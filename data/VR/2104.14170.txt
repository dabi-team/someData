Spatial Privacy-aware VR streaming

Xing Wei and Chenyang Yang
School of Electronics and Information Engineering, Beihang University, Beijing 100191, China
Email: {weixing, cyyang}@buaa.edu.cn

1

1
2
0
2

r
p
A
0
3

]

M
M

.
s
c
[

2
v
0
7
1
4
1
.
4
0
1
2
:
v
i
X
r
a

Abstract—Proactive tile-based virtual reality (VR) video
streaming employs the current tracking data of a user to predict
future requested tiles, then renders and delivers the predicted
tiles before playback. Very recently, privacy protection in proac-
tive VR video streaming starts to raise concerns. However,
existing privacy protection may fail even with privacy-preserve
federated learning. This is because when the future requested
tiles can be predicted accurately, the user-behavior-related data
can still be recovered from the predicted tiles. In this paper, we
consider how to protect privacy even with accurate predictors
and investigate the impact of privacy requirement on the quality
of experience (QoE). To this end, we ﬁrst add extra camouﬂaged
tile requests to the real tile requests and model the privacy
requirement as the spatial degree of privacy (sDoP). By ensuring
sDoP, the real tile requests can be hidden and privacy can be
protected. Then, we jointly optimize the durations for prediction,
computing, and transmitting, aimed at maximizing the privacy-
aware QoE given arbitrary predictor and conﬁgured resources.
From the obtained optimal closed-form solution, we ﬁnd that the
impacts of sDoP on the QoE are two sides of the same coin.
On the one side the increase of sDoP improves the capability
of communication and computing hence improves QoE. On the
other side it degrades the prediction performance hence degrades
the QoE. The overall impact depends on which factor dominates
the QoE. Simulation with two predictors on a real dataset veriﬁes
the analysis and shows that the overall impact of sDoP is to
improve the QoE.

Index Terms—privacy-aware VR, proactive VR, privacy pro-

tection, spatial degree of privacy, VR federated learning

I. INTRODUCTION

Wireless virtual reality (VR) can provide a seamless and
immersive experience to users. As the main type of VR
services, 360◦ video has the following unique features. First,
360◦ video usually has 360◦ ×180◦ panoramic view with ultra
high resolution (e.g., binocular 16K [1]). Second, the range
of angles of a 360◦ video that humans can see at arbitrary
time is only a small portion of the full panoramic view (e.g.,
110◦ × 110◦), which is called the ﬁeld of view (FoV). Third,
the stalls or black holes during watching 360◦ video will cause
physiological discomfort, e.g., dizziness, which degrades the
quality of experience (QoE) and thus should be avoided.

To stream such video with QoE guarantee, proactive
VR video streaming is proposed [2], which divides a full
panoramic view segment into small tiles in the spatial domain.
Before the playback of the segment, the tiles to be most likely
requested in the segment are ﬁrst predicted using the user-
behavior-related data in an observation window, which are then
rendered and ﬁnally delivered to the user.

While proactive VR video streaming is being intensively
investigated in academia and industry, most of the existing
works neglect the willingness of users. Are users willing to
share their behavior-related data while watching 360◦ videos?

Recent work shows that with less than 5 minutes tracking
data while watching VR videos, the random forest algorithm
can correctly identify 95% of users among all the 511 users
[3]. This indicates that behavior-related data can be used to in-
fer personal information. With the development of technology,
one may be able to dig more personal information than be-
yond imagination. Very recently, the ﬁrst privacy requirement
dataset shows that the privacy requirements of 360◦ videos
among videos and users are heterogeneous, and only 41% of
the totally watched videos have no privacy requirement [4].

With these ﬁndings, privacy protection in VR video stream-
ing starts to raise concerns. A privacy-preserve approach
has been proposed to continuously upload one of the user-
behavior-related data—eye-tracking data [5]. Privacy require-
ment has been deﬁned in the temporal domain and the cor-
responding impact on QoE has been investigated [4]. How-
ever, proactive VR streaming still needs to predict the future
requested tiles. When the prediction is accurate, the user-
behavior-related data can still be recovered from the predicted
tiles, and the privacy protection may fail. Then, here comes
two problems: How to protect privacy in VR video streaming
even with accurate predictors? What is the impact of privacy
protection on the system?

In this paper, we strive to answer these questions. Our

contributions can be summarized as follows.

• To protect privacy even with accurate predictors, we blur
the real tile requests by adding extra camouﬂaged tile
requests. Speciﬁcally, we deﬁne the spatial degree of
privacy (sDoP) as a metric related to the number of extra
camouﬂaged requested tiles in addition to real requested
tiles. Then, the input of the predictor becomes a mixture
of real and camouﬂaged requested tiles. A larger sDoP
indicates more extra camouﬂaged tile requests, which
will degrade the prediction accuracy. By ensuring sDoP,
the real tile requests can be hidden and privacy can be
efﬁciently protected.

• Based on the deﬁned privacy requirement, we opti-
mize the durations for prediction, communication, and
computing under arbitrarily given predictor as well as
communication and computing resources to maximize the
QoE. From the obtained optimal solution, we ﬁnd that the
impacts of sDoP on the QoE are contradictory. One the
one hand, the increase of sDoP improves the capability
of communication and computing hence improves QoE.
On the other hand, it degrades the prediction performance
hence degrades the QoE. The overall impact depends on
which factor dominates the QoE.

• Simulation with two predictors on a real dataset veriﬁes
the analysis and shows that the overall impact of increas-

 
 
 
 
 
 
2

ing the sDoP is to improve the QoE.

II. SYSTEM MODEL
Consider a tile-based VR video streaming system with a
multi-access edge computing (MEC) server co-located with a
base station (BS) that serves K users. The MEC server equips
with powerful computing units for rendering, accesses a VR
video library by local caching or high-speed backhaul, thus
the delay from the Internet to the MEC server can be omitted.
Each user requests 360◦ videos from the library according to
their own interests. In the sequel, we consider arbitrary one
request for vth video from kth user for analysis.

Each VR video consists of L segments in the temporal
domain, and each segment consists of M tiles in the spatial
domain. The playback duration of each tile equals the playback
duration of a segment, denoted by Tseg [2], [6].

Each user is equipped with an head mounted display
(HMD), which can measure the user-behavior-related data
(e.g., the head movement trace), send the tile requests to the
MEC server, and pre-buffer segments. To protect the privacy
of users, the HMD is also equipped with a light-weighted
computing unit for training a predictor and predicting tile
requests.

A. Spatial Degree of Privacy

degree of privacy as the ratio of extra camouﬂaged requested
tiles except tiles in an FoV among all the extra tiles except
tiles in an FoV, i.e.,

ρs (cid:44) Np − Nfov
M − Nfov

∈ [0, 100%]

(1)

where Np is the number of privacy-aware requested tiles in
a segment, which contains real or predicted requested tiles
and camouﬂaged requested tiles, Nfov is the number of tiles
in an FoV of a segment. Both numbers of real and predicted
requested tiles are Nfov. To protect privacy, Np ≥ Nfov. To
illustrate the sDoP, we provide an example in Fig. 1. The
number of tiles in an FoV is Nfov = 6, the predicted or
real requested tiles in the FoV are No. 24-26, 34-36. To
protect the privacy, varies masking schemes can be employed.
For example, for masking scheme (a), the extra camouﬂaged
requested tiles are No. 13-18, 23, 27, 28, 33, 37, 38, 43-48,
and the number of privacy-aware requested tiles is Np = 24.
Then, sDoP is ρs = 24−6
60−6 = 33.3%. When ρs = 0, the user
has no privacy requirement, the real or predicted tile requests
are uploaded to the MEC server. When ρs = 100%, the user
has the most stringent privacy requirement, the HMD always
requests all tiles or predicts all tiles will be requested.

When the user sets privacy requirement sDoP, the number
of privacy-aware requested tiles can be obtained from (1) as

Np(ρs) = Nfov + ρs(M − Nfov)

(2)

Fig. 1: Predicted or real requested tiles and privacy-aware
requested tiles in a segment, M = 60, Nfov = 3 × 2 = 6,
Np = 6 × 4 = 24.

For training a tile request predictor or predicting the re-
quested tiles at the MEC server by centralized learning, the
requested tiles should be uploaded to the MEC server. To hide
the real tile requests when a user has privacy requirement,
the HMD should request a mixture of real and camouﬂaged
requested tiles. For training at HMDs, say by federated
learning, the real tile requests are only stored at the local
HMD. However, when predicting at HMD, the predicted tile
requests still need to be uploaded to the MEC server. When the
prediction is accurate, the MEC server can still obtain the real
tile requests. That is to say, even with federated learning for
VR streaming, privacy will still be leaked out. Therefore, for
the same reason of privacy protection, the HMD should also
upload a mixture of predicted and camouﬂaged requested tiles.
To reﬂect the privacy requirement in centralized and federated
prediction when watching 360◦ videos, we deﬁne the spatial

Fig. 2: Streaming the ﬁrst four segments of a VR video. tb is
the start time of the observation window, te is the start time
of playback of the l0th segment, l0 = 3.

B. Streaming Procedure

As shown in Fig. 2, when a user requests a VR video with
sDoP ρs, the MEC server ﬁrst streams the initial (l0 − 1)th
segments in a passive streaming mode [7]. After an initial
delay, the ﬁrst segment begins to play at the time instant
tb, which is also the start time of the observation window.
Then, proactive streaming for l0th segment begins, subsequent
segments are predicted, computed, and transmitted. In the
sequel, we take the l0th segment as an example for elaboration.

Privacy-aware requested tiles,  masking scheme (b) WidthPrivacy-aware requested tiles,  masking scheme (a)Playback durationHeightPredicted  or real requested  tilessegT    1  2  3  4  5  6  7  8  9  10          11  12  13  14  15  16  17  18  19  20    21  22  23  24  25  26  27  28  29  30    31  32  33  34  35  36  37  38  39  40    41  42  43  44  45  46  47  48  49  50    51  52  53  54  55  56  57  58  59  60          1  2  3       4       5         6        7        8        9       10         10 20 30 40 50 60               Playback PassiveProactiveInitial delaytHead movement trace1RenderingTransmitting 2343344Prediction and tile selectionTile selectioncpttcomtpdwsegTTobwtccTpsTbtetAfter the MEC server collects the user-behaviour-related
data in an observation windows with duration tobw, the tiles
to be played in the l0th segment with duration Tpdw = Tseg
can be predicted. To avoid playback stalling, rendering and
transmitting the tiles in l0th segment should be ﬁnished before
the start time of playback of l0th segment, i.e., the time instant
te. The duration beginning from tb and terminating at te, is the
proactive streaming time for a segment Tps. We can observe
that Tps = (l0 − 1)Tseg. In Fig. 2, we consider predicting the
third segment as an example, i.e., l0 = 3, Tps = 2Tseg.

Speciﬁcally, at

the end of the observation window,

tile
request probabilities or the ﬁxation sequences of FoVs in
the l0th segment can be predicted at HMD. Based on the
probabilities (or the ﬁxation sequences) and the number of tiles
in an FoV Nfov, the predicted requested tiles can be obtained
[4]. Given sDoP ρs, the number of privacy-aware requested
tiles Np(ρs) can be obtained from (2). Then, based on the
predicted requested tiles, Np(ρs), and a masking scheme (say
scheme (b) in Fig. 1), the extra camouﬂaged requested tiles can
be determined. The selected tiles are rendered with duration
tcpt and the sequence of FoVs can be generated, and ﬁnally the
sequence of FoVs are transmitted with duration tcom, which
should be ﬁnished before the start time of playback for the
predicted segment. The durations for observation, computing,
and transmitting should satisfy tobw + tcpt + tcom = Tps. The
duration for communication and computing can be expressed
as tcc (cid:44) tcom + tcpt.

C. Computing and Transmission Model

According to the computing model in [8], the number of bits
that can be rendered per second, referred to as the computing
rate, is Ccpt,k (cid:44) Fcpt,k
(in bit/s), where µr is the required
K·µr
ﬂoating-point operations (FLOPs) for rendering one bit of FoV
in FLOPs/bit [8].

The BS serves K single-antenna users using zero-forcing
beamforming with Nt antennas. The instantaneous data rate
at the ith time slot for the kth user is

(cid:32)

C i

com,k = B log2

1 +

(cid:33)

k |˜hi
kd−α
pi
σ2

k|2

(cid:44) (hi

k)H wi

k and wi

where B is the bandwidth, ˜hi
k is the equivalent
k
channel gain, pi
k are respectively the transmit power
k ∈ CNt
and beamforming vector for the kth user, dk and hi
are respectively the distance and the small scale channel vector
from the BS to the kth user, α is the path-loss exponent, σ2
is the noise power, and (·)H denotes conjugate transpose.

We consider indoor users as in the literature, where the
distances of users, dk, usually change slightly [6], [9] and
hence are assumed ﬁxed. Due to the head movement and the
variation of the environment, small-scale channels are time-
varying, which are assumed as remaining constant in each
time slot with duration ∆T and changing independently with
identical distribution among time slots. With the proactive
transmission, the rendered tiles in a segment should be trans-

mitted with duration tcom. The number of bits transmitted with
tcom can be expressed as C com,k · tcom, where

3

C com,k (cid:44) 1
Ns

Ns(cid:88)

C i

com,k · ∆T

i=1
is the time average transmission rate, and Ns is the number
of time slots in tcom. Since future channels are unknown
when making the optimization, we use ensemble-average
rate Eh{Ccom,k} [10] to approximate the time-average rate
C com,k, where Eh{·} is the expectation over h, which can be
very accurate when Ns or Nt/K is large [8].

To ensure fairness among users in terms of QoE,
the
transmit power is allocated to compensate the path loss, i.e.,
, where β can be obtained from β((cid:80)K
k = β
pi
) = P
d−α
k
and P is the maximal transmit power of the BS. Then, the
ensemble-average transmission rate for each user is equal.

1
d−α
k

k=1

In the sequel, we consider arbitrary one user and use Ccom
to replace Eh{Ccom,k} and Ccpt,k for notional

and Ccpt
simplicity.

A. Performance Metric of Tile Prediction

III. PROBLEM FORMULATION

Average segment degree of overlap (average-DoO) has been
used to measure the prediction performance for a VR video
[8]. It indicates the average overlap of the predicted tiles and
the real requested tiles among all the proactively streamed
segments, which is deﬁned as

D(tobw) (cid:44)

1
L − l0 + 1

L
(cid:88)

l=l0

qT
l · el(tobw)
(cid:107)ql(cid:107)1

∈ [0, 100%]

where ql (cid:44) [ql,1, ..., ql,M ]T denotes the ground truth of
the tile requests for the lth segment with ql,m ∈ {0, 1},
el(tobw) (cid:44) [el,1(tobw), ..., el,M (tobw)]T denotes the predicted
tile requests for the segment with el,m(tobw) ∈ {0, 1}, (·)T
denotes transpose of a vector, and (cid:107) · (cid:107)1 denotes the (cid:96)1 norm
of a vector. When the mth tile in the lth segment is truly
requested, ql,m = 1, otherwise ql,m = 0. When the tile is
predicted to be requested, el,m(tobw) = 1, otherwise it is zero.
We consider (cid:107)el (tobw) (cid:107)1 = Nfov. A larger value of average-
DoO indicates a better prediction.

As the veriﬁed Assumption 1 in [8] states, a predictor can be
more accurate with a longer observation window. Therefore,
average-DoO is a monotonically increasing function of tobw.

B. Communication and Computing Capability as well as
Resources Rate

The capability of communication and computing (CC) can
be used to measure the capability of streaming tiles. It is
the ratio of tiles in a segment
that can be rendered and
transmitted with assigned transmission and computing rates
and corresponding durations, i.e.,

Ccc(tcom, tcpt) (cid:44) min

(cid:26) Ccomtcom
scom
(cid:111)

,

Ccpttcpt
scpt

(cid:27)(cid:30)

, M

M

(cid:110) Ccomtcom
scom

, M
where min
is the number of tiles that
can be computed and transmitted, scom = pxw · pxh · b · rf ·
Tseg/γc [1] is the number of bits in each tile for transmission,

, Ccpttcpt
scpt

4

scpt = pxw · pxh · b · rf · Tseg is the number of bits in a tile for
rendering, pxw and pxh are the pixels in wide and high of a
tile, b is the number of bits per pixel relevant to color depth
[1], rf is the frame rate, and γc is the compression ratio.

To reﬂect the capability of streaming tiles in unit time, we

further deﬁne the resources rate as

Rcc (cid:44) Ccc(tcom, tcpt)

tcc

,

(3)

C. Metric of Privacy-aware Quality of Experience

For proactive tile-based streaming without privacy require-
ment, the QoE can be measured by the percentage of the
correctly streamed tiles among all the real requested tiles [8].
When considering the spatial degree of privacy, we should also
consider whether the sDoP can be satisﬁed. This is because if
the QoE is only captured by the percentage of the correctly
predicted tiles,
the MEC server can still obtain the
accurate location of real requested tiles from the feedback of
QoE from the HMD. Therefore, the privacy-aware QoE should
consist of two parts: (1) The percentage of correctly streamed
tiles. (2) The level of sDoP satisfaction. For arbitrary given
predictor, sDoP, and resources, we consider the following
privacy-aware QoE metric

then,

QoE (cid:44)

1
L − l0 + 1

L
(cid:88)

l=l0

(ql)T · sl
(cid:107)ql(cid:107)1
(cid:123)(cid:122)
percent of correctly streamed tiles

(cid:124)

(cid:125)

·

(qρ

l )T · sl
(cid:107)qρ
l (cid:107)1
(cid:125)
(cid:123)(cid:122)
(cid:124)
sDoP satisfaction

where sl (cid:44) [sl,1, ..., sl,M ]T denotes the selected tiles for
streaming with sl,m ∈ {0, 1}, qρ
l,M ]T denotes
l
the privacy-aware tile requests for the segment with qρ
l,m ∈
{0, 1}. When the tiles are selected, sl,m = 1, otherwise
sl,m = 0. When the tile is truly requested or camouﬂaged
to be requested, qρ

l,m = 1, otherwise qρ

l,1, ..., qρ

l,m = 0.

(cid:44) [qρ

The number of selected tiles is limited by the CC capability,
i.e., (cid:107)sl(cid:107)1 = Ccc(tcom, tcpt) · M . The number of privacy-
aware requested tiles depends on sDoP, i.e., (cid:107)qρ
l (cid:107)1 = Np(ρs).
To gain useful insight, we assume that the selected tiles are
the privacy-aware requested tiles, i.e., sl = qρ
l . Hence the
number of selected tiles and privacy-aware requested tiles are
also identical, i.e.,

Ccc(tcom, tcpt) · M = Np(ρs)

Then, the privacy-aware QoE degenerates into

QoE =

1
L − l0 + 1

L
(cid:88)

l=l0

(ql)T · qρ
l
(cid:107)ql(cid:107)1

(4)

(5)

satisﬁed. When D (tobw) is improved, more of the streamed
tiles are the real requested tiles. Then, we can ﬁnd that the
privacy-aware QoE monotonically increases with average-DoO
and CC capability, respectively.

IV. SDOP: CONTRADICTORY ROLES FOR THE QOE
In this section, we investigate the role of sDoP for the
privacy-aware QoE. To this end, we ﬁrst optimize durations
for observation window, communication, and computing to
maximize the QoE. From the obtained closed-form solution,
we investigate the impact of sDoP on average-DoO and CC
capability, respectively. Finally, we discuss the overall impact
of sDoP on the QoE.
A. Joint Optimization of the Durations for Prediction, Com-
munication, and Computing

Given arbitrary computing rate Ccpt, transmission rate Ccom
and sDoP ρs, we aim to ﬁnd the optimal durations for
observation window, communication and computing to achieve
the maximized QoE, i.e.,

P0 :

max
tobw,tcpt,tcom

Q (D (tobw) , Ccc(tcom, tcpt))

(6a)

s.t. Ccc(tcom, tcpt) =

Np(ρs)
M

tobw + tcpt + tcom = Tps

As derived in the Appendix, the solution of P0 is,
(cid:18) scom
(cid:19)(cid:30)
Ccom

t∗
obw =

· Np(ρs)

Tps −

(cid:22) (cid:18)

+

(cid:19)

t∗
com =

scomNp(ρs)
Ccom

t∗
cpt =

scpt
Ccpt
scptNp(ρs)
Ccpt

(6b)

(6c)

(7a)

(7b)

(cid:23)

τ

where τ (in seconds) is the sampling interval of the user-
behavior-related data in the observation window. The optimal
duration for communication and computing t∗
cc can be obtained
from (7b) as

t∗
cc =

(cid:18) scom
Ccom

+

scpt
Ccpt

(cid:19)

· Np(ρs)

(8)

By substituting (7b) into (3), the maximized resources rate is

R∗

cc = 1

(cid:30)(cid:18) scomM
Ccom

(cid:19)

+

scptM
Ccpt

(9)

(cid:16) scomM
Ccom

+ scptM
Ccpt

is the required optimal duration to
where
render and transmit all tiles in a segment. By substituting (9)
into (7a), t∗

(cid:17)

obw can also be expressed as
Np(ρs)
R∗
cc · M

t∗
obw =

Tps −

(cid:22) (cid:18)

(cid:19)(cid:30)

(cid:23)

τ

(10)

We can observe that the QoE is affected by the average-DoO

B. Contradictory Roles of sDoP

and the CC capability, which can be expressed as

1) Improve the CC Capability: By substituting (8) and (9)

QoE = Q (D (tobw) , Ccc(tcom, tcpt)) ∈ [0, 100%]

When the value of the QoE is 100%, all the truly requested
tiles in a VR video are proactively computed and delivered
before playback. Moreover, the MEC server only obtains the
privacy-aware tile requests.

When Ccc(tcom, tcpt) is improved, more tiles can be ren-
dered and transmitted, then more real requested tiles can be

into (3), the CC capability can be rewritten as follows:
com, t∗

cpt) = R∗

Ccc(t∗

cct∗
cc,

Further considering (8) and (9), we can ﬁnd that the resources
rate R∗
cc has no relation with ρs. Besides, the optimal total
duration for communication and computing t∗
cc increases with
the increase of ρs improves the CC
ρs. This means that
capability.

2) Degrade the Average-DoO: With the increase of ρs, the
duration of observation window t∗
cc will be
reduced, which can also be veriﬁed from (7a). The reduction
of t∗

obw = Tps − t∗

obw degrades the average-DoO.
In Fig. 3, we use the values of t∗

obw obtained from (7a)
to visualize the impact of ρs on the average-DoO. We can
observe that as the increase of ρs,
obw
is discrete, which comes from the discrete sampling in the
observation window. Besides, the value of t∗
obw increases with
the maximized resources rate R∗
cc. This is because when the
resources rate is increased, privacy-aware requested tiles can
be streamed with less duration, i.e., t∗
cc is reduced. Then,
obw = Tps − t∗
t∗

the reduction of t∗

cc is increased.

5

FederatedAveraging algorithm in [16]. The settings of
the federated learning are as follows. For each round, we
select all of K = 30 users to update the model parameters
of the predictor. The number of local epochs for each user is
El = 50, the number of communication rounds is R = 10.
Hence, every trace in the train set is used 50 × 10 = 500 times
for training, which is consistent with the centralized training
[14]. The weighting coefﬁcient of the kth user on the model
parameter is ck = nk
, where Ntrain = 300 × 0.8 = 240 is
Ntrain
the total number of traces in the train set, nk is the number of
video traces that belong to the kth user in the training set. Due
to the random division of training and testing sets, nk varies
from 6 to 10. We refer to the predictor as tailored federated
position-only predictor. Other details and hyper-parameters
of the tailored predictor are the same as the position-only
predictor [14]. The no-motion predictor simply uses the last
position in the observation window as the predicted time series
of future positions [14].

The maximized resources rate R∗

cc depends on the con-
ﬁgured communication and computing resources as well as
the number of users. For example, when K = 4, Nt = 8,
P = 24 dBm, B = 150 MHz, and dk = 5 m, the ensemble-
average transmission rate for a user is Ccom = 2.85 Gbps
[8]. When Nvidia RTX 8000 GPU is used for rendering
VR videos for four users, the computing rate for a user is
Ccpt = 2.2 Gbps [8]. Then, the maximized resources rate is
R∗
= 0.6. To reﬂect the variation
of conﬁgured resources, we set R∗

(cid:46)(cid:16) scomM
Ccom

+ scptM
Ccpt

cc = 1

cc ∈ [0.6, 2].

(cid:17)

The settings of VR video are listed in Table I. To gain
useful insight, we assume that all users have identical sDoP
requirement among all videos, ranging from 0 to 100%. The
procedure of simulation is given in Procedure 1.

Procedure 1 Obtain the average QoE, D(t∗

obw), and

cpt)

com, t∗

Ccc(t∗
Input: set ρs ∈ [0, 100%], R∗

cc ∈ [0.6, 2].

obw from (10).

obw and two predictors, obtain the predicted

(i). Given sDoP ρs and maximized resource rates R∗
cc,
obtain the values of the optimal duration of observation
window t∗
(ii). Train the tailored federated position-only predictor with
different t∗
obw.
(iii). Given t∗
time series of positions.
(iv). With Nfov, determine the predicted requested tiles by
scheme (b) of Section IV-C in [4].
(v). Given sDoP, obtain the CC capability from (4).
(vi). Given the CC capability, the predicted requested tiles,
and masking scheme (a) in Fig. 1, determine the extra
camouﬂaged requested tiles.
(vii). Calculate the QoE from (5), then average over the
testing set.

In Fig. 4, we show the average QoE achieved by two
predictors versus the assigned resources rate and sDoP. We
can observe that no matter how much the resources rate is
assigned, which predictor is employed, the average QoE can
always be improved with the increase of ρs. Besides, the

Fig. 3: t∗

cc and ρs.

obw v.s. R∗
3) Overall Impact: For the ﬁnal QoE, the impact of sDoP is
complicated. On the one hand, it improves the CC capability.
On the other hand, it degrades the average-DoO. Generality
speaking, the overall effect depends on if the QoE is dominated
by the increase of CC capability or the reduction of the
average-DoO.

V. TRACE-DRIVEN SIMULATION RESULTS

In this section, we show the overall impact of sDoP on
QoE via trace-driven simulation results. First, we consider the
prediction task on a real dataset [9], where 300 traces of head
movement positions from 30 users watching 10 VR videos are
used for training and testing predictors.1 We randomly split the
total traces into training and testing sets with the ratio 8:2.

We use two predictors, position-only and no-motion pre-
dictors, which achieve the state-of-the-art accuracy for the
dataset, according to tests in [14]. The position-only predictor
employs a sequence-to-sequence LSTM-based architecture,
which uses the time series of past head movement positions as
input, to predict the time series of future positions [14]. The
predictor does not consider the time required for computing
and communication as well as the spatial degree of privacy.
To reserve time for computing and communication, we tailor
the predictor as follows. Set the duration between the end of
the observation window and the beginning of the prediction
windows as t∗
cc, set the durations of observation and prediction
windows as t∗
obw and Tseg, respectively. To satisfy the pri-
vacy requirement, we consider a classical federated learning,

1According to the analysis in [14], [15], the traces of the ﬁrst 20 users in
the dataset have mistakes, thus we only use the traces of the other 30 users.

6

TABLE I: Settings of VR video

Resolution
Number of tiles M
Pixels in wide of a tile pxw
Compression ratio γc
Number of bits in a tile for transmission scom
Size of FoV

12 bits per pixel [1]
30 FPS [11]
2160/10 = 216
1 s [11]
14.2 Mbitsa
33b
aThese values are calculated from the deﬁnition in Section III-B. bThis is the average value on the dataset [9], according to our tests.

b
Frame rate rf
Pixels in height of a tile pxh
Playback duration of a segment Tseg
Number of bits in a tile for rendering scpt
Number of tiles in an FoV Nfov

3840×2160 pixels [11]
10 rows × 20 columns = 200
3840/20 = 192
2.41 [12]
5.9 Mbitsa
100◦ × 100◦ circles [13], [14]

(a) No-motion predictor

(a) No-motion predictor

(b) Tailored federated postion-only predictor
Fig. 4: Average QoE v.s. resource rates and sDoP.

increase of ρs is equivalent to the increase of assigned
resources rate in terms of improving the QoE. For example,
consider the point “P” in Fig. 4b. To achieve QoE = 94%,
increasing ρs by 0.2 is equivalent to increasing R∗

cc by 1.4.

To further understand how the QoE is affected by the sDoP,
we consider a case where the resource rates R∗
cc = 0.6 as an
com, t∗
example, to investigate how the CC capability Ccc(t∗
cpt),
average-DoO D(t∗
obw), and average QoE is affected by ρs.
the increase of
As shown in Fig. 5, for both predictors,
sDoP improves the CC capability Ccc(t∗
com, t∗
cpt) and degrades
average-DoO D(t∗
obw). Since the degradation of average-DoO
is relative small, the QoE is dominated by the increase of the
CC capability.

VI. CONCLUSION
In this paper, we deﬁned spatial privacy requirement for
better privacy protection and investigated the impact of spatial
privacy requirement on VR video streaming. By duration
optimization and analyzing the obtained optimal closed-form
solution, we found the relation between sDoP and QoE. The
analysis showed that the increase of sDoP improves the CC

cc = 0.6.

(b) Tailored federated position-only predictor
Fig. 5: Average QoE, CC capability, and average-DoO v.s.
sDoP, R∗
capability but degrades the average-DoO. The overall impact
of sDoP on QoE depends on which factor dominates the QoE.
Simulation with two predictors on a real dataset validated the
analysis and showed that the overall impact of sDoP is to
improve the QoE.

REFERENCES

[1] iLab, “Cloud VR network solution whitepaper,” Huawei Technologies
CO., LTD., Tech. Rep., 2018. [Online]. Available: https://www.huawei.
com/minisite/pdf/ilab/cloud vr network solution white paper en.pdf
[2] F. Qian, L. Ji, B. Han, and V. Gopalakrishnan, “Optimizing 360 video
delivery over cellular networks,” ACM SIGCOMM Workshop, 2015.
[3] M. R. Miller, F. Herrera, H. Jun, J. A. Landay, and J. N. Bailenson,
“Personal identiﬁability of user tracking data during observation of 360-
degree VR video,” Scientiﬁc Reports, vol. 10, no. 1, pp. 1–10, 2020.
[4] X. Wei and C. Yang, “Privacy-aware VR streaming,” arXiv:2104.09779,

2021.

[5] B. David-John, D. Hosfelt, K. Butler, and E. Jain, “A privacy-preserving
approach to streaming eye-tracking data,” IEEE Transactions on
Visualization and Computer Graphics, vol. 27, no. 5, p. 2555–2565,
May 2021. [Online]. Available: http://dx.doi.org/10.1109/TVCG.2021.
3067787

[6] C.-L. Fan, W.-C. Lo, Y.-T. Pai, and C.-H. Hsu, “A survey on 360◦ video
streaming: Acquisition, transmission, and display,” ACM Comput. Surv.,
vol. 52, no. 4, Aug. 2019.

020%40%60%80%100%00.20.40.60.8160%70%80%90%100%020%40%60%80%100%00.20.40.60.8160%70%80%90%100%7

can be continuous, the user behavior-related data is sampled
discretely. Then,
the efﬁcient duration of the observation
window is

t∗
obw =

(cid:22) (cid:18)

Tps −

(cid:18) scom
Ccom

+

scpt
Ccpt

(cid:19)

(cid:19)(cid:30)

(cid:23)

· Np(ρs)

τ

(12)

[7] 3GPP, “Extended reality (XR) in 5G,” 2020, 3GPP TR 26.928 version

16.0.0 release 16.

[8] X. Wei, C. Yang, and S. Han, “Prediction, communication, and com-
puting duration optimization for VR video streaming,” IEEE Trans.
Commun., vol. 69, no. 3, pp. 1947–1959, 2021.

[9] W.-C. Lo, C.-L. Fan, J. Lee, C.-Y. Huang, K.-T. Chen, and C.-H. Hsu,
“360◦ video viewing dataset in head-mounted virtual reality,” ACM
MMSys, 2017.

[10] D. Bethanabhotla, G. Caire, and M. J. Neely, “Adaptive video streaming
for wireless networks with multiple users and helpers,” IEEE Trans.
Commun., vol. 63, no. 1, pp. 268–285, 2015.

[11] A. Mahzari, A. T. Nasrabadi, A. Samiei, and R. Prakash, “FoV-aware
edge caching for adaptive 360° video streaming,” ACM MM, 2018.
[12] M. Zhou, W. Gao, M. Jiang, and H. Yu, “HEVC lossless coding and
improvements,” IEEE Trans. Circuits Syst. Video Technol., vol. 22,
no. 12, pp. 1839–1843, 2012.

[13] C.-L. Fan, J. Lee, W.-C. Lo, C.-Y. Huang, K.-T. Chen, and C.-H. Hsu,
“Fixation prediction for 360◦ video streaming in head-mounted virtual
reality,” ACM NOSSDAV, 2017.

[14] Miguel Romero, “Analysis of head motion prediction in virtual reality,”

https://gitlab.com/miguelfromeror/head-motion-prediction/tree/master/.

[15] M. F. R. Rond´on, L. Sassatelli, R. Aparicio-Pardo, and F. Precioso, “A
uniﬁed evaluation framework for head motion prediction methods in
360° videos,” ACM MMsys, 2020.

[16] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efﬁcient learning of deep networks from decentralized
data,” PMLR AISTATS, 2017.

APPENDIX A
PROOF OF THE SOLUTION OF PROBLEM P0
We can observe that for arbitrary ρs, CC capability is ﬁxed
as Ccc(tcom, tcpt) = Np(ρs)
M . Then, QoE becomes a function
of a single variable D(tobw). Furthering consider Remark 1,
we can ﬁnd maximizing D(tobw) is equivalent to maximize
tobw = Tps − (tcom + tcpt). Then, without loss of optimally,
P0 can be transformed as

min
tcpt,tcom

s.t. min

tcom + tcpt
(cid:26) Ccomtcom
scom

(11a)

,

Ccpttcpt
scpt

(cid:27)

, M

= Np(ρs), (11b)

where (11b) can be obtained by multiplying both sides of (6b)
by M . Since Np(ρs) ≤ M , (11b) can be further simpliﬁed as
(cid:110) Ccomtcom
= Np(ρs). According to the constraint,
scom

, Ccpttcpt
scpt

(cid:111)

we discuss problem (11) in the following three cases.

, upon substituting into

(1) When Ccomtcom

> Ccpttcpt

scom

scpt
(11b), we have tcpt = Np(ρs)scpt
condition Ccomtcom
Then, we obtain tcom + tcpt > scomNp(ρs)

Ccpt
> Ccpttcpt
scpt

scom

Ccom

. Upon substituting into the
, we obtain tcom ≥ Np(ρs)scom

.

+ scptNp(ρs)
Ccpt

Ccom
.

, upon substituting into (11b),

(2) When Ccomtcom

scom

< Ccpttcpt
scpt

we have tcom = Np(ρs)scom
< Ccpttcpt
Ccomtcom
scom
scpt
obtain tcom + tcpt > scomNp(ρs)
Ccom
= Ccpttcpt
scpt

(3) When Ccomtcom

scom

Ccom
, we obtain tcpt > Np(ρs)scpt

. Upon substituting the condition
. Then, we

Ccpt
.

+ scptNp(ρs)
Ccpt
, upon substituting into (11b),

we have tcom = Np(ρs)scom
obtain tcom + tcpt = scomNp(ρs)

Ccom

and tcpt = Np(ρs)scpt
+ scptNp(ρs)
Ccpt

Ccpt
.

Ccom

From the three cases, we obtain the solution as t∗

. Then, we

scomNp(ρs)
Ccom

, t∗

cpt = scptNp(ρs)

Ccpt

com =
. Upon substituting into (6c),
+ scpt
Ccpt

(cid:16) scom
Ccom

(cid:17)

·Np(ρs).
tobw can be obtained as tobw = Tps −
Note that although the duration of the observation window

