2
2
0
2

y
a
M
6
1

]

C
O
.
h
t
a
m

[

5
v
1
0
1
6
1
.
6
0
1
2
:
v
i
X
r
a

AdaGDA: Faster Adaptive Gradient Descent Ascent Methods
for Minimax Optimization

Feihu Huang∗, Heng Huang †

Abstract

In the paper, we propose a class of faster adaptive Gradient Descent Ascent (GDA) meth-
ods for solving the nonconvex-strongly-concave minimax problems by using uniﬁed adaptive
matrices, which include almost existing coordinate-wise and global adaptive learning rates.
In particular, we provide an eﬀective convergence analysis framework for our adaptive GDA
methods. Speciﬁcally, we propose a fast Adaptive Gradient Descent Ascent (AdaGDA) method
based on the basic momentum technique, which reaches a lower gradient complexity of O(κ4(cid:15)−4)
for ﬁnding an (cid:15)-stationary point without large batches, which improves the existing results of
the adaptive GDA methods by a factor of O(
κ). At the same time, we present an accelerated
version of AdaGDA (VR-AdaGDA) method based on the momentum-based variance reduced
technique, which achieves a lower gradient complexity of O(κ4.5(cid:15)−3) for ﬁnding an (cid:15)-stationary
point without large batches, which improves the existing results of the adaptive GDA methods
by a factor of O((cid:15)−1). Moreover, we prove that our VR-AdaGDA method can reach the best
known gradient complexity of O(κ3(cid:15)−3) with the mini-batch size O(κ3). Some experimental
results on policy evaluation and fair classiﬁer tasks verify eﬃciency of our algorithms.

√

1 Introduction

In the paper, we consider the following stochastic nonconvex-strongly-concave minimax problem

min
x∈X

max
y∈Y

Eξ∼D[f (x, y; ξ)],

(1)

where function f (x, y) = Eξ[f (x, y; ξ)] is µ-strongly concave over y but possibly nonconvex over x,
and ξ is a random variable following an unknown distribution D. Here X ⊆ Rd1 and Y ⊆ Rd2 are
nonempty compact convex sets. In fact, the problem (1) is widely used to many machine learning
applications, such as adversarial training [Goodfellow et al., 2014, Tram`er et al., 2018, Nouiehed
et al., 2019], reinforcement learning [Wai et al., 2019] and robust federated learning [Deng et al.,
2021]. In the following, we speciﬁcally provide two popular applications that can be formulated as
the above problem (1).

1). Policy Evaluation. Policy evaluation aims at estimating the value function corresponding
to a certain policy, which is a stepping stone of policy optimization and serves as an essential

∗Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, USA. Email:

huangfeihu2018@gmail.com

†Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, USA. Email:

henghuanghh@gmail.com

1

 
 
 
 
 
 
Table 1: Gradient complexity comparison of the representative gradient descent ascent meth-
ods for ﬁnding an (cid:15)-stationary point of the nonconvex-strongly-concave problem (1),
i.e.,
E(cid:107)∇F (x)(cid:107) ≤ (cid:15) or its equivalent variants, where F (x) = maxy∈Y f (x, y). ALR denotes adap-
tive learning rate. Cons(x, y) denotes constraint sets on variables x and y, respectively. Here Y
denotes the fact that there exists a convex constraint set on variable, otherwise is N. 1 denotes Lip-
schitz continuous of ∇xf (x, y), ∇yf (x, y) for all x, y; 2 denotes Lipschitz continuous of ∇xf (x, y; ξ),
∇yf (x, y; ξ) for all ξ, x, y; 3 denotes the bounded set Y with a diameter D ≥ 0.

Algorithm
SGDA
SREDA
Acc-MDA
Acc-MDA
PDAda
AdaGDA
VR-AdaGDA
VR-AdaGDA

Reference
Lin et al. [2020a]
Luo et al. [2020]
Huang et al. [2022]
Huang et al. [2022]
Guo et al. [2021]
Ours
Ours
Ours

Cons(x, y) Loop(s) Batch Size Complexity ALR Conditions

N, Y
N, Y
Y, Y
Y, Y
N, Y
Y, Y
Y, Y
Y, Y

Single
Double
Single
Single
Single
Single
Single
Single

O(κ(cid:15)−2)
O(κ2(cid:15)−2)
O(1)
O(κ3)
O(1)
O(1)
O(1)
O(κ3)

O(κ3(cid:15)−4)
O(κ3(cid:15)−3)
O(κ4.5(cid:15)−3)
O(κ3(cid:15)−3)
O(κ4.5(cid:15)−4)
O(κ4(cid:15)−4)
O(κ4.5(cid:15)−3)
O(κ3(cid:15)−3)

√
√
√
√

1, 3
2
2
2
1
1
2
2

component of many reinforcement learning algorithms such as actor-critic algorithm [Konda and
Tsitsiklis, 2000]. Speciﬁcally, we consider a Markov decision process (MDP) (S, A, P, R, τ ), where
S denotes the state space, and A denotes the action space, and P(s(cid:48)|s, a) denotes the transition
kernel to the next state s(cid:48) given the current state s and action a, and τ ∈ [0, 1) is the discount factor.
R(s, a, s(cid:48)) ∈ [−r, r] (r > 0) is an immediate reward once an agent takes action a at state s and
transits to state s(cid:48), and R(s, a) is the reward at (s, a), deﬁned as R(s, a) = Es(cid:48)∼P(·|s,a)[R(s, a, s(cid:48))].
π(s, a) : S × A → R denotes a stationary policy that is the probability of taking action a ∈ A given
the current state s ∈ S. We let V π(s) = E(cid:2) (cid:80)+∞
t=0 τ tR(st, at)|s0 = s, π(cid:3) denote state value function.
Further let V (s; θ) denote the parameterized approximate function of V π(s), and V (s; θ) generally
is a smooth nonlinear function. Following [Wai et al., 2019], we can solve the following minimax
problem to ﬁnd an optimal approximated value function, deﬁned as

min
θ∈Θ

max
ω∈Rd

Es,a,s(cid:48)

(cid:20)
(cid:104)δ∇θV (s; θ), ω(cid:105) −

1
2

ωT (cid:0)∇θV (s; θ)∇θV (s; θ)T (cid:1)ω

(cid:21)
,

(2)

where δ = R(s, a, s(cid:48)) + τ Vθ(s(cid:48)) − Vθ(s), and Es,a,s(cid:48) is taking expectation for s ∼ dπ(·) that is station-
ary distribution of states, a ∈ π(·, s) and s(cid:48) ∼ P(·|s, a). Here matrix Hθ = E(cid:2)∇θV (s; θ)∇θV (s; θ)T (cid:3)
is generally positive deﬁnite. The above problem (2) is generally nonconvex on variable θ when
using the neural networks to approximate value function V π(s).

2). Robust Federated Averaging. Federated Learning (FL) [McMahan et al., 2017] is
a popular learning paradigm for training a centralized model based on decentralized data over a
network of clients. Speciﬁcally, we have n clients in FL framework, and Di is the data distribution
on i-th device, and the data distributions {Di}n
i=1 generally are diﬀerent. The goal of FL is to learn
a global variable w based on these heterogeneous data from diﬀerent data distributions. To well
solve the data heterogeneity issue in FL, some robust FL methods [Deng et al., 2021, Reisizadeh
et al., 2020] have been proposed, which solve the following distributionally robust empirical loss
problem:

min
w∈Ω

max
p∈Π

(cid:26) n
(cid:88)

i=1

piEξ∼Di[fi(w; ξ)] − λψ(p)

(cid:27)

,

(3)

2

where pi ∈ (0, 1) denotes the proportion of i-th device in the entire model, and fi(w; ξ) is the
loss function on i-th device, and λ > 0 is a tuning parameter, and ψ(p) is a (strongly) convex
regularization. Here Π = {p ∈ Rn : (cid:80)n
i=1 pi = 1, pi ≥ 0} is a n-dimensional simplex, and Ω ⊆ Rd
is a nonempty convex set.

Since the above minimax problem (1) has been frequently appeared in many machine learning
applications, recently some methods have been proposed to solve it. For example, [Lin et al.,
2020a,b] proposed a stochastic gradient descent ascent (SGDA) method to solve the problem (1).
Subsequently, a class of accelerated SGDA methods [Luo et al., 2020, Huang et al., 2022] have been
presented based on the variance reduced techniques of SPIDER [Fang et al., 2018, Wang et al.,
2019] and STORM [Cutkosky and Orabona, 2019], respectively. More recently, Guo et al. [2021]
have proposed an adaptive version of SGDA method by using the adaptive learning rate to update
the variable x. Then there exists a natural question:

Can we develop some faster adaptive gradient descent ascent methods for solv-
ing the problem (1), which use adaptive learning rates in updating both variables
x and y ?

In the paper, we give an aﬃrmative answer to the above question and propose a class of faster
adaptive gradient descent ascent methods for solving the problem (1). Our methods can use many
types of adaptive learning rates in updating both variables x and y. Moreover, our methods can
ﬂexibly incorporate the momentum and variance-reduced techniques. Our main contributions are
three-fold:

(1) We propose a class of faster adaptive gradient descent ascent methods for the nonconvex-
strongly-concave minimax problem (1) by using the universal adaptive matrices for both
variables x and y, which include almost existing adaptive learning rates.

(2) We propose a fast adaptive gradient descent ascent (AdaGDA) method based on the basic
momentum technique used in Adam algorithm [Kingma and Ba, 2014]. Further, we propose
an accelerated version of AdaGDA (VR-AdaGDA) method based on the momentum-based
variance reduced technique used in STORM algorithm [Cutkosky and Orabona, 2019].

(3) We provide an eﬀective convergence analysis framework for our adaptive methods under some
mild assumptions. Speciﬁcally, we prove that our AdaGDA method has a gradient complexity
of O(κ4(cid:15)−4) without large batches, which improves the existing result of adaptive method for
solving the problem (1) by a factor of O(κ1/2). Our VR-AdaGDA method has a lower gradient
complexity of O(κ4.5(cid:15)−3) without large batches, which improves the existing best known result
by a factor of O((cid:15)−1) (Please see Table 1).

2 Related Works

In this section, we overview the existing ﬁrst-order methods for minimax optimization and adaptive
gradient methods, respectively.

3

2.1 Minimax Optimization Methods

Minimax optimization has recently been shown great successes in many machine learning applica-
tions such as adversarial training, robust federated learning and policy optimization. Thus, many
ﬁrst-order methods [Nouiehed et al., 2019, Lin et al., 2020a,b, Lu et al., 2020, Yan et al., 2020,
Yang et al., 2020b,a, Raﬁque et al., 2021, Liu et al., 2021] recently have been proposed to solve
the minimax problems. For example, some (stochastic) gradient-based descent ascent methods [Lin
et al., 2020a, Nouiehed et al., 2019, Lu et al., 2020, Yan et al., 2020, Lin et al., 2020b] have been
proposed for solving the minimax problems. Subsequently, some accelerated gradient descent ascent
algorithms [Raﬁque et al., 2021, Luo et al., 2020, Huang et al., 2022] have been proposed to solve the
stochastic minimax problems based on the variance-reduced techniques. More recently, Zhang et al.
[2021], Li et al. [2021] have studied the lower bound complexities of nonconvex-strongly-concave
minimax optimization. Meanwhile, Guo et al. [2021] have proposed an adaptive gradient descent
ascent method for solving the minimax problem (1) by using Adam-type learning rate to variable
x.

2.2 Adaptive Gradient Methods

Adaptive gradient methods are a class of popular optimization tools to solve large-scale machine
learning problems, e.g., Adam [Kingma and Ba, 2014] is the default optimization tool for training
deep neural networks (DNNs). Recently, the adaptive gradient methods have been widely studied
in machine learning community. Adam [Kingma and Ba, 2014] is one of popular adaptive gradient
methods, which uses a coordinate-wise adaptive learning rate and momentum technique to accel-
erate algorithm. Subsequently, some variants of Adam algorithm [Reddi et al., 2019, Chen et al.,
2018, Loshchilov and Hutter, 2017] have been presented to obtain a convergence guarantee under
the nonconvex setting. Due to using coordinate-wise adaptive learning rate, Adam frequently shows
a bad generalization performance in training DNNs. To improve the generalization performance
of Adam, recently some adaptive gradient methods such as AdamW [Loshchilov and Hutter, 2017]
and AdaBelief [Zhuang et al., 2020] have been proposed. More recently, some accelerated adaptive
gradient methods [Cutkosky and Orabona, 2019, Huang et al., 2021] have been proposed based on
the variance-reduced techniques. In particular, Huang et al. [2021] proposed a faster and universal
adaptive gradient framework, i.e., SUPER-ADAM algorithm, by using a universal adaptive matrix.

Notations

For two vectors x and y, (cid:104)x, y(cid:105) denotes their inner product. (cid:107) · (cid:107) denotes the (cid:96)2 norm for vectors and
spectral norm for matrices, respectively. ∇xf (x, y) and ∇yf (x, y) denote the partial derivatives
w.r.t. variables x and y respectively. Id denotes d-dimension identity matrix. a = O(b) denotes
that a ≤ Cb for some constant C > 0, and the notation ˜O(·) hides logarithmic terms. Given the
mini-batch samples B = {ξi}q

i=1, we let ∇f (x; B) = 1
q

i=1 ∇f (x; ξi).

(cid:80)q

3

Faster Adaptive Gradient Descent Ascent Methods

In the section, we propose a class of faster adaptive gradient descent ascent methods for solving the
minimax problem (1). Speciﬁcally, we propose a fast adaptive gradient descent ascent (AdaGDA)
based on the basic momentum technique of Adam [Kingma and Ba, 2014]. Meanwhile, we further

4

Algorithm 1 AdaGDA Algorithm
1: Input: T , tuning parameters {γ, λ, ηt, αt, βt}T
2: initialize: Initial input x1 ∈ X , y1 ∈ Y, and draw a mini-batch i.i.d. samples B1 = {ξ1

t=1 and mini-batch size q;

i=1,
i ) and w1 = ∇yf (x1, y1; B1) =

i }q

(cid:80)q

(cid:80)q

i=1 ∇xf (x1, y1; ξ1

and then compute v1 = ∇xf (x1, y1; B1) = 1
q
1
i );
q

i=1 ∇yf (x1, y1; ξ1
3: for t = 1, 2, . . . , T − 1 do
4: Generate the adaptive matrices At ∈ Rd1×d1 and Bt ∈ Rd2×d2 ;
(cid:8)(cid:104)vt, x(cid:105) + 1
5:
(cid:8)(cid:104)wt, y(cid:105) − 1

xt+1 = xt + ηt(˜xt+1 − xt) with ˜xt+1 = arg minx∈X
yt+1 = yt + ηt(˜yt+1 − yt) with ˜yt+1 = arg maxy∈Y
}q
i=1, and then compute
vt+1 = αt+1∇xf (xt+1, yt+1; Bt+1) + (1 − αt+1)vt;
wt+1 = βt+1∇yf (xt+1, yt+1; Bt+1) + (1 − βt+1)wt;

6:
7: Draw a mini-batch i.i.d. samples Bt+1 = {ξt+1
8:
9:
10: end for
11: Output: xζ and yζ chosen uniformly random from {xt, yt}T

i

t=1.

2γ (x − xt)T At(x − xt)(cid:9);
2λ (y − yt)T Bt(y − yt)(cid:9);

propose an accelerated version of AdaGDA (VR-AdaGDA) based on the momentum-based variance
reduced technique of STORM [Cutkosky and Orabona, 2019].

3.1 AdaGDA Algorithm

In the subsection, we propose a fast adaptive gradient descent ascent (AdaGDA) algorithm for
solving the problem (1) based on the basic momentum technique. Algorithm 1 shows the algorithmic
framework of the AdaGDA.

At the line 4 of Algorithm 1, we generate the adaptive matrices At and Bt for variables x and
y, respectively. Speciﬁcally, we use the general adaptive matrix At (cid:23) ρId1 for variable x as in the
SUPER-ADAM [Huang et al., 2021], and the global adaptive matrix Bt = btId2 (bt > 0). For
example, we can generate the matrix At as in the Adam [Kingma and Ba, 2014], deﬁned as

˜v0 = 0, ˜vt = α˜vt−1 + (1 − α)∇xf (xt, yt; ξt)2, At = diag(

(cid:112)

˜vt + ρ0), t ≥ 1,

(4)

where α ∈ (0, 1) and ρ0 > 0. At the same time, we generate the matrix Bt that can be seen as a
new global adaptive learning rate, deﬁned as

b0 > 0, bt = βbt−1 + (1 − β)(cid:107)∇yf (xt, yt; ξt)(cid:107), Bt = (bt + (cid:37)0)Id2 , t ≥ 1,

(5)

where β ∈ (0, 1) and (cid:37)0 > 0.

At the lines 5 and 6 of Algorithm 1, we apply the generalized projection gradient iteration to
update variables x and y based on the adaptive matrices At and Bt, respectively. Meanwhile, we
also use the momentum iteration to update the variables x and y. At the lines 8 and 9 of Algorithm
1, we use the basic momentum technique to estimate the stochastic gradients vt and wt.

3.2 VR-AdaGDA Algorithm

In the subsection, we propose an accelerated version of AdaGDA (VR-AdaGDA) algorithm based
on the momentum-based variance reduced technique. Algorithm 2 shows the algorithmic framework
of the VR-AdaGDA.

5

Algorithm 2 VR-AdaGDA Algorithm
1: Input: T , tuning parameters {γ, λ, ηt, αt, βt}T
2: initialize: Initial input x1 ∈ X , y1 ∈ Y, and draw a mini-batch i.i.d. samples B1 = {ξ1

t=1 and mini-batch size q;

i }q

i=1,

and then compute v1 = ∇xf (x1, y1; B1) and w1 = ∇yf (x1, y1; B1);

3: for t = 1, 2, . . . , T − 1 do
4: Generate the adaptive matrices At ∈ Rd1×d1 and Bt ∈ Rd2×d2 ;
(cid:8)(cid:104)vt, x(cid:105) + 1
5:
(cid:8)(cid:104)wt, y(cid:105) − 1

xt+1 = xt + ηt(˜xt+1 − xt) with ˜xt+1 = arg minx∈X
yt+1 = yt + ηt(˜yt+1 − yt) with ˜yt+1 = arg maxy∈Y
}q
i=1, and then compute

6:
7: Draw a mini-batch i.i.d. samples Bt+1 = {ξt+1
8:

vt+1 = ∇xf (xt+1, yt+1; Bt+1) + (1 − αt+1)(cid:0)vt − ∇xf (xt, yt; Bt+1)(cid:1);
wt+1 = ∇yf (xt+1, yt+1; Bt+1) + (1 − βt+1)(cid:0)wt − ∇yf (xt, yt; Bt+1)(cid:1);

9:
10: end for
11: Output: xζ and yζ chosen uniformly random from {xt, yt}T

i

t=1.

2γ (x − xt)T At(x − xt)(cid:9);
2λ (y − yt)T Bt(y − yt)(cid:9);

At the lines 5 and 6 of Algorithm 2, we simultaneously use the momentum iteration and the
generalized projection gradient iteration to update variables x and y. At the lines 8 and 9 of
Algorithm 2, we apply the momentum-based variance reduced technique to estimate the stochastic
gradients vt and wt. For example, the estimator of gradient ∇f (xt+1, yt+1) is deﬁned as

vt+1 = αt+1∇xf (xt+1, yt+1; Bt+1)+(1 − αt+1)(cid:2)vt + ∇xf (xt+1, yt+1; Bt+1)−∇xf (xt, yt; Bt+1)(cid:3).

Compared with the estimator vt+1 in Algorithm 1, vt+1 in Algorithm 2 adds the term (1 −
αt+1)(cid:0)∇f (xt+1, yt+1; Bt+1) − ∇f (xt, yt; Bt+1)(cid:1) to reduce variance of gradient estimator, where
αt+1 ∈ (0, 1).

4 Convergence Analysis

In this section, we study the convergence properties of our algorithms (i.e., AdaGDA and VR-
AdaGDA) under some mild assumptions. All related proofs are provided in the Appendix.

4.1 Some Mild Assumptions

In this subsection, we give some mild assumptions about the problem (1).

Assumption 1. Each component function f (x, y; ξ) has an unbiased stochastic gradient with
bounded variance σ2, i.e., for all ξ, x ∈ X , y ∈ Y, E[∇xf (x, y; ξ)] = ∇xf (x, y), E(cid:107)∇xf (x, y) −
∇xf (x, y; ξ)(cid:107)2 ≤ σ2, E[∇yf (x, y; ξ)] = ∇yf (x, y) and E(cid:107)∇yf (x, y) − ∇yf (x, y; ξ)(cid:107)2 ≤ σ2.

Assumption 2. Function f (x, y) is µ-strongly concave in y ∈ Y, i.e., for all x ∈ X and y1, y2 ∈ Y,
we have (cid:107)∇yf (x, y1) − ∇yf (x, y2)(cid:107) ≥ µ(cid:107)y1 − y2(cid:107).

The function f (x, y) is strongly concave in y ∈ Y, there exists a unique solution to the problem
maxy∈Y f (x, y) for any x. Here we let y∗(x) = arg maxy∈Y f (x, y) and F (x) = f (x, y∗(x)) =
maxy∈Y f (x, y).

Assumption 3. The function F (x) is bounded below in X , i.e., F ∗ = inf x∈X F (x) > −∞.

6

Assumption 4. In our algorithms, the adaptive matrices At for all t ≥ 1 for updating the variables
x satisﬁes AT

t = At and λmin(At) = ρ ≥ ρ0 > 0, where ρ0 is an appropriate positive number.

Assumption 4 ensures that the adaptive matrices At for all t ≥ 1 are positive deﬁnite as in
[Huang et al., 2021]. Since the function f (x, y) is µ-strongly concave in y, we can easily obtain the
global solution of the subproblem maxy∈Y f (x, y). Without loss of generalization, in the following
convergence analysis, we consider the adaptive matrices Bt = btIp for all t ≥ 1 for updating the
variables y satisﬁes ˆb ≥ bt ≥ b > 0, as the global adapitve learning rates [Li and Orabona, 2019,
Ward et al., 2019, Huang et al., 2021].

Assumption 5. The objective function f (x, y) has a Lf -Lipschitz gradient, i.e., for all x, x1, x2 ∈
X and y, y1, y2 ∈ Y, we have

(cid:107)∇xf (x1, y) − ∇xf (x2, y)(cid:107) ≤ Lf (cid:107)x1 − x2(cid:107), (cid:107)∇xf (x, y1) − ∇xf (x, y2)(cid:107) ≤ Lf (cid:107)y1 − y2(cid:107),
(cid:107)∇yf (x1, y) − ∇yf (x2, y)(cid:107) ≤ Lf (cid:107)x1 − x2(cid:107), (cid:107)∇yf (x, y1) − ∇yf (x, y2)(cid:107) ≤ Lf (cid:107)y1 − y2(cid:107).

4.2 Convergence Metrics

In this subsection, we introduce useful convergence metrics to measure convergence of our algo-
rithms. Let φt(x) = 1
2 xT Atx, according to Assumption 4, φt(x) is ρ-strongly convex. Then we
deﬁne a prox-function (i.e., Bregman distance) associated with φt(x) as in [Censor and Lent, 1981,
Censor and Zenios, 1992, Ghadimi et al., 2016], deﬁned as

Dt(x, xt) = φt(x) − (cid:2)φt(xt) + (cid:104)∇φt(xt), x − xt(cid:105)(cid:3) =

1
2

(x − xt)T At(x − xt).

The line 5 of Algorithms 1 or 2 is equivalent to the following generalized projection problem

˜xt+1 = arg min
x∈X

(cid:8)(cid:104)vt, x(cid:105) +

1
γ

Dt(x, xt)(cid:9).

(6)

(7)

As in [Ghadimi et al., 2016], we deﬁne a generalized projected gradient GX (xt, vt, γ) = 1
At the same time, we deﬁne a gradient mapping GX (xt, ∇F (xt), γ) = 1

γ (xt − x∗

t+1), where

γ (xt − ˜xt+1).

x∗
t+1 = arg min
x∈X

(cid:8)(cid:104)∇F (xt), x(cid:105) +

Dt(x, xt)(cid:9).

1
γ

(8)

For the above problem (1), when X ⊂ Rd1, we use the standard gradient mapping metric E(cid:2)GX (xt, ∇F (xt), γ)(cid:3)
to measure convergence of our algorithms, as in [Ghadimi et al., 2016]. When X = Rd1 , we use the
standard gradient metric E(cid:107)∇F (xt)(cid:107) to measure convergence of our algorithms, as in [Lin et al.,
2020a].

4.3 Convergence Analysis of the AdaGDA Algorithm

In the subsection, we study the convergence properties of our AdaGDA algorithm under Assump-
tions 1, 2, 3, 4 and 5. The detail proofs are provided in the Appendix A.1. For notational simplicity,
let L = Lf (1 + κ) and κ = Lf
µ .

7

Theorem 1. Suppose the sequence {xt, yt}T
and given Bt = btId2 (ˆb ≤ bt ≤ b > 0) for all t ≥ 1, ηt =
βt+1 = c2ηt, m ≥ max (cid:0)k2, (c1k)2, (c2k)2(cid:1), k > 0, 9µ2
min (cid:0)

t=1 be generated from Algorithm 1. When X ⊂ Rd1,
(m+t)1/2 for all t ≥ 0, αt+1 = c1ηt,
75L2
2 ≤ c2 ≤ m1/2
f
k , 0 < γ ≤
(cid:1), we have

4 ≤ c1 ≤ m1/2
k ,
(cid:1) and 0 < λ ≤ min (cid:0) 405bL2
50L2

, m1/2ρ
4Lk

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2

b
6Lf

√
8

400L2

f µ2

15

(cid:113)

√

k

2

1
T

T
(cid:88)

t=1

E(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤

√
2

3Gm1/4
T 1/2

+

(9)

f µ3/2
f +9µ2 ,
√
3G
2
T 1/4

,

where G = F (x1)−F ∗

kγρ +

f ∆2

9b1L2
kλµρ2 + 2σ2

qkµ2ρ2 + 2mσ2

1

qkµ2ρ2 ln(m + T ) and ∆2

1 = (cid:107)y1 − y∗(x1)(cid:107)2.

Theorem 2. Assume that the sequence {xt, yt}T
X = Rd1, and given Bt = btId2 (ˆb ≤ bt ≤ b > 0) for all t ≥ 1, ηt =
αt+1 = c1ηt, βt+1 = c2ηt, m ≥ max (cid:0)k2, (c1k)2, (c2k)2(cid:1), k > 0, 9µ2
0 < γ ≤ min (cid:0)

t=1 be generated from the Algorithm 1. When
(m+t)1/2 for all t ≥ 0,
75L2
2 ≤ c2 ≤ m1/2
4 ≤ c1 ≤ m1/2
f
k ,
k ,
f µ3/2
(cid:1) and 0 < λ ≤ min (cid:0) 405bL2
(cid:1), we have
f +9µ2 ,
50L2

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2

, m1/2ρ
4Lk

b
6Lf

√
8

400L2

f µ2

15

(cid:113)

√

k

2

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

(cid:113)

1
T

(cid:80)T

t=1
ρ

E(cid:107)At(cid:107)2

√

(cid:18) 2

3G(cid:48)m1/4
T 1/2

+

√

3G(cid:48)
2
T 1/4

(cid:19)

,

(10)

where G(cid:48) = ρ(F (x1)−F ∗)

kγ

+

9b1L2

f ∆2

kλµ + 2σ2

qkµ2 + 2mσ2

qkµ2 ln(m + T ).

1

Remark 1. Without loss of generality, let k = O(1), b = O(1), ˆb = O(1) and

(cid:113)

2

m1/2ρ

4Lk , we have m ≥ (cid:0)k2, (c1k)2, (c2k)2,
405bL2
f µ3/2
f +9µ2 , we have 0 < λ ≤ b
√
50L2
8

6Lf

. Let γ =

225L2k2λ2µ4
f λ2+48µ2λ2+18750ˆb2κ2L2

f µ2

800L2

√

(cid:113)

2

400L2

15

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2

f µ2

400L2

√

15

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2
b
6Lf

≤

f µ2

≤

(cid:1). At the same time, let

, λ = b
6Lf

, c1 = 9µ2

4 and

75L2
f
2

κ2 ), λ = O( 1
Lf

, it is easily veriﬁed that γ = O( 1

f ). Then we have m = O(L4

. Without loss of generality, let µ ≤ 1
Lf

),
c2 =
c1 = O(µ2), c2 = O(L2
f ). When mini-batch size q = O(1), we have
G = O(κ2 + κ2 ln(m + T )) = ˜O(κ2). So our AdaGDA algorithm has a convergence rate of ˜O( κ
T 1/4 ).
Let ˜O( κ
T 1/4 ) ≤ (cid:15), i.e., E(cid:107)GX (xζ, ∇F (xζ), γ)(cid:107) ≤ (cid:15) or E(cid:107)∇F (xζ)(cid:107) ≤ (cid:15), we have T ≤ κ4(cid:15)−4. In
Algorithm 1, we need to compute 2q stochastic gradients to estimate partial derivative estimators vt
and wt at each iteration, and need T iterations. Thus, our AdaGDA algorithm has a gradient (i.e.,
stochastic ﬁrst-order oracle) complexity of 2q · T = ˜O(κ4(cid:15)−4) for ﬁnding an (cid:15)-stationary point. Note
E(cid:107)At(cid:107)2 is bounded to the existing adaptive learning rates in Adam algorithm
that the term
[Kingma and Ba, 2014] and so on. For example, given the above adaptive learning rate (4) and the
E(cid:107)At(cid:107)2 ≤ δ + σ + ρ0.

standard bounded gradient (cid:107)∇xf (x, y)(cid:107) ≤ δ as in Adam, we have

(cid:80)T

(cid:80)T

(cid:113)

(cid:113)

t=1

1
T

1
T

t=1

4.4 Convergence Analysis of the VR-AdaGDA Algorithm

In the subsection, we study the convergence properties of our VR-AdaGDA algorithm under As-
sumptions 1, 2, 3, 4 and 6. The detail proofs are provided in the Appendix A.2. Here we ﬁrst use
the following assumption instead of the above Assumption 5.

8

Assumption 6. Each component function f (x, y; ξ) has a Lf -Lipschitz gradient, i.e., for all
x, x1, x2 ∈ X and y, y1, y2 ∈ Y, we have

(cid:107)∇xf (x1, y; ξ)−∇xf (x2, y; ξ)(cid:107) ≤ Lf (cid:107)x1 − x2(cid:107), (cid:107)∇xf (x, y1; ξ)−∇xf (x, y2; ξ)(cid:107) ≤ Lf (cid:107)y1 − y2(cid:107),
(cid:107)∇yf (x1, y; ξ)−∇yf (x2, y; ξ)(cid:107) ≤ Lf (cid:107)x1 − x2(cid:107), (cid:107)∇yf (x, y1; ξ)−∇yf (x, y2; ξ)(cid:107) ≤ Lf (cid:107)y1 − y2(cid:107).
By using convexity of (cid:107)·(cid:107) and Assumption 6, we have (cid:107)∇xf (x1, y)−∇xf (x2, y)(cid:107) = (cid:107)E(cid:2)∇xf (x1, y; ξ)−
∇xf (x2, y; ξ)(cid:3)(cid:107) ≤ E(cid:107)∇xf (x1, y; ξ)−∇xf (x2, y; ξ)(cid:107) ≤ Lf (cid:107)x1−x2(cid:107). Similarly, we also have (cid:107)∇xf (x, y1)−
∇yf (x, y1)(cid:107) ≤ Lf (cid:107)y1−y2(cid:107), (cid:107)∇yf (x, y1)−∇yf (x, y1)(cid:107) ≤ Lf (cid:107)y1−y2(cid:107) and (cid:107)∇yf (x1, y)−∇yf (x2, y)(cid:107) ≤
Lf (cid:107)x1 −x2(cid:107). In the other words, Assumption 6 includes Assumption 5, i.e., Assumption 6 is stricter
than Assumption 5.

Theorem 3. Suppose the sequence {xt, yt}T
given Bt = btId2 (0 < b ≤ bt ≤ ˆb) for all t ≥ 1, ηt =
3k3 + 9µ2
c1 ≥ 2
0 < γ ≤ min (cid:0)

t=1 be generated from Algorithm 2. When X ⊂ Rd1, and
t , βt+1 = c2η2
t ,
(cid:1) and
b
6Lf

, m ≥ max (cid:0)k3, (c1k)3, (c2k)3(cid:1), 0 < λ ≤ min (cid:0) 27µbq
32 ,
(cid:1), we have

(m+t)1/3 for all t ≥ 0, αt+1 = c1η2

4 and c2 ≥ 2

3k3 +

√

√

k

75L2
f
2
, m1/3ρ
2Lk

ρλµ

q
32λ2+150qκ2ˆb2

Lf

1
T

T
(cid:88)

t=1

E(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤

√
2

3M m1/6
T 1/2

+

√
2
3M
T 1/3

,

(11)

where M = F (x1)−F ∗

T γkρ +

9L2
f b1
kλµρ2 ∆2

1 + 2σ2m1/3

k2qµ2ρ2 + 2k2(c2

1+c2
qµ2ρ2

2)σ2

ln(m + T ).

Theorem 4. Suppose the sequence {xt, yt}T
and given Bt = btId2 (0 < b ≤ bt ≤ ˆb) ηt =
and c2 ≥ 2
3k3 +
√
min (cid:0)
q
ρλµ
32λ2+150qκ2ˆb2

(cid:1), we have

75L2
f
2

√

Lf

, m ≥ max (cid:0)k3, (c1k)3, (c2k)3(cid:1), 0 < λ ≤ min (cid:0) 27µbq
32 ,
, m1/3ρ
2Lk

k

t=1 be generated from Algorithm 2. When X = Rd1,
3k3 + 9µ2
t , c1 ≥ 2
(m+t)1/3 , αt+1 = c1η2
(cid:1) and 0 < γ ≤

t , βt+1 = c2η2
b
6Lf

4

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

(cid:113)

1
T

(cid:80)T

t=1
ρ

E(cid:107)At(cid:107)2

√

(cid:18) 2

3M (cid:48)m1/6
T 1/2

+

√

2

3M (cid:48)

(cid:19)

T 1/3

,

(12)

+

T γk

2)σ2

m1/3ρ

9L2
f b1
kλµ ∆2

1+c2
qµ2

ln(m + T ).

k2qµ2 + 2k2(c2

where M (cid:48) = ρ(F (x1)−F ∗)

8(Lkλµ)3q3/2
Lf (32λ2+150qκ2ˆb2)3/2

1 + 2σ2m1/3
Remark 2. Without loss of generality, let k = O(1), b = O(1), ˆb = O(1) and
2Lk , we have m ≥ (cid:0)k3, (c1k)3, (c2k)3,
and λ = min (cid:0) 27µbq
, we have λ = O(bµ). When mini-
32 ,
batch size q = O(1), it is easily veriﬁed that γ = O(κ−3), λ = O(µ), c1 = O(µ2), c2 = O(L2
f ) and
f ). Then we have M = O(cid:0)κ3 + κ + κ2 + κ2 ln(m + T )(cid:1) = O(κ3). Thus, our VR-AdaGDA
m = O(L6
algorithm has a convergence rate of O( κ3/2
T 1/3 ). Let O( κ3/2
T 1/3 ) ≤ (cid:15), i.e., E(cid:107)GX (xζ, ∇F (xζ), γ)(cid:107) ≤ (cid:15) or
E(cid:107)∇F (xζ)(cid:107) ≤ (cid:15), we have T ≤ κ4.5(cid:15)−3. In Algorithm 2, we need to compute 4q stochastic gradients
to estimate the partial derivative estimators vt and wt at each iteration, and need T iterations.
Thus, our VR-AdaGDA algorithm has a gradient complexity of 4q · T = O(κ4.5(cid:15)−3) for ﬁnding an
(cid:15)-stationary point.

(cid:1). Without loss of generality, let µ ≤ 1
Lf

Lf
q
32λ2+150qκ2ˆb2

q
32λ2+150qκ2ˆb2

(cid:1). Let γ =

√
κ

b
6Lf

≤
√

ρλµ

ρλµ

√

√

=

Lf

√

√

ρλ

q
32λ2+150qκ2ˆb2

9

Corollary 1. Under the same conditions of Theorem 2, given mini-batch size q = O(κν) for ν > 0
and 27µbq
81Lf µ , our VR-AdaGDA algorithm has a lower gradient complexity
of ˜O(cid:0)κ(4.5− ν

32 ≤ b
6Lf
2 )(cid:15)−3(cid:1) for ﬁnding an (cid:15)-stationary point.

, i.e., q = κν ≤ 16

Remark 3. Without loss of generality, let ν = 1, we have q = κ = Lf
81Lf µ . Thus, we have
Lf ≤ 4
9 . Although the objective function f (x, y) in the minimax problem (1) maybe not satisfy this
condition Lf ≤ 4
9 , we can easily change the original objective function f (x, y) to a new function
˜f (x, y) = βf (x, y), β > 0. Since ∇ ˜f (x, y) = β∇f (x, y), the gradient of function ˜f (x, y) is ˆL-
Lipschitz continuous ( ˆL = βLf ). Thus, we can choose a suitable parameter β to ensure this new
objective function ˜f (x, y) satisﬁes the condition ˆL = βLf ≤ 4
9 .

µ ≤ 16

5 Numerical Experiments

In this section, we apply some numerical experiments to validate the eﬃciency of our algorithms
on two tasks: 1) Policy Evaluation, and 2) Fair Classiﬁer. We compare our algorithms (AdaGDA
and VR-AdaGDA) with the existing state-of-the-art algorithms in Table 1 for solving nonconvex-
strongly-concave minimax problems. The experiments are run on CPU machines with 2.3 GHz
Intel Core i9 as well as NVIDIA Tesla P40 GPU.

(a) CartPole-v1

(b) Acrobat-v1

(c) MountainCarContinuous-v0

Figure 1: Results of diﬀerent methods on the policy evaluation task.

(a) Fashion-MNIST

(b) MNIST

(c) CIFAR-10

Figure 2: Results of diﬀerent methods on the fair classiﬁer task.

10

5.1 Policy Evaluation

The ﬁrst task is to apply a neural network to estimate the value function in Markov Decision Process
(MDP). The value function Vθ(·) is parameterized as a 2-layer neural network, whose minimax
loss function is deﬁned in (2) given in the Introduction. In the experiment, we generate 10,000
state-reward pairs for three classic environments from GYM [Brockman et al., 2016]: CartPole-v1,
Acrobat-v1, and MountainCarContinuous-v0. Speciﬁcally, in CartPole-v1, a pole is connected with
a cart by a joint. The goal of CartPole-v1 is to keep the pole upright by adding force to the cart.
The system in Acrobot-v1 has two joints and two links. To get the reward, we need to swing the
end of the lower link and make it reach a given height. In MountainCarContinuous-v0, the car is
on a one-dimensional track between two ”mountains”. The car needs to drive up to the mountain
on the right but the car’s engine is not strong enough to complete this task without momentum.

In the MDP, we give the discount factor τ = 0.95. In our algorithms, we set γ = λ = 0.005, and
the adaptive matrices At and Bt are generated from (4) and (5) respectively, where α = β = 0.1
and ρ0 = (cid:37)0 = 0.001. In the other algorithms, we set the line-size for updating parameter θ be 0.005
and the line-size for w be 0.005. At the same time, in the SREDA algorithm, we set S1 = 10, 000
and S2 = q = 500. The batch-sizes for all other methods are 500. In AccMDA and VR-AdaGDA,
αt+1 = η2
t . In AdaGDA, αt+1 = ηt, βt+1 = ηt. In PDAda, βx = βt = ηx = ηy = 0.9.
The architecture of neural network for policy evaluation is given in the Appendix.

t , βt+1 = η2

Figure 1 shows the loss vs epoch of diﬀerent stochastic methods. From these results, we can
ﬁnd that our algorithms outperform the other algorithms, and the VR-AdaGDA consistently out-
performs the AdaGDA.

5.2

Fair Classiﬁer

In the second task, we train a fair classiﬁer by minimizing the maximum loss over diﬀerent categories,
where we use a Convolutional Neural Network (CNN) model as classiﬁer. In the experiment, we
use the MNIST, Fashion-MNIST and CIFAR-10 datasets as in [Nouiehed et al., 2019]. Following
[Nouiehed et al., 2019], we mainly focus on three categories in each dataset: digital numbers {0, 2, 3}
in the MNIST dataset, and T-shirt/top, Coat and Shirt categories in the Fashion-MNIST dataset,
and airplane, automobile and bird in the CIFAR10 dataset. Then we train this fair classiﬁer by
solving the following minimax problem:

min
w

max
u∈U

3
(cid:88)

(cid:8)

i=1

uiLi(w) − (cid:37)(cid:107)u −

(cid:107)2(cid:9),

1
3

(13)

where U = (cid:8)u | ui ≥ 0, (cid:80)3
i=1 ui = 1(cid:9), L1, L2 and L3 are the cross-entropy loss functions
corresponding to the samples in three diﬀerent categories. Here (cid:37) ≥ 0 is tuning parameter, and u
is a weight vector for diﬀerent loss functions, and w denotes the parameters of CNN.

In the experiment, we use xavier normal initialization to CNN layer.

In our algorithms, we
set γ = 0.001 and λ = 0.0001, and the adaptive matrices At and Bt are generated from (4) and
(5) respectively, where α = β = 0.1 and ρ0 = (cid:37)0 = 0.001. In the other algorithms, we set the
line-size for updating parameter w be 0.001 and step-size for u be 0.0001. At the same time, we set
ηt = 0.9 in our algorithms. We run all algorithms for 100 epochs, and then record the loss value.
For SREDA, we set S1 = 18, 000 and S2 = q = 900. The batch-sizes for all other methods are 900.
t , βt+1 = η2
For AccMDA and VR-AdaGDA, αt+1 = η2
t . For AdaGDA, αt+1 = ηt, βt+1 = ηt. For
PDAda, βx = βt = ηx = ηy = 0.9. Note that for fair comparison, we do not use the small stepsizes

11

relying on small (cid:15) following the original SREDA algorithm, but use the relatively large stepsizes in
the experiments. The architecture of CNN for policy evaluation is given in the Appendix.

Figure 2 plots the loss vs epoch of diﬀerent stochastic methods. From these results, we can ﬁnd

that our algorithms consistently outperform the other algorithms.

6 Conclusion

In the paper, we proposed a class of faster adaptive gradient descent ascent methods for solving the
above minimax problem (1) by using uniﬁed adaptive matrices for both variables x and y. In par-
ticular, our methods can easily incorporate both the momentum and variance-reduced techniques.
Moreover, we provided an eﬀective convergence analysis framework for our methods.

References

G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba. Openai

gym. arXiv preprint arXiv:1606.01540, 2016.

Y. Censor and A. Lent. An iterative row-action method for interval convex programming. Journal of

Optimization theory and Applications, 34(3):321–353, 1981.

Y. Censor and S. A. Zenios. Proximal minimization algorithm withd-functions. Journal of Optimization

Theory and Applications, 73(3):451–464, 1992.

X. Chen, S. Liu, R. Sun, and M. Hong. On the convergence of a class of adam-type algorithms for non-convex

optimization. arXiv preprint arXiv:1808.02941, 2018.

A. Cutkosky and F. Orabona. Momentum-based variance reduction in non-convex sgd. Advances in neural

information processing systems, 32, 2019.

Y. Deng, M. M. Kamani, and M. Mahdavi. Distributionally robust federated averaging. arXiv preprint

arXiv:2102.12660, 2021.

C. Fang, C. J. Li, Z. Lin, and T. Zhang. Spider: Near-optimal non-convex optimization via stochastic path-
integrated diﬀerential estimator. In Advances in Neural Information Processing Systems, pages 689–699,
2018.

S. Ghadimi, G. Lan, and H. Zhang. Mini-batch stochastic approximation methods for nonconvex stochastic

composite optimization. Mathematical Programming, 155(1-2):267–305, 2016.

I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.
In Advances in neural information processing systems, pages 2672–2680,

Generative adversarial nets.
2014.

Z. Guo, Y. Xu, W. Yin, R. Jin, and T. Yang. On stochastic moving-average estimators for non-convex

optimization. arXiv preprint arXiv:2104.14840, 2021.

F. Huang, J. Li, and H. Huang. Super-adam: Faster and universal framework of adaptive gradients.

Advances in Neural Information Processing Systems, 34, 2021.

F. Huang, S. Gao, J. Pei, and H. Huang. Accelerated zeroth-order and ﬁrst-order momentum methods from

mini to minimax optimization. Journal of Machine Learning Research, 23(36):1–70, 2022.

12

D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,

2014.

V. R. Konda and J. N. Tsitsiklis. Actor-critic algorithms. In Advances in neural information processing

systems, pages 1008–1014. Citeseer, 2000.

H. Li, Y. Tian, J. Zhang, and A. Jadbabaie. Complexity lower bounds for nonconvex-strongly-concave

min-max optimization. arXiv preprint arXiv:2104.08708, 2021.

X. Li and F. Orabona. On the convergence of stochastic gradient descent with adaptive stepsizes. In The
22nd International Conference on Artiﬁcial Intelligence and Statistics, pages 983–992. PMLR, 2019.

T. Lin, C. Jin, and M. Jordan. On gradient descent ascent for nonconvex-concave minimax problems. In

International Conference on Machine Learning, pages 6083–6093. PMLR, 2020a.

T. Lin, C. Jin, and M. I. Jordan. Near-optimal algorithms for minimax optimization. In Conference on

Learning Theory, pages 2738–2779. PMLR, 2020b.

M. Liu, H. Raﬁque, Q. Lin, and T. Yang. First-order convergence theory for weakly-convex-weakly-concave

min-max problems. Journal of Machine Learning Research, 22(169):1–34, 2021.

I. Loshchilov and F. Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101,

2017.

S. Lu, I. Tsaknakis, M. Hong, and Y. Chen. Hybrid block successive approximation for one-sided non-
convex min-max problems: algorithms and applications. IEEE Transactions on Signal Processing, 68:
3676–3691, 2020.

L. Luo, H. Ye, Z. Huang, and T. Zhang. Stochastic recursive gradient descent ascent for stochastic
nonconvex-strongly-concave minimax problems. Advances in Neural Information Processing Systems,
33, 2020.

B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-eﬃcient learning of
deep networks from decentralized data. In Artiﬁcial Intelligence and Statistics, pages 1273–1282. PMLR,
2017.

Y. Nesterov. Lectures on convex optimization, volume 137. Springer, 2018.

M. Nouiehed, M. Sanjabi, T. Huang, J. D. Lee, and M. Razaviyayn. Solving a class of non-convex min-max
games using iterative ﬁrst order methods. Advances in Neural Information Processing Systems, 32, 2019.

H. Raﬁque, M. Liu, Q. Lin, and T. Yang. Weakly-convex–concave min–max optimization: provable algo-
rithms and applications in machine learning. Optimization Methods and Software, pages 1–35, 2021.

S. J. Reddi, S. Kale, and S. Kumar. On the convergence of adam and beyond.

arXiv preprint

arXiv:1904.09237, 2019.

A. Reisizadeh, F. Farnia, R. Pedarsani, and A. Jadbabaie. Robust federated learning: The case of aﬃne

distribution shifts. arXiv preprint arXiv:2006.08907, 2020.

F. Tram`er, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel. Ensemble adversarial

training: Attacks and defenses. In International Conference on Learning Representations, 2018.

H.-T. Wai, M. Hong, Z. Yang, Z. Wang, and K. Tang. Variance reduced policy evaluation with smooth

function approximation. Advances in Neural Information Processing Systems, 32:5784–5795, 2019.

13

Z. Wang, K. Ji, Y. Zhou, Y. Liang, and V. Tarokh. Spiderboost and momentum: Faster variance reduction

algorithms. In Advances in Neural Information Processing Systems, pages 2403–2413, 2019.

R. Ward, X. Wu, and L. Bottou. Adagrad stepsizes: Sharp convergence over nonconvex landscapes. In

International Conference on Machine Learning, pages 6677–6686. PMLR, 2019.

Y. Yan, Y. Xu, Q. Lin, W. Liu, and T. Yang. Optimal epoch stochastic gradient descent ascent methods

for min-max optimization. Advances in Neural Information Processing Systems, 33, 2020.

J. Yang, N. Kiyavash, and N. He. Global convergence and variance reduction for a class of nonconvex-

nonconcave minimax problems. Advances in Neural Information Processing Systems, 33, 2020a.

J. Yang, S. Zhang, N. Kiyavash, and N. He. A catalyst framework for minimax optimization. Advances in

Neural Information Processing Systems, 2020b.

S. Zhang, J. Yang, C. Guzm´an, N. Kiyavash, and N. He. The complexity of nonconvex-strongly-concave

minimax optimization. arXiv preprint arXiv:2103.15888, 2021.

J. Zhuang, T. Tang, Y. Ding, S. Tatikonda, N. Dvornek, X. Papademetris, and J. S. Duncan. Adabelief
optimizer: Adapting stepsizes by the belief in observed gradients. arXiv preprint arXiv:2010.07468, 2020.

14

Table 2: Model Architecture for the Policy Evaluation

Layer Type
Fully Connected + tanh
Fully Connected

Shape
16
1

Table 3: Model Architecture for the Fair Classiﬁer

Layer Type
Convolution + ReLU
Max Pooling
Convolution + ReLU
Max Pooling
Fully Connected + ReLU 100
Fully Connected + ReLU 3

Shape
3 × 3 × 5
2 × 2
3 × 3 × 10
2 × 2

A Appendix

In this section, we provide the detailed convergence analysis of our algorithms. We ﬁrst gives some useful
lemmas.

Given a ρ-strongly convex function ψ(x) : X → R, we deﬁne a Bregman distance [Censor and Lent,

1981, Censor and Zenios, 1992, Ghadimi et al., 2016] associated with ψ(x) as follows:

D(z, x) = ψ(z) − (cid:2)ψ(x) + (cid:104)∇ψ(x), z − x(cid:105)(cid:3),

∀x, z ∈ X ,

(14)

where X ⊆ Rd is a closed convex set. Assume h(x) : X → R is a convex and possibly nonsmooth function,
we deﬁne a generalized projection problem:

x+ = arg min
z∈X

(cid:8)(cid:104)z, v(cid:105) + h(z) +

1
γ

D(z, x)(cid:9),

x ∈ X ,

where v ∈ Rd and γ > 0. Following Ghadimi et al. [2016], we deﬁne a generalized gradient as follows:

GX (x, v, γ) =

(x − x+).

1
γ

(15)

(16)

Lemma 1. (Lemma 1 in Ghadimi et al. [2016]) Let x+ be given in (15). Then we have, for any x ∈ X ,
v ∈ Rd and γ > 0,

(cid:104)v, GX (x, v, γ)(cid:105) ≥ ρ(cid:107)GX (x, v, γ)(cid:107)2 +

(cid:2)h(x+) − h(x)(cid:3),

1
γ

where ρ > 0 depends on ρ-strongly convex function ψ(x).

Based on Lemma 1, let h(x) = 0, we have

(cid:104)v, GX (x, v, γ)(cid:105) ≥ ρ(cid:107)GX (x, v, γ)(cid:107)2.

(17)

(18)

Lemma 2. [Nesterov, 2018] Assume function f (x) is convex and X is a convex set. x∗ ∈ X is the solution
of the constrained problem minx∈X f (x), if

(cid:104)∇f (x∗), x − x∗(cid:105) > 0, ∀x ∈ X .

(19)

where ∇f (x∗) denote the (sub-)gradient of function f (x) at x∗.

15

Lemma 3. [Lin et al., 2020a] Under the above Assumptions 2 and 5, the function F (x) = miny∈Y f (x, y) =
f (x, y∗(x)) and the mapping y∗(x) = arg maxy∈Y f (x, y) have L-Lipschitz continuous gradient and κ-
Lipschitz continuous respectively, such as for all x1, x2 ∈ X

(cid:107)∇F (x1) − ∇F (x2)(cid:107) ≤ L(cid:107)x1 − x2(cid:107),

(cid:107)y∗(x1) − y∗(x2)(cid:107) ≤ κ(cid:107)x1 − x2(cid:107),

(20)

where L = Lf (1 + κ) and κ = Lf /µ.
Lemma 4. For independent random variables {ξi}n
for any i ∈ [n].

i=1 with zero mean, we have E(cid:107) 1
n

(cid:80)n

i=1 ξi(cid:107)2 = 1

n

E(cid:107)ξi(cid:107)2

Lemma 5. Suppose the sequence {xt, yt}T
0 < γ ≤ ρ

, we have

2Lηt

t=1 be generated from Algorithms 1 or 2. Let 0 < ηt ≤ 1 and

F (xt+1) − F (xt) ≤

2γL2
f ηt
ρ

(cid:107)y∗(xt) − yt(cid:107)2 +

2γηt
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

ρηt
2γ

(cid:107)˜xt+1 − xt(cid:107)2,

(21)

where L = Lf (1 + κ).

Proof. According to the above Lemma 3, the function F (x) has L-Lipschitz continuous gradient. Then we
have

F (xt+1) ≤ F (xt) + (cid:104)∇F (xt), xt+1 − xt(cid:105) +

L
2

(cid:107)xt+1 − xt(cid:107)2

= F (xt) + ηt(cid:104)∇F (xt), ˜xt+1 − xt(cid:105) +

Lη2
t
2

(cid:107)˜xt+1 − xt(cid:107)2

= F (xt) + ηt (cid:104)vt, ˜xt+1 − xt(cid:105)
(cid:124)
(cid:125)

(cid:123)(cid:122)
=T1

+ηt (cid:104)∇F (xt) − vt, ˜xt+1 − xt(cid:105)
(cid:125)

(cid:124)

(cid:123)(cid:122)
=T2

+

Lη2
t
2

(cid:107)˜xt+1 − xt(cid:107)2,

(22)

where the ﬁrst equality holds by xt+1 = xt + ηt(˜xt+1 − xt).

According to Assumption 4, i.e., At (cid:31) ρId1 for any t ≥ 1, the function φt(x) = xT Atx is ρ-strongly

convex. By using the above Lemma 1 to the line 5 of Algorithm 1 or 2 , we have

Then we obtain

(cid:104)vt,

1
γ

(xt − ˜xt+1)(cid:105) ≥ ρ(cid:107)

1
γ

(xt − ˜xt+1)(cid:107)2.

T1 = (cid:104)vt, ˜xt+1 − xt(cid:105) ≤ −

ρ
γ

(cid:107)˜xt+1 − xt(cid:107)2.

Next, we decompose the term T2 = (cid:104)∇F (xt) − vt, ˜xt+1 − xt(cid:105) as follows:

T2 = (cid:104)∇F (xt) − vt, ˜xt+1 − xt(cid:105)

= (cid:104)∇F (xt) − ∇xf (xt, yt), ˜xt+1 − xt(cid:105)
(cid:125)

(cid:124)

(cid:123)(cid:122)
=T3

+ (cid:104)∇xf (xt, yt) − vt, ˜xt+1 − xt(cid:105)
(cid:123)(cid:122)
(cid:125)
=T4

(cid:124)

.

For the term T3, by the Cauchy-Schwarz inequality and Young’s inequality, we have

T3 = (cid:104)∇F (xt) − ∇xf (xt, yt), ˜xt+1 − xt(cid:105)

≤ (cid:107)∇F (xt) − ∇xf (xt, yt)(cid:107) · (cid:107)˜xt+1 − xt(cid:107)

(23)

(24)

(25)

(cid:107)∇F (xt) − ∇xf (xt, yt)(cid:107)2 +

ρ
8γ

(cid:107)˜xt+1 − xt(cid:107)2

(cid:107)∇xf (xt, y∗(xt)) − ∇xf (xt, yt)(cid:107)2 +

ρ
8γ

(cid:107)˜xt+1 − xt(cid:107)2

≤

=

≤

2γ
ρ
2γ
ρ
2γL2
f
ρ

(cid:107)˜xt+1 − xt(cid:107)2,

(26)

(cid:107)y∗(xt) − yt(cid:107)2 +

ρ
8γ

16

where the second inequality is due to the last inequality holds by (cid:104)a, b(cid:105) ≤ ν
the last inequality holds by Assumption 5. For the term T2, similarly, we have

2 (cid:107)a(cid:107)2 + 1

2ν (cid:107)b(cid:107)2 with ν = 4γ

ρ , and

T4 = (cid:104)∇xf (xt, yt) − vt, ˜xt+1 − xt(cid:105)

≤ (cid:107)∇xf (xt, yt) − vt(cid:107) · (cid:107)˜xt+1 − xt(cid:107)

≤

2γ
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ
8γ

(cid:107)˜xt+1 − xt(cid:107)2.

Thus, we have

T2 =

2γL2
f
ρ

(cid:107)y∗(xt) − yt(cid:107)2 +

2γ
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ
4γ

(cid:107)˜xt+1 − xt(cid:107)2.

Finally, combining the inequalities (22), (24) with (28), we have

F (xt+1) ≤ F (xt) −

ρηt
γ

(cid:107)˜xt+1 − xt(cid:107)2 +

2γL2
f ηt
ρ

(cid:107)y∗(xt) − yt(cid:107)2 +

2γηt
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2

(27)

(28)

+

ρηt
4γ

(cid:107)˜xt+1 − xt(cid:107)2 +

Lη2
t
2

(cid:107)˜xt+1 − xt(cid:107)2

≤ F (xt) +

2γL2
f ηt
ρ

(cid:107)y∗(xt) − yt(cid:107)2 +

2γηt
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

ρηt
2γ

(cid:107)˜xt+1 − xt(cid:107)2,

(29)

where the last inequality is due to 0 < γ ≤ ρ

2Lηt

.

Lemma 6. Suppose the sequence {xt, yt}T
sumptions, given Bt = btId2 (bt ≥ b > 0) for all t ≥ 1, 0 < ηt ≤ 1 and 0 < λ ≤ b
6Lf
have

t=1 be generated from Algorithm 1 or 2 . Under the above As-
, we

≤ bt
6Lf

(cid:107)yt+1 − y∗(xt+1)(cid:107)2 ≤ (1 −

)(cid:107)yt − y∗(xt)(cid:107)2 −

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2

ηtµλ
4bt
25ηtλ
6µbt

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

25κ2ηtbt
6µλ

(cid:107)˜xt+1 − xt(cid:107)2,

(30)

where κ = Lf /µ.

+

Proof. This proof is similar to the proof of Lemma 28 in [Huang et al., 2022]. According to Assumption 2,
i.e., the function f (x, y) is µ-strongly concave w.r.t y, we have

f (xt, y) ≤ f (xt, yt) + (cid:104)∇yf (xt, yt), y − yt(cid:105) −

µ
2

(cid:107)y − yt(cid:107)2

= f (xt, yt) + (cid:104)wt, y − ˜yt+1(cid:105) + (cid:104)∇yf (xt, yt) − wt, y − ˜yt+1(cid:105)

+ (cid:104)∇yf (xt, yt), ˜yt+1 − yt(cid:105) −

µ
2

(cid:107)y − yt(cid:107)2.

According to Assumption 5, i.e., the function f (x, y) is Lf -smooth, we have

−

Lf
2

(cid:107)˜yt+1 − yt(cid:107)2 ≤ f (xt, ˜yt+1) − f (xt, yt) − (cid:104)∇yf (xt, yt), ˜yt+1 − yt(cid:105).

Summing up the about inequalities (31) with (32), we have

f (xt, y) ≤ f (xt, ˜yt+1) + (cid:104)wt, y − ˜yt+1(cid:105) + (cid:104)∇yf (xt, yt) − wt, y − ˜yt+1(cid:105)

−

µ
2

(cid:107)y − yt(cid:107)2 +

Lf
2

(cid:107)˜yt+1 − yt(cid:107)2.

17

(31)

(32)

(33)

By the optimality of the line 6 of Algorithm 1 or 2 and Bt = btId2 , we have

(cid:104)−wt +

bt
λ

(˜yt+1 − yt), y − ˜yt+1(cid:105) ≥ 0,

∀y ∈ Y

(34)

where the above inequality holds by Lemma 2. Then we obtain

(cid:104)wt, y − ˜yt+1(cid:105) ≤

1
λ

(cid:104)bt(˜yt+1 − yt), y − ˜yt+1(cid:105)

= −

= −

1
λ
bt
λ

(cid:104)bt(˜yt+1 − yt), yt − ˜yt+1(cid:105) +

1
λ

(cid:104)bt(˜yt+1 − yt), y − yt(cid:105)

(cid:107)˜yt+1 − yt(cid:107)2 +

bt
λ

(cid:104)˜yt+1 − yt, y − yt(cid:105).

By plugging the inequalities (35) into (33), we have

f (xt, y) ≤ f (xt, ˜yt+1) +

bt
λ

(cid:104)˜yt+1 − yt, y − yt(cid:105) + (cid:104)∇yf (xt, yt) − wt, y − ˜yt+1(cid:105)

−

bt
λ

(cid:107)˜yt+1 − yt(cid:107)2 −

µ
2

(cid:107)y − yt(cid:107)2 +

Lf
2

(cid:107)˜yt+1 − yt(cid:107)2.

Let y = y∗(xt) and we obtain

f (xt, y∗(xt)) ≤ f (xt, ˜yt+1) +

bt
λ

(cid:104)˜yt+1 − yt, y∗(xt) − yt(cid:105) + (cid:104)∇yf (xt, yt) − wt, y∗(xt) − ˜yt+1(cid:105)

−

bt
λ

(cid:107)˜yt+1 − yt(cid:107)2 −

µ
2

(cid:107)y∗(xt) − yt(cid:107)2 +

Lf
2

(cid:107)˜yt+1 − yt(cid:107)2.

(35)

(36)

(37)

Due to the concavity of f (·, y) and y∗(xt) = arg maxy∈Y f (xt, y), we have f (xt, y∗(xt)) ≥ f (xt, ˜yt+1). Thus,
we obtain

0 ≤

bt
λ

−

(cid:104)˜yt+1 − yt, y∗(xt) − yt(cid:105) + (cid:104)∇yf (xt, yt) − wt, y∗(xt) − ˜yt+1(cid:105)

bt
λ

(cid:107)˜yt+1 − yt(cid:107)2 −

µ
2

(cid:107)y∗(xt) − yt(cid:107)2 +

Lf
2

(cid:107)˜yt+1 − yt(cid:107)2.

(38)

By yt+1 = yt + ηt(˜yt+1 − yt), we have

(cid:107)yt+1 − y∗(xt)(cid:107)2 = (cid:107)yt + ηt(˜yt+1 − yt) − y∗(xt)(cid:107)2

= (cid:107)yt − y∗(xt)(cid:107)2 + 2ηt(cid:104)˜yt+1 − yt, yt − y∗(xt)(cid:105) + η2

t (cid:107)˜yt+1 − yt(cid:107)2.

(39)

Then we obtain

(cid:104)˜yt+1 − yt, y∗(xt) − yt(cid:105) ≤

1
2ηt

(cid:107)yt − y∗(xt)(cid:107)2 +

ηt
2

(cid:107)˜yt+1 − yt(cid:107)2 −

1
2ηt

(cid:107)yt+1 − y∗(xt)(cid:107)2.

(40)

Considering the upper bound of the term (cid:104)∇yf (xt, yt) − wt, y∗(xt) − ˜yt+1(cid:105), we have

(cid:104)∇yf (xt, yt) − wt, y∗(xt) − ˜yt+1(cid:105)
= (cid:104)∇yf (xt, yt) − wt, y∗(xt) − yt(cid:105) + (cid:104)∇yf (xt, yt) − wt, yt − ˜yt+1(cid:105)

≤

=

1
µ
2
µ

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

µ
4
µ
4

(cid:107)y∗(xt) − yt(cid:107)2 +

(cid:107)y∗(xt) − yt(cid:107)2 +

1
µ
µ
4

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

µ
4

(cid:107)yt − ˜yt+1(cid:107)2

(cid:107)yt − ˜yt+1(cid:107)2.

(41)

18

By plugging the inequalities (40) and (41) into (38), we obtain

bt
2ηtλ

(cid:107)yt+1 − y∗(xt)(cid:107)2 ≤ (

−

µ
4

)(cid:107)yt − y∗(xt)(cid:107)2 + (cid:0) ηtbt
2λ

−

bt
λ

+

µ
4

+

Lf
2

(cid:1)(cid:107)˜yt+1 − yt(cid:107)2

(42)

+

≤ (

bt
2ηtλ
2
µ
bt
2ηtλ
bt
2ηtλ
2
µ
≤ (cid:0) bt
2ηtλ

= (

+

(cid:107)∇yf (xt, yt) − wt(cid:107)2

−

−

µ
4
µ
4

)(cid:107)yt − y∗(xt)(cid:107)2 + (

3Lf
4
)(cid:107)yt − y∗(xt)(cid:107)2 − (cid:0) 3bt
8λ

−

+

bt
2λ
bt
8λ

)(cid:107)˜yt+1 − yt(cid:107)2 +

2
µ

(cid:107)∇yf (xt, yt) − wt(cid:107)2

−

3Lf
4

(cid:1)(cid:107)˜yt+1 − yt(cid:107)2

(cid:107)∇yf (xt, yt) − wt(cid:107)2

−

µ
4

(cid:1)(cid:107)yt − y∗(xt)(cid:107)2 −

3bt
8λ

(cid:107)˜yt+1 − yt(cid:107)2 +

2
µ

(cid:107)∇yf (xt, yt) − wt(cid:107)2,

where the second inequality holds by Lf ≥ µ and 0 < ηt ≤ 1, and the last inequality is due to 0 < λ ≤

b
6Lf

≤ bt
6Lf

for all t ≥ 1. It implies that

(cid:107)yt+1 − y∗(xt)(cid:107)2 ≤ (1 −

ηtµλ
2bt

)(cid:107)yt − y∗(xt)(cid:107)2 −

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2 +

4ηtλ
µbt

(cid:107)∇yf (xt, yt) − wt(cid:107)2.

(43)

Next, we decompose the term (cid:107)yt+1 − y∗(xt+1)(cid:107)2 as follows:

(cid:107)yt+1 − y∗(xt+1)(cid:107)2
≤ (cid:107)yt+1 − y∗(xt+1)(cid:107)2
= (cid:107)yt+1 − y∗(xt) + y∗(xt) − y∗(xt+1)(cid:107)2
= (cid:107)yt+1 − y∗(xt)(cid:107)2 + 2(cid:104)yt+1 − y∗(xt), y∗(xt) − y∗(xt+1)(cid:105) + (cid:107)y∗(xt) − y∗(xt+1)(cid:107)2
4bt
ηtµλ
4bt
ηtµλ

)(cid:107)yt+1 − y∗(xt)(cid:107)2 + (1 +

)(cid:107)yt+1 − y∗(xt)(cid:107)2 + (1 +

)(cid:107)y∗(xt) − y∗(xt+1)(cid:107)2

ηtµλ
4bt
ηtµλ
4bt

)κ2(cid:107)xt − xt+1(cid:107)2,

≤ (1 +

≤ (1 +

(44)

where the ﬁrst inequality holds by Cauchy-Schwarz inequality and Young’s inequality, and the second
inequality is due to Lemma 3, and the last equality holds by xt+1 = xt + ηt(˜xt+1 − xt).

By combining the above inequalities (43) and (44), we have

(cid:107)yt+1 − y∗(xt+1)(cid:107)2 ≤ (1 +

ηtµλ
4bt

)(1 −

ηtµλ
2bt

)(cid:107)yt − y∗(xt)(cid:107)2 − (1 +

ηtµλ
4bt

)

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2

+ (1 +

ηtµλ
4bt

)

4ηtλ
µbt

(cid:107)∇yf (xt, yt) − wt(cid:107)2 + (1 +

4bt
ηtµλ

)κ2(cid:107)xt − xt+1(cid:107)2.

(45)

Since 0 < ηt ≤ 1, 0 < λ ≤ bt
6Lf

and Lf ≥ µ, we have λ ≤ bt
6Lf

≤ bt

6µ and ηt ≤ 1 ≤ bt

6µλ . Then we obtain

(1 +

ηtµλ
4bt

)(1 −

ηtµλ
2bt

) = 1 −

ηtµλ
2bt

+

ηtµλ
4bt

−

t µ2λ2
η2
8b2
t

≤ 1 −

ηtµλ
4bt

,

−(1 +

(1 +

ηtµλ
4bt
ηtµλ
4bt

)

)

3ηt
4
4ηtλ
µbt

≤ −

3ηt
4

,

≤ (1 +

1
24

)

(1 +

4bt
ηtµλ

)κ2 ≤

κ2bt
6ηtµλ

+

=

4ηtλ
µ
4κ2bt
ηtµλ

,

25ηtλ
6µbt
25κ2bt
6ηtµλ

=

,

19

(46)

(47)

(48)

(49)

where the second last inequality is due to ηtµλ
bt
have

≤ 1

6 and the last inequality holds by

bt
6µληt

≥ 1. Thus, we

(cid:107)yt+1 − y∗(xt+1)(cid:107)2 ≤ (1 −

)(cid:107)yt − y∗(xt)(cid:107)2 −

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

25κ2bt
6µληt

(cid:107)xt+1 − xt(cid:107)2

)(cid:107)yt − y∗(xt)(cid:107)2 −

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2

ηtµλ
4bt
25ηtλ
6µbt

ηtµλ
4bt
25ηtλ
6µbt

+

+

= (1 −

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

25κ2ηtbt
6µλ

(cid:107)˜xt+1 − xt(cid:107)2,

(50)

where the equality holds by xt+1 = xt + ηt(˜xt+1 − xt).

A.1 Convergence Analysis of the AdaGDA Algorithm

In this subsection, we study the convergence properties of our AdaGDA algorithm for solving the minimax
problem (1). We ﬁrst give a useful Lemma for the gradient estimators.

Lemma 7. Assume that the stochastic partial derivatives vt+1 and wt+1 be generated from Algorithm 1,
we have

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2 ≤ (1 − αt+1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

α2

t+1σ2
q

+

f η2
2L2
t
αt+1

(cid:0)E(cid:107)˜xt+1 − xt(cid:107)2 + E(cid:107)˜yt+1 − yt(cid:107)2(cid:1),

(51)

E(cid:107)∇yf (xt+1, yt+1) − vt+1(cid:107)2 ≤ (1 − βt+1)E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

t+1σ2
β2
q

f η2
2L2
t
βt+1
Proof. We ﬁrst consider the term E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2. Since vt+1 = αt+1∇xf (xt+1, yt+1; Bt+1) +
(1 − αt+1)vt, we have

(cid:0)E(cid:107)˜xt+1 − xt(cid:107)2 + E(cid:107)˜yt+1 − yt(cid:107)2(cid:1).

+

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2
= E(cid:107)∇xf (xt+1, yt+1) − αt+1∇xf (xt+1, yt+1; Bt+1) − (1 − αt+1)vt(cid:107)2
= E(cid:107)αt+1(∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)) + (1 − αt+1)(∇xf (xt, yt) − vt)

+ (1 − αt+1)(cid:0)∇xf (xt+1, yt+1) − ∇xf (xt, yt)(cid:1)(cid:107)2

= E(cid:107)(1 − αt+1)(∇xf (xt, yt) − vt) + (1 − αt+1)(cid:0)∇xf (xt+1, yt+1) − ∇xf (xt, yt)(cid:1)(cid:107)2

+ α2

t+1E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)(cid:107)2

≤ (1 − αt+1)2(1 +

1
αt+1

)E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt, yt)(cid:107)2

(52)

+ (1 − αt+1)2(1 + αt+1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 + α2

t+1E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)(cid:107)2

≤ (1 − αt+1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

≤ (1 − αt+1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

1
αt+1
f η2
2L2
t
αt+1

E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt, yt)(cid:107)2 +

(cid:0)E(cid:107)˜xt+1 − xt(cid:107)2 + E(cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

20

α2

t+1σ2
q
t+1σ2
q

,

α2

where the third equality is due to EBt+1 [∇f (xt+1, yt+1; Bt+1)] = ∇f (xt+1, yt+1); the second last inequality
holds by 0 ≤ αt+1 ≤ 1 such that (1 − αt+1)2(1 + αt+1) = 1 − αt+1 − α2
t+1 ≤ 1 − αt+1 and
(1 − αt+1)2(1 + 1
≤ 1
, and the last inequality holds by
αt+1
Assumption 5 and xt+1 = xt − ηt(˜xt+1 − xt), yt+1 = yt − ηt(˜yt+1 − yt).

) ≤ (1 − αt+1)(1 + 1

) = −αt+1 + 1

t+1 + α3

αt+1

αt+1

αt+1

Similarly, we have

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 ≤ (1 − βt+1)E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

t+1σ2
β2
q

+

2L2
f η2
t
βt+1

(cid:0)E(cid:107)˜xt+1 − xt(cid:107)2 + E(cid:107)˜yt+1 − yt(cid:107)2(cid:1).

(53)

Theorem 5. (Restatement of Theorem 1) Assume that the sequence {xt, yt}T
Algorithm 1. When X ⊂ Rd1 , and given Bt = btId2 (ˆb ≤ bt ≤ b > 0) for all t ≥ 1, ηt =
t ≥ 0, αt+1 = c1ηt, βt+1 = c2ηt, m ≥ max (cid:0)k2, (c1k)2, (c2k)2(cid:1), k > 0, 9µ2
0 < γ ≤ min (cid:0)

t=1 be generated from the
(m+t)1/2 for all
75L2
2 ≤ c2 ≤ m1/2
f
,
(cid:1), we have

, m1/2ρ

(cid:1) and 0 < λ ≤ min (cid:0) 405bL2
50L2

4 ≤ c1 ≤ m1/2
f µ3/2
,
f +9µ2

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2

b
6Lf

400L2

f µ2

4Lk

15

(cid:113)

(cid:113)

√

,

k

k

k

8

2

1
T

T
(cid:88)

t=1

E(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤

√

2

3Gm1/4
T 1/2

+

√
2
3G
T 1/4 ,

(54)

where G = F (x1)−F ∗

kγρ

+

f ∆2
1

9b1L2
kλµρ2 + 2σ2

qkµ2ρ2 + 2mσ2

qkµ2ρ2 ln(m + T ) and ∆2

1 = (cid:107)y1 − y∗(x1)(cid:107)2.

k

Proof. Since ηt =
≤ ρ

(m+t)1/2 on t is decreasing and m ≥ k2, we have ηt ≤ η0 = k
for any t ≥ 0. Due to 0 < ηt ≤ 1 and m ≥ (c1k)2, we have αt+1 = c1ηt ≤ c1k

ρ
2Lη0
due to m ≥ (c2k)2, we have βt+1 ≤ 1. At the same time, we have c1, c2 ≤ m1/2
we have

m1/2 ≤ 1 and γ ≤ m1/2ρ

4Lk ≤
m1/2 ≤ 1. Similarly,
. According to Lemma 7,

2Lηt

k

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2 − E(cid:107)∇xf (xt, yt) − vt(cid:107)2

(55)

≤ −αt+1E(cid:107)∇xf (xt, yt) − vt(cid:107)2 + 2L2

f η2

t /αt+1E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

= −c1ηtE(cid:107)∇xf (xt, yt) − vt(cid:107)2 + 2L2

f ηt/c1E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

≤ −

9µ2ηt
4

E(cid:107)∇xf (xt, yt) − ut(cid:107)2 +

8L2
f ηt
qµ2

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

α2

t+1σ2
q
1η2
t σ2
c2
q
mη2
t σ2
k2q

,

where the above equality holds by αt+1 = c1ηt, and the last inequality is due to 9µ2
given

, we have

75L2
2 ≤ c2 ≤ m1/2
f

k

4 ≤ c1 ≤ m1/2

k

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 − E(cid:107)∇yf (xt, yt) − wt(cid:107)2

≤ −

75L2
f ηt
2

E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

4ηt
75

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

t σ2

mη2
k2q

.

According to Lemma 5, we have

. Similarly,

(56)

F (xt+1) − F (xt) ≤

2γL2
f ηt
ρ

(cid:107)y∗(xt) − yt(cid:107)2 +

2γηt
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

ρηt
2γ

(cid:107)˜xt+1 − xt(cid:107)2.

(57)

21

According to Lemma 6, we have

(cid:107)yt+1 − y∗(xt+1)(cid:107)2 − (cid:107)yt − y∗(xt)(cid:107)2 ≤ −

+

ηtµλ
4bt
25ηtλ
6µbt

(cid:107)yt − y∗(xt)(cid:107)2 −

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2

(58)

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

25κ2ηtbt
6µλ

(cid:107)˜xt+1 − xt(cid:107)2.

Next, we deﬁne a Lyapunov function, for any t ≥ 1

Ωt = E(cid:2)F (xt) +

f γ

9btL2
λµρ

(cid:107)yt − y∗(xt)(cid:107)2 +

γ
ρµ2

(cid:0)(cid:107)∇xf (xt, yt) − vt(cid:107)2 + (cid:107)∇yf (xt, yt) − wt(cid:107)2(cid:3).

Then we have

Ωt+1 − Ωt

(cid:0)E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2

f γ

9btL2
λµρ

≤

= E(cid:2)F (xt+1) − F (xt)(cid:3) +

E(cid:107)y∗(xt) − yt(cid:107)2 +

(cid:0)E(cid:107)yt+1 − y∗(xt+1)(cid:107)2 − E(cid:107)yt − y∗(xt)(cid:107)2(cid:1) +

γ
ρµ2
− E(cid:107)∇xf (xt, yt) − vt(cid:107)2 + E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 − E(cid:107)∇yf (xt, yt) − wt(cid:107)2(cid:1)
2γL2
f ηt
ρ
9btL2
λµρ
25κ2ηtbt
6µλ
t σ2

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

3ηt
4
9µ2ηt
4

E(cid:107)yt − y∗(xt)(cid:107)2 −

E(cid:107)˜yt+1 − yt(cid:107)2 +

E(cid:107)˜xt+1 − xt(cid:107)2

E(cid:107)˜xt+1 − xt(cid:107)2

8L2
f ηt
9µ2

25ηtλ
6µbt

ηtµλ
4bt

2γηt
ρ

γ
ρµ2

ρηt
2γ

− 1

f γ

+

−

+

+

(cid:18)

(cid:19)

(cid:18)

E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

+

mη2
k2q

−

75L2
f ηt
2

4ηt
75

E(cid:107)∇yf (xt, yt) − wt(cid:107)2

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1)

(cid:19)

t σ2

mη2
k2q
t κ2L2
6µ2λ2ρ

f γ

125b2

(cid:1)ηtE(cid:107)˜xt+1 − xt(cid:107)2

= −

(cid:0)L2

γηt
4ρ
− (cid:0) 27btL2
f γ
4λµρ

≤ −

γηt
4ρ

(cid:0)L2

f E(cid:107)yt − y∗(xt)(cid:107)2 + E(cid:107)∇xf (xt, yt) − vt(cid:107)2(cid:1) − (cid:0) ρ
2γ
2mγσ2
k2ρµ2q
ρηt
4γ

f E(cid:107)yt − y∗(xt)(cid:107)2 + E(cid:107)∇xf (xt, yt) − vt(cid:107)2(cid:1) −

(cid:1)ηtE(cid:107)˜yt+1 − yt(cid:107)2 +

8L2
f γ
9ρµ4 −

4γ
75ρµ2

−

8L2
f γ
9ρµ4 −

4γ
75ρµ2 −

−

η2
t

E(cid:107)˜xt+1 − xt(cid:107)2 +

2mγσ2
k2ρµ2q

η2
t ,

(59)

where the ﬁrst inequality holds by the above inequalities (55), (56), (57) and (58); the last inequality is due

to 0 < γ ≤

(cid:113)

2

400L2

√

15

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2

f µ2

≤

(cid:113)

2

√

15

2λµ2ρ

400L2

f λ2+24µ2λ2+9375b2

t κ2L2

f µ2

and 0 < λ ≤

405bL2
(cid:113)

50L2

f µ3/2
f +9µ2

8

≤

405btL2
(cid:113)
50L2

f µ3/2
f +9µ2

8

for all t ≥ 1. Then we have

L2
f ηt
4

E(cid:107)yt − y∗(xt)(cid:107)2 +

ηt
4

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ2ηt
4γ2

E(cid:107)˜xt+1 − xt(cid:107)2 ≤

ρ(Ωt − Ωt+1)
γ

+

2mσ2
k2µ2q

η2
t .

(60)

Taking average over t = 1, 2, · · · , T on both sides of (60), we have

1
T

T
(cid:88)

t=1

E(cid:2) L2
f ηt
4

(cid:107)yt − y∗(xt)(cid:107)2 +

ηt
4

(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ2ηt
4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3)

≤

T
(cid:88)

t=1

ρ(Ωt − Ωt+1)
T γ

+

1
T

T
(cid:88)

t=1

2mσ2
k2µ2q

η2
t .

22

(61)

Given x1 ∈ X , y1 ∈ Y and ∆2

1 = (cid:107)y1 − y∗(x1)(cid:107)2, we have

Ω1 = F (x1) +

≤ F (x1) +

f γ

9b1L2
λµρ
9b1L2

λµρ

f γ∆2
1

(cid:107)y1 − y∗(x1)(cid:107)2 +

γ
ρµ2

(cid:0)E(cid:107)∇xf (x1, y1) − v1(cid:107)2 + E(cid:107)∇yf (x1, y1) − w1(cid:107)2(cid:1)

+

2γσ2
qρµ2 ,

(62)

where the above inequality holds by Assumption 1.

Since ηt is decreasing on t, i.e., η−1

T ≥ η−1

t

for any 0 ≤ t ≤ T , we have

1
T

T
(cid:88)

t=1

E(cid:2) L2
f
4

(cid:107)yt − y∗(xt)(cid:107)2 +

1
4

(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ2
4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3)

≤

≤

≤

≤

=

ρ
T γηT

ρ
T γηT

T
(cid:88)

t=1

(cid:0)Φt − Φt+1

(cid:1) +

1
T ηT

T
(cid:88)

t=1

2mσ2
k2µ2q

η2
t

(cid:0)F (x1) +

9b1L2

f γ∆2
1

λµρ

+

2γσ2
qρµ2 − F ∗(cid:1) +

1
T ηT

T
(cid:88)

t=1

2mσ2
k2µ2q

η2
t

+

+

ρ(F (x1) − F ∗)
T γηT
ρ(F (x1) − F ∗)
T γηT
(cid:18) ρ(F (x1) − F ∗)
kγ

9b1L2
f ∆2
1
λµηT T
f ∆2
9b1L2
1
λµηT T
9b1L2
kλµ

+

+

+

+

+

2σ2
qµ2ηT T
2σ2
qµ2ηT T
2σ2
qkµ2 +

f ∆2
1

+

2mσ2
ηT T k2µ2q
2mσ2
ηT T µ2q

(cid:90) T

1

k2
m + t

dt

ln(m + T )

2mσ2
kµ2q

ln(m + T )

(cid:19) (m + T )1/2
T

,

(63)

where the second inequality holds by the above inequality (62). Let G = F (x1)−F ∗
2mσ2
qkµ2ρ2 ln(m + T ), we have

kγρ

+

f ∆2
1

9b1L2
kλµρ2 + 2σ2

qkµ2ρ2 +

1
T

T
(cid:88)

t=1

E(cid:2) L2

f

4ρ2 (cid:107)y∗(xt) − yt(cid:107)2 +

1
4ρ2 (cid:107)∇xf (xt, yt) − vt(cid:107)2 +

1

4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3) ≤

G
T

(m + T )1/2.

(64)

According to Jensen’s inequality, we have

1
T

T
(cid:88)

t=1

E(cid:2) Lf
2ρ

(cid:107)y∗(xt) − yt(cid:107) +

1
2ρ

(cid:107)∇xf (xt, yt) − vt(cid:107) +

1
2γ

(cid:107)˜xt+1 − xt(cid:107)(cid:3)

≤

≤

f

T
(cid:88)

E(cid:2) L2

(cid:18) 3
T
√
3G
T 1/2 (m + T )1/4 ≤

4ρ2 (cid:107)y∗(xt) − yt(cid:107)2 +
√
3Gm1/4
T 1/2 +

t=1

1
4ρ2 (cid:107)∇xf (xt, yt) − vt(cid:107)2 +
√
3G
T 1/4 ,

1

4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3)

(cid:19)1/2

where the last inequality is due to (a + b)1/4 ≤ a1/4 + b1/4 for all a, b > 0. Thus, we have

1
T

T
(cid:88)

t=1

E(cid:2) Lf
ρ

(cid:107)y∗(xt) − yt(cid:107) +

1
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107) +

(cid:107)˜xt+1 − xt(cid:107)(cid:3) ≤

1
γ

√

2

3Gm1/4
T 1/2

+

√
2
3G
T 1/4 .

(65)

(66)

Let φt(x) = 1

2 xT Atx, according to Assumption 4, φt(x) is ρ-strongly convex. Then we deﬁne a prox-
function (i.e., Bregman distance) associated with φt(x) as in [Censor and Lent, 1981, Censor and Zenios,

23

1992, Ghadimi et al., 2016], deﬁned as

Dt(x, xt) = φt(x) − (cid:2)φt(xt) + (cid:104)∇φt(xt), x − xt(cid:105)(cid:3) =

1
2

(x − xt)T At(x − xt).

The line 5 of Algorithms 1 is equivalent to the following generalized projection problem

˜xt+1 = arg min
x∈X

(cid:8)(cid:104)vt, x(cid:105) +

1
γ

Dt(x, xt)(cid:9).

(67)

(68)

As in [Ghadimi et al., 2016], we deﬁne a generalized projected gradient GX (xt, vt, γ) = 1
the same time, we deﬁne a gradient mapping GX (xt, ∇F (xt), γ) = 1

t+1), where

γ (xt − x∗

γ (xt − ˜xt+1). At

x∗
t+1 = arg min
x∈X

(cid:8)(cid:104)∇F (xt), x(cid:105) +

Dt(x, xt)(cid:9).

1
γ

Since F (xt) = f (xt, y∗(xt)) = miny∈Y f (xt, y), by Assumption 5, we have

(cid:107)∇F (xt) − vt(cid:107) = (cid:107)∇xf (xt, y∗(xt)) − vt(cid:107)

= (cid:107)∇xf (xt, y∗(xt)) − ∇xf (xt, yt) + ∇xf (xt, yt) − vt(cid:107)
≤ (cid:107)∇xf (xt, y∗(xt)) − ∇xf (xt, yt)(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107)
≤ Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107).

(69)

(70)

According to Proposition 1 in [Ghadimi et al., 2016], we have (cid:107)GX (xt, ∇F (xt), γ) − GX (xt, vt, γ)(cid:107) ≤ 1
∇F (xt)(cid:107). Let Mt = 1

(cid:0)Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107)(cid:1), we have

γ (cid:107)xt − ˜xt+1(cid:107) + 1

ρ

ρ (cid:107)vt −

(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤ (cid:107)GX (xt, vt, γ)(cid:107) + (cid:107)GX (xt, ∇F (xt), γ) − GX (xt, vt, γ)(cid:107)

(71)

≤ (cid:107)GX (xt, vt, γ)(cid:107) +

≤

1
γ

(cid:107)xt − ˜xt+1(cid:107) +

(cid:107)∇F (xt) − vt(cid:107)

1
ρ
1
(cid:0)Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107)(cid:1) = Mt,
ρ

where the second inequality holds by the above inequality (cid:107)∇F (xt)−vt(cid:107) ≤ Lf (cid:107)y∗(xt)−yt(cid:107)+(cid:107)∇xf (xt, yt)−
vt(cid:107).

According to the above inequalities (71) and (66), we have

1
T

T
(cid:88)

t=1

E(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤

1
T

T
(cid:88)

t=1

E(cid:2)Mt

(cid:3) ≤

√

2

3Gm1/4
T 1/2

+

√
3G
2
T 1/4 .

(72)

Theorem 6. (Restatement of Theorem 2) Assume that the sequence {xt, yt}T
Algorithm 1. When X = Rd1 , and given Bt = btId2 (ˆb ≤ bt ≤ b > 0) for all t ≥ 1, ηt =
t ≥ 0, αt+1 = c1ηt, βt+1 = c2ηt, m ≥ max (cid:0)k2, (c1k)2, (c2k)2(cid:1), k > 0, 9µ2
0 < γ ≤ min (cid:0)

t=1 be generated from the
(m+t)1/2 for all
75L2
2 ≤ c2 ≤ m1/2
f
,
(cid:1), we have

, m1/2ρ

(cid:1) and 0 < λ ≤ min (cid:0) 405bL2
50L2

4 ≤ c1 ≤ m1/2
f µ3/2
,
f +9µ2

2λµ2ρ
f λ2+24µ2λ2+9375ˆb2κ2L2

b
6Lf

400L2

f µ2

4Lk

15

(cid:113)

(cid:113)

√

,

k

k

k

8

2

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

(cid:113) 1
T

(cid:80)T

t=1
ρ

E(cid:107)At(cid:107)2

(cid:18) 2

√

3G(cid:48)m1/4
T 1/2

+

√

3G(cid:48)
2
T 1/4

(cid:19)

,

(73)

where G(cid:48) = ρ(F (x1)−F ∗)

kγ

+

9b1L2

f ∆2
1

kλµ + 2σ2

qkµ2 + 2mσ2

qkµ2 ln(m + T ).

24

Proof. Since F (xt) = f (xt, y∗(xt)) = miny∈Y f (xt, y), we have (cid:107)∇F (xt) − vt(cid:107) = (cid:107)∇xf (xt, y∗(xt)) − vt(cid:107) =
(cid:107)∇xf (xt, y∗(xt)) − ∇xf (xt, yt) + ∇xf (xt, yt) − vt(cid:107) ≤ (cid:107)∇xf (xt, y∗(xt)) − ∇xf (xt, yt)(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107) ≤
Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107). Then we have

Mt =

≥

1
γ
1
γ

(cid:107)xt − ˜xt+1(cid:107) +

(cid:107)xt − ˜xt+1(cid:107) +

1
ρ
1
ρ

(cid:0)Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107)(cid:1)

(cid:107)∇F (xt) − vt(cid:107)

(i)
= (cid:107)A−1

t vt(cid:107) +

1
ρ

(cid:107)∇F (xt) − vt(cid:107)

1
(cid:107)At(cid:107)
1
(cid:107)At(cid:107)

(cid:107)At(cid:107)(cid:107)A−1

t vt(cid:107) +

1
ρ

(cid:107)∇F (xt) − vt(cid:107)

(cid:107)vt(cid:107) +

1
ρ

(cid:107)∇F (xt) − vt(cid:107)

(cid:107)vt(cid:107) +

1
(cid:107)At(cid:107)

(cid:107)∇F (xt) − vt(cid:107)

=

≥

(ii)
≥

≥

1
(cid:107)At(cid:107)
1
(cid:107)At(cid:107)

(cid:107)∇F (xt)(cid:107)

(74)

where the equality (i) holds by ˜xt+1 = xt − γA−1
t vt that can be easily obtained from the line 5 of Algorithm
1 when X = Rd1 , and the inequality (ii) holds by (cid:107)At(cid:107) ≥ ρ for all t ≥ 1 due to Assumption 4. Then we
have

(cid:107)∇F (xt)(cid:107) ≤ Mt(cid:107)At(cid:107).

(75)

By using Cauchy-Schwarz inequality, we have

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

1
T

T
(cid:88)

t=1

E(cid:2)Mt(cid:107)At(cid:107)(cid:3) ≤

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T

T
(cid:88)

t=1

E[M2
t ]

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T

T
(cid:88)

t=1

E(cid:107)At(cid:107)2.

(76)

According to the above inequality (64) and Mt = 1
we have

γ (cid:107)xt − ˜xt+1(cid:107) + 1

ρ

(cid:0)Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107)(cid:1),

1
T

T
(cid:88)

t=1

E(cid:2)M2

t

(cid:3) ≤

1
T

T
(cid:88)

t=1

f

(cid:2) 3L2
ρ2 (cid:107)y∗(xt) − yt(cid:107)2 +

3
ρ2 (cid:107)∇xf (xt, yt) − vt(cid:107)2 +

3

γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3)

≤

12G
T

(m + T )1/2.

By combining the above inequalities (76) and (77), we have

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T

T
(cid:88)

t=1

E(cid:107)At(cid:107)2 2

3G

√
T 1/2 (m + T )1/4.

Let G(cid:48) = ρ2G = ρ(F (x1)−F ∗)

kγ

+

qkµ2 ln(m + T ), we have

9b1L2

f ∆2
1

qkµ2 + 2mσ2
kλµ + 2σ2
(cid:113) 1
T

(cid:80)T

E(cid:107)At(cid:107)2

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

t=1
ρ

√

(cid:18) 2

3G(cid:48)m1/4
T 1/2

+

√

3G(cid:48)
2
T 1/4

(cid:19)

.

(77)

(78)

(79)

25

A.2 Convergence Analysis of the VR-AdaGDA Algorithm

In the subsection, we study the convergence properties of the VR-AdaGDA algorithm for solving the
minimax problem (1). We ﬁrst provide a useful lemma.

Lemma 8. Suppose the stochastic gradients vt and wt be generated from Algorithm 2, we have

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2 ≤ (1 − αt+1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

2α2

t+1σ2
q

+

4L2
f η2
t
q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1),

(80)

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 ≤ (1 − βt+1)E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

t+1σ2
2β2
q

+

4L2
f η2
t
q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1).

Proof. We ﬁrst prove the inequality (80). According to the deﬁnition of vt in Algorithm 2, we have

vt+1 − vt = −αt+1vt + (1 − αt+1)(cid:0)∇xf (xt+1, yt+1; Bt+1) − ∇xf (xt, yt; Bt+1)(cid:1)

+ αt+1∇xf (xt+1, yt+1; Bt+1).

Then we have

(81)

(82)

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2
= E(cid:107)∇xf (xt+1, yt+1) − vt − (vt+1 − vt)(cid:107)2
= E(cid:107)∇xf (xt+1, yt+1) − vt + αt+1vt − αt+1∇xf (xt+1, yt+1; Bt+1) − (1 − αt+1)(cid:0)∇xf (xt+1, yt+1; Bt+1)

(83)

− ∇xf (xt, yt; Bt+1)(cid:1)(cid:107)2

= E(cid:107)(1 − αt+1)(∇xf (xt, yt) − vt) + (1 − αt+1)(cid:0)∇xf (xt+1, yt+1) − ∇xf (xt, yt) − ∇xf (xt+1, yt+1; Bt+1)
(cid:0)∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)(cid:1)(cid:107)2

+ ∇xf (xt, yt; Bt+1)(cid:1) + αt+1

= (1 − αt+1)2E(cid:107)∇xf (xt, yt) − vt(cid:107)2 + α2

t+1E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)(cid:107)2

+ (1 − αt+1)2E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt, yt) − ∇xf (xt+1, yt+1; Bt+1) + ∇xf (xt, yt; Bt+1)(cid:107)2
+ 2αt+1(1 − αt+1)(cid:10)∇xf (xt+1, yt+1) − ∇xf (xt, yt) − ∇xf (xt+1, yt+1; Bt+1) + ∇xf (xt, yt; Bt+1),

∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)(cid:11)

≤ (1 − αt+1)2E(cid:107)∇xf (xt, yt) − vt(cid:107)2 + 2α2

t+1E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt+1, yt+1; Bt+1)(cid:107)2

+ 2(1 − αt+1)2E(cid:107)∇xf (xt+1, yt+1) − ∇xf (xt, yt) − ∇xf (xt+1, yt+1; Bt+1) + ∇xf (xt, yt; Bt+1)(cid:107)2

≤ (1 − αt+1)2E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

2α2

t+1σ2
q

+

2(1 − αt+1)2
q

E(cid:107)∇xf (xt+1, yt+1; ξt+1) − ∇xf (xt, yt; ξt+1)(cid:107)2
,
(cid:125)
(cid:123)(cid:122)
(cid:124)
=T1

where the fourth equality follows by EBt+1 [∇xf (xt+1, yt+1; Bt+1)] = ∇xf (xt+1, yt+1) and EBt+1 [∇xf (xt+1, yt+1; Bt+1)−
∇xf (xt, yt; Bt+1)] = ∇xf (xt+1, yt+1) − ∇xf (xt, yt); the ﬁrst inequality holds by Young’s inequality; the last
inequality is due to Lemma 4 and Assumption 1.

26

According to Assumption 6, we have

T1 = E(cid:13)
= E(cid:13)
≤ 2L2
= 2L2

(cid:13)∇xf (xt+1, yt+1; ξt+1) − ∇xf (xt, yt; ξt+1)(cid:13)
2
(cid:13)
(cid:13)∇xf (xt+1, yt+1; ξt+1) − ∇xf (xt, yt+1; ξt+1) + ∇xf (xt, yt+1; ξt+1) − ∇xf (xt, yt; ξt+1)(cid:13)
2
(cid:13)
f E(cid:107)xt+1 − xt(cid:107)2 + 2L2
f η2

t E(cid:107)˜xt+1 − xt(cid:107)2 + 2L2

t E(cid:107)˜yt+1 − yt(cid:107)2.

f E(cid:107)yt+1 − yt(cid:107)2

f η2

(84)

Plugging the above inequality (84) into (83), we obtain

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2 ≤ (1 − αt+1)2E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

2α2

t+1σ2
q

+

4(1 − αt+1)2L2
q

f η2
t

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1)

≤ (1 − αt+1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

2α2

t+1σ2
q

+

f η2
4L2
t
q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1),

(85)

where the last inequality holds by 0 < αt+1 ≤ 1.

Similarly, we have

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 ≤ (1 − βt+1)E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

t+1σ2
2β2
q

+

f η2
4L2
t
q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1).

(86)

Theorem 7. (Restatement of Theorem 3) Suppose the sequence {xt, yt}T
2. When X ⊂ Rd1 , and given Bt = btId2 (0 < b ≤ bt ≤ ˆb), ηt =
k
c1 ≥ 2
0 < γ ≤ min (cid:0)

3k3 + 9µ2

(cid:1), we have

, m1/3ρ

3k3 +

75L2
f
2

and c2 ≥ 2
√
q
32λ2+150qκ2ˆb2

ρλµ

2Lk

√

4

Lf

, m ≥ max (cid:0)k3, (c1k)3, (c2k)3(cid:1), 0 < λ ≤ min (cid:0) 27µbq
32 ,

b
6Lf

(m+t)1/3 , αt+1 = c1η2

t=1 be generated from Algorithm
t , βt+1 = c2η2
t ,
(cid:1) and

1
T

T
(cid:88)

t=1

E(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤

√

2

3M m1/6
T 1/2

+

√
2
3M
T 1/3 ,

(87)

where M = F (x1)−F ∗

T γkρ +

9L2
f b1
kλµρ2 ∆2

1 + 2σ2m1/3

k2qµ2ρ2 + 2k2(c2

1+c2
qµ2ρ2

2)σ2

ln(m + T ) and ∆2

1 = (cid:107)y1 − y∗(x1)(cid:107)2.

Proof. Since ηt is decreasing and m ≥ k3, we have ηt ≤ η0 = k
any t ≥ 0. Due to 0 < ηt ≤ 1 and m ≥ max (cid:0)(c1k)3, (c2k)3(cid:1), we have αt = c1η2
βt = c2η2

m1/3 ≤ 1. Then we consider the upper bound of the following term:

m1/3 ≤ 1 and γ ≤ ρ

t ≤ c2ηt ≤ c2k

= m1/3ρ
2Lη0
t ≤ c1ηt ≤ c1k

2Lk ≤ 1
for
2Lηt
m1/3 ≤ 1 and

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2 −

1
ηt−1

E(cid:107)∇xf (xt, yt) − vt(cid:107)2

1
ηt
≤ (cid:0) 1 − αt+1

ηt

−

1
ηt−1

(cid:1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

= (cid:0) 1
ηt

−

1
ηt−1

− c1ηt

(cid:1)E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

4L2
f ηt
q
4L2
f ηt
q

27

(88)

,

2α2

2c2

t+1σ2
qηt
t σ2
1η3
q

where the second inequality is due to 0 < αt+1 ≤ 1. Similarly, we have

1
ηt
≤ (cid:0) 1
ηt

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 −

1
ηt−1

E(cid:107)∇yf (xt, yt) − wt(cid:107)2

(89)

−

1
ηt−1

− c2ηt

(cid:1)E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

4L2
f ηt
q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

2c2

2η3
t σ2
q

.

By ηt =

k

(m+t)1/3 , we have

1
ηt

−

1
ηt−1

=

≤

≤

(cid:0)(m + t)

1
3 − (m + t − 1)

1

3 (cid:1)

1
k

1
3k(m + t − 1)2/3 =

22/3
3k(m + t)2/3 =

22/3
3k3

22/3
3k(cid:0)2(m + t − 1)(cid:1)2/3
22/3
3k3 η2

k2
(m + t)2/3 =

t ≤

2
3k3 ηt,

(90)

where the ﬁrst inequality holds by the concavity of function f (x) = x1/3, i.e., (x + y)1/3 ≤ x1/3 + y
and the last inequality is due to 0 < ηt ≤ 1.

3x2/3 ,

Let c1 ≥ 2

3k3 + 9µ2

4 , we have

1
ηt

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2 −

E(cid:107)∇xf (xt, yt) − vt(cid:107)2

≤ −

9µ2ηt
4

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

2c2

1η3
t σ2
q

.

1
ηt−1
4L2
f ηt
q

Let c2 ≥ 2

3k3 +

75L2
f
2

, we have

1
ηt

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 −

1
ηt−1

E(cid:107)∇yf (xt, yt) − wt(cid:107)2

≤ −

75L2
f ηt
2

E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

4L2
f ηt
q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

2c2

t σ2
2η3
q

.

(91)

(92)

According to Lemma 5, we have

F (xt+1) − F (xt) ≤

2γL2
f ηt
ρ

(cid:107)y∗(xt) − yt(cid:107)2 +

2γηt
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

ρηt
2γ

(cid:107)˜xt+1 − xt(cid:107)2.

(93)

According to Lemma 6, we have

(cid:107)yt+1 − y∗(xt+1)(cid:107)2 − (cid:107)yt − y∗(xt)(cid:107)2 ≤ −

+

ηtµλ
4bt
25ηtλ
6µbt

(cid:107)yt − y∗(xt)(cid:107)2 −

3ηt
4

(cid:107)˜yt+1 − yt(cid:107)2

(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

25κ2ηtbt
6µλ

(cid:107)˜xt+1 − xt(cid:107)2.

(94)

Next, we deﬁne a Lyapunov function, for any t ≥ 1

Φt = E(cid:2)F (xt) +

f bt

9γL2
ρλµ

(cid:107)yt − y∗(xt)(cid:107)2 +

γ
ρµ2

(cid:0) 1
ηt−1

(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

1
ηt−1

(cid:107)∇yf (xt, yt) − wt(cid:107)2(cid:1)(cid:3).

(95)

28

Then we have

Φt+1 − Φt

= E(cid:2)F (xt+1) − F (xt)(cid:3)+

f bt

9γL2
ρλµ

(cid:0)E(cid:107)yt+1 − y∗(xt+1)(cid:107)2 −E(cid:107)yt − y∗(xt)(cid:107)2(cid:1)+

γ
ρµ2

(cid:0) 1
ηt

E(cid:107)∇xf (xt+1, yt+1) − vt+1(cid:107)2

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

1
ηt

E(cid:107)∇yf (xt+1, yt+1) − wt+1(cid:107)2 −

1
ηt−1

E(cid:107)∇yf (xt, yt) − wt(cid:107)2(cid:1)

≤

E(cid:107)y∗(xt) − yt(cid:107)2 +

2γηt
ρ

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

ρηt
2γ

E(cid:107)˜xt+1 − xt(cid:107)2

f bt

(cid:18)

−

ηtµλ
4bt

E(cid:107)yt − y∗(xt)(cid:107)2 −

E(cid:107)˜yt+1 − yt(cid:107)2 +

25ηtλ
6µbt

E(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

25κ2ηtbt
6µλ

E(cid:107)˜xt+1 − xt(cid:107)2

(cid:19)

3ηt
4
4γL2
f ηt
ρµ2q

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

t σ2

2γc2

1η3
ρµ2q

ηtE(cid:107)∇yf (xt, yt) − wt(cid:107)2 +

4γL2
f ηt
ρµ2q

E(cid:0)(cid:107)˜xt+1 − xt(cid:107)2 + (cid:107)˜yt+1 − yt(cid:107)2(cid:1) +

t σ2

2γc2

2η3
ρµ2q

≤ −

E(cid:107)y∗(xt) − yt(cid:107)2 −

γηt
4ρ

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

−

8γL2
f
ρµ2q

(cid:1)ηtE(cid:107)˜yt+1 − yt+1(cid:107)2 − (cid:0) ρ
2γ

−

8γL2
f
ρµ2q

+

t σ2

2γc2

2η3
ρµ2q

2γc2

t σ2

1η3
ρµ2q
75γL2

−

f κ2b2
t

2ρλ2µ2

(cid:1)ηtE(cid:107)˜xt+1 − xt(cid:107)2

−

1
ηt−1
2γL2
f ηt
ρ
9γL2
ρλµ

+

−

−

9γηt
4ρ
75L2
f γ
2µ2ρ
γL2
f ηt
4ρ
− (cid:0) 27btγL2
4ρλµ
γL2
f ηt
4ρ

f

≤ −

E(cid:107)y∗(xt) − yt(cid:107)2 −

γηt
4ρ

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 −

ρηt
4γ

E(cid:107)˜xt+1 − xt(cid:107)2 +

t σ2

2γc2

1η3
ρµ2q

+

t σ2

2γc2

2η3
ρµ2q

,

(96)

where the ﬁrst inequality holds by the above inequalities (91), (92), (93) and (94); the last inequality is due
to 0 < λ ≤ 27µbq
for all t ≥ 1. Thus, we have

and 0 < γ ≤

ρλµ

ρλµ

√

√

≤

√

√

q
32λ2+150qκ2ˆb2

Lf

q
32λ2+150qκ2b2
t

Lf

32 ≤ 27µbtq

32

L2
f ηt
4

E(cid:107)y∗(xt) − yt(cid:107)2 +

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ2ηt
4γ2

E(cid:107)˜xt+1 − xt(cid:107)2

≤

ρ(Φt − Φt+1)
γ

+

+

2c2

t σ2

2η3
µ2q

.

(97)

ηt
4
1η3
t σ2
µ2q

2c2

Taking average over t = 1, 2, · · · , T on both sides of (97), we have

1
T

T
(cid:88)

t=1

(cid:0) L2
f ηt
4

E(cid:107)y∗(xt) − yt(cid:107)2 +

ηt
4

E(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ2ηt
4γ2

E(cid:107)˜xt+1 − xt(cid:107)2(cid:1)

≤

T
(cid:88)

t=1

ρ(Φt − Φt+1)
T γ

+

1
T

T
(cid:88)

t=1

(cid:0) 2c2

t σ2

1η3
µ2q

+

2c2

t σ2

2η3
µ2q

(cid:1).

Given x1 ∈ X , y1 ∈ Y and ∆2

1 = (cid:107)y1 − y∗(x1)(cid:107)2, we have

Φ1 = F (x1) +

≤ F (x1) +

f b1

9γL2
ρλµ
9γL2
ρλµ

f b1

(cid:107)y1 − y∗(x1)(cid:107)2 +

γ
ρµ2η0

E(cid:107)∇xf (x1, y1) − v1(cid:107)2 +

γ
ρµ2η0

E(cid:107)∇yf (x1, y1) − w1(cid:107)2

∆2

1 +

2γσ2
qρµ2η0

,

(98)

where the last inequality holds by Assumption 1.

29

Since ηt is decreasing, i.e., η−1

T ≥ η−1

t

for any 0 ≤ t ≤ T , we have

1
T

T
(cid:88)

t=1

E(cid:0) L2
f
4

(cid:107)y∗(xt) − yt(cid:107)2 +

1
4

(cid:107)∇xf (xt, yt) − vt(cid:107)2 +

ρ2
4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:1)

≤

=

≤

≤

=

T
(cid:88)

t=1

ρ(Φt − Φt+1)
ηT T γ

+

1
ηT T

T
(cid:88)

(cid:0) 2c2

t σ2

1η3
µ2q

+

2c2

t σ2

2η3
µ2q

(cid:1)

ρ(Φ1 − ΦT +1)
ηT T γ

+

2(c2

1 + c2
ηT T qµ2

t=1
2)σ2

T
(cid:88)

t=1

η3
t

+

+

ρ(F (x1) − F ∗)
T ηT γ
ρ(F (x1) − F ∗)
T ηT γ
(cid:18) ρ(F (x1) − F ∗)
T γk

9L2
f b1
ηT T λµ
9L2
f b1
ηT T λµ
9L2
f b1
kλµ

+

∆2

1 +

∆2

1 +

∆2

1 +

+

+

2σ2
ηT T qµ2η0
2σ2
ηT T qµ2η0
2σ2m1/3
k2qµ2 +

2(c2

2k3(c2

2)σ2

1 + c2
ηT T qµ2
1 + c2
ηT T qµ2
1 + c2
qµ2

2k2(c2

2)σ2

1
2)σ2

(cid:90) T

k3
m + t

dt

ln(m + T )

ln(m + T )

(cid:19) (m + T )1/3
T

,

(99)

where the second inequality holds by the above inequality (98). Let M = F (x1)−F ∗
2k2(c2

T γkρ +

2)σ2

1+c2
qµ2ρ2

ln(m + T ), we have

9L2
f b1
kλµρ2 ∆2

1 + 2σ2m1/3

k2qµ2ρ2 +

1
T

T
(cid:88)

t=1

E(cid:2) L2

f

4ρ2 (cid:107)y∗(xt) − yt(cid:107)2 +

1
4ρ2 (cid:107)∇xf (xt, yt) − vt(cid:107)2 +

1

4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3) ≤

M
T

(m + T )1/3.

(100)

According to Jensen’s inequality, we have

1
T

T
(cid:88)

t=1

E(cid:2) Lf
2ρ

(cid:107)y∗(xt) − yt(cid:107) +

1
2ρ

(cid:107)∇xf (xt, yt) − vt(cid:107) +

1
2γ

(cid:107)˜xt+1 − xt(cid:107)(cid:3)

≤

≤

f

T
(cid:88)

E(cid:2) L2

(cid:18) 3
T
√
3M
T 1/2 (m + T )1/6 ≤

4ρ2 (cid:107)y∗(xt) − yt(cid:107)2 +
√
3M m1/6
T 1/2

t=1

1
4ρ2 (cid:107)∇xf (xt, yt) − vt(cid:107)2 +

1

4γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3)

(cid:19)1/2

√
3M
T 1/3 ,

+

where the last inequality is due to (a + b)1/6 ≤ a1/6 + b1/6. Thus, we have

1
T

T
(cid:88)

t=1

E(cid:2) Lf
ρ

(cid:107)y∗(xt) − yt(cid:107) +

1
ρ

(cid:107)∇xf (xt, yt) − vt(cid:107) +

(cid:107)˜xt+1 − xt(cid:107)(cid:3) ≤

2

1
γ

√

3M m1/6
T 1/2

√
2
3M
T 1/3 .

+

According to the above inequalities (71) and (102), we can obtain

1
T

T
(cid:88)

t=1

E(cid:107)GX (xt, ∇F (xt), γ)(cid:107) ≤

1
T

T
(cid:88)

t=1

E(cid:2)Mt

(cid:3) ≤

2

√

3M m1/6
T 1/2

√
2
3M
T 1/3 .

+

(101)

(102)

(103)

Theorem 8. (Restatement of Theorem 4) Suppose the sequence {xt, yt}T
2. When X = Rd1 , and given Bt = btId2 (0 < b ≤ bt ≤ ˆb), ηt =
k

t=1 be generated from Algorithm
t , βt+1 = c2η2
t ,

(m+t)1/3 , αt+1 = c1η2

30

3k3 + 9µ2

c1 ≥ 2
0 < γ ≤ min (cid:0)

4

Lf

and c2 ≥ 2
√
q
32λ2+150qκ2ˆb2

ρλµ

√

, m1/3ρ

2Lk

(cid:1), we have

3k3 +

75L2
f
2

, m ≥ max (cid:0)k3, (c1k)3, (c2k)3(cid:1), 0 < λ ≤ min (cid:0) 27µbq
32 ,

(cid:1) and

b
6Lf

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

(cid:113) 1
T

(cid:80)T

t=1
ρ

E(cid:107)At(cid:107)2

(cid:18) 2

√

3M (cid:48)m1/6
T 1/2

√

2

3M (cid:48)

T 1/3

(cid:19)

,

+

(104)

where M (cid:48) = ρ(F (x1)−F ∗)

k2qµ2 + 2k2(c2
Proof. According to the above inequality (76), we have

1 + 2σ2m1/3

9L2
f b1
kλµ ∆2

T γk

+

2)σ2

1+c2
qµ2

ln(m + T ).

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

1
T

T
(cid:88)

t=1

E(cid:2)Mt(cid:107)At(cid:107)(cid:3) ≤

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T

T
(cid:88)

t=1

E[M2
t ]

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T

T
(cid:88)

t=1

E(cid:107)At(cid:107)2.

(105)

By using the above inequality (100) and Mt = 1
we have

γ (cid:107)xt − ˜xt+1(cid:107) + 1

ρ

(cid:0)Lf (cid:107)y∗(xt) − yt(cid:107) + (cid:107)∇xf (xt, yt) − vt(cid:107)(cid:1),

1
T

T
(cid:88)

t=1

E(cid:2)M2

t

(cid:3) ≤

≤

T
(cid:88)

1
T

t=1
12M
T

(m + T )1/3.

E(cid:2) 3L2

f

ρ2 (cid:107)y∗(xt) − yt(cid:107)2 +

3
ρ2 (cid:107)∇xf (xt, yt) − vt(cid:107)2 +

3

γ2 (cid:107)˜xt+1 − xt(cid:107)2(cid:3)

According to the above inequalities (105) and (106), we have

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T

T
(cid:88)

t=1

E(cid:107)At(cid:107)2 2

√
3M
T 1/2 (m + T )1/6.

Let M (cid:48) = ρ2M = ρ(F (x1)−F ∗)

T γk

+

9L2
f b1
kλµ ∆2

k2qµ2 + 2k2(c2

1+c2
qµ2

2)σ2

ln(m + T ), we have

1 + 2σ2m1/3
(cid:113) 1
T

(cid:80)T

1
T

T
(cid:88)

t=1

E(cid:107)∇F (xt)(cid:107) ≤

E(cid:107)At(cid:107)2

(cid:18) 2

√

3M (cid:48)m1/6
T 1/2

√

2

3M (cid:48)

T 1/3

(cid:19)

.

+

t=1
ρ

(106)

(107)

(108)

Corollary 2. (Restatement of Corollary 1) Under the same conditions of Theorems 3 and 4, given mini-
batch size q = O(κν ) for ν > 0 and 27µbq
81Lf µ , our VR-AdaGDA algorithm has a
lower gradient complexity of ˜O(cid:0)κ(4.5− ν

, i.e., q = κν ≤ 16
32 ≤ b
6Lf
2 )(cid:15)−3(cid:1) for ﬁnding an (cid:15)-stationary point.

κ

√

√

Lf

=

√

√

ρλµ

ρλµ

γ =

≤ m1/3ρ

q
32λ2+150qκ2ˆb2

q
32λ2+150qκ2ˆb2

q
32λ2+150qκ2ˆb2
ρλ
√

2Lk , we have m ≥ (cid:0)k3, (c1k)3, (c2k)3,
and λ = min (cid:0) 27µbq
32 ,

Proof. Under the same conditions of Theorems 3 and 4, without loss of generality, let k = O(1), b = O(1),
(cid:1). Let
ˆb = O(1) and
√

8(Lkλµ)3q3/2
Lf (32λ2+150qκ2ˆb2)3/2

Lf
Given q = O(κν ) for ν > 0 and 27µbq
κ3 ), c1 = O(1) and c2 = O(L2

b
6Lf
, i.e., κν ≤ 16
81Lf µ , it is easily veriﬁed that λ = O(qµ),
f ).
q ) = O(κ(3−ν)). Thus, our VR-AdaGDA algorithm
(cid:3) ≤ (cid:15) or E(cid:107)∇F (xζ)(cid:107) ≤ (cid:15), we choose
T 1/3 ≤ (cid:15), i.e., E(cid:2)Mζ
2 )(cid:15)−3. Thus, our VR-AdaGDA algorithm reaches a lower gradient complexity of 4q · T =
(cid:15)−3(cid:1) for ﬁnding an (cid:15)-stationary point.

γ = O( q
Then we have M = O( κ3
q + κ2
has a convergence rate of O(cid:0) κ(3/2− ν
T ≥ κ(9/2− 3ν
(4.5− ν
O(cid:0)κ
y

32 ≤ b
6Lf
f ). Due to L = Lf (1 + κ) and q ≤ 16

q ln(m + T )) = O( κ3
(cid:1). Let κ(3/2− ν

81Lf µ , we have m = O(L6

q + κ2

T 1/3

(cid:1).

2 )

2

2

)

)

31

