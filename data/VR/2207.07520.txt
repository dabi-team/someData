Short-Term Trajectory Prediction for Full-Immersive
Multiuser Virtual Reality with Redirected Walking

Filip Lemic∗†, Jakob Struye†, Jeroen Famaey†
∗NaNoNetworking Center in Catalunya (N3Cat), Polytechnic University of Catalonia, Spain
†Internet Technology and Data Science Lab (IDLab), Universiteit Antwerpen - imec, Belgium
Email: {ﬁlip.lemic, jakob.struye, jeroen.famaey}@uantwerpen.be

2
2
0
2

l
u
J

5
1

]
I

N
.
s
c
[

1
v
0
2
5
7
0
.
7
0
2
2
:
v
i
X
r
a

Abstract—Full-immersive multiuser Virtual Reality (VR) en-
visions supporting unconstrained mobility of the users in the
virtual worlds, while at the same time constraining their physical
movements inside VR setups through redirected walking. For
enabling delivery of high data rate video content in real-time,
the supporting wireless networks will leverage highly directional
communication links that will “track” the users for maintaining
the Line-of-Sight (LoS) connectivity. Recurrent Neural Networks
(RNNs) and in particular Long Short-Term Memory (LSTM)
networks have historically presented themselves as a suitable
candidate for near-term movement trajectory prediction for
natural human mobility, and have also recently been shown as
applicable in predicting VR users’ mobility under the constraints
of redirected walking. In this work, we extend these initial
ﬁndings by showing that Gated Recurrent Unit (GRU) networks,
another candidate from the RNN family, generally outperform
the traditionally utilized LSTMs. Second, we show that context
from a virtual world can enhance the accuracy of the prediction
if used as an additional input feature in comparison to the more
traditional utilization of solely the historical physical movements
of the VR users. Finally, we show that the prediction system
trained on a static number of coexisting VR users be scaled to
a multi-user system without signiﬁcant accuracy degradation.

I. INTRODUCTION
Virtual Reality (VR) continues to revolutionize our digital
perceptions and interactions [1]. It also promises novel ap-
plications with utility in healthcare, tourism, education, enter-
tainment, and occupational safety [2], [3], to name a few. VR
setups and contents are being rapidly improved, with primary
efforts targeting the enhancements in the immersiveness of
VR experiences. Toward this end,
the research is mainly
focused on enhancing the quality of video content that is being
presented to the VR users [4], as well as on “cutting the wire”
and enabling truly wireless delivery of the video content [5],
[6]. An additional important objective is to enable multiuser
experiences, in which the users are able to collaborate in a way
that the action of one user in the virtual world is delivered as
a virtual content to other, potentially collocated users [7], and
consequently affects their virtual experiences.

In the near future, VR systems will support multiple fully
immersed and coexisting VR users with constraint-free mo-
bility in the virtual worlds. Such setups will be supported
through high frequency wireless communication networks
primary operating in the millimeter Wave (mmWave) (i.e., 30-
300 GHz) frequency band [8]. For supporting the delivery of
high-quality video content to the mobile VR users in real-
time, the underlying wireless communication will have to be

highly directional on both transmit and receive sides [9]. These
directional mmWave beams are simultaneously expected to
“track” the users’ movements for continuously maintaining
Line-of-Sight (LoS) connectivity for maximizing the quality
of video delivery. At the same time, redirected walking is
envisioned to be utilized for avoiding collisions between the
collocated users, and between the users and the boundaries of
the constrained VR environments [7]. This will enable immer-
sion of the VR users in the virtual worlds by allowing them to
roam freely, while simultaneously and ideally imperceivably
redirecting them in the physical setups for collision avoidance.
For supporting continuous LoS maintenance with each of
the VR users, the directional mmWave beams will have to
be transmitted in such a way that they also provide coverage
with high-quality wireless signals at near-future locations of
the VR users. This in turn motivates the need for VR users’
short-term movement trajectory prediction in full-immersive
multiuser VR setups. Short-term movement trajectory predic-
tion for a natural human walk is a well-established topic in
the research community, which yielded RNNs in general and
LSTM networks as their particular RNN instance suitable for
this task (e.g., [10], [11]). However, it is intuitive that neither
imperceivable nor perceivable re-steers of the VR users resem-
ble a natural human walk, suggesting the need for evaluating
the suitability of RNNs for predicting VR users’ mobility
under the constraints stemming from redirecting walking. This
topic has received substantially less attention in the research
community. Nonetheless, an early work from Nescher and
Kunz [12] has shown that such precision is possible with
reasonable accuracy, while [13], [14] demonstrated that RNNs,
speciﬁcally LSTMs, can be utilized for this purpose as they
feature encouraging prediction accuracy. All three approaches
base the prediction of the near-future trajectories on the
historical movement trajectories of the VR users.

In this work, we extend these initial ﬁndings along several
dimensions. First, we consider GRUs in addition to LSTMs for
the near-future movement trajectory prediction. We consider
GRUs due to their faster training and execution in comparison
to LSTMs, which would conceptually make them a more suit-
able candidate for such prediction in case they feature compa-
rable prediction accuracies. Second, we consider information
from the virtual world (i.e., the VR users’ movement trajectory
in the virtual world) as an additional input feature for the two
considered approaches, which is in contrast to the existing

 
 
 
 
 
 
works from the literature that base the prediction solely on
historical movement trajectories in a physical space. Finally,
we evaluate the effects of a varying number of coexisting VR
users (e.g., the users dynamically entering and terminating
immersive experiences) on the prediction performance of the
considered approaches trained with the data from only a two-
user system.

Our results demonstrate that GRU outperforms LSTM not
only in terms of the execution times, but also in the prediction
accuracy, suggesting their utility in the considered scenario.
Moreover, we show that the information from the virtual ex-
perience, in our case the virtual movement trajectory, provides
additional useful context and, therefore, improves the accuracy
of prediction for both LSTM and GRU-based approaches.
Finally, our results show that a predictor trained on data from
two-user systems only can be scaled to a multi-user system
without signiﬁcant accuracy degradation, which has a potential
for enabling dynamic immersion in and termination of virtual
experiences in multiuser full-immersive VR setups.

II. SYSTEM OVERVIEW

A. Considered Scenario

We consider a full-immersive multiuser VR scenario as
depicted in Figure 1. Speciﬁcally, we consider a constrained
physical environment in which the full-immersive VR setup
is deployed. The environment is constrained in terms of its
physical sizes in order to create a boundary inside of which
it is safe to engage in virtual experiences. As such, it is
assumed that there are no obstacles inside the deployment
environment, which would represent a tripping hazard if not
properly accounted for. In other words, the only factors to be
considered as potential collision perils from the perspective of
a VR user are the environmental boundaries and other users,
as depicted in the ﬁgure.

In the scenario, multiple VR users can be collocated in the
same deployment environment. The VR content is streamed to
the users using highly directional mmWave communication.
Speciﬁcally, highly directional beams are transmitted by an
Access Point (AP) in such a way that they follow the move-
ments of the VR users. This is done in order to continuously
maintain LoS connectivity with each of the users, resulting in
a maximized link quality and consequently enhancing the VR
users’ Quality of Experience (QoE) [15]. To do so, we envision
the VR users’ Head-Mounted Devices (HMDs) reporting their
physical locations to the AP, which is then utilized for support-
ing both redirected walking and beamsteering. The assumption
of the availability of physical locations of the VR users is
well-established in the existing literature (e.g., [9]) and the
contemporary VR headsets such as Oculus Quest 2 and Vive
Cosmos already support its generation and provisioning. It is
also worth emphasizing that these VR headsets are able to
support the generation and provisioning of VR users’ location
information without the support of external devices such as
cameras or localization anchors.

In terms of transmitter-side beamsteering, the AP is envi-
sioned to utilize the current and near future locations of a

Figure 1: Considered scenario

VR user for forming a beam in a way that it covers both
current and near future locations of the user, enabling LoS
maintenance during a current time instance, as well as in the
near future instances. Simultaneously, redirected walking is
utilized for steering of the VR users in a way that guarantees
collision avoidance between the collocated users, as well as
between the users and the environmental boundaries. The aim
of redirected walking is to enable immersion of the VR users
(i.e., allowing them to roam freely in potentially unconstrained
virtual worlds), while simultaneously and (ideally) imperceiv-
ably redirecting them in the physical space.

Note that on the receiver side, beamforming is envisioned
to adapt in real-time to the VR user’s head rotations, relying
on the HMD’s built-in sensors providing accurate orientation
estimates. The receiver-side beamforming and beamsteering is
considered as out of scope of this work. Interested readers
can ﬁnd more details on this aspect of the system in [6],
where we present coVRage, a receiver beamforming solution
in which, based on past and current head orientations, the
HMD predicts how the Angle of Arrival (AoA) from the AP
will change in the near future, and covers this AoA trajectory
with a dynamically shaped beam.

Note that we consider as out of scope the potential interrup-
tions of the LoS connectivity between the AP and the users
due to the obstructions caused by the other users. An intuitive
solution to the issue can be based on an AP handover if it is
predicted that one user will block the LoS path of another one,
again motivating the need for short-term prediction of the VR
users’ movements. Alternative solutions based on Intelligent
Reﬂective Surfacess (IRSs) have also been presented [9].

B. Short-Term Trajectory Prediction

Based on the above discussion, short-term prediction of the
VR users’ movement trajectory is envisioned to be utilized for
both redirected walking and transmitter-side beam steering,
while also being potentially beneﬁcial for LoS obstruction
avoidance. It is intuitive that the accuracy of such prediction
will affect the performance of other parts of the envisioned
system, suggesting that the optimization of this accuracy will
be beneﬁcial from the perspective of the VR’s QoE.

As mentioned before, RNNs are arguably the most suitable
technological candidates for predicting the trajectory of human
movements, even in redirected walking scenarios. An RNN is
a class of artiﬁcial neural networks which contains multiple
neurons of the same type, each passing a message to a

(a) RNN structure

(b) LSTM neuron

(c) GRU neuron

(d) Legend

Figure 2: Considered types of recurrent neural networks

succeeding neuron, as depicted in Figure 2(a). This allows the
RNNs to exhibit temporally dynamic behavior, making them
suitable for tasks such as handwriting or speech recognition
and time-series prediction [16]. In this work, we consider two
of the most promising types of RNNs for such prediction,
namely LSTM and GRU. Single neurons of both types of
networks are depicted in Figure 2, together with the indications
of their main building blocks.

In LSTM, a sigmoid layer called the forget gate is utilized
for deciding on the retainment of the previous cell state.
Moreover, a sigmoid layer called the input gate jointly with a
tanh layer are utilized for updating the cell state. The output
of the cell is then based on our cell state ﬁltered through
a sigmoid layer for deciding the part of the cell state to
be outputted, normalized through a tanh layer, as depicted
in Figure 2(b). GRU neuron is comparable with the one
from LSTM, with the main differences stemming from the
combined forget and input gates into a one called update gate
and merged cell and hidden states, as depicted in Figure 2(c).
The aforementioned related works targeting short-term tra-
jectory prediction for full-immersive VR with redirected walk-
ing generally utilize LSTMs, while here we also consider GRU
networks due to their faster learning and execution times.
Moreover, in the literature the near future trajectory predictions
are predominantly based on previous locations and histori-
cal movements patters of the users, taking their inspiration
from works targeting the prediction of walking trajectories
assuming natural human walk. However, in full-immersive VR
setups with redirected walking the VR users’ movement is
not natural, as they are continuously being re-steered by the
redirected walking for collision avoidance. To do so, redirected
walking will deliver VR content to the users in such a way
that the users are drawn toward physical locations where there
is no collision hazard, while has two important implications.
First, as the movement trajectories of VR users do not resem-
ble a natural walk, the approaches developed for predicting
near-future trajectories based on historical locations assuming
naturally walking users are unoptimized for full-immersive
VR with redirected walking. Second, the redirections that are
envisioned to occur in the virtual world in the near future to
avoid collisions are the deﬁning feature of the mobility of VR
users in the physical setups.

Our intuition is that the redirected walking-related inputs
from the virtual worlds are a valuable source of information

Figure 3: Input features of the considered RNN approaches

for optimizing the near-future movement trajectory prediction
for full-immersive VR users. To model such information, we
deﬁne a notion of a virtual location of the VR user, i.e., its
location in the virtual space. We then utilize the stream of
historical virtual locations of the VR users as an input feature
to the LSTM and GRU networks, in addition to the stream
of their historical physical locations. Based on the type of
utilized input information, we distinguish the “baseline” (i.e.,
LSTM/GRU-B) and “virtual” (i.e., LSTM/GRU-V) versions of
the utilized RNN approaches. The former is inspired by the
existing literature, while the latter additionally accounts for the
speciﬁcities of the VR users’ mobility by utilizing the users’
virtual coordinates. Also note that, given that the decisions
stemming from redirected walking, and consequently also the
virtual coordinates of the users, are assumed to be known one
step ahead in time compared to the physical coordinates of the
users, as shown in Figure 3. We consider this to be a natural
assumption, given that the virtual coordinates for the next time
instance are in redirected walking derived using the physical
coordinates from a current time instance.

III. EVALUATION

A. Evaluation Setup

To simulate the users’ mobility in multiuser VR setups with
redirected walking, we utilize the simulator from [17]. The
core idea of the simulator is to provide a mapping between
design decisions about the users’ mobility in the virtual words,
and their effects on the physical mobility in constrained VR
environments. Speciﬁcally, given a set of VR users with
their virtual movement trajectories, the outline of the physical
environment, and a redirected walking algorithm for avoiding
physical collisions, the simulator is able to derive the physical
movements of the users, as indicated in Figure 4. Based on the
derived physical movements, the simulator is able to output

Figure 4: Simulator overview [17]

a set of performance metrics characterizing the number of
perceivable resets and the distances between such resets for
each user. We have extended the simulator to support VR
users’ near future movement trajectory predictions and have
implemented the four considered prediction approaches (i.e.,
LSTM-B, LSTM-V, GRU-B, GRU-V). As the performance
metric for characterizing the accuracy of prediction, we have
deﬁned the Squared Error (SE) between the predicted and true
near future physical locations of the VR users.

The deployment environment is deﬁned as a square with
size of 7.5 m. In the training of the considered approaches,
we assume two VR users coexist in the environment, fully
immersed in a VR experience. A redirected walking algo-
rithm is then utilized to map the users’ movements in the
virtual world to the corresponding movements in the physical
deployment environment. We utilize the redirected walking al-
gorithms from Bachmann et al. [7]. Speciﬁcally, the Artiﬁcial
Potential Field Redirected Walking (APF-RDW) algorithm for
imperceivable redirected walking in multiuser full-immersive
VR applications, and the Artiﬁcial Potential Field Reseting
(APF-R) algorithm to re-orient the VR user towards the safest
available area in case there is a need for perceivable resets to
avoid collisions with other users or environmental boundaries.
Example virtual and physical mobility patterns of the users
are also depicted in Figure 4, while the other simulator
parameters are summarized in Table I. The full implementation
of the simulator is available as an open source tool, while
the reproducibility of the results delivered in the following
sections is enabled through open data access1.

B. Hyperparameter Tuning

In this step of the evaluation, our goal is to determine which
hyperparameters have a considerable effect on the performance
of the considered RNN approaches. We do that with the aim
of reducing the hyperparameters’ optimization space, i.e., the
hyperparameter tuning would be needed only for inﬂuential
hyperparameters. We deﬁne inﬂuential hyperparameters as the
ones whose change affects the average prediction error by

1Both available at: https://bitbucket.org/ﬁlip lemic/pm4vr/src/master/

TABLE I: Simulation parameters

Parameter
Number of points per trajectory
Duration of simulation

Redirected walking
Exponential falloff due to other users
Arc radius or redirected walking
Maximum rotational rate
Velocity threshold

Value
10 [points/sec]
3600 [sec]

1.4
7.5 [m]
15 [°]
0.1 [m/s]

TABLE II: Hyperparameter values used in RNNs’ training

Parameter
Activation
Optimizer
# neurons
# batch/epochs

Initial
softplus
sgd
20
20/10

LSTM-B
relu
nadam
80
20/40

LSTM-V GRU-B GRU-V
softmax
softsign
nadam
nadam
80
40
80/30
80/30

relu
adam
80
60/50

more than 10%, speciﬁcally the activation function, optimizer,
number of neurons in the hidden LSTM/GRU layer, and num-
ber of batches and epochs. For the inﬂuential hyperparameters,
our consequent goal is to determine the hyperparameteriza-
tions that yield optimal performance for a given approach
for the near-future movement trajectory prediction in full-
immersive multiuser VR setups with redirected walking. In our
optimization approach, we tune the inﬂuential hyperparameters
individually, while keeping the ones not already tuned at their
initial values (cf., Table II). Hence, we are able to derive
a set of locally optimal hyperparameters for each of the
considered approaches, as shown in the table. We follow this
procedure, in contrast to performing an extensive multihyper-
parameter search (which would result in a globally optimal
hyperparameters) because of an extremely high computational
complexity and time overhead of the alternative. A selected set
of hyperparameter tuning results is depicted in Figure 5 for
the LSTM-B and GRU-B approaches, while the other hyper-
parameters and considered approaches (i.e., LSTM-V, GRU-
V) are left out for brevity. Note that in the ﬁgure we depict
only the hyperparameter values with “reasonable” prediction
accuracies, while the ones with comparatively larger prediction
errors are left out for clarity. The hyperparameter value that
maximizes the prediction accuracy is then considered as the
optimal one. For example, the optimal activation functions of
the LSTM-B and GRU-B approaches are respectively relu and

(a) LSTM activation

(b) GRU activation

(c) LSTM optimizer

(d) GRU optimizer

(e) Number of LSTM neurons

(f) Number of GRU neurons

Figure 5: Selected hyperparameter tuning results for the considered RNNs

softsign, as they yielded the smallest SE of the prediction, as
shown in the ﬁgure. The resulting set of hyperparameters for
the four considered approaches is given in Table II.

C. Evaluation Results

We present the performance results achieved by the four
considered prediction approaches, with their hyperparameters
optimized following the above-discussed procedure. Figures 6
and 7 depict the SEs observed by different versions of the
LSTM and GRU-based prediction approaches, respectively.
For each approach, we depict the baseline performance (i.e.,
GRU/LSTM-B), as well as the performance of their virtual
counterparts (i.e., LSTM/GRU-V), both with locally-optimal
hyperparameters. Moreover, we also depict two intermedi-
ary approaches. In LSTM/GRU-I1, the hyperparameters of
a predictor have not been changed in comparison to the
baseline approach to isolate solely the effect of utilizing virtual
trajectory as a feature for prediction. In LSTM/GRU-I2, only
the number of neurons in the hidden layer and the number
of epochs have been doubled in comparison to the baseline
approach. This has been done with an intuition of better

handling the complexity of utilizing virtual coordinates as an
additional input feature compared to LSTM/GRU-I1.

As visible in the ﬁgure,

for both LSTM- and GRU-
based approaches, the versions utilizing the virtual coordinates
generally outperform the baselines based on utilizing solely
historical knowledge about the physical movement trajectories
of the VR users. Additionally,
there are also beneﬁts of
hyperparameter tuning when utilizing virtual coordinates as
an additional input feature. For example, the average per-user
SE of the prediction is deceased from roughly 0.0003 m2 in
LSTM-B to less than 0.0001 m2 in LSTM-V, representing
a threefold increase in the prediction accuracy. Moreover,
a roughly ﬁvefold improvement is observed for the GRU-
based prediction when utilizing virtual coordinates of the
VR users in comparison to the more traditional baseline. We
argue that these results demonstrate that certain contextual
information from the virtual world, in this case the virtual
coordinates of the VR users, can be utilized for improving the
performance of the RNN-based near-term movement trajectory
prediction approaches in the physical VR setups. We believe
that this conclusion can be generalized and the fact that we

are comparable, as shown in the ﬁgure. This is an expected
behaviour as the prediction approaches are in this case neither
trained nor involved in the prediction, but it nonetheless makes
an argument about the correctness of the implementation.

In case the short-term trajectory prediction is enabled, one
can ﬁrst observe that the GRU-based approaches generally
features lower simulation times than the LSTM-based alter-
natives. This is a well-known behaviour demonstrating one of
the primarily beneﬁts of GRU over LSTMs, namely their faster
execution and training. Finally and perhaps counterintuitively,
the “virtual” version of the LSTM-based approach features
higher simulation time than its ’baseline’ counterpart, while
that is not the case for GRU-ﬂavored prediction methods. We
argue this discrepancy comes from the fact that an increase in
the number of input features of the “virtual” version of both
approaches is not the primary factor in their execution times,
despite the fact that it is certainly to an extent contributive
to the increase in the execution times. On the contrary, we
argue that the execution times are to a greater extent affected
by the hyperparameterization of the approaches, with the
most signiﬁcant contributions stemming from the selected
number of batches, epochs, and neurons. In case of LSTM, the
comparatively higher number of sample per batch in LSTM-V
allows for greater parallelization of the training process, which
arguably has a larger effect on the execution time than the
combined effect of a slight increase in the number of training
epochs and the increase in the input feature dimensionality
compared to LSTM-B, hence the execution time of LSTM-V
is lower than for LSTM-B. In case of GRU, an increase in
the number of neurons in the hidden GRU layer and in the
dimensionality of the input features jointly affect the increase
in the execution time of GRU-V compared to GRU-B. In
conclusion, we argue the increase in the dimensionality of the
input features when considering virtual coordinates has only
a slight negative effect on the training and execution times of
the considered approaches, while a more substantial affect can
be expected from hyperparameter tuning.

Finally, the extended simulator enables straightforward eval-
uation of the performance of redirected walking and short-
term trajectory prediction for a varying number of coexisting
VR users. We utilize this feature to evaluate if the considered
approaches can, once optimally trained for a two-user system,
be used for such prediction for a varying number of coexisting
users. Figure 9 depicts the output of the simulator (i.e., a set
of performance metrics) for the two optimally-parameterized
prediction approaches for different numbers of coexisting VR
users. The graphs in the ﬁrst row depict
the number of
perceivable resets experienced by each VR user for a varying
number of the VR users. Similarly, the graphs in the second
row depict the distances the users are able to traverse between
two consecutive perceivable resets. As visible from the ﬁgure,
the numbers of perceivable resets and the distances between
them are highly comparable for the two utilized approaches.
This is an expected behaviour as the same redirected walking
approach, which has an affect on the number of perceivable
rests and their respective distances, has been utilized for both

Figure 6: SEs achieved by different versions of the LSTM approach

Figure 7: SEs achieved by different versions of the GRU approach

Figure 8: Training time of different approaches

have demonstrated the beneﬁts for two types of prediction
approaches makes an argument for supporting this intuition.
The training duration of the four considered approaches
is depicted in Figure 8. Note that the execution times have
been captured using the simulator running on a contempo-
rary MacBook Air laptop and as such their absolute values
are indicative solely to that platform. Nonetheless, several
interesting trends can be observed. The ﬁgure depicts the
execution times of different approaches in cases when the
short-term trajectory prediction is enabled and vice-versa.
Intuitively, where the trajectory prediction is not enabled, the
simulation times of both “baseline” and “virtual”approaches

(a) LSTM-V

(b) GRU-V

Figure 9: Multiuser performance results for LSTM-V and GRU-V

shot-term trajectory prediction approaches. Moreover and as
visible in the ﬁgure, the number of such resets increases (and,
therefore, the corresponding distances between consecutive
resets decrease) with an increase in the number of users,
which is again an expected behaviour as reported in [17]. We
depict these two metrics solely to demonstrate that there are
signiﬁcant differences in the performance of the prediction
system as a function of a varying number of VR users.

The above suggests that datasets used for training of short-
term trajectory prediction are not comparable for a varying
number of users. Nonetheless, the prediction performance for
both of the utilized approaches is highly comparable across
a varying number of coexisting VR users, as indicated int he
bottom graphs of the ﬁgure depicting the SEs of predictions.
This suggests that both systems could, without signiﬁcant
prediction performance degradation, be used in scenarios in
which the users dynamically immerse in or terminate shared
VR experiences. In addition, one can observe that the GRU-
V approach generally outperforms LSTM-V, with average
reduction in the observed SEs of around 50%, suggesting their
utility for the movement trajectory prediction in full-immersive
multiuser VR setups with redirected walking.

IV. CONCLUSION

We have shown that Long Short-Term Memory (LSTM)
and Gated Recurrent Unit (GRU)-based Recurrent Neural
Networks (RNNs) are promising candidates for the near-future
movement trajectory prediction in multiuser full-immersive
Virtual Reality (VR) with redirected walking. We have also
demonstrated the beneﬁts of utilizing virtual context such as
the movement trajectory in the virtual world as an input feature
for such prediction, as well as shown that that the prediction
system, once trained on assuming on a static number of users,
can maintain the prediction accuracy once the number of users
in the system changes, without the need for re-training. The
main direction of our ongoing and future work is and will
be focused on experimentally conﬁrming our insights with
realistic traces.

ACKNOWLEDGMENTS
Filip Lemic was supported by the EU H2020 Marie
Skłodowska-Curie project ”Scalable Localization-enabled In-
body Terahertz Nanonetwork” (nr. 893760).

REFERENCES

[1]

[2]

[3]

L. Mu˜noz-Saavedra et al., “Augmented and virtual reality evolution
and future tendency,” Applied sciences, vol. 10, no. 1, p. 322, 2020.
L. Jensen and F. Konradsen, “A review of the use of virtual reality
head-mounted displays in education and training,” Education and
Information Technologies, vol. 23, no. 4, pp. 1515–1529, 2018.
S. G. Izard et al., “Virtual reality as an educational and training tool
for medicine,” J. of medical systems, vol. 42, no. 3, pp. 1–5, 2018.

[6]

[4] H. Zhang et al., “Wireless access to ultimate virtual reality 360-degree
video,” in IoT Design and Implementation, 2019, pp. 271–272.
[5] M. Chen et al., “Virtual reality over wireless networks: Quality-of-
service model and learning-based resource management,” IEEE Tran.
on Communications, vol. 66, no. 11, pp. 5621–5635, 2018.
J. Struye et al., “Millimeter-wave beamforming with continuous
reality,” arXiv preprint,
coverage for mobile interactive virtual
arXiv:2105.11793, 2021.
E. R. Bachmann et al., “Multi-user redirected walking and resetting
using artiﬁcial potential ﬁelds,” IEEE transactions on visualization
and computer graphics, vol. 25, no. 5, pp. 2022–2031, 2019.
[8] M. S. Elbamby et al., “Toward low-latency and ultra-reliable virtual

[7]

reality,” IEEE Network, vol. 32, no. 2, pp. 78–84, 2018.

[9] X. Liu et al., “Learning-based prediction, rendering and transmission
for interactive virtual reality in ris-assisted terahertz networks,” IEEE
Journal on Selected Areas in Communications, 2021.

[11]

[10] X. Song et al., “Pedestrian trajectory prediction based on deep
convolutional lstm network,” IEEE Transactions on Intelligent Trans-
portation Systems, vol. 22, no. 6, pp. 3285–3302, 2020.
F. Bartoli et al., “Context-aware trajectory prediction,” in Pattern
Recognition (ICPR), IEEE, 2018, pp. 1941–1946.
T. Nescher and A. Kunz, “Analysis of short term path prediction of
human locomotion for augmented and virtual reality applications,” in
International C. on Cyberworlds, IEEE, 2012, pp. 15–22.

[12]

[13] X. Hou et al., “Head and body motion prediction to enable mobile
vr experiences with low latency,” in IEEE Global Communications
(GLOBECOM), IEEE, 2019, pp. 1–7.

[14] Y.-H. Cho et al., “Path prediction using lstm network for redirected
walking,” in Virtual Reality and 3D UIs, IEEE, 2018, pp. 527–528.
J. Struye et al., “Towards ultra-low-latency mmwave wi-ﬁ for multi-
user interactive virtual reality,” in 2020 IEEE Global Communications
Conference (GLOBECOM), IEEE, 2020, pp. 1–6.

[15]

[16] Y. Yu et al., “A review of rnns: Lstm cells and network architectures,”

[17]

Neural computation, vol. 31, no. 7, pp. 1235–1270, 2019.
F. Lemic et al., “User mobility simulator for full-immersive multiuser
virtual reality with redirected walking,” in ACM Multimedia Systems
Conference, 2021, pp. 293–299.

