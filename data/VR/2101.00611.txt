Duration-Squeezing-Aware Communication and
Computing for Proactive VR

Xing Wei, Chenyang Yang, and Shengqian Han
School of Electronics and Information Engineering, Beihang University, Beijing 100191, China
Email: {weixing, cyyang, sqhan}@buaa.edu.cn

1
2
0
2

n
a
J

3

]

M
M

.
s
c
[

1
v
1
1
6
0
0
.
1
0
1
2
:
v
i
X
r
a

Abstract—Proactive tile-based virtual reality video streaming
computes and delivers the predicted tiles to be requested before
playback. All existing works overlook the important fact that
computing and communication (CC) tasks for a segment may
squeeze the time for the tasks for the next segment, which
will cause less and less available time for the latter segments.
In this paper, we jointly optimize the durations for CC tasks
to maximize the completion rate of CC tasks under the task
duration-squeezing-aware constraint. To ensure the latter seg-
ments remain enough time for the tasks, the CC tasks for a
segment are not allowed to squeeze the time for computing
and delivering the subsequent segment. We ﬁnd the closed-
form optimal solution, from which we ﬁnd a minimum-resource-
limited, an unconditional and a conditional resource-tradeoff
regions, which are determined by the total time for proactive
CC tasks and the playback duration of a segment. Owing to
the duration-squeezing-prohibited constraints, the increase of the
conﬁgured resources may not be always useful for improving
the completion rate of CC tasks. Numerical results validate
the impact of the duration-squeezing-prohibited constraints and
illustrate the three regions.

Index Terms—Proactive VR video streaming, computing com-
munication tradeoff, resource conﬁguration, duration-squeezing-
aware constraint

I. INTRODUCTION
Virtual reality (VR) video requires 360◦× 180◦ panoramic
view with ultra high resolution. Delivering such videos is cost-
prohibitive for wireless networks. This inspires proactive tile-
based streaming [1], [2], which divides a full panoramic view
segment into small tiles in spatial domain, predicts the future
ﬁeld of view (FoV) of a user, and then renders and transmits
the tiles overlapped with the predicted FoVs.

Proactive tile-based VR video streaming contains three
tasks: prediction, communication, and computing. Given the
predictor and the prediction accuracy required for satisfying
the quality of experience (QoE), the total time for rendering
and transmitting a segment can be determined [3]–[5]. With
such a total time budget, it has been shown in the literature
that the communication and computing (CC) resources can be
ﬂexibly traded off [6], [7]. For example, when the communica-
tion bandwidth is insufﬁcient, one can assign more computing
resource for rendering in order to provide longer time for
delivering.

However, all existing works [3], [8]–[11] for proactive tile-
based VR video streaming overlook an important fact: the
communication and computing tasks for successive segments
are coupled in timeline. Speciﬁcally, the communication task
for multiple segments in a video forms a queue, and the com-

puting task forms another queue. Transmitting and computing
a segment may squeeze the time for tasks for the next segment,
such that the QoE may degrade owing to the insufﬁcient time
left for accomplishing the tasks for latter segments.

In this paper, we investigate how to maximize the perfor-
mance of proactive tile-based VR video streaming considering
the coupled timeline for computing and delivering successive
segments. To this end, we jointly optimize the durations
for these two tasks to maximize the completion rate of CC
tasks under the duration-squeezing-aware constraint. When
the length of a VR video is long, to ensure that the latter
segments remain enough time for the tasks, the CC tasks for
a segment are not allowed to squeeze the time for computing
and delivering the subsequent segment. We obtain the global
optimal solution via Karush-Kuhn-Tucker (KKT) conditions.
As far as the authors know, this is the ﬁrst work that considers
the time squeeze of these two tasks in proactive VR streaming.
From the closed-form solution of the optimal durations,
we ﬁnd a minimum-resource-limited, an unconditional and
a conditional resource-tradeoff regions. The boundary of the
three regions depends on the relative values of the total
time budget for communication and computing as well as
the playback duration of a segment. In practice, these two
durations can be very different, with the range of 0.2∼10
seconds [4], [5], [12] and the range of 0.5∼2 seconds [1],
[13], [14], respectively, where the total time for proactive
streaming highly depends on the predictor and the required
prediction accuracy. With different combinations of these two
durations, the system may lie in one of the three regions. In
the minimum-resource-limited region, the communication and
computing resources can not be traded off and the transmission
and computing rates should be identical. In the unconditional
resource-tradeoff region, the resources can be ﬂexibly traded
off and increasing arbitrary resource is useful for improving
the completion rate of CC tasks. In the conditional resource-
tradeoff region, an extra condition should be satisﬁed to
achieve the tradeoff and improving the completion rate of CC
tasks.

II. SYSTEM MODEL
Consider a proactive tile-based VR video streaming system
with a mobile edge computing (MEC) server co-located with
a base station (BS). Each VR video consists of L segments
in temporal domain, and each segment consists of M tiles in
spatial domain. The playback duration of each tile equals to
the playback duration of a segment, denoted by Tseg [1], [2].

 
 
 
 
 
 
Each user is equipped with a head-mounted display (HMD),
which can measure the head movement data, send the data to
the MEC server, and pre-buffer segments. The MEC server
renders a video segment before delivering to the HMD.

(a) Rendering and transmitting pipeline squeeze, ∆p >
0, ∆m > 0

(b) Transmitting pipeline squeeze, ∆p < 0, ∆m > 0
Fig. 1: Proactively streaming the lth and (l+1)th segments.

When a user requests a VR video, the MEC server ﬁrst
streams the ﬁrst l − 1 segments in a reactive or a passive
mode [15]. When the MEC server collects the information
of the user (e.g., the head movement data) in an observation
window, proactive streaming for the lth segment begins, then
subsequent segments are predicted, rendered, and transmitted
one after another, as shown in Fig. 1a. Speciﬁcally, at the end
of the observation window for the lth segment, i.e, Bl, the tiles
in the lth segment to be requested are ﬁrst predicted, then the
predicted tiles are rendered with duration tcpt, and ﬁnally the
rendered tiles are transmitted with duration tcom, which should
be ﬁnished before the start time for playback for the segment,
i.e., El. Therefore, the total computing and transmission time
for the segment Tcc = El − Bl.

To train a predictor for the whole video, Tcc for every
segment needs to be identical. A predictor can be more
accurate with a smaller value of Tcc. This is because the tiles to
be predicted are closer to and hence are more correlated with
the head movement sequence in the observation window [3].
Given a predictor and required viewport prediction accuracy,
the value of Tcc can be determined [3]–[5].

A. Duration-Squeezing-Aware Constraint

With identical value of Tcc for every segment, we can
observe that El+1 − El = Bl+1 − Bl. Without playback
stalling, El+1 − El = Tseg holds and thus Bl+1 − Bl = Tseg.
If the rendering for the lth segment ﬁnishes after Bl+1, then
the computing task will squeeze the time for rendering the

(l+1)th segment. Denote the squeezed computing time as
∆p = tcpt − (Bl+1 − Bl) = tcpt − Tseg. If the rendering
for the lth segment can be ﬁnished within Tseg, then ∆p ≤ 0,
and there is no squeeze in rendering, as shown in Fig. 1b.

Similarly, the communication task may also squeeze the
time for delivering the (l+1)th segment. Denote the squeezed
communication time as ∆m. When ∆p > 0, ∆m = tcom −
tcpt, as shown in Fig. 1a. When ∆p < 0, ∆m = tcom −
tcpt − (−∆p), as shown in Fig. 1b. By summarizing the
two cases, we obtain ∆m = tcom − tcpt − (−∆p)+, where
(x)+ (cid:44) max{x, 0}. When ∆m ≤ 0, the transmission can be
ﬁnished on time and there is no squeeze in the pipeline.

For the lth segment, which is the ﬁrst segment with proac-
tive streaming, the transmission and rendering tasks should
be ﬁnished within Tcc,
i.e., tcpt + tcom ≤ Tcc. For the
(l+1)th segment,
the remaining duration for CC tasks is
tcpt + tcom ≤ Tcc − ((∆p)+ + (∆m)+). For the Lth segment,
the remaining duration for CC tasks is

tcpt + tcom ≤ Tcc − (L − l) (cid:8)(∆p)+ + (∆m)+(cid:9) .

(1)

B. Computing and Transmission Model

The computing resource of MEC for rendering a VR video
can be assigned by allocating graphics processing unit (GPU)
and compute uniﬁed device architecture cores [3], [16]. To
gain useful insight, we assume that the computing resource,
denoted as Ctotal (in ﬂoating-point operations per second,
the
FLOPS),
number of bits that can be rendered per second, referred to
as the computing rate, for the kth user, is

is equally allocated among K users. Then,

Ccpt,k (cid:44) Ctotal
K · µr
where µr is the required ﬂoating-point operations (FLOPs) for
rendering one bit of FoV in FLOP/bit [3].

(in bit/s),

The BS serves K single-antenna users using zero-forcing
beamforming over bandwidth B with Nt antennas. The in-
stantaneous data rate at the ith time slot for the kth user is
(cid:32)

(cid:33)

C i

com,k = B log2

1 +

k |˜hi
pkd−α
σ2

k|2

,

(cid:44) (hi

k)H wi

where ˜hi
k is the equivalent channel gain, pk
k
and wi
k are respectively the transmit power and beamforming
k ∈ CNt are respectively the
vector for the kth user, dk and hi
distance and the small scale channel vector from the BS to the
kth user, α is the path-loss exponent, σ2 is the noise power,
and (·)H denotes conjugate transpose.

We consider indoor users as in the literature, where the
distances of users, dk, usually change slightly [2], [17], [18]
and hence are assumed ﬁxed. Due to the head movement
and the variation of the environment, small-scale channels
are time-varying, which are assumed as remaining constant in
each time slot with duration ∆T and changing independently
with identical distribution among time slots. With the proactive
transmission,
the predicted FoVs in a segment should be
transmitted with duration tcom. The number of bits transmitted

ObservationTransmitting VR videoplaybacktl+1Renderingl+1Head movement tracePredicted tilesllll+1comtlBlE1lB1lEcpttsegTccTccTpmcpttcomtTransmitting VR videoplaybacktl+1Renderingl+1llll+1comtlBlE1lB1lEcpttsegTccTccTmpcpttcomt(cid:80)Ns

i=1 C i

with tcom can be expressed as C com,ktcom, where C com,k (cid:44)
1
com,k∆T is the time average transmission rate, and
Ns
Ns is the number of time slots in tcom. Since future channels
are unknown when optimizing the durations, we use ensemble-
average rate Eh{C i
com,k} to approximate the time-average rate
C com,k, which is very accurate when Ns or Nt/K is large [3].
To ensure fairness among users in terms of QoE, the transmit
power is used to compensate for the path loss, i.e., pk = β
,
d−α
k
where β can be obtained from β((cid:80)K
) = P and P is
the maximal transmit power of the BS. Then, the ensemble-
average transmission rate for each user is equal.

1
d−α
k

k=1

Without loss of generality, we consider an arbitrary user for
analysis in the sequel. For notational simplicity, we use Ccom
to represent Eh{C i

com,k} and use Ccpt to represent Ccpt,k.
III. DURATION OPTIMIZATION FOR COMPUTING AND
COMMUNICATION
To reﬂect the system performance for rendering and deliver-
ing all the predicted FoVs in a segment, deﬁne the completion
rate of communication and computing (CC) tasks as

,

,

(cid:27)

(2)

Scc (cid:44) min

Ccpttcpt
Scpt

(cid:26) Ccomtcom
Scom
where Scom = sfov · rf · Tseg/γc and Scpt = sfov · rf · Tseg are
respectively the number of bits of all the predicted FoVs in
a segment for transmission [19] and for rendering, γc is the
video compression ratio, rf (in frames per second) is frame
rate, sfov (cid:44) γfovRwRhb is the number of bits in a FoV, γfov
is the ratio of FoV in a frame, Rw and Rh are respectively
the pixels in wide and high of a frame, and b is the number
of bits per pixel relevant to color depth [19]. By substituting
Scom and Scpt into (2), we obtain

Scc =

min{ ˜Ccomtcom, Ccpttcpt}
sfov · rf · Tseg

,

(3)

where ˜Ccom (cid:44) Ccomγc is the equivalent transmission rate.

If Scc > 100%, the system is capable of streaming more
bits beyond all the predicted FoVs. The extra capability can be
used to stream the tiles at the marginal region of the predicted
viewport [19], [20] to compensate for the prediction errors and
increase the overlap of the delivered tiles and the requested
tiles in a segment. If Scc = 0, the HMD cannot receive any
rendered FoV on time, which will cause playout stalls.

The durations for computing and delivering are optimized

to maximize the completion rate of CC tasks, i.e.,

P0 : max

Scc

(4a)

tcpt,tcom
s.t.

(4b)

∆p = tcpt − Tseg,
∆m = tcom − tcpt − (−∆p)+,
tcpt + tcom ≤ Tcc − (L − l) (cid:8)(∆p)+ + (∆m)+(cid:9) .
Problem P0 contains four cases, depends on whether or not
∆p and ∆m exceed zero. When the length of a VR video (i.e.,
L) is long, to ensure that every latter segment has time to be
rendered and delivered, i.e., the right-hand side of (4d) is larger
than zero, the values of ∆p and ∆m should be non-positive.

(4d)

(4c)

> Tseg,
> Tseg,
≤ Tseg,
(6a)

> Tseg,
> Tseg,
≤ Tseg,
(6b)

(6c)

That is to say, squeezing either transmission or rendering
time of the subsequent segment is strictly prohibited. When
∆p ≤ 0, we obtain tcpt ≤ Tseg from (4b). When ∆m ≤ 0,
by substituting (4b) into (4c), we obtain tcom ≤ Tseg. Then,
problem P0 degenerates into

P1 : max

tcpt,tcom
s.t.

Scc

tcpt + tcom ≤ Tcc,
tcpt ≤ Tseg,
tcom ≤ Tseg.

(5a)

(5b)

(5c)

(5d)

Problem P1 can be transformed into a convex problem. From
the KKT conditions, its optimal solution and the maximal
value of the objective function of P1 can be obtained as






t∗
cpt

t∗
com






(cid:104) ˜CcomTseg
Ccpt

∈

, Tmin

(cid:105)

,

= Tseg,
= ˜CcomTcc
˜Ccom+Ccpt

,

˜Ccom < Ccpt and T max
˜Ccom ≥ Ccpt and T max
c
T max
c

c

= Tseg,
(cid:104) CcptTseg
∈
˜Ccom
= CcptTcc

˜Ccom+Ccpt

, Tmin
,

(cid:105)

,

˜Ccom ≤ Ccpt and T max
˜Ccom > Ccpt and T max
c
T max
c

c






S∗

cc =

T max
c
T max
c

min{ ˜Ccom,Ccpt}
,
sfov·rf
˜CcomCcptTcc
sfov·rf ·Tseg( ˜Ccom+Ccpt)
where Tmin (cid:44) min{Tcc − Tseg, Tseg} and
(cid:44) max{ ˜Ccom, Ccpt}Tcc
˜Ccom + Ccpt

T max
c

,

> Tseg,

≤ Tseg,

= max{to

cpt, to

com}.

(7)

cpt and to
to
com are the optimal durations for computing and
communication without the constraints in (5c) and (5d) as
considered in [3].

IV. MINIMUM-RESOURCE-LIMITED, UNCONDITIONAL
AND CONDITIONAL RESOURCE-TRADEOFF REGIONS
In this section, we show that

the system may operate
in a minimum-resource-limited, an unconditional resource-
tradeoff, or a conditional resource-tradeoff regions.

c

c

= to

First we discuss the two cases in (6c).
Case 1 T max

> Tseg: If ˜Ccom > Ccpt, then T max

> Tseg indicates that to

cpt
from (7). Since the allowed maximal duration for rendering
is Tseg as shown in (5c), T max
cpt
c
exceeds the allowed rendering duration. This suggests that the
completion rate of CC tasks is limited by the computing rate,
where increasing the other type of resource ˜Ccom is useless for
improving the system performance. Similarly, if ˜Ccom < Ccpt,
then T max
com and the system performance is limited by
the transmission rate. We refer to this case as “Minimum-
resource-limited case”, where the efﬁcient resource conﬁgura-
tion should satisfy ˜Ccom = Ccpt.

= to

c

We refer to a resource conﬁguration as “efﬁcient” when the
decrease of arbitrary one type of resources in the conﬁguration
will reduce the value of S∗
cc.

c

cpt and to

Case 2 T max

≤ Tseg: Both to

com satisfy the
duration-squeezing-prohibited constraints in (5c) and (5d).
In this case, either increasing the computing rate or the
transmission rate can improve the completion rate of CC
tasks. This indicates a tradeoff between the computing rate
and transmission rate [3]. We refer to this case as “Resource-
tradeoff case”, where the resource conﬁguration is ﬂexible.

However, the boundary of the two cases depends on T max
,
which further depends on ˜Ccom and Ccpt as shown in (7).
To provide useful insight into the resource conﬁguration, we
provide three regions in the following, which are independent
of the conﬁgured resources.
According to (7), we have

c

Tcc > T max

c

≥

Tcc
2

.

(8)

(a) Tcc > 2Tseg(Tcc = 2.1 s)

(b) Tcc < Tseg(Tcc = 0.9 s)

Minimum-resource-limited region: If Tcc

2 > Tseg, then with

T max
c

≥ Tcc

2 we have T max

c

> Tseg, i.e., Case 1 holds.

Unconditional resource-tradeoff region: If Tcc ≤ Tseg, then
< Tseg, which is the sufﬁcient

< Tcc we have T max

with T max
condition to make Case 2 satisﬁed.

c

c

c

∈ [ 1

Ccom+Ccpt

2 , 1), we obtain T max

Conditional resource-tradeoff region: If Tcc ∈ (Tseg, 2Tseg],
considering that max{Ccom,Ccpt}
∈
( Tseg
2 , 2Tseg). The system may operate in Case 1 or Case 2. If
T max
≤ Tseg, then the system lies in Case 2. If T max
> Tseg,
c
then the system lies in Case 1, where the efﬁcient resource
conﬁguration is Ccom = Ccpt and we have T max
from
(7). Further considering one boundary of the region Tcc ≤
2Tseg, we obtain T max
≤ Tseg, which is the condition of Case
2 and can also be re-written as the condition for the efﬁcient
resource conﬁguration as max{Ccom,Ccpt}
. That is to
say, in this region even if in Case 1, the efﬁcient resource
conﬁguration can transform the system into Case 2, i.e., the
resource-tradeoff case.

≤ Tseg
Tcc

= Tcc
2

Ccom+Ccpt

c

c

c

V. NUMERICAL RESULTS
In this section, we validate the obtained analytical results

and evaluate the performance of the optimized durations.

We consider the VR video with 4K resolution (3840×2160
pixels [21]) and b = 12 bits per pixel [19]. The ratio of a
FoV to a frame is γfov = 0.2 [18], then the number of bits
in a FoV is sfov = 3840 × 2160 × b × γfov = 19.9 Mbits.
The frame rate of VR video is rf = 30 frames per second
[21]. The compression ratio is γc = 2.41 [22]. The playback
duration of a segment is Tseg = 1 s [21]. Depending on the
conﬁgured communication and computing resources as well as
the number of users, the computing and transmission rates for
a user can be very different. For example, when K = 4, Nt =
8, P = 24 dBm, B = 40 MHz, and dk = 5 m, the ensemble-
average transmission rate for a user is Ccom = 0.78 Gbps [3],
and the equivalent transmission rate ˜Ccom = Ccomγc = 1.87
Gbps. When Nvidia P40 GPU is used for rendering VR videos
for four users, the computing rate for a user is Ccpt = 1.6
Gbps [3]. To reﬂect the variation of conﬁgured resources, we
set ˜Ccom, Ccpt ∈ [0, 1] Gbps, unless otherwise speciﬁed.

In Fig. 2, we illustrate the three regions. As shown in
Fig. 2a, if Ccom (cid:54)= Ccpt, then the system performance is

(c) Tcc ∈ (Tseg, 2Tseg)(Tcc = 1.5 s)
Fig. 2: (a) Minimum-resource-limited region, (b) Uncon-
ditional resource-tradeoff region, (c) Conditional resource-
tradeoff region.

restricted either by communication or computing resource. By
contrast, in the unconditional resource-tradeoff region shown
in Fig. 2b, the communication and computing resources can be
ﬂexibly adjusted. In the conditional resource-tradeoff region
in Fig. 2c, the system conﬁgured with different resources
lies in communication-limited case, resource-tradeoff case, or
computing-limited case. The boundary of the three cases is
max{Ccom,Ccpt}
. We can observe that if the system is
Ccom+Ccpt
resource-limited, say P3 in the ﬁgure, no matter if we increase
the computing rate or reduce the transmission rate in order to
satisfy the condition for efﬁcient resource conﬁguration (i.e.,
max{Ccom,Ccpt}
), the system will ﬁnally fall into the
Ccom+Ccpt

= Tseg
Tcc

≤ Tseg
Tcc
resource-tradeoff case.

In Fig. 3, we verify the necessity of imposing the duration-
squeezing-prohibited constraints by taking the value of Scc
over the ﬁrst four proactively streamed segments as an example
(the results for other values of ˜Ccom and Ccpt are similar
whenever the difference between the two values are more
than 500). We compare the optimal durations in (6) with two
baseline schemes without considering the duration-squeezing-
prohibited (SP) constraints. One is the optimal solution of
problem P1 without the SP constraints in (5c) and (5d), where
tcom = to
cpt, with legend “opt duration w/o
SP”. The other scheme ﬁxes the durations as tcom = Tcc
2 , with
legend “1:1 duration”. As expected, the optimal durations yield
the best performance from the (l+1)th segment.

com and tcpt = to

When Tcc < Tseg as shown in Fig. 3a, the optimal durations
achieve the same performance as the baseline “opt duration
w/o SP”, because Tcc ≤ Tseg is the sufﬁcient condition of Case

in the conditional resource-tradeoff region, the efﬁcient conﬁg-
uration should satisfy a condition. Numerical results validated
the necessity of imposing duration-squeezing-prohibited con-
straints and illustrated these regions.

REFERENCES

[1] F. Qian, L. Ji, B. Han, and V. Gopalakrishnan, “Optimizing 360 video
delivery over cellular networks,” ACM SIGCOMM Workshop, 2015.
[2] C.-L. Fan, W.-C. Lo, Y.-T. Pai, and C.-H. Hsu, “A survey on 360◦ video
streaming: Acquisition, transmission, and display,” ACM Comput. Surv.,
vol. 52, no. 4, Aug. 2019.

[3] X. Wei, C. Yang, and S. Han, “Prediction, communication, and com-
puting duration optimization for VR video streaming,” IEEE Trans.
Commun., early access, 2020.

[4] C. Li, W. Zhang, Y. Liu, and Y. Wang, “Very long term ﬁeld of view

prediction for 360-degree video streaming,” IEEE MIPR, 2019.

[5] C. Fan, S. Yen, C. Huang, and C. Hsu, “Optimizing ﬁxation prediction
using recurrent neural networks for 360◦ video streaming in head-
mounted virtual reality,” IEEE Trans. Multimedia, vol. 22, no. 3, pp.
744–759, March 2020.

[6] S. Mangiante, G. Klas, A. Navon, Z. GuanHua, J. Ran, and M. D. Silva,
“VR is on the edge: How to deliver 360◦ videos in mobile networks,”
ACM SIGCOMM, 2017.

[7] S. Gupta, J. Chakareski, and P. Popovski, “Millimeter wave meets edge
computing for mobile VR with high-ﬁdelity 8K scalable 360◦ video,”
IEEE MMSP, 2019.

[8] F. Guo, F. R. Yu, H. Zhang, H. Ji, V. C. M. Leung, and X. Li, “An
adaptive wireless virtual reality framework in future wireless networks:
A distributed learning approach,” IEEE Trans. Veh. Technol., vol. 69,
no. 8, pp. 8514–8528, 2020.

[9] J. Du, F. R. Yu, G. Lu, J. Wang, J. Jiang, and X. Chu, “MEC-assisted
immersive VR video streaming over Terahertz wireless networks: A deep
reinforcement learning approach,” IEEE Internet Things J., vol. 7, no. 10,
pp. 9517–9529, 2020.

[10] C. Zheng, S. Liu, Y. Huang, and L. Yang, “MEC-enabled wireless
VR video service: A learning-based mixed strategy for energy-latency
tradeoff,” IEEE WCNC, 2020.

[11] J. Chakareski and S. Gupta, “Multi-connectivity and edge computing for

ultra-low-latency lifelike virtual reality,” IEEE ICME, 2020.

[12] X. Hou, S. Dey, J. Zhang, and M. Budagavi, “Predictive adaptive
streaming to enable mobile 360-degree and VR experiences,” IEEE
Trans. Multimedia, early access, 2020.

[13] W. Xing and C. Yang, “Tile-based proactive virtual reality streaming via

online hierarchial learning,” APCC, 2019.

[14] W. Lo, C. Huang, and C. Hsu, “Edge-assisted rendering of 360° videos

streamed to head-mounted virtual reality,” IEEE ISM, 2018.

[15] 3GPP, “Extended reality (XR) in 5G,” 2020, 3GPP TR 26.928 version

16.0.0 release 16.

[16] NVIDIA, “NVIDIA CloudXR cuts the cord for VR, raises the bar for

AR,” https://blogs.nvidia.com/blog/2020/05/14/cloudxr-sdk.

[17] C. Perfecto, M. S. Elbamby, J. Del Ser, and M. Bennis, “Taming
the latency in multi-user VR 360°: A QoE-aware deep learning-aided
multicast framework,” IEEE Trans. Commun., vol. 68, no. 4, pp. 2491–
2508, 2020.

[18] W.-C. Lo, C.-L. Fan, J. Lee, C.-Y. Huang, K.-T. Chen, and C.-H. Hsu,
“360◦ video viewing dataset in head-mounted virtual reality,” ACM
MMSys, 2017.

[19] iLab, “Cloud VR network solution whitepaper,” Huawei Technologies
CO., LTD., Tech. Rep., 2018. [Online]. Available: https://www.huawei.
com/minisite/pdf/ilab/cloud vr network solution white paper en.pdf

[20] J. Zou, C. Li, C. Liu, Q. Yang, H. Xiong, and E. Steinbach, “Probabilistic
tile visibility-based server-side rate adaptation for adaptive 360-degree
video streaming,” IEEE J. Sel. Topics Signal Process., vol. 14, no. 1,
pp. 161–176, 2020.

[21] A. Mahzari, A. T. Nasrabadi, A. Samiei, and R. Prakash, “FoV-aware
edge caching for adaptive 360° video streaming,” ACM MM, 2018.
[22] M. Zhou, W. Gao, M. Jiang, and H. Yu, “HEVC lossless coding and
improvements,” IEEE Trans. Circuits Syst. Video Technol., vol. 22,
no. 12, pp. 1839–1843, 2012.

(a) Tcc < Tseg(Tcc = 0.9 s)

(b) Tcc ∈ (Tseg, 2Tseg)(Tcc = 1.5 s)

(d) Tcc > 2Tseg(Tcc = 2.1 s)
(c) Tcc ∈ (Tseg, 2Tseg)(Tcc = 1.5 s)
Fig. 3: Scc and MTP latency v.s. segment index, ˜Ccom = 900
Mbps and Ccpt = 400 Mbps.

com, to

2. When Case 2 holds, to
cpt ≤ Tseg, i.e., the transmitting
and computing with “opt duration w/o SP” will not cause
the squeeze. These two schemes outperform the scheme “1:1
duration”, which shows the gain of matching the imbalanced
computing rate and transmission rate.

When Tseg < Tcc < 2Tseg as shown in Fig. 3b, al-
though “opt duration w/o SP” slightly outperforms the op-
timal durations for the lth segment, the completion rate of
the CC tasks of this baseline degrades to zero and stalling
happens for the (l+1)th segment. This is because T max
=
max{ ˜Ccom,Ccpt}Tcc
= 1.04 > Tseg, i.e., Case 1 holds, where
˜Ccom+Ccpt
either the transmitting or the computing of this baseline
for the lth segment squeezes the duration for the (l+1)th
segment that causes the playback stalling, as visualized in
Fig. 3c. For the three schemes, the motion-to-photon (MTP)
latency of (l+n)th segment can be expressed as TMTP =
[tcom + tcpt − (n − 1) ((∆p)+ + (∆m)+)]+.

c

When Tcc > 2Tseg as shown in Fig. 3d, the squeeze is
unavoidable for two baselines. This shows the necessity of
imposing the duration-squeezing-prohibited constraints.

VI. CONCLUSION
In this paper, we investigated maximizing the completion
rate of CC tasks with task duration-squeezing-aware constraint
in proactive VR streaming. From the obtained closed-form
solution, we found the minimum-resource-limited, uncondi-
tional, and conditional resource-tradeoff regions. The bound-
ary of the three regions depends on the relation between the
total time budget for proactive communication and computing
and the playback duration of a segment. In the minimum-
resource-limited region, communication and computing re-
sources can not be traded off. In the unconditional resource-
tradeoff region, the resources can be ﬂexibly conﬁgured while

ll+1l+2l+3(stall)010%20%30%40%12%ll+1l+2l+3(stall) 020%40%60%80%17%ll+1l+2l+3(stall) 020%40%60%80%100%