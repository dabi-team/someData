Taming the latency in multi-user VR 360◦: A
QoE-aware deep learning-aided multicast framework

Cristina Perfecto, Member, IEEE, Mohammed S. Elbamby, Member, IEEE,
Javier Del Ser, Senior Member, IEEE, Mehdi Bennis, Senior Member, IEEE

1

0
2
0
2

n
a
J

0
1

]
T
I
.
s
c
[

2
v
8
8
3
7
0
.
1
1
8
1
:
v
i
X
r
a

Abstract—Immersive virtual reality (VR) applications require
ultra-high data rate and low-latency for smooth operation. Hence
in this paper, aiming to improve VR experience in multi-user
VR wireless video streaming, a deep-learning aided scheme for
maximizing the quality of the delivered video chunks with low-
latency is proposed. Therein the correlations in the predicted ﬁeld
of view (FoV) and locations of viewers watching 360◦ HD VR
videos are capitalized on to realize a proactive FoV-centric mil-
limeter wave (mmWave) physical-layer multicast transmission.
The problem is cast as a frame quality maximization problem
subject to tight latency constraints and network stability. The
problem is then decoupled into an HD frame request admission
and scheduling subproblems and a matching theory game is
formulated to solve the scheduling subproblem by associating
requests from clusters of users to mmWave small cell base stations
(SBSs) for their unicast/multicast transmission. Furthermore, for
realistic modeling and simulation purposes, a real VR head-
tracking dataset and a deep recurrent neural network (DRNN)
based on gated recurrent units (GRUs) are leveraged. Extensive
simulation results show how the content-reuse for clusters of
users with highly overlapping FoVs brought in by multicasting
reduces the VR frame delay in 12%. This reduction is further
boosted by proactiveness that cuts by half the average delays of
both reactive unicast and multicast baselines while preserving
HD delivery rates above 98%. Finally, enforcing tight latency
bounds shortens the delay-tail as evinced by 13% lower delays
in the 99th percentile.

Index Terms—Mobile virtual reality (VR) streaming, 5G, mul-
ticasting, millimeter wave (mmWave), Lyapunov optimization,
deep recurrent neural network (DRNN), hierarchical clustering,
resource allocation.

I. INTRODUCTION

V IRTUAL reality (VR) is expected to revolutionize how

humans interact and perceive media by inducing artiﬁcial
sensory stimulation to the brain and immersing them into
an alternative world [1]. Yet, given the well established fact
that the quality of the visual feedback highly impacts the
sense of presence [2], for true engagement to succeed high

Manuscript received April 23, 2019; revised 23 August, 2019; revised Oc-
tober 30th, 2019; Accepted December 26, 2019. This research was supported
in part by the Spanish Ministerio de Economia y Competitividad (MINECO)
under grant TEC2016-80090-C2-2-R (5RANVIR), in part by the INFOTECH
project NOOR, by the Kvantum institute strategic project SAFARI, by the
Academy of Finland projects CARMA, MISSION, SMARTER and 6Genesis
Flagship (grant no. 318927).

C. Perfecto and J. Del Ser are with the University of the Basque Country
(UPV/EHU), Spain (e-mail: cristina.perfecto@ehu.eus). J. Del Ser is also with
TECNALIA and with the Basque Center for Applied Mathematics (BCAM),
Spain (e-mail: javier.delser@tecnalia.com).

M. S. Elbamby and M. Bennis are with the Centre for Wireless Commu-
nications (CWC), University of Oulu, Finland (e-mail: {mohammed.elbamby,
mehdi.bennis}@oulu.ﬁ).

deﬁnition (HD) content needs to be consistently streamed
while the end-to-end latency or motion-to-photon (MTP) delay
is kept below 15-20 milliseconds. Otherwise VR sickness
or cybersickness –a phenomenon similar to motion sickness
due to the exposure to low quality or delayed VR con-
tent– might ruin the experience. For this reason, high-end
VR manufacturers have been long compelled to using wired
connections between the head mounted displays (HMDs) and
VR servers with high processing and storage capabilities.
However, this constraint physically limits the movement of
VR users and hence, degrades the quality-of-experience (QoE),
thereby calling for further development of mobile/wireless
solutions that are able to provide both convenience and a high-
quality VR. Moreover, as access to social VR experiences
surges, driven by location-based VR and 360◦ formats [3],
the gap between the available bandwidth and the prohibitively
high demands by mobile immersive VR is likely to prevail.
Clearly, disruptive content provisioning paradigms are needed
to unleash the plethora of new business opportunities for
leisure/entertainment industry that mobile interconnected VR
will bring. In this context, mobile VR spearheads the newly
coined highly reliable low latency broadband (HRLLBB) use
cases sitting across enhanced mobile broadband (eMBB) and
ultra reliable low latency communication (URLLC) service
categories in Fifth Generation (5G) networks [4]. The dis-
tinctive feature of HRLLBB, if compared to URLLC [5], is
the need to reliably provide massive data delivery to multiple
users with low-latency.

Focusing on omnidirectional 360◦ or spherical video for-
mat [6] and reducing its bandwidth consumption, video coding
solutions that adapt the streaming to users’ attention by track-
ing their visual region of interest are abundant in the literature.
Their common goal is to stream in HD1 only users’ viewports,
i.e., the portion of sphere in a user’s ﬁeld of view (FoV)
while wearing an HMD and, optionally, in lower quality the
rest. To do so, foveated, tile-based, and projection/viewport-
based FoV-streaming are the most commonly adopted ap-
proaches, all requiring real-time tracking of either users’ eye-
gaze or head angles i.e., the 3 degrees-of-freedom (3DoF) pose
expressed by yaw, pitch and roll angles2 as represented in
Fig. 1. Foveated solutions as per [7], [8] are conditioned to
availability of advance eye-gaze tracking mechanisms in the
HMDs and real-time frame rendering in the servers, whereas

1In the context of 360◦, 4K is widely viewed as the minimum resolution

in current HMDs, and ideally 8K or higher is desired.

2Pitch, yaw and roll head orientation angles represent rotations over the x,

y and z-axis, respectively.

 
 
 
 
 
 
2

Figure 1. Tiled-FoV mapping of a user’s 3DoF pose in the equirectangular
(EQR) projection of a 360◦ video frame.

for tile and viewport-based solutions, regular head-tracking is
enough. The main drawback of projection-streaming [9] lies
in its large server storage needs, given that for each frame
multiple viewpoints are kept. Lastly, in tile-based streaming
approaches as per [10]–[13], the video frame is divided in a
grid of regular tiles, each encoded in both HD and at a lower
resolution. Then, only the tiles within a user’s FoV region are
streamed in HD.

Real-time tile-based FoV streaming to a network of VR
users involves a number of time-consuming steps: edge con-
trollers/servers need to ﬁrst acquire pose data, process it to
compute the set of tiles within the FoV, and lastly sched-
ule their transmission. Then, on-HMD processing will be
performed to compose –stich–and display the corresponding
portion of the video frame. The end-to-end delay of the
process is non-negligible. Thus, as the number of users in the
network increases, operating this cycle within the MTP delay
budget for each frame for every user becomes challenging;
even more so if the server/edge controllers and users are not
wired. The latter realization calls for unconventional solutions
at different network levels. Among them, the use of proactive
transmission of FoV tiles –contingent on the availability of
prediction results on the FoV for the upcoming frames– can
signiﬁcantly improve the efﬁciency of content delivery even
with non-perfect prediction accuracy, especially in ﬂuctuating
channel environments, as illustrated by the following numer-
ical example: Let the tile size be 1 Mb and the FoV of the
user in each frame have a total of 32 tiles. This means that
without proactivity, a rate budget of 32 Mb on each frame
transmission interval is needed to fully deliver a user’s FoV
tiles. Assume that a user’s rate budget in the transmission
period of two subsequent frames f1 and f2 be 70 Mb and
10 Mb, respectively. This will lead to an outage in the second
frame. Assume that during the transmission period of frame f1,
the small cell base station (SBS) predicts the user’s future FoV
of frame f2 with an accuracy of 75%, i.e., 24 tiles out of the
32 are correctly predicted. Then, using proactive transmission,
the SBS can deliver during the ﬁrst transmission period the 32
tiles of frame f1 and the predicted 32 tiles of frame f2. When
the second transmission period starts and the user reports its
actual FoV for frame f2, the SBS will have to only transmit
the remaining 25% of the FoV, i.e., 8 tiles, which the user’s

Figure 2. Schematic representation of tiled-FoV mmWave multicast scheduled
transmission to VR users with overlapping FoVs. Users belonging to a given
cluster are served by a single mmWave SBS through different non-overlapping
beams of variable beamwidth.

rate budget allows handling without experiencing any outage.

A. Related Work

The need to predict users’ ﬁxation opens the door for
harnessing machine learning (ML) in wireless systems [14].
Moreover, public availability of extensive pose and saliency
datasets for 360◦ video equips an invaluable input to optimize
VR content streaming through supervised and unsupervised
deep learning applied to FoV prediction. To that end, content-
based [15] or trajectory-based [11], [16] strategies can be
adopted: the former tries to mimic human capacity to detect the
most salient regions of an upcoming video frame i.e., its point
of interests (PoIs), and predominantly rely on convolutional
neural networks (CNNs) to do so. The latter tracks head (or
eye-gaze) movement of VR users through their HMDs and
largely relies on the use of recurrent neural networks (RNNs).
However, due to the distinctive nature of 360◦ videos, the use
of content-based information alone might not be suitable since
the PoIs in a video frame might fall out of a user’s current
the viewing transition [17]. Similarly,
FoV and not affect
both having several PoIs or none within the FoV might be
problematic. Nevertheless,
the availability of proper video
saliency, could strongly improve the accuracy of the head
movement prediction by combining saliency-based head move-
ment prediction with head orientation history, as exempliﬁed
by [18]–[21]. Recently deep reinforcement learning (DRL) i.e.,
the hybridization of deep-learning with reinforcement learning
(RL), have provided the required tractability to deal with
highly-dimensional state and action space problems. Hence,
its application to 360◦ video streaming has been facilitated.
Good illustration of this trend are the works in [22] and [23],
where a DRL-based head movement prediction and a gen-
eral video-content independent tile rate-allocation framework
are respectively presented. Despite the rich recent literature
on FoV prediction, most of these and other works provide
bandwidth-aware adaptive rate schemes with a clear focus on
Internet VR video streaming. Hence, they do not address the
particularities of the mobile/cellular environment.

yyawTilesinFoVTilegridinunrolled2DEQRprojectionrollxpitchzFoVframeareaNon-FoVframeareaVRVRVRSBSb1SBSb2SBSb3b11b21b23b13b12VRVRVRVRTiled-FoVTiled-FoVTiled-FoVClusterCkservedbySBSb1withbeamsb11andb21.ClusterCk(cid:48)servedbySBSb2withbeamb12.ClusterCk(cid:48)(cid:48)servedbySBSb3withbeamsb13andb23.VRVRVRVRVRUsersinnon-activeclusters.Furthermore, HMDs have limited computing power and
storage capacity, so the above predictions need to be ofﬂoaded
to the network edge. In this sense, the emerging role of edge
computing for wireless VR and its relation with communica-
tion has been largely covered in the recent literature [4], [24]–
[28]. Therein, [4] outlined the challenges and the technology
enablers to realize a reliable and low-latency immersive mobile
VR experience. Whereas [24]–[28], explore different optimiza-
tion objectives while investigating some fundamental trade-
offs between edge computing, caching, and communication for
speciﬁc VR scenarios. Yet, most of the few works considering
VR multi-user scenarios focus either on direct [29] or device-
to-device (D2D)-aided [30] content broadcasting, disregarding
the potentials for bandwidth savings and caching of existing
correlations between VR users or contents [31]. Also the few
works that leverage content correlation through ML, such as
[32], none capitalizes prediction related information to perform
a proactive mmWave multicast transmission. Furthermore, to
the best of the authors’ knowledge, imposing high-reliability
and low-latency constraints on such wireless VR service
problem has not been studied so far.

Therefore, this manuscript proposes to incorporate ML and
multicasting into the optimization problem of maximizing the
streaming quality of FoV-based 360◦ videos with HRLLBB
guarantees. The use of ML to predict users’ FoV in advance
and leverage inter-user correlations is pivotal to the system.
Then, building upon the aforementioned correlations, multicast
transmissions aimed for clusters of users with partially or
fully overlapping FoVs will be proactively scheduled such
that strict latency bounds are kept. Moreover, the adoption of
millimeter wave (mmWave) frequency band communications
–where at each time slot a given SBS will steer multiple
spatially orthogonal beams towards a cluster of users–
to
transmit contents is key to beneﬁting from high transmission
rates that contribute to a reduced on-the-air delay.
For clarity, we summarize the main contributions of this paper
as follows:

• To provide high capacity while ensuring bounded la-
tencies in wireless 360◦ VR streaming, we propose a
proactive physical-layer multicast transmission scheme
that leverages future content and user location related
correlations.

• We model the problem as a quality maximization problem
by optimizing the users’ HD frame request admission
and scheduling to SBSs and, by borrowing tools from
dynamic stochastic optimization, we recast the problem
with trafﬁc load stability and latency bound considera-
tions. Subsequently, to solve it, a low complexity and
efﬁcient algorithm based on matching theory is proposed.
• To validate our proposed scheme, for FoV prediction we
developed a deep recurrent neural network (DRNN) based
on gated recurrent units (GRUs) that is trained with a
dataset of real 360◦ VR poses. The predicted FoVs for
a given time horizon are thus available to dynamically
cluster users based on their FoV overlap and proximity
within a VR theater, as well as to provide insights on
how much the scheme is affected by the accuracy of the
prediction and the clustering decisions.

3

• Extensive simulations are conducted to investigate the
effects of the prediction horizon, of the VR frame size, the
clustering, and of the network size, which conclude that
the proposed approach outperforms considered reference
baselines by delivering more HD quality frames, while
ensuring tight transmission delay bounds.

The remaining of this manuscript is organized as follows: In
Section II the system model and the underlying assumptions
are described. The optimization problem of wireless VR video
content delivery is formulated in Section III. Section IV
presents our proposed matching theory algorithm to schedule
wireless multicast/unicast transmission resources for VR video
chunks under latency constraints. A detailed description of
the FoV prediction and adopted user clustering schemes is
provided in Section V. Simulation results and performance
evaluation are presented in Section VI. Finally, Section VII
concludes the paper.

Notations: Throughout the paper, lowercase letters, boldface
lowercase letters, (boldface) uppercase letters and italic bold-
face uppercase letters represent scalars, vectors, matrices, and
sets, respectively. E[·] denotes the expectation operator and
Pr(·) the probability operator. Function of z and utility of z
(z) and by U(z). I{z } is the
are correspondingly expressed as
indicator function for logic z such that I{z } = 1 when z is true,
and 0, otherwise. The cardinality of a set S is given by S = |S|.
Moreover, [z]+ (cid:44) max(z, 0) and z stands for the time average
E[z(t)].
expectation of quantity z, given by z = limT →∞
Lastly, (cid:126) represents the Hadamard product, tanh(z)= ez −e−z
ez +e−z
is the hyperbolic tangent and σ(z) =
the sigmoid
activation functions for the neural network.

1
1+e−z

(cid:205)T

t=1

1
T

⨏

II. SYSTEM MODEL

In this section we introduce the system model which en-
compasses the considered deployment scenario, as well as the
adopted wireless channel and communication models. For ease
of reading, a non-comprehensive list of the notations used
throughout the rest of the manuscript is provided in Table I.

A. Deployment Scenario

We consider a VR theater with seats arranged in sr rows
and sc columns, and where a network of VR users U, all
wearing mmWave HMDs, are located. In this scenario, each
user chooses to watch an HD 360◦ VR video v ∈ V, with V
denoting the set of available VR videos in the catalog. Due to
their large size and to limited storage capacity in the HMDs,
the HD frames of videos are cached in the edge network
and are delivered to users through B = |B| SBSs distributed
around the theater. To ensure timely and smooth streaming
experience, a lower-quality standard deﬁnition (SD) version of
the video frames are assumed to be pre-cached in the user’s
HMD to be streamed if the HD frames are not successfully
delivered on time. The SBSs operate in the mmWave band
and are endowed with multi-beam beamforming capabilities
to boost physical layer multicast transmission [33] of shared
video content to users grouped into clusters. This setting is
graphically represented in Fig. 2.

Table I
SUMMARY OF MAIN NOTATIONS

4

Symbol
Time and Indexing
t, Tt
ta
f
Tf
fr
fp

Description

Time index and slot duration
Frame request arrival time
Video frame index
Time between frames
Real-time frame index
Prediction frame index

Sets

U, Ut r
B
V
F
C
C f
k
u , N f
Ck
u , (cid:98)N f
Ck
Problem Formulation

N f
(cid:98)N f

ru (t)
Lc f
au f , ηbu c f
τu f
(cid:15)d
µu c f
dt2MTP
τ MTP
Matching Theory
Υ, (cid:31)b , (cid:31)Ck
Ck , b
b, Ck
, U
U
C
B
Ck , b
b, Ck
, ˆU
ˆU
C
B
ν1, ν2
ν2
ˆIu , ˜I
u
User Clustering
fp
˜d
u, u(cid:48) ,d

fp
u, u(cid:48)

VR users (test set) and training users
SBSs
Videos
Frames indexes in a video
VR clusters
VR users in k-th cluster for video frame index f
FoV tiles of user u and cluster Ck for frame index f
Predicted tiles in the FoV of user u and of cluster Ck at
frame index f

Total trafﬁc admission for user u
Data size of chunk c f
Chunk admission and scheduling variables
Transmission delay of frame f to user u
Delay reliability metric
Rate of delivering chunk c f
Time left to schedule before MTP is exceeded
Motion-to-photon latency

to user u

Matching function and preference relations
Clusters and SBSs utilities

Modiﬁed utilities over the estimated parameters

Weight and sample number of moving average procedure
Estimated/moving-average interference for user u

FOV and FOV+ user location based clustering distances

In the network edge, without loss of generality, we assume
that all videos in the catalog are encoded at the same frame
rate 1/Tf –with Tf
the time between frames– and have the
f =1 ⊂ N.
same length i.e., consist of a set of frames F = { f }F
Moreover, the frames from the spherical videos are unwrapped
into a 2D equirectangular (EQR) or lat-long projection with
pixel dimensions PH × PV and divided into N = {1, . . . , N }
partitions or tiles arranged in an NH ×NV regular grid, so that
N = NH · NV and each tile is sized PH /NH × PV /NV pixels.
Therefore, when watching any given video v ∈ V, the FoV
of user u ∈ U during frame f ∈ F can be expressed as a tile
subset N f

u ⊆ N .

In a nutshell, two main indices are used in our manuscript:
one refers to the decision slots indexed by t = {1, 2, · · · } and
slot duration Tt which is the prevailing time scale enforced for
transmission/scheduling purposes, whereas the second index f
refers to the video frame index. Hence, the slotted time index t
and frame index f satisfy f (cid:44) (cid:100) t∗Tt
(cid:101) so that f = {1, 2, · · · } ∈ N.
Tf
With this division in mind, chunk hereafter denotes the part of
the video that corresponds to one frame in time and one tile
in EQR space.

B. FoV and Spatial Inter-user Correlation

To leverage FoV and spatial correlations between users in
the VR theater deployment from Section II-A , and as outlined
in Fig. 3b , we assume that users report in the uplink (UL)
their video index v and their 6 degrees-of-freedom (6DoF)
pose every Tf ms. This 6DoF pose includes head orientation

Symbol

Channel Model

NLOS

hbu
P(cid:96)bu , S(cid:96)bu , B(cid:96)bu
P(cid:96)LOS, P(cid:96)NLOS
LOS, ς S F
ς S F
fc
bu , d3D
d2D
bu
Tblock
Communication Model
bu , gRx
gTx
bu
ϕtx , ϕrx
ϑtx
bu , ϑrx
bu
pb , pb(cid:48)
BWb
SINRbu

SINR

c f

b, C

f
k

Iu
N0

Description

Channel gain for user u from SBS b
Pathloss, shadowing and blockage from b to user u
LOS and NLOS pathloss
LOS and NLOS shadowing variance
Normalized central frequency
Azimuth and elevation plane distance
Time between blockage events

Transmit/receive antenna gains of SBS b to user u
Transmit and receive beamwidths
Transmit and receive beams angular deviation.
Transmit powers of SBS b and interfering SBSs b(cid:48)
Bandwidth for SBS b in mmWave band
SINR for user u being served by SBS b
Multicast SINR of chunk c f from SBS b to cluster C f
k
Instantaneous interference for user u
Noise power spectral density

Lyapunov Optimization Framework

qu
zu , ju f
γu
L(·), ∆Lt
V∆

Trafﬁc queue of user u
Virtual queues of time averaged constraints
Auxiliary variables for the EOP
Lyapunov and Lyapunov-drift functions
Lyapunov drift-plus-penalty trade-off variable

FoV Prediction and DRNN

v,TH
M
θ
M, θ

X v

v,TH
t r , Y
t r
TH , TP
, p f
3u

3ut r

p f

r, Γ
h f −1, ˜h f , h f
α, β1, β2

Supervised learning model for video v and TH
Learning algorithm and parameter set
Training dataset and binary-encoded matrix of target tiles

Prediction horizon and input sequence length
3DoF pose vectors of a training user ut r and of a user u
Reset and update gates of the GRU
Previous, candidate and new hidden states in GRU

Learning rate and parameters for Adam algorithm

angles and x, y and z-axis coordinates3. The information is
then forwarded from the SBSs to the edge controller where
FoV prediction, user-clustering and scheduling decisions take
place.

New real-time/proactive chunk scheduling decisions will be
taken every Tt such that for all users chunks are scheduled for
downlink (DL) transmission by the SBSs, and delivered before
the frame deadline df expires. In this regard, the chunks that
f = fr , and to predicted future
correspond to real-time i.e.,
FoVs will be given by N fr

u and by { (cid:98)N f
To provide the estimated FoVs, let a supervised ML model
M v,TH
be deﬁned in the edge controller –with M denoting the
θ
model’s learning algorithm and θ its parameter set– associated
to each video v∈V and time horizon4 TH for which a model
is constructed as

f=fr+1, respectively.

u } fp

(cid:98)y fp
u (cid:44) M v,TH

θ

(x f

u).

(1)

Once the model’s ofﬂine training, as detailed in Section
V-C, has been completed and its parameters are known, given a
u of TP length of past 3DoF poses5 collected in x f
sequence x f
u,
the model will produce the vector of labels (cid:98)y fp
u,n} N
n=1
for frame index fp = f +TH as per (1). The corresponding set

u (cid:44) {(cid:98)y fp

3We notice here that 360◦ videos are displayed from a centered perspective
whereby users are only allowed to look around. Therefore, as users’ physical
location do not affect their view, for FoV prediction purposes only the 3DoF
head orientation needs to be considered, even if the whole 6DoF pose is
reported.

4Without loss of generality, that the time horizon for the prediction TH is

measured as an integer multiple of the frames.

5This sequence consists of the user’s last TP recorded head angles, as per
p f
3u with video frame indexes f ∈ { fr −TP +1, . . . , fr }.

u =

of tiles in the predicted FoV is a mapping such that { (cid:98)N fp
∀n ∈ [1, . . . , N]: (cid:98)y fp

u,n = 1}, ∀u ∈ U.

| (cid:208)K

Subsequently, the predicted FoVs and reported poses will
be fed into a user-clustering module whereby users watching
the same VR video v will be grouped together based on their
FoV and spatial correlation. The inputs for the scheduler will
therefore be: ∀u ∈ U the real-time FoV tile-sets N fr
u for the
current index frame f = fr as well as the predicted K user-
clusters {C fp
= U with their corresponding
}K
k=1
k
(cid:98)N fp
cluster-level predicted FoVs { (cid:98)N fp
Ck
Since spherical videos are not

u }K
locally cached, a huge
imbalance emerges in the amount of information being sent in
the UL vs. DL. Therefore, for the purpose of this manuscript
we will only focus on the effect of the DL HD 360◦ video
transmission from edge SBSs to VR users, and assume that
enough UL resources are available to users for timely pose
update and channel state information (CSI) report.

k=1 C fp

u ∈ C fp
k

k=1.

= (cid:208)

k

Also, in the remaining of the manuscript and for a given
time horizon TH , following the UL report of users’ pose, the
availability of the real-time and predicted FoVs as well as
of user-clustering partitioning results is assumed. The detailed
description of the proposed FoV prediction and user-clustering
schemes with their algorithmic implementation details to pro-
duce such inputs are provided in Section V. Next, the wireless
channel model and the communication model between the
SBSs and the VR users are presented.

C. mmWave Channel and Communication Model

At mmWave frequencies, due to the quasi-optical nature of
electromagnetic wave propagation, signals are highly direc-
tional. For that reason channels are composed of a single-
path propagation component for the dominant path and a
set of multi-path components. For tractability and without
loss of generality, in this paper we will neglect the multi-
path components and consider only the dominant path for the
purpose of VR wireless streaming.

In this single-path, we adopt the 3GPP contributed channel
model [34] which is valid for frequencies ranging from 0.5 to
100 GHz and bandwidths of up to 10% of the center frequency
not exceeding 2 GHz. Among the different scenarios therein,
typical indoor deployment cases including ofﬁce environments
and shopping malls, are showcased. Selecting the indoor open
ofﬁce scenario, with user devices and SBSs located at 1 m
and 3 m height respectively, a distance dependent line-of-sight
(LOS) probability is deﬁned as

Pr(LOS) =

1,
exp(cid:0)− d2D
(cid:1),
0.54exp(cid:0)− d2D

bu
70.8

−5

−49

bu
211.7

d2D
bu ≤ 5 m,
5 m < d2D
bu ≤ 49 m,
49 m < d2D
bu,

(cid:1),

(2)





where d2D
bu stands for the distance in meters between the SBS
and the user in the azimuth plane. Subsequently, results from
Pr(LOS) are exploited to calculate the large-scale fading effects
in the channel. Speciﬁcally, pathloss (cid:96) is given (in dB) as
follows,

(cid:96)LOS = 32.4 + 17.3 · log10d3D
bu

+ 20 · log10 fc,

(3)

(cid:96) prev
= 38.3 · log10d3D
bu
NLOS
(cid:96)NLOS = max((cid:96)LOS, (cid:96) prev
NLOS

+ 17.3 + 24.9 · log10 fc,
),

5

(4)

(5)

with d3D
fc in (3) and (4) representing the distance in
bu ,
meters between the SBS and the user in the elevation plane
and the channel’s central frequency normalized with 1 GHz,
respectively. A log-normally distributed shadowing fading loss
S(cid:96), with standard deviation for the LOS and non-line-of-
= 8.03 dB
sight (NLOS) cases of ς S(cid:96)
LOS
respectively, supplements the large-scale fading calculations.

= 3 dB and ς S(cid:96)

NLOS

the
In addition to the pathloss and shadowing fading,
channel intermittency due to sporadic human blockage is also
accounted for. This blockage B(cid:96)(tB) could hinder the com-
munication by bringing 20-30 dB penalty upon the channel
gain. To that end, based on the spatial location of users within
the VR theater, the prospective human blockers that might
obstruct the direct ray in the azimuth plane between a given
user and each of the available SBSs are counted. Thereupon,
the count-weighted probabilistic arrival of blockage-events is
evaluated every Tblock, with the value of Tblock chosen such
that Tblock/Tt (cid:29) 1 and the index tB satisfy tB (cid:44) (cid:100) t∗Tt
(cid:101). The
Tblock
reason for operating on larger time-scale lies on correlation
between blockage events along several transmission intervals
due to the relative slowness of human head and body limb
movement with respect to other channel fading effects. Indeed,
human blockage durations of few hundreds of ms or more are
reported in the literature [35]. By combining the channel as per
[34] with the statistic blockage model, both dynamic channel
ﬂuctuations and the arrival of sporadic and longer-lasting
human blockage events are suitably captured. Accordingly, the
channel gain hbu(t) in dB from SBS b ∈ B to user u ∈ U is
given as

hbu(t) = (cid:96)bu(t) + S(cid:96)bu(t) + B(cid:96)bu(tB).

(6)

To beneﬁt from multi-beam transmission, we assume that
SBSs are equipped with a limited number of radio frequency
(RF) chains, whereas users’ HMDs will have a single RF
chain,
limiting their beamforming and combining capabil-
ity. These assumptions are grounded on current high costs
and power consumption of analog-to-digital converters for
mmWave frequencies. For tractability, the actual antenna radi-
ation pattern is approximated by a 2D sectored antenna model
[36] in the SBSs and in the HMDs. In this model antenna
gains are considered constant within the mainlobe, and equal
to a smaller constant in the sidelobes. Let gTx
bu(t)) and
gRx
bu(ϕRx, ϑRx
bu(t)) denote the transmission and reception antenna
gains from SBS b to the HMD of VR user u while using beams
of beamwidth ϕ, given by

bu(ϕTx, ϑTx

(ϕ

g

bu
(cid:30)

(cid:30)

(cid:17)

gsl

,

(cid:30)

(cid:16)

, ϑ

2π−

bu
(cid:30)

2π−ϕ

(t)) =




∈ {Tx, Rx}, where ϑ

gsl,

(cid:30)

ϕ

|ϑ

bu
(cid:30)

(t)| ≤ ϕ

(cid:30)2 ,

(7)

otherwise,

(cid:30)

(t) stands for the angular
with
deviation from the boresight directions of SBS b and of VR
user u, and gsl is the constant sidelobe gain with gsl ∈ [0, 1).
High directionality of mmWave communication often implies
a search process to ﬁnd the best steering directions. In our

bu
(cid:30)

6

(a)

(b)

Figure 3.
(a) Timing sequence to showcase operation at transmission/scheduling level and at videoframe level. (b) Flowchart of the proposed DRNN aided
wireless scheduling of HD 360◦ video FoV chunks. Once user pose has been reported in the UL, FoV prediction and user clustering follow. Subsequently,
a scheduler balances HD chunk admission vs. queue stability subject to latency constraints. Finally a matching theory algorithm associates scheduled chunks
to SBS-user clusters pairs leveraging multi-beam mmWave multicast transmission in the DL.

system model, full knowledge of the seating area layout and
of the ﬁxed locations of the B SBSs is assumed. Moreover,
as stated before, users in U will report
their 6DoF pose
information in the UL with Tf periodicity. With these as-
sumptions, even if both the SBSs and users are aware of
each other’s location and know a priori what their respective
optimal beams’ boresight directions are, the above antenna
model effectively captures subtle misalignment errors arriving
from the limited availability of unique beam patterns common
in codebook-based beam alignment approaches under analog
(t) in
beamforming. In other words, the angular deviation ϑ
(7) reﬂects the inability of the analog beamformer to direct the
mainbeam at any arbitrary location. The signal-to-interference-
plus-noise ratio (SINR) for user u served by SBS b is thus
given by

bu
(cid:30)

SINRbu(t) =

pb hbu(t)gRx

bu(t)gTx
Iu(t) + BWb N0

bu(t)

,

(8)

the power of

where the numerator
the re-
represents
ceived signal at user u from SBS b under transmit power
pb, and the denominator is the sum of the interference
power and Gaussian noise power. In our system Iu(t) =
(cid:205)
b(cid:48)u(t) is the interference that ar-

b(cid:48) ∈B\{b } pb(cid:48) hb(cid:48)u(t)gRx

b(cid:48)u(t)gTx

b(cid:48)u(t), gTx

rives from the transmission of other SBSs reaching user u
transmit and receive antenna gains, and
through channel,
power level hb(cid:48)u(t), gRx
b(cid:48)u(t) and pb(cid:48), respectively. The
noise power is given by the noise power spectral density N0
in watts per hertz multiplied by the system bandwidth BWb.
Note that since multicast transmission is considered, the
achievable rate of user u ∈ C f
k depends on the composition of
Ck for each frame index f , with the assumptions behind this
composition being the FoV and spatial correlation as detailed
in Section V-D.

III. PROBLEM FORMULATION

In this section, building upon the multi-user VR scenario
described in Section II, we formulate the network-wide opti-
mization problem of scheduling the FoV contents of an HD
360◦ video frame by a deadline df such that VR sickness can
be avoided. The problem formulation explicitly incorporates
the proactive/real-time nature of content requests, as well as
multicast/unicast transmission capabilities in the SBSs. We
pose the problem as a frame quality maximization, while
the latency constraints and transmission queues stability are
maintained.

360◦VideoFrameRequestScheduler/TransmissionFrameindexfTimeindextFoVLearningandUserClustering{pf6u}u∈Ureported{pf+16u}u∈Ureported{pf+26u}u∈UreportedTfTfTtTtTtτMTPτMTPUserClusters&Cluster-FoVforframefp=f+THreadyProactiveFoVtilescanbescheduledNewproactiveFoVtilescanbescheduledFrameindexfTargetmaximumdelaytotransmitmissingreal-timeFoVtilesOUT:Clusters&cluster-levelFoVSchedulerEdgeControllerIN:User-levellocationandpredictedFoVtilesDeepRecurrentNeuralNetworkOUT:∀u∈USetoftilesinupcomingFoVIN:∀u∈USequenceoflastTp3DoFposes:UserClusteringComputesdistancematrixDfpwithelementsdfpu,u(cid:48)Incorporatespre-trainedmodelsMv,THθforallthevideosincatalogVandpredictionhorizonvaluesTH.OUT:Stablematchingclusters/users(cid:55)→SBSsLyapunovOpt.drift-plus-penaltyalgorithmRealtimeFoVRequestsIN:User-levelrealtimeFoVandcluster-levelpredictedFoVReport6DoFpose{pf6u}u∈UeveryTfReportCSIeveryTcHDvideochunkmulticast/unicasttransmissioneverytOUT:User-levelmissedtilestobedeliveredinreal-timeSectionV.dSectionV.atoV.cSectionIIISectionIVOP(cid:55)→EOPSeparateEOPinto3OSPs.User-SBSChunkSchedulingMatchingTheoryHDStreamingAdmissionAuxiliaryVariableSelectionSectionsII.c&II.d(cid:98)yfpu.=Mv,THθ(cid:0)xfu(cid:1)pitchyawrollOperatesonslottedtimeindextscale(Ttduration)Operatesonvideoframeindexfscale(f=(cid:100)t∗TtTf(cid:101))Proactivityandcontent-basemulticastingenablingblocksor to its real-time FoV N fr

For admission purposes, in our scenario a user u associated
during video frame index f = fp to a cluster C fp
⊂ C is
k
allowed to request chunks that belong either to the cluster-
level predicted FoV (cid:98)N fp
u . In this
Ck
sense, the admission of the predicted FoV proactive requests
allows to leverage cluster-level multicast
transmissions of
shared FoV chunks, i.e. content reuse. On their behalf, real-
time FoV chunk requests are the result of missed tiles, i.e.
N fr
(cid:44) ∅, due to imperfect prediction accuracy in the
DRNN module. In the latter case, these requests need to be
expedited to meet MTP latency related constraints and provide
a smooth VR experience.

u \ (cid:98)N fr
Ck

(cid:208)K

Let ru(t) be the total trafﬁc admission for user u ∈ C f
k=1 C f
ru(t) =(cid:213)

= U, ∀ f ∈ F
(cid:16)I{ f = fr }au f (t)

+ I{ f = fp }au f (t)

Lc f

Lc f

(cid:213)

(cid:213)

k

(cid:17)

k with

, (9)

f ∈ F

c f ∈N f
u

c f ∈ (cid:98)N f
Ck

where Lc f is the data size of chunk cf , and au f (t) is a binary
variable that indicates if the video frame f
is admitted for
ofﬂoading to user u. The aforementioned two-fold nature of the
chunk admission requests is evinced through the two separate
terms in (9). Moreover, we notice here that the value of ru(t)
in (9) is upper bounded by the maximum value rmax such that
ru(t) = rmax ⇒ au f = 1, ∀ f ∈ F that, in practice, represents
a situation where the system’s trafﬁc load is so low that all
frames can be admitted in HD without risking queue stability.
Extending the notation of the admission to consider unicast
and multicast transmission of chunks in real-time and proactive
respectively, the rate of delivering chunk cf to user u is

f = fr,

(cid:205)
b ∈B
(cid:205)
b ∈B

min

(10)

|c f ∈ (cid:98)N f
u(cid:48)

µbu(cid:48)(t),

ηbuc f (t)

otherwise,

µuc f (t) =

ηbuc f (t)µbu(t),



∀u(cid:48) ∈ C f
k

(cid:0)1+SINRbu(t)(cid:1) the unicast real-time
with µbu(t) = BWb log2
rate and ηbuc f (t) the binary scheduling variable for chunk cf
to user u from base station b. For the proactive multicast case
with fr< f ≤ fp, the SBS will adapt its rate to match that of the
worst user in the cluster C f
k to whom user u has been assigned
for the frame index at hand6. This way it guarantees that the
chunk will be correctly decoded by all the interested cluster-
users. Moreover, we remark here that the value of µuc f (t) in
(10) is bounded above by a maximum achievable service rate
µmax that in practice is determined by the highest available
modulation and coding scheme (MCS) index.

to express

compactness,

For notational

that
re-
quested chunk cf corresponds either
to the user’s real-
to the user’s cluster-level predicted FoV,
time FoV or
we will hereafter denote the targeted FoV chunk set as
(cid:101)N f
u + (1 − I{ f = fr }) (cid:98)N f
. Then qu(t) –namely, the
C f
trafﬁc queue of a user u, ∀u ∈ C f
k – evolves as
k
(cid:105) +
(cid:213)

u = I{ f = fr }N f

(cid:213)

a

qu(t + 1) =(cid:104)

qu(t) −

µuc f (t)

+ru(t).

(11)

f =[ fr, fp ]

c f ∈ (cid:101)N f
u

6In practice, this is accomplished by adapting the MCS that reﬂects users’

perceived channel quality.

7

We remark here that although only chunks for frame in-
dexes f = { fr, fp } are admitted, the range of frame indexes
corresponding to chunks co-existing in a user’s queue at a
given time may span to values f = [ fr, fr + 1, · · · , fp]. A
scheduling policy, that is aware of the VR speciﬁc latency-
reliability constraints, will
timely determine which chunks
need be expedited from these priority-based queues. Without
loss of generality, we assume that the video streaming and
FoV chunk scheduling start simultaneously, and denote the
transmission delay of the video frame f = fr to user u as
τu f (t). Let dt2MTP(t) represent the available time to schedule the
frame before the considered MTP delay deadline is exceeded
and given by

dt2MTP(t) = [ta + τ MTP − t]+,

(12)

where ta corresponds to the timestamp when the chunk
was requested, and τ MTP is the constant MTP latency-aware7
maximum transmission latency. In this regard, the following
HRLLBB constraint is imposed to ensure that the transmission
delay of the current playing frame does not exceed the MTP
delay with high probability:

lim
T →∞

1
T

T
(cid:213)

t=1

Pr(τu fr (t) ≥ dt2MTP(t)) ≤ (cid:15)d,

(13)

where (cid:15)d (cid:28) 1 is a predeﬁned delay reliability metric. We
then recast the probability in (13) as the expectation over an
indicator function, i.e., the constraint is rewritten as:

lim
T →∞

1
T

T
(cid:213)

t=1

E[I{τu fr (t)≥dt2MTP(t)}] ≤ (cid:15)d.

(14)

Collecting the HD frame admission and the binary
scheduling variables as A(t) = {au f : ∀u ∈ U, ∀ f ∈ { fp, fr }}
and η(t) = {ηbuc f (t) : ∀b ∈ B, ∀u ∈ U, ∀cf ∈ (cid:101)N f
u }, our opti-
mization problem is to maximize the user’s quality by optimiz-
ing the HD frame admission and scheduling policies subject
to the latency constraints:
U (cid:0){ru }(cid:1) = (cid:213)

OP: max

(ru)(cid:1)

(15a)

(cid:0)⨏

η(t),A(t)

s.t.

u ∈U

qu ≤ ∞, ∀u ∈ U,
au f (t) ∈ {0, 1}, ∀u ∈ U, ∀ f ∈ { fp, fr },
ru(t) ≤ rmax, ∀u ∈ U,
µuc f (t) ≤ µmax, ∀u ∈ U, ∀cf ∈ (cid:101)N f
u , ∀f ∈ F ,
ηbuc f(t) ∈ {0, 1}, ∀b ∈ B, ∀u ∈ U, ∀cf ∈ (cid:101)N f

(15b)

(15c)

(15d)

(15e)
u , ∀ f ∈ F ,
(15f)

lim
T →∞

1
T

T
(cid:213)

t=1

E[I{τu fr (t)≥dt2MTP(t)}] ≤ (cid:15)d, ∀u ∈ U. (15g)

7To realize a mobile VR operating within MTP bounds, a holistic approach
latency performance
that considers transmission, computing, and control
should be considered. Yet, 360◦ videos require substantially higher data rates
to provide acceptable quality to users and pose a greater challenge on the
content delivery process. Hence, in this work we argue that the question
of how this high data rate transmission can be realized with such latency
constraint is on itself important to study and focus on the transmission delay
saving a d f − τ MTP budget for other edge-server computing or on-HMD
processing delays.

⨏

(·) is a non-decreasing and concave function that can

where
be adjusted to reﬂect different optimization objectives.

To ﬁnd a tractable solution for the above stochastic opti-
mization problem, we ﬁrst deﬁne a set of auxiliary variables
{γu(t)}, ∀u ∈ U. Accordingly,
the stochastic optimization
problem in (15) can be transformed from a utility function
of time-averaged variables into an equivalent optimization
problem of time-averaged utility function of instantaneous
variables:

EOP:

max
A(t),η(t), {γu (t)}

s.t.

U (cid:0){γu(t)}(cid:1) = (cid:213)

(cid:16)⨏

(cid:17)

(γu)

u ∈U
γu ≤ ru, ∀u ∈ U,
γu(t) ≤ rmax, ∀u ∈ U,
(15b) − (15g)

(16a)

(16b)

(16c)

Next, by invoking the framework of Lyapunov optimization
[37], virtual queues are constructed to help satisfy the time-
average inequality constraints. By ensuring that these queues
are stable, the time average constraints, namely (15g) and
(16a), are guaranteed to be met. Therefore, we deﬁne zu(t)
and ju f (t) virtual queues that correspond to the constraints
over the auxiliary variables and over the transmission delay,
respectively. Accordingly, the virtual queues are updated as
follows:

zu(t + 1) = (cid:2)zu(t) − ru(t) + γu(t)(cid:3) +
,
ju f (t+1) = (cid:2) ju f (t) + (I{τu fr (t)≥dt2MTP(t)} − (cid:15)d)qu(t +1)(cid:3) +
Notice that the virtual queue in (18) is built after having
scaled-up the constraint in (14) by multiplying both sides of it
with the actual queue size. Hereinafter, for readability reasons
(t)≥dt2MTP(t)} will be shortened to I{dt2MTP(t)} to denote τuc f
I{τu c f
exceeding the MTP delay.

. (18)

(17)

Let χ(t) = {qu(t), zu(t), ju f (t) : u ∈ U, f ∈ F } be the vector
of combined trafﬁc and virtual queues with χ(t) = [χu(t)]u ∈U.
Then, to represent a scalar metric of the congestion, let the
quadratic Lyapunov function be given by

L(χ(t)) (cid:44) 1
2

(cid:213)

u ∈U

qu(t)2 + 1
2

(cid:213)

u ∈U

zu(t)2 + 1
2

(cid:213)

(cid:213)

ju f (t)2,

u ∈U

f ∈ F

the

drift

Lyapunov

one-timeslot

(19)
and
be
∆Lt = L(χ(t+1))−L(χ(t)). Hence, we leverage the drift-
plus-penalty algorithm to ﬁnd the control actions that greedily
minimize a bound of the drift function minus a scaled
utility function, i.e., ∆Lt − V∆E{U({γu(t)})}, where V∆ is the
parameter that controls the trade-off between minimizing the
queue backlog and approaching the optimal solution.

function

Lemma 1. At each time instant t, the following bound satisﬁes
the drift-plus-penalty function ∆Lt − V∆E{U({γu(t)})} under
any queue state and control strategy:
∆Lt −V∆E(cid:8)U({γu(t)})(cid:9) ≤ ∆0(t)
(cid:104)
(cid:213)

(cid:105)

−

zu(t)γu(t) − V∆U({γu(t)})

#1

u ∈U
(cid:213)

(cid:104)(cid:16)

−

u ∈U

αu(t) − zu(t)

(cid:17)

(cid:105)

ru(t)

#2

8

(cid:213)

(cid:104)

−

αu(t)

(cid:213)

(cid:213)

u ∈U

f ∈ F

c f ∈ (cid:101)N f
u

µuc f

(cid:105)

,
#3

(20)

where ∆0(t) is an upperbounded constant parameter at each
time slot t in (20), and αu(t) collects the terms related to the
trafﬁc queue and to the transmission delay virtual queue as
αu(t) = αq(t) + I{dt2MTP(t)}αj(t),
(cid:205)
d) − (cid:15)d

which are given as αq(t) = qu(t)(1 + (cid:15) 2
αj(t) = (cid:205)

f ∈ F ju f (t) + (1 − 2(cid:15)d)qu(t).

f ∈ F ju f (t) and

(21)

Proof: See Appendix A

The solution to (16) can be found by greedily minimizing
the right-hand side of (20) for each time slot. Instead, since
the optimization variables are decoupled in (20), we split the
optimization problem into three disjoint subproblems that are
solved concurrently based on the observation of the trafﬁc and
the virtual queues.

It can be also seen from (20) that the optimization problem
at a given time instant t is only function of the current states
of the trafﬁc and the virtual queues. This means that a solution
to the problem does not require the knowledge of the trafﬁc
statistics or queue evolution probabilities. The equation also
shows that the separability criteria [38] is met i.e., that the
admission and scheduling are not dependent on the variables
of each other.

A. Auxiliary Variable Selection

The ﬁrst subproblem is the minimization of the term #1 in
(20) i.e., the selection of the auxiliary variables. The problem
can be decoupled on a per user basis as follows:

V∆U(γu(t)) − zu(t)γu(t)

OSP1: max
{γu }
s.t. γu(t) ≤ rmax, ∀u ∈ U.

(22b)
By selecting a linear utility function, i.e., U(γu(t)) = γu(t),

(22a)

the optimal value of the auxiliary variable is found to be:

γu(t) =

(cid:40)

rmax,
0,

zu(t) ≤ V∆,
otherwise.

(23)

It is worth noting here that different utility functions can be
selected depending on the network optimization objective. For
example, a logarithmic function of the admission rates could
be selected to provide proportional fairness between users.

B. HD Streaming Admission

Next, the HD chunk admission problem is optimized by
solving the subproblem given by the term #2 of (20). The
optimization subproblem is formulated as:

(cid:213)

(cid:0)zu(t) − αu(t)(cid:1)ru(t)

OSP2: max
A(t)
s.t. au f (t) ∈ {0, 1}, ∀u ∈ U, ∀ f ∈ { fp, fr },

u ∈U

(24a)

(24b)

The above admission rate maximization problem is convex and
its optimal solution is:

au f (t) =

(cid:40)

1
0

zu(t) ≥ αu(t),
otherwise.

(25)

In other words, the optimal HD chunk admission control is
to either admit or discard the whole frame, depending on the
physical and virtual queue state.

C. User-SBS Chunk Scheduling

The third subproblem aims at scheduling user requests of
HD video chunks to base stations. The optimization subprob-
lem is formulated by maximizing the term #3 in (20) as
follows:

OSP3: max
η(t)

(cid:213)

αu(t)

(cid:213)

(cid:213)

µuc f (t)

(26a)

u ∈U

f ={ fr, fp }

c f ∈ (cid:101)N f
u
s.t. µuc f (t) ≤ µmax, ∀cf ∈ (cid:101)N f

u , ∀f ∈ F , ∀u ∈U,
ηbuc f (t) ∈ {0, 1},∀b ∈ B, ∀u ∈ U, ∀cf ∈ (cid:101)N f

(26b)
u , ∀ f ∈ F .
(26c)

We emphasize that OSP3 is a combinatorial problem where
video chunks for users need to be scheduled by SBSs using
a mmWave multicast transmission. Subsequently, a matching
algorithm is designed to associate chunk scheduling requests
arising either from clusters of users or from individual users
to the set of SBSs operating in mmWave band in the theater.

IV. A MATCHING THEORY APPROACH TO HD CHUNK
SCHEDULING

The use of Matching Theory [39] –a mathematical frame-
work from labor economics that attempts to describe the
formation of mutually beneﬁcial relationships over time–, has
recently garnered a considerable interest in the context of re-
source allocation for wireless networks [40]. However, for the
sake of completeness we will ﬁrst provide several deﬁnitions to
properly address the fundamentals of this framework adapted
to the problem at hand. Then, we will formulate the utility
functions that lie at its core for both sets of agents.

A. Matching Theory Preliminaries
Deﬁnition 1. A matching game is deﬁned by two sets of
players (C,B) and two preference proﬁles denoted by (cid:31)B and
(cid:31)C, allowing each player b ∈ B, Ck ∈ C to accordingly rank
the players in the opposite set.

Deﬁnition 2. The output of a matching game is a matching
function Υ(t) = {Υb, Ck (t)} that bilaterally assigns players
Υb(t) (cid:44) {b ∈ B : Υb, Ck (t) = 1} and ΥCk (t) (cid:44) {Ck ∈ C :
Υb, Ck (t) = 1} such that |ΥCk (t)| ≤ qC and |Υb(t)| ≤ qB are
fulﬁlled, with qB, qC the quota of the players which, for a
one-to-one matching game satisfy qB = qC = 1.

k) ∈ C × C with Ck (cid:44) C (cid:48)

Deﬁnition 3. A preference (cid:31) is a complete, reﬂexive and
transitive binary relation between the players in B and C.
Therefore, for any SBS b ∈ B a preference relation (cid:31)b is
deﬁned over the set of clusters C such that for any two clusters
k, and two matchings Υ(t), Υ(cid:48)(t)
(Ck, C (cid:48)
so that Υb(t) = Ck and Υ(cid:48)

b(t) = C (cid:48)
k:
k, Υ(cid:48)(t)(cid:1) ⇔ Ub, Ck
Similarly, for any cluster of users Ck ∈ C a preference relation
(cid:31)Ck is deﬁned over the set of SBS B such that for any two

(Ck, Υ(t)) (cid:31)b

(t) > U

b, C(cid:48)
k
B

(cid:0)C (cid:48)

(27)

(t).

B

9

SBSs (b, b(cid:48)) ∈ B × B with b (cid:44) b(cid:48), and two matchings Υ(t),
Υ(cid:48)(t) we have that ΥCk (t) = b and Υ(cid:48)
Ck
(t) > U Ck,b(cid:48)
(b, Υ(t)) (cid:31)Ck (b(cid:48), Υ(cid:48)(t)) ⇔ U Ck,b

(t) = b(cid:48):

(28)

(t),

C

C

where Ub, Ck
(t) denote the utility of cluster Ck for
SBS b and the utility of SBS b for cluster Ck, correspondingly.

(t) and U Ck,b

B

C

B. Matching Utility Formulation

The HD chunk scheduling subproblem in (26) is formulated
as a matching game between the SBSs and the clusters of
users. As such, both sides seek to greedily maximize the
overall VR experience by efﬁciently allocating the mmWave
transmission resources while VR QoE related constraints are
met. Hence, each timeslot with updated information on chan-
nel and queue state, new scheduling requests for video chunk
transmission will be prioritized in each cluster and in each
SBS, and new sets of matching pairs will be found using the
proposed approach. With the above principles in mind, we
formulate the utilities for both sets.

The utility of serving a given cluster of users with at least
one pending chunk request from the SBSs point of view will
essentially reﬂect two aspects: the priority and relevance of
the chunk cf at hand. The priority of the whole frame to
which the requested chunk belongs to is controlled by the
dynamics of qu(t) and ju f (t) as per (11) and (18) through
dt2MTP(t) as given by (12). The relevance of the chunk within
the cluster FoV is related to its popularity i.e., how many
of the cluster members have requested this chunk. Intuitively,
the cluster-level multicast approach decreases the wireless
network load by transmitting each chunk falling into the
cluster-level FoV only once. Moreover, transmitting ﬁrst the
most relevant chunks also contributes to increasing the overall
system welfare. Therefore, SBSs will build their preference
proﬁle using the following utility function:

Ub, Ck
B

(t) = (cid:213)
u ∈ Ck
= (cid:213)
u ∈ Ck

I

I

{c f ∈ (cid:101)N f

u }αu(t)

(29)

{c f ∈ (cid:101)N f
u }

(cid:8)αq(t) + I{dt2MTP(t)}αj(t)(cid:9).

Notice that in (29) by deﬁnition, I{dt2MTP(t)} can only be non-
zero for the currently playing frame index. Similarly, the utility
of a SBS from the clusters’ perspective will depend on the
goodness of the transmission opportunity through the offered
rate in (10). In other words, we deﬁne the utility as

U Ck,b
C

(t) =I{ f = fr }

min

µbu(t)

∀u ∈ C f
k

|c f ∈N f
u

+ (1 − I{ f = fr }) min

∀u ∈ C f
k

|c f ∈ (cid:98)N f
u

µbu(t),

(30)

C. Stability of the Matching

Next, the notion of stability is introduced and an interference
estimation method is proposed to guarantee that the HD chunk
scheduling game converges to a stable matching.
Deﬁnition 4. Given a matching Υ with Υb = Ck and ΥCk
and a pair (b(cid:48), C (cid:48)

= b,
(cid:44) b(cid:48), (b(cid:48), k (cid:48)) is

k) with Υb(t) (cid:44) k (cid:48) and ΥCk

said to be blocking the matching Υ and form a blocking pair
if: 1) b(cid:48) (cid:31)k b, 2) k (cid:48) (cid:31)b k. A matching Υ∗ is stable if there is
no blocking pair.

Gale-Shapley’s deferred acceptance (DA) algorithm [41]
provides a polynomial time solution guaranteed to be two-
sided stable for one-to-one canonical matchings i.e., those
matching games where the preference proﬁles of the players
are not affected by any other player’s decisions. The inﬂuence
of a given player’s matching over another’s is referred to as
externality. As the game evolves, the existence of externalities
triggers dynamic updates in the values of the perceived utilities
and, consequently, ensuring the stability of the matching is
challenging.

The above matching game cannot be directly solved using
DA; the utilities in (29)-(30) are function of the instantaneous
service rate which, in turn depends on the interference –a well-
known source of externalities– through the SINR. Moreover, in
the context of directional communications, the arrival direction
of the interference caused by other SBSs8 greatly impacts the
service rate. Hence, evaluating the instantaneous interference
and casting preferences accordingly implies full knowledge
of the system-wide current matching state by all the players,
which is impractical in terms of signaling overhead. Different
approaches are used in the literature to handle the matching
externalities either through ﬁnding preference proﬁles that do
not induce externality [42], or through centralized approval
methods that evaluate how each matching change affects other
players before allowing it [43]. Alternatively, we consider a
distributed and computationally efﬁcient algorithm that suits
the low latency nature of the considered application by replac-
ing the instantaneous values of the service rate in the utilities
with estimated ones.

Let the measured inter-SBS interference at user u in the
previous time instant t−1 be denoted as Iu(t−1), and ˆIu(t) the
estimated inter-SBS interference at time instant t. Adopting an
interference estimation procedure with learning parameter ν1
and moving average inference ˜Iν2
u (t − 1) with a window of ν2
samples, the estimated interference is given by

ˆIu(t) = ν1Iu(t − 1) + (1 − ν1) ˜Iν2

u (t − 1).

(31)

ˆUb, Ck
B

ˆU Ck,b
C

Let

(t) be

(t),
the utilities which exploit
ˆµbu(t)=BWb log2
such that

1 + pb hbu (t)gRx

the
(t)gTx
bu
bu
ˆIu (t)+BWb N0

(cid:16)

the new expressions
estimated service
(t)

for
rate
through ˆµuc f (t),

(t)

(cid:17)

ˆµbu(t),

(32)

ˆU Ck,b
C

ˆUb, Ck
B

(t) = I{ f = fr }

min

ˆµbu(t)

∀u ∈ C f
|c f ∈N f
u
k
+ (1 − I{ f = fr }) min

|c f ∈ (cid:98)N f
u

∀u ∈ C f
k
u } ˆαu(t)(t)

{c f ∈ (cid:101)N f

(t) = (cid:213)
u ∈ Ck
= (cid:213)
u ∈ Ck

I

I

{c f ∈ (cid:101)N f
u }

(cid:8) ˆαQ(t) + I{dt2MTP(t)} ˆαF (t)(cid:9).

(33)

8We remark here that by matching each SBS to a single cluster with
orthogonal non-overlapping beams for the multicast transmission, only the
impairment due to inter-SBS interference needs to be considered.

10

Algorithm 1: HD chunk scheduling between SBSs and
User-clusters
Phase I - Interference learning and candidate chunk selection

• Each u ∈ U, updates ˆIu (t) as per (31) and reports channel in the UL.
In the edge controller, queues in {χ(t)}u∈U are updated by solving (22), (24).
•
• For each Ck ∈ C a cluster-level chunk request pool is created and each request
c f
αu (t) with αu (t) as
Ck
c f
Ck

per (21).Then, the request pool is sorted in descending order of α

therein is assigned an urgency tag α

f
u∈Ck |c f ∈N
u

= (cid:205)

.

Phase II - Matching game construction

Ck , b
• Each cluster Ck ∈ C, updates ˆU
C
b, Ck
• Each SBS b∈ B, updates ˆU
B

over the SBSs in B as per (32).

over { Ck }K

k=1 as per (33) evaluating the

cluster utility by its most urgent chunk-request, i.e. by max{α

c f
Ck
Phase III - Deferred Acceptance for SBS-Cluster allocation
• For each SBS b, initialize the subset of eligible clusters, E b

}.

C ⊆ C so that

initially | E b

C | = | C |.

• For each SBS b, each cluster Ck , initialize the subset of unmatched clusters
SC ⊆ C and SBS SB ⊆ B, so that initially |SC | = | C |, |SB | = | B |.

while |SB | (cid:44) ∅ and (cid:205)

b∈B | E b
Pick a random SBS b ∈ B;
if | E b

C | (cid:44) ∅ do

C | (cid:44) ∅ then
SBS b sends a chunk scheduling proposal to its best ranked eligible
cluster Ck , Ck ∈ E b
C ;
if Ck ∈ SC then

Match b and Ck setting Υb (t) = Ck and ΥCk
Remove b and Ck from SB and SC respectively;

(t) = b;

else

(t )

(t) then

Ck ,ΥCk
Ck , b
if ˆU
(t) > ˆU
C
C
Reject proposal from ΥCk
(t )
ΥCk
remove Ck from E
C
Match b and Ck setting Υb (t) = Ck and ΥCk
Remove b from SB ;

(t); add back ΥCk
;

(t) to SB and

(t) = b;

else

Refuse proposal from b;
Remove Ck from E b
C ;

end

end

end

end
Phase IV - Stable matching

Under this new utility formulation there are no longer ex-
ternalities in the system. Therefore, the HD chunk scheduling
matching game can be solved using DA, which is guaranteed
to converge to a stable matching Υ(t) once the inter-cell
interference learning process converges. The process described
above as well as the details of the matching rounds are
described in Algorithm 1.

V. DRNN FOV PREDICTION AND FOV+LOCATION AWARE
USER CLUSTERING

In this section, the DRNN that predicts VR users’ FoVs
for upcoming video frames and the clustering scheme that
leverages FoV and spatial inter-user correlations are described.
We ﬁrst motivate the selection of the adopted sequential
learning model and brieﬂy summarize its operation dynamics.
Following that, the DRNN architecture implementation details
are provided and the training process is explained. Finally, the
distance metric driving the user-clustering partitioning and its
algorithmic implementation are speciﬁed.

A. Sequential Deep Learning Model Operation

Predicting a VR user’s tiled-FoV is an instance of movement
prediction where an input sequence of a user’s past and current
pose vectors is mapped to a multi-label output. In the output,

11

Figure 4. Detailed graphical representation of GRU unfolding and of the h(1)
f
computation in the unfolded GRU cell. The notation (·)(1) indicates that the
GRU at hand belongs to the ﬁrst layer, which is highlighted in blue in the
DRNN architecture from Fig. 5.

each label represents one tile in the video frame and its value
provides an estimate over the likelihood of the tile belonging
to the user’s future FoV.

To build our sequential learning model we adopt the GRU
[44] architecture, a variant of RNNs that uses two simple
gating mechanisms whereby long-term dependencies are effec-
tively tackled and the memory/state from previous activations
is preserved. Hence, compared to other models such as long
short-term memory (LSTM) units [45], GRUs are faster to
train and have proven to perform better for small datasets
[46], the case considered in Section VI-A. Speciﬁcally, for
every operation time step –which is measured in terms of
video frames and therefore indexed with f ∈ F – the GRU
units update the value of their hidden state h f as a non-
linear function of an input sequence x f
u and of the previous
hidden state h f −1. The non-linear function is parameterized
u; θ(cid:1) that
by θ following a recurrence relation h f =
is visually sketched in Fig.4 and formally described by the
following model equations:

⨏ (cid:0)h f −1, x f

Γf =σ (cid:0)WΓx f
rf =σ (cid:0)Wr x f
h f =(1 − Γ f ) (cid:126) h f −1

u + ZΓh f −1 + bΓ
(cid:1)
u + Zr h f −1 + br

(cid:1)

(34)

(35)

+ Γ f (cid:126) tanh(cid:0)W x f

u + Z (cid:0)r f (cid:126) h f −1

(cid:1) + bh

(cid:1),

(36)

where weight matrices WΓ, ZΓ, Wr , Zr , W , Z and bias
terms bΓ, br , bh represent the model parameters comprised in
θ that, with those of the fully connected neural layer in Fig.
5, are learned during the DRNN ofﬂine training process.

u +Z (cid:0)r f (cid:126) h f −1

The value of the update gate vector Γ f , as per (34), governs
through the linear interpolation in (36) the amount of the
previous hidden state h f −1 and of the new hidden state
candidate ˜h f = tanh(cid:0)W x f
(cid:1) contributing
to the next hidden state activation h f . Likewise, the reset gate
vector r f , as per (35), controls the degree of the contribution
of the previous hidden state h f −1 preserved for the new hidden
state candidate ˜h f . When the contribution from the previous
state is deemed irrelevant, the next hidden state ˜h f
is reset
and will depend only on the input sequence.
B. DRNN architecture

(cid:1) +bh

The building blocks of our proposed deep recurrent learning
model M v,TH
based on GRU layers and implemented using
Keras [47], a high-level neural networks API running on top
of a Tensorﬂow backend, are represented in Fig. 5.

θ

Input representation: Every Tf , an input sequence of size

TP corresponding to 3DoF pose vectors x f
is fed to the ﬁrst GRU layer.

u (cid:44) {p f

3u } fr

f = fr −TP +1

Sequence processing: The input is then processed follow-
ing model equations (34)-(36) in Section V-A by a TP time-
step GRU cell with a hidden state size equal to 512 examples.
Following a rectiﬁed linear unit (ReLU) activation that per-
forms a [z]+ operation, the output of the ﬁrst GRU layer goes
through a second GRU layer with the same characteristics.
The output state from this second layer h(2)
is then fed
f
to a serial to parallel (S/P) layer before going across a dense
neural layer that connects with the N output neurons.

(cid:44) o(2)
f

Figure 5. Block diagram of the deep learning model for the edge controller.
The DRNN predicts the tiles in the FoV of user u at frame index fp = fr +TH ,
i.e. TH frames ahead.

Output representation: Given the multi-label nature of our
learning model, a sigmoid activation layer is used to map
the N sized dense output into N probability values or logits
{Pr(n) = σ(Wdh(2)
n=1 that are Bernoulli distributed,
f
i.e., the probability of each label is treated as independent from
other labels’ probabilities. The output of the sigmoid is then
binarized with a cutoff layer such that
(cid:40)

+ bd)n} N

(cid:98)y fp
u,n =

1, σ(Wdh(2)
f
otherwise,
0,

+ bd)n ≥ γth,

(37)

where Wd, bd are the weights and biases of the dense fully-
connected layer and γth is the threshold value for the cutoff
layer, which is chosen to balance accuracy and recall. After the
binarization, the predicted FoV for a user u and frame index
fp = f + TH is retrieved as (cid:98)N fp
u,n = 1}.

u = {n ∈ [1, ..., N]: (cid:98)y fp

C. DRNN Training

θ

The aim of the training in the supervised deep recurrent
learning model M v,TH
is to iteratively ﬁnd the θ parameters
that minimize a binary cross-entropy loss function L(θ) for
all training instances. This loss function, for model parameters
θ, labels y fp
t r,n and logits {Pr(n)} N
n=1 captured from the output
uv
of the sigmoid layer in Fig. 5, is expressed as

L(θ)=−

1
N

N
(cid:213)

(cid:104)

n=1

t r,nlog(Pr(n))+(1−y fp
y fp
uv

uv
t r,n

) log(1−Pr(n))

(cid:105)

.

(38)

h(1)fh(1)f−1xf−TP+2urf(cid:101)hfΓf(cid:126)(cid:126)1−(·)(cid:126)σtanho(1)f⊕⊕⊕σZrWrZΓWΓZW1minusinput1−(·)Sumoperation⊕(cid:126)HadamardproductσSigmoidfunctiontanhTanhfunctionConcatenateDuplicateh(1)f−1h(1)fxf−TP+2uo(1)fh(1)f+1xf−TP+3uo(1)f+1h(1)f+THxfuo(1)f+THh(1)f+TH−1······GRUDetailUnfoldGRUxfuh(1)fﬄ(·)o(1)fGRUlayer1Cutoﬀ0/1(Tile1)(cid:98)yf+THu·········ReLUlayerTpcells512memoryunitsGRUlayer2·········Tpcells512memoryunits·········FullyConnectedDense·········SigmoidSerialtoparallel1×5121×5121×5121×5121×5121×5121×512·········Input:512Output:N·········0/1(Tile2)0/1(TileN)γth1······xfuxf−1uxf−TP+1uxf−2uxf−TP+2uxf−TP+3uTimepf−TP+1upfupf−1upf−2upf−TP+2upf−TP+3u(cid:98)yf+THu(cid:44)Mv,THθxfuxfuDuring the model ofﬂine training, Backpropagation Through
Time (BPTT) algorithm [48] and Adam algorithm [49] are
used to optimize the gradients. Adam is set with learning rate
α = 0.01, parameters β1 = 0.9, β2 = 0.999 and no decay. The
gradient backpropagation is performed over data batches of
size 512 and during 20 training epochs.

Next, the information related to users’ physical location
and to their predicted FoVs is leveraged to develop a user
clustering scheme.

D. Proposed FoV and Location Aware User Clustering

k

I

I

I

I

n=1

n=1

Once the predictions of the entire set of users U for a frame
index fp are ready, users viewing the same video v are grouped
into clusters based on their spatial and content correlations.

{n∈ (cid:98)N fp
u }

{n∈ (cid:98)N fp
u(cid:48) }

Mathematically, let C fp

k=1 C fp

uu(cid:48)/d2D
min

/(N − (cid:205)N

u,u(cid:48) = ˜d fp
u,u(cid:48)

k denote the k-th cluster in which
the set of users U is partitioned for frame index fp = f +TH
such that (cid:208)K
= U. Here, the cluster partitioning can
be obtained by i) computing the |U| × |U| distance matrix
D fp , whose d fp
(cid:1) element results from
(cid:0)d2D
quantifying the FoV-related distance or dis-similarity between
any pair of users {u, u(cid:48)} ∈ U which is given by ˜d fp
u,u(cid:48) =
1 − (cid:205)N
); and
{n(cid:60) (cid:98)N fp
u(cid:48) }
ii) scaling it by their relative physical distance d2D
uu(cid:48) divided
by d2D
min, that denotes the minimum value for such relative
distance as per the theater dimensions and seat arrangements.
the clustering scheme that builds on the
above distance metric, a hierarchical agglomerative clustering
with average linkage has been considered. This clustering
scheme allows operating over the constructed dendrogram
to increase/decrease the number of resulting clusters and
thereby investigating the trade-offs in terms of communica-
tion resource utilization versus achieved performance when
many/few clusters, as per K, are used.

To implement

{n(cid:60) (cid:98)N fp
u }

Once the clusters {C fp
k

}K
k=1 have been estimated using
the speciﬁc clustering strategy, the cluster-level FoV is built
and ready to be leveraged in the proposed multicast/unicast
scheduling strategy as (cid:98)N fp
Ck

(cid:98)N fp
u .

=(cid:208)

u ∈ C fp
k

VI. SIMULATION AND PERFORMANCE EVALUATION
In this section, we numerically validate the effectiveness of
the proposed solution. For that purpose, we start by describing
the dataset with real head-tracking information for 360◦ videos
and the DRNN FoV prediction accuracy results which will
impact the performance evaluation of the mmWave multicast
transmission. Following that,
the deployment scenario and
the considered baseline schemes are described. Finally, the
performance evaluation of the proposed approach is evaluated
and some insightful results are discussed9.

A. 360◦ Video Head-tracking Dataset and DRNN FoV Predic-
tion Accuracy Results

To validate our proposed approach, the information fed into
the DRNN for training and simulation corresponds to 3DoF

9For the interested reader, a demo showcasing the qualitative results
achieved comparing our approach to the baselines described in Section VI-B
is available at https://youtu.be/djt9efjCCEw.

12

Table II
FOV TEST ACCURACY: EFFECT OF PREDICTION HORIZON

Video

Category10

SFRSport
MegaCoaster
RollerCoaster
SharkShipwreck
Driving
ChariotRace
KangarooIsl
Pac-man
PerilsPanel
HogRider

NI, SP
NI, FP
NI, FP
NI, SP
NI, FP
CG, FP
NI, SP
CG, FP
NI, SP
CG, FP

Jaccard similarity index J
TH = 5
0.70±0.06
0.68±0.06
0.74±0.05
0.53±0.03
0.76±0.04
0.71±0.02
0.69±0.04
0.83±0.03
0.69±0.02
0.68±0.04

TH = 10
0.69±0.04
0.65±0.05
0.70±0.05
0.48±0.03
0.71±0.04
0.71±0.02
0.65±0.03
0.73±0.05
0.65±0.02
0.66±0.04

TH
v
TH = 20
0.63±0.03
0.64±0.07
0.64±0.04
0.44±0.03
0.63±0.03
0.68±0.02
0.63±0.03
0.67±0.05
0.56±0.03
0.65±0.04

(mean ± std. dev.)
TH = 30
0.50±0.05
0.61±0.05
0.63±0.05
0.36±0.03
0.58±0.02
0.65±0.03
0.58±0.03
0.66±0.06
0.53±0.03
0.57±0.05

Table III
FOV TEST ACCURACY: EFFECT OF THE NUMBER OF GRU LAYERS

Jaccard similarity index J

(mean ± std. dev.)

TH
v

Video

MegaCoaster

Pac-man

TH

5
10
20
30
5
10
20
30

Number of GRU layers

1
0.52±0.08
0.50±0.07
0.46±0.07
0.32±0.04
0.82±0.04
0.60±0.07
0.53±0.05
0.49±0.06

2
0.68±0.06
0.65±0.05
0.64±0.07
0.61±0.05
0.83±0.03
0.73±0.05
0.67±0.05
0.66±0.06

3
0.68 ± 0.04
0.65 ± 0.03
0.63 ± 0.05
0.61 ± 0.06
0.76 ± 0.04
0.73 ± 0.04
0.67 ± 0.05
0.65 ± 0.05

traces from the dataset in [50] whereby the pose of 50 different
users while watching a catalog of V=10 HD 360◦ videos from
YouTube were tracked. The selected videos are 60 s long, have
4K resolution and are encoded at 30 fps. A 100◦×100◦ FoV is
considered and, to build the tiled-FoV, the EQR projection of
each of the video frames has been divided into N = 200 square
tiles of 192 × 192 pixels arranged in a regular grid of NV = 10
and NH = 20 tiles. The dataset provides the ground-truth labels
after mapping the 3DoF poses to their corresponding tiled
FoVs. In view of the size and characteristics of the dataset, the
original 50 users have been split into disjoint Utr and U sets
for training and for test purposes with cardinalities |Utr | = 35
and |U| = 15, respectively.

u |/| (cid:98)N f

u ∩ N f

u ∪ N f

Results in Table II represent the accuracy of the prediction
models for different values of TH in terms of the Jaccard
similarity index, which is deﬁned for each user u viewing a
frame f of a video v as the intersection over the union between
the predicted and the actual FoV tile sets J( (cid:98)N f
u ) =
| (cid:98)N f
u |. In Table II, this index has been ﬁrst
averaged over the frames of the video at hand, and then over
all the test users, i.e., JTH
1
. The
|U | | F |
results in the table conﬁrm the anticipated decrease of the
accuracy as the prediction horizon moves further away from
the last reported pose. Similarly, results in Table III show
that increasing the depth of the DRNN by adding more GRU
layers is counter-productive; it overﬁts the training data and
unnecessarily increases the complexity of the model.

u ∩N f
u |
u ∪N f
u |

u , N f

v =

| (cid:98)N f
| (cid:98)N f

u ∈U

f ∈ F

(cid:205)

(cid:205)

B. Deployment Details and Reference Baselines

We consider two VR theater settings, a small and a medium
size capacity theaters with dimensions {sr, sc } = {5, 10} and
{sr, sc } = {10, 15} seats, respectively. In both conﬁgurations

10With category codes: NI=Natural

Image, CG=Computer Generated,

SP=Slow-paced, FP=Fast-paced.

Table IV
MAIN SIMULATION PARAMETERS

Parameter

Simulation time
Channel coherence time (Tc)
Blockage re-evaluation time (Tblock)
Transmission slot duration (Tt )
RF chains
Beam-level Rx beamwidth
Beam-level Tx beamwidths
Carrier frequency ( fc)
Bandwidth (BWb)
Noise spectral density (N0)
Noise ﬁgure
SBS transmit power (pi)
Motion-to-photon delay (τ MTP)
Delay reliability metric (cid:15)d
Tiles per frame (N)
Video frame duration (Tf )
Videos catalog size (V)
Users per video
Number of clusters (K)
Prediction horizon (TH )
DRNN input sequence (TP)
DRNN cutoff value (γth)

Value
60000 ms
1ms
100 ms
0.25 ms
1 per HMD; 4 per SBS
5◦
[5◦:5◦:45◦]
28 GHz
0.85 GHz
-174 dBm/Hz
9 dB
15 dBm
10 ms
0.01
200
33 ms (30 fps video)
[1, 3, 5, 10]
[10, 15]
[2 · V, 3 · V, 4 · V]
[5, 10, 20, 30] frames
30 pose values
0.5

the seats are separated from each other by 2 m, and there
is a 4 m distance from the seat area to the walls of the
enclosure. As detailed in Section II, SBSs are located at
ceiling level in the upper 4 corners of the theater. A total of
7 different scenarios are studied for simulation: scenarios sT-
$v correspond to the small theater with 10 users per video
with $ = V = {1, 3, 5} videos being played; scenarios bT-$v
correspond to the big theater with 15 users per video with
$ = V = {1, 3, 5, 10} videos being played. The set of default
parameter values for simulations is provided in Table IV. For
benchmarking purposes, the following baseline and proposed
schemes are considered:

• UREAC: Chunk requests are scheduled in real-time for

mmWave unicast transmission.

• MREAC: Chunk requests are scheduled in real-time and
multi-beam mmWave multicast transmission is used.
• MPROAC: Chunk requests are proactively scheduled and
multi-beam mmWave multicast transmission is used.
• MPROAC+: Corresponds to the proposed approach which
considers MPROAC and the HRLLBB constraint in the
scheduler.

C. Discussion

Next, the impact of the FoV prediction horizon, the re-
quested video quality, the maximum number of clusters and,
the network size are evaluated. To that end, the performance
of each scheme is evaluated through its average and the 99th
percentile (delay 99 pctl) transmission delay, calculated as the
delay until the last tile in the FoV of the requesting user
has been delivered. We observe here that focusing merely
on the average system performance would fail
to capture
the real-time aspects of the problem. Consequently, to show
that the adopted Lyapunov online control method is able to
keep the latency bounded below the τ MTP threshold with the
desired probability 1 − (cid:15), the 99th percentile delay is provided

13

too. Furthermore, alongside with the 99th percentile delay
plots, the HD successful delivery rate metrics highlight the
trade-off between the utility (maximizing the quality) and the
probabilistic latency constraint.

u , N f

u |/| ˘N f

u ∩ N f

u ) = | ˘N f

u | with ˘N f

u ⊆ (cid:208){ (cid:98)N f
Ck

Lastly, for each user u and frame index f

the Jaccard
similarity index between the successfully delivered chunks
and the actual FoV is computed. The index is given by
, N f
J( ˘N f
u ∪ N f
u }
denoting the set of tiles correctly decoded at user u ∈ C f
k .
u represents a measure of the
We notice here that
multicasting overhead owing to operating with cluster-level
predicted FoV chunk requests that, hence, will grow larger the
less correlated the FoVs of the cluster-members are. Similarly,
N f
u (cid:44) ∅ hints missed tiles. Therefore the evolution of this
index, averaged over all the users and frame indices, globally
captures the trade-off related to FoV correlation among cluster
members.

u \ N f

u \ ˘N f

˘N f

1) Impact of the FoV Prediction Horizon: We ﬁrst con-
sider the impact of the DRNN prediction horizon TH on
the performance of the proposed approaches MPROAC+ and
MPROAC, and compare it with the reactive baselines UREAC
and MREAC, whose performance is not affected. Intuitively, in
our scheme longer TH allow the scheduler to schedule future
frames earlier, but increases the overall amount of data to be
transmitted due to having lower prediction accuracy, as shown
in Table II. In Fig. 6, it can be seen that the scheduler can
maintain high HD quality streaming even with long prediction
horizons. The frame delay is shown to ﬁrst decrease, due
to having more time to schedule chunks in advance, then
increases again, due to having to schedule a higher number
of chunks in real-time that were missed by the predictor.
Transmitting more real time leads to lower utilization of the
user’s predicted FoV, which decreases the Jaccard index.

2) Impact of the Requested Video Quality: We move on
now to investigate the impact of the requested HD video
quality on the performance of the proposed scheme. To that
end, looking into both the sT-3v and bT-3v scenarios, we
evaluate the impact of the quality through the HD chunk size
of the frame shown to the user. The performance metrics
of each scheme are depicted in Fig. 7(a)-(d) and Fig. 7(e)-
(h) for the small and big theater scenarios, respectively. The
ﬁgures clearly show the trade-off between frame delay and
HD streaming rate. As the chunk size increases, the average
and 99th percentile delays increase for the different schemes.
Moreover, comparing UREAC with the other schemes, it is
shown that multicasting brings 40 − 50% increase in the HD
rate and 33 − 70% latency reduction through the utilization
of common FoVs of different users. At high chunk sizes, the
higher network load clearly increases the service delay. By
delivering the predicted frames in advance, both the MPROAC+
and MPROAC minimize the average delay without sacriﬁcing
the HD quality rate. The proposed MPROAC+ scheme is shown
to also keep the worst delay values bounded due to imposing
the latency constraint, as compared to the MPROAC. Further
comparing UREAC to MREAC, it is shown that multicasting sig-
niﬁcantly reduces the delay due to the utilization of common
FoVs of different users.

14

Figure 6.
in bT-3v with a load of 1 Gbps per user (0.972 Mb chunk size), and V∆ = 1 · 108.

(a) Average delay, (b) 99th percentile delay, and (c) HD delivery rate and (d) Jaccard index performance versus the prediction horizon (in frames)

(a) and (e) Average delay, (b) and (f) 99th percentile delay, (c) and (g) HD delivery rate and (d) and (h) Jaccard index performance in sT-3v
Figure 7.
and bT-3v, respectively, as a function of the HD chunk size, for V = 3 videos, K = 2 ×V clusters, TH = 5 frames, and Lyapunov trade-off V∆ = 1 ·108 and
V∆ = 1 ·109.

Figure 8.
a load of 1 Gbps per user (0.972 Mb chunk size)„ and V∆ = 1 · 108.

(a) Average delay, (b) 99th percentile delay, and (c) HD delivery rate and (d) Jaccard index performance versus cluster per video, in bT-3v with

As the performance of the MPROAC+ and MPROAC schemes
for different values of the Lyapunov parameter V∆ are pro-
vided, the trade-off between the frame delay and the quality is
further illustrated. Indeed, the results in Fig. 7 show that as the
V∆ increases, the scheduling algorithm prioritizes maximizing
users’ HD delivery rate, whereas at lower values of V∆, the

scheduler prioritizes stabilizing the trafﬁc and virtual queues
i.e., keeping the delay bounded with high probability. This
comes at the expense of having lower HD delivery rate. The
MPROAC+ approach also achieves 17-37% reduction in the
99th percentile latency as compared to MPROAC and MREAC
schemes, respectively.

15

VII. CONCLUSIONS

In this paper, we have formulated the problem of max-
imizing users’ VR streaming QoE as a network-wide HD
frame admission maximization problem subject to low latency
constraints with very high reliability. We have proposed a
Lyapunov-framework based approach which transforms the
stochastic optimization problem into a series of successive
instantaneous static optimization subproblems. Subsequently,
for each time instant, a matching theory algorithm is applied to
allocate SBS to user clusters and leverage a mmWave multicast
transmission of the HD chunks. Using simulations, we have
shown that the proposed DRNN can predict the VR users’
future FoV with high accuracy. The predictions of this model
are used to cluster users and proactively schedule schedule
the multicast transmission of their future video chunks. Fur-
thermore, simulations have provided evidence of considerable
gains achieved by the proposed model when compared to both
reactive baseline schemes, while notably outperforming the
unicast transmission baseline.

APPENDIX A
PROOF OF LEMMA 1
By leveraging the inequality (max[x, o])2 ≤ x2 for x ≥ 0, after
squaring the physical and virtual queues in (11), (17) and (18)
the upper bounds for the above terms are derived as
u(t) +(cid:213)

(t) − 2ru(t)µuc f (t)

u(t +1) − q2
q2

u(t) ≤ r 2

(cid:213)

µ2
uc f

(cid:16)

(cid:17)

f ={ fr, fp }
− 2qu(t)(cid:0)µuc f (t) − ru(t)(cid:1),

c f ∈ (cid:101)N f
u

u(t +1) − z2
z2

u(t) ≤ r 2

u(t) + γ2

u(t) − 2ru(t)γu(t)

u f (t +1) − j2
j2

u f (t) ≤ q2

− 2zu(t)(cid:0)ru(t) − γu(t)(cid:1),
u(t + 1)(cid:0)I{dt2MTP } −(cid:15)d

+ 2 ju f (t)(cid:0)I{dt2MTP } −(cid:15)d

(cid:1) 2
(cid:1)qu(t +1),

with the one time slot Lyapunov drift given by

(39)

(40)

(41)

∆Lt (cid:44) L( χ(t + 1)) − L( χ(t))
(cid:26) (cid:16)

(cid:213)

u(t + 1) − q2
q2

u(t)

(cid:17) + (cid:16)

u(t + 1) − z2
z2

u(t)

(cid:17)

u f (t + 1) − j2
j2

u f (t)

(cid:17) (cid:27)

.

(42)

= 1
2

+ (cid:213)
f ∈ F

u ∈U
(cid:16)

(cid:205)

f ={ fr, fp }

Replacing the term qu(t + 1) in (41) with qu(t + 1) =
qu(t) + (cid:205)
ru(t) − µuc f (t) due to the fact that
having I{dt2MTP } = 1 entails a non-empty queue guarantee, and
combining (39)-(41), an upperbound on the drift function can
be expressed as (43).

c f ∈ (cid:101)N f
u

Note that the terms #b, #c, and #e in (43) are quadratic,
therefore upper bounded to comply with the assumption of
queue stability. Hence, let

∆0(t)≥

(cid:40)

1
2

(cid:213)

u ∈U

2(cid:0)I{dt2MTP } −(cid:15)d

(cid:1)

(cid:26)

qu(t)

(cid:213)

(cid:27)

ju f (t)

+ (cid:0)I{dt2MTP } −(cid:15)d

(cid:1) 2

(cid:26)

u(t)+ (cid:16) (cid:213)
q2
f ={ fr, fp }

f ={ fr, fp }
(cid:213)

c f ∈ (cid:101)N f
u

µuc f (t)−ru(t)

(44)

(cid:17) 2(cid:27)

Figure 9. (a) Average delay and (b) HD delivery rate performance for different
network scenarios with a load of 1 Gbps per user (0.972 Mb chunk size).

Furthermore, the Jaccard similarity in Fig. 7(d) and Fig. 7(h)
illustrates the trade-offs of utility and latency versus transmis-
sion utilization. At low trafﬁc loads, high quality rate and low
latency result in lower Jaccard index, which is due to the large
amount of extra data sent due to sending an estimated FoV.
As the trafﬁc load increases, the proactive schemes transmits
more real-time frames, which increases the Jaccard index. The
Jaccard index decreases again at higher trafﬁc loads as the
effect of missed frames goes up (the average delay approaches
the deadline as can be seen in Fig. 7(a), Fig. 7(e))

3) Impact of the Number of Clusters: Subsequently, we
examine how the maximum number of clusters affects the
performance of the multicast schemes, as compared to the
UREAC scheme, which operates in unicast. Fig. 8 shows that
a lower number of clusters allows for higher content reuse
of the overlapping areas in the FoVs of users, which results
in lower delay and higher HD quality rate. By allowing a
higher number of clusters per video, however, higher Jaccard
similarity indices are scored, as less unnecessary chunks are
sent to users, as shown in Fig. 8(d).

4) Impact of the Network Size: Finally, the effect of the
network size is analyzed. To do so, both the small and the
big theater conﬁgurations are considered under an increasing
amount of users and videos. In Fig. 9, it is shown that the
proposed scheme achieves close to 100% HD streaming rate
in scenarios 1, 2, 4, and 5 while maintaining lower frame
delay. Moreover, in the congested scenarios with high number
of users and videos, i.e., scenarios 3, 6, and 7, the results
show that multicasting provides substantial performance im-
provement through the gains of MREAC over UREAC. This
demonstrates the capability of multicasting to minimize the
latency of VR streaming to multi-user scenarios. Although the
large amount of requested data in these congested scenarios
limits the available resources to schedule the predicted frames
in advance, the results in Fig. 9 show that the proposed scheme
MPROAC+ can achieve higher HD delivery rate and lower delay
compared to the baselines.

(cid:26)

u(t) + (cid:16) (cid:213)
q2
f ={ fr, fp }

16

(cid:213)

µuc f (t) − ru(t)

(cid:17) 2(cid:27)

c f ∈ (cid:101)N f
u
(cid:213)

µuc f (t) − ru(t)

#b
(cid:17) (cid:27)

#g

(43)

f ={ fr, fp }
c f ∈ (cid:101)N f
u
(cid:35)
(cid:17) (cid:27)

(cid:213)

1
2
u ∈U
(cid:26) (cid:16) (cid:213)

∆Lt ≤

+

(cid:34)
−2(cid:0)I{dt2MTP } −(cid:15)d

(cid:26)

(cid:1) 2

qu(t)

(cid:16) (cid:213)

(cid:213)

µuc f (t) − ru(t)

(cid:17) (cid:27)

+ (cid:0)I{dt2MTP } −(cid:15)d

(cid:1) 2

(cid:213)

µuc f (t) − ru(t)

f ={ fr, fp }

c f ∈ (cid:101)N f
u

c f ∈ (cid:101)N f
u

f ={ fr, fp }
+ (cid:16)

(cid:17) 2

ru(t) − γu(t)

#a

(cid:26)

(cid:16)

zu(t)

(cid:17) 2(cid:27)

− 2
#e

ru(t) − γu(t)

(cid:17) (cid:27)

(cid:26)

− 2

qu(t)

(cid:16) (cid:213)

# f

+ 2(cid:0)I{dt2MTP } −(cid:15)d

(cid:1)

(cid:26)

qu(t)

(cid:213)

(cid:27)

ju f (t)

− 2(cid:0)I{dt2MTP } −(cid:15)d

(cid:1)

(cid:26) (cid:213)

(cid:213)

(cid:16)

ju f (t)

µuc f (t) − ru(t)

.

f ={ fr, fp }

#c

f ={ fr, fp }

c f ∈ (cid:101)N f
u

#d

(cid:26) (cid:16) (cid:213)

+

(cid:213)

f ={ fr, fp }

c f ∈ (cid:101)N f
u

µuc f (t) − ru(t)

(cid:17) 2

+ (cid:16)

ru(t) − γu(t)

(cid:17) 2(cid:27)(cid:41)

be the constant parameter at each time instant t collecting the
aforementioned terms from the drift above. After subtracting
the penalty term V∆E(cid:2)U (cid:0)(cid:8)γu(t)(cid:9)(cid:1) (cid:3) on both sides of (43), and
further operating on #a, #d and #g to denote αu the term

αu(t) = (cid:2)(cid:0)I{dt2MTP } −(cid:15)d

(cid:1)qu(t)+ (cid:213)

ju f (t)(cid:3) (cid:0)I{dt2MTP } −(cid:15)d

(cid:1) + qu(t),

f ∈ F

we have that
∆Lt −V∆E(cid:104)
U

(cid:16)(cid:110)

γu(t)

(cid:111)(cid:17)(cid:105)

≤ ∆0(t) −

(cid:213)

V∆E(cid:104)
U

(cid:16)(cid:8)γu(t)(cid:9)(cid:17)(cid:105)

u ∈U
(cid:16) (cid:213)

αu(t)

(cid:213)

µuc f (t)−ru(t)

(cid:17)

f ={ fr, fp }
(cid:16)

c f ∈ (cid:101)N f
u
(cid:17)

ru(t)−γu(t)

,

zu(t)

(cid:213)

−

u ∈U
(cid:213)

−

u ∈U

which after some more rearrangements yields equation (20).

REFERENCES

[1] E. Ba¸stu˘g, M. Bennis et al., “Toward interconnected virtual reality:
Opportunities, challenges, and enablers,” IEEE Commun. Mag., vol. 55,
no. 6, pp. 110–117, June 2017.

[2] C. Hendrix and W. Barﬁeld, “Presence within virtual environments as
a function of visual display parameters,” Presence: Teleoperators and
Virtual Environments, vol. 5, no. 3, pp. 274–289, 1996.

[3] Cisco, “Cisco visual networking index: Global mobile data trafﬁc
forecast update, 2017â ˘A ¸S2022,” institution, Tech. Rep., 2 2017.
[4] M. S. Elbamby, C. Perfecto et al., “Toward low-latency and ultra-reliable
virtual reality,” IEEE Netw., vol. 32, no. 2, pp. 78–84, March 2018.
[5] M. Bennis, M. Debbah, and H. V. Poor, “Ultra-reliable and low-latency
wireless communication: Tail, risk and scale,” Proc. IEEE, vol. 106,
no. 10, pp. 1834–1853, 10 2018.

[6] M. Zink, R. Sitaraman, and K. Nahrstedt, “Scalable 360◦ video stream
delivery: Challenges, solutions, and opportunities,” Proceedings of the
IEEE, vol. 107, no. 4, pp. 639–650, April 2019.

[7] K. Doppler, E. Torkildson, and J. Bouwen, “On wireless networks for
the era of mixed reality,” in Proc. Eur. Conf. on Netw. and Commun.
(EuCNC), June 2017, pp. 1–6.

[8] P. Lungaro, R. Sjoberg et al., “Gaze-aware streaming solutions for the
next generation of mobile vr experiences,” IEEE Trans. Vis. Comput.
Graphics, vol. 24, no. 4, pp. 1535–1544, 2018.

[9] X. Corbillon, G. Simon et al., “Viewport-adaptive navigable 360-degree
video delivery,” in Proc. of IEEE Int. Conf. on Commun. (ICC), 2017,
pp. 1–7.

[10] M. Hosseini and V. Swaminathan, “Adaptive 360 VR video streaming:
Divide and conquer,” in IEEE Int. Symp. on Multimedia (ISM), Dec
2016, pp. 107–110.

[11] F. Qian, L. Ji et al., “Optimizing 360◦ video delivery over cellular
networks,” in Proc. Int. Conf. Mobile Comp. and Netw. (MOBICOM),
New York, NY, USA, 2016, pp. 1–6.

[12] M. Xiao, C. Zhou et al., “Optile: Toward optimal tiling in 360-degree
video streaming,” in Proc. of ACM Conf. on Multimedia, ser. MM ’17.
New York, NY, USA: ACM, 2017, pp. 708–716.

[13] A. Ghosh, V. Aggarwal, and F. Qian, “A rate adaptation algorithm
for tile-based 360-degree video streaming,” CoRR, vol. abs/1704.08215,
2017.

[14] M. Chen, U. Challita et al., “Machine learning for wireless networks
with artiﬁcial intelligence: A tutorial on neural networks,” CoRR, vol.
abs/1710.02913, 2017.

[15] M. Cornia, L. Baraldi et al., “Predicting human eye ﬁxations via an
lstm-based saliency attentive model,” IEEE Trans. Image Proc., vol. 27,
pp. 5142–5154, 2018.

[16] Y. Bao, H. Wu et al., “Shooting a moving target: Motion-prediction-
based transmission for 360-degree videos,” in IEEE Int. Conf. on Big
Data, Dec 2016, pp. 1161–1170.

[17] V. Sitzmann, A. Serrano et al., “Saliency in vr: How do people explore
virtual environments?” IEEE Trans. Visualization and Comp. Graphics,
vol. 24, no. 4, pp. 1633–1642, 4 2018.

[18] A. Nguyen, Z. Yan, and K. Nahrstedt, “Your attention is unique:
Detecting 360-degree video saliency in head-mounted display for head
movement prediction,” in Proc. ACM Int. Conf. on Multimedia, 2018,
pp. 1190–1198.

[19] A. Nguyen and Z. Yan, “A saliency dataset for 360-degree videos,” in
Proc. ACM Multimedia Systems Conference. ACM, 2019, pp. 279–284.
[20] C.-L. Fan, J. Lee et al., “Fixation prediction for 360◦; video streaming
in head-mounted virtual reality,” in Proc. Wksp on Network and Op. Sys.
Support for Dig. Audio and Video. New York, NY, USA: ACM, 2017,
pp. 67–72.

[21] C. Li, W. Zhang et al., “Very long term ﬁeld of view prediction for
360-degree video streaming,” CoRR, vol. abs/1902.01439, 2019.
[22] M. Xu, Y. Song et al., “Predicting head movement in panoramic video:
A deep reinforcement learning approach.” IEEE Trans. Pattern Analysis
and Machine Intelligence, 2018.

[23] Y. Zhang, P. Zhao et al., “Drl360: 360-degree video streaming with deep
reinforcement learning,” in IEEE Conf. on Comp. Commun. (INFOCOM
2019), April 2019, pp. 1252–1260.

[24] X. Hou, Y. Lu, and S. Dey, “Wireless VR/AR with edge/cloud comput-
ing,” in Int. Conf. Comp. Commun. and Netw. (ICCCN), July 2017, pp.
1–8.

[25] S. Mangiante, K. Guenter et al., “VR is on the edge: How to deliver
360◦ videos in mobile networks,” in Proc. ACM SIGCOMM. Wksh. on
VR/AR Network, 2017.

[26] J. Chakareski, “VR/AR immersive communication: Caching, edge com-
puting, and transmission trade-offs,” in Proc. ACM SIGCOMM. Wksh.
on VR/AR Network. New York, NY, USA: ACM, 2017, pp. 36–41.

[27] M. S. Elbamby, C. Perfecto et al., “Edge computing meets millimeter-
wave enabled VR: Paving the way to cutting the cord,” in 2018 IEEE
Wireless Commun. and Netw. Conf. (WCNC), April 2018.

[28] Y. Sun, Z. Chen et al., “Communication, computing and caching for
mobile VR delivery: Modeling and trade-off,” in IEEE Int. Conf. on
Commun. (ICC), May 2018, pp. 1–6.

[29] A. Prasad, M. A. Uusitalo et al., “Challenges for enabling virtual reality
broadcast using 5g small cell network,” in 2018 IEEE Wireless Commun.
and Netw. Conf. Wksh.s (WCNCW), April 2018.

[30] A. Prasad, A. Maeder, and M. A. Uusitalo, “Optimizing over-the-air
virtual reality broadcast transmissions with low-latency feedback,” in
IEEE 5G World Forum (5G-WF), July 2018.

[31] N. Carlsson and D. Eager, “Had you looked where i’m looking:
Cross-user similarities in viewing behavior for 360 video and caching
implications,” arXiv preprint arXiv:1906.09779, 2019.

17

Mohammed S. Elbamby received the B.Sc. degree
(Hons.) in Electronics and Communications Engi-
neering from the Institute of Aviation Engineering
and Technology, Egypt, in 2010, the M.Sc. degree in
Communications Engineering from Cairo University,
Egypt, in 2013, and the Dr.Sc. Degree (with dis-
tinction) in Communications Engineering from the
University of Oulu, Finland, in 2019. He is currently
with Nokia Bell Labs in Espoo, Finland. Previously,
he held research positions at the University of Oulu,
Cairo University, and the American University in
Cairo. His research interests span resource optimization, network manage-
ment, and machine learning in wireless cellular networks. He received the
Best Student Paper Award from the European Conference on Networks and
Communications (EuCNC’2017).

Javier Del Ser (M’07-SM’12) received his ﬁrst
Ph.D. degree (cum laude) in Electrical Engineering
from the University of Navarra (Spain) in 2006, and
a second Ph.D. degree (cum laude, extraordinary
Ph.D. prize) in Computational Intelligence from
the University of Alcala (Spain) in 2013. He is
currently a Research Professor in Artiﬁcial Intelli-
gence at TECNALIA, Spain. He is also an adjunct
professor at the University of the Basque Coun-
try (UPV/EHU), an invited research fellow at the
Basque Center for Applied Mathematics (BCAM),
an a senior AI advisor at the technological startup SHERPA.AI. He is also
the coordinator of the Joint Research Lab between TECNALIA, UPV/EHU
and BCAM (http://jrlab.science), and the director of the TECNALIA Chair in
Artiﬁcial Intelligence implemented at the University of Granada (Spain). His
research interests gravitate on the design of artiﬁcial intelligence methods
for data mining and optimization problems emerging from Industry 4.0,
intelligent transportation systems, smart mobility, logistics and health, among
other ﬁelds of application. He has published more than 290 scientiﬁc articles,
co-supervised 10 Ph.D. theses, edited 7 books, co-authored 9 patents and
participated/led more than 40 research projects. He is an Associate Editor of
tier-one journals from areas related to data science and artiﬁcial intelligence
such as Information Fusion, Swarm and Evolutionary Computation and
Cognitive Computation.

Mehdi Bennis (S’07-AM’08-SM’15) is an Asso-
ciate Professor at the Centre for Wireless Commu-
nications (CWC), University of Oulu, Finland, an
Academy of Finland Research Fellow and head of
the Intelligent COnnectivity and Networks/systems
group (ICON). His main research interests are in ra-
dio resource management, heterogeneous networks,
game theory and machine learning in 5G networks
and beyond. He has co-authored one book and pub-
lished more than 200 research papers in international
journals and book chapters. He has
conferences,
been the recipient of several prestigious awards including the 2015 Fred
W. Ellersick Prize from the IEEE Communications Society, the 2016 Best
Tutorial Prize from the IEEE Communications Society, the 2017 EURASIP
Best paper Award for the Journal of Wireless Communications and Networks,
the all-University of Oulu award for research and the 2019 IEEE ComSoc
Radio Communications Committee Early Achievement Award. Dr Bennis is
an editor for the IEEE TRANSACTIONS ON COMMUNICATIONS.

[32] M. Chen, W. Saad et al., “Echo state transfer learning for data correlation
aware resource allocation in wireless virtual reality,” in Asilomar Conf.
Signals, Syst., and Comp., Oct. 2017.

[33] N. D. Sidiropoulos, T. N. Davidson, and Z.-Q. Luo, “Transmit beam-
forming for physical-layer multicasting,” IEEE Trans. Signal Process.,
vol. 54, no. 6, pp. 2239–2251, June 2006.

[34] 3GPP, “ETSI TR 138 901 V14.3.0: 5G; Study on channel model for
frequencies from 0.5 to 100 GHz (3GPP TR 38.901 version 14.3.0
release 14),” European Telecommunications Standards Institute (ETSI),
Tech. Rep., 2018.

[35] V. Raghavan, L. Akhoondzadeh-Asl et al., “Statistical blockage model-
ing and robustness of beamforming in millimeter-wave systems,” IEEE
Transactions on Microwave Theory and Techniques, 2019.

[36] J. Wildman, P. H. J. Nardelli et al., “On the joint impact of beamwidth
in directional wireless poisson
and orientation error on throughput
networks,” IEEE Trans. Wireless Commun., vol. 13, no. 12, pp. 7072–
7085, Dec. 2014.

[37] M. J. Neely, “Stochastic network optimization with application to
communication and queueing systems,” Synthesis Lect. on Commun.
Netw., vol. 3, no. 1, pp. 1–211, 2010.

[38] L. Georgiadis, M. J. Neely, and L. Tassiulas, Resource Allocation and
Cross-Layer Control in Wireless Networks, ser. Foundations and Trends
in Networking. Now Publishers Inc., 2006.

[39] A. Roth and M. Sotomayor, Two-sided matching: A study in game-

theoretic modeling and analysis. Cambridge University Press, 1992.

[40] Y. Gu, W. Saad et al., “Matching theory for future wireless networks:
fundamentals and applications,” IEEE Commun. Mag., vol. 53, no. 5,
pp. 52–59, May 2015.

[41] D. Gale and L. S. Shapley, “College admissions and the stability of

marriage,” Am. Math. Mon., vol. 69, no. 1, pp. 9–15, 1962.

[42] Z. Zhou, K. Ota et al., “Energy-efﬁcient matching for resource allocation
in d2d enabled cellular networks,” IEEE Trans. Veh. Technol., vol. 66,
no. 6, pp. 5256–5268, June 2017.

[43] B. Di, L. Song, and Y. Li, “Sub-channel assignment, power allocation,
and user scheduling for non-orthogonal multiple access networks,” IEEE
Trans. Wireless Commun., vol. 15, no. 11, pp. 7686–7698, Nov 2016.

[44] K. Cho, B. van Merriënboer et al., “Learning phrase representations
using RNN encoder–decoder for statistical machine translation,” in Proc.
Conf. Emp. Methods Natural Lang. Process. (EMNLP), Oct. 2014, pp.
1724–1734.

[45] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural

Comput., vol. 9, no. 8, pp. 1735–1780, Nov 1997.

[46] J. Chung, C. Gulcehre et al., “Empirical evaluation of gated recurrent
neural networks on sequence modeling,” in NIPS 2014 Wksh. on Deep
Learning, 2014.

[47] F. Chollet et al., “Keras,” https://keras.io, 2015.
[48] P. J. Werbos, “Backpropagation through time: what it does and how to

do it,” Proc. IEEE, vol. 78, no. 10, pp. 1550–1560, Oct 1990.

[49] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”

CoRR, vol. abs/1412.6980, 2014.

[50] W.-C. Lo, C.-L. Fan et al., “360◦ video viewing dataset in head-mounted
virtual reality,” in Proc. ACM Conf. on Multimedia Syst., 2017, pp. 211–
216.

Cristina Perfecto (S’15-AM’20) received her M.Sc.
in Telecommunication Engineering and Ph.D. (with
distinction) on Information and Communication
Technologies for Mobile Networks from the Uni-
versity of the Basque Country (UPV/EHU) in 2000
and 2019, respectively. She is currently an Associate
Professor with the Department of Communications
Engineering at this same University. During 2016,
2017 and 2018 she was a Visiting Researcher at
the Centre for Wireless Communications (CWC),
University of Oulu, Finland where she worked on
the application of multidisciplinary computational intelligence techniques in
millimeter wave communications radio resource management. Her current
research interests lie on the use of machine learning and data analytics,
including different ﬁelds such as metaheuristics and bio-inspired computation,
for resource optimization in 5G networks and beyond.

