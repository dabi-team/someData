Horizontal and Vertical Collaboration for VR
Delivery in MEC-Enabled Small-Cell Networks

Zhuojia Gu, Hancheng Lu, Senior Member, IEEE, and Chenkai Zou

1

1
2
0
2

p
e
S
5

]
I

N
.
s
c
[

1
v
1
7
9
1
0
.
9
0
1
2
:
v
i
X
r
a

Abstract—Due to the large bandwidth, low latency and com-
putationally intensive features of virtual reality (VR) video
applications, the current resource-constrained wireless and edge
networks cannot meet the requirements of on-demand VR deliv-
ery. In this letter, we propose a joint horizontal and vertical col-
laboration architecture in mobile edge computing (MEC)-enabled
small-cell networks for VR delivery. In the proposed architecture,
multiple MEC servers can jointly provide VR head-mounted
devices (HMDs) with edge caching and viewpoint computation
services, while the computation tasks can also be performed
at HMDs or on the cloud. Power allocation at base stations
(BSs) is considered in coordination with horizontal collaboration
(HC) and vertical collaboration (VC) of MEC servers to obtain
lower end-to-end latency of VR delivery. A joint caching, power
allocation and task ofﬂoading problem is then formulated, and
a discrete branch-reduce-and-bound (DBRB) algorithm inspired
by monotone optimization is proposed to effectively solve the
problem. Simulation results demonstrate the advantage of the
proposed architecture and algorithm in terms of existing ones.

Index Terms—VR delivery, horizontal and vertical collabora-

tion, MEC, end-to-end latency.

I.

INTRODUCTION

O N-DEMAND virtual reality (VR) applications require

ultra-large bandwidth, ultra-low latency and abundant
computation resources in delivery networks, which hinders
its widespread popularity in existing 5G networks [1]. By
providing caching and computation capabilities at the network
edge, mobile edge computing (MEC) can signiﬁcantly reduce
the transmission and computation delays, which are the main
components of the end-to-end latency of VR delivery [2], [3].
Existing works on MEC can be categorized into two types:
1) vertical collaboration (VC)-based MEC, and 2) horizontal
collaboration (HC)-based MEC. The VC-based MEC typi-
cally adopts a three-tier hierarchical architecture including the
terminal tier, the edge tier, and the cloud tier to conduct
collaborative caching and computation ofﬂoading strategies
[4]. In the scenario of VR delivery, the authors in [5], [6]
proposed the joint communications, caching and computation
(3C) modeling of a hierarchical VR delivery network archi-
tecture, and revealed the 3C resources trade-off for saving
communication bandwidth while meeting the low latency
requirement. On the other hand, considering that mobile edge
servers (MESs) are usually deployed sinking to the densely
deployed base stations (BSs) in 5G wireless networks [7],
[8], HC-based MEC has been proposed for higher utilization
efﬁciency of edge resources, facilitated by the higher speed
wireless connections in dense small-cell networks than that of
the backhaul link [9]. The authors in [10], [11] investigated
the HC strategies of caching or computation resources among

MESs, respectively, and the performance gains using HC in
terms of the service delay were validated.

From the discussion above, it is evident that both VC and
HC are effective methods to improve the performance of
delay-sensitive applications in wireless networks. Intuitively,
combining HC with VC in MEC-enabled small-cell networks
is a potential solution to further meet the stringent latency
requirement of computation-intensive VR applications. How-
ever, there is a lack of studies focusing on the joint HC
and VC-assisted MEC for VR video delivery. Considering the
speciﬁc characteristic of VR video delivery, the design of joint
HC and VC in MEC-enabled small-cell networks is non-trivial.
First, since the VR ﬁeld of views (FoVs) needs to be projected
and rendered from monocular videos (MVs) into stereoscopic
videos (SVs) before it can be presented at VR head-mounted
displays (HMDs), caching MVs in MESs can save the cache
capacity, but at
the cost of consuming more computation
resources. Considering limited caching and computation re-
sources in MESs, it is a critical issue to design HC-based
caching and task ofﬂoading strategies among MESs to reduce
the transmission and computation delays while considering the
VC task ofﬂoading aspects. Second, since HC and VC are to
be considered in collaboration to further improve the end-to-
end latency performance for VR delivery, it will incur a trade-
off issue between HC and VC for collaborative caching and
task ofﬂoading. In addition, power allocation in dense small-
cell networks has a great impact on the transmission rates of
wireless links. In the case of limited power resources at BSs,
power allocation should be reconsidered in coordination with
joint HC and VC-based caching and task ofﬂoading strategies
to achieve lower total latency for VR delivery.

In this letter, we propose a joint HC and VC architecture
in MEC-enabled small-cell networks for VR delivery. A novel
task ofﬂoading problem with consideration of collaborative
caching and power allocation is formulated with the aim
of minimizing the end-to-end latency for VR delivery. A
joint caching, power allocation and task ofﬂoading algorithm
envisioned by discrete monotone optimization is proposed to
effectively solve the problem. Numerical simulations have
been conducted to justify the effectiveness of the joint HC and
VC architecture for VR delivery and show that the proposed
JCPT algorithm outperforms the benchmark algorithms.

II. SYSTEM MODEL

A. Network Architecture

The proposed network architecture is shown in Fig. 1. There
are M small-cell base stations (SBSs) equipped with MEC

 
 
 
 
 
 
αdi. Considering the caching capacity constraints at MESs
and HMDs, we have

2

N
(cid:88)

i=1

(cM,M

im + αcM,S

im )di ≤ CM

m , ∀m ∈ M,

N
(cid:88)

i=1

(cV,M

iu + αcV,S

iu )di ≤ C V

u , ∀u ∈ U.

(4)

(5)

i = kM f 2

MESs and VR HMDs are all equipped with computation
resources. According to [14], if the computation process is
executed on an MES, the consumed computation energy to
project MV i into SV i can be calculated as eM
M diwi,
where kM is the energy efﬁciency coefﬁcient related to the
computing process unit (CPU) architecture of the MES, fm is
the CPU frequency of the MES, and wi is the required CPU
cycles of projection MV i into SV i for 1 bit. Then the compu-
tation delay on the MES to process MV i can be calculated as
i = diwi
τ M
. On the other hand, if the computation process is
fM
executed on a VR HMD, the consumed computation energy is
eV
i = kV f 2
V diwi, and the corresponding computation delay is
i = diwi
τ V
. Assume that the requested probabilities of all the
fV
viewpoints conforms to the Zipf distribution, i.e., the requested
probability of viewpoint i is qi = 1/iλ
j=1 1/jλ , where λ reﬂects
the preference skewness of the Zipf distribution. To ensure that
the average energy consumption of each MES or HMD does
m or EV
not exceed the threshold EM

u , respectively, we have

(cid:80)N

U
(cid:88)

N
(cid:88)

u=1

i=1

qi(1 − cM,S

im )eM
i

I(cid:8) (cid:80)M

imu=1(cid:9) ≤ EM

m=1 T M

m , ∀m ∈ M,

(6)

N
(cid:88)

qi(1 − cV,S

iu )eV
i

I(cid:8) (cid:80)M

i=1

m=1 T M

imu+T C

imu=0(cid:9) ≤ EV

u , ∀u ∈ U,

(7)
where I{·} is an indicator function, i.e., I{z} = 1 if condition
z is true, and zero otherwise.

Each SBS allocates transmission power to the associated
HMDs, denoted by pmu. Assuming universal frequency reuse
among SBSs, according to Shannon’s formula, the downlink
wireless link rate Rmu from SBSs m to HMD u can be
expressed as

Rmu = W log2(1 + γmu(p)),

(8)

where W is the bandwidth allocated to HMD u, γmu(p) (cid:44)
pmuhmu
, hmu is the channel gain between
IInter−cell+ ζIIntra−cell+n0
SBS m and HMD u, n0 is the additive white Gaussian noise
(AWGN) power. The inter-cell and intra-cell
interferences
can be calculated as IInter−cell = (cid:80)b∈M
v(cid:54)=u pbvhbv and
IIntra−cell = (cid:80)v∈U
v(cid:54)=u pmvhmv, respectively, where ζ ∈ [0, 1] is
the orthogonality factor that represents the capability of intra-
cell interference cancelation at the HMD. Considering the total
power constraint PT at SBS m, we have

(cid:80)v∈U

b(cid:54)=m

U
(cid:88)

u=1

pmu ≤ PT , ∀m ∈ M.

(9)

Fig. 1. A joint horizontal and vertical collaboration architecture in MEC-
enabled small-cell networks for VR delivery.

servers (MESs) in the network denoted by an index set M =
{1, ..., M }, with each MES m ∈ M. The VR head-mounted
devices (HMDs) are denoted by an index set U = {1, ..., U },
with each HMD u ∈ U. The set of all viewpoints of VR videos
is denoted by N = {1, ..., N }, and each viewpoint i ∈ N
corresponds to a MV and a SV. MVs should be projected and
rendered into SVs by using the computation resources at MESs
or HMDs, thus the size of the SV version of viewpoint i should
be α(α > 2) times larger than that of the corresponding MV
version.

Due to the densiﬁcation of small-cell networks, a HMD can
be within the coverage of multiple SBSs, thus the viewpoints
can be retrieved from multiple SBSs caching the required MVs
or SVs, and the computation task of projecting MVs into
SVs can also be processed on multiple MESs. The multiple
connections of a HMD to SBSs can be realized by adopting the
multi-connectivity technology proposed in 3GPP speciﬁcation
[12], [13]. Let T M
imu ∈ {0, 1} denote whether the computation
task of the i-th MV on HMD u is ofﬂoaded to MES m.
Similarly, let T C
imu denote whether the computation task of
the i-th MV on HMD u is ofﬂoaded to the cloud service via
MES m. Assume that the ofﬂoading task for each viewpoint
is performed at one server, thus we have

imu + T C
T M

imu ≤ 1, ∀i ∈ N , ∀m ∈ M, ∀u ∈ U,

M
(cid:88)

m=1

M
(cid:88)

m=1

T M
imu ≤ 1, ∀i ∈ N , ∀u ∈ U,

T C
imu ≤ 1, ∀i ∈ N , ∀u ∈ U.

(1)

(2)

(3)

B. 3C Resource Model

im , cM,S

u , respectively. Let cM,M

SBSs and HMDs are equipped with caching capacity of
CM
u and C V
im ∈ {0, 1} denote
whether the MV or SV version of viewpoint i is cached on
MES m, respectively. Similarly, let cV,M
iu ∈ {0, 1} denote
whether the MV or SV version of viewpoint i is cached on
VR HMD u. The size of the MV version of viewpoint i
is denoted as di, then the size of the corresponding SV is

iu , cV,S

MEC serverCore NetworkHMDCentral OfficeCloud ServerCached SVsCached MVsLocal CPUSBSsCached viewpoint transmissionNon-cached viewpointtransmissionBackhaul linkC. HC and VC Task Ofﬂoading Model

A HMD can be associated to multiple SBSs simultaneously
to fetch the cached viewpoints and utilize the computation
resources on multiple MESs, which is referred to as horizontal
collaboration (HC) among MESs. Assume that the end-to-end
latency of VR delivery mainly includes the transmission delay
and the computation delay. Given the task ofﬂoading variable
T M
imu and the caching status of viewpoint i at MES m, the
end-to-end latency for HMD u requesting viewpoint i from
MES m can be calculated as
(cid:18) cM,M
im diwi
fM

αdi
Rmu

τ M
iu =

T M
imu.

M
(cid:88)

(10)

+

(cid:19)

m=1

Note that the task can be ofﬂoaded to MES m can only when
the MV or SV is cached at MES m. Thus we have the coupled
caching and task ofﬂoading constraint,
im )(1 − cM,S
imu(1 − cM,M
T M

im ) < 1, ∀i ∈ N , ∀m ∈ M, ∀u ∈ U.
(11)
On the other hand, computation task can also be im-
plemented locally at
the HMD, or be ofﬂoaded to cloud
server, which is referred to as vertical collaboration (VC).
Accordingly, if the computation task is implemented at the
HMD, the end-to-end latency just includes the computation
delay, which can be calculated as

iu = I(cid:8) (cid:80)M
τ V

imu=0(cid:9)

cV,M
iu diwi
fV

.

m=1 T M

imu+T C
imu = 0 can hold only when cV,M

iu =

(12)

Note that (cid:80)M
1 or cV,S
imu + T C
T M

m=1 T M
imu+T C
iu = 1, i.e., we have
iu + cV,S
imu + cV,M

iu > 0, ∀i ∈ N , ∀m ∈ M, ∀u ∈ U.
(13)
Otherwise, the requested viewpoint should be fetched via the
cloud server, and it would incur an additional backhaul retriev-
ing delay τb, thus the end-to-end latency can be calculated as
(cid:18) α di
Rmu

T C
imu.

τ C
iu =

M
(cid:88)

+ τb

(14)

(cid:19)

m=1

Taking consideration of collaborated HC and VC of the
MESs and the HMDs in the network, the end-to-end latency
for HMD u requesting viewpoint i can be written as

τiu = τ M

iu + τ V

iu + τ C
iu.

(15)

III. PROBLEM FORMULATION AND SOLUTION
In this letter, we aim to minimize the average end-to-end
latency of VR delivery based on the collaborated HC and
VC architecture by jointly considering the caching, power
allocation and task ofﬂoading strategies. Thus, the proposed
optimization problem can be formulated as follows,

3

Problem (16) is a mixed integer nonlinear programming
problem (MINLP), which is hard to solve in general. In the
following, we exploit the hidden monotonicity of the problem
and utilize the monotonic optimization method to solve the
problem effectively.

A. Monotonicity Analysis and Problem Transformation

im

imu, T C

and the task ofﬂoading variables T M

It can be observed that the objective function (16a) mono-
tonically increases with the increase of the caching variables
iu , cM,M
cV,M
imu.
However, (16a) is not a monotonic function of the power
allocation variables pmu. Nevertheless, inspired by the concept
of exploiting the hidden monotonicity in the objective function
using the general linear fractional programming (GLFP) [15],
(16a) is actually a monotonically decreasing function of the
positive-valued function γmu(p). More speciﬁcally, for ﬁxed
caching and task ofﬂoading variables, Problem (16) is equiv-
alent to

U
(cid:88)

N
(cid:88)

qiτiu(y)

u=1

i=1
y ∈ G,

min
y

s.t.

(17a)

(17b)

where G = {y|0 ≤ ymu ≤ γmu(p), ∀m ∈ M, ∀u ∈ U, (9)}.
Then, we should transform Problem (16) into the form of a
monotonic optimization problem.

Deﬁnition (Monotonic Optimization) [16]: An optimization
problem can be classiﬁed as a monotonic optimization (MO)
problem if it can be written in the following canonical form,

{f (x) | x ∈ G ∩ H}, x ∈ [a, b],

max
x
where x ∈ Rn
+, f : Rn
+, [a, b] ⊂ Rn
increasing function of x, G ⊂ Rn
nonempty interior, and H is a conormal set in [0, b].

+ → R is a monotonic
+ is a normal set with

(18)

Based on the above monotonicity analysis of Problem
(16), it is observed that the monotonicity of the objective
function (16a) with respect to the caching and task ofﬂoading
variables is the opposite of that with respect to the power
allocation variables. According to the deﬁnition of monotonic
optimization, the objective function to be minimized should
be a monotonically decreasing function with respect to the
optimization variables. Thus, variable substitutions are made
for the caching and task ofﬂoading variables to meet
the
(cid:44) 1 − cV,M
monotonic requirements. Speciﬁcally, let ¯cV,M
iu ,
and ¯cM,M
im for the caching variables, and similar
substitutions can be done to the task ofﬂoading variables
T M
imu, T C
imu. Besides, it can be inferred that the constraints
of Problem (16) forms the intersection of a normal set and a
conormal set. Then Problem (16) can be equivalently trans-
formed into a monotonic optimization problem.

(cid:44) 1 − cM,M

im

iu

U
(cid:88)

N
(cid:88)

u=1

i=1

qiτiu

{cV,M

iu ,cV,S
pmu,T M

im ,cM,S
im ,
imu}

min
iu ,cM,M
imu,T C
s.t.

im , cM,S

iu , cM,M
cV,M
iu ,cV,S
imu,T C
T M
imu ∈ {0, 1},
(1)−(9), (11), (13).

im ∈ {0, 1},

(16a)

(16b)

(16c)

B. Proposed Algorithm Based on DBRB

For the monotonic optimization problem, the most widely
adopted algorithm is the polyblock outer approximation (POA)
approach [16], which attempts to construct a sequence of poly-
blocks on the boundary of the constraints to approximate the
optimal solution of continuous variables. However, Problem

(16) cannot be solved using the POA approach since it involves
the discrete caching and task ofﬂoading optimization variables.
A discrete branch-reduce-and-bound (DBRB) algorithm was
proposed in [17] to deal with the discrete variables in a
monotonic optimization problem. The DBRB algorithm draws
on the idea of the standard branch-and-bound algorithm that
using box1 division based on three basic operations at each
iteration: branching, reduction, and bounding, to converge to
a near-optimal solution rapidly. In this letter, we propose
an improved DBRB algorithm that adapts to the speciﬁc
properties of Problem (16).

max and f (n)

The proposed joint caching, power control and task of-
ﬂoading (JCPT) algorithm based on the DBRB framework is
outlined in Algorithm 1, where Bn, f (n)
min represents
the set of boxes, the upper bound and the lower bound, respec-
tively. r(·) represents the reduction operation for a box. in the
nth iteration. On the basis of three basis operations at each
iteration, we have made two improvements considering the
properties of the problem to accelerate the solution searching
process. First, the branching and reduction operations in steps
6-8 can be improved considering that the caching and task
ofﬂoading variables are all binary variables. Speciﬁcally, given
a Box [a, b] ⊂ {0, 1}n, if bk−ak = 1, we can branch on its kth
dimension and obtain two new Box [a, a(cid:48)] and [b(cid:48), b], where
the value of each dimension of a(cid:48) is the same as that of b(cid:48)
except that the kth dimension of a(cid:48)
k is 0, and the kth dimension
b(cid:48)
k is 1. Thus, the dimension of each branched box is reduced
by one, which reduces the searching space. Also, the reduction
operation can also be improved using the same technique.
Second, the bounding operation in step 11 can be improved
considering the binary feature of the task ofﬂoading variables.
In the standard DBRB framework, the bounding operation is
to ﬁnd a projection point of the upper right vertex of a box
on the constraint curve, then the projection point serves as the
lower bound of the solution, and the L-shaped area around
the projection point serves as the upper bound of the solution.
Nevertheless, the binary task ofﬂoading variables make the
projection point not be a feasible solution. Alternatively, a
heuristic algorithm can be adopted to ﬁnd a tighter upper and
lower bound of the solution, e.g., by randomly assigning the
MEC task ofﬂoading solution and obtain the joint caching and
power allocation solution using a greedy algorithm. Thus, a
feasible solution utilized to compute the upper or lower bound
can be obtained.

IV. PERFORMANCE EVALUATION

Simulations are carried out to validate the proposed joint HC
and VC network architecture for VR delivery. The simulations
are conducted in a square area of 100 m × 100 m, where
40 SBSs and 100 HMDs are distributed in this area unless
otherwise stated. There are a total of 100 VR viewpoints
ranging in size from 10 Mb to 30 Mb. The maximum transmit
power of SBSs is 30 dBm, and the downlink bandwidth is
set to 1 GHz. For the sake of comparison, four benchmark
algorithms are listed as follows. 1) Nearest Ofﬂoading (NO):

1As deﬁned in [16], a box [a, b] is the set of all x ∈ Rn that satisﬁes

a ≤ x ≤ b. A box is also referred to as a hyper-rectangle.

Algorithm 1 The JCPT algorithm

4

1: Input: a, b;
2: Initialization: B1 = {r[a, b]}, n ← 1, f (1)

min ← 0,

f (1)
max ← +∞, γ ← +∞
3: while not converged do
4:

5:

6:
7:
8:
9:
10:

11:

12:
13:
14:

15:
16:
17:

n ← n + 1;
Select Box Bs that has the maximum upper bound of
objective function in Bn−1;
Branch on Box Bs to obtain Box B(1)
s
if B(k)
s

is feasible and contains a better solution then

and B(2)
s ;

Compute r(B(k)

s ), k ∈ {1, 2};

end if
if r(B(k)

s ) is feasbile then

Adopt a heuristic algorithm to compute the upper and
lower bounds in this iteration;
min and f (n)
Update f (n)

max, k ∈ {1, 2};

end if
if f (n)

max < γ then
Update γ ← f (n)

max and record the solution x∗.

end if
Add the feasible box in r(B(1)
and remove Box Bs;

s ) and r(B(2)

s ) into Bn−1

18: Bn ← Bn−1;
19: end while
20: Output (x∗, γ);

(a)

(b)

Fig. 2. Sum of delays versus (a) caching capacity on a MES, and (b) number
of SBSs.

a task is ofﬂoaded to the nearest MES if the local caching
or computation resources cannot meet the requirements. In
other words, HC is not adopted in this algorithm; 2) Power
Equally Allocation (PEA): transmit power is equally allocated
among HMDs within coverage, then the caching and task
ofﬂoading strategies are jointly optimized; 3) Popularity-ﬁrst
(PF): MESs and HMDs cache the most popular viewpoints,
then the task ofﬂoading and power allocation strategies are
jointly optimized; 4) Least Recently Used (LRU): a classical
caching placement algorithm that substitutes the least recently
requested MVs or SVs.

Fig. 2 shows the sum of delays with respect to the MES
caching capacity and the number of SBSs using different
algorithms. It
the proposed JCPT algo-
rithm achieves the lowest sum of delays in various net-
work parameters. The NO algorithm achieves the second
best delay performance, while the PF algorithm achieves the

is observed that

1020304050603.43.63.84.04.24.44.64.85.0Sum of Delays (s)Caching Capacity on MES (%) JCPT NO PEA PF LRU2030405060702.02.53.03.54.04.55.0Sum of Delays (s)Number of SBSs JCPT NO PEA PF LRUworst performance. This is because the proposed algorithm
comprehensively considers the HC and VC in wireless and
edge networks, especially making full use of the overlapping
coverage characteristics of dense small cell networks, so
that the utilization of communication, caching and computing
resources for VR delivery can be maximized. In contrast, the
NO algorithm is based on the classical nearby association and
task ofﬂoading principles, which does not make full use of the
HC among multiple MESs, and only considers VC to ofﬂoad
local tasks to the MESs or the cloud server, thus resulting in
performance degradation. The PEA algorithm does not take
into consideration the coupling relationship between wireless
transmit power and heterogeneous caching and computation
resources on the MESs, so the sum of delays is even higher.
The PF algorithm is a greedy heuristic algorithm which does
not consider the characteristics of VR videos, so it fails to
obtain a better strategy in the decision of caching MVs or
SVs of different viewpoints, which results in the highest the
delay performance.

(a)

(b)

Fig. 3. Cache Hit ratio versus (a) caching capacity on a MES, and (b) the
zipf parameter.

Fig. 3 shows the cache hit ratio with respect to the MES
cache capacity and the zipf viewpoint popularity parameter
with different algorithms. It can be seen that the proposed
JCPT algorithm achieves the highest cache hit ratio. Com-
bining with the observation in Fig. 2,
it can be inferred
that a higher cache hit ratio will lead to a lower sum of
delays, which indicates the importance of an edge caching
hit event to reduce the end-to-end latency of VR delivery
over MEC-enabled small cell networks. Since the proposed
JCPT algorithm exploits the multi-connectivity advantage of
a HMD associated to multiple SBSs, the HMD can obtain the
requested viewpoints directly from different MESs. Therefore,
the JCPT algorithm takes advantage of this characteristic
in making caching strategies, which can be viewed as a
collaborative caching strategy among MESs. Meanwhile, the
computation requirements of VR videos have been jointly
considered with the computation resources on MESs and
wireless resources of SBSs using the JCPT algorithm, thus
providing a higher cache hit ratio and reducing the end-to-end
latency of VR delivery.

V. CONCLUSION

In this letter, we design a collaborative HC and VC
architecture in MEC-enabled small cell networks for low-
latency on-demand VR delivery. A joint horizontal and vertical

5

task ofﬂoading model
is introduced with consideration of
caching and wireless communication resources to fully exploit
the advantage of small cell networks for VR delivery. The
hidden monotonicity of the formulated end-to-end latency
minimization problem is analyzed and an improved DBRB-
based algorithm is designed to efﬁciently solve the problem.
Simulation results validate the effectiveness of the proposed
JCPT algorithm in comparison with the existing benchmark
algorithms and show great promise of the proposed joint HC
and VC architecture for improving the quality of VR delivery
over MEC-enabled small cell networks.

REFERENCES

[1] M. Hosseini, “View-aware tile-based adaptations in 360 virtual reality
video streaming,” in 2017 IEEE Virtual Reality (VR), Los Angeles, CA,
2017, pp. 423–424.

[2] X. Liu and Y. Deng, “Learning-based prediction,

rendering and
association optimization for MEC-enabled wireless virtual
reality
(VR) network,” IEEE Transactions on Wireless Communications, doi:
10.1109/TWC.2021.3073623.

[3] Y. Qian, R. Wang, J. Wu, B. Tan, and H. Ren, “Reinforcement learning-
based optimal computing and caching in mobile edge network,” IEEE
Journal on Selected Areas in Communications, vol. 38, no. 10, pp. 2343–
2355, 2020.

[4] N. Abbas, Y. Zhang, A. Taherkordi, and T. Skeie, “Mobile edge
computing: A survey,” IEEE Internet of Things Journal, vol. 5, no. 1,
pp. 450–465, 2018.

[5] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, caching, and
computing for mobile virtual reality: Modeling and tradeoff,” IEEE
Transactions on Communications, vol. 67, no. 11, pp. 7573–7586, 2019.
[6] T. Dang and M. Peng, “Joint radio communication, caching, and
computing design for mobile virtual reality delivery in fog radio access
networks,” IEEE Journal on Selected Areas in Communications, vol. 37,
no. 7, pp. 1594–1607, 2019.

[7] H. Wu and H. Lu, “Delay and power tradeoff with consideration of
caching capabilities in dense wireless networks,” IEEE Transactions on
Wireless Communications, vol. 18, no. 10, pp. 5011–5025, 2019.
[8] Z. Gu, H. Lu, M. Zhang, H. Sun, and C. W. Chen, “Association
and caching in relay-assisted mmWave networks: From a stochastic
geometry perspective,” IEEE Transactions on Wireless Communications,
doi: 10.1109/TWC.2021.3091815.

[9] K. Wang, H. Yin, W. Quan, and G. Min, “Enabling collaborative edge
computing for software deﬁned vehicular networks,” IEEE Network, vol.
32, no. 5, pp. 112–117, 2018.

[10] Y. M. Saputra, D. T. Hoang, D. N. Nguyen, and E. Dutkiewicz, “A
novel mobile edge network architecture with joint caching-delivering
and horizontal cooperation,” IEEE Transactions on Mobile Computing,
vol. 20, no. 1, pp. 19–31, 2021.

[11] P. Dai, K. Hu, X. Wu, H. Xing, F. Teng, and Z. Yu, “A probabilis-
tic approach for cooperative computation ofﬂoading in MEC-assisted
vehicular networks,” IEEE Transactions on Intelligent Transportation
Systems, pp. 1–13, 2020.

[12] 3GPP, “Evolved universal terrestrial radio access (E-UTRA) and NR;
Multi-connectivity,” (Release 16), 3GPP TS 37.340, V16.6.0, 2021.
[13] A. Wolf, P. Schulz, M. Dorpinghaus, J. C. S. S. Filho, and G. Fettweis,
“How reliable and capable is multi-connectivity?,” IEEE Transactions
on Communications, vol. 67, no. 2, pp. 1506–1520, 2019.

[14] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey
on mobile edge computing: The communication perspective,” IEEE
Communications Surveys & Tutorials, vol. 19, no. 4, pp. 2322–2358,
2017.

[15] Y. J. A. Zhang, L. Qian, and J. Huang, “Monotonic optimization in
communication and networking systems,” Foundations and Trends in
Networking, vol. 7, no. 1, pp. 1–75, 2013.

[16] H. Tuy, “Monotonic optimization: Problems and solution approaches,”
SIAM Journal on Optimization, vol. 11, no. 2, pp. 464–494, 2000.
[17] H. Tuy, M. Minoux, and N. T. Hoai-Phuong, “Discrete monotonic
optimization with application to a discrete location problem,” SIAM
Journal on Optimization, vol. 17, no. 1, pp. 78–97, 2007.

1020304050600.00.20.40.60.81.0Cache Hit RatioCaching Capacity on MES (%) JCPT NO PEA PF LRU0.60.81.01.21.41.61.82.00.10.20.30.40.50.60.70.80.9Cache Hit RatioZipf Parameter  JCPT NO PEA PF LRU