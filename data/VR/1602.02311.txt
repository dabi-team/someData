6
1
0
2

t
c
O
8
2

]
L
M

.
t
a
t
s
[

3
v
1
1
3
2
0
.
2
0
6
1
:
v
i
X
r
a

Rényi Divergence Variational Inference

Yingzhen Li
University of Cambridge
Cambridge, CB2 1PZ, UK
yl494@cam.ac.uk

Richard E. Turner
University of Cambridge
Cambridge, CB2 1PZ, UK
ret26@cam.ac.uk

Abstract

This paper introduces the variational Rényi bound (VR) that extends traditional vari-
ational inference to Rényi’s α-divergences. This new family of variational methods
uniﬁes a number of existing approaches, and enables a smooth interpolation from
the evidence lower-bound to the log (marginal) likelihood that is controlled by the
value of α that parametrises the divergence. The reparameterization trick, Monte
Carlo approximation and stochastic optimisation methods are deployed to obtain a
tractable and uniﬁed framework for optimisation. We further consider negative α
values and propose a novel variational inference method as a new special case in
the proposed framework. Experiments on Bayesian neural networks and variational
auto-encoders demonstrate the wide applicability of the VR bound.

1

Introduction

Approximate inference, that is approximating posterior distributions and likelihood functions, is at the
core of modern probabilistic machine learning. This paper focuses on optimisation-based approximate
inference algorithms, popular examples of which include variational inference (VI), variational Bayes
(VB) [1, 2] and expectation propagation (EP) [3, 4]. Historically, VI has received more attention
compared to other approaches, although EP can be interpreted as iteratively minimising a set of local
divergences [5]. This is mainly because VI has elegant and useful theoretical properties such as the
fact that it proposes a lower-bound of the log-model evidence. Such a lower-bound can serve as
a surrogate to both maximum likelihood estimation (MLE) of the hyper-parameters and posterior
approximation by Kullback-Leibler (KL) divergence minimisation.

Recent advances of approximate inference follow three major trends. First, scalable methods,
e.g. stochastic variational inference (SVI) [6] and stochastic expectation propagation (SEP) [7, 8],
have been developed for datasets comprising millions of datapoints. Recent approaches [9, 10, 11]
have also applied variational methods to coordinate parallel updates arising from computations
performed on chunks of data. Second, Monte Carlo methods and black-box inference techniques have
been deployed to assist variational methods, e.g. see [12, 13, 14, 15] for VI and [16] for EP. They all
proposed ascending the Monte Carlo approximated variational bounds to the log-likelihood using
noisy gradients computed with automatic differentiation tools. Third, tighter variational lower-bounds
have been proposed for (approximate) MLE. The importance weighted auto-encoder (IWAE) [17]
improved upon the variational auto-encoder (VAE) [18, 19] framework, by providing tighter lower-
bound approximations to the log-likelihood using importance sampling. These recent developments
are rather separated and little work has been done to understand their connections.

In this paper we try to provide a uniﬁed framework from an energy function perspective that
encompasses a number of recent advances in variational methods, and we hope our effort could
potentially motivate new algorithms in the future. This is done by extending traditional VI to Rényi’s
α-divergence [20], a rich family that includes many well-known divergences as special cases. After
reviewing useful properties of Rényi divergences and the VI framework, we make the following
contributions:

29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.

 
 
 
 
 
 
Table 1: Special cases in the Rényi divergence family.

α

Deﬁnition

α

1

→
α = 0.5

0

α

→
α = 2

α

+

∞

→

p(θ) log p(θ)

q(θ) dθ

(cid:82)
2 log(1

Hel2[p

q])

−

−

||

log

−
p(θ)>0 q(θ)dθ
χ2[p
(cid:82)
log(1
||
p(θ)
q(θ)

−
−
log maxθ

q])

Θ

∈

||

p]) and EP (KL[p

Notes
Kullback-Leibler (KL) divergence,
q])
used in VI (KL[q
function of the square Hellinger distance
zero when supp(q)
(not a divergence)
proportional to the χ2-divergence
worst-case regret in
minimum description length principle [24]

supp(p)

⊆

||

•

•

•

We introduce the variational Rényi bound (VR) as an extension of VI/VB. We then discuss
connections to existing approaches, including VI/VB, VAE, IWAE [17], SEP [7] and black-box
alpha (BB-α) [16], thereby showing the richness of this new family of variational methods.
We develop an optimisation framework for the VR bound. An analysis of the bias introduced
by stochastic approximation is also provided with theoretical guarantees and empirical results.
We propose a novel approximate inference algorithm called VR-max as a new special case.
Evaluations on VAEs and Bayesian neural networks show that this new method is often
comparable to, or even better than, a number of the state-of-the-art variational methods.

2 Background

This section reviews Rényi’s α-divergence and variational inference upon which the new framework
is based. Note that there exist other α-divergence deﬁnitions [21, 22] (see appendix). However we
mainly focus on Rényi’s deﬁnition as it enables us to derive a new class of variational lower-bounds.

2.1 Rényi’s α-divergence

∈

(1)

We ﬁrst review Rényi’s α-divergence [20, 23]. Rényi’s α-divergence, deﬁned on
1,

, measures the “closeness” of two distributions p and q on a random variable θ

α : α > 0, α
{

< +

=
Θ:

Dα|
|

∞}

Dα[p

q] =

log

p(θ)αq(θ)1

αdθ.

−

1

||

(cid:90)

≤

−
∞

1
by continuity. We note that when α

α
The deﬁnition is extended to α = 0, 1, +
1 the Kullback-
Leibler (KL) divergence is recovered, which plays a crucial role in machine learning and information
theory. Some other special cases are presented in Table 1. The method proposed in this work also
considers α
0 (although (1) is no longer a divergence for these α values), and we include from
[23] some useful properties for forthcoming derivations.
Proposition 1. (Monotonicity) Rényi’s α-divergence deﬁnition (1), extended to negative α, is contin-
< Dα < +
uous and non-decreasing on α
Proposition 2. (Skew symmetry) For α
0, 1
}
[p
Dα[p

(cid:54)∈ {
0 for α < 0. For the limiting case D

.
∞}
, Dα[p
q] =

−∞
A critical question that is still in active research is how to choose a divergence in this rich family to
obtain optimal solution for a particular application, an issue which is discussed in the appendix.

q] = α
α D1
||
−
−
p].
D+
||
−

p]. This implies

−∞

1
[q

∈ {

α[q

α :

→

≤

q]

∞

||

||

||

2.2 Variational inference

Next we review the variational inference algorithm [1, 2] using posterior approximation as a running
N
example. Consider observing a dataset of N i.i.d. samples
n=1 from a probabilistic model
θ) parametrised by a random variable θ that is drawn from a prior p0(θ). Bayesian inference
p(x
|
involves computing the posterior distribution of the parameters given the data,

xn}

=

D

{

p(θ

|D

, ϕ) =

p(θ,
p(

ϕ)

D|

ϕ)

D|

θ, ϕ)

N

n=1 p(xn|
ϕ)
p(
(cid:81)
D|

p0(θ

ϕ)

|

=

2

,

(2)

(cid:54)
(a) Approximated posterior.

(b) Hyper-parameter optimisation.

Figure 1: Mean-Field approximation for Bayesian linear regression.
observation noise variance. The bound is tight as σ

In this case ϕ = σ the
, biasing the VI solution to large σ values.

+

→

∞

N

|

(cid:82)

D|

ϕ)

p0(θ

ϕ) =

n=1 p(xn|

where p(
θ, ϕ)dθ is called marginal likelihood or model evidence.
The hyper-parameters of the model are denoted as ϕ which might be omitted henceforth for notational
ease. For many powerful models the exact posterior is typically intractable, and approximate inference
introduces an approximation q(θ) in some tractable distribution family
to the exact posterior. One
Q
way to obtain this approximation is to minimise the KL divergence KL[q(θ)
)], which is
also intractable due the difﬁcult term p(
). Variational inference (VI) sidesteps this difﬁculty by
considering an equivalent optimisation problem that maximises the variational lower-bound:

p(θ

|D

(cid:81)

D

||

LVI(q;

D

, ϕ) = log p(

ϕ)

D|

KL[q(θ)

p(θ

||

−

|D

, ϕ)] = Eq

log

(cid:20)

p(θ,

ϕ)

D|
q(θ)

.

(cid:21)

(3)

The variational lower-bound can also be used to optimise the hyper-parameters ϕ.

To illustrate the approximation quality of VI we present a mean-ﬁeld approximation example to
Bayesian linear regression in Figure 1(a) (in magenta). Readers are referred to the appendix for
details, but essentially a factorised Gaussian approximation is ﬁtted to the true posterior, a correlated
Gaussian in this case. The approximation recovers the posterior mean correctly, but is over-conﬁdent.
Moreover, as
LVI is the difference between the marginal likelihood and the KL divergence, hyper-
parameter optimisation can be biased away from the exact MLE towards the region of parameter
space where the KL term is small [25] (see Figure 1(b)).

3 Variational Rényi bound

Recall from Section 2.1 that the family of Rényi divergences includes the KL divergence. Perhaps
variational free-energy approaches can be generalised to the Rényi case? Consider approximating
)] for some selected
the exact posterior p(θ
) by minimizing Rényi’s α-divergence Dα[q(θ)
)],
Dα[q(θ)
α > 0. Now we consider the equivalent optimization problem maxq
= 1, whose objective can be rewritten as
and when α

||
log p(

|D
)
−

p(θ

p(θ

|D

|D

∈Q

D

||

Lα(q;

D

) :=

1

1

−

α

log Eq

)

p(θ,

D
q(θ)

(cid:34)(cid:18)

α

1

−

(cid:19)

.

(cid:35)

(4)

≤

We name this new objective the variational Rényi (VR) bound. Importantly the above deﬁnition can
be extend to α
0, and the following theorem is a direct result of Proposition 1.
Theorem 1. The objective
D
Especially for all 0 < α+ < 1 and α
LVI(q;
) = log p(

) is continuous and non-increasing on α

) if and only if the support supp(p(θ

≤ Lα
supp(q(θ)).

≤ L0(q;
))

≤ Lα+(q;

) = lim
α
→

1 Lα(q;

Lα(q;

|Lα|

< 0,

< +

Also

∞}

∈ {

α :

(q;

D

D

D

D

D

−

)

)

)

)

−

.

L0(q;

D

D

|D

⊆

Theorem 1 indicates that the VR bound can be useful for model selection by sandwiching the marginal
likelihood with bounds computed using positive and negative α values, which we leave to future
) under the mild assumption that q is supported where the exact
work. In particular

L0 = log p(

D

3

(VI)(cid:54)
posterior is supported. This assumption holds for many commonly used distributions, e.g. Gaussians
are supported on the entire space, and in the following we assume that this condition is satisﬁed.

∞

→ −∞

Choosing different alpha values allows the approximation to balance between zero-forcing (α
→
+
, when using uni-modal approximations it is usually called mode-seeking) and mass-covering
(α
) behaviour. This is illustrated by the Bayesian linear regression example, again in Figure
1(a). First notice that α
(in cyan) returns non-zero uncertainty estimates (although it is more
over-conﬁdent than VI) which is different from the maximum a posteriori (MAP) method that only
returns a point estimate. Second, setting α = 0.0 (in green) returns q(θ) =
) and the exact
marginal likelihood log p(
) (Figure 1(b)). Also the approximate MLE is less biased for α = 0.5 (in
(cid:81)
blue) since now the tightness of the bound is less hyper-parameter dependent.

i p(θi|D

→

∞

+

D

4 The VR bound optimisation framework

This section addresses several issues of the VR bound optimisation by proposing further approxi-
mations. First when α
= 1, the VR bound is usually just as intractable as the marginal likelihood
for many useful models. However Monte Carlo (MC) approximation is applied here to extend the
set of models that can be handled. The resulting method can be applied to any model that MC-VI
[12, 13, 14, 15] is applied to. Second, Theorem 1 suggests that the VR bound is to be minimised
when α < 0, which performs disastrously in MLE context. As we shall see, this issue is solved also
by the MC approximation under certain conditions. Third, a mini-batch training method is developed
for large-scale datasets in the posterior approximation context. Hence the proposed optimisation
framework of the VR bound enables tractable application to the same class of models as SVI.

4.1 Monte Carlo approximation of the VR bound

Consider learning a latent variable model with MLE as a running example, where the model is
ϕ) on the latent variables h.
speciﬁed by a conditional distribution p(x
|
Examples include models treated by the variational auto-encoder (VAE) approach [18, 19] that
parametrises the likelihood with a (deep) neural network. MLE requires log p(x) which is obtained
by marginalising out h and is often intractable, so the VR bound is considered as an alternative
optimisation objective. However instead of using exact bounds, a simple Monte Carlo (MC) method
is deployed, which uses ﬁnite samples hk ∼

h, ϕ) and a prior p(h
|

ˆ
Lα,K:

Lα ≈

ˆ
Lα,K(q; x) =

1

1

−

α

x), k = 1, ..., K to approximate
q(h
|
1
K

p(hk, x)
x)
q(hk|

(cid:19)

(cid:35)

K

−

α

1

.

log

(cid:88)k=1 (cid:34)(cid:18)

The importance weighted auto-encoder (IWAE) [17] is a special case of this framework with α = 0
and K < +
. But unlike traditional VI, here the MC approximation is biased. Fortunately we can
characterise the bias by the following theorems proved in the appendix.

∞

(5)

[

∞

K
k=1

hk}

hk}
R and K

ˆ
] < +
Lα,K(q; x)
|
|
1 is:
≥
≤
→ Lα as K

Theorem 2. Assume E
{
as a function of α
∈
1) non-decreasing in K for ﬁxed α
[ ˆ
Lα,K(q; x)]
2) E
{
3) continuous and non-increasing in α with ﬁxed K.
Corollary 1. For ﬁnite K, either E
hk}
{
[ ˆ
LαK ,K(q; x)] = log p(x) and E
such that E
{
{
Also αK is non-decreasing in K if exists, with limK

hk}

K
k=1

K
k=1

K
k=1

→

∞

+

;

and

|Lα|

< +

. Then E
{

∞

hk}

K
k=1

[ ˆ
Lα,K(q; x)]

1, and non-increasing in K for ﬁxed α

1;

≥

[ ˆ
Lα,K(q; x)] < log p(x) for all α, or there exists αK ≤

0
[ ˆ
Lα,K(q; x)] > log p(x) for all α < αK.
1 αK =

and limK

αK = 0.

K
k=1

+

−∞

→

∞

hk}
→

The intuition behind the theorems is visualised in Figure 2(a). By deﬁnition, the exact VR bound
is a lower-bound or upper-bound of log p(x) when α > 0 or α < 0, respectively. However the
MC approximation E[ ˆ
LVI, where the approximation quality can
be improved using more samples. Thus for ﬁnite samples and under mild conditions, negative
alpha values can potentially be used to improve the accuracy of the approximation, at the cost of
losing the upper-bound guarantee. Figure 2(b) shows an empirical evaluation by computing the
exact and the MC approximation of the Rényi divergences. In this example p, q are 2-D Gaussian
distributions with µp = [0, 0], µq = [1, 1] and Σp = Σq = I. The sampling procedure is repeated

Lα,K] biases the estimate towards

4

(cid:54)
(a) MC approximated VR bounds.

(b) Simulated MC approximations.

Figure 2: (a) An illustration for the bounding properties of MC approximations to the VR bounds. (b)
The bias of the MC approximation. Best viewed in colour and see the main text for details.

200 times to estimate the expectation. Clearly for K = 1 it is equivalent to an unbiased estimate
of the KL-divergence for all α (even though now the estimation is biased for Dα). For K > 1 and
α < 1, the MC method under-estimates the VR bound, and the bias decreases with increasing K. For
α > 1 the inequality is reversed also as predicted.

4.2 Uniﬁed implementation with the reparameterization trick

= 1. In this section
LVI has a different form compared to
Readers may have noticed that
we show how to unify the implementation for all ﬁnite α settings using the reparameterization trick
[13, 18] as an example. This trick assumes the existence of the mapping θ = gφ((cid:15)), where the
distribution of the noise term (cid:15) satisﬁes q(θ)dθ = p((cid:15))d(cid:15). Then the expectation of a function F (θ)
over distribution q(θ) can be computed as Eq(θ)[F (θ)] = Ep((cid:15))[F (gφ((cid:15)))]. One prevalent example
(0, I). Now we apply
is the Gaussian reparameterization: θ
∼ N
the reparameterization trick to the VR bound

Lα with α

θ = µ + Σ

(µ, Σ)

2 (cid:15), (cid:15)

∼ N

⇒

1

Lα(qφ; x) =

1

1

−

α

log E(cid:15)

p(gφ((cid:15)), x)
q(gφ((cid:15)))

α

1

−

.

(cid:35)

(cid:19)

(cid:34)(cid:18)

Then the gradient of the VR bound w.r.t. φ is (similar for ϕ, see appendix for derivation)

∇φLα(qφ; x) = E(cid:15)

wα((cid:15); φ, x)

∇φ log

(cid:20)

p(gφ((cid:15)), x)
q(gφ((cid:15)))

,

(cid:21)

p(gφ((cid:15)),x)
q(gφ((cid:15)))

1

α

−

p(gφ((cid:15)),x)
q(gφ((cid:15)))

1

α

−

where wα((cid:15); φ, x) =

denotes the normalised importance
LVI by setting α = 1 in (7)
weight. One can show that this recovers the the stochastic gradients of
since now w1((cid:15); φ, x) = 1, which means the resulting algorithm uniﬁes the computation for all
ﬁnite α settings. For MC approximations, we use K samples to approximately compute the weight

(cid:20)(cid:16)

E(cid:15)

(cid:30)

(cid:16)

(cid:17)

(cid:17)

(cid:21)

ˆwα,k((cid:15)k; φ, x)

∝

p(gφ((cid:15)k),x)
q(gφ((cid:15)k))

1

α

−

, k = 1, ..., K, and the stochastic gradient becomes

(cid:16)
∇φ ˆ

(cid:17)

K

(cid:88)k=1 (cid:20)

Lα,K(qφ; x) =

ˆwα,k((cid:15)k; φ, x)

∇φ log

p(gφ((cid:15)k), x)
q(gφ((cid:15)k))

.

(cid:21)

(8)

When α = 1, ˆw1,k((cid:15)k; φ, x) = 1/K, and it recovers the stochastic gradient VI method [18].

→ −∞

To speed-up learning [17] suggested back-propagating only one sample (cid:15)j with j
pj = ˆwα,j, which
can be easily extended to our framework. Importantly, the use of different α < 1 indicates the degree
of emphasis placed upon locations where the approximation q under-estimates p, and in the extreme
case α
, the algorithm chooses the sample that has the maximum unnormalised importance
weight. We name this approach VR-max and summarise it and the general case in Algorithm 1. Note
that VR-max (and VR-α with α < 0 and MC approximations) does not minimise D1
q]. It is
log p(x) for negative α values. However Corollary 1 suggests that the tightest MC
true that
approximation for given K has non-positive αK value, or might not even exist. Furthermore αK
becomes more negative as the mismatch between q and p increases, e.g. VAE uses a uni-modal q
distribution to approximate the typically multi-modal exact posterior.

Lα ≥

α[p

∼

||

−

5

(6)

(7)

(cid:54)
Algorithm 1 One gradient step for VR-α/VR-max
with single backward pass. Here ˆw((cid:15)k; x) short-
hands ˆw0,k((cid:15)k; φ, x) in the main text.
1: given the current datapoint x, sample

(cid:15)1, ..., (cid:15)K ∼ p((cid:15))

2: for k = 1, ..., K, compute the unnormalised weight

log ˆw((cid:15)k; x) = log p(gφ((cid:15)k), x)−log q(gφ((cid:15)k)|x)

3: choose the sample (cid:15)j to back-propagate:

if |α| < ∞: j ∼ pk where pk ∝ ˆw((cid:15)k; x)1−α
if α = −∞: j = arg maxk log ˆw((cid:15)k; x)

4: return the gradients ∇φ log ˆw((cid:15)j; x)

Figure 3: Connecting local and global
divergence minimisation.

4.3 Stochastic approximation for large-scale learning

VR bounds can also be applied to full Bayesian inference with posterior approximation. However for
large datasets full batch learning is very inefﬁcient. Mini-batch training is non-trivial here since the
VR bound cannot be represented by the expectation on a datapoint-wise loss, except when α = 1.
This section introduces two proposals for mini-batch training, and interestingly, this recovers two
existing algorithms that were motivated from a different perspective. In the following we deﬁne the
“average likelihood” ¯f
N . Hence the joint distribution can be rewritten as
D
) = p0(θ) ¯f
p(θ,
, we
D
deﬁne the “subset average likelihood” ¯f
S
The ﬁrst proposal considers ﬁxed point approximations with mini-batch sub-sampling. It ﬁrst derives
(cid:81)
the ﬁxed point conditions for the variational parameters (e.g. the natural parameters of q) using the
exact VR bound (4), then design an iterative algorithm using those ﬁxed point equations, but with
¯f
(θ). The second proposal also applies this subset average likelihood approx-
D
imation idea, but directly to the VR bound (4) (so this approach is named energy approximation):

(θ)N . Also for a mini-batch of M datapoints
(θ) = [
θ)]

xn1, ..., xnM } ∼ D
{

(θ) replaced by ¯f
S

m=1 p(xnm |

n=1 p(xn|

(θ) = [

S
M .

θ)]

(cid:81)

=

D

M

N

1

1

˜
Lα(q;

S

) =

1

1

−

α

log Eq

(cid:34)(cid:18)

(θ)N

p0(θ) ¯f
S
q(θ)

α

1

−

(cid:19)

.

(cid:35)

(9)

In the appendix we demonstrate with detailed derivations that ﬁxed point approximation returns
Stochastic EP (SEP) [7], and black box alpha (BB-α) [16] corresponds to energy approximation. Both
algorithms were originally proposed to approximate (power) EP [3, 26], which usually minimises
α-divergences locally, and considers M = 1, α
1/N, 1) and exponential family distributions.
∈
These approximations were done by factor tying, which signiﬁcantly reduces the memory overhead
of full EP and makes both SEP and BB-α scalable to large datasets just as SVI. The new derivation
derivation provides a theoretical justiﬁcation from energy perspective, and also sheds lights on the
connections between local and global divergence minimisations as depicted in Figure 3. Note that
all these methods recover SVI when α
1, in which global and local divergence minimisation are
equivalent. Also these results suggest that recent attempts of distributed posterior approximation (by
carving up the dataset into pieces with M > 1 [10, 11]) can be extended to both SEP and BB-α.

→

−

[1

Monte Carlo methods can also be applied to both proposals. For SEP the moment computation can be
approximated with MCMC [10, 11]. For BB-α one can show in the same way as to prove Theorem
2 that simple MC approximation in expectation lower-bounds the BB-α energy when α
1. In
general it is also an open question how to choose α for given the mini-batch size M and the number
of samples K, but there is evidence that intermediate α values can be superior [27, 28].

≤

5 Experiments

We evaluate the VR bound methods on Bayesian neural networks and variational auto-encoders. All
the experiments used the ADAM optimizer [29], and the detailed experimental set-up (batch size,
learning rate, etc.) can be found in the appendix. The implementation of all the experiments in Python
is released at https://github.com/YingzhenLi/VRbound.

6

VREPSEPBB-globallocalmini-batchsub-samplingfactortyingenergyapprox.ﬁxed pointapprox.Figure 4: Test LL and RMSE results for Bayesian neural network regression. The lower the better.

5.1 Bayesian neural network

The ﬁrst experiment considers Bayesian neural network regression. The datasets are collected from
the UCI dataset repository.1 The model is a single-layer neural network with 50 hidden units (ReLUs)
for all datasets except Protein and Year (100 units). We use a Gaussian prior θ
(θ; 0, I) for
∼ N
(θ; µq, diag(σq)).
the network weights and Gaussian approximation to the true posterior q(θ) =
We follow the toy example in Section 3 to consider α
in order to
examine the effect of mass-covering/zero-forcing behaviour. Stochastic optimisation uses the energy
approximation proposed in Section 4.3. MC approximation is also deployed to compute the energy
function, in which K = 100, 10 is used for small and large datasets (Protein and Year), respectively.

, 0.0, 0.5, 1.0, +

∈ {−∞

∞}

N

We summarise the test negative log-likelihood (LL) and RMSE with standard error (across different
random splits except for Year) for selected datasets in Figure 4, where the full results are provided in
the appendix. These results indicate that for posterior approximation problems, the optimal α may
vary for different datasets. Also the MC approximation complicates the selection of α (see appendix).
Future work should develop algorithms to automatically select the best α values, although a naive
approach could use validation sets. We observed two major trends that zero-forcing/mode-seeking
methods tend to focus on improving the predictive error, while mass-covering methods returns better
calibrated uncertainty estimate and better test log-likelihood. In particular VI returns lower test
log-likelihood for most of the datasets. Furthermore, α = 0.5 produced overall good results for both
test LL and RMSE, possibly because the skew symmetry is centred at α = 0.5 and the corresponding
divergence is the only symmetric distance measure in the family.

5.2 Variational auto-encoder

The second experiments considers variational auto-encoders for unsupervised learning. We mainly
compare three approaches: VAE (α = 1.0), IWAE (α = 0), and VR-max (α =
), which are
implemented upon the publicly available code.2 Four datasets are considered: Frey Face (with 10-fold
cross validation), Caltech 101 Silhouettes, MNIST and OMNIGLOT. The VAE model has L = 1, 2
stochastic layers with deterministic layers stacked between, and the network architecture is detailed
in the appendix. We reproduce the IWAE experiments to obtain a fair comparison, since the results in
the original publication [17] mismatches those evaluated on the publicly available code.

−∞

ˆ
We report test log-likelihood results in Table 2 by computing log p(x)
L0,5000(q; x) following
[17]. We also present some samples from the trained models in the appendix. Overall VR-max is
almost indistinguishable from IWAE. Other positive alpha settings (e.g. α = 0.5) return worse results,
e.g. 1374.64
85.50 for MNIST with α = 0.5, L = 1 and K = 5. These
worse results for α > 0 indicate the preference of getting tighter approximations to the likelihood
function for MLE problems. Small negative α values (e.g. α =
2.0) returns better results on
different splits of the Frey Face data, and overall the best α value is dataset-speciﬁc.

5.62 for Frey Face and

1.0,

−

−

−

≈

±

1http://archive.ics.uci.edu/ml/datasets.html
2https://github.com/yburda/iwae

7

mass-coveringzero-forcingTable 2: Average Test log-likelihood. Results for VAE on
MNIST and OMNIGLOT are collected from [17].

Dataset
Frey Face
std. err.)
(
±
Caltech 101
Silhouettes
MNIST

OMNIGLOT

L K
5
1

1

1

2

1
1
2
2

5
50
5
50
5
50
5
50
5
50

VAE
1322.96
10.03
±
-119.69
-119.61
-86.47
-86.35
-85.01
-84.78
-107.62
-107.80
-106.31
-106.30

IWAE
1380.30
4.60
±
-117.89
-117.21
-85.41
-84.80
-83.92
-83.05
-106.30
-104.68
-104.64
-103.25

VR-max
1377.40
4.59
±
-118.01
-117.10
-85.42
-84.81
-84.04
-83.44
-106.33
-105.05
-104.71
-103.72

Figure 5: Bias of sampling approx-
imation to. Results for K = 5, 50
samples are shown on the left and
right, respectively.

(a) Log of ratio R = wmax/(1 − wmax)

(b) Weights of samples.

Figure 6: Importance weights during training, see main text for details. Best viewed in colour.

VR-max’s success might be explained by the tightness of the bound. To evaluate this, we compute
5, 50
the VR bounds on 100 test datapoints using the 1-layer VAE trained on Frey Face, with K =
}
ˆ
. Figure 5 presents the estimated gap ˆ
1,
and α
L0,5000. The results
−
∈ {
}
indicates that ˆ
Lα,K provides a lower-bound, and that gap is narrowed as α
. Also increasing
K provides improvements. The standard error of estimation is almost constant for different α (with
K ﬁxed), and is negligible when compared to the MC approximation bias.

Lα,K −

→ −∞

500

50,

−

−

−

5,

0,

{

−

wmax

wmax

Another explanation for VR-max’s success is that, the sample with the largest normalised importance
weight wmax dominates the contributions of all the gradients. This is conﬁrmed by tracking R =
during training on Frey Face (Figure 6(a)). Also Figure 6(b) shows the 10 largest importance
1
weights from K = 50 samples in descending order, which exhibit an exponential decay behaviour,
with the largest weight occupying more than 75% of the probability mass. Hence VR-max provides a
fast approximation to IWAE when tested on CPUs or multiple GPUs with high communication costs.
Indeed our numpy implementation of VR-max achieves up to 3 times speed-up compared to IWAE
(9.7s vs. 29.0s per epoch, tested on Frey Face data with K = 50 and batch size M = 100, CPU info:
Intel Core i7-4930K CPU @ 3.40GHz). However this speed advantage is less signiﬁcant when the
gradients can be computed very efﬁciently on a single GPU.

6 Conclusion

We have introduced the variational Rényi bound and an associated optimisation framework. We
have shown the richness of the new family, not only by connecting to existing approaches including
VI/VB, SEP, BB-α, VAE and IWAE, but also by proposing the VR-max algorithm as a new special
case. Empirical results on Bayesian neural networks and variational auto-encoders indicate that VR
bound methods are widely applicable and can obtain state-of-the-art results. Future work will focus
on both experimental and theoretical sides. Theoretical work will study the interaction of the biases
introduced by MC approximation and datapoint sub-sampling. A guide on choosing optimal α values
are needed for practitioners when applying the framework to their applications.

Acknowledgements

We thank the Cambridge MLG members and the reviewers for comments. YL thanks the Schlum-
berger Foundation FFTF fellowship. RET thanks EPSRC grants # EP/M026957/1 and EP/L000776/1.

8

References

[1] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul, “An introduction to variational methods for

graphical models,” Machine learning, vol. 37, no. 2, pp. 183–233, 1999.

[2] M. J. Beal, Variational algorithms for approximate Bayesian inference. PhD thesis, University College

London, 2003.

[3] T. Minka, “Expectation propagation for approximate Bayesian inference,” in Conference on Uncertainty in

Artiﬁcial Intelligence (UAI), 2001.

[4] M. Opper and O. Winther, “Expectation consistent approximate inference,” The Journal of Machine

Learning Research, vol. 6, pp. 2177–2204, 2005.

[5] T. Minka, “Divergence measures and message passing,” tech. rep., Microsoft Research, 2005.
[6] M. D. Hoffman, D. M. Blei, C. Wang, and J. W. Paisley, “Stochastic variational inference,” Journal of

Machine Learning Research, vol. 14, no. 1, pp. 1303–1347, 2013.

[7] Y. Li, J. M. Hernández-Lobato, and R. E. Turner, “Stochastic expectation propagation,” in Advances in

Neural Information Processing Systems (NIPS), 2015.

[8] G. Dehaene and S. Barthelmé, “Expectation propagation in the large-data limit,” arXiv:1503.08060, 2015.
[9] T. Broderick, N. Boyd, A. Wibisono, A. C. Wilson, and M. I. Jordan, “Streaming variational Bayes,” in

Advances in Neural Information Processing Systems (NIPS), 2013.

[10] A. Gelman, A. Vehtari, P. Jylänki, C. Robert, N. Chopin, and J. P. Cunningham, “Expectation propagation

as a way of life,” arXiv:1412.4869, 2014.

[11] M. Xu, B. Lakshminarayanan, Y. W. Teh, J. Zhu, and B. Zhang, “Distributed Bayesian posterior sampling

via moment sharing,” in Advances in Neural Information Processing Systems (NIPS), 2014.

[12] J. Paisley, D. Blei, and M. Jordan, “Variational Bayesian inference with stochastic search,” in Proceedings

of The 29th International Conference on Machine Learning (ICML), 2012.

[13] T. Salimans and D. A. Knowles, “Fixed-form variational posterior approximation through stochastic linear

regression,” Bayesian Analysis, vol. 8, no. 4, pp. 837–882, 2013.

[14] R. Ranganath, S. Gerrish, and D. M. Blei, “Black box variational inference,” in Proceedings of the 17th

International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 2014.

[15] A. Kucukelbir, R. Ranganath, A. Gelman, and D. M. Blei, “Automatic variational inference in Stan,” in

Advances in Neural Information Processing Systems (NIPS), 2015.

[16] J. M. Hernández-Lobato, Y. Li, M. Rowland, D. Hernández-Lobato, T. Bui, and R. E. Turner, “Black-box
α-divergence minimization,” in Proceedings of The 33rd International Conference on Machine Learning
(ICML), 2016.

[17] Y. Burda, R. Grosse, and R. Salakhutdinov, “Importance weighted autoencoders,” in International Confer-

ence on Learning Representations (ICLR), 2016.

[18] D. P. Kingma and M. Welling, “Auto-encoding variational Bayes,” in International Conference on Learning

Representations (ICLR), 2014.

[19] D. J. Rezende, S. Mohamed, and D. Wierstra, “Stochastic backpropagation and approximate inference
in deep generative models,” in Proceedings of The 30th International Conference on Machine Learning
(ICML), 2014.

[20] A. Rényi, “On measures of entropy and information,” Fourth Berkeley symposium on mathematical

statistics and probability, vol. 1, 1961.

[21] S.-i. Amari, Differential-Geometrical Methods in Statistic. New York: Springer, 1985.
[22] C. Tsallis, “Possible generalization of Boltzmann-Gibbs statistics,” Journal of statistical physics, vol. 52,

no. 1-2, pp. 479–487, 1988.

[23] T. Van Erven and P. Harremoës, “Rényi divergence and Kullback-Leibler divergence,” Information Theory,

IEEE Transactions on, vol. 60, no. 7, pp. 3797–3820, 2014.

[24] P. Grünwald, Minimum Description Length Principle. MIT press, Cambridge, MA, 2007.
[25] R. E. Turner and M. Sahani, “Two problems with variational expectation maximisation for time-series
models,” in Bayesian Time series models (D. Barber, T. Cemgil, and S. Chiappa, eds.), ch. 5, pp. 109–130,
Cambridge University Press, 2011.

[26] T. Minka, “Power EP,” Tech. Rep. MSR-TR-2004-149, Microsoft Research, 2004.
[27] T. D. Bui, D. Hernández-Lobato, Y. Li, J. M. Hernández-Lobato, and R. E. Turner, “Deep gaussian processes
for regression using approximate expectation propagation,” in Proceedings of The 33rd International
Conference on Machine Learning (ICML), 2016.

[28] S. Depeweg, J. M. Hernández-Lobato, F. Doshi-Velez, and S. Udluft, “Learning and policy search in

stochastic dynamical systems with bayesian neural networks,” arXiv preprint arXiv:1605.07127, 2016.

[29] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in International Conference on

Learning Representations (ICLR), 2015.

9

RényiDivergenceVariationalInference:AppendixYingzhenLiUniversityofCambridgeCambridge,CB21PZ,UKyl494@cam.ac.ukRichardE.TurnerUniversityofCambridgeCambridge,CB21PZ,UKret26@cam.ac.ukTheappendixisorganisedasfollows.SectionApresentsotherexistingdeﬁnitionsofα-divergences.SectionBprovidesthemathematicaldetailsfortheBayesianlinearregressionexample.SectionCprovidestheproofsforthemaintheoreticalresults.SectionDbrieﬂydiscussestheoptimisationissuesbroughtfromtheselectionofαvaluesandthenumberofMCsamplesK.SectionEappliesthereparametrizationtricktotheMCapproximatedbound,whichleadstoauniﬁedimplementation.SectionFdemonstratestheconnectionsbetweentheproposedsub-samplingapproximationandexistingalgorithms(SEP[1]andBB-α[2]).SectionGprovidesdetailedexperimentalset-upandfurtherresultsforthetestsconsideredinthemaintext.AOtherα-divergencedeﬁnitionsHereweincludesomeexistingα-divergencedeﬁnitionsotherthanRényi’s.•Amari’sα-divergence[3]Dα[p||q]=41−α2(cid:18)1−Zp(θ)1+α2q(θ)1−α2dθ(cid:19).•Tsallis’sα-divergence[4]Dα[p||q]=1α−1(cid:18)Zp(θ)αq(θ)1−αdθ−1(cid:19).Considertheproblemofposteriorapproximationbyminimisinganα-divergence.Whentheapproxi-mateposteriorqhasanexponentialfamilyform,minimisingDα[p||q],nomatterwhichdeﬁnitionaboveisused(althoughmayusedifferentalpha),requiresmomentmatchingtothetilteddistribution˜pα(θ)∝p(θ)αq(θ)1−α.IntheEPliteratureAmari’sdeﬁnitionisoftendiscussed.WefocusonRényi’sdeﬁnitioninthemaintextsimplybecauseDα[q(θ)||p(θ|D)]usingRényi’sdeﬁnitioncontainslogp(D)thatcanbecancelledinthesamewayasVIisderived.BAmean-ﬁeldapproximationexampleWepresentthemean-ﬁeldapproximationmethodfortheVRboundfamily,withBayesianlinearregressionasanillustratingexample.RecalltheVRboundforα6=1:Lα(q;D):=11−αlogEq"(cid:18)p(θ,D)q(θ)(cid:19)1−α#,(1)29thConferenceonNeuralInformationProcessingSystems(NIPS2016),Barcelona,Spain.wheretheqdistributionisfactorisedoverthecomponentsofθ=(θ1,...,θd):q(θ)=Qiq(θi).Inthefollowingwedenoteqj=q(θj)toreducenotationalclutter,andre-writetheVRboundasLα(q;D)=11−αlogZYiqi(cid:18)p(θ,D)Qiqi(cid:19)1−αdθ=11−αlogZqαjZYi6=jqi p(θ,D)Qi6=jqi!1−αdθi6=jdθj:=11−αlogZqαj˜p1−αjdθj+const,where˜pjdenotethe“marginal”distributionsatisfyinglog˜pj=11−αlogZYi6=jqi p(θ,D)Qi6=jqi!1−αdθi6=j+const.NowmaximisingtheVRbound(whenα>0,andforα<0weminimisethebound)isequivalenttominimisingDα[qj||˜pj](forα>0,andwhenα<0weminimiseD1−α[˜pj||qj]),whichmeanslogqj=log˜pj+const.Onecanverifythatwhenα→1itrecoversthetraditionalvariationalmean-ﬁeldapproximationlimα→1qj=ZYi6=jqilogp(θ,D)dθi6=j+const,andwhenα→0itreturnstheexactmarginaloftheposteriordistributionlimα→0qj=p(θj|D).NowconsiderBayesianlinearregressionwith2-Dinputxand1-Doutputy,asanexample:θ∼N(θ;µ0,Λ−10),y|x∼N(y;θTx,σ2).GiventheobservationsD={xn,yn},theposteriordistributionofθcanbecomputedanalyticallyasp(θ|D)=N(θ;µ,Λ−1)withΛ=Λ0+1σ2PnxnxTnandΛµ=Λ0µ0+1σ2Pnynxn.Toseehowthemean-ﬁeldapproachworkweexplicitlywritedowntheelementsoftheposteriorparametersµ=(cid:18)µ1µ2(cid:19),Λ=(cid:18)Λ11Λ12Λ21Λ22(cid:19),Λ12=Λ21,anddeﬁneqi=N(θi;mi,λ−1i)asaunivariateGaussiandistribution.Thenlogq1=11−αlogZq2(θ2)(cid:18)p(θ,D)q2(θ2)(cid:19)1−αdθ2+const=11−αlogZexp(cid:20)−1−α2(θ−µ)TΛ(θ−µ)−α2λ2(θ2−m2)2(cid:21)dθ2+const=11−αlogZN(θ;µ,˜Σ)dθ2+const=logN(θ1;m1,λ−1)+constwherethenewmeanm1andtheprecisionλ1satisﬁesm1=µ1+C1(µ2−m2),C1=αλ2Λ12(1−α)|Λ|+αλ2Λ11,λ1=Λ11−(1−α)Λ12((1−α)Λ22+αλ2)−1Λ21.Onecanderivethetermsm2andC2forq2inthesameway,andshowthatm=µistheonlystableﬁxedpointofthisiterativeupdate.Sowehaveq1=N(θ1;µ1,λ−11),andsimilarlyq2=N(θ1;µ2,λ−12)withλ2=Λ22−(1−α)Λ21((1−α)Λ11+αλ1)−1Λ12.Inthisexampleλ1,λ2arefeasibleforallα,andsolvingtheﬁxedpointequations,ﬁnallywehavethestableﬁxedpointasλ1=ραΛ11,λ2=ραΛ22,ρα=12α(2α−1)+s1−4α(1−α)Λ212Λ11Λ22.2Theothersolutionforthequadraticformulaiseliminatedsinceitviolatestheassumptionsthatλ1>0(when0<α<1)and|Lα|<+∞(whenα<0orα>1,sinceitrequires|αdiag(λ)+(1−α)Λ|>0).Thusthestableﬁxedpointinthiscaseisunique.Onecanshowthatlimα→1λ1=Λ11,limα→0λ1=Λ11−Λ12Λ−122Λ21andlimα→±∞λ1=Λ11±|Λ12|qΛ11Λ−122(similarresultsforλ2).Alsoραiscontinuousandnon-decreasinginα.Thismeansonecaninterpolatebetweenmass-coveringandzero-forcingbehaviourbyincreasingαvalues.Moreover,noticethatthelimitingcaseα→+∞stillreturnsuncertainestimates,althoughitisevenmoreover-conﬁdentthanVI.Thisisdifferentfrommaximumaposteriori(MAP)whichcapturesthemodebutonlyreturnsapointestimate.CProofsofthemainresultsWeprovidetheproofsofthetheoremspresentedinsection4ofthemaintext.C.1ProofofTheorem2Proof.1)Firstweproveforα≤1,E{hk}[ˆLα,K]isnon-decreasinginK.Itisstraightforwardtoshowtheresultsholdsforα=1.Wefollowtheproofin[5]forﬁxedα<1.LetK>1andthesubsetofindicesI={i1,...,iK0}⊂{1,...,K},K0<Krandomlysampledfromintegers1toK.Thenforanyα<1:E{hk}Kk=1[ˆLα,K]=11−αE{hk}"log1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α#=11−αE{hk}logEI⊂{1,...,K}1K0K0Xk=1(cid:18)p(hik,x)q(hik)(cid:19)1−α≥11−αE{hk}EI⊂{1,...,K}log1K0K0Xk=1(cid:18)p(hik,x)q(hik)(cid:19)1−α(logxisconcave)=11−αE{hk}log1K0K0Xk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α=E{hk}K0k=1[ˆLα,K0]WeusedJensen’sinequalityoflogarithmforthelower-boundingresulthere.Whenα>1wecanproofsimilarresultbutwithinequalityreversed,simplybecausenow1−α<0.2)Nextweprovethat,whenK→∞and|Lα|<+∞,wehaveE{hk}Kk=1[ˆLα,K]→LαifˆLα,Kisabsolutelyintegrablewrt.qdµ=dQforallK≥1(inotherwordsE{hk}Kk=1[|ˆLα,K|]<+∞).Weonlyproveitforα≤1,andforα>1itcanbeprovedinasimilarway.FirstweuseJensen’sinequalityagainforallﬁniteK:E{hk}Kk=1[ˆLα,K]=11−αE{hk}"log1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α#≤11−αlogE{hk}"1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α#=Lα.ThisimplieslimsupK→+∞E{hk}Kk=1[ˆLα,K]≤Lα.ThenasanintermediateresultweproveˆLα,K→LαalmostsurelywhenK→∞.Forα6=1,sincefunctionlogiscontinuousweagainswapthelimitandlogarithm:limK→+∞11−αlog1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α=11−αloglimK→+∞1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α.3Nowsinceweassume|Lα|<+∞,thisimpliesEq(cid:20)(cid:16)p(h,x)q(h|x)(cid:17)1−α(cid:21)isﬁnite.Alsonoticeforallαvaluestheratiop/qisnon-negative.ThusbythestronglawoflargenumberswehavelimK→+∞1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α=Eq(h|x)"(cid:18)p(h,x)q(h|x)(cid:19)1−α#a.s.,thenˆLα,K→LαalmostsurelyasK→+∞.Whenα=1wecanusesimilarmethodtoprovelimK→+∞ˆL1,K=LVIalmostsurely.Finally,usingthenon-increasinginαresultwewillprovelaterwehaveˆLα,K≥ˆL1,K.ThuswecanapplyFatou’sLemmaandobtainthefollowingalmostsurely(noticeE[ˆL1,K]=LVIforallK):Lα−LVI=E{hk}Kk=1[limK→+∞ˆLα,K−ˆL1,K]≤liminfK→+∞E{hk}Kk=1[ˆLα,K−ˆL1,K]=liminfK→+∞E{hk}Kk=1[ˆLα,K]−LVI.Combiningwiththesupremumbound,wehaveE{hk}Kk=1[ˆLα,K]→LαwhenKgoestoinﬁnity.Forα>1weuseJensen’sinequalitytoboundthelimitinﬁmumandthenon-increasingpropertyinαtoboundthelimitsupremum.Thustheconvergenceresultholdsforallα∈{α:|Lα|<+∞}.3)E[ˆLα,K]isnon-increasinginα:sinceexpectationpreservesmonotonicity,itissufﬁcienttoprovetheresultforˆLα,K.ThiscanbeprovedinsimilarwayasTheorem3and39in[6],andweincludetheprovehereforcompleteness.Noticethatforα<βfunctionx1−α1−βdeﬁnedonx>0isconvexwhenα<1andconcavewhenα>1.SoapplyingJensen’sinequality:ˆLα,K=11−αlog1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−α=11−αlog1KKXk=1 (cid:18)p(hk,x)q(hk|x)(cid:19)1−β!1−α1−β≥11−αlog 1KKXk=1(cid:18)p(hk,x)q(hk|x)(cid:19)1−β!1−α1−β=ˆLβ,K.Continuityinα:FirstweshowˆLα,Kiscontinuousinαwhenp(hk,x)6=0forhk∼q.Forα6=0,1,∞andforanysequence{αn}→αitissufﬁcienttoshowthatlimn→∞log1KXkq(hk|x)αnp(hk,x)1−αn=loglimn→∞1KXkq(hk|x)αnp(hk,x)1−αn(logxisacontinuousfunction)=log1KXklimn→∞q(hk|x)αnp(hk,x)1−αn(ﬁnitesum)=log1KXkq(hk|x)(cid:18)p(hk,x)q(hk|x)(cid:19)1−limn→∞αn(axiscontinuousinxforalla>0)=log1KXkq(hk|x)αp(hk,x)1−α.WenotethatsinceweassumeˆLα,Kisabsolutelyintegrable,wehavep/q>0almosteverywhereonthesupportofq.Hence{ˆLαn,K}haspoint-wiselimitˆLα,Kalmosteverywhereasn→+∞.Forα=0,1,∞theRényidivergenceisdeﬁnedbycontinuitysoonecanusethesametechniquetoshowthecontinuityofˆLα,KonthoseαvaluesforﬁxedK.Thensinceαn→α,forany(cid:15)>0,there4existsnthatislargeenoughsuchthatαm∈(α−(cid:15),α+(cid:15))forallm>n.Usingthemonotonicityresult,wehavefor∀m>n,ˆLαm,Kisboundedintheinterval(ˆLα+(cid:15),K,ˆLα−(cid:15),K)andbyassumptionwehaveE[|ˆLα−(cid:15),K|]<+∞andE[|ˆLα+(cid:15),K|]<+∞.Thisallowsustoapplythedominatedconvergencetheoremtoprovelimn→+∞E[ˆLαn,K]=E[limn→+∞ˆLαn,K]=E[ˆLα,K].ThuswehaveprovedthatE[ˆLα,K]iscontinuousonα∈{|Lα|<+∞}ifˆLα,Kisabsolutelyintegrable.C.2ProofofCorollary1Itissufﬁcienttoprovethecorollaryforthecaseq(h|x)6=p(h|x).Weﬁrstintroducethefollowinglemmas.Withoverloadednotation,µdenotesthemeasureonthecorrespondingspace,whichalsomeansdQ=qdµ.Asweassumesupp(p)⊆supp(q),theremightexistsomeregionsthatq>0butp=0.Wedeﬁneρ=µ(supp(q)\supp(p))µ(supp(q))andrewritethecomputationofE[ˆLα,K].Lemma1.Assumeρ>0.ThenforallﬁniteKandα<0,E{hk}Kk=1[ˆLα,K(q;x)]=−∞andthusˆLα,Kisnotintegrablewrt.qdµ=dQ.Proof.Wedeﬁne˜qastheqdistributionrestrictedonthesupportofp,i.e.˜q=q/(1−ρ)deﬁnedonsupp(p).ThenforanyﬁxedK<+∞andα<0,wehaveE{hk}Kk=1∼q[ˆLα,K(q;x)]=ρKlog0+KXk=1(cid:18)Kk(cid:19)ρK−k(1−ρ)k(cid:16)E{hj}kj=1∼˜q[ˆLα,k(˜q;x)]+logk(cid:17)−(1−ρK)((1−α)log(1−ρ)+logK)ThusE{hk}Kk=1[ˆLα,K(q;x)]=−∞forallﬁniteKandα<0.TheaboveexampleshowsthepathologyofMCapproximationwhichisfurtherdiscussedinsectionD.FromnowonweassumeˆLα,KisabsolutelyintegrableinordertoapplyTheorem2.Lemma2.Assumeα<0,ˆLα,Kabsolutelyintegrablewrt.qdµ=dQforallK,Lα>LVI,and|Lα|<+∞.Thenthereexists1≤Kα<+∞suchthatforallK≤Kα<K0,E{hk}Kk=1[ˆLα,K(q;x)]≤logp(x)<E{hk}K0k=1[ˆLα,K0(q;x)].AlsoKαisnon-decreasinginαwithlimα→0Kα=+∞andlimα→−∞Kα≥1.Proof.1)ExistenceofKα:ﬁrstfromTheorem2wehaveE[ˆLα,K]isnon-decreasinginKwhenα<0.Thensinceforallα,E[ˆLα,1]=LVI≤logp(x),wehaveKα≥1ifKαexists.AlsofromTheorem2wehavelimK→+∞E[ˆLα,K]=Lα>logp(x)forallα<0.Hencefor(cid:15)=Lα−logp(x)thereexistKthatisﬁnitebutlargeenoughsuchthatLα−E[ˆLα,K0]<(cid:15)forallK0>K.Nowwecandeﬁne(cid:15)=Lα−LVIandtakeKαastheminimumofsuchK,anditisstraight-forwardtoshowthat1≤Kα<+∞.2)Kαisnon-decreasinginα:supposethereexistα>βsuchthatKα<Kβ.ThenthereexistKα<K≤KβsuchthatE[ˆLα,K]>logp(x)≥E[ˆLβ,K].ButTheorem2saysE[ˆLα,K]isnon-increasinginα,acontradiction.3)SincelimK→+∞E[ˆLα,K]=LαandLα↓logp(x)whenα↑0,wehavelimα→0Kα=+∞.AlsosinceKαisnon-decreasinginαandislower-boundedby1,wehavethelimitexistsandlimα→−∞Kα≥1.NowweproveCorollary1,andweonlyproveitwiththeconditionsassumedinLemma2sinceKα=+∞fortheothercases,andifsoforallα<0,thenαK=−∞forallﬁniteK.Proof.1)ExistenceofαKforlimα→−∞Kα<K<+∞:fromLemma2wecanﬁndα>βsuchthatKα≥K≥Kβ.ThismeansE[ˆLα,K]≤logp(x)≤E[ˆLβ,K].SinceE[ˆLα,K]iscontinuousinαforanyﬁxedK,thereexitsα≤γ≤βtohaveE[ˆLγ,K]=logp(x).Notethatγmightnotbe5unique,sowedeﬁneαKastheminimumofsuchγ,whichalsogivesE[ˆLα,K]>logp(x)forallα<αK.2)αKisnon-decreasinginK:supposethereexistK<K0withαK>αK0.ThenwecanﬁndαK>α>αK0suchthatE[ˆLα,K]>logp(x)=E[ˆLαK0,K0]≥E[ˆLα,K0].ButfromTheorem2E[ˆLα,K]isnon-decreasinginK,acontradiction.3)SincelimK→+∞E[ˆLα,K]=LαandLα↓logp(x)whenα↑0,wehavelimK→+∞αK=0.Alsoforallα,E[ˆLα,1]=LVI≤logp(x),solimK→1αK=−∞.DOptimisationissueswithα-divergencesandMCapproximationsItisingeneralanoutstandingresearchquestiononhowtoselectthedivergencemeasureforaparticularmachinelearningproblem.Inourcasethiscorrespondstoselectingtheαvalue.Alsoanapproximateinferencealgorithmcanbeevaluatedwithdifferentperformancemeasures,anditisimpossibletoﬁndasinglealgorithmvaluethatreturnsthebestperformanceonallevaluations.Thusweonlypresenttheevaluationintesterrorandtestlog-likelihoodinthemaintext.WediscusstwoconjecturestoexplainthedifﬁcultyofselectingαintheBayesianneuralnetworkexperiments.Theﬁrstconjectureisthatzero-forcingalgorithmstendtofavourminimisingthetesterror,whilemass-coveringmethodstendtoimprovethetestlog-likelihood.Howeverzero-forcingmethodscanfailasitmightmissanimportantmodeduetolocaloptima.Similarlymass-coveringmethodscanbepathologicaliftheexactposteriorincludesmodesthatareveryfarawayfromeachother.Furthermore,theformoftheposteriorwillchangewiththenumberofobserveddatapointsN,sothe“optimal”settingofαforaﬁxedtaskmaychangewithN.ThesecondconjecturestatesthattheMCapproximationcomplicatestheselectionofα,sinceitfavourszero-forcing(becauseofthebiasintroduced).Forexample,inordertomaximizethequantityoftheMCapproximationthealgorithmneedtomakeE[ˆLα,K]ﬁniteﬁrst.However,Lemma1indicatesthat,ifρ>0,thenforﬁnitesamplesize,there’sasmallprobabilityρKthattheMCapproximationgoeswrong.Hencetoavoidthispathologytheoptimisationprocedurewillensureq=0wheneverpiszero.CombiningwithTheorem2,weconjecturethattheMCapproximationmakesthealgorithmmore“VI-like”comparedtotheexactcase.Inotherwords,whenMCapproximationisdeployed,theeffectiveαvalueisclosertoα=1whichisthevalueforVI(considerK=1).Thismeans,ifthereexistsαopt6=1foraspeciﬁctask,inpracticeoneshoulduseα≤αopt(forαopt<1,andshoulduseα≥αoptifαopt>1)whenrunningtheMCalgorithm.IngeneraloneshouldbeverycarefulwhenestimatingtheratiobetweendistributionwithMonteCarlomethods.AlsotheintroducedMCapproachusuallyhashighervariancecomparedtothevariationalcase,sofurthercontrolvariatetechniquesshouldbeappliedtoreducethesamplingvariance.Stillwewanttoemphasizethatformanyproblems,minimisinganα-divergenceotherthantheKL-divergencecanbeveryuseful,evenwhenwithMCapproximations.ApproximateEPhasbeenappliedtodeepGaussianprocessregressionandhasshowntoachievethestate-of-the-artresultsforbenchmarkdatasets[7].Arecentpaper[8]testedBB-αformodel-basedreinforcementlearningwithBayesianneuralnetworks.Intheirtestsusingα=0.5successfullycapturedthebi-modalityandheteroskedasticityinthepredictivedistribution,whileVIfaileddisastrously.EUniﬁedimplementation:derivationdetailsWeprovidedetailedderivationsofthegradientcomputationhere.Recallfromthemaintextthatwhenα6=1,theVRboundwiththereparameterizationtrickbecomesLα(qφ;x)=11−αlogE(cid:15)"(cid:18)p(gφ((cid:15)),x)q(gφ((cid:15)))(cid:19)1−α#.(2)6Sothedistributionp((cid:15))doesnotdependontherecognitionmodel.Weshort-handgφ=gφ((cid:15)),then,∇φLα(qφ;x)=11−α∇φlogE(cid:15)"(cid:18)p(gφ,x)q(gφ)(cid:19)1−α#=11−α E(cid:15)"(cid:18)p(gφ,x)q(gφ)(cid:19)1−α#!−1E(cid:15)"∇φ(cid:18)p(gφ,x)q(gφ)(cid:19)1−α#=11−α E(cid:15)"(cid:18)p(gφ,x)q(gφ)(cid:19)1−α#!−1E(cid:15)"(cid:18)p(gφ,x)q(gφ)(cid:19)1−α∇φ(1−α)logp(gφ,x)q(gφ)#=E(cid:15)(cid:20)wα((cid:15);φ,x)∇φlogp(gφ,x)q(gφ)(cid:21).Herewedeﬁnewα((cid:15);φ,x):=(cid:18)p(gφ,x)q(gφ)(cid:19)1−α(cid:30)E(cid:15)"(cid:18)p(gφ,x)q(gφ)(cid:19)1−α#.(3)ForMCapproximationwithﬁniteKsamples,onecanusethesametechniquetoshowthat∇φˆLα,K(qφ;x)=KXk=1(cid:20)ˆwα,k((cid:15)k;φ,x)∇φlogp(gφ((cid:15)k),x)q(gφ((cid:15)k))(cid:21).withtheimportanceweightsˆwα,k((cid:15)k;φ,x):=(cid:18)p(gφ((cid:15)k),x)q(gφ((cid:15)k))(cid:19)1−α(cid:30)KXk=1(cid:18)p(gφ((cid:15)k),x)q(gφ((cid:15)k))(cid:19)1−α.(4)Onecanshowthatlimα→1wα((cid:15);φ,x)=1andlimα→1ˆwα,k((cid:15)k;φ,x)=1/K.ThisindicatestherecoveryoftheoriginalVAEalgorithm.FStochasticapproximationforlarge-scalelearning:derivationsThissectionshowstheconnectionbetweenVRboundoptimisationandtherecentlyproposedalgorithms:SEP[1]andBB-α[2],bytakingM=1andα=1−β/N.Recallthatinthemaintextwedeﬁnethe“averagelikelihood”¯fD(θ)=[QNn=1p(xn|θ)]1N.Hencethejointdistributioncanberewrittenasp(θ,D)=p0(θ)¯fD(θ)N.Alsoforamini-batchofMdatapointsS={xn1,...,xnm}∼D,wedeﬁnethe“subsetaveragelikelihood”¯fS=[QMm=1p(xnm|θ)]1M.WhenM=1wealsowrite¯fS(θ)=fn(θ)forS={xn}.Nowassumetheposteriorapproximationisdeﬁnedasq(θ)=1Zqp0(θ)t(θ)N.Oftent(θ)ischosetohaveanexponentialfamilyformt(θ)∝exp[hλ,Φ(θ)i]withΦ(θ)denotingthesufﬁcientstatistic.Thenpickingα=1−β/N,β6=0,wehavetheexactVRboundasLα(q;D)=logZq+NβlogEq"(cid:18)¯fD(θ)t(θ)(cid:19)β#(5)Theﬁrstproposalconsidersderivingtheexactﬁxedpointconditions,thenapproximatingthemwithmini-batchsub-sampling.Inourexampletheexactﬁxedpointconditionforthevariationalparametersλis∇λLα(q;D)=0⇒Eq[Φ(θ)]=E˜pα[Φ(θ)],(6)withthetilteddistributiondeﬁnedas˜pα(θ)∝q(θ)αp0(θ)1−α¯fD(θ)N(1−α)∝p0(θ)t(θ)N−β¯fD(θ)β.Nowgivenamini-batchofdatapointsS,themomentmatchingupdatecanbeapproximatedbyreplacing¯fD(θ)with¯fS(θ)=[QMm=1p(xnm|θ)]1M.Moreprecisely,eachiterationwesamplea7subsetofdataS={xn1,...,xnM}∼D,andcomputethenewupdateforλbyﬁrstcomputing˜pα,S(θ)∝p0(θ)t(θ)N−β¯fS(θ)βthentakingEq[Φ(θ)]←E˜pα,S[Φ(θ)].ThismethodreturnsSEPwhenM=1,i.e.ineachiterationonlyonedatapointissampledtoupdatetheapproximateposterior.Thesecondproposalalsoappliesthissubsetaveragelikelihoodapproximationidea,butdirectlytotheVRbound(5),withESdenotestheexpectationovermini-batchsub-sampling:ESh˜Lα(q;S)i=logZq+NβES"logEq"(cid:18)¯fS(θ)t(θ)(cid:19)β##.(7)ItrecoverstheenergyfunctionofBB-αwhenM=1.Notethattheoriginalpaper[2]usesanadaptedformofAmari’sα-divergence,andtheαvalueintheBB-αalgorithmcorrespondstoβinourexposition.Nowthegradientofthisapproximatedenergyfunctionbecomes∇λESh˜Lα(q;S)i=N(Eq[Φ(θ)]−ESE˜pα,S[Φ(θ)]).(8)BothSEPandBB-αreturnSVIwhenα→1(orequivalentlyβ→0).Butforotherαvaluesitisimportanttonotethatthesetwoproposalsreturndifferentoptimumatconvergence.BB-αrequiresaveragesthemomentofthetilteddistributionESE˜pα,S[Φ(θ)].HoweverSEPﬁrstcomputetheinversemappingfromthemomentE˜pα,S[Φ(θ)]toobtainthenaturalparametersλS,thenupdatetheqdistributionbyλ←ES[λS].Ingeneraltheinversemappingisnon-linearsotheﬁxedpointconditionsofSEPandBB-αaredifferent.SEPisarguablymorewelljustiﬁedsinceitreturnstheexactposterioriftheapproximationfamilyQislargeenoughtoincludethecorrectsolution,justlikeVIandVRcomputedonthewholedataset.BB-αmightstillbebiasedeveninthisscenario.ButBB-αismuchsimplertoimplementsincetheenergyfunctioncanbeoptimisedwithstochasticgradientdescent.Indeedtheauthorsof[2]consideredthesameblack-boxapproachastoVI,bycomputingastochasticestimateoftheenergyfunctionthenusingautomaticdifferentiationtoolstoobtainthegradients.Wealsoprovideaboundoftheenergyapproximation(7)bythefollowingtheorem.Theorem3.Iftheapproximatedistributionq(θ)isGaussianN(µ,Σ),andthelikelihoodfunctionshasanexponentialfamilyformp(x|θ)=exp[hθ,Ψ(x)i−A(θ)],thenforα≤1andr>1thestochasticapproximationisboundedbyES[˜Lα(q;S)]≤L1−(1−α)r(q;D)+N2(1−α)r2(r−1)tr(ΣCovS∼D(¯ΨS)).Proof.WesubstitutetheexponentialfamilylikelihoodtermintothestochasticapproximationoftheVRboundwithα<1,anduseHölder’sinequalityforany1/r+1/s=1,r>1(deﬁne˜α=1−(1−α)r):ES[˜Lα(q;S)]=11−αlogEq[(cid:18)p0(θ)¯fD(θ)Nq(θ)¯fS(θ)N¯fD(θ)N(cid:19)1−α]≤L˜α(q;D)+1(1−α)sES(cid:8)logEq[exp[N(1−α)sh¯ΨS−¯ΨD,θi]](cid:9)=L˜α(q;D)+1(1−α)sES[Kθ(N(1−α)s(¯ΨS−¯ΨD))],where¯ΨSand¯ΨDdenotethemeanofthesufﬁcientstatisticΨ(x)onthemini-batchSandthewholedatasetD,respectively.ForGaussiandistributionq(θ)=N(µ,Σ)thecumulantgeneratingfunctionKθ(t)hasaclosedformKθ(t)=µTt+12tTΣt.8DeﬁnetS=N(1−α)s∆Swith∆S=¯ΨS−¯ΨD,thenES[tS]=0andtheupper-boundbecomesES[˜Lα(q;S)]≤L˜α(q;D)+1(1−α)sES[Kθ(tS)]=L˜α(q;D)+1(1−α)sES[µTtS+12tTSΣtS]=L˜α(q;D)+N2(1−α)s2ES[∆TSΣ∆S]=L˜α(q;D)+N2(1−α)s2tr(ΣCovS∼D(¯ΨS)).ApplyingtheconditionofHölder’sinequality1/r+1/s=1provestheresult.ThefollowingcorollaryisadirectresultofTheorem3appliedtoBB-α.Noteherewefollowtheconventionoftheoriginalpaper[2]touseM=1andoverloadthenotationα=βandLBB−α(q;D)=E{xn}h˜L1−α/N(q;{xn})i.Corollary2.AssumetheapproximateposteriorandthelikelihoodfunctionssatisfytheassumptionsinTheorem3,thenforα>0andr>1,theblack-boxalphaenergyfunctionisupper-boundedbyLBB−α(q;D)≤L1−αrN(q;D)+Nαr2(r−1)tr(ΣCovD(Ψ)).GFurtherexperimentaldetailsandresultsG.1BayesianneuralnetworkWedetailtheexperimentalset-upoftheBayesianneuralnetworkexample.Forregressiontests,weconsiderProteinandYearasthelargedatasetsandtheothersassmalldatasets.Thelikelihoodfunctionisdeﬁnedasp(y|x,θ)=N(y;Fθ(x),σ2)whereFθ(x)denotesthenon-lineartransformfromtheneuralnetworkwithweightsθ.WeuseunitGaussianpriorθ∼N(θ;0,I)andGaussianapproximationq(θ)=N(θ;µq,diag(σq)),whereweﬁttheparametersofqandthenoiselevelσbyoptimisingthelower-bound.Foralldatasetsweusesingle-layerneuralnetworkswith50hiddenunits(ReLUs)fordatasetsexceptProteinandYear(100units).Themethodsforcomparisonwererunfor500epochsonthesmalldatasetsand100,40epochsforthelargedatasetsProteinandYear,respectively.WeusedADAM[9]foroptimisationwithlearningrate0.001andthestandardsettingforotherparameters.Forstochasticoptimisationweusedlearningrate0.001,mini-batchsizeM=32andnumberofsamplesK=100,10forsmallandlargedatasets.Thenumberofdatasetrandomsplitsis20exceptforthelargedatasets,whichis5and1forProteinandYear,respectively.ThefulltestresultsareprovidedinFigure1andTable1,2.Inthetablesthebestperformingresultsareunderlined,whiletheworsecasesarealsobold-faced.Clearlytheoptimalαsettingisdatasetdependent,althoughforBostonandPowertheperformancesareverysimilar.AlsoforNavalmass-coveringseemstobeharmfulnotonlyforpredictiveerrorbutalsofortestlog-likelihoodmeasure.Overallmode-seekingmethodstendtofocusonimprovingthepredictiveerror,whilemass-coveringregimesoftenreturnbettertestlog-likelihood.G.2Variationalauto-encoderWedescribethenetworkarchitecturetestedintheVAEexperiments.ThenumberofstochasticlayersL,numberofhiddenunits,andtheactivationfunctionaresummarisedinTable3.Thepreﬁxofthenumberindicateswhetherthislayerisdeterministicorstochastic,e.g.d500-s200standsforaneuralnetworkwithonedeterministiclayerof500unitsfollowedbyastochasticlayerof200units.ForFreyFacedatawetrainthemodelsusinglearningrate0.0005andmini-batchsize100.ForMNISTandOMNIGLOTwereusethesettingsfrom[5]:thetrainingprocessrunsfor3ipasseswithlearningrate0.0001·10−i/7fori=0,...,7,andthebatchsizeis20.ForCaltechSilhouettesweusethesamesettingsasMNISTandOMNIGLOTexceptthatthetrainingproceededforP7i=02i=255epochs.WealsopresentsomesamplesfromtheVR-maxtrainedauto-encodersinFigure2,andnotethatthevisualqualityofthesesamplesarealmostidenticaltothosefromIWAE.9mass-coveringzero-forcingFigure1:TestLLandRMSEresultsforBayesianneuralnetworkregression.Thelowerthebetter.Table1:Regressionexperiment:Averagenegativetestloglikelihood/natsDatasetNDα→−∞α=0.0α=0.5α=1.0(VI)α→+∞boston506132.47±0.082.47±0.072.46±0.072.52±0.032.50±0.05concrete103083.09±0.023.08±0.023.09±0.023.11±0.023.12±0.02energy76881.39±0.021.42±0.021.40±0.030.77±0.021.23±0.01naval1193416-3.43±0.08-3.02±0.48-3.58±0.08-6.49±0.04-6.47±0.09kin8nm81928-1.13±0.01-1.13±0.01-1.14±0.01-1.12±0.01-1.12±0.01power956842.82±0.012.83±0.012.82±0.012.82±0.012.83±0.01protein4573092.94±0.012.91±0.002.92±0.012.91±0.002.91±0.00wine1588110.95±0.010.95±0.010.95±0.010.96±0.010.97±0.01yacht30861.82±0.011.83±0.011.82±0.011.77±0.012.01±0.00year515345903.54±NA3.55±NA3.55±NA3.60±NA3.60±NAAverageRank2.80±0.343.00±0.452.20±0.373.20±0.513.80±0.39Table2:Regressionexperiment:AveragetestRMSEDatasetNDα→−∞α=0.0α=0.5α=1.0(VI)α→+∞boston506132.84±0.182.85±0.172.85±0.152.89±0.172.86±0.17concrete103085.28±0.105.24±0.115.34±0.105.42±0.115.40±0.11energy76880.79±0.040.88±0.050.81±0.060.51±0.010.62±0.02naval11934160.01±0.000.01±0.000.01±0.000.00±0.000.00±0.00kin8nm819280.08±0.000.08±0.000.08±0.000.08±0.000.08±0.00power956844.08±0.034.10±0.044.07±0.044.07±0.044.08±0.04protein4573094.57±0.054.44±0.034.51±0.034.45±0.024.45±0.01wine1588110.64±0.010.64±0.010.64±0.010.63±0.010.63±0.01yacht30861.12±0.091.24±0.111.11±0.080.81±0.050.96±0.07year515345908.95±NA9.13±NA8.94±NA8.91±NA8.88±NAAverageRank3.40±0.383.70±0.513.20±0.312.40±0.452.30±0.3810Figure2:SampledimagesfromthethebestmodelstrainedwithIWAE(left)andVR-max(right).Table3:NetworkarchitectureoftestedVAEalgorithms.DatasetLarchitectureactivationprobabilitytype(p/q)FreyFace1d200-d200-s20softplusGaussian/GaussianCaltech1011d500-s200tanhBernoulli/GaussianMNIST&1d200-d200-s50tanhBernoulli/GaussianOMNIGLOT2d200-d200-s100-d100-d100-s50tanhBernoulli/Gaussian11References[1]Y.Li,J.M.Hernández-Lobato,andR.E.Turner,“Stochasticexpectationpropagation,”inAdvancesinNeuralInformationProcessingSystems(NIPS),2015.[2]J.M.Hernández-Lobato,Y.Li,M.Rowland,D.Hernández-Lobato,T.Bui,andR.E.Turner,“Black-boxα-divergenceminimization,”inProceedingsofThe33rdInternationalConferenceonMachineLearning(ICML),2016.[3]S.-i.Amari,Differential-GeometricalMethodsinStatistic.NewYork:Springer,1985.[4]C.Tsallis,“PossiblegeneralizationofBoltzmann-Gibbsstatistics,”Journalofstatisticalphysics,vol.52,no.1-2,pp.479–487,1988.[5]Y.Burda,R.Grosse,andR.Salakhutdinov,“Importanceweightedautoencoders,”inInternationalConfer-enceonLearningRepresentations(ICLR),2016.[6]T.VanErvenandP.Harremoës,“RényidivergenceandKullback-Leiblerdivergence,”InformationTheory,IEEETransactionson,vol.60,no.7,pp.3797–3820,2014.[7]T.D.Bui,D.Hernández-Lobato,Y.Li,J.M.Hernández-Lobato,andR.E.Turner,“Deepgaussianprocessesforregressionusingapproximateexpectationpropagation,”inProceedingsofThe33rdInternationalConferenceonMachineLearning(ICML),2016.[8]S.Depeweg,J.M.Hernández-Lobato,F.Doshi-Velez,andS.Udluft,“Learningandpolicysearchinstochasticdynamicalsystemswithbayesianneuralnetworks,”arXivpreprintarXiv:1605.07127,2016.[9]D.P.KingmaandJ.Ba,“Adam:Amethodforstochasticoptimization,”inInternationalConferenceonLearningRepresentations(ICLR),2015.12