Viewport-Aware Deep Reinforcement Learning
Approach for 360o Video Caching

Pantelis Maniotis, Nikolaos Thomos, Senior Member, IEEE

1

0
2
0
2

r
p
A
0
1

]

M
M

.
s
c
[

2
v
3
7
4
8
0
.
3
0
0
2
:
v
i
X
r
a

Abstract—360o video is an essential component of VR/AR/MR
systems that provides immersive experience to the users. How-
ever, 360o video is associated with high bandwidth requirements.
The required bandwidth can be reduced by exploiting the fact
that users are interested in viewing only a part of the video
scene and that users request viewports that overlap with each
other. Motivated by the ﬁndings of our recent works where the
beneﬁts of caching video tiles at edge servers instead of caching
entire 360o videos were shown, in this paper, we introduce the
concept of virtual viewports that have the same number of tiles
with the original viewports. The tiles forming these viewports
are the most popular ones for each video and are determined
by the users’ requests. Then, we propose a proactive caching
scheme that assumes unknown videos’ and viewports’ popularity.
Our scheme determines which videos to cache as well as which
is the optimal virtual viewport per video. Virtual viewports
permit to lower the dimensionality of the cache optimization
problem. To solve the problem, we ﬁrst formulate the content
placement of 360o videos in edge cache networks as a Markov
Decision Process (MDP), and then we determine the optimal
caching placement using the Deep Q-Network (DQN) algorithm.
The proposed solution aims at maximizing the overall quality of
the 360o videos delivered to the end-users by caching the most
popular 360o videos at base quality along with a virtual viewport
in high quality. We extensively evaluate the performance of the
proposed system and compare it with that of known systems such
as Least Frequently Used (LFU), Least Recently Used (LRU),
First-In-First-Out (FIFO), over both synthetic and real 360o
video traces. The results reveal the large beneﬁts coming from
proactive caching of virtual viewports instead of the original
ones in terms of the overall quality of the rendered viewports,
the cache hit ratio, and the servicing cost.

Index Terms—Deep reinforcement learning, 360o video, tile-

encoding, viewport-aware caching.

I. INTRODUCTION

Interactivity in VR/AR/MR systems is facilitated by the use
of 360o video content. However, the interactivity associated
with 360o videos comes with a huge increase in the bandwidth
needed to deliver the content to the users. This puts pressure
on the network infrastructure demanding further investments
to accommodate 360o video related network trafﬁc. Exploiting
360o video coding ﬂexibility,
i.e., encoding in tiles, and
caching at the edge servers, can be a remedy for the problem,
as we have shown in [1], [2]. However, existing solutions
assume known popularity, which may not always be the case.
Further, existing solutions do not scale well with big content
because of the cache optimization complexity. This naturally
calls for caching systems that exploit tiles encoding and can
estimate future content popularity trends, while preserving low

P. Maniotis and N. Thomos are with the School of Computer Science and
Electronic Engineering, University of Essex, Colchester, United Kingdom (e-
mail: {p.maniotis, nthomos}@essex.ac.uk).

complexity and scalability with respect to the number of 360o
video ﬁles.

In 360o videos, a 360o view of a scene is captured from a
single point with the use of an omnidirectional camera. The
captured scene is then mapped to the internal part of a spher-
ical surface. Each user is assumed to be placed at the center
of the sphere and is interested in watching only a portion of
the scene, known as viewport. Typically, each viewport covers
120o of the entire scene. According to the head movements
of the user, the Head Mounted Display (HMD) dynamically
alters the part of the scene that will be displayed. To prevent
users from experiencing motion sickness and discomfort, the
response of the system to the head movements should be
as fast as the HMD refresh rate [3]. Considering that the
refresh rate may be 120Hz, the whole system should project
the requested viewport in less than 10ms. However, state-of-
the-art network streaming architectures are not able to respond
under these tight time constraints due to the end-to-end delay.
Although transmitting the whole scene could help to overcome
the above limitation, it is not an efﬁcient strategy since the
resolution of a 360o video is commonly 4K, 8K, or even higher
[4]. Thus, it would lead to signiﬁcant bandwidth waste as only
a part of the 360o video would be eventually displayed.

In edge caching systems, Small Base Stations (SBSs), e.g.,
picocells and femtocells, are equipped with caches, which
can store a limited amount of popular content ﬁles. This is
inspired by the fact that only a small number of popular
content accounts for most of the network trafﬁc load [5]. As a
result, when there are multiple content requests for a cached
content at an SBS, these can be served from the cache directly
instead of obtaining the content through the core network using
pricey backhaul links. This allows users to receive the content
with lower latency, and the use of the backhaul links is limited.
The potential of using edge caching as a solution to address the
challenges that 360o video delivery faces in cellular networks,
has been recently studied in [1], [2], [6]. These works showed
that ofﬂine edge caching can be a prominent solution for
360o video delivery,
in particular, when tiles and layered
encoding are used. The main drawback of [1], [2], [6] is that
they assume that the content popularity proﬁle is known in
advance. However, often in practice, the content popularity
changes dynamically and may not be known a priori, or the
estimated distribution may not be accurate. For regular videos,
this problem has been addressed by online caching schemes
[7], [8]. These methods learn the optimal caching policy by
observing previous video consumption patterns. Though these
methods are efﬁcient for standard videos,
they cannot be
applied straightforwardly for 360o video. This is because 360o
videos have considerably larger sizes than traditional videos,

 
 
 
 
 
 
which limits the number of videos that can be stored at the
SBSs caches. Furthermore, online caching schemes for regular
videos have not been designed to take advantage of the fact
that large parts of the video scene are never displayed, as is
the case of 360o video where users are interested in watching
only a viewport. From the discussion above, it is clear that
there is a vast need for online 360o video caching schemes
which exploit 360o video features and do not necessitate the
delivery of the entire video scene.

In this paper, we propose a proactive caching scheme for
the transmission of 360o video in cellular networks. To the
best of our knowledge, this is the ﬁrst online caching scheme
for 360o videos. Our method aims at maximizing the overall
quality of the 360o videos delivered to the users, without
requiring a priori knowledge of 360o video and tiles popularity
distributions. To this aim, our method updates the cached
content based on limited observations regarding 360o video
consumption patterns, obtained from previous users’ requests.
We adopt tiles and layered encoding of 360o video because
of the ﬂexibility they offer to caching algorithms [1], [2],
[6]. These methods encode 360o videos into a number of
independently encoded tiles and multiple layers, as shown in
Fig. 1a. Encoding in tiles and layers allows network operators
to cache in high quality at each SBS only the parts of the
scene of each 360o video (i.e., the tiles that correspond to
these parts) that are the most popular to the users. Further, as
only some tiles of the 360o videos are popular, we introduce
the concept of virtual viewport, which is shaped by the overlap
that occurs because of the diverse users’ requests for different
viewports, as shown in Fig. 1b. Virtual viewports differ from
the original ones in that the tiles that comprise them are not
necessarily adjacent to each other, i.e., they do not form a
rectangular area. A virtual viewport has the same number of
tiles with regular viewports, but it consists of the most popular
ones. When a user requests a viewport of a 360o video in a
certain quality, then if some tiles of the requested viewport
also belong to the virtual viewport that is cached at the SBS
that received the request, these tiles will be served from that
cache. As a result, storing virtual viewports will lead to an
increase in the cache hit ratio, due to the greater ﬂexibility
they provide in terms of which tiles to cache in high quality.
In order to determine which videos and virtual viewports
to cache in each SBS, we ﬁrst formulate the problem of
360o video caching as a Markov Decision Process (MDP).
The aim is to ﬁnd the optimal set of 360o videos and virtual
viewports that should be cached at the SBS so that the overall
quality delivered to the users is maximized. This is done
by considering a limited history of users’ requests. Although
MDP offers an elegant way to describe our framework, the
requirement of knowing the state transition probabilities makes
it hard to evaluate the optimal policy (caching decisions per
360o video and virtual viewport) for our system. This require-
ment can be lifted with the use of Q-learning [9]. Despite Q-
learning convergence properties, it cannot be trivially applied
for large-sized problems. To address this limitation of the Q-
learning algorithm, we use the Deep-Q-Network (DQN) [10]
variant of Q-Learning. We evaluate the performance of our
solution for both real [11] and synthetic 360o video traces,

2

and compare its performance with that of known schemes
such as the Least Frequently Used (LFU), Least Recently
Used (LRU), First-In-First-Out (FIFO) algorithms. The results
illustrate the advantages of the proposed method compared to
its counterparts, in terms of the overall quality users enjoy, the
overall cache hit ratio, and the cost of delivering the requested
content to the users.

In summary, the main contributions of our work are:

• Reinforcement Learning framework: We introduce a novel
reinforcement learning framework for optimizing the content
cache placement of 360o videos, by formulating the problem
of caching 360o videos as a Markov Decision Process.
Our solution aims at maximizing the overall video quality
delivered to the users by taking into account both the 360o
videos and tiles’ popularity.

• Concept of Virtual Viewport: We introduce the concept of
the virtual viewport, which is shaped by the overlap of the
diverse users’ requests for different viewports. A virtual
viewport is comprised of the most popular tiles of a 360o
video over the users’ population. Virtual viewports enable us
to reduce the size of the online cache optimization problem
for 360o videos.

• Deep Neural Network representation: We use Deep-Q-
Network (DQN) to solve large instances of the online cache
optimization problem for 360o videos.

• Evaluation on real and synthetic 360o video traces: We
extensively evaluate our proposed solution for real naviga-
tion patterns extracted from the dataset described in [11],
as well as on synthetic navigation patterns in order to
show the beneﬁts coming from the introduction of virtual
viewports, and also, the impact of different users 360o video
consumption patterns on the overall quality users enjoy.
The rest of the paper is organized as follows. In Section
II, we overview work related to edge caching, reinforcement
learning, and tile-encoding of 360o videos. Next, in Section
III, we describe our system setup. Right after, in Section IV we
introduce the considered model of the users’ requests. Then,
we ﬁrst formulate our problem as an MDP in Section V, and
right after in Section VI, we show how DQN can be used to
solve the cache placement problem for 360o videos. In Section
VII, we thoroughly evaluate the performance of the proposed
scheme and compare it with other methods in the literature.
Finally, we draw conclusions in Section VIII.

II. RELATED WORK

In this section, we brieﬂy overview the literature related
to edge caching, online caching, and tile-based 360o video
streaming.

The use of edge caching has been proposed as an efﬁcient
way to bring content closer to the end-users and improve the
quality of the delivered content [12], [13]. In addition, caching
popular contents at the mobile edge servers has been shown to
reduce the usage of the pricey backhaul links [14]–[16] and the
network operation cost [17]. The optimal placement of layered
videos on edge caching systems is investigated in [18]. The
decisions regarding which video layers to cache in each SBS
are made by taking into account the caching cost, the available

3

encoding of the 360o videos into a number of quality layers
and tiles has been studied in [22]–[24]. These systems exploit
the fact that users are interested in viewing only a viewport
of the 360o video scene, and hence there is no need to deliver
the whole scene in high quality. Differently from [22]–[24],
in our previous work in [1], [2] we proposed a tile-based
collaborative caching scheme for 360o videos for video-on-
demand systems, where we showed the beneﬁts coming from
making the caching decisions on a per tile basis and the
advantages of exploiting SBSs collaboration. In contrast to
[1], [2], authors in [6] examine a tile-based caching scheme
that aims to optimize the error between the requested and
cached tile resolutions across different viewports as well as
the coverage of the tiles set. In their work, they examine the
caching of tile streams both at different resolutions and in a
layered encoding fashion. The works in [1], [2], [6] assume
known popularity and hence cannot be used in a straightfor-
ward way for the problem studied here. A motion-prediction-
based mechanism is proposed in [25], where viewers’ motion
is predicted with the use of machine learning. Similarly, the
navigation behaviors of users when watching 360o videos on
computers has been investigated in [26]. The results show that
viewers have similar viewing patterns for certain 360o video
categories. A navigation-aware adaptive streaming strategy is
presented in [27], where the aim is to optimize the rate at
which a tile is downloaded during the navigation of the 360o
video. The rate per tile optimization problem is formulated
as an integer linear programming problem. The proposed
solution reveals the beneﬁts of exploiting navigation patterns
on both quality and navigation-smoothness. The impact of
tile encoding on bandwidth saving, coding efﬁciency, and
scalability is examined in [28], where a tile-aware video
streaming system is proposed. The results show that an up
to 80% bit-rate reduction is achieved by only streaming the
tiles viewed by the user.

III. SYSTEM SETUP

In this section, we ﬁrst introduce the system model and the
network architecture, and then we discuss 360o video encoding
into multiple quality layers and tiles. Finally, we present the
employed viewport prediction algorithm.

1) Wireless cellular network: In this paper, we consider a
heterogeneous cellular network (HCN), like the one depicted
in Fig. 2. The network consists of N Small Base Stations
(SBSs), i.e., microcells, and a Macro-cell Base Station (MBS).
Let N = {1, . . . n, . . . , N } denote the set of the N SBSs,
and N + 1 represent the MBS. For notational convenience,
we also deﬁne the augmented set NB = N ∪ N + 1 that
includes the SBSs along with the MBS. The MBS is connected
to the core network through a high capacity backhaul link,
i.e., optical ﬁber, while the SBSs are connected to the MBS
through wireless millimeter-wave links.

Let pn be the communication range of the nth SBS and
P = {p1, . . . pn, . . . , pN } be the set that contains the commu-
nication ranges of all SBS. The communication range of the
MBS is pN +1, and is assumed to be large enough so that the
MBS can communicate with all SBSs. Each SBS n ∈ N has a

(a) Encoding of 360o video in two quality layers and several tiles.

(b) Overlapping viewports for various user requests, and virtual viewport.

Fig. 1. Users request different viewports encoded in quality layers and tiles.

cache capacity at the SBSs, and the social groups formed
by mobile users based on their content requests. Differently
from [18], caching several representations of multiple videos
that correspond to different qualities is examined in [13]. The
cached representations are decided so that the aggregate distor-
tion reduction of all the users is maximized while minimizing
the cost related to downloading the representations. In [12], the
delivery of 4K video quality in LTE-A networks is explored.
That work aims to assure for 4K live streaming systems high
Quality of Experience (QoE) to the users.

The aforementioned works consider that video popularity
proﬁles are known, which in many cases is not possible. To
address this limitation, the content popularity is predicted us-
ing reinforcement learning algorithms that exploit the demand
history [7], [8], [19], [20]. Speciﬁcally, in [7], the SBSs learn
the content popularity online, considering the switching cost
related to the addition of new ﬁles to the cache. Contextual
MABs are proposed for online cache optimization in [8] to
take advantage of users’ characteristics such as age, sex, etc.
Neural networks (NN) [19], [20] can be used to decide the
optimal cache placement when content popularity is unknown.
Speciﬁcally, a Deep Reinforcement Learning-based framework
aiming to maximize the long-term cache hit ratio is presented
in [19]. To limit the action space in [19], an Actor-Critic
algorithm based on the Wolpertinger architecture [21] is used.
Differently, in [20], an Actor-Critic algorithm is presented
where the actor uses the Gibbs distribution, and the critic uses
a deep neural network to minimize the average transmission
delay. To this aim, the users’ scheduling and content caching
policies are jointly designed.

The delivery of 360o videos encoded by advanced video
coding standards, e.g., H.265/HEVC, SHVC, that support the

4

assumed to be the same as the one that was requested in
the GOP g. For the ﬁrst GOP, without loss of generality, we
assume that the predicted viewport is the requested viewport.
Although the employment of advanced VP algorithms [32],
[33] would further improve the accuracy of the predicted
viewports, we do not adopt such algorithms as we aim to show
the advantages coming from caching. Further, the employment
of more advanced prediction algorithms would increase the
complexity of our system. At the same time, the conclusions
derived regarding the beneﬁts of tile-encoding and caching for
360o videos would stay unaltered.

4) End-to-end-delay: As we already mentioned, for each
GOP g ∈ G, all the tiles encoded at the base quality along with
all the enhancement layers up to the targeted quality for the
tiles that form the output viewport of the VP algorithm, need
to be prefetched to the users within a speciﬁc time window.
Failing to deliver these tiles on time would lead to buffer
underruns, as the tiles would not be available to the buffer at
the time they should be displayed. This would lead to degraded
QoE, as tiles that are not delivered on time are discarded. Let
us denote by dn the time needed to transmit one Mbit from
the nth SBS to a user, and dN +1 the time needed to transmit
one Mbit from the backhaul of the MBS to a user. Obviously,
dN +1 > dn, due to the additional time needed to initially fetch
data from the backhaul of the MBS to the SBS. The timely
delivery of the tiles of each GOP must respect the following
equation:

(cid:88)

(cid:88)

(cid:88)

ovglm · dn · qnu

vglm ≤ tdisp, ∀v ∈ V, ∀u ∈ U , g ∈ G

n∈NB

l∈L

m∈M

(1)
where ovglm is the size of the mth tile encoded in the lth
quality layer of the gth GOP of the vth 360o video. The
variable qnu
vglm takes the value 1 when the mth encoded tile
of the lth quality layer of the gth GOP of the vth 360o video
is delivered to the uth user from the cache of the nth SBS
(n ∈ N ) or the MBS (n = N + 1), and 0 otherwise. The
parameter tdisp denotes the playback duration of each GOP.
This constraint determines whether the tiles of the (g + 1)th
GOP can be prefetched as shown by the VP algorithm during
the playback of the gth GOP.

IV. USERS’ REQUESTS MODEL AND CACHE UPDATE
SCHEDULE

In this section, we present the considered users’ requests
model and the cache update schedule. We assume that for
each cached 360o video, our system caches all the tiles at the
base quality layer for all the GOPs, as well as the tiles of a
virtual viewport for each GOP in high quality. Recall that a
viewport consists of k tiles that form a rectangular area, while
a virtual viewport is comprised of the k most popular tiles,
which do not necessarily form a rectangular area, as shown in
Fig. 1b.

We assume that time is slotted in T time slots, and each time
slot has the duration of one GOP. When a user is interested in
watching a 360o video with duration of G GOPs, they should

Fig. 2. Considered network architecture.

cache capacity Cn ≥ 0, ∀n ∈ N where popular content can be
cached. We further assume that there are U users forming the
set U = {1, . . . u, . . . , U }. Since some users may be located
in the overlap of the coverage areas of multiple SBSs, these
users are assigned to the SBS with the maximum signal-to-
interference-plus-noise ratio (SINR).

2) Video Library: We assume that users request 360o video
ﬁles from a content catalogue of V = |V| ﬁles, with V =
{1, . . . v, . . . , V } being the set of the 360o videos. Each 360o
video is encoded into G Group of Pictures (GOPs) that form
the set G = {1, . . . , g, . . . , G}. Each GOP is encoded into L
quality layers and M tiles. For each tile, the ﬁrst quality layer
is known as the base layer, while the rest L − 1 layers are
called enhancement layers. The acquisition of the base layer
of a tile offers reconstruction of that tile at the lowest available
quality, while the acquisition of all the layers of a tile up to
the lth gradually improves the reconstruction quality of that
tile. For each GOP, in order to satisfy a user demand for a
requested viewport at a certain quality, the user has to acquire
the base layer for all the tiles of the video along with all the
enhancement layers corresponding to the demanded quality for
the tiles that form the requested viewport.

3) Viewport Prediction: A critical component of 360o video
streaming is the Viewport Prediction (VP) [29]–[31]. The aim
of VP is to predict the requested viewport by a user in the
near future (e.g., 1-2 sec), and prefetch it to the user. This
is essential to provide smooth playback, as SBSs are not able
to respond instantly to the user head movements due to the
end-to-end delay.

VP can be done by observing the most recently requested
frames by a user. These past requests are used to forecast
the viewport that will be requested in the next few seconds.
Such an approach is examined in [29], [30], where authors
use variants of the linear regression algorithm to predict the
users’ head movements. A more na¨ıve approach is presented
in [31], where VP is performed assuming that the users’ head
orientation will not change in the next 3 seconds.

In our system,

to perform viewport prediction, we use
the Last Sample Replication (LSR) algorithm [30]. We have
selected this algorithm because of its low complexity. Based
on the LSR, the predicted viewport of the GOP g + 1 is

5

the SBS from a remote content server through the backhaul
link of the MBS and be delivered to the user if the end-to-end
constraint permits. Then, a decision is made about whether
to cache some or all of the tiles that were fetched through
the backhaul. The latter decision reﬂects tiles’ popularity of a
360o video.

The proposed cache optimization algorithm regarding which

tiles to cache is presented in the next sections.

V. MDP FORMULATION

In this section, we formulate the problem of caching 360o
videos in cellular networks as a Markov Decision Process [35].
Since in our setting users can download the requested content
only from the SBS that they are connected to, each SBS
optimizes the cache use and the content replacement strategy
independently of each other. Hereafter, following reinforce-
ment learning terminology, SBSs are also called agents.

State Space: In the considered setting, the SBS n ∈ N can
be in a state s ∈ S, where S represents the set of all possible
states. Each state is characterized by the features extracted
from observations of users’ past requests, considering ﬁxed
observation windows. Below we describe the features we
consider.

s xn

The ﬁrst feature has two components that refer to the total
number of requests for each cached 360o video that occurred
in: a) a short-term window of Hs sets of user requests (see
Fig. 3), and b) a long-term window of Hl sets of user requests.
This feature associated with the cache of SBS n ∈ N can be
described by the vector xn = [xn
f,i], ∀f ∈
{s, l}, ∀i ∈ 1, . . . , C, and xn
f,i refers to
the total number of times the video in the ith cache position
was requested (either in short-term or long-term). Thus, the
f is given by {1, . . . , Hf }C and the overall
feature space X n
feature space is X n = X n
l . Recall that, C is the cache
capacity of the SBS. It is worth noting that the above deﬁnition
of features reduces the feature space drastically, as features
are computed for all the tiles (cached videos) in base quality
instead of each tile in base quality independently.

l ] with xn
f,i ∈ {1, . . . , Hf }. xn

f = [xn

s × X n

Similarly,

the second feature has two components that
correspond to the total number of requests for tiles in high
quality of the cached 360o videos that happened during: a)
the short-term window of Hs sets of user requests, and b) the
long-term window of Hl sets of user requests. This feature
is associated with the cache of SBS n ∈ N and is computed
for each cached tile in high quality of GOP g, when request
wg, g > 0 is processed. Let the vector yn = [yn
l ] describe
this feature, where yn
f = [yn
f,i,j], ∀f ∈ {s, l}, ∀j ∈ {1, . . . , k},
∀i ∈ {1, . . . , C} and yn
f,i,j denotes the
number of times the jth tile of the ith cached 360o video was
requested at the nth SBS. Thus, the feature space Y n
f is given
by {1, . . . , Hf }kC and the overall feature space for the cache
space at the nth SBS is given by Y n = Y n

f,i,j ∈ {1, . . . , Hf }. yn

s yn

s × Y n
l .

Finally, the third feature has two components that corre-
spond to the number of times the examined item (tile in
high quality or 360o video in base quality) was requested
at the nth SBS: a) in the short-term window of Hs sets of
user requests, and b) in the long-term window of Hl sets of

Fig. 3. User requests for a 360o video.

send G consecutive requests,1 as shown in Fig. 3. The ﬁrst
request is special and comprises a request w0, which is used
by our algorithm in Section VI to predict the popularity of
each 360o video, and a request w1 for obtaining the viewport
for the ﬁrst GOP. The request w0 is to acquire the 360o video
at the base quality for all GOPs. As we will show in Section
VI this request is used to reduce the size of the optimization
problem. Though all the tiles encoded at the base layer are
requested at the ﬁrst time slot, they may be delivered to the
users along with the enhancement layer tiles. We assume that
the request w0 occurs at the same time slot with the request
w1. The wgth request, g ∈ {1, . . . , G}, is to obtain the tiles
that comprise the requested viewport, and belong to the gth
GOP, in high quality. These requests are used by our algorithm
presented in the next sections to calculate the popularity of
each tile per GOP. For notational convenience, we denote the
ith set of requests {wi
1, . . . , wi
G} made by a user for a
360o video by W i, while W = ∪iW i contains all the sets of
users’ requests. Hereafter, we drop the index of the ith set of
requests when is not needed.

0, wi

The decisions of which tiles of a 360o video to cache at an
SBS and in what quality are made online, i.e., when the content
is requested. Speciﬁcally, when a user request w0 arrives at an
SBS in the time slot 1, if the tiles of the requested 360o video
at base quality are not cached in it, a decision has to be made
regarding whether to cache them. This decision depends on
the popularity of the video. If the decision is to cache these
tiles, all the tiles of the base layer for all GOPs will start
being fetched through the backhaul and cached at the SBS,
replacing the tiles of another 360o video that will be evicted.
When the user issues further requests wg for receiving tiles of
the GOPs of the 360o video in high quality, our system uses
the viewport prediction algorithm described in Section III to
decide which tiles of the predicted viewport will be fetched
from the backhaul so that they can be delivered to the user on
time. When the tiles that form the predicted viewport arrive at
the SBS, we identify two cases: (a) if the decision for w0 was
not to cache the 360o video in base quality, the fetched tiles
will be delivered to the user but these tiles will not be cached
at the SBS, as the video is not popular enough, (b) if the
decision for w0 was to cache the 360o video in base quality,
then for each request wg, g ∈ G, in case some (or none) of
the tiles that form the predicted viewport are cached in high
quality a soft cache hit [34] will occur. In such a case, the
cached tiles of the predicted viewport will be served to the
user directly from the SBS, while the tiles of the predicted
viewport that are not cached at the SBS will be fetched to

1When a user wants to stop watching a video, they halt sending requests

for the following GOPs.

user requests. Speciﬁcally, when the examined item is a 360o
video in base quality, this feature refers to the total number
of times this video was requested at the nth SBS. This is
the case when a request w0 is received. When the examined
item is a tile of a 360o video in high quality, i.e. for requests
wg, g > 0, the feature corresponds to the total number of
times the examined tile was requested. The feature vector
l ] with zn
is deﬁned as zn = [zn
f ], ∀f ∈ {s, l},
and ∀zn
f stands for the total number of
times the item (tile in high quality or 360o video in base
quality) was requested. Thus, the feature space Z n
f is given
by {1, . . . , Hf } and the overall feature space for the examined
item is Z n = Z n

s zn
f ∈ {1, . . . , Hf }. zn

f = [zn

s × Z n
l .

Following the above deﬁnitions of the features, the overall

state space is given by:

S n = X n × Y n × Z n.

(2)

Hereafter, we drop the superscript of the state space and use
S as each SBS makes decisions independently of each other.
Action Space: As we mentioned in Section IV, users’
requests w0 correspond to a request for a 360o video in base
quality for all the GOPs of this video, while requests wg ∈ W
with g ∈ 1, . . . , G stand for a request for a viewport of the
gth GOP encoded in high quality.

When an SBS receives a request from a user, there are three
possible cases regarding what data is cached at the SBS: a)
no data for the requested 360o video is cached, b) the 360o
video is cached at the base quality and the predicted viewport
is cached at high quality and, c) the 360o video is cached at
the base quality, but a different viewport is cached at high
quality.

In case a user requests a 360o video that is not cached
at
this has to be fetched through the backhaul
the SBS,
and be delivered to the user. Fetching content through the
backhaul adds cost to the network operator and increases the
delay experienced by the users. When no data of a 360o
video are cached at the SBS, a user request wg ∈ W with
g ∈ {0, . . . , G} is processed as follows. To accommodate a
request w0, all the tiles of the requested 360o video encoded at
the base quality will start being fetched through the backhaul
and delivered to the user for all the GOPs. For each of the
following requests wg with g ∈ {1, . . . , G}, all the tiles of the
viewport indicated by the prediction algorithm in Section III
encoded in high quality will be fetched through the backhaul in
high quality, and be delivered to the user. Therefore, when the
requested 360o video is not cached at the SBS, there are two
types of possible actions: a) to leave the cached content at the
SBS unchanged, or b) to evict the tiles of a cached 360o video
from the cache of the SBS and replace them with the tiles of
the requested one. Thus, there are C + 1 possible actions.
Let the set A1 = {A10, A11 . . . , A1i, . . . , A1C} denotes all
the possible actions when a video is not cached at the SBS.
A10 stands for the case the cached content at the SBS is left
unchanged, and A1i means that all the tiles of the ith cached
video at the SBS will be replaced by the corresponding tiles
of the requested 360o video.

6

If both the requested 360o video encoded in the base quality
and the tiles that form the predicted viewport for the examined
GOP, e.g., g ∈ {1, . . . , G} encoded in high quality are cached
at the SBS, the request wg will be served from the cache, and
no action will be taken. Then, a decision regarding whether
to cache the tiles of the predicted viewport for the next GOP,
i.e., g +1, is made. This happens because our scheme employs
the LSR algorithm, as we described in Section III-3.

Finally, if the 360o video is cached at the base quality,
but a different viewport than the predicted one is cached
at the SBS at high quality, the requested tiles that are not
cached have to be fetched through the backhaul, and then
be served to the user. In that case, the possible actions are
the following: a) to leave the cached viewport unchanged, or
b) to cache some of the tiles, which were not part of the
predicted viewport, and were fetched through the backhaul. To
limit the action space, we assume that each action concerns
only one tile that may be updated at the SBS cache. In this
way, the agent takes sequentially actions for all tiles that were
fetched through the backhaul in terms of whether to cache
them at the SBS or not. This process is repeated until a
decision is made for all the fetched tiles. Since each viewport
consists of k tiles, the possible actions for a tile form the set
A2 = {A20, A21 . . . , A2j, . . . , A2k}. The action A20 denotes
the case where the cached content is left unchanged, while the
action A2j corresponds to the case where the candidate tile
will replace the jth tile in high quality of the requested 360o
video that was cached at the SBS. We consider that a GOP
is fully processed when a decision has been made for all the
tiles that were fetched through the backhaul. After completing
the sequential decisions, the cached virtual viewport for the
considered video is updated. Next, the subsequent GOP is
processed in a similar way. We would like to note that the
use of virtual viewports and the decomposition of actions on
per tile basis permits to greatly reduce the action space as
otherwise, the action space would have been comprised of all
possible viewports.

Considering the above, the overall action space A is deﬁned

as:

A = A1 × A2.

(3)

Reward: We deﬁne the reward of each action to be the
average distortion reduction the users will experience in the
next H sets of users’ requests. Thus, given a state s ∈ S, the
reward of taking action a ∈ A is calculated as:

r(s, a) =

1
H

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

1(φh,v,g,l,m) · δv,g,l,m

h∈H

v∈V

g∈G

l∈L

m∈M

(4)
When we process the ith set of requests W i, the set H =
{W i+1, . . . , W i+h, . . . , W i+H } contains the next H sets of
user requests. In our formulation, the reward in (4) is obtained
after the next H sets of user requests have occurred [36].
The term φh,v,g,l,m represents the mth tile of the lth quality
layer of the gth GOP of the vth 360o video of the W i+hth
set of user requests. The term δv,g,l,m denotes the distortion
reduction achieved by obtaining the corresponding tile. The

indicator function 1(φh,v,g,l,m) in (4) is deﬁned as:

1(φh,v,g,l,m) =

1,

0,






if φh,v,g,l,m can be delivered
on time for W i+h.
if φh,v,g,l,m cannot be delivered
on time for W i+h.

Optimization Problem:
In order to quantify how good a particular state s is, we
estimate the value function. This function corresponds to the
expected discounted reward of policy π when starting from a
state s and then following this policy. The value function is
formally expressed as:

Vπ(s) = Eπ[Gτ |Sτ = s] = Eπ[

∞
(cid:88)

γτ Rτ +κ+1|Sτ = s]

(5)

κ=0

where Gτ , Rτ , and Sτ are the expected reward, the immediate
reward and the state at time τ , respectively. The parameter
0 ≤ γ ≤ 1 is called discount rate and gradually discounts
the effect of an action to future rewards. If γ = 0,
the
agent is “myopic” and maximizes the immediate reward. As γ
approaches 1, the objective takes into account future rewards
more strongly, and the agent becomes farsighted. The above
equation can be rewritten as a Bellman equation [37] as
follows:

Vπ(s) =

π(a|s)

(cid:88)

(cid:88)

p(s(cid:48), r|s, a)[r + γVπ(s(cid:48))]

(6)

a

s(cid:48),r

where p(s(cid:48), r|s, a) is the transition probability from the state
s to the state s(cid:48) by taking the action a with a reward r.

VI. DQN BASED CACHE OPTIMIZATION

to
The main challenge to solve (6) is the requirement
know the transition probabilities p(s(cid:48), r|s, a). For the studied
problem, continuous computation of the transition probability
matrix is necessary because of the non-stationary requests’
dynamics, which is computationally demanding. To overcome
this problem, we can adopt
the Q-learning algorithm [9],
which learns the optimal policy through interaction with the
environment. Q-learning uses the Q(s, a) values instead of
using the value function in (6). These values reﬂect how
“good” is to take action a when in state s. Similarly, Qπ(s, a)
represents how good it is to take action a when starting from
state s, and thereafter follow the policy π. This is deﬁned as
follows:

∞
(cid:88)

Qπ(s, a) = Eπ[

γτ Rτ +k+1|Sτ = s, Aτ = a]

(7)

where Aτ is the action at time τ .

k=0

The optimal policy is the one that maximizes the expected

reward for all states and is given by:

π(cid:63)(s) = arg max

(Q(s, a)), s ∈ S

(8)

a∈A

To determine the optimal policy π(cid:63)(s),

the Q-learning
algorithm updates the Q(s, a) values iteratively. Speciﬁcally,
the Q(s, a) values are updated according to the formula:
Q(sτ , aτ ) = (1 − ατ )Q(sτ , aτ ) + ατ [Rτ + γ max
a∈A

Q(sτ +1, a)]
(9)

7

where ατ is the learning rate at time τ . The learning rate
corresponds to the rate at which newly acquired information
overrides old one.

Q-learning can select actions using policies such as the (cid:15)-
greedy, where (cid:15) ∈ [0, 1], which ensures that random actions
are always explored and overﬁtting is avoided. According to (cid:15)-
greedy policy, the action resulting in the maximum Q(sτ , aτ )
value is selected with probability 1 − (cid:15), and a random action
is selected with probability (cid:15). The Q-learning algorithm is
guaranteed to converge to the optimal solution [38] when
all the state-action pairs are visited inﬁnitely often, and the
learning rate ατ satisﬁes the following conditions:
∞
(cid:88)

∞
(cid:88)

α2

τ (s, a) < ∞,

∀(s, a) ∈ S × A

ατ (s, a) = ∞ and

τ =0

τ =0

(10)
The Q-learning algorithm is an efﬁcient method to deter-
mine the optimal policy when the state-action space is small.
However, when the state-action space grows, the lookup table
where the Q(s, a) values are stored becomes prohibitively
large. To overcome this drawback of Q-learning, we employ
a Deep Reinforcement Learning (DRL) [10] approach. Using
DLR the Q(s, a) values are approximated by a Deep Neural
Network (DNN). The DRL framework consists of two phases:
a) the ofﬂine phase where the DNN is trained, and b) the online
phase during which the actual caching decisions are made.

During the ofﬂine phase,

the DNN is initially built by
selecting some random weights θ. Then, the DNN is trained
with a number of historic transition proﬁles, as in [39]. These
proﬁles correspond to request patterns experienced in the past.
The training of the DNN is performed in a mini-batch manner.
Speciﬁcally, at each training epoch, a sample of the transition
proﬁles and their estimated Q values are obtained by randomly
sampling the experience replay memory D, which has capacity
ND. This mechanism is used to remove the correlations
between observations, while the transitions between the states
become more independent and identically distributed.

To stabilize DNN training, apart from the experience replay,
we use the mechanism of the ﬁxed target network [38].
According to this mechanism, a second DNN is employed,
which is called ﬁxed-target network. This network has the
same architecture as the original DNN that is used for the
function approximation (evaluation network). Not using a
separate network to estimate the target Q values would lead
to destabilization. This would happen because as the Q values
(output of the evaluation network) are updated towards the
target values (calculated by (9)), the target values will also
be updated in the same direction. To overcome this problem,
the weight parameters of the target network are kept ﬁxed and
are copied from the evaluation network only every NT steps.
Thus, using a second network to estimate the target Q-values
leads to a more stable training, since the Q-values obtained
from the evaluation network are updated towards a target that
is kept ﬁxed (for a number of steps).

When the ofﬂine phase is completed, the obtained weights
θ are used to initialize the DNN in the online phase. During
this phase, if the candidate item (360o video in base quality
or tile in high quality) is not cached at an SBS, the agent
takes an action according to the (cid:15)-greedy policy (i.e., it decides

Algorithm 1 DRL Framework

1: Ofﬂine Phase
2: Initialize the evaluation network with weights θ
3: Initialize the ﬁxed target network with weights θ(cid:48)
4: Initialize the experience buffer D with capacity ND
5: Initialize a random exploration process
6: Train the DNN with features (s, a) and outcomes Q(s, a)

in a mini-batch manner

7: Online Phase
8: for each time slot do

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

25:

26:

27:

28:

for each user request in a time slot do

for each candidate item of a user request do

Receive observation sτ
if the candidate item is not cached at the SBS then

With probability 1 − (cid:15) select
Q(sτ , a, θ)

aτ = arg max
a∈A

Otherwise,

aτ ← random action

Take action aτ and observe rτ , sτ +1
Store the tuple (sτ , aτ , rτ , sτ +1) in the experi-
ence replay buffer D

end if

Update cache hit ratio
Update Feature Space
if Modulo(w, NB)==0 then

Sample MB tuples from D
Update DNN by minimizing Loss(θ) in (11)
Update ﬁxed target network weights

end if

end for

end for

29: end for

whether to cache the item or not and what content will be
replaced), and then proceeds to the next state. In this way,
new actions are always explored, and cached content whose
popularity the algorithm overestimated in the past will not
stay in the cache forever. After the execution of each action,
the tuple (sτ , aτ , rτ , sτ +1) is stored in the experience replay
buffer D, in order to be used later for the training of the DNN.

In the online phase, the DNN is trained in a similar way
to the ofﬂine phase, where a batch of MB transition proﬁles
is randomly sampled from the experience replay memory D
every NB steps. The DNN is trained towards the target Q
values using the back-propagation method, by minimizing the
loss function Loss(θ). The loss function is given by:

Loss(θ) =

1
MB

(cid:88)

i∈MB

(yi − Q(si, ai, θ))2

(11)

8

i, a(cid:48)
where yi = ri + maxa(cid:48)
value of the ith sample, and θ−

Q(s(cid:48)

i

i, θ−
i = θi−NB .

i ) represents the target Q

The overall DRL framework is presented in Algorithm 1.

VII. PERFORMANCE EVALUATION

In this section, we examine the performance of the proposed
DQN-based online caching algorithm for 360o videos in cellu-
lar networks. First, we describe the schemes under comparison
and provide the simulation setup. Next, we show the conver-
gence of the loss function during the training of the DNN.
Then, we analyze the impact of various system parameters on
the performance of the system. Finally, we demonstrate how
the viewports’ popularity shapes the popularity of each tile.

A. Simulation Setup

Let us describe the main characteristics of the schemes

under comparison and the proposed scheme:

1) Least Frequently Used (LFU): In this scheme, the net-
work operator keeps track of the number of requests that
occurred for each cached 360o video. When a user request
arrives at an SBS, then: a) if the requested 360o video
is not cached at it, all the tiles of the 360o video that
was requested the least number of times will be evicted
from the cache of the SBS. Then, for all the GOPs, all
the tiles of the requested 360o video encoded at the base
layer along with the tiles of the predicted viewport in high
quality will be cached at the SBS; b) if the 360o video
is already cached at the base quality for all the GOPs,
but some of the cached tiles in high quality are different
from the ones that belong to the predicted viewport, these
tiles will be evicted and be replaced by the tiles of the
predicted viewport.

2) Least Recently Used (LRU): In this scheme, the network
operator keeps track of how recent are the requests that
occurred for each cached 360o video. When a user request
happens at an SBS, then: a) if the requested 360o video
is not cached at the SBS, all the tiles of the 360o video
that were requested the least recently will be evicted from
the SBS cache. Next, all the tiles of the requested 360o
video will be cached at the SBS at the base quality for
all GOPs along with the tiles of the predicted viewport in
high quality; b) if the 360o video is cached at the SBS, for
each GOP, if some of the cached tiles in high quality are
different from the ones of the predicted viewport, these
tiles will be replaced by the corresponding tiles of the
predicted viewport.

3) First-In-First-Out (FIFO): In this scheme, the network
operator keeps track of when the requests for each cached
360o video occurred. When a user request arrives at an
SBS, then: a) if the requested 360o video is not cached at
the SBS, all the tiles of the 360o video that was cached
the earliest will be evicted from the SBS. Then, for all
GOPs, all the tiles of the requested 360o video encoded at
the base layer, along with, for each GOP, the tiles of the
predicted viewport in high quality will be cached at the
SBS in the place of the evicted tiles; b) if the 360o video
is cached at the SBS, then for each GOP, if some of the

cached tiles in high quality are different from the ones
forming the predicted viewport, these tiles will be evicted,
and be replaced by the tiles of the predicted viewport.
4) Proposed Scheme: In the proposed scheme, the caching
decisions are made exploiting observations derived from
past users’ requests. This scheme employs the DQN
algorithm presented in Section VI to decide on the cache
updates. For each cached 360o video, all the tiles at the
base quality along with the most popular tiles in high
quality that form a virtual viewport, are cached at the
SBS for all the GOPs.

For the sake of simplicity, all the conducted experiments
are done assuming a single SBS and an MBS. This does
not affect the derived conclusions, as SBSs make caching
decisions independently of each other. As we have already
mentioned in Section III, although SBSs’ coverage area may
overlap, users are assigned to a single SBS, i.e., the one with
the maximum SINR. The exploitation of opportunities arising
because of the overlapped coverage areas is part of our future
work. We would like to emphasize that our algorithm can be
applied to networks with an arbitrary number of SBSs. This is
because as each user is assigned to a single SBS, our algorithm
can run in parallel for each SBS. The coverage range of the
SBS is set to be Pn = 300m, while the coverage range of the
MBS is PN +1 = 2000m, and is large enough to permit the
communication with the SBS. The delay needed to obtain one
Mbit from the SBS is dn = 1/6 sec/Mbit, while the delay to
deliver one Mbit from the backhaul of the MBS to the user is
dN +1 = 1/2 sec/Mbit. The cache capacity of the SBS is set
to be enough to store 10% of the 360o videos of the content
library. The number of users is U = 200 who are randomly
placed in the coverage area of the SBSs. Recall that, when
a 360o video is cached at the SBS, this means that for each
GOP, all the tiles are cached at the base quality, and the tiles
that form a virtual viewport are cached in high quality.

The content library contains V = 500 videos, while each
video is encoded in 30 GOPs. The duration of each GOP
is assumed to be tdisp = 1 sec. Each GOP is encoded into
M = 12 tiles, where each tile is encoded into L = 2 quality
layers. The bitrate of the base layer is 2 Mbps, while the
bitrate of the enhancement layer is 12 Mbps. The size of each
viewport consists of 4 tiles, while the available viewports are
the ones depicted in Fig. 4. The distortion reduction achieved
by obtaining a tile at the base quality layer is 30 dB, while
the distortion reduction achieved by receiving a tile at the
enhancement quality layer is 10 dB. The probability of a
360o video to be requested from a user follows the Zipﬁan
distribution [40], as it is common to the literature. The shape
parameter of the Zipﬁan distribution is set to ηv = 1. The
probability of a 360o video v ∈ V to be selected under the
Zipﬁan distribution is given by:

pv =

1/vηv
v∈V 1/vηv

(cid:80)

.

We consider realistic navigation patterns, extracted from
the dataset in [11], from which we sampled 200 trajectories
of head movements. These trajectories are obtained from 10
different videos, where for each video, we sampled 20 different

9

Fig. 4. Considered set of viewports. The light blue area highlights the area
covered by the viewports.

trajectories. With equal probability, we mapped the index of
each one of the V = 500 videos from the content library to
one of the 10 sampled videos of the dataset. Then, for each
of the V = 500 videos of the content library, according to its
mapped index, we selected one of the 20 available trajectories
uniformly at random.

We assume that the total number of sets of users’ requests
is W = 10000. The short-term time window refers to Hs =
300 sets of user requests,2 while the long-term time window
corresponds to Hl = 1000 sets of user requests. The reward in
(4) is calculated for the next H = 1000 sets of user requests.

B. Deep Neural Network Training

We consider a Deep Neural Network (DNN), which consists
of four fully connected layers, i.e., the input layer, two hidden
layers, and the output layer. As the cache capacity of our
system is C, the input layer consists of 10C + 2 nodes that
reﬂect the vector size of each state. The hidden layers and the
output layer consist of 5C + 1 nodes, as there are 5C + 1
total actions. The activation function of the hidden layers is
the “ReLu”, while the activation function of the output layer
is the “linear” function. The DNN is trained with the Adam
optimizer. The DNN is trained for 100 epochs in order to
become sufﬁciently accurate. The learning rate is set to be
α = 0.001, while the (cid:15)-greedy parameter is set to (cid:15) = 0.05.
The discount factor is set to be γ = 0.6. The experience replay
buffer is set to be D = 2000, while the mini-batch size is set
to MB = 32. The mini-batch samples are obtained every
NB = 200 requests. The convergence of the loss function
during the training phase for the basic scenario is presented in
Fig. 5. When the DNN is trained with different system settings
than the ones of the basic scenario, a similar convergence
behavior is noticed.

C. System Parameter Analysis

1) Cache Size: First, we examine the impact of the cache
size on the overall quality of the rendered viewports. To this
aim, we vary the cache capacity C in the range [5, 25]%

2Each set of requests corresponds to the tiles of a single video demanded

by a user.

10

Fig. 5. MSE of the loss function with respect to the training epochs.

Fig. 6. Y-PSNR of the rendered viewports with respect to the cache size for
all the schemes under comparison.

of the size of the content library. As we can see in Fig. 6,
the proposed scheme outperforms the LFU, LRU and FIFO
schemes, for all cache sizes. In particular, for typical cache
capacity sizes, i.e., [5-10]%, the performance gap between
the proposed scheme and the LFU, the LRU and the FIFO
is about 1 dB, 1.5 dB, and 2 dB, respectively. This is because
the proposed scheme achieves a better cache hit ratio, as
shown in Fig. 7. The increased cache hit ratio of the proposed
scheme is attributed to the use of the DQN that learns from
the experience of the past observations, which content should
be cached. In addition, unlike LFU, LRU and FIFO, where the
cached tiles in high quality correspond to actual viewports, in
the proposed algorithm, the tiles that will be cached for each
360o video in high quality correspond to virtual viewports.
This provides us with greater ﬂexibility to decide the cached
tiles. The effect of the increased cache hit ratio on the quality
of the rendered viewports comes from the fact that the tiles
that are delivered from the cache of the SBS to the users are
delivered with a smaller delay. Hence, more tiles are delivered
in total to the users under the considered tight time constraints.
When the cache capacity is large, i.e., 25%, the performance
gap between the proposed algorithm and the LFU, the LRU
and the FIFO schemes closes to about 0.8 dB, 1 dB and 1.4
dB, respectively. This happens because as the cache capacity
becomes larger, most of the popular content is stored in the
SBS cache for all the schemes.

2) Video popularity distribution: In Fig. 8, we analyze the
impact of the skewness parameter of the Zipﬁan distribution,
which characterizes the 360o video popularity. Speciﬁcally,
we alter the shape parameter ηv in the range [0.8, 1.6] and
measure the overall quality of the rendered viewports for all
the schemes under comparison. We note that an increase in the
value of the Zipf shape parameter ηv leads to an increase in the
overall rendered quality for all the schemes. This is because
bigger values of ηv mean that the video popularity distribution
gets steeper, i.e., a smaller number of 360o videos is popular,
which increases the efﬁciency of the cache utilization. We
can further observe that as the users’ requests concern a
smaller number of videos (big ηv values), the performance gap
between the proposed algorithm and the LFU, the LRU, and
the FIFO schemes decreases. For example, as the skewness

Fig. 7. Cache Hit Ratio with respect to the cache size for all the schemes
under comparison.

parameter changes from 0.8 to 1.6,
the performance gap
between the proposed algorithm and the LFU decreases from
∼ 1 dB to ∼ 0.6 dB. This is attributed to the fact that as
a smaller number of 360o videos becomes popular, most of
these videos will be cached at the SBS for all the schemes.

3) Viewports’ popularity distribution: Besides video pop-
ularity, we examine the impact of viewports’ popularity. We
ﬁrst assume that the viewports’ popularity follows a Zipﬁan
distribution with skewness parameter ηp. To analyze the impact
of the skewness parameter on the quality of the rendered
viewports, we vary the shape parameter ηp in the range [0.5,
2.5]. The performance of the schemes under comparison is
depicted in Fig. 9. From the results, we can note that an in-
crease of the skewness parameter ηp leads to an increase in the
overall quality of the rendered viewports for all the examined
schemes. This is because as the parameter ηp increases, the
user requests for the various parts of the 360o video scenes
become less diverse. Thus, the cache effectiveness is improved.
In addition, as the skewness parameter changes from 0.5 to
2.5, the performance gap between the proposed algorithm
and the LFU increases from about 0.5 dB to about 0.65 dB,
respectively. This is because unlike LFU, in the proposed
algorithm, the caching decisions for the tiles that will be
cached in high quality are made for virtual viewports, which
offers increased ﬂexibility in the caching decisions regarding

020406080100Epoch051015202530MSE103510152025Cache Size (%)32333435363738Y-PSNR (dB)ProposedLFULRUFIFO510152025Cache Size (%)20304050607080Cache Hit Ratio (%)ProposedLFULRUFIFO11

Fig. 8. Y-PSNR of the rendered viewports with respect to the Zipf shape
parameter of the 360o videos for all schemes under comparison.

Fig. 10. Cache hit ratio with respect to the cache size for the proposed scheme
considering different viewport popularity distributions.

Fig. 9. Y-PSNR of the rendered viewports with respect to the Zipf shape
parameter of the viewports for all schemes under comparison.

Fig. 11. Backhaul usage with respect to the Cache Size for all schemes under
comparison.

which tiles to cache. Thus, as the requests for the various
viewports become less diverse, the performance gains in the
proposed algorithm increase. Similar conclusions can be drawn
by comparing the proposed scheme with the LRU and FIFO
schemes.

In Fig. 10, we evaluate the cache hit ratio of the proposed
scheme for: a) our basic scenario where the requests for the
viewports are according to the dataset [11], b) the case where
the requests for the viewports follow the Zipﬁan distribution
while the shape parameter ηp takes a value from the range
[0.5, 1.5], and c) the case where all the user requests are for
one viewport, which we term as “Selective”. To this aim, we
vary the cache size from 5% to 15% of the content library. As
we can observe, the “Selective” distribution achieves a better
cache hit ratio in all cases. This is expected, as when the
viewports follow either the dataset or the Zipﬁan distribution,
the requests for the viewports are diverse, while in case of
the Selective distribution, all requests are for one viewport.
In addition, the cache hit ratio is better when the skewness
parameter is higher as described above, while the performance
of the dataset, is comparable with the case when the skewness
parameter is ηp = 1.

4) Backhaul Usage: In Fig. 11, we compare the perfor-
mance of all the schemes under comparison in terms of the
backhaul usage. This is a very important performance indicator

of the caching schemes since ﬁeld trials [41] have shown that
by reducing the backhaul usage, the network service cost is
also reduced. To this end, we vary the cache size in the range
[5, 25]% of the content library and measure the backhaul
usage, in terms of the bandwidth that should be communicated
to satisfy the demands. As expected, an increase in the cache
size leads to a decrease in the backhaul usage for all cases.
This is because as the cache size increases, more videos will
be able to be stored at the SBS cache, thus, more content
will be served locally to the users. In addition, we can note
that as the cache size increases, the performance gap between
the proposed method and the other schemes under comparison
decreases. Speciﬁcally, as the cache size increases from 5% to
25%, the performance gap between the proposed method and
the LFU decreases from about 154.4 GB to approximately
106.15 GB. This is because as the cache size increases, most
of the requested content will be able to be cached at the SBS,
and thus, the effectiveness of the caching improves for all
schemes.

D. Overlap between Viewports

In this section, we present how the overlap between the
various viewports shapes the popularity of each tile. To this
aim, we examine the popularity of each viewport, along with
the popularity of each tile. These popularities are computed

0.811.21.41.6Zipf Shape parameter v303234363840Y-PSNR (dB)ProposedLFULRUFIFO0.511.522.5Zipf Shape parameter p32333435363738Y-PSNR (dB)ProposedLFULRUFIFO51015Cache Size (%)304050607080Cache Hit Ratio (%)SelectiveZipf np=1.5Zipf np=1Zipf np=0.5Dataset510152025Cache Size (%)0.811.21.41.61.82Backhaul Usage (TB)ProposedLFULRUFIFO12

taken. In this way, we are able to cache the 360o videos that
are predicted to be the most popular, along with for each GOP,
a virtual viewport. To evaluate our method, we use both real
and synthetic navigation patterns. We extensively compare our
proposed method with the LFU, LRU, and FIFO schemes.
The results show that the proposed method outperforms its
counterparts. This improved performance is attributed to the
exploitation of the tiles’ popularity and the use of virtual
viewports instead of the original ones, which increases the
ﬂexibility in the caching decisions.

REFERENCES

[1] P. Maniotis, E. Bourtsoulatze, and N. Thomos, “Tile-based joint caching
and delivery of 360o videos in heterogeneous networks,” in Proc. of
IEEE 21st Int. Workshop on Multimedia Signal Processing (MMSP’19),
Kuala Lumpur, Malaysia, Malaysia, Sep. 2019.

[2] ——, “Tile-based joint caching and delivery of 360o videos in hetero-

geneous networks,” IEEE Trans. on Multimedia, in press.

[3] X. Corbillon, G. Simon, A. Devlic, and J. Chakareski, “Viewport-
adaptive navigable 360-degree video delivery,” in Proc. of IEEE Int.
Conf. on Communications (ICC’17), Paris, France, May 2017.

[4] W.-C. Lo, C.-L. Fan, J. Lee, C.-Y. Huang, K.-T. Chen, and C.-H. Hsu,
“360 video viewing dataset in head-mounted virtual reality,” in Proc. of
the 8th ACM on Multimedia Systems Conf. (MMSys’17), Taipei, Taiwan,
Jun. 2017.

[5] M. Zink, K. Suh, Y. Gu, and J. Kurose, “Characteristics of youtube
network trafﬁc at a campus network - measurements, models, and
implications,” Comput. Netw., vol. 53, no. 4, pp. 501–514, Mar. 2009.
[6] G. Papaioannou and I. Koutsopoulos, “Tile-based caching optimization
for 360o videos,” in Proc. of the 20th ACM Int. Symp. on Mobile Ad
Hoc Networking and Computing, Mobihoc ’19, Catania, Italy, Jul. 2019,
pp. 171–180.

[7] P. Blasco and D. G¨und¨uz, “Multi-armed bandit optimization of cache
content in wireless infostation networks,” in Proc. of IEEE Int. Symp.
on Information Theory, Honolulu, HI, USA, Jun. 2014, pp. 51–55.
[8] S. M¨uller, O. Atan, M. van der Schaar, and A. Klein, “Context-
aware proactive content caching with service differentiation in wireless
networks,” IEEE Trans. on Wireless Communications, vol. 16, no. 2, pp.
1024–1036, Feb. 2017.

[9] C. J. C. H. Watkins and P. Dayan, “Q-learning,” Machine Learning,

vol. 8, pp. 279–292, May 1992.

[10] H. Li, T. Wei, A. Ren, Q. Zhu, and Y. Wang, “Deep reinforcement
learning: Framework, applications, and embedded implementations,”
vol. abs/1710.03792, 2017.
[Online]. Available: http://arxiv.org/abs/
1710.03792

[11] F. Duanmu, Y. Mao, S. Liu, S. Srinivasan, and Y. Wang, “A subjective
study of viewer navigation behaviors when watching 360-degree videos
on computers,” in Proc. of IEEE Int. Conf. on Multimedia and Expo
(ICME’18), San Diego, CA, USA, July 2018.

[12] C. Ge, N. Wang, W. K. Chai, and H. Hellwagner, “QoE-assured 4K
HTTP live streaming via transient segment holding at mobile edge,”
IEEE Journal on Selected Areas in Communications, vol. 36, no. 8, pp.
1816–1830, Aug. 2018.

[13] C. Li, L. Toni, J. Zou, H. Xiong, and P. Frossard, “QoE-driven mobile
edge caching placement for adaptive video streaming,” IEEE Trans. on
Multimedia, vol. 20, no. 4, pp. 965–984, Apr. 2018.

[14] D. Liu, B. Chen, C. Yang, and A. F. Molisch, “Caching at

the
wireless edge: design aspects, challenges, and future directions,” IEEE
Communications Magazine, vol. 54, no. 9, pp. 22–28, Sept. 2016.
[15] J. Poderys, M. Artuso, C. M. O. Lensbl, H. L. Christiansen, and J. Soler,
“Caching at the mobile edge: A practical implementation,” IEEE Access,
vol. 6, pp. 8630–8637, Feb. 2018.

[16] T. X. Vu, S. Chatzinotas, and B. Ottersten, “Edge-caching wireless
networks: Performance analysis and optimization,” IEEE Trans. on
Wireless Communications, vol. 17, no. 4, pp. 2827–2839, Apr. 2018.

[17] S. Zhang, N. Zhang, P. Yang, and X. Shen, “Cost-effective cache de-
ployment in mobile heterogeneous networks,” IEEE Trans. on Vehicular
Technology, vol. 66, no. 12, pp. 11 264–11 276, Dec. 2017.

[18] Z. Su, Q. Xu, F. Hou, Q. Yang, and Q. Qi, “Edge caching for layered
video contents in mobile social networks,” IEEE Trans. on Multimedia,
vol. 19, no. 10, pp. 2210–2221, Oct. 2017.

Fig. 12. Total amount of requests for each one of the available viewports.

Fig. 13. Total amount of requests for each one of the in high quality encoded
tiles.

by measuring the frequency of occurrence of a request wg in
a window of the previous Hl = 1000 sets of user requests.
The popularity of each viewport is depicted in Fig. 12 and
the popularity of each tile is depicted in Fig. 13. Although the
most popular viewport is the viewport 8 (see the viewports
illustrated in Fig. 4), by observing the Fig. 13, we can see
that the most popular tiles do not correspond to the tiles of
that viewport. The overlap between the diverse requests for the
various viewports is what determines the popularity of each
tile. Thus, by using virtual viewports, which consist of the
most popular tiles, the most popular tiles can be cached at the
SBS. This results in higher cache hit ratio and better quality
for the rendered viewports.

VIII. CONCLUSION
In this work, we studied the problem of delivering 360o
videos in mobile networks using edge caching for un-
known content popularity. We formulated the caching place-
ment/eviction problem as a Markov Decision Process that
aims at maximizing the overall quality of the videos delivered
to the users. To deal with the dimensionality problem, we
employ a DQN solution that exploits the patterns from the
observations in the sequence of users’ requests, in order to
learn for each state, which cache update action should be

12345678910Viewport index010203040Requests for Viewport13

[41] K. Poularakis, G. Iosiﬁdis, A. Argyriou, and L. Tassiulas, “Video
delivery over heterogeneous cellular networks: Optimizing cost and
performance,” in Proc. of IEEE Conf. on Computer Communications,
INFOCOM’14, Toronto, ON, Canada, Apr. 2014, pp. 1078–1086.

[19] C. Zhong, M. C. Gursoy, and S. Velipasalar, “A deep reinforcement
learning-based framework for content caching,” in Proc. of the 52nd
Annual Conf. on Information Sciences and Systems (CISS), Princeton,
NJ, USA, Mar. 2018.

[20] Y. Wei, Z. Zhang, F. R. Yu, and Z. Han, “Joint user scheduling
and content caching strategy for mobile edge networks using deep
reinforcement learning,” in Proc. of IEEE Int. Conf. on Communications
Workshops (ICC Workshops), Kansas City, MO, USA, May 2018.
[21] G. Dulac-Arnold, R. Evans, H. van Hasselt, P. Sunehag, T. Lillicrap,
J. Hunt, T. Mann, T. Weber, T. Degris, and B. Coppin, “Deep
reinforcement learning in large discrete action spaces,” 2015. [Online].
Available: http://arxiv.org/abs/1512.07679

[22] R. Skupin, Y. Sanchez, C. Hellge, and T. Schierl, “Tile based HEVC
video for head mounted displays,” in Proc. of IEEE Int. Symp. on
Multimedia (ISM’16), San Jose, CA, USA, Dec. 2016, pp. 399–400.

[23] M. Hosseini, “View-aware tile-based adaptations in 360 virtual reality
video streaming,” in Proc. of IEEE Virtual Reality (VR’17), Los Angeles,
CA, USA, Mar. 2017, pp. 423–424.

[24] J. Le Feuvre and C. Concolato, “Tiled-based adaptive streaming using
MPEG-DASH,” in Proc. of the 7th Int. Conf. on Multimedia Systems,
Klagenfurt, Austria, 2016, pp. 41–43.

[25] Y. Bao, H. Wu, A. A. Ramli, B. Wang, and X. Liu, “Viewing 360
degree videos: Motion prediction and bandwidth optimization,” in Proc.
of IEEE 24th Int. Conf. on Network Protocols (ICNP’16), Singapore,
Singapore, Nov. 2016.

[26] F. Duanmu, Y. Mao, S. Liu, S. Srinivasan, and Y. Wang, “A subjective
study of viewer navigation behaviors when watching 360-degree videos
on computers,” in Proc. of IEEE Int. Conf. on Multimedia and Expo
(ICME’18), San Diego, CA, USA, Jul. 2018.

[27] S. Rossi and L. Toni, “Navigation-aware adaptive streaming strategies
for omnidirectional video,” in Proc of. IEEE 19th Int. Workshop on
Multimedia Signal Processing (MMSP’17), Luton, UK, Oct. 2017.
[28] W. C. Lo, C. L. Fan, S. C. Yen, and C. H. Hsu, “Performance mea-
surements of 360o video streaming to head-mounted displays over live
4g cellular networks,” in Proc. of 19th Asia-Paciﬁc Network Operations
and Management Symp. (APNOMS’17), Seoul, South Korea, Sep. 2017,
pp. 205–210.

[29] F. Qian, B. Han, Q. Xiao, and V. Gopalakrishnan, “Flare: Practical
viewport-adaptive 360-degree video streaming for mobile devices,” in
Proc. of the 24th Annual Int. Conf. on Mobile Computing and Network-
ing, MobiCom ’18, New Delhi, India, 2018, pp. 99–114.

[30] L. Sun, F. Duanmu, Y. Liu, Y. Wang, Y. Ye, H. Shi, and D. Dai, “A two-
tier system for on-demand streaming of 360 degree video over dynamic
networks,” IEEE Journal on Emerging and Selected Topics in Circuits
and Systems, vol. 9, no. 1, pp. 43–57, March 2019.

[31] M. Xiao, C. Zhou, Y. Liu, and S. Chen, “Optile: Toward optimal tiling
in 360-degree video streaming,” in Proc. of the 25th ACM Int. Conf.
on Multimedia, MM ’17, Mountain View, California, USA, 2017, pp.
708–716.

[32] M. Assens, K. McGuinness, X. Gir´o,

and N. E. O’Connor,
“Saltinet: Scan-path prediction on 360 degree images using saliency
volumes,” CoRR, vol. abs/1707.03123, 2017.
[Online]. Available:
http://arxiv.org/abs/1707.03123

[33] A. D. Aladagli, E. Ekmekcioglu, D. Jarnikov, and A. Kondoz, “Predict-
ing head trajectories in 360 virtual reality videos,” in Proc. of Int. Conf.
on 3D Immersion (IC3D’17), Brussels, Belgium, Dec 2017.

[34] P. Sermpezis, T. Giannakas, T. Spyropoulos, and L. Vigneri, “Soft cache
hits: Improving performance through recommendation and delivery of
related content,” IEEE Journal on Selected Areas in Communications,
vol. 36, no. 6, pp. 1300–1313, June 2018.

[35] D. P. Bertsekas, Dynamic Programming and Optimal Control. Athena

Scientiﬁc, 1995.

[36] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction.

MIT Press, 1998.

[37] R. E. Bellman, Dynamic Programming. Dover Publications, 2003.
[38] N. C. Luong, D. T. Hoang, S. Gong, D. Niyato, P. Wang, Y. Liang,
and D. I. Kim, “Applications of deep reinforcement learning in com-
munications and networking: A survey,” IEEE Communications Surveys
Tutorials, vol. 21, no. 4, pp. 3133–3174, 2019.

[39] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den
Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam et al.,
“Mastering the game of Go with deep neural networks and tree search,”
Nature, vol. 529, no. 7587, pp. 484–489, Jan. 2016.

[40] L. Alexander, R. Johnson, and J. Weiss, “Exploring zipf’s law,” Teaching
Mathematics and Its Applications: Int. Journal of the IMA, vol. 17, no. 4,
pp. 155–158, Dec 1998.

