Auditory Feedback for Standing Balance Improvement in Virtual Reality

M. Rasel Mahmud*
Computer Science
The University of Texas at
San Antonio

Michael Stewart†
Kinesiology
The University of Texas at
San Antonio

Alberto Cordova‡
Kinesiology
The University of Texas at
San Antonio

John Quarles§
Computer Science
The University of Texas at
San Antonio

2
2
0
2

b
e
F
9

]

C
H
.
s
c
[

1
v
3
4
7
4
0
.
2
0
2
2
:
v
i
X
r
a

ABSTRACT

Virtual Reality (VR) users often experience postural instability, i.e.,
balance problems, which could be a major barrier to universal us-
ability and accessibility for all, especially for persons with balance
impairments. Prior research has conﬁrmed the imbalance effect,
but minimal research has been conducted to reduce this effect. We
recruited 42 participants (with balance impairments: 21, without
balance impairments: 21) to investigate the impact of several audi-
tory techniques on balance in VR, speciﬁcally spatial audio, static
rest frame audio, rhythmic audio, and audio mapped to the center of
pressure (CoP). Participants performed two types of tasks - standing
visual exploration and standing reach and grasp. Within-subject
results showed that each auditory technique improved balance in VR
for both persons with and without balance impairments. Spatial and
CoP audio improved balance signiﬁcantly more than other auditory
conditions. The techniques presented in this research could be used
in future virtual environments to improve standing balance and help
push VR closer to universal usability.

Keywords: Virtual Reality, balance, postural stability, auditory
feedback, VR accessibility, VR usability, Head-Mounted Display

Index Terms: Human-centered computing—Visualization—Visu-
alization techniques—Virtual Reality; Human Computer Interaction
(HCI)—Visualization design and evaluation methods—User studies

1 INTRODUCTION

Over one billion people (15%) around the world have disabilities [1].
Virtual reality (VR) is not accessible to many persons with disabil-
ities [2, 17, 18, 23, 51]. Unfortunately, these populations are rarely
consulted during VR research and development, which can result
in noninclusive and inaccessible experiences. For example, persons
with balance impairments (BI) may not be able to stand safely in
VR experiences. This limitation may prevent users from engaging
in parts of the VR experience. In addition to affecting persons with
BI, VR Head Mounted Displays (HMDs) also signiﬁcantly disrupt
the balance of users without BI [16, 35, 45]. However, minimal
research has been conducted to reduce this effect. If these imbal-
ance issues could be mitigated, both persons with and without BI
could more readily beneﬁt from consumer VR applications (e.g.,
education, physical ﬁtness, and entertainment).

In assistive technology research, there have been numerous feed-
back techniques of various modalities [19, 53] created to help im-
prove balance in reality. For example, researchers have used vi-
brotactile feedback to improve the balance of persons with low
vision [63]. Visual feedback also has been used to improve bal-
ance [7, 58, 61] . However, there has been minimal research into how
auditory feedback can affect balance in VR.

*e-mail: m.raselmahmud1@gmail.com
†e-mail: michael.stewart@utsa.edu
‡e-mail: Alberto.Cordova@utsa.edu
§e-mail: John.Quarles@utsa.edu

In this research, we conducted empirical studies in which partici-
pants (i.e., participants with and without BI) attempted to maintain
balance while standing in VEs with various approaches to auditory
feedback (i.e., spatial, static rest frame, rhythmic, and audio based
upon Center of Pressure (CoP)). The purpose of this work is to
make immersive VR more accessible for all persons. The results
are intended to give future VR developers an understanding of how
auditory feedback can be applied to improve the accessibility of VR.

2 BACKGROUND STUDY

2.1 Imbalance in VR

Previous literature has reported that there is an imbalance effect
caused by virtual environments (VEs). In the early 2000s, a ﬁnd-
ing reported that postural control mechanism was affected in VEs,
which could cause imbalance and motion sickness [59]. Participants
had less control on balance in the virtual environment than the real
environment [31]. HMDs also provided less stabilization of balance
in the virtual environment than the real environment [30]. As HMDs
block out visual feedback from the real world, participants wearing
HMDs may lose balance because of end-to-end latency and illusory
sensation of body movement caused by VEs [36, 55]. Longer immer-
sion in VR environments also caused postural instability [39]. Other
works have also investigated the imbalance effects on gait (walking
patterns) [56]. Thus, balance issues are a known problem for users
in HMD-based VR. However, there have been few previous efforts
to mitigate this problem. This inspired us to investigate solutions to
improve balance in VR.

Although most previous research was focused on users without
disabilities [16, 28, 35, 45], research from Ferdous et al. [18] was
one of the few that has investigated balance in VR for persons
with multiple sclerosis (MS). They studied how different visual
components (frame rate, ﬁeld of view, display resolution) affected
balance in VR for both persons with and without BI. They reported
that postural instability increases signiﬁcantly with the decrease of
frame rate and ﬁeld of view for the participants with BI, but no effect
of display resolution on balance was found. On the other hand, they
did not ﬁnd any effect of any visual components on balance for the
participants without BI. We have replicated their visual exploration
task in our current study.

VR has a long history of enabling effective rehabilitation ap-
proaches for improving balance and gait [4, 5, 10, 14, 15, 38, 41, 44].
However, most of this work has either not used HMDs or was con-
strained to seated tasks. Thus, the effects of immersive VR with
HMDs on standing balance have minimally been studied, which
motivated us to investigate the standing balance in VR environments
with HMDs for persons with disabilities.

2.2 Assistive Technology: Auditory Feedback for Bal-

ance Improvement in the Real World

Although they have received less attention than visual feedback
approaches [20], previous studies conducted in non-VR settings
reported that auditory cues could signiﬁcantly improve postural
control in the real world. For example, auditory feedback based
upon the lean of the user helped to correct posture for participants
without BI [9]. Spatial audio - audio that the user can localize in 3D
- was found to be effective in maintaining balance for participants

 
 
 
 
 
 
with BI [57]. Ross et al. reported auditory white noise - an auditory
static rest frame - decreased postural sway for participants who were
over the age of 65 [46]. Hasegawa et al. [26] reported auditory
feedback based on center of pressure (CoP) - the center pressure
point of the supporting surface, typically measured with multiple
pressure sensors on a balance board or force plate. The authors
increased the pitch of the sound when the CoP displacement was
in the backward direction and decreased the pitch of the sound
when the CoP displacement was in the forward direction, which
improved balance for participants without BI. Also, rhythmic audio -
hearing a steady beat - improved gait in individuals with neurological
problems (e.g., multiple sclerosis, Parkinson’s) and elderly persons
[22]. However, among the different auditory techniques, spatial
audio was more heavily used as it is intended to be more realistic and
natural [11, 42]. These previous studies motivated us to investigate
whether spatial, CoP, rhythmic, static rest frame audio could improve
balance signiﬁcantly for both participants with and without BI.

Very few prior studies investigated auditory techniques in a VR
environment for improving balance. For example, Gandemer et al.
investigated the postural sway of blindfolded people and reported
that spatial audio in an immersive virtual environment improved
postural stability [21]. Spatial audio was generally preferred to be
used in VR in most of the cases as it provided greater immersion
[40, 64]. However, auditory feedback-based balance improvement in
an immersive VR environment has been minimally explored, which
motivated us to investigate the effect of different auditory feedback
(spatial, static rest frame, rhythmic, and CoP) on balance in the VR
environment.

3 METHODS

3.1 Hypotheses

Our study investigated the effect of different auditory conditions
(spatial, static rest frame, rhythmic, and CoP) on balance in VR
environments. Based on the knowledge from the prior assistive
technology and VR balance literature, we investigated the following
hypotheses:

H1: Each VR-based auditory condition (spatial, static rest frame,
rhythmic, and CoP) will improve balance signiﬁcantly more than
the no audio in VR condition.

H2: Spatial auditory feedback may facilitate better balance than

other auditory feedback techniques.

H3: Postural stability will decrease in no audio in VR condition

compared to the baseline (non-VR) condition.

3.2 Participants, Selection Criteria, and Screening Pro-

cess

We recruited 42 participants (Male:11, Female:31) from the San An-
tonio area to investigate the effect of auditory feedback on balance in
VR. Twenty-one participants (Male:7, Female:14) aged 18-75 had BI
due to multiple sclerosis (MS) (18 participants), age (1 participant),
arthritis (1 participant), and vestibular dysfunction (1 participant).
The remaining twenty-one participants (Male:4, Female:17) were
without BI and had no MS, arthritis, vestibular dysfunction, or any
other physical issues, but they were of similar age, weight, and
height to that of the participants with BI. There were 52.4% White,
28.6% Hispanic, 23.8% African American in participants with BI.
For persons without BI, there were 19% White, 52.4% Hispanic,
28.6% African American, 9.5% American Indian, 9.5% Asian. The
mean (SD) age, height, weight, and gender details for both groups
(with and without BI) have been shown in Table 1. We had more
female participants than males in our study. This is because we
recruited from the population with MS, which is statistically more
common in females [1]. All participants were able to walk with-
out assistance. Participants were recruited from local MS support
groups, local rehabilitation hospitals, and church communities in the

Table 1: Descriptive statistics for participants

Participant
Group

BI
Without BI

Participants Age (years) Height (cm) Weight (kg)

Male Female Mean SD Mean SD Mean SD
46.5 13.0 164.84 12.62 82.79 22.18
43.2 12.6 164.33 12.7 85.25 17.96

14
17

7
4

local area. Verbal recruitment from the authors, email lists, websites,
and ﬂyers were the primary means for recruiting.

Screening Process: First, we interviewed every potential par-
ticipant by phone to verify if they were qualiﬁed for this study. For
example, we asked them some simple questions ﬁrst, including the
year and date (to loosely assess mental faculties) and demographic
information. We did not select any person who could not understand
the questions or did not have English language ﬂuency. Then we
asked them about the causes of their balance problems if known. We
also ensured that participants were demographically similar (i.e., age,
height, weight) across populations. We excluded the participants
from the study who were on medication to improve their balance or
could not stand without assistance.

3.3 System Description
We used the following equipment for our study.

Balance Measurement: BTrackS Balance Plate was used to
measure participants’ balance in each condition. The sampling
frequency of the balance plate was 25 HZ, which would yield a total
of 500 data points in a 20-second trial, for example.

Safety Equipment: A harness supported all participants to
prevent them from sudden falls. The harness was attached to a
partial weight-bearing suspension system. Both the harness and the
suspension system were from Kaye Products Inc.

Computers, VR Equipment, and Software: We designed the
VEs in Unity3D. The HTC Vive had a 2160 x 1200 pixel resolution
with a refresh rate of 90 Hz and a 110-degree ﬁeld of view. We
used integrated HMD headphones for hearing different audios for
our study. Vive controllers were used for the standing reach and
grasp task. We used a computer in this study to render the VE
and record the data. The system was equipped with Intel Core i7
Processor (4.20 GHz), 32 GB DDR3 RAM, NVIDIA GeForce RTX
2080 graphics card, and a Windows 10 operating system. We used
the NI LabView software (v. 2020) to gather data from the BTrackS
Balance Plate and streamed the data to Unity3D through sockets.

Environment: Our lab had sufﬁcient open space (> 600sq ft.)
in a temperature-controlled environment. Only the participant and
experimenters were allowed in the lab for the duration of the study.

3.4 Study Conditions
We investigated four types of VR-based auditory feedback tech-
niques and a condition with no audio to examine how auditory
feedback can affect balance in VR. We used white noise for auditory
feedback instead of music or user-selected audio tones because white
noise has been shown to change the signal-to-noise ratio and im-
prove performance due to the stochastic resonance phenomena [27].
Auditory white noise was also reported to be effective in reducing
postural sway in many previous non-VR studies [25, 47, 49, 66].

3.4.1 Spatial Audio
This was 3D audio played in headphones. Speciﬁcally, we played
spatialized white noise from Unity3D so that as the user turned their
head, the noise played at different volumes in each ear to simulate
the real stationary audio source. We used Google resonance audio
SDK in Unity for audio spatialization as the plugin uses head-related
transfer functions (HRTFs) and thus more realistically models 3D

Figure 1: The participants were supported by a harness while they
performed the standing visual exploration task (VR environment),
standing on balance board and wearing the HMD (left) and study
procedure (right).

sound than the unity default [11, 42]. The X, Y, and Z coordinates of
the 3D audio source in the VE relative to the participant’s head were
-2.45, -1.43, -1.76. We based this on the known facts that auditory
feedback plays a role in balance in the real world [21, 57].

3.4.2 Static Rest Frame Audio

This is white noise played in headphones. It had no relation to the
listener’s position. This technique was also reported in prior non-VR
studies to improve balance in elderly individuals [46].

3.4.3 Pitch and stereo pan feedback on Center of Pressure

(CoP)

We played white noise in headphones, similar to static rest frame
audio, but the pitch and stereo pan changed based on the center of
pressure path obtained from the balance board. In Unity3D, we
mapped the pitch to the center of pressure from x coordinate of
the balance plate and stereo pan to the center of pressure from y
coordinate of the balance plate [26].

3.4.4 Rhythmic Audio

We played a white noise beat at every 1-second interval. Previous
literature suggested that hearing a steady beat can improve balance
and gait in both individuals with neurological problems and in the
elderly in non-VR environments [22].

3.4.5 No Audio

We used this to measure participant’s balance in VR with no au-
ditory feedback. Participants still wore the headphones to make it
consistent with other conditions, but no audio was played.

3.5 Auditory Feedback Setup

We attached the audio to sound sources in Unity3D and modiﬁed
them based on our study conditions. For each auditory feedback
condition, we had a different Unity scene. When the user was
ready, we ran the corresponding scene at the beginning of each
condition to activate the auditory feedback. We played the scenes
in counterbalanced order for all participants to reduce the learning

Figure 2: Comparison between real environment (left) and virtual
environment (right) for standing visual exploration task.

effect. The audio was played through the integrated headphones
in the wireless HMD at the start of both tasks. Audio volume was
adjusted to the level that the participant felt was comfortable.

3.6 Study Procedure
The study was approved by Institutional Review Board (IRB). We
sterilized all pieces of equipment (e.g., HMD, controllers, balance
board, objects, harness, and suspension system) before each user
study. At the beginning of the study, the participants ﬁlled out a
COVID-19 screening questionnaire form, and their body temperature
was measured. Then the participant read and signed a consent form.
The participants answered handedness questions, which we used to
determine their dominant and non-dominant hands [13]. Then we
described the whole study procedure. Next, the participants were
attached to the harness and the suspension system. The participants
were supported by the harness, stood on balance board, and were
barefoot for the entire study session. Fig. 1 shows the participant
completing the standing visual exploration task (left) and study
procedure (right).

3.6.1 Pre-Session Questionnaires
At the beginning of the study, the participants ﬁlled out an Activities-
speciﬁc Balance Conﬁdence (ABC) [52], and a Simulator Sickness
Questionnaire (SSQ) [32].

3.6.2 Tasks
Participants performed a standing visual exploration task and a
standing reach and grasp task. Tasks were conducted in both a
VR environment and a non-VR environment. The VEs were the
replications of the real environments. We ensured that both tasks
were performed in a counterbalanced order to mitigate the possibility
of confounding variables such as the learning effect.

Standing Visual Exploration Task: A pre-recorded instruc-
tion was played at the beginning of each condition and trial which
directed participants to look at markers placed at different locations
throughout the room. The markers had directional labels, and the
instruction told them to look at a speciﬁc marker. The instruction
had two seconds of delay between one direction and another. The
total duration was three minutes. We placed different markers –
‘Left’, ‘Right’, ‘Top’, ‘Bottom’, ‘Front’ in respective directions in
the lab. We observed the participants’ head movements and images
rendered to ensure the participants were following the instructions.
This simple task only required participants to look at the markers
as directed. We wanted all the participants to observe the lab in
a controlled fashion to make it consistent for all participants. The
participants were standing straight on the balance board and not
allowed to move their bodies, except for their heads, while exploring

the VE. We collected real-time balance data from BTrackS Balance
Plate. Fig. 2 shows the real environment and corresponding VE. We
replicated the task presented in [18] to develop the standing visual
exploration task. We chose to perform this motor task in a laboratory
VE because we wanted to compare their balance in the VE lab to
their balance in the real lab.

Standing Reach and Grasp Task: Participants reached for
and grasped real objects within their reach. We placed four objects
(cube - 5.08 cm width) on the marked places on the table. The dis-
tance between every two objects was 24 cm. The balance board was
placed on the ground in alignment with the middle of the table. The
distance from the table to the balance board was 12 cm. Participants
were barefoot and positioned each foot on the marked places on
the balance board. Participants rested their non-dominant hands on
the upper thigh and used the dominant hand to reach and grasp the
objects. We allowed participants to reach the objects by leaning
forward to a maximum comfortable distance without lifting their
heels off the balance board and standing straight. We instructed
the participants to grasp the four objects in random order, lift the
objects to chest level, and put them back in the same place. We
followed [12] to implement this task. Fig. 3 shows the workspace
and a comparison between the real environment and VE for this
task. We chose this motor task, because reaching is a crucial part of
everyday activities, has been used for balance measurement, and is
common in VR [6, 29, 60].

3.6.3 Baseline Measurements without VR

The participants stood on a BTrackS Balance Plate while they were
supported by a harness to protect them from falling. Then we mea-
sured their balance for the standing visual exploration task and
standing reach and grasp task with three trials each. Each trial was
three minutes long.

3.6.4 VR Tasks

These are all replications of the above baseline tasks, except they
were performed in VR, and thus there were subtle differences. Par-
ticipants used the HTC Vive HMD to observe the VE for both virtual
tasks. We repeated the following tasks for four different auditory
conditions and a no audio VR condition with three trials for each ses-
sion while the auditory conditions and tasks were counterbalanced.

Standing Visual Exploration Task in VR: Participants fol-
lowed the same recorded instructions as the one used for real-world
balance measurement to explore the VE. We placed the virtual mark-
ers in the same location and the same size as the baseline measure-
ment. The measurements were the same as in the baseline standing
visual exploration task.

Standing Reach and Grasp Task in VR: Participants reached
for and grasped virtual objects within their reach with their dominant
hand using the controllers. When the participants touched the virtual
objects with the controller, the object’s color changed to red. Then
the participants pulled the controller trigger to grasp the objects,
brought them to chest level, and released the trigger when they
returned the object to the same place. The virtual environment and
measurements were the same as the baseline task.

Figure 3: Standing reach and grasp task: (A) Workspace (B) Real
environment (C) Virtual environment

4 METRICS
4.1 Center of Pressure (CoP) Velocity
Center of Pressure (CoP) [50] velocity is the primary metric of bal-
ance in our study. We chose to use CoP velocity because it is widely
used as a valid measurement to assess balance [34]. We calculated
CoP from the four pressure sensors of the BTrackS Balance Plate,
applying the following formula by Young et al. [65]:

CoP(X,Y ) =

∑4

i=1 Weighti ∗ (xi, yi)
i=1 Weighti

∑4

(1)

Where (xi, yi) = coordinates of the pressure sensor i, Weighti =
weight or pressure data on the ith sensor, and CoP(X,Y ) = coordi-
nates of the CoP.

Then, we computed the CoP path for all samples using the fol-

lowing formula.

CoP Path =

(cid:113)

(CoPi+1X −CoPiX)2 + (CoPi+1Y −CoPiY )2

n−1
∑
i=1

(2)
Here, CoPiX = X coordinate of CoP at ith second, and CoPiy = Y

coordinate of CoP at ith second.

Finally, we calculated CoP velocity by dividing the CoP path for

all samples by total data recording time for all samples (T).

CoP Velocity =

CoP Path
T

(3)

4.2 Activities-speciﬁc Balance Conﬁdence (ABC) Scale
ABC is a 16 item questionnaire where each item asks about partici-
pant’s conﬁdence in doing a speciﬁc daily life activity [43]. ABC
score is calculated by the sum of the percentages from each question
(1-16) for a maximum total of 1600. The sum is then divided by 16
to give the ABC%.

4.3 Simulator Sickness Questionnaire
Simulator Sickness Questionnaire (SSQ) is a 16 item questionnaire
where each item asks about participant’s physiological discomfort
[32]. This measure is needed to identify participants who are prone
to severe cybersickness and investigate the correlation with postural
instability.

3.7 Post-Session Questionnaires

Finally, the participants ﬁlled out an SSQ and demographic ques-
tionnaire at the end of the study.

The whole study took around two hours for the participants to
complete. Each participant received a payment of 30 US dollars per
hour and money for parking fees at the end of the study.

5 STATISTICAL ANALYSIS
We used the Shapiro-Wilk test for checking data normality. We found
the data was normally distributed for participants with and without
BI for both tasks; p = .321, w = 0.89. Then to ﬁnd any signiﬁcant
difference in CoP velocities, we performed a 2×6 mixed-model
ANOVA where we had two between-subject factors (participants

with BI and participants without BI) and six within-subject factors
(six study conditions: baseline, spatial, static, rhythmic, CoP, and no
audio). When there was a signiﬁcant difference, we conducted post-
hoc two-tailed t-tests for within and between-group comparisons.
For analyzing cybersickness, we also used two-tailed t-tests between
pre-session SSQ score and post-session SSQ score for both groups
of participants separately. We also performed two-tailed t-tests
between the ABC score of both groups of participants to evaluate
the difference in physical ability. We applied Bonferroni correction
for all tests that involved multiple comparisons.

6 RESULTS

We compared CoP velocities between study conditions and obtained
the following results.

6.1 Within Group Comparisons on CoP Velocity

After performing ANOVA tests, we found a signiﬁcant difference
for participants with BI, F(5,120) = 21.4, p < .001 for standing
visual exploration task and F(5,120) = 46.07, p < .001 for standing
reach and grasp task. We also obtained a signiﬁcant difference for
participants without BI, F(5,120) = 21.64, p < .001 for standing
visual exploration task and F(5,120) = 39.13, p < .001 for standing
reach and grasp task. Then we performed the following pair-wise
comparisons using two-tailed t-tests for both groups separately to
ﬁnd differences between particular study conditions.

6.1.1 Baseline vs. No Audio

Standing Visual Exploration Task: Experiment results did not
show any signiﬁcant difference between no audio (Mean, M = 4.67,
Standard Deviation, SD = 1.63) and baseline (M= 4.38, SD = 1.57)
condition; t(20) = 1.72, p = .101, r = 0.88 for participants with BI.
Similarly, we did not observe a signiﬁcant difference between no
audio (M = 4.08, SD = 1.33) and baseline (M= 3.89, SD = 1.49)
condition; t(20) = 1.11, p = .279, r = 0.86 for participants without
BI.

Standing Reach and Grasp Task: We did not obtain any
signiﬁcant difference between no audio (M = 6.44, SD = 1.48) and
baseline (M= 6.21, SD = 1.14) condition; t(20) = 1.14, p = .267, r
= 0.80 for participants with BI. We also did not ﬁnd a signiﬁcant
difference between no audio (M = 5.63, SD = 1.18) and baseline
(M= 5.27, SD = 0.97) condition; t(20) = 2.43, p = .024, r = 0.82 for
participants without BI. Although we expected a signiﬁcant increase
of CoP velocity in no audio in VR than the baseline condition, that
did not happen in this case.

6.1.2 No Audio vs. Spatial Audio

Standing Visual Exploration Task: For participants with BI,
CoP velocity was substantially lower in the spatial condition (M =
1.22, SD = 0.84 ) than no audio condition; t(20) = 12.17, p < .001,
r = 0.61. For participants without BI, we also observed in spatial
condition (M = 1.07, SD = 0.95) CoP velocity was signiﬁcantly
lower than no audio condition; t(20) = 10.02, p < .001, r = 0.30.

Standing Reach and Grasp Task: For participants with BI,
the obtained CoP velocity was signiﬁcantly less in spatial (M = 2.07,
SD = 0.92 ) than no audio condition; t(20) = 12.72, p < .001, r
= 0.22. For participants without BI, we also found CoP velocity
was signiﬁcantly less in spatial (M = 1.94, SD = 0.88) than no
audio condition; t(20) = 11.71, p < .001, r = 0.04. Thus, spatial
audio performed better than no audio in VR for both standing visual
exploration and standing reach and grasp tasks.

6.1.3 No Audio vs. CoP Audio

Standing Visual Exploration Task: CoP condition (M = 1.41,
SD = 1.15) improved balance (i.e., decreased CoP velocity) signif-
icantly than no audio condition; t(20) = 10.85, p < .001, r = 0.56

Figure 4: CoP velocity comparison between study conditions for
standing visual exploration task.

for participants with BI. We also observed CoP velocity was signif-
icantly lower in CoP audio (M = 1.23, SD = 0.97 ) than no audio
condition; t(20) = 10.38, p < .001, r = 0.44 for participants without
BI.

Standing Reach and Grasp Task: The obtained CoP velocity
was considerably less in CoP (M = 2.27, SD = 1.16) than no audio
condition; t(20) = 9.58, p < .001, r = -0.12 for participants with
BI. We also found CoP velocity was signiﬁcantly less in CoP audio
(M = 2.15, SD = 0.93 ) than no audio condition; t(20) = 10.42, p <
.001, r = -0.04 for participants without BI. Therefore, the CoP audio
condition outperformed no audio in VR condition for both tasks.

6.1.4 No Audio vs. Static Audio

Standing Visual Exploration Task: For participants with BI,
experimental results disclosed that CoP velocity was signiﬁcantly
less in static (M = 2.70, SD = 1.40 ) than no audio condition; t(20)
= 8.19, p < .001, r = 0.75. For participants without BI, we also
observed CoP velocity was signiﬁcantly less in static audio (M =
2.49, SD = 1.36 ) than no audio condition; t(20) = 7.30, p < .001, r
= 0.73.

Standing Reach and Grasp Task: The obtained CoP velocity
was signiﬁcantly less in static (M = 4.24, SD = 1.22) than no audio
condition; t(20) = 6.36, p < .001, r = 0.33 for participants with
BI. We also discovered that CoP velocity was substantially lower in
static audio (M = 3.46, SD = 1.29) than no audio condition; t(20) =

6.52, p < .001, r = 0.24 for participants without BI. Hence, static rest
frame audio also performed better than the no audio in VR condition
for both tasks.

6.1.5 No Audio vs. Rhythmic Audio

Standing Visual Exploration Task: Experiment results re-
vealed that CoP velocity was signiﬁcantly less in rhythmic (M =
3.01, SD = 1.77) than no audio condition for participants with BI;
t(20) = 10.77, p < .001, r = 0.92. We also noticed that CoP velocity
was signiﬁcantly decreased in rhythmic audio (M = 2.30, SD = 1.33)
than no audio condition for participants without BI; t(20) = 6.99, p
< .001, r = 0.62.

Standing Reach and Grasp Task: The obtained CoP velocity
was signiﬁcantly reduced in rhythmic (M = 4.10, SD = 1.51) than
no audio condition for participants with BI; t(20) = 6.80, p < .001,
r = 0.45. We also found CoP velocity was signiﬁcantly diminished
in rhythmic audio (M = 3.33, SD = 1.41 ) than no audio condition
for participants without BI; t(20) = 6.27, p < .001, r = 0.17. Thus, it
can be claimed that rhythmic audio outperformed no audio in VR
condition.

6.1.6 Rhythmic Audio vs. Spatial Audio

Standing Visual Exploration Task: We found that CoP veloc-
ity signiﬁcantly decreased in spatial than rhythmic audio condition
for both participants with BI (t(20) = 5.38, p < .001, r = 0.52) and
for participants without BI (t(20) = 4.09, p < .001, r = 0.31).

Standing Reach and Grasp Task: From mixed ANOVA and
post-hoc two-tailed t-test we noticed that CoP velocity was signiﬁ-
cantly less in spatial than rhythmic audio condition for participants
with BI (t(20) = 6.41, p < .001, r = 0.37) and for participants without
BI (t(20) = 5.53, p < .001, r = 0.58). These results indicated that
spatial audio could be preferred over rhythmic audio for balance
improvement.

6.1.7 Rhythmic Audio vs. CoP Audio

Standing Visual Exploration Task: Experiment results sub-
stantiated that CoP velocity was signiﬁcantly less in CoP audio than
rhythmic audio condition for participants with BI (t(20) = 4.68, p
< .001, r = 0.49) and for participants without BI (t(20) = 5.12, p <
.001, r = 0.70).

Standing Reach and Grasp Task: The obtained CoP velocity
was signiﬁcantly lower in CoP than rhythmic audio condition for
participants with BI (t(20) = 4.73, p < .001, r = 0.14) and for
participants without BI (t(20) = 5.15, p < .001, r = 0.67). The
outcomes supported that CoP audio might be better than rhythmic
audio for improving balance in VR.

6.1.8 Rhythmic Audio vs. Static Audio

Standing Visual Exploration Task: Experiment results re-
vealed that there is no signiﬁcant difference between rhythmic audio
and static audio condition for participants with BI (t(20) = 1.24, p
= .229, r = 0.77) and for participants without BI (t(20) = 0.99, p =
.333, r = 0.78).

Standing Reach and Grasp Task: We also did not obtain
a signiﬁcant difference between rhythmic audio and static audio
condition for participants with BI (t(20) = 0.64, p = .532, r = 0.77)
and for participants without BI (t(20) = 0.97, p = .344, r = 0.90).
Thus, the results did not clearly indicate which audio could be chosen
between rhythmic and static rest frame for balance improvement.

Figure 5: CoP velocity comparison between study conditions for
standing reach and grasp task.

6.1.9 Static Audio vs. Spatial Audio

Standing Visual Exploration Task: Experiment results sub-
stantiated that CoP velocity was signiﬁcantly lower in spatial audio
than static audio condition for participants with BI (t(20) = 6.04, p
< .001, r = 0.60) and for participants without BI (t(20) = 5.69, p <
.001, r = 0.56).

Standing Reach and Grasp Task: The obtained CoP veloc-
ity was signiﬁcantly less in spatial than static audio condition for
participants with BI (t(20) = 8.31, p < .001, r = 0.41). The same
result was found for participants without BI (t(20) = 6.48, p < .001,
r = 0.56). As a result, spatial audio could be favored over static rest
frame for balance improvement in VR.

6.1.10 Static Audio vs. CoP Audio

Standing Visual Exploration Task: We discovered that CoP
velocity was signiﬁcantly less in CoP audio than static audio condi-
tion; t(20) = 5.38, p < .001, r = 0.64 for participants with BI and for
participants without BI (t(20) = 6.87, p < .001, r = 0.79).

Standing Reach and Grasp Task: CoP velocity was signif-
icantly less in CoP than static audio condition; t(20) = 6.04, p <
.001, r = 0.22 for participants with BI and for participants without
BI (t(20) = 5.49, p < .001, r = 0.56). Results displayed that CoP
audio performed signiﬁcantly better than static rest frame audio for
both tasks.

6.1.11 CoP Audio vs. Spatial Audio

Standing Visual Exploration Task: Experiment results did not
show a signiﬁcant difference between spatial audio and CoP audio
condition for both participants with BI (t(20) = 1.16, p = .13, r =
0.77) and participants without BI (t(20) = 0.68, p = .253, r = 0.30).

Table 2: Summarized results for pairwise comparisons

Comparisons

Standing Visual
Exploration
BI Without BI

Standing Reach
and Grasp

BI Without BI

p <.001 p <.001 p <.001 p <.001
Spatial vs. Static
p <.001 p <.001 p <.001 p <.001
Spatial vs. Rhythmic
p <.001 p <.001 p <.001 p <.001
Spatial vs. CoP
p <.001 p <.001 p <.001 p <.001
Spatial vs. No audio
p >.05
p >.05
Static vs. Rhythmic
p <.001 p <.001 p <.001 p <.001
Static vs. CoP
p <.001 p <.001 p <.001 p <.001
Static vs. No audio
p <.001 p <.001 p <.001 p <.001
Rhythmic vs. CoP
Rhythmic vs. No audio p <.001 p <.001 p <.001 p <.001
p <.001 p <.001 p <.001 p <.001
CoP vs. No audio
p >.05
p >.05
Baseline vs. No audio

p >.05

p >.05

p >.05

p >.05

Standing Reach and Grasp Task: We discovered similar re-
sults in this case as the standing visual exploration. We did not
obtain a signiﬁcant difference between spatial and CoP audio condi-
tion for participants with BI (t(20) = 0.72, p = .238, r = 0.31) and for
participants without BI (t(20) = 0.97, p = .172, r = 0.39). Therefore,
the results did not indicate which audio can be preferred between
spatial and CoP for improving balance in VR environments.

Fig. 4 and Fig. 5 represents the experimental results for standing
visual exploration task and standing reach and grasp task, respec-
tively. Table 2 represents the summarized results.

6.2 Between Group Comparisons

Results from mixed-model ANOVA and post-hoc two-tailed t-tests
indicated that there was a signiﬁcant difference in CoP velocities for
baseline conditions between the two groups (participants with and
without BI); t(20) = 8.31, p < .001, r = 0.41. However, we did not
observe any signiﬁcant difference between other study conditions.

6.3 Activities-speciﬁc Balance Conﬁdence (ABC) Scale

We administered the Activities Speciﬁc Balance Scale (ABC-16)
for both participants with and without BI, which can be interpreted
as follows: 80% = high level of physical functioning; 50-80% =
moderate level of physical functioning; < 50% = low level of physi-
cal functioning. We performed a two-tailed t-test between the ABC
score of the participants with BI (M = 70.83, SD = 24.83) and those
without BI (M = 91.76, SD = 13.71), t(20) = 3.38, p < .001. The
mean ABC score of the participants with BI was 70.83%, indicating
the participants with BI had a moderate level of physical functioning.
On the other hand, the mean ABC score of the participants without
BI was 91.76%, conﬁrming their high level of physical functioning.

6.4 Simulator Sickness Questionnaire

We performed a two-tailed t-test between pre-session SSQ score
and post-session SSQ score for both groups of participants with BI
and those without BI. We did not ﬁnd any signiﬁcant difference
between the pre-session SSQ score and post-session SSQ score for
both groups of participants. We obtained t(20) = 1.72, p = .08, r =
0.6 for participants with BI and t(20) = 1.72, p = .06, r = 0.77 for
participants without BI.

7 DISCUSSION

7.1 Effect of Auditory Conditions on Balance in VR

Balance improves with the decrease of CoP velocity [48, 62]. We
observed the following differences in balance from our experimental
results.

7.1.1 No Audio in VR vs. All Auditory Conditions in VR

Experimental results showed that the CoP velocity was signiﬁcantly
lower in all audio conditions compared to the no audio in VR condi-
tion for both participants with and without BI for both tasks (standing
visual exploration and standing reach and grasp). Thus, we can say
that spatial, CoP, rhythmic, and static rest frame audio improved bal-
ance signiﬁcantly for both the participants with and without BI. As a
result, hypothesis 1 cannot be rejected. These results supported prior
studies where they reported auditory white noise [25, 47, 49, 66], spa-
tial [21,57], CoP [26], static rest frame [46], and rhythmic audio [22]
improved balance in the real-world environments.

However, the results indicated a difference compared to prior
work [18] where they investigated the effect of visual feedback on
balance using the standing visual exploration task for both partic-
ipants with and without BI in VR. They reported that the visual
feedback improved balance for the people with BI, but they did not
ﬁnd any signiﬁcant effects of any visual conditions on balance for the
people without BI. However, our experimental results suggested that
the auditory feedback improved balance for both participants with
and without BI. We hypothesized from the results that the speciﬁc
auditory feedback approaches evaluated might perform better than
the visual feedback. Similar results were found in prior studies [3]
where auditory feedback was more effective than visual feedback
during walking in VR.

7.1.2 Comparison Between All Auditory Conditions in VR

The experimental results demonstrated differences between the audio
conditions. Results suggested that spatial and CoP audio conditions
perform signiﬁcantly better than the rhythmic and static rest frame
audio conditions in both tasks of standing visual exploration and
standing reach and grasp for both the participants with and without
BI. However, there was no signiﬁcant difference statistically between
groups in the spatial and CoP audio conditions. The reason behind
this could be that both the tasks analyzed were stationary tasks using
a simple VE. Otherwise, spatial audio would have a greater impact on
an individual in motion as spatial audio provides greater immersion
and stabilization in an immersive VR environment [40, 64]. Thus,
hypothesis 2 was only partially supported.

Furthermore, static rest frame audio performed somewhat better
than rhythmic audio except in standing visual exploration tasks
for participants without BI, where rhythmic audio outperformed
static rest frame audio slightly. We hypothesized that this happened
because the participants with BI were more focused on keeping
their balance during the visual exploration task than maintaining
synchronicity with the rhythmic audio beat. From the post-session
comments of the participants, we observed that participants without
BI were often able to effectively follow the command pattern of pre-
recorded instruction (e.g., left, right, top, bottom, front) for standing
visual exploration task which might have given them an advantage
in contrast with balance-impaired individuals who might have had
a little more fatigue as we noticed that they rested longer than the
participants without BI in-between conditions. However, we did
not obtain a signiﬁcant difference between groups for rhythmic and
static rest frame audio conditions.

In our study, we discovered spatial audio outperformed all other
auditory conditions. Prior work also found that spatial auditory
feedback was the most preferred over other types as it provided
greater ﬁdelity [11, 42] and immersion [40, 64]. However, minimal
prior work quantitatively compares spatial audio to other audio
techniques with respect to the effects on balance in VR.

7.2 Signiﬁcant Effect of Auditory Changes with Position

The auditory conditions improved balance in VR but to a differing
amounts. The results demonstrated that spatial and CoP audio im-
proved balance signiﬁcantly more than other auditory conditions.
Spatial and CoP audio were related to participant’s position, i.e.,

when the participants leaned slightly in any direction while standing
on the balance board or moved their heads, there was a change in
audio volumes. As these two auditory conditions performed signiﬁ-
cantly better than other auditory conditions, we hypothesized that the
audio volume that changes with participant’s positioning provides
signiﬁcantly better feedback to the participants to correct their pos-
ture. However, spatial audio may be subjectively preferred over CoP
audio as spatial audio provides greater immersion in VR [40, 64].

7.3 Between Group Comparisons

The ABC scores indicated that participants with BI had potentially
lower physical functionality than participants without BI. Thus, it
was reasonable to have the difference in CoP velocities between
baseline conditions for the two groups. However, there was no
signiﬁcant difference between other conditions in VR. For further
investigation, we subtracted baseline data from all situations to see
which group improved balance the most. Then, we performed a
mixed ANOVA and post-hoc two-tailed t-tests across two groups
which demonstrated that the participants with BI improved balance
signiﬁcantly more than those without BI. We anticipated that because
the participants with BI had reduced balance functioning, they might
have a better chance of improving balance in VR than those without
BI. This result was also substantiated by the prior work where they
found that participants with BI improved balance and gait signiﬁ-
cantly more than the participants without BI [24]. We hypothesized
that as the participants with BI improved balance signiﬁcantly more
than the participants without BI in VR, we did not get any signiﬁcant
difference between the two groups in VR even though there was a
signiﬁcant difference between baseline conditions.

7.4 Effect of Virtual Environment

We evaluated no audio condition in VR and the baseline condition
without VR. We found the CoP velocity was slightly higher, albeit
not signiﬁcantly, in the no audio in VR condition compared to the
baseline condition for both standing visual exploration and standing
reach and grasp tasks for both groups of participants. Although
signiﬁcant differences were not found, prior research suggested that
postural instability generally increases in VR [16, 54], leading to
increased CoP velocity in VR than in a baseline condition. We
suspected that if we recruited more participants, we would see sig-
niﬁcant differences in the no audio in VR and baseline conditions.

7.5 Cybersickness

We did not ﬁnd a signiﬁcant difference between the pre-session
SSQ score and the post-session SSQ score for both participants
with and without BI, which indicated that participants were not
affected by cybersickness. Participants might have developed mild
cybersickness as our study had two different tasks, each task had
six different conditions, and each condition had three trials which
made the study take almost two hours to complete. Cybersickness is
common when engaged in VR activities for over 10 minutes [8, 33].
However, our environment was simple and designed to minimize
cybersickness as there was no illusory self-motion [37]. Therefore,
we assumed that cybersickness did not affect CoP velocity results.

tasks and the auditory conditions in VR to mitigate the learning
effects.

For designing our CoP audio condition, we streamed the CoPx
and CoPy data from the balance board to Unity through sockets and
mapped the CoPx to pitch and CoPy to stereo pan for providing
participants CoP audio feedback according to their positioning on
the balance board. However, it is unclear how our results for this
condition would be affected at lower levels of latency. While we did
not measure end-to-end latency, the additional network latency in
this condition was negligible.

We did not adjust the table height based on the participant’s height
for the standing reach and grasp task, which could have affected
results. However, there were no signiﬁcant differences in the heights
of the participants (Table 1) and thus, we expected it had a minimal
effect.

Participants used harnesses for the whole study to protect them-
selves from falling, which might have improved their balance slightly.
However, to make the study procedure consistent and safe, we re-
quired all participants to use the harnesses regardless of whether they
had balance impairments or not. Thus, studies looking at balance
not using a harness may have different results.

The study duration was quite long and required participants to
hear the white noise standing in one place. This often caused fatigue,
and individuals had to rest for a few minutes, taking the HMD
off between different trials. This might have allowed participants
to regain spatial awareness and regain balance which might have
skewed data.

We calculated mean CoP velocity, which is a very popular metric
for balance measurement [34]. However, we did not measure full-
body movement.

Due to COVID-19 and our targeted test population, primarily
persons with BI due to MS, the recruitment process was difﬁcult as
many potential participants had compromised immune systems mak-
ing them at high risk for COVID-19. Thus, they did not participate
in the study. If the study had been done outside of COVID-19, we
would have been able to recruit more participants. In that case, we
might have found a signiﬁcant difference between no audio in VR
and the baseline for within group comparisons. We also might have
found more signiﬁcant differences among different study conditions
in VR for between group comparisons. More research is needed to
conﬁrm this.

8 DESIGN IMPLICATIONS

Spatial and CoP auditory feedback performed signiﬁcantly better
than rhythmic and static rest frame audio conditions. Thus, spatial
and CoP audio can be used in future VR environments to improve
balance for VR users, especially for participants with balance impair-
ments. However, spatial audio might be favored over CoP audio, as
spatial audio renders greater immersion [40, 64] and ﬁdelity [11, 42]
in VR. Hypothetically, audio techniques may interfere with presence
less than visual techniques, for example, because most VEs are pre-
dominantly visual experiences. In the future, we plan to investigate
how different modalities of feedback, e.g., visual, auditory, tactile,
affect balance in VR. Also, end-to-end latency might need to be
considered, which we did not measure in our study.

7.6 Limitations

9 CONCLUSION

Participants were informed about the whole study procedure at the
beginning of the study. Then we had a few trials with them until
they were comfortable with the experimental procedure. We also
had three baseline trials for each of the two tasks before starting the
auditory conditions in VR. Each baseline trial duration was three
minutes. However, the baseline could be extended for more trials.
We did not do that as the study took almost two hours to complete and
included participants with balance impairments who had potentially
lower physical functionality. However, we counterbalanced both

In this paper, we evaluated the effect of different auditory feedback
techniques on balance in VR. All auditory conditions (spatial, CoP,
rhythmic, and static rest frame) improved balance signiﬁcantly in our
study. Spatial and CoP audio signiﬁcantly outperformed rhythmic
and static rest frame audio. However, there was no signiﬁcant differ-
ence between spatial and CoP audio or between rhythmic and static
rest frame audio. The results will help researchers better understand
the different kinds of auditory feedback for maintaining balance in
an HMD-based VE. Moreover, this research can help developers

create VR experiences that are more usable and accessible to per-
sons with and without balance impairments. In our future work, we
will include locomotion tasks and investigate the effectiveness of
auditory feedback for gait improvement.

ACKNOWLEDGMENTS

This work was funded through a grant from the National Science
Foundation (IIS 2007041). We would also like to thank Dr. Sharif
Mohammad Shahnewaz Ferdous for his directions towards develop-
ing the standing visual exploration scene.

REFERENCES

[1] [n. d.] people with disabilities

https:
//www.un.org/development/desa/disabilities/resources/
factsheet-on-persons-with-disabilities.html. Accessed:
2021-08-30.

in the world.

[2] Y. Agrawal, J. P. Carey, C. C. Della Santina, M. C. Schubert, and L. B.
Minor. Disorders of balance and vestibular function in us adults: data
from the national health and nutrition examination survey, 2001-2004.
Archives of internal medicine, 169(10):938–944, 2009.

[3] Y. Baram and R. Lenger. Gait improvement in patients with cerebral
palsy by visual and auditory feedback. Neuromodulation: Technology
at the Neural Interface, 15(1):48–52, 2012.

[4] M. Bergeron, C. L. Lortie, and M. J. Guitton. Use of virtual reality
tools for vestibular disorders rehabilitation: a comprehensive analysis.
Advances in medicine, 2015, 2015.

[5] E. Bisson, B. Contant, H. Sveistrup, and Y. Lajoie. Functional bal-
ance and dual-task reaction times in older adults are improved by
virtual reality and biofeedback training. Cyberpsychology & behavior,
10(1):16–23, 2007.

[6] D. A. Bolton, D. M. Cole, B. Butler, M. Mansour, G. Rydalch, D. W.
McDannald, and S. E. Schwartz. Motor preparation for compensatory
reach-to-grasp responses when viewing a wall-mounted safety handle.
cortex, 117:135–146, 2019.

[7] O. ˇCakrt, M. Chovanec, T. Funda, P. Kalitov´a, J. Betka, E. Zvˇeˇrina,
P. Kol´aˇr, and J. Jeˇr´abek. Exercise with visual feedback improves postu-
ral stability after vestibular schwannoma surgery. European archives
of oto-rhino-laryngology, 267(9):1355–1360, 2010.

[8] E. Chang, H. T. Kim, and B. Yoo. Virtual reality sickness: a review of
causes and measurements. International Journal of Human–Computer
Interaction, 36(17):1658–1682, 2020.

[9] L. Chiari, M. Dozza, A. Cappello, F. B. Horak, V. Macellari, and
D. Giansanti. Audio-biofeedback for balance improvement: an
accelerometry-based system. IEEE transactions on biomedical en-
gineering, 52(12):2108–2111, 2005.

[10] C. Cho, W. Hwang, S. Hwang, and Y. Chung. Treadmill training with
virtual reality improves gait, balance, and muscle strength in children
with cerebral palsy. The Tohoku journal of experimental medicine,
238(3):213–218, 2016.

[11] U. Chong and S. Alimardanov. Audio augmented reality using unity
for marine tourism. In International Conference on Intelligent Human
Computer Interaction, pp. 303–311. Springer, 2020.

[12] A. Cordova and C. Gabbard. Do older adults perceive postural con-
straints for reach estimation? Experimental aging research, 40(5):578–
588, 2014.

[13] S. Coren. The lateral preference inventory for measurement of hand-
edness, footedness, eyedness, and earedness: Norms for young adults.
Bulletin of the Psychonomic Society, 31(1):1–3, 1993.

[14] I. J. De Rooij, I. G. Van De Port, and J.-W. G. Meijer. Effect of virtual
reality training on balance and gait ability in patients with stroke:
systematic review and meta-analysis. Physical therapy, 96(12):1905–
1918, 2016.

[15] G. Duque, D. Boersma, G. Loza-Diaz, S. Hassan, H. Suarez,
D. Geisinger, P. Suriyaarachchi, A. Sharma, and O. Demontiero. Ef-
fects of balance training using a virtual-reality system in older fallers.
Clinical interventions in aging, 8:257, 2013.

[16] P. Epure, C. Gheorghe, T. Nissen, L.-O. Toader, A. Nicolae, S. S.
Nielsen, D. J. R. Christensen, A. L. Brooks, and E. Petersson. Effect of
the oculus rift head mounted display on postural stability. In The 10th

International Conference on Disability Virtual Reality & Associated
Technologies: Proceedings, pp. 119–127. Reading University Press,
2014.

[17] S. M. S. Ferdous, I. M. Arafat, and J. Quarles. Visual feedback to
improve the accessibility of head-mounted displays for persons with
balance impairments. In 2016 IEEE Symposium on 3D User Interfaces
(3DUI), pp. 121–128. IEEE, 2016.

[18] S. M. S. Ferdous, T. I. Chowdhury, I. M. Arafat, and J. Quarles. Inves-
tigating the reason for increased postural instability in virtual reality
for persons with balance impairments. In Proceedings of the 24th ACM
Symposium on Virtual Reality Software and Technology, pp. 1–7, 2018.
[19] C. Franco, A. Fleury, P.-Y. Gum´ery, B. Diot, J. Demongeot, and
N. Vuillerme. ibalance-abf: a smartphone-based audio-biofeedback bal-
ance system. IEEE transactions on biomedical engineering, 60(1):211–
215, 2012.

[20] L. Gandemer, G. Parseihian, C. Bourdin, and R. Kronland-Martinet.
Sound and posture: an overview of recent ﬁndings. In Computer Music
and Multidisciplinary Reasearch (CMMR) 2016, 2016.

[21] L. Gandemer, G. Parseihian, R. Kronland-Martinet, and C. Bourdin.
Spatial cues provided by sound improve postural stabilization: evidence
of a spatial auditory map? Frontiers in neuroscience, 11:357, 2017.

[22] S. Ghai, I. Ghai, and A. O. Effenberg. Effect of rhythmic auditory
cueing on aging gait: a systematic review and meta-analysis. Aging
and disease, 9(5):901, 2018.

[23] R. Guo, G. Samaraweera, and J. Quarles. The effects of ves on mo-
bility impaired users: Presence, gait, and physiological response. In
Proceedings of the 19th ACM Symposium on Virtual Reality Software
and Technology, pp. 59–68, 2013.

[24] R. Guo, G. Samaraweera, and J. Quarles. Mobility impaired users re-
spond differently than healthy users in virtual environments. Computer
Animation and Virtual Worlds, 26(5):509–526, 2015.

[25] J. D. Harry, J. B. Niemi, A. A. Priplata, and J. Collins. Balancing
act [noise based sensory enhancement technology]. IEEE Spectrum,
42(4):36–41, 2005.

[26] N. Hasegawa, K. Takeda, M. Sakuma, H. Mani, H. Maejima, and
T. Asaka. Learning effects of dynamic postural control by audi-
tory biofeedback versus visual biofeedback training. Gait & posture,
58:188–193, 2017.

[27] S. K. Helps, S. Bamford, E. J. Sonuga-Barke, and G. B. S¨oderlund.
Different effects of adding white noise on cognitive performance of sub-
, normal and super-attentive school children. PloS one, 9(11):e112768,
2014.

[28] C. G. Horlings, M. G. Carpenter, U. M. K¨ung, F. Honegger, B. Wieder-
hold, and J. H. Allum. Inﬂuence of virtual reality on postural stability
during movements of quiet stance. Neuroscience letters, 451(3):227–
231, 2009.

[29] M. H. Huang and S. H. Brown. Effects of task context during standing
reach on postural control in young and older adults: A pilot study. Gait
& posture, 41(1):276–281, 2015.

[30] J. W. Kelly, B. C. Klesel, and L. A. Cherep. Visual stabilization of
balance in virtual reality using the htc vive. ACM Transactions on
Applied Perception (TAP), 16(2):1–11, 2019.

[31] J. W. Kelly, B. Riecke, J. M. Loomis, and A. C. Beall. Visual control of
posture in real and virtual environments. Perception & psychophysics,
70(1):158–165, 2008.

[32] R. S. Kennedy, N. E. Lane, K. S. Berbaum, and M. G. Lilienthal.
Simulator sickness questionnaire: An enhanced method for quantifying
simulator sickness. The international journal of aviation psychology,
3(3):203–220, 1993.

[33] H. Kim, D. J. Kim, W. H. Chung, K.-A. Park, J. D. Kim, D. Kim,
K. Kim, and H. J. Jeon. Clinical predictors of cybersickness in virtual
reality (vr) among highly stressed people. Scientiﬁc reports, 11(1):1–
11, 2021.

[34] Z. Li, Y.-Y. Liang, L. Wang, J. Sheng, and S.-J. Ma. Reliability and
validity of center of pressure measures for balance assessment in older
adults. Journal of physical therapy science, 28(4):1364–1367, 2016.
[35] A. Lott, E. Bisson, Y. Lajoie, J. McComas, and H. Sveistrup. The
effect of two types of virtual reality on voluntary center of pressure
displacement. Cyberpsychology & behavior, 6(5):477–485, 2003.
[36] A. Martinez, A. I. Paganelli, and A. Raposo. Analysing balance loss in

[57] M. N. Stevens, D. L. Barbour, M. P. Gronski, and T. E. Hullar. Auditory
contributions to maintaining balance. Journal of Vestibular Research,
26(5-6):433–438, 2016.

[58] S. S¨utbeyaz, G. Yavuzer, N. Sezer, and B. F. Koseoglu. Mirror therapy
enhances lower-extremity motor recovery and motor functioning after
stroke: a randomized controlled trial. Archives of physical medicine
and rehabilitation, 88(5):555–559, 2007.

[59] Y. Takahashi and A. Murata. Change of equilibrium under the inﬂuence
of vr experience. In Proceedings 10th IEEE International Workshop
on Robot and Human Interactive Communication. ROMAN 2001 (Cat.
No. 01TH8591), pp. 642–647. IEEE, 2001.

[60] C. Tan, J. Tretriluxana, E. Pitsch, N. Runnarong, and C. J. Winstein.
Anticipatory planning of functional reach-to-grasp: a pilot study. Neu-
rorehabilitation and neural repair, 26(8):957–967, 2012.

[61] H. Thikey, F. van Wjick, M. Grealy, and P. Rowe. A need for meaning-
ful visual feedback of lower extremity function after stroke. In 2011
5th International Conference on Pervasive Computing Technologies
for Healthcare (PervasiveHealth) and Workshops, pp. 379–383. IEEE,
2011.

[62] L. A. Thompson, M. Badache, S. Cale, L. Behera, and N. Zhang.
Balance performance as observed by center-of-pressure parameter
characteristics in male soccer athletes and non-athletes. Sports, 5(4):86,
2017.

[63] R. Vel´azquez. Wearable assistive devices for the blind. In Wearable and
autonomous biomedical devices and systems for smart environment,
pp. 331–349. Springer, 2010.

[64] E. M. Wenzel, D. R. Begault, and M. Godfroy-Cooper. Perception of
spatial sound. In Immersive sound, pp. 5–39. Routledge, 2017.
[65] W. Young, S. Ferguson, S. Brault, and C. Craig. Assessing and training
standing balance in older adults: a novel approach using the ‘nintendo
wii’balance board. Gait & posture, 33(2):303–305, 2011.

[66] Z. Zhou, C. Wu, Z. Hu, Y. Chai, K. Chen, and T. Asakawa. Effects
of white gaussian noise on dynamic balance in healthy young adults.
Scientiﬁc reports, 11(1):1–10, 2021.

vr interaction with hmds. Journal on Interactive Systems, 9(2), 2018.
[37] M. E. McCauley and T. J. Sharkey. Cybersickness: Perception of
self-motion in virtual environments. Presence: Teleoperators & Virtual
Environments, 1(3):311–318, 1992.

[38] D. Meldrum, S. Herdman, R. Moloney, D. Murray, D. Duffy, K. Mal-
one, H. French, S. Hone, R. Conroy, and R. McConn-Walsh. Effective-
ness of conventional versus virtual reality based vestibular rehabilita-
tion in the treatment of dizziness, gait and balance impairment in adults
with unilateral peripheral vestibular loss: a randomised controlled trial.
BMC Ear, Nose and Throat Disorders, 12(1):1–8, 2012.

[39] A. Murata. Effects of duration of immersion in a virtual reality environ-
ment on postural stability. International Journal of Human-Computer
Interaction, 17(4):463–477, 2004.

[40] M. Naef, O. Staadt, and M. Gross. Spatialized audio rendering for
immersive virtual environments. In Proceedings of the ACM symposium
on Virtual reality software and technology, pp. 65–72, 2002.

[41] E.-C. Park, S.-G. Kim, and C.-W. Lee. The effects of virtual reality
game exercise on balance and gait of the elderly. Journal of physical
therapy science, 27(4):1157–1159, 2015.

[42] J. Pinkl and M. Cohen. Spatialized ar polyrhythmic metronome using

bose frames eyewear. 2020.

[43] L. E. Powell and A. M. Myers. The activities-speciﬁc balance conﬁ-
dence (abc) scale. The Journals of Gerontology Series A: Biological
Sciences and Medical Sciences, 50(1):M28–M34, 1995.

[44] A. A. Rendon, E. B. Lohman, D. Thorpe, E. G. Johnson, E. Medina,
and B. Bradley. The effect of virtual reality gaming on dynamic balance
in older adults. Age and ageing, 41(4):549–552, 2012.

[45] M. T. Robert, L. Ballaz, and M. Lemay. The effect of viewing a virtual
environment through a head-mounted display on balance. Gait &
posture, 48:261–266, 2016.

[46] J. Ross, O. Will, Z. McGann, and R. Balasubramaniam. Auditory white
noise reduces age-related ﬂuctuations in balance. Neuroscience letters,
630:216–221, 2016.

[47] J. M. Ross and R. Balasubramaniam. Auditory white noise reduces
postural ﬂuctuations even in the absence of vision. Experimental brain
research, 233(8):2357–2363, 2015.

[48] A. Ruhe, R. Fejer, and B. Walker. Center of pressure excursion as a
measure of balance performance in patients with non-speciﬁc low back
pain compared to healthy controls: a systematic review of the literature.
European Spine Journal, 20(3):358–368, 2011.

[49] C. C. Sacco, E. M. Gaffney, and J. C. Dean. Effects of white noise
achilles tendon vibration on quiet standing and active postural position-
ing. Journal of applied biomechanics, 34(2):151–158, 2018.

[50] M. Salavati, M. R. Hadian, M. Mazaheri, H. Negahban, I. Ebrahimi,
S. Talebian, A. H. Jafari, M. A. Sanjari, S. M. Sohani, and M. Parni-
anpour. Test–retest reliabty of center of pressure measures of postural
stability during quiet standing in a group with musculoskeletal disor-
ders consisting of low back pain, anterior cruciate ligament injury and
functional ankle instability. Gait & posture, 29(3):460–464, 2009.
[51] G. Samaraweera, R. Guo, and J. Quarles. Latency and avatars in
virtual environments and the effects on gait for persons with mobility
impairments. In 2013 IEEE Symposium on 3D User Interfaces (3DUI),
pp. 23–30. IEEE, 2013.

[52] S. Schepens, A. Goldberg, and M. Wallace. The short version of the
activities-speciﬁc balance conﬁdence (abc) scale: its validity, reliabil-
ity, and relationship to balance impairment and falls in older adults.
Archives of gerontology and geriatrics, 51(1):9–12, 2010.

[53] K. Sienko, S. Whitney, W. Carender, and C. Wall III. The role of
sensory augmentation for people with vestibular deﬁcits: real-time bal-
ance aid and/or rehabilitation device? Journal of Vestibular Research,
27(1):63–76, 2017.

[54] F. Soffel, M. Zank, and A. Kunz. Postural stability analysis in virtual
reality using the htc vive. In Proceedings of the 22nd ACM Conference
on Virtual Reality Software and Technology, pp. 351–352, 2016.
[55] P. Soltani and R. Andrade. The inﬂuence of virtual reality head-
mounted displays on balance outcomes and training paradigms: A
systematic review. Frontiers in sports and active living, 2:233, 2020.
[56] B. Sondell, L. Nyberg, S. Eriksson, B. Engstr¨om, A. Backman,
K. Holmlund, G. Bucht, and L. Lundin-Olsson. Altered walking
pattern in a virtual environment. Presence, 14(2):191–197, 2005.

