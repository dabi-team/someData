2
2
0
2

r
a

M
9

]

C
H
.
s
c
[

1
v
0
6
0
5
0
.
3
0
2
2
:
v
i
X
r
a

Both authors contributed equally to this research.

Erik Wolf
erik.wolf@uni-wuerzburg.de

Resize Me! Exploring the User Experience of
Embodied Realistic Modulatable Avatars for
Body Image Intervention in Virtual Reality
Nina D ¨ollinger 1,∗, Erik Wolf 2,∗, David Mal 1,2, Stephan Wenninger 3, Mario
Botsch 3, Marc Erich Latoschik 2 and Carolin Wienrich 1
1Human-Technology-Systems Group, University of W ¨urzburg, W ¨urzburg, Germany
2Human-Computer Interaction Group, University of W ¨urzburg, W ¨urzburg, Germany
3Computer Graphics Group, TU Dortmund University, Dortmund, Germany
Correspondence*:
Nina D ¨ollinger
nina.doellinger@uni-wuerzburg.de

preprint

Obesity is a serious disease that can affect both physical and psychological well-being. Due to
weight stigmatization, many affected individuals suffer from body image disturbances whereby
they perceive their body in a distorted way, evaluate it negatively, or neglect it. Beyond established
interventions such as mirror exposure, recent advancements aim to complement body image
treatments by the embodiment of visually altered virtual bodies in virtual reality (VR). We present a
high-ﬁdelity prototype of an advanced VR system that allows users to embody a rapidly generated
personalized, photorealistic avatar and to realistically modulate its body weight in real-time within
a carefully designed virtual environment. In a formative multi-method approach, a total of 12
participants rated the general user experience (UX) of our system during body scan and VR
experience using semi-structured qualitative interviews and multiple quantitative UX measures.
By using body weight modiﬁcation tasks, we further compared three different interaction methods
for real-time body weight modiﬁcation and measured our system’s impact on the body image
relevant measures body awareness and body weight perception. From the feedback received,
demonstrating an already solid UX of our overall system and providing constructive input for
further improvement, we derived a set of design guidelines to guide future development and
evaluation processes of systems supporting body image interventions.

ABSTRACT

Keywords: Virtual reality, avatar embodiment, user experience, body awareness, body weight perception, body weight modiﬁcation,

body image disturbance, eating and body weight disorders

1 INTRODUCTION

Obesity is deﬁned as a complex chronic disease characterized by a drastic overweight and an above-average
percentage of body fat (World Health Organization, 2021). In recent decades, its prevalence has more than
doubled and is expected to rise further (Venegas and Mehrzad, 2020). For those affected, it imposes a severe

1

 
 
 
 
 
 
D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

physical and psychological burden. Physically, it is associated with an increased risk of several secondary
diseases like diabetes, cardiovascular disorders, or cancer, and with increased mortality from infections
(Stefan et al., 2021). Psychologically, individuals deal with external or internalized stigmatization that
can lead to a disturbed body image (Meadows and Calogero, 2018). Noninvasive treatments of obesity
often consist of a multi-method approach combining lifestyle and weight-loss interventions with cognitive-
behavioral therapy (Yumuk et al., 2015). In addition to practicing beneﬁcial diet and exercise habits,
the focus lies on examining one’s own body and managing disturbances in body image. Disturbances
in body image, as part of a variety of body weight- and eating disorders (Rosen, 2001; Thompson and
Tantleff-Dunn, 1998), are composed of a misperception of body dimensions (body image distortion) and
the inability to like, accept, or value one’s own body (body image dissatisfaction) (Turbyne et al., 2021).
The treatment methods are various, including a confrontation with one’s own body using a mirror reﬂection
or video recordings, as well as self-acceptance exercises such as meditation (Ziser et al., 2018; Stewart,
2004).

preprint

In recent years, novel methods complementing the therapy of body image disturbances based on virtual
reality (VR) have been explored (Ferrer-Garcia et al., 2013; Wiederhold et al., 2016; Riva et al., 2019).
These methods often use 3D models of human beings (Horne et al., 2020; Turbyne et al., 2021), which can
be called avatar as they represent a particular user (Bailenson and Blascovich, 2004). VR in general, and the
confrontation with avatars in particular, have great potential to inﬂuence human perception and behavior
(Wienrich et al., 2021). Especially the feeling of embodiment towards an avatar holds enormous potential
for therapeutic purposes (Matamala-Gomez et al., 2021). It increases the emotional response to important
virtual stimuli (Gall et al., 2021), and users tend to adapt their behavior and attitudes to the characteristics of
their embodied avatar (Ratan et al., 2020; Yee and Bailenson, 2007). In the context of body image, avatars
have been utilized to expose users of a VR system to virtual bodies or body parts varying in size and/or
shape to investigate the principles of body weight perception (Thaler, 2019; Wolf et al., 2020, 2021, 2022)
or to inﬂuence the perception or attitude towards the user’s own body (Turbyne et al., 2021). D¨ollinger
et al. (2019) suggested simulating body weight changes using modulatable, photorealistic, personalized,
and embodied avatars, and Turbyne et al. (2021) further stated that the users’ body image may conform to
these avatars after being embodied to it. Recent developments in computer graphics allow the generation
of photorealistic avatars that exactly match a person’s real-life appearance within a short duration and at
low-cost (Achenbach et al., 2017; Wenninger et al., 2020; Bartl et al., 2021). Likewise, methods for a
realistic modulation of the generated avatars’ body dimensions have been established (Piryankova et al.,
2014a; Hudson et al., 2020; Maalin et al., 2020). However, to the best of our knowledge, no work to date
combines all the above introduced promising technologies in a joint system intending to support body
image therapy.

To address this gap, we developed and evaluated a VR system allowing users to embody their
photorealistic, personalized avatar and actively modify their avatar’s body weight in real-time. The
current work aims to present our system development, evaluate the user experience of this interactive
approach, and reveal ﬁrst insights into its usefulness for measuring body weight perception and its impact
on body image and body awareness. We used an optimized photogrammetry approach to create avatars
that reﬂect the user’s exact physical appearance. We carefully designed our system to ensure accessibility
and ease of use for future use cases. As our technical system was developed to be evaluated with potential
patients in a clinically relevant setting as part of a later feasibility study within our research project
ViTraS (Virtual Reality Therapy by Stimulation of Modulated Body Perception, D¨ollinger et al., 2019),
we aimed to guarantee high usability and user experience for future testing and usage with individuals
of the target population. For this purpose, we performed a formative user evaluation with a small sample

This is a provisional ﬁle, not the ﬁnal typeset article

2

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

2 RELATED WORK

of participants who did not suffer from a disturbed body image. A total of 12 participants underwent a
structured experimental procedure, which included the avatar generation process and exposure to their avatar
in a virtual therapy ofﬁce. In VR, they estimated their modulated avatars’ body weight and interactively
simulated different weight changes using gestures, a joystick, or virtual buttons. We conducted short
interviews before and after the virtual experience to capture qualitative feedback. Additionally, participants
quantitatively rated the usability of the calibration process and the interaction methods and reported their
feeling of presence, embodiment, body awareness, and general perception of their avatar. Finally, we
captured their performance during the interactive estimation task to measure body weight perception. Based
on our results, we present a set of design guidelines for the future development of similar avatar-based
body image therapy support tools.

Body image disturbance is characterized by an “excessively negative, distorted, or inaccurate perception
of one’s own body or parts of it” (World Health Organization, 2019). It may manifest into body image
distortion, the misperception of one’s body weight and dimensions that have repeatedly been reported
based on underestimations (Maximova et al., 2008; Valtolina, 1998) or overestimations (Thaler et al.,
2018a; Docteur et al., 2010), or body image dissatisfaction, a negative attitude towards the own body that is
associated with body image avoidance (Walker et al., 2018) and a reduced body awareness (awareness for
bodily signals, Mehling et al., 2011; Peat and Muehlenkamp, 2011; Todd et al., 2019a,b; Zanetti et al., 2013).
While often caused by internalized weight stigma and a fear of being stigmatized by others (Meadows
and Calogero, 2018), a disturbed body image interferes with efforts to stabilize body weight in the long
term (Rosen, 2001). Treatments for body image disturbances mainly rely on cognitive-behavioral therapy,
typically combining psychoeducation and self-monitoring tasks, mirror exposure, or video feedback (Farrell
et al., 2006; Ziser et al., 2018; Griffen et al., 2018). Based on the fundamentals of these established methods,
an increasing number of researchers have started to explore VR applications as additional support for
attitude and behavior change in general (Wienrich et al., 2021) and therapy of body image disturbance (Riva,
1997; Ferrer-Garcia et al., 2009, 2013; Riva et al., 2019; Turbyne et al., 2021) and obesity in particular
(Horne et al., 2020; D¨ollinger et al., 2019).

preprint

VR offers the opportunity to immerse oneself in an alternative reality and experience scenarios that are
otherwise only achievable via imagination. Endowed with this unique power, mainly the use of avatars has
attracted attention in treating body image disturbance (Turbyne et al., 2021; Horne et al., 2020). The use of
avatars allows the simulation of rapid changes in body shape or weight, enabling further investigation of
body weight perception in general (Thaler, 2019; Wolf et al., 2020, 2021). While some researchers are
using multiple generic avatars differing in body weight (Normand et al., 2011; Piryankova et al., 2014b;
Keizer et al., 2016; Preston and Ehrsson, 2018; Ferrer-Garcia et al., 2018), others have developed methods
for dynamic body weight modiﬁcation (Alca˜niz et al., 2000; Johnstone et al., 2008; Nimcharoen et al.,
2018; Piryankova et al., 2014a; Hudson et al., 2020; Maalin et al., 2020; Neyret et al., 2020). A huge
advantage when using advanced body weight modiﬁcation methods is that the avatar’s body weight can be
realistically changed to a desired numeric reference value. For this purpose, mainly the body mass index
(calculated as BMI = Body Weight in kg
(Body Height in m)2 , World Health Organization, 2000) is used. One example is the
work of Thaler et al. (2018a), who trained a statistical model to apply realistic BMI-based body weight
modiﬁcation to their generated personalized, photorealistic humans. But also other factors like muscle

2.1 The Unique Potential of Modulatable Avatars in VR

3

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

mass could be included into such models (Maalin et al., 2020). However, to our knowledge, previous
works have only presented participants with static modiﬁed avatars (usually in A-pose). Our system allows
users to dynamically alter their body weight while being embodied in VR. The statistical models of weight
gain/loss are usually trained on the whole body (Piryankova et al., 2014a) or neglect the head region
completely (Maalin et al., 2020). We also learn a statistical model of weight gain/loss, but keep a small part
of the face region ﬁxed in order to better preserve the identity of the users when applying the body weight
modiﬁcation.

Besides the shape of the used avatar, application or system-related properties also might alter how we
perceive body weight in VR. Wolf et al. (2020) presented an overview of potentially inﬂuencing factors.
While factors like the used display or the observation perspective might unintentionally alter body weight
perception, especially the personalization and embodiment of avatars hold potential for application in
body image interventions. For example, by using realistic and modulatable avatars, Thaler et al. (2018a)
investigated the inﬂuence of personalization on the perception of body weight. They found that the
estimator’s BMI inﬂuences body weight estimations of an avatar, but only when the avatar’s shape and
texture matched the estimator’s appearance. This comes along with a recent review of Horne et al. (2020),
who identiﬁed the personalization of avatars as an important factor when using avatars.

preprint

In addition to avatar personalization, the feeling of embodiment towards one’s avatar is particularly
interesting for avatar-based body weight estimation scenarios. It can be evoked by visuomotor coherence,
for example, when the virtual body moves like the real body (Slater et al., 2009, 2010) and is divided into
the feeling of being inside (self-location), of owning (virtual body ownership), and of controlling (agency)
an avatar (Kilteni et al., 2012). However, the feeling of embodiment interferes with the user’s physical
body awareness. Tsakiris et al. (2011) showed that individuals with a low body awareness are likely to
perceive a higher feeling of embodiment towards an avatar than individuals with high body awareness.
Filippetti and Tsakiris (2017) showed that individuals with low body awareness experience increased body
awareness when embodying a virtual avatar. In a recent experiment, D¨ollinger et al. (2022) revealed that
especially the feeling of body ownership towards a virtual body was positively related to an increase in
body awareness. Thus, embodiment offers the possibility of strengthening body awareness as a potential
mediator for a positive body image. However, there is no research on the connection between embodying
avatars and body awareness in a VR-based body image treatment task.

In terms of body weight perception, Wolf et al. (2021) recently found that a female’s own BMI inﬂuences
body weight estimations of a generic avatar only when embodying it. Jung et al. (2020) showed that
changes in the body weight of a self-embodied avatar are less likely to be noticed. Riva et al. (2019) further
stated that embodiment could potentially help to update the wrong representation of one’s physical body by
experiencing the ownership over a virtual body with a different shape or size. This statement goes along
with the work of Scarpina et al. (2019), who investigated the inﬂuence of being embodied in a thinner
generic avatar. They showed that both normal weight and obese users estimated the circumference of their
real hips lower after exposition to the embodied avatar, but not without being embodied. Turbyne et al.
(2021) highlighted that participants’ body image conformed to modiﬁed virtual body size when participants
felt embodied in it. This mechanism can be attributed to the Proteus effect (Yee and Bailenson, 2007; Ratan
et al., 2020), suggesting that people tend to conform to their embodied avatars’ characteristics both in
behavior and attitudes.

This is a provisional ﬁle, not the ﬁnal typeset article

4

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

2.2 User Interaction for Body Weight Modiﬁcation

2.3 Summary and Outline

Most VR applications for body image interventions aim for enhanced mirror confrontation. They surpass
real mirror confrontation by modifying the mirror image or the shown avatars into different body shapes.
In our work, we want to go one step further and allow users to adjust the shape of their avatar interactively.
Our idea is to give the users the opportunity to actively engage in analyzing their body image and develop a
novel feeling for their own body. Object manipulation in VR has been widely researched and can serve as a
reference in the development of body weight modiﬁcation interaction methods. For example, LaViola et al.
(2017) presented a set of design guidelines for different types of object manipulation, including object
scaling by virtual buttons or other control elements, the inclusion of physical interfaces as provided on most
VR controllers, or the design of gesture-based object manipulation. Furthermore, Williams et al. (2020)
and Wu et al. (2019) investigated the preference of users towards different gestures in object manipulation,
and both proposed using two-handed gestures (e.g., moving the hands apart or bringing them together) for
size modiﬁcation of large objects. These results could be applied to the manipulation of body weight in
VR. Another option, which could be especially beneﬁcial for novice users due to its high naturalness and
intuitiveness, are multimodal interfaces (Wolf et al., 2019; Zimmerer et al., 2020). However, due to the
still low complexity of our interface, we have refrained from integrating them into our system for now. In
summary, and to the best of our knowledge, there has been no speciﬁc research on interactive real-time
body weight modiﬁcation so far.

preprint

When considering the introduced research, it suggests to further work on complementing established
treatment methods for body image disturbances with the beneﬁts of avatar interaction. Former research
mainly focused on the general perception of body weight in VR or the impact of differently shaped
avatars on the perception of the own body. However, while highly developed avatar weight modiﬁcation
algorithms exist to date, only few systems combine the potentials of simulated body weight modiﬁcations
with embodiment or user interaction. Additionally, most current investigations have not considered body
awareness as a possible mediator between the feeling of embodiment and body image. Further, it has not
yet been investigated whether an interactive avatar modiﬁcation approach has an additional impact on
body image. Our current work within the interdisciplinary research project ViTraS (D¨ollinger et al., 2019)
addresses these research gaps and aims towards a novel approach for supporting body image therapy using
a user-centered design process. In the current work, we present a high-ﬁdelity prototype of a body image
therapy support system that allows users to embody their rapidly generated personalized, photorealistic
avatar within a carefully designed virtual environment. Users can realistically modify their avatars’ body
weight using three different interaction methods (joystick, gestures, and virtual objects). We focus on
a user experience evaluation with normal-weight participants performed within our ﬁrst system design
cycle. In a comprehensive mixed-methods evaluation, we assessed (1) the body scan experience during
the avatar generation process, (2) the user experience (UX) of the VR exposure and different modiﬁcation
methods, and (3) their impact on body image-related outcomes, including body awareness and body weight
misestimation. To sum up our results, we derive a set of guidelines for the design and implementation of
future VR systems to support body image interventions.

3 SYSTEM DESCRIPTION

The technical
implementation of our system is realized using the game engine Unity version
2019.4.15f1 LTS (Unity Technologies, 2019). As VR HMD, we use a Valve Index (Valve Corporation,

5

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

3.1 Virtual Environments

2020a), providing the user a resolution of 1440×1600 pixels per eye with a total ﬁeld of view of 120°
running at a refresh rate of 90 Hz. For motion tracking, we use the two handheld Valve Index controllers,
one HTC Vive Tracker 3.0 positioned on a belt at the lower spine, and two HTC Vive Tracker 3.0 on
each foot ﬁxed by a velcro strap. All VR hardware is integrated using SteamVR in version 1.16.10 (Valve
Corporation, 2020b) and its corresponding Unity plugin in version 2.7.3 1. In our evaluation, the system
was driven by a high-end PC composed of an Intel Core i7-9700K, an Nvidia RTX2080 Super, and 32 GB
RAM running Windows 10. To ensure that users always received a ﬂuent VR experience and to preclude
a possible cause of simulator sickness, we measured the motion-to-photon latency of our system by
frame-counting (He et al., 2000). For this purpose, the video output was split into two signals using an Aten
VanCryst VS192 display port splitter. One signal still led to the HMD, the other to an ASUS ROG SWIFT
PG43UQ low-latency gaming monitor. A high-speed camera of an iPhone 8 recorded the user’s motions
and the corresponding reactions on the monitor screen at 240 fps. The motion-to-photon latency for the
HMD matched the refresh rate of the used Valve Index closely, as it averaged 14.4 ms (SD = 2.8 ms). The
motion-to-photon latency for the body movements was considered low enough to provide a high feeling
of agency towards the avatar (Waltemate et al., 2016), as it averaged 40.9 ms (SD = 5.4 ms). A video
showing the application is provided in the supplementary material.

preprint

We realized two virtual environments. The ﬁrst environment replicates the real environment, in which the
user was located physically during our evaluation, and is automatically calibrated accurately to overlay
the physical environment spatially (see Figure 1). Here, all preparatory steps required for exposure are
performed and tested (e.g., ground calibration, vision test, equipment adjustments, embodiment calibration).
For spatial calibration, we use a customized implementation of the Kabsch algorithm 2 (M¨uller et al., 2016),
based on the positions of the SteamVR base stations in real and virtual environments. Additionally, the
virtual ground height is calibrated by brieﬂy placing the controller onto the physical ground.

Figure 1. The ﬁgure depicts a comparison between the real environment where the experiment took place
(left) and the replicated virtual environment used for preparation (right). Both environments contain a user,
respectively the avatar, performing the embodiment calibration.

1 https://assetstore.unity.com/packages/tools/integration/steamvr-plugin-32647
2 https://github.com/zalo/MathUtilities#kabsch

This is a provisional ﬁle, not the ﬁnal typeset article

6

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

The second environment is originally based on an asset taken from the Unity asset store 3 that was
modiﬁed to match our requirements. This exposition environment is inspired by a typical ofﬁce of a
psychotherapist with a desk and chairs and an exposure area in which the mirror exposure takes place
(see Figure 2). The exposure area includes a virtual mirror allowing for an allocentric observation of
the embodied avatar. We aimed for a realistic and coherent virtual environment to enhance the overall
plausibility of the exposure (Slater, 2009; Latoschik and Wienrich, 2021).

3.2 Generation and Animation of Personalized Avatars

Figure 2. The images show a participant’s personalized avatar standing in front of a mirror within the
virtual exposition environment of our concept prototype with a reduced (left), normal (center), or increased
(right) body weight.

In our system, the user embodies a personalized avatar from an egocentric perspective while the avatar
is animated according to the user’s body movements in real-time. The following sections describe the
generation of the avatars as well as the animation system.

preprint

The generation of the avatars closely follows the method of Achenbach et al. (2017). First, the subject is
scanned with a custom-made photogrammetry rig consisting of 94 DSLR cameras, where four studio lights
equipped with diffuser balls ensure uniform illumination (see Bartl et al., 2021, Figure 1, top). Instead
of employing a separate face scanner like Achenbach et al. (2017) did, 10 of the 94 DSLR cameras are
zoomed in on the subject’s face to capture more detail in this region. The images taken by the cameras are
then automatically processed with the commercial photogrammetry software Agisoft Metashape (Agisoft,
2021), resulting in a dense point cloud of the subject. We manually select 23 landmarks on the point
cloud in order to guide the subsequent template ﬁtting process. The counterparts of these landmarks are
pre-selected on the template model, which comes from the Autodesk Character Generator (Autodesk, 2014)
and consists of N ≈ 21k vertices, an animation skeleton with skinning weights, facial blendshapes, as well
as auxiliary meshes for eyes and teeth. Achenbach et al. (2017) enhance the template with a statistical
model of human shape variation. This statistical, animatable human template model is then ﬁtted to the
point cloud by optimizing for alignment, pose, and shape by employing non-rigid ICP (Bouaziz et al.,
2014). This optimization of the model parameters deﬁnes the initial registration of the template, which
is then further reﬁned by allowing ﬁne-scale deformation of the vertices to match the scanner data more
closely. For more details, we refer to Achenbach et al. (2017).

3.2.1 Generation Process

3 https://assetstore.unity.com/packages/3d/props/interior/manager-office-interior-107709

7

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

3.2.2 Animation Process

3.3 Body Weight Modiﬁcation of Avatars

3.3.1 Data-driven Body Weight Modiﬁcation

Our system allows the user to modify their body weight during runtime dynamically. The statistical

model of weight gain/loss and the implemented user interaction methods are described in the following.

For avatar animation, the participants’ movements are continuously captured using the SteamVR motion
tracking devices. The tracking solution provides for our work a sufﬁciently solid and rapid infrared-based
tracking solution for the crucial body parts required for animation without aligning different tracking spaces
(Niehorster et al., 2017). To calibrate the tracking devices to the user’s associated body parts and capture
the user’s body height, arm length, and current limb orientations, we use a custom-written calibration script
that requires the user to stand in T-pose for a short moment (see Figure 1). The calibrated tracking targets of
the head, left hand, right hand, pelvis, left foot, and right foot were then used to drive an inverse kinematics
(IK, Aristidou et al., 2018) approach realized by the Unity plugin FinalIK version 2.0 4. FinalIK’s integrated
VRIK solver continuously calculates the user’s body pose according to the provided tracking targets. The
tracking pose is automatically adjusted to the determined body height and arm length in order to match the
user’s body. In the next step, the tracking pose is continuously retargeted to the imported personalized avatar.
Potentially occurring inaccuracy in the alignment of the pose or the end-effectors can be compensated by a
post-retargeting IK-supported pose optimization step. This leads to high positional conformity between the
participant’s body and the embodied avatar and avoids sliding feet due to the retargeting process.

preprint

To build a statistical model of body weight modiﬁcation, we follow the approach of Piryankova et al.
(2014a), who ﬁrst create a statistical model of body shape using Principal Component Analysis (PCA) and
then estimate a linear function from anthropometric measurements to PCA coefﬁcients. For computing
the statistical model of human body shape, we use the template ﬁtting process described above to ﬁt our
template model to the European subset of the CAESAR scan database (Robinette et al., 2002). It consists
of M = 1700 3D scans, each annotated with anthropometric measurements such as weight, height, arm
span, inseam, waist width, etc. After bringing the scans into dense correspondence via template ﬁtting,
we are left with M pose-normalized meshes consisting of N vertices each. Our approach for data-driven
weight gain/loss simulation differs from the method of Piryankova et al. (2014a) in the following ways:
(1) instead of encoding body shape as a 3 × 3 deformation matrix per mesh face (Anguelov et al., 2005),
we encode body shape directly via vertex positions, (2) we keep vertices in the face region ﬁxed while
deforming the rest of the mesh in order to better preserve the identity of the participants.

To this end, we deﬁne a set S with cardinality V containing all vertices outside of the face region (see
Figure 3) as well as a selector matrix S ∈ R3V ×3N which extracts all coordinates belonging to vertices
(cid:1)T
in S. Let xj = (cid:0)pT
∈ R3N be the vector containing the stacked vertex positions of the jth
1 , . . . , pT
N
(cid:80)
j xj ∈ R3N be the corresponding mean. Performing PCA on the data matrix
training mesh and ¯x = 1
M
X = (cid:0)Sx1 − S¯x, . . . , SxM − S¯x(cid:1) ∈ R3V ×M and taking the ﬁrst k = 30 components then yields the
(cid:1) ∈ Rk×M contain the PCA coefﬁcients wj of the M
PCA matrix P ∈ R3V ×k. Let W = (cid:0)w1, . . . , wM
training meshes, computed by wj = PT (Sxj − S¯x). If we denote by D ∈ RM ×4 the matrix containing
the anthropometric measurements weight, height, armspan and inseam of the jth subject in its jth row,

4 https://assetstore.unity.com/packages/tools/animation/final-ik-14290

This is a provisional ﬁle, not the ﬁnal typeset article

8

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

we can then compute a linear mapping from anthropometric measurements D to PCA coefﬁcients W by
solving the linear system of equations (cid:0)D | 1(cid:1) C = WT in a least-squares sense via normal equations.

Figure 3. The ﬁgure illustrates our approach of facial weight gain simulation. When modifying the weight
of an avatar (left), part of the face region (highlighted in red) is ﬁxed (center left). The modiﬁed vertices
are stitched to the face region in a seamless manner using differential coordinates (Sorkine, 2005) (center
right). Not keeping these vertices ﬁxed would require recalculating the position of all auxiliary meshes
such as eyes and teeth due to the undesired change in shape for nose, mouth and eyes (right). For the right
image, eyes are copied from the unmodiﬁed avatar in order to better highlight the change in shape and
position.

preprint

New vertex positions for a subject with initial vertex positions x and a desired change in anthropometric
measurements ∆d ∈ R5 can then be calculated via ˜x = Sx + P (cid:0)CT ∆d(cid:1), i.e., by ﬁrst projecting the
desired change in measurements into PCA space via the learned linear function and then into vertex position
space via the PCA matrix. However, this only updates vertices in S. In order to seamlessly stitch the new
vertex positions to the unmodiﬁed face region, we compute the Laplacian coordinates (discretized through
cotangent weights and Voronoi areas (Botsch et al., 2010) of the resulting mesh and then use surface
reconstruction from differential coordinates (Sorkine, 2005). For the vertices of the face region and its
1-ring neighborhood, the Laplacian is computed based on the unmodiﬁed vertex positions x, while for the
rest of the vertices, the Laplacian is computed based on the modiﬁed vertex positions ˜x. Since the position
of vertices of the face region is known and should not change, we treat the position of these vertices as hard
instead of soft constraints as discussed by Botsch and Sorkine (2008). Setting ∆d = (cid:0)∆w, 0, 0, 0, 0(cid:1)T
then
allows modifying the user’s weight while keeping the other anthropometric measurements ﬁxed. Keeping
the face region ﬁxed (1) better preserves the identity of the user for high values of ∆w and (2) avoids having
to recalculate the position of auxiliary meshes of the avatar such as eyes and teeth (Figure 3). Results of the
described body weight modiﬁcation method are shown in Figure 4.

3.3.2 Interaction Methods

To allow users to modify the avatars’ body weight as quickly, easily, and precisely as possible, we compare
in our evaluation three implemented interaction methods regarding their usability. Since interaction methods
for human body weight modiﬁcation have not yet been explored, we considered the guidelines for object
modiﬁcation presented by LaViola et al. (2017). Figure 5 gives a short overview of the body weight
modiﬁcation methods. We restricted the body weight modiﬁcation for all interaction methods to a range of
±35% of the user’s body weight to avoid unrealistic, possibly unsettling shape deformation. The constants

9

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Figure 4. The ﬁgure shows a generated female avatar (BMI = 19.8) with modiﬁed body weight
corresponding to a BMI range of 16 to 32 in two-point increments.

given in the formulas for calculating the velocity of body weight change were determined empirically in a
pilot test.

3.3.2.1 Body Weight Modiﬁcation via Controller Movement Gestures

To modify the avatar’s body weight via gestures (see Figure 5, left), users have to press the trigger button
on each controller simultaneously. Moving the controllers away from each other then increases the body
weight, while moving them towards each other decreases it. The faster the controllers are moved, the faster
the body weight changes. When active, the body weight changes by the velocity v in kg/s, determined by
the relative distance change between the controllers r in m/s, and calculated as v = 3.5r2 + 15r.

preprint

To modify the avatar’s body weight via joystick (see Figure 5, center), users have to tilt the joystick of
either the left or the right controller. Selecting joystick for an initial modiﬁcation leads to a deactivation of
the other joystick for the remaining interaction. Tilting the joystick to the left decreases the body weight,
tilting it to the right increases it. The stronger the joystick is tilted, the faster the body weight changes.
When enabled, the body weight changes by the velocity v in kg/s, determined by the normalized tilt t of
the joystick and calculated as v = 10t2 + 5.

3.3.2.2 Body Weight Modiﬁcation via Joystick Movement

Figure 5. The ﬁgure sketches the three body weight modiﬁcation methods we used for our evaluation:
Gestures (left), Joystick (center), and Objects (right).

This is a provisional ﬁle, not the ﬁnal typeset article

10

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

3.3.2.3 Body Weight Modiﬁcation via Controller Movement Towards Objects

To modify the avatar’s body weight via objects (see Figure 5, right), users have to touch either a virtual
“plus” or a virtual “minus” object within the virtual environment. As long as an object is touched, the body
weight increases or decreases. The longer the object is touched, the faster the body weight changes. When
active, the body weight modiﬁcation velocity v in kg/s increases quadratically over a normalized contact
duration d of 1.5 s in a normalized range r between 3 kg/s and 15 kg/s.

4.1 Ethics

4 EVALUATION

We tested our ﬁrst system prototype in a structured UX evaluation based on multiple relevant qualitative
questions and quantitative measures concerning the users’ scan and VR exposure experience as well as
their body image. The following sections contain a detailed explanation of the evaluation process.

Since our technical system was developed with the aim of being tested on potential patients in a clinically
relevant context as part of a later feasibility study, particular attention has already been paid to ethical
aspects during the here reported development and evaluation of our system. As part of a conservative
development and evaluation strategy, we decided to work with a relatively small sample of healthy
participants in this initial formative evaluation. The system, as well as the evaluation, was designed in
consultation with our clinical partners within the context of our interdisciplinary research project ViTraS
(D¨ollinger et al., 2019). A detailed ethics proposal following the Declaration of Helsinki was submitted
to the ethics committee of the Human-Computer-Media Institute of the University of W¨urzburg and
found to be ethically unobjectionable. Free professional help services provided by the Anorexia Nervosa
and Associated Disorders (ANAD) 5 organization were explicitly highlighted during the acquisition and
evaluation process.

preprint

A total of 12 students (8 female, 4 male) of the University of W¨urzburg participated in our evaluation
and received course credit in return. Before the evaluation, we deﬁned four exclusion criteria queried
by self-disclosure: Participants had to have (1) normal or corrected to normal vision and hearing, (2)
at least ten years of experience with the German language, (3) not suffered from any kind of mental or
psychosomatic disease, or from body weight disorders, and (4) no known sensitivity to simulator sickness.
None of the participants matched any exclusion criteria. The participants were aged between 20 and 25
(M = 22.0, SD = 1.48), had a BMI between 17.85 and 32.85 (M = 22.72, SD = 3.98), and had mostly
very little VR experience. Nine out of the twelve participants claimed to know their current body weight.
The mean deviation of the indication of their body weight compared to that measured by the experimenter
was 0.29 kg (SD = 1.57).

4.2 Participants

4.3 Design

The evaluation of our system included qualitative and quantitative measures regarding (1) the body scan
experience, (2) the UX of the VR exposure and the different modiﬁcation methods used, and (3) their
impact on the body image-related measures body awareness and body weight estimation. To compare
our three modiﬁcation methods (see Figure 5), participants performed for each modiﬁcation method a

5 https://www.anad.de/

11

4.4.2 VR Experience

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

set of active modiﬁcation tasks (AMTs) in a counterbalanced order using a 1x3 within-subjects design.
For comparing the novel AMT with the more traditional passive estimation task (PET), the participants
performed a PET each before and after the AMTs (see Figure 6, right). All tasks and the timing of the
measures will be further explained in Section 4.5.

4.4 Measures

4.4.1 Body Scan Experience

We conducted a semi-structured interview to evaluate the body scan experience. It included questions
concerning the participants’ expectations, their physical and psychological comfort and/or discomfort
during the body scan and the assessment of their body measures, and about the clarity and transparency of
the process. A full version of the questions can be found in the supplementary material of this work.

We conducted a semi-structured interview with focus on the VR experience. It included questions
concerning the participants’ expectations and feelings towards the avatar, their favored body weight
modiﬁcation method and the perceived difﬁculty of the body weight estimation in general, their intensity
of body awareness, and their affect towards their body. A full version of the questions can be found in the
supplementary material of this work.

Regarding the VR experience, we included a variety of VR-speciﬁc and task-speciﬁc UX measures to
get a holistic view of the system’s overall UX, as recommended by previous work (Tcha-Tokey et al.,
2016; Wienrich and Gramlich, 2020). Following Wienrich and Gramlich (2020), we used a combination of
qualitative and quantitative measures, in virtuo ratings, and pre- and post-questionnaires for the VR UX
evaluation.

preprint

We measured the participants’ feeling of presence using the Igroup Presence Questionaire (IPQ, Schubert
et al., 2001). It captures presence through 14 questions, each rated on a scale from 0 to 6 (6 = highest
presence). The items are divided into four different dimensions: general presence, spatial presence,
involvement, and realism. The questionnaire was provided directly after the VR exposure to capture
presence as accurately as possible.

4.4.2.3 Embodiment

As suggested by prior work, we divided the measurements for the feeling of embodiment into VBO
and agency (Kilteni et al., 2012). Following Waltemate et al. (2018) and Kalckert and Ehrsson (2012),
we presented one embodiment question for each dimension on a scale from 0 to 10 (10 = highest). To
investigate possible differences in the feeling of embodiment caused by our interaction methods, the
questions were provided multiple times during exposure.

4.4.2.4 Simulator Sickness

To test our system prototype regarding simulator sickness, we included the Simulator Sickness
Questionnaire (SSQ, Kennedy et al., 1993; Bimberg et al., 2020) before and after the VR exposure.
It captures the appearance and intensity of 32 different simulator sickness associated symptoms on 4-point
Likert scales. The total score of the questionnaire ranges from 0 to 235.62 (235.62 = strongest). An increase

This is a provisional ﬁle, not the ﬁnal typeset article

12

4.4.2.1 Interview

4.4.2.2 Presence

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

in the score by 20 between a pre- and post-measurement indicates the occurrence of simulator sickness
(Stanney et al., 1997).

4.4.2.5 Avatar Perception

For measuring the affect towards the avatar, we used the revised version of the Uncanny Valley Index
(UVI, Ho and MacDorman, 2017), including its four sub-dimensions: humanness, eeriness, spine-tingling,
and attractiveness. Each dimension is captured by four to ﬁve items ranging from 1 to 7 (7 = highest)

4.4.2.6 Workload

4.4.2.7 Preference Rankings

We measured workload to (1) determine the perceived effort during the calibration of the system and
to (2) determine the perceived difﬁculty when modifying the avatar’s body weight with our modiﬁcation
methods. To capture workload fast and efﬁciently during VR, we used a single item scale ranging from 0 to
220 (220 = highest) called SEA scale (Eilers et al., 1986), a German version of the Rating Scale Mental
Effort (Zijlstra, 1993; Arnold, 1999).

Participants were asked to order the three body weight modiﬁcation methods concerning their workload,
perceived body weight estimation difﬁculty, vividness, contentment, and overall preference. Ranking scores
were then calculated using weighted scores with reversed weights. A weighting of 4 was used for the
highest rank, a weighting of 3 for the second highest, and so on. The overall rankings were summed up and
averaged over the number of ratings. A high scores states high workload, difﬁculty, vividness, contentment,
and overall preference.

4.4.2.8 Calibration and Modiﬁcation Time

To measure the efﬁciency of the avatar calibration and the interactions methods, we captured the average
time needed from the beginning of calibration or modiﬁcation until the end. Calibration time included
potential amendments of the avatar skeleton and re-calibrations. A lower time states a higher efﬁciency.

preprint

Similar to VBO, agency, and workload, we included (virtual) body awareness (VBA) as a one-item scale
from 0 to 10 (10 = highest VBA) assessed at multiple times during exposure. The item was derived from
the State Mindfulness Scale (SMS, Tanay and Bernstein, 2013).

4.4.3.2 Passive Body Weight Estimation (PET)

The PET was adapted from prior work (Wolf et al., 2020, 2021, 2022) and used to capture the participants’
ability to numerically estimate the avatars’ body weight based on a provided body shape. We repeatedly
modiﬁed the body weight of the embodied avatar within a range of ±20% incremented in 5% intervals in a
counterbalanced manner resulting in n = 9 modiﬁcations. To not provide any hints on the modiﬁcation
direction, the HMD was blacked-out during the modiﬁcation. For each modiﬁcation, the participants had
to estimate the avatar’s body weight in kg, which we used to calculate the misestimation M . It is based
on the estimated body weight e and the presented body weight of the avatar p as M = e−p
p . A negative
value states an underestimation, a positive value an overestimation. Additionally, we calculated (1) the
average misestimation M = 1
k=1 Mk and (2) the absolute average percentage of misestimation as
n
A = 1
k=1 |Mk|.
n

(cid:80)n

(cid:80)n

4.4.3 Body Image

4.4.3.1 Body Awareness

13

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

4.4.3.3 Active Body Weight Estimation (AMT)

The AMT was inspired by related work (Piryankova et al., 2014a; Thaler et al., 2018a,b) and used to
capture the participants’ ability to modify the avatar’s body weight to match a requested numeric value. We
also used it to analyze whether a certain interaction method for body weight modiﬁcation inﬂuenced the
participant’s ability to judge the avatars’ body weight. Participants had to modify the avatar’s body weight
by using one of our modiﬁcation interaction methods until they thought it matched a presented numeric
target weight in kg. The task was repeated for a target weight range of ±20% of the actual avatar’s body
weight incremented in 5% intervals in a counterbalanced manner resulting in n = 9 modiﬁcations. For
each modiﬁcation, we calculated the misestimation M based on the modiﬁed body weight m and the target
body weight t as M = t−m
. A negative value states an underestimation, a positive value an overestimation.
t
Additionally, we calculated M and A as for the PET.

4.5 Procedure

The entire evaluation took place in three adjacent rooms (ofﬁce, body scanner, laboratory) of the

University of W¨urzburg and averaged 117 min. The procedure is illustrated in Figure 6.

preprint

Figure 6. The ﬁgure provides an overview of the evaluation process as whole (left) and a detailed overview
of the VR exposure (right). The icons on the right side of each step show in which physical or virtual
environment the step was conducted. The icons on the left side indicate when steps were repeated.

4.5.1 Opening Phase

First, participants were informed about the local COVID-19 regulations, received information about the
experiment and the body scans, gave their consent, and generated two personal pseudonymization codes
used to store the experimental data and the generated avatars separately. Then, the main experimenter
answered potential questions and measured the participant’s body height without shoes as required for the
body scan.

This is a provisional ﬁle, not the ﬁnal typeset article

14

Opening PhaseInformation and ConsentBody Scan PhaseVR Exposure PhasePre-QuestionnairesInterviewQ&ABody ScanBody MeasurementsInterviewFittingPost-QuestionnairesEye TestPassive Estimation TasksVR Exposure2CalibrationBody Movement TasksPassive Estimation TasksActive Estimation Tasks3PreparationOfficeScannerLaboratoryPhysical EnvironmentsExposureVirtual EnvironmentsVR ExposureD ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

4.5.2 Body Scan Phase

An auxiliary experimenter performed the body scan in normal clothes without any accessories. Afterwards,
the main experimenter measured the interpupillary distance (IPD), body weight, and the participants’ waist
and hip circumference, and conducted the interview about the scan process. The duration of the interview
averaged 4 min. All interviews were recorded by a Tascam DR-05 voice recorder.

4.5.3 VR Exposure Phase

Prior to the VR exposure, participants answered demographic questions and the SSQ as pre-questionnaires
on a dedicated questionnaire computer. Then, an auxiliary experimenter demonstrated the participants
how to ﬁt the equipment, adjusted the HMD’s IPD, and controlled that all equipment was correctly
attached. After ﬁnishing the ﬁtting, a pre-programmed experimental procedure was started, and participants
were transferred to the preparation environment. For all virtual transitions during the VR exposure, the
display was blacked-out for a short moment. All instructions were displayed on an instruction panel and
additionally played as pre-recorded voice instructions. As the ﬁrst preparation step, the participants had
to undergo a short reading test to ensure the view was sufﬁcient. Then, they performed the embodiment
calibration in T-pose and judged its workload. During the whole VR exposure, participants had to answer
questions and measurements verbally. Although interaction between the experimenter and the user may
cause small breaks in presence (Putze et al., 2020), we considered this approach as part of the evaluation,
since interaction between patient and therapist would also likely occur in clinical settings and advanced in
virtuo interaction to answer questionnaires might be difﬁcult for novice users.

preprint

After the preparation ﬁnished, participants were transferred to the exposition environment. There, they
performed ﬁve movement tasks in front of a virtual mirror while being instructed to alternatingly look at
the mirror and directly on their body to induce the feeling of embodiment. Movement tasks were adapted
from related work (Wolf et al., 2020) and had to be performed for 20 s. The ﬁrst PET followed. Participants
estimated the modiﬁed body weight of their avatar nine times. Between the estimations, the display
was blacked-out brieﬂy to cover the weight changes. In the next phase, participants conducted AMTs
nine times for each body weight modiﬁcation method in a counterbalanced manner. For all body weight
estimation tasks, no feedback regarding the estimation error was provided to the participants. The second
PET concluded the phase. After each AMT (see Figure 6), participants were asked to judge workload,
agency, VBO, and VBA in virtuo. The whole VR exposure took 36 min on average. After the VR exposure,
participants answered IPQ, SSQ, UVI, and UX questions again on the dedicated questionnaire computer.

The questionnaires were followed by the second interview about the VR exposure that lasted on average
11 min. At the end of the session, the main experimenter thanked the participants and granted them
credits for their participation. As part of the debrieﬁng process after the session, the interviews were ﬁrst
transcribed and then by two researchers summarized and clustered the answers into categories.

4.5.4 Closing and Debrieﬁng Phase

5 RESULTS

In this section, we report the results of our evaluation separated into (1) the body scan experience, (2)
the UX of the VR exposure including the different modiﬁcation methods, and (3) their impact on body
image-related measures. The statistical analysis of our results was partially performed using the software R
for statistical computing (R Core Team, 2020) and partially using SPSS version 26.0.0.0 (IBM, 2020).

15

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

5.1 Body Scan Experience

5.1.1 Feedback on the Body Scanning Process

5.1.2 Feedback on the Body Measurements

When asked whether the body scan procedure matched their idea of a body scan, four participants
expected a different amount or arrangement of cameras, three participants expected a different scan process
(e.g., one camera moving around the body, a laser measuring the body shape, or cameras only in the
front), and one participant claimed to have no previous expectations on the body scan process. The other
participants stated they already knew the body scan procedure from former experiments and did not
remember expectations.

Most of the participants perceived the scan process as simple and clear. Only one participant stated not
knowing what was happening between two scans. The experience during the scan process differed from
“straightforward” and “easy” (n = 4) over “interesting” or “cool” (n = 4) to being “something to getting
used to” or making one “feel observed” (n = 4).

All participants stated positively they would do a body scan again. While most of them did not have
suggestions for improvement (n = 8). One suggested that the experimenter should be visible during the
whole scan process to increase a feeling of safety. Others pointed out that a reduced number of cameras
would ease the feeling of being watched and that the stiff posture during the scan felt kind of uneasy after
some time.

preprint

To evaluate the possible occurrence of simulator sickness, we compared SSQ pre- and post-measurements
using a two-tailed Wilcoxon signed-rank test since the pre-requirements for parametric testing were not
met. The ratings did not differ signiﬁcantly between measurements, Z = 1.14, p = .254. Additionally, the
observed increase in SSQ scores of 16.21 was below the indication threshold for simulator sickness of 20
points.

When evaluating the assessment of body measures, most participants claimed to perceive it as neutral or
similar to being measured during a doctor’s appointment (n = 8). Some others pointed out they would
not expect it in a “normal” lab study but did not perceive it as awkward (n = 3). One participant stated to
perceive the measuring of their weight as very private and therefore uncomfortable.

Since there was no comparison condition to the overall quantitative scores of the VR experience, we
report the data, which were mainly collected on validated and comparable scales, descriptively. For
measures captured multiple times during the experience, we calculated the mean value of all data points.
The descriptive results of the VR exposure experience are summarized in Table 1.

5.2 VR Experience

5.2.1 Feedback on Embodiment and Avatar Perception

When asked about their feelings towards their personalized avatar, two participants used “neutral” or
“okay” to describe their experience, and another four participants described it as “cool”, “interesting”,
or “pleasant”. The remaining six participants described the experience as less positive, using words like
“strange” and “irritating”. While one of the former emphasized the quality of the embodiment compared
to other studies, three of the latter criticized the embodiment, especially concerning the lack of facial
expression, eye movements and hand gestures. One pointed out that their “hands hold these controllers

This is a provisional ﬁle, not the ﬁnal typeset article

16

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Table 1. The table shows the descriptive values for our captured measurements concerning the VR
experience. Detailed information regarding the measurements can be found in Section 4.4.
Measure

M (SD)

[Range]

Presence

Embodiment

Simulator sickness

Avatar perception

Variable
IPQ General presence
IPQ Spatial presence
IPQ Involvement
IPQ Realism
VBO score
Agency score
Pre-SSQ
Post-SSQ
UVI Humanness
UVI Eeriness
UVI Spine-tingling
UVI Attractiveness
SEA score
Time in s

[0-6]
[0-6]
[0-6]
[0-6]
[0-10]
[0-10]
[0-235.62]
[0-235.62]
[1-7]
[1-7]
[1-7]
[1-7]
[0-220]

4.58 (0.90)
4.38 (0.95)
3.75 (0.89)
3.22 (1.2)
5.49 (2.33)
7.22 (1.94)
26.8 (23.7)
43.01 (39.21)
4.03 (1.10)
4.06 (0.95)
3.88 (0.88)
4.25 (0.87)
20.83 (16.35)
96.79 (50.29)

Calibration workload
Calibration time

but the avatar does not”. The participants who found the experience rather irritating emphasized a lack of
similarity in their avatar’s appearance.

The question of whether the avatar’s appearance met the participants’ expectations also received mixed
responses. While one participant found it overall disproportional, six participants stated that the look of
their avatar rather met their expectations. The remaining participants indicated that although the avatar’s
body looked as expected, they did not associate its face with themselves.

preprint

For comparing the three AMT conditions (gesture, joystick, and objects), we calculated a one-way
repeated-measures ANOVA for each listed measurement (see Table 2) except modiﬁcation times, where
we calculated a Friedman test, and preference rankings, which are presented descriptively only. Test results
showed signiﬁcant differences between conditions only for workload. Two-tailed paired-sample post-hoc
t-tests revealed signiﬁcant differences in the SEA score between body weight modiﬁcations with gesture
and joystick, t(11) = 2.74, p = .019, gesture and objects, t(11) = 2.8, p = .017, and joystick and objects,
t(11) = 4.86, p = .001. Thus, the workload was considered to be highest when modifying body weight via
objects and lowest when using the joystick.

5.2.2 Comparison of the Body Weight Modiﬁcation Methods

5.2.3 Feedback on the Body Weight Modiﬁcation Methods

When asked to explain their preference for an interaction method, most of the participants who preferred
joystick (n = 8) stated that it felt most controllable and least complicated. One participant additionally
preferred the continuity of joystick-based interaction compared to the necessity of repetition in the gesture-
based interaction. The participants who had preferred the gesture-based interaction (n = 4) stated they
found it most intuitive, ﬂexible, and direct. They reasoned that controlling the speed of modiﬁcation by
extent and speed of arm movements increased usability. None of the participants preferred modiﬁcation via
the objects. xx

17

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Table 2. The table shows all descriptive values of the measures related to the comparison between our
proposed body weight modiﬁcation methods including p-values when calculated. Asterisks indicate
signiﬁcant p-values. Post-hoc tests for signiﬁcant differences can be found in the corresponding text.

Gestures

M (SD)

Joystick

M (SD)

Objects

M (SD)

p

Measure

Embodiment

Variable

[Range]

VBO
Agency

[0-10]
[0-10]

5.38 (2.5)
7.33 (2.02)
27.82 (7.72)
65.33 (33.06) < .001∗

.300
.915
.197

5.75 (2.63)
7.25 (2.61)
23.19 (2.94)
41.25 (27.97)
1.91
3
3.09
3.36
3.27
6.58 (1.98)

5.08 (2.68)
7.16 (2.29)
24.53 (10.37)
20.75 (13.37)
2.73
1.81
3.09
3.45
3.45
7.08 (1.93)

VBA

5.3 Body Image

–
–
–
–
–
.053

Modiﬁcation time Time in s
Workload

[0-220]
[1-4]
[1-4]
[1-4]
[1-4]
[1-4]
[0-10]

3.45
3.36
2.27
1.91
2.09
6.67 (2.06)

awareness and body weight estimation as well as the related qualitative feedback.

5.3.1 Comparison of Body Awareness Between Body Weight Modiﬁcation Methods

In the following, we present the impact of our VR exposure on the body image-related measures of body

SEA
Ranking
Ranking
Task Difﬁculty
Ranking
Vividness
Ranking
Contentment
Overall preference Ranking
Body awareness

We calculated a one-way repeated-measures ANOVA to compare the body awareness (VBA) during
the three AMT conditions (gesture, joystick, and objects). As shown in Table 2, VBA ratings differed
tendentially between the three AMT conditions, with higher joystick ratings than the other conditions.

preprint

Seven participants stated they felt in contact with their physical body during the experience, while the
other ﬁve stated they had lost contact to their body at least once. The latter stated, for example, they focused
mainly on the task and the avatar. Others felt that their bodily awareness “got a bit lost” or that the situation
and virtual surroundings made them forget reality, including their real body. On the other hand, three
participants who stated being aware of their body during the experiment reasoned the embodiment as a
main cause. One of them stated that “once before re-calibration, my avatar’s foot was kind of crooked,
that’s when I paid attention to my real body. I made sure my knee was straight”. The other one focused on
the avatar weight and claimed that “I was still aware of my body, but it was very strange because I was
looking at a different mirror image, and sometimes, I felt much heavier when the weight of the avatar was
lower than my actual weight”. Another reason why participants were aware of their bodily sensations was
the physical contact with the ﬂoor or the proprioception during movements, which reminded them of their
presence in the physical room (n = 2).

5.3.2 Feedback on the Intensity of Body Awareness

5.3.3 Feedback on the Affect Towards the Body

Eight of the participants stated that their feelings towards their bodies had changed during the experience.
These changes concerned either their general awareness (n = 3), their experienced body size (n = 2), or
their satisfaction with their body (n = 3). The two participants stating a change in their experienced body
size had either felt thicker or thinner in contrast to their avatar during the experience or felt thinner after the
experience. Two of the participants whose bodily satisfaction changed stated an increased body satisfaction

This is a provisional ﬁle, not the ﬁnal typeset article

18

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

or increased motivation to care for their bodily interests. In contrast, one participant reported increased
dissatisfaction towards their physical body after the experience.

5.3.4 Feedback on the Perception of Body Weight Changes

5.3.5 Comparison of Body Weight Estimations between Body Weight Modiﬁcation Methods

For comparing the performance in body weight estimations between the AMT, we calculated a one-way
repeated-measures ANOVA for M -values, the percentage body weight misestimation, and a Friedman
test for A-values, the absolute percentage body weight misestimation. The tests revealed that the three
interaction methods did not differ signiﬁcantly, neither in M nor in A, as summarized in Table 3.

Concerning the changes in the avatar’s body weight, the participants equally rated them as “interesting”
(n = 6) or “weird” (n = 6). Two participants especially pointed out that it was interesting to compare the
avatar’s body shape to their own former body, as they had lost or gained weight in the past. One stated
“when I started my studies ﬁve years ago, I was 20 kg lighter than now, and it was kind of interesting
to compare the avatar’s look to the memories of my old body shape. It gave me a little perspective on
how I want to look”. Four of the other participants liked the idea of seeing how they could look if they
changed their eating/exercise behavior. Especially the modiﬁcation towards a lower weight was perceived
as threatening by some of the participants (n = 3), as they thought it looked a bit unhealthy. To enhance
the modiﬁcation, two participants suggested more individual and ﬁne-grained possibilities to manipulate
only body parts instead of the body as a whole, for example, by including “two ﬁxed points on the virtual
body, one in the middle of the body and one at the shoulder area, to adjust the weight in these areas more
exactly”.

preprint

We compared AMT and PET using two-tailed paired-samples t-tests for M -values and two-tailed
Wilcoxon signed-rank tests for A-values. For M , we showed that participants misestimated the body weight
signiﬁcantly less using the PET. For A, we could observe a clear tendency towards lower misestimations
for PET. Results are summarized in Table 4.

Table 3. The table summarizes the body weight estimation performance (average misestimation M and
absolute average of misestimation A) of the comparison between our proposed modiﬁcation methods.

5.3.6 Comparison of Body Weight Estimations Between Estimation Methods

M in %
A in % 8.92 (4.58)

2.41 (8.05)
8.36 (3.66)

3.44 (8.9)
8.46 (5.10)

.529
.780

M (SD)

M (SD)

M (SD)

Gestures

Joystick

3.44 (9)

Objects

p

We further analyzed the results of AMT and PET concerning the modiﬁcation levels (±20% in
5% steps) using linear regression. Our data violated pre-requirements for linear regression in terms
of homoskedasticity and normality. Therefore, we calculated each linear regression using parameter
estimations with robust standard errors (HC4) as recommended by Hayes and Cai (2007). Figure 7 shows
the body weight misestimations M (left) and the absolute body weight misestimations A (right) for PET
and AMT in relation to the modiﬁcation levels.

19

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Table 4. The table summarizes the body weight estimation performance (average misestimation M and
absolute average of misestimation A) of the comparison between passive estimation task (PET) and active
modiﬁcation tasks (AMT). Asterisks indicate signiﬁcant p-values.

PET

AMT

M (SD)

M (SD)

1.46 (8.4)
7.74 (4.43)

3.1 (8.4)
8.59 (4.14)

p
.031∗
.060

M in %
A in %

Figure 7. The ﬁgure shows the body weight misestimations M (left) and absolute body weight
misestimations A (right) in relation to the performed body weight modiﬁcations for PET and AMT.

preprint

For M , the results showed a signiﬁcant regression equation for PET, F (1, 106) = 7.88, p = .006, with
a R2 of .069. The prediction followed the equation M = −0.194 · Body Weight Modiﬁcation in % +
1.462. The modiﬁcation level did signiﬁcantly impact on body weight misestimations M , t(106) = −
5.11, p = .013. For AMT, we found no signiﬁcant prediction of the modiﬁcation level on the body weight
misestimations M , F (1, 106) = 3.05, p = .084, having a R2 of .028. The found prediction followed the
equation M = −0.120 · Body Weight Modiﬁcation in % + 3.099. In consequence, the modiﬁcation level
did not signiﬁcantly impact on body weight misestimations M , t(106) = − 3.46, p = .094.

For A, the results showed a signiﬁcant regression equation for PET, F (1, 106) = 5.27, p = .024, with
a R2 of .047. The prediction followed the equation A = −0.101 · Body Weight Modiﬁcation in % +
7.743. The modiﬁcation level did signiﬁcantly impact on body weight misestimations A, t(106) = −
2.09, p = .039. For AMT, we found a signiﬁcant prediction of the modiﬁcation level on the body weight
misestimations A, F (1, 106) = 15.7, p < .001, with a R2 of .129. The found prediction followed the
equation M = −0.147 · Body Weight Modiﬁcation in % + 8.585. The modiﬁcation level did signiﬁcantly
impact on body weight misestimations A, t(106) = − 17.9, p < .001.

In addition to the linear regressions, we averaged negative and positive modiﬁcations for both
measurements to analyze difference between the modiﬁcation directions. Test results for M -values showed
that body weight misestimations differed signiﬁcantly between positive (M = −1.09, SD = 7.44) and
negative(M = 3.96, SD = 11.13) modiﬁcations for PET, t(11) = 2.27, p = .044, but not between
positive (M = 1.38, SD = 7.45) and negative (M = 4.86, SD = 10.57) modiﬁcations for AMT,
t(11) = 1.63, p = .131. For A-values, we found no signiﬁcant differences between positive (M = 6.74,
SD = 3.5) and negative (M = 9.28, SD = 7.2) modiﬁcations for PET, Z = 1.26, p = .209, but found

This is a provisional ﬁle, not the ﬁnal typeset article

20

-6-4-20246-20-1001020M in %Body Weight Modification in %PETAMT02468101214-20-1001020A in %Body Weight Modification in %PETAMTD ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

signiﬁcant differences between positive (M = 6.8, SD = 4.4) and negative (M = 10.57, SD = 4.9)
modiﬁcations for AMT, Z = 2.59, p = .010.

5.3.7 Feedback on the Body Weight Estimation Difﬁculty

6 DISCUSSION

Regardless of the estimation method, estimating the body weight of the avatar was found to be difﬁcult
(n = 8). Only three participants stated they found it relatively easy or only medium-difﬁcult to estimate the
body weight. The main reason why participants rated the task as difﬁcult was the high number of repetitions
(n = 2) or a reduced perceptibility of their physical body, both leading to a “loss of perspective”.
Additionally, one participant stated that the task difﬁculty depended on the distance of the avatar’s weight
to their own.

In the present paper, we introduced a prototype of an interactive VR-based system that aims to support body
image interventions based on embodied, modulatable, and personalized avatars in future clinically relevant
settings. We evaluated the system regarding (1) the body scan experience, (2) the UX of the VR exposure
including body weight modiﬁcation interaction methods, and (3) the impact on two body image-related
measures body awareness and body weight misestimation. In the following, we summarize and discuss
the results of our evaluation to ultimately derive guidelines supporting the design of systems for body
image interventions. The guidelines are based on conclusions of the qualitative and quantitative results
accomplished by the researchers’ observations and participants’ comments during the evaluation. While
these may overlap with existing best practices or established VR guidelines, we believe it is elementary to
summarize them for the given context and to highlight their importance.

preprint

Nevertheless, two main criticisms of the scanning process were the feelings of being watched and being
left alone. The large number of visible cameras mainly caused the ﬁrst while both can be attributed to
the arrangement of the cameras surrounding the person in all directions. Curtains around the scanner also
supported the feeling of being left alone during the scan process. In particular for our target group and
the intended clinical usage, amendments seem necessary. Options to reduce the negative feelings could
be a change in the arrangement of cameras, e.g., opening the space by placing them only on one side or
reducing the number of cameras to a minimum as proposed by Wenninger et al. (2020) and supported by
the results of Bartl et al. (2021). In addition, we suggest a constant dialogue about and during the process
to counteract the feeling of being alone.

Overall, the scan process was mainly rated as simple and interesting, although it took place in a separate
room with great technical effort. Participants stated a high acceptance and willingness to be scanned again.
In addition, the scan and the associated body measurements were seen as something that one would do in a
clinical setting, and that does not trigger unpleasant reservations. This assessment strengthens the idea of
using body scans in a clinical context.

6.1 Body Scan Experience

Guidelines for Body Scanning

• Users should receive thorough information and instruction in advance about the body scan procedure

to provide clarity and transparency.

• Body scans should be performed unobtrusively to protect privacy and avoid the feeling of being

watched.

21

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

• The number and arrangement of cameras should be planned carefully to avoid the feeling of being

watched.

• The number of people involved in the body scan should be minimized to increase privacy, and personal

contact should be maximized to increase safety.

• Body-related measurements should be performed professionally while maintaining privacy.

6.2 User Experience of VR Experience

The feedback regarding preparation and calibration was consistently positive, conﬁrming the decision for
our approach. This is empirically supported by the low measured calibration times requiring only a short
time holding T-pose, and the low workload ratings during the calibration process. Nevertheless, there are
further possibilities to reduce the effort for calibration and invasiveness, for example, by using completely
markerless body tracking solutions (cf., Wolf et al., 2022).

Regarding VR-speciﬁc measures, participants rated their perceived feeling of presence on an acceptable
level (cf., Buttussi and Chittaro, 2018; Wolf et al., 2020), with lower ratings on involvement and realism. A
reason for the lower observed involvement score could be the constant interaction with the experimenter
during the tasks (e.g., conﬁrming body weight estimations, rating experiences). Possible implausible content
(e.g., body weight modiﬁcation by interaction) could have impacted negatively on realism. Continuous
communication between therapist and patient during weight modiﬁcations might be a crucial element in
clinical settings. Therefore, further research on the role of presence (and its sub-dimensions) in VR body
image interventions seems required, as the latest reviews did not address this topic (Turbyne et al., 2021;
Riva et al., 2019; Horne et al., 2020).

preprint

Surprisingly, although participants rated their feeling of virtual body ownership descriptively higher
compared to non-personalized avatars (Waltemate et al., 2018; Wolf et al., 2020), their ratings were lower
than in prior work using personalized and photorealistic avatars (Waltemate et al., 2018). A reason for the
noticed differences could be the particularly body-related nature of our task. Avatars created via body scans
have a very high resemblance to the individual but still do not provide a perfect visual replica. In a task
highly focusing on body perception, even minor inaccuracies may become noticeable, and participants
might focus on these, experiencing a diminished feeling of virtual body ownership. Another factor could be
the performed body weight modiﬁcation, as real-time changes in the avatar’s body shape lead to a reduced
concordance between real and virtual bodies.

The ratings and especially the qualitative statements on avatar perception reveal similar results, as some
of the participants stated their avatar to be uncanny or not fully recognizable as themselves. This raises
doubts about the degree of personalization of avatars and whether the creation of highly photorealistic
textures is currently necessary (and feasible). Tools such as Virtual Caliper (Pujades et al., 2019) can create
in shape personalized avatars using only VR equipment. In conjunction with generic avatar generators,
such as Meta Human (Epic Games, 2021), highly realistic avatars with personalized body shapes could be
created. They wouldn’t resemble the person perfectly. However, this lack of resemblance could make them
less uncanny while remaining a still better quality in general. Additionally, a personalization in body shape
would be sufﬁcient for simulating body weight changes. One counter-argument is provided by Thaler et al.
(2018a), who clearly state that the body weight perception of avatars having personalized textures differs
from generic ones. More research in this direction seems required.

Guidelines for VR Design

• The physical and mental effort for system calibration should be kept as low as possible.

This is a provisional ﬁle, not the ﬁnal typeset article

22

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

• The animations of embodied avatars should be as authentic as possible and include facial expressions,

eye movements, and hand gestures to increase realism and reduce eeriness.

• When using physical controllers, virtual controller representations should be displayed in VR and

controlled by the avatar.

• When using personalized avatars, body shape and texture should aim for the highest possible conformity

with the user to reduce uncanniness.

6.2.1 User Experience of Body Weight Modiﬁcation

Guidelines for Body Weight Modiﬁcations

• Body weight modiﬁcations severely differing from the user’s BMI or reaching unrealistic ranges should

Regardless of the interaction method, the lack of body weight modiﬁcation in relation to different body
parts (e.g., abdomen, hips, thighs) and in relation to the composition of the body tissue (e.g., fat or muscle
mass) was mentioned. The use of advanced body modiﬁcation methods, such as those presented by Maalin
et al. (2020) or Pujades et al. (2019) could allow for body weight modiﬁcations that go beyond using only
BMI as a single parameter modifying the whole body’s weight. However, having more complex body
weight modiﬁcation methods would also increase the difﬁculty of user interaction.

When comparing the subjective rankings of the three modiﬁcation methods, it becomes apparent that the
interaction via virtual objects was the least preferred. It was rated as more demanding and difﬁcult, and
less vivid, resulting in lower contentment and overall preference than the other two modiﬁcation methods.
Modiﬁcation via joystick and gestures were rated rather similarly with a slight preference towards the
joystick interaction. The in virtuo ratings of workload match these rankings. While joystick was rated
quantitatively most positively, the qualitative analysis shows arguments in favor of gesture interaction,
especially in terms of vividness and intuitivity. No impact has been noticed on the feeling of embodiment
or performance in body weight estimation, which is particularly important in our context.

preprint

The reported effects of the VR exposure on body awareness and affect towards the body were very
individual, with participants reporting either a loss or an increase of body awareness and either an
afﬁrmation of their positive body image or an increase of negative feelings towards their body. Future work
with an increased sample size is necessary to investigate whether these individual differences are related
to people’s overall body awareness, as proposed by Filippetti and Tsakiris (2017), and to a negative or
positive body image. These insights will be crucial to determine what effects can be expected for a target
group with low body awareness or negative body image. The comparison of body awareness between the
three modiﬁcation methods indicates a higher body awareness in joystick interaction, followed by gestures
and objects. Compared to the results on workload, this suggests that task load might harm body awareness
in VR.

preferred over virtual objects or buttons.

6.3 Body Image-Related Outcomes

• Body weight modiﬁcations should allow changing the body weight independently on different body

• Body weight modiﬁcations performed directly via a hardware input device or body gestures should be

parts considering different body tissue compositions.

be avoided to reduce alienation.

In contrast to body awareness, body weight estimations did not differ between body weight modiﬁcation
methods. However, when comparing the accuracy of the type of estimations task, PET provided more

23

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

accurate estimates than AMT. While estimating a person’s weight based on their appearance is not an
everyday task, it is surely more common than actively modifying a (virtual) body to a certain body weight.
Thus, the difference might originate in the relative novelty of active modiﬁcation compared to passive
estimation. Another reason could be the different phrasing of the task instructions, which has been shown
to have the ability to inﬂuence body weight estimation (Piryankova et al., 2014b). For both PET and
AMT, the accuracy of the body weight estimation depended on the target weight, or in other words, on
the deviation between the own real weight and the virtually presented body weight. This effect has been
observed priorly for VR body weight estimation tasks (Wolf et al., 2020; Thaler et al., 2018a) and is in
line with the so-called Contraction bias as described by Cornelissen et al. (2016, 2015). It states that body
weight estimates are most accurate around an estimator-dependent reference template (of a body) and
decrease with increasing BMI difference from this reference. Thereby, bodies heavier than the reference
tend to be underestimated, while lighter ones tend to be overestimated. Results on absolute body weight
estimations show that although the average misestimations were comparatively low, they are subject to high
deviations and uncertainties, which also has been observed priorly (Thaler et al., 2018a). The reasons for
this probably lie in the nature of the task, since estimating body weight seems generally challenging, and
body image disturbances are ubiquitous even in the healthy population (Longo, 2017). Qualitative feedback
conﬁrms the task difﬁculty. When further analyzing the absolute body weight estimations, it is particularly
noticeable that they seem to be easier and more accurate for increased than for reduced body weight. This
is rather unexpected since Weber’s Law suggests that differences in body weight become harder to detect
when body weight increases (Cornelissen et al., 2016). A possible reason for the high uncertainties in the
absolute body weight estimations and the contradiction to Weber’s law could be the perspective on the
avatar offered by the virtual mirror, which mainly shows the front side of the body (Cornelissen et al.,
2018). More research on this topic seems required.

preprint

The results of our work raise new research questions for future work. First, the high necessity of
communication between therapist and user, potentially leading to breaks in presence, raises the question
of the general impact of presence in body image interventions. This is also interesting when it comes to
augmented reality, as already recognized by Wolf et al. (2022).

• Body weight estimations capturing the current perception of the real body in VR should be performed
at the beginning of an intervention, as the perceptibility of the real body might decrease over time.
• When performing body weight estimations, care should be taken to present the respective body equally

• When analyzing body weight misestimations based on avatars, determining the average accuracy of
the misestimations with healthy individuals helps avoid strong inﬂuences of the system properties.

Guidelines for Body Weight Estimations

6.4 Future Research Directions

from multiple perspectives.

Second, the observed ratings in body ownership despite using photorealistic, personalized avatars and the
feedback on avatar perception leads to the question of how photorealism and personalization should be
applied to body image interventions. Future work should explore whether avatars that are less personalized
in texture are sufﬁcient for our purpose as they might raise less uncanniness.

Third, the severe individual differences in the report of body awareness and affect towards the body raise
the question, of which individual characteristics might predict the effects of a VR-based intervention on

This is a provisional ﬁle, not the ﬁnal typeset article

24

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

both variables. Further, future work should explore the effects of task difﬁculty on body awareness and
whether it mediates the effect of a VR-based intervention on body image.

Finally, future work should further address the difference between active body weight modiﬁcation and
passive body weight estimation we found in this study. It remains unclear which underlying processes lead
to differences between the two tasks and whether they impact differently on body image. Similar counts
for the observed differences in body weight misestimations for avatars with decreased or increased body
weight.

6.5 Limitations

Although our sample included slightly overweight participants, the current design and development phase
was limited to students without a diagnosed body image disturbance and predominantly with a BMI in
a healthy range. The clinical applicability to our target group, which is already in preparation as part of
our ViTraS research project (D¨ollinger et al., 2019), is consequently the next step after the here presented
design and UX optimization phase. Also, the limits of body weight modiﬁcation used in this study were
selected arbitrarily. Some participants felt uneasy when their avatar’s body weight was modiﬁed, especially
in the extreme ranges. Overall, the design and development phase would beneﬁt from a larger test user
group tailored to the ﬁnal target group. However, this is not an easy endeavor since it blurs the separation
between the user-centered design and development phases and the clinical application. Hence, it requires
closer integration and supervision by therapeutically trained professionals and experts in obesity treatment.
Ultimately, this integration would be necessary throughout all steps of the complete user-centered technical
developments to safeguard against unwanted effects for all participants during the design and development
and UX optimization steps. Notably, two participants of our overall healthy sample already showed some
emotional reactions when confronted with their modiﬁed virtual self. xx

preprint

In this work, we have presented and evaluated the prototype of an advanced VR therapy support system
that allows users to embody a rapidly generated, personalized, photorealistic avatar and modulate its body
weight in real-time. Our system already offers numerous positive features and qualities, especially regarding
the execution of body scans and an overall enjoyable VR experience. The guidelines for designing VR
body image therapy support systems we derived from our results help facilitate future developments in this
ﬁeld.

However, more research is needed for a therapeutic application. Possible areas of investigation include
the implementation of photorealism, which may need to be revisited when working on body image.
More research is also required on the differences between active body weight modiﬁcation and passive
body weight estimation. Finally, investigations with more focus on the target group and the individual
characteristics of future users will be necessary, especially concerning body image distortion, body
dissatisfaction, and body awareness.

7 CONCLUSION

CONFLICT OF INTEREST STATEMENT

The authors declare that the research was conducted in the absence of any commercial or ﬁnancial
relationships that could be construed as a potential conﬂict of interest.

25

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

AUTHOR CONTRIBUTIONS

ND and EW conceptualized large parts of the experimental design, collected the data, performed data
analysis, and took the lead in writing the manuscript. EW and DM developed the Unity application
including the experimental environment and avatar animation system. MB and SW provided the avatar
reconstruction and body weight modiﬁcation framework. CW and ML conceived the original project idea,
discussed the study design, and supervised the project. All authors continuously provided constructive
feedback and helped to shape study and the corresponding manuscript.

FUNDING

REFERENCES

ACKNOWLEDGMENTS

DATA AVAILABILITY STATEMENT

All datasets for this study can be provided upon request.

This research has been funded by the German Federal Ministry of Education and Research in the project
ViTraS (project number 16SV8219).

We thank Andrea Bartl for her extensive support when preparing and conducting the body scans,
Viktor Frohnapfel for contributing his Blender expertise to our virtual environments, Marie Fiedler for
proofreading, and Sara Wolf for her support with our illustrations. We also thank Miriam F¨oßel and Nico
Erdmannsd¨orfer for their help in preparing the interviews for qualitative analysis. In addition, we would
like to thank the project partners from the ViTraS research project for their constructive feedback.

preprint

Achenbach, J., Waltemate, T., Latoschik, M. E., and Botsch, M. (2017). Fast generation of realistic virtual
humans. In Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology
(New York, NY, USA: Association for Computing Machinery), VRST ’17, 1–10. doi:10.1145/3139131.
3139154

Agisoft (2021). Metashape Pro. http://www.agisoft.com [Accessed January 20, 2022]
Alca˜niz, M., Perpi˜n´a, C., Ba˜nos, R., Lozano, J. A., Montesa, J., Botella, C., et al. (2000). A new realistic 3d
body representation in virtual environments for the treatment of disturbed body image in eating disorders.
CyberPsychology & Behavior 3, 433–439. doi:https://doi.org/10.1089/10949310050078896

Anguelov, D., Srinivasan, P., Koller, D., Thrun, S., Rodgers, J., and Davis, J. (2005). Scape: Shape
completion and animation of people. ACM Transactions on Graphics 24, 408–416. doi:10.1145/
1073204.1073207

Aristidou, A., Lasenby, J., Chrysanthou, Y., and Shamir, A. (2018). Inverse kinematics techniques in
computer graphics: A survey. In Computer Graphics Forum (Wiley Online Library), vol. 37, 35–58.
doi:https://doi.org/10.1111/cgf.13310

Arnold, A. G. (1999). Mental effort and evaluation of user-interfaces: A questionnaire approach. In
Proceedings of HCI International (the 8th International Conference on Human-Computer Interaction) on
Human-Computer Interaction: Ergonomics and User Interfaces-Volume I - Volume I (USA: L. Erlbaum
Associates Inc.), 1003–1007

This is a provisional ﬁle, not the ﬁnal typeset article

26

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Autodesk (2014). Character Generator. https://charactergenerator.autodesk.com [Accessed January 20,

2022]

Bailenson, J. N. and Blascovich, J. (2004). Avatars. In Encyclopedia of human-computer interaction,

Berkshire Publishing Group (Citeseer). 64–68

Bartl, A., Wenninger, S., Wolf, E., Botsch, M., and Latoschik, M. E. (2021). Affordable but not cheap:
A case study of the effects of two 3d-reconstruction methods of virtual humans. Frontiers in Virtual
Reality doi:10.3389/frvir.2021.694617

CRC press). doi:10.1201/b10688

Tutorials. 1–17. doi:10.1145/2504435.2504456

Buttussi, F. and Chittaro, L. (2018). Effects of different types of virtual reality display on presence and
learning in a safety training scenario. IEEE Transactions on Visualization and Computer Graphics 24,
1063–1076. doi:10.1109/TVCG.2017.2653117

Botsch, M. and Sorkine, O. (2008). On linear variational surface deformation methods. IEEE Transactions

on Visualization and Computer Graphics 14, 213–230. doi:10.1109/TVCG.2007.1054

Bouaziz, S., Tagliasacchi, A., and Pauly, M. (2014). Dynamic 2D/3D registration. In Eurographics

Bimberg, P., Weissker, T., and Kulik, A. (2020). On the usage of the simulator sickness questionnaire for
virtual reality research. In 2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts
and Workshops (VRW) (IEEE), 464–467. doi:10.1109/VRW50115.2020.00098

Botsch, M., Kobbelt, L., Pauly, M., Alliez, P., and L´evy, B. (2010). Polygon Mesh Processing (AK Peters,

preprint

Cornelissen, K. K., Bester, A., Cairns, P., Tov´ee, M. J., and Cornelissen, P. L. (2015). The inﬂuence of
personal bmi on body size estimations and sensitivity to body size change in anorexia spectrum disorders.
Body Image 13, 75–85. doi:https://doi.org/10.1016/j.bodyim.2015.01.001

Cornelissen, K. K., Gledhill, L. J., Cornelissen, P. L., and Tov´ee, M. J. (2016). Visual biases in judging
body weight. British Journal of Health Psychology 21, 555–569. doi:https://doi.org/10.1111/bjhp.12185
Cornelissen, P. L., Cornelissen, K. K., Groves, V., McCarty, K., and Tov´ee, M. J. (2018). View-
dependent accuracy in body mass judgements of female bodies. Body Image 24, 116–123. doi:https:
//doi.org/10.1016/j.bodyim.2017.12.007

D¨ollinger, N., Wienrich, C., Wolf, E., and Latoschik, M. E. (2019). ViTraS – virtual reality therapy by
stimulation of modulated body image – project outline. In Mensch und Computer 2019 - Workshopband
(Bonn: Gesellschaft f¨ur Informatik e.V.), 1–6. doi:10.18420/muc2019-ws-633

D¨ollinger, N., Wolf, E., Mal, D., Erdmannsd¨orfer, N., Botsch, M., Latoschik, M. E., et al. (2022). Virtual
reality for mind and body: Does the sense of embodiment towards a virtual body affect physical body
awareness? In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New
York, NY, USA: Association for Computing Machinery), CHI ’22, 1–8

Docteur, A., Urdapilleta, I., Defrance, C., and Raison, J. (2010). Body perception and satisfaction
in obese, severely obese, and normal weight female patients. Obesity 18, 1464–1465. doi:https:
//doi.org/10.1038/oby.2009.418

Eilers, K., Nachreiner, F., and H¨anecke, K. (1986). Entwicklung und ¨uberpr¨ufung einer skala zur erfassung

subjektiv erlebter anstrengung. Zeitschrift f¨ur Arbeitswissenschaft , 214–224

Epic Games (2021). Meta Human. https://www.unrealengine.com/en-US/digital-humans [Accessed

January 20, 2022]

Farrell, C., Shafran, R., and Lee, M. (2006). Empirically evaluated treatments for body image disturbance:

a review. European Eating Disorders Review 14, 289–300. doi:https://doi.org/10.1002/erv.693

27

In International Immersive Projection Technology Workshop. 1–6

Ho, C.-C. and MacDorman, K. F. (2017). Measuring the Uncanny Valley Effect. International Journal of

Hayes, A. F. and Cai, L. (2007). Using heteroskedasticity-consistent standard error estimators in ols
regression: An introduction and software implementation. Behavior research methods 39, 709–722.
doi:https://doi.org/10.3758/BF03192961

He, D., Liu, F., Pape, D., Dawe, G., and Sandin, D. (2000). Video-based measurement of system latency.

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Ferrer-Garcia, M., Gutierrez-Maldonado, J., Caqueo-Urizar, A., and Moreno, E. (2009). The validity of
virtual environments for eliciting emotional responses in patients with eating disorders and in controls.
Behavior Modiﬁcation 33, 830–854. doi:https://doi.org/10.1177/0145445509348056

Ferrer-Garcia, M., Guti´errez-Maldonado, J., and Riva, G. (2013). Virtual reality based treatments
in eating disorders and obesity: a review. Journal of Contemporary Psychotherapy 43, 207–221.
doi:https://doi.org/10.1007/s10879-013-9240-1

Ferrer-Garcia, M., Porras-Garcia, B., Moreno, M., Bertomeu, P., Maldonado, J., Ferrer-Garcia, M., et al.
(2018). Embodiment in different size virtual bodies produces changes in women’s body image distortion
and dissatisfaction. Annual Review of Cybertherapy and Telemedicine 2018 16, 111

Filippetti, M. L. and Tsakiris, M. (2017). Heartfelt embodiment: Changes in body-ownership and

self-identiﬁcation produce distinct changes in interoceptive accuracy. Cognition 159, 1–10

Gall, D., Roth, D., Stauffert, J.-P., Zarges, J., and Latoschik, M. E. (2021). Embodiment in virtual reality
intensiﬁes emotional responses to virtual stimuli. Frontiers in Psychology 12, 3833. doi:10.3389/fpsyg.
2021.674179

Griffen, T. C., Naumann, E., and Hildebrandt, T. (2018). Mirror exposure therapy for body image

disturbances and eating disorders: A review. Clinical Psychology Review 65, 163–174

preprint

IBM (2020). SPSS Statistics. https://www.ibm.com/products/spss-statistics [Accessed January 20, 2022]
Johnstone, A. M., Stewart, A. D., Benson, P. J., Kalafati, M., Rectenwald, L., and Horgan, G.
Journal of
eprint:

(2008). Assessment of body image in obesity using a digital morphing technique.
Human Nutrition and Dietetics 21, 256–267.
https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-277X.2008.00862.x

doi:10.1111/j.1365-277X.2008.00862.x.

Jung, M., Kim, J., and Kim, K. (2020). Measuring recognition of body changes over time: A human-
computer interaction tool using dynamic morphing and body ownership illusion. PLOS ONE 15, 1–14.
doi:10.1371/journal.pone.0239322

Kalckert, A. and Ehrsson, H. H. (2012). Moving a rubber hand that feels like your own: A dissociation of
ownership and agency. Frontiers in Human Neuroscience 6, 40. doi:https://doi.org/10.3389/fnhum.2012.
00040

Keizer, A., van Elburg, A., Helms, R., and Dijkerman, H. C. (2016). A virtual reality full body illusion
improves body image disturbance in anorexia nervosa. PLOS ONE 11. doi:10.1371/journal.pone.
0163921

This is a provisional ﬁle, not the ﬁnal typeset article

28

Hudson, G. M., Lu, Y., Zhang, X., Hahn, J., Zabal, J. E., Latif, F., et al. (2020). The development
of a bmi-guided shape morphing technique and the effects of an individualized ﬁgure rating scale on
self-perception of body size. European Journal of Investigation in Health, Psychology and Education
10, 579–594. doi:https://doi.org/10.3390/ejihpe10020043

Horne, M., Hill, A., Murells, T., Ugail, H., Irving, Chinnadorai, R., et al. (2020). Using avatars in
Internet Interventions 19, 100295. doi:https:

weight management settings: A systematic review.
//doi.org/10.1016/j.invent.2019.100295

Social Robotics 9, 129–139. doi:10.1007/s12369-016-0380-9

theory and practice (Addison-Wesley Professional)

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Kennedy, R. S., Lane, N. E., Berbaum, K. S., and Lilienthal, M. G. (1993). Simulator sickness
questionnaire: An enhanced method for quantifying simulator sickness. The International Journal
of Aviation Psychology 3, 203–220. doi:https://doi.org/10.1207/s15327108ijap0303 3

Kilteni, K., Groten, R., and Slater, M. (2012). The sense of embodiment in virtual reality. Presence:

Teleoperators & Virtual Environments 21, 373–387. doi:https://doi.org/10.1162/PRES a 00124

Latoschik, M. E. and Wienrich, C. (2021). Coherence and plausibility, not presence?! Pivotal conditions

for XR experiences and effects, a novel model. arXiv 2104.04846

LaViola, J. J., Kruijff, E., McMahan, R. P., Bowman, D., and Poupyrev, I. P. (2017). 3D user interfaces:

Longo, M. R. (2017). Distorted body representations in healthy cognition. Quarterly Journal of

Experimental Psychology 70, 378–388. doi:https://doi.org/10.1080/17470218.2016.1143956

Matamala-Gomez, M., Maselli, A., Malighetti, C., Realdon, O., Mantovani, F., and Riva, G. (2021). Virtual
Body Ownership Illusions for Mental Health: A Narrative Review. Journal of Clinical Medicine 10, 139.
doi:10.3390/jcm10010139

Maximova, K., McGrath, J. J., Barnett, T., O’Loughlin, J., Paradis, G., and Lambert, M. (2008). Do you
see what I see? Weight status misperception and exposure to obesity among children and adolescents.
International Journal of Obesity 32, 1008. doi:https://doi.org/10.1038/ijo.2008.15

Maalin, N., Mohamed, S., Kramer, R. S., Cornelissen, P. L., Martin, D., and Tov´ee, M. J. (2020).
Beyond bmi for self-estimates of body size and shape: A new method for developing stimuli correctly
calibrated for body composition. Behavior Research Methods 53, 1–14. doi:https://doi.org/10.3758/
s13428-020-01494-1

preprint

Mehling, W. E., Wrubel, J., Daubenmier, J. J., Price, C. J., Kerr, C. E., Silow, T., et al. (2011). Body
awareness: a phenomenological inquiry into the common ground of mind-body therapies. Philosophy,
ethics, and humanities in medicine 6, 1–12

M¨uller, M., Bender, J., Chentanez, N., and Macklin, M. (2016). A robust method to extract the rotational
part of deformations. In Proceedings of the 9th International Conference on Motion in Games (New York,
NY, USA: Association for Computing Machinery), MIG ’16, 55–60. doi:10.1145/2994258.2994269
Neyret, S., Bellido Rivas, A. I., Navarro, X., and Slater, M. (2020). Which body would you like to have?
The impact of embodied perspective on body perception and body evaluation in immersive virtual reality.
Frontiers in Robotics and AI 7, 31. doi:https://doi.org/10.3389/frobt.2020.00031

Niehorster, D. C., Li, L., and Lappe, M. (2017). The accuracy and precision of position and orientation
tracking in the HTC Vive virtual reality system for scientiﬁc research. i-Perception 8, 2041669517708205.
doi:10.1177/2041669517708205

Meadows, A. and Calogero, R. M. (2018). Studies on weight stigma and body image in higher-weight

individuals. In Body image, eating, and weight (Springer). 381–400

Nimcharoen, C., Zollmann, S., Collins, J., and Regenbrecht, H. (2018). Is that me? – Embodiment and
body perception with an augmented reality mirror. In 2018 IEEE International Symposium on Mixed
and Augmented Reality Adjunct (ISMAR-Adjunct). 158–163. doi:10.1109/ISMAR-Adjunct.2018.00057
Normand, J.-M., Giannopoulos, E., Spanlang, B., and Slater, M. (2011). Multisensory stimulation can
induce an illusion of larger belly size in immersive virtual reality. PLOS ONE 6, e16128. doi:10.1371/
journal.pone.0016128

Peat, C. M. and Muehlenkamp, J. J. (2011). Self-objectiﬁcation, disordered eating, and depression: A test

of mediational pathways. Psychology of Women Quarterly 35, 441–450

29

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Piryankova, I. V., Stefanucci, J. K., Romero, J., De La Rosa, S., Black, M. J., and Mohler, B. J. (2014a).
Can I recognize my body’s weight? The inﬂuence of shape and texture on the perception of self. ACM
Transactions on Applied Perception 11, 13:1–13:18. doi:10.1145/2641568

Piryankova, I. V., Wong, H. Y., Linkenauger, S. A., Stinson, C., Longo, M. R., B¨ulthoff, H. H., et al.
(2014b). Owning an overweight or underweight body: Distinguishing the physical, experienced and
virtual body. PLOS ONE 9, e103428. doi:10.1371/journal.pone.0103428

[Accessed January 20, 2022]

R Core Team (2020). R: A language and environment for statistical computing. https://www.R-project.org

Preston, C. and Ehrsson, H. H. (2018). Implicit and explicit changes in body satisfaction evoked by
body size illusions: Implications for eating disorder vulnerability in women. PloS one 13, e0199426.
doi:https://doi.org/10.1371/journal.pone.0199426

Ratan, R., Beyea, D., Li, B. J., and Graciano, L. (2020). Avatar characteristics induce users’ behavioral
conformity with small-to-medium effect sizes: a meta-analysis of the proteus effect. Media Psychology
23, 651–675. doi:10.1080/15213269.2019.1623698

Pujades, S., Mohler, B., Thaler, A., Tesch, J., Mahmood, N., Hesse, N., et al. (2019). The virtual caliper:
Rapid creation of metrically accurate avatars from 3d measurements. IEEE Transactions on Visualization
and Computer Graphics 25, 1887–1897. doi:10.1109/TVCG.2019.2898748

Putze, S., Alexandrovsky, D., Putze, F., H¨offner, S., Smeddinck, J. D., and Malaka, R. (2020). Breaking the
experience: Effects of questionnaires in vr user studies. In Proceedings of the 2020 CHI Conference on
Human Factors in Computing Systems (New York, NY, USA: Association for Computing Machinery),
1–15

preprint

Riva, G., Guti´errez-Maldonado, J., Dakanalis, A., and Ferrer-Garc´ıa, M. (2019). Virtual reality
In Virtual reality for psychological
in the assessment and treatment of weight-related disorders.
and neurocognitive interventions (New York, NY: Springer New York). 163–193. doi:10.1007/
978-1-4939-9482-3 7

Robinette, K. M., Blackwell, S., Daanen, H., Boehmer, M., and Fleming, S. (2002). Civilian american
and european surface anthropometry resource (CEASAR), ﬁnal report. volume 1: Summary. Tech. rep.,
Sytronics Inc. doi:10.21236/ada406704

Rosen, J. C. (2001). Improving body image in obesity. In Body image, eating disorders, and obesity:
An integrative guide for assessment and treatment (American Psychological Association). 425–440.
doi:https://doi.org/10.1037/10502-017

Scarpina, F., Serino, S., Keizer, A., Chirico, A., Scacchi, M., Castelnuovo, G., et al. (2019). The effect of
a virtual-reality full-body illusion on body representation in obesity. Journal of Clinical Medicine 8.
doi:10.3390/jcm8091330

Riva, G. (1997). The Virtual Environment for Body-Image Modiﬁcation (VEBIM): Development and
Preliminary Evaluation. Presence: Teleoperators and Virtual Environments 6, 106–117. doi:10.1162/
pres.1997.6.1.106

Schubert, T., Friedmann, F., and Regenbrecht, H. (2001). The experience of presence: Factor analytic
insights. Presence: Teleoperators & Virtual Environments 10, 266–281. doi:https://doi.org/10.1162/
105474601300343603

Slater, M. (2009). Place illusion and plausibility can lead to realistic behaviour in immersive virtual
environments. Philosophical Transactions of the Royal Society B: Biological Sciences 364, 3549–3557.
doi:10.1098/rstb.2009.0138

Slater, M., P´erez Marcos, D., Ehrsson, H., and Sanchez-Vives, M. V. (2009). Inducing illusory ownership

of a virtual body. Frontiers in Neuroscience 3. doi:10.3389/neuro.01.029.2009

This is a provisional ﬁle, not the ﬁnal typeset article

30

GmbH)

Modiﬁcation 28, 783–811

Psychological assessment 25, 1286. doi:https://doi.org/10.1037/a0034044

Tanay, G. and Bernstein, A. (2013). State mindfulness scale (sms): development and initial validation.

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Slater, M., Spanlang, B., Sanchez-Vives, M. V., and Blanke, O. (2010). First person experience of body
transfer in virtual reality. PLOS ONE 5, e10564. doi:https://doi.org/10.1371/journal.pone.0010564
Sorkine, O. (2005). Laplacian Mesh Processing. In Eurographics 2005 - State of the Art Reports (The

Eurographics Association), 53–70. doi:10.2312/egst.20051044

Stanney, K. M., Kennedy, R. S., and Drexler, J. M. (1997). Cybersickness is not simulator sickness. In
Proceedings of the Human Factors and Ergonomics Society annual meeting (SAGE Publications Sage
CA: Los Angeles, CA), vol. 41, 1138–1142. doi:https://doi.org/10.1177/107118139704100292

Stefan, N., Birkenfeld, A. L., and Schulze, M. B. (2021). Global pandemics interconnected—obesity,

impaired metabolic health and covid-19. Nature Reviews Endocrinology 17, 135–149

Stewart, T. M. (2004). Light on body image treatment: Acceptance through mindfulness. Behavior

Tcha-Tokey, K., Loup-Escande, E., Christmann, O., and Richir, S. (2016). A questionnaire to measure
the user experience in immersive virtual environments. In Proceedings of the 2016 Virtual Reality
International Conference (New York, NY, USA: Association for Computing Machinery), VRIC ’16,
1–5. doi:10.1145/2927929.2927955

Thaler, A. (2019). The Role of Visual Cues in Body Size Estimation, vol. 56 (Berlin: Logos Verlag Berlin

preprint

Thaler, A., Geuss, M. N., M¨olbert, S. C., Giel, K. E., Streuber, S., Romero, J., et al. (2018a). Body
size estimation of self and others in females varying in bmi. PLOS ONE 13, e0192152. doi:https:
//doi.org/10.1371/journal.pone.0192152

Thaler, A., Piryankova, I. V., Stefanucci, J. K., Pujades, S., de la Rosa, S., Streuber, S., et al. (2018b).
Visual perception and evaluation of photo-realistic self-avatars from 3D body scans in males and females.
Frontiers in ICT 5, 18. doi:https://doi.org/10.3389/ﬁct.2018.00018

Thompson, J. K. and Tantleff-Dunn, S. (1998). MINI-REVIEW Assessment of Body Image Disturbance in

Obesity. Obesity Research 6, 375–377. doi:10.1002/j.1550-8528.1998.tb00366.x

Tsakiris, M., Jim´enez, A. T., and Costantini, M. (2011). Just a heartbeat away from one’s body: interoceptive
sensitivity predicts malleability of body-representations. Proceedings of the Royal Society B: Biological
Sciences 278, 2470–2476

Turbyne, C., Goedhart, A., de Koning, P., Schirmbeck, F., and Denys, D. (2021). Systematic review
and meta-analysis of virtual reality in mental healthcare: Effects of full body illusions on body image
disturbance. Frontiers in Virtual Reality 2, 39. doi:10.3389/frvir.2021.657638
Unity Technologies (2019). Unity. https://unity3d.com [Accessed January 20, 2022]
Valtolina, G. G. (1998). Body-size estimation by obese subjects. Perceptual and Motor Skills 86,

1363–1374. doi:https://doi.org/10.2466/pms.1998.86.3c.1363

Valve Corporation (2020a). Index. https://store.steampowered.com/valveindex [Accessed January 20,

2022]

Valve Corporation (2020b). SteamVR. https://store.steampowered.com/steamvr [Accessed January 20,

2022]

31

Todd, J., Aspell, J. E., Barron, D., and Swami, V. (2019a). An exploration of the associations between

facets of interoceptive awareness and body image in adolescents. Body image 31, 171–180

Todd, J., Aspell, J. E., Barron, D., and Swami, V. (2019b). Multiple dimensions of interoceptive awareness

are associated with facets of body image in british adults. Body Image 29, 6–16

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

Venegas, O. and Mehrzad, R. (2020). Chapter 3 - prevalence and trends in obesity in the united states
In Obesity, ed. R. Mehrzad (Elsevier). 19–41. doi:https://doi.org/10.1016/

and afﬂuent countries.
B978-0-12-818839-2.00003-X

Walker, D. C., White, E. K., and Srinivasan, V. J. (2018). A meta-analysis of the relationships between body
checking, body image avoidance, body image dissatisfaction, mood, and disordered eating. International
Journal of Eating Disorders 51, 745–770

Wienrich, C., D¨ollinger, N., and Hein, R. (2021). Behavioral framework of immersive technologies
(behaveﬁt): How and why virtual reality can support behavioral change processes. Frontiers in Virtual
Reality 2, 84. doi:10.3389/frvir.2021.627194

Waltemate, T., Gall, D., Roth, D., Botsch, M., and Latoschik, M. E. (2018). The impact of avatar
personalization and immersion on virtual body ownership, presence, and emotional response. IEEE
Transactions on Visualization and Computer Graphics 24, 1643–1652. doi:10.1109/TVCG.2018.
2794629

Waltemate, T., Senna, I., H¨ulsmann, F., Rohde, M., Kopp, S., Ernst, M., et al. (2016). The impact of
latency on perceptual judgments and motor performance in closed-loop interaction in virtual reality. In
Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology (New York, NY,
USA: Association for Computing Machinery), VRST ’16, 27–35. doi:10.1145/2993369.2993381

Wenninger, S., Achenbach, J., Bartl, A., Latoschik, M. E., and Botsch, M. (2020). Realistic virtual
humans from smartphone videos. In 26th ACM Symposium on Virtual Reality Software and Technology
(New York, NY, USA: Association for Computing Machinery), VRST ’20, 1–11. doi:10.1145/3385956.
3418940

Wiederhold, B. K., Riva, G., and Guti´errez-Maldonado, J. (2016). Virtual reality in the assessment and
treatment of weight-related disorders. Cyberpsychology, Behavior, and Social Networking 19, 67–73.
doi:10.1089/cyber.2016.0012

preprint

Williams, A. S., Garcia, J., and Ortega, F. (2020). Understanding multimodal user gesture and speech
IEEE Transactions on

behavior for object manipulation in augmented reality using elicitation.
Visualization and Computer Graphics 26, 3479–3489. doi:10.1109/TVCG.2020.3023566

Wolf, E., D¨ollinger, N., Mal, D., Wienrich, C., Botsch, M., and Latoschik, M. E. (2020). Body
weight perception of females using photorealistic avatars in virtual and augmented reality. In 2020
IEEE International Symposium on Mixed and Augmented Reality (ISMAR). 583–594. doi:10.1109/
ISMAR50242.2020.00071

Wolf, E., Fiedler, M. L., D¨ollinger, N., Wienrich, C., and Latoschik, M. E. (2022). Exploring presence,
avatar embodiment, and body perception with a holographic augmented reality mirror. In Proceedings of
the 29th IEEE Virtual Reality Conference (VR ’22). 1–10

Wolf, E., Kl¨uber, S., Zimmerer, C., Lugrin, J.-L., and Latoschik, M. E. (2019). ”Paint that object yellow”:
Multimodal interaction to enhance creativity during design tasks in vr. In 2019 International Conference
on Multimodal Interaction (New York, NY, USA: Association for Computing Machinery), ICMI ’19,
195–204. doi:10.1145/3340555.3353724

Wienrich, C. and Gramlich, J. (2020). Appraisevr–an evaluation framework for immersive experiences.

i-com 19, 103–121. doi:https://doi.org/10.1515/icom-2020-0008

Wolf, E., Merdan, N., D¨ollinger, N., Mal, D., Wienrich, C., Botsch, M., et al. (2021). The embodiment of
photorealistic avatars inﬂuences female body weight perception in virtual reality. In 2021 IEEE Virtual
Reality and 3D User Interfaces (VR). 65–74. doi:10.1109/VR50410.2021.00027

World Health Organization (2000). Obesity: Preventing and managing the global epidemic: Report of a

WHO consultation. No. 894 in WHO technical report series (World Health Organization)

This is a provisional ﬁle, not the ﬁnal typeset article

32

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

World Health Organization (2019). International statistical classiﬁcation of diseases and related health

problems (11th ed.) (World Health Organization)

World Health Organization (2021). Obesity and overweight. https://www.who.int/news-room/fact-

sheets/detail/obesity-and-overweight [Accessed January 20, 2022]

Wu, H., Luo, W., Pan, N., Nan, S., Deng, Y., Fu, S., et al. (2019). Understanding freehand gestures: a study
of freehand gestural interaction for immersive vr shopping applications. Human-centric Computing and
Information Sciences 9, 1–26

Yee, N. and Bailenson, J. (2007). The Proteus Effect: The Effect of Transformed Self-Representation
on Behavior. Human Communication Research 33, 271–290. doi:10.1111/j.1468-2958.2007.00299.x.
Publisher: Oxford Academic

Yumuk, V., Tsigos, C., Fried, M., Schindler, K., Busetto, L., Micic, D., et al. (2015). European guidelines
for obesity management in adults. Obesity Facts 8, 402–424. doi:https://doi.org/10.1159/000442721
Zanetti, T., Santonastaso, P., Sgaravatti, E., Degortes, D., and Favaro, A. (2013). Clinical and temperamental
correlates of body image disturbance in eating disorders. European Eating Disorders Review 21, 32–37
Zijlstra, F. R. H. (1993). Efﬁciency in work behaviour: A design approach for modern tools. Ph.D. thesis,

Delft University

Zimmerer, C., Wolf, E., Wolf, S., Fischbach, M., Lugrin, J.-L., and Latoschik, M. E. (2020). Finally
on par?! Multimodal and unimodal interaction for open creative design tasks in virtual reality.
In
Proceedings of the 2020 International Conference on Multimodal Interaction (New York, NY, USA:
Association for Computing Machinery), ICMI ’20, 222–231. doi:10.1145/3382507.3418850

Ziser, K., M¨olbert, S. C., Stuber, F., Giel, K. E., Zipfel, S., and Junne, F. (2018). Effectiveness of body
image directed interventions in patients with anorexia nervosa: A systematic review. International
Journal of Eating Disorders 51, 1121–1127. doi:https://doi.org/10.1002/eat.22946

preprint

33

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

1 EVALUATION INTERVIEW QUESTIONS

1.1 Body Scan Experience

Questions about the body scan:

1. What expectations did you have before the participation about how a body scan would be?

2. Was it clear at any point during the body scan what you had to do?

a. If not: At what point were there ambiguities and how did they arise?

5. If you could change something about the scanning process, what would it be?

6. Did the gender of the experimenter affect how comfortable/uncomfortable you felt during the scan?

7. Would you have felt differently about the scanning process if you had known the experimenter better?

3. How did you feel about the scanning process?

a. What was the reason for it?

b. Were those feelings more pleasant or unpleasant?

4. Would you decide to get your body scanned again?

a. If not: What is the reasoning behind it?

Questions about the body measurements:

1. How did you feel about the body measurements being taken?

a. What was the reason for it?

b. Were those feelings more pleasant or unpleasant?

preprint

Questions about the interaction with the embodied virtual human (avatar):

1. How did you feel about the interaction with your personal avatar?

a. What was the reason for it?

b. Were those feelings more pleasant or unpleasant?

measurements?

Questions about the body scan and body measurements:

measurement process?

1.2 VR Exposure Experience

2. If you could change something about the body measurement process, what would it be?

3. Did the gender of the experimenter affect how comfortable/uncomfortable you felt during the body

1. What could the experimenter have done to make you feel more comfortable during the scanning and

2. Did the appearance of your avatar meet your expectations?

a. If not: What would you have expected differently?

b. If not: Was the deviation from your expectation positive or negative?

3. Did you ﬁnd it rather easy or rather difﬁcult to estimate the weight of your avatar when it changed

without your action?
a. If difﬁcult: What was the reason for it?

4. Did you ﬁnd it rather easy or rather difﬁcult to adjust your avatar to the given weight?

This is a provisional ﬁle, not the ﬁnal typeset article

34

4. Did the interaction with your in body weight changed avatar cause you to perceive or see your own

D ¨ollinger and Wolf, et al.

Resize Me! Embodying Realistically Modulatable Avatars in VR

a. If difﬁcult: What was the reason for it?

5. Is there one method of interaction that you would prefer over the others?

a. What was the reason for it?

6. If you could make something about the interaction with your avatar different, what would it be?

Questions about the (physical) experience:

1. How did it feel for you when the appearance of your personal avatar changed?

a. Did it feel different when you actively changed the appearance of your personal avatar?

2. Were you aware of your physical body while being embodied to your virtual avatar?

a. If yes: Were there moments when you paid particular attention to your physical body?

3. Do you had the feeling that interacting with your avatar had an impact on how you felt in your physical

body more consciously?
a. If yes: How would it look like?

Questions for the instruction of the tasks:

body?
a. If yes: In what ways did you feel changed?

body differently?
a. If yes: What has changed?

preprint

for the verbal instructions?
a. If yes: Was it rather pleasant or rather unpleasant?
b. Where in the virtual environment did you locate the instruction?

1. What were your expectations about how you would receive instruction within the virtual environment?

2. How did you feel that the instructions for the tasks were given verbally and in text form?

a. What was the reason for it?

3. Did you notice that there was no visual representation in the form of a speaker or something similar

b. Do you take any direct consequences from this experience?

5. Could you imagine an interaction in which the virtual avatar supports you in experiencing your physical

4. If you imagine a visual representation of the instructing voice, how would it look like?

5. Can you imagine sharing the virtual environment with another person while changing the appearance

of your virtual avatar?

Questions about the overall process:

1. If you had the choice - what would you change about the overall process?

a. Did you notice anything else?

35

