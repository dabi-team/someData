8
1
0
2

p
e
S
8
2

]

R
G
.
s
c
[

1
v
8
2
0
0
0
.
0
1
8
1
:
v
i
X
r
a

Data-Driven Modeling of Group Entitativity in Virtual
Environments

Aniket Bera
University of North Carolina
Chapel Hill, NC, USA
ab@cs.unc.edu

Husam Shaik
University of North Carolina
Chapel Hill, NC, USA
hshaik@live.unc.edu

Tanmay Randhavane
University of North Carolina
Chapel Hill, NC, USA
tanmay@cs.unc.edu

Kurt Gray
University of North Carolina
Chapel Hill, NC, USA
kurtgray@unc.edu

Emily Kubin
Tilburg University
North Brabant, Netherlands
e.r.kubin@tilburguniversity.edu

Dinesh Manocha
University of Maryland
College Park, MD, USA
dm@cs.umd.edu

Figure 1: Interactive Crowd Simulation: Our adaptive data-driven group emotion algorithm is based on a statistical scheme that
dynamically learns pedestrian behavior. Our method can generate realistic trajectory-level pedestrian behaviors with varying
perceptual entitativity features like friendliness, creepiness, comfort, and unnervingness. We can simulate a large number of
agent groups at interactive rates.

ABSTRACT
We present a data-driven algorithm to model and predict the socio-
emotional impact of groups on observers. Psychological research
finds that highly entitative i.e. cohesive and uniform groups in-
duce threat and unease in observers. Our algorithm models realistic
trajectory-level behaviors to classify and map the motion-based
entitativity of crowds. This mapping is based on a statistical scheme
that dynamically learns pedestrian behavior and computes the re-
sultant entitativity induced emotion through group motion charac-
teristics. We also present a novel interactive multi-agent simulation
algorithm to model entitative groups and conduct a VR user study
to validate the socio-emotional predictive power of our algorithm.
We further show that model-generated high-entitativity groups do
induce more negative emotions than low-entitative groups.

1 INTRODUCTION
Understanding and modeling group behavior is an important prob-
lem in many domains including virtual reality, robotics, pedestrian
dynamics, psychology, and behavior learning. Some of the driv-
ing applications include investigation of pathological processes in
mental disorders [1], virtual reality therapy for crowd phobias [2],

training of law enforcement officials or military personnel [3], un-
derstanding crowd flow analysis in urban layouts, etc. In these
applications, one of the goals is to generate realistic group move-
ments or emerging behaviors in the background, while the user is
immersed in the scene and performing certain tasks. The realism of
group movement and the ability to interact with the virtual crowds
enhances the presence in the virtual environment and steering
strategies [4].

In a group of walking individuals, a critical issue is understanding
how the individual motion trajectories combine into “group-level”
features. Understanding such features is essential because collective
and macroscopic motion of groups has the potential to induce a
variety of emotional reactions in the user. In a multi-agent envi-
ronment, some agents may appear friendly whereas some other
may appear threatening. These feelings can arise from a variety of
sources but frequently stem from how entitative a group seems to
be.

Entitativity, Emotions, and Reactions. In this paper, we explore
the importance of entitativity, which is a measure of how “group-
like” (i.e., how cohesive, uniform, and similar) a collection of agents
seems to be (Figure 3). Entitativity consists of perceptions of similar-
ity, cohesiveness, and uniformity. For example, a military platoon

 
 
 
 
 
 
VRST ’18, November 28-December 1, 2018, Tokyo, Japan

Bera et al.

Figure 2: Overview: We highlight the various components of our group emotion-induced entitativity algorithm. We start with
a large-scale virtual crowd dataset (generated using a crowd simulation model) and perform a user-perception study to reveal
the entitativity level of each group in every video. We present a novel approach to compute the data-driven mapping between
entitativity perceptions/features (four inter-related and previously-validated measures of negative socio-affective judgments:
friendliness, creepiness, comfort, and unnervingness) and the motion model parameters which were used to generate the virtual
datasets. We then use this data-driven mapping for two use cases: to compute the entitativity in real videos and to simulate
human-like characters with varying entitativity.

with matching uniforms and haircuts is highly entitative, whereas
people waiting at a government office are much less entitative.

quickly tie these entitativity assessments to the resultant negative
socio-emotional experiences in users.

In addition to the similarity of appearance, one important aspect
of entitativity is the similarity of movement. When people move
together in a cohesive group (with the same trajectory and with
proximity) people judge them to be highly “group-like”. In this
paper, we restrict ourselves to only the trajectory-level movement
features of the pedestrian groups.

Research in social psychology reveals the importance of group-
level characteristics and their impact on others. Since humans are
a social species consisting of complex social groups, people are
highly sensitive to the characteristics and dynamics of groups [5].
In particular, humans are very attuned to the entitativity of groups
because large collections of like-minded people can pose a coordi-
nated threat to others (e.g., gangs, armies; [6]). Given the potential
threat of coordinated groups, when people observe highly entita-
tive groups, having similar appearance and/or motion trajectories,
negative emotions are generated. More specifically highly enti-
tative groups have been shown to generate unease and negative
socio-emotional appraisals including perceptions/experiences of
unfriendliness, creepiness, unnervingness, and discomfort [7, 8].
Therefore, for VR applications including social VR, in order to pre-
dict emotions induced by groups of virtual agents, it is necessary
to automatically assess how entitative a group appears to be and

Main Results: In this paper, we present a novel data-driven al-
gorithm for modeling and automatically classifying the entitativity
of a group of pedestrians (Figure 2). Our formulation is based on
using the results of an elaborate web-based user study on a large
virtual crowd dataset to establish a mapping between trajectory
characteristics and their entitativity induced emotions (i.e., socio-
emotional appraisals). Consistent with predictions (and past social
psychological work) people report being made more unnerved
and uncomfortable by those collections of agents classified by the
algorithm as highly entitative. We map the various features of en-
titativity (operationalized as friendliness, creepiness, unnerving,
and comfort) with the motion model parameters that were used to
generate the virtual crowd dataset.

We present two use-cases for our method of being able to

a) classify the entitativity of groups in real videos and,
b) generate characters in a VR environment to simulate varying
degrees of entitativity.

For the first case, we extract the trajectory of each pedestrian in
a video using Bayesian learning at an interactive rate. We cluster
the pedestrians in a group and learn various group trajectory-level
characteristics. We combine these characteristics to yield an overall
entitativity measure based on our mapping, which we tie to nega-
tive socio-emotional appraisals. For the second case, we generate

Data-Driven Modeling of Group Entitativity in Virtual Environments

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

we evaluate our algorithm on real videos.In Section 6, we evaluate
our simulation algorithm in a VR scene using an HMD.

2 RELATED WORK
In this section, we give a brief overview of prior work on psy-
chological perspectives on group dynamics, behavior modeling of
pedestrians, and work related to background of crowd analysis.

2.1 Psychological Perspectives on Group

Dynamics

Human beings are inherently social creatures [9], which evolved to
rapidly process and form judgments about collections of people [10].
Many argue the complex social structure and group dynamics of
humanity are the key to our ability to be a successful species [11].
Not only do groups help humans survive by providing benefits that
come from collective coordination but they can also represent a
definite threat, as groups can make even mild-mannered individuals
perpetrate harm upon others [12].

Because of the social importance of groups, people have evolved
to be extremely adept at detecting information about groups in
visual scenes [13] and rapidly process the social elements that
make up groups, such as cohesion and motion. For example, both
classic [14] and modern [15] studies find that people automatically
see social features in the movement of basic shapes, and people can
infer relatively rich social information in groups of people even
from a large distance [16]. Our algorithm is inspired by these classic
studies on the rich social context of trajectory motion.

2.2 Behavior Modeling of Pedestrians
There is considerable literature in psychology, robotics, and au-
tonomous driving on modeling the behavior of pedestrians. Many
rule-based methods have been proposed to model complex behav-
iors based on motor, perceptual, behavioral, and cognitive com-
ponents [17]. There is extensive literature on modeling emergent
behaviors, starting from Reynolds work [18]. Yeh et al. [19] describe
velocity-based methods to model different behaviors including ag-
gression, social priority, authority, protection, and guidance. Other
techniques have been proposed to model heterogeneous crowd
behaviors based on personality traits [20–22]. Different techniques
have been proposed to model collision avoidance behaviors [23, 24]
and effect of appearance on perception of virtual characters [25, 26].
Our approach is compatible to most of these works and can also
predict the entitativity induced emotions of groups of characters
created by these methods.

2.3 Pedestrian and Crowd Analysis from

Videos

There is extensive work in computer vision and AI literature that
analyzes the behaviors and movement patterns of pedestrians in
crowd videos [27]. The main objectives of these works include
human behavior understanding and crowd activity recognition for
detecting abnormal behaviors or for surveillance applications [28].
Many of these methods use a large number of training videos for
offline learning [29]. Other methods utilize motion models to learn
crowd behaviors [30].

Figure 3: Entitativity Classification: Our novel algorithm
can automatically classify the emotion-induction potential
of pedestrian group motion based upon entitativity. Top:
We extract individual pedestrian trajectories from video in-
put, combine these trajectories to cluster individuals into
groups. Bottom: Our model then calculates the group’s enti-
tativity and its emotion induction potential (operationalized
as friendliness, creepiness, unnerving, and comfort).

various virtual reality scenes with virtual agents with varying enti-
tativity. These scenes induce variations of friendliness, creepiness,
and comfort in the users.

Finally, we validate the algorithm by performing additional user
studies for both the use-cases. The studies reveal that the entitativity
algorithm accurately predicts negative socio-emotional appraisals
of users.

Overall, our approach has the following benefits:

1. Social Prediction: Our approach accurately predicts and models
important socio-emotional reactions towards other social agents.
2. Robust computation: Our approach is robust and can account
for noise in the pedestrian trajectories.
3. Generalizability: Our approach is agnostic to the underlying
crowd simulation model.

The rest of the paper is organized as follows. In Section 2, we
review the related work in the field of social psychology and be-
havior modeling. In Section 3, we give background on quantifying
entitativity and introduce our notation. We also present our interac-
tive algorithm, which computes the perceived group entitativity. In
Section 4, we describe our user study on the perception of multiple
virtual characters with varying degrees of entitativity. In Section 5,

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

Bera et al.

2.4 Group Dynamics and Socio-Emotional

Reaction

Decades of psychological research reveals that people interact more
negatively with groups than with individuals [31, 32], acting with
more hostility towards a group of people rather than a single in-
dividual [33], due to a greater sense of fear [34]. At the heart of
anti-social actions are negative socio-emotional reactions, which
can be directed at any social agent, whether human, robot [35], or
virtual agent [36]. These negative socio-emotional reactions involve
appraisals of unease [37], threat [35], fear [38] and overall aversive
experiences [39].

3 NOTATION AND OVERVIEW
In this section, we first define entitativity formally. Then, we intro-
duce the notation and present an overview of the approach.

3.1 Entitativity
Entitativity is the perception how much a set of individuals is seen
as a single entity (i.e., a group). Perceptions of group entitativity
are increased by perceived psychological similarity, such as when
people belong to the same racial groups [40] or ideologies [41],
and pursuing the same goal [42]. Perceptions of group entitativity
are also increased by perceived physical similarity, defined as the
following three elements:

1. Appearance uniformity: Highly entitative groups have mem-

bers that look the same.

2. Common movement: Highly entitative groups have mem-

bers that move similarly.

3. Proximity: Highly entitative groups have members that are

very close to each other.

In this paper, we present an automated algorithm that examines
the idea of common movement. When people move together as a
single unit, it leads to perceptions of entitativity which then induces
unease which can in turn lead to aggression and harm. While it is
non-trivial to extract or capture the collective pedestrian motion
from a video, our approach is based on formulating an entitativity
metric from individual trajectories of pedestrians computed using
Bayesian learning.

3.2 Notation and Terminology
Here, we introduce the notation used in the rest of the paper. We
refer to an agent in the crowd as a pedestrian. The trajectory and
behavior characteristics of each pedestrian are called its state. These
behavior characteristics control how the pedestrian moves on the
2D ground plane. We refer the pedestrian’s state by the symbol
x ∈ R6: x = [p vc vpr ef ]T, where p is the pedestrian’s position,
vc is its current velocity, and vpr ef
is the preferred velocity on
a 2D plane. The preferred velocity is the optimal velocity that
a pedestrian would take to achieve its intermediate goal in the
absence of other pedestrians or obstacles in the scene. In practice,
where other pedestrians and obstacles are present, vpr ef tends
to be different from vc for a given pedestrian. The states of all
the other pedestrians and the current positions of the obstacles
in the scene are collectively represented by the symbol S. We call
this the current state of the environment. We refer to the union of
the set of each pedestrian’s state as the state of the crowd, which

consists of individual pedestrians. We represent this as X = (cid:208)
i xi,
where subscript i denotes the ith pedestrian. In real-world crowds,
pedestrians often walk as a part of a group, and we represent a
group of pedestrians by G = (cid:208)
j xj where subscript j denotes the
jth pedestrian in the group.

Our state formulation does not include any full body or ges-
ture information. Moreover, we do not explicitly model or capture
pairwise interactions between pedestrians. However, the difference
between vpr ef and vc provides partial information about the local
interactions between a pedestrian and the rest of the environment.
P ∈ R6 denotes the set of parameters for the motion model.
The motion model corresponds to the local navigation rule or
scheme that each pedestrian uses to avoid collisions with other
pedestrians or obstacles and has a group strategy. Our formulation
is based on the RVO velocity-based motion model [43]. In this model,
the motion of each pedestrian is governed by these five individ-
ual pedestrian characteristics: Neighbor Dist, Maximum Neighbors,
Planning Horizon, (Radius) Personal Space, and Preferred Speed and
one group characteristic: Group Cohesion. We combine RVO with a
group navigation scheme in Section 4.4. In our approach, we mainly
analyze four parameters (GP ∈ R4): Neighbor Dist, (Radius) Personal
Space, Group Cohesion, and Preferred Speed.

Assessing Negative Socio-Emotional Reactions: Prior
research in social psychology reveals that entitative groups induce
negative socio-emotional reactions which can license aggression.
We therefore use an index of four items to assesses negative socio-
emotional reactions and provide a criterion for our entitativity-
induced negative emotions algorithm:

E =

Friendliness
Creepiness
Com f ort
U nnervinд

(cid:169)
(cid:173)
(cid:173)
(cid:173)
(cid:171)

(cid:170)
(cid:174)
(cid:174)
(cid:174)
(cid:172)

(1)

Item and Index Justification: Each of these items has been
used before in social psychological research in intergroup research
to assess negative socio-emotional reactions. Moreover, the high
Cronbach’s α (a test of statistical reliability) in pilot studies (α =
0.794) justifies their combination into a single negative socio-emotional
vector.

3.3 Overview
In this section, we present an overview (Figure 2) of our interactive
algorithm, which computes the group entitativity model and then
simulates virtual agents in real-time.

For each pedestrian in the crowd, the function G : R × R6 × S →
R2 maps time t, the current state of the pedestrian x ∈ X, and the
current state of the environment S ∈ S to a preferred velocity vpr e f .
Function I : R6 × S → R2 represents the group RVO motion model
that is used to compute the current velocity vc for collision-free
interactions with other pedestrians and obstacles. The function
P : R2 → R2 computes the position given vc and E : R → R2
computes the initial position for time t0 which is the time at which
a particular pedestrian enters the environment.

Each pedestrian uses a local navigation scheme to avoid collisions
with other pedestrians and obstacles. In addition to following their
individual rules or navigation schemes, pedestrians also navigate
as part of a group. We represent these individual as well as group

Data-Driven Modeling of Group Entitativity in Virtual Environments

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

Figure 4: Varying Entitativity - Our user study consisted of three cases for each parameter: (1) high entitativity when there is
little to no variation in pedestrian speed and all pedestrian trajectories are somewhat similar/parallel, (2) medium entitativity
when there is moderate variation in pedestrian speed and the trajectory directions deviate from each other, (3) low entitativity
when there is large variation in pedestrian speed and all pedestrians travel in vastly different directions. The width of the blue
arrow denotes the speed (the wider the arrow, the higher the speed) and the direction represents the path taken.

navigation rules by a group motion model. Our formulation is
based on a velocity-based motion model which also takes into
account proxemic group behaviors [44]. In this model, the motion
of pedestrians is governed by four characteristics/parameters (GP).
Entitativity Feature Computation: Once we compute the pedes-
trian cluster, we make use of a data-driven mapping to compute the
collective perceived entitativity-induced emotions E of the group
from the group motion model parameters GP. The derivation and
details of this mapping are given in Section 4.

4 DATA-DRIVEN ENTITATIVITY MODEL
To evaluate the impact of the various parameters of the group
motion model on the perception of entitativity of a group of pedes-
trians, we performed a user study using simulated trajectories. We
provide the details of this user study in this section.

4.1 Study Goals and Design
This study aimed to understand how the perception of multiple
pedestrians is affected by the parameters of the group motion model.
We use the results of this user study to compute a data-driven
statistical mapping between the group motion model parameters
and the perception of groups in terms of friendliness, creepiness,
and social comfort. We recruited 212 participants (105 male, 107
female, ¯xaдe = 36, saдe = 11.72) electronically and also from Amazon
MTurk. Here, we provide details of the design of our experiment.

4.2 Procedure
We performed a web-based study in which the participants were
asked to watch pairs of simulated videos of pedestrians and compare
the entitativity features (Figure 5). Each video contained 3 simulated
agents with various settings of the group motion model parameters.
We consider variations in four group motion models parameters
(GP): Neighbor Dist, Radius, Pref Speed, and Group Cohesion. We
present the default values for simulation parameters used in our
experiments in Table 1. In each pair, one of the videos corresponds
to the default values of the parameters (called the Reference video).
We generated the other video (called the Question video) by varying

Figure 5: Varying Levels of Entitativity: Parameters of the
group motion model affected the entitativity of multiple
simulated agents. Agents having the same speed and simi-
lar trajectories were perceived to be highly entitative (top)
whereas agents walking at different speeds and varying tra-
jectories were perceived as less entitative (bottom).

one parameter to either the minimum or the maximum value. Thus
a total of 8 pairs of videos were generated corresponding to the
minimum and the maximum value for each motion model parameter.
Out of the 8 videos, each participant watched a random subset of 4
pairs of videos. The participants watched the video pairs side by
side in randomized order. They could watch the videos multiple
times if they wished and compared the entitativity features of the
pedestrian groups in the two videos. We collected the demographic
information about participants’ gender and age at the end of the
study.

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

Bera et al.

4.3 Questions
For each trial, the participant compared the two videos (Refer-
ence and Question) on a 6-point scale from Strongly Disagree (1) -
Strongly Agree (6). The following items were adapted [45] to assess
creepiness and social comfort experienced:

As compared to the Reference video, in the Question video ...

• Did the characters seem more friendly?
• Did the characters seem more creepy?
• Did you feel more comfortable with the characters?
• Did you feel more unnerved by the characters?

These questions were motivated by previous studies [31]. We de-
fine an entitativity feature corresponding to each question. Thus,
we represent the entitativity features of a group as a 4-D vector:
Friendliness, Creepiness, Comfort, Unnerving (Ability to Unnerve).

4.4 Analysis
We average the participant responses to each video pair to obtain
8 entitativity feature data points (Ei , i = 1, 2, ..., 8}). The range of
entitativity features in these data points is presented in Table 2. We
also present the standard deviation of the features.

Table 3 provides the correlation coefficients between the features
for all the participant responses. The high correlation between the
features indicates that the features measure different aspects of
socio-emotional reactions to entitativity. As expected, creepiness
and unnerving are inversely correlated with friendliness and comfort.
Principal Component Analysis of the four socio-emotional features
also reveals that a single principal component is enough to explain
over 98% of the variance in the participants’ responses. We use
this component to combine the four entitativity features into an
entitativity label ei ∈ R:

ei = −0.31 ∗ EF r iendliness
i

+ 0.66 ∗ ECr eepiness
i
+ 0.51 ∗ EU nnervinд
i

− 0.46 ∗ EComf or t
i

(2)

Parameters (GP)
Neighbor Distance (m)
Radius (Personal Space) (m)
Preferred speed (m/s)
Group Cohesion

min max default
3
0.8
1.2
0.1

4
1.0
1.5
0.5

5
1.7
1.8
1.0

Table 1: Default values for simulation parameters used in
our experiments

Friendliness
Creepiness
Comfort
Unnerving

Min Max
3.636
2.664
4.452
2.654
3.810
2.617
4.343
2.882
Table 2: Range of the Entitativity Features: For low and high
values of motion model parameters (keeping the other pa-
rameters at default value) we obtain the above range of en-
titativity features.

STD
0.392
0.797
0.557
0.631

Friendliness Creepiness Comfort Unnerving

Friendliness
Creepiness
Comfort
Unnerving

1
-0.963
0.973
-0.944

-0.963
1
-0.990
0.977

0.973
-0.990
1
-0.969

-0.944
0.977
-0.969
1

Table 3: Correlation Between Questions: We provide the cor-
relation coefficients between the questions. The high cor-
relation between the questions indicates that the questions
measure different aspects of a single perception feature, en-
titativity.

We normalize the responses and obtain entitativity values (ei , i =
1, 2, ..., 8}) for each variation of the motion model parameters (GPi , i =
1, 2, ..., 8}), we can fit a linear model to the entitativity and the model
parameters. We refer to this model as the Data-Driven Entitativity
Model. For each video pair i in the gait dataset, we have a vector
of parameter values GPi and an entitativity value ei . Given these
parameters and features, we compute the entitativity mapping of
the form:

e = a0 + a1 ∗ N eiдhbor Dist + a2 ∗ Radius

+ a3 ∗ Pre f . Speed + a4 ∗ Group Cohesion

(3)
We obtain the coefficient vector A = {a0, a1, a2, a3, a4} using lin-
ear regression with entitativity values as the responses and the
parameter values as the predictors using the normal distribution
(R2 = 0.942, F (1, 3) = 29.6, p < 0.01):

A = [0.60 − 0.42 − 0.58

0.75

0.73]

(4)

We can make many inferences from the values of A. The negative
values of a0 and a1 indicate that as the values of neighbor distance
and radius increases, the entitativity of the group decreases. That
is, groups with larger interpersonal distances appear less entitative.
This validates the psychological findings in the previous literature.
Entitativity increases with walking speed and group cohesion. This
indicates that faster-walking groups of agents appear discomforting
and less friendly.

We can use our data-driven entitativity model to predict per-
ceived entitativity of any group for any new input video. Given the
motion parameter values GP for the group, the perceived entitativ-
ity e can be obtained as: e = A ∗ GP.

In addition to computing entitativity from the motion parame-
ters, we can also predict individual features of entitativity as well.
We perform multiple linear regression and obtain the following
equation:

0.32
0.33
0.20
0.56 −0.45 −0.51
0.34
0.36
0.28
0.57 −0.29 −0.52

−0.23 −0.42
0.69
0.73
−0.49 −0.59
0.47
0.68

E =



















1


N eiдhbor Dist


Radius


Pre f Speed


Group Cohesion














(5)

Given the motion model parameters GP, we can compute any of
the features of entitativity (E = [Friendliness, Creepiness, Comfort,
Unnerving]) using Equation 5. R2 and F-statistic values in Table 4
indicate that our linear model fits the data well.

Data-Driven Modeling of Group Entitativity in Virtual Environments

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

R2
0.980
0.916
0.933
0.952
Table 4: R2 and F-statistic values which indicate that our
model fits the data well.

Friendliness
Creepiness
Comfortable
Unnerving

p
0.002
0.017
0.012
0.007

F
85.0
20.1
25.2
35.8

5 VALIDATION ON REAL DATA
We validated our algorithm on videos of pedestrians walking in
the real world. We performed a user study to obtain the values of
perceived entitativity for our validation videos. We computed the
error between the user reported entitativity values and the values
computed using our Data-Driven Entitativity Model. We describe
the details of the user study below. We also applied our novel
algorithms to the 2D pedestrian trajectories generated and extracted
from different publicly available crowd videos and calculated the
performance.
Pedestrian Tracking: Our method takes a crowd video as an input
and we extract the initial set of pedestrian trajectories using an
online pedestrian tracker. We learn the pedestrian group motion
model parameters using statistical methods [46, 47]. We use the
Bayesian-inference technique to compensate for any errors and to
compute the state of each pedestrian. We use an Ensemble Kalman
Filter (EnKF) and Expectation Maximization (EM) to estimate the
most likely state x of each pedestrian. Our approach extends the
method presented in [48].

5.1 Study Goals
This study aimed to obtain the perceived entitativity values for
videos of pedestrians walking in the real world. We recruited 46
participants (29 male, 17 female, ¯xaдe = 32.52, saдe = 10.34) elec-
tronically and also from Amazon MTurk. Participants watched the
videos in the dataset and answered some questions. We presented
the videos in randomized order to the participants, and they could
watch each video as many times as they wanted. After answering
the questions for all the videos, participants provided demographic
information. We asked questions which are similar to Section 4.1
and were adapted [45] to assess creepiness and social comfort ex-
perienced.

5.2 Dataset
We captured eight videos of pedestrians walking in the real world.
In each of these videos (~10 seconds), three pedestrians were walk-
ing on a university campus (Figure 6). We used the videos which
contained the same set of pedestrians to account for differences in
appearance and body shapes.

5.3 Results and Analysis
Using the participant responses, we calculated entitativity values
using a method similar to Section 4.4. We averaged the participant
responses and combined the four entitativity features using the
obtained PCA coefficients. We obtained the entitativity values ei ∈
R for each video i using Equation 2.

i

i

i

i

, EComf or t

, ECr eepiness

, EU nnervinд

Here, EF r iendl iness

are
the average participant responses to the four questions. We nor-
malized these entitativity values eдr ound
which we treat as ground
i
truth for error computation. For each video, we also computed the
pedestrian parameters GP. Given GP, we used e (Section 4.2) to
compute the predicted entitativity value epr ed
for each video i. We
define the error (eдr ound
) between the ground truth eдr ound
, epr ed
i
and predicted entitativity epr ed
as:

i

i

i

i

error (eдr ound
i

, epr ed
i

) =

|eдr ound
i

− epr ed
i
emax − emin

|

(6)

where emax and emin are the maximum and minimum attainable
entitativity values. For our dataset, we observe an average error of
5.91% which indicates that the perceived entitativity of groups of
real pedestrians by participants matches the predicted entitativity
by our algorithm.

6 VALIDATION IN A VR ENVIRONMENT
We validated our algorithm on videos of pedestrians walking in a
VR setting.

6.1 Study Goal
We conducted a within users VR study to evaluate the perception of
entitativity of a group of pedestrians in a virtual environment. This
study aimed to validate whether our entitativity model correctly
predicts the socio-emotional reactions of the users.

6.2 Experimental Design
We conducted the user study using an HTC VIVE HMD on a desktop
machine with an Nvidia Titan X GPU, Intel Xeon E5-1620 v3 4-
core processor, 16 GB of memory, and Windows 10 OS. The study
involved 4 scenarios with each scenario containing 3 characters.
Each scenario had different entitativity parameters related to a
group of three virtual pedestrians (Table 5).

Scenarios Description

Entitativity
Level
Highest

High

Scene 1

Scene 2

Scene 3

Pedestrians walked with identical
trajectories, high synchronization
and movement, and high cohesion.
Pedestrians had the Scene 1 trajec-
tories and movement with a slightly
lower cohesion, less synchronized
and slightly slower walking pace.
Pedestrians walked with varying
trajectories and movement with low
cohesion at a regular walking pace.
Pedestrians had the Scene 3 trajec-
tories and movement with a lower
cohesion and a slower walking pace.
Table 5: Four scenarios with varying levels of entitativity
were used to validate our algorithm in a virtual environ-
ment.

Medium

Scene 4

Low

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

Bera et al.

Figure 6: We captured videos of pedestrians walking in the real world. In each of these videos (~10 seconds), three pedestrians
were walking on a university campus.

6.3 Participants
Participants were recruited from staff and students of a university.
Total 30 participants (17 males, 12 females) were recruited.

6.4 Procedure
The participants were asked to watch scenarios with a group of vir-
tual pedestrians with varying entitativity in a virtual environment
and evaluate their perception (friendly/creepy) of the group.

Each participant was presented with the 4 scenarios on the HTC
VIVE HMD in a randomized order. The participants were free to
look and walk around the environment, but there was no interaction
between the virtual pedestrians in the scenes and the participant.
The participants rated their perception of the pedestrian group us-
ing questions similar to Section IV on a 4-point scale from Strongly
Disagree(1) to Strongly Agree(4).

6.5 Results
We provide the mean values of participant responses to the four
questions for the four scenes in Table 6. Mean values of friendliness
and comfort decrease with higher entitativity whereas mean values
of creepiness and unnervingness increase.

We combined the participant responses to obtain the entitativity
labels using Equation 2. There was a statistically significant differ-
ence between the responses for the different levels of entitativity
as determined by one-way ANOVA (F (3, 30) = 249.44, p < 0.001).
We also conducted pairwise t-tests to compare the four entitativity
levels.

6.6 Discussion
Our results (Table 7) indicate that there was a significant difference
between all the pairwise comparisons. Our algorithm can create dif-
ferent levels of entitativity that can induce more negative emotions
than low-entitative groups.

Since realistic behaviors, interactions, and movements of virtual
agents can increase the sense of presence and immersion in VR,
understanding user-crowd interaction is important. As shown by
our results, varying entitativity can be used to create virtual ex-
periences having characters with different levels of friendliness,
creepiness, comfort, and unnervingness.

7 CONCLUSIONS, LIMITATIONS, AND

FUTURE WORK

We present a novel method for automatically classifying entita-
tivity via pedestrian motion trajectories. Our algorithm identifies

Scene
Scene 1
Scene 2
Scene 3
Scene 4

Friendliness Creepiness Comfort Unnerving
1.30
1.57
2.83
3.63

1.47
1.73
3.20
3.67

3.60
3.27
2.00
1.23

3.47
3.20
2.07
1.47

Table 6: Mean participant responses to the VR scenes.

Scenes
Scene 1 and 2
Scene 1 and 3
Scene 1 and 4
Scene 2 and 3
Scene 2 and 4
Scene 3 and 4

t(29)
4.38
17.62
21.25
13.57
17.59
8.80

p
<0.001
<0.001
<0.001
<0.001
<0.001
<0.001

Table 7: Results of our pairwise t-tests.

groups of pedestrians and extracts their individual trajectories be-
fore synthesizing them together into group-level characteristics.
We precompute a data-driven entitativity metric that predicts nega-
tive socio-emotional reactions (supported by a VR user study) with
important implications for real-world behavior. To the best of our
knowledge, this is the first approach for automatic video-based
group entitativity classification and the associated prediction of
socio-emotional reactions. Our approach can also be used in VR
applications including social VR to create scenarios with groups of
virtual agents having varying entitativity levels which can induce
different levels of friendliness, comfort, and creepiness in the users.
Our approach has some limitations. Most importantly, people
rely upon more than group-level motion characteristics when mak-
ing judgments of groups of people, also relying upon rich social and
identity information (e.g., perceptions of race, class, religion, and
gender). Our algorithm only considers socio-emotional reactions to
motion trajectories and so may not capture the other diverse inputs
of socio-emotional reactions. Additionally, the predictive benefit
of our algorithm may be limited in some cases, such as in a very
large high-density group in which motion-trajectories are heavily
constrained.

A key future direction involves extending the prediction of enti-
tativity judgment to additional cues, primarily appearance. When
individuals look more similar based on race, clothing, or posture,
they are seen to be more entitative. This trajectory-based algorithm
could be expanded to incorporate appearance-based cues, such as
overall color. An additional future direction would be to understand
entitativity judgments as a combination of both the behavior of
others and the personality of the perceiver.

Data-Driven Modeling of Group Entitativity in Virtual Environments

VRST ’18, November 28-December 1, 2018, Tokyo, Japan

8 ACKNOWLEDGEMENTS
This research is supported in part by ARO grant W911NF16-1-0085,
and Intel. We thank Austin Wang for his help in designing 3D
scenes for the user study and Tanya Amert for lending her voice
for the video.

REFERENCES
[1] Julia Diemer, Georg W Alpers, Henrik M Peperkorn, Youssef Shiban, and Andreas
Mühlberger. The impact of perception and presence on emotional reactions: a
review of research in virtual reality. Frontiers in psychology, 6, 2015.

[2] Marine Taffou.

Inducing feelings of fear with virtual reality: the influence of
multisensory stimulation on negative emotional experience. PhD thesis, Paris 6,
2014.

[3] Branislav Ulicny and Daniel Thalmann. Crowd simulation for interactive virtual

environments and VR training systems. Springer, 2001.

[4] Nan Hu, Michael Harold Lees, and Suiping Zhou. A pattern-based modeling
framework for simulating human-like pedestrian steering behaviors. In Proceed-
ings of the 19th ACM Symposium on Virtual Reality Software and Technology, VRST
’13, pages 179–188, New York, NY, USA, 2013. ACM. ISBN 978-1-4503-2379-6.
doi: 10.1145/2503713.2503723. URL http://doi.acm.org/10.1145/2503713.2503723.
[5] Thomas F Pettigrew and Linda R Tropp. When groups meet: The dynamics of

intergroup contact. Psychology Press, 2013.

[6] Robert P Abelson, Nilanjana Dasgupta, Jaihyun Park, and Mahzarin R Banaji.
Perceptions of the collective other. Personality and Social Psychology Review, 2(4):
243–250, 1998.

[7] Aniket Bera, Tanmay Randhavane, Emily Kubin, Austin Wang, Dinesh Manocha,
and Kurt Gray. Classifying group emotions for socially-aware autonomous
vehicle navigation. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition Workshops, pages 1039–1047, 2018.

[8] Aniket Bera, Tanmay Randhavane, Emily Kubin, Austin Wang, Kurt Gray, and
Dinesh Manocha. The socially invisible robot: Navigation in the social world
using robot entitativity. In Intelligent Robots and Systems (IROS), 2018.

[9] RI Dunbar. The social brain hypothesis. brain, 9(10):178–190, 1998.
[10] Rebecca Saxe. Uniquely human social cognition. Current opinion in neurobiology,

16(2):235–239, 2006.

[11] Yaneer Bar-Yam. Complexity rising: From human beings to human civilization, a

complexity profile, 2008.

[12] Henri Tajfel. Social psychology of intergroup relations. Annual review of psy-

chology, 33(1):1–39, 1982.

[13] Andrew C Gallagher and Tsuhan Chen. Understanding images of groups of people.
In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on,
pages 256–263. IEEE, 2009.

[14] Fritz Heider and Marianne Simmel. An experimental study of apparent behavior.

The American journal of psychology, 57(2):243–259, 1944.

[15] Tao Gao, George E Newman, and Brian J Scholl. The psychophysics of chasing:
A case study in the perception of animacy. Cognitive psychology, 59(2):154–179,
2009.

[16] Kang Hoon Lee, Myung Geol Choi, Qyoun Hong, and Jehee Lee. Group behavior
from video: a data-driven approach to crowd simulation. In Proceedings of the
2007 ACM SIGGRAPH/Eurographics symposium on Computer animation, pages
109–118. Eurographics Association, 2007.

[17] Wei Shao and Demetri Terzopoulos. Autonomous pedestrians. In Symposium on

Computer animation, pages 19–28, 2005. ISBN 1-59593-198-8.
[18] Craig Reynolds. Steering Behaviors for Autonomous Characters.

In Game

Developers Conference 1999, 1999.

[19] H. Yeh, S. Curtis, S. Patil, J. van den Berg, D. Manocha, and M. Lin. Composite
agents. In Symposium on Computer Animation, pages 39–47, 2008. ISBN 978-3-
905674-10-1.

[20] Stephen J. Guy, Sujeong Kim, Ming C. Lin, and Dinesh Manocha. Simulating
heterogeneous crowd behaviors using personality trait theory. In Symposium on
Computer Animation, pages 43–52. ACM, 2011. ISBN 978-1-4503-0923-3.
[21] F. Durupinar, N. Pelechano, J.M. Allbeck, U. Gü anddü andkbay, and N.I. Badler.
How the ocean personality model affects the perception of crowds. Computer
Graphics and Applications, IEEE, 31(3):22 –31, may-june 2011. ISSN 0272-1716.

[22] Aniket Bera, Tanmay Randhavane, and Dinesh Manocha. Aggressive, tense,
or shy? identifying personality traits from crowd videos. In Proceedings of the
Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17,
pages 112–118, 2017.

[23] Sean D Lynch, Julien Pettré, Julien Bruneau, Richard Kulpa, Armel Crétual,
and Anne-Helene Olivier. Effect of virtual human gaze behaviour during an
orthogonal collision avoidance walking task. In 2018 IEEE Conference on Virtual
Reality and 3D User Interfaces (VR), pages 136–142. IEEE, 2018.

[24] Anne-Hélène Olivier, Julien Bruneau, Richard Kulpa, and Julien Pettré. Walking
with virtual people: Evaluation of locomotion interfaces in dynamic environments.
IEEE transactions on visualization and computer graphics, 24(7):2251–2263, 2018.

[25] Christos Mousas, Dimitris Anastasiou, and Ourania Spantidi. The effects of
appearance and motion of virtual characters on emotional reactivity. Computers
in Human Behavior, 86:99–108, 2018.

[26] Katja Zibrek, Elena Kokkinara, and Rachel McDonnell. The effect of realistic
appearance of virtual characters in immersive environments-does the character’s
personality play a role? IEEE transactions on visualization and computer graphics,
24(4):1681–1690, 2018.

[27] Teng Li, Huan Chang, Meng Wang, Bingbing Ni, Richang Hong, and Shuicheng
Yan. Crowded scene analysis: A survey. Circuits and Systems for Video Technology,
IEEE Transactions on, 25(3):367–386, March 2015.

[28] Weiming Hu, Tieniu Tan, Liang Wang, and Steve Maybank. A survey on visual
surveillance of object motion and behaviors. Systems, Man, and Cybernetics, Part
C: Applications and Reviews, IEEE Transactions on, 34(3):334–352, 2004.

[29] G. Zen and E. Ricci. Earth mover’s prototypes: A convex learning approach for
discovering activity patterns in dynamic scenes. In Computer Vision and Pattern
Recognition (CVPR), 2011 IEEE Conference on, pages 3225–3232, June 2011. doi:
10.1109/CVPR.2011.5995578.

[30] Stefano Pellegrini, JÃĳrgen Gall, Leonid Sigal, and Luc Gool. Destination flow for
crowd simulation. In Computer Vision âĂŞ ECCV 2012. Workshops and Demonstra-
tions, volume 7585, pages 162–171. 2012. ISBN 978-3-642-33884-7. doi: 10.1007/
978-3-642-33885-4_17. URL http://dx.doi.org/10.1007/978-3-642-33885-4_17.

[31] George A Quattrone and Edward E Jones. The perception of variability within
in-groups and out-groups: Implications for the law of small numbers. Journal of
Personality and Social Psychology, 38(1):141, 1980.

[32] Vincent Y Yzerbyt, Anouk Rogier, and Susan T Fiske. Group entitativity and social
attribution: On translating situational constraints into stereotypes. Personality
and Social Psychology Bulletin, 24(10):1089–1103, 1998.

[33] Erin Cooley and B Keith Payne. Using groups to measure intergroup prejudice.

Personality and Social Psychology Bulletin, 43(1):46–59, 2017.

[34] Chester A Insko, John Schopler, Rick H Hoyle, Gregory J Dardis, and Kenneth A
Graetz. Individual-group discontinuity as a function of fear and greed. Journal
of Personality and Social Psychology, 58(1):68, 1990.

[35] Marlena R Fraune, Steven Sherrin, Selma Sabanović, and Eliot R Smith. Rabble
of robots effects: Number and type of robots modulates attitudes, emotions,
and stereotypes.
In Proceedings of the Tenth Annual ACM/IEEE International
Conference on Human-Robot Interaction, pages 109–116. ACM, 2015.

[36] David-Paul Pertaub, Mel Slater, and Chris Barker. An experiment on public
speaking anxiety in response to three different types of virtual audience. Presence:
Teleoperators & Virtual Environments, 11(1):68–78, 2002.

[37] Didier Bigo. Security and immigration: Toward a critique of the governmentality

of unease. Alternatives, 27(1):63–92, 2002.

[38] Reidar Ommundsen, Oksana Yakushko, Kees Van der Veer, and Pål Ulleberg.
Exploring the relationships between fear-related xenophobia, perceptions of
out-group entitativity, and social contact in norway. Psychological reports, 112(1):
109–124, 2013.

[39] Megan Strait, Lara Vujovic, Victoria Floerke, Matthias Scheutz, and Heather
Urry. Too much humanness for human-robot interaction: exposure to highly
humanlike robots elicits aversive responding in observers. In Proceedings of the
33rd Annual ACM Conference on Human Factors in Computing Systems, pages
3593–3602. ACM, 2015.

[40] Arne Roets and Alain Van Hiel. The role of need for closure in essentialist entita-
tivity beliefs and prejudice: An epistemic needs approach to racial categorization.
British Journal of Social Psychology, 50(1):52–73, 2011.

[41] Kira J Harris. Entitativity and ideology: a grounded theory of disengagement.

2011.

[42] Thomas F Denson, Brian Lickel, Mathew Curtis, Douglas M Stenstrom, and
Daniel R Ames. The roles of entitativity and essentiality in judgments of collective
responsibility. Group Processes & Intergroup Relations, 9(1):43–61, 2006.

[43] J. van den Berg, Ming Lin, and D. Manocha. Reciprocal velocity obstacles for
real-time multi-agent navigation. In Robotics and Automation, 2008. ICRA 2008.
IEEE International Conference on, pages 1928 –1935, may 2008.

[44] Liang He, Jia Pan, Wenping Wang, and Dinesh Manocha. Proxemic group behav-
iors using reciprocal multi-agent navigation. In Robotics and Automation (ICRA),
2016 IEEE International Conference on, pages 292–297. IEEE, 2016.

[45] Kurt Gray and Daniel M Wegner. Feeling robots and human zombies: Mind

perception and the uncanny valley. Cognition, 125(1):125–130, 2012.

[46] Aniket Bera and Dinesh Manocha. REACH: Realtime crowd tracking using a

hybrid motion model. ICRA, 2015.

[47] Aniket Bera, Sujeong Kim, Tanmay Randhavane, Srihari Pratapa, and Dinesh
Manocha. Glmp-realtime pedestrian path prediction using global and local
movement patterns. ICRA, 2016.

[48] Sujeong Kim, Aniket Bera, Andrew Best, Rohan Chabra, and Dinesh Manocha.
Interactive and adaptive data-driven crowd simulation. In Virtual Reality (VR),
pages 29–38. IEEE, 2016.

