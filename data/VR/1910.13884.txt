Prediction, Communication, and Computing

1

Duration Optimization for VR Video Streaming

0
2
0
2

g
u
A
4
1

]
T
I
.
s
c
[

4
v
4
8
8
3
1
.
0
1
9
1
:
v
i
X
r
a

Xing Wei, Chenyang Yang, and Shengqian Han

Abstract

Proactive tile-based video streaming can avoid motion-to-photon latency of wireless virtual reality

(VR) by computing and delivering the predicted tiles to be requested before playback. All existing

works either focus on designing predictors or allocating computing and communications resources.

Yet to avoid the latency, the successively executed prediction, communication, and computing tasks

should be accomplished within a predetermined time. Moreover, the quality of experience (QoE) of

proactive VR streaming depends on the worst performance of the three tasks. In this paper, we jointly

optimize the duration of the observation window for predicting tiles and the durations for computing

and transmitting the predicted tiles, aimed at balancing the performance for three tasks to maximize the

QoE given arbitrary predictor and conﬁgured resources. We obtain the closed-form optimal solution by

decomposing the formulated problem equivalently into two subproblems. With the optimized durations,

we ﬁnd a resource-limited region where the QoE increases rapidly with conﬁgured resources, and

a prediction-limited region where the QoE can be improved more efﬁciently with a better predictor.

Simulation results using three existing predictors and a real dataset validate the analysis and demonstrate

the gain from the joint optimization over non-optimized counterparts.

Index Terms

Wireless VR, proactive tiled-based VR video streaming, prediction, computing, communication.

I. INTRODUCTION

Wireless virtual reality (VR) can provide an immersive experience to wireless users. As the

main type of VR services [1], VR video usually has 360◦ × 180◦ panoramic view with ultra

high resolution (e.g. 16 K [2]). Evidently, delivering such video is cost-prohibitive for wireless

August 17, 2020

DRAFT

 
 
 
 
 
 
2

networks. Nonetheless, the range of angles that humans can see at the same time is only a

limited area of the full panoramic view (about 110◦ × 90◦ [3]), called ﬁeld of view (FoV). This

inspires tile-based streaming [4], [5], which divides a full panoramic view segment into small

tiles in spatial domain, and only computes and transmits the tiles overlapped with the FoVs.

To avoid dizziness in watching VR video, the motion-to-photon (MTP) latency should be

low, which usually should be less than 20 ms [6]. With reactive tile-based streaming, the tiles

within the FoVs should be computed and delivered within the MTP latency after a user initiates

a request, which demands for very high transmission rate and computing rate [6], [7]. Proactive

tile-based streaming can avoid the MTP latency [5], [6], [8], which is anticipated to be the

mainstream in the ultimate stage of VR video streaming [6].

A. Motivation and Major Contributions

Proactive tile-based VR video streaming contains three tasks: prediction, communication, and

computing. Before the playback of a segment, the tiles to be most likely requested in the segment

are ﬁrst predicted using the user behavior-related data in an observation window, which are then

computed and ﬁnally delivered to the user.

To avoid the MTP latency, these successively executed tasks should be accomplished within

a pre-determined duration, which depends on the “coherence time” of the data of user behavior

in watching a VR video, the employed predictor and the playback duration of a segment.

On the other hand, even without the MTP latency, the quality of experience (QoE) of a user

may degrade due to the black holes during VR video playback [5], [9]. This occurs when the

following cases happen. (1) More tiles to be requested in a segment can be correctly predicted

with longer observation window, but no enough time is left for computing and delivering all the

predicted tiles before the playback of the segment. (2) More tiles can be computed and delivered

with longer time for computing and communication, but some of these tiles are not requested due

to the poor prediction performance. It suggests that the QoE depends on the worst performance

DRAFT

August 17, 2020

3

of the three tasks. In this context, the performance of prediction indicates how many tiles to

be requested can be predicted correctly [8], [10], and the performance of communication and

computing refers to how many predicted tiles can be computed and delivered before playback.

The prediction performance is restricted by the “coherence time” even with the best predictor.

Delivering and computing large amount of data within short time requires high transmission

and computing rates. To maximize the QoE with a given predictor and conﬁgured resources, the

performance of the three tasks should be balanced. This can be achieved by judiciously allocating

the durations for the observation window and for processing and delivering the predicted tiles.

In this paper, we strive to investigate how to match the computing rate and transmission rate

to the prediction performance to maximize the QoE of proactive tile-based VR video streaming.

The main contributions are summarized as follows.

• To balance the performance of the three tasks, we formulate a problem to optimize the

duration assigned to the observation window for any given predictor and the durations for

processing and delivering the predicted tiles with given computing and transmission rates.

• We ﬁnd the optimal durations with closed-form expressions, with a reasonable assumption

on the relation between the prediction performance and the observation time, which is

validated using existing predictors and a real dataset. From the optimal solution, we ﬁgure

out a single parameter to reﬂect the conﬁgured communication and computing resources,

and ﬁnd resource-limited and prediction-limited regions, which provides useful insights into

the system design. In the resource-limited region, the QoE can be improved by boosting

communication and computing performance. In the prediction-limited region, the QoE can

be improved more effectively by enhancing the prediction performance.

B. Related Works

As far as the authors known, there are no prior works to co-design the prediction, communi-

cation, and computing tasks for proactive tile-based VR video streaming.

August 17, 2020

DRAFT

4

For tile prediction, a linear regression (LR) method was proposed in [8] to predict the central

point of FoV, which was then transformed into corresponding tiles [11]. A deep reinforcement

learning technique was used in [12] to predict the FoV of the next frame. A deep learning method

was proposed in [10] that uses head mounted display (HMD) orientations, image saliency maps,

and motion maps to predict the tiles to be requested. Context bandits (CB) learning technique

was considered in [11] to predict the tile requests and in [13] to predict the user orientation

in longitude and latitude. A sequence-to-sequence prediction method was proposed in [14] to

predict the future FoV in seconds ahead.

For communication and computing resource allocation, the rendering task in computing was

ofﬂoaded in [15] from HMD to multiple-access edge computing (MEC) server to reduce the

bandwidth usage and computational workload on HMD. The computing and caching resources

were leveraged in [16] to reduce the communication resource usage. Multicast opportunity was

exploited for multiple users watching the same video in [17] to minimize the transmission energy.

The uplink and downlink communication resource allocation was optimized in [18] to maximize

a utility function that takes prediction accuracy, communication delay, and computing delay

into consideration. In [19], [20], partial computing task was ofﬂoaded from the MEC server to

the HMD, which reveals the tradeoff between caching and computing without considering tile

prediction. In our previous work [11], the durations for communication and computing were

optimized, while the duration for prediction was simply given.

All prior works do not investigate how to balance the performance of the three tasks in order

to maximize the QoE of proactive tile-based VR streaming.

The rest of this paper is organized as follows. Section II describes the system model. Section III

formulates the problem, and Section IV derives the optimal solution and provides the prediction-

limited and resource-limited regions. Simulation and numerical results are provided in Section

V to validate the assumption, show the QoE in the two regions, and evaluate the gain from

optimizing the durations for three tasks. Section VI concludes the paper.

DRAFT

August 17, 2020

II. SYSTEM MODEL

5

Consider a proactive tile-based VR video streaming system with an MEC server co-located

with a base station (BS). Each VR video consists of L segments in temporal domain, and each

segment consists of M tiles in spatial domain. The playback duration of each tile equals to the

playback duration of a segment, denoted by Tseg [5], [8]. Each user is equipped with a HMD,

which can measure data1 of the user, send the recorded data to the MEC server, and pre-buffer

segments. While both the MEC server and the HMD can be used for rendering, we consider

that the MEC server renders a video segment before delivering to the HMD.

Fig. 1: Proactively streaming the (l+1)th segment of a VR video. tb is the start time for streaming

the (l+1)th segment, and te is the start time of playback of the (l+1)th segment.

During the VR video playback, subsequent segments are predicted, computed, and delivered

one after another [5], [6], as shown in Fig. 1. Each segment has its own deadline for the pre-

diction, computing, and communication, hence the three tasks for L segments can be decoupled

into L groups of tasks. In the sequel, we take the (l +1)th segment as an example for elaboration.

1The useful data for prediction include sensor-related data (i.e., the head movement orientation tracking [8] and eye tracking

data [12], [21] from the HMD sensors), and content-related data (i.e., the images in historical FoVs [12], [22] and temporal-

spatial saliency [10], [23]). The audio data in a VR video are also under discussion [23]. While our framework is applicable

for prediction using one or multiple types of data, we take the head movement trace as an example for easy exposition.

August 17, 2020

DRAFT

VR videoplaybackCommunication pipelinetl+1l+1obwtcpttComputingpipelinel+1comtHead movement tracecctbtpsTetpdwsegTT=Predicted tilesllll6

With proactive VR streaming, the MTP latency can be avoided by processing and delivering

the tiles in the (l+1)th segment to be requested before te. Hence, the tiles to be played in a

prediction window, which begins at te and is with duration Tpdw = Tseg, should be predicted.

This can be accomplished by ﬁrst predicting the head movement sequence in the prediction

window with the observations (say also a head movement sequence) in a time window with

duration tobw, then mapping the predicted sequence into the predicted tiles [11], [22]. Since

the prediction performance for a time series depends on its auto-correlation, there exists a time

instant tb, before which the observations have low correlation with the sequence to be predicted

and hence contribute little or even negatively for improving the prediction accuracy [10], [24],

[25]. We can set tb as the start time of the observation window. At the end of the observation

window, the MEC server ﬁrst makes the prediction, then renders the predicted tiles with duration

tcpt, and ﬁnally delivers the processed tiles with duration tcom. Then, the duration between tb

and te, denoted as Tps, is the total proactive streaming time available for prediction, computing,

and communication, i.e., tobw + tcpt + tcom ≤ Tps. The value of Tps can be predetermined for

any given dataset and predictor [10], [24], [25]. The duration Tps + Tpdw can be regarded as the

“coherence time” for the head movement time series.

A. Computing Model

For tile-based VR video streaming, rendering contains two steps. (1) The tiles in a segment

are unpacked and the tiled-frames at the same timestamp are concatenated to generate successive

two-dimensional (2D) FoVs [15]. (2) The 2D planar FoVs are converted to the three-dimensional

(3D) spherical FoVs, by multiplying the image matrix of 2D FoV with a projection matrix

(this step is sometimes called “projection” in the rendering operation [5]). In practice, GPU

is necessary for real-time rendering. When the GPU with Turing architecture [26] is used for

MEC [27], [28], the computing resource for rendering a VR video can be assigned by allocating

compute uniﬁed device architecture cores [29] and multiple GPUs can be used at the server.

DRAFT

August 17, 2020

7

To gain useful insight, we assume that the computing resource, denoted as Ctotal (in ﬂoating-

point operations per second, FLOPS), is equally allocated among K users. Then, the number of

bits that can be rendered per second, referred to as the computing rate for the kth user, is

Ccpt,k (cid:44) Cr,k
µr

(in bits/s),

(1)

where Cr,k = Ctotal/K is the computing resource assigned to the kth user for rendering, µr =

TrCr
γfovRwRhb

is the required ﬂoating-point operations (FLOPs) of rendering one bit of FoV in

FLOPs/bit, Tr is the time used for rendering a FoV, γfov is the ratio of FoV in a frame, Rw

and Rh are respectively the pixels in wide and high of a frame, and b is the number of bits per

pixel relevant to color depth [30].

B. Transmission Model

The BS equipped with Nt antennas serves K single-antenna users with zero-forcing beam-

forming. The instantaneous transmission rate at the ith time slot for the kth user is

(cid:32)

C i

com,k = B log2

1 +

k |˜hi
kd−α
pi
σ2

k|2

(cid:33)

,

(2)

where B is the bandwidth, ˜hi
k

(cid:44) (hi

k)Hwi

k is the equivalent channel gain, pi

k and wi

respectively the transmit power and beamforming vector for the kth user, dk and hi

k are
k ∈ CNt

are respectively the distance and the small scale channel vector from the BS to the kth user, α

is the path-loss exponent, σ2 is the noise power, and (·)H denotes conjugate transpose.

We consider indoor users as in the literature of wireless VR video streaming, where the dis-

tances of users usually change slightly [22], [31] and are assumed ﬁxed. We consider block fading

channels, which remain constant in each time slot and are identical and independently distributed

among time slots. With the proactive transmission, the predicted tiles in a segment should be

transmitted with duration tcom. Thereby, we are concerned about the number of bits transmitted

within the duration, i.e., we are concerned about time-average rate C com,k = 1
Ns

((cid:80)Ns

i=1 C i

com,k)

rather than instantaneous transmission rates [32], where Ns is the number of time slots in tcom,

August 17, 2020

DRAFT

8

depending on the coherence time of small scale channel. Since the future channel is unknown

during proactive delivering, we can use the ensemble-average rate Eh{Ccom,k} to approximate

C com,k [32], where Eh{·} is the expectation over h. The approximation is very accurate when

Ns or Nt/K is large, as validated via extensive simulations. To ensure fairness among users in

terms of QoE, the transmit power is allocated to compensate the path loss, i.e., pi

k = β
d−α
k

, where

β can be obtained from β((cid:80)K

k=1

1
d−α
k

) = P and P is the maximal transmit power of the BS.

Then, the ensemble-average transmission rate for each user is equal.

In the sequel, we ﬁrst consider one user for analysis and then show the impact of K. We use

Ccom to replace Eh{C i

com,k} and use Ccpt to replace Ccpt,k for notational simplicity.

III. PROBLEM FORMULATION FOR OPTIMIZING THE DURATIONS FOR THREE TASKS

In this section, we ﬁrst introduce the performance metrics for the tile prediction task, for the

computing and communication tasks, and for the QoE in watching a VR video. To balance the

performance of the three tasks for maximizing the QoE, we then formulate a problem to jointly

optimize the duration of the observation window with any given predictor, and the durations for

communication and computing with given computing rate and transmission rate.

A. Performance Metric of Tile Prediction

Degree of overlap (DoO) has been used to measure the overlap between the predicted and

the requested frames of a panoramic video [12], [31]. A larger value of DoO indicates a better

prediction. To reﬂect the prediction performance for proactive tile-based streaming, we consider

segment DoO (seg-DoO), which measures the overlap of the predicted tiles and the requested tiles

in a segment. From this perspective, the DoO used in [12], [31] can be considered as a special

case of seg-DoO where a segment contains only one frame [31]. The seg-DoO of the lth segment

is deﬁned as DoOseg

l

(tobw) (cid:44) qT

l ·el(tobw)
(cid:107)ql(cid:107)1

, where ql (cid:44) [ql,1, ..., ql,M ]T denotes the ground-truth of

the tile requests for the segment with ql,m ∈ {0, 1}, el(tobw) (cid:44) [el,1(tobw), ..., el,M (tobw)]T denotes

the predicted tile requests for the segment with el,m(tobw) ∈ {0, 1}, (·)T denotes transpose of

DRAFT

August 17, 2020

9

a vector, and (cid:107) · (cid:107)1 denotes the (cid:96)1 norm of a vector. When the mth tile in the lth segment

is truly requested, ql,m = 1, otherwise ql,m = 0. When the tile is predicted to be requested,

el,m(tobw) = 1, otherwise it is zero.

We use average seg-DoO to measure the prediction performance for a VR video, which is

D(tobw) (cid:44) 1
L

L
(cid:88)

l=1

DoOseg

l

(tobw) =

∞
(cid:88)

n=0

antn

obw,

(3)

where the second equality is the power series expansion, which holds for any inﬁnitely differ-

entiable function. The value of an depends on the predictor.

For any pre-determined value of Tps, a predictor can be more accurate with a longer observation

window, because the tiles to be predicted are closer to and hence are more correlated with the head

movement sequence having been observed, as shown in Fig. 1. This gives rise to a reasonable

assumption as follows.

Assumption 1: D(tobw) is a monotonically increasing function of tobw.

B. Completion Rate of Communication and Computing Tasks

To reﬂect the performance of the system for rendering and delivering the predicted tiles in a

segment, we deﬁne the completion rate of communication and computing (CC) tasks as

Scc(tcom, tcpt) (cid:44) min{S(tcom, tcpt), N }

N

,

(4)

where N (cid:44) (cid:107)el(tobw)(cid:107)1 is the number of predicted tiles in a segment, S(tcom, tcpt) is the number

of tiles in the segment that can be delivered with tcom and computed with tcpt, which is

S(tcom, tcpt) (cid:44) min

(cid:26) Ccomtcom
scom

,

Ccpttcpt
scpt

(cid:27)

,

(5)

where scom = rwrhbNtf/γc [30] is the number of bits in each tile for transmission, scpt = rwrhbNtf

is the number of bits in a tile for rendering, rw and rh are the pixels in wide and high of a

tiled-frame, γc is the compression ratio, and Ntf is the number of tiled-frame in a tile.

After substituting (5) into (4), the completion rate of CC tasks can be expressed as

Scc(tcom, tcpt) = min

(cid:26) Ccomtcom
scomN

,

Ccpttcpt
scptN

(cid:27)

, 1

.

(6)

DRAFT

August 17, 2020

10

C. Metric of Quality of Experience

For proactive tile-based streaming, there will be no MTP latency if the constraint tobw +tcom +

tcpt ≤ Tps can be satisﬁed. Yet black holes will appear if either the requested tiles cannot be

predicted correctly, or some predicted tiles cannot be computed and delivered before playback.

To reﬂect the percentage of the correctly predicted tiles for any given predictor with observation

window of duration ttow that can be computed and delivered within durations tcom and tcpt among

all the requested tiles, we consider the following QoE metric

QoE (cid:44) 1
L

L
(cid:88)

l=1

l · (cid:0)el(tobw) · Scc(tcom, tcpt)(cid:1)
qT
(cid:107)ql(cid:107)1

=

(cid:16) 1
L

L
(cid:88)

l=1

qT
l · el(tobw)
(cid:107)ql(cid:107)1

(cid:17)

· Scc(tcom, tcpt)

= D(tobw) · Scc(tcom, tcpt),

(7)

where el(tobw) · Scc(tcom, tcpt) is the predicted tiles that can be delivered and computed with

durations tcom and tcpt. When the value of the QoE is 100%, all the requested tiles in a VR

video are proactively computed and delivered before playback. The QoE can be increased by

improving the prediction performance or the computing and communication performance. To

reduce the impact of wrong prediction, one can proactively streaming extra tiles in addition to

the predicted tiles. For example, we can set N = (cid:100)γptM (cid:101) [30], where γpt = γfov + γextra ∈ [0, 1],

γfov and γextra are respectively the percentage of the tiles in a FoV in a frame and the percentage

of the tiles additionally computed and transmitted [30], and (cid:100)·(cid:101) is the ceil function.

D. Joint Optimization of the Durations for Prediction, Computing, and Communications

The duration optimization problem to maximize the QoE with given computing rate Ccpt and

transmission rate Ccom can be formulated as

P1 : max

tobw,tcom,tcpt

D(tobw) · Scc(tcom, tcpt)

s.t.

tobw + tcom + tcpt = Tps,

tobw ≥ τ,

tcom, tcpt ≥ 0,

(8a)

(8b)

(8c)

DRAFT

August 17, 2020

11

where τ is the minimal duration of the observation window, which depends on the speciﬁc

prediction method [11], [31]. In this problem, we replace the constraint imposed by ensuring

zero MTP latency with (8b), because the objective is a monotonically increasing function of

tobw, tcc, and tcpt under Assumption 1.

IV. OPTIMAL DURATIONS AND PREDICTION-LIMITED AND RESOURCE-LIMITED REGIONS

In this section, we investigate how to balance the performance of the three tasks by solving

the joint duration optimization problem. To this end, we ﬁrst decouple problem P1 equivalently

into two subproblems, thanks to the separability of the objective function in (8a) with respect to

tcom, tcpt and tobw, and obtain the global optimal solution with closed-form expression. Then, we

show that the system may operate in a prediction-limited or a resource-limited region, depending

on the computing rate and transmission rate.

A. Problem Decomposition

First, we optimize tcom and tcpt for arbitrarily given total time for computing and delivering

the predicted tiles tcc (cid:44) tcom + tcpt that satisﬁes (8b) from the following problem

P2 : max
tcom,tcpt

Scc(tcom, tcpt)

s.t.

tcom + tcpt = tcc, tcom, tcpt ≥ 0.

Then, we optimize tobw and tcc from the following problem

P3 : max
tobw,tcc

D(tobw) · S∗

cc(tcc)

s.t.

tobw + tcc = Tps, tobw ≥ τ,

(9a)

(9b)

(10a)

(10b)

where S∗

cc(tcc) is the maximized objective of problem P2 as a function of tcc.

Problem P2 optimizes the durations for communication and computing with given values of

Ccpt and Ccom, so as to maximize the term of completion rate of CC tasks in (8a). The solution

of problem P3 can match the maximal completion rate of CC tasks to the prediction performance

of any given predictor, so as to maximize the QoE in (8a).

August 17, 2020

DRAFT

12

B. Solution of Problem P2

By eliminating tcom = tcc−tcpt and considering the expression of Scc(tcom, tcpt) in (6), problem

P2 can be equivalently transformed as

max
tcpt,Scc(tcc)

Scc(tcc)

s.t.

Scc(tcc) ≤

Ccom(tcc − tcpt)
scomN

,

Scc(tcc) ≤

Ccpttcpt
scptN

,

Scc(tcc) ≤ 1.

(11a)

(11b)

(11c)

(11d)

We do not express tcpt as a function of tcc in this problem for notational simplicity. As derived

in Appendix A, the solution of problem (11) is,








t∗
cpt(tcc) =

S∗

cc(tcc) =

Ccomscpt
Ccomscpt+Ccptscom
α, α ∈ ( scptN
Ccpt

tcc,

tcc ≤ T max

cc

,

, ∞),

tcc ≥ T max

cc

,

tcc
T max
cc

,

tcc ≤ T max

cc

,



1,

tcc ≥ T max

cc

,

(12a)

(12b)

where T max

cc

is the duration to deliver and compute the predicted tiles in a segment with expression

T max
cc

(cid:44) scomN
Ccom

+

scptN
Ccpt

.

(13)

The value of 1/T max

cc monotonically increases with transmission rate or computing rate of a VR

user, which reﬂects the tradeoff between communication and computing.

From (12a) and the deﬁnition of tcc, we have

t∗
com(tcc) =

Ccptscom
Ccomscpt + Ccptscom

tcc.

C. Solution of Problem P3

We can observe from (12b) that S∗

cc(tcc) ﬁrst increases with tcc until tcc reaches T max

cc

(14)

, after

which further increasing tcc does not improve S∗

cc(tcc). On the other hand, increasing tcc decreases

DRAFT

August 17, 2020

tobw as shown in (10b), which leads to the reduction of D(tobw) according to Assumption 1.

This suggests that the optimal value of tcc must satisfy the constraint tcc ≤ T max

cc

.

13

By substituting S∗

cc(tcc) under tcc ≤ T max

cc

case in (12b), problem P3 can be re-written as

max
tobw,tcc

D(tobw) ·

tcc
T max
cc

s.t.

tobw + tcc = Tps,

tobw ≥ τ, 0 ≤ tcc ≤ T max

cc

.

As derived in Appendix B, the solution of problem (15) is










W,

W,

t∗
obw =

H, φ(H) > 0 and Φ = ∅,

T ∗
Φ, φ(H) = 0 and Φ (cid:54)= ∅,

H, φ(H) > 0, Φ (cid:54)= ∅ and f (H) ≥ f (T ∗

Φ),

Φ, φ(H) > 0, Φ (cid:54)= ∅ and f (H) < f (T ∗
T ∗

Φ),

φ(H) > 0 and Φ = ∅,

Tps − T ∗

Φ, φ(H) = 0 and Φ (cid:54)= ∅,

t∗
cc =

φ(H) > 0, Φ (cid:54)= ∅ and f (H) ≥ f (T ∗

Φ),

Tps − T ∗

Φ, φ(H) > 0, Φ (cid:54)= ∅ and f (H) < f (T ∗

Φ),

(15a)

(15b)

(15c)

(16a)

(16b)

f (tobw), tobw ∈ Φ,

where H (cid:44) max{Tps − T max

cc

, τ }, W (cid:44) min{T max

cc

f (x) (cid:44) D(x) · (Tps−x)
T max
cc

, ∅ denotes an empty set, and

, Tps − τ }, T ∗

Φ = argmax

tobw

φ(tobw) (cid:44) D(tobw) −

dD(tobw)
dtobw

· (Tps − tobw) =

∞
(cid:88)

n=0

∞
(cid:88)

antn

obw − (

n=1

nantn−1

obw )(Tps − tobw), (17a)

Φ (cid:44) (cid:8)tobw|φ(tobw) = 0, tobw ≥ max{Tps − T max

cc

, τ }(cid:9).

(17b)

D. Solution of Problem P1

The optimal durations for communication and computing can be obtained by substituting (16b)

into (14) and (12a). The optimal duration of the observation window is (16a). By substituting

(16b) into (12b), we obtain the maximal achievable completion rate of CC tasks with t∗

cc as

August 17, 2020

DRAFT

14

cc(t∗
S∗

cc) =






W
T max
cc

,

Tps−T ∗
Φ
T max
cc

W
T max
cc

,

Tps−T ∗
Φ
T max
cc

φ(H) > 0 and Φ = ∅,

, φ(H) = 0 and Φ (cid:54)= ∅,

φ(H) > 0, Φ (cid:54)= ∅ and f (H) ≥ f (T ∗

Φ),

, φ(H) > 0, Φ (cid:54)= ∅ and f (H) < f (T ∗

Φ).

(18)

E. Resource-limited Region and Prediction-limited Region

In this subsection, we show that the system may operate in a resource-limited region or a

prediction-limited region. We consider the optimal durations under the case where φ(H) >

0 and Φ = ∅, which can be obtained from (16a) and (16b) as

t∗
obw =

t∗
cc =








τ,

T max
cc > Tps − τ,

cc − τ, T max
T max

cc < Tps − τ,

Tps − τ, T max

cc > Tps − τ,



T max
cc

,

T max
cc < Tps − τ,

(19a)

(19b)

because only this case yields feasible solution for the three prediction methods and the real dataset

to be considered in the next section. Both the relations t∗

obw ∼ 1
T max
cc

in (19a) and t∗

cc ∼ 1
T max
cc

in

(19b) can be divided into two regions with a boundary line T max

cc = Tps − τ .

When the value of

1
T max
cc

is small, i.e., at least one type of the communication and computing

resources is limited, not all the predicted tiles can be delivered or computed. To increase the

completion rate of CC tasks, all remaining time should be used for computing or delivering

after satisfying the minimal duration required by the observation window, i.e., tobw = τ . We

refer to this region as “Resource-limited region”, where T max

cc > Tps − τ . When the value

of

1
T max
cc

approaches T max

cc = Tps − τ and further increases, the completion rate of CC tasks

matches the prediction performance, i.e., all the predicted tiles can be delivered and computed.

Yet as the value of

1
T max
cc

exceeds such a boundary, the prediction performance becomes the

bottleneck of improving QoE. Since the prediction performance can be improved by increasing

DRAFT

August 17, 2020

15

tobw, the optimal solution allocates all the remaining time for the observation window, i.e.,

obw = Tps − T max
t∗

cc

. We refer to this region with T max

cc < Tps − τ as “Prediction-limited region”.

To help understand the relation of the parameter

1
T max
cc

with Ccom and Ccpt, we provide the

values of

1
T max
cc

obtained from (13) given different computing rate and transmission rate in Fig.

2a, where we set N = 8, scom = 52 Mbits, and scpt = 124 Mbits (to be explained later).

To visualize the “Resource-limited region” and “Prediction-limited region”, we provide the

values of t∗

obw and t∗

cc obtained from (19a) and (19b) given τ = 0.1 s, respectively considering

Tps = 1 s and showing the impact of different values of Tps in Figs. 2b and 3.

(a)

1
T max
cc

∼ Ccom and Ccpt

(b) t∗

obw and t∗

cc ∼ 1

T max
cc

Fig. 2: The relation of

1
T max
cc

with Ccom and Ccpt, and the optimal durations v.s.

1
T max
cc

.

Fig. 3: Optimal durations v.s.

1
T max
cc

and Tps.

August 17, 2020

DRAFT

0.02123450.10.20.40.60.8Duration(seconds)Resource-limited regionPrediction-limited region16

V. SIMULATION AND NUMERICAL RESULTS

In this section, we ﬁrst verify Assumption 1 with three predictors, namely LR, CB, and

Gated Recurrent Unit (GRU) neural network, by ﬁtting their achieved prediction performance,

average DoO, as the functions of tobw over a real dataset. Then, we verify the feasible case of

the solution with the three predictors and dataset via numerical results. After that, we show the

QoE in the two regions achieved by the LR and CB methods, and demonstrate how the QoE

is respectively improved by boosting the prediction performance and the completion rate of CC

tasks with the CB method. Finally, we show the gain from balancing the three tasks in terms

of improving QoE and the impact of the number of users. Again, the solutions are all obtained

from (16a), (16b), and (18) under the case that φ(H) > 0 and Φ = ∅.

A. D(tobw) Functions under LR, CB and GRU Methods

The LR method in [8] employs a head movement trace to train a linear model for predicting

head movement, which then is mapped into the predicted tiles [11]. The CB method in [11]

predicts the tiles to be requested implicitly, by using the tile requests in an observation window

as contexts and setting the tile requests in the next segment as arms. The GRU method in [31]

employs a sequence of tile requests in an observation window to predict the tile requests in the

future FoVs in a segment where the segment contains only one frame, hence seg-DoO degradates

to DoO.

We consider the real dataset in [22], which contains 500 traces of tile requests from K = 50

users watching 10 VR videos. For the LR and CB methods, we make the prediction with the

dataset and obtain the average seg-DoO. For the GRU method, we use the DoO obtained in [31]

that is also with the dataset in [22].

Speciﬁcally, for the LR and CB method, τ = 0.1 s [11], and we set Tps = 1 s. For each

video, J = 50 traces are used to compute the ground-truth of the average seg-DoO. By making

the prediction with each method using the jth trace as training set, Dj(tobw) can be obtained

DRAFT

August 17, 2020

under different durations of the observation window. Then, for each video, the ground-truth of

the average seg-DoO can be obtained as D(tobw) = 1
J

(cid:80)J

j=1 Dj(tobw), which is ﬁtted in sequel.

17

For the LR method, the ﬁtted function is DLR(tobw) = (cid:80)3

n=0 antn

obw, where {an} are the ﬁtted

coefﬁcients. For the CB method, the ﬁtted function is

DCB(tobw) = a1tobw + a0.

(20)

For the GRU method, τ = 1 s and Tps = 2 s [31]. We take the DoO in [31] as the ground-truth
of D(tobw), for which the ﬁtted function can be obtained as DGRU(tobw) = (cid:80)2

n=0 antn

obw.

To evaluate the ﬁtting performance, we use mean square error (MSE) as the metric that is

widely used in regression analysis, MSE (cid:44) (cid:80)D

d=1

(cid:0)D(tobw,d) − (cid:98)D(tobw,d)(cid:1)2

, where D is the

number of values of tobw, tobw,d is the dth value of tobw, and (cid:98)D(tobw,d) is the ﬁtted value of

D(tobw,d). For the LR and CB methods, tobw is set within [0.1, 1] s, which is equally divided

into D = 28 discrete values. For the GRU method, tobw is set within [1, 2] s, which is equally

divided into D = 4 discrete values [31].

The corresponding ﬁtting parameters for each video and the ﬁtting performance are provided

in Tables I, II, and III, respectively.

TABLE I: LR ﬁtting parameters and ﬁtting performance

Fitting parameters

Video

MSE

a0

a1

a2

a3

1

2

3

4

5

6

7

8

9

0.7101

0.1594

-0.1648

0.0717

9.6782×10−7

0.7274

0.1686

-0.2354

0.1215

7.7358×10−7

0.5773

0.1462

-0.1955

0.1015

7.2133×10−7

0.7305

0.0759

-0.0879

0.0392

2.9301×10−7

0.7276

0.2081

-0.2722

0.1392

9.6005×10−7

0.7155

0.05881

-0.0090

-0.0100

7.0082×10−7

0.7813

0.10309

-0.1231

0.0627

1.1473×10−6

0.6883

0.04294

-0.0484

0.0178

9.9769×10−7

0.7404

0.1499

-0.1802

0.0837

7.3371×10−7

10

0.7309

0.1060

-0.0816

0.0210

1.4887×10−6

August 17, 2020

DRAFT

18

TABLE II: CB ﬁtting parameters and ﬁtting performance

Video

Fitting parameters

a0

a1

MSE

1

2

3

4

5

6

7

8

9

0.7702

0.1242

4.7013×10−6

0.7665

0.1277

4.5542×10−6

0.6903

0.1669

6.6648×10−6

0.7211

0.1544

8.1762×10−6

0.6578

0.1833

7.5323×10−6

0.6680

0.1793

9.1398×10−6

0.7638

0.1343

5.2914×10−6

0.6565

0.1863

9.0814×10−6

0.7183

0.1562

7.1564×10−6

10

0.7008

0.1648

8.4279×10−6

TABLE III: GRU ﬁtting parameters and ﬁtting performance

Video

Fitting parameters

a0

a1

a2

MSE

1

2

3

4

5

6

7

8

9

0.8525

-0.4180

0.1949

1.2312×10−5

0.5764

0.0139

0.0217

1.6985×10−4

0.1242

0.2638

-0.0253

3.2563×10−4

0.6032

-0.1540

0.1307

2.5126×10−7

0.1339

0.6118

-0.1732

2.7362×10−4

0.4739

0.1018

0.0068

2.7362×10−4

1.2081

-0.9462

0.4012

4.2236× 10−4

0.6508

-0.2979

0.1755

1.2161×10−4

0.4786

0.0.2221

-0.0516

3.6181×10−5

10

-0.2761

1.0700

-0.2935

6.2814×10−6

In Fig. 4, we compare the ﬁtting function and the prediction performance D(tobw). For each

method, two curves for the videos with the best and worst ﬁtting performance (highlighted in

the Tables) are presented. We can see that both the functions ﬁt well, and the ﬁtted functions

for all methods on all videos are increasing functions of tobw, which veriﬁes Assumption 1.

Therefore, we use the ﬁtted functions to obtain the prediction performance in the following.

DRAFT

August 17, 2020

19

(a) LR method, Tps = 1 s.

(b) CB method, Tps = 1 s.

(c) GRU method, Tps = 2 s.

Fig. 4: Prediction performance of three existing predictors and corresponding ﬁtting functions.

B. Verify the Feasible Case of the Solution

Now we show that the solutions in (16a), (16b), and (18) are feasible in the case with φ(H) > 0

and Φ = ∅ for the considered three predictors and the real dataset. By substituting DLR(tobw),

DCB(tobw), and DGRU(tobw) into (17a), respectively, we obtain φ(tobw) for the three predictors

as φLR(tobw) = 4a3t3

obw + (3a2 − 3a3Tps)t2

obw + (2a1 − 2a2Tps)tobw + a0 − a1Tps, φCB(tobw) =

2a1tobw + a0 − a1Tps, and φGRU(tobw) = 3a2t2

obw + (2a1 − 2a2Tps)tobw + a0 − a1Tps. Using the

same values of Tps and τ as in subsection V-A, the numerical results with values of T max

cc

ranging

from 0 to 10 s show that φ(H) > 0 always holds.

Then, we can obtain the values of tobw satisfying φ(tobw) = 0 for the CB and GRU methods

respectively as tobw,CB = Tps

2 − a0
2a1

√
, tobw,GRU,1 = 2a2Tps−2a1+

6a2

∆

, and tobw,GRU,2 = 2a2Tps−2a1−

6a2

√

∆

,

where ∆ (cid:44) (2a1 − 2a2Tps)2 − 12a2(a0 − a1Tps). The values of tobw satisfying φ(tobw) = 0 for

the LR method can be obtained via Shengjing’s formula from a cubic equation [33]. Numerical

results show that all these values are either less than zero or complex numbers, which violate

the constraint tobw ≥ max{Tps − T max

cc

, τ } > 0 in (17b). Therefore, Φ = ∅ holds.

C. Relation of T max

cc with Communication and Computing Resources

T max
cc

in (13) characterizes the tradeoff between computing rate (depending on the allocated

computing resource, performance of computing units, and the video contents) and transmission

August 17, 2020

DRAFT

0.10.30.50.70.9173%74%75%76%77%78%Video 10 fitting curveVideo 10  real dataVideo 4 fitting curveVideo 4 real data0.10.30.50.70.9165%70%75%80%85%90%Video 6 fitting curveVideo 6 real dataVideo 2 fitting curveVidoe 2 real data11.31.61.9250%55%60%65%70%75%80%85%90%Video 7 fitting curveVideo 7 real dataVideo 4 fitting curveVideo 4 real data20

rate (depending on the transmit power, bandwidth, the number of antennas, and propagation en-

vironment). To illustrate such a tradeoff, we provide numerical results under different computing

and transmission setups in the following.

We ﬁrst show how to obtain the parameter µr in the computing model in (1) using the measured

values of Tr and other parameters in literature. We consider one video named “Roller Coaster”

in the dataset [22] that has been measured by different GPUs. The measured value of Tr in

[15] for the video is 47.13 ms, where the video are rendered by Nvidia GTX970 GPU under

Maxwell architecture (commercialized in 2015) with Cr = 3.92×1012 FLOPS, Rw = 4096 and

Rh = 2160 [15]. The measured value of Tr for the same video is 4.5 ms in [34], which is

rendered by Nvidia TITAN X GPU under Pascal architecture (commercialized in 2016) with

Cr = 6.691 × 1012 FLOPS, Rw = 2160 and Rh = 1200 [34]. For both results, γfov = 0.2 [22],

b = 12 bits per pixel [30]. Then, we can obtain µr as 1.04×105 and 5.81×104, respectively.

Since there are no measured results for rendering using the latest GPU with Turing architecture

(commercialized in 2018) as in the NVIDA cloudXR solution [27], [28], we roughly estimate µr

from publicized measurement. The gain in terms of reducing µr achieved by a new architecture

can be obtained as Gµr

(cid:44) 1.04×105

5.81×104 = 21.5. By conservatively assuming that µr can be improved in

the same gain [35], we can calculate the value of µr for Turing architecture as µT

r = (¯µM

r )/G2

µr =

2.23 × 103 FLOPs/bit, where ¯µM
r

represents value for the Maxwell architecture obtained by

averaging over the 10 videos in [15], considering that the values of µr differ for videos.

We consider the VR video with 4K resolution in 3840×2160 pixels [36]. The playback duration

of a segment is Tseg = 1 s [36]. Each segment is divided into M = 24 tiles in 4 rows and 6

columns, which can provide a good trade-off between encoding efﬁciency and bandwidth saving

[37]. We set γfov = 0.2 [22] and γextra = 0.1 [30]. Then, the number of predicted tiles is

N = (cid:100)γptM (cid:101) = 8. Each tile has the resolution of rw = 3840/6 = 640, and rh = 2160/4 = 540

pixels [36], the number of tiled-frame in a tile Ntf = 30 [22], b = 12 bits per pixel [30]. To

ensure the QoE of VR users, consider that the tiles are compressed with lossless coding, where

DRAFT

August 17, 2020

21

the compression ratio γc = 2.41 [38]. Hence, the numbers of bits in each tile for transmission and

for rendering are scom = rwrhbNtf/γc = 52 Mbits and scpt = rwrhbNtf = 124 Mbits, respectively.

When the distance between BS and users are identical to dk = 5 m or 201 m (considering

the height of the HMD), the path loss models are 32.4 + 20 log10(fc) + 17.3 log10(dk) in dB [39]

or 32.4 + 20 log10(fc) + 30 log10(dk) in dB [39], the maximal transmit power are P = 24 dBm

[39] (and 20 dBm) or P = 53 dBm [40] (and 46 dBm), and consider Rician channel [41] with

the ratio between the line-of-sight (LoS) and non-LoS channel power as 10 dB [42] or Rayleigh

channel. The carrier frequency is fc = 3.5 GHz, the noise spectral density is -174 dBm/Hz.

The ensemble-average rate Ccom for each user is obtained by averaging over 106 instantaneous

transmission rates. The proactive streaming parameters are Tps = 1 s and τ = 0.1 s, respectively.

The numerical results are provided in Table IV, where cases (a), (b), (d), (e), (f) and (g) are in

prediction-limited region, and cases (c) and (h) are in resource-limited region.

TABLE IV: Numerical examples of T max

cc

under different settings, a GPU with Turing architecture is used

Index K dk(m)

Communication Parameters

Computing Parameters

Nt

P (dBm) B (MHz) Ccom (Gbps)

GPU

Ctotal (FLOPS) Ccpt (Gbps)

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

1

2

4

4

4

1

1

10

5

5

5

5

5

201

201

201

4

4

8

8

8

16

64

64

20

20

20

24

24

46

53

53

40

40

40

150

80

40

40

40

0.88

0.81

0.78

2.85

1.59

0.62

0.79

0.65

T4

P40

P40

P40

8.1×1012

11.7 × 1012

11.7 × 1012

11.7 × 1012

RTX 8000

16.3 × 1012

RTX 8000

16.3 × 1012

T4

T4

8.1×1012

8.1×1012

4.3

3.1

1.6

1.6

2.2

8.7

4.3

0.4

T max
cc

(s)

0.70

0.82

1.16

0.78

0.71

0.78

0.75

2.93

As shown in cases (f) and (g), doubling the computing resource is roughly equivalent to

reducing the communication resource to one fourth. As shown in cases (g) and (h), the system

enters to the resource-limited region as K increases. By comparing cases (a) and (g), we can

see that T max

cc

is smaller for small distance when the available computing resources are identical.

We have also computed T max

cc

using a GPU with Maxwell (i.e., Nvidia GTX970) or Pascal

August 17, 2020

DRAFT

22

architecture (i.e, Nvidia TITAN X) at the MEC server under these settings. The results show

that the system always operates in the resource-limited region even for a single VR user.

D. QoE in the Two Regions

To understand how the QoE is improved by increasing the resources and by improving the

prediction performance, we illustrate the average QoE in the resource-limited and prediction-

limited regions achieved by the LR and CB methods. We set τ = 0.1 s and Tps = 1 s, while

the results for other values of Tps are similar. The average QoE is the average value of the QoE

obtained by substituting (16a) and (16b) into (7), taken over the 10 videos.

(a) QoE achieved by two predictors.

(b) QoE, D(t∗

obw), and S∗

cc(t∗

cc) v.s. T max

cc

, CB method.

Fig. 5: Impact of predictors, prediction performance and CC task completion rate on QoE.

In Fig. 5a, we show the average QoE achieved by two predictors versus the assigned resources

to a user. We observe that the average QoE increases rapidly in the resource-limited region, since

the term Scc(tcom, tcpt) in the QoE metric grows with more resources. By contrast, the average

QoE increases slowly in the prediction-limited region, because the increase of resources only

plays a role of improving D(tobw) with longer observation window by reducing the total duration

for communication and computing. In this region, the CB method outperforms the LR method

in terms of the average QoE. This is because the CB method can achieve better prediction

DRAFT

August 17, 2020

0.0212345020%40%60%80%90%Average QoEResource-limited regionPrediction-limited regionP0.5%5%0.0212345020%40%60%80%100%Resource-limited regionPrediction-limited regionperformance than the LR method, as shown in Fig. 4a and Fig. 4b. Speciﬁcally, consider the

average QoE achieved by the LR method when 1/T max

cc = 2.5, which is the point “P” in the

23

ﬁgure. We can see that increasing the resources from 1/T max

cc = 2.5 to 1/T max

cc = 5 only improves

the average QoE by 0.5%. By contrast, when using the CB method for prediction, the average

QoE is improved by 5%. This indicates that using a better predictor provides much larger gain

than using more resources in the prediction-limited region.

In Fig. 5b, we show how the average QoE is respectively enhanced by improving the prediction

performance and by increasing the CC task completion rate. The value of D(t∗

obw) is obtained by

ﬁrst substituting (16a) into (20) and then being averaged over the 10 videos. The value of S∗

cc(t∗

cc)

is obtained from (18). In the resource-limit region, the average QoE is improved by increasing

the completion rate of CC tasks, while the prediction performance remains constant. In the

prediction-limit region, the average QoE is improved by enhancing the prediction performance,

while the completion rate of CC tasks remains constant.

In Table V, we provide two groups of transmission and computing rates to achieve identical

value of 1/T max

cc

, from which we illustrate how much communication resource or computing

resource are required for further improving the QoE after the boundary line.

TABLE V: Communication and computing rates to achieve three values of 1/T max

cc

in Fig. 5

1/T max
cc

(1/seconds)

Group 1

Group 2

Ccom (Gbps) Ccpt (Gbps) Ccom (Gbps) Ccpt (Gbps)

0.02

1.1 (Boundary line)

5

3.5

3.5

3.5

0.2

1.0

12.1

0.1

0.4

4.8

8.7

8.7

8.7

E. QoE Gain from Optimizing tobw and tcc

We evaluate the performance gain from optimizing tobw and tcc, which is with legend “Opt

duration”, in terms of the average QoE taken over the 10 videos, by comparing with the

following three schemes without duration optimization. (1) Tcc = Tobw = Tps/2, which is

August 17, 2020

DRAFT

24

with legend “1:1 duration”. (2) Tobw = Tps/3, Tcc = 2Tps/3, i.e., more time is allocated

for communication and computing, which is with legend “1:2 duration”. (3) Tobw = 2Tps/3,

Tcc = Tps/3, i.e., more time is allocated for prediction, which is with legend “2:1 duration”.

The QoE for each video is obtained by substituting (16a) and (16b) with the ﬁtted function

for each video into (8a). The average QoE achieved by the CB and LR methods are provided in

Fig. 6. As expected, the optimal solution always yields the best performance. Speciﬁcally, we

observe the following results. (1) As the conﬁgured resources increase in the resource-limited

region, the gain of the optimal solution over the three baselines becomes larger and achieves the

maximum on the boundary line. As the resources further increase, the gain becomes smaller. This

is because in this region, the scheme with more time for communication and computing yields

better performance. The optimal solution allocates largest value of tcc, thus can compute and

deliver most predicted tiles among the four schemes. When the conﬁgured resources achieve the

boundary line, the optimal solution can compute and deliver all the predicted tiles and begins to

enter into the prediction-limited region, while the three baselines are still in the resource-limited

region. The reason that the gain of the optimal solution becomes smaller after the boundary

line is two-fold. On the one hand, for the optimal solution, the QoE increases slowly in the

prediction-limited region. On the other hand, the baselines are still in the resource-limited region,

so that increasing the conﬁgured resources can increase the QoE rapidly. (2) As the conﬁgured

resources increase, the QoE achieved by the three non-optimized schemes ﬁrst increases then

remains constant, while the QoE achieved by the optimal solution still increases. This is more

clear in Fig. 6(a). The reason that the QoE keeps constant for the baselines is that they are

in the prediction-limited region but still employ ﬁxed duration for prediction. On the contrary,

the optimal solution allocates more time to the observation window for assisting the prediction,

thus the QoE can be further improved. (3) For the optimal solution, the case with smaller Tps

shown in Fig. 6(b) and Fig. 6(d) needs more resources to achieve the boundary line, compared

to the case with larger Tps in Fig. 6(a) and Fig. 6(c). This is because when Tps is smaller,

DRAFT

August 17, 2020

cc = Tps − τ is smaller, and 1/T max
T max

cc

is larger, i.e., more resources need to be conﬁgured

to achieve the boundary line. (4) For the average QoE, the gain of the CB method is higher

than the gain of the LR method after the boundary line, because the CB method yields better

prediction as shown in Fig. 5a.

25

(a) Tps = 1s, CB method.

(b) Tps = 0.5s, CB method.

(c) Tps = 1s, LR method.

(d) Tps = 0.5s, LR method.

Fig. 6: Performance comparison on average QoE.

To show the impact of the number of the VR users on the QoE, we provide simulation with

the same channel as in the 201 m cases of Table IV where the users are with identical distance.

The transmit power is P = 53 dBm [40], Nt = 64, B = 100 MHz. A NVIDIA RTX 8000

GPU is used for rendering, where the computing resource Ctotal = 16.3 × 1012 FLOPS is equally

August 17, 2020

DRAFT

012345020%40%60%80%90%Average QoE3.5480%16%29%43%012345020%40%60%80%Average QoE11%26%41%012345020%40%60%80%Average QoE16%29%43%012345020%40%60%80%Average QoE12%26%41%26

allocated among users. Then,

1
T max
cc

for each user is identical.

Fig. 7: Average QoE per user v.s. K, Tps = 1 s and τ = 0.1 s, CB method

As shown in Fig. 7, the optimal solution always yields the best performance as expected. The

achieved QoE decreases ﬁrst slowly with K. This is because the optimal solution falls in the

prediction-limited region when the number of users is small such that the resource reduction

has little impact on the QoE, meanwhile the optimal solution can still exploit resources to

improve the QoE even in this region thereby the reduced resources degrades the QoE. As the

resources further decreases, the “Optimal duration” enters the resource-limited region, and the

QoE decreases rapidly. The QoE of baseline “1:2 duration” ﬁrst remains unchanged and then

decreases with K. This is because all the predicted tiles can be computed and transmitted with

such durations and thus the baseline is in the prediction-limited region, which cannot use the

extra resources and hence the achieved QoE is not affected by the reduced resources. The QoE

of other two baselines (i.e., “1:1 duration” and “2:1 duration”) decrease rapidly with K, because

they lie in the resource-limited region.

VI. CONCLUSIONS

In this paper, we studied how to match the communication and computing performance with the

prediction performance to maximize the QoE of proactive tile-based VR streaming. To this end,

we jointly optimized the durations for communication and computing with given transmission and

DRAFT

August 17, 2020

124681020%40%60%80%85%Average QoE/user16%28%41%27

computing rates and the duration of the observation window for prediction given any predictor.

With a reasonable assumption, we obtained the closed-form optimal solution, from which we

found a resource-limited region where the QoE can be rapidly improved by conﬁguring more

resources, and a prediction-limited region where designing better predictor is more effective in

improving QoE. Simulations with three existing tile predictors and a real dataset validated the

employed assumption, and demonstrated the performance gain from jointly optimizing durations

for communication, computing and prediction.

APPENDIX A

PROOF OF THE SOLUTION OF PROBLEM (11)

The Karush-Kuhn-Tucker (KKT) conditions of problem (11) can be expressed as

Ccom
scomN

λ1 −

Ccpt
scptN

λ2 = 0,

−1 + λ1 + λ2 + λ3 = 0,

(cid:0)Scc(tcc) −

λ1

Ccom(tcc − tcpt(tcc))
scomN
Ccpttcpt(tcc)
scptN

(cid:1) = 0,

(cid:1) = 0,

(cid:0)Scc(tcc) −

λ2

(cid:0)Scc(tcc) − 1(cid:1) = 0,

λ3

(11b) − (11d), λ1, λ2, λ3 ≥ 0.

(A.1a)

(A.1b)

(A.1c)

(A.1d)

(A.1e)

(A.1f)

From (A.1a), we obtain that both λ1 and λ2 are either positive or equal to zero, thus there

are two cases.

When λ1, λ2 > 0, from (A.1c) and (A.1d) we have
(cid:0)tcc − tcpt(tcc)(cid:1)

Ccom

Scc(tcc) =

scomN

=

Ccpttcpt(tcc)
scptN
CcomscptN

.

(A.2)

We can obtain tcpt(tcc) from (A.2) as tcpt(tcc) =

CcomscptN +CcptscomN tcc. Upon substituting

into (A.2), we have Scc(tcc) =

CcomCcpt

CcomscptN +CcptscomN tcc. Upon substituting into (11d), we have

CcomCcpt

CcomscptN +CcptscomN tcc ≤ 1, and after some regular derivations, we obtain tcc ≤ scomN

Ccom

August 17, 2020

+ scptN
Ccpt

.

DRAFT

28

When λ1, λ2 = 0 from (A.1b), we have λ3 = 1 > 0. From (A.1e), we have Scc(tcc) = 1. Upon

substituting into (11c) and (11b), we obtain

tcpt(tcc) ≥

tcc ≥

,

scptN
Ccpt
scomN
Ccom

+ tcpt(tcc).

(A.3a)

(A.3b)

By substituting (A.3a) into (A.3b), we obtain tcc ≥ scomN
Ccom

+ scptN
Ccpt

. From these two cases, the

solution of problem (11) can be obtained.

APPENDIX B

PROOF OF THE SOLUTION OF PROBLEM (15)

By eliminating the variable tcc = Tps − tobw, problem (15) becomes

min
tobw

−D(tobw)

(Tps − tobw)
T max
cc

s.t. Tps − tobw ≤ T max

cc

,

− tobw ≤ −τ.

The KKT conditions of problem (B.1) can be expressed as

D(cid:48)(tobw)(Tps − tobw) − D(tobw) + λ1 + λ2 = 0,

λ1(Tps − tobw − T max

cc

) = 0,

λ2(τ − tobw) = 0,

(B.1b), (B.1c), λ1, λ2 ≥ 0,

(B.1a)

(B.1b)

(B.1c)

(B.2a)

(B.2b)

(B.2c)

(B.2d)

where D(cid:48)(tobw) is the derivative function of D(tobw).

There are four cases in the KKT conditions. (1) When λ1 > 0, λ2 = 0, we have tobw =

cc

Tps − T max
where φ(tobw) = (cid:80)∞

from (B.2b), Tps − T max

cc ≥ τ from (B.1c), and we obtain φ(tobw) > 0 from (B.2a)

n=0 antn

obw − ((cid:80)∞

n=1 nantn−1

obw )(Tps − tobw). (2) When λ1 = 0, λ2 > 0, we

DRAFT

August 17, 2020

29

have tobw = τ from (B.2c), τ ≥ Tps − T max

cc

from (B.1b), and φ(tobw) > 0 from (B.2a). (3)

When λ1 > 0, λ2 > 0, we have tobw = Tps − T max

cc

from (B.2b), Tps − T max

cc = τ from (B.1c),

and φ(tobw) > 0 from (B.2a). (4) When λ1 = 0, λ2 = 0, we obtain tobw ≥ max{Tps − T max

cc

, τ }

from (B.1b) and (B.1c), and φ(tobw) = 0 from (B.2a). Since the monotonicity of φ(tobw) is

unknown, there are three cases in the solutions of φ(tobw) = 0: i) multiple different values, ii)

only one value, iii) no real number value. Besides, the solutions of φ(tobw) = 0 should satisfy

tobw ≥ max{Tps − T max

cc

, τ }. In the above feasible solutions, we ﬁnd the optimal solution that

maximizes the objective function in (B.1a). Thus we consider the following problem

max
tobw

f (tobw) (cid:44) D(tobw)

(Tps − tobw)
T max
cc

s.t. φ(tobw) = 0,

tobw ≥ max{Tps − T max

cc

, τ }.

(B.3a)

(B.3b)

(B.3c)

The feasible set of problem (B.3) can be expressed as

Φ (cid:44) {tobw|φ(tobw) = 0, tobw ≥ max{Tps − T max

cc

, τ }}.

(B.4)

When Φ is not an empty set, i.e., at least one value of tobw can satisfy φ(tobw) = 0 and

tobw ≥ max{Tps − T max

cc

, τ }, the optimal solution can be obtained as

T ∗
Φ = argmax

tobw

f (tobw), tobw ∈ Φ,

(B.5)

by exhaustive searching. Since the number of feasible solutions (i.e., |Φ|) is ﬁnite, the complexity

of searching is acceptable. When Φ is an empty set, no feasible solution in this case.

From the ﬁrst three cases, we can obtain that

tobw = H = max{Tps − T max

cc

, τ }, if φ(H) > 0.

From the fourth case, we can obtain that tobw = T ∗

Φ, if Φ (cid:54)= ∅.

August 17, 2020

(B.6)

DRAFT

30

When only one of the two cases holds, i.e., φ(H) > 0 and Φ = ∅, or φ(H) = 0 and Φ (cid:54)= ∅,

the solution is

t∗
obw =






H, φ(H) > 0 and Φ = ∅,

T ∗
Φ, φ(H) = 0 and Φ (cid:54)= ∅.

(B.7)

When both cases hold, i.e., φ(H) > 0 and Φ (cid:54)= ∅, we can obtain the solution by comparing

the objective function in the two cases. Then, the solution is

t∗
obw =






H, φ(H) > 0, Φ (cid:54)= ∅ and f (H) ≥ f (T ∗

Φ),

Φ, φ(H) > 0, Φ (cid:54)= ∅ and f (H) < f (T ∗
T ∗

Φ).

(B.8)

The case that φ(H) = 0 and Φ = ∅ does not exist. This is because by substituting φ(H) = 0

into (B.4), at least one value tobw = H can be found in Φ. Thus, Φ (cid:54)= ∅, and this case can be

omitted.

From (B.7) and (B.8), the solution of t∗

obw can be obtained as in (16a). By substituting t∗

obw

into tcc = Tps − tobw, the solution of t∗

cc can be obtained as (16b).

REFERENCES

[1] Virtual Reality (VR) Media Services Over 3GPP, 3GPP Std. document TR 26.918, Mar. 2018.

[2] E. Bastug, M. Bennis, M. Medard, and M. Debbah, “Toward interconnected virtual reality: Opportunities, challenges, and

enablers,” IEEE Commun. Mag., vol. 55, no. 6, pp. 110–117, June 2017.

[3] VR

Lens

Lab,

“Field

of

view for

virtual

reality

headsets

explained,”

https://vr-lens-lab.com/

ﬁeld-of-view-for-virtual-reality-headsets/.

[4] M. Hosseini and V. Swaminathan, “Adaptive 360 VR video streaming: Divide and conquer,” IEEE ISM, 2016.

[5] C.-L. Fan, W.-C. Lo, Y.-T. Pai, and C.-H. Hsu, “A survey on 360◦ video streaming: Acquisition, transmission, and display,”

ACM Comput. Surv., vol. 52, no. 4, Aug. 2019.

[6] Huawei,

“Whitepaper

on

the VR-oriented

bearer

network

requirement,” Huawei

Technologies CO.,

LTD., Tech. Rep., 2016.

[Online]. Available: https://www.huawei.com/en/industry-insights/technology/white-papers/

whitepaper-on-the-vr-oriented-bearer-network-requirement

[7] M. S. Elbamby, C. Perfecto, M. Bennis, and K. Doppler, “Toward low-latency and ultra-reliable virtual reality,” IEEE

Netw., vol. 32, no. 2, pp. 78–84, 2018.

[8] F. Qian, L. Ji, B. Han, and V. Gopalakrishnan, “Optimizing 360 video delivery over cellular networks,” ACM SIGCOMM

Workshop, 2015.

DRAFT

August 17, 2020

31

[9] M. Zink, R. Sitaraman, and K. Nahrstedt, “Scalable 360◦ video stream delivery: Challenges, solutions, and opportunities,”

Proceedings of the IEEE, vol. 107, no. 4, pp. 639–650, 2019.

[10] C. Fan, S. Yen, C. Huang, and C. Hsu, “Optimizing ﬁxation prediction using recurrent neural networks for 360◦ video

streaming in head-mounted virtual reality,” IEEE Trans. Multimedia, vol. 22, no. 3, pp. 744–759, March 2020.

[11] W. Xing and C. Yang, “Tile-based proactive virtual reality streaming via online hierarchial learning,” APCC, 2019.

[12] M. Xu, Y. Song, J. Wang, M. Qiao, L. Huo, and Z. Wang, “Predicting head movement in panoramic video: A deep

reinforcement learning approach,” IEEE Trans. Pattern Anal. Machine Intell., vol. 41, no. 11, pp. 2693–2708, Nov 2019.

[13] J. Heyse, M. T. Vega, F. de Backere, and F. de Turck, “Contextual bandit learning-based viewport prediction for 360

video,” IEEE VR, 2019.

[14] C. Li, W. Zhang, Y. Liu, and Y. Wang, “Very long term ﬁeld of view prediction for 360-degree video streaming,” IEEE

MIPR, 2019.

[15] W. Lo, C. Huang, and C. Hsu, “Edge-assisted rendering of 360 videos streamed to head-mounted virtual reality,” IEEE

ISM, 2018.

[16] X. Yang, Z. Chen, K. Li, Y. Sun, N. Liu, W. Xie, and Y. Zhao, “Communication-constrained mobile edge computing

systems for wireless virtual reality: Scheduling and tradeoff,” IEEE Access, vol. 6, pp. 16 665–16 677, 2018.

[17] C. Guo, Y. Cui, and Z. Liu, “Optimal multicast of tiled 360 VR video in ofdma systems,” IEEE Commun. Lett., vol. 22,

no. 12, pp. 2563–2566, Dec 2018.

[18] M. Chen, W. Saad, and C. Yin, “Virtual reality over wireless networks: Quality-of-service model and learning-based

resource management,” IEEE Trans. Commun., vol. 66, no. 11, pp. 5621–5635, Nov 2018.

[19] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, caching, and computing for mobile virtual reality: Modeling and

tradeoff,” IEEE Trans. Commun., vol. 67, no. 11, pp. 7573–7586, Nov 2019.

[20] T. Dang and M. Peng, “Joint radio communication, caching, and computing design for mobile virtual reality delivery in

fog radio access networks,” IEEE J. Select. Areas Commun., vol. 37, no. 7, pp. 1594–1607, July 2019.

[21] HTC vive, “the introduction of vive pro eye,” https://enterprise.vive.com/us/product/vive-pro-eye/.

[22] W.-C. Lo, C.-L. Fan, J. Lee, C.-Y. Huang, K.-T. Chen, and C.-H. Hsu, “360◦ video viewing dataset in head-mounted

virtual reality,” ACM MMSys, 2017.

[23] Y. Xu, Y. Dong, J. Wu, Z. Sun, Z. Shi, J. Yu, and S. Gao, “Gaze prediction in dynamic 360◦ immersive videos,” IEEE/CVF

CVPR, 2018.

[24] X. Hou, S. Dey, J. Zhang, and M. Budagavi, “Predictive adaptive streaming to enable mobile 360-degree and VR

experiences,” IEEE Trans. Multimedia, early access, 2020.

[25] X. Hou, J. Zhang, M. Budagavi, and S. Dey, “Head and body motion prediction to enable mobile VR experiences with

low latency,” IEEE GLOBECOM, 2019.

[26] NVIDIA,

“NVIDIA Turing GPU architecture whitepaper,” NVIDIA Corporation., Tech. Rep., 2018.

[On-

August 17, 2020

DRAFT

32

line]. Available: https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/

NVIDIA-Turing-Architecture-Whitepaper.pdf

[27] ——, “NVIDIA CloudXR cuts the cord for VR, raises the bar for AR,” https://blogs.nvidia.com/blog/2020/05/14/

cloudxr-sdk.

[28] ——, “NVIDIA RTX server,” https://www.nvidia.com/en-us/design-visualization/quadro-servers/rtx.

[29] ——, “CUDA FAQ,” https://developer.nvidia.com/cuda-faq/.

[30]

iLab, “Cloud VR network solution whitepaper,” Huawei Technologies CO., LTD., Tech. Rep., 2018. [Online]. Available:

https://www.huawei.com/minisite/pdf/ilab/cloud vr network solution white paper en.pdf

[31] C. Perfecto, M. S. Elbamby, J. Del Ser, and M. Bennis, “Taming the latency in multi-user VR 360°: A QoE-aware deep

learning-aided multicast framework,” IEEE Trans. Commun., vol. 68, no. 4, pp. 2491–2508, 2020.

[32] C. She and C. Yang, “Energy efﬁcient resource allocation for hybrid services with future channel gains,” IEEE Trans.

Green Commun. Netw., vol. 4, no. 1, pp. 165–179, 2020.

[33] S. Fan, “A new extracting formula and a new distinguishing means on the one variable cubic equation,” Nat. Sci. J. Hainan

Teach. Coll, vol. 2, no. 2, pp. 91–98, 1989.

[34] L. Liu, R. Zhong, W. Zhang, Y. Liu, J. Zhang, L. Zhang, and M. Gruteser, “Cutting the cord: Designing a high-quality

untethered VR system with low latency remote rendering,” ACM MobiSys, 2018.

[35] BoostClock, “GPU rendering ft Turing vs Pascal vs Maxwell - GTX 1660 Ti — RTX 2060-2070-2080(Ti) — GTX

980(Ti)-1080(Ti),” http://boostclock.com/show/000255/gpu-rendering-nv-maxwell-pascal-turing.html/.

[36] A. Mahzari, A. T. Nasrabadi, A. Samiei, and R. Prakash, “FoV-aware edge caching for adaptive 360 video streaming,”

ACM MM, 2018.

[37] M. Graf, C. Timmerer, and C. Mueller, “Towards bandwidth efﬁcient adaptive streaming of omnidirectional video over

HTTP: Design, implementation, and evaluation,” ACM MMSys, 2017.

[38] M. Zhou, W. Gao, M. Jiang, and H. Yu, “HEVC lossless coding and improvements,” IEEE Trans. Circuits Syst. Video

Technol., vol. 22, no. 12, pp. 1839–1843, 2012.

[39] ETSI TR 138 901 V14.3.0: 5G; Study on channel model for frequencies from 0.5 to 100 GHz, 3GPP Std. 3GPP TR 38.901

version 14.3.0 release 14, 2018.

[40] Electromagnetic ﬁeld compliance assessments for 5G wireless networks, ITU Std. K.Sup16, May 2019.

[41] S. Jin, W. Tan, M. Matthaiou, J. Wang, and K. Wong, “Statistical eigenmode transmission for the MU-MIMO downlink

in Rician fading,” IEEE Trans. Wireless Commun., vol. 14, no. 12, pp. 6650–6663, 2015.

[42] X. Li, S. Jin, H. A. Suraweera, J. Hou, and X. Gao, “Statistical 3-D beamforming for large-scale MIMO downlink systems

over Rician fading channels,” IEEE Trans. Commun., vol. 64, no. 4, pp. 1529–1543, 2016.

DRAFT

August 17, 2020

