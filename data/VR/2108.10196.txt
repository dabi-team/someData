1
2
0
2

g
u
A
3
2

]

C
H
.
s
c
[

1
v
6
9
1
0
1
.
8
0
1
2
:
v
i
X
r
a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

The ”Kinesthetic HMD”:
Enhancing Self-Motion Sensations in VR
with Head-Based Force Feedback.

Antoine Costes, Anatole L ´ecuyer

Abstract—The sensation of self-motion is essential in many virtual reality applications, from entertainment to training, such as ﬂying
and driving simulators. If the common approach used in amusement parks is to actuate the seats with cumbersome systems,
multisensory integration can also be leveraged to get rich effects from lightweight solutions. In this short paper, we introduce a novel
approach called the ”Kinesthetic HMD”: actuating a head-mounted display with force feedback in order to provide sensations of
self-motion. We discuss its design considerations and demonstrate an augmented ﬂight simulator use case with a proof-of-concept
prototype. We conducted a user study assessing our approach’s ability to enhance self-motion sensations. Taken together, our results
show that our Kinesthetic HMD provides signiﬁcantly stronger and more egocentric sensations than a visual-only self-motion
experience. Thus, by providing congruent vestibular and proprioceptive cues related to balance and self-motion, the Kinesthetic HMD
represents a promising approach for a variety of virtual reality applications in which motion sensations are prominent.

Index Terms—Virtual reality, force feedback, haptics, vection, simulator.

(cid:70)

1 INTRODUCTION

W ITH the blossoming of virtual reality (VR) consumer-

grade devices in the last ﬁve years, numerous appli-
cations for VR bloomed in the entertainment, healthcare and
manufacturing industries [14]. Impressive advances were
achieved in visual and audio quality, with audio spatial-
ization being now common place and human-eye resolution
about the be reached [1]. However, although VR experiences
are often praised as ”fully immersive”, bodily sensations
are still largely missing, while they are crucial for several
aspects of user experience [22].

The perception of self-motion, in particular, can be in-
duced visually but relies on multisensory cues, and notably
on vestibular cues, i.e. acceleration and motion applied to
the head [5]. Although visual cues are usually more precise
for perceiving displacement, in some cases they can be
dominated by vestibular cues [13] [10].

This perceptual discrepancy leads to cybersickness ef-
fects as well as user disinvestment (in particular for whole-
body displacement such as vehicle driving, ﬂying, falling,
etc), both of which are major issues in many VR applica-
tions. As a result, VR content producers tend to adapt to
those technological limitations instead of ﬁtting the best
possible user experience. The most stunning example is
probably the use of teleportation as a relatively standard
locomotion system, despite huge design efforts for other
metaphors with better realism and ecological agency [3].
In order to address this lack of physical sensations, over
the last years both researchers and industrialists proposed
a large number of haptic VR peripherals (see [30] for a

• Antoine Costes was with Inria, Univ Rennes, CNRS, IRISA, France.

E-mail: see http://www.antoinecostes.net

• Anatole L´ecuyer was with Inria, Univ Rennes, CNRS, IRISA, France.

E-mail: anatole.l´ecuyer@inria.fr

Manuscript received April 19, 2005; revised August 26, 2015.

Fig. 1. The Kinesthetic HMD: head-based force feedback enhancing
self-motion sensations.

review).

Yet only a subset of them addressed motion sensations.
If the common approach used in amusement parks is to
actuate the seats with cumbersome systems, multisensory
integration can also be leveraged to get rich effects from
lightweight solutions [8] [18].

In this short paper, we propose a novel approach called
the ”Kinesthetic HMD” to enhance self-motion sensations in
immersive VR applications. It consists in actuating a head-
mounted display (HMD) with force feedback in order to

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

provide rich and versatile self-motion effects. Similarly to
a motion platform, our approach provides motion cues to
the user, but at the level of his/her head, so to simulate
whole-body accelerations and enhance illusory self-motion.
In contrast with actuated seats, the Kinesthetic HMD stimu-
lates the vestibular system rather than the whole body.

In the remainder of this paper, we ﬁrst present related
work on VR peripherals providing motion sensations. Then,
the Kinesthetic HMD approach is introduced and its hard-
ware, software and safety design is discussed. We demon-
strate a ﬂight simulator use case with a proof-of-concept
prototype featuring a high-end grounded 6-DoF (degrees of
freedom) haptic arm. Then we present a user study focusing
on the haptic enhancement of visual self-motion sensations,
before ﬁnally discussing our experimental results and pos-
sible future works.

2 RELATED WORK

Although “vection” (illusory self-motion) was historically
considered as a visual illusion, it can be deﬁned more
broadly as a subjective conscious experience of self-motion”
[20]. Its correlations with presence and immersion are stud-
ied, yet their relationship remain unclear [21] [23] [28].
It was found that exposure to vection in VR modulates
vestibular processing [11].

The vestibular system provides information about the
angular rotation speed and linear acceleration of the head in
space, which are crucial for self-motion estimation [7]. The
relationship between visual and vestibular contributions to
motion sensations is still not fully understood [5], and they
seem to be dynamically reweighted [10]. Yet it can be said
that the visual system is specialized for position and velocity
estimation, while the vestibular system is optimized for
acceleration processing.

This explains why the visual motion provided by a
HMD, despite its ability to evoke illusory displacement,
remains ”incomplete” and not sufﬁcient to provide com-
pelling inertial sensations. In order to get physical sen-
sations, there is a need for physical stimulation. Haptic
devices provide kinesthetic and/or tactile stimulation. The
vast majority of haptic solutions for VR are either wearable,
holdable or grounded, and stimulate the ﬁnger or the hand
in order to reproduce contact mechanics, material properties
and physics of digital interaction (see [30] for a review).
Much less addressed self-motion sensations.

One approach to induce vection is to stimulate a large
part of the skin, usually by integrating vibrators in a chair
[26]. Yet the most common technological solution is to
provide actual motion to the seat: moving seats are usually
found in amusement arcades for racing games and in theme
parks for so-called 4D cinemas [2]. Those systems being
usually cumbersome and expensive, and yet limited by a
restricted amplitude, several researchers proposed simpli-
ﬁed versions relying on illusions or sensory substitution [25]
[27]. In particular, Danieau et al. proposed to afﬁx multiple
force-feedback devices to a chair, stimulating speciﬁc parts
of the body (hands and head), in order to provide inexpen-
sive 6-DoF motion effects [8].

2

achieve rich effects with a minimalist setup. It was shown
that a haptic stimulation of the feet could induce self-
motion sensations while standing still in various virtual
reality scenes [18], and modulates vection even in a seated
position [9] [16]. L´ecuyer et al. investigated the perception
improvement of visual turns by reproducing the turn angle
(or its opposite) through a haptic handle [17]. Ouarti et
al. used a similar setup to show that a haptic feedback
in the hands could improve duration and occurrence of
visually-induced illusory self-motion for linear and curved
trajectories [19]. Bouyer et al. extended this approach to an
interactive video game context [4].

HMD-embedded haptics is a quite recent research topic.
Peng et al. showed that step-synchronized vibrotactile stim-
uli on the head could signiﬁcantly reduce cybersickness
[36], while Wolf et al. proposed to combine vibrotactile
and thermal feedback inside the HMD for an increased
presence [37]. Gugenheimer et al. attached ﬂywheels to
an Oculus Rift DK2 to generate torque feedback on the
head [12]. A major drawback of this solution is the lack
of transparency, as when the ﬂywheel turns faster it builds
up inertia against user’s movements. Kon et al. suggested
to leverage the intriguing so-called ”hanger reﬂex” effect,
which is an involuntary head rotation arising from a speciﬁc
pressure distribution, in order to provide various illusory
forces [15]. However this technique does not allow precise
force rendering as it relies on muscular reﬂex that is likely
to vary a lot among individuals. Chang et al. proposed a
pulley-based mechanism to produce normal force on the
HMD [6]. This system could improve immersion in boxing
or swimming simulations, but did not aim at generating
self-motion sensations. Finally, Wang et al. integrated skin-
stretch modules inside a HTC Vive Pro to provide haptic
feedback on the user’s face [29]. In a motorcycle racing
simulation context, their system would simulate weight,
bumping transients, inertial turns, and wind pressure. How-
ever, to our knowledge, grounded force feedback was never
applied to a VR headset.

3 THE KINESTHETIC HMD APPROACH
3.1 Concept

The Kinesthetic HMD is a novel approach to enhance self-
motion sensations in virtual reality with head-based force
feedback. It can be viewed as an augmentation of the
HMD, adding precise forces and displacement to images
and sound provided to the head. The generated vestibu-
lar and proprioceptive cues emphase the visual motion to
produce stronger and more compelling sensations of begin
accelerated, although the user, standing or seated, remains
in the same place.

The force feedback should be congruent with visual mo-
tion, for instance being proportional to ego-acceleration. Yet
the rendering algorithm can be adapted to the locomotion
context. When the user walks virtually, the haptic device can
simulate head movements in compliance with the walking
pace. When the user gets in virtual car and drives, the
force feedback can push or pull to simulate acceleration and
braking.

Applying haptic stimulation on speciﬁc regions of the
body (feet, hand or head) is indeed a promising approach to

The Kinesthetic HMD approach requires at least four
components: a force-feedback device, a VR headset, a head

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

clamping part transmitting the forces, and a software plat-
form for VR content and haptic rendering. Such a system
implies hardware, software as well as safety considerations,
detailed in the reminder of this section.

3.2 Hardware considerations

Applying force feedback to the head raises a number of
technical challenges, especially as producing vestibular cues
requires steady directional forces, able to move the head
relatively to the thorax in one to three directions. First,
the actuator should beneﬁt of adequate backing. Second,
the system should be comfortable enough not to break
immersion. Lastly, the forces should be correctly transmitted
to the head.

Backing Most force feedback devices requires back-
ing, either on the body (wearable) or on a ﬁxed frame
(grounded). Backing on the shoulders (or any body part
other than the head) is complicated because of their mo-
bility relatively to the head. Holdable devices, which could
be totally embedded on a helmet, come with signiﬁcant
limitations like motion impediment and saturation (reaction
wheels and weight shifting devices), or buzzing (asymmet-
ric vibrations). Moreover their force capability is directly
limited by their moving mass, and therefore their carrying
weight.

Comfort The head is more sensitive than other body
parts to noise, motion restriction or extra weight. Therefore
mechanical actuators should ideally be properly isolated, or
departed from the point of application. Also, the mechanical
transmission should not present any risk of wrong move-
ments for the neck.

Point of application The force feedback should not only
be produced, but also properly transmitted, and choosing
the adequate clamping system can be an issue.. The clamp-
ing part should not slip on the head, yet it should remain
comfortable. Pressure should be limited and therefore area
of contact maximized, but avoiding ears or any sensitive
part. Even with a capable device, producing a constant
directional force on the head is challenging because when
the head rotates the alignment with its mass center is easily
lost, resulting in unwanted counter torques.

3.3 Software considerations

Designing the proper self-motion rendering algorithms for
head-based force feedbacl is not straight-forward for several
reasons, detailed in this subsection. First, the haptic stimulus
should act as a metaphor, as we want the user to feel an
illusory whole-body motion. Second, the provided forces
and displacement should ensure safety and all values are
not acceptable. The consequent ﬁltering can impede realism,
especially for real-time interactive content that is not known
in advance. Third, the effect of the force feedback might
depend on the user’s position, which should be taken in
account in the rendering loop.

Haptic rendering Several authors used velocity-based
vestibular feedback to study vection [34] [35], but a com-
parative study suggested that acceleration is a better choice,
producing stronger and more consistent illusory self-motion
sensations [19]. Another advantage of acceleration over ve-
locity is that the summed amplitude over time is lower, and

3

Fig. 2. Flight simulation use case: the force feedback is inversely pro-
portional to visual acceleration.

thus is less prone to workspace limitation issues. Among
possible haptic metaphors, two were pointed out by previ-
ous works: the direct mode and the indirect mode [17] [4]. In
the direct mode, the haptic feedback is proportional to visual
acceleration: this means if the virtual vehicle speeds up,
the haptic device will push forwards, simulating physical
acceleration. In the indirect mode, the haptic feedback is
inverted: when the virtual vehicle speeds up the haptic
device will pull backwards, simulating the physical body
displacement.

Interactivity Just like the visual content, the haptic
effects can be fully interactive (i.e. generated from user
input), pre-recorded (i.e. experienced passively), or a mix
of both (i.e. actively triggered or modulated). Pre-recorded
content can be analyzed and scaled to mitigate extreme val-
ues while preserving realism. Fully interactive experiences
might require thorough real-time ﬁltering, depending on the
content. Trade-offs can be found with hybrid strategies, for
instance triggering a pre-recorded sequence only when the
user reaches the adequate part of the workspace.

Motion ﬁltering As our force feedback is expected to
move the head, the user will lean (assuming they stay in
the same position). The leaning amplitude will be limited
either by the user’s anatomy or the haptic device’s capabil-
ities. Just like with actuated seats, the rendering algorithms
should avoid reaching the edges of the workspace, and
eventually come back towards the center below perceptual
thresholds, which can be achieved with so-called ”washout
ﬁlters” [38]. One potential issue in the context of head-
based haptic rendering is to determine which perceptual
thresholds (vestibular or proprioceptive) to consider.

3.4 Safety considerations

Respecting anatomical limits and avoiding any risk of injury
is of course a major requirement for any haptic setup, and
even more when applied on the head. Although deﬁning
general-case safe limits is tricky, an order of magnitude of
100N seem to be a low value both for neck muscular force in
any direction for healthy adults [32] and for neck loadings
involved by common non-injurious physical activities [33].
Thus, values of one order of magnitude lower (dozens of
N ) might be considered for the maximal applied forces in
healthy and warmed-up adults. In addition to limiting the
total applied force, we suggest to limit the applied jerk (to
avoid false moves), to have a hardware kill switch, and to

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

4

a virtual cylinder joint along the direction of the applied
force. When the forces were lower than 1N there were no
applied torques in order to let the head free to move.

Another advantage of ﬂight simulation softwares is that
they allow for recording and replaying scenarios. Therefore
the user can choose between the intense experience of a
fully interactive ﬂight, or the comfort of a pre-recorded
ﬂight without the stress of manoeuvring the aircraft. In both
cases, the force feedback is rendered in real-time from the
acceleration values output.

No ”washout ﬁlter” was implemented as applied forces
usually lasted only a few seconds and were limited to 10N ,
so the user would not reach the edges of the workspace
during our scenario.

4.3 Safety considerations

The Virtuose arm has a hardware security switch usually
controlled by a proximity sensor integrated to the handle,
so that force feedback is disabled whenever the handle is
not held. We replaced it with a mechanical button acting
as a kill switch that could be held either by the user or the
experimenter. We limited the total applied force to 10N . The
gain factor between visual acceleration and applied forces
could also be reﬁned upon user request to adjust experience
intensity.

5 USER STUDY

In order to evaluate our system’s ability to enhance visually-
induced self-motion sensations, we conducted a user study
comparing the motion sensations evoked by visual and
visuo-haptic displacement stimuli. On the basis of Ouarti
et al.’s results, we chose to focus on acceleration-based
haptic rendering, and also to evaluate both direct mode and
indirect mode, as Ouarti et al. suggested that half the people
would prefer one and half the people the other [19].

5.1 Hypotheses and objectives

In the context of virtual reality applications, we are not only
interested in strengthening motion sensations, but also mak-
ing them more compelling. That is, providing an illusory
self-motion experience rather than a ”scrolling landscape”
feeling. In other words, we want the motion to be felt as
more egocentric (self-motion rather than landscape motion)
as well as more intense (with vivid bodily sensations). Com-
fort should also be considered, as visuo-haptic discrepancy
can produce immersion-breaking awkwardness if they are
not congruent.

Therefore we designed several displacement stimuli and

evaluated the sensations they produced as follow:

• Relative motion: am I moving in a ﬁxed an environ-
ment or am I at rest watching a moving environ-
ment?

• Acceleration: do I have bodily sensations similar to

being in a moving vehicle with eyes closed?

• Comfort: how pleasant or unpleasant is the motion

experience?

We designed our study to test the following hypotheses:

Fig. 3. The rigid headband and the custom 3D-printed connector.

design pre-session tests to adapt the gain to each individual.
If the user is standing, the risk of unbalance and fall has also
to be considered.

4 PROOF OF CONCEPT

In order to showcase our concept, we developed a prototype
(see Figure 1 for the detailed components) based on a high-
end grounded haptic arm and tuned it for a ﬂight simulation
scenario. That is, we wanted to provide the user strong and
compelling sensations of acceleration, deceleration, gravi-
tational roll and turbulence. Also, we wanted our demo
to be accessible without prior skills, so we chose a glider
ﬂight scenario, which requires minimal pilot skills. The full
scenario is detailed in the accompanying video.

4.1 Hardware components

We used a Virtuose 6D 35-45 haptic arm, which pro-
vides strong forces and torques in a workspace of about
1.3mx5mx1m. We placed its base about 1m above the ﬂoor
in order to have the user’s head in the middle of the
workspace.

By using a grounded device, we don’t load the head
with extra weight, and don’t expose it to motor sound and
vibrations.

For the HMD we used a HTC Vive headset with an
unofﬁcial ”Rift S style” rigid headband found online. We
designed and 3D-printed a mechanical connector replacing
the Virtuose handle, plugged at the back of the headband
and secured with a screw (see Figure 3). The use of a 6-
DoF haptic arm allows for cancelling counter torques when
applying steady 3-DoF forces.

4.2 Software components

We built upon a glider ﬂight scenario of a standard software
ﬂight simulator (X-Plane 11). Flight simulation softwares
output a series a real-time motion data, and notably accel-
eration values to be used for motion platforms. We used a
python script to receive the ﬂight simulation acceleration
data through UDP and to compute the haptic rendering.
The applied forces were negatively proportional to visual
acceleration. In order to cancel counter torques, when force
modulus exceeded 1N the applied torques were simulating

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

to prevent cybersickness symptoms, participants were asked
to hydrate well before participating, and were free to have a
break anytime during the experiment. One extra participant
could not ﬁnish the experiment because of cybersickness
symptoms, thus their incomplete data was removed from
the results.

5.4 Experimental design

Each participant would attend a single session of about
50mn consisting in three phases: an introduction phase, an
exploration phase, and an experimental phase.

In the introduction phase, the participant read and
signed an informed consent form conforming to the decla-
ration of Helsinki. In order to clarify the vocabulary used
during the experiment, the participant was orally given
examples of different motion sensations related from a
displacement stimulus: estimated traveled distance, relative
motion (which of me or the landscape is actually moving ?),
and ”acceleration”, that is the non-visual sensation of being
moved that can be felt when closing your eyes in a moving
vehicle.

Then, the participant was introduced to the protocol
through the exploration phase. The participant sat on a
stool and adjusted the HMD for a correct vision. The ex-
perimenter progressively explained the experimental con-
duct by running 8 trials (4 H NONE, 2 H DIRECT, 2
H INDIRECT) and answering any question (except about
the nature of the stimuli). In order to avoid surprise effects,
the haptic arm was not connected to the HMD before the
third trial (the ﬁrst visuo-haptic stimulus). On one of the
visuo-haptic trial, the participant was asked to perform a
”security break exercise”: they would say a safeword any
time during the stimulus, after which the experimenter im-
mediately released the kill switch to disable haptic feedback
and cancel the trial. The participant’s answers were not
recorded during the introduction phase. After the eighth
trial, the participant was offered to have a break, and the
experimenter made sure they had no remaining question
about the protocol or the task, before moving to the experi-
mental phase.

The experimental phase consisted in a randomized block
of 30 trials (10 repetitions of each three conditions). All
the trials followed the same structure. First, the participant
validated the launch of the trial. Then, a visual target was
displayed forward for 1.5 seconds (see Figure 5). Then the

Fig. 5. The visual stimulus used in the experiment.

Fig. 4. The temporal acceleration pattern used for the stimuli. The curve
shows acceleration (m.s−2) over time (s).

• H1: visuo-haptic stimuli induce more egocentric mo-

tion sensations than a similar visual stimulus

• H2: visuo-haptic stimuli induce stronger bodily sen-

sations than a similar visual stimulus

• H3: some participants would have higher ratings (in
relative motion, acceleration and/or comfort) for the
direct mode, and some other for the indirect mode

5.2 Stimuli

The visual context was designed so as to be as neutral as
possible. The virtual environment was an empty space ﬁlled
with a random spatial distribution of 20000 white cubes,
vanishing in a black fog at about 70 meters distance. In order
to mitigate the lack of embodiment and eventual vertigo
symptoms, a white 3mx4m rectangle was used as a symbolic
ground.

The displacement stimulus was based on a double step
acceleration pattern (see Figure 4): a forward acceleration for
5 seconds followed by a deceleration of 5 seconds. In order
to avoid transient effects, those two steps were eased with
0.5sec long sinusoidal curves, so the acceleration magnitude
was of a maximal of 5 m.s−2 for 4 seconds.

The visual stimulus was identical for all conditions: the
cubes were accelerated according to the previously depicted
pattern, creating an ambiguous relative displacement be-
tween them and the participant and ground. The three
experimental conditions were as follow:

• H NONE: no force feedback
• H DIRECT: force feedback is proportional to the
acceleration pattern: pushing during acceleration,
pulling during deceleration

• H INDIRECT: the force feedback is proportional to

the opposite of the acceleration pattern

In both H DIRECT and H INDIRECT conditions, the
haptic arm maintained head orientation constant during the
stimulus to avoid any lever arm effect.

5.3 Participants

17 participants (2 females, age 23-54, mean=35.3, SD=10.7)
volunteered for the experiment. They were all recruited in
the research center, had corrected-to-normal vision, and no
balance disorder history. They all signed an informed con-
sent form prior to participating to the experiment. In order

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

6

Fig. 6. User rating during the experiment.

stimulus was played for 10 seconds. Finally, the participant
rated the stimulus on Relative Motion, Acceleration and Com-
fort scales (see Figure 6).

Participants were asked to keep their gaze towards the
direction indicated by the target at the beginning of the trial.
They were asked to maintain their gaze direction and simply
remain comfortable if the haptic stimulus would modify
their posture.

5.5 Results

Participants’ ratings for are shown on Figure 7. Relative
Motion was mostly rated positive (egocentric motion) in
the H DIRECT and H INDIRECT conditions, while an-
swers were mixed for the H NONE condition. Comfort
ratings were mostly weakly positive for the H DIRECT
and H NONE condition, and mixed for the H INDIRECT
condition. Acceleration was mostly rated above 3/5 in the
H DIRECT and H INDIRECT conditions, while mostly un-
der 3/5 in the H NONE condition.

For each of the three variables, as the normality assump-
tion was violated (Shapiro–Wilk’s normality test, p < 0.05),
a Friedman test was conducted independently followed by
a post-hoc Wilcoxon-signed ranks test with a Bonferroni
correction. For Relative Motion and Acceleration, signiﬁcant
differences (p < 0.001) were found between H NONE and
H DIRECT and between H NONE and H INDIRECT. For
Comfort, a signiﬁcant difference (p < 0.001) was found
between H NONE and H INDIRECT only. We didn’t ﬁnd
any effect of age, gender or previous experience of virtual
reality on any of the three variables.

Taken together our result validate both H1 and H2, with
signiﬁcantly higher ratings of Relative Motion and Acceler-
ation for visuo-haptic stimuli compared the to the visual-
only stimulus. Surprisingly, the rating distributions for both
H DIRECT and H INDIRECT were very similar, and con-
trary to H3 we could not split the results in two populations
preferring one or the other type of haptic feedback, as
suggested by previous work [19]. The only noticeable differ-
ence was the Comfort ratings, slightly more negative for the
H INDIRECT condition, leading to signiﬁcant differences
with the H NONE condition, which ratings were mostly
positive (almost never judged as uncomfortable).

Fig. 7. Ratings distributions across all participants. Red dots are outliers.

6 GENERAL DISCUSSION

6.1 Approach

The informal reactions to our ﬂight simulator prototype
conﬁrmed that the visuo-haptic experience was much more
compelling than the visual-only one. After having tried
the haptic-enhanced scenario, the visual-only scenario felt
”empty” or ”ﬂat”, and also more prone to dizziness. It
seemed that both low-frequency and high frequency haptic
feedback contributed strongly to the quality of experience:
the roaring take-off would lack of power without the slow
and strong pull, but would also lack of realism without the
swift turbulences.

The rigid headband can be used separately from the
haptic arm, but also from the HMD, which means we could
use it with other visual conditions, from a simple screen to
video-projected space or augmented reality glasses. A quick
fastener on various haptic devices could allow for a versatile
usage.

Depending on the application the displacement might
be active or passive, and the user can be seated or stand-
ing. The design of head-based haptic feedback for active
displacement might lead to novel locomotion techniques,
improving user performance and/or quality of experience.
When standing, the workspace can be limited depending
on the chosen haptic device, and hardware should also be
adapted to imbalance and falling issues.

The lack of bodily sensations is a major issue for virtual
reality, limiting user quality of experience and agency, and
increasing cybersickness occurrence. Our approach opens
thrilling possibilities to apply haptic cinematography prin-
ciples, as proposed by Danieau et al. [39]. Beyond the
realism of physical simulations, creators can make use of
non-diegetetic effects to increase dramatic intensity, and di-
rect attention with staging or anticipation techniques. More
generally, haptics could be seen as a media by itself, able
to improve storytelling and make better narratives, just like
cinema sound design.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

7

6.2 User Study

7 CONCLUSION

Taken together the results of our study show that, as ex-
pected, the visuo-haptic stimuli induced more vivid and
more compelling self-motion sensations than a similar
visual-only stimulus. Those enhanced motion sensations
might arise from vestibular and/or proprioceptive cues.
As the participants could resist more or less to the haptic
feedback to maintain their posture, their leaning amplitude
could vary a lot between the stimuli. However we could not
ﬁnd, formally or informally, a clear difference in the accom-
panying sensations. On top of that there was a signiﬁcant
difference in amplitude between individuals depending on
their weight (which varied with a factor of two between
participants). Yet even weighted individuals with no visible
leaning might answer with high self-motion ratings. Fur-
ther research should clarify the respective contributions of
vestibular and proprioceptive cues.

The vestibular haptic cues might also alter the estima-
tions travel distance, as suggested by previous work [13].
We initially planned to include this task in our study, but
the pilot tests revealed an surprisingly high cognitive load
for making both distance and velocity/acceleration esti-
mations. After providing a traveled distance estimate, the
participants could hardly make assessments about relative
motion or non-visual sensations and vice-versa, as if those
two kinds of task had conﬂicting short memory processes.
The perception of displacement given by visual and visuo-
haptic stimuli remains to be studied.

6.3 Future Work

Head-based force feedback opens exciting possibilities in
terms of haptic rendering, training simulation and virtual
reality quality of experience. It also comes with various
application-related challenges to address in future work.

Our prototype based on a 6-DoF haptic arm was able to
provide stable forces in any of the three directions. Yet both
visual and vestibular perceptual thresholds are anisotropic
[31], thus directionality could be taken in account when
elaborating head-based visuo-haptic stimuli, and the psy-
chophysical thresholds could be investigated.

High individual variance, habituation and attentional
phenomenons as well as inﬂuence from various top-down
factors [24] need to be taken in account to achieve the ren-
dering of bodily sensations. Control laws could be adjusted
depending on the user as well as the virtual environment
context, like getting in a virtual vehicle or ﬂying. Those
adjustment might be achieved with ofﬂine tests to estimate
user sensibility, as well as tuned in real-time depending
on user’s state, similarly to motion platform washout al-
gorithms. The role of habituation and attention could also
be further studied.

For speciﬁc scenarios, smaller haptic devices could be
used. For instance, for a ﬂight simulation altitude control ex-
ercise, the force feedback might only simulate gravitational
tilt: when the plane pitches up, the user is pulled backwards,
and when the plane is pointing down the user is pushed
forwards.

In this short paper, we proposed a novel approach to make
self-motion sensations stronger and more compelling in
virtual reality applications, by means of head-based force
feedback. The provided vestibular and proprioceptive cues
enhance the perception of self-motion, making it more ego-
centric and more bodily, while preserving user’s comfort.

We discussed the technical and scientiﬁc challenges
raised by head-based force feedback and demonstrated a
ﬂight simulator use case with a proof-of-concept prototype
based on a high-end grounded haptic arm. We evaluated our
system with a user study focused on the motion sensations
provided by visuo-haptic displacement stimuli. Our results
showed that the visuo-haptic rendering induced more vivid
and more egocentric sensations of self-motion than a similar
visual-only rendering.

REFERENCES

[1] Varjo website. https://varjo.com/products/vr-3. Accessed: 2021-

03-04.

[2] Wikepedia notice on 4d ﬁlm. https://en.wikipedia.org/wiki/4D

ﬁlm. Accessed: 2021-03-04.

[3] C. Boletsis. The new era of virtual reality locomotion: A systematic
literature review of techniques and a proposed typology. Multi-
modal Technologies and Interaction, 1(4):24, 2017.

[4] G. Bouyer, A. Chellali, and A. L´ecuyer.

Inducing self-motion
sensations in driving simulators using force-feedback and haptic
motion. In 2017 IEEE Virtual Reality (VR), pp. 84–90. IEEE, 2017.

[5] Z. Britton and Q. Arshad. Vestibular and multi-sensory inﬂuences
upon self-motion perception and the consequences for human
behavior. Frontiers in neurology, 10:63, 2019.

[6] H.-Y. Chang, W.-J. Tseng, C.-E. Tsai, H.-Y. Chen, R. L. Peiris,
and L. Chan. Facepush: Introducing normal force on face with
In Proceedings of the 31st Annual ACM
head-mounted displays.
Symposium on User Interface Software and Technology, pp. 927–935,
2018.

[7] K. E. Cullen. The vestibular system: multimodal integration and
encoding of self-motion for motor control. Trends in neurosciences,
35(3):185–196, 2012.

[8] F. Danieau, J. Fleureau, P. Guillotel, N. Mollet, A. L´ecuyer, and
M. Christie. Hapseat: producing motion sensation with multiple
force-feedback devices embedded in a seat. In Proceedings of the
18th ACM symposium on Virtual reality software and technology, pp.
69–76, 2012.
I. Farkhatdinov, N. Ouarti, and V. Hayward. Vibrotactile inputs
to the feet can modulate vection. In 2013 World Haptics Conference
(WHC), pp. 677–681. IEEE, 2013.

[9]

[10] C. R. Fetsch, A. H. Turner, G. C. DeAngelis, and D. E. Angelaki.
Dynamic reweighting of visual and vestibular cues during self-
Journal of Neuroscience, 29(49):15601–15612,
motion perception.
2009.

[11] M. Gallagher, R. Dowsett, and E. R. Ferr`e. Vection in virtual re-
ality modulates vestibular-evoked myogenic potentials. European
Journal of Neuroscience, 50(10):3557–3565, 2019.

[12] J. Gugenheimer, D. Wolf, E. R. Eiriksson, P. Maes, and E. Rukzio.
Gyrovr: Simulating inertia in virtual reality using head worn
In Proceedings of the 29th Annual Symposium on User
ﬂywheels.
Interface Software and Technology, pp. 227–232, 2016.

[13] L. R. Harris, M. Jenkin, and D. C. Zikovitz. Visual and non-visual
cues in the perception of linear self motion. Experimental brain
research, 135(1):12–21, 2000.

[14] K. Kim.

Is virtual reality (vr) becoming an effective application
for the market opportunity in health care, manufacturing, and
entertainment industry? European Scientiﬁc Journal, ESJ, 12:14–14,
2016.

[15] Y. Kon, T. Nakamura, and H. Kajimoto. Hangerover: Hmd-
embedded haptics display with hanger reﬂex. In ACM SIGGRAPH
2017 Emerging Technologies, pp. 1–2. 2017.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

8

[16] E. Kruijff, A. Marquardt, C. Trepkowski, R. W. Lindeman,
A. Hinkenjann, J. Maiero, and B. E. Riecke. On your feet! en-
hancing vection in leaning-based interfaces through multisensory
In Proceedings of the 2016 Symposium on Spatial User
stimuli.
Interaction, pp. 149–158, 2016.

[17] A. L´ecuyer, M. Vidal, O. Joly, C. M´egard, and A. Berthoz. Can
haptic feedback improve the perception of self-motion in virtual
In 12th International Symposium on Haptic Interfaces for
reality?
Virtual Environment and Teleoperator Systems, 2004. HAPTICS’04.
Proceedings., pp. 208–215. IEEE, 2004.

[18] N. C. Nilsson, R. Nordahl, E. Sikstr ¨om, L. Turchet, and S. Seraﬁn.
Haptically induced illusory self-motion and the inﬂuence of con-
text of motion. In International Conference on Human Haptic Sensing
and Touch Enabled Computer Applications, pp. 349–360. Springer,
2012.

[19] N. Ouarti, A. L´ecuyer, and A. Berthoz. Haptic motion: Improving
sensation of self-motion in virtual worlds with force feedback. In
2014 IEEE Haptics Symposium (HAPTICS), pp. 167–174. IEEE, 2014.
[20] S. Palmisano, R. S. Allison, M. M. Schira, and R. J. Barry. Future
challenges for vection research: deﬁnitions, functional signiﬁcance,
measures, and neural bases. Frontiers in psychology, 6:193, 2015.
[21] J. D. Prothero, H. G. Hoffman, D. E. Parker, T. A. Furness III,
and M. J. Wells. Foreground/background manipulations affect
presence. In Proceedings of the Human Factors and Ergonomics Society
Annual Meeting, vol. 39, pp. 1410–1414. SAGE Publications Sage
CA: Los Angeles, CA, 1995.

[22] M. Reiner. The role of haptics in immersive telecommunication
environments. IEEE Transactions on Circuits and Systems for Video
Technology, 14(3):392–401, 2004.

[23] B. E. Riecke, J. Schulte-Pelkum, M. N. Avraamides, M. Von
Der Heyde, and H. H. B ¨ulthoff. Scene consistency and spatial
presence increase the sensation of self-motion in virtual reality. In
Proceedings of the 2nd Symposium on Applied Perception in Graphics
and Visualization, pp. 111–118, 2005.

[24] B. E. Riecke, D. V¨astfj¨all, P. Larsson, and J. Schulte-Pelkum. Top-
down and multi-modal inﬂuences on self-motion perception in
In Proceedings of HCI international 2005, pp. 1–10,
virtual reality.
2005.

[25] M. Rietzler, T. Hirzle, J. Gugenheimer, J. Frommel, T. Dreja, and
E. Rukzio. Vrspinning: Exploring the design space of a 1d rotation
platform to increase the perception of self-motion in vr.
In
Proceedings of the 2018 Designing Interactive Systems Conference, pp.
99–108, 2018.

[26] F. Soave, N. Bryan-Kinns, and I. Farkhatdinov. A preliminary
study on full-body haptic stimulation on modulating self-motion
In International Conference on Aug-
perception in virtual reality.
mented Reality, Virtual Reality and Computer Graphics, pp. 461–469.
Springer, 2020.

[27] S.-Y. Teng, D.-Y. Huang, C. Wang, J. Gong, T. Seyed, X.-D. Yang,
and B.-Y. Chen. Aarnio: passive kinesthetic force output for
foreground interactions on an interactive chair. In Proceedings of
the 2019 CHI Conference on Human Factors in Computing Systems,
pp. 1–13, 2019.

[28] A. V¨aljam¨ae, P. Larsson, D. V¨astfj¨all, and M. Kleiner. Vibrotactile
enhancement of auditory-induced self-motion and spatial pres-
ence. Journal of the Audio Engineering Society, 54(10):954–963, 2006.
[29] C. Wang, D.-Y. Huang, S.-w. Hsu, C.-E. Hou, Y.-L. Chiu, R.-C.
Chang, J.-Y. Lo, and B.-Y. Chen. Masque: Exploring lateral skin
In
stretch feedback on the face with head-mounted displays.
Proceedings of the 32nd Annual ACM Symposium on User Interface
Software and Technology, pp. 439–451, 2019.

[30] D. Wang, K. Ohnishi, and W. Xu. Multimodal haptic display for
virtual reality: A survey. IEEE Transactions on Industrial Electronics,
67(1):610–623, 2019.

[31] B. T. Crane, K. Ohnishi, and W. Xu. Human visual and vestibular
heading perception in the vertical planes. Journal of the Association
for Research in Otolaryngology, 15(1), 87-102., 2014.

[32] J. Lecompte, PhD. Thesis. Biomecanique du segment tete-cou
in vivo & aeronautique militaire. Approches neuromusculaire et
morphologique. Arts et M´etiers ParisTech, 2007.

[33] J.R. Funk., J.M. Cormier, C.E. Bain, H. Guzman, E. Bonugli, and
S.J. Manoogian. Head and neck loading in everyday and vigorous
activities. Annals of biomedical engineering, 39.2, 766-776, 2011.
[34] B.E. Riecke. Simple user-generated motion cueing can enhance
self-motion perception (Vection) in virtual reality. In Proceedings of
the ACM symposium on Virtual reality software and technology, 2006.

[35] G. Vailland, Y. Gaffary, L. Devigne, V. Gouranton, B. Arnaldi, and
M. Babel. Vestibular Feedback on a Virtual Reality Wheelchair
In Proceedings of the 2020
Driving Simulator: A Pilot Study.
ACM/IEEE International Conference on Human-Robot Interaction (HRI
’20), 2020.

[36] Y. H. Peng, C. Yu, S. H. Liu, C. W. Wang, P. Taele, N. H. Yu and
M. Y. Chen. WalkingVibe: Reducing Virtual Reality Sickness and
Improving Realism while Walking in VR using Unobtrusive Head-
In Proceedings of the 2020 CHI
mounted Vibrotactile Feedback.
Conference on Human Factors in Computing Systems, 1–12, 2020.
[37] D. Wolf, M. Rietzler, L. Hnatek and E. Rukzio. Face/on: multi-
modal haptic feedback for head-mounted displays in virtual re-
In IEEE transactions on visualization and computer graphics,
ality.
25(11), 3169-3177. 2019.

[38] F. Danieau, A. L´ecuyer, P. Guillotel, J. Fleureau, N. Mollet and
M. Christie. A Kinesthetic Washout Filter for Force-Feedback
Rendering. In IEEE transactions on haptics, 8(1), 114-118, 2014.

[39] P. Guillotel, F. Danieau, J. Fleureau, and I. Rouxel.

Introducing
Basic Principles of Haptic Cinematography and Editing. In WICED
, 15-21, 2016.

PLACE
PHOTO
HERE

Antoine Costes is a research engineer at Inria
Rennes, France. He obtained a PhD in Com-
puter Science from INSA Rennes in 2018, within
a collaboration between the Immersive Lab of
InterDigital company (formerly Technicolor R&I)
and the Hybrid research team at Inria Rennes.
His research topics include pseudo-haptic ren-
dering and human perception in immersive en-
vironments. He prototypes connected objects,
interactive systems and haptic actuators for both
scientiﬁc and artistic purposes.

Anatole L ´ecuyer is a senior researcher and
head of the Hybrid team, Inria Rennes, France.
He is currently an associate editor of the IEEE
Transactions on Visualization and Computer
Graphics, Frontiers in Virtual Environments, and
Presence journals, as well as formerly of the
ACM Transactions on Applied Perception and
the International Journal of Humanities and
Cultural Studies. He was a program chair of
the IEEE Virtual Reality Conference(2015-2016)
and the IEEE Symposium on 3D User Interfaces

PLACE
PHOTO
HERE

(2012-2013).

