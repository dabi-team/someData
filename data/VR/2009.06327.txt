0
2
0
2

p
e
S
4
1

]

R

I
.
s
c
[

1
v
7
2
3
6
0
.
9
0
0
2
:
v
i
X
r
a

Double-Wing Mixture of Experts for
Streaming Recommendations

Yan Zhao1,2, Shoujin Wang2, Yan Wang2, Hongwei Liu1(cid:0), and Weizhe Zhang1,3

1 School of Computer Science and Technology, Harbin Institute of Technology, China
{yanzhao,liuhw,wzzhang}@hit.edu.cn
2 Department of Computing, Macquarie University, Australia
{shoujin.wang,yan.wang}mq.edu.au
3 Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, China

Abstract. Streaming Recommender Systems (SRSs) commonly train
recommendation models on newly received data only to address user pref-
erence drift, i.e., the changing user preferences towards items. However,
this practice overlooks the long-term user preferences embedded in his-
torical data. More importantly, the common heterogeneity in data stream
greatly reduces the accuracy of streaming recommendations. The reason
is that diﬀerent preferences (or characteristics) of diﬀerent types of users
(or items) cannot be well learned by a uniﬁed model. To address these two
issues, we propose a Variational and Reservoir-enhanced Sampling based
Double-Wing Mixture of Experts framework, called VRS-DWMoE, to
improve the accuracy of streaming recommendations. In VRS-DWMoE,
we ﬁrst devise variational and reservoir-enhanced sampling to wisely
complement new data with historical data, and thus address the user
preference drift issue while capturing long-term user preferences. After
that, we propose a Double-Wing Mixture of Experts (DWMoE) model
to ﬁrst eﬀectively learn heterogeneous user preferences and item charac-
teristics, and then make recommendations based on them. Speciﬁcally,
DWMoE contains two Mixture of Experts (MoE, an eﬀective ensemble
learning model) to learn user preferences and item characteristics, respec-
tively. Moreover, the multiple experts in each MoE learn the preferences
(or characteristics) of diﬀerent types of users (or items) where each expert
specializes in one underlying type. Extensive experiments demonstrate
that VRS-DWMoE consistently outperforms the state-of-the-art SRSs.

Keywords: Recommender System · Mixture of Experts · Streaming
Recommendation.

1

Introduction

Recommender Systems (RSs) have played an increasingly important role to as-
sist users to make wise decisions. Nowadays, E-commerce platforms generate
continuous data stream, e.g., continuous users’ purchase records, at an unprece-
dented speed, which poses new challenges for RSs. Conventional oﬄine RSs

This paper was accepted by WISE’2020. The ﬁnal authenticated publication is avail-
able online at https://doi.org/[DOI to be inserted]

 
 
 
 
 
 
2

Yan Zhao et al.

train recommendation models with large-volume data periodically [7, 26], and
thus cannot process data stream in a real-time manner. To this end, Streaming
Recommender Systems (SRSs) [23], which perform real-time recommendations
based on the data stream, have emerged.

Various SRSs have been proposed through diﬀerent ways. As an earlier at-
tempt, researchers have constructed SRSs by adapting oﬄine RSs to the stream-
ing setting through training the recommendation models incrementally with new
data, e.g., incremental collaborative ﬁltering [12]. Later on, SRSs speciﬁcally
devised for the streaming scenario have been proposed, e.g., Neural Memory
Recommender Networks (NMRN) [20].

Despite many SRSs have been proposed, the following two challenges still
need to be well addressed to improve the accuracy of streaming recommen-
dations: CH1: how to address user preference drift, i.e., the user preferences
towards items changing over time [17], while capturing long-term user prefer-
ences, and CH2: how to handle the heterogeneity of users and items, i.e., dif-
ferent types of users (or items) have diﬀerent preferences (or characteristics).
To address CH1, Wang et al. [20] and Wang et al. [23] have proposed a neural
memory network based approach, i.e., NMRN, and a reservoir-based approach,
i.e., Stream-centered Probabilistic Matrix Factorization (SPMF), respectively.
However, NMRN has diﬃculties in capturing long-term user preferences as the
preferences stored in memory might be overwritten frequently over the continu-
ous data stream, while SPMF has limited capability to address user preference
drift as it could not suﬃciently learn from new data to capture the changing user
preferences. Diﬀerent from the ﬁrst challenge, CH2 has not been discussed in
the literature of SRSs. Existing SRSs commonly utilize a uniﬁed model to learn
user preferences and item characteristics for all users and items [4, 6]. However,
they cannot well deal with the intrinsic diﬀerence between user preferences and
item characteristics. Moreover, the preferences (or characteristics) of diﬀerent
types of users (or items) cannot be well learned by a uniﬁed model, either.

Our Approach and Contributions. To address the above two challenges,
we propose a novel Variational and Reservoir-enhanced Sampling based Double-
Wing Mixture of Experts framework, called VRS-DWMoE, to improve the ac-
curacy of streaming recommendations. Speciﬁcally, VRS-DWMoE contains two
key components: 1) Variational and Reservoir-enhanced Sampling (VRS), which
wisely samples historical data containing long-term user perferences from the
reservoir, i.e., a set of representative historical data, with an adjustable sam-
pling size to complement new data, and 2) Double-Wing Mixture of Experts
(DWMoE), which ﬁrst learns heterogeneous user preferences and item charac-
teristics with the training data prepared by VRS, and then utilizes the learned
preferences and characteristics to make recommendations. Speciﬁcally, DWMoE
contains two elaborately devised Mixture of Experts (MoEs) to learn user pref-
erences and item characteristics, respectively. Note that MoE is an eﬀective
ensemble learning model which wisely fuses the outputs of multiple experts, i.e.,
atomic models specializing in diﬀerent types of input, for better learning perfor-
mance [10]. Moreover, the multiple experts in each of the aforementioned two

Double-Wing Mixture of Experts for Streaming Recommendations

3

MoEs learn the preferences (or characteristics) of diﬀerent types of users (or
items) where each expert specializes in one underlying type.

The characteristics and contributions of our work are summarized as follows:

– In this paper, we propose a novel VRS-DWMoE framework, which consists
of Variational and Reservoir-enhanced Sampling (VRS) and Double-Wing
Mixture of Experts (DWMoE), for accurate streaming recommendations.
– To address CH1, we propose VRS to wisely complement new data with
historical data while guaranteeing the proportion of new data. In this way,
VRS not only captures long-term user preferences from the sampled histor-
ical data, but also eﬀectively addresses user preference drift by highlighting
the importance of new data.

– To address CH2, we propose DWMoE to ﬁrst eﬀectively learn heterogeneous
user preferences and item characteristics, and then make recommendations
with learned preferences and characteristics. Speciﬁcally, DWMoE not only
learns user preferences and item characteristics with two elaborately devised
MoEs, respectively, to deal with their intrinsic diﬀerence, but also allows
each expert to specialize in one underlying type of users (or items) to more
eﬀectively learn the heterogeneous user preferences (or item characteristics).

2 Related Work

In this section, we ﬁrst review streaming recommender systems, and then intro-
duce mixture of experts, based on which we propose VRS-DWMoE.

2.1 Streaming Recommender Systems

The early SRSs enhance oﬄine RSs with elaborately devised online update mech-
anisms for streaming recommendations. For example, Papagelis et al. [12] adapt
user-based collaborative ﬁltering to the streaming setting by incrementally up-
dating the user-to-user similarities. Later on, several approaches have been pro-
posed to adapt the matrix factorization to the streaming setting, including incre-
mental stochastic gradient descent [19], randomized block coordinate descent [1],
and fast alternating least square [6]. Moreover, the optimization methods for
oﬄine matrix factorization have also been applied to the streaming setting, in-
cluding pair-wise personalized ranking [2] and Bayesian inference [15].

Recently, SRSs focusing on the challenges in streaming recommendations
have emerged. To address user preference drift while capturing long-term user
preferences, the neural memory network based approach, i.e., NMRN [20], and
the reservoir-based approach, i.e., SPMF [23], have been proposed. Speciﬁcally,
NMRN tries to capture user preferences by neural memory network. However,
it has limited capability to capture long-term user preferences, as the long-term
preferences stored in the memory might be overwritten frequently over the con-
tinuous data stream. In addition, SPMF maintains a reservoir and trains the
recommendation model with both sampled historical data and sampled new
data. However, SPMF has diﬃculties in addressing user preference drift, as it
equally treats the historical data and new data when conducting the sampling

4

Yan Zhao et al.

process and thus overlooks the importance of new data. In addition, to avoid the
limitations of a single model, OCFIF [25] ensembles multiple recommendation
models to conduct streaming recommendations. However, it does not fully exploit
the potential of these recommendation models, as it trains the recommendation
models independently and selects only one model for recommendations.
Summary. More work is needed to address user preference drift while capturing
long-term user preferences. In addition, studies on addressing the issue of user
or item heterogeneity in streaming recommendations have not been reported.

2.2 Mixture of Experts

Mixture of Experts (MoE) [10] is an eﬀective ensemble learning model which
wisely fuses the results of multiple experts to achieve better learning perfor-
mance. Speciﬁcally, MoE contains 1) multiple experts where each expert is an
atomic model specializing in learning from a particular type of input data, 2)
a gating network to calculate the gating weights, i.e., the expertise of each ex-
pert regarding the input, and 3) a fusion module to fuse the outputs of the
experts with the gating weights. Its eﬀectiveness has been veriﬁed in various
areas [14], including oﬄine recommendations [9]. However, these existing MoE
based RSs commonly employ MoE to perform multi-task learning [9] or sim-
ply combine multiple independent RSs [18], rather than eﬀectively learning the
heterogeneous user preferences and item characteristics from the interactions.
In addition, although MoE has achieved good performance regarding streaming
data in multiple areas [11], its eﬀectiveness in streaming recommendations has
not been explored.
Summary. The potential of MoE has not been explored by existing SRSs. Al-
though MoE based oﬄine RSs have been proposed, they cannot well learn the
heterogeneous user preferences and item characteristics. Moreover, conventional
MoE based approaches only contain a single MoE, and thus can not be employed
directly to well address the aforementioned challenge, i.e., CH2.

3 VRS-DWMoE Framework

We ﬁrst formulate our research problem. After that, we propose Variational and
Reservoir-enhanced Sampling based Double-Wing Mixture of Experts (VRS-
DWMoE), and then introduce its two key components, i.e., VRS and DWMoE.

3.1 Problem Statement

In this section, we formulate the research problem of streaming recommendations
with implicit interactions, e.g., the users’ purchase records of items. Given the
user set U and item set V, we use yu,v to denote an interaction between user
u ∈ U and item v ∈ V. Then, the list of currently received interactions is denoted
by Y = {y1
uk,vk , . . . }. Note that the interactions in Y are sorted
uk,vk indicates the kth received interaction. In
based on their receiving time, e.g., yk
addition, as in the real-world data stream, the adjacent interactions, e.g., yk
uk,vk

u2,v2, . . . , yk

u1,v1 , y2

Double-Wing Mixture of Experts for Streaming Recommendations

5

Fig. 1. Workﬂow of our proposed VRS-DWMoE.

and yk+1
uk+1,vk+1, may involve diﬀerent users, i.e., user uk is possibly diﬀerent from
user uk+1. With the above information, given the target user u(cid:48) and target item
v(cid:48), the task of SRSs can be formulated as ˆyu(cid:48),v(cid:48) = P (yu(cid:48),v(cid:48)|Y), i.e., predicting the
probability of an interaction between the target user and target item conditional
on the currently received interactions.

3.2 Our Proposed VRS-DWMoE Framework

To simultaneously address user preference drift while capturing long-term user
preferences and handle the heterogeneity of users and items, we propose VRS-
DWMoE, which contains two key components: 1) Variational and Reservoir-
enhanced Sampling (VRS), and 2) Double-Wing Mixture of Experts (DWMoE).
Speciﬁcally, as shown in Fig. 1, VRS ﬁrst complements the new data with sam-
pled historical data while guaranteeing the proportion of new data in prepara-
tion for training. After that, with the training data prepared by VRS, DWMoE
better learns heterogeneous user preferences and item characteristics with two

6

Yan Zhao et al.

elaborately devised Mixture of Experts (MoEs), i.e., Mixture of User Experts
(MoUE) and Mixture of Item Experts (MoIE), respectively, and then makes rec-
ommendations based on the learned user preferences and item characteristics.

3.3 Variational and Reservoir-enhanced Sampling

The continuous and inﬁnite data stream makes it impractical for SRSs to train
recommendation models with all the data. To this end, we propose VRS to
prepare the data for training by wisely complementing new data with sampled
historical data while guaranteeing the proportion of new data.

Speciﬁcally, following [8, 23], we ﬁrst maintain a reservoir to store a set of
representative historical data. As newer data commonly reﬂect more recent user
preferences, we put new data into the reservoir and discard the oldest data when
the reservoir runs out of space. With this reservoir and new data, VRS gener-
ates the training data with two diﬀerent strategies in two typical scenarios for
streaming recommendations, i.e., the underload scenario, where the data receiv-
ing speed is lower than the data processing speed, and the overload scenario,
where the data receiving speed is higher than the data processing speed, respec-
tively. Note that the contribution of VRS mainly lies in the underload scenario,
which is more common in the real world [3]. More details are presented below.
Underload Scenario. In the underload scenario, VRS generates training data
by ﬁrst sampling representative historical data Shis from the reservoir with a
variational sampling size, and then merging Shis and all the new data N (i.e., all
the new data are sampled by VRS in the underload scenario). Speciﬁcally, with
the training batch size bs and a predetermined parameter δ (δ ≥ 0) measuring
the ratio of the sampling size |Shis| of reservoir against the size snew of new
data, the sampling size |Shis|of reservoir can be calculated as below,

|Shis| = min(snew ∗ δ, bs − snew).

(1)

In this way, the sampling size of reservoir can be adjusted by δ based on the
characteristics of data stream. For example, δ should be set to a small value, e.g.,
0.1, for data stream where users’ preferences change frequently to focus more on
new data. Then, Shis is sampled from the reservoir based on their receiving time,
i.e., more recent received interactions are assigned higher sampling probabilities.
Speciﬁcally, to reﬂect the importance of newer data, we employ a decay ratio
λres (λres > 1) to assign higher sampling probabilities to newer data in the
reservoir,

pk = pk−1 ∗ λres,
(2)
where pi denotes the sampling probability of the ith received interaction. As-
suming that the sampling probability of the earliest received interaction in the
reservoir is p1, we can get pk by iteratively performing Eq. (2), i.e.,

pk = p1 ∗ (λres)k−1.

(3)

Then, with Eq. (3), we can obtain the normalized sampling probabilities, taking
the probability of the kth received interaction as an example,

Double-Wing Mixture of Experts for Streaming Recommendations

7

P (k|λres, sres) =

pk
(cid:80)sres
i=1 pi

=

(λres)k−1 ∗ (1 − λres)
1 − (λres)sres

,

(4)

where sres denotes the size of the reservoir.

With the normalized sampling probabilities and the sampling size calculated
in Eq. (1), VRS samples representative historical data Shis from the reservoir.
Finally, the training data T is obtained by merging Shis and the new data N.
Overload Scenario. In the overload scenario, VRS only samples Snew from new
data to form the training data, i.e., |Shis| is set to 0, for eﬀectively capturing
the latest user preferences. The sampling probability of the new data can be
calculated in a similar way as described by Eqs. (2) to (4), i.e.,

P (k|λnew, snew) =

pk
(cid:80)snew
i=1 pi

=

(λnew)k−1 ∗ (1 − λnew)
1 − (λnew)snew

,

(5)

where λnew and snew denote the decay ratio and size, respectively, of new data.
With this sampling probability and the sampling size set to be the batch size bs,
VRS samples Snew from the new data as the training data T. Note that, in the
case where the data receiving speed exactly equals to the data processing speed,
VRS utilizes the entire new data to form the training data T.

3.4 Double-Wing Mixture of Experts

With the training data T prepared by VRS, DWMoE ﬁrst utilizes two MoEs,
i.e., MoUE and MoIE, to learn user preferences and item characteristics, respec-
tively, to deal with their intrinsic diﬀerence [21]. Moreover, each expert in MoUE
(or MoIE) specializes in one underlying type of users (or items) for more eﬀec-
tively learning heterogeneous user preferences (or item characteristics). Then,
DWMoE makes recommendations with the learned user preferences and item
characteristics.

Speciﬁcally, MoUE and MoIE share the same structure with diﬀerent pa-
rameters. This structure has three key parts: 1) multiple experts, 2) a gating
network, and 3) a fusion module. Taking MoUE as an example, multiple experts
ﬁrst learn the user preferences in parallel. Then, the gating weights, which mea-
sure the expertise of each expert regarding each input user, are calculated by the
gating network. After that, the fusion module calculates the uniﬁed preferences
for each user by fusing the preferences learned by all experts with the gating
weights. Note that we set the numbers (ne) of experts in MoUE and MoIE the
same in this paper, and will study the eﬀect of diﬀerent numbers of experts in
MoUE and MoIE in the future work. More details are presented below.
Expert. The experts in MoUE and MoIE learn user preferences and item char-
acteristics, respectively. Taking MoUE as an example, each expert ﬁrst utilizes
an embedding layer to learn the user embedding pi
u, where i denotes the index of
the expert. Then, the user preferences are learned by the experts with x (x ≥ 1)
fully connected layers, taking the user preferences Pi

u as an example,
) + bM oU E
i,2

pi
u + bM oU E

i,1

) · · · ),

(6)

Pi

u = aM oU E
i,x

(· · · aM oU E
i,2

(WM oU E
i,2

aM oU E
i,1

(WM oU E
i,1

8

Yan Zhao et al.

i,x

∗, W∗

∗, and b∗

, WM oU E
i,x

where a∗
∗ denote the activation function, weight matrix, and bias
vector, respectively. For example, aM oU E
denote the acti-
vation function, weight matrix, and bias vector, respectively, in the xth layer for
the ith expert in MoUE. Note that the symbols a∗
∗ are used in the
rest of this paper with diﬀerent superscripts and subscripts to introduce the fully
connected layers. In a similar way as described by Eq. (6), item characteristics
Qj

v can be learned by the jth expert in MoIE with the item embedding qj
v,
Qj
v = aM oIE
j,x

v +bM oIE
qj
j,1

, and bM oU E

(· · · aM oIE
j,2

)+bM oIE
j,2

∗, and b∗

(WM oIE
j,1

(WM oIE
j,2

) · · · ). (7)

aM oIE
j,1

∗, W∗

i,x

Gating Network. The gating networks in MoUE and MoIE calculate the gating
weights measuring the expertise scales of each expert in learning the preferences
of input users and characteristics of input items, respectively. To achieve this
goal, taking the gating network in MoUE as an example, we ﬁrst employ an
embedding layer and a fully connected layer to calculate user embedding pM oU E
and item interference IM oU E, respectively. Note that the item interference is
employed to more accurately calculate the gating weights in MoUE by taking
the items interacted with the corresponding users into consideration. Speciﬁcally,
the item interference can be calculated with the item embedding qM oIE
in MoIE,

u

v

IM oU E = aM oU E

gate

(WM oU E

inter qM oIE
v

+ bM oU E

inter ).

Then, the user embedding and item interference are concatenated,
cM oU E = (cid:2)pM oU E

; IM oU E(cid:3) .

u

(8)

(9)

After that, cM oU E is fed into a softmax layer to get the gating weights gM oU E,

gM oU E = sof tmax(WM oU E

sof t cM oU E + bM oU E

sof t

).

(10)

Likewise, the gating weights gM oIE for the experts in MoIE can be calculated
in a similar way as described by Eqs. (8) to (10).
Fusion Module. The user preferences (or item characteristics) learned by mul-
tiple experts in MoUE (or MoIE) are fused to the uniﬁed ones to fully utilize the
expertise of all the experts. Speciﬁcally, with the above calculated user prefer-
ences, item characteristics, and their corresponding gating weights, the uniﬁed
user preferences Puni
can be calculated
u
with the dot production, respectively,

and uniﬁed item characteristics Quni

v

Puni

u = [P1
v = [Q1

u; · · · ; Pne
v; · · · ; Qne

u ]T gM oU E,
v ]T gM oIE,

Quni

(11)

(12)

where ne denotes the number of experts.
Interaction Module. To make recommendations based on uniﬁed user prefer-
ences and uniﬁed item characteristics, we ﬁrst utilize cosine similarity to measure
how the uniﬁed preferences match the corresponding uniﬁed characteristics,

cos sim<Puni

u ,Quni

v > = cosine(Puni

u , Quni

v

) =

(Puni
u )T Quni
v
u (cid:107)2(cid:107)Quni
v (cid:107)2

(cid:107)Puni

,

(13)

Double-Wing Mixture of Experts for Streaming Recommendations

9

and then we obtain the predicted probability ˆyu,v of the interaction between user
u and item v by performing a nonlinear transformation of this cosine similarity,

ˆyu,v = apredict

out

(Wpredict
out

cos sim<Puni

u ,Quni

v > + bpredict

out

).

(14)

Optimization. To learn the parameters of our proposed DWMoE, we train the
model by minimizing the following loss with stochastic gradient descent,

(cid:96)osstotal = (cid:96)ossacc + γ((cid:96)ossgate),
where (cid:96)ossacc is the loss for the recommendation accuracy, (cid:96)ossgate is used as
the regularization term for gating weights to avoid local optimizations, and γ is
the coeﬃcient to adjust the importance of (cid:96)ossgate.

(15)

Speciﬁcally, to measure the diﬀerence between the ground truth and the

prediction, we employ the cross-entropy loss as below,

(cid:96)ossacc(yu,v, ˆyu,v) = −(yu,vlog(ˆyu,v) + (1 − yu,v)log(1 − ˆyu,v)),
where yu,v is the label of the interaction between user u and item v, i.e., it
is 1 if this interaction exists and 0 otherwise, and ˆyu,v denotes the predicted
probability for this interaction. Moreover, we introduce (cid:96)ossgate to avoid the
local optimization caused by the imbalanced utilization of experts, i.e., some
experts receive large gating weights for most interactions while others always
receive small gating weights. Speciﬁcally, we employ the standard derivations of
gating weights in both MoUE and MoIE to form (cid:96)ossgate,

(16)

(cid:96)ossgate = (cid:96)ossgate

M oU E + (cid:96)ossgate

M oIE

=

(cid:114) 1
ne

(cid:88)ne
i=1

(gM oU E

i

− ¯gM oU E)2 +

(cid:114) 1
ne

(cid:88)ne

j=1

(gM oIE
j

− ¯gM oIE)2,

(17)

i

and gM oIE
j

denote the gating weight for the ith expert in MoUE
where gM oU E
and the gating weight for the jth expert in MoIE, respectively, and ¯gM oU E and
¯gM oIE denote the average of gating weights for MoUE and MoIE, respectively.
Through minimizing (cid:96)ossgate, DWMoE encourages MoUE and MoIE to more
eﬀectively utilize all their experts to learn the heterogeneous user preferences and
item characteristics, respectively, and thus to increase the accuracy of streaming
recommendations .

4 Experiments

In this section, we present the results of the extensive experiments we conducted
which aim to answer the following four research questions:

RQ1. How does our proposed VRS-DWMoE perform when compared with the

state-of-the-art approaches?

RQ2. How does our proposed DWMoE perform when compared with the ex-

isting recommendation models?

RQ3. How does our proposed VRS perform when compared with the existing

sampling methods?

RQ4. How does the number of experts in VRS-DWMoE aﬀect the recommen-

dation accuracy?

10

Yan Zhao et al.

Table 1. Statistics of three datasets used in our experiments1.

Datasets
MovieLens
Netﬂix
Yelp

#Users #Items #Interactions

6400
5000
25677

3703
16073
25815

994169
1010588
731671

Sparsity
95.81%
98.74%
99.89%

4.1 Experimental Settings

Datasets. In the experiments, we employ three widely-used real-world datasets [6,
23], i.e., MovieLens (1M)2, Netﬂix3, and Yelp4, to verify the eﬀectiveness of our
proposed VRS-DWMoE. Note that we extract the interactions of randomly se-
lected 5000 users from the Netﬂix dataset for the experiments, as processing
the original Netﬂix dataset, which contains more than 100 million interactions,
is beyond our computational capacity. In addition, following the common prac-
tice [6,13], for each dataset, we retain the interactions from users who have more
than 10 interactions to reduce data sparsity. The statistics of the tuned datasets
are summarized in Table 1. Moreover, following [20,25], we transform the explicit
ratings in all three datasets into the implicit ones, where it is 1 if an explicit
rating exists and 0 otherwise, as this work focuses on the recommendations with
implicit interactions.
Evaluation Policy. Following [6], we ﬁrst sort the data in each of the three
datasets by their receiving time, and then divide them into two parts, i.e., 1) the
training set to simulate the historical data, and 2) the test set to simulate the
upcoming data in the streaming scenario. Speciﬁcally, the data in the training
set are used for incremental training while the data in the test set are ﬁrst used
for the test and then used for incremental training. We have set the proportion of
training set to 85%, 90% and 95%, respectively, for evaluating the performance
of our proposed VRS-DWMoE. Due to the space limit, we report the results
in the case where the proportion of the training set is 90% only, as the work
in [6] does, while the results in the other two cases are similar to the reported
ones. Moreover, to verify the eﬀectiveness of our proposed VRS-DWMoE in the
underload scenario and overload scenario, we train the recommendation model
with a ﬁxed number np (np = 256 in this paper) of interactions each time and
adjust the number nr of interactions received in this training period to indicate
diﬀerent workload intensities. For the sake of simplicity, we use np and nr to
simulate the data processing speed sp and data receiving speed sr, respectively.
In this way, the underload scenario and the overload scenario can be simulated
by the cases where sp > sr and sp < sr, respectively.
Evaluation Metrics. Following the common practice [6, 23], we adopt the

1 The symbol # indicates the number, e.g., #Users indicates the number of users.
2 https://grouplens.org/datasets/movielens/1m
3 https://www.kaggle.com/netﬂix-inc/netﬂix-prize-data
4 https://www.yelp.com/dataset/challenge

Double-Wing Mixture of Experts for Streaming Recommendations

11

ranking-based evaluation strategy. Speciﬁcally, for each interaction between a
target user and a target item, we ﬁrst randomly sample 99 items which are not
interacted with this user as negative items, and then rank the target item among
these 100 items, i.e., the target one plus the 99 sampled ones. Finally, the rec-
ommendation accuracy is measured by two widely used metrics, i.e., Hit Ratio
(HR) and Normalized Discounted Cumulative Gain (NDCG) [6, 23].
Baselines. The following eight baselines are used for comparisons, including
iBPR, iGMF, iMLP, iNeuMF, RCD, eAls, SPMF, and OCFIF.

– Bayesian Personalized Ranking (BPR) [13] is a representative personalized
ranking method to optimize the matrix factorization. We adapt BPR to the
streaming setting, named as iBPR, by training it with new data continu-
ously via stochastic gradient descent.

– Neural Matrix Factorization (NeuMF) [5] is an advanced matrix factorization
model, which combines two other recommendation models, i.e., Generalized
Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP), to achieve
higher recommendation accuracy. We adapt these three recommendation
models, i.e., NeuMF, GMF, and MLP, to the streaming setting, named as
iNeuMF, iGMF, and iMLP, respectively, by training the recommendation
models with new data continuously via stochastic gradient descent.

– Randomized block Coordinate Descent (RCD) [1] and Element-wise Alter-
nating Least Squares (eAls) [6] are two representative approaches for opti-
mizing the matrix factorization models in the streaming setting. We enhance
RCD and eAls with abilities of batch processing to increase their throughput
for fair comparisons.

– Stream-centered Probabilistic Matrix Factorization (SPMF) [23] is a state-
of-the-art SRS. SPMF is originally performed along with a time-consuming
sampling method and does not perform well with our evaluation policy where
sampling needs to be frequently performed. For a fair comparison, we employ
our proposed VRS to prepare training data for SPMF.

– Online Collaborative Filtering with Implicit Feedback (OCFIF) [25] is the
only reported SRS employing multiple models (i.e., matrix factorization) to
avoid the limitations of a single model for higher recommendation accuracy.

In addition, we equip our proposed VRS-DWMoE with diﬀerent numbers of
experts (i.e., 2, 4, 6, and 8) for comparisons. For example, VRS-DWMoE 8 in-
dicates VRS-DWMoE equipped with 8 experts for both MoUE and MoIE.
Parameter Setting. For a fair comparison, we initialize the baselines with
parameters reported in their papers and optimize them for our settings. For
our VRS-DWMoE, we empirically set the learning rate to 0.001, the batch size
bs to 256, the loss coeﬃcient γ to 0.01, and the volume of reservoir to 10000
interactions. Besides, we employ the widely used negative sampling technique [22,
24, 25], where the reservoir is used to check if an interaction exists and the
negative sampling size is set to four, to improve the learning performance. We
also adopt L2 regularization and Adam optimizer to avoid overﬁtting and for
the optimization purpose, respectively. Other parameters including δ, λres, and

12

Yan Zhao et al.

Table 2. Performance comparison with baselines.

Datasets

MovieLens

Netﬂix

Yelp

Metrics

HR@10
256

NDCG@10
256

512

128

Ours

Baselines

Baselines

Data Receiving Speeds (sr) 128

eAls
RCD
iBPR
SPMF
iGMF
iMLP
iNeuMF
OCFIF

512
0.231 0.231 0.234 0.106 0.106 0.108
0.287 0.297 0.278 0.139 0.145 0.138
0.303 0.303 0.279 0.147 0.147 0.134
0.460 0.453 0.440 0.251 0.246 0.238
0.525 0.529 0.477 0.295 0.297 0.265
0.538 0.539 0.488 0.304 0.303 0.272
0.551 0.546 0.496 0.311 0.307 0.275
0.532 0.508 0.467 0.291 0.279 0.256
VRS-DWMoE 8 0.563 0.558 0.535 0.317 0.313 0.299
Improvement percentages5 2.20% 2.20% 7.90% 1.90% 2.00% 8.70%
0.395 0.389 0.362 0.211 0.207 0.192
0.447 0.436 0.435 0.226 0.226 0.219
0.685 0.686 0.627 0.396 0.395 0.360
0.701 0.669 0.640 0.425 0.397 0.378
0.747 0.748 0.577 0.482 0.482 0.352
0.787 0.782 0.624 0.519 0.510 0.369
0.801 0.798 0.711 0.531 0.529 0.430
0.745 0.734 0.606 0.457 0.453 0.357
VRS-DWMoE 8 0.821 0.814 0.790 0.553 0.548 0.515
Improvement percentages5 2.50% 2.00% 11.1% 4.10% 3.60% 19.8%
0.287 0.289 0.290 0.167 0.167 0.169
0.454 0.452 0.447 0.260 0.257 0.259
0.307 0.295 0.188 0.180 0.172 0.108
0.197 0.192 0.184 0.104 0.100 0.097
0.499 0.470 0.396 0.294 0.276 0.228
0.573 0.574 0.438 0.338 0.338 0.246
0.566 0.570 0.435 0.331 0.334 0.247
0.260 0.249 0.203 0.135 0.129 0.107
VRS-DWMoE 8 0.608 0.603 0.602 0.354 0.358 0.353
Improvement percentages5 6.10% 5.10% 37.4% 4.70% 5.90% 42.9%

eAls
RCD
iBPR
SPMF
iGMF
iMLP
iNeuMF
OCFIF

eAls
RCD
iBPR
SPMF
iGMF
iMLP
iNeuMF
OCFIF

Baselines

Ours

Ours

λnew are adjusted via cross validation to achieve the best performance in diﬀerent
cases.

4.2 Performance Comparison and Analysis
Experiment 1: Comparison with Baselines (for RQ1 and RQ2)
Setting. To answer RQ1 and RQ2, we compare our proposed VRS-DWMoE
(the number ne of experts is set to eight) with all eight baselines with a ﬁxed data
processing speed sp = 256 and diﬀerent data receiving speeds, where sr = 128
and sr = 512 indicate the underload scenario and overload scenario, respectively.
Result 1 (for RQ1). Table 2 shows the results of our proposed approach and
eight baselines on all three datasets. In all the cases, VRS-DWMoE 8 delivers
the highest recommendation accuracies (marked with bold font), and the im-
provement percentages of VRS-DWMoE 8 over the best-performing baselines

5 Improvement percentages over the best-performing baseline(s)

Double-Wing Mixture of Experts for Streaming Recommendations

13

Fig. 2. Performance of VRS. VRS outperforms all the other sampling methods.

(marked with underline) are introduced in the last row for each dataset, ranging
from 2.0% to 37.4% with an average of 8.5% in terms of HR@10, and ranging
from 1.9% to 42.9% with an average of 10.4% in terms of NDCG@10.

The superiority of VRS-DWMoE can be explained in two aspects: 1) VRS
addresses user preference drift while capturing long-term user preferences by
wisely complementing new data with sampled historical data, and 2) DWMoE
better learns the heterogeneous user preferences and item characteristics with
two MoEs, where each expert specializes in one underlying type of users or items.
Result 2 (for RQ2). The superiority of our DWMoE is veriﬁed by the cases
where sr = sp, i.e., sr = 256, in Table 2. Speciﬁcally, in these cases, both our
apporach and baselines utilize all the new data to train recommendation mod-
els, thus their recommendation accuracy only depends on their recommendation
models. Therefore, the superiority of DWMoE is conﬁrmed by the highest rec-
ommendation accuracy delivered by VRS-DWMoE in these cases. The reason for
this superiority is that DWMoE not only learns heterogeneous user preferences
and item characteristics with two dedicated MoEs, respectively, but also allows
each of their experts to specialize in one underlying type of users or items.
Experiment 2: Performance of VRS (for RQ3)
Setting. To answer RQ3, we replace our proposed VRS with existing sampling
methods, including New Data Only (NDO) [25], Reservoir-enhanced Random
sampling (RR) [2], and Sliding Window (SW) [16], for comparisons. In this
experiment, we report the results in the underload scenario only to save space
while the results in the overload scenario are similar to the reported ones.
Result 3 (for RQ3). As Fig. 2 illustrates, our proposed VRS outperforms all
the other sampling methods. The improvements of VRS over the best-performing
baseline, i.e., NDO, range from 1.2% (on Netﬂix) to 2.0% (on Yelp) with an
average of 1.9% in terms of HR@10, and range from 3.2% (on Netﬂix) to 4.3%
(on Yelp) with an average of 3.4% in terms of NCDG@10. The eﬀectiveness
of VRS comes from wisely complementing new data with sampled historical
data while guaranteeing the proportion of new data, and thus addressing user
preference drift while capturing long-term user preferences.
Experiment 3: Impact of Number of Experts (for RQ4)
Setting. To answer RQ4, we compare the performance of VRS-DWMoE when

MovieLensNetflixYelpDatasetsHR@100.50.550.60.750.8MovieLensNetflixYelpDatasetsNDCG@100.260.30.340.460.50.5414

Yan Zhao et al.

Fig. 3. Impact of the number (ne) of experts. VRS-DWMoE delivers higher
recommendation accuracy with more experts.

equipped with diﬀerent numbers (ne) of experts, i.e., 2, 4, 6, and 8. In this
experiment, we report the results in the overload scenario only to save space
while the results in the underload are similar to the reported ones.
Result 4 (for RQ4). As Fig. 3 illustrates, our proposed VRS-DWMoE de-
livers higher recommendation accuracy when equipped with more experts. The
improvements of VRS-DWMoE equipped with eight experts over that equipped
with two experts range from 2.7% (on Netﬂix) to 6.5% (on Yelp) with an average
of 4.4% in terms of HR@10, and range from 4.0% (on Netﬂix) to 8.4% (on Yelp)
with an average of 6.3% in terms of NCDG@10. The reason for the superior-
ity of more experts is that more experts better complement one another with
their expertise to more eﬀectively learn user preferences and item characteristics.

5 Conclusions
In this paper, we have proposed a Variational and Reservoir-enhanced Sampling
based Double-Wing Mixture of Experts framework (VRS-DWMoE) for accu-
rate streaming recommendations. We ﬁrst propose VRS to wisely complement
new data with sampled historical data to address user preference drift while
capturing long-term user preferences. After that, with these sampled data, DW-
MoE learns heterogeneous user preferences and item characteristics with two
MoEs, i.e., MoUE and MoIE, respectively, and then makes recommendations
with learned preferences and characteristics. The superiority of VRS-DWMoE
has been veriﬁed by extensive experiments. In the future, we will wisely utilize
diﬀerent numbers of experts in MoUE and MoIE and study more eﬀective reser-
voir maintenance strategy for higher accuracy of streaming recommendations.

6 Acknowledgements

This work was partially supported by Australian Research Council Discovery
Projects DP180102378 and DP210101810.

References

1. Devooght, R., Kourtellis, N., Mantrach, A.: Dynamic matrix factorization with pri-

ors on unknown values. In: SIGKDD. pp. 189–198 (2015)

2468Number of Experts HR@100.520.550.580.610.750.782468Number of ExpertsNDCG@100.280.30.320.340.360.480.50.52Double-Wing Mixture of Experts for Streaming Recommendations

15

2. Diaz-Aviles, E., Drumond, L., Schmidt-Thieme, L., Nejdl, W.: Real-time top-n rec-

ommendation in social streams. In: RecSys. pp. 59–66 (2012)

3. Forbes Report:

forbes.com/sites/benkepes/2015/06/03/30-of-servers-are-sitting-

comatose-according-to-research/. Last accessed 29 May 2020

4. Guo, L., Yin, H., Wang, Q., Chen, T., Zhou, A., Quoc Viet Hung, N.: Streaming

session-based recommendation. In: SIGKDD. pp. 1569–1577 (2019)

5. He, X., Liao, L., Zhang, H., Nie, L., Hu, X., Chua, T.S.: Neural collaborative ﬁlter-

ing. In: WWW. pp. 173–182 (2017)

6. He, X., Zhang, H., Kan, M.Y., Chua, T.S.: Fast matrix factorization for online

recommendation with implicit feedback. In: SIGIR. pp. 549–558 (2016)

7. Hou, Y., Yang, N., Wu, Y., Yu, P.S.: Explainable recommendation with fusion of

aspect information. World Wide Web 22(1), 221–240 (2019)

8. Lefakis, L., Fleuret, F.: Reservoir boosting: Between online and oﬄine ensemble

learning. In: NIPS. pp. 1412–1420 (2013)

9. Ma, J., Zhao, Z., Yi, X., et al.: Modeling task relationships in multi-task learning

with multi-gate mixture-of-experts. In: SIGKDD. pp. 1930–1939 (2018)

10. Masoudnia, S., Ebrahimpour, R.: Mixture of experts: a literature survey. Artif.

Intell. Rev. 42(2), 275–293 (2014)

11. McKinnon, C.D., Schoellig, A.P.: Learning multimodal models for robot dynamics
online with a mixture of gaussian process experts. In: ICRA. pp. 322–328 (2017)
12. Papagelis, M., Rousidis, I., Plexousakis, D., et al.: Incremental collaborative ﬁlter-
ing for highly-scalable recommendation algorithms. In: ISMIS. pp. 553–561 (2005)
13. Rendle, S., Freudenthaler, C., Gantner, Z., Schmidt-Thieme, L.: BPR: bayesian

personalized ranking from implicit feedback. In: UAI. pp. 452–461 (2009)

14. Shazeer, N., Mirhoseini, A., et al.: Outrageously large neural networks: The

sparsely-gated mixture-of-experts layer. In: ICLR. pp. 1–19 (2017)

15. Silva, J.G., Carin, L.: Active learning for online bayesian matrix factorization. In:

SIGKDD. pp. 325–333 (2012)

16. Soares, S.G., Ara´ujo, R.: An on-line weighted ensemble of regressor models to

handle concept drifts. Eng. Appl. Artif. Intell. 37, 392–406 (2015)

17. Song, D., Li, Z., Jiang, M., Qin, L., Liao, L.: A novel temporal and topic-aware

recommender model. World Wide Web 22(5), 2105–2127 (2019)

18. Su, X., Greiner, R., Khoshgoftaar, T.M., Zhu, X.: Hybrid collaborative ﬁltering

algorithms using a mixture of experts. In: ICWI. pp. 645–649 (2007)

19. Vinagre, J., Jorge, A.M., Gama, J.: Fast incremental matrix factorization for rec-

ommendation with positive-only feedback. In: UMAP. pp. 459–470 (2014)

20. Wang, Q., Yin, H., Hu, Z., Lian, D., et al.: Neural memory streaming recommender

networks with adversarial training. In: SIGKDD. pp. 2467–2475 (2018)

21. Wang, S., Cao, L.: Inferring implicit rules by learning explicit and hidden item

dependency. IEEE Trans. Syst. Man Cybern. Syst. 50(3), 935–946 (2020)

22. Wang, S., Hu, L., Wang, Y., Sheng, Q.Z., Orgun, M., Cao, L.: Modeling multi-
purpose sessions for next-item recommendations via mixture-channel purpose rout-
ing networks. In: IJCAI. pp. 3771–3777 (2019)

23. Wang, W., Yin, H., Huang, Z., Wang, Q., Du, X., Nguyen, Q.V.H.: Streaming

ranking based recommender systems. In: SIGIR. pp. 525–534 (2018)

24. Xu, Y., Zhu, Y., Shen, Y., Yu, J.: Leveraging app usage contexts for app recom-

mendation: a neural approach. World Wide Web 22(6), 2721–2745 (2019)

25. Yin, J., Liu, C., Li, J., Dai, B., Chen, Y.c., Wu, M., Sun, J.: Online collaborative

ﬁltering with implicit feedback. In: DASFAA. pp. 433–448 (2019)

26. Yu, Y., Gao, Y., Wang, H., Wang, R.: Joint user knowledge and matrix factoriza-

tion for recommender systems. World Wide Web 21(4), 1141–1163 (2018)

