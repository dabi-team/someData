Applying advanced machine learning models to
classify electro-physiological activity of human brain
for use in biometric identiﬁcation

7
1
0
2

g
u
A
3

]

G
L
.
s
c
[

1
v
7
6
1
1
0
.
8
0
7
1
:
v
i
X
r
a

Iaroslav Omelianenko
NewGround LLC
Kiev, Ukraine
Email: yaric@newground.com.ua

Abstract—In this article we present the results of our research
related to the study of correlations between speciﬁc visual
stimulation and the elicited brain’s electro-physiological response
collected by EEG sensors from a group of participants. We will
look at how the various characteristics of visual stimulation
affect the measured electro-physiological response of the brain
and describe the optimal parameters found that elicit a steady-
state visually evoked potential (SSVEP) in certain parts of the
cerebral cortex where it can be reliably perceived by the electrode
of the EEG device. After that, we continue with a description of
the advanced machine learning pipeline model that can perform
conﬁdent classiﬁcation of the collected EEG data in order to
(a) reliably distinguish signal from noise (about 85% validation
score) and (b) reliably distinguish between EEG records collected
from different human participants (about 80% validation score).
Finally, we demonstrate that the proposed method works reliably
even with an inexpensive (less than $100) consumer-grade EEG
sensing device and with participants who do not have previous
experience with EEG technology (EEG illiterate). All this in
combination opens up broad prospects for the development of
new types of consumer devices, [e.g.] based on virtual reality
helmets or augmented reality glasses where EEG sensor can be
easily integrated.

The proposed method can be used to improve an online user
experience by providing [e.g.] password-less user identiﬁcation
for VR / AR applications. It can also ﬁnd a more advanced
application in intensive care units where collected EEG data can
be used to classify the level of conscious awareness of patients
during anesthesia or to automatically detect hardware failures
by classifying the input signal as noise.

Keywords—biometric identiﬁcation; electro-physiological brain
activity; machine learning; auto-encoder; visually evoked potential;
SSVEP; EEG

I.

INTRODUCTION

A steady increase in the computing power of mobile
devices allows them to be fully integrated with a variety of
portable or wearable consumer devices such as virtual reality
(VR) helmets, augmented reality (AR) glasses, monitors of
the health and ﬁtness, and so on. At the same time, they have
enough computational resources to execute advanced machine
learning models for processing of biometric data received from
various sensors in the real time. One of these non-intrusive
sensors that can be used to collect biometric information
is the sensor to monitor the electro-physiological activity of
the brain - electroencephalography (EEG). To collect EEG
data it’s enough to place electrodes along the scalp of the

user. Moreover, the EEG sensors can be easily integrated into
VR helmets or AR glasses, also providing easy means for
speciﬁc visual stimulation. As has been demonstrated in recent
studies [1], [2], exposing a person to external stimuli, such
as aural tone or a speciﬁc visualization, can cause a speciﬁc
response in the electro-physiological activity of the brain. And
this stationary cerebral cortex response, called steady-state
visually evoked potentials (SSVEP) [2], demonstrates a strong
correlation with the parameters of visual stimuli, such as ﬂicker
frequency and visual appearance (conﬁguration).

In [1], it was found that a reliable SSVEP response can
be detected in the Delta and Alpha (Low and High) frequency
bands of the EEG signal collected at stimulation with a fre-
quency of visual stimuli in the range: 4 − 10Hz. That is, visual
stimuli with a certain frequency and conﬁguration can elicit a
reliable SSVEP response in certain parts of the cerebral cortex,
which leads to a resonance effect that can be easily detected
by EEG sensors placed in speciﬁc positions on the scalp of
the participant’s head. (This can be partially explained if we
consider neural networks of the cerebral cortex as a structural
dynamic network of oscillators [3] which can be entrained by
speciﬁc stimulus; where different regions of cerebral cortex
having speciﬁc resonance frequencies amplifying its response
on stimulation.) Later, the ampliﬁed response detected by EEG
sensors can be processed using advanced machine learning
classiﬁcation methods to extract useful patterns.

In this work, we use a consumer-grade EEG sensing device
with a single electrode located above the FP1 position, which
collects the electrical activity of the frontal and pre-frontal
cerebral cortex. Because of this limitation, we are most inter-
ested in ﬁnding speciﬁc visual stimuli capable of eliciting a
reliable SVEP response in these areas. From the work of other
researchers [1], we know that the frontal cortex has a strong
response in the High Alpha band, so we focused our efforts on
creating a main visual stimulus with a frequency in the range
of 8−10Hz and auxiliary visual stimulus with the frequency of
one harmonic down. In [1] it was found that with simultaneous
use of several visual stimuli with frequencies related on the
harmonic scale, the SSVEP response of certain parts of neural
networks of the cerebral cortex can be ampliﬁed.

The purpose of this study is to create an advanced ma-
chine learning classiﬁcation model suitable for processing of
collected EEG records and capable of revealing the differences:

-

between signal and noise,

1 | P a g e

 
 
 
 
 
 
-

between EEG records collected from different human
participants.

This paper is organized as follows: In Section II, we
describe the raw input signals received from the EEG device,
visual stimulation details, and basic information about the
involved participants. It is followed in Section III by details
about collected data records and how it was pre-processed
before the analysis. In Section IV, we provide description of
machine learning classiﬁcation model applied to the data cor-
pus. Then, the Section V follows, describing the methodology
used to ﬁnd the optimal conﬁguration of visual stimulation
and to ﬁnd optimal hyper-parameters of the machine learning
classiﬁcation model. After that in Section VI we consider
achieved results (validation scores) for both signal / noise and
participants identiﬁcation tasks. Finally, in Section VII and
VIII we describe our plans for future experiments and review
the results obtained during the research.

II. EXPERIMENT SETUP DESCRIPTION

A. EEG monitoring device and raw input signals

In our experiments, we use NeuroSky MindWave device
that monitors the brain’s electro-physiological activity using
one electrode at the FP1 position and other at the ear lobe. It
has a sampling rate of 512 Hz and decomposes the raw input
signal on several frequency bands at the hardware level using
a fast Fourier transform (FFT) [4]. After FFT decomposition,
the MindWave device broadcasts the decomposed EEG signal
once per second (i.e., the refresh rate is 1Hz). See Table I

TABLE I: The ranges of frequency bands for FFT decomposed
EEG signal

Band name

Frequency range, Hz

Delta, ∆

Theta, Θ

Low Alpha, Lα

High Alpha, Hα

Low Beta, Lβ

High Beta, Hβ

Low Gamma, Lγ

High Gamma, Hγ

1-3

4-7

8-9

10-12

13-17

18-30

31-40

41-50

Additionally,

it provides two complex synthetic signals
calculated by combining data from several frequency bands,
namely:

-

Attention to indicate users attention level in range
[1, 100]

- Meditation to indicate users contemplation level in

range [1, 100]

We use the mentioned complex synthetic signals as control
signals that trigger the recording / processing of EEG data
when a certain threshold value is reached.

B. Visual stimulation and data collection

Following research [1], we created an advanced software
library to produce a certain visual stimulation. The visualiza-
tion library provides tools for conﬁguring various visualization

Fig. 1: The screen shoot of visual stimulator window in WISP
rendering mode.

options and applying various visual modeling schemes: WISP
and WAVE. This allows a series of experiments with different
parameters to be performed to ﬁnd the optimal parameters for
eliciting proper SSVEP response.

The visual stimuli created by the visualization library have
a strong correlation with the collected EEG data in real time,
providing positive feedback to the user on the activity of the
cerebral cortex. In the WISP rendering mode, this correlation
is represented as the relative position of points in polar coordi-
nates and as the color of points and wisp lines (see Figure 1).
The position of the points relative to the center, determined
by the strength of the EEG signal for a particular frequency
band. Each frequency band has a certain color assigned to it.
To elicit appropriate SSVEP response the visualization has two
ﬂickering areas:

1)

2)

wisp of lines with dots - ﬂickers with selected primary
frequency
background - ﬂickers with secondary frequency (one
harmonic down)

The background color saturation is determined by the cur-
rent value of selected control signal - Attention or Meditation,
where higher values result in a more saturated color. Thus, the
saturation of the background color provides positive feedback
for the participant about current value of the control signal.

The central idea of the described scheme of visual stim-
ulation is to achieve aesthetically pleasing and attractive vi-
sualization, which can be used in consumer devices: helmets
VR, AR glasses, etc. But at the same time, it should provide
appropriate visual stimulation to elicit proper SSVEP response
from cerebral cortex.

Another studied mode of visual stimulation, we called
WAVE. Its main difference from WISP is that it displays only
dots, skipping lines that connect them to the center point
(see Figure 2). We found that different visual modes have
a variable effect on elicited SSVEP response in different
frequency ranges of stimuli. In the WISP rendering mode the
most effective primary stimulation frequency is 10Hz (High
Alpha) and secondary - 5Hz. And for the WAVE this is: primary
- 8Hz (Low Alpha) and secondary - 4Hz.

2 | P a g e

seconds, if participant can maintain a continuous high-level
value of the control signal. But this can take much longer
if the value of the control signal drops below the threshold
and the recording pauses until participant can again reach the
threshold value.

C. Experiment Participants

In our experiments we collected EEG data records from

three participants:

1) male, 43 years, −1 myopia, astigmatism
2)
3) male 35 years, −7 myopia

female 28 years, normal sight

For each participant, we collected from six to eighteen
sessions of EEG records with various schemes of visual
stimulation and at different times. It is very important that
EEG sessions be recorded at different times in order to observe
the electro-physiological response of the participants’ brain in
different conditions.

III. DATA CORPUS DESCRIPTION

The data collected from the EEG device during a particular
recording session is stored as comma-separated records with
40 rows, 11 columns wide. Each line contains three meta-
data variables (time stamp of record, frequency of primary and
secondary stimuli) and eight values for each frequency band.

The frequency bands data collected from EEG device
represent a power spectrum and its values vary exponentially
in the range [0, 32767]. But performance of a majority of
machine learning methods is best with small ﬂoating point
values centered around zero. Thus, in order to improve the
quality of the collected data and to balance the values of
the data points for different frequency bands, we scaled it
to ﬁt in range [0, 1] during the preprocessing. And the pre-
processed data is later used as input for the machine learning
classiﬁcation model.

IV. MACHINE LEARNING CLASSIFICATION PIPELINE
MODEL DESCRIPTION

Essentially, the collected data corpus of EEG records is a
time series. Therefore, it may seem natural to analyze it using
machine learning methods, which are usually considered to
have the best architecture for time series data analysis, e.g.
Recurrent Neural Networks (RNN) and its modern reincarna-
tion - Long Short Time Memory Neural Network (LSTM) [6].
But for RNN model to learn useful patterns from input data at
least two conditions should be met: (a) the data samples should
be collected at equal time intervals between events; (b) it is
important to collect a signiﬁcant number of data samples for
each recording session. In our experiment, no above condition
can be fulﬁlled. First of all, it is unpractical to collect a lot
of data samples for consumer device setup, because people
easily get bored during long recording sessions. Furthermore,
we collect EEG data events only when the level of the control
signal exceeds a certain threshold, which makes our time series
rather inconsistent with different intervals between time stamps
of collected events.

Taking into account the speciﬁc conditions of our experi-
ment mentioned above, we decided to explore a novel approach

3 | P a g e

Fig. 2: The screen shoot of visual stimulator window in WAVE
rendering mode.

The graphic interface of the created visualization library
also allows you to set a certain control signal threshold that
starts / stops recording the received EEG signals. We learned
that with higher threshold values, it is much more difﬁcult for
a participant to maintain that level of control signal (Attention
/ Meditation), but the collected data is of better quality. Thus,
it is important to ﬁnd the right balance between the quality of
the collected data and ease of use for the participants. In our
experiments, we applied four threshold values from 80 down
to 50 in steps of ten. The optimal threshold value for the WISP
rendering mode is 70 providing a good balance between the
quality of the collected data and ease of use for the participant.

We measure quality of the collected data and the applica-
bility of a speciﬁc conﬁguration of visual stimuli, by checking
Pearson product-moment correlation [5] between the processed
data from the recorded sessions for each participant per each
conﬁguration. (For more information on calculating correlation
coefﬁcients, see Section: ” Finding Optimal Conﬁguration for
Visual Stimulation”.) And for further analysis, the conﬁgu-
ration of visual stimuli creating the most correlated results
is considered. Our hypothesis for this is that the maximum
correlation between recording sessions is the result of properly
elicit SSVEP response from a speciﬁc parts of the cerebral
cortex that has a steadily recognizable pattern among all
recorded sessions.

Applying the above-mentioned method to estimate quality
of the collected EEG data, following visualization parameters
were chosen for all participants as optimal:

- WISP rendering mode

-

-

-

10Hz primary and 5Hz secondary ﬂicker frequencies

Attention complex synthetic signal as a control signal

70 as the control signal threshold value

In a series of experiments, we found that reliable data
processing requires at least forty collected data samples (EEG
events) per session. The MindWave device broadcasts data
event signals (with 8 frequency bands values) once per second.
This means that one recording session should take at least 40

Fig. 3: The machine learning processing pipeline scheme from
left to right: the EEG input data source, the auto-encoder, and
the classiﬁer.

to the analysis of time series, which allows us to extract
useful patterns (essence) from the analyzed EEG signal records
and classify it later. Our idea is to create advanced machine
learning classiﬁcation pipeline, where the input EEG data is
processed in two stages (see Figure 3):

-

-

at the ﬁrst stage, raw input data are analyzed using
unsupervised machine learning method based on the
auto-encoder neural network with single hidden layer
[7]

at the second stage, the learned weights of the auto-
encoder hidden layer (data encoding) are used as input
for the classiﬁer of choice to train the supervised
classiﬁcation model

In the following we describe considered methods of ma-

chine learning used at both stages, with more details.

A. The First stage - Auto-Encoder Selection

In our experimental setup - per each individual session -
we have the data corpus consisting of eight frequency bands
values collected for forty data events. That gives us the features
space dimension width of 320 for each EEG recording session.
At the same time, we have very limited number of recording
sessions (6 to 18) for every participant, which is much less than
the dimensionality of the features space. Such characteristics
of the input data make it unacceptable for analysis by almost
any machine learning classiﬁcation model, since ideally the
number of data samples must signiﬁcantly exceed the number
of features and not vice versa. This forced us to look for a
speciﬁc method of machine learning that can extract its reliable
representation (encoding) from the raw EEG input signal and
accordingly reduce the dimensionality of the features space.

Our attention was captured by family of unsupervised
machine learning methods called auto-encoders [7]. An auto-
encoder takes an input x ∈ [0, 1]d and ﬁrst maps it (with
an encoder) to a hidden representation h ∈ [0, 1]d(cid:48)
through a
deterministic mapping, e.g.:

h = σ(Wx + b)

(1)

where σ is a non-linearity such as the sigmoid.

The latent representation h, or encoding is then mapped
back with a decoder into a reconstruction z of the same shape
as x. The mapping happens through a similar transformation,
e.g.:

z = σ(W(cid:48)h + b(cid:48))

(2)

z should be seen as a prediction of x, given the code h.
Optionally, the weight matrix W(cid:48) of the reverse mapping may
be constrained to be the transpose of the forward mapping:
W(cid:48) = WT . This is referred to as tied weights. The parameters
of this model (W, b, b(cid:48) and, if one doesn’t use tied weights,
also W(cid:48)) are optimized such that the average reconstruction
error is minimized.

The reconstruction error can be measured in many ways,
depending on the appropriate distributional assumptions on the
input given the code. The traditional squared error L(xz) =
||x − z||2, can be used as well. If the input is interpreted
as either bit vectors or vectors of bit probabilities, the cross-
entropy of the reconstruction can be used:

LH (x, z) = −

d
(cid:88)

[xk log zk + (1 − xk) log(1 − zk)]

(3)

k=1

The h can be viewed as lossy compression of x and op-
timization makes it a good compression for training examples
and hopefully for all other examples as well. But this can not
be guaranteed for arbitrary inputs. The simple auto-encoder
gives low reconstruction error on test samples from the same
distribution as train samples, but usually gives higher error
values for inputs randomly chosen from input space.

To prevent auto-encoder from learning identity function of
input signal and to force it to learn something useful about
input signal in its hidden units, several methodologies can
be applied: (a) addition of sparsity to inputs, (b) addition of
randomness to transformation (encoding) or (c) introducing
speciﬁc explicit regularizer to the objective function.

In this research we study two types of auto-encoders with

various learning enhancements applied:

-

-

Denoising auto-encoder (addition of sparsity to inputs)

Contractive auto-encoder (the explicit regularizer to
the objective function)

The denoising auto-encoder [8] is a stochastic version
of simple auto-encoder where stochastic corruption process
randomly sets many of inputs (maximum half of them) to
zero. Then we train it to reconstruct correct input from a
stochastically corrupted version of it. As result, the higher level
representations of input data (encoding) are relatively stable
and robust to the corruption of input data.

The contractive auto-encoder [9] adds explicit regularizer
to the objective function that forces model to obtain a ro-
bust representation of the input space not sensitive to slight
variations of input data. This regularizer corresponds to the
Frobenius norm (L2) of the Jacobian matrix of the hidden
representation with respect to the input. The ﬁnal objective
function has the following form:

d
(cid:88)

L = −

[xk log zk + (1 − xk) log(1 − zk)] + λ

d
(cid:88)

n
(cid:88)

J2
ij

k=1

i=1

j=1

(4)
where z = σ(W(cid:48)h + b(cid:48)) is the reconstruction of input vector,
Ji = hi(1 − hi) · Wi is Jacobian of h with respect to x, and
h = σ(Wx + b) is the projection of the input into the latent
space h.

4 | P a g e

is well known that

Both mentioned auto-encoder variations are robust to the
slight corruption of input data. This is especially useful for
our experiment, since it
the electro-
physiological activity of the brain is non-stationary and varies
greatly, depending on the circumstances. I.e. the collected EEG
data for each subsequent recording session under the same type
of visual stimuli can give the same essence (compressed repre-
sentation), but can introduce various non-stationary deviations
from previous sessions. Using an auto-encoder to analyze the
input data at the ﬁrst stage, we hope to reduce non-stationary
deviations and extract a useful compressed representation.
Then, at the second stage, the extracted compressed repre-
sentation with signiﬁcantly reduced dimensionality of features
space will be fed into the classiﬁer of choice.

The above-mentioned auto-encoders was implemented in
Python programming language using Theano framework [20].

TABLE II: The classiﬁers used in the study with range of
hyper-parameter values applied for exhaustive grid search.

Classiﬁer

Parameters space

Random Forest

Ada Boost

Decision Tree

max depth: [3, 5, 8, None], max features: [1, 3, 4],
min samples split: [2, 3, 4], min samples leaf: [1,
3, 10], bootstrap: [True, False], criterion: [”gini”,
entropy], n estimators: [10, 20, 50, 100, 200]

learning rate: [0.01, 0.1, 1], n estimators: [10, 20,
50, 100]

max depth: [3, 5, 8, None], min samples split: [2,
3, 4], min samples leaf: [1, 3, 10, 20, 30]

Gaussian Process

warm start: [True, False]

Multi Layer Perceptron

K-neighbors

alpha: [0.0001, 0.001, 0.01],
learning rate init:
[0.001, 0.01, 0.1, 0.5], momentum: [0.9, 0.99,
0.999], solver: [”lbfgs”, ”sgd”, adam”], activation:
[”logistic”, ”tanh”, relu”], hidden layer sizes: [4,
8, 10]

n neighbors:
”kd tree”, ”brute”]

[2, 3, 5], algorithm:

[”ball tree”,

B. The Second Stage - Classiﬁers Evaluation

Gaussian Nave Bayes

priors: [None]

At the end of the ﬁrst stage of the processing pipeline, the
dimensionality of data corpus features space is considerably
reduced. After that, at the second stage, the data is fed to a
set of classiﬁers from simple to advanced in order to ﬁnd the
one that has the most powerful prediction model.

To automate the evaluation of classiﬁers against different
sets of hyper-parameters, we use exhaustive grid search with
cross-validation. This method exhaustively generates candi-
dates from the grid of parameter values speciﬁed for each
classiﬁer, and then performs a 3-fold cross-validation (CV)
of the predictive performance of each classiﬁer with respect
to the input data [10]. In the k-fold cross-validation method,
the training set is split into smaller sets and the following
procedure is performed for each of the folds:

1)

2)

a model is trained using k − 1 of the folds as training
data
the resulting model is validated on the remaining part
of the data (i.e., it is used as a test set to compute a
performance measure such as accuracy)

The resulting classiﬁer performance measure is done by
averaging scores computed for each fold. Thus, we can avoid
the effect of model overﬁtting, when it shows perfect score for
train data but fails to predict anything useful for unseen data.
Refer to Table II for a list of all tested classiﬁers and all tested
values of corresponding hyper-parameters per each estimator.

Hereafter we provide short description of each tested

classiﬁer.

Random Forest classiﬁer [11] is a meta estimator that ﬁts
a number of decision tree classiﬁers on various sub-samples
of the dataset and use averaging to improve the predictive
accuracy and control overﬁtting.

Ada Boost classiﬁer [12] is a meta-estimator that begins by
ﬁtting a classiﬁer on the original dataset and then ﬁts additional
copies of the classiﬁer on the same dataset but where the
weights of incorrectly classiﬁed instances are adjusted such
that subsequent classiﬁers focus more on difﬁcult cases.

Decision Tree classiﬁer [13] is a ﬂow-chart-like structure,
where each internal (non-leaf) node denotes a test on an

Quadratic Discriminant
Analysis

priors: [None], reg param: [0.0, 0.01, 0.1, 0.9]

Support Vector Machine
with RBF kernel

C: [0.1, 0.5, 1.0], gamma: [0.1, 0.5, 1.0, 2.0, 3.0,
’auto’]

Support Vector Machine
with Linear kernel

C: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5,
1.0]

attribute, each branch represents the outcome of a test, and
each leaf (or terminal) node holds a class label. This structure
allows to go from observations (branches) to the conclusions
about the item’s target value (leaves).

Gaussian Process classiﬁer [14] based on Laplace approx-
imation, which is used for approximating the non-Gaussian
posterior by a Gaussian.

Multi-layer Perceptron (MLP) classiﬁer [15] is an ar-
tiﬁcial neural network based classiﬁer optimizing log-loss
function using LBFGS or stochastic gradient descent.

K-neighbors classiﬁer [16] use a type of instance-based
learning or non-generalizing learning where classiﬁcation is
computed from a simple majority vote of the nearest neighbors
of each point: a query point is assigned the data class which
has the most representatives within the nearest neighbors of
the point.

Gaussian Naive Bayes [17] is a model assuming that the
continuous values associated with each class are distributed
according to a Gaussian distribution.

Quadratic Discriminant Analysis [18] is a classiﬁer
with a quadratic decision boundary, generated by ﬁtting class
conditional densities to the data and using Bayes rule.

Support Vector Machine classiﬁer [19] builds a represen-
tation of the examples as points in space, mapped so that the
examples of the separate categories are divided by a clear gap
that is as wide as possible. New examples are then mapped
into that same space and predicted to belong to a category
based on on which side of the gap they fall.

We implemented exhaustive grid search with 3-fold cross-
validation for all above mentioned classiﬁers in Python pro-
gramming language using Scikit-learn framework [21].

5 | P a g e

3)

4)

(10/5Hz). It was found that for best results the auto-
encoder should have only two units in the hidden
layer.
The learned weight matrix of the auto-encoder’s
hidden layer (compressed input data representation)
per each recording session then collected as represen-
tation data matrix with columns holding compressed
data for each session.
Finally, the Pearson product-moment correlation co-
efﬁcients calculated from representation matrix and
heat map plot with correlations are rendered (see
Figure 4).

B. Finding Optimal Conﬁguration for Machine Learning Clas-
siﬁcation Pipeline Model

The optimal conﬁguration of classiﬁcation pipeline was
found in a series of experiments by applying various hyper-
parameters to auto-encoders and classiﬁers. After that, the
classiﬁcation model with the maximum validation score was
chosen as optimal. To automate the process of selecting
the optimal model, a software framework was created that
performs the following procedures:

1)

2)

3)

starts preprocessor to process the raw input data cor-
pus consisting of collected EEG recording sessions,
uses auto-encoder against preprocessed input data to
extract useful patterns,
perform classiﬁers evaluation against extracted pat-
terns as described in Section: ”The Second Stage -
Classiﬁers Evaluation”.

The experimental framework allows to separately deﬁne
various conﬁguration parameters for each processing stage.
Thus, the conﬁguration of each experiment can be encapsulated
in a separate Python script, which makes it easy to reproduce
a speciﬁc experiment in the future.

We tested a variety of hyper-parameters combinations per
each auto-encoder with different sets of ﬁltered input data sam-
ples (only values for speciﬁc frequency bands are included).
As result, we found that learning rate, contraction / corruption
level and the number of learning epochs can be ﬁxed by the
values presented in Table III. Only the batch size, the number
of auto-encoder’s hidden units and frequency bands included
into input data corpus, can be changed when searching for the
best validation score.

VI. RESULTS

In this paper, we considered the possibility of creating
reliable machine learning classiﬁcation pipeline model able to:

1)

2)

conﬁdently distinguish between signal and noise in
collected EEG records
conﬁdently classify EEG records of different partici-
pants, that is, provide means to determine which EEG
record belongs to which participant.

Hereafter we consider achieved results in more details.

6 | P a g e

Fig. 4: The heat map with correlation coefﬁcients between
eight recording sessions for one of the experiment participants.
It can be seen that majority of sessions highly correlate with
each other and only session #6 is a bit outlier. Such high
correlation values is a good sign that applied conﬁguration of
the visual stimuli is optimal to elicit robust SSVEP response
which can be compressed to extract useful pattern (encoding).

V. FINDING OPTIMAL EXPERIMENT CONFIGURATION

The details of the experiment described above suggest that
in order to obtain reliable classiﬁcation, it is important to ﬁnd
optimal conﬁguration parameters for both parts of the exper-
iment: visual stimulation and machine learning classiﬁcation
pipeline.

Hereafter we consider in more details how optimal conﬁg-

uration was found.

A. Finding Optimal Conﬁguration for Visual Stimulation

To achieve the objectives of the experiment, ﬁrst, we
need to ﬁnd the optimal conﬁguration of visual stimuli that
elicit a reliable SSVEP response in the cerebral cortex of
participants. The optimal conﬁguration should give comparable
results for different EEG sessions recorded on different times.
As mentioned in Subsection: ”Visual stimulation and data
collection” to do this we conducted series of experiments
(recording sessions) and evaluate collected data by calculating
Pearson product-moment correlation [5] between outputs from
the ﬁrst stage of machine learning pipeline (auto-encoder).
Our hypothesis is that the visual stimulation scheme leading
to outputs with the maximal correlation can be considered
optimal.

The correlation coefﬁcients can be calculated as following:

1)

2)

The collected EEG raw input data preprocessed by
scaling it down to ﬁt range [0, 1] (see Section: ”Data
Corpus Description”).
After that, the scaled data corpus is fed into auto-
encoder of choice. The input data is ﬁltered to include
only Delta and High Alpha bands. These bands were
chosen based on the results of [1], which state that
the elicited SSVEP response should have bands fre-
quencies close to the frequencies of the visual stimuli

TABLE III: The optimal hyper-parameters for auto-encoders
for signal / noise classiﬁcation task.

values

Contractive
auto-encoder

Denoising
auto-encoder

Hyper-parameter

Batch size

Learning rate

Tested
range

[1, 10]

[0.001, 0.1]

Number of units in hid-
den layer

[2, 10]

1 or 10

0.1

5

5

0.1

5

Number
epochs

of

learning

Contraction level
tractive auto-encoder)

(con-

Corruption level (denois-
ing auto-encoder)

Included frequency bands

[104, 5 · 104]

5 · 104

5 · 104

[0.1, 0.3]

[0.1, 0.3]

0.1

-

-

0.1

∆, Θ, Lα,
Hα, Lβ, Hβ,
Lγ, Hγ

∆, Θ, Lα,
Hα, Lβ, Hβ

∆, Θ, Lα,
Hα, Lβ, Hβ

A. Signal / Noise Classiﬁcation

For this task our main goal is to build classiﬁer capable
of distinguishing between signal and noise records collected
under different conditions and at different times. The signal
records include SSVEP affected records plus EEG records
obtained from participants performing other cognitive tasks
(sky watching, reading, etc). The basic requirement for the
proper signal record - is to be collected when the value of the
control signal (Attention or Meditation) is greater than or equal
to the speciﬁed threshold value. The noise records are collected
when the electrodes of the EEG device are improperly installed
on the participants (for example, the base electrode is not
connected) or when the device is turned on but not connected
to the participant at all. At total, we studied data samples
collected over 26 signal and 26 noise sessions.

TABLE IV: The comparison of the best validation scores for
signal / noise classiﬁcation per particular set of included fre-
quency bands and speciﬁc values of contractive auto-encoder
hyper-parameters. The score value is given as the average of 3-
fold cross validation with standard deviation among individual
values for each fold.

Frequency
bands included

Batch size

# of hid-
den units

Best classiﬁer

Validation score

∆, Hα

∆, Lα, Hα

∆, Θ, Lα, Hα

∆, Θ, Lα, Hα

∆, Θ, Lα,
Hα, Lβ

∆, Θ, Lα,
Hα, Lβ, Hβ

∆, Θ, Lα,
Hα, Lβ, Hβ,
Lγ

5

5

5

1

5

10

5

2

4

3

2

4

5

9

Multi
Perceptron

Layer

Multi
Perceptron

Layer

SVM with lin-
ear kernel

Gaussian Nave
Bayes

Multi
Perceptron

Layer

Multi
Perceptron

Layer

0.736 (std: 0.184)

0.736 (std: 0.050)

0.755 (std: 0.034)

0.833 (std: 0.068)

0.774 (std: 0.098)

0.849 (std: 0.058)

Random Forest

0.792 (std: 0.075)

We began experiments with ﬁnding a best validation score
for a speciﬁc set of auto-encoder’s hyper-parameters when only
two frequency bands were included in the input data corpus
and continued until all bands were involved. We found that in
all experiments the classiﬁcation pipeline based on contractive
auto-encoder was superior to that based on the denoising auto-
encoder. Therefore, we will provide only the best results for
the contractive auto-encoder together with the classiﬁer name
and the included frequency bands (see Table IV).

The best signal / noise classiﬁcation score (0.849) obtained
for the machine learning classiﬁcation pipeline, including the
contractive auto-encoder, followed by the classiﬁer based on
multi-layer perceptron architecture. See Table III, IV for used
auto-encoder hyper-parameters. Optimum hyper-parameters of
the most effective classiﬁer (MLP) - momentum: 0.999, acti-
vation: ’relu’, solver: ’sgd’, alpha: 0.0001, learning rate init:
0.001, hidden layer sizes: 8

As a result of the experiments, we found that for the signal
/ noise classiﬁcation the SSVEP response elicited by visual
stimulation is not important. Only the level of the control signal
(Attention or Meditation) during the recording of EEG events
is of primary importance. The best result was achieved when
almost all frequency bands is included in the analyzed data
corpus, which conﬁrms that the elicited by visual simulation
SSVEP response is not important for this task.

Thus, we can conclude that the proposed method of signal /
noise classiﬁcation can be used without any visual stimulation.
The scope of this method application can be related both to
the monitoring of EEG hardware failures and to control the
user’s level of consciousness in intensive care units.

B. The Classiﬁcation of Participants

The second goal of our research is to build a model of
machine learning classiﬁcation pipeline that allows correctly
labeling EEG records for speciﬁc participants, that is, allowing
to classify a participant on the basis of her unique ﬁngerprint
in the collected EEG data.

In our experiments we decided to apply visual stimulation
with main ﬂicker frequency at 10Hz and secondary - at 5Hz,
which corresponds to Theta (Θ) and High Alpha (Hα) bands.
In accordance with [1], we assumed that elicited SSVEP
response should be detected at these or adjacent frequency
bands and that the best validation score will be obtained if only
these frequency bands are included in the input data corpus.

A series of experiments was performed on the collected
signal-only EEG records with various frequency bands in-
cluded and the best result (0.800) was achieved with data
corpus consisting of signal-only records with Delta (∆) and
High Alpha (Hα) bands included. It almost perfectly ﬁts into
the expected range - the Delta (∆) band is adjacent to the Theta
(Θ) band. This congruence is a good indication that SSVEP
stimulation is important when collecting EEG records to be
classiﬁed by participants. See Table V for details about the
best results found for various data corpus and hyper-parameters
conﬁgurations.

VII. FUTURE WORKS

Our current research based on very limited data corpus
collected from only three participants. Because of this limi-

7 | P a g e

Random Forest

0.650 (std: 0.138)

and Trends in Machine Learning. 2. DOI:10.1561/2200000006

TABLE V: Comparison of the best validation scores for signal-
only classiﬁcation per particular set of included frequency
bands and speciﬁc values of hyper parameters of contractive
auto-encoder. The score value is given as an average of 3-fold
cross validation with standard deviation between individual
values for each fold.

Frequency
bands included

Batch size

# of hid-
den units

Best classiﬁer

Validation score

Θ, Hα

∆, Hα

∆, Lα, Hα

∆, Θ, Lα

∆, Θ, Lα, Hα

∆, Θ, Lα,
Hα, Lβ

∆, Θ, Lα,
Hα, Lβ, Hβ

5

5 or 1

5

5

5

5

1

3

2

2

2

5

4

5

Multi
Perceptron

Layer

0.750 (std: 0.165)

Random Forest

0.800 (std: 0.041)

Multi
Perceptron

Layer

Multi
Perceptron

Layer

0.750 (std: 0.065)

0.600 (std: 0.267)

Random Forest

0.700 (std: 0.135)

Random Forest

0.750 (std: 0.102)

tation, we may have missed some important patterns in EEG
records, which can further improve the validation scores of
studied machine learning classiﬁcation pipeline methods. In
the future, we plan to collect and process EEG records from
a much wider audience of participants.

VIII. CONCLUSION

In this paper, we demonstrated how to build machine learn-
ing classiﬁcation pipeline capable of processing and reliably
classifying EEG records collected from different participants.
We described a visual stimulation scheme suitable to elicit
speciﬁc SSVEP response from visual cortex and hypothesized
how to measure its quality using the collected EEG recordings.
In addition, special attention was paid to creating an aestheti-
cally attractive scheme of visual stimulation in the assumption
of its use in consumer devices.

We managed to get a fairly good estimate of conﬁdence
score with signal / noise classiﬁcation task (best validation
score: 0.849, see Table IV). This conﬁrms that the proposed
method is suitable for automatic processing of EEG records,
when it is important to distinguish the signal from noise.

We also demonstrate that, using the proposed method, it
is possible with sufﬁcient conﬁdence to classify EEG records
for each participant (best validation score: 0.800, see Table V).
We believe that further improvement of the method can provide
sufﬁciently reliable means for use even for user identiﬁcation
based on the collected EEG data.

REFERENCES

[1]

Jian Ding, George Sperling, Ramesh Srinivasan (2006). Attentional
modulation of SSVEP power depends on the network tagged by the
ﬂicker frequency.
Cereb Cortex (2006) 16 (7): 1016-1029. DOI:
10.1093/cercor/bhj044

[2] Regan D. (1977). Steady-state evoked potentials.

J Opt Soc Am

67:14751489.

[3] Evelyn Tang, Danielle S. Bassett (2017). Control of Dynamics in Brain

Networks. arXiv preprint: arXiv:1701.01531

[4] Heideman, M. T.; Johnson, D. H.; Burrus, C. S. (1984). Gauss and the
IEEE ASSP Magazine. 1 (4):

history of the fast Fourier transform.
1421. DOI: 10.1109/MASSP.1984.1162257

[5] Gain, A. K. (1951). The frequency distribution of the product moment
correlation coefﬁcient in random samples of any size draw from non-
normal universes. Biometrika. 38: 219-247, 1951.

[6] Hochreiter, Sepp; and Schmidhuber, Jrgen (1997) Long Short-Term

Memory. Neural Computation, 9(8):17351780, 1997

[7] Bengio, Y. (2009). Learning Deep Architectures for AI.

Foundations

[8] P. Vincent, H. Larochelle Y. Bengio and P.A. Manzagol (2008) Ex-
tracting and Composing Robust Features with Denoising Autoencoders.
Proceedings of the Twenty-ﬁfth International Conference on Machine
Learning (ICML08), pages 1096 - 1103, ACM, 2008.

[9] S. Rifai, P. Vincent, X. Muller, X. Glorot, Y. Bengio Contractive Auto-
Encoders: Explicit Invariance During Feature Extraction.
Proceedings
of the Twenty-eight International Conference on Machine Learning
(ICML11)

[10] Kohavi, Ron (1995). A study of cross-validation and bootstrap for ac-
curacy estimation and model selection.
Proceedings of the Fourteenth
International Joint Conference on Artiﬁcial Intelligence. San Mateo, CA:
Morgan Kaufmann. 2 (12): 1137-1143.

[11] L. Breiman (2001) Random Forests. Machine Learning, 45(1), 5-32,

[12]

2001.
J. Zhu, H. Zou, S. Rosset, T. Hastie (2009) Multi-class AdaBoost.
Statistics and Its Interface, 2. 349-360. 2009.

[13] L. Breiman, J. Friedman, R. Olshen, and C. Stone (1984) Classiﬁcation

and Regression Trees. Wadsworth, Belmont, CA, 1984.

[14] C. E. Rasmussen, C. K. I. Williams (2006) Gaussian Processes for

Machine Learning.

The MIT Press, 2006. ISBN 0-262-18253-X.

[15] Hinton, Geoffrey E. (1989) Connectionist learning procedures. Arti-

ﬁcial intelligence 40.1 (1989): 185-234.

[16] Altman, N. S. (1992) An introduction to kernel and nearest-neighbor
The American Statistician. 46 (3): 175185.

nonparametric regression.
DOI:10.1080/00031305.1992.10475879

[17] Chan, Golub, and LeVeque (1979) Stanford CS tech report STAN-CS-
Retrieved from: http://i.stanford.edu/pub/cstr/reports/cs/tr/79/

79-773.
773/CS-TR-79-773.pdf

[18] Hastie T., Tibshirani R., Friedman J. (2008) The Elements of Statistical
Springer, Section 4.3, p.106-119, 2008. ISBN 978-0-387-

Learning.
84858-7

[19] Cortes C., Vapnik V. (1995). Support-vector networks.

Machine

Learning. 20 (3): 273297, (1995). DOI:10.1007/BF00994018

[20] Rami Al-Rfou et al. Theano: A Python framework for fast computation

of mathematical expressions. arXiv preprint: 1605.02688

[21] Fabian Pedregosa; Gal Varoquaux; Alexandre Gramfort; Vincent
Michel; Bertrand Thirion; Olivier Grisel; Mathieu Blondel; Peter Pretten-
hofer; Ron Weiss; Vincent Dubourg; Jake Vanderplas; Alexandre Passos;
David Cournapeau; Matthieu Perrot; douard Duchesnay (2011). Scikit-
learn: Machine Learning in Python.
Journal of Machine Learning
Research. 12: 28252830, (2011).

8 | P a g e

