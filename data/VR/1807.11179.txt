8
1
0
2

v
o
N
2
1

]
h
p
-
d
e
.
s
c
i
s
y
h
p
[

2
v
9
7
1
1
1
.
7
0
8
1
:
v
i
X
r
a

Virtual Reality as a Teaching Tool for Moon Phases and Beyond

J. H. Madden,1 A. S. Won,2 J. P. Schuldt,2 B. Kim,2 S. Pandita,2 Y. Sun,2 T. J. Stone,2 and N. G. Holmes3
1Astronomy and Space Science, Cornell University, Ithaca NY 14850
2Communication, Cornell University, Ithaca NY 14850
3LASSP, Cornell University, Ithaca NY 14850

A ball on a stick is a common and simple activity for teaching the phases of the Moon. This activity, like many
others in physics and astronomy, gives students a perspective they otherwise could only imagine. For Moon
phases, a third person view and control over time allows students to rapidly build a mental model that connects
all the moving parts. Computer simulations of many traditional physics and astronomy activities provide new
features, controls, or vantage points to enhance learning beyond a hands-on activity. Virtual reality provides the
capabilities of computer simulations and embodied cognition experiences through a hands-on activity making
it a natural step to improve learning. We recreated the traditional ball-and-stick moon phases activity in virtual
reality and compared participant learning using this simulation with using traditional methods. We found a
strong participant preference for VR relative to the traditional methods. However, we observed no difference
across conditions in average levels of performance on a pre/post knowledge test.

I.

INTRODUCTION

The physics classroom today contains many forms of
teaching designed to show students a different perspective on
the material. Students can read a textbook, take notes in class,
and observe demonstrations of the phenomenon being stud-
ied, among much else. The different routes of exposure are
chosen to complement each other and provide new pathways
to learn the material.

A hands-on activity provides students with a personal, real,
physical application of course content. This type of activity
provides an embodied cognitive experience in which we make
sense of the world through our body’s interaction with it [1].
While embodied cognitive experiences enhance learning, the
activities are often plagued by variability in ﬁdelity, cognitive
load, and sacriﬁces of realism that distract from the concepts
being taught [2]. Implementing a heavily guided activity re-
duces these variables but also the opportunity for self-directed
learning [3]. This is where the beneﬁts of computer simula-
tions and virtual reality step in to help. A computer simu-
lation is able to reduce variability by providing a controlled
experience and the realism can be programmed. A computer
simulation that is designed with exploration in mind can also
lend itself well to self-directed learning [2, 4].

Virtual Reality (VR) goes an extra step beyond the versa-
tility and consistency of a computer simulation by also pro-
viding the embodied learning experience of a hands-on activ-
ity. VR brings other features that make it uniquely suited as
a teaching tool in physics [5, 6]. It also allows for the use
of inaccessible perspectives that are more immersive, and its
ability to track students provides additional opportunities to
monitor learning, engagement, and provide feedback in real
time [7].

A brief search through Physical Review - Physics Educa-
tion Research (PER) and the PERC proceedings will show
that very little research has been done in PER on the im-
pacts of VR on learning. Recently, one study performed a
controlled experiment comparing student learning and atti-
tudes due to VR, video, and static images [8]. They found

no differences between conditions, except for a marginal im-
provement from VR for students with experience with video
games. They also found signiﬁcant participant preference to-
wards VR.

A signiﬁcant limitation to the study, however, was that
the electrostatics concepts evaluated across conditions did not
take advantage of the interactive and embodied cognitive af-
fordances of VR. The students were not able to interact with
the environment, control variables, or explore the concepts
- features that are key for student learning from simulations
[4, 9].

In the present study, we aimed to test the impacts of a fully
featured and interactive experience in VR. We compared par-
ticipant learning and activity preference when engaging in
equivalent activities in VR, a hands-on activity, and a desktop
simulation. We found that, even with the interactive elements,
participant learning was again equivalent across conditions,
and that participants overwhelmingly preferred engaging in
the VR condition.

II. METHODS

To carry out our study we created three Moon phase activ-
ities; a hands-on activity as close to traditional as possible, a
computer based version, and a fully featured VR version.

The traditional hands-on version of this activity involved a
bright spotlight (the Sun) pointed at a participant (the Earth)
who is holding a short stick with a ball on top (the Moon). If
the participant holds the ball constantly at arm’s length and
spins around, this symbolic Sun-Earth-Moon system mimics
the illumination pattern of the Moon phases so they can be
viewed with the control of the participant [10, 11].

In the desktop simulation version of the activity, partic-
ipants saw realistic visualizations of the Sun, Earth, and
Moon. Students used the keys on the computer keyboard to
move forward or backwards in time. They could also change
their viewing position by using the mouse and keyboard, for
example to see a birds-eye-view of the 3-body system, or

 
 
 
 
 
 
planar perspectives to more clearly see the shadows on the
Moon. The time progression appropriately synced Earth’s ro-
tation, the Moon’s orbit, and Earth’s orbit.

ing their time with the teaching activity and tracked move-
ment data was collected for participants in the VR condition.
The data have not yet been analyzed.

The VR activity used the Oculus Rift head mounted dis-
play with two hand controllers running a simulation made
using the Unity game engine. The structure of the VR ac-
tivity was much the same as the desktop simulation, except
that participants used the hand controllers to move forward
or backwards in time. They could also use a cursor, virtually
attached to their hand, to reach out and grab the Moon to drag
it forwards or backwards in its orbit, in much the same way
as the hands-on condition. Participants were initially placed
in space above Earth’s North pole, but could relocate to other
viewing positions.

The desktop simulation and VR conditions also had the op-
portunity for participants to transport to Earth’s surface to ob-
serve rise and set times. They could ﬂuidly transition between
views to observe the rise and set of the Moon on Earth and the
relative positions of the bodies at the same time.

Participants were recruited from a pool of Cornell students
and the instructions were kept as similar as possible for each
condition. Each participant was randomly assigned to one
of the three conditions. We used a pre-post model to mea-
sure participant learning and activity preference. The pre-
and post-tests consisted of 14 questions each, drawn from ex-
isting assessments of student understanding of Moon phases
[12–15]. Due to the short duration of the activity, the pre-
and post-test items were not identical. The questions were,
however, matched on content, such that each test contained a
isomorphic set of questions.

After completing the pre-test, the researcher provided ver-
bal instructions on how to use the equipment for their con-
dition. The language of the instructions were matched as
closely as possible between conditions. The participant then
completed an activity that used guiding questions modeled
after common tutorials in astronomy [10, 11]. We opted
to use semi-structured activities as research has found that
students can struggle to engage productively in unstructured
computer-based activities [4, 9]. Once again, the guiding
questions were equivalent between conditions.

Following the activity, the participant completed the post-
test, which also included demographic and attitudinal ques-
tions. The participant was then shown the other two condi-
tions and completed a short survey to indicate their preferred
activity and to explain their reasoning.

There were 56 participants in the VR condition, 59 in the
hands-on condition, and 57 in the desktop condition. All par-
ticipants were students at Cornell University. 138 participants
identiﬁed themselves as women, 31 as men, and 3 identiﬁed
as other. The most common majors were social science, such
as communication but there were also participants from bio-
logical science, engineering, physical science, and art.

The results presented here, as gathered from the pre- and
post-tests, include: participant performance by condition,
participant performance by question, and activity preference.
Video recordings were also collected for each participant dur-

III. RESULTS

A. Total score comparisons

The average score on the pre-test was around 36% in all
three conditions, with no signiﬁcant differences between con-
ditions (Fig.1). There were statistically signiﬁcant increases
in performance in all three conditions between pre- and post-
test (p<0.001). Because pre-test scores were statistically
equivalent, we directly compared the post-test scores across
conditions. The average score on the post-test was about
58% in all three conditions, with no signiﬁcant differences
between conditions (F (2, 169) = 0.86, p = 0.57).

FIG. 1. An overall view of pre- to post-test performance. Vi-
olin plots show how scores were distributed across conditions
with green (left) being the pre-test and blue (right) being the
post-test. Bins are 1 point wide. Average scores and standard
error are indicated in white.

B. Score comparison by topic

The three conditions provided different potential affor-
dances for teaching particular content. For example, the orbit
and rotation periods are not controlled in the hands-on con-
dition, but are appropriately controlled in the desktop simu-
lation and VR conditions. We would expect, therefore, that
participants in the hands-on condition may perform worse on
questions related to time scales. Upon being broken down
by question the pre- to post-test scores show some variation
between conditions but no statistically or practically signiﬁ-
cant differences (Fig. 2). A Fisher’s exact test gives p-values
greater than 0.1 for all pre/post scores by question. Some
topic areas show gains over 40% that are consistent across
condition (orbit period, phase period, and illumination) while

PrePostPrePostPrePost020%40%60%80%100%VRHands-onDesktopParticipantscoreothers show gains less than 10% (scale, Moon rotation, phase
diagram, rise/set time), consistent with previous research on
learning about Moon phases [14, 16]. Note the negative shifts
in the “Why phases occur" question. Upon investigation, the
questions for this topic were not truly isomorphic. Though
they referred to the same topic, they varied signiﬁcantly in
difﬁculty level.

FIG. 2. The difference in participant responses from the pre-
test to the post-test broken down by question topic. The per-
cent of correct responses on the pre-test and post test for that
topic are connected by a colored bar. A green bar signiﬁes im-
provement, with the higher number representing the post-test
score. A red bar means there were fewer correct responses
on the post-test, with the higher number representing pre-test
score.

C. Participant preference

Despite these lack of differences between learning, we
found that 78% of participants preferred the VR activity (Fig.
3) with no dependence on assigned condition. The partici-
pants who preferred VR generally found that seeing the full
picture helped build their mental model. The main contribu-
tors to this were the ease of viewing different perspectives and
having control over the system. For example, one participant
wrote:

“Having a overall space to see where everything
is helps a lot. Even in class I still had a hard
time understanding what they are talking about
in concept. But I think I learned a lot in VR and
being able to manipulate the environment on my
own accord. It seems more engaging than the 2
other methods."

If the participant did not prefer VR it was mostly because
they felt uncomfortable with the overwhelming sensory in-
put. They preferred either the hands-on or desktop conditions

because they were more familiar. For example, a participant
who preferred hands-on wrote:

“I really liked the virtual reality method. And
it gave me more information than the other two
methods, for instance, what time of day certain
moon phases would rise and set. Nevertheless,
it was almost too overwhelming and it was as if
I was too excited to be in space to actually com-
mit to learning the moon phases. With the hands-
on demonstration. there was nothing to distract
me. And, obviously, controlling the demonstra-
tion felt about as natural as possible."

A participant who preferred the desktop simulation wrote:

“The VR was cool but since I’m very new to it
I spent most of my time just trying to ﬁgure out
how it worked–it was also tough to ﬁnd where
the sun and moon were at times because of how
‘large’ the environment was. The desktop game
was more familiar and easy-to-use for me. Per-
sonally."

We can see that even participants who preferred other
methods indicated that they liked the VR activity, but some
participants were either overwhelmed by the controls or
found it generally too distracting. As with computers, if the
technology becomes more common, the issues regarding con-
trol and novelty may one day no longer be relevant. Currently
however, efforts should be made to ensure familiarity before
optimal efﬁciency is attained.

FIG. 3. Preferred choice after viewing each activity.

IV. DISCUSSION

In this study, we evaluated the impact of an immersive and
interactive VR activity, compared with similarly interactive
hands-on and desktop simulations. It is clear there was sig-
niﬁcant improvement in all conditions in overall test scores
from the pre- to post-test, but differences in learning between

�����������������������������������������������������������������������������������������������������������������������������������/��������������������������/������������������������%�����������������������������������-������-����VRHands-onDesktopVR78.2%Desktop11.8%Hands-on10.0%Whichofthethreewaystosimulatethemoonphasesisyourfavoritemethod?conditions were not signiﬁcant (Fig. 1). Previous work us-
ing these assessments found that typical astronomy students
score just between 30 and 50% at pre-test and after a course in
astronomy score about 65% [14, 17]. This suggests that our
participants, from various majors, achieved similar learning
gains on the subject of moon phases after a single 10 minute
activity as to those obtained in typical instruction. While the
non-signiﬁcant difference between conditions does not indi-
cate virtual reality as one that enhances learning over tradi-
tional methods, it does show that VR can perform just as
well. The hands-on and desktop activities both used tech-
nology very familiar with our participants. If participants can
learn the same amount from a new technology they are not
familiar with and running a simulation with a low production
value there is likely still room for improvement for VR as a
teaching tool.

We can also see how this activity in general performs as a
teaching tool for the various Moon phase topic areas. There is
clear evidence that further instruction is required on the top-
ics of scale, Moon rotation, reasoning behind phases, and the
rise/set times of certain phases (Fig. 2). Students typically
struggle with understanding the topic of rise and set times for
the Moon phases [17]. Our results indicate that VR does not
help in these areas any better than the traditional methods.
Learning in these areas may improve with alternate teaching
methods since the results also suggest that the learning activ-
ity may be the stronger factor for student learning than the
modality of instruction. The population differences between
conditions may also be making it difﬁcult to determine the
advantages of each condition.

As in the previous work, we saw dramatic differences in
participants’ preference towards the VR simulation. It is pos-
sible that VR could be a powerful tool for improving student
attitudes towards learning, while obtaining the same learn-
ing beneﬁts as other modalities. This impact should be con-
sidered as researchers aim to develop ways to recruit more
STEM majors or to promote knowledge retention.

V. FUTURE WORK

Previous work found no differences in student learning in
VR, video, and static images, but did ﬁnd interactions with
gender and video game experience [8]. We are currently
analyzing our data for these effects and how performance
relates to previous VR experience. We also aim to further
probe students’ attitudes towards and experiences in the
activities through analysis of the video recordings,
time
spent in the simulations, and tracking movement. Future
publications will provided greater detail on the population,
methods, analysis, and results of the work presented in this
paper and explore whether the various modalities provide
different beneﬁts to different learners.

VI. CONCLUSIONS

A cursory glance reveals that VR is as good at teaching
Moon phases as traditional methods. The inexperience of par-
ticipants and the current technical limits on VR appear to be
the main limitations in providing a truly immersive experi-
ence and distract users from the concepts being taught much
as hands-on activities do. Unlike hands-on activities how-
ever, these distractions can be overcome by advances in the
technology. Higher frame rates, and larger ﬁelds of view will
eventually remove simulator sickness as an obstacle to im-
mersive interaction with the environment. At its current stage
VR is a highly favored way to show the same learning gains
as the tried-and-true methods.

ACKNOWLEDGMENTS

This work was supported by Oculus Education. We would
like to thank all the graduate and undergraduate students who
helped develop the simulations and run participants.

[1] M. L. Anderson, Artiﬁcial Intelligence 149, 91 (2003).
[2] N. D. Finkelstein, W. K. Adams, C. J. Keller, P. B. Kohl, K. K.
Perkins, N. S. Podolefsky, S. Reid, and R. LeMaster, Phys.
Rev. ST Phys. Educ. Res. 1, 010103 (2005).
[3] C. Wieman, The Physics Teacher 53, 349 (2015).
[4] W. K. Adams, A. Paulson, and C. E. Wieman, AIP Conference

Proceedings 1064, 59 (2008).

[5] M. Bricken, SIGGRAPH Comput. Graph. 25, 178 (1991).
[6] B. Perone, Stanford (2016).
[7] A. S. Won, J. N. Bailenson, and J. H. Janssen, IEEE Transac-

[9] S. Salehi, M. Keil, E. Kuo, and C. Wieman, in Physics Ed-
ucation Research Conference 2015, PER Conference (College
Park, MD, 2015) pp. 291–294.

[10] E. Prather, Lecture tutorials for introductory astronomy (Pear-

son, 2008).

[11] P. Newbury, “Phases of the moon,” (2011).
[12] B. Hufnagel, Astronomy Education Review 1, 47 (2002).
[13] R. Lindell and J. P. Olsen, in Physics Education Research Con-

ference 2002, PER Conference (Boise, Idaho, 2002).

[14] R. Lindell, in Physics Education Research Conference 2004,

tions on Affective Computing 5, 112 (2014).

pp. 53–56.

[8] J. R. Smith, A. Byrum, T. M. McCormick, N. Young, C. Or-
ban, and C. D. Porter, Physics Education Research Conference
2017, PER Conference, 376 (2017).

[15] S. J. Slater, J. Astro. Earth. Sci. Educ. 1, 22 (2014).
[16] J. Wilhelm, M. Cole, C. Cohen, and R. Lindell, Phys. Rev.

Phys. Educ. Res. 14, 010150 (2018).

[17] R. S. Lindell and S. R. Sommer, AIP Conference Proceedings

720, 73 (2004).

