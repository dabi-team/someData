2
2
0
2

l
u
J

4
1

]

C
H
.
s
c
[

1
v
9
6
7
6
0
.
7
0
2
2
:
v
i
X
r
a

Virtual Reality (VR) as a testing bench for consumer optical solutions: A
machine learning approach (GBR) to visual comfort under simulated
progressive addition lenses (PALs) distortions

Miguel GarcÃ­a GarcÃ­a1, Yannick Sauer 1, Tamara Watson 2, and Siegfried Wahl 1,3

1Institute for Ophthalmic Research, University of Tuebingen, Elfriede-Aulhorn-StraÃŸe 7, TÃ¼bingen, 72072
2School of Social Science and Psychology, Western Sydney University, New South Wales, Australia
3Carl Zeiss Vision International GmbH, TurnstraÃŸe 27, 73430 Aalen

July 15, 2022

MGG Orcid 0000-0001-7379-0080
YS Orcid 0000-0002-7513-341X
TW Orcid 0000-0001-7899-0858
SW Orcid 0000-0003-3437-6711
Corresponding author: Miguel GarcÃ­a GarcÃ­a
miguel.garcia-garcia@uni-tuebingen.de

Abstract

For decades, manufacturers have attempted to reduce or eliminate the
optical aberrations that appear on the progressive addition lensâ€™ sur-
faces during manufacturing. Besides every eï¬€ort made, some of these
distortions are inevitable given how lenses are fabricated, where in
fact, astigmatism appears on the surface and cannot be entirely re-
moved or where non-uniform magniï¬cation becomes inherent to the
power change across the lens. Some presbyopes may refer to certain
discomfort when wearing these lenses for the ï¬rst time, and a subset
of them might never adapt. Developing, prototyping, testing and pur-
veying those lenses into the market come at a cost, which is usually
reï¬‚ected in the retail price. This study aims to test the feasibility of
virtual reality for testing customersâ€™ satisfaction with these lenses, even
before getting them onto production. VR oï¬€ers a controlled environ-
ment where diï¬€erent parameters aï¬€ecting progressive lens comforts,
such as distortions, image displacement or optical blurring, can be
analysed separately. In this study, the focus was set on the distortions
and image displacement, not taking blur into account. Behavioural
changes (head and eye movements) were recorded using the built-in
eye tracker. Participants were signiï¬cantly more displeased in the
presence of highly distorted lens simulations. In addition, a gradient
boosting regressor was ï¬tted to the data, so predictors of discomfort
could be unveiled, and ratings could be predicted without performing
additional measurements.

Keywords: virtual reality distortions comfort progressive addi-

tion lenses eye-tracking

1

Introduction

Progressive addition lenses (PALs) provide presbyopes with clear vi-
sion at diï¬€erent distances, with the use of a single ophthalmic lens
[Poullain and Cornet, 1911]. Firstly patented in 1907 [Aves, 1907],
multifocal ophthalmic lenses have undergone a great deal of evolution
[Sullivan and Fowler, 1988]. Although their introduction to the market
was neither rapid nor widely accepted, being only in 1959, when pre-
cursors of modern progressive lenses became commercially available
[Maitenaz, 1969, Volk and Weinberg, 1962], over the years, progres-
sive lenses have become the most popular solution for presbyopia.

1

In general, the fabrication of progressive power lenses leaves in-
evitably residual surface astigmatism that leads to peripheral distor-
tions [Minkwitz, 1963, Esser et al., 2017]. How this residual astig-
matism is spread across the surface was usually employed to classify
PALs into soft (more spread) and hard designs (more concentrated)
[Atchison, 1987]. However, nowadays, these lenses navigate between
both classes, diï¬€using the borders as to whether they belong to one or
another category, with manufacturers aiming to obtain the best combi-
nation of parameters for each group of individuals.

Besides their popularity and the fact that they do seem to improve
wearersâ€™ quality of life [Ahmad Najmee et al., 2017], not everyone
gets used to them. Scientiï¬c literature is scarce when it comes to
gathering knowledge about why few "rookie" wearers suï¬€er in adapting
to these lenses or which could be the main factors contributing to this.
Some papers mainly refer to spectacles in general and report errors
in the prescription as the primary source of discomfort [Bist et al.,
2021]. However, assuming no errors from the optician, a small group
still reports discomfort due to distortions and multifocality. Alvarez
et al. [2017] proposed that non-adopters may have a weaker ability to
modify their convergence and a reduced rate and magnitude of phoria
adaptation. Yet, individuals who reject these lenses report blurred
vision, headaches, perceived movement of the peripheral visual ï¬eld
(a.k.a. swim), balance issues and even nausea [Cho et al., 1991, Han
et al., 2003], symptoms more likely associated with poor adaptation to
novel visual conditions [Alvarez et al., 2009].

Traditionally, as reported by Ogle and Saunders W.B. [1950], one
of the most signiï¬cant handicaps when analysing the tolerance to dis-
tortions induced by ophthalmic lenses was the diï¬ƒculty in separating
them from blur [Barbero and GonzÃ¡lez, 2020]. With the computational
development of the last decades, it is entirely possible to present an
image that is solely distorted [Habtegiorgis et al., 2017, Sauer et al.,
2020] or blurred [Sawides et al., 2010, Vinas et al., 2012], helping to
understand how our visual system adapts to these changes. However,
these experiments are somewhat forced, built upon certain constraints,
such as speciï¬c gazing or a ï¬xed head position, and while they do drive
knowledge forward, they often lose sight of the big picture.

On the other hand, one can analyse eye-tracking data while wearing
PALs [Hutchings et al., 2007], bringing more natural conditions at
the expense of not fully comprehending which features are aï¬€ecting
what since they can not be separated. In addition, the potential source
of error that arises when ï¬tting PALs cannot be ignored. All in all,
virtual reality oï¬€ers a perfect test bench as it can replicate the eï¬€ect
of distortions and blurring apiece while maintaining the freedom of
movement and immersion of virtual environments.

This study aims to test the feasibility of virtual reality to assess,
benchmark and rate the discomfort that four diï¬€erent ophthalmic lenses
with various refractive powers can introduce, given the distortions they
present. Subjective grading was performed continuously after ï¬nishing

 
 
 
 
 
 
a simple task involving navigation, locomotion, scene exploration, and
grasping to recognise the subjectsâ€™ ability to perceive such simulated
distortions and assess their comfort when aï¬€ected by them. Possible
behavioural changes prompted by optical distortions were also sought,
and a model was developed to predict what the discomfort might be
like without requiring additional measurements.

2 Material & Methods

2.1 Subjects and informed consent

A total of 18 naÃ¯ve subjects (9 males / 9 females) participated in the
course of the study. The participants were aged between 19 and 30
years (mean = 24; SD = 3). None of the subjects presented a prior
history of problems using a virtual reality headset or motion issues,
nor did they present any refractive error that could have compromised
their vision during the experiment or inï¬‚uenced their perception due
to the usual wear of their lenses.

2.2 Ethics

The study adhered to the tenets of the Helsinki Declaration (2013) and
subsequent amends. The ethics authorisation to perform the measure-
ments was granted by the Ethics Committee at the Medical Faculty of
the Eberhard-Karls University and the University Hospital TÃ¼bingen
with the ID 986/2020BO2. Before data collection, the experiment was
explained in detail to the participants, and written informed consent
from each participant was stored. All data was pseudo-anonymised
and stored in full compliance with the principles of the Data Protection
Act GDPR 2016/679 of the European Union [The European Parliament
and the Council of the European Union, 2016].

2.3 Set-Up

A cuboidal booth of 3 Ã— 3 m deï¬ned the physical space around which
the participants were entitled to freely move. On every upper corner
(4 in total), one HTC Vive lighthouse base station tracker v2 (HTC
Cooperation, Xindian, Taiwan) recorded the position and orientation
of the headset as well as the controller used. The StarVR One (StarVR,
Taipei, Taiwan) head-mounted display was used to present the virtual
environment to the participants. This head-mounted display (HMD)
has an eï¬€ective ï¬eld of view (FoV) of 182Â° by 99Â° [Sauer et al., 2022],
and an average eye relief (or distance from lens/display to the eye of
18.2 mm (15.8 to 23.9 mm). The display has a resolution of 2240 px Ã—
1792 px, a maximum luminance of 68.4 cd mâˆ’2 and the refresh rate
ï¬xed at 90 Hz. This device presents eye-tracking capabilities through
Tobii Pro libraries. For reference, the display area covered by the
eye-tracker, as reported by the manufacturer, is plotted in Figure 1.
To provide input and locate the hand position, a standard HTC Vive
controller was used.

Figure 1: Area of display resolution of the VR headset(gray)
as well as area in pixels covered by the eye tracker(orange) as
provided by the manufacturer.

2

2.3.1 Virtual environment & Computer

The virtual environment was constructed using the rendering engine
Unity version 2019.4.25.f1 (Unity Technologies, California, USA)
and Blender 3.0 (Stichting Blender Foundation, Amsterdam, Nether-
lands). The experiment was written in C# and the eye-tracking data
was recorded using the Tobii Pro (Tobii Pro AB, Danderyd, Sweden)
eye-tracking libraries. A view of the virtual reality environment used
is depicted in Fig 2.

The whole experiment ran on a Windows 10(20H2) PC with an

Intel(R) Core i7-10700, 16 GB of RAM and an Nvidia 3080 GPU.

2.4 The task

After providing informed consent and having the experiment explained
in detail, participants had time to ask questions. They then wore the
virtual reality headset to acclimate to the scene by wandering around
the virtual environment (a replica of a lab room) before the actual
assignment started. Across the task, participants were requested to
position three diï¬€erent virtual cubes from point A (Green star) to
point B (Red circle)(See Fig 2). The location at which those cubes
spawned was randomised between several pre-deï¬ned positions in the
shelf unit. The cubesâ€™ colours, the patterns they presented on their
surface and the location where they were supposed to be placed were
also randomly changed across trials. Instructions on where the cubes
had to be placed were provided on a virtual whiteboard (Blue square)
opposite the cubesâ€™ spawn origin. Thus, participants were forced to
move and look around in the virtual environment during each trial.

2.4.1 Ratings of discomfort

After every cube was correctly placed on the plate, a UI panel with a
slider popped up in front of the participant. In this panel, the partic-
ipants were asked to report their level of visual discomfort on a scale
from 0 (no discomfort) to 7 (highest discomfort). Previous to providing
this feedback, participants were instructed to rate only based on how
the distortions aï¬€ected their perception of their visual comfort and to
not take into account factors such as possible frame drops or the image
resolution. Given the rating and conï¬rmation, the trial was completed,
and a new trial started.

A total of 25 trials were answered (ï¬ve per lens condition), with an
average duration of a trial of 36 s (SD = 12 s, range from 18 s to 101 s).

2.5 Lens Conditions - Distortion simulation

Four progressive additional lenses of the same type, but diï¬€erent pre-
scription power were used. Diï¬€erent addition powers or spherical
power prescriptions do modify how distortions are present. The distor-
tions proï¬les were provided by the manufacturer from a set of lenses
with the following parameters ï¬xed: a refractive index of 1.5, a panto-
scopic angle of 7.5Â°, a 5.28 mm base curvature, a back vertex distance
of 12 mm and a corridor length of 14 mm. Two of these lenses had
non spherical power and addition powers from +2 and +3 D, and the
other two lenses had an addition power +2 D and a spherical refractive
correction of +2 and âˆ’2 D. In line with modern PALs, these lenses
have their "umbilical line" tilted, with the near point shifted towards
the nasal side to account for vergence.

A set of grid points (ğ‘¥, ğ‘¦) on a plane perpendicular to a straight
gaze direction is perceived in a distorted position (ğ‘¥ğ‘‘, ğ‘¦ğ‘‘) when seen
through a progressive addition lens. The displacement between (ğ‘¥ğ‘‘,
ğ‘¦ğ‘‘) and (ğ‘¥, ğ‘¦) was pre-computed for each lens using ray tracing based
on these lensesâ€™ digital lens surface data. The displacement in the
horizontal and vertical coordinates were encoded into a raster image
(EXR format) where the red colour channel was used for the shift of
the pixel in the horizontal direction and the green colour for the vertical
component.

These distortions were then applied pixel-wise to the image dis-
played in the virtual reality headset through a custom shader in Unity
3D, written in HLSL. The amount of pixel displacement that these lens

050010001500200025003000350040004500050010001500Left Eye                                   Right EyeFigure 2: View of the virtual environment. The blue square denotes where the instructions were located in the virtual environment,
and the rating user interface (UI) was presented. The red circle is located where the cubes need to be placed. Finally, the green
star is placed upon the cube spawnsâ€™ origin.

simulations prompted in visual angle, along with the magniï¬cation,
skew, aspect or rotation, as seen by the participants, can be observed
in Fig 3.

The angular displacement in the visual ï¬eld as observed was com-

puted using the following formula:

Displacement (V(Visual angle in degrees) ) =

ğ‘ğ‘œğ‘ âˆ’1 (cid:169)
(cid:173)
(cid:173)
(cid:171)

ğ‘¥ğ‘‘ Ã— ğ‘¥ + ğ‘¦ğ‘‘ Ã— ğ‘¦ + 1
ğ‘‘ + ğ‘¦2

ğ‘‘ + 1) Ã— (ğ‘¥2 + ğ‘¦2 + 1)

(ğ‘¥2

âˆšï¸ƒ

(cid:170)
(cid:174)
(cid:174)
(cid:172)

(1)

;

Where (ğ‘¥, ğ‘¦) are the coordinates of the original grid points and (ğ‘¥ğ‘‘,
ğ‘¦ğ‘‘) are the location of those points after the distortion is applied.

2.6 Tracking

On every frame, the position coordinates of the head-mounted display
(HMD) along with the rotation quaternions and gaze vectors were
stored.

2.6.1 Head-tracking

Head rotation values were converted using quat2eul into Euler angles
following the MATLAB coordinates system for analysis and plotting.
The table 1 summarises the diï¬€erent coordinates systems that are used
in the main libraries of this study.

Program
Library

Coordinate
System

X

Y

Z

Euler angles
order

Unity 3D

Left-handed â†’ â†‘ (cid:37)

MATLAB Right-handed (cid:37) â† â†‘

z,x,y

z,y,x

Table 1: Coordinates system references for each software sys-
tem. â†’ - right; â† - left; â†‘ - up; (cid:37) - forward.
,

On every trial the yaw, pitch and roll were computed using the HMD

quaternions as described in the equation 2.

Tait Bryan Angles (roll, pitch, yaw) =
quat2eul(ğ‘Ÿğ‘œğ‘¡ğ‘Š, ğ‘Ÿğ‘œğ‘¡ğ‘, âˆ’ğ‘Ÿğ‘œğ‘¡ ğ‘‹, ğ‘Ÿğ‘œğ‘¡ğ‘Œ , ğ‘‹ğ‘Œ ğ‘);

(2)

The roll data (tilt of the head) was further characterised with a Von

Misses distribution ï¬t (See equation 3).

M (ğœƒ| ğœ‡, ğœ…) = [2ğœ‹ğ¼0 (ğœ…)]âˆ’1ğ‘’ğ‘¥ ğ‘{ğœ… ğ‘ğ‘œğ‘ (ğœƒ âˆ’ ğœ‡)};

(3)

3

Where ğœ‡ is the mean direction, ğ¼0 is the bessel function of the ï¬rst kind,
ğœ… is the concentration parameter, and ğœƒ refers to the angle in radians
from âˆ’ğœ‹ to ğœ‹.

The pitch (or head inclination up to down) was described using a
combination of two Von Misses distributions. And ï¬nally, the yaw (or
horizontal head rotation) was represented by the ï¬t (See equation 4)
of two inverse Power Batschelet distributions [Mulder, 2019, Mulder
et al., 2020], as the data was highly peaked towards the cube spawns
origin and the horizontal location of the plate, whiteboard and rating
UI panel.

ğ‘“P B (ğœƒ| ğœ‡, ğœ…, ğœ†) =

(cid:104)

(cid:105) âˆ’1

ğ‘’ğ‘¥ ğ‘{ğœ… ğ‘ğ‘œğ‘  ğ‘¡âˆ—

ğœ† (ğœƒ âˆ’ ğœ‡)};

ğ‘’ğ‘¥ ğ‘{ğœ… ğ‘ğ‘œğ‘  ğ‘¡âˆ—

ğœ† (ğœƒ âˆ’ ğœ‡)} ğ‘‘ğœƒ;

Kâˆ—
ğœ… ,ğœ†
âˆ« ğœ‹

âˆ’ ğœ‹

Kâˆ—

ğœ…,ğœ† =

ğ‘¡âˆ—
ğœ† (ğœƒ) = ğ‘ ğ‘–ğ‘”ğ‘›(ğœƒ)ğœ‹

(cid:19) ğ›¾ (ğœ†)

;

(cid:18) |ğœƒ|
ğœ‹

(4)

ğ›¾(ğœ†) =

1 âˆ’ ğ‘ğœ†
1 + ğ‘ğœ† ;

where c = 0.04082284 as noted by Mulder [2019].

2.6.2 Eye Tracking

The eye-tracking data was obtained using the Tobii Pro SDK 1.10 for
Unity. The SDK was modiï¬ed to further record the hit-point of the
gaze vector in the world coordinates.

Fixations While recording the eye-tracking data, on every frame,
the combined (head and gaze) origin and direction were used to cast
a ray within Unity until it hit a collider in the scene. The coordinates
of this hit-point (x,y,z) were later used to detect ï¬xations. If a cluster
of continuous hit-points stood within the volume of a sphere of 0.05 m
radius, during more than 200 ms (See van der Lans et al. [2011] for
a review on average ï¬xations duration while visual search and scene
viewing), it was considered a ï¬xation. The amounts of ï¬xations per-
formed per minute and their average duration were recorded on every
trial.

Saccades To estimate saccadic eye movements, the gaze ray from
the right eye (in headset relative coordinates) was transformed into
polar (ğœƒ) and azimuthal angles (ğœ™). The median angular distance
travelled (ğœ“) between the original frame vector, and the ï¬ve subsequent
frames was computed following the equation 5. Then, the angular
speed was estimated as the angular distance per second, on which a

Figure 3: Representation of how distortions aï¬€ect a grid and the image observed (background), and maps of pixel displacement
in visual angles as observed from the subjectâ€™s perspective for the OD, as well as magniï¬cation, diï¬€erences in aspect ratio, skew
and rotation calculated from the ï¬rst derivatives of the distortions.

4

Savitzky-Golay ï¬lter [Dai et al., 2016] was applied.

ğœ™ = arctan

(cid:16) ğ‘¦
ğ‘¥

(cid:17)

;

ğœƒ = arccos(ğ‘§);
ğœ“ =

(5)

(sin(ğœƒğ‘›+ğ‘–) Ã— sin(ğœƒğ‘›) Ã— cos(ğœ™ğ‘›+ğ‘– âˆ’ ğœ™ğ‘›)
(cid:17)

+ cos(ğœƒğ‘›) Ã— cos(ğœƒğ‘›+ğ‘–)

;

(cid:16)

arccos

A speed threshold of 50 Â° sâˆ’1 and a minimum distance (ğœ“) of 1Â°
were deï¬ned as thresholds for deï¬ning a saccade. The number of sac-
cades per minute, the average amplitude and maximum peak velocity
performed on every trial were recorded.

Eye tracking to measure average observed displacement,
magniï¬cation, aspect, skew and rotation Every gaze position
was projected over the displacement, magniï¬cation, skew, rotation,
and diï¬€erences on aspect ratio maps, and the observed absolute and
relative ("foveally") pixel displacement, magniï¬cation, skew, rotation
and aspect ratio parameters were computed by summing the values
at gaze position over all the frames of the trial. The mean value and
standard deviation per trial were recorded and compared.

3 Analysis & Preprocessing of the Data

All the statistical analysis and plotting were performed in MATLAB
2020b (Mathworks Inc, Natick, CA, USA) and Python 3.10 with sci-kit
learn 1.0.2 [Pedregosa et al., 2011].

4 Results

4.1 Visual discomfort

On every trial, the participants rated their visual discomfort on a scale
from 0 to 7, with zero being normal and seven being the most uncom-
fortable. Discomfort is, in fact, a subjective parameter that is highly
susceptible to vary between subjects and depends on where the par-
ticipant sets the threshold towards unpleasantness. Given the same
distortion and conditions, two subjects can be uncomfortable or not.
To standardise our answers and limit the subjectâ€™s susceptibility, the
ratings were normalised using the ratings where no lens distortion was
presented as a baseline. The formula used can be observed in the
equation 6.

ğ‘…{ğ‘– } = ğ‘…{ğ‘– } ğ‘œğ‘Ÿğ‘–ğ‘” Ã—

ğ‘…{ğ‘– } ğ‘›ğ‘œğ‘Ÿğ‘š =

+ 1;

10
7
ğ‘…{ğ‘– }
ğ‘… {ğ‘ğ‘ğ‘ ğ‘’ğ‘™ğ‘–ğ‘›ğ‘’ }

;

(6)

The distribution of visual discomfort ratings was not parametric in
any of the conditions tested. Thus, a non-parametric test (Kruskal-
Wallis) was used to compare lens condition discomfort ratings. Sig-
niï¬cant diï¬€erences were found between the distributions of visual
discomfort ratings across conditions (p < 0.01; Ëœğœ’2 = 69). Bonferroniâ€™s
Post-Hoc test indicated that the lens distortions from the lens +2D and
addition +2 were more disturbing than the rest. Likewise, the lens with
a spherical power of -2 and addition +2 had the smallest discomfort.
Fig 4 shows the distribution of ratings and the statistical diï¬€erences.

The Cronbachâ€˜s alpha value (ğœŒğœ ) for the rating scale was found to

be statistically consistent (0.88).

Figure 4: Visual discomfort ratingsâ€™ distribution across condi-
tions, all values have been normalised. The horizontal bars on
top indicate signiï¬cant diï¬€erences in Post-Hoc analysis.

4.3 Duration

A small correlation (ğ‘…2 = 0.11, p = 0.02) was found between the du-
ration of the trials and the rating given. In general, subjects seemingly
were faster deciding whether to give the highest and the lowest ratings
of discomfort. However, subjects may have taken longer times during
the trial if the decision was unclear, as they perceived some level of
discomfort but not the highest.

4.4 Yaw, pitch and roll

Tables 3, 2 and 4 present the main characteristics of the ï¬tted distri-
butions for pitch, yaw and roll per trial with their mean and standard
deviations. The statistical diï¬€erences of each parameter (individual,
lens or rating (rounded to the closest integer)) were computed using
the Kruskal-Wallis test, and are also reported in the tables.

None of the parameters above mentioned was signiï¬cantly diï¬€erent
across lens conditions, but the full-width half maximum (FWHM)
of the ï¬rst inverse power Bachelet distribution on yaw. The same
FWHM, as well as the mean directions of pitch, and the FWHM of the
roll changed across rating groups.

4.5 Gaze behaviour

Fixations The number of ï¬xations per minute and duration of
ï¬xations were signiï¬cantly diï¬€erent across subjects (Kruskal-Wallis,
H(17) = 255, p < 0.001) and (H(17) = 197, p < 0.001). Signiï¬cant dif-
ferences were also found in the number of ï¬xations per minute across
ratings (KW, H(5) = 25.7, p<0.001), where the greater discomfort is
perceived, the higher amount of ï¬xations are found, with the exception
of the group with the highest discomfort (4-5 ratings).

4.2 Gender & Age

No bias was found in the ratings of discomfort due to gender (Mann-
Withney-U; ğ‘ ğ‘“ ğ‘’ğ‘šğ‘ğ‘™ğ‘’ğ‘  = 9 (MdN = 0.29); ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘  = 9 (MdN = 0.29);
U = 51917 ; z-val = 0.87; p = 0.39).

No correlation was found between the ratings and the age of the

participants (Spearman - ğ‘…2 = 0.0018; p = 0.97).

Saccades The number of saccades per minute, as well as the peak
velocity and the average distance, travelled on a saccade, were signif-
icantly diï¬€erent across participants (Kruskal-Wallis, H(17) = 269, p
< 0.001),(KW, H(17) = 301, p < 0.001) and (KW, H(17) = 285, p <
0.001). In the trials with more discomfort, the saccades were on aver-
age larger (KW, H(5) = 14, p < 0.05) and had a higher peak velocity
(KW, H(5) = 18, p < 0.01). Signiï¬cantly (KW, H(4) = 9.6, p < 0.05)

5

Add+2Add+3-2Add+2+2Add+2Baseline01234567Visual Discomfort RatioFigure 5: Examples of distributions ï¬tted for Yaw, Pitch and Roll. The green line denotes the ï¬nal distribution ï¬tted, and the
dashed red and blue lines indicate the individual distributions (inverse power Batschelet or von Mises, contributing to the ï¬nal
one). The icons on the Yaw plot represent the same locations as in the Fig. 2)
+2/+2
âˆ’/+3
âˆ’1.65 Â± 0.10
âˆ’1.64 Â± 0.11
6.57 Â± 2.91
6.58 Â± 2.88
0.68 Â± 0.31
0.76 Â± 0.27
0.28 Â± 0.20
0.23 Â± 0.17
0.60 Â± 0.10
0.58 Â± 0.11
1.77 Â± 0.17
1.77 Â± 0.13
2.25 Â± 0.84
2.17 Â± 0.99
1.00
1.00
0.32 Â± 0.23
0.35 Â± 0.21

âˆ’2/+2
âˆ’1.65 Â± 0.12
6.42 Â± 2.68
0.75 Â± 0.26
0.23 Â± 0.17
0.59 Â± 0.10
1.75 Â± 0.14
2.26 Â± 0.96
1.00
0.32 Â± 0.18

âˆ’/+2
âˆ’1.65 Â± 0.10
6.04 Â± 2.46
0.80 Â± 0.22
0.20 Â± 0.12
0.59 Â± 0.09
1.75 Â± 0.13
2.10 Â± 0.76
1.00
0.34 Â± 0.18

Baseline
âˆ’1.66 Â± 0.08
6.15 Â± 2.54
0.77 Â± 0.23
0.22 Â± 0.12
0.59 Â± 0.09
1.76 Â± 0.16
2.10 Â± 0.72
1.00
0.34 Â± 0.18

ğœ‡1
ğœ…1
ğœ†1
FWHM1
ğœ”
ğœ‡2
ğœ…2
ğœ†2
FWHM2

Lens Ratings
ğ‘›.ğ‘ .

âˆ— âˆ— âˆ—
ğ‘›.ğ‘ .

âˆ—âˆ—
ğ‘›.ğ‘ .

Subj

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

Table 2: Yaw. Two inverse power Batschelet F PB were ï¬tted. In addition to those in the caption of Table 2, ğœ† refers to the
peakness of the ï¬tted distribution.

1-9
ğœ‡1

ğœ…1

FWHM1
ğœ”
ğœ‡2
ğœ…2
FWHM2

âˆ’/+2
âˆ’0.05 Â± 0.39
277.66 Â±
145.80
0.55 Â± 0.19
0.19 Â± 0.22
âˆ’0.33 Â± 0.15
48.66 Â± 90.70
0.52 Â± 0.31

âˆ’/+3
âˆ’0.06 Â± 0.39
286.41 Â±
160.89
0.55 Â± 0.22
0.20 Â± 0.20
âˆ’0.33 Â± 0.17
49.47 Â± 83.45
0.45 Â± 0.29

âˆ’2/+2
âˆ’0.03 Â± 0.48
283.69 Â±
148.15
0.55 Â± 0.21
0.15 Â± 0.18
âˆ’0.31 Â± 0.14
45.12 Â± 88.38
0.57 Â± 0.32

+2/+2
âˆ’0.10 Â± 0.42
296.62 Â±
150.39
0.57 Â± 0.21
0.19 Â± 0.20
âˆ’0.32 Â± 0.14
44.28 Â± 83.99
0.49 Â± 0.29

Baseline
âˆ’0.01 Â± 0.53
327.90 Â±
155.98
0.54 Â± 0.20
0.17 Â± 0.19
âˆ’0.33 Â± 0.16
48.41 Â± 79.49
0.50 Â± 0.36

Lens Ratings
ğ‘›.ğ‘ .

âˆ—

Subj

âˆ— âˆ— âˆ—

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

âˆ—

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

âˆ—
ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

Table 3: Pitch. Two Von Mises (M) were ï¬tted. For each of them ğœ‡ stands for mean direction, ğœ… is concentration, ğœ” is the
contribution of the function from 0 to 1, and FWHM stands for full-width half maximum of the distribution.

ğœ‡

ğœ…

FWHM

âˆ’/+2
0.02 Â± 0.04
344.33 Â±
142.43
0.14 Â± 0.04

âˆ’/+3
0.02 Â± 0.05
352.14 Â±
128.91
0.14 Â± 0.04

âˆ’2/+2
0.03 Â± 0.04
360.01 Â±
130.41
0.13 Â± 0.04

+2/+2
0.02 Â± 0.04
361.83 Â±
125.27
0.13 Â± 0.03

Baseline
0.03 Â± 0.04
382.43 Â±
127.06
0.13 Â± 0.03

Lens Ratings
ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

ğ‘›.ğ‘ .

âˆ—âˆ—

âˆ—âˆ—

Subj

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

âˆ— âˆ— âˆ—

Table 4: Roll. A single Von Mises distribution (M).

6

YawPitchRollmore saccades were performed when the lens presented had higher
amount of distortions.

estimated using the "SHAP" or SHapley Additive exPlanation values
[Lundberg and Lee, 2017].

Observed displacement, magniï¬cation, rotation, skew and
aspect All the components that deï¬ned the experienced distortion
computed from the movement data of each participant and the lens
worn were signiï¬cantly diï¬€erent (KW, H(4) < 434 , p < 0.001) for
every lens condition tested in their mean and standard deviation. The
ranking order for it can be observed in Table 5. Signiï¬cantly more
mean pixel displacement, magniï¬cation, diï¬€erences on aspect ratio,
skew, and rotation were observed when the subjects indicated higher
discomfort (KW, H(5) < 103 , p < 0.001). The standard deviation
of all the observed parameters was signiï¬cantly higher when more
discomfort was perceived. No diï¬€erences across subjects were found
for any of the mean values or standard deviation, but rotation standard
deviation diï¬€erences across subjects was close to signiï¬cant (KW,
H(17) = 27, p = 0.057).

Parameter

+2/+2

âˆ’/+3

âˆ’/+2

âˆ’2/+2

Displacement Mean

Displacement SD

Magniï¬cation Mean

Magniï¬cation SD

Aspect Mean

Aspect SD

Skew Mean

Skew SD

Rotation Mean

Rotation SD

Table 5: Matrix draw showing the lens conditions ordered from
highest (darker) to lowest(brighter), if the same colour appeared
no signiï¬cant diï¬€erences were found between these two condi-
tions.

5 Model - Gradient Boosting Regressor

Understanding what features might have inï¬‚uenced the decision for
speciï¬c discomfort ratings can be a herculean task if deferred to tra-
ditional methods. However, thanks to the advances in computational
power and machine learning algorithms, it is possible nowadays. Using
scikit learn package in Python [Pedregosa et al., 2011], we built a gra-
dient boosting regressor [Friedman, 2002], which ensembles several
decision trees, using the residuals to ï¬t the next iteration and weighting
them to obtain a ï¬nal model, capable of not only predicting new ratings
given the estimators but also providing the relevance of the estimators.
The dataset used comprised a total of 450 trials, and contained
age, gender, duration, baseline, maximum and minimum ratings of
the subject, absolute mean and standard deviations of the "foveally"
observed factors as described before, each of the parameters ï¬tted to
pitch, yaw and roll, and the already analysed data from the eye-tracking
(i.e. ï¬xations and saccades).

70% of the dataset was used to train the model, and the remaining
30% was only used to test the modelâ€™s accuracy, i.e. the data was never
shown to the model until the testing phase. The split was performed
with stratiï¬cation on subjects and lens conditions and testing for its
robustness. The best hyper-parameters were decided using a bayesian
optimisation search from skopt [Head et al., 2020], and a repeated
stratiï¬ed group cross-validation fold within a pipeline.

The best features were selected from the model using the meta-
transformer SelectFromModel and their relevance to the model was

7

Figure 6: Visual discomfort ratingsâ€™ distribution across lenses,
all values have been normalised. Diï¬€erent hues show the train-
ing dataset(true values), test dataset and the predictions from
the model.

Over 400 seeds of random splits were tested to assure the model

robustness, the table 6 shows the results of it.

R2

ğ‘¡ğ‘’ğ‘ ğ‘¡

R2

ğ‘¡ğ‘Ÿ ğ‘ğ‘–ğ‘› MAPE MSE

Maximum
error

Mean

SD

0.53
Â±0.08

0.84
Â±0.06

44.18% 0.33
Â±4.69% Â±0.05

2.12
Â±0.30

Table 6: Performance metrics from the model.

Fig. 6 presents the predictions of the model classiï¬ed for diï¬€erent
lenses and compared with the real values. Fig. 7 shows the residuals
of the model for the train and test dataset.

The Fig. 8 presents the "SHAP" values for the selected features of

the model.

6 Discussion

This study shows that distortions of PALs can be simulated in Virtual
Reality and that diï¬€erent lenses holding various degrees of distortions
are perceived by the participants as having diï¬€erent levels of vexation,
being those that presented a higher level of distortions experienced as
more uncomfortable. In our case, the lens with spherical power +2 D
and addition +2 D was rated the worst of all, followed by those without
spherical power and addition +3 D and +2 D. One would expect the
baseline (i.e. no distortions) to be rated as the most comfortable, but
nevertheless, the lens distortions due to the negative spherical power
and the +2 addition presented levels of discomfort equal to the baseline.
A sum of several factors could have contributed to this result. On
the one hand, these lens distortions have low levels of displacement

Figure 7: Residuals of the model depicted using Bengfort and Bilbro [2019] yellowbrick library for one of the best outcomes of
the model.

distribution, implying the more distortions, the less accurate our hor-
izontal head movement is. The statistical results comparing against
clusters of ratings should be taken with care. Although non-parametric
tests were used, the number of measurements on the worse/higher
ratings (4-5, after normalising) were quite low. For example, some
parameters of yaw and roll were signiï¬cantly diï¬€erent across rating
groups, but no clear pattern was found, and no additional diï¬€erences
were found in the post-hoc analysis.

Regarding gaze movements, fewer ï¬xations per minute lead to better
ratings, this was not found between lens conditions, where there were
no statistical diï¬€erences, but +2/Add2 presented more ï¬xations per
In this case, a pattern could be observed from the ratings,
minute.
where the more ï¬xations are made per minute, the more distress is
perceived, and only in the 4-5 groups it was disrupted, probably due
to the reduced sample of this groups. Thus, more distortions may
have led to more ï¬xations, and the more one ï¬xates, the more one
perceives those distortions, giving them worse ratings. Furthermore,
more saccades were performed in the textures with greater distortions,
and ratings followed the same pattern but did not reach signiï¬cance.
Otherwise, the worse ratings presented shorter saccadic lengths and
slower peak velocities in the saccades, but, in this case, nothing could
be found for the diï¬€erent lens conditions. In general, gazing behaviour
is highly tied to each individual, like the heading movements. However,
more saccades and more ï¬xations led to higher rates of discomfort,
although that might have been coupled with the lens in use.

The lens condition dictated how much of the mean and standard
deviation of displacement, magniï¬cation, rotation, diï¬€erences in the
aspect ratio, and skew were observed, a factor which inï¬‚uence the ï¬nal
rating. No diï¬€erences across subjects were found, probably because
even if they gaze diï¬€erently, the area they cover and locations they gaze
through were pretty similar.

Limitations of the study

There are several limiting factors that may have constrained the studyâ€™s
outcome. One of the main hiccups of the data was the reduced amount
of high/worse discomfort ratings (see Fig. 7), precluding the draw-
ing of some conclusions and probably limiting the modelâ€™s accuracy.
To gather more data with high ratings, the sample size must be in-
creased by presenting more trials with higher distortions lenses, more

Figure 8: SHAP values for the selected features of the model.

in the central area, as can be seen in Fig. 3, which could explain
similar ratings to the baseline. We also cannot be entirely sure that the
manufacturer has fully corrected in the software the distortions caused
by the VR headset lenses, and considering this headset uses a canted
display, magniï¬cation from negative lenses may have made the image
look more natural. The subjective input scale was consistent given the
Cronbachâ€™s index.

Although no correlation was found between the age of the subjects
and the ratings given, it is important to mention that we have a reduced
It can not be
sample of young participants with a small variance.
discarded that ratings might be diï¬€erent if an older group was tested,
including presbyopes. Moreover, all of our subjects were emmetropes
with an aim to avoid bias in our reduce sample, but usual ophthalmic
wearers might like more the distortions that look alike to those they are
habituated to.

Subjectsâ€™ heading and gazing presented a signiï¬cant variance across
individuals, independently of the distortions applied, which is expected
as it is known that these parameters are tied to each individual. Only
one of the inverse power Batschelet distributions ï¬tted for yaw varied
signiï¬cantly between the lenses and ratings, with a wider "+2/Add2"

8

lens conditions with a high amount of distortions, or simply measuring
more subjects. In fact, including more lenses, with not only diï¬€erent
prescription powers but also diï¬€erent designs may provide more infor-
mation on individual characteristics and their inï¬‚uence on discomfort.
In this study, only "static distortions" were measured, i.e. the distor-
tions of the PALs were only measured on the lens surface and presented
as if looking through the main line of sight. Although the perceived
distortions varied when looking through diï¬€erent areas, the distortions
applied through the custom shader did not update with the gaze. Pre-
senting "dynamic distortions" entails having previously measured and
stored a texture of how each pixel shifts on the texture at each possible
gaze point. Considering the FoV reported for this HMD, one would
need roughly 18000 measurements per lens to do it on every degree of
the visual ï¬eld. This task becomes unfeasible unless a model is built
that, from lesser measurements, interpolates the rest of the textures.

As already mentioned, the lenses used by the HMD present several
distortions that must be corrected through software. Therefore, the
image presented on display is already warped to compensate for the
lenses. It sets a limitation as only the manufacturer usually knows how
well it is corrected. Additionally, this compensation only takes one
ï¬xed pupil position (â€™static distortionsâ€™), and only a recent paper [Chan
et al., 2022] has started to look at how dynamic distortions aï¬€ect the
whole VR experience and discomfort by inducing unintended optic
ï¬‚ow.

Beyond distortions, progressive lenses present diï¬€erent blurring
across the visual ï¬eld, usually requiring a change in gaze behaviour to
avoid blurry vision, which can additionally inï¬‚uence the comfort while
wearing these types of lenses. In fact, the visual system is thought to
be more tolerant to distortions than it is to blur [Barbero and Portilla,
2015]. Nevertheless, a future study should assess the discomfort that
these lenses present due to blurring alone and perhaps a combination
of both.

7 Conclusions

Similar to how using free-form technologies impacted the PALs market,
reducing stock, costs, and expanding the ï¬tting possibilities [Alonso
et al., 2019], virtual reality holds the potential to become a testing
bench for acceptance of new optical consumer solutions and thus to
decrease the innovation costs of developing such lenses. VR combines
the naturality of performing a daily task with the ability to tweak
speciï¬c conditions which might not be possible in the real world.

This study proves it is possible to simulate, in virtual reality (up
to a certain degree), how distortions aï¬€ect our visual ï¬eld given dif-
ferent progressive lenses. Besides the high inter-subject variability,
every participant perceived diï¬€erent levels of discomfort for diï¬€erent
amounts of distortions. Other traits were found beyond subjectsâ€™ sus-
ceptibility or the distortions quantity deï¬ning the discomfort level that
one can perceive with a speciï¬c lens in certain conditions, such as
certain gazing or heading behaviours.

Finally, a machine learning model may help reduce the amount of
testing required and help to understand what features contribute the
most or why this sensation of discomfort does appear for some but not
everyone. However, an ampler amount of data is required to obtain a
more applicable model.

8 Acknowledgements

The authors acknowledge support by the Open Access Publishing Fund
of the University of TÃ¼bingen and the state of Baden-WÃ¼rttemberg
through bwHPC.

9 Declarations

Funding

The model

A gradient boosting regressor model was built. Although the modelâ€™s
accuracy on a single prediction is not outstanding, the model does
behave as expected for the diï¬€erent lenses. It is capable of predicting
ratings well within ranges deï¬ned for each lens condition. As men-
tioned in the limitations, the model could be further enhanced if more
data was acquired, mostly to support the high discomfort ratings.

Although SHAP values [Lundberg and Lee, 2017] were calculated
to look for how model features act on predictions of discomfort, these
values should be taken with care, especially when trying to understand
decision tree models. The minimum rating given by the subject can
be found as a main contributor. This could have occurred because
the model may have learned to identify the subject from the minimum
rating given, hence putting all individual preference weights into that
decision, i.e. basing its decisions on its idea of which subject was
estimating, even though this information was not. Other factors con-
tributing to the predictions were the baseline values reported by the
subject, which also could have served to acknowledge the participant,
the SD of the observed skew, aspect ratio diï¬€erences, magniï¬cation
and a minor role of displacement. The concentration parameter of
the ï¬rst distribution ï¬tted in yaw also contributed, which might be an
indirect consequence of how straight was the head relative to a gazed
target, upon a yaw movement, due to the diï¬€erent lenses.

It is not strange that skew was found to be a contributing factor
to discomfort while "wearing" PALs.
In fact, other studies already
connected skew and adaptation [Habtegiorgis et al., 2017, Rifai et al.,
2020]. Magniï¬cation was also previously connected to the so-called
swim eï¬€ect, which relates to the illusory and variable seesaw-like move-
ment of the visual ï¬eld that originates with lateral head movements.
This is further perceived with the nonuniform optical magniï¬cation
eï¬€ects between near and far objects [Han et al., 2003]. Magniï¬cation
in the adaptation to spectacles was also mentioned to induce changes
in the vestibular ocular reï¬‚ex and discomfort [Cannon et al., 1985],
which might induce more discomfort in VR [Chang et al., 2020].

This work was supported by the European Grant PLATYPUS (Grant
Agreement No 734227), a Marie Sklodowska-Curie RISE initiative.
Authors MGG & YS are employees of the University of TÃ¼bingen (E),
SW is employed by Carl Zeiss Vision International GmbH (E) and is a
scientist at the University TÃ¼bingen. TW is employed (E) by Western
Sydney University. According to the journal policy, they declare their
employment positions.

The founders did not play any additional role in the study design,
data collection, and analysis, decision to publish, or preparation of the
manuscript. The speciï¬c roles of these authors are articulated in the
â€™author contributionsâ€™ statement.

Conï¬‚icts of interest/Competing interests

The authors declare that the research was conducted in the absence of
any commercial or ï¬nancial relationships that could be construed as a
potential conï¬‚ict of interest.

Availability of data and material (data
transparency)

The datasets generated during and/or analysed during the current study
are available from the corresponding author on reasonable request.

Authorsâ€™ contributions

Conceptualization: MGG, TW & SW. Formal analysis, methodology,
software, validation and visualization: MGG & YS. Data curation, in-
vestigation, writing-original draft: MGG. Writing-review and editing:
MGG, YS, TW & SW. Supervision, resources and project administra-
tion: TW & SW. Funding acquisition: SW.

9

Ethics

The ethics authorisation to perform the measurements was granted
by the Ethics Committee at the Medical Faculty of the Eberhard-
Karls University and the University Hospital TÃ¼bingen with the ID
986/2020BO2.

References

Nur Aresya Ahmad Najmee, Noor Halilah Buari, Rabiatun Mujari, and
Muhammad Irwan Rahman. Satisfaction Level of Progressive Addi-
tional Lens (PALs) Wearers. Environment-Behaviour Proceedings
Journal, 2(6):373, 11 2017. doi: 10.21834/e-bpj.v2i6.999.

JosÃ© Alonso, JosÃ© A. GÃ³mez-Pedrero, and Juan A. Quiroga. Modern
Ophthalmic Optics. Cambridge University Press, 3 2019.
ISBN
9781316275474. doi: 10.1017/9781316275474. URL https://www.
cambridge.org/core/product/identiï¬er/9781316275474/type/book.

Tara L. Alvarez, Sang Han, Crystal Kania, Eun Kim, Oscar Tsang,
John L. Semmlow, Berangere Granger-Donetti, and Claude Pe-
drono. Adaptation to progressive lenses by presbyopes. In 2009
4th International IEEE/EMBS Conference on Neural Engineering,
pages 143â€“146. IEEE, 4 2009.
ISBN 978-1-4244-2072-8. doi:
10.1109/NER.2009.5109255.

Tara L Alvarez, Eun H Kim, and BÃ©rangÃ¨re Granger-Donetti. Adap-
tation to Progressive Additive Lenses: Potential Factors to Con-
sider.
ISSN 20452322.
doi: 10.1038/s41598-017-02851-5. URL http://www.ncbi.nlm.
nih . gov / pubmed / 28566706http : / / www. pubmedcentral . nih . gov /
articlerender.fcgi?artid=PMC5451391.

Scientiï¬c Reports, 7(1):2529, 2017.

David A. Atchison. Optical performance of progressive power lenses.
Clinical and Experimental Optometry, 70(5):149â€“155, 9 1987.
ISSN 0816-4622. doi: 10.1111/j.1444-0938.1987.tb04235.x.

Owen Aves. Special properties achieved by the combination of the
front and back surfaces, 1907. URL https://patents.google.com/
patent / GB190715735A / en ? q = spectacle + lens & inventor = owen +
aves&after=priority:19070101&scholar.

Eunhee Chang, Hyun Taek Kim, and Byounghyun Yoo. Virtual Reality
Sickness: A Review of Causes and Measurements. International
Journal of Human-Computer Interaction, 36(17):1658â€“1682, 2020.
ISSN 15327590. doi: 10.1080/10447318.2020.1778351. URL
https://doi.org/10.1080/10447318.2020.1778351.

M H Cho, C H Spear, and L Caplan. The eï¬€ect of excessive add
power on the acceptance of progressive addition lenses. Journal of
the American Optometric Association, 62(9):672â€“5, 9 1991. ISSN
0003-0244.

Weiwei Dai, Ivan Selesnick, John-Ross Rizzo, Janet Rucker, and Todd
Hudson. A parametric model for saccadic eye movement.
In
2016 IEEE Signal Processing in Medicine and Biology Symposium
(SPMB), pages 1â€“6. IEEE, 12 2016. ISBN 978-1-5090-6713-8. doi:
10.1109/SPMB.2016.7846860.

Gregor Esser, Wolfgang Becken, Helmut Altheimer, and Werner
MÃ¼ller. Generalization of the Minkwitz theorem to nonumbilical
lines of symmetrical surfaces. Journal of the Optical Society of
America. A, Optics, image science, and vision, 34(3):441â€“448, 3
2017. ISSN 1520-8532. doi: 10.1364/JOSAA.34.000441. URL
http://www.ncbi.nlm.nih.gov/pubmed/28248371.

Jerome H. Friedman. Stochastic gradient boosting. Computational
Statistics & Data Analysis, 38(4):367â€“378, 2 2002. ISSN 01679473.
doi: 10.1016/S0167-9473(01)00065-2.

Selam Wondimu Habtegiorgis, Katharina Rifai, Markus Lappe, and
Siegfried Wahl. Adaptation to Skew Distortions of Natural Scenes
and Retinal Speciï¬city of Its Aftereï¬€ects. Frontiers in Psychology,
8:1158, 7 2017. ISSN 1664-1078. doi: 10.3389/fpsyg.2017.01158.
URL http://journal.frontiersin.org/article/10.3389/fpsyg.2017.
01158/full.

Ying Han, Kenneth J. Ciuï¬€reda, Arkady Selenow, and Steven R. Ali.
Dynamic interactions of eye and head movements when reading with
single-vision and progressive lenses in a simulated computer-based
environment. Investigative Ophthalmology and Visual Science, 44
(4):1534â€“1545, 4 2003. ISSN 01460404. doi: 10.1167/iovs.02-
0507. URL http://iovs.arvojournals.org/article.aspx?doi=10.1167/
iovs.02-0507.

Sergio Barbero and MarÃ­a del Mar GonzÃ¡lez. Admissible surfaces in
progressive addition lenses. Optics Letters, 45(20), 10 2020. ISSN
0146-9592. doi: 10.1364/OL.401927.

Tim Head, Manoj Kumar, Holger Nahrstaedt, Gilles Louppe, and
Iaroslav Shcherbatyi. scikit-optimize/scikit-optimize, 9 2020. URL
https://doi.org/10.5281/zenodo.4014775.

Sergio Barbero and Javier Portilla. Geometrical interpretation of
dioptric blurring and magniï¬cation in ophthalmic lenses. Op-
tics Express, 23(10):13185, 5 2015.
doi:
10.1364/oe.23.013185.

ISSN 1094-4087.

Benjamin Bengfort and Rebecca Bilbro. Yellowbrick: Visualizing
the Scikit-Learn Model Selection Process. Journal of Open Source
Software, 4(35):1075, 3 2019. ISSN 2475-9066. doi: 10.21105/
joss.01075.

Jeewanand Bist, Dinesh Kaphle, Sanjay Marasini, and Himal Kandel.
Spectacle non-tolerance in clinical practice â€“ a systematic review
with meta-analysis. Ophthalmic and Physiological Optics, 41(3):
610â€“622, 5 2021. ISSN 0275-5408. doi: 10.1111/opo.12796.

Stephen C. Cannon, R. John Leigh, David S. Zee, and Larry A.
Abel. The Eï¬€ect of the Rotational Magniï¬cation of Corrective
Spectacles on the Quantitative Evaluation of the VOR. Acta Oto-
Laryngologica, 100(1-2):81â€“88, 1 1985.
ISSN 0001-6489. doi:
10.3109/00016488509108591.

Natalie Hutchings, Elizabeth L. Irving, Nadine Jung, Lisa M. Dowling,
and Kelly A. Wells. Eye and head movement alterations in naÃ¯ve
progressive addition lens wearers. Ophthalmic and Physiological
Optics, 27(2):142â€“153, 3 2007. ISSN 02755408. doi: 10.1111/j.
1475-1313.2006.00460.x.

Scott M Lundberg and Su-In Lee. A Uniï¬ed Approach to Interpreting
Model Predictions. In I Guyon, U Von Luxburg, S Bengio, H Wal-
lach, R Fergus, S Vishwanathan, and R Garnett, editors, Advances in
Neural Information Processing Systems, volume 30. Curran Asso-
ciates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/
ï¬le/8a20a8621978632d76c43dfd28b67767-Paper.pdf.

Bernard F. Maitenaz. Ophthalmic lenses with a progressively varying

focal power, 1969.

G. Minkwitz. Ãœber den FlÃ¤chenastigmatismus Bei Gewissen Sym-
metrischen AsphÃ¤ren. Optica Acta: International Journal of Optics,
10(3):223â€“227, 7 1963. ISSN 0030-3909. doi: 10.1080/713817794.
URL https://www.tandfonline.com/doi/full/10.1080/713817794.

Tsz Tai Chan, Yixuan Wang, Richard Hau Yue So, and Jerry Jia.
Predicting Subjective Discomfort Associated with Lens Distortion
in VR Headsets During Vestibulo-Ocular Response to VR Scenes.
IEEE Transactions on Visualization and Computer Graphics, pages
1â€“1, 2022. ISSN 1077-2626. doi: 10.1109/TVCG.2022.3168190.

Kees Mulder, Irene Klugkist, Daan van Renswoude, and Ingmar Visser.
Mixtures of peaked power Batschelet distributions for circular data
with application to saccade directions. Journal of Mathematical
Psychology, 95:102309, 4 2020. ISSN 00222496. doi: 10.1016/j.
jmp.2019.102309.

10

Kees Tim Mulder. Bayesian Circular Statistics: von Mises-based
solutions for practical problems. PhD thesis, Utrecht University, 6
2019.

Kenneth Neil Ogle and Saunders W.B. Researches in binocular vision.
W.B .Saunders, Philadelphia, 1950. URL https://books.google.de/
books?id=PykEAQAAIAAJ.

Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent
Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Pe-
ter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas,
Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu
Perrot, and Edouard Duchesnay. Scikit-learn: Machine Learning in
Python. Journal of Machine Learning Research, 12(85):2825â€“2830,
2011. URL http://jmlr.org/papers/v12/pedregosa11a.html.

Augustin Georges Poullain and Darius Henri Julien Cornet. Op-
lens., 7 1911. URL https://patents.google.com/patent/

tical
US1143316A/en?oq=U.S.+Patent+No.+1%2C143%2C316.

Katharina Rifai, Selam W. Habtegiorgis, Caroline Erlenwein, and
Siegfried Wahl. Motion-form interaction: Motion and form afteref-
fects induced by distorted static natural scenes. Journal of Vision,
20(13):10, 12 2020. ISSN 1534-7362. doi: 10.1167/jov.20.13.10.

Yannick Sauer, Siegfried Wahl, and Katharina Rifai. Parallel Adapta-
tion to Spatially Distinct Distortions. Frontiers in Psychology, 11,
11 2020. ISSN 1664-1078. doi: 10.3389/fpsyg.2020.544867.

Yannick Sauer, Alexandra Sipatchin, Siegfried Wahl, and Miguel
GarcÃ­a GarcÃ­a. Assessment of consumer VR-headsetsâ€™ objective
and subjective ï¬eld of view (FoV) and its feasibility for visual
ï¬eld testing. Virtual Reality, 1 2022.
ISSN 1359-4338. doi:
10.1007/s10055-021-00619-x. URL https://link.springer.com/10.
1007/s10055-021-00619-x.

L. Sawides, S. Marcos, S. Ravikumar, L. Thibos, A. Bradley, and
M. Webster. Adaptation to astigmatic blur. Journal of Vision, 10
(12):22â€“22, 10 2010. ISSN 1534-7362. doi: 10.1167/10.12.22.
URL http://jov.arvojournals.org/Article.aspx?doi=10.1167/10.12.
22.

Colin M. Sullivan and Colin W. Fowler. Progressive addition and
veriables focus lenses: A review. Ophthalmic and Physiological
Optics, 8(4):402â€“414, 10 1988. ISSN 0275-5408. doi: 10.1111/j.
1475-1313.1988.tb01177.x. URL https://onlinelibrary.wiley.com/
doi/10.1111/j.1475-1313.1988.tb01177.x.

The European Parliament and the Council of the European Union.
Regulation (EU) 2016/679 of the European Parliament and of the
Council. Oï¬ƒcial Journal of the European Union, 59(L119/1), 2016.

Ralf van der Lans, Michel Wedel, and Rik Pieters. Deï¬ning eye-ï¬xation
sequences across individuals and tasks:
the Binocular-Individual
Threshold (BIT) algorithm. Behavior Research Methods, 43(1):
239â€“257, 3 2011.
ISSN 1554-3528. doi: 10.3758/s13428-010-
0031-2.

Maria Vinas, Lucie Sawides, Pablo de Gracia, and Susana Marcos.
Perceptual Adaptation to the Correction of Natural Astigmatism.
PLoS ONE, 7(9):e46361, 9 2012. ISSN 1932-6203. doi: 10.1371/
journal.pone.0046361. URL http://dx.plos.org/10.1371/journal.
pone.0046361.

D. Volk and J. W. Weinberg. The Omnifocal Lens for Presbyopia.
Archives of Ophthalmology, 68(6):776â€“784, 12 1962. ISSN 0003-
9950. doi: 10.1001/archopht.1962.00960030780012.

11

