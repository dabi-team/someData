2
2
0
2

l
u
J

4
1

]

C
H
.
s
c
[

1
v
9
6
7
6
0
.
7
0
2
2
:
v
i
X
r
a

Virtual Reality (VR) as a testing bench for consumer optical solutions: A
machine learning approach (GBR) to visual comfort under simulated
progressive addition lenses (PALs) distortions

Miguel García García1, Yannick Sauer 1, Tamara Watson 2, and Siegfried Wahl 1,3

1Institute for Ophthalmic Research, University of Tuebingen, Elfriede-Aulhorn-Straße 7, Tübingen, 72072
2School of Social Science and Psychology, Western Sydney University, New South Wales, Australia
3Carl Zeiss Vision International GmbH, Turnstraße 27, 73430 Aalen

July 15, 2022

MGG Orcid 0000-0001-7379-0080
YS Orcid 0000-0002-7513-341X
TW Orcid 0000-0001-7899-0858
SW Orcid 0000-0003-3437-6711
Corresponding author: Miguel García García
miguel.garcia-garcia@uni-tuebingen.de

Abstract

For decades, manufacturers have attempted to reduce or eliminate the
optical aberrations that appear on the progressive addition lens’ sur-
faces during manufacturing. Besides every eﬀort made, some of these
distortions are inevitable given how lenses are fabricated, where in
fact, astigmatism appears on the surface and cannot be entirely re-
moved or where non-uniform magniﬁcation becomes inherent to the
power change across the lens. Some presbyopes may refer to certain
discomfort when wearing these lenses for the ﬁrst time, and a subset
of them might never adapt. Developing, prototyping, testing and pur-
veying those lenses into the market come at a cost, which is usually
reﬂected in the retail price. This study aims to test the feasibility of
virtual reality for testing customers’ satisfaction with these lenses, even
before getting them onto production. VR oﬀers a controlled environ-
ment where diﬀerent parameters aﬀecting progressive lens comforts,
such as distortions, image displacement or optical blurring, can be
analysed separately. In this study, the focus was set on the distortions
and image displacement, not taking blur into account. Behavioural
changes (head and eye movements) were recorded using the built-in
eye tracker. Participants were signiﬁcantly more displeased in the
presence of highly distorted lens simulations. In addition, a gradient
boosting regressor was ﬁtted to the data, so predictors of discomfort
could be unveiled, and ratings could be predicted without performing
additional measurements.

Keywords: virtual reality distortions comfort progressive addi-

tion lenses eye-tracking

1

Introduction

Progressive addition lenses (PALs) provide presbyopes with clear vi-
sion at diﬀerent distances, with the use of a single ophthalmic lens
[Poullain and Cornet, 1911]. Firstly patented in 1907 [Aves, 1907],
multifocal ophthalmic lenses have undergone a great deal of evolution
[Sullivan and Fowler, 1988]. Although their introduction to the market
was neither rapid nor widely accepted, being only in 1959, when pre-
cursors of modern progressive lenses became commercially available
[Maitenaz, 1969, Volk and Weinberg, 1962], over the years, progres-
sive lenses have become the most popular solution for presbyopia.

1

In general, the fabrication of progressive power lenses leaves in-
evitably residual surface astigmatism that leads to peripheral distor-
tions [Minkwitz, 1963, Esser et al., 2017]. How this residual astig-
matism is spread across the surface was usually employed to classify
PALs into soft (more spread) and hard designs (more concentrated)
[Atchison, 1987]. However, nowadays, these lenses navigate between
both classes, diﬀusing the borders as to whether they belong to one or
another category, with manufacturers aiming to obtain the best combi-
nation of parameters for each group of individuals.

Besides their popularity and the fact that they do seem to improve
wearers’ quality of life [Ahmad Najmee et al., 2017], not everyone
gets used to them. Scientiﬁc literature is scarce when it comes to
gathering knowledge about why few "rookie" wearers suﬀer in adapting
to these lenses or which could be the main factors contributing to this.
Some papers mainly refer to spectacles in general and report errors
in the prescription as the primary source of discomfort [Bist et al.,
2021]. However, assuming no errors from the optician, a small group
still reports discomfort due to distortions and multifocality. Alvarez
et al. [2017] proposed that non-adopters may have a weaker ability to
modify their convergence and a reduced rate and magnitude of phoria
adaptation. Yet, individuals who reject these lenses report blurred
vision, headaches, perceived movement of the peripheral visual ﬁeld
(a.k.a. swim), balance issues and even nausea [Cho et al., 1991, Han
et al., 2003], symptoms more likely associated with poor adaptation to
novel visual conditions [Alvarez et al., 2009].

Traditionally, as reported by Ogle and Saunders W.B. [1950], one
of the most signiﬁcant handicaps when analysing the tolerance to dis-
tortions induced by ophthalmic lenses was the diﬃculty in separating
them from blur [Barbero and González, 2020]. With the computational
development of the last decades, it is entirely possible to present an
image that is solely distorted [Habtegiorgis et al., 2017, Sauer et al.,
2020] or blurred [Sawides et al., 2010, Vinas et al., 2012], helping to
understand how our visual system adapts to these changes. However,
these experiments are somewhat forced, built upon certain constraints,
such as speciﬁc gazing or a ﬁxed head position, and while they do drive
knowledge forward, they often lose sight of the big picture.

On the other hand, one can analyse eye-tracking data while wearing
PALs [Hutchings et al., 2007], bringing more natural conditions at
the expense of not fully comprehending which features are aﬀecting
what since they can not be separated. In addition, the potential source
of error that arises when ﬁtting PALs cannot be ignored. All in all,
virtual reality oﬀers a perfect test bench as it can replicate the eﬀect
of distortions and blurring apiece while maintaining the freedom of
movement and immersion of virtual environments.

This study aims to test the feasibility of virtual reality to assess,
benchmark and rate the discomfort that four diﬀerent ophthalmic lenses
with various refractive powers can introduce, given the distortions they
present. Subjective grading was performed continuously after ﬁnishing

 
 
 
 
 
 
a simple task involving navigation, locomotion, scene exploration, and
grasping to recognise the subjects’ ability to perceive such simulated
distortions and assess their comfort when aﬀected by them. Possible
behavioural changes prompted by optical distortions were also sought,
and a model was developed to predict what the discomfort might be
like without requiring additional measurements.

2 Material & Methods

2.1 Subjects and informed consent

A total of 18 naïve subjects (9 males / 9 females) participated in the
course of the study. The participants were aged between 19 and 30
years (mean = 24; SD = 3). None of the subjects presented a prior
history of problems using a virtual reality headset or motion issues,
nor did they present any refractive error that could have compromised
their vision during the experiment or inﬂuenced their perception due
to the usual wear of their lenses.

2.2 Ethics

The study adhered to the tenets of the Helsinki Declaration (2013) and
subsequent amends. The ethics authorisation to perform the measure-
ments was granted by the Ethics Committee at the Medical Faculty of
the Eberhard-Karls University and the University Hospital Tübingen
with the ID 986/2020BO2. Before data collection, the experiment was
explained in detail to the participants, and written informed consent
from each participant was stored. All data was pseudo-anonymised
and stored in full compliance with the principles of the Data Protection
Act GDPR 2016/679 of the European Union [The European Parliament
and the Council of the European Union, 2016].

2.3 Set-Up

A cuboidal booth of 3 × 3 m deﬁned the physical space around which
the participants were entitled to freely move. On every upper corner
(4 in total), one HTC Vive lighthouse base station tracker v2 (HTC
Cooperation, Xindian, Taiwan) recorded the position and orientation
of the headset as well as the controller used. The StarVR One (StarVR,
Taipei, Taiwan) head-mounted display was used to present the virtual
environment to the participants. This head-mounted display (HMD)
has an eﬀective ﬁeld of view (FoV) of 182° by 99° [Sauer et al., 2022],
and an average eye relief (or distance from lens/display to the eye of
18.2 mm (15.8 to 23.9 mm). The display has a resolution of 2240 px ×
1792 px, a maximum luminance of 68.4 cd m−2 and the refresh rate
ﬁxed at 90 Hz. This device presents eye-tracking capabilities through
Tobii Pro libraries. For reference, the display area covered by the
eye-tracker, as reported by the manufacturer, is plotted in Figure 1.
To provide input and locate the hand position, a standard HTC Vive
controller was used.

Figure 1: Area of display resolution of the VR headset(gray)
as well as area in pixels covered by the eye tracker(orange) as
provided by the manufacturer.

2

2.3.1 Virtual environment & Computer

The virtual environment was constructed using the rendering engine
Unity version 2019.4.25.f1 (Unity Technologies, California, USA)
and Blender 3.0 (Stichting Blender Foundation, Amsterdam, Nether-
lands). The experiment was written in C# and the eye-tracking data
was recorded using the Tobii Pro (Tobii Pro AB, Danderyd, Sweden)
eye-tracking libraries. A view of the virtual reality environment used
is depicted in Fig 2.

The whole experiment ran on a Windows 10(20H2) PC with an

Intel(R) Core i7-10700, 16 GB of RAM and an Nvidia 3080 GPU.

2.4 The task

After providing informed consent and having the experiment explained
in detail, participants had time to ask questions. They then wore the
virtual reality headset to acclimate to the scene by wandering around
the virtual environment (a replica of a lab room) before the actual
assignment started. Across the task, participants were requested to
position three diﬀerent virtual cubes from point A (Green star) to
point B (Red circle)(See Fig 2). The location at which those cubes
spawned was randomised between several pre-deﬁned positions in the
shelf unit. The cubes’ colours, the patterns they presented on their
surface and the location where they were supposed to be placed were
also randomly changed across trials. Instructions on where the cubes
had to be placed were provided on a virtual whiteboard (Blue square)
opposite the cubes’ spawn origin. Thus, participants were forced to
move and look around in the virtual environment during each trial.

2.4.1 Ratings of discomfort

After every cube was correctly placed on the plate, a UI panel with a
slider popped up in front of the participant. In this panel, the partic-
ipants were asked to report their level of visual discomfort on a scale
from 0 (no discomfort) to 7 (highest discomfort). Previous to providing
this feedback, participants were instructed to rate only based on how
the distortions aﬀected their perception of their visual comfort and to
not take into account factors such as possible frame drops or the image
resolution. Given the rating and conﬁrmation, the trial was completed,
and a new trial started.

A total of 25 trials were answered (ﬁve per lens condition), with an
average duration of a trial of 36 s (SD = 12 s, range from 18 s to 101 s).

2.5 Lens Conditions - Distortion simulation

Four progressive additional lenses of the same type, but diﬀerent pre-
scription power were used. Diﬀerent addition powers or spherical
power prescriptions do modify how distortions are present. The distor-
tions proﬁles were provided by the manufacturer from a set of lenses
with the following parameters ﬁxed: a refractive index of 1.5, a panto-
scopic angle of 7.5°, a 5.28 mm base curvature, a back vertex distance
of 12 mm and a corridor length of 14 mm. Two of these lenses had
non spherical power and addition powers from +2 and +3 D, and the
other two lenses had an addition power +2 D and a spherical refractive
correction of +2 and −2 D. In line with modern PALs, these lenses
have their "umbilical line" tilted, with the near point shifted towards
the nasal side to account for vergence.

A set of grid points (𝑥, 𝑦) on a plane perpendicular to a straight
gaze direction is perceived in a distorted position (𝑥𝑑, 𝑦𝑑) when seen
through a progressive addition lens. The displacement between (𝑥𝑑,
𝑦𝑑) and (𝑥, 𝑦) was pre-computed for each lens using ray tracing based
on these lenses’ digital lens surface data. The displacement in the
horizontal and vertical coordinates were encoded into a raster image
(EXR format) where the red colour channel was used for the shift of
the pixel in the horizontal direction and the green colour for the vertical
component.

These distortions were then applied pixel-wise to the image dis-
played in the virtual reality headset through a custom shader in Unity
3D, written in HLSL. The amount of pixel displacement that these lens

050010001500200025003000350040004500050010001500Left Eye                                   Right EyeFigure 2: View of the virtual environment. The blue square denotes where the instructions were located in the virtual environment,
and the rating user interface (UI) was presented. The red circle is located where the cubes need to be placed. Finally, the green
star is placed upon the cube spawns’ origin.

simulations prompted in visual angle, along with the magniﬁcation,
skew, aspect or rotation, as seen by the participants, can be observed
in Fig 3.

The angular displacement in the visual ﬁeld as observed was com-

puted using the following formula:

Displacement (V(Visual angle in degrees) ) =

𝑐𝑜𝑠−1 (cid:169)
(cid:173)
(cid:173)
(cid:171)

𝑥𝑑 × 𝑥 + 𝑦𝑑 × 𝑦 + 1
𝑑 + 𝑦2

𝑑 + 1) × (𝑥2 + 𝑦2 + 1)

(𝑥2

√︃

(cid:170)
(cid:174)
(cid:174)
(cid:172)

(1)

;

Where (𝑥, 𝑦) are the coordinates of the original grid points and (𝑥𝑑,
𝑦𝑑) are the location of those points after the distortion is applied.

2.6 Tracking

On every frame, the position coordinates of the head-mounted display
(HMD) along with the rotation quaternions and gaze vectors were
stored.

2.6.1 Head-tracking

Head rotation values were converted using quat2eul into Euler angles
following the MATLAB coordinates system for analysis and plotting.
The table 1 summarises the diﬀerent coordinates systems that are used
in the main libraries of this study.

Program
Library

Coordinate
System

X

Y

Z

Euler angles
order

Unity 3D

Left-handed → ↑ (cid:37)

MATLAB Right-handed (cid:37) ← ↑

z,x,y

z,y,x

Table 1: Coordinates system references for each software sys-
tem. → - right; ← - left; ↑ - up; (cid:37) - forward.
,

On every trial the yaw, pitch and roll were computed using the HMD

quaternions as described in the equation 2.

Tait Bryan Angles (roll, pitch, yaw) =
quat2eul(𝑟𝑜𝑡𝑊, 𝑟𝑜𝑡𝑍, −𝑟𝑜𝑡 𝑋, 𝑟𝑜𝑡𝑌 , 𝑋𝑌 𝑍);

(2)

The roll data (tilt of the head) was further characterised with a Von

Misses distribution ﬁt (See equation 3).

M (𝜃| 𝜇, 𝜅) = [2𝜋𝐼0 (𝜅)]−1𝑒𝑥 𝑝{𝜅 𝑐𝑜𝑠(𝜃 − 𝜇)};

(3)

3

Where 𝜇 is the mean direction, 𝐼0 is the bessel function of the ﬁrst kind,
𝜅 is the concentration parameter, and 𝜃 refers to the angle in radians
from −𝜋 to 𝜋.

The pitch (or head inclination up to down) was described using a
combination of two Von Misses distributions. And ﬁnally, the yaw (or
horizontal head rotation) was represented by the ﬁt (See equation 4)
of two inverse Power Batschelet distributions [Mulder, 2019, Mulder
et al., 2020], as the data was highly peaked towards the cube spawns
origin and the horizontal location of the plate, whiteboard and rating
UI panel.

𝑓P B (𝜃| 𝜇, 𝜅, 𝜆) =

(cid:104)

(cid:105) −1

𝑒𝑥 𝑝{𝜅 𝑐𝑜𝑠 𝑡∗

𝜆 (𝜃 − 𝜇)};

𝑒𝑥 𝑝{𝜅 𝑐𝑜𝑠 𝑡∗

𝜆 (𝜃 − 𝜇)} 𝑑𝜃;

K∗
𝜅 ,𝜆
∫ 𝜋

− 𝜋

K∗

𝜅,𝜆 =

𝑡∗
𝜆 (𝜃) = 𝑠𝑖𝑔𝑛(𝜃)𝜋

(cid:19) 𝛾 (𝜆)

;

(cid:18) |𝜃|
𝜋

(4)

𝛾(𝜆) =

1 − 𝑐𝜆
1 + 𝑐𝜆 ;

where c = 0.04082284 as noted by Mulder [2019].

2.6.2 Eye Tracking

The eye-tracking data was obtained using the Tobii Pro SDK 1.10 for
Unity. The SDK was modiﬁed to further record the hit-point of the
gaze vector in the world coordinates.

Fixations While recording the eye-tracking data, on every frame,
the combined (head and gaze) origin and direction were used to cast
a ray within Unity until it hit a collider in the scene. The coordinates
of this hit-point (x,y,z) were later used to detect ﬁxations. If a cluster
of continuous hit-points stood within the volume of a sphere of 0.05 m
radius, during more than 200 ms (See van der Lans et al. [2011] for
a review on average ﬁxations duration while visual search and scene
viewing), it was considered a ﬁxation. The amounts of ﬁxations per-
formed per minute and their average duration were recorded on every
trial.

Saccades To estimate saccadic eye movements, the gaze ray from
the right eye (in headset relative coordinates) was transformed into
polar (𝜃) and azimuthal angles (𝜙). The median angular distance
travelled (𝜓) between the original frame vector, and the ﬁve subsequent
frames was computed following the equation 5. Then, the angular
speed was estimated as the angular distance per second, on which a

Figure 3: Representation of how distortions aﬀect a grid and the image observed (background), and maps of pixel displacement
in visual angles as observed from the subject’s perspective for the OD, as well as magniﬁcation, diﬀerences in aspect ratio, skew
and rotation calculated from the ﬁrst derivatives of the distortions.

4

Savitzky-Golay ﬁlter [Dai et al., 2016] was applied.

𝜙 = arctan

(cid:16) 𝑦
𝑥

(cid:17)

;

𝜃 = arccos(𝑧);
𝜓 =

(5)

(sin(𝜃𝑛+𝑖) × sin(𝜃𝑛) × cos(𝜙𝑛+𝑖 − 𝜙𝑛)
(cid:17)

+ cos(𝜃𝑛) × cos(𝜃𝑛+𝑖)

;

(cid:16)

arccos

A speed threshold of 50 ° s−1 and a minimum distance (𝜓) of 1°
were deﬁned as thresholds for deﬁning a saccade. The number of sac-
cades per minute, the average amplitude and maximum peak velocity
performed on every trial were recorded.

Eye tracking to measure average observed displacement,
magniﬁcation, aspect, skew and rotation Every gaze position
was projected over the displacement, magniﬁcation, skew, rotation,
and diﬀerences on aspect ratio maps, and the observed absolute and
relative ("foveally") pixel displacement, magniﬁcation, skew, rotation
and aspect ratio parameters were computed by summing the values
at gaze position over all the frames of the trial. The mean value and
standard deviation per trial were recorded and compared.

3 Analysis & Preprocessing of the Data

All the statistical analysis and plotting were performed in MATLAB
2020b (Mathworks Inc, Natick, CA, USA) and Python 3.10 with sci-kit
learn 1.0.2 [Pedregosa et al., 2011].

4 Results

4.1 Visual discomfort

On every trial, the participants rated their visual discomfort on a scale
from 0 to 7, with zero being normal and seven being the most uncom-
fortable. Discomfort is, in fact, a subjective parameter that is highly
susceptible to vary between subjects and depends on where the par-
ticipant sets the threshold towards unpleasantness. Given the same
distortion and conditions, two subjects can be uncomfortable or not.
To standardise our answers and limit the subject’s susceptibility, the
ratings were normalised using the ratings where no lens distortion was
presented as a baseline. The formula used can be observed in the
equation 6.

𝑅{𝑖 } = 𝑅{𝑖 } 𝑜𝑟𝑖𝑔 ×

𝑅{𝑖 } 𝑛𝑜𝑟𝑚 =

+ 1;

10
7
𝑅{𝑖 }
𝑅 {𝑏𝑎𝑠𝑒𝑙𝑖𝑛𝑒 }

;

(6)

The distribution of visual discomfort ratings was not parametric in
any of the conditions tested. Thus, a non-parametric test (Kruskal-
Wallis) was used to compare lens condition discomfort ratings. Sig-
niﬁcant diﬀerences were found between the distributions of visual
discomfort ratings across conditions (p < 0.01; ˜𝜒2 = 69). Bonferroni’s
Post-Hoc test indicated that the lens distortions from the lens +2D and
addition +2 were more disturbing than the rest. Likewise, the lens with
a spherical power of -2 and addition +2 had the smallest discomfort.
Fig 4 shows the distribution of ratings and the statistical diﬀerences.

The Cronbach‘s alpha value (𝜌𝜏 ) for the rating scale was found to

be statistically consistent (0.88).

Figure 4: Visual discomfort ratings’ distribution across condi-
tions, all values have been normalised. The horizontal bars on
top indicate signiﬁcant diﬀerences in Post-Hoc analysis.

4.3 Duration

A small correlation (𝑅2 = 0.11, p = 0.02) was found between the du-
ration of the trials and the rating given. In general, subjects seemingly
were faster deciding whether to give the highest and the lowest ratings
of discomfort. However, subjects may have taken longer times during
the trial if the decision was unclear, as they perceived some level of
discomfort but not the highest.

4.4 Yaw, pitch and roll

Tables 3, 2 and 4 present the main characteristics of the ﬁtted distri-
butions for pitch, yaw and roll per trial with their mean and standard
deviations. The statistical diﬀerences of each parameter (individual,
lens or rating (rounded to the closest integer)) were computed using
the Kruskal-Wallis test, and are also reported in the tables.

None of the parameters above mentioned was signiﬁcantly diﬀerent
across lens conditions, but the full-width half maximum (FWHM)
of the ﬁrst inverse power Bachelet distribution on yaw. The same
FWHM, as well as the mean directions of pitch, and the FWHM of the
roll changed across rating groups.

4.5 Gaze behaviour

Fixations The number of ﬁxations per minute and duration of
ﬁxations were signiﬁcantly diﬀerent across subjects (Kruskal-Wallis,
H(17) = 255, p < 0.001) and (H(17) = 197, p < 0.001). Signiﬁcant dif-
ferences were also found in the number of ﬁxations per minute across
ratings (KW, H(5) = 25.7, p<0.001), where the greater discomfort is
perceived, the higher amount of ﬁxations are found, with the exception
of the group with the highest discomfort (4-5 ratings).

4.2 Gender & Age

No bias was found in the ratings of discomfort due to gender (Mann-
Withney-U; 𝑁 𝑓 𝑒𝑚𝑎𝑙𝑒𝑠 = 9 (MdN = 0.29); 𝑁𝑚𝑎𝑙𝑒𝑠 = 9 (MdN = 0.29);
U = 51917 ; z-val = 0.87; p = 0.39).

No correlation was found between the ratings and the age of the

participants (Spearman - 𝑅2 = 0.0018; p = 0.97).

Saccades The number of saccades per minute, as well as the peak
velocity and the average distance, travelled on a saccade, were signif-
icantly diﬀerent across participants (Kruskal-Wallis, H(17) = 269, p
< 0.001),(KW, H(17) = 301, p < 0.001) and (KW, H(17) = 285, p <
0.001). In the trials with more discomfort, the saccades were on aver-
age larger (KW, H(5) = 14, p < 0.05) and had a higher peak velocity
(KW, H(5) = 18, p < 0.01). Signiﬁcantly (KW, H(4) = 9.6, p < 0.05)

5

Add+2Add+3-2Add+2+2Add+2Baseline01234567Visual Discomfort RatioFigure 5: Examples of distributions ﬁtted for Yaw, Pitch and Roll. The green line denotes the ﬁnal distribution ﬁtted, and the
dashed red and blue lines indicate the individual distributions (inverse power Batschelet or von Mises, contributing to the ﬁnal
one). The icons on the Yaw plot represent the same locations as in the Fig. 2)
+2/+2
−/+3
−1.65 ± 0.10
−1.64 ± 0.11
6.57 ± 2.91
6.58 ± 2.88
0.68 ± 0.31
0.76 ± 0.27
0.28 ± 0.20
0.23 ± 0.17
0.60 ± 0.10
0.58 ± 0.11
1.77 ± 0.17
1.77 ± 0.13
2.25 ± 0.84
2.17 ± 0.99
1.00
1.00
0.32 ± 0.23
0.35 ± 0.21

−2/+2
−1.65 ± 0.12
6.42 ± 2.68
0.75 ± 0.26
0.23 ± 0.17
0.59 ± 0.10
1.75 ± 0.14
2.26 ± 0.96
1.00
0.32 ± 0.18

−/+2
−1.65 ± 0.10
6.04 ± 2.46
0.80 ± 0.22
0.20 ± 0.12
0.59 ± 0.09
1.75 ± 0.13
2.10 ± 0.76
1.00
0.34 ± 0.18

Baseline
−1.66 ± 0.08
6.15 ± 2.54
0.77 ± 0.23
0.22 ± 0.12
0.59 ± 0.09
1.76 ± 0.16
2.10 ± 0.72
1.00
0.34 ± 0.18

𝜇1
𝜅1
𝜆1
FWHM1
𝜔
𝜇2
𝜅2
𝜆2
FWHM2

Lens Ratings
𝑛.𝑠.

∗ ∗ ∗
𝑛.𝑠.

∗∗
𝑛.𝑠.

Subj

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

Table 2: Yaw. Two inverse power Batschelet F PB were ﬁtted. In addition to those in the caption of Table 2, 𝜆 refers to the
peakness of the ﬁtted distribution.

1-9
𝜇1

𝜅1

FWHM1
𝜔
𝜇2
𝜅2
FWHM2

−/+2
−0.05 ± 0.39
277.66 ±
145.80
0.55 ± 0.19
0.19 ± 0.22
−0.33 ± 0.15
48.66 ± 90.70
0.52 ± 0.31

−/+3
−0.06 ± 0.39
286.41 ±
160.89
0.55 ± 0.22
0.20 ± 0.20
−0.33 ± 0.17
49.47 ± 83.45
0.45 ± 0.29

−2/+2
−0.03 ± 0.48
283.69 ±
148.15
0.55 ± 0.21
0.15 ± 0.18
−0.31 ± 0.14
45.12 ± 88.38
0.57 ± 0.32

+2/+2
−0.10 ± 0.42
296.62 ±
150.39
0.57 ± 0.21
0.19 ± 0.20
−0.32 ± 0.14
44.28 ± 83.99
0.49 ± 0.29

Baseline
−0.01 ± 0.53
327.90 ±
155.98
0.54 ± 0.20
0.17 ± 0.19
−0.33 ± 0.16
48.41 ± 79.49
0.50 ± 0.36

Lens Ratings
𝑛.𝑠.

∗

Subj

∗ ∗ ∗

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

∗

𝑛.𝑠.

𝑛.𝑠.

∗
𝑛.𝑠.

𝑛.𝑠.

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

Table 3: Pitch. Two Von Mises (M) were ﬁtted. For each of them 𝜇 stands for mean direction, 𝜅 is concentration, 𝜔 is the
contribution of the function from 0 to 1, and FWHM stands for full-width half maximum of the distribution.

𝜇

𝜅

FWHM

−/+2
0.02 ± 0.04
344.33 ±
142.43
0.14 ± 0.04

−/+3
0.02 ± 0.05
352.14 ±
128.91
0.14 ± 0.04

−2/+2
0.03 ± 0.04
360.01 ±
130.41
0.13 ± 0.04

+2/+2
0.02 ± 0.04
361.83 ±
125.27
0.13 ± 0.03

Baseline
0.03 ± 0.04
382.43 ±
127.06
0.13 ± 0.03

Lens Ratings
𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

𝑛.𝑠.

∗∗

∗∗

Subj

∗ ∗ ∗

∗ ∗ ∗

∗ ∗ ∗

Table 4: Roll. A single Von Mises distribution (M).

6

YawPitchRollmore saccades were performed when the lens presented had higher
amount of distortions.

estimated using the "SHAP" or SHapley Additive exPlanation values
[Lundberg and Lee, 2017].

Observed displacement, magniﬁcation, rotation, skew and
aspect All the components that deﬁned the experienced distortion
computed from the movement data of each participant and the lens
worn were signiﬁcantly diﬀerent (KW, H(4) < 434 , p < 0.001) for
every lens condition tested in their mean and standard deviation. The
ranking order for it can be observed in Table 5. Signiﬁcantly more
mean pixel displacement, magniﬁcation, diﬀerences on aspect ratio,
skew, and rotation were observed when the subjects indicated higher
discomfort (KW, H(5) < 103 , p < 0.001). The standard deviation
of all the observed parameters was signiﬁcantly higher when more
discomfort was perceived. No diﬀerences across subjects were found
for any of the mean values or standard deviation, but rotation standard
deviation diﬀerences across subjects was close to signiﬁcant (KW,
H(17) = 27, p = 0.057).

Parameter

+2/+2

−/+3

−/+2

−2/+2

Displacement Mean

Displacement SD

Magniﬁcation Mean

Magniﬁcation SD

Aspect Mean

Aspect SD

Skew Mean

Skew SD

Rotation Mean

Rotation SD

Table 5: Matrix draw showing the lens conditions ordered from
highest (darker) to lowest(brighter), if the same colour appeared
no signiﬁcant diﬀerences were found between these two condi-
tions.

5 Model - Gradient Boosting Regressor

Understanding what features might have inﬂuenced the decision for
speciﬁc discomfort ratings can be a herculean task if deferred to tra-
ditional methods. However, thanks to the advances in computational
power and machine learning algorithms, it is possible nowadays. Using
scikit learn package in Python [Pedregosa et al., 2011], we built a gra-
dient boosting regressor [Friedman, 2002], which ensembles several
decision trees, using the residuals to ﬁt the next iteration and weighting
them to obtain a ﬁnal model, capable of not only predicting new ratings
given the estimators but also providing the relevance of the estimators.
The dataset used comprised a total of 450 trials, and contained
age, gender, duration, baseline, maximum and minimum ratings of
the subject, absolute mean and standard deviations of the "foveally"
observed factors as described before, each of the parameters ﬁtted to
pitch, yaw and roll, and the already analysed data from the eye-tracking
(i.e. ﬁxations and saccades).

70% of the dataset was used to train the model, and the remaining
30% was only used to test the model’s accuracy, i.e. the data was never
shown to the model until the testing phase. The split was performed
with stratiﬁcation on subjects and lens conditions and testing for its
robustness. The best hyper-parameters were decided using a bayesian
optimisation search from skopt [Head et al., 2020], and a repeated
stratiﬁed group cross-validation fold within a pipeline.

The best features were selected from the model using the meta-
transformer SelectFromModel and their relevance to the model was

7

Figure 6: Visual discomfort ratings’ distribution across lenses,
all values have been normalised. Diﬀerent hues show the train-
ing dataset(true values), test dataset and the predictions from
the model.

Over 400 seeds of random splits were tested to assure the model

robustness, the table 6 shows the results of it.

R2

𝑡𝑒𝑠𝑡

R2

𝑡𝑟 𝑎𝑖𝑛 MAPE MSE

Maximum
error

Mean

SD

0.53
±0.08

0.84
±0.06

44.18% 0.33
±4.69% ±0.05

2.12
±0.30

Table 6: Performance metrics from the model.

Fig. 6 presents the predictions of the model classiﬁed for diﬀerent
lenses and compared with the real values. Fig. 7 shows the residuals
of the model for the train and test dataset.

The Fig. 8 presents the "SHAP" values for the selected features of

the model.

6 Discussion

This study shows that distortions of PALs can be simulated in Virtual
Reality and that diﬀerent lenses holding various degrees of distortions
are perceived by the participants as having diﬀerent levels of vexation,
being those that presented a higher level of distortions experienced as
more uncomfortable. In our case, the lens with spherical power +2 D
and addition +2 D was rated the worst of all, followed by those without
spherical power and addition +3 D and +2 D. One would expect the
baseline (i.e. no distortions) to be rated as the most comfortable, but
nevertheless, the lens distortions due to the negative spherical power
and the +2 addition presented levels of discomfort equal to the baseline.
A sum of several factors could have contributed to this result. On
the one hand, these lens distortions have low levels of displacement

Figure 7: Residuals of the model depicted using Bengfort and Bilbro [2019] yellowbrick library for one of the best outcomes of
the model.

distribution, implying the more distortions, the less accurate our hor-
izontal head movement is. The statistical results comparing against
clusters of ratings should be taken with care. Although non-parametric
tests were used, the number of measurements on the worse/higher
ratings (4-5, after normalising) were quite low. For example, some
parameters of yaw and roll were signiﬁcantly diﬀerent across rating
groups, but no clear pattern was found, and no additional diﬀerences
were found in the post-hoc analysis.

Regarding gaze movements, fewer ﬁxations per minute lead to better
ratings, this was not found between lens conditions, where there were
no statistical diﬀerences, but +2/Add2 presented more ﬁxations per
In this case, a pattern could be observed from the ratings,
minute.
where the more ﬁxations are made per minute, the more distress is
perceived, and only in the 4-5 groups it was disrupted, probably due
to the reduced sample of this groups. Thus, more distortions may
have led to more ﬁxations, and the more one ﬁxates, the more one
perceives those distortions, giving them worse ratings. Furthermore,
more saccades were performed in the textures with greater distortions,
and ratings followed the same pattern but did not reach signiﬁcance.
Otherwise, the worse ratings presented shorter saccadic lengths and
slower peak velocities in the saccades, but, in this case, nothing could
be found for the diﬀerent lens conditions. In general, gazing behaviour
is highly tied to each individual, like the heading movements. However,
more saccades and more ﬁxations led to higher rates of discomfort,
although that might have been coupled with the lens in use.

The lens condition dictated how much of the mean and standard
deviation of displacement, magniﬁcation, rotation, diﬀerences in the
aspect ratio, and skew were observed, a factor which inﬂuence the ﬁnal
rating. No diﬀerences across subjects were found, probably because
even if they gaze diﬀerently, the area they cover and locations they gaze
through were pretty similar.

Limitations of the study

There are several limiting factors that may have constrained the study’s
outcome. One of the main hiccups of the data was the reduced amount
of high/worse discomfort ratings (see Fig. 7), precluding the draw-
ing of some conclusions and probably limiting the model’s accuracy.
To gather more data with high ratings, the sample size must be in-
creased by presenting more trials with higher distortions lenses, more

Figure 8: SHAP values for the selected features of the model.

in the central area, as can be seen in Fig. 3, which could explain
similar ratings to the baseline. We also cannot be entirely sure that the
manufacturer has fully corrected in the software the distortions caused
by the VR headset lenses, and considering this headset uses a canted
display, magniﬁcation from negative lenses may have made the image
look more natural. The subjective input scale was consistent given the
Cronbach’s index.

Although no correlation was found between the age of the subjects
and the ratings given, it is important to mention that we have a reduced
It can not be
sample of young participants with a small variance.
discarded that ratings might be diﬀerent if an older group was tested,
including presbyopes. Moreover, all of our subjects were emmetropes
with an aim to avoid bias in our reduce sample, but usual ophthalmic
wearers might like more the distortions that look alike to those they are
habituated to.

Subjects’ heading and gazing presented a signiﬁcant variance across
individuals, independently of the distortions applied, which is expected
as it is known that these parameters are tied to each individual. Only
one of the inverse power Batschelet distributions ﬁtted for yaw varied
signiﬁcantly between the lenses and ratings, with a wider "+2/Add2"

8

lens conditions with a high amount of distortions, or simply measuring
more subjects. In fact, including more lenses, with not only diﬀerent
prescription powers but also diﬀerent designs may provide more infor-
mation on individual characteristics and their inﬂuence on discomfort.
In this study, only "static distortions" were measured, i.e. the distor-
tions of the PALs were only measured on the lens surface and presented
as if looking through the main line of sight. Although the perceived
distortions varied when looking through diﬀerent areas, the distortions
applied through the custom shader did not update with the gaze. Pre-
senting "dynamic distortions" entails having previously measured and
stored a texture of how each pixel shifts on the texture at each possible
gaze point. Considering the FoV reported for this HMD, one would
need roughly 18000 measurements per lens to do it on every degree of
the visual ﬁeld. This task becomes unfeasible unless a model is built
that, from lesser measurements, interpolates the rest of the textures.

As already mentioned, the lenses used by the HMD present several
distortions that must be corrected through software. Therefore, the
image presented on display is already warped to compensate for the
lenses. It sets a limitation as only the manufacturer usually knows how
well it is corrected. Additionally, this compensation only takes one
ﬁxed pupil position (’static distortions’), and only a recent paper [Chan
et al., 2022] has started to look at how dynamic distortions aﬀect the
whole VR experience and discomfort by inducing unintended optic
ﬂow.

Beyond distortions, progressive lenses present diﬀerent blurring
across the visual ﬁeld, usually requiring a change in gaze behaviour to
avoid blurry vision, which can additionally inﬂuence the comfort while
wearing these types of lenses. In fact, the visual system is thought to
be more tolerant to distortions than it is to blur [Barbero and Portilla,
2015]. Nevertheless, a future study should assess the discomfort that
these lenses present due to blurring alone and perhaps a combination
of both.

7 Conclusions

Similar to how using free-form technologies impacted the PALs market,
reducing stock, costs, and expanding the ﬁtting possibilities [Alonso
et al., 2019], virtual reality holds the potential to become a testing
bench for acceptance of new optical consumer solutions and thus to
decrease the innovation costs of developing such lenses. VR combines
the naturality of performing a daily task with the ability to tweak
speciﬁc conditions which might not be possible in the real world.

This study proves it is possible to simulate, in virtual reality (up
to a certain degree), how distortions aﬀect our visual ﬁeld given dif-
ferent progressive lenses. Besides the high inter-subject variability,
every participant perceived diﬀerent levels of discomfort for diﬀerent
amounts of distortions. Other traits were found beyond subjects’ sus-
ceptibility or the distortions quantity deﬁning the discomfort level that
one can perceive with a speciﬁc lens in certain conditions, such as
certain gazing or heading behaviours.

Finally, a machine learning model may help reduce the amount of
testing required and help to understand what features contribute the
most or why this sensation of discomfort does appear for some but not
everyone. However, an ampler amount of data is required to obtain a
more applicable model.

8 Acknowledgements

The authors acknowledge support by the Open Access Publishing Fund
of the University of Tübingen and the state of Baden-Württemberg
through bwHPC.

9 Declarations

Funding

The model

A gradient boosting regressor model was built. Although the model’s
accuracy on a single prediction is not outstanding, the model does
behave as expected for the diﬀerent lenses. It is capable of predicting
ratings well within ranges deﬁned for each lens condition. As men-
tioned in the limitations, the model could be further enhanced if more
data was acquired, mostly to support the high discomfort ratings.

Although SHAP values [Lundberg and Lee, 2017] were calculated
to look for how model features act on predictions of discomfort, these
values should be taken with care, especially when trying to understand
decision tree models. The minimum rating given by the subject can
be found as a main contributor. This could have occurred because
the model may have learned to identify the subject from the minimum
rating given, hence putting all individual preference weights into that
decision, i.e. basing its decisions on its idea of which subject was
estimating, even though this information was not. Other factors con-
tributing to the predictions were the baseline values reported by the
subject, which also could have served to acknowledge the participant,
the SD of the observed skew, aspect ratio diﬀerences, magniﬁcation
and a minor role of displacement. The concentration parameter of
the ﬁrst distribution ﬁtted in yaw also contributed, which might be an
indirect consequence of how straight was the head relative to a gazed
target, upon a yaw movement, due to the diﬀerent lenses.

It is not strange that skew was found to be a contributing factor
to discomfort while "wearing" PALs.
In fact, other studies already
connected skew and adaptation [Habtegiorgis et al., 2017, Rifai et al.,
2020]. Magniﬁcation was also previously connected to the so-called
swim eﬀect, which relates to the illusory and variable seesaw-like move-
ment of the visual ﬁeld that originates with lateral head movements.
This is further perceived with the nonuniform optical magniﬁcation
eﬀects between near and far objects [Han et al., 2003]. Magniﬁcation
in the adaptation to spectacles was also mentioned to induce changes
in the vestibular ocular reﬂex and discomfort [Cannon et al., 1985],
which might induce more discomfort in VR [Chang et al., 2020].

This work was supported by the European Grant PLATYPUS (Grant
Agreement No 734227), a Marie Sklodowska-Curie RISE initiative.
Authors MGG & YS are employees of the University of Tübingen (E),
SW is employed by Carl Zeiss Vision International GmbH (E) and is a
scientist at the University Tübingen. TW is employed (E) by Western
Sydney University. According to the journal policy, they declare their
employment positions.

The founders did not play any additional role in the study design,
data collection, and analysis, decision to publish, or preparation of the
manuscript. The speciﬁc roles of these authors are articulated in the
’author contributions’ statement.

Conﬂicts of interest/Competing interests

The authors declare that the research was conducted in the absence of
any commercial or ﬁnancial relationships that could be construed as a
potential conﬂict of interest.

Availability of data and material (data
transparency)

The datasets generated during and/or analysed during the current study
are available from the corresponding author on reasonable request.

Authors’ contributions

Conceptualization: MGG, TW & SW. Formal analysis, methodology,
software, validation and visualization: MGG & YS. Data curation, in-
vestigation, writing-original draft: MGG. Writing-review and editing:
MGG, YS, TW & SW. Supervision, resources and project administra-
tion: TW & SW. Funding acquisition: SW.

9

Ethics

The ethics authorisation to perform the measurements was granted
by the Ethics Committee at the Medical Faculty of the Eberhard-
Karls University and the University Hospital Tübingen with the ID
986/2020BO2.

References

Nur Aresya Ahmad Najmee, Noor Halilah Buari, Rabiatun Mujari, and
Muhammad Irwan Rahman. Satisfaction Level of Progressive Addi-
tional Lens (PALs) Wearers. Environment-Behaviour Proceedings
Journal, 2(6):373, 11 2017. doi: 10.21834/e-bpj.v2i6.999.

José Alonso, José A. Gómez-Pedrero, and Juan A. Quiroga. Modern
Ophthalmic Optics. Cambridge University Press, 3 2019.
ISBN
9781316275474. doi: 10.1017/9781316275474. URL https://www.
cambridge.org/core/product/identiﬁer/9781316275474/type/book.

Tara L. Alvarez, Sang Han, Crystal Kania, Eun Kim, Oscar Tsang,
John L. Semmlow, Berangere Granger-Donetti, and Claude Pe-
drono. Adaptation to progressive lenses by presbyopes. In 2009
4th International IEEE/EMBS Conference on Neural Engineering,
pages 143–146. IEEE, 4 2009.
ISBN 978-1-4244-2072-8. doi:
10.1109/NER.2009.5109255.

Tara L Alvarez, Eun H Kim, and Bérangère Granger-Donetti. Adap-
tation to Progressive Additive Lenses: Potential Factors to Con-
sider.
ISSN 20452322.
doi: 10.1038/s41598-017-02851-5. URL http://www.ncbi.nlm.
nih . gov / pubmed / 28566706http : / / www. pubmedcentral . nih . gov /
articlerender.fcgi?artid=PMC5451391.

Scientiﬁc Reports, 7(1):2529, 2017.

David A. Atchison. Optical performance of progressive power lenses.
Clinical and Experimental Optometry, 70(5):149–155, 9 1987.
ISSN 0816-4622. doi: 10.1111/j.1444-0938.1987.tb04235.x.

Owen Aves. Special properties achieved by the combination of the
front and back surfaces, 1907. URL https://patents.google.com/
patent / GB190715735A / en ? q = spectacle + lens & inventor = owen +
aves&after=priority:19070101&scholar.

Eunhee Chang, Hyun Taek Kim, and Byounghyun Yoo. Virtual Reality
Sickness: A Review of Causes and Measurements. International
Journal of Human-Computer Interaction, 36(17):1658–1682, 2020.
ISSN 15327590. doi: 10.1080/10447318.2020.1778351. URL
https://doi.org/10.1080/10447318.2020.1778351.

M H Cho, C H Spear, and L Caplan. The eﬀect of excessive add
power on the acceptance of progressive addition lenses. Journal of
the American Optometric Association, 62(9):672–5, 9 1991. ISSN
0003-0244.

Weiwei Dai, Ivan Selesnick, John-Ross Rizzo, Janet Rucker, and Todd
Hudson. A parametric model for saccadic eye movement.
In
2016 IEEE Signal Processing in Medicine and Biology Symposium
(SPMB), pages 1–6. IEEE, 12 2016. ISBN 978-1-5090-6713-8. doi:
10.1109/SPMB.2016.7846860.

Gregor Esser, Wolfgang Becken, Helmut Altheimer, and Werner
Müller. Generalization of the Minkwitz theorem to nonumbilical
lines of symmetrical surfaces. Journal of the Optical Society of
America. A, Optics, image science, and vision, 34(3):441–448, 3
2017. ISSN 1520-8532. doi: 10.1364/JOSAA.34.000441. URL
http://www.ncbi.nlm.nih.gov/pubmed/28248371.

Jerome H. Friedman. Stochastic gradient boosting. Computational
Statistics & Data Analysis, 38(4):367–378, 2 2002. ISSN 01679473.
doi: 10.1016/S0167-9473(01)00065-2.

Selam Wondimu Habtegiorgis, Katharina Rifai, Markus Lappe, and
Siegfried Wahl. Adaptation to Skew Distortions of Natural Scenes
and Retinal Speciﬁcity of Its Aftereﬀects. Frontiers in Psychology,
8:1158, 7 2017. ISSN 1664-1078. doi: 10.3389/fpsyg.2017.01158.
URL http://journal.frontiersin.org/article/10.3389/fpsyg.2017.
01158/full.

Ying Han, Kenneth J. Ciuﬀreda, Arkady Selenow, and Steven R. Ali.
Dynamic interactions of eye and head movements when reading with
single-vision and progressive lenses in a simulated computer-based
environment. Investigative Ophthalmology and Visual Science, 44
(4):1534–1545, 4 2003. ISSN 01460404. doi: 10.1167/iovs.02-
0507. URL http://iovs.arvojournals.org/article.aspx?doi=10.1167/
iovs.02-0507.

Sergio Barbero and María del Mar González. Admissible surfaces in
progressive addition lenses. Optics Letters, 45(20), 10 2020. ISSN
0146-9592. doi: 10.1364/OL.401927.

Tim Head, Manoj Kumar, Holger Nahrstaedt, Gilles Louppe, and
Iaroslav Shcherbatyi. scikit-optimize/scikit-optimize, 9 2020. URL
https://doi.org/10.5281/zenodo.4014775.

Sergio Barbero and Javier Portilla. Geometrical interpretation of
dioptric blurring and magniﬁcation in ophthalmic lenses. Op-
tics Express, 23(10):13185, 5 2015.
doi:
10.1364/oe.23.013185.

ISSN 1094-4087.

Benjamin Bengfort and Rebecca Bilbro. Yellowbrick: Visualizing
the Scikit-Learn Model Selection Process. Journal of Open Source
Software, 4(35):1075, 3 2019. ISSN 2475-9066. doi: 10.21105/
joss.01075.

Jeewanand Bist, Dinesh Kaphle, Sanjay Marasini, and Himal Kandel.
Spectacle non-tolerance in clinical practice – a systematic review
with meta-analysis. Ophthalmic and Physiological Optics, 41(3):
610–622, 5 2021. ISSN 0275-5408. doi: 10.1111/opo.12796.

Stephen C. Cannon, R. John Leigh, David S. Zee, and Larry A.
Abel. The Eﬀect of the Rotational Magniﬁcation of Corrective
Spectacles on the Quantitative Evaluation of the VOR. Acta Oto-
Laryngologica, 100(1-2):81–88, 1 1985.
ISSN 0001-6489. doi:
10.3109/00016488509108591.

Natalie Hutchings, Elizabeth L. Irving, Nadine Jung, Lisa M. Dowling,
and Kelly A. Wells. Eye and head movement alterations in naïve
progressive addition lens wearers. Ophthalmic and Physiological
Optics, 27(2):142–153, 3 2007. ISSN 02755408. doi: 10.1111/j.
1475-1313.2006.00460.x.

Scott M Lundberg and Su-In Lee. A Uniﬁed Approach to Interpreting
Model Predictions. In I Guyon, U Von Luxburg, S Bengio, H Wal-
lach, R Fergus, S Vishwanathan, and R Garnett, editors, Advances in
Neural Information Processing Systems, volume 30. Curran Asso-
ciates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/
ﬁle/8a20a8621978632d76c43dfd28b67767-Paper.pdf.

Bernard F. Maitenaz. Ophthalmic lenses with a progressively varying

focal power, 1969.

G. Minkwitz. Über den Flächenastigmatismus Bei Gewissen Sym-
metrischen Asphären. Optica Acta: International Journal of Optics,
10(3):223–227, 7 1963. ISSN 0030-3909. doi: 10.1080/713817794.
URL https://www.tandfonline.com/doi/full/10.1080/713817794.

Tsz Tai Chan, Yixuan Wang, Richard Hau Yue So, and Jerry Jia.
Predicting Subjective Discomfort Associated with Lens Distortion
in VR Headsets During Vestibulo-Ocular Response to VR Scenes.
IEEE Transactions on Visualization and Computer Graphics, pages
1–1, 2022. ISSN 1077-2626. doi: 10.1109/TVCG.2022.3168190.

Kees Mulder, Irene Klugkist, Daan van Renswoude, and Ingmar Visser.
Mixtures of peaked power Batschelet distributions for circular data
with application to saccade directions. Journal of Mathematical
Psychology, 95:102309, 4 2020. ISSN 00222496. doi: 10.1016/j.
jmp.2019.102309.

10

Kees Tim Mulder. Bayesian Circular Statistics: von Mises-based
solutions for practical problems. PhD thesis, Utrecht University, 6
2019.

Kenneth Neil Ogle and Saunders W.B. Researches in binocular vision.
W.B .Saunders, Philadelphia, 1950. URL https://books.google.de/
books?id=PykEAQAAIAAJ.

Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent
Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Pe-
ter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas,
Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu
Perrot, and Edouard Duchesnay. Scikit-learn: Machine Learning in
Python. Journal of Machine Learning Research, 12(85):2825–2830,
2011. URL http://jmlr.org/papers/v12/pedregosa11a.html.

Augustin Georges Poullain and Darius Henri Julien Cornet. Op-
lens., 7 1911. URL https://patents.google.com/patent/

tical
US1143316A/en?oq=U.S.+Patent+No.+1%2C143%2C316.

Katharina Rifai, Selam W. Habtegiorgis, Caroline Erlenwein, and
Siegfried Wahl. Motion-form interaction: Motion and form afteref-
fects induced by distorted static natural scenes. Journal of Vision,
20(13):10, 12 2020. ISSN 1534-7362. doi: 10.1167/jov.20.13.10.

Yannick Sauer, Siegfried Wahl, and Katharina Rifai. Parallel Adapta-
tion to Spatially Distinct Distortions. Frontiers in Psychology, 11,
11 2020. ISSN 1664-1078. doi: 10.3389/fpsyg.2020.544867.

Yannick Sauer, Alexandra Sipatchin, Siegfried Wahl, and Miguel
García García. Assessment of consumer VR-headsets’ objective
and subjective ﬁeld of view (FoV) and its feasibility for visual
ﬁeld testing. Virtual Reality, 1 2022.
ISSN 1359-4338. doi:
10.1007/s10055-021-00619-x. URL https://link.springer.com/10.
1007/s10055-021-00619-x.

L. Sawides, S. Marcos, S. Ravikumar, L. Thibos, A. Bradley, and
M. Webster. Adaptation to astigmatic blur. Journal of Vision, 10
(12):22–22, 10 2010. ISSN 1534-7362. doi: 10.1167/10.12.22.
URL http://jov.arvojournals.org/Article.aspx?doi=10.1167/10.12.
22.

Colin M. Sullivan and Colin W. Fowler. Progressive addition and
veriables focus lenses: A review. Ophthalmic and Physiological
Optics, 8(4):402–414, 10 1988. ISSN 0275-5408. doi: 10.1111/j.
1475-1313.1988.tb01177.x. URL https://onlinelibrary.wiley.com/
doi/10.1111/j.1475-1313.1988.tb01177.x.

The European Parliament and the Council of the European Union.
Regulation (EU) 2016/679 of the European Parliament and of the
Council. Oﬃcial Journal of the European Union, 59(L119/1), 2016.

Ralf van der Lans, Michel Wedel, and Rik Pieters. Deﬁning eye-ﬁxation
sequences across individuals and tasks:
the Binocular-Individual
Threshold (BIT) algorithm. Behavior Research Methods, 43(1):
239–257, 3 2011.
ISSN 1554-3528. doi: 10.3758/s13428-010-
0031-2.

Maria Vinas, Lucie Sawides, Pablo de Gracia, and Susana Marcos.
Perceptual Adaptation to the Correction of Natural Astigmatism.
PLoS ONE, 7(9):e46361, 9 2012. ISSN 1932-6203. doi: 10.1371/
journal.pone.0046361. URL http://dx.plos.org/10.1371/journal.
pone.0046361.

D. Volk and J. W. Weinberg. The Omnifocal Lens for Presbyopia.
Archives of Ophthalmology, 68(6):776–784, 12 1962. ISSN 0003-
9950. doi: 10.1001/archopht.1962.00960030780012.

11

