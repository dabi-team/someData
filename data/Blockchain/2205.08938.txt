SplitBFT: Improving Byzantine Fault Tolerance Safety Using
Trusted Compartments
Markus Horst Becker
TU Braunschweig, Germany

Ines Messadi
TU Braunschweig, Germany

Kai Bleeke
TU Braunschweig, Germany

Leander Jehl‚àó
University of Stavanger, Norway

Sonia Ben Mokhtar
LIRIS-CNRS, France

R√ºdiger Kapitza
TU Braunschweig, Germany

2
2
0
2

y
a
M
4
2

]

C
D
.
s
c
[

2
v
8
3
9
8
0
.
5
0
2
2
:
v
i
X
r
a

ABSTRACT
Byzantine fault-tolerant agreement (BFT) in a partially synchronous
system usually requires 3ùëì + 1 nodes to tolerate ùëì faulty replicas.
Due to their high throughput and finality property BFT algorithms
build the core of recent permissioned blockchains. As a complex and
resource-demanding infrastructure, multiple cloud providers have
started offering Blockchain-as-a-Service. This eases the deployment
of permissioned blockchains but places the cloud provider in a
central controlling position, thereby questioning blockchains‚Äô fault
tolerance and decentralization properties and their underlying BFT
algorithm.

This paper presents SplitBFT, a new way to utilize trusted execu-
tion technology (TEEs), such as Intel SGX, to harden the safety and
confidentiality guarantees of BFT systems thereby strengthening
the trust in could-based deployments of permissioned blockchains.
Deviating from standard assumptions, SplitBFT acknowledges that
code protected by trusted execution may fail. We address this by
splitting and isolating the core logic of BFT protocols into multi-
ple compartments resulting in a more resilient architecture. We
apply SplitBFT to the traditional practical byzantine fault toler-
ance algorithm (PBFT) and evaluate it using SGX. Our results show
that SplitBFT adds only a reasonable overhead compared to the
non-compartmentalized variant.

KEYWORDS
Byzantine Fault Tolerance, Intel SGX, Safety

1 INTRODUCTION
Byzantine Fault Tolerance (BFT) agreement algorithms are designed
to tolerate arbitrary failures in distributed systems [16, 40]. Over
the years, they have been extended to become faster [32, 33], flexi-
ble [5, 45], resource-efficient [9, 35], and in many more ways. Re-
cently, they started receiving increasing attention as they order
transactions at the heart of many blockchain infrastructures [3, 8].
Blockchains were initially focused on exchanging digital curren-
cies in a trustless, decentralized manner. Yet, their purpose broad-
ened to enable secure transactions of all kinds, e.g., supply chains,
NFT marketplaces, secure sharing of medical data [23, 25, 39]. Be-
cause setting up a blockchain infrastructure for such purposes is a
non-trivial effort, several companies (e.g., cloud providers such as
Microsoft Azure [12] and Amazon AWS [2]) launched Blockchain-
as-a-Service (BaaS) to spread their blockchain solution while pro-
viding the underlying infrastructure. Specifically, they offer public
open (also called permissionless) blockchains for use cases in which

‚àóWork done while at TU Braunschweig - Germany

users can participate unrestrictedly and permissioned blockchains
for more sensitive use cases that require a restricted access control
list, that allows only authorized participants.

However, having a central blockchain service provider contra-
dicts one of the pillars that made the success of blockchains, i.e., de-
centralized governance, and it partly jeopardizes the fault model of
the utilized BFT algorithm. Indeed, the BaaS provider does not only
become a single point of failure, possibly harming the blockchain
service availability, but it also requires strong trust in the provider
and his personnel regarding the integrity and confidentiality of the
hosted blockchain.

For conventional applications, recent Trusted Execution Envi-
ronments (TEE) remedy the trust issues in terms of integrity and
confidentiality of the cloud, as these environments provide an iso-
lated and shielded execution, protecting applications even from
local privileged attackers [26]. Today, TEEs (e.g., Intel Software
Guard Extension) are readily available in cloud infrastructures, and
several applications have been extended for its use [24].

TEEs have already been identified as a technical means to im-
prove the performance and resource-efficiency of BFT in conven-
tional data center settings [9, 35, 58]. However, for these systems,
the main idea is to address equivocation based on a hybrid fault
model [9, 35, 58], where malicious replicas send conflicting mes-
sages during agreement. In these models, a fraction of the codebase
is shielded by trusted execution that is assumed to fail only by
crashing and by definition, cannot be subject to Byzantine faults.
While introducing trusted execution for BFT, such as in the hybrid
fault model, can be beneficial, it does not address the integrity and
confidentiality issues of current BaaS-based solutions where the
cloud provider has the central control over the infrastructure.

This paper introduces SplitBFT, a TEE-tailored BFT architecture
enabling a more trustworthy implementation of BaaS. Specifically,
SplitBFT introduces an agreement protocol‚Äôs fine-grained, TEE-
based compartmentalization. Splitting a BFT protocol into TEE-
enabled compartments improves resilience and confidentiality and
eases the implementation of diversity.

We illustrate SplitBFT by compartmentalizing Practical Byzan-
tine Fault Tolerance (PBFT). Using our solution, PBFT is decom-
posed into three independent compartments guarded by trusted
execution. The separation follows a careful analysis enforcing that
individual steps in the protocol are secured by a quorum decision
that makes these steps independent of each other. Based on this
approach, the resilience of SplitBFT goes beyond traditional BFT
protocols in terms of integrity by tolerating ùëì Byzantine faults of a
particular compartment type. In terms of confidentiality, the service
tolerates Byzantine faults as long as a specific type of compartment

 
 
 
 
 
 
Conference‚Äô17, July 2017, Washington, DC, USA

Messadi et al.

that hosts the service is correct. Also SplitBFT contributes to easing
the diversity as it limits the code base that has to be diversified at
the level of the BFT protocol implementation to preserve integrity.
Orthogonal to these improvements, SplitBFT ensures availability
if not more than ùëì nodes are faulty.

We implemented SplitBFT as a Rust-based framework that offers
a compartmentalized version of PBFT and utilizes Intel Software
Guard Extensions (SGX) as a trusted execution technology. How-
ever, SplitBFT is a generic approach to compartmentalizing BFT
protocols that is neither limited to PBFT nor SGX. We evaluate
SplitBFT in a cloud setting with two use cases: (i) the replication
of a trusted key/value store and (ii) as an ordering service for a
blockchain application. Both use cases show moderate overhead
compared to a plain use of PBFT, which instead offers weaker in-
tegrity, no confidentiality protection, and is harder to diversify.
In summary, this paper makes the following contributions:

‚Ä¢ Compartmentalized BFT. We present the first approach
towards a multi-compartment paradigm for BFT applications
using SGX enclaves and show how a compartmentalized
system that uses multiple enclaves can improve safety and
preserve integrity with more than ùëì adversaries. We also
propose principles that similar BFT protocols can apply.
‚Ä¢ Diversity of Replicas. We ease the diversity using multiple
compartments that share no common code to minimize the
number of shared vulnerabilities among enclaves. Further-
more, in our model, enclaves can fail independently.

‚Ä¢ Cloud-tailored BFT. We propose a confidentiality-enhanced
BFT protocol tailored for consortium blockchain in a cloud
setting. We present an extensive experimental evaluation
of our system in scenarios with up to 150 clients using two
applications; a key-value store and a distributed ledger.

2 TOWARDS A FINE-GRAINED

PARTITIONING OF BFT PROTOCOLS

The crux of BFT Protocols. BFT spanned years of academic re-
search but noticeably gained renewed interest due to its relevance in
permissioned blockchains where nodes must be authorized [3, 65],
including more recent cases of Blockchain-as-a-Service [2, 12]
where a cloud provider hosts the entire blockchain infrastructure
for its customers. In a nutshell, a BFT consensus typically runs
between nodes assuming a broad spectrum of faults, covering ar-
bitrary and malicious behavior. Thus, they are employed to allow
cooperation between participants that do not trust each other or
in scenarios where individual replicas may be subject to unpre-
dicted faults or outside attacks. The fault model of BFT systems
is extensive and comes at a high cost: typically, at most ùëì < ùëõ/3
out of ùëõ replicas can be faulty. This differs from systems focused
on crash failures, where ùëì < ùëõ/2 can be tolerated. Accordingly,
when deploying a BFT system, it is essential to consider failure
assumptions. Especially, common failures that may happen on all
replicas must be prevented. We argue that for cloud applications,
like BaaS, BFT‚Äôs basic fault model is hard to maintain, considering
the higher likelihood of an attacker or a rogue administrator that
controls more than a third of the nodes. Furthermore, traditional
BFT designs assume no confidentiality, an essential ingredient for
cloud users and sensitive blockchain applications.

TEE in BFT. Security threats in cloud infrastructure motivated
the use of CPU extensions that support trusted execution (TEEs) in
various applications, including BFT [4, 36]. BFT protocols leverage
Intel SGX as it allows trusted applications with small TCB and for
its maturity and availability in commodity hardware compared to
its predecessor TEEs [9, 58]. Intel SGX‚Äôs isolated execution environ-
ments are known as enclaves, a hardware-protected and encrypted
memory. It offers strong integrity and confidentiality protection
from the underlying OS. A fundamental property of SGX is cre-
ating multiple separate enclaves on one CPU. Thus, it gives three
opportunities for BFT protocols:

ùëú1

ùëú2

Integrity-protection. it allows to guard the integrity of state
and code loaded into the enclave from faults and adversaries
in the environment of the replica;
Inter-enclave protection. it safeguards code in one enclave
from failures in a different enclave and;

ùëú3 Confidentiality. it protects the confidentiality of the data in
the enclave from failures and attackers outside that enclave.

Clement et al. [19] have shown that, relying on ùëú1 , ùëì replica
failures can be tolerated using only 2ùëì + 1 replicas. They require the
use of digital signatures and a TEE that may only fail by crashing.
So-called hybrid systems [9, 35] use a minimal trusted subsystem,
e.g., a trusted counter, to implement this design. However, like tra-
ditional BFT protocols, hybrid systems lose safety and liveness if
an attacker gains access to more than ùëì replicas or if an enclave
within any replica acts maliciously or deviates from the protocol.
Specifically, while secure, SGX enclaves are susceptible to attacks,
significantly when increasing the TCB. The application code itself
may include bugs and memory corruption that leads to vulnerabili-
ties and security vulnerabilities (e.g., synchronization bugs [60]).
Most applications that rely on SGX use the memory-unsafe C/C++
because of the C-based interfaces of the SGX SDK. In this mat-
ter, the SGX hardware gives no memory-safety guarantees for the
software running in the enclave. Using Rust as a memory-safe al-
ternative improves application code safety, but it is not entirely
safe from memory corruption errors [22]. In hybrid approaches, a
single byzantine fault, e.g., a bug or successful attack breaching the
trusted subsystem, puts safety at risk.

SplitBFT. Unlike hybrid protocols, we do not aim to use TEEs to
reduce BFT protocols‚Äô overhead but rather to increase BFT resilience
by enforcing safety despite more complex failure scenarios. We
exploit Opportunity ùëú1 to guarantee safety despite an attacker
being present on all machines. To achieve this, we place both the
core BFT logic and the execution of client requests into the trusted
environment.

Further, we do assume that enclaves can fail and become byzan-
tine, i.e., enclaves can equivocate. SplitBFT design tolerates any ùëì
enclaves failing. To further increase reliability, we aim for a small
TCB. Especially, using Opportunity ùëú2 , we separate the complex
protocol logic located at each replica into multiple independent
compartments, each run in a different enclave. This allows us to
even tolerate faults in more than ùëì individual enclaves, given that
these happen in enclaves of different compartment types. Figure 1
shows our compartmentalization of the PBFT algorithm. With four
replicas, safety is ensured, even if one enclave of each type is faulty.

SplitBFT: Improving Byzantine Fault Tolerance Safety Using Trusted Compartments

Conference‚Äô17, July 2017, Washington, DC, USA

Work

PBFT [16]
Hybrid Protocols [9, 35]
SplitBFT

# Replicas TEE

Liveness

Enclave
-
3ùëì + 1
0
2ùëì + 1
3ùëì + 1
ùëìùëùùëüùëíùëù ‚àß ùëìùëêùëúùëõùëì ‚àß ùëìùëíùë•ùëíùëê
Table 1: Comparison of fault models in BFT systems.

‚úó
‚úì
‚úì

ùëì
ùëì
ùëì

Faulty
TEE
-
‚úó
‚úì

Integrity

Host
ùëì
ùëì
ùëõ

Confidentiality
Enclave Host

-
0
0ùëíùë•ùëíùëê

0
0
ùëõ

Diversification. As mentioned, traditional BFT systems need
to avoid common failures of multiple replicas. Typically, this is
achieved by diversifying the replicas‚Äô environment. Diversity is not
trivial due to the complexity of implementations and the wide range
of employed techniques and libraries. The most common approach
is to use different and diverse OSs [31]. However, diversifying the
implementation remains a tedious and error-prone task, especially
when unsafe languages such as C are susceptible to memory errors,
e.g., buffer overflows. SplitBFT‚Äôs fault model enables a more ac-
cessible approach that diversifies only a fraction of the codebase,
namely the code running inside the different enclaves. The use
of compartments further simplifies diversification; only common
failures in the same compartment need to be avoided.

2.1 System Assumptions
We use a similar networking model as presented in the traditional
BFT state machine replication model [16, 64]. However, the goal
is to tolerate many simultaneous replica faults under pre-defined
timing and threshold assumptions. The network is unreliable and
may discard, reorder, and delay messages but not indefinitely to
guarantee liveness. Safety guarantees do not depend on timing or
crash failures.

ùëñ , ùëê2

Modeling SplitBFT. The system consists of a set of clients C and
a set of replicas Œ† = {ùëü1, ùëü 2, ..., ùëüùëõ }. We deviate from classical BFT
assumptions by not treating a replica as a unit of failure. Instead, we
assume that a replica ùëüùëñ contains multiple compartments (enclaves)
ùê∂ = {ùëê1
ùëñ , ...} and an environment ùëíùëñ such as ùëüùëñ = ùê∂ ‚à™ ùëíùëñ . Both
the environment and compartments may fail arbitrarily. Thus, a
faulty or byzantine compartment may omit or delay operations,
perform arbitrary steps and lie to other compartments. We note
that a fault in the environment may render the compartments in
that replica unavailable. The environment may fail independently
of the compartments, while compartments, whether part of the
same or different replicas, fail independently. However, we assume
that once a compartment (e.g., ùëê1
ùëñ ) is faulty, the environment ùë¢ùëñ
is considered to be faulty (e.g., faulty compartments corrupt the
environment)

We consider multiple compartment types, and every replica
contains one compartment of each type. Compartments of the
same type contain the same logic. Figure 1 shows the 3 types in
our adaptation of PBFT, namely Preparation, Confirmation, and
Execution compartments. In the remainder of this paper, we use the
term enclave to denote a compartment part of a specific replica. On
the other hand, we use the term compartment to indicate the code
or logic executed by all enclaves of a given compartment type.

An attacker may simultaneously compromise the ùëõ machines,
manipulating separate compartments but not multiple enclaves of

Figure 1: Compartmentalized PBFT with four nodes. Using
SplitBFT, failures indicated in red, in different compart-
ments and on multiple replicas can be tolerated.

Finally, we encrypt client requests and responses and only de-
crypt them inside the enclave. Thus, we utilize Opportunity ùëú3
to ensure confidentiality despite an attacker present on one of the
replicas, as long as enclaves are fault-free. In our PBFT variant from
Figure 1, confidentiality is maintained as long as all enclaves of
type Execution are correct.

In Table 1, we compare SplitBFT to previous plain BFT protocols
such as PBFT and prevailing TEE-based BFT protocols, i.e., hybrid
protocols. SplitBFT follows traditional BFT protocols liveness-wise;
however, it enhances resilience. Our design guarantees safety de-
spite ùëõ powerful attackers. In other words, an attacker on each
replica host, which is not the case for hybrid protocols and PBFT
that can only tolerate up to ùëì byzantine attacks. SplitBFT also
tolerates faulty enclaves. Enclaves belong to different compartment
types, and ùëì enclaves belonging to each compartment type may fail.
In summary, SplitBFT guarantees safety in cases where PBFT and
hybrid protocols do not. SplitBFT separates liveness from safety
and tries to ensure safety even when liveness may be lost. Violating
safety provides the attacker gains, such as double-spending attacks
or clients receiving inconsistent replies but violating liveness does
not. Losing liveness means progress happens only at the disposal
of Byzantine replicas but may still happen or be regained later.

Finally, we target confidentiality of client requests, a property
that is important in a cloud setting. In SplitBFT, the client‚Äôs requests
and the application state remain confidential despite an attacker
corrupting the environment on one or multiple machines.

  ClientsConfirmationPreparationExecutionReplica 1ConfirmationPreparationExecutionReplica 0ConfirmationPreparationExecutionReplica 2ConfirmationPreparationExecutionReplica 3Conference‚Äô17, July 2017, Washington, DC, USA

Messadi et al.

the same type. Still, the risk of compromising similar compartments
is somewhat reduced by using diverse enclaves environments (e.g.,
various programming languages), therefore reducing common vul-
nerabilities. We assume Intel SGX enclaves implementation and
standard cryptographic operations are correct. Still, the developer
code may include programming errors/bugs (e.g., buffer overflow)
that can lead to arbitrary enclave behavior if exploited. We ex-
clude side-channels on TEEs [14, 17, 37, 50, 54, 60] from our threat
model, but mitigations or microcode updates can be applied to
SplitBFT [48, 53]. We assume that each enclave has a public and
private key pair and that private keys of correct enclaves cannot be
derived by either the environment or other enclaves on the same
replica. In addition, clients are authorized and identified through
public keys.

3 BFT-CENTRIC PARTITIONING
In this section, we address the question: How to identify fitting units
for different compartments that fail independently? We first present
several principles that guide decisions about what data and logic
should be placed into individual compartments. We then apply our
reasoning to the traditional PBFT protocol.

3.1 Partitioning Principles
SplitBFT is a customizable approach to designing a multi-enclave
BFT architecture. By compartmentalizing safety-sensitive function-
alities, we can build a BFT system with improved security and
robustness. The core argument is that this allows us to contain
failures within one compartment while the other compartments re-
main intact even when located on the same replica. Intel SGX offers
this possibility of partitioning a single program into an untrusted
environment and multiple secure enclaves and is noticeably char-
acterized by a small TCB compared to other TEEs. In the following,
we propose the principles ùëÉ1 - ùëÉ5 that can guide decisions on
how to separate a BFT protocol into an environment and multiple
compartments:

ùëÉ1 Place only safety-critical state and logic into the en-
clave. SplitBFT should maintain safety, even if an attacker is
present in the environment of every replica. Thus, all safety-related
logic and state needs to be placed inside an enclave. If an attacker
has compromised the environment, liveness of code running in an
enclave cannot be guaranteed. Therefore, logic that is only relevant
for liveness should stay in the untrusted environment. The sepa-
ration of liveness results in a reduced TCB and can thus increase
the resilience. Typically, protocol logic must stay in the enclave,
while timers, network handling, buffering, static variables, and the
output log can remain in the untrusted environment.

ùëÉ2 Event handlers as decision units. BFT protocols, as most
distributed algorithms are event-driven. They are formulated as a
set of event handlers. An event handler is a function invoked on
a timeout or the receipt of a message. Event handlers manipulate
shared state and may again trigger new messages to be sent. Event
handlers should run until completion in a single compartment.
Indeed, splitting one event handler into multiple compartments
favors complex dependencies that may lead to dependent failures.
Also, entering/exiting multiple enclaves during one event handler

may be detrimental to performance. Placing an event handler into
a compartment imposes that different enclaves communicate via
authenticated messages, as is done between various replicas.

ùëÉ3 Place event handlers that access the same state into one
compartment. We restrict the shared state accessed by different
compartments to global and static configurations. To achieve this,
event handlers that operate on the same state should be placed in
the same compartment.

We note that a naive application of this principle may easily
require all event handlers to be placed in a single enclave. A more
fine-grained design requires carefully separating the data structures
used by the algorithm. Another possible solution is to duplicate the
state and maintain it separately in multiple compartment. However,
duplication may lead the system to deviate from the original speci-
fication and result in a safety violation (e.g., state divergence). In
the case of data structure such as a log of messages, if two compart-
ments rely on each other‚Äôs messages to trigger an event, one could
intentionally omit or withhold messages.

ùëÉ4 Place event handlers including similar logic into one
compartment. Sometimes, event handlers do not share state but
execute the same or similar logic. Duplicating such logic in multiple
compartments may also duplicate vulnerabilities. We therefore
suggest placing these event handlers into one compartment.

ùëÉ5 Place compartment transitions on quorum decisions.
When handling individual messages, a faulty sender may easily
influence the receiver. For that reason, BFT protocols typically
collect messages from multiple senders and only act upon receiving
a super-majority (quorum) of matching messages. These quorum
of messages are ideal for compartment transitions since the failure
of individual senders cannot corrupt the receiving compartment.

3.2 SplitBFT Principles Applied to PBFT
In the following, we first give some background on the PBFT algo-
rithm and especially the state maintained by the algorithm. We then
discuss how we identify safety critical variables and how we parti-
tion event handlers into multiple compartments applying Principles
ùëÉ1 to ùëÉ5 .

Preliminaries. PBFT is regarded as the baseline for almost all
published BFT protocols [21, 32, 38, 64]. The consensus procedures
of PBFT can be described as follows: the agreement is a three-phase
protocol with one designated sender process, the primary associ-
ated with a ùë£ùëñùëíùë§, decides on the total order of clients‚Äô requests
in a PrePrepare message. All other replicas coordinate through
broadcasting Prepare messages to validate the primary proposal.
Finally, all replicas agree on the total order of requests after receiv-
ing a quorum of Commit messages. These steps are repeated while
increasing sequence numbers to order additional requests. Each
replica maintains a copy of an application, e.g., a blockchain. PBFT
uses the ordered requests as input in the execution stage, executes
clients‚Äô operations, and sends replies. In the case of a blockchain,
this execution may entail the creation of a new block. PBFT guar-
antees two properties: Safety and liveness. Safety implies clients
receive correct (linearizable) replies. Liveness ensures that they
eventually receive replies, given that the network does not delay
messages indefinitely. Replicas use timers to detect a faulty primary

SplitBFT: Improving Byzantine Fault Tolerance Safety Using Trusted Compartments

Conference‚Äô17, July 2017, Washington, DC, USA

and trigger the view-change sub-protocol. Upon agreement of 2ùëì +1
replicas, the system moves to a new view with a new, dedicated
primary. PBFT discards requests already executed using the check-
pointing sub-protocol to prevent the log of messages from growing
indefinitely. Periodically, replicas obtain proof that their state is
correct by collecting a certificate of 2ùëì + 1 Checkpoint messages
with the same digest and sequence number. In doing so, they can
safely remove old entries from the log.

PBFT State. According to Principle ùëÉ3 , we need to place not
only logic but also state into different compartments. We base our
partitioning on the PBFT pseudocode [15], where each replica is
modeled as an I/O automaton. According to the algorithm, each
replica maintains two message logs, ùëñùëõ and ùëúùë¢ùë°, a few variables,
and an instance of the application state. The log ùëñùëõ contains re-
ceived messages and some sent messages that are later needed to
validate pre-conditions. The ùëúùë¢ùë° contains messages that should be
sent. For variables, we ignore values that can be derived from the
input log. For example, the low watermark, a variable marking for
which sequence numbers messages have been garbage collected,
can be derived from Checkpoint messages in the log ùëñùëõ. Similarly,
we ignore configuration parameters that stay constant throughout
execution and assume they can be safely loaded into enclaves. Ex-
amples of such parameters are ùëõ, the total number of replicas, and
public and private keys.

Local variables are mostly related to the execution of requests,
e.g. sequence numbers for the last request executed from each client.
Most relevant for the agreement procedure is the view variable, a
number used to identify the current primary and ignore all messages
sent under previous primaries, i.e. in an earlier view.

Splitting safety and liveness. Following ùëÉ1 , we start by sepa-
rating the state into safety-critical variables that should go into
the trusted context from liveness variables that may remain in the
untrusted environment. Following the replica automaton model
in PBFT, we argue that the core safety-critical variables consist
of the application state and variables related to request execution,
the view, and the input log. We consider the input log ùëñùëõ as safety-
relevant since even an omission from that log may result in faulty
behavior. For example, the omission of sent messages may result in
re-sent messages with diverging data, also known as ùëéùëöùëõùëíùë†ùëñùëé [7].
Hence, it is easier to protect the integrity of the log ùëñùëõ through the
enclave memory than to repeatedly verify the authentication of the
included messages. Contrarily, the ùëúùë¢ùë° log remains untrusted as it
is only relevant to liveness. The same applies to timers and network
connections. Message authentication (i.e., signatures) happens in
the enclave before messages are added to the ùëúùë¢ùë° log. Besides con-
nection handling, we also place the batching of requests into the
untrusted environment.

Compartments. Following the principles ùëÉ1 to ùëÉ5 , we partition

the PBFT protocol into three compartments:

‚Ä¢ Preparation Compartment: Receives client requests and ini-

tializes its order distribution

‚Ä¢ Confirmation Compartment: Confirms that a request was

prepared by a quorum

‚Ä¢ Execution Compartment: Collects a quorum of confirmations,
executes authenticated requests and sends back the replies
to the clients. As this enclave holds the application state, it
is also responsible for generating checkpoints.

Figure 2 shows the normal operation, view change, and check-
pointing subprotocols of PBFT. The responsibilities of different
compartments are highlighted in different colors.

Separating event handlers. Following Principle ùëÉ2 , we separate
the event handlers from the PBFT algorithm into three compart-
ments, the Preparation, Confirmation, and Execution Compartment.
Figure 2 shows the different event handlers in the PBFT algorithm.
Event handler (1) is triggered when receiving a batch of requests
from the environment and starts the normal operation. Event han-
dlers (5) and (8) are triggered through timeouts and start the view-
change or checkpointing procedure, respectively. The remaining
event handlers are executed every time a respective message is
received.

Following principle ùëÉ3 , event handlers accessing the same state
should be placed in the same compartment. However, a naive ap-
plication of ùëÉ3 would result in a single compartment. Indeed, all
the identified message handlers need access to the input log ùëñùëõ to
receive a message; each handler accesses different messages from ùëñùëõ.
We eliminate this dependency by separating this log into multiple
logs containing one message type.

For event handlers (1)-(4) involved in normal operation, we
apply Principle ùëÉ5 and split them according to quorum decisions.
We note that no quorum decision happens between event han-
dlers (1) and (2). Indeed, the Prepare and prepare messages are
used together to form a quorum decision in message handler (3).
Thus, if both the enclave sending a PrePrepare, and ùëì enclaves
of the compartment sending Prepare messages are faulty, safety
may be violated. Placing these into one compartment makes this
dependency clear.

One problem with this splitting is that PrePrepare messages
are accessed both by message handlers (2) and (3). Colocating (2)
and (3) would violate ùëÉ5 . We therefore duplicate PrePrepares in
the input log of the Preparation and Confirmation Compartment,
to avoid shared state ( ùëÉ3 ). We also duplicate PrePrepares in
the input of the Execution Compartment. Thus, the requests are
forwarded to this compartment, even if Commit messages only
contain a hash of that request.

For the checkpointing subprotocol, we note that a checkpoint
message includes a snapshot of the application state. As the applica-
tion state is already needed to execute client requests in the event
handler (4), we place the sending of checkpoint messages (8) with
(4) in the Execution compartment, following ùëÉ3 .

Finally, the message handler of Checkpoint messages (9) ac-
cesses all input logs and deletes old messages. We therefore opt to
duplicate this handler in different compartments. Following ùëÉ2
each of the duplicates runs independently without dependencies
between the different compartments. While this forgoes ùëÉ4 and
clearly creates additional performance overhead, we argue that this
is acceptable since Checkpoints are only performed periodically
and lie outside the critical path.

Conference‚Äô17, July 2017, Washington, DC, USA

Messadi et al.

ùê∂

ùëü1

ùëü2

ùëü3

ùëü4

Reqest

PrePrepare

Prepare

Commit

Reply

ViewChange

NewView

Checkpoint

1

3

3

3

3

4

4

4

4

2

2

2

5

5

5

5

6

6

6

6

7

7‚Ä≤

7‚Ä≤

7‚Ä≤

7‚Ä≤

7

7‚Ä≤

7‚Ä≤

7

7‚Ä≤

7‚Ä≤

8

8

8

8

9

9

9

9

9

9

9

9

9

9

9

9

normal operation

view-change

checkpoint

Preparation Compartment

Confirmation Compartment

Execution Compartment

Figure 2: PBFT protocol phases and separation of event handlers into compartments. Event handlers are numbered for refer-
ence in the text.

Regarding the view change, we first note that a ViewChange
includes received Prepare and PrePrepare messages. Following
ùëÉ3 the sending of ViewChange (5) is co-located with the sending
of Commit messages (3) in the confirmation enclave. For the han-
dling of NewView messages, we note that these messages serve
two purposes. First, the NewView contains a checkpoint, applied
similar to the checkpointing subprotocol. We extract this function-
ality as event handler (7‚Äô) and duplicate it over all compartments,
similar to the handling of checkpoints.

Additional to the checkpoints, a NewView message contains
PrePrepares, which results in the sending of Prepare messages.
Following Principle ùëÉ4 , we place the sending (6) and receiving (7)
of the NewView in the Preparation compartment, together with
the sending and receiving of PrePrepare (1,2).

One remaining issue is the view variable, which all event han-
dlers use to avoid processing and sending messages belonging to
an outdated view. To avoid merging all event handlers into a single
compartment, we instead replicate the view variable. As in PBFT,
the view variable is updated when sending a ViewChange mes-
sage (5), or when receiving a valid NewView message (7, 7‚Äô). Thus,
together with the checkpoints in a NewView message, we update
the view in all compartments.

4 SPLITBFT
In this section, we answer the question of how to maintain correct-
ness when splitting an algorithm. We first give a detailed description
of our split variant of PBFT. We then argue why it maintains cor-
rectness and report on our effort to verify this correctness formally.

SplitBFT Workflow. We now show a request execution workflow
with further details and explain how our design prevents enclaves
from tricking each other and ensures correctness and safety.

1) Client requests: Clients are identified with a pair of keys a ùëùùëòùëñ ,
and ùë†ùëòùëñ . Additionally, each enclave has an individual key pair. We
assume public keys are known to all participants. At the start of
the service, the client first attests to the execution and prepara-
tion enclave verifying their genuineness and SGX support. When

the attestation is successful, the client provides the execution en-
clave with a session key ùë†ùëíùëõùëê to encrypt requests and preserve their
confidentiality from the untrusted environment and the rest of
the enclaves. The encrypted requests are then signed for authen-
tication. When clients submit corrupted operations, the Execution
Compartment will detect this and execute a no-op instead.

2) Ordering protocol: The Preparation enclave on the primary
replica authenticates the request, assigns it a sequence number and
then stores it in its input log ùëñùëõùëùùëüùëíùëù . After checking the correct-
ness of the request, the preparation enclave creates a PrePrepare
message, signs it using its private key, and then pushes it into the
output log. Preparation enclaves on the backups receive the PrePre-
pare message, verify its correctness, and create and sign a Prepare
messages. PrePrepares are also forwarded to the Confirmation
Compartment.

The Confirmation Compartment waits for a Prepare certificate
containing one PrePrepare and 2ùëì matching Prepare messages
from different enclaves of type Preparation Compartment. Then
each Confirmation enclave creates and signs a Commit. Finally, the
Execution Compartment waits for a quorum of Commits. Since
Commit may only include a hash of the request, the Execution also
receives PrePrepares containing the full request. It then executes
requests and sends replies to the clients.

Following ùëÉ5 , we note that in the above, an enclave does not
react to a single message from a different compartment, but only
reacts to a certificate of 2ùëì +1 messages. This ensures that failures in
individual enclaves cannot affect other compartments and protects
the quorum certificate from any unanticipated changes.

3) Garbage collection: Each compartment keeps a separate pri-
vate log and executes checkpoints. The Checkpoint message origi-
nates from the Execution Compartment, which holds the application
state. Each compartment erases old message upon receiving 2ùëì + 1
Checkpoints. Compartments keep the Checkpoints and discard
messages for sequence numbers before the checkpoint, even if they
are received later.

4) View-change: As in PBFT, our replicas set a timer on receiving
a request from a client. If this timer expires before the request is
executed, replicas suspect the primary to be faulty. These timers

SplitBFT: Improving Byzantine Fault Tolerance Safety Using Trusted Compartments

Conference‚Äô17, July 2017, Washington, DC, USA

are managed by the environment but upon suspicion, the Confirma-
tion Compartment sends the ViewChange message. This message
contains a certificate of 2ùëì + 1 Checkpoints and all Prepare certifi-
cates from ùëñùëõùëêùëúùëõùëì . Upon sending this ViewChange, a Confirmation
enclave increases its view. Thus, it will no longer process Prepares
or send commits in the old view. The Preparation Compartment
receives the ViewChange messages, validates them, and sends a
NewView.

The NewView in PBFT has three important functions. First,
it updates the view and primary on all replicas, second, it dis-
tributes a checkpoint, and third, it allows the new primary to
resend PrePrepares for requests that have been assigned a se-
quence numbers in the previous view, but are not included in the
checkpoint yet. The new primary needs to create PrePrepare mes-
sages for the NewView based on the Prepare certificates included
in ViewChanges. This logic is complex and it is repeated when
validating the NewView in the Preparation Compartment. The Con-
firmation and Execution Compartments also receive the NewView
but do not validate the PrePrepares included. They only validate
and apply the checkpoint and update their view number, if they did
not yet do so.

Correctness. We first argue informally why our splitting of PBFT
is correct. We then report on our formal verification. We need to ar-
gue that our split protocol maintains both liveness and safety if, on
2ùëì + 1 replicas, both the environment and all enclaves are correct. If
the environment of a replica is correct, PrePrepare, Checkpoint,
and NewViews are forwarded to all compartments at the same
time. A replica in SplitBFT thus behaves like a replica in PBFT.
Safety and liveness follow from the respective properties in PBFT.
There is one corner case, namely that a NewView that contains
false PrePrepares but is otherwise correct will be accepted by the
Confirmation and Execution Compartment, but not by the Prepara-
tion Compartment. In this case, the replica may send Commits in
the new view but will not send Prepares. We note that a prepare
certificate containing 2ùëì Prepare and one PrePrepare message is
still needed to send a commit. Thus, safety is guaranteed.

Furthermore, we have to argue that our compartmentalized ver-
sion of PBFT does maintain safety as long as 2ùëì + 1 enclaves from
each compartment-type are correct. In this case, messages may
arrive selectively or reordered at the different compartments. Re-
garding checkpoints, we note that receiving Checkpoint messages
in a different order gives the same result. A replica only handles
messages in a fixed window of sequence numbers above the last
checkpoint. Thus, the replica may not respond to messages in higher
sequence numbers after omitting a checkpoint. This does not en-
danger safety.

In case the Preparation Compartment at the primary is faulty, a
replica may receive two different PrePrepares and forward them
once to the Preparation and once to the Confirmation enclave. How-
ever, if 2ùëì + 1 Preparation enclaves are correct, no two replicas can
receive different Prepare certificates. Therefore, safety still holds.
Finally, given a faulty environment, the Preparation enclave may
process a PrePrepare and send a Prepare after the Confirmation
enclave has sent a ViewChange. If that additional Prepare is
used in a Prepare certificate triggering a Commit on some replica,
then this replica will include the certificate in its ViewChange.

Otherwise, it remains without effect. BFT protocols are known for
their complexity, and some previous protocols are known to contain
faults [1, 11]. We formally verify that SplitBFT does maintain safety
under the complex conditions stated above. To do that, we proved
safety using the Ivy verification tool [47]. Ivy is a tool that can
verify safety proofs for parametrized models. This gives better
confidence in correctness than finite model checkers like TLA+ that
only verify the model for fixed parameters and suffer from state
explosion. Since no synchronization between different enclaves
on one replica can be ensured in case of a faulty environment, we
modeled the different enclaves as individual nodes in our proof.
For deriving the proof, we adjusted an existing proof of PBFT [57].
This derivation was surprisingly straightforward and only required
minor adjustments to the proof. This gives us additional confidence
that our model is correct.1

Discussions and Extensions
Further Compartmentalization. PBFT is not the only fault-tolerant
protocol that can be compartmentalized. The principles and ideas
we show apply to other BFT protocols, including streamlined vari-
ants such as the recent Hotstuff protocol [65]. Besides, the applica-
tion included in our execution enclave may significantly increase
the TCB for certain use cases. In such cases, further compartmental-
ization may be applied by (i) separating the application in its own
enclave and (ii) a more fine-grained partitioning of the application,
e.g., applying sharding techniques [29].

Enclave recovery. When enclaves are identified to either be cor-
rupted by a memory leak or fail by crashing, we consider rebooting
the single affected component. Enclaves that possibly store data
persistently, e.g., the execution or application enclave, can use the
SGX sealing technique for uniquely encrypting the enclave secrets
and securely recovering them when rebooting. An important issue
is rollback and forking attacks. In this case, the malicious server
can return a correctly checked outdated state or create multiple
instances of an enclave. To detect these attacks, previous works use
trusted time or monotonic counter and can be integrated into our
design as a defensive technique [6, 13].

Denial-of-service and performance attacks. Note that an enclave is
subject to sudden crashes triggered due to a compromised environ-
ment. In addition, an exploited enclave could remain unresponsive
to messages or delay executing an operation that breaks the pro-
tocol liveness or slows down the execution. Clients can also harm
the performance by consistently sending corrupted operations that
will be ordered but ignored during execution. This is no different
from a client sending unnecessary but correctly formed requests
and can be addressed by rate limiting. Alternatively, the execution
enclave can intercept client requests and apply an access control
check preventing the ordering of corrupted requests.

Contribution Above PBFT. We show how PBFT can be separated
into three independent compartments while maintaining overall
correctness. This separation increases resilience, and especially
ensures safety despite failures on all machines and in a fraction of
the enclaves. We also prevent cases where enclaves may consciously
break safety, e.g., by duplicating the log entries when necessary.

1Formal models are available online: https://github.com/leandernikolaus/splitbft-
proofs.

Conference‚Äô17, July 2017, Washington, DC, USA

Messadi et al.

Shared
types

2430
2430
2430

Logic

487
458
579

Total
LOC

2917
2888
3009
12565
439

Binary
Size (MB)

1.1
1.1
1.2
‚Äî
0.524

Preparation Enc.
Confirmation Enc.
Execution Enc.
Untrusted Env.
Trusted Counter

Table 2: TCB sizes for all enclaves

The separation is also relevant for performance. Since components
are independent, they can be executed in parallel without the need
for synchronization.

5 IMPLEMENTATION
We implement SplitBFT on top of Themis a Rust-based implemen-
tation of PBFT [51] ( using the nightly-2021-02-17).

Trusted enclaves. Enclaves are responsible for preserving the
integrity of the pre-selected variables or functions and the confi-
dentiality of requests and replies. Our initial implementation uses
Intel SGX due to its availability, the minimal TCB, and support for
multiple TEEs. Intel SGX implements enclaves that use an isolated
reserved part of the DRAM called Enclave Page Cache (EPC), en-
crypted and authenticated by the CPU. Two Intel SGX SDKs are
available implemented in Rust and C/C++. Our implementation
uses the rust SDK Teaclave v1.1.3 [34]. To avoid synchronization
primitives inside enclaves, we only allow a single thread to execute
in each enclave.

The SDK defines calls between the enclave and the outside world
that are part of the application logic. An ecall into the enclave or an
ocall into the untrusted side. An essential practice when enclavising
an application is minimizing the performance overhead that comes
from these transitions (‚âà 8,640 cycles [61]).

To digitally sign enclave messages, we use the implementation
of 256-bit ED25519 from the ring library v0.16.20 [55]. For authen-
ticating client requests and replies, we use the HMAC-SHA2 function.
Untrusted broker. The untrusted host environment holds a shim
layer or a broker where enclaves register. The broker is responsible
for handling I/O for the enclaves. For sending messages or requiring
an I/O operation, enclave handlers request it from the broker by
posting ocalls into its queue. Likewise, the broker intercepts incom-
ing messages and sends them to the corresponding enclave using
ecalls. The calls into the trusted environment are multi-threaded,
i.e., each enclave is associated with a thread that triggers ecalls.
The broker expects the data that it needs to send over the network
serialized using serde 2. This layer can be compromised, causing
liveness issues or denial of service by not handling events, dropping
messages, or communicating the wrong timer to the concerned en-
claves. However, confidentiality and integrity are not affected as
attempts to tamper with the data are detected.

Analysis. As there is a correlation between the amount of code
and the likelihood of vulnerabilities or defects, we analyze our soft-
ware in terms of lines of code (using the tokei utility) and enclave

2https://serde.rs/

size. We show the code that executes within each enclave and the
untrusted infrastructure. Table 2 shows the resulting LOC. The
table shows separate line numbers for the type definitions and data
structures used in all enclaves and the logic unique to the enclave.
While the Teaclave SGX SDK, serde, and ring dependencies are in-
cluded in the TCB, they are not included in the numbers presented.
The untrusted line consists of the broker layer, the communication
handling between replicas, and networking (i.e., sockets). For com-
parison, we also report the LOC of a Rust implementation of the
trusted counter, as used in hybrid systems. The execution enclave
code mostly depends on the application and how the developer
decides to engineer it. In our case, the LOC of the execution enclave
includes the key-value store. While these numbers do not reveal
the complexity of the implementation, it gives us an impression of
the TCB. Indeed, we show that individual enclaves are significantly
smaller than a complete application. An attacker who targets a
non-split application has a larger attacker surface to explore than a
split BFT application.

6 EVALUATION
We evaluated SplitBFT to get an answer to the following questions:

‚Ä¢ What is the overhead of SplitBFT compared to a common

PBFT implementation?

‚Ä¢ How does SplitBFT perform with realistic applications?
‚Ä¢ What is the overhead of the SGX enclaves?

Experimental Setup. We deploy SplitBFT on a cluster of four
SGX-enabled Azure VMs Standard DC4s_v2 (4 vcpus, 16 GiB mem-
ory), each equipped with an Intel Xeon E-2288G CPU comprising
four cores running at 3.7 GHz without HyperThreading connected
via 40 Gb switched Ethernet and 16 GB of memory. The software
environment of the machines includes a Linux Ubuntu 18.04 with
kernel 5.4.0-1074-azure and the Intel SGX SDK in version 2.16. A
VM machine Standard_D8s_v3 (8 vcpus) is dedicated to running
the client implementation that generates the workload. The VMs
are all located in the same region West Europe.

Configuration and baseline. We chose PBFT as a general baseline
to evaluate the performance of SplitBFT with batching and with-
out batching using a payload of 10 bytes and reply size of 10 bytes.
SplitBFT uses a dedicated thread for each enclave, which performs
ecalls, and an additional thread running the event loop. We config-
ure PBFT to use a pool of 4 worker threads using the work stealing
thread pool from the tokio library. Instead, SplitBFT uses regular
OS threads that are more suited for the enclaves development.

As SplitBFT, our PBFT implementation uses HMACs to authen-
ticate client requests and responses but signatures for messages
between replicas. In our PBFT implementation, networking and
message authentication are parallelized, but the core protocol is
not. We target two custom applications as use-cases: a key-value
store and a blockchain. Clients constantly issue synchronous re-
quests in all our measurements and measure the time it takes to
collect the replies. We report the latency and throughput based
on these measurements and save the average of five runs. The
blockchain application creates blocks of five messages in the exe-
cution enclave and writes them using an ocall into the untrusted
memory to be stored and encrypted persistently. For that, we use

SplitBFT: Improving Byzantine Fault Tolerance Safety Using Trusted Compartments

Conference‚Äô17, July 2017, Washington, DC, USA

(a) Not Batched

(b) Batched

Figure 3: Throughput (ops/s) and latency (ms) for SplitBFT and PBFT without batching and with 200 batches using two appli-
cations: a blockchain and a key-value store (KVS).

Figure 4: Average latency for ecalls done during the process-
ing of one request/batch in different compartments for 40
clients. Measurements are taken on the leader using the KVS
application.

the sgx_tprotected_fs crate that allows secure I/O operations.
Our throughput and latency measurements evaluate a PUT oper-
ation that updates the entries. To better understand the overhead
introduced by SplitBFT we also measured the latency for different
ecalls done on our enclaves. Our evaluation shows that multithread-
ing significantly reduces the overhead of SplitBFT and that the
overhead due to enclave transitions can be amortized over request
batches.

Throughput and Latency Without Batching. Figure 3 (a) shows
the throughput and latency without batching. We see that SplitBFT
reaches about 43%-74% of the throughput of PBFT for the key-value
store and 38%-59% for the blockchain application. The key-value
store application performs up to 33% better than the blockchain
application due to the additional I/O operation and encryption
when writing a block persistently.

Compared to the baseline, SplitBFT adds performance overhead
due to many reasons, including: (i) enclave transitions, (ii) data
copying in and out of enclaves, and (iii) added serialization and
de-serialization of protocol messages and client requests. From the
results, we observe that measuring SplitBFT with a single thread
performing all ecalls reduces the performance significantly. To
better understand the overhead, we evaluate SplitBFT running
enclaves in simulation mode. As the simulation mode omits costly
enclave transitions, results suggest that (i) enclave transitions cause
20% of the overhead. To further analyze the overhead, we measure
execution times of the ecalls performed in different enclaves during
normal request processing. Figure 4 shows the average time spent
in different enclaves during the processing of one request. All ecalls
sum up to 841 ùúás. Thus, if a single thread is performing all ecalls,
a maximum throughput of ‚âà1190 rps could be reached. Without
batching, ecalls to the Execution compartment have the longest

020406080100120140Number of clients10002000300040005000Throughput(ops/s)SplitBFT KVSPBFT KVSSplitBFT KVS SimulationSplitBFT KVS Single ThreadSplitBFT BlockchainPBFT Blockchain020406080100120140Number of clients101102103Latency (ms)020406080100120140Number of clients050000100000150000200000250000Throughput(ops/s)020406080100120140Number of clients0255075100125150175Latency (ms)00.20.40.60.811.21.41.61.82BatchedNotBatchedLatency(ms)PreparationCommitExecutionConference‚Äô17, July 2017, Washington, DC, USA

Messadi et al.

latency, with a total of 343ùúás. In multithreaded SplitBFT, a single
thread performs all ecalls to the Execution compartment. This thread
thus cannot process more than 2900rps. We see that the throughput
in Figure (a) comes close to these theoretical upper limits. Thus, the
overhead for unbatched SplitBFT is due to ecalls to the Execution
compartment. The added overhead in the blockchain application is
also located in the Execution compartment and therefore effects the
overall throughput.

Throughput and Latency With Batching. Figure 3 (b) show results
for SplitBFT and PBFT, when client requests are processed as
batches. This experiment allows each client to have 40 outstanding
requests in parallel. In both systems, we create batches on either
receiving 200 requests or expiration of a 10ms timeout. The results
show that SplitBFT reaches ‚âà 64% the throughput of PBFT for the
key-value store and 55% for the blockchain application. SplitBFT
key-value store performs better than the blockchain application
with up to a 4.6√ó more throughput. Indeed, the execution enclave
performs one ocall for each block (5 requests), while in the case of
the key-value store, we only perform one ocall on executing each
batch.

From Figure 4, we see that the ecalls to the Preparation and Ex-
ecution compartment are significantly longer now. Ecalls to the
Confirmation compartment are similar to the unbatched mode since
this compartment only handles a hash of the request batch. Here,
ecalls to the Preparation compartment are the longest. These ecalls
give a theoretical upper limit of ‚âà 227k operation per second. The
long ecalls compared to the non batched mode are due to the au-
thentication verification of a batch of client requests instead of a
single request and the copy in/out of the enclave. For the Execu-
tion, requests need to be un-marshaled and executed. Responses
need to be authenticated and copied out of the enclave. The last is
also a good example of how enclaves add additional overhead. All
responses are collected, marshaled, and passed out of the enclave
to avoid multiple enclave transitions (ocalls). The collection then
needs to be split and sent to individual clients. On the other hand,
in PBFT, marshaling and authentication of different responses are
performed concurrently by all threads.

7 RELATED WORK

Using TEEs on BFT protocols and Blockchains. A number of BFT
systems explored the use of TEEs to isolate a small fraction of
the system functionality thereby establishing a hybrid fault model,
where the protected part is excluded from the Byzantine fault as-
sumption and can only fail by crashing [9, 35, 43, 58]. In particular,
they aim at reducing the degree of replication by achieving non-
equivocation. Clement et al. [19] show that non-equivocation is
not enough to decrease the number of required replicas unless it is
coupled with transferable authentication.

MinBFT [58], CheapBFT [35] and Hybster [9] assume a trusted
subsystem where replicas sign messages using a monotonic counter
to address equivocation and thus reduce the fault requirement
to 2ùëì + 1. Damysus [27] addresses the case of streamlined BFT
protocols such as HotStuff, proposing two trusted services that
improve the resilience and reduce the communication rounds as
in Hybrid protocols. These services record additional information
relevant to blocks to guarantee nodes cannot lie about the last

prepared blocks. Recent Avocado places a crash tolerant replica
into a TEE, to tolerate ensure confidentiality and integrity despite
an attacker present on all nodes, but assumes that TEEs remain
correct.

Fairy [56] leverages TEEs as a layer on top of an ordering service
to add fairness when executing client‚Äôs requests. Troxy [41] uses a
TEE to intercept client requests and replies as a proxy layer, result-
ing in removing the client-side library functionality and making
the use of BFT transparent while improving performance. However,
these hybrid protocols as well as the work of Clement et al. assume
achieving equivocation entails the TEE only fails by crashing, an
assumption that comes with a high confidence in the protected
code, especially with increased TCB. A recent line of research aims
to leverage the security guarantees of TEEs in blockchain and BFT.
CCF [52] implements a consortium-based blockchain, assumes that
TEE can deviate from the utilized protocol. Therefore, the services
record enough signed evidence to attribute the TEE. Ekiden [18]
uses TEE-backed smart contracts to preserve confidentiality in
blockchain applications.

Another line of Blockchain and cryptocurrency solutions [10, 59]
rely on Zero-knowledge proof as an encryption scheme to protect
their users‚Äô privacy which is application-specific and requires a
large amount of computation power.

Separating Execution Replica. Previous research focused on the
separation of the responsibility of execution replicas [18, 64]. Yin
et al. [64] give a system that runs the agreement and execution on
separate clusters, preventing execution replicas from leaking confi-
dentiality through a privacy firewall. This also brings the benefit
of reducing the number of execution replicas. Other works such as
Spare [30], TwinBFT [28] rely on separation using virtualization,
facilitating recovery, or as a trusted separate component. Hyper-
ledger Fabric [3] separates the ordering and execution allowing it to
occur in a separate processes which gives performance advantages.

Alternative fault models. Many proposed alternative faults mod-
els to reduce the complexity or require fewer replicas, e.g., XFT [44],
FaB [46], UpRight [20]. These works do not target improving the
resilience to byzantine faults as in SplitBFT and focus mainly on
performance and scalability. UpRight [20] and Visigoth [49] enable
different thresholds for safety and liveness.

Resilience and Robustness. A common goal in BFT research is to
further increase the robustness and the resilience of a protocol, as
preserving the initial fault model seems hard to achieve in practical
scenarios. Flexible BFT [63] aim is to prevent a fraction of faults be-
sides byzantine, assuming an alive-but-corrupt replica, which may
deviate from breaking safety however will not try to break liveness.
BFT2F explores the design space beyond ùëì failures [42]. When no
more than ùëì replicas fail, it preserves the same guarantees as PBFT.
With more than ùëì , it prohibits certain kinds of safety violations.
While these works improves the resilience to some degree, some
rely on certain timing assumptions. Furthermore, none leverage
the security of TEEs to increase the resilience to byzantine faults.

Partitioning. Partitioning applications is not a new concept and
has been explored in different scenarios. Whittaker et al. [62]
presents compartmentalized Paxos to improve the scalability and
performance. It separates the logic of the application based on the

SplitBFT: Improving Byzantine Fault Tolerance Safety Using Trusted Compartments

Conference‚Äô17, July 2017, Washington, DC, USA

identified bottleneck. To our knowledge, SplitBFT is the first pro-
tocol to leverage compartmentalization based on TEEs to increase
resilience.

8 CONCLUSION
SplitBFT introduces compartmentalization based on TEE to Byzan-
tine fault tolerance. While our approach is neutral to the availability
guarantees of BFT, integrity and confidentiality are substantially
strengthened. SplitBFT is especially useful in cloud-based deploy-
ments where resources and availability are the main concerns of
a provider, and the provider can, to some extent, be relieved from
concerns regarding the integrity and confidentiality of the hosted
code and data. This becomes particularly evident in the context
of BaaS, where the central role of the cloud providers contradicts
the decentralization and fault tolerance demands of permission
blockchains. The performed experiments highlight the approach‚Äôs
feasibility but make the additional overhead of switching between
different TEE compartments visible. While SplitBFT exercises the
compartmentalization of PBFT using SGX, the approach can be
transferred to other BFT protocols that feature quorum decisions as
part of the agreement and other trusted execution technology that
enables fine-grained trusted execution preferable at the process
level.

ACKNOWLEDGMENT
We thank our anonymous reviewers for their helpful comments.
This work was supported by the German Research Foundation
(DFG) under grant no. KA 3171/9-1.

REFERENCES
[1] Ittai Abraham, Guy Golan-Gueta, Dahlia Malkhi, Lorenzo Alvisi, Ramakrishna
Kotla, and Jean-Philippe Martin. 2017. Revisiting Fast Practical Byzantine Fault
Tolerance. (2017). https://doi.org/10.48550/arXiv.1712.01367 arXiv:arXiv:hep-
ph/9609357

[2] Amazon. 2022. Amazon Managed Blockchain. Retrieved Mai 9, 2022 from

https://aws.amazon.com/managed-blockchain/

[3] Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin, Konstanti-
nos Christidis, Angelo De Caro, David Enyeart, Christopher Ferris, Gennady
Laventman, Yacov Manevich, Srinivasan Muralidharan, Chet Murthy, Binh
Nguyen, Manish Sethi, Gari Singh, Keith Smith, Alessandro Sorniotti, Chrysoula
Stathakopoulou, Marko Vukoliƒá, Sharon Weed Cocco, and Jason Yellick. 2018. Hy-
perledger Fabric: A Distributed Operating System for Permissioned Blockchains.
In Proceedings of the Thirteenth EuroSys Conference (Porto, Portugal) (EuroSys
‚Äô18). ACM, New York, NY, USA, Article 30, 15 pages. https://doi.org/10.1145/
3190508.3190538

[4] Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andre Martin,
Christian Priebe, Joshua Lind, Divya Muthukumaran, Dan O‚ÄôKeeffe, Mark L.
Stillwell, David Goltzsche, David Eyers, R√ºdiger Kapitza, Peter Pietzuch, and
Christof Fetzer. 2016. SCONE: Secure Linux Containers with Intel SGX. In
Proceedings of the 12th USENIX Conference on Operating Systems Design and
Implementation (Savannah, GA, USA) (OSDI‚Äô16). USENIX Association, USA, 689‚Äì
703.

[5] Jean-Paul Bahsoun, Rachid Guerraoui, and Ali Shoker. 2015. Making BFT Proto-
cols Really Adaptive. In 2015 IEEE International Parallel and Distributed Processing
Symposium. IEEE, Hyderabad, India, 904‚Äì913. https://doi.org/10.1109/IPDPS.
2015.21

[6] Maurice Bailleu, J√∂rg Thalheim, Pramod Bhatotia, Christof Fetzer, Michio Honda,
and Kapil Vaswani. 2019. SPEICHER: Securing LSM-Based Key-Value Stores
Using Shielded Execution. In Proceedings of the 2019 USENIX Conference on Usenix
Annual Technical Conference (Boston, MA, USA) (FAST‚Äô19). USENIX Association,
USA, 173‚Äì190.

[7] Shehar Bano, Alberto Sonnino, Andrey Chursin, Dmitri Perelman, and Dahlia
Malkhi. 2020. Twins: White-Glove Approach for BFT Testing. (2020). https:
//doi.org/10.48550/arXiv.2004.10617 arXiv:arXiv:2004.10617

[8] Mathieu Baudet, Avery Ching, Andrey Chursin, George Danezis, Fran√ßois Garillot,
Zekun Li, Dahlia Malkhi, Oded Naor, Dmitri Perelman, and Alberto Sonnino.

2019. State machine replication in the libra blockchain. The Libra Assn., Tech.
Rep (2019).

[9] Johannes Behl, Tobias Distler, and R√ºdiger Kapitza. 2017. Hybrids on Steroids:
SGX-Based High Performance BFT. In Proceedings of the Twelfth European Con-
ference on Computer Systems (Belgrade, Serbia) (EuroSys ‚Äô17). ACM, New York,
NY, USA, 222‚Äì237. https://doi.org/10.1145/3064176.3064213

[10] Eli Ben Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers,
Eran Tromer, and Madars Virza. 2014. Zerocash: Decentralized Anonymous
Payments from Bitcoin. In 2014 IEEE Symposium on Security and Privacy. IEEE,
San Jose, California, 459‚Äì474. https://doi.org/10.1109/SP.2014.36

[11] Christian Berger, Hans P. Reiser, and Alysson Bessani. 2021. Making Reads in BFT
State Machine Replication Fast, Linearizable, and Live. In 2021 40th International
Symposium on Reliable Distributed Systems (SRDS). IEEE, Chicago, IL, USA, 1‚Äì12.
https://doi.org/10.1109/SRDS53918.2021.00010

[12] Ga√´l Blanchemain. 2018. Azure BaaS. Retrieved July 7, 2021 from https://docs.

nethereum.com/en/latest/azure/set-up-blockchain-on-azure/

[13] Marcus Brandenburger, Christian Cachin, Matthias Lorenz, and R√ºdiger Kapitza.
2017. Rollback and Forking Detection for Trusted Execution Environments Using
Lightweight Collective Memory. In 47th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks, DSN 2017, Denver, CO, USA, June 26-29,
2017. IEEE, Denver, CO, USA, 157‚Äì168. https://doi.org/10.1109/DSN.2017.45
[14] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank
Piessens, Mark Silberstein, Thomas F. Wenisch, Yuval Yarom, and Raoul Strackx.
2018. Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient
Out-of-Order Execution. In 27th USENIX Security Symposium (USENIX Security
18). USENIX Association, Baltimore, MD, 991‚Äì1008. https://www.usenix.org/
conference/usenixsecurity18/presentation/bulck

[15] Miguel Castro. 2001. Practical Byzantine Fault Tolerance. Ph.D. MIT. Also as

Technical Report MIT-LCS-TR-817.

[16] Miguel Castro and Barbara Liskov. 1999. Practical Byzantine Fault Tolerance.
In Proceedings of the Third Symposium on Operating Systems Design and Imple-
mentation (New Orleans, Louisiana, USA) (OSDI ‚Äô99). USENIX Association, USA,
173‚Äì186. https://dl.acm.org/doi/10.5555/296806.296824

[17] Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and
Flavio D. Garcia. 2021. VoltPillager: Hardware-based fault injection attacks
against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th
USENIX Security Symposium (USENIX Security 21). USENIX Association, 699‚Äì716.
https://www.usenix.org/conference/usenixsecurity21/presentation/chen-zitai

[18] Raymond Cheng, Fan Zhang, Jernej Kos, Warren He, Nicholas Hynes, Noah
Johnson, Ari Juels, Andrew Miller, and Dawn Song. 2019. Ekiden: A Platform for
Confidentiality-Preserving, Trustworthy, and Performant Smart Contracts. In
2019 IEEE European Symposium on Security and Privacy (EuroS P). IEEE, Stockholm,
Sweden, 185‚Äì200. https://doi.org/10.1109/EuroSP.2019.00023

[19] Allen Clement, Flavio Junqueira, Aniket Kate, and Rodrigo Rodrigues. 2012. On
the (Limited) Power of Non-Equivocation (PODC ‚Äô12). ACM, New York, NY, USA,
301‚Äì308. https://doi.org/10.1145/2332432.2332490

[20] Allen Clement, Manos Kapritsos, Sangmin Lee, Yang Wang, Lorenzo Alvisi, Mike
Dahlin, and Taylor Riche. 2009. Upright Cluster Services. In Proceedings of the
ACM SIGOPS 22nd Symposium on Operating Systems Principles (Big Sky, Montana,
USA) (SOSP ‚Äô09). ACM, New York, NY, USA, 277‚Äì290. https://doi.org/10.1145/
1629575.1629602

[21] Allen Clement, Edmund Wong, Lorenzo Alvisi, Mike Dahlin, and Mirco Marchetti.
2009. Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults. In
Proceedings of the 6th USENIX Symposium on Networked Systems Design and
Implementation (Boston, Massachusetts) (NSDI‚Äô09). USENIX Association, USA,
153‚Äì168.

[22] Tobias Cloosters, Michael Rodler, and Lucas Davi. 2020. TeeRex: Discovery and Ex-
ploitation of Memory Corruption Vulnerabilities in SGX Enclaves. In 29th USENIX
Security Symposium (USENIX Security 20). USENIX Association, Boston, MA, USA,
841‚Äì858. https://www.usenix.org/conference/usenixsecurity20/presentation/
cloosters

[23] IBM Corp. 2018. Blockchain in retail solutions. Retrieved July 7, 2021 from

https://www.ibm.com/blockchain/industries/retail

[24] Intel Corporation. 2019. Confidential Computing Consortium. Retrieved October
2, 2021 from https://www.intel.com/content/www/us/en/security/confidential-
computing.html

[25] IBM Corporation. 2021. Research leading blockchain use cases. Retrieved Septem-

ber 16, 2021 from https://www.ibm.com/blockchain/use-cases/

[26] Victor Costan and Srinivas Devadas. 2016. Intel sgx explained. IACR Cryptol.

ePrint Arch. 2016, 86 (2016), 1‚Äì118.

[27] J√©r√©mie Decouchant, David Kozhaya, Vincent Rahli, and Jiangshan Yu. 2022.
DAMYSUS: Streamlined BFT Consensus Leveraging Trusted Components. In
Proceedings of the Seventeenth European Conference on Computer Systems (Rennes,
France) (EuroSys ‚Äô22). ACM, New York, NY, USA, 1‚Äì16. https://doi.org/10.1145/
3492321.3519568

[28] Fernando Dettoni, Lau Cheuk Lung, Miguel Correia, and Aldelir Fernando Luiz.
2013. Byzantine fault-tolerant state machine replication with twin virtual ma-
chines. In 2013 IEEE Symposium on Computers and Communications (ISCC). IEEE,

Conference‚Äô17, July 2017, Washington, DC, USA

Messadi et al.

Split, Croatia, 398‚Äì403. https://doi.org/10.1109/ISCC.2013.6754979

[29] Diego Didona and Willy Zwaenepoel. 2019. Size-Aware Sharding for Improving
Tail Latencies in in-Memory Key-Value Stores. In Proceedings of the 16th USENIX
Conference on Networked Systems Design and Implementation (Boston, MA, USA)
(NSDI‚Äô19). USENIX Association, USA, 79‚Äì93.

[30] Tobias Distler, Ivan Popov, Wolfgang Schr√∂der-Preikschat, Hans P Reiser, and
R√ºdiger Kapitza. 2011. SPARE: Replicas on Hold. In Proceedings of the 18th
Network and Distributed System Security Symposium (NDSS ‚Äô11). Internet Society,
San Diego, California, USA, 407‚Äì420.

[31] Miguel Garcia, Alysson Bessani, and Nuno Neves. 2019. Lazarus: Automatic
Management of Diversity in BFT Systems. In Proceedings of the 20th International
Middleware Conference (Davis, CA, USA) (Middleware ‚Äô19). ACM, New York, NY,
USA, 241‚Äì254. https://doi.org/10.1145/3361525.3361550

[32] Guy Golan Gueta, Ittai Abraham, Shelly Grossman, Dahlia Malkhi, Benny Pinkas,
Michael Reiter, Dragos-Adrian Seredinschi, Orr Tamir, and Alin Tomescu. 2019.
SBFT: A Scalable and Decentralized Trust Infrastructure. In 2019 49th Annual
IEEE/IFIP International Conference on Dependable Systems and Networks (DSN).
IEEE, Portland, OR, USA, 568‚Äì580. https://doi.org/10.1109/DSN.2019.00063
[33] Bingyong Guo, Zhenliang Lu, Qiang Tang, Jing Xu, and Zhenfeng Zhang. 2020.
Dumbo: Faster Asynchronous BFT Protocols. ACM, New York, NY, USA, 803‚Äì818.
https://doi.org/10.1145/3372297.3417262

[34] Apache Inc. 2022. Teaclave SGX SDK. https://github.com/apache/incubator-

teaclave-sgx-sdk

[35] R√ºdiger Kapitza, Johannes Behl, Christian Cachin, Tobias Distler, Simon Kuhnle,
Seyed Vahid Mohammadi, Wolfgang Schr√∂der-Preikschat, and Klaus Stengel. 2012.
CheapBFT: Resource-Efficient Byzantine Fault Tolerance. In Proceedings of the 7th
ACM European Conference on Computer Systems (Bern, Switzerland) (EuroSys ‚Äô12).
ACM, New York, NY, USA, 295‚Äì308. https://doi.org/10.1145/2168836.2168866

[36] Taehoon Kim, Joongun Park, Jaewook Woo, Seungheun Jeon, and Jaehyuk Huh.
2019. ShieldStore: Shielded In-Memory Key-Value Storage with SGX. In Proceed-
ings of the Fourteenth EuroSys Conference 2019 (Dresden, Germany) (EuroSys ‚Äô19).
ACM, New York, NY, USA, Article 14, 15 pages. https://doi.org/10.1145/3302424.
3303951

[37] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas,
Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael Schwarz,
and Yuval Yarom. 2019. Spectre Attacks: Exploiting Speculative Execution. In
2019 IEEE Symposium on Security and Privacy (SP). IEEE, San Francisco, CA, USA,
1‚Äì19. https://doi.org/10.1109/SP.2019.00002

[38] Ramakrishna Kotla, Lorenzo Alvisi, Mike Dahlin, Allen Clement, and Edmund
Wong. 2010. Zyzzyva: Speculative Byzantine Fault Tolerance. ACM Trans. Comput.
Syst. 27, 4, Article 7 (jan 2010), 39 pages. https://doi.org/10.1145/1658357.1658358
[39] Tsung-Ting Kuo, Hyeon-Eui Kim, and Lucila Ohno-Machado. 2017. Blockchain
distributed ledger technologies for biomedical and health care applications. Jour-
nal of the American Medical Informatics Association 24, 6 (2017), 1211‚Äì1220.
[40] Leslie Lamport, Robert Shostak, and Marshall Pease. 1982. The Byzantine
Generals Problem. ACM Trans. Program. Lang. Syst. 4, 3 (jul 1982), 382‚Äì401.
https://doi.org/10.1145/357172.357176

[41] Bijun Li, Nico Weichbrodt, Johannes Behl, Pierre-Louis Aublin, Tobias Distler, and
R√ºdiger Kapitza. 2018. Troxy: Transparent Access to Byzantine Fault-Tolerant
Systems. In 2018 48th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks (DSN). IEEE, Luxembourg, Luxembourg, 59‚Äì70. https:
//doi.org/10.1109/DSN.2018.00019

[42] Jinyuan Li and David Mazi√©res. 2007. Beyond One-Third Faulty Replicas in
Byzantine Fault Tolerant Systems. In Proceedings of the 4th USENIX Conference on
Networked Systems Design Implementation (Cambridge, MA) (NSDI‚Äô07). USENIX
Association, USA, 10.

[43] Jian Liu, Wenting Li, Ghassan O. Karame, and N. Asokan. 2019. Scalable Byzantine
IEEE Trans. Comput. 68, 1

Consensus via Hardware-Assisted Secret Sharing.
(2019), 139‚Äì151. https://doi.org/10.1109/TC.2018.2860009

[44] Shengyun Liu, Paolo Viotti, Christian Cachin, Vivien Quema, and Marko Vukoliƒá.
2016. XFT: Practical Fault Tolerance beyond Crashes. In 12th USENIX Symposium
on Operating Systems Design and Implementation (OSDI 16). USENIX Association,
Savannah, GA, 485‚Äì500. https://www.usenix.org/conference/osdi16/technical-
sessions/presentation/liu

[45] Dahlia Malkhi, Kartik Nayak, and Ling Ren. 2019. Flexible Byzantine Fault
Tolerance. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security (London, United Kingdom) (CCS ‚Äô19). ACM, New York,
NY, USA, 1041‚Äì1053. https://doi.org/10.1145/3319535.3354225

[46] J.-P. Martin and L. Alvisi. 2005. Fast Byzantine consensus. In 2005 International
Conference on Dependable Systems and Networks (DSN‚Äô05). IEEE, Yokohama, Japan,
402‚Äì411. https://doi.org/10.1109/DSN.2005.48

[47] Kenneth L. McMillan and Oded Padon. 2020. Ivy: A Multi-Modal Verification Tool
for Distributed Algorithms. In Computer Aided Verification: 32nd International
Conference, CAV 2020, Los Angeles, CA, USA, July 21‚Äì24, 2020, Proceedings, Part
II (Los Angeles, CA, USA). Springer-Verlag, Berlin, Heidelberg, 190‚Äì202. https:
//doi.org/10.1007/978-3-030-53291-8_12

[48] Oleksii Oleksenko, Bohdan Trach, Robert Krahn, Andre Martin, Christof Fetzer,
and Mark Silberstein. 2018. Varys: Protecting SGX Enclaves from Practical Side-
Channel Attacks. In Proceedings of the 2018 USENIX Conference on Usenix Annual
Technical Conference (Boston, MA, USA) (USENIX ATC ‚Äô18). USENIX Association,
USA, 227‚Äì239.

[49] Daniel Porto, Jo√£o Leit√£o, Cheng Li, Allen Clement, Aniket Kate, Flavio Junqueira,
and Rodrigo Rodrigues. 2015. Visigoth Fault Tolerance. In Proceedings of the Tenth
European Conference on Computer Systems (Bordeaux, France) (EuroSys ‚Äô15). ACM,
New York, NY, USA, Article 8, 14 pages. https://doi.org/10.1145/2741948.2741979
[50] Ivan Puddu, Moritz Schneider, Miro Haller, and Srdjan Capkun. 2021. Frontal
Attack: Leaking Control-Flow in SGX via the CPU Frontend. In 30th USENIX
Security Symposium (USENIX Security 21). USENIX Association, 663‚Äì680. https:
//www.usenix.org/conference/usenixsecurity21/presentation/puddu

[51] Signe R√ºsch, Kai Bleeke, and R√ºdiger Kapitza. 2019. Themis: An Efficient and
Memory-Safe BFT Framework in Rust: Research Statement. In Proceedings of
the 3rd Workshop on Scalable and Resilient Infrastructures for Distributed Ledgers
(Davis, CA, USA) (SERIAL ‚Äô19). ACM, New York, NY, USA, 9‚Äì10. https://doi.org/
10.1145/3366611.3368144

[52] Mark Russinovich, Edward Ashton, Christine Avanessians, Miguel Castro,
Amaury Chamayou, Sylvan Clebsch, Manuel Costa, C√©dric Fournet, Matthew
Kerner, Sid Krishna, Julien Maffre, Thomas Moscibroda, Kartik Nayak, Olya
Ohrimenko, Felix Schuster, Roy Schwartz, Alex Shamis, Olga Vrousgou,
and Christoph M. Wintersteiger. 2019.
CCF: A Framework for Building
Confidential Verifiable Replicated Services. Technical Report MSR-TR-2019-
16. Microsoft. https://www.microsoft.com/en-us/research/publication/ccf-a-
framework-for-building-confidential-verifiable-replicated-services/

[53] Jaebaek Seo, Byoungyoung Lee, Seong Min Kim, Ming-Wei Shih, Insik Shin,
Dongsu Han, and Taesoo Kim. 2017. SGX-Shield: Enabling Address Space Layout
Randomization for SGX Programs. In NDSS. Internet Society, San Diego, CA
USA.

[54] Ming-Wei Shih, Sangho Lee, Taesoo Kim, and Marcus Peinado. 2017. T-SGX:
Eradicating Controlled-Channel Attacks Against Enclave Programs. In Network
and Distributed System Security Symposium 2017 (NDSS‚Äô17) (network and dis-
tributed system security symposium 2017 (ndss‚Äô17) ed.). Internet Society, San
Diego, CA USA. https://www.microsoft.com/en-us/research/publication/t-sgx-
eradicating-controlled-channel-attacks-enclave-programs/

[55] Brian Smith. 2022. ring. https://github.com/briansmith/ring
[56] Chrysoula Stathakopoulou, Signe R√ºsch, Marcus Brandenburger, and Marko
Vukoliƒá. 2021. Adding Fairness to Order: Preventing Front-Running Attacks
in BFT Protocols using TEEs. In 2021 40th International Symposium on Reliable
Distributed Systems (SRDS). IEEE, Chicago, IL, USA, 34‚Äì45. https://doi.org/10.
1109/SRDS53918.2021.00013

[57] Marcelo Taube, Giuliano Losa, Kenneth L. McMillan, Oded Padon, Mooly Sa-
giv, Sharon Shoham, James R.Wilcox, and Doug Woos. 2018. Modularity for
Decidability of Deductive Verification with Applications to Distributed Systems.
https://doi.org/10.5281/zenodo.2577103

[58] Giuliana Santos Veronese, Miguel Correia, Alysson Neves Bessani, Lau Cheuk
Lung, and Paulo Verissimo. 2011. Efficient byzantine fault-tolerance. IEEE Trans.
Comput. 62, 1 (2011), 16‚Äì30.

[59] Zhipeng Wang, Stefanos Chaliasos, Kaihua Qin, Liyi Zhou, Lifeng Gao, Pascal
Berrang, Ben Livshits, and Arthur Gervais. 2022. On How Zero-Knowledge Proof
Blockchain Mixers Improve, and Worsen User Privacy. https://doi.org/10.48550/
ARXIV.2201.09035

[60] Nico Weichbrodt, Anil Kurmus, Peter Pietzuch, and R√ºdiger Kapitza. 2016. Async-
Shock: Exploiting Synchronisation Bugs in Intel SGX Enclaves. In Computer
Security ‚Äì ESORICS 2016, Ioannis Askoxylakis, Sotiris Ioannidis, Sokratis Katsikas,
and Catherine Meadows (Eds.). Springer, Cham, 440‚Äì457.

[61] Ofir Weisse, Valeria Bertacco, and Todd Austin. 2017. Regaining Lost Cycles
with HotCalls: A Fast Interface for SGX Secure Enclaves. In Proceedings of the
44th Annual International Symposium on Computer Architecture (Toronto, ON,
Canada) (ISCA ‚Äô17). ACM, New York, NY, USA, 81‚Äì93. https://doi.org/10.1145/
3079856.3080208

[62] Michael Whittaker, Ailidani Ailijiang, Aleksey Charapko, Murat Demirbas, Neil
Giridharan, Joseph M. Hellerstein, Heidi Howard, Ion Stoica, and Adriana Szek-
eres. 2021. Scaling Replicated State Machines with Compartmentalization. Proc.
VLDB Endow. 14, 11 (jul 2021), 2203‚Äì2215. https://doi.org/10.14778/3476249.
3476273

[63] Zhuolun Xiang, Dahlia Malkhi, Kartik Nayak, and Ling Ren. 2021. Strengthened
Fault Tolerance in Byzantine Fault Tolerant Replication. In 2021 IEEE 41st Inter-
national Conference on Distributed Computing Systems (ICDCS). IEEE, DC, USA,
205‚Äì215. https://doi.org/10.1109/ICDCS51616.2021.00028

[64] Jian Yin, Jean-Philippe Martin, Arun Venkataramani, Lorenzo Alvisi, and Mike
Dahlin. 2003. Separating Agreement from Execution for Byzantine Fault Tolerant
Services. SIGOPS Oper. Syst. Rev. 37, 5 (oct 2003), 253‚Äì267. https://doi.org/10.
1145/1165389.945470

[65] Maofan Yin, Dahlia Malkhi, Michael K. Reiter, Guy Golan Gueta, and Ittai Abra-
ham. 2019. HotStuff: BFT Consensus with Linearity and Responsiveness. In

SplitBFT: Improving Byzantine Fault Tolerance Safety Using Trusted Compartments

Conference‚Äô17, July 2017, Washington, DC, USA

Proceedings of the 2019 ACM Symposium on Principles of Distributed Comput-
ing (Toronto ON, Canada) (PODC ‚Äô19). ACM, New York, NY, USA, 347‚Äì356.
https://doi.org/10.1145/3293611.3331591

