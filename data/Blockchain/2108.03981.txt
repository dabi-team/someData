Digital Communications and Networks(DCN)

journal homepage: www.elsevier.com/locate/dcan

A Credibility-aware Swarm-Federated Deep Learning
Framework in Internet of Vehicles

Zhe Wanga, Xinhang Lia, Tianhao Wu∗a, Chen Xua, Lin Zhangba

aSchool of Artiﬁcial Intellegence, Beijing University of Posts and Telecommunications, Beijing 100876, China
bBeijing Information Science and Technology University, Beijing 100096, China

Abstract

Federated Deep Learning (FDL) is helping to realize distributed machine learning in the Internet of Vehicles (IoV). However,
FDL’s global model needs multiple clients to upload learning model parameters, thus still existing unavoidable communica-
tion overhead and data privacy risks. The recently proposed Swarm Learning (SL) provides a decentralized machine-learning
approach uniting edge computing and blockchain-based coordination without the need for a central coordinator. This paper pro-
poses a Swarm-Federated Deep Learning framework in the IoV system (IoV-SFDL) that integrates SL into the FDL framework.
The IoV-SFDL organizes vehicles to generate local SL models with adjacent vehicles based on the blockchain empowered SL,
then aggregates the global FDL model among diﬀerent SL groups with a proposed credibility weights prediction algorithm.
Extensive experimental results demonstrate that compared with the baseline frameworks, the proposed IoV-SFDL framework
achieves a 16.72% reduction in edge-to-global communication overhead while improving about 5.02% in model performance
with the same training iterations.

© 2021 Published by Elsevier Ltd.

KEYWORDS:
Swarm Learning, Federated Deep Learning, Internet of Vehicles, Privacy, Eﬃciency

1. Introduction

With new computing and communication technolo-
gies coming up, the communication network’s rapid
development provides the possibility for advanced
vehicular services and applications [1], such as au-
tonomous driving and content delivery. In this context,
the Internet of Vehicles (IoV), as a combination of
the Internet of Things (IoT) and Vehicular networks,
has gained considerable attention from industry and
academia. Some works in [2–4] have shown that
compared with data centralized in traditional machine
learning (ML), Federated Deep Learning (FDL) solves
privacy concerns and reduces the cost of data trans-
mission by distributing the training work to clients.
Clients keep their data locally and send the model pa-
rameters to a central server for model aggregation[5].
In this way, FDL provides a parallel scheme to learn
the global model cooperatively and protect data pri-
vacy [6].

∗Corresponding Author. Email: shogun2015@hotmail.com

As for the FDL application in the IoV, it demands
the eﬃciency of information exchanging about vehi-
cle statuses and road conditions while protecting data
privacy [7]. Scholars have made several communi-
cation eﬃciency improvements and achieved sound
performance in IoV scenarios. For instance, [8] pro-
posed a Federated-Learning-Based Cooperative Posi-
tioning Scheme (FedVCP) to fully utilize the poten-
tial of collaborative edge computing while protect-
[9] proposed a
ing data privacy in the IoV system.
novel Federated Learning-based framework for Plate
Recognition (FedLPR) to identify traﬃc signs and
participants in low latency and consumption while
keeping pace with preserving data privacy. [10] pro-
posed a two-timescale federated Deep Reinforcement
Learning(DRL)-based algorithm to help obtain robust
models in the IoV scenarios.

[11] integrated homomorphic cryptography into
parking space searching and booking for communi-
cation security.
[12] designed a data collection and
pre-processing scheme based on deep learning, reduc-

1
2
0
2

g
u
A
9

]

Y
S
.
s
s
e
e
[

1
v
1
8
9
3
0
.
8
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
2

Zhe Wang, et al.

Figure 1. An overview of the proposed IoV-SFDL framework. (1) Vehicles in the end-client layer form an SL group according to the relative
distance and task type, update the latest global model in the group issued by Road Side Unit (RSU), collect surrounding information with
onboard sensors, and train the model. (2) The vehicles in the SL group connect through blockchain and aggregate group model in the SL
process. (3) RSU nodes at the edge-server layer receive the model from SL groups and predict the weights according to group size and model
credibility. (4) RSU nodes upload model parameters and weights to the central server. (5) The central server generates a global model by
aggregating models from SL groups with diﬀerent weights, and distributes the global model to the edge server for subsequent updates. After
several iterations, the ﬁnal model with good performance is obtained.

ing the amount of data uploaded to the cloud and ef-
fectively protecting the data privacy in the IoV sys-
tem. Blockchain technology has been applied to IoV
for data privacy in recent years as a newly emerg-
ing technology. For instance, [13] created a local
Blockchain for real-world event message exchange
among vehicles within the boundary of the country,
and [14] proposed a DRL and blockchain-empowered
Spatial Crowd-sourcing System (DB-SCS). [15] de-
veloped a hybrid blockchain architecture that consists
of the permission blockchain and the local Directed
Acyclic Graph to relieve transmission load and ad-
dress privacy concerns of data providers.

Based on blockchain technology and FDL, The
authors in [16] introduced Swarm Learning (SL)
and achieved outstanding performance in the medical
ﬁeld. The SL framework dispenses with a dedicated
server, shares the parameters via the Swarm network,
and builds the models independently on private data
at the individual sites. However, all the above works
don’t consider vehicles’ mobility, unreliable commu-
nication connection, and a highly dynamic driving en-
vironment. These factors will bring some new chal-
lenges for FDL and blockchain applications in the IoV
including overcoming the model’s ineﬀec-
system,
tive and communication ineﬃciency caused by clients
(such as malicious and redundant sharing parameters)
and ensuring clients’ privacy security from the third
party in the process of data transmission [17].

This paper addresses these issues by proposing a
Swarm-Federated Deep Learning framework in the
IoV system (IoV-SFDL) with a credibility weights
prediction algorithm. The contributions of this paper

can be summarized as follows:

(1) An IoV-SFDL framework is proposed to ensure
data privacy with blockchain technology while mini-
mizing the total cost of edge-to-global communication
overhead, consisting of a central server, RSU-based
edge servers, and vehicles.

(2) A credibility weights prediction algorithm is
proposed to improve the model convergence eﬃciency
in the global model aggregation process.

(3) Various experiments in the IoV system are im-
plemented to verify the performance of the IoV-SFDL
framework and credibility weights prediction algo-
rithm on the Next Generation Simulation (NGSIM)
dataset.

The rest of this paper is organized as follows: The
system architecture is present in Section 2. The pro-
posed credibility weights prediction algorithm is de-
tailed in Section 3. Section 4 provides the NGSIM
trajectory dataset, framework performance evaluation,
and analysis. Section 5 concludes this paper.

2. System Architecture

The overview of the proposed IoV-SFDL frame-
work is shown in Figure 1. The problem formation,
data transmission and framewrok detail of the pro-
posed IoV-SFDL will be introduced in this section.

2.1. Problem Formation

This paper assumes that a highway with N vehicles
facing diﬀerent traﬃc conditions. The main notations
used throughout the paper are listed in Table 1. Be-
cause vehicular GPS, radars, cameras, and other on-
board sensors can obtain real-time vehicle trajectory,

A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles

3

Table 1: SUMMARY OF MAIN NOTATIONS

F(w)

The loss function of global model in cloud server

FS L(w)

The loss function of the aggregated model in SL group

fi(w)

W

WS L

Lm(i)

Rm(i)

Cb(i)

Ce(i)

λi

Di

ei
wi

γi

The loss function of the model in the ith vehicle

Aggregated model of central server

Aggregated model of SL group

Local model parameters of the ith vehicle

Merged model parameters of the ith vehicle

The robustness value of the ith SL group

The credibility value of the ith SL group

The model weights of the ith RSU node

The dataset obtained by onboard sensors of the ith vehicle

The driving environment of the ith vehicle

Onboard model of the ith vehicle

The model weights of the ith vehicle

we believe that each vehicle can be modeled as a triple
G = (V, P, E).

(1) V = {vi | i ∈ {1, 2, . . .}} represents all vehicles,
where vi represents vehicle i on the road. N = |V|
represents the number of vehicles on the road.

(2) P = {pi | vi ∈ V} represents the private informa-
tion of the vehicle, including the speed, acceleration,
orientation, and position.

(3) E = {ei | vi ∈ V} is a matrix, which is used to
store the road environment information around the ve-
hicle, that is, information of the vehicle from four di-
rections in the visual distance.

The information ei of vehicle vi in road environment

matrix is deﬁned as:

ei =

(cid:16)

I

vi, v j

(cid:17) =

(cid:34)





(cid:35)

Ir
Ip

Il
I f

0
1 − (d(vi,v j))2

R2

(cid:17)

(cid:17)

(cid:16)
vi, v j
(cid:16)
vi, v j

d

d

> R

≤ R

,

(1)

(cid:17)

(cid:16)
vi, v j

where d
denotes the Euclidean Distance be-
tween vi and v j, R represents the visual range of ve-
hicles.

Back propagation of the loss function is essential
for ML training to adjust weights and parameters. The
loss function in Deep Neural Network (DNN) models
quantiﬁes the modeling eﬀect of the algorithm on the
training data. The goal of training is to ﬁnd the op-
timal parameters to minimize the loss function. The
loss function in machine learning can be roughly di-
vided into classiﬁcation loss and regression loss. The
general loss functions for classiﬁcation include loga-
rithmic loss, focus loss, Kullback-Leibler(KL) diver-
gence, exponential loss, hinge loss, etc. This paper
uses the Mean Square Error (MSE) as the loss func-
tion of the vehicle onboard model. The expression of
the loss function fi(w) of the vehicle vi is as follows:

(cid:80)N

n=1

(cid:12)(cid:12)(cid:12)(cid:12)yn
predict − yn
N

observe

2

(cid:12)(cid:12)(cid:12)(cid:12)

,

fi(w) =

(2)

predict and yn

where yn
observe represent the model predic-
tion and observation of the sample batch n, and N is
the number of batches. Diﬀerent functions are avail-
able for parameter merging as a conﬁguration of the
Swarm Learning, such as average, weighted average,
minimum, maximum, or median functions. In this pa-
per, the weighted average is deﬁned as :

Rm(i) =

(cid:80)i

(cid:16)
γk × Lm(k)
k=1 γk

k=1
i × (cid:80)i

(cid:17)

,

(3)

in which Rm(i) is merged parameters of the ith vehicle.
Lm(k) is model parameters from the kth vehicle, γ is
the model weight. In this way, the loss function of an
SL group in this paper is deﬁned as:

FS L(w) = 1
|S L|

(cid:88)

i∈S L

[ fi(w) + fi−1(w)],

(4)

where |S L| means the number of vehicles in an SL
group.

Redundant or invalid experience data decrease the
eﬃcient implementation of the model aggregation pro-
cess. According to the model’s eﬀectiveness,
the
weights could be ﬂexibly adjusted by the proposed
credibility weights prediction algorithm. Making the
model with better results have a higher weight in
model aggregation helps the model converge faster
and achieve higher accuracy in FDL. To describe the
problem of model aggregation in IoV-SFDL, we in-
troduce λi = λ1, λ2, . . . , λ|S L| as the weights in global
model aggregation. |S L| represents the number of SL
groups on the road. The objective function of global
learning optimization is deﬁned as:

F(w) = 1
|S L|

(cid:88)

i∈S L

λiFS Li(w).

(5)

As mentioned earlier, we use the minimization of
the loss of the global model for the current training
task as the objective function:

min F(w) = min [

1
|S L|

(cid:88)

i∈S L

λiFS Li (w)].

(6)

2.2. Swarm-Federated Deep Learning Framework

The IoV-SFDL framework in the IoV system con-
tains three layers: A central server in the cloud layer,
RSU-based edge nodes in the edge layer, Vehicle
clients in the end layer. The three-layer structure con-
stitutes the whole IoV-SFDL architecture, and the op-
eration is divided into three steps as a whole. First of
all, vehicles in the end layer collect trajectory informa-
tion and train a time-sensitive local model. Accord-
ing to the SL process, vehicles with the same train-
ing task will form a blockchain network, with local
model parameters transferred and aggregated. Then,
the RSUs receive the model parameters from the SL
group and predict model weights according to the

4

Zhe Wang, et al.

Figure 2. The workﬂow in the proposed IoV-SFDL framework

credibility weights prediction algorithm. At last, the
parameters and weights are transmitted to the central
server for a global model aggregation.

The model’s aggregation process can be divided
into local SL and global FDL processes. Each vehicle
aggregates the model passed from the previous vehi-
cle with its onboard model in the local swarm learning
process. In this process, the distributed feature of SL
is combined with the point-to-point network based on
blockchain. Compared with the general operation of
federated deep learning, it provides a higher level of
data security, central coordinator elimination, and ma-
chine learning model attacks protection. According to
the proposed credibility weights prediction algorithm,
each RSU predicts the model’s weight in the global
FDL process and sends the model parameters to the
central server. In this process, the global FDL realizes
the global model aggregation through a central server,
which aggregates the value of local model parame-
ters according to their weights to generate a global
model. Compared with the general operation of FDL,
the IoV-SFDL provides less edge-to-global communi-
cation overhead and a more eﬀective training process.
the data transmission scheme in the
framework consists of ﬁve steps: (1) Group forming
and model updating; (2) Vehicle group-based Swarm
Learning; (3) Credible weights prediction and com-
parison; (4) Model parameters and weights uploading;
(5) Global Model Aggregation. After several itera-
tions of these steps, the ﬁnal model with good perfor-
mance is obtained.

Above all,

3. Credibility Weights Prediction Scheme

The key to guaranteeing model security and train-
ing eﬃciency in the IoV system is detecting ineﬀec-

tive models and scheduling less of them in each com-
munication round. This work proposes a credibility
weights prediction algorithm in the IoV-SFDL frame-
work to prevent unreliable updates and minus noise
from models with poor eﬀectiveness. With the cred-
ibility weights prediction algorithm, the RSU node
will evaluate the model’s eﬀectiveness and robust-
ness of the received model and global model. The
model’s credibility will be predicted as the weight for
the global model aggregation process in each com-
munication round. The total workﬂow is shown in
Figure 2. The algorithm can help the central server
in FDL distinguish eﬀective models from ineﬀective
ones, thereby preventing malicious or incorrect up-
dates of the global aggregate process in FDL.

3.1. Credibility Weights Prediction Algorithm

The Credible value Ci of model i in this paper can
be divided as Cb and Ce, where Cb and Ce represent
the robustness value and eﬀectiveness value of model
from an SL group. To represent the node’s robustness,
we consider the logarithms’ formulation, a single in-
In ML, we believe that the more
creasing function.
datasets in the training process, the better robustness
of the model will be. Therefore, in global model ag-
gregation, the model trained on more datasets can be
given higher weight. Thus, the robustness value of the
model with n vehicles in SL is given by the following
formula:

Cb = logk n.

(7)

In this formula, we believe that n is the number of ve-
hicles in the current SL group, k is the max group size
among all SL groups. The speciﬁc experimental pa-
rameters will be classiﬁed in the next section.

A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles

5

To represent the model’s eﬀectiveness, we use ob-
servation B made by the RSU node to illustrate the ef-
fective prediction P(ei) of a model. The eﬀectiveness
of the model, P (ei | B) is calculated and predicted by
the RSU node based on the observation, which can be
derived as:

P (ei | B) =

P (ei) P (B | ei)
(cid:17)
e j
j=1 P

P

(cid:16)

(cid:16)

B | e j

(cid:80)n

(cid:17) ,

(8)

To facilitate the expression and update of eﬀectiveness
value, we use beta distribution to represent aggregate
weights from the eﬀectiveness of an RSU node, de-
ﬁned as:

f (x; p, q) =

xp−1(1 − x)q−1

up−1(1 − u)p−1du

(cid:82) 1
0

=

Γ(p + q)
Γ(p)Γ(q)

xp−1(1 − x)q−1

,

(9)

=

1
B(p, q)

xp−1(1 − x)q−1

where p > 0 and q > 0 and p and q respectively rep-
resent the number of times that the receiving model
is better than the global model and the number of
times that the global model is better than the receiving
model, the Γ(x) is the Gamma function, which could
be written as:

Γ(x) =

(cid:90) +∞

0

tx−1e−t dt(x > 0),

(10)

For example, we assume the ai and bi represent the
positive and negative behaviors currently, while p and
q represent the initial positive and negative behaviors.
To update the credibility, it is equivalent to updating
the two parameters p and q, as:

from SL group in the next event. The validity proba-
bility of the model is deﬁned as:

Ce = E[Beta(p, q)] = p
p + q

.

(13)

Central server can normalize all the weights and
model parameters sent by the RSUs, and the weights
of model from ith RSU is deﬁned as:

λi =

(cid:80)n

Ci
j=1 C j

.

(14)

3.2. Eﬀectiveness Comparison Module

In the model aggregation process of FDL, the credi-
bility comparison module at RSU uses the test dataset
to evaluate and compare the model received from SL
group and global model download from central server.
Based on the value of the loss function derived from
the test dataset, we deﬁne the model’s credibility for
comparing the eﬀectiveness of diﬀerent models in
model aggregation.

=

et
k

f (wt, xi j, yi j) − f (W t
f (wt, xi j, yi j)

k, xi j, yi j)

,

(15)

(cid:16)

(cid:17)

xi j, yi j

where
is a data sampled from the current RSU
node’s test dataset. We use the diﬀerence between the
loss function value of the SL model and global model
to evaluate the quality of the received SL model pa-
rameters.

For a tagged RSU node,

its contribution to the
global model aggregation can be considered positive
or negative. Precisely, if et
k > 0, we assume that the ef-
fectiveness comparison module will characterize RSU
node k’s transmission as positive behavior and vice
versa. Moreover, we can also use et
k to represent the
eﬀect gap between the local model and the receiving
model imposed by the RSU.

(cid:40)

pnew = ai + p
qnew = bi + q

,

(11)

3.3. Vehicle Group-based Swarm Learning

When a node is initialized without prior knowledge,
the credibility of a node can be expressed as a uniform
distribution on (0, 1), deﬁned as:

P(x) = uni(0, 1) = Beta(1, 1).
(12)
By comparing the eﬀectiveness of the receiving model
and the global model previous time, the RSU can eval-
uate the eﬀectiveness of the receiving model, that is,
convert into positive behavior and negative behavior.
The evaluation process of the models is detailed in the
next section. Suppose that in n rounds of communica-
tion, the SL group has sent the model to RSU (p + q)
times. By comparing the eﬀectiveness of the models,
these interactions are described as p times positive be-
havior and q times negative behavior. With this infor-
mation, the RSU can predict the model’s eﬀectiveness

In the process of local model aggregation, vehicle
group-based swarm learning is considered. RSUs, as
the participants in the local model aggregation pro-
cess, are evenly distributed on both sides of the road.
The SL framework cooperatively optimizes the model
inside the vehicle through continuous iteration of the
following three steps:

1) Each vehicle carries out the model training task
by collecting the privacy information of local vehicles,
such as geographical location, speed, direction angle,
etc.

2) Vehicles with the same subtask and close to each
other can form groups and aggregate models through
blockchain in the SL process.

3) After model aggregation, the vehicle sends the
model parameters to the RSU for the further proces-
sion.

6

Zhe Wang, et al.

Generally, the number of vehicles in diﬀerent SL
groups is diﬀerent due to the rapid mobility of vehi-
cles on the road and the uncertainty of driving pur-
pose. By evaluating the credibility of the SL groups
and their internal LSTM model eﬀectiveness, the best
weight in the global FDL aggregation process could
be predicted. The whole training process of vehicle
group-based SL is shown in Algorithm 1.

Algorithm 1: Vehicle Group-based Swarm
Learning. The K vehicles are indexed by k; Dk
is local dataset of vehicle k, η is the learning
rate, B is the local mini-batch size, wk
t is the
onboard model of the vehicle, and WS L repre-
sented the aggregated model of SL group.

Algorithm 2: Global Federated Deep Learn-
ing. The K RSUs are indexed by k; wk
is
t
local model parameters at time t, λk
t is model
weights of wk
t , Wt is the global model parame-
ters

Input: wk

t , λk
1
t
2 Output: W Initialize wk
0;
3 for each round t = 1, 2, . . . do
for each RSU k do
4

t+1 ← WeightsPrediction(wk
λk
t );

end
W ← (cid:80)K
k=1

1

K λk

t+1wk

t+1;

5

6

7
8 end
9 return W

Input: wk
t

1
2 Output: WS L Initialize wk
0 ;
3 for each round t = 1, 2, . . . do
4

Update model wk
b ← spilt Dk into batches of size B;
for each vehicle k = 1, 2, . . . do

t from RSU;

wk
t+1 ← wk
t+1 ← wk
wk

t − η∇(cid:96)(wk
+wk−1
t+1
;
2

t+1

t ; b);

5

6

7

8

end

9
10 end
11 WS L = wk
t+1;
12 return WS L;

3.4. Global Federated Deep Learning

In the global model aggregation process, an FDL
framework with credibility is considered. As shown in
Figure 1, the FDL enables the local RSUs and central
server to collaboratively optimize the global model by
continuously iterating the following two steps:

1) Each RSU receives the model parameters, pre-
dicts the weight by the credibility weights prediction
algorithm, and sends the parameters to the central
server in the up-link.

2) The central server collects the model parameters
from RSU, aggregates the global model according to
their weights predicted from RSU, and broadcasts the
new model to all the RSUs in the down-link. Along the
training process, each iteration is generally referred to
as a communication round.

After suﬃcient communication rounds involving
parameters exchanges and training, we can obtain the
best global FDL model without sacriﬁcing the vehi-
cle’s privacy. The whole training process of FDL is
shown in Algorithm 2.

4. Performance Evaluation

In this section, we introduce the simulation setups
and then compare the performance of the proposed
IoV-SFDL with the other two baseline frameworks.
All source code about the framework, dataset used,
and proposed algorithm in this study are provided

on GitHub (https://github.com/CoderTylor/IoVSFDL-
Swarm-Federated-Deep-Learning-).

4.1. Experiment Setup

The hardware is 32GB RAM,

i7-10700 CPU
2.90GHz. The experimental platform is built based on
the PyTorch 1.9 framework, a ﬂexible deep learning
tool widely used in academics. The software adopts
Inspired
Python 3.7.0 in the Ubuntu18.04 system.
by the performance of Social LSTM [20], an LSTM-
centered model is trained as an onboard vehicle train-
ing task to predict the vehicle’s trajectory in 5s. The
complete model parameters are listed in Table 2. For
all LSTM learning models, we used the greedy explo-
ration with linearly annealed from 1.0 to 0.1 in the
whole training process. Adam optimizer is used to
learn all neural network parameters with a learning
rate of 10−4.

The simulation deﬁnes three traﬃc ﬂow densities:
high-traﬃc ﬂow density, medium-traﬃc ﬂow density,
and low-traﬃc ﬂow density. The number of total vehi-
cles ranges from 5 to 16, and the size of the SL group
ranges from 2 to 10. The NGSIM trajectory dataset
is used to verify the eﬀectiveness of the IoV-SFDL
framework. The dataset is collected for the next-

Table 2: LSTM Model Parameters

CELL

LSTM CELL

Input Embedding Layer

Social Tensor Conv1

Social Tensor Conv2

Social Tensor Embedded

Output Layer

Dropout

Activation Function

(Input, Output)

(64,32)
(In Feature=9, Out Feature=32)
(32,16, Kernel size=(5,3), stride(2,1))
(16,8, Kernel size=(5,3), stride(2,1))
(In Feature=32, Out Feature=32)
(In Feature=32, Out Feature=5)
Dropout(p=0, inplace=False)
ReLU

Time Length

Episode

Learning rate

Optimizer

10

50
10−4
Adam

A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles

7

Figure 3. Loss comparison of the IoV-SFDL, the Federated-Avg Learning in [18], and the Communication-Eﬃcient Learning in [19] on
diﬀerent traﬃc densities. (a)High-density traﬃc: 10 vehicles in one group and 6 vehicles in the other group. (b)Medium-density traﬃc: 6
vehicles in one group and 4 vehicles in the other group. (c)Low-density traﬃc: 2 vehicles in one group and 3 vehicles in the other group.

generation traﬃc simulation by Federal Highway Ad-
ministration. It use videos to capture real-world traﬃc
information, including vehicle velocity, position, ac-
celeration, lane, etc. As high-resolution real-world ve-
hicle trajectory data, NGSIM is widely used to explore
the characteristics of the trajectory-prediction process
and calibrate and validate the trajectory-prediction
models. Detailed descriptions of the dataset can be
found in [21].

To the best of our knowledge, there is no research
investigating the SL application under the IoV system,
so two other baseline FDL frameworks are added in
the simulations for better gauging the performance of
the proposed IoV-SFDL framework, which are:

(1) Federated-Average Learning (Federated-Avg):
Based on the Federated Average deep learning algo-
rithm proposed in [18], all vehicles on the road par-
ticipating in FDL. After training the model locally, the
average aggregation of model parameters is carried out
in the central server.

(2) Communication-Eﬃcient Federated Learn-
ing (Communication-Eﬃcient):
Based on the
Communication-Eﬃcient
federated deep learning
algorithm proposed in [19], we add the LSTM net-
work for trajectory prediction in their code and set the
parameters Frac as 0.8 for client selection.

4.2. Indicator

Three indicators are chosen to comprehensively
evaluate the performance of the proposed IoV-SFDL
framework, such as model Loss, trajectory Prediction
Accuracy, and Prediction Error. The descent speed of
the Loss function is the ﬁrst indicator to evaluate the
converging rate. The Loss of the LSTM model is de-
ﬁned as:

(cid:80)N
i=1

Loss =

(cid:12)(cid:12)(cid:12)(cid:12)(xi
predict, yi

observe, yi

(cid:12)(cid:12)(cid:12)(cid:12)
observe)

2

(16)

predict) − (xi
N

where (xpredict, ypredict) is the vehicle trajectory pre-
dicted by LSTM, and (xobserve, yobserve) is the actual
trajectory of the vehicle in the dataset.

Then, the Prediction Error is used to evaluate the
average Euclidean distance between predict trajectory

and actual trajectory in the NGSIM dataset under dif-
ferent traﬃc densities in meters. The Prediction Error
is deﬁned as:
Prediction Error =

(cid:113)

(cid:80)N

i=1

(xi

predict − xi

observe)2 + (yi
N

predict − yi

observe)2

(17)

.

At last, the Predict Accuracy is evaluated to esti-
mate the model performance. For the trajectory after
5 seconds, we compare the distance diﬀerence of each
path point as the basis for whether the prediction is
true or false. To be precise, we deﬁne positive predic-
tion PT , negative prediction PF and prediction accu-
racy as:

P =





PF
PT

Prediction Error > 10m
Prediction Error ≤ 10m

.

(18)

Based on equation (18), N(P = PT ) and N(P = PF) is
deﬁned as the number of positive and negative predic-
tion, and the Prediction Accuracy is deﬁned as:

Prediction Accuracy =

N(P = PT )
N(P = PT ) + N(P = PF)

.

(19)

4.3. Performance of the IoV-SFDL Framework

In Figure 3, we can see that the loss function change
is almost the same in the ﬁrst ten episodes among IoV-
SFDL and the other two benchmark frameworks. As
shown in Figure 3(b) and 3(c), the IoV-SFDL performs
better on the same computing cost than the others. Al-
though Figure 3(a) shows that the change speed of the
loss function of the three frameworks is almost the
same under the condition of high-density traﬃc ﬂow,
the loss function of IoV-SFDL is lower than the other
two benchmark frames after 20 iterations. This is be-
cause, with the increase of traﬃc ﬂow, the proposed
credibility weight prediction algorithm can help the
cloud server identify the redundant model update, And
give this update a minor weight to ensure the conver-
gence speed of the model.

8

Zhe Wang, et al.

Figure 4. Prediction Error comparison of the IoV-SFDL, the Federated-Avg Learning in [18], and the Communication-Eﬃcient Learning in
[19] on diﬀerent traﬃc densities. (a)High-density traﬃc: 10 vehicles in one group and 6 vehicles in the other group. (b)Medium-density traﬃc:
6 vehicles in one group and 4 vehicles in the other group. (c)Low-density traﬃc: 2 vehicles in one group and 3 vehicles in the other group.

Figure 5. Prediction Accuracy Comparison of the IoV-SFDL, the Federated-Avg Learning in [18], and the Communication-Eﬃcient Learning
in [19] on diﬀerent traﬃc densities. (a)High-density traﬃc: 10 vehicles in one group and 6 vehicles in the other group. (b)Medium-density
traﬃc: 6 vehicles in one group and 4 vehicles in the other group. (c)Low-density traﬃc: 2 vehicles in one group and 3 vehicles in the other
group.

Figure 4 shows the Prediction Error between predict
trajectory and actual trajectory under diﬀerent traﬃc
densities in meters. With the same experimental pa-
rameters settings of the three frameworks, the Predic-
tion Error decrease with the iteration number increase,
indicating that the LSTM learning agent has learned
to predict trajectory more precisely. As shown in Fig-
ure 4(a), 4(b), and 4(c), the more vehicle clients par-
ticipating in the FDL, the redundant data will aﬀect
the model prediction error of the two baseline frame-
works. Federated-Avg Learning is the most vulnerable
framework facing redundant training data. In contrast,
the IoV-SFDL can converge with less Prediction Error
quickly under all traﬃc densities given.

Figure 5 shows the model’s Prediction Accuracy
comparison for trajectory under the IoV-SFDL frame-
work with the other two baseline frameworks. We use
equation 18 to classify the positive and negative val-
ues of the predicted points so that the LSTM becomes
a binary network. Figure 5(c) illustrates that the Pre-
diction Accuracy diﬀerence between the IoV-SFDL
framework and baselines in Prediction Accuracy is
not evident under low-density conditions. However,
as shown in Figure 5(a) and 5(b), with more vehicles
clients participating in global model aggregation, the
IoV-SFDL can achieve higher model accuracy with the
same computing cost.

Figure 6. Communication Links of Diﬀerent Frameworks

Figure 6 shows the communication links estab-
lishment diﬀerence between IoV-SFDL and base-
line frameworks. Unlike Fed-Avg Learning and
Communication-Eﬃcient Learning, each client partic-
ipating in global model aggregation has to establish a
two-way link with the central server. The IoV-SFDL
only needs to establish a blockchain connection be-
tween clients in the SL group. Each group merely re-
quires one two-way communication link with the cen-
tral server to realize global model aggregation. Un-
der the conditions of 5, 10, 16 vehicles (Low-density,
Medium-density, and High-density) on the road, com-

A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles

9

ing for internet of vehicles, IEEE Transactions on Industrial
Informatics 16 (10) (2019) 6663–6672.

[13] R. Shrestha, R. Bajracharya, A. P. Shrestha, S. Y. Nam, A
new type of blockchain for secure message exchange in vanet,
Digital communications and networks 6 (2) (2020) 177–186.
[14] H. Lin, S. Garg, J. Hu, G. Kaddoum, M. Peng, M. S. Hos-
sain, Blockchain and deep reinforcement learning empowered
spatial crowdsourcing in software-deﬁned internet of vehi-
cles, IEEE Transactions on Intelligent Transportation Systems
22 (6) (2020) 3755–3764.

[15] Y. Lu, X. Huang, K. Zhang, S. Maharjan, Y. Zhang,
Blockchain empowered asynchronous federated learning for
secure data sharing in internet of vehicles, IEEE Transactions
on Vehicular Technology 69 (4) (2020) 4298–4311.

[16] S. Warnat-Herresthal, H. Schultze, K. L. Shastry, S. Man-
amohan, S. Mukherjee, V. Garg, R. Sarveswara, K. H¨andler,
P. Pickkers, N. A. Aziz, et al., Swarm learning for decen-
tralized and conﬁdential clinical machine learning, Nature
594 (7862) (2021) 265–270.

[17] Z. Chen, W. Liao, K. Hua, C. Lu, W. Yu, Towards asyn-
chronous federated learning for heterogeneous edge-powered
internet of things, Digital Communications and Networks
PP (3) (2021) 1–1.

[18] T. Li, A. K. Sahu, A. Talwalkar, V. Smith, Federated learn-
ing: Challenges, methods, and future directions, IEEE Signal
Processing Magazine 37 (3) (2020) 50–60.

[19] B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y Ar-
cas, Communication-eﬃcient learning of deep networks from
decentralized data, in: Artiﬁcial intelligence and statistics,
PMLR, 2017, pp. 1273–1282.

[20] A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-
Fei, S. Savarese, Social lstm: Human trajectory prediction in
crowded spaces, in: Proceedings of the IEEE conference on
computer vision and pattern recognition, 2016, pp. 961–971.
[21] B. Coifman, L. Li, A critical evaluation of the next generation
simulation (ngsim) vehicle trajectory dataset, Transportation
Research Part B: Methodological 105 (2017) 362–377.

pared with the other two baseline frameworks, the
IoV-SFDL needs the least communication links to
complete the global model aggregation.

Overall, the proposed IoV-SFDL framework is su-
perior to other baseline frameworks in edge-to-global
communication overhead and convergence times.

5. Conclusion

This paper proposed an IoV-SFDL framework for
protecting data privacy by integrating the parallel SL
into the FDL process. With the help of the SL process,
the reliability of shared data among FDL is guaran-
teed by blockchain veriﬁcation. Moreover, to achieve
the high-level performance of the proposed framework
in the IoV system, a credibility weights prediction al-
gorithm was designed to speed up the convergence of
model training in the IoV scenery. Simulation results
showed that the IoV-SFDL framework has less edge-
to-global communication overhead and higher com-
puting eﬃciency than other state-of-art FDL frame-
works in the IoV system. Our future work will ex-
pand the scale of the experiment and show how our
framework protects vehicle privacy data in the case of
attacks.

References
[1] X. Wang, S. Garg, H. Lin, G. Kaddoum, J. Hu, M. F. Alhamid,
An intelligent uav based data aggregation algorithm for 5g-
enabled internet of things, Computer Networks 185 (2021)
107628.

[2] J. Hamer, M. Mohri, A. T. Suresh, Fedboost:

A
communication-eﬃcient algorithm for federated learning, in:
International Conference on Machine Learning, PMLR, 2020,
pp. 3973–3983.

[3] C. Feng, Z. Zhao, Y. Wang, T. Q. S. Quek, M. Peng, On the de-
sign of federated learning in the mobile edge computing sys-
tems, IEEE Transactions on Communications (2021) 1–1.
[4] Z. Song, H. Sun, H. H. Yang, X. Wang, T. Quek, Reputation-
based federated learning for secure wireless networks, IEEE
Internet of Things Journal PP (99) (2021) 1–1.

[5] L. Li, Y. Fan, M. Tse, K.-Y. Lin, A review of applications
in federated learning, Computers & Industrial Engineering
(2020) 106854.

[6] M. Hao, H. Li, G. Xu, S. Liu, H. Yang, Towards eﬃ-
cient and privacy-preserving federated deep learning, in: ICC
2019-2019 IEEE International Conference on Communica-
tions (ICC), IEEE, 2019, pp. 1–6.

[7] H. Zhou, W. Xu, J. Chen, W. Wang, Evolutionary v2x tech-
nologies toward the internet of vehicles: Challenges and op-
portunities, Proceedings of the IEEE 108 (2) (2020) 308–323.
[8] X. Kong, H. Gao, G. Shen, G. Duan, S. K. Das, Fedvcp: A
federated-learning-based cooperative positioning scheme for
social internet of vehicles, IEEE Transactions on Computa-
tional Social Systems PP (99) (2021) 1–10.

[9] X. Kong, K. Wang, M. Hou, X. Hao, F. Xia, A feder-
ated learning-based license plate recognition scheme for 5g-
enabled internet of vehicles, IEEE Transactions on Industrial
Informatics PP (99) (2021) 1–1.

[10] X. Zhang, M. Peng, S. Yan, Y. Sun, Deep-reinforcement-
learning-based mode selection and resource allocation for cel-
lular v2x communications, IEEE Internet of Things Journal
7 (7) (2019) 6380–6391.

[11] T. Fu, P. Liu, K. Liu, P. Li, Privacy-preserving vehicle assign-
ment in the parking space sharing system, Wireless Commu-
nications and Mobile Computing 2020.

[12] T. Wang, Z. Cao, S. Wang, J. Wang, L. Qi, A. Liu, M. Xie,
X. Li, Privacy-enhanced data collection based on deep learn-

