1
2
0
2

p
e
S
9
2

]
P
S
.
s
s
e
e
[

1
v
3
6
2
4
1
.
9
0
1
2
:
v
i
X
r
a

Accepted at IEEE Transactions on Mobile Computing

Cooperative Task Ofﬂoading and Block Mining in
Blockchain-based Edge Computing with
Multi-agent Deep Reinforcement Learning

Dinh C. Nguyen, Member, IEEE, Ming Ding, Senior Member, IEEE, Pubudu N. Pathirana, Senior
Member, IEEE, Aruna Seneviratne, Senior Member, IEEE, Jun Li, Senior Member, IEEE,
and H. Vincent Poor, Fellow, IEEE

Abstract—The convergence of mobile edge computing (MEC) and blockchain is transforming the current computing services in mobile
networks, by offering task ofﬂoading solutions with security enhancement empowered by blockchain mining. Nevertheless, these
important enabling technologies have been studied separately in most existing works. This article proposes a novel cooperative task
ofﬂoading and block mining (TOBM) scheme for a blockchain-based MEC system where each edge device not only handles data tasks
but also deals with block mining for improving the system utility. To address the latency issues caused by the blockchain operation in
MEC, we develop a new Proof-of-Reputation consensus mechanism based on a lightweight block veriﬁcation strategy. A multi-objective
function is then formulated to maximize the system utility of the blockchain-based MEC system, by jointly optimizing ofﬂoading
decision, channel selection, transmit power allocation, and computational resource allocation. We propose a novel distributed deep
reinforcement learning-based approach by using a multi-agent deep deterministic policy gradient algorithm. We then develop a
game-theoretic solution to model the ofﬂoading and mining competition among edge devices as a potential game, and prove the
existence of a pure Nash equilibrium. Simulation results demonstrate the signiﬁcant system utility improvements of our proposed
scheme over baseline approaches.

Index Terms—Blockchain, mobile edge computing, task ofﬂoading, block mining, deep reinforcement learning.

1 INTRODUCTION
Recent advances in Internet of Things (IoT) have pro-
moted the proliferation of numerous mobile applications
that mostly rely on edge devices (EDs), e.g., laptops, tablets,
and smartphones, to collect data from IoT sensors to serve
end users. To meet the increasing users’ computation de-
mand, mobile edge computing (MEC) has been proposed as
a promising technique to improve the computation experi-
ence of EDs, by ofﬂoading computationally intensive tasks
to a nearby MEC server located at a base station (BS) [1].
Mapping each ofﬂoading process to a speciﬁc application,
multiple distributed EDs naturally share computation and
communication resources of the BS to handle data tasks
without device’s battery depletion. Task ofﬂoading with
MEC thus becomes a viable solution to satisfy various

• Dinh C. Nguyen and Pubudu N. Pathirana are with School of Engi-
neering, Deakin University, Waurn Ponds, VIC 3216, Australia (e-mails:
{cdnguyen, pubudu.pathirana}@deakin.edu.au).

• Ming Ding

is with

the Data61, CSIRO, Australia

(email:

ming.ding@data61.csiro.au).

• Aruna Seneviratne is with School of Electrical Engineering and Telecom-
munications, University of New South Wales (UNSW), NSW, Australia
(e-mail: a.seneviratne@unsw.edu.au).
Jun Li is with School of Electrical and Optical Engineering, Nanjing
University of Science and Technology, Nanjing 210094, China (e-mail:
jun.li @njust.edu.cn).

•

• H. Vincent Poor is with the Department of Electrical Engineering, Prince-
ton University, Princeton, NJ 08544 USA (e-mail: poor@princeton.edu).
• This work was supported in part by the CSIRO Data61, Australia, and
in part by U.S. National Science Foundation under Grant CCF-1908308.
The work of Jun Li was supported by National Natural Science Foundation
of China under Grant 61872184.

(cid:70)

1

EDs’ computation demands and enhances the quality of
experience (QoE) of end users.

However, the design of an efﬁcient task ofﬂoading
scheme for MEC systems still faces non-trivial challenges.
Each ED always aims to maximize its individual utility by
occupying as many edge resources (e.g., channel spectrum,
CPU frequency) as possible, which is likely to cause network
trafﬁc congestion and user interference. The heterogeneous
resource requirements of multiple IoT data tasks, e.g., dif-
ferent resource allocations needed for handling different
data tasks, and the heterogeneous features of real-time IoT
data tasks, e.g., computation deadlines and data task sizes,
pose challenges for the design of ofﬂoading strategies for
all EDs. Moreover, the lack of prior information on system
statistics in practical multi-user MEC systems, e.g., channel
state and edge computational resource state, makes it chal-
lenging to derive an optimal ofﬂoading solution for each
ED. Therefore, it is of the utmost importance to develop a
intelligent and self-organized ofﬂoading scheme to guide
the ofﬂoading actions of all EDs in the distributed MEC
systems.

Furthermore, the dynamic communications between IoT
devices, EDs, and the MEC server and the migration of
IoT data tasks across the MEC network potentially cause
security vulnerabilities. Recent works [1]–[3] have mainly
focused on computation ofﬂoading designs for task schedul-
ing and resource allocation, with the lack of considering
security aspects in MEC networks. Fortunately, blockchain
has been envisioned as a strong candidate to enhance secu-
rity of MEC systems [4]. In fact, blockchain is able to provide

 
 
 
 
 
 
high degrees of security and trust for MEC by employing
the community veriﬁcation among edge nodes via mining
mechanisms such as Delegated Proof of Stake (DPoS) [4]
without requiring any central authority.

In this context, the use of blockchain is highly desirable
to support edge computing systems
[5]–[7]. Speciﬁcally,
blockchain decentralizes the MEC system where edge nodes
can communicate with each other via the peer-to-peer net-
work over the decentralized data ledger. Different from
traditional MEC systems that often rely on a central server
to coordinate the MEC operation, blockchain helps build
decentralized edge communications without the need for
a single authority, which eliminates the risks of single-
point failure. This feature is very useful in practical ap-
plication scenarios, e.g., decentralized edge data sharing
and decentralized edge data caching in MEC networks.
Another motivation behind the integration of blockchain
in MEC is its immutability that makes edge data records,
e.g., IoT data, unchangeable once they are stored on the
ledger [8]. By deploying immutable transaction ledgers, EDs
can establish reliable communications to perform heteroge-
neous networking and computation, such as large-scale IoT
collaborations or mobile edge computing over trustless IoT
environments. Moreover, blockchain provides transparency
for MEC networks, where blockchain allows the copy of
data records to replicate across edge nodes for public vali-
dation, which in return enhances data integrity. This feature
is particularly suitable for MEC ecosystems where openness
and fairness are required. For example, blockchains can offer
transparent ledger solutions to support open and secure
data delivery and payment for EDs in a fashion such that
EDs can trace and monitor transactions.

Moreover, each ED joins the block mining process to
maintain the operation of blockchain in MEC. The key
purpose of mining is to verify the data transactions, aim-
ing to guarantee the security for the involved edge net-
works. Accordingly, in the blockchain-based MEC system,
EDs perform the mining, and data blocks are secured and
chained via an immutable ledger. With more devices mining
the blockchain, the security of the edge network increases
accordingly.

1.1 Related Works

Recently, many edge task ofﬂoading solutions have been
proposed [9]–[11], but these works mostly considered of-
ﬂoading scenarios with a single agent using traditional con-
vex optimization tools. Deep reinforcement learning (DRL)
techniques such as deep Q-learning (DQN) have emerged
as a promising alternative, by modelling the ofﬂoading
problem as a Markov decision process (MDP) with using
deep neural network (DNN) for function approximation
[12]–[14]. However, these works only used a single agent to
handle the entire ofﬂoading process which could not work
well in large-scale distributed MEC environments. An inter-
esting alternative is to use multi-agent-DRL (MA-DRL) [15]
for supporting intelligent task ofﬂoading in MEC networks
[16]. The work in [17] proposed a non-cooperative MA-DRL
scheme where EDs could build their ofﬂoading policy inde-
pendently. Another study in [18] also suggested an MA-DRL
approach for joint data ofﬂoading and resource allocation in

2

multiple independent edge clouds. Furthermore, a multi-
agent Q-learning algorithm was developed in [19] for a joint
computation ofﬂoading and resource allocation scheme in
edge computing.

In terms of reputation-based DPoS mining design, the
work in [4] focused primarily on addressing the secure block
veriﬁcation issues in the DPoS mechanism using contract
theory. The paper in [20] suggested a fair voting scheme for
the DPoS mechanism via vague set theory. Speciﬁcally, this
work leveraged a general model of transforming vague sets
into fuzzy sets to calculate the comprehensive evaluation
indices for agent node selection. The paper in [21] proposed
a contract theory-based optimization scheme for transaction
relaying and DPoS based block veriﬁcation. The authors of
this work focused on formulating two mathematical models:
value of transaction relaying and value of block veriﬁcation,
and developed the optimal contract to maximize utility of
the miners. Further, the work in [8] proposed a lightweight
blockchain-based information trading framework to model
the interactions between trafﬁc administration and vehicles
in the reputation-based DPoS mechanism via a budgeted
auction approach. This study paid attention to the opti-
mization of the mining proﬁt by using a truthful budgeted
selection and pricing algorithm. However, a design for
low-latency block veriﬁcation in the reputation-based DPoS
mechanism has not been developed.

Moreover, the research related to task ofﬂoading and
blockchain mining in MEC networks has been conducted
recently. A blockchain-empowered computation ofﬂoading
scheme was presented in [16] where blockchain was mainly
used for data integrity in the ofﬂoading. The authors in [22]–
[24] studied edge ofﬂoading schemes for blockchain mining
tasks with edge clouds, aiming to enhance the quality of
service (QoS) for efﬁcient block mining. Blockchain was also
utilized in [25] to support resource trading for the edge
task ofﬂoading, while the work in [26] considered a co-
operative blockchain-MEC system with an actor-critic DRL
algorithm. The study in [27] optimized the edge computa-
tion ofﬂoading and resource allocation via a double-dueling
deep Q network. The authors in [28] considered a coop-
erative computation ofﬂoading framework for blockchain-
based IoT networks. An MA-DRL algorithm was designed
which could allow IoT devices to collaboratively explore the
ofﬂoading environments in order to minimize long-term of-
ﬂoading costs. Another work [29] considered a blockchain-
based energy trading scheme to manage the energy trading
process toward building a secure energy trading system
in Industry 4.0. In [30], the problem of resource trading
for blockchain-based IoT was studied by using a two-
level Stackelberg game with a credit-based payment with
smart contracts. Game theory was also applied in [31] to
minimize the economic cost of industrial IoT devices. How-
ever, in most existing works [22]–[27], [29]–[31], the design
and optimization of task ofﬂoading and blockchain mining
were implemented separately, which would result in a sub-
optimal performance.

1.2 Motivations and Our Key Contributions

Despite the recent research efforts in blockchain-MEC de-
signs, there are several limitations in existing works, as
highlighted below:

TABLE 1: The comparison of the existing works and our scheme.

Design features

Task ofﬂoading with blockchain
Intelligent edge task ofﬂoading
Cooperative edge task ofﬂoading
Lightweight blockchain design
Joint ofﬂoading and mining design

[13]

(cid:88)

[16]
(cid:88)

[17]

[18]

(cid:88)

(cid:88)

Schemes
[27]
(cid:88)
(cid:88)

[26]
(cid:88)
(cid:88)

[28]
(cid:88)
(cid:88)
(cid:88)

[31]
(cid:88)
(cid:88)
(cid:88)

Our scheme
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

3

• In distributed blockchain-based MEC systems, tradi-
tional single-agent DRL algorithms like DQN [13],
[14], [22], [26], [32] face critical challenges caused by
diversiﬁed and time-varying local environments. In
more details, during the training process of DQN,
each agent only observes its local
information and
cannot know the updates from other agents due to
non-collaboration. This makes it hard to ensure the
stability and convergence of the agents’ algorithm [33].
Moreover, this breaks the Markov properties required
by the Q-learning algorithm and thus, DQN may not
be capable of learning the cooperative ofﬂoading poli-
cies of EDs. Moreover, the non-cooperative multi-agent
DRL solutions [17]–[19] may not be able to learn the
cooperative policy; and thus resource usage over the
edge network is not efﬁcient which limits the overall
ofﬂoading performance, e.g., ofﬂoading utility.

• In addition, in most existing blockchain-based MEC
schemes [22]–[26], the design and optimization of task
ofﬂoading and blockchain mining are done separately,
which would result in sub-optimal performance. More-
over, the problem of high network latency caused by
blockchain mining in the edge ofﬂoading system has
not been addressed so far [27], [28], [30], [31]. To
improve the overall performance, a joint ofﬂoading
and blockchain design is needed for realizing efﬁcient
blockchain-based MEC systems.
Motivated by the aforementioned limitations, we pro-
pose a novel cooperative task ofﬂoading and blockchain
mining (TOBM) scheme for blockchain-based MEC systems
enabled by a new MA-DRL solution. Different from existing
works [23]–[27], [29]–[31], we here focus on maximizing the
overall system utility as the sum of ofﬂoading utility and
mining utility. More speciﬁcally, each ED handles data tasks
collected from its IoT sensors and deals with block mining
tasks simultaneously. To reduce the network latency caused
by the blockchain integration in the MEC system, we design
a new Proof-of-Reputation (PoR) mining mechanism en-
abled by a lightweight block veriﬁcation solution. In partic-
ular, we develop a novel distributed DRL-based algorithm
using a multi-agent deep deterministic policy gradient (MA-
DDPG) approach to optimize the overall system utility.
The proposed MA-DDPG approach enables the efﬁcient
learning of the mutual policy among cooperative EDs in the
dynamic environment and high-dimensional system state
space. Indeed, the proposed MA-DDPG scheme allows EDs
to learn mutually the cooperative ofﬂoading and mining
policy which helps enhance the computation efﬁciency and
thus improves the system utility. To enhance the conver-
gence performance in model training and solve the nonsta-
tionary issues caused by the concurrently learning process
of all EDs in the multi-agent environment, a centralized
learning and decentralized execution solution is adopted.

As such, the proposed MA-DRL algorithm is ﬁrst trained at
the centralized MEC server, and the learned model is then
executed at EDs in a distributed manner. In fact, the beneﬁts
of the MA-DDPG algorithm in edge computing have been
proved in recent works for MEC-based industry 4.0 [34],
smart ocean federated learning IoTs [35], and smart grid
[36]. However, its potential in blockchain-MEC system has
not been explored so far. The comparison of our paper and
the related works via some key features is summarized in
Table 1. In a nutshell, the unique contributions of this article
are highlighted as follows:

1) We propose a novel cooperative TOBM scheme in a
blockchain-based MEC system to enable a joint design
of task ofﬂoading and blockchain mining for improving
the overall system utility.

2) The details of task ofﬂoading are presented, where
EDs cooperatively ofﬂoad their IoT data tasks to the
MEC server. Moreover, we propose a new PoR mining
mechanism enabled by a lightweight block veriﬁcation
strategy, in order to solve latency issues caused by the
blockchain adoption in the MEC system.

3) In the TOBM scheme, each ED as an intelligent agent
to learn cooperatively policies, by jointly considering
ofﬂoading decision, channel selection, transmit power
allocation, and computational resource allocation with
respect to both ofﬂoading and mining states for max-
imizing the system utility. Then, we propose a novel
distributed DRL-based approach using an MA-DDPG
algorithm to solve the proposed problem based on a
centralized learning and decentralized execution strat-
egy.

4) We further develop a game-theoretic solution to model
the competition among EDs in ofﬂoading and mining
as a potential game. We then analyze the properties of
the formulated game and prove the existence of a pure
Nash equilibrium (NE).

5) We conduct extensive numerical simulations and com-
pare with the existing schemes to verify the effective-
ness of the proposed scheme.

1.3 Paper Organization

The remainder of this paper is organized as follows. Sec-
tion 2 introduces the system model along with the analysis
of network model edge task ofﬂoading model. The PoR
blockchain consensus mechanism is proposed in Section 3.
Based on the ofﬂoading and mining design, a joint system
utility problem is formulated in Section 4 which is then
modelled by a cooperative ofﬂoading game. A new MA-
DRL algorithm is proposed to solve the formulated ofﬂoad-
ing game by using an MA-DDPG algorithm. The simulation
results are provided in Section 5 and the comparison with
other related ofﬂoading schemes is also discussed. Finally,

4

Fig. 1: The cooperative task ofﬂoading and block mining
architecture in the blockchain-based MEC system.

Section 6 concludes this article and highlights possible fu-
ture directions.

2 SYSTEM MODEL
In this section, we introduce the network model of the
blockchain-based MEC system, and then present the task
ofﬂoading model.

2.1 Network Model

We consider a cooperative TOBM architecture in the
blockchain-based MEC system as illustrated in Fig. 1. The
BS is equipped with an MEC server to provide computa-
tion services for EDs. We denote the set of EDs as N =
{1, 2, ..., N }. For the sake of simplicity, we assume that each
ED n ∈ N has an IoT data task Yn to be executed [9], [10],
which can be deﬁned by a tuple Yn = (Cn, Dn, τn), n ∈ N .
Herein, Cn denotes the total computational resource (i.e.,
the number of the CPU cycles) to accomplish the task
Yn. Also, Dn expresses the size of the input data, and τn
speciﬁes the maximum permissible latency to accomplish
task Yn. In addition to the task ofﬂoading function, each
ED also participates in the block mining by using a PoR
consensus mechanism. The key network components of the
blockchain-based MEC system are described as follows:

• IoT Sensors: IoT sensors such as cameras, smart me-
ters, and wearables are responsible for sensing physcial
environments, e.g., entertainment, logistics, transporta-
tion and healthcare monitoring, and generating data
which need to be computed to serve end users. IoT
sensors can act as lightweight blockchain nodes to
securely communicate and transmit data to their nearby
ED via the blockchain network.

• Edge Devices: Each ED such as a laptop or a powerful
smartphone manages a group of IoT sensors under
its coverage. Based on the QoE requirements, EDs can
use their computational capability to process data tasks
locally or ofﬂoad to a nearby MEC server via wire-
less links. EDs also participate in block mining, i.e.,

Fig. 2: Illustration of the blockchain operation in our MEC
network: (1) An IoT sensor user sends a transaction to its
associated ED for triggering the IoT data task ofﬂoading, (2)
A new block is created to represent the veriﬁed transaction,
(3) A mined block is appended to the blockchain.

transaction veriﬁcation and block generation, via a PoR
consensus mechanism where IoT sensor users vote to
select representative EDs to run the mining process. The
details of our blockchain mining design are explained
in Section 3.

• MEC Server: In our considered blockchain-based MEC
system, there is a single MEC sever located at a BS to
handle computationally extensive data tasks ofﬂoaded
from EDs. By analyzing the task proﬁle such as task
sizes, channel conditions, and available resource, EDs
can make ofﬂoading decisions so that the MEC server
can allocate its resources for computation under QoE
requirements.

• Blockchain: A blockchain network is deployed over the
MEC system where each ED acts as a blockchain miner.
In this paper, we propose a PoR framework and fo-
cus on analyzing the block veriﬁcation latency that is
a signiﬁcant factor in evaluating the efﬁciency of a
blockchain network. The use of our proposed PoR
scheme allows EDs to participate in the block mining
with an enhanced mining utility which contributes to
the system utility improvement in the blockchain-based
MEC system.

The blockchain framework for our MEC network is
illustrated in Fig. 2, and its operational concept is explained
via the following steps:

• Step 1: The IoT sensor user ﬁrst creates a transaction
with metadata (i.e. user ID), user signature and times-
tamp from its wallet account and sends it to the associ-
ated ED. The user then submits a transaction to the ED
for a certain request, such as IoT data task ofﬂoading.
• Step 2: The ED releases its available resources and
processes the request from the user. For example, an
ED can use a smart contract [37], a self-executing soft-
ware running on blockchain, to automatically perform
transaction authentication, user veriﬁcation, or resource
trading. Moreover, the ED collaborates with other min-
ing members to aggregate the transactions ofﬂoaded
from IoT users to build a block after a certain period of
time. Then, the EDs participate in the mining to verify
the block using a consensus mechanism, e.g., PoR.

• Step 3: After the mining, if all miners achieve an agree-
ment on the veriﬁed block, this block with its signature

Edge Devices (EDs)Previous Hash Transactions Block k+1Block kPrevious Hash Transactions ......MEC ServerIoT SensorsBase station (BS) BlockchainData offloadingNode consensusIoT sensor usersBlock miningData collectionBlock n+1Block n+2Block n...time(1) Transaction IoT Sensor UserContractsEdge DeviceMined blockStorageMining process(2)(3)is then appended to the chain of blocks in chronological
order. Finally, all network entities receive this block and
synchronize the copy of the blockchain.

2.2 Edge Task Ofﬂoading Model

Here, we present the communication model and the com-
puting model for the edge task ofﬂoading.

2.2.1 Communication Model

We denote K = {1, ..., K} as the set of available sub-bands
at the BS. We deﬁne a task ofﬂoading policy, which also
incorporates the uplink sub-band scheduling, by a binary
variable xk
n = 1 indicates that
the task Yn from ED n is ofﬂoaded to the MEC server via
sub-band k, and xk
n = 0 otherwise. Each computation task
can be either executed locally at the ED or ofﬂoaded to the
MEC server under a feasible ofﬂoading policy:

n, (n ∈ N , k ∈ K). Here, xk

xk
n ≤ 1, n ∈ N .

(cid:88)

k∈K

(1)

In line of the above discussion, we deﬁne the task ofﬂoading
policy X that contains all the task ofﬂoading variables xk
n
as X = {xk
n = 1, n ∈ N , k ∈ K}. Besides, we denote
Nn = {n ∈ N |(cid:80)
n = 1} as the set of EDs ofﬂoading
their tasks to the MEC server.

k∈K xk

n|xk

n|0 < pk

Moreover, we consider that each ED and the BS have a
single antenna for uplink communications. We denote hk
n
as the uplink channel gain between the ED n and the BS
on sub-band k. Let P = {pk
n , n ∈ Nn}
denote the transmit power policy of EDs, where pk
n is the
transmit power of ED n when ofﬂoading the task Yn to the
BS via the channel k, subject to a maximum budget P k
n . We
also assume that the MEC system has a total operational
frequency band BM EC that is divided into K sub-bands of
an equal size W = BM EC/K [Hz]. Then, the transmission
data rate of the ED n can be calculated as

n ≤ P k

Rn = W log2


1 +

nhk
pk
n

σ2 + (cid:80)

j∈Nn,j(cid:54)=n

(cid:16)

j pk
xk

j hk
j


 ,

(cid:17)

(2)

where σ2 is the background noise variance and the sec-
ond term at the denominator is the interference among
mobile users in the same channel. We also denote xn =
(cid:80)
n, ∀n ∈ N . Thus, the required time that the ED n
upload its task input Dn via the uplink is speciﬁed as

k∈K xk

T up
n =

Dn
Rn

, ∀n ∈ N .

(3)

Accordingly, the energy consumption of ED n for ofﬂoading
the task Yn is speciﬁed as

Eup

n = pnT up

n = pn

Dn
Rn

, ∀n ∈ N ,

(4)

where pn = (cid:80)

k∈K pk

n, ∀n ∈ N .

2.2.2 Computing Model

5

We consider two computing modes: local execution and
edge ofﬂoading.

- Local execution: Let f l

n denote the computational re-
source of ED n (in CPU cycles/s) allocated to execute the
data task, which should not exceed its total computation ca-
pacity Fn. Thus, we can deﬁne the policy of computational
resource allocation of EDs as F = {f l
n ≤ Fn, n ∈
N }. The time consumed to execute the task input Dn (with
Cn in CPU cycles) at an ED n is expressed as

n|0 < f l

T l
n =

Cn
f l
n

.

(5)

Moreover, the energy consumption of an ED n when

executing its task locally is speciﬁed as
n)2Cn,

n = κ(f l

El

(6)

where κ is the energy coefﬁcient depending on the chip
architecture [9] and Cn is the CPU workload of ED n.

- Edge ofﬂoading: For the ofﬂoading case, the MEC
server at the BS can provide computation services to mul-
tiple EDs concurrently. Compared to the local device, the
MEC server has much more powerful computation capacity
f e (in CPU cycles/s) and more stable power supply. The ex-
ecution time of task Yn at the MEC server can be calculated
as

T ex
n =

Cn
f e , ∀n ∈ N .

(7)

Similar to [9], [10], we do not model the downloading
part due to the small size of data results compared to the
ofﬂoading data.

In summary, the latency cost consumed by the ED n

when ofﬂoading its task Yn is given by

n =

n + T ex

n = T up
T of f

(cid:18) Dn
Rn
Moreover, the energy cost consumed by the ED n when
ofﬂoading its task Yn is only associated with the data
transmission, which is given by

, ∀n ∈ N .

Cn
f e

(8)

+

(cid:19)

Eof f

n = Eup

n = pn

Dn
Rn

, ∀n ∈ N .

(9)

3 BLOCKCHAIN CONSENSUS DESIGN

In the blockchain-based MEC system, a crucial component
is blockchain consensus that aims to mine the blocks of
transactions (i.e., IoT data records) and add them to the
blockchain. To handle the transactions, the EDs work as
blockchain miners to perform mining. In the blockchain-
based edge ofﬂoading environment, latency is one of the
most important factors determining the efﬁciency of a
blockchain system. Given a consensus algorithm, when the
number of transactions to the blockchain increases, the
consensus workload to validate and append them into the
blockchain will increase signiﬁcantly. In current consensus
schemes, e.g., DPoS [38], each miner node must implement
a repeated veriﬁcation process across the miner network,
which results in unnecessary consensus latency and net-
work bandwidth waste. A possible solution is to reduce
the number of miner nodes to reduce the consensus latency,

but it potentially compromises the security of blockchain
because of the high probability of adding compromised
transactions from malicious nodes [39]. To solve these min-
ing issues, here we propose a new lightweight Proof of
Reputation (PoR) consensus mechanism for our blockchain
system. Compared to the DPoS scheme, we make an im-
provement in the miner selection based on a reputation
score evaluation approach. Moreover, instead of using a
repeated veriﬁcation among miner nodes, we implement
a lightweight block veriﬁcation solution that allows each
miner only needs to verify once with another node during
the consensus process, which would signiﬁcantly reduce the
veriﬁcation latency and save network bandwidth. There are
two main parts of our PoR consensus, including miner node
selection and block veriﬁcation, as illustrated in Fig. 3.

3.1 Miner Node Selection

In this phase, the IoT users ﬁrst calculate the reputation
score of EDs and then select the miner nodes to implement
the mining process.

3.1.1 Reputation Calculation

In our MEC system, IoT sensors’ users participate in the
delegate selection process to vote the mining candidates
among EDs for performing blockchain consensus. In this
regard, each IoT user votes its preferred ED with the most
reputation. Here, the reputation of an ED is measured by its
mining utility with respect to mining latency. That is, an ED
exhibits a lower mining latency will have a better mining
utility which increases its reputation. To this end, we deﬁne
a mining utility function of each ED as:

J mine
n

=

(cid:20)
e1−

T P oR
n
τn − 1

(cid:21)+

,

(10)

n

where T P oR
is the mining latency of the ED n (its detail will
be explained in the following sub-section), τn denotes the
task execution latency constraint. [y]+ = max{y, 0} implies
that the reputation of an ED is set to 0 if the mining latency
T P oR
is exceeded to its task execution constraint τn.
n

3.1.2 Miner Selection

Based on the calculated reputation score, each sensor user
will vote for the ED candidates as the miners based on their
reputation ranking. The top EDs with highest reputation
scores are selected to become edge miners (EMs) to perform
mining, as indicated in Fig. 3. Also, similar to the traditional
DPoS framework [38], in our PoR mechanism, each of the
active EMs takes turn to act as a block manager during
its time slot to coordinate the consensus process. In other
words, there is one manager in each consensus process. In
the next time slot, another active EM will undertake this
manager role.

3.2 Lightweight Block Veriﬁcation

In this phase, the block manager ﬁrst produces an unver-
iﬁed block B that contains several ofﬂoading transactions
collected in a given amount of time. Then, the manager
broadcasts this created block to all EMs within the miner
network for veriﬁcation. Different from the traditional DPoS

6

Fig. 3: The proposed PoR consensus in our blockchain-based
MEC system.

scheme [38] which relies on a repeated veriﬁcation process
among miners, here we implement a lightweight veriﬁcation
solution that allows each miner to only verify once with
another node during the consensus process. Algorithm 1
presents how our proposed block veriﬁcation procedure is
performed. In lines 4 to 9, the block manager divides the
block B consisting of transactions into N transaction parts
T rn, n ∈ N that will be assigned to each mining member
EM within the miner group. Each miner EM will also be
assigned a unique random number Rn. In lines 11 to 21, an
EM selects any miner s (s ∈ N \n) within the miner group
to implement the veriﬁcation for its assigned transaction
part T rn. If 51% of the EMs respond positive veriﬁcation,
and the sum of random numbers Sum calculated by all EMs
is equal to the initial number set Rnd, the block manager
accepts the veriﬁed block B(cid:48) and adds it to the blockchain
with a signature. For instance, in Fig. 3, the EM 4 works
as a manager to create the block C and append it into the
blockchain. Otherwise, the manager discards it from the
network (in lines 22 to 27).

3.3 Latency of Block Veriﬁcation

In this sub-section, we calculate the veriﬁcation latency
incurred by the mining. For simplicity, we assume that
the transaction part T rn (which also expresses the size)
is the same for all EMs. Each EM is willing to allocate a
certain CPU resource φn (in CPU cycles) for the veriﬁcation
of transaction part n. Then, the CPU resource allocation
policy for block veriﬁcation of EDs can be deﬁned as
G = {φn|0 < φn ≤ Φn, n ∈ N }, where Φn is the CPU
resource budget of the ED n. Further, the size of veriﬁed
transaction result for the T rn is denoted by T rre
n . Hence,
the transaction veriﬁcation task can be expressed as a tuple
(T rn, φn, T rre
n ).

Conceptually, the block veriﬁcation process in our pro-
posed PoR mechanism at an EM experiences four steps: (1)
unveriﬁed block transmission from the block manager to
the EMs, (2) local block veriﬁcation at the EM, (3) broad-
casting of the veriﬁcation result among two EMs, and (4)
transmission of veriﬁcation result feedback from the EMs

Previous HashTransactionsNonceBlock DTimestampBlock headerPrevious HashTransactionsNonceBlock ATimestampBlock headerPrevious HashTransactionsNonceBlock BTimestampBlock headerPrevious HashTransactionsNonceBlock CTimestampBlock headerEM 2Edge Miner (EM) 1 EM 3EM 4EM 5EM m1Miner node selectionVotingVotingVotingVotingVoting2Block verificationAdding block to the chainIoT Sensor UsersTransaction exchangeTransaction exchangeMiningMiningAlgorithm 1 Procedure of the proposed PoR consensus

1: Input: the unveriﬁed block B, a set of EMs N
2: Output: the veriﬁed block B(cid:48)
3: Initialization: Select an unveriﬁed block B, group the selected EMs
EM in the list Array[n], n ∈ N , initiate public key Array[n].P K
and block manager BM

4: Divide the block B into N parts T rn, Sum ← 0
5: for n = 1, ..., N do
6:
7:
8:

Set a part of block T rn → Array[n].content
Assign a random number Rn ← Random()
Sign
Calculate
Hash(Array[n].content, Array[n].P K, timestamp)

signature

as

a

9: end for
10: Specify the total random number Rnd = N (1 + N −1
2 )
11: for n = 1, ..., N do
12:
13:
14:
15:

Run a random function s = Random.randrange(1, N, 1)
if s (cid:54)= n then

to EMs: EM → EMs

T rn

the

Select a random different EM within the list
Send
(T rn, Array[n].P K, Sign, timestamp)
Verify the transaction T rn
if (Array[n].P KEMs == EM EM.P K
true) then

s

) ∩ (V erif y(Sign) ←

←

:

16:
17:

24:

Sum ← Sum + Rn

end if

end if

18:
19:
20:
21: end for
22: if Sum == Rnd then
23:

Accept the block B as a veriﬁed one (B(cid:48)) and send it back to the
block manager BM
The manager
B(cid:48)
the
into
(BMP K , B(cid:48), SignB, timestamp)

network: BM → ∗

BM appends

block
:

blockchain

veriﬁed

the

25: else
26:
27: end if

Discard the block B from the blockchain

to the manager. For a miner EM n, the time required to
complete these steps is expressed as:

+

φn
Fn

+ ξT rn|L2|+

T rre
n
ru
n

, n ∈ N ,

(11)

T P oR
n

=

T rn
rd
n
n and rd

where ru
n are uplink and downlink transmission
rates between the miner n and the block manager. Here,
the transmission time of an unveriﬁed transaction part T rn
from the block manager to the miner is T rn
, while the local
rd
n
veriﬁcation time of this transaction is φn
. Moreover, similar
Fn
to [4], the time for transaction broadcasting among two
miners is a function of transaction size T rn and network
scale T rn|L2| (which means two miners for transaction
veriﬁcation), which is deﬁned as ξT rn|M 2|. Here, ξ is a pre-
deﬁned parameter of broadcasting veriﬁcation result and
comparison among two miners, which can be acquired from
the previous veriﬁcation records [4]. Besides,
is the
veriﬁcation feedback time

T rre
n
ru
n

Meanwhile, in the traditional DPoS scheme [38], each
miner has to implement a repeated veriﬁcation process
among all miners for the block B, instead of dividing into
separate transaction parts like our proposed PoR model.
Therefore, the veriﬁcation latency of the DPoS consensus
at an EM n is expressed as [4]:

T DP oS
n

=

B
rd
n

+

φB
n
cB
n

+ ξB|LN |+

Bre
ru
n

,

(12)

where φB
B under the computation budget cB

n is the CPU resource occupied to verify the block
n . Bre denotes the size

7

of veriﬁed result of the block B. |LN | expresses the whole
miner network which means all miners n join the repeated
block veriﬁcation in each consensus process, instead of two-
miner veriﬁcation in our PoR scheme. By comparison of
equations 11 and 12, it can be seen that the proposed PoR
scheme needs less time for block veriﬁcation in compari-
son with the traditional DPoS scheme, for the same block
size and number of miners. Moreover, our mining scheme
can save much network bandwidth due to less message
exchange during the consensus process. The beneﬁts of
our proposed PoR mechanism are veriﬁed in the following
sections.

4 SYSTEM UTILITY FORMULATION AND PRO-
POSED MA-DRL ALGORITHM
In this section, we present the system utility formulation for
our proposed TOBM scheme based on the joint consider-
ation of ofﬂoading utility and mining utility as presented
in the previous sections. Then, we derive the system utility
optimization problem as a cooperative game and propose a
new MA-DRL algorithm to solve it.

4.1 System Utility Formulation

In this paper, we formulate the system utility for the TOBM
scheme by taking both ofﬂoading utility and mining utility
into account.

4.1.1 Ofﬂoading Utility

Here, we focus on formulating the QoE-aware ofﬂoading
utility function. In an MEC system, the ofﬂoading’s QoE is
mainly characterized by their task computation time, i.e.,
Tn and energy consumption, i.e., En. Speciﬁcally, Tn and
En can be speciﬁed as
Tn = T of f
En = Eof f

n xn + T l
n xn + El

n(1 − xn), ∀n ∈ N .

n(1 − xn), ∀n ∈ N ,

(13)

(14)

Accordingly, we deﬁne a QoE-aware utility function to
measure the ofﬂoading utility that is speciﬁed as a trade-
off between the time and energy consumption of the task
compared with local execution
(cid:33)

(cid:33)

(cid:32)

(cid:32)

n = λT
J of f
n

T l
n − Tn
T l
n

+ λE
n

El

n − En
El
n

,

(15)

n , λE

n + λE

n ∈ [0, 1] (with λT

where λT
n = 1, ∀n ∈ N ) are set
by ED n to show the preference on time and energy cost
when computing the task Yn. If the task is emergency, the
ED can increase the weighting factor of time consumption.
Meanwhile, if the ED is operating with low battery, the
factor of energy consumption should be preferred.

(cid:17)

(cid:16) T l

(cid:16) El

n−Tn
T l
n

It is noting that here, the ofﬂoading utility function
J of f
reﬂects the improvement in QoE over local execution,
n
that is measured by
, respectively.
and
Speciﬁcally, when the ED n executes the task locally, the
ofﬂoading utility equals 0 (i.e., J of f
n = 0). If the computation
cost (i.e., latency and energy consumption) of the ofﬂoading
mode is lower than that of the local execution mode, the
ofﬂoading utility (J of f
n ) can be positive, which indicates the
ofﬂoading’s QoE improvement. However, if ofﬂoading too

n−En
El
n

(cid:17)

many tasks, the EDs can suffer from higher latency due to
the trafﬁc congestion, which would reduce the QoE. As a
result, the ofﬂoading utility (J of f

n ) can be negative.

To this end, we formulate the QoE-aware ofﬂoading util-
ity for the MEC system. Given the ofﬂoading decision policy
X, the transmission power policy P , and the computational
resource allocation policy F , we deﬁne the ofﬂoading utility
as the weighted sum of all MDs’ ofﬂoading utilities J of f
n ,
denoted as:

J of f =

(cid:88)

n∈N

J of f
n (X, P , F ),

(16)

4.1.2 Mining Utility

We adopt the mining utility built in equation 10 to analyse
the efﬁciency of the mining in the blockchain-enabled task
ofﬂoading. Given the CPU resource allocation policy G,
each MEC server yields an utility J mine
when performing
the mining process. Then, we can specify the total mining
utility of EDs in the MEC system as

n

J mine =

(cid:88)

n∈N

J mine
n

(G).

(17)

Accordingly, the system utility of each MD Jn can be

expressed as

Jn = J of f

n + J mine

n

.

(18)

4.1.3 System Utility Formulation

In this paper, our objective is maximize the total system
utility as the sum of the ofﬂoading utility and the mining
utility for the proposed TOBM scheme:

maximize
X ,P ,F ,G

subject to

J of f + J mine

xk
n ∈ {0, 1}, ∀n ∈ N , k ∈ K,
(cid:88)

xk
n ≤ 1, n ∈ N ,

n , ∀n ∈ Nn, k ∈ K,

k∈K
n ≤ P k
0 < pk
0 < f l
n ≤ Fn, ∀n ∈ N ,
0 < φn ≤ Φn, ∀n ∈ Nn
Tn ≤ τn, ∀n ∈ N .

(19a)

(19b)

(19c)

(19d)

(19e)

(19f)

(19g)

Here, the constraints (19b) and (19c) imply that each task
can be either executed locally or ofﬂoaded to the MEC server
via a sub-channel. (19d) shows the transmission power con-
straint of each ED. The constraint (19e) states that each ED n
must allocate a positive computational resource to execute
the computing task, but not exceed the total computation
budget Fn. Each ED n also must allocate a positive CPU
resource for the block veriﬁcation under a maximum CPU
capability Φn, as indicated in (19f). Constraint (19g) ensures
that each data task needs to be completed under a delay
threshold.

The key intuition behind this integrated calculation is
that in the blockchain-based MEC system, each ED needs to
simultaneously perform task ofﬂoading and block mining.
In this context, the evaluation of the system quality, e.g.,
overall utility performance, must consider both ofﬂoading
utility and mining utility. Indeed, an ED needs to minimize
its ofﬂoading latency and energy consumption to maintain
the quality of task ofﬂoading service, while also minimizing

8

its mining latency to maintain the quality of block mining
service. Therefore, we come up with a ﬁnal solution to
satisfy both services, aiming to optimize the overall system
utility performance.

The problem 19 is non-convex and centralized. As a
dynamic TOBM problem (due to varying channel conditions
and task sizes) and high-dimensional system state space
(due to the increase of EDs), the use of traditional optimiza-
tion approaches results in high computational complexity
which would hinder the applicability of the proposed model
in practical blockchain-based MEC scenarios. Moreover,
most of current solutions [13], [14], [32] rely on single-agent
learning which suffers from some critical shortcomings:

• Dimensionality: The cardinalities of DNN input and
output are generally proportional to the number of EDs,
and thus the use of centralized learning to obtain the
optimal policy for all EDs is challenging. Moreover, ex-
ploration in high-dimensional state space is inefﬁcient
especially when the number of EDs increases exponen-
tially, which makes the learning in the blockchain-based
MEC system impractical.

• Information transmission: Since the centralized learning
always requires full information of all EDs (e.g., data
task state, resource state, block size state) for decision
making, the information transmission becomes chal-
lenging with the increase of EDs.

Due to the powerlessness of centralized learning algo-
rithms in the multi-agent environment like our considered
blockchain-based MEC system, we propose to use a dis-
tributed MA-DRL scheme to solve our cooperative TOBM
problem, as presented in the following sub-sections.

4.2 Cooperative Learning Formulation

First, we convert the objective function 19a from a system
utility maximization problem to a reward maximization
problem. To do this, we formulate the task ofﬂoading prob-
lem using a multi-agent version of MDP, also known as a
Markov game which is denoted by a tuple < N , S, A, O >.
Here, each ED n is considered as an intelligent agent to learn
its optimal policy by observing the TOBM environment
and collaborating with other agents, aiming to achieve the
optimal system utility. Then, we have N = {1, 2, ..., N } as
the set of EDs (or agents). Moreover, S = {s1, s2, ..., sN }
is deﬁned as the set of states, A = {a1, a2, ..., aN } is a set
of agent actions, and O = {o1, o2, ..., oN } denotes a set of
observations for agents. We assume that the considered co-
operative TOBM scheme operates on discrete time horizon
with each time slot t equal and non-overlapping, and the
communication parameters keep unchanged during each
time slot. Now we deﬁne each item in the tuple at each
time slot t as follows.

4.2.1 State
The environment states in the cooperative TOBM network
include ﬁve components: task state Stask(t), channel state
Schannel(t), power state Spower(t), resource state Sres(t),
and transaction state Strans(t). Therefore, the system state
is deﬁned as a matrix:

S(t) = {Stask(t), Schannel(t), Spower(t), Sres(t), Strans(t)},
(20)

where each state vector is explained as follows. Stask(t) is
deﬁned as Stask(t) = [Dn(t), Cn(t)], n ∈ N where Dn(t)
represents the computation task size of the ED n and Cn(t)
is the required input CPU cycles number to complete the
task data Dn(t). Schannel(t) is deﬁned as:

Schannel(t) = ck

n(t) =






c1,1
...
cN,1

· · ·
. . .
· · ·




 ,

c1,K
...
cN,K

(21)

9

n(t) indicates whether the sub-channel k is used by
n(t) = 0.

n(t) = 1, otherwise ck

where ck
ED n at time slot t. If yes, ck
Also, Spower(t) is deﬁned as:


Spower(t) = pk

n(t) =




p1,1
...
pN,1

p1,K
· · ·
...
. . .
· · · pN,K




 ,

(22)

where pk
n(t) represents the ED n’s transmit power level in
the kth sub-channel, which is a continuous variable and
satisﬁes 0 < pk
n . Moreover, the resource state
Sres(t) is expressed as

n(t) ≤ P k

Sres(t) = {v1(t), v2(t), ..., vN (t)},

(23)

where vn(t) contains the states of current available compu-
tational resource f l
n(t) and CPU resource φn(t) of the ED n.
Lastly, the transaction state Strans(t) is deﬁned as

Strans(t) = {T r1(t), T r2(t), ..., T rN (t)},

(24)

where T rn(t) is the transaction state of ED n.

4.2.2 Action

By observing the system states, each ED needs to make
actions in each time step to deal with the task execution
and block mining, including ofﬂoading decision, channel
selection, transmit power selection, computational resource
allocation, and CPU resource allocation. Accordingly, the
action space can be expressed as
n(t), k(t), pk
A(t) = {xk

n(t), φn(t)},

n(t), f l

(25)

where each action compopent is explained as follows:

n(t): xk

• Ofﬂoading decision xk

n(t) ∈ {0, 1}, (n ∈ N , k ∈
K). Each ED n makes decision to execute the task locally
xk
n(t) = 0 or ofﬂoad it to the MEC server xk
n(t) = 1 via
the channel k, based on the current task state Stask(t).
• Channel selection k(t): k(t) = [1, 2, ..., K]. Each ED n
selects one of the available channels to ofﬂoad the task
to the MEC server, based on the current channel state
Schannel(t).

n(t): pk

• Transmit power selection pk

n ], (n ∈
Nn, k ∈ K). Each ED n chooses a transmit power
value to transmit the data task to the MEC server with
respect to the current task state Stask(t) and channel
state Schannel(t).

n(t) ∈ (0, P k

1(t), f l

2(t), ..., f l

• Computational resource allocation f l

n(t) =
[f l
N (t)]. Each ED n allocates part of its
computational resource to execute the task with respect
to the current resource state Sres(t) and task state
Stask(t).

n(t): f l

• CPU

=
[φ1(t), φ2(t), ..., φN (t)]. Each ED n allocates part of

allocation

resource

φn(t):

φn(t)

Fig. 4: The proposed MA-DDPG architecture.

its CPU resource to verify the blockchain transaction,
resource state Sres(t) and
based on the current
transaction state Strans(t).

4.2.3 System Reward Function
The system reward at one time slot t is the sum of the re-
wards of all EDs. Each ED n will get a reward r(sn(t), an(t))
in a certain state sn(t) after executing each possible action
an(t). In our paper, the system reward function should
be positively correlated to the objective function in the
optimization problem 19, aiming to maximize the system
utility of all EDs. Then, we can specify the system reward
function of our ofﬂoading network at each time slot t as

r(s(t), a(t)) =

(cid:88)

n∈N

r(sn(t), an(t)) = J(t),

(26)

where J(t) = J of f (t) + J mine(t) is the total system utility
of the blockchain-based MEC system.

4.3 Proposed MA-DRL Algorithm for Cooperative
TOBM

In the cooperative TOBM problem in our blockchain-based
MEC system, conventional single-agent [13], [14], [32] or
independent multi-agent [17]–[19] solutions are unable to
obtain the cooperative policies of EDs due to the nonsta-
tionary and partially observable environment. Indeed, when
policies of other agents change (i.e., due to computation
mode preference), the ED (agent) n observation On can be
changed (nonstationary), which makes the obtained reward
rn(t) different from the accumulated reward from its ac-
tual state-action pair. Moreover, in independent multi-agent
learning schemes, the agent n only has the local information
and cannot know the updates from other agents due to non-
collaboration. This would affect the agent n’s reward rn(t)
and make the learning algorithms hard to ensure stable
convergence [40]. Therefore, we adopt a centralized learning
and decentralized execution solution to implement our MA-
DRL algorithm for the proposed TOBM scheme.

4.3.1 Preliminaries of Reinforcement Learning

In RL, an agent takes some actions to obtain rewards
through the trial and error procedure according to a pre-
deﬁned MDP, aiming to accumulate experience as much
as possible to construct an optimal policy. Speciﬁcally, the
state-action function can be updated using the agent n’s

Task Offloading and Block Mining Environment Agent NActorCriticLoss function𝑄𝑁𝜋Update𝑠𝑁Replay Memory Agent 2𝑎𝑁(𝑶,𝑆,𝐴)…Agent N-1𝑟𝑁UpdateAgent 1 (Edge Device)ActorPolicy gradient𝑄1𝜋Update𝑠1𝑎1(𝑶,𝑆,𝐴)𝑟1UpdateLoss function  (𝑶,𝑆,𝐴,𝑅,𝑆′)Critic𝜵𝜽𝑵𝑳(𝜽𝑵)𝑳(𝜽𝟏)Policy gradient𝜵𝜽𝟏experience tuple (sn(t), an(t), rn(t), sn(t + 1)) at each time
step t as

Q(sn(t), an(t)) ← Q(sn(t), an(t)) + ασ(t),

(27)

which is called as the Q-learning algorithm [32], where σ(t)
is a temporal difference (TD) error that would be zero for the
optimal Q-value, α is the learning rate, and γ is the discount
factor between (0, 1).

4.3.2 Proposed MA-DDPG Algorithm

Here, we present an MA-DRL approach using an MA-
DDPG algorithm to solve the cooperative TOBM problem
in the blockchain-based MEC system, as illustrated in Fig. 4.
Different from RL, DRL uses a DNN as the non-linear ap-
proximator to sample the loss function at each training step
in order to alleviate the computational complexity for the
large-scale ofﬂoading problem. Here, agents cooperatively
ofﬂoad their tasks to the MEC server and perform mining
to form a shared learning environment consisting of all EDs
and the MEC server. In the centralized training step, the
information of state-action of all EDs is aggregated by the
MEC server to train the DRL model where each agent can
obtain the global view of the learning environment to learn
collaboratively with other agents. This makes the learning
environment stationary and thus enhances the convergence
performance. After training at the MEC server, the learned
parameters are downloaded to each of EDs to execute the
model for decision making based on its own locally ob-
served information.

We denote π = {π1, π2, ..., πN } as the set of all agent
policies and θ = {θ1, θ2, ..., θN } as the parameter set of
corresponding policies. Every agent updates its parameters
θn to obtain the optimal policy π∗
= argmaxθn J(θn),
θn
where J(θn) is the objective function (also the expected
reward) of agent n as deﬁned in equation 26. MA-DDPG is
a deterministic policy gradient-based off-policy actor-critic
operating over continuous action spaces in a multi-agent
environment. Here, the actor generates deterministic action
a over time slots with a behavior network and the critic
evaluates the behavior of the actor with a target network.
In the training, the actor updates the behavior network by
computing the gradient of the objective function J(θn) as
(cid:53)θn J(πn) = Eo,a∼D [(cid:53)θnQπ

n(o, a1, ..., aN ). (cid:53)θn πn(an|on)] ,
(28)
with (o = {o1, ..., oN })
the observation set,
Qπ
n(o, a1, ..., aN ) is a centralized action-value function of
the agent n with a1, a2, ..., aN as the actions of all agents
and is learned separately for each n ∈ N . Also, D is the
memory buffer for experience replay, containing multiple
episode samples (o, a, r, o(cid:48)). Moreover, the critic updates the
behavior Q-function Qπ
n() in a fashion that minimizes the
loss function, which is written as

as

(cid:2)(yn − Qπ
n(o(cid:48), a(cid:48)
1, a(cid:48)

n(o, a1, a2, ..., aN ))2(cid:3) ,
2, ...a(cid:48)
n=π(cid:48)

L(θn) = Eo,a,r,o(cid:48)
(29)
where yn = rn +γQπ
n(on) is the is TD
target and π(cid:48)
n(on) deﬁnes the target policies with delayed
parameters θ(cid:48)
n. The training procedure is summarized in Al-
gorithm 2. Here, the procedure consists of two main phases,
the planning phase and the updating phase. In the planning
phase, we use an (cid:15)-greedy policy to balance the exploration

N )|a(cid:48)

10

and exploitation for updating the Q function (line 7). At
each time epoch, each ED executes an action and estimates
the system reward, i.e., system utility, and stores training
information in the replay memory (lines 8-10). After each
action, the ED moves to the next step, updates the critic and
actor networks as well as corresponding target networks
(lines 11-17). The training is iterated until achieving the
desired system reward performance.

We can see that the update of θn of the target network
in the policy gradient method (cid:53)θn would guide how the
agent ED acts correctly to obtain the optimal policy. It
is based on the fact that that the value of DNN in the
target actor network is ﬁxed for several iterations, and the
weights θn of the DNN in the actor behavior network are
updated. In other words, all agent EDs in the blockchain-
based MEC system can maximize their expected function
J(θn) (i.e., user utility) and obtain stable policies even via
interactions between EDs and the environment. This makes
the learning environment stationary even when the policies
πn change, which would enhance the quality of policy
evaluation for improving the overall system utility. After
the training is completed, EDs download the learned policy
network parameters from the MEC server and update the
target network parameters for the actor and critic as

j ← ζθj + (1 − ζ)θ(cid:48)
θ(cid:48)
j,

(30)

where ζ ∈ (0, 1) is the update step.

4.3.3 Computational Complexity Analysis
In our MA-DRL algorithm, the training process is imple-
mented in the MEC server with sufﬁcient computational
resource. Therefore, we mainly focus on the computational
complexity of the execution process at EDs. Here, a DRL
agent with a DNN is established for each ED and all DNNs
run in parallel across the MEC network. As a result, the
overall complexity of the multi-agent system can be deter-
mined by the complexity of a single DNN at an ED. We
assume that are K neurons at the input layer of the DNN
for each ED, and Z as the number of neurons at the output
layer. Also, the hidden layer is L, and the number of neurons
at hidden layers is H. Accordingly, the computation cost at a
DNN is (KH +(L−1)HH +HZ) =O(H(K+(L−1)H +Z)).
Also, the complexity of using activation function is O(HL).
Hence, the total complexity is O(H(K + HL − H + Z + L))
which can be simpliﬁed as O(H(K + HL + Z)).

4.4 Cooperative Game-theoretic Solution

We next develop a game-theoretic approach for the pro-
posed TOMB problem, where each ED can act as a game
player to react to other players’ decisions for maximizing
its utility [41], [42]. After a number of steps, all the EDs
self-organize into a mutual equilibrium state, i.e., the Nash
equilibrium, at which no ED can further increase its utility
by unilaterally altering its strategy.

G

as

We

ﬁrst

game

deﬁne

=
the
{N , {An}n∈N , {Jn}n∈N }, where N is the set of rational
game players, An is the strategy set for player n, and Jn is
the utility function of ED n. Let denote an as the ofﬂoading
decision proﬁle of the player n over the wireless sub-bands
K, from 18 we can rewrite as
Jn(an) = J of f

n I{an=1} + J mine

(31)

n

,

Algorithm 2 The MA-DDPG training procedure in the
blockchain-based MEC system

Proof: We ﬁrst prove that the proposed game G is an exact
(cardinal) potential game with potential function

11

1: Input: Replay memory D, time budget T , exploration

probability (cid:15), discount factor γ, update step ζ

2: Output: The optimal policy π∗

θn and maximum reward

r∗(s, a)

3: Initialization: Initialize the deep Q network Q(s, a)
with random weight θ and θ(cid:48), initialize the exploration
probability (cid:15) ∈ (0, 1)
4: for episode = 1,..., M do
5:

←

s0

Initialize
the
{Stask(t), Schannel(t), Spower(t)}|t=0
for t = 1, 2, ..., T do

state

For each agent ED j ∈ N , select a random ac-
tion aj(t) with probability (cid:15), otherwise aj(t) =
πθj (sj(t))
Execute actions a(t) = (a1(t), a2(t), ..., aN (t)) by
performing ofﬂoading decision xk
n(t), channel se-
lection k(t), transmit power selection pk
n(t), compu-
tational resource allocation f l
n(t), and CPU resource
allocation φn(t)
Observe the system reward r(t) via 26 and the new
state s(cid:48)
Store (s(t), a(t), r(t), s(cid:48)(t)) into the memory D
for agent j = 1 to N do

(cid:104)

of

j (oj )

j =π(cid:48)

j, a(cid:48)

N )|a(cid:48)

2, ...a(cid:48)

transitions

random mini-batch
j) from D
j (s(cid:48)

Sample
(sj, aj, rj, s(cid:48)
Set yj = rj + γQπ
1, a(cid:48)
Update behavior critic by minimizing the loss:
L(θj) = 1
S
Update
pled
(cid:104)
1
S
end for
Update the target network parameters for each
agent via 30

(cid:105)
j, a1, a2, ..., aN ). (cid:53)θj πj(aj|sj)

using
the
gradient: (cid:53)θj J(πj)

j (sj, a1, a2, ..., aN )

yj − Qπ
by

policy
j (s(cid:48)

(cid:80)
j
actor

sam-
=

(cid:53)θj Qπ

(cid:105)2

6:
7:

8:

9:

10:
11:
12:

13:
14:

15:

16:
17:

end for

18:
19: end for

where Iz is an indicator function. If z is true, Iz = 1;
otherwise, Iz = 0. Based on 18 and 31, the utility of a player
n in the cooperative game can be expressed as

J(an, a−n) =

(cid:40)

J mine
,
n
n + J mine
J of f

n

an = 0
, an = 1

,

(32)

where a−n is the ofﬂoading decisions of all players exept n.
Accordingly, by considering the inﬂuence of other players
on the utility optimization of a player n in the cooperative
game, we can express the game-theoretic utility function as



,

J mine

J(an,a−n)=

+J mine
n

n
(cid:80)

(an),

m#n(J of f

n (an)+J of f

m (am))I{am=an }

an=0

an=1

(33)

where m ∈ N \{n}.
Theorem
1:
{N , {An}n∈N , {Jn}n∈N } has
(NE) and guarantees the ﬁnite improvement property.

=
a pure Nash equilibrium

collaborative

game

The

G

Ψ(an, a−n) =

(cid:88)

(cid:88)

(J of f

n + J of f

m )I{am=an}I{an=1}

I{an=1} +

(cid:88)

n∈N

J mine
n

I{an=0},

(34)

1
2

m#n

n∈N
J mine
n

(cid:88)

+

n∈N

such that

Ψ(a(cid:48)

n, a−n) − Ψ(an, a−n) = J(a(cid:48)

n, a−n) − J(an, a−n),
∀an, a−n ∈ An.

(35)

We now consider three cases as follows:
Case 1: an > 0, a(cid:48)
n > 0

Ψ(a(cid:48)

n, a−n) − Ψ(an, a−n)
(cid:16)
n (a(cid:48)
J of f

(cid:88)

=

1
2

n) − J of f

(cid:17)
n (am)

I{am=a(cid:48)

n}

+

1
2

(cid:88)

(cid:16)

m#n

−

1
2

m#n

n (am) − J of f
J of f

n (a(cid:48)

(cid:17)
n)

I{a(cid:48)

n=am} + J mine

n

(a(cid:48)

n)

n (an) − J of f
J of f

n (am)

(cid:17)

I{am=an}

(cid:88)

(cid:16)

m#n

(cid:88)

(cid:16)

n (am) − J of f
J of f

n (an)

(cid:17)

I{an=am}+J mine

n

(an)−J mine

n

(an)

−

1
2

m#n
(cid:88)

=

(cid:16)

n (a(cid:48)
J of f

n) + J of f

(cid:17)
m (am)

I{am=a(cid:48)

n} + J mine

n

(a(cid:48)

n)

−

m#n
(cid:88)

m#n

(cid:16)
n (an) + J of f
J of f

(cid:17)
m (am)

I{am=an} − J mine

n

(an)

= J(a(cid:48)

n, a−n) − J(an, a−n).

(36)

Case 2: an = 0, a(cid:48)

n > 0

Ψ(a(cid:48)

n, a−n) − Ψ(an, a−n)
(cid:16)
n (a(cid:48)
J of f

(cid:88)

=

1
2

m#n

n) − J of f

(cid:17)
n (am)

I{am=a(cid:48)

n}

+

1
2

=

(cid:88)

(cid:16)

n (am) − J of f
J of f

n (a(cid:48)

n)

(cid:17)

I{a(cid:48)

n=am}+J mine

n

(a(cid:48)

n)−J mine
n

m#n
(cid:16)
(cid:88)

n (a(cid:48)
J of f

n) + J of f

(cid:17)
m (am)

I{am=a(cid:48)

n}+J mine

n

(a(cid:48)

n)−J mine
n

m#n

Case 3: an > 0, a(cid:48)

n = 0

= J(a(cid:48)

n, a−n) − J(an, a−n).

(37)

Ψ(a(cid:48)

Similar to Case 2, it is also straightforward to prove that
n, a−n) − Ψ(an, a−n) = J(a(cid:48)
Therefore, the game G is an exact potential game with
the potential function given in 34. Finally, according to the
potential game theory [41], our proposed collaborative game
G has an NE and possesses the ﬁnite improvement property.

n, a−n) − J(an, a−n).

5 SIMULATIONS AND PERFORMANCE ANALYSIS

In this section, we perform extensive simulations to verify
the performance of the proposed TOBM scheme.

TABLE 2: Simulation parameters.

Fig. 5: Illustration of the MEC network with an MEC server
and distributed mobile phones.

5.1 Simulation Setting

We here leverage the widely used mobile wireless dataset
provided by Shanghai Telecom1 for numerical simulations.
We select maximum 500 mobile phones as EDs and an MEC
server in a sub-area of Shanghai city with the geographical
distribution as illustrated in Fig. 5. Moreover, IoT sensor
data traces from location services [43] collected during 6
months in 2014 are selected as data tasks for task ofﬂoading
simulations. Inspired by [11], [13], [14], [32], our simulation
parameters are conﬁgured as in Table 2.
Moreover, the channel gains hk

n are generated using
distance-dependent path-loss model L[dB] = 140.7 +
36.7log10d[km]. For the proposed multi-agent DRL algo-
rithm, the discount factor γ equals 0.85 and the replay
memory capacity and training batch size are set to 105
and 128, respectively. The update step ζ in the critic-actor
training is set to 0.8. The used DNN structure has three
hidden layers (64, 32 and 32 neurons) with ReLU as the acti-
vation function and Adam as the optimizer. For blockchain
mining, we set up 10 transactions per block and vary the
numbers of mining nodes (i.e., EDs) from 2 to 100. The

1. http://www.sguangwang.com/dataset/telecom.zip

12

other mining parameters are included in Table 2. The results
from simulation are averaged from 50 runs of numerical
simulations.

5.2 Evaluation of Training Performance

We ﬁrst evaluate the training performance of our proposed
algorithm. To prove the advantage of the proposed coop-
erative MA-DDPG algorithm, we compare its performance
with the state-of-the-art non-cooperative schemes, includ-
ing DDPG, actor-critic [26] and DQN [18]. Here, DDPG
and actor-critic are policy-based algorithms where each ED
agent only observes the local information and does not the
information of other EDs during the training. Meanwhile,
DQN is a value-based algorithm where each ED also has no
information of other EDs.

Fig. 6(a) shows the performance of average system re-
ward with different learning rates α. It can be seen that the
learning rate affects the learning rewards over the training
episodes. That is, when the learning rate decreases, the con-
vergence performance of the proposed algorithm decreases
due to slow learning speed. Based on our experimental
results, the learning value α = 0.01 yields the best reward
performance and has good convergence rate and thus we
use it in the following system simulations and evaluations.
Fig. 6(b) shows the learning curves of the average system
reward with the increase of episodes for an MEC system
with 50 EDs. It is clear that our MA-DDPG scheme is
more robust and yields the best performance in terms of
average system reward, compared to the baseline schemes.
This is because the proposed scheme allows EDs to learn
mutually the cooperative policy which helps reduce the
channel congestion and user interference, and enhance
computational resource efﬁciency for improving the overall
system reward. Meanwhile, in the DQN and actor-critic
schemes, EDs greedily access the wireless channel spectrum
to maximize their own utility as much as possible without
collaborating with each other, which increases the possibil-
ity of channel collision and thus results in higher ofﬂoading
latency. Consequently, the average system reward becomes
worse. Although the DDPG scheme shows a better reward
performance than these two schemes, it still remains a non-
stationary learning issue and its average reward is lower
than that of the MA-DDPG scheme.

5.3 Evaluation of Task Ofﬂoading Utility

Next, Fig. 7(a) indicates the performance of average ofﬂoad-
ing utility versus the different numbers of ofﬂoaded EDs. It
can be seen that when the number of EDs is small (< 60),
the average ofﬂoading utility increases with the number
of EDs because in this case, the MEC system can support
sufﬁcient spectrum and computing resources to handle all
tasks ofﬂoaded from EDs. However, after exceeding some
thresholds (e.g., N = 60 EDs), the system utility decreases
because the higher the number of ofﬂoaded EDs, the higher
the competition of resource usage (i.e., channel spectrum).
Note that the conﬁgured number of sub-bands K = 30 is
relatively low with respect to the increase in the number
of EDs, thus the channel bandwidth allocated for each ED
decreases when there are more EDs in the system. In turn,
this increases the ofﬂoading latency and thus, degrades

13

(a) Comparison of average system rewards with different learn-
ing rates.

(b) Comparison of average system rewards with different algo-
rithms.

Fig. 6: Evaluation of training performance.

(a) Average ofﬂoading utility with different numbers of EDs.

(b) Average ofﬂoading utility with different IoT data task sizes.

Fig. 7: Evaluation of task ofﬂoading performance.

the overall ofﬂoading utility. Nevertheless, our MA-DDPG
scheme still achieves the best utility performance due to
its cooperative ofﬂoading policies among EDs compared to
the other schemes with selﬁsh learning. For instance, in the
case of 100 EDs, the average ofﬂoading utility of the MA-
DDPG scheme is 22.5%, 37.5%, and 43.6% higher than those
of the DDPG, actor-critic, and DQN schemes, respectively.
These results also imply that as the EDs number increases,
the cooperative policy learned by MA-DDPG becomes more
important in the cooperative edge task ofﬂoading.

Moreover, we evaluate the effect of different task sizes
on the average ofﬂoading utility as shown in Fig. 7(b). We
ﬁnd that a higher task size results in a higher ofﬂoading
utility. Speciﬁcally, when the task size is relatively high
(> 2MB), the ofﬂoading utility increases signiﬁcantly. The
reason is that the edge computation mode becomes more
efﬁcient than the local execution mode in terms of lower
computing cost in handling the larger-size tasks due to the
high MEC capability. This leads to the increase of the user
utility Jn which thus enhances the system-inter utility J .

Particularly, when the task size increases, the advantage of
the proposed MA-DDPG scheme over the baselines become
more profound, with the larger performance gaps and better
utilities. For example, as the task size is 3.5 MB, the pro-
posed MA-DDPG scheme achieves 30%, 24.5% and 21.7%
higher ofﬂoading utilities compared with the DDPG, actor-
critic, and DQN schemes, respectively.

5.4 Evaluation of Blockchain Performance

Here, we evaluate the performance of our proposed PoR
consensus scheme via numerical simulations using Python
programming and compare it with the traditional DPoS
scheme [38] via the veriﬁcation block latency and band-
width usage metrics.

We ﬁrst show the block veriﬁcation latency performance
versus different numbers of mining nodes with the block
size ﬁxed at 50 KB and compare with the traditional DPoS
scheme [38]. As illustrated in Fig. 8(a), our proposed PoR
scheme requires signiﬁcantly less time for mining blocks,
compared to the DPoS scheme thanks to the optimized block

0500100015002000Training episodes234567Average System RewardLearning rate = 0.01Learning rate = 0.001Learning rate = 0.00010500100015002000Training episodes01234567Average System RewardProposed MA-DDPG schemeDDPG schemeActor-critic schemeDQN scheme20406080100Number of EDs123456789Average Offloading UtilityProposed MA-DDPG schemeDDPG schemeActor-critic schemeDQN scheme11.522.533.5Task Input Size (MB)2345678910Average Offloading UtilityProposed MA-DDPG schemeDDPG schemeActor-critic schemeDQN scheme14

(a) Comparison of block veriﬁcation latency.

(b) Comparison of network bandwidth cost.

Fig. 8: Evaluation of blockchain performance.

veriﬁcation procedure. Although the time required for block
veriﬁcation increases with the increasing number of min-
ers, our solution still achieves a much better performance
than that of the DPoS scheme. This result conﬁrms our
lightweight consensus design that is thus well suitable for
large-scale blockchain-based MEC systems.

Next, Fig. 8(b) indicates the simulation result in terms
of network bandwidth cost spent by the mining process for
different data block sizes from 50 KB to 500 KB in the edge
blockchain network. Due to the optimized block exchange
procedure where each ES only needs to contact with one
different miner for transaction veriﬁcation, instead of using
a repeated process, our PoR scheme can save much network
bandwidth resources, compared to the DPoS scheme [38].

5.5 Evaluation of Overall System Utility Performance

In this subsection, we evaluate the performance of the
overall system utility of our TOBM scheme enabled by the
joint consideration of ofﬂoading utility and mining utility.
The performances of our cooperative scheme with our PoR
mining design and other non-cooperative schemes with PoR
and DPoS mining are illustrated in Fig. 9. Unsurprisingly,
our TOBM scheme with a PoR mining design achieves the
best overall system utility. The reasons for this observation
are two-fold. First, our ofﬂoading scheme with a cooperative
MA-DDPG algorithm outperforms other non-cooperative
ofﬂoading schemes in terms of a better ofﬂoading utility, as
evidenced in Fig. 7. Second, our PoR design yields a lower
mining latency which consequently increases the mining
utility, as explained in Section 3.1.1. As a result, our scheme
with a cooperative ofﬂoading design and a lightweight
mining design achieves a much better overall system utility
than the other non-cooperative ofﬂoading schemes with
DPoS design. Moreover, due to its better mining utility, our
PoR design contributes to better overall system utilities in
each non-cooperative ofﬂoading scheme, compared to the
use of DPoS design.

Furthermore, we compare the system utility perfor-
mance of our cooperative TOBM scheme with other co-
operative schemes, including a cooperative scheme with

Fig. 9: Comparison of system utility with non-cooperative
schemes.

Fig. 10: Comparison of system utility with cooperative
schemes.

020406080100Number of Mining Nodes (EDs)0500100015002000Block Verification Latency (ms)Proposed PoR schemeTraditional DPoS scheme100200300400500Data Block Size(KB)0.20.40.60.811.21.41.6Network Bandwidth Cost (Mbps)Proposed PoR schemeTraditional DPoS scheme102030405060Number of EDs4681012Average System UtilityOur cooperative scheme with PoRDDPG scheme with PoRActor-critic scheme with PoRDQN scheme with PoRDDPG scheme with DPoSActor-critic scheme with DPoSDQN scheme with DPoS102030405060Number of EDs4681012Average System UtilityOur cooperative scheme with PoRCooperative scheme with DPoSCooperative scheme without mining design15

(a) Average system utility with different numbers of EDs.

(b) Average system utility with different IoT data task sizes.

Fig. 11: Comparison of learning and game-theoretic approaches.

DPoS design [27] and a cooperative scheme without mining
design [26]. As shown in Fig. 10, our TOBM scheme with
PoR design achieves a better system utility than the cooper-
ative scheme with DPoS design, thanks to the better mining
utility of our PoR framework. Meanwhile, the cooperative
scheme in [26] has lowest system utility due to the lack of
consideration of mining design.

5.6 Comparison of Learning and Game-theoretic Ap-
proaches

Next, we compare the utility performance between the MA-
DRL scheme and the game-theoretic scheme, where the
DQN scheme is used as the baseline, after averaging the
results from 5 simulations. As shown in Fig. 11(a), the game-
theoretic approach can achieve the optimal system utility,
compared to the MA-DRL scheme, when increasing the
number of MDs. This is because in the game approach,
each MD can obtain the full knowledge of other MDs’ infor-
mation such as the information of ofﬂoading decisions and
mining status via the collaborative interactions. This allows
each MD to determine the optimal computation ofﬂoading
strategy to achieve the converged point of NE. Meanwhile,
the MA-DRL scheme can also achieve reasonably close
results, where the physical parameters of MDs are time-
varying, and each MD can compute the approximately opti-
mal computation ofﬂoading strategy without requiring any
prior information about other MDs. Similar performances
can also be seen in Fig. 11(b), when increasing the size of
task inputs.

6 CONCLUSIONS AND FUTURE WORKS

In this article, we have proposed a novel cooperative TOBM
scheme to enable a joint design of task ofﬂoading and
blockchain mining in blockchain-based MEC systems. First,
we have proposed a new cooperative ofﬂoading framework
that enables EDs to learn ofﬂoading policies in a collabo-
rative manner. Then, we have designed a new PoR mining
scheme enabled by a lightweight block veriﬁcation strategy.
To this end, we have formulated a joint ofﬂoading and

mining optimization problem which is solved by an MA-
DRL algorithm. We then derived a game-theoretic solution
to model the competition among EDs in ofﬂoading and
mining as a potential game, and proved the existence of
a pure Nash equilibrium. Simulation results have clearly
showed the signiﬁcant advantages of our proposed scheme
over the existing schemes in terms of higher system rewards
with better ofﬂoading utility and lower blockchain costs
which thus enhance the overall system utility.

Our proposed approach has potential for future intel-
ligent mobile networks, where EDs are able to build dis-
tributed intelligent solutions via our cooperative DRL model
for enabling intelligent computation, communications and
network control [44]. In future work, it is of interest to con-
sider fair resource allocation strategies for simultaneously
supporting the edge computation and blockchain services.
The tradeoff between mining security and latency should
be also studied to strike a beneﬁcial balance between these
two important design factors before integrating into MEC.
Moreover, resource trading solutions should be developed
to enable reliable energy purchase for resource-constrained
edge nodes in blockchain-based MEC systems.

REFERENCES

[1] H. Guo, J. Liu, J. Ren, and Y. Zhang, “Intelligent Task Ofﬂoading
in Vehicular Edge Computing Networks,” IEEE Wireless Commu-
nications, vol. 27, no. 4, pp. 126–132, Aug. 2020.

[2] H. Guo and J. Liu, “UAV-Enhanced Intelligent Ofﬂoading for
Internet of Things at the Edge,” IEEE Transactions on Industrial
Informatics, vol. 16, no. 4, pp. 2737–2746, Apr. 2020.

[3] P. A. Apostolopoulos, G. Fragkos, E. E. Tsiropoulou, and S. Pa-
pavassiliou, “Data Ofﬂoading in UAV-assisted Multi-access Edge
Computing Systems under Resource Uncertainty,” IEEE Transac-
tions on Mobile Computing, pp. 1–1, 2021.
J. Kang, Z. Xiong, D. Niyato, D. Ye, D. I. Kim, and J. Zhao, “To-
ward Secure Blockchain-Enabled Internet of Vehicles: Optimizing
Consensus Management Using Reputation and Contract Theory,”
IEEE Transactions on Vehicular Technology, vol. 68, no. 3, pp. 2906–
2920, 2019.

[4]

[5] Z. Xiong, Y. Zhang, D. Niyato, P. Wang, and Z. Han, “When
Mobile Blockchain Meets Edge Computing,” IEEE Communications
Magazine, vol. 56, no. 8, pp. 33–39, Aug. 2018.

102030405060Number of EDs4681012Average System UtilityOur MA-DRL schemeThe game-theoretic schemeThe baseline scheme with DQN11.522.533.5Task Input Size (MB)246810Average System UtilityOur MA-DRL schemeThe game-theoretic schemeThe baseline scheme with DQN[6]

[7]

[8]

S. Guo, X. Hu, S. Guo, X. Qiu, and F. Qi, “Blockchain Meets Edge
Computing: A Distributed and Trusted Authentication System,”
IEEE Transactions on Industrial Informatics, vol. 16, no. 3, pp. 1972–
1983, Mar. 2020.
J. Kang, R. Yu, X. Huang, M. Wu, S. Maharjan, S. Xie, and Y. Zhang,
“Blockchain for Secure and Efﬁcient Data Sharing in Vehicular
Edge Computing and Networks,” IEEE Internet of Things Journal,
vol. 6, no. 3, pp. 4660–4670, Jun. 2019.
J. Guo, X. Ding, and W. Wu, “Reliable Trafﬁc Monitoring Mecha-
nisms Based on Blockchain in Vehicular Networks,” IEEE Transac-
tions on Reliability, pp. 1–11, 2021.

[9] C. Wang, C. Liang, F. R. Yu, Q. Chen, and L. Tang, “Computation
Ofﬂoading and Resource Allocation in Wireless Cellular Networks
With Mobile Edge Computing,” IEEE Transactions on Wireless
Communications, vol. 16, no. 8, pp. 4924–4938, Aug. 2017.

[10] Z. Kuang, L. Li, J. Gao, L. Zhao, and A. Liu, “Partial Ofﬂoading
Scheduling and Power Allocation for Mobile Edge Computing
Systems,” IEEE Internet of Things Journal, vol. 6, no. 4, pp. 6774–
6785, Aug. 2019.

[11] J. Zhao, Q. Li, Y. Gong, and K. Zhang, “Computation Ofﬂoad-
ing and Resource Allocation For Cloud Assisted Mobile Edge
Computing in Vehicular Networks,” IEEE Transactions on Vehicular
Technology, vol. 68, no. 8, pp. 7944–7956, Aug. 2019.

[12] D. C. Nguyen, P. N. Pathirana, M. Ding, and A. Seneviratne,
“Deep Reinforcement Learning for Collaborative Ofﬂoading in
Heterogeneous Edge Networks,” in 2021 IEEE/ACM 21st Interna-
tional Symposium on Cluster, Cloud and Internet Computing (CCGrid).
Melbourne, Australia: IEEE, May 2021, pp. 297–303.

[13] Y. Liu, H. Yu, S. Xie, and Y. Zhang, “Deep Reinforcement Learning
for Ofﬂoading and Resource Allocation in Vehicle Edge Com-
puting and Networks,” IEEE Transactions on Vehicular Technology,
vol. 68, no. 11, pp. 11 158–11 168, Nov. 2019.

[14] D. C. Nguyen, P. N. Pathirana, M. Ding, and A. Seneviratne,
“Privacy-Preserved Task Ofﬂoading in Mobile Blockchain with
Deep Reinforcement Learning,” IEEE Transactions on Network and
Service Management, vol. 17, no. 4, pp. 2536–2549, Jul. 2020.
[15] Y. Yu, S. C. Liew, and T. Wang, “Multi-Agent Deep Reinforcement
Learning Multiple Access for Heterogeneous Wireless Networks
with Imperfect Channels,” IEEE Transactions on Mobile Computing,
pp. 1–1, Feb. 2021.

[16] X. Xu, X. Zhang, H. Gao, Y. Xue, L. Qi, and W. Dou, “BeCome:
Blockchain-Enabled Computation Ofﬂoading for IoT in Mobile
Edge Computing,” IEEE Transactions on Industrial Informatics,
vol. 16, no. 6, pp. 4187–4195, Jun. 2020.

[17] J. Heydari, V. Ganapathy, and M. Shah, “Dynamic Task Ofﬂoading
in Multi-Agent Mobile Edge Computing Networks,” in 2019 IEEE
Global Communications Conference (GLOBECOM), Waikoloa, HI,
USA, Dec. 2019, pp. 1–6.

[18] Y. Zhang, B. Di, Z. Zheng, J. Lin, and L. Song, “Joint Data
Ofﬂoading and Resource Allocation for Multi-Cloud Heteroge-
neous Mobile Edge Computing Using Multi-Agent Reinforcement
Learning,” in 2019 IEEE Global Communications Conference (GLOBE-
COM), Waikoloa, HI, USA, Dec. 2019, pp. 1–6.

[19] X. Liu, J. Yu, and Y. Gao, “Multi-agent Reinforcement Learning
for Resource Allocation in IoT networks with Edge Computing,”
arXiv preprint arXiv:2004.02315, 2020.

[20] G. Xu, Y. Liu, and P. W. Khan, “Improvement of the DPoS
Consensus Mechanism in Blockchain Based on Vague Sets,” IEEE
Transactions on Industrial Informatics, vol. 16, no. 6, pp. 4252–4259,
Jun. 2020.

[21] L. Jiang, S. Xie, S. Maharjan, and Y. Zhang, “Joint Transaction
Relaying and Block Veriﬁcation Optimization for Blockchain Em-
powered D2D Communication,” IEEE Transactions on Vehicular
Technology, vol. 69, no. 1, pp. 828–841, Jan. 2020.

[22] X. Qiu, L. Liu, W. Chen, Z. Hong, and Z. Zheng, “Online Deep Re-
inforcement Learning for Computation Ofﬂoading in Blockchain-
Empowered Mobile Edge Computing,” IEEE Transactions on Vehic-
ular Technology, vol. 68, no. 8, pp. 8050–8062, Aug. 2019.

[23] S. Guo, Y. Dai, S. Guo, X. Qiu, and F. Qi, “Blockchain Meets Edge
Computing: Stackelberg Game and Double Auction Based Task
Ofﬂoading for Mobile Blockchain,” IEEE Transactions on Vehicular
Technology, vol. 69, no. 5, pp. 5549–5561, May 2020.

[24] M. Liu, F. R. Yu, Y. Teng, V. C. M. Leung, and M. Song, “Com-
putation Ofﬂoading and Content Caching in Wireless Blockchain
Networks With Mobile Edge Computing,” IEEE Transactions on
Vehicular Technology, vol. 67, no. 11, pp. 11 008–11 021, Nov. 2018.

16

[25] Z. Zhang, Z. Hong, W. Chen, Z. Zheng, and X. Chen, “Joint Com-
putation Ofﬂoading and Coin Loaning for Blockchain-Empowered
Mobile-Edge Computing,” IEEE Internet of Things Journal, vol. 6,
no. 6, pp. 9934–9950, Dec. 2019.

[26] J. Feng, F. Richard Yu, Q. Pei, X. Chu, J. Du, and L. Zhu, “Co-
operative Computation Ofﬂoading and Resource Allocation for
Blockchain-Enabled Mobile-Edge Computing: A Deep Reinforce-
ment Learning Approach,” IEEE Internet of Things Journal, vol. 7,
no. 7, pp. 6214–6228, Jul. 2020.

[27] F. Guo, F. R. Yu, H. Zhang, H. Ji, M. Liu, and V. C. M. Leung,
“Adaptive Resource Allocation in Future Wireless Networks With
Blockchain and Mobile Edge Computing,” IEEE Transactions on
Wireless Communications, vol. 19, no. 3, pp. 1689–1703, Mar. 2020.

[28] Z. Li, M. Xu, J. Nie, J. Kang, W. Chen, and S. Xie, “NOMA-Enabled
Cooperative Computation Ofﬂoading for Blockchain-Empowered
Internet of Things: A Learning Approach,” IEEE Internet of Things
Journal, pp. 1–1, 2020.

[29] M. Li, D. Hu, C. Lal, M. Conti, and Z. Zhang, “Blockchain-Enabled
Secure Energy Trading With Veriﬁable Fairness in Industrial Inter-
net of Things,” IEEE Transactions on Industrial Informatics, vol. 16,
no. 10, pp. 6564–6574, Oct. 2020.

[30] Z. Yang, K. Liu, Y. Chen, W. Chen, and M. Tang, “Two-Level
Stackelberg Game for IoT Computational Resource Trading Mech-
anism: A Smart Contract Approach,” IEEE Transactions on Services
Computing, pp. 1–1, 2020.

[31] W. Chen, Z. Zhang, Z. Hong, C. Chen, J. Wu, S. Maharjan,
Z. Zheng, and Y. Zhang, “Cooperative and Distributed Compu-
tation Ofﬂoading for Blockchain-Empowered Industrial Internet
of Things,” IEEE Internet of Things Journal, vol. 6, no. 5, pp. 8433–
8446, Oct. 2019.

[32] J. Wang, J. Hu, G. Min, W. Zhan, Q. Ni, and N. Georgalas,
“Computation Ofﬂoading in Multi-Access Edge Computing Using
a Deep Sequential Model Based on Reinforcement Learning,” IEEE
Communications Magazine, vol. 57, no. 5, pp. 64–69, May 2019.
[33] L. Busoniu, R. Babuska, and B. De Schutter, “A Comprehensive
Survey of Multiagent Reinforcement Learning,” IEEE Transactions
on Systems, Man, and Cybernetics, Part C (Applications and Reviews),
vol. 38, no. 2, pp. 156–172, Mar. 2008.

[34] Z. Cao, P. Zhou, R. Li, S. Huang, and D. Wu, “Multiagent Deep
Reinforcement Learning for Joint Multichannel Access and Task
Ofﬂoading of Mobile-Edge Computing in Industry 4.0,” IEEE
Internet of Things Journal, vol. 7, no. 7, pp. 6201–6213, Jul. 2020.
[35] D. Kwon, J. Jeon, S. Park, J. Kim, and S. Cho, “Multi-Agent DDPG-
based Deep Learning for Smart Ocean Federated Learning IoT
Networks,” IEEE Internet of Things Journal, vol. 7, no. 10, pp. 9895–
9903, Apr. 2020.

[36] S. Wang, J. Duan, D. Shi, C. Xu, H. Li, R. Diao, and Z. Wang,
“A Data-driven Multi-agent Autonomous Voltage Control Frame-
work Using Deep Reinforcement Learning,” IEEE Transactions on
Power Systems, vol. 35, no. 6, pp. 4644–4654, Apr. 2020.

[37] D. Nguyen, P. Pathirana, M. Ding, and A. Seneviratne, “Secure
Computation Ofﬂoading in Blockchain based IoT Networks with
Deep Reinforcement Learning,” IEEE Transactions on Network Sci-
ence and Engineering, pp. 1–1, 2021.

[38] W. Sun, J. Liu, Y. Yue, and P. Wang, “Joint Resource Allocation and
Incentive Design for Blockchain-Based Mobile Edge Computing,”
IEEE Transactions on Wireless Communications, vol. 19, no. 9, pp.
6050–6064, Sep. 2020.

[39] F. Yang, W. Zhou, Q. Wu, R. Long, N. N. Xiong, and M. Zhou, “Del-
egated Proof of Stake With Downgrade: A Secure and Efﬁcient
Blockchain Consensus Algorithm With Downgrade Mechanism,”
IEEE Access, vol. 7, pp. 118 541–118 555, 2019.

[40] R. Lowe, Y. WU, A. Tamar, J. Harb, O. Pieter Abbeel, and
I. Mordatch, “Multi-Agent Actor-Critic for Mixed Cooperative-
Competitive Environments,” in Advances in Neural Information
Processing Systems, 2017, pp. 6379–6390.

[41] H. Guo and J. Liu, “Collaborative Computation Ofﬂoading for
Multiaccess Edge Computing Over Fiber–Wireless Networks,”
IEEE Transactions on Vehicular Technology, vol. 67, no. 5, pp. 4514–
4526, May 2018.

[42] Z. Ning, P. Dong, X. Wang, X. Hu, J. Liu, L. Guo, B. Hu, R. Kwok,
and V. C. M. Leung, “Partial Computation Ofﬂoading and Adap-
tive Task Scheduling for 5G-enabled Vehicular Networks,” IEEE
Transactions on Mobile Computing, pp. 1–1, 2020.

[43] S. Yang, K. Xu, L. Cui, Z. Ming, Z. Chen, and Z. Ming, “EBI-
PAI: Towards An Efﬁcient Edge-Based IoT Platform for Artiﬁcial
Intelligence,” IEEE Internet of Things Journal, pp. 1–1, 2020.

[44] D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li,
D. Niyato, O. Dobre, and H. V. Poor, “6G Internet of Things: A
Comprehensive Survey,” IEEE Internet of Things Journal, 2021.

Dinh C. Nguyen (Member, IEEE) is currently
working toward the Ph.D. degree with the School
of Engineering, Deakin University, Victoria, Aus-
tralia. His research interests focus on wireless
communications, federated learning, deep rein-
forcement learning, blockchain, and edge com-
puting. He has published over 20 papers as
the ﬁrst author at the top-tier IEEE journals and
conferences, such as IEEE Transactions on Mo-
bile Computing, IEEE Wireless Communications
Magazine, IEEE Communications Surveys and
Tutorials, IEEE Internet of Things Journal, IEEE GLOBECOM, ICC, and
CCGrid conferences. He has been a recipient of the prestigious Data61
PhD scholarship, CSIRO, Australia. He has been the TPC member of
top-tier conferences including IEEE GLOBECOM 2021.

Ming Ding (Senior Member, IEEE) received the
B.S. and M.S. degrees (with ﬁrst-class Hons.)
in electronics engineering from Shanghai Jiao
Tong University (SJTU), Shanghai, China, and
the Doctor of Philosophy (Ph.D.) degree in sig-
nal and information processing from SJTU, in
2004, 2007, and 2011, respectively. From April
2007 to September 2014, he worked at Sharp
Laboratories of China in Shanghai, China as
a Researcher/Senior Researcher/Principal Re-
searcher. Currently, he is a senior research sci-
entist at Data61, CSIRO, in Sydney, NSW, Australia. His research inter-
ests include information technology, data privacy and security, machine
learning and AI, etc. He has authored over 140 papers in IEEE jour-
nals and conferences, all in recognized venues, and around 20 3GPP
standardization contributions, as well as a Springer book “Multi-point
Cooperative Communication Systems: Theory and Applications”. Also,
he holds 21 US patents and co-invented another 100+ patents on 4G/5G
technologies in CN, JP, KR, EU, etc. Currently, he is an editor of IEEE
Transactions on Wireless Communications and IEEE Wireless Commu-
nications Letters. Besides, he has served as Guest Editor/Co-Chair/Co-
Tutor/TPC member for many IEEE top-tier journals/conferences and
received several awards for his research work and professional services.

Pubudu N. Pathirana (Senior Member, IEEE)
was born in 1970 in Matara, Sri Lanka, and
was educated at Royal College Colombo. He
received the B.E. degree (ﬁrst class honors) in
electrical engineering and the B.Sc. degree in
mathematics in 1996, and the Ph.D. degree in
electrical engineering in 2000 from the Univer-
sity of Western Australia, all sponsored by the
government of Australia on EMSS and IPRS
scholarships, respectively. He was a Postdoc-
toral Research Fellow at Oxford University, Ox-
ford, a Research Fellow at the School of Electrical Engineering and
Telecommunications, University of New South Wales, Sydney, Australia,
and a Consultant to the Defence Science and Technology Organization
(DSTO), Australia, in 2002. He was a visiting professor at Yale University
in 2009. Currently, he is a full Professor and the Head of Discipline,
Mechatronics, Electrical and Electronic Engineering and the Director of
Network Sensing and Biomedical Engineering(NSBE) research group
at the School of Engineering, Deakin University, Geelong, Australia. His
current research interests include Bio-Medical assistive device design,
human motion capture, mobile/wireless and IoT networks, rehabilitation
robotics and signal processing.

17

Aruna Seneviratne (Senior Member, IEEE) is
currently a Foundation Professor of
telecom-
munications with the University of New South
Wales, Australia, where he holds the Ma-
hanakorn Chair of telecommunications. He has
also worked at a number of other Universi-
ties in Australia, U.K., and France, and indus-
trial organizations, including Muirhead, Standard
Telecommunication Labs, Avaya Labs, and Tele-
com Australia (Telstra). In addition, he has held
visiting appointments at INRIA, France. His cur-
rent research interests are in physical analytics: technologies that en-
able applications to interact intelligently and securely with their environ-
ment in real time. Most recently, his team has been working on using
these technologies in behavioral biometrics, optimizing the performance
of wearables, and the IoT system veriﬁcation. He has been awarded
a number of fellowships, including one at British Telecom and one at
Telecom Australia Research Labs.

Jun Li (M’09-SM’16) received Ph. D degree in
Electronic Engineering from Shanghai Jiao Tong
University, Shanghai, P. R. China in 2009. From
January 2009 to June 2009, he worked in the
Department of Research and Innovation, Alcatel
Lucent Shanghai Bell as a Research Scientist.
From June 2009 to April 2012, he was a Post-
doctoral Fellow at the School of Electrical Engi-
neering and Telecommunications, the University
of New South Wales, Australia. From April 2012
to June 2015, he is a Research Fellow at the
School of Electrical Engineering, the University of Sydney, Australia.
From June 2015 to now, he is a Professor at the School of Electronic
and Optical Engineering, Nanjing University of Science and Technology,
Nanjing, China. He was a visiting professor at Princeton University from
2018 to 2019. His research interests include network information the-
ory, game theory, distributed intelligence, multiple agent reinforcement
learning, and their applications in ultra-dense wireless networks, mobile
edge computing, network privacy and security, and industrial Internet of
things. He has co-authored more than 200 papers in IEEE journals and
conferences, and holds 1 US patents and more than 10 Chinese patents
in these areas. He was serving as an editor of IEEE Communication
Letters and TPC member for several ﬂagship IEEE conferences. He
received Exemplary Reviewer of IEEE Transactions on Communications
in 2018, and best paper award from IEEE International Conference on
5G for Future Wireless Networks in 2017.

H. Vincent Poor (S’72, M’77, SM’82, F’87) re-
ceived the Ph.D. degree in EECS from Princeton
University in 1977. From 1977 until 1990, he
was on the faculty of the University of Illinois at
Urbana-Champaign. Since 1990 he has been on
the faculty at Princeton, where he is currently
the Michael Henry Strater University Professor.
During 2006 to 2016, he served as the dean of
Princeton’s School of Engineering and Applied
Science. He has also held visiting appointments
at several other universities, including most re-
cently at Berkeley and Cambridge. His research interests are in the
areas of information theory, machine learning and network science,
and their applications in wireless networks, energy systems and related
ﬁelds. Among his publications in these areas is the forthcoming book
Machine Learning and Wireless Communications, (Cambridge Univer-
sity Press). Dr. Poor is a member of the National Academy of Engineer-
ing and the National Academy of Sciences and is a foreign member of
the Chinese Academy of Sciences, the Royal Society, and other national
and international academies. He received the IEEE Alexander Graham
Bell Medal in 2017.

