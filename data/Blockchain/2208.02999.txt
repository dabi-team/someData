2
2
0
2

g
u
A
5

]

R
C
.
s
c
[

1
v
9
9
9
2
0
.
8
0
2
2
:
v
i
X
r
a

Cryptoeconomic Security for
Data Availability Committees

Ertem Nusret Tas and Dan Boneh

Stanford University

Abstract. Layer 2 systems have received increasing attention due to
their potential to scale the throughput of L1 blockchains. To avoid the
cost of putting data on chain, these systems increasingly turn to oﬀ-chain
data availability solutions such as data availability commitees (DACs).
However, placing trust on DACs conﬂicts with the goal of obtaining an
L2 architecture whose security relies solely on the L1 chain. To eliminate
such trust assumptions, we propose a DAC protocol that provides ﬁnan-
cial incentives to deter the DAC nodes from adversarial behavior. We
then analyze the interaction of rational DAC nodes and clients as a dy-
namic game, with a Byzantine adversary that can corrupt and bribe the
participants. We also deﬁne a notion of optimality for the DAC proto-
cols, inspired by fairness and economic feasibility. Our main result shows
that our protocol is optimal and guarantees security with the highest
possible probability under reasonable assumptions on the adversary.

1

Introduction

Layer 2 systems [1,2,3] are an important approach to scaling the throughput of
Layer 1 blockchains such as Ethereum. One of the key challenges in securing an
L2 system is data availability: how to ensure that the state of the L2 system is
always available and can be reconstructed when needed? This data is needed
to safely restart the L2 system after a failure, and for basic operations such
as deposits and withdrawals. The data availability problem comes up in other
contexts as well, such as in decentralized storage systems [4,5,6].
There are three general approaches to data availability in L2 systems:

– On-chain data: Rollup systems [3] store all transaction data on a Layer 1
parent chain, such as Ethereum. These systems rely on the security of the
L1 nodes to ensure that the data is always available.

– Oﬀ-chain data stored by a Data Availability Committee (DAC): Other sys-
tems such as StarkEx [7], zkPorter [8] and EigenLayr [9] use a DAC to store
data oﬀ-chain across a number of trusted nodes [10]. While the DAC pro-
vides a gas-eﬃcient alternative to on-chain data, these systems rely on the
correct operation of the DAC members to ensure that the data is always
available.

– Oﬀ-chain data with Data Availability Sampling (Celestium [11]): An en-
hancement to DACs employs data availability sampling [12,13,14,15] so that

 
 
 
 
 
 
2

Ertem Nusret Tas and Dan Boneh

light clients, such as rollup users, can identify unavailable blocks created by
the DAC. This approach is being used by modular blockchains such as Ce-
lestia [16] and Polygon Avail [17] that specialize in preserving the data of
other chains.

Providing a standalone data availability service, such as Celestia and others,
reﬂects a general trend towards modularity in the design of blockchains.

In this paper, we focus on the security of Data Availability Committees
(DAC), namely the last two bullets on the previous page. A DAC consists of
multiple DAC members, which we call nodes, that store copies of the data that
should be made available (e.g., data sent by the rollup sequencer). These nodes
are expected to provide the data to querying clients in a timely manner. Since
malicious DAC members can withhold the data, DACs typically replicate the
data on each DAC node for fault tolerance. Thus, as long as one member is
honest, rollup clients would receive the data upon request. Although the storage
requirement of the DAC scales linearly in the number of nodes due to repli-
cation, this redundancy can be reduced through the use of erasure codes and
polynomial commitments. For instance, the semi-AVID-PR scheme [18] uses lin-
ear erasure-correcting codes and homomorphic vector commitments to guarantee
the availability of data as long as over 2/3 of the nodes faithfully follow the pro-
tocol.

A major drawback of DACs is the need to trust the DAC members. Consider
a compromised DAC, where the adversary can prevent the reconstruction of the
data, for example, by controlling more than 1/3 of the DAC members. Such a
DAC can evolve the rollup state using unavailable transaction data, and withhold
this data from the rollup clients. This prevents clients from issuing transactions,
and enables the adversary to steal client funds through ransom attacks [19].
Thus, relying on a DAC hinders the goal of realizing a trust-minimized scaling
architecture that solely relies on the security of the L1 chain for the safety and
liveness of the rollup. Here, liveness signiﬁes that the rollup clients can continue
to submit transactions to the rollup system, and the system processes these
transactions.

Data availability sampling (DAS) does not improve the liveness guarantees
over the basic DAC architecture. If the DAC is not compromised, then DAS
helps rollup clients verify that the rollup data is available without downloading
all the data from the DAC. However, if the DAC is compromised, DAS provides
no guarantees for data availability. The compromised DAC can update the rollup
state with unavailable transactions, and ignore all DAS queries from the clients.
Hence, DAS does not remove the trust assumption placed on the DAC members
for liveness.

Incentive-based data availability. One way to strengthen the security of a
DAC is to rely on ﬁnancial incentives to deter the DAC members from adver-
sarial behavior, namely withholding data. However, as withholding data is not
a provable oﬀense, it not clear how to enforce the slashing of the adversarial
members’ stake. Moreover, any incentive-based data availability proposal must

Cryptoeconomic Security for Data Availability Committees

3

be analyzed in the face of rational DAC members who may respond to bribes,
and Byzantine adversaries who may oﬀer bribes.

Our main contribution is a DAC protocol that introduces a slashing mech-
anism for malicious DAC nodes. The bulk of the paper is a technical analysis
of the protocol, and proves its security under certain assumptions on the adver-
sary’s power. Moreover, we show that our protocol is optimal in a rigorous sense.
We deﬁne the security model and the optimality notions in Sections 2 and 4.

We model the interactions of the DAC as a dynamic game involving multiple

parties:

– DAC members, i.e., nodes, are denoted by P1, . . . , PN , where N is the
number of nodes. These nodes store the data provided by an external entity.

– A client V sends a sequence of data queries to the N nodes. Every node
can either respond to V with the requested data, or not respond. We assume
the data held by the nodes is signed by the data provider, so that integrity
of the response is easily veriﬁed. If a response contains incorrect data, it is
treated as a non-response.

– A contract running on the L1 chain is used to resolve disputes and punish
misbehaving DAC nodes. In particular, all N nodes are staked, and the stake
is held in the contract. If the nodes do not respond to V with the requested
data, V can send its query to the contract. In this case, the nodes are obliged
to post their responses to the contract. If a node provably fails to do so, the
contract can slash that node by conﬁscating part of its stake. Part of the
slashed stake is given to the client as compensation and the rest is burned.
The size of the per-node stake and the behavior of the contract are the key
design decisions for a DAC protocol.

Nodes and clients are rational agents that seek to maximize their utilities. An
adversary A who fully controls f corrupt nodes may try to bribe the remaining
N − f nodes to cause a client query to fail. This will make the requested data
unrecoverable. Our goal is to design a DAC, so that under reasonable assump-
tions on the size of f and on the adversary’s budget, every query from the client
will succeed with probability at least 1 − (cid:15), for some small (cid:15).

Queries from the client model data requests needed for normal operations
such as withdrawals. For instance, in a rollup system, clients might have to
prove their account balances with respect to the latest state root, and they do
so by presenting a Merkle proof for their account. A non-responsive DAC storing
the latest state can delay withdrawals by refusing to provide these Merkle proofs.
In this case, each client can post a query to the contract, and force the nodes
to place the requested proof on the L1 chain. We discuss use cases for a DAC
system in Section 2.

The DAC protocol. Suppose every query requires at least k nodes out of N
to respond either directly to the client, or to the contract, for the client to obtain
an answer to its query. If no erasure coding is used and the data is replicated
across all nodes, then k = 1, otherwise k could be bigger than 1.

4

Ertem Nusret Tas and Dan Boneh

The protocol proceeds in four steps:

– step 1: the client V sends its query to all DAC nodes over the network.

– step 2: if k or more nodes respond, then the client obtains the requested data

and the protocol terminates.

– step 3: if by a certain timeout the client does not receive k responses, it posts
its query to the contract on chain. For this purpose, the client has to send
a base payment to the contract, which is needed to deter spamming clients.
We discuss the choice of client payment amount in Section 6.

– step 4: all N nodes are then asked to post their responses to the query on

chain. The protocol terminates once a certain timeout is reached.

It remains to describe what the contract does once the timeout is reached in
step 4. Every node that does not post its response to the contract by the time-
out loses part or all of its stake. The precise slashing function is explained in
Section 3. Moreover, if by the timeout in step 4 the client does not obtain an
answer to its query, the client is compensated by the contract using the funds
obtained from the slashed nodes.

The question is how to analyze the security and performance of a contract in
comparison to other contracts. In Section 4 we present four desirable properties
that a slashing function should satisfy. Informally, these properties are:

– Symmetry. Motivated by fairness, the slashing function does not depend on

the identities of the nodes, only on their actions.

– No Reward. The slashing function does not pay out any rewards to the
responsive nodes. This is motivated by economic feasibility as the contract
should maintain a non-negative balance, and discourage the nodes from forc-
ing an on-chain interaction for extra payoﬀ rather than sending clues over
the network.

– Security Under No Attack. The slashing function ensures that the client
promptly learns the correct response to its query, if the adversary does not
oﬀer any bribes. This captures a minimal notion of security.

– Minimal Punishment. The slashing function keeps the slashed amounts of
non-responsive nodes at a minimum when the client obtains an answer to
its query. Thus, when most nodes are responsive, those that fail to respond
due to benign failures, e.g., crash faults, are not heavily penalized.

We then deﬁne a notion of optimality for these functions:

Deﬁnition 1 (Informal). A slashing function is optimal with respect to a set
of slashing functions F, if for all adversaries the function satisﬁes the following
two conditions: (i) upon sending its query to the contract, the client obtains an
answer with the maximum probability from among all the functions in F, and (ii)
when the client obtains an answer, the function imposes the minimal punishment
on non-responsive nodes from among all the functions in F.

In Section 4, we show that our slashing function is optimal for both risk-
neutral and risk-averse nodes among the set of all functions that satisfy the four

Cryptoeconomic Security for Data Availability Committees

5

desirable properties described above. We also analyze the security of a dynamic
game among a rational client and the DAC nodes. The analysis of Section 4 is
the most technical part of the paper, and is our core contribution.

Evaluation. In Section 5, we evaluate the real-world performance of our optimal
contract. To match the number of Ethereum validators and the minimum value
that can be staked as an independent validator on Ethereum, we set the total
number of DAC nodes to N = 300, 000 and the amount staked per node to 32
ETH. Then, given risk-neutral nodes, the adversary has to oﬀer a total bribe
of ≈ 3.2 · 103 ETH (≈ 3.9 million USD1) to the nodes, to reduce the security
probability per query by a tiny amount, namely to reduce the probability that a
client learns the answer to its query from 100% to 99.9%. To prevent clients from
learning the answers over repeated queries, the adversary has to spend at least
3.9 million USD for each query. As our contract is optimal, no other contract
can force the adversary to pay a higher bribe for the same security probability.
The minimum bribe needed by the adversary to reduce the security probability
increases as N or the collateral grows, or as the nodes become more risk-averse.

2 Model

Notation. We denote the security parameter by λ. We say that an event hap-
pens with negligible probability, if its probability, as a function of λ, is o(1/λd)
for all d > 0. We say that an event happens with overwhelming probability if
it happens except with probability negligible in λ. If an event happens with
probability q + negl(λ) or q − negl(λ), where q is a non-negligible constant, for
simplicity, we say that the event happens with probability q. We assume that
except with probability negligible in λ, the contract implements the speciﬁed
slashing function correctly, the underlying cryptographic primitives are secure,
and messages can be posted to the contract within bounded time. We use the
shorthand [N ] to denote the set {1, 2, . . . , N }.

Environment and the Adversary. Time is slotted, and the clocks of the client
and nodes are synchronized2. Messages, e.g., queries and replies, can only be
sent at the beginning of a slot, and are delivered to the recipient by the end of
the same slot by the environment Z.

Adversary A is a probabilistic polynomial time algorithm. Before the exe-
cution starts, A corrupts f nodes, which are subsequently called adversarial.
These nodes can deviate from the protocol arbitrarily (Byzantine faults) un-
der A’s control, which has access to their internal states. The remaining N − f
nodes and the client are utility maximizing agents and can choose any action
that gives them a higher utility. In the subsequent analysis, we will assume that

1 Ethereum to USD conversion rate, 1 ETH ≈ 1231.0 USD, is the average Ethereum
price on July 15, 2022, as stated in https://www.investing.com/crypto/ethereum/
historical-data.

2 Bounded clock oﬀsets can be captured by the network delay.

6

Ertem Nusret Tas and Dan Boneh

Pi, i = N − f + 1, . . . , N represent the adversarial nodes, and f ≤ N − k. Other-
wise, it is impossible to guarantee the recovery of the answer to a query as the
adversarial nodes can withhold their responses from the client and the contract.
Before the protocol execution starts, the adversary can also oﬀer bribes to the
remaining nodes and the client subject to certain constraints. It has a supply
of p0 coins, which it can distribute to any subset of the nodes as additional
payoﬀ if the nodes adopt an adversarial action during the game. Similarly, the
adversary can give up to p1 coins to the client if it adopts an adversarial action.
Such an adversary is called a (p0, p1)-adversary. When the bribe oﬀered to the
client is irrelevant, we use the notation p0-adversary. Upon hearing an oﬀer, each
participant can independently choose to accept or reject the bribe depending on
the expected utility. Once a participant accepts the bribe, the adversary can
monitor through the environment and the contract if the speciﬁed action was
taken. Although the action and the exchange of the bribe might not happen
atomically, the adversary and nodes can ensure that no party deviates from its
promise through a trusted third party, or repeated games (cf. Section 4.4).

Actions, Payoﬀs, and the Game. We next describe the dynamic game played by
the client and the DAC nodes. Before the game starts, the client V and the nodes
are input a single query by the environment Z. Given a query, each node Pi can
instantaneously generate a response ci, called the clue. The contract accepts a
clue if and only if it is the correct response to a previous query, and was not
already posted. It records the time slots when each query or clue was received,
in a contract state. At the beginning of each slot, the participants learn about
the state recorded at the end of the previous slot.

Let ps be the amount that every node is required to stake before it can
function as a DAC member. It costs pc coins for the client to send a query to
the contract, and pw coins for each node to prepare and post the corresponding
clue to the contract (It is free to send a clue to the client over the network).
These parameters are summarized in Table 1. We assume that each node starts
the game with a baseline payoﬀ of C = ps + pw, as it has ps coins staked in
the contract, and is assumed to have enough funds to post clues to the contract
during the game3. The client starts the game with an initial payoﬀ of 0.

The actions available to the client V and a node P at any slot t are denoted

as follows:

– Sr: P sends a correct clue to V over the network at slot t.
– Sq: V sends a query to the contract for the ﬁrst time at slot t.
– Sp: In response to a query, P sends a correct clue to the contract for the ﬁrst

time at slot t.

The notation ¬(.) is used to denote the opposite of the speciﬁed action. At any
time slot, a node can take an action (a, b), where a ∈ {Sr, ¬Sr} and b ∈ {Sp, ¬Sp}.
Similarly, the client can take an action from {Sq, ¬Sq}. Although the clients and
nodes can exchange messages other than queries and clues, only the queries, clues

3 For risk-neutral nodes, the baseline is normalized to be 0.

Cryptoeconomic Security for Data Availability Committees

7

or their absence can lead to a change in their payoﬀs. Since the participants play
a dynamic game, the actions chosen at later slots can depend on the actions
observed at the earlier ones.

The game ends, and the payoﬀs are realized at the beginning of slot Tanswer.
If V ﬁnds out the correct answer to its query by slot Tanswer, it receives a payoﬀ
of pf coins. We set Tanswer = 4 though it can be any suﬃciently large constant.
In our model, Tanswer should be at least 4 to guarantee any meaningful security.
The payoﬀs of the participants depend on the bribes p0 and p1, the collateral
ps, the environment variables pf , pc, pw selected by Z, and the slashing function
used by the contract.

Utility of a participant is given as a function U (.) of the payoﬀ obtained at
the end of the game. In the subsequent sections, we will ﬁrst consider risk-neutral
nodes with a linear utility function U (x) = x, where x is the net payoﬀ at the
end of the game. We will then analyze risk-averse nodes with a strictly concave
utility function of the form U (x) = (x)ν, where ν ∈ (0, 1). We do not consider
risk-seeking nodes with strictly convex utility functions, e.g., U (x) = (x)ν, ν > 1,
as such a function would violate the law of diminishing marginal utility for the
payoﬀs.

In the subsequent sections, we will also consider a sub-game that focuses
exclusively on the interaction between the nodes and the contract. In this game,
we assume that a query appears in the contract at some slot t, and the nodes
choose to post clues or not at slot t + 1, after which the payoﬀs are realized.
These payoﬀs depend on the bribe p0, the collateral ps, the cost pw, and the
slashing function.

Security. We say Tanswer-security is satisﬁed if the client receives k or more
correct clues from the nodes either over the network or through the contract by
the beginning of slot Tanswer with overwhelming probability.

Application. The game above models the withdrawal of client funds from a
blockchain or rollup. Each client has an account, represented as a key-value pair,
and the balances of these accounts constitute the blockchain state. The hashes of
the key-value pairs are organized in a vector commitment, e.g., a sparse Merkle
tree, with a constant size commitment, called the state root. The state data is
preserved by the DAC nodes.

To prove its account balance, a client can request a witness from the nodes
for the inclusion of its account with respect to the latest state root. If it does not
receive a witness over the network, the client can complain on a smart contract
by sending a query that contains the hash of the account’s key-value pair. If the
hash is a hiding commitment, the client can also ensure that no observer learns
its balance. It can always prove its balance to a select third party by revealing
the key-value pair at the pre-image of the hash, the latest state root on chain,
and the obtained witness.

Upon receiving a query, the contract expects a witness to be provided by the
DAC nodes within a bounded time, e.g., the chain’s conﬁrmation latency. If the
query is for an account not included in the latest state, the nodes can convince

8

Ertem Nusret Tas and Dan Boneh

the contract of this fact via a proof of non-inclusion. If there are multiple queries,
instead of sending the witness for each query, the nodes can compute a SNARK
proof that veriﬁes the inclusion of all the queried accounts within the state.
Clients can then verify the inclusion of the queried accounts by checking the
proof with respect to the latest state root, and the hashes of the queried accounts.
Succinctness of the SNARK proof enable us to assume a bounded delay on the
response time.

3 The Optimal Contract

Parameter

Explanation

N
p0
p1
pcomp
pf
pc
pw
ps

Number of nodes
Total payoﬀ the adversary can oﬀer to the nodes
Total payoﬀ the adversary can oﬀer to the client
Compensation for the client if reconstruction fails
Client’s payoﬀ from a valid reply within 4 slots
Cost of sending a query to the contract
Cost of constructing and sending a clue to the contract
Collateral per node

Table 1: Parameters in our model

A contract can reward or punish the nodes depending on whether it received
clues from the nodes for a query within a timeout period. We normalize this
timeout to be a single slot for all contracts. Let xi = 1 if the node Pi sends
a valid clue at slot t + 1 in response to a query posted at some slot t, and
xi = 0 otherwise. We characterize a contract by a slashing function f that maps
actions x = (x1, . . . , xN ) ∈ {0, 1}N to payoﬀs (f1(x), . . . , fN (x)) ∈ RN for the
nodes, and the payoﬀ fV (x) ∈ R for the client. Since the contract cannot punish
the nodes more than the staked collateral, fi(x) ≥ −ps for every action x ∈
{0, 1}N . We will hereafter use slashing function and the contract interchangably
depending on the context.

The proposed contract and the associated slashing function is parameterized

by a small number (cid:15) > 0:

fi(x) =






0
−ps

−pw − (cid:15)

if xi = 1
if (cid:80)N
if (cid:80)N

j=1 xj < k and xi = 0
j=1 xj ≥ k and xi = 0

fV (x) =

(cid:40)0

pcomp

if (cid:80)N
if (cid:80)N

j=1 xj ≥ k
j=1 xj < k

Here, pcomp < ps, pf , and pcomp > pc to ensure that the client’s net payoﬀ is
above zero.

Cryptoeconomic Security for Data Availability Committees

9

The contract burns, i.e., slashes the collateral ps put up by each node that has
not sent a valid clue by the end of slot t + 1, if there are less than k clues. In this
case, the contract also awards pcomp of the slashed coins to V. Otherwise, if there
are k or more clues in the contract by slot t + 1, it punishes the non-responsive
nodes by a modest amount, namely pw + (cid:15).

4 Analysis

In Section 4.1, we formalize the desirable properties and notions of optimality for
slashing functions. In Section 4.2, we show that the slashing function of Section 3
is optimal for risk-neutral and risk-averse nodes. In Section 4.3, we generalize
the analysis to a dynamic game with a rational client. In Section 4.4, we analyze
a repeated game played between the nodes and the adversary.

4.1 Contract Properties

The desirable properties for a slashing function f , introduced in Section 1, are
formalized below:

– A1: Symmetry. A slashing function f is symmetric if f (π(x)) = π(f (x)) for

every action x ∈ {0, 1}N and permutation π.

– A2: No Reward. A slashing function f oﬀers no rewards if for every action

x ∈ {0, 1}N , fi(x) ≤ 0, ∀i ∈ [N ], and fV (x) + (cid:80)

i∈[N ] fi(x) ≤ 0.

– A3: Security Under No Attack. A slashing function f guarantees security
under no attack if for all (0, 0)-adversaries, it achieves Tanswer-security with
overwhelming probability in all Nash equilibria of the game.

– A4: B-Minimal punishment. A slashing function f oﬀers B minimal punish-
i=1 xi ≥ k, we have that

ment if for every action x ∈ {0, 1}N such that (cid:80)N
fi(x) ≥ −B for all i ∈ [N ].

Deﬁnition 2. A slashing function f is said to be compliant if it satisﬁes the
axioms A1–A3, and the axiom A4 for some constant B ∈ R+.

Deﬁnition 3. A compliant slashing function f is said to be (p0, q)-tolerant if
for all p0-adversaries, when a query is received by the contract at some slot t,
there are k or more correct clues in the contract at slot t + 1, with probability at
least q, in all Nash equilibria.

The value q of a (p0, q)-tolerant contract can be interpreted as the maximum
failure probability for security given that the client received no responses over
the network and sent its query to the contract.

We next introduce two notions of optimality for the contract. A security-
optimal function ensures that for any p0, security is violated with the minimum
possible probability in the equilibrium of the game with the largest failure prob-
ability.

10

Ertem Nusret Tas and Dan Boneh

Deﬁnition 4. A compliant slashing function f is said to be security-optimal
if for all p0 ≥ 0, there exists a q0 ∈ [0, 1] such that f is (p0, q0)-tolerant, and
there does not exist any compliant, (p0, q)-tolerant function f (cid:48), where q > q0.

A punishment-optimal contract imposes the minimum punishment on the
nodes that fail to send clues due to benign failures without compromising secu-
rity.

Deﬁnition 5. A compliant slashing function f is said to be (cid:15)-punishment-
optimal if it satisﬁes B-minimal punishment, and no compliant slashing func-
tion f (cid:48) can satisfy B(cid:48)-minimal punishment for some B(cid:48) < B − (cid:15).

Finally, we combine the two notions of optimality in a single deﬁnition:

Deﬁnition 6. A family of slashing functions f(cid:15), parameterized by (cid:15), is said to
be optimal if each member f(cid:15) of the family is compliant, security-optimal and
(cid:15)-punishment-optimal.

4.2 Analysis of The Optimal Contract

We prove the following theorem for risk-neutral and risk-averse nodes.

Theorem 1. The family of slashing functions described in Section 3 is optimal.

Theorem 1 follows from Theorems 2, 3, and 4. Their proofs for risk-neutral

and risk-averse nodes are given in Appendices A and B respectively.

We ﬁrst showing that the slashing function is compliant:

Theorem 2. Each slashing function from Section 3, parameterized by (cid:15) > 0,
satisﬁes symmetry (A1), no reward (A2), security under no attack (A3), and
(pw + (cid:15))-minimal punishment (A4).

The axioms A1, A2 and A4 follow by inspection, whereas A3 is shown by
Lemma 1. Its proof is given in Appendices A and B for risk-neutral and risk-
averse nodes respectively.

Lemma 1. Given the slashing function of Section 3, for any (0, 0)-adversary
A, 4-security is satisﬁed with overwhelming probability in all Nash equilibria.

When pcomp > pc, the client is incentivized to send its query to the contract if
it receives less than k clues over the network. Then, the nodes post their clues to
the contract to avoid slashing of their stakes, and the contract ensures security
with overwhelming probability.

Remark 1. If pcomp ≤ pc, for any contract that oﬀers no rewards to the nodes,
and for any ((cid:15), 0)-adversary where (cid:15) ≥ 0, there exists a Nash equilibrium such
that 4-security is violated with overwhelming probability. Consider the action
proﬁle, where the nodes do not send their clues to the client V over the network,
and do not post their clues to the contract. Given these actions, if pcomp ≤ pc,
V’s payoﬀ can at most be 0, and the maximum payoﬀ is achieved if V does

Cryptoeconomic Security for Data Availability Committees

11

not send a query to the contract, even when it does not receive clues over the
network. In this case, the normalized payoﬀ of each node becomes 0 as well,
which is the maximum payoﬀ attainable by any node. Hence, the nodes do not
have any incentive to deviate from the action proﬁle above, which constitutes a
Nash equilibrium.

We next show that the slashing function is (cid:15)-punishment optimal.

Theorem 3. Consider a slashing function that is symmetric (A1), oﬀers no
rewards (A2), and satisﬁes B-minimal punishment for some B < pw (A4). Then,
for k > 1, there exists a (0, 0)-adversary A and a Nash equilibrium, where 4-
security is violated with non-negligible probability. Thus, no compliant slashing
function can satisfy B-minimal punishment for some B < pw.

When B < pw, punishment for a node that does not post its clue to the
contract while the other nodes send their clues is smaller than the cost of posting
the clue. This leads to a free-rider problem, and results in an equilibrium with a
non-negligible failure probability for security, where each non-adversarial node
trusts the others to send clues to the contract.

Finally, we prove security-optimality:

Theorem 4. The slashing function of Section 3 is security optimal.

Consider the sub-game, where the contract receives a query at some slot t.
For a given contract and utility function U (x) = xν, let qA
v denote the probability
that given a p0-adversary A, there are less than k valid clues in the contract at
slot t + 1 in the Nash equilibrium with the largest probability of failure. Then,
the proof of Theorem 4 for risk-neutral nodes follow from Theorem 5:

Theorem 5. Suppose p0 < (N − f − k + 1)(ps − pw) and the nodes are risk-
neutral with the utility function U (x) = x. Then, for any p0-adversary A, the
slashing function of Section 3 satisﬁes

v ≤ q∗ =
qA

p0
(N − f − k + 1)(ps − pw)

Moreover, there exists a p0-adversary A such that for any compliant slashing
function, qA

v ≥ q∗.

The p0-adversary A of Theorem 5 oﬀers a bribe of

N −f −k+1 to N − f − k + 1
non-adversarial nodes, e.g., Pi, i ∈ [N − f − k + 1]. In return, it requests these
nodes to collectively withhold their clues from the contract with probability q∗.

p0

Remark 2. If p0 ≥ (N − f − k + 1)(ps − pw), there exists a Nash equilibrium,
where 4-security is violated with overwhelming probability. Adversary oﬀers a
payoﬀ of ps − pw to each of the N − f − k + 1 nodes, and requests them to
withhold their clues from the contract. In the equilibrium, the oﬀer is accepted
and the nodes do not post their clues to the contract.

12

Ertem Nusret Tas and Dan Boneh

Remark 3. Sending repeated queries to the contract does not reduce the failure
probability by more than a linear factor in latency. Suppose the client V is
allowed to send the same query to the contract up to (cid:96) times. Then, if there are
less than k valid clues in the contract at slot t + 1, V might want to repeat the
sub-game up to (cid:96) times with the hope of eventually learning the answer to its
N −f −k+1 to the nodes
query. In this case, the adversary A can oﬀer a payoﬀ of
Pi, i ∈ [N − f − k + 1], and in return, ask them to collectively withhold their
clues in all of the games with probability q∗/(cid:96). Via a similar reasoning to the
proof of Theorem 5, this adversary ensures qA
v ≥ q∗/(cid:96) for any compliant slashing
function.

p0

Finally, we characteruze the failure probability for the optimal contract. Sup-
pose the contract of Section 3 is (p0, 1 − q∗
p0,ν)-tolerant per Deﬁnition 3, where
the failure probability q∗
p0,ν is depends on the total bribe p0 and the nodes’ utility
function U (x) = xν, e.g., q∗
p0,1 = q∗ by Theorem 5. Although Theorem 4 proves
that the contract of Section 3 is security optimal, unlike Theorem 5, its proof
does not provide an explicit expression for q∗
p0,ν when ν < 1, i.e., for risk-averse
nodes. Instead, in Appendix C, we identify an optimization problem whose so-
lution gives q∗
p0,ν. As the optimization problem is not convex for ν < 1, in lieu of
solving the problem, we provide bounds on q∗
p0,ν that characterize its asymptotic
behavior in terms of ν, p0 and N .

4.3 Analysis of the Dynamic Game

In this section, we analyze the interaction among a rational client and the nodes
during the dynamic game. For a speciﬁed slashing function, let q(p0, ν) denote
the maximum probability that 4-security is violated in the Nash equilibrium
with the largest probability of failure, across all p0-adversaries.

Theorem 6 shows that when k > 1, the slashing function of Section 3 achieves
the minimum q(p0, ν) among all compliant slashing functions, and this probabil-
ity equals q∗
p0,ν. Proofs of the subsequent theorems are presented in Appendix D.

Theorem 6. Consider (p0, p1)-adversaries such that p1 < pcomp − pc and p0 <
(N − f − k + 1)(ps − pw). Then, for the slashing function of Section 3, it holds
that q(p0, ν) ≤ q∗

p0,ν.

Moreover, given any compliant slashing function, if k > 1, then, there exists
a (p0, 0)-adversary and a subgame perfect equilibrium such that 4-security is
violated in the equilibrium with probability q∗

p0,ν.

Theorem 6 proves that even if the adversary does not oﬀer any bribe to the
client, i.e., p1 = 0, if k > 1, there exists a subgame perfect equilibrium where
security is violated with the maximum probability q∗

p0,ν.

Remark 4. If p1 > pcomp−pc, there exists a Nash equilibrium, where 4-security is
violated with overwhelming probability. Suppose the adversary A asks the nodes
to not send their clues to V or to the contract, and requests V to not post its
query to the contract. If V never sends its query to the contract, nodes achieve

Cryptoeconomic Security for Data Availability Committees

13

a strictly better utility by accepting the adversary’s oﬀer. Similarly, V cannot
increase its utility by deviating from the adversarial action. This is because, if V
rejects its bribe and sends a query to the contract, given the nodes’ actions, its
payoﬀ becomes pcomp − pc, less than the bribe p1. Hence, given A, the speciﬁed
actions indeed constitute a Nash equilibrium.

Theorem 7 analyzes the game when k = 1.

Theorem 7. Consider any compliant slashing function and (p0, p1)-adversaries
such that p1 < pcomp − pc and p0 < (N − f − k + 1)(ps − pw). Suppose there are
N nodes, and k = 1 ≤ N − f . Then, if p1 satisﬁes

(1 − q∗

p0,ν)(pf − pc + p1)ν + q∗

p0,ν(pf − pc + p1 + pcomp)ν ≥ (pf )ν,

(1)

there exists a (p0, p1)-adversary and a subgame perfect equilibrium such that 4-
security is violated with probability at least q∗

p0,ν, i.e., q(p0, ν) ≥ q∗

p0,ν.

Via Theorems 6 and 7, for all values of k and all (p0, p1)-adversaries with
a suﬃciently large p1, the slashing function of Section 3 achieves the minimum
possible failure probability for 4-security among all compliant slashing functions.
If p1 satisﬁes formula (1), then the adversary can incentivize V to send a query
to the contract regardless of whether V received clues over the network. This in
turn discourages the nodes from sending clues over the network, and helps sustain
an equilibrium where security rests solely on the clues sent to the contract. In
this context, slashing function of Section 3 minimizes the failure probability for
security, which becomes q∗

p0,ν.

On the other hand, if p1 is too small to satisfy formula (1) and k = 1, given
the optimal slashing function of Section 3, 4-security can be satisﬁed, without
any query sent to the contract, with probability exceeding q∗

p0,ν.

Theorem 8. Consider the slashing function of Section 3 and (p0, p1)-adversaries
such that p1 < pcomp − pc, p0 < (N − f − k + 1)(ps − pw), and p1 satisﬁes

(1 − q∗

p0,ν)(pf − pc + p1)ν + q∗

p0,ν(pf − pc + p1 + pcomp)ν < (pf )ν.

Suppose there are N nodes, and k = 1 ≤ N − f . Then, 4-security is satisﬁed
with overwhelming probability in all Nash equilibria, without the client sending
its query to the contract.

When ν = 1, i.e., for risk-neutral nodes, formula (1) implies p1 ≥ pc. As pc
can be as small as the gas cost of sending a query, for most (p0, p1)-adversaries,
we expect p1 to exceed pc, i.e. to satisfy formula (1).

4.4 Repeated Games

Although the adversary can oﬀer any bribe and specify any action in return,
exchange of the bribe and the execution of the action do not necessarily hap-
pen atomically. This might discourage cooperation between the nodes and the
adversary as they can renege on their promises.

14

Ertem Nusret Tas and Dan Boneh

One way the parties can ensure atomicity is through a trusted third party.
It can take the custody of the nodes’ internal states, along with the adversary’s
bribe, and adjust the payoﬀs after the game. Alternatively, the adversary and
nodes can sustain a cooperative equilibrium over the repeated instances of the
single-stage query-response game analyzed in Section 4.2, with the help of a
common random coin. For repeated games to be feasible, we assume that the
nodes have more coins than the collateral p0, enabling them to absorb occasional
losses due to slashing in return for long-term proﬁt. Similarly, we assume that the
adversary can continue to oﬀer bribes each new game. Let δ denote the discount
rate. We consider the optimal contract of Section 3 in the following analysis.

Suppose p0 < (N − f − k + 1)(ps − pw), and there is a query at the contract
at slot t. By Section 4.2, for any p0 and ν ∈ (0, 1], there exists a p0-adversary
and Nash equilibrium, where less than k nodes send their clues to the contract
at slot t + 1 with probability at least q∗
p0,ν. The utilities of the nodes in the
equilibrium are feasible and strictly individually rational as they are at least as
large as the maximum utility, (C − pw)ν, any node can get without cooperating
with the adversary. Thus, by the Nash folk theorem, we can state the following:

Theorem 9. There exists a discount rate δ∗ < 1 such that for all δ > δ∗, there
is a subgame perfect equilibrium of the repeated game with the same expected
utilities for the nodes per game as the single-stage game. Moreover, at each
game, less than k clues are posted to the contract with probability at least q∗
p0,ν.
By the proof of Theorem 4, no adversary can guarantee less than k clues to
be posted to the contract with probability larger than q∗
p0,ν without making the
utility of a node less than (C − pw)ν, its minimax utility. Consequently, q∗
p0,ν is
the maximum failure probability that can be sustained through repeated games.
To maintain the aforementioned equilibrium, the adversary and nodes can
use a grim trigger strategy: Consider the adversary of Theorem 5. The common
random coin is ﬂipped before each game, and obtains the value 0 with probability
p0,ν and the value 1 with probability 1 − q∗
q∗
p0,ν. Before each game, the adversary
oﬀers its bribe. Then, the coin is ﬂipped. If the outcome is 0, the bribed nodes
are asked to withhold their clues from the contract. At this point, if any of the
bribed nodes sends its clue to the contract, the adversary stops oﬀering any
future payoﬀ to that node. Similarly, if the adversary fails to oﬀer a suﬃcient
bribe before the coin is ﬂipped, the nodes stop cooperating with the adversary.

5 Evaluation

We next calculate the bribe p0 needed to violate security in the equilibrium
with the largest failure probability, when a query is sent to the optimal contract
of Section 3 on Ethereum. When the clues are SNARK proofs as argued in
Section 2, assuming that sending and verifying a SNARK proof on Ethereum
requires 650000 gas [20], and the gas cost is 34.77 Gwei4, we estimate the cost

4 The gas cost is the average gas price for July 15, 2022, as stated in https://ycharts.

com/indicators/ethereum_average_gas_price.

Cryptoeconomic Security for Data Availability Committees

15

Fig. 1: Lower bounds on the total bribe, p0, needed to ensure that the probability the
client does not obtain the answer to its query is (cid:15) = 10−6, as a function of the number
of DAC nodes N , and the utility functions U (x) = xν , ν = 0.1, 0.5, 0.8, 1.0.

of posting a clue to the contract as pw ≈ 0.0226 ETH. We set the collateral ps
to be 32 ETH to match the minimum amount that can be staked in Ethereum
by an independent node. Assuming that the adversary can control up to 1/3 of
the N DAC nodes, and clues from 1/3 of the nodes are suﬃcient to recover the
answer to the client queries, we set N − f − k + 1 to be N/3. The 1/3 bound for
the adversarial DAC nodes matches the maximum tolerable adversary fraction
shown for the security of Casper FFG [21], the ﬁnality gadget of PoS Ethereum.
We consider N < 300, 000, which matches the magnitude of the number of
validators on PoS Ethereum5.

p0
ps−pw

1
N −f −k+1

Let (cid:15) denote the maximum failure probability for security tolerable by the
clients. Suppose (cid:15) = 0.1%. For risk-neutral nodes, Theorem 5 implies that (cid:15) =
min(1,
). For risk-averse nodes with the utility function U (x) =
xν, (cid:15) is the solution to the optimization problem in Theorem 10, which is upper
and lower by Theorem 11 in Appendix C. Using the parameters identiﬁed above,
the formula for (cid:15) for risk-neutral nodes and the bounds for risk-averse nodes,
we calculate the following values6 for the minimum bribe p0 needed to violate
security with probability (cid:15) = 10−3 (0.1%), as a function of the utility parameter
ν (Details of the calculation are presented in Appendix C).

5 For reference, https://www.thecoinrepublic.com/2022/03/05/eth-2-0-crosses-

300000-validators-ether-deposits-worth-28-9b-already-locked/

6 Ethereum to USD conversion rate, 1 ETH ≈ 1231.0 USD, is the average Ethereum
price on July 15, 2022, as stated in https://www.investing.com/crypto/ethereum/
historical-data.

16

Ertem Nusret Tas and Dan Boneh

ν

0.1
0.5
0.8
1.0

Lower bound on p0
3197.9 ETH (3.9 Million USD)
3197.9 ETH (3.9 Million USD)
3197.9 ETH (3.9 Million USD)
3197.9 ETH (3.9 Million USD)

Upper bound on p0
13257.7 ETH (16.3 Million USD)
6082.5 ETH (7.5 Million USD)
3977.5 ETH (4.9 Million USD)
3197.9 ETH (3.9 Million USD)

Table 2: Lower and upper bounds on p0 in ETH and USD as a function of the utility
parameter ν, where 1 ETH ≈ 1231.0 USD, the number of DAC nodes N is 300, 000,
and the failure probability is (cid:15) = 0.1%.

The exact value of p0 increases as ν decays, i.e., as the nodes become more
risk averse. This increase becomes more stark at small values of the maximum
failure probability (cid:15). To illustrate this point, we plot the lower bound on p0 as a
function of N ∈ [1, 300000], for ν = 0.1, 0.5, 0.8, 1.0 and (cid:15) = 10−6 in Figure 1.

6 Discussion and Future Work

Preventing centralization of storage. DAC members have an incentive to
pool their resources and pay for a central data repository, e.g., a cloud provider.
They then answer the client queries by querying the central repository, and split
the cost of the repository among themselves. However, if this single repository
loses the data, then all is lost. Thus, a DAC protocol should discourage data
centralization, and this can be done using a cryptographic Proofs of Replication
(POR) [22] that forces every node to store a diﬀerent incompressible version of
the data. However, POR introduces a signiﬁcant computation overhead. Inter-
estingly, the data centralization problem is not addressed by data availability or
storage systems such as Celestia [16] and Arweave [4].

While our protocol does not solve the problem, arguably, it discourages data
centralization. A node that participates in a centralization scheme is putting its
trust in the repository to keep the data around. However, the repository has
little to lose if the data is lost, while the node will lose its entire stake. As a
result, the node is incentivized to store the data locally rather than to trust a
third party with little at stake.

Preventing client DoS attack. Clients can send queries to the contract fre-
quently, at the cost of pc coins per query. Although pc can be as low as the gas
cost of posting the account information on chain (cf. Application in Section 2),
which implies a potential DoS vector, the contract can increase this cost to dis-
incentivize DoS attacks. The value of pc can even be adaptively chosen as a
function of the number of queries to reduce congestion. Then, as long as pc is
not subsidized by the bribe p1, no rational client would send a query unless the
nodes withhold their clues. However, pc should not be too high as that would
hurt the contract balance by requiring a high pcomp (cf. Remark 4), and discour-
age rational clients from sending queries for accounts with smaller balances, i.e.,
pf . An interesting future work is to determine the optimal pc that would not
impose a high burden on most accounts while making spamming attacks costly.

Cryptoeconomic Security for Data Availability Committees

17

Utility functions The analysis in Section 5 demonstrates how risk-aversion
implies a higher bribe for the adversary to violate security. However, the exact
shape of the utility function depends on the marginal utility for the coin in
which the payoﬀs are provided. Quantifying this marginal utility and identifying
the correct function would be important as future work to accurately assess the
aﬀect of bribery on security.

Acknowledgments. This work was supported by NSF, ONR, the Simons Foun-
dation, NTT Research, and a grant from Ripple. Additional support was pro-
vided by the Stanford Center for Blockchain Research.

References

1. Bennet Yee, Dawn Song, Patrick McCorry, and Chris Buckland. Shades of ﬁnality

and layer 2 scaling. arXiv:2201.07920, 2022.

2. Lewis Gudgeon, Pedro Moreno-Sanchez, Stefanie Roos, Patrick McCorry, and
Arthur Gervais. Sok: Layer-two blockchain protocols.
In Financial Cryptogra-
phy, volume 12059 of Lecture Notes in Computer Science, pages 201–226. Springer,
2020.

3. Patrick McCorry, Chris Buckland, Bennet Yee, and Dawn Song. Sok: Validating
bridges as a scaling solution for blockchains. Cryptology ePrint Archive:2021/1589,
2021.

4. Sam Williams, Viktor Diordiiev, Lev Berman, India Raybould, and Ivan Uemlianin.
Arweave: A protocol for economically sustainable information permanence. Yellow
paper, 2019. https://www.arweave.org/yellow-paper.pdf.

5. Yiannis Psaras and David Dias. The interplanetary ﬁle system and the ﬁlecoin

network. In DSN (Supplements), page 80. IEEE, 2020.

6. Andrew Miller, Ari Juels, Elaine Shi, Bryan Parno, and Jonathan Katz. Permacoin:
Repurposing bitcoin work for data preservation. In IEEE Symposium on Security
and Privacy, pages 475–490. IEEE Computer Society, 2014.

7. StarkEx v4. https://docs.starkware.co/starkex-v4/.
8. zkPorter: a breakthrough in L2 scaling.

https://blog.matter-labs.io/

zkporter-a-breakthrough-in-l2-scaling-ed5e48842fbf, 2021.

9. Eigenlayer. https://www.layrlabs.com/.
10. Aditi Sriram and John Adler. The Ethereum Oﬀ-Chain Data Availability Land-
scape. https://blog.celestia.org/ethereum-off-chain-data-availability-
landscape/, 2022.

11. Aditi Sriram, John Adler, and Mustafa Al-Bassam. Quantum gravity bridge: Se-
cure oﬀ-chain data availability for ethereum l2s with celestia. https://blog.
celestia.org/celestiums/, 2022.

12. Mustafa Al-Bassam, Alberto Sonnino, Vitalik Buterin, and Ismail Khoﬃ. Fraud
and data availability proofs: Detecting invalid blocks in light clients. In Financial
Cryptography (2), volume 12675 of Lecture Notes in Computer Science, pages 279–
298. Springer, 2021.

13. Mingchao Yu, Saeid Sahraei, Songze Li, Salman Avestimehr, Sreeram Kannan,
and Pramod Viswanath. Coded merkle tree: Solving data availability attacks in
blockchains. In Financial Cryptography, volume 12059 of Lecture Notes in Com-
puter Science, pages 114–134. Springer, 2020.

18

Ertem Nusret Tas and Dan Boneh

14. Vitalik Buterin. 2d data availability with kate commitments. https://ethresear.

ch/t/2d-data-availability-with-kate-commitments/8081, 2020.

15. Dankrad Feist. New sharding design with tight beacon and shard block integration.

https://notes.ethereum.org/@dankrad/new_sharding, 2022.

16. Mustafa Al-Bassam. Lazyledger: A distributed data availability ledger with client-

side smart contracts. arXiv:1905.09274, 2019.

17. Polygon.

Avail

- the data availability blockchain.

https://github.com/

maticnetwork/data-availability, 2021.

18. Kamilla Nazirkhanova, Joachim Neu, and David Tse. Information dispersal with
provable retrievability for rollups. arXiv:2111.12323, 2021. To appear in ACM
Advances in Financial Technologies - AFT 2022.

19. Justin Drake. Starkex validium ransom attack. https://notes.ethereum.org/

DD7GyItYQ02d0ax_X-UbWg?view, 2020.

20. Vitalik Buterin. On-chain scaling to potentially ˜500 tx/sec through mass tx vali-
dation. https://ethresear.ch/t/on-chain-scaling-to-potentially-500-tx-
sec-through-mass-tx-validation/3477, 2018.

21. Vitalik Buterin and Virgil Griﬃth.

Casper the friendly ﬁnality gadget.

arXiv:1710.09437, 2019.

22. Ben Fisch.

Poreps: Proofs of space on useful data.

Cryptology ePrint

Archive:2018/678, 2018.

A Proofs of Lemma 1, and Theorems 3 and 5 for

risk-neutral nodes

Proof of Lemma 1 for risk-neutral nodes and clients. Consider a game played among
the client and the DAC nodes. At the beginning of slot 2 the client V either re-
ceived k or more valid clues over the network from the nodes, or it did not.

– Let Q≥k denote the event that V takes the action Sq, i.e., sends query to the
contract, by slot 2 even if it receives k or more valid clues over the network
by the end of slot 3.

– Let Q<k denote the event that V takes the action Sq by slot 2 if it does not

receive k or more valid clues over the network by the end of slot 3.

– Let R denote the event that k or more nodes take the action Sr, i.e. send

clues to the client over the network, by slot 3.

– Let P denote the event k or more nodes take the action Sp, i.e., post clues
to the contract, at slot t + 1 ≤ 3 if a query is received by the contract by the
end of some slot t ≤ 2.

Given the events above, we can summarize the V’s payoﬀ by the following table:

Towards contradiction, suppose there exists a Nash equilibrium, where the
probability Pr[R∧P ] is non-zero. If Pr[R∧P ] > 0, then the client never takes the
actions Q≥k ∧ Q<k and Q≥k ∧ Q<k with positive probability in the equilibrium,
as it can increase its expected payoﬀ by reducing the probability of Q≥k ∧ Q<k
in favor of Q≥k ∧ Q<k, and by reducing the probability of Q≥k ∧ Q<k in favor
of Q≥k ∧ Q<k. Hence, in the equilibrium, either V receives k or more valid clues
over the network by the end of slot 3, i.e., the event R happens, or V sends a

Cryptoeconomic Security for Data Availability Committees

19

R ∧ P
R ∧ P
R ∧ P
R ∧ P

Q≥k ∧ Q<k
pf − pc
pf − pc
pf + pcomp − pc
pcomp − pc

Q≥k ∧ Q<k
pf − pc
0
pf + pcomp − pc
0

Q≥k ∧ Q<k
pf
pf − pc
pf
pcomp − pc

Q≥k ∧ Q<k
pf
0
pf
0

Table 3: Payoﬀ of a risk-neutral client

query to the contract by slot 2. In the latter case, V’s query is received by the
contract by the end of slot 2.

If a valid query appears in the contract by the end of some slot t, and the
node Pi, i ∈ [N −f ], sends its clue to the contract at slot t+1, its payoﬀ becomes
−pw. On the other hand, if a valid query is received by the contract by the end
of some slot t, and Pi does not send its clue to the contract at slot t + 1, its
payoﬀ can at most be −pw − (cid:15). Since −pw > −pw − (cid:15), in the equilibrium, if V’s
query is received by the contract by the end of slot 2, Pi sends its clue to the
contract by slot 3, which is then observed by the client by the beginning of slot
4. As this holds for all nodes Pi, i ∈ [N −f ], if a query is received by the contract
by the end of slot 2, all non-adversarial nodes send their clues to the contract
by slot 3, i.e., the event P happens. However, this implies Pr[R ∨ P ] = 1, and
Pr[R ∧P ] = 0, which is a contradiction. Consequently, 4-security is satisﬁed with
overwhelming probability in all Nash equilibria.

Proof of Theorem 3 for risk-neutral nodes. Suppose a query is received by the
contract at some slot t ∈ N. Consider the adversary A that makes every ad-
versarial node take the action ¬Sp (not post clues to the contract) at all slots.
Suppose there exists a Nash equilibrium of this subgame, where each node Pi,
i ∈ [N − f ], independently decides to take the action Sp at slot t + 1, with
probability r∗ ∈ [0, 1), and to take the action ¬Sp at slot t + 1, with probability
1−r∗. Then, in the equilibrium, the expected payoﬀ of each node Pi, i ∈ [N −f ],
becomes

r∗(−pw + E[fi(X)|Xi = 1]) + (1 − r∗)E[fi(X)|Xi = 0]

Here, E[fi(X)|Xi = 1] and E[fi(X)|Xi = 0] denote the expected payoﬀ of Pi
given all other nodes’ actions and conditioned on the fact that Pi takes the action
Sp and ¬Sp at slot t + 1 respectively. As the slashing function is symmetric and
oﬀers no rewards, there exist e0, e1 ∈ [−ps, 0] such that E[fi(X)|Xi = 1] =
E[fj(X)|Xj = 1] = e1, and E[fi(X)|Xi = 0] = E[fj(X)|Xj = 0] = e0 for all
i, j ∈ [N − f ].

For the action proﬁle described above to be a Nash equilibrium, it must be

the case that

r∗(−pw + e1) + (1 − r∗)e0 ≥ r(−pw + e1) + (1 − r)e0

for all r ∈ [0, 1]. For each i ∈ [N − f ], the inequality above is satisﬁed by

– r∗ = 1, if −pw + e1 > e0,

20

Ertem Nusret Tas and Dan Boneh

– r∗ = 0, if −pw + e1 < e0,
– any r∗ ∈ [0, 1], if −pw + e1 = e0.

Let r∗

−i ∈ [0, 1] denote the probability that among the N − f − 1 non-
adversarial nodes other than Pi, at most k − 1 nodes take the action Sp (send
clues to the contract) at slot t + 1 in the equilibrium. As the slashing function
is symmetric, r∗

−1 for all i, j ∈ [N − f ], and

−j = r∗

−i = r∗

−(1 − r∗

−1)B − r∗

−1ps ≤ e0 ≤ 0

−pw − ps ≤ −pw + e1 ≤ −pw,

where B < pw. This implies a value r∗
r∗ < 1.

−1 ∈ (0, 1] such that −pw + e1 ≤ e0, and

If −pw +e1 < e0, then r∗ = 0. On the other hand, if −pw +e1 = e0, as B < pw,
−1 ∈ (0, 1], which implies r∗ ∈ [0, 1). Consequently,
it must be the case that r∗
if B < pw, there indeed exists a (0, 0)-adversary A and a Nash equilibrium,
where each non-adversarial node independently decides to not post its clue to
the contract at the slot after a query is received by the contract, with probability
r∗ > 0.

Finally, suppose there exists a subgame perfect equilibrium of the dynamic
game, where none of the nodes send a valid clue to the client V over the network
by slot 3, and V sends its query to the contract by slot 2. Once the query appears
in the contract, each nodes chooses to withhold its clue from the contract in the
next slot with probability r∗.

As shown above, if there is a query in the contract, none of the nodes can
increase its expected payoﬀ by deviating from the speciﬁed action given the other
nodes’ actions. Similarly, V cannot increase its expected payoﬀ by not sending
a query to the contract, when none of the nodes sends a valid clue over the
network by slot 3. Finally, none of the nodes can increase its expected payoﬀ by
sending a valid clue to V over the network by slot 2, since this does not aﬀect
V’s behavior. This is because k > 1 and all other nodes refuse to send their clues
over the network. Hence, the claimed action proﬁle indeed constitutes a subgame
perfect equilibrium. However, in this case, there are less than k valid clues in the
contract by slot 4 with probability at least (1 − r∗)N −f > 0. Thus, there exists a
(0, 0)-adversary and a subgame perfect equilibrium, where 4-security is violated
with positive probability.

Proof of Theorem 5. We ﬁrst show that given the slashing function of Section 3,
qA
v ≤ q∗ for any p0-adversary A. Let F denote the event that there are less than
k valid clues in the contract at slot t + 1. Towards contradiction, suppose there
exists a Nash equilibrium such that Pr[F ] > q∗ in the equilibrium. Then, with
probability greater than q∗, at least N − f − k + 1 non-adversarial nodes take
the action ¬Sp, i.e., do not post their clues to the contract, at slot t + 1 in the
equilibrium. Let U ∗
i denote the realization of the node Pi’s payoﬀ, i ∈ [N − f ],
in the equilibrium. In the case of event F , at least N − f − k + 1 nodes incur
a penalty of −ps, and given the total bribe p0, the total expected payoﬀ of the

Cryptoeconomic Security for Data Availability Committees

21

non-adversarial nodes can at most be

N −f
(cid:88)

i=1

E[U ∗

i |F ] ≤ p0 − (k − 1)pw − (N − f − k + 1)ps

in the equilibrium. Conversely, if the event F does not happen, the total expected
payoﬀ can at most be

N −f
(cid:88)

i=1

E[U ∗

i |F ] ≤ p0 − (N − f )pw

in the equilibrium. Using the two inequalities and the assumed lower bound on
Pr[F ], we derive the following upper bound on the total expected payoﬀ of the
non-adversarial nodes in the equilibrium:

N −f
(cid:88)

i=1

E[U ∗

i ] ≤ p0 − (N − f )pw − Pr[F ](N − f − k + 1)(ps − pw)

< p0 − (N − f )pw − q∗(N − f − k + 1)(ps − pw)
= −(N − f )pw

The inequality above implies the existence of at least one node Pi∗ , i∗ ∈ [N − f ],
such that E[U ∗
i∗ ] < −pw. However, sending a valid clue to the contract at slot
t + 1 gives a payoﬀ of −pw for Pi∗ regardless of the actions of all other nodes,
implying that there exists an action that strictly dominates the one taken by
Pi∗ in the equilibrium. Thus, we have reached a contradiction.

***

We next construct a p0-adversary A such that for any compliant slashing
function, there exists a Nash equilibrium, where qA
v ≥ q∗. Let Xi denote the
indicator random variable for the event that Pi takes the action Sp, i.e. sends its
query to the contract, at slot t + 1. Then, any adversary A can be characterized
as follows:

– Bribes oﬀered to the non-adversarial nodes Pi, i ∈ [N − f ]: pi

Bribes must satisfy the equation (cid:80)
is called corrupt if it accepts the bribe.

i∈[N −f ] pi

b, i ∈ [N − f ].
b ≤ p0. A non-adversarial node

– The probability distribution over the actions adopted by the adversarial and
corrupt nodes. For each Q, {N − f + 1, . . . , N } ⊆ Q ⊆ [N ], representing the
set of adversarial and corrupt nodes, A proposes the following action proﬁle:
Pr[Xi = xi ∈ {0, 1}, i ∈ Q] = q(xi,i∈Q).

Similarly, given any adversary A, each Nash equilibrium can be described by the
following variables: {˜r∗
i }i∈[N −f ]. Here, ˜r∗
i denotes the probability
that Pi accepts the bribe in the equilibrium, whereas r∗
i denotes the probability
that Pi takes the action Sp in the event that it does not accept the bribe.
We allow r∗
i = 1, i.e., if Pi accepts the

i to be undeﬁned (shown as −) if ˜r∗

i }i∈[N −f ] and {r∗

22

Ertem Nusret Tas and Dan Boneh

adversary’s bribe, in which case it will take the action Sp as dictated by the
adversary. In the equilibrium, each node Pj, j ∈ [N − f ], chooses the values ˜r∗
j
and r∗
j to maximize its expected payoﬀ given the adversary A, and the other
nodes’ equilibrium actions, i.e., {˜r∗

i }i∈[N −f ]/{j} and {r∗
Consider the p0-adversary A that oﬀers a bribe of pi

i }i∈[N −f ]/{j}.
b = p0/(N − f − k + 1)
to the nodes Pi, i ∈ [N − f − k + 1], and for the set Q ⊆ [N − f − k + 1] ∪ {N −
f + 1, . . . , N }, speciﬁes

Pr[Xi = 0, i ∈ Q] =

Pr[Xi = 1, i ∈ Q] = 1 −

p0
(N − f − k + 1)(ps − pw)

,

p0
(N − f − k + 1)(ps − pw)

.

We will show that given A, for any compliant slashing function, there exists a
v ≥ q∗. In the equilibrium, for each i ∈ [N − f −
Nash equilibrium such that qA
i , r∗
k + 1], either (˜r∗
i ) = (0, 0), and for each i ∈ [N − f ]/[N −
f − k + 1], (˜r∗
i , r∗
i ) = (0, 0). In other words, nodes that are oﬀered bribes either
accept the bribe and become corrupted, or do not post their clues to the contract
in the equilibrium, whereas those that are not oﬀered bribes post their clues to
the contract.

i ) = (1, −) or (˜r∗

i , r∗

Since the considered slashing functions are compliant, they oﬀer no rewards
and satisfy B minimal punishment for some B ≥ pw by Theorem 3. Thus, for all
i ∈ [N ], it must be the case that fi(x) ≤ 0 for all x ∈ {0, 1}N , and fi(x) ≤ −pw
for all x ∈ {0, 1}N such that xi = 0. Then, if a node Pi, i ∈ [N − f − k + 1],
rejects the bribe, its expected payoﬀ becomes

(−pw + E[fi(X)|Xi = 1])r∗

i + E[fi(X)|Xi = 0](1 − r∗

i ) ≤ E[fi(X)|Xi = 1]r∗

i − pw.

Here, E[fi(X)|Xi = 1] and E[fi(X)|Xi = 0] denote the expected payoﬀ of Pi
given all other nodes’ actions in the claimed equilibrium and conditioned on
the fact that Pi takes the actions Sp and ¬Sp at slot t + 1 respectively. As the
slashing function is symmetric, for any i, j ∈ [N − f − k + 1], E[fi(X)|Xi = 1] =
E[fj(X)|Xj = 1] = e1 ≤ 0 and E[fi(X)|Xi = 0] = E[fj(X)|Xj = 0] = e0 ≤
−B ≤ −pw.

As each node Pi, i ∈ [N − f − k + 1], maximizes its payoﬀ given all other
nodes’ payoﬀs in the equilibrium, if Pi rejects the bribe, it must be the case that

– r∗

i = 1, if −pw + e1 > e0. In this case, Pi’s expected payoﬀ becomes −pw +
e1 ≤ −pw.
i = 0, if −pw + e1 < e0.
i can be any value in [0, 1], if −pw + e1 = e0. In this case, Pi’s expected
payoﬀ becomes e0 ≤ −B ≤ −pw

– r∗
– r∗

Cryptoeconomic Security for Data Availability Committees

23

On the other hand, if Pi accepts the bribe, its expected payoﬀ becomes at least

p0
N − f − k + 1

− ps

p0
(N − f − k + 1)(ps − pw)
p0
(N − f − k + 1)(ps − pw)

1 −

(cid:18)

(cid:19)

+ (−pw + E[fi(X)|Xi = 1])
(cid:18)

= −pw + e1

1 −

p0
(N − f − k + 1)(ps − pw)

(cid:19)

.

Since e1 ≤ 0, if −pw + e1 ≥ e0, then the expected payoﬀ of node Pi when it
accepts the bribe is at least as large as its expected payoﬀ when it rejects the
bribe. Hence, if −pw + e1 ≥ e0, for the nodes Pi, i ∈ [N − f − k + 1], there does
not exist any action that strictly dominates (˜r∗
i ) = (1, −). In this case, the
action proﬁle speciﬁed by the adversary constitutes a Nash equilibrium, and qA
v
becomes at least

i , r∗

Pr[Xi = 0, i ∈ Q] =

p0
(N − f − k + 1)(ps − pw)

= q∗,

where Q = [N − f − k + 1] ∪ {N − f + 1, . . . , N }. Conversely, if −pw + e1 < e0,
then either the nodes Pi, i ∈ [N − f − k + 1], all reject the bribe, and set r∗
i = 0,
v ≥ q∗. In
which implies qA
both cases, qA

v = 1, or they all accept the bribe, which implies qA

v ≥ q∗, thus concluding the proof.

B Proofs of Lemma 1, and Theorems 3, and 4 for

risk-averse nodes

Proof of Lemma 1 for risk-averse nodes and clients. Consider a game played among
the client and the DAC nodes. At the beginning of slot 2, the client V either
received k or more valid clues over the network from the nodes, or it did not. Re-
call the deﬁnitions of the events Q≥k, Q<k, R and P from the proof of Lemma 1
for risk-neutral nodes in Appendix A. Given these events, we can summarize the
V’s payoﬀ by the following table:

R ∧ P
R ∧ P
R ∧ P
R ∧ P

Q≥k ∧ Q<k
(pf − pc)ν
(pf − pc)ν
(pf + pcomp − pc)ν
(pcomp − pc)ν

Q≥k ∧ Q<k
(pf − pc)ν
0
(pf + pcomp − pc)ν
0

Q≥k ∧ Q<k
(pf )ν
(pf − pc)ν
(pf )ν
(pcomp − pc)ν

Q≥k ∧ Q<k
(pf )ν
0
(pf )ν
0

Table 4: Utility of a risk-averse client

Towards contradiction, suppose there exists a Nash equilibrium, where the
probability Pr[R∧P ] is non-zero. If Pr[R∧P ] > 0, then the client never takes the

24

Ertem Nusret Tas and Dan Boneh

actions Q≥k ∧ Q<k and Q≥k ∧ Q<k with positive probability in the equilibrium,
as it can increase its expected payoﬀ by reducing the probability of Q≥k ∧ Q<k
in favor of Q≥k ∧ Q<k, and by reducing the probability of Q≥k ∧ Q<k in favor
of Q≥k ∧ Q<k. Hence, in the equilibrium, either V receives k or more valid clues
over the network by the end of slot 3, i.e., the event R happens, or V sends a
query to the contract by slot 2. In the latter case, V’s query is received by the
contract by the end of slot 2.

If a valid query appears in the contract by the end of some slot t, and the
node Pi, i ∈ [N −f ], sends its clue to the contract at slot t+1, its payoﬀ becomes
(C − pw)ν. On the other hand, if a valid query is received by the contract by the
end of some slot t, and Pi does not send its clue to the contract at slot t + 1,
its payoﬀ can at most be (C − pw − (cid:15))ν. Since (C − pw)ν > (C − pw − (cid:15))ν, in
the equilibrium, if V’s query is received by the contract by the end of slot 2, Pi
sends its clue to the contract by slot 3, which is then observed by the client by
the beginning of slot 4. As this holds for all nodes Pi, i ∈ [N − f ], if a query
is received by the contract by the end of slot 2, all non-adversarial nodes send
their clues to the contract by slot 3, i.e., the event P happens. However, this
implies Pr[R∨P ] = 1, and Pr[R∧P ] = 0, which is a contradiction. Consequently,
4-security is satisﬁed with overwhelming probability in all Nash equilibria.

Theorem 2 follows from Lemma 1, which shows security under no attack (A3)

for the slashing function of Section 3.

Proof of Theorem 3 for risk-averse nodes. Suppose a query is received by the
contract at some slot t ∈ N. Consider the adversary A that makes every ad-
versarial node take the action ¬Sp (not post clues to the contract) at all slots.
Suppose there exists a Nash equilibrium of this subgame, where each node Pi,
i ∈ [N − f ], independently decides to take the action Sp at slot t + 1, with
probability r∗ ∈ [0, 1), and to take the action ¬Sp at slot t + 1, with probability
1−r∗. Then, in the equilibrium, the expected payoﬀ of each node Pi, i ∈ [N −f ],
becomes

r∗E[(C − pw + fi(X))ν|Xi = 1] + (1 − r∗)E[(C + fi(X))ν|Xi = 0],

where C = ps+pw. Here, E[(C −pw +fi(X))ν|Xi = 1] and E[(C +fi(X))ν|Xi = 0]
denote the expected payoﬀ of Pi given all other nodes’ actions and conditioned
on the fact that Pi takes the action Sp and ¬Sp at slot t + 1 respectively. As the
slashing function is symmetric and oﬀers no rewards, there exist e0, e1 ∈ [−ps, 0]
such that E[(C − pw + fi(X))ν|Xi = 1] = E[(C − pw + fj(X))ν|Xj = 1] = e1, and
E[(C + fi(X))ν|Xi = 0] = E[(C + fj(X))ν|Xj = 0] = e0 for all i, j ∈ [N − f ].

For the action proﬁle described above to be a Nash equilibrium, it must be

the case that

r∗e1 + (1 − r∗)e0 ≥ re1 + (1 − r)e0

for all r ∈ [0, 1]. For each i ∈ [N − f ], the inequality above is satisﬁed by

– r∗ = 1, if e1 > e0,

Cryptoeconomic Security for Data Availability Committees

25

– r∗ = 0, if e1 < e0,
– any r∗ ∈ [0, 1], if e1 = e0.

Let r∗

−i ∈ [0, 1] denote the probability that among the N − f − 1 non-
adversarial nodes other than Pi, at most k − 1 nodes take the action Sp (send
clues to the contract) at slot t + 1 in the equilibrium. As the slashing function
is compliant, r∗

−1 for all i, j ∈ [N − f ], and

−j = r∗

−i = r∗

(1 − r∗

−1)(C − B)ν − r∗

−1(C − ps)ν ≤ e0 ≤ (C)ν

(C − pw − ps)ν ≤ e1 ≤ (C − pw)ν,

where B < pw. This implies a value r∗

−1 ∈ (0, 1] such that e1 ≤ e0, and r∗ < 1.
If e1 < e0, then r∗ = 0. On the other hand, if e1 = e0, as B < pw, it must
be the case that r∗
−1 ∈ (0, 1], which implies r∗ ∈ [0, 1). Consequently, if B < pw,
there indeed exists a (0, 0)-adversary A and a Nash equilibrium, where each
non-adversarial node independently decides to not post its clue to the contract
at the slot after a query is received by the contract, with probability r∗ > 0.

Finally, suppose there exists a subgame perfect equilibrium of the dynamic
game, where none of the nodes send a valid clue to the client V over the network
by slot 3, and V sends its query to the contract by slot 2. Once the query appears
in the contract, each nodes chooses to withhold its clue from the contract in the
next slot with probability r∗.

As shown above, if there is a query in the contract, none of the nodes can
increase its expected payoﬀ by deviating from the speciﬁed action given the other
nodes’ actions. Similarly, V cannot increase its expected payoﬀ by not sending
a query to the contract, when none of the nodes sends a valid clue over the
network by slot 3. Finally, none of the nodes can increase its expected payoﬀ by
sending a valid clue to V over the network by slot 2, since this does not aﬀect
V’s behavior. This is because k > 1 and all other nodes refuse to send their clues
over the network. Hence, the claimed action proﬁle indeed constitutes a subgame
perfect equilibrium. However, in this case, there are less than k valid clues in the
contract by slot 4 with probability at least (1 − r∗)N −f > 0. Thus, there exists a
(0, 0)-adversary and a subgame perfect equilibrium, where 4-security is violated
with positive probability.

Proof of Theorem 4. Consider the subgame, where a query is received by the
contract of Section 3 at some slot t. Let qA
v denote the probability that given
an adversary A, there are less than k valid clues in the contract at slot t + 1
in the Nash equilibrium with the largest probability of failure. We ﬁrst show
that there exists a function q∗(x) : [0, (N − f − k + 1)(ps − pw)) −→ (0, 1) such
that given the slashing function of Section 3, for any p0-adversary A, 0 ≤ p0 <
(N − f − k + 1)(ps − pw), it holds that qA
v ≤ q∗(p0). By Remark 2, if p0 ≥
(N − f − k + 1)(ps − pw), qA
v = 1 for any compliant slashing function, including
the function of Section 3.

Given a p0-adversary with p0 < (N − f − k + 1)(ps − pw), consider the Nash
equilibrium with the maximum failure probability. Let qi denote the probability
that in the equilibrium, Pi, i ∈ [N −f ], does not take the action Sp, i.e., does not

26

Ertem Nusret Tas and Dan Boneh

post its clue to the contract, and there are less than k valid clues in the contract
at slot t + 1. Let pi
b denote the bribe oﬀered to Pi by A. As Pi maximizes its
utility given all other nodes’ actions in the equilibrium, any qi ∈ [0, 1] satisﬁes
the following inequality; otherwise, Pi can increase its utility by posting its clue
to the contract at slot t + 1:

(C − pw)ν ≤ qi(pi

b + C − ps)ν + (1 − qi)(pi

b + C − pw)ν,

which further implies

qi ≤

where C = ps + pw.

b + C − pw)ν − (C − pw)ν

(pi
b + C − pw)ν − (pi

b + C − ps)ν

(pi

,

Let G denote the set of subsets of [N − f ] with N − f − k + 1 elements. Let
EG, G ∈ G, denote the event that the nodes in G do not take the action Sp at
slot t + 1. By deﬁnition of qi,

qi = Pr[∪G∈G:i∈GEG] = Pr[∪G∈GiEG],

where Gi = {G ∈ G : i ∈ G}. Similarly, by deﬁnition of qA
v ,

qA
v = Pr[∪G∈GEG].

Hence, the function q∗(p0) is upper bounded by the solution ˜q∗(p0) to the fol-
lowing optimization problem:

max
G∈G

Pr[∪G∈GEG]

s.t. Pr[∪G∈GiEG] = qi ≤

N −f
(cid:88)

pi
b ≤ p0

i=1
pi
b ≥ 0 ∀i ∈ [N − f ]

b + C − pw)ν − (C − pw)ν

(pi
b + C − pw)ν − (pi

b + C − ps)ν

(pi

∀i ∈ [N − f ]

Let { ˜EG : G ∈ G}, denote one set of events for which the value of Pr[∪G∈GEG]
is maximized. Let ˜pi
b and ˜qi, i ∈ [N − f ], denote the optimal values of the
parameters pi

b and qi, i ∈ [N − f ], associated with this set of events.
We next construct a p0-adversary A such that for any compliant slashing
v ≥ ˜q∗(p0) ≥ q∗(p0). This

function, there exists a Nash equilibrium, where qA
would show that the slashing function of Section 3 is security optimal:

– Bribes oﬀered to the nodes Pi, i ∈ [N − f ] are given by ˜pi
b.
– The probability distribution over the actions adopted by the adversarial and
corrupt nodes is determined by the events ˜EG, which satisfy the equation
Pr[∪G∈Gi

˜EG] = ˜qi.

Cryptoeconomic Security for Data Availability Committees

27

By deﬁnition of the optimization problem, it holds that

˜qi ≤

b + C − pw)ν − (C − pw)ν

(pi
b + C − pw)ν − (pi

b + C − ps)ν

(pi

∀i ∈ [N − f ]

(2)

i }i∈[N −f ] and {r∗

Recall that given any adversary A, each Nash equilibrium can be described
i }i∈[N −f ]. Here, ˜r∗
by the following variables: {˜r∗
i denotes the
probability that Pi accepts the bribe in the equilibrium, whereas r∗
i denotes the
probability that Pi takes the action Sp, i.e., posts a valid clue to the contract,
at slot t + 1 in the event that it does not accept the bribe. We allow r∗
i to be
undeﬁned if Pi accepts the bribe, in which case it will take the action Sp as
dictated by the adversary.

If a node Pi, i ∈ [N − f ], rejects the bribe, its expected payoﬀ becomes

E[(C + fi(X) − pw)ν|Xi = 1]r∗

i + E[(C + fi(X))ν|Xi = 0](1 − r∗
i )

Here the expectation is over the actions of the other nodes in the equilibrium.
As the slashing function satisﬁes symmetry, for any i, j ∈ [N − f ], E[(C +
fi(X) − pw)ν|Xi = 1] = E[(C + fj(X) − pw)ν|Xj = 1] = e1 and E[(C +
fi(X))ν|Xi = 0] = E[(C + fj(X))ν|Xj = 0] = e0. As Pi maximizes its util-
ity given all other nodes’ actions in the equilibrium, it must be the case that

– r∗
– r∗
– r∗

i = 1, if e1 > e0. In this case, Pi’s expected utility becomes e1.
i = 0, if e1 < e0.
i can be any value in [0, 1], if e1 = e0. In this case, Pi’s expected utility
becomes e1.

Here, e1 is upper bounded as shown by the following lemma:
Lemma 2. For any i ∈ [N − f ], pi

b ≥ 0 and r∗

i ∈ [0, 1],

(C − pw)ν + (1 − r∗

i )(E[(C − pw + fi(X) + pi

b)ν|Xi = 1] − (C + pi

b − pw)ν)

≥ E[(C + fi(X) − pw)ν|Xi = 1] = e1

Proof. For any ﬁxed a, b, c ∈ R+ ∪ {0} such that a ≥ b ≥ c, it holds that
(a−c)ν −(b−c)ν ≥ aν −bν, which implies bν −(b−c)ν ≥ aν −(a−c)ν. Moreover,
for any compliant slashing function, −ps ≤ fi(x) ≤ 0 for all x ∈ {0, 1}N and all
i ∈ [N ]. Since C = ps + pw, it holds that C − pw + fi(x) ≥ 0 for all x ∈ {0, 1}N
and all i ∈ [N ]. Then, for any x ∈ {0, 1}N −f and i ∈ [N − f ],
(C − pw)ν − (C − pw + fi(x))ν ≥ (C − pw + pi

b)ν − (C − pw + fi(x) + pi

b)ν

=⇒ (C − pw)ν − ((C − pw + pi
=⇒ (C − pw)ν − (1 − r∗

≥ (C − pw + fi(x))ν,

b)ν − (C − pw + fi(x) + pi

b)ν) ≥ (C − pw + fi(x))ν

i )((C − pw + pi

b)ν − (C − pw + fi(x) + pi

b)ν)

i ∈ [0, 1] and (C − pw + pi

b)ν − (C − pw + fi(x) + pi

b)ν ≥ 0. Hence, by

i )(E[(C − pw + fi(X) + pi

b)ν|Xi = 1] − (C + pi

b − pw)ν)

since 1 − r∗
linearity of expectation,
(C − pw)ν + (1 − r∗

≥ E[(C − pw + fi(X))ν|Xi = 1].

28

Ertem Nusret Tas and Dan Boneh

On the other hand, if e1 > e0 and Pi accepts the bribe, its expected payoﬀ

becomes at least

(cid:0)C + pi

b − ps

(cid:1)ν

˜qi + E[(C − pw + fi(X) + pi

≥ (C − pw)ν + (1 − ˜qi)(E[(C − pw + fi(X) + pi
≥ e1.

b)ν|Xi = 1](1 − ˜qi)
b)ν|Xi = 1] − (C + pi

b − pw)ν)

Here, the ﬁrst inequality follows from the equation (2), and the last inequality
follows from Lemma 2. Hence, if e1 ≥ e0, the expected utility of node Pi when
it accepts the bribe is at least as large as its expected utility when it rejects the
bribe. Thus, for the nodes Pi, i ∈ [N − f ], there does not exist any action that
dominates (˜r∗
i ) = (1, −), implying that they accept the adversary’s bribe
when any bribe oﬀer is made. In this case, the action proﬁle speciﬁed by the
adversary constitutes a Nash equilibrium, and in the equilibrium, qA
v becomes
at least ˜q∗(p0) ≥ q∗(p0).

i , r∗

Finally, if e1 < e0, then either the nodes Pi, i ∈ [N − f ], all reject the bribe,
and set r∗
i = 0, or they all accept the bribe. The ﬁrst case happens if for the
nodes Pi, i ∈ [N − f − k + 1], there does not exist any action that dominates
(˜r∗
i , r∗
v becomes 1. In the latter case,
v ≥ q∗(p0) as argued above, thus concluding the proof.
qA

i ) = (0, 0). Then, in the equilibrium, qA

C Probability of security failure for risk-averse nodes

Theorem 10. For any p0, 0 ≤ p0 < (N − f − k + 1)(ps − pw), and ν ∈ (0, 1],
q∗
p0,ν is the solution to the following optimization problem: Let G denote the set
of subsets of [N −f ] with N −f −k +1 elements. Let xG denote variables indexed
by the sets G ∈ G.

|G|
(cid:88)

j=1

xG

(cid:88)

max
j∈[|G|]

s.t.

xG ≤

G∈G:i∈G

N −f
(cid:88)

pi
b ≤ p0

b + ps)ν − (ps)ν

(pi
b + ps)ν − (pi

b + pw)ν

(pi

∀i ∈ [N − f ]

(3)

i=1
pi
b ≥ 0 ∀i ∈ [N − f ]
xG ∈ [0, 1] ∀G ∈ G

By Remark 2, q∗

p0,ν = 1 if p0 ≥ (N − f − k + 1)(ps − pw).

Proof of Theorem 10. From the proof of Theorem 4, we know that q∗
p0,ν is the
solution to the following optimization problem, where EG is the event that the

Cryptoeconomic Security for Data Availability Committees

29

nodes in G do not post their clues to the contract at slot t + 1 when a query is
received by the contract at slot t:

max
G∈G

Pr[∪G∈GEG]

s.t. Pr[∪G∈G:i∈GEG] = qi ≤

N −f
(cid:88)

pi
b ≤ p0

i=1
pi
b ≥ 0 ∀i ∈ [N − f ]

b + C − pw)ν − (C − pw)ν

(pi
b + C − pw)ν − (pi

b + C − ps)ν

(pi

∀i ∈ [N − f ]

(4)
Let {Gj}j∈[|G|] denote a total order across the events G ∈ G. Deﬁning the
disjoint events ˆEG1 := EG1, and ˆEGi := EGi/(∪j∈[i−1]EGj ) for i = 2, . . . , |G|,
we observe that the solution of the following optimization is at least as large as
the solution to the problem presented by Formula (4), i.e., q∗

p0,ν:

max
j∈[|G|]

|G|
(cid:88)

j=1

Pr[ ˆEGj ]

(cid:88)

s.t.

Pr[ ˆEG] ≤

G∈G:i∈G

N −f
(cid:88)

pi
b ≤ p0

b + C − pw)ν − (C − pw)ν

(pi
b + C − pw)ν − (pi

b + C − ps)ν

(pi

∀i ∈ [N − f ]

(5)

i=1
pi
b ≥ 0 ∀i ∈ [N − f ]
Pr[ ˆEG] ∈ [0, 1] ∀G ∈ G

This is because by deﬁnition of ˆEGj , the optimal values are the same

Pr[∪G∈GEG] = Pr[∪G∈G ˆEG] =

|G|
(cid:88)

j=1

Pr[ ˆEGj ]

in both formulas whereas the constraints are relaxed in Formula (5):

(cid:88)

G∈G:i∈G

Pr[ ˆEG] = Pr[∪G∈G:i∈G ˆEG] ≤ Pr[∪G∈G:i∈GEG]

Note that by setting all of EG, G ∈ G, to be disjoint events, which implies
ˆEG = EG, we can ensure that q∗
p0,ν is the same as the solution to Formula (5). In
this case, using C = ps + pw and deﬁning xG := ˆEG, we can re-write Formula (4)
as Formula (3).

30

Ertem Nusret Tas and Dan Boneh

Theorem 11. Suppose p0 < (N − f − k + 1)(ps − pw). Then,

(ps + pb)ν − (ps)ν

(ps + pb)ν − (pw + pb)ν ≤ q∗
1
q∗
p0,ν ≤
min
N − f − k + 1

p0,ν, and
(cid:18) p0

ps − pw

,

(ps + p0)ν − (ps)ν
(ps + p0)ν − (pw + p0)ν

(cid:19)

,

where pb =

p0
N −f −k+1 .

Proof of Theorem 11. We ﬁrst prove the upper bound. Recall that the maximum
value for q∗

p0,ν is given by the solution to Formula (3), where

q∗
p0,ν =

(cid:88)

G∈G

xG =

1
N − f − k + 1

N −f
(cid:88)

(cid:88)

xG

i=1

G∈G:i∈G

≤

1
N − f − k + 1

N −f
(cid:88)

i=1

b + C − pw)ν − (C − pw)ν

(pi
b + C − pw)ν − (pi

b + C − ps)ν

(pi

(6)

(7)

Since (cid:80)N −f

i=1 pi

b ≤ p0 and the function

f (x) =

(x + C − pw)ν − (C − pw)ν
(x + C − pw)ν − (x + C − ps)ν

is convex in x, the sum in equation (7) is maximized when one variable, e.g., p1
b
is set to be p0 and the rest becomes 0. Thus, given C = ps + pw, we obtain

q∗
p0,ν ≤

1
N − f − k + 1

(ps + p0)ν − (ps)ν
(ps + p0)ν − (pw + p0)ν .

We next observe that for any pi

b such that 0 ≤ pi

b ≤ ps − pw

7, and any

ν ∈ (0, 1), it holds that

(ps + pi

b)ν − (ps)ν
b)ν − (pw + pi

b)ν

(ps + pi

≤

pi
b
ps − pw

Thus, if we relax the constraints for (cid:80)
bounds with pi
is possible since the problem has now become convex, we obtain

G∈G:i∈G xG by replacing their upper
b/(ps − pw) in Formula (3), and maximize the objective, which

1
N − f − k + 1

p0
ps − pw

.

(Note that this is the solution to the optimization problem when ν = 1.)

Finally, we prove the lower bound on q∗

p0-adversary A that oﬀers a bribe of pi

p0,ν. For this purpose, we consider the
b = p0/((N −f −k+1)(ps−pw)) = pb to the

7 Oﬀering more bribes to a node is a waste of coins for the adversary. Without loss of

generality, we can assume pi

b ≤ ps − pw.

Cryptoeconomic Security for Data Availability Committees

31

nodes Pi, i ∈ [N −f −k+1], and for the set Q ⊆ [N −f −k+1]∪{N −f +1, . . . , N },
speciﬁes

Pr[Xi = 0, i ∈ Q] = ˜q =

(C + pb − pw)ν − (C − pw)ν
(C + pb − pw)ν − (C + pb − ps)ν ,

Pr[Xi = 1, i ∈ Q] = 1 − ˜q = 1 −

(C + pb − pw)ν − (C − pw)ν
(C + pb − pw)ν − (C + pb − ps)ν .

v ≥ ˜q, which would imply q∗

We will show that given A, for any compliant slashing function, there exists a
Nash equilibrium such that qA
p0,ν ≥ ˜q. Recall the
variables ˜r∗
i and r∗
from the proof of Theorem 5. In the equilibrium, either
i
(˜r∗
i ) = (0, 0) for all i ∈
[N − f − k + 1]. In other words, each node that is oﬀered a bribe either accepts
the bribe and becomes corrupted, or does not send a valid clue to the contract
at slot t + 1.

i ) = (1, −) for all i ∈ [N − f − k + 1], or (˜r∗

i , r∗

i , r∗

If a node Pi, i ∈ [N −f −k +1], rejects the bribe, its expected payoﬀ becomes

E[(C + fi(X) − pw)ν|Xi = 1]r∗

i + E[(C + fi(X))ν|Xi = 0](1 − r∗
i )

As the slashing function satisﬁes symmetry, for any i, j ∈ [N − f − k + 1],
E[(C + fi(X) − pw)ν|Xi = 1] = E[(C + fj(X) − pw)ν|Xj = 1] = e1 and E[(C +
fi(X))ν|Xi = 0] = E[(C + fj(X))ν|Xj = 0] = e0. As Pi maximizes its utility
given all other nodes’ actions in the equilibrium, it must be the case that

– r∗
– r∗
– r∗

i = 1, if e1 > e0. In this case, Pi’s expected utility becomes e1.
i = 0, if e1 < e0.
i can be any value in [0, 1], if e1 = e0. In this case, Pi’s expected utility
becomes e1.

On the other hand, if e1 > e0 and Pi accepts the bribe, its expected payoﬀ

becomes at least

(C + pb − ps)ν ˜q + E[(C + pb + fi(X) − pw)ν|Xi = 1](1 − ˜q)

≥ (C − pw)ν + (1 − ˜q)(E[(C + pb + fi(X) − pw)ν|Xi = 1] − (C + pb − pw)ν)
≥ e1,

where the ﬁrst equality follows from the value of ˜q speciﬁed by the adversary,
and the last inequality follows from Lemma 2 of Theorem 4. Thus, if e1 ≥ e0,
then the expected payoﬀ of node Pi when it accepts the bribe is at least as
large as its expected payoﬀ when it rejects the bribe. Hence, for the nodes Pi,
i ∈ [N − f − k + 1], there does not exist any action that dominates (˜r∗
i ) =
(1, −). Then, the action proﬁle speciﬁed by the adversary constitutes a Nash
equilibrium, and in the equilibrium, qA

v becomes at least ˜q:

i , r∗

(C + pb − pw)ν − (C − pw)ν
(C + pb − pw)ν − (C + pb − ps)ν =

(pb + ps)ν − (ps)ν
(pb + ps)ν − (pb + pw)ν ,

where C = ps + pw.

32

Ertem Nusret Tas and Dan Boneh

Finally, if e1 < e0, then either the nodes Pi, i ∈ [N − f ], all reject the bribe,
and set r∗
i = 0, or they all accept the bribe. The ﬁrst case happens if for the
nodes Pi, i ∈ [N − f − k + 1], there does not exist any action that dominates
(˜r∗
i ) = (0, 0). Then, in the equilibrium, qA
i , r∗
v becomes 1. In the latter case,
qA
v ≥ ˜q as argued above, thus concluding the proof.

Lower and upper bounds on p0 for risk-averse nodes Let ˜p0 = p0/pw and ˜ps =
ps/pw ≈ 1416 for the given values of ps = 32 ETH and pw = 0.0226 ETH.
Using the formula of Theorem 11, we can bound the value of ˜p0 as a function of
N , ν and (cid:15): ˜p0,min ≤ ˜p0 ≤ ˜p0,max, where ˜p0,max and ˜p0,min satisfy the following
expressions respectively:

(cid:15) =

(cid:15) =

=

min

(1416 + 3 ˜p0,max
(cid:18) ˜p0,min
3
N
1415
3
N

(1416 + 3 ˜p0,max

N )ν − (1416)ν
N )ν − (1 + 3 ˜p0,max

N )ν
(1416 + ˜p0,min)ν − (1416)ν
(1416 + ˜p0,min)ν − (1 + ˜p0,min)ν

,

(cid:19)

(1416 + ˜p0,min)ν − (1416)ν

(1416 + ˜p0,min)ν − (1 + ˜p0,min)ν for N < 300, 000

Solving for ˜p0,min and ˜p0,max at diﬀerent values of N , ν and (cid:15), we can calculate
the lower and upper bounds on p0 for diﬀerent N < 300, 000, utility functions of
the form U (x) = xν and (cid:15). These bounds are presented by Table 2 and Figure 1.
We observe that when p0ν/ps << 1, the upper and lower bounds diﬀer by at
most a constant factor for all values of ν.

D Proofs of Theorems 6, 7 and 8

Proof of Theorem 6. We ﬁrst show that for any (p0, p1)-adversary, q(p0, ν) ≤
q∗
p0,ν for the contract of Section 3. Consider a game played among the client and
the DAC nodes. At the beginning of slot 2, the client V either received k or more
valid clues over the network from the nodes, or it did not. Recall the deﬁnitions
of the events Q≥k, Q<k, R and P from the proof of Lemma 1. Recall Table 4
summarizing V’s payoﬀ under diﬀerent actions taken by V.

Since 4-security is violated only in the event R∧P , given the slashing function
of Section 3, q(p0, ν) = Pr[R ∧ P ]. If Pr[R ∧ P ] = 0 in all Nash equilibria, it
trivially holds that 0 = q(p0, ν) ≤ q∗
p0,ν. Thus, we next assume that there exists
a Nash equilibrium where Pr[R ∧ P ] > 0.

Given that the event R happens, i.e., k or more nodes send clues to V over
the network by slot 3, the adversary cannot distinguish between the actions
Q≥k ∧ Q<k and Q≥k ∧ Q<k, and between the actions Q≥k ∧ Q<k and Q≥k ∧ Q<k.
Moreover, the utility (pf − pc)ν of the events Q≥k ∧ Q<k and Q≥k ∧ Q<k exceeds
the maximum utility (pcomp − pc)ν of the events Q≥k ∧ Q<k and Q≥k ∧ Q<k
with the bribe. Thus, even if the adversary oﬀers an additional payoﬀ of p1 <
pcomp − pc for the actions Q≥k ∧ Q<k or Q≥k ∧ Q<k, if Pr[R ∧ P ] > 0, then V can

Cryptoeconomic Security for Data Availability Committees

33

increase its expected utility by reducing the probability of taking Q≥k ∧ Q<k in
favor of Q≥k ∧ Q<k, and reducing the probability of taking Q≥k ∧ Q<k in favor
of Q≥k ∧ Q<k. Hence, V never takes the actions Q≥k ∧ Q<k and Q≥k ∧ Q<k with
positive probability in any equilibrium where Pr[R ∧ P ] > 0. In other words, if
V does not receive k or more clues over the network by slot 3, it sends a query
to the contract by slot 2 in any equilibrium with a positive failure probability
for 4-security.

Suppose a query appears in the contract of Section 3 at some slot t. By the
optimality of the contract, for any given p0 and ν, no compliant contract with
a diﬀerent slashing function can ensure that there are less than k valid clues in
the contract at slot t + 1 with probability less than q∗
p0,ν in the equilibrium with
the maximum failure probability.

Finally, if the event R happens, i.e., the nodes send k or more clues over the
network by slot 3, then 4-security is satisﬁed with probability 1. If R does not
happen, then the client sends a query to the contract by slot 2, in which case
there are k or more clues in the contract by slot 4 except with probability q∗
p0,ν in
the equilibrium with the maximum failure probability. Consequently, 4-security
is violated with probability at most q∗
p0,ν for the
contract of Section 3.

p0,ν, implying that q(p0, ν) ≤ q∗

For the achievability claim, consider a compliant contract and the adversary
A from Theorem 4. Suppose there exists a subgame perfect equilibrium, where
none of the nodes sends a valid clue over the network by slot 3, and V takes
the action Sq, i.e., sends its query to the contract, by slot 2. Once the query
appears in the contract, the nodes follow the actions speciﬁed by A in the proof
of Theorem 4.

Observe that if there is a query in the contract, none of the nodes can increase
its expected utility by deviating from the action speciﬁed by the adversary A
given the other nodes’ actions. Similarly, V cannot increase its expected utility
by taking the action ¬Sq when none of the nodes sends a valid clue over the
network by slot 3. Finally, none of the nodes can increase its expected utility
by sending a valid clue to V over the network by slot 2, since this does not
aﬀect V’s behavior. This is because k > 1 and all other nodes withhold their
clues. Hence, the claimed action proﬁle indeed constitutes a subgame perfect
equilibrium. However, in this case, the p0-adversary A ensures that less than
k valid clues are sent to the contract by slot 4 with probability at least q∗
p0,ν
for any compliant contract. Consequently, there exists a (p0, 0)-adversary and
a subgame perfect equilibrium such that 4-security is violated with probability
q∗
p0,ν.

Proof of Theorem 7. We ﬁrst augment the adversary A from Theorem 4 to also
oﬀer a bribe of p1 to the client V such that p1 ≤ pcomp − pc and p1 satisﬁes
formula (1). In return, A asks V to take the action Sq, i.e. to send its query
to the contract, by slot 2 in addition to the actions speciﬁed for the nodes. We
show that the action proﬁle, where V and the nodes accept their bribes, and
none of the nodes sends valid clues over the network to V by slot 3, constitutes a

34

Ertem Nusret Tas and Dan Boneh

subgame perfect equilibrium, where security is violated with probability at least
q∗
p0,ν.

Suppose a query appears in the contract at some slot t. By the optimality
of the slashing function of Section 3, for any given p0 and ν, no contract with
a diﬀerent slashing function can ensure that there are less than k valid clues in
the contract at slot t + 1 with probability less than q∗
p0,ν in the Nash equilibrium
with the maximum failure probability.

Suppose V receives no valid clues over the network by slot 3. Then, if V
does not take the action Sq by slot 2, V’s expected utility becomes at most 0.
Conversely, if V takes the action Sq by slot 2, it obtains a utility of at least
(pcomp − pc + p1)ν. Hence, if none of the nodes sends a valid clue to V by slot 3,
since (pcomp − pc + p1)ν > 0, V chooses to take the action Sq by slot 2.

On the other hand, consider an action proﬁle where one or more of the nodes
sends a valid clue to V over the network by slot 2. In this case, if V accepts
the bribe and takes the action Sq by slot 2, its utility becomes (pf − pc + p1)ν
p0,ν and (pf − pc + p1 + pcomp)ν with probability
with probability at most 1 − q∗
p0,ν. Thus, its expected utility becomes at least (1 − q∗
at least q∗
p0,ν)(pf − pc +
p0,ν(pf − pc + p1 + pcomp)ν. However, if V rejects the bribe, its expected
p1)ν + q∗
p0,ν)(pf − pc + p1)ν +
payoﬀ can at most be (pf )ν. Since this is less than (1 − q∗
q∗
p0,ν(pf − pc + p1 + pcomp)ν by formula (1), V cannot increase its expected utility
by rejecting the bribe even if one or more of the nodes sends a valid clue over
the network by slot 2. Hence, regardless of whether the nodes send valid clues to
V by slot 2 or not, V sends a query to the contract by slot 2, implying that the
nodes cannot increase their expected utility by deviating from the action proﬁle
claimed to be a subgame perfect equilibrium.

Finally, the action proﬁle, where V accepts the bribe and sends a query to the
contract by slot 2, and the nodes do not send valid clues over the network by slot
3, indeed constitutes a subgame perfect equilibrium. However, in this case, the
p0-adversary A ensures that less than k valid clues are sent to the contract by
slot 4 with probability at least q∗
p0,ν for any compliant contract. Hence, 4-security
is violated with probability at least q∗

p0,ν.

Proof of Theorem 8. For the sake of contradiction, suppose there exists a (p0, p1)-
adversary and a subgame perfect equilibrium, where all of the nodes withhold
their clues from the client V with some positive probability. By the proof of
Theorem 6, if V receives no valid clues over the network by slot 2, it takes the
action Sq, i.e. sends query to the contract, by slot 2. Since p0 < (N −f )pw, given
any distribution of bribes to the nodes, there exists a non-adversarial node P,
which receives a bribe less than pw. Thus, in the subgame, where V takes the
action Sq by slot 2, the maximum expected utility of P becomes less than (C)ν
if it takes the action Sp at slot 3, i.e., sends its clue to the contract, as its bribe
cannot compensate for the cost pw of sending a clue to the contract. Similarly,
P’s expected utility becomes less than (C)ν if it does not take the action Sp as
its bribe cannot compensate for the minimum punishment pw + (cid:15) of not sending
a clue to the contract. Thus, in this subgame perfect equilibrium, P’s expected
utility is less than (C)ν.

Cryptoeconomic Security for Data Availability Committees

35

Given the action proﬁle, where one of the nodes sends a valid clue to V over
the network by slot 2, thus enabling V to recover the response to its query, if V
takes the action Sq, its utility becomes (pf − pc + p1)ν with probability at least
1 − q∗
p0,ν. In this case,
V’s expected utility is upper bounded by (1 − q∗
p0,ν(pf −
pc +p1 +pcomp)ν. Conversely, if V does not take the action Sq, its payoﬀ becomes
(pf )ν. As

p0,ν and (pf − pc + p1 + pcomp)ν with probability at most q∗

p0,ν)(pf − pc + p1)ν + q∗

(1 − q∗

p0,ν)(pf − pc + p1)ν + q∗

p0,ν(pf − pc + p1 + pcomp)ν < (pf )ν,

if at least one node sends a valid clue to V by slot 2, V does not take the action
Sq at any slot.

Finally, if P deviates from the claimed equilibrium and sends a valid clue to
V over the network by slot 2, V does not take the action Sq before the game ends.
In this case, P obtains a payoﬀ of at least (C)ν. However, this is larger than
P’s claimed equilibrium payoﬀ, implying a contradiction. Thus, in all subgame
perfect equilibria, there is at least one node that sends a valid clue to V by
slot 2 over the network, in which case V does not take the action Sq before the
game ends. Consequently, all subgame perfect equilibria of this game satisﬁes
4-security without the use of the contract.

