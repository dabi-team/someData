2
2
0
2

y
a
M
7
1

]
T
E
.
s
c
[

1
v
2
1
5
8
0
.
5
0
2
2
:
v
i
X
r
a

Experimental evaluation of digitally-veriﬁable photonic computing for blockchain and
cryptocurrency

Sunil Pai,1,

∗ Taewon Park,1 Marshall Ball,2 Bogdan Penkovsky,3 Maziyar Milanizadeh,4 Michael Dubrovsky,3

Nathnael Abebe,1 Francesco Morichetti,4 Andrea Melloni,4 Shanhui Fan,1 Olav Solgaard,1 and David A.B. Miller1
1Department of Electrical Engineering, Stanford University, Stanford, CA 94305, USA
2Courant Institute, New York University, NY, USA
3PoWx, Cambridge, MA, USA
4Politecnico di Milano, Milan, Italy

As blockchain technology and cryptocurrency become increasingly mainstream, ever-increasing
energy costs required to maintain the computational power running these decentralized platforms
create a market for more energy-eﬃcient hardware. Photonic cryptographic hash functions, which
use photonic integrated circuits to accelerate computation, promise energy eﬃciency for verifying
transactions and mining in a cryptonetwork. Like many analog computing approaches, however,
current proposals for photonic cryptographic hash functions that promise similar security guarantees
as Bitcoin are susceptible to systematic error, so multiple devices may not reach a consensus on
computation despite high numerical precision (associated with low photodetector noise).
In this
paper, we theoretically and experimentally demonstrate that a more general family of robust discrete
analog cryptographic hash functions, which we introduce as LightHash, leverages integer matrix-
vector operations on photonic mesh networks of interferometers. The diﬃculty of LightHash can be
adjusted to be suﬃciently tolerant to systematic error (calibration error, loss error, coupling error,
and phase error) and preserve inherent security guarantees present in the Bitcoin protocol. Finally,
going beyond our proof-of-concept, we deﬁne a “photonic advantage” criterion and justify how recent
developments in CMOS optoelectronics (including analog-digital conversion) provably achieve such
advantage for robust and digitally-veriﬁable photonic computing and ultimately generate a new
market for decentralized photonic technology.

Photonic integrated circuits consisting of networks or
“meshes” of Mach-Zehnder interferometers (MZIs) [1, 2]
are typically proposed as time- and energy-eﬃcient ma-
trix multiplication accelerators for analog domain ap-
plications such as quantum computing [3, 4], sensing,
telecommunications [5] and machine learning [6]. Since
photonic meshes can be designed and mass-produced us-
ing well-established silicon foundry processes, there has
recently been increased eﬀort to commercialize the tech-
nology for analog domains that do not necessarily require
high accuracy for high performance (e.g. machine learn-
ing).
In this work, we extend applications of photonic
meshes from the continuous analog domains of sensing
and quantum computing to discrete and digital domains
of cryptography and blockchain technology. The problem
we want to solve is to design photonic matrix multiplica-
tion hardware successfully under more stringent numer-
ical accuracy requirements that require nearly “perfect”
digital computation. Essentially, we are exploring the use
of such meshes as digital rather than analog multipliers.
explore “photonic
blockchain” technology which implements “optical proof
of work” (oPoW) [7], proof that this discrete matrix mul-
tiply computational work has been performed in the op-
tical domain. Equipped by optical computation with
suﬃcient accuracy, such protocols can leverage energy
eﬃcient computation and state-of-the-art photonic hard-
ware (such as photonic meshes) to verify cryptocurrency

core application, we

As our

∗ sunilpai@stanford.edu

transactions and ultimately other wide ranging applica-
tions of blockchain such as medical data, smart contracts,
voting, logistics and tracking, spam ﬁlters and protection
from distributed denial-of-service (DDoS) attacks.
In
situations where energy cost is a bottleneck, blockchain
technologies that use optical proof of work inherently in-
centivize using photonic hardware over other alternatives
to gain competitive advantages in compute eﬃciency and
further security against malicious actors such as malware
or attack vectors. For example, at the time of writing,
cryptocurrency mining accounts for as much energy as
all data centers globally and this energy consumption
will increase, by design, as more value is stored in de-
centralized PoW blockchains. Energy cost concerns have
contributed to recent crashes in the cryptocurrency mar-
ketplace, including over the span of two weeks in May
2021 and again in Jan 2022 that reduced market capital-
ization of popular cryptocurrencies by the equivalent of
more than 1 trillion dollars. Photonic blockchain could
thus serve as a timely application for a proof-of-work
based cryptocurrency that incentivizes energy-eﬃcient
photonic hardware, which can furthermore prove to be
an appealing option for other blockchain-based applica-
tions.

While the primary emphasis in this paper is on the
photonic implementation and performance of optical
proof of work, we must ﬁrst clarify the energy-eﬃciency
problem in blockchain and cryptocurrency. Cryptocur-
rency is a decentralized currency market where transac-
tions (e.g. “Alice gives Bob 1 bitcoin”) are stored in a
chain of blocks (“blockchain”). To earn a share of the

 
 
 
 
 
 
market, a cryptocurrency miner can “mine” (add a new
block of transactions) to the blockchain using computa-
tional “proof of work” (PoW) where the computer can
solve a puzzle for a payout reward. This puzzle consists
of generating a 256-element bitvector (vector of 1’s and
0’s) by feeding digital block transaction data through a
cryptographic hash function H, such as SHA-256 (a map
which converts any digitally encoded data into 256-bit
numbers and which is infeasible to invert), which is the
“computational work.” 1 This function is called twice
(once on the original block data and again on the result
of the ﬁrst call) through a scheme called “HashCash”
while adjusting a nonce (32-bit pseudorandom number)
in the block until the ﬁrst B bits in the bitvector are 0,
which proves that suﬃcient computational work has been
done and adds the block to the blockchain. The param-
eter B is a tunable diﬃculty parameter that is increased
as the coin (which in many cases has limited supply) is
more scarce and the expected number of cycles before
the puzzle is solved is 2B. Crucially, as it relates to this
paper, cryptocurrency mining comes at an energy cost
proportional to the number of hash function solves be-
fore a block is mined and transactions in the block are
considered veriﬁed.

In optical PoW, the miner is incentivized to reduce
mining costs by choosing optical (photonic) hardware
that improves the energy eﬃciency and speed of com-
putation compared to digital alternatives. However, the
great challenge of such computing is that any error in
the bits output by the analog hardware renders an entire
hash veriﬁcation invalid; this necessitates some strict de-
sign criteria and possibly some error correction coding
which we explore in this paper. We address this accu-
racy problem by numerically and experimentally evalu-
ating a new photonic hash function called “LightHash,”
a modiﬁed hash function from Bitcoin’s Hashcash that
combines the energy-eﬃciency of linear optics with the
security assurances of the Bitcoin protocol. We deﬁne
feasible design criteria (e.g., number of photonic inputs
and outputs) and propose a hardware agnostic error cor-
rection scheme that enables our photonic hash function
to outperform any digital alternative.

PHOTONIC BLOCKCHAIN

Photonic blockchain can be deﬁned as a modiﬁcation
of the Bitcoin protocol hash functions using what we re-
fer to as a “photonic hash function,” which is a type of
optical cryptography.
In optical cryptography, a cryp-
tographer encrypts or decrypts a message by sending the
message bits through a hash function, where at least one

1 Such hash functions, “one-way” (non-invertible) functions for
private-key cryptography, are more generally used to securely
encrypt and decrypt data for various secure applications beyond
blockchain.

2

∈

part of the hash function requires an optical device. Here,
we explore photonic hash functions that incorporate a
“universal” photonic mesh [7] or N -port triangular or
rectangular MZI networks [1, 8, 9]. Meshes operate by
repeatedly interfering spatially multiplexed mode vectors
of coherent light (over the N ports), where modes are rep-
resented as complex numbers with amplitude and phase.
The constructive and destructive interference can be pro-
grammed using electrically-controlled phase shifts to im-
plement any unitary transmission matrix U
U(N ) (sat-
isfying the energy conserving property U †U = I) [1, 8].
After adding a column of “singular value” MZIs followed
by a second universal network as in Ref.
[1], it is pos-
sible to compute an arbitrary linear operator based on
the singular value decomposition (SVD) of any matrix
Q [1]. The resulting photonic processors can be pro-
grammed to implement arbitrary energy-eﬃcient linear
operations; though energy must be spent in generating,
modulating, and detecting the optical signals, the actual
matrix-vector product is performed by passive linear op-
tical transformations without additional power. The rest
of the computation in photonic hash functions include
logical operations on bits that are best implemented in
the digital domain (e.g. SHA-256 is eﬃciently imple-
mented on digital processors) and ultimately provide the
necessary provably secure protection. By co-integrating
this digital functionality with photonic meshes in a sys-
tematic manner, we leverage the unique beneﬁts of optics
(linear computation) and electronics (nonlinear compu-
tation and logic) for a fully integrated photonic crypto-
graphic solution. While previous proposals of this scheme
exist (e.g. HeavyHash [7]), a protocol that is suﬃciently
error tolerant and is both time-and energy-eﬃcient (in-
cluding the analog-digital conversion) is yet to be pro-
posed. Similar challenges are faced in photonic circuits
for digital optical telecommunications, and indeed, the
mathematics of “bit error rates” also can be applied to
the problem of optical cryptography. Ultimately, the core
challenge is to ﬁnd a protocol that successfully brings
photonic computing, a technology typically used for ana-
log computing, into the digital realm with near perfect
accuracy.

To this end, we examine whether meshes can ac-
curately implement matrix multiplication compared to
an electronic digital implementation so they could ulti-
mately be used for PoW cryptography and confer a “pho-
tonic advantage.” The “photonic advantage” for our par-
ticular scheme follows from the conjecture that, within
the LightHash evaluation, photonic hardware performs
amortized matrix multiplication by a random block-
diagonal Q operator at least an order of magnitude
more eﬃciently than traditional hardware, where element
within the blocks of Q is sampled from uniform distribu-
tions over a set of K integers. First, through numerical
simulation, we show that programming a block integer
matrix Q onto a series of SVD-based photonic architec-
tures [1] (as opposed to purely unitary circuits [8]) and
adjusting the numerical precision through diﬀerent inte-

×

ger K values can minimize the systematic error in the
analog computation to make it more amenable to op-
tical cryptography. Then, we experimentally evaluate
the cryptographic protocol on a physical photonic chip
accelerator capable of performing 4
4 unitary matrix-
vector products to estimate performance on our new pro-
posed LightHash protocol. Since the LightHash matrix-
vector operation is performed in discrete space, we can
ﬁnd conditions such that possible outputs are separated
suﬃciently far enough to guarantee near-perfect accu-
racy. The increased energy-eﬃciency-per-compute of a
photonic platform would not only help to increase the
security of cryptocurrencies and blockchain operations
generally but also would result in a signiﬁcant shift from
energy cost (operating expense) to resource cost (cap-
ital expense) in cryptocurrency mining [7]. The result-
ing increased demand for photonic chips could incentivize
photonic integrated circuit (PIC) development and man-
ufacturing by adding new applications.

ALGORITHM

As shown in Fig. 1, our photonic cryptocurrency pro-
tocol incorporates a photonic processor unit (photonic
mesh) within Bitcoin’s proof-of-work hash computation
to implement LightHash.

Our LightHash photonic cryptographic protocol trans-
forms block (transaction) data into a 256-bit “possible
solution” to a cryptographic puzzle, and includes a pho-
tonic integrated chip computation within the protocol.
The protocol begins with the well-known SHA3-256 pro-
tocol, which is part of the already-prevalent digital cryp-
tocurrency Bitcoin and converts block data (containing
transactions in the marketplace) into a 256-bit vector
containing a sequence of 256 0’s and 1’s. This bit data is
directly fed to optical modulators that control the optical
input into the photonic accelerator chip in chunks of N
bits, which has the following behavior:

1. Input: the input into the photonic network is a
phase-shift keyed bitstream bin which is represented
as inputs of equal magnitude set to either xn =
so,
depending on a bit value bn =
1,
{
a vector of inputs x = eiπbin /√N ; this can be set
by sending digital signals to well-calibrated optical
modulators.

0, 1
{

1
}

−

}

2. Device operator: As shown in Fig. 1(a, c), the
device operator for each block Qm = U ΣV † with
circuit size N consists of two unitary operators U, V
of size N , implemented using triangular or rectan-
gular networks [8, 9] and a set of N singular val-
ues Σ, implemented using MZI node attenuators
(with “drop ports”) [1]. The elements Qm,ij are
randomly sampled to be one of K distinct inte-
gers centered symmetrically around 0 and spaced 2
apart. At block creation only, a digital computer is

3

used to ﬁnd the static phase shifts for meshes im-
plementing U, V, Σ to ultimately program Q onto
the chip.

|

| · |

2, where

3. Output: The output of the device is the complex
output vector y = Qx with output power p =
2 is an elementwise absolute value-
y
|
squared operation. A photodetector equipped with
a transimpedance element (load resistor or am-
pliﬁer) converts power to voltage, which is then
fed through output comparators corresponding to
threshold power pth = y2
th to determine output bits
b := H(p
pth) (where H is the Heaviside step
function). At block creation, selection of pth via
simulation guarantees roughly equal probability of
a 0 or 1 output bit.

−

Note that the deﬁnition of the threshold amplitude
should be consistent with the scaling of the blocks
yth|
|
in matrix Q. Since the maximum singular value of Q is
set to 1 in the physical implementation (no optical gain
elements are used in our photonic mesh), the threshold
amplitude is also scaled by this factor as discussed in
more detail in the Appendix.

3,

−

−

A unique feature of LightHash is the numerical resolu-
tion K, which can be used to change the range of possible
output values. For instance, K = 2 means the matrix el-
1, and K = 4 means the
ements can be either 1 or
options for each matrix element are (
1, 1, 3). Each
row vector-vector product in the overall matrix vector
product can actually be thought of as a random walk
with K deﬁning possible step sizes (1 for K = 2 and
(1, 3) for K = 4). Since the inputs are either
1 or 1,
an increase in K means an increase in range of possi-
ble output values and eﬀectively the number of bits or
quantized levels present in the output. Due to a larger
required number of output bits, the use of higher K, as
with higher N , leads to higher computational eﬃciency
but a more error-prone photonic chip.

−

−

Note that the device is set to implement Q only once
per block added to the blockchain, which means that the
photonic miner has some time to self-conﬁgure itself to
implement Q, and block times can generally be several
minutes at suﬃciently high diﬃculty.
If N < 256, we
repeat 256/N times (assuming N divides 256) to out-
put a total of 256 bits that is “exclusive or’d” (XOR’d)
with the original input vector and fed into the second
SHA3-256 function as in Fig. 1(a). Additional context
for the design choices here is provided in the Appendix;
the gist is that our formulation makes optical proof of
work feasible in the presence of error.

Aside from random laser and photodetector noise,
there are three types of non-random errors that are more
challenging to address and on which we focus on in this
paper: phase error, coupling error, and loss error. These
sources of error can be compensated in various ways using
phase shifter calibration in a photonic mesh; for exam-
ple, self-conﬁguration [1, 10] or oﬀ-chip calculation [11]
can to some extent compensate for these errors. (Note

4

FIG. 1. (a) The LightHash optical proof of work protocol, similar to HeavyHash [7], is a slight modiﬁcation of the Bitcoin
protocol, where an arbitrary photonic mesh-based matrix-vector product is inserted in the middle. Transactions are veriﬁed
by photonic miners as in the Bitcoin network, with photonic chips being the ideal technology to achieve a block reward.
Output bits are measured using femtojoule comparators ideally running at GHz speeds. (b) The experimental setup used to
evaluate the LightHash protocol (N = 4, variable K) involves running U, V on-chip, responsible for most of the error, and
multiplying singular values oﬀ-chip. (c) The photonic proof of work error analysis model shows how systematic error in the
device mathematically propagates all the way to an overall hash error rate which arises due to overlap between successive values
near the threshold shown in the inset. Reducing the hash error rate is the main aim of this work and is necessary to implement
LightHash in practice.

that while phase and coupling error can be mostly com-
pensated using error correction or self-conﬁguration, er-
ror due to unequal losses cannot be compensated in this
way.) As discussed in the Appendix, calibration and error
correction generally occurs at the level of individual “unit
cell” nodes or Mach-Zehnder interferometers (MZIs) that
can be more straightforwardly characterized.

To correct this error, we use a simple form of
“hardware-agnostic error correction” in which the com-
putation is repeated up to R times across R circuit copies.
If the expected error is σout, this can reduce the error
to σout/√R, a factor of √R improvement. This repeti-
tion may be implemented using R separate devices im-
plemented on the same chip. To save on energy consump-
tion, we can use the same number of modulators and split
the input signal x across R diﬀerent meshes implement-
ing the same Q but diﬀerent error, in a process called
“hardware agnostic error correction” as each mesh sam-
ples a presumably random systematic error. One poten-
tial drawback of this approach is that the systematic error
may be correlated across the R meshes, so one way to en-

sure uncorrelated error is to permute the singular values
(and appropriate basis vectors of U, V †). The number
of comparators might also stay the same assuming the
photocurrents from corresponding photodetectors at the
R device operator outputs can be grouped into a single
current, and then passed through a transimpedance am-
pliﬁer and comparator.

The challenge of photonic cryptography that we ad-
dress is to ensure accuracy across all 256 bits (hash or
packet error rate, PER) while also aﬀording a signiﬁcant
advantage over equivalent digital hardware in speed and
energy eﬃciency (otherwise there would be less demand
for photonic hardware). For simplicity, we may consider
all bits to have independent bit error rates (BER) εb so
the hash error rate is given by ε = 1
256εb.
To put this in practical terms, for any given device to
have 1% PER, each of the individual bits should have
roughly 0.004% BER. This increases the importance of
error correction in photonic integrated circuits, which is
especially challenging in the presence of unbalanced pho-
tonic loss. This requires exploring the tradeoﬀs of in-

ε)256

(1

−

−

≈

Photonic minersExchangeNonceHeaderBlock...Blockchain ledgerTXOptical proof of workSHA3-256DigitalfJ modulatorsEqualsplitterSample/hold123N...123N...Q256 bitsfJ comparatorsLaserXORHashcashPPUNew nonceFirst B bits all 0?YesBlock rewardNo256 bitsSHA3-256†ΣUVGeneratorAnalyzerMatrix unitEqual split, PSKMeasure sign/phaseU, VDAC, PCB1101000110011101Bit vectors†Experimental proof-of-concept0101BitcoinElectronicsIR Camera1550 nmUV†ΣσdBσBSσθ,φσoutyloss errorcoupling errorphase erroroutput error(c)bit error ratehash error ratecomparatorbaggregate256 output bitserfcx256(cid:31)εb(cid:30)(cid:31)ε(cid:30)Photonic proof of work flow and error modelaggregatedistributexSVD photonic architectureMZIθϕpnVrefbn−+VnRVb,nbias(repeat)yth−1ythyth+1Threshold-subtractedoutputs(|y|−yth)0.00.51.0σout=0.5(cid:31)(cid:24)b(cid:30)(σout)MeasurementacrossdevicesE(-1, 1)(-3, -1, 1, 3)K = 4K = 2(integer elements)SVDcreasing circuit size N and diﬃculty K (which increase
the diﬃculty) over the error. Pseudocode for the entire
optical proof of work based on LightHash is provided in
the Appendix.

SCALING SIMULATIONS

First, we numerically evaluate increasing circuit sizes

N = 8 to 64 for K = 2, 4, 8.

Ideally, the outputs y follow a roughly discretized
Gaussian distribution as might be expected by a ran-
dom walk based on our deﬁnitions of Q and x (The ma-
trix vector multiplication implements exactly a random
walk of N time steps for K = 2.). The ﬁeld magnitudes
are more readily measured by output photodetectors
y
|
and as expected form a discrete half-normal distribution
as shown in Fig. 2(a), with a notable dip in histogram
values for outcomes equal to zero.

|

|

y
|

The simulation outputs are measured over a large
range of possible Q, x, and we assume that this is equiv-
alent to simulating many devices implementing the same
operator over many inputs. The resulting histogram of
outputs
form error distributions with roughly similar
standard deviations σout. Evaluated over MZIs across
the photonic mesh, the loss standard deviation error σdB
is in dB, the phase standard deviation error σθ,φ is in ra-
dians, and the coupling standard deviation error σBS is
also in radians scaled by 50/50 coupler beat length. Fur-
ther details on these error source models are discussed in
the Appendix.

These diﬀerent types of errors all increase linearly with
K and N and thus add in quadrature to approximately
give the overall error:

σ2
out ≈

N 2K 2(kθ,φσ2

θ,φ + kBSσ2

BS + kdBσ2

dB),

(1)

which we generally observe in Fig. 2(a) assuming a min-
imal thermal or shot noise contribution. (This minimal
noise contribution is a valid assumption for our photonic
mesh as shown in the Appendix and in general, can be
compensated by integrating longer or changing photode-
tector circuitry.) As is evident in Fig. 2(a), error dis-
tributions are roughly Gaussian, though our simulations
suggest that the coupling error σBS results in a long “tail”
compared to the loss and phase error types which are
more Gaussian. One possible reason for this may have
to do with the nonlinear transformation of phase errors
equivalent to these coupling errors [11, 12].

As previously shown in Fig.

1(c), bit errors arise
when there is “bit threshold overlap” in the (approx-
imately) Gaussian error distributions between succes-
sive values around the threshold, given by
(σout) =
1), where erfc denotes the error func-
0.5erfc((σout√2)−
tion. To ﬁnd the corresponding expected bit error, we
multiply the overlap in error by twice the probability
ρ(N, K) (the densities in the histogram of Fig. 2(a))
that the values belong to the Gaussian spikes immedi-
is
ately before or after the threshold yth. Assuming

E

εb(cid:105)

(cid:104)

small, we get the expression for expected hash error

ε

(cid:104)

(cid:105) ≈

256ρ(N, K)

E

(σout).

5

:

ε
(cid:104)
(cid:105)
(2)

0.25.

The analysis of scaling of the bit error rate is shown in
Fig. 2(b, c) to indicate relatively small contribution of
the prefactor for output errors except in the transition
region between high and low error around σout ≈
The main ﬁnding from our simulations in Fig. 2(d)
is that high-ﬁdelity (feasible) operation for appreciably
large N generally requires error standard deviation much
less than 0.01 radians (coupling, phase) or 0.03 dB (loss)
which can be considered to be empirical error bound
requirements. Such a design at the component level is
challenging and depends heavily on the implementation
(calibration) and fabrication of the device. While cali-
bration and self-conﬁguration may sidestep such issues
in suﬃciently small circuits [1, 5], such stringent require-
ments are worth noting when designing devices for cryp-
tographic applications.

EXPERIMENTAL EVALUATION

×

Now that we have deﬁned our protocol and simulated
the scalability of the technique, we experimentally quan-
tify errors in a 4
4 port MZI mesh network (i.e., N = 4)
as a function of numerical resolution K using our cus-
tom designed chip and the experimental setup in Fig.
1(b). To estimate these errors, we record a distribution of
output magnitudes at the network output given random
x, Q. Using this, we assume we can achieve an experi-
mental estimate of σout measured across many devices.
As expected and shown in Fig. 3(a, b), the distribu-
tion follows a discretized half-normal distribution with
Gaussian-distributed spikes at each of the possible out-
puts.

Next, as shown in Fig. 3(c, d, e), we perform an er-
ror correction analysis by singular value permutation as
previously proposed. The singular value decomposition
is invariant given any permutation identically applied to
the rows of V †, the columns of U , and the singular val-
ues of Σ, i.e., Q = U ΣV † = (U P )(P Σ)(P V †), where P
is a matrix that implements the permutation. There-
fore, error correction is possible by applying diﬀerent
P to the R meshes implementing Q. The proof of in-
N
k=1 UikΣkkV †kj and k can be
variance is that Qij =
relabelled in any order, resulting in the same Q by re-
ﬂective property of addition.
In our case, we average
the result over four cyclic permutations of the singular
values, i.e. (1, 2, 3, 4), (4, 1, 2, 3), (3, 4, 1, 2), (2, 3, 4, 1). As
expected, we ﬁnd that the error gets roughly cut in half
when R = 4 (the slope m is reduced by about 41%). This
suggests that averaging results over devices implementing
Q with permuted singular values can signiﬁcantly reduce
the error at the expense of increased device footprint.

(cid:80)

Finally in Fig. 3(f), we consider the “error disper-
sion” relation ε(λ), exploring the eﬀect of wavelength on
the error to explore the possibility of parallelizing the

6

FIG. 2. (a) Example output histogram for N = 16 and K = 8 exceeds the capabilities of our device (N = 4) shown for
both ideal and experimental implementations. Overall coupling error, loss error and phase error contributions for various
component-wise σ < 0.01 all are roughly Gaussian with coupling errors skewed slightly to the right. (b) Error scaling ρ(N, K)
can be empirically determined found via simulation to determine the error at threshold pth. (c) The error prefactor ρ has a
small eﬀect on the bit error scaling; regardless of the scaling of ρ, we ﬁnd that σout = 0.25 is suﬃcient to ensure suﬃciently
low bit error (< 1%) throughout the entire range of ρ in (b). (d) Bit threshold error proﬁle shows sharp transition in overall
hash error as a function of circuit size N and/or loss, phase, and coupling errors that increases with K = 2, 4, 8 (1 to 3 bits),
establishing performance bounds for each error type.

computation over multiple wavelengths in a 20 nm wide
band at our empirically determined optimal wavelength
λc = 1560 nm:

achieve such a success level. In this paper, we have taken
a two-tier approach to improve on past proposals and
ultimately address these challenges.

ε(λ)

ε
≈ (cid:104)

[1 + Dε(∆λ)2],
(cid:105)

(3)

−

where ∆λ = λ
λc and Dε is the “relative” error disper-
sion (that depends on N, K) evaluated at λc. Our results
in Fig. 3(f) indicate that this relative dispersion coeﬃ-
cient as deﬁned in Eq. 3 actually decreases slightly with
K. Note that there is an increase in absolute dispersion,
but a decrease in the relative error dispersion.

DISCUSSION AND OUTLOOK

First, we propose the LightHash protocol which allows
us to modulate the “diﬃculty” of a problem by changing
the number of possible values (numerical resolution) K.
For larger values of N and K, we ﬁnd that the likelihood
of error is dramatically increased and generally ﬁnd an
N Kσ,
approximate scaling for the output error σout ∝
when σ is a component-wise phase or coupling error (in
radians) or component-wise loss error (in dB) localized to
the phase shifters. This is an important design criterion
that establishes fundamental limits on how high N and
K can go before there is too much hash error
for a
blockchain or cryptocurrency scheme to be “feasible.”

ε
(cid:104)

(cid:105)

Our results suggest that a digitally veriﬁable photonic
mesh for proof-of-work applications such as cryptocur-
rency requires stringent design and fabrication require-
ments.
In particular, for a large ensemble of crypto-
graphic devices to agree on some computation, the sys-
tematic (biased) error rate has to be suﬃciently small
such that proof of work can be achieved with high prob-
ability. Our results indicate that past proposals of pho-
tonic cryptocurrency such as HeavyHash face hurdles to

Second, we propose a new method of “hardware agnos-
tic error correction,” which can help to reduce the error
in a manner orthogonal to current error correction pro-
tocols such as self-conﬁguration [1, 10], hardware-aware
error correction [11], and gradient-based approaches [13].
By “orthogonal,” we refer to the fact that error correc-
tion can be applied using any of the currently known
approaches to individual photonic meshes, and hardware
agnostic error correction can be used to further reduce
the error once those options are completely exhausted.

(a)(b)(c)(d)10.80.60.40.20.0Hashpacket errorrate/PER020406080Outputhistogram:(N,K)=(16,8)IdealErrorσout=0.25−101Loss(σdB)−0.50.00.5Coupling(σBS)−202Phase(σθ,φ)8163264NforK=2Loss(∝σdBN)Phase(∝σθ,φN)Coupling(∝σBSN)8163264NforK=40.0000.0150.030Losserror(σdB)8163264NforK=80.0000.0050.010Phaseerror(σθ,φ)0.0000.0050.010Couplingerror(σBS)Bitvspacket(256 bits) errorErrorprefactorρ(N,K)0.0020.0030.0040.0050.0060.008σ2468Numericalresolution(K)0.20.40.6ρ(N,K)N=16N=32N=640.000.250.500.751.00Outputerror(σout)10010−210−410−610−810−10Errorrate((cid:29)(cid:25)(cid:28))BER(cid:29)(cid:25)b(cid:28),ρ=1PER(cid:29)(cid:25)(cid:28),ρ=1BER(cid:29)(cid:25)b(cid:28),ρ=0.2PER(cid:29)(cid:25)(cid:28),ρ=0.27

FIG. 3. Outcome LightHash histograms for 250 random matrices Q given N = 4 for varying K for (a) baseline and (b) hardware-
agnostic error-corrected implementations. We label alternating colors green and black to clearly delineate the overlap regions
between successive values (spaced 2 apart) labelled by tick marks. The red and blue regions correspond to a bit assignment of
0 and 1 respectively by digital thresholding. (c) Comparison between the baseline and hardware agnostic error correction error
distributions (subtracting the ideal values from the outcome histograms in (a) and (b)). (d) The standard deviation of the error,
σout, is roughly proportional to K for both the baseline and corrected implementations, with the corrected implementation
having a much smaller slope m. (e) Sharp transition in feasibility is demonstrated for the baseline and error-corrected cases
as a function of K (similar behavior is expected for N ) (f) Dispersion of the error given calibration at the center wavelength
1560 nm shows parabolic increase in error around the center wavelength as expected, but the dispersion coeﬃcient interestingly
decreases with K.

ε
(cid:104)

εb(cid:105)
(cid:104)

Our results indicate that of the many routes achieve
a feasible blockchain technology for cryptocurrency min-
ing, suﬃcient reduction of systematic error σout will have
. For in-
the most eﬀect on reducing hash error rate
(cid:105)
stance, error correction resulting in a decrease of σout
from 0.5 to 0.25 (using R = 4, which roughly multiplies
device footprint by 4) can reduce
by four orders of
magnitude due to the exponentially-decaying tail of the
Gaussian and ultimately greater than 99% accuracy. In
comparison, the choice of threshold pth aﬀects only the
prefactor ρ(N, K) in the ranges N
[2, 9]
and therefore has signiﬁcantly less impact on the ex-
pected error
. This observation, in addition to Figs.
2(c) and 3(e), suggests that the barrier between feasibil-
ity and infeasibility is rather sharp and can be addressed
by error correction to reduce σout mostly in cases where
feasibility is marginal. This sharp boundary is explained
by the fact that there is a quadratic exponent in the erfc
function’s integrand, i.e., erfc(z)

[8, 64], K

ε
(cid:104)

dt.

∈

∈

t2

(cid:105)

Based on the results of this paper, there are several rea-
sons to prefer a photonic blockchain and optical proof of
work over a digital alternative to carry out the LightHash
proof of work scheme. First, photonic cryptocurrency
miners could scale to being more proﬁtable since the en-

∝

z e−
∞
(cid:82)

ergy eﬃciency and reduced latency lead to higher prof-
its. With increased adoption, “mining pools” that use
photonic hardware can lead to a frequent and consistent
stream of income for a photonic miner compared to a con-
ventional digital miner (Appendix). The reason for this
improved eﬃciency is that most of the energy used by
the LightHash protocol is nominally concentrated in out-
put comparators that require at least 40 fJ/bit [14, 15],
assuming the chip operates at GHz speeds. The total en-
ergy for N = 64 LightHash becomes roughly 10.5 pJ of
energy which is two orders of magnitude less energy than
the most energy eﬃcient digital hardware for matrix-
vector multiplication [16]. Further discussion is left to
the Appendix.

Second, photonic hardware used in hash protocols can
also be used for other applications, i.e., the hardware
is not necessarily an application speciﬁc device. Impor-
tantly, the very chip we use in this paper to explore cryp-
tographic hash functions can also be used to perform in-
ference tasks and backpropagation training in photonic
neural networks [17]. This would suggest that photonic
mining hardware has key advantages over pure digital
application-speciﬁc hardware that implements energy-
eﬃcient cryptography but serve no other purpose.

2CorrectedLightHash-4,Kdistributions345792BaselineLightHash-4,Kdistributions34579KK(a)(b)(d)(e)−202012345678Corrected error−2020.00.51.01.52.02.53.03.54.0Baseline errorK=2K=3K=4K=5K=7K=9K=2K=3K=4K=5K=7K=9(c)(f)K=2K=3K=4K=5K=7K=9Dispersion analysisσoutσoutσout155015601570Wavelength(λ,nm)0.00.51.01.5Outputerror(σout)246810Numericalresolution(K)0.03000.03250.03500.03750.04000.0425Dispersioncoeﬃcient(D(cid:31))0246810Numericalresolution(K)0.00.10.20.30.40.50.60.7Outputerror(σout)Hardware-agnosticerrorcorrection(R=4)Baselineﬁt(m=0.0681)BaselineerrorCorrectedﬁt(m=0.0402)Correctederror0246810Numericalresolution(K)10−1110−910−710−510−310−1101Hasherrorrate((cid:30)(cid:25)(cid:29)=128·E(σout))Overallhasherror(PER)correctionBaselineerrorCorrectederrorCONFLICTS OF INTEREST

METHODS

8

SP, MD, MB, and BP all own a nominal amount of op-
tical bitcoin (oBTC), a cryptocurrency launched in 2021
that uses the HeavyHash (not LightHash) protocol for
PoW and are involved with PoWx, a nonproﬁt organiza-
tion dedicated to energy-eﬃcient optical computing for
cryptography. MB and BP also own a nominal amount
of Kaspa. SP, MD, BP, MB, SF, OS, DM are coinven-
tors on a provisional patent application for LightHash,
Prov. Appl. No.: 63/323727. DM holds patents on the
SVD photonic mesh architecture. The authors declare
no other conﬂicts of interest.

CONTRIBUTIONS

SP taped out the photonic integrated circuit and ran
all experiments with input from TP, NA, MM, FM,
AM, OS, SF, DM. SP conceptualized and simulated the
LightHash protocol with input from BP, MD and MB.
TP designed the custom PCB with input from SP. SP
wrote the manuscript with input from all coauthors.

A. Chip design

×

×

We have designed a 6

6 photonic mesh chip fabricated
by Advanced Micro Foundries (AMF) in their silicon-on-
insulator platform capable of implementing 4
4 matrix-
vector multiplication. The phase shifters controlling the
generator and the mesh itself are all titanium nitride
(TiN) and are all calibrated to achieve up to 2π phase
shift as a polynomial function of the square-voltage ap-
plied across each of the phase shifters. The calibration
proceeds by sending light progressively to each MZI in
the device starting from the left-most to the right-most
MZI and sweeping phase shifts from 0 to 5 volts. More
details on this calibration are provided in the Supplemen-
tal Material. One feature of our mesh design is that there
are grating taps at each of the waveguide segments of the
3%) of
MZIs capable of outputting a small fraction (
the power in the guide. These are used to measure the
powers after each MZI to calibrate phase shifts and are
also used to measure the outputs of the device using an
IR camera.

∼

DATA AND SOFTWARE

B. Experimental setup

All software and data for running the simulations
and experiments are available through Zenodo [18] and
Github through the Phox framework, including our ex-
perimental code via Phox [19], simulation code via Sim-
phox [20], and automated photonic circuit design code
via Dphox [21].

ACKNOWLEDGEMENTS

We would like to acknowledge help from Advanced Mi-
croFoundries (AMF) in Singapore and for their help in
building the necessary circuitry for our demonstration.
We would also like to acknowledge funding from Air Force
Oﬃce of Scientiﬁc Research (AFOSR) through grants
FA9550-17-1-0002 in collaboration with UT Austin and
FA9550-18-1-0186 through which we share a close col-
laboration with UC Davis under Dr. Ben Yoo. Thanks
also to Payton Broaddus for helping with wafer dicing,
Nagaraja Pai for advice on electronics and thermal con-
trol packaging, and Carsten Langrock and Karel Urbanek
for their help in designing our movable optical bread-
board. Finally we would like to thank Dirk Englund,
Ryan Hamerly, and Saumil Bandyopadhyay for fruitful
discussions on error modelling as well as Mustafa Ham-
mood, Vsevolod Hulchuk, and Maxim Karpov for illumi-
nating feedback.

The photonic mesh chip is wirebonded by Silitronics
Solutions to our custom-built PCB designed to inter-
face with an NI PCIe-6739 controller for setting pro-
grammable phase shifts throughout the device. The in-
put optical source is a Agilent 81606A tunable laser with
a tunable range of 1460 nm to 1580 nm. To measure
powers coming out of grating taps, we use an infrared
(IR) Xenics Bobcat 640 series camera set to “raw” mode
connected to an IR/visible microscope with an inﬁnity
corrected Mitutuyo 10X IR objective lens attached to a
40 cm tube lens. This optical setup is ﬁxed to a movable
Applied Scientiﬁc Imaging (ASI) stage to image optical
powers emitted from the grating taps.

Automation of the LightHash algorithm is accom-
plished via USB/GPIB connections to the tunable laser,
MXIe-PCIe slot connection to the NI control board, and
ethernet connection to the camera for measurements and
calibration. A graphical user interface is designed using
Holoviews/Bokeh to debug the device and analyze the
calibration. The chip consists of 6
6 photonic meshes
with grating inputs and ﬁber array optical interconnects
(constructed by W2 Optronics) shown in the image of
Fig. 1(b). These are wirebonded to a custom PCB or-
dered via Advanced Circuits which also features a ther-
mistor and thermal connection to a thermoelectric cooler
on an aluminum mount for eﬃcient thermal stabilization
based on a feedback loop.

×

C. Calibration and operation

With the above errors, the transmission matrix T2 from

9

In order to operate the mesh as a 4

4 matrix-vector
multiplier, we couple the tunable coherent laser to the
top input of the device via the ﬁber array interconnect
and use the ﬁrst diagonal “row” of MZIs to function as an
optical setup machine or generator [22, 23]. Full details
and associated ﬁgures for our calibration follow the same
procedure as in [17], but we provide a summary here.

×

We take an initial reference image to get a background
and then to measure the spots intensities or powers, we
sum up the reference-subtracted pixel values that “ﬁll”
the appropriate grating taps throughout the device. We
ensure that saturation does not take place by reducing
the laser power to approximately 50 µW at 20 ms inte-
gration time, which suggests nW camera pixel sensitivity
as expected. The output powers are all normalized based
on the total power in the system (sum of all grating taps
along a column of MZIs or waveguides), which automati-
cally removes any laser power ﬂuctuation not originating
from the photodetector measurement (i.e. from the laser
source itself). The units of power used in this paper are
based on renormalizing this power based on the input
into the system such that the total power propagating
through a column of waveguides is 1.

Because our architecture is capable of implementing
only unitary matrices (not an SVD architecture), we elect
to perform the singular value operation (Σ) on the com-
puter and the majority of the computation (unitary ma-
trices U, V †) on the computer. Since only four phase
shifters are required to implement these singular value
operations (versus 32 for the unitary operators), we as-
sume that the experimental evaluation of the overall SVD
architecture is roughly the same as multiplying by the ap-
propriate singular values and evaluating U, V † separately
as indicated in the green box of Fig. 1(b).

Eq. 4 becomes:

T2(θ, φ) = B(cid:15)r (λ)

(cid:98)

B(cid:15) =

(cid:20)
C(cid:15)
iS(cid:15)
iS(cid:15) C(cid:15)
(cid:20)

(cid:21)

ei(θ+δθ(λ)) 0
1
0

B(cid:15)(cid:96)

ei(φ+δφ(λ)) 0
1
0
(cid:21)

(cid:20)

(cid:21)

(5)
where we model the beamsplitter error using Cj =
π
cos
, where j = (cid:96), r stands
4 + δj
for the left and right beamsplitters of the MZI.
(cid:0)

The errors may be statistically modelled from wave-

, Sj = sin

π
4 + δj

(cid:1)

(cid:1)

(cid:0)

length and fabrication variations as follows:

1. The coupling errors δ(λ)

λc)2, σ),
λc)2 is a dispersion contribution with
where µbs(λ
scaling µbs and σ is fabrication or drift error which
is present in an MZI.

(µbs(λ

∼ N

−

−

2. The phase errors δη(λ)

λc), σps), where
λc) is a dispersion contribution with scaling
µη(λ
µη and σ is crosstalk or drift error which is present
in an MZI.

(µη(λ

∼ N

−

−

3. When incorporating loss imbalance error, we have

δξ(λ)

∼ N

(µlossηj, σloss).

Note that loss imbalance errors δξ only needed in the
positions of the phase shifters; all remaining losses may
be “pushed” to the end of the mesh by algorithmically ap-
plying commutations of common mode losses in the MZIs
[24]. Ultimately, grating coupler eﬃciency variations and
the algorithm to move all losses to the branches will com-
bine to give an array of N independent loss elements, but
this can be eﬀectively calibrated out by the network by
scaling the power threshold pth by these constant loss
terms.

D. Node error model

E. Phase shifter calibration

As discussed in the main text, we explore three sources
loss, coupling and phase. Each
of error in simulation:
source of error arises from various fabrication imperfec-
tions or phase drift sources. In order to formalize these
error contributions, we deﬁne an ideal MZI node and con-
trast the ideal operation from the non-ideal operation
(phase, coupling, and loss error). All of our calculations
are performed using our open source Python photonic
simulation code simphox [20].

The ideal MZI node in terms of building blocks that
consist of a φ phase shift, 50:50 coupler, θ phase shift, and
another 50:50 coupler, giving us the following mathemat-
ical representation acting on modes x1, x2 and yielding
outputs y1, y2:

As discussed in the main text, the calibration protocol
involves sweeping phase shifter voltages such that the
phase is calibrated from 0 to 2π.

Each phase shifter is calibrated by optical interference
measurements evaluated at each MZI output in the mesh.
The split transmissivity measured from spots ca be mod-
elled as t = sin2 θ, where θ is twice the phase shift in the
internal arm, which is used for calibration:

t =

pt
p ≈

pt
pr + pt

(6)

where t is the transmissivity, p is the total power at the
input, pt is the cross state grating power and pr is the
bar state grating power determined by summing up pixel
values from the camera.

The model is:

y1
y2
(cid:20)

= i

eiφ sin θ
2
eiφ cos θ
2 −
(cid:21)
(cid:20)
y = T2(θ, φ)x,

cos θ
2
sin θ

2 (cid:21) (cid:20)

x1
x2

(cid:21)

(4)

θ = p0v3 + p1v2 + p2v + p3
t = a sin θ + b.

(7)

Empirically, it suﬃces to ﬁt v2 = q0θ3 + q1θ2 + q2θ + q3

to convert voltage to phase.

The calibration proceeds by ﬁrst calibrating all inter-
nal phase shifters (θ phase shifts) and then calibrating all
external phase shifters (φ phase shifts) using the already
calibrated θ phase shifts. In order to address each of the
individual MZIs, we use the calibration approaches ar-
gued in Refs. 25, 26 which treats already-calibrated MZIs
as switches to progressively calibrate MZIs from input-
to-output in the network. A useful trick for calibrating
the external phase shifts is to create “meta-MZIs” in the
mesh, which is a technique also used in Refs. [6, 27, 28]
where external phase shifts φ can be treated as internal
phase shifters in an MZI by setting appropriate θ phase
shifts to π/2.

Appendix A: Mining pool implementation

(cid:104)

(cid:105)

(cid:15)

It is important to have a sense for the expected hash
error rate
for a given LightHash-based miner upon
widespread adoption of a photonic proof of work-based
cryptocurrency. While an accurate hash computation
intermediate
isn’t required unless the block is solved,
mining rewards in “mining pools” are typically oﬀered
to miners in units of “shares” that have a much lower
B than the ﬁnal proof of work solu-
diﬃculty Bshare (cid:28)
tion, where B as deﬁned earlier represents the number
of bits for proof of work. Mining pools act as a sin-
gle mining entity consisting of many individual miners
that earn shares in proportion to the amount of work
they do. Mining pools are chosen by miners who do not
have the capability of getting signiﬁcant proﬁts by mining
alone. Getting a share is generally proof that the “cor-
rect” proof of work is being performed. Accurate mining
is important to ensure that these shares can be earned at
a suﬃciently high percentage to reap proﬁts. Therefore,
the error rate multiplied by the number of shares will
yield the total proﬁt for the miner. Note that there is no
penalty for a failed calculation for a nonce that does not
yield any share reward.

Appendix B: General purpose usage

The functionality of a photonic mesh as general pur-
pose hardware is key to their ﬁt as an optical proof of
work device. For Bitcoin, the most eﬃcient (and thus
proﬁtable) mining equipment are electronic application-
speciﬁc integrated chips (ASICs) such as the Antminer
S19 by Bitmain, which coerce miners to rely on the ser-
vices of centralized institutions. Other coins such as
Ethereum are ASIC resistant and can be proﬁtably mined
using more general purpose Graphical Processing Units
(GPUs) or Field-Programmable Gate Arrays (FPGAs).
This creates less hardware investment risk for miners be-
cause the GPUs and FPGAs have general use cases as
opposed to mining ASICs; namely, GPUs can be used for

10

graphics engines and machine learning applications and
FPGAs are used for low-energy digital signal process-
ing. Likewise, photonic mesh technology can be applied
across several applications, with industry eﬀort already
underway in applications such as machine learning and
fast signal processing. This ultimately mitigates the risk
of buying new photonic hardware, if it can ultimately ac-
crue monetary value via mining when not used for other
purposes. As a simple demonstration, we show in Ref.
[17] that our photonic mesh is capable of machine learn-
ing inference and is additionally the ﬁrst to implement
in situ backpropagation training when integrated within
photonic neural networks, which furthers the case for its
eventual use as a cryptocurrency miner.

Appendix C: Energy considerations

·

The digital implementation of LightHash-N, K con-
N ﬂoating point
sumes most of the computation if 256
operations (each costing A fJ of energy) exceeds the en-
ergy per SHA3-256 hash. In a fully digital implementa-
tion, if N = 64 and A = 0.1 pJ, we would have 1.6384 nJ
of energy used for matrix multiply portion. This is much
more than the energy required of ASIC hash technol-
ogy currently costing up to 10 pJ per hash for Bitmain’s
state-of-the-art Antminer S19 device which is nearly 2
orders of magnitude lower.

In photonic implementations, the number of electrical
ops is reduced by a factor of N/2 to eﬀectively 512 op-
toelectronic ops, 256 each for the inputs and outputs.
The input modulators, which may include using lithium
niobate modulators [29] or silicon-organic hybrid modu-
lators [30], each require around 1 fJ/bit and the output
comparators require at least 40 fJ/bit [14, 15] operating
at GHz speeds. As a result, the total energy for N = 64
becomes roughly 10.5 pJ of energy which is two orders of
magnitude less energy than the digital and roughly the
same order of magnitude as the rest of the hash.

In summary, the guiding principle behind our energy
eﬃcient design is to perform all linear operations in the
optical domain and all nonlinear or logic operations in
the digital electronic domain, which leverages the core
advantages of each platform. Since our protocol is dom-
inated by linear ﬂoating point operations, most of the
computation is thus handled in the optical domain, which
in turn provides the strongest computational advantage
possible. Of course, as explored in this work this must
be evaluated in the context of systematic error, which is
the principal roadblock remaining in order to realize the
full potential of a photonic cryptocurrency.

Appendix D: Digital conversion and rescaling

An important aspect of the LightHash algorithm is
the analog-digital interface implementing the threshold-
ing, which consumes most of the energy in our platform.

11

FIG. 4. We extend the simulation results of Fig. 2 of the main text. Speciﬁcally, we analyze error scaling by plotting the
histogram of errors and discrete outputs with σ = 0.25 for (a) (N, K) = (32, 4) and (b) (N, K) = (64, 2). The histograms
are evaluated over 10 matrices Q, 1000 inputs x and 1280/N errors given loss, coupling, and phase component errors σ. We
ﬁnd that the errors are similar to each other (conﬁrming approximate N Kσ scaling) but not exactly the same (loss errors
are slightly larger but coupling errors are smaller for N = 32). (c) We analyze the error scaling of dimension K instead of
component error σ, ﬁnding feasible operation of K = 2, N = 32 or N K = 64 for an error of roughly 0.01 radians for phase and
coupling and 0.03 dB for loss. As in Fig. 2, the transition between feasible and infeasible (N, K) is very sharp.

Here, we explain exactly how those interfaces might be
implemented in a manner that avoids any laser ﬂuctua-
tion or drift error contributions since the reference itself
also has the same ﬂuctuation and drift.

First, note that singular values can only be represented
as lossy elements in linear optical networks. Therefore,
given Q = U ΣV † with singular values in the diagonal Σ
matrix represented as σ, we typically divide the singular
values by σmax = max(σ) such that no singular value
exceeds 1. As a result, we need to “remember” this term
when computing thresholds at the end of the circuit.

For the “unsigned” implementation of LightHash dis-
cussed in the main text and shown in Fig. 5(a), no ad-
ditional phase reference is required. However, we still
need some way to cancel out the laser noise and drift,
and the implementation of the thresholding requires some
more care to various scaling factors in the hardware. For
laser drift compensation, one can tap out a small frac-
tion ξ < 1 of the input power P to establish a reference
power. The corresponding input vector x is renormal-
ξ)P x/√N . The actual photonic net-
ized to
(1
x/σmax, where L
work performs the operation

y = QL

x =

−

(cid:112)

(cid:101)

(cid:101)

(cid:101)

is the photonic loss expressed as a fraction of the power
(maximum of 1). This means that the actual output is
y = √couty, where:

(cid:101)

cout =

(1

ξ)P L

−
σ2
maxN

(D1)

cref = ξP/N

where cref is similar scaling factor for the reference signal
split across N outputs. The split reference photocurrent
is related to the threshold power by Iref = ηcref and the
2
output photocurrents are given by In = η
yn|
(Note that using the same bias voltages for all photode-
tectors ensures roughly same η, and additional atten-
uator MZIs may be used to correct for any sensitivity
diﬀerences across photodetectors). Our scaling problem
can therefore be reduced to ﬁnding a condition for ξ
2 = pth and Iref = In simultaneously, i.e.
such that
yn|
|
cout = cref /pth, giving:

yn = ηcout|

(cid:101)

ξ =

1 +

(cid:18)

1

−

σ2
max
pthL

(cid:19)

(D2)

05101520253035Outputhistogram:(N,K)=(64,2)Errorσout=0.25Ideal0.00.10.2σdBLoss(σdB)0.000.250.500.75σBSCoupling(σBS)0.000.250.500.75σθ,φPhase(σθ,φ)248K8163264NLoss(σ=0.003)248K8163264NPhase(σ=0.001)248K8163264NCoupling(σ=0.001)248K8163264NLoss(σ=0.012)248K8163264NPhase(σ=0.004)248K8163264NCoupling(σ=0.004)248K8163264NLoss(σ=0.030)248K8163264NPhase(σ=0.010)248K8163264NCoupling(σ=0.010)0102030405060Outputhistogram:(N,K)=(32,4)Errorσout=0.25Ideal0.00.10.2σdBLoss(σdB)0.000.250.500.75σBSCoupling(σBS)0.000.250.500.75σθ,φPhase(σθ,φ)10.80.60.40.20.0Hashpacket errorrate/PERσ=0.002σ=0.003σ=0.004σ=0.005σ=0.006σ=0.008(a)(b)(c)1000 inputs, 10 matrices1000 inputs, 10 matrices12

FIG. 5. (a) Unsigned thresholding design can compensate for laser drift and ﬂuctuation by using light tapped from the input.
(b) Signed thresholding involves interfering a reference signal to measure the sign of the output signals. (c) A hardware-agnostic
error correction SVD architecture can operate using the same energy consumption.

If ξ > 1, an alternate type of rescaling may be done by
setting ξ = 0.5 and instead changing the bias voltages
and thus the output photocurrents output by the inte-
grated PDs to equalize the scaling:

ηref
ηout

=

σ2
max
pthL

(D3)

This rescaling calculation only needs to be performed
once per block since L, σ2
max only depend on the imple-
mented Q and not the inputs x.

For the “signed” implementation of LightHash shown
in Fig. 5(b), a circuit using a phase reference and com-
parator is required to measure whether the output of the
mesh is a number that is positive or negative. The phase
reference is generated by splitting the original input light
into a reference path, which is in turn split into N waveg-
uides. The phase reference is then interfered with the
In
overall output of the photonic network given by y.
this manner we can treat the output signal r = i (a vec-
tor of all i’s). Using a directional coupler to interfere
any output y with incoming ﬁeld i will give two outputs
2. The assignment of a
1
=
p+ =
|
bit is thus given by the simple condition p+ > p
, which
indicates whether a presumed real y is positive or nega-
tive. Note that the aforementioned laser noise and drift
will aﬀect r and y equally since they are sourced from
the same laser, so the comparator will not be aﬀected
by this error source. However, other errors such as var-
ious systematic errors in the photonic circuit will still
contribute the dominant portion of the error. Note that

y + 1
|
|

2 and p

y
|

−

−

−

with this technique, there is no need for rescaling based
on the maximum singular value and loss as is required in
the unsigned implementation.

Another point to address is whether to use an analog
digital converter (ADC) to output the ﬁnal aggregated
bits to allow for more bits per output. An analog-to-
digital converter operates at low power using a succes-
sive approximation (SAR) approach and is actually built
using stages of 2b comparators, where b is the number of
bits we use to represent the output. Compared to raw
comparators, the additional overhead required for SAR
might reduce the overall energy eﬃciency and increase
latency in the overall computation per bit. This war-
rants future investigation because if the SAR overhead is
designed to be negligible, an ADC could also be useful
to aggregate bits and separate more peaks in Fig. 3 with
minimal change in the hash error rate as we found using
the scaling arguments in Fig. 2(b).

Yet another alternative similar to an ADC would be
to use “parallel multithresholding” where we split the
output photonic signal into M waveguides. At the cost of
additional photonic loss by a factor of M , this split signal
could be compared to multiple thresholds set between
the peaks in Fig. 3. Alternatively, we could split the
2b splitter to measure
photocurrent equally using a 1
among 2b thresholds spaced 2 apart, implementing using
the unsigned thresholding comparator of Fig. 5(a). Note
that using multiple thresholds (eﬀectively more than a
single bit) will increase the error rate by a factor of at
most 1/ρ(N, K), at most an order of magnitude increase

×

DigitalEqualsplitterSample/hold......QLaser†ΣUV1550 nm...Q†ΣUV...Q†ΣUV...123N......R repeatsSplitter(photonic)Photocurrentcombiner(electronic)Q†ΣUVQ†ΣUV123NpnVrefbn−+VnprefVrefRRpbn−+V+RpVR−−+...123N...123N123N123N...p+p−prefSignedUnsigned(a)(b)(c)Hardware-agnostic error correctionSigned thresholdingUnsigned thresholdingEqualsplitterEqualsplitterEqualsplitterComparatorComparatorNrefVb,nVb,ref50/50prefpnVb,−Vb,+−+Buffer13

FIG. 6. (a, b) We compare the unitary and orthogonal matrix multiplication errors evaluated for 1000 Haar random matrix-
vector pairs. Speciﬁcally, we compare 1. amplitude only, 2. amplitude and phase (see Ref. [17]), 3. amplitude and sign (for
reals). We ﬁnd that unitary and orthogonal matrices do not diﬀer much import. (c, d) The expected signal is [0.2, 0.2, 0.2,
0.2, 0.2] shown using the dotted line, and biased systematic error clearly dominate compared to the standard deviation of the
Gaussian distributions. (e) The FFT of the camera fractional spots (used for all optical IO, normalized over the 5 output
channels). This spectrum reveals classic 1/f noise (the slower variation in (c)) and white noise (broadband noise region) caused
by camera photodetector noise with a noticeable dip at the end occurring at the frame rate of the camera (100 Hz).

according to Fig. 2.

Appendix E: Experimental error analysis

Chip errors in photonic meshes can be categorized as
either random noise (polarization, photodetection, laser
noise errors) or systematic error (loss, coupling, phase
errors). In this paper, we analyze systematic error in our
simulations since such errors shift the operation of the de-
vice and this are challenging to compensate straightfor-
wardly. In this Appendix, we address collective random
and systematic error contributions in our experimental
setup.

the case for systematic error which is a major reason we
emphasize this error type in the main text. Nevertheless,
we aim to explore the various random errors in our ex-
perimental setup and the contribution of such errors to
overall performance compared to systematic error.

As referenced in the main text, systematic error dom-
inates random noise in our experimental system. This is
because our random noise sources are generally straight-
forward to mitigate. For instance, as is shown in Fig.
5(a), unsigned thresholding uses a laser reference signals
to compensate for any laser drift. Signal to noise ratio
can also generally be improved by using longer photode-
tector integration time, addressing error sources such as
shot noise and 1/f noise caused by drift.

Random noise can be dealt with by integrating or aver-
aging long enough, which implies a tradeoﬀ with latency
and ultimately energy eﬃciency of operation. This is not

In our experimental setup, the photodetection noise
is represented in terms of camera noise (eﬀectively the
photodetectors in our system). Camera noise consists of

(a)(b)(c)(d)(e)10−510−410−310−210−1100Error((cid:31)y−(cid:31)y(cid:31)2)020406080100UnitaryMVMerror((cid:31)y=Ux,N=4)AmplitudeonlyAmplitudeandphase10−510−410−310−210−1100Error((cid:31)y−(cid:31)y(cid:31)2)020406080OrthogonalMVMerror((cid:31)y=Ox,N=4)AmplitudeonlyAmplitudeandphaseAmplitudeandsign020000400006000080000100000Timet(ms)0.180.200.22MeasuredfractionalpowerpMonitoring5equaloutputs(raw)0.180.200.220.24010000200003000010−210−1100101102Frequency(Hz)10−1102NoiseDensity(1/Hz)Monitoring5equaloutputs(FFT)quantization noise in the camera pixels (14 bits of accu-
racy), camera photodetector shot noise, and noise due to
vibration of the setup due to coupling to the mechanical
stage. Other sources of noise include thermal ﬂuctua-
tions throughout the chip (which appears to dominate
when phase shifts change) and polarization noise due to
vibrations in the ﬁber. While not impossible to isolate
these various sources of error, the systematic error in
the photonic chip typically dominates these other error
sources. As a consequence, we consolidate all of these
errors into a single random error quantity to facilitate
the comparison with systematic error. As an experimen-
tal demonstration, to conﬁrm our claims we provide the
evidence based on our results from Fig 6(c, d).

In addition to characterizing random error sources, we
can perform an analog comparison of expected and mea-
sured device operations, speciﬁcally matrix-vector multi-
plications in the real and complex domain. To do this,
we use our photonic mesh to compute the dot product
of the measured vector and the predicted vector of the
matrix multiply y = U x over random U and random x.
This procedure for calculating the amplitude and phase
of 4
6 triangular
×
mesh is discussed in more detail in Ref. [17].

4 matrix-vector products in our 6

×

For our characterization of systematic error, we com-
pare real (orthogonal) and complex (unitary) matrix-
vector multiplication errors performed on our chip. To
select a random complex x, we sample from the com-
(0, 0.5)i and to
plex normal distribution
N
(0, 1) where
select a random real x, we sample from
(µ, σ) represents a normal distribution with mean µ
N
and standard deviation σ. For the complex vector, we
multiply by random complex matrix U sampled from the
Haar measure of the unitary group. For the real vector,
we multiply by random real matrix O sampled from the
Haar measure of the orthogonal group.

(0, 0.5) +

N

N

(cid:107)

(cid:98)

(cid:101)

(cid:98)

(cid:101)

(cid:98)

y

y

y

−

|(cid:107)

y)

|−|

| ·
(cid:98)

−
y
|

2), amplitude and phase (
y
(cid:107)
y =

The results of this analysis are shown in Fig 6(a, b),
where we evaluate three types of errors: amplitude only
2), and ampli-
(
y
(cid:107)
(cid:107)|
2), where
sign(
y)). A
(
tude and sign (
(cid:107)
R
potential reason amplitude-and-phase measurements are
so error-prone has to do with our readout method that
relies on imperfect phase shifter calibration; this speciﬁ-
cally aﬀects the operation of the network for solving ma-
chine learning tasks [17]. For amplitude and sign error
to achieve the amplitude-only accuracy, we use the phase
measurement to measure only the sign and not the phase
itself and use the direct output power measurements to
measure the output power to ultimately minimize the er-
ror. Note that all SVD calculations in this paper assume
that amplitude-only measurement is suﬃcient to repre-
sent error due to the U, V orthogonal matrix operations
on inputs x, which is justiﬁed by Fig 6(b). More details
on our exact implementation are provided in our Phox
software [19] and accompanying Zenodo data availability
upload [18].

14

(cid:46) Prepare nonce

Q ← blk.matrix
D ← blk.difficulty
for s ∈ [1, 2, . . . S] do

Algorithm 1 LightHash
1: function LightHash(blk, S)
2:
3:
4:
5:
6:
7:
8:

end for
Ninputs ← Length(U )
Nbits ← 256/Ninputs
X, (cid:101)X ← 0S×N
for s ∈ [0, 1, 2, . . . S] do

nonceList[s] = blk.nonce + s

9:
10:

11:

12:
13:
14:
15:
16:
17:

(cid:46) For batch matmul

(cid:101)Xs ← SHA3-256(blk, nonceList[s])
Xs ← eiπ (cid:98)Xs /16

(cid:46) Digital
(cid:46) On-chip

end for
Y ← QX
P ← |Y |2
B ← P > pth(N, K)
for s ∈ [1, 2, . . . S] do

(cid:46) On-chip propagation
(cid:46) Photodetection
(cid:46) Unsigned comparator
(cid:46) Access batch elements
b ← SHA3-256(Bs ⊕ (cid:101)Xs)
(cid:46) Digital
if Int(b) < 2256−D then (cid:46) First D bits are zero.

return b

18:
19:
20:
21:
end for
22:
return Ø
23:
24: end function

end if

(cid:46) Initialize Q to zeros

(cid:46) For deterministic behavior.
(cid:46) Block diagonal Q

Algorithm 2 Optical Proof of Work
1: function LHBlock(transactions, N , K, prevBlk)
require N = 2L ≤ 256 for L ∈ Z+ positive integer
2:
blk ← EmptyBlock()
3:
blk.height ← prevBlk.height + 1
4:
blk.difficulty ← LHDifficulty(blk.height)
5:
blk.prevBlkPtr ← prevBlk.hash
6:
merkleTree ← MerkleTree(transactions)
7:
blk.merkleRoot ← RootPointer(merkleTree)
8:
Nblocks ← 256/N
9:
Q ← O256×256
10:
n ← 0
11:
Seed(prevBlk.hash)
12:
for m ∈ [1, 2, . . . Nblocks] do.
13:
for i ∈ [1, 2, . . . N ] do
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
end while
28:
blk.hash ← bsol
29:
return blk
30:
31: end function

n ← n + 1
seed ← merkleRoot + n
q ← Pseudorand([1, . . . K], seed)
Qm,ij ← 2q − K − 1

end for
blk.matrix ← Q
bsol ← Ø
while bsol is Ø do:

blk.nonce ← Pseudorand([0, 1, . . . 2Nbits − 1]).
bsol ← LightHash(blk, 1)

for j ∈ [1, 2, . . . N ] do

end for

end for

(cid:46) Do all chip calibration here.
(cid:46) Solved hash

(cid:46) Block m, elem i, j.

15

FIG. 7. LightHash function ﬂow in more detail embedded in a conceptual chip footprint with a digital processing portion
(orange) and an optical processing portion (green) implementing 256/N parallel SVD operations of size N , here shown for
N = 4.

Appendix F: LightHash justiﬁcation

The LightHash function, albeit relatively simple math-
ematically, was chosen carefully to allow for a feasible
photonic cryptographic protocol. The key insight in
LightHash is that spacing possible optical output val-
ues in a discrete grid (i.e. using integer math) ultimately
enables an error tolerant threshold and digital veriﬁa-
bility of the hash function. Additionally, LightHash has
the elegant property at K = 2 of implementing a random
walk for each vector-vector product in the overall matrix-
vector product since the matrix elements and vector ele-
ments are both

1, 1.

The LightHash function is represented in more detail
in Fig. 7, which shows that signals are split into chunks
of size N and sent into 256/N meshes of circuit size N .
Unlike HeavyHash [7], here we provide a scheme that
allows for diﬃculty tunability in N and K (numerical
resolution) that allows for a feasible optical proof of work
implementation.

−

The choice of parametrizing LightHash by N, K has
to do with adjusting the problem diﬃculty to achieve
feasible bit error rate
1%. We center the possible
integers in the matrix to zero since LightHash is supposed
to represent an optical physical random walk in discrete
space. We space the integers by 2 instead of 1 to maintain
integer step sizes for both odd and even K.

(cid:105) ≤

ε
(cid:104)

The choice of K and N is of course important when
building any blockchain protocol around optical proof of
work. Note that there exists a possible “digital attack

vector” to consider that can “cheat” on LightHash based
on caching results rather than performing the matrix
multiply. One such issue is that we work in a ﬁnite state
space of possible combinations of matrix row and vec-
tor combinations. This means that vector-vector prod-
uct results can in principle be cached provided there is
suﬃcient memory in the device. Therefore, understand-
ing the total state space size is of critical importance
in LightHash to prevent digital attacks. The system we
study in this paper, N = 4, K = 2 to 9, is susceptible
to a digital attack vector of this kind because there are
only 120 to 104976 possible vector-vector products that
can feasibly be stored in RAM on a single computer. In
general, there are on the order of C := (2K)N possible
vector-vector products in the state space. Since N, K af-
fect the error equally, increasing N is a more eﬀective way
to increase the overall state space to avoid this attack vec-
tor compared to increasing K. As an extreme example,
if K = 64, N = 2, we have C = 16384 which is feasible
1038
to cache but if N = 64, K = 2, we have C = 3.4
which is astronomically large. Despite this scaling argu-
ment, an increase in K could be useful for improving the
photonic advantage by requiring more bits to represent
the possible outputs of the LightHash function, which
would require more expensive digital hardware.

×

EqualsplitterLaser1550 nmUV†ΣQxybSHA3-256acceleratorOptical domain0001111010011001010000100011101001001110110100100111011000001000101000010101101000100110000101101010001010110000111010011110010100101100111011010011001100001010110001010011000011101101110011000011001011001000111111111100011010100101001001101010111011011101Block data256 bits0111011010011010001001100001011011101001111001011110110111001100001100101100100011111111110001100010110011101101001100110000101010100010101100001100010100110000101001010010011010101110110111010001111010010011010000100011101001001110110100100111011000001000Optical data256 bitsSHA3-256accelerator............Digital domainXOR256 / N meshesPossiblesolutionpnVrefbn−+VnRVb,ncomparatorAppendix G: LightHash pseudocode

In this section we describe the various algorithms of
required to implement LightHash and optical proof of
work deﬁned in terms of pseudocode in Algs. 1 and 2.
As mentioned in the main text, at a high level, the op-
tical proof of work we propose is an improvement upon
Bitcoin’s current protocol which uses SHA256, which we
have proposed as a Bitcoin Improvement Proposal [31].
Note also our usage of the Keccak or SHA3-256 func-
tion (as opposed to other variants of SHA256) which has
the following advantages: (1) it is a new-generation re-
placement of SHA2, developed under the NIST initiative
and (2) it does not have adders and therefore results in
a smaller area on chip, unlike SHA2.

There are two ways we can vary the LightHash im-
plementation. First, we consider signed and unsigned
thresholding as shown in Fig. 5; we choose the unsigned

16

variety discussed in the main text. The other parameter
provided in the LightHash function of Alg. 1 is the batch
size S which can be used by digital implementations to
parallelize the matrix multiplication across many hashes
at once.

The optical proof of work protocol shown in Alg. 2
considers the case S = 1. Using wavelength multiplexing
at the expense of higher error rates, this can be extended
to larger S by encoding S bitvectors across S wavelengths
propagating through the mesh simultaneously. some pre-
liminary analysis of the bit error dependence vs wave-
length is shown in the main text in Fig. 3(f) though this
may overestimate the error dispersion relation since the
input vectors are also aﬀected by the wavelength shift.

Finally,

to demonstrate

an implementation of
LightHash, we have a bare-bones Python emulator imple-
mented for LightHash in our Phox repository [19] which
is also explicitly tested in our data availability repository
[18].

[1] David A. B. Miller, “Self-conﬁguring universal

linear
optical component [Invited],” Photonics Research 1, 1
(2013).

[2] Wim Bogaerts, Daniel P´erez, Jos´e Capmany, David A.B.
Miller, Joyce Poon, Dirk Englund, Francesco Morichetti,
and Andrea Melloni, “Programmable photonic circuits,”
Nature 586, 207–216 (2020).

[3] Juan Miguel Arrazola, Thomas R. Bromley, Josh Izaac,
Casey R. Myers, Kamil Br´adler,
and Nathan Killo-
ran, “Machine learning method for state preparation and
gate synthesis on photonic quantum computers,” arXiv
preprint (2018).

[4] Jacques Carolan, Christopher Harrold, Chris Sparrow,
Enrique Mart´ın-L´opez, Nicholas J. Russell, Joshua W.
Silverstone, Peter J. Shadbolt, Nobuyuki Matsuda,
Manabu Oguma, Mikitaka Itoh, Graham D. Marshall,
Mark G. Thompson, Jonathan C.F. Matthews, Toshikazu
and Anthony Laing,
Hashimoto, Jeremy L. O’Brien,
“Universal linear optics,” Science
(2015), 10.1126/sci-
ence.aab3642.

[5] Andrea Annoni, Emanuele Guglielmi, Marco Carminati,
Giorgio Ferrari, Marco Sampietro, David Ab Miller, An-
drea Melloni,
and Francesco Morichetti, “Unscram-
bling light - Automatically undoing strong mixing be-
tween modes,” Light: Science and Applications 6 (2017),
10.1038/lsa.2017.110.

[6] Yichen Shen, Nicholas C. Harris, Scott Skirlo, Mihika
Prabhu, Tom Baehr-Jones, Michael Hochberg, Xin Sun,
Shijie Zhao, Hugo Larochelle, Dirk Englund, and Marin
Soljaˇci´c, “Deep learning with coherent nanophotonic cir-
cuits,” Nature Photonics 11, 441–446 (2017).

[7] Michael Dubrovsky, Marshall Ball, Lucianna Kiﬀer, and
Bogdan Penkovsky, “Towards Optical Proof of Work,” in
Cryptoeconomic Systems (2020).

[8] Michael Reck, Anton Zeilinger, Herbert J. Bernstein,
and Philip Bertani, “Experimental realization of any dis-
crete unitary operator,” Physical Review Letters 73, 58–
61 (1994).

[9] William R. Clements, Peter C. Humphreys, Benjamin J.

Metcalf, W. Steven Kolthammer, and Ian A. Walmsley,
“An Optimal Design for Universal Multiport Interferom-
eters,” Optica , 1–8 (2016).

[10] Ryan Hamerly, Saumil Bandyopadhyay, and Dirk En-
glund, “Accurate Self-Conﬁguration of Rectangular Mul-
tiport Interferometers,” (2021).

[11] Saumil Bandyopadhyay, Ryan Hamerly, and Dirk En-
glund, “Hardware error correction for programmable
photonics,” Optica 8, 1247 (2021).

[12] Ryan Hamerly, Saumil Bandyopadhyay,

and Dirk
Englund, Inﬁnitely Scalable Multiport Interferometers,
Tech. Rep. (2021).

[13] Sunil Pai, Ben Bartlett, Olav Solgaard,

and David
A. B. Miller, “Matrix Optimization on Universal Unitary
Photonic Devices,” Physical Review Applied 11, 064044
(2019).

[14] Leo Filippini and Baris Taskin, “A 900 MHz Charge Re-
covery Comparator with 40 fJ per Conversion,” in Pro-
ceedings - IEEE International Symposium on Circuits
and Systems, Vol. 2018-May (Institute of Electrical and
Electronics Engineers Inc., 2018).

[15] Masaya Miyahara, Yusuke Asada, Daehwa Paik,

and
Akira Matsuzawa, “A low-noise self-calibrating dynamic
comparator for high-speed ADCs,” in Proceedings of 2008
IEEE Asian Solid-State Circuits Conference, A-SSCC
2008 (2008) pp. 269–272.

[16] Mitchell A. Nahmias, Thomas Ferreira De Lima, Alexan-
der N. Tait, Hsuan Tung Peng, Bhavin J. Shastri,
and Paul R. Prucnal, “Photonic Multiply-Accumulate
Operations for Neural Networks,” IEEE Journal of
Selected Topics in Quantum Electronics 26 (2020),
10.1109/JSTQE.2019.2941485.

[17] Sunil Pai, Zhanghao Sun, Tyler Hughes, Taewon Park,
Ben Bartlett, Ian A.D. Williamson, Momchil Minkov,
Nathnael Abebe, Francesco Morichetti, Andrea Mel-
and David A. B.
loni, Shanhui Fan, Olav Solgaard,
Miller, “Experimentally realized in situ backpropagation
for deep learning in nanophotonic neural networks,” In
preparation (2022).

17

for

[18] Sunil Pai, “solgaardlab/photoniccrypto: Data and
code
evaluation of
the paper ”Experimental
digitally-veriﬁable photonic computing for blockchain
and cryptocurrency”,” Zenodo
(2022), 10.5281/ZEN-
ODO.6557372.

[19] Sunil Pai, Zhanghao Sun,

and Taewon Park, “phox:
Base repository for simulation and control of photonic
devices,” (2022).

[20] Sunil Pai, “simphox: Another inverse design library,”

(2022).

[21] Sunil Pai and Nathnael Abebe, “dphox: photonic layout

and device design,” (2022).

[22] David A. B. Miller, “Setting up meshes of interferome-
ters – reversed local light interference method,” Optics
Express 25, 29233 (2017).

[23] David A. B. Miller, “Analyzing and generating mul-
timode optical ﬁelds using self-conﬁguring networks,”
(2020).

[24] Micha(cid:32)l Oszmaniec and Daniel J. Brod, “Classical simu-
lation of photonic linear optics with lost particles,” New
Journal of Physics 20, 092002 (2018).

[25] Jacob Mower, Nicholas C. Harris, Gregory R. Stein-
brecher, Yoav Lahini, and Dirk Englund, “High-ﬁdelity
quantum state evolution in imperfect photonic integrated
circuits,” Physical Review A 92, 032322 (2015).

ponents,” Optica 2, 747 (2015).

[27] Nicholas C. Harris, Gregory R. Steinbrecher, Mihika
Prabhu, Yoav Lahini, Jacob Mower, Darius Bunandar,
Changchen Chen, Franco N.C. Wong, Tom Baehr-Jones,
Michael Hochberg, Seth Lloyd,
and Dirk Englund,
“Quantum transport simulations in a programmable
nanophotonic processor,” Nature Photonics 11, 447–452
(2017).

[28] Mihika Prabhu, Charles Roques-Carmes, Yichen Shen,
Nicholas Harris, Li Jing, Jacques Carolan, Ryan
Hamerly, Tom Baehr-Jones, Michael Hochberg, Vladimir
ˇCeperi´c, John D. Joannopoulos, Dirk R. Englund, and
Marin Soljaˇci´c, “Accelerating recurrent Ising machines in
photonic integrated circuits,” Optica 7, 551 (2020).
[29] Cheng Wang, Mian Zhang, Brian Stern, Michal Lip-
son,
and Marko Lonˇcar, “Nanophotonic lithium nio-
bate electro-optic modulators,” Optics Express 26, 1547
(2018).

[30] Clemens Kieninger, Christoph F¨ullner, Heiner Zwickel,
Yasar Kutuvantavida, Juned N. Kemal, Carsten Es-
chenbaum, Delwin L. Elder, Larry R. Dalton, Wolfgang
Freude, Sebastian Randel, and Christian Koos, “Silicon-
organic hybrid (SOH) Mach-zehnder modulators for 100
GBd PAM4 signaling with Sub-1 dB phase-shifter loss,”
(2020).

[26] David A. B. Miller, “Perfect optics with imperfect com-

[31] Michael Dubrovsky and Bogdan Penkovsku, “BIP 52:

Durable, Low Energy Bitcoin PoW,” (2021).

