The Convergence Rates of Blockchain Mining Games:
A Markovian Approach

Alejandro Jofr´e *

Angel Pardo †

David Salas ‡

Victor Verdugo §

Jos´e Verschae ¶

Abstract

Understanding the strategic behavior of miners in a blockchain is of great importance for its
proper operation. A common model for mining games considers an inﬁnite time horizon, with
players optimizing asymptotic average objectives. Implicitly, this assumes that the asymptotic
behaviors are realized at human-scale times, otherwise invalidating current models. We study
the mining game utilizing Markov Decision Processes. Our approach allows us to describe
the asymptotic behavior of the game in terms of the stationary distribution of the induced
Markov chain. We focus on a model with two players under immediate release, assuming two
different objectives: the (asymptotic) average reward per turn and the (asymptotic) percentage
of obtained blocks.

Using tools from Markov chain analysis, we show the existence of a strategy achieving slow
mixing times, exponential in the policy parameters. This result emphasizes the imperative need
to understand convergence rates in mining games, validating the standard models. Towards
this end, we provide upper bounds for the mixing time of certain meaningful classes of
strategies. This result yields criteria for establishing that long-term averaged functions are
coherent as payoff functions. Moreover, by studying hitting times, we provide a criterion to
validate the common simpliﬁcation of considering ﬁnite states models. For both considered
objectives functions, we provide explicit formulae depending on the stationary distribution of
the underlying Markov chain. In particular, this shows that both mentioned objectives are not
equivalent. Finally, we perform a market share case study in a particular regime of the game.
More precisely, we show that an strategic player with a sufﬁciently large processing power can
impose negative revenue on honest players.

1
2
0
2

l
u
J

6
1

]
T
G
.
s
c
[

1
v
7
7
0
8
0
.
7
0
1
2
:
v
i
X
r
a

*Department of Mathematical Engineering, Universidad de Chile. ajofre@dim.uchile.cl
†Department of Mathematical Engineering, Universidad de Chile. aapardo@dim.uchile.cl
‡Institute of Engineering Sciences, Universidad de O’Higgins. david.salas@uoh.cl
§Institute of Engineering Sciences, Universidad de O’Higgins. victor.verdugo@uoh.cl
¶Institute of Mathematical and Computational Engineering, Pontiﬁcia Universidad Cat ´olica. jverschae@uc.cl

 
 
 
 
 
 
1 Introduction

As the use of cryptocurrencies continue to grow, understanding the behavior of its miners
becomes paramount. A typical approach to analyze the Bitcoin mining process considers a
game-theoretical setting where selﬁsh miners aim to optimize an average objective. This has been
considered in the inﬂuential work by Eyal and Sirer [8], Kiayias et al. [11] and several subsequent
works [7, 22, 18, 9, 12, 3, 14]. Most models study this setting as a sequential game with inﬁnite
time horizon, where each player optimizes an asymptotic payoff. An implicit assumption on
this deﬁnition, is that these asymptotic objectives are realized at human time scales. Our long
term purpose is to understand the convergence rates to steady states of the mining game, hence
validating mathematically these deﬁnitions if possible, and more importantly, understanding their
limitations.

At an intuitive level, the main argument for the pertinence of such payoff functions and the
inﬁnite horizon assumption is a natural Markovian structure of the sequential game: once blocks
are validated by all miners, they become part of the ofﬁcial blockchain and they are no longer in
competition. However, the underlying Markovian process that miners face has, to the best of our
knowledge, never been carefully formalized. The ergodic properties of the underlying Markov
process allow to study the payoff functions asymptotically. However, Markovian properties alone
do not guarantee fast convergence. Thus, a natural question arises: Are asymptotic payoffs
actually observable in a time scale that is reasonable for the miners? That is, can we see the long
term behavior at human time scale? Once this question is on the table, the assumption of inﬁnite
time horizon, together with other ones like constant rewards and no simultaneous mining, become
questionable. Indeed, taking as example the Bitcoin protocol (well surveyed in [23]), the rewards
of mining a block (which are new Bitcoins that are created) halves every four years, starting at 50
BTC on 2009. By July 2021, the reward of a block is 6.25 BTC and it is projected that new Bitcoins
8 BTC (see [23]). This
rewards will end the year 2140, when the reward of a block becomes 10−
discount rate tells us that the assumption of constant rewards is valid only if long run means less
than 4 years.

Regarding the Markovian structure of the sequential game, it is usual in the literature [8, 11,
7, 22, 18, 9, 12, 3, 14] to consider ﬁnitely many possible states in the chain representation of it.
These states are given by the blocks that have not been recognized by all miners. The assumption
rests on the original blockchain white paper [17], where it is stated that blocks in dispute tend to
be resolved naturally by the consensus of honest miners, choosing one branch as the ofﬁcial an
leaving the blocks in the other ones as orphans. Thus, truncated models are applied, where it
is assumed that no strategic miner will persevere beyond certain threshold d: If another branch
reaches the length d + 1, he or she will capitulate, abandon his or her branch as orphan. However,
this threshold is not part of the blockchain protocol, and miners could potentially deviate from
this assumption. Thus, another natural question is when truncated models are consistent, in the
sense that they predict correctly the evolution of the sequential game.

In order to study these questions, we ﬁrst formalize the mining game by the lens of a Markov
Decision Process (MDP). This is not an easy task, mainly due to the fact that strategic miners can
hide information. Thus, as a starting point for this line of work, we focus our attention on mining
games under perfect information, or, as it was called in [11], immediate release. Once this is done,
we will use the explicit Markov chain structure to answer the questions described above in using
the theory of mixing and hitting times.

2

1.1 Our Contribution

We start by formalizing the mining game through the lens of MDP’s, allowing us to analyze the
mining game through the theory of Markov chains. In particular, we can describe some of the
relevant payoff functions considered in the literature by understanding the stationary distribution
of the underlying chain. The formal deﬁnition of the game and the payoffs can be found in
Section 2, while the Markovian approach is formalized in Section 3.

We consider the case of two players. In this case, both players can mine either the same block,
or mine their own branch of the blockchain. After each mining race, they can either decide to
keep mining their branch or capitulates to some block of the other branch. Hence, the state of the
game are given by two parameters ((cid:96)1, (cid:96)2), which represent the length of the two branches from
the last common ancestor. The states of the Markov chains can be represented within the integer
lattice, which allows us to ﬁnd explicit expressions of the stationary distributions by solving a
combinatorial problem corresponding to counting interior paths. We exploit this representation to
provide an example showing that certain strategies can have large mixing times. This highlights
the importance of understanding mixing times, and hence the validity of the models, for different
strategies. We are also able to give upper bounds on the mixing time, which helps us evaluate
convergence rates to the stationary regime. We evaluate this measure for the case in which one
player plays honestly, while the other capitulates if the length difference of the two branches is
larger than a given parameter g. Our upper bound of the mixing time depends on the processing
power of the strategic player and g. The proof is obtained by coupling techniques. Our analysis
allows us to validate the common assumption of asymptotic payoff functions for these strategies.
Through our representation, we formalize a notion of safety, which captures the idea of when
selﬁsh mining can be based on simpliﬁed models, at no risk of violating the blockchain protocol,
that is, parallel validated blocks. This is performed by studying the hitting time of the critical
state of having two parallel branches of length d. We provide sufﬁcient conditions under which a
strategy can be safely played, and we show the existence of unsafe strategies. The study is carried
out by bounding the number of interior paths from the initial states to the critical points in the
lattice representation. The mixing and hitting time study can be found in Section 4.

Finally, in Section 5 we perform a market share study over a particular family of strategies,
based on our Markovian model and the convergence analysis, in order to understand the impact
on the proﬁt of the miners according and how it behaves depending on the miner payoff function.
In this setting, we study the two most common payoff functions, which are the asymptotic ratio of
owned blocks, and the asymptotic revenue per time unit. We observe that these two functions are
far from being equivalent. Furthermore, we observe that in our regimes, a sufﬁciently powerful
strategic miner can apply a strategy that makes other miners to have negative proﬁts, and therefore
pushing them out of the mining game.

1.2 Related Literature

Since the introduction of the Bitcoin blockchain protocol in 2008 by Nakamoto [17], there has been
an intensive study around the development and understanding of the blockchain protocol and
its variants. We refer to Abadi and Brunnermeier [1] for an economic analysis of the blockchain
protocol, and to [23] for a technical review. Selﬁsh mining was originally studied by Eyal and
Sirer [8], and they show the existence of a non-honest mining strategy that is proﬁtable if the hash
power of the non-honest players is at least 33.3%. Particularly relevant to our setting is the work
by Kiayias et al. [11], that model strategic mining through the lens of a stochastic game under
complete information.

3

Recently, Marmolejo-Coss´ıo et al. [16] extend the analysis of Eyal and Sirer to the case of
multiple, not necessarily colluded, selﬁsh miners, showing that they have incentives to deviate in
block from honest mining. Arnosti and Weinberg [4] study the Bitcoin mining through the lens of
investment costs vs market concentration, ﬁnding evidence of an oligopolistic behavior. The study
of strategic and selﬁsh mining is a very active area; see e.g. [7, 22, 18, 9, 12, 3, 14]. Recently, there
have been efforts in studying variations of the blockchain protocol and to analyze the impact in
terms of mining incentives [5, 20].

2 Preliminaries: The Mining Game

In this section we describe the model of the sequential game that is played by the miners in the
Blockchain protocol. This model was already implicit in [8] and it is fully described in [11]. We
consider a sequential game of N players called miners, each miner having a computing capacity.
We assume that the computing capacity remains constant during the game and that players stay
in the mining game if it is proﬁtable for them. That is, we do not consider in-and-out strategies,
where some players might strategically stop mining for some turns to temporarily reduce the total
computing power of the game (this strategic behavior has been studied in [10]).

At each turn n, the blockchain is given by a public rooted directed tree of blocks T. Each block
B is labeled with i
, which is the player that wrote it. Miners are rewarded for writing
blocks. At each turn, each player i has a private tree Ti that might differ from T and a current
mining block Bi in Ti. Players are trying to solve a crypto-puzzle associated to their mining blocks,
in order to ﬁnd a key to attach (write) a new block.

1, . . . , N

∈ {

}

Deﬁnition 1. At each turn, we say that a player i
has won the mining race if he or she
is the ﬁrst one in solving the crypto-puzzle associated to his or her current mining block Bi. We suppose
that the mining race has only one winner almost surely, and we set pi to be the probability that player
i

is the one winning the mining race.

1, . . . , N

1, . . . , N

∈ {

}

∈ {

}

In practice, there is a delay between the ﬁnding of a new block and the communication to
all miners of this new block. If a second miner ﬁnds a block in this time window, then this
second block is considered as simultaneous. Here, however, we omit the possibility of multiple
players ﬁnding simultaneous blocks. The probabilities p1, p2, . . . , pN follow by modeling the time
needed to solve the crypto-puzzles as exponential random variables, depending on the ﬁxed
computational capacity of each player and the difﬁculty of the puzzle. The sequential game is
then played as follows:

Step 0. At the beginning of the game (n = 0), there is a public tree T of only one block. Each

player starts mining this block.

Step 1. A mining race is played.

Step 2. The player i

that has found a block adds it to his or her private tree, Ti, and
updates the current mining block to the new block found. Then, a revealing phase starts:

1, . . . , N

∈ {

}

Step 2.1: Each player i
elements in Ti \

∈ {
T to the public tree.

}

1, . . . , N

reveals part of its private tree to add some

Step 2.2: Every player updates the public tree. If the public tree is the same as before,

the reveal phase ends. If not, we go back to Step 2.1.

4

Step 3. Each player i

decides a (possibly new) block to mine, and updates its
current mining block Bi to the selected block. If the depth of T is less than a maximum
length Dmax, the game goes back to Step 1. Otherwise, the game ends.

1, . . . , N

∈ {

}

The mining game is said to be of immediate release if every player i
decides to reveal
his private tree at the revealing phase, that is, at the beginning of Step 3, Ti = T for every player
i
. In the following we deﬁne a particular type of “honest” strategy, corresponding to
a player immediately releasing any mined block and selecting one of the deepest nodes. This type
of strategy was studied by Kiayias et al. [11].

1, . . . , N

1, . . . , N

∈ {

∈ {

}

}

is playing the Frontier strategy if, at Step 3, he or she
Deﬁnition 2. We say that a player i
selects a leaf of the deepest level of the public tree T. If one of the leaves of the deepest level belongs to i, then
i selects that block.

1, . . . , N

∈ {

}

2.1 Payoff Functions

In order to deﬁne the objective functions, we need to understand how blocks become part of the
ofﬁcial blockchain. The blockchain protocol states that the ofﬁcial transaction history must be
the longest path in the public tree T, which is the chain with most proof-of-work (see [17, 23]).
However, when forks appear (due to strategic mining or simultaneous mining), there is an
ambiguity in the deﬁnition of the longest chain. Thus, users of the cryptocurrency consider a
block valid once this block has a certain amount of children in the tree. This delay on validation of
transactions contained in a block is the key element to prevent double spend-attacks. We formalize
this idea with the following deﬁnition.

Deﬁnition 3. A block B
mining game has maximum depth d
becomes validated.

∈

∈

∪ {

}

T is validated if all miners only select blocks that are descendants of B. A
if once a block B has a path of d descendants, then it

N

∞

In practice, there is not an ofﬁcial depth d in the cryptocurrency protocols. However, assuming
that miners are not seeking to perform double-spend attacks [21], an implicit maximum depth d is
considered, obtained consensually to prevent ambiguity in the transactions’ history. For example,
in the Bitcoin protocol, blocks are paid once a path of length d = 100 follows them, and it is a
reasonable maximum depth to consider. This simplifying hypothesis has been used before in [11].
In what follows we consider the following parameters in the game:

1. Dmax is considered as ∞. Each player i has a marginal cost ci ≥
2. Each block has a reward r > 0, which is collected by the player that owns it once the block
is validated. The marginal costs c1, c2, . . . , cN and the rewards are normalized so r = 1.

0 of mining per time unit.

For every positive integer n and player i, we denote by ri,n the number of blocks won by player
i that are validated at the end of turn n. We set distn to be the number of blocks that are validated
at the end of turn n, and τn to be the time length of turn n. We model the sequence (τn)n
N
∈
as independent identically (exponentially) distributed variables. This structure yields a natural
Ω0
probability space (Ω0,
1, . . . , N
N
∈
represents the outcomes of a sequence of mining races together with their time lengths, and
F0 is
the product σ-algebra (cid:78)
(R+) is the Borel σ-algebra. Then,
P0 is the unique probability measure satisfying that P0(ωn = i) = pi for every i
and
means that the player i won the mining race at turn n.
every positive integer n, where

F0, P0) where Ω0 = (
(

} ×
(R+)), where

, a sequence ω = (ωn, tn)n

R+)N

1, . . . , N

1, . . . , N

} × B

∈ {

P

ωn = i

B

}

{

{

N

∈

∈

n

{

}

5

With this probability space, the law of large numbers ensures that ∑n

τb almost
surely, where τb = E0(τ0). Thus, τb is the averaged time needed to ﬁnd a new block, which we set
to be the averaged time length of a turn. The blockchain protocol adjust the difﬁculty of mining a
new block periodically (see e.g. [23]) in such a way that a target average constant time per block
is obtained. We can model this property by assuming that
(cid:33)

1
k=0 τk/n
−

→

(cid:32)

E0

lim
∞
n
→

∑n
1
k=0 τk
−
1 + ∑n
1
k=0 distk
−

= τ,

(1)

where τ is a constant time called target (in Bitcoin, τ is set at 10 minutes). Strategic behavior
modify the distributions of (τn)n
N and the average time τb of mining a block, by inﬂuencing the
difﬁculty adjustment (see [10]). However, if strategic players maintain their strategies and do not
perform in-and-out attacks, it is reasonable to assume that the sequence (τn)n
N is identically
distributed and that τb remains constant.

∈

∈

Now, we are ready to present the possible objective functions for miners in the game. In this
work, we consider two possible objectives that players seek to maximize, both in the long term:
The expected revenue per turn and the expected ratio of validated blocks. More speciﬁcally, the
three criteria are the following:

(i) A player i maximizes the asymptotic revenue per turn Ri = lim
∞
→

n

E

1
n

(cid:32)n

1
∑
−
k=0

(cid:33)

ri,k −

ciτk

.

(ii) A player i maximizes the asymptotic ratio of validated blocks, that is,

E

Gi = lim
∞
n
→

(cid:32) ∑n
1
k=0 ri,k
−
1 + ∑n
1
k=0 distk
−

(cid:33)

,

with the additional constraint that Ri ≥
that the average costs per validated block become asymptotically constant, equal to ciτ.

0. Here the cost can be neglected since (1) ensures

The ﬁrst work considering selﬁsh mining [8] assumes that players try to maximize the ratio of
owned blocks in the ofﬁcial chain, that is, each player i is maximizing Gi (i.e. their market share).
This objective was also considered in other earlier inﬂuential work [11], and it has been generally
accepted as one of the natural payoff functions in the mining game. As we will see, the choice of
the objective function has a deep inﬂuence on the strategic behavior of the players. In a nutshell,
maximizing Gi might induce that players beneﬁt by diminishing the total number of available
blocks (i.e., reduce 1 + ∑n
k=0 distk), and it is not necessarily related to maximizing the revenues Ri.
−
The following proposition states that Frontier strategies are a Nash equilibrium when only two
players are trying to maximize Ri without difﬁculty adjustment. This result was already stated by
[10] and here we recall it to show the impact of the payoff function. Other studies of proﬁtability
including the impact of difﬁculty adjustment can be found in [2, 6].

1

Proposition 1 ([10, Theorem 4.4]). For N = 2, when both players try to maximize their asymptotic
expected revenue R1 and R2, Frontier strategy is a Nash equilibrium.

2.2 Discussion of the Model

In this work we aim to build the foundations for the study of fast convergence rates of long-term
payoff functions, as well as for the validity of truncated models. In particular, we aim to determine
how strategic mining can be performed under such regimes. The main assumptions of the model
we presented in this section are the following:

6

(A.1) The computational capacity of each agent is ﬁxed, and therefore so it is his or her probability

of winning a mining race. Dmax is very large, and can be assumed to be ∞.

(A.2) The reward of adding a block to the ofﬁcial blockchain is ﬁxed.

(A.3) There exists a maximum depth d, after which a block with d descendants becomes validated

by all miners.

(A.4) There is no simultaneous mining. All miners play with immediate release, that is, there is

no strategic revealing.

Assumptions (A.1)-(A.2) are related with time scales and allow us to validate the payoff
functions presented in Section 2.1. The ﬁrst two are quite standard and appear in several works
studying the mining game [11, 16]. Assumption (A.2) has been used in several studies, but it is
deﬁnitely more debatable. Again in the Bitcoin protocol, as in February 2021, mined blocks are
rewarded with r = 2.56 BTC. The classic blockchain protocol has a discount rate on the reward of
mining a block: in Bitcoin, it is reduced to the half every 210000 validated blocks, starting at 50
BTC. This reduction, which happens around every 4 years, will continue until the reward becomes
10−

8 BTC, and it is expected to happen in year 2140 (see [23]).
The reader can observe that, in order to safely consider assumptions (A.1)-(A.2), it is necessary
that the time horizon at which the assumptions are no longer valid must be large with respect to
the scale of time of the game (minutes). However, this requirement is not sufﬁcient, since these
assumptions are in competition with the convergence rate of the asymptotic payoff functions.
Indeed, if one aims to consider limit objective functions, which represent long-term goals, it is
also necessary that those limits are perceived within the scale of time where the assumptions are
valid. This fast convergence requirement is assured, through the lens of a Markovian approach,
by a fast mixing of the dynamics of the game, and it is studied in Subsection 4.1.

Assumption (A.3) is used to truncate the feasible states of the dynamics to a ﬁnite description.
As we already mentioned, this assumption is artiﬁcial in some sense, since it is not part of the
blockchain protocols. However, it simpliﬁes the study of the game, and even when it has been
used before, there is no validation, to the best of our knowledge, as a coherent approximation of
the real dynamic without this truncation. Based on the theory of Markov processes, we provide
a criteria to safely use the truncated model: The expected time needed to visit the states in the
boundary of the truncation must be exponentially large. We study this criterion in Subsection 4.2.
Assumption (A.4) is a simplifying condition, which we expect to overcome in subsequent work.

3 A Markov Model for a Mining Game with Two Players

In what follows, we focus our attention in a mining game under immediate release with two
players. When only one player (or colluded pool of players) is mining strategically, the honest
players can be reduced to only one that concentrates the computational power. This reduction has
been done previously in [8, 11] to study if Frontier strategy is an equilibrium. In this same line,
while immediate release is a simpliﬁed model, since strategic players hide information, as stated
in [11] and studied in [8, 16], it is a starting point to develop the theory of convergence rates.

Following the description of the mining game of Section 2 under the immediate release
assumption, every state of the 2-players game is given by the tuple (T, B1, B2), that is, the public
tree and the mining blocks of each player. By Deﬁnition 3, the only relevant information of T is
given by the subtree rooted at the last validated block. Assuming rationallity of both players, this
subtree has only two branches: The path mined by player 1 of depth (cid:96)1, and the path mined by

7

player 2 of depth (cid:96)2. Thus, (T, B1, B2) can be compactly represented by a pair ((cid:96)1, (cid:96)2) (see Fig. 1).
If one of the branches has a length strictly larger than d, it would mean that the ﬁrst block of this
branch has been validated. According to the truncated model, the other player must recognize this
block as valid, and so the root of the tree must be a descendant of this block. Therefore, all possible
states of the stochastic process are given by the integer pairs ((cid:96)1, (cid:96)2) such that 0
d. At
each turn, both players make a decision in Step 3, concerning which blocks to mine in order to
ﬁnd their new blocks. These decisions depend on two factors: the state ((cid:96)1, (cid:96)2) of the game at the
beginning of the turn, and the result of the mining race. Assuming rationality of both players,
there are possibilities: To continue the branch or to capitulate it.

(cid:96)1, (cid:96)2 ≤

≤

On the one hand, to continue the branch means to mine the deepest block. On the other hand,
to capitulate the branch means to select a block on the branch of the other player to restart the
mining process. See Figure 1 that represents a capitulation of player 1. When a player capitulates,
the state of the game is reset to (0, s1) if player 1 capitulates, or to state (s2, 0) if player 2 capitulates.
It is natural that for a given state ((cid:96)1, (cid:96)2) and as a result of the mining race, at most one of the
players capitulates (the one who loses the mining race). As Figure 1 shows, the value si with
, is the amount of blocks that player i will try to surpass after capitulation. We deﬁne a
i
round of the game as a set of transitions starting from one of the initial states (0, s1) and (s2, 0)
and a capitulation of one of the players. Players collect the rewards at the end of the rounds, and
only one player wins the round (has positive revenue), which is the one that does not capitulate.

∈ {

1, 2

}

Last validated block

(cid:96)1

B1

(cid:96)2

root

(cid:96)1

Capitulation of 1

2 won the mining race

B1

(cid:96)2

B1

new root

B2

B2

s1

B2

Figure 1: On the left, representation of the public tree T. The mining block of player 1, B1, must be the
last block in the left-side branch; the mining block of player 2, B2, must be the last block in the right-side
branch. On the right, capitulation of player 1. Player 2 won the mining race getting a branch of length
(cid:96)2 + 1. Player 1 validates (cid:96)2 + 1

s1 blocks of player 2; the new state is (0, s1).

−

This structure implies that each player takes part of a Markov Decision Process: At each turn,
the game will be at a state ((cid:96)1, (cid:96)2), and each player must decide if he will capitulate or not if he
loses the mining race. When both decisions are taken, only two possible new states are reachable
for the next turn: the one given by player 1 winning the mining race (with probability p1), and the
one given by player 2 winning the mining race (with probability p2). By the Markovian property,
for a state ((cid:96)1, (cid:96)2), each player should make the same decision each time the game passes through
that conﬁguration. Moreover, we take the values of s1 and s2 to be constant, both independent of
the previous state (i.e. each time that a player capitulates, the player capitulates to the same state).
Thus, the strategies for a player can be summarized as what we call capitulation policies.

Deﬁnition 4. A capitulation policy for a player i

1, 2

is a couple (C, s) such that the following holds:

(i) C :

0, . . . , d

} × {

0, . . . , d

} → {

0, 1

}

{

and s

∈ {

}
0, . . . , d

,

}

∈ {

8

(ii) If C((cid:96)1, (cid:96)2) = 0, it means that if a turn starts at state ((cid:96)1, (cid:96)2), player i continues to mine his or her

branch, regardless if he or she wins the mining race or not that turn.

(iii) If C((cid:96)1, (cid:96)2) = 1, it means that if a turn starts at state ((cid:96)1, (cid:96)2), player i continues to mine his or her
branch only if he or she wins the mining race at that turn, and he or she capitulates with si = s
otherwise.

3.1 Description of the Markov Chain

In what follows consider (C1, s1) and (C2, s2) two feasible ﬁxed capitulation policies, for player 1
and 2 respectively. Then, the Markov decision process previously described induces a Markov
chain (Xn)n
, which is
N, formally described as follows. The states of the chain are given by
the subset of all states ((cid:96)1, (cid:96)2) reachable from (0, s1) and (s2, 0). For any initial distribution µ over
R+)N
(
,
{
Ω, m stands for the initial state
N is the outcome of a sequence of mining races with their time lengths, and

, Pµ) where Ω =
× F0 and for every (m, ω)

, we consider the probability space (Ω,

M ×
∈

Ω0 =

M ×

} ×

1, 2

M

M

=

F

F

P

)

(

∈

P0, that is Pµ(X0 = m) = µ(m) (see Section 2 for the deﬁnition of (Ω0,

F0, P0)). For a

there are two outgoing transitions, which are given by the following four cases:

M
the measurable sets are
and ω = (ωn, tn)n
Pµ = µ
state ((cid:96)1, (cid:96)2)

×

∈

∈ M

Pµ(Xn+1 = ((cid:96)1, (cid:96)2 + 1)

(a) When C1((cid:96)1, (cid:96)2) = 0 and C2((cid:96)1, (cid:96)2) = 0, then Pµ(Xn+1 = ((cid:96)1 + 1, (cid:96)2)
Xn = ((cid:96)1, (cid:96)2)) = p2.
(b) When C1((cid:96)1, (cid:96)2) = 1 and C2((cid:96)1, (cid:96)2) = 0, then Pµ(Xn+1 = ((cid:96)1 + 1, (cid:96)2)

|

Pµ(Xn+1 = (0, s1)

Xn = ((cid:96)1, (cid:96)2)) = p2.

Xn = ((cid:96)1, (cid:96)2)) = p1 and

Xn = ((cid:96)1, (cid:96)2)) = p1 and

|

|

(c) When C1((cid:96)1, (cid:96)2) = 0 and C2((cid:96)1, (cid:96)2) = 1, then Pµ(Xn+1 = (s2, 0)

Pµ(Xn+1 = ((cid:96)1, (cid:96)2 + 1)

Xn = ((cid:96)1, (cid:96)2)) = p2.

(d) When C1((cid:96)1, (cid:96)2) = 1 and C2((cid:96)1, (cid:96)2) = 1, then Pµ(Xn+1 = (s2, 0)

|

|

Xn = ((cid:96)1, (cid:96)2)) = p1 and

Xn = ((cid:96)1, (cid:96)2)) = p1 and

|

|

Pµ(Xn+1 = (0, s1)
|
1, 2

For each player i
respect to the probability space (Ω,

∈ {

}

Xn = ((cid:96)1, (cid:96)2)) = p2.

, Pµ), that is,

, the expectations in the objective functions Ri and Gi are taken with

(cid:32) ∑n

1

F
k=0 ri,k −
n

−

Ri = lim
∞
n
→

Eµ

(cid:33)

ciτk

and Gi = lim
∞
→

n

Eµ

(cid:32) ∑n
1
k=0 ri,k
−
1 + ∑n
k=0 distk

(cid:33)

,

to emphasize the initial distribution whenever it is necessary. At turn n, the values of ri,n are
computed depending on the transition e = XnXn+1 from the state Xn to Xn+1. For each transition
((cid:96)(cid:48)1, (cid:96)(cid:48)2), the rewards of each player are the following: If ((cid:96)(cid:48)1, (cid:96)(cid:48)2) = (0, s1), then
(edge) e = ((cid:96)1, (cid:96)2)
s1. If ((cid:96)(cid:48)1, (cid:96)(cid:48)2) = (s2, 0), then r1(e) = (cid:96)1 + 1
s1 and r2(e) = 0. In any
r1(e) = 0 and r2(e) = (cid:96)2 + 1
N.
other case, r1(e) = r2(e) = 0. Then, ri,n = ri(XnXn+1) for each player i
and every n
1, 2
We denote by P the transition matrix of this chain, omitting the dependence on (C1, s1, C2, s2)
when there is no ambiguity. As usual, if the initial distribution µ is the delta distribution δm for
some state m

, we will simply write Pm and Em instead of P

−
∈ {

δm in this case.

δm and E

→

−

∈

}

Lemma 1. The chain (

, P) is irreducible and there is a unique stationary distribution πP.

∈ M

M

is either reachable from (0, s1) or (s2, 0). Furthermore,
Proof. By construction, each state of
, there is at least one path to arrive to (s2, 0), given by consecutive
for each state ((cid:96)1, (cid:96)2)
winnings of P1 of the mining races. Similarly, consecutive winnings of P2 form a path from ((cid:96)1, (cid:96)2)
to (0, s1). Thus, the chain is irreducible. Since the chain is ﬁnite, the existence and uniqueness of
the stationary distribution follows (see e.g. [15, Corollary 1.17]).

∈ M

M

9

For the chain (

M

, P) let us deﬁne the sets

∂1M
∂2M

=
=

m

m

{
{

∈ M
∈ M

: P(m, (s2, 0)) > 0
: P(m, (0, s1)) > 0

,

.

}
}

(2)

∈ M

for which C

corresponds to the states m

-dimensional vectors ˆr1 and ˆr2 as follows: ˆr1((cid:96)1, (cid:96)2) = p1((cid:96)1 + 1
∂2M

i(m) = 1, that is, the set of states for
The set ∂iM
which player i wins the current round after winning the current mining race. Let us deﬁne the
, and
−
|M|
ˆr1((cid:96)1, (cid:96)2) = 0 otherwise; ˆr2((cid:96)1, (cid:96)2) = p2((cid:96)2 + 1
, and ˆr2((cid:96)1, (cid:96)2) = 0 otherwise.
In principle, the values of the objective functions might depend on the initial distribution µ.
However, the ergodic theorem (see e.g. [19, Theorem 1.10.2]) suggest that regardless the initial
distribution, the values of Ri and Gi should depend only on the invariant distribution πP, for each
. The following proposition formalizes this notion. Given two vectors x, y with entries in
i

s2) if ((cid:96)1, (cid:96)2)

s1) if ((cid:96)1, (cid:96)2)

∂1M

1, 2

−

∈

∈

−

∈ {

}

, we denote by

x, y

M
Proposition 2. For the chain (
each i

, where

1, 2

(cid:105)

(cid:104)

= ∑a

∈ {

}

x(a)y(a) the inner product between x and y.

∈M

, P) and any initial distribution µ, we have that Gi =

πP, ˆri(cid:105)

(cid:104)

/ dist, for

M

dist = lim
∞
→

n

(cid:32)

1 +

1
n

Eµ

n
∑
k=1

(cid:33)

distk

.

(cid:104)

Furthermore, dist =

and Ri = dist(Gi −
πP, ˆr1 + ˆr2(cid:105)
Proof. Let E be the set of all edges of the chain (
Consider i
(Xn(m, ω)Xn+1(m, ω))
distribution ˜µ, where

and let (Zn)n

E. Then, the process (Zn)n

∈ {

1, 2

∈

}

∈

∈

(cid:104)

ciτ) =

ciτ dist for each i

πP, ˆri(cid:105) −
, P), that is, e = (m1m2)

∈ {
E if P(m1, m2) > 0.
, Pµ) given by Zn(m, ω) =
N is a Markov chain (E, Q) with initial

1, 2

F

∈

}

.

M
N be the stochastic process over (Ω,

˜µ(m1, m2) =

(cid:40)

µ(m1)
µ(m1)

p1
p2

·
·

if m2 follows after player 1 won the mining race,
if m2 follows after player 2 won the mining race.

The transition matrix Q over E is given as follows: For e = (m1m2) and e(cid:48) = (m(cid:48)1m(cid:48)2), if m2 = m(cid:48)1,
then Q(e, e(cid:48)) = P(m(cid:48)1, m(cid:48)2); otherwise, Q(e, e(cid:48)) = 0. We have that (E, Q) is also irreducible and ﬁnite
and therefore it has a unique stationary distribution πQ [15, Corollary 1.17]. Furthermore, for
each turn n, we have that ri,n = ri(Zn) and distn = r1(Zn) + r2(Zn). Since every ﬁnite irreducible
Markov chain is also positive recurrent (see e.g. [19, Theorem 1.7.7]) we can apply the ergodic
theorem [19, Theorem 1.10.2] obtaining that 1

f1,n =

f2,n =

1
n

1
n

(cid:32)

1
n

1 +

n
1
∑
−
k=0
n
1
∑
−
k=0

n
1
∑
−
k=0

r1(Zk)

r2(Zk)

Pµ
−→ (cid:104)

Pµ
−→ (cid:104)

πQ, r1(cid:105)

,

πQ, r2(cid:105)

,

(cid:33) Pµ

−→ (cid:104)

distk

πQ, r1 + r2(cid:105)

.

hn =

1A sequence of random variables (Yn)n

for every ε > 0 we have that limn

→

∞ P(

∈

Yn −

|

N converges in probability to a random variable Y, denoted by Yn

P

−→

Y, if

> ε) = 0.

Y

|

10

On the one hand, the total amount of mined blocks at turn n (validated or not) is n. On the
other hand, in the worst case scenario, there is at least one block that is validated every 2d turns.
Thus, we get that

(cid:107)

n
2d −
f1,n}n
The upper bound yields that
and therefore we have the convergence in expectation:2 Eµ( fi,n)
and Eµ(hn)
when n
converges in probability,3 that is

distk ≤
hn}n

πQ, r1 + r2(cid:105)

f2,n}n

N and

→ (cid:104)

(cid:106) n
2d

→

N,

≤

≤

n
1
∑
−
k=0

n.

{

1

∈

∈

∈

{
1, 2
}
→ (cid:104)
∞. Furthermore, we have that the ratio of the sequences

πQ, ri(cid:105)

for each i

∈ {

{

N are uniformly bounded by two

Finally, recalling that distk = r1(Zk) + r2(Zk), we have that fi,n/hn ≤
n, and therefore we have the convergence in expectation,

fi,n
hn

Pµ
−→

πQ, ri(cid:105)
(cid:104)
πQ, r1 + r2(cid:105)

.

(cid:104)

1 for every positive integer

Eµ

lim
∞
n
→

(cid:19)

(cid:18) fi,n
hn

πQ, ri(cid:105)
πQ, r1 + r2(cid:105)

= (cid:104)
(cid:104)
E we have that

,

∈

for each i

1, 2

}

∈ {

. For every e = (m1m2)

πQ(e) =

(cid:40)

πP(m1)
πP(m1)

p1
p2

·
·

if m2 follows after player 1 won the mining race,
if m2 follows after player 2 won the mining race.

Now, noting for e = (m1m2) we have that that r1(e) = 0, whenever m2 (cid:54)

= (s2, 0) we have that

πQ, r1(cid:105)

(cid:104)

πQ(m, (s2, 0))r1(m, (s2, 0))

πP(m)p1r1(m, (s2, 0)) = ∑

πP(m)ˆr1(m) =

m

∈M

πP, ˆr1(cid:105)

.

(cid:104)

= ∑
m
∈M
= ∑
m

∂1M

∈
=

Similarly, we get
that dist = limn

πQ, r2(cid:105)
(cid:104)
(cid:104)
(cid:104)
∞ Eµ(hn), that Gi = limn
→

πP, ˆr2(cid:105)

and

πQ, r1 + r2(cid:105)

=
πP, ˆr1 + ˆr2(cid:105)
(cid:104)
∞ Eµ( fi,n/hn) for each i
→
(cid:33)

. The proof is ﬁnished noting
, and writing

1, 2

∈ {

}

Ri = lim
∞
n
→

Eµ

(cid:32)

(cid:32)

fi,n −

1
n

n
1
∑
−
k=0

ciτk

Eµ

= lim
∞
n
→

fi,n −

cihn

(cid:33)

∑n
1
k=0 τk
−
1 + ∑n
1
k=0 distk
−
(cid:32)

= lim
∞
n
→

Eµ( fi,n)

E(hn)

ci

Eµ

·

−

∑n
1
k=0 τk
−
1 + ∑n
1
k=0 distk
−

(cid:33)

=

πP, ˆri(cid:105) −

(cid:104)

ciτ dist .

The formula Ri = dist(Gi −

ciτ) reﬂects the trade-off between Ri and Gi: While strategic
mining might increase the value of Gi above pi, it does that by reducing dist (which is always
pi (see the corollary
equal to 1 if both players play Frontier), and thus, since Gi ·
below) the true effect of strategic mining is not in the revenues per turn, but in the averaged costs.

πP, ˆri(cid:105) ≤

dist =

(cid:104)

2If we have a sequence of random variables (Yn)n

that

Yn| ≤

|

C for some C and every n

∈
N, then E(Yn)

E(Y).

→

∈

3If we have two sequences of positive random variables

Yn}n
N bounded away from zero, then

{

and Z respectively, with

Zn}n

{

∈

N and
{
Yn/Zn}n

∈
{

∈

N that converge in probability to Y

Zn}n
N converges in probability to Y/Z.

∈

N that converges in probability to a random variable Y and such

11

Corollary 1. Regardless the capitulation policies (C1, s1) and (C2, s2), one always has that
pi, for i
their asymptotic expected revenue, R1 and R2, then Frontier is a Nash equilibrium.

πP, ˆri(cid:105) ≤
. Therefore, if the normalized marginal costs ci are zero and both players try to maximize

∈ {

1, 2

}

(cid:104)

Proof. Let us assume that player 2 is playing Frontier. Regardless the capitulation policy (C1, s1)
of player 1, in the best case player 1 will get the reward of all the blocks that player 1 has mined,
and thus ∑n

. This yields that

∑n

1

−

k=0 r1,k ≤

1
k=0 1
−

ωk=1

}

{

R1 = lim
∞
→

n

E

1
n

(cid:32)n

1
∑
−
k=0

(cid:33)

r1,k

E

1
n

(cid:32)n

1
∑
−
k=0

≤

lim
∞
n
→

(cid:33)

1

{

ωk=1

}

= p1.

Since p1 is the value of R1 under Frontier, the conclusion follows.

The above corollary shows the impact of the selection in the payoff functions. Our result does
not, in principle, contradict the results obtained in [8, 11, 16], since they assume that players aim
to maximize the ratio of owned validated blocks, that is, Gi. However, when we look revenues,
Proposition 2 and Corollary 1 tell us that maximizing Gi is not necessarily optimal: informally, in
simple words, strategic players maximizing Gi get a bigger portion of a smaller cake. Furthermore,
the same proof of Corollary 1 is valid without the immediate release assumption, since it is based
on the fact that under strategic mining, it is not possible for a player to win more blocks than
those that the player has found, which is the payment when all players play Frontier.

4 Convergence Study for the Markov Chain

In what follows we suppose that the player 2 plays the Frontier strategy, that is, C2 = 1
(cid:96)2}
and s2 = 0. We denote s = s1 and C = C1 the capitulation policy for player 1. With this notation
we can describe the sets in (2) as ∂1M
.
}
is the set of states where the other player capitulates if player i wins the current
That is, ∂iM
mining race. We will call these states and the corresponding outgoing transitions, capitulation states
and transitions for player i. Any other state or transition is called interior. Assuming rationality of
players, it is natural to consider capitulation policies (C, s) satisfying the following:

and ∂2M

: C((cid:96)1, (cid:96)2) = 1

((cid:96)1,(cid:96)2):(cid:96)1≥

((cid:96)1, (cid:96)2)

∈ M}

∈ M

((cid:96), (cid:96))

=

=

{

{

{

When C((cid:96)1, (cid:96)2) = 0, we have that C((cid:96)1, (cid:96)(cid:48)2) = 0 for all (cid:96)(cid:48)2 ≤
The above implication tells us that if the strategic player is willing to continue the round at state
((cid:96)1, (cid:96)2), then he or she should be willing to continue the round for any other state ((cid:96)1, (cid:96)(cid:48)2) with
(cid:96)2, since those are more favorable states than ((cid:96)1, (cid:96)2). Thus, it is natural to introduce the
(cid:96)(cid:48)2 ≤
notion of gap tolerance, which should be the maximum value of (cid:96)2 satisfying that C((cid:96)1, (cid:96)2) = 0.

(cid:96)2.

(3)

Deﬁnition 5. For a capitulation policy (C, s) for player 1, we deﬁne the gap tolerance as the function
g :
. We deﬁne the maximum
} → {
}
gap tolerance as g = max(cid:96)1∈{

such that g((cid:96)1) = max
0,...,d

(cid:96)1 : C((cid:96)1, (cid:96)2) = 0

(cid:96)2 −

0, . . . , d

0, . . . , d

g((cid:96)1).

{

}

{

}

Note that we can always characterize the maximal gap tolerance by g = max((cid:96)1,(cid:96)2)

(cid:96)1),
where the inequality holds by the construction of the reachable states. In order to study the
Markov chain, it results useful to consider a lattice representation of (
, P). In this representation,
we represent the states of the Markov chain in the two dimensional integer lattice and we represent
the transitions as arrows. See Figure 2 for an example.

((cid:96)2 −

M

∈M

If we have a state ((cid:96)1, (cid:96)2)

∂2M
,
we identify ((cid:96)1, (cid:96)2 + 1) with (0, s). Observe that, regardless the capitulation policy of player 1,

, we identify ((cid:96)1 + 1, (cid:96)2) with (0, 0). If we have ((cid:96)1, (cid:96)2)

∂1M

∈

∈

12

Figure 2: Lattice representation of our Markov chain. Blue dots and arrows correspond to capitulation states
and transitions for player 1 and green ones, for player 2. Black arrows correspond to interior transitions.

one has that the induced Markov chain is aperiodic, since Pn((0, 0), (0, 0))
pn
1 > 0, for every
positive integer n. Thus, the classic convergence theorem (see e.g. [15, Theorem 4.9]) implies that
πP(cid:107)
maxm
TV is the total variation norm of measures. Together
with Proposition 2, this yields that, in the long run, the behavior of the mining game can be fully
described by the stationary distribution πP.

0, where

Pn(m,

∈M (cid:107)

(cid:107) · (cid:107)

→

−

≥

TV

)

·

4.1 Mixing Time of the Markov Chain

For the policy (C, s), we are interested in estimating how much time do we need in order
to observe the objective values considered, R1 the expected revenue, and G1 the expected
ratio of validated blocks. As a benchmark, we consider the mixing time of the induced
, P). Recall that the mixing time for a tolerance ε > 0 is given by tmix(ε) =
Markov chain (
. In what follows we provide a bound for tmix(ε)
min
·
in terms of the maximum gap tolerance supported by player 1.

N : maxm

Pn(m,

πP(cid:107)

∈M (cid:107)

M

−

≤

TV

∈

n

{

}

)

ε

Theorem 1. Let (C, s) be the capitulation policy of 1 and let (
the player 2 plays Frontier. Then, for every ε

M
(0, 1), we have that

, P) the associated Markov chain when

∈


tmix(ε)

≤






(cid:16)

ln

ln(ε)

pg+1
1

1

−








(cid:17)

(g + 1).

Proof. Choose any two states x, y
N be a sequence of independent Bernoulli
trials of parameter p1. If Zn is a success, it represents that player 1 has won the n-th mining race.
Let (An, Bn)n

N be the stochastic process with values in

and let (Zn)n

given by

∈ M

∈

M × M

∈
δx,

1. A0 ∼
2. B0 ∼
3. An+1 = An + (Zn, 1

δy,

Zn) and Bn+1 = Bn + (Zn, 1

Zn).

−

−

13

•••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••◦s•◦0•ddFollowing the notation of [15, Chapter 5], we will consider Px,y as the probability measure over a
space where the random variables An, Bn and Zn are deﬁned, and satisfying that A0 ∼
δy
B(p1). By construction, for every states ((cid:96)1, (cid:96)2), ((cid:96)(cid:48)1, (cid:96)(cid:48)2), ((cid:96)(cid:48)(cid:48)1 , (cid:96)(cid:48)(cid:48)2 )
and Zn ∼

δx, B0 ∼

we have that

∈ M

Px,y(An+1 = ((cid:96)(cid:48)(cid:48)1 , (cid:96)(cid:48)(cid:48)2 )
Px,y(Bn+1 = ((cid:96)(cid:48)(cid:48)1 , (cid:96)(cid:48)(cid:48)2 )

|
|

An = ((cid:96)1, (cid:96)2), Bn = ((cid:96)(cid:48)1, (cid:96)(cid:48)2)) = P(((cid:96)1, (cid:96)2), ((cid:96)(cid:48)(cid:48)1 , (cid:96)(cid:48)(cid:48)2 )),
An = ((cid:96)1, (cid:96)2), Bn = ((cid:96)(cid:48)1, (cid:96)(cid:48)2)) = P(((cid:96)(cid:48)1, (cid:96)(cid:48)2), ((cid:96)(cid:48)(cid:48)1 , (cid:96)(cid:48)(cid:48)2 )).

This yields that (An, Bn) is a coupling for the Markov chain (
, P), satisfying that An = Bn
n. Intuitively, for each transition n to n + 1, either both processes
implies Ak = Bk for every k
An and Bn move up or both processes move to the right in the lattice representation of Figure 2.
Let Tc be the coalescence time of the coupling, that is, Tc = min
. Note that, for
any turn n, and any state ((cid:96)1, (cid:96)2)

N : An = Bn}

, we have that

M

≥

∈

n

{

∈ M
Px,y(An+g+1 = (0, 0)
Px,y(Bn+g+1 = (0, 0)

|
|

An = ((cid:96)1, (cid:96)2), Zn = 1, . . . , Zn+g = 1) = 1,
An = ((cid:96)1, (cid:96)2), Zn = 1, . . . , Zn+g = 1) = 1.

≤

∈ M

(cid:96)2 −

, then 0

(cid:96)1 ≤
(cid:96)1 = g, it means that after g consecutive wins of player 1, the chain is at ((cid:96)2, (cid:96)2)

The above equations follow from the fact that if ((cid:96)1, (cid:96)2)
g. Thus, after
g + 1 consecutive winnings of player 1, the state must be (0, 0). Indeed, on the one hand, if
(cid:96)2 −
, and
thus, after one more win of player 1, the chain goes to (0, 0). On the other hand, if the chain goes
back to (0, 0) before the g + 1 consecutive wins, each win of player 1 maintains the chain at (0, 0).
1) contains
g + 1 consecutive successes. Then, we have that Px,y(Sn)
n). While Sn is a well-known
event in the literature, it is hard to explicitly estimate its probability. Thus, we will provide a
simpler lower bound for it. Let Uk be the event given by Zk(g+1) = 1, . . . , Z(k+1)(g+1)
1 = 1. We
have Px,y(Uk) = pg+1
N is independent. Furthermore, we
have that

For every positive integer n, consider the event Sn where the sequence (Z0, . . . , Zn

N and the sequence (Uk)k

Px,y(Tc ≤

for each k

∂1M

≤

∈

∈

−

−

∈

1

Px,y(Tc ≤

n(g + 1))

≥

(cid:16)

Px,y

Sn(g+1)

(cid:17)

Px,y

≥



Uj

 = 1





n
1
(cid:91)
−

j=0

(cid:16)

1

−

−

pg+1
1

(cid:17)n

.

We deduce that Px,y(Tc > n(g + 1))
ε if and only if n

ln(ε)/ ln(1

pg+1
1

)n. On the other hand, we have that (1

(1
−
), and then we conclude that Px,y(Tc > n(g + 1))

−

pg+1
1

)n
ε, for

≤

≤

≤
pg+1
1

−

≥

(cid:38)

n =

(cid:39)

ln(ε)

ln(1

−

pg+1
1

)

and so by [15, Corollary 5.5], we deduce that tmix(ε)

n(g + 1), ﬁnishing the proof.

≤

As a direct corollary from Theorem 1, when the time horizon T and the total variation tolerance
ε are given, we can provide a lower bound on p1 in terms of these parameters and the maximum
gap tolerance g.

Corollary 2. For every ε > 0 and T > 0, we have tmix(ε)

T when p1 ≥ (cid:101)p1 =

≤

g+1
(g+1)

−

T

ε

(cid:17) 1
g+1

.

(cid:16)

1

−

For instance, for ε = 10−

104, that is, about 70 days, if the average time of a mining
race is 10 minutes, we get the values of (cid:101)p1 as in Table 1 and Figure 3. The inverse problem of
determining (cid:101)g, for a given p1, such that any capitulation policy with maximum gap tolerance

3 and T

≤

14

g
(cid:101)p1

1
0.037

2
0.127

3
0.229

4
0.322

5
0.401

6
0.467

7
0.522

8
0.569

9
0.609

10
0.642

Table 1: Examples of rapid mixing strategies for ε = 10−
maximum gap tolerance g, the associated chain satisﬁes tmix(ε) < T whenever p1 ≥ (cid:101)p1.

3 and T = 104. For any (C, s) with the given

. For any (C, s)
Figure 3: On the left, rapid mixing strategies for ε = 10−
with the given maximum gap tolerance ¯g, the associated Markov chain mixes rapidly (that is, tmix(ε) < T)
3 and T = 104. For a given p1, the
whenever p1 ≥ (cid:101)p1. On the right, rapid mixing strategies for ε = 10−
associated chain mixes rapidly whenever g < (cid:101)g.

3 and T = 104 with ¯g

1, . . . , 20

∈ {

}

g
≤ (cid:101)g exhibits fast mixing, can be easily read from the previous analysis, since our upper bound
for tmix(ε) is increasing in g (see Figure 3). In the following theorem, we show the existence of
a capitulation policy for which the mixing time of the associated Markov chain is exponentially
large as a function of d.

Theorem 2. There exists a capitulation policy for player 1 for which the associated Markov chain has a
mixing time of at least 1

4 (5/4)d.

Proof. Consider the capitulation policy (C, s) for player 1 given as follows: s = d, C((cid:96)1, (cid:96)2) = 1
if (cid:96)2 = d, and zero otherwise. We denote by π the stationary distribution of the associated
Markov chain (
. In what
1
⊆ M
M
−
follows we denote π(S) = ∑((cid:96)1,(cid:96)2)
S Pt((0, d), ((cid:96)1, (cid:96)2)). Then,
∈
observe that for any positive integer t we have

a subset of states given by S =
S π((cid:96)1, (cid:96)2) and Pt((0, d), S) = ∑((cid:96)1,(cid:96)2)

((cid:96)1, (cid:96)2) : (cid:96)2 ≤

, P). Let S

{

}

d

∈

Pt((0, d),

(cid:107)

)

·

π

(cid:107)

−

TV

π(S)
≥
= π(S)
π(S)
≥
= π(S)

= π(S)

−
−
−
−

−

S

Pt((0, d), S)
P(Xt ∈
|
P(X1 ∈
S
P(τ(0,d)(S)
≤
P(τ(0,d)(0, 0)

X0 = (0, d))
Xt ∈

∨ · · · ∨

t)

t),

≤

X0 = (0, d))

S

|

where τ(0,d)(S) and τ(0,d)(0, 0) denote the hitting times of S and (0, 0) starting from (0, d), respec-
t if and only if there is a sequence of d + 1 consecutive winnings
tively. Furthermore, τ(0,d)(0, 0)
for player 1 within the t turns. For every i
, let Ai be the event in which
1
∈ {
player 1 wins consecutively from turn i to turn i + d. Thus, by the union bound we have that

0, 1, . . . , t

≤

−

−

}

d

P(τ(0,d)(0, 0)

t) = P

≤

(cid:32)t

1

d
(cid:91)
−
−

(cid:33)

Ai

i=0

1

t

d
∑
−
−
i=0

≤

P(Ai) = (t

d)pd+1,

−

15

0g0p1201.....................˜p10p10g140˜gwhere p is the probability that player 1 is winning the mining race. In particular, by setting
t = tmix(ε), we have that ε

d)pd+1 and therefore

(tmix(ε)

π(S)

≥

−

−
π(S)

−
pd+1

tmix(ε)

≥

ε

+ d

π(S)
pd

ε

.

−

≥

Similarly, we have that

Pt((0, 0),

)

·

(cid:107)

π

TV

π(Sc)

Pt((0, 0), Sc)

π(Sc)

P(τ(0,0)(Sc)

t).

(cid:107)

≥

−

≥

≤

−
t if and only if there is a sequence of d + z turns with z

We have that τ(0,0)(Sc)
d within the t
turns starting from (0, 0) such that the following holds: i) Player 2 wins d mining races, ii) player 1
wins z mining races and iii) there is no sub-sequence where player 1 has more wins than player 2.
For any such pair (d, z), let Bd,z the event in which the previous three conditions hold and let Cd,z
be the event in which only conditions i) and ii) hold. Let us denote by Bs the event in which there
is a sequence of d + z turns with z
d. In
d
1
particular, we have that Bs =
i=0 Bd,z. Then, we have that
−

d within the t turns starting from (0, 0) at turn s

−

≤

≤

−

≤

≤

t

∪
d
1
∑
−
z=0

≤

P(Bs)

P(Bd,z)

d
1
∑
−
z=0

≤

P(Cd,z) =

d
1
∑
−
z=0

(cid:19)

(cid:18)d + z
z

qd pz,

Now, using the hockey-stick identity, we have that

P(Bs)

≤

≤

qd pz

(cid:19)

(cid:19)

(cid:18)d + z
z
(cid:18)d + z
z
(cid:19)

d
1
∑
−
z=0
d
1
∑
−
z=0
(cid:18) 2d
d

qd

2d(2d

= qd

2
−
1
−
where C(n) is the n-th Catalan number, which is bounded from above by 4n. Therefore, we have
that

−
d + 1

−
d + 1

qdC(d

qd4d,

1
d

qd

1)

=

−

≤

−

=

1

·

2d(2d

d2
d + 1

1)

1)

(cid:18)2d
d

(cid:19)

P(τ(0,0)(Sc)

t) = P

≤

(cid:32)t

d
(cid:91)
−

(cid:33)

Bs

s=0

t
d
∑
−
s=0

≤

P(Bs)

t
d
∑
−
s=0

d2
d + 1

≤

qd4d

(t

−

≤

d + 1)

d2
d + 1

qd4d.

Thus, by setting t = tmix(ε) we conclude that

π(Sc)

ε

≥

−

(tmix(ε)

d + 1)

−

d2
d + 1

qd4d,

which we can rewrite as

tmix(ε)

d + 1
d2

≥

(π(Sc)

−
(4q)d

ε)

+ d

1

−

≥

π(Sc)

−
(4q)d

ε

.

Since π(S) + π(Sc) = 1, one of these values has to be greater than 1/2 and therefore by taking
ε = 1/4, p = 4/5 and q = 1

p = 1/5, we deduce that

−

tmix(1/4)

(cid:18) 5
4

1
4

(cid:19)d

.

≥

16

4.2 Hitting Time of the State (d, d)

In this section, we are interested to know whether, for a given strategy of player 1, the truncated
model with maximum depth d is reliable or not. In our model, parallel blocks can not be both
validated, since whenever a player mines a path of d + 1 blocks, the other one is forced to capitulate.
If the strategic player actually faces the situation of potentially parallel validated blocks, he or
she might not capitulate due to the high losses of doing so. This undesirable situation arises only
when the Markov chain is at (d, d).

Ideally, strategic miners should have capitulation policies for which the state (d, d) is unreach-
able. However, as we can see in the lattice representation of Figure 2, this is not the case in general.
We propose an alternative criterion, which considers the hitting time of the state (d, d). If the
hitting time of this state is very large (i.e. beyond human scale), the associated strategy can be
safely played in the truncated model.

For example, if the average time τb of a mining race is 5 minutes, a time horizon of T = 108
corresponds to about a millennia. Therefore, any capitulation strategy for which the hitting time
of (d, d) is greater that T, can be considered as safe. For the Bitcoin time scale of 100 years, T = 108
means that the complete sequential game must be played about 10 times before (d, d) is hit. On
the other hand, a time horizon of T = 104 corresponds to about one month, and clearly they
should be considered as unsafe. We show that, under certain conditions, unsafe strategies exist for
5 minutes follows from the fact that τb = dist τ (which is
this time horizon. The benchmark τb ≥
easily deduced from Proposition 2) and that in the examples we provide next, dist

1/2.

{

n

∈

to

T
(d, d)

N : Xn = (d, d)

Formally, when the chain starts at state (0, 0), the hitting time of the state (d, d) corresponds
(d, d) = E(min
). We say that a capitulation policy is safe for T > 0 if
T. Recall that a round of the game is a set of transitions from a capitulation transition
T
(or the beginning of the game) to the next capitulation transition. The length of a round, that is,
the number of transitions between two capitulation transitions, is bounded above by 2d, which is
the number of interior transitions needed to go from (0, 0) to (d, d). Thus, if
is the number of
rounds before hitting (d, d) for the ﬁrst time, we have

R

≥

}

≥

≤ T
Then, up to a constant factor of d, studying

R

E(

)

E(

2d

(d, d)
(d, d) can be reduced to estimating the value E(

R

≤

).

·

).

R
Proposition 3. Let N((cid:96)1, (cid:96)2) be the number of interior lattice paths from ((cid:96)1, (cid:96)2) to (d, d) in the lattice
representation of (

, P). Then

T

M

1 pd+s
Proof. In the n-th round, the probability of hitting (d, d) is given by

2 ≤

R

≤

2

N(0, s)p2s
2
1 pd
N(0, 0)2 pd

E(

)

N(0, 0)
N(0, s)2 pd

.

(cid:40)

ρn =

νn(0, 0)N(0, 0)pd
νn(0, 0)N(0, 0)pd

1 pd
1 pd
2

2 + νn(0, s)N(0, s)pd

1 pd

2

s

−

if s > 0,
if s = 0,

where νn((cid:96)1, (cid:96)2) is the probability that the round starts at ((cid:96)1, (cid:96)2). In particular, we have 1 =
νn(0, 0) + νn(0, s) if s > 0 and νn(0, 0) if s = 0. We have that N(0, s)
N(0, 0), since for every
path γ from (0, s) to (d, d), there is a path from (0, 0) to (d, d) consisting in the vertical path from
(0, 0) to (0, s) and then γ. Then, we have that

≤

ρn ≤

N(0, 0)

≤

(cid:16)

νn(0, 0)pd
1 pd
2

−

s

1 pd

2 + νn(0, s)pd

1 pd
2

(cid:17)

s

−

N(0, 0)pd

(νn(0, s) + νn(0, s)) = N(0, 0)pd

1 pd
2

s

.

−

17

Similarly, we have that ρn ≥
needed to hit (d, d) is equal to

N(0, s)pd

1 pd

2. On the other hand, the expected number of rounds

E(

R

) =

∞
∑
n=1

nρn

n
1
∏
−
k=1

(1

−

ρk),

and therefore we can upper bound the value E(

) by

E(

)

R

≤

∞
∑
n=1

nN(0, 0)pd

1 pd
2

s

−

(cid:32)

= N(0, 0)pd

1 pd
2

s

−

R
(cid:16)

1

−

N(0, s)pd

1 pd
2

(cid:17)n

1

−

(cid:33)2

1
N(0, s)pd

1 pd
2
) to get E(

=

)

R

.

N(0, 0)
N(0, s)2 pd

1 pd+s
N(0, s)p2s

2

Similarly, we can lower bound the value of E(

R

Note that when s = 0 we get that the expected value of

2 /(N(0, 0)2 pd

1 pd

2).

≥
is exactly given by 1/N(0, 0)pd

1 pd
2.
s))
−
0). Therefore, using Proposition 3, we get directly the

d attains its minimum at p1 = d/(2(d

2 (p1 p2)−

R

Furthermore, when s < d/2, the function p2s
(subject to p1 + p2 = 1 and p1, p2 ≥
following lower bound on E(

).

R

Corollary 3. For s < d/2, we get that E(

)

R

≥

N(0, s)
N(0, 0)2 4d

−

s (d
−
dd(d

s)2(d
−
2s)d

s)
2s .

−

−

Recall that the maximum gap tolerance is given by g = max((cid:96)1,(cid:96)2)

maximum is necessarily attained in ∂2M
We say that a capitulation policy (C, s) has constant gap tolerance g
(cid:96)

0, . . . , d

(cid:96)1). Note that the
, that is, at some state ((cid:96)1, (cid:96)2) such that C((cid:96)1, (cid:96)2) = 1.
, if g((cid:96)) = g for all

((cid:96)2 −
1, . . . , d

∈M

. We consider the following proposition borrowed from the integer lattice theory.

∈ {

}

Proposition 4 ([13, Theorem 10.3.3]). Let (C, s) be a capitulation policy with constant gap tolerance
g

. Then, we have that

1, . . . , d

∈ {

∈ {

}

}

N(0, 0) = ∑

Z

k

∈
N(0, s) = ∑

Z

k

∈

(cid:18)(cid:18)

−

d
(cid:18)(cid:18) 2d
d

−

2d
k(g + 2)

s
k(g + 2)

−

(cid:19)

(cid:18)

−

(cid:19)

(cid:18)

−

d

d

−

s

−

−

2d

k(g + 2) + g + 1

(cid:19)(cid:19)

,

s

2d
k(g + 2) + g + 1

−

(cid:19)(cid:19)

.

Thanks to Proposition 4, we obtain the following corollary.

Corollary 4. For d = 100 and a tolerance of T = 108 we have that constant gap tolerance strategies are
safe for 0

(0, 1).

g

s

≤

≤

4, for any p1 ∈

≤

In fact, for d = 100, there are additional cases, namely, g = 5 and s

3, or (g, s) = (6, 0), that
also deﬁne safe strategies. Moreover, it is possible to determine several safe strategies for p1 in a
given range as shown in Table 2. The examples shown are not extensive as for each one of the
ranges for p1 in Table 2, it is possible to take higher values for s (higher than smax in Table 2) for
some smaller values of g (smaller than gmax in Table 2). We can also exhibit examples of strategies
(d, d) is small, namely, less than
which are unsafe, that is, capitulation policies such that the
T = 104 (about one month under τb = 5 minutes). Since
), by Proposition 3,
we get

T
(d, d)

E(

2d

R

≤

≤

T

·

(d, d)

2d

≤

T

N(0, 0)
N(0, s)2 pd

1 pd+s

2

.

18

Together with Proposition 4, we can determine several unsafe strategies for a given p1 as shown in
Table 3. We remark that for s
2, our methods are not accurate enough in order to detect possible
unsafe strategies in that case.

≥

p1 ≤
0.45

gmax
5

smax
3

p1 ≥
0.65

gmax
9

smax
1

0.40

0.33

0.30

0.25

0.20

0.10

0.05

5

d

d

d

d

d

d

5

1

5

14

30

77

d

0.60

0.66

0.70

0.75

0.80

0.90

0.95

6

d

d

d

d

d

d

2

0

2

5

9

17

23

Table 2: Examples of safe strategies for d = 100 and T = 108. For p1 in a given range, (s, g) is safe for every
g

min

gmax and s

.

≤

≤

g, smax}

{

p1

0.43

s = 0
s = 1

gmin
gmin

−
−

0.44
19

−

0.45
16
21

0.46
14
17

0.47
14
16

0.48–0.52
13
15

0.53
14
16

0.54
14
19

0.55
16

0.56
19

−

−

0.57

−
−

Table 3: Examples of unsafe strategies for d = 100 and T = 104. For the given values of p1 and s, (s, g) is
unsafe for every g

gmin.

≥

5 A Market Share Case Study

In what follows we analyse a family of capitulation regimes through the lens of the objective
functions Ri and Gi deﬁned in Section 2.1. More precisely, we do this for the family of capitulation
policies with constant gap tolerance g
g, which means
that, in practice, we consider d = ∞. By Proposition 2, we have that

1 and s = 0. We further assume that d

(cid:29)

≥

Ri =

π, ˆri(cid:105) −

(cid:104)

ciτ

πP, ˆr1 + ˆr2(cid:105)

(cid:104)

and Gi =

(cid:104)

π, ˆri(cid:105)
πP, ˆr1 + ˆr2(cid:105)

,

(cid:104)

where π = πP is the corresponding stationary distribution. Thus, our analysis can be reduced to
the computation of ρi =

. In particular, we have

πP, ˆri(cid:105)

(cid:104)

Ri = ρi −

ciτ(ρ1 + ρ2) and Gi =

ρi
ρ1 + ρ2

(4)

1, 2

for each i
. In order to compute explicitly the values of the objective functions Ri and
Gi, we compute the values ρi, that are completely determined by the corresponding stationary
distributions. To this end, we use a lattice path enumeration approach (see [13] for a survey).

∈ {

}

In the stationary distribution, the value at any state of the Markov chain can be described as a
linear combination of the value of πP at incoming states. Thus, πP((cid:96)1, (cid:96)2) is a linear combination of

19

the number of interior lattice paths from (0, 0) and (0, s) to ((cid:96)1, (cid:96)2), weighted by the corresponding
probabilities of such paths to occur. Recall that in capitulation policies of constant gap tolerance
1 with ﬁxed s = 0, player 1 capitulates every time that player 2 has mined g blocks more
g
=
, and the
than 1. Thus, the Markov chain has states
{
and ∂2M
capitulation states are ∂1M
. See in Figure 4
the corresponding representation.

((cid:96), (cid:96)), ((cid:96), (cid:96) + k) : (cid:96), k
((cid:96), (cid:96) + g) : (cid:96)

N, k
N

((cid:96), (cid:96)) : (cid:96)

M
}

∈
∈

N

=

≥

≤

=

∈

{

}

}

{

g

Figure 4: Lattice representation of a Markov chain of constant gap tolerance g = 3, s = 0 and d = ∞.

When d = ∞, the states used to describe the game might be inﬁnitely many. In this case,
, P) with inﬁnitely many states as well.
the capitulation policies might induce Markov chains (
While the chain (
, P) keeps irreducible by construction, the ergodicity property described
in Proposition 2 does not apply directly, since the existence of a stationary distribution is not
guaranteed. However, the following proposition allow us to replicate the results of Proposition 2
if both players have bounded gap tolerance functions.

M

M

Proposition 5. Let (C1, s1) and (C2, s2) be two capitulation policies for a mining game with depth
d = ∞. Suppose that both players have bounded gap tolerance, that is, there exists g such that for every
((cid:96)1, (cid:96)2)
(cid:96)1 ≥
g,
we have C1((cid:96)1, (cid:96)2) = 1. Then, the induced Markov chain (
, P) is positive recurrent, which yields that
the conclusions of Lemma 1 and Proposition 2 hold.

g, we have C2((cid:96)1, (cid:96)2) = 1, and when (cid:96)1 −

N the following holds: When (cid:96)2 −

(cid:96)2 ≥

M

N

×

∈

Proof. Since (
M
least one state m
∈ M
be its ﬁrst passage time, that is, T = inf
positive recurrent if Ex(T) < ∞. Deﬁne the random variables (Zn)n
deﬁnition of this probability space at Section 3.1) as

, P) is irreducible, it is sufﬁcient, according to [19, Theorem 1.7.7], to show that at
is positive recurrent. Let us consider the initial state x = (s2, 0), and let T
. Recall that (s2, 0) is said to be
, Px) (see the

1 : Xn = (s2, 0)

N over (Ω,

≥

F

n

{

}

∈

namely, Zn = 1 if player 1 won the mining race at turn n. Observe that, for any state ((cid:96)1, (cid:96)2)
,
∈ M
in order to pass by (s2, 0) it is enough for player 1 to have 2g + 1 consecutive wins of the mining

Zn(m, ω) = 1

(m, ω),

ωn=1

}

{

20

••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••◦0◦•races. Let us deﬁne the random variables (Uk)k

N as

∈

Uk =

2g
∏
i=0

Z(2g+1)k+i.

∈

, and when Uk(m, ω) = 1 we have that T(m, ω)

We have that (Uk)k
q = p2g+1
1
the stopping time Tseq = inf
can write T(m, ω)
distribution of parameter q, we conclude that

N are independent, that Uk follows a Bernoulli distribution of parameter
(2g + 1)(k + 1). Then, we can deﬁne
, and in view of the previous implication, we
(2g + 1)(Tseq(m, ω) + 1). Thus, by noting that Tseq follows a geometric

N : Uk = 1

≤

≤

∈

{

}

k

Ex(T)

≤

(2g + 1)(Ex(Tseq) + 1) < ∞,

and therefore x = (s2, 0) is positive recurrent as we wanted to. Then, the conclusions follow by
[19, Theorem 1.7.7] and [19, Theorem 1.10.2].

Let L((cid:96)1, (cid:96)2) be the number of interior lattice paths from (0, 0) to ((cid:96)1, (cid:96)2). We have π((cid:96)1, (cid:96)2) =
. By [13, Theorem 10.3.4], the number of
(x, x) : x
and below

π(0, 0)L((cid:96)1, (cid:96)2)p(cid:96)1
lattice paths from (0, 0) to ((cid:96), (cid:96) + m) that are (weakly) above the line
, is given by
the line

2 , where (cid:96)2 ∈ {
R

(cid:96)1, (cid:96)1 + 1, . . . , (cid:96)1 + g

(x, x + g) : x

1 p(cid:96)2

R

∈

}

}

{

{

∈

}

L((cid:96), (cid:96) + m) =

2
g + 2

g+1
∑
k=1

sin

(cid:19)

(cid:18) πk
g + 2

(cid:18) πk(m + 1)
g + 2

sin

·

(cid:19)

(cid:18)

2 cos

·

(cid:18) πk
g + 2

(cid:19)(cid:19)2(cid:96)+m

.

(5)

In the following proposition we summarize the exact values obtained for ρ1 and ρ2.

Proposition 6. Consider the capitulation policies with constant gap tolerance g
and let ρi =

. Then, we have

for each i

1, 2

1, s = 0 and d = ∞,

≥

(cid:104)

πP, ˆri(cid:105)
p1
Γ

g+1
∑
k=1
pg+1
2
Γ

ρ1 =

ρ2 =

∈ {
sin2( πk

}
g+2 )

(1

−

g+1
∑
k=1

(

−

4p1 p2 cos2( πk
sin2( πk

1)k

−

1

, and

g+2 ))2
g+2 )(2 cos( πk
4p1 p2 cos2( πk

g+2 ))g
g+2 ))2

(1

−

(cid:18)

(cid:18)

g

1

4p1 p2 cos2

−

(cid:18) πk
g + 2

(cid:19)(cid:19)

(cid:19)

+ 1

,

where Γ = ∑g+1

k=1 sin

(cid:17)

(cid:16) πk
g+2

∑g

m=0 sin

(cid:16) πk(m+1)
g+2

(cid:17) 2m cosm(cid:16) πk
g+2
(cid:16) πk
4 cos2
g+2

1

(cid:17)

(cid:17)

pm
2

p1 p2

−

.

1, 2

∈ {

The proof of Proposition 6 can be found in the Appendix. By February 2021, the value of 1 BTC
was close to 47000 USD 4 and the social energy consumption per year for Bitcoin mining has been
estimated in 77.78 TWh per year.5 Assuming the hash power of a player to be proportional to the
energy consumption, and that the price of a kWh is 0.01 USD, we estimate the marginal costs of
0.005pi [units/min].
(77.78
each i
When both players try to maximize their asymptotic expected revenue neglecting their costs,
by Corollary 1, Frontier is a Nash equilibrium. However, under Frontier regimes, we have that
τb = τ = 10 min and thus, the average cost of player i becomes ciτb ≈
0.05pi units per turn, which
is the 5% of the average reward pi. Thus, the question of proﬁtability of selﬁsh mining is deﬁnitely
relevant and it has already been addressed by different authors (see e.g. [2, 6]). The estimation of
ci is rough, and we simply provide it to illustrate the ideas of this section.

as ci ≈

109)/(365

0.01/(6.25

pi ≈

104)

60)

4.7

24

×

×

}

·

·

·

·

·

21

Figure 5: R1 (left) and R2 (right) as a function of p1 and p2, respectively, with g

1, 3, . . . , 49

}

∈ {

and s = 0.

Figure 6: G1 (left) and G2 (right) as a function of p1 and p2, respectively, with g

1, 3, . . . , 49

}

∈ {

and s = 0.

When everybody plays Frontier strategy, there is only one state, namely (0, 0), and we have
ρi = pi for each player. In this scenario, we get Ri = 0.95pi and Gi = pi. Observing how function
G1 evolves with respect to p1 for different tolerances g, we see a similar behavior as in [11]:
around p1 ≈
0.42 strategic mining under immediate release becomes proﬁtable (see Figure 6).
However, for R1 a different behavior is observed: strategic mining is only proﬁtable for values of
p1 larger than 0.5 (se Figure 5). Furthermore, very large tolerances (beyond the maximum gap
described in Table 1) are required for proﬁtability when p1 < 0.6. This suggests that in terms of
proﬁtability, strategic miners should decide using the average revenues per turn, rather than the
ratio of validated blocks.

Despite the discussion above, an interesting phenomenon occurs when we look at the revenues
R2 of the honest player (see Figure 7). For sufﬁciently large tolerances, they become negative
when p1 is large enough. This means that a sufﬁciently powerful strategic miner with a very
stubborn strategy (i.e. large gap tolerance) could eliminate honest ones from the market. For this
to happen, rapid mixing is essential. We observe that if the strategic miner has p1 > 0.65 and
applies a capitulation policy of constant gap g = 10, then, within months (see Corollary 2), honest
miners will lose money and quit the mining game in the long run. For even larger tolerances,
the amount of power required to perform such strategy seems to approximate 0.5. However, it
is not clear if larger tolerances could be applied since fast mixing is not ensured. This situation
deserves a further study since a monopolistic miner jeopardizes the very essence of decentralized
cryptocurrencies. We aim to explore these perspectives in a subsequent work.

4https://bitcoinmagazine.com/
5https://digiconomist.net/bitcoin-energy-consumption/

22

g1g30.20.40.60.81.00.20.40.60.81.0g1g30.20.40.60.81.00.20.40.60.81.0g1g30.20.40.60.81.00.20.40.60.81.0g1g30.20.40.60.81.00.20.40.60.81.0Figure 7: R2 with respect to the power of the strategic miner (p1) for different capitulation regimes of
constant gap. For p1 > 0.5, R2 becomes negative for sufﬁciently large g.

References

[1] J. Abadi and M. Brunnermeier. Blockchain economics. Technical report, National Bureau of Economic

Research, 2018.

[2] H. Albrecher and P.-O. Goffard. On the proﬁtability of selﬁsh blockchain mining under consideration

of ruin. arXiv preprint arXiv:2010.12577, 2020.

[3] M. Arenas, J. Reutter, E. Toussaint, M. Ugarte, F. Vial, and D. Vrgoˇc. Cryptocurrency mining games
with economic discount and decreasing rewards. In International Symposium on Theoretical Aspects of
Computer Science (STACS), 2020.

[4] N. Arnosti and S. M. Weinberg. Bitcoin: A natural oligopoly. In Innovations in Theoretical Computer

Science (ITCS), 2019.

[5] G. Birmpas, E. Koutsoupias, P. Lazos, and F. J. Marmolejo-Coss´ıo. Fairness and efﬁciency in dag-based
cryptocurrencies. In International Conference on Financial Cryptography and Data Security (FC), pages
79–96, 2020.

[6] M. Davidson and T. Diamond. On the proﬁtability of selﬁsh mining against multiple difﬁculty

adjustment algorithms. IACR Cryptol. ePrint Arch., 2020:94, 2020.

[7] I. Eyal. The miner’s dilemma. In IEEE Symposium on Security and Privacy, pages 89–103, 2015.

[8] I. Eyal and E. G. Sirer. Majority is not enough: Bitcoin mining is vulnerable. 61(7):95–102, 2018.

[9] G. Goren and A. Spiegelman. Mind the mining. In ACM Conference on Economics and Computation (EC),

pages 475–487, 2019.

[10] C. Grunspan and R. P´erez-Marco. On proﬁtability of selﬁsh mining. CoRR, abs/1805.08281, 2018.

[11] A. Kiayias, E. Koutsoupias, M. Kyropoulou, and Y. Tselekounis. Blockchain mining games. In ACM

Conference on Economics and Computation (EC), 2016.

[12] E. Koutsoupias, P. Lazos, F. Ogunlana, and P. Seraﬁno. Blockchain mining games with pay forward.

In The World Wide Web Conference (WWW), pages 917–927, 2019.

[13] C. Krattenthaler. Lattice path enumeration. In M. Bona, editor, Handbook of Enumerative Combinatorics,

pages 589–678. New York, 2015.

[14] N. Leonardos, S. Leonardos, and G. Piliouras. Oceanic games: Centralization risks and incentives in

blockchain mining. In Mathematical Research for Blockchain Economy, pages 183–199. 2020.

[15] D. A. Levin and Y. Peres. Markov chains and mixing times. American Mathematical Society, Providence,

Rhode Island, 2017.

[16] F. J. Marmolejo-Coss´ıo, E. Brigham, B. Sela, and J. Katz. Competing (semi-) selﬁsh miners in bitcoin.

In ACM Conference on Advances in Financial Technologies (AFT), pages 89–109, 2019.

23

g1g30.20.40.60.81.00.20.40.60.81.0[17] S. Nakamoto. Bitcoin: A peer-to-peer electronic cash system. Technical report, Manubot, 2019.

[18] K. Nayak, S. Kumar, A. Miller, and E. Shi. Stubborn mining: Generalizing selﬁsh mining and combining
with an eclipse attack. In IEEE European Symposium on Security and Privacy (EuroS&P), pages 305–320,
2016.

[19] J. R. Norris. Markov chains. Cambridge University Press, 1998.

[20] R. Pass and E. Shi. Fruitchains: A fair blockchain. In ACM Symposium on Principles of Distributed

Computing (PODC), pages 315–324, 2017.

[21] M. Rosenfeld. Analysis of hashrate-based double spending. arXiv:1402.2009, 2014.

[22] A. Sapirshtein, Y. Sompolinsky, and A. Zohar. Optimal selﬁsh mining strategies in bitcoin.
International Conference on Financial Cryptography and Data Security (FC), pages 515–532, 2016.

In

[23] F. Tschorsch and B. Scheuermann. Bitcoin and beyond: A technical survey on decentralized digital

currencies. IEEE Communications Surveys & Tutorials, 18(3):2084–2123, 2016.

A Appendix

Proof of Proposition 6. Since π is a stationary distribution, and thanks to the path enumeration (5),
we have

1 = π(0, 0)

= π(0, 0)

= π(0, 0)

= π(0, 0)

∞
∑
(cid:96)=0
∞
∑
(cid:96)=0

g
∑
m=0
g
∑
m=0

2
g + 2

2
g + 2

g+1
∑
k=1

g+1
∑
k=1

L((cid:96), (cid:96) + m)p(cid:96)

1 p(cid:96)+m
2

2
g + 2

sin

sin

g+1
∑
k=1
(cid:18) πk
g + 2

(cid:19)

(cid:18) πk
g + 2

(cid:19) g
∑
m=0

sin

sin

·
(cid:18) πk(m + 1)
g + 2

·

(cid:18)

2 cos

(cid:19) ∞
∑
(cid:96)=0

(cid:18) πk(m + 1)
g + 2

(cid:19)

(cid:18)

2 cos

(cid:18) πk
g + 2

(cid:19)(cid:19)2(cid:96)+m

1 p(cid:96)+m
p(cid:96)
2

(cid:19)(cid:19)2(cid:96)+m

1 p(cid:96)+m
p(cid:96)
2

(cid:18) πk
g + 2
(cid:17)

sin

(cid:18) πk
g + 2

(cid:19) g
∑
m=0

sin

(cid:18) πk(m + 1)
g + 2

(cid:19) 2m cosm (cid:16) πk
g+2
(cid:16) πk
g+2

4 cos2

1

−

pm
2

,

(cid:17)

p1 p2

and therefore we get





π(0, 0) =

2
g + 2

g+1
∑
k=1

sin

(cid:18) πk
g + 2

(cid:19) g
∑
m=0

sin

(cid:18) πk(m + 1)
g + 2

(cid:19) 2m cosm (cid:16) πk
g+2
(cid:16) πk
g+2

4 cos2

1

−

(cid:17)

(cid:17)

pm
2

p1 p2



1

−



and π((cid:96), (cid:96) + m) = π(0, 0)L((cid:96), (cid:96) + m)p(cid:96)

1 p(cid:96)+m

2

, for m

0, 1, . . . , g

. It follows that

ρ1 = p1

∞
∑
(cid:96)=0

π((cid:96), (cid:96))((cid:96) + 1) = p1π(0, 0)

∞
∑
(cid:96)=0
(cid:96)=0 L((cid:96), (cid:96))x(cid:96)((cid:96) + 1), so that ρ1 = p1π(0, 0)G1(p1 p2). Observe that G1(x) =

2((cid:96) + 1).

1 p(cid:96)

∈ {

}
L((cid:96), (cid:96))p(cid:96)

We deﬁne G1(x) = ∑∞
xF(cid:48)1(x) + F1(x), where

F1(x) =

∞
∑
(cid:96)=0

L((cid:96), (cid:96))x(cid:96) =

2
g + 2

g+1
∑
k=1

sin2

(cid:18) πk
g + 2

(cid:19)

(cid:18)

2 cos

·

(cid:18) πk
g + 2

(cid:19)(cid:19)2(cid:96)

x(cid:96)

∞
∑
(cid:96)=0
(cid:18) πk
g + 2

=

2
g + 2

g+1
∑
k=1

sin2

(cid:18)

(cid:19) ∞
∑
(cid:96)=0

2 cos

(cid:18) πk
g + 2

(cid:19)(cid:19)2(cid:96)

x(cid:96) =

2
g + 2

g+1
∑
k=1

24

sin2 (cid:16) πk

g+2

(cid:17)

4x cos2

1

−

(cid:16) πk
g+2

(cid:17) .

It follows that

G1(x) =

2
g + 2

g+1
∑
k=1

(cid:16)

1

−

and therefore we conclude that

sin2 (cid:16) πk

(cid:17)

g+2
(cid:16) πk
g+2

(cid:17)(cid:17)2

4x cos2

ρ1 =

p1
Γ

g+1
∑
k=1

sin2 (cid:16) πk

g+2

(cid:17)

(cid:16)

1

−

4p1 p2 cos2

(cid:16) πk
g+2

(cid:17)(cid:17)2 .

Similarly, we have that

ρ2 = p2

∞
∑
(cid:96)=0

π((cid:96), (cid:96) + g)((cid:96) + g + 1) = p2π(0, 0)

∞
∑
(cid:96)=0

L((cid:96), (cid:96) + g)p(cid:96)

1 p(cid:96)+g

2

((cid:96) + g + 1)

and consider G2(x) = ∑∞
that G2(x) = xF(cid:48)2(x) + (g + 1)F2(x), where

(cid:96)=0 L((cid:96), (cid:96) + g)x(cid:96)((cid:96) + g + 1) so that ρ2 = pg+1

2 π(0, 0)G2(p1 p2). We have

F2(x) =

∞
∑
(cid:96)=0

L((cid:96), (cid:96) + g)x(cid:96) =

∞
∑
(cid:96)=0

1)k

−

1 sin2

(cid:18) πk
g + 2

(cid:19)

(cid:18)

2 cos

(cid:18) πk
g + 2

(cid:19)(cid:19)2(cid:96)+g

x(cid:96)

·

(cid:18)

(cid:18) πk
g + 2
(cid:17)(cid:17)g

(cid:19)(cid:19)g ∞
∑
(cid:96)=0

2 cos

(cid:18) πk
g + 2

(cid:19)(cid:19)2(cid:96)

x(cid:96)

.

(cid:18)

(cid:18)

g

1

4x cos2

−

(cid:18) πk
g + 2

(cid:19)(cid:19)

(cid:19)

+ 1

,

(cid:18)

(cid:18)

g

1

4p1 p2 cos2

−

(cid:18) πk
g + 2

(cid:19)(cid:19)

(cid:19)

+ 1

.

=

2
g + 2

=

2
g + 2

g+1
∑
k=1

(

g+1
∑
k=1

(

−

−

1)k

−

1 sin2

sin2 (cid:16) πk

g+2

1)k

−

1

(

g+1
∑
k=1
(cid:19) (cid:18)

−

2
g + 2
(cid:18) πk
g + 2
(cid:17) (cid:16)

4x cos2

1

−

2 cos

2 cos

(cid:16) πk
g+2
(cid:17)

(cid:16) πk
g+2

Therefore, we have that G2(x) is equal to

2
g + 2

g+1
∑
k=1

(

−

1)k

−

1

sin2 (cid:16) πk
(cid:16)

g+2

(cid:17) (cid:16)

2 cos

(cid:17)(cid:17)g

(cid:16) πk
g+2
(cid:17)(cid:17)2

(cid:16) πk
g+2

4x cos2

1

−

from where we recover that

ρ2 =

pg+1
2
Γ

g+1
∑
k=1

(

−

1)k

−

1

(cid:17) (cid:16)

2 cos

sin2 (cid:16) πk
(cid:16)

g+2

4p1 p2 cos2

1

−

(cid:17)(cid:17)g

(cid:17)(cid:17)2

(cid:16) πk
g+2
(cid:16) πk
g+2

25

