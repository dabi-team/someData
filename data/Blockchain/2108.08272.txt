1
2
0
2

g
u
A
9

]

R
C
.
s
c
[

1
v
2
7
2
8
0
.
8
0
1
2
:
v
i
X
r
a

1

Aurora: a probabilistic algorithm for distributed
ledgers enabling trustless synchronization and
transaction inclusion veriﬁcation

Federico Matteo Benˇci´c, Member, IEEE, Ivana Podnar ˇZarko, Member, IEEE,

Abstract—A new node joining a blockchain network ﬁrst synchronizes with the network to verify ledger state by downloading the entire
ledger history. We present Aurora, a probabilistic algorithm that identiﬁes honest nodes for transient or persistent communication in the
presence of malicious nodes in a blockchain network, or ceases operation if it is unable to do so. The algorithm allows a node joining
the network to make an informed decision about its next synchronization step or to verify that a transaction is contained in a valid
ledger block without downloading the entire ledger or even the header chain. The algorithm constructs a Directed Acyclic Graph on the
network topology to select a subset of nodes including a predeﬁned number of honest nodes with a given probability. It is evaluated on
a Bitcoin-like network topology using an open-source blockchain simulator. We investigate algorithm performance and analyze its
communication complexity. Our results show that the algorithm facilitates trustless interactions of resource-constrained nodes with a
blockchain network containing malicious nodes to enable a leaner initial blockchain download or an efﬁcient and trustless transaction
inclusion veriﬁcation. Moreover, the algorithm can be implemented without any changes to the existing consensus protocol.

Index Terms—blockchain, scalability, decentralization, trustless, light client

(cid:70)

1 INTRODUCTION

D ISTRIBUTED LEDGER Technology (DLT) is a revolu-

tionary technology for digitizing assets [1] and has
become widely known through one of its specializations,
the blockchain. Blockchain is a distributed ledger based
on a peer-to-peer (P2P) network to manage transactions
for multiple entities in a veriﬁable and traceable manner.
Data is written within blocks of blockchain transactions, and
does not require a centralized entity, but rather the entire
P2P network, to maintain the blocks. The main features of
blockchain are immutability, transparency and fault toler-
ance [2].

Users running blockchain nodes can choose between
two types of nodes: full and light. Full nodes download
and verify the entire ledger which contains all transactions
since the ledger creation. Consequently, they operate in a
trustless manner, but also have more stringent hardware
requirements. In contrast, light nodes only need to down-
load part of the ledger (e.g., the header chain) and therefore
consume less processing power, network bandwidth and
memory compared to full nodes. However, light nodes
depend on full nodes — full nodes provide light nodes with
the metadata required for their operation.

Regardless of the node type and due to the immutability
requirement, the size of the ledger is immense as the num-
ber of transactions continuously increases. This leads to a
signiﬁcant load during node synchronization. For example,
in January 2020, the Ethereum blockchain had about 250
GB in non-archived mode [3]. Bitcoin’s header chain had
50 MB in April 2020, while Ethereum’s header chain had 5
GB [4] and is growing about 1 GB per year [5]. Since the
synchronization process is memory and time consuming,
a new node may either be unable to download the ledger
or unwilling to wait too long for the process to complete.
For example, nodes in the Internet of Things (IoT) domain

are often resource-constrained devices with limited memory,
processing power, and energy, which further exacerbates
the problem. As a result, users often opt for third-party
explorers instead of running their own nodes.

In addition to high resource consumption, the process of
node synchronization (i.e., bootstrapping) becomes a point
of centralization, as it depends in part on a set of well known
nodes that are assumed to be both available and honest.
Today’s client implementations rely on a list of well known
addresses [6] that may not always be available or may even
exhibit Byzantine behavior. One could work around the
issue of unavailable seeds by manually adding bootstrap
peers, but manually added nodes may also exhibit malicious
behavior, making a new node vulnerable to various types
of attacks, from denial of service to Eclipse attacks [7], [8].
The consequences of a malicious node being a ﬁrst contact
node can vary for a victim. They range from a waste of
time and resources, in the best case, to a state where, in the
worst case, the victim is unaware of the existence of a longer
chain because no honest node is available to advertise it.
Note that if a new node joins the network through a set
of partitioned nodes (which may or may not be malicious),
the new node could synchronize with a ledger that is in a
state of extended fork, and such a state can lead to a double-
spending attack. For simplicity, hereinafter we do not distin-
guish between partitioned and malicious Byzantine nodes,
as our algorithm is applicable in both scenarios.

The Aurora algorithm, originally proposed in [9], is a
consensus-agnostic probabilistic algorithm designed to en-
able a new node to avoid the adverse inﬂuence of Byzantine
or malicious nodes in ledger networks by detecting a prede-
ﬁned number of honest nodes with a high and controllable
probability. The identiﬁed nodes are used thereafter for
persistent or transient communication of the new node with

 
 
 
 
 
 
the network. If the predeﬁned number of honest nodes
cannot be identiﬁed, the algorithm stops. Assuming that
an honest node reveals to a new node what is accepted
as canonical truth by the majority of the voting power, as
opposed to a malicious node that tries to subvert the new
node, the algorithm saves the node’s resources by efﬁciently
discovering a subset of network nodes containing at least 1
or 1 + |M | honest nodes, where M is the set of malicious
network nodes. Such subsets of network nodes can be used
for trustless ledger synchronization, or transaction inclusion
veriﬁcation without the need to download the entire ledger
or even the header chain.

While the algorithm can be used by both full and light
nodes, its low memory footprint and stochastic behavior
make it particularly suitable for resource-constrained de-
vices, where it offers the greatest beneﬁt. Although poten-
tially applicable in other domains, the algorithm offers par-
ticular beneﬁts in the domain of public and permissionless
DLT solutions, as it reinforces the decentralized and trustless
ethos on which the technology is based.

This work builds on our previous work which intro-
duced the initial version of the Aurora algorithm [9]. The
main contributions of the paper and the most notable dis-
tinctions compared to our previous work are the following:

1) Redeﬁnition of the algorithm to provide an accurate
probabilistic output and communication complexity
of the algorithm. The algorithm identiﬁes a subset of
network nodes containing a predeﬁned number of
honest nodes with high probability as a function of
the assumed number of malicious network nodes.

2) A comprehensive evaluation of the redeﬁned al-
gorithm is performed by simulation on a realis-
tic network topology using open-source simulation
tools in a Bitcoin-like network environment. The
simulation results conﬁrm our analytical ﬁndings.

3) Two concrete application examples of the algorithm:

a)

In a scenario where a new node joins a
distributed ledger network, the algorithm
assists the node during the synchronization
process with a blockchain network with ma-
licious nodes.

b) The algorithm facilitates trustless and efﬁ-
cient veriﬁcation of transaction inclusion in
a block with a predeﬁned correctness proba-
bility and signiﬁcantly reduces the resource
consumption of a device executing the veri-
ﬁcation procedure.

Although our work is relevant to solutions for peer-
to-peer (P2P) networks which detect malicious actors or
counter their direct inﬂuence, our work differs from such so-
lutions in that it does not detect malicious nodes, but rather
identiﬁes node sets containing honest nodes. Moreover, our
work has a well-deﬁned application domain, namely DLT
networks. Comparison with related work is discussed in
more detail in Section 2.

The paper is organized as follows: Section 2 compares
our solution with other existing solutions. Section 3 intro-
duces necessary terms and deﬁnitions, and enumerates the
assumptions under which our algorithm works. Section 4

2

discusses how relevant variables affect the size of sets that
contain a predeﬁned number of honest nodes. Section 5
presents the Aurora algorithm and introduces two relevant
applications of the algorithm, while Section 6 investigates its
communication complexity. Section 7 explains the method-
ology used for algorithm veriﬁcation, the experiments per-
formed, and their results. Section 8 discusses possible chal-
lenges and future work, while Section 9 concludes the paper
with a glossary appended at the end of the paper.

2 RELATED WORK

We begin by taking a closer look at light-client solutions,
highlighting potential synergies and contrasting differences
to our algorithm. Next, since our work is the most valu-
able when adversarial inﬂuences are present in both P2P
and DLT networks, we continue with a brief overview of
relevant works.

Light client implementations fall broadly into the fol-
lowing three categories: remote clients, simpliﬁed payment
veriﬁcation clients, and trustless clients.

Remote clients rely on a centralized solution for com-
munication with a DLT network. An example is MetaMask,
an Ethereum wallet that communicates with the Ethereum
ledger via the Infura Gateway System [10]. Remote clients
which are not completely centralized also exist, for example
the SlockIt INCUBED client1. This client uses multiple gate-
ways to communicate with a ledger network. The gateways
have a stake in the network that can be reduced if their mis-
behavior is discovered. Such clients sacriﬁce the integrity of
the data by trusting a third party in exchange for a very
small computational resource requirement to interact with a
DLT network. They differ greatly from our solution because
our solution is completely decentralized.

Simpliﬁed Payment Veriﬁcation clients (SPVs) are stan-
dard distributed ledger clients that synchronize with the
network’s header chain and request the rest of the block
information as needed. Examples are Electrum2 for Bitcoin,
or Geth (in light mode) for Ethereum. There are SPVs
that, similar to our solution, recognize the added value of
multiple sources of truth and can even be used in conjunc-
tion with our solution. For example, Electrum maintains
connections to approximately 10 servers and subscribes to
block header notiﬁcations to all of them to detect forks and
partitions. Here we see an emerging synergy: The Aurora
algorithm can be used to identify 10 servers which are
honest with high probability. The Tendermint [11] light
client acquires prerequisites for connecting to the network
by means outside of Tendermint3 (e.g., social consensus),
and thus it can apply our solution to identify these prereq-
uisites. SPVs differ from remote clients since they maintain
their trustlessness to some extent by validating metadata
against the header chain in their possession. However, since
they are served by full nodes, they rely on full nodes
which are assumed to be available and honest. Moreover,
the applicability of SPVs to resource-constrained devices is
debatable — even the header chain may be too large for

1. https://consensys.net/diligence/audits/2019/09/slock.it-

incubed3/

2. https://electrum.readthedocs.io/en/latest/faq.html
3. https://docs.tendermint.com/master/spec/p2p/node.html

some devices. Our solution differs greatly from SPVs since
it does not require the header chain to work.

Trustless clients attempt to maintain the trustless mech-
anisms of SPVs while keeping their size sublinear or con-
stant compared to ledger size or even header chain size. As
such, they are sometimes referred to as super light clients.
A client running the Aurora algorithm would partially fall
into this category — when used for transaction inclusion
veriﬁcation, the client does not need to download the header
chain (or part of the header chain). A proposal from [12]
uses a cryptography accumulator and generates a chain
summary in the form of a block attribute. Then, the client
must randomly choose a slice of the network nodes, and
if the majority of nodes is compromised by the attacker,
the protocol is not secure. Consequently, our algorithm can
be used in conjunction with the above — the slice can
be the output of our algorithm. Vault [13] is a solution
built on a proof-of-stake consensus protocol proposed by
Algorand [14] and introduces a fast bootstrapping method
relying on the presence of stamping certiﬁcates, while our
solution does not require any additional data structures to
operate.

We continue by highlighting two solutions: Fly-
Client [15] as an example of a solution that would beneﬁt
signiﬁcantly from our algorithm, and BlockQuick [16] as an
example of a solution that addresses the potential existence
of Eclipse attacks, but does so in a fundamentally different
way than our solution.

FlyClient is a light client proposal for Proof of Work
blockchains [15]. The client only needs to store a logarithmic
number of block headers to provide strong mechanisms for
ensuring the validity of those block headers by using tech-
niques such as probabilistic sampling, MRRs4, and the Fiat-
Shamir heuristic. As FlyClient requires nodes to maintain
MRRs, FlyClient cannot be used on the currently running
Bitcoin and Ethereum networks without forks. Also, the
client must be connected to at least one honest node, which
means that FlyClient cannot protect a node against Eclipse
attacks, unlike the Aurora client. Thus, our client does not
compete with this solution, but can work in synergy with it.
The one honest node that FlyClient needs to operate can be
found with our solution.

BlockQuick is based on a consensus-based reputation
scheme [16]. A BlockQuick client maintains the Consensus
Reputation Table, which contains miner addresses with the
highest reputation shares generated based on the latest 100
block headers. The reputation share of a miner is equal to the
number of blocks mined in the last 100 blocks. When new
blocks are broadcasted, the client validates the miner’s cryp-
tographic signature against the data from the Consensus
Reputation Table. A new block is considered valid only if the
block receives a consensus share score > 50%. Thus, it is not
just a matter of choosing the longest chain with the highest
difﬁculty, but accepting the block from miners with a high
consensus share. The client is resistant to both MITM and
Eclipse attacks. Similar to FlyClient, the requirements for
running BlockQuick clients with the current Ethereum and
Bitcoin networks are not met. According to [16], each miner
should be reachable at the address speciﬁed in the block,

4. Merkle Mountain Ranges

3

each block header must contain an address and the public
ID of the block miner and each block must contain a proof
of inclusion of all previous block headers. The result is that,
unlike our solution, a BlockQuick client cannot be deployed
on currently running Ethereum or Bitcoin networks without
a hard fork.

Relevant solutions in the P2P domain are anomaly de-
tection methods and sibyl group inference solutions (e.g.,
SybilGuard [17]). However, since reputation measurements
are not available in existing blockchain solutions, such ap-
proaches are not applicable in this context. Anomaly de-
tection techniques [18], ﬂow-based and graph-based meth-
ods [19], [20] as well as network trafﬁc reliant solutions
(e.g., [21], [22]) differ from our solution in two key aspects:
The ﬁrst and most obvious is the application domain — our
work is DLT-speciﬁc. Second, we do not deal with or infer
the identity of malicious clusters, but focus on identifying
honest nodes for bootstrapping and transaction inclusion
veriﬁcation.

As for the adversarial inﬂuence in DLT networks, pre-
vious studies, e.g., [6], [7], [23], [24], [25], [26], [27], have
conﬁrmed that prominent DLT solutions such as Bitcoin [28]
and Ethereum [23] are vulnerable to Denial of Service,
Eclipse Attacks, BGP highjacks, Man-in-the-Middle (MITM)
attacks, network partitioning, etc. The consequences of ad-
versarial inﬂuences are non-trivial and range from trans-
action dropping to double spending. Although the related
work proposes and implements several countermeasures,
it differs from our work in two key ways. First, we do
not directly counteract malicious clusters, but focus on
detecting honest nodes for persistent or transient commu-
nication, thus circumventing the malicious inﬂuence rather
than countering it or dealing with the consequences. Second,
our algorithm does not require special data structures or
protocol modiﬁcations to be integrated with deployed DLT
solutions.

3 PRELIMINARIES

Let us consider a network S with M malicious nodes. We
assume the following:

Assumption 1. A new node a ∈ S joins the network by
contacting a single ﬁrst-contact node f c and is unaware
of any other network node (e.g., bootstrap peers are not
available).

Assumption 2. The ﬁrst-contact node f c may be malicious,
and may collude with other malicious peers to subvert node
a.

Assumption 3. A subset of nodes from S, denoted by Γ,
contains nodes discoverable by node a via f c.

By discoverable nodes we refer to those nodes that node a has
encountered or become aware of their existence when its
ﬁrst-contact node is f c.

Assumption 4. There is a set of malicious nodes, M ⊂ S,
the size of M is κ and the relation κ < |Γ| holds. The value
of κ is known a priori or can be inferred (the initialization
of κ is discussed in the following sections).

Assumption 5. The adversary always holds a minority of
the voting power.

Assumption 6. The number of malicious nodes in the
network cannot increase during algorithm execution.

Under these assumptions, node a performs a process of
network exploration which we name gathering, as the pro-
cess of collecting discoverable nodes initiated from node f c
to create Γ. Each node queried during a gathering exposes
a set of its neighboring nodes to node a, which a uses to
expand Γ. We continue by providing deﬁnitions based on
the previously stated assumptions.

Deﬁnition 1 (Deterministic Honest Set, ∆h). For a given Γ,
a set ∆h is a subset of Γ which contains at least h honest
nodes.

Corollary 1.1. For any given Γ, there exists a deterministic
honest set with at least 1 honest node, ∆1.

Proof. Iff the relation κ < |Γ| holds as per Assumption 4,
Γ must contain at least one honest node. Consequently, ∆1
can always be constructed.

Deﬁnition 2 (Probabilistic Honest Set, Πh). For a given Γ,
a set Πh is a subset of Γ which contains at least h honest
nodes with probability ρ. The probability ρ is derived from
an underlying hypergeometric distribution.

To reduce problem complexity, we introduce justiﬁable
constraints on h relevant to the DLT domain. First, we con-
sider those ∆h and Πh that contain at least one honest node,
which guarantees that the truth (e.g., the longest blockchain)
can eventually be received by node a. Second, we consider
those ∆h and Πh that contain a majority of honest nodes,
which guarantees that an honest answer can be derived
by majority voting without requiring a resource-intensive
process of ledger/header chain analysis. With respect to
the above constraints on h, we deﬁne the corresponding
deterministic sets that will be used as a naive baseline as
follows:

Deﬁnition 3 (Deterministic Safe Set, ∆s ≡ ∆1). For a given
Γ containing κ malicious nodes, where |Γ| > κ, ∆s is a
deterministic honest set which contains at least one honest
node and its size is at least κ + 1.

We call this set safe set since node a can obtain at least one
honest answer in the worst case by querying all members
of ∆s. By analyzing the obtained ledgers and verifying
their transactions since genesis, the node can detect possible
discrepancies in the ledger state as reported by the queried
nodes, but also identify a correct ledger.

Deﬁnition 4 (Deterministic Progress Set, ∆p ≡ ∆(cid:98)|∆|/2(cid:99)+1).
For a given Γ containing κ malicious nodes, where |Γ| > 2κ,
∆p is a deterministic honest set which contains a majority
of honest nodes and its size is at least 2κ + 1.

We call this set progress set because node a can obtain a
majority of honest answers in the worst case by querying
all members of the set and perform an action based on the
majority vote about the ledger state reported by the queried
nodes.

The deterministic baselines, both safe and progress sets,
offer a naive solution to the problem of identifying a truthful

4

node: A node can trivially query multiple network nodes
under the assumption that there are at most κ malicious
nodes, and compare the obtained answers in search of
the truth. However, this method is very inefﬁcient, as we
show in Section 4. Let us now consider deﬁnitions of the
corresponding sets with probabilistic bounds.

Deﬁnition 5 (Probabilistic Safe Set, Πs ≡ Π1). For a given
Γ containing κ malicious nodes, where |Γ| > κ, Πs is a
probabilistic honest set which contains at least one honest
node with probability ρ.

Deﬁnition 6 (Probabilistic Progress Set, Πp ≡ Π(cid:98)|Π|/2(cid:99)+1).
For a given Γ containing κ malicious nodes, where |Γ| > 2κ,
Πp is a probabilistic honest set which contains a majority of
honest nodes with probability ρ.

Probabilistic sets are generated during an iterative pro-
cess when node a in each step 1) contacts a network node,
2) asks for a set of its neighbors, and then 3) selects a next-
draw node to repeat the process. For this reason, we deﬁne
the following:

Deﬁnition 7 (Set of discoverable network nodes in step i,
Γi). Γi is a subset of network nodes which node a has
learned about while performing a gathering up to step i,
where |Γi| ≤ |Γi+1|.

In other words, Γi is ﬁlled by nodes appearing in neigh-
bor sets (i.e., peer lists) reported by contacted nodes, and
this set contains candidates for probabilistic honest sets.
Πh is generated from a ﬁnite population Γi by sampling
random nodes without replacement. The sampling process
can be modeled by the hypergeometric distribution [29], as
each element selected from Γi can be classiﬁed as a failure
or a success. In our context, a success denotes the selection
of an honest node, while a failure occurs when a malicious
node is selected. In summary, the distribution models the
probabilities associated with the number of successes in a
hypergeometric experiment, and is deﬁned by

X ∼ Hypergeometric(N , K, n),

(1)

where N is the population size, K is the number of suc-
cesses in the population, and n is the sample size.

The underlying probability mass function is then given

by

P (X = x) =

(cid:0)K
k

(cid:1)

(cid:1)(cid:0)N −K
n−k
(cid:1)

(cid:0)N
n

= f (N , K, n, k),

(2)

where k is the number of successes in the sample.

We begin the construction of a probabilistic set by a
gathering initiated at node f c to explore the network un-
til |Γi| > κ, and then start performing hypergeometric
experiments for a given Γi (the population). It contains
|Γi|−κ honest nodes (successes), and there exists a subset of
size |Πh| (the sample) which contains h honest nodes with
probability ρ or more. More formally, the hypergeometric
distribution can be stated as

X ∼ Hypergeometric(|Γi|, |Γi| − κ, |Πh|),

where we evaluate the following predicate

p(X ≥ h) ≥ ρ.

(3)

(4)

5

If the predicate is evaluated as true, we have constructed
a probabilistic set of size |Πh| containing at least h honest
nodes with at least probability ρ. If the predicate is evalu-
ated as false, we continue exploring the network.

The pseudocode deﬁning the construction of a proba-
bilistic set is given in Alg. 1 which requires three input
parameters: the correctness probability ρ, the ﬁrst contact
node f c, and κ, the initialization of which is covered in Sec-
tion 5.3.

Algorithm 1: Πh construction

Input
Input
Input

: ρ — Probability guarantee
: |Πh| — Desired probabilistic set size
: κ — Desired malicious node
tolerance

1 Gather at least κ + 1 nodes in Γ;
2 constructed ← f alse;
3 do
4

X ∼ Hypergeometric(|Γ|, |Γ| − κ, |Πh|);
if p(X ≥ h) ≥ ρ then

5

6

7

8

constructed ← true;

else

Add more nodes to Γ;

end

9
10 while !constructed;

Now that we understand how Πh is constructed, we
can analyze why using probabilistic sets is advantageous
compared to using their deterministic counterparts.

We perform an experiment to compare the deterministic
and probabilistic honest sets which are the most relevant to
be used in the DLT domain, namely safe sets and progress
sets. For four different population sizes |Γ|, we gradually
increase the number of malicious nodes κ to compare ∆s
with Πs, and ∆p with Πp. The results presented in Fig. 1
lead us to the following conclusions:

• The sizes of probabilistic sets Πs and Πp are much

smaller compared to the sizes of ∆s and ∆p;

• The size of deterministic sets is, as expected, lin-
early dependant on the number of malicious network
nodes, while the size of probabilistic sets shows
sublinear growth. For certain parameters (e.g., when
κ is reasonably small), the probabilistic set sizes are
signiﬁcantly smaller compared to their deterministic
counterparts. The observed difference is signiﬁcant
for larger populations, when a probabilistic set size
can be several orders of magnitude smaller com-
pared to its deterministic counterpart.

Thus, we can conclude that probabilistic honest sets
bring signiﬁcant beneﬁts for solving the problem of iden-
tifying honest nodes within subsets of network nodes, espe-
cially for large networks.

4 PROBABILISTIC SET SIZE
Since node a uses members of Πh (i.e., Πs or Πp) for
transient or persistent communication, reducing |Πh| will
diminish the communication complexity of our algorithm.
As shown in the previous section, the size of Πh can be

Fig. 1. Deterministic vs. probabilistic set sizes with an increase of κ
for four different population sizes. When population size increases, we
observe a greater difference between a probabilistic set size and its
deterministic counterpart.

reduced by increasing the number of successes in the popu-
lation. In this section, we examine the rate at which |Πh| is
reduced with respect to the growth of |Γ|, and compare |Πh|
to sublinear functions of κ in the context of the current size
of the Bitcoin IPV4 network.

An experiment was conducted to mimic algorithm exe-
cution that creates an increasing set of discoverable network
nodes: We varied the number of discoverable nodes |Γ|
from 2 to 20480, which is the maximum number of total
nodes that a Bitcoin client can store [30]. For each |Γ|, κ was
set to |Γ| − 1 and gradually decreased in increments of 1.
During each experimental run, the ratio between |Γ| and κ
was marked when the following predicates (i.e., conditions)
were met:

√

κ.
|Πs| ≤
|Πs| ≤ ln κ.

1)
2)

√

κ.
|Πp| ≤
|Πp| ≤ ln κ.

3)
4)

Fig. 2. Ratio |Γ|
√
sizes to

κ when the four predicates limiting the probabilistic set

κ and ln κ have been satisﬁed with an increase of |Γ|.

(cid:19)(cid:21)(cid:19)(cid:23)(cid:19)(cid:25)(cid:19)(cid:27)(cid:19)(cid:19)(cid:24)(cid:19)(cid:20)(cid:19)(cid:19)(cid:19)(cid:21)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:25)(cid:19)(cid:19)(cid:27)(cid:19)(cid:19)(cid:19)(cid:24)(cid:19)(cid:19)(cid:20)(cid:19)(cid:19)(cid:19)(cid:19)(cid:21)(cid:19)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:19)(cid:25)(cid:19)(cid:19)(cid:19)(cid:19)(cid:21)(cid:19)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:19)(cid:25)(cid:19)(cid:19)(cid:19)(cid:19)(cid:24)N(cid:20)(cid:19)N(cid:20)(cid:24)N(cid:21)(cid:19)N(cid:19)(cid:24)N(cid:20)(cid:19)N(cid:20)(cid:24)N(cid:21)(cid:19)N_b(cid:3)V(cid:3)__n(cid:3)V(cid:3)__b(cid:3)S(cid:3)__n(cid:3)S(cid:3)__a_(cid:3) (cid:3)(cid:20)(cid:19)(cid:19)_a_(cid:3) (cid:3)(cid:20)(cid:19)(cid:19)(cid:19)_a_(cid:3) (cid:3)(cid:25)(cid:22)(cid:24)(cid:25)_a_(cid:3) (cid:3)(cid:21)(cid:19)(cid:23)(cid:27)(cid:19)(cid:135)6HW(cid:3)VL]HV(cid:28)(cid:20)(cid:19)(cid:19)(cid:21)(cid:22)(cid:23)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:20)(cid:19)(cid:19)(cid:19)(cid:21)(cid:22)(cid:23)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:20)(cid:19)N(cid:21)(cid:19)(cid:20)(cid:19)(cid:21)(cid:19)(cid:22)(cid:19)(cid:23)(cid:19)(cid:24)(cid:19)_·(cid:3)V(cid:3)_(cid:3)(cid:148)(cid:3)¥(cid:201)_·(cid:3)V(cid:3)_(cid:3)(cid:148)(cid:3)ORJ(cid:11)(cid:201)(cid:12)_·(cid:3)S(cid:3)_(cid:3)(cid:148)(cid:3)¥(cid:201)_·(cid:3)S(cid:3)_(cid:3)(cid:148)(cid:3)ORJ(cid:11)(cid:201)(cid:12)_+__+_(cid:18)(cid:201)Results are depicted in Fig. 2. By examining the ratios
indicating potential reduction of probabilistic set sizes with
respect to malicious node tolerance, we can conclude that
as the size of the population increases, the ratio between |Γ|
and κ required to reduce the probabilistic set sizes decreases.
Thus, it is easier to satisfy the four predicates limiting |Πh|
for larger populations, i.e., for larger sets of discoverable
nodes.

Table 1 shows the values extracted from Fig. 2 for
|Γ| = 6356, which is the number of active Bitcoin IPV4
nodes discovered and reported in [31]. This number is used
as the default network size in all the following experiments.

TABLE 1
ps: probabilistic set type, f : upper bound for probabilistic set size as a
function of κ, f (κ): f evaluated at respective κ, P : predicate, |Π|:
respective probabilistic set size, |∆|: respective deterministic set size

|Γ|

ps

f

P

|Γ| − κ

κ

|Γ|/κ

f (κ)

|∆|

|Π|

|∆|
|Π|

p

6356

Πs

Πp

sqrt(κ)

ln(κ)

sqrt(κ)

ln(κ)

|ps| ≤ f (κ)

|ps| ≤ f (κ)

|ps| ≤ f (κ)

|ps| ≤ f (κ)

549

5807

1.09454

76.20367

5808

76

3985

2371

2.68073

7.77107

2372

7

4615

1741

3.65078

41.72529

3483

41

6053

303

20.9769

5.71373

607

5

76.421052

338.85714

84.951219

121.4

0.9990005

0.9990004

0.9990073

0.9990014

√

For example, by examining the ﬁrst column in Table 1,
we see that to satisfy the predicate |Πs| ≤ sqrt(κ), even up
to 5807 of 6356 network nodes can be malicious, while the
5807 = 76.20367, which
size of Πs is less than or equal to
corresponds to 76, and the correct execution is guaranteed
with p = 0.9990005. If we would want to deterministically
ﬁnd at least one honest node within the same network,
|∆s| = κ + 1 = 5808. In other words, 76.421052 times
more nodes need to be queried for a deterministic answer
in comparison to a probabilistic answer.

From a pragmatic point of view, the ﬁrst three predicates
limiting probabilistic set sizes with respect to κ (results
displayed in the ﬁrst three columns of Table 1) can be
satisﬁed relatively easily, while the last condition has little
value for a real-world scenario due to its extremely high
|Γ|/κ ratio. Further reduction of the probabilistic set size
requires an even larger |Γ|/κ ratio and is considered im-
practical. Therefore, we decided to use the square root as
a sublinear function that bounds the probabilistic set size
with respect to malicious node tolerance and we deﬁne
the following constraint which will be of great use in the
upcoming complexity analysis:

Constraint 1. |Πh| is bounded by

√

κ, i.e., |Πh| ≤

√

κ.

Note that so far we have relied on the existence of the
set Γ without elaborating on how this set is constructed,
as our analysis has been independent of any particular

DLT solution or underlying network topology. However,
both the topology and speciﬁcs of DLT solutions need to
be considered when deﬁning the Aurora algorithm, as we
explain in the following section.

6

5 THE AURORA ALGORITHM AND ITS APPLICA-
TIONS

The Aurora algorithm is used to construct probabilistic
sets from a list of discoverable nodes. When performing
the algorithm, node a contacts other network nodes: In
accordance with Assumption 1 it does not have access to
trusted nodes and contacts a random one. As previously
stated, starting from node f c, node a explores the network
in a series of steps, where a single step is deﬁned as:

Deﬁnition 8 (Draw). A draw is a step performed by node a
during network exploration which consists of two messages:
a ping message from node a to a network node requesting its
peer list, and the corresponding pong message containing a
response denoted as ℵ. A draw at step i expands Γi−1 with
the unique nodes found in ℵi, i.e., Γi ← Γi−1 ∪ ℵi

A network node can receive multiple ping queries and
is assumed to be stateful [32], which means it retains state
about which addresses of neighboring peers are revealed
to node a together with a timestamp. Consequently, the
network node will not reveal nodes that have already been
revealed to node a in a previous pong message. A network
node is no longer queried by node a if it responds with
an empty peer list or fails to respond. Once a draw is
successful, node a terminates a connection to the network
node since resources should be released as soon as possible.
Draws are executed in steps until a halting condition is
satisﬁed.

Deﬁnition 9 (Halting condition). Halting condition is a
predicate that deﬁnes speciﬁc conditions which indicate to
node a to terminate further draws in the network.

Node a checks, after each draw, whether the halting
condition is satisﬁed and consequently terminates further
draws. Hereafter, unless otherwise speciﬁed, the default halt-
ing condition is deﬁned as a step when all discoverable nodes
stop responding to ping requests of node a (i.e., there are no
available nodes left to query).

We deﬁne a sequence of draw steps as follows:

Deﬁnition 10 (Gathering). Gathering is the process of net-
work exploration which consists of a sequence of draws
executed in steps i = 1 . . . d, where a halting condition is
met in step d. We assume it is executed in a directed and
acyclic manner.

We assume that a network can be represented as a graph
in which nodes are represented as vertices and connections
between nodes are represented as edges, where edges have
an associated direction. In such a graph, a gathering can be
associated with a Directed Acyclic Graph (DAG) consisting
of nodes contacted during a gathering. After a node re-
sponds with an empty peer list or does not respond at all, a
subsequent node is selected from Γ uniformly at random. As
node a performs the gathering, it also overlooks the creation

of the associated DAG to ensure that cycle formation is
avoided.

Although at ﬁrst glance a gathering is similar to the
process of recursively scraping the entire network, it is
something quite different. The purpose of a gathering is
to collect a minimal number of nodes within a minimal
period of time to construct probabilistic honest sets. The
probabilistic sets are then used by node a to choose an op-
timal bootstrap candidate and honest nodes for transaction
inclusion veriﬁcation.

The Aurora algorithm, as deﬁned in Alg. 2, requires
the following input parameters: a ﬁrst contact node f c, a
desired malicious node tolerance κ, the probability ρ under
which it guarantees correct execution, a halting condition
hc, the maximum acceptable size of the probabilistic set
|Πh|, and the number of honest nodes h which the proba-
bilistic honest set should contain. The last parameter conse-
quently determines which of the probabilistic sets is created:
Πs or Πp. The algorithm performs a do-while loop which
either constructs a Πh (line 7) or throws an exception (line
13). Ping and pong messages are exchanged between node
a and a randomly sampled responding node from Γ (lines
9−11). Unique nodes gathered from ping responses are used
to expand Γ (line 12). After each ping and pong exchange,
the algorithm checks weather the halting condition has been
satisﬁed in line 13.

Algorithm 2: Aurora algorithm

Input
Input
Input

Input
Input
Input

: ρ — Probability guarantee
: f c — First contact node identiﬁer
: hc — Halting condition
encapsulation
: |Πh| — Maximum Πh size
: h — [1, (cid:98)|Πh|/2(cid:99) + 1]
: κ — Desired malicious node
tolerance

1 nxtDraw ← f c;
2 Γ ← ∅;
3 do
4

X ∼ Hypergeometric(|Γ|, |Γ| − κ, |Πh|);
if p(X ≥ h) ≥ ρ then

Πh ← Sample without replacement |Πh|
nodes from Γ;
return Πh

else

nxtDraw ← random responding node in Γ;
Send ping to nxtDraw;
ℵ ← peers in pong message from nxtDraw;
Add ℵ to Γ;
if
hc.isHaltingConditionReached(nxtDraw, ℵ)
then

throw

end

5

6

7

8

9

10

11

12

13

14

15

end
16
17 while T rue;

7

input parameters nxtDraw, which is the next node queried
for its peer list, and the corresponding peer list ℵ.
A halting condition may be deﬁned as follows:

1)

2)

halt if the average number of newly-discovered
nodes in a draw falls below a deﬁned threshold, or
halt if a predeﬁned maximal number of gathering
steps has been reached.

Examples of halting conditions and their inﬂuence on

algorithm performance are investigated in Section 7.

5.1 Choosing a bootstrap candidate

For the purposed of identifying an honest bootstrap candi-
date, node a should use the probabilistic safe set generated
as the output of the Aurora algorithm since it contains at
least 1 honest node with high probability. Here, we assume
that nodes in the network advertise the state of the ledger
(e.g., the highest total difﬁculty represents the latest ledger
in Ethereum), and node a will attempt to synchronize its
ledger with other nodes using the order starting from the
latest to the oldest advertised state. To understand why Πs
is adequate for this purpose, let us analyze the behavior
of an adversary. First, if the adversary advertises an older
ledger state compared to honest nodes (i.e., a lower chain
head), node a will synchronize with another honest member
of Πs that reveals the latest ledger state (i.e., the highest
chain head). Second, if the adversary advertises a newer
ledger state compared to an honest node (i.e., a highest
chain head), then by Assumption 5 the ledger offered by
the adversary must be tampered with. In this scenario, Πs
will eventually provide safety with respect to blockchain
synchronization. In other words, node a could choose a
malicious node from Πs and start synchronizing, but it will
eventually detect that fraudulent data is provided by the
malicious node by examining the ledger. Since there is a
guarantee with probability ρ that an honest node is available
among all nodes in Πs, the node will start synchronizing
with the available honest node.

Alg. 3 relies on the existence of a Πs constructed
by Alg. 2 and allows node a to choose a candidate node
for synchronization. The candidate is the node that provides
the most recent ledger according to the consensus protocol,
e.g., advertises the longest chain, highest difﬁculty, etc. For
each such candidate, node a attempts to synchronize with
its ledger. If it turns out that the ledger has been tampered
with, node a chooses the next candidate. The algorithm
stops when node a downloads and veriﬁes an entire ledger
without detecting any tampering.

5.2 Transaction inclusion veriﬁcation

For the purpose of transaction inclusion veriﬁcation, node
a should use the probabilistic progress set Πp to verify
whether a transaction with identiﬁer txid is contained
within a block with identiﬁer blkid. Here we make further
assumptions:

The halting condition used in line 12 is an injected de-
pendency that implements a generic method which returns
true if a gathering should halt, or f alse otherwise. It uses as

Assumption 7. The data contained in a block is part of an
integrity-validating structure, and a node can verify that
the transaction is indeed contained in that structure. It is

Algorithm 3: Πs use for synchronization

Input

: Πs — Probabilistic Safe Set

1 sync ← f alse;
2 while sync = f alse do
3

candidate ← null;
for node in Πs do

4

5

6

7

8

9

10

11

candidate ← node offering latest ledger state

end
Attempt to sync with candidate;
if Attempt successful then

sync ← true;

else

Remove candidate from Πs;

end

12
13 end

assumed that all necessary additional metadata is available
to the node.5

To explain the usefulness of a progress set Πp for trans-
action inclusion veriﬁcation, we compare it with Πs. When
relying on an instance of Πs, node a cannot assume that the
chosen bootstrap candidate is honest, since ledgers need to
be downloaded and veriﬁed. However, node a can compare
answers from all members of Πp and conclude that the
answer provided by the majority is true with probability
ρ.

When Assumption 7 holds, Alg. 4 either checks whether
a transaction with ID txid is included in a block blkid with
probability ρ by checking with every member of Πp if the
provided Merkle proof is valid with respect to the available
Merkle root mroot, and thus chooses the majority answer.

5.3 Initialization of parameters and use cases

To use Alg. 2, at least six parameters are required. As
mentioned earlier, it is recommended to set the correctness
probability ρ to 0.999, with a note that the impact of ρ on
the size of probability sets is part of our future work. The
ﬁrst contact node f c can be found in any way a user sees
ﬁt, e.g., via chat, forums, etc. We deﬁne the default halting
condition hc as the moment when there are no more nodes
to ask for peer lists, although we strongly suggest changing
this to a condition that better ﬁts the underlying network
topology and the resources of a ledger client (an example
is given in Section 7.3). The maximum size of Πh can be
κ(cid:99). The number
set in accordance with Constraint 1, i.e., (cid:98)
of honest nodes h in Πh, i.e. choosing between Πs and Πp,
depends on the use case, as discussed further in this section.
Initializing κ is nontrivial: if a user makes a correct guess
and sets κ = M , the algorithm executes optimally. If the
user sets κ < M , then correct algorithm execution cannot be
guaranteed, while if κ > M , correct execution is guaranteed
with probability ρ at the cost of higher communication
complexity. Thus, this parameter should in general be an
overestimation of the envisioned number of malicious nodes
in the network.

√

8

Algorithm 4: Πp use for txid inclusion veriﬁcation

Input
Input
Input
Input

: mroot — String, merkle root
: txid — String, transaction ID
: blkid — String, block ID
: Πp — Probabilistic Progress Set

1 majority ← (cid:98)|Πp|/2(cid:99) + 1;
2 included ← 0;
3 notIncluded ← 0;
4 for node in Πp do
5

Request Merkle proof from node;
Verify Merkle proof for txid in blkid using mroot;
if node offers valid Merkle proof then
included ← included + 1;

6

7

8

9

10

11

12

13

14

15

16

17

else

notIncluded ← notIncluded + 1;

end
if included = majority then

Declare transaction included;
return;

else if notIncluded = majority then
Declare transaction not included;
return;

end

18
19 end

Since it is excessive to expect that a number of malicious
nodes in the network can be guessed correctly, an alternative
can be offered instead of κ which uses another parameter,
the maximum execution time in seconds tmax specifying
how long a user is willing to wait for the algorithm to
complete. Within a period of tmax, a node running the
algorithm collects nodes. After the speciﬁed timeout occurs,
using the values from Fig. 2, the user is presented with a
table such as Table 1 to choose an adequate probabilistic set
based on the underlying use case.

To use Alg. 3, a user must obtain the transaction ID txid,
the block ID blkid, and the corresponding Merkle root mroot
from an entity issuing the transaction. For example, in a
use case scenario when a merchant ships products after a
buyer has paid for the goods, the buyer sends the above
parameters to the merchant as proof of payment.

The Aurora algorithm has a variety of potential use
cases. For example, if a user is willing to download the
ledger and time is not critical6. The vital parameter for this
use case is tolerance to κ malicious nodes, and thus the user
may decide to construct a Πs that guarantees at least one
honest node while specifying an overestimated κ.

Similarly, if consumer-grade hardware is used to check
the state of a transaction, but it cannot store the entire
ledger, time is again not critical and a user wants a trustless
veriﬁcation without relying on a third-party service. For this
use case, the user will opt to use the Πp to query the state of
a transaction.

Finally, if a user applies a resource-constrained device
(e.g., a mobile phone) which cannot store the entire ledger
and is unwilling to download the header chain, but the user

5. Such structures are present in prominent DLT solutions in the form

of Merkle trees and Merkle proofs.

6. The user is willing to wait for an extended period of time to collect
unique nodes during a gathering. The constructed Πh does not need to
satisfy Constraint 1

still wants to verify that a transaction is contained in a ledger
and is interested in doing so in an efﬁcient manner, the user
should construct a Πp that follows constraints adequate for
this use case, for example Constraint 1. Since in this paper
we focus on applying the Aurora algorithm on resource-
constrained devices, this use case is discussed in more detail
in Section 7.5.

6 COMMUNICATION COMPLEXITY
Let us examine an upper bound on the number of messages
exchanged by node a running the Aurora algorithm as a
function of the desired malicious nodes tolerance κ.

The communication complexity of the algorithm can be

decomposed into two main parts:

1)

2)

the number of messages exchanged during a gath-
ering, and
the number of messages exchanged during commu-
nication with members of Πh.

The total communication complexity can be expressed
as a sum of these values, which we can derive from the
following three equations.

First, a gathering can be described as a linear function
where the domain is the number of steps performed during
a gathering d, the co-domain is the number discoverable
nodes discovered during the gathering |Γ|, and the slope Y
is a random variable. Thus, we write

|Γ| = f (d) = Y ∗ d.

(5)

The average slope Z is a random variable and is the
average of the sample means7 that can be calculated for
any network or topology via Monte Carlo simulation to ap-
proximate a normal distribution. By applying the previous
statement to Eq. (5), we obtain the following

|Γ| = f (d) = Z ∗ d.

(6)

Second, as observed in Fig. 2, the ratio ω = |Γ|

κ when |Πs|
and |Πp| begin behaving like
κ is a function of κ and can
be precomputed8. Thus, the total unique number of nodes
|Γ| can also be expressed as:

√

|Γ| = f (κ) = ω ∗ κ

By joining Eq. (6) and Eq. (7) we get

ω ∗ κ = Z ∗ d =⇒ d =

ω
Z

∗ κ

(7)

(8)

Since there are d steps in a gathering and each step
involves ping and pong messages, the number of messages
exchanged during a gathering can be expressed as

f (κ, Z) = 2 ∗

(cid:25)

(cid:24) ω ∗ κ
Z

(9)

Third, given Constraint 1, the number of requests (pings)
to be sent from the node executing the algorithm to the
members of the constructed Πh can be expressed as follows:

7. Central Limit Theorem (CLT)
8. E.g, for Πp, ω ranges from 55.22 to 1.99 for all relevant values of

the domain.

f (κ) = |Πh| = (cid:98)

√

κ(cid:99)

9

(10)

In other words, the maximum number of messages
exchanged when communicating with members of Πh is
exchanged when all members Πh must be queried. In total,
|Πh| ping and |Πh| pongs messages are exchanged, which
can be expressed as follows:

f (κ) = 2 ∗ (cid:98)

√

κ(cid:99)

(11)

Consequently, the total number of messages exchanged
before the algorithm terminates can be expressed as the sum
of Eq. (9) and Eq. (11):

f (κ, Z) = 2 ∗

(cid:25)

(cid:24) ω ∗ κ
Z

+ 2 ∗ (cid:98)

√

κ(cid:99)

(12)

where ω can be read from Fig. 2 and Z can be set equal
to the threshold on the average number of newly discovered
nodes per draw (see Section 7.3).

7 METHODOLOGY AND EXPERIMENTS

Having established a theoretical basis for the Aurora algo-
rithm performance, we verify our ﬁndings using simula-
tions. In this section, we explain the applied methodology
and present the results of ﬁve distinct experiments per-
formed using the available open-source tools.

The network topology was modelled in accordance with
previous work [31], [33], i.e., by modelling a highly con-
nected core network and a lightly connected edge. The
active Bitcoin IPV4 network slice deﬁned in [31] was chosen
as the basis for the experiments, i.e., all experiments use a
Bitcoin-like network with a total of 6356 nodes.

An adversary was modelled to advertise a spoofed total
difﬁculty in the network that is higher than the canonical
chain difﬁculty. When asked about transaction inclusion, the
adversary always lies. When an adversary replies with a
peer list, it reveals only malicious peers. All malicious nodes
know about each other (the assumption that a malicious
clique is fully connected is supported by [34]). Finally, a
single group of colluding malicious peers was modelled in
the network.

The Simblock [35] simulator was applied to deﬁne a
network topology and extended to enable nodes to send
ping messages and respond with pong messages, as deﬁned
by the Bitcoin protocol [7], [30], [31], [32], [33], where a
ping message maps to a GETADDR message and a pong
request message to an ADDR message. The simulator was
redesigned to rely on the Java streaming API to reduce
its memory requirements and allow parallel execution. All
other parameters are inherited from the Simblock codebase.
Mining did not occur during a simulation run (i.e., the chain
header was not modiﬁed). The Algorithms 2, 3 and 4 were
redesigned to match the underlying discrete event-driven
environment.

7.1 Experiment 1: Algorithm effectiveness when in-
creasing the percentage of malicious network nodes

The goal of this experiment is to evaluate the effectiveness
of the algorithm when gradually increasing the percentage

10

with respect to ledger synchronization. As mentioned ear-
lier, the algorithm provides eventual safety with respect to
blockchain synchronization as long as the ﬁrst contact is not
malicious. That is, if the ﬁrst contact is honest, the algorithm
ensures the presence of at least one honest node (see trace At
least one honest in Fig. 3) and node a will eventually detect
that fraudulent data is provided by malicious nodes and
start synchronization with the available honest node.

7.2 Experiment 2: Number of discoverable nodes as a
function of the number of draws

This experiment investigates how the number of gathering
steps d relates to the number of discoverable nodes, given
an underlying network topology and without the presence
of malicious nodes.

A total of 1000 experiments were conducted where node
a enters a network using a randomly-selected ﬁrst contact
node f c. Node a has unlimited time and resources, and the
halting condition remains the default one.

Fig. 4 shows the average rate at which Γi grows as new
draws are performed, i.e. the node discovery rate for the
executed 1000 runs is depicted as a function of the number
of gathering steps. The shaded region around the average
represents uncertainty and is bounded by one standard
deviation. The results show that the node discovery rate is
irregular and depends on the underlying topology and entry
point. That is, if a node encounters a high-degree node early,
the network expansion is faster and vice versa.

of malicious network nodes, while the node running the
algorithm is assumed to have unlimited time and resources.
No upper bound is placed on the probabilistic set sizes (i.e.,
Constraint 1 has been abolished).

The effectiveness of the algorithm is measured by run-
ning a Monte Carlo simulation of the network while grad-
ually increasing the number of malicious nodes from 0%
to 100%. Malicious nodes are selected uniformly at random
from the existing nodes in the topology and marked as mali-
cious. First contact nodes f c are also selected uniformly and
randomly from malicious nodes to ensure a 99% conﬁdence
level and a 1% margin of error. We use the default halting
condition for each gathering, i.e., the node executing the
algorithm halts the gathering if there are no more nodes to
ask for peer lists. The ultimate goal of the node executing
the algorithm is to synchronize with an honest peer. The
desired malicious node tolerance κ is always set equal to
the maximum value M .

An outcome of a simulation run is classiﬁed as halt if
the algorithm cannot guarantee protection against a desired
number of malicious nodes and the node decides to abort
operation. In contrast, an outcome is classiﬁed as progressed
when the algorithm does not halt, i.e., it has succeeded in
making a decision about a ledger synchronization candi-
date, which may be either honest or malicious.

An outcome is marked as success if the node has chosen
to halt or has progressed to synchronize with an honest
node. Otherwise it is marked as failure since the node
executing the algorithm decided to synchronize with a
malicious node.

The results are displayed in Fig. 3. The algorithm be-
haves as expected, i.e., it maintains a high success rate re-
gardless of the underlying network topology or entry point,
and identiﬁes an honest node for persistent communication
in 99.9% of cases. The algorithm consistently halts when the
number of malicious nodes in the network exceeds 50% in
accordance with Assumption 5: It halts only when the ﬁrst
contact is malicious and the gathering could not collect a
desired number of nodes.

Fig. 4. The average and standard deviation of the node discovery rate
with an increase of the number of gathering steps during 1000 experi-
ments.

The results lead us to two conclusions. First, the number
of newly discovered nodes at the beginning of a gathering
shows a linear dependence on the number of gathering
steps. As the gathering progresses, the expansion rate slows
down, which means that new nodes are harder to ﬁnd.
Second, after a certain point in time, the continuation of
a gathering makes little sense, as very few, if any, new
nodes are discovered. From a pragmatic point of view, it
is unreasonable to discover the entire network before the
algorithm terminates. The communication complexity of the
gathering can be reduced by introducing a more complex

Fig. 3. Outcomes of the algorithm with an increase of the percentage of
malicious network nodes.

The experiment highlights the idea of eventual safety

halting condition which we investigate in the following
experiment.

7.3 Experiment 3: Average number of new nodes dis-
covered in a draw

After studying the algorithm effectiveness when node a has
unlimited resources, we introduce additional constraints to
test the algorithm in a more realistic scenario. This exper-
iment examines whether a custom halting condition based
on the average number of newly discovered nodes can be
constructed to reduce the communication complexity of the
gathering in terms of the number of gathering steps, with-
out signiﬁcantly affecting the number of nodes discovered
during a gathering.

Node a enters a network using a randomly-selected ﬁrst
contact node f c and monitors the average number of newly
discovered nodes in a draw (at least 10 draws are needed
before an average is calculated). If the average number of
newly discovered nodes in a draw falls below a threshold,
the node halts. The threshold varies from 1 to 500, and for
each threshold, a total of 1000 experiments is performed,
based on which the average and standard deviation of the
percentage of the network discovered is calculated.

Fig. 5 shows the average of the percentage of the network
discovered with an increase of the threshold for the average
number of newly discovered nodes. The shaded region
around the average represents uncertainty and is bounded
by one standard deviation. The experiment conﬁrms the
expected behavior, i.e., larger thresholds are not reliable in
terms of percentage of network discovered, while smaller
thresholds provide a more consistent result, regardless of
the number of nodes known by the ﬁrst contact node.

Fig. 5. The average and the uncertainty of the percentage of the network
nodes seen at the end of a gathering with an increase of the threshold
for the average number of newly discovered nodes in a draw.

Since Fig. 5 shows that when introducing a minimal
threshold on the average number of newly discovered nodes
in a draw results with a high percentage of the network
nodes discovered, we continue by examining a setup when
the threshold is set to 15 (i.e., the node running the al-
gorithm must discover on average at least 15 new nodes

11

Fig. 6. Percentage of network nodes seen when the threshold on the
average number of newly discovered nodes in a draw is set to 15.

after each draw). When such a threshold is chosen, the
node discovers on average 98.00% of network nodes with
a standard deviation of 0.911%, as shown in Fig. 6. This
particular threshold is used in the following experiments,
as we consider the result beneﬁcial for a real world usage
scenario leading to a reliable result in terms of the percent-
age of network nodes discovered. Note that the threshold
chosen in the scope of this experiments is not applicable
to any network. The method for obtaining the threshold is
generic and should be repeated for a new network topology.

7.4 Experiment 4: The upper bound on the number of
generated messages

This experiment tests the validity of the theoretical results
for communication complexity expressed by Eq. (12) in a
real network with malicious nodes. Hence the experiment
investigates the number of messages generated during each
simulation run.

We ran two simulation scenarios and for each scenario
1000 experiments were performed where node a enters the
network using a randomly-selected ﬁrst contact node f c.
The threshold on the average number of newly discovered
nodes per draw is set to 15 in both scenarios9. In each exper-
iment, the node running the algorithm attempts to construct
and query a probabilistic progress set Πp. The construc-
tion and use of a probabilistic safe set Πs is intentionally
omitted here, as it is much more difﬁcult to construct a Πp,
making Πp more suitable for this experiment, which can be
viewed as a stress test. Nevertheless, Eq. (12) can be applied
regardless of the probabilistic set type (safe of progress).
During the experiment we count the number of messages
exchanged before the algorithm terminates, either because
it managed to progress or because it halted.

In the ﬁrst scenario, we set κ = M = 1272. In this
setting, the probabilistic set Πp can be constructed and Con-
straint 1 can be met quite easily. Eq. (12) gives us an upper
bound of 728 exchanged messages. In the second scenario,

9. Note that this value has the same semantics as Z, which is used

in Eq. (12).

(cid:19)(cid:17)(cid:28)(cid:24)(cid:19)(cid:17)(cid:28)(cid:25)(cid:19)(cid:17)(cid:28)(cid:26)(cid:19)(cid:17)(cid:28)(cid:27)(cid:19)(cid:17)(cid:28)(cid:28)(cid:20)(cid:19)(cid:20)(cid:19)(cid:19)(cid:21)(cid:19)(cid:19)(cid:22)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:24)(cid:19)(cid:19)3HUFHQW$PRXQWwe set κ = M = 1614. Compared to the ﬁrst setting, this one
is more demanding: a node must collect at least 6000 total
nodes in a gathering in order to satisfy Constraint 1. Eq. (12)
gives us an upper bound of 880 exchanged messages.

The results are shown in Fig. 7. In all simulation runs,
the actual number of generated messages is smaller then or
equal to the corresponding analytic bound, which strongly
suggests that Eq. (12) is valid.

is adequate for resource-constrained devices when similar
network conditions can be expected.

12

Fig. 7. Comparing the actual number of generating messages with the
analytical bound on communication complexity. Markers (dots) mark
one or more gatherings that ended with the corresponding number of
exchanged messages.

7.5 Experiment 5: Transaction inclusion veriﬁcation for
light clients

This experiment investigates the effectiveness of the algo-
rithm on a Bitcoin-like network containing a total of 6356
nodes, with a gradual increase in the total number of ma-
licious nodes, given that the node running the algorithm
does not have unlimited time and resources. Thus, this
experiment examines a realistic usage scenario in which, for
instance, a user has only a resource-constrained device (e.g.,
a mobile phone), but still wants to verify that a transaction is
contained in a ledger and is interested in doing so efﬁciently
and trustworthy.

The simulation setup and methodology is the same as
in Section 7.1, with two key differences. First, Constraint 1
must be satisﬁed — if the node executing the algorithm is
unable to respect the given constraint, it will not construct a
probabilistic set and will consequently halt. Second, the halt-
ing condition is changed to take into account the threshold
for the average number of unique nodes per draw, which
is set to 15, but only if 10 or more draws were previously
made.

The results shown in Fig. 8 conﬁrm that the algorithm ex-
ecutes within the expected success rate with good progress
while the number of reachable nodes which are malicious is
below one quarter. Similarly to Fig. 3, the algorithm behaves
as expected and identiﬁes an honest node for transient
or persistent communication in 99.9% of the trials, while
halting consistently when less than a quarter of nodes in
Γ are malicious. Thus, we conclude that the algorithm

Fig. 8. Outcomes of the algorithm in a realistic setup when Constraint 1
is satisﬁed and the average message size threshold is set to 15, while
increasing the malicious number of network nodes.

After verifying our work on a Bitcoin-like network, we
draw three main conclusions. First, the algorithm behaves
as expected, i.e., it manages to download a correct ledger,
infer a state of a transaction, or halt in ρ percent of the
cases. Second, since the number of detected nodes in pong
messages decreases as the number of steps increases, it
is useful to reduce the number of steps executed in a
gathering. This can be done by halting the gathering when
the average number of newly discovered nodes in a draw
falls below a threshold. Third, the algorithm can be applied
on a resource-constrained device in a realistic Bitcoin-like
network when about a quarter of the network nodes are
malicious. Comparing the deterministic and probabilistic
variants, the probabilistic approach generates one to two
orders of magnitude fewer messages when inferring the
state of the ledger.

8 CHALLENGES AND FUTURE WORK

The most pressing challenge in a production environment
concerns the responses to ping requests where network
nodes are expected to respond with their peer list. Currently
in Bitcoin, only publicly reachable nodes with a free slot
send such replies [36]. We can approach the problem in three
different ways. First, as part of a temporary solution, if a
node does not respond because a free slot is unavailable,
we can ﬁlter out that node and contact another node. This
will generate additional steps for the algorithm. The second
solution requires a change in the node protocol so that nodes
respond to ping messages regardless of the number of free
slots. Such a change would not affect the underlying con-
sensus protocol and can be presented as an opt-in feature.
However, such a change makes nodes vulnerable to denial-
of-service attacks. If an attack is detected, the affected node
may simply decide not to respond to ping requests for a
while. Third, as a persistent solution, it is likely that more
publicly reachable nodes will emerge as DLT becomes more

(cid:19)(cid:21)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:25)(cid:19)(cid:19)(cid:27)(cid:19)(cid:19)(cid:201) (cid:20)(cid:21)(cid:26)(cid:21)(cid:201) (cid:20)(cid:25)(cid:20)(cid:23)(cid:201) (cid:20)(cid:21)(cid:26)(cid:21)(cid:3)ERXQG(cid:201) (cid:20)(cid:25)(cid:20)(cid:23)(cid:3)ERXQG1XPEHU(cid:3)RI(cid:3)H[FKDQJHG(cid:3)PHVVDJHV2FFXUUHQFH(cid:19)(cid:19)(cid:17)(cid:20)(cid:19)(cid:17)(cid:21)(cid:19)(cid:17)(cid:22)(cid:19)(cid:17)(cid:23)(cid:19)(cid:19)(cid:17)(cid:21)(cid:19)(cid:17)(cid:23)(cid:19)(cid:17)(cid:25)(cid:19)(cid:17)(cid:27)(cid:20))DLOXUH(cid:3)UDWH+DOWLQJ(cid:3)UDWH3URJUHVV(cid:3)UDWH6XFFHVV(cid:3)UDWH3HUFHQWDJH(cid:3)RI(cid:3)PDOLFLRXV(cid:3)QRGHV(cid:3)LQ(cid:3)WKH(cid:3)QHWZRUN(cid:3)(cid:16)(cid:3)03HUFHQWDJH(cid:3)RI(cid:3)DOO(cid:3)UXQVwidespread and mature. As a result, more peers will be
available (e.g., each BTC node can connect to 8 outgoing
peers and up to 117 incoming peers [33], [36]), to partially
mitigate the problem.

Furthermore, one may argue that the gathering process
is resource intensive and time consuming. However,
it
provides trustless and decentralized capabilities which are
otherwise unavailable in today’s DLT networks. The caching
of received peer lists and their reuse can help to mitigate the
problem, while a gathering can also be performed while the
device is idle or charging. Sets can also be shared by social
consensus (e.g., by a trusted person, friend, family member,
etc.) and then used for future queries.

Finally, there is the question of incentive. Why would
a node act as a serving node for other nodes running
the Aurora protocol? The information about neighboring
peers and the ledger head is already shared voluntarily
by nodes, however with a limit on the maximum number
of concurrent node connections. Furthermore, responses
regarding the inclusion of transactions can be classiﬁed
as simple requests comparable to peer list responses, so
we assume that a node would be willing to share such
information without additional incentives. If at any point
our assumption proves to be wrong, the solution can be
adapted to provide incentives for full nodes to collaborate,
e.g., in the form of micro-payments for each transaction
inclusion request.

As our future work, some of the open questions have
already been mentioned, namely, the impact of ρ on the size
of probabilistic sets and the use case, and the study of a time-
based halting condition. We also want to study the impact of
mining on the execution of the algorithm. We could compen-
sate for new blocks generated during the execution of the
algorithm by querying for blocks beyond the ledger head
and then checking if there is a common ancestor. In addition,
the algorithm would beneﬁt from parallel execution of the
gathering, the effects of which can be studied in a controlled
environment using a prominent distributed ledger client
modiﬁed to run the Aurora algorithm.

9 CONCLUSION

The Aurora algorithm presented in this paper allows a new
node entering a DLT network that contains |M | malicious
nodes to discover sets of nodes that have a high probability
of containing at least 1 or 1 + |M | honest nodes. Such sets
can then be used by a new node to synchronize with the
latest ledger or to determine the state of ledger transaction.
The algorithm can be divided into two main parts. First,
the algorithm constructs a Directed Acyclic Graph over a
network topology for the purpose of node discovery using
response messages from contacted nodes conveying lists of
their neighbors. Second, the algorithm selects a subset of
the collected nodes to be tolerant to κ malicious nodes with
probability ρ by relying on the hypergeometric distribution.
In this work, we study a scenario where bootstrap nodes
are unavailable or malicious, i.e., their behavior is hostile
and they conspire against a victim that enters the network.
The goal of such an adversary can range from denial of
service (i.e., wasting the victim’s resources) to withholding

13

the canonical truth (i.e., the longest chain) from the vic-
tim. In such an environment, we enable decentralized and
trustless ledger synchronization and attempt to reduce the
victim’s resource consumption by providing a probabilistic
algorithm that detects an honest peer with probability ρ
for subsequent interaction. Speciﬁcally, the algorithm either
allows ledger synchronization to continue if it determines
that an honest bootstrap candidate has been found, or aborts
the process if no such guarantee can be made.

The second application of the Aurora algorithm allows
a device, under the same conditions and with the same
guarantees as for trustless ledger synchronization, to verify
that a transaction has been included in the ledger without
having to download the entire ledger or ledger header, or to
trust a central authority.

We compare the Aurora algorithm with existing solu-
tions, provide the pseudocode of the algorithm, explain
the prerequisites for running the algorithm, provide an
analytical expression for communication complexity, and
highlight two prominent applications of the algorithm. We
evaluate the algorithm using Monte Carlo simulations on a
Bitcoin IPV4 network slice. We used an open-source and dis-
crete event-driven blockchain simulator to run experiments
which conﬁrmed that the experimental results are consistent
with our analytical ﬁndings.

Our experimental results show that the Aurora algo-
rithm ensures decentralized and trustless DLT interaction
of nodes running on both consumer-grade hardware and
resource-constrained devices. In a realistic scenario where
up to a quarter of the nodes in the network are malicious
and actively attempt to subvert a new node joining the
network, the algorithm is able to correctly synchronize
the ledger state, infer the state of a transaction, or other-
wise halt with high probability guarantees. Comparing our
probabilistic algorithm with its deterministic variant, the
probabilistic approach is much more efﬁcient and generates
one to two orders of magnitude fewer messages.

Our solution thus lowers the barrier to entry that DLT
imposes on consumer-grade hardware and improves net-
work decentralization, while allowing changes to be im-
plemented in existing solutions without changing to the
consensus protocol.

ACKNOWLEDGMENTS
This work has been supported in part by Croatian Sci-
ence Foundation under the project IP-2019-04-1986 (IoT4us:
Human-centric smart services in interoperable and decen-
tralized IoT environments).

REFERENCES

[1]

J. Ghosh, “The blockchain: Opportunities for research in informa-
tion systems and information technology,” 2019.

[2] X. Zheng, Y. Zhu, and X. Si, “A survey on challenges and pro-
gresses in blockchain technologies: A performance and security
perspective,” Applied Sciences, vol. 9, no. 22, p. 4731, 2019.

[3] A. Gabizon, K. Gurkan, P.

Jovanovic, G. Konstantopoulos,
A. Oines, M. Olszewski, M. Straka, and E. Tromer, “Plumo: To-
wards scalable interoperable blockchains using ultra light valida-
tion systems,” 2020.

[4] A. Zamyatin, Z. Avarikioti, D. Perez, and W. J. Knottenbelt, “Tx-
chain: Efﬁcient cryptocurrency light clients via contingent trans-
action aggregation,” in Data Privacy Management, Cryptocurrencies
and Blockchain Technology. Springer, 2020, pp. 269–286.

[5] Y. Lu, Q. Tang, and G. Wang, “Generic superlight client for
permissionless blockchains,” in European Symposium on Research
in Computer Security. Springer, 2020, pp. 713–733.
I. Homoliak, S. Venugopalan, Q. Hum, and P. Szalachowski, “A
security reference architecture for blockchains,” in 2019 IEEE
International Conference on Blockchain (Blockchain).
IEEE, 2019, pp.
390–397.

[6]

[7] E. Heilman, A. Kendler, A. Zohar, and S. Goldberg, “Eclipse
attacks on bitcoin’s peer-to-peer network,” in 24th {USENIX}
Security Symposium ({USENIX} Security 15), 2015, pp. 129–144.
[8] M. Saad, J. Spaulding, L. Njilla, C. Kamhoua, S. Shetty, D. Nyang,
and D. Mohaisen, “Exploring the attack surface of blockchain: A
comprehensive survey,” IEEE Communications Surveys & Tutorials,
vol. 22, no. 3, pp. 1977–2008, 2020.

[9] F. M. Benˇci´c, A. Hrga, and I. P. ˇZarko, “Aurora: a robust and trust-
less veriﬁcation and synchronization algorithm for distributed
ledgers,” in 2019 IEEE International Conference on Blockchain
(Blockchain).

IEEE, 2019, pp. 332–338.

[10] W.-M. Lee, “Beginning ethereum smart contracts programming,”

With Examples in Python, Solidity and JavaScript, 2019.

[11] J. Kwon, “Tendermint: Consensus without mining,” Draft v. 0.6,

fall, vol. 1, no. 11, 2014.

[12] L. Xu, L. Chen, Z. Gao, S. Xu, and W. Shi, “Efﬁcient pub-
lightweight users,” arXiv preprint

for

lic blockchain client
arXiv:1811.04900, 2018.

[13] D. Leung, A. Suhl, Y. Gilad, and N. Zeldovich, “Vault: Fast

bootstrapping for the algorand cryptocurrency.” in NDSS, 2019.

[14] J. Chen and S. Micali, “Algorand,” arXiv preprint arXiv:1607.01341,

2016.

[15] B. B ¨unz, L. Kiffer, L. Luu, and M. Zamani, “Flyclient: Super-light
clients for cryptocurrencies,” in 2020 IEEE Symposium on Security
and Privacy (SP).

IEEE, 2020, pp. 928–946.
[16] D. Letz, “Blockquick: Super-light client protocol for blockchain
validation on constrained devices.” IACR Cryptol. ePrint Arch., vol.
2019, p. 579, 2019.

[17] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman, “Sybilguard:
defending against sybil attacks via social networks,” in Proceedings
of the 2006 conference on Applications, technologies, architectures, and
protocols for computer communications, 2006, pp. 267–278.

[18] Q. Ding, N. Katenka, P. Barford, E. Kolaczyk, and M. Crovella,
“Intrusion as (anti) social communication: characterization and
detection,” in Proceedings of the 18th ACM SIGKDD international
conference on Knowledge discovery and data mining, 2012, pp. 886–
894.

[19] H.-H. Chen and C. L. Giles, “Ascos: an asymmetric network
structure context similarity measure,” in 2013 IEEE/ACM Interna-
tional Conference on Advances in Social Networks Analysis and Mining
(ASONAM 2013).

IEEE, 2013, pp. 442–449.

[20] S. Chowdhury, M. Khanzadeh, R. Akula, F. Zhang, S. Zhang,
H. Medal, M. Marufuzzaman, and L. Bian, “Botnet detection using
graph-based feature clustering,” Journal of Big Data, vol. 4, no. 1,
pp. 1–23, 2017.

[21] J. Zhang, Y. Xiang, Y. Wang, W. Zhou, Y. Xiang, and Y. Guan, “Net-
work trafﬁc classiﬁcation using correlation information,” IEEE
Transactions on Parallel and Distributed systems, vol. 24, no. 1, pp.
104–117, 2012.

[22] J. Zhang, C. Chen, Y. Xiang, W. Zhou, and A. V. Vasilakos, “An
effective network trafﬁc classiﬁcation method with unknown ﬂow
detection,” IEEE Transactions on Network and Service Management,
vol. 10, no. 2, pp. 133–147, 2013.

[23] K. W ¨ust and A. Gervais, “Ethereum eclipse attacks,” ETH Zurich,

Tech. Rep., 2016.

[24] Y. Marcus, E. Heilman, and S. Goldberg, “Low-resource eclipse
attacks on ethereum’s peer-to-peer network.” IACR Cryptol. ePrint
Arch., vol. 2018, p. 236, 2018.

[25] G. Xu, B. Guo, C. Su, X. Zheng, K. Liang, D. S. Wong, and H. Wang,
“Am i eclipsed? a smart detector of eclipse attacks for ethereum,”
Computers & Security, vol. 88, p. 101604, 2020.

[26] M. Apostolaki, A. Zohar, and L. Vanbever, “Hijacking bitcoin:
Routing attacks on cryptocurrencies,” in 2017 IEEE Symposium on
Security and Privacy (SP).

IEEE, 2017, pp. 375–392.

[27] M. Al-Bassam, A. Sonnino, and V. Buterin, “Fraud and
data availability proofs: Maximising light client security and
scaling blockchains with dishonest majorities,” arXiv preprint
arXiv:1809.09044, 2018.

[28] S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,”

Manubot, Tech. Rep., 2019.

14

[29] A. Rivadulla, “Mathematical statistics and metastatistical analy-

sis,” Erkenntnis, vol. 34, no. 2, pp. 211–236, 1991.

[30] A. Biryukov, D. Khovratovich, and I. Pustogarov, “Deanonymisa-
tion of clients in bitcoin p2p network,” in Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Security,
2014, pp. 15–29.

[31] V. Deshpande, H. Badis, and L. George, “Btcmap: Mapping bitcoin
peer-to-peer network topology,” in 2018 IFIP/IEEE International
Conference on Performance Evaluation and Modeling in Wired and
Wireless Networks (PEMWN).

IEEE, 2018, pp. 1–6.

[32] A. Miller, J. Litton, A. Pachulski, N. Gupta, D. Levin, N. Spring,
and B. Bhattacharjee, “Discovering bitcoin’s public topology and
inﬂuential nodes,” et al, 2015.

[33] J. Miˇsi´c, V. B. Miˇsi´c, X. Chang, S. G. Motlagh, and M. Z. Ali, “Mod-
eling of bitcoin’s blockchain delivery network,” IEEE Transactions
on Network Science and Engineering, vol. 7, no. 3, pp. 1368–1381,
2019.

[34] D. Dagon, G. Gu, C. P. Lee, and W. Lee, “A taxonomy of botnet
structures,” in Twenty-Third Annual Computer Security Applications
Conference (ACSAC 2007).

IEEE, 2007, pp. 325–339.

[35] Y. Aoki, K. Otsuki, T. Kaneko, R. Banno, and K. Shudo, “Simblock:
A blockchain network simulator,” in IEEE INFOCOM 2019-IEEE
Conference on Computer Communications Workshops (INFOCOM WK-
SHPS).

IEEE, 2019, pp. 325–329.

[36] L. Wang and I. Pustogarov, “Towards better understanding of

bitcoin unreachable peers,” arXiv preprint arXiv:1709.06837, 2017.

Federico Matteo Ben ˇci ´c received the M.Sc.
degree in information and communication tech-
nology from the University of Zagreb, Faculty of
Electrical Engineering and Computing in 2017,
where he is currently pursuing the Ph.D. degree
with the Department of Telecommunications. He
is currently an Assistant with the Department of
Telecommunications, Faculty of Electrical Engi-
neering and Computing, University of Zagreb.
His interests include applications of DLT in the
IoT area.

Ivana Podnar ˇZarko is Full Professor at the
University of Zagreb, Faculty of Electrical Engi-
neering and Computing, Croatia (UNIZG-FER)
where she teaches distributed information sys-
tems. She received her B.Sc., M.Sc. and Ph.D.
degrees in electrical engineering from UNIZG-
FER, in 1996, 1999 and 2004, respectively. She
is afﬁliated with the Department of Telecommu-
nications at UNIZG-FER from 1997. She was a
guest researcher and research associate at the
Technical University of Vienna, Austria, and a
postdoctoral researcher at the Swiss Federal Institute of Technology in
Lausanne (EPFL), Switzerland. She was promoted to Full Professor in
December 2017. She has participated in a number of research projects
funded by national sources and EU funds, and is currently leading
the UNIZG-FER Internet of Things Laboratory. Ivana Podnar ˇZarko is
the Technical Manager of the H2020 project symbIoTe: Symbiosis of
smart objects across IoT environments, and is currently participating
in the Centre of Research Excellence for Data Science and Advanced
Cooperative Systems, which is the ﬁrst national center of excellence in
the ﬁeld of technical sciences in Croatia. She has co-authored more
than 60 scientiﬁc journal and conference papers in the area of large-
scale distributed systems, IoT, and Big data processing, and has as a
program committee member for a number of international conferences
and workshops. Prof. Ivana Podnar ˇZarko is a member of IEEE and was
the Chapter Chair of IEEE Communications Society, Croatia Chapter
(2011— 2014). She has received the award for engineering excellence
from the IEEE Croatia Section in 2013.

15

honest set which contains a majority of honest
nodes with probability ρ

Probabilistic Safe Set For a given Γ containing κ malicious
nodes, where |Γ| > κ, Πs is a probabilistic honest
set which contains at least one honest node with
probability ρ

GLOSSARY
K Number of success in the population
M Number of malicious nodes in the network
N Population size parameter for the construction of a

hypergeometric distribution

S A set of all network nodes
X Random variable
Y Random variable denoting the number of unique nodes

found throughout a single gathering

Z Random variable denoting the average number of unique
nodes found throughout a single gathering, Z ∼
N (µ, σ2)
∆p Deterministic Progress Set
∆s Deterministic Safe Set
∆ A shorthand for ∆h when h is implied from context or

not relevant

Γ Subset of network nodes encountered in a gathering
Πp Probabilistic Progress Set
Πs Probabilistic Safe Set
Π A shorthand for Πh when h is implied from context or

not relevant

ℵ Response to a peer list request, a of node identiﬁers
∆h Deterministic Honest Set
Πh Probabilistic Honest Set
Γi Subset of network nodes encountered up to step i
κ Desired malicious node tolerance, expressed as an abso-

lute number

ω Measured ratio between |Γ| and κ when the correspond-
ing probabilistic sets size starts to behave as a sub-
linear function of κ

ρ Probability guarantee on probabilistic sets correctness
a A new node entering a distributed ledger network
blkid A block identiﬁer
d Number of draws made in a gathering
f c First contact node identiﬁer
hc Halting condition encapsulation
k Number of success in the sample
mroot A Merkle root
nxtDraw Identiﬁer of a next draw in a gathering
n The sample size
tmax Maximum execution time in seconds
txid A transaction identiﬁer
x Random variable occurrence
|Γ| The number of unique nodes discovered during a
gathering, also the population size used for hy-
pergeometric set construction

Deterministic Progress Set For a given Γ containing κ
malicious nodes, where |Γ| > 2κ, ∆p is a deter-
ministic honest set which contains a majority of
honest nodes and its size is at least 2κ + 1
Deterministic Safe Set For a given Γ containing κ malicious
nodes, where |Γ| > κ, ∆s is a deterministic honest
set which contains at least one honest node and its
size is at least κ + 1

draw A step performed during network exploration

gathering The process of exploring the network

Probabilistic Progress Set For a given Γ containing κ mali-
cious nodes, where |Γ| > 2κ, Πp is a probabilistic

