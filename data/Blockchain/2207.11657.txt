FileInsurer: A Scalable and Reliable Protocol
for Decentralized File Storage in Blockchain

Hongyin Chen‚àó‚Ä†, Yuxuan Lu‚àó‚Ä°, Yukun Cheng¬ß¬∂
‚Ä†‚Ä°Center on Frontiers of Computing Studies, Peking University, Beijing, China
¬ßSuzhou University of Science and Technology, Suzhou, China
Email: ‚Ä†chenhongyin@pku.edu.cn, ‚Ä°yx lu@pku.edu.cn, ¬∂ykcheng@amss.ac.cn

2
2
0
2

l
u
J

4
2

]

R
C
.
s
c
[

1
v
7
5
6
1
1
.
7
0
2
2
:
v
i
X
r
a

Abstract‚ÄîWith the development of blockchain applications,
the requirements for Ô¨Åle storage in blockchain are increasing
rapidly. Many protocols, including Filecoin, Arweave, and Sia,
have been proposed to provide scalable decentralized Ô¨Åle storage
for blockchain applications. However, the reliability is not well
promised by existing protocols. Inspired by the idea of insurance,
we innovatively propose a decentralized Ô¨Åle storage protocol in
blockchain, named as FileInsurer, to achieve both scalability
and reliability. While ensuring scalability by distributed storage,
FileInsurer guarantees reliability by enhancing robustness and
fully compensating for the Ô¨Åle loss. SpeciÔ¨Åcally, under mild
conditions, we prove that no more than 0.1% value of all Ô¨Åles
should be compensated even if half of the storage collapses.
Therefore, only a relatively small deposit needs to be pledged by
storage providers to cover the potential Ô¨Åle loss. Because of lower
burdens of deposit, storage providers have more incentives to
participate in the storage network. FileInsurer can run in the top
layer of the InterPlanetary File System (IPFS), and thus it can be
directly applied in Web 3.0, Non-Fungible Tokens, and Metaverse.
Storage, Blockchain
application, Mechanism Design, Decentralized System, Insurance

Terms‚ÄîDecentralized

Index

File

I. INTRODUCTION

File storage is a fundamental issue in distributed systems.
Recently, the developments of Web 3.0 [1], Non-Fungible
Tokens (NFTs) [9, 22], and Metaverse [20] have raised high
requirements on reliability and accessibility of Ô¨Åle storage. For
example, the metadata of NFTs should be veriÔ¨Åable and acces-
sible in NFT markets, as the values of NFTs disappear if the
metadata is lost. Billions of metadata generated by blockchain
applications are searching for reliable storage services.

Traditionally, people store Ô¨Åles in personal storage or cloud
storage service. However, personal storage struggles to keep
Ô¨Åles secure and accessible. Additionally, cloud storage lacks
transparency and trust [5]. It is hard for users to recognize
how many backups of their Ô¨Åles should be stored to guarantee
security. Moreover, Ô¨Åle loss often occurs in cloud storage.

Due to the defects of personal storage and cloud storage,
more and more users choose to store Ô¨Åles in the blockchain-
based Decentralized Storage Networks
such as
Sia [21], Filecoin [4], Arweave [24], and Storj [23]. In a DSN,

(DSNs)

This work has been performed with support from the National Natural
Science Foundation of China (No. 11871366), Qing Lan Project of Jiangsu
Province, China, and the Algorand Foundation Grants Program

‚àó These authors contributed to the work equllly and should be regarded

as co-Ô¨Årst authors.

¬ß Yukun Cheng is the corresponding author.

storage providers contribute their available hard disks to store
Ô¨Åles from clients and then earn proÔ¨Åts. The storing, discarding,
and storing state-changing events of Ô¨Åles are recorded in the
blockchain. Files can be stored by multiple storage providers
to enhance security. Additionally, in Filecoin, backups are
changed to be replicas, once they have been proved by proof-
of-replication (PoRep). PoRep well resists Sybil attacks [13]
by a storage provider, who may pretend to store multiple
backups by forging multiple identities, while she actually
only stores one backup. PoRep can also be used to ensure
providers cannot cheat on the available storage space.

However, the existing DSN protocols do not well promise
the reliability. In DSN, there are always Ô¨Åles only stored by a
small part of storage providers due to the issue of scalability.
Therefore, it is impossible to completely avoid loss of Ô¨Åles.
When Ô¨Åles are lost, the owners of these Ô¨Åles only receive
little compensation.

In this paper, we aim to enhance the reliability of
decentralized Ô¨Åle storage from the perspective of economic
incentive approaches. For the Bitcoin Blockchain [17], the
most success is to apply the economic incentive approach,
by awarding a certain amount of token to encourage miners
to actively mine. Thus, in the era of blockchain, the issue of
economic approaches is getting more and more important. We
build a decentralized insurance scheme on Ô¨Åles stored in DSN
to protect the interests of users when their Ô¨Åles are lost. Under
the insurance scheme, storage providers need to pledge a
deposit before storing Ô¨Åles. If a Ô¨Åle is lost, which means that all
providers storing this Ô¨Åle are corrupted, the total deposit from
these providers can fully compensate for the loss of this Ô¨Åle.
We hope that the deposit should be small to incentivize
participants to contribute their storage space. Let us denote
deposit ratio to be the ratio of the sum of deposits to the
total value of Ô¨Åles. Chen et. al. [11] Ô¨Årstly studied how to
decrease the deposit ratio in the decentralized custody scheme
with insurance. However, the methodology in [11] cannot be
directly applied in our scenario. The reason is that storage
providers and Ô¨Åles change over time in DSN, while [11] is
only suitable for static setting. Our approach is to achieve
provable robustness by ensuring storage randomness. Storage
randomness requires the locations of replicas are randomly
selected by DSN, such that
these locations are uniformly
distributed. Consequently, the attackers must corrupt a consid-

 
 
 
 
 
 
erable portion of providers even if they only want to destroy all
backups of a small portion of Ô¨Åles. Therefore, the randomness
can promises that only a relatively small deposit needs to be
pledged by storage providers to cover the potential Ô¨Åle loss.

Main Contributions

We propose FileInsurer, a novel design for blockchain-based
Decentralized Storage Network, to achieve both scalability and
reliability of Ô¨Åle storage. In our protocol, storage providers
are required to pledge deposits to registered sectors and the
locations of Ô¨Åles are randomly selected. To further ensure
storage randomness, locations of Ô¨Åles‚Äô replicas shall change
from time to time because the list of sectors is dynamic.

Our protocol advances the technology of decentralized Ô¨Åle

storage in the following three aspects.

randomness. FileInsurer

‚Ä¢ Firstly, FileInsurer supports dynamic content stored in
sectors with low cost, which is necessary to ensure
storage
deploys Dynamic
Replication (DRep) to support adding and refreshing
stored Ô¨Åles. DRep is also able to resist Sybil attacks and
make sure the free space of sectors is indeed available.
‚Ä¢ Secondly, FileInsurer can achieve provable robustness.
In FileInsurer, Ô¨Åles are stored as replicas in sectors.
Naturally, a Ô¨Åle is missing, if and only if all replicas
of this Ô¨Åle have been destroyed. A sector is collapsed,
as long as any bit in this sector is lost. Under mild
conditions, we prove that no more than 0.1% value of
all Ô¨Åles are lost even if half of the storage collapses.
‚Ä¢ Thirdly, FileInsurer implements an insurance scheme on
DSN that can provide full compensation for the loss of
those missing Ô¨Åles. The compensation is covered by the
deposit of all crashed storage sectors. Our theoretical
analysis indicates that only a small deposit ratio is
needed to cover all of the Ô¨Åle loss in FileInsurer.
To the best of our knowledge, FileInsurer is the Ô¨Årst DSN
protocol that can provide full compensation for the Ô¨Åle loss
and has provable robustness.

Paper Organization

The rest of this paper is organized as follows. Section II
introduces the related works of decentralized storage protocols.
In Section III, we describe the structure and components
of FileInsurer protocol. Then, we continue to introduce the
protocol design of FileInsurer in Section IV. In Section V, we
propose the theoretical analysis on the scalability, robustness,
and deposit issue of our protocol. We also compare FileInsurer
with other blockchain-based decentralized storage protocols.
In addition, some practical problems in FileInsurer are
detailedly discussed in Section VI. Finally, we summarize
our protocol and raise some open problems in Section VII.

II. RELATED WORKS

A. InterPlanetary File System (IPFS)

The InterPlanetary File System (IPFS) is a peer-to-peer
distributed Ô¨Åle system that seeks to connect all computing
devices with the same system of Ô¨Åles [2]. Files, identiÔ¨Åed

by their cryptographic hashes, are stored and exchanged by
nodes in IPFS. Nodes also provide the service of retrieving
Ô¨Åles to earn proÔ¨Åts through BitSwap protocol. The routing of
IPFS is achieved by Distributed Hash Tables (DHTs), which
is an efÔ¨Åcient way to locate data among IPFS nodes. Based
on BitSwap and DHTs, IPFS builds an Object Merkle DAG
which allows participants to address Ô¨Åles through IPFS paths.

B. FileCoin

Filecoin builds a blockchain-based Decentralized Storage
Network which runs in the top layer of IPFS [4]. There are
three types of participants in Filecoin, which are clients,
storage miners, and retrieval miners. SpeciÔ¨Åcally, clients pay
to store and retrieve Ô¨Åles, storage miners earn proÔ¨Åts by
registering sectors to offer storage, and retrieval miners earn
proÔ¨Åts by serving data to clients.

1) Proof-of-Replication (PoRep): PoRep [3] is a kind of
proof-of-storage scheme deployed in Filecoin. In the PoRep
the prover Ô¨Årstly generates a replica of Ô¨Åle D,
scheme,
denoted by RD
ek, through the process of PoRep.setup(D,ek).
ek is a randomly chosen encryption key that with ek, RD
ek
can be encrypted from D, and D can be decrypted from RD
ek.
The prover then submits the hash root of RD
ek to the DSN.
Finally, the prover proves that RD
ek is a replica of D with
encryption key ek via SNARK.

The veriÔ¨Åcation of SNARK is very efÔ¨Åcient. However,
the calculation of RD
ek would take a lot of time because it
can‚Äôt be parallelized. Additionally, the calculation of SNARK
would consume lots of computation resources.

2) Filecoin Sectors: In Filecoin, sectors are divided into
sealed ones and unsealed ones1. Only sealed sectors are
part of the Filecoin network and can get rewards of storage.
Unsealed sectors only contain raw data, and a sealed sector
can be registered from an unsealed sector by PoRep. Storage
miners would pledge deposits when registering a sector, but
when the sector crashes, that deposit is burnt other than used
for compensating the Ô¨Åle loss to clients.

When registering an unsealed sector, if the sector is not
full, the rest space of the sector would be Ô¨Ålled with zeros
before encoding by PoRep. If a sealed sector doesn‚Äôt contain
any Ô¨Åles, which means the contents of that sector are all
zeros when registering, it‚Äôs called a committed capacity (CC).
Other sealed sectors are called regular sectors. A CC sector
can be upgraded to a regular sector by discarding the CC
the
sector and registering a new regular sector. However,
content of a regular sector can be no longer changed.

3) Proof-of-Spacetime: PoSt is another kind of proof-of-
storage scheme for storage miners to prove that
they are
indeed actually storing a replica. There are two kinds of PoSt
in Filecoin. WinningPoSt serves as a part of the Expected
Consensus of Filecoin, while WindowPoSt guarantees that
the miner continuously maintains a replica over
time.
Therefore, Sybil attacks are prevented by the combination
of WindowPoSt and PoRep because storage miners should
actually store all replicas.

1See in https://spec.Ô¨Ålecoin.io/systems/Ô¨Ålecoin mining/sector/

4) Storage Market and Retrieval Market: There are two
markets in Filecoin, the Storage Market and the Retrieval Mar-
ket. In the Storage Market, storage miners and clients negotiate
on the price and length of storage. Similarly, retrieval miners
and clients would negotiate on the price of Ô¨Åle retrieving.

C. Other Solutions to Decentralized File Storage

1) Storj: Storj [23] is a sharding [16, 26] based protocol
to archive a peer-to-peer cloud storage network implementing
end-to-end encryption. It stores Ô¨Åles in encrypted shards to
ensure that the Ô¨Åle itself cannot be recovered by anyone other
than the owner. Moreover, it uses erasure code to ensure Ô¨Åle
availability in case some shards are lost.

2) Sia: Sia [21] is a platform for decentralized storage
enabling the formation of storage contracts between peers. The
Sia protocol provides an algorithm of storage proof in order to
build storage contracts. According to the Ô¨Åle contract, storage
providers need to generate proof-of-storage periodically. The
client needs to pay for each valid storage proof.

3) Arweave: Arweave [24] is a mechanism design-based
approach to achieving a sustainable and permanent ledger
of knowledge and history. Storing Ô¨Åles on Arweave only
requires a single upfront fee, after which the Ô¨Åles become
part of the consensus. Arweave uses the mechanism of Proof
of Access in consensus to ensure that miners need to store as
many Ô¨Åles as possible to participate in mining.

III. PRELIMINARIES

FileInsurer

is a protocol

to build a blockchain-based
Decentralized Storage Network (DSN) [5]. The structure of
DSN could be an independent blockchain or a decentralized
application (DApp) parasitic on existing blockchains or other
distributed network types. In DSN, a group of participants,
called storage providers, are willing to rent out their unused
hardware storage space to store the clients‚Äô Ô¨Åles, and then
the distributed Ô¨Åle storage is realized.

In this section, we introduce the structure and components
of FileInsurer protocol. Particularly, we deploy Dynamic
Replication (DRep) to support dynamic content in sectors
to ensure storage
with low cost, which is
randomness. Additionally, we also explain why compensation
is necessary for DSN.

important

A. Participants

There are two kinds of participants in DSN that are clients

and storage providers.

1) Client: Clients are the participants who have the demand
to store Ô¨Åles in the network. They propose a request to declare
which Ô¨Åle needs to be stored, via File Add request. Once
her Ô¨Åle is stored, the client shall pay the rent for the storage
service at periodic intervals (introduced in Section IV-A),
which depends on the Ô¨Åle‚Äôs value and size. They also can ask
DSN to discard their Ô¨Åles stored before, via File Discard
request. Besides, clients can retrieve any Ô¨Åle stored in DSN,
via File Get request, by paying the retrieving payment. As
the uploaded Ô¨Åles are public in DSN, clients can encrypt their
Ô¨Åles before uploading if she concerns about privacy.

2) Storage Providers: Storage Providers are the participants
who rent out their hard disks to store clients‚Äô Ô¨Åles and offer the
service of retrieving Ô¨Åles in exchange for payments. When re-
ceiving the File Add request from a client, DSN automatically
selects several independent storage providers to store this Ô¨Åle,
so that the robustness could be guaranteed by replicating Ô¨Åles.
After receiving a Ô¨Åle from a client, providers need to declare
that they have obtained this Ô¨Åle by File ConÔ¨Årm request. In
addition, after storing a Ô¨Åle, it is necessary for providers to
repeatedly submit the proofs of Ô¨Åle storage to DSN at each
speciÔ¨Åed checkpoint, to show that they are storing this Ô¨Åle,
via File Prove request. In order to guarantee security, each
storage provider must pledge a deposit, so that her deposit
could be liquidated to compensate for the loss of clients once
her disk is corrupted. When a client requests retrieval of
a speciÔ¨Åed Ô¨Åle, the providers, who store this Ô¨Åle, compete
to respond to the request for the corresponding payment.
Hence a Retrieval Market is formed, in which the clients and
providers exchange the Ô¨Åle without the witness of DSN.

B. Data Structures

Figure 1 shows a brief description of the data structures
of the FileInsurer. There are four main data structures, which
are sector, Ô¨Åle descriptor, allocation table, and pending list.

1) Sector: A disk sector is the smallest unit that a provider
rents out to store Ô¨Åles. Sector sizes vary but are required to
be an integer multiple of a minimum value of minCapacity.
to 64GB or other deterministic
minCapacity can be set
value. A sector is considered to be corrupted, as long as any
bit in this sector is destroyed. A Ô¨Åle is missing, if and only
if the sectors storing this Ô¨Åle are all corrupted. In FileInsurer
protocol, providers could divide their storage spaces into
multiple sectors, and are not allowed to register multiple disks
as the same sector. In addition, FileInsurer requires that a Ô¨Åle
is integratedly stored in a sector, instead of being dispersed
into multiple sectors. Such a requirement ensures the owner
of a lost Ô¨Åle obtains the compensation, which can completely
make up for her loss.

2) File descriptor: The Ô¨Åle descriptor f describes a Ô¨Åle
stored in the network, including its size, value, Merkle root,
the number of copies, and other necessary information. When
a Ô¨Åle is stored, the following two conditions must be satisÔ¨Åed.
‚Ä¢ The total size of the Ô¨Åles stored in a sector must not

exceed the capacity of this sector.

‚Ä¢ If a Ô¨Åle f is lost, meaning all sectors storing it are all
corrupted, then the deposits from these sectors are at
least f.value to make up the loss of the Ô¨Åle‚Äôs owner.

selects

3) Allocation table: FileInsurer

some feasible
sectors to store a Ô¨Åle and makes a note of it recorded in the
allocation table. The allocation table will be updated when a
Ô¨Åle is stored in the network, a Ô¨Åle is discarded, or the storage
location of a Ô¨Åle is transferred. The allocation table is a part
of the network consensus and can support fast random access.
4) Pending list: In the design of FileInsurer, some tasks
need to be automatically executed at a speciÔ¨Åc time in the
future, such as regularly checking whether a Ô¨Åle is saved

correctly. Therefore FileInsurer needs to maintain a pending
list to save these tasks and their corresponding execution time.
When a new time point t is reached, the tasks in the pending
list whose timestamp is t will be automatically executed by
the network. As the gas fee for these tasks should be paid in
advance, tasks that are placed in the pending list must have a
clear gas used upper bound. In the basic design of FileInsurer,
these tasks are only generated through network consensus.

Data structures

Sector
sector : (owner, id, capacity, freeCap, state)
‚Ä¢ owner: the provider who owns the sector.
‚Ä¢ id: the id of the sector, a provider cannot have two sectors

with the same id.

‚Ä¢ capacity: the storage capacity of the sector.
‚Ä¢ freeCap: current free capacity of the sector.
‚Ä¢ state: normal means this sector has capacity to accept new
Ô¨Åles, disable means the sector no longer accepts new Ô¨Åles.

File descriptor
Ô¨ÅleDescriptor : (size, value, merkleRoot, cp, cntdown, state)

‚Ä¢ size: the size of the Ô¨Åle.
‚Ä¢ value: the value of the Ô¨Åle.
‚Ä¢ merkleRoot: merkle root of the Ô¨Åle.
‚Ä¢ cp:

determined by the Ô¨Åle value.

the number of replicas to be stored in the network,

‚Ä¢ cntdown: the number of checkpoints until the next refresh of

the Ô¨Åle store.

‚Ä¢ state: normal means this Ô¨Åle needs to be stored, discard

means this Ô¨Åle is discarded.

Allocation table
allocTable : {(Ô¨ÅleDescriptor, index) ‚Üí allocEntry}
allocEntry : (prev, next, last, state)

‚Ä¢ prev: the current sector storing the Ô¨Åle.
‚Ä¢ next: the next sector to store the Ô¨Åle.
‚Ä¢ last: time of the last proof of storage.
‚Ä¢ state: alloc means the Ô¨Åle is being (re)allocated to a sector,
confirm means that the Ô¨Åle is conÔ¨Årmed by the next sector
to store, normal means the current sector is storing the Ô¨Åle,
corrupted means the current sector is corrupted.

Pending list
pendingList : {time ‚Üí [task,task,...]}

‚Ä¢ time:

time point when the tasks need to be automatically

executed.

‚Ä¢ task: description and parameters of the task to be executed.

Fig. 1. The data structures of FileInsurer

C. Interactions between Participants and Network

This subsection introduces the abovementioned operations

performed by clients and storage providers in detail.

1) Client requests:
‚Ä¢ File Add: Client stores a Ô¨Åle in DSN.

A client submits an order through a File Add request to
inform DSN of the Ô¨Åle‚Äôs description f , containing size
f.size, value f.value, Merkle root f.merkleRoot, the
number of replicas f.cp, and other necessary information.
DSN automatically allocates feasible f.cp sectors. When
these sectors are found, the client transmits the Ô¨Åle to
these sectors.

‚Ä¢ File Discard: Client discards a Ô¨Åle stored in DSN.

It is not necessary for clients to specify how long to
store the Ô¨Åle in advance. As an alternative, the client can
discard the Ô¨Åle at any time by submitting File Discard
request, which contains the description f of this Ô¨Åle, to
DSN.

‚Ä¢ File Get: Client retrieves a Ô¨Åle from DSN.

Each client can request any Ô¨Åle in DSN, via File Get
request, by paying a certain amount of tokens. Because
this requested Ô¨Åle is available in multiple providers‚Äô
sectors, the retrieve request can be satisÔ¨Åed by receiving
one of the copies from these providers.

2) Provider requests:

‚Ä¢ Sector Register: Provider registers a new sector in

DSN.
When providers launch a new storage space, they have
two options. One is to register the whole storage space
as one sector. The other is to divide this space into
several parts and each part is registered as one sector.
When a sector is registered, the provider shall pledge a
deposit proportional to the capacity of this sector.

‚Ä¢ Sector Disable: An operation to afÔ¨Årm that a sector no

longer accepts new Ô¨Åles.
In the design of FileInsurer protocol, providers are not al-
lowed to revoke the sectors they leased on the network be-
fore. Instead, when a provider decides not to provide stor-
age service from a sector, she shall declare that the sector
is disabled, that it is no longer accepts any new Ô¨Åle. After
all Ô¨Åles stored in this sector are allocated to other sectors
by the network, the sector is removed from the network.
‚Ä¢ File ConÔ¨Årm: The provider conÔ¨Årms to the network

that a Ô¨Åle has been received.
The network automatically speciÔ¨Åes the storage sector
for Ô¨Åles, and the provider of the sector needs to conÔ¨Årm
to the network after receiving the client‚Äôs Ô¨Åle.

‚Ä¢ File Prove: The provider submits the certiÔ¨Åcate to the

network of its correct storage of Ô¨Åles.
When providers store the Ô¨Åles,
they must repeatedly
submit proofs of replication to ensure they are storing
the Ô¨Åles. Proofs are posted on and veriÔ¨Åed by DSN.
‚Ä¢ File Supply: The provider responds a File Get request

from a client.
Once the supply and demand relationship of one Ô¨Åle has
been established, the transmission of this Ô¨Åle would be
carried off-chain.

D. Dynamic Content in Sectors

In FileInsurer, the content of a sector needs to be dynamic
from time to time, which is supported by ensuring storage
randomness. FileInsurer can resist Sybil attack by storing the
Ô¨Åles as multiple replicas. In FileInsurer, these replicas are
generated by PoRep, and the free capacity of a sector needs
to be proven that it is indeed available. A trivial idea is to
make a new replica of the sector whenever the content is
changed by PoRep. However, it is not a wise solution because

it would lead to an extremely high burden on providers and
much more veriÔ¨Åcation of PoRep.

We propose a novel solution called Dynamic Replication
(DRep) to solve this problem. Different from Filecoin, we
don‚Äôt encode a whole sector into a replica, but make each
Ô¨Åle in a sector to be a unique replica. We deÔ¨Åne a Capacity
Replica (CR) as a replica of zeros bits generated by the
PoRep process. When a sector is registered, it should be just
Ô¨Ålled with l unique CRs. The sector is requested to contain
as many CRs as possible while storing Ô¨Åles. Therefore, the
unsealed space of a sector is smaller than the size of a CR.
Figure 2 shows some examples of DRep.

Fig. 2. Examples of DRep: Initially the sector contains six Capacity
Replicas (as shown in (a)). After Ô¨Ålling some Ô¨Åles, there are two Capacity
Replicas left (as shown in (b)). When the total size of Ô¨Åles decreases, the
provider regenerates the CR3 (as shown in (c)).

Ensuring free space of sectors is indeed available by
CRs is an efÔ¨Åcient way. All CRs only need to be generated
by PoRep once and then veriÔ¨Åed continuously stored via
the provider
WindowPoSt [4]. If a CR has been thrown,
can recover it by PoRep.setup because the raw data of
a CR are zeros. It doesn‚Äôt need to go through the whole
PoRep process because the Merkle roots of CRs have been
previously veriÔ¨Åed. Therefore, DRep won‚Äôt bring an extra
veriÔ¨Åcation burden on the DSN and providers don‚Äôt need to
generate SNARK of PoRep again.

Additionally, FileInsurer changes the location of replicas
at a low cost. Consider that a replica of a Ô¨Åle f needs to
be transferred to another sector. The provider do not need
to generate new replicas of f by PoRep, but just transfer
the old ones. Liveness issue occurs that a provider may not
transfer the replica of f to the successor provider. However,
it doesn‚Äôt bother because the successor provider can fetch the
source data of f from other providers and recover the replica
via PoRep.Setup. Similar to CRs, these replicas don‚Äôt need
to be veriÔ¨Åed again, and they can be recovered from the raw
Ô¨Åle. Therefore, the movement of replicas is efÔ¨Åcient.

E. Storage Market and Retrieval Market

Similar to Filecoin, there are two markets in FileInsurer,
the Storage Market and the Retrieval Market. The Retrieval
Market in FileInsurer is the same as that in Filecoin. In the
DSN, clients can send the request to retrieve any Ô¨Åle f . Any
participant with f or a replica of f can answer that request.
The process of retrieving is accomplished by BitSwap of
IPFS. However, the Storage Market in FileInsurer is quite
different from the one in Filecoin. In FileInsurer, the price
of storing a Ô¨Åle is decided by the size and the value of that

Ô¨Åle. Clients do not need to negotiate prices of storage with
providers and even do not need to specify who to store their
Ô¨Åles. Prices for storage services may change over time, which
will be discussed in Section IV-A.

F. Source of Randomness

Just like other DSN protocols, FileInsurer needs a huge
amount of on-chain random bits. To achieve this with low
expense, we use a pseudorandom number generator [15, 18]
to generate long pseudo-random bits based on a short random
the issue of generating an unbiased
beacon. Additionally,
and unpredictable public random beacon in blockchain has
been well studied [6, 7, 12]. Combining the abovementioned
two technologies, we can cheaply get enough public pseudo-
random bits. In this paper, we omit the implementation of
generating and using random bits because it is too detailed
and not our main contribution.

G. Necessity of Compensation in DSN

Compensation is needed in DSN because the scalability of
DSN would lead to an unavoidable risk of missing data. Nec-
essarily, the scalability of storage means that a participant in
DSN only needs to store a very small part of all data in DSN.
Therefore, many data of DSN must only be stored by a small
part of participants. However, if a constant ratio, for example,
0.1, of sectors (or storage capacity) crash instantaneously,
some data may be lost. So DSN brings a huge risk of Ô¨Åle loss.
To demonstrate more clearly, let us provide some other
concrete examples. In Storj, a Ô¨Åle is lost if enough shards
of the Ô¨Åle are not available beyond what can be recovered
by erasure code. In Filecoin, a Ô¨Åle is lost, if and only if all
sectors storing replicas of this Ô¨Åle crash down.

To balance the safety and the scalability of DSN,
compensation is an effective method to motivate users to take
part in the distributed Ô¨Åle storage. The reasonable deposit
shall compensate the users‚Äô loss from missing data.

IV. PROTOCOL DESIGN OF FILEINSURER

In this section, we introduce the protocol design of
FileInsurer in detail. The insurance scheme is introduced
into the protocol design so that the storage providers are
responsible for Ô¨Åle loss and their deposit can fully compensate
the clients whose Ô¨Åles are lost. To support the dynamical Ô¨Åle
storing in sectors, storage randomness is needed to randomly
distribute the locations of replicas in DSN, which can be
realized by randomly selecting and refreshing the locations
of replicas. Additionally, Ô¨Åles with higher values have more
replicas so it is harder to destroy all replicas of these Ô¨Åles.

In FileInsurer, all Ô¨Åle replicas and Capacity Replicas
are generated by PoRep, which means that WinningPoSt
can be easily achieved. Therefore, the Expected Consensus
deployed by Filecoin can be directly applied to our consensus
algorithm. Additionally, FileInsurer protocol can be deployed
as a smart contract or sidechain in other blockchain protocols
such as Ethereum [25] and Algorand [10, 14].

A. Fee mechanism

In our DSN design, clients need to pay a fee when they
obtain the storage service and retrieval service. Moreover,
there are three kinds of fees in FileInsurer, which are the
trafÔ¨Åc fee, storage rent, and prepaid gas fee.

1) TrafÔ¨Åc fee: The trafÔ¨Åc fee needs to be paid when a client
occupies the network bandwidth of providers by transmitting
Ô¨Åles, retrieving Ô¨Åles, or other interactions. The mechanism to
pay a trafÔ¨Åc fee is necessary because malicious clients may
transmit Ô¨Åles but pay nothing to block the providers‚Äô network.
The operation to upload trafÔ¨Åc fee must be committed to the
storage provider before the Ô¨Åle transmission, and the provider
obtains the fee only when it has conÔ¨Årmed the Ô¨Åle.

2) Storage rent: Clients need to pay the storage rent for
the used storage space, which is proportional to the size of the
Ô¨Åle times the number of replicas. The unit rent is the same for
all Ô¨Åles, and the network informs the client how much rent it
should pay. The client will be automatically charged storage
rent in the task Auto CheckAlloc which will be introduced
in section IV-C. In particular, the network distributes revenue
by time period. In a time period, all storage rent is stored
in the network at Ô¨Årst. At the end of the period, the network
distributes the rent to owners of proper functioning sectors
during this period. Storage providers are paid proportionally
according to their
total storage capacity, without paying
attention to which Ô¨Åle is stored in which sector.

3) Prepaid gas fee: After a client stores Ô¨Åles on the
network, the network needs to periodically check the proof
and refresh the Ô¨Åle storage locations. These operations use the
consensus space and thus incur a gas fee. The gas fee for these
operations should be prepaid by the user as these operations
are performed automatically. The prepaid gas fee shall be col-
lected together with storage rent through Auto CheckAlloc.
In addition, anyone who submits requests to the network
must pay a gas fee to avoid wasting valuable consensus space.
The design of the gas fee mechanism is part of the network
design. As our DSN design does not focus on the network
design, we can use other existing gas fee mechanisms and do
not detailedly address it in this work.

B. Deposit and Compensation

When registering a sector,

the storage provider should
pledge to DSN with a certain amount of deposit. The deposit
the sector safely quits the system or is
is locked until
corrupted. If the sector safely quits, the deposit would be
withdrawn to the storage provider. If the sector is corrupted,
the deposit must be conÔ¨Åscated.

When the deposit of a sector is conÔ¨Åscated, it shall be
stored in the network to compensate for lost Ô¨Åles. File loss
in a network means that all its copies are no longer available,
i.e. those storage sectors storing the copies are all corrupted.
When a Ô¨Åle is lost, the network shall provide users with
compensation equal to the value of the Ô¨Åle. Values of Ô¨Åles
are given by users when storing their Ô¨Åles. If a user reports
a higher value than the value of her Ô¨Åle, she would pay a

higher storage rent, and if she reports a lower value, the
compensation would be lower once her Ô¨Åle gets lost.

The deposit ratio Œ≥deposit of FileInsurer is deÔ¨Åned as the
ratio that the sum of deposits compared to the maximal value
of Ô¨Åles stored in the network. It can be understood as how
much deposit is required for each unit of value stored in the
network. Thus, the lower the deposit ratio makes the providers
have more incentives to participate in the distributed storage
network, and thus make our protocol more competitive.

Now we show how to calculate the deposit by Œ≥deposit
while registering a sector. Assume that the total size of sectors
in FileInsurer is Ns √ó minCapacity and the maximal total
value of stored Ô¨Åles are N m
v √óminV alue. For a sector s with
capacity s.capacity, the deposit should be the proportion of
s.capacity in the network multiplied by the total deposit,
s.capacity
which is Œ≥deposit √ó N m
Ns√óminCapacity .
Let capP ara = N m
be a constant and the deposit becomes
v
Ns
s.capacity √ó Œ≥deposit √ó capP ara√óminV alue
, which can be
calculated only by s.capacity, Œ≥deposit, and some constants.
The setting of Œ≥deposit are discussed in Theorem 4.

v √ó minV alue √ó

minCapacity

C. Main Protocol

TABLE I
DESCRIPTIONS OF PARAMETERS AND FUNCTIONS

Notation

Description

RandomSector()

SampleExp(x)

RandomIndex(f )

DelayP erSize

AvgRef resh

P roof Cycle

P roof Due

P roof Deadline

Sample a random sector. The probability
of selecting each sector is proportional
to its capacity.
Sample from an exponential distribution
with mean x.
Sample a number between 1 and f.cp
uniformly at random.
The maximum transmit time allowed per
unit Ô¨Åle size. This constant multiplied by
the Ô¨Åle size is the upper limit of the Ô¨Åle
transfer time allowed by the network.
The number of P roof Cycles to refresh
the Ô¨Åle storage on average
Time interval between each inspection
proof.
The speciÔ¨Åed upper limit of the time the
last proof until now.
The tolerable upper limit of the time the
last proof until now.

FileInsurer mainly includes three parts:
‚Ä¢ File : protocols with File preÔ¨Åx handles the storage of

data on the network,

‚Ä¢ Sector : protocols with Sector
sector registration and revocation,

preÔ¨Åx handles the

‚Ä¢ Auto : protocols with Auto preÔ¨Åx are mainly used for
the maintenance of network. They are special because
they cannot be called by anyone and will be executed
automatically at a speciÔ¨Åc time.

Figure 3 proposes a brief overview of the protocol of
FileInsurer by explaining how Ô¨Åles and sectors interact with

(a) Storing Ô¨Åles on the network: First, the Ô¨Åle should be informed to the network to get the sectors where the Ô¨Åles are stored at. The client
then sends the Ô¨Åle to those sectors. The Ô¨Åle is successfully stored after the system executes Auto CheckAlloc, and the rent is paid every time
the system executes Auto CheckProof.

(b) Renting sectors to the network: After the sector has been registered, the Ô¨Åle will be swapped into or out of the sector through
Auto Refresh from time to time. Moreover, the network may also inform the sector to take over new Ô¨Åles by corresponding File Add.

Fig. 3. Brief overview of the protocol: How Ô¨Åles and sectors interact with the network. The symbol ‚ÄúF‚Äù represents a Ô¨Åle, and ‚ÄúR‚Äù represents a Ô¨Åle replica.

the network. Table I lists all parameters and functions used
in FileInsurer protocol.

File protocol: client part

File Add

‚Ä¢ Inputs. the size of the Ô¨Åle sz, the value of the Ô¨Åle val and the merkle

‚Ä¢ Goal. generate the Ô¨Åle descriptor for the Ô¨Åle and allocate k sectors to

root of the Ô¨Åle rt

it for storage

f ‚Üê (size = sz, value = val, merkleRoot = rt, cp =
backupCnt(val),cntdown = ‚àí1,state = normal)
count ‚Üê 0
for i ‚àà [f.cp] do

number of backup Ô¨Åles that need to be stored is calculated
by f.cp = f.value
minV alue k, where minV alue is a parameter repre-
senting the lower limit of the Ô¨Åle value of network storage and
each f.value must be integer multiple of minV alue. Next,
the waiting time is calculated and the user needs to transfer
the Ô¨Åle to the owner of the selected sectors before the waiting
time expires. Once the waiting time expires, a task named
as Auto CheckAlloc is performed automatically to conÔ¨Årm
whether the Ô¨Åle is successfully stored on the network. When
a client submits a File Discard request, the network simply
sets the state of the corresponding Ô¨Åle descriptor to discard.

s ‚Üê RandomSector()
while s.f reeCap < f.size do
s ‚Üê RandomSector()

(cid:46) almost never happens

File protocol: provider part

let e be a reference of allocTable[f,i]
count ‚Üê count+1
e ‚Üê (prev = null,next = s,last = ‚àí1,state = alloc)

t ‚Üê N ow+DelayP erSize√óf.size
add CheckAlloc(f ) to pendingList[t]

File Discard

‚Ä¢ Inputs. a Ô¨Åle descriptor f
‚Ä¢ Goal. discard Ô¨Åle f
f.state ‚Üê discard

Fig. 4. File Protocol: Add and discard Ô¨Åles

1) File : Figure 4 shows the network response for the
clients‚Äô File requests. When a client makes a File Add re-
quest, the network Ô¨Årst generates a Ô¨Åle descriptor and samples
f.cp sectors for storage. The probability of each sector being
selected is proportional to the capacity of this sector. The

File ConÔ¨Årm

‚Ä¢ Inputs. Ô¨Åle descriptor f , index i and sector s
‚Ä¢ Goal. conÔ¨Årm that a selected sector begins to store a speciÔ¨Åc Ô¨Åle
check the request is from the owner of sector s
verify allocTable[f,i].next = s and allocTable[f,i].state = alloc
entry.state ‚Üê confirm

File Prove

‚Ä¢ Inputs. Ô¨Åle descriptor f , index i, sector s and proof œÄ
‚Ä¢ Goal. verify that a selected sector is storing speciÔ¨Åc Ô¨Åle
check the request is from the owner of sector s
verify allocTable[f,i].prev = s
verify œÄ is a valid proof at time œÄ.t
allocTable[f,i].last ‚Üê œÄ.t

Fig. 5. File Protocol: ConÔ¨Årm and prove Ô¨Åles

Figure 5 illustrates the network response for providers‚Äô
File requests. When receiving an File ConÔ¨Årm request, the

clientAddCheckAllocCheckProofCheckProofCheckProofCheckProofnetworkùëùùëüùëúùëúùëìùê∂ùë¶ùëêùëôùëíùëùùëüùëúùëúùëìùê∂ùë¶ùëêùëôùëíùëùùëüùëúùëúùëìùê∂ùë¶ùëêùëôùëíùëùùëüùëúùëúùëìùê∂ùë¶ùëêùëôùëíùëëùëíùëôùëéùë¶ùëÉùëíùëüùëÜùëñùëßùëí√ó ùëì.ùë†ùëñùëßùëíFsectorsDiscarddiscard filerentrentrentùëì.ùëêùëùsectorsAddnetworkRefreshCheckRefreshAllocRefreshCheckRefreshRegisterCheckAllocsectorswap in the ùëñthreplica of  file ùëì1from sector ùë†RiCommitproduce the ùëóthreplica of file ùëì2FclientproduceRjsector ùë†Commitswap out the ùëñthreplica of  file ùëì1to sector ùë†Risector ùë†Registerdepositnetwork sets the state of the corresponding allocation entry
to confirm. It means the sector has successfully received
the Ô¨Åle. When the network receives a File Prove request,
it shall update the last proof time of the Ô¨Åle storage after
checking the correctness of the proof.

Sector protocol

Sector Register

‚Ä¢ Inputs. capacity cap and owner own
‚Ä¢ Goal. register a new sector on the network
the owner pledges deposit proportional to the sector size
s ‚Üê (owner = own, id = nextId(own), capacity = cap, f reeCap =
cap,state = normal)

Sector Disable

‚Ä¢ Inputs. sector s
‚Ä¢ Goal. mark the sector as disabled
s.state ‚Üê disable

Fig. 6. Sector Protocol: Register and disable sectors

2) Sector :

automatically.

In the design of

It is simple for the network to respond to
Sector
requests. The pseudo-code is shown in Figure 6. A
new sector is registered when a Sector Register request is
received and the state of a sector will be set to disable
when a request of Sector Disable is received. When all Ô¨Åles
in a disabled sector are swapped out, then it can be removed.
3) Auto : Note that the tasks with Auto preÔ¨Åx cannot
be called by anyone and shall be executed at a speciÔ¨Åc
time
the FileInsurer
protocol,
the network needs to maintain a pending list
to ensure that these tasks are executed at a speciÔ¨Åc time.
There are 4 kinds of tasks with Auto
preÔ¨Åx, which are
Auto CheckAlloc, Auto CheckProof, Auto Refresh, and
Auto CheckRefresh. In simple terms, Auto CheckAlloc
is used to check that
the Ô¨Åle has been correctly stored
on the network, Auto CheckProof
is periodically proof
checking, while Auto Refresh and Auto CheckRefresh
are the processes of Ô¨Åle storage refreshing in order to ensure
the randomness of storage. Therefore, the period of proof
checking should be short, and thus the frequency of the Ô¨Åle
storage location refreshing could be very low.

Auto protocol

Auto CheckAlloc

‚Ä¢ Inputs. Ô¨Åle descriptor f
‚Ä¢ Goal. check if Ô¨Åle f is already conÔ¨Årmed by all of the selected sectors
for i ‚àà [f.cp] do

let e be a reference of allocTable[f,i]
if e.state (cid:54)= confirm and e.state (cid:54)= corrupted then
inform that the client failed to upload the Ô¨Åle f
remove f from the network

for i ‚àà [f.cp] do

let e be a reference of allocTable[f,i]
if e.state = confirm then

e ‚Üê (prev = e.next,next = null,last = N ow,state = normal)

else

e ‚Üê (prev = null,next = null,last = ‚àí1,state = corrupted)

f.cntdown ‚Üê SampleExp(AvgRef resh)
add CheckP roof (f ) to pendingList[N ow+P roof Cycle]
inform that the client succeed to upload the Ô¨Åle f

Fig. 7. Auto CheckAlloc: Check each allocation has conÔ¨Årmed the Ô¨Åle

Auto protocol

Auto CheckProof

‚Ä¢ Inputs. Ô¨Åle descriptor f
‚Ä¢ Goal. check that all storage locations of Ô¨Åle f are working
if the client of Ô¨Åle f has does not have enough tokens to pay the cost for
the next cycle then

f.state ‚Üê discard
inform that Ô¨Åle f is discarded due to insufÔ¨Åcient cost

if f.state = normal then

deduct the cost for the next cycle from the client‚Äôs account
for i ‚àà [f.cp] do

let e be a reference of allocTable[f,i]
if e.prev is not corrupted then

if e.last < N ow‚àíP roof Deadline then

conÔ¨Åscate the deposit of s
mark and inform that s is corrupted
else if e.last < N ow‚àíP roof Due then

else if ‚àÄj,allocTable[f,j].prev is corrupted then

punish e.prev
if f.state = discard then

remove f from the network

inform that Ô¨Åle f is lost
compensate to the client
remove f from the network

else

add CheckP roof (f ) to pendingList[N ow+P roof Cycle]
f.cntdown ‚Üê f.cntdown‚àí1
if f.cntdown = 0 then

i ‚Üê RandomIndex(f )
call Ref resh(f,i)

Auto CheckAlloc will be executed automatically at some
time after a File Add request is responded by the network.
The network shall conÔ¨Årm if all f.cp sectors have received
the Ô¨Åle described by f . If so, the network goes to change
the state of the Ô¨Åle descriptor to normal; otherwise, it shall
inform the client that it failed to upload the Ô¨Åle.

Every Ô¨Åle needs to be checked at some speciÔ¨Åc time
whether it is stored properly. In each speciÔ¨Åc time period, a
task named Auto CheckProof automatically runs to check
whether each proof to the Ô¨Åle is timely. We provide the
pseudo-code of Auto CheckProof
in Figure 8. We use
WindowPoSt of Filecoin [4] to implement the proof process.
A sector will be punished if it cannot submit the proof of
storage of its Ô¨Åles within P roof Due time, and then its

Fig. 8. Auto CheckProof: Check each proof of the Ô¨Åle

corresponding deposit is liquidated if the proof of storage of
its Ô¨Åles cannot be provided within P roof Deadline time.

Whenever a random number2 of checkpoints are passed,
a task named Auto Refresh will be called to randomly
refresh one of the storage places of the Ô¨Åle. Figure 9 shows
the details of Auto Refresh and another corresponding
task Auto CheckRefresh. The probability of sampling the
to the capacity of the
new storage sector is proportional

2This random number follows an exponential distribution

Auto protocol

Auto Refresh

‚Ä¢ Inputs. Ô¨Åle descriptor f and index i
‚Ä¢ Goal. change the i-th storage place of Ô¨Åle f to a random sector
s ‚Üê RandomSector()
if s.f reeCap ‚â• f.size then
allocTable[f,i].next ‚Üê s
allocTable[f,i].state ‚Üê alloc
t ‚Üê N ow+DelayP erSize√óf.size
add CheckRef resh(f,i) to pendingList[t]
pre ‚Üê allocTable[f,i].prev
inform the ith replica of Ô¨Åle f should be swapped from pre to s

else

f.cntdown ‚Üê SampleExp(AvgRef resh)

Auto CheckRefresh

(cid:46) almost never happens

‚Ä¢ Inputs. Ô¨Åle descriptor f and index i
‚Ä¢ Goal. check whether the last refresh for Ô¨Åle f is conÔ¨Årmed
let e be a reference of allocTable[f,i]
if e.state = confirm then

e ‚Üê (prev = e.next,next = null,last = N ow,state = normal)
f.cntdown ‚Üê SampleExp(AvgRef resh)

else

punish entry.next
for j ‚àà [f.cp] do

punish allocTable[f,j].prev

call Ref resh(f,i)

Fig. 9. Auto Refresh and Auto CheckRefresh: Swap in and out the Ô¨Åles

sector. The network then calculates a waiting time and the
current sectors that store this Ô¨Åle need to transfer it to the
selected sector before the waiting time expires. Once the
waiting time expires, the task named Auto CheckRefresh
will be executed automatically to conÔ¨Årm whether the Ô¨Åle is
successfully stored in the new sector.

V. ANALYSIS

In this section, we analyze the performance of our protocol
and compare FileInsurer with other DSN protocols in detail.

A. Notation and Assumption

Before the analysis, we list notations in Table II which are
necessary for our theoretical analysis. Additionally, The fol-
lowing assumptions are necessary for our theoretical analysis.
the
secure. The issue of

security: FileInsurer
network consensus
itself
consensus security is not the target of this paper.

‚Ä¢ Consensus

requires

that

is

‚Ä¢ Adversary ability: FileInsurer allows an adversary to
corrupt Œª proportion of network capacity immediately.
‚Ä¢ Redundant capacity: FileInsurer requires that the total
capacity in the network is no less than twice the total
size of all Ô¨Åles‚Äô replicas. This assumption is deployed to
ensure storage randomness.

B. Performance of FileInsurer

1) Analysis for Capacity Scalability: We consider
the
capacity scalability of FileInsurer as the maximal size of
stored Ô¨Åles. The following theorem indicates that FileInsurer
is scalable in capacity.

TABLE II
NOTATION TABLE

Notation

Description

minCapacity

minV alue

The minimum capacity of
sector. The
capacity of each sector is an integer multiple of
minCapacity.
The minimum value of a Ô¨Åle. The value of each
Ô¨Åle is an integer multiple of minV alue.

a

Nf

Ns

Nv

N m
v

Œ≥m
v

Œ≥deposit

capP ara

c

k

of

of

number

number

‚Äúweighted‚Äù

‚Äúweighted‚Äù

The number of Ô¨Åles.
The
sectors.
Ns √óminCapacity indicates the total capacity
of the network.
Ô¨Åles.
The
Nv √ó minV alue indicates the total value
of Ô¨Åles stored on the network.
The maximum ‚Äúweighted‚Äù number of Ô¨Åles the
network is designed to carry. N m
v √óminV alue
is the maximum value the network can carry.
Œ≥m
v = Nv
is the ratio that the total value stored
N m
v
in FileInsurer compared to the maximal value.
The deposit ratio. Œ≥deposit is the ratio that the
sum of deposits compared to the maximal value
of Ô¨Åles stored in the network.
capP ara is deÔ¨Åned as N m
v
Ns
Security parameter. We set it to be 10‚àí18.
The number of backups should be stored of a
Ô¨Åle whose value is minV alue.

.

Theorem 1 The total size of Ô¨Åles can be stored in FileInsurer
is

min

(cid:26) Ns √óminCapacity
2r1k

,

Ns √óminCapacity
r2

(cid:27)

,

where

r1 =

r2 =

f f.size√óf.value

(cid:80)
minV alue√ó(cid:80)

f f.size

,

minCapcity√ó(cid:80)

minV alue√ó(cid:80)

f f.value
f f.size√ócapP ara

(1)

(2)

.

The proof of Theorem 1 is provided in Appendix A. We
claim that each of r1 and r2 is bounded by a constant in
Section VI-A. Then the total size of raw Ô¨Åles can be stored in
FileInsurer is ÀúO(Ns √óminCapacity), which is almost linear
to the total size of sectors.

is

Storage

randomness

2) Storage Randomness:

an
important issue in FileInsurer. Storage randomness can ensure
the locations of replicas are evenly distributed. Therefore, the
adversaries must corrupt a huge number of sectors even if they
only want to destroy all replicas of a small portion of Ô¨Åles. In
FileInsurer, replicas are stored by randomly selected sectors
in File Add and their locations are randomly refreshed by
Auto Refresh. Such operations make the locations of all
replicas are independent and identically distributed.

However, when the total used space is close to the capacity
of DSN, the process of File Add and Auto Refresh faces
the free space of selected sectors is not
the trouble that
enough for the storage of a replica. We call this event a
collision. Although sectors can be reselected to store these
replicas, Storage randomness would be inÔ¨Çuenced. Therefore,

redundant capacity is required to avoid collisions. We claim
that the frequency of collisions is ignorant by preliminary
theoretical proof and further experiments.

We Ô¨Årst consider a trivial case that all Ô¨Åles have the same
size. The following theorem indicates that a collision happens
with an extremely low probability.

Theorem 2 If all Ô¨Åles have the same size f.size,
for a
sector s with total capacity s.capacity and free capacity
s.f reeCap, then

(cid:20)

(cid:21)

(cid:26)

Pr

‚àÉs, s.f reeCap ‚â§

s.capacity

‚â§ Nsexp

‚àí0.144

(cid:27)

s.capacity
f.size

1
8

Theorem 2, when s.capacity
Pr(cid:2)‚àÉs, s.f reeCap ‚â§ 1

The proof of Theorem 2 is provided in Appendix B. By
f.size ‚â• 1000 and Ns ‚â§ 1012, we have
8 s.capacity(cid:3) < 10‚àí50.
A replica of the Ô¨Åle can be stored in any sector s with
8 s.capacity because f.size < 1
8 s.capacity.
the probability of collision is

s.f reeCap ‚â§ 1
This result
indicates that
extremely low under these conditions.

We further consider the general case that

the size of
Ô¨Åles follows a certain distribution. We conduct a series of
numerical experiments in two different settings. In the Ô¨Årst
setting, we reallocate all Ô¨Åle backups in one go for 100 times.
In the second setting, we allocate each Ô¨Åle backup and then
randomly refresh the location of a Ô¨Åle backup 100Ncp times.
Recall that Ncp = kNv is the number of Ô¨Åle backups and each
Ô¨Åle f needs to store f.cp backups on the network.

In the experiments, we test several distributions for the
size of Ô¨Åle backups. We focus on the maximum ratio of
capacity usage. If the ratio is less than 1, no Ô¨Åle backups
are allocated to sectors with insufÔ¨Åcient capacity. Table III
shows the results of our experiments. We can Ô¨Ånd that the
maximum ratios of capacity usage never exceed 0.64 under
all tested distributions, which means that the probability that
Ô¨Åle backups are allocated to sectors with insufÔ¨Åcient capacity
the results of our experiments
is very small. Therefore,
indicate that collisions would hardly occur when the average
size of Ô¨Åle backups is much smaller than the sector capacity.
We also discuss how to maintain storage randomness when
the list of sectors changes in section VI-B. These results show
that storage randomness is easy to be promised in practice.
Therefore, each allocation of replicas is assumed to be inde-
pendent and identically distributed in the following analyses.
3) Analysis of Robustness: We consider the robustness of
FileInsurer as the ability of resisting corruptions of sectors.
The following theorem indicates that FileInsurer is quite
robust. The proof is left in Appendix C.

TABLE III
EXPERIMENT RESULT: MAXIMUM CAPACITY USAGE OF SECTORS

reallocate all Ô¨Åle backups 100 times

parameter
Ns
20
100
200
1000
2000
10000
20000
105

Ncp
105
105
106
106
107
107
108
108

[1]
0.525
0.571
0.538
0.591
0.540
0.589
0.541
0.591

.

maximum capacity usage
[3]
0.536
0.584
0.542
0.598
0.544
0.609
0.550
0.614

[4]
0.530
0.572
0.534
0.594
0.545
0.606
0.547
0.599

[2]
0.524
0.566
0.530
0.571
0.534
0.576
0.534
0.582

[5]
0.529
0.569
0.533
0.576
0.534
0.585
0.538
0.586

refresh the location of a Ô¨Åle backup 100Ncp times
parameter
Ns
20
100
200
1000
2000
10000
20000
105

maximum capacity usage
[3]
0.538
0.599
0.546
0.610
0.553
0.626
0.560
0.639

[4]
0.535
0.595
0.542
0.605
0.549
0.613
0.558
0.628

[2]
0.529
0.571
0.535
0.581
0.535
0.591
0.547
0.604

[1]
0.532
0.588
0.536
0.592
0.542
0.610
0.551
0.611

Ncp
105
105
106
106
107
107
108
108

[5]
0.531
0.581
0.541
0.589
0.540
0.599
0.548
0.611

[1]: Uniform distribution in interval [0,1]
[2]: Uniform distribution in interval [1,2]
[3]: Exponential distribution
[4]: Normal distribution with ¬µ = œÉ2
[5]: Normal distribution with ¬µ = 2œÉ2

Let us propose a concrete example to show that the result
of Theorem 3 is quite strong. Set k = 20, Ns = 106, and
capP ara = 103. Let Œª = 0.5, which means that half capacity
of FileInsurer is broken. Then
Œ≥v
lost ‚â§ max

5√ó10‚àí6,0.001,

√ó5√ó10‚àí6

(cid:26)

(cid:27)

.

1
Œ≥m
v

When Œ≥m

v ‚â• 0.005, Œ≥v

lost ‚â§ 0.001. It means that in this case,
even when half of the capacity of FileInsurer is corrupted,
the value of lost Ô¨Åles is no more than 0.1% of the value of
all stored Ô¨Åles.

4) Deposit Ratio: The following theorem indicates that

only a small deposit ratio is needed for full compensation.

Theorem 4 Assume that the total size of corrupted sectors
is no more than ŒªNs √ó minCapacity. If the deposit ratio
satisÔ¨Åes

Œ≥deposit ‚â• max

(cid:26)

5Œªk‚àí1,Œª

k

2 ‚àí1,

4
k√ócapP ara

(cid:18) logNs
log 1
Œª

+

log 1
c
logNs

(cid:19)(cid:27)

,

then full compensation can be achieved with a probability
of not less than 1‚àíc.

Vlost

lost =

Theorem 3 Assume that the total size of corrupted sectors
is ŒªNs √óminCapacity. Denote the total value of lost Ô¨Åles to
be Vlost, and Œ≥v
Sv√óminV alue represents the ratio of the
value of lost Ô¨Åles to the total value of all Ô¨Åles. Then with a
probability of not less than 1‚àíc, Œ≥v
2œÄ ‚àílogc
Ns
v klog 1
Œ≥m

lost satisÔ¨Åes
‚àílog(cid:0)ŒªŒª(1‚àíŒª)1‚àíŒª(cid:1)(cid:17)
Œª √ócapP ara

Œ≥v
lost ‚â§ max

Ô£º
Ô£Ω
.
Ô£æ

5Œªk,Œª

(cid:16) log e

Ô£±
Ô£≤

k
2 ,

Ô£≥

4

The proof of theorem 4 is in Appendix D. Set k = 20, Ns =
106, capP ara = 103 and Œª = 0.5. Then Œ≥deposit = 0.0046 is
enough to ensure full compensation, which is relatively small.

C. Comparison with Existing Protocols

Table IV shows the comparison between FileInsurer and
existing DSN protocols including Filecoin, Arweave, Sia, and
Storj. We observe that FileInsurer is the only DSN protocol

TABLE IV
COMPARISON OF DSN PROTOCOLS

C. Adjusting to Extremely Large Files

Property
Capacity Scalability
Preventing Sybil Attacks
Provable Robustness
Compensation for File Loss

FileInsurer Filecoin Arweave Storj Sia
Yes Yes
Yes No
No No
No No

Yes
Yes
Yes
Yes
No
Yes
No
Yes
[1] Provides only limited Ô¨Åle loss compensation

Yes
Yes
No
No[1]

that has provable robustness and gives full compensation for
Ô¨Åle loss.

VI. DISCUSSION

In previous

sections, we have proposed the general
framework of FileInsurer and theoretically proved the
excellent performance of FileInsurer. Besides, some practical
issues exist and we explore the corresponding solutions for
them under FileInsurer in this section.

A. Distributions and Parameters

The value and size of a Ô¨Åle follows a certain distribution in
DSN. We have the following reasonable assumptions about
the distribution.

‚Ä¢ The maximal value of a Ô¨Åle is bounded by a constant.
eq. (1)) is bounded by a

Therefore, r1 (deÔ¨Åned in
constant.

‚Ä¢ The average value of a unit size is a bounded constant.
f f.value
f f.size is bounded
eq. (2)) is

Then it‚Äôs reasonable to assume that
by a constant. Therefore, r2 (deÔ¨Åned in
bounded by a constant.

(cid:80)
(cid:80)

fail

In some special cases, very few huge Ô¨Åles, whose sizes
are comparable to the capacity of sectors, need to be stored
in the network. These very large Ô¨Åles might break storage
randomness because their allocations might
to Ô¨Ånd
enough space in one turn. To address this problem from the
extremely large Ô¨Åles, the network needs to specify an upper
limit sizeLimit on the size of a single Ô¨Åle. For a Ô¨Åle with a
size greater than sizeLimit, we can convert it to a collection
of segments by the erasure code, such that each segment‚Äôs
size is upper bounded by sizeLimit. By this operation, the
Ô¨Åle can still be recovered even if half of the segments are lost.
Therefore, we can simply regard each segment as an individual
Ô¨Åle with value 2value
. In practice, we can apply the common
erasure code such as Reed‚ÄìSolomon code [19] to archive this.

k

D. Storing Files with Widely Varying Values

v

In FileInsurer protocol, the value of each Ô¨Åle is required
to be an integer multiple of minV alue. Thus a Ô¨Åle with a
value of v can be treated as
minV alue documents worth of
minV alue. This means that a high-value Ô¨Åle needs to have
many replicas in the system, and the number of replicas is
linearly related to this Ô¨Åle‚Äôs value. A compromise solution
is to pre-divide the value levels of Ô¨Åles and to establish a
storage subnetwork corresponding to each level. Then the
clients can choose which subnetwork to store Ô¨Åles based on
the value level of their Ô¨Åles.

The parameters of FileInsurer should be properly set
according to the distribution of Ô¨Åles. For example, we should
set parameters to make 2r1k is not far away from r2 to
further improve scalability bound in theorem 1. It also helps
to avoid the bad situation that the total value of Ô¨Åles is far
below the maximal, but the used space has reached its limit.

B. Storage Randomness When Adding or Removing Sectors

In our analysis of storage randomness, we ignore the case
that the network may add or remove sectors online. When a
new sector s is registered in the network, in order to maintain
the independently and identically distributed property of the
allocations, the network should traverse each allocation and
swap out the allocation to that sector with the probability
of
Ns√óminCapacity . Such an operation is impossible because
traversing over Ô¨Åles is too expensive. One good approximation
method is that the network Ô¨Årst calculates how many Ô¨Åles
backups need to be swapped into the sector by sampling
from a Poisson distribution, and then randomly select the Ô¨Åle
backups to swap into the sector.

s.capacity

If a sector is disabled, We can request it to keep storing
all replicas it currently stores even if they are slowly being
swapped out. As a result, it does not get easier to attack the
corresponding Ô¨Åles. When all of its Ô¨Åles are swapped out,
this sector no longer exists in the network so the storage
randomness can guarantee.

E. Avoiding SelÔ¨Åsh Storage Providers

SelÔ¨Åsh storage providers refer to these providers who
store Ô¨Åles but do not normally provide retrieval services.
Assume the ratio of the number of selÔ¨Åsh storage providers
to the number of all providers is Œ± in the network. Then
is expected that Œ±k proportion of Ô¨Åles suffer from the
it
threat of the selÔ¨Åsh providers‚Äô collusion. Here k is just the
number of copies of a stored Ô¨Åle. As a result, any protocol
that Ô¨Åxes Ô¨Åle storage locations cannot fundamentally solve
the problem of selÔ¨Åsh storage providers. However, a natural
advantage of FileInsurer is that its Ô¨Åle refresh mechanism
can fundamentally eliminate the threat from selÔ¨Åsh storage
providers. Because of the existence of refreshing Ô¨Åle storage
location, no single Ô¨Åle will be completely controlled by the
selÔ¨Åsh storage provider for a long time.

F. Supports for IPFS

Filecoin has shown how to support IPFS in a blockchain-
based DSN, and FileInsurer has a similar approach.
In
FileInsurer, the hashes and locations of Ô¨Åles are all stored in
blockchain. Therefore, it‚Äôs easy to build and update DHTs
and Merkle DAGs on FileInsurer so that anyone can address
Ô¨Åles stored in FileInsurer through IPFS paths. The retrieval
of Ô¨Åles can be also realized through BitSwap protocol.

VII. CONCLUSION

In this paper, we propose FileInsurer, a novel design for
blockchain-based Decentralized Storage Network, which
achieves both scalability and reliability. FileInsurer is the Ô¨Årst
DSN protocol that gives full compensation to Ô¨Åle loss and
has provable robustness. Our work also raises many open
problems. First, are there other approaches to enhance the
reliability of Decentralized Storage Networks? For example,
a reputation mechanism [8] on storage providers may be
also helpful to reduce the loss of Ô¨Åles. Second, are there
other ways to support dynamic content in sectors other than
DRep? Furthermore, can the idea of FileInsurer be extended
to decentralized insurance in other scenarios?

REFERENCES

[1] F. A. Alabdulwahhab. Web 3.0: the decentralized web
blockchain networks and protocol innovation. In 2018 1st
International Conference on Computer Applications &
Information Security (ICCAIS), pages 1‚Äì4. IEEE, 2018.
Ipfs-content addressed, versioned, p2p Ô¨Åle

[2] J. Benet.

system. arXiv preprint arXiv:1407.3561, 2014.

[3] J. Benet, D. Dalrymple, and N. Greco.

Proof of

replication. Protocol Labs, July, 27:20, 2017.

[4] J. Benet and N. Greco. Filecoin: A decentralized storage

network. Protoc. Labs, pages 1‚Äì36, 2018.

[5] N. Z. Benisi, M. Aminian, and B. Javadi. Blockchain-
based decentralized storage networks: A survey. Journal
of Network and Computer Applications, 162:102656,
2020.

[6] A. Bhat, N. Shrestha, Z. Luo, A. Kate, and K. Nayak.
random beacons
Randpiper‚ÄìreconÔ¨Åguration-friendly
In Proceedings of the
with quadratic communication.
2021 ACM SIGSAC Conference on Computer and
Communications Security, pages 3502‚Äì3524, 2021.
[7] C. Cachin, K. Kursawe, and V. Shoup. Random oracles
in constantinople: Practical asynchronous byzantine
agreement using cryptography. Journal of Cryptology,
18(3):219‚Äì246, 2005.

[8] H. Chen, Z. Chen, Y. Cheng, X. Deng, W. Huang,
J. Li, H. Ling, and M. Zhang. A provable softmax
reputation-based protocol for permissioned blockchains.
IEEE Transactions on Cloud Computing, 2021.

[9] H. Chen, Y. Cheng, X. Deng, W. Huang, and L. Rong.
Absnft: Securitization and repurchase
for
non-fungible tokens based on game theoretical analysis.
arXiv preprint arXiv:2202.02199, 2022.

scheme

[10] J. Chen and S. Micali. Algorand: A secure and efÔ¨Åcient
Theoretical Computer Science,

distributed ledger.
777:155‚Äì183, 2019.

[11] Z. Chen and G. Yang. Decentralized asset custody
scheme with security against rational adversary. In Web
and Internet Economics: 17th International Conference,
WINE 2021, Potsdam, Germany, December 14‚Äì17,
2021, Proceedings, page 449. Springer Nature, 2021.

[12] S. Das, V. Krishnan, I. M. Isaac, and L. Ren. Spurt:
Scalable distributed randomness beacon with transparent
setup. Cryptology ePrint Archive, 2021.

[13] J. R. Douceur.

In International
The sybil attack.
workshop on peer-to-peer systems, pages 251‚Äì260.
Springer, 2002.

[14] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zel-
dovich. Algorand: Scaling byzantine agreements for
cryptocurrencies. In Proceedings of the 26th symposium
on operating systems principles, pages 51‚Äì68, 2017.
[15] F. James. A review of pseudorandom number generators.
60(3):329‚Äì344,

communications,

physics

Computer
1990.

[16] E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly,
E. Syta, and B. Ford. Omniledger: A secure, scale-out,
In 2018 IEEE
decentralized ledger via sharding.
Symposium on Security and Privacy (SP), pages
583‚Äì598. IEEE, 2018.

[17] S. Nakamoto. Bitcoin: A peer-to-peer electronic cash sys-
tem. Decentralized Business Review, page 21260, 2008.
[18] V. Pareek. An overview of cryptographically secure
pseudorandom number generators and bbs. International
Journal of Computer Applications (IJCA)(0975‚Äì8887),
2014.

[19] I. S. Reed and G. Solomon. Polynomial codes over
certain Ô¨Ånite Ô¨Åelds. Journal of the society for industrial
and applied mathematics, 8(2):300‚Äì304, 1960.

[20] B. Ryskeldiev, Y. Ochiai, M. Cohen, and J. Herder.
Distributed metaverse: creating decentralized blockchain-
based model for peer-to-peer sharing of virtual spaces
In Proceedings of the
for mixed reality applications.
9th Augmented Human International Conference, pages
1‚Äì3, 2018.

[21] D. Vorick and L. Champine. Sia: Simple decentralized

storage. Retrieved May, 8:2018, 2014.

[22] Q. Wang, R. Li, Q. Wang, and S. Chen. Non-fungible
token (nft): Overview, evaluation, opportunities and
challenges. arXiv preprint arXiv:2105.07447, 2021.
[23] S. Wilkinson, T. Boshevski, J. Brandoff, and V. Buterin.
Storj a peer-to-peer cloud storage network. 2014.
[24] S. Williams, V. Diordiiev, L. Berman, and I. Uemlianin.
Arweave: A protocol
for economically sustainable
information permanence. arweave. org, Tech. Rep, 2019.
Ethereum: A secure decentralised
generalised transaction ledger. Ethereum project yellow
paper, 151(2014):1‚Äì32, 2014.

[25] G. Wood et al.

[26] M. Zhang, J. Li, Z. Chen, H. Chen, and X. Deng.
Cycledger: A scalable and secure parallel protocol
In 2020 IEEE
for distributed ledger via sharding.
International Parallel
and Distributed Processing
Symposium (IPDPS), pages 358‚Äì367. IEEE, 2020.

APPENDIX A
PROOF OF THEOREM 1
Theorem 1 The total size of Ô¨Åles can be stored in FileInsurer
is

min

(cid:26) Ns √óminCapacity
2r1k

,

Ns √óminCapacity
r2

(cid:27)
,

where

r1 =

r2 =

f f.size√óf.value

(cid:80)
minV alue√ó(cid:80)

f f.size

,

minCapcity√ó(cid:80)

minV alue√ó(cid:80)

f f.value
f f.size√ócapP ara

(1)

(2)

.

Proof:

There are two restrictions on the total size of raw
Ô¨Åles. One is the restriction of total capacity. The other is the
restriction of the maximal total value of stored Ô¨Åles.

Under the former restriction, each Ô¨Åle f is stored as f.cp
replicas. Due to the assumption of redundant capacity, The
total size of all replicas can not exceed 1
2 of total capacity.
That is,

(f.size√óf.cp) ‚â§

Ns √óminCapacity.

1
2

(cid:88)

f

Because f.cp = k√ó f.value

minV alue , we have
1
2

f.value
minV alue

) ‚â§

(f.size√ók√ó

Ns √óminCapacity.

Then we have

(cid:88)

f

k√ó

Let r1 =

Then

Ns √óminCapacity
f f.size

(cid:80)

.

(cid:80)

√ó

‚â§

1
2

(cid:80)
minV alue√ó(cid:80)

f (f.size√óf.value)
f f.size
f f.size we have
minV alue√ó(cid:80)
1
√ó
2

f f.size√óf.value

(cid:80)

k
r1

‚â§

.

Ns √óminCapacity
f f.size
Ns √óminCapacity
2r1k

.

f.size ‚â§

(cid:88)

f

Under the latter restriction, the total value of Ô¨Åles can‚Äôt

exceed Sm

v √óminV alue. That is,

f.value ‚â§ n√óminV alue.

(cid:88)

f

(cid:80)

Because n = Cap P ara√óm,
f f.value
f f.size

(cid:80)

‚â§

Cap P ara√óNs √óminV alue
f f.size

(cid:80)

.

Therefore,

where

r2 =

(cid:88)

f.size ‚â§

f

Ns √óminCapacity
r2

,

minCapcity√ó(cid:80)

f f.value
f f.size√óCap P ara

minV alue√ó(cid:80)

.

(cid:3)

APPENDIX B
PROOF OF THEOREM 2

for a
Theorem 2 If all Ô¨Åles have the same size f.size,
sector s with total capacity s.capacity and free capacity
s.f reeCap, then

(cid:20)

(cid:21)

(cid:26)

Pr

‚àÉs, s.f reeCap ‚â§

s.capacity

‚â§ Nsexp

‚àí0.144

s.capacity
f.size

(cid:27)

.

1
8

Proof:

In the special case, all Ô¨Åles have the same size
f.size. For a sector s with capacity s.capacity, it can store

s.capacity
f.size

backups. We deÔ¨Åne Ncp = kNv as the number of Ô¨Åle
backups in total because Ncp = (cid:80)
f.value
minV alue √ók =
kNv. Additionally, let Xi be the event that the backup i
is stored in this sector and S = (cid:80)Ncp
i=1 Xi. Because the
assumption of redundant capacity, we have E[S] ‚â§ s.capacity
2f.size .
By multiplicative Chernoff bound, we have

f f.cp = (cid:80)

f

Pr

s.f reeCap ‚â§

s.capacity

(cid:21)

1
8

(cid:20)

Ô£Æ

Ô£π

Ô£ª

(cid:27)

Ncp
(cid:88)

=Pr

Ô£∞

i=1

(cid:20)

‚â§Pr

S ‚â•

Xi ‚â•

7
8

s.capacity
f.size

(cid:21)

E[S]

7
4

(cid:26)(cid:16)

(cid:26)(cid:16)

log

log

e
4
e
4

(cid:26)

‚àí0.144

‚â§exp

‚â§exp

‚â§exp

(cid:27)

E[S]

(cid:17) 3
4

(cid:17) 3s.capacity
8f.size
s.capacity
f.size

(cid:27)

By applying union bound, we obtain
(cid:20)
1
8

‚àÉs,s.f reeCap ‚â§

s.capacity

‚â§ Nsexp

(cid:21)

Pr

(cid:26)

‚àí0.144

s.capacity
f.size

(cid:27)
.
(cid:3)

APPENDIX C
PROOF OF THEOREM 3
We deÔ¨Åne the state of a FileInsurer network as (F,S,A,C)
consisting of Ô¨Åles F ,sectors S, all allocations A, and
corrupted bits C in the network. Also, we deÔ¨Åne V (F,S,A,C)
lost
as the sum of values of the lost Ô¨Åles and V (F,S,A,C)
conf iscated as the
conÔ¨Åscated deposits of the corrupted sectors.

Lemma 1 For a speciÔ¨Åc state (F, S, A, C), keeping the
content and availability of each physical disk in the network
unchanged, it can be viewed as another state (F (cid:48), S, A(cid:48), C)
where the value of each Ô¨Åle is minV alue. State (F (cid:48),S,A(cid:48),C)
satisÔ¨Åes V (F,S,A,C)

‚â§ V (F (cid:48),S,A(cid:48),C)

.

lost

lost

Proof: We divide each Ô¨Åle descriptor f to f.value
minV alue differ-
ent Ô¨Åle descriptors. These Ô¨Åle descriptors all have the value
minV alue and the same Merkle root as that of f . Divide the
f.cp allocations of f equally among these new Ô¨Åle descriptors,
so each Ô¨Åle descriptor have exactly k allocations. By deÔ¨Åning
F (cid:48) as all these new Ô¨Åle descriptors, A(cid:48) as these new Ô¨Åle
allocations, we construct a state (F (cid:48), S, A(cid:48), C) such that the
value of each Ô¨Åle is minV alue.

conf iscated = V (F (cid:48),S,A(cid:48),C)

The content and availability of each physical disk in the
network are same in state (F,S,A,C) and state (F (cid:48),S,A(cid:48),C).
Since we do not change the state of sectors, we simply
obtain V (F,S,A,C)
conf iscated . For each Ô¨Åle f lost in
state (F,S,A,C), since all its backups are lost, every new Ô¨Åle
descriptor generated by f in state (F (cid:48),S,A(cid:48),C) also lost. The
value of the Ô¨Åle f is equal to the sum of the values of the
Ô¨Åle descriptors it generates, so V (F,S,A,C)
. (cid:3)

‚â§ V (F (cid:48),S,A(cid:48),C)

lost

lost

Lemma 2 ‚àÄ0 < p ‚â§ 1

5 and 5p ‚â§ x ‚â§ 1, DKL(x||p) ‚â• 1

2 xlog x
p .

Proof:
Let

In the proof below, we will use x ‚â• p unspeciÔ¨Åed.

Ô£±
Ô£¥Ô£¥Ô£≤

Ô£¥Ô£¥Ô£≥

p ‚àí(1‚àíx)2log 1‚àíx
1‚àíp
(cid:16)
(cid:17)

‚àílog x

p +x‚àí1

f (x) = x2log x
g(x) = log x‚àí1
p‚àí1
xlog x
p
‚àí(1‚àíx)log 1‚àíx
1‚àíp

h(x) =

‚àíxlog x
p

whose domain is x ‚àà [p, 1]. First, we have f (x) ‚â• 0
because df
dx = 1 + 2DKL(x||p) ‚â• 0 and f (p) = 0. Then,
dx = f (x)
we have g(x) ‚â• 0 because dg
x(1‚àíx) ‚â• 0 and g(p) = 0.
Finally, we obtain h(x) is monotonically increasing because
dh
dx =

g(x)
(x‚àí1)2log2 1‚àíx
1‚àíp

‚â• 0.

Because h(x) is monotonically increasing, ‚àÄx ‚â• 5p,

h(x) ‚â• h(5p) =

5plog5
(1‚àí5p)log 1‚àíp
1‚àí5p

. We can Ô¨Ånd that

d
dp

5plog5
(1‚àí5p)log 1‚àíp
1‚àí5p

=

(cid:16)

(1‚àíp)log 1‚àíp
5log5
1‚àí5p ‚àí4p
(cid:17)
(1‚àí5p)2(1‚àíp)log2(cid:16) 1‚àíp

1‚àí5p

(cid:17)

(cid:16)
(cid:17)
(1‚àíp)(1‚àí 1‚àí5p
5log5
1‚àíp )‚àí4p
(cid:17)
(1‚àí5p)2(1‚àíp)log2(cid:16) 1‚àíp

1‚àí5p

‚â•

=0.

When p ‚Üí 0,

5plog5
(1‚àí5p)log 1‚àíp
1‚àí5p

> 2, so ‚àÄ0 < p ‚â§ 1
5 ,

5plog5
(1‚àí5p)log 1‚àíp
1‚àí5p

>

2, that is ‚àÄx ‚â• 5p,h(x) > 2. At last,

DKL(x||p) = xlog

+(1‚àíx)log

x
p

1‚àíx
1‚àíp

Then all Xi are independent events and Pr[Xi] = Œªk when any
sectors with total space of ŒªNs √óminCapacity are corrupted.
minV alue . By Chernoff bound and lemma 2,

Denote Œ≥ = V v

lost

when Œ≥ ‚â• 5NvŒªk, we obtain

(cid:34)

Pr

(cid:88)

Xi ‚â• Œ≥

(cid:35)

i
(cid:26)

‚â§exp

‚àíNv

(cid:26)

‚â§exp

‚àí

Œ≥
2

log

(cid:18) Œ≥
Nv
Œ≥
NvŒªk

log

Œ≥
NvŒªk +
(cid:27)

.

(cid:18)

1‚àí

Œ≥
Nv

(cid:19)

log

Nv ‚àíŒ≥
Nv ‚àíNvŒªk

(cid:19)(cid:27)

Consider the number of scenarios in which an adversary
can corrupt sectors with capacity ŒªNs √óminCapacity. Here
we do a simple scaling that treat a sector with s.capacity
s.capacity
minCapacity sectors with capacity minCapacity.
capacity as
After this scaling, the adversary has (cid:0) Ns
(cid:1) options to corrupt
ŒªNs
sectors. Therefore, for the original situation, the number of
scenarios in which an adversary can corrupt sectors with
capacity ŒªNs √óminCapacity does not exceed (cid:0) Ns
ŒªNs

(cid:1).

By union bound, when Œ≥ ‚â• 5NvŒªk, the probability it cannot

(cid:19)

1‚àí

manufacture Œ≥ lost Ô¨Åles is at least
Œ≥
Œ≥
NvŒªk
2
(cid:16)
2 , we have log Œ≥
NvŒªk ‚â• log

(cid:18) Ns
ŒªNs

exp

When Œ≥ ‚â• NvŒª k
Then we Ô¨Ånd that

log

‚àí

(cid:26)

(cid:27)

.

(cid:17)

‚àík
2

Œª

= ‚àí k

2 logŒª.

= xlog

= xlog

x
p

x
p

(cid:32)

1+

(cid:18)

1‚àí

(1‚àíx)log 1‚àíx
1‚àíp
xlog x
p
(cid:19)

1
h(x)

(cid:33)

‚áîŒ≥

‚áí

Œ≥
2

k
4

log

1
Œª
Œ≥

‚â•

1
2

xlog

x
p

.

(cid:3)

Lemma 3 Assume that the total size of corrupted sectors is
ŒªNs √ó minCapacity. Denote the total value of lost Ô¨Åles to
be Vlost. Then, with a probability of not less than 1‚àíc, Vlost
satisÔ¨Åes

Vlost ‚â§ minV alue√ómax

5NvŒªk,NvŒª

k
2 ,4

(cid:40)

(cid:1)‚àílogc

log(cid:0) Ns
ŒªNs
klog 1
Œª

(cid:41)
.

Proof:

Because of lemma 1, we can make the relaxation
of that each Ô¨Åle has value minV alue in subsequent analysis.
Under the relaxations,
the setting of the problem can be
simpliÔ¨Åed as follow: there are Nv Ô¨Åles, each Ô¨Åle has the same
value minV alue and needs to be stored in k sectors. Each
storage location of each Ô¨Åle is generated independent and
identically distributed.

For any certain scheme that the adversary corrupts Œª ratio of
capacity, which means that the total size of corrupted sectors is
ŒªNs √óminCapacity, deÔ¨Åne random variable Xi as the indica-
tor variable of that the Ô¨Åle fi is lost. Recall storage randomness
indicates that all replicas are evenly and randomly distributed.

(cid:1)

‚â§

‚áî

exp

‚áîexp

(cid:18) Ns
ŒªNs

c
(cid:0) Ns
ŒªNs
(cid:27)

Œ≥
NvŒªk
(cid:26)
Œ≥
2
This shows that when Œ≥ meets the above three conditions,
the probability that an adversary can make Œ≥ lost Ô¨Åles does
not exceed 1‚àíc, that is, Œ≥ needs to satisfy
log(cid:0) Ns
ŒªNs
klog 1
Œª

Œ≥
NvŒªk

5ŒªkNv,Œª

(cid:1)‚àílogc

Œ≥ ‚â§ max

2 Nv,4

‚â§ c.

log

(cid:41)

(cid:40)

‚àí

.

k

Therefore, with a probability of no less than 1 ‚àí c, V v
(cid:41)
.

satisÔ¨Åes
V v
lost ‚â§ minV alue√ómax

5NvŒªk,NvŒª

(cid:1)‚àílogc

k
2 ,4

(cid:40)

lost

log(cid:0) Ns
ŒªNs
klog 1
Œª

(cid:3)

Theorem 3 Assume that the total size of corrupted sectors
is ŒªNs √óminCapacity. Denote the total value of lost Ô¨Åles to
be Vlost, and Œ≥v
Sv√óminV alue represents the ratio of the
value of lost Ô¨Åles to the total value of all Ô¨Åles. Then with a

lost =

Vlost

Œ≥ ‚â• 4

(cid:1)‚àílogc

log(cid:0) Ns
ŒªNs
klog 1
Œª

‚â• ‚àílog

c
(cid:0) Ns
ŒªNs

(cid:1)

c
(cid:0) Ns
ŒªNs
c
(cid:0) Ns
ŒªNs

(cid:1)

(cid:1)

log

Œ≥
2
(cid:26)

NvŒªk ‚â• ‚àílog
Œ≥
NvŒªk ‚â§ log
log
(cid:27)
Œ≥
2
(cid:19)

log

‚àí

‚áî‚àí

Considering the third part, we have
(cid:1)‚àílogc

4

log(cid:0) Ns
Œª(cid:48)Ns
v klog 1
Œª(cid:48)N m
Œª(cid:48)
(cid:16)
N Œª(cid:48)Ns
4log
s
v klog 1
Œª(cid:48)

Œª(cid:48)N m

‚â§Œª(cid:48)‚â§Œª

(cid:17)

‚â§ max
1
Ns

‚àí4logc

4Œª(cid:48)NslogNs ‚àí4logc

= max
1
Ns
(cid:32)

‚â§Œª(cid:48)‚â§Œª

1
Ns

max
‚â§Œª(cid:48)‚â§Œª
4NslogNs
v klog 1
N m
Œª

‚â§

‚â§

Then

Œª(cid:48)N m

v klog 1
Œª(cid:48)
(cid:33)

4NslogNs
v klog 1
N m
Œª(cid:48)
‚àí4Nslogc
N m
v klogNs

+

.

+

(cid:32)

max
‚â§Œª(cid:48)‚â§Œª

1
Ns

‚àí4logc
v klog 1
Œª(cid:48)

Œª(cid:48)N m

(cid:33)

(cid:26)

5Œªk‚àí1,Œª

k

2 ‚àí1,

4NslogNs
v klog 1
N m
Œª

+

‚àí4Nslogc
N m
v klogNs

(cid:27)

.

Œ≥deposit ‚â• max
As capP ara = N m
v
Ns
5Œªk‚àí1,Œª

Œ≥deposit ‚â• max

(cid:26)

,

k

2 ‚àí1,

4
k√ócapP ara

(cid:18) logNs
log 1
Œª

+

log 1
c
logNs

(cid:19)(cid:27)

.

(cid:3)

probability of not less than 1‚àíc, Œ≥v
2œÄ ‚àílogc
Ns
v klog 1
Œ≥m

Œ≥v
lost ‚â§ max

5Œªk,Œª

lost satisÔ¨Åes
‚àílog(cid:0)ŒªŒª(1‚àíŒª)1‚àíŒª(cid:1)(cid:17)
Œª √ócapP ara

(cid:16) log e

Ô£±
Ô£≤

k
2 ,

4

Ô£≥

Ô£º
Ô£Ω
.
Ô£æ

Proof:

Now we use an upper bound of the binomial

number via Stirling‚Äôs formula,

(cid:19)

(cid:18) Ns
ŒªNs

Ns!
(ŒªNs)!(Ns ‚àíŒªNs)!

=

‚â§

=

‚â§

N Ns+ 1

2

s

(ŒªNs)ŒªNs+ 1
(cid:115)

1
NsŒª(1‚àíŒª)

2

(cid:18)

2 (Ns ‚àíŒªNs)Ns‚àíŒªNs+ 1
(cid:19)Ns
1
ŒªŒª(1‚àíŒª)1‚àíŒª
(cid:19)Ns

(cid:18)

1
ŒªŒª(1‚àíŒª)1‚àíŒª

e
2œÄ

e
2œÄ

e
2œÄ

Using this upper bound, we can have a simpler version of
Œ≥v
lost:

(cid:40)

Œ≥v
lost ‚â§ max

5Œªk,Œª

k
2 ,4

(cid:40)

= max

5Œªk,Œª

k
2 ,4

log e

2œÄ ‚àíNslog(cid:0)ŒªŒª(1‚àíŒª)1‚àíŒª(cid:1)‚àílogc
Nvklog 1
Œª

(cid:41)

log e

2œÄ ‚àílogc
Ns

‚àílog(cid:0)ŒªŒª(1‚àíŒª)1‚àíŒª(cid:1)
v klog 1
Œª

capP ara¬∑Œ≥m

(cid:41)

(cid:3)

APPENDIX D
PROOF OF THEOREM 4

Theorem 4 Assume that the total size of corrupted sectors
is no more than ŒªNs √ó minCapacity. If the deposit ratio
satisÔ¨Åes

Œ≥deposit ‚â• max

5Œªk‚àí1,Œª

(cid:26)

k

2 ‚àí1,

4
k√ócapP ara

(cid:18) logNs
log 1
Œª

+

log 1
c
logNs

(cid:19)(cid:27)

,

then full compensation can be achieved with a probability
of not less than 1‚àíc.

Proof: By assumption, the total size of corrupted sectors
is no more than ŒªNs √óminCapacity. Because the deposit of
corrupted sectors should always cover the Ô¨Åle loss, for all 1
‚â§
Ns
Œª(cid:48) ‚â§ Œª we shall have Œª(cid:48)Œ≥depositN m
v ‚â• Œ≥, which is equivalent
to
(cid:26) Œ≥

(cid:27)

Œ≥deposit ‚â• max

.

‚â§Œª(cid:48)‚â§Œª
Then with probability no less than 1‚àíc, the following Œ≥deposit
is enough for full compensation

1
Ns

Œª(cid:48)N m
v

Œ≥deposit ‚â• max

max

1
Ns

‚â§Œª(cid:48)‚â§Œª

(cid:40)

5(Œª(cid:48))k‚àí1,(Œª(cid:48))

k

2 ‚àí1,4

(cid:1)‚àílogc

log(cid:0) Ns
Œª(cid:48)Ns
v klog 1
Œª(cid:48)N m
Œª(cid:48)

(cid:41)

.

