FileInsurer: A Scalable and Reliable Protocol
for Decentralized File Storage in Blockchain

Hongyin Chen∗†, Yuxuan Lu∗‡, Yukun Cheng§¶
†‡Center on Frontiers of Computing Studies, Peking University, Beijing, China
§Suzhou University of Science and Technology, Suzhou, China
Email: †chenhongyin@pku.edu.cn, ‡yx lu@pku.edu.cn, ¶ykcheng@amss.ac.cn

2
2
0
2

l
u
J

4
2

]

R
C
.
s
c
[

1
v
7
5
6
1
1
.
7
0
2
2
:
v
i
X
r
a

Abstract—With the development of blockchain applications,
the requirements for ﬁle storage in blockchain are increasing
rapidly. Many protocols, including Filecoin, Arweave, and Sia,
have been proposed to provide scalable decentralized ﬁle storage
for blockchain applications. However, the reliability is not well
promised by existing protocols. Inspired by the idea of insurance,
we innovatively propose a decentralized ﬁle storage protocol in
blockchain, named as FileInsurer, to achieve both scalability
and reliability. While ensuring scalability by distributed storage,
FileInsurer guarantees reliability by enhancing robustness and
fully compensating for the ﬁle loss. Speciﬁcally, under mild
conditions, we prove that no more than 0.1% value of all ﬁles
should be compensated even if half of the storage collapses.
Therefore, only a relatively small deposit needs to be pledged by
storage providers to cover the potential ﬁle loss. Because of lower
burdens of deposit, storage providers have more incentives to
participate in the storage network. FileInsurer can run in the top
layer of the InterPlanetary File System (IPFS), and thus it can be
directly applied in Web 3.0, Non-Fungible Tokens, and Metaverse.
Storage, Blockchain
application, Mechanism Design, Decentralized System, Insurance

Terms—Decentralized

Index

File

I. INTRODUCTION

File storage is a fundamental issue in distributed systems.
Recently, the developments of Web 3.0 [1], Non-Fungible
Tokens (NFTs) [9, 22], and Metaverse [20] have raised high
requirements on reliability and accessibility of ﬁle storage. For
example, the metadata of NFTs should be veriﬁable and acces-
sible in NFT markets, as the values of NFTs disappear if the
metadata is lost. Billions of metadata generated by blockchain
applications are searching for reliable storage services.

Traditionally, people store ﬁles in personal storage or cloud
storage service. However, personal storage struggles to keep
ﬁles secure and accessible. Additionally, cloud storage lacks
transparency and trust [5]. It is hard for users to recognize
how many backups of their ﬁles should be stored to guarantee
security. Moreover, ﬁle loss often occurs in cloud storage.

Due to the defects of personal storage and cloud storage,
more and more users choose to store ﬁles in the blockchain-
based Decentralized Storage Networks
such as
Sia [21], Filecoin [4], Arweave [24], and Storj [23]. In a DSN,

(DSNs)

This work has been performed with support from the National Natural
Science Foundation of China (No. 11871366), Qing Lan Project of Jiangsu
Province, China, and the Algorand Foundation Grants Program

∗ These authors contributed to the work equllly and should be regarded

as co-ﬁrst authors.

§ Yukun Cheng is the corresponding author.

storage providers contribute their available hard disks to store
ﬁles from clients and then earn proﬁts. The storing, discarding,
and storing state-changing events of ﬁles are recorded in the
blockchain. Files can be stored by multiple storage providers
to enhance security. Additionally, in Filecoin, backups are
changed to be replicas, once they have been proved by proof-
of-replication (PoRep). PoRep well resists Sybil attacks [13]
by a storage provider, who may pretend to store multiple
backups by forging multiple identities, while she actually
only stores one backup. PoRep can also be used to ensure
providers cannot cheat on the available storage space.

However, the existing DSN protocols do not well promise
the reliability. In DSN, there are always ﬁles only stored by a
small part of storage providers due to the issue of scalability.
Therefore, it is impossible to completely avoid loss of ﬁles.
When ﬁles are lost, the owners of these ﬁles only receive
little compensation.

In this paper, we aim to enhance the reliability of
decentralized ﬁle storage from the perspective of economic
incentive approaches. For the Bitcoin Blockchain [17], the
most success is to apply the economic incentive approach,
by awarding a certain amount of token to encourage miners
to actively mine. Thus, in the era of blockchain, the issue of
economic approaches is getting more and more important. We
build a decentralized insurance scheme on ﬁles stored in DSN
to protect the interests of users when their ﬁles are lost. Under
the insurance scheme, storage providers need to pledge a
deposit before storing ﬁles. If a ﬁle is lost, which means that all
providers storing this ﬁle are corrupted, the total deposit from
these providers can fully compensate for the loss of this ﬁle.
We hope that the deposit should be small to incentivize
participants to contribute their storage space. Let us denote
deposit ratio to be the ratio of the sum of deposits to the
total value of ﬁles. Chen et. al. [11] ﬁrstly studied how to
decrease the deposit ratio in the decentralized custody scheme
with insurance. However, the methodology in [11] cannot be
directly applied in our scenario. The reason is that storage
providers and ﬁles change over time in DSN, while [11] is
only suitable for static setting. Our approach is to achieve
provable robustness by ensuring storage randomness. Storage
randomness requires the locations of replicas are randomly
selected by DSN, such that
these locations are uniformly
distributed. Consequently, the attackers must corrupt a consid-

 
 
 
 
 
 
erable portion of providers even if they only want to destroy all
backups of a small portion of ﬁles. Therefore, the randomness
can promises that only a relatively small deposit needs to be
pledged by storage providers to cover the potential ﬁle loss.

Main Contributions

We propose FileInsurer, a novel design for blockchain-based
Decentralized Storage Network, to achieve both scalability and
reliability of ﬁle storage. In our protocol, storage providers
are required to pledge deposits to registered sectors and the
locations of ﬁles are randomly selected. To further ensure
storage randomness, locations of ﬁles’ replicas shall change
from time to time because the list of sectors is dynamic.

Our protocol advances the technology of decentralized ﬁle

storage in the following three aspects.

randomness. FileInsurer

• Firstly, FileInsurer supports dynamic content stored in
sectors with low cost, which is necessary to ensure
storage
deploys Dynamic
Replication (DRep) to support adding and refreshing
stored ﬁles. DRep is also able to resist Sybil attacks and
make sure the free space of sectors is indeed available.
• Secondly, FileInsurer can achieve provable robustness.
In FileInsurer, ﬁles are stored as replicas in sectors.
Naturally, a ﬁle is missing, if and only if all replicas
of this ﬁle have been destroyed. A sector is collapsed,
as long as any bit in this sector is lost. Under mild
conditions, we prove that no more than 0.1% value of
all ﬁles are lost even if half of the storage collapses.
• Thirdly, FileInsurer implements an insurance scheme on
DSN that can provide full compensation for the loss of
those missing ﬁles. The compensation is covered by the
deposit of all crashed storage sectors. Our theoretical
analysis indicates that only a small deposit ratio is
needed to cover all of the ﬁle loss in FileInsurer.
To the best of our knowledge, FileInsurer is the ﬁrst DSN
protocol that can provide full compensation for the ﬁle loss
and has provable robustness.

Paper Organization

The rest of this paper is organized as follows. Section II
introduces the related works of decentralized storage protocols.
In Section III, we describe the structure and components
of FileInsurer protocol. Then, we continue to introduce the
protocol design of FileInsurer in Section IV. In Section V, we
propose the theoretical analysis on the scalability, robustness,
and deposit issue of our protocol. We also compare FileInsurer
with other blockchain-based decentralized storage protocols.
In addition, some practical problems in FileInsurer are
detailedly discussed in Section VI. Finally, we summarize
our protocol and raise some open problems in Section VII.

II. RELATED WORKS

A. InterPlanetary File System (IPFS)

The InterPlanetary File System (IPFS) is a peer-to-peer
distributed ﬁle system that seeks to connect all computing
devices with the same system of ﬁles [2]. Files, identiﬁed

by their cryptographic hashes, are stored and exchanged by
nodes in IPFS. Nodes also provide the service of retrieving
ﬁles to earn proﬁts through BitSwap protocol. The routing of
IPFS is achieved by Distributed Hash Tables (DHTs), which
is an efﬁcient way to locate data among IPFS nodes. Based
on BitSwap and DHTs, IPFS builds an Object Merkle DAG
which allows participants to address ﬁles through IPFS paths.

B. FileCoin

Filecoin builds a blockchain-based Decentralized Storage
Network which runs in the top layer of IPFS [4]. There are
three types of participants in Filecoin, which are clients,
storage miners, and retrieval miners. Speciﬁcally, clients pay
to store and retrieve ﬁles, storage miners earn proﬁts by
registering sectors to offer storage, and retrieval miners earn
proﬁts by serving data to clients.

1) Proof-of-Replication (PoRep): PoRep [3] is a kind of
proof-of-storage scheme deployed in Filecoin. In the PoRep
the prover ﬁrstly generates a replica of ﬁle D,
scheme,
denoted by RD
ek, through the process of PoRep.setup(D,ek).
ek is a randomly chosen encryption key that with ek, RD
ek
can be encrypted from D, and D can be decrypted from RD
ek.
The prover then submits the hash root of RD
ek to the DSN.
Finally, the prover proves that RD
ek is a replica of D with
encryption key ek via SNARK.

The veriﬁcation of SNARK is very efﬁcient. However,
the calculation of RD
ek would take a lot of time because it
can’t be parallelized. Additionally, the calculation of SNARK
would consume lots of computation resources.

2) Filecoin Sectors: In Filecoin, sectors are divided into
sealed ones and unsealed ones1. Only sealed sectors are
part of the Filecoin network and can get rewards of storage.
Unsealed sectors only contain raw data, and a sealed sector
can be registered from an unsealed sector by PoRep. Storage
miners would pledge deposits when registering a sector, but
when the sector crashes, that deposit is burnt other than used
for compensating the ﬁle loss to clients.

When registering an unsealed sector, if the sector is not
full, the rest space of the sector would be ﬁlled with zeros
before encoding by PoRep. If a sealed sector doesn’t contain
any ﬁles, which means the contents of that sector are all
zeros when registering, it’s called a committed capacity (CC).
Other sealed sectors are called regular sectors. A CC sector
can be upgraded to a regular sector by discarding the CC
the
sector and registering a new regular sector. However,
content of a regular sector can be no longer changed.

3) Proof-of-Spacetime: PoSt is another kind of proof-of-
storage scheme for storage miners to prove that
they are
indeed actually storing a replica. There are two kinds of PoSt
in Filecoin. WinningPoSt serves as a part of the Expected
Consensus of Filecoin, while WindowPoSt guarantees that
the miner continuously maintains a replica over
time.
Therefore, Sybil attacks are prevented by the combination
of WindowPoSt and PoRep because storage miners should
actually store all replicas.

1See in https://spec.ﬁlecoin.io/systems/ﬁlecoin mining/sector/

4) Storage Market and Retrieval Market: There are two
markets in Filecoin, the Storage Market and the Retrieval Mar-
ket. In the Storage Market, storage miners and clients negotiate
on the price and length of storage. Similarly, retrieval miners
and clients would negotiate on the price of ﬁle retrieving.

C. Other Solutions to Decentralized File Storage

1) Storj: Storj [23] is a sharding [16, 26] based protocol
to archive a peer-to-peer cloud storage network implementing
end-to-end encryption. It stores ﬁles in encrypted shards to
ensure that the ﬁle itself cannot be recovered by anyone other
than the owner. Moreover, it uses erasure code to ensure ﬁle
availability in case some shards are lost.

2) Sia: Sia [21] is a platform for decentralized storage
enabling the formation of storage contracts between peers. The
Sia protocol provides an algorithm of storage proof in order to
build storage contracts. According to the ﬁle contract, storage
providers need to generate proof-of-storage periodically. The
client needs to pay for each valid storage proof.

3) Arweave: Arweave [24] is a mechanism design-based
approach to achieving a sustainable and permanent ledger
of knowledge and history. Storing ﬁles on Arweave only
requires a single upfront fee, after which the ﬁles become
part of the consensus. Arweave uses the mechanism of Proof
of Access in consensus to ensure that miners need to store as
many ﬁles as possible to participate in mining.

III. PRELIMINARIES

FileInsurer

is a protocol

to build a blockchain-based
Decentralized Storage Network (DSN) [5]. The structure of
DSN could be an independent blockchain or a decentralized
application (DApp) parasitic on existing blockchains or other
distributed network types. In DSN, a group of participants,
called storage providers, are willing to rent out their unused
hardware storage space to store the clients’ ﬁles, and then
the distributed ﬁle storage is realized.

In this section, we introduce the structure and components
of FileInsurer protocol. Particularly, we deploy Dynamic
Replication (DRep) to support dynamic content in sectors
to ensure storage
with low cost, which is
randomness. Additionally, we also explain why compensation
is necessary for DSN.

important

A. Participants

There are two kinds of participants in DSN that are clients

and storage providers.

1) Client: Clients are the participants who have the demand
to store ﬁles in the network. They propose a request to declare
which ﬁle needs to be stored, via File Add request. Once
her ﬁle is stored, the client shall pay the rent for the storage
service at periodic intervals (introduced in Section IV-A),
which depends on the ﬁle’s value and size. They also can ask
DSN to discard their ﬁles stored before, via File Discard
request. Besides, clients can retrieve any ﬁle stored in DSN,
via File Get request, by paying the retrieving payment. As
the uploaded ﬁles are public in DSN, clients can encrypt their
ﬁles before uploading if she concerns about privacy.

2) Storage Providers: Storage Providers are the participants
who rent out their hard disks to store clients’ ﬁles and offer the
service of retrieving ﬁles in exchange for payments. When re-
ceiving the File Add request from a client, DSN automatically
selects several independent storage providers to store this ﬁle,
so that the robustness could be guaranteed by replicating ﬁles.
After receiving a ﬁle from a client, providers need to declare
that they have obtained this ﬁle by File Conﬁrm request. In
addition, after storing a ﬁle, it is necessary for providers to
repeatedly submit the proofs of ﬁle storage to DSN at each
speciﬁed checkpoint, to show that they are storing this ﬁle,
via File Prove request. In order to guarantee security, each
storage provider must pledge a deposit, so that her deposit
could be liquidated to compensate for the loss of clients once
her disk is corrupted. When a client requests retrieval of
a speciﬁed ﬁle, the providers, who store this ﬁle, compete
to respond to the request for the corresponding payment.
Hence a Retrieval Market is formed, in which the clients and
providers exchange the ﬁle without the witness of DSN.

B. Data Structures

Figure 1 shows a brief description of the data structures
of the FileInsurer. There are four main data structures, which
are sector, ﬁle descriptor, allocation table, and pending list.

1) Sector: A disk sector is the smallest unit that a provider
rents out to store ﬁles. Sector sizes vary but are required to
be an integer multiple of a minimum value of minCapacity.
to 64GB or other deterministic
minCapacity can be set
value. A sector is considered to be corrupted, as long as any
bit in this sector is destroyed. A ﬁle is missing, if and only
if the sectors storing this ﬁle are all corrupted. In FileInsurer
protocol, providers could divide their storage spaces into
multiple sectors, and are not allowed to register multiple disks
as the same sector. In addition, FileInsurer requires that a ﬁle
is integratedly stored in a sector, instead of being dispersed
into multiple sectors. Such a requirement ensures the owner
of a lost ﬁle obtains the compensation, which can completely
make up for her loss.

2) File descriptor: The ﬁle descriptor f describes a ﬁle
stored in the network, including its size, value, Merkle root,
the number of copies, and other necessary information. When
a ﬁle is stored, the following two conditions must be satisﬁed.
• The total size of the ﬁles stored in a sector must not

exceed the capacity of this sector.

• If a ﬁle f is lost, meaning all sectors storing it are all
corrupted, then the deposits from these sectors are at
least f.value to make up the loss of the ﬁle’s owner.

selects

3) Allocation table: FileInsurer

some feasible
sectors to store a ﬁle and makes a note of it recorded in the
allocation table. The allocation table will be updated when a
ﬁle is stored in the network, a ﬁle is discarded, or the storage
location of a ﬁle is transferred. The allocation table is a part
of the network consensus and can support fast random access.
4) Pending list: In the design of FileInsurer, some tasks
need to be automatically executed at a speciﬁc time in the
future, such as regularly checking whether a ﬁle is saved

correctly. Therefore FileInsurer needs to maintain a pending
list to save these tasks and their corresponding execution time.
When a new time point t is reached, the tasks in the pending
list whose timestamp is t will be automatically executed by
the network. As the gas fee for these tasks should be paid in
advance, tasks that are placed in the pending list must have a
clear gas used upper bound. In the basic design of FileInsurer,
these tasks are only generated through network consensus.

Data structures

Sector
sector : (owner, id, capacity, freeCap, state)
• owner: the provider who owns the sector.
• id: the id of the sector, a provider cannot have two sectors

with the same id.

• capacity: the storage capacity of the sector.
• freeCap: current free capacity of the sector.
• state: normal means this sector has capacity to accept new
ﬁles, disable means the sector no longer accepts new ﬁles.

File descriptor
ﬁleDescriptor : (size, value, merkleRoot, cp, cntdown, state)

• size: the size of the ﬁle.
• value: the value of the ﬁle.
• merkleRoot: merkle root of the ﬁle.
• cp:

determined by the ﬁle value.

the number of replicas to be stored in the network,

• cntdown: the number of checkpoints until the next refresh of

the ﬁle store.

• state: normal means this ﬁle needs to be stored, discard

means this ﬁle is discarded.

Allocation table
allocTable : {(ﬁleDescriptor, index) → allocEntry}
allocEntry : (prev, next, last, state)

• prev: the current sector storing the ﬁle.
• next: the next sector to store the ﬁle.
• last: time of the last proof of storage.
• state: alloc means the ﬁle is being (re)allocated to a sector,
confirm means that the ﬁle is conﬁrmed by the next sector
to store, normal means the current sector is storing the ﬁle,
corrupted means the current sector is corrupted.

Pending list
pendingList : {time → [task,task,...]}

• time:

time point when the tasks need to be automatically

executed.

• task: description and parameters of the task to be executed.

Fig. 1. The data structures of FileInsurer

C. Interactions between Participants and Network

This subsection introduces the abovementioned operations

performed by clients and storage providers in detail.

1) Client requests:
• File Add: Client stores a ﬁle in DSN.

A client submits an order through a File Add request to
inform DSN of the ﬁle’s description f , containing size
f.size, value f.value, Merkle root f.merkleRoot, the
number of replicas f.cp, and other necessary information.
DSN automatically allocates feasible f.cp sectors. When
these sectors are found, the client transmits the ﬁle to
these sectors.

• File Discard: Client discards a ﬁle stored in DSN.

It is not necessary for clients to specify how long to
store the ﬁle in advance. As an alternative, the client can
discard the ﬁle at any time by submitting File Discard
request, which contains the description f of this ﬁle, to
DSN.

• File Get: Client retrieves a ﬁle from DSN.

Each client can request any ﬁle in DSN, via File Get
request, by paying a certain amount of tokens. Because
this requested ﬁle is available in multiple providers’
sectors, the retrieve request can be satisﬁed by receiving
one of the copies from these providers.

2) Provider requests:

• Sector Register: Provider registers a new sector in

DSN.
When providers launch a new storage space, they have
two options. One is to register the whole storage space
as one sector. The other is to divide this space into
several parts and each part is registered as one sector.
When a sector is registered, the provider shall pledge a
deposit proportional to the capacity of this sector.

• Sector Disable: An operation to afﬁrm that a sector no

longer accepts new ﬁles.
In the design of FileInsurer protocol, providers are not al-
lowed to revoke the sectors they leased on the network be-
fore. Instead, when a provider decides not to provide stor-
age service from a sector, she shall declare that the sector
is disabled, that it is no longer accepts any new ﬁle. After
all ﬁles stored in this sector are allocated to other sectors
by the network, the sector is removed from the network.
• File Conﬁrm: The provider conﬁrms to the network

that a ﬁle has been received.
The network automatically speciﬁes the storage sector
for ﬁles, and the provider of the sector needs to conﬁrm
to the network after receiving the client’s ﬁle.

• File Prove: The provider submits the certiﬁcate to the

network of its correct storage of ﬁles.
When providers store the ﬁles,
they must repeatedly
submit proofs of replication to ensure they are storing
the ﬁles. Proofs are posted on and veriﬁed by DSN.
• File Supply: The provider responds a File Get request

from a client.
Once the supply and demand relationship of one ﬁle has
been established, the transmission of this ﬁle would be
carried off-chain.

D. Dynamic Content in Sectors

In FileInsurer, the content of a sector needs to be dynamic
from time to time, which is supported by ensuring storage
randomness. FileInsurer can resist Sybil attack by storing the
ﬁles as multiple replicas. In FileInsurer, these replicas are
generated by PoRep, and the free capacity of a sector needs
to be proven that it is indeed available. A trivial idea is to
make a new replica of the sector whenever the content is
changed by PoRep. However, it is not a wise solution because

it would lead to an extremely high burden on providers and
much more veriﬁcation of PoRep.

We propose a novel solution called Dynamic Replication
(DRep) to solve this problem. Different from Filecoin, we
don’t encode a whole sector into a replica, but make each
ﬁle in a sector to be a unique replica. We deﬁne a Capacity
Replica (CR) as a replica of zeros bits generated by the
PoRep process. When a sector is registered, it should be just
ﬁlled with l unique CRs. The sector is requested to contain
as many CRs as possible while storing ﬁles. Therefore, the
unsealed space of a sector is smaller than the size of a CR.
Figure 2 shows some examples of DRep.

Fig. 2. Examples of DRep: Initially the sector contains six Capacity
Replicas (as shown in (a)). After ﬁlling some ﬁles, there are two Capacity
Replicas left (as shown in (b)). When the total size of ﬁles decreases, the
provider regenerates the CR3 (as shown in (c)).

Ensuring free space of sectors is indeed available by
CRs is an efﬁcient way. All CRs only need to be generated
by PoRep once and then veriﬁed continuously stored via
the provider
WindowPoSt [4]. If a CR has been thrown,
can recover it by PoRep.setup because the raw data of
a CR are zeros. It doesn’t need to go through the whole
PoRep process because the Merkle roots of CRs have been
previously veriﬁed. Therefore, DRep won’t bring an extra
veriﬁcation burden on the DSN and providers don’t need to
generate SNARK of PoRep again.

Additionally, FileInsurer changes the location of replicas
at a low cost. Consider that a replica of a ﬁle f needs to
be transferred to another sector. The provider do not need
to generate new replicas of f by PoRep, but just transfer
the old ones. Liveness issue occurs that a provider may not
transfer the replica of f to the successor provider. However,
it doesn’t bother because the successor provider can fetch the
source data of f from other providers and recover the replica
via PoRep.Setup. Similar to CRs, these replicas don’t need
to be veriﬁed again, and they can be recovered from the raw
ﬁle. Therefore, the movement of replicas is efﬁcient.

E. Storage Market and Retrieval Market

Similar to Filecoin, there are two markets in FileInsurer,
the Storage Market and the Retrieval Market. The Retrieval
Market in FileInsurer is the same as that in Filecoin. In the
DSN, clients can send the request to retrieve any ﬁle f . Any
participant with f or a replica of f can answer that request.
The process of retrieving is accomplished by BitSwap of
IPFS. However, the Storage Market in FileInsurer is quite
different from the one in Filecoin. In FileInsurer, the price
of storing a ﬁle is decided by the size and the value of that

ﬁle. Clients do not need to negotiate prices of storage with
providers and even do not need to specify who to store their
ﬁles. Prices for storage services may change over time, which
will be discussed in Section IV-A.

F. Source of Randomness

Just like other DSN protocols, FileInsurer needs a huge
amount of on-chain random bits. To achieve this with low
expense, we use a pseudorandom number generator [15, 18]
to generate long pseudo-random bits based on a short random
the issue of generating an unbiased
beacon. Additionally,
and unpredictable public random beacon in blockchain has
been well studied [6, 7, 12]. Combining the abovementioned
two technologies, we can cheaply get enough public pseudo-
random bits. In this paper, we omit the implementation of
generating and using random bits because it is too detailed
and not our main contribution.

G. Necessity of Compensation in DSN

Compensation is needed in DSN because the scalability of
DSN would lead to an unavoidable risk of missing data. Nec-
essarily, the scalability of storage means that a participant in
DSN only needs to store a very small part of all data in DSN.
Therefore, many data of DSN must only be stored by a small
part of participants. However, if a constant ratio, for example,
0.1, of sectors (or storage capacity) crash instantaneously,
some data may be lost. So DSN brings a huge risk of ﬁle loss.
To demonstrate more clearly, let us provide some other
concrete examples. In Storj, a ﬁle is lost if enough shards
of the ﬁle are not available beyond what can be recovered
by erasure code. In Filecoin, a ﬁle is lost, if and only if all
sectors storing replicas of this ﬁle crash down.

To balance the safety and the scalability of DSN,
compensation is an effective method to motivate users to take
part in the distributed ﬁle storage. The reasonable deposit
shall compensate the users’ loss from missing data.

IV. PROTOCOL DESIGN OF FILEINSURER

In this section, we introduce the protocol design of
FileInsurer in detail. The insurance scheme is introduced
into the protocol design so that the storage providers are
responsible for ﬁle loss and their deposit can fully compensate
the clients whose ﬁles are lost. To support the dynamical ﬁle
storing in sectors, storage randomness is needed to randomly
distribute the locations of replicas in DSN, which can be
realized by randomly selecting and refreshing the locations
of replicas. Additionally, ﬁles with higher values have more
replicas so it is harder to destroy all replicas of these ﬁles.

In FileInsurer, all ﬁle replicas and Capacity Replicas
are generated by PoRep, which means that WinningPoSt
can be easily achieved. Therefore, the Expected Consensus
deployed by Filecoin can be directly applied to our consensus
algorithm. Additionally, FileInsurer protocol can be deployed
as a smart contract or sidechain in other blockchain protocols
such as Ethereum [25] and Algorand [10, 14].

A. Fee mechanism

In our DSN design, clients need to pay a fee when they
obtain the storage service and retrieval service. Moreover,
there are three kinds of fees in FileInsurer, which are the
trafﬁc fee, storage rent, and prepaid gas fee.

1) Trafﬁc fee: The trafﬁc fee needs to be paid when a client
occupies the network bandwidth of providers by transmitting
ﬁles, retrieving ﬁles, or other interactions. The mechanism to
pay a trafﬁc fee is necessary because malicious clients may
transmit ﬁles but pay nothing to block the providers’ network.
The operation to upload trafﬁc fee must be committed to the
storage provider before the ﬁle transmission, and the provider
obtains the fee only when it has conﬁrmed the ﬁle.

2) Storage rent: Clients need to pay the storage rent for
the used storage space, which is proportional to the size of the
ﬁle times the number of replicas. The unit rent is the same for
all ﬁles, and the network informs the client how much rent it
should pay. The client will be automatically charged storage
rent in the task Auto CheckAlloc which will be introduced
in section IV-C. In particular, the network distributes revenue
by time period. In a time period, all storage rent is stored
in the network at ﬁrst. At the end of the period, the network
distributes the rent to owners of proper functioning sectors
during this period. Storage providers are paid proportionally
according to their
total storage capacity, without paying
attention to which ﬁle is stored in which sector.

3) Prepaid gas fee: After a client stores ﬁles on the
network, the network needs to periodically check the proof
and refresh the ﬁle storage locations. These operations use the
consensus space and thus incur a gas fee. The gas fee for these
operations should be prepaid by the user as these operations
are performed automatically. The prepaid gas fee shall be col-
lected together with storage rent through Auto CheckAlloc.
In addition, anyone who submits requests to the network
must pay a gas fee to avoid wasting valuable consensus space.
The design of the gas fee mechanism is part of the network
design. As our DSN design does not focus on the network
design, we can use other existing gas fee mechanisms and do
not detailedly address it in this work.

B. Deposit and Compensation

When registering a sector,

the storage provider should
pledge to DSN with a certain amount of deposit. The deposit
the sector safely quits the system or is
is locked until
corrupted. If the sector safely quits, the deposit would be
withdrawn to the storage provider. If the sector is corrupted,
the deposit must be conﬁscated.

When the deposit of a sector is conﬁscated, it shall be
stored in the network to compensate for lost ﬁles. File loss
in a network means that all its copies are no longer available,
i.e. those storage sectors storing the copies are all corrupted.
When a ﬁle is lost, the network shall provide users with
compensation equal to the value of the ﬁle. Values of ﬁles
are given by users when storing their ﬁles. If a user reports
a higher value than the value of her ﬁle, she would pay a

higher storage rent, and if she reports a lower value, the
compensation would be lower once her ﬁle gets lost.

The deposit ratio γdeposit of FileInsurer is deﬁned as the
ratio that the sum of deposits compared to the maximal value
of ﬁles stored in the network. It can be understood as how
much deposit is required for each unit of value stored in the
network. Thus, the lower the deposit ratio makes the providers
have more incentives to participate in the distributed storage
network, and thus make our protocol more competitive.

Now we show how to calculate the deposit by γdeposit
while registering a sector. Assume that the total size of sectors
in FileInsurer is Ns × minCapacity and the maximal total
value of stored ﬁles are N m
v ×minV alue. For a sector s with
capacity s.capacity, the deposit should be the proportion of
s.capacity in the network multiplied by the total deposit,
s.capacity
which is γdeposit × N m
Ns×minCapacity .
Let capP ara = N m
be a constant and the deposit becomes
v
Ns
s.capacity × γdeposit × capP ara×minV alue
, which can be
calculated only by s.capacity, γdeposit, and some constants.
The setting of γdeposit are discussed in Theorem 4.

v × minV alue ×

minCapacity

C. Main Protocol

TABLE I
DESCRIPTIONS OF PARAMETERS AND FUNCTIONS

Notation

Description

RandomSector()

SampleExp(x)

RandomIndex(f )

DelayP erSize

AvgRef resh

P roof Cycle

P roof Due

P roof Deadline

Sample a random sector. The probability
of selecting each sector is proportional
to its capacity.
Sample from an exponential distribution
with mean x.
Sample a number between 1 and f.cp
uniformly at random.
The maximum transmit time allowed per
unit ﬁle size. This constant multiplied by
the ﬁle size is the upper limit of the ﬁle
transfer time allowed by the network.
The number of P roof Cycles to refresh
the ﬁle storage on average
Time interval between each inspection
proof.
The speciﬁed upper limit of the time the
last proof until now.
The tolerable upper limit of the time the
last proof until now.

FileInsurer mainly includes three parts:
• File : protocols with File preﬁx handles the storage of

data on the network,

• Sector : protocols with Sector
sector registration and revocation,

preﬁx handles the

• Auto : protocols with Auto preﬁx are mainly used for
the maintenance of network. They are special because
they cannot be called by anyone and will be executed
automatically at a speciﬁc time.

Figure 3 proposes a brief overview of the protocol of
FileInsurer by explaining how ﬁles and sectors interact with

(a) Storing ﬁles on the network: First, the ﬁle should be informed to the network to get the sectors where the ﬁles are stored at. The client
then sends the ﬁle to those sectors. The ﬁle is successfully stored after the system executes Auto CheckAlloc, and the rent is paid every time
the system executes Auto CheckProof.

(b) Renting sectors to the network: After the sector has been registered, the ﬁle will be swapped into or out of the sector through
Auto Refresh from time to time. Moreover, the network may also inform the sector to take over new ﬁles by corresponding File Add.

Fig. 3. Brief overview of the protocol: How ﬁles and sectors interact with the network. The symbol “F” represents a ﬁle, and “R” represents a ﬁle replica.

the network. Table I lists all parameters and functions used
in FileInsurer protocol.

File protocol: client part

File Add

• Inputs. the size of the ﬁle sz, the value of the ﬁle val and the merkle

• Goal. generate the ﬁle descriptor for the ﬁle and allocate k sectors to

root of the ﬁle rt

it for storage

f ← (size = sz, value = val, merkleRoot = rt, cp =
backupCnt(val),cntdown = −1,state = normal)
count ← 0
for i ∈ [f.cp] do

number of backup ﬁles that need to be stored is calculated
by f.cp = f.value
minV alue k, where minV alue is a parameter repre-
senting the lower limit of the ﬁle value of network storage and
each f.value must be integer multiple of minV alue. Next,
the waiting time is calculated and the user needs to transfer
the ﬁle to the owner of the selected sectors before the waiting
time expires. Once the waiting time expires, a task named
as Auto CheckAlloc is performed automatically to conﬁrm
whether the ﬁle is successfully stored on the network. When
a client submits a File Discard request, the network simply
sets the state of the corresponding ﬁle descriptor to discard.

s ← RandomSector()
while s.f reeCap < f.size do
s ← RandomSector()

(cid:46) almost never happens

File protocol: provider part

let e be a reference of allocTable[f,i]
count ← count+1
e ← (prev = null,next = s,last = −1,state = alloc)

t ← N ow+DelayP erSize×f.size
add CheckAlloc(f ) to pendingList[t]

File Discard

• Inputs. a ﬁle descriptor f
• Goal. discard ﬁle f
f.state ← discard

Fig. 4. File Protocol: Add and discard ﬁles

1) File : Figure 4 shows the network response for the
clients’ File requests. When a client makes a File Add re-
quest, the network ﬁrst generates a ﬁle descriptor and samples
f.cp sectors for storage. The probability of each sector being
selected is proportional to the capacity of this sector. The

File Conﬁrm

• Inputs. ﬁle descriptor f , index i and sector s
• Goal. conﬁrm that a selected sector begins to store a speciﬁc ﬁle
check the request is from the owner of sector s
verify allocTable[f,i].next = s and allocTable[f,i].state = alloc
entry.state ← confirm

File Prove

• Inputs. ﬁle descriptor f , index i, sector s and proof π
• Goal. verify that a selected sector is storing speciﬁc ﬁle
check the request is from the owner of sector s
verify allocTable[f,i].prev = s
verify π is a valid proof at time π.t
allocTable[f,i].last ← π.t

Fig. 5. File Protocol: Conﬁrm and prove ﬁles

Figure 5 illustrates the network response for providers’
File requests. When receiving an File Conﬁrm request, the

clientAddCheckAllocCheckProofCheckProofCheckProofCheckProofnetwork𝑝𝑟𝑜𝑜𝑓𝐶𝑦𝑐𝑙𝑒𝑝𝑟𝑜𝑜𝑓𝐶𝑦𝑐𝑙𝑒𝑝𝑟𝑜𝑜𝑓𝐶𝑦𝑐𝑙𝑒𝑝𝑟𝑜𝑜𝑓𝐶𝑦𝑐𝑙𝑒𝑑𝑒𝑙𝑎𝑦𝑃𝑒𝑟𝑆𝑖𝑧𝑒× 𝑓.𝑠𝑖𝑧𝑒FsectorsDiscarddiscard filerentrentrent𝑓.𝑐𝑝sectorsAddnetworkRefreshCheckRefreshAllocRefreshCheckRefreshRegisterCheckAllocsectorswap in the 𝑖threplica of  file 𝑓1from sector 𝑠RiCommitproduce the 𝑗threplica of file 𝑓2FclientproduceRjsector 𝑠Commitswap out the 𝑖threplica of  file 𝑓1to sector 𝑠Risector 𝑠Registerdepositnetwork sets the state of the corresponding allocation entry
to confirm. It means the sector has successfully received
the ﬁle. When the network receives a File Prove request,
it shall update the last proof time of the ﬁle storage after
checking the correctness of the proof.

Sector protocol

Sector Register

• Inputs. capacity cap and owner own
• Goal. register a new sector on the network
the owner pledges deposit proportional to the sector size
s ← (owner = own, id = nextId(own), capacity = cap, f reeCap =
cap,state = normal)

Sector Disable

• Inputs. sector s
• Goal. mark the sector as disabled
s.state ← disable

Fig. 6. Sector Protocol: Register and disable sectors

2) Sector :

automatically.

In the design of

It is simple for the network to respond to
Sector
requests. The pseudo-code is shown in Figure 6. A
new sector is registered when a Sector Register request is
received and the state of a sector will be set to disable
when a request of Sector Disable is received. When all ﬁles
in a disabled sector are swapped out, then it can be removed.
3) Auto : Note that the tasks with Auto preﬁx cannot
be called by anyone and shall be executed at a speciﬁc
time
the FileInsurer
protocol,
the network needs to maintain a pending list
to ensure that these tasks are executed at a speciﬁc time.
There are 4 kinds of tasks with Auto
preﬁx, which are
Auto CheckAlloc, Auto CheckProof, Auto Refresh, and
Auto CheckRefresh. In simple terms, Auto CheckAlloc
is used to check that
the ﬁle has been correctly stored
on the network, Auto CheckProof
is periodically proof
checking, while Auto Refresh and Auto CheckRefresh
are the processes of ﬁle storage refreshing in order to ensure
the randomness of storage. Therefore, the period of proof
checking should be short, and thus the frequency of the ﬁle
storage location refreshing could be very low.

Auto protocol

Auto CheckAlloc

• Inputs. ﬁle descriptor f
• Goal. check if ﬁle f is already conﬁrmed by all of the selected sectors
for i ∈ [f.cp] do

let e be a reference of allocTable[f,i]
if e.state (cid:54)= confirm and e.state (cid:54)= corrupted then
inform that the client failed to upload the ﬁle f
remove f from the network

for i ∈ [f.cp] do

let e be a reference of allocTable[f,i]
if e.state = confirm then

e ← (prev = e.next,next = null,last = N ow,state = normal)

else

e ← (prev = null,next = null,last = −1,state = corrupted)

f.cntdown ← SampleExp(AvgRef resh)
add CheckP roof (f ) to pendingList[N ow+P roof Cycle]
inform that the client succeed to upload the ﬁle f

Fig. 7. Auto CheckAlloc: Check each allocation has conﬁrmed the ﬁle

Auto protocol

Auto CheckProof

• Inputs. ﬁle descriptor f
• Goal. check that all storage locations of ﬁle f are working
if the client of ﬁle f has does not have enough tokens to pay the cost for
the next cycle then

f.state ← discard
inform that ﬁle f is discarded due to insufﬁcient cost

if f.state = normal then

deduct the cost for the next cycle from the client’s account
for i ∈ [f.cp] do

let e be a reference of allocTable[f,i]
if e.prev is not corrupted then

if e.last < N ow−P roof Deadline then

conﬁscate the deposit of s
mark and inform that s is corrupted
else if e.last < N ow−P roof Due then

else if ∀j,allocTable[f,j].prev is corrupted then

punish e.prev
if f.state = discard then

remove f from the network

inform that ﬁle f is lost
compensate to the client
remove f from the network

else

add CheckP roof (f ) to pendingList[N ow+P roof Cycle]
f.cntdown ← f.cntdown−1
if f.cntdown = 0 then

i ← RandomIndex(f )
call Ref resh(f,i)

Auto CheckAlloc will be executed automatically at some
time after a File Add request is responded by the network.
The network shall conﬁrm if all f.cp sectors have received
the ﬁle described by f . If so, the network goes to change
the state of the ﬁle descriptor to normal; otherwise, it shall
inform the client that it failed to upload the ﬁle.

Every ﬁle needs to be checked at some speciﬁc time
whether it is stored properly. In each speciﬁc time period, a
task named Auto CheckProof automatically runs to check
whether each proof to the ﬁle is timely. We provide the
pseudo-code of Auto CheckProof
in Figure 8. We use
WindowPoSt of Filecoin [4] to implement the proof process.
A sector will be punished if it cannot submit the proof of
storage of its ﬁles within P roof Due time, and then its

Fig. 8. Auto CheckProof: Check each proof of the ﬁle

corresponding deposit is liquidated if the proof of storage of
its ﬁles cannot be provided within P roof Deadline time.

Whenever a random number2 of checkpoints are passed,
a task named Auto Refresh will be called to randomly
refresh one of the storage places of the ﬁle. Figure 9 shows
the details of Auto Refresh and another corresponding
task Auto CheckRefresh. The probability of sampling the
to the capacity of the
new storage sector is proportional

2This random number follows an exponential distribution

Auto protocol

Auto Refresh

• Inputs. ﬁle descriptor f and index i
• Goal. change the i-th storage place of ﬁle f to a random sector
s ← RandomSector()
if s.f reeCap ≥ f.size then
allocTable[f,i].next ← s
allocTable[f,i].state ← alloc
t ← N ow+DelayP erSize×f.size
add CheckRef resh(f,i) to pendingList[t]
pre ← allocTable[f,i].prev
inform the ith replica of ﬁle f should be swapped from pre to s

else

f.cntdown ← SampleExp(AvgRef resh)

Auto CheckRefresh

(cid:46) almost never happens

• Inputs. ﬁle descriptor f and index i
• Goal. check whether the last refresh for ﬁle f is conﬁrmed
let e be a reference of allocTable[f,i]
if e.state = confirm then

e ← (prev = e.next,next = null,last = N ow,state = normal)
f.cntdown ← SampleExp(AvgRef resh)

else

punish entry.next
for j ∈ [f.cp] do

punish allocTable[f,j].prev

call Ref resh(f,i)

Fig. 9. Auto Refresh and Auto CheckRefresh: Swap in and out the ﬁles

sector. The network then calculates a waiting time and the
current sectors that store this ﬁle need to transfer it to the
selected sector before the waiting time expires. Once the
waiting time expires, the task named Auto CheckRefresh
will be executed automatically to conﬁrm whether the ﬁle is
successfully stored in the new sector.

V. ANALYSIS

In this section, we analyze the performance of our protocol
and compare FileInsurer with other DSN protocols in detail.

A. Notation and Assumption

Before the analysis, we list notations in Table II which are
necessary for our theoretical analysis. Additionally, The fol-
lowing assumptions are necessary for our theoretical analysis.
the
secure. The issue of

security: FileInsurer
network consensus
itself
consensus security is not the target of this paper.

• Consensus

requires

that

is

• Adversary ability: FileInsurer allows an adversary to
corrupt λ proportion of network capacity immediately.
• Redundant capacity: FileInsurer requires that the total
capacity in the network is no less than twice the total
size of all ﬁles’ replicas. This assumption is deployed to
ensure storage randomness.

B. Performance of FileInsurer

1) Analysis for Capacity Scalability: We consider
the
capacity scalability of FileInsurer as the maximal size of
stored ﬁles. The following theorem indicates that FileInsurer
is scalable in capacity.

TABLE II
NOTATION TABLE

Notation

Description

minCapacity

minV alue

The minimum capacity of
sector. The
capacity of each sector is an integer multiple of
minCapacity.
The minimum value of a ﬁle. The value of each
ﬁle is an integer multiple of minV alue.

a

Nf

Ns

Nv

N m
v

γm
v

γdeposit

capP ara

c

k

of

of

number

number

“weighted”

“weighted”

The number of ﬁles.
The
sectors.
Ns ×minCapacity indicates the total capacity
of the network.
ﬁles.
The
Nv × minV alue indicates the total value
of ﬁles stored on the network.
The maximum “weighted” number of ﬁles the
network is designed to carry. N m
v ×minV alue
is the maximum value the network can carry.
γm
v = Nv
is the ratio that the total value stored
N m
v
in FileInsurer compared to the maximal value.
The deposit ratio. γdeposit is the ratio that the
sum of deposits compared to the maximal value
of ﬁles stored in the network.
capP ara is deﬁned as N m
v
Ns
Security parameter. We set it to be 10−18.
The number of backups should be stored of a
ﬁle whose value is minV alue.

.

Theorem 1 The total size of ﬁles can be stored in FileInsurer
is

min

(cid:26) Ns ×minCapacity
2r1k

,

Ns ×minCapacity
r2

(cid:27)

,

where

r1 =

r2 =

f f.size×f.value

(cid:80)
minV alue×(cid:80)

f f.size

,

minCapcity×(cid:80)

minV alue×(cid:80)

f f.value
f f.size×capP ara

(1)

(2)

.

The proof of Theorem 1 is provided in Appendix A. We
claim that each of r1 and r2 is bounded by a constant in
Section VI-A. Then the total size of raw ﬁles can be stored in
FileInsurer is ˜O(Ns ×minCapacity), which is almost linear
to the total size of sectors.

is

Storage

randomness

2) Storage Randomness:

an
important issue in FileInsurer. Storage randomness can ensure
the locations of replicas are evenly distributed. Therefore, the
adversaries must corrupt a huge number of sectors even if they
only want to destroy all replicas of a small portion of ﬁles. In
FileInsurer, replicas are stored by randomly selected sectors
in File Add and their locations are randomly refreshed by
Auto Refresh. Such operations make the locations of all
replicas are independent and identically distributed.

However, when the total used space is close to the capacity
of DSN, the process of File Add and Auto Refresh faces
the free space of selected sectors is not
the trouble that
enough for the storage of a replica. We call this event a
collision. Although sectors can be reselected to store these
replicas, Storage randomness would be inﬂuenced. Therefore,

redundant capacity is required to avoid collisions. We claim
that the frequency of collisions is ignorant by preliminary
theoretical proof and further experiments.

We ﬁrst consider a trivial case that all ﬁles have the same
size. The following theorem indicates that a collision happens
with an extremely low probability.

Theorem 2 If all ﬁles have the same size f.size,
for a
sector s with total capacity s.capacity and free capacity
s.f reeCap, then

(cid:20)

(cid:21)

(cid:26)

Pr

∃s, s.f reeCap ≤

s.capacity

≤ Nsexp

−0.144

(cid:27)

s.capacity
f.size

1
8

Theorem 2, when s.capacity
Pr(cid:2)∃s, s.f reeCap ≤ 1

The proof of Theorem 2 is provided in Appendix B. By
f.size ≥ 1000 and Ns ≤ 1012, we have
8 s.capacity(cid:3) < 10−50.
A replica of the ﬁle can be stored in any sector s with
8 s.capacity because f.size < 1
8 s.capacity.
the probability of collision is

s.f reeCap ≤ 1
This result
indicates that
extremely low under these conditions.

We further consider the general case that

the size of
ﬁles follows a certain distribution. We conduct a series of
numerical experiments in two different settings. In the ﬁrst
setting, we reallocate all ﬁle backups in one go for 100 times.
In the second setting, we allocate each ﬁle backup and then
randomly refresh the location of a ﬁle backup 100Ncp times.
Recall that Ncp = kNv is the number of ﬁle backups and each
ﬁle f needs to store f.cp backups on the network.

In the experiments, we test several distributions for the
size of ﬁle backups. We focus on the maximum ratio of
capacity usage. If the ratio is less than 1, no ﬁle backups
are allocated to sectors with insufﬁcient capacity. Table III
shows the results of our experiments. We can ﬁnd that the
maximum ratios of capacity usage never exceed 0.64 under
all tested distributions, which means that the probability that
ﬁle backups are allocated to sectors with insufﬁcient capacity
the results of our experiments
is very small. Therefore,
indicate that collisions would hardly occur when the average
size of ﬁle backups is much smaller than the sector capacity.
We also discuss how to maintain storage randomness when
the list of sectors changes in section VI-B. These results show
that storage randomness is easy to be promised in practice.
Therefore, each allocation of replicas is assumed to be inde-
pendent and identically distributed in the following analyses.
3) Analysis of Robustness: We consider the robustness of
FileInsurer as the ability of resisting corruptions of sectors.
The following theorem indicates that FileInsurer is quite
robust. The proof is left in Appendix C.

TABLE III
EXPERIMENT RESULT: MAXIMUM CAPACITY USAGE OF SECTORS

reallocate all ﬁle backups 100 times

parameter
Ns
20
100
200
1000
2000
10000
20000
105

Ncp
105
105
106
106
107
107
108
108

[1]
0.525
0.571
0.538
0.591
0.540
0.589
0.541
0.591

.

maximum capacity usage
[3]
0.536
0.584
0.542
0.598
0.544
0.609
0.550
0.614

[4]
0.530
0.572
0.534
0.594
0.545
0.606
0.547
0.599

[2]
0.524
0.566
0.530
0.571
0.534
0.576
0.534
0.582

[5]
0.529
0.569
0.533
0.576
0.534
0.585
0.538
0.586

refresh the location of a ﬁle backup 100Ncp times
parameter
Ns
20
100
200
1000
2000
10000
20000
105

maximum capacity usage
[3]
0.538
0.599
0.546
0.610
0.553
0.626
0.560
0.639

[4]
0.535
0.595
0.542
0.605
0.549
0.613
0.558
0.628

[2]
0.529
0.571
0.535
0.581
0.535
0.591
0.547
0.604

[1]
0.532
0.588
0.536
0.592
0.542
0.610
0.551
0.611

Ncp
105
105
106
106
107
107
108
108

[5]
0.531
0.581
0.541
0.589
0.540
0.599
0.548
0.611

[1]: Uniform distribution in interval [0,1]
[2]: Uniform distribution in interval [1,2]
[3]: Exponential distribution
[4]: Normal distribution with µ = σ2
[5]: Normal distribution with µ = 2σ2

Let us propose a concrete example to show that the result
of Theorem 3 is quite strong. Set k = 20, Ns = 106, and
capP ara = 103. Let λ = 0.5, which means that half capacity
of FileInsurer is broken. Then
γv
lost ≤ max

5×10−6,0.001,

×5×10−6

(cid:26)

(cid:27)

.

1
γm
v

When γm

v ≥ 0.005, γv

lost ≤ 0.001. It means that in this case,
even when half of the capacity of FileInsurer is corrupted,
the value of lost ﬁles is no more than 0.1% of the value of
all stored ﬁles.

4) Deposit Ratio: The following theorem indicates that

only a small deposit ratio is needed for full compensation.

Theorem 4 Assume that the total size of corrupted sectors
is no more than λNs × minCapacity. If the deposit ratio
satisﬁes

γdeposit ≥ max

(cid:26)

5λk−1,λ

k

2 −1,

4
k×capP ara

(cid:18) logNs
log 1
λ

+

log 1
c
logNs

(cid:19)(cid:27)

,

then full compensation can be achieved with a probability
of not less than 1−c.

Vlost

lost =

Theorem 3 Assume that the total size of corrupted sectors
is λNs ×minCapacity. Denote the total value of lost ﬁles to
be Vlost, and γv
Sv×minV alue represents the ratio of the
value of lost ﬁles to the total value of all ﬁles. Then with a
probability of not less than 1−c, γv
2π −logc
Ns
v klog 1
γm

lost satisﬁes
−log(cid:0)λλ(1−λ)1−λ(cid:1)(cid:17)
λ ×capP ara

γv
lost ≤ max



.


5λk,λ

(cid:16) log e




k
2 ,



4

The proof of theorem 4 is in Appendix D. Set k = 20, Ns =
106, capP ara = 103 and λ = 0.5. Then γdeposit = 0.0046 is
enough to ensure full compensation, which is relatively small.

C. Comparison with Existing Protocols

Table IV shows the comparison between FileInsurer and
existing DSN protocols including Filecoin, Arweave, Sia, and
Storj. We observe that FileInsurer is the only DSN protocol

TABLE IV
COMPARISON OF DSN PROTOCOLS

C. Adjusting to Extremely Large Files

Property
Capacity Scalability
Preventing Sybil Attacks
Provable Robustness
Compensation for File Loss

FileInsurer Filecoin Arweave Storj Sia
Yes Yes
Yes No
No No
No No

Yes
Yes
Yes
Yes
No
Yes
No
Yes
[1] Provides only limited ﬁle loss compensation

Yes
Yes
No
No[1]

that has provable robustness and gives full compensation for
ﬁle loss.

VI. DISCUSSION

In previous

sections, we have proposed the general
framework of FileInsurer and theoretically proved the
excellent performance of FileInsurer. Besides, some practical
issues exist and we explore the corresponding solutions for
them under FileInsurer in this section.

A. Distributions and Parameters

The value and size of a ﬁle follows a certain distribution in
DSN. We have the following reasonable assumptions about
the distribution.

• The maximal value of a ﬁle is bounded by a constant.
eq. (1)) is bounded by a

Therefore, r1 (deﬁned in
constant.

• The average value of a unit size is a bounded constant.
f f.value
f f.size is bounded
eq. (2)) is

Then it’s reasonable to assume that
by a constant. Therefore, r2 (deﬁned in
bounded by a constant.

(cid:80)
(cid:80)

fail

In some special cases, very few huge ﬁles, whose sizes
are comparable to the capacity of sectors, need to be stored
in the network. These very large ﬁles might break storage
randomness because their allocations might
to ﬁnd
enough space in one turn. To address this problem from the
extremely large ﬁles, the network needs to specify an upper
limit sizeLimit on the size of a single ﬁle. For a ﬁle with a
size greater than sizeLimit, we can convert it to a collection
of segments by the erasure code, such that each segment’s
size is upper bounded by sizeLimit. By this operation, the
ﬁle can still be recovered even if half of the segments are lost.
Therefore, we can simply regard each segment as an individual
ﬁle with value 2value
. In practice, we can apply the common
erasure code such as Reed–Solomon code [19] to archive this.

k

D. Storing Files with Widely Varying Values

v

In FileInsurer protocol, the value of each ﬁle is required
to be an integer multiple of minV alue. Thus a ﬁle with a
value of v can be treated as
minV alue documents worth of
minV alue. This means that a high-value ﬁle needs to have
many replicas in the system, and the number of replicas is
linearly related to this ﬁle’s value. A compromise solution
is to pre-divide the value levels of ﬁles and to establish a
storage subnetwork corresponding to each level. Then the
clients can choose which subnetwork to store ﬁles based on
the value level of their ﬁles.

The parameters of FileInsurer should be properly set
according to the distribution of ﬁles. For example, we should
set parameters to make 2r1k is not far away from r2 to
further improve scalability bound in theorem 1. It also helps
to avoid the bad situation that the total value of ﬁles is far
below the maximal, but the used space has reached its limit.

B. Storage Randomness When Adding or Removing Sectors

In our analysis of storage randomness, we ignore the case
that the network may add or remove sectors online. When a
new sector s is registered in the network, in order to maintain
the independently and identically distributed property of the
allocations, the network should traverse each allocation and
swap out the allocation to that sector with the probability
of
Ns×minCapacity . Such an operation is impossible because
traversing over ﬁles is too expensive. One good approximation
method is that the network ﬁrst calculates how many ﬁles
backups need to be swapped into the sector by sampling
from a Poisson distribution, and then randomly select the ﬁle
backups to swap into the sector.

s.capacity

If a sector is disabled, We can request it to keep storing
all replicas it currently stores even if they are slowly being
swapped out. As a result, it does not get easier to attack the
corresponding ﬁles. When all of its ﬁles are swapped out,
this sector no longer exists in the network so the storage
randomness can guarantee.

E. Avoiding Selﬁsh Storage Providers

Selﬁsh storage providers refer to these providers who
store ﬁles but do not normally provide retrieval services.
Assume the ratio of the number of selﬁsh storage providers
to the number of all providers is α in the network. Then
is expected that αk proportion of ﬁles suffer from the
it
threat of the selﬁsh providers’ collusion. Here k is just the
number of copies of a stored ﬁle. As a result, any protocol
that ﬁxes ﬁle storage locations cannot fundamentally solve
the problem of selﬁsh storage providers. However, a natural
advantage of FileInsurer is that its ﬁle refresh mechanism
can fundamentally eliminate the threat from selﬁsh storage
providers. Because of the existence of refreshing ﬁle storage
location, no single ﬁle will be completely controlled by the
selﬁsh storage provider for a long time.

F. Supports for IPFS

Filecoin has shown how to support IPFS in a blockchain-
based DSN, and FileInsurer has a similar approach.
In
FileInsurer, the hashes and locations of ﬁles are all stored in
blockchain. Therefore, it’s easy to build and update DHTs
and Merkle DAGs on FileInsurer so that anyone can address
ﬁles stored in FileInsurer through IPFS paths. The retrieval
of ﬁles can be also realized through BitSwap protocol.

VII. CONCLUSION

In this paper, we propose FileInsurer, a novel design for
blockchain-based Decentralized Storage Network, which
achieves both scalability and reliability. FileInsurer is the ﬁrst
DSN protocol that gives full compensation to ﬁle loss and
has provable robustness. Our work also raises many open
problems. First, are there other approaches to enhance the
reliability of Decentralized Storage Networks? For example,
a reputation mechanism [8] on storage providers may be
also helpful to reduce the loss of ﬁles. Second, are there
other ways to support dynamic content in sectors other than
DRep? Furthermore, can the idea of FileInsurer be extended
to decentralized insurance in other scenarios?

REFERENCES

[1] F. A. Alabdulwahhab. Web 3.0: the decentralized web
blockchain networks and protocol innovation. In 2018 1st
International Conference on Computer Applications &
Information Security (ICCAIS), pages 1–4. IEEE, 2018.
Ipfs-content addressed, versioned, p2p ﬁle

[2] J. Benet.

system. arXiv preprint arXiv:1407.3561, 2014.

[3] J. Benet, D. Dalrymple, and N. Greco.

Proof of

replication. Protocol Labs, July, 27:20, 2017.

[4] J. Benet and N. Greco. Filecoin: A decentralized storage

network. Protoc. Labs, pages 1–36, 2018.

[5] N. Z. Benisi, M. Aminian, and B. Javadi. Blockchain-
based decentralized storage networks: A survey. Journal
of Network and Computer Applications, 162:102656,
2020.

[6] A. Bhat, N. Shrestha, Z. Luo, A. Kate, and K. Nayak.
random beacons
Randpiper–reconﬁguration-friendly
In Proceedings of the
with quadratic communication.
2021 ACM SIGSAC Conference on Computer and
Communications Security, pages 3502–3524, 2021.
[7] C. Cachin, K. Kursawe, and V. Shoup. Random oracles
in constantinople: Practical asynchronous byzantine
agreement using cryptography. Journal of Cryptology,
18(3):219–246, 2005.

[8] H. Chen, Z. Chen, Y. Cheng, X. Deng, W. Huang,
J. Li, H. Ling, and M. Zhang. A provable softmax
reputation-based protocol for permissioned blockchains.
IEEE Transactions on Cloud Computing, 2021.

[9] H. Chen, Y. Cheng, X. Deng, W. Huang, and L. Rong.
Absnft: Securitization and repurchase
for
non-fungible tokens based on game theoretical analysis.
arXiv preprint arXiv:2202.02199, 2022.

scheme

[10] J. Chen and S. Micali. Algorand: A secure and efﬁcient
Theoretical Computer Science,

distributed ledger.
777:155–183, 2019.

[11] Z. Chen and G. Yang. Decentralized asset custody
scheme with security against rational adversary. In Web
and Internet Economics: 17th International Conference,
WINE 2021, Potsdam, Germany, December 14–17,
2021, Proceedings, page 449. Springer Nature, 2021.

[12] S. Das, V. Krishnan, I. M. Isaac, and L. Ren. Spurt:
Scalable distributed randomness beacon with transparent
setup. Cryptology ePrint Archive, 2021.

[13] J. R. Douceur.

In International
The sybil attack.
workshop on peer-to-peer systems, pages 251–260.
Springer, 2002.

[14] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zel-
dovich. Algorand: Scaling byzantine agreements for
cryptocurrencies. In Proceedings of the 26th symposium
on operating systems principles, pages 51–68, 2017.
[15] F. James. A review of pseudorandom number generators.
60(3):329–344,

communications,

physics

Computer
1990.

[16] E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly,
E. Syta, and B. Ford. Omniledger: A secure, scale-out,
In 2018 IEEE
decentralized ledger via sharding.
Symposium on Security and Privacy (SP), pages
583–598. IEEE, 2018.

[17] S. Nakamoto. Bitcoin: A peer-to-peer electronic cash sys-
tem. Decentralized Business Review, page 21260, 2008.
[18] V. Pareek. An overview of cryptographically secure
pseudorandom number generators and bbs. International
Journal of Computer Applications (IJCA)(0975–8887),
2014.

[19] I. S. Reed and G. Solomon. Polynomial codes over
certain ﬁnite ﬁelds. Journal of the society for industrial
and applied mathematics, 8(2):300–304, 1960.

[20] B. Ryskeldiev, Y. Ochiai, M. Cohen, and J. Herder.
Distributed metaverse: creating decentralized blockchain-
based model for peer-to-peer sharing of virtual spaces
In Proceedings of the
for mixed reality applications.
9th Augmented Human International Conference, pages
1–3, 2018.

[21] D. Vorick and L. Champine. Sia: Simple decentralized

storage. Retrieved May, 8:2018, 2014.

[22] Q. Wang, R. Li, Q. Wang, and S. Chen. Non-fungible
token (nft): Overview, evaluation, opportunities and
challenges. arXiv preprint arXiv:2105.07447, 2021.
[23] S. Wilkinson, T. Boshevski, J. Brandoff, and V. Buterin.
Storj a peer-to-peer cloud storage network. 2014.
[24] S. Williams, V. Diordiiev, L. Berman, and I. Uemlianin.
Arweave: A protocol
for economically sustainable
information permanence. arweave. org, Tech. Rep, 2019.
Ethereum: A secure decentralised
generalised transaction ledger. Ethereum project yellow
paper, 151(2014):1–32, 2014.

[25] G. Wood et al.

[26] M. Zhang, J. Li, Z. Chen, H. Chen, and X. Deng.
Cycledger: A scalable and secure parallel protocol
In 2020 IEEE
for distributed ledger via sharding.
International Parallel
and Distributed Processing
Symposium (IPDPS), pages 358–367. IEEE, 2020.

APPENDIX A
PROOF OF THEOREM 1
Theorem 1 The total size of ﬁles can be stored in FileInsurer
is

min

(cid:26) Ns ×minCapacity
2r1k

,

Ns ×minCapacity
r2

(cid:27)
,

where

r1 =

r2 =

f f.size×f.value

(cid:80)
minV alue×(cid:80)

f f.size

,

minCapcity×(cid:80)

minV alue×(cid:80)

f f.value
f f.size×capP ara

(1)

(2)

.

Proof:

There are two restrictions on the total size of raw
ﬁles. One is the restriction of total capacity. The other is the
restriction of the maximal total value of stored ﬁles.

Under the former restriction, each ﬁle f is stored as f.cp
replicas. Due to the assumption of redundant capacity, The
total size of all replicas can not exceed 1
2 of total capacity.
That is,

(f.size×f.cp) ≤

Ns ×minCapacity.

1
2

(cid:88)

f

Because f.cp = k× f.value

minV alue , we have
1
2

f.value
minV alue

) ≤

(f.size×k×

Ns ×minCapacity.

Then we have

(cid:88)

f

k×

Let r1 =

Then

Ns ×minCapacity
f f.size

(cid:80)

.

(cid:80)

×

≤

1
2

(cid:80)
minV alue×(cid:80)

f (f.size×f.value)
f f.size
f f.size we have
minV alue×(cid:80)
1
×
2

f f.size×f.value

(cid:80)

k
r1

≤

.

Ns ×minCapacity
f f.size
Ns ×minCapacity
2r1k

.

f.size ≤

(cid:88)

f

Under the latter restriction, the total value of ﬁles can’t

exceed Sm

v ×minV alue. That is,

f.value ≤ n×minV alue.

(cid:88)

f

(cid:80)

Because n = Cap P ara×m,
f f.value
f f.size

(cid:80)

≤

Cap P ara×Ns ×minV alue
f f.size

(cid:80)

.

Therefore,

where

r2 =

(cid:88)

f.size ≤

f

Ns ×minCapacity
r2

,

minCapcity×(cid:80)

f f.value
f f.size×Cap P ara

minV alue×(cid:80)

.

(cid:3)

APPENDIX B
PROOF OF THEOREM 2

for a
Theorem 2 If all ﬁles have the same size f.size,
sector s with total capacity s.capacity and free capacity
s.f reeCap, then

(cid:20)

(cid:21)

(cid:26)

Pr

∃s, s.f reeCap ≤

s.capacity

≤ Nsexp

−0.144

s.capacity
f.size

(cid:27)

.

1
8

Proof:

In the special case, all ﬁles have the same size
f.size. For a sector s with capacity s.capacity, it can store

s.capacity
f.size

backups. We deﬁne Ncp = kNv as the number of ﬁle
backups in total because Ncp = (cid:80)
f.value
minV alue ×k =
kNv. Additionally, let Xi be the event that the backup i
is stored in this sector and S = (cid:80)Ncp
i=1 Xi. Because the
assumption of redundant capacity, we have E[S] ≤ s.capacity
2f.size .
By multiplicative Chernoff bound, we have

f f.cp = (cid:80)

f

Pr

s.f reeCap ≤

s.capacity

(cid:21)

1
8

(cid:20)







(cid:27)

Ncp
(cid:88)

=Pr



i=1

(cid:20)

≤Pr

S ≥

Xi ≥

7
8

s.capacity
f.size

(cid:21)

E[S]

7
4

(cid:26)(cid:16)

(cid:26)(cid:16)

log

log

e
4
e
4

(cid:26)

−0.144

≤exp

≤exp

≤exp

(cid:27)

E[S]

(cid:17) 3
4

(cid:17) 3s.capacity
8f.size
s.capacity
f.size

(cid:27)

By applying union bound, we obtain
(cid:20)
1
8

∃s,s.f reeCap ≤

s.capacity

≤ Nsexp

(cid:21)

Pr

(cid:26)

−0.144

s.capacity
f.size

(cid:27)
.
(cid:3)

APPENDIX C
PROOF OF THEOREM 3
We deﬁne the state of a FileInsurer network as (F,S,A,C)
consisting of ﬁles F ,sectors S, all allocations A, and
corrupted bits C in the network. Also, we deﬁne V (F,S,A,C)
lost
as the sum of values of the lost ﬁles and V (F,S,A,C)
conf iscated as the
conﬁscated deposits of the corrupted sectors.

Lemma 1 For a speciﬁc state (F, S, A, C), keeping the
content and availability of each physical disk in the network
unchanged, it can be viewed as another state (F (cid:48), S, A(cid:48), C)
where the value of each ﬁle is minV alue. State (F (cid:48),S,A(cid:48),C)
satisﬁes V (F,S,A,C)

≤ V (F (cid:48),S,A(cid:48),C)

.

lost

lost

Proof: We divide each ﬁle descriptor f to f.value
minV alue differ-
ent ﬁle descriptors. These ﬁle descriptors all have the value
minV alue and the same Merkle root as that of f . Divide the
f.cp allocations of f equally among these new ﬁle descriptors,
so each ﬁle descriptor have exactly k allocations. By deﬁning
F (cid:48) as all these new ﬁle descriptors, A(cid:48) as these new ﬁle
allocations, we construct a state (F (cid:48), S, A(cid:48), C) such that the
value of each ﬁle is minV alue.

conf iscated = V (F (cid:48),S,A(cid:48),C)

The content and availability of each physical disk in the
network are same in state (F,S,A,C) and state (F (cid:48),S,A(cid:48),C).
Since we do not change the state of sectors, we simply
obtain V (F,S,A,C)
conf iscated . For each ﬁle f lost in
state (F,S,A,C), since all its backups are lost, every new ﬁle
descriptor generated by f in state (F (cid:48),S,A(cid:48),C) also lost. The
value of the ﬁle f is equal to the sum of the values of the
ﬁle descriptors it generates, so V (F,S,A,C)
. (cid:3)

≤ V (F (cid:48),S,A(cid:48),C)

lost

lost

Lemma 2 ∀0 < p ≤ 1

5 and 5p ≤ x ≤ 1, DKL(x||p) ≥ 1

2 xlog x
p .

Proof:
Let

In the proof below, we will use x ≥ p unspeciﬁed.






p −(1−x)2log 1−x
1−p
(cid:16)
(cid:17)

−log x

p +x−1

f (x) = x2log x
g(x) = log x−1
p−1
xlog x
p
−(1−x)log 1−x
1−p

h(x) =

−xlog x
p

whose domain is x ∈ [p, 1]. First, we have f (x) ≥ 0
because df
dx = 1 + 2DKL(x||p) ≥ 0 and f (p) = 0. Then,
dx = f (x)
we have g(x) ≥ 0 because dg
x(1−x) ≥ 0 and g(p) = 0.
Finally, we obtain h(x) is monotonically increasing because
dh
dx =

g(x)
(x−1)2log2 1−x
1−p

≥ 0.

Because h(x) is monotonically increasing, ∀x ≥ 5p,

h(x) ≥ h(5p) =

5plog5
(1−5p)log 1−p
1−5p

. We can ﬁnd that

d
dp

5plog5
(1−5p)log 1−p
1−5p

=

(cid:16)

(1−p)log 1−p
5log5
1−5p −4p
(cid:17)
(1−5p)2(1−p)log2(cid:16) 1−p

1−5p

(cid:17)

(cid:16)
(cid:17)
(1−p)(1− 1−5p
5log5
1−p )−4p
(cid:17)
(1−5p)2(1−p)log2(cid:16) 1−p

1−5p

≥

=0.

When p → 0,

5plog5
(1−5p)log 1−p
1−5p

> 2, so ∀0 < p ≤ 1
5 ,

5plog5
(1−5p)log 1−p
1−5p

>

2, that is ∀x ≥ 5p,h(x) > 2. At last,

DKL(x||p) = xlog

+(1−x)log

x
p

1−x
1−p

Then all Xi are independent events and Pr[Xi] = λk when any
sectors with total space of λNs ×minCapacity are corrupted.
minV alue . By Chernoff bound and lemma 2,

Denote γ = V v

lost

when γ ≥ 5Nvλk, we obtain

(cid:34)

Pr

(cid:88)

Xi ≥ γ

(cid:35)

i
(cid:26)

≤exp

−Nv

(cid:26)

≤exp

−

γ
2

log

(cid:18) γ
Nv
γ
Nvλk

log

γ
Nvλk +
(cid:27)

.

(cid:18)

1−

γ
Nv

(cid:19)

log

Nv −γ
Nv −Nvλk

(cid:19)(cid:27)

Consider the number of scenarios in which an adversary
can corrupt sectors with capacity λNs ×minCapacity. Here
we do a simple scaling that treat a sector with s.capacity
s.capacity
minCapacity sectors with capacity minCapacity.
capacity as
After this scaling, the adversary has (cid:0) Ns
(cid:1) options to corrupt
λNs
sectors. Therefore, for the original situation, the number of
scenarios in which an adversary can corrupt sectors with
capacity λNs ×minCapacity does not exceed (cid:0) Ns
λNs

(cid:1).

By union bound, when γ ≥ 5Nvλk, the probability it cannot

(cid:19)

1−

manufacture γ lost ﬁles is at least
γ
γ
Nvλk
2
(cid:16)
2 , we have log γ
Nvλk ≥ log

(cid:18) Ns
λNs

exp

When γ ≥ Nvλ k
Then we ﬁnd that

log

−

(cid:26)

(cid:27)

.

(cid:17)

−k
2

λ

= − k

2 logλ.

= xlog

= xlog

x
p

x
p

(cid:32)

1+

(cid:18)

1−

(1−x)log 1−x
1−p
xlog x
p
(cid:19)

1
h(x)

(cid:33)

⇔γ

⇒

γ
2

k
4

log

1
λ
γ

≥

1
2

xlog

x
p

.

(cid:3)

Lemma 3 Assume that the total size of corrupted sectors is
λNs × minCapacity. Denote the total value of lost ﬁles to
be Vlost. Then, with a probability of not less than 1−c, Vlost
satisﬁes

Vlost ≤ minV alue×max

5Nvλk,Nvλ

k
2 ,4

(cid:40)

(cid:1)−logc

log(cid:0) Ns
λNs
klog 1
λ

(cid:41)
.

Proof:

Because of lemma 1, we can make the relaxation
of that each ﬁle has value minV alue in subsequent analysis.
Under the relaxations,
the setting of the problem can be
simpliﬁed as follow: there are Nv ﬁles, each ﬁle has the same
value minV alue and needs to be stored in k sectors. Each
storage location of each ﬁle is generated independent and
identically distributed.

For any certain scheme that the adversary corrupts λ ratio of
capacity, which means that the total size of corrupted sectors is
λNs ×minCapacity, deﬁne random variable Xi as the indica-
tor variable of that the ﬁle fi is lost. Recall storage randomness
indicates that all replicas are evenly and randomly distributed.

(cid:1)

≤

⇔

exp

⇔exp

(cid:18) Ns
λNs

c
(cid:0) Ns
λNs
(cid:27)

γ
Nvλk
(cid:26)
γ
2
This shows that when γ meets the above three conditions,
the probability that an adversary can make γ lost ﬁles does
not exceed 1−c, that is, γ needs to satisfy
log(cid:0) Ns
λNs
klog 1
λ

γ
Nvλk

5λkNv,λ

(cid:1)−logc

γ ≤ max

2 Nv,4

≤ c.

log

(cid:41)

(cid:40)

−

.

k

Therefore, with a probability of no less than 1 − c, V v
(cid:41)
.

satisﬁes
V v
lost ≤ minV alue×max

5Nvλk,Nvλ

(cid:1)−logc

k
2 ,4

(cid:40)

lost

log(cid:0) Ns
λNs
klog 1
λ

(cid:3)

Theorem 3 Assume that the total size of corrupted sectors
is λNs ×minCapacity. Denote the total value of lost ﬁles to
be Vlost, and γv
Sv×minV alue represents the ratio of the
value of lost ﬁles to the total value of all ﬁles. Then with a

lost =

Vlost

γ ≥ 4

(cid:1)−logc

log(cid:0) Ns
λNs
klog 1
λ

≥ −log

c
(cid:0) Ns
λNs

(cid:1)

c
(cid:0) Ns
λNs
c
(cid:0) Ns
λNs

(cid:1)

(cid:1)

log

γ
2
(cid:26)

Nvλk ≥ −log
γ
Nvλk ≤ log
log
(cid:27)
γ
2
(cid:19)

log

−

⇔−

Considering the third part, we have
(cid:1)−logc

4

log(cid:0) Ns
λ(cid:48)Ns
v klog 1
λ(cid:48)N m
λ(cid:48)
(cid:16)
N λ(cid:48)Ns
4log
s
v klog 1
λ(cid:48)

λ(cid:48)N m

≤λ(cid:48)≤λ

(cid:17)

≤ max
1
Ns

−4logc

4λ(cid:48)NslogNs −4logc

= max
1
Ns
(cid:32)

≤λ(cid:48)≤λ

1
Ns

max
≤λ(cid:48)≤λ
4NslogNs
v klog 1
N m
λ

≤

≤

Then

λ(cid:48)N m

v klog 1
λ(cid:48)
(cid:33)

4NslogNs
v klog 1
N m
λ(cid:48)
−4Nslogc
N m
v klogNs

+

.

+

(cid:32)

max
≤λ(cid:48)≤λ

1
Ns

−4logc
v klog 1
λ(cid:48)

λ(cid:48)N m

(cid:33)

(cid:26)

5λk−1,λ

k

2 −1,

4NslogNs
v klog 1
N m
λ

+

−4Nslogc
N m
v klogNs

(cid:27)

.

γdeposit ≥ max
As capP ara = N m
v
Ns
5λk−1,λ

γdeposit ≥ max

(cid:26)

,

k

2 −1,

4
k×capP ara

(cid:18) logNs
log 1
λ

+

log 1
c
logNs

(cid:19)(cid:27)

.

(cid:3)

probability of not less than 1−c, γv
2π −logc
Ns
v klog 1
γm

γv
lost ≤ max

5λk,λ

lost satisﬁes
−log(cid:0)λλ(1−λ)1−λ(cid:1)(cid:17)
λ ×capP ara

(cid:16) log e




k
2 ,

4





.


Proof:

Now we use an upper bound of the binomial

number via Stirling’s formula,

(cid:19)

(cid:18) Ns
λNs

Ns!
(λNs)!(Ns −λNs)!

=

≤

=

≤

N Ns+ 1

2

s

(λNs)λNs+ 1
(cid:115)

1
Nsλ(1−λ)

2

(cid:18)

2 (Ns −λNs)Ns−λNs+ 1
(cid:19)Ns
1
λλ(1−λ)1−λ
(cid:19)Ns

(cid:18)

1
λλ(1−λ)1−λ

e
2π

e
2π

e
2π

Using this upper bound, we can have a simpler version of
γv
lost:

(cid:40)

γv
lost ≤ max

5λk,λ

k
2 ,4

(cid:40)

= max

5λk,λ

k
2 ,4

log e

2π −Nslog(cid:0)λλ(1−λ)1−λ(cid:1)−logc
Nvklog 1
λ

(cid:41)

log e

2π −logc
Ns

−log(cid:0)λλ(1−λ)1−λ(cid:1)
v klog 1
λ

capP ara·γm

(cid:41)

(cid:3)

APPENDIX D
PROOF OF THEOREM 4

Theorem 4 Assume that the total size of corrupted sectors
is no more than λNs × minCapacity. If the deposit ratio
satisﬁes

γdeposit ≥ max

5λk−1,λ

(cid:26)

k

2 −1,

4
k×capP ara

(cid:18) logNs
log 1
λ

+

log 1
c
logNs

(cid:19)(cid:27)

,

then full compensation can be achieved with a probability
of not less than 1−c.

Proof: By assumption, the total size of corrupted sectors
is no more than λNs ×minCapacity. Because the deposit of
corrupted sectors should always cover the ﬁle loss, for all 1
≤
Ns
λ(cid:48) ≤ λ we shall have λ(cid:48)γdepositN m
v ≥ γ, which is equivalent
to
(cid:26) γ

(cid:27)

γdeposit ≥ max

.

≤λ(cid:48)≤λ
Then with probability no less than 1−c, the following γdeposit
is enough for full compensation

1
Ns

λ(cid:48)N m
v

γdeposit ≥ max

max

1
Ns

≤λ(cid:48)≤λ

(cid:40)

5(λ(cid:48))k−1,(λ(cid:48))

k

2 −1,4

(cid:1)−logc

log(cid:0) Ns
λ(cid:48)Ns
v klog 1
λ(cid:48)N m
λ(cid:48)

(cid:41)

.

