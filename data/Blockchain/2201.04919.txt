Translation Certiﬁcation for Smart Contracts

Jacco O.G. Krijnen 1, Manuel M. T. Chakravarty2, Gabriele Keller

1, and

Wouter Swierstra

1

2
2
0
2

b
e
F
2
2

]
L
P
.
s
c
[

2
v
9
1
9
4
0
.
1
0
2
2
:
v
i
X
r
a

1 Utrecht University
{j.o.g.krijnen, w.s.swierstra, g.k.keller}@uu.nl
2 IOHK
manuel.chakravarty@iohk.io

Abstract. Compiler correctness is an old problem, but with the emer-
gence of smart contracts on blockchains that problem presents itself in
a new light. Smart contracts are self-contained pieces of software that
control (valuable) assets in an adversarial environment; once commit-
ted to the blockchain, these smart contracts cannot be modiﬁed. Smart
contracts are typically developed in a high-level contract language and
compiled to low-level virtual machine code before being committed to the
blockchain. For a smart contract user to trust a given piece of low-level
code on the blockchain, they must convince themselves that (a) they are
in possession of the matching source code and (b) that the compiler has
correctly translated the source code to the given low-level code.
Classic approaches to compiler correctness tackle the second point. We
argue that translation certiﬁcation also squarely addresses the ﬁrst. We
describe the proof architecture of a novel translation certiﬁcation frame-
work, implemented in Coq, for a functional smart contract language. We
demonstrate that we can model the compilation pipeline as a sequence of
translation relations that facilitate a modular veriﬁcation methodology
and are robust in the face of an evolving compiler implementation.

1

Introduction

Compiler correctness is an old problem that has received renewed interest in
the context of smart contracts — that is, compiled code on public blockchains,
such as Ethereum or Cardano. This code often controls a signiﬁcant amount of
ﬁnancial assets, must operate under adversarial conditions, and can no longer be
updated once it has been committed to the blockchain. Bugs in smart contracts
are a signiﬁcant problem in practice [5]. Recent work has also established that
smart contract language compilers can exacerbate this problem [26, Section 3] (in
this case, the Vyper compiler). More speciﬁcally, the authors report (a) that they
did ﬁnd bugs in the Vyper compiler that compromised smart contract security
and (b) that they performed veriﬁcation on generated low-level code, because
they were wary of compiler bugs.

Hence, to support reasoning about smart contract source code, we need to
get a handle on the correctness of smart contract compilers. On top of that, we
do also need a veriﬁable link between the source code and its compiled code

 
 
 
 
 
 
2

Krijnen et al.

to prevent code substitution attacks, where an adversary presents the user with
source code that doesn’t match the low-level code committed on-chain.

In this paper, we are reporting on our ongoing eﬀort to develop a certiﬁcation
engine for the open-source on-chain code compiler of the Plutus smart contract
system3 for the Cardano blockchain.4 Speciﬁcally, we make the following contri-
butions:

– We describe a novel architecture for a translation certiﬁer based on trans-
lation relations, which enables us to generate translation certiﬁcates—proof
objects that relate the source code to the resulting compiled code and es-
tablish the correctness of the translation (Section 2).

– We provide formal deﬁnitions for the transformation passes that step-by-step
translate PIR (Plutus Intermediate Representation) to PLC (Plutus Core)
and brieﬂy discuss the challenges associated with the certiﬁcation of each of
these passes (Section 3).

– We present a summary of existing approaches to compiler correctness and
discuss the importance of generating translation certiﬁcates in the domain
of smart contracts (Section 4).

We also evaluate how our approach to gradual certiﬁcation copes with changes
to the compiler, which is being developed in an independent open source project.
Finally, we discuss related work in Section 5 and future work in Section 6.

2 The Architecture of the Certiﬁer

On-chain code in the Plutus smart contract system is written in a subset of
Haskell called Plutus Tx [18]. The Plutus Tx compiler is implemented as a
plugin for the widely-used, industrial-strength GHC Haskell compiler, combining
large parts of the GHC’s compilation pipeline with custom translation steps to
generate Plutus Core. In this context, it seems infeasible to apply full-scale
compiler veriﬁcation `a la CompCert [21]. We will therefore outline the design of
a certiﬁcation engine that, using the Coq proof assistant [6,9], generates a proof
object, a translation certiﬁcate, asserting the validity of a Plutus Core program
with respect to a given Plutus Tx source contract. In addition to asserting the
correct translation of this one program, the translation certiﬁcate serves as a
veriﬁable link between source and generated code.

We model the compiler as a composition of pure functions that transform
one abstract syntax tree into another. Figure 1 illustrates the architecture for a
single transformation, where the grey area marks the compiler implementation as
a function fi : ASTi → ASTi+1. We use a family of types ASTi to illustrate that
the representation of the abstract syntax might change after each transformation.
To support certiﬁcation, the compiler outputs each intermediate tree ti, so
that we can parse these in our Coq implementation of the certiﬁer. Within Coq,

3 https://developers.cardano.org/docs/smart-contracts/plutus/
4 http://cardano.org is, at the time of writing, the 5th largest public blockchain by

market capitalisation.

Translation Certiﬁcation for Smart Contracts

3

Fig. 1. Architecture for a single compiler pass. The grey area (left) represents the
compiler, orange (center) and blue (right) represent the certiﬁcation component in
Coq.

we deﬁne a high-level speciﬁcation of each pass. We call this speciﬁcation a
translation relation: a binary relation on abstract syntax trees that speciﬁes the
intended behaviour of the compiler pass. The orange area in Figure 1 displays
the translation relation Ri of pass i, where the vertical dashed line indicates that
Ri(ti, ti+1) holds. To establish this, we deﬁne a search procedure that, given two
subsequent trees produced by the compiler, can construct a derivation relating
the two.

The translation relation is purely syntactic—it does not assert anything
about the correctness of the compiler—but rather speciﬁes the behaviour of
a particular compiler pass. To verify that the compilation preserves language se-
mantics requires an additional proof, the blue area in Figure 1, that establishes
that any two terms related by Ri have the same semantics.

We have implemented this approach for a range of concrete passes of the
Plutus Tx compiler. To illustrate our approach in this section, we will use an
untyped lambda calculus, extended with non-recursive let-bindings.

t ::= x | λx. t | t t | let x = t in t

In the following section, we will extend this to a lambda calculus that is closer
to the intermediate language used by the Plutus Tx compiler.

2.1 Characterising a transformation

To assert the correctness of a single compiler stage fi, we begin by deﬁning a
translation relation Ri on a pair of source and target terms ti and ti+1, respec-
tively. This relation characterises the admissible translations of that compiler
stage. That is, for all ti, ti+1, we have fi(ti) = ti+1 implies Ri(ti, ti+1).

4

Krijnen et al.

Γ (x) = t′

Γ ⊢ t′ ⊲ t

[Inline-Var1]

Γ ⊢ x ⊲ t

Γ ⊢ x ⊲ x

[Inline-Var2]

Γ ⊢ t1 ⊲ t′

1

(x, t1), Γ ⊢ t2 ⊲ t′

Γ ⊢ let x = t1 in t2 ⊲ let x = t′

2
1 in t′
2

[Inline-Let]

Γ ⊢ t1 ⊲ t′

1

Γ ⊢ t2 ⊲ t′
1 t′
2

2

Γ ⊢ t1 t2 ⊲ t′
Γ ⊢ t1 ⊲ t′
1
Γ ⊢ λx.t1 ⊲ λx.t′
1

[Inline-App]

[Inline-Lam]

Fig. 2. Characterisation of an inliner

As a concrete example, consider an inlining pass. We have characterised this
as an inductively deﬁned relation in Figure 2. Here, Γ ⊢ s ⊲ t asserts that program
s can be translated into t given an environment Γ of let-bound variables, paired
with their deﬁnition. According to Rule [Inline-Var1] the variable x may be
replaced by t when the pair (x, t′) can be looked up in Γ and t′ can be translated
to t, accounting for repeated inlining. The remaining rules are congruence rules,
where Rule [Inline-Let] also extends the environment Γ . We omitted details about
handling variable capture to keep the presentation simple: hence, we assume that
variable names are globally unique.

Crucially, these rules do not prescribe which variable occurrences should be
inlined, since the [Inline-Var1] and [Inline-Var2] rules overlap. The choice in the
implementation of the pass may rely on a complex set of heuristics internal to
the compiler. Instead, we merely deﬁne a relation capturing the possible ways
in which the compiler may behave. This allows for a certiﬁcation engine that is
robust with respect to changes in the compiler, such as the particular heuristics
used to decide when to replace a variable with its deﬁnition or not.

We can then encode the relation · ⊢ · ⊲ · in Coq as an inductive type Inline,
which is indexed by an environment and two ASTs, as shown in Figure 3. This
type corresponds closely to the rules of Figure 2: we deﬁne exactly one construc-
tor per rule. However, there are some small diﬀerences. Since we cannot omit
details about variable capture anymore, we choose a de Bruijn representation
for variables and implement the environment Γ as a cons-list. In the Inline_Let
constructor, we extend the list with the bound term and furthermore shift free
variables in the other bound terms. For a let-bound variable n, its correspond-
ing bound term can then be found at the n’th position in the list using Coq’s
nth_error list-indexing function. For this indexing to work properly, the envi-
ronment also has to be extended at every lambda, as seen in Inline_Lam. We
distinguish the two types of binding sites with the type binding.

These inductive types implement the translation relation: its inhabitants are

proof derivations which will be a key ingredient of a compilation certiﬁcate.

Translation Certiﬁcation for Smart Contracts

5

Inductive binding :=

| LetBound
| LambdaBound : binding.

: term -> binding

Inductive Inline : list binding -> term -> term -> Type :=

| Inline_Var_1 : forall {env n t},

nth_error env n = Some (LetBound t) ->
Inline env (Var n) t

| Inline_Var_2 : forall {env n},

Inline env (Var n) (Var n)

| Inline_Let : forall {env s t s' t'},

Inline env s s' ->
Inline (LetBound s :: shiftEnv env) t t' ->
Inline env (Let s t) (Let s' t')

| Inline_Lam : forall {env s t},

Inline (LambdaBound :: shiftEnv env) s t ->
Inline env (Lam s) (Lam t)

| Inline_App : forall {env s sx t tx},

Inline env s t -> Inline env sx tx ->
Inline env (App s sx) (App t tx)

.

Fig. 3. Characterisation of an inliner in Coq

2.2 Proof search

After deﬁning a translation relation Ri characterising one compiler stage, we now
deﬁne a decision procedure to construct a proof that for two particular terms ti
and ti+1, produced by a run of the compiler, the relation Ri(ti, ti+1) holds. To
ﬁnd and implement such a search procedure, we generally follow these steps:

1. We write proofs for speciﬁc compilations by hand using Coq’s tactics, a form
of metaprogamming. For simple relations, like the inline example sketched
above, a proof can often be found with a handful of tactics such as auto or
constructor. This is particularly useful for debugging the design of our rela-
tions describing compiler passes. The drawback of this approach is, however,
that it is diﬃcult to reason when such proof search may fail. Furthermore,
proofs written using such tactics quickly become slow for large terms.

2. Once we are suﬃciently conﬁdent that a relation accurately captures admis-
sible compiler behaviour, we write a decision procedure of the form forall
(t1 t2 : term), option (R t1 t2). These procedures can still produce
large proof terms and may not always successfully construct a proof, but
they form a useful intermediate step towards full-on proof by reﬂection.

6

Krijnen et al.

3. Finally, we write a boolean decision procedure in the style of ssreﬂect [17] of
type term -> term -> bool, together with a soundness proof stating that
it will only return true when two terms are related through Ri. Verifying
such boolean functions for complex compilation passes is non-trivial; hence,
we only invest the eﬀort once we have a reasonable degree of conﬁdence that
the relation we have deﬁned accurately describes a given compiler pass.

2.3 Semantics preservation

Given the relational speciﬁcation of each individual compiler pass, we can now
establish the correctness properties for each pass. In the simplest case, this could
be asserting the preservation of a program’s static semantics, i.e., a proof of
type preservation. On the other end of the spectrum, we can demonstrate that
the translated term is semantically equivalent to the original program. Proving
such properties for PIR and Plutus Core passes, however, requires advanced
techniques such as step-indexed logical relations [2], which go beyond the scope
of the current paper.

In Figure 1, we denote Ri’s correctness properties in the blue area by means
of an abstract binary relation ∼i on the semantic objects JtiKi of ASTs ti. In the
case of static semantics, we can choose typing derivations as semantic objects,
and (for most passes) relate these by simply comparing types syntactically.

We can construct these proofs independently and gradually for each step in
the translation. In fact, even without any formal proof about the semantics, in-
spection of the (relatively concise) deﬁnition of a translation relation may already
provide some degree of conﬁdence that the translation step was performed cor-
rectly. After all, the translation relation asserts the speciﬁcation of this compiler
pass’ admissible behaviour.

2.4 Certiﬁcate generation

A complete translation certiﬁcate includes at least the entire set of ASTs t1, . . . , tn
together with a proof term witnessing the translation relations of type R1(t1, t2) ∧
. . . ∧ Rn−1(tn−1, tn). In addition, any semantic preservation results on transla-
tion relations can be instantiated and included as a proof of JtiK ∼i Jti+1K.

Together with the source and compiled program, one can now independently
check the certiﬁcate using a trusted proof checker, such as the Coq kernel [9]. The
deﬁnitions of the abstract syntax, translation relations and semantic preservation
can be inspected to conﬁrm that the certiﬁcate proves the right theorem. One
can then be conﬁdent that the compiled program is a faithful translation of the
source code.

3 Translation Relations of the Plutus Tx Compiler

The Plutus Tx compiler translates Plutus Tx (a subset of Haskell) to Plutus
Core, a variant of System F µ
ω [13]. The Plutus Core code is committed to the

Translation Certiﬁcation for Smart Contracts

7

t ::= x | λ(x : τ ). t | t t
| Λ(α : κ). t | t {τ }
s
r x = t in t
| let

| data T α = Ci τi with x in t

r ::= rec | nonrec
s ::= strict | nonstrict
τ ::= . . .

variable, lambda, function application

type abstraction, type application

term bindings

datatype binding

recursion type of binding

strictness of binding

types

Fig. 4. Simpliﬁed PIR

Cardano blockchain, constituting the deﬁnitive reference to any deployed smart
contract.

Plutus Core programs are pure, self-contained functions (i.e., they do not
link to other code) and are passed a representation of the transaction whose
validation they contribute to. The programs are run by an interpreter during
the transaction validation phase of the blockchain.

The Plutus Tx compiler reuses parts of the GHC infrastructure and imple-
ments its custom passes by installing a core-to-core pass plugin [15] in the GHC
compiler pipeline. On a high level, the compiler comprises three steps:

1. The parsing, type-checking and desugaring phases of GHC are reused to

translate a surface-level Haskell program into a GHC Core program.

2. A large subset of GHC Core is directly translated into an intermediate lan-
guage named Plutus Intermediate Representation (PIR). These languages
are similar and both based on System F, with some extensions. Additionally,
all referred deﬁnitions are included as local deﬁnitions so that the program
is self-contained.

3. The PIR program is then transformed and compiled down into Plutus Core.

The certiﬁcation eﬀort reported here focuses on Step 3, which consists of several
optimisation passes and translation steps. PIR is a superset of the Plutus Core
language: it adds several conveniences, such as user-deﬁned datatypes, strict and
non-strict let-bindings that may be (mutually) recursive. The compilation steps
translate these constructs into simpler language constructs.

In Figure 4 we present a simpliﬁed version of the PIR syntax, where we omit
some constructs for the sake of presentation. The full PIR language speciﬁcation
has been formalised elsewhere [13,19]. In particular, we ignore the fact that in
PIR, let-bindings may contain a group of (mutually recursive) bindings. Simi-
larly, we do not include mutually-recursive datatypes. Furthermore, we omit the
syntax of types, and the term-level witnesses of iso-recursive types. We occasion-
ally omit type annotations, when they are not relevant.

8

Krijnen et al.

We introduce the individual compiler passes that the Plutus Tx compiler

performs using the following Haskell program to illustrate their behaviour:

-- | Either a specific end date, or "never".
data EndDate = Fixed Integer | Never

pastEnd :: EndDate -> Integer -> Bool
pastEnd end current =

let inlineMe = False
in case end of
Fixed n ->

(let floatMe = if current `greaterThanEqInteger` 0

then n else 0 in floatMe) `lessThanEqInteger` current

Never

-> inlineMe

This program is a basic implementation of a timelock, a contract that states
that funds may be moved after a certain date, or not at all. It contains a few
contrived bindings (inlineMe and floatMe) that will be useful to illustrate some
transformations. After the program is desugared to GHC Core, it is converted
to a term in PIR that corresponds to the following Simpliﬁed PIR term:

data Bool = True | False with Bool_match in

data Unit = Unit with Unit_match in

let nonrec strict lessThanEqInteger = ... in

data EndDate = Fixed Integer | Never with EndDate_match in

\(end : EndDate).
\(current : Integer).

let nonrec nonstrict inlineMe = False in
EndDate_match end

(\unit n -> lessThanEqInteger

(let nonrect nonstrict floatMe =

Bool_match (greaterThanEqInteger current 0)

(\unit -> n) (\unit -> 0)
Unit
in floatMe)
current)

(\unit -> inlineMe)
Unit

Note that case distinction of a type T is encoded as the application of a pattern
match function T_match, which is introduced as part of a data deﬁnition. Fur-
thermore, branches of a case distinction are delayed by abstracting over a unit
value, since PIR is a strict language.

Next we will discuss the compiler passes, we have included each intermediate

form of the above program with some commentary in Appendix A.

Translation Certiﬁcation for Smart Contracts

9

3.1 Variable Renaming

In the renaming pass, the compiler transforms a program into an α-equivalent
program, such that all variable names are globally unique, a property also known
as the Barendregt-convention. The implementation of some subsequent compiler
passes depend on it. We can express variable renaming as a translation relation
∆ ⊢ t ⊲α t′, stating that under the renaming environment ∆ (consisting of pairs
of variables), t is renamed to t′. The environment ∆ records all variables that
are free in t, paired with their corresponding name in t′.

The case for lambda abstractions is deﬁned as follows:
{z | (z, y) ∈ ∆} ∩ F V (t) = ∅

(x, y), ∆ ⊢ t ⊲α t′

∆ ⊢ λx.t ⊲α λy.t′

[Rename-Abs]

The [Rename-Abs] rule states that a lambda-bound variable x may be re-
named at its binding-site to y, when t and t′ are related under the extended envi-
ronment. Of course, x may equal y, indicating that no renaming was performed.
Additionally, the new binder y should not capture any other free variable z in t
that was also renamed to y. Very similar rules can be stated for other binding
constructs such as let.

Note that this relation does not establish global uniqueness of variables: we
consider that an implementation detail internal to the compiler. If this property
would be required or convenient in semantic preservation proofs, we will establish
it separately, allowing this renaming relation to be as general as possible.

The variable case simply follows from the environment ∆:

(x, y) ∈ ∆
∆ ⊢ x ⊲α y

[Rename-Var]

3.2 Inlining

The rules of the translation relation for inlining in PIR are similar to those
in Section 2.1. However, the Plutus Tx compiler does more than just inlining
let-bound deﬁnitions. It also performs dead-code elimination (removing those
let-bindings that have been inlined exhaustively) and it renames variables to
ensure the global uniqueness of bound variables. This introduces a problem for
our certiﬁcation approach, as we cannot observe and dump the intermediate
ASTs, since the transformations are fused into a single pass in the compiler.

We solve this by modeling the individual transformations, composing them
using relational composition, ∃t2.R1(t1, t2)∧R2(t2, t3). To construct a proof relat-
ing two terms, then amounts to also ﬁnding the intermediate term, t2 witnessing
the composite transformation. To simplify the search of this intermediate AST,
we adjust the compiler to emit supporting information about the performed pass;
in this case, a list of the eliminated variables. If the compiler emits incorrect in-
formation, we may fail to construct a certiﬁcate, but we will never produce an
incorrect certiﬁcate.

10

Krijnen et al.

3.3 Let-ﬂoating

During let-ﬂoating, let-bindings can be moved upwards in the program. This
may save unnecessarily repeated computation and makes the generated code
more readable. The Plutus Tx compiler constructs a dependency graph to main-
tain a correct ordering when multiple deﬁnitions are ﬂoated. For the translation
relation, we ﬁrst consider the interaction of a let expression with its parent
node in the AST. For example, consider the case of a lambda with a non-strict
let directly under it:

x /∈ F V (t1)

t1 ⊲let

x 6= y
λx.letnonstrict
r
⊲let
y = t′

letnonstrict

r

y = t1 in t2

1 in λx.t′
2

t′
1

t2 ⊲let

t′
2

[Float-Let-Lam]

This rule states that a non-strict let-binding may ﬂoat up past a lambda, if the
bound term does not reference the lambda-bound variable. Furthermore, we re-
quire x 6= y, to avoid variable capture in t2. This rule does not apply to strict
let-bindings, as ﬂoating them outside a lambda might change termination be-
haviour of the program. Similar rules express when a let may ﬂoat upwards past
the other language constructs. Most of these are much simpler, only binding con-
structs pose additional constraints on scoping and strictness. Since the compiler
pass may ﬂoat lets more than just one step up, we deﬁne the translation re-
lation as the transitive closure of ⊲let. Note that we do not need to maintain a
dependency graph in the certiﬁer, but only need to assert that transformations
do not break dependencies.

3.4 Dead-code elimination

By means of a live variable analysis, the compiler determines which let-bound
deﬁnitions are unused. This is mainly useful for deﬁnitions that are introduced
by other compiler passes. Since PIR is a strict language, however, the compiler
can only eliminate those bindings for which it can determine they have no side-
eﬀects. For example, a let-bound expression that is unused but diverges cannot
be removed, as that could change the termination behaviour of the program.

The analysis in the compiler is not as straightforward as counting occurences.
Even a let-bound variable that does occur in the code, may be dead-code, if it
is only used in other dead bindings. This is also known as strongly live variable
analysis [16]. We deﬁne a translation relation t ⊲dce t′ that captures dead code
elimination. The crucial rule is for let-bindings.

t2 ⊲dce t′

2 x /∈ F V (t′
2)
x = t1 in t2 ⊲dce t′
2

let nonstrict
r

[DCE-Let-nonstrict]

Note that the condition x /∈ F V (t′
2) mentions the resulting body of the let t′
2.
This is justiﬁed since the rules of ⊲dce can remove bindings only, but cannot

Translation Certiﬁcation for Smart Contracts

11

change any other language constructs. This illustrates how succinct we can de-
scribe the speciﬁcation of a complex compiler pass.

In practice, the Plutus Tx compiler also eliminates some strict bindings that

obviously do not diverge, such as values.

3.5 Encoding of non-strict bindings

The PIR language allows both for strict and non-strict let-bindings, but Plutus
Core does not. The thunking transformation is used to obtain semantic equivalent
deﬁnitions which use a strict let-binding. We deﬁne the rules as a relation Γ ⊢
t ⊲thunk t′, where Γ records for every bound variable whether it was bound
strictly or non-strictly. The rule for a non-strict binding site is:

Γ ⊢ t1 ⊲thunk t′
1
(x, nonstrict), Γ ⊢ t2 ⊲thunk t′
2

Γ ⊢

nonstrict
nonrec

x = t1 in t2

⊲thunk
strict
nonrec x = λy. t′

1 in t′
2

let

let

y /∈ F V (t1)

[Thunk-Let-nonstrict]

This rule states that a right hand side is thunked by introducing a lambda
abstraction that expects a trivial unit value y as its argument.

The rules for other variable binders extend Γ . The rule for a recursive let-
binding also extends the environment under which t1 is transformed. Finally, we
also replace the occurrences of nonstrict variables, adding an application to the
unit value, thereby forcing evaluation.

(x, nonstrict) ∈ Γ
Γ ⊢ x ⊲thunk x ()

[Thunk-Var]

3.6 Encoding of recursive bindings

The Plutus Tx compiler translates (mutually) recursive let-bindings in non-
recursive ones using ﬁxpoint combinators. Here we only consider the rule for
individual recursive lets in simpliﬁed PIR:

t1 ⊲µ t′
1
let s

t2 ⊲µ t′
2
rec x = t1 in t2

y /∈ F V (t1)

[EncRec-Let]

⊲µ
strict
nonrec x = ﬁx (λx. t′
nonrec ﬁx = ... in let s

1) in t′
2

let

This rule relates recursive bindings to non-recursive ones, and expects an explicit
deﬁnition of the ﬁxpoint operator as well. Since PIR has no primitive construct
for term-level ﬁx-points, the compiler generates a deﬁnition ﬁx . Note that ﬁx is
deﬁned in a non-recursive let, its construction relies on recursive types [19].

The actual transformation for PIR is much more involved, since mutually
recursive binding groups require a more involved ﬁxpoint combinator of which
the deﬁnition depends on the size of the group.

12

Krijnen et al.

3.7 Encoding of datatypes

Datatype deﬁnitions are encoded using lambda and type abstractions according
to the Scott encoding [1]. To show the idea of the rather general ⊲data translation
relation, we show a rule specialised to the Maybe datatype.

t ⊲data t′
data Maybe α = Just α | Nothing with maybe in t
⊲data
(ΛMaybe.λJust.λNothing.λmaybe. t′) τMaybe tJust tNothing tmaybe

[Scott-Maybe]

The [Scott-Maybe] rule relates the datatype deﬁnition to a term that abstracts
over the type Maybe, its constructors Just and Nothing and the matching func-
tion maybe, which are each lambda encoded. For the exact deﬁnitions of τMaybe ,
tJust , tNothing and tmaybe we refer to the general formalisation of PIR [19].

3.8 Encoding of non-recursive bindings

A non-recursive let-binding is simply compiled into a β redex:

t1 ⊲β t′
1

t2 ⊲β t′
2

let

strict
nonrec x = t1 in t2 ⊲β (λx. t′

2) t′
1

[Redex-Let]

Note that at this point in the compiler pipeline, let
let-binding that can still occur.

strict
nonrec is the only type of

4 Evaluation

In this section, we evaluate our approach to proof engineering for an indepen-
dently developed, constantly evolving compiler under the application constraints
imposed by smart contracts.

4.1 Compilers and correctness

The standard approach to compiler correctness is full compiler veriﬁcation: a
proof that asserts that the compiler is correct as it demonstrates that, for any
valid source program, the translation produces a semantically equivalent target
program. Examples of this approach include the CompCert [21] and CakeML [20]
projects, showing that (with signiﬁcant eﬀort) it is possible to verify a compiler
end-to-end. To do so, the compiler is typically implemented in a language suitable
for veriﬁcation, such as the Coq proof assistant or the HOL theorem prover.

In contrast, the technique that we propose for the Plutus Tx compiler is based
on translation validation [27]. Instead of asserting an entire compiler correct,
translation validation establishes the correctness of individual compiler runs.

A statement of full compiler correctness is, of course, the stronger of the
two statements. Translation validation may fail to assert the correctness of some

Translation Certiﬁcation for Smart Contracts

13

compiler runs; either because the compiler did not produce correct code or be-
cause the translation certiﬁer is incomplete. In exchange for being the weaker
property, translation validation is potentially (1) less costly to realise, (2) easier
to retroﬁt to an existing compiler, and (3) more robust in the face of changes to
the compiler.

The idea of proof-carrying code [23] is closely related to translation validation,
shifting the focus to compiled programs, rather than the compiler itself. A pro-
gram is distributed together with a proof of a property such as memory or type
safety. Such a proof excludes certain classes of bugs and gives direct evidence
to the users of such a program, who may independently check the proof before
running it. Our certiﬁcation eﬀort, while related, diﬀers in that we keep proof
and program separate and in that we are interested in full semantic correctness
and not just certain properties like memory and type safety.

4.2 Certiﬁcates and smart contracts

Smart contracts often manage signiﬁcant amounts of ﬁnancial and other assets.
Before a user engages with such a contract, which has been committed to the
blockchain as compiled code, they may want to inspect the source code to assert
that it behaves as they expect. In order to be able to rely on that inspection,
they need to know without doubt that (1) they are looking at the correct source
code and (2) that the source code has been compiled correctly.

While a veriﬁed smart contract compiler addresses the second point, it doesn’t
help with the ﬁrst. An infrastructure of reproducible builds, on the other hand,
solves only the ﬁrst point. The latter is the approach taken by Etherscan5: to
verify that a deployed Ethereum smart contract was the result of a compiler run,
one provides the source code and build information such as the compiler version
and optimisation settings.

In contrast, a certifying compiler [24] that generates an independently veriﬁ-
able certiﬁcate of correct translation, squarely addresses both points. By verify-
ing a smart contract’s translation certiﬁcate, a smart contract user can convince
themselves that they are in possession of the matching source code and that this
was correctly compiled to the code committed to the blockchain.

4.3 Engineering considerations

Gradual veriﬁcation. The certiﬁer architecture outlined in this paper allows
for a gradual approach to veriﬁcation: during the development of the certiﬁcation
engine, each individual step in the process increases our overall conﬁdence in the
compiler’s correctness, even if we have not yet completed the end-to-end semantic
veriﬁcation of the compiler pipeline.

By deﬁning only the translation relations, we have an independent formal
speciﬁcation of the compiler’s behaviour. This makes it easier to reason infor-
mally and to spot potential mistakes or problems with the implementation.

5 https://etherscan.io/verifyContract

14

Krijnen et al.

Implementing the decision procedures for translation relations ties the im-
plementation to the speciﬁcation: we can show on a per-compilation basis that a
pass is sound with respect to its speciﬁcation as a translation relation. Further-
more, we can test and debug translation relations by automatically constructing
evidence for various input programs.

Finally, by proving semantics preservation of a translation relation, we gain
full conﬁdence in the corresponding pass for compiler runs that abide by that
translation relation.

Agility. The Plutus Tx compiler is developed independently of our certiﬁcation
eﬀort. Moreover, it depends on large parts of a large code base — namely, that
of the Glasgow Haskell Compiler (GHC). In addition, both GHC and the Plu-
tus Tx-speciﬁc parts evolve on a constant basis; for example, to improve code
optimisation or to ﬁx bugs.

In that context, full veriﬁcation appears an insurmountable task and a proof
on the basis of the compiler source code would constantly have to adapt to the
evolving compiler source. Hence, the architecture of our certiﬁcation engine is
based on a grey box approach, where the certiﬁer matches the general outline
(such as the phases of the compiler pipeline), but not all of the implementation
details of the compiler. For example, our translation relation for the inliner
admits any valid inlining. Improvements of the compiler heuristics to produce
more eﬃcient programs by being selective about what precisely to inline don’t
aﬀect the inliner’s translation relation, and hence, don’t aﬀect the certiﬁer.

Trusted Computing Base (TCB). The fact that the Plutus Tx compiler
is not implemented in a proof assistant, but in Haskell complicates direct com-
piler veriﬁcation. It might be possible to use a tool like hs-to-coq [29], which
translates a subset of Haskell into Coq’s Gallina and has been used for proving
various properties about Haskell code [11]. However, given that those tools of-
ten only cover language subsets, it is not clear that they are applicable. More
importantly, such an approach would increase the size of the trusted computing
base (TCB), as the translation from Haskell into Coq’s Gallina is not veriﬁed.
Similarly, extraction-based approaches suﬀer from the same problem if the ex-
traction itself is not veriﬁed, although there are projects like CertiCoq [3] that
try to address that issue.

In any case, our architecture has a small TCB. We directly relate the source
and target programs, taking the compiler implementation out of the equation.
Trusting a translation certiﬁcate comes down to trusting the Coq kernel that
checks the proof, the theorem with its supporting deﬁnitions and soundness of
the Plutus Core interpreter with respect to the formalised semantics. Of course,
these components are part of the TCB of a veriﬁed compiler too. This aspect
also motivated our choice of Coq over other languages such as Agda, due to its
relatively small and mature kernel.

Translation Certiﬁcation for Smart Contracts

15

5 Related Work

Ethereum was the ﬁrst blockchain to popularise use of smart contracts, written
in the Solidity programming language. Solidity is an imperative programming
language that is compiled to EVM bytecode, which runs on a stack machine op-
erating on persistent mutable state. The DAO vulnerability [12] has underlined
the importance of formal veriﬁcation of smart contracts. Notably, a veriﬁca-
tion framework has been presented [10] for reasoning about embedded Solidity
programs in F*. The work includes a decompiler to convert EVM bytecode, gen-
erated by a compiler, into Solidity programs in F*. The authors propose that
correctness of compilation can be shown by proving equivalence of the embedded
source and (decompiled) target program using relational reasoning [7]. However,
this would involve a manual proof eﬀort on a per-program basis, and relies on
the F* semantics since the embeddings are shallow. Furthermore, components
such as the decompiler are not formally veriﬁed, adding to the size of the TCB.
The translation validation technique has been used for the veriﬁcation of a
particular critical Ethereum smart contract [26] using the K framework. The
work demonstrates how translation validation can succesfully be applied to con-
struct proofs about the low-level EVM bytecode by mostly reasoning on the
(much more understandable) source code. The actual reﬁnement proof is still
constructed manually, however.

The Tezos blockchain also uses a stack-like language, called Michelson. The
Mi-Cho-Coq framework [8] formalises the language and supports reasoning with
a weakest precondition logic. There is ongoing work for developing a certiﬁed
compiler in Coq for the Albert intermediate language, intended as a target lan-
guage for certiﬁed compilers of higher-level languages. This diﬀers from our ap-
proach as it requires the compiler to be implemented in the proof assistant.

ConCert is a smart contract veriﬁcation framework in Coq [4]. It enables for-
mal reasoning about the source code of a smart contracts, deﬁned in a diﬀerent
(functional) language. The programs are translated and shallowly embedded in
Coq’s Gallina. Interestingly, the translation is proven sound, in contrast with
approaches such as hs-to-coq [29], since it is implemented using Coq’s metapro-
gramming and reasoning facility MetaCoq [28].

The Cogent certifying compiler [25] has shown that it is possible to use trans-
lation validation for lowering the cost of functional veriﬁcation of low-level code:
a program can be written and reasoned about in a high-level functional lan-
guage, which is compiled down to C. The generated certiﬁcate then proves a
reﬁnement relation, capable of transporting the veriﬁcation results to the cor-
responding C code. The situation is diﬀerent from ours: the Cogent compiler
goes through a range of languages with diﬀerent semantic models and uses the
forward-simulation technique as a consequence. In contrast, we are working with
variations of lambda calculi that have similar semantics, allowing us to use logical
relations and translation relations.

In their Coq framework [22], Li and Appel use a similar technique for speci-
fying compiler passes as inductive relations in Coq. Their tool reduces the eﬀort
of implementing program transformations and corresponding correctness proofs.

16

Krijnen et al.

The tool is able to generate large parts of an implementation together with a
partial soundess proof with respect to those relations. The approach is used to
implement parts of the CertiCoq backend.

6 Conclusions and further work

The Plutus Tx compiler translates a Haskell subset into Plutus Core. The com-
piler consists of three main parts: the ﬁrst one reuses various stages of GHC
to compile the Haskell subset to GHC Core — GHC’s principal intermediate
language. The second part translates GHC Core to PIR and the ﬁnal part com-
piles PIR to Plutus Core. As Plutus Core is strict and doesn’t directly support
datatypes, these parts are quite complex. Moreover, they consist of a signiﬁcant
number of successive transformation steps.

In this paper, we focused on the certiﬁcation eﬀort covering the third part
of that pipeline; speciﬁcally, the translation steps from PIR to Plutus Core. We
developed translation relations for all passes described in Section 3, such that
we can, for example, produce a proof relating the previously described timelock
example in PIR to its ﬁnal form in Plutus Core. For some of these passes,
such as inlining, we have implemented a veriﬁed decision procedure, but most
of the evidence is generated semi-automatically by using Coq tactics. We have
not yet covered all transformations in their full generality; for example, we do
not cover (mutually) recursive datatypes yet. We have also started the semantic
veriﬁcation of key passes of the translation[14] and are investigating diﬀerent
ways to improve the eﬃciency of proof search for larger programs.

Our next steps comprise the following: (1) ﬁlling in the remaining gaps in
translation relations (such as covering mutually recursive datatypes); (2) com-
plete all decision procedures; (3) drive the semantic veriﬁcation forward; and (4)
develop techniques to further automate our approach and improve the eﬃciency
of the certiﬁer.

The ﬁrst three steps pose a signiﬁcant amount of work, but we do not expect
major new conceptual questions or obstacles. This is diﬀerent for Step (4), where
we anticipate the need for further research work. This includes more composi-
tional deﬁnitions of the translation relations, such that we can generate at least
part of the decision procedures (semi-)automatically. Moreover, we already per-
ceive eﬃciency to be a bottleneck and we plan to work on optimising the proof
search. Finally, we plan to apply our approach to the ﬁrst part of the Plutus Tx
compiler (Haskell subset to GHC Core).

References

1. Abadi, M., Cardelli, L., Plotkin, G.: Types for the Scott numerals (1993)
2. Ahmed, A.: Step-indexed syntactic logical relations for recursive and quantiﬁed
types. In: European Symposium on Programming. pp. 69–83. Springer (2006)
3. Anand, A., Appel, A., Morrisett, G., Paraskevopoulou, Z., Pollack, R., Belanger,
O.S., Sozeau, M., Weaver, M.: CertiCoq: A veriﬁed compiler for Coq. In: The third
international workshop on Coq for programming languages (CoqPL) (2017)

Translation Certiﬁcation for Smart Contracts

17

4. Annenkov, D., Nielsen, J.B., Spitters, B.: ConCert: a smart contract certiﬁcation
framework in Coq. In: Proceedings of the 9th ACM SIGPLAN International Con-
ference on Certiﬁed Programs and Proofs. pp. 215–228 (2020)

5. Atzei, N., Bartoletti, M., Cimoli, T.: A survey of attacks on Ethereum smart con-
tracts (SoK). In: Principles of Security and Trust (POST 2017). LNCS, vol. 10204
(2017)

6. Barras, B., Boutin, S., Cornes, C., Courant, J., Filliatre, J.C., Gimenez, E., Herbe-
lin, H., Huet, G., Munoz, C., Murthy, C., et al.: The Coq proof assistant reference
manual: Version 6.1. Ph.D. thesis, Inria (1997)

7. Barthe, G., Fournet, C., Gr´egoire, B., Strub, P.Y., Swamy, N., Zanella-B´eguelin,
S.: Probabilistic relational veriﬁcation for cryptographic implementations. ACM
SIGPLAN Notices 49(1), 193–205 (2014)

8. Bernardo, B., Cauderlier, R., Hu, Z., Pesin, B., Tesson, J.: Mi-Cho-Coq, a frame-
work for certifying Tezos smart contracts. In: International Symposium on Formal
Methods. pp. 368–379. Springer (2019)

9. Bertot, Y., Cast´eran, P.: Interactive theorem proving and program development:
Coq’Art: the calculus of inductive constructions. Springer Science & Business Me-
dia (2013)

10. Bhargavan, K., Delignat-Lavaud, A., Fournet, C., Gollamudi, A., Gonthier, G.,
Kobeissi, N., Kulatova, N., Rastogi, A., Sibut-Pinote, T., Swamy, N., et al.: Formal
veriﬁcation of smart contracts: Short paper. In: Proceedings of the 2016 ACM
workshop on programming languages and analysis for security. pp. 91–96 (2016)

11. Breitner, J., Spector-Zabusky, A., Li, Y., Rizkallah, C., Wiegley, J., Weirich, S.:
Ready, set, verify! applying hs-to-coq to real-world Haskell code (experience re-
port). Proceedings of the ACM on Programming Languages 2(ICFP), 1–16 (2018)
Vulnerability.
UPDATE

12. Buterin,

CRITICAL

DAO

Re:

V.:

https://blog.ethereum.org/2016/06/17/critical-update-re-dao-vulnerability/
(2016), retrieved December 10, 2021

13. Chapman, J., Kireev, R., Nester, C., Wadler, P.: System F in Agda, for fun and
proﬁt. In: Mathematics of Program Construction (MPC 2019). LNCS, vol. 11825
(2019)

14. Dral, J.: Veriﬁed Compiler Optimisations. Master’s thesis, Utrecht University

(2022)

15. GHC Team: GHC 9.0 User Manual. https://downloads.haskell.org/~ghc/9.0.1/docs/html/users_guide/extending_ghc.html
16. Giegerich, R., M¨oncke, U.: Invariance of approximative semantics with respect to
program transformations. In: GI—11. Jahrestagung, pp. 1–10. Springer (1981)

17. Gonthier, G., Le, R.S.: An Ssreﬂect Tutorial. Ph.D. thesis, INRIA (2009)
18. IOHK: The

Platform and Marlowe
https://plutus.readthedocs.io/en/latest/plutus/tutorials/plutus-tx.html

documentation.

Plutus

1.0.0

19. Jones, M.P., Gkoumas, V., Kireev, R., MacKenzie, K., Nester, C., Wadler, P.:
Unraveling recursion: compiling an IR with recursion to System F. In: International
Conference on Mathematics of Program Construction. pp. 414–443. Springer (2019)
20. Kumar, R., Myreen, M.O., Norrish, M., Owens, S.: CakeML: a veriﬁed implemen-

tation of ML. ACM SIGPLAN Notices 49(1), 179–191 (2014)

21. Leroy, X., Blazy, S., K¨astner, D., Schommer, B., Pister, M., Ferdinand, C.:
CompCert—a formally veriﬁed optimizing compiler. In: ERTS 2016: Embedded
Real Time Software and Systems, 8th European Congress (2016)

22. Li, J.M., Appel, A.W.: Deriving eﬃcient program transformations from rewrite
rules. Proceedings of the ACM on Programming Languages 5(ICFP), 1–29 (2021)
23. Necula, G.C.: Proof-carrying code. In: Proceedings of the 24th ACM SIGPLAN-
SIGACT symposium on Principles of programming languages. pp. 106–119 (1997)

18

Krijnen et al.

24. Necula, G.C., Lee, P.: The design and implementation of a certifying compiler.

SIGPLAN Not. 39(4), 612–625 (Apr 2004)

25. O’Connor, L., Chen, Z., Rizkallah, C., Jackson, V., Amani, S., Klein, G., Murray,
T., Sewell, T., Keller, G.: Cogent: uniqueness types and certifying compilation.
Journal of Functional Programming 31 (2021)

26. Park, D., Zhang, Y., Rosu, G.: End-to-end formal veriﬁcation of Ethereum 2.0
deposit smart contract. In: Computer Aided Veriﬁcation (CAV 2020). LNCS, vol.
12224 (2020)

27. Pnueli, A., Siegel, M., Singerman, E.: Translation validation. In: International Con-
ference on Tools and Algorithms for the Construction and Analysis of Systems. pp.
151–166. Springer (1998)

28. Sozeau, M., Anand, A., Boulier, S., Cohen, C., Forster, Y., Kunze, F., Malecha,
G., Tabareau, N., Winterhalter, T.: The MetaCoq project. Journal of Automated
Reasoning (2020)

29. Spector-Zabusky, A., Breitner, J., Rizkallah, C., Weirich, S.: Total Haskell is rea-
sonable Coq. In: Proceedings of the 7th ACM SIGPLAN International Conference
on Certiﬁed Programs and Proofs. pp. 14–27 (2018)

Translation Certiﬁcation for Smart Contracts

19

A Compiler dumps for the timelock program

In this appendix we show step-by-step how the timelock example in section 3 is transformed
by the passes in the Plutus Tx compiler. These programs were obtained by running the Plutus
Tx compiler on the Haskell source code program, after modifying the pretty-printer to output
a bit more compact presentation. We ocassionally omit some sub-terms to improve readability
(indicated as ...).

A.1 Original PIR Term

The Plutus Tx compiler converts the GHC Core program into the following PIR program. Note
that variables in PIR are represented as pairs of names and unique integers. The name is only
maintained for readability, whereas the integers are used for actual program transformations. We
pretty-print the integer in subscript after the name.

The conversion includes deﬁnitions for all the built-in types and functions that may be used in
PIR program, since the program has to be self-contained. Starting from line 34 we can recognise
the timelock example. Note that Haskell’s lazy case expression has been translated to a call to
EndDate_match, where the case branches have been “thunked” by abstracting over a unit value.
This thunking prevents the (strict) function application of EndDate_match from evaluating all
the branches.

= True13 : ... | False14 : ... with Bool_match12 in

= Unit62 : ... with Unit_match61 in

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

let nonrec type ByteString0 = ... in
let nonrec data Bool11
let nonrec strict verifySignature57 = ... in
let nonrec type String2 = ... in
let nonrec data Unit60
let nonrec strict trace70 = ... in
let nonrec type Integer1 = ... in
let nonrec strict takeByteString5 = ... in
let nonrec strict subtractInteger27 = ... in
let nonrec strict sha3_8 = ... in
let nonrec strict sha2_7 = ... in
let nonrec strict remainderInteger32 = ... in
let nonrec strict quotientInteger31 = ... in
let nonrec strict multiplyInteger28 = ... in
let nonrec strict modInteger30 = ... in
let nonrec strict lessThanInteger44 = ... in
let nonrec strict lessThanEqInteger48 = ... in
let nonrec strict lessThanByteString20 = ... in
let nonrec strict greaterThanInteger36 = ... in
let nonrec strict greaterThanEqInteger40 = ... in
let nonrec strict greaterThanByteString24 = ... in
let nonrec strict error64 = ... in
let nonrec strict equalsInteger52 = ... in
let nonrec strict equalsByteString16 = ... in
let nonrec strict emptyString66 = ... in

20

Krijnen et al.

let nonrec strict emptyByteString25 = ... in
let nonrec strict dropByteString6 = ... in
let nonrec strict divideInteger29 = ... in
let nonrec strict concatenate4 = ... in
let nonrec type Char3 = ... in
let nonrec strict charToString67 = ... in
let nonrec strict appendString65 = ... in
let nonrec strict addInteger26 = ... in
let nonrec data EndDate71
λds75 : EndDate71 .
λds76 : Integer .
let nonrec nonstrict inlineMe77 = False in
let nonrec nonstrict wild78 = ... in
(((EndDate_match72 ds75 { Unit60 -> Bool11 }) (λn79 : Integer .
λthunk84 : Unit60 .
(lessThanEqInteger48 (let nonrec nonstrict floatMe83 = ... in
floatMe83)) ds76)) (λthunk85 : Unit60 .
inlineMe77)) Unit62

= Fixed73 : ... | Never74 : ... with EndDate_match72 in

A.2 Renaming

The ﬁrst pass does a global renaming to ensure each variable is in fact globally unique. Note
that the integers of all bound variables are indeed renamed compared to the previous version of
the program.

= True88 : ... | False89 : ... with Bool_match90 in

= Unit98 : ... with Unit_match99 in

let nonrec type ByteString86 = ... in
let nonrec data Bool87
let nonrec strict verifySignature91 = ... in
let nonrec type String96 = ... in
let nonrec data Unit97
let nonrec strict trace100 = ... in
let nonrec type Integer103 = ... in
let nonrec strict takeByteString104 = ... in
let nonrec strict subtractInteger105 = ... in
let nonrec strict sha3_106 = ... in
let nonrec strict sha2_107 = ... in
let nonrec strict remainderInteger108 = ... in
let nonrec strict quotientInteger109 = ... in
let nonrec strict multiplyInteger110 = ... in
let nonrec strict modInteger111 = ... in
let nonrec strict lessThanInteger112 = ... in
let nonrec strict lessThanEqInteger116 = ... in
let nonrec strict lessThanByteString120 = ... in
let nonrec strict greaterThanInteger124 = ... in
let nonrec strict greaterThanEqInteger128 = ... in
let nonrec strict greaterThanByteString132 = ... in

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

1

2

3

4

5

6

7

8

9

10

11

12

13

Translation Certiﬁcation for Smart Contracts

21

let nonrec strict error136 = ... in
let nonrec strict equalsInteger140 = ... in
let nonrec strict equalsByteString144 = ... in
let nonrec strict emptyString148 = ... in
let nonrec strict emptyByteString149 = ... in
let nonrec strict dropByteString150 = ... in
let nonrec strict divideInteger151 = ... in
let nonrec strict concatenate152 = ... in
let nonrec type Char153 = ... in
let nonrec strict charToString154 = ... in
let nonrec strict appendString155 = ... in
let nonrec strict addInteger156 = ... in
let nonrec data EndDate157
λds161 : EndDate157 .
λds162 : Integer .
let nonrec nonstrict inlineMe163 = False in
let nonrec nonstrict wild164 = ... in
(((EndDate_match160 ds161 { Unit97 -> Bool87 }) (λn165 : Integer .
λthunk166 : Unit97 .
(lessThanEqInteger116 (let nonrec nonstrict floatMe167 = ... in
floatMe167)) ds162)) (λthunk171 : Unit97 .
inlineMe163)) Unit98

= Fixed158 : ... | Never159 : ... with EndDate_match160 in

A.3 Dead Code Elimination

In this pass, the compiler cleans up the unused deﬁnitions that were present after the GHC core
translation.

= Fixed72 : ... | Never73 : ... with EndDate_match74 in

= True2 : ... | False3 : ... with Bool_match4 in
= Unit12 : ... with Unit_match13 in

let nonrec data Bool1
let nonrec data Unit11
let nonrec strict lessThanEqInteger30 = ... in
let nonrec strict greaterThanEqInteger42 = ... in
let nonrec data EndDate71
λds75 : EndDate71 .
λds76 : Integer .
let nonrec nonstrict inlineMe77 = False in
(((EndDate_match74 ds75 { Unit11 -> Bool1 }) (λn79 : Integer .
λthunk80 : Unit11 .
(lessThanEqInteger30 (let nonrec nonstrict floatMe81 = ... in
floatMe81)) ds76)) (λthunk85 : Unit11 .
inlineMe77)) Unit12

A.4 Inlining

The compiler performs an inlining pass and decides to inline the let-bound deﬁnition inlineMe
on line 8 in Section A.3. This results in the following program, where the let-binding has been
eliminated and the inlined deﬁnition (False) can be seen on line 12.

22

Krijnen et al.

= True2 : ... | False3 : ... with Bool_match4 in
= Unit12 : ... with Unit_match13 in

let nonrec data Bool1
let nonrec data Unit11
let nonrec strict lessThanEqInteger30 = ... in
let nonrec strict greaterThanEqInteger42 = ... in
let nonrec data EndDate71
λds75 : EndDate71 .
λds76 : Integer .
(((EndDate_match74 ds75 { Unit11 -> Bool1 }) (λn79 : Integer .
λthunk80 : Unit11 .
(lessThanEqInteger30 (let nonrec nonstrict floatMe81 = ... in
floatMe81)) ds76)) (λthunk85 : Unit11 .
False3)) Unit12

= Fixed72 : ... | Never73 : ... with EndDate_match74 in

A.5 Thunking recursive deﬁnitions

The next pass thunks recursive term bindings (similar to the encoding of non-strict let bindings
in Section A.7), to make sure that they are of a function type and work well with the ﬁxpoint
combinator that is introduced in a later pass (Section A.9). Since this program does not include
any recursive term bindings, the result is unchanged.

A.6 Let-ﬂoating

Next, the Plutus Tx compiler decides to ﬂoat a let-bound deﬁnition. In this run, the floatMe
deﬁnition is moved outside of the ﬁrst argument of lessThanEqInteger, as can be seen on line
10. Additionally, this pass performs merging of adjacent let deﬁnitions into a single let with a
group of bindings, printed on line 1. We did not mention this transformation in Section 3.3, since
simpliﬁed PIR has no binding groups. The order of these deﬁnitions has also changed, but this
is ﬁne as long as no dependencies are broken. We use a translation relation that is reminiscent
of the one in Sectionsub:let-ﬂoat, but for bindings only.

let nonrec data Bool1

= True2 : ... | False3 : ... with Bool_match4;

strict greaterThanEqInteger42 = ...;
data Unit11
data EndDate71
strict lessThanEqInteger30 = ... in

= Unit12 : ... with Unit_match13;

= Fixed72 : ... | Never73 : ... with EndDate_match74;

λds75 : EndDate71 .
λds76 : Integer .
(((EndDate_match74 ds75 { Unit11 -> Bool1 }) (λn79 : Integer .
λthunk80 : Unit11 .
let nonrec nonstrict floatMe81 = ... in
(lessThanEqInteger30 floatMe81) ds76)) (λthunk85 : Unit11 .
False3)) Unit12

1

2

3

4

5

6

7

8

9

10

11

12

1

2

3

4

5

6

7

8

9

10

11

12

Translation Certiﬁcation for Smart Contracts

23

A.7 Encoding of non-strict let bindings

The non-strict binding on line 10 is transformed in a strict binding by thunking. From the type
we can see that the Plutus Tx compiler actually abstracts over the Scott-encoded version of a
unit value. The occurrence is applied to a unit value on line 11.

let nonrec data Bool1

= True2 : ... | False3 : ... with Bool_match4;

strict greaterThanEqInteger42 = ...;
data Unit11
data EndDate71
strict lessThanEqInteger30 = ... in

= Unit12 : ... with Unit_match13;

= Fixed72 : ... | Never73 : ... with EndDate_match74;

λds75 : EndDate71 .
λds76 : Integer .
(((EndDate_match74 ds75 { Unit11 -> Bool1 }) (λn79 : Integer .
λthunk80 : Unit11 .
let nonrec strict floatMe81 = λarg207 : ∀a0 : *.a0 -> a0 . ... in
(lessThanEqInteger30 (floatMe81 (Λa0 : *.
λx1 : a0 .
x1))) ds76)) (λthunk85 : Unit11 .
False3)) Unit12

A.8 Encoding of datatypes

Next, the three datatype deﬁnitions are Scott encoded. For example, the Bool datatype with its
constructors and matching function are bound on line 1 to 4, and the corresponding deﬁnitions
are found as arguments on line 40 for Bool, line 41-44 for True, line 45-48 for False and line
49-50 for Bool_match.

(((ΛBool1 : *.
λTrue2 : Bool1 .
λFalse3 : Bool1 .
λBool_match4 : Bool1 -> (∀a221 : *.a221 -> (a221 -> a221)) .
let nonrec strict greaterThanEqInteger42 = ... in
((ΛUnit11 : *.
λUnit12 : Unit11 .
λUnit_match13 : Unit11 -> (∀a217 : *.a217 -> a217) .
(((ΛEndDate71 : *.
λFixed72 : Integer -> EndDate71 .
λNever73 : EndDate71 .
λEndDate_match74 : EndDate71 -> (∀a208 : *.(Integer -> a208) -> (a208 -> a208)) .
let nonrec strict lessThanEqInteger30 = ... in
λds75 : EndDate71 .
λds76 : Integer .
(((EndDate_match74 ds75 { Unit11 -> Bool1 }) (λn79 : Integer .
λthunk80 : Unit11 .
let nonrec strict floatMe81 = ... in

1

2

3

4

5

6

7

8

9

10

11

12

13

14

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

24

Krijnen et al.

(lessThanEqInteger30 (floatMe81 (Λa0 : *.
λx1 : a0 .
x1))) ds76)) (λthunk85 : Unit11 .
False3)) Unit12 { ∀a208 : *.(Integer -> a208) -> (a208 -> a208) })
(λarg_0212 : Integer .

Λa209 : *.
λcase_Fixed210 : Integer -> a209 .
λcase_Never211 : a209 .

case_Fixed210 arg_0212))

(Λa213 : *.

λcase_Fixed214 : Integer -> a213 .
λcase_Never215 : a213 .

case_Never215))

(λx216 : ∀a208 : *.(Integer -> a208) -> (a208 -> a208) .

x216)

{ ∀a217 : *.a217 -> a217 })
(Λa218 : *.

λcase_Unit219 : a218 .

case_Unit219))

(λx220 : ∀a217 : *.a217 -> a217 .

x220)

{ ∀a221 : *.a221 -> (a221 -> a221) })
(Λa222 : *.

λcase_True223 : a222 .
λcase_False224 : a222 .
case_True223))

(Λa225 : *.

λcase_True226 : a225 .
λcase_False227 : a225 .

case_False227))

(λx228 : ∀a221 : *.a221 -> (a221 -> a221) .

x228)

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

A.9 Recursive let bindings, inlining and dead-code elimination

The next three passes encode recursive term-bindings, and perform another round of inlining and
dead code elimination. In this example program however, they have no eﬀect and the program
does not change.

A.10 Non-recursive let bindings

The ﬁnal pass encodes non-recursive let bindings as a beta-redex. The floatMe binding in Section
A.8 line 18 can be recognised below on line 18, where it is now lambda-bound, and line 43 where
the deﬁnition is provided as an argument.

Translation Certiﬁcation for Smart Contracts

25

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

(((ΛBool0 : *.
λTrue1 : Bool0 .
λFalse2 : Bool0 .
λBool_match3 : Bool0 -> (∀a4 : *.a4 -> (a4 -> a4)) .
(λgreaterThanEqInteger5 : Integer -> (Integer -> Bool0) .
((ΛUnit9 : *.
λUnit10 : Unit9 .
λUnit_match11 : Unit9 -> (∀a12 : *.a12 -> a12) .
(((ΛEndDate13 : *.
λFixed14 : Integer -> EndDate13 .
λNever15 : EndDate13 .
λEndDate_match16 : EndDate13 -> (∀a17 : *.(Integer -> a17) -> (a17 -> a17)) .
(λlessThanEqInteger18 : Integer -> (Integer -> Bool0) .
λds22 : EndDate13 .
λds23 : Integer .
(((EndDate_match16 ds22 { Unit9 -> Bool0 }) (λn24 : Integer .
λthunk25 : Unit9 .
(λfloatMe26 : (∀a27 : *.a27 -> a27) -> Integer .
(lessThanEqInteger18 (floatMe26 (Λa32 : *.
λx33 : a32 .
x33))) ds23) (λarg28 : ∀a29 : *.a29 -> a29 .
(((Bool_match3 ((greaterThanEqInteger5 ds23) 0) { Unit9 -> Integer }) (λthunk30 : Unit9 .
n24)) (λthunk31 : Unit9 .
0)) Unit10))) (λthunk34 : Unit9 .
False2)) Unit10) (λarg19 : Integer .
λarg20 : Integer .
(λb21 : Bool .
(((ifThenElse { Bool0 }) b21) True1) False2) ((lessThanEqInteger arg19) arg20)) {...})
(λarg_036 : Integer .

30 Λa37 : *.

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

λcase_Fixed38 : Integer -> a37 .
λcase_Never39 : a37 .
case_Fixed38 arg_036)) (Λa40 : *.
λcase_Fixed41 : Integer -> a40 .
λcase_Never42 : a40 .
case_Never42)) (λx43 : ∀a44 : *.(Integer -> a44) -> (a44 -> a44) .
x43) { ∀a45 : *.a45 -> a45 }) (Λa46 : *.
λcase_Unit47 : a46 .
case_Unit47)) (λx48 : ∀a49 : *.a49 -> a49 .
x48)) (λarg6 : Integer .
λarg7 : Integer .
(λb8 : Bool .
(((ifThenElse { Bool0 }) b8) True1) False2) ((greaterThanEqInteger arg6) arg7)) {...})
(Λa51 : *.
λcase_True52 : a51 .

26

Krijnen et al.

46

47

48

49

50

51

λcase_False53 : a51 .
case_True52)) (Λa54 : *.
λcase_True55 : a54 .
λcase_False56 : a54 .
case_False56)) (λx57 : ∀a58 : *.a58 -> (a58 -> a58) .
x57)

