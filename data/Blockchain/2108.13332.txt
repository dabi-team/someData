IEEE TRANSACTIONS ON COMMUNICATIONS

1

Overcoming Data Availability Attacks in
Blockchain Systems: Short Code-Length LDPC
Code Design for Coded Merkle Tree

Debarnab Mitra, Student Member, IEEE, Lev Tauz, Student Member, IEEE and Lara Dolecek, Senior
Member, IEEE

2
2
0
2

g
u
A
7
2

]
T
I
.
s
c
[

3
v
2
3
3
3
1
.
8
0
1
2
:
v
i
X
r
a

Abstract—Light nodes in blockchains improve the scalability
of the system by storing a small portion of the blockchain ledger.
light nodes are vulnerable to a data
In certain blockchains,
availability (DA) attack where a malicious node makes the light
nodes accept an invalid block by hiding the invalid portion of
the block from the nodes in the system. Recently, a technique
based on LDPC codes called Coded Merkle Tree (CMT) was
proposed by Yu et al. that enables light nodes to detect a DA
attack by randomly requesting/sampling portions of the block
from the malicious node. However, light nodes fail to detect a
DA attack with high probability if a malicious node hides a small
stopping set of the LDPC code. To mitigate this problem, Yu et al.
used random LDPC codes that achieve large minimum stopping
set size with high probability. Although effective, these codes are
not necessarily optimal for this application, especially at short
code lengths, which are relevant for low latency systems, IoT
blockchains, etc.. In this paper, we focus on short code lengths
and demonstrate that a suitable co-design of specialized LDPC
codes and the light node sampling strategy can improve the
probability of detection of DA attacks. We consider different
adversary models based on their computational capabilities of
ﬁnding stopping sets in LDPC codes. For a weak adversary
model, we devise a new LDPC code construction termed as
the entropy-constrained PEG (EC-PEG) algorithm which con-
centrates stopping sets to a small group of variable nodes.
We demonstrate that the EC-PEG algorithm coupled with a
greedy sampling strategy improves the probability of detection
of DA attacks. For stronger adversary models, we provide a co-
design of a sampling strategy called linear-programming-sampling
(LP-sampling) and an LDPC code construction called linear-
programming-constrained PEG (LC-PEG) algorithm. The new
co-design demonstrates a higher probability of detection of DA
attacks compared to approaches in earlier literature.

Index Terms—Blockchain Systems, Data Availability Attacks,

LDPC codes, Coded Merkle Tree

I. INTRODUCTION

Blockchains are tamper-proof ledgers of transaction data
maintained by a network of nodes in a decentralized manner.
They were initially proposed in the ﬁeld of cryptocurrencies
like Bitcoin and Ethereum. However, the decentralized nature
of blockchains has lead to their application in ﬁelds such as
supply chains [5], Internet of Things [6], and healthcare [7].
A blockchain is a collection of transaction blocks arranged
in the form of a hash-chain. Full nodes in the blockchain
network store the entire blockchain ledger and operate on it
to validate transactions. However, storing the entire ledger re-

quires a signiﬁcant storage overhead1 which prevents resource
limited nodes from joining the blockchain system. To alleviate
this problem, some blockchain systems also run light nodes
[4]. These are nodes that only store the headers corresponding
to each block of the blockchain. The header for each block
contains a ﬁeld called a Merkle root which is constructed from
the block transactions [4]. Using the Merkle root, light nodes
can verify the inclusion of a given transaction in a block via a
technique called a Merkle proof. However, they cannot verify
the correctness of the transactions in the block.

Assuming that the system has a majority of honest full
nodes, light nodes simply accept headers that are a part of
the longest header chain because honest full nodes will not
mine blocks on chains containing fraudulent transactions (i.e.,
a longest chain consensus protocol [4] is used). However,
when the honest majority assumption is removed, the longest
chain protocol becomes insecure for light nodes. As such,
researchers were prompted to ﬁnd methods to provide security
even under a dishonest majority of full nodes. One such
research endeavor was [1] where authors provided protocols
for honest full nodes to broadcast veriﬁable fraud proofs of
invalid transactions. The mechanism allows light nodes, even
in the presence of a majority of malicious full nodes, to reject
headers of invalid blocks on receiving fraud proofs from an
honest full node. However, with a majority of malicious full
nodes, the light nodes are still susceptible to data availability
(DA) attacks [1], [2]. In this attack, as illustrated in Fig. 1 left
panel, a malicious full node generates a block with invalid
transactions, publishes the header of the invalid block to the
light nodes, and hides the invalid portion of the block from
the full nodes. Honest full nodes cannot validate the missing
portion of the block and hence are unable to generate fraud
proofs to be sent to the light nodes. Since the absence of a
fraud proof also corresponds to the situation that the block is
valid, light nodes accept the invalid header2.

Light nodes can independently detect a DA attack if a
request for a portion of the block is rejected by the full node
that generates the block. As such, as illustrated in Fig. 1 right
panel, light nodes randomly sample the block, i.e., randomly
request for different portions of the block transactions and
accept the header if all the requested portions are returned.
In this paper, we are interested in reducing the probability of
failure for a light node to detect a DA attack for a given sample

D. Mitra, L. Tauz, and L. Dolecek are with the ECE Department,
UCLA, Los Angeles, CA 90095 USA (e-mail: debarnabucla@ucla.edu, lev-
tauz@ucla.edu, dolecek@ee.ucla.edu). A part of this paper was presented at
the IEEE Information Theory Workshop 2020 [3]. Research supported in part
by the Guru Krupa Foundation and NSF-BSF grant no. 2008728.

1At the time of writing, the size of the Bitcoin and Ethereum ledgers are

around 400GB [9] and 650GB [10], respectively.

2In this system, there is no way of identifying honest alarm messages sent

by full nodes about block unavailability [2], [11].

 
 
 
 
 
 
2

IEEE TRANSACTIONS ON COMMUNICATIONS

Fig. 1: Left: Data Availability (DA) attack; Right: Detection of DA attack via light node sampling

size, thus improving the security of the system. Since the size
of individual transactions is much smaller compared to the
entire block, an adversary can hide a very small portion of the
block corresponding to the invalid transactions. Such a hiding
will result in a high probability of failure for the light nodes
using random sampling. To alleviate this problem, authors in
[1] proposed coding the block using erasure codes3. When the
block is erasure coded, to make the invalid portion of the block
unavailable, the malicious block producer must prevent honest
full nodes from decoding back the original block. They do so
by either 1) hiding a larger portion of the coded block (more
than the erasure correcting capability of the code). This hiding
can be detected with a high probability by the light nodes using
random sampling; 2) incorrectly generating the coded data. In
this case, honest full nodes can broadcast veriﬁable incorrect-
coding (IC) proofs [1], [2] allowing light nodes to reject the
header. To keep the IC proof size small, authors in [1] used
2D Reed-Solomon (RS) codes. 2D-RS codes result in an IC
proof size of O(√b log b), where b is the size of the block.
Work in [2] extends the idea into a technique called Coded
Merkle Tree (CMT). A CMT uses Low-Density Parity-Check
(LDPC) codes for encoding a Merkle tree and it provides the
following beneﬁts: 1) small check node (CN) degrees in the
LDPC codes reduce the IC proof size to O(log b) [2]; 2) LDPC
codes can be decoded using a linear time peeling decoder [12],
thus reducing the decoding complexity compared to Reed-
Solomon codes. Despite these beneﬁts, an LDPC code with
a peeling decoder leads to certain problematic objects, called
stopping sets [12] that allow malicious nodes to successfully
hide a smaller portion of the block compared to Reed-Solomon
codes. A stopping set of an LDPC code is a set of variable
nodes (VNs) that if erased prevents a peeling decoder from
fully decoding the original block. If a malicious node hides
coded symbols corresponding to a stopping set of the LDPC
code, full nodes will not be able to decode the CMT. Since
the malicious node can hide the smallest stopping set, the
best code design strategy to reduce the probability of failure

3As with all applications of channel coding, coded redundancy results in
a rate penalty, which in this case is a storage overhead at the full nodes. In
this work, we improve the trade-off between the storage overhead and the
probability of failure of detecting DA attacks by providing better codes, thus,
making channel coding a more viable solution despite the overhead.

using random sampling is to construct deterministic LDPC
codes with large minimum stopping set size. Constructing such
LDPC codes is considered a hard problem [13].

Another important coding parameter for the CMT is the
length of the LDPC codes which affects the encoding/decoding
complexity and Merkle proof sizes. Similar to applications
such as wireless systems, short code lengths are beneﬁcial
in CMT applications (like low latency blockchains [8] or
resource limited IoT blockchains [6]) since they keep the
above quantities small. Previous work in [2] have focused on
using codes from an LDPC ensemble to construct the CMT.
At large code lengths, the LDPC ensemble guarantees, with
high probability, a large stopping ratio (the smallest stopping
set size divided by the code length [2]) and hence a low
probability of failure. However, at short code lengths, the
LDPC ensemble is unable to provide good guarantees on the
minimum stopping set size. Authors in [2] combat this issue
through the use of bad-code proofs when codes with a smaller
stopping ratio (bad-codes) than guaranteed by the ensemble
get used. A bad-code proof triggers all nodes in the system
to use a newly sampled code from the ensemble. However, at
short code lengths, this approach requires many rounds of bad
codes until a good code has been found which undermines
the security of the system. Thus, the LDPC code design of
[2] is inappropriate for short CMT code lengths. Hence, in
this paper, we focus on short CMT code lengths and provide
deterministic LDPC codes that allow for good detection of DA
attacks. Due to our focus on short code-lengths, we do not
make guarantees for the extension of the techniques proposed
in this paper to longer code lengths. For various adversary
models, we provide a co-design of specialized LDPC codes
and sampling strategies that reduce the probability of failure
compared to techniques used in earlier literature.

We can broadly categorize all possible adversaries into
three types based on their computational capabilities. The
computational complexity is based on how hard it
is for
a malicious node to ﬁnd the minimum stopping set in the
LDPC code (which is known to be an NP-hard problem
[14]). Note that the light node sampling strategy is known
by all entities in the system. The ﬁrst adversary type is
termed as a weak adversary. A weak adversary does not
have the resources to ﬁnd a large number of stopping sets. It

SUBMITTED PAPER

3

settles for hiding a random one it ﬁnds and is unable to take
advantage of the light node sampling strategy. The second
type is a medium adversary. A medium adversary, using
more computational resources, can ﬁnd all stopping sets up
to a certain size and select the stopping set that performs the
worst under the posted light node sampling strategy. While
the medium adversary has more computational capability
than a weak adversary, a medium adversary represents a
malicious node with bounded resources and can only ﬁnd
stopping sets up to a certain size within a reasonable time
frame. The ﬁnal type is a strong adversary which we assume
has unlimited resources and can ﬁnd all stopping sets (of
any size) and hide one among them that performs the worst.
These three models represent how much resources we assume
an adversary possesses to disrupt our system. As such, our
modeling encompasses everything from a single hacker with
a standard computer to a small group of hackers with a
cluster of computers to a large organization with unlimited
resources.

A. Contributions

Our main contributions in this paper are co-design tech-
niques for LDPC codes and coupled light node sampling
strategies that result in a low probability of failure under
the different adversary models described above. In LDPC
codes with no degree-one VNs, all stopping sets are made
up of cycles [21]. Since working with stopping sets directly
is computationally difﬁcult, in this paper we design LDPC
codes by optimizing cycles to indirectly optimize stopping
sets. We show that our LDPC codes result in the desired
stopping set properties and produce low probability of failures
for the different adversary models. The contributions are listed
as follows:

1) For the weak adversary, we demonstrate that concen-
trating stopping sets in LDPC codes to a small set of VNs
and then greedily sampling this small set of VNs results
in a low probability of light node failure. We then provide
a specialized LDPC code construction technique called the
entropy-constrained Progressive Edge Growth (EC-PEG) al-
gorithm that is able to concentrate stopping sets in the LDPC
code to a small set of VNs. We provide a greedy sampling
strategy for the light nodes to sample this small set of VNs.
We demonstrate that for a weak adversary, LDPC codes
constructed using the EC-PEG algorithm along with the greedy
sampling strategy result in a signiﬁcantly lower probability of
failure compared to techniques used in earlier literature.

2) To secure the light nodes against a medium and a strong
adversary, we provide a co-design of a light node sampling
strategy called linear-programming-sampling (LP-sampling)
and an LDPC code construction called linear-programming-
constrained PEG (LC-PEG) algorithm. LP-sampling is tailor-
made for the particular LDPC codes used to construct each
layer of the CMT. It is designed by solving a linear program
(LP) based on the knowledge of the small stopping sets in
the LDPC codes to minimize the probability of failure. We
demonstrate that, for a medium and a strong adversary, LDPC
codes designed by the LC-PEG algorithm coupled with LP-
sampling result in a lower probability of failure compared to
techniques used in earlier literature.

B. Previous Work

In [1], authors proposed to solve DA attacks by encoding
the block using 2D-RS codes. Their approach was optimized
in [35]. However, 2D-RS codes results in an IC proof size of
O(√b log b). In [2], authors proposed the CMT and demon-
strated that encoding the CMT using LDPC codes results in a
small IC proof size of O(log b). Authors in [2] used codes from
a random LDPC ensemble of [16] to construct the CMT to
result in a low probability of failure. However, random LDPC
ensembles used in [2] were originally designed for other types
of channels (i.e., BSC) and we show that they are not the
best choice for this speciﬁc application at short CMT code
lengths. At the same time, as described before, random LDPC
ensembles undermine the security of the system, especially at
short CMT code lengths. In this work, we demonstrate that the
presented co-design techniques result in a lower probability
of failure compared to using codes from a random LDPC
ensemble and random sampling. Furthermore,
to alleviate
the security problem, we provide deterministic LDPC code
design algorithms in this paper. In [17], authors provide a
protocol called CoVer based on CMT, which allows light
nodes to collectively validate blocks. However, [17] still uses
random sampling and random LDPC ensembles to mitigate
DA attacks.

DA attacks are possible in other blockchain systems as well.
Sharded blockchains where each node stores a fraction of the
entire block are vulnerable to DA attacks that can be solved us-
ing the CMT [18]. The LDPC co-design techniques described
in this paper can also be used in sharded blockchains. Side
Blockchains [19] that improve the throughput of block trans-
actions are also vulnerable to DA attacks. The vulnerability
is mitigated in [19] by introducing a DA oracle that uses the
CMT. A similar idea as this paper of co-design to construct
specialized LDPC codes to improve the performance of the
DA oracle was demonstrated in [20].

While this paper focuses on designing codes to mitigate
DA attacks, channel coding has been extensively used to
mitigate other scalability issues in blockchain systems: [23]
uses network codes to reduce the storage cost associated with
full nodes; [24] combines downsampling and erasure coding to
reduce the storage cost while allowing nodes to directly use the
stored data without decoding; [25] proposes secure fountain
codes to reduce the storage and bootstrapping communication
cost of full nodes; [26] uses Lagrange coding in sharded
blockchains to simultaneously improve storage, computation,
and security; [27] proposes using erasure codes to allow light
nodes to contribute in storing the blockchain. The proposal in
[27] can be combined with techniques proposed in this paper
to enable light nodes to ensure data availability.

The rest of this paper is organized as follows. In Section
II, we provide the preliminaries and system model. In Section
III, we describe the greedy sampling strategy and the EC-
PEG algorithm and how they overcome DA attacks against
the weak adversary. In Section IV, we present our approach
for the medium and strong adversary where we describe the
LP-sampling strategy and the LC-PEG algorithm. We discuss
system aspects of our co-design in Section V. We provide

4

IEEE TRANSACTIONS ON COMMUNICATIONS

simulation results in Section VI and concluding remarks in
Section VII.

II. PRELIMINARIES AND SYSTEM MODEL
In this section, we ﬁrst look at the preliminaries of the CMT
and LDPC notation. We then present our system, network, and
threat model. We use the following notation in the rest of the
t
i=1 pi = 1,
paper. For p = (p1, . . . , pt) such that pi ≥
0,
t
i=1 pi log(pi). For
we use the entropy function
H
a vector a, let max(a) (min(a)) denote the largest (smallest)
entry of a and let ai denote the ith element of a. For a matrix
d, let Mki denote the element of M on the
M of size c
×
kth row and ith column, 1
d. Deﬁne
x mod p := (x)p.
A. Coded Merkle Tree (CMT)

(p) =

c, 1

P

P

≤

≤

≤

≤

−

k

i

1}. Detailed discussion on the properties of Merkle proofs6

j
can be found in [19].

−

3) Hash-Aware Peeling decoder: Using the CMT root and
the available symbols of each layer of the CMT, the original
block can be decoded using a hash-aware peeling decoder
described in [2]. The hash-aware peeling decoder decodes each
layer of the CMT (from top to bottom) like a conventional
peeling decoder [12]. However, after decoding a symbol in
layer j, the decoder matches its hash with the corresponding
hash present
1. Matching the hashes allows
the decoder to detect IC attacks and generate IC proofs as
described in [2]. The IC proof size is proportional to the degree
of CNs in the LDPC codes used to build the CMT.

in layer j

−

B. Stopping sets and LDPC notation

j

≤

≤

1) CMT construction: A CMT of a block is built using the
block transactions as leaf nodes and the CMT root is included
in the block header. It is constructed by encoding each layer of
the Merkle tree [4] with an LDPC code and then hashing the
layer to generate its parent layer. A simpliﬁed description of
the CMT construction is shown in Fig. 2 left panel. As shown
in Fig. 2 left panel, coded symbols of a layer are interleaved
into the data symbols of the parent layer4. In this paper, we
adopt the interleaving technique introduced in [19]. Let the
CMT have l layers (except the root), L1, L2, . . . , Ll, where
Ll is the base layer. The root of the CMT is referred to as
L0. For 1
l, let Lj have nj coded symbols and let the
≤
LDPC code used in Lj have a parity check matrix Hj. Let
i < nj, be the (i + 1)th symbol of the jth layer
Nj[i], 0
Lj
i < Rnj and Pj[i] = Nj[i],
i < nj, be the systematic (data) and parity symbols
Rnj ≤
i < nj are
of Lj, respectively. Coded symbols Pj[i], Rnj ≤
obtained from Dj[i], 0
i < Rnj using a rate R systematic
≤
LDPC code Hj. In the above CMT, hashes of every q coded
symbols of Lj are concatenated to form a data symbol of
Lj−1. Hence, nj =
(qR)l−j , j = 1, . . . , l. The CMT root
has t = n1 hashes. Let the number of systematic and parity
symbols in Lj be denoted by sj = Rnj and pj = (1
R)nj,
l, the data symbols of Lj−1 are
respectively. For 1
≤
formed from the coded symbols of Lj as follows:
Dj−1[i] = Nj−1[i] =concat(
0
|
≤
{
i < sj−1,
i = (x)sj−1 }

Hash(Nj[x])
0

5. Also, let Dj[i] = Nj[i], 0

where Hash and concat represent the hash and the string
concatenation functions, respectively.

x < nj,

≤

≤

−

≤

∀

nl

j

)

2) Merkle Proof for CMT symbols: The Merkle proof of a
symbol in Lj consists of a data symbol and a parity symbol
from each intermediate layer of the tree that is above Lj [19].
An illustration of a Merkle proof is shown in Fig. 2 left panel.
In particular, the Merkle proof of the symbol Nj[i], 1 < j
l,
is the set of symbols {Nj′ [ (i)sj′ ], Nj′ [ sj′ + (i)pj′ ]

≤
j′

1

|

≤

≤

4In this paper, we refer to chunks of a ﬁxed length as symbols of a ﬁeld. A
symbol of c bits is represented as an element in Fc
2 and encoding and decoding
are performed using bitwise XOR operations over the bitwise representation of
the symbols (similar to [25]). Thus, the complexity of encoding and decoding
depends on the size of the chunks (i.e., symbols) c which is calculated as
c = b
nR where b is the block size, and n and R are the length and rate of
the LDPC code in the CMT base layer.

5Due to modulo operations, we deﬁne Nj[i] starting with index 0 for i.

All other variables in the paper start with index 1.

{

. VN v(j)

Gj has nj VNs

A stopping set of an LDPC code is a set of VNs such
that every CN connected to this set is connected to it at least
twice [12]. A stopping set is hidden (made unavailable) by a
malicious node if all VNs present in it are hidden. The hash-
aware peeling decoder fails to successfully decode layer j of
the CMT if a stopping set of Hj is unavailable. Let the Tanner
graph (TG) [12] representation of Hj be denoted by
Gj such
1 , . . . , v(j)
v(j)
corresponds to
that
nj }
the ith column of Hj and CNs in
Gj correspond to the rows of
Hj. Let Hj[v(j)
] denote the column of the parity check matrix
i
corresponding to VN v(j)
. CMT symbol Nj[i], 0
i < nj,
i
corresponds to VN v(j)
Gj. A cycle of length g is called a
i+1 of
g-cycle. For a set
denote its cardinality. For a cycle
, let
, we say that a VN v touches the
(stopping set) in the TG
cycle (stopping set) iff v is part of the cycle (stopping set).
Deﬁne the weight of a stopping set as the number of VNs
touching it. Let ω(j)
min denote the minimum stopping set size
of Hj, 1
l. The girth of a TG is deﬁned as the length
of the smallest cycle present in the graph.

|S|
G

≤

≤

≤

S

j

i

C. System and Network Model

We consider a blockchain system similar to [1] and [2] that
has full nodes and light nodes. One of the full nodes acts
as a block producer of a new block. We consider the same
blockchain network model as [2]. In particular, we assume
a synchronous network where the subgraph of honest full
nodes is connected7 and the messages sent on the network
are anonymous. The network can have a dishonest majority
of full nodes, but each light node is connected to at least
one honest full node (thus preventing eclipse attacks [1]).
Nodes broadcast a message (fraud proofs, IC proofs, and CMT
symbols) by sending the message to all its connected nodes.
The connected nodes check the message correctness (Merkle
proofs) and forward valid messages to their neighbors8. In

6The data part of the Merkle proof of Nj[i] from each layer lie on the path
of Nj [i] to the CMT root and can be used to check the integrity of Nj [i]
in a manner similar to regular Merkle trees in [4]. The parity symbols in the
Merkle proof are only for sampling purposes and the information provided in
the Merkle proof of Nj[i] are sufﬁcient to check their integrity [19].

7The connected subgraph of honest full nodes ensures that a message

broadcasted by a honest node reaches all honest nodes.

8Since messages are communicated only to connected nodes, the cost of
broadcasting is not high. Moreover, honest nodes prevent fake communication
from malicious nodes by forwarding only valid messages.

SUBMITTED PAPER

5

Fig. 2: Left Panel: Construction process of a CMT. A block of size b is partitioned into k data chunks (data symbols) each of size b
k and
a rate R systematic LDPC code is applied to generate n coded symbols. These n coded symbols form the base layer of the CMT. The n
coded symbols are then hashed using a hashing function and the hashes of every q coded symbols are concatenated to get one data symbol
of the parent layer. The data symbols of this layer are again coded using a rate R systematic LDPC code and the coded symbols are further
hashed and concatenated to get the data symbols of its parent layer. This iterative process is continued until there are only t (t > 1) hashes
in a layer which form the CMT root. Left panel shows a CMT with n = 16, q = 4, R = 0.5 and t = 4. The circled symbols in L1 and L2
are the Merkle proof of the circled symbol in L3. Right panel: DA attack on the CMT.

the following, we describe actions performed by the block
producer, other full nodes, and light nodes. We also mention
the items included in the publicly available protocol that is
designed by a blockchain system designer to be used by nodes
in the system. In Section V, we provide a discussion on the
blockchain system designer.

1) Items included in the protocol: Parity check matrices Hj,
l, systematic generator matrix of each Hj, and the
1
light node sampling strategy (a rule to sample CMT symbols).

≤

≤

j

2) Block Producer: A full node that produces (mines) a
new block (see Fig. 1). On producing a new block, the block
producer encodes the block to construct its CMT using the
systematic generator matrices speciﬁed in the protocol. It
then broadcasts all the coded symbols in the CMT (including
the root) to other full nodes and the root of the CMT to
the light nodes. On receiving a sampling request from the
light nodes, it returns the requested symbols along with their
Merkle proofs. The block producer can be malicious and can
act arbitrarily.

j

≤

≤

they received,

3) Full nodes that are not

the block producer: These
nodes perform Merkle proof checks on the coded symbols
of the CMT that they receive from a block producer, other
full nodes, or light nodes (see Fig. 1). They forward symbols
that satisfy the Merkle proofs to other connected full nodes.
Using the symbols that
they decode each
layer of the CMT with a hash-aware peeling decoder using
l, speciﬁed in the
the parity check matrices Hj, 1
protocol. After decoding the base layer of the CMT, which
contains transaction data,
the transactions.
They store a local copy of all blocks (i.e., its CMT) that they
verify to be valid (i.e., fully available, having no fraudulent
transactions and no incorrect-coding at any layer). They
declare the availability of this valid block to all other nodes
and respond to sample requests from the light nodes. If they
ﬁnd a certain block to be invalid, either due to fraudulent
transactions or incorrect coding, they broadcast a fraud proof
or an IC proof for other nodes to reject the block. If they
ﬁnd a certain layer of the CMT to be unavailable (i.e., having
coded symbols missing that prevent decoding), they reject
the block. A malicious full node need not follow the above
protocol and can act arbitrarily.

they verify all

4) Light nodes: These nodes are storage constrained and
only store the CMT root corresponding to each block (see
Fig. 1). They download only a small portion of the block and
perform tasks like fraud and IC proof checks. Additionally,
light nodes check the availability of each layer of the CMT.
They do so by making sampling requests for coded symbols
of the CMT base layer from the block producer (or any other
full node that declares the block to be available). They make
sample requests using the sampling strategy speciﬁed in the
protocol. They perform Merkle proof checks on the returned
symbols and broadcast symbols that satisfy the Merkle proofs
to other connected full nodes. Upon receiving all the requested
symbols and verifying their Merkle proofs, light nodes accept
the block as available and store the block header. On receiving
fraud proofs or IC proofs sent out by a full node, light nodes
verify the proof and reject the header if the proof is correct.
We assume that each light node is honest.
Remark 1. In this paper, we provide co-design of LDPC codes
and sampling strategies (that are included in the protocol)
to reduce the probability of
failure. As such, we do not
compromise on other performance metrics considered in [2]:
the CMT root has a ﬁxed size t which does not grow with the
blocklength; the hash-aware peeling decoder has a decoding
complexity linear in the blocklength; we empirically show that
the IC proof size for our codes is similar to [2].

D. Threat Model

A blockchain system involves two aspects: block generation
and block veriﬁcation. The block generation depends on the
consensus algorithm used in the blockchain e.g., Proof of
Work (PoW) [4], Proof of Stake (PoS) [28], etc.. However,
a DA attack caused by an adversary with dishonest majority
(in terms of work, stake, etc.) affects the block veriﬁcation
process. Hence, the exact consensus algorithm used by the
blockchain is not relevant to our work. Similar to [1] and [2],
we focus on block veriﬁcation and propose LDPC codes to
mitigate DA attacks9.

9Note that forking-based double spending attacks (related to block genera-
tion) where an adversary generates an invalid longest chain are still possible
with a dishonest majority of full nodes [1] but are not necessary to launch a
DA attack.

6

IEEE TRANSACTIONS ON COMMUNICATIONS

Similar to [1] and [2], we model our system security in
terms of two properties: i) Soundness: If a light node thinks
that a block is available and accepts the block, then at least
one honest full node in the system will be able to fully
decode all layers of the CMT corresponding to the block;
ii) Agreement: If a light node determines that a block is
available, all light nodes in the system determine that the
block is available. Similar to [1], we analyse probability of
soundness or agreement failure per light client. Let P S,A
be
the probability that soundness or agreement fails for a single
light client due to a DA attack. In Section V, we show that
in our proposed co-design, P S,A
is reduced by reducing the
f
probability of failure of a single light node to detect DA attacks
when there is a sufﬁciently large number of light nodes in the
system. Thus, in the rest of the paper, we focus on reducing
the probability of failure of a single light node.

f

We consider an adversary that conducts a DA attack by
hiding coded symbols of the CMT. An illustration of a DA
attack is shown in Fig. 2 right panel. On receiving sampling
requests from the light nodes, the adversary only returns coded
symbols that it has not hidden and ignores other requests. The
adversary conducts a DA attack at layer j of the CMT by 1)
generating coded symbols of layer j, that satisfy their Merkle
proof, for the light nodes to accept these coded symbols as
valid, and 2) hiding a small portion of the coded symbols of
layer j, corresponding to a stopping set of Hj, such that honest
full nodes are not able to decode the layer. A DA attack at
layer j prevents an honest full node from generating a fraud
proof of fraudulent transactions (if j = l) or an IC proof
for incorrect coding at layer j. Since an incorrect coding can
occur at any layer, for the full nodes to be able to send IC
proofs, light nodes must detect a DA attack at any layer j that
the adversary may perform. They do so by sampling few base
layer coded symbols. For each intermediate layer j, 1
j < l,
the symbols of layer j collected as part of the Merkle proofs
of the base layer samples are used to check the availability of
layer j.

≤

f

j

≤

≤

(s), 1

Light nodes fail to detect a DA attack if none of the base
samples requested or the symbols in their Merkle proofs are
hidden. Let P (j)
l, be the probability of failure
of detecting a DA attack at layer j by a single light node
when it samples s base layer coded symbols. Also, let J max =
(s). To maximize the probability of failure, we
argmax
1≤j≤l
assume that the adversary is able to perform a DA attack at
layer J max. We now provide precise mathematical deﬁnitions
of the three adversary models discussed in Section I based on
their computational capabilities:

P (j)
f

j

≤

1) Weak Adversary: For each layer j, 1

l, they
hide stopping sets of size < µj for the parity check matrix
Hj (for some integer µj). Moreover, they do not exhaustively
ﬁnd all stopping sets of a particular size of a given parity
check matrix or perform a tailored search for stopping sets.
Instead, we assume that to conduct a DA attack at layer j,
for all stopping sets of Hj of a particular size, they randomly
choose one of them to hide.

≤

2) Medium Adversary: For each layer j, 1

l, they
hide stopping sets of size < µj for the parity check matrix

≤

≤

j

f

Hj. However, they use the knowledge of the sampling strategy
employed by the light nodes to hide the worst case stopping
set that has the lowest probability of being sampled by the
light nodes. Let Ψj be set of all stopping sets of Hj of size
< µj. Also, let P (j)
(s; ψ)
is the probability of failure for the light nodes to detect a DA
attack at layer j under the light node sampling strategy when
the adversary hides the stopping set ψ of Hj. For J max =
(s), the medium adversary conducts a DA attack
argmax
1≤j≤l
at layer J max by hiding a stopping set ψ from ΨJ max with the
highest P J max

(s; ψ), where P (j)

(s) = max
ψ∈Ψj

P (j)
f

P (j)
f

(s; ψ).

f

f

f

3) Strong Adversary: They can ﬁnd the worst case stopping
sets of any size of Hj, 1
j
j be the set of all
≤
stopping sets of Hj. Similar to the medium adversary, deﬁne
P (j)
(s). The
f

(s; ψ) and J max = argmax
1≤j≤l

(s) = max
ψ∈Ψ∞
j

l. Let Ψ∞

strong adversary conducts a DA attack at layer J max by hiding
a stopping set ψ from Ψ∞

J max with the highest P J max

(s; ψ).

P (j)
f

P (j)
f

≤

The co-design that we provide to mitigate DA attacks
against weak adversaries, i.e.,
the EC-PEG algorithm and
the greedy sampling strategy, has the advantage of being
computationally cheap and does not involve ﬁnding stopping
sets. In order to mitigate DA attacks against a medium and
a strong adversary we provide LP-sampling and the LC-PEG
algorithm. LP-sampling uses stopping sets of size < µj from
layer j of the CMT and is more computationally expensive. It
is an overkill for the weak adversary which can be mitigated
using cheaper techniques. Factors such as the choice of the
consensus algorithm, area of deployment, etc. can give an idea
about the expected computational capabilities of full nodes
in the system and allow the system designer to choose the
adversary model. For example, in PoS [28] and PoSpace [29]
consensus blockchains, full nodes need not have a high com-
putational power and a weak adversary would be a reasonable
model to follow. For PoW blockchains [4], full nodes are
expected to have high computational power and a strong and
medium adversary model would be a suitable design choice.
Another example is small scale IoT-blockchains where the
blockchain nodes are IoT devices [6]. Here, full nodes have
low computational power and a weak adversary model would
be appropriate.

j

≤

≤

In our co-design to mitigate a DA attack against a medium
and a strong adversary, we assume that a blockchain system
designer decides the value of µj, 1
l, and is able
to ﬁnd all stopping sets of Hj of size < µj, that is used
to design LP-sampling. Although ﬁnding all stopping sets of
Hj of size < µj is NP-hard, since we focus on short code
lengths in this paper, the set of stopping sets can be found in a
reasonable amount of time using Integer Linear Programming
(ILP) methods demonstrated in [30]. Note that µj and the set
of all stopping sets of Hj of size < µj that the designer uses
to design LP-sampling is not publicly released. Only the ﬁnal
design output, i.e., the LP-sampling strategy is included in the
protocol. Here, we have made a trusted set up assumption of
a blockchain system designer to design the items included in
the protocol. In Section V, we will discuss potential ways to
prevent security attacks by a malicious designer and how some

SUBMITTED PAPER

7

attacks are naturally handled by our co-design method.

Given the above adversary models, we provide LDPC code
construction and sampling strategies to minimize the proba-
bility of failure for a single light node to detect DA attacks.
In the next section, we discuss the techniques to mitigate DA
attacks conducted by a weak adversary.

III. LDPC CODE AND SAMPLING CO-DESIGN FOR WEAK
ADVERSARY

G

V

1 , ζg

and TG

1 , ssκ

2 , . . . , ζg

In this section, we demonstrate our novel design idea of
concentrating stopping sets in LDPC codes to reduce the
probability of failure against a weak adversary. Since work-
ing with stopping sets directly is computationally difﬁcult,
we focus on concentrating cycles to indirectly concentrate
stopping sets. It is well known that codes with irregular VN
degree distributions are prone to small stopping sets. Thus, we
consider VN degree regular LDPC codes of VN degree dv ≥
3
in this paper. In the following, we ﬁrst look at the effect of
the light node sampling strategy on the probability of failure
when a DA attack occurs on the base layer of the CMT. This
will motivate the LDPC code construction for the base layer.
Later, we demonstrate how the LDPC code construction for
the base layer can be used in all layers by aligning the columns
of the parity check matrices before constructing the CMT. For
simplicity of notation, we denote Hl by H having n VNs
=
v1, v2, . . . , vn}
. Consider the following deﬁnition.
{
let ssκ =
Deﬁnition 1. For a parity check matrix H,
(ssκ
2 , . . . , ssκ
n) denote the VN-to-stopping-set of weight
κ distribution where ssκ
is the fraction of stopping sets of H
i
of weight κ touched by vi. Similarly, for a parity check matrix
H, let ζg = (ζg
n) be the VN-to-g-cycle distribution
where ζg
i

is the fraction of g-cycles of H touched by vi.
We informally say that distribution ssκ (ζg) is concentrated
if a small set of VNs have high corresponding stopping set (g-
cycle) fractions ssκ
i ). The following lemma demonstrates
that LDPC codes with concentrated ssκ results in a smaller
probability of light node failure when a weak adversary
conducts a DA attack (on the base layer). The proof is
straightforward and we omit it due to space limitations. It can
be found in [3] and references therein.
Lemma 1. Let
SS κ denote the set of all weight κ stopping sets
of H. For a weak adversary that randomly hides a stopping set
SS κ, the probability of failure at the base layer, P (l)
from
f (s),
when the light nodes use s samples and any sampling strategy
satisﬁes P (l)
, κ) is
maxS⊆V,|S|=s τ (
the fraction of stopping sets of weight κ touched by the subset
of VNs
of H. The lower bound in the above equation is
achieved when light nodes sample, with probability one, the
set

opt
κ = argmaxS⊆V,|S|=sτ (
S
S
Lemma 1 suggests that for a sample size s, the lowest
opt
κ , κ) and is achieved when
probability of failure is 1
S
−
opt
opt
κ , κ) is large if
κ . Now, τ (
the light nodes sample the set
S
a majority of stopping sets of weight κ are touched by a small
subset of VNs. This goal is achieved if the distributions ssκ
are concentrated towards a small set of VNs. Thus, designing
LDPC codes with concentrated ssκ increases τ (
opt
κ , κ) and
S
reduces the probability of failure. In Section III-B, we design

, κ). Here, τ (

i (ζg

f (s)

, κ).

τ (

≥

−

S

S

S

S

1

the EC-PEG algorithm that achieves concentrated stopping set
distributions.

G

−

f (s) = 1

We are unaware of an efﬁcient method to ﬁnd

opt
κ . Instead,
S
we use a greedy algorithm using cycles to ﬁnd the light node
samples, provided in Algorithm 1. Algorithm 1 takes as input
, its girth gmin, an upper bound cycle length gmax,
the TG
and the sample size s. It outputs a set of VNs S(s)
greedy that
the light nodes will sample, which we call greedy samples.
The probability of failure using this strategy when a weak
adversary randomly hides a stopping set of size κ from the
τ (S(s)
base layer is P (l)
greedy, κ) (see proof of Lemma
1 in [3]). At the end of this section, we empirically show that
concentrating the cycle distributions ζg also concentrates the
stopping set distributions. Thus, the EC-PEG algorithm aims to
concentrate the cycle distributions to improve the probability
of failure. It is easy to see that the complexity of Algorithm
1 is dominated by the complexity of ﬁnding cycles (of worst
case length gmax) and is O(ngmax/2) using brute force.
Remark 2. (Overall Greedy Sampling Strategy) In the above
sampling strategy, some coded symbols may never get sampled
which can affect
the system. We allevi-
ate this problem without affecting the probability of failure
by modifying the sampling strategy as follows: Let ρ be
a ﬁxed parameter where 0 < ρ < 1. For a total of s
samples, the light nodes select ρs greedy samples S(ρs)
greedy =
greedy-set(
, gmin, gmax, ρs) and randomly select s
ρs
base layer coded symbols for the remaining samples. We dis-
cuss the soundness and agreement of this modiﬁed strategy in
Section V. For this strategy, P (l)
ω(l)
min
nl

the soundness of

f (s) = [1

greedy, κ)]

τ (S(ρs)

1
(cid:0)

−

−

−

G

(s−ρs).
(cid:1)

A. Aligning the parity check matrices of the CMT

In the above discussion, we demonstrated how to mitigate
a DA attack conducted by a weak adversary on the base layer
of the CMT using greedy sampling. Now, we extrapolate the
idea of greedy sampling to the intermediate layers. Since the
intermediate layers are sampled via the Merkle proofs of the
base layers samples, we align the base and intermediate layer
symbols such that the intermediate layers are also sampled
greedily. We do so by aligning (permuting) the columns of
the parity check matrices used in different CMT layers. We
align the columns such that the samples of an intermediate
layer j collected from the Merkle proofs of the base layer
samples coincide with the greedy samples for layer j provided
Gj, g(j)
by greedy-set(
min is the girth of
Gj and g(j)
max is the upper cycle length for layer j.
the output S(s)
greedy of Algorithm 1 is
ordered according to the order VNs were added to S(s)
greedy.
Let S(j)
Gj , g(j)
l.
j
VNs in S(j)
ordered are all the VNs of Hj ordered (permuted)
according to the order they were added to S(j)
ordered. Hence,
we denote S(j)
ordered[i] as the ith VN in this ordered list
of VNs. The procedure to align the columns of the parity
check matrices of different layers of the CMT is provided in
Algorithm 2. In the algorithm, we ﬁrst permute the columns of
Hl) such the
the base layer parity check matrix Hl (to obtain

ordered = greedy-set(

max, ˜s). Here, g(j)

We assume that

min, g(j)

min, g(j)

max, nj), 1

≤

≤

e

8

IEEE TRANSACTIONS ON COMMUNICATIONS

Algorithm 1 Light node sampling strategy for weak adversary: greedy-set(

, gmin, gmax, s)

|

3:

4:

greedy, Initialize: S(s)

< s do

, gmin, gmax, s, Output: S(s)

1: Inputs: TG
G
S(s)
2: while
greedy|
v = VN that touches the maximum number of g-cycles in
S(s)
greedy = S(s)
if
G
if g
gmax then
b
Vr = randomly select s

has no g-cycles then g = g + 2

S(s)
greedy|

greedy ∪ {

VNs from

− |

G
b

≥

}

6:

7:

5:

v

, Purge v and all its incident edges from

greedy =

∅

G
b

G
, g = gmin,

=

G

G
b

(ties broken randomly)

(ordered arbitrarily); S(s)

greedy = S(s)

greedy ∪ Vr

G
b

{

e

−

1+(i

1)sj, 1+sj +(i

e
1)pj }

ordered appear as columns 1, 2, . . . , nl in

the VNs in S(l)
Hl (line
3). Recall that when the base layer symbol corresponding to
v(l)
is sampled, then for every intermediate layer j, the VNs
i
get
with with subscript indices
−
Hj at these indices (starting
sampled. We assign columns of
from i = 1) the columns of Hj correspond to the greedy
samples in S(j)
ordered from start to end (lines 4-6). We continue
Hj have been assigned. The
this process until all columns of
complexity of Algorithm 2 is dominated by the complexity of
e
ﬁnding S(j)
ordered using Algorithm 1 and has a complexity of
j=1 ng(j)
l
O(
Remark 3. The parity check matrices
l, after
the alignment are included in the protocol. Recall that a CMT
is built using systematic LDPC codes. Under the assumption
l,
of full rank, for the parity check matrices
the corresponding generator matrices are constructed in a
systematic form which are then included in the protocol
for CMT construction. Also, after the alignment, the overall
greedy sampling strategy as described in Remark 2 becomes:
sample the ﬁrst ρs coded symbols of the base layer of the CMT
and then randomly sample s
ρs base layer coded symbols.
This sampling rule is included in the protocol.

Hj, 1

Hj, 1

max/2

P

≤

−

≤

≤

≤

).

e

e

j

j

j

j

≤

≤

For a CMT built using

l, provided by
Hj, 1
Algorithm 2, greedy sampling of the base layer of the CMT
e
according to Algorithm 1 ensures that all intermediate layers
of the CMT are greedily sampled according to Algorithm 1
through the Merkle proofs of the base layer samples. Next,
we provide a design strategy to construct LDPC codes with
concentrated stopping set distributions that result in a low
probability of failure under greedy sampling. Note that codes
produced in the next subsection are aligned by Algorithm 2
and then included in the protocol.

B. Entropy-Constrained PEG (EC-PEG) Algorithm

The EC-PEG algorithm is based on minimizing the entropy
of cycle distribution ζg. The intuition behind our algorithm
is using the fact that uniform distributions have high entropy
and distributions that are concentrated have low entropy. Thus,
we construct LDPC codes using the PEG algorithm [15] by
making CN selections that minimize the entropy of the cycle
distributions. Algorithm 3 presents the EC-PEG algorithm for
with n VNs, m CNs, and VN degree dv
constructing a TG
that concentrates distributions ζg
g′ < gc. Choice of gc is
∀
a complexity constraint of how many cycles we keep track in
the algorithm. All ties in the algorithm are broken randomly.

G
e

,

′

The PEG algorithm builds a TG by iterating over the set of
VNs and for each VN vj in the TG, establishing dv edges to
it. For establishing the kth edge to VN vj, the PEG algorithm
encounters two situations: i) addition of the edge is possible
without creating cycles; ii) addition of the edge creates cycles.
In both situations, the PEG algorithm ﬁnds a set of candidate
CNs that it proposes to connect to vj, to maximize the girth.
We abstract out the steps followed in [15] to ﬁnd the set
of candidate CNs by a procedure PEG(
, vj). The procedure
G
returns the set of candidate CNs
for establishing a new
e
K
edge to VN vj under the TG setting
according to the PEG
algorithm in [15]. For ii), the procedure returns the cycle
length g of the smallest cycles formed when an edge is added
and vj. For i), it returns g =
between any CN in
is
K
that create new g-cycles when an edge
the set of all CNs in
G
is added between the CN and vj. When g =
is the set
e
of all CNs in

that if connected to vj create no cycles.
, vj) procedure returns g

gc, either
no new cycles are created or the cycles created have length
gc. In both these situations, similar to the original PEG algo-
≥
with the minimum degree
rithm in [15], we select a CN from
, vj)
under the current TG setting
G
returns g < gc, we modify the CN selection procedure so that
e
the resultant cycle distributions get concentrated. We explain
the modiﬁed CN selection procedure next.

K
(line 7). When PEG(

Thus, when the PEG(

.
∞

,
∞

G
e

G
e

G
e

G
e

≥

K

K

′

′

′

′

′

i

)

)

)

i

≤

, Λ(g
2

, . . . , Λ(g

) = (Λ(g
1

n ), where Λ(g
i

While progressing through the EC-PEG algorithm, for
all g′-cycles, g′ < gc, we maintain VN-to-g′-cycle counts
)
Λ(g
is the number
of g′-cycles that are touched by VN vi. When the PEG(
, vj)
G
procedure returns g < gc, for each candidate CN c
, new
e
∈ K
g-cycles are formed in the TG when an edge is established
between c and vj. These cycles are listed in
Lcycles (line 11).
For these new g-cycles, we calculate the resultant VN-to-g-
cycle counts λ(g,c)
n, if an edge is established
, 1
between c and vj (line 12). Using λ(g,c)
, we calculate the
′
VN-to-g′-cycle normalized counts αg
2 , . . . , αg
n )
(line 13) and then the joint normalized cycle counts αgc
for g′-cycles, g′ < gc (line 14). The joint normalized cycle
counts αgc is simply the average of the normalized cycle
counts across all the cycle lengths. Using αgc , we calculate
(αgc ) for each CN c in
(line 14). Our
the entropy
modiﬁed CN selection procedure is to select a CN from
K
with minimum Entropy[] (line 15). We then update the VN-
to-g-cycle counts for the new g-cycles that get created (line
15) to be used in future iterations. Minimizing the entropy
of the joint normalized cycle counts ensures that the different

= (αg

1 , αg

H

≤

K

i

′

′

′

SUBMITTED PAPER

9

ordered, 1

Algorithm 2 Aligning parity check matrices of CMT for greedy sampling
1: Inputs: Hj, S(j)
2: Initialize:
Hl[i] = Hl[S(l)
3:
4: for j = 1, 2, . . . , l
5:

Hj, 1
≤
Hj: matrix with unassigned columns, 1

1 do for i = 1, 2, . . . , nl do d = 1 + (i

l
l, counter = 1

ordered[i]], 1

l, Outputs:

≤
≤

≤
≤

j
j

nl

−

≤

≤

≤

e

e

e

j

i

if

Hj[d] is not assigned before then
Hj[p] is not assigned before then
e

Hj[d] = Hj[S(j)
Hj[p] = Hj[S(j)
e

1)sj , p = 1 + sj + (i

−

−
ordered[counter]], counter += 1
ordered[counter]], counter += 1

1)pj

Hj have been assigned then Break i for loop

e

6:

7:

if
if all columns of

e

Algorithm 3 EC-PEG Algorithm

e

, gmin, Initialize

to n VNs, m CNs and no edges

i

≤

≤

G
n, T =
e

4, 6, . . . , gc −

|{

2

}|

i = 0, for all g′ < gc and 1

′

1: Inputs: n, m , dv, gc, Outputs:
2: Initialize Λ(g
)
3: for j = 1 to n do
4:
5:

for k = 1 to dv do
, g] = PEG(
G
gc then
e
csel = Select a CN from

[
K
if g

, vj )

≥

G
e

K

else

with the minimum degree under the current TG setting

⊲ (g-cycles, g < gc, are created)

G
e

6:
7:

8:

9:
10:

11:

12:

13:

14:

15:

16:

for each c in
,c)

′

′

do
)
, g′ < gc, 1

i

K
= Λ(g
i

λ(g
n
i
≤
≤
Lcycles = new g-cycles formed in
G
do λ(g,c)
= λ(g,c)
for all v in
+
v
v
|{O ∈ Lcycles |
e
G
′
′
, . . . , α(g
)
n ), where α(g
)
, α(g
)
) = (α(g
e
2
1
α(g
T ,
1

α(g
T , . . . ,
2

g′<gc

g′<gc

α(g

)

)

)

′

′

′

′

′

i = λ(g

n

i

with minimum Entropy[c]; Λg

P

P

v is part of

′

,c)

O}|

′

i

)

i=1 λ(g′ ,c)
α(g
T ); Entropy[c] =
P
n
g′<gc
i = λ(g,csel)
n

, 1

i

i

≤

≤

, g′ < gc (deﬁne 0

0 = 0)

(αgc)

H

due to the addition of edge between c and vj

αgc = (
P
csel = CN in
=

edge
{

G
e

G ∪
e

K
csel, vj}

cycle distributions are concentrated towards the same set of
VNs.

IV. LDPC CODE AND SAMPLING CO-DESIGN FOR MEDIUM
AND STRONG ADVERSARY

We now mention the complexity of the EC-PEG algorithm.
Note that the complexity of the original PEG algorithm is
O(mn) [15]. The EC-PEG algorithm differs from the original
PEG algorithm in steps 8-15. Step 14 has the largest complex-
ity which results in the complexity of the EC-PEG algorithm
to be at most O(mn2) = O(n3). Note that
Lcycles in step 11
is obtained during step 5 as a by-product and does not incur
additional complexity.

Fig. 3 demonstrates the effectiveness of the EC-PEG algo-
rithm in concentrating the stopping set distribution. In Fig.
3 left panel, we plot the cycle distributions generated by the
PEG and EC-PEG algorithms. From the ﬁgure, we see that
the EC-PEG algorithm generates signiﬁcantly concentrated
distributions ζ6 and ζ8 compared to the original PEG algo-
rithm. Fig. 3 middle and right panels show the corresponding
stopping set distributions ssκ. We see that for the EC-PEG
algorithm, the VNs towards the left (right) on the x-axis
have high (low) stopping set fraction. Thus, concentrating the
cycle distributions concentrates the stopping set distributions
towards the same set of VNs as the cycles. In Section VI,
we demonstrate that such concentrated distributions result in
a low probability of failure using the greedy sampling strategy
in Algorithm 1.

For the medium and strong adversary, the EC-PEG al-
gorithm and greedy sampling is insufﬁcient to secure the
system and requires stronger code and sampling design. In this
section, we focus on overcoming these stronger adversaries
that hide the worst case stopping set. Similar to Section III,
we ﬁrst look at a medium and a strong adversary who conduct
a DA attack on the base layer of the CMT and propose a
sampling strategy for the light nodes to sample the base layer
to minimize the probability of failure. This will motivate the
construction of LDPC codes for the base layer. Finally, we
will generalize the sampling strategy and LDPC construction
for the situation when the adversary conducts a DA attack at
any layer of the CMT.

j

{

≤

≤

Recall that for each layer j, 1

2 , . . . , ψ(j)
|Ψj|}
j
≤
≤

l, the medium
adversary hides stopping sets of Hj of size < µj. Let
1 , ψ(j)
ψ(j)
be the set of all stopping sets
Ψj =
l. For Ψj, let Π(j) denote the
of Hj of size < µj, 1
VN-to-stopping-set adjacency matrix of size
nj, where
Ψj| ×
|
k , else Π(j)
touches stopping set ψ(j)
ki = 1 iff v(j)
Π(j)
ki = 0,
k
n, 1
1
≤
Deﬁnition 2. A sampling (with replacement)
strategy
xnl]T , where xi is
x , β(l)
1 vector x = [x1 · · ·
the probability that a light node requests for the ith base layer
(cid:0)

is a nl ×

Ψj|

≤ |

≤

≤

(cid:1)

i

.

i

10

0.05

0.04

g
ζ

0.03

0.02

IEEE TRANSACTIONS ON COMMUNICATIONS

0.25

0.2

0.15

0.1

0.05

3
1
s
s

Original PEG
EC-PEG

0.25

0.2

0.15

0.1

0.05

4
1
s
s

Original PEG
EC-PEG

0.01

0

20

40

60
80
VN index

100

120

0

0

20

40

60
80
VN index

100

120

0

0

20

40

60
80
VN index

100

120

Fig. 3: Results for LDPC codes with R = 0.5, dv = 4, n = 128 using different PEG algorithms. The x-axis in all the plots are the VN
indices vi in the decreasing order of the 6-cycle fractions ζ 6
i (for the respective codes); Left panel: cycle distributions ζ 6 and ζ 8; Middle
Panel: stopping set distribution ss13; Right Panel: stopping set distribution ss14. The lines in the middle and right panels are the best ﬁt
lines for ssκ indicating the graph slope.

i

β(l)

satisfy 0

symbol (i.e., v(l)
) for every sample request and β(l) controls
the minimum probability of requesting a given CMT base layer
symbol.

x , β(l)
(cid:1)
(cid:0)
(f,med)(s) (P (l)
Let P (l)

xi ≤
(f,str)(s)) be the probability of failure
against a medium (strong) adversary for a DA attack on the
base layer of the CMT. (Deﬁne similarly P (j)
(f,med)(s) and
P (j)
(f,str)(s) for DA attack on layer j). We have the following
lemma (all proofs are deferred to the Appendix).

n
i=1 xi = 1.

P

1,

≤

≤

max

. Deﬁne P (l)

Lemma 2. For a sampling strategy
s

Π(l)x)
max(1
−
(cid:2)
(cid:3)
Then, P (l)
(f,str)(s)
≤

, P (l)
x , β(l)
(f,med)(s) =
s
(cid:0)
(cid:1)
β(l)µl
.
(f,str-bnd)(s) :=
1
−
(cid:0)
(f,med)(s), P (l)
P (l)
.
(f,str-bnd)(s)
(cid:17)
(cid:16)
In the rest of the paper, we assume that P (l)
(f,str)(s) is equal
to the upper bound provided in Lemma 2. We ﬁnd the light
node sampling strategy by formulating a linear program (LP)
in
to minimize the probabilities in Lemma 2. The
optimization problem (which can be easily converted into an
LP by introducing additional variables) is provided below:

x , β(l)
(cid:0)

(cid:1)

(cid:1)

minimize
x , β(l)

max

max(1

(cid:16)

Π(l)x), θ

−

β(l)µl

1
× h

−

(1)

i(cid:17)
nl

subject to β(l)

≤

1, i = 1, . . . , nl; β(l)

xi ≤
1, is a parameter that controls the trade-off

Xi=1

xi = 1,

0;

≥

where θ, 0
≤
(f,med)(s) and P (l)
between P (l)

≤

θ

(f,str)(s).

A. Linear-programming-sampling (LP-sampling) for DA at-
tacks on any layer of the CMT

In this subsection, we modify LP (1) to take into effect a
DA attack conducted on any layer of the CMT and derive the
sampling strategy based on the modiﬁed LP. We ﬁrst align the
columns of the parity check matrices of all the CMT layers as
described in Section III-A. Assume that the stopping sets and
VNs in the following are based on the aligned parity check
matrices.

Since a base layer symbol samples, via its Merkle proof, two
symbols from every intermediate layer of the CMT, the events
of sampling intermediate layer symbols are not disjoint. To
calculate the probability that each intermediate layer symbol
1, a matrix A(j)
is sampled, we deﬁne for each j, 1
sj
of size nj ×

nl whose entries are as follows: 1) if (k

≤

−

≤

≤

j

l

−

1)sj = k) then A(j)

ki = 1; 3) A(j)

−
1)pj = k) then A(j)

ki = 1; 2) if (k > sj and
and 1 + (i
1+sj +(i
ki = 0 for all other
cases. For simplicity, assume that A(l) is an nl ×
nl identity
l, the matrices ∆(j) =
matrix. Also, deﬁne for 1
≤
min(Π(j)A(j), 1) where the minimum is element wise. Using
the above matrices, we calculate P (j)
(f,str)(s)
in Lemma 3. First, consider the following deﬁnition.

≤
(f,med)(s) and P (j)

j

is a sampling strategy

Deﬁnition 3. A sampling (with replacement)
strategy
x , β(l)
x , β(1) , β(2) , . . . , β(l)
,
1, x(j)
such that for x(j) = A(j)x, 1
(cid:1)
(cid:0)
(cid:0)
’s satisfy
i
−
x(j)
1. Parameter β(j),
i ≥
≤
l, is a non-negative real number and controls the
j
1
≤
minimum probability of requesting a given symbol from layer
j of the CMT.

(cid:1)
nj, 1

β(j), 1

≤
j

≤
l

≤

−

≤

≤

≤

j

i

l

j

x , β(1) , . . . , β(l)
, let
is the probability that v(j)
(cid:1)
(cid:0)
k
. Also, for
max(1

Lemma 3. For a sampling strategy
l. x(j)
x(j) = A(j)x, 1
k
≤
≤
is sampled and P (j)
(f,med)(s) =
1
≤
P (j)
(f,str)(s)
Using Lemmas 2 and 3, we formulate the following LP to

−
(f,str-bnd)(s) :=
1
−
(f,str-bnd)(s), P (j)
(cid:0)
(f,med)(s)).

j < l, let P (j)
max(P (j)

∆(j)x)
(cid:3)
1
2 β(j)µj

. Then,

≤

(cid:1)

(cid:2)

s

s

ﬁnd the light node sampling strategy:

minimize
x, β(1), . . . , β(l)

max

max
1≤j≤l

(cid:18)

max(1

−

∆(j)x),

max
1≤j≤l

θ(j)

1
× h

−

ξ(j)β(j)µj

i(cid:17)

nl

(2a)

(2b)

subject to

β(l)

xi ≤

≤

1, i = 1, . . . , nl,

xi = 1,

Xi=1

β(j)

≤

min(A(j)x), j = 1, . . . , l

1,

−

(2c)

(2d)

≥
≤

β(j)
2 for 1

0, j = 1, . . . , l,
(2e)
where ξ(j) = 1
j < l and ξ(l) = 1. The ﬁrst and
second term in the outer maximum above corresponds to the
probability of failure against the medium and strong adversary
for a DA attack on different layers of the CMT. θ(j)’s are
trade-off parameters and control the importance given to a
strong adversary on layer j of the CMT compared to a medium
adversary.

SUBMITTED PAPER

11

(cid:1)

The sampling strategy

x , β(1), . . . , β(l)
(cid:0)

obtained as the
optimal solution of LP (2) is called LP-sampling and is
included in the protocol. To reduce the probability of fail-
ure against a medium and a strong adversary under LP-
sampling, we design LDPC codes aimed towards minimizing
the probability for each layer. The complexity of LP-sampling
is determined by the complexity of ﬁnding all stopping sets of
Hj of size < µj. Although stopping set enumeration is NP-
hard, they can be found in a reasonable time for small code
lengths using an ILP [30]. However, it is difﬁcult to obtain an
analytical complexity expression for stopping set enumeration
using ILP.
B. Linear-programming-Constrained PEG (LC-PEG) Algo-
rithm

In this section, we design LDPC codes that perform well
under LP-sampling. We design such codes by modifying
the CN selection procedure in the PEG algorithm. We call
our construction linear-programming-constrained PEG or LC-
PEG algorithm since it is trying to minimize the optimal
objective value of an LP. Codes designed in this section are
aligned by Algorithm 2 and then included in the protocol.
Similar to the EC-PEG algorithm, we optimize cycles instead
of stopping sets. The motivation for focusing on cycles is
the following: for lists
and Ψ of cycles and stopping sets,
respectively, such that for every ψ
O ∈ C
which is part of ψ, we have maxψ∈Ψ
(cid:17) ≤
−
. Thus, the optimal objective value
maxO∈C
of LP (1) can be upper bounded by the optimal objective value
(cid:1)
of a modiﬁed version of LP (1) which is based on cycles. We
select CNs in the PEG algorithm depending on the optimal
objective value they produce on the modiﬁed LP. Algorithm
4 presents our LC-PEG algorithm for constructing a TG
G
with n VNs, m CNs, and VN degree dv. All ties are broken
e
randomly.

Ψ, there exists a

vi:vi∈O xi

vi:vi∈ψ xi

1
(cid:0)

P

P

−

∈

(cid:16)

C

1

In the LC-PEG algorithm, we use the concept of the
extrinsic message degree (EMD) of a set of VNs that allows
us to rank the harm a cycle may have in creating stopping sets.
EMD of a set of VNs is the number of CN neighbors singly
connected to the set [21] and is calculated using the method in
[22]. EMD of a cycle is the EMD of the VNs involved in the
cycle. Low EMD cycles are more likely to form stopping sets
and we term cycles with EMD below a threshold Tth as bad
cycles. We use bad cycles to form the modiﬁed linear program
below:

max

min
ˆx, ˆβ

(cid:16)

max(1

−

Cˆx), ˆθ[1

ˆβ ˆµ]

−

s.t. ˆβ

ˆxi ≤

≤

1, i = 1, . . . , ˆn; ˆβ

0;

≥

(cid:17)

ˆn

Xi=1

(3)

ˆxi = 1.

The LC-PEG algorithm uses LP (3) via the procedure
) which outputs its optimal objective

LP-objective(
,
L
value. The procedure has inputs of a list
b
have ˆn VNs
of cycles and a TG
is a matrix of size
else Cki = 0, 1
a parameter.

L
ˆv1, . . . , ˆvˆn}
b
{
G
ˆn, such that Cki = 1 if ˆvi touches
b
ˆn, 1

O|
L|}
. Here, C
b
Ok,
1, is

G
b
L|×
|
i
b
≤

{O1, . . . ,

. Also, ˆθ, 0

G
b
. Let

≤ |

=

≤

≤

≤

≤

ˆθ

k

In the LC-PEG algorithm, we use the procedure PEG()
deﬁned in Section III-B for the EC- PEG algorithm. The LC-

L|
b

PEG algorithm proceeds exactly as the EC-PEG algorithm
when the PEG() procedure returns cycle length g
gc. When
the PEG() procedure returns cycle length g < gc, we select a
CN from the set of candidate CNs
such that the resultant
LDPC codes have a low optimal objective value of LP (1).
We explain the CN selection procedure next.

≥

K

L

L

L

G
e

of cycles.

c
cycles,
L∪L

(line 5). Of the CNs in

Kmincycles, we ﬁnd the list

While progressing through the LC-PEG algorithm, we main-
contains cycles of length g < gc that
tain a list
had EMD less than or equal to threshold Tth when they were
are considered bad cycles and we base
formed. Cycles in
our CN selection procedure on these cycles. When the PEG()
, we ﬁrst select the set of
procedure returns candidate CNs
K
Kmindeg that have the minimum degree under the current
CNs
TG setting
Kmindeg, we select the set
Kmincycles that form the minimum number of new g-
of CNs
cycles if an edge is established between the CN and vj (line 8).
c
Now for every CN c in
cycles of
L
new g-cycles formed due to the addition of an edge between c
and vj (line 10) and compute LP-objective(
)
G
to get cost[c] (line 11). Our modiﬁed CN selection procedure is
e
Kmincycles that has the minimum cost[c] (line
to select a CN in
12). After selecting csel using the above criteria, we update
L
csel
sel be the list of g-cycles in
cycles that have
as follows: let
EMD
(line 13). Finally, we update
≤
the TG
G
e

Remark 4. We empirically observed that reducing the number
of cycles in the TG (and hence the number of stopping sets)
reduces the probability of failure against the medium and
strong adversary when LP-sampling is employed. The above
holds even if the size of the smallest stopping set remains
unchanged. This is in contrast to random sampling where the
probability of failure only depends on the size of the smallest
stopping set and is agnostic to the number of stopping sets of
small size present in the code. Thus, based on this observation,
we have added line 8 in our LC-PEG algorithm which selects
Kmincycles that form the minimum number of cycles
CNs
when a new edge is established. However, we further make
an informed choice among the CNs in
Kmincycles to select a
CN that has the minimum optimal objective value of LP (3).

L
Tth. We add
(line 14).

sel to

L

L

L

We now discuss the complexity of the LC-PEG algorithm.
Note that it differs from the original PEG algorithm (that has
complexity O(mn) [15]) in steps 7-13. Of these steps, step
11 has the largest complexity due to solving LP (3). An LP
minAz≤b cT z with d variables and t constraints can be solved
with complexity ˜O((nnz(A) + d2)√d) [31] where nnz(A) is
the number of non-zero entries in A and ˜O hides factors poly-
logarithmic in d and t. In our case, LP (3) has n variables and
at most mndv constraints (step 10 in the algorithm can result
in at most m cycles) and hence nnz(A)
gcmndv. Thus,
the overall complexity of the LC-PEG algorithm is at most
˜O(mn√n(gcmndv + n2)) = ˜O(n4.5). In our simulations, we
were able to generate codes up to length 500 for different
rates in a reasonable time frame (within a day) using the
LC-PEG algorithm. Note that the algorithms proposed in this
paper for LDPC code construction and sampling strategy
design have more complexity compared to [2]. However,
these algorithms are used ofﬂine instead of on-the-ﬂy. The

≤

12

IEEE TRANSACTIONS ON COMMUNICATIONS

Algorithm 4 LC-PEG Algorithm
1: Inputs: n, m , dv, gc, Tth, ˆθ, ˆµ; Outputs:
2: Initialize
3: for j = 1 to n do
4:
5:

G
e
for k = 1 to dv do
, g] = PEG(

G
to n VNs, m CNs and no edges,
e

, vj );

Kmindeg = CNs in

, gmin
=

L

∅

[
K
if g
else

≥

gc then csel = Select a CN randomly from

K

G
e

Kmindeg

Kmincycles = CNs in
for each c in

between the CN and vj
Kmincycles do
c
cycles = new g-cycles formed in
L
cost[c] = LP-objective(

G
c
cycles,
e
L ∪ L

)
G
Kmincycles with minimum cost[c]
e
csel
Tth;
cycles that have EMD

csel = CN in

sel = cycles in

L
=

G
e

edge
{

G ∪
e

L
csel, vj}

≤

=

L

sel

L ∪ L

6:

7:
8:

9:

10:

11:

12:

13:

14:

with the minimum degree under the TG setting

G
e

⊲ (g-cycles, g < gc, are created)
Kmindeg that result in the minimum number of new g-cycles due to the addition of edge

due to the addition of edge between c and vj

complexity increase is still tractable for short code lengths. We
demonstrate improvement in the probability of failure using
our algorithms in Section VI.

adversaries. Thus, when the number of light nodes M is large,
P S,A
is affected by the probability of failure of a single light
f
node, which we minimize in this paper.

V. SYSTEM ASPECTS

1) Security Performance: Here, we discuss how soundness
and agreement deﬁned in Section II-D are affected by our co-
design. Let M be the total number of light nodes in the system

nj −ω(j)
min+1
nj

, where ω(j)

(cid:18)

max
1≤j≤l

and ηrec =
min is the minimum
(cid:19)
stopping set size of the LDPC code used in layer j of the
CMT. We have the following lemmas (we defer the proofs to
the Appendix).
Lemma 4. For a weak adversary, when light nodes sample
according to the overall greedy sampling strategy, the proba-
bility of soundness or agreement failure per light client P S,A
satisﬁes
P S,A

f

f ≤
max

max
1≤j≤l, ω(j)<µj (cid:20)

[1

(cid:18)

−

τ (S(ρs , j)

greedy , ω(j))]

ω(j)
nj (cid:1)
2[H(ηrec,1−ηrec)nl−Ms(1−ρ) log( 1

1
(cid:0)

−

)]

ηrec

s−ρs

,

(cid:21)

(cid:19)
Here, S(ρs , j)
l, collected
when the light nodes request for the ﬁrst ρs coded symbols
from the base layer of the CMT.

greedy is the samples of layer j, 1

≤

≤

j

Lemma 5. For a medium and a strong adversary, when light
nodes sample according to LP-sampling x, the probability of
soundness or agreement failure per light client P S,A
satisﬁes

f

P S,A

f ≤

max

max
1≤j≤l

(cid:18)

P (j)
f

(s),

[H(ηrec,1−ηrec)nl−Ms log

2

1

ηrecnl
i=1

x[i]

]
(cid:1)

(cid:19)
(f,med)(s) and P (j)
Here, P (j)
(f,str)(s) for
the medium and strong adversary, respectively, as deﬁned in
Section IV-A and x[i] is the ith largest entry in vector x.

(s) = P (j)

(cid:0)
(s) = P (j)

P

f

f

The ﬁrst term in the maximum in Lemma 4 and 5 is the
probability of failure of a single light node against different

2) Blockchain System Designer: In the system model in
Section II-C, we have made a trusted set up assumption of
a blockchain system designer who designs the parity checks
matrices and the LP-sampling strategy. Note that for greedy
sampling, after the overall sampling rule described in Remark
3, nothing more needs to be designed by the system designer.
Additionally, as previously mentioned in Section II-D, only
the ﬁnal LP-sampling strategy obtained by solving LP (2) is
included in the protocol and inputs to LP (2) (µj and set of all
stopping sets of Hj of size < µj) are not part of the protocol.
Existing examples of blockchain systems that rely on trusted
set up assumptions include [28], [32], [33]. In our system,
there are two attacks possible by a compromised designer: i)
incorrect protocol design (i.e., the designed sampling strategy
and LDPC codes do not result in the claimed probability of
failure. Here, the probability of failure can be thought of
as an output of the protocol design computation task and
nodes join the system based on the published probability of
failure performance); ii) the designer acts as the adversary and
launches a DA attack using the known stopping sets of Hj of
size < µj.

A possible direction to remove the ﬁrst attack is as follows.
A cryptographic tool called zk-STARK [34] can be used
by the system designer to create veriﬁable proofs of correct
computation of the LDPC codes, the LP-sampling strategy, and
the probability of failure. This proof can be veriﬁed by nodes
(full and light) before joining the blockchain system to ensure
that the protocol is correctly designed. The proof created
using zk-STARK has the following properties: it has a small
size, it can be veriﬁed using signiﬁcantly less computational
complexity compared to the actual computation, it is secure
against quantum computers, it reveals no information about the
secrets involved in the computation (here µj and all stopping
sets of Hj of size < µj).

In the second attack, the system designer acts as the adver-

SUBMITTED PAPER

13

)
s
(
ω

,
f
P

)
4
(

1

0.8

0.6

0.4

0.2

0

0

5

10

15

s

20

25

30

35

)
s
(

)
j
(

f
P

100

10-1

10-2

10-3

10-4

10-5

0

5

10

15

s

20

25

30

35

Fig. 4: The probability of light node failure for various coding schemes and sampling strategies for CMT T1 = (128, 0.5, 4, 4) and weak
adversary. In this and all other ﬁgures, RS refers to random sampling; Left panel: probability of failure for a DA attack on the base layer
for different stopping set sizes. The black curve is achieved using stopping ratio ν ∗
= 0.064353. The value ν ∗ is the best stopping ratio
obtained for a rate 0.5 code following the method in [2, section 5.3] using parameters (c, d) = (8, 16). GS refers to the overall greedy
)s−ρs,
sampling strategy described in Section V 1) where we have used ρ = 0.9. P (j)
where S(ρs , j)
(s) is calculated as
P (j)
f

f, ω(s) for GS is calculated as [1 − τ (S(ρs , j)
greedy is described in Lemma 4; Right panel: probability of failure across different layers of the CMT. P (j)

f, ω(s), where µj = ω(j),P EG

(s) = maxω<µj P (j)

greedy , ω)](1 − ω
nj

+ 6.

min

f

sary (medium) to launch a DA attack using the knowledge
of the stopping sets (which it enumerated while correctly
designing LP-sampling x). However, this DA attack will be
detected by the light nodes with a probability of failure
P (j)
(f,med)(s) which is guaranteed by the protocol. Also, to
launch this DA attack, the system designer spends the same
amount of computational power as a medium adversary who
doesn’t have the knowledge of the stopping sets and wishes
to attack the system. Thus, the system designer is not at an
advantage to launch DA attacks due to the knowledge of the
secret.

T

VI. SIMULATION RESULTS
In this section, we compare the performance of our co-
design techniques with that of codes designed by the original
PEG algorithm and the performance of [2] using random
LDPC codes and random sampling (RS). Since many works
e.g., [17] [18] use random LDPC codes and random sam-
pling to mitigate DA attacks, any improvements we show in
comparison to [2] will also provide beneﬁts in these works.
The different CMTs used for simulation are parametrized by
= (nl, R, q, l) (individual parameters are deﬁned in Section
T
, in order to compare the performance of
II-A). For a CMT
different PEG based codes, we choose µj = ω(j),P EG
+ γ,
l, for the various adversary models described in
1
Section II-D. Here, ω(j),P EG
is the minimum stopping set
size for an LDPC code constructed using the original PEG
and γ is a parameter. We
algorithm for layer j of the CMT
calculate the probability of failure when the light nodes request
for s base layer samples using random sampling for various
scenarios as follows: for the base layer when the adversary
hides a stopping set of size ω, P (l)
; for
nl (cid:17)
intermediate layers, we calculate the probability of failure for
1nl
the medium and strong adversary by substituting x =
nl
in the probability of failure expressions provided in Section
is a vector of ones of length nl; for an
IV-A, where 1nl
LDPC code with a stopping ratio ν∗ we calculate the prob-

f, ω(s) =

min

min

−

≤

≤

(cid:16)

T

1

j

ω

s

f (s) = (1

ability of failure at the base layer using random sampling as
P (l)
ν∗)s. The LDPC codes at different layers of the
CMTs are aligned using Algorithm 2 where we use gmax = gc
(observed cycles in the code constructions) and gmin is set to
the girth of the respective codes.

−

c = 10 and g(j)

Fig. 4 demonstrates the performance of the EC-PEG al-
gorithm and the greedy sampling strategy for CMT
T1 =
(128, 0.5, 4, 4) and a weak adversary. For the EC-PEG algo-
rithm, we have used the parameters: dv = 4 for all layers,
R = 0.5, g(4)
c = 8 for j = 1, 2, 3. For
the adversary model we have chosen γ = 6. Note that
ω(4),P EG
= 9 and thus µ4 = 9 + 6 = 15. In Fig. 4 left
min
panel, we plot P (4)
f, ω(s) for various coding algorithms and
sampling strategies when a weak adversary conducts a DA
attack on the base layer of the CMT by hiding stopping
sets of size ω < µ4. The codes designed by the original
PEG and EC-PEG algorithms have a minimum stopping set
size of 9 and 10, respectively. For these algorithms, P (4)
f, ω(s)
quickly becomes zero for ω = 9, 10 using greedy sampling
as s increases. Hence, we have not included these stopping
set sizes in Fig. 4 left panel. The ﬁgure demonstrates three
beneﬁts of our co-design. The ﬁrst beneﬁt is due to the use
of deterministic LDPC codes that provide larger stopping set
sizes than random ensembles, as can be seen when comparing
the black and green curves. The second beneﬁt comes from
using greedy sampling as opposed to random sampling, which
can be observed by comparing the green and red curves. The
ﬁnal beneﬁt is provided by the EC-PEG algorithm, as can
be seen by comparing the red and blue curves. These beneﬁts
combine to signiﬁcantly reduce P (4)
f, ω(s) compared to the black
curve which was proposed in earlier literature10.

10The singularities in some plots in Fig. 4 (e.g., Original PEG + GS ω =
11) is because P (4)
f, ω(s) becomes zero after certain number of greedy samples.
This situation happens when all the stopping sets of weight ω get touched by
the greedy samples.

14

IEEE TRANSACTIONS ON COMMUNICATIONS

)
s
(
ω

,
f
P

)
4
(

1

0.8

0.6

0.4

0.2

0

0

5

10

15

s

20

25

30

35

7
1
s
s

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

0

Original PEG
EC-PEG

50

100
VN index

150

200

Fig. 5: Weak adversary performance plots for Nl = 200, R = 0.5, dv = 4. Left panel: probability of failure for a DA attack on the base
layer for different stopping set sizes (see Fig. 4 left panel for plot properties). We have parameters ωP EG
min = 13 and γ = 5, ρ = 0.9; Right
panel: stopping set distribution ss17.

)
s
(

)
j
(
f
P

100

10-1

10-2

10-3

10-4

10-5

20

Original PEG

25

30

35
s

40

45

50

)
s
(

)
j
(
f
P

100

10-1

10-2

10-3

10-4

10-5

20

LC-PEG

25

30

35
s

40

45

50

)
s
(

)
j
(
f
P

100

10-1

10-2

10-3

10-4

10-5

20

MC-PEG

25

30

35
s

40

45

50

Fig. 6: For CMT T1 = (128, 0.5, 4, 4), we plot the probability of failure for a DA attack at all layers for different codes under the following
cases; i) Base layer is randomly sampled (RS base), ii) LP-Sampling with medium adversary (Med), iii) LP-sampling with strong adversary
(Str-bound). For the strong adversary, we plot P (j)

(f,str)(s).

In Fig. 4 right panel, we plot the probability of failure
P (j)
(s) when the weak adversary conducts a DA attack on
f
T1. From Fig. 4 right panel11, we see that
layer j of CMT
the base layer of the CMT (L4) has a larger probability of
failure compared to other layers and the probability of failures
for the intermediate layers quickly become very small. This
is due to the alignment of the columns of the parity check
matrices, which ensures that each intermediate layer is greedy
sampled. We next observe that the EC-PEG algorithm with
greedy sampling results in a lower P (j)
(s) compared to the
original PEG algorithm for all layers of the CMT. Moreover,
for the base layer, P (4)
(s) (for both EC-PEG and original PEG
coupled with greedy sampling) is lower than the probability
of failure using random sampling for ω = 14 (green curve)
and the probability of failure achieved by random LDPC codes
and random sampling (black curve). Thus, in combination, the
co-design of concentrated LDPC codes and greedy sampling
results in a signiﬁcantly lower P (4)
f, ω(s) compared to methods
proposed in [2]. To illustrate the beneﬁts of the EC-PEG
algorithm and the greedy sampling strategy, we provide plots

f

f

f, ω(s) and P (j)

11The plots for P (4)

f, ω(s) in Fig. 4 sometimes exhibit ﬂoors
(i.e., they remain constant for different values of s). This is due to i) the new
greedy samples that are selected (on increasing s) do not increase the number
of stopping sets that are touched; ii) the number of random samples in the
overall greedy sampling strategy remain same on increasing s.

similar to Fig. 3 and Fig. 4 for a different choice of code
parameters in Fig. 5. From the ﬁgure, we see similar stopping
set concentration and probability of failure improvement as in
Fig. 3 and Fig. 4.

min

min

c = 10 and g(j)

th = 3 for j = 1, 2, T (j)

In Figs. 6, 7 and Table I, we demonstrate the performance
of the LC-PEG algorithm and LP-sampling (LS) against a
medium and a strong adversary. Fig. 6 and 7 correspond to
T1 = (128, 0.5, 4, 4) where we have used γ = 4, thus
CMT
+ 4. Table II lists ω(j),P EG
µj = ω(j),P EG
for different j.
Additionally, for LP-sampling, we have used θ(4) = 0.993,
θ(j) = 1, j = 1, 2, 3. For the LC-PEG algorithm, we have used
dv = 4 for all layers, R = 0.5, g(4)
c = 8 for
j = 1, 2, 3, T (j)
th = 4 for j = 3, 4,
ˆθ(j) = 0.997, j = 1, 2, 3, 4 (we tested with Tth = 3, 4
and ˆθ = 0.995, 0.996, 0.997, 0.998 and picked the codes that
provide the lowest P J max
(s)) and ˆµj = µj, j = 1, 2, 3, 4.
To demonstrate the effectiveness of the LC-PEG algorithm,
we also plot the performance of an algorithm termed as the
Minimum-Cycles PEG (MC-PEG) algorithm. It is the same as
the LC-PEG algorithm but instead of the CN selection steps
in lines 10-13 of Algorithm 4, the MC-PEG algorithm selects
Kmincycles as csel.
a CN randomly from
We ﬁrst look at the improvements provided by LP-sampling.
Fig. 6 shows the performance of LP-sampling for a DA attack
at different layers of the CMT constructed using the PEG,

f

SUBMITTED PAPER

15

10-1

)
s
(

)
4
(

f
P

10-2

3 10-1

0.1

)
0
3
=
s
(

)
4
(

f
P

25

30

35

s

40

45

0.01

0.94

0.96
θ(4)

0.98

1

Fig. 7: The probability of light node failure for a DA attack on the base layer of CMT T1 = (128, 0.5, 4, 4); Left panel: comparison of
different coding schemes and sampling strategies. The black curve uses ν ∗
(s = 30) for the
strong and medium adversary as a function of θ(4) for θ(j) = 1, j = 1, 2, 3.

= 0.064353; Right panel: variation in P (4)

f

TABLE I: P (l)
f (s = 0.25nl) for a DA attack on the base layer for various CMT parameters, coding schemes, and sampling strategies. The
parameters used for the different CMTs is listed in Table II. For the ensemble codes, we follow the method of [2, Section 5.3] and for each
R obtain the following parameters (R, c, d, ν ∗) = {(0.5, 8, 16, 0.0643),
(0.4, 6, 10, 0.0851), (0.8, 11, 55, 0.0187)} where (c, d) are optimized to maximize the stopping ratio ν ∗.

Random Sampling

LP-Sampling

Ensemble PEG MC-PEG LC-PEG

CMT
= (nl, R, q, l)
T
(128, 0.5, 4, 4)
(208, 0.5, 4, 4)
(200, 0.5, 4, 3)
(200, 0.4, 5, 4)
(200, 0.8, 5, 2)

0.1190
0.0314
0.0356
0.0117
0.3891

0.0970 0.0740
0.0204 0.0155
0.0347 0.0202
0.0089 0.0067
0.4697 0.3641

Strong Adversary

Medium Adversary

PEG MC-PEG LC-PEG PEG MC-PEG LC-PEG
0.0428 0.04914 0.04602 0.04106 0.03925 0.03675 0.03279
0.0267
0.0304 0.02427 0.02294 0.00815 0.00651 0.00615
0.0202 0.02778 0.02028 0.01781 0.00606 0.00447 0.00388
0.0052 0.00558 0.00513 0.00484 0.00225 0.00207 0.00195
0.1411
0.2332
0.2820

0.2827

0.1549

0.256

0.171

TABLE II: Parameters used for LP-sampling and LC-PEG code construction for various CMTs in Table I. For all LDPC codes we use
dv = 4, g(j)
+ γ, j = 1, . . . , l. Under each
variable that depends on the layer, we enumerate the layer numbers.

min + 4, j = 1, . . . , l. For LC-PEG algorithm, we use ˆµ(j) = µ(j) = ω(j),P EG

max = g(j)

c = g(j)

min

CMT

= (nl, R, q, l) 1 2 3 4

T
(128, 0.5, 4, 4)
(208, 0.5, 4, 4)
(200, 0.5, 4, 3)
(200, 0.4, 5, 4)
(200, 0.8, 5, 2)

1

2

3

b

θ(j)

T (j)
th

g(j)
min

ω(j),P EG
min
4
1
1 2 3 4 1 2 3
3 3 4 4 0.997 0.997 0.997 0.997 4 4 4 6 2 4 5
9 4 1
3 4 4 5 0.997 0.997 0.997 0.9959 4 4 6 6 4 6 10 15 3 1
-
4 4 5 - 0.997 0.997 0.998
3 4 4 5 0.997 0.997 0.997 0.998 4 4 6 6 5 8 11 18 4 1
-
4 5 -

4 6 6 - 6 8 13 -

- 0.997 0.997

- 2 3 -

4 4 -

γ

4

-

-

4
0.993
0.997 0.975

2
1
1
3 1 0.99 0.97
1

0.992 0.982

-

3 1 0.99

-

-

θ(j)
3
1

LC-PEG and MC-PEG algorithms. We see that while the
probability of failure for some layers worsens in comparison
to random sampling, for the worst layer, which is the base
layer, the probability of failure improves for both the strong
and medium adversary. We generally ﬁnd that the base layer is
the worst layer so we focus on the base layer in the subsequent
simulations.

f

We plot P (4)

(s) vs. s for the PEG, MC-PEG, and LC-
PEG algorithms using LP-sampling in Fig. 7 left panel, where
we see the following improvements. The ﬁrst improvement is
between the black and magenta curves due to using determin-
istic LDPC codes that produce larger stopping set sizes. The
second improvement is due to using LP-sampling compared
to random sampling. Compared to random sampling (magenta
curve), LP-sampling with the original-PEG algorithm results
in a lower probability of failure for the medium (red-solid
curve) and strong adversary (red-dotted curve). The third im-
provement (between the red and light blue curves) comes from

utilizing the MC-PEG algorithm to reduce the number of small
cycles as discussed in Remark 4. The ﬁnal improvement comes
from the informed CN selection in the LC-PEG algorithm to
create tailored codes for LP-sampling as seen by comparing
the dark and light blue curves.

f

In Fig. 7 right panel, we plot P (4)

(s = 30) as a function
of the parameter θ(4) for the original PEG, MC-PEG and LC-
PEG algorithms using LP-sampling. From Fig. 7 right panel,
we see that θ(4) controls the trade-off between the probabilities
of failure for the medium adversary and strong adversary.
Thus, θ(4) can be chosen as a hyper-parameter based on the
system speciﬁcations. We also see from Fig. 7 right panel that
for all the values of θ(4), the LC-PEG algorithm outperforms
the PEG and MC-PEG algorithm for both the medium and
strong adversary.

For completeness, we provide further examples of how our
novel code constructions improve the probability of failure

16

IEEE TRANSACTIONS ON COMMUNICATIONS

TABLE III: Maximum CN degree for the LDPC codes used in different layers of the CMT. Under each algorithm, we enumerate the layer
numbers and specify the maximum CN degree for that layer.

CMT
= (nl, R, q, l)
T
(128, 0.5, 4, 4)
(208, 0.5, 4, 4)
(200, 0.5, 4, 3)
(200, 0.4, 5, 4)
(200, 0.8, 5, 2)

Ensemble

16
16
16
10
55

3

4

EC-PEG

MC-PEG
PEG
2 3 4 1
1
2
8 9 9 10 13 12 14 8
9 8 8 11 11 11 16 8
9 9 - 12 11 18 -
9
7 7 7 12 9 11 14 7
- 26 48 -

1
8
8
9
7
20 21 -

2 3 4 1
8 9 9 8
9 8 9 8
9 9 - 8
7 7 8 7

- 20 20 -

LC-PEG

2 3 4
8 9 9
8 9 9
9 9 -
8 7 7
-

- 20 20 -

for different CMT parameters. In Table I, we list P (l)
f (s)
and compare various sampling strategies and LDPC code
constructions. Similar to Fig. 7 left panel, from Table I, we
see that the novel co-design of the LC-PEG algorithm and
LP-sampling results in the lowest probability of failure for the
different CMT parameters. We see that even at a high rate of
0.8, our techniques of LC-PEG algorithm and LP-sampling
offer an improvement.

In Table III, we compare the maximum CN degree for
the LDPC codes used in different CMT layers for various
construction techniques. We see that PEG based constructions
have similar maximum CN degrees compared to the ensemble
LDPC codes used in [2]. Since the incorrect coding proof size
is proportional to the maximum CN degree, we conclude that
the new LDPC code constructions do not signiﬁcantly impact
the incorrect coding proof size to improve the probability
of failure. Additionally for rate 0.8 codes, we see that the
LC-PEG algorithm results in a signiﬁcantly lower maximum
CN degree compared to the ensemble LDPC codes thus also
improving the incorrect coding proof size along with the
probability of failure.

VII. CONCLUSION

In this paper, we considered the problem of DA attacks
pertinent to blockchains with light nodes. For various strengths
of the malicious nodes, we demonstrated that, at short code
lengths, a suitable co-design of specialized LDPC codes
and the light node sampling strategy can result in a much
lower probability of failure to detect DA attacks compared to
schemes in prior literature.

REFERENCES
[1] M. Al-Bassam, et al., “Fraud and data availability proofs: Detecting
invalid blocks in light clients," Int. Conf. on Financial Cryptography and
Data Secur., Springer, Mar. 2021.

[2] M. Yu, et al., “Coded merkle tree: Solving data availability attacks in
blockchains," Int. Conf. on Financial Cryptography and Data Secur.,
Springer, Feb. 2020.

[3] D. Mitra, et al., “Concentrated stopping set design for coded merkle
tree: Improving security against data availability attacks in blockchain
systems," 2020 IEEE Inf. Theory Workshop (ITW), Apr. 2021, full version:
https://arxiv.org/abs/2010.07363.

[4] S. Nakamato, “Bitcoin: A peer to peer electronic cash system," 2008.

[Online] Available: https://bitcoin.org/bitcoin.pdf.

[5] M. J. Casey and P. Wong, “Global supply chains are about to get better,
thanks to blockchain,” Harvard Business Review, Mar. 2017. [Online]
Available: https://hbr.org/2017/03/global-supply-chains-are-about-to-get-
better-thanks-to-blockchain.

[6] X. Wang, et al., “Survey on blockchain for internet of things," Comput.

Commun., vol. 136, pp. 10-29, 2019.

[7] M. Mettler, “Blockchain technology in healthcare: The revolution starts
here,” IEEE 18th Int. Conf. on e-Health Network., Apps., and Services
(Healthcom), Sept. 2016.

[9] Online: https://www.blockchain.com/charts/blocks-size, accessed: May 5,

2022.

[10] Online: https://etherscan.io/chartsync/chaindefault, accessed: May. 5,

2022.
[11] Online:

https://github.com/ethereum/research/wiki/A-note-on-data-

availability-and-erasure-coding

[12] T. Richardson, and R. Urbanke, “Modern coding theory," Cambridge:

Cambridge University Press, 2008.

[13] X. Jiao, et al., “Eliminating small stopping sets in irregular low-density
parity-check codes," IEEE Commun. Lett., vol. 13, no. 6, pp. 435-437,
Jun. 2009.

[14] K. M. Krishnan, and P. Shankar, “Computing the stopping distance of
a Tanner graph is NP-hard," IEEE Trans. on Inf. Theory, vol. 53, no. 6,
pp. 2278-2280, Jun. 2007.

[15] X.Y. Hu, et al., “Regular and irregular progressive edge-growth tanner
graphs," IEEE Trans. on Inf. Theory, vol. 51, no. 1, pp. 386-398,
Jan. 2005.

[16] A. Orlitsky, et al., “Stopping set distribution of LDPC code ensembles,"
IEEE Trans. on Inf. Theory, vol. 51, no. 3, pp. 929-953, Mar. 2005.
[17] S. Cao, et al., “CoVer: Collaborative light-node-only veriﬁcation and
data availability for blockchains," IEEE Int. Conf. on Blockchain, Nov.
2020.

[18] Trifecta Team,

“Trifecta: The
http://pramodv.ece.illinois.edu/pubs/Whitepaper2019-9.pdf

blockchain

trilemma

solved,"

[19] P. Sheng, et al., “ACeD: Scalable data availability oracle," Financial

Cryptography, Springer, Mar. 2021.

[20] D. Mitra, et al., “Communication-efﬁcient LDPC code design for data
availability oracle in side blockchains," IEEE Inf. Theory Workshop
(ITW), Oct. 2021.

[21] T. Tian, et al., “Construction of irregular LDPC codes with low error

ﬂoors," IEEE Int. Conf. on Commun., May 2003.

[22] S. Kim, et al., “LDPC code construction with low error ﬂoor based on
the IPEG algorithm," IEEE Commun. Lett., vol. 11, no. 7, pp. 607-609,
Jul. 2007.

[23] M. Dai, et al., “A low storage room requirement framework for dis-
tributed ledger in blockchain," IEEE Access, vol. 6, pp. 22970-22975,
Mar. 2018.

[24] Q. Huang, et al., “Downsampling and transparent coding for blockchain"
IEEE Trans. on Network Sci. and Eng., vol. 9, no. 4, pp. 2139-2149, Jul.-
Aug. 2022.

[25] S. Kadhe, et al., “SeF: A secure fountain architecture for slashing storage

costs in blockchains," arXiv:1906.12140, 2019.

[26] S. Li, et al., “PolyShard: coded sharding achieves linearly scaling
efﬁciency and security simultaneously," IEEE Trans. on Inf. Forensics
and Secur., vol. 16, Jul. 2020.

[27] D. Perard, et al., “Erasure code-based low storage blockchain node,"
IEEE Int. Conf. on Internet of Things (iThings) and IEEE Green Comput.
and Commun. (GreenCom) and IEEE Cyber, Physical and Social Comput.
(CPSCom) and IEEE Smart Data (SmartData), Jul. 2018.

[28] P. Daian, et al., “Snow white: Robustly reconﬁgurable consensus and
applications to provably secure proof of stake," Financial Cryptography,
Sept. 2019.

[29] S. Park, et al., “Spacemint: A cryptocurrency based on proofs of space,"

Financial Cryptography, Springer, Feb. 2018.

[30] A. Sarıduman, et al., “An integer programming-based search technique
for error-prone structures of LDPC codes," AEU-Int. Journal of Electron-
ics and Commun., vol. 8, no. 11, pp. 1097-1105, Nov. 2014.

[31] Y. T. Lee, and A. Sidford, “Efﬁcient inverse maintenance and faster
algorithms for linear programming," IEEE Annual Symp. on Foundations
of Computer Science, Oct. 2015.

[32] E. B. Sasson, et al., “Zerocash: decentralized anonymous payments from

bitcoin," IEEE Symp. on Secur. and Privacy, May 2014.

[8] T. Rocket, et al., “Scalable and probabilistic leaderless BFT consensus

[33] K. Nazirkhanova, et al., “Information dispersal with provable retriev-

through metastability," arXiv:1906.08936, Jun. 2019.

ability for rollups," arXiv:2111.12323, Nov. 2021.

SUBMITTED PAPER

17

[34] E. B. Sasson, et al., “Scalable, transparent, and post-quantum secure

computational integrity," IACR Cryptol. ePrint Arch, 2018.

[35] P. Santini, et al., “Optimization of a Reed-Solomon code-based protocol
against blockchain data availability attacks", IEEE Int. Conf. on Commun.,
May 2022.

APPENDIX

1) Proof of Lemma 2:
P (l)
(f,med)(s)

=

max
k∈{1,2,...,|Ψl|}
s

f (s; ψ(l)
P (l)
k )

=

s

.

k

(cid:2)

(cid:17)

−

−

=

xi

i:v(l)

max

max(1

max(1

i ∈ψ(l)

Π(l)x)
(cid:3)

1
max
k∈{1,2,...,|Ψl|} (cid:16)
that Ψ∞
Recall
j
have the following: P (l)
(f,str)(s) = maxψ∈Ψ∞
s

P
is set of all stopping sets of Hj. We
f (s; ψ) =
f (s; ψ)
(cid:17)
s
=

max(1
(cid:0)

≤
max
The second term in the maximum of P (l)
(cid:0)
(f,str)(s) is because
s
f (s; ψ)
.

P (l)
,size(ψ)≥µl P (l)
β(l)µl
1
s
(cid:2)
.

, maxψ∈Ψ∞
Π(l)x)
(cid:3)
β(l)µl

Π(l)x)
(cid:3)
max(1
−
Π(l)x), 1

(cid:1)(cid:1)
β(l)µl

(cid:16)(cid:2)
−

P (l)

max

(cid:16)(cid:2)

−

−

−

l
,

(cid:17)

(cid:3)

s

l

max
,size(ψ)≥µl

ψ∈Ψ∞
l

≤

−

1
(cid:0)

(cid:1)

2) Proof of Lemma 3:
j
For 1

i

l

(cid:1)

≤

−

≤

. Thus, for a sampling strategy

l, it is easy to see that x(j)
k

1, the ith column of A(j) (see Section
≤
IV-A) corresponds to VN v(l)
of the base layer and the non-
zero positions in the ith column (two per column) correspond
to the symbols of layer j which are part of the Merkle proof of
v(l)
and x(j) = A(j)x,
x , β(l)
i
(cid:0)
j
is the probability that
1
≤
v(j)
is sampled. Now, consider a stopping set ψ that belongs
k
to an intermediate layer j. Note that the Merkle proof for a
base layer sample contains a single data and a single parity
symbol from layer j and is deterministic given the base layer
sample. If both the symbols (VNs) exist in ψ, it is possible for
a single base layer symbol to sample ψ at two VNs. To avoid
over-counting, we have deﬁned the matrices ∆(j) in Section
IV-A. ∆(j) has the property that ∆(j)
is 1 if the ith base layer
ki
symbol (i.e., v(l)
) samples, via its Merkle proof from layer
j, the kth stopping set of Ψj and zero otherwise. Thus, for
x , β(1) , . . . , β(l)
a sampling strategy
, it is not difﬁcult to
s
see that P (j)
∆(j)x)
(cid:1)
(cid:0)
(f,med)(s) =
(cid:3)

−
Now, let us consider the strong adversary. Since a Merkle
proof contains one data and one parity symbol from every
intermediate layer, all data (parity) symbols are sampled
disjointly. As such, we can bound the probability of sam-
j < l, by
pling a stopping set ψ of size
P (j)
and
f
is a parity symbol x(j)
P (j)
f
Summing the two inequalities and dividing over 2 yields
P
P (j)
(s = 1; ψ)
f
Finally, use P (j)

i ∈ψ,v(j)
i ∈ψ x(j)
:v(j)
(s = 1; ψ))s.

≤
is a data symbol x(j)

x(j)
≤
−
i
P
(s; ψ) = (P (j)
f

≥
i ∈ψ,v(j)

(s = 1; ψ)

1
2 β(j)µj.

(s = 1; ψ)

i ≤

max(1

uj, 1

P
−

−
1

:v(j)

:v(j)

x(j)
i

x(j)
i

, 1

−

≤

≤

≤

≤

l.

1
2

1

1

1

(cid:2)

j

f

.

i

i

i

i

i

3) Proof of Lemma 4:
Soundness fails if the light nodes get back all the requested
samples but no honest full node is able to fully decode the
entire CMT. We consider two cases:
i) There is a DA attack at layer j: In this case, no honest
full node will be able to decode layer j of the CMT. Light
nodes fail to detect this DA attack using the overall greedy

(s) = max

sampling strategy described in Remark 3 with probability
τ (S(ρs , j)
P (1)
f

(cid:21)
The term inside the maximum is the probability of failure
using the overall greedy sampling strategy when the weak
adversary hides a stopping set of size ω(j).

greedy , ω(j))]

ω(j)
nj (cid:17)

ω(j)<µj (cid:20)

s−ρs

[1

−

−

(cid:16)

1

.

ii) There is no DA attack: In this case, light nodes will
accept the block. Soundness failure occurs when honest full
nodes are not able to decode the entire CMT from the samples
broadcasted by the light nodes. Let P (2)
(s) be the probability
(s), we use the following
of
f
property of the CMT which was proved in [19]: the Merkle
proof of η fraction of distinct base layer coded symbols
have at least η fraction of distinct coded symbols from each

this event. To bound P (2)

f

nj −ω(j)
min+1
nj

j

(cid:18)

≤

max1≤j≤l

nj −
1
∀

layer of the CMT. Thus for ηrec =
,
(cid:19)
if a full node has ηrec fraction of distinct coded symbols
from the base layer of the CMT, then it has at least ηrec
least ηrecnj distinct coded symbols from
fraction or at
ω(j)
layer j of the CMT. Since ηrecnj ≥
min + 1, using
these ηrecnj distinct coded symbols, the full node will be
able to successfully decode layer j,
l. Let Z
be the total number of distinct base layer coded symbols
collected by a honest full node from the random portion of
the light node’s overall greedy sampling strategy. Then, we
have P (2)
ηrecnl)
≤
≤
2[H(ηrec,1−ηrec)nl−Ms(1−ρ) log( 1
of
soundness failure is smaller than the maximum of the above
two cases. Moreover, in our system, for the same reasons
as [2], soundness implies agreement (since each light node
least one honest full node and honest
is connected to at
full nodes form a fully connected graph; see network model
in Section II-C). Thus, P S,A
(s))
completing the proof.

(ηrecnl)M s(1−ρ)
nM s(1−ρ)
probability

nl
ηrecnl
≤
(cid:1)
(cid:0)
)]. The

max(P (1)

(s), P (2)

P (Z

(s)

ηrec

≤

≤

≤

f

f

f

f

l

4) Proof of Lemma 5:
Again we consider the two cases described in the proof
to de-
layer j using LP-sampling with
f,med(s) and P (1)
P (j)
(s) =

of Lemma 4. For the ﬁrst case,
tect
probability P (1)

the DA attack at

light nodes fail

(s) = max
1≤j≤l

f

f

P (j)

f,str(s) for the medium and the strong adversary,
max
1≤j≤l
respectively. For the second case, let Z be the total number
of distinct base layer coded symbols collected by a hon-
est full node when light nodes use LP-sampling. We have
P (2)
f

ηrecnl
i=1

ηrecnl)

P (Z

x[i]

(s)

Ms

[H(ηrec,1−ηrec)nl−Ms log

(cid:1) (cid:0)P
. Similar to the proof
2
of Lemma 4, soundness implies agreement and we have
P S,A

max(P (1)

(s), P (2)

(s)).

(cid:1)

P

nl
ηrecnl
≤
(cid:0)
]
ηrecnl
x[i] !
i=1

1

≤

≤

≤

f

f

f ≤

 
18

IEEE TRANSACTIONS ON COMMUNICATIONS

Debarnab Mitra is a Ph.D. candidate in the Elec-
trical and Computer Engineering Department at the
University of California, Los Angeles (UCLA). He
received his B. Tech (with honors) in Electrical
Engineering from the Indian Institute of Technol-
ogy Bombay in 2018 and his M.S. in Electrical
and Computer Engineering from the University of
California, Los Angeles in 2020. Currently, he works
at the Laboratory for Robust Information Systems
(LORIS), and his focus is on coding schemes for
blockchain systems. His research interests include
coding and information theory, signal processing, graph theory, and blockchain
systems. Debarnab is a receipt of the Best Poster Award from the IEEE North
American School of Information Theory (NASIT), 2021. In 2020, he received
the Distinguished Masters Thesis Award in Signals and Systems from the
Electrical and Computer Engineering Department at UCLA.

Lev Tauz is a Ph.D. candidate in the Electrical and
Computer Engineering Department at the University
of California, Los Angeles (UCLA). He received
his B.S. (with honors) in Electrical Engineering and
Computer Science from the University of California,
Berkeley in 2016 and his M.S. in Electrical and
Computer Engineering from the University of Cal-
ifornia, Los Angeles in 2020. Currently, he works
at the Laboratory for Robust Information Systems
(LORIS), and is focused on coding techniques for
distributed storage and computation. His research
interests include distributed systems, error-correcting codes, machine learning,
and graph theory. Lev is the recipient of the Memorable Paper Award from
the 2021 Non-Volatile Memories Workshop (NVMW).

Lara Dolecek is a Full Professor with the Elec-
trical and Computer Engineering Department and
Mathematics Department (courtesy) at the Univer-
sity of California, Los Angeles (UCLA). She holds
a B.S. (with honors), M.S. and Ph.D. degrees in
Electrical Engineering and Computer Sciences, as
well as an M.A. degree in Statistics, all from the
University of California, Berkeley. She received the
2007 David J. Sakrison Memorial Prize for the most
outstanding doctoral research in the Department of
Electrical Engineering and Computer Sciences at UC
Berkeley. Prior to joining UCLA, she was a postdoctoral researcher with
the Laboratory for Information and Decision Systems at the Massachusetts
Institute of Technology. She received IBM Faculty Award (2014), Northrop
Grumman Excellence in Teaching Award (2013), Intel Early Career Faculty
Award (2013), University of California Faculty Development Award (2013),
Okawa Research Grant (2013), NSF CAREER Award (2012), and Hellman
Fellowship Award (2011). With her research group and collaborators, she
received numerous best paper awards. Her research interests span coding
and information theory, graphical models, statistical methods, and algorithms,
with applications to emerging systems for data storage and computing. She
currently serves as an Associate Editor for IEEE Transactions on Information
Theory and as the Secretary of the IEEE Information Theory Society. Prof.
Dolecek is 2021-2022 Distinguished Lecturer of the IEEE Information Theory
Society. Prof. Dolecek has served as a consultant for a number of companies
specializing in data communications and storage.

