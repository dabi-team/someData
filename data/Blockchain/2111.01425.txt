1
2
0
2

v
o
N
2

]
T
G
.
s
c
[

1
v
5
2
4
1
0
.
1
1
1
2
:
v
i
X
r
a

Rational Agreement in the Presence of Crash Faults

Alejandro Ranchal-Pedrosa
University of Sydney

Vincent Gramoli
University of Sydney and EPFL

Sydney, Australia

Sydney, Australia

alejandro.ranchalpedrosa@sydney.edu.au

vincent.gramoli@sydney.edu.au

Abstract

Blockchain systems need to solve consensus despite the
presence of rational users and failures. The notion of (k, t)-
robustness has shown instrumental to list problems that
cannot be solved if k players are rational and t players are
Byzantine or act arbitrarily. What is less clear is whether
one can solve such problems if the faults are benign.

In this paper, we bridge the gap between games that
are robust against Byzantine players and games that are
robust against crash players. Our ﬁrst result is an impossi-
bility result: We show that no (k, t)-robust consensus pro-
tocol can solve consensus in the crash model if k + 2t ≥ n
unless there is a particular punishment strategy, called the
(k, t)-baiting strategy. This reveals the need to introduce
baiting as the act of rewarding a colluding node when be-
traying its coalition, to make blockchains more secure.

Our second result is an equivalence relation between
crash fault tolerant games and Byzantine fault tolerant
games, which raises an interesting research question on
the power of baiting to solve consensus. To this end, we
show, on the one hand, that a (k, t)-robust consensus pro-
tocol becomes (k + t, t)-robust in the crash model. We
show, on the other hand, that the existence of a (k, t)-
robust consensus protocol in the crash model that does
not make use of a baiting strategy implies the existence
of a (k − t, t)-robust consensus protocol in the Byzantine
model, with the help of cryptography.

1

Introduction

With the advent of blockchains, there is a growing interest
at the frontier between distributed computing and game

theory. As one fundamental building block of blockchains
is consensus, it is natural to seek equilibria in which con-
sensus is reached despite the presence of both failures and
rational players. Moreover, as blockchains handle valuable
assets over the Internet, they are typically subject to net-
work attacks [10, 22, 11] and should tolerate unexpected
delays—an assumption called partial synchrony [8]—to
avoid asset losses.

There are traditionally two types of failures considered
in the distributed computing literature: crash failures af-
ter which a participant stops and Byzantine failures when
participants act arbitrarily (i.e., irrationally). This is why
considering fault tolerant distributed protocols as games
requires to cope with a mixture of up to k rational players
and t faulty players. The idea of mixing rational players
with faulty players has already been extensively explored
in the context of secret sharing and multi-party compu-
tation [21, 13, 7, 2] but rely usually on a trusted central
authority, called a mediator.

Recent results [1] showed that mediators could be im-
plemented in a fully distributed setting when n > 3(k + t)
and t players are Byzantine. Unfortunately, this adapta-
tion makes it impossible to devise even a consensus solu-
tion that is immune to a single t = 1 Byzantine failure
as it is impossible to solve consensus with complete asyn-
chrony and failures [12]. More recent results [14] seem to
indicate that when n ≤ 4(k + t) there exist equilibria that
cannot be implemented in a distributed fashion when the
player behaviors are irrational or failures are Byzantine.

These impossibility results raise the question of whether
one can solve consensus in a distributed fashion with
k rationals and t failures when the failures are crashes
and communication is partially synchronous [8]. We be-
lieve this combination to be particularly relevant in the

1

 
 
 
 
 
 
blockchain context as players are incentivized to steal
assets by leading other players to a disagreement—also
called a fork. Such a situation went undetected in Bit-
coin and led the attackers to “double spend”, eﬀectively
doubling their assets.1

Our result
In this paper, we focus instead on the par-
tially synchronous model, where the bound on the delay of
messages is unknown [8], to design a protocol that solves
consensus among n players, where up to t players can crash
and k are rational players that can collude and deviate, in
what we refer to as a (k, t)-crash-robust protocol. To this
end, we ﬁrst deﬁne (k, t)-crash-robustness by extending
(k, t)-robustness [2] but replacing t Byzantine players by
t crash players, and we consider that rational players pre-
fer to form a coalition and cause a disagreement than to
satisfy agreement.

To the best of our knowledge, we present the ﬁrst
work that obtains bounds for the robustness of agreement
against coalitions of crash and rational players in partial
synchrony in a setting where rational players prefer to
disagree. This result establishes constructively a direct
relation between (k, t)-robust protocols and (k′, t′)-crash-
robust protocols.

More precisely, we ﬁrst prove that no resilient-optimal
crash-fault tolerant protocol can tolerate even one rational
player. Speciﬁcally, we prove that it is not possible, in gen-
eral, to design a protocol that implements consensus and
is (k, t)-crash-robust for k + 2t ≥ n, unless there is a (k, t)-
crash-baiting strategy (that is, a punishment strategy that
strictly dominates deviations towards a disagreement for a
number of deviating rational players) with respect to the
protocol. This means that state-of-the-art crash-fault tol-
erant (CFT) protocols that tolerate up to less than n/2
crash players [8] do not tolerate even one rational player
in partial synchrony.

This raises a new research question: what would be a
protocol that achieves a good compromise between crash-
fault tolerance and tolerance to rational players in partial
synchrony?

To answer this question, and since the literature tackled
the problem for Byzantine faults, we demonstrate a link
between Byzantine players with rational and crash play-
ers: a protocol that tolerates s Byzantine players also tol-

erates s rational players and s crash players. We complete
this relation by proving that a protocol that implements
consensus and is ǫ-(k, t)-robust (where ǫ accounts for the
small probability of the adversary breaking the cryptog-
raphy) is also ǫ-(k + t, t)-crash-robust. Additionally, we
deﬁne a (t′, t)-immune protocol as a protocol that toler-
ates up to t′ crash faults and up to t Byzantine faults, and
prove that if a protocol is ǫ-(t′, t)-immune, then it is also
ǫ-(t, t′ + t)-crash-robust.

Finally, we also establish a relation in the opposite di-
rection assuming cryptography and ignoring crash-baiting
strategies: a protocol that tolerates up to k rational play-
ers and up to t crash players without a (k, t)-crash-baiting
strategy also tolerates up to min(k, t) Byzantine players,
that is, a (k, t)-crash-robust protocol is also min(k, t)-
immune. We then prove the relation relative to robust-
#»
ness: if there is a protocol
σ that is ǫ-(k, t)-crash-robust
with k ≥ t then we can construct an ǫ-(k − t, t)-robust
#»
σ does not
protocol
implement a (k, t)-crash-baiting strategy, or instead that it
implements an eﬀective (k, t)-crash-baiting strategy that
is also an eﬀective (k−t, t)-baiting strategy, where eﬀective
means that playing the baiting strategy still implements
consensus. We apply the analogous if t ≥ k to obtain that
ǫ-(k, t)-crash-robust protocols are also ǫ-(t−k, k)-immune,
excluding baiting strategies. Finally, we discuss in detail
the implications of baiting and punishment strategies to
this relation.

#»
σ′, assuming cryptography and that

1.1 Related work

Multiple research groups studied the consensus problem
by combining rational players with crash faults [6, 17, 5]
or by replacing crash faults by rational players [16]. Groce
et al. [16] show a protocol that solves Byzantine agreement
in synchrony even in the presence of rational coalitions as
long as the size k of the coalition is such that k < n and
given complete knowledge of the adversary’s preferences.
Nevertheless, they consider neither crash nor Byzantine
(irrational) faults, a model also used by Ebrahimi et al. [9].
Bei et al. [5] extend this synchrony result to add crash
failures, obtaining that if colluding players are allowed an
extra communication round after each synchronous round,
then there is no protocol that can tolerate even 2 collud-
ing rational players and 1 crash player under their model.
Clementi et al. [6] study the problem of fair consensus

1https://www.cnet.com/news/hacker-swipes-83000-from-bitcoin-mining-pools/.

2

in the presence of rational and crash faults in the syn-
chronous gossip communication model. Fair consensus
adds a new property, fairness, deﬁned by all players shar-
ing the same probability of their proposal being decided.
The gossip communication model allows all agents to con-
tact at most one neighbor via a push/pull operation at
every round.

Harel et al. [19] assume a set of utilities for rational play-
ers such that they guarantee solution preference, mean-
ing that all rational players want to satisfy all properties
of consensus. Finally, Halpern et al. [17] extend the re-
sults on fair consensus in the synchronous model. None of
the results listed so far consider either the partially syn-
chronous model or rational players that are interested in
disagreeing in blockchains to maximize their proﬁt.

Secret sharing and multi-party computation already ex-
plored a combined group of rational players with faulty
players [21, 13, 7, 2], specially focused on implementing
trusted mediators through cheap-talk [2], i.e., private pair-
wise communication channels of negligible cost. In partic-
ular, Abraham et al. [2] showed in 2006 that there are
ǫ-(k, t)-robust protocols that implement mediators with
synchronous cheap-talk if n > k + 2t, to later extend it in
2019 to ǫ-(k, t)-robust protocols that implement mediators
with asynchronous cheap-talk for n > 3(k + t).

Since it is well known that it is impossible to imple-
ment a 1-immune protocol that solves consensus in the
asynchronous model [20, 12], Ranchal-Pedrosa et al. [23]
devised the Huntsman protocol, a protocol that is ǫ-
(k, t)-robust and implements the consensus problem with
n > max( 3
2 k + 3t, 2(k + t)), which is the highest robustness
to date in the presence of Byzantine players and coalitions
of rational players that may be interested in causing dis-
agreement. Our result implies that the Huntsman protocol
is ǫ-(k + t, t)-crash-robust for n > max( 3
2 k + 3t, 2(k + t)).
Other works have also explored the other properties
of the consensus problem (besides the agreement prop-
erty). Added to the works that focused on fairness, Vila¸ca
et al. [25, 26] and Amoussou-guenou et al. [4] focus on
the properties of termination and validity in a model
where communication and local computation incur a non-
negligible cost for players, and disregarding potential in-
terests of rational players in causing a disagreement. Abra-
ham et al. [3] explore the problem of leader election by re-
deﬁning fairness in the sense of a randomized dictatorship
in which all players have equal probability of being elected.

This protocol can also be used to solve fair consensus.

To the best of our knowledge, we present the ﬁrst
work that obtains bounds for the robustness of agreement
against coalitions of crash and rational players in partial
synchrony, and that establishes constructively direct re-
lations between (k, t)-robust protocols and (k′, t′)-crash-
robust protocols.

1.2 Roadmap

The rest of the paper is structured as follows: Section 2
presents our model and deﬁnitions taken from the litera-
ture, Section 3 shows the impossibility of resilient-optimal
crash-fault tolerance in the presence of rational players.
Section 4 establishes the relation between Byzantine play-
ers with rational players and crash players, ﬁrst by showing
in Section 4.1 that for every Byzantine player tolerated by
a consensus protocol, the same protocol can instead toler-
ate one rational player and one crash player, and second
by showing in Section 4.2 that if a consensus protocol tol-
erates k rational players and t crash players then there
is a consensus protocol that tolerates min(k, t) Byzantine
players. We ﬁnally conclude and detail future work in
Section 5.

2 Preliminaries

Our focus is on a partially synchronous communication
network [8], where messages can be delayed by up to a
bound that is unknown, but not indeﬁnitely. For this pur-
pose, we adapt the synchronous and asynchronous models
of Abraham et al. [2, 1] to partial synchrony, including the
deﬁnitions of Halpern et al. [18] to introduce crash play-
ers, with the appropriate modiﬁcations to account for par-
tial synchrony [23]. Hence, our model consists of a game
played by a set N of players, with |N | = n. The players in
N can be of four diﬀerent types: correct, rational, crash
or Byzantine.

In order to model partial synchrony, we introduce the
scheduler as an additional player that will model the delay
on messages derived from partial synchrony. The game is
in extensive form, described by a game tree whose leaves
are labeled by the utility ui of each player i. We assume
that players alternate making moves with the scheduler :
ﬁrst the scheduler moves, then a player moves, then the

3

scheduler moves and so on. The scheduler’s move consists
of choosing a player i to move next and a set of messages
in transit targeting i that will be delivered just before i
moves (so that i’s move can depend on all the messages i
receives). Every non-leaf tree node is associated with ei-
ther a player or the scheduler. The scheduler is bound to
two constraints. First, the scheduler can choose to delay
any message up to a bound, known only to the scheduler,
before which he must have chosen all receivers of the mes-
sage to move and provided them with this message, so
that they deliver it before making a move. Second, the
scheduler must eventually choose all players that are still
playing. That is, if player i is playing at time e, then the
scheduler chooses him to play at time e′ ≥ e.

Each player i has some local state at each node, which
translates into the initial information known by i, the mes-
sages i sent and received at the time that i moves, and the
moves that i has made. The tree nodes where a player i
moves are further partitioned into information sets, which
are sets of nodes in the game tree that contain the same
local state for the same player, in that such player cannot
distinguish them. We assume that the scheduler has com-
plete information, so that the scheduler’s information sets
simply consist of singletons.

Since faulty or rational players can decide not to move
during their turn, we assume that players that decide not
to play will at least play the default-move, which consists
of notifying to the scheduler that this player will not move,
so that the game continues with the scheduler choosing
the next player to move. Thus, in every node where the
scheduler is to play a move, the scheduler can play any
move that combines a player and a subset of messages that
such player can deliver before playing. Then, the selected
player moves, after which the scheduler selects again the
next player for the next node, and the messages it receives,
and so on. The scheduler thus alternates with one player
at each node down a path in the game tree up to a leaf. A
run of the game is then a path in the tree from the root
to a leaf.

Strategies We denote the set of actions of a player i
(or the scheduler) as Ai, and a strategy σi for that set of
actions is denoted as a function from i’s information sets
to a distribution over the actions.

We denote the set of all possible strategies of player i as

Si. Let SI = Πi∈I Si and AI = Πi∈I Ai for a subset I ⊆ N .
Let S = SN with A−I = Πi6∈I Ai and S−I = Πi6∈I Si. A
#»
joint strategy
σ = (σ0, σ1, ..., σn−1) draws thus a distri-
bution over paths in the game tree (given the scheduler’s
#»
σ , σs) is player’s i expected util-
strategy σs), where ui(
#»
ity if
σ is played along with a strategy for the sched-
uler σs. A strategy θi strictly dominates τi for i if for all
#»
φ −i ∈ S−i and all strategies σs of the scheduler we have
ui(θi,

#»
φ −i, σs) > ui(τi,

#»
φ −i, σs).

Given some desired functionality F , a protocol is the
#»
recommended joint strategy
σ whose outcome satisﬁes F ,
and an associated game Γ for that protocol is deﬁned as
all possible deviations from the protocol [2]. In this case,
#»
we say that the protocol
σ implements the desired func-
tionality. Note that both the scheduler and the players
can use probabilistic strategies.

Failure model k players out of n can be rational and
up to t of them can be faulty (i.e. Byzantine or crash),
while the rest are correct. Correct players follow the pro-
tocol: the expected utility of correct player i is equal and
positive for any run in which i follows the protocol, and 0
for any other run. Rational players can deviate to follow
the strategy that yields them the highest expected utility
at any time they are to move, while Byzantine players can
deviate in any way, even not replying at all (apart from
notifying the scheduler that they will not move). A crash
player i behaves exactly as a correct player, except that it
can crash in any round of any run. If i crashes in round
m of run r, then it may send a message to some subset of
agents in round m, but from then on, it sends no further
messages (except for playing the default-move). We will
detail further the utilities of rational players after deﬁning
the Byzantine consensus problem.

We let rational players in a coalition and Byzantine
players (in or outside the coalition) know the types of all
players, so that these players know which players are the
other faulty, rational and correct players, while the rest of
the players only know the upper bounds on the number
of rational and faulty players, i.e., k and t respectively,
and their own individual type (that is, whether they are
rational, Byzantine, crash or correct).

Cheap talks As we are in a fully distributed system,
without a trusted central entity like a mediator, we as-

4

sume cheap-talks, which are private pairwise communica-
tion channels. We also assume negligible communication
cost through these channels. Rational and correct players
are not interested in the number of messages exchanged.
Similarly, we assume the cost of performing local computa-
tions (such as validating proposals, or verifying signatures)
to be negligible.

Cryptography We require the use of cryptography, for
which we reuse the assumptions of Goldreich et al. [15]:
polynomially bounded players and the enhanced trapdoor
permutations.
In practice, these two assumptions mean
that players can sign unforgeable messages, and that they
can perform oblivious transfer.

Robustness We restate Abraham’s et al. [2] deﬁnitions
of t-immunity, ǫ-(k, t)-robustness and the most recent deﬁ-
nition of k-resilient equilibrium [1] to consider multiplayer
deviations. We also add the deﬁnitions of t-crash-immune
and (k, t)-crash-robust equilibrium. Notice that our def-
inition of (k, t)-crash-robust equilibrium diﬀers from Bei
et al’s (c, t)-resilient equilibrium, since we simply extend
Abraham et al’s [2] deﬁnition of a (k, t)-robust equilib-
rium. While this deﬁnition is too restrictive for Bei et al’s
model, it ﬁts properly our illustration of the utilities of
the rational players that we deﬁne in this work.

The notion of k-resilience is motivated in distributed
computing by the need to tolerate a coalition of k rational
players that can all coordinate actions. A joint strategy is
k-resilient if no coalition of size k can gain greater utility
by deviating in a coordinated way.

Deﬁnition 2.1 (k-resilient equilibrium). A joint strategy
#»
σ ∈ S is a k-resilient equilibrium (resp. strongly k-resilient
equilibrium) if, for all sets K of rational players such that
#»
K ⊆ N with |K| ≤ k, all
τ K ∈ SK, all strategies σs of
the scheduler, and for some (resp. all) i ∈ K we have:
#»
σ −K, σs).
ui(

#»
σ −K, σs) ≥ ui(

#»
σ K,

#»
τ K,

The notion of t-immunity is motivated by the need to
tolerate t faulty players. An equilibrium is t-immune if the
expected utility of the non-faulty players is not aﬀected by
the actions of up to t other faulty players. The ǫ here ac-
counts for the (small) probability of the coalition breaking
cryptography, as previously assumed in the literature [2]:

5

#»
Deﬁnition 2.2 (ǫ-t-immunity). A joint strategy
σ ∈ S
is ǫ-t-immune if, for all sets T of Byzantine players such
#»
τ ∈ ST , all strategies σs of
that T ⊆ N with |T | ≤ t, all
#»
#»
the scheduler, and all i 6∈ T , we have: ui(
τ T , σs) ≥
σ −T ,
ui(

#»
σ , σs) − ǫ.

A joint strategy

#»
σ is an ǫ-(k, t)-robust equilibrium if no
coalition of k rational players can coordinate to increase
their expected utility by ǫ regardless of the arbitrary be-
havior of up to t faulty players, even if the faulty players
join their coalition.

Deﬁnition 2.3 (ǫ-(k, t)-robust equilibrium). Let K de-
note the set of |K| = k rational players and let T denote
the set of |T | ≤ t Byzantine players, K ∩ T = ∅. A joint
#»
σ ∈ S is an ǫ-(k, t)-robust equilibrium if for all
strategy
#»
#»
K, T ⊆ N , for all
φ K ∈ SK , and all
τ T ∈ ST , for all
strategies of the scheduler σs, there exists i ∈ K such
that:

#»
σ −T ,

#»
τ T , σs) ≥ ui(

#»
σ N −(K∪T ),

ui(

#»
φ K,

#»
τ T , σs) − ǫ.

If ǫ = 0, we simply refer to an ǫ-(k, t)-robust equilibrium
as a (k, t)-robust equilibrium, and an ǫ-t-immune protocol
as a t-immune protocol.

#»
σ is a k-resilient protocol for F if

Given some game Γ and desired functionality F , we say
#»
σ im-
that a protocol
plements F and is a k-resilient equilibrium. We extend
this notation to t-immunity and ǫ-(k, t)-robustness. The
required functionality of this paper is thus reaching con-
sensus.

Punishment and baiting strategy We also restate
the deﬁnition of a punishment strategy [2] as a threat from
correct and rational players in order to prevent other ra-
tional players from deviating. For example, in a society,
this threat can be viewed as a punishment strategy of the
judicial system against committing a crime. Slashing a
player if he is found to be guilty of deviating is another
punishment strategy.

The punishment strategy guarantees that if k rational
players deviate, then t + 1 players can lower the utility of
these rational players by playing the punishment strategy.

2.4

Deﬁnition
strategy). Let
K, T, P ⊆ N be disjoint sets of rational players, Byzan-
tine players and correct players, respectively, such that

((k, t)-punishment

#»
ρ is a
|K| ≤ k, |T | ≤ t, |P | > t. A joint strategy
#»
(k, t)-punishment strategy with respect to
σ if for all
#»
φ K ∈ SK, for all i ∈ K, and all strategies of the scheduler
σs, we have:

#»
σ −T ,

#»
τ T , σs) > ui(

#»
σ N −(K∪T ∪P ),

ui(

#»
φ K,

#»
τ T ,

#»
ρ P , σs)

Intuitively, a punishment strategy represents a threat
to prevent rational players from deviating, in that if they
deviate, then players in P can play the punishment strat-
#»
egy
ρ , which decreases the utility of rational players with
respect to following the strategy

#»
σ .

Recent works consider a particular type of punishment
strategies, deﬁned as baiting strategies [23].
In baiting
strategies, some players that enforce the punishment on
the deviants are rational players from within the coali-
tion: they have an incentive to bait other players into a
punishment strategy. An example of a baiting strategy
can be found when law-enforcement oﬃcers oﬀer an eco-
nomic reward, or a reduced sentence, if a member of a
criminal group helps them arrest the rest of the group.

Deﬁnition 2.5 ((k, t, m)-baiting strategy). Let K, T ⊆ N
be disjoint sets of rational players and Byzantine players,
respectively. Let P ⊆ N be a set of baiters, composed
of rational and correct players, and let the rest of correct
#»
η is
players be C = N − (K ∪ T ∪ P ). A joint strategy
#»
σ if
a (k, t, m)-baiting strategy with respect to a strategy
#»
#»
η is a (k − m, t)-punishment strategy with respect to
σ ,
with 0 < m ≤ k, |K| ≤ k, |T | ≤ t, |P | > t, |P ∩ K| ≥ m,
#»
#»
θ P ∈ SP ,
for all
φ K\P ∈ SK\P − {
all i ∈ P , and all strategies of the scheduler σs, we have:

#»
τ ∈ ST , all

#»
σ K}, all

#»
σ C ,

ui(

#»
φ K\P ,

#»
τ T ,

#»
η P , σs) ≥ ui(

#»
σ C ,

#»
φ K\P ,

#»
τ T ,

#»
θ P , σs)

Additionally, we call this strategy a strong (k, t)-baiting
strategy in the particular case where for all rational coali-
tions K ⊆ N such that |K| ≤ k + f , |K ∩ P | ≥ m and all
#»
φ K\P ∈ SK\P , we have:

#»
σ N −(K∪P ),

ui(

#»
φ K\P ,

X
i∈K

#»
η P , σs) ≤ X
i∈K

#»
σ , σs).

ui(

We write (strong) (k, t)-baiting strategy instead to refer
to a (strong) (k, t, m)-baiting strategy for some m, with
0 < m ≤ k.

We also refer to an eﬀective baiting strategy if playing
such strategy still implements the desired functionality.
An example of an eﬀective baiting strategy for the problem
of consensus is rewarding a baiter for exposing a disagree-
ment attempt before it takes place, if it is resolved [23].
Strong baiting strategies are strategies in which the coali-
tions formed entirely by rational players end up collec-
tively losing compared to if they had just followed the
protocol, even if a subset of them play the baiting strat-
egy. This prevents coalitions from baiting themselves just
for the purpose of maximizing the sum of their utilities.

We extend the above-deﬁned terms to their analo-
gous crash fault tolerant counterparts by replacing Byzan-
tine players by crash players in all their deﬁnitions,
in what we refer to as (t)-crash-immunity, (k, t)-crash-
robustness, (k, t)-crash-punishment strategy and (k, t, m)-
crash-baiting strategy.

Consensus We recall the Byzantine consensus prob-
lem [20] in the presence of rational players: The Byzan-
tine consensus problem is, given n players, each with an
initial value, to ensure (1) Agreement, in that no two non-
deviating players decide diﬀerent values, (2) Validity in
that if a non-deviating player decides a value v, then v
has been proposed by some player, and (3) Termination
in that all non-deviating players eventually decide.

Disagreements Notice a disagreement of consensus can
mean two or more disjoint groups of non-deviating players
deciding two or more conﬂicting decisions [24]. We speak
of the disagreeing strategy as the strategy in which devi-
ating players collude to produce a disagreement, and of a
coalition disagreeing to refer to a coalition that plays the
disagreeing strategy.

Rational players The utilities of a rational player i de-
pending on its actions and a particular run of the protocol
are as follows:

1. If an agreement is reached,
#»
τ T ) ≥ ǫ where ǫ > 0.

#»
σ −T ,

ui(

then i gets utility

2. If coalition where i

performs a disagreement,
#»
φ K∪T ) = g > ǫ.
ui(

#»
σ N −K−T ,

6

is a member

successfully
then i gets utility

3. If the protocol does not terminate, then i obtains a

negative utility.

4. If player i suﬀers a disagreement caused by a coalition

external to i, then i obtains a negative utility.

Note that we do not consider fairness of consensus, com-
putational costs, communication costs, or a preference
from a proposal over another, but we rather focus on the
interests in causing a disagreement. As such, setting the
expected utility of causing agreement to be greater than
that of causing disagreement would inevitably lead to ra-
tional players behaving exactly as correct players. Simi-
larly, selecting the utilities of not terminating greater than
the utilities of causing agreement would lead to all ratio-
nal players behaving as crash players. For both of these
cases, the state-of-the-art bounds are applicable. The set
of utilities that we choose here also reﬂects a realistic be-
havior of rational players in the blockchain context, where
players can get an economic incentive from a fork (as it is
the case when they double spend by forking). It is easy
to notice that not terminating as well as deciding a pro-
posal while a coalition causes a disagreement are strictly
dominated by reaching agreement, which is in turn strictly
dominated by causing a disagreement. A baiting strategy
means a rational player possibly joining the coalition only
to later betray it in exchange of a reward. This additional
strategy would strictly dominate the strategy to disagree
by deﬁnition.

3

Impossibility result

In this section, we show that resilient-optimal protocols
cannot tolerate even one rational player. Previous results
showed that a resilient-optimal protocol tolerates up to
t < n/2 crash faults [8]. We show in Lemma 3.1 and
Theorem 3.2 that this number of crash faults does not
tolerate even one rational player.

#»
Lemma 3.1. Let
σ be a protocol that implements con-
sensus such that there is no (k, t, m)-crash-baiting strategy
#»
σ to be t-
with respect to
crash-immune and k-resilient for k + 2t ≥ n, m > k−n
2 + t.

#»
σ . Then, it is impossible for

Proof. If a protocol is t-crash-immune, that means that
the protocol must terminate even if t players do not par-

ticipate in it at all, since t players may have crashed from
the beginning. Therefore, the protocol must terminate
and decide with the participation of n − t players.

Since the protocol must be able to terminate with the
participation of at most n − t players, consider now that
there are no crash players and there are exactly k rational
players. Let us ﬁnd a disjoint partition of correct players
A and B such that k + |A| + |B| = n. If k + |A| ≥ n − t
and k + |B| ≥ n − t then the k rational players can cause a
disagreement, which can occur if k + 2t ≥ n. There is only
left to prove that k rational players will try to cause a dis-
agreement. For this, let us consider the minimum number
of rational players m that must not try to cause a disagree-
ment for the remaining deviating rational players to not
be able to cause a disagreement. That is, for which values
we have k − m + |A| < n − t and k − m + |B| < n − t, hence
resulting in m > k−n
2 + t. Therefore, the utilities for ratio-
nal players from causing a disagreement are greater than
from causing agreement. This means that at least enough
rational players will deviate and cause the disagreement
unless there is a (k, t, m)-baiting strategy that prevents m
rational players from deviating into a disagreement.

The next theorem follows directly from Lemma 3.1 be-
cause every (k, t)-crash-robust protocol must also be t-
crash-immune and k-resilient.

#»
Theorem 3.2. Let
σ be a protocol that implements con-
sensus such that there is no (k, t)-crash-baiting strategy
#»
#»
with respect to
σ to be (k, t)-
σ . Then, it is impossible for
crash-robust for k + 2t ≥ n.

#»
Corollary 3.3. Let
σ be a protocol that implements con-
sensus such that there is no (1, t)-crash-baiting strategy
#»
with respect to
σ and is t-crash-immune for t < n/2.
#»
σ is not 1-resilient.
Then,

The results from Lemma 3.1, Theorem 3.2 and Corol-
lary 3.3 show that it is necessary to consider new bounds
for CFT protocols in terms of their crash-fault tolerance,
since their resilient-optimal bounds make them vulnera-
ble to even one rational player for state-of-the-art proto-
cols, because they do not consider oﬀering a crash-baiting
strategy. In Section 4, we explore the link between crash-
robustness and immunity, so as to obtain results for this
model with the existing protocols designed for Byzantine
faults.

7

4 Bridging the gap: crash and ra-
tional players as Byzantine play-
ers

In this section we bridge the gap between games that are
robust against Byzantine players and games that are ro-
bust against crash players.

4.1 From Byzantine to crash players

It is immediate that a protocol that tolerates up to t
Byzantine faults also tolerates up to t crash faults, the
question lies with the inclusion of rational players. We
propose in Lemma 4.1 a ﬁrst relation between Byzantine
fault tolerance and crash-fault tolerance in the presence of
rational players.

Lemma 4.1. Let
sensus and is ǫ-s-immune. Then
robust.

#»
σ be a protocol that implements con-
#»
σ is also ǫ-(s, s)-crash-

Proof. We prove this by contradiction. Let r be the mini-
mum number of players that must participate in the pro-
tocol for it to terminate, it is clear that r ≤ N − s since
the protocol is ǫ-s-immune. As such, let A and B be
two disjoint sets of correct players. Since the protocol
must also guarantee agreement, it follows by contradic-
tion that if agreement was not satisﬁed then |A| + s ≥ r
and |B| + s ≥ r, but this is only possible if r ≤ n+s
2 .
Therefore, we have N − s ≥ r > n+s
2 .

We deﬁne sc ≤ s and sk ≤ s as the maximum combined
values of tolerated crash and rational faults, respectively.
It is immediate that termination is guaranteed, since ra-
tional players will participate and r ≤ N − s ≤ N − sc.
For agreement, we have |A| + |B| + sc + sk < n, with
sc ≤ s and sk ≤ s. We consider that sc crash players
crash after having sent some messages only to players in
|A| and the sk rational players, which is the best-case for
the deviating coalition (otherwise they crash sending the
same message to the entire set of correct players and thus
they do not contribute to disagreeing). For the sk ra-
tional players to lead players in B to a diﬀerent decision
than the decision of players in A plus the crash players
sc, both sk + sc + |A| ≥ r and sk + |B| ≥ r must hold.
This means that |A| + |B| + 2sk + sc ≥ 2r ⇐⇒ n + sk ≥
2r ⇐⇒ n+s
2 ≥ r, however, this is a contradiction: we

#»
already showed that n+s
σ to be ǫ-s-immune.
2 < r for
It follows that if a protocol that implements consensus is
ǫ-s-immune then it is also ǫ-(s, s)-crash-robust.

Notice that the statement of Lemma 4.1 does not re-
quire to assume cryptography, and thus the same result
takes place by considering ǫ = 0, i.e., (k, t)-robustness.
The same occurs with Theorem 4.2. Lemma 4.1 es-
tablishes a surprising yet meaningful relation between t-
immunity and (k, t)-crash-robustness, further extended by
Theorem 4.2:
if a protocol is (k, t)-robust then it is also
(k+t, t)-crash-robust. We omit the proofs of Theorems 4.2
and 4.3 as they are analogous to that of Lemma 4.1.

Theorem 4.2. Let
sensus and is ǫ-(k, t)-robust. Then,
crash-robust.

#»
σ be a protocol that implements con-
#»
σ is also ǫ-(k + t, t)-

By Lemma 4.1 and Theorem 4.2,

it is possible to
take existing protocols, bounds and other results that
apply to immunity and robustness and apply them di-
rectly to crash-immunity and crash-robustness. Moreover,
Lemma 4.1 establishes a parametrizable hierarchy between
crash faults and Byzantine faults:
for every Byzantine
fault tolerated by a protocol that solves consensus, the
same protocol tolerates instead one crash fault and one
rational player.

Interestingly, an analogous proof provides the same re-
sult for a protocol that tolerates instead crash and Byzan-
tine players. We show this result in Theorem 4.3. How-
ever, we ﬁrst deﬁne ǫ-(t′, t)-immunity to combine tolerance
to a number of crash and Byzantine players together:

#»
Deﬁnition 4.1 (ǫ-(t′, t)-immunity). A joint strategy
σ ∈
S is ǫ-(t, t′)-immune if, for all sets T of Byzantine players
such that T ⊆ N with |T | ≤ t, all sets T ′ of crash players
#»
such that T ′ ⊆ N , T ∩ T ′ = ∅, all
θ ∈ ST ′ , all
strategies σs of the scheduler, and all i 6∈ T ∪ T ′, we have:

#»
τ ∈ ST , all

#»
σ −{T ∪T ′},

ui(

#»
θ T ′ , σs) ≥ ui(

#»
τ T ,
#»
σ be a protocol that implements con-
#»
σ is also ǫ-(t, t′ +t)-

#»
σ , σs) − ǫ.

Theorem 4.3. Let
sensus and is ǫ-(t′, t)-immune. Then,
crash-robust.

4.2 From crash to Byzantine players

One may wonder if the same result listed in Lemma 4.1 is
true in the opposite direction, that is, whether a protocol

8

#»
σ that is ǫ-(k, t)-crash-robust is also ǫ-fun(k, t)-immune
where fun(k, t) = s for some s > 0.

We prove in Lemma 4.4 that we can construct a pro-
tocol that implements consensus and is ǫ-s-immune based
on a protocol that is ǫ-(k, t)-crash-robust for s = min(k, t),
assuming cryptography and that the protocol does not im-
plement a (k, t)-crash-baiting strategy.

#»
Lemma 4.4. Let
σ be an ǫ-(k, t)-crash-robust protocol
that implements consensus without a (k, t)-crash-baiting
#»
strategy with respect to
σ . Then, assuming cryptogra-
phy and a public-key infrastructure scheme, there is an
#»
σ ′ that implements consen-
ǫ-min(k, t)-immune protocol
sus.

#»
Proof. We show how we create the protocol
σ to
tolerate the new deviations that Byzantine players can fol-
low. We list the possible deviations of t Byzantine players
in a protocol

#»
σ ′ from

#»
σ ′:

1. Byzantines players force disagreement by sending

equivocating messages.

2. Byzantine players stop replying.

3. Byzantine players reply only to a subset of the correct

players.

4. Byzantine players reply wrongly formatted messages.

5. Byzantine players force non-termination by sending

equivocating messages.

6. Byzantine players force non-decision (empty decision)

by sending equivocating messages.

#»
σ already tolerates coalitions of up to min(k, t)
Protocol
players following deviation 2, since t crash players can stop
replying. For deviation 1, we show that if the k rational
players are not enough to cause a disagreement, then k
Byzantine players would also not be enough. Consider
instead that k rational players can make a coalition big
enough to cause a disagreement, then it is clear that they
would cause a disagreement unless there is a (k, t)-crash-
baiting strategy that prevents it, by deﬁnition. Therefore,
#»
σ does not implement a (k, t)-crash-baiting strategy,
since
if the protocol tolerates k rational players trying to deviate
then it also tolerates deviation 1 from Byzantine players.
#»
σ ′ to be robust against
We now show how to construct

the rest of the deviations. To tolerate deviation 4, correct
#»
σ ′ ignore wrongly formatted messages, convert-
players in
ing deviation 4 into the same deviation as 2. Now, we
consider deviations 5 and 6. Since up to min(k, t) rational
players cannot force a disagreement, these players would
not even deviate to not terminate or to not decide (their
expected utilities from playing such strategies is less than
#»
from following
σ ), however, min(k, t) Byzantine players
can have a greater expected utility from such deviations.
First, we require every player to broadcast any signed
message newly delivered. This makes deviation 3 not a
deviation anymore, since every correct player eventually
veriﬁes and delivers all messages. Also, in the event of
an impasse between two partitions (that is, deviations 5
and 6), this makes it possible for correct players to gather
enough evidence of which processes are responsible for
such an event, in that they signed conﬂicting messages.
#»
σ decides an empty proposal in the absence
If protocol
#»
σ ′ so that it instead re-
of agreement, then we construct
peats the protocol in a new round. This way, we make
deviations 5 and 6 the same deviation.

What is left to prove is that it is impossible for a coali-
tion of up to min(k, t) Byzantine players to force non-
termination by leading correct players into a next round
sending equivocating messages. For this purpose, recall
that every message sent to a non-empty subset of correct
players eventually reaches all correct players since they
all broadcast all signed messages they each deliver. As
such, correct players are eventually able to gather two
conﬂicting, equivocating messages from each of the de-
viating players, identifying such set as responsible for the
attempted equivocation. Thus, we describe the ﬁnal mod-
#»
iﬁcation of
σ : once a correct player i
identiﬁes (via conﬂicting signed messages) a player j that
sent equivocating messages, i ignores any message coming
directly from j from that moment on. Notice that this
modiﬁcation thus converts deviations 5 and 6 into either
#»
σ ′ tolerates
deviation 3 or 2, and we already showed that
such deviations as long as the number of Byzantine play-
ers is at most min(k, t). Therefore, we have constructed
#»
#»
σ′ extending
σ so that every above-shown deviation from
up to min(k, t) Byzantine players converts into a deviation
#»
σ′ is ǫ-min(k, t)-
that
immune.

#»
σ already tolerates, meaning that

#»
σ ′ with respect to

Lemma 4.4 establishes a relation in the opposite direc-

9

tion from Lemma 4.1. We conjecture that this is possible
to prove even without the help of cryptography. Never-
#»
theless, we do need to restrict the protocol
σ to be ǫ-
(k, t)-crash-robust without the help of (k, t)-crash-baiting
strategies. This is because we can only consider k rational
players that behave as Byzantine faults in terms of equiv-
ocation, that is, that try to cause a disagreement. The ex-
istence of a (k, t)-crash-baiting strategy means that some
rational players will not try to cause a disagreement, and
thus we could not rule out deviation 2 as a deviation that
Byzantine players can follow in order to break safety.

We show in Theorem 4.5 the analogous result to
Lemma 4.4 as Theorem 4.2 is to Lemma 4.1. The
proofs of theorems 4.5 and 4.7 are analogous to that of
Lemma 4.4.

#»
Theorem 4.5. Let
σ be an ǫ-(k, t)-crash-robust protocol
that implements consensus without a (k, t)-crash-baiting
#»
strategy with respect to
σ , where k ≥ t. Then, assum-
ing cryptography and a public-key infrastructure scheme,
#»
σ ′ that implements
there is an ǫ-(k − t, t)-robust protocol
consensus.

Theorem 4.5 excludes protocols that make use of a (k, t)-
#»
η to be ǫ-(k, t)-crash-robust, we
crash-baiting strategy
#»
show in Theorem 4.6 that if
η is both an eﬃcient (k, t)-
crash-baiting strategy and an eﬃcient (k, t)-crash-baiting
strategy, then there is a protocol that is ǫ-(k − t, t)-robust.

#»
Theorem 4.6. Let
σ be an ǫ-(k, t)-crash-robust proto-
col that implements consensus such that there is an ef-
#»
ﬁcient (k, t)-crash-baiting strategy
σ ,
#»
σ , assuming
where k ≥ t. Let
cryptography and a public-key infrastructure scheme.
If
#»
η′ is also an eﬃcient (k − t, t)-baiting
there is
#»
σ′ is an ǫ-(k − t, t)-robust
strategy with respect to
protocol that implements consensus.

#»
σ′ be the BFT-extension of

#»
η with respect to

#»
η′ such that

#»
σ′, then

Proof. The proof is analogous to that of Lemma 4.4, with
#»
η ′ is an eﬃcient (k − t, t)-baiting
the addition that since
#»
#»
σ′, in every scenario where
η is
strategy with respect to
#»
#»
#»
η′ is
σ′, and since
played in
σ , then
eﬃcient, it implements consensus.

#»
η′ is also played in

is trivial from Theorem 3.2 that k + 2t < n and thus
min(k, t) < n/3. The state of the art has already shown
protocols that are s-immune for s < n/3.

Again, notice that the results from Theorems 4.5 and 4.6
assume k ≥ t, if instead t ≥ k, then we obtain the result
from theorems 4.7, for which we reuse the deﬁnition of
ǫ-(t, t′)-immunity from Section 4.1.

#»
Theorem 4.7. Let
σ be an ǫ-(k, t)-crash-robust protocol
that implements consensus without a (k, t)-crash-baiting
#»
strategy with respect to
σ , where t ≥ k. Then, assum-
ing cryptography and a public-key infrastructure scheme,
#»
σ ′ that implements
there is an ǫ-(t−k, k)-immune protocol
consensus.

5 Conclusion & Future Work

In this paper, we showed two interesting relations between
types of faults in the solvability of the rational agreement.
First, if a consensus protocol is ǫ-(k, t)-robust then it is
also ǫ-(k + t, t)-crash-robust, meaning that in the absence
of irrational (Byzantine) players, one can tolerate coali-
tions with t additional rational players. Second, with cryp-
tography but in the absence of a baiting strategy then we
can devise a ǫ-(k −t, t)-robust consensus protocol from a ǫ-
(k, t)-crash-robust consensus protocol. We also prove that
if a protocol is ǫ-(t′, t)-immune, then it is also ǫ-(t, t′ + t)-
#»
crash-robust, and that if a protocol
σ is ǫ-(k, t)-crash-
robust, where t ≥ k, then there is an ǫ-(t − k, k)-immune
#»
σ ′ that implements consensus, excluding bait-
protocol
ing strategies. We can conclude, thanks to the results
here outlined, that the Huntsman protocol [23] yields the
greatest crash-robustness to date under this model, as it
is (k + t, t)-crash-robust for n > max( 3

2 k + 3t, 2(k + t)).

Future work includes exploring values of robustness and
crash-robustness in variations of this model, such as dif-
ferent assumptions on the communication network, and
including the property of fairness for fair consensus.

References

We make use of cryptography in Lemma 4.4 in or-
der to oﬀer a constructive proof that is useful for both
Theorem 4.5 and Theorem 4.6. Notice however that it

[1] Ittai Abraham, Danny Dolev,

Ivan Geﬀner, and
Joseph Y. Halpern.
Implementing mediators with
asynchronous cheap talk. In Proceedings of the 2019

10

ACM Symposium on Principles of Distributed Com-
puting, PODC ’19, page 501–510, New York, NY,
USA, 2019. Association for Computing Machinery.
doi:10.1145/3293611.3331623.

[2] Ittai Abraham, Danny Dolev, Rica Gonen, and Joe
Halpern. Distributed computing meets game the-
ory: Robust mechanisms for rational secret sharing
and multiparty computation. In PODC, pages 53–62,
2006.

[3] Ittai Abraham, Danny Dolev, and Joseph Y. Halpern.
Distributed protocols for leader election: A game-
theoretic perspective. ACM Trans. Econ. Comput.,
7(1), 2019.

[4] Yackolley Amoussou-guenou, Bruno Biais, Maria
Sara Tucci-
F Paris,
and
Potop-butucaru,
piergiovanni.
Rational vs Byzantine Players in
Consensus-based Blockchains. Proceedings of the
19th
on Autonomous
Agents and MultiAgent Systems, pages 43–51, 2020.

International Conference

[5] Xiaohui Bei, Wei Chen, and Jialin Zhang. Distributed
consensus resilient to both crash failures and strate-
gic manipulations. arXiv preprint arXiv:1203.4324,
2012.

[10] Parinya Ekparinya, Vincent Gramoli, and Guillaume
Impact of man-in-the-middle attacks on
Jourjon.
ethereum.
In 2018 IEEE 37th Symposium on Reli-
able Distributed Systems (SRDS), pages 11–20, 2018.
doi:10.1109/SRDS.2018.00012.

[11] Parinya Ekparinya, Vincent Gramoli, and Guillaume
Jourjon. The attack of the clones against proof-of-
authority. NDSS Symposium, 2020.

[12] Michael J Fischer, Nancy A Lynch, and Michael S
Paterson. Impossibility of distributed consensus with
one faulty process. Journal of the ACM (JACM),
32(2):374–382, 1985.

[13] Georg Fuchsbauer, Jonathan Katz, and David Nac-
cache. Eﬃcient rational secret sharing in standard
communication networks. In Proceedings of the 7th
International Conference on Theory of Cryptography
(TCC), page 419?436, 2010.

[14] Ivan Geﬀner and Joseph Y. Halpern. Lower bounds
implementing mediators in asynchronous systems,
2021. arXiv:2104.02759.

[15] Oded Goldreich, Silvio Micali, and Avi Wigderson.
How to play any mental game. In Annual ACM Sym-
posium on Theory of Computing, 1987.

Rational

[6] A. Clementi, L. Gual`a, G. Proietti, and G. Scor-
navacca.
fair consensus in the gossip
model. In 2017 IEEE International Parallel and Dis-
tributed Processing Symposium (IPDPS), pages 163–
171, 2017. doi:10.1109/IPDPS.2017.67.

[16] Adam Groce, Jonathan Katz, Aishwarya Thiruven-
gadam, and Vassilis Zikas. Byzantine agreement with
a rational adversary. In International Colloquium on
Automata, Languages, and Programming, pages 561–
572. Springer, 2012.

[7] Varsha Dani, Mahnush Movahedi, Yamel Rodriguez,
and Jared Saia. Scalable rational secret sharing. In
PODC, pages 187–196, 2011.

[8] Cynthia Dwork, Nancy Lynch, and Larry Stock-
meyer. Consensus in the presence of partial syn-
chrony. Journal of the ACM (JACM), 35(2):288–323,
1988.

[9] Zahra Ebrahimi, Bryan Routledge, and Ariel Zetlin-
Jones. Getting blockchain incentives right. Technical
report, Tech. rep., Carnegie Mellon University Work-
ing Paper, 2019.

[17] Joseph Y. Halpern and Xavier Vila¸ca. Rational con-
sensus: Extended abstract. In Proceedings of the 2016
ACM Symposium on Principles of Distributed Com-
puting, PODC ’16, page 137–146, New York, NY,
USA, 2016. Association for Computing Machinery.
doi:10.1145/2933057.2933088.

[18] Joseph Y. Halpern and Xavier Vila¸ca. Rational con-
sensus: Extended abstract. In Proceedings of the 2016
ACM Symposium on Principles of Distributed Com-
puting, PODC ’16, page 137–146, New York, NY,
USA, 2016. Association for Computing Machinery.
doi:10.1145/2933057.2933088.

11

23rd

editors,

Consensus

[19] Itay Harel, Amit Jacob-Fanani, Moshe Sulamy,
in Equilibrium:
and Yehuda Afek.
Can One Against All Decide Fairly?
In Pascal
Felber, Roy Friedman, Seth Gilbert, and Avery
International Conference
Miller,
on Principles of Distributed Systems
(OPODIS
2019), volume 153 of Leibniz International Pro-
ceedings in Informatics (LIPIcs), pages 20:1–20:17,
2020. Schloss Dagstuhl–
Dagstuhl, Germany,
Leibniz-Zentrum fuer Informatik. URL: https://
drops.dagstuhl.de/opus/volltexte/2020/11806,
doi:10.4230/LIPIcs.OPODIS.2019.20.

[26] Xavier Vila¸ca, Jo˜ao Leit˜ao, and Lu´ıs Rodrigues. N-
party bar transfer: Motivation, deﬁnition, and chal-
lenges. In Proceedings of the 3rd International Work-
shop on Theoretical Aspects of Dynamic Distributed
Systems, TADDS ’11, page 18–22, New York, NY,
USA, 2011. Association for Computing Machinery.
doi:10.1145/2034640.2034647.

[20] Leslie Lamport, Robert Shostak, and Marshall Pease.
The Byzantine generals problem. ACM Trans. Pro-
gram. Lang. Syst., 4(3):382–401, July 1982.

[21] Anna Lysyanskaya and Nikos Triandopoulos. Ratio-
nality and adversarial behavior in multi-party com-
putation. In Cynthia Dwork, editor, CRYPTO, pages
180–197, 2006.

[22] Christopher Natoli and Vincent Gramoli. The bal-
ance attack or why forkable blockchains are ill-suited
for consortium. In 2017 47th Annual IEEE/IFIP In-
ternational Conference on Dependable Systems and
doi:10.
Networks (DSN), pages 579–590, 2017.
1109/DSN.2017.44.

[23] Alejandro Ranchal-Pedrosa and Vincent Gramoli.
Agreement in the presence of disagreeing rational
players: The huntsman protocol, 2021. arXiv:2105.
04357.

[24] Atul Singh, Pedro Fonseca, Petr Kuznetsov, Rodrigo
Rodrigues, and Petros Maniatis. Zeno: Eventually
consistent byzantine-fault tolerance. In Proceedings of
the 6th USENIX Symposium on Networked Systems
Design and Implementation, NSDI’09, page 169–184,
USA, 2009. USENIX Association.

[25] Xavier Vila¸ca, Oksana Denysyuk, and Lu´ıs Ro-
drigues. Asynchrony and collusion in the n-party
bar transfer problem. In Guy Even and Magn´us M.
Halld´orsson, editors, Structural Information and
Communication Complexity, pages 183–194, Berlin,
Heidelberg, 2012. Springer Berlin Heidelberg.

12

