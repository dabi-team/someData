Blockchain Mining with Multiple Selﬁsh Miners

Qianlan Bai, Yuedong Xu, Nianyi Liu, Xin Wang

1

2
2
0
2

b
e
F
7
1

]

R
C
.
s
c
[

2
v
4
5
4
0
1
.
2
1
1
2
:
v
i
X
r
a

Abstract—This paper studies a fundamental problem re-
garding the security of blockchain PoW consensus on how
the existence of multiple misbehaving miners inﬂuences the
proﬁtability of selﬁsh mining. Each selﬁsh miner (or attacker
interchangeably) maintains a private chain and makes it public
opportunistically for acquiring more rewards incommensurate
to his Hash power. We ﬁrst establish a general Markov chain
model to characterize the state transition of public and private
chains for Basic Selﬁsh Mining (BSM), and derive the stationary
proﬁtable threshold of Hash power in closed-form. It reduces from
25% for a single attacker to below 21.48% for two symmetric
attackers theoretically, and further reduces to around 10% with
eight symmetric attackers experimentally. We next explore the
proﬁtable threshold when one of the attackers performs strategic
mining based on Partially Observable Markov Decision Process
(POMDP) that only half of the attributes pertinent to a mining
state are observable to him. An online algorithm is presented to
compute the nearly optimal policy efﬁciently despite the large
state space and high dimensional belief space. The strategic
attacker mines selﬁshly and more agilely than BSM attacker
when his Hash power is relatively high, and mines honestly
otherwise, thus leading to a much lower proﬁtable threshold.
Last, we formulate a simple model of absolute mining revenue
that yields an interesting observation: selﬁsh mining is never
proﬁtable at the ﬁrst difﬁculty adjustment period, but replying on
the reimbursement of stationary selﬁsh mining gains in the future
periods. The delay till being proﬁtable of an attacker increases
with the decrease of his Hash power, making blockchain miners
more cautious on performing selﬁsh mining.

Index Terms—Proof-of-Work, Selﬁsh Mining, Proﬁtability,

Markov Chain, Partially Observable MDP.

I. INTRODUCTION

Bitcoin has gained tremendous concerns as the ﬁrst fully
decentralized cryptocurrency since its advent in 2008. All
historical transactions between Bitcoin clients are recorded
in a global and public data structure known as blockchain.
The security of Bitcoin-like blockchain is established by a
chain of cryptographic Hash puzzles, addressed by a large-
scale network of pseudonymous participants called miners [1].
Solving a Hash puzzle is deemed as a way to generate Proof-
of-Work (PoW) of reaching global consensus. The PoW of
Bitcoin demands intensive computations, thus consuming a
lot of energy. Each miner competes for this “game”, and
is rewarded by cryptocurrencies (i.e. bitcoins) if he is the
ﬁrst acknowledged miner to ﬁnd a valid block. When the
population of miners is large,
the aggregate Hash power
is sufﬁciently high such that a malicious miner can hardly
accumulate enough resource to perform double spending or
51% attack. The PoW consensus of Bitcoin has been widely

Q. Bai and X. Wang are with the School of Computer Science, Fudan

University, Shanghai 200438, China.

Y. Xu and N. Liu are with the School of Information Science and

Technology, Fudan University, Shanghai 200438, China.

deployed in public blockchains, serving as the cornerstone of
current major cryptocurrencies.

The security of PoW is challenged by the trend of cen-
tralization of Hash power. Mining a Bitcoin block is random
and it needs more than 10 years on average with a latest-
generation ASIC chip [4]. Therefore, blockchain miners oper-
ate cooperatively to form pools that have a much larger chance
of solving puzzles in a short time. By splitting the mining
reward appropriately, they acquire a stable income rate. As
a side effect, a small number of mining pools occupy a vast
majority of global Hash power, placing blockchain systems at
the risk of being overthrown by a gigantic pool or colluding
pools. The conventional wisdom believes that PoW is secure
as long as no mining pool (or miner interchangeably) controls
51% of total Hash power. However, a miner can choose to
mine selﬁshly instead of conforming to the standard Bitcoin
protocol.

Selﬁsh mining refers to a class of block publishing policies
in which a miner does not release his newly found block
immediately, but forks a private chain unaware to others. At
a future epoch, he will release his private blocks strategically
to obsolete the current public chain or compete with it for
the purpose of obtaining a higher share of valid blocks in the
new public chain than his ratio of Hash power. In a word, a
selﬁsh miner does not want to destroy the blockchain PoW
consensus, but to take advantage of it. The minimum ratio of
Hash power that brings more rewards to a selﬁsh miner than
this ratio is conventionally called proﬁtable threshold. Eyal
and Sirer introduced the ﬁrst selﬁsh mining scheme (namely
basic selﬁsh mining, BSM) and pointed out that the proﬁtable
threshold of BSM is 25% of total Hash power [2]. Nayak
et al. [9] proposed the stubborn mining that improves the
revenue of the selﬁsh miner by 13.94% compared to BSM.
As the key trick of stubborn scheme, the selﬁsh miner insists
on forking if his private chain slightly lags behind the public
chain. Sapirshtein et al. modeled the optimal selﬁsh mining as
a Markov Decision Process (MDP) that reduces the selﬁsh
miner’s proﬁtable threshold to 23.21% [7]. Tao et al. [20]
introduced the semi-selﬁsh mining attack based on hidden
MDP with the control of fork rate. Grunspan and Perez-
Marco proved rigorously using martingale theory that selﬁsh
mining is an attack on the difﬁculty adjustment algorithm of
blockchain consensus [32]. Recently, a lot of efforts have been
devoted to the compound attacks of selﬁsh mining with block
withholding attacks [14] [34], bribery attacks [15], eclipse
attacks and double spending attacks [22].

Until very recently,

the competition of multiple selﬁsh
miners came into view. Liu et al. presented the publish-n
scheme for two selﬁsh mining attackers and simulated their
revenues as well as proﬁtable thresholds [3]. Bai et al. modeled
the mining race among two BSM miners and one honest miner

 
 
 
 
 
 
as a Markov process [31]. Zhang et al. [18] simulated the
proﬁtable threshold in the presence of multiple selﬁsh miners.
Charlie et al. [19] proposed SquirRL, a framework for using
deep reinforcement learning (DRL) to analyze selﬁsh mining
and block withholding attacks in blockchain systems. Their
multi-agent setting is roughly equivalent to multiple selﬁsh
miners, and their focus is to train a highly performance DRL
model to tackle the strategic mining with large state space
and incomplete information. Previous experimental studies,
though insightful, lack of theoretical understandings on the
principle of competitive selﬁsh mining. It is usually believed
that modeling the proﬁtable threshold with multiple selﬁsh
miners is hard, and the optimal mining may be intractable
due to the above-mentioned challenges.

In this paper, we theoretically investigate the proﬁtability
of selﬁsh mining with multiple attackers by asking a sequence
of key progressive questions: 1) Will selﬁsh mining become
more easily proﬁtable with multiple attackers than with a solo
attacker? 2) How can we design a nearly optimal mining
policy for an attacker despite the complex interactions among
miners and the incomplete observations of the system state?
3) How long should an BSM attacker wait from the beginning
of selﬁsh mining until being proﬁtable eventually? Figuring
out these questions will provide essential understandings to
the security of blockchain PoW consensus.

We formulate a Markov chain model to compute the station-
ary relative revenue of BSM attackers for the ﬁrst question.
The relative revenue of an attacker is the percentage of his
valid blocks in the public chain. Our model is very general
in the sense that it can capture the cases with more than two
attackers or allow an attacker to hide multiple blocks privately.
In particular, the latter case may cause the complicated chain-
reaction release in which the publishing action of one attacker
triggers that of the other attacker.

Answering the second question is very challenging if a
strategic attacker (Alice), a BSM attacker (Bob) and an honest
miner (Henry) coexist in the system. Firstly, the interactions
among three chains are more complicated. The state of the
mining race is captured by a 10-tuple pertinent to the com-
position of all chains and the forking status, as opposed to a
3-tuple in the MDP-based optimal policy for a single attacker.
The number of actions is larger and the state-action pairs can
be 102 to 103 times larger. Second, Alice as the strategic miner
cannot observe the complicated state information. In fact, she
is merely aware of 5 attributes at each state related to her
private chain and the public chain. We formulate a family of
parameterized partially observable Markov decision process
(POMDP) models to characterize Alice’s strategic mining
policy with a continuous belief of the current state. To tackle
the large state space and the high-dimensional belief space, we
adopt AEMS2, one of the fastest POMDP online algorithms,
to compute the nearly optimal mining policy. A binary search
method similar to [7] is used to ﬁnd the maximum relative
revenue among the family of POMDP models.

As for the third question, we build a simple model to com-
pute attackers’ absolute revenue, which is the average number
of valid blocks received by each miner per unit of time.
Since selﬁsh mining is an attack on the difﬁculty adjustment

2

algorithm (DAA), it is not proﬁtable instantaneously even if
the attacker’s Hash power is above the proﬁtable threshold.
This model enables us to compute the number of DAA periods
that lead to proﬁtable selﬁsh mining eventually.

Our major observations are summarized as below.
• BSM. The proﬁtable threshold of Hash power is below
21.48% with two symmetric BSM attackers, as opposed
to 25% with a single BSM attacker and 23.21% with
a single optimal attacker. More blocks allowed to hold
privately or more attackers will dramatically reduce this
threshold. When the Hash powers of two attackers are
asymmetric, the proﬁtable threshold of one attacker will
decrease ﬁrst and then increase as the other attacker’s
Hash power increases (i.e. non-monotonic).

• POMDP. The POMDP mining policy brings more rev-
enues to the strategic miner than BSM and honest mining,
and approaches the performance of MDP mining pol-
icy with complete information. When the BSM attacker
(Bob) has 34% Hash power, the other attacker’s (Alice’s)
proﬁtable threshold decreases from 29.44% to about 2%
if she chooses POMDP rather than BSM. The designed
online algorithm can rapidly and effectively compute
the near optimal action under the current observable
information.

• Proﬁtable Delay. A BSM miner receives less absolute
revenue than honest mining in the ﬁrst difﬁculty adjust-
ment period even if his Hash power is above the proﬁtable
threshold, and his gain is achieved in future periods. BSM
is proﬁtable after 51 rounds of difﬁculty adjustment (i.e.
714 days in Bitcoin) if the Hash power of two symmetric
selﬁsh miners is 22%. This delay decreases to 5 rounds
(i.e. 70 days in Bitcoin) as their Hash power accrues to
33%, which is still quite long.

The remainder of this paper is organized as follows. Section
II describes the background of selﬁsh mining. Section III
models the relative revenue of basic selﬁsh mining with differ-
ent attackers. Section IV proposed the POMDP-based mining
policy and designed the efﬁcient algorithm. The proﬁtable time
of basic selﬁsh mining is modeled in Section V. Section VI
validates the revenue model of BSM and the performance of
the POMDP-based policy. Section VII introduces the related
work, and Section VIII concludes our work.

II. SYSTEM MODEL

In this section, we present the block-release procedure of
blockchain mining in the presence of two adversarial miners.
We further introduce the new features on tie-breaking and
chain-reaction release.

A. System Description

Consider a blockchain system with two misbehaving at-
tackers Alice and Bob, as well as an honest miner, Henry1.
They compete to solve cryptographic puzzles to mine a valid
block for the purpose of acquiring bitcoin-like tokens. The

1Multiple honest miners can be boiled down to a single miner for the sake

of their linear additivity of Hash powers.

proof-of-work (PoW) consensus is adopted and the mining
of blocks is stateless: the probability of discovering a block
by a miner is proportional to his current Hash power, but
inversely proportional to the current aggregate Hash power
of the entire blockchain network. The blockchain system
dynamically adjusts the difﬁculty of cryptographic puzzles
such that new blocks are generated at a ﬁxed average rate
(e.g., one block per 10 minutes on average in Bitcoin). The
miners maintain a globally-agreed ordered set of transactions
via the adoption and the mining on the longest chain. The
relative revenue of a miner is the fraction of blocks mined by
him out of all the blocks in the longest chain. The reward of
each valid block is normalized as one cryptographic coin.

For simplicity, we make the following assumptions con-
sistent with the literature [2] [7]. The blockchain mining
environment has that

• The total Hash power of the blockchain system is nor-
malized as a unit. Then, the Hash power of a miner is
represented as a fraction of the total;

• The block discovery time by a miner is exponentially

distributed.

The honest miner Henry who ﬁnds a valid block will release
it immediately. Alice (resp. Bob) may release her blocks strate-
gically by forcing Henry into wasting his computation. When
Alice and Bob are both selﬁsh miners, the interaction between
two private chains becomes more complicated because none
of them know the other’s state. In what follows, we capture
all the different states that each miner may encounter.

Denote by α1, α2 and αh the Hash powers of Alice, Bob
and Henry respectively, i.e., α1 + α2 + αh = 1. Denote by
γ1 (resp. γ2) the proportion that Henry’s Hash power mines
after Alice’s (resp. Bob’s) released chain in the tie-breaking
between Alice (resp. Bob) and Henry. Denote by θ1 and θ2 the
probabilities that honest miners choose to mine after Alice’s
and Bob’s chains in the three-party tie-breaking, respectively.
When the blockchain system creates a new block, it is mined
by pool i with the probability αi , ∀i ∈ {1, 2, h}, owing to
the memorylessness of Hash computations.

B. Basic Selﬁsh Mining Mode

Alice maintains a private chain, so does Bob, while Henry
operates on the public chain. Alice and Bob are not aware of
each other’s role, even each other’s presence. We suppose that
all the miners work on the same public chain at the beginning
where the starting point is expressed as “0”. The length of
the private chain is kept as private information by Alice and
Bob, and the length of the public chain is observed by all of
them. We consider the selﬁsh mining method proposed by [2],
and our analytical approach can be generalized to a variety of
other methods.

The mining procedure consists of two cases as follows.
• (Public-chain mining case) Henry always mines after the
public chain. Alice or Bob also mines on the public chain
if it is longer than his private chain.

• (Private-chain mining case) Alice (resp. Bob) continues
to mine on her (resp. his) private chain if she (resp. he)

3

discovers a new block and the private chain is now longer
than the public chain.

The release procedure is more complicated than the mining
procedure. Henry broadcasts his mined block as soon as it is
discovered, while Alice and Bob will decide whether to release
their mined blocks depending on the length of the public chain.
• (Forfeit case) Alice (resp. Bob) abandons her (resp. his)
private chain and conforms to mining after the public
chain if the latter is longer. Henry also abandons his
public chain if Alice or Bob publishes a longer chain.
• (Risk-avoiding release case) Alice (resp. Bob) releases
her (resp. his) privately mined blocks to the public
because of the fear of loss if the new block is mined
by the others and the leading advantage of her private
chain is no more than two blocks.

• (Chain reaction case) When Alice (resp. Bob) releases
her (resp. his) blocks to the public chain and updates its
length, the release of Bob’s (resp. Alice’s) private blocks
is triggered immediately.

The chain reaction case is the combination of the forfeit
and the risk-avoiding cases, whereas the existence of chain
reaction complicates evolution of the public chain. Suppose
that Alice publishes her private blocks to obsolete the current
public chain. After the construction of the new public chain,
Bob may release his private chain to forfeit it immediately.

C. Release procedure and tie-breaking Logics

The consensus on the public chain requires that it is the
longest. A crucial question is how the public chain evolves
when it is of the same length as Alice or Bob. In general,
each miner works on his own chain, and the release behavior
of Alice and Bob is triggered when Henry mines a new block.
We hereby illustrate the evolution of private and public chains
where Ak, Bk, and Hk denote that the kth block belongs
to Alice, Bob and Henry respectively. The blocks of private
chains are in grey and those of public chains are in white.
Risk-avoiding release case. We show the risk-avoiding release
of Alice’s private chain in Fig. 1. Alice is only one block
ahead of Henry after the latter mines a new block for the
public chain. Because Alice fears of losing the competition,
she publishes her private blocks, obsoleting Henry’s public
chain, so that both Alice and Henry mine on the new longest
chain afterwards.

Fig. 1. Alice’s risk-avoiding release and Henry’s abandonment.

Tie-breaking resolving. If Alice’s private chain is only one
block ahead of Henry’s, Henry may catch up with her. When
it happens, Alice publishes her private blocks immediately to
compete with Henry. Thus, two public chains of the same
length exist in Fig. 2. Since only one public chain prevails, a

tie-breaking rule needs to be taken into account. The ﬁrst case
is that the public chains of Alice and Henry have the same
length, and Bob’s private chain is 0. Hence, we only need to
resolve the tie between Alice and Henry. All the miners are
possible to mine after block A1, while Bob and Henry may
mine after H1. There are ﬁve possibilities of extending the
longest public chain, and the shorter one will be obsoleted.
We omit the tie-breaking between Bob and Henry because
this can be analyzed in the same way.

Fig. 2. Tie-breaking case of two public chains.

For the situation that each of Alice and Bob hides one
private block, they will publish their private chains instantly
after Henry ﬁnds a new block. As shown in Fig. 3, there exist
three competing public chains. Alice will mine after A1 and
Bob will mine after B1 for sure; Henry is not aware of which
chain is maliciously forked so that he may mine on each public
chain. There are also ﬁve possible situations. The risk-avoiding
release, together with two tie-breaking solutions, constitutes all
the dynamics of private and public chains.

Fig. 3. Tie-breaking case of three public chains.

Fig. 4. Chain reaction case.

Chain reaction release. We next introduce the chain reaction
release that complicates the evolution of the private and public
the chain reaction release consists of a
chains. Note that
sequence of risk-avoiding releases and tie-breaking resolvings.

4

Fig. 4 illustrates an example of how the chain reaction
phenomenon is triggered. At stage 1, Alice’s private chain
contains four blocks, while the lengths of Bob’s private chain
and Henry’s public chain are 0. After a tie-breaking resolving
at stage 2, the longer public chain contains two blocks B1 and
H2, and the shorter is orphaned. Bob constructs a new private
chain starting from B3 to B8, while Henry continues to mine
one block after H2 at stage 4. From Alice’s perspective, her
private chain is merely one block ahead of the public chain.
She releases her private blocks in order to avoid the risk of
losing the race with Henry. The new public chain now starts
from block A4. Next, stages 5 and 6 constitute a new round of
tie-breaking resolving between Alice and Henry, extending the
public chain to block A7. However, the release of A7 triggers
Bob to release all of his private blocks starting from B3 to
B8. When retrospecting all the mining stages, we observe
that the winning branch switches back and forth, making the
analysis of selﬁsh mining extremely complicated. To be noted,
the chain reaction occurs only when the length of the private
chain is greater than three.

III. STATIONARY ANALYSIS OF BASIC SELFISH MINING

In this section, we present Markov chain models to char-
acterize the block-publishing dynamics with multiple selﬁsh
miners. The expected revenues of selﬁsh miners are derived
in explicit form.

A. Deﬁnition

The theme of our study is placed on the proﬁtability
of selﬁsh mining so that the proﬁtable measures should be
clariﬁed ﬁrst. For notational simplicity, we only consider three
miners: Alice, Bob and Henry.

Deﬁnition 1: (Relative Revenue) Let Ra, Rb and Rh be the
expected numbers of valid blocks mined by Alice, Bob and
Henry in a mining round, respectively. The relative revenue of
a miner, ˆRi, is expressed as

ˆRi =

Ri
Ra + Rb + Rh

,

i ∈ {a, b, h}.

It should be emphasized that the valid blocks are conﬁrmed
blocks in the longest chain. The proﬁtability of selﬁsh mining
does not refer to the surplus that the block reward subtracts the
cost of cryptographic computation. In fact, it is a contrastive
measure to the honest mining that needs an objective index.
Deﬁnition 2: (Proﬁtability) The selﬁsh or strategic mining
performed by Alice (resp. Bob) is deemed proﬁtable if the
relative revenue is higher than the normalized Hash power,
i.e. ˆRa > α1 (resp. ˆRb > α2).

B. Stationary Analysis for Two Attackers

In order to analyze the proﬁtability of selﬁsh mining, we
need to compute the fractions of blocks mined by the selﬁsh
miners in the public chain. We hereby formulate a discrete-
time Markov chain model to characterize the dynamics of
the public and private chains. We begin with the assumption
that each selﬁsh miner will release his two private blocks
immediately after he has mined the second one (i.e. N = 2).

The underlying reasons are two-fold. Firstly,
the simpler
block-release process avoids the complicated representation of
Markov states, thus allowing for more tractable mathematical
modeling. Secondly, the bursty release of many valid blocks
in a very short time usually indicates the existence of selﬁsh
mining attacks that can be easily detected. The selﬁsh miners
intend to acquire extra mining rewards other than destabilizing
the authority of cryptocurrencies.

5

The average number of Henry’s orphaned blocks in each attack
round is calculated as:

Oh =π000[(α1+(1−α1)γ1)α1αh + (α2+(1−α2)γ2)α2αh

+ (α1 + α2 + (θ1 + θ2)αh)2α1α2αh].

(6)

As a special case that the both selﬁsh miners are homogeneous,
i.e. α1 = α2 = α < 0.5, γ1 = γ2 = 0.5 and θ1 = θ2 = 1/3,
the expected revenues can be simpliﬁed as

π000 = (1 + 4α − 4α3)−1;

Ra = Rb = π000 · 1
Rh = π000 · [(1 − 2α)(1 + 3α − 7

6 α(25α + 2α2 + 3 − 32α3);
3 α3)].

3 α2 − 16

(7)

(8)

We can easily observe that the attackers’ (resp. Henry’s)
expected revenues in Eq. (7) (resp. Eq. (8)) monotonically
increase (resp. decrease) with regard to attackers’ ratios of
Hash power.

C. Scaling to Multiple Attackers

Although the proﬁtable selﬁsh mining demands a high Hash
power, it is possible that multiple selﬁsh miners can choose to
opt in. The impact of more selﬁsh miners on the proﬁtability
is obscure. The honest miner’s share of Hash power decreases,
and the competition among selﬁsh miners becomes more
ﬁerce when the number of selﬁsh miners increases beyond
two. Therefore, we consider a general mire scenario with m
(m > 2) BSM miners.

Fig. 6. Markov State Transition with m Attackers.

We model the dynamics of the public and private chains
as a Markov process likewise. Fig. 6 illustrates all the states
and their transition probabilities. Recall that the assumption
of the maximum private chain length also holds. Each state
is expressed as a m-tuple, i.e. L = {l1, l2, · · · , lm} with li ∈
{0, 1}, which consists of the lengths of each attacker’s private
chain. The state with m zeros, denoted as L0, indicates the
start of the mining competition. The states with a single ‘1’
are grouped together in which one and only one attacker has
mined a valid block to build his private chain. Similarly, the
states with k elements of ‘1’ indicate that the private chains
of k out of m attackers have one valid block. Formally, we
denote by L the set of all states with the cardinality 2m, and

Fig. 5. Markov chain with less than two private blocks.

We deﬁne a state as a three-tuple consisting of the lengths
of Alice’s, Bob’s and Henry’s chains. Fig. 5 illustrates all
the states, the state transition indicators and their transition
probabilities. For instance, the transition from state (0, 0, 0) to
state (1, 0, 0) means that Alice discovers a valid block with
probability α1 and forks the private chain. If the maximum
length of any private chain is below 2, Alice and Bob can
hide their private chains and continue the selﬁsh mining.
All the transitions to state (0, 0, 0) means that the forked
chains return to the unanimous public chain and a new round
of selﬁsh mining starts. Denote by P the state transition
probability matrix and by Pss(cid:48) the transition probability from
state s = (i, j, k) to s(cid:48) = (i(cid:48), j(cid:48), k(cid:48)). Let πijk be the stationary
distribution of state (i, j, k). According to the detailed balance
equation [5] [21]

πs =

(cid:88)

s(cid:48)

πs(cid:48)Ps(cid:48)s.

(1)

Then, we can compute π000 as
π000 = (1+α1+α2+α1αh+2α1α2+α2αh+2α1α2αh)−1,

(2)

and πijk at any other state s = (i, j, k) in the same way.

The transitions to state (0, 0, 0) manifest which miner is
the ﬁnal winner in the current round of selﬁsh mining. There-
fore, we can compute the expected revenues of Alice, Bob
and Henry that are deﬁned as Ra, Rb and Rh respectively.
Facilitated by the stationary state distributions, we calculate
them as below,

Ra = π000 · [2α2

+ α1α2αh + 4α2

Rb = π000 · [2α2

+ α1α2αh + 4α2

1 (1 + αh) + (α2 + αh) α1αhγ1
1α2 (1 + αh) + 2α1α2α2
2 (1 + αh) + (α1 + αh) αhα2γ2
2α1 (1 + αh) + 2α1α2α2

hθ1];

hθ2];
h (2−θ1 − θ2)

Rh = π000 · [α1α2

h (2 − γ1) + 2α1α2α2

(3)

(4)

+ αh + α2α2

h (2 − γ2) + α1α2αh(2 − γ1 − γ2)]. (5)

6

Fig. 7. State machine with N = 4.

Fig. 8. A path sample with N = 4.

by Lk ⊆ L the subset in which k selﬁsh miners hold their
private blocks.

Rh = (cid:0)

m
(cid:88)

(cid:88)

k=1

L∈Lk

αhπLαh(

2
k + 1

+

k
k + 1

)(cid:1) + πL0 · αh. (11)

The state transition probabilities are described as the fol-
lowing. The blockchain system can reside at the initial state
with probability αh, i.e., the block is mined by the honest
miner. Denote by ei the vector whose ith element is 1 and all
others are zero. When a valid block is discovered by attacker
i, the blockchain system transits to a new state (L + ei) with
probability αi. At the state L ∈ Lk, if the ith attacker who
has a private block ﬁnds a valid block again, the blockchain
system returns to the initial state L0 (in which the state is
expressed as a double circle). Otherwise, it jumps to a state
in Lk+1 with the probability equivalent to the relative Hash
power of the selﬁsh miner. The state transition probabilities
can be expressed as:

PLL(cid:48) = αi ∀L(cid:48) = L + ei ∈ Lk+1 and L ∈ Lk,
PL0L0 = αh,
PLL(cid:48) = αi + αh, PL(cid:48)L0 = 1, ∀L ∈ Lk, L(cid:48) /∈ Lk+1.

Using the detailed balance equations, we can compute the
stationary distribution of each state. Speciﬁcally, the stationary
probability at state S0 is computed explicitly as

πL0 = (cid:0)1 +

m
(cid:88)

(cid:88)

m
(cid:89)

k!

(αi · 1lj =1)(cid:1)−1

.

(9)

k=1

L∈Lk

j=1

The stationary probability at state L is given by:

πL = k! · πL0 ·

m
(cid:89)

(αi · 1lj =1), ∀L ∈ Lk.

(10)

j=1

The revenues of all miners are computed based on the
stationary state distribution and the particular transition paths
to state L0. If all miners have the same γ in tie-breaking cases,
their revenues can be written as:



πL · [αh(2αi +

1− (cid:80)
j∈L

li = 1;

αj ·1lj =1

)],

m
(cid:88)

(cid:88)

k+1

Ri =

k=1

L∈Lk



αh · πL · αi,

li = 0.

D. Scaling to N ≥ 2

We next model

the revenues of all miners when each
private chain can hide more than one block. Especially, as
the maximum number of private blocks for one attacker is no
less than four (i.e. N =4), the “chain reaction” occurs and the
resulting ﬁnite state machine becomes very much complicated.
A state should include not only the lengths of all chains, but
also the interleaving of blocks on them. We conﬁne our study
to three miners: Alice, Bob and Henry, and investigate the
case N = 4 without loss of generality. The main difﬁculty
hindering the mathematical analysis is that Alice and Bob have
different beliefs in the starting position of the current mining
round. Besides, the blocks in the winning chain may belong
to Henry and Alice/Bob so that we need to memorize them in
order to compute their revenues. In contrast, both Alice and
Bob always have the common starting position in the racing
without chain reaction (i.e. state (0, 0, 0) in Fig.5).

The state transitions with N = 4 are expressed in Fig. 7
where each state consists of eight parameters. The current
mining round starts at the leftmost node where no miner has
discovered a block. The notation h1 indicates the distance
between the starting position believed by Alice and the real
starting position. Similarly, h2 and h3 indicate these distances
of Bob and Henry. We record h1, h2 and h3 because the blocks
between the real and the believed starting positions inﬂuence
which chain will prevail ﬁnally and how the revenues are
calculated. The notation l1 (resp. l2) represents the number
of unreleased blocks at Alice’s (resp. Bob’s) private chain. µ1
denotes the number of Henry’s block between the real starting
position and the Alice-believed starting position. µ2 and µ3 are
deﬁned for Bob and Henry in the same way. Combined them
h1h2h3
together, we deﬁne an Markov state as l1l2
µ1µ2µ3 that is also
applicable to the situation with N > 4.

We hereby present a concrete example of state transition.
The related states in Fig. 7 are marked in blue, and their

000 and 20000

000 through 10000

011. Bob has mined three blocks after H1 at stage

transitions are illustrated in Fig. 8 separately. At stage
1 ,
Alice has mined three blocks stealthily so that the system state
jumps from 0 to 30000
000. At stage 2 ,
Henry mines a valid block H1 and publishes it to the public
chain immediately. The system state then jumps from 30000
000 to
30011
and
the system state moves to 33011
011. So far, neither Alice nor Bob
will release their private blocks. At stage 4 , Henry discovers
a new block H2 that triggers the release action of Alice. After
Alice publishes all her blocks to obsolete Henry’s chain, Bob
ﬁnds that the public chain is catching up. As a consequence,
Bob publishes all his blocks and wins the competition ﬁnally,
i.e. the system state returning to the stating position. In this
round, Bob receives three block rewards and Henry receives
one block reward.

3

According to the transitive probability, the revenue for each

miner can be represented as:

1 + 2α2α1 + α2

1 + 2α1α2α3 + 3α1α2

π000 = 1/(1 + α1 + α2 + α1α3 + α2
1 + 3α2α2
+ α2α3 + α3
1α2 + 6α2
+ 4α3
1α2
1α2
+ 6α2
2α3 + 10α2
1α3
2 + α3
1α3
+ 20α3
2α3 + 20α3
1α3
+ α4
1α4
+ α3
2α3);

2 + 4α1α3
1α3
2α3 + α3
2α2
1α3

2 + 4α1α3
2α2
1α2
1α3
3 + α2

2 + α3

2α3 + α3
2α3 + α1α3
1α3
3 + 20α3
1α3
2α3 + α3

2 + α3
1
2 + α3
2 + α3
1α3
1α2α3 + 10α3
1α2
2
1α2
2α3 + α3
2α3
2α3 + 4α3
1α2α3
2α2
1α3
2α3 + α2
3
(12)

1 (1 + αh) + 3α3
1αh
2 (1 + 2α2) + α1α2αh (1 + γ1 + 2θ1αh)

1α2 + 4α2

h + 16α4

1α2

R1 =π000 · [4α4
1α2
+ 40α4
1α2αh + 20α3
+ 10α2
2αh (1 + αh) + 4α4
1α2
+ 4α4
1α3
+ 5α5
1α3
2αh + 4α4
+ α1α2
hγ1 + 12α2
1α2
2α2
1α3
+ 6α3
h (10αhβ1 + 1)];

1α2αh (3α2 + α1) + 15α3

1α2α2
h

1α3

2α2
2αh (α2 + 21) + 3α3
2α2

h (β1 + 20)
1α4

hβ1 + α2

1α2

2α3

hβ1

2α2
hβ1 (3α1 + 2α2)
(13)

2αh

2α2

2 + 4α2

h + 16α1α4

2 (1 + αh) + 3α3
R2 =π000[4α4
1α4
+ 40α2
2 (1 + 2α1) + α1α2αh (1 + γ2 + 2θ2αh)
2αh + 20α1α3
2αh (3α1 + α2) + 15α1α3
+ 10α1α2
2αh (1 + αh) + 4α3
1α4
+ 4α2
+ 5α3
1α4
2αh + 4α3
1α5
1α2
hγ2 + 12α2
+ α2α2
2α2
1α3
+ 6α3
h (10αhβ2 + 1)];

2α2
2αh (α1 + 21) + 3α4
2α2

h (β2 + 20)
1α3

2α2
hβ2 (2α1 + 3α2)
(14)

hβ2 + α2

2α2
h

2α3

1α2

1α4

hβ2

Rh =π000[α1α2

h (2 − γ1) + α2α2

h (2 − γ2) + α2
2α2

1α3
h (6 + 4α1α2)

1α2

2α3

h (2β1+β2)

h (2 − θ1 − θ2) + α2
h (β1 + 2β2) + α1α2αh (2 − γ1 − γ2)
1α4
1α3

+ 2α1α2α2
2α3
1α2
+ α3
+ α3
2αh (α1 + α2) + α3
1α3
1α4
h (β1+2β2)+20α3
2α2
1α3
+ α4
β1 = γ1/(γ1 + γ2) β2 = γ2/(γ1 + γ2).

h (2β1 + β2) + αh
h+2α4

2α2
2α3

2αh];

(15)

(16)

The cases with N > 4 can be analyzed in the same way.
We validate in our experiments that the relative revenue tends
to converge when N ≥ 4. If N is too large, the repeated

7

chain-reactions will occur, which aggravates the system insta-
bility and increases the possibility of detecting selﬁsh mining
attacks.

IV. OPTIMAL STRATEGY UNDER MULTIPLE ATTACKERS

The basic selﬁsh mining policy restricts the choices of
withholding and releasing blocks. In this section, we present
the optimal selﬁsh mining strategy (POMDP-based mining
policy) for two attackers when one of them chooses the basic
selﬁsh mining and the other chooses to be strategic.

A. OPT for an Upper Bound of Revenue

The limitations of basic selﬁsh mining are intuitive. An
attacker is “conservative” to adopt the public chain when his
private chain slightly lags behind it, and is “less wise” to
override the public chain when it is catching up. The optimal
selﬁsh mining problem with a single attacker was raised in
[7] [22] that modeled the mining race as a Markov decision
process. Under the optimal policy, the attacker does not adopt
the public chain if his private chain is slightly shorter than
the public chain; he may intentionally release some blocks to
cause the forking if his private chain is ahead of the public
chain by several blocks. This strategic selﬁsh mining policy
lowers the proﬁtable threshold of Hash power.

The optimal selﬁsh mining (OPT) in the presence of two
attackers (Alice as the strategic attacker and Bob as the
basic attacker) is far more challenging than that with a single
attacker. First, the state and the state transition are greatly
augmented. Alice has to incorporate the status of multiple
chains in the state other than merely the lengths of the
chains. The racing of three chains also causes complicated
state transitions. Second, Alice cannot acquire the information
regarding Bob’s private chain. In other words, the state is
partially observable to Alice. To tackle these difﬁculties, we
begin with the assumption that Alice has the full information
of the private chain of Bob. The optimal policy of Alice can
be solved based on an MDP model, and the corresponding
revenue will be used as the upper bound of revenue when the
private chain of Bob is unknown. Meanwhile, the MDP model
offers the principle of designing optimal policy with partially
observable states.

1) Main components: We formulate an MDP model for
the strategic attacker as the four-tuple M =< S, A, P, R >
where S denotes the state space, A denotes the action space,
P corresponds to the transition matrix, and R corresponds to
the reward matrix.

State: The state space S is deﬁned as a 10-tuple in the
form < loc, f ork, l1, l2, h1, h2, h3, u1, u2, u3 >. The attribute
loc ∈ {1, 2, 3} indicates the branch that Henry is working on.
If loc = 1 (resp. loc = 2), Henry is mining on the public chain
that also contains Alice’s (resp. Bob’s) blocks at the current
mining round. If loc = 3, the longest public chain contains
only Henry’s blocks. Note that Alice’s and Bob’s blocks are
mutually exclusive on the public chain at the same mining
round because one attacker will not accept the blocks of the
other before this attack round ends.

The attribute f ork obtains six values, dubbed as {ir,
r, f12, f13, f23, f123}, where r represents that Alice can
release blocks to compete with the current public chain when
h3 > 0 while ir represents that she can not. If multiple
miners are competing on the public chain, f ork takes four
values {f12, f13, f23, f123}, indicating that (Alice, Bob), (Al-
ice, Henry), (Bob, Henry) and (Alice, Bob, Henry) are in the
competition respectively. The other attributes such l1, l2, h1,
h2, h3, µ1, µ2 and µ3 have the same meanings as those in
the aforementioned Markov chain. Similar to [7], we limit the
lengths of private and public chains in a mining round so as to
conﬁne the size of state space, i.e. l1 ≤ N and h3 ≤ h3,max.
Action: An action is the number of blocks that Alice
publishes under a particular state. We deﬁne Alice’s action
space A as A = {adopt, 0, 1, · · · , l1} in which adopt means
that Alice gives up her private chain, 0 means that Alice
chooses to wait, and l1 is the current number of blocks hold
by Alice privately. The action taken by Alice has certain
reasonable restrictions: if l1 reaches N , Alice must release
at least one block; if h3 reaches h3,max, Alice either choose
“adopt” or to release no less than (h3 − h1) blocks to end this
mining round.

State Transition: We deﬁne the state transition function as
Pr(s(cid:48)|s, a ∈ A), the probability that the state s jumps to state
s(cid:48) under the action a. The state transition is triggered by the
mining of a new block, and is determined by which miner
discovers it. All the transitions are summarized in Table III.
Reward Function: The purpose of “optimal” mining is to
acquire a larger share of conﬁrmed blocks on the public chain,
or to purse a larger relative revenue in other word. Recall that
the relative revenue of a miner is the fraction of his blocks
on the public chain for a long period. Obviously, the relative
revenue cannot be measured under each state-action pair,
and cannot be taken as the corresponding immediate reward.
Sapirshtein et al. [7] transform the (long-term) relative revenue
into the family of (one-shot) absolute revenues parameterized
by the weight ρ ∈ [0, 1].

This ingenious transformation operates as the following.
Deﬁne a transformation function wρ : N3 → R related to
Alice’s instantaneous reward:

wi

ρ(ri
1, ri

2, ri
1, ri
2 and ri

h) = (1 − ρ) · ri

1 − ρ · (ri

2 + ri

h),

(17)

where ri
h represent the instantaneous rewards of
Alice, Bob and Henry at step i (analogous to time t in
classical MDP). We reformulate the original MDP model as
Mρ =< S, A, P, wρ(r1, r2, rh) >. The underlying reason of
such transformation is that instead of maximizing the relative
revenue, we choose to maximize the expected ﬁctitious reward
wρ(r1, r2, rh). For any admissible policy π, the mean reward
denoted by vπ

ρ is characterized as:

ρ = E[ lim
vπ
ξ→∞

1
ξ

ξ
(cid:88)

i=1

wρ(ri

1(π), ri

2(π), ri

h(π))],

(18)

where ξ is the total number of state transition steps. The
optimal revenue v∗

ρ is given by
v∗
ρ = max

π

{vπ

ρ }.

(19)

8

The equivalence between two MDPs M and Mρ is indirect.
Sapirshtein et al. [7] presents two propositions to guarantee
their equivalence for a single selﬁsh miner.

• If v∗

ρ = 0 for some ρ ∈ [0, 1], then any policy π∗
obtaining this value also maximizes the relative revenue,
and the relative revenue equals to ρ.
ρ is monotonically decreasing in ρ.

• v∗
The above propositions tell us that by searching an appropri-
ate ρ that yields the mean reward of Mρ to be 0, we can obtain
the optimal relative revenue of Alice in M. We generalize this
idea to the MDP with multiple selﬁsh miners. In addition, the
maximum number of steps, ξ, is truncated to avoid excessive
computations by tolerating a very gentle loss in the optimal
mean reward vπ
ρ .

2) Algorithm: Owing to the monotonicity of v∗

ρ to ρ, a
binary search of ρ ∈ [0, 1] is adequate. For a given ρ, we
utilize the value iteration method to solve the optimal policy
π∗
ρ as [7]. Compared to policy iteration, the advantage of value
iteration is its fast convergence rate especially in large-scale
MDPs [12] [13].

B. POMDP-based policy for Optimal Mining

The OPT framework provides important insights on the
optimal mining policy in the presence of two attackers, yet
its real world deployment is unrealistic. The strategic miner
Alice is assumed to know precisely the system state, while
in reality Bob’s private chain is not observable to Alice, and
the blocks on the public chain released by Bob and Henry
cannot be differentiated because of their anonymity. In light of
the incomplete state information, we reformulate the optimal
mining as a Partially Observable Markov Decision Process
(POMDP). Before diving into details, we enumerate three key
challenges:

• which subset of information is non-observable to Alice;
• how the mining event-driven MDP model is generalized

to the POMDP model;

• how the POMDP-based optimal mining policy can be

computed efﬁciently.

1) Main components: The POMDP model is expressed as a
six-tuple MP O :=< S, A, P, R, O, Z >, where O is Alice’s
observation space, Z(·) is the observation function, and the
the same meanings as their
remaining components inherit
counterparts in MDP.

Observable Information: In the partially observable en-
vironment, Alice cannot obtain all the attributes in S. The
length of Bob’s private chain l2 cannot be observed absolutely.
The attribute loc is non-observable either because Alice is
unaware of whether Henry is mining on his own chain or
Bob’s chain. h2, µ2 and µ3 are non-observable for that the
anonymity of mining covers up the owners of the blocks on
the public chain. The attribute f ork is observable because ir
and r are pertinent to Alice’s private chain, and the values
f∗ ∈ {f12, f13, f23, f123} is obtained by counting the number
of focks in competition. l1, h1 and µ1 are known for sure;
h3 is actually the length of the longest public chain. In
summary, the observation space is represented as O :=<

f ork, l1, h1, h3, µ1 >⊂ S. Given the same observation, Alice
is likely to be in many possible states.

State Transition: The state transition function is also
denoted as Pr(s(cid:48)|s, a ∈ A). Though taking the similar form,
MP O possesses a different state transition logic from M. In
M, an action is triggered by the discovery of a new block,
and the state transition follows. In MP O, the pure event-driven
state transition will restrict Alice from participating in the fork
competition. For instance, if Bob hides one block, Alice should
publish her private block while there is no observable event
to trigger a fork competition. On the contrary, if Bob does not
have any private block while Alice believes that the length
of Bob’s private chain is 1, Alice may publish one or two
blocks unnecessarily. Therefore, one can see that a time-slotted
plus event-driven POMDP model is appropriate to handle the
intricate optimal mining problem.

Due to the memoryless Hash computation [8], the block
arrival process is actually a stationary stochastic process. If
we slice this stochastic process equally with a slot duration
∆t, the number of mined blocks in every slot has the same
distribution. By choosing a relatively small ∆t, we suppose
that at most one block is mined in each slot (the chance of
mining two or more blocks is rarer by orders of magnitude).
Denote by p the probability of generating a block in one time
slot. The probabilities that Alice, Bob and Henry generate it
are α1p, α2p and αhp respectively. Alice can estimate the
Hash power α2 and αh through mining honestly for a certain
period. It is worth highlighting that our POMDP model makes
the optimal mining with partially observable states feasible,
and is in accordance with realistic blockchain systems. All
the transitions are summarized in Table IV.

Observation function: Deﬁne Z := S × A → ∆(O)
as the observation function that speciﬁes the relationship
between system states and observations. Here, z(s, a, o) is
the probability that observation o will be reached after Alice
performs action a and lands in state s:

zt+1(s, a, o) = Pr(ot+1 = o|st+1 = s, at = a).

(20)

In MP O, the observation of a state is certain, i.e,

9

Pr(o|a, s(cid:48))

(cid:88)

Pr(s(cid:48)|a, s)b(s).

(25)

given by

Pr(o|a, b) =

(cid:88)

s(cid:48)

s
1(s, a), ri

2(s, a) and ri

Reward function: We use ri

h(s, a) to
denote the instantaneous rewards of Alice, Bob and Henry
at step i when Alice takes action a at state s. Due to the
uncertainty of system state, the expected reward functions
ri
2(b, a) and ri
1(b, a), ri
h(b, a) are constructed on the belief of
instantaneous rewards, ∀a ∈ A,
(cid:88)

ri
1(b, a) =

bi(s)ri

1(s, a),

(26)

ri
2(b, a) =

ri
h(b, a) =

s∈S
(cid:88)

s∈S
(cid:88)

s∈S

bi(s)ri

2(s, a),

bi(s)ri

h(s, a).

(27)

(28)

Alice’s purpose is to maximize her relative reward that can
be transformed into an alternative expression of her absolute
reward at each time slot. Similar to the transformation in the
MDP model, we replace the relative reward by the absolute
reward wi
ρ(ri
h(bi, a)) parameterized by ρ
using Eq. (17).

2(bi, a), ri

1(bi, a), ri

We next formulate the optimal mining as a ﬁnite-horizon
average reward POMDP problem as [7] and [22]. The expected
average value function is deﬁned as

ρ = E[ lim
vπ
ξ→∞

1
ξ

ξ
(cid:88)

i=1

wρ(ri

1(bi, π), ri

2(bi, π), ri

h(bi, π))].

The optimal policy π∗ is a set of decision rules depending on
belief-state pairs:

ρ }.

{vπ

π∗ = arg max
π∈A
The parameter ρ that solves v∗
ρ = 0 is the relative revenue
of Alice under the POMDP model. In practice, the sum of
revenues over ξ is truncated by a sufﬁciently large number ξ0.
Given a precision threshold (cid:15), ξ0 needs to satisfy:

(29)

|vπ

ρ − E[

1
ξ0

ξ0
(cid:88)

i=1

wρ(ri

1(π), ri

2(π), ri

h(π))]| ≤ (cid:15).

(30)

s =< loc, f ork, l1, l2, h1, h2, h3, µ1, µ2, µ3 >,
o =< f ork, l1, h1, h3, µ1 >,
zt+1(s, a, o) = 1.

(21)

C. Algorithm

Belief: Our POMDP model is pertinent to a belief b which
is a probability distribution over all the possible states. Intu-
itively, Alice makes a guess on the current state iteratively.
The belief on a particular state s at time t is given by:

b(s) = Pr(st = s|zt, at−1, zt−1, · · · , a0, b0).

(22)

The updated belief state b(cid:48)(s(cid:48)) is calculated whenever the
action a is taken and the observation o is perceived.

b(cid:48)(s(cid:48)) ≡ Pr(s(cid:48)|a, o, b) =
Pr(o|s(cid:48), a) (cid:80)

=

Pr(s(cid:48), a, o, b)
Pr(a, o, b)
s Pr(s(cid:48)|a, s)b(s)

Pr(o|a, b)

(23)

(24)

,

where (cid:80)

s∈S b(s) = 1 and Pr(o|a, b) is a normalization factor

A POMDP is essentially an expanded MDP deﬁned on
belief space, and classical value iteration methods can be
adopted to solve the optimal policy ofﬂine. However, the belief
space is a high-dimensional continuous space that needs to
be segmented into a huge number of belief states. An ofﬂine
POMDP algorithm will compute the optimal actions at every
belief state. Considering a large-scale POMDP like ours, the
ofﬂine computation is time-consuming because of generating
the rewards, updating the beliefs and constructing the optimal
policy at each belief. This is in contrast to MDP that only has
an exact belief state. For efﬁciency considerations, we propose
using the online POMDP algorithm that explores the future
belief states reachable from the current belief state. The policy
construction time is often substantially shorter. Furthermore,

three important properties can be used to reduce the time of
searching for ρ.

Lemma 1: Under the same parameter setting, the optimal

result of M is the upper bound of MP O.
Proof: Among the approximation algorithms of the POMDP
problem, the MDP approximation consists in approximating
the value function of the POMDP by the value function of its
underlying MDP [36]. This value function is an upper bound
(cid:4)
on the value function of the POMDP [28].
Lemma 2: The revenue obtained under the optimal policy
based on any ρ is the lower bound of the actual optimal
revenue for MP O.
Proof: In the online algorithm, the policy construction steps
and the execution steps are interleaved with one another.
Hence, we record the number of blocks that each miner obtains
at every time step, i.e, (ri
2, ri
h). After enough time steps,
we can compute the relative revenue under the current ρ even
though it is not optimal. Therefore, the revenue of the current
optimal policy obtained under the current ρ is the lower bound
(cid:4)
of the actual optimal revenue.
Lemma 3: There exists an optimal stationary deterministic

1, ri

policy for MP O model.
Proof: The states, actions and beliefs are countable because
the maximum lengths of private and public chains are limited.
Since a POMDP problem can be regarded as a belief MDP,
the existence of an optimal stationary policy for our POMDP
(cid:4)
problem is guaranteed by Theorem 7.3.6 of [10].
Our online mining algorithm is described in Algorithm 1.
We calculate the optimal revenue based on binary search.
The upper bound can be set as the result of the underlying
MDP model according to Lemma 1 (lines 2-3). Alice will
execute the optimal action based on the current ρ and obtain
the relative revenue (lines 16 and 24). Her optimal revenue is
no less than the relative revenue according to Lemma 2 (lines
25-29). We do not have to recalculate the optimal action at
every step according to Lemma 3. The online algorithm will
adopt the corresponding action if the same belief state has
met. Otherwise, it will calculate and store the new optimal
action (lines 11-15). A block of size 1MB needs 18 seconds
to reach three thousand nodes in Bitcoin [27]. Making timely
decisions by Alice is very important. In line 5, we use AEMS2
[11] [28], one of the fastest POMDP algorithms, to compute
the optimal action (line 14).

V. TRANSIENT ANALYSIS OF PROFITABILITY

In this section, we ﬁrst describe the difﬁculty adjustment
algorithm (DAA) in Bitcoin-like systems, and model
the
revenue of miners in one difﬁculty adjustment period. We
analytically show that the extra revenue of selﬁsh mining is
originated from the DAA.

A. Bitcoin-like Difﬁculty Adjustment

The essence of Bitcoin mining is to solve a cryptographic
puzzle. The header of a block mainly includes the Hash of
the previous block, the Merkle root Hash of transactions, the
beginning time of calculating header Hash, the nBits used to
generate the target difﬁculty and the NONCE. A Bitcoin miner

10

Algorithm 1 Algorithm for solving the POMDP.
Input: MP O, M, a truncation parameter ξ0, a precision value
ε;
Output:ρ;
Static: bc:The current belief;
a∗ : optimal action;

else

a∗ ← AEM S2(bc, MP O)

if bc ∈ RESULT then
a∗ =RESULT[bc]

ρ ← (low + upper)/2
RESULT← {};
r1 ← 0, r2 ← 0, rh ← 0;
vρ ← 0;
bc ← initial belief
while ξ0 > 0 do

1: low ← 0;
2: ρ∗ =QMDP(M);
3: upper ← ρ∗;
4: while upper − low > ε do
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30: end while
31: return ρ;

end if
h)← Execute a∗ for bc.
2, ri
1, ri
(ri
2, rh+ = ri
i, r2+ = ri
r1+ = ri
h;
vρ+ = wρ(ri
2, ri
1, ri
h);
RESULT[bc] = a∗
Perceive a new observation z
bc ← b(cid:48)(bc, a∗, z)
ξ0− = 1

end while
R(cid:48)
if vρ > 0 then

1 = r1/(r1 + r2 + rh);

low ← max(ρ, R(cid:48)

end if

else

1);

upper ← ρ; lower ← max(low, R(cid:48)

1);

(cid:66) update algorithm is Eq. (23)

repeatedly enumerates a NONCE until the head Hash is below
the difﬁculty target. The smaller a target value is, the more
difﬁcult the discovery of a valid NONCE will be. For a ﬁxed
target difﬁculty, a larger Hash power means a shorter time of
ﬁnding a valid NONCE.

To maintain a stable block generating interval, Bitcoin and
Altcoins introduce difﬁculty adjustment algorithms (DAAs)
to cope with the variable Hash powers in the systems. The
Bitcoin DAA is executed after 2016 blocks have been mined.
It is actually a feedback control system: if the actual time of
mining 2016 blocks is larger than 20160 minutes (10 minutes
per block), the target difﬁculty decreases proportionally, and
increases otherwise. To avoid excessive ﬂuctuation, the dif-
ﬁculty of the next period should be within the range [ 1
4 , 4]
times of the current difﬁculty. When a miner performs selﬁsh
mining, a lot of blocks are orphaned so that the actual time
to mine 2016 blocks becomes longer. In the next difﬁculty
adjustment periods, the target difﬁculty is lowered down to
maintain the ﬁxed block generating rate.

B. Absolute Revenue

Previously we deﬁne the revenue of a miner in each mining
round and his/her relative revenue. However, the duration of
a mining round may not be ﬁxed all the time, and the actual

number of valid blocks obtained by a miner in each unit of
wall-clock time is overlooked. In Bitcoin system, we denote
10 minutes as the unit time, and denote a DAA period as the
expected time units of mining 2016 valid blocks.

Deﬁnition 3: (Absolute Revenue) The absolute revenue is

the average number of blocks obtained in each unit time.

#1 DAA Period. We treat the ﬁrst DAA period as the begin-
ning of selﬁsh mining in order to analyze the transient absolute
revenues of Alice and Bob. The following normalization rule
is made to simplify the analysis by eliminating the randomness
of block generating interval. A block is generated every time
unit at the ﬁrst difﬁculty adjustment period, i.e., ∆t1 = 1.

With the above assumption, we can easily compute the
duration of generating 2016 valid blocks,
though slightly
sacriﬁcing its rigorousness. Let Rvld be the total number of
valid blocks of all miners in a mining round, and let Rtot be
the total number of blocks including the valid and orphan
blocks in the same round. This means that a mining round
occupies Rtot time units. Denote by T1 the expected time
units to accomplish the ﬁrst DAA period. One can calculate
the time of mining rounds that the total number of valid blocks
reaches 2016. Then, T1 is equivalent to the sum of time units
of these mining rounds. There exists

Rvld = R1 + R2 + Rh;
Rtot = 1;

E[T1] =

2016
Rvld
Due to the orphaned blocks, Rtot is greater than Rvld so that
the actual time of the ﬁrst DAA period is longer than 2016
time units.

· Rtot.

(31)

Subsequent DAA Periods. After the ﬁrst DAA period, the
blockchain consensus mechanism ﬁnds that the time interval
of generating a valid block is longer than one time unit. Con-
sequently, the target difﬁculty decreases to match the current
valid (visible or perceptible) Hash power in the system. Given
the invariable Hash power of miners, the block generating
interval ∆ti becomes smaller for i ≥ 2. Let Ti be the expected
time units of the ith DAA period that has Ti = 2016 for i ≥ 2.
It is noted we assume Rtot ≤ (4 · Rvld). This is also the goal
that DAA is going to achieve.

Absolute Revenue Over Time. Recall that the absolute
revenue captures the expected reward of a miner in each
time unit. Since our purpose is to investigate the transient
proﬁtability of selﬁsh mining, we deﬁne ˜Ri(K) as the absolute
revenue of the ith miner over K DAA periods. Therefore, we
obtain the following expressions for ∀i ∈ {a, b, h}

˜Ri(K) =

=

1
k=1 E[Tk]

·

2016 · K · Ri
Rvld
2016 · KRi
Rtot + (K − 1)Rvld

(cid:80)K

.

(32)

Now we are aware that
the selﬁsh mining has a smaller
absolute revenue in the ﬁrst DAA period no matter whether the
Hash power of the attacker is above the stationary proﬁtable
threshold or not. This claim also holds in different selﬁsh
mining policies. As K increases, a selﬁsh miner hopefully

11

Fig. 9. Bob’s threshold under the inﬂuence of Alice’s Hashrate.

can reimburse his/her loss in the ﬁrst DAA period by his/her
extra revenue in the future DAA periods. With our absolute
revenue model, we can characterize how much time is needed
to make selﬁsh mining proﬁtable eventually.

VI. EVALUATION

In this section, we develop an event-driven simulator for
basic selﬁsh mining and a time-driven simulator for POMDP-
based selﬁsh mining. Comprehensive experiments validate the
correctness of our models and reveal
important properties
regarding the proﬁtability of selﬁsh mining.

A. Basic Selﬁsh Mining

Observation 1: When there are multiple attackers in Bitcoin-
like systems, the attackers’ proﬁtable thresholds decrease and
the system security is degraded.

2 and θ1=θ2= 1

We illustrate Bob’s proﬁtable threshold of selﬁsh mining
in Fig. 9 as Alice’s Hash power increases from 0 to nearly
0.5. To avoid involving too many control variables, the tie-
breaking parameters are set to γ1=γ2= 1
3 . One
can observe from three curves with different N that Bob’s
proﬁtable threshold decreases in the beginning and increases
afterwards. Especially when N = 2 and α1 = 0.16, Bob’s
proﬁtable threshold is the lowest. Under this situation, Alice’s
selﬁsh mining may yield less revenue compared with her
honest mining. We further draw a 45◦ line to indicate the
proﬁtable threshold for both Alice and Bob when their Hash
power are symmetric. When N is 2, 3 and 4, the proﬁtable
threshold is 26.64%, 22.57% and 21.48%. In contrast, it takes
the value of 33.33%, 28.08% and 26.50% respectively,
if
there has a single attacker. An obvious conclusion is that the
existence of multiple attackers makes the selﬁsh mining more
easily proﬁtable.

Observation 2: The proﬁtable threshold decreases with
the increase of N , and remains stable with the attackers of
symmetric Hash power as N ≥ 4; it also decreases when the
number of attackers m increases.

We evaluate the proﬁtable thresholds of BSM with different
N and m. Our purposes are twofold: one is analyzing the inter-
play between this threshold and the environment variables, and
the other is justifying the use of N ≤ 4 in the mathematical
modeling. The Hash powers of all the attackers are identical,

12

Fig. 10. Proﬁtable threshold vs the maximum num-
ber of private blocks (N ).

Fig. 11. Henry’s orphan block ratio vs the maximum
number of private blocks (N ).

Fig. 12.
attackers (m).

Proﬁtable threshold vs the number of

Fig. 13. Alice’s Revenue with α1> max(α2, αh). Fig. 14. Simulated threshold for Bob when α1 >

max(α2, αh).

Fig. 15. Simulated threshold for Bob when αh >
max(α1, α2).

and the competing chains are indistinguishable upon the tie-
breaking rules.

Fig. 10 shows the relationship between N and the proﬁtable
threshold. The cases with 1, 2, 3 and 4 symmetric attackers are
expressed in solid, dashed, dash-dotted and dotted lines. One
can observe that the proﬁtable threshold decreases remarkably
for different m as N increases from 2 to 4. The event-driven
simulations exhibit a stable proﬁtable threshold when Alice
and Bob can hold more than 5 private blocks. For instance, this
threshold converges to 25% for a sufﬁciently large N with a
single attacker, which is in line with [2]. With two symmetric
attackers (m = 2), its value is 20.60% at N = 30, slightly
different from that at N = 4. In general, Alice’s or Bob’s
Hash power is much smaller than Henry’s Hash power. The
chance that Alice’s or Bob’s private chain takes a large lead
over the public chain in a mining round is very small. Hence, it
does not make an evident inﬂuence on the proﬁtable threshold
when N is already large. Moreover, hiding a long private
chain and releasing all the blocks simultaneously will make the
selﬁsh mining attack easily detected. Fig. 11 shows Henry’s
orphan block ratio as N increases from 2 to 9 with m = 2.
Even though Alice’s and Bob’s Hash powers are merely (0.22,
0.22), they cause a very high orphan block ratio to Henry,
e.g., 18.73% with N = 2, 28.53% with N = 4 and 31.66%
with N = 9. Such a high orphan ratio can easily expose the
identity of attackers. Therefore, our modeling framework only
considers N ≤ 4 though it is extensible to N > 4.

We use mathematical models and event-driven simulations
to quantify the impact of m on the proﬁtable threshold in Fig.
10 and 12. One can observe that the increase in the number

of attackers reduces the proﬁtable threshold, thus endangering
blockchain security. For N = 4, the proﬁtable thresholds
with m ∈ {2, 4, 8} are {0.2148, 0.155, 0.11} respectively. This
challenges the cognition that selﬁsh mining is less likely to
happen if the Hash power of a mining pool is below 25%. The
primary reason that more attackers lead to smaller proﬁtable
thresholds lies in that the Hash power of the honest miner
declines relatively. Meanwhile, our model coincides with the
simulation result at N = 2 in Fig. 12, thus validating its
correctness.

Since the advent of the seminal work [2],

the Bitcoin
community tries to constrain mining pools to possess less
than 25% of Hash power. However, we prove that 25% is not
enough: Bitcoin mining is fragile in the presence of multiple
selﬁsh miners.

Observation 3:

If αh < max(α1, α2), the revenue of
the attacker with more Hash power among three miners will
increase as N increases. If αh > max(α1, α2), the revenue
of the attacker with more Hash power will increase ﬁrst and
then remain stable as N increases. The common beneﬁt Hash
two attackers increases at ﬁrst and then
power region of
decreases with the increase of N .

We explore the revenue of the attackers with more Hash
power than the honest miner under different N when αh <
max(α1, α2). In Fig. 13, we show Alice’s revenue of Alice at
four situations: the Hash powers of Alice, Bob and Henry are
(0.45, 0.25, 0.3), (0.4, 0.3, 0.3), (0.35, 0.25, 0.4) and (0.3, 0.3,
0.4) that are labeled as situations 1, 2, 3 and 4. Situations 1
and 2 manifest that the revenue of the attacker with more Hash
power than others increases as N increases. The attacker can

13

Fig. 16. Proﬁtable regions of both selish mining attackers with N = 2, 3, 4, 5, 7, 8, 15, 25, 35, ∞.

also encourages other miners including other selﬁsh mining
attackers to continue mining even if N is large. According
to these analyses, the attacker will not hide too many blocks
even he has more Hash power than others.

We now analyze the interplay between Alice’s and Bob’s
proﬁtable thresholds. Fig. 16 shows the proﬁtable regions for
each attacker under different N . The blue part indicates that
neither attacker can gain additional revenue if they perform
the BSM attack, and the red part indicates that both attackers
can gain additional revenue through selﬁsh mining. The green
(resp. orange) part represents the situation that only Alice
(resp. Bob) can obtain extra revenue. The intersection of four
regions is actually the proﬁtable threshold with symmetric
Hash powers of Alice and Bob that decreases over N and
converges gradually. The common proﬁtable region (in red)
ﬁrst expands and then shrinks as N increases. The reason is
the following. A large red region basically says that both Alice
and Bob are proﬁtable with BSM even if their Hash powers are
asymmetric to some extent. When N is very small, Alice and
Bob can hide only a couple of blocks so that their ability of
wasting Henry’s Hash power is restrained. With the increases
of N , their selﬁsh mining ability becomes more powerful,
and thus could have more chances of obsoleting the public
chain even if each of them has a smaller Hash power than
Henry. Meanwhile, given the restriction of N , both Alice and
Bob may receive a certain amount of extra revenues, resulting
in a larger common proﬁtable region. When N is large, the
stronger attacker is inclined to dominating the selﬁsh mining.
If Alice’s Hash power is larger than Bob’s, Bob will ﬁnd
it difﬁcult to compete with Alice so that Bob’s proﬁtable
threshold is getting higher. If Alice’s Hash power is the largest,
it is similar to 51% attack. Bob’s selﬁsh mining is proﬁtable
only when Alice’s and Bob’s Hash powers are sufﬁciently
close, causing the common proﬁtable region to shrink to a
line segment.

Fig. 17. Estimating Bob’s Hash power by observing orphan block ratio.

obtain more than 90% of the revenue, achieving the similar
effect as the 51% attack, even though she does not have
51% of Hash power. Situation 3 and 4 show that Alice’s
revenue converges as N increases if Henry has the largest Hash
power. The revenue of Alice converges to 0.524 in situation
3 and 0.357 in situation 4 with N = 200. This implies that
limiting the attacker’s Hash power will prevent the attacker
from obtaining too many revenues when N is large.

We then investigate Bob’s proﬁtable threshold when Alice
has a different Hash power and N is large. Fig. 14 shows Bob’s
thresholds under different N when Alice has the largest Hash
power, i.e. α1 > max{α2, αh}. Bob’s proﬁtable threshold
decreases ﬁrst and then increases as N increases. That means
even if Bob can obtain extra revenue when N is small,
he can not obtain extra revenue when N is large enough.
Under this circumstance, Alice’s revenue can obtain far more
than her Hash power proportion, and her attack becomes
meaningless because this system can not attract other miners
even other selﬁsh mining attackers. Fig. 15 shows Bob’s
proﬁtable threshold will decrease ﬁrst and then converge as N
increases when Henry has more Hash power than Alice and
Bob. This suggests that limiting the attacker’s Hash power

14

Fig. 18. Optimal revenue for Alice when N = 2.

Fig. 20. Proﬁtable threshold for Alice when N = 2.

Fig. 19. Optimal revenue for Alice when N = 3.

B. MDP and POMDP-based Mining

The roadmap of performing optimal mining is the follow-
ing. We explore its feasibility by estimating the unknown
parameters. Then, we compute the optimal mining policy
and the corresponding revenue using MDP, and on this basis
we compute the optimal mining policy using POMDP under
partially observable states.

Recall that Alice is the optimal miner (OPT) and Bob is the
basic selﬁsh miner (BSM). At the ﬁrst stage, Alice needs to
decide whether there exists a selﬁsh miner namely Bob, and
if so, what Bob’s Hash power is. Note that there has a one-to-
one mapping between Henry’s orphan block ratio and Bob’s
Hash power. Fig. 17 shows the orphan ratio of the honest
miner as a function of Bob’s Hash power with N = 2 and
N = 3. The theoretical and experimental results match well,
which indicates the feasibility of calculating Bob’s Hash power
through the observed orphan block ratio.

We next compute Alice’s optimal policy and the corre-
sponding revenue of OPT mining. Let the error parameter
(cid:15) = 0.00001 and the execution number ξ0 = 500000. Fig.
18 illustrates the optimal revenue obtained by Alice when
Alice’s Hash power is α1 ∈ {0.10, 0.15, 0.20, 0.25, 0.30, 0.35,
0.40, 0.45}, Bob’s Hash power is α2 ∈ {0.30, 0.35, 0.40} and
N = 2. The maximum length of longest public chain is set
as (N + 1). One can observe that Alice’s optimal mining and
honest mining yield the same revenue when her mining power
is relatively small, e.g. α1 = 0.1, α2 = 0.40 and αh = 0.50.
Under these situations, the optimal mining policy is exactly the
honest mining, while BSM underperforms the honest mining
signiﬁcantly. On the contrary, when Alice’s Hash power is

Fig. 21. Proﬁtable threshold for Alice when N = 3.

large, e.g., α1 = 0.40, α2 = 0.40 and αh = 0.20, the optimal
mining policy results in a higher revenue than the basic selﬁsh
mining, and the basic selﬁsh mining is better than the honest
mining. Fig. 19 shows a set of similar experiments except for
N = 3. When α1 = 0.30, α2 = 0.30 and αh = 0.4, Alice’s
optimal mining policy obviously outperforms both BSM and
the basic selﬁsh mining.

We describe a concrete example of optimal mining policy at
a few representative states for simplicity. Table I shows Alice’s
optimal strategy with α1=0.2, α2=0.4 and αh=0.4. Alice has
less Hash power than Bob and Henry. She chooses to adopt
the public chain if the length of her chain is shorter than that
of Bob or Henry. If the length of the chain (i.e. l1 + h1) she is
mining on is equal to that of the public chain (i.e. h3), and is
able to “fork”, she will release l1 private blocks to seize the
chance of winning. If both Alice and Bob hold a private block,
she will choose to hide the private block and continue to mine
after her own block. By performing the optimal policy, Alice
can earn an additional 0.08% revenue, even though Bob has
40% Hash power.

TABLE I
OPTIMAL POLICY FOR (α1 = 0.2, α2 = 0.4, N = 2).

state
(l2 + h2) > (l1 + h1)
h3 > (l1 + h1)
(l1 + h1) = (l2 + h2) = h3, f ork = r
l1 = l2 = 1, h3 = 0
l1 = 1, l2 = 0
(l1 + h1) > (l2 + h2)

action
adopt
adopt
l1
0
l1
l1

Observation 4: When Alice uses the POMDP-based policy,
and Bob uses the basic selﬁsh mining, Alice has a much lower
proﬁtable threshold compared with the basic selﬁsh mining.

15

Fig. 22.
0.3, N = 2.

The revenue for Alice when α2 =

Fig. 23.
0.35, N = 2.

The revenue for Alice when α2 =

Fig. 24.
0.4, N = 2.

The revenue for Alice when α2 =

Fig. 25.
0.26, N = 3.

The revenue for Alice when α2 =

Fig. 26.
0.28, N = 3.

The revenue for Alice when α2 =

Fig. 27.
0.3, N = 3.

The revenue for Alice when α2 =

Her revenue is no less than the honest mining and the basic
selﬁsh mining, and is close to the MDP-based policy with
complete state information.

We further evaluate Alice’s proﬁtable threshold and revenue
when she uses the POMDP-based mining policy. Fig. 20
and 21 compare the proﬁtable thresholds of BSM, MDP-
based (OPT) and POMDP-based (POMDP) mining strategies
when N = 2, 3 and α2 increases from 0.285 to 0.42. An
interesting ﬁnding is that both OPT and POMDP strategies
have much smaller proﬁtable thresholds compared with BSM.
For instance, the proﬁtable threshold is 0.02 when α2 = 0.34
and N = 2, and is 0.08 when α2 = 0.3 and N = 3. The
reason is the following. When Bob is playing BSM and Bob’s
Hash power is much larger than Alice’s, Alice will choose
to mine honestly. If there is a fork between Bob and Henry,
Alice insists on mining on the public chain that contains her
own blocks. Alice’s policy is equivalent to decreasing γ2 in
the situation of a single attacker. Therefore, Bob will ﬁnd it
difﬁcult to gain more revenues, and Alice as well as Henry
beneﬁt from Bob’s losses. When Alice’s Hash power is below
the proﬁtable threshold, the POMDP policy cannot yield the
revenue commensurable with her Hash power. In addition,
with the increase of Bob’s Hash power, Alice’s proﬁtable
threshold becomes higher. A cross-comparison between Fig.
20 and Fig. 21 shows that a larger N makes Alice hard to
compete with Bob if α1 ≤ α2. When Bob’s Hash power is
0.36, Alice’s proﬁtable threshold is 0.08 when N = 2 and is
about 21.6% when N = 3.

The POMDP policy can improve Alice’s revenue under
different situations. Fig. 22∼24 plot Alice’s revenues using
Honest mining, BSM, OPT and POMDP-based mining at
N = 2; Fig. 25∼27 show those revenues with N = 3. In
each set of experiments, we ﬁx Bob’s Hash power (α2) and

changes Alice’s Hash power (α1) from 0.20 to 0.40. As for
the POMDP policy, three cases are considered, in which the
probability of generating a block is 0.9, 0.8 or 0.5 at each time
slot. Note that this probability does not inﬂuence the execution
of our POMDP solver. One can easily observe that the POMDP
policy has the comparable revenues with the honest and the
MDP mining policies when Alice’s Hash power is relatively
small. While the basic selﬁsh mining seems very “stubborn”,
causing Alice’s revenue much lower than the honest mining
in this situation. The PODMP-based policy generates equal or
higher revenues than the honest mining and the basic selﬁsh
mining, and approaches the performance of the MDP policy.
The designed online algorithm can effectively calculate
the optimal revenue of MOP . We compare the number of
iterations required to execute the binary search algorithm in [7]
and Algorithm 1. The reduction ratios are summarized in Table
II. Under different Hash power combinations and different
action slots, the efﬁciency of Algorithm 1 is signiﬁcantly
higher. When N = 2, α1 = 0.3, α2 = 0.3 and p = 0.5,
we can save 46% of the computing time. It takes a long time
to simulate half a million times to obtain the revenue for each
ρ. The improvement of our search algorithm plays a signiﬁcant
role in solving MP O rapidly.

C. Selﬁsh Mining on Multiple Difﬁculty Adjustment Periods

Observation 5: A selﬁsh miner obtains a smaller absolute
revenue than that of honest mining during the ﬁrst difﬁculty
adjustment period regardless of his Hash power. However, he
might gain proﬁt after a number of periods that is related to
the selﬁsh miners’ Hash power.

Fig. 28 shows the relative revenue and absolute revenue of
attackers with same Hashrate 33% and N = 4 in each DAA

16

Fig. 28. Relative revenue and absolute revenue when
α1 = α2 = 0.33, N = 4.

Fig. 29. The theoretical relative revenue and abso-
lute revenue when α1 = α2 after 100 periods.

Fig. 30. The theoretical relative revenue and abso-
lute revenue when α1 = α2 after 1000 periods.

TABLE II
THE TIME REDUCTION RATIO OF ALG. 1 COMPARED TO TRADITIONAL
ALGORITHM.

Hash power
α1 = 0.3, α2 = 0.3

N = 2
α1 = 0.35, α2 = 0.35

N = 2

α1 = 0.28, α2 = 0.28

N = 3

α1 = 0.3, α2 = 0.3

N = 3

p
0.9
0.8
0.5
0.9
0.8
0.5
0.9
0.8
0.5
0.9
0.8
0.5

EFF IMP
53.3%
46.6%
66.6%
80%
60%
46.7%
60%
46.7%
46.7%
73.3%
46.7%
40%

Fig. 31. Proﬁtable time and Hash power.

period. The relative revenue and absolute revenue are equal
within the allowable range of error. Therefore, the relative
revenue can play the same rule with absolute revenue in
representing beneﬁt. Fig. 29 and Fig. 30 show the theoretical
relative revenue and absolute revenue after 100 and 1000
DAA periods when α1 = α2. It can be observed that the
absolute revenue is always less than the relative revenue,
but the difference is small. When α1 = 0.22, the relative
revenue is 0.2217 and the absolute revenue is 0.2209. This
difference decreases to 0.0001 after 1000 periods. That means
the difference between relative revenue and absolute revenue
decreases with the increase of the attack time.

As Eq. (32) shows, when Alice has more Hash powers,
she can get illegal revenue earlier. However, if both of the
two attackers has large Hashrate, they will beneﬁt late. Fig.

31 shows the simulation results and the theoretical results of
proﬁtable time under different Hash powers with symmetric
attackers. The horizontal axis represents the attack’s Hash
power and the ordinate represents the attackers’ proﬁtable
time, also the curves are theoretical results and the dots are
simulation results. The selﬁsh mining is proﬁtable after 51
rounds of difﬁculty adjustment (i.e. 714 days in Bitcoin) if the
Hashrates of selﬁsh miners are both 22% (slightly higher than
the proﬁtably threshold). This delay decreases to 5 rounds (i.e.
70 days in Bitcoin) as their Hashrates accrues to 33%, which is
still very long. As the attackers gained more computing power,
Alice’s main competitor became Bob rather than Henry. The
beneﬁt time begins to increases for Alice and Bob. When there
is only one attacker and she has 25.5% Hashrates, the attacker
will obtain extra revenue after 26 rounds (about 364 days).

It shows that when attackers’ Hashrate is relatively small,
it takes a rather long period to gain proﬁt. When the two
attackers all have large Hashrates, it also takes a long period
to obtain extra revenue. That means in the real system, it is a
little bit hard to perform attack. If the global Hashrate increase,
we can also use this formula to calculate when to stop the
attack before we can beneﬁt the most.

VII. RELATED WORK

Selﬁsh mining attack is one of the core challenges of
blockchain consensus that has been extensively studied in the
past several years. We hereby describe the recent advances
in selﬁsh mining policies and their analytical or experimental
performance.

One attacker. Since the advent of [2], there have been many
studies on different forms of selﬁsh mining attacks. Nayak
et al. [9] proposed the stubborn mining based on the basic
selﬁsh mining, it points out that selﬁsh mining is not always
the best for different parameters. The stubborn attack improves
about 13.94% revenues compared with the basic selﬁsh mining
attack. A more intelligent selﬁsh mining strategy has been
proposed in [7] based on the Markov Decision Process and it
decreases the proﬁtable threshold to 23.21%. Tao et al. [20]
described semi-selﬁsh mining attack on the basis of selﬁsh
mining based on hidden Markov decision process, which not
only ensures the beneﬁt of the attack, but also reduces the fork-
ing rate. Negy et al. [23] introduced intermittent selﬁsh mining
and showed that the intermittent selﬁsh miner above 37% hash
power earns more coins per time unit even when γ = 0. Negy
and Davidson et al. [23] [24] simulated the proﬁtability of

selﬁsh mining under several difﬁculty adjustment algorithms
used in popular cryptocurrencies.Selﬁsh mining attack takes
on different properties in the Ethereum system because of
the uncle block. Grunspan and Ritz introduced the selﬁsh
mining attack in Ethereum and found that Ethereum is more
vulnerable to selﬁsh mining than Bitcoin [25] [26].

At the same time, selﬁsh mining attack can also be com-
bined with other attacks to achieve greater beneﬁts. Gervais et
al. devised optimal strategies for double-spending and selﬁsh
mining while taking into account real world constraints such
as network propagation, different block sizes, block generation
intervals, information propagation mechanism, and the impact
of eclipse attacks [22]. Kwon et al. [14] proposed FAW attack
which combines the selﬁsh mining attack and withholding
attack. The reward for an FAW attacker is always equal to
or greater than that for a BWH attacker. Gao et al. extended
the work of Kwon et al. proposing the power adjusting with-
holding attack (PAW) and bribery selﬁsh mining attack (BSM)
[15]. They showed PAW could avoid the “miner’s dilemma”
in BWH attack and BSW increases 10% revenues compared
with traditional SM [33]. However, BSW will introduce “venal
miner’s dilemma”. To avoid the “venal miner’s dilemma”,
Yang et al. proposed the IPBSM attack which assumed all
attackers take the optimal bribery selﬁsh mining [16].

Multiple attackers. The participation of multiple attackers in
the system will greatly change the beneﬁts of selﬁsh mining
attacks. Ruan et al. simulated the situation in which there are
two attackers in the system and obtained the corresponding
threshold will decrease [3]. Francisco et al. proposed semi-
selﬁsh mining when there are two attackers and modeled this
attack [17]. They obtained the Nash equilibrium under differ-
ent Hash powers and the threshold for each policy based on the
game theory. Also, they model the situation when the number
of attackers is more than two. However, they do not get the
closed-form result. Azimy et al. designed a Bitcoin network
simulator and used it to simulate different conﬁgurations of
miners to be able to address this problem. Their ﬁnding shows
that in almost all of the conﬁgurations, with the presence of a
more powerful selﬁsh miner, selﬁsh mining actually decreases
the revenue of the weaker selﬁsh miners and also helps the
stronger selﬁsh miner [30]. Sebastian et al. proposed the
simulation results that the proﬁtable threshold decreases in
proportion to the number of selﬁsh miners [35]. Moreover,
there exist Nash equilibrium where all selﬁsh miners mine
honestly and simultaneously earn their unfair mining reward.
Zhang et al. simulated the situation when there were multiple
selﬁsh mining attackers in the system. It shows there are
scenarios where it is enough to have 12% mining power to
beneﬁt from selﬁsh mining but also that having more than
seven selﬁsh miners which beneﬁt simultaneously is highly
unlikely [18]. Charlie et al. proposed SquirRL which is a
framework for using deep reinforcement learning to analyze
attacks on blockchain incentive mechanisms. The revenue of
SquirRL is greater than that of the Markov decision attackers
when there are multiple selﬁsh mining attackers [19]. Xia et
al. explored the impact of multiple miners and propagation
delay on selﬁsh mining [29].

17

VIII. CONCLUSION
In this paper, we ﬁrst study how the existence of multiple
misbehaving miners inﬂuences the proﬁtability of basic selﬁsh
mining. By establishing the Markov chain model to describe
the action of attackers and honest miners, we can obtain the
minimum proﬁtable threshold is symmetric 21.48%, which
decreases as the number of symmetric attackers increases.
If there are two asymmetric selﬁsh mining attackers in the
system, the proﬁtable threshold of one attacker decreases ﬁrst
and then increases with the increase of the other attacker’s
Hash power. We validate this in both models and experiments.
We next investigate the revenues of the attackers when one
executes the basic selﬁsh mining and the other implements the
strategic mining. A new mining strategy is designed for the
miners with incomplete information based on POMDP. We
can obtain revenue by the new strategy no less than honest
mining and basic selﬁsh mining. Considering the difﬁculty
adjustment, we model the transient process and acquire the
closed-form solution of the proﬁtable time. It can be discov-
ered that the proﬁtable time is large when the attacker’s Hash
power is low. Moreover, there is a negative correlation between
the proﬁtable time and the attackers’ mining power.

REFERENCES

[1] S. Nakamoto. “Bitcoin: A peer-to-peer electronic cash system” , 2008.
[2] I. Eyal and E. G. Sirer. “Majority is not enough: Bitcoin mining is
vulnerable”. In Financial Cryptography and Data Security. Springer,
2014, pp. 436-454.

[3] Q.H. Liu, N. Ruan, et al. “On the Strategy and Behavior of Bitcoin
Mining with N-attackers”. Proc. of the Asia Conference on Computer
and Communications Security, pp. 357-368, 2018.

[4] https://decrypt.co/35373/how-long-does-it-take-to-mine-a-bitcoin,

[online].

[5] A. Papoulis, S. U. Pillai. Probability, random variables, and stochastic

processes[M]. Tata McGraw-Hill Education, 2002.

[6] R. Pass, E. Shi, “Fruitchains: A fair blockchain”. Proc. of the Asia Con-
ference on Computer Symposium on Principles of Distributed Computing,
pp. 315-324, 2017.

[7] A. Sapirshtein, Y. Sompolinsky, A. Zohar. “Optimal selﬁsh mining strate-
gies in bitcoin”. International Conference on Financial Cryptography and
Data Security, pp. 515-532, 2016.

[8] S. Jiang and J. Wu, “Bitcoin Mining with Transaction Fees: A Game on
the Block Size,” in 2019 IEEE International Conference on Blockchain
(Blockchain), Atlanta, GA, USA, Jul. 2019, pp. 107–115.

[9] K. Nayak, S. Kumar, A. Miller, and E. Shi, “Stubborn Mining: Generaliz-
ing Selﬁsh Mining and Combining with an Eclipse Attack,” in 2016 IEEE
European Symposium on Security and Privacy (EuroS&P), Saarbrucken,
Mar. 2016, pp. 305–320.

[10] Puterman, Martin L. Markov decision processes: discrete stochastic

dynamic programming. John Wiley Sons, 2014.

[11] Ross, Stephane, and Brahim Chaib-Draa. “AEMS: An anytime online ´
search algorithm for approximate policy reﬁnement in large POMDPs.”
IJCAI. 2007, pp. 2592-2598.

[12] Karkus, Peter, David Hsu, and Wee Sun Lee. “QMDP-Net: deep
learning for planning under partial observability.” Proceedings of the
31st International Conference on Neural Information Processing Systems.
2017.

[13] P. Ashok, K. Chatterjee, P. Daca, J. Kˇret´ınsk´y, and T. Meggendorfer,
“Value Iteration for Long-Run Average Reward in Markov Decision
Processes,” in Computer Aided Veriﬁcation, vol. 10426, Springer Inter-
national Publishing, 2017, pp. 201–221.

[14] Y. Kwon, D. Kim, Y. Son, E. Vasserman, and Y. Kim, “Be Selﬁsh and
Avoid Dilemmas: Fork After Withholding (FAW) Attacks on Bitcoin,”
in Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security, Dallas Texas USA, Oct. 2017, pp. 195–209.

[15] S. Gao, Z. Li, Z. Peng, and B. Xiao, “Power Adjusting and Bribery
Racing: Novel Mining Attacks in the Bitcoin System,” in Proceedings of
the 2019 ACM SIGSAC Conference on Computer and Communications
Security, London United Kingdom, Nov. 2019, pp. 833–850.

.

18

[16] G. Yang, Y. Wang, Z. Wang, Y. Tian, X. Yu, and S. Li, “IPBSM: An
optimal bribery selﬁsh mining in the presence of intelligent and pure
attackers,” Int J Intell Syst, vol. 35, no. 11, pp. 1735–1748, Nov. 2020.
[17] F. J. Marmolejo-Coss´ıo, E. Brigham, B. Sela, and J. Katz, “Competing
(Semi-)Selﬁsh Miners in Bitcoin,” in Proceedings of the 1st ACM Con-
ference on Advances in Financial Technologies, Zurich Switzerland, Oct.
2019, pp. 89–109.

[18] S. Zhang, K. Zhang, and B. Kemme, “Analysing the Beneﬁt of Selﬁsh
Mining with Multiple Players,” in 2020 IEEE International Conference on
Blockchain (Blockchain), Rhodes Island, Greece, Nov. 2020, pp. 36–44.
[19] Hou, Charlie, et al. “SquirRL: Automating attack analysis on blockchain
incentive mechanisms with deep reinforcement learning.” arXiv 2019.
[20] T. Li, Z. Wang, G. Yang, Y. Cui, Y. Chen, and X. Yu, “Semi-selﬁsh
mining based on hidden Markov decision process,” Int J Intell Syst, vol.
36, no. 7, pp. 3596–3612, Jul. 2021.

[21] Meyn, Sean P., and Richard L. Tweedie. Markov chains and stochastic

stability. Springer Science & Business Media, 2012.

[22] A. Gervais, et al., “On the Security and Performance of Proof of Work
Blockchains,” in Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security, Vienna Austria, Oct. 2016, pp.
3–16.

[23] K. A. Negy, P. R. Rizun, and E. G. Sirer, “Selﬁsh Mining Re-Examined,”
in Financial Cryptography and Data Security, vol. 12059, J. Bonneau
and N. Heninger, Eds. Cham: Springer International Publishing, 2020,
pp. 61–78.

[24] Davidson, Michael, and Tyler Diamond. “On the Proﬁtability of Self-
ish Mining Against Multiple Difﬁculty Adjustment Algorithms.” IACR
Cryptol. ePrint Arch. 2020 (2020): 94.

[25] C. Grunspan and R. Perez-Marco, “Selﬁsh Mining in Ethereum,” in
Mathematical Research for Blockchain Economy, P. Pardalos, I. Kotsireas,
Y. Guo, and W. Knottenbelt, Eds. Cham: Springer International Publish-
ing, 2020, pp. 65–90.

[26] F. Ritz and A. Zugenmaier, “The Impact of Uncle Rewards on Selﬁsh
Mining in Ethereum,” in 2018 IEEE European Symposium on Security
and Privacy Workshops (EuroS&PW), London, Apr. 2018, pp. 50–57.

[27] https://tradeblock.com/bitcoin/historical.
[28] S. Ross, J. Pineau, S. Paquet, and B. Chaib-draa, “Online Planning

Algorithms for POMDPs”, jair, vol. 32, pp. 663–704, Jul. 2008.

[29] Q. Xia et al., “The Impact Analysis of Multiple Miners and Propagation
in 2021 IEEE 45th Annual Computers,
Delay on Selﬁsh Mining”,
Software, and Applications Conference (COMPSAC), Madrid, Spain, Jul.
2021, pp. 694–703.

[30] H. Azimy and A. Ghorbani, “Competitive Selﬁsh Mining”, in 2019
17th International Conference on Privacy, Security and Trust (PST),
Fredericton, NB, Canada, Aug. 2019, pp. 1–8.

[31] Q. Bai, X. Zhou, X. Wang, Y. Xu, X. Wang, and Q. Kong, “A Deep Dive
Into Blockchain Selﬁsh Mining”, in ICC 2019 - 2019 IEEE International
Conference on Communications (ICC), Shanghai, China, May 2019, pp.
1–6.

[32] C. Grunspan and R. P´erez-Marco, “On proﬁtability of selﬁsh mining”,

arXiv, 2019.

[33] I. Eyal, “The Miner’s Dilemma”, arXiv, 2014.
[34] X. Dong, F. Wu, A. Faree, D. Guo, Y. Shen, and J. Ma, “Selfholding:
A combined attack model using selﬁsh mining with block withholding
attack,” Computers & Security, vol. 87, p. 101584, Nov. 2019.

[35] T. Leelavimolsilp, L. Tran-Thanh, and S. Stein, ”On the Preliminary
Investigation of Selﬁsh Mining Strategy with Multiple Selﬁsh Miners,”
arxiv, 2018.

[36] Littman et al., ”Learning policies for partially observable environments:
scaling up”. In Proceedings of the 12th International Conference on
Machine Learning (ICML-95), pp. 362–370.

19

APPENDIX

TABLE III
A DESCRIPTION OF THE TRANSITION AND REWARD MATRICES P AND R IN THE DECISION PROBLEM M .

adopt

h1 + action < h3

h1 + action = h3

loc! = 2

loc = 2

r, action > 0

f13, action = 0

l2 + h2 − h3 > 2

h3 < h1 + action < l2 + h2 − 1

h1 + action = l2 + h2 − 1

h1 + action = l2 + h2

h1 + action > l2 + h2

adopt

h1 + action < h3

h1 + action = h3

h1 + action = l2 + h2 − 1

h1 + action = l2 + h2

h1 + action > l2 + h2

loc! = 2

loc = 2

r, action > 0
f13, action = 0

l2 + h2 − h3 = 2

adopt

loc = 2, loc = 3

l2 + h2 − h3 = 1

h1 + action < h3

h1 + action = l2 + h2

h1 + action > l2 + h2

α1
α2
αh
α1
α2
αh
α1
α2
αh
α1
α2
αhγ1
αh(1 − γ1)
α1
α2
αh
α1
α2
αh
α1
α2
αhβ1
αhβ2
α1
α2
αh
α1
α2
αh
α1
α2
αh
α1
α2
αh
α1
α2
αh
α1
α2
αh
α1
α2
αhβ2
αhβ1
α1
α2
αh
α1
α2
αh
α1
α2
αh
α1
α2
αhβ2
αhβ1
α1
α2
αh

(1, ir, 1, l2, h3, h2, h3, µ3, µ2, µ3)
(1, ir, 0, l2 + 1, h3, h2, h3, µ3, µ2, µ3)
(1, r, 0, l2, h3, h2, h3 + 1, µ3, µ2, µ3 + 1)
(1, ir, 1, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 0, l2 + 1, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, r, 0, l2, h3 − h2, 0, h3 − h2 + 1, h3 − h2, 0, h3 − h2 + 1)
(loc, ir, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action, l2 + 1, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, r, l1 − action, l2, h1 + action, h2, h3 + 1, µ1, µ2, µ3 + 1)
(loc, f13, l1 − action + 1, l2, h3, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action, l2 + 1, h3, h2, h3, µ1, µ2, µ3)
(1, r, l1 − action, l2, h3, h2, h3 + 1, µ1, µ2, µ1 + 1)
(1, r, l1 − action, l2, h3, h2, h3 + 1, µ1, µ2, µ3 + 1)
(1, ir, l1 − action + 1, l2, h1 + action, h2, h1 + action, µ1, µ2, µ1)
(1, ir, l1 − action, l2 + 1, h1 + action, h2, h1 + action, µ1, µ2, µ1)
(1, r, l1 − action, l2, h1 + action, h2, h1 + action + 1, µ1, µ2, µ1 + 1)
(2, r, l1 + 1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 1, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(loc, f12, l1 − action + 1, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(1, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, 0, 0, 1, 1, 0, 1, 1)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))
(1, ir, 1, l2, h3, h2, h3, µ3, µ2, µ3)
(1, ir, 0, l2 + 1, h3, h2, h3, µ3, µ2, µ3)
(2, r, 0, 0, h3, h2 + l2, h2 + l2, µ3, µ2, µ2)
(1, ir, 1, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 0, l2 + 1, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(2, r, 0, 0, h3 − h2, l2, l2, h3 − h2, 0, 0)
(loc, ir, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action, l2 + 1, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(loc, f13, l1 − action + 1, l2, h3, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action, l2 + 1, h3, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 + 1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 1, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(loc, f12, l1 − action + 1, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(1, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, 0, 0, 1, 1, 0, 1, 1)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))
(1, ir, 1, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 0, l2 + 1, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(loc, f23, 0, 0, h3 − h2, h3 − h2 + 1, h3 − h2 + 1, 0, 0, 1)
(loc, ir, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action, l2 + 1, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, f23, l1 − action, 0, h1 + action, h3 + 1, h3 + 1, µ1, µ2, µ3 + 1)
(loc, f12, l1 − action + 1, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(1, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, 0, 0, 1, 1, 0, 1, 1)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))

(0, 0, 0)

(0, h2 − µ2, µ2)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(h1 + action − µ1, 0, µ1)

(h1 + action − µ1, 0, µ1)

(0, 0, 0)

(0, h2 − µ2, µ2)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(h1 + action − µ1, 0, µ1)

(h1 + action − µ1, 0, µ1)

(0, h2 − µ2, µ2)

(0, 0, 0)

(0, 0, 0)

(h1 + action − µ1, 0, µ1)

(h1 + action − µ1, 0, µ1)

20

adopt

f23, f123, loc = 2

f23, f123, loc! = 2

(r, ir, loc = 2), f12

(r, ir, loc! = 2), f13

l2 + h2 = h3

action = 0

f12

f13

f23

f123

r, ir

f23

action = h3 − h1 > 0

r, h2 = µ2

r, h2! = µ2

h1 + action > l2 + h2

α1γ2
α1(1 − γ2)
α2
αhγ2
αh(1 − γ2)
α1γ2
α1(1 − γ2)
α2
αhγ2
αh(1 − γ2)
α1
α2
αh
α1
α2
αh
α1
α2
αhβ1
αhβ2
α1
α2γ1
α2(1 − γ1)
αhγ1
αh(1 − γ1)
α1
α2
αhγ2
αh(1 − γ2)
α1
α2
αhθ1
αhθ2
αh(1 − θ1 − θ2)
α1
α2
αh
α1
α2
αhθ1
αhθ2
αh(1 − θ1 − θ2)
α1
α2γ1
α2(1 − γ1)
αhγ1
αh(1 − γ1)
α1
α2
αhβ1
αhβ2
α1
α2
αh

(1, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, r, 0, 0, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 0, 0, 0, 0, 0)
(1, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, r, 0, 0, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 1, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 1, 1, 0, 1, 1)
(3, ir, 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 1, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 1, 1, 0, 1, 1)
(loc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(1, r, l1, l2, h1, h2 + 1, h2 + 1, µ1, µ2, µ2)
(2, r, l1, l2, 0, 1, 1, 0, 1, 1)
(1, r, l1, l2, h1, h2 + 1, h3 + 1, µ1, µ2 + 1, µ2 + 1)
(1oc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(2, r, l1, l2, 0, 1, 1, 0, 0, 0)
(2, r, l1, l2, 0, h3 + 1, h3 + 1, µ1, µ3, µ3)
(2, r, l1, 0, 0, 1, 1, 0, 1, 1)
(2, r, l1, l2, h1, h3 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(1, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ2, µ2)
(2, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(2, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ2, µ2)
(2, r, l1, 0, 0, 1, 1, 0, 1, 1)
(2, r, l1, 0, h1, h3 + 1, h3 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1, 0, h1, h3 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, ir, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(loc, ir, l1, l2 + 1, h1, h2, h3, µ1, µ2, µ3)
(loc, ir, l1, l2, h1, h2 + 1, h3 + 1, µ1, µ2 + 1, µ3 + 1)
(loc, f123, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, 0, h1 + action, h2 + 1, h3 + 1, µ1, µ2, µ2)
(2, r, l1 − action, l2, 0, 1, 1, 0, 1, 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f13, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, l2, 0, 1, 1, 0, 0, 0)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3, µ3)
(2, r, l1 − action, l2, 0, 1, 1, 0, 1, 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f12, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, l1, h1 + action, h2 + 1, h3 + 1, µ1, µ2, µ2)
(2, r, l1 − action, l2, 0, 1, 1, 0, 1, 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))

(1, h2 − µ2, µ2)
(1, h3 − µ3, µ3)
(0, h2 + 1 − µ2, µ2)
(0, h2 − µ2, µ2 + 1)
(0, h3 − µ3, µ3 + 1)
(1, h2 − µ2, µ2)
(1 + h3 − µ3, 0, µ3)
(0, h2 + 1 − µ2, µ2)
(0, h2 − µ2, µ2 + 1)
(h3 − µ3, 0, µ3 + 1)

(0, h2 − µ2, µ2)

(h3 − µ3, 0, µ3)

(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)

(0, 0, 0)

(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)

(0, 0, 0)

(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 + action − µ1, 0, µ1)
(0, 0, 0)
(h1 + action − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 + action − µ1, 0, µ1)
(0, 0, 0)

(h1 + action − µ1, 0, µ1)

21

TABLE IV
A DESCRIPTION OF THE TRANSITION AND REWARD MATRICES P AND R IN THE DECISION PROBLEM MP O .

adopt

h1 + action < h3

h1 + action = h3

loc! = 2

loc = 2

r, action > 0

f13, action = 0

h3 < h1 + action < l2 + h2 − 1

h1 + action = l2 + h2 − 1

l2 + h2 − h3 > 2

loc! = 2

loc = 2

r, action > 0

f13, action = 0

h1 + action = l2 + h2

h1 + action > l2 + h2

adopt

h1 + action < h3

h1 + action = h3

h1 + action = l2 + h2 − 1

h1 + action = l2 + h2

h1 + action > l2 + h2

l2 + h2 − h3 = 2

adopt

loc = 2, loc = 3

l2 + h2 − h3 = 1

h1 + action < h3

h1 + action = l2 + h2

h1 + action > l2 + h2

(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
1 − p
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhpγ1
αhp(1 − γ1)
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
1 − p
α1p
α2p
αhpβ1
αhpβ2
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhpβ2
αhpβ1
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhpβ2
αhpβ1
(1 − p)
α1p
α2p
αhp

(1, ir, 0, l2, h3, h2, h3, µ3, µ2, µ3)
(1, ir, 1, l2, h3, h2, h3, µ3, µ2, µ3)
(1, ir, 0, l2 + 1, h3, h2, h3, µ3, µ2, µ3)
(1, r, 0, l2, h3, h2, h3 + 1, µ3, µ2, µ3 + 1)
(1, ir, 0, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 1, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 0, l2 + 1, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, r, 0, l2, h3 − h2, 0, h3 − h2 + 1, h3 − h2, 0, h3 − h2 + 1)
(loc, ir, l1 − action, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action, l2 + 1, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, r, l1 − action, l2, h1 + action, h2, h3 + 1, µ1, µ2, µ3 + 1)
(loc, f13, l1 − action, l2, h3, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action + 1, l2, h3, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action, l2 + 1, h3, h2, h3, µ1, µ2, µ3)
(1, r, l1 − action, l2, h3, h2, h3 + 1, µ1, µ2, µ1 + 1)
(1, r, l1 − action, l2, h3, h2, h3 + 1, µ1, µ2, µ3 + 1)
(1, ir, l1 − action, l2, h1 + action, h2, h1 + action, µ1, µ2, µ1)
(1, ir, l1 − action + 1, l2, h1 + action, h2, h1 + action, µ1, µ2, µ1)
(1, ir, l1 − action, l2 + 1, h1 + action, h2, h1 + action, µ1, µ2, µ1)
(1, r, l1 − action, l2, h1 + action, h2, h1 + action + 1, µ1, µ2, µ1 + 1)
(2, ir, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 + 1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 1, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(loc, f12, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(loc, f12, l1 − action + 1, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(1, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, 0, 0, 1, 1, 0, 1, 1)
(3, ir, l1 − action, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))
(1, ir, 0, l2, h3, h2, h3, µ3, µ2, µ3)
(1, ir, 1, l2, h3, h2, h3, µ3, µ2, µ3)
(1, ir, 0, l2 + 1, h3, h2, h3, µ3, µ2, µ3)
(2, r, 0, 0, h3, h2 + l2, h2 + l2, µ3, µ2, µ2)
(1, ir, 0, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 1, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 0, l2 + 1, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(2, r, 0, 0, h3 − h2, l2, l2, h3 − h2, 0, 0)
(loc, ir, l1 − action, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action, l2 + 1, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(loc, f13, l1 − action, l2, h3, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action + 1, l2, h3, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action, l2 + 1, h3, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, ir, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 + 1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 1, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(loc, f12, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(loc, f12, l1 − action + 1, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(1, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, 0, 0, 1, 1, 0, 1, 1)
(3, ir, l1 − action, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))
(1, ir, 0, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 1, l2, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(1, ir, 0, l2 + 1, h3 − h2, 0, h3 − h2, h3 − h2, 0, h3 − h2)
(loc, f23, 0, 0, h3 − h2, h3 − h2 + 1, h3 − h2 + 1, 0, 0, 1)
(loc, ir, l1 − action, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 − action, l2 + 1, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, f23, l1 − action, 0, h1 + action, h3 + 1, h3 + 1, µ1, µ2, µ3 + 1)
(loc, f12, l1 − action, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(loc, f12, l1 − action + 1, 0, h1 + action, h2 + l2, h2 + l2, µ1, µ2, µ3)
(1, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2, µ2)
(2, r, l1 − action, 0, h1 + action, h2 + l2 + 1, h2 + l2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, 0, 0, 1, 1, 0, 1, 1)
(3, ir, l1 − action, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))

(0, 0, 0)

(0, h2 − µ2, µ2)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(h1 + action − µ1, 0, µ1)

(h1 + action − µ1, 0, µ1)

(0, 0, 0)

(0, h2 − µ2, µ2)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(0, 0, 0)

(h1 + action − µ1, 0, µ1)

(h1 + action − µ1, 0, µ1)

(0, h2 − µ2, µ2)

(0, 0, 0)

(0, 0, 0)

(h1 + action − µ1, 0, µ1)

(h1 + action − µ1, 0, µ1)

22

f23, f123, loc = 2

adopt

f23, f123, loc! = 2

(r, ir, loc = 2), f12

(r, ir, loc! = 2), f13

f12

f13

f23

f123

r, ir

f23

r, h2 = µ2

r, h2! = µ2

l2 + h2 = h3

action = 0

action = h3 − h1 > 0

h1 + action > l2 + h2

(1 − p)
α1pγ2
α1p(1 − γ2)
α2p
αhpγ2
αhp(1 − γ2)
(1 − p)
α1pγ2
α1p(1 − γ2)
α2p
αhpγ2
αhp(1 − γ2)
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhpβ1
αhpβ2
(1 − p)
α1p
α2pγ1
α2p(1 − γ1)
αhpγ1
αhp(1 − γ1)
(1 − p)
α1p
α2p
αhpγ2
αhp(1 − γ2)
(1 − p)
α1p
α2p
αhpθ1
αhpθ2
αhp(1 − θ1 − θ2)
(1 − p)
α1p
α2p
αhp
(1 − p)
α1p
α2p
αhpθ1
αhpθ2
αhp(1 − θ1 − θ2)
(1 − p)
α1p
α2pγ1
α2p(1 − γ1)
αhpγ1
αhp(1 − γ1)
(1 − p)
α1p
α2p
αhpβ1
αhpβ2
(1 − p)
α1p
α2p
αhp

(loc, f23, 0, l2, 0, µ3 − µ2, µ3 − µ2, 0, µ3 − µ2, µ3 − µ2)
(1, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, r, 0, 0, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 0, 0, 0, 0, 0)
(loc, f23, 0, l2, 0, h2, h3, µ1, µ2, µ3)
(1, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(2, r, 0, 0, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 1, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 1, 1, 0, 1, 1)
(3, ir, 0, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, 0, 1, 0, 0, 0, 0, 0, 0)
(3, r, 0, 0, 0, 1, 1, 0, 1, 1)
(loc, f ork, l1, l2, h1, h2, h3, µ1, µ2, µ3)
(loc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(1, r, l1, l2, h1, h2 + 1, h2 + 1, µ1, µ2, µ2)
(2, r, l1, l2, 0, 1, 1, 0, 1, 1)
(1, r, l1, l2, h1, h2 + 1, h3 + 1, µ1, µ2 + 1, µ2 + 1)
(1oc, f ork, l1, l2, h1, h2, h3, µ1, µ2, µ3)
(1oc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(2, r, l1, l2, 0, 1, 1, 0, 0, 0)
(2, r, l1, l2, 0, h3 + 1, h3 + 1, µ1, µ3, µ3)
(2, r, l1, 0, 0, 1, 1, 0, 1, 1)
(2, r, l1, l2, h1, h3 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f ork, l1, l2, h1, h2, h3, µ1, µ2, µ3)
(loc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(1, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ2, µ2)
(2, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f ork, l1, l2, h1, h2, h3, µ1, µ2, µ3)
(loc, f ork, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(2, r, l1, 0, h1, h2 + 1, h2 + 1, µ1, µ2, µ2)
(2, r, l1, 0, 0, 1, 1, 0, 1, 1)
(2, r, l1, 0, h1, h3 + 1, h3 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1, 0, h1, h3 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, ir, l1, l2, h1, h2, h3, µ1, µ2, µ3)
(loc, ir, l1 + 1, l2, h1, h2, h3, µ1, µ2, µ3)
(loc, ir, l1, l2 + 1, h1, h2, h3, µ1, µ2, µ3)
(loc, ir, l1, l2, h1, h2 + 1, h3 + 1, µ1, µ2 + 1, µ3 + 1)
(loc, f123, l1 − action, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, f123, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, 0, h1 + action, h2 + 1, h3 + 1, µ1, µ2, µ2)
(2, r, l1 − action, l2, 0, 1, 1, 0, 1, 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ2 + 1, µ2 + 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f13, l1 − action, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, f13, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, l2, 0, 1, 1, 0, 0, 0)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3, µ3)
(2, r, l1 − action, l2, 0, 1, 1, 0, 1, 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(loc, f12, l1 − action, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(loc, f12, l1 − action + 1, l2, h1 + action, h2, h3, µ1, µ2, µ3)
(2, r, l1 − action, l1, h1 + action, h2 + 1, h3 + 1, µ1, µ2, µ2)
(2, r, l1 − action, l2, 0, 1, 1, 0, 1, 1)
(2, r, l1 − action, l2, h1 + action, h2 + 1, h3 + 1, µ1, µ3 + 1, µ3 + 1)
(3, ir, l1 − action, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action + 1, 0, 0, 0, 0, 0, 0, 0)
(3, ir, l1 − action, 1, 0, 0, 0, 0, 0, 0)
((3, r, l1 − action, 0, 0, 1, 1, 0, 1, 1))

(0, h3 − µ3, µ2)
(1, h2 − µ2, µ2)
(1, h3 − µ3, µ3)
(0, h2 + 1 − µ2, µ2)
(0, h2 − µ2, µ2 + 1)
(0, h3 − µ3, µ3 + 1)
(0, 0, 0)
(1, h2 − µ2, µ2)
(1 + h3 − µ3, 0, µ3)
(0, h2 + 1 − µ2, µ2)
(0, h2 − µ2, 1 + µ2)
(h3 − µ3, 0, µ3 + 1)

(0, h2 − µ2, µ2)

(h3 − µ3, 0, µ3)

(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)

(0, 0, 0)

(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)

(0, 0, 0)

(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 + action − µ1, 0, µ1)
(0, 0, 0)
(h1 + action − µ1, 0, µ1)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(0, 0, 0)
(h1 + action − µ1, 0, µ1)
(0, 0, 0)

(h1 + action − µ1, 0, µ1)

