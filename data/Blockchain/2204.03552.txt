2
2
0
2

r
p
A
7

]

B
D
.
s
c
[

1
v
2
5
5
3
0
.
4
0
2
2
:
v
i
X
r
a

On the Correctness of Speculative Consensus

Jelle Hellings
Department of Computing and Software
McMaster University
Hamilton, ON, Canada

Sajjad Rahnama
Exploratory Systems Lab
Department of Computer Science
University of California, Davis
Davis, CA, USA

Suyash Gupta
RISELab
Department of Electrical Engineering and
Computer Science
University of California, Berkeley
Berkeley, CA, USA

Mohammad Sadoghi
Exploratory Systems Lab
Department of Computer Science
University of California, Davis
Davis, CA, USA

ABSTRACT

The introduction of Bitcoin fueled the development of blockchain-
based resilient data management systems that are resilient against
failures, enable federated data management, and can support data
provenance. The key factor determining the performance of such
resilient data management systems is the consensus protocol used
by the system to replicate client transactions among all participants.
Unfortunately, existing high-throughput consensus protocols are
costly and impose significant latencies on transaction processing,
which rules out their usage in responsive high-performance data
management systems.

In this work, we improve on this situation by introducing the
Proof-of-Execution consensus protocol (PoE), a consensus protocol
designed for high-performance low-latency resilient data manage-
ment. PoE introduces speculative execution, which minimizes laten-
cies by starting execution before consensus is reached, and PoE
introduces proof-of-executions to guarantee successful execution to
clients. Furthermore, PoE introduces a single-round check-commit
protocol to reduce the overall communication costs of consensus.
Hence, we believe that PoE is a promising step towards flexible
general-purpose low-latency resilient data management systems.

1 INTRODUCTION

The introduction of the cryptocurrency Bitcoin [26] marked the
first wide-spread deployment of a permissionless blockchain. The
emergence of Bitcoin and other blockchains has fueled the devel-
opment of new resilient data management systems [3, 11, 17, 27, 28,
34]. These new systems are attractive for the database community,
as they can be used to provide data management systems that are re-
silient against failures, enable cooperative (federated) data manage-
ment with many independent parties, and can support data prove-
nance. Due to these qualities, interest in blockchains is widespread
and includes applications in health care, IoT, finance, agriculture,
and the governance of supply chains for fraud-prone commodities
(e.g., such as hardwood and fish) [14, 20, 21, 24, 30, 35, 38].

At their core, blockchain systems are distributed systems in
which each participating replica maintains a copy of a ledger that
stores an append-only list of all transactions requested by users

An extended abstract of this work appeared at the 24th International Conference on
Extending Database Technology (EDBT 2021) [18].

and executed by the system [16]. This ledger is constructed and
stored in a tamper-proof manner: changes (e.g., appending new
transactions) are made via a consensus protocol, which will only
allow changes that are supported by the majority of all participants,
ruling out malicious changes (e.g., overwriting existing operations)
by a minority of faulty participants [16, 33]. These consensus proto-
cols can be seen as generalizations of the well-known two-phase
commit [15] and three-phase commit [32] protocols (as uses in tra-
ditional replicated databases) toward dealing gracefully with replica
failures and even malicious behavior. As the ledger is replicated over
and maintained by all participating replicas, it is highly resilient
and will survive even if individual participants fail.

The key factor determining the performance of blockchain-based
systems is the choice of consensus protocol [7, 16, 19]: the consensus
protocol determines the throughput of the system, as the consensus
protocol determines the speed by which transactions are replicated
and appended to the ledger of each replica, and the latency clients
observe on their requested transactions, as the operations necessary
to reach consensus on these transactions determine the minimum
time it takes for individual replicas to execute the requested trans-
actions and inform clients of the result.

Unfortunately, existing consensus protocols typically focus on
either providing high throughput or low latency, thereby failing
to provide the combination of high throughputs and low laten-
cies required for responsive high-performance data management
systems. First, we observe that the Proof-of-Work style consen-
sus protocols of permissionless blockchains such as Bitcoin and
Ethereum suffer from high costs, very low throughputs, and very
high latencies, making such permissionless designs impractical
for high-performance data management [9, 29, 37]. Permissioned
blockchains, e.g., those based on Pbft-style consensus, are more
suitable for high-performance data management: fine-tuned per-
missioned systems can easily process up-to-hundreds-of-thousands
transactions per second, this even in wide-area (Internet) deploy-
ments [7, 16, 17, 19]. Still, even the best permissioned consensus
protocols cannot provide the low latencies we are looking for, as
all reliable consensus protocols require three-or-more subsequent
rounds of internal communication before requests can be executed
and clients can be informed.

 
 
 
 
 
 
To further unlock the development of new resilient data man-
agement systems, we designed the Proof-of-Execution consensus
protocol (PoE), a novel consensus protocol that is able to provide
high throughputs, while minimizing client latencies. At the core of
PoE are two innovative techniques:

(1) PoE introduces speculative execution: PoE executes transac-
tions requested by clients and informs clients of the result
before consensus is reached on these transactions, while pro-
viding the clients a proof-of-execution that guarantees that
speculatively-executed transactions will eventually reach
consensus; and

(2) PoE introduces the check-commit protocol, a decentralized
single-round protocol that, under normal conditions, can
commit consensus decisions for which a proof-of-execution
exists and can replicate such decisions among all replicas
without relying on specific replicas and without requiring
several rounds of communication.

By combining these innovative techniques, PoE only imposes
two rounds of communication on a consensus step before execution
can commence and the client can be informed, while only requiring
three rounds of communication to complete a consensus step in
the normal case. Furthermore, the design of PoE is flexible and
allows for optimizations that further balance communication costs,
transaction latency, and recovery complexity. E.g., via the usage of
digests to reduce communication costs (at the cost of more-complex
recovery paths), via the usage of threshold signatures to further
reduce communication costs (at the cost of higher latencies), via the
usage of message authentication codes to reduce computation costs
(at the cost of more-complex recovery paths), and via the usage of
out-of-order processing to significantly improve throughput (at the
cost of higher resource usage).

In this paper, we not only introduce the design of PoE, but also
provide rigorous proofs of the correctness of all parts of the protocol.
Furthermore, we provide an in-depth analytical and experimental
evaluation of PoE in comparison with other contemporary per-
missioned consensus protocols. In specific, we make the following
contributions:

(1) In Section 3 we introduce the concept of speculative execu-
tion and formalize its usage in a client-oriented system that
processes transactions via consensus.

(2) In Section 4, we provide an in-depth description of all parts

of PoE. In specific:

(a) Section 4.1 describes the normal-case operations that are
optimized for high-performance low-latency transaction
processing utilizing speculative execution and proof-of-
execution;

(b) Section 4.2 describes the situations in which the normal-
case of PoE can fail and the impact this has on the state
of individual replicas;

(c) Section 4.3 introduces the novel single-round check-commit
protocol that allows PoE replicas to recover from minor
failures without interrupting the normal-case operations;
(d) Section 4.4 introduces the view-change protocol that al-
lows PoE replicas to recover from major failures (including
network failures) without invalidating any transactions
that have received a proof-of-execution;

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

(e) Section 4.5 proves the correctness of all parts of PoE,
showing that PoE provides consensus and maintains all
speculatively-executed transactions that have received a
proof-of-execution. Due to the level of detail (which in-
cludes all modes of operations), this proof of correctness is
a major contribution in itself and can be used as a stepping
stone in the analysis of other primary-backup consensus
protocols; and

(f) Section 4.6 proves that PoE provides services to clients.
In the normal case, PoE does so by providing the client
with a proof-of-execution, which can be provided with low
latency. In the case of failures, PoE can always fall back
to a proof-of-commit, which takes an additional round of
communication to establish.

(3) In Section 5, we take an in-depth look at the complexity of
PoE, we introduce PoE variants that use digests, threshold
signatures, or message authentication codes to reduce com-
plexity, and we show that PoE and all its variants can utilize
out-of-order processing to maximize performance.

(4) In Section 5.4 we introduce Linear-PoE, a variant of PoE that
uses threshold signatures to make the normal-case and the
check-commit protocol fully linear. Central in this variant is
a novel Linear Check-Commit protocol that utilizes aggrega-
tor rotation, aggregated (multi-round) check-commits, and
recovery certificates to ensure a single-round decentralized
design with only linear communication costs.

(5) Finally, in Section 6, we perform an in-depth analytical eval-
uation of PoE in comparison with other frequently-used
consensus protocols.

Furthermore, Section 2 introduces the notation used throughout
this paper and Section 7 concludes on our findings.

A summary of the comparison between PoE and other high-
performance consensus protocols can be found in Figure 1. As one
can see, PoE outperforms other high-performance consensus proto-
cols, as PoE combines the lowest latencies with low communication
costs. Furthermore, PoE provides high resilience, as it can operate in
fully asynchronous environments without any further assumptions
on replicas or clients.

An extended abstract of this work appeared at the 24th Inter-
national Conference on Extending Database Technology (EDBT
2021) [18]. In comparison with that extended abstract, we have
added a full presentation of the operations of PoE, introduced the
novel single-round check-commit protocol to further improve the
performance of PoE, included complete proofs of the correctness
of PoE, introduced a new single-round linear check-commit pro-
tocol for use in Linear-PoE, and included an in-depth analytical
evaluation of PoE in comparison with contemporary consensus
protocols.

2 PRELIMINARIES

System Model. We model a system as a tuple (ℜ, ℭ), in which ℜ
is a set of replicas and ℭ is a set of clients. We assign each replica
r ∈ ℜ a unique identifier id(r) with 0 ≤ id(r) < |ℜ|. We write
F ⊆ ℜ to denote the set of Byzantine replicas that can behave in
arbitrary, possibly coordinated and malicious, ways.

On the Correctness of Speculative Consensus

Communication Rounds

Message Complexity

a

Protocol

Before Execution

Total

Total

Per Replica (max)

b
Environment

Remarks

PoE

Linear-PoE

Pbft

Zyzzyva

c

d

Sbft

HotStuff

e

MinBFT

2

3

3

1

4

7

2

nC + 2n2

nC + 4n

nC + n

nC + n

nC + 3n2

nC + 2n

3

5

4

1

nC

5 + 1cp

nC + 4n + n2

cp

8

2

nC + 3n

nC + n2

nC

nC + 3

nC + 3

nC + n

Asynchronous (recovery)
Partial Synchrony (progress)
Asynchronous (recovery)
Partial Synchrony (progress)

Asynchronous (recovery)
Partial Synchrony (progress)

Asynchronous (recovery)
Partial Synchrony (progress)
Asynchronous (recovery)
Partial Synchrony (progress)
Partial synchrony
(progress and recovery)
Reliable communication
(progress and recovery)

Speculative execution.

Speculative execution.

Requires reliable clients;
Has vulnerabilities [1, 2]

No out-of-order processing.

Requires trusted hardware;
can tolerate more faulty replicas.

a

c

For readability, we used a simplified notation for the message complexity by omitting off-by-one terms. E.g., PoE requires a total of (n − 1)C + 2n(n − 1) messages.
b
The environment specifies in which environment the protocol can operate. This does not mean that the protocol will be able to make progress (new consensus decisions are made),
however. Indeed, all these protocols require sufficiently reliable communication to guarantee progress. Only the protocols labeled with asynchronous (recovery) can recover from any
number of periods in which communication is not sufficiently reliable.
This entry only reflects the optimistic fast path of Zyzzyva, which cannot deal with any replica failures. The complexity of the slow path of Zyzzyva is akin that of Pbft.
This entry only reflects the optimistic fast path of Sbft, which cannot deal with any replica failures when replicas are either non-faulty or malicious. Furthermore, Sbft utilizes a
checkpoint protocol akin to the one used by Pbft. As no explicit description of this checkpoint protocol is provided in the original Sbft paper, we have used the cost of the Pbft
checkpoint protocol (complexity-terms related to the checkpoint protocol are subscripted with cp).
In the standard configuration of HotStuff, phases of up-to-four consensus decisions are overlapped. Even with this overlapping, each consensus decision has to go through four
all-to-one-to-all communication phases. The costs in this table reflect the communication necessary to complete these four phases.

d

e

Figure 1: A cost comparison of the normal-case operations of PoE and other consensus protocols when reaching reaching
consensus among n replicas on a client request with a size bounded by C. We refer to Section 6 for an in-depth analysis and
breakdown of the details in this table.

We assume that non-faulty replicas behave in accordance to the
protocols they are executing. We do not make any assumptions on
clients: all clients can be malicious without affecting PoE. We write
n = |ℜ|, f = |F |, and nf = n − f to denote the number of replicas,
faulty replicas, and non-faulty replicas, respectively.

Communication. We assume authenticated communication: Byzan-
tine replicas are able to impersonate each other, but replicas cannot
impersonate non-faulty replicas. Authenticated communication is
a minimal requirement to deal with Byzantine behavior. To en-
force authenticated communication and simplify presentation, we
assume that all messages are digitally signed (e.g., via public-key
cryptography) [22]: every replica and every client 𝑧 ∈ (ℜ ∪ ℭ) can
sign arbitrary messages 𝑚, resulting in a certificate ⟨𝑚⟩𝑧. These
certificates are non-forgeable and can be constructed only if 𝑧 co-
operates in constructing them. Based on only the certificate ⟨𝑚⟩𝑧,
anyone can verify that 𝑚 was originally supported by 𝑧. We refer to
Section 5.5 for a discussion on how to eliminate digital signatures
from all messages used between replicas in a system.

Consensus. A consensus protocol [16, 33] coordinates decision
making among the replicas ℜ of a system by providing a reliable or-
dered replication of decisions. To do so, consensus protocols provide
the following guarantees:

Termination if non-faulty replica r ∈ ℜ makes a 𝜌-th deci-
sion, then all non-faulty replicas q ∈ ℜ will make a 𝜌-th
decision;

Non-Divergence if non-faulty replicas r1, r2 ∈ ℜ make 𝜌-th
decisions 𝐷1 and 𝐷2, respectively, then 𝐷1 = 𝐷2 (they make
the same 𝜌-th decisions); and

Non-Triviality whenever a non-faulty replica r ∈ ℜ learns
that a decision 𝐷 needs to be made, then replica r can force
consensus on 𝐷.

In this work, we assume that each decision represents one or
more client transactions. Hence, in practice, the non-triviality guar-
antee simply specifies that replicas can force processing of new
client requests whenever clients are requesting execution of trans-
actions.

Consensus cannot be solved in environments in which commu-
nication is asynchronous (e.g., when messages can get lost or be
arbitrarily delayed) [12]. Even though practical networks are re-
liable most of the time, they also have periods of failure during
which they behave asynchronous. One way to deal with this is by
providing weak consensus: weak consensus always guarantees non-
divergence, while only guaranteeing termination and non-triviality
in periods of reliable communication (during which messages are
delivered within some unknown bounded delay) [7]. We assume
n > 3f (nf = n − f > 2f), a minimal requirement to provide
consensus in an asynchronous environment [6, 10, 16].

3 FROM CONSENSUS TO CLIENT SERVICES

In the previous section, we defined consensus. The definition of
consensus does not specify how one builds an effective service that
clients can use for the execution of their transactions, however.
Next, we take a look at how consensus-base systems can provide
such client services.

Traditional Execution. First, we consider traditional consensus-
based systems that provide client services. Consider a client 𝛾 re-
questing the execution of some transaction 𝜏. In traditional systems,
replicas will execute 𝜏 as the 𝜌-th transaction and inform 𝛾 of the
outcome after they decided upon 𝜏 (using consensus) as the 𝜌-th
decision and after executing all transactions decided upon by pre-
ceding decisions.

Example 3.1. Consider a deployment of the Pbft consensus pro-
tocol [7, 16]. Under normal conditions, Pbft operates via a primary-
backup design in which a designated replica (the primary) is re-
sponsible for proposing client transactions to all other replicas (the
backups). The primary does so via a PrePrepare message. Next,
all replicas exchange their local state to determine whether the pri-
mary properly proposed a decision. To do so, all replicas participate
in two phases of all-to-all communication.

In the first phase, all (non-faulty) replicas that receive a proposal
via PrePrepare message 𝑚 broadcast a message Prepare(𝑚). Then
each replica r waits until it receives Prepare messages identical
to Prepare(𝑚) from at-least nf distinct replicas. After receiving
these nf messages, the proposal 𝑚 is prepared.

Notice that at-least nf − f = n − 2f Prepare messages received
by r are sent by non-faulty replicas. Hence, there are at-most f
non-faulty replicas that did not participate in preparing 𝑚. As such,
for any other PrePrepare message 𝑚, replicas will only be able to
collect up-to 2f < nf Prepare messages, guaranteeing that only
the message 𝑚 will be prepared at non-faulty replicas.

In the second phase, all (non-faulty) replicas that prepared 𝑚
broadcast a message Commit(𝑚). Then each replica r waits until it
receives Commit messages identical to Commit(𝑚) from at-least nf
distinct replicas. After receiving these nf messages, the proposal
𝑚 is committed, after which r decides 𝑚 (and, hence, executes the
client transaction proposed by 𝑚).

In Pbft, a replica r commits 𝑚 when it has a guarantee that
𝑚 can always be recovered from the state of at-most nf replicas
(e.g., all non-faulty replicas). To see this, consider the at-least nf
Commit messages received by r due to which r commits 𝑚. Of these
messages, at-least nf − f = n − 2f are sent by non-faulty replicas.
Now consider any replica q trying to recover based on the state
of any set 𝐶 of at-least nf replicas. At-least nf − f = n − 2f of the
replicas in 𝐶 are non-faulty replicas. Let 𝑇 = 𝑆 −F be the non-faulty
replicas in 𝑆 and let 𝐷 = 𝐶 − F be the non-faulty replicas in 𝐶. We
have |𝑇 | > n − 2f and |𝐷 | > n − 2f. As we assumed n > 3f, we
must have (𝑇 ∩ 𝐷) ≠ ∅ (as otherwise, |𝑇 | + |𝐷 | ≥ 2(n − 2f) and
|𝑇 | + |𝐷 | ≤ nf = n − f must hold, which would imply n ≤ 3f). As
such, q will be able to recover 𝑚 from the state of any replica in
𝑇 ∩ 𝐷. Hence, after a non-faulty replica commits 𝑚, there is the
guarantee that 𝑚 can be recovered from the transactions prepared
by any set of nf replicas.

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

p
r1
r2
r3

PrePrepare

Prepare

Commit

Decide 𝜏
Execute 𝜏

Figure 2: A schematic representation of the normal-case of
Pbft: the primary p proposes transaction 𝜏 to all replicas via
a PrePrepare message. Next, replicas commit to 𝜏 via a two-
phase all-to-all message exchange. In this example, replica
r3 is faulty and does not participate.

We have sketched this working of Pbft in Figure 2. Besides
the normal-case operations of Pbft outlined above, Pbft also has
two recovery mechanisms to recover from primary failures and
network failures, namely a checkpoint protocol and a view-change
protocol. Crucially, these recovery mechanisms assure that all trans-
actions that are ever decided (committed) by a non-faulty replica
will eventually be recovered and committed by all non-faulty repli-
cas whenever communication becomes sufficiently reliable.

We assume that execution of 𝜏 is deterministic: executing 𝜏 at
any non-faulty replica yields identical outputs when executed upon
identical inputs. Using this deterministic nature, the consensus-
coordinated replication and execution of transactions will imple-
ment a fully-replicated system in which all non-faulty replicas will
manage a copy of the same data. Under these assumptions, it is
straightforward to deliver client services:

(1) To assure that client transactions get executed, a client sim-
ply needs to send their transaction 𝜏 to any non-faulty replica
(whom can then use the non-triviality property of consensus
to force a decision on 𝜏).

(2) To observe the result of execution of a transaction 𝜏, the
client simply awaits until it receives a single response by any
non-faulty replica. As non-faulty replicas execute after they
decided on 𝜏, non-divergence and termination guarantee
that all non-faulty replicas will eventually do the same.

When using traditional execution, a client can effectively detect
whether it received a single response by any non-faulty replica
after it received identical responses from at-least f + 1 distinct
replicas, as at-most f of those responses can originate from faulty
replicas. Using the assumption that execution is deterministic and
that all n − f > f non-faulty replicas will eventually execute 𝜏,
all non-faulty replicas will eventually inform the client with the
same identical result. Hence, independent of the behavior of faulty
replicas, the client will receive at-least f + 1 identical responsed and
is able to reliably derive execution results.

Speculative Execution. Traditional execution assures that it is
easy to reason about the operations of a system, both for its replicas
(which have strong guarantees during execution) and for the clients
(whom can easily derive execution results). This ease-of-use comes
at a significant cost: by only executing transactions until replicas
are able to make consensus decisions, we significantly delay the
latencies clients will observe on their requests, even when the
system is operating entirely correctly.

On the Correctness of Speculative Consensus

Example 3.2. Consider again the operations of Pbft with tradi-
tional execution, as outlined in Example 3.1. Let 𝜏 be a transaction
requested by some client and let 𝛿 be the message delay. At 𝑡, the
primary receives 𝜏 and is able to propose 𝜏. Assuming that the band-
width and processing time required to send, receive, and process
a message is negligible, these PrePrepare proposals will arrive
after 𝑡 + 𝛿 at all other replicas, whom then all broadcast Prepare
messages. All these Prepare messages will arrive after 𝑡 + 2𝛿. Only
then are all replicas able to broadcast Commit messages, which will
arrive after 𝑡 + 3𝛿. Hence, execution will only happen 3𝛿 after the
initial proposal, and only after execution will the client be notified
of any outcome.

Modern variants of Pbft such as Sbft [13] and HotStuff [40]
use threshold signatures to replace some phases of all-to-all com-
munication with a quadratic message complexity (e.g., the prepare-
phase and the commit-phase), to subphases of all-to-one and one-
to-all communication with a linear message complexity each. Such
implementations typically trade computational complexity and
latency for lower communication costs, and will result in Pbft
variants with much higher client latencies. E.g., execution in Sbft
happens after 4𝛿 and execution in HotStuff happens after 7𝛿.

The many phases before execution in these consensus protocols
is especially noticeable in practical deployments of consensus: to
maximize resilience against disruptions at any location, individual
replicas need to be spread out over a wide-area network. Due to this
spread-out nature, the message delay will be high and a message
delay of 15 ms ≤ 𝛿 ≤ 200 ms is not uncommon [8, 17].

As an alternative to traditional execution, we propose speculative
execution: replicas will execute 𝜏 as the 𝜌-th transaction and inform
𝛾 of the outcome before they decided upon 𝜏 as the 𝜌-th decision
(but still after executing all preceding transactions). As replicas
execute transactions before a final consensus decision is made, this
introduces two challenges:

(1) A non-faulty replica r can execute 𝜏 as the 𝜌-th transaction
only to later make an 𝜌-th decision for another transaction
𝜏 ′. In this case, r needs a way to rollback the execution of 𝜏
and replace it with an execution of 𝜏 ′.

(2) As non-faulty replicas can rollback their execution, clients
can no longer observe the result of execution of a transaction
𝜏 via a single response of any non-faulty replica (or f + 1
identical responses).

Even with these challenges, speculative execution is worthwhile:
when the system operates correctly, speculative execution can
greatly reduce the latency clients perceive upon their requests,
especially in systems utilizing threshold signatures. In the next sec-
tion, we introduce the Proof-of-Execution consensus protocol (PoE)
that utilizes speculative execution and shows methods to overcome
both these challenges.

4 CONSENSUS VIA PROOF-OF-EXECUTION
The Proof-of-Execution consensus protocol (PoE) shares the primary-
backup design of Pbft and utilizes speculative execution to mini-
mize client latencies in the normal case (when the primary is non-
faulty and communication is reliable). To simplify presentation, we
will present a non-optimized version of PoE, after which we take
an in-depth look at optimizing the complexity of PoE in Section 5.

Our presentation of PoE is broken-up in six parts. First, in Sec-
tion 4.1, we describe the normal-case protocol that is used by the
primary to propose consensus decision. Next, in Section 4.2, we
look at how replica and network failures can disrupt the normal-
case protocol. Third, in Section 4.3, we describe the check-commit
protocol to deal with failures that do not disrupt the normal-case.
Then, in Section 4.4, we describe the view-change protocol to deal
with failures that disrupt the normal-case. After presenting these
three protocols in full detail, we will prove in Section 4.5 that PoE
provides weak consensus and we will prove in Section 4.6 that PoE
provides reliable service to clients.

4.1 The Normal-Case Protocol
PoE operates in views and in view 𝑣 the replica p with id(p) =
𝑣 mod n is the primary that coordinates the normal-case protocol.
Consider a client 𝛾 that wants to request transaction 𝜏. For now,
we assume that 𝛾 knows that p is the current primary, we refer to
Section 4.6 for the case in which the primary is unknown to 𝛾. To
prevent any party to forge requests by client 𝛾, the client 𝛾 signs
any transactions it wants to request before sending them to the
current primary. Hence, to request 𝜏, the client will send ⟨𝜏⟩𝛾 to
primary p.

After primary p receives ⟨𝜏⟩𝛾 , a transaction 𝜏 requested and
signed by client 𝛾, it can propose 𝜏. To propose 𝜏 as the 𝜌-th trans-
action, the primary broadcasts a message Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) to all
other replicas.

Next, all replicas exchange their local state to determine whether
the primary properly proposed a decision. In PoE, the replicas do
so in one phase of all-to-all communication. Upon arrival of the
first proposal for round 𝜌 of view 𝑣 via some Propose message
𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), each (non-faulty) replica r that received
𝑚 will enter the prepare phase for 𝑚. As the first step of the prepare
phase, r broadcasts a message Prepare(𝑚). Next, r waits until it
receives Prepare messages identical to Propose(𝑚) from at-least
nf distinct replicas. After receiving these nf messages, the proposal
𝑚 is prepared. As a proof of this prepared state for 𝑚, r stores a
prepared certificate P(𝑚) consisting of these nf Prepare messages.
When replica r prepared proposal 𝑚, it schedules 𝜏 for specu-
lative execution. Whenever all preceding transactions are already
executed, 𝜏 will be executed by r yielding some result 𝑟 . Next, r
will inform the client 𝛾 via an Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ) of the outcome.
Finally, client 𝛾 waits for a proof-of-execution for ⟨𝜏⟩𝛾 consisting
of identical Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ) messages from nf distinct replicas.
When 𝛾 receives this proof-of-execution, it considers 𝜏 executed.
As we shall prove later on, the existence of this (𝑣, 𝜌)-proof-of-
execution for ⟨𝜏⟩𝛾 guarantees that the speculative execution of 𝜏
will be preserved by all replicas (and will never rollback).

The pseudo-code for this normal-case protocol can be found in
Figure 3 and an illustration of the working of this protocol can be
found in Figure 4.

The correctness of PoE is based on the following properties of

the normal-case protocol:

Theorem 4.1. Round 𝜌 of view 𝑣 of the normal-case protocol of

PoE satisfies the following two properties.

(1) If non-faulty replicas r𝑖 , 𝑖 ∈ {1, 2}, prepared proposals 𝑚𝑖 =

PrePrepare(⟨𝜏𝑖 ⟩𝛾𝑖 , 𝑣, 𝜌), then 𝑚1 = 𝑚2.

Client role (used by client 𝛾 to request transaction 𝜏) :

1: Send ⟨𝜏 ⟩𝛾 to the primary p.
2: Await a (𝑣, 𝜌)-proof-of-execution for ⟨𝜏 ⟩𝛾 consisting of identical mes-

sages Inform( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌, 𝑟 ) from nf distinct replicas.

3: Considers 𝜏 executed, with result 𝑟 , as the 𝜌-th transaction.

Primary role (running at the primary p of view 𝑣) :
4: Let view 𝑣 start after execution of the 𝜌-th transaction.
5: while p is the primary do
6:

Await receipt of well-formed client requests ⟨𝜏 ⟩𝛾 .
Broadcast Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌) to all replicas.
𝜌 := 𝜌 + 1.

7:

8:
9: end while

Backup role (running at every replica r ∈ ℜ) :

10: event r receives message 𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌) such that:

(1) 𝑣 is the current view;
(2) 𝑚 is signed by the primary of view 𝑣;
(3) r did not prepare a 𝜌-th proposal in view 𝑣; and
(4) ⟨𝜏 ⟩𝛾 is a well-formed client request

do

11:

Prepare 𝑚 as the proposal for round 𝜌 in view 𝑣.
Broadcast Prepare(𝑚) to all replicas.

12:
13: end event
14: event r receives nf messages 𝑚𝑖 = Prepare(𝑚) such that:

(1) 𝑣 is the current view;
(2) 𝑚 is a well-formed proposal Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌);
(3) each message 𝑚𝑖 is signed by a distinct replica; and
(4) r started the prepare phase for 𝑚

do

15: Wait until execution of all rounds preceding 𝜌.
16:

Store prepared certificate P(𝑚) = {𝑚𝑖 | 1 ≤ 𝑖 ≤ nf }.
Execute 𝜏 as the 𝜌-th transaction, yielding result 𝑟 .
Send Inform( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌, 𝑟 ) to 𝛾 .

17:

18:
19: end event

Figure 3: The normal-case protocol in PoE.

p
r1
r2
r3

Propose

Prepare

Execute 𝜏 (Speculative)

Figure 4: A schematic representation of the normal-case pro-
tocol of PoE: the primary p proposes transaction 𝜏 to all repli-
cas via a Propose message. Next, replicas prepare 𝜏 via a one-
phase all-to-all message exchange. Notice that replicas do
not explicitly decide on 𝜏 in the normal case, but do execute
𝜏. In this example, replica r3 is faulty and does not partici-
pate.

(2) If a non-faulty primary p proposes 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌),
communication is reliable, transaction execution is determin-
istic, and all non-faulty replicas executed the same sequence

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

of 𝜌 − 1 transactions, then 𝛾 will receive a (𝑣, 𝜌)-proof-of-
execution for ⟨𝜏⟩𝛾 .

Proof. We prove the two statements separately.
We prove the first statement by contradiction. Assume that non-
faulty replicas r1 and r2 prepared proposals 𝑚1 and 𝑚2 with
𝑚1 ≠ 𝑚2. As r𝑖 , 𝑖 ∈ {1, 2}, prepared proposal 𝑚𝑖 , it must have
received messages Prepare(𝑚𝑖 ) from nf distinct replicas (Line 14
of Figure 3). Let 𝑆𝑖 be the set of nf replicas from which r𝑖 received
these messages and let 𝑇𝑖 = 𝑆𝑖 \ F be the non-faulty replicas in 𝑆𝑖 .
By construction, we have |𝑇𝑖 | ≥ nf − f. As each non-faulty replica
only sends prepare messages for a single proposal in round 𝜌 of
view 𝑣 (Line 10 of Figure 3), 𝑚1 ≠ 𝑚2 implies that 𝑆1 ∩ 𝑆2 = ∅.
Hence, we must have |𝑆1 ∪ 𝑆2| = |𝑆1| + |𝑆2| ≥ 2(nf − f). As all
replicas in 𝑆1 ∪ 𝑆2 are non-faulty, we must also have |𝑆1 ∪ 𝑆2| ≤ nf.
Hence, we must have 2(nf − f) ≤ nf, which implies nf ≤ 2f. As
n = nf + f, this implies n ≤ 3f, a contradiction. Consequently, we
conclude that 𝑚1 = 𝑚2 must hold.

Next, we prove the second statement. A non-faulty primary p
will broadcast 𝑚 to all non-faulty replicas (Line 7 of Figure 3). As
communication is reliable, all nf non-faulty replicas will receive 𝑚
as the first proposal of round 𝜌 of view 𝑣 (Line 10 of Figure 3) and
broadcast a message Prepare(𝑚). As communication is reliable,
all nf non-faulty replicas will receive Prepare(𝑚) from these nf
non-faulty replicas (Line 14 of Figure 3) and execute 𝜏 (Line 17 of
Figure 3). As all non-faulty replicas executed the same sequence of
𝜌 −1 transactions before executing 𝜏, each non-faulty replica has the
same state before executing 𝜏. Consequently, due to deterministic
execution of 𝜏, all non-faulty replicas will obtain the same result
𝑟 from execution of 𝜏 and send the same Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ) to 𝛾
□
(Line 18 of Figure 3).

PoE only requires two phases of communication before execution
commences, which is one less phase than Pbft. Consequently, the
processing time of transactions within PoE is sharply reduced from
at-least 3𝛿 to 2𝛿, which will also reduce the latency clients perceive.
Finally, the elimination of a phase of communication eliminates one
round of messages, reducing the bandwidth cost for the normal-
case of PoE (and, hence, allowing for an increase in throughput). As
shown in Theorem 4.1(2), the elimination of a phase in PoE does not
affect the service that is provided under normal conditions: clients
still have a strong guarantee of service whenever the primary is
non-faulty and communication is reliable.

The normal-case protocol of PoE provides only few guaran-
tees, however. If non-faulty replica r speculatively executes some
transaction 𝜏 proposed via 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), then, due to
Theorem 4.1(1), r only has the guarantee that no other transaction
𝜏 ′ is executed in round 𝜌 of 𝑣. In specific, r has no guarantees that
any other non-faulty replicas prepared 𝑚 or executed 𝜏 and has
no guarantees that 𝛾 received a (𝑣, 𝜌)-proof-of-execution for ⟨𝜏⟩𝛾 .
As we shall see in Section 4.2 and Section 4.4, a subsequent failure
of view 𝑣 can easily lead to a situation in which the proposal 𝑚 is
not preserved, due to which r needs to rollback 𝜏. As we shall show
in the remainder of Section 4, the design of PoE does provide the
strong guarantee that 𝑚 will always be guaranteed if a proof-of-
execution for 𝑚 could be received by client 𝛾. To provide this strong
guarantee (and to deal with certain kinds of failures), non-faulty

On the Correctness of Speculative Consensus

replicas rely on the check-commit protocol of Section 4.3 and the
view-change protocol of Section 4.4. Next, we look at the operations
of PoE during failures: we look at how PoE deals with faulty (and
possibly malicious) primaries and how PoE recovers from periods
of unreliable communication.

4.2 Failure of the Normal-Case Protocol

The normal-case protocol described in Section 4.1 is designed to effi-
ciently make consensus decisions and provide clients with proof-of-
executions when operating under normal conditions. If the normal
conditions are not met, then the normal-case protocol can fail in
several ways, each following directly from the conditions stipulated
in Theorem 4.1(2):

Example 4.2. Consider round 𝜌 of view 𝑣 in a deployment of PoE.
The normal-case protocol of PoE can be disrupted in round 𝜌 in
the following ways:

(1) Any non-primary faulty replica can behave malicious by not
participating or by sending invalid messages. Under normal
conditions, this will not disrupt the normal-case protocol,
however, as Theorem 4.1(2) does not depend on the behavior
of any faulty replicas (that are not the primary).

(2) A malicious primary can choose to send different proposals
for round 𝜌 of view 𝑣 to different non-faulty replicas or can
choose to send no proposals to some non-faulty replicas. Due
to Theorem 4.1(1), at-most one proposal will be prepared in
round 𝜌 of view 𝑣, this independent of the behavior of any
faulty replicas. Hence, this malicious behavior can have only
two outcomes:
(a) A proposal 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) will be prepared by
some non-faulty replicas. The non-faulty replicas that did
not receive 𝑚 are left in the dark, as they will not be able to
prepare in round 𝜌 of view 𝑣 and, consequently, are stuck.
In this case, the client can still receive a proof-of-execution:
if at-least nf − f non-faulty replicas prepared 𝑚, then the
f faulty replicas can choose to also execute 𝜏 and send
Inform messages to the client, this to assure the client
receives nf identical Inform messages.

(b) No proposal will be prepared by non-faulty replicas, in
which case the primary disrupts the progress of the normal-
case protocol and, consequently, prevents any transactions
from being executed.

(3) Due to unreliable communication, messages can get lost (or
arbitrarily delayed due to which receiving replicas consider
them lost). Consequently, unreliable communication can pre-
vent replicas from receiving proposals even from non-faulty
primaries. Furthermore, unreliable communication can pre-
vent replicas from receiving sufficient Prepare messages to
finish their prepare phases.

Using digital signatures, it is rather straightforward to detect
that a primary is sending conflicting proposals for a given round 𝜌
of view 𝑣, as non-faulty replicas forward these conflicting proposals
to each other during the prepare phase. Unfortunately, this does
not extend to other malicious behavior, as we shall show next.

Example 4.3. Consider a system with ℜ = {p, r1, r2, r3} such
that p is the current primary of some view 𝑣. We consider the
following three cases:

(1) The primary p is faulty and does not send any proposal
to r3. Hence, eventually r3 detects a primary failure. To
alert all other replicas of this failure, r3 broadcasts message
Failure(𝑣).

(2) The primary p is non-faulty and sends a proposal to r3. Un-
fortunately, r3 is faulty and pretends that the primary failed
to propose. Consequently, r3 broadcasts message Failure(𝑣).
(3) The primary p is non-faulty and sends a proposal to r3. Un-
fortunately, communication is unreliable and this proposal
is lost. This loss is interpreted by r3 as a failure of the pri-
mary to propose. To alert all other replicas of this failure, r3
broadcasts message Failure(𝑣).

We have sketched these three cases in Figure 5. As one can see, the
replicas r1 and r2 receive the exact same set of messages in all three
cases and, hence, observe identical behavior and cannot distinguish
between the three cases.

As Example 4.2 illustrates, any disruption of the normal-case
protocol of PoE is caused by a faulty primary or by unreliable com-
munication. If communication is unreliable, then there is no way to
guarantee continuous service [12]. Hence, replicas assume failure
of the current primary if the normal-case protocol is disrupted,
while the design of PoE guarantees that unreliable communication
does not affect the correctness of PoE and that the normal-case pro-
tocol of PoE will be able to recover when communication becomes
reliable.

As Example 4.2(2) illustrated, a faulty primary can cause two
kinds of disruptions. First, the primary can leave replicas in the dark
without disrupting the progress of the normal-case protocol (Exam-
ple 4.2(2a)) and we use the check-commit protocol of Section 4.3 to
deal with such behavior. Second, the behavior of the primary can
disrupt the progress of the normal-case protocol (Example 4.2(2b))
and we use the view-change protocol of Section 4.4 to deal with such
behavior.

4.3 The Check-Commit Protocol
The main purpose of the check-commit protocol is to commit pro-
posals 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), after which non-faulty replicas that
speculatively executed 𝜏 have the guarantee that 𝜏 will never roll-
back. Furthermore, we use the check-commit protocol to assure that
non-fauulty replicas cannot be left in the dark: the check-commit
protocol assures that all non-faulty replicas receive prepared cer-
tificates for 𝑚 if any replica can commit 𝑚.

For non-faulty replicas that successfully prepared via the normal-
case protocol of Section 4.1, the check-commit protocol operates
in a single phase of communication. Let 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌)
be some proposal. The non-faulty replica r uses the check-commit
protocol for 𝑚 to indicate its willingness to commit to 𝑚 and to
determine whether a sufficient number of other replicas are willing
to commit 𝑚. Replica r is willing to commit to 𝑚 if the following
conditions are met:

(1) r prepared 𝑚 and speculatively executed 𝜏 and, hence, stored

a prepared certificate for 𝑚 and informed the client;

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

p ∈ F
r1
r2
r3

Propose

Prepare

p
r1
r2
r3 ∈ F

Propose

Prepare

p
r1
r2
r3

Propose

Prepare

Figure 5: A schematic representation of three failures in the normal-case protocol of PoE. Left, a faulty primary p does not
propose to r3. Middle, a faulty replica r3 pretends that the primary p did not propose. Right, unreliable communication pre-
vents the delivery of a proposal to r3. In all three cases, r3 alerts other replicas of failure via a Failure message (dashed arrow),
while the replicas r1 and r2 observe identical behavior.

(2) r committed in all rounds before round 𝜌;1 and
(3) r is currently still in view 𝑣.

If these conditions are met, then r starts the process to commit to
𝑚 by broadcasting a message CheckCommit(P(𝑚)) with P(𝑚) the
prepared certificate for 𝑚 stored by r. Then each replica r waits
until it receives well-formed CheckCommit messages for proposal 𝑚
from at-least nf distinct replicas. After receiving these nf messages,
the proposal 𝑚 is committed. As a proof of this committed state
for 𝑚, r stores a commit certificate C(𝑚) consisting of these nf
CheckCommit messages.

Let 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) be a proposal. If any replica receives
a well-formed message CheckCommit(P(𝑚)), then it can use the
provided prepared certificate P(𝑚) for 𝑚 to prepare 𝑚 and execute
𝜏 (if it has not yet done so).2

The pseudo-code for this check-commit protocol can be found
in Figure 6 and an illustration of the working of this protocol can
be found in Figure 7.

The correctness of PoE is based on the following properties of

the check-commit protocol:

Theorem 4.4. Assume that communication is reliable, transaction
execution is deterministic, and all non-faulty replicas are in view 𝑣.
Round 𝜌 of view 𝑣 of the check-commit protocol of PoE satisfies the
following three properties:

(1) if a client 𝛾 receives a (𝑣, 𝜌)-proof-of-execution for ⟨𝜏⟩𝛾 , then
all non-faulty replicas will prepare some proposal proposing
⟨𝜏⟩𝛾 in round 𝜌;

(2) if all non-faulty replicas executed the same sequence of 𝜌 − 1
transactions and a non-faulty replica stored a commit certifi-
cate for proposal 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), then all non-faulty
replicas will store a commit certificate for 𝑚 and 𝛾 will receive
a (𝑣, 𝜌)-proof-of-execution for ⟨𝜏⟩𝛾 ; and

(3) if there exists a commit certificate C(𝑚) for proposal 𝑚 =
Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), then at-least nf − f non-faulty replicas
stored prepared certificates for proposal 𝑚, executed 𝑚, and

1To maximize throughput, one can choose for a design with out-of-order commit steps
(in which round 𝜌 + 1 can commit before round 𝜌). We have omitted such a design
in this presentation of PoE, as it would complicate view-changes and substantially
increase the complexity of the correctness proofs of PoE.
2If digital signatures are not used on Prepare messages, then prepared certificates
cannot be reliably forwarded. In that case, a replica needs to receive nf − f > f
identical CheckCommit messages for proposal 𝑚 from distinct replicas before it can
use the provided information to prepare 𝑚. We refer to Section 5.2 and Section 5.5 for
further details. We note that if communication is reliable, then a replica is guaranteed
to receive nf − f identical CheckCommit messages unless the behavior of the primary
disrupts the progress of the normal-case protocol, in which case a view-change will
happen (see Section 4.4).

Check-commit role (running at every replica r ∈ ℜ) :

1: event r prepared 𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌) and executed 𝜏 do
2: Wait until all previous rounds have a commit certificate.
3:

if 𝑣 is the current view then

4:

5:

Let P(𝑚) be the prepared certificate stored for 𝑚.
Broadcast CheckCommit(P(𝑚)) to all replicas.

end if

6:
7: end event
8: event r receives a well-formed message CheckCommit(P(𝑚)) do
Let 𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣′, 𝜌′) and P(𝑚) = {𝑚1, . . . , 𝑚nf }.
9:
if 𝑣 = 𝑣′ and r did not prepare 𝑚 then

10:

11:

Prepare 𝑚 and execute 𝜏 using Lines 16–18 of Figure 3 with
Prepare messages 𝑚1, . . . , 𝑚nf .

end if

12:
13: end event
14: event r receives nf messages 𝑚𝑖 = CheckCommit(P(𝑚)𝑖 ) such that:

(1) 𝑚 is a well-formed proposal Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌);
(2) 𝑣 is the current view;
(3) P(𝑚)𝑖 is a well-formed prepared certificate for 𝑚;
(4) each message is signed by a distinct replica; and
(5) r prepared 𝑚

do

15: Wait until all previous rounds have a commit certificate.
Store commit certificate C(𝑚) = {P(𝑚)𝑖 | 1 ≤ 𝑖 ≤ nf }.
16:
17: end event

Figure 6: The check-commit protocol in PoE.

r1
r2
r3
r4

CheckCommit CheckCommit

Prepare and execute 𝜏.
Commit 𝜏 (Decide).

Figure 7: A schematic representation of the check-commit
protocol of PoE. In this illustration, replicas r1, r2, and r3
initiate the check-commit protocol due to preparing and ex-
ecuting a transaction 𝜏 (which they finish at different times),
whereas r4 learns 𝜏 via the CheckCommit message it receives
from replicas r1 and r2. The replicas explicitly decide on 𝜏
upon finishing the protocol.

stored commit certificates for proposals in every round 𝜌 ′ pre-
ceding round 𝜌 (𝜌 ′ < 𝜌).

On the Correctness of Speculative Consensus

Proof. We prove the three statements separately.
Client 𝛾 only receives a (𝑣, 𝜌)-proof-of-execution for ⟨𝜏⟩𝛾 if at-
least nf distinct replicas signed some message Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ).
As there are at-most f faulty replicas and nf > 2f, there exist at-least
nf − f ≥ f + 1 non-faulty replicas that must have sent these Inform
messages to 𝛾. Choose such a non-faulty replica q. Replica q will
only do so after preparing some proposal 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌)
and executing 𝜏 (Line 18 of Figure 3). Consequently, q satisfies the
conditions to start the commit-phase for 𝑚 and will broadcast a
well-formed message CheckCommit(P(𝑚)q) to all replicas (Line 5
of Figure 6). Hence, as communication is reliable, all non-faulty
replicas will receive a well-formed message CheckCommit(P(𝑚)q)
and will be able to prepare 𝑚 (Line 11 of Figure 6).

Next, we prove the second statement. Assume that non-faulty
replica r stored a commit certificate C(𝑚). This certificate is based
on well-formed CheckCommit messages from nf distinct replicas
(Line 14 of Figure 6). Consequently, there exists a non-faulty replica
q that must have sent one of these CheckCommit messages to r.
This replica q must have broadcasted its well-formed message
CheckCommit(P(𝑚)q) to all replicas (Line 5 of Figure 6). Hence,
as communication is reliable, all non-faulty replicas will receive
a well-formed message CheckCommit(P(𝑚)q), will be able to pre-
pare 𝑚 (Line 11 of Figure 6), will receive well-formed messages
CheckCommit(P(𝑚)𝑖 ) from all nf non-faulty replicas (Line 5 of Fig-
ure 6), and will be able to commit 𝑚 (Line 14 of Figure 6). Finally,
we can use the same argument as in the proof of Theorem 4.1(2) to
prove that 𝛾 will receive a (𝑣, 𝜌)-proof-of-execution for ⟨𝜏⟩𝛾 .

Finally, we prove the third statement. The commit certificate
C(𝑚) can only exist if nf distinct replicas signed the message
CheckCommit(𝑚). Hence, there are at-least nf − f non-faulty repli-
cas that signed message CheckCommit(𝑚). These nf − f non-faulty
replicas will only sign CheckCommit(𝑚) after they prepared and
executed 𝑚 and committed all previous rounds (Line 2 of Figure 6),
□
completing the proof.

4.4 The View-Change Protocol

To deal with disruptions of the normal-case protocol of PoE, PoE
employs a view-change protocol. This protocol has two goals:

(G1) The view-change protocol must always preserve requests ⟨𝜏⟩𝛾
with a proof-of-execution: if client 𝛾 could have observed
successful execution of transaction 𝜏, then the view-change
protocol must guarantee that the execution of 𝜏 is preserved
by the system and included in all future views. Furthermore,
the view-change protocol must always preserve committed
transactions.

(G2) The view-change protocol must resume the normal-case pro-
tocol when communication is reliable: if communication
is reliable and the normal-case protocol is disrupted to the
point where the check-commit protocol can no longer assure
that all non-faulty replicas commit, then the view-change
protocol eventually puts all non-faulty replicas in the same
future view 𝑣 ′ in which the normal-case protocol can operate
without disruptions.

These goals reflect the guarantees provided by weak consensus:
Goal G1 will be used to provide non-divergence, whereas Goal G2

will be used to provide termination (when communication is suffi-
ciently reliable).

The view-change protocol for view 𝑣 operates in three stages:
(1) Replicas enter the failure detection stage when they detect
failure of view 𝑣. In this first stage, each replica that detects
failure of the current primary will alert all other replicas of
this failure. These failure alert messages are not only used
to assure that all replicas detect failure of the primary, but
will also assure sufficient synchronization of the replicas to
guarantee the view-change protocol will succeed whenever
communication is reliable.

(2) When replicas receive failure alerts for the same primary
from nf distinct replicas, they enter the new-view proposal
stage. During this second stage, replicas provide the new
primary, the replica p′ with id(p′) = (𝑣 + 1) mod n, with a
summary of their internal state. After the new primary p′
receives such summary of sufficient replicas, p′ can deter-
mine the state in which the next view starts, which it then
proposes and broadcast to all other replicas. All replicas wait
for this new-view proposal from p′ (and detect failure of
view 𝑣 + 1 if no valid new-view proposal arrives on time).
(3) When replicas receive a valid new-view proposal from the
new primary, they enter the new-view accept stage. In this
third and final stage, the replicas will validate the new-view
proposal they received, update their local state based on the
information in the new-view proposal, and start the normal-
case protocol of PoE for this new view.

The pseudo-code for the view-change protocol can be found in
Figure 8, and an illustration of the working of this protocol can be
found in Figure 9. Next, we will detail each of the three stages in
more detail.

The Failure Detection Stage. In the failure detection stage, replicas
detect failure of view 𝑣 and alert other replicas of this failure. To
alert other replicas of a failure of view 𝑣, replicas will broadcast
messages Failure(𝑣). Before a replica r enters the failure detection
stage, replica r needs to detect failure of the primary. Replica r can
do so in two ways.

First, r can set a timer whenever it expects a proposal for some
round 𝜌 from the current primary. If this timer expires and no pro-
posal for round 𝜌 was finished (proposed, executed, and committed),
then r detects failure. Replica r can expect a proposal whenever it
forwarded a valid client request to the current primary or whenever
it receives valid Prepare messages for round 𝜌 from non-faulty
replicas (e.g., by receiving such Prepare messages from f +1 distinct
replicas) without receiving any corresponding Propose messages.
Second, r can receive failure alerts for the current (or future)
view of at-least f + 1 distinct other replicas. As there are at-most
f faulty replicas, at-least one of these alerts must have originated
from some non-faulty replica q. In this case, r can simply use this
observation to detect failure.

The New-View Proposal Stage. Replicas enter the new-view pro-
posal stage for view 𝑣 after they receive messages Failure(𝑣 ′),
𝑣 ′ ≥ 𝑣, from nf distinct replicas. This condition will synchronize the
view-change in all non-faulty replicas whenever communication is
reliable:

Failure detection stage (running at every replica r ∈ ℜ) :

1: event r detects failure of view 𝑣 do
2:

if r did not previously detect failure of view 𝑣 then

3:

Broadcast Failure(𝑣) to all replicas and periodically rebroadcast
until the new-view proposal stage is entered.

end if

4:
5: end event
6: event r receives messages Failure(𝑣′) with 𝑣′ ≥ 𝑣 and

signed by f + 1 distinct replicas do

r detects failure of view 𝑣.

7:
8: end event

New-view proposal stage (running at every replica r ∈ ℜ) :

9: event r receives messages Failure(𝑣′) with 𝑣′ ≥ 𝑣 and

signed by nf distinct replicas do

10:

11:

12:

13:

14:

Halt the normal-case protocol of Section 4.1 for view 𝑣.
Halt the check-commit protocol of Section 4.3 for view 𝑣.
Let C(𝑚) be the last commit certificate stored by r and let E be the
set of prepared certificates P(𝑚′) for all proposals 𝑚′ that r executed
(without rollback) after proposal 𝑚.
Send ViewState(𝑣, C(𝑚), E) to replica p′, id(p′) = (𝑣 + 1) mod n.
Await a valid NewView message for view 𝑣 + 1. If no such message
arrives on time, then detect failure of view 𝑣 + 1.

15: end event
16: event r receives well-formed messages ViewState(𝑣, C(𝑚𝑖 )𝑖, E𝑖 ),

1 ≤ 𝑖 ≤ nf, signed by nf distinct replicas do

if id(r) = (𝑣 + 1) mod n (r is the primary of view 𝑣 + 1) then

Let V = {ViewState(𝑣, C(𝑚𝑖 )𝑖, E𝑖 ) | 1 ≤ 𝑖 ≤ nf }.
Broadcast NewView(𝑣 + 1, V) to all replicas.

17:

18:

19:

end if

20:
21: end event

New-view accept stage (running at every replica r ∈ ℜ) :

22: event r receives well-formed message NewView(𝑣 + 1, V)
from replica p′, id(p′) = (𝑣 + 1) mod n do

23:

Update the internal state in accordance to V and start the normal-case
protocol of Section 4.1 for view 𝑣 + 1.

24: end event

Figure 8: The view-change protocol of PoE.

p′
r1
r2

b ∈ F

Failure

Failure
(Join)

ViewState

NewView

Figure 9: A schematic representation of the view-change pro-
tocol of PoE. The current primary b is faulty and needs to be
replaced. The next primary, p′, and the replica r1 detected
this failure first and alerted all replicas via Failure mes-
sages. The replica r2 joins in on this failure. After replicas
receive nf = 3 Failure messages, they send their state to p′
via ViewState messages. Finally, p′ uses nf such ViewState
messages to propose a new view via a NewView message.

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

Lemma 4.5. Assume communication is reliable and has message
delay 𝛿. If the first non-faulty replica to enter the new-view proposal
stage does so at time 𝑡, then all non-faulty replicas will enter the
new-view proposal stage before-or-at 𝑡 + 2𝛿.

Proof. Let r be the first non-faulty replica that enters the new-
view proposal stage. As replica r entered the new-view proposal
stage at 𝑡, it received messages Failure(𝑣 ′), 𝑣 ′ ≥ 𝑣, from nf distinct
replicas before-or-at 𝑡 (Line 9 of Figure 8). As there are at-most f
faulty replicas and nf > 2f, at-least nf − f ≥ f + 1 of these messages
originated from non-faulty replicas, whom always broadcast their
Failure messages (Line 3 of Figure 8). Hence, if communication is
reliable, then all replicas will receive at-least f +1 Failure messages
within at-most a message-delay 𝛿. Consequently, all non-faulty
replicas will have detected failure of view 𝑣 at-most at 𝑡 + 𝛿 and
broadcast Failure messages themselves (Line 7 of Figure 8), due
to which all replicas will receive nf Failure messages at-most at
𝑡 + 2𝛿 and enter the new-view proposal stage for view 𝑣 (Line 9 of
□
Figure 8).

Consider a period of reliable communication in an asynchronous
environment. In this environment, the message delay 𝛿 as used
in Lemma 4.5 is bounded by a value unknown to the non-faulty
replicas. In Lemma 4.13 and Theorem 4.15, we show how non-faulty
replicas can determine a sufficiently high upper bound for 𝛿.

When a non-faulty replica r enters the new-view proposal stage
for view 𝑣, r first halts its participation in the normal-case protocol
of Section 4.1 and the check-commit protocol of Section 4.3 for view
𝑣. Next, r constructs a summary of its internal state. To do so, r
constructs the set E that holds the prepared certificates P(𝑚′) of
proposals executed (without rollback) by r and stored since the last
commit certificate C(𝑚) stored by r. To simplify presentation, we
assume that each replica r has a dummy commit certificate for round
𝜌 = 0 (that does not propose any request), which r uses when it
has not yet committed proposals. The pair (C(𝑚), E) will serve as
the summary of the current state of r. Finally, r sends (C(𝑚), E) to
the next primary, the replica p′ with id(p′) = (𝑣 + 1) mod n, via a
ViewState(𝑣, C(𝑚), E) message.3

The next primary, the replica p′ with id(p′) = (𝑣 + 1) mod n,

will wait until it receives well-formed messages

V = {ViewState(𝑣, C(𝑚𝑖 )𝑖, E𝑖 ) | 1 ≤ 𝑖 ≤ nf },
signed by nf distinct replicas. After p′ has received these messages
V, p′ broadcasts the message NewView(𝑣 + 1, V) to all replicas. This
message announces a new-view whose initial state is based on the
information in V. To assure timely arrival of these messages, we
use the following assumption:

Assumption 4.6. All PoE messages have a predetermined bounded
size. In specific, there is a known upper bound on the size of proposals
of the form Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) and there is an upper bound on the
number of rounds with prepared proposals that are not yet committed.
We refer to this upper bound as the window size.

3In PoE, we distinguish between Failure messages, which are small and broadcasted
to all other replicas, that are used to detect failures; and ViewState messages, which are
large and send only to the next primary, that are used to construct a NewView message. If
bandwidth is not a limiting factor, then one can simply broadcast ViewState messages
to all replicas to fulfill both roles.

On the Correctness of Speculative Consensus

Using Assumption 4.6, we can assume, without loss of generality,
that message delivery times are independent of the message size
and are fully determined by some unknown message delay.

Lemma 4.7. Assume communication is reliable and has message
delay 𝛿. If the first non-faulty replica to enter the new-view proposal
stage does so at time 𝑡, then any non-faulty next primary will be able
to deliver a new-view proposal before 𝑡 + 4𝛿.

Proof. Due to Lemma 4.5, all non-faulty replicas will have en-
tered the new-view proposal stage at 𝑡 +2𝛿. Hence, the next primary
will have received sufficient ViewState messages at 𝑡 + 3𝛿 to pro-
pose a new-view (Line 16 of Figure 8), and a well-formed new-view
proposal will be broadcast at-or-before 𝑡 + 3𝛿 to all replicas (Line 19
of Figure 8). Consequently, all replicas will receive this new-view
□
proposal before 𝑡 + 4𝛿.

Due to synchronized entry of the new-view proposal stage, every
non-faulty replica r will expect a timely new-view proposal. If no
such proposal is received, then r will detect failure of view 𝑣 + 1.

The New-View Accept Stage. Replicas enter the new-view accept
stage after they receive a well-formed NewView(𝑣 + 1, V) message
from the primary of view 𝑣 + 1, the replica p′ with id(p′) = (𝑣 +
1) mod n. Based on the information included in V, each replica
will determine the state in which 𝑣 + 1 starts. This state consists of
the set of transactions that have been proposed before view 𝑣 + 1
and, hence, determines at which round the primary p′ of 𝑣 + 1 can
start proposing. We make the following key assumption:

Assumption 4.8. If there exists a commit certificate C(𝑚) for pro-
posal 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), then every commit certificate C(𝑚′)
for round 𝜌 is a commit certificate for a proposal proposing ⟨𝜏⟩𝛾 .

As part of proving the correctness of the view-change protocol,
we will prove that Assumption 4.8 holds. Before we do so, we first
show how we interpret the unique state represented by a well-
formed proposal 𝑛 = NewView(𝑣 + 1, V) using Assumption 4.8.
Furthermore, we will show that this derived state satisfies Goal G1.
Let V = {ViewState(𝑣, C(𝑚𝑖 )𝑖, E𝑖 ) | 1 ≤ 𝑖 ≤ nf } be the set of
ViewState messages included in 𝑛. Let

C(𝜌) = {⟨𝜏⟩𝛾 | ∃𝑣 ∃C(𝑚) (𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌))},

be the set of client requests ⟨𝜏⟩𝛾 that have been committed in round
𝜌 (a view 𝑣 exists for which a commit certificate C(𝑚) exists with
𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌)). Let

P(𝑛, 𝜌) = {𝑚 | (P(𝑚) ∈ E𝑖 ) ∧ (𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌))}

be the set of all proposals included in V for round 𝜌, let

M(𝑛, 𝜌) = {⟨𝜏⟩𝛾 | (Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) ∈ P(𝑛, 𝜌)) ∧

𝑣 = max{𝑣 ′ | Propose(⟨𝜏 ′⟩𝛾 ′, 𝑣 ′, 𝜌) ∈ P(𝑛, 𝜌)}}

be the set of client requests proposed in the most-recent view of
any proposals in P(𝑛, 𝜌), let

LC(𝑛) = max{𝜌𝑖 | 𝑚𝑖 = Propose(⟨𝜏𝑖 ⟩𝛾𝑖 , 𝑣𝑖, 𝜌𝑖 )}

be the latest round for which a commit certificate is included in V,
and let

LP(𝑛) = max({𝜌 | P(𝑛, 𝜌) ≠ ∅} ∪ LC(𝑛))

be the latest round for which 𝑛 includes proposals. We will use
the sets C(·) and M(𝑛, ·) to define the unique sequence of client
transactions preserved by new-view proposal 𝑛. To do so, we use
the following technical result:

Lemma 4.9. Let 𝑛 = NewView(𝑣 + 1, V) be a well-formed new-view

proposal. We have:

(1) if Assumption 4.8 holds, then C(𝜌) is a singleton set (|C(𝜌)| =

1) for all 𝜌 ≤ LC(𝑛) ; and

(2) M(𝑛, 𝜌) is a singleton set (|M(𝑛, 𝜌)| = 1) for all LC(𝑛) < 𝜌 ≤

LP(𝑛).

Proof. First, we prove |C(𝜌)| = 1 for all 𝜌 ≤ LC(𝑛). By the
definition of LC(𝑛), there exists a commit certificate for round
LC(𝑛). By Theorem 4.4(3), there exist commit certificates for all
rounds 𝜌 ≤ LC(𝑛). Hence, for all 𝜌 ≤ LC(𝑛), C(𝜌) ≠ ∅. Finally, by
Assumption 4.8, we conclude |C(𝜌)| = 1.

Next, we prove |M(𝑛, 𝜌)| = 1 for all LC(𝑛) < 𝜌 ≤ LP(𝑛).
By the definition of LP(𝑛), we must have P(𝑛, LP(𝑛)) ≠ ∅ and
M(𝑛, LP(𝑛)) ≠ ∅. Let ⟨𝜏⟩𝛾 ∈ M(𝑛, LP(𝑛)). By the definition of
M(𝑛, LP(𝑛)), there exists a message 𝑚vs = ViewState(𝑣, C(𝑚), E) ∈
V such that there exists a prepared certificate P(𝑚′) ∈ E with
𝑚′ = Propose(⟨𝜏⟩𝛾 , 𝑣, LP(𝑛)). Let r be the replica that signed this
message 𝑚vs and let 𝜌 ′ be the round for which 𝑚 was proposed. By
the definition of LC(𝑛), we have 𝜌 ′ ≤ LC(𝑛). As NewView(𝑣 + 1, V)
is well-formed, also the message 𝑚vs is well-formed. As non-faulty
replicas only execute proposals for round 𝜌 after they executed pro-
posals for all preceding rounds (Line 17 of Figure 3) and E is well-
formed, it must contain proposals for all rounds 𝜌, 𝜌 ′ ≤ LC(𝑛) <
𝜌 ≤ LP(𝑛). Hence, for all LC(𝑛) < 𝜌 ≤ LP(𝑛), P(𝑛, 𝜌) ≠ ∅
which implies M(𝑛, 𝜌) ≠ ∅. Due to Theorem 4.1(1), we also have
□
|M(𝑛, 𝜌)| ≤ 1 and we conclude |M(𝑛, 𝜌)| = 1.

Due to Lemma 4.9, the sequence of client requests

L (𝑛) = ⟨𝜏1⟩𝛾1

, . . . , ⟨𝜏LP(𝑛) ⟩𝛾LP(𝑛) with
(cid:40)

⟨𝜏𝜌 ⟩𝛾𝜌 ∈

C(𝜌)
M(𝑛, 𝜌)

if 1 ≤ 𝜌 ≤ LC(𝑛);
if LC(𝑛) < 𝜌 ≤ LP(𝑛).

is uniquely defined by the new-view proposal 𝑛 and specifies the
state in which view 𝑣 + 1 starts. Replica r will update its internal
state (Line 23 of Figure 8) in accordance to L (𝑛) in the following
way:

(1) r will rollback every client request it executed and that is

not included in L (𝑛);

(2) r will obtain a commit certificate for each round 𝜌, 1 ≤ 𝜌 ≤
LC(𝑛), for which it does not yet have a commit certificate,
execute the newly obtained requests in order, and inform
the client of the result,

(3) r will expect the new primary to repropose client requests
⟨𝜏𝜌 ⟩𝛾𝜌 , LC(𝑛) < 𝜌 ≤ LP(𝑛), in round 𝜌 of view 𝑣 + 1. If
the new primary fails to do so, then failure of view 𝑣 + 1 is
detected.

The last step assures that all non-faulty replicas that receive a
new-view proposal for view 𝑣 + 1 will only proceed in this new
view if they all received compatible new-view proposals that each
represent the same unique ledger.

After updating its internal state, replica r will start the normal-
case protocol for view 𝑣 + 1 by accepting any proposal from p′ for
rounds after LP(𝑛).

Next, we prove that the view-change protocol outlined above

satisfies Goal G1 and Goal G2.

The View-Change Protocol Satisfies Goal G1. A client request ⟨𝜏⟩𝛾
needs to be preserved by the view-change protocol as the 𝜌-th re-
quest if it either has a (𝑣, 𝜌)-proof-of-execution or a replica stored a
commit certificate C(𝑚) for some proposal 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌).
If ⟨𝜏⟩𝛾 has a (𝑣, 𝜌)-proof-of-execution, then there must be a set of
identical messages Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ) signed by nf distinct repli-
cas. Likewise, if ⟨𝜏⟩𝛾 has a commit certificate C(𝑚), then there must
be a set of identical messages CheckCommit(𝑚) signed by nf dis-
tinct replicas. As there are at-most f faulty replicas, at-least nf − f
of these messages must originate from non-faulty replicas, which
will only produce these messages after they prepared and executed
proposal 𝑚. Hence, a necessary condition for the preservation of
⟨𝜏⟩𝛾 is the existence of a proposal 𝑚 that is executed by at-least
nf − f non-faulty replicas. Next, we prove that the view-change
protocol preserves such requests:

Theorem 4.10. Let 𝑣 be the first view in which a proposal 𝑚 =
Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) for round 𝜌 was executed by nf − f non-faulty
replicas, let 𝑚′ = Propose(⟨𝜏 ′⟩𝛾 ′, 𝑣 ′, 𝜌) be any proposal for round
𝜌 with 𝑣 ≤ 𝑣 ′, and let 𝑛 = NewView(𝑤 + 1, V), 𝑣 ≤ 𝑣 ′ ≤ 𝑤, be a
well-formed new-view proposal. The following properties hold:

(1) there exist no commit certificates C(Propose(⟨𝜏 ′′⟩𝛾 ′′, 𝑣 ′′, 𝜌))

with 𝑣 ′′ < 𝑣;

(2) in views 𝑣 ′, 𝑣 < 𝑣 ′, non-faulty replicas only sign Prepare(𝑚′)

if ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 ;

(3) if there exists a prepared certificate P(𝑚′), then ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 ;
(4) if nf − f non-faulty replicas executed 𝑚′, then 𝜌 ≤ LP(𝑛);
(5) if nf − f non-faulty replicas committed 𝑚′, then 𝜌 ≤ LC(𝑛);

and

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

(4) and (5). As 𝑤 = 𝑣, we can use (1) and the proof of (3), to derive
that 𝑚′ = 𝑚. Let 𝑛 = NewView(𝑤 + 1, V), 𝑤 = 𝑣, be a well-formed
new-view proposal. Let 𝐶 be the set of nf −f non-faulty replicas that
executed 𝑚 (proof for (4)) or committed 𝑚 (proof for (5)), let 𝑆 be
the set of nf distinct replicas that signed the ViewState messages
included in V, and let 𝑇 = 𝑆 \ F be the non-faulty replicas in 𝑆.
By construction, we have |𝑇 | ≥ nf − f. Hence, using the same
contradiction argument as used in the proof of Theorem 4.1(1), we
can conclude that (𝐶 ∩ 𝑇 ) ≠ ∅. Let r ∈ (𝐶 ∩ 𝑇 ) be such a non-
faulty replica that executed 𝑚 (proof for (4)) or committed 𝑚 (proof
for (5)) and that signed a message ViewState(𝑣, C(𝑚r), E) ∈ V
with 𝑚r = Propose(⟨𝜏r⟩𝛾r

If r committed 𝑚, then we must have 𝜌 ≤ 𝜌r as non-faulty
replicas commit proposals in order (Line 15 of Figure 6) and 𝑚r is
the last proposal r committed (Line 12 of Figure 8). Hence, by the
definition of LC(𝑛) and LP(𝑛), we have 𝜌 ≤ 𝜌r ≤ LC(𝑛) ≤ LP(𝑛).
If r executed 𝑚 without committing 𝑚, then 𝜌 > 𝜌r. As r exe-
cuted 𝑚, r must have stored a prepared certificate P(𝑚) (Line 16
of Figure 3) and we conclude P(𝑚) ∈ E (Line 12 of Figure 8). By
the definition of P(𝑛, 𝜌) and the definition of LP(𝑛), we conclude
𝑚 ∈ P(𝑛, 𝜌) and 𝜌 ≤ LP(𝑛).

, 𝑣r, 𝜌r).

(6). As nf − f non-faulty replicas executed 𝑚 in view 𝑤 = 𝑣, we

have 𝜌 ≤ LP(𝑛) by (5). Hence, L (𝑛) [𝜌] is defined.

If 𝜌 ≤ LC(𝑛), then, by the definition of L (𝑛) and C(𝜌), we have
L (𝑛) [𝜌] = ⟨𝜏𝑛⟩𝛾𝑛 with ⟨𝜏𝑛⟩𝛾𝑛 ∈ C(𝜌) and there exists a commit
certificate C(𝑚𝑛) for some proposal 𝑚𝑛 = Propose(⟨𝜏𝑛⟩𝛾𝑛 , 𝑣𝑛, 𝜌).
By (1), we conclude that 𝑣 ≤ 𝑣𝑛 and, hence, 𝑣𝑛 = 𝑣. Due to Theo-
rem 4.4(3), there exists a prepared certificate P(𝑚𝑛) and, by (3), we
conclude ⟨𝜏𝑛⟩𝛾𝑛 = ⟨𝜏⟩𝛾 .

If LC(𝑛) < 𝜌 ≤ LP(𝑛), then, by the definition of L (𝑛), M(𝑛,),
and P(𝑛, 𝜌), we have L (𝑛) [𝜌] = ⟨𝜏𝑛⟩𝛾𝑛 with ⟨𝜏𝑛⟩𝛾𝑛 ∈ M(𝑛, 𝜌)
and there exists a prepared certificate P(𝑚𝑛) for some proposal
𝑚𝑛 = Propose(⟨𝜏𝑛⟩𝛾𝑛 , 𝑣𝑛, 𝜌) with 𝑚𝑛 ∈ P(𝑛, 𝜌). Using the same
reasoning as in the proof of (4), there exists a non-faulty replica r
that executed 𝑚 and signed a message ViewState(𝑣, C(𝑚r), E) ∈ V.
As LC(𝑛) < 𝜌, r did not commit 𝑚, P(𝑚) ∈ E, and 𝑚 ∈ P(𝑛, 𝜌). By
the definition of M(𝑛, 𝜌), we conclude 𝑣 ≤ 𝑣𝑛. Hence, 𝑣𝑛 = 𝑣 and,
by (3), we conclude ⟨𝜏𝑛⟩𝛾𝑛 = ⟨𝜏⟩𝛾 .

(6) L (𝑛) [𝜌] = ⟨𝜏⟩𝛾 ;

Proof. First, we prove (1) by contradiction. Assume there ex-
ists a commit certificate C(Propose(⟨𝜏 ′′⟩𝛾 ′′, 𝑣 ′′, 𝜌)) with 𝑣 ′′ < 𝑣.
Hence, there exist messages CheckCommit(P(𝑚′′)𝑖 ), 1 ≤ 𝑖 ≤ nf,
signed by nf distinct replicas (Line 16 of Figure 6). At-least nf − f
of these messages are signed by non-faulty replicas. As non-faulty
replicas only construct and sign messages CheckCommit(P(𝑚′′)𝑖 )
if they prepared and executed 𝑚′′ (Line 5 of Figure 6) and 𝑣 was the
first view in which nf − f non-faulty replicas executed a proposal
for round 𝜌, we must have 𝑣 ≤ 𝑣 ′′, a contradiction, and we conclude
that C(𝑚′′) does not exist.

We prove (2)–(6) by induction on the current view 𝑤. As the
base case, we prove that each of the statements (2)–(6) hold in view
𝑤 = 𝑣.

(2). We have 𝑤 = 𝑣 ′ = 𝑣. Hence, the statement voidly holds.
(3). As 𝑤 = 𝑣, we only need to consider 𝑣 = 𝑣 ′. If 𝑣 = 𝑣 ′, then, by

Theorem 4.1(1), we have 𝑚′ = 𝑚 and ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 .

As the induction hypothesis, we assume that (2)–(6) hold in
every view 𝑗, 𝑣 ≤ 𝑗 < 𝑤. Now consider view 𝑤 and let 𝑛𝑤 =
NewView(𝑤, V𝑤) be a well-formed new-view proposal that can be
used to enter view 𝑤 (Line 22 of Figure 8). Next, we prove the
inductive step for each of the statements (2)–(6).

(2). Let Prepare(𝑚′), 𝑣 < 𝑣 ′ ≤ 𝑤, be a message signed by a
non-faulty replica. We apply induction hypothesis (4) on 𝑛𝑤 and
conclude 𝜌 ≤ LP(𝑛𝑤). If, furthermore, 𝜌 ≤ LC(𝑛𝑤), then the
primary of view 𝑤 cannot propose for round 𝜌 and we must have
𝑣 ≤ 𝑣 ′ < 𝑤. We apply induction hypothesis (2) on Prepare(𝑚′) to
conclude ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 . Otherwise, if LC(𝑛𝑤) < 𝜌 ≤ LP(𝑛𝑤), then
the primary of view 𝑤 can only propose ⟨𝜏⟩𝛾 for round 𝜌 (Line 23
of Figure 8), and we conclude ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 .

(3). Let P(𝑚′) be a prepared certificate, 𝑣 ≤ 𝑣 ′ ≤ 𝑤. If 𝑣 ′ < 𝑤,
then we apply induction hypothesis (3) to conclude that ⟨𝜏 ′⟩𝛾 ′ =
⟨𝜏⟩𝛾 . Otherwise, if 𝑣 ′ = 𝑣, then there exist messages Prepare(𝑚)
signed by nf distinct replicas (Line 16 of Figure 3). At-least nf − f

On the Correctness of Speculative Consensus

of these messages are signed by non-faulty replicas. By (2), these
non-faulty replicas will only sign 𝑚′ if ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 .

(4) and (5). Let 𝑛 = NewView(𝑤 + 1, V) be a well-formed new-
view proposal. Let 𝐶 be the set of nf − f non-faulty replicas that
executed 𝑚′ (proof for (4)) or committed 𝑚′ (proof for (5)), let 𝑆 be
the set of nf distinct replicas that signed the ViewState messages
included in V, and let 𝑇 = 𝑆 \ F be the non-faulty replicas in 𝑆.
By construction, we have |𝑇 | ≥ nf − f. Hence, using the same
contradiction argument as used in the proof of Theorem 4.1(1), we
can conclude that (𝐶 ∩𝑇 ) ≠ ∅. Let r ∈ (𝐶 ∩𝑇 ) be such a non-faulty
replica that executed 𝑚′ (proof for (4)) or committed 𝑚′ (proof
for (5)) and that signed a message ViewState(𝑣, C(𝑚r), E) ∈ V
, 𝑣r, 𝜌r). Let 𝑣 ′′ be the last view in which
with 𝑚r = Propose(⟨𝜏r⟩𝛾r
r executed transactions. As r executed 𝑚′, we have 𝑣 ≤ 𝑣 ′ ≤ 𝑣 ′′ ≤
𝑤.

If 𝑣 ′ = 𝑣 ′′, then r is guaranteed to execute 𝑚′ in view 𝑣 ′′ (proof
of (4)) or to commit 𝑚′ in view 𝑣 ′′ (proof of (5)). If 𝑣 ′ < 𝑣 ′′, then
r used a well-formed new-view message 𝑛′′ = NewView(𝑤, V𝑤) to
enter view 𝑣 ′′ ≤ 𝑤 (Line 22 of Figure 8). For the proof of (4), we
apply induction hypothesis (4) on 𝑛′′ to conclude that 𝜌 ≤ LP(𝑛′′).
As r executed transactions in view 𝑣 ′′, r is guaranteed to have
executed some proposal for round 𝜌 while updating its internal
state (Line 23 of Figure 8). For the proof of (5), we apply induction
hypothesis (5) on 𝑛′′ to conclude that 𝜌 ≤ LC(𝑛′′). As r executed
transactions in view 𝑣 ′′, r is guaranteed to have committed some
proposal for round 𝜌 while updating its internal state (Line 23 of
Figure 8).

If r is guaranteed to have committed some proposal 𝑚′′ in round
𝜌 of view 𝑣 ′′ or in round 𝜌 when entering view 𝑣 ′′, then we must
have 𝜌 ≤ 𝜌r as non-faulty replicas commit proposals in order
(Line 15 of Figure 6) and 𝑚r is the last proposal r committed (Line 12
of Figure 8). Hence, by the definition of LC(𝑛) and LP(𝑛), we have
𝜌 ≤ 𝜌r ≤ LC(𝑛) ≤ LP(𝑛).

If r is guaranteed to have executed some proposal 𝑚′′ in round
𝜌 of view 𝑣 ′′ or in round 𝜌 when entering view 𝑣 ′′ without com-
mitting 𝑚′′, then 𝜌 > 𝜌r. As r executed 𝑚′′, r must have stored a
prepared certificate P(𝑚′′) (Line 16 of Figure 3) and we conclude
P(𝑚′′) ∈ E (Line 12 of Figure 8). By the definition of P(𝑛, 𝜌) and
the definition of LP(𝑛), we conclude 𝑚 ∈ P(𝑛, 𝜌) and 𝜌 ≤ LP(𝑛).
(6) As nf − f non-faulty replicas executed 𝑚 in view 𝑣, we have

𝜌 ≤ LP(𝑛) by (5). Hence, L (𝑛) [𝜌] is defined.

If 𝜌 ≤ LC(𝑛), then, by the definition of L (𝑛) and C(𝜌), we have
L (𝑛) [𝜌] = ⟨𝜏𝑛⟩𝛾𝑛 with ⟨𝜏𝑛⟩𝛾𝑛 ∈ C(𝜌) and there exists a commit
certificate C(𝑚𝑛) for some proposal 𝑚𝑛 = Propose(⟨𝜏𝑛⟩𝛾𝑛 , 𝑣𝑛, 𝜌).
By (1), we conclude that 𝑣 ≤ 𝑣𝑛. Due to Theorem 4.4(3), there exists
a prepared certificate P(𝑚𝑛) and, by (3), we conclude ⟨𝜏𝑛⟩𝛾𝑛 = ⟨𝜏⟩𝛾 .
If LC(𝑛) < 𝜌 ≤ LP(𝑛), then, by the definition of L (𝑛), M(𝑛, 𝜌),
and P(𝑛, 𝜌), we have L (𝑛) [𝜌] = ⟨𝜏𝑛⟩𝛾𝑛 with ⟨𝜏𝑛⟩𝛾𝑛 ∈ M(𝑛, 𝜌)
and there exists a prepared certificate P(𝑚𝑛) for some proposal
𝑚𝑛 = Propose(⟨𝜏𝑛⟩𝛾𝑛 , 𝑣𝑛, 𝜌) with 𝑚𝑛 ∈ P(𝑛, 𝜌). As nf − f replicas
executed 𝑚, we can use the same reasoning as in the proof of (4) to
obtain a non-faulty replica r that executed 𝑚 and signed a message
ViewState(𝑣, C(𝑚r), E) ∈ V with 𝑚r = Propose(⟨𝜏r⟩𝛾r
, 𝑣r, 𝜌r).
Let 𝑣 ′′ be the last view in which r executed transactions. As r
executed 𝑚, we have 𝑣 ≤ 𝑣 ′′ ≤ 𝑤.

If 𝑣 = 𝑣 ′′, then r executed some proposal 𝑚′′ = 𝑚 in view 𝑣 ′′. If
𝑣 ′ < 𝑣 ′′, then r used some new-view message 𝑛′′ = NewView(𝑤, V𝑤)

to enter view 𝑣 ′′ ≤ 𝑤 (Line 22 of Figure 8). As r executed transac-
tions in view 𝑣 ′′, r is guaranteed to have executed some proposal
𝑚′′ for round 𝜌 while updating its internal state (Line 23 of Fig-
ure 8). As LC(𝑛) < 𝜌, r did not commit 𝑚′′ in round 𝜌 , P(𝑚′′) ∈ E,
and 𝑚′′ ∈ P(𝑛, 𝜌). By the definition of M(𝑛, 𝜌), we conclude 𝑣 ≤ 𝑣𝑛.
□
By (3), we conclude ⟨𝜏𝑛⟩𝛾𝑛 = ⟨𝜏⟩𝛾 .

Theorem 4.10 not only proves that the view-change protocol

satisfies Goal G1, it also proves that Assumption 4.8 holds.

Corollary 4.11 (Assumption 4.8). If there exists a commit certifi-
cate C(𝑚) for proposal 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌), then every commit
certificate C(𝑚′) for round 𝜌 is a commit certificate for a proposal
proposing ⟨𝜏⟩𝛾 .

Proof. By Theorem 4.4(3), at-least nf − f non-faulty replicas
stored a prepared certificate for 𝑚 and executed 𝑚 whenever a
commit certificate C(𝑚) exists. Let 𝑚′ = Propose(⟨𝜏 ′⟩𝛾 ′, 𝑣 ′, 𝜌),
𝑣 ′ ≤ 𝑣, be the first proposal for round 𝜌 that is executed by nf − f
non-faulty replicas. By Theorem 4.10(3), we conclude that ⟨𝜏 ′⟩𝛾 ′ =
□
⟨𝜏⟩𝛾 .

Theorem 4.10 and Corollary 4.11 assure that one can derive
a unique ledger from each well-formed new-view proposal 𝑛 =
NewView(𝑣 + 1, V). To resume the normal-case protocol, we also
need the guarantee that each non-faulty replica derives the same
ledger from the new-view proposal they receive, even if they re-
ceive different new-view proposals. For rounds for which a commit
certificate exists, Theorem 4.10 already provides this guarantee,
whereas for rounds for which only prepared certificates exists, the
repropose mechanisms will enforce this guarantee. Finally, to re-
sume the normal-case protocol, each individual replica also needs
to be able to derive from 𝑛 the exact content of L (𝑛). Unfortunately,
the message 𝑛 itself only contains all necessary information to de-
rive L (𝑛) [𝜌] for all 𝜌, LC(𝑛) ≤ 𝜌 ≤ LP(𝑛). Fortunately, also the
remainder of L (𝑛) can be derived:

Lemma 4.12. Let 𝑛 = NewView(𝑣 + 1, V) be a well-formed new-
view proposal. If communication is reliable, then every non-faulty
replica can derive L (𝑛) (this independent of their internal state).

Proof. Let r be a non-faulty replica that receives 𝑛 and is un-
aware of a client request L (𝑛) [𝜌], 𝜌 < LC(𝑛). By the definition of
LC(𝑛), there exists a message 𝑚vs = ViewState(𝑣, C(𝑚), E) with
𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑤, LC(𝑛)), 𝑤 ≤ 𝑣. By Theorem 4.4(3), the exis-
tence of C(𝑚) assures that at-least nf − f non-faulty replicas stored
commit certificates for some proposal 𝑚′ = Propose(⟨𝜏 ′⟩𝛾 ′, 𝑤 ′, 𝜌).
Hence, r can query all replicas for the transaction they com-
mitted in round 𝜌. To do so, r uses the query protocol outlined in
Figure 10. As the first step, r broadcasts a message QueryCC(𝜌) to all
replicas (Line 1 of Figure 10). Non-faulty replicas will respond with
the message RespondCC(P(𝑚′′), C(𝑚′′)) if they committed some
proposal 𝑚′′ in round 𝜌 and will not respond otherwise (Line 12
of Figure 10). By Corollary 4.11, no commit certificates for round
𝜌 can exist that proposes a request other than ⟨𝜏 ′⟩𝛾 ′. Hence, using
any of the received messages RespondCC(C(𝑚′′)), r will be able
to prepare, execute, and commit a proposal for ⟨𝜏 ′⟩𝛾 ′ in round 𝜌
□
(Line 4 of Figure 10).

Query role (running at replica r) :
1: Broadcast QueryCC(𝜌) to all replicas.
2: event r receives a well-formed message RespondCC(P(𝑚), C(𝑚)) do
Let 𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣′, 𝜌′) and P(𝑚) = {𝑚1, . . . , 𝑚nf }.
3:
if r did not commit in round 𝜌′ then

4:

5:

6:

7:

Wait until all previous rounds have a commit certificate.
Prepare 𝑚 and execute 𝜏 using Lines 16–18 of Figure 3 with
Prepare messages 𝑚1, . . . , 𝑚nf .
Store commit certificate C(𝑚).

end if

8:
9: end event

Query response role (running at every replica q ∈ ℜ) :

10: event q receives messages QueryCC(𝜌) from r do
11:

if q stored prepared certificate P(𝑚) and commit certificate C(𝑚)

for some proposal 𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌) then

12:

Send RespondCC(P(𝑚), C(𝑚)) to replica r.

end if

13:
14: end event

Figure 10: The query protocol of Lemma 4.12 used by repli-
cas r ∈ ℜ when recovering a missing committed proposal
for round 𝜌.

The View-Change Protocol Satisfies Goal G2. In Lemma 4.5 and
Lemma 4.7, we already outlined the main timing-based synchroniza-
tion steps used by the view-change protocol to guarantee Goal G2.
This mechanism relies on the availability of some message delay
value 𝛿 known to all non-faulty replicas that is long enough to
guarantee the delivery of any message used by PoE (see also As-
sumption 4.6). In practice, non-faulty replicas are not aware of this
bound and must use some internal message delay estimate.

Let r be a non-faulty replica that uses internal message delay esti-
mate Δ(𝑣, r) in view 𝑣. If Δ(𝑣, r) is too small, then r can erroneously
detect failure of 𝑣 + 1 (e.g., at Line 14 of Figure 8). To assure that r
will not erroneously detect failure of consecutive views, r needs
to eventually use an internal message delay estimate Δ(𝑣 + 𝑖, r) in
view 𝑣 + 𝑖 for which Δ(𝑣 + 𝑖, r) ≥ 𝛿 holds. To do so, we assume
that all non-faulty replicas q have some backoff function 𝑓 (𝑖) for
which 𝑓 (𝑖) ≥ 𝑖 holds and use the internal message delay estimate
Δ(𝑣 + 𝑖, q) = 𝑓 (𝑖) · Δ(𝑣, q). We have:

Lemma 4.13. Let Δ(𝑣, r) be the internal message delay estimate of
replica r at view 𝑣, let 𝑓 (𝑖) be the backoff function used by r, and let
𝛿 be a message delay value. There exists a 𝑗 such that Δ(𝑣 + 𝑗, r) ≥ 𝛿.

Proof. By definition, we have Δ(𝑣 + 𝑖, r) = 𝑓 (𝑖) · Δ(𝑣, r) ≥
, we have Δ(𝑣 + 𝑗, r) ≥ 𝛿. □

𝑖 · Δ(𝑣, r). Hence, for all 𝑗 ≥

(cid:109)

(cid:108)

𝛿
Δ(𝑣,r)

Frequently, an exponential function is used as the backoff func-

tion, leading to so-called exponential backoff :

Example 4.14. Consider a system with ℜ = {r1, r2, r3, r4} in
an environment with a message delay of 𝛿 = 30 ms. Assume that
all replicas are non-faulty and that we have the following internal
message delay estimates in view 𝑣:

Δ(𝑣, r1) = 7 ms;
Δ(𝑣, r3) = 5 ms;

Δ(𝑣, r2) = 3 ms;
Δ(𝑣, r4) = 1 ms,

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

and assume that all replicas use the exponential backup function
𝑓 (𝑖) = 2𝑖 . We have:

Δ(𝑣 + 3, r1) = 23 · 7 = 56 ms; Δ(𝑣 + 3, r2) = 23 · 3 = 24 ms;
Δ(𝑣 + 3, r3) = 23 · 5 = 40 ms; Δ(𝑣 + 3, r4) = 23 · 1 = 8 ms.
Hence, within three backoffs, two out of four replicas have an in-
ternal message delay estimate that is sufficiently large. The other
replicas will require four and five backoffs, respectively.

Next, we shall use backoff-based internal message delay esti-

mates to prove that the view-change protocol satisfies Goal G2.

Theorem 4.15. If non-faulty replicas use backoff-based internal
message delay estimates, the normal-case protocol was disrupted, and
communication becomes reliable, then the view-change protocol guar-
antees that the normal-case protocol will eventually be reestablished.

Proof. Assume the normal-case protocol was disrupted in some
view 𝑣. Consequently, non-faulty replicas will perform view-changes
for consecutive views 𝑣 ′ ≥ 𝑣 until the normal-case protocol is
reestablished (Line 14 of Figure 8). During the view-change for
such view 𝑣 ′, non-faulty replicas periodically rebroadcast their mes-
sages Failure(𝑣 ′) until they reach the new-view proposal stage for
𝑣 ′ (Line 3 of Figure 8). Hence, each non-faulty replica will eventually
broadcast messages Failure(𝑤) for some view 𝑤 ≥ 𝑣 whenever
communication becomes reliable. As all nf non-faulty replicas are
guaranteed to receive these messages from all nf non-faulty repli-
cas when communication becomes reliable, all non-faulty replicas
will enter the new-view proposal stage for consecutive views 𝑣 ′ ≥ 𝑣
when communication becomes reliable (Line 9 of Figure 8).

Assume that communication becomes reliable with message de-
lay 𝛿 unknown to all non-faulty replicas. Without loss of generality,
we can assume that each non-faulty replica r ∈ (ℜ \ F ) uses a
backoff function 𝑓r and uses the internal message delay estimate
Δ(𝑣 + 𝑖, r) = 𝑓r (𝑖) · Δ(𝑣, r) in view 𝑣 + 𝑖. Hence, by Lemma 4.13,
there exists a 𝑗r such that, for all views 𝑗 ≥ 𝑗r, Δ(𝑣 + 𝑗, r) ≥ 𝛿.
Consequently, in all views 𝑣 + 𝑗 ′ with 𝑗 ′ ≥ max{ 𝑗r | r ∈ (ℜ \ F )},
the internal message delay estimate of all non-faulty replicas is
at-least 𝛿.

Choose 𝑖 ≥ max{ 𝑗r | r ∈ (ℜ \ F )} such that view 𝑣 + 𝑖 is a view
for which all non-faulty replicas entered the new-view proposal
stage after communication became reliable. Let p𝑗 be the primary
of view 𝑣 +𝑖 + 𝑗 (with id(p𝑗 ) = (𝑣 +𝑖 + 𝑗) mod n). Finally, choose the
first view 𝑣 + 𝑖 + 𝜎 for which p𝜎 is non-faulty. As there are at-most
f faulty replicas, we must have 0 ≤ 𝜎 ≤ f. If the view-change
protocol reestablish the normal-case protocol in any view before
view 𝑣 + 𝑖 + 𝜎, then the statement of this theorem voidly holds.

To complete the proof, we assume that the view-change protocol
did not reestablish the normal-case protocol before view 𝑣 + 𝑖 + 𝜎
and we show that the view-change protocol will reestablish the
normal-case protocol for view 𝑣 +𝑖 +𝜎. Let 𝑡 (r) be the time at which
a non-faulty replica r ∈ (ℜ \ F ) enters the new-view proposal
stage of view 𝑣 +𝑖 +𝜎 − 1 and let 𝑡min = min{𝑡 (r) | r ∈ (ℜ \ F )} be
the time at which the first non-faulty replica enters this new-view
proposal stage. By Lemma 4.7, all replicas will receive an identical
new-view proposal NewView(𝑣 + 𝑖 + 𝜎, V) (Line 3 of Figure 8) at-or-
before 𝑡min + 4𝛿. Finally, let q be any non-faulty replica. Due to the
internal message delay estimate used by q, replica q will expect

On the Correctness of Speculative Consensus

NewView(𝑣 + 𝑖 + 𝜎, V) before

𝑡 (q) + 4Δ(𝑣 + 𝑖 + 𝜎, q) ≥ 𝑡 + 4Δ(𝑣 + 𝑖 + 𝜎, q).
As 𝑖 ≥ 𝑗 (r), we can conclude 𝑡min + 4Δ(𝑣 + 𝑖 + 𝜎, q) ≥ 𝑡 + 4𝛿, that q
receives NewView(𝑣 +𝑖 +𝜎, V), and that q enters the new-view accept
stage. Hence, all non-faulty replicas will enter the new-view accept
stage with the same new-view proposal NewView(𝑣 + 𝑖 + 𝜎, V), will
update their internal state accordingly, and reestablish the normal-
□
case protocol in view 𝑣 + 𝑖 + 𝜎.

Next, we further illustrate Theorem 4.15 in an environment with

exponential backoff.

Example 4.16. Consider the situation of Example 4.14. Due to
some disruptions, view 𝑣 fails and all replicas participate in consec-
utive view-changes (until one of these view-changes succeeds). Let
𝑡 𝑗 (r𝑖 ) be the time at which replica r𝑖 , 1 ≤ 𝑖 ≤ 4, enters the new-
view proposal phase for view 𝑣 + 𝑗 and let 𝑡 𝑗,min = min{𝑡 𝑗 (r𝑖 ) | 1 ≤
𝑖 ≤ 4} be the time at which the first replica enters the new-view
proposal phase for view 𝑣 + 𝑗.

If all replicas are non-faulty, then one can expect a valid new-
view proposal for view 𝑣 + 𝑗 + 1 at 𝑡 𝑗,min + 4𝛿, while replica r𝑖 ,
1 ≤ 𝑖 ≤ 4, will expect a valid new-view proposal for view 𝑣 + 𝑗 + 1
before

𝑡 𝑗 (r𝑖 ) + 4Δ(𝑣 + 𝑗, r𝑖 ) ≥ 𝑡 𝑗 + 4 · 2

𝑗 · Δ(𝑣, r𝑖 ).

Consequently, the new-view proposal for view 𝑣 + 𝑗 +1 is guaranteed
to arrive on time for replica r𝑖 whenever 𝑡 𝑗,min + 4 · 2𝑗 · Δ(𝑣, r𝑖 ) ≥
𝑡 𝑗,min + 4𝛿 and, hence, when 2𝑗 · Δ(𝑣, r𝑖 ) ≥ 𝛿, which simplifies to
𝑗 ≥ log2

(cid:109)
. Filling in yields

(cid:108)

𝛿
Δ(𝑣,r𝑖 )
(cid:108)

𝑗 ≥ log2

(cid:108)

(cid:108)

(cid:108)

𝑗 ≥ log2

𝑗 ≥ log2

𝑗 ≥ log2

𝛿
Δ(𝑣,r1)
𝛿
Δ(𝑣,r2)
𝛿
Δ(𝑣,r3)
𝛿
Δ(𝑣,r4)

(cid:109)

(cid:109)

(cid:109)

(cid:109)

= log2

= log2

= log2

= log2

(cid:6) 30
7

(cid:6) 30
3

(cid:6) 30
5

(cid:6) 30
1

(cid:7) = 3

(cid:7) = 4

(cid:7) = 3

(cid:7) = 5

(for replica r1);

(for replica r2);

(for replica r3);

(for replica r4).

We conclude that within at-most five consecutive view-changes,
all replicas will have a sufficiently large internal message delay
estimate to guarantee a successful view-change.

Remark 4.17. Theorem 4.15 will use arbitrarily large internal
message delay estimates to assure that all non-faulty replicas are
eventually sufficiently synchronized. In most practical deployments,
one can utilize a reasonable upper bound on any message estimate
(e.g., 10 s when sending small messages over a wide-area network),
as this upper bound will always hold whenever the network is
operating correctly (and communication is reliable).

4.5 PoE Provides Consensus
In Sections 4.1–4.4, we have laid out the design of PoE. From the
details presented, one can already derive how PoE provides non-
divergence (Theorem 4.1(1) and Theorem 4.10) and termination
(Theorem 4.4(1) and Theorem 4.15). To prove that PoE provides
weak consensus, we also need to detail how PoE provides non-
triviality. To do so, we introduce a mechanism that allows non-
faulty clients to force replication of their transactions whenever
communication is sufficiently reliable.

Consider a client 𝛾 that wants to request transaction 𝜏. In the
normal-case protocol, it is assumed that 𝛾 knows primary p of
the current view, in which case 𝛾 will simply send ⟨𝜏⟩𝛾 to p. If
this primary p is non-faulty and communication is reliable, then
this normal-case protocol will assure a proof-of-execution (The-
orem 4.1(2)). To deal with deviations of the normal-case (e.g., an
unknown primary or a faulty primary), PoE allows client 𝛾 to send
its request ⟨𝜏⟩𝛾 to any replica r. If r is non-faulty, then it will for-
ward ⟨𝜏⟩𝛾 to the primary of the current view, after which r expects
a timely proposal of ⟨𝜏⟩𝛾 via the normal-case protocol. If no such
timely proposal arrives, r will detect failure of the current view
(Line 1 of Figure 8), and, after a successful view-change, forward
⟨𝜏⟩𝛾 to the next primary.

Using the above request-forward mechanism, clients can force
consensus on requests whenever communication is sufficiently
reliable: to force consensus on request ⟨𝜏⟩𝛾 , client 𝛾 simply sends
this request to all replicas. Consequently, all non-faulty replicas will
forward ⟨𝜏⟩𝛾 to the current primary and expect a timely proposal of
⟨𝜏⟩𝛾 . If this does not happen, then all non-faulty replicas will detect
failure of the current view. As there are nf non-faulty replicas, this
is sufficient to trigger a view-change (Line 9 of Figure 8). After a
new view is established, the non-faulty replicas forward ⟨𝜏⟩𝛾 to the
next primary, this until the request is proposed and executed.

To prevent abuse of the request-forward mechanism by malicious
clients, PoE uses two heuristics. First, malicious clients can try to
suppress requests by other clients by continuously sending requests
to all replicas. To deal with such behavior, non-faulty replicas can
limit the rate at which they forward requests of a single client to the
primary (assuring that the primary has the room to timely propose
requests for all clients). Second, malicious clients can send distinct,
conflicting, requests to different replicas. In this case, the primary
has to choose one of these transactions to propose first, due to
which the primary might be unable to propose all client requests
forwarded to it within a timely fashion. To prevent failure detection
of the view due to this malicious client behavior, any replica r that
forwarded a request of client 𝛾 to the current primary will consider
any subsequent proposal of a transaction requested by 𝛾 as a timely
proposal by the primary (even if that proposal does not match the
request forwarded by r).

Using the request-forward mechanism, we are finally able to

prove that PoE provides weak consensus:

Theorem 4.18. If PoE is operated in a system with n > 3f, then

PoE provides weak consensus.

Proof. We say that a non-faulty replica r decides on ⟨𝜏⟩𝛾 in
round 𝜌 whenever it stores a commit certificate C(𝑚) with 𝑚 =
Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌). Due to Theorem 4.4(3), the existence of C(𝑚)
implies that at-least nf − f non-faulty replicas executed 𝑚. Using
these facts, we will prove that PoE provides the three guarantees
of consensus.

Termination (in periods of reliable communication). Due to The-
orem 4.4(3), the existence of C(𝑚) implies that at-least nf − f non-
faulty replicas executed 𝑚. If communication is reliable, then Theo-
rem 4.4(2) guarantees termination. If communication is unreliable
and leads to a view failure, then Theorem 4.15 assures that a new

view, view 𝑤, will be established whenever communications be-
comes reliable and Theorem 4.10(6) and Lemma 4.12 assure that
all replicas participating in view 𝑤 will recover ⟨𝜏⟩𝛾 as the 𝜌-th
decision.

Now consider non-faulty replica q that is not able to participate
in the new view 𝑤, e.g., due to faulty behavior of the primary of
view 𝑤. Replica q can make a decision for round 𝜌 in two ways.
First, if the primary of view 𝑤 can propose in round 𝜌, then either a
proposal 𝑚′ = Propose(⟨𝜏⟩𝛾 , 𝑤, 𝜌) gets committed by a non-faulty
replica, in which case Theorem 4.4(1) guarantees that q commits
𝑚′, or the failure of view 𝑤 will be detected. If the primary of
view 𝑤 cannot propose in round 𝜌, then q can use Lemma 4.12 to
derive ⟨𝜏⟩𝛾 as the 𝜌-th request whenever q detects the existence of
a commit certificate for round 𝜌. Replica q can detect the existence
of commit certificates for round 𝜌, 𝜌 < 𝜌 ′, after receiving well-
formed CheckCommit messages for round 𝜌 ′ from at-least a single
non-faulty replica (by receiving such messages from f + 1 distinct
replicas).

Non-Divergence. Let 𝑣 ′ be the first view in which a proposal
𝑚′ = Propose(⟨𝜏 ′⟩𝛾 ′, 𝑣 ′, 𝜌) was executed by nf − f non-faulty repli-
cas. By Theorem 4.10(1), 𝑣 ′ ≤ 𝑣. Hence, by Theorem 4.10(3), we
must have ⟨𝜏 ′⟩𝛾 ′ = ⟨𝜏⟩𝛾 .

Non-Triviality (in periods of reliable communication). We say
that a decision needs to be made for request ⟨𝜏⟩𝛾 of client 𝛾 when-
ever 𝛾 is non-faulty. In this case, a non-faulty replica q learns that
a decision needs to be made for ⟨𝜏⟩𝛾 whenever it receives ⟨𝜏⟩𝛾 . As
non-faulty clients will repeatedly send ⟨𝜏⟩𝛾 to all replicas whenever
they do not receive a proof-of-execution for 𝜏, every non-faulty
replica will receive ⟨𝜏⟩𝛾 when communication becomes reliable.
Assume that communication becomes reliable in view 𝑣. Either the
primary of view 𝑣 will propose ⟨𝜏⟩𝛾 , or all non-faulty replicas will
trigger view changes until reaching a view whose primary will
propose ⟨𝜏⟩𝛾 . As there are at-most f faulty replicas, at-most f such
□
view changes will happen before ⟨𝜏⟩𝛾 is proposed.

Remark 4.19. PoE is designed to be able to deal with many types
of failures, e.g., Byzantine failures, network failures, and crashes.
First, as proven in Theorem 4.18, PoE provides both consensus and
client services if at-most f concurrent replicas fail (e.g., Byzantine
replicas or crashed replicas), n > 3f. Second, as a consequence of
Theorem 4.1(1) and Theorem 4.10, PoE will always provide non-
divergence if at-most f replicas are Byzantine. Third, PoE can recover
form any number of non-Byzantine replica crashes as long as these
crashes are recoverable: if replicas store any certificates they produce
in permanent store (Line 16 of Figure 3 and Line 16 of Figure 6) such
that they can always recover these certificates after a crash, then
non-Byzantine crashes can only lead to service disruption (similar
to network failure), and service will be recovered when sufficient
replicas have recovered.

4.6 PoE Provides Client Service
Theorem 4.18 proves that PoE provides weak consensus. Hence, due
to the non-triviality guarantee of PoE (as proven in Theorem 4.18),
every client can force a consensus decision on their requests. Hence,
to provide client services, we only need to show that PoE guarantees

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

that a consensus decision for request ⟨𝜏⟩𝛾 will lead to a proof-of-
execution for 𝜏. If communication is reliable and no view changes
happen, then either Theorem 4.1(2) or Theorem 4.4(2) guarantees
such proof-of-execution. Due to the speculative design of PoE, view
changes can result in consensus decisions without an accompanying
proof-of-execution:

Example 4.20. Consider a system with n = 3f + 1 replicas. We
partition the non-faulty replicas in sets 𝐴, 𝐵, and 𝐶 with |𝐴| = |𝐵| =
f and |𝐶 | = 1. Now let ⟨𝜏⟩𝛾 be a client request and consider the
following sequence of events in round 𝜌 of views 𝑣, 𝑣 + 1, and 𝑣 + 2.

View 𝑣. Due to unreliable communication the f replicas in 𝐵
become unreachable while the primary p𝑣 of view 𝑣 proposes
𝑚𝑣 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌). Hence, only the nf replicas in 𝐴 ∪ 𝐶 ∪ F
receive 𝑚𝑣 and exchange Prepare messages. Consequently, the
nf − f non-faulty replicas in 𝐴 ∪ 𝐶 are able to execute 𝜏 and in-
form the client 𝛾. The faulty replicas in F decide to not inform the
client. Hence, the client 𝛾 only receives f + 1 messages of the form
Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ), which is insufficient for a proof-of-execution.
Next, the replicas in 𝐴 ∪ 𝐶 exchange CheckCommit messages,
while the faulty replicas only send CheckCommit messages to 𝐴.
Consequently, the replicas in 𝐴 are able to construct commit cer-
tificates C(𝑚𝑣), while the replicas in 𝐶 are unable to do so. When
communication becomes reliable, the f + 1 non-faulty replicas in
𝐵 ∪ 𝐶 will be able to successfully trigger a view change.

View 𝑣 + 1. Due to unreliable communication, the f non-faulty
replicas in 𝐴 become unreachable. Hence, the primary p𝑣+1 of view
𝑣 + 1 ends up proposing a new view based on the information
provided by the replicas in 𝐵 ∪ 𝐶 ∪ F . In specific, the non-faulty
replicas in 𝐵 only provide information on rounds before 𝜌, the non-
faulty replica in 𝐶 provides a prepared certificate for 𝑚𝑣, and the
faulty replicas in F lie and only provide information on rounds
before 𝜌. Hence, any replica that enters view 𝑣 + 1 will rollback
transaction 𝜏 and will expect the primary p𝑣+1 to propose 𝑚𝑣+1 =
Propose(⟨𝜏⟩𝛾 , 𝑣 + 1, 𝜌).

After primary p𝑣+1 proposes 𝑚𝑣+1, the nf replicas in 𝐵 ∪ 𝐶 ∪ F
receive 𝑚𝑣+1 and exchange Prepare messages. Consequently, the
nf − f non-faulty replicas in 𝐵 ∪ 𝐶 are able to execute 𝜏 and inform
the client 𝛾. The faulty replicas in F once again decide to not inform
the client. Hence, at this point, the client received f + 1 messages
of the form Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ) and f + 1 messages of the form
Inform(⟨𝜏⟩𝛾 , 𝑣 + 1, 𝜌, 𝑟 ), which is still insufficient for a proof-of-
execution.

Next, the replicas in 𝐵 ∪ 𝐶 exchange CheckCommit messages,
while the faulty replicas only send CheckCommit messages to 𝐵.
Consequently, the replicas in 𝐵 are able to construct commit certifi-
cates C(𝑚𝑣+1), while the replicas in 𝐶 are unable to do so. When
communication becomes reliable, the f + 1 non-faulty replicas in
𝐴 ∪ 𝐶 will be able to successfully trigger a view change.

View 𝑣 + 2. The (faulty) primary p𝑣+2 of view 𝑣 + 2 will receive
commit certificates C(𝑚𝑣) from the replicas in 𝐴, commit certifi-
cates C(𝑚𝑣+1) from the replicas in 𝐵, a prepared certificate for 𝑚𝑣+1
from 𝐶, and, again, the faulty replicas in F lie and only provide in-
formation on rounds before 𝜌. Using this information, the primary
p𝑣+2 decides to construct two distinct new-view proposals 𝑛𝐴 and

On the Correctness of Speculative Consensus

𝑛𝐵 that are based on the information provided by the nf replicas in
𝐴 ∪ 𝐶 ∪ F and 𝐵 ∪ 𝐶 ∪ F , respectively.

The replicas in 𝐴 receive 𝑛𝐴, the replicas in 𝐵 receive 𝑛𝐵, and
replica 𝐶 also receives 𝑛𝐵 (due to which 𝐶 only has to store an
additional commit certificate). Hence, after the view-change, at-
most f + 1 non-faulty replicas hold identical commit certificates
for round 𝜌, while all non-faulty replicas hold a commit certificate
for a proposal proposing ⟨𝜏⟩𝛾 in round 𝜌 and no non-faulty replica
will send additional Inform messages for the request ⟨𝜏⟩𝛾 to client
𝛾. As such, the client 𝛾 fails to obtain a proof-of-execution for a
fully-decided request.

As the final step in this example, the (faulty) primary p𝑣+2 suc-
cessfully proposes 𝑚 = Propose(⟨𝜏 ′⟩𝛾 ′, 𝑣 + 2, 𝜌 + 1). Due to this
proposal, all non-faulty replicas end up with commit certificates
C(𝑚), thereby assuring that future view changes will omit any in-
formation on round 𝜌 and, thus, assuring that no proof-of-execution
will be produced in future views.

To deal with the issue raised in Example 4.20, we utilize a recov-
ery protocol by which clients can obtain a proof-of-commit that
implies a proof-of-execution. This recovery protocol is based on a
straightforward observation: if a client 𝛾 can observe that a non-
faulty replica committed a proposal Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) for request
⟨𝜏⟩𝛾 , then, by Theorem 4.18, this observation provides proof that
all non-faulty replicas will eventually execute ⟨𝜏⟩𝛾 in round 𝜌.

Note that as part of providing non-triviality, a client 𝛾 that re-
quires execution for a request ⟨𝜏⟩𝛾 will eventually send ⟨𝜏⟩𝛾 to all
replicas, this to enforce an eventual consensus decision. When a
non-faulty replica r receives ⟨𝜏⟩𝛾 after the replica stored a commit
certificate for a proposal proposing ⟨𝜏⟩𝛾 , then, as the first step of the
proof-of-commit recovery protocol, replica r responds with a mes-
sage InformCC(⟨𝜏⟩𝛾 , 𝜌, 𝑟 ), in which 𝑟 was the original execution
result r obtained while executing 𝜏 in round 𝜌. As the second step
of the proof-of-commit recovery protocol, client 𝛾 will considers 𝜏
executed after it receives a proof-of-commit for ⟨𝜏⟩𝛾 consisting of
identical InformCC(⟨𝜏⟩𝛾 , 𝜌, 𝑟 ) messages from f + 1 distinct replicas.
The pseudo-code for the proof-of-commit recovery protocol can be
found in Figure 11.4

Using the proof-of-commit recovery protocol, we can finally

prove that PoE provides client services:

Theorem 4.21. If PoE is operated in a system with n > 3f, then

PoE provides client service whenever communication is reliable.

Proof. When communication is reliable and client 𝛾 requests
⟨𝜏⟩𝛾 , then, by Theorem 4.18, client 𝛾 can force execution of ⟨𝜏⟩𝛾 .
If client 𝛾 receives a (𝑣, 𝜌)-proof-of-execution for 𝜏, then client 𝛾
considers 𝜏 executed and, due to Theorem 4.10, the executed state
observed by the client will be preserved.

Next, we consider the case in which client 𝛾 does not receive
a proof-of-execution for 𝜏. Due to Theorem 4.18, all non-faulty
replicas will eventually commit a proposal for ⟨𝜏⟩𝛾 in some round
𝜌. By Theorem 4.4(3) and Corollary 4.11, all non-faulty replicas
executed the same sequence of 𝜌 − 1 transactions before executing

4Non-faulty replicas in PoE can opt to always send an InformCC message to clients
after they commit a proposal: InformCC messages carry the same information to the
client as normal client replies do in consensus protocols such as Pbft. Such a design
will trade an increase of network bandwidth for a decrease of latencies when replicas
are left in the dark.

Client recovery role (used by client 𝛾 to force transaction 𝜏) :

1: Send ⟨𝜏 ⟩𝛾 to all replicas r ∈ ℜ.
2: Await a 𝜌-proof-of-commit for ⟨𝜏 ⟩𝛾 consisting of identical messages

InformCC( ⟨𝜏 ⟩𝛾 , 𝜌, 𝑟 ) from f + 1 distinct replicas.

3: Considers 𝜏 executed, with result 𝑟 , as the 𝜌-th transaction.

Replica recovery role (running at every replica r ∈ ℜ) :

4: event r receives ⟨𝜏 ⟩𝛾 do
5:

if r stored commit certificate P(𝑚) for some proposal

𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌) then

6:

7:

Let 𝑟 be the result r obtained while executing 𝜏 in round 𝜌.
Send InformCC( ⟨𝜏 ⟩𝛾 , 𝜌, 𝑟 ) to 𝛾 .

end if

8:
9: end event

Figure 11: The proof-of-commit recovery protocol in PoE.

𝜏. Hence, if client 𝛾 resends ⟨𝜏⟩𝛾 to the non-faulty replicas, then
these non-faulty replicas will eventually all be able to send identical
messages InformCC(⟨𝜏⟩𝛾 , 𝜌, 𝑟 ) to the client (Line 7 of Figure 11).
Consequently, the client 𝛾 will receive at-least nf > f such messages
and client 𝛾 will consider 𝜏 executed (Line 3 of Figure 11). Due
to Theorem 4.10, the executed state observed by the client will
be preserved. Finally, as there are at-most f faulty replicas, the
faulty replicas can produce at-most InformCC(⟨𝜏⟩𝛾 , 𝜌 ′, 𝑟 ′) messages
distinct form InformCC(⟨𝜏⟩𝛾 , 𝜌, 𝑟 ) and, hence, cannot produce an
□
invalid proof-of-commit.

Remark 4.22. PoE does not enforce that client requests are pro-
posed in order: if a client 𝛾 first sends ⟨𝜏1⟩𝛾 to the current primary
p and then sends ⟨𝜏2⟩𝛾 , then nothing prevents p of first proposing
⟨𝜏2⟩𝛾 in round 𝜌2 and then proposing ⟨𝜏1⟩𝛾 in round 𝜌1 (𝜌2 < 𝜌1).
If a client requires ordered execution, then it can simply request 𝜏2
only after it receives a proof-of-execution of 𝜏1. If the application
that utilizes PoE requires ordered execution of all client requests,
then one can require that valid client requests come with a baked-
in counter indicating its order and that subsequent proposals use
subsequent counter values.

5 ON THE COMPLEXITY OF POE
In Section 4 we provided an in-detail description and proof of
correctness of the Proof-of-Execution consensus protocol (PoE).
Next, we will take a deep dive into the exact message complexity
of this protocol. Furthermore, as we kept the presentation of PoE
described in Section 4 as simple as possible, we will also introduce
techniques one can employ to obtain PoE variants with a reduced
message complexity. We have summarized the complexity of PoE
and its variants in Figure 12.

5.1 The Complexity of Standard PoE
As the first step, we take a look at the complexity of the standard
variant of PoE as it is presented in Section 4. To simplify presenta-
tion, we have assumed in Section 4 that replicas send messages to
themselves whenever they broadcast messages. In practice, these
messages can be eliminated.

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

Element

Example

Size

Amount

Client request

Propose message
Prepare message
Inform message

⟨𝜏 ⟩𝛾

𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌)
Prepare(𝑚)
Inform( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌, 𝑟 )

CheckCommit message

CheckCommit(P(𝑚))

Standard PoE
(Section 5.1)

C

O (C)
O (C)
O (C + ∥𝑟 ∥)

O (nf + C)

Failure message
ViewState message
NewView message

QueryCC message
RespondCC message
InformCC message

Prepared certificate
Commit certificate

Failure(𝑣)
ViewState(𝑣, C(𝑚), E)
NewView(𝑣 + 1, V)

O (1)
O (cid:0)nf 2 + W(nf + C)(cid:1)
O (cid:0)nf (cid:0)nf 2 + W(nf + C)(cid:1)(cid:1)

QueryCC(𝜌)
RespondCC(P(𝑚), C(𝑚))
InformCC( ⟨𝜏 ⟩𝛾 , 𝜌, 𝑟 )

P(𝑚)
C(𝑚)

O (1)
O (cid:0)nf 2 + C(cid:1)
O (C + ∥𝑟 ∥)

O (nf + C)
O (cid:0)nf 2 + C(cid:1)

Using Digests Using Threshold Certificates
(Section 5.2)

(Section 5.3)

C

O (C)
O (1)
O (1 + ∥𝑟 ∥)

O (1) b

O (1)
O (Wnf) b
O (cid:0)Wnf 2(cid:1) b

O (1)
O (nf) b
O (1 + ∥𝑟 ∥)

O (nf) d
O (nf) d

C

O (C)
O (1)
O (1 + ∥𝑟 ∥)

O (1) b

O (1)
O (W) b
O (Wnf) b

O (1)
O (1) b
O (1 + ∥𝑟 ∥)

O (1) d
O (1) d

1

n − 1
n(n − 1) a
n

n(n − 1)

n(n − 1)
(n − 1)
(n − 1)

n c
n c
n c

b

a

The Prepare message of the primary can be merged into the Propose it broadcasts, reducing the amount of Prepare messages to (n − 1) 2.
The complexities noted are for versions that minimize message size at the cost of additional recovery steps for replicas to obtain missing client requests. See Remark 5.2 for details.
These messages are only required for individual recovery processes and are not used when communication is sufficiently reliable.
d
As client requests are not part of these certificates, replicas need to store a copy of the client request alongside these certificates.

c

Figure 12: The message complexity (of messages exchanged) and storage complexity (of certificates stored) in the standard
variants of PoE. We assume that client requests have a size bounded by C, that the primary can propose at-most W requests
out-of-order after the last commit certificate (the window size), and that the execution result 𝑟 has size ∥𝑟 ∥.

In the normal case protocol of Figure 3, the primary broadcasts
n − 1 messages 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) whose size is directly de-
termined by the size C = ∥⟨𝜏⟩𝛾 ∥ of the proposed client request ⟨𝜏⟩𝛾 .
Next, all n replicas broadcast messages Prepare(𝑚) to all other
(n−1) replicas, resulting in n(n−1) messages of size O (C). Finally,
all n replicas respond to the client via messages Inform(⟨𝜏⟩𝛾 , 𝑣, 𝜌, 𝑟 ),
whose size is directly determined by the size C of a client request
and the size ∥𝑟 ∥ of the result 𝑟 .

In the check-commit protocol of Figure 6, all replicas broadcast
a message CheckCommit(P(𝑚)), in which P(𝑚) is a prepared cer-
tificate for proposal 𝑚. This prepared certificate P(𝑚) consists of
nf messages Prepare(𝑚) signed by nf distinct replicas. As these
nf messages are identical, only a single copy needs to be included
(with size O (C)) together with nf signatures that have a constant
size each.5

In the view-change protocol of Figure 8, all at-most n replicas that
detect failure of view 𝑣 broadcast a message Failure(𝑣) of constant
size to all other (n − 1) replicas. All at-most n replicas that enter the
new-view proposal stage in view 𝑣 will send a single message of the
form ViewState(𝑣, C(𝑚), E), with C(𝑚) a commit certificate and E
a set of prepared certificates, to the new primary. The commit cer-
tificate C(𝑚) consists of nf messages Commit(P(𝑚)𝑖 ), 1 ≤ 𝑖 ≤ nf,
signed by nf distinct replicas. As each replica can construct a pre-
pared certificate P(𝑚)𝑖 distinct from all other prepared certificates
and the signature on Commit(P(𝑚)𝑖 ) can only be verified when the
message Commit(P(𝑚)𝑖 ) is known, a commit certificate needs to

5To simplify presentation in Section 4, the CheckCommit messages carry prepared
certificates. Without affecting the correctness of PoE or the complexity of recovery,
these prepared certificates can be eliminated in favor of constant-sized CheckCommit
messages. We refer to Section 5.2 and Section 5.5 for further details.

store the nf individual prepared certificates: one can only elimi-
nate nf − 1 redundant copies of the original proposal 𝑚. Hence,
each commit certificate consists of a proposal 𝑚, nf 2 signatures
of prepare message Prepare(𝑚), and nf signatures of messages
Commit(P(𝑚)𝑖 ), 1 ≤ 𝑖 ≤ nf. By Assumption 4.6, the number of
prepared certificates in E is upper bounded by some window size
W. Finally, the new primary will broadcast a single message of the
form NewView(𝑣 + 1, V), with V a set of nf ViewState messages, to
all (n − 1) other replicas.

Finally, in the query protocol of Figure 10, each replica that
needs to recover the status of round 𝜌 after a period of unreliable
communication will broadcast constant-sized messages of the form
QueryCC(𝜌) and get responses RespondCC(P(𝑚), C(𝑚)) with P(𝑚)
a prepared certificate and C(𝑚) a commit certificate. In the proof-
of-commit recovery protocol of Figure 11, each replica will send
a message InformCC(⟨𝜏⟩𝛾 , 𝜌, 𝑟 ) whose size is determined by C to
clients that are recovering from unreliable communication.

5.2 Reducing Message Sizes with Digests

A close look at PoE shows that in the original design of PoE, full
copies of Propose messages are included in Prepare, CheckCommit,
ViewState, and NewView messages. Furthermore, full copies of the
client request are included in Inform and InformCC messages.

When client requests are large, this will incur a substantial com-
munication cost. The typical way to support large client requests
is by replacing client requests ⟨𝜏⟩𝛾 by a constant-sized message di-
gest digest(⟨𝜏⟩𝛾 ) obtained from ⟨𝜏⟩𝛾 using a strong cryptographic
hash function digest(·) [22]. To do so, one simply replaces the

On the Correctness of Speculative Consensus

message Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌) the primary broadcasts when propos-
ing transaction 𝜏, requested by client 𝛾, as the 𝜌-th transaction in
some view 𝑣 by the pair (𝑚𝑑 = Propose(𝑑, 𝑣, 𝜌), ⟨𝜏⟩𝛾 ) such that
𝑑 = digest(⟨𝜏⟩𝛾 ). All other messages will use the constant-sized
proposal 𝑚𝑑 , which only includes the constant-sized digest 𝑑, in
all messages that contain a Propose message. Furthermore, also
the client request ⟨𝜏⟩𝛾 in Inform and InformCC messages can be
replaced by the constant-sized digest 𝑑.

Receipt of a message CheckCommit(P(𝑚𝑑 )) is no longer suffi-
cient to prepare and execute client request ⟨𝜏⟩𝛾 (Line 11 of Figure 6):
after receiving message CheckCommit(P(𝑚𝑑 )), one only has a di-
gest 𝑑 = digest(⟨𝜏⟩𝛾 ) of client request ⟨𝜏⟩𝛾 , but not the client
request itself. Fortunately, the existence of prepared certificate
P(𝑚𝑑 ) guarantees that at-least nf − f non-faulty replicas have sent
Prepare(𝑚𝑑 ) and, hence, have received a pair (𝑚𝑑, ⟨𝜏⟩𝛾 ). Hence,
after a replica q receives prepared certificate P(𝑚𝑑 ), it can query
the replicas whose signed prepared certificates are in P(𝑚𝑑 ) for the
missing client request. As q can derive the digest 𝑑 from P(𝑚𝑑 ),
it can verify whether any request ⟨𝜏 ′⟩𝛾 ′ it received in response to
its query is valid by verifying whether 𝑑 = digest(⟨𝜏 ′⟩𝛾 ′) (under
normal cryptographic assumptions). Similar strategies can be made
to recover missing client requests due to NewView messages. As
such, the usage of digests to eliminate copies of client requests
trades a reduction of message complexity with a more-complex
recovery path.

Remark 5.1. Although digests reduce the impact of very large
client requests on throughput, they do not eliminate the need for a
limit on the size of client requests as specified in Assumption 4.6: if
the size of client requests is not limited, then non-faulty replicas
cannot expect a timely response of any forwarded client requests,
as the primary could always be busy with sending an arbitrarily
large proposal.

The second source of large messages in PoE are CheckCommit
messages, which impacts the size of commit certificates and of
ViewState, NewView, and RespondCC messages. To further reduce
the size of CheckCommit messages, one can replace messages of
the form CheckCommit(P(𝑚)), with P(𝑚) a prepared certificate for
proposal 𝑚, by messages of the form CheckCommit(𝑚𝑑 ) (where 𝑚𝑑
is the proposal obtained from 𝑚 when the client request is repre-
sented by a digest). Doing so will reduce the size of a CheckCommit
message from O (nf + C) to O (1). Due to this change, all commit
certificates C(𝑚𝑑 ) will consists of nf messages CheckCommit(𝑚𝑑 )
signed by nf distinct replicas. As these nf messages are identical,
only a single copy needs to be included in C(𝑚𝑑 ) (with size O (1))
together with nf signatures that have a constant size each, thereby
reducing the size of commit certificates from O (nf 2 + C) to O (nf).
Eliminating prepared certificates from CheckCommit messages,
by replacing messages of the form CheckCommit(P(𝑚)) by mes-
sages of the form CheckCommit(𝑚𝑑 ), does impact the recovery
mechanism of Line 8 of Figure 6 by which replicas can prepare and
execute proposals: a single message CheckCommit(𝑚𝑑 ) not only
lacks a client request, it also lacks a prepared certificate that pro-
vides the necessary information to obtain ⟨𝜏⟩𝛾 , to prepare 𝑚𝑑 , and
to execute ⟨𝜏⟩𝛾 . To deal with this lack of information, a replica q
that wants to use the recovery mechanism of Line 8 of Figure 6 has
to wait for identical CheckCommit(𝑚𝑑 ) messages signed by f + 1

distinct replicas, after which q has a guarantee that at-leas one
of these signing replicas is non-faulty and can be queried for the
necessary prepared certificate P(𝑚𝑑 ) and client request ⟨𝜏⟩𝛾 . (For
completeness, we note that this change in the number of required
CheckCommit messages necessary to recover prepared certificates
does not invalidate the core properties of the check-commit pro-
tocol proven in Theorem 4.4). As such, also this simplification of
CheckCommit messages trades a reduction of message complexity
with a more-complex recovery path.

Remark 5.2. One can strike other balances between message com-
plexity and the complexity of the recovery path than the approach
outlined above. E.g., we can retain most message size benefits, while
keeping the recovery path simple with a slightly different approach.
In specific,

(1) To fully retain the recovery path of Line 11 of Figure 6,
while also reducing the size of commit certificates to O (nf),
one can replace messages of the form CheckCommit(P(𝑚))
by triples of the form (CheckCommit(𝑚𝑑 ), P(𝑚𝑑 ), ⟨𝜏⟩𝛾 ), in
which the signed constant-sized message CheckCommit(𝑚𝑑 )
is used in the construction of commit certificates of size
O (nf), while the prepared certificate P(𝑚𝑑 ) and the client
request ⟨𝜏⟩𝛾 can be used for the recovery path of Line 11 of
Figure 6.

(2) To assure that the new primary has access to all necessary
client requests, while also reducing the size of ViewState
and, consequently, NewView messages, one can replace mes-
sages of the form ViewState(𝑣, C(𝑚), E) by pairs of the form
(ViewState(𝑣, C(𝑚𝑑 ), E𝑑 ), 𝑆) in which 𝑆 is the set of client
requests proposed by 𝑚𝑑 and by the proposals 𝑚′
𝑑 with
P(𝑚′

𝑑 ) ∈ E.

(3) To assure that replicas have knowledge of all client requests
necessary to start a new view, while also reducing the size
of NewView mesages, the new primary can replace mes-
sages of the form NewView(𝑣 + 1, V) by pairs of the form
(NewView(𝑣 + 1, V𝑑 ), ⟨𝜏⟩𝛾 ), with 𝑛𝑑 = NewView(𝑣 + 1, V𝑑 )
and L𝑛𝑑 [LC(𝑛𝑑 )] = ⟨𝜏⟩𝛾 the client request proposed by any
commit certificate included in V in the last round LC(𝑛𝑑 )
for which V includes commit certificates. We note that the
NewView message 𝑛𝑑 only requires this single client request
to convey sufficient information: all client requests for rounds
𝜌, LC(𝑛𝑑 ) < 𝜌 ≤ LP(𝑛𝑑 ) need to be re-proposed by the new
primary, while all replicas can validate whether the new pri-
mary proposed the right requests via the digests available in
𝑛𝑑 .

5.3 Threshold Signatures for Certificates

A further look at the usage of certificates in PoE shows that the pre-
pared and commit certificates, which are used in several messages,
will grow large in deployments with many replicas and will cause
high storage costs and communication costs in such deployments.
E.g., consider the prepared and commit certificates for a Propose
message 𝑚 = Propose(⟨𝜏⟩𝛾 , 𝑣, 𝜌). Even when using digests, both
P(𝑚) and C(𝑚) will consists of a set of nf distinct (constant-sized)
signatures. Hence, these certificates have a size that is linear with
respect to the number of (non-faulty) replicas.

To further reduce the size of certificates, one can employ thresh-

old signatures [5, 31].

Definition 5.3. A 𝑥 : 𝑦 threshold signature scheme is a digital
signature scheme for a set 𝑋 of |𝑋 | = 𝑥 participants in which any
set 𝑌 ⊆ 𝑋 of |𝑌 | = 𝑦 participants can cooperate to produce a
certificate for any given value 𝑣. To do so, each participant in 𝑌
produces their signature share for 𝑣. Using only valid signature
shares for 𝑣 produced by at-least 𝑦 distinct participants, anyone can
produce a valid certificate for 𝑣.

In specific, each participant 𝑝 ∈ 𝑋 will receive a distinct private
key 𝑘 (𝑝) that 𝑝 can use to sign any value 𝑣, resulting in a signature
share ⟨|𝑣 |⟩𝑝 . As with traditional public-key cryptography, the signa-
ture share of 𝑝 can only be produced using 𝑘 (𝑝) and anyone can
verify the authenticity of signature share ⟨|𝑣 |⟩𝑝 using the public key
associated with 𝑘 (𝑝). Given a set of signature shares {𝑘 (𝑝) | 𝑝 ∈ 𝑌 },
one can produce a single constant-sized threshold signature that
certifies that value 𝑣 was signed by at-least 𝑦 distinct participants
from the set 𝑋 of participants in the threshold signature scheme.

In the setting of PoE, one can use a n : nf threshold signature
scheme in which each replica is a participant. Next, instead of
using normal digital signatures to sign a message 𝑚′, each replica
r uses their private key 𝑝 (r) to produce signature shares ⟨|𝑚|⟩r for
𝑚′. These signature shares can be used to provide authenticated
communication. If a replica receives nf signature shares for a given
Prepare message for proposal 𝑚, then one can use these signature
shares to produce a prepared certificate for 𝑚 of constant size.
Likewise, one can use nf signature shares for a given CheckCommit
message to produce a commit certificate of constant size.

5.4 A Linear Proof-of-Execution

Although using digests (Section 5.2) or threshold certificates (Sec-
tion 5.3) drastically reduces the size of individual messages, they
do not change the amount of messages being sent: all replicas will
broadcast Prepare and CheckCommit messages in the normal case,
a quadratic amount. Next, we show how to further apply threshold
signatures to assure that each phase of communication only uses
a linear amount of messages. We note that such applications of
threshold signatures are common among modern variants of Pbft
such as Sbft [13], LinBFT [39], and HotStuff [40]. Hence, we shall
mainly focus on the novel design necessary to make all normal-
case communication of PoE linear, this including the decentralized
check-commit protocol. Next, we detail the design of Linear-PoE.
The normal-case of PoE consists of two phases of quadratic com-
munication: in the first phase, Prepare messages are exchanged,
while in the second phase CheckCommit messages are exchanged.
These two phases are rather different in their design: the prepare
phase (the first phase) follows the traditional primary-backup design
of Pbft and only has to succeed when the primary is non-faulty,
whereas the check-commit phase (the second phase) is fully de-
centralized in the sense that it should succeed independent of any
non-faulty behavior in all rounds that do not lead to primary failure.
To make the prepare phase linear, we can apply the well-known
transformation from all-to-all communication to all-to-one-to-all
communication using threshold signatures (e.g., [13, 16, 39, 40]).
To do so, we replace the prepare phase by two subphases. In spe-
cific, upon arrival of the first proposal for round 𝜌 of view 𝑣 via

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

p
r1
r2
r3

Propose

Support

Certify

Execute 𝜏

Figure 13: A schematic representation of the linear normal-
case protocol of PoE: the primary p proposes transaction 𝜏 to
all replicas via a Propose message 𝑚. Next, all other replicas
respond with Support message holding a signature share for
a message of the form Prepare(𝑚). The primary combines nf
of these signature shares to construct a constant-sized pre-
pared certificate P(𝑚) holding a constant-sized threshold sig-
nature. Finally, the primary sends the prepared certificate
P(𝑚) to all replicas via a Certify message, after which repli-
cas can execute 𝜏. In this example, replica r3 is faulty and
does not participate.

some Propose message pair (𝑚𝑑 = Propose(𝑑, 𝑣, 𝜌), ⟨𝜏⟩𝛾 ), with
𝑑 = digest(⟨𝜏⟩𝛾 ), each (non-faulty) replica r that received this
pair will enter the prepare phase for 𝑚𝑑 . As the first subphase of
the prepare phase, r supports the proposal 𝑚𝑑 by sending a re-
ply message Support(⟨|Prepare(𝑚𝑑 )|⟩r) to the primary. As the
last subphase, the primary collects well-formed messages of the
form Support(⟨|Prepare(𝑚𝑑 )|⟩q), q ∈ 𝑆, 𝑆 ⊂ ℜ, from a set of
nf = |𝑆 | replicas. Next, the primary uses the provided signature
shares to produce a constant-sized prepared certificate P(𝑚𝑑 ). Fi-
nally, the primary broadcasts P(𝑚𝑑 ) to all replicas via a message
Certify(P(𝑚𝑑 )). After replicas receive Certify(P(𝑚𝑑 )), they use
the prepared certificate P(𝑚𝑑 ) included in Certify(P(𝑚𝑑 )) to pre-
pare 𝑚 and execute 𝜏 using Lines 16–18 of Figure 3. We note that
the linear version of the prepare phase relies on a single replica, the
primary, to aggregate Support messages into a prepared certificate.
Primaries will only fail to do so if they are faulty or communication
is unreliable. Hence, the normal view-change protocol can deal with
failures of this linear version of the prepare phase. An illustration
of the working of this linear version of the normal-case protocol
can be found in Figure 13.

Next, we look at the check-commit phase. We reiterate that the
check-commit phase operates rather differently than the prepare
phase (and than the commit phases in most Pbft-style primary-
backup consensus protocols). Indeed, the decentralized design of the
check-commit protocol of Figure 6 is crucial for its correctness: the
check-commit protocol of Figure 6 guarantees that any replicas that
are left in the dark by the primary (without the primary disrupting
the progress of the normal-case protocol) will be able to recover any
missing proposals via the check-commit protocol (this independent
of the behavior of any faulty replicas).

Consequently, we cannot simply make the check-commit proto-
col linear by assigning a fixed replica q that aggregates signature
shares of the form ⟨|Commit(𝑚𝑑 )|⟩r into commit certificates C(𝑚𝑑 ):
replica q can be faulty and will have the power to keep individual
replicas in the dark, thereby breaking a main correctness guarantee
of the check-commit protocol.

On the Correctness of Speculative Consensus

To make the ckeck-commit protocol linear, we employ three

Check-commit role (running at every replica r ∈ ℜ) :

techniques:

aggregator rotation. In round 𝜌, the replica q with id(q) =
𝜌 mod n will be the aggregator that receives signature shares.
Hence, every round has a different aggregator, assuring that
nf out of n consecutive rounds have a non-faulty aggregator
(when communication is reliable) and can succeed even with
interference of other replicas.

aggregated multi-round check-commits. As the previous
rounds can have faulty aggregators, due to which these
rounds did not properly finish their check-commit steps,
the aggregator q of round 𝜌 will perform a multi-round
check-commit for round 𝜌 and the preceding n − 1 rounds
(hence, a multi-round check-commit for all rounds since the
previous round for which q was the aggregator). In this
way, the correct behavior of q can guarantee that it can
always perform a successful check-commit when it is the
aggregator. To assure that the aggregated check-commit
messages for round 𝜌 can have a constant size, we do not
check-commit on an individual Propose message, but on
the digest digest(P(𝑚𝑑,1), . . . , P(𝑚𝑑,n)) of n propose cer-
tificates, one for each Propose message of the last n rounds.
(For simplicity, we assume that all replicas have agreed on
default propose certificates and proposals for any rounds
before the first round).

recovery certificates. The aggregator q of round 𝜌 is only
guaranteed to be able to construct a commit certificate for
digest(P(𝑚𝑑,1), . . . , P(𝑚𝑑,n)) if all non-faulty replicas have
a prepared certificates for the last n rounds. A core functional-
ity of the check-commit protocol is to provide such prepared
certificates to non-faulty replicas that are missing them (if
at-least f + 1 non-faulty replicas obtained such prepared cer-
tificates, as otherwise the view-change protocol will take
care of recovery). To be able to provide such recovery, the
linear check-commit protocol will employ a recovery step
that uses a n : f + 1 threshold signature scheme to produce
recovery certificates that can be used by non-faulty replicas
to reliably obtain any missing prepared certificates. This
n : f + 1 threshold signature scheme is distinct from the
normal n : nf threshold signature scheme we use to gener-
ate prepared and commit certificates and we write ⟨|𝑣 |⟩′
r to
denote a signature share produced by r using this n : f + 1
threshold signature scheme.

The pseudo-code for this linear check-commit protocol can be
found in Figure 14 and an illustration of the working of this linear
version of the check-commit protocol can be found in Figure 15.

Remark 5.4. We note that the failure detection stage still ex-
changes a quadratic number of Failure messages. As shown in
Lemma 4.5, PoE depends on these all-to-all messages to synchro-
nize replicas after periods of unreliable communication. We do not
believe we can fully eliminate such quadratic communication when
operating in an asynchronous environment in which communica-
tion has unreliable periods in which messages are arbitrary delayed
or lost without making additional assumptions (e.g., by assuming
reliable or synchronous communication, or by assuming external
services to detect and deal with failures).

1: event r prepared 𝑚 = Propose( ⟨𝜏 ⟩𝛾 , 𝑣, 𝜌) and executed 𝜏 do
2: Wait until all rounds up-to round 𝜌 − n have a commit certificate.
3:

if 𝑣 is the current view then

4:

5:

Let 𝐷 = digest(P(𝑚𝑑,1), . . . , P(𝑚𝑑,n)) be the digest for the
prepared certificates stored in the last n rounds (the rounds 𝜌 −
(n − 1), . . . , 𝜌).
Send SupportCC(𝜌, 𝐷, ⟨|𝐷 |⟩r, ⟨|𝐷 |⟩′
𝜌 (replica q with id(q) = 𝜌 mod n). .

r) to the aggregator q of round

end if

6:
7: end event
8: event r with id(r) = 𝜌 mod n receives f + 1 well-formed messages

𝑚𝑖 = SupportCC(𝜌, 𝐷, ⟨|𝐷 |⟩r𝑖 , ⟨|𝐷 |⟩′
f + 1 distinct replicas do

r𝑖 ), 1 ≤ 𝑖 ≤ f + 1, from

9:

Broadcast RecoveryCC(𝜌, 𝐷, R(𝐷)) to all replicas, in which R(𝐷) is
the recovery certificate constructed using the signature shares ⟨|𝐷 |⟩′
r𝑖 ,
1 ≤ 𝑖 ≤ f + 1.

10: end event
11: event r receives a message 𝑚𝑟 = RecoveryCC(𝜌, 𝐷, R(𝐷)) from

12:

13:

aggregator q of round 𝜌 (q with id(q) = 𝜌 mod n) do
if r cannot construct 𝐷 with its local prepared certificates then

Query q for the missing prepared certificates. If q does not have
these, then q can query the f + 1 distinct replicas (of which at-least
one is non-faulty) from which q received the SupportCC messages
used to construct 𝑚𝑟 for the prepared certificates they used to
construct 𝐷.

end if

14:
15: end event
16: event r with id(r) = 𝜌 mod n receives nf well-formed messages

𝑚𝑖 = SupportCC(𝜌, 𝐷, ⟨|𝐷 |⟩r𝑖 , ⟨|𝐷 |⟩′
nf distinct replicas do

r𝑖 ), 1 ≤ 𝑖 ≤ nf, from

17:

Broadcast CertifyCC(𝜌, 𝐷, C(𝜌)) to all replicas, in which C(𝜌) is
the commit certificate constructed using the signature shares ⟨|𝐷 |⟩r𝑖 ,
1 ≤ 𝑖 ≤ nf.

18: end event
19: event r receives a message 𝑚𝑐 = CertifyCC(𝜌, 𝐷, C(𝜌)) from

aggregator q of round 𝜌 (q with id(q) = 𝜌 mod n) do
20: Wait until all rounds up-to round 𝜌 − n have a commit certificate.
Store commit certificate C(𝜌) for round 𝜌, which can also be used as
21:
a commit certificate for the n − 1 rounds preceding round 𝜌.

22: end event

Figure 14: The linear check-commit protocol in PoE.

We complete our treatment of Linear-PoE with a caution that
applies to all consensus protocols that use threshold signatures.
First, the usage of threshold signatures will increase the latency
between receiving client requests and executing client request. In
PoE, this increase stems from the increase from two communica-
tion rounds to three communication rounds. Furthermore, even
though the usage of threshold signatures does sharply reduces the
overall communication complexity of consensus (the total number
of messages sent between all replicas), this overall reduction does
not imply a significant reduction of the communication complexity
at the level of individual replicas, however, as illustrated next:

Example 5.5. Consider a deployment of PoE with n = 31 repli-
cas. We assume that Propose messages are larger than all other
messages, which is typically the case due to the usage of digests
(Section 5.2). Consequently, the primary, whom broadcasts Propose

p
r1
r2
r3

SupportCC

RecoveryCC

SupportCC

CertifyCC

Commit

Figure 15: A schematic representation of the linear check-
commit protocol of PoE: in round 𝜌 = 6, all replicas send a
SupportCC message holding a signature share for the digest
𝐷 of the last n proposals to the aggregator of round 𝜌 (replica
q with id(q) = 𝜌 mod n). In this case, all replicas send to
replica r2. The aggregator q uses the first f + 1 of these mes-
sages to construct a recovery certificate, which can be used
for replicas in the dark to recover missing rounds. Next, the
aggregator q uses nf of these messages to construct a commit
certificate C(𝜌) for rounds 𝜌 − (n − 1), . . . , 𝜌. Finally, the ag-
gregator q sends the commit certificate C(𝜌) to all replicas
via a CertifyCC message, after which replicas can commit
𝑚𝜌−n+1, . . . , 𝑚𝜌 . In this example, replica r3 is left in the dark
by a faulty primary and can only participate after receiving
a recovery certificate.

messages to all other replicas, has a much higher bandwidth usage
than all other replicas.

Now consider a deployment in which Propose messages with
client requests have size C = 10 KiB and in which all other mes-
sages have a size of M = 256 B. Without using threshold signatures,
the primary will send n−1 Propose messages, receive n−1 Prepare
messages, and send and receive n − 1 CheckCommit messages per
consensus decision. Hence, in this case, a single consensus decision
costs (n − 1)(C + 3M) = 322 KiB of bandwidth for the primary. If
we switch to using threshold signatures, then the primary will still
send n − 1 Propose messages, will receive n − 1 Support message,
and send n−1 Certify messages. Furthermore, once every n rounds
the primary will send and receive 3(n − 1) messages associated
with the linear check-commit protocol. Hence, in this case, a single
consensus decision still costs (n − 1)(C + 2M + 3M
n ) ≈ 315 KiB of
bandwidth for the primary, a reduction of only 2%.

Due to Example 5.5, the usage of Linear-PoE over PoE in deploy-
ments in which the bandwidth at the primary is the bottleneck for
performance will only yield a minor improvement in throughput,
this at the cost of a roughly- 1

3 -th increase in latency.

5.5 MAC-based message authentication
Up till now, we have presented the design of PoE using digital signa-
tures and threshold signatures, two powerful forms of asymmetric
cryptography that provide strong message authentication: messages
signed by some replica r using either digital signatures or threshold
signatures can be safely forwarded by replicas, while faulty replicas
are unable to forge or tamper with such signed messages. This
strong form of message authentication is used throughout the de-
sign of PoE, especially within the view-change protocol that relies
on message forwarding.

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

Unfortunately, the usage of asymmetric cryptography for mes-
sage authentication comes at a high computational cost [16, 19]. As
an alternative, one can consider using message authentication codes
(MACs) [22], which are based on symmetric cryptography, to pro-
vide message authentication with much lower costs. Unfortunately,
MACs only provide a weaker form of message authentication: MACs
can only be used to verify the sender of messages (if the sender is
non-faulty), as MACs prevent faulty replicas from impersonating
non-faulty replicas. Hence, MACs do not protect messages against
tampering when they are forwarded.

Still, it is well-known that Pbft-style consensus protocols can
be built using MACs only [7, 16, 19]. This is also the case for PoE:
when using message digests (as outlined in Section 5.2), neither
the normal-case protocol, nor the check-commit protocol, nor the
failure detection stage of the view-change protocol rely on message
forwarding, as each of these protocols only rely on counting the
number of senders of valid messages. Hence, to assure that PoE
can operate using only MACs, one only needs to redesign the new-
view proposal stage and new-view accept stage of the view-change
protocol. Such a redesign is possible in an analogous way as the
redesign of Pbft to a MAC-based version [7].

5.6 Out-of-Order Processing

All variants of PoE support out-of-order processing of consensus
decisions, which is crucial for providing high consensus through-
put in environments with high message delays such as wide-area
(Internet) deployments.

In out-of-order consensus protocols such as PoE, the primary
can freely propose requests for future rounds even if the current
consensus decision is not yet finalized (as long as those future
rounds lay in the current window determined by the window size).
By doing so, the primary can fully utilize its outgoing bandwidth
to replicate future requests, instead of waiting for other replicas to
finish their consensus steps. The following example illustrates the
impact of out-of-order processing:

Example 5.6. Consider a deployment with n = 31 replicas, with
a message delay of 𝛿 = 15 ms (e.g., replicas are distributed over
datacenters in a country), and in which all replicas have an outgoing
bandwidth of B = 1 Gbit/s. In this environment, a single PoE
consensus round takes at-least 3 consecutive messages (Propose,
Prepare, and CheckCommit) and takes at-least 3𝛿 = 45 ms. Hence,
if consensus processing is not out-of-order (sequential), then this
deployment of PoE will only have a throughput of less-than 1 s
3𝛿 ≈
22 consensus decisions per second.

As in Example 5.5, we consider a deployment in which Propose
messages with client requests have size C = 10 kB and in which all
other messages have a size of M = 256 B. As noted in Example 5.5,
the primary has the highest bandwidth usage in PoE and in this
deployment, each consensus decision will cost (n − 1)(C + 3M).
Hence, if consensus processing is out-of-order, then this deployment
(n−1) (C+3M) ≈ 3028 consensus
of PoE can have a throughput of
decisions per second, which is two orders of magnitude larger than
the sequential approach.

B

On the Correctness of Speculative Consensus

6 ANALYTICAL EVALUATION

In Section 5, we analyzed in-depth the cost of consensus using the
PoE consensus protocol and its variants. Next, we compare these
costs with the costs of existing and frequently-used consensus
protocols. A summary of our comparison can be found in Figure 1.

6.1 The Baseline of Comparison: Pbft
The Practical Byzantine Fault Tolerance consensus protocol [7] was
introduced two decades ago and to this day is a baseline for provid-
ing high-performance consensus in practical environments. Pbft is
highly resilient and can even deal with network failures: although
network failures can temporarily disrupt new consensus decisions
in Pbft, Pbft is able to automatically recover its operations once the
network becomes reliable, this without ever loosing any previously-
made consensus decisions. Furthermore, recent works have shown
that highly-optimized and fine-tuned implementations of this pro-
tocol can achieve throughputs surpassing more modern protocols
in moderately-sized deployments [16, 19].

We have already provided a high-level description of the working
of Pbft in Example 3.1. As mentioned in Section 4, PoE shares the
primary-backup design of Pbft and, as proven in Section 4.5, PoE
shares the high resilience of Pbft. The main differences between
Pbft and PoE can be summarized as follows:

(1) PoE utilizes speculative execution, due to which replicas can
execute transactions and inform clients directly after the
prepare phase, whereas Pbft only executes client requests
after their commit phase. Due to this, PoE can inform clients
within only two communication rounds, while Pbft requires
three communication rounds before it can inform clients.
(2) PoE utilizes the check-commit protocol, a decentralized single
phase protocol that servers the same roles as the commit
phase of Pbft, which requires a round of communication,
and the checkpoint protocol of Pbft, which requires another
round of communication. Due to this, the normal case of
PoE only takes three rounds of communication (of which
only two are all-to-all), whereas the normal case of Pbft
requires four rounds of communication (of which three are
all-to-all).

The view-change protocols of PoE and Pbft are comparable in com-
munication costs: the main difference between these view-change
protocols is that view-changes in PoE need to account for specula-
tive execution (e.g., perform rollbacks), but this accounting is done
while determining the state represented by new view proposals and
does not impose additional communication costs.

Due to the above analysis, we can conclude that PoE will out-
perform Pbft in all situations, as PoE lowers communication costs
in all cases (by eliminating one round of all-to-all communication),
while also potentially reducing client latencies due to speculative
execution.

6.2 Optimistic Protocols: Zyzzyva
Several consensus protocols have attempted to reduce the com-
munication cost of Pbft via optimistic consensus [4, 23, 25]. In an
optimistic consensus protocol, the normal-case consensus protocol
consists of a fast path that will succeed under optimal conditions

(no faulty behavior or unreliable communication) and a slow path
to deal with non-optimal conditions.

An example of such optimistic consensus is Zyzzyva [23]: in
Zyzzyva, all replicas execute directly after they receive a proposal
of the primary, directly inform the client, and proceed with the
next round of consensus. Hence, in Zyzzyva the optimal-case cost
of consensus are minimal: only one round of primary-to-backup
communication. We note that this fast path is not able to detect fail-
ures between replicas: Zyzzyva requires clients to inform replicas
of any failures, after which replicas can enter a slow path to deal
with these failures.

Unfortunately, consensus protocols with optimistic fast paths
such as Zyzzyva [23] and FaB [25] have over time shown vulnerabil-
ities to faulty behavior, this especially in the presence of unreliable
communication [1, 2].

We note that speculative execution, as used by PoE, and opti-
mistic execution, e.g., as used by Zyzzyva [23] and FaB [25], are not
the same: as part of the normal-case of PoE, PoE will internally de-
tect and correct any replica failures, this without any assumptions
on correct behavior by any replicas or clients.

6.3 Consensus with Threshold Signatures: Sbft
Several recent Pbft-style consensus protocols have explored the
usage of threshold signatures to transform the two phases of all-to-
all communication in Pbft (the prepare and commit phases) to two
phases of all-to-one-to-all communication. These transformations
are similar to how we can transform the prepare phase of PoE from
all-to-all communication to an all-to-one support sub-phase and an
one-to-all certify sub-phase. We note that such a transformation,
when applied on the two all-to-all communication phases of Pbft,
will result in a consensus protocol with a high latency: in such a
protocol, it will take five communication rounds before replicas
can execute client requests and inform clients. Although such a
transformation can successfully reduce the global communication
cost of the normal-case operations of the consensus protocol, such
threshold signature transformations do little to address the costs
associated with any checkpoint and view-change protocols.

A good examples of a Pbft-style consensus protocols that use
threshold signatures is Sbft [13], which uses an optimistic fast path
to reduce the number of rounds when all replicas are non-faulty,
uses threshold signatures to eliminate all-to-all communication,
and uses threshold signatures to reduce the number of messages
send to the client. The design of Sbft uses a fast path which starts
execution of client requests after the prepare phase if no replicas
are faulty. Furthermore, Sbft can aggregrate the a proof of the
execution results and send such proof in a single message to the
client (instead of f + 1 messages), this to reduce communication
costs towards the client. With this optimization, Sbft is able to
inform clients in four rounds of communication (which is one more
round than Pbft and Linear-PoE and two more rounds than PoE).
In case the fast path fails, Sbft falls back to a slow path via a
Linear-Pbft implementation. To reduce the load on the primary
(see Example 5.5), Sbft uses non-primary replicas as the aggregator
that constructs prepared and commit certificates during the prepare
and commit phases. The usages of non-primary aggregators at
these parts of the protocol does introduce additional failure cases,

however, for which Sbft introduces separate recovery mechanisms.
Similar fine-tuning can also be applied to PoE, but we have not
explored such fine-tuning in this work (as separate aggregators only
introduce minimal bandwidth savings for the primary). Besides the
fast path and the slow path, Sbft also requires a checkpoint protocol
similar to the one utilized by Pbft (which can be run periodically).

6.4 Chained consensus: HotStuff
Another approach toward utilizing threshold signatures in primary-
backup consensus protocols is provided by HotStuff. HotStuff
provides a clean-slate consensus design that is tuned toward mini-
mizing complexity and communication cost, both during normal-
case operations and during view-changes. To achieve this, Hot-
Stuff relies on chaining consensus: the 𝑖-th consensus proposal
builds upon the preceding (𝑖 − 1)-th consensus proposal. This al-
lows HotStuff to represent the state of the ledger via a single value,
namely the last-made consensus decision (that builds upon all pre-
ceding decisions). Finally, HotStuff uses threshold signatures to
produce constant-size certificates for each consensus decision. This
combination of techniques allows HotStuff to implement cheap
primary rotation: each round starts with a switch of primary via a
constant-sized single-message view-change.

The design of HotStuff requires 4 consecutive all-to-one-to-all
phases of communication before consensus is reached on a single
request, which leads to 7 rounds of communication between the
initial proposal of a client request and replicas being able to ex-
ecute these requests. Both the normal-case and the view-change
of HotStuff are linear. To deal with unresponsive replicas and
replica failures, HotStuff uses a Pacemaker. Unfortunately, the
standard Pacemaker of HotStuff assumes partial synchrony and
cannot recover from network failures. To improve the resilience
against network failure in HotStuff, one can replace the standard
Pacemaker that HotStuff uses with a Pacemaker suitable for an
asynchronous environment. As stated in Remark 5.4, we believe
that any asynchronous Pacemaker that can sufficiently synchro-
nize replicas after network failure will have to operate similarly
to the failure detection stage of PoE, which would introduce a de-
centralized all-to-all communication phase in the recovery path of
HotStuff.

Due to the chained design of HotStuff, HotStuff does not
support out-of-order processing: consensus decisions are strictly
made in sequence. HotStuff does support overlapping of rounds
of consecutive consensus decisions, however. Hence, in practice,
HotStuff is able to propose a request every 2 rounds of commu-
nication. Consequently, the performance of typical deployments
of HotStuff are latency based and non-local deployments can
only reach tens-to-hundreds consensus decisions per second. E.g.,
with a message delay of 15 ms, HotStuff can perform at-most 33
consensus decisions per second, whereas, as shown in Example 5.6,
an out-of-order PoE can easily process thousands of consensus
decisions per second.

6.5 Trusted Hardware

There is a large body of work on consensus protocols that utilize
trusted hardware to simplify and optimize consensus. The usage of

Jelle Hellings, Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi

trusted hardware restricts the behavior allowed by faulty or mali-
cious replicas, e.g., by assuring faulty replicas cannot share their
private keys and cannot forge round numbers and other counters. A
representative example of a consensus protocol that utilizes trusted
hardware is MinBFT [36]. Due to the usage of trusted hardware,
MinBFT can skip the prepare phase of Pbft and can achieve con-
sensus in only two rounds of communication. Furthermore, the
usage of trusted hardware makes MinBFT more resilient against
failure, as it requires f fewer non-faulty replicas than normal con-
sensus protocols (MinBFT can operate even in deployments in
which 3f ≥ n > 2f holds). Unfortunately, the presented version of
MinBFT does require reliable communication, as the protocol itself
does not deal with message loss.

To the best of our knowledge, MinBFT and other consensus pro-
tocols that utilize trusted hardware are the only consensus protocols
besides PoE that have a latency of two rounds of communication
(without relying on a fault-prone optimistic path).

6.6 Other Consensus Protocols

There are many other recent Pbft-style consensus protocols that we
did not cover in the above. Most of these protocols have properties
similar to the ones discussed, however. E.g., FaB [25] is an optimistic
protocol that has a fast path in the same vein as Zyzzyva [23] and
LinBFT [39] is a version of Pbft that uses threshold signatures
and is based on techniques similar to those used in Sbft [13] and
HotStuff [40].

7 CONCLUSION

In this paper, we introduced PoE, a consensus protocol designed for
high-performance low-latency resilient data management systems
and that can operate in practical asynchronous deployments. PoE
introduces the usage of speculative execution and proof-of-execution
to minimize the latency of transaction processing in such resilient
systems and introduces a single-round check-commit protocol to
further reduce communication costs of consensus. Furthermore, the
flexible design of PoE allows for optimizations that further balance
communication costs, transaction latency, and recovery complexity.
The flexible low-latency high-throughput design of PoE is es-
pecially suited for resilient data management systems. To illus-
trate this, we performed an in-depth analytical and experimental
comparison with other consensus protocols, that underlined the
outstanding performance of PoE. Hence, we believe that PoE is
a promising step towards flexible general-purpose resilient data
management systems.

REFERENCES
[1] Ittai Abraham, Guy Gueta, Dahlia Malkhi, Lorenzo Alvisi, Rama Kotla, and Jean-
Philippe Martin. Revisiting fast practical byzantine fault tolerance, 2017. URL:
https://arxiv.org/abs/1712.01367.

[2] Ittai Abraham, Guy Gueta, Dahlia Malkhi, and Jean-Philippe Martin. Revisiting
fast practical byzantine fault tolerance: Thelma, velma, and zelma, 2018. URL:
https://arxiv.org/abs/1801.10022.

[3] Mohammad Javad Amiri, Divyakant Agrawal, and Amr El Abbadi. CAPER: A
cross-application permissioned blockchain. Proc. VLDB Endow., 12(11):1385–1398,
2019. doi:10.14778/3342263.3342275.

[4] Pierre-Louis Aublin, Rachid Guerraoui, Nikola Knežević, Vivien Quéma, and
Marko Vukolić. The next 700 BFT protocols. ACM Trans. Comput. Syst., 32(4),
2015. doi:10.1145/2658994.

[5] Yuliang Baek, Joonsang Zheng. Simple and efficient threshold cryptosystem from
the gap diffie-hellman group. In GLOBECOM ’03. IEEE Global Telecommunications

challenges and future research directions. Logistics, 4(4), 2020. doi:10.3390/
logistics4040027.

[31] Victor Shoup. Practical threshold signatures.

In Advances in Cryptology —
EUROCRYPT 2000, pages 207–220. Springer, 2000. doi:10.1007/3-540-45539-
6_15.

[32] Dale Skeen. A quorum-based commit protocol. Technical report, Cornell Univer-

sity, 1982.

[33] Gerard Tel. Introduction to Distributed Algorithms. Cambridge University Press,

2nd edition, 2001.

[34] The Hyperledger White Paper Working Group. An introduction to Hyperledger.

Technical report, The Linux Foundation, 2018.

[35] Horst Treiblmaier and Roman Beck, editors. Business Transformation through

Blockchain. Springer, 2019. doi:10.1007/978-3-319-98911-2.

[36] Giuliana Santos Veronese, Miguel Correia, Alysson Neves Bessani, Lau Cheuk
IEEE Trans.

Lung, and Paulo Verissimo. Efficient byzantine fault-tolerance.
Comput., 62(1):16–30, 2013. doi:10.1109/TC.2011.221.

[37] Harald Vranken. Sustainability of bitcoin and blockchains. Current Opinion in
Environmental Sustainability, 28:1–9, 2017. doi:10.1016/j.cosust.2017.04.
011.

[38] Mingli Wu, Kun Wang, Xiaoqin Cai, Song Guo, Minyi Guo, and Chunming Rong.
A comprehensive survey of blockchain: From theory to IoT applications and
beyond. IEEE Internet Things J, 6(5):8114–8154, 2019. doi:10.1109/JIOT.2019.
2922538.

[39] Yin Yang. LinBFT: Linear-communication byzantine fault tolerance for public

blockchains, 2018. URL: https://arxiv.org/abs/1807.01829.

[40] Maofan Yin, Dahlia Malkhi, Michael K. Reiter, Guy Golan Gueta, and Ittai Abra-
ham. HotStuff: BFT consensus with linearity and responsiveness. In Proceedings
of the 2019 ACM Symposium on Principles of Distributed Computing, pages 347–356.
ACM, 2019. doi:10.1145/3293611.3331591.

On the Correctness of Speculative Consensus

Conference, volume 3, pages 1491–1495. IEEE, 2003. doi:10.1109/GLOCOM.2003.
1258486.

[6] Gabriel Bracha and Sam Toueg. Asynchronous consensus and broadcast protocols.

J. ACM, 32(4):824–840, 1985. doi:10.1145/4221.214134.

[7] Miguel Castro and Barbara Liskov. Practical byzantine fault tolerance and
proactive recovery. ACM Trans. Comput. Syst., 20(4):398–461, 2002.
doi:
10.1145/571637.571640.

[8] Hung Dang, Tien Tuan Anh Dinh, Dumitrel Loghin, Ee-Chien Chang, Qian
Lin, and Beng Chin Ooi. Towards scaling blockchain systems via sharding. In
Proceedings of the 2019 International Conference on Management of Data, pages
123–140. ACM, 2019. doi:10.1145/3299869.3319889.

[9] Alex de Vries. Bitcoin’s growing energy problem. Joule, 2(5):801–805, 2018.

doi:10.1016/j.joule.2018.04.016.

[10] Danny Dolev. The byzantine generals strike again. J. Algorithm, 3(1):14–30, 1982.

doi:10.1016/0196-6774(82)90004-9.

[11] Muhammad El-Hindi, Carsten Binnig, Arvind Arasu, Donald Kossmann, and
Ravi Ramamurthy. BlockchainDB: A shared database on blockchains. Proc. VLDB
Endow., 12(11):1597–1609, 2019. doi:10.14778/3342263.3342636.

[12] Michael J. Fischer, Nancy A. Lynch, and Michael S. Paterson. Impossibility of
distributed consensus with one faulty process. J. ACM, 32(2):374–382, 1985.
doi:10.1145/3149.214121.

[13] Guy Golan Gueta, Ittai Abraham, Shelly Grossman, Dahlia Malkhi, Benny Pinkas,
Michael Reiter, Dragos-Adrian Seredinschi, Orr Tamir, and Alin Tomescu. SBFT:
A scalable and decentralized trust infrastructure. In 49th Annual IEEE/IFIP Inter-
national Conference on Dependable Systems and Networks (DSN), pages 568–580.
IEEE, 2019. doi:10.1109/DSN.2019.00063.

[14] William J. Gordon and Christian Catalini. Blockchain technology for healthcare:
Facilitating the transition to patient-driven interoperability. Comput. Struct.
Biotechnol. J., 16:224–230, 2018. doi:10.1016/j.csbj.2018.06.003.

[15] Jim Gray. Notes on data base operating systems.

In Operating Systems, An
Advanced Course, pages 393–481. Springer-Verlag, 1978. doi:10.1007/3-540-
08755-9_9.

[16] Suyash Gupta, Jelle Hellings, and Mohammad Sadoghi. Fault-Tolerant Distributed
Transactions on Blockchain. Synthesis Lectures on Data Management. Morgan &
Claypool, 2021. doi:10.2200/S01068ED1V01Y202012DTM065.

[17] Suyash Gupta, Sajjad Rahnama, Jelle Hellings, and Mohammad Sadoghi. Re-
silientDB: Global scale resilient blockchain fabric. Proc. VLDB Endow., 13(6):868–
883, 2020. doi:10.14778/3380750.3380757.

[18] Suyash Gupta, Sajjad Rahnama, Jelle Hellings, and Mohammad Sadoghi. Proof-of-
execution: Reaching consensus through fault-tolerant speculation. In Proceedings
of the 24th International Conference on Extending Database Technology (EDBT),
pages 301–312. OpenProceedings.org, 2021. doi:10.5441/002/edbt.2021.27.
Permissioned
blockchain through the looking glass: Architectural and implementation lessons
learned. In 2020 IEEE 40th International Conference on Distributed Computing
Systems (ICDCS), pages 754–764. IEEE, 2020. doi:10.1109/ICDCS47774.2020.
00012.

[19] Suyash Gupta, Sajjad Rahnama, and Mohammad Sadoghi.

[20] Maged N. Kamel Boulos, James T. Wilson, and Kevin A. Clauson. Geospatial
blockchain: promises, challenges, and scenarios in health and healthcare. Int. J.
Health. Geogr, 17(1):1211–1220, 2018. doi:10.1186/s12942-018-0144-x.
[21] Andreas Kamilaris, Agusti Fonts, and Francesc X. Prenafeta-Boldύ. The rise of
blockchain technology in agriculture and food supply chains. Trends in Food
Science & Technology, 91:640–652, 2019. doi:10.1016/j.tifs.2019.07.034.

[22] Jonathan Katz and Yehuda Lindell. Introduction to Modern Cryptography. Chap-

man and Hall/CRC, 2nd edition, 2014.

[23] Ramakrishna Kotla, Lorenzo Alvisi, Mike Dahlin, Allen Clement, and Edmund
Wong. Zyzzyva: Speculative byzantine fault tolerance. ACM Trans. Comput. Syst.,
27(4), 2010. doi:10.1145/1658357.1658358.

[24] Laphou Lao, Zecheng Li, Songlin Hou, Bin Xiao, Songtao Guo, and Yuanyuan
Yang. A survey of iot applications in blockchain systems: Architecture, consensus,
and traffic modeling. ACM Comput. Surv., 53(1), 2020. doi:10.1145/3372136.
[25] Jean-Philippe Martin and Lorenzo Alvisi. Fast byzantine consensus. IEEE Trans.

Dependable Secur. Comput., 3(3):202–215, 2006. doi:10.1109/TDSC.2006.35.

[26] Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system. URL: https:

//bitcoin.org/en/bitcoin-paper.

[27] Senthil Nathan, Chander Govindarajan, Adarsh Saraf, Manish Sethi, and Praveen
Jayachandran. Blockchain meets database: Design and implementation of a
blockchain relational database. Proc. VLDB Endow., 12(11):1539–1552, 2019. doi:
10.14778/3342263.3342632.

[28] Faisal Nawab and Mohammad Sadoghi. Blockplane: A global-scale byzantizing
middleware. In 35th International Conference on Data Engineering (ICDE), pages
124–135. IEEE, 2019. doi:10.1109/ICDE.2019.00020.

[29] Michael Pisa and Matt Juden.

Blockchain and economic development:
Technical report, Center for Global Development,
URL: https://www.cgdev.org/publication/blockchain-and-economic-

Hype vs. reality.
2017.
development-hype-vs-reality.

[30] Abderahman Rejeb, John G. Keogh, Suhaiza Zailani, Horst Treiblmaier, and
Karim Rejeb. Blockchain technology in the food industry: A review of potentials,

