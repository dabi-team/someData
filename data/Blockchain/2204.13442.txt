TTAGN: Temporal Transaction Aggregation Graph Network for
Ethereum Phishing Scams Detection
Sijia Li1,2, Gaopeng Gou1,2, Chang Liu1,2∗, Chengshang Hou1,2, Zhenzhen Li1,2, Gang Xiong1,2
1 Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China
2 School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China
{lisijia,gougaopeng,liuchang,houchengshang,lizhenzhen,xionggang}@iie.ac.cn

2
2
0
2

r
p
A
8
2

]

R
C
.
s
c
[

1
v
2
4
4
3
1
.
4
0
2
2
:
v
i
X
r
a

ABSTRACT
In recent years, phishing scams have become the most serious
type of crime involved in Ethereum, the second-largest blockchain
platform. The existing phishing scams detection technology on
Ethereum mostly uses traditional machine learning or network
representation learning to mine the key information from the trans-
action network to identify phishing addresses. However, these meth-
ods adopt the last transaction record or even completely ignore
these records, and only manual-designed features are taken for
the node representation. In this paper, we propose a Temporal
Transaction Aggregation Graph Network (TTAGN) to enhance
phishing scams detection performance on Ethereum. Specifically,
in the temporal edges representation module, we model the tem-
poral relationship of historical transaction records between nodes
to construct the edge representation of the Ethereum transaction
network. Moreover, the edge representations around the node are
aggregated to fuse topological interactive relationships into its
representation, also named as trading features, in the edge2node
module. We further combine trading features with common sta-
tistical and structural features obtained by graph neural networks
to identify phishing addresses. Evaluated on real-world Ethereum
phishing scams datasets, our TTAGN (92.8% AUC, and 81.6% F1-
score) outperforms the state-of-the-art methods, and the effective-
ness of temporal edges representation and edge2node module is
also demonstrated.

CCS CONCEPTS
• Applied computing → Digital cash; • Security and privacy
→ Phishing.

KEYWORDS
Blockchain, Ethereum, Phishing scams detection, Network repre-
sentation learning

ACM Reference Format:
Sijia Li1,2, Gaopeng Gou1,2, Chang Liu1,2∗, Chengshang Hou1,2, Zhenzhen
Li1,2, Gang Xiong1,2. 2022. TTAGN: Temporal Transaction Aggregation
Graph Network for Ethereum Phishing Scams Detection. In Proceedings of
the ACM Web Conference 2022 (WWW ’22), April 25–29, 2022, Virtual Event,

∗Chang Liu is the corresponding author.

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France
© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9096-5/22/04.
https://doi.org/10.1145/3485447.3512226

Lyon, France. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/
3485447.3512226

1 INTRODUCTION
Ethereum[29] is one of the most popular and scalable blockchain
platforms with 14.8 transactions per second and 700,000 daily active
addresses on it[7]. However, along with its high-speed development,
Ethereum has also become a hotbed of various cybercrimes[15].
Phishing, as a typical scam, has received a great deal of attention
due to its high visibility and lots of potential victims. Based on
2021 statistics of phishing scams from Chainalysis, victims lost
$645,000 within the first week of the phishing campaign, and the
attacker’s illegal profits exceeded $3,000,000 in just one month[6].
Phishing scams cause great economic losses and have become a
major threat to the trading security of Ethereum[7]. Therefore,
identifying phishing scams on Ethereum becomes a crucial research
topic and attracts widespread attention[3, 28].

Figure 1: The difference between traditional phishing scams
and Ethereum phishing scams.

Traditional phishing scams detection methods cannot be well
adapted to the Ethereum scenario. As Figure 1 shows, traditional
phishing scams rely on building forged platforms (websites or soft-
ware) to collect sensitive information or receive remittances from
victims, so traditional methods focus on mining forged platform
patterns, such as CSS styles[13], website URLs[23], etc. However,
in Ethereum, phishing organizations take high-reward propaganda
to induce remittances[6], they can swindle money directly without
forged platforms by spreading phishing addresses to victims in any
way such as emails, chat groups, etc. Since there is no fixed pattern
for phishing scams on Ethereum, traditional detection methods are
ineffective.

 
 
 
 
 
 
WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sijia Li et al.

The current methods of phishing scam detection on Ethereum
are to learn the representation of phishing nodes through the trans-
action network and classify nodes[2, 19], in which nodes represent
Ethereum transaction addresses and edges represent transactions
between addresses. The main detection methods can be roughly di-
vided into two types. One is to combine traditional machine learning
and manual-designed features (i.e. structural and statistical features)
of nodes for phishing detection [9]. However, these methods mainly
rely on professional knowledge to extract manual-designed features
(e.g., node’s in-degree, total transaction amount, transaction time
interval, etc.) , which are inefficient and non-automated. The other
one is to apply network representation learning to the Ethereum
transaction network for mining deep features. Random walk[30, 31]
and graph neural network[8] are adopted to automatically learn
representations from the Ethereum transaction network, which has
made a very important breakthrough. However, there are still two
remaining problems: (1) Lack of temporal transaction informa-
tion. The existing methods only adopt the last transaction record
or even completely ignore these records, instead of taking temporal
information of transaction records into consideration, which leads
to the incomplete edge representations in the Ethereum transac-
tion network. (2) Weak node representation. Only statistical and
structural features extracted from transaction records are consid-
ered as the node representation, while trading features referring
to the contextual information of transaction records are ignored
totally. In summary, the lack of temporal transaction information
and weak node representation finally cause the unsatisfactory per-
formance of Ethereum phishing addresses detection.

To address the above challenges, in this paper, we propose Temporal

Transaction Aggregation Graph Network (TTAGN) to enhance
phishing scams detection on Ethereum by effectively utilizing trans-
action temporal information. We first build a large-scale Ethereum
multilateral directed transaction network graph, in which a node is
a unique address and a directed edge refers to a transaction between
two addresses, and obtain the nodes’ basic statistical features. We
design three modules to generate node representations by graph
mining. In detail, the graph is fed to the Temporal Edge Representa-
tion module which fully models and mines temporal information
of Ethereum transaction records between transaction nodes to gen-
erate the edge representations. In the Edge2node module, the edge
representations around the node are aggregated to fuse topologi-
cal interactive relationships into its representation, also named as
trading features, which enriches the characteristics of the nodes.
We also extract the common structural features in the Structural
Enhancement module and further combine statistical, structural
and trading features to generate the final node representation. Fi-
nally, the obtained node representations are fed into the classifier
to identify phishing nodes. Extensive experiments are conducted
on real-world datasets to verify the effectiveness of TTAGN.
Contributions. Our contributions can be summarized as:

• We propose a Temporal Transaction Aggregation Graph
Network (TTAGN) to enhance the Ethereum phishing scams
detection performance by combining trading, structural and
statistical features.

• All the directed transaction edges (records) between nodes
(addresses) in the Ethereum transaction graph (network) are

modeled to mine the temporal information and enrich the
edge representation.

• The edge representations around each node are aggregated
to fuse topological interactive relationships to generate the
trading features.

• We conduct extensive experiments on real-world Ethereum
phishing scam dataset and results show that TTAGN outper-
forms state-of-the-art methods on multiple metrics.

The remainder of the this paper is organized as follows. Section
2 summarizes the prior researches related to our work. Section
3 introduces the problem statement of this paper. Section 4 high-
lights the overall design of TTAGN and Section 5 illustrates the
experiments. Section 6 concludes the paper.

2 RELATED WORK
Phishing scams detection on Ethereum is a new fraud scenario.
In this section, we first briefly review prior work on Ethereum
phishing scams detection. Next, we review the network representa-
tion learning which is the core task of Ethereum phishing scams
detection.

2.1 Ethereum Phishing Scams Detection
For the phishing scams detection problem on Ethereum, there are
two main categories of existing methods.

The former mainly employ shallow models such as traditional
machine learning methods with dedicated feature engineering, fo-
cusing on statistical features. Chen et al.[9] extracted 219-dimensional
statistical features from the node’s 1-order and 2-order neighbors,
including the node’s in-degree, out-degree, maximum transaction
value, and so on. Then they used a LightGBM-based ensemble ma-
chine learning algorithm to identify phishing nodes.

The latter applies some network embedding methods such as
DeepWalk[21], Node2Vec[11], and graph convolutional networks
(GCN)[17] to mine deep features. Wu et al.[30] proposed Trans2Vec
on the basis of Node2Vec[11]. The difference between Trans2Vec
and Node2Vec is that the sampling process of Trans2Vec is not
random, but biased based on the last transaction of the two nodes,
which is more suitable for phishing detection on Ethereum. Chen
et al.[8] designed E-GCN to detect phishing nodes, which is the
first time GCN[17] has been introduced in Ethereum phishing node
detection. They extracted 8-dimensional statistical features and then
used GCN to learn the structural characteristics of the transaction
network.

However, these works rarely use the temporal information of
transaction behaviors, so they can not capture complete edge rep-
resentations. Moreover, only manual-designed features are taken
for the node representation, which further led to weak node repre-
sentation capabilities of these detection methods.

2.2 Network Representaion Learning
According to a survey[10], network representation learning (i.e.,
graph embedding or network embedding) methods can be summa-
rized into three categories: based on (1) Factorization, (2) Random
Walk, and (3) Deep Learning.

Factorization-based algorithm uses the connection information
between nodes to construct various matrices (e.g., Laplacian matrix,

TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

adjacency matrix, and Katz similarity matrix), and then factorize
the above matrix to obtain embeddings. The models associated with
factorization are, for example, Locally Linear Embedding (LLE)[22],
Laplacian Eigenmaps[4], Graph Factorization[1], Learning Graph
Representations with Global Structural Information (GraRep)[5],
High-Order Proximity Preserved Embedding (HOPE)[20].

Random walk-based algorithm utilizes walk to perceive the cen-
trality and similarity of nodes. DeepWalk[21] tries to maximize the
co-occurrence probability of nodes in the window after obtaining
the node sequence of random walk. As for Node2Vec[11], in the
first stage of generating nodes’ corpus, the walking decision is more
flexible than DeepWalk, but the time consumption increases greatly.
Different from DeepWalk, Large-scale Information Network Em-
bedding (LINE)[24] aims to generate neighbors rather than nodes
on a path based on current nodes.

Deep learning-based method mainly uses deep neural networks
to learn non-linear information in graphs. Structural Deep Network
Embedding (SDNE)[27] apply deep autoencoders to keep network
proximities within 2-order. It uses a semi-supervised autoencoder
to reconstruct the neighbor relationships of the nodes and uses a
supervised approach to trim the results. GraphSAGE[12] is an in-
ductive GNN model based on a fixed sample number of the neighbor
nodes and Graph Attention Networks (GAT)[26] employs attention
mechanism for neighbor aggregation.

We have selected representative works from three categories
for comparison in the subsequent experimental part, which further
highlights the effectiveness of our model.

3 PROBLEM DEFINITION
In this paper, the Ethereum phishing scams detection task is phrased
as a graph node classification problem. Let the partially labeled
Ethereum transaction network 𝒢𝐿 = (𝒱, ℰ, 𝑋, 𝐶), we treat the trans-
action address as a node 𝑣𝑖 , 𝒱 = {𝑣1, . . . , 𝑣𝑁 } is a set of addresses.
The transaction as an edge ℰ𝑖 , ℰ = {ℰ1, . . . , ℰ𝑅 } is the transaction
set. The transaction direction, amount and time information as the
edge attributes 𝑋 ∈ R |ℰ |×𝑆 where 𝑆 is the size of the feature space
for each edge, and 𝐶 ∈ R |𝒱 |×|𝒴 | where 𝒴 is the set of labels. The
goal of our model is to efficiently learn the representation of nodes
from the known large-scale transaction network information, so
we learn the embeddings of all nodes 𝑋𝐸 ∈ R|𝑉 |×𝑑 , where 𝑑 is the
number of dimensions for feature representation.

4 DESIGN OF TTAGN
TTAGN enhances the representation of edges by modeling trans-
action temporal information, finally improving the identification
of Ethereum phishing nodes. Specifically, TTAGN includes three
modules, named building transaction graphs, learning network
embedding and phishing addresses detection.

4.1 Temporal Transaction Graphs
Based on a large amount of Ethereum transaction data obtained,
we first build a large-scale Ethereum transaction Multiple edges
Directed Graph (MultiDiGraph). In the transaction graph, we use
nodes to represent Ethereum transaction addresses, and edges to
represent transactions between addresses. Noting that the Ethereum
transaction MultiDiGraph allows multiple directed edges between

any pair of nodes, and each edge carries information of the transac-
tion, such as the transaction amount in ETH (the unit of Ether) and
the execution timestamp. The scale of the original graph is huge, so
we take the sampling step with a random walk. We randomly select
a node from the graph to start walking, then randomly select its
neighbor as the next node, and repeat this process until the number
of nodes reaches our requirement. After that we obtain subgraphs
of the scale we want.

The collected subgraph will first perform feature engineering
to prepare for the subsequent learning of the structural features
of the node. Because of the anonymity of the blockchain platform,
the node itself does not carry any attribute characteristics. So we
extract the following 10-dimensional features as the attribute char-
acteristics of the node. They are the node’s total degree, out-degree,
in degree, the sum of transactions amount, transfer out transac-
tion amount, transfer in transaction amount, the total number of
neighbors, the inverse of transaction frequency, the percentage
of neighbors whose transactions are all zeros, and the number of
transactions with the most frequent neighbors.

4.2 Model Architecture
TTAGN is a network representation framework to detect phishing
addresses. As shown in Figure 2, the architecture could be divided
into three objectives: temporal edges representation, edge2node,
structural enhancement.

4.2.1 Temporal Edges Representation. In this module, edge repre-
sentations are generated from transactions interaction relationships
between nodes.

This module improves the detection effect by introducing transac-
tion temporal information. Transaction information includes trans-
action direction, amount, time, etc., which will reflect the difference
between phishing addresses and normal at the transaction level.
Therefore, by introducing the transaction information, the nodes’
representations are enhanced.

However, there are two difficulties with using transaction in-
formation directly: (1) Sequential. Transactions are temporal and
inherently sequential, this information needs to be incorporated
into edge representations. (2) Variable length. The number of trans-
actions between nodes is different, edge representations should
include all valid information without causing information redun-
dancy.

As for sequential, we apply the sequence model LSTM[14] to
characterize the multiple temporal transactions and capture the
temporal pattern of interaction between a pair of nodes. As Figure
3 shows, the transactions between each pair of nodes are treated as
a time series, sorted in ascending order by timestamp, and then be
fed into the LSTM model. For the node pair (𝑢, 𝑣), we denote ˜𝑒𝑢𝑣
as the edge embedding generated by the sequence model LTSM,
where:

˜𝑒𝑢𝑣 = 𝐿𝑆𝑇 𝑀

= 𝐿𝑆𝑇 𝑀

(cid:16) (cid:2)𝑒1
(cid:16) (cid:104)(cid:16)

𝑢𝑣, 𝑒2

(cid:3) (cid:17)

𝑢𝑣, · · · , 𝑒𝑛
𝑢𝑣
(cid:16)
(cid:17)
𝑢𝑣, 𝑡 2
𝑎2
𝑢𝑣

,

𝑢𝑣, 𝑡 1
𝑎1
𝑢𝑣

(cid:17)

, · · · , (cid:0)𝑎𝑛

𝑢𝑣, 𝑡𝑛
𝑢𝑣

(cid:1)(cid:105) (cid:17)

(1)

Among them, 𝑎𝑖
𝑢𝑣 represents the transaction amount of the 𝑖-th
transaction with direction between nodes 𝑢 and 𝑣. The plus or
minus of 𝑎𝑖
𝑢𝑣 represents the direction of this transaction, if the

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sijia Li et al.

Figure 2: The overall architecture of TTAGN. TTAGN inputs different sizes of Ethereum transaction subgraphs to learn their
nodes’ representation. The temporal edges representation module model the temporal relationship of historical transaction
records to construct the representation of edges, the edge2node module aggregates edge representations around the node to
fuse topological interactive relationships into trading features, and the graph autoencoder further enhances the perception
of node structure information. Finally, the outputs of several modules are combined as the final representation of the node,
which feeds into the classifier to get the result.

node transfers ETH to other nodes, 𝑎 is positive, else, the value
is negative. 𝑡𝑛
𝑢𝑣 represents the transaction timestamp of the 𝑛-th
transaction between nodes 𝑢 and 𝑣.

As for variable length, we realize the variable-length input of
LSTM, further make full use of the temporal transaction records.

Combining the above two points, we captured the temporal rela-
tionship of historical transaction records, generated effective edge
representations, and simplified the complex graph structure (con-
vert MultiDiGraph to undirected graph with edge representations),
which is helpful for the subsequent node classification work.

4.2.2 Edge2node. In this module, nodes representations are en-
riched by biased aggregation of edge representations with temporal
transaction information to the nodes.

In the transaction network on Ethereum, the node itself does
not carry information, and only manual-designed features are not
comprehensive which leads to weak node representation. Each
Ethereum transaction node usually interacts with multiple nodes
at the same time, and is also connected with multiple transaction
edge representations. We need to fuse its interaction with all other
nodes into its representation. Meanwhile, different interaction have
different effects on the node representation.

To solve these problems, we aggregated the edge representa-
tions around each node to fuse topological interactive relationships.
Moreover, we adopt Attention [25] with multiple levels mechanism
to catch similar transaction behaviors, and finally generate the
trading features. Figure 4 shows the main steps of edge2node. For
each node of input transaction graphs, the edge2node learns the

weights of adjacent edges and aggregates them to get the expressive
node representation. Given 𝑁𝑢 denotes the adjacent edges of node
𝑢 and edge 𝑣 ∈ 𝑁𝑢 , the importance node-edge pair ⟨𝑢, 𝑣⟩ can be
formulated as follows:

𝑒Φ
𝑢𝑣 = 𝜎

(cid:16)
𝑎𝑇
Φ · [ℎ𝑢 ∥ℎ𝑣]

(cid:17)

𝛼 Φ
𝑢𝑣 = softmaxv

(cid:17)

(cid:16)
𝑒Φ
𝑢𝑣

=

exp (cid:16)

(cid:17)

𝑒Φ
𝑢𝑣
exp (cid:16)

(cid:205)

𝑘 ∈𝑁 Φ
𝑢

𝑒Φ
𝑢𝑘

(2)

(cid:17)

where ℎ𝑢 and ℎ𝑣 are the features of node 𝑢 and edge 𝑣, 𝑎Φ is the
attention parametrize matrix for transaction graph Φ, 𝜎 denotes
the activation function, and || denotes the concatenate operation.
Then, the node 𝑢 trading features can be obtained by aggregating
all edge neighbor attributes with the corresponding coefficients as
follows:

𝑧Φ
𝑢 = ∥𝐾

∑︁

𝑣 ∈𝑁 Φ
𝑢

𝑘=1𝜎 (cid:169)
(cid:173)
(cid:171)

𝛼𝑘
𝑢𝑣 · ℎ𝑣(cid:170)
(cid:174)
(cid:172)

(3)

where 𝑧Φ
𝑢 is the learned trading features of node 𝑢 for the transaction
graph Φ, 𝐾 is the head number using the multi-head attention
mechanism[25].

Structural Enhancement. In this module, structural features

4.2.3
are obtained by reconstructing the transaction graph.

The above two modules focus more on extracting effective trans-
action features. In order to obtain a comprehensive node repre-
sentation, in this module, we pay more attention to extracting the

TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Figure 3: Process of learning edge representation from the Ethereum transaction network.

4.3 Phishing Addresses Detection
The task of this section is to classify nodes to distinguish between
phishing nodes and normal nodes. After the above operations, we
have obtained three types of features: trading features learned from
Temporal Edge Representation and Edge2node modules, structural
features learned from Structural Enhancement module, and statisti-
cal features obtained from nodes. We splice them together as the
complete representation of the node. On the basis of obtaining com-
plete node representations, we need to learn the difference between
fishing and normal node representations. So we input them into
the classifier for Ethereum phishing addresses classification.

There are many choices of classifiers, and in this article, we
choose LightGBM[16], which is a new GBDT (Gradient Boosting
Decision Tree) algorithm supporting efficient parallel training. The
key concept behind GBDT is to iteratively train the weak classi-
fier (decision tree) to get the optimal model. The model has the
advantages of beneficial training effect and difficult over-fitting.

5 EXPERIMENTS
In this section, we perform empirical evaluations to demonstrate
the effectiveness of the proposed TTAGN framework. Specifically,
we aim to answer the following research questions:

• RQ1: How effective is the proposed approach TTAGN for
detecting phishing addresses on the Etherum transaction
network?

• RQ2: How does each component of TTAGN (i.e., temporal
edges representation, edge2node and structural enhance-
ment) contribute to the final detection performance?

• RQ3: How much will the performance of TTAGN change
by providing different maximum temporal sequence lengths
or different attention hidden sizes?

5.1 Datasets
5.1.1 Data Collection. We crawled accounts labeled "phishing"
from the Ethereum label cloud of the authorized website Ether-
scan1. As of July 2021, 4,932 addresses have been verified to be
phishing addresses. With these labeled nodes being the central
nodes, we extract their first-order, second-order neighbors and
the transactions between all of them through the API provided by
Etherscan. Finally, we obtain 6,844,050 Ethereum addresses and
208,847,461 transaction records. The scale of the original graph
is huge, so we sample with random walks to obtain subgraphs as

1https://etherscan.io

Figure 4: Illustration of the edge2node module.

node structure features of the transaction graph. Analogous to the
idea of Graph Auto-encoder[18], we reconstruct the relationship
between the nodes of the transaction graph. We combine the trad-
ing features obtained from edge2node with statistical features as
node embedding, and input them into the GCN as the encoder to
learn the structural features of the node.

The spectral convolution function is formulated as

𝐻 (𝑙+1) = 𝜎

(cid:16) ˜𝐷− 1

2 ˜𝐴 ˜𝐷− 1

2 𝐻 (𝑙)𝑊 (𝑙) (cid:17)

(4)

where 𝐼 is the identity matrix, ˜𝐴 = 𝐴 + 𝐼 is the adjacency matrix 𝐴
with added self-connections 𝐼 . ˜𝐷 is the degree matrix of ˜𝐴, and 𝑊 (𝑙) ,
𝜎 (·) is the layer-specific trainable weight matrix and activation
function, respectively. 𝐻 (𝑙) ∈ 𝑅𝑛×𝑘 means the matrix of activation
in 𝑙 layer, while 𝑛 and 𝑘 denote the number of nodes and output
dimensions of layer 𝑙.

The overall framework of the module can be defined as follows

𝑍 = 𝐺𝐶𝑁 (𝑋, 𝐴)
𝑍𝑍𝑇 (cid:17)
(cid:16)
ˆ𝐴 = 𝜎

(5)

Among them, 𝑋 is the input node embedding, 𝑍 is the representa-
tion of all transaction nodes learned in the last layer of GCN. 𝑍𝑍𝑇 is
an operation that reconstructs the original graph structure with 𝑍 ,
which is essentially a decoding process, and ˆ𝐴 is the reconstructed
adjacency matrix obtained after decoding. The reconstructed loss
can be written as

ℒ𝑟𝑒𝑐𝑜𝑛 =

∥ ˆ𝐴 − 𝐴∥2
𝐹
𝑛

(6)

∥·∥𝐹 denotes the 𝑙2-norm of a vector, By minimizing the recon-
struction loss ℒ𝑟𝑒𝑐𝑜𝑛, 𝑍 will learn a more comprehensive node
representation that includes the structural features of the transac-
tion graph nodes.

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Table 1: Statistics of evaluation datasets. Labeled represents
the number of labeled nodes in the dataset, and each number
is the average calculated by five subgraphs.

Dataset #Total Nodes #Labeled #Edges #Average Degree

𝐷1

𝐷2

𝐷3

30000

40000

50000

108

139

170

25048388

834.9741

27481082

687.0442

29854251

590.8691

our datasets with sizes of 30,000, 40,000, and 50,000 respectively,
denoted as 𝐷1, 𝐷2, 𝐷3. For each subgraph of different sizes, we
sample five times to ensure the effectiveness of the performance.
Detailed data information is shown in Table 1.

5.1.2 Data Cleaning. After getting all the data, we found that the
class is very imbalanced. We refer to the data cleaning steps of [9],
eliminating obvious non-phishing addresses to build a more effec-
tive model. (1) We clean all transactions that appear before times-
tamp 2016-08-02 because all phishing addresses are active after this
time; (2) We eliminate addresses with less than 5 or more than 1,000
transaction records which may be wallets or other normal types
of accounts [9, 30], and we also did data analysis which proves
that these addresses are not phishing nodes. After data cleaning,
the average number of remaining nodes in each subgraph is 46930,
37194, and 27538 respectively. In the final classification task, we set
80% of the total data as training data and the rest as test data.

Finally, each subgraph is embedded through TTAGN to obtain
the nodes’ representations for the downstream classification task.
In the final classification task, we set 80% of the total data as training
data and the rest as test data[8].

5.2 Experimental Setup
5.2.1 Comparison Methods. We compare our proposed TTAGN
framework with four categories of Ethereum phishing scams de-
tection methods, including (1) Feature-based methods where only
the node attributes are considered[9], (2) Factorization-based net-
work embedding methods[22], and (3) Random walk-based net-
work embedding methods (i.e., DeepWalk[21], Node2Vec[11], and
LINE[24]) where both topological information and node attributes
are involved. In addition, we also use some of the popular (4)
Deep learning-based network representation methods (SDNE[27],
E-GCN[8], GraphSage[12] and GAT[26]) to learn nodes representa-
tions to compare with the representations learned by our method.

• Features only [9] are 219-dimensional statistical features

from the node’s 1-order and 2-order neighbors.

• LLE [22] factorizes the constructed matrix which uses the

connection information to obtain embeddings.

• DeepWalk [21] tries to maximize the co-occurrence prob-
ability of nodes in the window after obtaining the node
sequence of random walk.

• Node2Vec [11] defines a more flexible notion of a node’s
neighborhood and exploits a biased random walk to encode
both local and global network structures.

• LINE [24] learns a low-dimensional embedding via preserv-
ing the first-order and second-order closeness of nodes.

Sijia Li et al.

• SDNE [27] uses semi-supervised autoencoder to reconstruct
the neighbor relationships and supervised approaches to
trim the results.

• GraphSAGE [12] is an inductive GNN model based on a

fixed sample number of the neighbor nodes.

• GAT [26] employs attention mechanism for neighbor aggre-

gation.

• E-GCN [8] is the first time that Graph Neural Network has

been applied to Ethereum phishing node detection.

5.2.2 Evaluation Metrics. In this paper, we use the following four
metrics to have a comprehensive evaluation of the performance of
different methods in terms of Ethereum phishing scam detection:
(1) Area Under Curve (AUC). The AUC metric is to calculate the
area under the ROC curve formed by TPRs and FPRs with multiple
thresholds, which is frequently used in binary classification tasks.
(2) Recall. The recall rate means the percentage of known phishing
nodes samples detected. (3) Precision. The precision rate means
the percentage of real phishing nodes are in the accounts that are
judged to be suspicious. (4) F1-score. F1-score is a comprehensive
evaluation of the Precision and Recall score.

Implementation Details. The embedding size of all models
5.2.3
is fixed to 10. For attention, we set the attention hidden size to 2
and the learning rate to 0.01. For GCN in our method, we set two
layers with 0.001 learning rate. For DeepWalk and Node2Vec, the
walk length, window size, the latter’s 𝑝 and 𝑞 are set to 20 and
4, 0.25, 0.4, respectively. For the LightGBM model, the number of
leaves and the learning rate are empirically fixed at 50 and 0.03,
respectively. Due to the imbalance of the data, we upsample the
minority class with a ratio of 50. For all the comparison methods,
we set parameters based on their official implementations.

5.3 Effectiveness Results (RQ1)
To answer RQ1, we evaluate the performance of all the compared
methods in the task of phishing scams detection on Ethereum. The
corresponding results are reported in Table 2. We can draw the
following conclusions:

(1) In terms of the four evaluation metrics, our approach TTAGN
outperforms all the other compared methods by a significant mar-
gin. Our method TTAGN achieves the best performance about
92.8%AUC, 85.9% Recall, 77.7% precision and 81.6% F1-score under
𝐷3 dataset. The second best method is deep learning methods which
reach the AUC exceeding 80%. The performances of the random
walk-based method and the factorization-based method are similar,
and their indicators are both around 75%. The worst performance
is the feature-based method, and its Recall rate is very low, only
about 55%.

(2) TTAGN has better node representation capability on large
graphs. As the number of datasets nodes increases from 30,000 to
50,000, the gap between TTAGN and other comparison methods is
further widened. Compared with the well-performing GraphSAGE
method, the AUC difference between the two methods is 6.5% on
𝐷1 and 12.6% on 𝐷3. These results again demonstrate that TTAGN
can better detect phishing nodes on large-scale transaction net-
works than other methods by fully mining temporal information
of Ethereum transaction records between transaction nodes.

TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Table 2: Performance comparison results w.r.t. AUC, Recall, Precision and F1-score on three datasets.

Method

Dataset

Metric

𝐷1

𝐷2

𝐷3

AUC Recall

Pre

F1

AUC Recall

Pre

F1

AUC Recall

Pre

F1

Feature-based Only Features

0.807

0.669

0.699

0.684

0.778

0.524

0.723

0.607

0.733

0.575

0.686

0.633

Factorization

LLE

0.773

0.784

0.488

0.602

0.732

0.575

0.339

0.427

0.753

0.455

0.422

0.438

Random walk

Deep learning

Deep Walk
Node2Vec
LINE

SDNE
E-GCN
GAT
GraphSAGE

0.790
0.602
0.813

0.720
0.722
0.764
0.838

0.499
0.414
0.736

0.838
0.615
0.622
0.675

Ours

TTAGN

0.903

0.855

0.755
0.550
0.624

0.360
0.607
0.498
0.731
0.721

0.601
0.472
0.675

0.504
0.698
0.553
0.702

0.742
0.717
0.797

0.729
0.806
0.812
0.804

0.515
0.519
0.650

0.613
0.761
0.665
0.634

0.398
0.475
0.676

0.320
0.762
0.580
0.577

0.449
0.496
0.662

0.421
0.761
0.620
0.604

0.733
0.826
0.802

0.739
0.765
0.828
0.802

0.367
0.735
0.655

0.717
0.703
0.682
0.665

0.632
0.434
0.611

0.334
0.626
0.556
0.619

0.464
0.545
0.632

0.456
0.662
0.643
0.641

0.783

0.910

0.833

0.807

0.820

0.928

0.859

0.777

0.816

(3) Compared with the feature-based methods, our four evalua-
tion metrics are nearly 20% higher than them. The performance of
the feature-only method is the worst across all compared methods.
When the dataset is small, its effect is better than the factorization-
based method, but as the number of nodes increases, the informa-
tion that the statistical features can learn is very limited. Apart from
the lack of feature mining, it may be because of these methods’ un-
awareness of the network structure and environment information
that we obtain from the structural enhancement module.

(4) As for the random walk-based methods, LINE performed
the best, which is lower than our method 12.6% AUC and 18.4% F1-
score on the 𝐷3 dataset. LINE uses the deep excavation of proximity
within the second-order, through it LINE can perceive the nearby
information than Deep Walk and Node2Vec. However, this type of
methods completely ignores the transaction records between the
nodes, which lead to incomplete representation learning of nodes.
In our method TTAGN, we model the temporal relationship of
historical transaction records, which makes full use of transaction
information and learns the effective edge representation.

(5) Network representation methods based on deep learning are
our strong opponents, however, they are also not performing well.
On the dataset 𝐷3, our four evaluation metrics are nearly 10% higher
than it. As for GraphSAGE, it does not explore label distribution
when sampling, thus they perform worse than GAT. GAT performs
worse than our method TTAGN because in the biased aggrega-
tion step, GAT aggregates neighbors with statistical characteristics,
while we use the edge2node module to aggregate the obtained edge
representations to nodes. This approach enriches the characteristics
of the nodes and strengthens the nodes’ representation ability.

5.4 Ablation Study (RQ2)
To answer RQ2 and validate the effectiveness of our innovation, we
eliminate the Temporal Edge Representation module (i.e. TTAGN/t),
the Edge2node module (i.e. TTAGN/e) and the Structural Enhance-
ment module (i.e. TTAGN/s) respectively.

As shown in Figure 5, the corresponding observation results

have the following aspects:

(1) Compared to TTAGN, the performance of TTAGN/t drasti-
cally degrades, which are 7%, 8.5%, and 9.8% lower than TTAGN’s

(a) AUC Result

(b) Recall Result

Figure 5: AUC and Recall results of TTAGN and its variants.

AUC on 𝐷1, 𝐷2, and 𝐷3 datasets, respectively. The main reason is
the sequences model LSTM can fully extract the temporal pattern
of transaction interaction between nodes, learn expressive edge
representations. This result indicates that learning temporal edges
representation of each edge in the transaction graph is essential for
the phishing scams detection task, and also proves the importance
of edges with transaction information in the transaction graph.

(2) After removing the edge2node module, TTAGN/e is 6.4%
lower than the full model on the 𝐷3 dataset. The main function
of edge2node is to aggregate around edges representations into
nodes. If the learned edge representations are directly spliced with
statistical features as classification features, the effect is far inferior
to aggregation on nodes. The result proves that the aggregation
of edges representations can more comprehensively capture the
features of the nodes and strengthen the nodes’ representation abil-
ity. The edge2node module and the temporal edges representation
module complement each other and are indispensable.

(3) Among the three modules, the structural enhancement mod-
ule contributes the least. The AUC of TTAGN/s on the 𝐷3 dataset is
3.1% lower than TTAGN. It seems that this module is not as signifi-
cant as the temporal edges representation and edge2node effects,
but it also effectively extracts the information of the topological en-
vironment. These obtained structural information further enriches
the representations of the nodes.

(4) The performance of the complete model TTAGN on the three
datasets is better than other ablation models. This proves that each
module could provide effective improvement to finally lead to the
significantly high AUC of TTAGN. At the same time, as the graph

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sijia Li et al.

(a) AUC

(b) Recall

(c) Precision

(d) F1-score

Figure 6: Sensitivity analysis of TTAGN with different sequence lengths

(a) AUC

(b) Recall

(c) Precision

(d) F1-score

Figure 7: Model robustness study of TTAGN with different attention sizes

scale becomes larger, the gap between the models is further widened,
proving that TTAGN is more effective on large-scale transaction
graphs.

5.5 Sensitivity Analysis (RQ3)
To answer RQ3, we further evaluate the performance of TTAGN
with respect to the transaction sequence length and edge2node
attention size.

Figure 6 presents four metrics scores of TTAGN on three datasets
when varying the fixed value of transaction sequence length. The
variable-length is also used as a parameter on the far right of the
axis. Specifically, we can clearly find that (1) as the fixed value of
transaction sequence length increases, combining the four evalu-
ation metrics, the model has achieved enhanced performance on
all datasets; (2) Sometimes shorter sequences perform better than
the longer sequences, which may be caused by information redun-
dancy; (3) When using the shortest transaction sequence training
on the three datasets, there is a large gap compared with the longer
transaction sequences; (4) Variable-length performs better than
all fixed-length parameters. These phenomena reflect the impor-
tance of temporal transaction information and also show that this
parameter is unstable, which increasing brings both effective in-
formation and information redundancy. Therefore, our method
TTAGN proposes the input variable-length transaction sequence,
which ensures the effectiveness of the model and also enhances the
robustness of the model.

As for edge2node’ attention size, by providing different attention
sizes during training, the model sensitivity results are presented
in Figure 7. We can observe that, under each attention size setting
(1) TTAGN always achieves similar performance in terms of four
evaluation metrics on all datasets, which is still the best perfor-
mance compared with other methods in Table 2; (2) TTAGN can

still achieve relatively good performance when training with a small
attention size (e.g., ℎ = 2), which demonstrates the strong capability
of its infrastructure. For example, on 𝐷3 dataset, the Recall barely
drops 0.06 if we change the attention size from ℎ = 10 to ℎ = 2. There-
fore, we conclude that TTAGN is robust to the edge2node’ attention
size and consistently outperforms other compared methods.

6 CONCLUSION
In this work, we propose a Temporal Transaction Aggregation
Graph Network (TTAGN) to enhance the performance of phishing
scams detection on Ethereum. TTAGN fully models and captures
the temporal relationship of historical transaction records between
nodes, which helps effectively extract edge representations of the
Ethereum transaction network. Then, TTAGN aggregates the ob-
tained effective edge representations to fuse topological interactive
relationships into nodes, generates trading features which enrich
nodes’ characteristics and realize their strong representation abil-
ity. Finally, combining the three types of features, we improve
the performance of Ethereum phishing scams detection. Extensive
experiments indicate that TTAGN’s performance and practical-
ity outperform state-of-the-art algorithms by significant margins.
We hope that our work demonstrates the serious threat of phish-
ing scams on Ethereum and calls for effective countermeasures
deployed by the blockchain community.

ACKNOWLEDGMENTS
This work is supported by The National Key Research and Devel-
opment Program of China No.2020YFB1006100 and the Strategic
Priority Research Program of Chinese Academy of Sciences, Grant
No.XDC02040400. We would like to thank the anonymous review-
ers for their valuable comments.

25102030variableSequence length0.850.900.95AUCD3D2D125102030variableSequence length0.650.700.750.800.850.90RecallD3D2D125102030variableSequence length0.600.650.700.750.800.85PrecisionD3D2D125102030variableSequence length0.700.750.800.85F1-scoreD3D2D1246810Attention size0.850.900.951.00AUCD3D2D1246810Attention size0.800.850.90RecallD3D2D1246810Attention size0.650.700.750.800.850.90PrecisionD3D2D1246810Attention size0.750.800.850.90F1-scoreD3D2D1TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

REFERENCES
[1] Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski,
and Alexander J Smola. 2013. Distributed large-scale natural graph factorization.
In Proceedings of the 22nd international conference on World Wide Web. 37–48.
[2] Israa Alqassem, Iyad Rahwan, and Davor Svetinovic. 2018. The anti-social system
properties: Bitcoin network data analysis. IEEE Transactions on Systems, Man,
and Cybernetics: Systems 50, 1 (2018), 21–31.

[3] N Anita and M Vijayalakshmi. 2019. Blockchain security attack: a brief survey. In
2019 10th International Conference on Computing, Communication and Networking
Technologies (ICCCNT). IEEE, 1–6.

[4] Mikhail Belkin and Partha Niyogi. 2001. Laplacian eigenmaps and spectral

techniques for embedding and clustering.. In Nips, Vol. 14. 585–591.

[5] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. Grarep: Learning graph rep-
resentations with global structural information. In Proceedings of the 24th ACM
international on conference on information and knowledge management. 891–900.
[6] chainalysis. [n. d.]. 2021-Crypto-Crime-Report. https://go.chainalysis.com/2021-

Crypto-Crime-Report.html. Accessed February, 2021.

[28] Zeli Wang, Hai Jin, Weiqi Dai, Kim-Kwang Raymond Choo, and Deqing Zou.
2021. Ethereum smart contract security research: survey and future research
opportunities. Frontiers of Computer Science 15, 2 (2021), 1–18.

[29] Gavin Wood et al. 2014. Ethereum: A secure decentralised generalised transaction

ledger. Ethereum project yellow paper 151, 2014 (2014), 1–32.

[30] Jiajing Wu, Qi Yuan, Dan Lin, Wei You, Weili Chen, Chuan Chen, and Zibin
Zheng. 2020. Who are the phishers? phishing scam detection on ethereum via
network embedding. IEEE Transactions on Systems, Man, and Cybernetics: Systems
(2020).

[31] Qi Yuan, Baoying Huang, Jie Zhang, Jiajing Wu, Haonan Zhang, and Xi Zhang.
2020. Detecting phishing scams on ethereum based on transaction records. In
2020 IEEE International Symposium on Circuits and Systems (ISCAS). IEEE, 1–5.

[7] Huashan Chen, Marcus Pendleton, Laurent Njilla, and Shouhuai Xu. 2020. A
survey on ethereum systems security: Vulnerabilities, attacks, and defenses. ACM
Computing Surveys (CSUR) 53, 3 (2020), 1–43.

[8] Liang Chen, Jiaying Peng, Yang Liu, Jintang Li, Fenfang Xie, and Zibin Zheng.
2020. Phishing scams detection in ethereum transaction network. ACM Transac-
tions on Internet Technology (TOIT) 21, 1 (2020), 1–16.

[9] Weili Chen, Xiongfeng Guo, Zhiguang Chen, Zibin Zheng, and Yutong Lu. 2020.
Phishing Scam Detection on Ethereum: Towards Financial Security for Blockchain
Ecosystem.. In IJCAI. 4506–4512.

[10] Palash Goyal and Emilio Ferrara. 2018. Graph embedding techniques, applications,
and performance: A survey. Knowledge-Based Systems 151 (2018), 78–94.
[11] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for
networks. In Proceedings of the 22nd ACM SIGKDD international conference on
Knowledge discovery and data mining. 855–864.

[12] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation
learning on large graphs. In Proceedings of the 31st International Conference on
Neural Information Processing Systems. 1025–1035.

[13] Shuichiro Haruta, Hiromu Asahina, and Iwao Sasase. 2017. Visual similarity-
based phishing detection scheme using image and CSS with target website finder.
In GLOBECOM 2017-2017 IEEE Global Communications Conference. IEEE, 1–6.

[14] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural

computation 9, 8 (1997), 1735–1780.

[15] Artsiom Holub and Jeremiah O’Connor. 2018. COINHOARDER: Tracking a
ukrainian bitcoin phishing ring DNS style. In 2018 APWG Symposium on Electronic
Crime Research (eCrime). IEEE, 1–5.

[16] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,
Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting
decision tree. Advances in neural information processing systems 30 (2017), 3146–
3154.

[17] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph

convolutional networks. arXiv preprint arXiv:1609.02907 (2016).

[18] Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. arXiv

preprint arXiv:1611.07308 (2016).

[19] Dan Lin, Jiajing Wu, Qi Yuan, and Zibin Zheng. 2020. Modeling and understanding
ethereum transaction records via a complex network approach. IEEE Transactions
on Circuits and Systems II: Express Briefs 67, 11 (2020), 2737–2741.

[20] Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, and Wenwu Zhu. 2016. Asym-
metric transitivity preserving graph embedding. In Proceedings of the 22nd ACM
SIGKDD international conference on Knowledge discovery and data mining. 1105–
1114.

[21] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning
of social representations. In Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery and data mining. 701–710.

[22] Sam T Roweis and Lawrence K Saul. 2000. Nonlinear dimensionality reduction

by locally linear embedding. science 290, 5500 (2000), 2323–2326.

[23] Ozgur Koray Sahingoz, Ebubekir Buber, Onder Demir, and Banu Diri. 2019. Ma-
chine learning based phishing detection from URLs. Expert Systems with Applica-
tions 117 (2019), 345–357.

[24] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei.
2015. Line: Large-scale information network embedding. In Proceedings of the
24th international conference on world wide web. 1067–1077.

[25] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in neural information processing systems. 5998–6008.
[26] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint
arXiv:1710.10903 (2017).

[27] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network em-
bedding. In Proceedings of the 22nd ACM SIGKDD international conference on
Knowledge discovery and data mining. 1225–1234.

