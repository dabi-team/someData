2
2
0
2

g
u
A
1
3

]

R
C
.
s
c
[

2
v
6
4
0
2
1
.
8
0
2
2
:
v
i
X
r
a

1

A Platform-Free Proof of Federated Learning
Consensus Mechanism for Sustainable Blockchains
Yuntao Wang†, Haixia Peng‡, Zhou Su†∗, Tom H Luan§, Abderrahim Benslimane¶, and Yuan Wu‡‡
†School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China
‡School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China
§School of Cyber Engineering, Xidian University, Xi’an, China
¶Laboratory of Computer Sciences, Avignon University, France
‡‡State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China
∗Corresponding author: Zhou Su (zhousu@ieee.org)

federated learning (FL)

Abstract—Proof of work (PoW), as the representative con-
sensus protocol for blockchain, consumes enormous amounts
of computation and energy to determine bookkeeping rights
among miners but does not achieve any practical purposes.
To address the drawback of PoW, we propose a novel energy-
recycling consensus mechanism named platform-free proof of
federated learning (PF-PoFL), which leverages the computing
power originally wasted in solving hard but meaningless PoW
tasks.
puzzles to conduct practical
Nevertheless, potential security threats and efﬁciency concerns
may occur due to the untrusted environment and miners’ self-
interested features. In this paper, by devising a novel block
structure, new transaction types, and credit-based incentives, PF-
PoFL allows efﬁcient artiﬁcial intelligence (AI) task outsourcing,
federated mining, model evaluation, and reward distribution in
a fully decentralized manner, while resisting spooﬁng and Sybil
attacks. Besides, PF-PoFL equips with a user-level differential
privacy mechanism for miners to prevent implicit privacy leakage
in training FL models. Furthermore, by considering dynamic
miner characteristics (e.g., training samples, non-IID degree, and
network delay) under diverse FL tasks, a federation formation
game-based mechanism is presented to distributively form the
optimized disjoint miner partition structure with Nash-stable
convergence. Extensive simulations validate the efﬁciency and
effectiveness of PF-PoFL.

Index Terms—Blockchain, AI-inspired consensus, federated

learning, dynamic pool formation.

I. INTRODUCTION

Blockchain, as a disruptive next paradigm innovation, of-
fers a decentralized solution to immutably store information,
transparently execute transactions, and automatically establish
trust in open and trustless environments [1]–[4]. In blockchain
systems, the consensus protocol is the core component which
determines the system scalability, security, and consistency.
The goal of consensus protocols is to ensure that all involved
entities agree on an identical and consistent ledger without
the need for a central authority. The representative consensus
protocol is the proof of work (PoW) [5], which is widely
adopted in various blockchains such as Bitcoin and Ethereum.
In PoW, miners compete for the bookkeeping rights and
rewards by solving a cryptographic puzzle (which is hard to

This work was supported in part by NSFC (nos. U20A20175, U1808207),
the Central Universities, FDCT

the Fundamental Research Funds for
0162/2019/A3 and SKL-IOTSC(UM)-2021-2023.

solve but easy to validate) through brute-forcing, i.e., mining
[6]. Unfortunately, the mining process is computation-hungry
and consumes an enormous amount of computation and energy
in solving meaningless PoW puzzles, controversial
to the
trend of sustainable and environment-friendly technology. As
reported,
the annual electricity consumption of Bitcoin is
comparable to that of Thailand, and the electricity that a single
Bitcoin transaction consumes can power a U.S. household for
about 3 weeks [7].

To mitigate the energy waste in PoW, research efforts have
been made from two aspects: energy saving and energy recy-
cling. Proof of stake [8] and proof of space [9] are two typical
energy-saving alternatives, which conserve energy by reducing
mining difﬁculty for wealthy stakeholders who invest more
in cryptocurrency or storage space. An explicit side effect
of these methods is the non-democracy and corresponding
Matthew’s effects as rich participants have a higher chance
for bookkeeping to earn more rewards. Meanwhile, there still
exists “useless” resource waste on computation or storage in
reaching consensus, remaining far from being really “useful”.
Another line of work studies the energy-recycling consensus
approaches, where the wasted energy in solving hard but
meaningless puzzles in PoW is recycled to perform practical
useful works, known as proof of useful work (PoUW) [10].
In PoUW, PoW mining tasks can be replaced with practical
computational problems such as searching prime chains [11],
image segmentation [12], and all-pairs shortest path [10],
which offers a suitable substitution of PoW for better sus-
tainability of the blockchain system. Recently, various works
have attempted to design PoUW mechanisms using machine
learning as the basis for useful tasks [13], [14]. Essentially,
similar to PoW mining, training artiﬁcial intelligence (AI)
models usually costs considerable computing power and time
while its veriﬁcation process is much easier. Besides,
the
current trend of going deeper in AI models inevitably results
in the ever-increasing demand for computing power. Thereby,
it is natural to reinvest the computation power in PoW to train
valuable AI models and employ trained models as proofs for
completing the consensus.

However, training a qualiﬁed AI model requires consid-
erable training data as “fuel”, and a single miner or the
task initiator may lack sufﬁcient data samples on its device.

 
 
 
 
 
 
2

Fig. 1. Architecture of the PoFL scheme [15]. ((cid:172): Requesters upload FL
tasks with rewarding information to the FL platform; (cid:173): The FL platform
maintains a task queue and selects an unﬁnished task to start PoUW; (cid:174): All
members in a mining pool train the requested FL model and each pool uses
the trained model as a proof; (cid:175): The blockchain performs model validation
and ranking; (cid:176): The model with the highest performance is delivered to the
platform and the pool who produces it earns the mining reward.)

Moreover, privacy concerns make it risky or even illegal in
centralizing data samples from data owners (i.e., miners) for
model training [3]. As an attempt to fully unleash the power
of AI using distributed data, Qu et al. [15] recently intro-
duced a general proof of federated learning (PoFL) consensus
framework by reinvesting miners’ computing power in solv-
ing meaningless PoW puzzles to train high-quality federated
learning (FL) models. FL is a distributed AI paradigm which
usually contains (i) a crowd of data owners (e.g., miners)
who cooperatively train an AI model by sharing intermediate
gradients and model parameters instead of their local datasets,
and (ii) a central curator for learning coordination. Under
FL, miners’ training datasets are kept on local devices and
only the locally computed model updates are shared, thereby
greatly alleviating data privacy concerns. As shown in Fig. 1,
in PoFL [15], users ﬁrst outsource their FL tasks to the
online third-party platform (e.g., Kaggle and Codalab), then
all the members within a mining pool collaboratively train the
requested FL model before the deadline, and ﬁnally different
pools compete to earn rewards by using the trained models as
proofs.

Although the work [15] has made signiﬁcant progress, there
are still signiﬁcant challenges that remain to be tackled. First,
the working of PoFL in [15] heavily depends on the trusted
third-party platform which hosts FL tasks issued by requesters,
determines the order of tasks for mining, and delivers re-
wards to the winning pool in the race. The malfunction or
breakdown of the platform can cause a system failure, which
is essentially a single point of failure (SPoF). Besides, the
platform may collude with certain mining pools and disclose
the FL tasks to them in an early stage, so that they can
start training before others and gain beneﬁts. Therefore, it
remains a concern to design a robust and fully decentralized
PoFL scheme which gets rid of the central platform. Next,
the work [15] directly leverages off-the-shelf pooled-mining
structures in PoW-based blockchains to train FL models.
Different from the homogeneous PoW tasks, miners usually
have distinct training samples and non-IID degrees and cor-
respondingly distinct contributions when conducting different

Fig. 2. Architecture of our PF-PoFL scheme. ((cid:172): Requesters upload FL tasks
with rewards to the blockchain which maintains an unﬁnished task queue; (cid:173):
Miners dynamically form the optimized pool structure to perform PoUW for
an unﬁnished task; (cid:174): All members in a pool train the requested FL model
in a differentially private manner and each pool uses the trained model as
a proof; (cid:175): Selected validators in blockchain perform model validation and
ranking for the uncompleted task; (cid:176): The model with the highest performance
is delivered to its requester and the pool who produces it earns the mining
reward.)

FL tasks under PoFL, causing a more complex pool formation
problem. There exists a challenge in dynamically forming
optimized pooled structures with stable miner-pool association
for diverse FL tasks. Furthermore, in the fully distributed
and autonomous blockchain system, well-designed incentives
for self-interested miners are benign impetuses to build a
healthy consensus system with enhanced efﬁciency. Due to the
intrinsic selﬁshness and behavior diversity of miners, how to
offer precise incentives to heterogenous miners for optimized
consensus process is a challenging issue.

To address these issues, we propose a novel platform-free
proof of federated learning (PF-PoFL) scheme to build a
sustainable and robust blockchain ecosystem by removing the
central platform and forming a dynamically optimized pooled
structure for AI model training. As shown in Fig. 2, PF-
PoFL involves three types of blockchain nodes: (i) requesters
trainers (consisting of
that produce FL tasks, (ii) model
curators and miners) that train FL models within a pool,
and (iii) validators (selected from miners) that are in charge
of model rankings and proposing new blocks. Speciﬁcally,
requesters directly announce their FL tasks with rewards to
the blockchain, and a group of validators collectively maintain
an ordered queue of unﬁnished tasks. For an unﬁnished task,
a crowd of miners with distinct training data size, non-IID
degree, and network delay dynamically form a stable pooled
structure via the federation formation game. Next, coordinated
by the corresponding curator, different pools compete to train
the FL model and the pool with the best model earns the task
reward via the consensus process. The validators are evenly
compensated with the transaction fees. The main contributions
of this work are summarized below.

• Sustainable and robust blockchain framework. We pro-
pose PF-PoFL, an energy-recycling consensus framework
which leverages the computing power of blockchain for
efﬁcient AI task outsourcing and reward distribution in a
fully decentralized manner. Under PF-PoFL, we devise a

Online platformblockchain ledgerpool 3pool 1pool 2modeltaskmodel validation & block buildingtask& rewardmodel with highest performance①②③③③④⑤⑥minerpool / federationAI modelcurator of the poolrequesterP2P networktask queue③model trainingblockchain ledger④pool 3pool 1pool 2P2P network②③optimized pool formationmodel training③③③minerrequesterpool orfederationAI modelcurator of the poolpublish task①⑤model with highest performancemodel validation & block building task queuenovel block structure, new transaction types, and credit-
based incentives to support FL model ranking and realize
efﬁcient consensus in the blockchain.

• User-level privacy-preserving federated mining. We en-
hance the record-level differential privacy (DP) by de-
signing a user-lever DP (UDP) algorithm to prevent the
leakage of a user’s whole data records during federated
mining. Then, we rigorously analyze the sensitivity bound
of a global aggregation and prove the federated mining
process satisﬁes ((cid:15), δ)-UDP by adapting the variance of
Gaussian noise added by curators.

• Game-theoretical optimized pool formation. We formu-
late the disjoint pool formation problem for performing
distinct FL tasks as a social welfare maximization prob-
lem, and propose a distributed federation formation game-
based algorithm, which converges to Nash-stable equilib-
rium. By introducing the switch gain, both miners and
pools execute an iterative two-sided matching process,
where each miner decides its switch strategy to switch to
the optimal pool while each pool decides its admission
strategy to accept the optimal miner.

• Extensive simulations for performance evaluation. We
evaluate the efﬁciency and effectiveness of PF-PoFL us-
ing extensive simulations. Numerical results show that the
PF-PoFL can attain not only stable blockchain throughput
and desirable model performance with UDP guarantees,
but also lower computation cost in reaching consensus
and higher efﬁciency in federated mining, compared with
conventional approaches.

The remainder of the paper is organized as follows. In
Section II, we review the related works. Section III introduces
the system model. Section IV provides a detailed construction
of the PF-PoFL framework. We analyze the game-theoretical
stable pool formulation process in Section V. We evaluate the
performance of our proposed framework in Section VI. Section
VII concludes this paper.

II. RELATED WORKS

In the literature, there has been an increasing interest in
designing energy-recycling consensus mechanisms by substi-
tuting the hash puzzles in PoW with valuable works which
are hard to solve but easy to verify. Initially, early efforts
focus on replacing the PoW nonce with practical computa-
tional problems. Ball et al. [10] proposed a novel concept
proof of useful work (PoUW) to replace the PoW mining
with mathematic problems such as all-pairs shortest path and
orthogonal vectors. King [11] proposed a novel cryptocurrency
named Primecoin to generate scientiﬁc value in the mining
process, where miners are required to search long prime
chains as proofs of work with difﬁculty adjustability and
non-reusability. Shoker [16] devised a sustainable consensus
protocol named proof of exercise, in which miners choose to
solve matrix-oriented computation issues hosted on a third-
party platform instead of calculating hashes in PoW. Daian
et al. [17] developed PieceWork to mitigate the energy waste
in PoW by solving outsourced tasks such as denial-of-service
(DoS) defense and spam prevention.

3

Recently, many attempts have been made in the integration
of AI and blockchain by exploiting the computing capacity
of blockchain for AI model training. Li et al. [12] proposed
a PoUW mechanism to reuse the wasted computing power
in PoW for deep learning (DL)-based biomedical
image
segmentation to help clinical diagnosis. Chenli et al. [14]
developed a proof of deep learning (PoDL) consensus protocol
by forcing miners to perform DL training and employing the
trained models as proofs to earn rewards for outsourced DL
tasks. Lan et al. [13] devised an efﬁcient proof of learning
consensus mechanism to ensure data integrity and prevent
malicious behaviors without sacriﬁcing model performance.
Nevertheless, a single user may lack sufﬁcient training data,
and the centrally aggregated training/test dataset for public
training/veriﬁcation may sacriﬁce user privacy and
model
frustrate the adoption of blockchain.

Distinguished from the above works, our work combines
blockchain and AI under the FL paradigm in a fully decen-
tralized manner with privacy preservation and dynamic pool
formation functions.

III. SYSTEM MODEL

We introduce the system model

in this section, which
consists of the blockchain model and adversary model. Then,
we discuss the desired properties of PF-PoFL.

A. Blockchain Model

The proposed decentralized blockchain network in this
paper mainly consists of three types of nodes: requesters,
trainers, and validators, as illustrated in Fig. 3.

• Requesters. Every node in the blockchain can act as a task
requester to publish its FL tasks (e.g., semantic analysis
and biomedical image recognition) to the blockchain plat-
form with speciﬁc completion deadline and performance
requirements, as well as the corresponding rewards as
incentives. Let R = {1, · · · , r, · · · , R} be the set of task
requesters in the blockchain network. The set of published
tasks and unﬁnished tasks in the blockchain are denoted
as T = {1, · · · , t, · · · , T } and Tu = {1, · · · , τ, · · · , Tu},
respectively.

• Trainers. Analogy to the pooled-mining in PoW-based
blockchains such as Bitcoin, a set of model trainers in PF-
PoFL can form the pooled (or federated) structure [15],
which is featured with intra-pool cooperation and inter-
pool competition. A set of pools or federations are formed
in the blockchain network, and the set of which is deﬁned
as (cid:61) = {(cid:61)1, · · · , (cid:61)j, · · · , (cid:61)J }. In each pool/federation
(cid:61)j ∈ (cid:61) managed by the corresponding curator φj, a
group of miners, denoted as Mj = {1, · · · , m, · · · , Mj},
cooperatively train a qualiﬁed FL model for an unﬁnished
task τ ∈ Tu within the pool, and compete to earn the task
reward with other pools in (cid:61)\{(cid:61)j}.

• Validators. In PF-PoFL, validators are a group of con-
sensus nodes, denoted as V = {1, · · · , v, · · · , V }, which
are responsible for transaction veriﬁcation and new block
construction. An ordered queue of uncompleted tasks,
denoted as (cid:102)Tu = ordered(Tu), is collectively maintained

4

After FL model training, malicious pools may submit multiple
meaningless models (to waste system resources) or send the
same model multiple times (to earn more beneﬁts), using
Sybil identities. Besides, adversarial validators may create an
arbitrary number of Sybil pseudonyms to inﬂuence the process
of reaching an agreement on blockchain ledgers [18].

Untrusted Third-Party Platform. In traditional PoFL [15],
the central FL platform operated by third parties is responsible
for hosting and ranking the FL tasks to be performed, as well
as the payment delivery, whose malfunction or breakdown can
result in a SPoF. The malicious platform may also collude with
part of miners to conduct market manipulation by revealing
FL tasks to them in advance. In addition, the platform may
be compromised by attacks such as DDoS, causing leakage of
miners’ sensitive information that is stored in it.

Implicit Privacy Leakage. According to [19]–[21], user
privacy (e.g., the participation status in a task and the data
used for training) may still be leaked unconsciously under FL
in sharing raw local updates through differential attacks and
advanced inference attacks.

C. Desired Properties

The design goal of the PF-PoFL is to achieve the following

desirable properties simultaneously.

1) Fully decentralized operation. The whole process of
PF-PoFL including FL task outsourcing, AI model training,
model evaluation and ranking, and reward distribution should
be operated in a fully decentralized paradigm.

2) Dynamically optimized pool structure. PF-PoFL aims
for an optimized pool structure to competitively train FL tasks
by considering dynamic user characteristics such as miners’
cooperation and competition.

3) Spooﬁng and Sybil prevention. PF-PoFL should resist

the Sybil identities and defend against spooﬁng attacks.

4) User-level differential privacy (UDP). Existing works
in FL mainly focus on the record-level differential privacy
(RDP) [22]–[24], namely, whether a certain data sample is
used for training. Different from them, we focus on the user-
level privacy protection, which offers stronger provisions to
protect the whole data samples of a user, i.e., the learned model
does not leak whether a user participates in FL or not.

IV. PF-POFL: PLATFORM-FREE PROOF OF FEDERATED
LEARNING FRAMEWORK

A. Design Overview

The workﬂow of PF-PoFL consensus framework consists of
four successive phases: (i) FL task publication, (ii) FL model
training, (iii) model ranking and rewarding, and (iv) block
building and commit.

• FL task publication. Requesters publish their FL tasks T
with rewards to the blockchain platform which maintains
an ordered queue of uncompleted tasks (cid:102)Tu.

• Federated mining with UDP. A group of trainers form
an optimized pool/federation structure (cid:61) and choose an
uncompleted task τ ∈ (cid:102)Tu to perform model training
within the pool (cid:61)j ∈ (cid:61) under FL in a privacy-preserving

Fig. 3. Entities and workﬂow of PF-PoFL.

by validators and is updated before the block height
grows. Validators also perform the evaluation and ranking
operations for released FL models, which are trained by
each pool, via the consensus process.

In the blockchain network, a node can simultaneously
perform all three roles or two of them. The set of all nodes
in blockchain is denoted as N = {1, · · · , n, · · · , N }. The
blockchain ledger B is composed of a series of growing hash-
chained blocks, i.e., B = {Bi ← Bi−1 ← · · · ← B0}, where
B0 is called the genesis block, and Bi is the latest block with
height i. Speciﬁcally, Bi contains two parts (i.e., block header
and block body) and can be denoted by

(cid:110)

Bi =

Hash(Bi−1)||Tstamp||rooti||metai
(cid:123)(cid:122)
(cid:125)
(cid:124)
header

|| T X i
(cid:124)(cid:123)(cid:122)(cid:125)
body

(cid:111)
.

(1)

In Eq. (1), T X i is a set of timestamped transactions in the
block, which is organized into a Merkle tree structure with
root value rooti. Hash(Bi−1) is a cryptographic hash of the
previous block to maintain a chained structure. Tstamp is
the timestamp for block creation. metai is the metadata in
validating and ranking trained FL models, which ensures the
validity of block Bi (details are shown in Sect. IV-F). The
metadata metai can be analogical to the random nonce in
Bitcoin, which serves a veriﬁable proof of the work.

B. Adversary Model and Assumptions

In the system, model trainers (i.e., the curator φj and miners
in Mj) in each pool (cid:61)j ∈ (cid:61) are assumed to be semi-honest.
In other words, they will honestly obey the FL procedure in AI
model training, while the miners may plagiarize others’ trained
FL models and the curator may be curious about miners’
privacy information and refuse to pay at last. Besides, the
blockchain platform is assumed to be secure and its stored
transactions are immutable and non-repudiable. Particularly,
the following four kinds of attacks are considered:

Spooﬁng Attack. The model trainers may carry out spoof-
ing attacks to gain high illegal proﬁts. For example, they may
publish a perfect model by training on the released testing
data to win the competition with paltry cost. They could also
plagiarize the FL models trained by other pools [15].

Sybil Attack. During FL model training, malicious trainers
may launch Sybil attacks by submitting multiple meaningless
local updates (to deteriorate model performance) or uploading
the same local update multiple times (to earn more beneﬁts).

RequesterBlockchain PlatformTrainerValidatorOff-chain IPFS④ send model tx① publish FL task⑦ rank FL models & commit block⑤ release test data② select FL task③ federated mining⑥ download model & testtask queuetest datatraining datamanner. Different pools compete to train and submit the
best FL model before the task deadline.

• Model ranking and rewarding. The validators mutually
execute the model ranking contract to evaluate and rank
the trained FL models. Besides, validators perform the
block rewarding contract to automatically enforce ﬁnan-
cial rewarding and update credits for participants.

• Block building and commit. Each validator executes the
credit-based Algorand Byzantine agreement protocol to
efﬁciently reach consensus on the new block to be added
into the blockchain with deterministic ﬁnality.

In PF-PoFL,

three types of blockchain transactions are

implemented as follows.

• Payment Transaction refers to transferring or redeeming
the cryptocurrency from one node to another node for task
payment, participation fee, etc.

• Task Publication Transaction in which a task requester

proposes its FL tasks for learning competition.

• FL Model Transaction in which a training pool uploads
its trained FL model as a solution for a particular FL task.

B. System Initialization

For system initialization, a bilinear pairing e : G1 × G2 →
G3 is chosen, where G1, G2, and G3 are groups of prime order
q. The generators of G1 and G2 are g1 and g2, respectively.
Two hash functions H1 : {0, 1}∗ → G2 and H2 : {0, 1}∗ →
Zq are selected as random oracles. Taking a security parameter
ϕ as an input, the bilinear group generator G(ϕ) outputs the
system parameters as params = (q, g1, g2, G1, G2, G3, e).
Both G(·) and params are recorded in the genesis block.

Based on these public information, each participant n ∈ N
R←− Zq and
sets up its secret key in the blockchain via skn
, where R←− represents
generates its public key via pkn ← gskn
randomly sampling. The wallet address of each node n can be
computed as wan ← H2(pkn). Each blockchain node n stores
(skn, pkn, wan) into its local tamper-proof device.

2

C. FL Task Publication

In PF-PoFL, the machine learning problems such as sen-
timent analysis and image classiﬁcation are produced by the
requesters along with the corresponding rewards. Speciﬁcally,
each requester r ∈ R can publish an AI task t ∈ T at any time
by sending a task publication transaction txt to the blockchain.
The detailed transaction format is as below.

• Inputs:

– Task reward pt and task hosting fee ξ1 of task t;
– Initial AI model parameters Θt(0);
– Performance metrics ψ to evaluate model performance
such as accuracy;
– The testing release block height it, i.e., the deadline
(measured by block height [25]) to release test dataset
Dtest;
– Cryptographic hash of
Hash(Dtest).

the test dataset dID ←

• Outputs: Task publication transaction txt:

5

txt =

(cid:110)

txID
t

, pt, ξ1, Θt(0), ψ, it, dID, Tstamp, pkr, Sigskr (txID
t )

(cid:111)
,
(2)

t

where txID
is the unique transaction identiﬁer, i.e., hash of
the transaction txt. Tstamp is the timestamp for transaction
generation. Sigskr (txID
t ) ← H1(txt)skr is the digital signature
of requester r on the transaction. A small task hosting fee ξ1
is utilized to encourage the validators to package txt into the
block and prevent malicious requesters from sending multiple
meaningless tasks to cause a DoS.

The task publication transaction txt also contains a payment
transaction in which the requester transfers the task reward
pt and task hosting fee ξ1 to an escrow address esAdd
under public supervision. The formal transaction format is as
follows.

• Inputs: Task identiﬁer txID
• Outputs: Payment transaction txp:

t

and user identiﬁer pkr.

txp =

(cid:110)

txID

p , txID
t

, pt, ξ1, Tstamp, pkr, Sigskr (txID
p )

(cid:111)
,

(3)

where txID
is the identiﬁer (i.e., hash) of the transaction txp.
p
Here, if the requester fails to release the test dataset for task
t after the testing release block height it, it will lose these
cryptocurrencies.

After receiving the task and payment transactions, validators
mutually validate each of them via the function verif y(txt)
by checking: (i) the task requester r holds enough funds to pay
the task hosting fee ξ1 and reward pt; and (ii) the difference
between the testing release block height it and the current
block height i is positive and larger than the minimum model
training period preset by the system. If veriﬁcation passes, we
have verif y(txt) = true, otherwise verif y(txt) = f alse.
The invalid transactions are discarded and only valid ones are
forwarded to the network.

For all valid tasks to be completed, each validator v ∈ V
independently ranks these tasks in ascending order of times-
tamp and maintains a ready queue (cid:102)Tu of uncompleted tasks.
Generally, the task reward reﬂects the importance and urgency
of a machine learning task. As nodes in blockchain are selﬁsh
and rational, it is reasonable to assume that the priority of
each running task t for miners is determined by joint effect of
the announced task reward pt and the remaining task training
duration it − i. In other words, miners prefer FL tasks with
higher rewards and longer remaining training duration. For the
case that multiple tasks have the same priority, these tasks are
ordered by their publication timestamp, i.e., the earlier-arrived
one gets a better ranking. After reaching an agreement among
validators, the ready queue (cid:102)Tu is updated and recorded in the
blockchain. In practice, we further implement a soft handover
mechanism in which the PF-PoFL will be rolled back to PoW
once the ready queue is empty.

D. Federated Mining with UDP

Currently, there is a trend of pooled-mining in blockchain,
which has a similar clustering structure with FL [15]. In this
work, we study PF-PoFL under the pooled-mining structure,
as shown in Fig. 4. The detailed federated mining process
consists of the following steps.

6

FL, the curator applies a randomized function F to add the
UDP noise to the sum of scaled local updates.

The above training process is repeated until a desirable
accuracy of the global model is attained or the communication
round reaches its maximum value. In the following, we ﬁrst
give the deﬁnition of UDP and then present the detailed UDP
implementation mechanism.

Deﬁnition 1. (User-level Differential Privacy (UDP)): A
randomized function F : D → R satisﬁes ((cid:15), δ)-UDP if for
any two user-adjacent datasets y, y(cid:48) ∈ D and for any subset
of outputs Y ⊆ R, the following inequality holds:

Fig. 4.

Illustration of federated mining with UDP in a pool under FL.

Pr [F (y) ∈ Y] ≤ e(cid:15)Pr [F (y(cid:48)) ∈ Y] + δ,

(6)

Step 1: Task selection & pool formation. Each trainer can
pick any task τ ∈ (cid:102)Tu published on the blockchain which is
still in its training phase (i.e., i ≤ iτ ). Let Mτ ⊆ M be
the set of trainers or miners that involve in training FL task
τ . All trainers in the set Mτ dynamically form an optimized
stable pooled structure (cid:61)∗ (details are shown in Sect. V) in
a distributed manner. For each pool (cid:61)j ∈ (cid:61)∗, a group of
trainers within the pool collaboratively train a qualiﬁed AI
model for that task under the FL paradigm using their private
data. Besides, in each pool (cid:61)j ∈ (cid:61)∗, a curator φj is randomly
selected from the pool members whose experienced network
latency is less than a predeﬁned threshold Dth. Distinguished
with the PoW protocol, in our PF-PoFL consensus protocol,
different mining pools can concurrently train on different FL
tasks that are in the training phase.

Step 2: FL model training with UDP within a pool. In
pooled-mining under FL, as depicted in Fig. 4, each pool
member (i.e., miner) computes the intermediate gradients (i.e.,
local model update) of the current global model based on
its local dataset and uploads them to the curator (i.e., pool
manager) for periodic global aggregation (i.e., global model
update). Let Ψglobal
be the number of communication rounds
in training task τ . Initially, each miner in pool (cid:61)j initializes its
local model parameters as the initial model parameters Θt(0)
downloaded from the transaction txτ . At k-th communication
round (k = 1, 2, · · · , Ψglobal
), it consists of a parallel local
training stage on miners followed by a global aggregation and
perturbation stage on the curator.

j,τ

j,τ

1) Local training at miner’s side. After receiving the previ-
ous global model (cid:98)Θ(k − 1), each miner m ∈ (cid:61)j individually
calculates its local model Θm(k) using its local dataset via
mini-batch stochastic gradient descent (SGD) with learning
rate η, i.e.,

Θm(k) ← (cid:98)Θ(k − 1) − η∇L(cid:0)

(cid:98)Θ(k−1)(cid:1),

(4)

where ∇L is the gradient of loss function L(.) on the mini-
batch. Then miner m calculates the local updates by

∆Θm(k) ← Θm(k) − (cid:98)Θ(k − 1),

(5)

and uploads ∆Θm(k) to the curator.

where D and R are the domain (e.g., possible training datasets)
and range (e.g., possible trained global models) of F, respec-
tively. Two datasets y, y(cid:48) are user-neighboring if y can be
formed from y(cid:48) by removing or adding all data samples related
to a single miner.

Remark 1: In conventional record-level DP (RDP) mecha-
nisms [22]–[24], the datasets y, y(cid:48) are deﬁned to be record-
neighboring, i.e., y can be formed from y(cid:48) by removing or
adding a single data record. Instead of protecting a single
data sample of the miner, we design a UDP mechanism F to
protect the miner’s whole data samples in the training process.
As such, any adversary observing the published ﬁnal model
cannot deduce the participation of any speciﬁc miner and the
usage of any speciﬁc data samples in model training with
strong probability.

The Gaussian mechanism is adopted to design such function
F by sanitizing the sum of all updates with low utility
decrease. To enforce the bounded sensitivity of local updates,
the curator φj scales each local update by

∆ ˜Θm(k) ←

(cid:110)

∆Θm(k)
1, ||∆Θm(k)||2
A

(cid:111) .

max

(7)

Thereby, ||∆ ˜Θm(k)||2 ≤ A can be ensured, and the sen-
sitivity in the summing operation of all scaled updates is
upper bounded by A. According to [26], we choose A =
median{||∆Θm(k)||2 : m ∈ Mj ∪ {φj}}.

The Gaussian noise scaled to sensitivity A with zero mean,
i.e., G(0, σ2A2), is added to the sum of the scaled updates to
prevent individual privacy leakage, i.e.,

(cid:98)Θ(k) ← (cid:98)Θ(k−1)+

1
Mj +1

|Mj ∪{φj }|
(cid:88)





m=1


∆ ˜Θm(k)+G(0, σ2A2)

,

(8)

where the parameter σ controls the scale of Gaussian noise.
After that, the curator φj delivers the perturbed global model
(cid:98)Θ(k) to all miners in the pool.

Step 3: FL model submission. Once pool (cid:61)j accomplishes
the FL learning process, the curator φj as the pool manager
submits its trained ﬁnal model Θj,τ by sending a FL model
transaction, whose formal format is as follows.

2) Global aggregation and perturbation at curator’s side.
The curator φj aggregates the local updates into a global model
Θ(k). Besides, to ensure user-level privacy preservation under

• Inputs:

– Hash of
Hash(Θj,τ );

the trained model Θj,τ ,

i.e., mID ←

  Local trainingGlobal aggregationLocal dataCurator (pool manager)MinerMinerMinerMinerUDP noise7

Algorithm 1 Model Ranking Contract

1: Input: 1) Task publication transaction txτ ; 2) Stable
transactions txm and

pooled structure (cid:61)∗; 3) Model
payment transactions txp related to the txτ .

2: Output: Model ranking mrListτ .
3: Extract {txID
τ , pτ , ξ1, ψ, iτ , dID} ← txτ .
4: If verif y(txτ ) = true, proceed to line 5, otherwise

terminate.

5: Add the model transactions txm and payment transactions

txp related to the txτ into the local memory pool.

6: for txm ∈ T X τ
7:

m do

Extract {mID, rs, ξ2, apkj} ← txm
If depositj ≥ ξ2 && im ≤ iτ , proceed to line 9,
otherwise terminate.
if the model Θj,τ identiﬁed by mID is successfully
downloaded from IPFS then

if the current height iτ ≤ i ≤ iτ + ∆i then

Download task τ ’s test dataset Dtest identiﬁed by
dID.
Evaluate performance score tsj,τ on the test
dataset Dtest.
Insert (cid:104)mID, tsj,τ (cid:105) into the local model ranking
mrListτ depending on the performance metric.

else if the current height i < iτ then

Wait until i ≥ iτ , i.e., reaching the test phase.

else if the current height i > iτ + ∆i then

Terminate.

end if

else

8:

9:

10:
11:

12:

13:

14:
15:
16:
17:
18:
19:

Set tsj,τ = “unevaluated(cid:48)(cid:48).
Insert (cid:104)mID, “unevaluated(cid:48)(cid:48)(cid:105) into mrListτ .

20:
21:
end if
22:
23: end for

Fig. 5.

Illustration of training and testing phases of a FL task in PF-PoFL.

– Reference score rs in model training phase;
– Participation fee ξ2;
– Aggregated public key apkj of trainers in the pool;
– Multi-signature MulSig(txID
• Outputs: FL model transaction txm:

m ) of trainers in the pool.

(cid:111)
,

(cid:110)

txm =

txID

m , txID

τ , mID, rs, ξ2, Tstamp, apkj, MulSig(txID
m )

(9)

where txID
m is the transaction identiﬁer. Notably, each mining
pool only submits the hash value of the trained AI model (i.e.,
mID) at this stage, to prevent from being plagiarized by other
rivals. Once the test dataset is released, all involved pools will
upload their trained models to an off-chain IPFS platform.
Besides, the training score rs can be a reference value of
model performance and is not considered for model ranking.
In addition, a small participation fee ξ2 is involved in txm
to defend against Sybil attacks conducted by malicious train-
ers/pools during/after FL model training. The participation fee
ξ2 is evenly assigned to all members within each pool, which
can be redeemed to the trainers whose model performance is
above a certain threshold in consensus model ranking. Similar
to transaction txτ , a payment transaction is involved, i.e.,

(cid:110)

txID

p , txID

txp =

m , ξ2, Tstamp, pkφj , Sigskφj
For trainers in pool (cid:61)j, their aggregated public key can be

(10)

(txID
p )

(cid:111)
.

derived as

apkj =

(cid:89)

H2(pkn,{pk1,··· ,pkMj ,pkφj })
n

.

pk

(11)

n∈Mj ∪{φj }

We deﬁne ςn ← H2(pkn, {pk1, · · · , pkMj , pkφj }) to ease the
formulation. For each pool member n ∈ Mj ∪ {φj}, its
signature can be computed as Sigskn (txID
m ) ← H1(txm)ςnskn .
Within a pool (cid:61)j, the multi-signature can be computed by
aggregating all members’ signatures [27], i.e.,

MulSig(txID

m ) ←

(cid:89)

Sigskn (txID

m ).

(12)

n∈Mj ∪{φj }

The correctness of multi-signature can be veriﬁed by checking
whether e(MulSig(msg), g−1

2 ) · e(H1(msg), apkj) = 1G3 .

Once the training phase for a task τ has elapsed (i.e., current
block height i ≥ iτ ), the task requester proceeds to submit the
corresponding test dataset Dtest identiﬁed by the previously
published hash value dID to the off-chain data storage. The
InterPlanetary File System (IPFS) [28] is adopted to serve as
the distributed off-chain data store, where data is stored in the
form of distributed ﬁles and is uniquely addressed through the
hash pointer of the data. After that, all involved pools proceed
to upload their FL models to the IPFS identiﬁed by the hash

value mID. The training and testing phases for a FL task are
depicted in Fig. 5. To prevent malicious trainers from training
a model using the released test data, the model transactions
are regarded as invalid if they are generated during the task
testing phase (i.e., the current block height is larger than the
testing release block height).

E. Model Ranking and Rewarding

For each FL task to be completed, the more trained models
associated with it, the higher chance for validators to earn
more participation fees. Consequently, for all running tasks
that are in the testing phase, it is reasonable to assume that
validators are incentivized to reach consensus on the most
urgent and proﬁtable task (i.e., the task with the largest number
of model transactions and shortest remaining test duration).
The validators in the set V independently execute the model
ranking contract and block rewarding contract to compute the
model ranking and complete ﬁnancial settlements. The model
ranking contract and block rewarding contract are shown in
Algorithms 1 and 2, respectively.

Step 1: Model ranking. As shown in Algorithm 1, each
validator v ∈ V ﬁrst validates the task publication transaction

Task publicationTask completiontraining phasetesting phaseblock height iτblock height iτ +ϫi block height i'Algorithm 2 Block Rewarding Contract

1: Input: 1) Task publication transaction txτ ; 2) Stable
pooled structure (cid:61)∗ and curator φj, ∀(cid:61)j ∈ (cid:61)∗; 3) Con-
sensus ranking mrListτ .

2: Output: Financial rewarding transactions and node cred-

its.

3: Transfer pτ → waj∗ from esAdd to the pool (cid:61)j∗ that

ranks best in mrListτ .

4: Transfer ξ1· 1

|V (cid:48)| + ξ2 · |(cid:61)∗\Wτ |

|V (cid:48)| → wav from esAdd to all

non-faulty validators in the set V (cid:48).

5: Transfer ξ2 → waj from esAdd to all pools in Wτ whose

model is performed above the preset threshold.

6: Update crev ← crev + χ1, ∀v ∈ V (cid:48).
7: Update crem ← crem + χ2, ∀m ∈ (cid:61)j∗ .
8: Update crem(cid:48) ← crem(cid:48) + χ3, ∀m(cid:48) ∈ (cid:61)j ⊆ Wτ , j (cid:54)= j∗.

txτ by using verif y(txτ ) deﬁned in Sect. IV-C (lines 3-4).
Then, validator v adds all model transactions txm and payment
transactions txp associated with the unﬁnished FL task τ ∈ (cid:102)Tu
into its memory pool (line 5). For each model transaction
txm issued by pool (cid:61)j, validator v veriﬁes (i) whether the
deposit depositj is no less than the participation fee ξ2, and
(ii) whether the issuing time (measured by block height) of
transaction txm (i.e., im) is no larger than the testing release
block height iτ (line 8). For all valid model transactions,
validator v downloads the corresponding FL models identiﬁed
by the hash pointer mID from the off-chain IPFS (line 9).

Once the task τ elapses its training phase and enters the
testing phase (i.e., iτ ≤ i ≤ iτ +∆i), validator v downloads the
test dataset Dtest identiﬁed by the previously published hash
pointer dID from the IPFS and evaluates all the downloaded
models (line 11). Here, ∆i is the time duration (measured
by block height) of the testing phase. For each model Θj,τ , it
computes the performance score tsj,τ on the test dataset Dtest
(line 12). Based on the performance scores, each validator
creates a candidate model ranking mrListτ , i.e., an ordered
list of model-score pairs on the testing data, which is sorted
either in descending or ascending order depending on the
speciﬁc metrics ψ (line 13). Due to network latency, models
that cannot be timely evaluated during the time limit ∆i obtain
a special “unevaluated” score in mrListτ (lines 20–21).

Step 2: Block rewarding. After reaching consensus on the
model ranking for the selected task τ ∈ (cid:102)Tu, validators will
independently carry out
the block rewarding procedure to
enforce the reward and punishment for blockchain nodes, as
shown in Algorithm 2. Speciﬁcally, the following ﬁnancial
transactions for rewarding and punishment will be added to
the candidate block built by the validator.

1) A payment transaction transferring the task reward pτ
escrowed by the escrow address esAdd to the wallet of the
pool (cid:61)j∗ that owns the top-performing model in the consensus
ranking mrListτ (line 3).

2) A payment transaction transferring the task hosting fee
ξ1 from esAdd to all honest validators in the set V (cid:48) (line 4).
The fee ξ1 is evenly distributed among all honest validators
in V (cid:48).

3) A payment transaction redeeming the participation fee

8

ξ2 to all pools in Wτ whose models are performed above the
preset threshold such as ﬁrst quartile (line 5).

4) A payment transaction transferring the participation fee
ξ2 of all pools in (cid:61)∗\Wτ whose models are either invalid or
performed below the preset threshold to all honest validators
(line 4). The total fee ξ2 · |(cid:61)∗\Wτ | is evenly divided.

Apart from the economic rewards, the credits (as a virtual
token) can offer incentives for blockchain nodes. The credit
values of blockchain nodes can reﬂect their honest active par-
ticipation statuses [29]. After reaching consensus, the current
credit value of the honest validators, members in the winning
pool (cid:61)j∗ , and trainers in Wτ will be increased by χ1, χ2, and
χ3, respectively (lines 6–8). Here, χk > 0 (k = 1, 2, 3).

F. Block Building and Commit

A validator committee V is responsible for proposing and
adding a new block to the blockchain by carrying out the
proposed credit-based Algorand Byzantine agreement (BA)
protocol with the following steps.

Step 1: Validator committee formation. In conventional
Algorand BA protocol [18], nodes are weighted based on their
account balance which can be only used for cryptocurrency
applications. Instead, in our work, each node is weighted based
on its owned credit value. Thereby, our work is also applicable
to non-cryptocurrency applications and can encourage nodes’
participation willingness and honesty. Speciﬁcally, members of
the validator committee are randomly chosen based on their
weights via a cryptographic sortition approach implemented
by a veriﬁable random function (VRF).

A simple implementation of VRF using digital signature and
hash function is adopted. At the beginning stage s = 1, each
node n ∈ PK(i − k) ⊆ N independently validates whether it
is a member of committee Vi,s by checking

.Hash (cid:0)Sigskn (i, s, seedi)(cid:1) ≤

crei
n
C

·

|Vi,s|
#PK(i−k)

.

(13)

n

In Eq. (13), seedi is a public random seed for height i which
is included in the previous block with height i − 1. crei
n is
the current credit value of node n. C = (cid:80)crei
n∈N is the total
credit of blockchain nodes. #PK(i−k) represents the number
of public keys involved in consensus process between heights
i − k and i. The signature σi,s
n = Sigskn (i, s, seedi) means
the credential of node n to prove its role as a validator in
(cid:1) is a random
Vi,s by revealing its public key pkn. Hash (cid:0)σi,s
256-bit long string uniquely determined by skn and i, which
is indistinguishable from random to any node which does
not know the private key skn. The symbol “.” indicates the
transformation of hash value into a decimal in (0, 1].

n

Step 2: Candidate block building and propagation. All
members in Vi,1 are responsible for building candidate blocks
and disseminating them to the whole network for veriﬁcation.
The validator v ∈ Vi,1 validates each transaction (i.e., txτ ,
txp, and txm) in its memory pool that has not been included
in the blockchain and is associated with an unﬁnished FL task
τ ∈ (cid:102)Tu. After that, it builds a candidate ranking mrListv
according to the model ranking contract in Algorithm 1. Then
it orders all valid ones by timestamps, compresses them into
a Merkle tree, and constructs a candidate block Bca
v .

Step 3: Mutual veriﬁcation via multi-stage voting. The
members in committee Vi,s are replaced in each consensus
stage s at height i to prevent being targeted by adversaries.
At stage s > 1 of height i, n ∈ PK(i − k) is a validator
in Vi,s, if formula (13) holds. To mitigate block propagation
delay, validators in Vi,s independently vote for hashes of
candidate blocks, instead of the entire block proposal. The
ﬁnal agreement can be reached via the following two phases.
Phase 1. All validators in Vi,2 runs the (N, f )-graded
consensus (GC) protocol [30] to determine a value-grade
pair (µv, ρv). Here, f < N is the number of malicious
or Byzantine nodes in PF-PoFL. Speciﬁcally, each validator
v ∈ Vi,2 delivers its signed vote message µv = voteMsgv
to other validators for mutual veriﬁcation via the gossiping
protocol, i.e.,

voteMsgv = (cid:104)Hash(Bca
pkv, σi,s

v(cid:48) ), i, s, seedi, Tstamp,
n , Sigskv (voteMsgv)(cid:11) ,

(14)

where Bca
v(cid:48)

is its voted candidate block.
For each validator v ∈ Vi,2, if and only if #2

v(voteMsg) ≥
2f + 1, it sends the vote message voteMsg to other validators.
Besides, it sets the value-grade pair as (µv = voteMsg, ρv =
2). If #2
v(voteMsg) ≥ f + 1, it sets (µv = voteMsg, ρv =
1). Otherwise, it sets (µv = ⊥, ρv = 0). Here, #s
v(msg)
means the number of validators from which v has received
the message msg in stage s.

Phase 2. Each validator in Vi,s(s > 2) executes the im-
proved binary BA (BBA*) protocol [18] (with initial input 0
if ρv = 2, and 1 otherwise) to determine the ﬁnal consensus
block and model ranking. If the result of BBA* is outv = 0,
then the network reaches consensus on a candidate block
voted by µv. Otherwise, an empty block is recognized as the
consensus block.

Step 4: Adding the consensus block. After reaching con-
sensus, the newly built block Bi is successfully added into
the blockchain which is linearly linked to the previous block
with height i − 1 via a hash pointer. Fig. 6 illustrates the
structure of a block in our PF-PoFL. The metadata metai in
the newly built block Bi contains the identity of the completed
FL task τ , the consensus ranking mrListτ , the random seed
seedi for VRF, and a script Script that aggregates the signed
votes of validators during the multi-stage voting for model
ranking and consensus building. The script Script for each
block is agreed upon by the consensus process, which allows
new users to catch up with the validation process of the block
by processing these votes. Besides, the Script (as a certiﬁcate)
allows any user to prove the safety of a block and efﬁciently
verify the model ranking and credit updating process.

G. Security and Privacy Analysis

In this subsection, we give the privacy and security analysis
of our PF-PoFL scheme. To analyze the query sensitivity of
the UDP mechanism in Eqs. (7)–(8), an estimator ˆf is deﬁned
as ˆf ((cid:61)j) = 1
∆Θm in every communication round.
|(cid:61)j |
For privacy protection, the sensitivity of the query function ˆf ,
i.e., S( ˆf ) = max(cid:61)j ,m || ˆf ((cid:61)j ∪ {m}) − ˆf ((cid:61)j)||2 should be
controlled. Theorem 1 analyzes the sensitivity bound of S( ˆf ).

m∈(cid:61)j

(cid:80)

9

the

(15)

Fig. 6. Structure of a block in PF-PoFL.

Theorem 1: If ||∆ ˜Θm||2 ≤ A holds ∀m ∈ (cid:61)j,

sensitivity of ˆf is bounded as S( ˆf ) ≤ 2A
|(cid:61)j | .

Proof: For any m ∈ (cid:61)j, as ||∆ ˜Θm||2 ≤ A, we have
|| ˆf ((cid:61)j ∪ {m}) − ˆf ((cid:61)j) ||

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

=

≤

(cid:80)

∆Θn

−

(cid:80)

∆Θn

n∈(cid:61)j

n∈(cid:61)j ∪{m}
|(cid:61)j ∪ {m}|
(cid:80)

∆Θm
|(cid:61)j| + 1

−

∆Θm
|(cid:61)j| + 1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

n∈(cid:61)j

∆Θn

|(cid:61)j|
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
|(cid:61)j| (|(cid:61)j| + 1)
(cid:12)
(cid:12)
(cid:12)
∆Θn
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

|(cid:61)j|

n∈(cid:61)j

(cid:80)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
|(cid:61)j| + 1

≤

2A
|(cid:61)j|

.

Theorem 1 is proved.

Theorem 2: Given the number of communication rounds
Ψglobal
and the sample ratio λs, ∀(cid:15) < 2(λs)2 log(1/λs)Ψglobal
j,τ
and ∀δ > 0, the proposed mechanism satisﬁes ((cid:15), δ)-UDP, if

j,τ

(cid:113)

2λs

Ψglobal
j,τ

log(1/λs)

σ ≥

.

(16)

(cid:15)
Proof: According to the Lemma 3 of [22], given σ > 1
16σ , for any positive integer γ ≤ σ2 ln(1/λsσ), the

and λs < 1
moment of UDP mechanism F satisﬁes

αF (γ) ≤

(λs)2γ(γ + 1)
(1 − λs)σ2 + O

(cid:16)(cid:16) λsγ
σ

(cid:17)3(cid:17)

,

(17)

which is bounded by αF (γ) ≤ (λs)2γ(γ+1)
(1−λs)σ2
the Theorem 2 of [22], to be ((cid:15), δ)-UDP, it sufﬁces that

. Besides, based on

Ψglobal
j,τ

(λs)2γ2
σ2

≤

γ(cid:15)
2

, and δ ≥ exp

(cid:16)

−

(cid:17)

.

γ(cid:15)
2

(18)

According to formula (18), we can derive that

λs

σ ≥

(cid:113)

2Ψglobal
j,τ
(cid:15)

γ(cid:15)

≥

(cid:113)

2λs

Ψglobal
j,τ

log(1/λs)

(cid:15)

.

(19)

As σ > 1 and λs ∈ (0, 1], we have ln(1/λsσ) < ln(1/λs).
According to δ ≥ exp (cid:0)− γ(cid:15)
(cid:1), we have γ(cid:15) ≥ 2 log (1/δ). By
transforming γ ≤ σ2 ln(1/λsσ), we have

2

(cid:15) ≤

4 (λs)2 Ψglobal

j,τ

log (1/δ) log (1/λsσ)

γ(cid:15)

(20)

< 2(λs)2Ψglobal

j,τ

log(1/λsσ) < 2(λs)2Ψglobal

j,τ

log(1/λs).

Theorem 2 is proved.

TimestampMerkle rootblock headerblock bodyTask publication txPrevious block hashModel txPayment tx...Task IDModel rankingScriptMetadata...Model txPayment tx< model ID #1 , score >…< model ID #J , score >Model rankingOff-chain data storeTrained FL ModelsSeedIn the blockchain, the reasonable security assumption is
adopted, where the fraction of the credit value held by
malicious blockchain nodes is assumed to be less than 1/3.
In the following, we analyze the ﬁnality, consistency, and
efﬁciency of our PF-PoFL system, as well as security analysis
in defending against adversaries deﬁned in Sect. III-B.

V. DYNAMIC OPTIMIZED POOL STRUCTURE FORMATION

In this section, we ﬁrst analyze the federation utility of each
pool, then we present a stable pool formation algorithm based
on the federation formation game, followed by the property
analysis of the proposed algorithm.

10

• Finality and consistency. According to [18], [30], under
the above majority honest assumption, our PF-PoFL sys-
tem is resilient up to 1/3 credit values held by malicious
or Byzantine nodes, and all honest nodes can reach
an agreement on the same block with overwhelming
probability. It ensures the ﬁnality and consistency of the
blockchain, as well as the prevention of blockchain forks
and double-spending threats.

the BBA* protocol

• Consensus efﬁciency. Under the strong synchrony as-
sumption (i.e., messages sent by most honest nodes can
be received by most other honest nodes within a known
time bound),
is proved to reach
agreement within one stage, thereby ensuring the high
efﬁciency of consensus protocol in common situations.
• Defense of spooﬁng attack. In the model ranking smart
contract, a model transaction will not be included in the
candidate block by honest validators if it is published
within the testing phase of the task. Hence, trainers do
not have incentives to cheat by training a perfect model
on the test data. Besides, as only the hashes of trained
FL models are released in federated mining process,
adversaries cannot plagiarize the FL models trained by
other pools. Besides, the payment delivery to members of
the winning pool is executed automatically via the block
rewarding smart contract, the refusal-to-pay threat can be
avoided. Thereby, PF-PoFL can resist spooﬁng attacks.
• Defense of Sybil attack. By introducing the participation
fee, trainers/pools have to pay a participation fee before
their trained models are ranked, which increases the cost
for nodes to carry out Sybil attacks. Besides, as the
committee members are randomly formed via VRF based
on their credit values, Sybil attacks to the committee
selection process can be prevented, as well as ensuring
fairness for blockchain nodes. Thereby, PF-PoFL can
mitigate Sybil attacks.

• Defense of the central platform. PF-PoFL offers a fully
decentralized solution for the life-cycle process including
task outsourcing, model
training, model ranking, and
reward sharing. In PF-PoFL, as the third-party platform
is removed, potential risks it brings including SPoF, col-
lusion, and sensitive information leakage can be avoided.
• Privacy leakage prevention. According to Theorem 2,
PF-PoFL ensures UDP for miners to prevent user-level
privacy leakage during federated mining. Besides, as
the committee selection is pseudo-random and non-
interactive and the committee members are replaced
in every stage, adversaries cannot target a committee
member until that validator starts participation. Thereby,
PF-PoFL also ensures membership unpredictability for
validators to prevent being targeted.

A. Federation Utility Function

The federation utility of pool (cid:61)j is determined by the
accuracy loss of the trained global model and the federation
cost. First, we characterize the expected accuracy loss of the
global model under federated mining in Sect. IV-D.

1) Non-IID Effect. The non-IID data can affect the accu-
racy of the global model under FL. We adopt the widely
used average earth mover’s distance (EMD) to measure the
heterogeneity of data distribution among diverse miners [31].
In a typical classiﬁcation problem with Y classes deﬁned over
a label space Y = {1, · · · , Y } and a compact space X . Let
Prm(y = k) denote the proportion of miner m’s local training
samples with label k ∈ Y, and Pr(y = k) be the proportion
of training samples with label k ∈ Y in all miners’ training
data. Thereby, Pr(y), ∀y ∈ Y denotes the data distribution for
each data sample {x, y} distributed over X × Y. The EMD of
miner m ∈ Mτ is computed as

Ξm =

Y
(cid:88)

k=1

||Prm(y = k) − Pr(y = k)||.

(21)

The average EMD in pool (cid:61)j is computed as the weighted
sum of all miners’ EMDs, which is expressed as

Ξj =

(cid:88)|(cid:61)j |
m=1

sm
(cid:80)|(cid:61)j |
m=1 sm

Ξm,

(22)

where sm is miner m’s local data size, and |(cid:61)j| is the number
of members in pool (cid:61)j.

2) Latency analysis. In a global communication round k, the
total latency consists of (i) local training latency Dk
tl in local
model training and (ii) network latency Dk
nl for uploading the
trained local model and receiving the latest global model using
wired/wireless networks. According to [32], we have Dk
nl (cid:29)
Dk
tl, thereby Dk
tl can be negligible. Here, the maximum waiting
time (i.e., Dmax
) of pool (cid:61)j in a global communication round
j
is deﬁned as

Dmax

j = βDnl = β

|(cid:61)j |
(cid:88)

m=1

Dnl,m,

(23)

where β > 0 is an adjustment factor to control the ratio
of participants in a global communication round. Dnl is the
average network latency of all miners in the pool (cid:61)j. Dnl,m
is the expected network latency of miner m ∈ (cid:61)j.

3) Number of training samples. In a global communication
the total number of data samples used for model
m=1 αmsm. Here,

round,
training in pool (cid:61)j is denoted as Sj = (cid:80)|(cid:61)j |
αm = {0, 1} a binary variable, i.e.,

αm =

(cid:40)

if Dnl,m ≤ Dmax

1,
0, otherwise.

j

,

(24)

It means that only miners with Dnl,m ≤ Dmax
to join the model training.

j

are admitted

4) Total global communication rounds. The number of
global communication rounds of pool (cid:61)j can be computed
as Ψglobal
is the total training
time duration (measured by block height) of a FL task, as
shown in Fig. 5.

j,τ = (cid:98)T train

(cid:99). Here, T train

/Dmax
j

τ

τ

j,τ

5) Expected accuracy loss. The accuracy loss of the global
model after Ψglobal
rounds can be measured by the prediction
loss between the optimal parameter Θ∗ and the parameter
Θ(Ψglobal
)) − L(Θ∗). According to [33],
j,τ
[34], when adopting mini-batch SGD for local training, the
expected accuracy loss Πj under non-IID case is bounded by
. Here, E(Ξj) is the relative
O

), i.e., L(Θ(Ψglobal

+ 1

E(Ξj)

(cid:17)(cid:17)

j,τ

(cid:16)

(cid:16)

(cid:113)

1
Sj Ψglobal
j,τ

Ψglobal
j,τ

and the number of training samples Sj.

accuracy loss function. Obviously, the expected accuracy loss
decreases with the increase of the number of global iterations
Ψglobal
j,τ
Apart from the federated mining strategy, miners can also
in which the miner m
employ the solo mining strategy,
chooses to work alone and forms a singleton, i.e., (cid:61)j = {m}.
Under this case, the expected accuracy loss bound can be
approximated as O
, where
Ψlocal
max,τ is the maximum number of local epoches in training
task τ to avoid overﬁtting. To summarize, the explicit form of
the expected accuracy loss is expressed as

+ 1
Ψlocal

E(Ξm)

1√

smΨlocal

(cid:17)(cid:17)

max,τ

max,τ

(cid:16)

(cid:16)

Πj =






(cid:16)

E(Ξj)

E(Ξm)

(cid:113)
(cid:16)

1
Sj Ψglobal
j,τ
1√

smΨlocal

max,τ

+ 1

Ψglobal
j,τ

+ 1
Ψlocal

max,τ

(cid:17)

,

if |(cid:61)j| > 1,

(cid:17)

,

if |(cid:61)j| = 1.

(25)

6) Federation satisfaction function. The federation satisfac-
tion function S(Πj) measures the satisfaction that the pool
(cid:61)j receives in the expected accuracy loss Πj. Generally, the
lower the accuracy loss, the higher the federation satisfaction.
Besides, it becomes harder to further reduce the accuracy loss
when the loss is smaller, indicating that the faster the drop rate
of accuracy loss, the higher the obtained federation satisfac-
tion. Thereby, S(Πj) should satisfy S(Πj) ≥ 0, dS(Πj )
< 0,
dΠj
and d2S(Πj )
≥ 0. A well-suited satisfaction function satisfying
these requirements can be the exponential decay function [35]
given by

dΠ2
j

S(Πj) = γs exp(−γd · Πj),

(26)

where γs > 0 is the satisfaction parameter, and γd > 0 is the
decay parameter which controls the decay speed. A larger γd
indicates a faster decay of satisfaction.

Next, we analyze the federation cost in pool formulation.
7) Federation cost function. The miners in pool (cid:61)j need
to frequently synchronize the latest global model from the
curator. According to [36], [37], the federation cost C((cid:61)j) can
be measured by the communication cost which varies linearly
with the federation size |(cid:61)j|. We have

C((cid:61)j) =

(cid:40)

λc|(cid:61)j|,
0,

if |(cid:61)j| > 1,
if |(cid:61)j| = 1,

(27)

where λc > 0 is a scaling factor.

11

Finally, the federation utility of pool (cid:61)j can be obtained
as the difference between the federation satisfaction and the
federation cost, i.e.,

U((cid:61)j) = S(Πj) − C((cid:61)j)




γs exp

−γdE(Ξj)

(cid:114)

1

(cid:80)|(cid:61)j |

m=1 αmsm

(cid:4) T train
τ
Dmax
j

(cid:106) T train
τ
Dmax
j

(cid:5) +

(cid:107)−1(cid:17)





(cid:18)

γs exp

−γdE(Ξj)

1√

sj Ψlocal

max,τ

+ 1
Ψlocal

max,τ

− λc|(cid:61)j|, if |(cid:61)j| > 1,

(cid:17)(cid:19)

, if |(cid:61)j| = 1.

(28)

=




(cid:16)

(cid:16)

Let W ((cid:61)) denote the social welfare of a partition (cid:61), i.e.,
the sum of federation utilities of disjoint pools in a partition
(cid:61). The target of PF-PoFL is to maximize the social welfare
by forming the optimal partition structure (cid:61)∗, where the
optimization problem for task τ is formulated as:

Problem : max W ((cid:61)) :=

(cid:88)|(cid:61)|
j=1

U((cid:61)j).

s.t. (cid:61)j ∩ (cid:61)j(cid:48) = ∅, ∀j (cid:54)= j(cid:48), ∪|(cid:61)|

j=1(cid:61)j = Mτ .

(29)

B. Stable Pool Formation Algorithm

To solve the problem in (29), the pooled-mining formation
process among miners is modeled as a federation formation
game with transferable utility (FFG-TU), where distributed
miners (as game players) tend to form various disjoint fed-
erations to maximize their individual proﬁts [38].

Deﬁnition 2 (FFG-TU game): For each uncompleted FL
task τ , a FFG-TU game for optimized pool structure is deﬁned
by a triple (Mτ , U, (cid:61)), where the speciﬁc formulation is
shown as below.

• Players: The players of the game is the set of miners

(i.e., Mτ ) that participate FL task τ .

• Transferable federation utility: U((cid:61)j) is the federation
utility of each federation (or pool) (cid:61)j ⊆ Mτ , which can
be apportioned arbitrarily among the members of (cid:61)j.
• Pooled structure: A pooled structure (or a federation
partition) is deﬁned as the set (cid:61) = {(cid:61)1, · · · , (cid:61)J } that
partitions the miner set Mτ . Here, (cid:61)j, j = 1, · · · , J are
disjoint federations such that (cid:61)j ∩ (cid:61)j(cid:48) = ∅, ∀j (cid:54)= j(cid:48), and
∪J

j=1(cid:61)j = Mτ .

• Strategy: Each miner decides whether to work alone by
adopting the solo mining strategy or choose a federation
to join to cooperatively train a FL model using the
federated mining strategy.

Deﬁnition 3 (Switch operation): A switch operation
Φl,k(m) is deﬁned as the transfer of miner m from the current
pool (cid:61)l ∈ (cid:61) to another pool (cid:61)k ∈ (cid:61) ∪ {∅}, mathematically,

Φl,k(m) : (cid:61)l (cid:46) {(cid:61)−

l , {m}} and {(cid:61)k, {m}} (cid:46) (cid:61)+
k .

(30)

Remark 2: The switch operation consists of two successive
parts: the split operation (i.e., (cid:61)l (cid:46) {(cid:61)−
l , {m}}) and the merge
operation (i.e., {(cid:61)k, {m}} (cid:46) (cid:61)+
l = (cid:61)l\{m} and
(cid:61)+
l = (cid:61)k ∪ {m}. In the case that (cid:61)l = {m}, Φl,k(m) means
the merge of (cid:61)l with (cid:61)k, causing the number of federations
decrease by one. In the case that (cid:61)k = {∅}, Φl,k(m) means

k ), where (cid:61)−

the formation of a new singleton (cid:61)k = {m}, causing the
number of federations increase by one. In the case that k = l,
it means miner n stays in the current federation and the number
of federations remains unchanged.

Deﬁnition 4 (Switch gain): The switch gain Ωm(Φl,k)

related to the switch operation Φl,k(m) is deﬁned as:

Ωm(Φl,k) := vm((cid:61)k ∪ {m}) − vm((cid:61)l)
= [U((cid:61)k ∪ {m}) − U((cid:61)k)] − [U((cid:61)l) − U((cid:61)l\{m})]. (31)

Here, vm((cid:61)k ∪ {m}) and vm((cid:61)l) mean the extra utility value
that miner m brings to the pools (cid:61)k∪{m} and (cid:61)l, respectively.
Remark 3: Specially, we deﬁne Ωm(Φl,k) = 0 when
k = l. Besides, when (cid:61)k = {∅}, we have Ωm(Φl,∅) =
U({m}) − vm((cid:61)l). The transferable switch gain in the pool
switch operation accords with the transferable utility of our
proposed federation formation game. Besides, the federation
gain of any switch operation only relies on the utilities of
involved pools, rather than the manner that federation utilities
are shared among their members.

Deﬁnition 5 (Preference order): For any miner m ∈ Mτ ,
the preference order (cid:23) is deﬁned as a complete and transitive
binary relation between two switch operations Φl,k(m) and
Φl(cid:48),k(cid:48)(m) such that:

Φl,k(m) (cid:23) Φl(cid:48),k(cid:48)(m) ⇔ Ωm(Φl,k) ≥ Ωm(Φl(cid:48),k(cid:48)).

(32)

Similarly, for the strict preference order (cid:31), we also have
Φl,k(m) (cid:31) Φl(cid:48),k(cid:48)(m) ⇔ Ωm(Φl,k) > Ωm(Φl(cid:48),k(cid:48)).

As miners can transfer from one federation to another one,
the federation partition (i.e., (cid:61)) varies with time. The solution
of the proposed FFG-TU game is a stable pooled structure
(cid:61)∗. In general, the stable partition outcome can be attained
using exhaustive search methods, where the possible partition
iterations increase exponentially with the number of involved
miners [37]. In the following, we design a distributed stable
pool formation algorithm with low computational complexity
in Algorithm 3 to obtain the optimal federation partition
strategy of each player (i.e., miner m) in the game. The
proposed algorithm consists of the following three phases.

Phase 1: Pool initialization (line 3). At the beginning (h =
0), an initial partition (cid:61)(0) is generated according to the
speciﬁc application. For example, the initial partition can be
the result of the stable partition outcome for the previously
ﬁnished FL task.

Given

current

federation

the
1 , · · · , (cid:61)(h)

J (h) }, each miner can opt

Phase 2: Switch strategy-making on miner’s side

(lines
partition
5–8).
(cid:61)(h) = {(cid:61)(h)
three
strategies: (i) stay in the current federation; (ii) split from
the current federation and merge with any other non-empty
federation; and (iii) split from the current federation and act
alone. The ﬁrst two strategies are federated mining strategies
and the last one is the solo mining strategy. To formulate
each miner’s switch strategy, the switchable candidate pool is
ﬁrst deﬁned as below.

Deﬁnition 6 (Switchable candidate pool): For each miner
m ∈ (cid:61)l, its switchable candidate pool set is deﬁned as Cpool
m ,
where Ωm(Φl,k) > 0, ∀(cid:61)k ∈ Cpool
m ⊆ (cid:61)∪{∅}. In other words,
only the pool with positive switch gain can be added into the
switchable candidate pool set.

12

Algorithm 3 Distributed Pool Formation Algorithm
1: Input: Tu, Mτ , Ξm, sm, β, Dnl,m, T train

, Ψlocal

τ

m,τ , γs, γd,

λc.

2: Output: Stable federation structure (cid:61)∗.
3: Initialization: Set h = 0 and the initial pool structure

(cid:61)(0).
4: Repeat
5: for m ∈ Mτ do
6:

7:

11:

12:

13:

14:

Calculate all candidate pools (including the empty set
{∅}) with positive switch gain, and record them into the
set Cpool
m .
Send transfer request to most preferred pool (cid:61)(h)
Cpool
m such that
Ωm(Φl,j∗ ) ≥ Ωm(Φl,j), m ∈ (cid:61)(h)

, ∀(cid:61)(h)

j ∈ Cpool

m , (33)

j∗ ∈

l

where (cid:61)(h)
l
iteration.

is the current federation of miner m at h-th

8: end for
9: for (cid:61)(h)
10:

j ∈ (cid:61)(h) do

Record the candidate miners that send a transfer request
into the set Cminer
Accept the most preferred miner m∗ ∈ (cid:61)(h)
l(cid:48)
the admission rule:

through

.

j

Ωm∗ (Φl(cid:48),j) ≥ Ωm(Φl,j), m ∈ (cid:61)(h)

l

, ∀m ∈ Cminer

j

.

(34)

Reject other candidate miners in the set Cminer

j

\ {m∗}.

Do split operation, i.e., (cid:61)(h)
= (cid:61)(h)
(cid:61)(h+1)
l(cid:48) \ {m∗}.
l(cid:48)
Do merge operation, i.e.,
= (cid:61)(h)
(cid:61)(h+1)
j ∪ {m∗}.
j

(cid:110)

(cid:110)

(cid:61)(h+1)
l(cid:48)

(cid:111)

, {m∗}

, where

l(cid:48) (cid:46)

(cid:61)(h)
j

(cid:111)

, {m∗}

(cid:46)(cid:61)(h+1)
j

, where

15: end for
16: h = h + 1.
17: Update
{(cid:61)(h)

1 , · · · , (cid:61)(h)

J (h)}.

the

federation

structure

as (cid:61)(h)

=

18: Until no miner do switch operations, i.e., Φl,l(m) (cid:23)
∈

, j (cid:54)= l, ∀m ∈ Mτ , ∀(cid:61)(h)

j

Φl,j(m), m ∈ (cid:61)(h)
(cid:61)(h) ∪ {∅}.

l

Remark 4: If Ωm(Φl,k) ≤ 0, ∀(cid:61)k ∈ (cid:61) ∪ {∅}, there exists no
available federation in (cid:61) nor the empty set to transfer for the
miner m (i.e., Cpool
m = ∅), indicating that the miner intends to
stay in the current federation (cid:61)l (i.e., Φl,l(m)). Otherwise, the
miner makes its strategy based on the following switch rule.
Deﬁnition 7 (Switch rule): Given the switchable candidate
m ∪{∅}, each miner m ∈ (cid:61)l sends transfer request

pool set Cpool
to the candidate pool (cid:61)j∗ with the largest switch gain, i.e.,

(cid:61)j∗ = arg max Ωm(Φl,j), m ∈ (cid:61)l, ∀(cid:61)j ∈ Cpool

m ∪ {∅}, (35)

where (cid:61)l is the current federation of miner m.

Remark 5:

∪ {∅}(cid:9) = {∅},

In the case arg max (cid:8)Ωm(Φl,j) : ∀(cid:61)j ∈
the miner m
from

the solo mining strategy and will

it means

split

that

Cpool
m
prefers

federation (i.e., Φl,∅(m)).

In the other case
the current
arg max (cid:8)Ωm(Φl,j) : ∀(cid:61)j ∈ Cpool
it means
that the miner m prefers splitting from the current federation
(cid:61)l and merging with another federation (cid:61)j∗ (i.e., Φl,j∗ (m)).
m ∪ {∅}, the optimal switch

To summarize, ∀(cid:61)j ∈ Cpool

m ∪ {∅}(cid:9) = (cid:61)j∗ ,

strategy of each miner m ∈ (cid:61)l can be expressed as

Φ∗

l,k(m) =






Φl,l(m),
Φl,∅(m),
Φl,j∗ (m),

m = ∅,

if Cpool
if arg max Ωm(Φl,j) = {∅},
if arg max Ωm(Φl,j) = (cid:61)j∗ .

(36)

Phase 3: Admission strategy-making on pool’s side

(lines
9–17). When multiple miners request to join the same pool
(cid:61)j, the switch order can affect the federation utilities and the
federation formation outcome. To capture the pool’s preference
for the transfer order, the admission rule is deﬁned as below.
Deﬁnition 8 (Admission rule): For a set of candidate miners
(i.e., Cminer
) that send transfer request to the same pool (cid:61)j,
j
only the candidate m∗ with the largest switch gain is permitted
by the pool (cid:61)j, i.e.,

m∗ = arg max Ωm(Φl,k), m ∈ (cid:61)l, ∀m ∈ Cminer

j

,

(37)

and other candidate miners in the set Cminer
jected.

j

\ {m∗} are re-

According to the admission rule, each pool (cid:61)j ∈ (cid:61) accepts
the most preferred miner m∗ ∈ (cid:61)l(cid:48) (in line 11) and rejects
other candidates (in line 12). Correspondingly,
the switch
operation is performed between two pools (cid:61)j, (cid:61)l(cid:48) ∈ (cid:61)
, {m∗}(cid:9))
consisting of the split operation (i.e., (cid:61)(h)
and the merge operation (i.e., (cid:8)(cid:61)(h)
), where
(cid:61)(h+1)
l(cid:48) \ {m∗} and (cid:61)(h+1)
j ∪ {m∗}. Then, the
l(cid:48)
j
federation structure is updated as (cid:61)(h) → (cid:61)(h+1) (in line 17).
The above phases 2-3 are repeated until no miner m ∈
(cid:61)∗
l ⊆ Mτ in the ﬁnal pooled structure (cid:61)∗ intends to execute
switch operations to increase the overall gain by transferring
j ∈ (cid:61)∗ ∪ {∅} with j (cid:54)= l, i.e., Φl,l(m) (cid:23)
to another pool (cid:61)∗
Φl,j(m).

l(cid:48) (cid:46) (cid:8)(cid:61)(h+1)
, {m∗}(cid:9) (cid:46) (cid:61)(h+1)
= (cid:61)(h)

= (cid:61)(h)

l(cid:48)

j

j

C. Property Analysis

Given any initial partition (cid:61)(0), the federation formation
procedure can be formulated as a sequence of switch opera-
tions, i.e.,

{(cid:61)(0) → · · · → (cid:61)(h) → · · · → (cid:61)(H) = (cid:61)∗},

(38)

where H is total number of transformations.

Lemma 1: Any successive transformation of the federation
partition, i.e., (cid:61)(h) → (cid:61)(h+1), h = {0, 1, · · · , H − 1}, can
improve the social welfare for miners in Mτ .

it

Proof: According to Deﬁnitions 6–7, for each switch
operation Φl,k(m),
results in a strictly positive gain
Ωm(Φl,k) > 0 for the two involved pools (cid:61)j and (cid:61)k, while
the utilities of other pools in (cid:61)\{(cid:61)j, (cid:61)k} remain unchanged.
Let (cid:80)(h) be the set of permitted switch operations during the
transformation (cid:61)(h) → (cid:61)(h+1). Therefore, we can obtain

W (cid:0)(cid:61)(h+1)(cid:1) = W (cid:0)(cid:61)(h)(cid:1) +

(cid:88)

Ωm(Φl,k).

(39)

Φl,k(m)∈(cid:80)(h)

13

The second term in the right side of (39) means the improved
social welfare (i.e., the sum of added switch gains) during
(cid:61)(h) → (cid:61)(h+1). As (cid:80)
Φl,k(m)∈(cid:80)(h) Ωm(Φl,k) > 0, we have
W ((cid:61)(h+1)) > W ((cid:61)(h)). Lemma 1 is proved.

In the following, we ﬁrst prove the convergence of federa-
tion partition transformations in Theorem 3. Then, we prove
the Nash-stability, near-optimality, and low computational
complexity in Theorems 4, 5, 6, respectively.

Theorem 3: Given an arbitrary initial pooled structure
(cid:61)(0), the proposed Algorithm 3 can always converge to a
ﬁnal disjoint federation partition (cid:61)∗ after a ﬁnite number of
transformations.

Proof: According to the miner’s switch strategy deﬁned in
Eq. (36), we can observe that a single switch operation either
yields (i) a previously visited partition with a non-cooperative
miner (i.e., a singleton) or (ii) an unvisited new partition.

Case (i). When it comes to the partition structure (cid:61)(h)
where miner m forms a singleton, the non-cooperative miner
m should either join a new federation or decide to remain
non-cooperative in the next iteration (cid:61)(h+1).

• If miner m chooses to join a new federation, an unvisited
partition without this non-cooperative miner m will be
formed via the switch operation.

• If miner m chooses to remain non-cooperative, any
visited partition will not appear in the transformation of
the current partition structure.

Case (ii). When it comes to the partition structure (cid:61)(h)
where a single switch operation leads to an unvisited partition
in the next iteration (cid:61)(h+1), the maximum number of partitions
among miners in Mτ can be given by the well-known Bell
number function, i.e.,

b|Mτ | =

(cid:88)|Mτ |
m=1

(cid:18) |Mτ |−1
m

(cid:19)

bm, ∀m ∈ Mτ & b0 = 1.

(40)

According to Eq. (40), the number of transformations of
federation partitions in formula (38) is ﬁnite. Thereby, in all
cases, the transformation sequence in formula (38) will always
terminate and converge to a ﬁnal partition (cid:61)∗ = (cid:61)(H), which
is composed of a number of disjoint federations after ﬁnite H
iterations. Theorem 3 is proved.

Deﬁnition 9 (Nash-stability): A federation partition (cid:61) =
{(cid:61)1, · · · , (cid:61)J } is Nash-stable if ∀m ∈ Mτ , ∀(cid:61)j ∈ (cid:61), ∀(cid:61)l ∈
(cid:61) ∪ {∅}, Ωm(Φj,l) ≤ 0.

Remark 6: The Nash-stability implies that, under the Nash-
stable partition, any single switch operation will not result in a
strictly positive gain. In other words, no miner has incentives
to move from its current federation to another one or to deviate
and act alone in the Nash-stable partition.

Theorem 4: The ﬁnal partition (cid:61)∗ from Algorithm 3 is

Nash-stable.

Proof: The Nash-stability of partition (cid:61)∗ is proved by
contradiction. Suppose that the ﬁnal partition (cid:61)∗ resulting
from Algorithm 3 is not Nash-stable. As a consequence, there
exists a miner m ∈ (cid:61)j and a federation (cid:61)j(cid:48) ∈ (cid:61)∗ ∪{∅}, j (cid:54)= j(cid:48)
such that Φj,j(cid:48)(m)(cid:23)Φj,j(m). Under this circumstance, miner

m will execute the switch operation Φj,j(cid:48)(m), which con-
tradicts with the fact that (cid:61)∗ is the ﬁnal partition result of
Algorithm 3. Theorem 4 is proved.

Theorem 5: The ﬁnal partition outcome from Algorithm 3

attains a near-optimal performance.

Proof: According to Lemma 1, the consecutive transfor-
mation of the federation partition, i.e., (cid:61)(h) → (cid:61)(h+1), can
improve the overall social welfare. Moreover, according to
Theorem 3, the overall system welfare derived by Algorithm 3
is convergent after several iterations. Besides, instead of allow-
ing multiple miners to simultaneously transfer to a single pool,
the switch operation to a single pool is executed in a greedy
manner in our work, where only the miner with the largest
positive switch gain is permitted. Thereby, the partition result
derived through Algorithm 3 is near-optimal, which is also
evaluated using simulations in comparison with the exhaustive
optimal solution in Sect. VI-C.

Theorem 6: The computational complexity of the proposed
Algorithm 3 is O(H ·J ·|Mτ |), where J = |(cid:61)∗| is the number
of federations in the Nash-stable partition (cid:61)∗.

Proof: The complexity of the distributed pool formation
algorithm in Algorithm 3 mainly consists of two parts: (i) the
ﬁrst for-loop for each miner to decide its switch strategy (lines
5-8); and (ii) the second for-loop for each federation to decide
its admission strategy (lines 9-15). For the ﬁrst part, it has a
complexity of O(H|Mτ |J). The second part has a complexity
of O(HJ(cid:12)
(cid:12)
(cid:12)} ≤ |Mτ |, the overall
computational complexity yields O(HJ|Mτ |). Theorem 6 is
proved.

(cid:12)). As max{(cid:12)
(cid:12)

(cid:12)Cminer
j

(cid:12)Cminer
j

VI. PERFORMANCE EVALUATION

In this section, the simulation setup is ﬁrst introduced in
Sect. VI-A, followed by the numerical results and discussions
in Sects. VI-B∼VI-D.

A. Simulation Setup

We implement

the prototype of PF-PoFL on a private
blockchain network based on the open-source Go-Algorand
project [39] under both local and distributed settings. For the
distributed setting (i.e., setting 1), the prototype is deployed
across 20 Azure B8ms virtual machines (VMs), with 8 CPU
cores and 32 GB of RAM. The VMs spread across ﬁve
locations: West US, Canada East, UK South, Korea South,
and North Europe. Each VM hosts 5 blockchain miners, and
the total number of blockchain miners (i.e., N ) is 100. For
the local setting (i.e., setting 2), the prototype is deployed
and tested on a single computer with Intel Core i7-8700 CPU
(3.6GHz) and 32GB RAM, where the number of blockchain
miners is set as 100.

We use Go 1.17 to create and manage the private multi-
node networks, as well as handle all networking and dis-
tributed systems aspects. We use the Turing-complete PyTeal
[40] to write the smart contract
in Python 3.10 and use
the compileProgram method to produce the bytecode-based
TEAL source code, which can be deployed on the blockchain.
Besides, miners in a pool use PyTorch to perform federated
mining with UDP to produce SGD updates during training,

14

TABLE I
USED DATASETS AND MODELS IN PF-POFL

Dataset
MNIST
CIFAR-10

#Training samples
60,000
50,000

#Test samples
10,000
10,000

#Classes
10
10

Model
CNN
ResNet18

and our prototype can support any AI model which can be
optimized via SGD.

Dataset. We consider two types of FL tasks trained on two
typical datasets: one type is the handwritten digits recognition
tasks on the MNIST dataset [41]; and another is the image
recognition tasks on the CIFAR-10 dataset [42]. MNIST
consists of 60,000 training images and 10,000 test images with
size of 28×28 in 10 classes. CIFAR-10 contains 60,000 32×32
images evenly divided in 10 classes, with 50,000 training
images and 10,000 test samples. For the dataset partition
among miners, the non-IID setting is adopted. Speciﬁcally,
each miner is assigned with z classes of 600 training samples
for MNIST (resp. 500 training samples for CIFAR-10) and the
training samples of different miners can be repeated, where the
integer z is randomly selected from {1, 2, · · · , 10}.

j,τ

Model. For federated mining within each pool in PF-PoFL,
the 3-layer CNN model is adopted for MNIST, while the
ResNet18 model is employed for CIFAR-10. The total number
of communication rounds is set as Ψglobal
= 200, and the
sample ratio is set as λs = 0.35. For the learning algorithm,
to 50 is
the mini-batch SGD with local batch size equal
adopted for all miners, where the initial learning rate η is
set as 0.01 and declines to 0.001 after 120-th communication
round. Besides, the local epoch of miners is set as 1 under
the federated mining strategy, while the maximum local epoch
Ψlocal
max,τ of miners is set as 1000 under the solo mining strategy.
Table I summarizes the datasets and models used in PF-
PoFL. For the UDP model, the privacy parameters (σ, (cid:15)) are
selected from {(3, 5.52), (14, 1.06), (24, 0.61)}. Besides, we
set δ = 1 × 10−6. For the federation formation game model,
we set γd = 30, γs = 23, λc = 0.01. In addition, we set
miner’s initial credit value as cre0
n = 1 and the credit updates
as χ1 = 2, χ2 = 4, and χ3 = 1.

Comparing method. We evaluate the performance of the
PF-PoFL in comparison with the PoFL scheme [15]. In PoFL
[15], its working relies on a central FL platform, and the ﬁxed
mining pool structure is employed for federated mining. PoFL
ensures privacy preservation and prevents model plagiarism
for trained models using homomorphic encryption (HE)-based
label prediction and secure two-party computation (2PC)-
based label comparison. As PoFL does not specify the detailed
agreement protocol to acquire consensus, to be objective and
fair, we implement the conventional Algorand BA protocol
[18] for miners in PoFL to reach consensus on a new block.
Here, the number of miners is set as N = 100 and the number
of malicious or Byzantine miners is set as f = 20.

In the following, we ﬁrst evaluate the blockchain through-
put, block latency, and system overhead of our PF-PoFL in
Figs. 7–8 and Tables II–III. Next, we analyze the impacts of
non-IID, number of miners, and privacy parameters on the
federated mining process with UDP in Figs. 9–13. Finally, we

15

Fig. 7. Throughput and block latency in different block heights in PF-PoFL
(setting 1).

Fig. 8. Throughput and block latency vs. block size in PF-PoFL (setting 1).

analyze the efﬁciency and stability of the federation formation
game approach for optimized pool structure in Figs. 14–15.

B. System Throughput and Latency

Fig. 7 shows the throughput (measured by transactions per
second (TPS)) and the block latency (i.e., the consensus time
for a block from being pending to be conﬁrmed) of the
blockchain system in the distributed setting. In the blockchain,
the better the consensus
the shorter the consensus time,
efﬁciency. Here,
the consensus time is mainly determined
by the delay in model downloading, model ranking, model
veriﬁcation, block propagation, and voting-based agreement
process. In the simulation, the ratio of malicious or Byzantine
miners is set to be 20%. From Fig. 7, it can be seen that, when
the block height grows from 100 to 200, both the TPS and the
block latency of our proposed PF-PoFL consensus mechanism
remain relatively stable. Speciﬁcally, the throughput mainly
varies between [300, 500] TPS, while the block latency
changes within [18, 25] seconds, which indicates a relatively
stable block packaging frequency of our PF-PoFL consensus
mechanism. It can be explained as follows.

In the traditional PoW consensus protocol, all miners com-
pete to solve the same PoW puzzle and the fastest node to
solve it earns the block rewards. Distinguished from the PoW
protocol, in our PF-PoFL consensus protocol, different mining
pools can concurrently train on different FL tasks that are in
the training phase; meanwhile, in the current block height, the
validators prefer to reach consensus on the most urgent and
proﬁtable task from all tasks that are in the testing phase. For
example, for a FL task τ with a high difﬁculty level, in its
training phase, validators will carry out consensus on other
tasks that are in the testing phase; until the FL task τ reaches
its testing phase, validators will perform consensus on it if the
task τ is most urgent and proﬁtable in current block height. As
such, for FL tasks with different difﬁculty levels, the relatively
stable throughput of the blockchain system can be obtained.
Fig. 8 shows the throughput and the block latency of PF-
PoFL in the distributed setting when the block size increases
from 0.5 MB to 10 MB. It can be observed that our PF-
PoFL system can efﬁciently handle hundreds of transactions
per second and the block latency is below 47 seconds. As
seen in Fig. 8, with the increase of block size, the block
latency keeps increasing while the blockchain throughput ﬁrst

TABLE II
TIME COST OF EXECUTING MODEL RANKING CONTRACT IN PF-POFL
(SETTING 1)

Operation

Running
Reaching
agreement
Overall latency

Time for the
fastest validator
3.215 s

Time for the
slowest validator
6.246 s

Ave. time for
validators
4.952 s

16.583 s
≈ 21.1 s

increases then decreases when the block size is over 8.5 MB.
It can be explained as follows. On one hand, the higher block
size indicates that more transactions are included within a
block, resulting in a higher latency in transaction processing
and block propagation. On the other hand, the relatively higher
block size means that more transactions to be processed in a
new block, which brings a higher TPS. However, the TPS
cannot grow with the block size all the time. The reason is
when the block size is too large (i.e., over 8.5 MB), the time
to verify and broadcast the block can be extended, so that the
distributed blockchain cannot be synchronized in time.

Table II shows the time cost of executing model rank-
ing contract in PF-PoFL under the distributed setting. The
execution time of model ranking contract mainly consists
of two parts:
the contract running time (to produce local
model ranking result) and the time to reach agreement on the
ﬁnal model ranking result (to be committed on blockchain).
Note that in Algorithm 1, each validator can process multiple
FL model
transactions (including model downloading and
evaluation) in parallel to reduce the contract running time. As
seen in Table II, the average contract running time of validators
is 4.952 seconds and the time to reach agreement is 16.283
seconds, leading to a overall latency of about 21.1 seconds.

Table III compares the time cost of model operations
for pools and validators in PoFL and PF-PoFL under both
local and distributed settings. As seen in Table III, PoFL
involves huge computation cost in model evaluation process
(i.e., calculating model performance), especially for pools due
to the expensive HE operations. Compared with the PoFL
scheme, our PF-PoFL adds the Gaussian noise according to
Eqs. (7) and (8) to ensure UDP for miners, and the time
cost for pools in this process can be negligible. For model
ranking and veriﬁcation operations performed by validators,
PoFL only needs to determine the best model. It indicates
that if the model with the best performance is veriﬁed as
true, there is no need to verify other models. In our PF-PoFL,

10012014016018020001002003004005006007008009001000 TPS Block latencyBlock heightThroughput (TPS) 051015202530Block latency (second)0.512345678910-50050100150200250300350400450500 TPS Block latencyBlock size (MB)Throughput (TPS)152025303540455055Block latency (second)TABLE III
COMPUTATION COST OF MODEL OPERATIONS FOR POOLS AND VALIDATORS UNDER POFL AND OUR PF-POFL

16

Setting

Scheme

Setting 1

Setting 2

PoFL [15]
Ours
PoFL [15]
Ours

Pool
Model evaluation
1.7 × 106 s
Negligible
2.3 × 106 s
Negligible

Validator

Downloading Model veriﬁcation Model ranking
1.675 s
3.241 s
1.296 s
2.927 s

Negligible
Negligible
1.21 s
1.88 s

59 us
184 us
51 us
172 us

Total consensus delay
12.2 s
9.4 s
39.8 s
21.3 s

Fig. 9. Relative accuracy loss E(Ξj ) vs. average EMD Ξj (CIFAR-10).

Fig. 10. Test accuracy of federated mining vs. noise parameter σ and data
distribution, under different communication rounds (MNIST, N = 100).

each validator needs to test and sort all relevant models to
determine the ﬁnancial rewards and credit incentives in the
block rewarding contract, causing a longer running time (e.g.,
172 microseconds for model ranking and 2.927 seconds for
model veriﬁcation in setting 2) than that in the PoFL (e.g., 51
microseconds for model ranking and 1.296 seconds for model
veriﬁcation in setting 2). Besides, Table III shows that the
total consensus time for reaching agreement among validators
on a new block is about 9.4 seconds in our PF-PoFL in
setting 1 (resp. 21.3 seconds in setting 2), which is faster
than that in the PoFL, i.e., 12.2 seconds in setting 1 (resp.
39.8 seconds in setting 2). The reasons are as follows. On one
hand, the block proposal in PoFL involves huge storage space
for encrypted model parameters in HE and 2PC, resulting in
a higher block propagation latency. On the other hand, our
credit-based Algorand BA protocol can employ more honest
miners in the validator committee and incentivize miners to act
legitimately and actively, thereby reducing the voting stages
and the delay in reaching an unambiguous agreement.

C. Federated Mining with UDP

In this subsection, we evaluate the performance of the
federated mining process with UDP on MNIST and CIFAR-
10, in comparison with the baseline scheme, by changing the
number of miners and values of privacy parameters. In the
baseline scheme, the curator in a pool directly delivers the raw
global update (instead of the perturbed version) to all miners.
Fig. 9 illustrates the relationship between average EMD Ξj
and relative accuracy loss E(Ξj) in Eq. (25) on CIFAR-10
dataset under non-IID settings. As seen in Fig. 9, the relative
accuracy loss ﬁrst grows slowly and tends to increase fast
when Ξj > 1.2. Besides, when Ξj = 0, it corresponds to the

Fig. 11. Test accuracy of federated mining vs. noise parameter σ and data
distribution, under different communication rounds (CIFAR-10, N = 100).

IID case and we have E(Ξj) = 1. According to Eq. (22), a
higher EMD indicates a higher non-IID degree, and thereby a
larger drop on test accuracy.

Figs. 10 and 11 show the evolution of test accuracy on
MNIST and CIFAR-10 under different privacy parameters
in our UDP noise-adding mechanism, respectively, compared
with baseline schemes. In this simulation,
the number of
participating miners is ﬁxed as 100. As seen in Figs. 10 and
11, the test accuracy of the trained model via federated mining
with σ = 3 UDP noise is very close to the baseline under non-
IID, while the accuracies of the trained model with σ = 14
and σ = 24 are decreased to a certain degree. It is because a
higher σ implies a higher privacy preservation level, causing
larger perturbations to be added to the global model update

0.00.20.40.60.81.01.21.41.61.81.01.21.41.61.82.02.22.42.62.83.0Relative accuracy loss Average EMD 0204060801005060708090100Test accuracy (100%)Communication round  Baseline (no noise,IID)   Baseline (no noise, non-IID)  UDP noise, non-IID, s=3   UDP noise, non-IID, s=14   UDP noise, non-IID, s=2402040608010012014016018020001020304050607080Test accuracy (100%)Communication round  Baseline (no noise,IID)   Baseline (no noise, non-IID)  UDP noise, non-IID, s=3  UDP noise, non-IID, s=14   UDP noise, non-IID, s=2417

Fig. 12. Test accuracy of federated mining vs. number of participating miners
|(cid:61)j |, under different communication rounds (MNIST, σ = 3).

Fig. 14. Evolution of social welfare W ((cid:61)) of miner partition over time in
four schemes (N = 100).

Fig. 13. Test accuracy of federated mining vs. number of participating miners
|(cid:61)j |, under different communication rounds (CIFAR-10, σ = 3).

Fig. 15. Evolution of partition structure over time in terms of number of
pools and number of switch operations (N = 100).

in Eq. (8) which eventually deteriorates the model accuracy.
Moreover, compared with the IID case, the existence of non-
IID results in an accuracy drop to the baseline.

Figs. 12 and 13 show the evolution of test accuracy on
MNIST and CIFAR-10 under different pool sizes (i.e., number
of miners in a pool), respectively. In this simulation, we set
σ = 3. From Figs. 12 and 13, we can observe that with a larger
pool size, the performance of the trained model is improving
in terms of both accuracy and stability. The reason is that
given the ﬁxed sample ratio, when the number of participating
miners in a pool increases, the impact of the added UDP noise
to the global update in Eq. (8) can be reduced, resulting in
higher accuracy and stability in training FL models.

D. Federation Formation Game

In this subsection, we evaluate the performance of the
proposed federation formation game, in comparison with the
exhaustive optimal scheme, the non-cooperative scheme, and
the PoFL scheme [15]. In the exhaustive optimal scheme,
the optimal pool structure among miners is derived via the
exhaustive searching method in a centralized manner. In the
non-cooperative scheme, each miner behaves uncooperatively
and applies the solo-mining strategy in completing FL tasks.

In PoFL scheme [15], all miners utilize the off-the-shelf
ﬁxed pooled-mining structure in PoW-based blockchains for
federated mining. Here, the total number of miners is set as
N = 100, where miners perform federated mining on CIFAR-
10 using the ResNet18 model under the setting 1.

Fig. 14 compares the social welfare W deﬁned in formula
(29) in four schemes. As shown in Fig. 14, when the number
of iterations grows, the social welfare of miner partition in
the proposed FFG-TU game gradually converges to a stable
value after around 7 iterations. Besides, the proposed FFG-TU
game can yield a near-optimal performance, as its performance
gap to the exhaustive optimal solution does not exceed 2.1%
when h ≥ 7. In addition, as seen in Fig. 14, the stable social
welfare in our FFG-TU game is greater than that in the non-
cooperative scheme and the PoFL scheme, and it brings up to
about 67% improvement to the non-cooperative scheme and
about 17.6% improvement to the PoFL scheme when h = 10.
The reason is that in the non-cooperative scheme, all miners
work alone and each of them forms a singleton in conducting
FL tasks, resulting in the lowest social welfare. Besides, as
different miners generally have distinct training samples and
non-IID degrees under heterogenous FL tasks, the ﬁxed mining
pool structure in the PoFL scheme cannot adapt to the varying

020406080100020406080100Test accuracy (100%)Communication round  UDP noise, non-IID, 100 miners  UDP noise, non-IID, 50 miners406080100120140160180200666870727476788082Test accuracy (100%)Communication round  UDP noise, non-IID, 100 miners  UDP noise, non-IID, 400 miners  UDP noise, non-IID, 800 miners012345678910250300350400450500550Social welfare, WNumber of iterations, h  Exhaustive optimal partition  Proposed pool formation game   Non-cooperative scheme  PoFL01234567891001234567 # pools # switch operationsNumber of iterations, hNumber of pools, J01234567Number of switch operationsfederated mining environment, resulting in relatively lower
social welfare.

Fig. 15 further inspects the evolution of partition structure
among miners over time in terms of the number of pools
and the number of switch operations. As seen in Figs. 14
and 15, the switch operations at each iteration can improve
the social welfare for miners, which accords with Lemma 1.
Moreover, as observed in Fig. 15, the proposed pool formation
algorithm converges to a ﬁnal disjoint partition structure after
7 iterations and achieves Nash-stability, which accords with
Theorems 3 and 4. Besides, Fig. 15 shows that, the number
of switch operations | (cid:80)(h) | at each iteration h satisﬁes
| (cid:80)(h) | ≤ |(cid:61)(h)| + 1, where |(cid:61)(h)| is the number of pools
in current partition (cid:61)(h). The reason is that, according to the
switch rule and admission rule in Deﬁnitions 7 and 8, each
miner can either switch to another pool or form a singleton
if it decides to leave the current pool, while each pool only
admits the optimal miner greedily at each iteration.

According to the aforementioned results, our PF-PoFL can
effectively recycle energy for efﬁcient federated mining and
attain stable throughput of the blockchain system, low block
latency in reaching consensus, desirable model performance
with UDP guarantees, and optimized federated structure with
high social welfare.

VII. CONCLUSION

In this paper, we have proposed a novel energy-recycling
consensus mechanism named PF-PoFL, where the wasted
energy in solving cryptographic puzzles in PoW is reinvested
to FL. To implement PF-PoFL in a fully decentralized manner,
we utilize the blockchain to host the unﬁnished tasks, perform
model ranking, and enforce ﬁnancial settlement by devising
a novel block structure, a model ranking contract, and a
block rewarding contract. PF-PoFL also incorporates credit-
based incentives to motivate miners’ honest participation
and improve consensus efﬁciency. Furthermore, a user-level
privacy-preserving model training algorithm is designed to
offer rigorous privacy protection for miners in each pool. In
addition, based on the federation formation game, we present
an optimized pool formulation algorithm, where miners with
diverse characteristics (i.e., training samples, non-IID degree,
and network delay) in heterogenous FL tasks can self-organize
into a disjoint Nash-stable partition. Simulation results have
validated the efﬁciency and effectiveness of the proposed
PF-PoFL mechanism. For the future work, we will further
investigate the optimized PF-PoFL consensus mechanism with
optimal FL task rewarding, task difﬁculty adjustment function,
and non-reusability guarantees.

REFERENCES

[1] Y. Wang, Z. Su, J. Ni, N. Zhang, and X. Shen, “Blockchain-empowered
space-air-ground integrated networks: Opportunities, challenges, and
solutions,” IEEE Communications Surveys & Tutorials, vol. 24, no. 1,
pp. 160–209, 2022.

[2] Z. Xiong, J. Kang, D. Niyato, P. Wang, and H. V. Poor, “Cloud/edge
computing service management in blockchain networks: Multi-leader
multi-follower game-based admm for pricing,” IEEE Transactions on
Services Computing, vol. 13, no. 2, pp. 356–367, 2020.

18

[3] Y. Li, C. Chen, N. Liu, H. Huang, Z. Zheng, and Q. Yan, “A blockchain-
based decentralized federated learning framework with committee con-
sensus,” IEEE Network, vol. 35, no. 1, pp. 234–241, 2021.

[4] Y. Wang, Z. Su, N. Zhang, and A. Benslimane, “Learning in the
air: Secure federated learning for UAV-assisted crowdsensing,” IEEE
Transactions on Network Science and Engineering, vol. 8, no. 2, pp.
1055–1069, 2021.

[5] R. Zhang and B. Preneel, “Lay down the common metrics: Evaluating
proof-of-work consensus protocols’ security,” in IEEE Symposium on
Security and Privacy (SP), 2019, pp. 175–192.

[6] R. Chen, I.-P. Tu, K.-E. Chuang, Q.-X. Lin, S.-W. Liao, and W. Liao,
“Endex: Degree of mining power decentralization for proof-of-work
based blockchain systems,” IEEE Network, vol. 34, no. 6, pp. 266–271,
2020.

[7] Bitcoin energy consumption index. Accessed: Oct. 4, 2021. [Online].

Available: https://digiconomist.net/bitcoin-energy-consumption/

[8] M. Saad, Z. Qin, K. Ren, D. Nyang, and D. Mohaisen, “e-PoS: Making
proof-of-stake decentralized and fair,” IEEE Transactions on Parallel
and Distributed Systems, vol. 32, no. 8, pp. 1961–1973, 2021.

[9] G. Ateniese, I. Bonacina, A. Faonio, and N. Galesi, “Proofs of space:
When space is of the essence,” in International Conference on Security
& Cryptography for Networks, 2014, pp. 538–557.

[10] M. Ball, A. Rosen, M. Sabin, and P. N. Vasudevan, “Proofs of useful
work,” IACR Cryptology ePrint Archive, vol. 2017, pp. 1–28, 2017.
[11] K. Sunny, “Primecoin: Cryptocurrency with prime number proof-of-

work,” self-published, 2013.

[12] B. Li, C. Chenli, X. Xu, T. Jung, and Y. Shi, “Exploiting computation
power of blockchain for biomedical image segmentation,” in IEEE/CVF
Conference on Computer Vision and Pattern Recognition Workshops
(CVPRW), 2019, pp. 2802–2811.

[13] Y. Lan, Y. Liu, B. Li, and C. Miao, “Proof of learning (PoLe):
Empowering machine learning with consensus building on blockchains
(demo),” in Proceedings of AAAI, vol. 35, no. 18, May 2021, pp. 16 063–
16 066.

[14] C. Chenli, B. Li, Y. Shi, and T. Jung, “Energy-recycling blockchain
with proof-of-deep-learning,” in IEEE International Conference on
Blockchain and Cryptocurrency (ICBC), 2019, pp. 19–23.

[15] X. Qu, S. Wang, Q. Hu, and X. Cheng, “Proof of federated learning:
A novel energy-recycling consensus algorithm,” IEEE Transactions on
Parallel and Distributed Systems, vol. 32, no. 8, pp. 2074–2085, 2021.
[16] A. Shoker, “Sustainable blockchain through proof of exercise,” in IEEE
16th International Symposium on Network Computing and Applications
(NCA), 2017, pp. 1–9.

[17] P. Daian, I. Eyal, A. Juels, and E. G. Sirer, “(short paper) PieceWork:
Generalized outsourcing control for proofs of work,” in Financial
Cryptography Workshops, 2017, pp. 182–190.

[18] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich, “Algorand:
Scaling byzantine agreements for cryptocurrencies,” in Proceedings of
26th Symposium on Operating Systems Principles (SOSP), 2017, pp.
51–68.

[19] L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” in Proceed-

ings of NeurIPS, 2019, pp. 1–11.

[20] Z. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, and H. Qi, “Beyond
inferring class representatives: User-level privacy leakage from federated
learning,” in Proceedings of IEEE INFOCOM, 2019, pp. 2512–2520.

[21] R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership
inference attacks against machine learning models,” in IEEE Symposium
on Security and Privacy (SP), 2017, pp. 3–18.

[22] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov,
K. Talwar, and L. Zhang, “Deep learning with differential privacy,” in
Proceedings of ACM CCS, 2016, pp. 308–318.

[23] M. Zhang, E. Wei, and R. Berry, “Faithful edge federated learning:
Scalability and privacy,” IEEE Journal on Selected Areas in Communi-
cations, vol. 39, no. 12, pp. 3790–3804, 2021.

[24] K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin,
T. Q. S. Quek, and H. V. Poor, “Federated learning with differential
privacy: Algorithms and performance analysis,” IEEE Transactions on
Information Forensics and Security, vol. 15, pp. 3454–3469, 2020.
[25] F. Bravo-Marquez, S. Reeves, and M. Ugarte, “Proof-of-learning: A
blockchain consensus mechanism based on machine learning competi-
tions,” in IEEE International Conference on Decentralized Applications
and Infrastructures (DAPPCON), 2019, pp. 119–124.

[26] R. C. Geyer, T. Klein, and M. Nabi, “Differentially private federated
learning: A client level perspective,” arXiv preprint arXiv:1712.07557,
pp. 1–7, 2017.

[27] D. Boneh, B. Lynn, and H. Shacham, “Short signatures from the weil
pairing,” Advances in Cryptology — ASIACRYPT, vol. 2248, 2001.

[28] J. Benet, “IPFS-content addressed, versioned, P2P ﬁle system,” arXiv

preprint arXiv:1407.3561, pp. 1–11, 2014.

[29] J. Kang, Z. Xiong, X. Li, Y. Zhang, D. Niyato, C. Leung, and C. Miao,
“Optimizing task assignment for reliable blockchain-empowered fed-
erated edge learning,” IEEE Transactions on Vehicular Technology,
vol. 70, no. 2, pp. 1910–1923, 2021.

[30] J. Chen and S. Micali, “Algorand,” arXiv preprint arXiv:1607.01341,

pp. 1–75, 2016.

[31] Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra, “Federated
learning with non-IID data,” arXiv preprint arXiv:1806.00582, pp. 1–13,
2018.

[32] J. Konecn´y, H. B. McMahan, D. Ramage, and P. Richt´arik, “Federated
optimization: Distributed machine learning for on-device intelligence,”
ArXiv preprint arXiv:1712.07557, pp. 1–38, 2016.

[33] N. Ding, Z. Fang, and J. Huang, “Optimal contract design for efﬁcient
federated learning with multi-dimensional private information,” IEEE
Journal on Selected Areas in Communications, vol. 39, no. 1, pp. 186–
200, 2021.

[34] M. Li, T. Zhang, Y. Chen, and A. J. Smola, “Efﬁcient mini-batch training
for stochastic optimization,” in Proceedings of ACM SIGKDD, 2014, pp.
661–670.

[35] A. Das and M. M. Islam, “SecuredTrust: A dynamic trust computa-
tion model for secured communication in multiagent systems,” IEEE
Transactions on Dependable and Secure Computing, vol. 9, no. 2, pp.
261–274, 2012.

[36] T. Wang, L. Song, Z. Han, and B. Jiao, “Dynamic popular content
distribution in vehicular networks using coalition formation games,”
IEEE Journal on Selected Areas in Communications, vol. 31, no. 9,
pp. 538–547, 2013.

[37] W. Saad, Z. Han, A. Hjorungnes, D. Niyato, and E. Hossain, “Coalition
formation games for distributed cooperation among roadside units in ve-
hicular networks,” IEEE Journal on Selected Areas in Communications,
vol. 29, no. 1, pp. 48–60, 2011.

[38] J. S. Ng, W. Y. B. Lim, Z. Xiong, X. Cao, J. Jin, D. Niyato, C. S. Leung,
and C. Miao, “Reputation-aware hedonic coalition formation for efﬁcient
serverless hierarchical federated learning,” IEEE Transactions on Paral-
lel and Distributed Systems, 2021, doi: 10.1109/TPDS.2021.3139039.

[39] Go-Algorand project. [Online]. Available: https://github.com/algorand/

go-algorand

[40] PyTeal: Algorand smart contracts in Python.

[Online]. Available:

https://pyteal.readthedocs.io/en/latest/

[41] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
applied to document recognition,” Proceedings of the IEEE, vol. 86,
no. 11, pp. 2278–2324, 1998.

[42] A. Krizhevsky and G. Hinton, “Learning multiple layers of features from
tiny images,” Handbook of Systemic Autoimmune Diseases, vol. 1, no. 4,
2009.

Yuntao Wang is working on his Ph.D degree with
the school of Cyber Science and Engineering, Xi’an
Jiaotong University, Xi’an, China. His research in-
terests include security and privacy protection in
wireless networks, vehicular networks, and UAV
networks.

19

Haixia Peng received her Ph.D. degrees in Com-
puter Science and Electrical & Computer Engi-
neering from Northeastern University (Shenyang,
China) in 2017 and the University of Waterloo
(Waterloo, Canada) in 2021, respectively. She is
currently an Associate Professor with the School
of Information and Communications Engineering,
Xi’an Jiaotong University, China. Her research inter-
ests include satellite-terrestrial vehicular networks,
multi-access edge computing, resource management,
learning.
intelligence, and reinforcement
artiﬁcial
She serves/served as a TPC member in IEEE VTC-fall 2016&2017, IEEE
ICCEREC 2018, IEEE GlobeCom 2016-2022, and IEEE ICC 2017-2022
conferences and serves as an Associate Editor for the PEER-TO-PEER NET-
WORKING AND APPLICATIONS.

Zhou Su is an Associate Editor of IEEE INTER-
NET OF THINGS JOURNAL, IEEE OPEN JOURNAL
OF COMPUTER SOCIETY, and IET COMMUNICA-
TIONS. His research interests include wireless net-
working, mobile computing, and network security.
He served as the track/symosuim chair for sev-
eral international conferences including IEEE VTC,
IEEE/CIC ICCC, WCSP, and so on. He received
the best paper award of IEEE ICC2020, IEEE Big-
dataSE2019, IEEE CyberSciTech2017, and so on.

Tom H. Luan received the Ph.D. degree from
the University of Waterloo, Canada, in 2012. He
is currently a Professor with the School of Cy-
ber Engineering, Xidian University, China. He has
authored/coauthored more than 40 journal articles
and 30 technical articles in conference proceedings.
He awarded one U.S. patent. His research mainly
focuses on content distribution and media streaming
in vehicular ad hoc networks and peer-to-peer net-
working and the protocol design and performance
evaluation of wireless cloud computing and edge
computing. He served as a TPC Member for IEEE Globecom, ICC, and
PIMRC.

Abderrahim Benslimane is Full Professor with the
Laboratory of Computer Sciences at the Avignon
University, France. He is Chair of the ComSoc
Technical Committee of Communication and Infor-
mation Security. He is EiC of Inderscience Int. J.
of Multimedia Intelligence and Security (IJMIS),
Area Editor of Security in IEEE IoT Journal, Area
Editor of Wiley Security and Privacy Journal and
Editorial Member of IEEE Wireless Communication
Magazine, Elsevier Ad Hoc, IEEE Systems and
Wireless Networks Journals.

Yuan Wu received the PhD degree in Electronic
and Computer Engineering from the Hong Kong
University of Science and Technology in 2010. He
is currently an Associate Professor with the State
Key Laboratory of Internet of Things for Smart City,
University of Macau and also with the Department
of Computer and Information Science, University
of Macau. His research interests include resource
management for wireless networks, green communi-
cations and computing, mobile edge computing and
edge intelligence. He was a recipient of the Best
Paper Award from the IEEE ICC2016, and the Best Paper Award from
IEEE Technical Committee on Green Communications and Computing in
2017. He is currently on the Editorial Boards of IEEE TRANSACTIONS ON
VEHICULAR TECHNOLOGY, IEEE TRANSACTIONS ON NETWORK SCIENCE
AND ENGINEERING, IEEE INTERNET OF THINGS JOURNAL, and IEEE
OPEN JOURNAL OF THE COMMUNICATIONS SOCIETY.

