2
2
0
2

p
e
S
3
1

]

M
M

.
s
c
[

1
v
1
6
7
5
0
.
9
0
2
2
:
v
i
X
r
a

1

A Survey on Mobile Edge Computing for Video
Streaming: Opportunities and Challenges
Muhammad Asif Khan∗, Emna Baccour‡, Zina Chkirbene†, Aiman Erbad‡, Ridha Hamila†, Mounir Hamdi‡ and
Moncef Gabbouj§
Qatar University∗†, Hamad Bin Khalifa University‡, Tampere University§
Email: {asifk, aerbad}@ieee.org∗‡, {hamila, zina.chk}@qu.edu.qa†, {ebaccourepbesaid, mhamdi}@hbku.edu.qa‡,
moncef.gabbouj@tuni.ﬁ§

Abstract—5G communication brings substantial improvements
in the quality of service provided to various applications by
achieving higher throughput and lower latency. However, inter-
active multimedia applications (e.g., ultra high deﬁnition video
conferencing, 3D and multiview video streaming, crowd-sourced
video streaming, cloud gaming, virtual and augmented reality)
are becoming more ambitious with high volume and low latency
video streams putting strict demands on the already congested
networks. Mobile Edge Computing (MEC)
is an emerging
paradigm that extends cloud computing capabilities to the edge of
the network i.e., at the base station level. To meet the latency re-
quirements and avoid the end-to-end communication with remote
cloud data centers, MEC allows to store and process video content
(e.g., caching, transcoding, pre-processing) at the base stations.
Both video on demand and live video streaming can utilize MEC
to improve existing services and develop novel use cases, such as
video analytics, and targeted advertisements. MEC is expected to
reshape the future of video streaming by providing ultra-reliable
and low latency streaming (e.g., in augmented reality, virtual
reality, and autonomous vehicles), pervasive computing (e.g., in
real-time video analytics), and blockchain-enabled architecture
for secure live streaming. This paper presents a comprehensive
survey of recent developments in MEC-enabled video streaming
bringing unprecedented improvement to enable novel use cases. A
detailed review of the state-of-the-art is presented covering novel
caching schemes, optimal computation ofﬂoading, cooperative
caching and ofﬂoading and the use of artiﬁcial intelligence (i.e.,
machine learning, deep learning, and reinforcement learning) in
MEC-assisted video streaming services.

Index Terms—Live streaming, Machine Learning, Mobile Edge

Computing, VoD, Video Streaming.

I. INTRODUCTION

The emergence of 5G brings substantial improvements in
quality of service by achieving higher throughput and lower
latency. These advantages enable network providers to tailor
the quality of experiences for new use cases across different
vertical markets. However,
these new capabilities on one
side are promising to transform industries, but on the other
side, the massive wave of new devices and bandwidth inten-
sive multimedia applications supported by 5G, trigger new
challenges. In the context of video streaming, the improved
cellular bandwidth has enabled novel use cases of video
streaming e.g. ultra HD (e.g. 4K and 8K) videos, 3D videos,
360◦ videos, virtual and augmented reality and interactive
video streaming. These new classes of video streaming put
forward new demands in terms of reliable computation and
reduced delay to match the desired quality of experience.

These services traditionally rely on cloud computing in which
the data storage and computational resources reside at the
cloud servers. However, as the network scales, the increasing
number of users requests can lead to signiﬁcant increase in
latency. Several factors add to the end-to-end latency i.e.,
delay caused by ofﬂoading the computation to the cloud, delay
of processing and queuing at the cloud server and network
communication delay to transmit the requested video back
to the user. Furthermore, as the number of requests grows,
meeting the delay requirement of latency-sensitive applications
becomes challenging.

While latency is the key factor in the context of video
streaming, there are a number of other beneﬁts that can be
achieved using MEC as compared to the traditional cloud
computing paradigm. For instance, popular video streaming
services such as Netﬂix [1], Hulu [2], and Amazon Prime
[3] create a heavy load on network. MEC can be used to
cache popular content closer to the end users for a smoother
experience. In cloud-based video streaming, the content is
stored relatively far from the user geographical
locations
leading to a poor user’s experience when there is a congestion
along the end to end route. Cloud-based streaming services
also suffers from quality of service (QoS) degradation when
the users requesting similar video content grows abruptly.

To alleviate the issues of traditional cloud service models,
mobile edge computing is emerging as a promising solution.
The primary beneﬁt of edge computing is to bring the storage
and computing capabilities closer to the end users i.e., at
the edge of the network. In MEC assisted 5G networks, the
storage and computing services can be deployed at the network
edge (i.e., within the RAN) to enable network providers
better handle latency-sensitive services. MEC can bring a
range of beneﬁts to users as well as network providers. By
providing storage and computing resources at the edge of
the network (i.e. RAN), communication latency is reduced.
Content providers can use edge storage capability to cache the
content locally which reduces the bandwidth resources on the
backhaul links. Distributed computing and storage resources
improve resiliency and availability using collaboration among
edge servers. Users can access content at lower costs available
locally. Edge computing can also enhance security and greater
improve scalability due to the fact that any attack on an edge
server will affect the users connected to that server and not the
whole network. These beneﬁts are of MEC are further detailed

 
 
 
 
 
 
in Section III.

MEC is still an emerging area and a huge amount of
research work on mobile edge computing is in progress.
MEC can help revolutionize several sectors including but not
limited to, enterprises, smart buildings, healthcare, vehicles-
to-infrastructure (V2I) services, Internet of Things, video
streaming and virtual and augmented reality. Several survey
papers exist to summarize the ongoing research efforts on
mobile edge computing. A large number of these surveys
provide a high-level broader view of the research area covering
different aspects e.g. architectural development, functional
overview, data caching, computational ofﬂoading, potential
use cases, opportunities and challenges [4]–[17]. Some of
these works cover speciﬁc aspects e.g. computation ofﬂoading
[5], [18]–[20], communication [21] and security [22]–[27].
There are few studies covering edge computing research in
particular applications such as IoT [28]–[30], whereas some of
these aim to cover the state-of-the-art scientiﬁc contributions
of integrating edge computing with sophisticated machine
learning and deep learning [6], [31]–[34]. A summary of these
surveys is presented in Table I.

Although most of the aforementioned survey papers (sum-
marised in Table I) provide a detailed review of research
efforts on mobile edge computing, we realise it is worthy that
the huge amount of research works on MEC-assisted video
streaming services shall be reviewed and summarized. In this
survey, we provide a comprehensive review of the state-of-
the-art in mobile edge computing for video streaming use
cases. The paper describes different types of video streaming
services and the associated challenges, and explains how these
applications can beneﬁt from using edge computing. Although
we aim at focusing on video streaming, nevertheless we
included reference works which are not explicitly proposed for
video streaming use cases, but these have good correlation and
are readily applicable in the relevant use-cases. We dedicate
separate sections for novel research contributions in the area
of cooperative device-to-device (D2D) communication and
machine learning and their respective beneﬁts and applications
in MEC-assisted video streaming.

The organization of the paper is illustrated in Figure I.
Section II presents an overview of video streaming services
outlining different types of video streaming services, listing
streaming protocols and video streaming challenges in terms of
the quality of experience. Section III provides a brief overview
of mobile edge computing, explaining the architecture, func-
tional overview, fundamental deﬁnitions and related concepts.
Section IV explains how MEC can improve video streaming
services in different streaming use cases. A detailed review
of the state-of-the-art on mobile edge computing for video
streaming is presented in Section V, with separate subsections
dedicated for research contributions in edge caching and
computational ofﬂoading. Sections VI and VII summarise the
most recent developments on edge computing techniques using
cooperative networking and machine learning respectively. The
abbreviations and acronyms used in this paper are listed in
Table II.

2

Figure 1. Paper Organization: Illustration of various topics covered in each
section.

II. VIDEO STREAMING - TYPES, PROTOCOLS AND
CHALLENGES

Video streaming is the method of viewing videos without

downloading the media ﬁles.

A. Types of Video Streaming

Video streaming is not only at the forefront of entertainment
industry but also is transforming several other sectors such
as enterprises, education, retail, tourism, transportation and
healthcare. The unprecedented use cases of video streaming
are reshaping the Internet, while at the same time, network
and content providers are doing huge investments in improving
user experience in video streaming services. Generally, video
streaming applications can be broadly categorized as Video on
Demand (VoD) and Live video streaming.

1) VoD Streaming: VoD streaming allows users to watch
stored videos from any Internet-connected devices at any
suitable time. In VoD streaming, content can be prefetched,
stored and edited before it is distributed. Popular applications
of VoD streaming are Netﬂix [1], Apple iTunes Store [38], and
YouTube. There are three popular models of VoD streaming
in today’s video streaming world.

2) Live Streaming: Unlike VoD streaming, in live video
streaming the video is distributed in real-time directly from
the origin device to the destination, without ﬁrst storing it on
a server. Live videos are more sensitive to network delays as
compared to VoD streaming. The use of live video streaming
is increasing over time [39] due to multiple reasons such as the
availability of high quality cameras in the modern smartphones
that enable users to shoot high quality videos, and the high
data rates of 5G, enabling the users to share videos over the
internet in real time. Live video streaming has many attractive

IV.  Mobile Edge Computing Applications in Video Streaming I.  IntroductionIII.  Mobile Edge Computing Overview, Applications and Resource AllocationII.  Video StreamingTypes, Protocols and ChallengesV.  State-of-the-art in MEC-based Video StreamingVI.  D2D Cooperation in MEC Systems D2D in caching and offloadingVII.  Machine Learning in Edge Computing Proactive caching & offloading, adaptive streaming, analytics, AR/VRVIII.  Future Research Directions MEC in 5G/6G, Resource migration, Video analytics for drones, AR/VR/MRand 360 videos, IX.  ConclusionsTable I
COMPARATIVE STUDY OF THIS PAPER WITH EXISTING SURVEYS ON EDGE COMPUTING. THE SYMBOL (cid:88) INDICATES A PUBLICATION IS IN THE SCOPE OF
A DOMAIN; (cid:55) MARKS PAPERS THAT DO NOT DIRECTLY COVER THAT AREA, BUT FROM WHICH READERS MAY RETRIEVE SOME RELATED INSIGHTS; (cid:3)
INDICATES THE TOPIC IS COVERED BUT IN LESS DEPTH.

Ref

One-sentence summary

Scope of the Publication

3

Wang et al. [31]

Deep learning in edge computing

Deng et al. [32]

Artiﬁcial Intelligence (AI) in edge computing

Carvalho et al. [33]

Using AI for computation ofﬂoading in edge computing for

Cao et al. [4]

Lin et al. [5]

Overview of edge computing research

A survey of computation ofﬂoading techniques in edge computing

Shakarami et al. [6]

A survey of computation ofﬂoading techniques in edge and cloud computing

Xiao et al. [22]

A survey on security challenges in edge computing

Yang et al. [23]

A survey on integration of bloackchains and edge computing

Liu et al. [24]

A survey on secured edge-based data analytics

Jiang et al. [19]

A survey of computation ofﬂoading in edge computing

Lin et al. [20]

A survey of computation ofﬂoading in edge computing

Donno et al. [7]

A tutorial on modern computing paradigms

Khan et al. [8]

A survey on edge computing applications

Hassan et al. [9]

A review of edge computing in 5G networks

Chen et al. [34]

A review of deep learning applications in edge computing

Zhang et al. [25]

A survey on security and privacy in edge computing and

Marjanovic et al. [28]

A tutorial on edge computing for crowdsensing

Porambage et al. [29]

A survey on application of edge computing in Internet of Things (IoT)

Abbas et al. [10]

A tutorial and survey on mobile edge computing

Wang et al. [11]
Baktir et al. [12]

A survey on edge computing services
A survey on software-deﬁned networking in edge computing

Ahmed et al. [13]

A survey of the state-of-the-art in mobile edge computing

Taleb et al. [14]

A survey of edge computing in 5G networks

Mao et al. [15]

A review of the state-of-the-art in mobile edge computing

Mao et al. [21]

A survey of communication techniques in mobile edge computing

Shirazi et al. [27]

A tutorial on security in mobile edge and fog computing

Yu et al. [30]

A survey and tutorial on edge computing in IoT

Ahmed et al. [16]

A survey of mobile edge computing systems

Shi et al. [17]

A futuristic overview of mobile edge computing

Jiang et al. [35]

MEC in Video Streaming

Kanai et al. [36]

MEC for multimedia applications

Zhang et al. [37]

MEC for video analytics in public safety

g
n
i
m
a
e
r
t
s

o
e
d
i
V

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)
(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:3)

g
n
i
d
a
o
ﬂ
f
O

(cid:55)

(cid:55)

/

L
D
L
M

(cid:88)

(cid:88)

(cid:88) (cid:88)

(cid:55)

(cid:55)

(cid:88) (cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:55)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88) (cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)
(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

e
r
u
t
c
e
t
i
h
c
r
A

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

g
n
i
h
c
a
C

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88) (cid:88) (cid:88)
(cid:55)
(cid:55)
(cid:88)

(cid:55)

(cid:88)

(cid:55)

(cid:88) (cid:88) (cid:88)

(cid:88)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:88)

(cid:88) (cid:3) (cid:88)

(cid:55)

(cid:3)

(cid:3)

(cid:55)

(cid:3)

(cid:55)

This survey

A survey of MEC in video streaming covering the MEC architecture, video
streaming applications and novel services, and traditional and state-of-the-art
techniques for edge-based caching and processing. It also covers the use of
ML and pervasive computing including D2D for the next generation intelligent
edge services.

(cid:88) (cid:88) (cid:88) (cid:88) (cid:88)

Table II
SUMMARY OF ACRONYMS.

Acronym Deﬁnition

3D
3GPP
4K
5G
ABR
AI
AR
BS
CC
CDN
CMAF
CNN
D2D
DL
DNN
DOS
DQN
DRL
EC
ETSI
FIFO
FOV
HD
HDS
HLS
HTTP
ILP
INLP
IoT
ISG
ISG
LFU
LLR
LRU
LRFU
LSTM
MDP
MEC
MEC
MILP
ML
MLR
DASH
MPV
MPEG
MSS
NFV
PcP
P-UPP
PoP
QoE
QoS
R-UPP
RAN
RFC
RL
RNN
RTMP
RTP
RTSP
SIP
SRT
TDMA
UA
UAV
UPP
URRLC
V2I
VoD
VR
WebRTC Web Real-Time Communications

Three Dimensional
Third Generation Partnership Project
Horizontal video resolution of 4000 pixels
Fifth-Generation
Adaprive Bit Rate
Artiﬁcial Intelligence Internet
Augmented Reality
Base Station
Cloud Computing
Content Delivery Network
Common Media Application Format
Convolutional Neural Network Recurrent
Device to Device
Deep Learning
Deep Neural Network
Denial Of Service
Deep Q-learning Network
Deep Reinforcement Learning
Edge Computing
European Telecommunication Standards Institute
First In First Out
Field of View
High Deﬁnition
HTTP Dynamic Streaming
HTTP Live Streaming
Hypertext Transfer Protocol
Integer Linear Programming
Integer Non-Linear Programming
Internet of Things
Industry Speciﬁcation Group
Industry Speciﬁc Groups
Least Frequently Used
Least Likely Requested
Least Recently Used
Least Recently Frequency Used
Long-short Term Memory model
Markov Decision Problem
Mobile Edge Computing
Mobile (or Multi-Access) Edge Computing
Mixed Integer Linear Programming
Machine Learning
Most Likely Requested
Dynamic Adaptive Streaming over HTTP
Most Popular Videos
Motion Picture Expert Group
Microsoft Smooth Streaming
Network Function Virtualization
Proactive Cache Policy
Proactive User Preference Proﬁle
Point of Presence
Quality of Experience
Quality of Service
Reactive User Preference Proﬁle
Radio Access Network
Request For Comments
Reinforcement Learning
Recurrent Neural Network
Real-Time Messaging Protocol
Real-Time Transport Protocol
Real-Time Streaming Protocol
Session Initiation Protocol
Secure Reliable Transport
Time Devision Multiple Access
User Attrition
Unmanned Aerial Vehicle
User Preference Proﬁle
Ultra-reliable Low-latency Communications
Vehicle to Infrastructure
Video On Demand
Virtual Reality

4

applications such as E-Sports and Game Streaming [40]–
[44], virtual reality and augmented reality, user-generated live
streaming (e.g. Periscope [45], Youtube Live [46], Twitch [47],
Facebook Live [48], Instagram Live [49], Twitter Live [50]
and Ustream [51]) and online learning (e.g. Dacast [52], IBM
Cloud Video [51], Kaltura [53], Vimeo Live [54] and Panopto
[55]). In the following, we categorize the live streaming by
application scenarios:

live streaming videos: This type of ap-
• Conventional
including Twitch, YouTube live, Facebook
plications,
live, allows random users to capture live videos using
their handheld devices. In such applications,
the live
system needs to handle a huge volume of videos from
broadcasters to thousands of viewers located all over
the world in a very short end-to-end latency (e.g., 100
ms [56]). Moreover, to provide the required formats to
viewers based on their preferences, the capability of their
devices, and the quality of the network, the videos should
be transcoded. This transcoding task needs to be done in
real-time and adapts on the ﬂy to the available computing
resources to match the spontaneous broadcasts.

• Streaming 360o (or panoramic) videos: This type of
streaming is more challenging than conventional videos
as it requires higher bandwidth availability due to the vol-
ume of the content. Moreover, such live stream allows a
ﬂexible interaction, i.e., the user can potentially move and
expects to see different views of the panorama. Therefore,
the latency and delay variance are even stricter in order
to update the display without any motion sickness. This
delay is called motion-to-photon latency and should not
exceed few milliseconds, in order to provide a smooth
experience [57].

• VR/AR live streaming: The Virtual Reality (VR) is a
simulated experience that can be ﬁctional or similar to the
real world. Multiple features characterize the VR systems,
which are the imagination, interaction, and immersion,
in addition to the integration of the VR user in the
virtual environment. The VR experience requires a device
with a screen, computing components and sensors that
track the user’s motions. The VR live streaming has
the same requirements as conventional and 360o live
videos, including those related to network parameters
(e.g., bandwidth, latency, stalling, buffering time, and
bitrate switching) and the application parameters (e.g.,
video quality, frame rate, and resolution) with higher
constraints on the delay variance and image freezing to
avoid motion sickness. Besides these requirements, the
VR system depends also on physical environment factors
(e.g., sounds, objects locations, and lighting) and user’s
proﬁle (e.g., gender and length), which highly inﬂuence
the quality of the experience [58]. The Augmented Re-
ality (AR) is also a real-world interactive experience,
where real or ﬁctive objects are enhanced and integrated
into the user’s experience. In terms of system require-
ments, combining the real world environment with the
augmented objects is very critical, as the AR algorithm
has to superimpose these objects into the coordinates of

the user’s location with a high accuracy.
Even though the AR and VR technologies brought new
opportunities in various industries and applications (e.g.,
medicine, maintenance, sports,
tourism and
architecture.), they also added new challenges related to
image display, delivery and content storage.

teaching,

Figure 2 illustrates a generic functional architecture of VoD
streaming and live streaming. In VoD streaming (black lines),
the videos are recorded ﬁrst, then transcoded to one or more
bit rates versions, and then stored on a cloud server. The
viewers can request and access these stored videos anytime
using different protocols such as HLS. In most of the video
deployments, there are also geographically distributed servers
(also known as point of presence (POP)) that cache the videos
from the remote cloud and serve them to the user when
requested. In the case of live streaming (red lines), videos
are transmitted to the end user without storing them ﬁrst on
the cloud. However, videos are still being transcoded in live
video streaming, as different users can request different bit
rate versions of the video based on the quality of the wireless
channel.

Both VoD and Live video streaming are likely to co-exist
as both have different applications and use cases. VoD gives
users the opportunity to watch videos anytime, anywhere and
from any device using the Internet. On the other hand, live
streaming provides great convenience to users to share videos
in real time without ﬁrst recording them.

B. Video Streaming Protocols

Video streaming protocols can be broadly categorized as
(1) Push-based (non-HTTP) and (2) Pull-based (HTTP-based)
protocols. Push-based protocols are traditional streaming pro-
tocols in which the server and client ﬁrst establish a connection
before transmitting data. These include RTMP (Real-Time
Messaging Protocol) [59] and RTSP (Real-Time Streaming
Protocol) [60], and SIP (Session Initiation Protocol).

Since 2010, pull-based protocols have been introduced
e.g. HLS (HTTP Live Streaming) [61], Low Latency HLS
[62], MPEG-DASH (Moving Picture Expert Group -Dynamic
[63], CMAF (Common
Adaptive Streaming over HTTP)
Media Application Format)
for DASH [64], MSS (Mi-
crosoft Smooth Streaming) [65], Adobe HDS (HTTP Dynamic
Streaming) [66], SRT (Secure Reliable Transport) [67] and
WebRTC (Web Real-Time Communications) [68].

HLS is the most widely used pull-based streaming protocol
[69] supported by many media players, web browsers, devices,
and streaming media servers. Low-Latency HLS [62] is an
improved version of HLS which provide low latency (up to
2 seconds). The Adobe HDS was the ﬁrst adaptive bitrate
(ABR) protocol. Subsequently, Microsoft developed its own
adaptive bitrate protocol for video streaming i.e., MSS in 2008
to deliver on-demand video of the 2008 Summer Olympics.
MPEG-DASH is an open standard adaptive bitrate streaming
protocol, whereas CMAF was developed by joint collaboration
of Microsoft, Apple and MPEG to simplify the streaming ser-
vices. The most recent addition to this list is the open standard
WebRTC framework. Today HLS is the standard platform for

5

Apple whereas MPEG-DASH is the international standard [63]
for video streaming. Table III presents a summary of various
video streaming protocols. A comparison of streaming delay
(i.e. media transfer delay) of these protocols is illustrated in
Figure 3.

Table III
VIDEO STREAMING PROTOCOLS.

Protocol

Developer

Year

Latency(s)

ABR

RTMP
RTSP/RTP
HLS
LL-HLS
MPEG-DASH
CMAF
MSS
HDS v3
SRT
SIP/RTP
WebRTC

Macromedia
IETF
Apple
Apple
MPEG
MPEG
Microsoft
Adobe
Haivision
IETF
IETF

2012
1998
2009
2009
2011
2018
2008
2013
2013
1999
2011

Low
Ultra low
Reduced
Low
High
Low
Reduced
Reduced
Low
Reduced
Ultra low

(cid:88)
(cid:55)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

Video streaming protocols can be generally categorized
(based on latency) as (i) High Latency (> 18 seconds),
(ii) reduced latency (10-18 seconds), (iii) low latency (4-10
seconds) and (iv) Ultra low latency (1-4 seconds) [70].

C. Video Streaming Challenges

Video streaming applications are gaining popularity due to
the inherited convenience for sharing content. However, there
are several challenges in live video streaming . The three major
challenges associated with video streaming services are:

• Limited Bandwidth: Modern 5G networks offer higher
the growing use of
data rates over cellular links but
video content with a much higher resolution than before
is making the bandwidth limitations more prevalent. In
particular, the modern 4K (3840 × 2160), 8K (7680 ×
4320), and 360◦ videos are bandwidth intensive [71].
On average, the 4K videos requires bit rate of 20-50
Mbps, whereas 8K videos requires 50-200 Mbps [72]. To
understand the bandwidth requirement of these videos, a
60-frame 4K video consumes 1GB to 10GB of trafﬁc per
minute, and a 20 min 4K video requires almost 100 GB of
trafﬁc [72]. The use of these high resolution videos is also
continuously increasing. It is estimated that by 2023, 66%
of connected ﬂat-panel TV sets will be 4K. [73] The 360◦
videos are even more bandwidth intensive as in these,
pixels are transmitted to users from every direction. The
efﬁcient transmission of such huge volumes of bandwidth
intensive videos is a challenge yet to continue. As also
indicated in [74], 5G systems fall short of providing a
full immersive extended reality (XR) experience due to
lack of support for ultra-low latency and higher data rates
in such applications.

• Latency: Video streaming in general and live streaming
in particular are sensitive to latency. Higher latency leads
to poor user experience in many applications, such as
real-time online video gaming, virtual reality, and live
streaming of high resolution videos such as 4K and
8K. With the existing content distribution architecture

6

Figure 2. Video on Demand (VoD) versus Live streaming.

Figure 3. Video Streaming Protocols - Delay Comparison.

that relies on cloud computing, latency guarantees is a
critical challenge [21]. Similarly, in the next generation
Industrial IoT (IIoT) and applications such as autonomous
imaging for
vehicles, augmented reality and medical
remote surgeries, 5G cannot meet the sub-millisecond
latency [75].
In VoD streaming, videos are stored in remote cloud
servers. The larger propagation distance between the
cloud servers and the end users encounter delay dete-
riorate the user experience. To cope with this, content
delivery network (CDN) servers are usually deployed to
cache content from remote cloud servers to relatively
closer servers located in different geographical areas.
However, the CDN servers are deployed in relatively few
locations and often not located in densely populated areas
where viewers may reside. The transmission of video
streams from these centralized cloud servers to viewers
that are far apart, requires extensive bandwidth and can
often create bottlenecks as the number of viewers grows.
This results in inconsistent and higher startup delays,
video quality degradation, and sometimes the inability
to join popular live streams.

In contrast to VoD streaming live video streaming is more
sensitive to network delays due to the fact that live videos
are not cached and are directly transmitted from origin
to the viewer. Live videos hold users’ attention 10 − 20×
longer than VoD videos [76].
In Facebook, live videos
appear at the top of news feed. Also, users in a page
receive notiﬁcations about a new live video post, thus the
number of viewers increases rapidly. Furthermore, live
streaming has random viewing patterns with very high
peaks. The high number of simultaneous user requests can
cause a problem known as “Thundering Herd problem”
[77]. A ﬁne example of such sudden increase in demand
of live video is the popular online trivia craze [78], where
the demand for online streams grew from zero to over
one million viewers in just a matter of minutes. Another
example is a 45 minutes video of two people exploding
a watermelon with rubber bands, which reached a peak
of over 800,000 simultaneous viewers [79]. Thus, the
rapidly increasing viewing patterns of live videos can
cause network congestion that results in higher end to
end delay.

• Jitter: Jitter or delay variation is the undesired deviation
from true periodicity of an assumed periodic signal.
Jitters can be caused by ﬂuctuations in queuing and
scheduling delays [80]. Packets transmitted on the net-
works encounter different delays due to two reasons:
First, packets route through the network independently,
Second, network devices receives packets in queue and
thus encounter different queuing delay. Thus, packets
transmitted even at almost same time (consecutive pack-
ets) experience large variations in end to end delay. Jitter
is a considerable issue in video streaming and can degrade
QoS [81], [82]. Jitter requirements vary as per appli-
cation ranging from 10ms–50ms e.g., VoD streaming
(≤ 50ms) [83], videoconferencing and interactive video
streaming (≤ 30ms) [84].

VOD ViewersLive ViewersVideo TranscoderRTMPLive BroadcasterCameraInternetHLS/HTMLRTMPStoreRetrieveHLS/HTMLRTMPRTMPVoD PathLive streaming pathOne-waystreamingLivestreamingof news, sportsUGS ande-sportsstreamingTwo-wayvideoconferencing45s +5s1s18s0sDelay (s)HLSMPEG-DASHMSSHLS TunesDASH-TunedRTMPSRTRTMP TunedWeb-RTCRTSP/RTPIII. MOBILE EDGE COMPUTING

In this section, we elaborate the concept of mobile edge
computing (MEC) and its key advantages to improve video
streaming. First, a brief overview of MEC architecture and its
beneﬁts to the network operators and end users are presented.
Then, we discuss some relevant works to understand the state-
of-the-art in MEC for novel emerging services (not speciﬁcally
video streaming). The state-of-the-art in MEC for novel video
streaming services is detailed in Section V.

A. Overview and Deﬁnitions

The term Mobile Edge Computing (MEC) was ﬁrst intro-
duced by the European Telecommunications Standards Insti-
tute (ETSI) in 2014 as, “it provides information technology
(IT) and cloud computing capabilities at
the edge of the
mobile network, within the Radio Access Network (RAN)
in close proximity to mobile subscribers” [85]. MEC aims
to deploy storage and computational services closer to the
end users. It also enables third party applications and services
at the edge of mobile networks. Recently, ETSI renamed its
associated Industry Speciﬁcation Group (ISG) as Multi-access
Edge Computing (MEC).

Other closely related concept to MEC include cloudlets
[86], [87] and fog computing [88]. However, typically cloudlet
is referred to as the architecture in which the computational
servers are located closed to the user premise (not at the RAN).
In fog computing, the computational capability is integrated
inside the IoT gateway which connects IoT devices. The
concept of edge, cloudlet and fog computing are overlapping
and these terms are frequently used interchangeably [21].
However, in the context of this paper, we will be referring
to the MEC architecture in which the edge servers are located
at the RAN, unless stated otherwise. Figure 4 illustrates the
architecture of mobile edge computing. MEC allows storage
and computational capabilities at the RAN level to provide
several enhanced services to the end users.

MEC offers several potential advantages in live video

streaming services.

• Efﬁciency: Using computational ofﬂoading, user devices
can ofﬂoad high computational tasks to edge servers for
remote processing.

• Ultra low latency: By storing content closer to the users,
delay associated with fetching content can be signiﬁcantly
reduced.

• Available computation: MEC can be used to augment
capabilities of other devices, thus reducing the cost of
transport.

Figure 5 illustrates the various beneﬁts of MEC for end
users as well as network operators in details. As depicted in the
ﬁgure, these beneﬁts are generally categorized into two cate-
gories: beneﬁts to network providers and beneﬁts to end users.
Network providers can improve services reliability. As edge
servers are distributed at RAN level, thus if one edge server
is down or congested, users connected to other edge servers
are not affected. This is in contrast to cloud computing which
has computing resources at one or fewer locations. Similarly,
denial of service (DOS) attacks on MEC servers can affect

7

users only the users at the effected servers, making edge-based
applications more robust to DOS attacks. MEC also helps to
alleviate network congestion at the backhaul links, by caching
and processing locally at the edge servers whereas, in MCC
the data has to be fetched from remote cloud servers. When
the data is stored locally, more economical content can be
provided to the users, providing more business opportunities
to network and content providers. As compared to cloud-based
centralized services, edge-based services are more reliable
and secure, hence scalability comes as an inherited beneﬁt
provided by MEC.

In addition to the aforementioned beneﬁts to network
providers, MEC also bring a range of beneﬁts to the end users.
Users can ofﬂoad their computation-intensive tasks to the
edge server. By ofﬂoading computation and fetching locally
cached content, the end-to-end latency experienced by end
users can be signiﬁcantly reduced. As mobile users are battery
powered devices, mobile users can also exploit edge-based
processing to save their energy consumption. When content is
cached locally at the RAN (i.e. available at lower propagation
distance or even at single-hop), video packets can be delivered
with minimum delay and relatively less variations in packet
delays, thus improving connectivity and reducing jitter. With
the power of edge computing, mobile users can be enabled to
run novel applications such as computationally intensive AI
applications.

Mobile Edge Computing offers two major services i.e.,
providing (i) storage facility and (ii) computation resources,
in the user proximity primarily to reduce latency with a range
of associated beneﬁts as illustrated in Figure 5. Using MEC,
users can access locally stored content with low latency, and
ofﬂoad their computational tasks to the edge server for fast
processing. In the following, the two concepts are explained
in details. Furthermore, a brief review of recent research works
in these areas is presented. (Note: The review of the state-of-
the-art of MEC in video streaming services is presented in
Section V).

B. Edge-based Caching

Traditional cloud-based architectures store millions of
videos in relatively large-sized servers in few geographical
locations. Edge caching is the process of fetching content
from these remote cloud servers and storing at
the local
edge servers. Edge caching reduces data trafﬁc transported
over backhaul links and reduces the content delivery time.
Edge caching techniques can be categorized in different ways
e.g. proactive versus reactive caching,
independent versus
collaborative caching.

Proactive caching refers to fetching content before arrival of
the request usually based on the video popularity or probability
of the request, whereas reactive caching is post-request content
fetching. Independent caching refers to the capacity of an
edge server to solely decide content fetching based on local
or central information, whereas in collaborative caching (also
referred to as coordinated caching), multiple edge servers can
provide their cached content to each other.

Any caching algorithm has two parts, i.e., content fetching
and cache replacement. Content fetching refers to the process

8

Figure 4. Mobile Edge Computing Architecture: Storage and computational servers deployed at the RAN that enables a range of services to the network
users.

of bringing content from the remote server (origin or cloud
storage) and storing it into the local/edge server. Cache re-
placement refers to the process of selecting content that need
to be removed from the local/edge server if there is limited
storage size available to store the newly fetched content.
Content caching in traditional networks such as content centric
networks have been extensively investigated in several studies
[89], [90]. In edge computing, the caching problem is typically
studied as a joint problem with the ofﬂoading decision [91],
[92]. A detailed review of caching schemes in video streaming
context is provided in Section IV.

C. Edge-based Computation

Computation at edge nodes can be implemented in several
ways depending on the design objective. Common design
objectives for implementing edge-based computation and op-
timization include energy consumption, computation latency
or bandwidth utilization. In this section, we present a brief
overview of different computation ofﬂoading models in mobile
edge computing and a summary of some representative works
of each category. As illustrated in Figure 6, the computation
models are categorized into three classes. A similar classiﬁca-
tion of computation ofﬂoading in MEC networks can be found
in [21].

1) Single User Systems: This is the simplest computation
ofﬂoading model that consists of a single edge server and
a single user. Although real networks always have multiple
users, the purpose of the model is to simplify the computation

ofﬂoading decision by considering the task of every single user
independently. The model decides whether a particular task of
a user should be computed locally at the device or ofﬂoaded to
the edge server. The model can be sub-classiﬁed as (i) binary
ofﬂoading and (ii) partial ofﬂoading.

If the whole task is computed locally or ofﬂoaded wholly
to the edge, this is referred as “binary ofﬂoading”. In contrast,
when a user device computes a part of the task locally whereas
ofﬂoad the remaining part to the edge, the model is referred
as partial ofﬂoading. Examples of binary ofﬂoading include
[93]–[95]. In [93], authors investigate the simple case of single
user to analyze computation ofﬂoading while minimizing the
energy consumption at the mobile device under a computa-
tional rate constraint. The model considers various parameters
including device’s and server computational power and the
communication bandwidth to take the ofﬂoading decision. A
task is ofﬂoaded to server if the energy consumption by the
user device for ofﬂoading the task is less than the energy
needed for local computation. The energy consumption is
studied as a function of distance between the device and
edge server. The results show improved energy performance at
shorter distance which increases when the distance increases.
The delay in this work is considered as a hard constraint. In
[94], authors propose an alternate method to solve the binary
ofﬂoading decision to run mobile application locally or at
cloud server. The objective is similar to [93] i.e., to minimize
the device’s energy consumption, while considering soft delay
deadlines. The energy consumption in this work is modeled

          CloudNLP APIAutoMLSpeech-to -TextTranslation APIAI PlatformVideo Intelligence     Vision APIRANEdge ServerData analyticVideo streaming AI serviceAR / VRTranslation serviceTweets analysisSpeech recognitionEnd Devicesrequesting multipleservices and runningintensive applications.Edge LayerProvide resources tohost several APIs thatmeet user's demands.Cloud LayerRich resources to runheavy computationaltasks and provide verylarge storage.9

Figure 5. Beneﬁts of Mobile Edge Computing for network operators (right side) and end users (left side).

as a function of CPU frequency:

ξ(f ) = kf 2

(1)

where, k is the switched capacitance (set to 10−11) depending
on the processor chip architecture. To minimize the energy
in local computing mode, the CPU frequency is adjusted,
whereas in remote computing mode, the data transmission rate
is adjusted. A limitation of this work is that in local mode,
the energy consumption is reduced by reducing CPU cycle
frequency which means the application will run slowly, which
make it unsuitable for heavily intensive applications with
delay constraint. In [95], binary task ofﬂoading is proposed
to maximize the revenue of the service provider. This paper
does not focus on the QoS requirement of the user/application.
Other works on binary ofﬂoading can be found in [96], [97].
Partial ofﬂoading schemes in MEC systems have been
investigated in [98]–[100]. In [98], authors proposed a partial
task ofﬂoading model in which a single task is divided into
sub-tasks and then each sub-tasks is either computed locally
or ofﬂoaded to the edge. The task ofﬂoading depends upon
the local computation resource available, the communication
channel capacity and the queue size in the edge server. The
ofﬂoading decision is optimized using a greedy algorithm
(called as Select Maximum Saved Energy First (SMSEF) al-
gorithm) to maximize the energy saving at the mobile devices.
However, this scheme does not minimize the task completion
delay, but only ensures that the delay deadline is met. In [99],
authors proposed a partial computation ofﬂoading scheme by
jointly optimizing the computational speed, transmit power
and the ofﬂoading ratio. The study aims at minimizing both
the energy consumption and the computation time. The energy
consumption is modeled similar to Eq. 1. In [100], authors
proposed a heuristic that makes an online ofﬂoading decision
tasks. The algorithm aims to minimize the
on sequential

completion time of the application. The task completion time
for local and remote execution is modeled as:

Execution time =

(cid:40) s
µm
s
µc

+ (cid:80) si
µc

+ di,j
R

Local
Remote

where, si is the task size (as number of instruction), µm and
µc are the CPU capacity of mobile device and the edge server
respectively, and R is the data rate of the wireless channel.
Other works on partial ofﬂoading can be found in [101]–[104].
Binary ofﬂoading is preferred for problems involving similar
tasks and in which user device has strong channel conditions to
the base station for fast computation. The beneﬁts are to reduce
the overall latency reduction of the system and energy saving
at the user device. On the other hand, partial ofﬂoading is a
preferred model for problems involving heterogeneous tasks,
thus ofﬂoading computational intensive portion of the task to
the edge whereas perform the remaining tasks locally. Simi-
larly users can decide to ofﬂoad tasks of small transmission
payload to the edge to reduce data loss.

The aforementioned two single user MEC models are used
when the task arrival process is deterministic. However, in
some cases, the task arrival is random i.e., tasks arrive at
the processor queue at a random rate. In such a case, the
ofﬂoading decision is also dynamic and is referred to as
stochastic ofﬂoading. Stochastic ofﬂoading becomes a neces-
sary requirement in some problems e.g. if the random task
arrival rate is leading to buffer overﬂow, dynamic ofﬂoading
can help to avoid this by randomly ofﬂoading tasks to the
edge when the task arrival rate increases. Another use case
is to exploit the randomness of the wireless channel to design
channel-aware ofﬂoading schemes in which tasks are ofﬂoaded
only when the channel supports the required communication

4/16/2021mec_survey.drawio1/1ReliabilitySecurityBandwidthCostSavingScalabilityO oadingLatencyEnergyConnectivityUsecasesUsers can o oad high computational tasks to the edgeserver, saving local resources for other applications.By reducing the distance between edge server and mobiledevices, the transmission latency is reduces.High computational tasks can be o oaded to edgeserver to reduce energy consumption at the userdevices.Edge computing can enable improved connectivity byreducing jitters and network disruptions.Edge computing enables users to run novel applicationsthat requires high computational resources that the usercannot support.Edge servers being local to the user, the chances ofoutage reduces. Even if an edge server is down, therest of the network is not affected.By distributing the data and computation resourcesacross the network, the chances that wholenetwork is affected by DDoS attack reduces.By caching data and performing computations atthe local edge, network bandwidth use issigni cantly reduced.By retaining data within the edge, the cost oftransporting the data (i.e. bandwidth cost) can bereduced.MEC can help the network to scale by providingdistributed computing and intelligence centers aswell as limiting the security risks to a small portion.   MEC  BenefitsBene ts for Network OperatorsBene ts for End Usersdelay. Example works on stochastic ofﬂoading can be found
in [105], [106]. As compared to deterministic task arrival
rates, stochastic tasks arrival requires more robust techniques
to optimize the ofﬂoading decisions. Authors in [105] use
Q-learning to perform the ofﬂoading such that the tasks are
completed within the delay deadlines, thus achieving the end-
to-end reliability. Similarly, authors in [106] studied the re-
source allocation problem in dynamic scenarios. The objective
is to reduce the unnecessary resource allocation, maximize the
QoE and minimize the network cost to the content provider
in a multi-edge servers environment. The authors used several
machine learning (ML) algorithms (Long Short Term Memory
(LSTM), Gated Recurrent Unit (GRU), Convolutional Neural
Network (CNN), MultiLayer Perceptron (MLP) and XGboost)
on synthetic datasets to evaluate the effectiveness of each
model. The use of ML based techniques achieves better
performance due to their capability to accurately estimate the
stochastic parameters in real-world applications.

2) Multi User Systems: Multi users system refers to the
computation model in which multiple user devices share a
single edge server. In such systems, computation ofﬂoading
can be implemented in various ways. For instance, the tasks
ofﬂoaded by multiple users can have different priorities, hence
the server must schedule the tasks computation according
to the priorities of the tasks. Similarly, different users have
usually different channel conditions and consequently support
different data rates, hence a “joint resource allocation” model
which jointly optimizes the ofﬂoading and radio resources
is desired to improve system-wide performance. Examples
of joint optimization of radio and ofﬂoading in multi users
MEC systems are studied in [107], [108]. In such kind of
problem, one of the parameter is taken as a hard constraint,
while optimizing over the others. For instance, in [107] the
mobile energy consumption is minimized under average la-
tency constraint, whereas in [108] the weighted-sum of latency
is minimized while considering/satisfying the mobile devices’
energy consumption requirements. The joint optimization over
two parameters does not preclude to consider other parameters
such as computational and storage resources.

As the edge server also provides caching facility to store
content, the joint optimization of caching and processing can
provide several beneﬁts such as service provider revenue or
content retrieval latency and storage utilization. Joint caching
and processing systems are studied in [91], [92]. In joint
caching and processing, the objective is to ﬁnd the optimal
location (i.e., edge/cloud servers) for storing and processing
the content. For instance in [91], authors consider jointly the
storage and processing resources to minimize the backhaul
network cost of serving all requests. This is done by jointly
determining the cache placement and processing scheduling
using Integer Linear Programming (ILP).

In multi user systems, when users ofﬂoad tasks to the
edge server, the tasks may have different priorities. To meet
the QoS of such applications, the edge server may schedule
these tasks based on the latency requirements. Hence, latency
sensitive tasks are computed ﬁrst, followed by latency-tolerant
tasks. Examples of server scheduling include [109]–[111].
Authors in [109] proposed task scheduling based on the energy

10

saving opportunity. Thus, a device ofﬂoads the task to the
server when the ofﬂoading can achieve more energy saving
the ofﬂoading method in
than local computing. However,
this work is binary and task splitting was not investigated.
In [110], authors propose the task scheduling under strict
delay requirement. The work proposes to use dynamic voltage
and frequency scaling (DVFS) technique for local computing
whereas adjusting transmission power for remote computing
(edge/cloud) to reduce energy consumption in both modes.
In [111], authors further investigated the scheduling problem
by jointly considering server scheduling and video bitrate
selection to improve the overall QoE and fairness in resources
allocation.

Unlike the cloud computing paradigm, in edge computing,
the edge servers have limited computation power. Furthermore,
serving heterogeneous users requests becomes more chal-
lenging when the server has limited resources. To overcome
the resource limitations, recently, MEC operations have been
investigated with device-to-device cooperation. D2D-assisted
MEC systems have been recently proposed in [112]–[115]. In
D2D-assisted MEC systems improve system’s overall capacity
in two ways. First, users can exploit D2D cooperation to
ofﬂoad tasks to its neighboring devices, instead of ofﬂoading to
the resource limited server. Secondly, MEC servers can itself
ofﬂoad computation tasks to user devices.

3) Multi Server Systems: Multi Server systems refer to
the MEC systems consisting of multiple and typically het-
erogeneous MEC servers. Multi server systems offer several
challenges. The ﬁrst challenge in multi-server system is the
selection of server for ofﬂoading computation. Different se-
lection criteria can be considered e.g. selecting closest server,
selecting least loaded server, selecting between cloud or edge
server. For example, in [116], authors proposed a scheme to se-
lect the closest server to minimize the resource allocation cost
and maximize QoE. The work used the FaceBook 2018 live
video dataset to predict the viewing patterns and automatically
select the edge server to minimize the startup delay. The work
employs ML techniques such as Multilayer-perceptron (MLP),
Decision trees (DT) and Random Forest (RF). Similarly, in
[117], authors propose a load balancing and task allocation
scheme using Particle Swarm Optimization (PSO). The users
select the edge server based on multiple criteria i.e., current
server load and distance to the edge server.

Multi-server systems can beneﬁt

from the cooperation
among the servers. Servers can collaborate with each other in
several ways. For example, servers in a small geographical area
connected by single hop cooperate by ofﬂoading computation
to each other. Similarly, edge servers can collaborate with
to compute delay-sensitive tasks locally (at
cloud servers,
the edge server), whereas ofﬂoad delay-tolerant tasks to the
cloud servers. Examples of edge-cloud cooperation are [108],
[118], [119]. In [108], cloud-edge cooperation is used to split
tasks among edge and cloud to minimize the latency. On the
other hand, [118] proposes to schedule tasks such that delay-
sensitive tasks are processed at the nearest resource-constraint
edge server whereas delay-tolerant tasks are ofﬂoaded to the
remote resource abundant cloud servers. Similarly, in [119],
authors propose the cooperation among multiple edge servers

to share contents via backhaul links when requested.

In multi server systems, a mobile user may move away
from one server and get closer to another MEC server. Con-
sequently, the network controller can optimize computation in
two ways: (i) by ofﬂoading computation to the new server
or (ii) performing computation on the origin server and then
forwarding the computation results to the new server. Example
works on computation migration are available in [120]–[122].
In [120], authors used Markov Decision Problem (MDP) to
formulate the computation migration in multi-server environ-
ment. The migration decision is taken considering the distance
between the users to each server and using two thresholds. The
work is extended in [121] by jointly considering the com-
putation scheduling and computation migration to minimize
the average transmission energy and reconﬁguration cost. In
[122], authors proposed to compute the tasks locally or migrate
computation to remote cloud server such that the total energy
consumption and latency is minimized.

Table IV provides a brief summary of representative works
on resource allocation schemes in edge computing. In Sec-
tion V, we provided a details review of the state-of-the-art
on resource management in video streaming applications. A
more exhaustive list of research contributions on resources
management in MEC in generic applications is provided in
[15] and [123].

D. Lessons learned and challenges

Edge computing provides storage and computation re-
sources closer to the mobile devices i.e., at the base station.
In the caching process, content is pre-fetched and stored at
the edge server. As edge storage capacity is limited, older
content need to be replaced when it is reaching the available
storage capacity. Content caching can be implemented in non-
cooperative method such as in [124], [125] or cooperative
method [126], [127]. Cooperative caching methods are more
popular due to their system-wide performance gains. The
computation power of edge server is also limited and hence
efﬁcient resource allocation strategies are required. In the
simplest case (single user system), a mobile device connected
to an edge server can ofﬂoad computationally intensive tasks to
the edge whereas perform simpler tasks locally. Alternatively,
mobile devices can also ofﬂoad sub-tasks to the edge (i.e.,
partial ofﬂoading). In the case of multi user systems, edge
server can schedule ofﬂoaded tasks according to the latency
requirements of the user’s applications.

Due to the high number of decision factors and the sys-
tem uncertainties, the resource allocation problem in mobile
edge networks becomes highly complex. More speciﬁcally,
to optimize the MEC resource utilization, multiple decisions
should be considered, including the caching, computing and
networking variables. The main metric related to the caching
is the hit ratio, whereas the metrics related to the computing
are the latency, the throughput, and the energy consumption.
On the other hand, the transmission latency, the data rate and
the QoE, should be taken into account while scheduling trans-
mission decisions. Resource allocation problems are typically
addressed by formulating an optimization problem with one or

11

multiple objective functions using different system constraints.
The traditional techniques to solve such problems are included
mainly under the umbrella of stochastic and convex optimiza-
tions and game theory. However, these approaches are very
complex and time consuming and are not adequate for online
implementation. Recently, reinforcement learning gained a lot
of attention owing to its ability to solve resource allocation
systems, particularly, those with dynamic, large and complex
problem spaces. RL-based approaches are still in their infancy
and further efforts need to be conducted to examine their
performance on MEC networks.

Further improvements can be achieved by considering the
users radio channel in the joint optimization scheme. The joint
optimization of edge resources can improve the resource uti-
lization to a certain level, however recently, D2D collaboration
has been proposed in edge computing system, which enabled
mobile devices to ofﬂoad computations to other resource-rich
helper devices. Such types of D2D-enabled MEC systems can
boost the performance of the system beyond the edge capacity
limits.

IV. MOBILE EDGE COMPUTING - APPLICATIONS IN VIDEO
STREAMING
In the previous section, we discussed the detail overview
of mobile edge computing, its architecture and state-of-the-art
including caching and computation. However, it is important
to understand how MEC can help to improve the users’
video streaming experience and/or implement novel video
streaming applications and services. The primary beneﬁt of
mobile edge computing in the video streaming is reducing
the end to end latency to enhance user quality of experience
by eliminating network lags, frames dropping and buffering.
However, in addition to latency reduction, MEC alleviate the
network congestion by running applications and performing
the processing tasks closer to the end users. As the MEC
thus
servers are deployed at
it allows ﬂexible and rapid deployment of new applications
and services for cellular customers. Similarly, as network
service providers can authorize trusted third parties, such as
application developers and content providers to deploy MEC-
based services.

the base station (i.e. RAN),

This section outlines novel video streaming services in
which MEC can bring potential advantages. It
is evident
from the previous discussion in Section III that MEC helps
improve video streaming via optimal caching of contents
at the network edge and provide computing resources for
faster processing. However, how these inherited advantages
of MEC beneﬁt video streaming? What are the scenarios
and novel services that can be realised using MEC? This
section provides an overview of the attractive applications of
MEC-based video streaming services. Figure 7 illustrates the
most attractive applications of MEC assisted video streaming,
whereas speciﬁc examples of each application category are
listed in Table V.

A. Content Searching

The powerful computing capabilities of the edge server can
bring a more personalized search features which runs faster

12

Figure 6. Computational Ofﬂoading in Mobile Edge Computing.

C. Targeted Advertisement

When powerful computations are applied to user’s prefer-
ence data, the usually unwanted advertisements that interrupt
streaming videos can be tailored to the user’s interest. Adver-
tisement agencies can beneﬁt from the user search preferences,
search history, previous purchase history, locations visited with
timing information etc., to send highly targeted advertisements
[129]. As an example, a user at a shopping mall would be
probably buying some goods whereas another user at a hospital
would be interested in a healthcare product. MEC thus allows
location-based service recommendations tightly coupled with a
speciﬁc place. Particularly, information of radio node to which
user terminals is connected is available at MEC server that
can be used to get location information of users especially
when users are connected to an indoor small cell. Then an
inference engine deployed at the MEC server can determine
proper services and sends the related advertisements for the
user at the moment.

D. Interactive Video Experience

Users would always enjoy interacting with live videos e.g.
displaying the statistics of a baseball game being streamed,
pulling the ﬁlmography of an actor as he appears in a scene.
Such user interaction always requires a level of immediacy
which can be made possible using the high computation power
of the edge servers available with minimum latency [130].

E. Video Analytics

Surveillance and video analytics to detect accidents are
included under the umbrella of live video streaming. More
speciﬁcally, in surveillance applications, the aim is to monitor
a speciﬁc area and identify potential threats within the target
region. Some of the area are very critical and need 24/7
surveillance such as military borders, oil/gas off-shores, and
forests exposed to potential ﬁres. The video frames (or video
streaming) are sent instantaneously to remote servers for real-
time object/accident detection using AI for example. The

Figure 7. MEC Use cases in Video Streaming Applications.

than traditional approaches using cloud computing. Using
MEC, locally available information at the edge servers about
user preferences, location, local events and incidents can help
improve user search experience [17], [128]. For instance, users
in a speciﬁc area when search for a local event or incidents, the
content searching can be optimized based on the other local
users’ search history and selections data saved at the local
MEC server. This kind of localised content searching is only
possible using MEC servers deployed in users’ proximity.

B. Content Suggestion

MEC offers the computational capabilities to process the
data related to user preferences and activities. When such
processing is done faster, the user can be served with appealing
content in real time that ultimately enhancing user streaming
experience [128]. The kind of location speciﬁc content sug-
gestions is based on the search history of other local users,
which is saved in the edge caches.

ComputationO oadingSingle User SystemMulti User SystemMulti Server SystemBinary O oadingStochastic O oadingPartial O oadingJoin Resource AllocationServer SchedulingServer SelectionServer CooperationComputation MigrationSingle-hop clustersCloud-Edge CooperationJoint Radio and ComputationJoint Radio and CachingD2D CooperationJoint Caching and ProcessingContentSearchingVirtual	&AugmentedRealityMobile	EdgeComputingContentSuggestionTargetedAdvertisementInteractiveVideosVideo	Analytics13

Table IV
COMPUTATIONAL OFFLOADING SCHEMES IN MOBILE EDGE COMPUTING.

Category

Ref

Description

Evaluation Metrics

Method/Algorithm

Binary
Ofﬂoading

Partial
Ofﬂoading

Stochastic
Ofﬂoading

Server Schedul-
ing

Joint Radio and
Processing

Joint
and Processing

Caching

Server Selection

Server Coopera-
tion

Computation Mi-
gration

[93]

[94]

[95]

[98]

[99]

[100]

[105]

[106]

[111]

[109]

[110]

[108]

[107]

[91]

[92]

[117]

[116]

[119]

[108]

[118]

[120]

[121]

[122]

Transmission energy minimization under computation deadline.

Delay, Energy

Convex programming

Minimize energy consumption with a soft real-time requirement.

Delay, Energy

Convex Programming

A binary ofﬂoading model to maximize proﬁt to video service provider.

N/A

Schedule ofﬂoading tasks from multiple mobile nodes to a single MEC
server in order to maximize energy savings of all mobile nodes.

Energy

MAB

SMSEF

Task-input data is divided for local and remote execution.

Energy, Latency

uni-variate search

Load balancing between mobile and edge servers to minimize latency.

Latency

Heuristic

Reinforcement learning to proactive allocation resources to multiple.

E2E Reliability

Q-learning

Transcoding resource allocation using past video requests and then
using time series forecasting to predict the resources needed for future
requests using a heuristic.
A scheduling algorithm that solves client
balancing) and per client bit rate selection problems.

to edge mapping (load

QoE, Network cost

LSTM, GRU, CNN,
MLP, XGboost

Throughput,
delay, Fairness

Buffer

Heuristic

Scheduling uplink and downlink transmissions using queuing theory.

Energy

Nested interval algo-
rithm

Tasks Ofﬂoading selection using clock frequency and transmission
power allocation.
Jointly optimize communication and computational resources with
tasks splitting between edge and cloud.

Energy, Delay

DVFS

Latency

Convex optimization

Joint allocation of computation and radio resources.

Power consumption

Convex optimization

Jointly optimize caching and transcoding resources to minimize the
backhaul network cost.

Collaborative ofﬂoading and caching scheme using Lyapunov opti-
mization to minimize the overall latency of all mobile devices.

Balance work load among edge nodes by considering edge computing
capability, existing work load and distance among edge server and
user.
Proactively allocate resources by predicting the number of viewers in
a cloud site and then serving viewers by their closest server.
edge servers in a sing-hop clusters cooperate to cache and transcode
contents.
Jointly optimize communication and computational resources with
tasks splitting between edge and cloud.

Network cost

ILP

Throughput, Playout
delay, Buffer length,
Rebuffering duration

Theoretical architec-
ture

Service delay

PSO

Viewers’ QoE, Net-
work cost
Network cost, delay,
cache hit ratio

MLP, DT, RF

ILP

Delay

Convex optimization

Edge/cloud selection to meet deadline requirements.

Task completion

Heuristic

Computation migration based on distance threshold between user and
two servers using MDP.
Jointly optimize computation scheduling and service migration to
minimize energy transmission and reconﬁguration cost.
Compute locally or ofﬂoad to remote server such that total energy
consumption and latency is minimized.

MDP

MDP

Delay

Application
length

queue

Energy, Delay

MIP

traditional wisdom resorts to cloud or servers to compute these
heavy tasks. However, video streaming destined for detection
and surveillance do not tolerate high latency, such as forest ﬁre
detection that needs immediate intervention. Furthermore, used
cameras are sending high-resolution video frames to cloud
servers and knowing that incidents are rarely occurring, the
large data volume transmitted by source units has become
problematic, particularly for systems that do not have stable
bandwidth availability. Because of this tremendous amount of
data, video analytics should be done at the edge of the network.

The huge amount of videos generated by mobile users,
social media, IoT devices, scientiﬁc apparatus, satellites, and
video surveillance cameras is being processed by modern
computer vision techniques powered with AI. The processing
can be done on-camera, which requires expensive AI-powered

chips. Alternatively, to process these videos on cloud, longer
delays occur as previously described (approximately 150 to
200 milliseconds). Edge computing offers a good trade-off
by eliminating the need for on-camera processing to reduce
cost and processing videos locally reduces delay (around 10
milliseconds). Reduced delay allows for quick detection and
faster response which is required in many applications.

Video streaming analytic has a broad range of applications
such as head counting in live streaming videos, suspicious
activity detection, correlations in different video streams, com-
bining real time information with historical context and search
and rescue in live videos captured using drones. All these
use cases require low latency (sometimes ultra low latency)
analysis of streaming videos, thus motivates for using edge
computing. Representative works in video analytics can be

Table V
MEC APPLICATIONS IN VIDEO STREAMING.

Content Searching

Faster search

Personalised
search

Faster content search with user’s search
history cached and updated over time.

Personalized search based on user’s location
(e.g. supermarket, ofﬁce, stadium)

Use case 1

Use case 2

Use case 3

Use case 1

Use case 2

Content Suggestions

Personalized content suggestion based on
user preferences.
Improved content suggestions over
when user preferences changes.
Content suggestions based on local/regional
events.

time

Targeted Advertisements

Highly targeted advertisements based on
user’s interests.
Targeted advertisements based on user’s
previously visited shopping locations with
timing information.

Interactive Videos

Live Sports

Display Live statistics of a match

Filmography

Retail/E-
commerce

Pulling ﬁlmography of an actor appearing
in a scene

Allowing users to click on objects inside
video to see details or buy.

Education/Trainings Allow users to ask questions, submit an-

swers, ﬁll surveys

Video Analytics

Surveillance

Content detection

QoE
Measurement

Realtime
Assistance

object detection, motion tracking,
facial
recognition, gesture recognition , activity
recognition, head counting
detecting banned videos, parental control,
illegal videos

KPI calculation for encrypted streaming
videos

Detecting obstacles using videos captured
by stereoscopic camera

VR and AR

Retail

Gaming

Try items using AR/VR reality without
physically trying things
Pok´emon GO is a popular example.

Education/Trainings Wearable cognitive assistance

Tourism

Healthcare

Try items using AR/VR reality without
physical try things
AR enabled minimal invasive surgeries

Industry/safety

Building Digital maps and digital twin

14

found in [131]–[137].

F. Virtual Reality (VR) and Augmented Reality (AR)

VR and AR are two emerging technologies that connect
the physical and digital worlds. While there is a distinction
between both1, both uses streaming videos to enrich user
experience. There are a range of attractive use cases of both
technologies such as games, entertainment, training, education
and scientiﬁc areas [138]. A list of games using VR/AR
technologies can be found in [139].

Recently many commercialized smart applications [140] are
proposing to create a virtual avatar of the user, that allows to
try the clothes virtually. More speciﬁcally, the user is able
see his/her reﬂection on the screen as if he/she is looking
to a mirror, where the virtual clothes are blended with the
scene. This process is called blended-reality. The application
users can see themselves moving, turning around, and walking
while being dressed with the chosen items. The users can also
see, in 360°, how the item looks like on them and if the size
is appropriate. In the same context, Amazon has published a
patent [141] of its partially reﬂective intelligent mirror, where
virtual clothes and real scenes are transmitted through the
mirror to generate a blended-reality client able to see him-
self/herself wearing new items. This type of application, called
interactive application, uses virtual reality streaming that is
extremely intolerant to delay variance or image freezing, as the
user wants to see his/her avatar without any motion sickness
affecting the quality of experience. For this reasons, the cloud
wisdom to blend the streamed video is no longer sustainable of
such real-time applications and sending data to remote severs
may not satisfy the latency requirements. MEC can be used
to improve VR/AR applications for several beneﬁts such as
latency reduction [142], [143], efﬁcient resource utilization
using device-MEC collaboration [142], improved throughput
[142], and reducing the backhaul trafﬁc load [144].

G. Lessons learned and challenges

Mobile edge computing can help improve video streaming
services by providing proximal caching and computational
resources for transcoding the videos. In addition, faster edge-
based processing of videos, a number of beneﬁts can be
achieved such as faster content searching and personalized
suggestions, targeted advertisements, real-time user interaction
with videos, video analytics for surveillance, object detection
and real-time assistance, and virtual reality applications such
as gaming, retail, healthcare and industrial safety. It is widely
believed that 5G networks fall short of meeting the un-
precedented requirements of data-intensive and delay-sensitive
applications such as autonomous vehicles, remote surgeries
etc., thus leaving room for acceptance of edge-based solutions.
The future 6G networks further mandates the use of edge
intelligence in a variety of network functions and services.

1AR overlay digital elements such as visual content and information on
your real world view, whereas VR implies a complete immersion experience,
allowing users to experience things and places that actually do not exist there
in the user’s environment. Mixed Reality (MR) refers to combining VR and
AR technologies for a richer user experience.

However, the success of MEC-based solution heavily rely upon
the edge infrastructure deployment. MEC deployment will
incrementally progress in a way to support as new network
services are introduced. As will be explored further in the
subsequent section, MEC deployment considerations include
revenue as an important factor in addition to the QoS metrics
(e.g., delay, storage, throughput, energy etc.).

V. STATE-OF-THE-ART IN MEC-BASED VIDEO
STREAMING

In the previous section, we discussed MEC-assisted video
streaming applications and services. However, to implement
these services in real-world applications, providing caching
and computing resources along the network edge is not sufﬁ-
cient. Indeed, it involves various challenges such as efﬁcient
caching strategies, optimal resource allocation, cooperation
among network entities, and tasks/requests scheduling, etc,
to realise the full range of these applications. There have
been a huge amount of research efforts contributed to cope
with these challenges. This section focuses on covering these
research works to solve the aforementioned problems. We have
dedicated separate sections for the works involving device-
to-device (D2D) cooperation (in Section VI) and machine
learning (in Section VII).

A. Content Caching at Edge

As discussed earlier, MEC offers proximal storage at the
edge server that signiﬁcantly reduces the delay to retrieve
content and alleviate the congestion and bandwidth usage for
network operators, resulting in overall improved performance
and QoS in several services [131]. However an edge server
has limited storage as compared to cloud servers to store
large-sized video content, hence caching schemes need to
be optimized for efﬁcient allocation of storage resources to
end users. In the following, we present research contributions
aiming at edge caching optimization.

Figure 8. Caching Techniques in Video Streaming.

One of the key parameters that

inﬂuences the content
retrieval latency and the trafﬁc transmitted over the network
is the distance between the end-user and the remote servers.
In this context, caching the video content in MEC servers is
a promising solution that enhances the bandwidth efﬁciency
and reduces the latency to serve viewers. However, the edge

15

servers are characterized by their limited capacities in terms of
storage. On the other hand, we are witnessing an explosion of
newly published video streaming. For example, in 2020, users
have been uploading to Youtube around 500 hours of videos
every minute [145]. Therefore, edge caching should be per-
formed wisely. Several approaches responsible for scheduling
the content caching and removal have been proposed in the
literature. These approaches can be classiﬁed into two groups,
namely traditional schemes and popularity/human behavior-
aware strategies.

1) Traditional Caching Schemes: The traditional schemes
assume that each video has a popularity assessed by the
number of views and this popularity remains stable, even after
passing the trend. Several policies are proposed in this context:

• Most Popular Videos (MPV): This technique was origi-
nally used by Hulu [146] for content caching. MPV is
a proactive caching policy that caches the content based
on the nation-wide content popularity. The shortcoming
of MPV is that the cache is not updated based on the
user requests or viewing patterns. MPV is suitable for
large caches such as Internet CDN to achieve a high hit
ratio but performs poorly on edge caching due to the fact
that the local request by users may be different than the
nation-wide distribution.

• Least Recently Used (LRU): This conventional caching
scheme can be considered as a baseline that has been
used for a long time in networking systems. LRU stores
the time of the last access of each content and when the
memory capacity of the server is insufﬁcient, it replaces
the most idle video that was not requested for a long
time, by a new content. The problem of LRU is that it
gives priority to some unpopular content just because they
were recently requested [147]. LRU has multiple variants
including the three Segmented Least Recently (S3-LRU),
which divides the cache into three segments where the
most requested videos are stored in the highest segments
and least requested are saved in the last segment. If a new
content is requested, it is placed in the head of the list
while removing the tail of the last segment. If it already
exists in the cache, it is considered as the least recently
requested and all the others are shifted downwards [148].
• Least Frequently Used (LFU): This caching strategy
relies on the number of requests per video to judge
the popularity of content. In this way, the content with
the lowest number of requests is evicted to create a
room for the new published video. However, LFU suffers
from gradual performance degradation as videos with
historical high number of requests can remain a long
time in the cache even if they are no longer accessed
[149]. This problem is solved by deﬁning a time window
for observing the frequency of requests as done in the
Jumping Window Least Frequently Used (JW-LFU) and
the Sliding Window Least Frequently Used (SW-LFU).
• First In First Out (FIFO): This scheme caches the videos
according to the order of their ﬁrst request. It means when
a new video is requested for the ﬁrst time, it occupies the

Caching  in  Video Streaming   Traditional    based on past popularity                and requests.   Human Behavior-aware    based on predicted popularity        and requests.   Cooperative    based on cooperation among         edge/edge and/or edge/cloud head of the list. The FIFO was later combined with LFU
(FIFO-LFU) to take into consideration the popularity of
the content [150].

• Least Recently Frequency Used (LRFU): This caching
approach takes into consideration both frequency of re-
quests and recentness, as adopted in [151].

The aforementioned traditional caching schemes are widely
used in edge computing owing to their low complexity and
simplicity of deployment. However, these approaches ignored
the dynamic of viewers, and their preferences and behaviors.
Therefore, due to the limitation of edge bandwidth and mem-
ory, better caching schemes that take into consideration the
viewership and their capacities and make videos available at
peak hours beforehand using prediction techniques should be
designed.

Figure 9. Popularity prediction features.

2) Human Behavior-Aware Strategies: This type of strate-
gies is based on popularity prediction and the learning of the
viewers’ preferences through either AI or mathematical stud-
ies. However, prediction techniques can add latency overheads
and computational costs to ensure satisfactory performance
and take accurate caching decisions. Therefore, the designed
algorithm should be quick, provide accurate decisions, and
scalable to handle high number of requests and large library
of content. Finally, the prediction should be based on the
preferences and behaviors of in-proximity viewers. Specif-
ically,
the content’
demands, the users’ interests, and the geographical location
of viewers should be the input of the prediction model. These
data is processed to get spatial, temporal and social insights
and identify the viewing pattern. In this way, the designed
caching strategy will be able to predict the videos that will
receive higher attention locally or globally, and accordingly
plan for content storage, replication, eviction and select the
most adequate MEC server for content storage. The input
features can be classiﬁed into four groups: static, temporal,
cross-domain and social features as we can see in Figure 9.

the contextual and social

information,

• Static features: refer to the parameters that are prepared
before publishing the content. These features include the
video characteristics that give hints about the quality of
the video such as the duration, publication date, video and
audio standard, music style, etc. The visual features such

16

as the images at each frame and the text features such as
the category, the title, the keywords, and the description
can contribute to increase the popularity of the video and
enhance its visibility in the search engines.

• Temporal features: refer to the data that change over
time such as the channel features including the number
of rates, views, subscribers, comments and shares for
different published videos and the video features such as
the video age, the watch time, and the subscribers gained
from this content. Additionally, the previous requests of
viewers can give insights about their future requests for
other content.

• Cross-domain features: refer to the external sources
such as the reputation of the content creator and the
propagation of the content via other social medias or
video platforms.

• Social features: includes the relationship between users,
their followers and followees, and their social interaction
which can help to share and forward the content to more
viewers.

A wise selection of the features fed as an input to the
prediction model is very important to improve the accuracy,
reduce the complexity and computation time of the decisions,
and remove the redundancy of attributes. Next, we will discuss
the popularity-aware MEC caching approaches that rely on the
described features. These approaches can be classiﬁed into
two groups: a single domain and cross-domain strategies. The
single domain covers the approaches trusting only the features
related to the video and its broadcasting platform such as:

• Popularity evolution of a content: The high correlation
between the past popularity of a videos (e.g., number
of views, shares, and requests) can indicate its trend for
the future. In [125], two caching policies i.e., P-UPP and
R-UPP are proposed, which are based on the popularity
of content. In P-UPP (Proactive User Preference Proﬁle)
scheme, videos that are Most Likely to be Requested
(MLR) by active users of the cell are pre-fetched. This
is different from the traditional scheme such as MPV,
which accounts for the nation-wide popularity of the
video content. The local popularity of a video vi in a
pool of videos V is calculated using the equation:

p(vi,j) =

pvcj (vi)
(cid:80)|V |
i=1 (vi)

(2)

where the denominator of the equation represents the
probabilities of all videos in the category vcj. A drawback
of this scheme is that if the cell is highly dynamic, the
users may leave or join frequently which will change
the MLR set of videos, thus increasing the computation.
To reduce the computation complexity caused by cell
dynamics, authors proposed to use a threshold value for
cache hit ratio to decide before pre-fetching/replacing
content. In R-UPP (Reactive User Preference Proﬁle),
a video is fetched upon user request, however if the
cache is full, the video that is “Least Likely Requested”
(LLR) is replaced. LLR is calculated using the probability
of requesting a video. In real-world, the demand of a

Static featuresTemporal featureCross-domainSocial featuresFeatures prepared beforethe upload of a video,e.g., title, keywords, anddescription.Features changing overtime, e.g., number ofviews.Features related to theattractiveness in othersources.Features related to thesocial connections andspread of a video.video content is always associated with the user behavior
i.e., it is the user preference that makes a video more
popular. Hence, caching schemes based on the user con-
text/behavior is proposed in [152]. The authors proposed
a smart caching scheme using knapsack problem to ﬁnd
context-aware content popularity to maximise video hit
rate within a limited time. As the user preference may
change based on time and/or location, in [152], the spatio-
temporal context is constructed from the user’s access
time and spatial characteristics to mimic video popularity.
In [153], a collaborative online caching algorithm is
proposed that minimizes the sum of User Attrition (UA)
cost and caching cost for each content. The problem is
formulated as Integer Linear Program (ILP). In the online
settings, the user requests are revealed one by one to the
edge server and the server should take decision before
next request to provide the content from local cache (if
available), or fetch from neighboring edge servers or from
the origin server. Authors in [154] proposed Proactive
Cache Policy (PcP) i.e., a popularity-aware proactive
video chunks caching based on chunk popularity instead
of the whole video popularity. This is particularly useful
as normally the users would not watch the whole video
but rather watches the ﬁrst few chunks. Hence, this work
proposes to cache the popular chunks rather than the
entire video of long duration.

indication about

• Metadata of the content: Some videos are newly pub-
the past. Hence,
lished and has not
the content data such as subscribers, title, and frames
can be considered to predict the popularity. Authors in
[155] proposed an online caching strategy that uses the
mixed-integer linear program (MILP) to load the MEC
cache with most popular videos during the valley hours,
based on the content metadata such as keywords and
description. Authors in [156] designed a deep learning
approach that handles the popularity of new published
videos. The input data of the model are extracted from
the video raw data. Then, the popularity is deﬁned by
studying the similarity of the extracted features to the
old videos.

• Social dynamics: the interaction between users (e.g.,
friendship, likes, and shares) are very insightful for the
watching trend of videos within a small edge area. The
authors in [157] used the susceptible-infected-recovery
(SIR) model to study the social propagation of videos.
More speciﬁcally, the SIR model deﬁnes three states:
susceptible, informed and refractory. In the ﬁrst state, the
viewers are notiﬁed of the new published content. During
the informed state, the users discover the video and decide
whether to share it to the followers or not. If the content
is shared, more viewers can see it, if not the initial user is
considered in refractory state. The popularity of a video
can be examined through the probability to spread the
content, which is also called social connections.

The cross-domain prediction models use features from
external sources (e.g., attractiveness of the video on other
sources) to increase the accuracy of the decision. In [158],

17

authors improve the popularity-aware video caching by jointly
considering the popularity and attractiveness of the video
stream. The authors argue that despite the high popularity of
the videos, user may decide to ﬁnish the videos after a short
duration of viewing (i.e 15 seconds). This duration is known
as retention rate. Thus, simple heuristic algorithm is developed
to cache videos with high popularity as well as low retention
rates.

3) Cooperative Content Caching: In cooperative caching,
multiple MEC servers collaborate with each other to serve the
network-wide users’ requests. Thus, a single MEC does not
need to cache all videos. In fact, different MECs serve the
requested videos to any user in the network to minimize the
CDN cost and access delay, while maximizing the cache hit ra-
tio. Several works propose cooperative caching in multi-server
MEC environment. For instance, in [119] authors proposed to
fetch content from neighboring servers using high rate X2
interfaces (instead of typically used S1 interface), when the
requested bitrate of the video is not locally available. The
scheme aims at improve bandwidth utilization of backhaul
links. Despite the fact that cooperative caching can help to
efﬁciently utilize the network resources, storing multiple bit
rates of the same video in overlapping regions is still a chal-
lenge. Authors in [159] explain the trade-off between caching
for high bitrate videos and caching for diversity videos. [159]
propose an optimum caching algorithm to store multi-bitrates
of videos at the edge servers aiming at maximising the user
perceived QoE. The authors adopt the proactive caching policy
to update edge caches when the system is idle (i.e., least busy).
Video content has huge storage size that makes caching a large
number of video ﬁles at the edge server challenging; hence,
efﬁcient cache replacement strategies are required. To cope
with this problem, authors in [160] proposed to improve the
performance of mobile video delivery through caching layered
videos i.e., instead of caching the entire videos at the edge
server, only layers/descriptions of videos can be stored at the
edge. Thus when a user request is generated, the edge server
can send the cached layer to the users, while in the meanwhile
the rest of the video is fetched form the remote/origin server.
Similar to cooperation among MEC servers, network users
can also implement cooperative strategies to serve contents
to each other. A relevant study on users’ cooperation in
vehicular network is found in [161]. The work proposes a
low-cost video caching strategy for mobile devices for delay-
tolerant video applications and provided simulation evidences
to claim the efﬁcacy. While caching most popular videos at the
edge servers signiﬁcantly improves the performance of video
delivery system, there is still a tradeoff between caching high
bit rate videos versus caching high diversity videos.

Video retrieval occurs too frequently as compared to cache
placement. Hence to enhance the efﬁciency of edge based
caching, the caching policy shall consider the two different
time scaled of cache placement and video retrieval. In [162],
authors proposed a caching policy that jointly considers the
long-term cache placement and short-term cache retrieval in
coordinated multi-server system to reduce service delay and
cache hit ratio. In [163], authors propose a hybrid caching
scheme by combining edge cache sponsoring (ECS) and cellu-

lar data sponsoring (CDS). In CDS, the content provider serve
free content to the user at the cost of playing advertisements
to generate revenue. The user is allowed to select any scheme
with the aim to achieve total maximum revenue for both ECS
and CDS via cooperation or for an individual provider via
competition.

To avoid caching a large number of multiple bitrate versions
of the same videos at the edge server, a single high bitrate
version of a videos is stored and then transcoded to lower
bitrate when lower bitrates are requested by users. However,
when the number of user requests increases, the simultaneous
transcoding tasks can exhaust edge computation resources.
To efﬁciently uses caching and transcoding resources at the
edge server, authors in [164] proposed a RAN-aware adaptive
caching scheme, which employs network information acquired
from the RAN to estimate the probability distribution of
the user requests and uses it to jointly decide video bitrate
selection for caching and transcoding. In [165], authors jointly
optimize caching, transcoding and retrieval in an energy efﬁ-
cient manner. The probability of uncertain user requests is
inferred via historical data to propose a proactive caching
policy. The work proposes that edge server can use backhaul
links to retrieve requested but not locally available from other
neighboring servers.

Few works consider ﬁnancial metrics (e.g., revenue etc) to
design cooperative caching schemes. For instance, in [153],
a collaborative online caching algorithm is proposed that
minimizes the sum of User Attrition (UA) cost and caching
cost for each content. The problem is formulated as Integer
Linear Program (ILP). In the online settings, the user requests
are revealed one by one to the edge server and the server
should take decision before next request to provide the content
from local cache (if available), or fetch from neighboring edge
servers or from the origin server.

B. Edge-based Processing

Cloud computing has been preferred for computational ex-
tensive tasks. However, it has several shortcomings in addition
to the common issue i.e., delay constraints as discussed earlier.
First, when transcoding a video stream at cloud, multiple
versions are created. The number of such transcoded bit rate
versions increases the trafﬁc traversing the core network. Sec-
ond, the cloud-based transcoding strategy is usually ﬁxed and
does not adapt to the dynamic changes in viewership. Hence,
edge-based processing of video content improves the network
resources utilization by sending only the higher bit rate version
to the edge server and then the edge server transcodes videos
locally as per local viewership. However, edge servers have
limited computational resources as discussed earlier and hence
must optimize computational tasks to improve the system’s
capacity. This section presents an overview of research efforts
in MEC based video content processing.

1) Joint Caching and Processing: The edge server pro-
vides caching and computation resources in close proximity
to the end devices. In video streaming applications, mobile
devices may need to utilize both resources i.e., fetching cached
video content from the edge server and ofﬂoad computation

18

tasks such as video transcoding to the edge server. For
efﬁcient utilization of both resources, the joint optimization
of caching and processing functions can improve the network
performance to achieve several beneﬁts. In this section, we
provide research efforts on joint optimization of caching and
processing resource allocation.

The collaboration among multiple MEC servers connected
via backhaul links is proposed in [91], i.e., for each new video
request, servers collaborate with each other to jointly cache
and transcode videos for each other. The idea is that any
MEC server in the delivery path (from video origin) to the
home MEC server of the requesting user can transcode the
video. A major beneﬁt of this scheme is that a server does
not need to cache different bitrate versions of the same video,
enabling efﬁcient storage across the edge network. Multi-MEC
cooperation allows to efﬁciently utilize overall edge resources
in a network. To improve the utilization of a single edge
server’s resources, end-devices must cooperate to access edge
servers. One way to achieve this is efﬁcient scheduling of
tasks at the edge server. In [166], authors propose an optimal
scheduling strategy for video streaming in best-effort HTTP
DASH-based video delivery,
leveraging joint coordination
among mobile users. Example of joint caching and processing
using edge-device cooperation is in [167]. In this work, the
authors investigated edge-based processing in VR application.
While the VR devices cache most of the components locally,
the MEC delivers the components not cached at the VR device.
The components are cached and processed at the edge server
to reduce computation delay. In order to cope with high com-
munication delay of the component delivery, a task scheduling
strategy is proposed. Joint caching and processing has a great
signiﬁcance in adaptive video streaming in which the video bit
rate is automatically adjusted (or selected) based on the user
device capability (e.g., channel, buffers capacity etc). Instead
of storing all possible bit rates of a video, MEC servers decides
which bit rates of a popular video are stored and which bit
rates are to be generated upon request. For instance, authors
in [168] proposed joint caching and processing to implement
adaptive bitrate video streaming by formulating it as integer
linear program to minimize the the latency of video retrieval.
The authors used ML technique to ﬁnd the video popularity
for caching. As caching large number of videos incurs storage
cost, caching/processing decision also involves revenue as an
important consideration. As a example. authors in [95] studied
edge based joint caching and processing to maximise the proﬁt
to video service providers. The joint scheme is formulated
as a binary optimization problem and solved using multi-
armed bandits (MAB) problem and the cache is updated in
real time as per users requests. Another interesting approach
to solve the joint caching and processing problem is to use
a more direct and realistic metric such as the “number of
user requests”. The work in [169] addressed this issue by
proposing a joint caching and processing scheme which aims
at the maximising the number of service requests that can
be served by each base station using a Stackelberg game.
The edge server predicts the requests of each BS’s users and
deﬁnes the caching/computing price that maximises its utility.
The BS then compete with each other to maximise the availed

resources from the MEC at ﬁxed price. A similar approach to
[169] is proposed in [170] with additionally considering the
user association. The problem is formulated as a mixed integer
programming (MIP) to minimize the video retrieval latency in
ultra dense heterogeneous networks.

In [171], authors propose a joint video caching and
transcoding for VoD streaming called as “proactive caching
and chunk processing (PCCP)”. First video chunks of popular
videos based on the user viewing patterns are proactively
fetched and stored in neighboring edge servers such that none
are replicated. When user requests a video, the respective
chunks corresponding to the same video are collected from the
neighboring servers and served to the user. A similar approach
is used in [172] to fetch only high bitrate versions of a video
from the origin/CDN server and transocode to lower bitrate
versions at the edge servers. Different edge servers in the
neighborhood can collaborate to transcode and share videos
with each other via X2 backhaul interface. In [173], authors
propose a joint caching and ofﬂoading scheme to ofﬂoad
duplicate computation tasks and the requested data content
to the edge servers. By jointly optimizing the caching and
ofﬂoading decision, the scheme minimizes the latency while
satisfying the energy consumption of mobile devices. The
work uses genetic algorithm to implement an online-learning
without requiring future information.

2) Joint Radio, Caching and Processing: Resource alloca-
tion in edge computing can be further improved by considering
the user’s wireless channel quality in the resource allocation
problem. Several works propose the joint optimization of
the edge resource allocation and the user’s communication
resources to meet the QoS requirement. Some representative
works are listed [137], [174]–[178].

In [174], authors proposed a joint radio, caching and pro-
cessing scheme for MEC-assisted VR applications. The edge
server proactively caches some parts of the videos and process
these videos. The caching and processing resource allocation
at the edge is jointly optimized with the transmission rate
constraint of end VR devices to maximize average delay,
while guaranteeing transmission rates, cache size, energy
consumption and front-haul capacity. In [175], MEC-assisted
VR delivery is proposed in which some parts of the videos
are cached at the edge whereas others are stored at the VR
device. The algorithm jointly optimize caching and computing
resources to determine the parts of videos (more speciﬁcally
called Field of Views or FOVs) to be cached and processed at
the mobile device and which ones to ofﬂoad to the edge server
under three constraints (i.e., cache size, power consumption
and latency). Due to the more dynamic and complex nature
of the problem, advanced techniques based on DL are being
proposed. For instance, in [176], the joint caching, transcoding
and transmission of videos is formulated as Markov Deci-
sion Process (MDP) and solved using Deep Reinforcement
Learning (DRL) to improve user experience in adaptive video
streaming. In [177], authors consider joint optimization of
caching, processing and radio resources to maximize sys-
tem revenue. In [178], authors propose video caching and
transcoding scheme in heterogeneous virtual MEC networks.
The scheme jointly optimize caching and transcoding with

19

the network radio conditions during the cache placement
and delivery phase respectively. In [137], authors propose to
perform the pre-processing of the videos at edge servers using
a lightweight Deep Neural Network (DNN) model, and upload
the results to cloud nodes for further analysis to produce a
complete video analytic solution. The aforementioned state-
of-the-art discussed in this section is summarized in Table VI.

C. Lessons learned and challenges

The main objective of deploying video streaming applica-
tions in the mobile edge networks is to minimize the perceived
delay,
the network cost and the energy consumption, and
to maximize different resources utilities (e.g., computation,
memory, and bandwidth) and the users’ QoE. Hence, most
of the recent works in the literature focus on establishing a
joint optimization to balance different purposes. The MEC
strategies are classiﬁed into centralized and collaborative video
caching and processing. The centralized approach relies typ-
ically on a base station or eNodeB to deploy different tasks.
In general, this strategy is simpler and the optimal resource
decisions are less complex. On the other hand,
the joint
strategies involve multiple MEC entities that collaborate to
ofﬂoad the streams, while respecting the objective constraints.
More speciﬁcally, when the users’ demand increases, MEC
servers can collaborate to serve content to its neighboring
servers. The collaboration among MEC servers becomes es-
sential when storing all requested video content locally is not
possible due to limited storage capacity. Typically, the caching
and processing of content is considered as a joint problem in
various works to improve the overall network performance.
Moreover, due to its strong impact on the ofﬂoading capability,
the channel quality is also considered in the joint optimization
problem. In this context, previous works proved that
the
optimal solution is NP-hard and approximation algorithms
have to be designed.

Due to the large size of videos and increasing use of
video-based services, traditional cloud-based caching schemes
such as MPV, LRU and LFU schemes are inefﬁcient to meet
the network demand. MEC-based video caching can beneﬁt
from machine learning to implement proactive content caching
at the network edge to reduce latency and improving the
utilization of limited caching capacity.

VI. DEVICE-TO-DEVICE (D2D) COOPERATION IN MEC
SYSTEMS

Over the last decade, a signiﬁcant increase in the compu-
tational power in the end devices has been observed. These
resource-rich devices can collaborate with each other via D2D
communication to achieve network-wide performance gains.
In the MEC system, mobile devices can implement D2D
communication to achieve several beneﬁts: First, to alleviate
the computation load on the edge server, particularly if the
edge server has limited resources or high computation load
by ofﬂoading tasks to mobile devices. Second, devices can
collaborate to exploit and reduce communication latency by
exploiting the high speed D2D communication. Third, due

Category

Ref

Description of Contribution

Evaluation Metrics

Table VI
STATE-OF-THE-ART OF MEC IN VIDEO STREAMING.

(cid:88) (cid:88)

Fetch Most Popular Videos (MPV) using nation-wide popularity.

Proactively fetch contents to reduce the sum of storage cost and user attrition cost.

Caching based on popularity and retention rate of video streams to maximize their video bitrate.

Smart caching based on user behavior to maximize the hit rate of contents within limited time.

Cache layered videos for multiple user groups. Users in same group share caching cost.

Prefetch popular videos from YouTube using ML-based prediction.

Cache videos that serves the maximum users by estimating the requested qualities using RAN information.

y
a
l
e
D

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:88)

Edge caching strategy for vehicular networks in which video content is stored on the RSU and fetched by users. (cid:88)

Prefetch highest bitrate version of the video from CDN server using X2 interface.

Prefetch video chunks into playout buffer from encountered vehicle caches/ stream from the cellular.

Solve the multiple bitrate video caching problem using polynomial complexity algorithm.

Operators advertise contents to attract a mobile user to request cached contents instead of non-cached contents.

Context-aware adaptive caching through network virtualization at the edge.

Jointly optimize caching of bitrate-aware ﬁles and the scheduling requests to minimize energy consumption.

Jointly optimize caching and transcoding resources using ILP to minimize the backhaul network cost.

Cooperative caching when users’ preference is unknown and only the historical content demands.

Joint caching placement (long-term) and video retrieval (short-term) in coordinated multi-server system.

Using Q-learning, ﬁnd the appropriate cache state to improve caching mechanism.

Joint collaborative caching and processing at multiple servers to minimize the delay of video retrieval.

Cache only the video chunks to be watched and collaboration among neighboring MECs to improve utilization.

A greedy collaborative caching strategy in heterogenous MEC network to minimize total delay of all users..

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

y
g
r
e
n
E

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

Edge nodes pre-process video data using DNN model and upload the results to cloud for further analysis.

(cid:88) (cid:88)

Peer-ofﬂoading using perceptual parameters such as pausing frequency, watching percentage and bit rates.

Reduce communication-resource consumption by using MEC to compute components not stored on VR device.

Implement per-channel optimal service-aware resource allocation.

(cid:55)

(cid:55)

(cid:55)

A method to decide (i) transcode locally or (ii) fetch from neighboring MEC or (iii) fetch from the origin server. (cid:88)

A video caching and processing model that offers maximized proﬁt to video service provider.

A joint caching and transcoding scheduling strategy to minimize the energy consumption.

BSs compete to maximise its revenue by maximising the request rate that can be served by the MEC server.

Minimizes the average retrieval latency of all users using proactively caching and user-BS association scheme.

Proactively cache video chunks likely to be watched instead of whole video content.

Online bit rate conversion to the requested version of videos fetched from the origin/CDN servers.

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

Joint task ofﬂoading and dynamic caching strategy to reduce overall latency of all mobile devices.

(cid:88) (cid:88)

Joint optimization of caching and transcoding for resource allocation in DASH.

To maximize the average tolerant delay while meeting the rate constraint in VR devices.

To decide whether to pre-cache (and if yes, which) parts of the ﬁeld of views (FOVs), with local pre-processing.

Jointly considers buffers, video quality, edge caching, transcoding and transmission for energy saving and QoE.

Jointly optimize the caching, radio and resource allocation to maximize the system revenue.

Joint multi-bitrate caching and transcoding by allocating physical and radio resources based on network stats.

Jointly considers transmission, coding, caching, and computation to meet delay requirement in mobile VR.

Jointly optimize cachig, processing and transmission to reduce latency.

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

Caching and
Proactive
Content Fetching

Cooperative
Caching

Cooperative
Processing

Joint Caching
and Processing

Joint Radio,
Caching and
Processing

[146]

[153]

[158]

[152]

[160]

[131]

[164]

[179]

[119]

[161]

[159]

[162]

[163]

[165]

[91]

[180]

[181]

[182]

[168]

[171]

[183]

[137]

[184]

[167]

[166]

[168]

[95]

[185]

[169]

[170]

[171]

[172]

[173]

[186]

[174]

[175]

[176]

[177]

[178]

[187]

[188]

t
s
o
c

k
r
o
w
t
e
N

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

o
i
t
a
r

t
i

H

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88) (cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88) (cid:88)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:88) (cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:88) (cid:88)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

y
t
i
c
a
p
a
C

(cid:88)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

20

e
u
n
e
v
e
R

r
e
h
t
O

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:88)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

21

in the network is a computational resource and thus can aid
to improve the overall computational capability of the system
by realising cooperation among devices and edge server. Such
kind of D2D-MEC cooperation can be extremely useful.

Several works have recently proposed the integration of
D2D communication in MEC systems to achieve performance
gains. In [202], authors proposed that D2D communication
can be used by mobile users to ﬁnd alternative resources
when accessing the cloud server encounters long delays due to
intermittent wireless connectivity. D2D-fogging is proposed in
[112], a concept similar to standard edge computing architec-
ture with D2D communication enabled among user devices.
The D2D devices collaborate with each other to share their
computation resources controlled by the base station (associ-
ated edge server). The tasks are ofﬂoaded online, aiming at
minimizing the time-average energy consumption. In [203]
authors proposed a D2D-ECN (Edge Computing Network)
framework for computation ofﬂoading. Using D2D-ECN,
computation intensive devices can ofﬂoad tasks to resource
rich devices. Q-learning has been used to perform optimal
resource allocation in a point-to-point ofﬂoading system. In
[113], authors proposed D2D-MEC system in which devices
ofﬂoad their computation to nearby idle devices (helpers). The
task ofﬂoading is jointly optimized with communication and
energy beamforming to maximize the sum-computation rates
of users. In [204] authors used D2D communication in MEC
system to maximize the number of devices supported by the
system with communication and computation constraints. A
mixed integer programming (MIP) formulation is presented
for the D2D-MEC system and solved by decomposing the
MIP problem into two sub problem. The simulation results
reveal signiﬁcance of the proposed D2D-MEC system in
cellular networks. In [114], authors highlighted the use of D2D
collaboration in MEC system to improve the overall system
capacity. Computing in D2D network is more complicated
when it comes to resource and topology management. The
work in [205] presents resource management in D2D-MEC
system such as link selection and sub-channel allocation,
transmit beamforming, transmit power and receiver combiner.
In [206], authors investigated experimentally the feasibil-
ity of video transcoding at
the user devices. The authors
transcoded videos of short duration on mobile phones to
measure the transcoding time. In [196], authors propose a
D2D-MEC system to improve the computation capacity of the
network i.e., to maximize the number of devices supported by
the cellular networks. In this scheme, a device can ofﬂoad its
tasks to an edge server and a nearby D2D device. In [11]
a joint communication and computation optimization scheme
for MEC is proposed that leverages on D2D communica-
tion. The nodes use collaborative beamforming to wirelessly
charge other devices and ofﬂoading computational tasks to idle
devices. In [115], authors studied D2D-enabled multi-MEC
system in which a user ofﬂoad computational tasks to multiple
local users using time division multiple access (TDMA) trans-
mission to achieve latency reduction. The timeslots are divided
into three phases. In the ﬁrst phase, the task is ofﬂoaded to the
helper nodes. In the second phase, the helper node executes
the task. The computation results are downloaded in the third

Figure 10. D2D Cooperation in MEC System.

to the short range communication, the device’s energy con-
sumption can be signiﬁcantly reduced. Fourth, the spectrum
utilization of cellular network can be multiplexed to improve
system’s overall capacity.

Both D2D and MEC systems aim to beneﬁt from the
proximity of the devices to achieve performance gains. In
D2D networks, a device connects with another nearby device
to communicate at smaller distance and thus achieve high
data rates and less latency. In MEC systems, devices can
beneﬁt from the closely located edge servers to fetch content
and ofﬂoad computations thus achieving low latency and
computational gains. Thus, the integration of both systems
will
intuitively allow network users to beneﬁt from both
technologies in a range of applications. Figure 10 illustrates
D2D ofﬂoading in MEC systems.

A. Relevant Works

D2D communication has been used in wireless networks to
gain several beneﬁts such as energy saving, less bandwidth
utilization and enhanced quality of experience [189]–[191].
For instance, [189] proposes a generic framework for D2D
communication to improve video quality and reduce energy
consumption and bandwidth utilization. In [191], authors pro-
pose Wi-Fi Direct based D2D scheme to scale the network
size and increase throughput.

Recently, D2D-enabled MEC systems have been proposed
[192]–[201]. In D2D-enabled MEC systems, mobile devices
can not only exploit the communication resources over D2D
links but they can also beneﬁt from the computational re-
sources of under-utilized devices. Every D2D enabled device

RANEdge	ServerD2DOffloadingEdgeOffloadingphase.

Quantile-based CSMA [207] and ITLinQ [208] have been
proposed to improve the network throughput for video trans-
mission in static networks without consideration for dynamic
user mobility. In [209], [210], the authors proposed the caching
at the network edge to reduce the congestion and the delay
transmission for video content. The caching technique is also
proposed in [211], [212] where the D2D communication is
used to create a direct communication between nearby mobile
users. These caching solutions are effective for stored video
but they introduce higher throughput, delay, and jitter in case
of live streaming. In [213], the authors proposed FlashLinQ
based on CSMA protocol to establish a D2D link. The links
are classiﬁed according to the link’s priorities where the links
with higher-priority do not suffer from signiﬁcant interference
with lower priority links. The algorithm uses the priority for
each link to schedule its activation time. FlashLinQ has a
good performance in terms of latency; however, the video
quality-aware mechanism was not considered in this work and
therefore its suitability for D2D on-demand video streaming
remains open. D2D communication has been proposed for
video streaming in [214]. The proposed model improves the
resource utilization in 5G by using a scheduling algorithm
for effectively sharing the multimedia content using D2D
communication. However, this algorithm studied only the case
for one user and one video without considering the case for a
multi-user with multi video sources.In [215], D2D multicast
communications for live streaming video is investigated. The
proposed scheme uses the frame priority (FP) to improve the
QoS perceived by users and the users’ satisfaction with the
video quality. The proposed model considers the encoding
characteristics of video streaming and users’ feedback to
ensure that the frames to be retransmitted are valuable for
decoding.

Table VII summarizes the recent research studies on D2D-

enabled MEC systems.

B. Lessons learned and challenges

Device-to-device collaboration for communication is an ef-
ﬁcient technique and is widely proposed in wireless networks.
D2D standard protocols also exists for direct communica-
tion among mobile users. D2D communication is used for
improved network coverage, higher throughput and reduced
energy consumption. In MEC, D2D has been proposed to
improve the ofﬂoading capacity of the edge server. Particularly,
devices can ofﬂoad computational tasks to helper devices in-
stead of the edge server. Such D2D ofﬂoading can be efﬁcient
when the total delay (sum of computation of communication
delays) for local processing or edge-based processing is higher
then D2D processing. D2D-ofﬂoading can also be used on the
downlink i.e., when the edge server is overloaded, the server
can ofﬂoad user’s tasks to the resource-rich helper devices.

Incentive mechanisms need also to be envisaged to system-
atize the revenue between broadcasters, MEC infrastructure
and D2D-participants. Furthermore, the security and privacy
aspects of the D2D ofﬂoading for video crowdsourcing appli-
cations are not well considered in the literature and they are

22

still the major limitation for such an approach. In this context,
blockchain-based techniques have been proposed as a strong
tool to handle an incentive and trusted environment for many
applications. However, it is rarely studied for edge-assisted
video streaming systems. We believe that blockchain combined
with distributed and cooperative network can guarantee data
integrity and effectively realize a trusted topology, particularly
in 5G networks. Moreover, since blockchain provides limited
data storage, efforts should focus on establishing a balance
between off-chain and on-chain strategies.

VII. INTELLIGENT EDGE FOR VIDEO STREAMING
Both Machine Learning (ML) and edge computing are
making profound impact in several domains, however when
they are combined, they can bring a more intriguing user ex-
perience. The intersection of both is being considered as a suit-
able platform for vertical applications e.g., automotive (e.g.,
autonomous cars), healthcare [217] (e.g., remote surgeries,
real-time assistance),security [218] (e.g., intrusion detection),
manufacturing (e.g., predictive maintenance), retail (e.g., VR-
enabled online shopping experience and personalized sugges-
tions) and connected homes (e.g., temperature control, smart
smart doorbells, access control, and smart lighting). Most of
the video streaming services that beneﬁt from edge computing
are using machine learning or have the potential to beneﬁt
from it.

Deep learning (DL) is a sub-domain of machine learning
which has been successful in solving highly complex prob-
lems. However, to meet the computational requirements, DL
applications typically leverage cloud computing. An associated
drawback of running deep learning on the cloud is the that data
might need to be transferred to the remote cloud server [219].
If such data is not available at the cloud (e.g., data coming
from visual sensors such as IoT video sensors) [220], this
“can result in network congestion and delays due to the long-
distance or multi-hop transmissions” [221]. Two illustrative
examples of scenarios which involves transmission of videos
to a server for processing include object/event detection (e.g.,
automatic ﬁre detection, crime detection) using videos from
surveillance cameras, and driving assistance in autonomous
driving (e.g., sending captured videos from preceding vehicles
to the server). To cope with this challenge, edge computing
comes as a suitable choice. By processing such data at edge
servers, the latency is reduced and most of the data required to
run the DL models is either available at the edge or at closely
located end devices, hence improving bandwidth utilization.

One of the broad applications of DL for multimedia stream-
ing is the video analytics for surveillance systems, which was
introduced in the previous section IV-E. In fact, we showed
that some monitored areas are very critical and need contin-
uous surveillance, such as military borders. In this scenario,
video frames (or video streaming) are sent instantaneously to
remote servers for real-time object/accident detection at every
small interval, which incurs huge data transfer. This type of
applications has also stringent latency constraint, as it requires
a prompt intervention, if an accident is detected.

Furthermore, for a better accuracy of the results, high-
resolution videos having high data volumes are transmitted

Table VII
DEVICE-TO-DEVICE (D2D) COOPERATION IN MEC SYSTEMS.

23

Category

Ref

Algorithm

Metric

Description

Evaluation
Method
Not Avail-
able

Simulation

Energy

Task success rate

Numerical model

Lyapunov
optimization

MIP

Simulation

Capacity

Lagrangian Multipliers

Simulation

Capacity

Convex optimization

Simulation

Energy

MINLP

Simulation

Latency, capacity

Convex optimization

Simulation

Capacity

Q Learning

Simulation

Latency

NLIP

Simulation

Energy

Android testbed

Real data

Capacity, Energy

Methods and
Use cases

Resource
Optimizing

Performance
Evaluation

[202]

[112]

[204]

[114]

[216]

[115]

[113]

[203]

[205]

[206]

Propose (i) optimal and (ii) periodic scheme to ofﬂoad tasks
and retrieve results.
Dynamic D2D ofﬂoading that minimize energy consumption
of all users, while preventing over-exploiting helper device’s
resources
Maximize the number of devices supported by cellular net-
work by minimizing edge resource computation and optimal
D2D pairing.
Propose a ﬁle allocation algorithm in D2D MEC systems to
improve the caching capacity

Collaborative beamforming to wirelessly charge other devices
using D2D and ofﬂoading computational tasks to idle devices.

User ofﬂoad computational tasks to multiple local users using
time division multiple access (TDMA).

Jointly optimize energy beam-forming, communication and
computation resources to maximize sum of computation rates
of users.
Jointly optimize computational ofﬂoading, power allocation
and CPU frequency adjustment for computation ofﬂoading
and resource management.
Select links in D2D to minimize energy consumption and then
jointly optimize resource allocation and MIMO signal design.

Transcoded videos of short duration on mobile phones to
measure the transcoding time.

by the source to the computation units. The accuracy is also
affected by the speed of feeding the data to the model, which
requires bandwidth availability and efﬁcient communication
technologies to follow the requirements of the DL model. It is
worth to mention that video surveillance cameras are highly
pervasive. For example, 170 million cameras are in deployed
in China roads only [222]. These devices are generating a
huge amount of data as previously described. It is reported
that the data produced by IoT devices will witness a growth
of 28% by 2025 [223], where 65% of it is related to the
surveillance cameras [224]. Even-though the conventional
wisdom resorts to the centralized cloud servers for analytics
owing to their high computational capacity, ofﬂoading these
bulk of data presents scalability issues, as the access to the
cloud can experience bandwidth bottleneck when the number
of video sources increases. Moreover, due to the strict latency
requirements, the cloud is no longer a feasible solution.

Recently, DRL techniques have been applied for video
streaming and network selection in [225]–[227]. In [225], a
system that generates adaptive bitrate (ABR) algorithms using
reinforcement learning (RL) is proposed. This model trains
a neural network model to select bitrates for future video
chunks based on observations collected by client video players.
In [226], the authors proposed QARC (Quality Aware Rate
Control) algorithm to obtain a higher perceptual video quality
with possible lower sending rate and transmission latency.
QARC uses DRL algorithm to train a neural network for
selecting future bitrates based on previously observed network
status and past video frames. In [227], a predictive panoramic
video delivering based on DRL has been proposed. The LSTM
model is used to predict the user’s ﬁeld of view (FoV) in

the next few seconds. These systems focus on the continuous
prediction of video resolution and average video bitrate.

In the following, we provide a more detailed review of
the research contributions on the use of ML/DL techniques
in MEC systems for video streaming use cases. The section
covers various areas of video streaming i.e., proactive caching,
optimal computation ofﬂoading, adaptive streaming, video
analytics and AR/VR streaming. A summary of these works
is presented in Table VIII.

A. Proactive Caching

Machine learning is being widely proposed to implement
proactive caching. Proactive caching is extremely useful when
the user viewing patterns are not constant and resource al-
location is required to meet service requirements. Machine
learning thus brings new possibilities by implementing intel-
ligent edge caching to capture hidden features from historical
data or current network stats. For instance, ML techniques
can be used to forecast video popularity or predict future user
requests based on historical viewing patterns of users. ML
assisted proactive caching schemes are investigated in [149],
[228]–[232]. In [149], authors integrated three ML techniques
i.e., Auto Regressive Integrated Moving Average (ARIMA),
Multiple Linear Regression (MLR), and k-Nearest Neighbor
the users social patterns and
regression (kNN) to predict
used it for caching resource allocation. Advanced prediction
techniques such as Long Short-Term Memory (LSTM) deep
learning model can be used for more efﬁcient prediction of
video popularity. LSTM has been effectively used in [232] to
predict both long-term and short-term video content popularity.

24

Figure 11. DRL for video transmission.

While historical user viewing data can provide a reasonable
estimate of future behavior, other parameters can also be
considered for effective caching policies. In [230], authors
applied Deep Reinforcement Learning (DRL) to implement
caching scheme by using user requests, network constraints,
and external information. In the proposed DRL-based scheme,
the inputs are the index of currently requested content, the
number of requests for the cached content, and the time when
the cached content was most recently requested. Using these
inputs as “states”, the DRL agent determines whether or not
to cache the currently requested content. The reward function
is the ofﬂoaded trafﬁc in each request. The DRL model
evaluated using the MovieLens dataset [245] shows improved
performance against traditional caching policies i.e., FIFO,
LFU, and LRU. In [229], a network-aware caching scheme
is implemented using machine learning. The users’ behavior
and networks parameters such as cache size, bandwidth, and
load are to build a neural network model to estimate video
popularity. The estimated video popularity of video content
is used in mixed integer programming to calculate cache
size and content placement. Authors in [231] developed a
DQN model to implement a mobility-aware joint caching and
computing design in vehicular networks. The model states
include parameters i.e., available caches, available vehicles,
contacts per time slot, and contact times for every vehicle.
The agent performs the action i.e., decides which server and/or
vehicle is assigned to the requesting vehicle, and determines
whether to cache the requested content or not. The reward
function is cost of communication for data transmission.

B. Computation Ofﬂoading

The computation ofﬂoading and resource allocation at edge
servers is often solved as an optimization problem using
integer programming or heuristics [154], [246], [247]. How-
ever, recently deep learning models such as DRL and Deep

Q-learning networks (DQN) are proposed to solve resource
allocation in various networks. For instance, in [233], DRL
has been employed to jointly optimize caching, computation
ofﬂoading policy, and radio resource allocation to minimize
the average end-to-end delay. The DRL model in this work
uses state parameters including number of requests, number of
fog nodes, task sizes, computation requirement, popularity of
requested content, and channel quality vector between devices
and fog nodes. The action space includes multiple decisions
such as the fog node to serve the user, whether to store the
requested content or not, the allocated communications sub-
channels and computational resources. The reward function
is the weighted sum of time for computation and content
delivery. In [234], the edge resource allocation problem con-
sidering multiple tasks ofﬂoaded to the edge server by mobile
devices is investigated. The problem is formulated as mixed
integer program and then solved using DQN. The system
state includes all users’ ofﬂoading decisions and bandwidth
allocations for all users. The action is an index that denotes the
selection among two different neighboring states. The reward
is chosen as 1 if the total ofﬂoading cost is decrease after
taking an action and -1 if the cost is increased. If the ofﬂoading
cost remains constant after an action, reward is 0. The total
ofﬂoading cost is the sum of energy cost, computation cost,
and delay cost.

C. Adaptive Streaming and QoS

Adaptive streaming is the ability of the video delivery
system in which the video quality is automatically adjusted
according to the user’s preference or network conditions.
More speciﬁcally, the video bitrate is automatically adjusted
as the user’s channel quality degrades or improves, or the user
requests a particular bitrate. Although mobile edge computing
provides extra support to implement adaptive video stream-
ing in video services, recent development in deep learning

 Actions Reward States Features EnvironmentsRL  CNN, LSTM, NN …. Table VIII
MACHINE LEARNING IN EDGE COMPUTING FOR VIDEO STREAMING.

Category

Ref

Model

Method

Dataset

Description

25

[149]

[228]

[229]

[230]

[231]

[232]

[233]

[234]

[235]

[236]

[237]

[238]

[239]

[240]

[241]

[242]

[243]

[244]

Caching

Computation
Ofﬂoading

Adaptive Video
Streaming &
QoS

Video Analytics

DRL

DQN

RBM

DRL

DRL

CNN

CNN

CNN

CNN

ARIMA, MLR,
KNN

Testbed

Real

Forecast video popularity pattern to cache popular videos

Q-learning

Simulation

Synthetic

Distributed cache replacement using Q-learning based on content
popularity

ELM

DRL

DQN

Simulation

Simulation

Real

Real

Simulation

Synthetic

LSTM

Simulation

Real

Estimate the unknown popularity of contents for caching.

Learn end-to-end caching policy using DRL

Estimating mobility-aware reward for joint caching and computing in
edge.
Cache videos using long-term and short-term popularity prediction of
videos.

Simulation

Synthetic

Simulation

Synthetic

Minimizes end-to-end delay for caching, ofﬂoading, and radio re-
sources
Minimizes energy, computation, and delay cost for multiple task
ofﬂoading

Simulation

Simulation

Real

Real

Simulation

Synthetic

Using RBM with linear classiﬁer for concurrent
multiple users with QoS guarantees
Use DRL to assign users to the appropriate server in multi server MEC
system.
MEC-assisted adaptive video streaming for driving assistance for
improved “quality level switching”.

transmission to

Testbed

Testbed

Testbed

Simulation

Real

Real

Real

Real

Real

L-CNN

Simulation

ADMM

Simulation

Real

DNN

Testbed

Real

Edge-based faster object detection in videos.

Edge-based object recognition model for food items.

Improving frame rate and accuracy with edge computing running
CNN.
Collaboration among user and edge server to train a CNN Model to
improve object recognition.

A CNN model for resource-constrained edge server.

Latency-aware video summarization using ADMM, to understand the
story-line of a video before a client requests the complete video content
summarizing
Automated ML framework using DNN to perform object recognition
in device-captured frames sent at the edge server, while improving
recognition accuracy.

particularly deep reinforcement learning are being proposed
to improve MEC based adaptive streaming. In [235], au-
thors proposed a multi-stage learning system using Restricted
Boltzmann Machine (RBM) to manage simultaneous video
transmission which guarantees a minimum quality level for
each user. In [236], authors used DRL model to assign users
to the most suitable edge server aiming at improving quality
of service in video streaming. In this model, the states include
resource usage, viewer scheduling information, and current
viewer request. The agent’s action is to assign a viewer’s
request to a server. When a new user’s request is assigned
to a server, it will increase the load on the system which
impacts the QoE for the new users. Thus, the reward function
is chosen as the opposite number of the overall penalty for the
coming viewer. The aforementioned works on adaptive video
streaming do not include mobility scenario such as vehicular
users. To implemented MEC-assisted video streaming services

in road scenarios, authors in [237] propose the use of DRL
technique. The states of the DRL model include video quality
level, queue length in the edge server, and average wireless
channel gain. The wireless channel gain captures the mobility
pattern of users. The agent uses the states to decide the action
i.e., assigning the video quality levels to users. For each action,
the reward is computed i.e., weighted sum of high quality level
assigned to user, negative reward of quality level switching and
the negative reward for queue length.

D. Video Analytics

Video analytics are advanced services using streaming
videos to extract real-time insights. There is a broad range of
applications which requires real-time analytics in streaming
services such as surveillance [238], autonomous vehicles,
cognitive assistance [239], video summarization [243], and
ﬁlmography etc. However, such analytics are only useful

when provided in real-time i.e., within strict delay deadlines.
These advanced services rely on deep learning techniques
which requires huge computational resources. MEC is being
increasingly proposed as a promising solution to perform faster
analytics and at lower data transmission delay. Authors in
[238] used CNN model for object detection in edge computing
based video analytics for real-time surveillance and achieved
accurate Region Of Interest (ROI) detection. The edge servers
train local models on data collected from devices connected
to it in a distributed way whereas the cloud server contains
a global model which is shared with the edge servers. In
[239], CNN model is used for food object recognition for
latency-sensitive application using edge computing services.
The recognition latency and energy consumption of devices is
reduced by distributing the model learning tasks among edge
servers and the cloud server. The initial image pre-processing
such as identiﬁcation of blurred images is performed at devices
using simple methods i.e., K-means algorithm. Then image
segmentation i.e., extracting background and foreground object
from the image is performed at the edge layer. Lastly, the
DNN model i.e., CNN for object recognition is executed at
the cloud. In [240], a CNN model, Yolo [248] is implemented
on edge server to support computationally weak front-end
devices by ofﬂoading their tasks to the edge to achieve a higher
frame rate and accuracy. The scheme estimates the network
conditions and the actual requirements of the application to
decide the ofﬂoading strategy in CNN computing. DeepCham,
a DL-based object recognition model is proposed in [241]
using collaboration among users and edge server. Devices and
edge servers collaborate to train the CNN model to improved
accuracy of the model. Similarly, a lightweight CNN model is
developed in [242] for resource-constrained edge server with
reduced numbers of ﬁlter numbers in each layer.

Video summarizing on edge server and sending the video
summary instead of the whole video to let the user understand
the video content have many attractive use cases. User expe-
rience can be signiﬁcantly improved if the video summary
size is tailored according to the varying network bandwidth
and user viewing behavior. Authors in [243] proposed latency-
aware edge computing to achieve the adaptive summarization
with improved bandwidth utilization and viewing experience.
In [244], authors applied DNN to automatically perform object
recognition in videos. The proposed method improves the
accuracy of the object recognition while meeting the frame
capturing rate constraint.

E. AR/VR

MEC is being used in AR/VR streaming services to ac-
complish DL tasks such as object recognition and features
extraction at much higher rates. This involves relatively more
complex tasks such as ﬁeld of view (FOV) prediction in in
360◦ using deep learning [249]–[251]. The predicted FOV is
used to determine the spatial region in video to be fetched from
the VR content provider. Edge computing can help to improve
such applications by reducing the latency as illustrated in
[252]. In Table IX, we have provided a list of useful datasets
of video streaming with brief descriptions and applications for
prospective researchers.

26

F. Lessons learned and challenges

Machine learning techniques can be efﬁciently applied in
mobile edge computing to gain several beneﬁts. In video
caching, ML techniques can predict
the cache demand to
allocate storage resources and prefetch video content before
users request them. User requests can be accurately predicted
using user’s viewing patterns or video popularity on both
short-term and long-term basis. LSTM and DRL techniques
are relatively efﬁcient for proactive video caching. For com-
putation ofﬂoading and resource allocation on the edge server,
DQN and DRL have been widely proposed. In addition to
these, MEC also provides a platform to deploy ML-based
services for several applications including video analytics,
interactive videos, and content detection. A detailed analysis
of the ML-based techniques discussed in this section shows
that MEC improves the application performance in several
ways; (i) perform training and inference of DL models fully
or partially, (ii) MEC can be used for pre-processing of huge
amount of data, (iii) collaboration among edge servers and
cloud improve system’s capacity. Such applications (e.g., VR
and AR.) do not only require a successful classiﬁcation of the
objects, but also a high accuracy rate. However, the stringent
requirements in terms of latency halt them from computing
remote tasks. In other words, even 100 ms end-to-end latency
of edge classiﬁcation may no longer match the highly variable
location of moving objects [263]. In this context, authors in
[264] expected a latency equal to 20 ms to avoid motion sick-
ness in virtual reality applications. Compression techniques
to minimize the data transmission latency are proved to be
promising [263]. However, compression strategies should be
revisited to establish a trade-off between data transmission
and classiﬁcation accuracy. Moreover, edge-assisted on-device
inferences are envisaged to avoid remote transmissions.

VIII. FUTURE RESEARCH DIRECTIONS

A. Mobile Edge Computing in 5G/6G Networks

The current 5G networks have the potential to provide a
robust network for connecting people around the world. How-
ever, challenges persist as new services with more stringent
requirements are introduced. The next generation of wireless
communication known as 6G [265], [266] can meet these
unprecedented requirements that 5G might not support. In
fact, when we deep dive on the roadmap of the 8K, VR,
AR, and even eXtended Reality (XR), we can point
that
it not possible with 5G to longer support these volumetric
videos. This is due to the 5G design and baseline KPIs that
aim to reach an average ubiquitous capability equal to 100
Mbps downlink and 50 Mbps uplink [267]. Whereas, the long
term roadmap of eXtended reality videos is to be pervasive
everywhere on a network offering multi-gigabytes to users.
Moreover, current 360° 4K videos need 10 to 50 Mbps to be
delivered to devices, meanwhile the next generation 8k videos
require from 50 to 200 Mbps, which cannot be served by
5G. Also, looking to the futuristic types of videos, such as
6 Degrees of Freedom streamings, and holography presenting
full immersive experience and requiring few Gbps to Tbps, 5G
network is highly challenging. Aside from the incapacity to

27

n
o
i
t
a
c
o
l
l
a

c
ﬁ
f
a
r
t

d
n
a

,
g
n
i
h
c
a
c

e
g
d
e

,
n
o
i
t
a
c
o
l
l
a

e
c
r
u
o
s
e
r

d
u
o
l
c
-
i
t
l
u
M

a

r
e
v
o

e
v
i
l

k
o
o
b
e
c
a
F

m
o
r
f

d
e
t
c
e
l
l
o
c

s
o
e
d
i
v

3
7
4
.
6
0
5
.
1

f
o

t
s
i
l

a

f
o

s
t
s
i
s
n
o
c

t
e
s
a
t
a
d

e
h
T

.

m
e
l
b
o
r
p

.
s
r
e
t
s
a
c
d
a
o
r
b

t
n
e
r
e
f
f
i
d

1
3
2
.
8
0
4

y
b

d
e
h
s
i
l
b
u
p

e
r
a

s
o
e
d
i
v

e
h
T

.
s
y
a
d

4
3

f
o

d
o
i
r
e
p

8
1
0
2

]
3
5
2
[

e
v
i
L

k
o
o
b
e
c
a
F

-
ﬁ
i
s
s
a
l
c

d
n
a

,
g
n
i
n
o
i
t
p
a
c

,
n
o
i
t
i
n
g
o
c
e
r

y
t
i
v
i
t
c
a

s
a

h
c
u
s

s
c
i
t
y
l
a
n
a

o
e
d
i
V

e
h
T

.
3

e
r
a

o
e
d
i
v

h
c
a
e

r
o
f

s
l
e
b
a
l

d
e
t
a
r
e
n
e
g
-
e
n
i
h
c
a
m

f
o

r
e
b
m
u
n

e
g
a
r
e
v
a

e
h
T

.
s
e
s
s
a
l
c

2
6
8
3

d
n
a

s
o
e
d
i
v

f
o

s
r
u
o
h

0
0
0
,
0
5
3

,
s
D

I

o
e
d
i
v

n
o
i
l
l
i

M
1
.
6

s
n
i
a
t
n
o
c

t
e
s
a
t
a
d

l
a
n
i
g
i
r
o

e
h
T

.
n
o
i
t
a
c

s
t
n
e
m
g
e
s

K
7
3
2

t
u
o
b
a

n
o

s
l
e
b
a
l

d
e
ﬁ

i
r
e
v
-
n
a
m
u
h

s
n
i
a
t
n
o
c

t
e
s
a
t
a
d

e
h
t

f
o

n
o
i
s
r
e
v

d
e
d
n
e
t
x
e

.
t
e
s

n
o
i
t
a
d
i
l
a
v

e
h
t

m
o
r
f

s
e
s
s
a
l
c

0
0
0
1

n
o

)
o
e
d
i
v
/
s
t
n
e
m
g
e
s

5

f
o

e
g
a
r
e
v
a
(

9
1
0
2

]
4
5
2
[

M
8
-
e
b
u
T
u
o
Y

,
g
n
i
l
e
d
o
m

n
o
i
t
n
e
t
t
a

l
a
u
s
i
v

,
g
n
i
m
a
e
r
t
s

R
V

n
i

s
n
r
e
t
t
a
p

r
o
i
v
a
h
e
b

r
e
s
U

8
1

g
n
i
h
c
t
a
w

)
s
e
l
a
m
e
f

4
2

d
n
a

s
e
l
a
m

4
2
(

s
r
e
s
u

8
4

f
o

g
n
i
k
c
a
r
t

d
a
e
h

s
n
i
a
t
n
o
c

t
e
s
a
t
a
d

e
h
T

.
n
r
e
t
t
a
p

n
o
i
t
o
m
d
a
e
h

n
o

d
e
s
a
b

n
o
i
t
a
c
ﬁ
i
t
n
e
d
i

r
e
s
u

,
n
o
i
t
c
i
d
e
r
p

g
n
i
z
a
g

.
s
e
i
r
o
g
e
t
a
c

5
m
o
r
f

s
o
e
d
i
v

l
a
c
i
r
e
h
p
s

7
1
0
2

]
6
5
2
[

t
e
s
a
t
a
d

g
n
i
m
a
e
r
t
S

R
V

g
n
i
m
a
e
r
t
s

o
e
d
i
v

◦
0
6
3

n
i

e
c
n
e
i
r
e
p
x
e

g
n
i
w
e
i
V

m
o
r
f

s
e
c
a
r
t

t
r
o
p
w
e
i
v

d
e
d
r
o
c
e
r

d
n
a

,
y
m
o
n
o
x
a
t

e
h
t

n
o

d
e
s
a
b

s
o
e
d
i
v

◦
0
6
3

8
2

f
o

t
e
s
a
t
a
d
A

.
s
o
e
d
i
v

e
h
t

g
n
i
h
c
t
a
w
s
t
n
a
p
i
c
i
t
r
a
p

0
6

9
1
0
2

]
7
5
2
[

t
e
s
a
t
a
d

s
o
e
d
i
V

◦
0
6
3

c
i
r
t
n
e
c
-
r
e
s
u

d
n
a

,
g
n
i
k
r
a
m
h
c
n
e
b

e
c
n
a
m
r
o
f
r
e
p

,
s
l
e
d
o
m

e
v
i
t
c
i
d
e
r
p

E
o
Q

g
n
i
n
n
a
l
p

k
r
o
w
t
e
n

e
l
i
b
o
m

s
o
e
d
i
v

e
c
n
e
r
e
f
e
r

4
2

m
o
r
f

d
e
t
a
r
e
n
e
g

s
o
e
d
i
v

d
e
t
r
o
t
s
i
d

4
7
1

f
o

l
a
t
o
t

a

s
n
i
a
t
n
o
c

t
e
s
a
t
a
d

e
h
T

e
v
i
t
c
e
j
b
u
s

l
l
a
r
e
v
o

d
n
a

e
m

i
t
-
s
u
o
u
n
i
t
n
o
c

h
t
o
b

s
e
d
u
l
c
n
i

o
s
l
a

t
I

.
s
t
n
e
v
e

g
n
i
l
l
a
t
s

e
u
q
i
n
u

6
2

h
t
i

w

7
1
0
2

.
s
t
c
e
j
b
u
s

e
u
q
i
n
u

4
5
m
o
r
f

s
e
r
o
c
s

]
8
5
2
[

o
e
d
i
V

l
l
a
t
S
e
l
i
b
o
M
E
V
I
L

I
I
-
e
s
a
b
a
t
a
D

g
n
i
m
a
e
r
t
s

e
v
i
l

d
e
t
a
r
e
n
e
g
-
r
e
s
U

,
s
r
e
w
e
i
v

e
v
i
t
c
a

f
o

r
e
b
m
u
n

,
s
r
e
w
e
i
v

f
o

r
e
b
m
u
n

.
g
.
e

s
r
e
t
e
m
a
r
a
p

1
1

f
o

s
t
s
i
s
n
o
c

t
e
s
a
t
a
d

e
h
T

5
1
0
2

.
d
o
i
r
e
p

h
t
n
o
m
-
e
n
o

a

n
i

s
e
t
u
n
i
m
e
v
ﬁ

y
r
e
v
e

h
c
t
i

w
T
m
o
r
f

d
e
t
c
e
l
l
o
c

a
t
a
d

d
e
l
w
a
r
c

f
o

t
e
s
a
t
a
d
A

.
r
e
m
a
e
r
t
s

r
a
l
u
c
i
t
r
a
p

f
o

s
r
e
t
e
m
a
r
a
p

d
n
a

d
e
n
i
a
g

s
r
e
w
o
l
l
o
f

]
5
5
2
[

t
e
s
a
t
a
d

h
c
t
i

w
T

C
V
V
n
o
i
t
a
r
e
n
e
g
-
t
x
e
n

f
o

s
t
n
e
m
s
s
e
s
s
a

y
t
i
l
a
u
q

e
v
i
t
c
e
j
b
o

d
n
a

e
v
i
t
c
e
j
b
u
S

K
4

e
l
i
t
a
s
r
e
v

6
1

f
o

g
n
i
t
s
i
s
n
o
c

,
s
i
s
y
l
a
n
a

c
e
d
o
c

o
e
d
i
v

)

G
V
U

(

p
u
o
r
G
o
e
d
i
V
a
r
t
l

U

r
o
f

t
e
s
a
t
a
D

.
s
c
e
d
o
c

.
)
s
p
f
(

d
n
o
c
e
s

r
e
p

s
e
m
a
r
f

0
2
1

r
o

0
5

t
a

r
e
h
t
i
e

d
e
r
u
t
p
a
c

,
s
e
c
n
e
u
q
e
s

o
e
d
i
v

0
2
0
2

]
1
6
2
[

t
e
s
a
t
a
d
G
V
U

f
o

s
t
n
e
v
e

g
n
i
r
e
f
f
u
b
e
r

,
s
n
o
i
t
a
u
t
c
u
ﬂ

y
t
i
l
a
u
q

o
e
d
i
v

.
g
.
e

s
e
i
d
u
t
s

E
o
Q

5
6

y
b

d
e
t
a
u
l
a
v
e

e
r
e
w

t
a
h
t

s
o
e
d
i
v

0
2
4

s
e
d
u
l
c
n
i

h
c
i
h
w

t
e
s
a
t
a
d

E
o
Q

o
e
d
i
V

e
v
i
t
c
e
j
b
u
s

A

e
s
r
e
v
i
d

d
n
a

,
s
e
g
n
a
h
c

n
o
i
t
u
l
o
s
e
r

l
a
i
t
a
p
s

,
s
r
e
b
m
u
n

d
n
a

s
n
o
i
t
a
r
u
d

g
n
i
y
r
a
v

t
n
e
r
e
f
f
i
d

7

r
e
d
n
u

d
e
m
a
e
r
t
s

s
t
n
e
t
n
o
c

o
e
d
i
v

5
1
m
o
r
f

d
e
t
a
r
e
n
e
g

e
r
e
w
s
o
e
d
i
v

e
s
e
h
T

.
s
t
c
e
j
b
u
s

8
1
0
2

.
s
e
p
y
t

t
n
e
t
n
o
c

o
e
d
i
v

d
n
a

s
l
e
v
e
l

y
t
i
l
a
u
q
/
e
t
a
r
t
i
b

.
s
e
i
g
e
t
a
r
t
s

n
o
i
t
a
t
p
a
d
a

t
n
e
i
l
c

4

d
n
a

s
n
o
i
t
i
d
n
o
c

k
r
o
w
t
e
n

]
2
6
2
[

I
I
-

X
L
F
N
-
E
V
I
L

.
y
a
l
e
d

l
a
i
t
i
n
i

s
o
e
d
i
v

e
l
i
b
o
m
n
o

s
e
i
d
u
t

S

d
n
a

k
r
o
w
t
e
n

l
a
r
e
v
e
s

n
i
a
t
n
o
c

d
n
a

e
m

i
t

k
c
a
b
y
a
l
p

f
o

s
r
u
o
h

8
8
.
3
8
7

r
o
f

d
e
r
i
u
q
c
a

s
i

t
e
s
a
t
a
D

t
e
k
c
a
p

,

D
I
o
e
d
i
v

,
o
i
r
a
n
e
c
s

,
p
m
a
t
s
e
m

i
t

,
t
n
e
m
e
r
u
s
a
e
m

f
o

e
p
y
t

.
e
.
i

s
r
e
t
e
m
a
r
a
p

d
e
t
a
l
e
r

c
ﬁ
f
a
r
t

d
n
a

d
n
a

e
z
i
s
w
o
ﬂ

,
n
o
i
t
a
r
u
d
w
o
ﬂ

P
C
T

,
r
e
b
m
u
n

l
o
c
o
t
o
r
p

d
a
o
l
y
a
p

e
h
t

d
n
a

t
r
o
p

P
C
T

n
o
i
t
a
n
i
t
s
e
d

e
c
r
u
o
s

,
s
s
e
r
d
d
a

P
I

n
o
i
t
a
n
i
t
s
e
d

d
n
a

e
c
r
u
o
s

,
s
e
t
y
b

n
i

h
t
g
n
e
l

t
e
k
c
a
p

,
p
m
a
t
s
e
m

i
t

l
a
v
i
r
r
a

9
1
0
2

.
y
a
l
e
d

k
c
a
b
y
a
l
p

o
e
d
i
v

l
a
i
t
i
n
i

]
9
5
2
[

o
e
d
i
v

e
l
i
b
o
m

s
’
e
b
u
T
u
o
Y

t
e
s
a
t
a
d

g
n
i
m
a
e
r
t
s

s
k
r
o
w
t
e
n
G
5

n
i

E
o
Q
g
n
i
m
a
e
r
t
s

o
e
d
i
V

s
n
o
i
t
a
c
i
l
p
p
a

t
n
e
r
e
f
f
i
d

o
w

t

g
n
i
s
u

,
s
r
a
c

g
n
i
v
o
m
d
n
a

c
i
t
a
t
s

o
w

t

m
o
r
f

d
e
t
a
r
e
n
e
g

s
i

t
e
s
a
t
a
d

e
h
T

y
e
k

r
a
l
u
l
l
e
c

e
d
i
s
-
t
n
e
i
l
c

s
n
i
a
t
n
o
c

t
e
s
a
t
a
d

e
h
T

.
d
a
o
l
n
w
o
d

e
l

ﬁ

d
n
a

g
n
i
m
a
e
r
t
s

o
e
d
i
v

.
e
.
i

-
l
l
e
c

,
s
c
i
r
t
e
m

d
e
t
a
l
e
r
-
t
x
e
t
n
o
c

,
s
c
i
r
t
e
m

d
e
t
a
l
e
r
-
l
e
n
n
a
h
c

.
g
.
e

)
s
I
P
K

(

s
r
o
t
a
c
i
d
n
i

e
c
n
a
m
r
o
f
r
e
p

.
n
o
i
t
a
m
r
o
f
n
i

t
u
p
h
g
u
o
r
h
t

d
n
a

s
c
i
r
t
e
m
d
e
t
a
l
e
r

0
2
0
2

]
0
6
2
[

t
e
s
a
t
a
d

e
c
a
r
t

G
5

X

I

e
l
b
a
T

.

H
C
R
A
E
S
E
R
G
N

I

M
A
E
R
T
S

O
E
D

I

V
R
O
F

S
T
E
S
A
T
A
D

s
n
o
i
t
a
c
i
l

p
p
A

n
o
i
t
p
i
r
c
s
e
D

r
a
e
Y

f
e
R

t
e
s
a
t
a
D

deliver a fast data rate for volumetric applications, 5G is not
designed for ultra-precision streaming tasks, such as remote
surgeries. On this basis, future works on 6G paradigm should
think about enhanced Ultra-Reliable and Low-Latency Com-
munications (URLLC) services, advanced massive machine
type communications (mMTC) services, and eventually new
network capabilities that allow to deploy pervasive streaming
on IoT devices or to fuse physical and virtual technologies.
More speciﬁcally, a new research area namely network slicing
has emerged [268], which consists of dividing a single network
connection into several virtual connections providing distinct
portions of resources that serve different types of trafﬁcs. An
interesting direction could be the enhancement of volumetric
video streaming in 6G networks via resource slicing.

the edge to perform critical

Another major transformation from previous cellular net-
works generations that 6G will bring, is the use of artiﬁcial
intelligence (AI) in the entire system architecture, from core
to the edge of the network. This transformation will be an
evolution towards “connect intelligence”. In the video stream-
ing context, 6G networks can use AI to perform big data
analytics of multimedia content to gain insights on network
performance, channel conditions, viewers perspectives and
preferences, and viewers’ location prediction. MEC plays a
key role in 6G networks as it can operate as an intermediate
layer providing localized and low-latency data processing for
real-time applications. More speciﬁcally, the high capacities
of centralized cloud servers offer sophisticated video and
metadata analysis, while sacriﬁcing in terms of transmission
overhead. Using the MEC allows to divide the data analytics
into tow phases. First, fast content caching and processing
can be done at
tasks, owing
to the proximity of MEC servers to viewers. As a second
step, a deeper and more efﬁcient data processing is carried
out in the remote servers, at the expense of higher delays.
Resource allocation decisions for live videos, cache placement
of content, video recommendation, and advertising process
can be cited as relevant use cases [266]. However, given the
limited resources in MEC networks, computing the AI train-
ing/inferences in MEC devices may be infeasible, particularly
when the task requires high computational load, e.g., Deep
Neural Networks. A promising solution is to adopt pervasive
computing, where different data storages and processing ca-
pacities existing everywhere and including distributed edge
servers and users devices cooperate to accomplish AI tasks
that need large memory and intensive computation. This
marriage of pervasive computing in MEC networks and AI
has given rise to a new research area, namely “Pervasive AI”,
which garnered considerable attention from both academia
and industry [269]. Formally, pervasive AI focuses on how
to intelligently distribute the inference or the training of the
AI model across edge devices, to minimize the latency, and
improve privacy and scalability. Research of this paradigm is
still in its infancy and needs further investigation to improve
the deployment of AI for video streaming tasks in mobile edge
computing networks.

28

B. Resource Migration with User Mobility

While the purpose of edge computing is to bring storage
and computation closer to the user, mobile users often move
around from one edge server to another one and resource
migration is required to provide high quality of experience.
Consider the example of a tourist moving around a city with
interactive glasses through which he receives video content
about the places he sees through it. While the video content is
always served through the nearest edge server to the respective
place he is currently viewing, the tourist might move away
(e.g. sitting in a tourist bus) while he still wishes to continue
watching the video of the previous place. In such a scenario,
the previous edge server needs to migrate the content and
computation to the new server closer to to the user’s current
location. Another use case when resource migration might
be required across edge servers, is to emergency treatment
provided to a critical patient in an ambulance moving towards
the hospital. The ambulance on-board facilities are connected
via 5G links to the healthcare provider central data and
computing resources. As the ambulance is traveling, it changes
association to different edge servers and consequently the
resource migration is required. The resource migration in the
above two use-cases have different latency constraints i.e.,
the second case have more stringent latency constraint. The
current state-of-the-art in resource migration is not sufﬁcient
and more investigation is required to provide the required QoS
in different use cases involving resource migration in edge
networks.

C. Live Video Analytics for Drones

Drones also termed as Unmanned Aerial Vehicles (UAVs)
are becoming popular and affordable and their use in commer-
cial application is growing. Drones are considered as a ﬁrst
choice for applications such as search-and-rescue, surveillance,
and wildlife conservation. These applications usually require
real-time video analytics which is a major challenge. Although
the use of edge computing in drone-based video applications
can bring signiﬁcant improvement in latency and ofﬂoading
intensive computation tasks, live video analytics is still the area
which requires further research and state-of-the-art solutions.
In particular these issues need further attention. (i) Drone’s
mobility may need computation migration from one edge
server to another on the ﬂy. (ii) The wireless links from drone
to the edge server rapidly vary and the resource allocation
shall be mandatory considering a joint communication and
computation mechanism. (iii) Drones have limited onboard
energy and only minimal computation to be performed locally
to reduce energy consumption of drone. (iv) Drones that are
receiving poor coverage by all edge servers may rely on
D2D ofﬂoading to forward computation or caching access to
other drones in the coverage. However, the effectiveness of
such D2D cooperation is highly dependent upon the aerial
links quality and stability. MEC-assisted drones [270] and
drone-drone cooperation in video services involve large-sized
content sharing and intensive ofﬂoading, which poses severe
challenges as compared to normal drone cooperation.

D. MEC in VR, AR, MR and 360◦ Videos Streaming

Virtual Reality, Augmented Reality and Mixed Reality have
been brieﬂy discussed earlier in the paper. Recently 360◦
videos have been introduced, as a part of VR. 360◦ videos
are large sized videos typically about 5x larger than that of
the 360◦ videos require
conventional videos. Furthermore,
lower delivery latency and higher bandwidth compared to
traditional video streaming. More importantly,
the Quality
of Experience (QoE) of viewers is highly sensitive to the
dynamics of the network environment and it is extremely
intolerant to delay variance and image freezing. Moreover,
because of the huge increase of the number of VR devices
which are estimated to reach 50 million in 2021 [271], the
backhaul network becomes a bottleneck. As stated previously,
the cloud wisdom is no longer sustainable for such real-
time applications with stringent requirements. Therefore, MEC
edge servers are introduced as an alternative to the cloud
computing offering computation and caching capabilities in
the vicinity of end-users. However, the huge processing re-
quirements of 360◦ videos could quickly exhaust the available
resources of the MEC Servers. Hence, efﬁcient algorithms
need to be designed for the given computational resources.
Second, caching multiple views of video incurs high overhead
in storage. Even if hard disks are not expensive nowadays,
storing all of these ﬁles is neither economical nor feasible.

E. Secure live video streaming using Blockchain

To address the challenges of lives video streaming, the
collaborative MEC servers process raw streams locally to
serve viewers with minimal delays. However, the wireless
data transmission incurs concerns in data security and privacy
because it exposes vulnerabilities to potential attackers to
perform malicious operations, such as eavesdropping private
video streams (e.g. non-paying subscribers). To prevent the
attackers from hacking the data, it is necessary to secure
the communication channel between different edge nodes
through encryption. However, due to the limited computational
resources available at MEC servers and the time sensitivity of
live streaming, the encryption will be relatively weak. Since
the live streaming system is composed of a distributed network
environment with a huge number of crowdsourcers with large
heterogeneity, a dynamic, ﬂexible, scalable and lightweight se-
curity mechanism is required. Additionally, the crowdsourcers
(subscribers) are geographically distributed across an untrusted
edge network. Hence, it is not suitable to implement security
system on a centralized device, which may suffer from perfor-
mance bottleneck. Blockchain [272] is a distributed database
that contains chronologically connected data blocks. Each
block is an individual component that includes information
linked to a speciﬁc transaction. We envision that blockchain
will be a strong ﬁt to provide a suitable solution for secure live
video sharing because of its immutability and decentralization
features, which are perfectly consistent with our context.
New requirements need to be handled in this task including,
addressing the trade-off between increasing security level and
latency. Public blockchain is slower than traditional database,

29

since it coordinates the blocks of multiple unafﬁliated partici-
pants, which contradicts the immediate responsiveness of live
streaming. However, since we deal with already subscribed
users of paid channels, blockchain solution can be feasible. A
future direction could be the design of a complete architecture
for blockchain-enabled authentication scheme for live videos
systems in MEC networks and a comprehensive evaluation to
validate the feasibility of the proposed authentication on the
live streaming platforms.

IX. CONCLUSIONS

This paper surveys the research efforts on mobile edge
computing for video streaming services. The paper presented
a brief overview of mobile edge computing architecture and
the various beneﬁts it brings to users and network/content
providers. Different schemes for edge-based content caching
and processing are discussed and categorized. The potential
beneﬁts of mobile edge computing for video streaming ser-
vices are presented. The state-of-the-art in MEC for video
streaming is summarized. In addition to the MEC applications
for video streaming services, D2D cooperation among end
users to improve the edge computing performance is presented
and research efforts in D2D-streaming are discussed. Machine
learning techniques have been rigorously used in MEC systems
and a signiﬁcant amount of work has been done in this area.
The paper summarised the use of ML/DL in MEC systems
for video streaming applications. Lastly, some useful insights
and future research directions are provided for prospective
researchers.

ACKNOWLEDGEMENT

This paper was made possible by Qatar University Internal
Grant No. IRCC-2020-001. The statements made herein are
solely the responsibility of the authors.

REFERENCES

[1] Netﬂix, Inc., Netﬂix [Online], Last accessed September 27, 2020. https:

//www.netflix.com/.

[2] , Hulu [Online], Last accessed September 27, 2020. http://www.hulu

.com/.

[3] Amazon, Inc., Amazon Prime [Online], Last accessed March 21, 2021.

https://www.primevideo.com/.

[4] K. Cao, Y. Liu, G. Meng, and Q. Sun, “An overview on edge computing

research,” IEEE Access, vol. 8, pp. 85714–85728, 2020.

[5] H. Lin, S. Zeadally, Z. Chen, H. Labiod, and L. Wang, “A survey
on computation ofﬂoading modeling for edge computing,” Journal of
Network and Computer Applications, p. 102781, 2020.

[6] A. Shakarami, M. Ghobaei-Arani, M. Masdari, and M. Hossein-
zadeh, “A survey on the computation ofﬂoading approaches in mobile
edge/cloud computing environment: A stochastic-based perspective,”
Journal of Grid Computing, pp. 1–33, 2020.

[7] M. De Donno, K. Tange, and N. Dragoni, “Foundations and evolution
of modern computing paradigms: Cloud, iot, edge, and fog,” Ieee
Access, vol. 7, pp. 150936–150948, 2019.

[8] W. Z. Khan, E. Ahmed, S. Hakak, I. Yaqoob, and A. Ahmed, “Edge
computing: A survey,” Future Generation Computer Systems, vol. 97,
pp. 219–235, 2019.

[9] N. Hassan, K.-L. A. Yau, and C. Wu, “Edge computing in 5g: A

review,” IEEE Access, vol. 7, pp. 127276–127289, 2019.

[10] N. Abbas, Y. Zhang, A. Taherkordi, and T. Skeie, “Mobile edge
computing: A survey,” IEEE Internet of Things Journal, vol. 5, no. 1,
pp. 450–465, 2018.

[11] S. Wang, X. Zhang, Y. Zhang, L. Wang, J. Yang, and W. Wang, “A
survey on mobile edge networks: Convergence of computing, caching
and communications,” Ieee Access, vol. 5, pp. 6757–6779, 2017.
[12] A. C. Baktir, A. Ozgovde, and C. Ersoy, “How can edge computing
beneﬁt from software-deﬁned networking: A survey, use cases, and
future directions,” IEEE Communications Surveys & Tutorials, vol. 19,
no. 4, pp. 2359–2391, 2017.

[13] E. Ahmed and M. H. Rehmani, “Mobile edge computing: opportunities,

solutions, and challenges,” 2017.

[14] T. Taleb, K. Samdanis, B. Mada, H. Flinck, S. Dutta, and D. Sabella,
“On multi-access edge computing: A survey of the emerging 5g
network edge cloud architecture and orchestration,” IEEE Communi-
cations Surveys & Tutorials, vol. 19, no. 3, pp. 1657–1681, 2017.
[15] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “Mo-
bile edge computing: Survey and research outlook,” arXiv preprint
arXiv:1701.01090, 2017.

[16] A. Ahmed and E. Ahmed, “A survey on mobile edge computing,” in
2016 10th International Conference on Intelligent Systems and Control
(ISCO), pp. 1–8, 2016.

[17] W. Shi, J. Cao, Q. Zhang, Y. Li, and L. Xu, “Edge computing: Vision
and challenges,” IEEE internet of things journal, vol. 3, no. 5, pp. 637–
646, 2016.

[18] D. Prerna, R. Tekchandani, and N. Kumar, “Device-to-device content
caching techniques in 5g: A taxonomy, solutions, and challenges,”
Computer Communications, vol. 153, pp. 48–84, 2020.

[19] C. Jiang, X. Cheng, H. Gao, X. Zhou, and J. Wan, “Toward compu-
tation ofﬂoading in edge computing: A survey,” IEEE Access, vol. 7,
pp. 131543–131558, 2019.

[20] L. Lin, X. Liao, H. Jin, and P. Li, “Computation ofﬂoading toward edge
computing,” Proceedings of the IEEE, vol. 107, no. 8, pp. 1584–1607,
2019.

[21] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey
on mobile edge computing: The communication perspective,” IEEE
Communications Surveys Tutorials, vol. 19, no. 4, pp. 2322–2358,
2017.

[22] Y. Xiao, Y. Jia, C. Liu, X. Cheng, J. Yu, and W. Lv, “Edge computing
security: State of the art and challenges,” Proceedings of the IEEE,
vol. 107, no. 8, pp. 1608–1631, 2019.

[23] R. Yang, F. R. Yu, P. Si, Z. Yang, and Y. Zhang, “Integrated blockchain
and edge computing systems: A survey, some research issues and
challenges,” IEEE Communications Surveys & Tutorials, vol. 21, no. 2,
pp. 1508–1532, 2019.

[24] D. Liu, Z. Yan, W. Ding, and M. Atiquzzaman, “A survey on secure
data analytics in edge computing,” IEEE Internet of Things Journal,
vol. 6, no. 3, pp. 4946–4967, 2019.

[25] J. Zhang, B. Chen, Y. Zhao, X. Cheng, and F. Hu, “Data security
and privacy-preserving in edge computing paradigm: Survey and open
issues,” IEEE Access, vol. 6, pp. 18209–18237, 2018.

[26] R. Roman, J. Lopez, and M. Mambo, “Mobile edge computing, fog et
al.: A survey and analysis of security threats and challenges,” Future
Generation Computer Systems, vol. 78, pp. 680–698, 2018.

[27] S. N. Shirazi, A. Gouglidis, A. Farshad, and D. Hutchison, “The
extended cloud: Review and analysis of mobile edge computing and fog
from a security and resilience perspective,” IEEE Journal on Selected
Areas in Communications, vol. 35, no. 11, pp. 2586–2595, 2017.
[28] M. Marjanovi´c, A. Antoni´c, and I. P. ˇZarko, “Edge computing architec-
ture for mobile crowdsensing,” IEEE Access, vol. 6, pp. 10662–10674,
2018.

[29] P. Porambage, J. Okwuibe, M. Liyanage, M. Ylianttila, and T. Taleb,
“Survey on multi-access edge computing for internet of things real-
ization,” IEEE Communications Surveys & Tutorials, vol. 20, no. 4,
pp. 2961–2991, 2018.

[30] W. Yu, F. Liang, X. He, W. G. Hatcher, C. Lu, J. Lin, and X. Yang, “A
survey on the edge computing for the internet of things,” IEEE access,
vol. 6, pp. 6900–6919, 2017.

[31] X. Wang, Y. Han, V. C. Leung, D. Niyato, X. Yan, and X. Chen,
“Convergence of edge computing and deep learning: A comprehensive
survey,” IEEE Communications Surveys & Tutorials, vol. 22, no. 2,
pp. 869–904, 2020.

[32] S. Deng, H. Zhao, W. Fang, J. Yin, S. Dustdar, and A. Y. Zomaya,
“Edge intelligence: the conﬂuence of edge computing and artiﬁcial
intelligence,” IEEE Internet of Things Journal, 2020.

[33] G. Carvalho, B. Cabral, V. Pereira, and J. Bernardino, “Computation
ofﬂoading in edge computing environments using artiﬁcial intelligence
techniques,” Engineering Applications of Artiﬁcial Intelligence, vol. 95,
p. 103840, 2020.

30

[34] J. Chen and X. Ran, “Deep learning with edge computing: A review,”
Proceedings of the IEEE, vol. 107, no. 8, pp. 1655–1674, 2019.
[35] Jiang, Xiantao and Yu, F. Richard and Song, Tian and Leung, Victor
C. M., “A Survey on Multi-Access Edge Computing Applied to Video
Streaming: Some Research Issues and Challenges,” IEEE Communica-
tions Surveys Tutorials, vol. 23, no. 2, pp. 871–903, 2021.

[36] Kenji Kanai and Kentaro Imagane and Jiro Katto, “[Invited Paper]
Overview of Multimedia Mobile Edge Computing,” ITE Transactions
on Media Technology and Applications, vol. 6, no. 1, pp. 46–52, 2018.
[37] Zhang, Qingyang and Sun, Hui and Wu, Xiaopei and Zhong, Hong,
“Edge Video Analytics for Public Safety: A Review,” Proceedings of
the IEEE, vol. 107, no. 8, pp. 1675–1696, 2019.

[38] Apple Inc., iTunes (Home Box Ofﬁce) [Online], Last accessed Septem-

ber 27, 2020. https://www.apple.com/qa/itunes/.

[39] “Cisco annual internet report - cisco annual internet report (2018–2023)

white paper,” Mar 2020.

[40] , League of Legends [Online], Last accessed September 27, 2020. https:

//na.leagueoﬂegends.com/en-us/.

[41] , Counter-Strike: Global Offensive [Online], Last accessed September

27, 2020. https://blog.counter-strike.net/.

[42] , Overwatch [Online], Last accessed September 27, 2020. https://play

overwatch.com/en-us/.

[43] , Dota 2 [Online], Last accessed September 27, 2020. https://blog.dot

a2.com/.

[44] , Call of Duty [Online], Last accessed September 27, 2020. https:

//blog.dota2.com/.

[45] Twitter Inc., “Periscope [online],” Last accessed September 27, 2020.

https://www.pscp.tv/.

[46] Google, YouTube Live Streaming API Overview [Online], Last accessed
September 27, 2020. https://developers.google.com/youtube/v3/live/ge
tting-started.

[47] K. Pires and G. Simon, “Youtube live and twitch: a tour of user-
generated live streaming systems,” in Proceedings of the 6th ACM
multimedia systems conference, pp. 225–230, 2015.

[48] R. T. Shefﬁeld, “Facebook live as a recordmaking technology,”

Archivaria, vol. 85, pp. 96–121, 2018.

[49] Instgram, How do I view someone’s live video on Instagram? - Twitter
Blog [Online], Last accessed September 27, 2020. https://help.instagr
am.com/699289326902954.

[50] Twitter, Go Live on Twitter! - Twitter Blog [Online], Last accessed
September 27, 2020. https://blog.twitter.com/en us/a/2016/go-live-o
n-twitter.html.

[51] IBM, IBM Cloud Video (formerly Ustream) [Online], Last accessed

September 27, 2020. https://video.ibm.com/.

[52] Dacast Inc., Dacast [Online], Last accessed September 27, 2020. https:

//www.dacast.com/.

[53] , Kaltura [Online], Last accessed September 27, 2020. https://corp.k

altura.com/.

[54] , Vimeo Livestream [Online], Last accessed September 27, 2020. https:

//vimeo.com/features/livestreaming.

[55] , “Panopto [online],” Last accessed September 27, 2020. https://www.

panopto.com/.

[56] P. Dogga, S. Chakraborty, S. Mitra, and R. Netravali, “Edge-based
transcoding for adaptive live video streaming,” in 2nd USENIX Work-
shop on Hot Topics in Edge Computing (HotEdge 19), (Renton, WA),
USENIX Association, 2019.

[57] M. Zink, R. Sitaraman, and K. Nahrstedt, “Scalable 360° video stream
delivery: Challenges, solutions, and opportunities,” Proceedings of the
IEEE, vol. 107, no. 4, pp. 639–650, 2019.

[58] J. Ruan and D. Xie, “A survey on qoe-oriented vr video streaming:
Some research issues and challenges,” Electronics, vol. 10, no. 17,
2021.

[59] Macromedia Inc., “Real-time messaging protocol (rtmp) speciﬁcation,”
Speciﬁcation Version 1.0, 2012. https://www.adobe.com/devnet/rtmp.
html.

[60] Schulzrinne, H., Rao, A., Lanphier, R., Westerlund, M., and M.
Stiemerling, Ed., “Real time streaming protocol (rtsp) version 2.0,”
Standard RFC 7826, IETF, 2012. https://www.rfc-editor.org/info/rfc7
826.

[61] Pantos, R., Ed., and W. May, “Http live streaming,” Speciﬁcation RFC

8216, 2017. https://www.rfc-editor.org/info/rfc8216.

[62] Apple Inc., Enabling Low-Latency HLS [Online], 2009 (accessed
September 24, 2020). https://developer.apple.com/documentation/
http live streaming/about apple s http live streaming tools.

[63] “Information technology—dynamic adaptive streaming over http
(dash)—part 1: Media presentation description and segment format,”

Standard ISO/IEC 23009-1:2012, International Organization for Stan-
dardization, 2012. https://www.iso.org/standard/57623.html.

[64] Apple Inc., Common Media Application Format with HTTP Live
Streaming [Online], (accessed September 24, 2020). https://develo
per.apple.com/documentation/http live streaming/about the commo
n media application format with http live streaming.

[65] Microsoft Inc., Microsof Smooth Streaming (MSS) [Online], 2009
(accessed September 24, 2020). https://docs.microsoft.com/en-us/i
is/media/on-demand-smooth-streaming/smooth-streaming-technical-o
verview.

[66] Adobe Systems Inc., HTTP Dynamic Streaming [Online], 2009 (ac-
cessed September 24, 2020). https://www.adobe.com/products/hds-d
ynamic-streaming.html.

[67] Open Source., Secure Reliable Transport (SRT) [Online], (accessed
September 24, 2020). https://en.wikipedia.org/wiki/Secure Reliable T
ransport.

[68] Open Source., Real-time communication for the web [Online], (ac-

cessed September 24, 2020). https://webrtc.org/.

[69] WOWZA Media Systems, “2019 video streaming latency report [on-
line],” Last accessed September 27, 2020. https://www.wowza.com/bl
og/2019-video-streaming-latency-report.

[70] Nicolas Weil, “Part 1: How to compete with broadcast latency using
current adaptive bitrate technologies [online],” Last accessed September
27, 2020. https://aws.amazon.com/blogs/media/how-to-compete-with
-broadcast-latency-using-current-adaptive-bitrate-technologies-part-
1/.

[71] “Parameter values for ultra-high deﬁnition television systems for pro-
duction and international programme exchange ,” recommendation,
International Telecommunication Union, Geneva, CH, Oct. 2019.
[72] “Requirements for mobile edge computing enabled content delivery
networks,” recommendation, International Telecommunication Union,
Geneva, CH, Mar. 2019.

[73] Cisco, U, “Cisco Annual Internet Report (2018–2023) White Paper.

2020.”

[74] Walid Saad and Mehdi Bennis and Mingzhe Chen, “A Vision of
6G Wireless Systems: Applications, Trends, Technologies, and Open
Research Problems,” IEEE Network, vol. 34, pp. 134–142, 5 2020.

[75] Ping Yang and Yue Xiao and Ming Xiao and Shaoqian Li, “6G Wireless
Communications: Vision and Potential Techniques,” IEEE Network,
vol. 33, pp. 70–75, 7 2019.

[76] Nick Barber, “Prepare To Support Video Livestreaming For Customer

Experiences,” white paper, 2017.

[77] Thundering Herd Problem. https://en.wikipedia.org/wiki/Thundering

herd problem, Last accessed March 03, 2021.

[78] Guardian, HQ Trivia: the gameshow app that’s an online smash?, 2020
(last accessed August 08, 2020). https://www.theguardian.com/techno
logy/2018/may/04/name-gameshow-app-thats-an-online-smash-hq-tr
ivia.

[79] Exploding watermelon blows the internet’s mind. https://edition.cnn.
com/2016/04/08/entertainment/buzzfeed-exploding-watermelon-irpt/in
dex.html,LastaccessedMarch03,2021.

[80] Greengrass, Jason and Evans, John and Begen, Ali C., “Not All Packets
Are Equal, Part I: Streaming Video Coding and SLA Requirements,”
IEEE Internet Computing, vol. 13, no. 1, pp. 70–75, 2009.

[81] Bertino, E. and Catarci, T. and Elmagarmid, A.K. and Hacid, M.-S.,
“Quality of service speciﬁcation in video databases,” IEEE MultiMedia,
vol. 10, no. 4, pp. 71–81, 2003.

[82] Venkataraman, Mukundan and Chatterjee, Mainak IEEE Network.
[83] “Quality of experience requirements for IPTV services,” standard,

International Telecommunication Union, Dec. 2008.

[84] Tim Szigeti, Christina Hattingh, “Quality of Service Design Overview,”
in End-to-End QoS Network Design: Quality of Service in LANs,
WANs, and VPNs (Jan Fagerberg and David C. Mowery and Richard
R. Nelson, ed.), ch. 2, US: Cisco Press, 2004.

[85] M. Patel, B. Naughton, C. Chan, N. Sprecher, S. Abeta, A. Neal, et al.,
“Mobile-edge computing introductory technical white paper,” White
paper, mobile-edge computing (MEC) industry initiative, pp. 1089–
7801, 2014.

[86] C. Systems, “Fog computing and the internet of things: Extend the

cloud to where the things are,” 2015.

[87] K. Bilal, O. Khalid, A. Erbad, and S. U. Khan, “Potentials, trends, and
prospects in edge technologies: Fog, cloudlet, mobile edge, and micro
data centers,” Computer Networks, vol. 130, pp. 94 – 120, 2018.
[88] F. Wang, M. Zhang, X. Wang, X. Ma, and J. Liu, “Deep learning for
edge computing applications: A state-of-the-art survey,” IEEE Access,
vol. 8, pp. 58322–58336, 2020.

31

[89] A. Khreishah, I. Khalil, A. Gharaibeh, H. B. Salameh, and R. Alasem,
“Joint caching and routing for greening computer networks with
renewable energy sources,” in 2014 International Conference on Future
Internet of Things and Cloud, pp. 101–106, 2014.

[90] A. Khreishah, J. Chakareski, A. Gharaibeh, I. Khalil, and Y. Jararweh,
“Joint data placement and ﬂow control for cost-efﬁcient data center
networks,” in 2015 6th International Conference on Information and
Communication Systems (ICICS), pp. 274–279, 2015.

[91] T. X. Tran, P. Pandey, A. Hajisami, and D. Pompili, “Collaborative
multi-bitrate video caching and processing in mobile-edge computing
networks,” in 2017 13th Annual Conference on Wireless On-demand
Network Systems and Services (WONS), pp. 165–172, 2017.

[92] C. Ge, N. Wang, G. Foster, and M. Wilson, “Toward QoE-Assured
4K Video-on-Demand Delivery Through Mobile Edge Virtualization
with Adaptive Prefetching,” IEEE Transactions on Multimedia, vol. 19,
no. 10, pp. 2222–2237, 2017.

[93] S. Barbarossa, S. Sardellitti, and P. Di Lorenzo, “Communicating while
computing: Distributed mobile cloud computing over 5g heterogeneous
networks,” IEEE Signal Processing Magazine, vol. 31, no. 6, pp. 45–
55, 2014.

[94] W. Zhang, Y. Wen, K. Guan, D. Kilper, H. Luo, and D. O. Wu,
“Energy-optimal mobile cloud computing under stochastic wireless
channel,” IEEE Transactions on Wireless Communications, vol. 12,
no. 9, pp. 4569–4581, 2013.

[95] Y. Hao, L. Hu, Y. Qian, and M. Chen, “Proﬁt Maximization for Video
Caching and Processing in Edge Cloud,” IEEE Journal on Selected
Areas in Communications, vol. 37, no. 7, pp. 1632–1641, 2019.
[96] K. Kumar and Y. Lu, “Cloud computing for mobile users: Can
ofﬂoading computation save energy?,” Computer, vol. 43, no. 4, pp. 51–
56, 2010.

[97] Huaming Wu, Qiushi Wang, and K. Wolter, “Tradeoff between per-
formance improvement and energy saving in mobile cloud ofﬂoading
systems,” in 2013 IEEE International Conference on Communications
Workshops (ICC), pp. 728–732, 2013.

[98] F. Wei, S. Chen, and W. Zou, “A greedy algorithm for task ofﬂoading
in mobile edge computing system,” China Communications, vol. 15,
no. 11, pp. 149–157, 2018.

[99] Y. Wang, M. Sheng, X. Wang, L. Wang, and J. Li, “Mobile-edge com-
puting: Partial computation ofﬂoading using dynamic voltage scaling,”
IEEE Transactions on Communications, vol. 64, no. 10, pp. 4268–4282,
2016.

[100] M. Jia, J. Cao, and L. Yang, “Heuristic ofﬂoading of concurrent tasks
for computation-intensive applications in mobile cloud computing,”
in 2014 IEEE Conference on Computer Communications Workshops
(INFOCOM WKSHPS), pp. 352–357, IEEE, 2014.

[101] L. Yang, J. Cao, S. Tang, T. Li, and A. T. S. Chan, “A framework for
partitioning and execution of data stream applications in mobile cloud
computing,” in 2012 IEEE Fifth International Conference on Cloud
Computing, pp. 794–802, 2012.

[102] D. Huang, P. Wang, and D. Niyato, “A dynamic ofﬂoading algorithm
for mobile computing,” IEEE Transactions on Wireless Communica-
tions, vol. 11, no. 6, pp. 1991–1995, 2012.

[103] O. Mu˜noz, A. Pascual-Iserte, and J. Vidal, “Optimization of radio and
computational resources for energy efﬁciency in latency-constrained
application ofﬂoading,” IEEE Transactions on Vehicular Technology,
vol. 64, no. 10, pp. 4738–4755, 2015.

[104] B. Dab, N. Aitsaadi, and R. Langar, “Joint optimization of ofﬂoading
and resource allocation scheme for mobile edge computing,” in 2019
IEEE Wireless Communications and Networking Conference (WCNC),
p. 1–7, IEEE Press, 2019.

[105] T. Yang, Y. Hu, M. C. Gursoy, A. Schmeink, and R. Mathar, “Deep
reinforcement learning based resource allocation in low latency edge
computing networks,” in 2018 15th International Symposium on Wire-
less Communication Systems (ISWCS), pp. 1–5, 2018.

[106] F. Haouari, E. Baccour, A. Erbad, A. Mohamed, and M. Guizani,
“Transcoding resources forecasting and reservation for crowdsourced
live streaming,” in 2019 IEEE Global Communications Conference
(GLOBECOM), pp. 1–7, 2019.

[107] S. Barbarossa, S. Sardellitti, and P. Di Lorenzo, “Joint allocation
of computation and communication resources in multiuser mobile
cloud computing,” in 2013 IEEE 14th workshop on signal processing
advances in wireless communications (SPAWC), pp. 26–30, IEEE,
2013.

[108] J. Ren, G. Yu, Y. He, and G. Y. Li, “Collaborative cloud and edge
computing for latency minimization,” IEEE Transactions on Vehicular
Technology, vol. 68, no. 5, pp. 5031–5044.

[109] M. Molina, O. Mu˜noz, A. Pascual-Iserte, and J. Vidal, “Joint scheduling
of communication and computation resources in multiuser wireless
application ofﬂoading,” in 2014 IEEE 25th Annual International
Symposium on Personal, Indoor, and Mobile Radio Communication
(PIMRC), pp. 1093–1098, IEEE, 2014.

[110] S. Guo, B. Xiao, Y. Yang, and Y. Yang, “Energy-efﬁcient dynamic of-
ﬂoading and resource scheduling in mobile cloud computing,” in IEEE
INFOCOM 2016-The 35th Annual IEEE International Conference on
Computer Communications, pp. 1–9, IEEE, 2016.

[111] A. Mehrabi, M. Siekkinen, and A. Yl¨a-J¨a¨aski, “Edge computing as-
sisted adaptive mobile video streaming,” IEEE Transactions on Mobile
Computing, vol. 18, no. 4, pp. 787–800, 2019.

[112] L. Pu, X. Chen, J. Xu, and X. Fu, “D2D Fogging: An Energy-Efﬁcient
and Incentive-Aware Task Ofﬂoading Framework via Network-Assisted
D2D Collaboration,” IEEE Journal on Selected Areas in Communica-
tions, vol. 34, no. 12, pp. 3887–39014, 2016.

[113] D. Wu, F. Wang, X. Cao, and J. Xu, “Joint Communication and Com-
putation Optimization for Wireless Powered Mobile Edge Computing
with D2D Ofﬂoading,” pp. 1–29, 2019.

[114] P. Yuan, Y. Cai, X. Huang, S. Tang, and X. Zhao, “Collaboration
Improves the Capacity of Mobile Edge Computing,” IEEE Internet
of Things Journal, vol. 6, no. 6, pp. 10610–10619, 2019.

[115] H. Xing, L. Liu, J. Xu, and A. Nallanathan, “Joint task assignment
and resource allocation for d2d-enabled mobile-edge computing,” IEEE
Transactions on Communications, vol. 67, no. 6, pp. 4193–4207, 2019.
[116] F. Haouari, E. Baccour, A. Erbad, A. Mohamed, and M. Guizani, “Qoe-
aware resource allocation for crowdsourced live streaming: A machine
learning approach,” in ICC 2019 - 2019 IEEE International Conference
on Communications (ICC), pp. 1–6, 2019.

[117] X. Niu, S. Shao, C. Xin, J. Zhou, S. Guo, X. Chen, and F. Qi,
“Workload allocation mechanism for minimum service delay in edge
computing-based power internet of things,” IEEE Access, vol. 7,
pp. 83771–83784, 2019.

[118] T. Zhao, S. Zhou, X. Guo, Y. Zhao, and Z. Niu, “A cooperative
scheduling scheme of local cloud and internet cloud for delay-aware
mobile cloud computing,” in 2015 IEEE Globecom Workshops (GC
Wkshps), pp. 1–6, IEEE, 2015.

[119] K. Bilal, E. Baccour, A. Erbad, A. Mohamed, and M. Guizani,
“Collaborative joint caching and transcoding in mobile edge networks,”
Journal of Network and Computer Applications, vol. 136, pp. 86 – 99,
2019.

[120] S. Wang, R. Urgaonkar, T. He, M. Zafer, K. Chan, and K. K. Leung,
“Mobility-induced service migration in mobile micro-clouds,” in 2014
IEEE Military Communications Conference, pp. 835–840, 2014.
[121] R. Urgaonkar, S. Wang, T. He, M. Zafer, K. Chan, and K. K. Leung,
“Dynamic service migration and workload scheduling in edge-clouds,”
Performance Evaluation, vol. 91, pp. 205–228, 2015.

[122] M.-H. Chen, B. Liang, and M. Dong, “Joint ofﬂoading decision and
resource allocation for multi-user multi-task mobile cloud,” in 2016
IEEE International Conference on Communications (ICC), pp. 1–6,
IEEE, 2016.

[123] K. Kumar, J. Liu, Y.-H. Lu, and B. Bhargava, “A survey of computation
ofﬂoading for mobile systems,” Mobile networks and Applications,
vol. 18, no. 1, pp. 129–140, 2013.

[124] Cha, Meeyoung and Kwak, Haewoon and Rodriguez, Pablo and Ahn,
Yong-Yeol and Moon, Sue, “Analyzing the Video Popularity Charac-
teristics of Large-Scale User Generated Content Systems,” IEEE/ACM
Transactions on Networking, vol. 17, no. 5, pp. 1357–1370, 2009.

[125] H. Ahlehagh and S. Dey, “Video-aware scheduling and caching in the
radio access network,” IEEE/ACM Transactions on Networking, vol. 22,
no. 5, pp. 1444–1462, 2014.

[126] Borst, Sem and Gupta, Varun and Walid, Anwar, “Distributed Caching
Algorithms for Content Distribution Networks,” in 2010 Proceedings
IEEE INFOCOM, pp. 1–9, 2010.

[127] Jiang, Wei and Feng, Gang and Qin, Shuang, “Optimal Cooperative
Content Caching and Delivery Policy for Heterogeneous Cellular
Networks,” IEEE Transactions on Mobile Computing, vol. 16, no. 5,
pp. 1382–1393, 2017.

[128] Platform9 Blog, Edge Computing and Video Streaming: Improving
User Experience [Online], 2020 (accessed November 04, 2020). https:
//platform9.com/blog/edge-computing-and-video-streaming-improvin
g-user-experience/.

[129] IEEE, Real-Life Use Cases for Edge Computing [Online], 2020 (ac-
cessed November 04, 2020). https://innovationatwork.ieee.org/real-lif
e-edge-computing-use-cases/.

32

[130] K. Bilal and A. Erbad, “Edge computing for interactive media and
video streaming,” in 2017 Second International Conference on Fog
and Mobile Edge Computing (FMEC), pp. 68–73, 2017.

[131] S. R. Yang, Y. J. Tseng, C. C. Huang, and W. C. Lin, “Multi-
Access Edge Computing Enhanced Video Streaming: Proof-of-Concept
Implementation and Prediction/QoE Models,” IEEE Transactions on
Vehicular Technology, vol. 68, no. 2, pp. 1888–1902, 2019.

[132] H. Hu, H. Shan, C. Wang, T. Sun, X. Zhen, K. Yang, L. Yu,
Z. Zhang, and T. Q. S. Quek, “Video surveillance on mobile edge
networks—a reinforcement-learning-based approach,” IEEE Internet of
Things Journal, vol. 7, no. 6, pp. 4746–4760, 2020.

[133] H. Hu, H. Shan, Z. Zheng, Z. Huang, C. Cai, C. Wang, X. Zhen, L. Yu,
Z. Zhang, and T. Q. S. Quek, “Intelligent video surveillance based on
mobile edge networks,” in 2018 IEEE International Conference on
Communication Systems (ICCS), pp. 286–291, 2018.

[134] Z. Rao and Z. Guo, “Application of video analysis based on mobile
edge computing,” in 2017 3rd IEEE International Conference on
Computer and Communications (ICCC), pp. 2040–2044, 2017.
[135] Y. Zhang, J. H. Liu, C. Y. Wang, and H. Y. Wei, “Decomposable
intelligence on cloud-edge iot framework for live video analytics,”
IEEE Internet of Things Journal, vol. 7, no. 9, pp. 8860–8873, 2020.
[136] X. Jiang, F. R. Yu, T. Song, and V. C. M. Leung, “Intelligent
resource allocation for video analytics in blockchain-enabled internet
of autonomous vehicles with edge computing,” IEEE Internet of Things
Journal, pp. 1–1, 2020.

[137] H. Sun, Y. Yu, K. Sha, and B. Lou, “MVideo: Edge Computing Based
Mobile Video Processing Systems,” IEEE Access, vol. 8, pp. 11615–
11623, 2020.

[138] Ericsson Blog, How 5G and Edge Computing can enhance virtual
reality [Online], 2020 (accessed November 04, 2020). https://ww
w.ericsson.com/en/blog/2020/4/how-5g-and-edge-computing-can-en
hance-virtual-reality.

[139] Multimodal Educatyion Center, Virtual Reality Experiences at the MEC
[Online], 2020 (accessed November 04, 2020). https://www.cwu.edu/
multimodal-education/virtual-reality-experiences-mec.

[140] “TriMirror.” https://www.trimirror.com/Solutions/InStore, 2021.

[Online; Available].

[141] Charles, Shearer Dorner and Paul, Barnhart Sayre and William, L
Hazlewood, “Blended reality systems and methods,” U.S. Patent 9 858
719, Jan. 2018.

[142] S. Sukhmani, M. Sadeghi, M. Erol-Kantarci, and A. El Saddik, “Edge
caching and computing in 5g for mobile ar/vr and tactile internet,”
IEEE MultiMedia, vol. 26, no. 1, pp. 21–30, 2019.

[143] J. Dai and D. Liu, “An mec-enabled wireless vr transmission system
with view synthesis-based caching,” in 2019 IEEE Wireless Commu-
nications and Networking Conference Workshop (WCNCW), pp. 1–7,
2019.

[144] J. Dai, Z. Zhang, S. Mao, and D. Liu, “A view synthesis-based 360°
vr caching system over mec-enabled c-ran,” IEEE Transactions on
Circuits and Systems for Video Technology, vol. 30, no. 10, pp. 3843–
3855, 2020.

[145] “YouTube at 15: My personal journey and the road ahead.” https:
//blog.youtube/news-and-events/youtube-at-15-my-personal-journey,
2020. [Online; Available].

[146] D. K. Krishnappa, S. Khemmarat, L. Gao, and M. Zink, “On the feasi-
bility of prefetching and caching for online tv services: A measurement
study on hulu,” in Passive and Active Measurement (N. Spring and
G. F. Riley, eds.), (Berlin, Heidelberg), pp. 72–80, Springer Berlin
Heidelberg, 2011.

[147] S. Li, J. Xu, M. van der Schaar, and W. Li, “Popularity-driven content
caching,” in IEEE INFOCOM 2016 - The 35th Annual IEEE Interna-
tional Conference on Computer Communications, pp. 1–9, 2016.
[148] S. M. S. Tanzil, W. Hoiles, and V. Krishnamurthy, “Adaptive scheme
for caching youtube content in a cellular network: Machine learning
approach,” IEEE Access, vol. 5, pp. 5870–5881, 2017.

[149] H. Li, X. Ma, F. Wang, J. Liu, and K. Xu, “On popularity prediction
of videos shared in online social networks,” in Proceedings of the
22nd ACM international conference on Information & Knowledge
Management, pp. 169–178, 2013.

[150] Y. Zhou, L. Chen, C. Yang, and D. M. Chiu, “Video popularity
dynamics and its implication for replication,” IEEE Transactions on
Multimedia, vol. 17, no. 8, pp. 1273–1285, 2015.

[151] Donghee Lee, Jongmoo Choi, Jong-Hun Kim, S. H. Noh, Sang Lyul
Min, Yookun Cho, and Chong Sang Kim, “Lrfu: a spectrum of
policies that subsumes the least recently used and least frequently used
policies,” IEEE Transactions on Computers, vol. 50, no. 12, pp. 1352–
1361, 2001.

[152] Y. Zeng, J. Xie, H. Jiang, G. Huang, S. Yi, N. Xiong, and J. Li,
“Smart caching based on user behavior for mobile edge computing,”
Information Sciences, vol. 503, no. 2019, pp. 444–468, 2019.
[153] A. Gharaibeh, A. Khreishah, B. Ji, and M. Ayyash, “A provably efﬁ-
cient online collaborative caching algorithm for multicell-coordinated
systems,” IEEE Transactions on Mobile Computing, vol. 15, no. 8,
pp. 1863–1876, 2016.

[154] E. Baccour, A. Erbad, A. Mohamed, K. Bilal, and M. Guizani,
“Proactive video chunks caching and processing for latency and cost
minimization in edge networks,” in 2019 IEEE Wireless Communica-
tions and Networking Conference (WCNC), pp. 1–7, 2019.

[155] S. M. S. Tanzil, W. Hoiles, and V. Krishnamurthy, “Adaptive scheme
for caching youtube content in a cellular network: Machine learning
approach,” IEEE Access, vol. 5, pp. 5870–5881, 2017.

[156] K. N. Doan, T. Van Nguyen, T. Q. S. Quek, and H. Shin, “Content-
aware proactive caching for backhaul ofﬂoading in cellular network,”
IEEE Transactions on Wireless Communications, vol. 17, no. 5,
pp. 3128–3140, 2018.

[157] S. He, H. Tian, and X. Lyu, “Edge popularity prediction based on
social-driven propagation dynamics,” IEEE Communications Letters,
vol. 21, no. 5, pp. 1027–1030, 2017.

[158] A. T. Tran, N. N. Dao, and S. Cho, “Bitrate Adaptation for Video
Streaming Services in Edge Caching Systems,” IEEE Access, vol. 8,
pp. 135844–135852, 2020.

[159] Z. Qu, B. Ye, B. Tang, S. Guo, S. Lu, and W. Zhuang, “Cooperative
caching for multiple bitrate videos in small cell edges,” IEEE Trans-
actions on Mobile Computing, vol. 19, no. 2, pp. 288–299, 2020.
[160] Z. Su, Q. Xu, F. Hou, Q. Yang, and Q. Qi, “Edge Caching for Layered
Video Contents in Mobile Social Networks,” IEEE Transactions on
Multimedia, vol. 19, no. 10, pp. 2210–2221, 2017.

[161] L. Vigneri, T. Spyropoulos, and C. Barakat, “Low Cost Video Stream-
ing through Mobile Edge Caching: Modelling and Optimization,” IEEE
Transactions on Mobile Computing, vol. 18, no. 6, pp. 1302–1315,
2019.

[162] C. Zhang, H. Pang, L. Gao, Q. Ding, Y. Yang, and L. Sun, “Incentiviz-
ing mobile video users with data sponsoring and edge caching,” IEEE
Access, vol. 8, pp. 9640–9654, 2020.

[163] Y. Cheng, “Edge caching and computing in 5G for mobile augmented
reality and haptic internet,” Computer Communications, vol. 158,
no. February, pp. 24–31, 2020.

[164] S. Kumar, S. V. Doddala, A. A. Franklin, and J. Jin, “RAN-aware adap-
tive video caching in multi-access edge computing networks,” Journal
of Network and Computer Applications, vol. 168, no. November 2019,
p. 102737, 2020.

[165] L. Li, D. Shi, R. Hou, R. Chen, B. Lin, and M. Pan, “Energy-
efﬁcient proactive caching for adaptive video streaming via data-driven
optimization,” IEEE Internet of Things Journal, vol. 7, no. 6, pp. 5549–
5561, 2020.

[166] Z. Yan, M. Zhao, C. Westphal, and C. W. Chen, “Toward guaranteed
video experience: Service-aware downlink resource allocation in mo-
bile edge networks,” IEEE Transactions on Circuits and Systems for
Video Technology, vol. 29, no. 6, pp. 1819–1831, 2019.

[167] X. Yang, Z. Chen, K. Li, Y. Sun, N. Liu, W. Xie, and Y. Zhao,
“Communication-Constrained Mobile Edge Computing Systems for
Wireless Virtual Reality: Scheduling and Tradeoff,” IEEE Access,
vol. 6, pp. 16665–16677, 2018.

[168] T. X. Tran and D. Pompili, “Adaptive Bitrate Video Caching and
Processing in Mobile-Edge Computing Networks,” IEEE Transactions
on Mobile Computing, vol. 18, no. 9, pp. 1965–1978, 2019.

[169] Q. Tang, R. Xie, T. Huang, and Y. Liu, “Jointly caching and compu-
tation resource allocation for mobile edge networks,” IET Networks,
vol. 8, no. 5, pp. 329–338, 2019.

[170] T. Zhang and S. Mao, “Joint Video Caching and Processing for Multi-
Bitrate Videos in Ultra-dense HetNets,” IEEE Open Journal of the
Communications Society, vol. 1, no. September, pp. 1–1, 2020.
[171] E. Baccour, A. Erbad, K. Bilal, A. Mohamed, and M. Guizani, “PCCP:
Proactive Video Chunks Caching and Processing in edge networks,”
Future Generation Computer Systems, vol. 105, pp. 44–60, 2020.

[172] K. Bilal, E. Baccour, A. Erbad, A. Mohamed, and M. Guizani, “Collab-
orative joint caching and transcoding in mobile edge networks,” Journal
of Network and Computer Applications, vol. 136, no. December 2018,
pp. 86–99, 2019.

[173] N. Zhang, S. Guo, Y. Dong, and D. Liu, “Joint task ofﬂoading and
data caching in mobile edge computing networks,” Computer Networks,
vol. 182, no. January, p. 107446, 2020.

[174] T. Dang and M. Peng, “Joint Radio Communication, Caching, and
Computing Design for Mobile Virtual Reality Delivery in Fog Radio

33

Access Networks,” IEEE Journal on Selected Areas in Communica-
tions, vol. 37, no. 7, pp. 1594–1607, 2019.

[175] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, Caching,
and Computing for Mobile Virtual Reality: Modeling and Tradeoff,”
IEEE Transactions on Communications, vol. 67, no. 11, pp. 7573–7586,
2019.

[176] J. Luo, F. R. Yu, Q. Chen, L. Tang, and Z. Zhang, “Adaptive video
streaming in software-deﬁned mobile networks: A deep reinforcement
learning approach,” 2019 IEEE Global Communications Conference,
GLOBECOM 2019 - Proceedings, vol. 19, no. 3, pp. 1577–1592, 2019.
[177] Z. S. Wang Chenmeng, Feng Daquan and C. Qianbin, “Video Caching
and Transcoding in Wireless Cellular Networks with Mobile Edge
Computing: A Robust Approach,” IEEE Transactions on Vehicular
Technology, vol. 69, no. 8, pp. 9234–9238, 2020.
[178] S. Rezvani, S. Parsaeefard, N. Mokari, M. R.

and
H. Yanikomeroglu, “Delivery-Aware Cooperative Joint Multi-Bitrate
Video Caching and Transcoding in 5G,” pp. 1–53, 2018.

Javan,

[179] Yang, Ruihang and Guo, Songtao, “A Mobile Edge Caching Strategy
for Video Grouping in Vehicular Networks,” in 2021 13th International
Conference on Advanced Computational Intelligence (ICACI), pp. 40–
45, 2021.

[180] W. Jiang, G. Feng, S. Qin, and Y. Liu, “Multi-Agent Reinforcement
Learning Based Cooperative Content Caching for Mobile Edge Net-
works,” IEEE Access, vol. 7, pp. 61856–61867, 2019.

[181] Y. Wang, Y. Zhang, M. Sheng, and K. Guo, “On the interaction of video
caching and retrieving in multi-server mobile-edge computing sys-
tems,” IEEE Wireless Communications Letters, vol. 8, no. 5, pp. 1444–
1447, 2019.

[182] W. C. Chien, H. Y. Weng, and C. F. Lai, “Q-learning based collabo-
rative cache allocation in mobile edge computing,” Future Generation
Computer Systems, vol. 102, pp. 603–610, 2020.

[183] Sang, Zihao and Guo, Songtao and Wang, Ying, “Collaborative Video
Cache Management Strategy in Mobile Edge Computing,” in 2021
IEEE Wireless Communications and Networking Conference (WCNC),
pp. 1–6, 2021.

[184] Taha, Abd-Elhamid M. and Abu Ali, Najah and Chi, Hao Ran and
Radwan, Ayman, “MEC Resource Ofﬂoading for QoE-Aware HAS
Video Streaming,” in ICC 2021 - IEEE International Conference on
Communications, pp. 1–5, 2021.

[185] R. Xie, Z. Li, J. Wu, Q. Jia, and T. Huang, “Energy-efﬁcient joint
caching and transcoding for HTTP adaptive streaming in 5G networks
with mobile edge computing,” China Communications, vol. 16, no. 7,
pp. 229–244, 2019.

[186] Huang, Xinyu and He, Lijun and Wang, Liejun and Li, Fan, “Towards
5G: Joint Optimization of Video Segment Caching, Transcoding and
Resource Allocation for Adaptive Video Streaming in a Multi-access
Edge Computing Network,” IEEE Transactions on Vehicular Technol-
ogy, pp. 1–1, 2021.

[187] Cheng, Qi and Shan, Hangguan and Zhuang, Weihua and Yu, Lu and
Zhang, Zhaoyang and Quek, Tony Q. S., “Design and Analysis of
MEC- and Proactive Caching-based 360 Mobile VR Video Streaming,”
IEEE Transactions on Multimedia, pp. 1–1, 2021.

[188] Liu, Chunyu and Zhang, Heli and Ji, Hong and Li, Xi, “MEC-assisted
ﬂexible transcoding strategy for adaptive bitrate video streaming in
small cell networks,” China Communications, vol. 18, no. 2, pp. 200–
214, 2021.

[189] E. Yaacoub, Z. Dawy, and A. Abu-Dayya, “On real-time video stream-
ing over lte networks with mobile-to-mobile cooperation,” in 2012 19th
International Conference on Telecommunications (ICT), pp. 1–6, 2012.
[190] M. A. Khan, R. Hamila, M. S. Kiranyaz, and M. Gabbouj, “A novel
uav-aided network architecture using wi-ﬁ direct,” IEEE Access, vol. 7,
pp. 67305–67318, 2019.

[191] M. A. Khan, R. Hamila, and M. O. Hasna, “Optimal group formation
in dense wi-ﬁ direct networks for content distribution,” IEEE Access,
vol. 7, pp. 161231–161245, 2019.

[192] Y. Li, L. Sun, and W. Wang, “Exploring device-to-device commu-
nication for mobile cloud computing,” in 2014 IEEE International
Conference on Communications (ICC), pp. 2239–2244, 2014.
[193] L. Pu, X. Chen, J. Xu, and X. Fu, “D2d fogging: An energy-efﬁcient
and incentive-aware task ofﬂoading framework via network-assisted
d2d collaboration,” IEEE Journal on Selected Areas in Communica-
tions, vol. 34, no. 12, pp. 3887–3901, 2016.

[194] W. Hu and G. Cao, “Quality-aware trafﬁc ofﬂoading in wireless
networks,” IEEE Transactions on Mobile Computing, vol. 16, no. 11,
pp. 3182–3195, 2017.

[195] P. Yuan, Y. Cai, X. Huang, S. Tang, and X. Zhao, “Collaboration
improves the capacity of mobile edge computing,” IEEE Internet of
Things Journal, vol. 6, no. 6, pp. 10610–10619, 2019.

[196] Y. He, J. Ren, G. Yu, and Y. Cai, “D2d communications meet
mobile edge computing for enhanced computation capacity in cellular
networks,” IEEE Transactions on Wireless Communications, vol. 18,
no. 3, pp. 1750–1763, 2019.

[197] G. Qiao, S. Leng, and Y. Zhang, “Online learning and optimization for
computation ofﬂoading in d2d edge computing and networks,” Mobile
Networks and Applications, pp. 1–12, 2019.

[198] P. Gope, J. Lee, R.-H. Hsu, and T. Q. Quek, “Anonymous communi-
cations for secure device-to-device-aided fog computing: architecture,
challenges, and solutions,” IEEE Consumer Electronics Magazine,
vol. 8, no. 3, pp. 10–16, 2019.

[199] G. S. Park and H. Song, “Video quality-aware trafﬁc ofﬂoading system
for video streaming services over 5g networks with dual connectivity,”
IEEE Transactions on Vehicular Technology, vol. 68, no. 6, pp. 5928–
5943, 2019.

[200] X. Zhang, H. Lin, M. Chen, B. Kang, and L. Wang, “Mec-enabled
video streaming in device-to-device networks,” IET Communications,
vol. 14, no. 15, pp. 2453–2461, 2020.

[201] J. Kim, T. Kim, M. Hashemi, C. G. Brinton, and D. J. Love, “Joint
optimization of signal design and resource allocation in wireless d2d
edge computing,” arXiv preprint arXiv:2002.11850, 2020.

[202] Y. Li, L. Sun, and W. Wang, “Exploring device-to-device communica-
tion for mobile cloud computing,” 2014 IEEE International Conference
on Communications, ICC 2014, pp. 2239–2244, 2014.

[203] G. Qiao, S. Leng, and Y. Zhang, “Online Learning and Optimization
for Computation Ofﬂoading in D2D Edge Computing and Networks,”
Mobile Networks and Applications, 2019.

[204] Y. He, J. Ren, G. Yu, and Y. Cai, “D2D communications meet
mobile edge computing for enhanced computation capacity in cellular
networks,” IEEE Transactions on Wireless Communications, vol. 18,
no. 3, pp. 1750–1763, 2019.

[205] J. Kim, T. Kim, M. Hashemi, C. G. Brinton, and D. J. Love, “Joint
Optimization of Signal Design and Resource Allocation in Wireless
D2D Edge Computing,” Proceedings - IEEE INFOCOM, vol. 2020-
July, pp. 2086–2095, 2020.

[206] P. Dogga, S. Chakraborty, S. Mitra, and R. Netravali, “Edge-based
transcoding for adaptive live video streaming,” in 2nd {USENIX}
Workshop on Hot Topics in Edge Computing (HotEdge 19), 2019.

[207] Y. Kim, F. Baccelli, and G. De Veciana, “Spatial reuse and fairness of
ad hoc networks with channel-aware csma protocols,” IEEE Transac-
tions on Information Theory, vol. 60, no. 7, pp. 4139–4157, 2014.

[208] N. Naderializadeh and A. S. Avestimehr, “Itlinq: A new approach for
spectrum sharing in device-to-device communication systems,” IEEE
journal on selected areas in communications, vol. 32, no. 6, pp. 1139–
1151, 2014.

[209] S. Goebbels and R. Jennen, “Enhancements in wireless broadband
networks using smart caching an analytical evaluation,” in 2008 IEEE
19th International Symposium on Personal, Indoor and Mobile Radio
Communications, pp. 1–5, IEEE, 2008.

[210] M. Dehghan, A. Seetharam, B. Jiang, T. He, T. Salonidis, J. Kurose,
D. Towsley, and R. Sitaraman, “On the complexity of optimal routing
and content caching in heterogeneous networks,” in 2015 IEEE confer-
ence on computer communications (INFOCOM), pp. 936–944, IEEE,
2015.

[211] N. Golrezaei, P. Mansourifard, A. F. Molisch, and A. G. Dimakis,
“Base-station assisted device-to-device communications for high-
throughput wireless video networks,” IEEE Transactions on Wireless
Communications, vol. 13, no. 7, pp. 3665–3676, 2014.

[212] M. Ji, A. M. Tulino, J. Llorca, and G. Caire, “Order-optimal rate
of caching and coded multicasting with random demands,” IEEE
Transactions on Information Theory, vol. 63, no. 6, pp. 3923–3949,
2017.

[213] X. Wu, S. Tavildar, S. Shakkottai, T. Richardson, J. Li, R. Laroia, and
A. Jovicic, “Flashlinq: A synchronous distributed scheduler for peer-to-
peer ad hoc networks,” IEEE/ACM Transactions on networking, vol. 21,
no. 4, pp. 1215–1228, 2013.

[214] U. Abbasi and H. Elbiaze, “Multimedia streaming using d2d in 5g ultra
dense networks,” in 2018 15th IEEE Annual Consumer Communica-
tions & Networking Conference (CCNC), pp. 1–6, IEEE, 2018.
[215] Q. Ren, J. Chen, B. Chen, and L. Jin, “A video streaming trans-
mission scheme based on frame priority in device-to-device multicast
networks,” IEEE Access, vol. 7, pp. 20187–20198, 2019.

[216] F. Wang, J. Xu, X. Wang, and S. Cui, “Joint ofﬂoading and computing
optimization in wireless powered mobile-edge computing systems,”

34

IEEE Transactions on Wireless Communications, vol. 17, no. 3,
pp. 1784–1797, 2017.

[217] Z. Chkirbene, A. Mohamed, A. Erbad, and M. Guizani, “Smart edge
healthcare data sharing system,” in 2020 International Wireless Com-
munications and Mobile Computing (IWCMC), pp. 577–582, IEEE,
2020.

[218] Z. Chkirbene, A. Erbad, R. Hamila, A. Gouissem, A. Mohamed,
M. Guizani, and M. Hamdi, “A weighted machine learning-based
attacks classiﬁcation to alleviating class imbalance,” IEEE Systems
Journal, 2020.

[219] A. Redondi, L. Barofﬁo, L. Bianchi, M. Cesana, and M. Tagliasacchi,
“Compress-then-analyze versus analyze-then-compress: What is best
in visual sensor networks?,” IEEE Transactions on Mobile Computing,
vol. 15, no. 12, pp. 3000–3013, 2016.

[220] C. W. Chen, “Internet of video things: Next-generation iot with visual
sensors,” IEEE Internet of Things Journal, vol. 7, no. 8, pp. 6676–6685,
2020.

[221] Y. Cao, Z. Xu, P. Qin, and T. Jiang, “Video processing on the edge for

multimedia iot systems,” 2018.

[222] I. E. Olatunji and C. Cheng, “Dynamic threshold for resource tracking
in observed scenes,” in 2018 9th International Conference on Informa-
tion, Intelligence, Systems and Applications (IISA), pp. 1–6, 2018.

[223] A. Alam, I. Ullah, and Y. K. Lee, “Video big data analytics in
the cloud: A reference architecture, survey, opportunities, and open
research issues,” IEEE Access, vol. 8, pp. 152377–152422, 2020.
[224] B. Marr, “Big data: Using smart big data, analytics and metrics to make

better decisions and improve performance,” 2015.

[225] H. Mao, R. Netravali, and M. Alizadeh, “Neural adaptive video

streaming with pensieve,” pp. 197–210, 08 2017.

[226] T. Huang, R.-X. Zhang, C. Zhou, and L. Sun, “Qarc: Video quality
aware rate control for real-time video streaming based on deep rein-
forcement learning,” pp. 1208–1216, 10 2018.

[227] G. Xiao, M. Wu, Q. Shi, Z. Zhou, and X. Chen, “Deepvr: Deep
reinforcement
learning for predictive panoramic video streaming,”
IEEE Transactions on Cognitive Communications and Networking,
vol. PP, pp. 1–1, 09 2019.

[228] W. Wang, R. Lan, J. Gu, A. Huang, H. Shan, and Z. Zhang, “Edge
caching at base stations with device-to-device ofﬂoading,” IEEE Ac-
cess, vol. 5, pp. 6399–6410, 2017.

[229] S. S. Tanzil, W. Hoiles, and V. Krishnamurthy, “Adaptive scheme
for caching youtube content in a cellular network: Machine learning
approach,” Ieee Access, vol. 5, pp. 5870–5881, 2017.

[230] H. Zhu, Y. Cao, W. Wang, T. Jiang, and S. Jin, “Deep reinforcement
learning for mobile edge caching: Review, new features, and open
issues,” IEEE Network, vol. 32, no. 6, pp. 50–57, 2018.

[231] L. T. Tan and R. Q. Hu, “Mobility-aware edge caching and computing
in vehicle networks: A deep reinforcement learning,” IEEE Transac-
tions on Vehicular Technology, vol. 67, no. 11, pp. 10190–10203, 2018.
[232] C. Zhang, H. Pang, J. Liu, S. Tang, R. Zhang, D. Wang, and L. Sun,
“Toward edge-assisted video content
intelligent caching with long
short-term memory learning,” IEEE access, vol. 7, pp. 152832–152846,
2019.

[233] Y. Wei, F. R. Yu, M. Song, and Z. Han, “Joint optimization of caching,
computing, and radio resources for fog-enabled iot using natural actor–
critic deep reinforcement learning,” IEEE Internet of Things Journal,
vol. 6, no. 2, pp. 2061–2073, 2018.

[234] L. Huang, X. Feng, C. Zhang, L. Qian, and Y. Wu, “Deep reinforcement
learning-based joint task ofﬂoading and bandwidth allocation for multi-
user mobile edge computing,” Digital Communications and Networks,
vol. 5, no. 1, pp. 10–17, 2019.

[235] M. D. F. De Grazia, D. Zucchetto, A. Testolin, A. Zanella, M. Zorzi,
and M. Zorzi, “Qoe multi-stage machine learning for dynamic video
streaming,” IEEE Transactions on Cognitive Communications and
Networking, vol. 4, no. 1, pp. 146–161, 2017.

[236] F. Wang, C. Zhang, J. Liu, Y. Zhu, H. Pang, L. Sun, et al., “Intelligent
edge-assisted crowdcast with deep reinforcement learning for person-
alized qoe,” in IEEE INFOCOM 2019-IEEE Conference on Computer
Communications, pp. 910–918, IEEE, 2019.

[237] Yang, Wanting and Chi, Xuefen and Zhao, Linlin and Xiong, Zehui,
“QoE-based MEC-assisted Predictive Adaptive Video Streaming for
On-road Driving Scenarios,” IEEE Wireless Communications Letters,
pp. 1–1, 2021.

[238] J. Ren, Y. Guo, D. Zhang, Q. Liu, and Y. Zhang, “Distributed and
efﬁcient object detection in edge computing: Challenges and solutions,”
IEEE Network, vol. 32, no. 6, pp. 137–143, 2018.

[239] C. Liu, Y. Cao, Y. Luo, G. Chen, V. Vokkarane, M. Yunsheng, S. Chen,
and P. Hou, “A new deep learning-based food recognition system for
dietary assessment on an edge computing service infrastructure,” IEEE
Transactions on Services Computing, vol. 11, no. 2, pp. 249–261, 2017.
[240] X. Ran, H. Chen, X. Zhu, Z. Liu, and J. Chen, “Deepdecision: A mobile
deep learning framework for edge video analytics,” in IEEE INFOCOM
2018-IEEE Conference on Computer Communications, pp. 1421–1429,
IEEE, 2018.

[241] D. Li, T. Salonidis, N. V. Desai, and M. C. Chuah, “Deepcham:
Collaborative edge-mediated adaptive deep learning for mobile object
recognition,” in 2016 IEEE/ACM Symposium on Edge Computing
(SEC), pp. 64–76, IEEE, 2016.

[242] S. Y. Nikouei, Y. Chen, S. Song, R. Xu, B.-Y. Choi, and T. Faughnan,
“Smart surveillance as an edge network service: From harr-cascade,
svm to a lightweight cnn,” in 2018 ieee 4th international conference
on collaboration and internet computing (cic), pp. 256–265, IEEE,
2018.

[243] Y. Wang, Y. Dong, S. Guo, Y. Yang, and X. Liao, “Latency-Aware
Adaptive Video Summarization for Mobile Edge Clouds,” IEEE Trans-
actions on Multimedia, vol. 22, no. 5, pp. 1193–1207, 2020.
[244] Galanopoulos, Apostolos and Ayala-Romero, Jose A. and Leith, Dou-
glas J. and Iosiﬁdis, George, “AutoML for Video Analytics with
Edge Computing,” in IEEE INFOCOM 2021 - IEEE Conference on
Computer Communications, pp. 1–10, 2021.

[245] Harper, F. Maxwell and Konstan, Joseph A., “The MovieLens Datasets:
History and Context,” ACM Trans. Interact. Intell. Syst., vol. 5, Dec.
2015.

[246] E. Baccour, A. Erbad, A. Mohamed, M. Guizani, and M. Hamdi, “Ce-
d2d: Collaborative and popularity-aware proactive chunks caching in
edge networks,” in 2020 International Wireless Communications and
Mobile Computing (IWCMC), pp. 1770–1776, 2020.

[247] E. Baccour, A. Erbad, K. Bilal, A. Mohamed, and M. Guizani, “Pccp:
Proactive video chunks caching and processing in edge networks,”
Future Generation Computer Systems, vol. 105, pp. 44 – 60, 2020.

[248] Redmon, Joseph and Farhadi, Ali, “YOLO9000: Better, Faster,
Stronger,” in 2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 6517–6525, 2017.

[249] X. Hou, S. Dey, J. Zhang, and M. Budagavi, “Predictive view genera-
tion to enable mobile 360-degree and vr experiences,” in Proceedings of
the 2018 Morning Workshop on Virtual Reality and Augmented Reality
Network, pp. 20–26, 2018.

[250] Y. Xu, Y. Dong, J. Wu, Z. Sun, Z. Shi, J. Yu, and S. Gao, “Gaze
prediction in dynamic 360 immersive videos,” in proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 5333–5342, 2018.

[251] S. Afzal, J. Chen, and K. Ramakrishnan, “Characterization of 360-
degree videos,” in Proceedings of the Workshop on Virtual Reality and
Augmented Reality Network, pp. 1–6, 2017.

[252] K. Ha, Z. Chen, W. Hu, W. Richter, P. Pillai, and M. Satyanarayanan,
“Towards wearable cognitive assistance,” in Proceedings of the 12th
annual international conference on Mobile systems, applications, and
services, pp. 68–81, 2014.

[253] E. Baccour, A. Erbad, K. Bilal, A. Mohamed, M. Guizani, and
M. Hamdi, “Facebookvideolive18: A live video streaming dataset for
streams metadata and online viewers locations,” in 2020 IEEE Inter-
national Conference on Informatics, IoT, and Enabling Technologies
(ICIoT), pp. 476–483, 2020.

[254] Google Research, YouTube-8M Segments Dataset [Online], Last ac-

cessed November 03, 2020. http://research.google.com/youtube8m/.

[255] K. Pires and G. Simon, “Youtube live and twitch: A tour of user-
generated live streaming systems,” in Proceedings of the 6th ACM
Multimedia Systems Conference, MMSys ’15, (New York, NY, USA),
p. 225–230, Association for Computing Machinery, 2015.

[256] C. Wu, Z. Tan, Z. Wang, and S. Yang, “A dataset for exploring user
behaviors in vr spherical video streaming,” in Proceedings of the 8th
International Conference on Multimedia Systems, MMSys ’17, (Taipei,
Taiwan), ACM, 2017.

[257] A. T. Nasrabadi, A. Samiei, A. Mahzari, R. P. McMahan, R. Prakash,
M. C. Q. Farias, and M. M. Carvalho, “A taxonomy and dataset for 360°
videos,” MMSys ’19, (New York, NY, USA), p. 273–278, Association
for Computing Machinery, 2019.

[258] D. Ghadiyaram, J. Pan, and A. C. Bovik, “A subjective and objective
study of stalling events in mobile streaming videos,” IEEE Transactions
on Circuits and Systems for Video Technology, vol. 29, no. 1, pp. 183–
197, 2019.

[259] F. Loh, F. Wamser, C. Moldovan, B. Zeidler, T. Hoßfeld, D. Tsiliman-
tos, and S. Valentin, “From click to playback: A dataset to study the

35

response time of mobile youtube,” in Proceedings of the 10th ACM
Multimedia Systems Conference, MMSys ’19, (New York, NY, USA),
p. 267–272, Association for Computing Machinery, 2019.

[260] D. Raca, D. Leahy, C. J. Sreenan, and J. J. Quinlan, “Beyond
throughput, the next generation: A 5g dataset with channel and context
metrics,” in Proceedings of the 11th ACM Multimedia Systems Con-
ference, MMSys ’20, (New York, NY, USA), p. 303–308, Association
for Computing Machinery, 2020.

[261] A. Mercat, M. Viitanen, and J. Vanne, “Uvg dataset: 50/120fps 4k
sequences for video codec analysis and development,” in Proceedings
of the 11th ACM Multimedia Systems Conference, MMSys ’20, (New
York, NY, USA), p. 297–302, Association for Computing Machinery,
2020.

[262] C. G. Bampis, Z. Li, I. Katsavounidis, T.-Y. Huang, C. Ekanadham,
and A. Bovik, “Towards perceptually optimized end-to-end adaptive
video streaming.,” arXiv: Image and Video Processing, 2018.
[263] L. Liu, H. Li, and M. Gruteser, “Edge assisted real-time object
detection for mobile augmented reality,” MobiCom ’19, Association
for Computing Machinery, 2019.

[264] K. Boos, D. Chu, and E. Cuervo, “Flashback: Immersive virtual
reality on mobile devices via rendering memoization,” MobiSys ’16,
p. 291–304, Association for Computing Machinery, 2016.

[265] T. S. Rappaport, Y. Xing, O. Kanhere, S. Ju, A. Madanayake, S. Man-
dal, A. Alkhateeb, and G. C. Trichopoulos, “Wireless communications
and applications above 100 ghz: Opportunities and challenges for 6g
and beyond,” IEEE Access, vol. 7, pp. 78729–78757, 2019.

[266] K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y.-J. A. Zhang, “The
roadmap to 6g: Ai empowered wireless networks,” IEEE Communica-
tions Magazine, vol. 57, no. 8, pp. 84–90, 2019.

[267] Adrian Pennington, 5G’s Future Is Broken. Here’s Why We Need 6G
[Online], 2020 (accessed September 14, 2021). https://www.streamin
gmedia.com/Articles/Editorial/Featured-Articles/5Gs-Future-Is-Brok
en.-Heres-Why-We-Need-6G-143474.aspx?utm source=related artic
les&utm medium=gutenberg&utm campaign=editors selection.
[268] S. Wijethilaka and M. Liyanage, “Survey on network slicing for internet
of things realization in 5g networks,” IEEE Communications Surveys
Tutorials, vol. 23, no. 2, pp. 957–994, 2021.

[269] E. Baccour, N. Mhaisen, A. A. Abdellatif, A. Erbad, A. Mo-
hamed, M. Hamdi, and M. Guizani, “Pervasive AI for iot appli-
cations: Resource-efﬁcient distributed artiﬁcial intelligence,” CoRR,
vol. abs/2105.01798, 2021.

[270] J. Wang, Z. Feng, Z. Chen, S. A. George, M. Bala, P. Pillai, S.-W.
Yang, and M. Satyanarayanan, “Edge-based live video analytics for
drones,” IEEE Internet Computing, vol. 23, no. 4, pp. 27–34, 2019.

[271] C. V. Forecast, “Cisco visual networking index: Global mobile data

trafﬁc forecast update,” white paper, 2017.

[272] R. Yang, F. R. Yu, P. Si, Z. Yang, and Y. Zhang, “Integrated blockchain
and edge computing systems: A survey, some research issues and
challenges,” IEEE Communications Surveys Tutorials, vol. 21, no. 2,
pp. 1508–1532, 2019.

Muhammad Asif Khan (SM’20) received the B.Sc.
degree in Telecommunication Engineering from Uni-
versity of Engineering and Technology Peshawar,
Pakistan (2009) and M.Sc. in Telecommunication
Engineering from University of Engineering and
Technology Taxila, Pakistan (2013). He received the
Ph.D. degree in Electrical Engineering from Qatar
University in 2020. He was a Researcher Assistant
at Qatar University (2014-2015) and at Qatar Mobil-
ity Innovation Center (2016-2017). He is currently
working as a postdoctoral researcher at Qatar Uni-
versity. His current research interests include wireless communication, mobile
edge computing, machine learning and distributed optimization. He is a Senior
Member of IEEE and a Member of IET. For more detailed information, please
visit his homepage: http://www.asifk.me.

36

Prof. Ridha Hamila received the MSc, LicTech
with distinction, and PhD degrees from Tampere
University, Tampere, Finland, in 1996, 1999, and
2002, respectively. Dr. Hamila currently a Full Pro-
fessor at the Department of Electrical Engineering,
Qatar University, Qatar. From 1994 to 2002 he
held various research and teaching positions at TUT
within the Department of Information Technology,
Finland. From 2002 to 2003 he was a System
Specialist at Nokia research Center and Nokia Net-
works, Helsinki. From 2004 to 2009 he was with
Emirates Telecommunications Corporation, UAE. Also, from 2004 to 2013
he was adjunct Professor at the Department of Communications Engineering,
TUT. His current research interests include mobile and broadband wireless
communication systems, Mobile Edge Computing, Internet of Everything,
and Machine Learning. In these areas, he has published over 200 journal
and conference papers most of them in the peered reviewed IEEE publi-
cations, ﬁled seven US patents, and wrote numerous conﬁdential industrial
research reports. Dr. Hamila has been involved in several past and current
industrial projects, Ooreedo, Qatar National Research Fund, Finnish Academy
projects, EU research and education programs. He supervised a large number
of under/graduate students and postdoctoral fellows. He organized many
international workshops and conferences. He is a Senior Member of IEEE.

Prof. Mounir Hamdi is the founding Dean of the
College of Science and Engineering at Hamad Bin
Khalifa University (HBKU). He is an IEEE Fellow
for contributions to design and analysis of high-
speed packet switching. As founding Dean of the
College of Science and Engineering, Dr. Hamdi led
the foundation of 15 graduate programs and 1 un-
dergraduate program and all the associated research
labs and activities. Before joining HBKU, he was
Chair Professor at the Hong Kong University of
Science and Technology (HKUST), and the Head
of the Department of Computer Science and Engineering. In 1999 to 2000
he held visiting professor positions at Stanford University, USA, and the
Swiss Federal Institute of Technology, Lausanne, Switzerland. His general
area of research is in high-speed wired/wireless networking in which he has
published more than 400 research publications, received numerous research
grants, and graduated more 50 MS/PhD students. Prof. Hamdi is/was on the
Editorial Board of various prestigious journals and magazines including IEEE
Transactions on Communications, IEEE Communication Magazine, Computer
Networks, Wireless Communications and Mobile Computing, and Parallel
Computing. In addition to his commitment
to research and professional
service, he is also frequently involved in higher education quality assurance
activities as well as engineering programs accreditation all over the world.

Aiman Erbad (Senior Member, IEEE) received the
MSc degree from the University of Essex (2005),
and the Ph.D degree from the University of British
Columbia (2012). He is currently an Associate Pro-
fessor with the College of Science and Engineer-
ing, Hamad Bin Khalifa University (HBKU). His
research interests include cloud computing, edge
computing, the IoT, private and secure networks,
and multimedia systems. He received the Platinum
award from H. H. Emir Sheikh Tamim bin Hamad
Al Thani at the Education Excellence Day 2013
(Ph.D. category). He also received the 2020 Best Research Paper Award
from Computer Communications, the IWCMC 2019 Best Paper Award, and
the IEEE CCWC 2017 Best Paper Award. His research interest spans cloud
computing, edge computing, IoT, distributed AI algorithms, and private /
secure networks. Aiman is currently an editor in the International Journal
of Sensor Networks (IJSNet), an editor in KSII Transactions on Internet and
Information Systems, and served as a guest editor in IEEE Networks.

Prof. Moncef Gabbouj (F’11) is a well-established
world expert in the ﬁeld of image processing, and
held the prestigious post of Academy of Finland
Professor during 2011-2015. He has been leading
the Multimedia Research Group for nearly 25 years
and managed successfully a large number of projects
in excess of 18M Euro. He has supervised 45 PhD
theses and over 50 MSc theses. He is the author
of several books and over 700 papers. His research
interests include Big Data analytics, multimedia
content-based analysis, indexing and retrieval, artiﬁ-
cial intelligence, machine learning, pattern recognition, nonlinear signal and
image processing and analysis, voice conversion, and video processing and
coding. Dr. Gabbouj is a Fellow of the IEEE and member of the Academia
Europaea and the Finnish Academy of Science and Letters. He is the past
Chairman of the IEEE CAS TC on DSP and committee member of the IEEE
Fourier Award for Signal Processing. He served as associate editor and guest
editor of many IEEE, and international journals.

Emna Baccour received the Ph.D. degree in com-
puter Science from the University of Burgundy,
France, in 2017. She was a postdoctoral fellow at
Qatar University on a project covering the intercon-
nection networks for massive data centers and then
on a project covering video caching and processing
in mobile edge computing networks. She currently
holds a postdoctoral position at Hamad Ben Khalifa
University. Her research interests include data center
networks, cloud computing, green computing and
software deﬁned networks as well as distributed
systems. She is also interested in edge networks, mobile edge caching and
computing, and IoT systems.

Zina Chkirbene received her Ph.D. in Computer
science in 2017 from the University of Burgundy
Dijon, France. She received her Bachelor’s degree
in Computer Science Networks and Telecommunica-
tions from the National Institute of Applied Science
and Technology, in 2011, and received her master’s
degree in Electronic Systems and Communication
Networks from Polytechnic School, in 2012. She
was a Research Assistant at Qatar University on
a project covering the interconnection networks for
massive data centers. She currently holds a postdoc-
toral position at Qatar University. Her research interests include data center
networks, edge computing, green computing, and machine learning as well
as deep reinforcement learning techniques.

