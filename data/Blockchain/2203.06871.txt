Block-STMâˆ—
Scaling Blockchain Execution by Turning Ordering Curse to a Performance Blessing

Rati Gelashvili
Aptos

Alexander Spiegelman
Aptos

George Danezis
Mysten Labs & UCL

Zekun Li
Aptos

Zhuolun Xiang
Aptos

Dahlia Malkhi
Chainlink Labs

2
2
0
2

g
u
A
5
2

]

C
D
.
s
c
[

3
v
1
7
8
6
0
.
3
0
2
2
:
v
i
X
r
a

Yu Xia
MIT

Abstract

Block-STM is a parallel execution engine for smart contracts,
built around the principles of Software Transactional Memory.
Transactions are grouped in blocks, and every execution of the block
must yield the same deterministic outcome. Block-STM further en-
forces that the outcome is consistent with executing transactions
according to a preset order, leveraging this order to dynamically
detect dependencies and avoid conflicts during speculative transac-
tion execution. At the core of Block-STM is a novel, low-overhead
collaborative scheduler of execution and validation tasks.

Block-STM is implemented on the main branch of the Diem
Blockchain code-base and runs in production at Aptos. Our evalua-
tion demonstrates that Block-STM is adaptive to workloads with
different conflict rates and utilizes the inherent parallelism therein.
Block-STM achieves up to 110ğ‘˜ tps in the Diem benchmarks and
up to 170ğ‘˜ tps in the Aptos Benchmarks, which is a 20x and 17x
improvement over the sequential baseline with 32 threads, respec-
tively. The throughput on a contended workload is up to 50ğ‘˜ tps
and 80ğ‘˜ tps in Diem and Aptos benchmarks, respectively.

1 Introduction
A central challenge facing emerging decentralized web3 plat-
forms and applications is improving the throughput of the
underlying Blockchain systems. At the core of a Blockchain
system is state machine replication, allowing a set of entities
to agree on and apply a sequence of blocks of transactions.
Each transaction contains smart contract code to be executed,
and every entity that executes the block of transactions must
arrive at the same final state. While there has been progress
on scaling parts of the system, Blockchains are still bottle-
necked by other components, such as transaction execution.
Our goal is to accelerate the in-memory execution of trans-
actions via parallelism. Transactions that access different
memory locations can always be executed in parallel. How-
ever, in a Blockchain system transactions can have significant
number of access conflicts. This may happen due to potential

âˆ—Rati Gelashvili, Alexander Spiegelman, and Zhuolun Xiang share first
authorship. Contact emails: gelash@aptoslabs.com, sasha.spiegelman@
gmail.com, xiangzhuolun@gmail.com. The work was initiated while all
authors were working at Novi at Meta.

Runtian Zhou
Aptos

performance attacks, accessing popular contracts or due to
economic opportunities (such as auctions and arbitrage [16]).
Conflicts are the main challenge for performance. An ap-
proach pioneered by Software Transactional Memory (STM)
libraries [29, 44] is to instrument memory accesses to de-
tect conflicts. STM libraries with optimistic concurrency
control [17] (OCC) record memory accesses, validate every
transaction post execution, and abort and re-execute transac-
tions when validation surfaces a conflict. The final outcome
is equivalent to executing transactions sequentially in some
order. This equivalent order is called serialization.

Prior works [5, 8, 18] have capitalized on the specifics
of the Blockchain use-case to improve on the STM perfor-
mance. Their approach is to pre-compute dependencies in
a form of a directed acyclic graph of transactions that can
be executed via a fork-join schedule. The resulting schedule
is dependency-aware, and avoids corresponding conflicts.
If entities are incentivized to record and share the depen-
dency graph, then some entities may be able to avoid the
pre-computation overhead.

In the context of deterministic databases, Bohm [21] demon-
strated a way to avoid pre-computing the dependency graph.
Bohm assumes that the write-sets of all transactions are
known prior to execution, and enforces a specific preset
serialization of transactions. As a result, each read is asso-
ciated with the last write preceding it in that order. Using
a multi-version data-structure [10], Bohm executes transac-
tions when their read dependencies are resolved, avoiding
corresponding conflicts.

Our contribution. We present Block-STM, an in-memory
smart contract parallel execution engine built around the
principles of optimistically controlled STM. Block-STM does
not require a priori knowledge of transaction write-sets,
avoids pre-computation, and accelerates transaction execu-
tion autonomously without requiring further communica-
tion. Similar to Bohm, Block-STM uses multi-version shared
data-structure and enforces a preset serialization. The final
outcome is equivalent to the sequential execution of transac-
tions in the preset order in which they appear in the block.

 
 
 
 
 
 
The key observation is that with OCC and a preset serial-
ization, when a transaction aborts, its write-set can be used
to efficiently detect future dependencies. This has two ad-
vantages with respect to pre-execution: (1) in the optimistic
case when there are few conflicts, most transactions are ex-
ecuted once, (2) otherwise, write-sets are likely to be more
accurate as they are based on a more up-to-date execution.
Anther advantage of the of the preset order is that it allows
as comprehensive correctness testing as we can compare to
a sequential execution output.

Two observations that contribute to the performance of
Block-STM in the Blockchain context are the following. First,
in blockchain systems, the state is updated per block. This
allows the Block-STM to avoid the synchronization cost
of committing transactions individually. Instead Block-STM
lazily commits all transactions in a block based on two atomic
counters and a double-collect technique [9]. Second, trans-
actions are specified in smart contract languages, such as
Move [11] and Solidity [51], and run in a virtual machine
that encapsulates their execution and ensures safe behavior.
Therefore, opacity [24] is not required, allowing Block-STM
to efficiently combine an optimistic concurrent control with
multi-version data structure, without additional mechanisms
to avoid reaching inconsistent states.

The main challenge in combining OCC and preset serial-
ization is that validations are no longer independent from
each other and must logically occur in a sequence. A failed
validation of a transaction implies that all higher transac-
tions can be committed only if they get successfully validated
afterwards. Block-STM handles this issue via a novel collabo-
rative scheduler that optimistically dispatches execution and
validation tasks, prioritizing tasks for transactions lower in
the preset order. While concurrent priority queues are noto-
riously hard to scale across threads [4, 40], Block-STM capi-
talizes on the preset serialization order and the boundedness
of transaction indices to implement a concurrent ordered set
abstraction using only a few shared atomic counters.

We provide comprehensive correctness proofs for both
Safety and Liveness, proving that no deadlock or livelock is
possible and the final state is always equivalent to the state
produced by executing the transactions sequentially.

A Rust implementation of Block-STM is merged on the
main branches of the Diem [47] and its successor Aptos [2]
open source blockchain code-bases [1, 3]. The experimental
evaluation demonstrates that Block-STM outperforms se-
quential execution by up to 20x on low-contention workloads
and by up to 9x on high-contention ones. Importantly, Block-
STM suffers from at most 30% overhead when the workload is
completely sequential. In addition, Block-STM significantly
outperforms a state-of-the-art deterministic STM [52] im-
plementation, and performances closely to Bohm which re-
quires perfect write-sets information prior to execution.

The rest of the paper is organized as following: Section 2
provides a high-level overview of Block-STM. Section 3 de-
scribes the full algorithm, while Section 4 describes Block-
STM implementation and evaluation. Section 5 discusses
related work and Section 6 concludes the paper. Appendix A
contains the comprehensive correctness proofs.

2 Overview
The input of Block-STM is a block of transactions, denoted
by BLOCK, containing ğ‘› transactions, which defines the pre-
set serialization order ğ‘¡ğ‘¥1 < ğ‘¡ğ‘¥2 < ... < ğ‘¡ğ‘¥ğ‘›. The problem
definition is to execute the block and produce the final state
equivalent to the state produced by executing the transac-
tions in sequence ğ‘¡ğ‘¥1, ğ‘¡ğ‘¥2, . . .ğ‘¡ğ‘¥ğ‘›, each ğ‘¡ğ‘¥ ğ‘— executed to com-
pletion before ğ‘¡ğ‘¥ ğ‘—+1 is started. The goal is to utilize available
threads to produce such final state as efficiently as possible.
Each transaction in Block-STM might be executed several
times and we refer to the ğ‘–ğ‘¡â„ execution as incarnation ğ‘– of a
transaction. We say that an incarnation is aborted when the
system decides that a subsequent re-execution with an incre-
mented incarnation number is needed. A version is a pair of
a transaction index and an incarnation number. To support
reads and writes by transactions that may execute concur-
rently, Block-STM maintains an in-memory multi-version
data structure that separately stores for each memory loca-
tion the latest value written per transaction, along with the
associated transaction version. When transaction ğ‘¡ğ‘¥ reads
a memory location, it obtains from the multi-version data-
structure the value written to this location by the highest
transaction that appears before ğ‘¡ğ‘¥ in the preset serializa-
tion order, along with the associated version. For example,
transaction ğ‘¡ğ‘¥5 can read a value written by transaction ğ‘¡ğ‘¥3
even if transaction ğ‘¡ğ‘¥6 has written to same location. If no
smaller transaction has written to a location, then the read
(e.g. all reads by ğ‘¡ğ‘¥1) is resolved from storage based on the
state before the block execution.

For each incarnation, Block-STM maintains a write-set
and a read-set. The read-set contains the memory locations
that are read during the incarnation, and the corresponding
versions. The write-set describes the updates made by the
incarnation as (memory location, value) pairs. The write-set
of the incarnation is applied to shared memory (the multi-
version data-structure) at the end of execution. After an in-
carnation executes it needs to pass validation. The validation
re-reads the read-set and compares the observed versions.
Intuitively, a successful validation implies that writes ap-
plied by the incarnation are still up-to-date, while a failed
validation implies that the incarnation has to be aborted.

Dependency estimation. Block-STM does not pre-compute

dependencies. Instead, for each transaction, Block-STM treats
the write-set of an aborted incarnation as an estimation of
the write-set of the next one. Together with the multi-version
data structure and the preset order it allows reducing the

2

Check done: if ğ‘‰ and ğ¸ are empty and no other thread is performing a task, then return.
Find next task: Perform the task with the smallest transaction index ğ‘¡ğ‘¥ in ğ‘‰ and ğ¸:

1. Execution task: Execute the next incarnation of ğ‘¡ğ‘¥. If a value marked as estimate is read, abort execution and add ğ‘¡ğ‘¥ back to ğ¸. Otherwise:

(a) If there is a write to a memory location to which the previous finished incarnation of ğ‘¡ğ‘¥ has not written, create validation tasks for all transactions

â‰¥ ğ‘¡ğ‘¥ that are not currently in ğ¸ or being executed and add them to ğ‘‰ .

(b) Otherwise, create a validation task only for ğ‘¡ğ‘¥ and add it to ğ‘‰ .

2. Validation task: Validate the last incarnation of ğ‘¡ğ‘¥. If validation succeeds, continue. Otherwise, abort:

(a) Mark every value (in the multi-versioned data-structure) written by the incarnation (that failed validation) as an estimate.
(b) Create validation tasks for all transactions > ğ‘¡ğ‘¥ that are not currently in ğ¸ or being executed and add them to ğ‘‰ .
(c) Create an execution task for transaction ğ‘¡ğ‘¥ with an incremented incarnation number, and add it to ğ¸.

Figure 1. High level scheduling

Illustration of an example execution of the abstract Block-STM collaborative scheduler.
Initially, all transactions are in the ordered set ğ¸. In this example, transaction ğ‘¡ğ‘¥4 depends on ğ‘¡ğ‘¥2. In stage 1, since there are no validation tasks, the threads
execute transactions ğ‘¡ğ‘¥1, ğ‘¡ğ‘¥2, ğ‘¡ğ‘¥3 in parallel. Then, in stage 2, the threads validate transactions ğ‘¡ğ‘¥1, ğ‘¡ğ‘¥2, ğ‘¡ğ‘¥3 in parallel, the validation of ğ‘¡ğ‘¥2 fails and the
validations of ğ‘¡ğ‘¥1 and ğ‘¡ğ‘¥3 succeed. The incarnation of ğ‘¡ğ‘¥2 is aborted, each of its writes is marked as an estimate in the multi-version data-structure, the next
incarnation task is added to ğ¸, and a new validation task for ğ‘¡ğ‘¥3 is added to ğ‘‰ . In stage 3, transaction ğ‘¡ğ‘¥3 is validated and transactions ğ‘¡ğ‘¥2 and ğ‘¡ğ‘¥4 start
executing their respective incarnations. However, the execution of ğ‘¡ğ‘¥4 reads a value marked as estimate, is aborted due to the dependency on ğ‘¡ğ‘¥2 and the
thread executes the next transaction in ğ¸, which is ğ‘¡ğ‘¥5. As explained above, ğ‘¡ğ‘¥4 is recorded as a dependency of ğ‘¡ğ‘¥2 and added back to ğ¸ when ğ‘¡ğ‘¥2â€™s
incarnation finishes. After both ğ‘¡ğ‘¥2 and ğ‘¡ğ‘¥5 finish execution, the corresponding validation tasks are added to ğ‘‰ . In this example, the incarnation of ğ‘¡ğ‘¥2 does
not write to a memory location to which its previous incarnation did not write. Therefore, another validation of ğ‘¡ğ‘¥3 is not required. In stage 4, ğ‘¡ğ‘¥2 and ğ‘¡ğ‘¥5 are
successfully validated and ğ‘¡ğ‘¥4 is executed. From this point on, ğ‘¡ğ‘¥1, ğ‘¡ğ‘¥2, and ğ‘¡ğ‘¥3 will never be re-executed as there is no task associated with them in ğ‘‰ or ğ¸
(and no task associated with a higher transaction may lead to creating it). The execution of ğ‘¡ğ‘¥4 writes to a new memory location, and thus ğ‘¡ğ‘¥5 is added to ğ‘‰
for re-validation. In stage 5, transactions ğ‘¡ğ‘¥4 and ğ‘¡ğ‘¥5 are validated and transaction ğ‘¡ğ‘¥6 is executed.

abort rate by efficiently detecting potential dependencies.
When an incarnation is aborted due to a validation failure,
the entries in the multi-version data-structure corresponding
to its write-set are replaced with a special estimate marker.
This signifies that the next incarnation is estimated to write
to the same memory location. In particular, an incarnation of
transaction ğ‘¡ğ‘¥ ğ‘— stops and is immediately aborted whenever
it reads a value marked as an estimate that was written by
a lower transaction ğ‘¡ğ‘¥ğ‘˜ . This is an optimization to abort an
incarnation early when it is likely to be aborted in the future
due to a validation failure, which would happen if the next
incarnation of ğ‘¡ğ‘¥ğ‘˜ would indeed write to the same location
(the ESTIMATE markers that are not overwritten are removed
by the next incarnation).

Collaborative scheduler. Block-STM introduces a col-
laborative scheduler, which coordinates the validation and
execution tasks among threads. The preset serialization order
dictates that the transactions must be committed in order, so
a successful validation of an incarnation does not guarantee

that it can be committed. This is because an abort and re-
execution of an earlier transaction in the block might invali-
date the incarnation read-set and necessitate re-execution.
Thus, when a transaction aborts, all higher transactions are
scheduled for re-validation. The same incarnation may be
validated multiple times, by different threads, and potentially
in parallel, but Block-STM ensures that only the first abort
per version succeeds (the rest are ignored).

Since transactions must be committed in order, the Block-
STM scheduler prioritizes tasks (validation and execution) as-
sociated with lower-indexed transactions. Next, we overview
the high-level ideas behind the approach. The detailed logic
is described in Section 3 and formally proved in Appendix A.
Abstractly, the Block-STM collaborative scheduler tracks
an ordered set ğ‘‰ of pending validation tasks and an ordered
set ğ¸ of pending execution tasks. Initially, ğ‘‰ is empty and
ğ¸ contains execution tasks for the initial incarnation of all
transactions in the block. A transaction ğ‘¡ğ‘¥ âˆ‰ ğ¸ is either
currently being executed or (its last incarnation) has com-
pleted. On a high level, each thread repeats the instructions
described in Figure 1.

3

When a transaction ğ‘¡ğ‘¥ğ‘˜ reads an ESTIMATE marker written
by ğ‘¡ğ‘¥ ğ‘— (with ğ‘— < ğ‘˜), we say that ğ‘¡ğ‘¥ğ‘˜ encounters a dependency.
We treat ğ‘¡ğ‘¥ğ‘˜ as ğ‘¡ğ‘¥ ğ‘— â€™s dependency because its read depends
on a value that ğ‘¡ğ‘¥ ğ‘— is estimated to write. For the ease of
presentation, in the above description a transaction is added
back to ğ¸ immediately upon encountering a dependency.
However, as explained in Section 3, Block-STM implements
a slightly more involved mechanism. Transaction ğ‘¡ğ‘¥ğ‘˜ is first
recorded separately as a dependency of ğ‘¡ğ‘¥ ğ‘— , and only added
back to ğ¸ when the next incarnation of ğ‘¡ğ‘¥ ğ‘— completes (i.e.
when the dependency is resolved).

The ordered sets, ğ‘‰ and ğ¸, are each implemented via a
single atomic counter coupled with a mechanism to track
the status of transactions, i.e. whether a given transaction
is ready for validation or execution, respectively. To pick a
task, threads increment the smaller of these counters until
they find a task that is ready to be performed. To add a
(validation or execution) task for transaction ğ‘¡ğ‘¥, the thread
updates the status and reduces the corresponding counter
to ğ‘¡ğ‘¥ (if it had a larger value). For presentation purposes,
the above description omits an optimization that the Block-
STM scheduler uses in cases 1(b) and 2(c), where instead of
reducing the counter value, the new task is returned.

Optimistic validation. An incarnation of transaction
might write to a memory location that was previously read
by an incarnation of a higher transaction according to the
preset serialization order. This is why in 1(a), when an incar-
nation finishes, new validation tasks are created for higher
transactions. Importantly, validation tasks are scheduled op-
timistically, e.g. it is possible to concurrently validate the
latest incarnations of transactions ğ‘¡ğ‘¥ ğ‘— , ğ‘¡ğ‘¥ ğ‘—+1, ğ‘¡ğ‘¥ ğ‘—+2 and ğ‘¡ğ‘¥ ğ‘—+4.
Suppose transactions ğ‘¡ğ‘¥ ğ‘— , ğ‘¡ğ‘¥ ğ‘—+1 and ğ‘¡ğ‘¥ ğ‘—+4 are successfully
validated, while the validation of ğ‘¡ğ‘¥ ğ‘—+2 fails. When threads
are available, Block-STM capitalizes by performing these
validations in parallel, allowing it to detect the validation
failure of ğ‘¡ğ‘¥ ğ‘—+2 faster in the above example (at the expense of
a validation of ğ‘¡ğ‘¥ ğ‘—+4 that needs to be redone). Identifying val-
idation failures and aborting incarnations as soon as possible
is crucial for the system performance, as any incarnation
that reads values written by a incarnation that aborts also
needs to be aborted, forming a cascade of aborts.

When an incarnation writes only to a subset of memory
locations written by the previously completed incarnation
of the same transaction, i.e. case 1(b), Block-STM schedules
validation just for the incarnation. This is sufficient due to
2(a), as the whole write-set of the previous incarnation is
marked as estimates during the abort. The abort leads to op-
timistically creating validation tasks for higher transactions
in 2(b). Threads that perform these tasks can already detect
validation failures due to the estimate markers on memory
locations, instead of waiting for a subsequent incarnation to
finish.

Commit rule. In [23], we derive a precise predicate for
when transaction ğ‘¡ğ‘¥ ğ‘— can be considered committed (its roughly

4

when an incarnation is successfully validated after lower
transactions 0, . . . , ğ‘— âˆ’ 1 have already been committed). It
would be possible to continuously track this predicate, but
to reduce the amount of work and synchronization involved,
the Block-STM scheduler only checks whether the entire
block of transactions can be committed. This is done by ob-
serving that there are no more tasks to perform and at the
same time, no threads that are performing any tasks.

Figure 2. Illustration of status transitions

3 Block-STM Detailed Description
In this section, we describe Block-STM. Upon spawning,
threads perform the run() procedure in Line 1. Our pseudo-
code is divided into several modules that the threads use.
The Scheduler module contains the shared variables and
logic used to dispatch execution and validation tasks. The
MVMemory module contains shared memory in a form of a
multi-version data-structure for values written and read by
different transactions in Block-STM. Finally, the VM module
describes how reads and writes are instrumented during
transaction execution.

Block-STM finishes when all threads join after returning
from the run() invocation. At this point, the output of Block-
STM can be obtained by calling the MVMemory.snapshot()
function that returns the final values for all affected memory
locations. This function can be easily parallelized and the
output can be persisted to main storage (abstracted as a
Storage module), but these aspects are out of the scope here.

3.1 High-Level Thread Logic
We start by the high-level logic described in Algorithm 1. The
run() procedure interfaces with the Scheduler module and
consists of a loop that lets the invoking thread continuously
perform available validation and execution tasks. The thread
looks for a new task in Line 9, and dispatches a proper han-
dler based on its kind, i.e. function try_execute in Line 5
for an EXECUTION_TASK and function needs_reexecution
in Line 7 for a VALIDATION_TASK (since, as discussed in Sec-
tion 2, a successful validation does not change state, while
failed validation implies that the transaction requires re-
execution). Both of this functions take a transaction version
(transaction index and incarnation number) as an input. A
try_execute function invocation may return a new vali-
dation task back to the caller, and a needs_reexecution
function invocation may return a new execution task.

READY_TO_EXECUTE(i)EXECUTING(i)EXECUTED(i)ABORTING(i)READY_TO_EXECUTE(i+1)ABORTING(i)try_incarnatefinish_executiontry_validation_abortadd_dependencyfinish_validationw.aborted=trueresumeâŠ² returns a validation task, or âŠ¥

âŠ² returns a re-execution task, or âŠ¥

âŠ² returns a validation task, or âŠ¥

âŠ² VM does not write to shared memory

Algorithm 1 Thread logic

1: procedure run()
2:
task â† âŠ¥
while Â¬Scheduler.done() do
3:
4:
5:

if task â‰  âŠ¥ âˆ§ task.kind = EXECUTION_TASK then

task â† try_execute(task.version)

6:
7:

if task â‰  âŠ¥ âˆ§ task.kind = VALIDATION_TASK then
task â† needs_reexecution(task.version)

if task = âŠ¥ then

task â† Scheduler.next_task()

8:
9:
10: function try_execute(version)
11:
12:
13:
14:
15:

(txn_idx, incarnation_number) â† version
vm_result â† VM.execute(txn_idx)
if vm_result.status = READ_ERROR then

return try_execute(version)

else

return âŠ¥

16:
17:
18:
19:
20: function needs_reexecution(version)
21:
22:
23:
24:
25:

if Â¬Scheduler.add_dependency(txn_idx, vm_result.blocking_txn_idx) then

âŠ² dependency resolved in the meantime, re-execute

wrote_new_location â† MVMemory.record(version, vm_result.read_set, vm_result.write_set)
return Scheduler.finish_execution(txn_idx, incarnation_number, wrote_new_location)

(txn_idx, incarnation_number) â† version
read_set_valid â† MVMemory.validate_read_set(txn_idx)
aborted â† Â¬read_set_valid âˆ§ Scheduler.try_validation_abort(txn_idx, incarnation_number)
if aborted then

MVMemory.convert_writes_to_estimates(txn_idx)

âŠ² returns a task for re-execution, or âŠ¥

26:

return Scheduler.finish_validation(txn_idx, aborted)

3.1.1 Execution Tasks. An execution task is processed
using the try_execute procedure. First, a VM.execute func-
tion is invoked in Line 12. As discussed in Section 3.2.1, by the
VM design, this function reads from memory (MVMemory
data-structure and the main Storage), but never modifies
any state while being performed. Instead, a successful VM
execution returns a write-set, consisting of memory locations
and their updated values, which are applied to MVMemory
by the record function invocation in Line 18. In Block-STM,
VM.execute also captures and returns a read-set, containing
all memory locations read during the incarnation, each asso-
ciated with whether a value was read from MVMemory or
Storage, and in the former case, the version of the transac-
tion execution that previously wrote the value. The read-set
is also passed to the MVMemory.record call in Line 18 and
stored in MVMemory for later validation purposes.

Every MVMemory.record invocation returns an indica-
tor whether a write occurred to a memory location not writ-
ten to by the previous incarnation of the same transaction.
As discussed in Section 2, in Block-STM this indicator deter-
mines whether the higher transactions (than the transaction
that just finished execution, in the preset serialization order)
require further validation. Scheduler.finish_execution in
Line 19 schedules the required validation tasks. When a new
location is not written, wrote_new_location variable is set
to false and it suffices to only validate the transaction itself.

In this case, due to an internal performance optimization,
the Scheduler module sometimes returns this validation task
back to the caller from the finish_execution invocation.
The VM execution of transaction ğ‘¡ğ‘¥ ğ‘— may observe a read
dependency on a lower transaction ğ‘¡ğ‘¥ğ‘˜ in the preset order,
ğ‘˜ < ğ‘—. As discussed in Section 2, this happens when the last
incarnation of ğ‘¡ğ‘¥ğ‘˜ wrote to a memory location that ğ‘¡ğ‘¥ ğ‘— reads,
but when the incarnation of ğ‘¡ğ‘¥ğ‘˜ aborted before the read by
ğ‘¡ğ‘¥ ğ‘— . In this case, the index ğ‘˜ of the blocking transaction is
returned as vm_result.blocking_txn_idx, a part of the output
in Line 12. In order to re-schedule the execution task for ğ‘¡ğ‘¥ ğ‘—
for after the blocking transaction ğ‘¡ğ‘¥ğ‘˜ finishes its next incar-
nation, Scheduler.add_dependency is called in Line 14. This
function returns false if it encounters a race condition when
ğ‘¡ğ‘¥ğ‘˜ gets re-executed before the dependency can be added.
The execution task is then retried immediately in Line 15.

3.1.2 Validation Tasks. A validate_read_set call in Line 22
obtains the last read-set recorded by an execution of txn_idx
and checks that re-reading each memory location in the
read-set still yields the same values. To be more precise, for
every value that was read, the read-set stores a read descrip-
tor. This descriptor contains the version of the transaction
(during the execution of which the value was written), or
âŠ¥ if the value was read from storage (i.e. not written by a

5

Algorithm 2 The MVMemory module

Atomic Variables:

data â† Map, initially empty
âŠ² (location, txn_idx) maps to a pair (incarnation_number, value), or to an ESTIMATE marker.
last_written_locations â† Array(BLOCK.size(), {}) âŠ² txn_idx to a set of memory locations written during its last finished execution.
âŠ² txn_idx to a set of (location, version) pairs per reads in last finished execution.
last_read_set â† Array(BLOCK.size(), {})

for every (location, value) âˆˆ write_set do

data[(location, txn_idx)] â† (incarnation_number, value)

27: procedure apply_write_set(txn_index, incarnation_number, write_set)
28:
29:
30: function rcu_update_written_locations(txn_index, new_locations)
31:
32:
33:

prev_locations â† last_written_locations[txn_idx]
for every unwritten_location âˆˆ prev_locations \ new_locations do

data.remove((unwritten_location, txn_idx))
34:
last_written_locations[txn_idx] â† new_locations
return new_locations \ prev_locations â‰  {}
35:
36: function record(version, read_set, write_set)
(txn_idx, incarnation_number) â† version
37:
apply_write_set(txn_idx, incarnation_number, write_set)
38:
new_locations â† {location | (location, â˜…) âˆˆ write_set}
39:
wrote_new_location â† rcu_update_written_locations(txn_idx, new_locations)
40:
41:
last_read_set[txn_idx] â† read_set
return wrote_new_location
42:
43: procedure convert_writes_to_estimates(txn_idx)
44:
45:
46:

prev_locations â† last_written_locations[txn_idx]
for every location âˆˆ prev_location do

data[(location, txn_idx)] â† ESTIMATE

âŠ² store in the multi-version data structure

âŠ² loaded atomically (RCU read)

âŠ² remove entries that were not overwritten
âŠ² store newly written locations atomically (RCU update)
âŠ² was there a write to a location not written the last time

âŠ² extract locations that were newly written

âŠ² store the read-set atomically (RCU update)

âŠ² loaded atomically (RCU read)

âŠ² entry is guaranteed to exist

47: function read(location, txn_idx)
48:
49:
50:

ğ‘† â† {((location, idx), entry) âˆˆ data | idx < txn_idx}
if ğ‘† = {} then

return (status â† NOT_FOUND)
((location, idx), entry) â† arg maxğ‘–ğ‘‘ğ‘¥ ğ‘†
if entry = ESTIMATE then

return (status â† READ_ERROR, blocking_txn_idx â† idx)
return (status â† OK, version â† (idx, entry.incarnation_number),

51:
52:
53:

54:

55: function snapshot()
56:
ret â† {}
for every location | ((location, â˜…), â˜…) âˆˆ data do
57:
result â† read(location, BLOCK.size())
58:
if result.status = OK then
59:
60:

ret â† ret âˆª {location, result.value}

61:

return ret

value â† entry.value)

62: function validate_read_set(txn_idx)
63:
prior_reads â† last_read_set[txn_idx]
for every (location, version) âˆˆ prior_reads do
64:
65:
cur_read â† read(location, txn_idx)
if cur_read.status = READ_ERROR then
66:
67:

return false

68:
69:

70:
71:

72:

if cur_read.status = NOT_FOUND âˆ§ version â‰  âŠ¥ then

return false

if cur_read.status = OK âˆ§ cur_read.version â‰  version then

return false

return true

smaller transaction). The incarnation numbers are monoton-
ically increasing, so it is sufficient to validate the read-set by
comparing the corresponding descriptors.

If validation fails, try_validation_abort on Scheduler
is called in Line 23, which returns an indicator of whether
the abort was successful. Scheduler ensures that only one
failing validation per version may lead to a successful abort.

âŠ² last recorded read_set, loaded atomically via RCU
âŠ² version is âŠ¥ when prior read returned NOT_FOUND

âŠ² previously read entry from data, now ESTIMATE

âŠ² previously read entry from data, now NOT_FOUND

âŠ² read some entry, but not the same as before

Hence, if abort_validation returns false, then the incar-
nation was already aborted. If the abort was successful,
then convert_writes_to_estimates(txn_idx) in Line 25
is called, which replaces the write-set of the aborted version
in the shared memory data-structure with special ESTIMATE
markers. A successful abort leads to scheduling the trans-
action for re-execution and the higher transactions for valida-
tion during the Scheduler.finish_validation call in Line 26.

6

Algorithm 3 The VM module
73: function execute(txn_id)
74:
read_set â† {}
75:
write_set â† {}
76:
run transaction BLOCK[txn_idx]

....
upon writing value at a memory location:
if (location, prev_value) âˆˆ write_set then

write_set â† write_set \ {(location, prev_value)}

write_set â† write_set âˆª {(location, value)}

....
upon reading a memory location:

if (location, value) âˆˆ write_set then

VM reads value

else

result â† MVMemory.read(location, txn_idx)
if result.status = NOT_FOUND then

read_set â† read_set âˆª {(location, âŠ¥)}
VM reads from Storage
else if result.status = OK then

read_set â† read_set âˆª {(location, result.version)}
VM reads result.value

else

77:
78:

79:
80:

81:

82:
83:

84:
85:
86:
87:
88:
89:
90:
91:
92:
93:
94:
95:

96:
97:

âŠ² (location, version) pairs
âŠ² (location, value) pairs
âŠ² run transaction, intercept reads and writes

âŠ² store the latest value per location
âŠ² VM does not write to MVMemory or Storage

âŠ² value written by this txn

âŠ² record version âŠ¥ when reading from storage

return result

....

return (read_set, write_set)

âŠ² return (READ_ERROR, blocking_txn_id) from the VM.execute

Sometimes, (as an optimization), the re-execution task is
returned (that proceeds to return the new version from
needs_reexecution and then in Line 5 become the only
thread to execute the next incarnation of the transaction).

3.2 Multi-Version Memory
The MVMemory module (Algorithm 2) describes the shared
memory data-structure in Block-STM. It is called multi-
version because it stores multiple writes for each memory
location, along with a value and an associated version of a
corresponding transaction. In the pseudo-code, we represent
the main data-structure, called data, with an abstract map
interface, mapping (location, txn_idx) pairs to the correspond-
ing entries, which are (incarnation_number, value) pairs. In
order to support a read of memory location by transaction
ğ‘¡ğ‘¥ ğ‘— , data provides an interface that returns an entry written
at location by the transaction with the highest index ğ‘– such
that ğ‘– < ğ‘— This functionality is used in Line 48 and Line 51.
For clarity of presentation, our pseudo-code focuses on the
abstract functionality of the map, while standard concurrent
data-structure design techniques can be used for an efficient
implementation (discussed in Section 4).

For every transaction, MVMemory stores a set of mem-
ory locations in the last_written_locations array and a set of
(location, version) pairs in the last_read_set array. We assume
that these sets are loaded and stored atomically, which can

7

be accomplished by storing a pointer to the set and accessing
the pointer atomically, i.e. via the read-copy-update [33].

Recording. The record function takes a transaction ver-
sion along with the read-set and the write-set (resulting
from the execution of the version). The write-set consists of
(memory location, value) pairs that are applied to the data
map by apply_write_set procedure invocation. The in-
vocation of rcu_update_written_locations that follows
in Line 40 updates last_written_locations and also removes
(in Line 33) from the data map all entries at memory loca-
tions that were not overwritten by the latest write-set of the
transaction (i.e. locations in the last_written_locations before,
but not after the update). This function also determines and
returns whether a new memory location was written (i.e.
in last_written_locations after, but not before the update).
This indicator is stored in wrote_new_location variable and
returned from the record function. Before returning, the
read-set of the transaction is stored in the last_read_set array
via an RCU pointer update.

The convert_writes_to_estimates procedure, called
during a transaction abort, iterates over last_written_locations
of the transaction, and replaces each stored (incarnation_number,
value) pair with a special ESTIMATE marker. It ensures that
validations fail for higher transactions if they have read the
data written by the aborted incarnation. While removing the
entries can also accomplish this, the ESTIMATE marker also
serves as a â€œwrite estimate" for the next incarnation of this

Algorithm 4 The Scheduler module, variables, utility APIs and next task logic

Atomic variables:

execution_idx â† 0, validation_idx â† 0, decrease_cnt â† 0, num_active_tasks â† 0, done_marker â† false

âŠ² Respectively: An index that tracks the next transaction to try and execute. A similar index for tracking validation. Number of

times

completion.

validation_idx or execution_idx was decreased. Number of ongoing validation and execution tasks. Marker for

txn_dependency â† Array(BLOCK.size(), mutex({}))
txn_status â† Array(BLOCK.size(), mutex((0, READY_TO_EXECUTE)))

âŠ² txn_idx to a mutex-protected set of dependent transaction indices
âŠ² txn_idx to a mutex-protected pair (incarnation_number,

status),

âŠ² atomic

return done_marker

98: procedure decrease_execution_idx(target_idx)
execution_idx â† min(execution_idx, target_idx)
99:
100:
decrease_cnt.increment()
101: function done()
102:
103: procedure decrease_validation_idx(target_idx)
104:
105:
106: procedure check_done()
107:
108:

observed_cnt â† decrease_cnt
if min(execution_idx, validation_idx) â‰¥ BLOCK.size() âˆ§

validation_idx â† min(validation_idx, target_idx) âŠ² atomic
decrease_cnt.increment()

num_active_tasks = 0 âˆ§ observed_cnt = decrease_cnt then
done_marker â† true

109:
110: function try_incarnate(txn_idx)
if txn_idx < BLOCK.size() then
111:
112:

with txn_status[txn_idx].lock()

113:
114:
115:

if txn_status[txn_idx].status = READY_TO_EXECUTE then

txn_status[txn_idx].status â† EXECUTING
return (txn_idx, txn_status[txn_idx].incarnation_number)

num_active_tasks.decrement()
return âŠ¥

116:
117:
118: function next_version_to_execute()
119:
120:
121:
122:

check_done()
return âŠ¥

if execution_idx â‰¥ BLOCK.size() then

num_active_tasks.increment()

transaction. Any transaction that observes an ESTIMATE of
transaction ğ‘¡ğ‘¥ when reading during a speculative execution,
waits for the dependency to resolve (ğ‘¡ğ‘¥ to be re-executed), as
opposed to ignoring the ESTIMATE and likely aborting if ğ‘¡ğ‘¥â€™s
next incarnation again writes to the same memory location.
Reads. The MVMemory.read function takes a memory
location and a transaction index txn_idx as its input param-
eters. First, it looks for the highest transaction index, idx,
among transactions lower than txn_idx that have written to
this memory location (Line 48 and Line 51). Based on the
fixed serialization order of transactions in the block, this is
the best guess for reading speculatively (writes by transac-
tions lower than idx are overwritten by idx, and the specula-
tive premise is that the transactions between idx and txn_idx
do not write to the same memory location). The value writ-
ten by transaction idx is returned in Line 54, alongside with

8

where status âˆˆ {READY_TO_EXECUTE, EXECUTING, EXECUTED, ABORTING}.

idx_to_execute â† execution_idx.fetch_and_increment()
return try_incarnate(idx_to_execute)

123:
124:
125: function next_version_to_validate()
if validation_idx â‰¥ BLOCK.size() then
126:
127:
128:
129:
130:
131:
132:

check_done()
return âŠ¥

num_active_tasks.increment()
idx_to_validate â† validation_idx.fetch_and_increment()
if idx_to_validate < BLOCK.size() then

(incarnation_number, status) â† txn_status[idx_to_validate].lock()

133:
134:

if status = EXECUTED then

return (idx_to_validate, incarnation_number)

135:
num_active_tasks.decrement()
return âŠ¥
136:
137: function next_task()
138:
139:
140:
141:

if validation_idx < execution_idx then

version_to_validate â† next_version_to_validate()
if version_to_validate â‰  âŠ¥ then

return (version â† version_to_validate,
kind â† VALIDATION_TASK)

142:
143:
144:
145:

146:

else

version_to_execute â† next_version_to_execute()
if version_to_execute â‰  âŠ¥ then

return (version â† version_to_execute,
kind â† EXECUTION_TASK)

return âŠ¥

the full version (i.e. idx and the incarnation number) and an
OK status. However, if the entry corresponding to transac-
tion idx is an ESTIMATE marker, then the read returns an
READ_ERROR status and idx as a blocking transaction index.
This is an indication for the caller to postpone the execu-
tion of transaction txn_idx until the next incarnation of the
blocking transaction idx completes. Essentially, at this point,
it is estimated that transaction idx will perform a write that
is relevant for the correct execution of transaction txn_idx.
When no lower transaction has written to the memory
location, a read returns a NOT_FOUND status, implying that
the value cannot be obtained from the previous transactions
in the block. As we will describe shortly, the caller can then
complete the speculative read by reading from storage.

Algorithm 5 The Scheduler module, dependencies and finish logic
147: function add_dependency(txn_idx, blocking_txn_idx)
148:

with txn_dependency[blocking_txn_idx].lock()

149:
150:

151:
152:

if txn_status[blocking_txn_idx].lock().status = EXECUTED then

return false

txn_status[txn_idx].lock().status() â† ABORTING
txn_dependency[blocking_txn_idx].insert(txn_idx)

num_active_tasks.decrement()
return true

153:
154:
155: procedure set_ready_status(txn_idx)
with txn_status[txn_idx].lock()
156:

(incarnation_number, status) â† txn_status[txn_idx]
txn_status[txn_idx] â† (incarnation_number + 1, READY_TO_EXECUTE)

157:
158:
159: procedure resume_dependencies(dependent_txn_indices)
160:
161:

for each dep_txn_idx âˆˆ dependent_txn_indices do

set_ready_status(dep_txn_idx)

decrease_execution_idx(min_dependency_idx)

min_dependency_idx â† min(dependent_txn_indices)
if min_dependency_idx â‰  âŠ¥ then

162:
163:
164:
165: procedure finish_execution(txn_idx, incarnation_number, wrote_new_path)
166:
167:
168:
169:
170:
171:
172:
173:

txn_status[txn_idx].lock().status â† EXECUTED
deps â† txn_dependency[txn_idx].lock().swap({})
resume_dependencies(deps)
if validation_idx > txn_idx then
if wrote_new_path then

decrease_validation_idx(txn_idx)

else

return (version â† (txn_idx, incarnation_number), kind â† VALIDATION_TASK)

âŠ² thread holds 2 locks
âŠ² dependency resolved before locking in Line 148
âŠ² previous status must be EXECUTING

âŠ² execution task aborted due to a dependency

âŠ² status must be ABORTING

âŠ² minimum is âŠ¥ if no elements

âŠ² ensure dependent indices get re-executed

âŠ² status must have been EXECUTING
âŠ² swap out the set of dependent transaction indices

âŠ² otherwise index already small enough

âŠ² schedule validation for txn_idx and higher txns

num_active_tasks.decrement()
return âŠ¥

174:
175:
176: function try_validation_abort(txn_idx, incarnation_number)
177:

with txn_status[txn_idx].lock()

if txn_status[txn_idx] = (incarnation_number, EXECUTED) then

return false

txn_status[txn_idx].status â† ABORTING
return true

178:
179:
180:
181:
182: procedure finish_validation(txn_idx, aborted)
183:
184:
185:
186:
187:
188:
189:

set_ready_status(txn_idx)
decrease_validation_idx(txn_idx + 1)
if execution_idx > txn_idx then

new_version â† try_incarnate(txn_idx)
if new_version â‰  âŠ¥ then

if aborted then

190:
191:

num_active_tasks.decrement()
return âŠ¥

return (new_version, kind â† EXECUTION_TASK)

âŠ² no task returned to the caller

âŠ² thread changes status, starts aborting

âŠ² schedule validation for higher transactions
âŠ² otherwise index already small enough

âŠ² return re-execution task to the caller
âŠ² done with validation task
âŠ² no task returned to the caller

The validate_read_set function loads (via RCU) the
most recently recorded read-set from the transactionâ€™s ex-
ecution in Line 63. The function calls read for each loca-
tion and checks observed status and version against the
read-set (recall that version âŠ¥ in the read-set means that
the corresponding prior read returned NOT_FOUND status, i.e.
it read a value from Storage). As we saw in Section 3.1.2,
validate_read_set function is invoked during validation

in Line 22, at which point the incarnation that is being
validated is already executed and has recorded the read-
set. However, if the thread performing a validation task
for incarnation ğ‘– of a transaction is slow, it is possible that
validate_read_set function invocation observes a read-
set recorded by a later (i.e. > ğ‘–) incarnation. In this case,
incarnation ğ‘– is guaranteed to be already aborted (else higher
incarnations would never start), and the validation task will

9

have no effect on the system regardless of the outcome (only
validations that successfully abort affect the state and each
incarnation can be aborted at most once).

The snapshot function is called after Block-STM finishes,
and returns the value written by the highest transaction for
every location that was written to by some transaction.

3.2.1 VM execution. In Algorithm 3 we describe how
reads and writes are handled in Block-STM by the VM.execute
function (invoked while performing an execution task, in Line 12).
This function tracks and returns the transactionâ€™s read- and
write-sets, both initialized to empty. When a transaction at-
tempts to write a value to a location, the (location, value)
pair is added to the write-set, possibly replacing a pair with
a prior value (if it is not the first time the transaction wrote
to this location during the execution).

When a transaction attempts to read a location, if the loca-
tion is already in the write-set then the VM reads the corre-
sponding value (that the transaction itself wrote) in Line 85.
Otherwise, MVMemory.read is performed. If it returns
NOT_FOUND, then VM reads the value directly from storage
(abstracted as a Storage module that contains values pre-
ceding the block execution) and records (location, âŠ¥) in the
read-set. If MVMemory.read returns READ_ERROR, then VM
execution stops and returns the error and the blocking trans-
action index (for the dependency) to the caller. If it returns
OK, then VM reads the resulting value from MVMemory and
records the location and version pair in the read-set.

Note that for simplicity of presentation, if the transaction
reads the same location more than once, the pseudo-code
repeats the read and makes separate record in the read-set.
Even if reading the same location results in reading different
values, Block-STM algorithm maintains correctness because
all reads are eventually validated and the VM captures the
errors that may arise due to any opacity violations.

3.3 Scheduling
The Scheduler module contains the necessary state and syn-
chronization logic for managing the execution and valida-
tion tasks. For each transaction in a block, the txn_status
array contains the most up-to-date incarnation number (ini-
tially 0) and the status of this incarnation, which can be one
of READY_TO_EXECUTE (initial value), EXECUTING, EXECUTED
and ABORTING. The entries of the txn_status array are pro-
tected by a lock to provide atomicity.

Status transitions are illustrated in Figure 2. The thread
that changes the status from READY_TO_EXECUTE to EXECUTING
in Line 114 when incarnation number is ğ‘– performs incarna-
tion ğ‘– of the transaction. The status never becomes
READY_TO_EXECUTE(i) again, guaranteeing that no incarna-
tion is performed more than once. Afterwards, this thread
sets the status to EXECUTED(i) in Line 166. Similarly, only
the thread that changes the status from EXECUTED(i) to
ABORTING(i) returns true from try_validation_abort for
incarnation ğ‘–. After performing the steps associated with a

10

successful abort, as discussed in Section 3.1.2, this thread
then updates the status to
READY_TO_EXECUTE(i + 1) in Line 158. This indicates that
an execution task for incarnation ğ‘– + 1 is ready to be created.
When incarnation ğ‘– of transaction ğ‘¡ğ‘¥ğ‘˜ aborts because of a
read dependency on transaction ğ‘¡ğ‘¥ ğ‘— (ğ‘— < ğ‘˜ in the preset seri-
alization order), the status of ğ‘¡ğ‘¥ğ‘˜ is updated to ABORTING(i)
in Line 151. The corresponding add_dependency(k, j) in-
vocation returns true and Block-STM guarantees that some
thread will subsequently finish executing transaction ğ‘¡ğ‘¥ ğ‘— and
resolve ğ‘¡ğ‘¥ğ‘˜ â€™s dependency in Line 158 (called from Line 161)
by setting its status to READY_TO_EXECUTE(i + 1).

The txn_dependency array is used to track transaction
dependencies. In the above example, when transaction ğ‘¡ğ‘¥ğ‘˜
reads an estimate of transaction ğ‘¡ğ‘¥ ğ‘— and calls add_dependency(k, j)
(that returns true), ğ‘˜ is added to txn_dependency[j] in Line 152.
Our pseudo-code explicitly describes lock-based synchro-
nization for the dependencies stored in the txn_dependency
array. This is to demonstrate the handling of a race between
the add_dependency function of ğ‘¡ğ‘¥ğ‘˜ and the finish_execution
procedure of ğ‘¡ğ‘¥ ğ‘— (in particular, to guarantee that transaction
ğ‘¡ğ‘¥ ğ‘— will always clear its dependencies in Line 167). The prob-
lematic scenario could arise if after ğ‘¡ğ‘¥ğ‘˜ observed the read
dependency, transaction ğ‘¡ğ‘¥ ğ‘— raced to finish_execution
and cleared its dependencies. However, due to the check
in Line 149, dependency will not be added and the add_dependency
invocation will return false. Then, the status of ğ‘¡ğ‘¥ğ‘˜ would
remain EXECUTING and the caller would immediately re-
attempt the execution task of ğ‘¡ğ‘¥ğ‘˜ , incarnation ğ‘–, in Line 15.
Managing Tasks. Block-STM scheduler maintains execu-
tion_idx and validation_idx atomic counters. Together, one
can view the status array and the validation (or execution)
index counter as a counting-based implementation of an or-
dered set abstraction for selecting lowest-indexed available
validation (or execution) task.

The validation_idx counter tracks the index of the next
transaction to be validated. A thread picks an index in Line 130
in the next_version_to_validate function by performing
the fetch_and_increment instruction on the validation_idx. It
then checks if the transaction with the corresponding index
is ready to be validated (i.e. the status is EXECUTED), and if it
is, determines the latest incarnation number. A similar execu-
tion_idx counter is used in combination with the status array
to manage execution tasks. In the next_version_to_execute
function, a thread picks an index by fetch_and_increment-
ing in Line 123, then invokes the try_incarnate function.
Only if the transaction is in a READY_TO_EXECUTE state, this
function will set the status to EXECUTING and return the
corresponding version for execution.

When transaction status is updated to READY_TO_EXECUTE,
Block-STM ensures that the corresponding execution task
eventually gets created. In the resume_dependencies pro-
cedure, the execution index is reduced by the call in Line 164

to be no higher than indices of all transactions that had a de-
pendency resolved. In finish_validation function after a
successful abort, however, there may be a single re-execution
task (unless the task was already claimed by another thread
after the status was set, something that is checked in Line 188).
As an optimization, instead of reducing execution_idx, the
execution task is sometimes returned to the caller in Line 189.
Similarly, if a validation of transaction ğ‘¡ğ‘¥ğ‘˜ was successfully
aborted, then Block-STM ensures, in the finish_validation
function (in Line 185), that validation_idx â‰¤ ğ‘˜. In addition, in
the finish_execution function of transaction ğ‘¡ğ‘¥ğ‘˜ , Block-
STM invokes decrease_validation_idx in Line 171 if a
new memory location was written by the associated incar-
nation. Otherwise, only a validation task for ğ‘¡ğ‘¥ğ‘˜ is created
that may be returned to the caller.

Finally, the next_task function decides whether to obtain
a version to execute or version to validate based on a simple
heuristic, by comparing the two indices in Line 138.

Detecting Completion. The Scheduler provides a mech-
anism for the threads to detect when all execution and valida-
tion tasks are completed. This is not trivial because individual
threads might obtain no available tasks from the next_task
function, but more execution and validation tasks could still
be created later, e.g. if a validation task that is being per-
formed by another thread fails.

Block-STM implements a check_done procedure that de-
termines when all work is completed and the threads can
safely return. In this case, a done_marker is set to true, pro-
viding a cheap way for all threads to exit their main loops
in Line 3. Threads invoke a check_done procedure in Line 120
and Line 127, when observing an execution or validation in-
dex that is already â‰¥ BLOCK.size(). In the following, we
explain the logic behind check_done.

A straw man approach would be to check that both ex-
ecution and validation indices are at least as large as the
BLOCK.size(). The first problem with this approach is that
it does not consider when the execution and validation tasks
actually finish. For example, the validation_idx may be in-
cremented in Line 130 and become BLOCK.size(), but it
would be incorrect for the threads to return, as the corre-
sponding validation task of transaction BLOCK.size() âˆ’ 1
may still fail. To overcome this problem, Block-STM uti-
lizes the num_active_tasks atomic counter to track the num-
ber of ongoing execution and validation tasks. Then, in
addition to the indices, the scheduler also checks whether
num_active_tasks = 0 in Line 108.

The num_active_tasks counter is incremented in Line 122
and Line 129, right before execution_idx and validation_idx
are fetch-and-increment-ed, respectively. The num_active_tasks
is decremented if no task corresponding to the fetched in-
dex is created (Line 116 and Line 135), or after the tasks
finish (Line 174 and Line 190). As an optimization, when
finish_execution or finish_validation functions return

a new task to the caller, num_active_tasks is left unchanged
(instead of incrementing and decrementing that cancel out).
The second challenge is that validation_idx, execution_idx
and num_active_tasks are separate counters, e.g. it is possible
to read that validation_idx has value BLOCK.size(), then read
that num_active_tasks has value 0, without these variables
simultaneously holding the respective values. Block-STM
handles this by another counter, decrease_cnt, incremented
in decrease_execution_idx and
decrease_validation_idx procedures (Line 100, Line 105).
By reading decrease_cnt twice in check_done, it is possible
to detect if validation or execution index decreases from their
observed values when num_active_tasks is read to be 0.

4 Implementation and Evaluation
Our Block-STM implementation is in Rust, and is merged
on the main branch of the open source Diem and Aptos
projects [2, 47]. Both Blockchains run a virtual machine for
smart contracts in Move language [11]. The VM captures all
execution errors that could stem from inconsistent reads dur-
ing speculative transaction execution. The VM also caches
the reads from Storage. Importantly, the preset order allows
us to test correctness by comparing to sequential implemen-
tation outputs.

Diem VM does not support suspending transaction ex-
ecution at the exact point when a read dependency is en-
countered. Instead, when a transaction is aborted due to a
READ_ERROR, it is later (after the dependency is resolved)
restarted from scratch. Aptos VM supports this feature.

To mitigate the impact of restarting VM execution from
scratch, we check the read-set of the previous incarnation for
dependencies before the VM.execute invocation in Line 12.
Another related optimization implemented in Block-STM
occurs when the Scheduler.add_dependency invocation re-
turns false in Line 14. This indicates that the dependency
has been resolved. Instead of Line 15 (that would restart the
execution from scratch with the Diem VM), Block-STM calls
add_dependency from the VM itself, and can thus re-read
and continue execution when false is returned.

Block-STM implementation uses the standard cache padding
technique to mitigate false sharing. The logic for num_active_tasks
is implemented using the Resource Acquisition Is Initializa-
tion (RAII) design pattern. Finally, Block-STM implements
the data map in MVMemory as a concurrent hashmap over
access paths, with lock-protected search trees for efficient
txn_idx-based look-ups.

4.1 Experimental Results
We evaluated Block-STM on a Amazon Web Services c5a.16xlarge
instance (AMD EPYC CPU and 128GB memory) with Ubuntu
18.04 operating system. The experiments run on a single
socket with up to 32 physical cores without hyper-threading.

11

BSTM, 103 acc

BSTM, 104 acc

LiTM, 103 acc

LiTM, 104 acc

Bohm, 103 acc

Bohm, 104 acc

Sequential

Â·103

Â·103

t
u
p
h
g
u
o
r
h
T

40

30

20

10

0

4

8

16

24
Number of threads

32

t
u
p
h
g
u
o
r
h
T

100

80

60

40

20

0

4

8

16

24
Number of threads

32

Figure 3. Comparison of BSTM, LiTM, Bohm and sequential execution for block size 103 (left) and 104 (right). Bohm is provided with perfect
write estimates. Diem p2p txns.

BSTM, 2 acc, 103 bch
BSTM, 100 acc, 103 bch
BSTM, 10 acc, 104 bch
Sequential

BSTM, 10 acc, 103 bch
BSTM, 2 acc, 104 bch
BSTM, 100 acc, 104 bch

Â·103

t
u
p
h
g
u
o
r
h
T

50

40

30

20

10

0

4

8

16

24
Number of threads

32

Figure 4. Comparison of BSTM and sequential execution for block
size 103 and 104, account sizes 2, 10 and 100. Diem p2p transactions.

16 threads, 103 acc
32 threads, 103 acc

16 threads, 104 acc
32 threads, 104 acc

Â·103

120

100

80

60

40

t
u
p
h
g
u
o
r
h
T

1

5

10

20
Block size

Figure 5. Throughput of BSTM for various block sizes. Diem p2p
transactions.

50

Â·103

The evaluation benchmark executes the whole block, con-
sisting of peer-to-peer (p2p) transactions implemented in
Move. Each p2p transaction randomly chooses two different
accounts and performs a payment.

We first perform experiments with Diem p2p transactions 1
that perform 21 reads and 4 writes. For a Diem p2p trans-
action from account ğ´ to account ğµ, the 4 writes of the
transaction involve updating balances and sequence num-
bers of ğ´ and ğµ. The reason for 21 reads is that every Diem
transaction is verified against some on-chain information to
decide whether the transaction should be processed, some
of which is specific to p2p transactions. During this process,
information such as the correct block time and whether or
not the account is frozen is read.

We also perform experiments with Aptos p2p transac-
tions 2 that perform 8 reads and 5 writes each, where the
Aptos p2p transactions reduce many of the verification and
on-chain reads mentioned above. The VM execution over-
head of a single Diem p2p compared to a single Aptos p2p is
about 100%, as will be shown in Figure 3 and Figure 6, the
throughput of sequentially executing Diem and Aptos p2p
transaction is about 5ğ‘˜ and 10ğ‘˜, respectively. We experiment
with block sizes of 103 and 104 transactions and the number
of accounts of 2, 10, 100, 103 and 104. The number of accounts
determines the amount of conflicts, and in particular, with
just 2 accounts the load is inherently sequential (each trans-
action depends on the previous one). Each data point is an
average of 10 measurements.

This reported measurements include the cost of reading
all required values from storage, and computing the outputs
(i.e. all affected paths and the final values), but not persisting
the outputs to Storage. The outputs are computed accord-
ing to the MVMemory.snapshot logic, but parallelized (per
affected memory locations).

We compare Block-STM to Bohm [21] and LiTM [52].
Bohm is a deterministic database engine that enforces a
preset order by assuming transactionsâ€™ write-sets are known.
Bohm has a pre-execution phase in which it uses the write-
sets information to build a multi-version data-structure that

1https://github.com/danielxiangzl/Block-STM
2https://github.com/danielxiangzl/Block-STM/tree/aptos

12

BSTM, 103 acc

BSTM, 104 acc

Sequential

Â·103

Â·103

t
u
p
h
g
u
o
r
h
T

150

100

50

0

4

8

16

24
Number of threads

32

4

8

16

24
Number of threads

32

t
u
p
h
g
u
o
r
h
T

80

60

40

20

0

Figure 6. Comparison of BSTM and Sequential execution for block size 103 (left) and 104 (right). Aptos p2p transactions.

BSTM, 2 acc, 103 bch
BSTM, 100 acc, 103 bch
BSTM, 10 acc, 104 bch
Sequential

BSTM, 10 acc, 103 bch
BSTM, 2 acc, 104 bch
BSTM, 100 acc, 104 bch

Â·103

t
u
p
h
g
u
o
r
h
T

80

60

40

20

0

4

8

16

24
Number of threads

32

Figure 7. Comparison of BSTM and sequential execution for block
size 103 and 104, account sizes 2, 10 and 100. Aptos p2p transactions.

16 threads, 103 acc
32 threads, 103 acc

16 threads, 104 acc
32 threads, 104 acc

Â·103

180

160

140

120

100

80

60

t
u
p
h
g
u
o
r
h
T

1

5

10

20
Block size

Figure 8. Throughput of BSTM for various block sizes. Aptos p2p
transactions.

50

Â·103

captures the dependencies with respect to the preset or-
der. Then, Bohm executes transactions in parallel, delays
any transaction that has unresolved read dependencies by
buffering it in a concurrent queue, and resumes the execu-
tion once the dependencies are resolved. Note that in the

Blockchain use-case the assumption of knowing all write-
sets in advance is not realistic, so to compare Block-STM
to Bohm we artificially provide Bohm with perfect write-
sets information. Note that our measurements of Bohm only
include parallel execution but not the write-sets analysis,
thus would be significantly better than the performance of
Bohm in practice when the write-sets analysis time is non-
negligible. LiTM [52], a recent deterministic STM library,
claims to outperform other deterministic STM approaches
on the Problem Based Benchmark Suite [45]. We describe
LiTM in more detail in Section 5. In order to have a uniform
setting for comparison, we implemented both a variant of
Bohm 3 and LiTM 4 in Rust in the Diem Blockchain.

The Block-STM comparison to Bohm, LiTM and sequential
baseline for Diem p2p transactions is shown in Figure 3. The
Block-STM comparison to sequential baseline for Aptos p2p
transactions is shown in Figure 6. We will open source all
our implementations and benchmarks to enable reproducible
results.

Comparison to Bohm [21]. The results show that Block-
STM has comparable throughput to Bohm in most cases, and
is significantly better with 32 threads and 103 block size.
Since Bohm relies on perfect write-sets information and thus
perfect dependencies among all transactions, it can delay
the execution of a transaction after all its dependencies have
been executed, avoiding the overhead of aborting and re-
execution. In contrast, Block-STM require no information
about write dependencies prior to execution and therefore
will incur aborts and re-execution. Still, the performance of
Block-STM is comparable to Bohm, implying the abort rates
of Block-STM is substantially small, thanks to the run-time
write-sets estimation and the low-overhead collaborative
scheduler. We also found the overhead of constructing the
multi-version data-structure of Bohm significant compared
to Block-STM, without which Bohmâ€™s throughput will be
slightly better than Block-STM.

3https://github.com/danielxiangzl/Block-STM/tree/bohm
4https://github.com/danielxiangzl/Block-STM/tree/litm

13

Comparison to LiTM [52]. With 104 accounts, Block-
STM has around 3-4x speedup over LiTM regardless of the
block size or transactions type (standard or simplified). With
103 accounts, the speedup is larger (up to 25x) over LiTM,
confirming that Block-STM is less sensitive to conflicts.

Comparison to sequential execution. For Diem and
Aptos benchmarks, Block-STM scales almost perfectly under
low contention, achieving up to 90ğ‘˜ tps and 160ğ‘˜ tps, which
is 18x and 16x over the sequential execution, respectively.

Comparison under highly contended workload. Fig-
ure 4 and Figure 7 reports Block-STM evaluation results with
highly contended workloads. With a completely sequential
workload (2 accounts) Block-STM has at most 30% overhead
vs the sequential execution in both Diem and Aptos bench-
marks. With 10 accounts Block-STM already outperforms
the sequential execution and with 100 accounts Block-STM
gets up to 8x speedup in both benchmarks. Note that with
100 accounts Block-STM does not scale beyond 16 threads,
suggesting that 16 threads already utilize the inherent paral-
lelism in such a highly contended workload.

Maximum throughput of Block-STM We also evalu-
ate Block-STM with increasing block sizes (up to 50ğ‘˜) to
find the maximum throughput of Block-STM in Figure 5 and
Figure 8. For 32 threads, Block-STM achieves up to 110ğ‘˜ tps
for Diem p2p (21x speedup over sequential) and 170ğ‘˜ tps
for Aptos p2p (17x speedup over sequential). For 16 threads,
Block-STM achieves up to 67ğ‘˜ tps for Diem p2p (13x speedup)
and 120ğ‘˜ tps for Aptos p2p (12x speedup).

Conclusion. Our evaluation demonstrates that Block-
STM is adaptive to workload contention and utilizes the in-
herent parallelism therein. For Aptos benchmark, it achieves
over 160ğ‘˜ tps on workloads with low contention, over 80ğ‘˜ on
workloads with high contention, and at most 30% overhead
on workload that are completely sequential.

5 Related Work

The STM approach. The problem of atomically execut-
ing transactions in parallel in shared memory has been ex-
tensively studied in the literature in the past few decades in
the context of STM libraries (e.g., [17, 19, 22, 25, 28, 29, 44]).
These libraries instrument the concurrent memory accesses
associated with different transactions, detect and deal with
conflicts, and provide the final outcome equivalent to exe-
cuting transactions sequentially in some serialization order.
In the STM libraries based on optimistic concurrency con-
trol [17, 31], threads repeatedly speculatively execute and
validate transactions. A successful validation commits and
determines the transaction position in the serialization order.
By default, STM libraries do not guarantee the same out-
come when transactions are re-executed multiple times. This
is unsuitable for Blockchain systems, as validators need to
agree on the outcome of block execution. Deterministic STM
libraries [36, 38, 49] guarantee a unique final state.

14

Due to required conflict bookkeeping and aborts, general-
purpose STM libraries often suffer from performance limi-
tations compared to custom-tailed solutions and are rarely
deployed in production [14]. However, STM performance
can be dramatically improved by restricting it to specific
use-cases [20, 26, 30, 32, 46]. For the Blockchain use-case,
the granularity is a block of transactions. Thus, unlike the
general setting, Block-STM do not need to handle a long-
lived stream of transactions that arrive at arbitrary times
and commit them one by one. Moreover, thanks to the VM,
the Blockchain use-case does not require opacity [24].

Preset and deterministic order. There is prior work on
designing STM libraries constrained to the predefined se-
rialization order [34, 42, 50]. In [34, 50] each transaction is
committed by a designated thread and thus the predefined
order reduces resource utilization. This is because threads
have to stall until all previous transactions in the order are
committed before they can commit their own. Transactions
in [42] are also committed by designated threads, but they
limit the stalling periods to only the latency of the com-
mit via a complex forwarding locking mechanism and flat
combining [27] based validation.

Deterministic STM libraries [36, 38, 49, 52] consider a less
restricted case in which every execution of the same set of
transaction produces the same final state. The idea in the
state-of-the-art [52] is simple. All transactions are executed
from the initial state and the maximum independent set of
transaction (i.e., with no conflicts among them) is committed,
arriving to a new state. The remaining transaction are exe-
cuted from the new state, the maximum independent set is
committed, and so on. This approach thrives for low conflict
workloads, but otherwise suffers from high overhead.

To summarize, in the context of STM literature, the (de-
terministic or preset) ordering constraints have been viewed
as a â€œcurse", i.e. an extra requirement that the system needs
to satisfy at the cost of added overhead. For the Block-STM
approach, on the other hand, the preset order is the â€œbless-
ing" that the whole algorithm is centered around. In fact,
the closest works to Block-STM in terms of how the preset
serialization order is used to deal with conflicts are from the
databases literature. Calvin [48] and Bohm [21] use batches
(akin to blocks) of transactions and their preset order to
execute transactions when their read dependencies are re-
solved. This is possible because, in the databases context,
the write-sets of transactions are assumed to be known in
advance. This assumption is not suitable for Blockchains as
smart contracts might encode an arbitrary logic. Therefore,
Block-STM does not require the write-set to be known and
learns dependencies on the fly.

Multi-version data-structures. Multi-version data struc-
tures are designed to avoid write conflicts [10]. They have a
history of applications in the STM context [13, 37], some of
which utilize optimistic concurrency control [12]. The multi-
version data-structure maps between memory locations and

Once this feature is available, Block-STM can restart execu-
tion from the read that caused suspension upon encountering
a dependency. A potential optimization to go along with this
feature is to validate the reads that happened during the
execution prefix (before transaction was suspended) upon
resumption. This could allow earlier detection of impending
aborts.

The current Block-STM implementation is not optimized
for NUMA architectures or hyperthreading. Exploring these
optimizations is another direction for future research. An-
other interesting direction is to explore nesting techniques [35]
for transactional smart contract design.

Acknowledgment
The authors would like to thank Sam Blackshear and Avery
Ching for fruitful discussions.

values that are indexed based on versions that are assigned
to transactions via global version clock [12, 17, 39].

Blockchain execution. The connection between STM
techniques and parallel smart contract execution was ex-
plored in the past [5, 7, 8, 18]. A miner-replay paradigm was
explored in [18], where miners parallelize block execution
using a white-box STM library application that extracts the
resulting serialization order as a â€œfork-joinâ€ schedule. This
schedule is sent alongside the new block proposal (via the
consensus component) from miners to validators. After the
block is proposed, validators utilize the fork-join schedule
to deterministically replay the block. ParBlockchain [5] in-
troduced an order-execute paradigm (OXII) for deterministic
parallelism. The ordering stage is similar to the schedule
preparation in [18], but the transaction dependency graph
is computed without executing the block. OXII relies on
read-write set being known in advance via static-analysis
or on speculative pre-execution to generate the dependency
graph among transactions. OptSmart [7, 8] makes two im-
provements. First, the dependency graph is compressed to
contain only transactions with dependencies; those that are
not included may execute in parallel. Second, execution uses
multi-versioned memory to mitigate write-write conflicts.
Hyperledger Fabric [6] and several related works [41, 43]
follow the execute-order-validate paradigm. As a result, the
execution phase can abort unserializable transactions before
ordering. Transactions in [15] are pre-executed off the critical
path to produce hints for final execution.

6 Summary
This paper presents Block-STM, a parallel execution engine
for the Blockchain use-case that achieves up to 170k tps
with 32 threads in our benchmarks. For a fully sequential
workload, it has a smaller than 30% overhead, mitigating any
potential performance attacks. Block-STM relies on the write-
sets of transactionsâ€™ last incarnations to estimate dependen-
cies and reduce wasted work. If write-set pre-estimation was
available, e.g., with a best effort static analysis, it could be
similarly used by the first incarnation of a transaction. More-
over, using static analysis to find the best preset order is an
interesting future direction.

Block-STM uses locking for synchronization in the Scheduler

module. It is possible to use standard multicore techniques
to avoid using locks, however, we did not see significant
performance difference in our experiments. Thus, we chose
the design with locks for the ease of presentation.

In Blockchain systems, there is usually an associated â€œgasâ€
cost to executing transactions. A single location for gas up-
dates, could make any block inherently sequential. However,
this issue is typically avoided by tracking gas natively, burn-
ing it or having specialized types or sharded implementation.
As discussed in the Section 4, Diem VM currently does
not support suspending and resuming transaction execution.

15

References
[1] [n.d.]. Aptos codebase. https://github.com/aptos-labs/aptos-core.
[2] [n.d.]. Aptos whitepaper. https://github.com/aptos-labs/aptos-core/

blob/main/developer-docs-site/static/papers/whitepaper.pdf.
[3] [n.d.]. Diem codebase. https://github.com/diem/diem/tree/main.
[4] Dan Alistarh, Justin Kopinsky, Jerry Li, and Nir Shavit. 2015. The
spraylist: A scalable relaxed priority queue. In Proceedings of the 20th
ACM SIGPLAN Symposium on Principles and Practice of Parallel Pro-
gramming. 11â€“20.

[5] Mohammad Javad Amiri, Divyakant Agrawal, and Amr El Abbadi.
2019. ParBlockchain: Leveraging Transaction Parallelism in Permis-
sioned Blockchain Systems. In proceedings of the IEEE 39th Interna-
tional Conference on Distributed Computing Systems (ICDCS). 1337â€“
1347. https://doi.org/doi:10.1109/ICDCS.2019.00134

[6] Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin, Kon-
stantinos Christidis, Angelo De Caro, David Enyeart, Christopher
Ferris, Gennady Laventman, Yacov Manevich, et al. 2018. Hyperledger
fabric: a distributed operating system for permissioned blockchains.
In Proceedings of the thirteenth EuroSys conference. 1â€“15.

[7] Parwat Singh Anjana, Hagit Attiya, Sweta Kumari, Sathya Peri, and Ar-
chit Somani. 2020. Efficient concurrent execution of smart contracts in
blockchains using object-based transactional memory. In International
Conference on Networked Systems. Springer, 77â€“93.

[8] Parwat Singh Anjana, Sweta Kumari, Sathya Peri, Sachin Rathor, and
Archit Somani. 2021. OptSmart: A Space Efficient Optimistic Concur-
rent Execution of Smart Contracts. arXiv:2102.04875 [cs.DC]

[9] Hagit Attiya and Jennifer Welch. 2004. Distributed computing: fun-
damentals, simulations, and advanced topics. Vol. 19. John Wiley &
Sons.

[10] Philip A Bernstein and Nathan Goodman. 1983. Multiversion concur-
rency controlâ€”theory and algorithms. ACM Transactions on Database
Systems (TODS) 8, 4 (1983), 465â€“483.

[11] Sam Blackshear, Evan Cheng, David L Dill, Victor Gao, Ben Maurer,
Todd Nowacki, Alistair Pott, Shaz Qadeer, Dario Russi Rain, Stephane
Sezer, et al. 2019. Move: A language with programmable resources.
Libra Assoc. (2019).

[12] Edward Bortnikov, Eshcar Hillel, Idit Keidar, Ivan Kelly, Matthieu
Morel, Sameer Paranjpye, Francisco Perez-Sorrosal, and Ohad
Shacham. 2017. Omid, Reloaded: Scalable and {Highly-Available}
Transaction Processing. In 15th USENIX Conference on File and Storage
Technologies (FAST 17). 167â€“180.

[13] Joao Cachopo and AntÃ³nio Rito-Silva. 2006. Versioned boxes as the
basis for memory transactions. Science of Computer Programming 63,
2 (2006), 172â€“185.

[14] Calin Cascaval, Colin Blundell, Maged Michael, Harold W Cain, Peng
Wu, Stefanie Chiras, and Siddhartha Chatterjee. 2008. Software trans-
actional memory: Why is it only a research toy? Commun. ACM 51,
11 (2008), 40â€“46.

[15] Yang Chen, Zhongxin Guo, Runhuai Li, Shuo Chen, Lidong Zhou, Yajin
Zhou, and Xian Zhang. 2021. Forerunner: Constraint-based speculative
transaction execution for ethereum. In Proceedings of the ACM SIGOPS
28th Symposium on Operating Systems Principles. 570â€“587.

[16] Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li, Xueyuan Zhao,
Iddo Bentov, Lorenz Breidenbach, and Ari Juels. 2019. Flash boys 2.0:
Frontrunning, transaction reordering, and consensus instability in
decentralized exchanges. arXiv preprint arXiv:1904.05234 (2019).
[17] Dave Dice, Ori Shalev, and Nir Shavit. 2006. Transactional locking II. In
International Symposium on Distributed Computing. Springer, 194â€“208.
[18] Thomas Dickerson, Paul Gazzillo, Maurice Herlihy, and Eric Koskinen.
2020 (ArXiv version 2017). Adding concurrency to smart contracts.
Distributed Computing 33, 3 (2020 (ArXiv version 2017)), 209â€“225.
[19] Aleksandar DragojeviÄ‡, Pascal Felber, Vincent Gramoli, and Rachid
Guerraoui. 2011. Why STM can be more than a research toy. Commun.
ACM 54, 4 (2011), 70â€“77.

16

[20] Avner Elizarov, Guy Golan-Gueta, and Erez Petrank. 2019. LOFT: lock-
free transactional data structures. In Proceedings of the 24th Symposium
on Principles and Practice of Parallel Programming. 425â€“426.

[21] Jose M Faleiro and Daniel J Abadi. 2015. Rethinking serializable multi-
version concurrency control. Proceedings of the VLDB Endowment 8,
11 (2015), 1190â€“1201.

[22] Pascal Felber, Christof Fetzer, and Torvald Riegel. 2008. Dynamic
performance tuning of word-based software transactional memory. In
Proceedings of the 13th ACM SIGPLAN Symposium on Principles and
practice of parallel programming. 237â€“246.

[23] Rati Gelashvili, Alexander Spiegelman, Zhuolun Xiang, George
Danezis, Zekun Li, Yu Xia, Runtian Zhou, and Dahlia Malkhi. 2022.
Block-STM: Scaling Blockchain Execution by Turning Ordering Curse
to a Performance Blessing. arXiv preprint arXiv:2203.06871 (2022).
[24] Rachid Guerraoui and Michal Kapalka. 2008. On the correctness of
transactional memory. In Proceedings of the 13th ACM SIGPLAN Sym-
posium on Principles and practice of parallel programming. 175â€“184.

[25] Rachid Guerraoui, Michal Kapalka, and Jan Vitek. 2006. Stmbench7: a
benchmark for software transactional memory. Technical Report.
[26] Ahmed Hassan, Roberto Palmieri, and Binoy Ravindran. 2014. Opti-
mistic transactional boosting. In Proceedings of the 19th ACM SIGPLAN
symposium on Principles and practice of parallel programming. 387â€“388.
[27] Danny Hendler, Itai Incze, Nir Shavit, and Moran Tzafrir. 2010. Flat
combining and the synchronization-parallelism tradeoff. In Proceed-
ings of the twenty-second annual ACM symposium on Parallelism in
algorithms and architectures. 355â€“364.

[28] Maurice Herlihy and Eric Koskinen. 2008. Transactional boosting: a
methodology for highly-concurrent transactional objects. In Proceed-
ings of the 13th ACM SIGPLAN Symposium on Principles and practice of
parallel programming. 207â€“216.

[29] Maurice Herlihy and J Eliot B Moss. 1993. Transactional memory:
Architectural support for lock-free data structures. In Proceedings of
the 20th annual international symposium on Computer architecture.
289â€“300.

[30] Nathaniel Herman, Jeevana Priya Inala, Yihe Huang, Lillian Tsai, Eddie
Kohler, Barbara Liskov, and Liuba Shrira. 2016. Type-aware transac-
tions for faster concurrent code. In Proceedings of the Eleventh European
Conference on Computer Systems. 1â€“16.

[31] Hsiang-Tsung Kung and John T Robinson. 1981. On optimistic meth-
ods for concurrency control. ACM Transactions on Database Systems
(TODS) 6, 2 (1981), 213â€“226.

[32] Pierre LaBorde, Lance Lebanoff, Christina Peterson, Deli Zhang, and
Damian Dechev. 2019. Wait-free dynamic transactions for linked
data structures. In Proceedings of the 10th International Workshop on
Programming Models and Applications for Multicores and Manycores.
41â€“50.

[33] Paul E McKenney and John D Slingwine. 1998. Read-copy update:
Using execution history to solve concurrency problems. In Parallel
and Distributed Computing and Systems, Vol. 509518.

[34] Mojtaba Mehrara, Jeff Hao, Po-Chun Hsu, and Scott Mahlke. 2009.
Parallelizing sequential applications on commodity hardware using a
low-cost software transactional memory. ACM Sigplan Notices 44, 6
(2009), 166â€“176.

[35] John Eliot Blakeslee Moss. 1981. Nested Transactions: An Approach to
Reliable Distributed Computing. Technical Report. MASSACHUSETTS
INST OF TECH CAMBRIDGE LAB FOR COMPUTER SCIENCE.
[36] Donald Nguyen, Andrew Lenharth, and Keshav Pingali. 2014. De-
terministic Galois: On-demand, portable and parameterless. ACM
SIGPLAN Notices 49, 4 (2014), 499â€“512.

[37] Dmitri Perelman, Rui Fan, and Idit Keidar. 2010. On maintaining
multiple versions in STM. In Proceedings of the 29th ACM SIGACT-
SIGOPS symposium on Principles of distributed computing. 16â€“25.

[38] Kaushik Ravichandran, Ada Gavrilovska, and Santosh Pande. 2014.
DeSTM: harnessing determinism in STMs for application develop-
ment. In Proceedings of the 23rd international conference on Parallel
architectures and compilation. 213â€“224.

[39] Torvald Riegel, Pascal Felber, and Christof Fetzer. 2006. A lazy snap-
shot algorithm with eager validation. In International Symposium on
Distributed Computing. Springer, 284â€“298.

[40] Hamza Rihani, Peter Sanders, and Roman Dementiev. 2015. Multi-
queues: Simple relaxed concurrent priority queues. In Proceedings of
the 27th ACM symposium on Parallelism in Algorithms and Architectures.
80â€“82.

[41] Pingcheng Ruan, Dumitrel Loghin, Quang-Trung Ta, Meihui Zhang,
Gang Chen, and Beng Chin Ooi. 2020. A transactional perspective on
execute-order-validate blockchains. In Proceedings of the 2020 ACM
SIGMOD International Conference on Management of Data. 543â€“557.

[42] Mohamed M Saad, Masoomeh Javidi Kishi, Shihao Jing, Sandeep Hans,
and Roberto Palmieri. 2019. Processing transactions in a predefined
order. In Proceedings of the 24th Symposium on Principles and Practice
of Parallel Programming. 120â€“132.

[43] Ankur Sharma, Felix Martin Schuhknecht, Divya Agrawal, and Jens
Dittrich. 2019. Blurring the lines between blockchains and database
systems: the case of hyperledger fabric. In Proceedings of the 2019
International Conference on Management of Data. 105â€“122.

[44] Nir Shavit and Dan Touitou. 1997. Software transactional memory.

Distributed Computing 10, 2 (1997), 99â€“116.

[45] Julian Shun, Guy E Blelloch, Jeremy T Fineman, Phillip B Gibbons,
Aapo Kyrola, Harsha Vardhan Simhadri, and Kanat Tangwongsan.
2012. Brief announcement: the problem based benchmark suite. In
Proceedings of the twenty-fourth annual ACM symposium on Parallelism
in algorithms and architectures. 68â€“70.

[46] Alexander Spiegelman, Guy Golan-Gueta, and Idit Keidar. 2016. Trans-
actional data structure libraries. ACM SIGPLAN Notices 51, 6 (2016),
682â€“696.

[47] The DiemBFT Team. 2021. State machine replication in the Diem
Blockchain. https://developers.diem.com/docs/technical-papers/state-
machine-replication-paper.

[48] Alexander Thomson, Thaddeus Diamond, Shu-Chun Weng, Kun Ren,
Philip Shao, and Daniel J. Abadi. 2012. Calvin: Fast Distributed Trans-
actions for Partitioned Database Systems. In SIGMOD.

[49] Tiago M Vale, JoÃ£o A Silva, Ricardo J Dias, and JoÃ£o M LourenÃ§o.
2016. Pot: Deterministic transactional execution. ACM Transactions
on Architecture and Code Optimization (TACO) 13, 4 (2016), 1â€“24.
[50] Christoph Von Praun, Luis Ceze, and Calin CaÅŸcaval. 2007. Implicit
parallelism with ordered transactions. In Proceedings of the 12th ACM
SIGPLAN symposium on Principles and practice of parallel programming.
79â€“89.

[51] Maximilian Wohrer and Uwe Zdun. 2018. Smart contracts: security
patterns in the ethereum ecosystem and solidity. In 2018 International
Workshop on Blockchain Oriented Software Engineering (IWBOSE). IEEE,
2â€“8.

[52] Yu Xia, Xiangyao Yu, William Moses, Julian Shun, and Srinivas De-
vadas. 2019. LiTM: A Lightweight Deterministic Software Transac-
tional Memory System. In Proceedings of the 10th International Work-
shop on Programming Models and Applications for Multicores and Many-
cores. 1â€“10.

17

A Correctness
We consider concurrent runs5 by threads, where each thread
performs a sequence of atomic operations, and there is a
global order in which these operations appear to take place.
We use the term time to refer to a point in this global order,
i.e. a time ğ‘‡ determines for each thread the operations that
it performed before ğ‘‡ .

A.1 Life of a Version
We say that validation of version ğ‘£ = ( ğ‘—, ğ‘–) starts anytime
a validation task with version ğ‘£ is returned to some thread
ğ‘¡, either in Line 5 or in Line 9. We say execution of version
ğ‘£ starts immediately after Line 114 is performed that sets
the status of transaction ğ‘¡ğ‘¥ ğ‘— to EXECUTING(i). We say that
the execution of version ğ‘£ aborts immediately after Line 151
is performed, and that the validation of version ğ‘£ aborts
immediately after Line 179 is performed. In both cases, the
transaction status is set to ABORTING(i).

After thread ğ‘¡ starts the execution of version ğ‘£, an exe-
cution task with ğ‘£ is returned either in Line 7 or in Line 9.
Thread ğ‘¡ then invokes the try_execute function for the
execution task, which may invoke finish_execution pro-
cedure in Line 19. The finish_execution function is not
called only when the execution aborts, in which case we say
the execution finishes at the same time when it aborts. Simi-
larly, after a validation starts, ğ‘¡ invokes needs_reexecution
function for the validation task, which always invokes
finish_validation procedure in Line 26.

If Line 174 (for execution) or Line 190 (for validation)
is performed, then the corresponding validation or execu-
tion finishes immediately before. If these lines are not per-
formed in finish_execution and in finish_validation,
respectively, then the finish_execution invocation returns
a validation task and the finish_validation invocation
returns an execution task. We say that such an execution
finishes immediately before the try_execute invocation re-
turns in Line 5 (i.e. before validation starts for the version
in the returned task). Analogously, such a validation fin-
ishes immediately before a needs_reexecution invocation
returns in Line 7 (i.e. before execution starts for the version
in the returned task).

An update to a transaction status is always performed
by a thread while holding the corresponding lock. Figure 2
describes all possible status transitions. For example, once
txn_status[j] becomes EXECUTING(i), it can never be
READY_TO_EXECUTE(i) at a later time. By the code, illus-
trated in the allowable transitions in Figure 2, we have

Corollary 1. The following observations are true:
â€¢ The status of transaction ğ‘¡ğ‘¥ ğ‘— must be set to

READY_TO_EXECUTE(i) in Line 158 before the execution
of the version ğ‘£ = ( ğ‘—, ğ‘–) can start.

5Typically called executions in the literature, but we use the term run to
avoid a naming clash with transaction execution.

â€¢ Any version ğ‘£ = ( ğ‘—, ğ‘–) can be executed at most once
(by a thread that updates the status of transaction ğ‘¡ğ‘¥ ğ‘— to
EXECUTING(i) from READY_TO_EXECUTE(i) to start the
execution of ğ‘£). Only the executing thread may update
the status next, either to ABORTING(i) in Line 151 or to
EXECUTED(i) in Line 166.

â€¢ The status of transaction ğ‘¡ğ‘¥ ğ‘— must be set to EXECUTED(i)
in Line 166 during the execution of version ğ‘£ = ( ğ‘—, ğ‘–)
before any validation of ğ‘£ can start. Once the status is set
to EXECUTED(i), it can only be updated to ABORTING(i)
in Line 179 during a validation of ğ‘£.

â€¢ At most one execution or validation of version ğ‘£ = ( ğ‘—, ğ‘–)
can abort, updating the status to ABORTING(i) either
in Line 151 from EXECUTING(i) or in Line 179 from
EXECUTED(i). The next update to the status of transac-
tion ğ‘¡ğ‘¥ ğ‘— must be to READY_TO_EXECUTE(i + 1) in Line 158.

A.2 Safety
We say that a pre-validation of transaction ğ‘¡ğ‘¥ ğ‘— starts any
time some thread ğ‘¡ performs a fetch_and_increment oper-
ation, returning ğ‘—, in Line 130. The pre-validation finishes
immediately before ğ‘¡ performs Line 135, if this line is per-
formed. Otherwise, by code, a validation task for transaction
ğ‘¡ğ‘¥ ğ‘— is returned from the
next_version_to_validate function invocation. In this
case, pre-validation finishes immediately before the valida-
tion task is returned in Line 9, i.e. before the corresponding
validation starts.

Definition 1 (Global Commit Index). The global commit
index at time ğ‘‡ is defined as the minimum among all the
following quantities at time ğ‘‡ :
â€¢ Scheduler.validation_idx
â€¢ all indices ğ‘—, such that Scheduler.txn_status[j].status â‰ 

EXECUTED

â€¢ transaction indices with ongoing pre-validation
â€¢ transaction indices of versions with ongoing execution

or validation

We say that transactions ğ‘¡ğ‘¥0, . . . , ğ‘¡ğ‘¥ğ‘˜ of the block are glob-
ally committed at time ğ‘‡ if the global commit index at time
ğ‘‡ is strictly greater than ğ‘˜. Next, we prove the essential
properties of the commit definition.

Claim 1. If transaction ğ‘¡ğ‘¥ğ‘˜ is committed at time ğ‘‡ , then it is
also committed at all times ğ‘‡ â€² â‰¥ ğ‘‡ .
Proof. We prove this claim by a simple inductive reasoning
on time. Specifically, for every time ğ‘‡ â€² â‰¥ ğ‘‡ we prove that
ğ‘˜ is strictly less than the global commit index at time ğ‘‡ â€².
The base case for time ğ‘‡ follows from the Claim assumption.
For the inductive step, we suppose the assumption holds at
time ğ‘‡ â€² and show that the Definition 1 still leads to a global
commit index > ğ‘˜ when the next event after ğ‘‡ â€² takes effect.
â€¢ The operation may change validation index from time
ğ‘‡ â€² only in Line 104, which can be due to a call in Line 171

18

(during finish_execution) or in Line 185 (during
finish_validation). In the first case, if validation_idx
is reduced to value ğ‘—, there must be an ongoing execu-
tion with transaction index ğ‘— at time ğ‘‡ â€². In the second
case, there must be an ongoing validation with transac-
tion index ğ‘— at timeğ‘‡ â€². Thus, in both cases, by inductive
hypothesis, ğ‘— > ğ‘˜.

â€¢ The operation may change a status of transaction ğ‘¡ğ‘¥ ğ‘—
from EXECUTED only in Line 179, in which case there
is an ongoing validation with transaction index ğ‘— at
time ğ‘‡ â€². Thus, by inductive hypothesis, ğ‘— > ğ‘˜.

â€¢ A fetch-and-increment operation in Line 130 may start
a pre-validation of transaction ğ‘¡ğ‘¥ ğ‘— . The validation_idx
must have been ğ‘— at time ğ‘‡ â€² and by inductive hypoth-
esis, ğ‘— > ğ‘˜.

â€¢ If validation of a version ğ‘£ with transaction index ğ‘—
starts immediately after ğ‘‡ â€², then there must have been
a pre-validation or an execution of version ğ‘£ that ended
immediately before, hence, that was ongoing at time
ğ‘‡ â€². Thus, by inductive hypothesis, ğ‘— > ğ‘˜.

â€¢ If an execution of a version ğ‘£ with transaction index ğ‘—
starts immediately after ğ‘‡ â€², then let us consider two
cases:
â€“ if an execution task was returned in Line 7, then
there was a validation of a version with index ğ‘— (pre-
vious incarnation) that ended immediately before,
and hence, was ongoing at time ğ‘‡ â€². Thus, by induc-
tive hypothesis, ğ‘— > ğ‘˜.

â€“ if an execution task was returned to some thread ğ‘¡
in Line 9, then, by the code, the status of transac-
tion ğ‘¡ğ‘¥ ğ‘— must have been previously set to EXECUTING
by ğ‘¡. By Corollary 1, the status of transaction ğ‘¡ğ‘¥ ğ‘—
may not change to EXECUTED until ğ‘¡ starts the exe-
cution. Thus, since the status of transaction ğ‘¡ğ‘¥ ğ‘— is
not EXECUTED at time ğ‘‡ â€², by inductive hypothesis,
ğ‘— > ğ‘˜.

Hence, the global commit index is monotonically non-
â–¡

decreasing with time.

Next, we prove some auxiliary claims regarding the inter-
play between transaction status and shared (execution and
validation) indices.

Claim 2. Suppose all transactions are eventually committed,
and that at all times after ğ‘‡ the status of transaction ğ‘¡ğ‘¥ ğ‘— is
EXECUTED. If no validation of a version of ğ‘¡ğ‘¥ ğ‘— starts after ğ‘‡ ,
then the validation index must be > ğ‘— at all times after ğ‘‡ .

Proof. Let us assume for contradiction that validation_idx
is at most ğ‘— at some time ğ‘‡ â€² â‰¥ ğ‘‡ . Since all transactions
are eventually committed and due to Claim 1, validation_idx
must have value BLOCK.size() > ğ‘— at some time after ğ‘‡ â€². The
validation index is only incremented in Line 130, which is by
definition a start of pre-validation. Therefore, transaction ğ‘¡ğ‘¥ ğ‘—
must start pre-validation after ğ‘‡ â€², and pre-validation must

19

finish due to Definition 1 since all transactions are eventually
committed. By the claim assumption, transaction ğ‘¡ğ‘¥ ğ‘— â€™s status
is EXECUTED, so by code (due to Line 133), pre-validation
finish must lead to a start of a validation of a version of ğ‘¡ğ‘¥ ğ‘— ,
â–¡
giving the desired contradiction.

Claim 3. Suppose all transactions are eventually committed,
and ğ‘– is the highest incarnation of transaction ğ‘¡ğ‘¥ ğ‘— such that
version ğ‘£ = ( ğ‘—, ğ‘–) is executed. Then, ğ‘£ must start validation
after Line 166 is performed in the execution of ğ‘£.
Proof. The execution of version ğ‘£ sets the status of trans-
action ğ‘¡ğ‘¥ ğ‘— to EXECUTED(i) in Line 166. The execution of
ğ‘£ eventually finishes due to Definition 1 and Claim 1, as
transaction ğ‘¡ğ‘¥ ğ‘— eventually commits. If a validation task is
returned in Line 173, then a validation of version ğ‘£ starts
immediately after execution finishes. Otherwise, by Corol-
lary 1, the status of transaction ğ‘¡ğ‘¥ ğ‘— will remain EXECUTED(i)
unless it is updated to ABORTING(i) by some validation of
ğ‘£, which also concludes the proof of the claim. If the status
remains EXECUTED(i) and a validation task is not returned,
then validation index has a value at most ğ‘— after the status up-
date in Line 166 due to Line 169 and Line 171. Then, Claim 2
implies that a validation must start after Line 166 is per-
â–¡
formed.

Next, we establish the correctness invariant of the com-
mitted transactions. When we refer to a sequential run of
all transactions, we mean the execution of transaction ğ‘¡ğ‘¥0,
followed by the execution of transaction ğ‘¡ğ‘¥1, etc, for all trans-
actions in the block.
Lemma 1. After all transactions are committed, MVMemory
contains exactly the paths written in the sequential run of all
transactions. Moreover, a read of a path from MVMemory
with txn_idx = BLOCK.size() returns the same value as the
contents of the path after the sequential run.
Proof. Suppose all transactions are eventually committed.
Since initial status for each transaction is READY_TO_EXECUTE,
while Definition 1 requires status EXECUTED, by the code, for
each transaction ğ‘¡ğ‘¥ ğ‘— the version ( ğ‘—, 0) must start executing at
some point. Also, due to the commit definition and Claim 1,
all executions that start must finish (in order for the trans-
actions to eventually be committed). In fact, by Claim 1 the
total number of executions, validations and pre-validations
must be finite and they must all finish. For each transaction
index ğ‘—, let ğ‘š ğ‘— the the highest incarnation for which there
is an execution of version ( ğ‘—, ğ‘š ğ‘— ). By Corollary 1, among
the versions of transaction ğ‘¡ğ‘¥ ğ‘— that are executed, version
( ğ‘—, ğ‘š ğ‘— ) is executed last. We show by induction on ğ‘— that the
execution of version ( ğ‘—, ğ‘š ğ‘— ) reads the same paths and values
from MVMemory as the execution of transaction ğ‘¡ğ‘¥ ğ‘— would
during the sequential run. Thus, at the end of version ( ğ‘—, ğ‘š ğ‘— )
execution, all entries with transaction index ğ‘— in MVMemory
also correspond to the same paths and contain the same val-
ues as the write-set in the sequential run.

The base case holds because every read with txn_idx = 0
reads from storage. Next, suppose the inductive claim holds
for transactions ğ‘¡ğ‘¥0, . . . , ğ‘¡ğ‘¥ğ‘˜ . By Claim 3, version ğ‘£ğ‘˜+1 =
(ğ‘˜ + 1, ğ‘šğ‘˜+1) is validated at least once after Line 166 is per-
formed during ğ‘£ğ‘˜+1â€™s (unique, by Corollary 1) execution. Any
validation of ğ‘£ğ‘˜+1 that starts also finishes in order for the
global commit index to reach values above ğ‘˜ + 1. Finally,
no validation of version ğ‘£ğ‘˜+1 may abort, as this would set
txn_status[k+1] to an ABORTING status and prevent global
commit index from reaching BLOCK.size() without another
incarnation of transaction ğ‘¡ğ‘¥ğ‘˜+1, contradicting the maximal-
ity of ğ‘šğ‘˜+1. Therefore, we only need to show that a value read
at any access path during the validation of ğ‘£ğ‘˜+1 is the same
as in the sequential run of transaction ğ‘¡ğ‘¥ğ‘˜+1. Then, since the
validation must succeed, the execution of ğ‘£ğ‘˜+1 must have
read the same values, and produced a compatible output to
the sequential run, proving the inductive step.

Let ğ›¼ be the validation of ğ‘£ğ‘˜+1 that starts last. Let ğ‘ be any
path read during ğ›¼, and let ğ‘£ğ‘ be the corresponding version
observed during the validate_read_set invocation that
returned true (if the read returned a READ_ERROR in Line 67
then ğ›¼ would fail). If ğ‘£ğ‘ = âŠ¥, then validation ğ›¼, and the cor-
responding execution of version ğ‘£ğ‘˜+1 both read from storage.
If ğ‘£ğ‘ is a version of some transaction ğ‘¡ğ‘¥ ğ‘— , since MVMemory
only reads values from lower transactions, we have ğ‘— < ğ‘˜ + 1.
Version ğ‘£ğ‘ is written during a record call invoked in Line 18
during an execution that sets the status of transaction ğ‘¡ğ‘¥ ğ‘— to
an EXECUTED status before finishing. We show this must have
been the last execution of ğ‘¡ğ‘¥ ğ‘— using a proof by contradiction.
Otherwise, by Corollary 1, a validation ğ›½ of the same version
of ğ‘¡ğ‘¥ ğ‘— must follow and abort. Thus, by code, before finishing,
ğ›½ marks path ğ‘ as an ESTIMATE, after it is read by ğ›¼. The
validation_idx is then ensured to be at most ğ‘— in Line 185 in
ğ›½, contradicting Claim 2 (Due to Claim 3 the status of trans-
action ğ‘¡ğ‘¥ğ‘˜+1 is set to EXECUTED(mk+1) in Line 166 during the
execution of ğ‘£ğ‘˜+1, before ğ›¼ starts. Since no validation of ğ‘£ğ‘˜+1
aborts, by Corollary 1, txn_status[k+1] never changes from
EXECUTED).

Hence, if ğ‘£ğ‘ is a version of ğ‘¡ğ‘¥ ğ‘— , then the value read from
ğ‘ is in fact the value written at path ğ‘ during the execution
of the last ğ‘¡ğ‘¥ ğ‘— â€™s version ( ğ‘—, ğ‘š ğ‘— ). By the induction hypothesis,
this is the same value that transaction ğ‘¡ğ‘¥ ğ‘— writes at ğ‘ in
the fully sequential run. To finish the proof, suppose for
contradiction that in the sequential run transaction ğ‘¡ğ‘¥ğ‘˜+1
reads a value written by transaction ğ‘¡ğ‘¥ ğ‘— â€² with ğ‘— â€² > ğ‘—. The
validation ğ›¼ did not observe any entry from ğ‘— â€² at path ğ‘,
not even an ESTIMATE. However, by induction hypothesis,
during the execution of version ( ğ‘— â€², ğ‘š ğ‘— â€²) the same value as in
the sequential run must be written to path ğ‘. Therefore, after
a read by ğ›¼, there is an execution of a version of transaction
ğ‘¡ğ‘¥ ğ‘— â€² that sets wrote_new_path to true due to ğ‘ and decreases
validation index by calling Line 171. This again contradicts
our assumption about ğ›¼ and completes the proof, as the

20

argument when ğ‘£ğ‘ = âŠ¥ instead of ğ‘£ğ‘ = ( ğ‘—, ğ‘š ğ‘— ) is analogous.
â–¡

A.2.1 Number of Active Tasks. What is left is to show
is the safety of the check_done mechanism for determin-
ing when the transactions are committed. The key is to un-
derstand the role of the num_active_tasks variable in the
Scheduler module. The num_active_tasks is initialized to 0
and incremented in Line 122 and Line 129. The increment
in Line 129 is accounting for the pre-validation that starts
with a fetch-and-increment in the following line (Line 130).
The num_active_tasks is decremented in Line 135 if no val-
idation task corresponding to the fetched index is created.
Otherwise, pre-validation leads to a the start of a validation,
and num_active_tasks is decremented immediately after the
validation finishes, in Line 190 (unless an execution task
is created for the caller). The logic for execution tasks is
analogous, with one difference that an execution can also
finish in Line 151, in which case num_active_tasks is decre-
mented shortly after, in Line 153. When finish_execution
or finish_validation functions return a new task to the
caller, num_active_tasks is left unchanged (instead of incre-
menting and decrementing that cancel out). It follows that
num_active_tasks is always non-negative. The following aux-
iliary claims establish useful properties of when the value
becomes 0.

Claim 4. Suppose the status of transaction ğ‘¡ğ‘¥ ğ‘— was set to
READY_TO_EXECUTE at time ğ‘‡ , and did not change until a later
time ğ‘‡ â€². If execution index was at most ğ‘— at some time between
ğ‘‡ and ğ‘‡ â€², then either num_active_tasks > 0 or execution_idx
â‰¤ ğ‘— at time ğ‘‡ â€².

Proof. Let as assume for contradiction that at time ğ‘‡ â€²
num_active_tasks is 0 and execution_idx is strictly larger than
ğ‘—, but that at some time between ğ‘‡ and ğ‘‡ â€², the execution
index was at most ğ‘—. Since execution index reaches a value
larger than ğ‘— by time ğ‘‡ â€², a fetch-and-increment operation
must have been performed in Line 123 between ğ‘‡ and ğ‘‡ â€²,
returning ğ‘—. The num_active_tasks counter is incremented
in the previous line, in Line 122 (this is very similar to the
increment to account for pre-validation, while here it is an
analogous pre-execution stage). Since the status is of transac-
tion ğ‘¡ğ‘¥ ğ‘— remains READY_TO_EXECUTE until ğ‘‡ â€², the only way
to reduce num_active_tasks to 0 at time ğ‘‡ â€² is to perform
the corresponding decrement, which by code, would occur
only after an execution of a version of transaction ğ‘¡ğ‘¥ ğ‘— (due
to Line 113). However, before an execution finishes (and then
num_active_tasks is decremented), it must perform Line 113
and since the status of transaction ğ‘¡ğ‘¥ ğ‘— is READY_TO_EXECUTE,
it must update the status to EXECUTING in Line 114, giving
the desired contradiction with assumption in the claim. â–¡

Lemma 2. Suppose execution_idx â‰¥ BLOCK.size(), valida-
tion_idx â‰¥ BLOCK.size() and num_active_tasks is 0 simul-
taneously at time ğ‘‡ . Then, all transactions are committed at
time ğ‘‡ .

Proof. As num_active_tasks is 0 at time ğ‘‡ , there may not be
an ongoing pre-validation, validation or execution at time ğ‘‡ .
This is because an increment corresponding of num_active_tasks
always occurs before the start, while the decrement always
occurs after the finish of the corresponding pre-validation,
validation or execution. Next, we will prove that for any
transaction index ğ‘—, Scheduler.txn_status[j].status = EXECUTED
at time ğ‘‡ . Then, by Definition 1, the global commit index is
equal to the validation_index, which is at least BLOCK.size(),
meaning that all transactions are committed at time ğ‘‡ .

In the following, we prove by contradiction that all trans-
actions must have an EXECUTED status at time ğ‘‡ . Suppose ğ‘—
is the smallest index of a transaction with a non-EXECUTED
status. Consider three cases:

â€¢ Scheduler.txn_status[j].status = READY_TO_EXECUTE.
We consider the time when the READY_TO_EXECUTE
status was last set for transaction ğ‘¡ğ‘¥ ğ‘— in Line 113. This
is due to a call either in Line 161 or in Line 184.
â€“ Call in Line 161: there is an ongoing execution, which
must finish in order for num_active_tasks to be 0 at
time ğ‘‡ . Before finishing,
the decrease_execution_idx invocation in Line 164
ensures that the execution index has a value at most
ğ‘—. Thus, by Claim 4, the execution index is at most ğ‘—
at time ğ‘‡ . A contradiction.

â€“ Call in Line 184: there is an ongoing validation which
must finish in order for num_active_tasks to be 0
at time ğ‘‡ . Before finishing, execution_idx must be
observed in Line 186 to be strictly higher than ğ‘—, or
we would get a contradiction with Claim 4. But then,
try_incarnate must be called in Line 187, which
by code, would observe READY_TO_EXECUTE status
and update it to EXECUTING, contradicting the status
at time ğ‘‡ .

â€¢ Scheduler.txn_status[j].status = EXECUTING. By Corol-
lary 1 and the definition of execution, there must be an
ongoing execution at time ğ‘‡ (of a version of ğ‘¡ğ‘¥ ğ‘— by the
thread that set the status), which we already showed
is impossible.

â€¢ Scheduler.txn_status[j].status = ABORTING. Let ğ‘‡ â€² be
the time when the ABORTING status was last set for
transaction ğ‘¡ğ‘¥ ğ‘— , which can be in Line 151 or in Line 179.
â€“ call in Line 151 in an add_dependency invocation:
in this case, txn_idx must be ğ‘— and the thread must
be holding a lock on the status of a blocking_txn_idx,
which we will call ğ‘— â€². Because MVMemory only
reads entries, including an ESTIMATE, from lower
transactions, and reading an ESTIMATE is required
for calling the add_dependency function, we have

21

ğ‘— â€² < ğ‘—. Since Line 151 was performed, due to the
check in Line 149, the status of transaction ğ‘¡ğ‘¥ ğ‘— â€² can-
not be EXECUTED, but by the minimality of ğ‘¡ğ‘¥ ğ‘— it must
be EXECUTED at time ğ‘‡ . Therefore, an execution of a
version of ğ‘¡ğ‘¥ ğ‘— â€² must invoke Line 166 between times
ğ‘‡ â€² and ğ‘‡ . This execution must finish in order for
num_active_tasks to be 0 at time ğ‘‡ , meaning that
resume_dependencies invocation in Line 168 must
be completed before ğ‘‡ . However, due to locks, ğ‘¡ğ‘¥ ğ‘— is
now a dependency of ğ‘¡ğ‘¥ ğ‘— â€², and this resume_dependencies
invocation must update the status of transaction ğ‘¡ğ‘¥ ğ‘—
to
READY_TO_EXECUTE due to the call in Line 161, con-
tradicting the status at time ğ‘‡ .

â€“ call in Line 179: there is an ongoing validation which
must finish in order for num_active_tasks to be 0 at
time ğ‘‡ . Before finishing, the status must be updated
to READY_TO_EXECUTE due to the call in Line 184,
â–¡
contradicting the status at time ğ‘‡ .

A.2.2 Safety Guarantees.

Lemma 3. Let time ğ‘‡ be right before the operation in Line 99
or operation in Line 104 by thread ğ‘¡ takes effect. Suppose
num_active_tasks is 0 at some time ğ‘‡ â€² â‰¥ ğ‘‡ . Then, thread ğ‘¡
must have incremented decrease_cnt (in Line 100 or in Line 105)
between times ğ‘‡ and ğ‘‡ â€².

Proof. Performing Line 99 as a part of
decrease_execution_idx reduces execution_idx to the min-
imum of execution_idx and target_idx, while performing Line 104
as a part of decrease_validation_idx is similar for the
validation_idx. The decrease_execution_idx procedure is
invoked only in Line 164 as a part of an ongoing execu-
tion, and accounting for this execution, num_active_task
must be at least 1 during the whole invocation. Hence, in
order for num_active_tasks to become 0, it must be decre-
mented after the execution completes. Thus, ğ‘¡ must first
complete decrease_execution_idx, which includes per-
forming Line 100.

The decrease_validation_idx procedure is invoked ei-
ther as a part of validation that aborts, or as a part of exe-
cution when wrote_new_path is true in finish_execution.
In both cases, num_active_tasks is at least 1 accounting for
the ongoing validation or execution, since both finish after
decrease_validation_idx invocation completes. Hence,
in order for num_active_tasks to become 0, by code, ğ‘¡ must
decrement it after it finishes execution of validation. How-
ever, before doing so, it must perform Line 105 and return
â–¡
from the decrease_validation_idx invocation.

Theorem 1. If a thread joins after invoking the run procedure,
then all transactions are necessarily committed at that time.

Proof. The threads return from the run invocation when they
observe a done_marker = true in Line 102. The done_marker

is set to true in Line 109 after observing that validation_idx â‰¥
BLOCK_SIZE, execution_idx â‰¥ BLOCK_SIZE and num_active_tasks
is 0. These checks are not performed atomically, but instead
a double-collect mechanism is used on the decrease_count
variable, which is a monotonically non-decreasing counter.
In particular, check_done confirms that decrease_count did
not change (increase) while execution_idx, validation_index
and num_active_tasks were read.

Since a thread joined, decrease_count did not increase
while it first observed execution_idx to be at least BLOCK_SIZE
at timeğ‘‡1, then observed validation_idx to be at least BLOCK_SIZE
at time ğ‘‡2 > ğ‘‡1, and finally observed num_active_tasks to be 0
at timeğ‘‡3 > ğ‘‡2. We show by contradiction that num_active_tasks
was 0 and execution_idx and validation_idx were still at least
BLOCK.size() simultaneously at ğ‘‡3. Assume by contradic-
tion that ğ‘‡3 does not have this property. Thus, execution_idx
must be decreased between ğ‘‡1 and ğ‘‡3 or validation_idx must
be decreased between ğ‘‡2 and ğ‘‡3. In both cases, we can ap-
ply Lemma 3, implying that decrease_count must have been
incremented between ğ‘‡1 and ğ‘‡3, giving the desired contra-
diction.

Therefore, check_done only succeeds if the number of
active tasks is 0 while the execution index and the valida-
tion index are both at least BLOCK.size() at the same time.
By Lemma 2 and, all transactions must be committed at this
â–¡
time.

The MVMemory.snapshot function internally calls read
with txn_id = BLOCK.size() for all affected paths. By The-
orem 1 all transactions are committed after a thread joins,
so Lemma 1 implies the following

Corollary 2. A call to MVMemory.snapshot() after a thread
joins returns the exact same values at exact same paths as
would be persisted at the end of a sequential run of all trans-
actions.

A.3 Liveness
We prove liveness under the assumption that every thread
keeps taking steps until it joins6 and that the VM.execute
is wait-free. We start by formally defining pre-execution in
an analogous fashion to pre-validation. A pre-execution of
a transaction ğ‘¡ğ‘¥ ğ‘— starts any time some thread ğ‘¡ performs a
fetch_and_increment operation, returning ğ‘—, in Line 123. The
pre-execution finishes immediately before ğ‘¡ performs Line 116,
if this line is performed. Otherwise, by code, an execution
task for transaction ğ‘¡ğ‘¥ ğ‘— is returned from the
next_version_to_execute function invocation. In this case,
pre-execution finishes immediately before the execution task
is returned in Line 9, i.e. before the corresponding execution
starts.

6A standard assumption used to prove deadlock-freedom and starvation-
freedom of algorithms, which are equivalent in our, single-shot, setting.

22

Lemma 4. There are finitely many pre-executions, executions,
pre-validations and validations.

Proof. We prove the lemma by induction on transaction in-
dex, with a trivial base case (no pre-execution, execution, pre-
validation or validation occurs for transactions with indices
< 0). For the inductive step, show that for any transaction
index ğ‘˜ there are finitely many associated pre-executions,
pre-validations, executions or validations. For the inductive
hypothesis, we only assume that there are finitely many exe-
cutions and validations for versions of transactions indexed
< ğ‘˜. It implies that after some finite time ğ‘‡ :

(a) the execution index is never updated to a value â‰¤ ğ‘˜
in Line 99. The decrease_execution_idx procedure
is only called in Line 164 as a part of an ongoing exe-
cution of some transaction ğ‘¡ğ‘¥ ğ‘— when execution index
is reduced to the minimum index of other transactions
that depend on ğ‘¡ğ‘¥ ğ‘— , all of which must have index > ğ‘—
(as only higher-indexed transactions could have read
from MVMemory an ESTIMATE written during ğ‘¡ğ‘¥ ğ‘— â€™s
execution and become a dependency).

(b) the entries in MVMemory for transactions indexed
lower than ğ‘˜ never change. This holds because
MVMemory.record invocation in Line 18 that affects
entries with transaction index ğ‘—, is, as defined, a part
of transaction ğ‘¡ğ‘¥ ğ‘— â€™s execution.

Due to (a), only one pre-execution of transaction ğ‘¡ğ‘¥ğ‘˜ may
start after time ğ‘‡ , so there are finitely many pre-executions
for ğ‘¡ğ‘¥ğ‘˜ in total. Next, we show that there is at most one vali-
dation of a version of ğ‘¡ğ‘¥ğ‘˜ that aborts after time ğ‘‡ . If such a
version exists, let (ğ‘˜, ğ‘–) be the first version that aborts after
ğ‘‡ . Due to Corollary 1, version (ğ‘˜, ğ‘–) may not abort more than
once, and after it aborts, an execution of version (ğ‘˜, ğ‘–+1) must
complete before any validation of version (ğ‘˜, ğ‘– +1) (or higher)
starts. However, no validation of version (ğ‘˜, ğ‘– + 1) may abort,
since by (b), the entries associated with transaction indices
strictly smaller than ğ‘˜ no longer change in the multi-version
data-structure, i.e. MVMemory.validate_read_set for a
version whose execution started after ğ‘‡ necessarily returns
true in Line 22. Thus, after some finite time no execution of
a version of transaction ğ‘¡ğ‘¥ğ‘˜ may start, as this only happens
either following a pre-execution or a validation that aborts.
Moreover, we can now show that similar to (a) for the exe-
cution index, after some finite time, the validation index can
never be reduced to a value â‰¤ ğ‘˜ in Line 104. This is because
the decrease_validation_idx procedure is either called
in Line 171, when the validation_idx may be reduced to ğ‘— as
a part of a transaction ğ‘¡ğ‘¥ ğ‘— â€™s ongoing execution, or it is called
in Line 185, when the validation index may be reduced to
ğ‘— + 1 as a part of a transaction ğ‘¡ğ‘¥ ğ‘— â€™s ongoing validation.

Therefore, there are finitely many pre-validations of trans-
action ğ‘¡ğ‘¥ğ‘˜ and as a result, no validation of a version of ğ‘¡ğ‘¥ğ‘˜
may start after some finite time. This is because a validation
starts either following a pre-validation, or an execution of

by Claim 5, and by code there is no other potential wait-
ing involved in pre-execution, pre-validation, execution or
â–¡
validation.

Theorem 2. If threads keep taking steps before they join and
VM.execute is wait-free, then all threads eventually join.
Proof. For contradiction, suppose some thread never joins.
By the theorem assumption, the thread keeps taking steps
and by Claim 5, it acquires all required locks within finitely
many steps. Moreover, since the VM.execute function is
wait-free, by Corollary 3, after some finite time there can
be no ongoing pre-execution, pre-validation, execution or
validation. By code, the thread in this case must keep repeat-
edly entering the loop in Line 3 and invoking next_task
in Line 9, while both the execution index and the validation
index are always â‰¥ BLOCK.size - otherwise, a pre-execution
or pre-validation would commence.

Since decrease_execution_idx and decrease_validation_idx

procedures are only invoked as a part of an ongoing execu-
tion or validation, respectively, after some finite time, this
counter remains unchanged. Finally, by the mechanism that
counts the active tasks, described in Section A.2.1, num_active_tasks
counts ongoing pre-executions, pre-validations, executions
and validations. By code and since all threads keep taking
steps before they join, the counter is always decremented
after these finish. Since by Lemma 4, all pre-executions, pre-
validations, executions and validations eventually finish, af-
ter some finite time the num_active_tasks counter must al-
ways be 0.

The thread that repeatedly invokes next_task must also
repeatedly call check_done procedure. However, by the above,
after some finite time it must set the done_marker to true
in Line 109. However, the next time the thread reaches Line 3,
it will not enter the loop and join, proving the theorem by
â–¡
contradiction.

a version of ğ‘¡ğ‘¥ğ‘˜ . As there are finitely many threads, we ob-
tain that there are finitely many total pre-validations and
pre-executions of transaction ğ‘¡ğ‘¥ğ‘˜ , as well as executions and
â–¡
validations versions of ğ‘¡ğ‘¥ğ‘˜ .

In Block-STM, locks are used to protect statuses and depen-
dencies for transactions. We now prove starvation-freedom
for these locks.

Claim 5. If threads keep taking steps before they join, then any
thread that keeps trying to acquire a lock eventually succeeds.

Proof. A lock on transaction dependencies is acquired in Line 148
or in Line 167, both of which, by definition, occur as a part of
some versionâ€™s execution. There are more cases of when
a lock on a transaction status may be acquired. The op-
erations in Line 112 and in Line 132 are a part of a pre-
execution of pre-validation of some transaction, respectively.
The lock may be acquired in Line 156 in order to set the
READY_TO_EXECUTE status as a part of an ongoing execution
(call to set_ready_status in Line 161) or validation (call
in Line 184). The operation in Line 166 sets the status to
EXECUTED as a part of an ongoing execution, and the op-
eration in Line 179 sets the status to ABORTING as a part
of an ongoing validation (that aborts). The remaining two
instances in Line 149 and in Line 151 occur as a part of a ver-
sionâ€™s execution when a dependency is encountered, while
the thread is also holding a lock on dependencies. These are
the only instances when a thread may simultaneously hold
more than one lock, and also only the two operations within
any critical section that may involve waiting. Because the
acquisition order in these cases is unique (first the lock for
dependencies, then for status) and all threads keep taking
steps, a deadlock is therefore impossible.

Moreover, as described above, all acquisitions happen as a
part of an ongoing pre-execution, pre-validation, execution
or validation. By Lemma 4, there are finite number of these,
implying that in our setting, deadlock-freedom is equivalent
to starvation-freedom, i.e. as long as threads keep taking
steps, any thread that tries to acquire a lock in Block-STM
â–¡
must eventually succeed.

Combining the above claims, we show

Corollary 3. Suppose all threads keep taking steps before they
join and VM.execute is wait-free. Then, after some finite time,
there may not be any ongoing pre-execution, pre-validation,
execution or validation.

Proof. By Lemma 4, there are finitely many pre-executions,
pre-validations, executions and validations. Since all threads
keep taking steps, to complete the proof we need to show
that they all finish within finitely many steps of the invok-
ing thread. This is true because VM.execute is assumed to
be wait-free, lock are acquired within finitely many steps

23

