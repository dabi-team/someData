2
2
0
2

t
c
O
8
1

]

O
L
.
s
c
[

2
v
6
2
8
8
0
.
2
1
1
2
:
v
i
X
r
a

A CASE STUDY ON PARAMETRIC VERIFICATION
OF FAILURE DETECTORS

THANH-HAI TRAN, IGOR KONNOV, AND JOSEF WIDDER

a TU Wien, Austria and ConsenSys, Australia

e-mail address: thanh.tran@tuwien.ac.at, thanh-hai.tran@consensys.net

b Informal Systems, Austria

e-mail address: igor@informal.systems

c Informal Systems, Austria

e-mail address: josef@informal.systems

Abstract. Partial synchrony is a model of computation in many distributed algorithms
and modern blockchains. These algorithms are typically parameterized in the number of
participants, and their correctness requires the existence of bounds on message delays and
on the relative speed of processes after reaching Global Stabilization Time (GST). These
characteristics make partially synchronous algorithms both parameterized and parametric,
which render automated veriﬁcation of partially synchronous algorithms challenging. In
this paper, we present a case study on formal veriﬁcation of both safety and liveness of the
Chandra and Toueg failure detector that is based on partial synchrony. To this end, we
ﬁrst introduce and formalize the class of symmetric point-to-point algorithms that contains
the failure detector. Second, we show that these symmetric point-to-point algorithms
have a cutoﬀ, and the cutoﬀ results hold in three models of computation: synchrony,
asynchrony, and partial synchrony. As a result, one can verify them by model checking
small instances, but the veriﬁcation problem stays parametric in time. Next, we specify
the failure detector and the partial synchrony assumptions in three frameworks: TLA+,
IVy, and counter automata. Importantly, we tune our modeling to use the strength of each
method: (1) We are using counters to encode message buﬀers with counter automata, (2)
we are using ﬁrst-order relations to encode message buﬀers in IVy, and (3) we are using
both approaches in TLA+. By running the tools for TLA+ (TLC and APALACHE) and
counter automata (FAST), we demonstrate safety for ﬁxed time bounds. This helped us to
ﬁnd the inductive invariants for ﬁxed parameters, which we used as a starting point for the
proofs with IVy. By running IVy, we prove safety for arbitrary time bounds. Moreover, we
show how to verify liveness of the failure detector by reducing the veriﬁcation problem to
safety veriﬁcation. Thus, both properties are veriﬁed by developing inductive invariants
with IVy. We conjecture that correctness of other partially synchronous algorithms may be
proven by following the presented methodology.

Key words and phrases: Failure detectors, TLA+, counter automata, FAST, and IVy.
This work was supported by Interchain Foundation (Switzerland) and the Austrian Science Fund (FWF)
via the Doctoral College LogiCS W1255. This work was done when the ﬁrst author was at TU Wien. This
paper is an extended version of papers [TKW20] and [TKW21] that adds the formalization of the model of
computation under partial synchrony and detailed proofs.

Preprint submitted to
Logical Methods in Computer Science

© T.H. Tran, I. Konnov, and J. Widder
CC(cid:13) Creative Commons

 
 
 
 
 
 
2

T.H. TRAN, I. KONNOV, AND J. WIDDER

1. Introduction

Distributed algorithms play a crucial role in modern infrastructure, but they are notoriously
diﬃcult to understand and to get right. Network topologies, message delays, faulty processes,
the relative speed of processes, and fairness conditions might lead to behaviors that were
neither intended nor anticipated by algorithm designers. To be able to make meaningful
statements about correctness, many speciﬁcation and veriﬁcation techniques for distributed
algorithms [Lam02, LT88, MP20, DWZ20] have been developed.

Veriﬁcation techniques for distributed algorithms usually focus on two models of compu-
tation: synchrony [SKWZ19] and asynchrony [KLVW17a, KLVW17c]. Synchrony is hard to
implement in real systems, while many basic problems in fault-tolerant distributed computing
are unsolvable in asynchrony.

Partial synchrony lies between synchrony and asynchrony, and escapes their shortcom-
ings. To guarantee liveness properties, proof-of-stake blockchains [BKM18, YMR+19] and
distributed algorithms [CT96, BCG20] assume time constraints under partial synchrony.
That is the existence of bounds ∆ on message delay, and Φ on the relative speed of processes
after some time point. This combination makes partially synchronous algorithms parametric
in time bounds. While partial synchrony is important for system designers, it is challenging
for veriﬁcation.

We thus investigate veriﬁcation of distributed algorithms under partial synchrony, and
start with the speciﬁc class of failure detectors: the Chandra and Toueg failure detec-
tor [CT96]. This is a well-known algorithm under partial synchrony that provides a service
to solve many problems in fault-tolerant distributed computing.

Contributions. In this paper, we do formal veriﬁcation of both safety and liveness of the
Chandra and Toueg failure detector in case of unknown bounds ∆ and Φ. In this case, both
∆ and Φ are arbitrary, and the constraints on message delay and the relative speeds hold in
every execution from the start.

(1) We introduce and formalize the class of symmetric point-to-point algorithms that contains

the failure detector.

(2) We prove that the symmetric point-to-point algorithms have a cutoﬀ, and the cutoﬀ
properties hold in three models of computation: synchrony, asyncrony, and partial
synchrony. In a nutshell, a cutoﬀ for a parameterized algorithm A and a property φ is a
number k such that φ holds for every instance of A if and only if φ holds for instances
with k processes [EN95, BJK+15a]. Our cutoﬀ results with k = 2 were presented
in [TKW20, TKW21]. Hence, we verify the Chandra and Toueg failure detector under
partial synchrony by checking instances with two processes.

(3) We introduce encoding techniques to eﬃciently specify the failure detector based on our
cutoﬀ results. These techniques can tune our modeling to use the strength of the tools:
FAST [BFLP08], Ivy [MP20], and model checkers for TLA+ [YML99, KKT19].
(4) We demonstrate how to reduce the liveness properties Eventually Strong Accuracy, and

Strong Completeness to safety properties.

(5) We check the safety property Strong Accuracy, and the mentioned liveness properties
on instances with ﬁxed parameters by using FAST, and model checkers for TLA+.
(6) To verify cases of arbitrary bounds ∆ and Φ, we ﬁnd and prove inductive invariants of the
failure detector with the interactive theorem prover Ivy. We reduce the liveness properties
to safety properties by applying the mentioned techniques. While our speciﬁcations are

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

3

Algorithm 1 The eventually perfect failure detector algorithm in [CT96]

1: Every process p ∈ 1..N executes the following:
2: for all q ∈ 1..N do
timeout [p, q] ··= default-value
3:
suspected [p, q] ··= ⊥
4:
5: Send “alive” to all q ∈ 1..N
6: for all q ∈ 1..N do
7:
8:
9: if suspected [p, q] then
10:
11:

timeout [p, q] ··= timeout [p, q] + 1
suspected [p, q] ··= ⊥

suspected [p, q] ··= (cid:62)

(cid:46) Initalization step

(cid:46) Task 1: repeat periodically
(cid:46) Task 2: repeat periodically

(cid:46) Task 3: when receive “alive” from q

if suspected [p, q] = ⊥ and not hear q during last timeout [p, q] ticks then

not in the decidable theories that Ivy supports, Ivy requires no additional user assistance
to prove most of our inductive invariants.

Structure. In Section 2, we discusses challenges in veriﬁcation of the Chandra and Toueg
failure detector. In Section 3, we introduce the class of symmetric point-to-point algorithms,
and present how to formalize this class. Our cutoﬀ results in the asynchronous model are
presented in Section 4, and the detailed proofs are provided in Section 5. We extend the
cutoﬀ results for partial synchrony in Section 6. Our encoding technique to eﬃciently specify
the failure detector is presented in Section 7. In Section 8, we present how to reduce the
mentioned liveness properties to safety ones. Experiments for small ∆ and Φ are described
in Section 9. Ivy proofs for parametric ∆ and Φ are discussed in Section 10. Finally, we
discuss related work in Section 11.

2. Challenges in verification of failure detectors

The Chandra and Toueg failure detector [CT96] can be seen as an oracle to get information
about crash failures in the distributed system. The failure detector usually guarantees some
of the following properties [CT96] (numbers 1..N denote the process identiﬁers):
• Strong Accuracy: No process is suspected before it crashes.

G(∀p, q ∈ 1..N : (Correct(p) ∧ Correct(q)) ⇒ ¬Suspected (p, q))

• Eventual Strong Accuracy: There is a time after which correct processes are not suspected

by any correct process.

F G(∀p, q ∈ 1..N : (Correct(p) ∧ Correct(q)) ⇒ ¬Suspected (p, q))

• Strong Completeness: Eventually every crashed process is permanently suspected by every

correct process.

F G(∀p, q ∈ 1..N : (Correct(p) ∧ ¬Correct(q)) ⇒ Suspected (p, q))

where F and G are temporal operators in linear temporal logic (LTL) [Pnu77] 1, predicate
Suspect(p, q) refers to whether process p suspects process q to have crashed, and predicate
Correct(p) refers to whether process p is correct. Given an execution trace, process p is

1A brief introduction of LTL is provided in Appendix A.

4

T.H. TRAN, I. KONNOV, AND J. WIDDER

correct if Correct(p) is true for every time point 2. However, a process might crash later (and
not recover). Given an execution trace, if process q crashes at time t, predicate Correct(q)
is evaluated to false from time t. Predicate Suspected (p, q) corresponds to the variable
suspected in Algorithm 1, and depends on the variable timeout[p, q] and the waiting time of
process p for process q.

Algorithm 1 presents the pseudo code of the failure detector of [CT96]. A system instance
has N processes that communicate with each other by sending-to-all and receiving messages
through unbounded N 2 point-to-point communication channels. A process performs local
computation based on received messages (we assume that a process also receives the messages
that it sends to itself). In one system step, all processes may take up to one step. Locally in
each step, a process can only make a step in at most one of the locally concurrent task. Some
processes may crash, i.e., stop operating. Correct processes follow Algorithm 1 to detect
crashes in the system. Initially, every correct process sets a default value for a timeout of each
other (Line 3), i.e. how long it should wait for others, and assumes that no processes have
crashed (Line 4). Symbols ⊥ and (cid:62) refers to truth values false and true, respectively. Every
correct process p has three tasks: (i) repeatedly sends an “alive” message to all (Line 5),
and (ii) repeatedly produces predictions about crashes of other processes based on timeouts
(Line 6), and (iii) increases a timeout for process q if p has learned that its suspicion on q is
wrong (Line 9). Notice that process p raises suspicion on the operation of process q (Line 6)
by considering only information related to q: timeout [p, q] , suspected [p, q], and messages
that p has received from q recently.

Algorithm 1 does not satisfy Eventually Strong Accuracy under asynchrony since there
exists no bound on message delay, and messages sent by correct processes might always
arrive after the timeout expired. Liveness of the failure detector is based on the existence of
bounds ∆ on the message delay, and Φ on the relative speed of processes after reaching the
Global Stabilization Time (GST) at some time point T0 [CT96].3 There are many models
of partial synchrony [DLS88, CT96]. In this paper, we focus only on the case of unknown
bounds ∆ and Φ because other models might call for abstractions which are out of scope of
this paper. In our case, T0 = 1, and both parameters ∆ and Φ are arbitrary. Moreover, the
following constraints hold in every execution:
(TC1) If message m is placed in the message buﬀer from process q to process p by some
operation Send (m, p) at a time s1 ≥ 1, and if process p executes an operation
Receive(p) at a time s2 with s2 ≥ s1 + ∆, then message m must be delivered to p at
time s2 or earlier.

(TC2) In every contiguous time interval [t, t + Φ] with t ≥ 1, every correct process must

take at least one step.

These constraints make the failure detector parametric in ∆ and Φ.

Moreover, Algorithm 1 is parameterized by the number of processes and by the initial
value of the timeout. If a default value of the timeout is too small, there exists a case in

2We deviate from the original deﬁnition in [CT96], as it allows us to describe global states at speciﬁc
times, without reasoning about potential crashes that happen in the future. Actually, our modeling captures
more closely the failure patterns from [CT96]. Regarding the failure detector properties, the strong accuracy
property is equivalent to the one in [CT96]. The other two properties have the form F G(. . .), where we may
consider satisfaction only at times after the last process has crashed and thus our crashed predicates coincide
with the ones in [CT96].

3A time T0 is called the Global Stabilization Time (GST) if ∆ or Φ holds in [T0, ∞].

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

5

which sent messages are delivered after the timeout expired. This behavior violates Strong
Accuracy.

As a result, veriﬁcation of the failure detector faces the following challenges:

(1) Its model of computation lies between synchrony and asynchrony since multiple processes

can take a step in a global step.

(2) The failure detector is parameterized by the number of processes. Hence, we need to

verify inﬁnitely many instances of algorithms.

(3) The initial value of the timeout is an additional parameter in Algorithm 1.
(4) The failure detector relies on a global clock and local clocks. A straightforward encoding

of a clock with an integer would produce an inﬁnite state space.

(5) The algorithm is parametric by time bounds ∆ and Φ.
(6) Eventually Strong Accuracy and Strong Completeness are liveness properties.

3. Model of Computation

In this section, we introduce the class of symmetric point-to-point algorithms, and present
how to formalize such algorithms as transition systems. Since every process follows the
same algorithm, we ﬁrst deﬁne a process template that captures the process behavior in
Section 3.1. Every process is an instance of the process template.

In Section 3.2, we present the formalization of the global system. This formalization is
adapted with the time constraints under partial synchrony in Section 3.3, and our analysis
is for the model under partial synchrony.

Intuitively, a global system is a composition of N processes, N 2 point-to-point outgoing
message buﬀers, and N control components that capture what processes can take a step.
Every process is identiﬁed with a unique index in 1..N , and follows the same deterministic
algorithm. Moreover, a global system allows: (i) multiple processes to take (at most) one
step in one global step, and (ii) some processes to crash. Every process may execute three
kinds of transitions: internal, round, and stuttering. Notice that in one global step, some
processes may send a message to all, and some may receive messages and do computation.
Hence, we need to decide which processes move, and what happens to the message buﬀers.
We introduce four sub-rounds: Schedule, Send, Receive, and Computation. The transitions
for these sub-rounds are called internal ones. A global round transition is a composition
of four internal transitions. We formalize sub-rounds and global steps later. As a result of
modeling, there exists an arbitrary sequence of global conﬁgurations which is not accepted
in asynchrony. So, we deﬁne so-called admissible sequences of global conﬁgurations under
asynchrony.

Recall that the network topology of algorithms in the symmetric point-to-point class
contains N 2 point-to-point message buﬀers. Every transposition on a set of process indexes
preserves the network topology. Importantly, every transposition on process indexes also
preserves the structures of both the process template and the global transition system. It
implies that both the process template and the global transition system are symmetric.

3.1. The Process Template. We ﬁx a set of process indexes as 1..N . Moreover, we assume
that the message content does not have indexes of its receiver and sender. We let Msg denote
a set of potential messages, and Set(Msg) denote the set of sets of messages.

6

T.H. TRAN, I. KONNOV, AND J. WIDDER

We model a process template as a transition system UN = (QN , Tr N , Rel N , q 0

N ) where

QN = Loc × Set(Msg) × . . . × Set(Msg)
(cid:125)

(cid:124)

× D × . . . × D
(cid:125)
(cid:123)(cid:122)
N times

(cid:124)

(cid:123)(cid:122)
N times
is a set of template states 4, Tr N is a set of template transitions, Rel N ⊆ QN × Tr N × QN
is a template transition relation, and q 0
N ∈ QN is an initial state. These components of UN
are deﬁned as follows.

States. A template state ρ is a tuple ((cid:96), S1, . . . , SN , d1, . . . , dN ) where:
• (cid:96) ∈ Loc refers to the value of a program counter that ranges over a set Loc of locations.
We assume that Loc = Locsnd ∪ Locrcv ∪ Loccomp ∪ {(cid:96)crash }, and three sets Locsnd , Locrcv ,
Loccomp are disjoint, and (cid:96)crash is a special location of crashes. To access the program
counter, we use a function pc : QN → Loc that takes a template state at its input, and
produces its program counter as the output. Let ρ(k ) denote the k th component in a
template state ρ. For every ρ ∈ QN , we have pc(ρ) = ρ(1) .

• Si ∈ Set(Msg) refers to a set of messages. It is to store the messages received from a
process pi for every i ∈ 1..N . To access a set of received messages from a particular
process whose index is in 1..N , we use a function rcvd : QN × 1..N → Set(Msg) that takes
a template state ρ and a process index i at its input, and produces the (i + 1)th component
of ρ at the output, i.e. for every ρ ∈ QN , we have rcvd (ρ, i ) = ρ(1 + i ) .

• di ∈ D refers to a local variable related to a process pi for every i ∈ 1..N . To access
a local variable related to a particular process whose index in 1..N , we use a function
lvar : QN × 1..N → D that takes a template state ρ and a process index i at its input, and
produces the (1 + N + i )th component of ρ as the output, i.e. lvar (ρ, i ) = ρ(1 + N + i )
for every ρ ∈ QN . For example, for every process p in Algorithm 1, variable di of process
p refers to a tuple of the two variables timeout[p, i ] and suspect[p, i ].

Initial state. The initial state q 0
N = ((cid:96)0, ∅, . . . , ∅, d0, . . . , d0) where (cid:96)0 is a
location, every box for received messages is empty, and every local variable is assigned a
constant d0 ∈ D.

N is a tuple q 0

Transitions. We deﬁne Tr N = CSnd ∪ CRcv ∪ {comp, crash, stutter } where
• CSnd is a set of transitions. Every transition in CSnd refers to a task that does some
internal computation, and sends a message to all. For example, in task 1 in Algorithm 1, a
process increases its local clock, and performs an instruction to send “alive” to all. We let
csnd (m) denote a transition referring to a task with an action to send a message m ∈ Msg
to all.

• CRcv is a set of transitions. Every transition in CRcv refers to a task that receives N sets
of messages, and does some internal computation. For example, in task 2 in Algorithm 1, a
process increases its local clock, receives messages, and removes false-negative predictions.
We let crcv (S1, . . . , SN ) denote a transition referring to a task with an action to receive
sets S1, . . . , SN of messages. These sets S1, . . . , SN are delivered by the global system.
• comp is a transition which refers to a task with purely local computation. In other words,

this task has neither send actions nor receive actions.

• crash is a transition for crashes.

4We denote S1 × . . . × Sm by a set {(s1, . . . , sm ) | (cid:86)

1≤i≤m si ∈ Si } of tuples. The elements of the set QN

are tuples with 2N + 1 elements.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

7

• stutter is a transition for stuttering steps.

Transition relation. For two states ρ, ρ(cid:48) ∈ QN and a transition tr ∈ Tr N , instead of
(ρ, tr, ρ(cid:48)), we write ρ tr−→ ρ(cid:48). In the model of [DLS88, CT96], each process follows the same
1, if ρ0 = ρ1
deterministic algorithm. Hence, we assume that for every ρ0
and tr 0 = tr 1, then it follows that ρ(cid:48)
1. Moreover, we assume that there exist the
following functions which are used to deﬁne constraints on the template transition relation:
• A function nextLoc : Loc → Loc takes a location at its input and produces the next location

0 and ρ1

0 = ρ(cid:48)

tr 1−−→ ρ(cid:48)

tr 0−−→ ρ(cid:48)

as the output.

• A function genMsg : Loc → Set(Msg) takes a location at its input, and produces a singleton
set that contains the message that is sent to all processes in the current task. The output
can be an empty set. For example, if a process is performing a Receive task, the output of
genMsg is an empty set.

• A function nextVal : Loc × Set(Msg) × D → D takes a location, a set of messages, and a

local variable’s value, and produces a new value of a local variable as the output.

Let us ﬁx functions nextLoc, genMsg and nextVal . We deﬁne the template transitions as
follows.
(1) For every message m ∈ Msg, for every pair of states ρ, ρ(cid:48) ∈ QN , we have ρ

csnd (m)
−−−−−→ ρ(cid:48) if

and only if
(a) pc(ρ) ∈ Locsnd ∧ pc(ρ(cid:48)) = nextLoc(pc(ρ)) ∧ {m} = genMsg(pc(ρ))
(b) ∀i ∈ 1..N : rcvd (ρ, i ) = rcvd (ρ(cid:48), i )
(c) ∀i ∈ 1..N : lvar (ρ(cid:48), i ) = nextVal (cid:0)pc(ρ), ∅, lvar (ρ, i )(cid:1)

Constraint (a) implies that the update of a program counter and the construction
of a sent message m depend on only the current value of a program counter, and a
process sends only m to all in this step. For example, process p in Algorithm 1 sends
only message “alive” in Task 1. Constraint (b) refers to that no message was delivered.
Constraint (c) implies that the value of lvar (ρ(cid:48), i ) depends on only the current location,
an empty set of messages, and the value of lvar (ρ, i ).

(2) For arbitrary sets of messages S1, . . . , SN ⊆ Msg, for every pair of states ρ, ρ(cid:48) ∈ QN , we

crcv (S1,...,SN )
−−−−−−−−−→ ρ(cid:48) if and only if the following constraints hold:
have ρ
(a) pc(ρ) ∈ Locrcv ∧ pc(ρ(cid:48)) = nextLoc(pc(ρ)) ∧ ∅ = genMsg(pc(ρ))
(b) ∀i ∈ 1..N : rcvd (ρ(cid:48), i ) = rcvd (ρ, i ) ∪ Si
(c) ∀i ∈ 1..N : lvar (ρ(cid:48), i ) = nextVal (cid:0)pc(ρ)), Si , lvar (ρ, i )(cid:1)
Constraint (a) in crcv is similar to constraint (a) in csnd , except that no message is sent in
this sub-round. Constraint (b) refers that messages in a set Si are from a process indexed
i , and have been delivered in this step. For example, in Algorithm 1 Constraint (b)
implies that rcvd (ρ, i ) ⊆ {“alive”} for every template state ρ and every index 1 ≤ i ≤ N .
After the ﬁrst “alive” message was received, the value of rcvd (ρ, i ) is unchanged. This
does not raise any issues in our analysis as Line 7 in Algorithm 1 considers only how
long process p has waited for a new message from process q. Constraint (c) in crcv
implies that the value of lvar (ρ(cid:48), i ) depends on only the current location, the set Si of
messages that have been delivered, and the value of lvar (ρ, i ).

(3) For every pair of states ρ, ρ(cid:48) ∈ QN , we have ρ

comp
−−−→ ρ(cid:48) if and only if the following

constraints hold:
(a) pc(ρ) ∈ Loccomp ∧ pc(ρ(cid:48)) = nextLoc(pc(ρ)) ∧ ∅ = genMsg(pc(ρ))

8

T.H. TRAN, I. KONNOV, AND J. WIDDER

(b) ∀i ∈ 1..N : rcvd (ρ(cid:48), i ) = rcvd (ρ, i )
(c) ∀i ∈ 1..N : lvar (ρ(cid:48), i ) = nextVal (cid:0)pc(ρ), ∅, lvar (ρ, i )(cid:1)
Hence, this step has only local computation. No message is sent or delivered.

(4) For every pair of states ρ, ρ(cid:48) ∈ QN , we have ρ crash−−−→ ρ(cid:48) if and only if the following

constraints hold:
(a) pc(ρ) (cid:54)= (cid:96)crash ∧ pc(ρ(cid:48)) = (cid:96)crash
(b) ∀i ∈ 1..N : rcvd (ρ, i ) = rcvd (ρ(cid:48), i ) ∧ lvar (ρ, i ) = lvar (ρ(cid:48), i )
Only the program counter is updated by switching to (cid:96)crash .

(5) For every pair of states ρ, ρ(cid:48) ∈ QN , we have ρ stutter−−−−→ ρ(cid:48) if and only if ρ = ρ(cid:48).

3.2. Modeling the Global Distributed Systems. We now present the formalization of
the global system. In this model, multiple processes might take a step in a global step.
This characteristic allows us to extend this model with partial synchrony constraints that
are formalized in Section 3.3. To capture the semantics of asynchrony, we simply need a
constraint that only one process can take a step in a global step [AW04]. This constraint is
formalized in the end of this subsection.

Given N processes which are instantiated from the same process template UN =
(QN , Tr N , Rel N , q 0
N ), the global system is a composition of (i) these processes, and (ii) N 2
point-to-point buﬀers for in-transit messages, and (iii) N control components that capture
what processes can take a step. We formalize the global system as a transition system
GN = (cid:0)CN , TrN , RN , g 0
• CN = (QN )N × Set(Msg)N ·N × BoolN is a set of global conﬁgurations,
• TrN is a set of global internal, round, and stuttering transitions,
• RN ⊆ CN × TrN × CN is a global transition relation, and
• g 0
These components are deﬁned as follows.

N is an initial conﬁguration.

(cid:1) where

N

Conﬁgurations. A global conﬁguration κ is deﬁned as a following tuple
(cid:1)

1 , S 2

1 . . . , S r

s , . . . S N

N , act1, . . . , actN

κ = (cid:0)q1, . . . , qN , S 1

where:
• qi ∈ QN : This component is a state of a process pi for every i ∈ 1..N . To access a local
state of a particular process, we use a function lstate : CN × 1..N → QN that takes input as
a global conﬁguration κ and a process index i , and produces output as the i th component
of κ which is a state of a process pi . Let κ(i ) denote the i th component of a global
conﬁguration κ. For every i ∈ 1..N , we have lstate(κ, i ) = κ(i ) = qi .
s ∈ Set(Msg): This component is a set of in-transit messages from a process ps to
a process pr for every s, r ∈ 1..N . To access a set of in-transit messages between two
processes, we use a function buf : CN ×1..N ×1..N → Set(Msg) that takes input as a global
conﬁguration κ, and two process indexes s, r , and produces output as the (s · N + r )th
component of κ which is a message buﬀer from a process ps (sender) to a process pr
(receiver). Formally, we have buf (κ, s, r ) = κ(s · N + r ) = S r

s for every s, r ∈ 1..N .

• S r

• acti ∈ Bool: This component says whether a process pi can take one step in a global step for
every i ∈ 1..N . To access a control component, we use a function active : CN ×1..N → Bool
that takes input as a conﬁguration κ and a process index i , and produces output as the
((N + 1) · N + i )th component of κ which refers to whether a process pi can take a step.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

9

Formally, we have active(κ, i ) = κ((N + 1) · N + i ) for every i ∈ 1..N . The environment
sets the values of act1, . . . , actN in the sub-round Schedule deﬁned later.

We will write κ ∈ (QN )N × Set(Msg)N ·N × BoolN or κ ∈ CN .

Initial conﬁguration. The global system GN has one initial conﬁguration g 0
satisfy the following constraints:
(1) ∀i ∈ 1..N : ¬active(g 0
(2) ∀s, r ∈ 1..N : buf (g 0

N , i ) ∧ lstate(g 0

N , i ) = q 0
N

N , s, r ) = ∅

N , and it must

Global stuttering transition. We extend the relation (cid:59) with stuttering:
for every
conﬁguration κ, we allow κ (cid:59) κ. The stuttering transition is necessary in the proof of
Lemma 4.11 presented in Section 4.

Global internal transitions. In the model of [DLS88, CT96], many processes can take a
step in a global step. We assume that a computation of the distributed system is organized
in rounds, i.e. global ticks, and every round is organized as four sub-rounds called Schedule,
Send, Receive, and Computation. To model that as a transition system, for every sub-round
we deﬁne a corresponding transition: Sched−−−→ for the sub-round Schedule, Snd−−→ for the sub-
Comp
round Send, Rcv−−→ for the sub-round Receive,
−−−→ for the sub-round Comp. These transitions
are called global internal transitions. We deﬁne the semantics of these sub-rounds as follows.
(1) Sub-round Schedule. The environment starts with a global conﬁguration where every
process is inactive, and move to another by non-deterministically deciding what processes
become crashed, and what processes take a step in the current global step. Every correct
process takes a stuttering step, and every faulty process is inactive. If a process p is
crashed in this sub-round, every incoming message buﬀer to p is set to the empty set.
Formally, for κ, κ(cid:48) ∈ CN , we have κ Sched−−−→ κ(cid:48) if the following constraints hold:
(a) ∀i ∈ 1..N : ¬active(κ, i )
(b) ∀i ∈ 1..N : lstate(κ, i ) stutter−−−−→ lstate(κ(cid:48), i ) ∨ lstate(κ, i ) crash−−−→ lstate(κ(cid:48), i )
(c) ∀i ∈ 1..N : pc(lstate(κ(cid:48), i )) = (cid:96)crash ⇒ ¬active(κ(cid:48), i )
(d) ∀s, r ∈ 1..N : pc(lstate(κ(cid:48), r )) (cid:54)= (cid:96)crash ⇒ buf (κ, s, r ) = buf (κ(cid:48), s, r )
(e) ∀r ∈ 1..N : pc(lstate(κ(cid:48), r )) = (cid:96)crash ⇒ (∀s ∈ 1..N : buf (κ(cid:48), s, r ) = ∅)

We let predicate Enabled (κ, i , L) denote whether process i whose location at the

conﬁguration κ is in L takes a step from κ. Formally, we have

Enabled (κ, i , L) (cid:44) active(κ, i ) ∧ pc(lstate(κ, i )) ∈ L

Predicate Enabled is used in the deﬁnitions of other sub-rounds.

(2) Sub-round Send. Only processes that perform send actions can take a step in this
sub-round. Such processes become inactive at the end of this sub-round. Fresh sent
messages are added to corresponding message buﬀers. To deﬁne the semantics of the
sub-round Send, we use the following predicates:

Frozen S (κ, κ(cid:48), i ) (cid:44) lstate(κ, i ) stutter−−−−→ lstate(κ(cid:48), i )

∧ active(κ, i ) = active(κ(cid:48), i )
∧ ∀r ∈ 1..N : buf (κ, i , r ) = buf (κ(cid:48), i , r )

Sending(κ, κ(cid:48), i , m) (cid:44) ∀r ∈ 1..N : m /∈ buf (κ, i , r )

10

T.H. TRAN, I. KONNOV, AND J. WIDDER

∧ ∀r ∈ 1..N : buf (κ(cid:48), i , r ) = {m} ∪ buf (κ, i , r )

∧ lstate(κ, i )

csnd (m)
−−−−−→ lstate(κ(cid:48), i )

Formally, for κ, κ(cid:48) ∈ CN , we have κ Snd−−→ κ(cid:48) if the following constraints hold:

(a) ∀i ∈ 1..N : ¬Enabled (κ, i , Locsnd ) ⇔ Frozen S (κ, κ(cid:48), i )
(b) ∀i ∈ 1..N : Enabled (κ, i , Locsnd ) ⇔ ∃m ∈ Msg : Sending(κ, κ(cid:48), i , m)
(c) ∀i ∈ 1..N : Enabled (κ, i , Locsnd ) ⇒ ¬active(κ(cid:48), i )

The semantics of the Send sub-round forces that the Send primitive is atomic.
(3) Sub-round Receive. Only processes that perform receive actions can take a step in
this sub-round. Such processes become inactive at the end of this sub-round. Sets of
delivered messages that may be empty are removed from corresponding message buﬀers.
To deﬁne the semantics of this sub-round, we use the following predicates:

Frozen R(κ, κ(cid:48), i ) (cid:44) lstate(κ, i ) stutter−−−−→ lstate(κ(cid:48), i )

∧ active(κ, i ) = active(κ(cid:48), i )
∧ ∀s ∈ 1..N : buf (κ, s, i ) = buf (κ(cid:48), s, i )

Receiving(κ, κ(cid:48), i , S1, . . . , SN ) (cid:44) ∀s ∈ 1..N : Ss ∩ buf (κ(cid:48), s, i ) = ∅

∧ ∀s ∈ 1..N : buf (κ(cid:48), s, i ) ∪ Ss = buf (κ, s, i )

∧ lstate(κ, i )

crcv (S1,...,SN )
−−−−−−−−−→ lstate(κ(cid:48), i )

Formally, for κ, κ(cid:48) ∈ CN , we have κ Rcv−−→ κ(cid:48) if the following constraints hold:
(a) ∀i ∈ 1..N : ¬Enabled (κ, i , Locrcv ) ⇔ Frozen R(κ, κ(cid:48), i )
(b) ∀i ∈ 1..N : Enabled (κ, i , Locrcv )

⇔ ∃S1, . . . , SN ⊆ Msg : Receiving(κ, κ(cid:48), i , S1, . . . , SN )

(c) ∀i ∈ 1..N : Enabled (κ, i , Locrcv ) ⇒ ¬active(κ(cid:48), i )

(4) Sub-round Computation. Only processes that perform internal computation actions
can take a step in this sub-round. Such processes become inactive at the end of this
sub-round. Every message buﬀer is unchanged. Formally, for κ, κ(cid:48) ∈ CN , we have
Comp
−−−→ κ(cid:48) if the following constraints hold:
κ
(a) ∀i ∈ 1..N : Enabled (κ, i , Loccomp) ⇔ lstate(κ, i )
(b) ∀i ∈ 1..N : ¬Enabled (κ, i , Loccomp) ⇔ lstate(κ, i ) stutter−−−−→ lstate(κ(cid:48), i )
(c) ∀s, r ∈ 1..N : buf (κ, s, r ) = buf (κ(cid:48), s, r )
(d) ∀i ∈ 1..N : Enabled (κ, i , Loccomp) ⇒ ¬active(κ(cid:48), i )

comp
−−−→ lstate(κ(cid:48), i )

Remark 3.1. Predicate Sending refers that at most one “alive” message in Algorithm 1 is in
every message buﬀer. In Section 3.3, we extend our formalization by introducing the notion
of time and by modeling time constraints under partial synchrony. In that formalization,
every “alive” message is tagged with its age, and therefore, the message buﬀers can have
multiple messages.

Remark 3.2. Observe that the deﬁnitions of κ Sched−−−→ κ(cid:48), and κ Snd−−→ κ(cid:48), and κ Rcv−−→ κ(cid:48), and
Comp
−−−→ κ(cid:48) allow κ = κ(cid:48), that is stuttering. This captures, e.g., global steps in [DLS88, CT96]
κ
where no process sends a message.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

11

Global round transitions. Intuitively, every global round transition is induced by a se-
Comp
quence of four transitions: a Sched−−−→ transition, a Snd−−→ transition, a Rcv−−→ transition, and a
−−−→
transition. We let (cid:59) denote global round transitions. For every pair of global conﬁgurations
κ0, κ4 ∈ CN , we say κ0 (cid:59) κ4 if there exist three global conﬁgurations κ1, κ2, κ3 ∈ CN such
Comp
−−−→ κ4. Moreover, global round transitions allow some
that κ0
processes to crash only in the sub-round Schedule. We call these faults clean crashes. Notice
that correct process i can make at most one global internal transition in every global round
transition since the component acti is false after process i makes a transition.

Sched−−−→ κ1

Rcv−−→ κ3

Snd−−→ κ2

Admissible sequences. An inﬁnite sequence π = κ0κ1 . . . of global conﬁgurations in GN
is admissible if the following constraints hold:
(1) κ0 is the initial state, i.e. κ0 = g 0
(2) π is stuttering equivalent with an inﬁnite sequence π(cid:48) = κ(cid:48)

N , and

Sched−−−→

1 . . . such that κ(cid:48)
4k

0κ(cid:48)

κ(cid:48)

4k +1

Snd−−→ κ(cid:48)

4k +2

Rcv−−→ κ(cid:48)

4k +3

Comp
−−−→ κ(cid:48)

4k +4 for every k ≥ 0.

Notice that it immediately follows by this deﬁnition that if π = κ0κ1 . . . is an admissible
(cid:59) κ(cid:48)
sequence of conﬁgurations in GN , then κ(cid:48)
4k +4 for every k ≥ 0. From now on, we only
4k
consider admissible sequences of global conﬁgurations.

Admissible sequences under synchrony. Let π = κ0κ1 . . . be an admissible sequence of
global conﬁgurations in GN . As every correct process makes a transition in every global step
under synchrony[AW04], we say that π is under synchrony if every correct process is active
after a sub-round Schedule. Formally, for every transition κ Sched−−−→ κ(cid:48) in π, the following
constraint holds: ∀i ∈ 1..N : pc(lstate(κ(cid:48), i )) (cid:54)= (cid:96)crash ⇒ active(κ(cid:48), i ).

Admissible sequences under asynchrony. Let π = κ0κ1 . . . be an admissible sequence
of global conﬁgurations in GN . As at most one process can make a transition in every global
step under asynchrony[AW04], we say that π is under asynchrony if at most one process
is active after a sub-round Schedule. Formally, for every transition κ Sched−−−→ κ(cid:48) in π, the
following constraint holds: ∀i , j ∈ 1..N : active(κ(cid:48), i ) ∧ active(κ(cid:48), j ) ⇒ i = j .

3.3. Modeling Time Constraints under Partial Synchrony. Time parameters in
partial synchrony only reduce the execution space compared to asynchrony. Hence, we
can formalize the system behaviors under partialy synchrony by extending the above
formalization of the system behaviors with the notion of time, message ages, time constraints,
and admissible sequences of conﬁgurations under partial synchrony. They are deﬁned as
follows.

Time. Time is progressing with global round transitions. Formally, let π = κ0κ1 . . . be an
admissible sequence of global conﬁgurations in GN . We say that the conﬁguration κ0 is at
time 0, and that four conﬁgurations κ4k −3, . . . , κ4k are at time k for every k > 0.

Recall that in Section 3.2, a global round transition is induced of a sequence of four sub-
rounds: Schedule, Send, Receive, and Computation. In an admissible sequence π = κ0κ1 . . .
of global conﬁgurations in GN , for every k > 0, every sub-sequence of four conﬁgurations
κ4k −3, . . . , κ4k presents one global round transition. Conﬁguration κ4k −3 is in sub-round
Schedule, and conﬁguration κ4k is in sub-round Computation for every k > 0. So, the notion
of time says that the global round transition κ4k −3 (cid:59) κ4k happens at time k .

12

T.H. TRAN, I. KONNOV, AND J. WIDDER

Message ages. Now we discuss the formalization of message ages. For every sent message
m, the global system tags it with its current age, i.e., (m, age m ). Message ages require that
the type of message buﬀers needs to be changed to buf : CN × 1..N × 1..N → Set(Msg × N).
In our formalization, when message m was added to the message buﬀer in sub-round
Send, its age is 0. Instead of predicate Sending, our formalization now uses the following
predicate Sending (cid:48).

Sending (cid:48)(κ, κ(cid:48), i , m) (cid:44) ∀r ∈ 1..N : (m, 0) /∈ buf (κ, i , r )

∧ ∀r ∈ 1..N : buf (κ(cid:48), i , r ) = {(m, 0)} ∪ buf (κ, i , r )

∧ lstate(κ, i )

csnd (m)
−−−−−→ lstate(κ(cid:48), i )

Message ages are increased by 1 when the global system takes a Sched−−−→ transition.
Formally, for every time k ≥ 0, for every process s, r ∈ 1..N , the following constraints hold:
(i) For every message (m, agem ) in buf (κ4k , s, r ), there exists a message (m (cid:48), agem (cid:48)) in

buf (κ4k +1, s, r ) such that m = m (cid:48) and agem (cid:48) = agem + 1.

(ii) For every message (m (cid:48), agem (cid:48)) in buf (κ4k +1, s, r ), there exists a message (m, agem ) in

buf (κ4k , s, r ) such that m = m (cid:48) and agem (cid:48) = agem + 1.

Constraint (i) ensures that every in-transit message age will be added by one time-unit in
the sub-round Schedule. Constraint (ii) sensures that no new messages will be added in
buf (κ4k +1, s, r ). These two constraints are used to replace Constraint (1d) about unchanged
message buﬀers in the deﬁnition of sub-round Schedule in Section 3.2.

Moreover, the age of an in-transit message is unchanged in other sub-rounds. Formally,
for every time k > 0, for every 0 ≤ (cid:96) ≤ 3, for every pair of processes s, r ∈ 1..N , for every
message (m, agem ) in buf (κ4k −(cid:96), s, r ), there exists (m (cid:48), agem (cid:48)) in buf (κ4k −3, s, r ) such that
m = m (cid:48) and agem = agem (cid:48).

Finally, message ages are not delivered to processes in sub-round Receive. Instead of

predicate Receiving, our formalization now uses the following predicate Receiving (cid:48).
Receiving(κ, κ(cid:48), i , S1, . . . , SN ) (cid:44) ∀s ∈ 1..N : Ss ∩ buf (κ(cid:48), s, i ) = ∅

∧ ∀s ∈ 1..N : buf (κ(cid:48), s, i ) ∪ Ss = buf (κ, s, i )
crcv (g(S1),...,g(SN ))
−−−−−−−−−−−−−→ lstate(κ(cid:48), i )

∧ lstate(κ, i )
where function g : Set(Msg × N) → Set(Msg) is to detag message ages in a set S . Formally,
we have two following constraints:
(1) For every (m, agem ) ∈ S , it holds m ∈ g(S ).
(2) For every m ∈ g(S ), there exists agem ∈ N such that (m, agem ) ∈ S .

Partial synchrony constraints. We here focus on the case of unknown bounds. Recall that
Constraints (TC1) and (TC2) hold in this case. Given an admissible sequence π = κ0κ1 . . .
of global conﬁgurations in GN , Constraints (TC1) and (TC2) on π can be formalized as
follows, respectively:
(PS1) For every process r ∈ 1..N , for every time k > 0, if Enabled (κ4k −2, r , Locrcv ), then
for every process s ∈ 1..N , there exists no message (m, agem ) in buf (κ4k −1, s, r )
such that agem ≥ ∆.

(PS2) For every process i ∈ 1..N , for every time interval [k , k + Φ], if we have that
pc(lstate(κ(cid:96), i )) (cid:54)= (cid:96)crash for every conﬁguration index in the interval [4k − 3, 4(k + Φ)],

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

13

then there exist a conﬁguration index t in [4k − 3, 4(k + Φ)] and a set L of locations
such that Enabled (κt , i , L) where L is one of Locsnd , Locrcv , and Loccomp.

Constraint (PS1) requires that if process r takes a step from κ4k −2 in the sub-round
Receive, then there exists no in-transit messages (sent to process r ) whose ages are at least
∆ time-units in κ4k −1, that is, older messages must have been received before that. In
principle, partial synchrony allows messages to be older than ∆ time-units as long as the
receiver does not take a step after the message reaches age Delta. Consistent to (TC1),
whenever a receiver takes a step after a message is older than ∆ time-units, the reception
step removes it from the buﬀer. This limitation is to enabled processes. Constraint (PS2)
ensures that for every time interval [k , k + Φ] with conﬁgurations κ4k −3, . . . , κ4(k +Φ), for
every process i ∈ 1..N , if process i is correct in this time interval, there exist a conﬁguration
κ(cid:96)0 ∈ {κ4k −3, . . . , κ4(k +Φ)} and a set L of locations such that the location of process i at κ(cid:96)0
is in L and process i takes a step from κ(cid:96)0.

Admissible sequences under partial synchrony. Let π = κ0κ1 . . . be an admissible
sequence of global conﬁgurations in GN . We say that π is under partial synchrony if
Constraints (PS1) and (PS2) hold in π. Notice that admissible sequences under partial
synchrony allow multiple processes to make a transition in a time unit.

4. Cutoff Results in the Model of the Global Distributed Systems

Let A be a symmetric point–to–point algorithm. In this section, we show cutoﬀ results for
the number of processes in the algorithm A in the unrestricted model. These results are
Theorems 4.1 and 4.2, and the detailed proofs are provided in Section 5. With these cutoﬀ
results, one can verify two properties Strong Completeness and Eventually Strong Accuracy
of the failure detector of [CT96] by model checking two instances of sizes 1 and 2 in case of
synchrony.

Theorem 4.1. Let A be a symmetric point–to–point algorithm under the unrestricted model.
Let G1 and GN be instances of 1 and N processes respectively for some N ≥ 1. Let Path 1
and Path N be sets of all admissible sequences of conﬁgurations in G1 and in GN , respectively.
Let ω{i} be a LTL\X formula in which every predicate takes one of the forms: P1(i ) or
P2(i , i ) where i is an index in 1..N . Then, it follows that:

(cid:16)

∀πN ∈ Path N : GN , πN |=

(cid:94)

(cid:17)

ω{i}

⇔

(cid:16)

i ∈ 1..N

∀π1 ∈ Path 1 : G1, π1 |= ω{1}

(cid:17)

Theorem 4.2. Let A be a symmetric point–to–point algorithm under the unrestricted model.
Let G2 and GN be instances of 2 and N processes respectively for some N ≥ 2. Let Path 2
and Path N be sets of all admissible sequences of conﬁgurations in G2 and in GN , respectively.
Let ψ{i,j } be an LTL\X formula in which every predicate takes one of the forms: P1(i ), or
P2(j ), or P3(i , j ), or P4(j , i ) where i and j are diﬀerent indexes in 1..N . It follows that:

(cid:0)∀πN ∈ Path N : GN , πN |=

i(cid:54)=j
(cid:94)

i,j ∈ 1..N

ψ{i,j }

(cid:1) ⇔ (cid:0)∀π2 ∈ Path 2 : G2, π2 |= ψ{1,2}

(cid:1)

Since the proof of Theorem 4.1 is similar to the one of Theorem 4.2, we focus on
Its proof is based on the symmetric characteristics in the system

Theorem 4.2 here.

14

T.H. TRAN, I. KONNOV, AND J. WIDDER

model (the network topology and the three functions nextLoc, genMsg, and nextVal ) and
correctness properties, and on the following lemmas.
• Lemma 4.6 says that every transposition on a set of process indexes 1..N preserves the

structure of the process template UN .

• Lemma 4.7 says that every transposition on a set of process indexes 1..N preserves the

structure of the global transition system GN for every N ≥ 1.

• Lemma 4.11 says that G2 and GN are trace equivalent under a set AP{1,2} of predicates

that take one of the forms: P1(i ), or P2(j ), or P3(i , j ), or P4(j , i ).

In the following, we present deﬁnitions and constructions to prove these lemmas.

4.1. Index Transpositions and Symmetric Point-to-point Systems. We ﬁrst recall
the deﬁnition of transposition. Given a set 1..N of indexes, we call a bijection α : 1..N → 1..N
a transposition between two indexes i , j ∈ 1..N if the following properties hold: α(i ) = j ,
and α(j ) = i , and ∀k ∈ 1..N : (k (cid:54)= i ∧ k (cid:54)= j ) ⇒ α(k ) = k . We let (i ↔ j ) denote a
transposition between two indexes i and j .

The application of a transposition to a template state is given in Deﬁnition 4.3. Informally,
applying a transposition α = (i ↔ j ) to a template state ρ generates a new template state
by switching only the evaluation of rcvd and lvar at indexes i and j . The application of a
transposition to a global conﬁguration is provided in Deﬁnition 4.4. In addition to process
conﬁgurations, we need to change message buﬀers and control components. We override
notation by writing αQ (ρ) and αC (κ) to refer the application of a transposition α to a state
ρ and to a conﬁguration κ, respectively. These functions αQ and αC are named a local
transposition and a global transposition, respectively.

Deﬁnition 4.3 (Local Transposition). Let UN be a process template with process in-
dexes 1..N , and ρ = ((cid:96), S1, . . . , SN , d1, . . . , dN ) be a state in UN . Let α = (i ↔ j ) be a
transposition on 1..N . The application of α to ρ, denoted as αQ (ρ), generates a tuple
1, . . . , d (cid:48)
((cid:96)(cid:48), S (cid:48)
(1) (cid:96) = (cid:96)(cid:48), and Si = S (cid:48)
(2) ∀k ∈ 1..N : (k (cid:54)= i ∧ k (cid:54)= j ) ⇒ (Sk = S (cid:48)

j and dj = d (cid:48)
k ∧ dk = d (cid:48)
k )

N ) such that
j , and Sj = S (cid:48)

i , and di = d (cid:48)

1, . . . , S (cid:48)

i , and

N , d (cid:48)

Deﬁnition 4.4 (Global Transposition). Let GN be a global system with process indexes
1..N , and κ be a conﬁguration in GN . Let α = (i ↔ j ) be a transposition on 1..N . The
application of α to κ, denoted as αC (κ), generates a conﬁguration in GN which satisﬁes
following properties:
(1) ∀i ∈ 1..N : lstate(αC (κ), α(i )) = αQ (lstate(κ, i )).
(2) ∀s, r ∈ 1..N : buf (αC (κ), α(s), α(r )) = buf (κ, s, r )
(3) ∀i ∈ 1..N : active(αC (κ), α(i )) = active(κ, i )

Since the content of every message in Msg does not have indexes of the receiver and
sender, no transposition aﬀects the messages. We deﬁne the application of a transposition to
one of send, compute, crash, and stutter template transitions return the same transition. We
extend the application of a transposition to a receive template transition as in Deﬁnition 4.5.

Deﬁnition 4.5 (Receive-transition Transposition). Let UN be a process template with
indexes 1..N , and α = (i ↔ j ) be a transposition on 1..N . Let crcv (S1, . . . , SN ) be a
transition in UN which refers to a task with a receive action. We let αR(crcv (S1, . . . , SN ))

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

15

i , and

1, . . . , S (cid:48)

j , and Sj = S (cid:48)

N ) in UN such that:

denote the application of α to crcv (S1, . . . , SN ), and this application returns a new transition
crcv (S (cid:48)
(1) Si = S (cid:48)
(2) ∀k ∈ 1..N : (k (cid:54)= i ∧ k (cid:54)= j ) ⇒ (Sk = S (cid:48)

k ∧ dk = d (cid:48)
k )
We let αU (UN ) and αG (GN ) denote the application of a transposition α to a process
template UN and a global transition system GN , respectively. Since these deﬁnitions are
straightforward, we skip them in this chapter. We prove later that αQ (UN ) = UN and
αC (GN ) = GN (see Lemmas 4.6 and 4.7).
Lemma 4.6 (Symmetric Process Template). Let UN = (QN , Tr N , Rel N , q 0
N ) be a process
template with indexes 1..N . Let α = (i ↔ j ) be a transposition on 1..N , and αQ be a local
transposition based on α (from Deﬁnition 4.3). The following properties hold:
(1) αQ is a bijection from QN to itself.
(2) The initial state is preserved under αQ , i.e. αQ (q 0
(3) Let ρ, ρ(cid:48) ∈ UN be states such that ρ
in Set(Msg). It follows αQ (ρ)

crcv (S1,...,SN )
−−−−−−−−−→ ρ(cid:48) for some sets of messages S1, . . . , SN

αR(crcv (S1,...,SN ))
−−−−−−−−−−−−→ αQ (ρ(cid:48)).

N ) = q 0
N .

(4) Let ρ, ρ(cid:48) be states in UN , and tr ∈ Tr N be one of send, local computation, crash and

stutter transitions such that ρ tr−→ ρ(cid:48). Then, αQ (ρ) tr−→ αQ (ρ(cid:48)).
(cid:1) be a global transition
Lemma 4.7 (Symmetric Global System). Let GN = (cid:0)CN , TrN , RN , g 0
system. Let α be a transposition on 1..N , and αC be a global transposition based on α (from
Deﬁnition 4.4). The following properties hold:
(1) αC is a bijection from CN to itself.
(2) The initial conﬁguration is preserved under αC , i.e. αC (g 0
(3) Let κ and κ(cid:48) be conﬁgurations in GN , and tr ∈ TrN be either a internal transition such

N ) = g 0
N .

N

that κ tr−→ κ(cid:48). It follows αC (κ) tr−→ αC (κ(cid:48)).

(4) Let κ and κ(cid:48) be conﬁgurations in GN . If κ (cid:59) κ(cid:48), then αC (κ) (cid:59) αC (κ(cid:48)).

4.2. Trace Equivalence of G2 and GN under AP{1,2}. Let G2 and GN be two global
transition systems whose processes follow the same symmetric point–to–point algorithm. In
the following, our goal is to prove Lemma 4.11 that says G2 and GN are trace equivalent under
a set AP{1,2} of predicates which take one of the forms: Q1(1), Q2(2), Q3(1, 2), or Q4(2, 1).
To do that, we ﬁrst present two construction techniques: Construction 4.1 to construct a
state in U2 from a state in UN , and Construction 4.2 to construct a global conﬁguration in
G2 from a given global conﬁguration in GN . Second, we deﬁne trace equivalence under a
set AP{1,2} of predicates in which every predicate takes one of the forms: P1(i ), or P2(j ),
or P3(i , j ), or P4(j , i ). Our deﬁnition of trace equivalence under AP{1,2} is extended from
the deﬁnition of trace equivalence in [Hoa80]. Next, we present two Lemmas 4.8 and 4.10.
These lemmas are required in the proof of Lemma 4.11.

To keep the presentation simple, when the context is clear, we simply write UN ,
(cid:1). We also write GN , instead of fully GN =

instead of fully UN = (cid:0)QN , Tr N , Rel N , q 0
(cid:0)CN , TrN , RN , g 0
Construction 4.1 (State Projection). Let A be an arbitrary symmetric point–to–point
algorithm. Let UN be a process template of A for some N ≥ 2, and ρN be a process

(cid:1).

N

N

16

T.H. TRAN, I. KONNOV, AND J. WIDDER

G3

G2

p3
p2
p1

p2
p1

Figure 1. Given execution in G3, construct an execution in G2 by index
projection.

conﬁguration of UN . We construct a tuple ρ2 = (pc1, rcvd1, rcvd2, v1, v2) based on ρN and a
set {1, 2} of process indexes in the following way:
(1) pc1 = pc(ρN ).
(2) For every i ∈ {1, 2}, it follows rcvdi = rcvd (ρN , i ).
(3) For every i ∈ {1, 2}, it follows vi = lvar (ρN , i ).

Construction 4.2 (Conﬁguration Projection). Let A be a symmetric point–to–point algo-
rithm. Let G2 and GN be two global transition systems of two instances of A for some N ≥ 2,
and κN ∈ CN be a global conﬁguration in GN . A tuple

κ2 = (s1, s2, buf 1

1 , buf 2

1 , buf 1

2 , buf 2

2 , act1, act2)

is constructed based on the conﬁguration κN and a set {1, 2} of indexes in the following way:
(1) For every i ∈ {1, 2}, a component si is constructed from lstate(κN , i ) with Construc-

tion 4.1 and indexes {1, 2}.

(2) For every s, r ∈ {1, 2}, it follows buf r
(3) For every process i ∈ {1, 2}, it follows acti = active(κN , i ).

s = buf (κN , s, r ).

Note that a tuple ρ2 constructed with Construction 4.1 is a state in U2, and a tuple
κ2 constructed with Construction 4.2 is a conﬁguration in G2. We call ρ2 (and κ2) the
index projection of ρN (and κN ) on indexes {1, 2}. The following Lemma 4.8 says that
Construction 4.2 allows us to construct an admissible sequence of global conﬁgurations in G2
based on a given admissible sequence in GN . Intuitively, the index projection throws away
processes 3..N as well as their corresponding messages and buﬀers. Moreover, for every
i , j ∈ {1, 2}, the index projection preserves (i) when process i takes a step, and (ii) what
action process i takes at time t ≥ 0, and (iii) messages between process i and process j . For
example, Figure 1 demonstrates an execution in G2 that is constructed based on a given
execution in G3 with the index projection.

Lemma 4.8. Let A be a symmetric point–to–point algorithm. Let G2 and GN be two
transition systems such that all processes in G2 and GN follow A, and N ≥ 2. Let πN =
0 κN
κN
1 . . . be a sequence
of conﬁgurations in G2 such that κ2
k on indexes {1, 2} for every
k ≥ 0. Then, π2 is admissible in G2.

1 . . . be an admissible sequence of conﬁgurations in GN . Let π2 = κ2

k is the index projection of κN

0κ2

Sketch of proof. The proof of Lemma 4.8 is based on the following observations:
(1) The application of Construction 4.1 to an initial template state of UN constructs an

initial template state of U2.

(2) Construction 4.1 preserves the template transition relation.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

17

G2

G3

p2
p1

p3
p2
p1

Figure 2. Construct an execution in G3 based on a given execution in G2.

(3) The application of Construction 4.2 to an initial global conﬁguration of GN constructs

an initial global conﬁguration of G2.

(4) Construction 4.2 preserves the global transition relation.

0κ2

1 . . . in GN such that κ2

1 . . . in G2, there
i is the index projection of

Moreover, Lemma 4.10 says that given an admissible sequence π2 = κ2
0 κN

exists an admissible sequence πN = κN
κN
i on indexes {1, 2} for every 0 ≤ i .
Deﬁnition 4.9. (Trace Equivalence under AP{1,2}). Let A be an arbitrary symmetric
point–to–point algorithm. Let G2 = (Q2, Tr2, Rel 2, q 0
N ) be
global transition systems of A for some N ≥ 2. Let AP{1,2} be a set of predicates that
take one of the forms: P1(i ), or P2(j ), or P3(i , j ), or P4(j , i ). Let L : Q2 ∪ QN → 2AP be
an evaluation function. We say that G2 and GN are trace equivalent under AP{1,2} if the
following constraints hold:
(1) For every admissible sequence π2 = κ2

2 ) and GN = (QN , TrN , Rel N , q 0

0κ2

1 . . . of conﬁgurations in G2, there exists an
i ) for

1 . . .in GN such that L(κ2

i ) = L(κN

0 κN

admissible sequence of conﬁgurations πN = κN
every i ≥ 0.

(2) For every admissible sequence admissible sequence of conﬁgurations πN = κN

1 . . .in
1 . . . of conﬁgurations in G2 such that

0 κN

0κ2

GN , there exists an admissible sequence π2 = κ2
L(κ2

i ) for every i ≥ 0.

i ) = L(κN

Lemma 4.10. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 and GN be
global transition systems of A for some N ≥ 2. Let π2 = κ2
1 . . . be an admissible sequence
of conﬁgurations in G2. There exists an admissible sequence πN = κN
1 . . . of conﬁgurations
i is the index projection of κN
in GN such that κ2

i on indexes {1, 2} for every i ≥ 0.

0 κN

0κ2

Sketch of proof. We construct an execution πN in GN based on π2 such that all processes
3..N crash from the beginning, and π2 is an index projection of πN . For instance, Figure 2
demonstrates an execution in G3 that is constructed based on one in G2. We have that π2 is
admissible in G2.

Lemma 4.11. Let A be a symmetric point–to–point algorithm. Let G2 and GN be its
instances for some N ≥ 2. Let AP{1,2} be a set of predicates that take one of the forms:
P1(1), P2(2), P3(1, 2) or P4(2, 1). It follows that G2 and GN are trace equivalent under
AP{1,2}.

Sketch of proof. The proof of Lemma 4.11 is based on Deﬁnition 4.9, Lemma 4.8, and
Lemma 4.10.

18

T.H. TRAN, I. KONNOV, AND J. WIDDER

5. Detailed Proofs for Cutoff Results in the Model of the Global

Distributed Systems

In this section, we present the detailed proofs for Theorems 4.1 and 4.2. In Sections 5.1 and
5.2 we prove that every transposition on a set of process indexes 1..N preserves the structure
of the process template UN and the structure of the global transition system GN for every
N ≥ 1, respectively. In Section 5.3 we show that G2 and GN are trace equivalent under
AP{1,2}. Next, we prove that G1 and GN are trace equivalent under AP{1} in Section 5.4.
Then, the detailed proofs for Theorems 4.1 and 4.2 is presented in Section 5.5. Finally, we
discuss why we can verify the strong completeness property of the failure detector of [CT96]
under synchrony by model checking instances of size 2 by applying our cutoﬀ results.

5.1. Transpositions and Process Templates. The proof of Lemma 4.6 requires the
following propositions:
• Given a transposition α, Proposition 5.1 says that a function αQ , which refers to the

application of α to a state in QN , is a bijection from QN to itself.

• Proposition 5.2 says that αQ has no eﬀect on the initial template state q 0
N .
• Propositions 5.3 and 5.4 describe the relationship between transpositions and template

transitions.

Lemma 4.6. Let UN = (QN , Tr N , Rel N , q 0
N ) be a process template with indexes 1..N . Let
α = (i ↔ j ) be a transposition on 1..N , and αQ be a local transposition based on α (from
Deﬁnition 4.3). The following properties hold:
(1) αQ is a bijection from QN to itself.
(2) The initial state is preserved under αQ , i.e. αQ (q 0
(3) Let ρ, ρ(cid:48) ∈ UN be states such that ρ
in Set(Msg). It follows αQ (ρ)

crcv (S1,...,SN )
−−−−−−−−−→ ρ(cid:48) for some sets of messages S1, . . . , SN

αR(crcv (S1,...,SN ))
−−−−−−−−−−−−→ αQ (ρ(cid:48)).

N ) = q 0
N .

(4) Let ρ, ρ(cid:48) be states in UN , and tr ∈ Tr N be one of send, local computation, crash and

stutter transitions such that ρ tr−→ ρ(cid:48). Then, αQ (ρ) tr−→ αQ (ρ(cid:48)).

Proof. We have: point 1 holds by Proposition 5.1, and point 2 holds by Proposition 5.2, and
point 3 holds by Proposition 5.3, and point 4 holds by Proposition 5.4.

Proposition 5.1. Let UN = (QN , Tr N , Rel N , q 0
N ) be a process template with indexes 1..N .
Let α = (i ↔ j ) be a transposition on 1..N , and αQ be a local transposition based on α (from
Deﬁnition 4.3). Then, αQ is a bijection from QN to itself.

Proof. Since two transpositions (i ↔ j ) and (j ↔ i ) are equivalent, we assume i < j . To
show that αQ is a bijection from QN to itself, we prove that the following properties hold:
(1) For every template state ρ(cid:48) ∈ QN , there exists a template conﬁguration ρ ∈ QN such

that αQ (ρ) = ρ(cid:48).

(2) For every pair of states ρ1, ρ2 ∈ QN , if αQ (ρ1) = αQ (ρ2), then ρ1 = ρ2.
We ﬁrst show that Point 1 holds. Assume that ρ(cid:48) is a following tuple
ρ(cid:48) = ((cid:96), S1, . . . , Si , . . . , Sj , . . . , SN , d1, . . . , di , . . . , dj , . . . , dN )

where (cid:96) ∈ Loc, Si ∈ Set(Msg), di ∈ D for every i ∈ 1..N . Let ρ be the following tuple

ρ = ((cid:96), S1, . . . , Sj , . . . , Si , . . . , SN , d1, . . . , dj , . . . , di , . . . , dN )

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

19

where Sk = S (cid:48)
Moreover, by the deﬁnition of a process template in Section 3.1, it follows ρ ∈ QN .

k for every k ∈ 1..N \ {i , j }. By Deﬁnition 4.3, we have αQ (ρ) = ρ(cid:48).

k ∧ dk = d (cid:48)

We now focus on Point 2. By deﬁnition of the application of a process–index transposition
to a template state, it is easy to check that αQ ((αQ (ρ))) = ρ for every ρ ∈ QN . It follows
that ρ1 = αQ ((αQ (ρ1))) = αQ ((αQ (ρ2))) = ρ2 since αQ (ρ1) = αQ (ρ2).

Therefore, Proposition 5.1 holds.

Proposition 5.2. Let UN = (QN , Tr N , Rel N , q 0
N ) be a process template. Let α = (i ↔ j )
be a transposition on 1..N , and αQ be a local transposition based on α (from Deﬁnition 4.3).
It follows that αQ (q 0

N ) = q 0
N .

Proof. By deﬁnition of q 0
lvar (q 0

N in Section 3.1, we have rcvd (q 0

N , i ) = rcvd (q 0

N , j ) and lvar (q 0

N , i ) =

N , j ). It immediately follows αQ (q 0
N ) = q 0
N .
Proposition 5.3. Let UN = (QN , Tr N , Rel N , q 0
N ) be a process template with indexes 1..N .
crcv (S1,...,SN )
Let ρ0 and ρ1 be states in UN such that ρ0
−−−−−−−−−→ ρ1 for some sets of messages:
S1, . . . , SN ⊆ Set(Msg). Let α = (i ↔ j ) be a transposition on 1..N , and αR be a receive-
αR(crcv (S1,...,SN ))
transition transposition based on α (from Deﬁnition 4.5). It follows αQ (ρ0)
−−−−−−−−−−−−→
αQ (ρ1).

Proof. We prove that all Constraints (a)–(c) between two states αQ (ρ0) and αQ (ρ1) in the
transition csnd deﬁned in Section 3.1 hold. First, we focus on Constraint (a). We have
pc(αQ (ρ1)) = pc(ρ1) by Deﬁnition 4.3. We have pc(ρ1) = nextLoc(pc(ρ0)) by the semantics
of crcv (S1, . . . , SN ) in Section 3.1. We have nextLoc(pc(ρ0)) = nextLoc(pc(αQ (ρ0))) by
Deﬁnition 4.3. It follows pc(αQ (ρ1)) = nextLoc(pc(αQ (ρ0))). Moreover, we have

{m} = genMsg(pc(ρ0))

(by the semantics of crcv in Section 3.1)

= genMsg(pc(αQ (ρ0)))

(by Deﬁnition 4.3)

Hence, Constraint (a) holds.

Now we focus on Constraint (b). By Deﬁnition 4.3, we have rcvd (αQ (ρ0), k ) = rcvd (ρ0, k )
and rcvd (αQ (ρ1), k ) = rcvd (ρ1, k ) for every k ∈ 1..N \ {i , j }. We have rcvd (ρ1, k ) = Sk ∪
rcvd (ρ0, k ) by the semantics of crcv (S1, . . . , SN ) in Section 3.1. It follows rcvd (αQ (ρ1), k ) =
Sk ∪ rcvd (αQ (ρ0), k ) for every k ∈ 1..N \ {i , j }. Now we focus on rcvd (αQ (ρ1), i ). We have
rcvd (αQ (ρ1), i ) = rcvd (ρ1, j ) and rcvd (αQ (ρ0), i ) = rcvd (ρ0, j ) by Deﬁnition 4.3. Since
rcvd (ρ1, j ) = rcvd (ρ0, j ) ∪ Sj , it follows rcvd (αQ (ρ1), i ) = rcvd (αQ (ρ0), i ) ∪ Sj . By similar
arguments, we have rcvd (αQ (ρ1), j ) = rcvd (αQ (ρ0), j ) ∪ Si . Hence, Constraint (b) holds.

Now we focus on Constraint (c). By similar arguments in the proof of Constraint (b),

for every k ∈ 1..N \ {i , j }, we have

lvar (αQ (ρ1), k ) = nextVal (cid:0)pc(αQ (ρ0)), Sk , lvar (αQ (ρ0), k )(cid:1)

Now we focus on lvar (αQ (ρ1), i ). We have lvar (αQ (ρ1), i ) = lvar (ρ1, j ) by Deﬁni-
tion 4.3. By the semantics of crcv (S1, . . . , SN ) in Section 3.1, it follows that lvar (ρ1, j ) =
nextVal (cid:0)pc(ρ0), Sj , lvar (ρ0, j )(cid:1). By Deﬁnition 4.3, we have

lvar (αQ (ρ1), i )

= lvar (ρ1, j )
= nextVal (cid:0)pc(ρ0), Sj , lvar (ρ0, j )(cid:1)
= nextVal (cid:0)pc(αQ (ρ0)), Sj , lvar (αQ (ρ0), i )(cid:1)

20

T.H. TRAN, I. KONNOV, AND J. WIDDER

Moreover, by similar arguments, we have

lvar (αQ (ρ1), j ) = nextVal (cid:0)pc(αQ (ρ0)), Si , lvar (αQ (ρ0), i )(cid:1)

Constraint (c) holds. Hence, we have αQ (ρ0)

αR(crcv (S1,...,SN ))
−−−−−−−−−−−−→ αQ (ρ1).

Proposition 5.4. Let UN = (QN , Tr N , Rel N , q 0
N ) be a process template with indexes 1..N .
Let ρ and ρ(cid:48) be states in UN , and tr ∈ Tr N be a transition such that ρ tr−→ ρ(cid:48) and tr refers
to a task without a receive action. Let α = (i ↔ j ) be a transposition on 1..N , and αQ be a
local transposition based on α (from Deﬁnition 4.3). It follows αQ (ρ) tr−→ αQ (ρ(cid:48)).

Proof. We prove Proposition 5.4 by case distinction.

• Case ρ0

csnd (m)
−−−−−→ ρ1. By similar arguments in the proof of Proposition 5.3, it follows
pc(αQ (ρ1)) = nextLoc(pc(αQ (ρ0))) and {m} = genMsg(pc(αQ (ρ0))). Constraint (a) holds.
By Deﬁnition 4.3, for every k ∈ 1..N \ {i , j }, we have rcvd (αQ (ρ0), k ) = rcvd (ρ0, k ) and
rcvd (αQ (ρ1), k ) = rcvd (ρ1, k ). Hence, it follows rcvd (αQ (ρ1), k ) = rcvd (αQ (ρ0), k ) for ev-
ery k ∈ 1..N \ {i , j }. Now we focus on rcvd (αQ (ρ1), i ). We have rcvd (αQ (ρ1), i ) =
rcvd (ρ1, j ) and rcvd (αQ (ρ0), i ) = rcvd (ρ0, j ) by Deﬁnition 4.3. Since rcvd (ρ1, j ) =
rcvd (ρ0, j ), it follows that rcvd (αQ (ρ1), i ) = rcvd (αQ (ρ0), i ). By similar arguments,
we have rcvd (αQ (ρ1), j ) = rcvd (αQ (ρ0), j ). Constraint (b) holds. By similar arguments
in the proof of Proposition 5.3, for every k ∈ 1..N , we have

lvar (αQ (ρ1), k ) = nextVal (cid:0)pc(αQ (ρ0)), ∅, lvar (αQ (ρ0), k )(cid:1)

Constraint (c) holds. It follows αQ (ρ1)

csnd (m)
−−−−−→ αQ (ρ(cid:48)

1).

• Case ρ0
• Case ρ0

comp
−−−→ ρ1. Similar to the case of csnd .
crash−−−→ ρ1. We have pc(αQ (ρ1)) = pc(ρ1) and pc(αQ (ρ0)) = pc(ρ0) by Deﬁnition 4.3.
By the transitions’ assumptions, we have pc(αQ (ρ1)) = (cid:96)crash and pc(αQ (ρ0)) (cid:54)= (cid:96)crash .
it follows ∀k ∈ 1..N : rcvd (αQ (ρ1), k ) =
By similar arguments in the case of csnd ,
rcvd (αQ (ρ0), k ) ∧ lvar (αQ (ρ1), k ) = lvar (αQ (ρ0), k ). Hence, it holds αQ (ρ0) crash−−−→ αQ (ρ1).

• Case ρ stutter−−−−→ ρ(cid:48). Similar to the case of csnd .
Hence, Proposition 5.4 holds.

5.2. Transpositions and Global Systems. The proof strategy of Lemma 4.7 is similar
to the one of Lemma 4.6, and the proof of Lemma 4.7 requires the following Propositions 5.5,
5.6, 5.7 and 5.8.

Lemma 4.7.

N

Let GN = (cid:0)CN , TrN , RN , g 0

(cid:1) be a global transition system. Let α be a transposition on
1..N , and αC be a global transposition based on α (from Deﬁnition 4.4). The following
properties hold:
(1) αC is a bijection from CN to itself.
(2) The initial conﬁguration is preserved under αC , i.e. αC (g 0
(3) Let κ and κ(cid:48) be conﬁgurations in GN , and tr ∈ TrN be either a internal transition such

N ) = g 0
N .

that κ tr−→ κ(cid:48). It follows αC (κ) tr−→ αC (κ(cid:48)).

(4) Let κ and κ(cid:48) be conﬁgurations in GN . If κ (cid:59) κ(cid:48), then αC (κ) (cid:59) αC (κ(cid:48)).

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

21

Proof. We have: point 1 holds by Proposition 5.5, and point 2 holds by Proposition 5.6, and
point 3 holds by Proposition 5.7, and point 4 holds by Proposition 5.8.
Proposition 5.5. Let GN = (cid:0)CN , TrN , RN , g 0
(cid:1) be a global transition system with indexes
N
1..N . Let α be a process–index transposition on 1..N , and αC be a global transposition based
on α (from Deﬁnition 4.4). Then, αC is a bijection from CN to itself.

Proof. By applying similar arguments in the proof of Proposition 5.1.
Proposition 5.6. Let GN = (cid:0)CN , TrN , RN , g 0
(cid:1) be a global transition system with indexes
N
1..N . Let α be a process–index transposition on 1..N , and αC be a global transposition based
on α (from Deﬁnition 4.4). It follows that αC (g 0

N ) = g 0
N .

Proof. By applying similar arguments in the proof of Proposition 5.2.
(cid:1) be a global transition system with indexes
Proposition 5.7. Let GN = (cid:0)CN , TrN , RN , g 0
1..N and a process template UN = (QN , Tr N , Rel N , q 0
N ). Let α be a process–index transposi-
tion on 1..N , and αC be a global transposition based on α (from Deﬁnition 4.4). Let κ and
κ(cid:48) be conﬁgurations in GN , and tr ∈ TrN be an internal transition such that κ tr−→ κ(cid:48). Then,
αC (κ) tr−→ αC (κ(cid:48)).
Proof. We prove Proposition 5.7 by case distinction.
(1) Sub-round Schedule. We prove that all Constraints (a)–(e) for the sub-round Schedule

N

hold as follows.

First, we focus on Constraint (a). By Proposition 5.5, both αC (κ) and αC (κ(cid:48)) are con-
ﬁgurations in GN . By Deﬁnition 4.4, for every i ∈ 1..N , we have active(αC (κ), α(i )) =
active(κ, i ). We have ¬active(κ, i ) by the semantics of the sub-round Schedule in Sec-
tion 3.2. It follows ¬active(αC (κ), α(i )). Hence, the sub-round Schedule can start with
a conﬁguration αC (κ0). Constraint(a) holds.

Now we focus on Constraint (b) by examining process transitions. For every i ∈ 1..N ,

by Lemma 4.6, we have

lstate(κ, i ) stutter−−−−→ lstate(κ(cid:48), i ) ⇒ αQ (lstate(κ, i )) stutter−−−−→ αQ (lstate(κ(cid:48), i ))

By Deﬁnition 4.4, it follows αQ (lstate(κ, i )) = lstate(αC (κ), α(i )) and αQ (lstate(κ(cid:48), i )) =
lstate(αC (κ(cid:48)), α(i )). Hence, it follows

lstate(κ, i ) stutter−−−−→ lstate(κ(cid:48), i )

⇒ lstate(αC (κ), α(i )) stutter−−−−→ lstate(αC (κ(cid:48)), α(i ))

By similar arguments, we have

lstate(κ, i ) crash−−−→ lstate(κ(cid:48), k )

⇒ lstate(αC (κ), α(i )) crash−−−→ lstate(αC (κ(cid:48)), α(k ))

Hence, every process makes either a crash transition or a stuttering step from a conﬁgu-
ration αC (κ) to a conﬁguration αC (κ(cid:48)). Constraint (b) holds.

We now focus on Constraint (c) by examining control components of crashed processes.
Assume that pc(lstate(κ(cid:48), r )) = (cid:96)crash for some i ∈ 1..N . By the semantics of the sub-
round Schedule in Section 3.2, we have ¬active(κ(cid:48), i ). By Deﬁnition 4.4, it follows
¬active(αC (κ), α(i )) ∧ ¬active(κ(cid:48), i ). Constraint (c) hodls.

22

T.H. TRAN, I. KONNOV, AND J. WIDDER

Now we focus on Constraint (d) by examining incoming message buﬀers to cor-
rect processes. By Deﬁnition 4.4, we have buf (αC (κ(cid:48)), α(s), α(r )) = buf (κ(cid:48), s, r )
for every s, r ∈ 1..N . By the semantic of the sub-round Schedule in Section 3.2,
if pc(lstate(κ(cid:48), r )) (cid:54)= (cid:96)crash ,
, then buf (κ(cid:48), s, r ) = buf (κ, s, r ). By Deﬁnition 4.4,
we have buf (κ, s, r ) = buf (αC (κ), α(s), α(r )). Hence, Constraint (d) holds since
buf (αC (κ(cid:48)), α(s), α(r )) = buf (αC (κ), α(s), α(r ))

Now we focus on Constraint (e) by examining incoming message buﬀers to a crashed
process. Let r be an index in 1..N such that pc(lstate(κ(cid:48), r )) = (cid:96)crash . If pc(lstate(κ(cid:48), r )) =
(cid:96)crash , then buf (αC (κ(cid:48)), α(s), α(r )) = buf (κ(cid:48), s, r ) by similar arguments in the above case
of pc(lstate(κ(cid:48), r )) (cid:54)= (cid:96)crash . By the semantics of the sub-round Schedule in Section 3.2,
we have buf (κ(cid:48), s, r ) = ∅. It follows buf (αC (κ(cid:48)), α(s), α(r )) = ∅. Constraint (e) holds.

It implies αC (κ) Sched−−−→ αC (κ(cid:48)).

(2) Sub-round Send. We prove that all Constraints (a)–(c) for the sub-round Send hold as

follows. By Deﬁnition 4.4, we have

active(αC (κ), α(i )) = active(κ, i )

pc(lstate(αC (κ), α(i ))) = pc(αQ (lstate(κ, i )))

By Deﬁnition 4.3, we have pc(αQ (lstate(κ, i ))) = pc(lstate(κ, i )) for every i ∈ 1..N .
Hence, we have pc(lstate(αC (κ), α(i ))) = pc(lstate(κ, i )). For every i ∈ 1..N , we have
Enabled (κ, i , Locsnd ) ⇔ Enabled (αC (κ), α(i ), Locsnd ) by the deﬁnition of Enabled in
Section 3.2. It implies that a process lstate(κ, s) is enabled in this sub-round if and only
if a process lstate(αC (κ), α(s)) is enabled in this sub-round for every s ∈ 1..N .

Now we focus on Constraint (a) by examining processes which are not enabled in this
sub-round Send. Let i be an arbitrary index in 1..N such that ¬Enabled (κ, i , Locsnd ).
By the semantics of the sub-round Send in Section 3.2, it follows that lstate(κ, i ) stutter−−−−→
lstate(κ(cid:48), i ). By Deﬁnition 4.4, we have

Enabled (αC (κ), α(i ), Locsnd ) = Enabled (κ, i , Locsnd )

Since ¬Enabled (κ, i , Locsnd ) (we are examining inactive processes in this sub-round
Send), we have ¬Enabled (αC (κ), α(i ), Locsnd ). We prove that

as follows. By Deﬁnition 4.4, we have

Frozen S (αC (κ), αC (κ(cid:48)), α(i ))

αQ (lstate(κ, i )) = lstate(αC (κ), α(i ))
αQ (lstate(κ(cid:48), i )) = lstate(αC (κ(cid:48)), α(i ))

By Proposition 5.4, it follows that αQ (lstate(κ, i )) stutter−−−−→ αQ (lstate(κ(cid:48), i )). It follows
lstate(αC (κ), α(i )) stutter−−−−→ lstate(αC (κ(cid:48)), α(i )). We now examine the control component
for a process pi . By Deﬁnition 4.4, we have

active(κ, i ) = active(αC (κ), α(i ))
active(κ(cid:48), i ) = active(αC (κ(cid:48)), α(i ))

By deﬁnition of Frozen S in Section 3.2, we have active(κ, i ) = active(κ(cid:48), i ). It follows
active(αC (κ), α(i )) = active(αC (κ(cid:48)), α(i )). We now show that each outgoing message
buﬀer from a process pi is unchanged from αC (κ) to αC (κ(cid:48)). By Deﬁnition 4.4, we have
buf (αC (κ(cid:48)), α(i ), α((cid:96))) = buf (κ(cid:48), i , (cid:96)). Since buf (κ(cid:48), i , (cid:96)) = buf (κ, i , (cid:96)), (we are examining

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

23

inactive processes in this sub-round Send), it follows buf (αC (κ(cid:48)), α(i ), α((cid:96))) = buf (κ, i , (cid:96)).
By Deﬁnition 4.4, we have buf (κ, i , (cid:96)) = buf (αC (κ), α(i ), α((cid:96))). It follows that

buf (αC (κ(cid:48)), α(i ), α((cid:96))) = buf (αC (κ), α(i ), α((cid:96)))

Therefore, it follows Frozen S (αC (κ), αC (κ(cid:48)), α(i )). Constraint (a) holds.

Now we focus on Constraint (b) by examining processes which are enabled in this
sub-round Send. Let s ∈ 1..N be an arbitrary index such that active(κ, i ). By the
csnd (m)
−−−−−→ lstate(κ(cid:48), s).
semantics of the sub-round Send in Section 3.2, it follows lstate(κ, s)
We have lstate(κ, s) = lstate(αC (κ), α(s)) and lstate(κ(cid:48), s) = lstate(αC (κ(cid:48)), α(s)) by
Deﬁnition 4.4. By Proposition 5.4, it follows

lstate(αC (κ), α(s))

csnd (m)
−−−−−→ lstate(αC (κ(cid:48)), α(s))

We show that m is new in buﬀers buf (αC (κ), α(s), 1), . . . , buf (αC (κ), α(s), 1). By
Deﬁnition 4.4, for every s, r ∈ 1..N , we have

buf (αC (κ), α(s), α(r )) = buf (κ, s, r )
buf (αC (κ(cid:48)), α(s), α(r )) = buf (κ(cid:48), s, r )

We have m /∈ buf (κ, s, r ) and m ∈ buf (κ(cid:48), s, r ) by the semantics of the sub-round

Send in Section 3.2. It follows

m /∈ buf (αC (κ), α(s), α(r ))

and m ∈ buf (αC (κ), α(s), α(r ))

In other words, the message m is new in the buﬀer buf (αC (κ), α(s), α(r )). As a result,
Constraint (b) holds.

Now we focus on Constraint (c). Let s ∈ 1..N be an arbitrary index such that
Enabled (κ, i , Locsnd ) = (cid:62). By arguments at the beginning of the proof of Proposi-
tion 5.15, we have Enabled (αC (κ), α(i ), Locsnd ). By the semantics of the sub-round
Send in Section 3.2, we have ¬active(κ(cid:48), i ). By Deﬁnition 4.4, we have active(κ(cid:48), i ) =
active(αC (κ(cid:48)), α(i )). It follows ¬active(αC (κ(cid:48)), α(i )). Constraint (c) holds.

It implies that αC (κ) Snd−−→ αC (κ(cid:48)).

(3) Sub-round Receive. By similar arguments in the case of the sub-round Send, we have
that Constraints (a) and (c) in the sub-round Receive holds. In the following, we focus
on Constraint (b). By similar arguments in the case of the sub-round Send, we have
that a process lstate(κ, s) is enabled in this sub-round Receive if and only if a process
lstate(αC (κ), α(s)) is enabled in this sub-round Receive for every s ∈ 1..N . Hence, we
focus on processes which are enabled in this sub-round Receive. Let r ∈ 1..N be an index
such that Enabled (κ, i , Locrcv ). By the semantics of the sub-round Receive in Section 3.2,
crcv (S1,...,SN )
−−−−−−−−−→ lstate(κ(cid:48), r ) for some sets S1, . . . , SN ⊆ Set(Msg) of

we have lstate(κ, r )
messages. By Deﬁnition 4.3, we have

αQ (lstate(κ, r )) = lstate(αC (κ), α(r ))
αQ (lstate(κ(cid:48), r )) = lstate(αC (κ(cid:48)), α(r ))

By Proposition 5.3, it follows

lstate(αC (κ), α(r ))

αR(crcv (S1,...,SN ))
−−−−−−−−−−−−→ lstate(αC (κ(cid:48)), α(r ))

Now we focus on the update of message buﬀers. By the semantics of the sub-round
Receive in Section 3.2, we have Ss ⊆ buf (κ, s, r ) for every s ∈ 1..N . By Deﬁnition 4.4, we

24

T.H. TRAN, I. KONNOV, AND J. WIDDER

have buf (κ, s, r ) = buf (αC (κ), α(s), α(r )). It follows that Ss ⊆ buf (αC (κ), α(s), α(r ))
for every s ∈ 1..N . We now prove that for every s ∈ 1..N , Ss is removed from the
message buﬀer buf (αC (κ(cid:48)), α(s), α(r )). By Deﬁnition 4.4, we have

buf (αC (κ(cid:48)), α(s), α(r )) = buf (κ(cid:48), s, r )
buf (αC (κ), α(s), α(r )) = buf (κ, s, r )

By the semantics of the sub-round Receive in Section 3.2, we have

Ss ∩ buf (κ(cid:48), s, r ) = ∅
buf (κ, s, r ) = buf (κ(cid:48), s, r ) ∪ Ss

It follows that

Ss ∩ buf (αC (κ(cid:48)), α(s), α(r )) = ∅¸
buf (αC (κ), α(s), α(r )) = buf (αC (κ(cid:48)), α(s), α(r )) ∪ Ss

Constraint (b) holds. It implies that αC (κ(cid:48)) Rcv−−→ αC (κ).

(4) Sub-round Computation. By applying similar arguments in above sub-rounds.

Therefore, Proposition 5.7 holds.
(cid:1) be a global transition system with indexes
Proposition 5.8. Let GN = (cid:0)CN , TrN , RN , g 0
1..N and a process template UN = (QN , Tr N , Rel N , q 0
N ). Let κ and κ(cid:48) be conﬁgurations in
GN such that κ (cid:59) κ(cid:48). Let α be a transposition on 1..N , and αC be a global transposition
based on α (from Deﬁnition 4.4). It follows αC (κ) (cid:59) αC (κ(cid:48)).

N

Proof. It immediately follows by Proposition 5.7 and the fact that for all i ∈ 1..N , we have
active(αC (κ), α(i )) = active(κ, i ).

5.3. Trace Equivalence of G2 and GN under AP{1,2}. Recall that G2 and GN are two
global transition systems of N and 2 processes, respectively, such that every correct process
runs the same arbitrary symmetric point–to–point algorithm, and a set AP{1,2} contains
predicates that takes one of the forms: P1(1), P2(2), P3(1, 2), or P4(2, 1) where 1 and 2 are
process indexes.

Proposition 5.9. Let A be an arbitrary symmetric point–to–point algorithm. Let U2 and
UN be two process templates of A for some N ≥ 2, and ρN ∈ QN be a state of UN . Let ρ2
be a tuple that is the application of Construction 4.1 to ρN and indexes {1, 2}. Then, ρ2 is
a template state of U2.

Proof. It immediately follows by Construction 4.1.

Proposition 5.10. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 and
GN be two global transition systems of two instances of A for some N ≥ 2, and κN ∈ CN be
a global conﬁguration in GN . Let κ2 be a tuple that is the application of Construction 4.2 to
κN and indexes {1, 2}. Then, κ2 is a global conﬁguration of G2.

Proof. It immediately follows by Construction 4.2.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

25

Lemma 4.8. Let A be a symmetric point–to–point algorithm. Let G2 and GN be two
transition systems such that all processes in G2 and GN follow A, and N ≥ 2. Let πN =
κN
0 κN
1 . . . be a sequence
of conﬁgurations in G2 such that κ2
k on indexes {1, 2} for every
k ≥ 0. Then, π2 is admissible in G2.

1 . . . be an admissible sequence of conﬁgurations in GN . Let π2 = κ2

k is the index projection of κN

0κ2

The proof of Lemma 4.8 requires the following propositions:

(1) Proposition 5.11 says that the application of Construction 4.1 to an initial template

state of GN constructs an initial template state of G2.

(2) Lemmas 5.12 and 5.13 say that Construction 4.1 preserves the process transition relation.
(3) Proposition 5.14 says that the application of Construction 4.2 to an initial global

conﬁguration of GN constructs an initial global conﬁguration of G2.

(4) Propositions 5.15 and 5.16 say Construction 4.2 preserves the global transition rela-
tion. Proposition 5.15 captures internal transitions. Proposition 5.16 captures round
transitions.
Proof of Lemma 4.8. It is easy to check that Lemma 4.8 holds by Propositions 5.11,

5.13, 5.14, 5.15, and 5.16. The detailed proofs of these propositions are given below.

Proposition 5.11. Let A be an arbitrary symmetric point–to–point algorithm. Let UN =
(QN , Tr N , Rel N , q 0
2 ) be two process templates of A for some N ≥ 2.
It follows that q 0

N ), U2 = (Q2, Tr 2, Rel 2, q 0
2 is the index projection of q 0
Proof. It follows by Construction 4.1 and the deﬁnition of q 0

N on indexes {1, 2}.

2 in Section 3.1.

crcv (S1,...,SN )
−−−−−−−−−→ ρ1 for some sets S1, . . . , SN of messages . Let ρ(cid:48)

Proposition 5.12. Let A be an arbitrary symmetric point–to–point algorithm, and U2
and UN be process templates of A. Let ρ0 and ρ1 be template states in UN such that
ρ0
1 be template states
of U2 such that they are constructed with Construction 4.2 and based on conﬁgurations ρ0
rcv (S1,S2)
−−−−−−→ ρ(cid:48)
and ρ1 and indexes {1, 2}. It follows ρ(cid:48)
1.
0

0 and ρ(cid:48)

Proof. We prove that all Constraints (a)–(c) for the transition csnd deﬁned in Section 3.1
hold. First, we focus on Constraint (a). We have pc(αQ (ρ1)) = pc(ρ1) by Deﬁnition 4.3.
We have pc(ρ1) = nextLoc(pc(ρ0)) by the semantics of crcv (S1, . . . , SN ) in Section 3.1. We
have nextLoc(pc(ρ0)) = nextLoc(pc(ρ(cid:48)
0)) by Deﬁnition 4.3. Hence, it follows pc(αQ (ρ1)) =
nextLoc(pc(αQ (ρ0))). Moreover, we have ∅ = genMsg(pc(ρ0)) by the semantics of crcv in
Section 3.1. By Construction 4.1, we have genMsg(pc(ρ0)) = genMsg(pc(ρ(cid:48)
0)). It follows
that genMsg(pc(ρ(cid:48)

0)) = ∅. Constraint (a) holds.

We now check components related to received messages (Constraint (b)). Let i be an

arbitrary index in 1..2. It follows

rcvd (ρ(cid:48)
1, i )
= rcvd (ρ1, i )
= rcvd (ρ0, i ) ∪ Si
= rcvd (ρ(cid:48)
0, i ) ∪ Si

(by Construction 4.1)
(by the semantics of crcv (S1, . . . , SN ) in Section 3.1)
(by Construction 4.1)

Hence, we have ∀i ∈ 1..2 : rcvd (ρ(cid:48)
similar arguments in the proof of Proposition 5.3, we have

1, i ) = rcvd (ρ(cid:48)

0, i ) ∪ Si . Constraint (b) holds. Moreover, by

∀i ∈ 1..2 : lvar (ρ(cid:48)

1, i ) = nextVal (cid:0)pc(ρ(cid:48)

0), Si , lvar (ρ(cid:48)

0, i )(cid:1)

26

T.H. TRAN, I. KONNOV, AND J. WIDDER

Constraint (c) holds. It follows ρ(cid:48)
0

rcv (S1,S2)
−−−−−−→ ρ(cid:48)
1.

Proposition 5.13. Let A be an arbitrary symmetric point–to–point algorithm, and U2 and
UN be process templates of A. Let tr ∈ Tr N be a transition such that it is one of send,
computation, crash or stuttering transitions. Let ρ0 and ρ1 be template states in UN such
0 and ρ(cid:48)
1 be states of U2 such that they are the index projection of ρ0
that ρ0
and ρ1 on indexes {1, 2}, respectively. Then, ρ(cid:48)
0
Proof. By similar arguments in the proof of Lemma 5.12.

tr−→ ρ1. Let ρ(cid:48)

tr−→ ρ(cid:48)
1.

Now we turn to properties of global conﬁgurations under Constructions 4.2.

Proposition 5.14. Let A be an arbitrary symmetric point–to–point algorithm. Let GN =
(CN , TrN , RN , g 0
2 ) be two transition systems of two instances of A
for some N ≥ 2. It follows that g 0
Proof. It immediately follows by Construction 4.2 and the deﬁnition of g 0
N .

2 is the index projection of g 0

N ) and G2 = (C2, Tr2, R2, g 0

N on indexes {1, 2}.

tr−→ κ(cid:48)
1.

0 and ρ(cid:48)

2 ) and GN = (CN , TrN , RN , g 0

Proposition 5.15. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 =
(C2, Tr2, R2, g 0
N ) be global transition systems such that all
processes in G2 and GN follow the same algorithm A for some N ≥ 2. Let κ0 and κ1 be
tr−→ κ1 where tr is an internal transition. Let κ(cid:48)
global conﬁgurations in GN such that κ0
0
and κ(cid:48)
1 be the index projection of κ0 and κ1 on a set {1, 2} of indexes, respectively. It follows
that κ(cid:48)
0
Proof. First, by Proposition 5.10, both ρ(cid:48)
1 are conﬁgurations in G2. We prove
Proposition 5.15 by case distinction. Here we provide detailed proofs only of two sub-rounds
Schedule and Send. The proofs of other sub-rounds are similar.
• Sub-round Schedule. We prove that all Constraints (a)–(c) hold in κ(cid:48)

1. We now focus
on Constraint (a). We have active(κ(cid:48)
0, 1) = active(κ0, 1) and active(κ0, 2) = active(κ0, 2)
by Construction 4.2. By the semantics of the sub-round Schedule in Section 3.2, we have
0, 1) ∧ ¬active(κ(cid:48)
¬active(κ0, 1) ∧ ¬active(κ0, 2). Hence, it follows ¬active(κ(cid:48)
0, 2). Hence,
the sub-round Schedule can start with a conﬁguration κ(cid:48)
0. Constraint (a) holds. By
Proposition 5.13, Constraint (b) holds. Constraint (c) holds by Construction 4.2. Now
we focus on incoming message buﬀers to correct processes to prove Constraint (d). Let r
be an index in 1..N such that pc(lstate(κ(cid:48)
1, r )) (cid:54)= (cid:96)crash . By Construction 4.2, for every
s ∈ 1..2, we have buf (κ(cid:48)
0, s, r ). By the
semantics of the sub-round Schedule in Section 3.2, we have buf (κ1, s, r ) = buf (κ0, s, r )
for every s ∈ 1..2. It follows buf (κ(cid:48)
0, s, r ) for every s ∈ 1..2. Constraint (d)
holds. Now we focus on message buﬀers to crashed processes to prove Constraint (d). Let
r be an index in 1..N such that pc(lstate(κ(cid:48)
1, r )) = (cid:96)crash . By Construction 4.2, for every
s ∈ 1..2, we have buf (κ(cid:48)
1, s, r ) = buf (κ1, s, r ). By the semantics of the sub-round Schedule
in Section 3.2, we have buf (κ1, s, r ) = ∅ for every s ∈ 1..2, It follows buf (κ(cid:48)
1, s, r ) = ∅ for
every s ∈ 1..2. Constraint (e) holds. It implies that κ(cid:48)
0

1, s, r ) = buf (κ1, s, r ) and buf (κ0, s, r ) = buf (κ(cid:48)

1, s, r ) = buf (κ(cid:48)

Sched−−−→ κ(cid:48)
1.

0 and κ(cid:48)

• Sub-round Send. For every k ∈ 1..2, we have active(κ(cid:48)

0, 1) = active(κ0, 1) and active(κ0, 2) =
active(κ0, 2). Hence, if a process pN
in GN is enabled in this sub-round, a corresponding
i
process p2
in GN is also for every i ∈ 1..2. We prove that all Constraints (a)–(c) between
i
κ(cid:48)
0 and κ(cid:48)
1 for the sub-round Send deﬁned in Section 3.2 hold. By similar arguments in
the proof of Proposition 5.15, Constraint (a) holds. Now we focus on enable processes to
prove Constraints (b) and (c).

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

27

Assume that a process pN
i

0, i )
1, i , 1) and buf (κ(cid:48)

1, i , (cid:96)) = buf (κ1, i , (cid:96)) and buf (κ(cid:48)

in GN has sent a message m in this sub-round, we show
that a process p2
in G2 has also sent the message m in this sub-round where i ∈ 1..2.
i
csnd (m)
By Proposition 5.13, it follows that lstate(κ(cid:48)
−−−−−→ lstate(κ(cid:48)
1, i ). Now we show
that the message m is new in buﬀers buf (κ(cid:48)
1, i , 2). By Construction
4.2, we have buf (κ(cid:48)
0, i , (cid:96)) = buf (κ0, i , (cid:96)) for every (cid:96) ∈ 1..2.
By the semantics of the sub-round Send in Section 3.2, we have buf (κ1, i , (cid:96)) = {m} ∪
buf (κ0, i , (cid:96)). It follows buf (κ(cid:48)
0, i , (cid:96)) for every (cid:96) ∈ 1..2. Moreover, since
m /∈ buf (κ0, i , (cid:96)) for every (cid:96) ∈ 1..2, we have m /∈ buf (κ(cid:48)
0, i , (cid:96)). Therefore, the message
m is new in a buﬀer buf (κ(cid:48)
1, i , (cid:96)) for every (cid:96) ∈ 1..2. Constraint (b) holds. Moreover, by
Construction 4.2, we have active(κ1, i ) = active(κ(cid:48)
1, i ). We have ¬active(κ1, i ) by the
semantics of the sub-round Send in Section 3.2. It follows ¬active(κ(cid:48)
1, i ). Constraint (e)
holds. It follows that κ(cid:48)
0

1, i , (cid:96)) = {m}∪buf (κ(cid:48)

Snd−−→ κ(cid:48)
1.

• Sub-rounds Receive and Computation. Similar.
Therefore, Proposition 5.15 holds.

Proposition 5.16. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 and
GN be global transition systems of A for some N ≥ 2. Let κ0 and κ1 be global conﬁgurations
of CN such that κ0 (cid:59) κ1. Let κ(cid:48)
1 be the index projection of κ0 and κ1 on indexes
{1, 2}. Then, κ(cid:48)
0

0 and κ(cid:48)

(cid:59) κ(cid:48)
1.

Proof. It immediately follows by Propositions 5.13 and 5.15.

Now we present how to construct an admissible path of GN from a given admissible
path of G2 with Lemma 4.10 below. The main argument is that from an admissible sequence
of conﬁgurations in G2, we can get an admissible sequence of conﬁgurations in GN by letting
processes 3 to N be initially crashed. The proof of Lemma 4.10 requires the preliminary
Propositions 5.17 and 5.18.

Proposition 5.17. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 and
GN be global transition systems of A for some N ≥ 2. Let κ2 be a conﬁguration in G2. There
exists a conﬁguration κN in GN such that the following properties hold:
• κ2 is the index projection of κN on indexes {1, 2}, and
• ∀i ∈ 3..N : pc(lstate(κN , i )) = (cid:96)crash ∧ ¬active(κN , i )
• ∀s ∈ 3..N , r ∈ 1..N : buf (κ, s, r ) = ∅
• ∀s ∈ 3..N , r ∈ 1..2 : rcvd (lstate(κN , s), r ) = ∅
• ∀s ∈ 1..N , r ∈ 3..N : buf (κ, s, r ) = ∅

Proof. Proposition 5.17 is true since our construction simply adds N − 2 crashed processes
that have not sent any messages in the global system. The last two constraints requires that
processes 1 and 2 have not received any messages from crashes processes and the message
buﬀers to crashed processes are empty. Other components are arbitrary.

Proposition 5.18. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 and
GN be global transition systems of A for some N ≥ 2. Let κ2
1 be conﬁgurations in G2
tr−→ κ2
such that κ2
1 where tr is an internal transition. There exists two conﬁgurations κN
0
0
and κN
1 in GN such that
(1) κ2
0 and κ2
and
(2) κN
0

1 are respectively the index projection of κN

1 on a set {1, 2} of indexes,

0 and κN

0 and κ2

tr−→ κN
1 .

28

T.H. TRAN, I. KONNOV, AND J. WIDDER

Proof. By Proposition 5.17, there exists a conﬁguration κN
0 is the
index projection of κN
0 on indexes {1, 2}, and (ii) all processes with indexes in 3..N are
crashed and inactive in κN
0 , and (iii) every process pi has not received any messages from
a process pj where i ∈ {1, 2}, j ∈ 3..N (as the conﬁguration construction in the proof of
Proposition 5.17).

0 in GN such that (i) κ2

We construct κN

1 as the following. Intuitively, this construction keeps process 3..N
crashed, and two processes 1 and 2 in GN make similar transitions with processes 1 and 2 in
G2.´

0 , i ) ∧ ¬active(κN

1 , i ).

1 , i ) = lstate(κN

(1) ∀i ∈ 3..N : lstate(κN
(2) ∀s ∈ 1..N , r ∈ 3..N : buf (κN
(3) ∀i ∈ {1, 2} : active(κN
(4) ∀s ∈ 3..N , r ∈ 1..N : rcvd (lstate(κN
1 , s), r ) = ∅
(5) ∀s, r ∈ {1, 2} : buf (κN
1, s, r )
(6) For every s ∈ {1, 2}, we have: If lstate(κ2

1 , s, r ) = ∅
1 , i ) = active(κ2

1 , s, r ) = buf (κ2

1, i )

then buf (κN
buf (κN
0 , s, r ).

1 , s, r ) = {m}∪buf (κN

csnd (m)
−−−−−→ lstate(κ2
0 , s, r ) for every 3 ≤ r ≤ N . Otherwise, buf (κN

1, s) for some m ∈ Msg,
1 , s, r ) =

0, s)

(7) For every i ∈ {1, 2}, the conﬁgurations of processes with index i is updated as following:

1, i ))

1 , i )) = pc(lstate(κ2

• pc(lstate(κN
• ∀j ∈ {1, 2} : rcvd (lstate(κN
• ∀j ∈ {1, 2} : lvar (lstate(κN
• ∀j ∈ 3..N : rcvd (lstate(κN
• ∀j ∈ 3..N : lvar (lstate(κN

1 , i ), j ) = rcvd (lstate(κ2
1 , i ), j ) = lvar (lstate(κ2
1 , i ), j ) = rcvd (lstate(κN
1 , i ), j ) = nextVal (cid:0)pc(lstate(κN

1, i ), j )
1, i ), j )
0 , i ), j ) = ∅

0 , i )), ∅, lvar (lstate(κN

0 , i ), j )(cid:1)

1 , it follows that κN
By the construction of κN
lstate(κN
1 , i ) and lstate(κN
no message from a process pi has been sent or received for every i ∈ 3..N .

1 is a conﬁguration in GN . Moreover, we have
0 , i ) is crashed for every i ∈ 3..N . Moreover,

0 , i ) stutter−−−−→ lstate(κN

1 , we have κN
1

construction of κN

1 is the index projection κN

• Sub-round Send. By construction of κN

By the above construction, it immediately follows that κ2

1 on
indexes {1, 2}. Hence, point 1 in Proposition 5.18 holds. We prove point 2 in Proposition 5.18
by case distinction.
• Sub-round Schedule. By similar arguments in the proof of Proposition 5.15 and the
stutter−−−−→ cN
2 .
0 and κN

1 , we know that every process pi is crashed,
and its state is not updated, and every outgoing message buﬀer from pi is always empty for
every i ∈ 3..N . Therefore, in the following, we focus on only two processes p1 and p2. For
every i ∈ 1..2, if ¬Enabled (cN
1 , i ) by the construc-
tion of conﬁgurations κN
1 . Constraint (a) holds. We now focus on enabled processes
in this sub-round. Let i be an index in 1..2 such that Enabled (cN
1 , Locsnd ). By the
csnd (m)
−−−−−→ lstate(κ1, i ).
1 , i ) as follows. By the construction of κN
0 ,
0 , i )) = pc(lstate(κ0, i )). By the construction of κN
1 , we have
1 , i )) = pc(lstate(κ1, i )). By the semantics of the transition csnd (m) in

semantics of the sub-round Send in Section 3.1, we have lstate(κ0, i )
We prove that lstate(κN
0 , i )
we have that pc(lstate(κN
that pc(lstate(κN
Section 3.1, we have pc(lstate(κ1, i )) = nextLoc(pc(lstate(κ0, i ))). It follows that

1 , Locsnd ), it follows Frozen S (κN

csnd (m)
−−−−−→ lstate(κN

0 and κN

0 , cN

0 , κN

0 , cN

pc(lstate(κN

1 , i )) = nextLoc(pc(lstate(κN

0 , i )))

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

29

By similar arguments, it follows {m} = genMsg(pc(lstate(κN
0 , i ))). Now we focus on
received messages of a process pi . By the semantics of the transtion csnd (m) in Section 3.1,
we have rcvd (lstate(κ2

0, i ), j ). For every j ∈ {1, 2}, we have

1, i ), j ) = rcvd (lstate(κ2

rcvd (lstate(κN

1 , i ), j )
= rcvd (lstate(κ1, i ), j )
= rcvd (lstate(κ0, i ), j )
= rcvd (lstate(κN

0 , i ), j )

(by the construction of κN
1 )
(by the semantics of csnd (m) in Section 3.1)
(by the construction of κN
0 )

For every j ∈ 3..N , we have

rcvd (lstate(κN

1 , i ), j ) = ∅

= rcvd (lstate(κN

0 , i ), j )

(by the construction of κN
1 )
(by the construction of κN
0 )

Hence, a process pi does not receive any message when taking a step from κN
the construction of κN

0 to κN

1 . By

1 , it follows
lvar (lstate(κN

1 , i ), j )
=nextVal (cid:0)pc(lstate(κN

0 , i )), ∅, lvar (lstate(κN

0 , i ), j )(cid:1)

csnd (m)
−−−−−→ lstate(κN

0 , i )

0 , i , j ) and m ∈ buf (κN

1, i , j ). By construction of κN

for every j ∈ 1..N . Hence, it follows lstate(κN
1 , i ). Now we focus
It is easy to see that the message m is new
on outgoing message buﬀers from pi .
in every message buﬀer buf (κ2
1 , it follows that
m /∈ buf (κN
0 , i , j ) =
{m} ∪ buf (κN
1 in the sub-round Send
in Section 3.2 hold. Moreover, by the construction of κN
1 , i ) =
active(κ1, i ). By the semantics of the sub-round Send in Section 3.2, we have ¬active(κ1, i ).
It follows ¬active(κN
1 in the sub-round Send in
Section 3.2 holds. Therefore, it follows κN
0

Snd−−→ κN
1 .
Rcv−−→ κ1. It follows by similar arguments of the sub-round Send, except that if

1 , i , j ). By similar arguments, we have buf (κN

1 , i , j ). Hence, Constraint (b) between κN

1 , i ). Constraint (c) between κN

1 , we have active(κN

0 and κN

0 and κN

0 and κN

• Case κ0

lstate(κ0, i )

rcv (S1,S2)
−−−−−−→ lstate(κ1, i ), then

lstate(κN

0 , i )

rcv (S1,S2,∅,...,∅)
−−−−−−−−−−→ lstate(κN

1 , i )

• Case κ0
Then, Proposition 5.18 holds.

Comp
−−−→ κ1. By similar arguments in the case of the sub-round Send.

Notice that in Proposition 5.18, if both pN

1 and pN

2 take a stuttering step from κN

0 to

0 = κN
1 .

1 , then κN
κN
Lemma 4.10. Let A be an arbitrary symmetric point–to–point algorithm. Let G2 and
GN be global transition systems of A for some N ≥ 2. Let π2 = κ2
1 . . . be an admissible
sequence of conﬁgurations in G2. There exists an admissible sequence πN = κN
1 . . . of
conﬁgurations in GN such that κ2
i on indexes {1, 2} for every
i ≥ 0.

i is the index projection of κN

0 κN

0κ2

Proof. We prove Lemma 4.10 by inductively constructing κN
k .

30

T.H. TRAN, I. KONNOV, AND J. WIDDER

0 = g 0

2 and κN
N .¸
0 on indexes {1, 2}. We

0 = g 0

1 by scheduling that all processes 3..N crash in κN

1 . Formally, we have:

Base case. Since π2 and πN are admissible sequences, it follows κ2

0 is the index projection of κN

By Proposition 5.14, we have that κ2
construct κN
(1) ∀i ∈ 3..N : pc(lstate(κN
(2) ∀i ∈ {1, 2} : active(κN
(3) ∀s, r ∈ 1..N : buf (κN
(4) ∀s, r ∈ 1..N : rcvd (lstate(κN
(5) ∀s, r ∈ 1..N : lvar (lstate(κN

The above constraints ensure that κN
0

1 , i ).

1 , i )) = (cid:96)crash ∧ ¬active(κN
1 , i ) = active(κ2
1 , s, r ) = buf (κN

1, i ) ∧ pc(lstate(κN
0 , s, r )
1 , s), r ) = rcvd (lstate(κN
1 , s), r ) = lvar (lstate(κN
Sched−−−→ κN
1 .

0 , s), r )
0 , s), r )

Induction step. It immediately follows by Proposition 5.18.
Hence, Lemma 4.10 holds.

1 , i )) = pc(lstate(κ2

1, i ))

Lemma 4.11. Let A be a symmetric point–to–point algorithm. Let G2 and GN be its
instances for some N ≥ 2. Let AP{1,2} be a set of predicates that take one of the forms:
P1(1), P2(2), P3(1, 2) or P4(2, 1). It follows that G2 and GN are trace equivalent under
AP{1,2}.

Proof. It immediately follows by Deﬁnition 4.9, Lemma 4.8 and Lemma 4.10.

5.4. Trace Equivalence of G1 and GN under AP{1}. Lemma 5.19 says that two global
transition systems G1 and GN whose processes follow an arbitrary symmetric point–to–
point algorithm are trace equivalent under a set AP{1} of predicates which inspect only
variables whose index is 1. The proof of Lemma 5.19 is similar to one of Lemma 5.19, but
applies Constructions 5.1 and 5.2. Constructions 5.1 and 5.2 are respectively similar to
Constructions 4.1 and 4.2, but focus on only an index 1. Constructions 5.1 and 5.2 are used
in the proof of Lemma 5.19.

Construction 5.1. Let A be an arbitrary symmetric point–to–point algorithm. Let UN be
a process template of A for some N ≥ 2, and ρN be a template state of UN . We construct a
tuple ρ1 = (pc1, rcvd1, v1) based on ρN and a set {1} of process indexes in the following way:
pc1 = pc(ρN ), rcvd1 = rcvd (ρN , 1), and v1 = lvar (ρN , 1).

Construction 5.2. Let A be a symmetric point–to–point algorithm. Let G1 and GN be
two global transitions of two instances of A for some N ≥ 1, and κN ∈ CN be a global
conﬁguration in GN . We construct a tuple κ2 = (s1, buf 1
1 , act1) based on κN and a set {1} in
the following way: s1 is constructed from lstate(κN , 1) with Construction 5.1 and an index
1, and buf 1

1 = buf (κN , 1, 1), and act1 = active(κN , 1).

Lemma 5.19. Let A be a symmetric point–to–point algorithm. Let G1 and GN be its
instances for some N ≥ 2. Let AP{1} be a set of predicates which inspect only variables
whose index is 1. It follows G1 and GN are trace equivalent under AP{1}.

Proof. By applying similar arguments in the proof of Lemma 4.11 with Constructions 5.1
and 5.2.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

31

5.5. Cutoﬀ results in the unrestricted model. In the following, we prove Proposi-
tions 5.20 and 5.21 which allows us to change positions of big conjunctions in speciﬁc
formulas. Propositions 5.20 and 5.21 are used in the proof of our cutoﬀ results, Theorems 4.1
and 4.2, respectively.

Proposition 5.20. Let A be a symmetric point–to–point algorithm. Let GN be instances of
N processes for some N ≥ 1. Let Path N be sets of all admissible sequences of conﬁgurations
in GN . Let ω{i} be a LTL\X formula in which every predicate takes one of the forms: P1(i )
or P2(i , i ) where i is an index in 1..N . Then,

(cid:16)

∀πN ∈ Path N : GN , πN |=

(cid:94)

(cid:17)

ω{i}

i ∈ 1..N

(cid:0)∀πN ∈ Path N : GN , πN |= ω{i}

(cid:16) (cid:94)

⇔

i ∈ 1..N

(cid:1)(cid:17)

(5.1)

(5.2)

Proof. (⇒) Let πN be an arbitrary admissible sequence of conﬁgurations in Path N such
that GN , πN |= (cid:86)
i ∈ 1..N ω{i}. Let i0 be an arbitrary index in 1..N , we have GN , πN |= ω{i0}.
Hence, for every πN ∈ Path N , for every i0 ∈ 1..N , it follows GN , πN |= ω{i0}. Therefore,
Formula 5.1 implies: for every i0 ∈ 1..N , for every πN ∈ Path N , it follows GN , πN |= ω{i0}.
It follows that: for every i0 ∈ 1..N , ∀πN ∈ Path N : GN , πN |= ω{i0}. Now, we have that
Formula 5.1 implies Formula 5.2.

(⇐) By applying similar arguments.

Proposition 5.21. Let A be a symmetric point–to–point algorithm. Let GN be instances of
N processes respectively for some N ≥ 1. Let Path N be sets of all admissible sequences of
conﬁgurations in GN . Let ω{i} be a LTL\X formula in which every predicate takes one of
the forms: P1(i ) or P2(i , i ) where i is an index in 1..N . Then,

(cid:0)∀πN ∈ Path N : GN , πN |=

i(cid:54)=j
(cid:94)

(cid:1)

ψ{i,j }

i,j ∈ 1..N

(cid:16)

⇔

i(cid:54)=j
(cid:94)

i,j ∈ 1..N

(cid:0)∀πN ∈ Path N : GN , πN |= ψ{i,j }

(cid:1)(cid:17)

(5.3)

(5.4)

Proof. (⇒) Let πN be an arbitrary admissible sequence of conﬁgurations in Path N such that
GN , πN |= (cid:86)i(cid:54)=j
i,j ∈ 1..N ψ{i,j }. Let i0 and j0 be arbitrary indexes in 1..N such that i0 (cid:54)= j0, we
have that GN , πN |= ψ{i0,j0}. Hence, for every πN ∈ Path N , for every i0 ∈ 1..N , for every
j0 ∈ 1..N such that i0 (cid:54)= j0, it follows that GN , πN |= ψ{i0,j0}. Therefore, Formula 5.3 implies:
for every i0 ∈ 1..N , for every j0 ∈ 1..N such that i0 (cid:54)= j0, for every πN ∈ Path N , it follows
GN , πN |= ψ{i0,j0}. It follows that: for every i0 ∈ 1..N , for every j0 ∈ 1..N such that i0 (cid:54)= j0,
it holds ∀πN ∈ Path N : GN , πN |= ψ{i0,j0}. Therefore, Formula 5.3 implies Formula 5.4.

(⇐) By applying similar arguments.

Theorem 4.1. Let A be a symmetric point–to–point algorithm under the unrestricted
model. Let G1 and GN be instances of 1 and N processes respectively for some N ≥ 1. Let
Path 1 and Path N be sets of all admissible sequences of conﬁgurations in G1 and in GN ,
respectively. Let ω{i} be a LTL\X formula in which every predicate takes one of the forms:

32

T.H. TRAN, I. KONNOV, AND J. WIDDER

P1(i ) or P2(i , i ) where i is an index in 1..N . Then, it follows that:

(cid:16)

∀πN ∈ Path N : GN , πN |=

(cid:94)

(cid:17)

ω{i}

⇔

(cid:16)

i ∈ 1..N

∀π1 ∈ Path 1 : G1, π1 |= ω{1}

(cid:17)

Proof. By Proposition 5.20, we have

(cid:16)

∀πN ∈ Path N : GN , πN |=

(cid:94)

(cid:17)

⇔

ω{i}

(cid:16) (cid:94)

(cid:0)∀πN ∈ Path N : GN , πN |= ω{i}

(cid:1)(cid:17)

i ∈ 1..N

i ∈ 1..N

Let i be an index in a set 1..N . Hence, α = (i ↔ 1) is a transposition on 1..N (*). By
Lemma 4.7, we have: (i) ψ{α(i) = ψ{1}, and (ii) α(GN )) = GN , and (iii) α(g 0

N ) = g 0
N .

Since ω{i} is an LTL\X formula, A ω{i} is a LTL\X formula where A is a path op-
erator in LTL\X (see [CJGK+18]). By the semantics of the operator A, it follows that
∀πN ∈ Path N : GN , πN |= ω{i} if and only if GN , g 0
N |= A ω{1}. By point (*), it follows
GN , g 0
N |= A ω{1}. Since an index i is arbitrary, we have
GN , g 0

N |= A ω{i} if and only if GN , g 0
N |= (cid:86)
We have that GN , g 0
semantics of the operator A.
∀π2 ∈ Path 2 : G2, π2 |= ω{1} by Lemma 5.19. Then, Theorem 4.1 holds.

N |= A ω{i} if and only if ∀πN ∈ Path N : GN , πN |= ω{i} by the
It follows ∀πN ∈ Path N : GN , πN |= ω{i} if and only if

i ∈ 1..N A ω{i} if and only if GN , g 0

N |= A ω{i}.

Theorem 4.2. Let A be a symmetric point–to–point algorithm under the unrestricted
model. Let G2 and GN be instances of 2 and N processes respectively for some N ≥ 2. Let
Path 2 and Path N be sets of all admissible sequences of conﬁgurations in G2 and in GN ,
respectively. Let ψ{i,j } be an LTL\X formula in which every predicate takes one of the forms:
P1(i ), or P2(j ), or P3(i , j ), or P4(j , i ) where i and j are diﬀerent indexes in 1..N . It follows
that:

(cid:0)∀πN ∈ Path N : GN , πN |=

i(cid:54)=j
(cid:94)

i,j ∈ 1..N

ψ{i,j }

(cid:1) ⇔ (cid:0)∀π2 ∈ Path 2 : G2, π2 |= ψ{1,2}

(cid:1)

Proof. By similar arguments in the proof of Theorem 4.1.

5.6. Veriﬁcation of the Failure Detector of [CT96] with the Cutoﬀs. In the following,
we present Lemmas 5.23 which explains why the cutoﬀ result 4.2 allows us to verify the
strong completeness property of the failure detector of [CT96] under synchrony by model
checking instances of size 2.

Proposition 5.22. Let GN = (CN , TrN , RN , g 0
N ) be a global transition system of a symmetric
point-to-point algorithm under the unrestricted model. Its indexes are 1..N for some N ≥ 1.
Let i and j be two indexes in the set 1..N . Let µ{i,j } be a ﬁrst-order formula in which every
predicate takes one of the forms: Q1(i ), or Q2(j ), or Q3(i , j ), or Q4(j , i ). The following
conditions hold:
(1) F G (cid:86)
(2) (cid:86)
(3) Let π = κ0κ1 . . . be an admissibe sequence of conﬁgurations in GN . It follows GN , π |=

i,j ∈ 1..N µ{i,j } be an LTL\X formula.
i,j ∈ 1..N F G µ{i,j } be an LTL\X formula.

F G (cid:86)

i,j ∈ 1..N µ{i,j } if and only if GN , π |= (cid:86)

i,j ∈ 1..N F G µ{i,j }.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

33

Proof. Points (1) and (2) hold by the deﬁnition of LTL\X (see [CJGK+18]). We prove Point
(3) as follows.

(⇒) Since GN , π |= F G (cid:86)

i,j ∈ 1..N µ{i,j }, there exists (cid:96)0 ≥ 0 such that for every (cid:96) ≥ (cid:96)0,
we have κ(cid:96) |= (cid:86)
i,j ∈ 1..N µ{i,j }. Let i0 and j0 be two indexes in 1..N . We have κ(cid:96) |= µ{i0,j0}
for every (cid:96) ≥ (cid:96)0. Hence, it follows GN , π |= F G µ{i0,j0}. Because i0 and j0 are arbitrary
indexes in 1..N , it follows that GN , π |= (cid:86)

i,j ∈ 1..N F G µ{i,j }.
(⇐) Let i0 and j0 be two indexes in 1..N . Since GN , π |= (cid:86)

i,j ∈ 1..N F G µ{i,j }, it follows
that GN , π |= F G µ{i0,j0}. Therefore, there exists (cid:96)i
j ≥ 0 such that κ(cid:96) |= µ{i0,j0} for every
(cid:96) ≥ (cid:96)i0
j : i ∈ 1..N ∧ j ∈ 1..N }) where max is a function to pick a maximum
j0
number in a ﬁnite set of natural numbers. It follows that κ(cid:96) |= µ{i,j } for every (cid:96) ≥ (cid:96)0, for
every i , j ∈ 1..N . Therefore, GN , π |= F G (cid:86)

. Let (cid:96) = max ({(cid:96)i

i,j ∈ 1..N µ{i,j }.

Lemma 5.23. Let G2 and GN be two global transition systems of a symmetric point-to-point
algorithm such that:
(1) These systems G2 and GN have 2 and N processes respectively where N ≥ 2.
(2) All processes G2 and GN follow Algorithm 1.
(3) The model of computation of these systems is under the unrestricted model.
Let Π be a set of indexes, and µ(Π) denote the strong completeness property in which the set
of process indexes is Π, i.e.

µ(Π) (cid:44) F G(∀p, q ∈ Π : (Correct(p) ∧ ¬Correct(q)) ⇒ Suspected (p, q))

Let Path 2 and Path N be sets of all admissible sequences of conﬁgurations in G2 and in GN ,
respectively. Then, it holds:

∀πN ∈ Path N : GN , πN |= µ(1..N )

⇔∀π2 ∈ Path 2 : G2, π2 |= µ(1..2)

Proof. To keep the presentation simple, let ν(p, q) be a predicate such that ν(p, q) (cid:44)
(Correct(p) ∧ ¬Correct(q)). Let πN be an admissible sequence of conﬁgurations in GN . We
have GN , πN |= µ(Π) if and only if GN , πN |= F G(∀p, q ∈ 1..N : ν(p, q) ⇒ Suspected (p, q)).
It follows

GN , πN |= µ(1..N )

⇔ GN , πN |= F G(

(cid:94)

p,q ∈ 1..N

ν(p, q) ⇒ Suspected (p, q))

⇔ GN , πN |=

(cid:94)

p,q ∈ 1..N

F G(ν(p, q) ⇒ Suspected (p, q))

(by Proposition 5.22)

The last formula is equivalent to

GN , πN |=

∧ GN , πN |=

p(cid:54)=q
(cid:94)

p,q ∈ 1..N
p=q
(cid:94)

p,q ∈ 1..N

F G(ν(p, q) ⇒ Suspected (p, q))

F G(ν(p, q) ⇒ Suspected (p, q))

34

T.H. TRAN, I. KONNOV, AND J. WIDDER

For every p, q ∈ 1..N , if p = q, then (Correct(p) ∧ ¬Correct(q)) = ⊥ (*). Hence, it follows
that

GN , πN |=

⇔ GN , πN |=

(cid:94)

p,q ∈ 1..N
p(cid:54)=q
(cid:94)

p,q ∈ 1..N

F G(ν(p, q) ⇒ Suspected (p, q))

F G(ν(p, q) ⇒ Suspected (p, q))

It follows that ∀πN ∈ Path N : GN , πN |= µ if and only if

∀πN ∈ Path N : GN , πN |=

p(cid:54)=q
(cid:94)

p,q ∈ 1..N

F G(ν(p, q) ⇒ Suspected (p, q))

By Theorem 4.2, it follows

∀πN ∈ Path N : GN , πN |= µ(1..N )

⇔ ∀π2 ∈ Path 2 : G2, π2 |=

p(cid:54)=q
(cid:94)

p,q ∈ 1..2

By point (*), we have

F G(ν(p, q) ⇒ Suspected (p, q))

∀πN ∈ Path N : GN , πN |= µ(1..N )

⇔ ∀π2 ∈ Path 2 : G2, π2 |=

(cid:94)

p,q ∈ 1..2

F G(ν(p, q) ⇒ Suspected (p, q))

By Proposition 5.22, it follows

∀πN ∈ Path N : GN , πN |= µ(1..N )

⇔ ∀π2 ∈ Path 2 : G2, π2 |= F G(

(cid:94)

(ν(p, q) ⇒ Suspected (p, q)))

⇔ ∀π2 ∈ Path 2 : G2, π2 |= µ(1..2)

p,q ∈ 1..2

Hence, Lemma 5.23 holds.

Lemma 5.24. Let G1 and G2 and GN be three global transition systems of a symmetric
point-to-point algorithm such that:
(1) These systems G1 and G2 and GN have 1, 2 and N processes respectively.
(2) All processes in G1 and G2 and GN follow Algorithm 1.
(3) Three sets Path 1 and Path 2 and Path N be sets of admissible sequences of conﬁgurations

in G1 and G2 and GN , respectively.

(4) The model of computation of these systems is under the unrestricted model.
Let Π be a set of process indexes, and µ(Π) denote the eventually strong accuracy property
in which the set of process indexes is Π, i.e.,

µ(Π) (cid:44) F G(∀p, q ∈ Π : (Correct(p) ∧ Correct(q)) ⇒ ¬Suspected (p, q))

It follows ∀πN ∈ Path N : GN , πN |= µ(1..N ) if and only if both ∀π2 ∈ Path 2 : G2, π2 |= µ(1..2)
and ∀π1 ∈ Path 1 : G1, π1 |= µ(1..1).

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

35

Proof. To keep the presentation simple, we deﬁne

ν(p, q) = (Correct(p) ∧ Correct(q)) ⇒ ¬Suspected (p, q)

By similar arguments in Proposition 5.23, we have ∀πN ∈ Path N : GN , πN |= µ(1..N ) is
equivalent to the following conjunction

(cid:16)

(cid:16)

∧

∀πN ∈ Path N : GN , πN |=

p=q
(cid:94)

F G ν(p, q)

(cid:17)

∀πN ∈ Path N : GN , πN |=

p,q ∈ 1..N
p(cid:54)=q
(cid:94)

p,q ∈ 1..N

F G ν(p, q)

(cid:17)

By Theorems 4.1 and 4.2, the above conjunction is equivalent to

(cid:16)

(cid:16)

∧

∀π1 ∈ Path 1 : G1, π1 |=

p=q
(cid:94)

F G ν(1, 1)

(cid:17)

∀π2 ∈ Path 2 : G2, π2 |=

p,q ∈ 1..N
p(cid:54)=q
(cid:94)

p,q ∈ 1..N

F G ν(1, 2)

(cid:17)

By Proposition 5.22, the above conjunction is equivalent to

(cid:16)

(cid:16)

∧

∀π1 ∈ Path 1 : G1, π1 |= F G

∀π2 ∈ Path 2 : G2, π2 |= F G

p=q
(cid:94)

(cid:17)

ν(1, 1)

p,q ∈ 1..N
p(cid:54)=q
(cid:94)

p,q ∈ 1..N

(cid:17)

ν(1, 2)

Therefore, Lemma 5.24 holds.

6. Cutoff Results in the Case of Unknown Time Bounds

In this section, we extend the above cutoﬀ results on a number of processes (see Theorems 4.1
and 4.2) for partial synchrony in case of unknown bounds ∆ and Φ. The extended results
are formalized in Theorems 6.1 and 6.2. It is straightforward to adapt our approach to other
models of partial synchrony in [DLS88, CT96].

Theorem 6.1. Let A be a symmetric point–to–point algorithm under partial synchrony
with unknown bounds ∆ and Φ. Let G1 and GN be instances of A with 1 and N processes
respectively for some N ≥ 1. Let Path 1 and Path N be sets of all admissible sequences of
conﬁgurations in G1 and in GN under partial synchrony, respectively. Let ω{i} be a LTL\X
formula in which every predicate takes one of the forms: P1(i ) or P2(i , i ) where i is an
index in 1..N . It follows that:

(cid:16)

∀πN ∈ Path N : GN , πN |=

(cid:94)

(cid:17)

ω{i}

⇔

(cid:16)

i ∈ 1..N

∀π1 ∈ Path 1 : G1, π1 |= ω{1}

(cid:17)

36

T.H. TRAN, I. KONNOV, AND J. WIDDER

Theorem 6.2. Let A be a symmetric point–to–point algorithm under partial synchrony
with unknown bounds ∆ and Φ. Let G2 and GN be instances of A with 2 and N processes
respectively for some N ≥ 2. Let Path 2 and Path N be sets of all admissible sequences of
conﬁgurations in G2 and in GN under partial synchrony, respectively. Let ψ{i,j } be an LTL\X
formula in which every predicate takes one of the forms: Q1(i ), or Q2(j ), or Q3(i , j ), or
Q4(j , i ) where i and j are diﬀerent indexes in 1..N . It follows that:

(cid:0)∀πN ∈ Path N : GN , πN |=

i(cid:54)=j
(cid:94)

i,j ∈ 1..N

ψ{i,j }

(cid:1) ⇔ (cid:0)∀π2 ∈ Path 2 : G2, π2 |= ψ{1,2}

(cid:1)

Since the proofs of these theorems are similar, we here focus on only Theorem 6.2. The
proof of Theorem 6.2 follows the approach in [EN95, TKW20], and is based on the following
observations. Remind that Steps 1 and 2 are already proved in Section 4.

(1) The global transition system and the desired property are symmetric.
(2) Let G2 and GN be two instances of a symmetric point-to-point algorithm with 2 and
N processes, respectively. We have that two instances G2 and GN are trace equivalent
under a set of predicates in the desired property.

(3) We will now discuss that the constraints maintain partial synchrony. Let πN be an
execution in GN . By applying the index projection to πN , we obtain an execution π2 in
G2. If partial synchrony constraints (PS1) and (PS2) – deﬁned in Section 3.3 – hold on
πN , these constraints also hold on π2. This result is proved in Lemma 6.3.

(4) Let π2 be an execution in G2. We construct an execution πN in GN based on π2 such
that all processes 3..N crash from the beginning, and π2 is an index projection of πN
(deﬁned in Section 4.2). For instance, see Figure 2. If partial synchrony constraints (PS1)
and (PS2) – deﬁned in Section 3.3 – hold on π2, these constraints also hold on πN . This
result is proved in Lemma 6.4.

Lemma 6.3. Let A be a symmetric point–to–point algorithm under partial synchrony with
unknown bounds ∆ and Φ. Let G2 and GN be instances of A with 2 and N processes,
respectively, for some N ≥ 2. Let Path 2 and Path N be sets of all admissible sequences of
conﬁgurations in G2 and in GN under partial synchrony, respectively. Let πN = κN
1 . . .
be an admissible sequences of conﬁgurations in GN . Let π2 = κ2
1 . . . be a sequence of
conﬁgurations in G2 such that κ2
k on indexes {1, 2} for every
k ≥ 0. It follows that
(a) Constraint (PS1) on message delay holds on π2.
(b) Constraint (PS2) on the relative speed of processes holds on π2.

k be an index projection of κN

0 κN

0κ2

Proof. Recall that the index projection is deﬁned in Section 4.2. In the following, we denote
p2 and pN two processes such that they have the same index, and p2 is a process in G2, and
pN is a process in GN . We prove Lemma 6.3 by contradiction.

(a) Assume that Constraint (PS1) does not hold on π2. Hence, there exist a time (cid:96) > 0,
and two processes s 2, r 2 ∈ 1..2 in G2 such that after r 2 executes Receive at a time (cid:96), there
exists an old message in a message buﬀer from process s 2 to process r 2. By the deﬁnition of
the index projection, for every k ≥ 0, we have that:
• Let pN , q N ∈ {1, 2} be two processes in GN , and p2, q 2 be corresponding processes in G2.
k , and from process

For every k ≥ 0, two message buﬀers from process p2 to process q 2 in κ2
pN to process q N in κN

k are the same.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

37

• Let pN ∈ {1, 2} be a process in GN , and p2 be a corresponding process in G2. For every
k if and only if process pN takes

k ≥ 0, process p2 takes an action act in conﬁguration κ2
the same action in conﬁguration κN
k .

It implies that process r N in GN also executes Receive at a time (cid:96), and there exists an old
message in a buﬀer from process s N to process r N . Contradiction.

(b) By applying similar arguments in case (a).

Lemma 6.4. Let A be a symmetric point–to–point algorithm under partial synchrony with
unknown bounds ∆ and Φ. Let G2 and GN be instances of A with 2 and N processes,
respectively, for some N ≥ 2. Let Path 2 and Path N be sets of all admissible sequences of
conﬁgurations in G2 and in GN under partial synchrony, respectively. Let π2 = κ2
1 . . .
be an admissible sequences of conﬁgurations in G2. Let πN = κN
1 . . . be a sequence of
conﬁgurations in GN such that (i) every process p ∈ 3..N crashes from the beginning, and
(ii) κ2
(a) Constraint (PS1) on message delay holds on πN .
(b) Constraint (PS2) on the relative speed of processes holds on πN .

k on indexes {1, 2} for every k ≥ 0. It follows that

k be an index projection of κN

0 κN

0κ2

Proof. By applying similar arguments in the proof of Lemma 6.3, and the facts that every
process p ∈ 3..N crashes from the beginning, and that κ2
k on
indexes {1, 2} for every k ≥ 0.

k be an index projection of κN

7. Encoding the Chandra and Toueg Failure Detector

In this section, we ﬁrst discuss why it is suﬃcient to verify the failure detector by checking a
system with only one sender and one receiver by applying the cutoﬀs presented in Section 6.
Next, we introduce two approaches to encoding the message buﬀer, and an abstraction of
in-transit messages that are older than ∆ time-units. Finally, we present how to encode the
relative speed of processes with counters over natural numbers. These techniques allow us
to tune our models to the strength of the veriﬁcation tools: FAST, IVy, and model checkers
for TLA+.

7.1. The System with One Sender and One Receiver. The cutoﬀ results in Section 6
allow us to verify the Chandra and Toueg failure detector under partial synchrony by
checking only instances with two processes. In the following, we discuss the model with two
processes, and formalize the properties with two-process indexes. By process symmetry, it is
suﬃcient to verify Strong Accuracy, Eventually Strong Accuracy, and Strong Completeness
by checking the following properties.

G((Correct(1) ∧ Correct(2)) ⇒ ¬Suspected (2, 1))

F G((Correct(1) ∧ Correct(2)) ⇒ ¬Suspected (2, 1))

F G((¬Correct(1) ∧ Correct(2)) ⇒ Suspected (2, 1))

(7.1)

(7.2)

(7.3)

We can take a further step towards facilitating veriﬁcation of the failure detector. First,
every process typically has a local variable to store messages that it needs to send to itself,
instead of using a real communication channel. Hence, we can assume that there is no
delay for those messages, and that each correct process never suspects itself. Second, local
variables in Algorithm 1 are arrays whose elements correspond one-to-one with a remote

38

T.H. TRAN, I. KONNOV, AND J. WIDDER

process, e.g., timeout[2, 1] and suspected [2, 1]. Third, communication between processes is
point-to-point. When this is not the case, one can use cryptography to establish one-to-one
communication. Hence, reasoning about Properties 7.1–7.3 requires no information about
messages from process 1 to itself, local variables of process 1, and messages from process 2.
Due to the above characteristics, it is suﬃcient to consider process 1 as a sender, and
process 2 as a receiver. In detail, the sender follows Task 1 in Algorithm 1, but does nothing
in Task 2 and Task 3. The sender does not need the initialization step, and local variables
suspected and timeout. In contrast, the receiver has local variables corresponding to the
sender, and follows only the initialization step, and Task 2, and Task 3 in Algorithm 1. The
receiver can increase its waiting time in Task 1, but does not send any message.

7.2. Encoding the Message Buﬀer. Algorithm 1 assumes unbounded message buﬀers
between processes that produce an inﬁnite state space. Moreover, a sent message might be
in-transit for a long time before it is delivered. We ﬁrst introduce two approaches to encode
the message buﬀer based on a logical predicate, and a counter over natural numbers. The
ﬁrst approach works for TLA+ and IVy, but not for counter automata (FAST). The latter
is supported by all mentioned tools, but it is less eﬃcient as it requires more transitions.
Then, we present an abstraction of in-transit messages that are older than ∆ time-units.
This technique reduces the state space, and allows us to tune our models to the strength of
the veriﬁcation tools.

7.2.1. Encoding the message buﬀer with a predicate. In Algorithm 1, only “alive” messages
are sent, and the message delivery depends only on the age of in-transit messages. Moreover,
the computation of the receiver does not depend on the contents of its received messages.
Hence, we can encode a message buﬀer by using a logical predicate existsMsgOfAge(x ). For
every k ≥ 0, predicate existsMsgOfAge(k ) refers to whether there exists an in-transit message
that is k time-units old. The number 0 refers to the age of a fresh message in the buﬀer.

It is convenient to encode the message buﬀer's behaviors in this approach. For instance,
Formulas 7.4 and 7.5 show constraints on the message buﬀer when a new message is sent:

existsMsgOfAge(cid:48)(0)
∀x ∈ N . x > 0 ⇒ existsMsgOfAge(cid:48)(x ) = existsMsgOfAge(x )

(7.4)

(7.5)

where existsMsgOfAge(cid:48) refers to the value of existsMsgOfAge in the next state. Formula 7.4
implies that a fresh message has been added to the message buﬀer. Formula 7.5 ensures
that other in-transit messages are unchanged.

Another example is the relation between existsMsgOfAge and existsMsgOfAge(cid:48) after the
message delivery. This relation is formalized with Formulas 7.6–7.9. Formula 7.6 requires
that there exists an in-transit message in existsMsgOfAge that can be delivered. Formula 7.7
ensures that no old messages are in transit after the delivery. Formula 7.8 guarantees that no
message is created out of thin air. Formula 7.9 implies that at least one message is delivered.

∃x ∈ N . existsMsgOfAge(x )
∀x ∈ N . x ≥ ∆ ⇒ ¬existsMsgOfAge(cid:48)(x )
∀x ∈ N . existsMsgOfAge(cid:48)(x ) ⇒ existsMsgOfAge(x )
∃x ∈ N . existsMsgOfAge(cid:48)(x ) (cid:54)= existsMsgOfAge(x )

(7.6)

(7.7)

(7.8)

(7.9)

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

39

Age indexes
Messages in buf

0 1 2 3 4 . . .

Age indexes
Messages in buf(cid:48)

0 1 2 3 4 . . .

Figure 3. The message buﬀer after increasing message ages in case of
buf = 6

This encoding works for TLA+ and IVy, but not for FAST, because the input language

of FAST does not support functions.

7.2.2. Encoding the message buﬀer with a counter. In the following, we present an encoding
technique for the buﬀer that can be applied in all tools TLA+, IVy, and FAST. This
approach encodes the message buﬀer with a counter buf over natural numbers. The k th bit
refers to whether there exists an in-transit message with k time-units old.

In this approach, message behaviors are formalized with operations in Presburger
arithmetic. For example, assume ∆ > 0, we write buf(cid:48) = buf + 1 to add a fresh message in
the buﬀer. Notice that the increase of buf by 1 turns on the 0th bit, and keeps the other
bits unchanged.

To encode the increase of the age of every in-transit message by 1, we simply write
buf(cid:48) = buf × 2. Assume that we use the least signiﬁcant bit (LSB) ﬁrst encoding, and the
left-most bit is the 0th bit. By multiplying buf by 2, we have updated buf(cid:48) by shifting to
the right every bit in buf by 1. For example, Figure 3 demonstrates the message buﬀer after
the increase of message ages in case of buf = 6. We have buf(cid:48) = buf × 2 = 12. It is easy to
see that the 1st and 2nd bits in buf are on, and the 2nd and 3rd bits in buf(cid:48) are on.

Recall that Presburger arithmetic does not allow one to divide by a variable. Therefore,
to guarantee the constraint in Formula 7.8, we need to enumerate all constraints on possible
values of buf and buf(cid:48) after the message delivery. For example, assume buf = 3, and ∆ = 1.
After the message delivery, buf(cid:48) is either 0 or 1. If buf = 2 and ∆ = 1, buf(cid:48) must be 0
after the message delivery. Importantly, the number of transitions for the message delivery
depends on the value of ∆.

To avoid the enumeration of all possible cases, Formula 7.8 can be rewritten with
bit-vector arithmetic. However, bit-vector arithmetic are currently not supported in all
veriﬁcation tools TLA+, FAST, and IVy.

The advantage of this encoding is that when bound ∆ is ﬁxed, every constraint in the
system behaviors can be rewritten in Presburger arithmetic. Thus, we can use FAST, which
accepts constraints in Presburger arithmetic. To specify cases with arbitrary ∆, the user
can use TLA+ or IVy.

7.2.3. Abstraction of old messages. Algorithm 1 assumes underlying unbounded message
buﬀers between processes. Moreover, a sent message might be in transit for a long time
before it is delivered. To reduce the state space, we develop an abstraction of in-transit
messages that are older than ∆ time-units; we call such messages “old”. This abstraction
makes the message buﬀer between the sender and the receiver bounded. In detail, the
message buﬀer has a size of ∆. Importantly, we can apply this abstraction to two above
encoding techniques for the message buﬀer.

In partial synchrony, if process p executes Receive at some time point from the Global
Stabilization Time, every old message sent to p will be delivered immediately. Moreover,

40

T.H. TRAN, I. KONNOV, AND J. WIDDER

Age indexes
Messages in buf

(a)

0 1 2

Age indexes
Messages in buf(cid:48)

0 1 2

Age indexes
Messages in buf

(b)

0 1 2

Age indexes
Messages in buf(cid:48)

0 1 2

Figure 4. The increase of message ages with the abstraction of old messages.
In the case (a), we have ∆ = 2, buf = 6, and buf(cid:48) = 4. In the case (b), we
have ∆ = 2, buf = 5, and buf(cid:48) = 6.

1: if buf < 2∆ then buf(cid:48) ← buf × 2
2: else
3:
4:

if buf ≥ 2∆ + 2∆−1 then buf(cid:48) ← buf × 2 − 2∆+1
else buf(cid:48) ← buf × 2 − 2∆+1 + 2∆

Figure 5. Encoding the increase of message ages with
a counter buf, and the abstraction of old messages.

the computation of a process in Algorithm 1 does not depend on the content of received
messages. Hence, instead of tracking all old messages, our abstraction keeps only one old
message that is ∆ time-units old, does not increase its age, and throws away other old
messages.

In the following, we discuss how to integrate this abstraction into the encoding techniques
of the message buﬀer. We demonstrate our ideas by showing the pseudo code of the increase
of message ages. It is straightforward to adopt this abstraction to the message delivery, and
to the sending of a new message.

Figure 4(a) presents the increase of message ages with this abstraction in a case of
∆ = 2, and buf = 6. Unlike Figure 3, there exists no in-transit message that is 3 time-units
old in Figure 4(a). Moreover, the message buﬀer in Figure 4(a) has a size of 3. In addition,
buf(cid:48) has only one in-transit message that is 2 time-units old. We have buf(cid:48) = 4 in this case.
Figure 4(b) demonstrates another case of ∆ = 2, buf = 5, and buf(cid:48) = 6.

Formally, Figure 5 presents the pseudo code of the increase of message ages that is
encoded with a counter buf, and the abstraction of old messages. There are three cases. In
the ﬁrst case (Line 1), there exist no old messages in buf, and we simply set buf(cid:48) = buf × 2.
In other cases (Lines 3 and 4), buf contains an old message. Figure 4(a) demonstrates the
second case (Line 3). We subtract 2∆+1 to remove an old message with ∆ + 1 time-units old
from the buﬀer. Figure 4(b) demonstrates the third case (Line 4). In the third case, we also
need to remove an old message with ∆ + 1 time-units old from the buﬀer. Moreover, we
need to put an old message with ∆ time-units old to the buﬀer by adding 2∆.

Now we discuss how to integrate the abstraction of old messages in the encoding of
the message buﬀer with a predicate. Formulas 7.10–7.13 present the relation between
existsMsgOfAge and existsMsgOfAge(cid:48) when message ages are increased by 1, and this abstrac-
tion is applied. Formula 7.10 ensures that no fresh message will be added to existsMsgOfAge(cid:48).
Formula 7.11 ensures that the age of every message that is until (∆ − 2) time-units old will
be increased by 1. Formulas 7.12–7.13 are introduced by this abstraction. Formula 7.12

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

41

implies that if there exists an old message or a message with (∆ − 1) time-units old in
existsMsgOfAge, there will be an old message that is ∆ time-units old in existsMsgOfAge(cid:48).
Formula 7.13 ensures that there exists no message that is older than ∆ time-units old.

¬existsMsgOfAge(cid:48)(0)
∀x ∈ N . (0 ≤ x ≤ ∆ − 2)

⇒ existsMsgOfAge(cid:48)(x + 1) = existsMsgOfAge(x )

existsMsgOfAge(cid:48)(∆) = existsMsgOfAge(∆) ∨ existsMsgOfAge(∆ − 1)
∀x ∈ N . x > ∆ ⇒ existsMsgOfAge(cid:48)(x ) = ⊥

(7.10)

(7.11)

(7.12)

(7.13)

7.3. Encoding the Relative Speed of Processes. Recall that we focus on the case of
unknown bounds ∆ and Φ. In this case, every correct process must take at least one step in
every contiguous time interval containing Φ time-units [DLS88].

To maintain this constraint on executions generated by the veriﬁcation tools, we intro-
duced two additional control variables sTimer and rTimer for the sender and the receiver,
respectively. These variables work as timers to keep track of how long a process has not
taken a step, and when a process can take a step. Since these timers play similar roles,
we here focus on rTimer. In our encoding, only the global system can update rTimer. To
schedule the receiver, the global systems non-deterministically executes one of two actions
in the sub-round Schedule: (i) resets rTimer to 0, and (ii) if rTimer < Φ, increases rTimer
by 1. In other sub-rounds, the value of rTimer is unchanged. Moreover, the receiver must
take a step whenever rTimer = 0.

8. Reduce Liveness Properties to Safety Properties

To verify the liveness properties Eventually Strong Accuracy and Strong Completeness with
IVy, we ﬁrst need to reduce them to safety properties. Intuitively, these liveness properties
are bounded; therefore, they become safety ones. In the following, we explain how to do
that.

8.1. Eventually Strong Accuracy. By cutoﬀs discussed in Section 6, it is suﬃcient to
verify Eventually Strong Accuracy on the Chandra and Toueg failure detector by checking
the following property on instances with 2 processes.

F G((Correct(1) ∧ Correct(2)) ⇒ ¬Suspected (2, 1))

(8.1)

where process 1 is the sender and process 2 is the receiver.

In the following, we present how to reduce Formula 8.1 to a safety property. Our

reduction is based on the following observations:

(1) Fairness (Line 5 in Algorithm 1): correct processes send “alive” inﬁnitely often.
(2) The reliable communication (Constraint (TC1)): Let rcv msg from(2, 1) be a predicate
that refers to whether process 2 receives a message from process 1. If processes p and q
are always correct, then it holds G F rcv msg from(2, 1).

42

T.H. TRAN, I. KONNOV, AND J. WIDDER

(3) Transition invariant: Let ψ1(2, 1) be a predicate such that

ψ1(2, 1) (cid:44) rcv msg from(2, 1) ∧ Correct(1) ∧ Correct(2) ∧ Suspected (2, 1)

Then, the following property is a transition invariant.

G(ψ1(p, q) ⇒ timeout (cid:48)[2, 1] = timeout[2, 1] + 1)

(8.2)

Points 1–3 implies that if timeout[2, 1] is always less than some constant in an arbitrary

execution path, then Formula 8.1 holds in this path.

Now we discuss why timeout[2, 1] does not keep increasing forever if processes 1 and 2 are
correct. To that end, we ﬁnd a speciﬁc guard g for timeout[2, 1] such that if timeout[2, 1] ≥ g 5
and the sender is correct, then the receiver waits for the sender in less than g time-units.
Moreover, the value of g depends only on the values of ∆ and Φ. Hence, it is suﬃcient to
verify Formula 8.1 by checking Formula 8.3.

G (cid:0)timeout[2, 1] ≥ g ⇒ ((Correct(1) ∧ Correct(2)) ⇒ ¬Suspected (2, 1))(cid:1)

(8.3)

8.2. Strong Completeness. By cutoﬀs discussed in Section 6, it is suﬃcient to verify
Strong Completeness on the Chandra and Toueg failure detector by checking the following
property on instances with 2 processes.

F G((¬Correct(1) ∧ Correct(2)) ⇒ Suspected (2, 1))

(8.4)

Notice that in partial synchrony, every sent message is eventually delivered. Hence,
after the sender crashes, the receiver eventually receives nothing from the sender. To reduce
Formula 8.4 to a safety property, we ﬁrst introduced a ghost variable hLFSC to measure for
how long the sender has crashed. hLFSC is set to 0 when the sender crashes. After that, hLFSC
is increased by 1 in every global step if the receiver has not suspected the crashed sender.
Let ψ2(2, 1) denote the constraint: ψ2(2, 1) (cid:44) ¬Correct(1) ∧ Correct(2) ∧ ¬Suspected (2, 1).
Then, the following property is a transition invariant.

G(ψ2(p, q) ⇒ hLFSC(cid:48) = hLFSC + 1)

(8.5)

By Formula 8.5, if hLFSC is always less than some constant in an arbitrary execution

path, then Formula 8.4 holds in this path.

Now we show that hLFSC cannot keep increasing forever. To that end, we ﬁnd a speciﬁc
guard g (cid:48) > 0 for hLFSC such that if hLFSC = g (cid:48), then the receiver suspects the sender. It
implies that hLFSC is unchanged. Moreover, the value of g (cid:48) depends only on the values of ∆
and Φ. Hence, it is suﬃcient to verify Formula 8.4 by checking Formula 8.6.

G (cid:0)hLFSC = g (cid:48) ⇒ ((¬Correct(1) ∧ Correct(2)) ⇒ Suspected (2, 1))(cid:1)

(8.6)

´

9. Experiments for Small ∆ and Φ
In this section, we describe our experiments with TLA+ and FAST. We ran the following ex-
periments on a virtual machine with Core i7-6600U CPU and 8GB DDR4. Our speciﬁcations
can be found at [TKW].

5As the default-value of timeout[2, 1] is a parameter, timeout[2, 1] might be greater than g from the

initialization.

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

43

∧ if (sTimer = 0 ∧ sPC = “SSnd”)

1 : SSnd ∆= ∧ ePC = “SSnd”
2 :
3 :
4 :
5 :
6 :

then buf (cid:48) = buf + 1
else unchanged buf

∧ ePC (cid:48) = “RNoSnd”
∧ unchanged (cid:104)sTimer , rTimer ...(cid:105)

Figure 6. Sending a new message in TLA+ in case of ∆ > 0

9.1. Model Checkers for TLA+: TLC and APALACHE. We ﬁrst use TLA+ [Lam02]
to specify the failure detector with both encoding techniques for the message buﬀer, and the
abstraction in Section 7. Then, we use the model checker TLC in the TLA+ Toolbox version
1.7.1 [YML99, Mic] and the model checker APALACHE version 0.15.0 [KKT19, Sys19] to
verify instances with ﬁxed bounds ∆ and Φ, and the GST T0 = 1. This approach helps us
to search constraints in inductive invariants in case of ﬁxed parameters. The main reason is
that counterexamples and inductive invariants in case of ﬁxed parameters, e.g., ∆ ≤ 1 and
Φ ≤ 1, are simpler than in case of arbitrary parameters. Hence, if a counterexample is found,
we can quickly analyze it, and change constraints in an inductive invariant candidate. We
apply the counterexample-guided approach to ﬁnd inductive strengthenings. After obtaining
inductive invariants in small cases, we can generalize them for cases of arbitrary bounds,
and check with theorem provers, e.g., IVy (Section 10).

TLA+ oﬀers a rich syntax for sets, functions, tuples, records, sequences, and control
structures [Lam02]. Hence, it is straightforward to apply the encoding techniques and the
abstraction presented in Section 7 in TLA+. For example, Figure 6 represents a TLA+
action SSnd for sending a new message in case of ∆ > 0. Variables ePC and sPC are
program counters for the environment and the sender, respectively. Line 1 is a precondition,
and refers to that the environment is in subround Send. Lines 2–3 say that if the sender is
active in subround Send, the counter buf (cid:48) is increased by 1. Otherwise, two counters buf
and buf (cid:48) are the same (Line 4). Line 5 implies that the environment is still in the subround
Send, but it is now the receiver's turn. Line 6 guarantees that other variables are unchanged
in this action.

Figure 7 represents the next–state relation in TLA+. Line 1 describes actions in sub-
round Schedule. The environment schedules the Sender, schedules the Receiver, and then
increases message ages. Lines 2, 3, and 4 describes actions in sub-rounds Send, Receive, and
Computation, respectively. The program counter ePC of the environment is used to ensure
that every action is repeated periodically and in order.

Figure 8 represents how the environment schedules the Receiver in TLA+. Line 1 says
that the current step is to schedule the Receiver, and Line 2 refers to the next action that
is to increase message ages. Line 3 non-deterministically sets the Receiver active in the
current global step. Lines 4–6 are to update the program counter rPC of the Receiver. The
environment schedules the Sender, schedules the Receiver, and then increases message ages.
Lines 7–8 non-deterministically sets the Receiver inactive in the current global step if the
Receiver is not frozen in the last Phi − 1 global steps. Line 9 is to keep other variables
unchanged.

Now we present the experiments with TLC and APALACHE. We used these tools to
verify (i) the safety property Strong Accuracy, and (ii) an inductive invariant for Strong
Accuracy, and (iii) an inductive invariant for a safety property reduced from the liveness

44

T.H. TRAN, I. KONNOV, AND J. WIDDER

1 : Next ∆= ∨ SSched ∨ RSched ∨ IncMsgAge
∨ SSnd ∨ RNoSnd
2 :
∨ RRcv
3 :
∨ RComp
4 :

Figure 7. The Next predicate for the next-state relation in TLA+

∧ ePC (cid:48) = “IncMsgAge”
∧ ∨ ∧ rTimer (cid:48) = 0

1 : RSched ∆= ∧ ePC = “RSched”
2 :
3 :
4 :
5 :
6 :
7 :
8 :
9 :

∨ ∧ rTimer < Phi − 1

∧ rTimer (cid:48) = rTimer + 1

∧ unchanged (cid:104)buf , sTimer ...(cid:105)

∧ rPC (cid:48) = “RComp”)
∧ ∨ (rPC = “RRcv”
∧ rPC (cid:48) = “RComp”)
∨ (rPC = “RRcv”
∨ (rPC = “RComp” ∧ rPC (cid:48) = “RNoSnd”)

Figure 8. The RSched predicate for scheduling the Receiver in TLA+

property Strong Completeness in case of ﬁxed bounds, and GST = 1 (initial stabilization).
The structure of the inductive invariants veriﬁed here are very close to one in case of arbitrary
bounds ∆ and Φ. While all parameters are assigned speciﬁc values in the inductive invariants
of small instances, they have arbitrary values in the case of arbitrary bounds.

Table 1 shows the results in veriﬁcation of Strong Accuracy in case of the initial
stabilization, and ﬁxed bounds ∆ and Φ. Table 1 shows the experiments with the three
tools TLC, APALACHE, and FAST. The column “#states” shows the number of distinct
states explored by TLC. The column “#depth” shows the maximum execution length
reached by TLC and APALACHE. The column “buf” shows how to encode the message
buﬀer. The column “LOC” shows the number of lines in the speciﬁcation of the system
behaviors (without comments). The symbol “-” (minus) refers to that the experiments are
intentionally missing since FAST does not support the encoding of the message buﬀer with
a predicate. The abbreviation “pred” refers to the encoding of the message buﬀer with
a predicate. The abbreviation “cntr” refers to the encoding of the message buﬀer with a
counter. The abbreviation “TO” means a timeout of 6 hours. In these experiments, we
initially set timeout = 6 × Φ + ∆, and Strong Accuracy is satisﬁed. The experiments show
that TLC ﬁnishes its tasks faster than the others, and APALACHE prefers the encoding of
the message buﬀer with a predicate.

Table 2 summarizes the results in veriﬁcation of Strong Accuracy with the tools TLC,
APALACHE, and FAST in case of the initial stabilization, and small bounds ∆ and Φ,
and initially timeout = ∆ + 1. Since timeout is initialized with a too small value, there exists
a case in which sent messages are delivered after the timeout expires. The tools reported
an error execution where Strong Accuracy is violated. In these experiments, APALACHE
is the winner. The abbreviation “TO” means a timeout of 6 hours. The meaning of other
columns and abbreviations is the same as in Table 1.

Table 3 shows the results in veriﬁcation of inductive invariants for Strong Accuracy and
Strong Completeness with TLC and APALACHE in case of the initial stabilization, and
slightly larger but ﬁxed bounds ∆ and Φ, e.g., ∆ = 20 and Φ = 20. The message buﬀer was

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

45

Table 1. Showing Strong Accuracy for ﬁxed parameters.

# ∆ Φ buf

1
2
3
4
5
6

2

4

4

4

4

5

pred
cntr
pred
cntr
pred
cntr

TLC

time #states
10.2K
10.2K
16.6K
16.6K
44.7K
44.7K

3s
3s
3s
3s
3s
3s

depth
176
176
183
183
267
267

APALACHE

FAST

LOC time
190
8m
9m
266
190 12m
487 35m
190 TO
487 TO

depth
176
176
183
183
222
223

time
-
16m
-

LOC
-
387
-
TO 2103
-
TO 2103

-

Table 2. Violating Strong Accuracy for ﬁxed parameters.

# ∆ Φ buf

TLC
time #states
840
945
1.3K
2.4K
22.1K

4

2

1s
1s
2s
2s
20 20 pred TO

pred
cntr
pred
cntr

4

4

1
2
3
4
5

APALACHE FAST
time
depth
42
-
10m
42
-
42
TO
42
-
168

time
depth
11s
43
12s
43
15s
48
56
16s
77 1h15m

Table 3. Proving inductive invariants with TLC and APALACHE.

# ∆ Φ

Property

1
2

4
4

40
10

Strong Accuracy
Strong
Completeness

TLC
time #states
33m 347.3M
13.4M
44m

APALACHE
time
12s
17s

encoded with a predicate in these experiments. In these experiments, inductive invariants
hold, and APALACHE is faster than TLC in verifying them. In our experiment, we applied
the counterexample-guided approach to manually ﬁnd inductive strengtheningss.

As one sees from the tables, APALACHE is fast at proving inductive invariants, and at
ﬁnding a counterexample when a desired safety property is violated. TLC is a better option
in cases where a safety property is satisﬁed.

In order to prove correctness of the failure detector in cases where parameters ∆
and Φ are arbitrary, the user can use the interactive theorem prover TLA+ Proof System
(TLAPS) [CDLM10]. A shortcoming of TLAPS is that it does not provide a counterexample
when an inductive invariant candidate is violated. Moreover, proving the failure detector
with TLAPS requires more human eﬀort than with IVy. Therefore, we provide IVy proofs
in Section 10.

9.2. FAST. A shortcoming of the model checkers TLC and APALACHE is that parameters
∆ and Φ must be ﬁxed before running these tools. FAST is a tool designed to reason
about safety properties of counter systems, i.e. automata extended with unbounded integer
variables [BLP06]. If ∆ is ﬁxed, and the message buﬀer is encoded with a counter, the
failure detector becomes a counter system. We speciﬁed the failure detector in FAST, and

46

T.H. TRAN, I. KONNOV, AND J. WIDDER

1: transition SSnd Active ··= {
2:
3:
4:
5:

from ··= incMsgAge;
to ··= ssnd;
guard ··= sTimer = 0;
action := buf(cid:48) = buf + 1; };

Figure 9. Sending a new message in FAST in
case of ∆ > 0

made experiments with diﬀerent parameter values to understand the limit of FAST: (i) the
initial stabilization, and small bounds ∆ and Φ, and (ii) the initial stabilization, ﬁxed ∆,
but unknown Φ.

Figure 9 represents a FAST transition for sending a new message in case of ∆ > 0.
Line 2 describes the (symbolic) source state of the transition, and region incMsgAge is a set
of conﬁgurations in the failure detector that is reachable from a transition for increasing
message ages. Line 3 mentions the (symbolic) destination state of the transition, and region
sSnd is a set of conﬁgurations in the failure detector that is reachable from a transition
named “SSnd Active” for sending a new message. Line 4 represents the guard of this
transition. Line 5 is an action. Every unprimed variable that is not written in Line 5 is
unchanged.

The input language of FAST is based on Presburger arithmetics for both system and
properties speciﬁcation. Hence, we cannot apply the encoding of the message buﬀer with a
predicate in FAST.

Tables 1 and 2 described in the previous subsection summarize the experiments
with FAST, and other tools where all parameters are ﬁxed. Moreover, we ran FAST
to verify Strong Accuracy in case of the initial stabilization, ∆ ≤ 4, and arbitrary Φ. FAST
is a semi-decision procedure; therefore, it does not terminate on some inputs. Unfortunately,
FAST could not prove Strong Accuracy in case of arbitrary Φ, and crashed after 30 minutes.

10. IVy Proofs for Parametric ∆ and Φ
While TLC, APALACHE, and FAST can automatically verify some instances of the failure
detector with ﬁxed parameters, these tools cannot handle cases with unknown bounds ∆ and
Φ. To overcome this problem, we specify and prove correctness of the failure detector with
the interactive theorem prover IVy [MP20]. In the following, we ﬁrst discuss the encoding
of the failure detector, and then present the experiments with IVy.

The encoding of the message buﬀer with a counter requires that bound ∆ is ﬁxed. We
here focus on cases where bound ∆ is unknown. Hence, we encode the message buﬀer with
a predicate in our IVy speciﬁcations,

In IVy, we declare relation existsMsgOfAge(X : num). Type num is interpreted as
integers. Since IVy does not support primed variables, we need an additional relation
tmpExistsMsgOfAge(X : num). Intuitively, we ﬁrst compute and store the value of existsMs-
gOfAge in the next state in tmpExistsMsgOfAge, then copy the value of tmpExistsMsgOfAge
back to existsMsgOfAge. We do not consider the requirement of tmpExistsMsgOfAge as a
shortcoming of IVy since it is still straightforward to transform the ideas in Section 7 to IVy.
Figure 2 represents how to add a fresh message in the message buﬀer in IVy. Line 1 means
that tmpExistsMsgOfAge is assigned an arbitrary value. Line 2 guarantees the appearance

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

47

of a fresh message. Line 3 ensures that every in-transit message in existsMsgOfAge is
preserved in tmpExistsMsgOfAge. Line 4 copies the value of tmpExistsMsgOfAge back to
existsMsgOfAge.

Algorithm 2 Adding a fresh message in IVy
1: tmpExistsMsgOfAge(X ) ··= ∗;
2: assume tmpExistsMsgOfAge(0);
3: assume forall X : num . 0 < X → existsMsgOfAge(X ) = tmpExistsMsgOfAge(X );
4: existsMsgOfAge(X ) ··= tmpExistsMsgOfAge(X );

In
Importantly, our speciﬁcations are not in decidable theories supported by IVy.
Formula 7.11, the interpreted function “ + ” (addition) is applied to a universally quantiﬁed
variable x .

The standard way to check whether a safety property Prop holds in an IVy speciﬁcation is
to ﬁnd an inductive invariant IndInv with Prop, and to (interactively) prove that Indinv holds
in the speciﬁcation. To verify the liveness properties Eventually Strong Accuracy, and Strong
Completeness, we reduced them into safety properties by applying a reduction technique in
Section 8, and found inductive invariants containing the resulting safety properties reduced
from the liveness properties. These inductive invariants are the generalization of the inductive
invariants in case of ﬁxed parameters that were found in the previous experiments.

Table 4. Proving inductive invariants with IVy for arbitrary ∆ and Φ.

#

1

2

3
4
5

Property

timeoutinit

time

LOC #lineI

Strong Accuracy
Eventually
Strong Accuracy

Strong Completeness

= 6×Φ+∆

= (cid:63)

= 6×Φ+∆
≥ 6×Φ+∆
= (cid:63)

4s

4s

8s
22s
44s

183

186

203
207
207

30

35

111
124
129

#strengthening
steps
0

0

0
15
0

Table 4 shows the experiments on veriﬁcation of the failure detector with IVy in case
of unknown ∆ and Φ. The symbol (cid:63) refers to that the initial value of timeout is arbitrary.
The column “#lineI ” shows the number of lines of an inductive invariant, and the column
“#strengthening steps” shows the number of lines of strengthening steps that we provided
for IVy. The meaning of other columns is the same as in Table 1. While our speciﬁcations
are not in the decidable theories supported in IVy, our experiments show that IVy needs no
user-given strengthening steps to prove most of our inductive invariants. Hence, it took us
about 4 weeks to learn IVy from scratch, and to prove these inductive invariants.

The most important thing to prove a property satisﬁed in an IVy speciﬁcation is
to ﬁnd an inductive invariant. Our inductive invariants use non-linear integers, quanti-
ﬁers, and uninterpreted functions. (The inductive invariants in Table 4 are given in the
repository [TKW].)

While IVy supports a liveness-to-safety reduction [PHL+17], this technique is not fully
automated, and IVy still needs user-guided inductive invariant for reduced safety properties
that may be diﬀerent from those in Table 4. Moreover, IVy has not supported reasoning
techniques for clocks. Therefore, we did not try the liveness-to-safety reduction of IVy.

48

T.H. TRAN, I. KONNOV, AND J. WIDDER

It is straightforward to generalize the inductive invariants in Table 4 for partially
synchronous models with known time bounds in [DLS88, CT96]. To reason about models
with GST > 0, we need to ﬁnd additional inductive strengthenings because the global
system is under asynchrony before GST. Other partially synchronous models in [ABND+87]
consider additional paramaters, e.g., message order or point-to-point transmission that are
out of scope of this paper.

11. Related work

11.1. Cutoﬀs. Distributed algorithms are typically parameterized in the number of par-
ticipants, e.g., two-phase commit protocol [LS79] and the Chandra and Toueg failure
detector in Section 2. While the general parameterized veriﬁcation problem is undecid-
able [AK86, Suz88, BJK+15b], many distributed algorithms such as mutual exclusion and
cache coherence enjoy the cutoﬀ property, which reduces the parameterized veriﬁcation
problem to veriﬁcation of a small number of instances. In a nutshell, a cutoﬀ for a pa-
rameterized algorithm A and a property φ is a number k such that φ holds for every
instance of A if and only if φ holds for instances with k processes [EN95, BJK+15b]. In
the last decades, researchers have proved the cutoﬀ results for various models of compu-
tation: ring-based message-passing systems [EN95, EK04], purely disjunctive guards and
conjunctive guards [EK00, EK03], token-based communication [CTTV04], and quorum-based
algorithms [MSB17]. However, we cannot apply these results to the Chandra and Toueg
failure detector because it relies on point-to-point communication and timeouts. Moreover,
distributed algorithms discussed in [EN95, EK00, EK03, EK04, CTTV04, MSB17] are not
in the symmetric point-to-point class.

11.2. Formal veriﬁcation for partial synchrony. Partial synchrony is a well-known
model of computation in distributed computing. To guarantee liveness properties, many prac-
tical protocols, e.g., the failure detector in Section 2 and proof-of-stake blockchains [BKM18,
YMR+19], assume time constraints under partial synchrony. That is the existence of bounds
∆ on message delay and Φ on the relative speed of processes after some time point.

While partial synchrony is important for system designers, it is challenging for veriﬁcation.
The mentioned constraint makes partially synchronous algorithms parametric in time bounds.
Moreover, partially synchronous algorithms are typically parameterized in the number of
processes.

Research papers about partially synchronous algorithms, including papers about failure
detectors [LAF99, ADGFT06, ADGFT08] contain manual proofs and no formal speciﬁca-
tions. Without these details, proving those distributed algorithms with interactive theorem
provers [CDL+12, MP20] is impossible.

System designers can use timed automata [AD94] and parametric veriﬁcation frame-
works [LPY97, AFKS12, LRST09] to specify and verify timed systems. In the context of
timed systems, we are aware of only one paper about veriﬁcation of failure detectors [AMO12].
In this paper, the authors used three tools, namely UPPAAL [LPY97], mCRL2 [BGK+19],
and FDR2 [Ros10] to verify small instances of a failure detector based on a logical ring
arrangement of processes. Their veriﬁcation approach required that message buﬀers were
bounded, and had restricted behaviors in the speciﬁcations. Moreover, they did not consider

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

49

the bound Φ on the relative speed of processes. In contrast, there are no restrictions on
message buﬀers, and no ring topology in the Chandra and Toueg failure detector.

In recent years, automatic parameterized veriﬁcation techniques [KLVW17b, SKWZ19,
DWZ20] have been introduced for distributed systems, but they are designed for synchronous
and/or asynchronous models. Interactive theorem provers have been used to prove correctness
of distributed algorithms recently. For example, researchers proved safety of Tendermint
consensus with IVy [Gal].

12. Conclusion

We have presented parameterized and parametric veriﬁcation of both safety and liveness of
the Chandra and Toeug failure detector. To this end, we ﬁrst introduce and formalize the
class of symmetric point-to-point algorithms that contains the failure detector. Second, we
show that the symmetric point-to-point algorithms have a cutoﬀ, and the cutoﬀ properties
hold in three models of computation: synchrony, asyncrony, and partial synchrony.

Next, we develop the encoding techniques to eﬃciently specify the failure detector, and
to tune our models to the strength of the veriﬁcation tools: model checkers for TLA+ (TLC
and APALACHE), counter automata (FAST), and the theorem prover Ivy. We verify safety
in case of ﬁxed parameters by running the tools TLC, APALACHE, and FAST. To cope
with cases of arbitrary bounds ∆ and Φ, we reduce liveness properties to safety properties,
and proved inductive invariants with desired properties in Ivy. While our speciﬁcations are
not in the decidable theories supported in Ivy, our experiments show that Ivy needs no
additional user assistance to prove most of our inductive invariants.

Modeling the failure detector in TLA+ helped us understand and ﬁnd inductive invari-
ants in case of ﬁxed parameters. Their structure is simpler but similar to the structure of
parameterized inductive invariants. We found that the TLA+ Toolbox [KLR19] has conve-
nient features, e.g., Proﬁler and Trace Exploration. A strong point of Ivy is in producing a
counterexample quickly when a property is violated, even if all parameters are arbitrary. In
contrast, FAST reports no counterexample in any case. Hence, debugging in FAST is very
challenging.

While our speciﬁcation describes executions of the Chandra and Toueg failure detector,
we conjecture that many time constraints on network behaviors, correct processes, and
failures in our inductive invariants can be reused to prove other algorithms under partial
synchrony. We also conjecture that correctness of other partially synchronous algorithms may
be proven by following the presented methodology. For future work, we would like to extend
the above results for cases where GST is arbitrary. It is also interesting to investigate how
to express discrete partial synchrony in timed automata [AD94], e.g., UPPAAL [LPY97].

50

T.H. TRAN, I. KONNOV, AND J. WIDDER

References

[ABND+87] Hagit Attiya, Amotz Bar-Noy, Danny Dolev, Daphne Koller, David Peleg, and Radiger Reischuk.
Achievable cases in an asynchronous environment. In 28th Annual Symposium on Foundations
of Computer Science (sfcs 1987), pages 337–346. IEEE, 1987.
Rajeev Alur and David L Dill. A theory of timed automata. Theoretical computer science,
126(2):183–235, 1994.

[AD94]

[ADGFT06] Marcos Kawazoe Aguilera, Carole Delporte-Gallet, Hugues Fauconnier, and Sam Toueg. Con-
sensus with Byzantine failures and little system synchrony. In DSN, pages 147–155. IEEE,
2006.

[ADGFT08] Marcos K Aguilera, Carole Delporte-Gallet, Hugues Fauconnier, and Sam Toueg. On implement-
ing omega in systems with weak reliability and synchrony assumptions. Distributed Computing,
21(4):285–314, 2008.
´Etienne Andr´e, Laurent Fribourg, Ulrich K¨uhne, and Romain Soulat. IMITATOR 2.5: A tool
for analyzing robustness in scheduling problems. In FM, pages 33–36. Springer, 2012.
K. Apt and D. Kozen. Limits for automatic veriﬁcation of ﬁnite-state concurrent systems. IPL,
15:307–309, 1986.

[AFKS12]

[AK86]

[AMO12] Muhammad Atif, Mohammad Reza Mousavi, and Ammar Osaiweran. Formal veriﬁcation of

[AW04]

[BAS02]

[BCG20]

[BFLP08]

unreliable failure detectors in partially synchronous systems. In SAC, pages 478–485, 2012.
Hagit Attiya and Jennifer Welch. Distributed Computing: Fundamentals, Simulations and
Advanced Topics, Second Edition. John Wiley & Sons, Inc., 2004.
Armin Biere, Cyrille Artho, and Viktor Schuppan. Liveness checking as safety checking. Electronic
Notes in Theoretical Computer Science, 66(2):160–177, 2002.
Manuel Bravo, Gregory Chockler, and Alexey Gotsman. Making Byzantine consensus live. In
DISC. Schloss Dagstuhl-Leibniz-Zentrum f¨ur Informatik, 2020.
S´ebastien Bardin, Alain Finkel, J´erˆome Leroux, and Laure Petrucci. Fast: acceleration from
theory to practice. STTT, 10(5):401–424, 2008.

[BGK+19] Olav Bunte, Jan Friso Groote, Jeroen JA Keiren, Maurice Laveaux, Thomas Neele, Erik P
de Vink, Wieger Wesselink, Anton Wijs, and Tim AC Willemse. The mCRL2 toolset for
analysing concurrent systems. In TACAS, pages 21–39. Springer, 2019.

[BJK+15a] Roderick Bloem, Swen Jacobs, Ayrat Khalimov,

Igor Konnov, Sasha Rubin, Helmut
Veith, and Josef Widder. Decidability of Parameterized Veriﬁcation. Synthesis Lectures
on Distributed Computing Theory. Morgan & Claypool Publishers, 2015. doi:10.2200/
S00658ED1V01Y201508DCT013.

[BJK+15b] Roderick Bloem, Swen Jacobs, Ayrat Khalimov, Igor Konnov, Sasha Rubin, Helmut Veith,
and Josef Widder. Decidability of parameterized veriﬁcation. Synthesis Lectures on Distributed
Computing Theory, 6(1):1–170, 2015.
Ethan Buchman, Jae Kwon, and Zarko Milosevic. The latest gossip on BFT consensus. arXiv
preprint arXiv:1807.04938, 2018.
S´ebastien Bardin, J´erˆome Leroux, and G´erald Point. Fast extended release. In CAV, pages
63–66, 2006.

[BKM18]

[BLP06]

[CDL+12] Denis Cousineau, Damien Doligez, Leslie Lamport, Stephan Merz, Daniel Ricketts, and Hern´an

Vanzetto. TLA+ proofs. In FM, pages 147–154. Springer, 2012.

[CDLM10] Kaustuv Chaudhuri, Damien Doligez, Leslie Lamport, and Stephan Merz. The TLA+ Proof
System: Building a heterogeneous veriﬁcation platform. In ICTAC, pages 44–44. Springer, 2010.
[CJGK+18] Edmund M Clarke Jr, Orna Grumberg, Daniel Kroening, Doron Peled, and Helmut Veith. Model

[CT96]

checking. MIT press, 2018.
Tushar Deepak Chandra and Sam Toueg. Unreliable failure detectors for reliable distributed
systems. Journal of the ACM, 43(2):225–267, 1996.

[CTTV04] Edmund Clarke, Muralidhar Talupur, Tayssir Touili, and Helmut Veith. Veriﬁcation by network
decomposition. In International Conference on Concurrency Theory, pages 276–291. Springer,
2004.
Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer. Consensus in the presence of partial
synchrony. Journal of the ACM, 35(2):288–323, 1988.
Cezara Dr˘agoi, Josef Widder, and Damien Zuﬀerey. Programming at the edge of synchrony.
Proceedings of the ACM on Programming Languages, 4(OOPSLA):1–30, 2020.

[DWZ20]

[DLS88]

A CASE STUDY ON PARAMETRIC VERIFICATION OF FAILURE DETECTORS

51

[EK00]

[EK03]

[EK04]

[EN95]
[Gal]

[Hoa80]
[KKT19]

[KLR19]

E Allen Emerson and Vineet Kahlon. Reducing model checking of the many to the few. In
International conference on automated deduction, pages 236–254. Springer, 2000.
E Allen Emerson and Vineet Kahlon. Exact and eﬃcient veriﬁcation of parameterized cache
coherence protocols. In Advanced Research Working Conference on Correct Hardware Design
and Veriﬁcation Methods, pages 247–262. Springer, 2003.
E. Allen Emerson and Vineet Kahlon. Parameterized model checking of ring-based message
passing systems. In CSL, volume 3210 of LNCS, pages 325–339. Springer, 2004.
E Allen Emerson and Kedar S Namjoshi. Reasoning about rings. In POPL, pages 85–94, 1995.
Inc. Galois. Ivy proofs of tendermint. URL: https://github.com/tendermint/spec/tree/
master/ivy-proofs, accessed: December 2020.
Charles Antony Richard Hoare. A model for communicating sequential process. 1980.
Igor Konnov, Jure Kukovec, and Thanh-Hai Tran. TLA+ model checking made symbolic.
Proceedings of the ACM on Programming Languages, 3(OOPSLA):1–30, 2019.
Markus Alexander Kuppe, Leslie Lamport, and Daniel Ricketts. The TLA+ toolbox. arXiv
preprint arXiv:1912.10633, 2019.

[KLVW17a] Igor Konnov, Marijana Lazic, Helmut Veith, and Josef Widder. Para2: Parameterized path
reduction, acceleration, and SMT for reachability in threshold-guarded distributed algorithms.
Formal Methods in System Design, 51(2):270–307, 2017.

[KLVW17b] Igor Konnov, Marijana Lazi´c, Helmut Veith, and Josef Widder. Para2: parameterized path
reduction, acceleration, and SMT for reachability in threshold-guarded distributed algorithms.
Formal Methods in System Design, 51(2):270–307, 2017.

[LAF99]

[KLVW17c] Igor Konnov, Marijana Lazi´c, Helmut Veith, and Josef Widder. A short counterexample property
for safety and liveness veriﬁcation of fault-tolerant distributed algorithms. In POPL, pages
719–734, 2017.
Mikel Larrea, Sergio Ar´evalo, and Antonio Fernndez. Eﬃcient algorithms to implement unreliable
failure detectors in partially synchronous systems. In DISC, pages 34–49. Springer, 1999.
Leslie Lamport. Specifying systems: The TLA+ language and tools for hardware and software
engineers. Addison-Wesley, 2002.
Kim G Larsen, Paul Pettersson, and Wang Yi. UPPAAL in a nutshell. International Journal on
Software Tools for Technology Transfer, 1(1-2):134–152, 1997.

[LPY97]

[Lam02]

[LS79]

[LT88]

[LRST09] Didier Lime, Olivier H Roux, Charlotte Seidner, and Louis-Marie Traonouez. Romeo: A
parametric model-checker for Petri nets with stopwatches. In TACAS, pages 54–57. Springer,
2009.
Butler Lampson and Howard E Sturgis. Crash recovery in a distributed data storage system.
1979.
Nancy A Lynch and Mark R Tuttle. An introduction to input/output automata. Laboratory for
Computer Science, Massachusetts Institute of Technology, 1988.
Microsoft and HP. The TLA+ Toolbox. URL: github.com/tlaplus, accessed: July 2021].
Kenneth L McMillan and Oded Padon. Ivy: a multi-modal veriﬁcation tool for distributed
algorithms. In CAV, pages 190–202. Springer, 2020.
Ognjen Mari´c, Christoph Sprenger, and David Basin. Cutoﬀ bounds for consensus algorithms.
In International Conference on Computer Aided Veriﬁcation, pages 217–237. Springer, 2017.

[Mic]
[MP20]

[MSB17]

[PW97]

[Pnu77]

[PHL+17] Oded Padon, Jochen Hoenicke, Giuliano Losa, Andreas Podelski, Mooly Sagiv, and Sharon
Shoham. Reducing liveness to safety in ﬁrst-order logic. Proceedings of the ACM on Programming
Languages, 2(POPL):1–33, 2017.
Amir Pnueli. The temporal logic of programs. In 18th Annual Symposium on Foundations of
Computer Science (sfcs 1977), pages 46–57. ieee, 1977.
Doron Peled and Thomas Wilke. Stutter-invariant temporal properties are expressible without
the next-time operator. Information Processing Letters, 63(5):243–246, 1997.
Andrew William Roscoe. Understanding concurrent systems. Springer Science & Business Media,
2010.
Ilina Stoilkovska, Igor Konnov, Josef Widder, and Florian Zuleger. Verifying safety of synchronous
fault-tolerant algorithms by bounded model checking. In TACAS, pages 357–374. Springer, 2019.
Ichiro Suzuki. Proving properties of a ring of ﬁnite-state machines. Information Processing
Letters, 28(4):213–214, 1988.

[SKWZ19]

[Ros10]

[Suz88]

52

T.H. TRAN, I. KONNOV, AND J. WIDDER

[Sys19]

[TKW]

[TKW20]

Informal Systems. APALACHE: symbolic model checker for TLA+, 2019. URL: github.com/
informalsystems/apalache, accessed: July 2021.
Thanh-Hai Tran, Igor Konnov, and Josef Widder. Speciﬁcations of the Chandra and Toueg failure
detector in TLA+, FAST, and Ivy. URL: https://zenodo.org/record/4687714#.YHcBeBKxVH4,
accessed: April 2021.
Thanh-Hai Tran, Igor Konnov, and Josef Widder. Cutoﬀs for symmetric point-to-point dis-
tributed algorithms. In NETYS, pages 329–346. Springer, 2020.
Thanh-Hai Tran, Igor Konnov, and Josef Widder. A case study on parametric veriﬁcation of
failure detectors. In International Conference on Formal Techniques for Distributed Objects,
Components, and Systems, pages 138–156. Springer, 2021.
Yuan Yu, Panagiotis Manolios, and Leslie Lamport. Model checking TLA+ speciﬁcations. In
Correct Hardware Design and Veriﬁcation Methods, pages 54–66. Springer, 1999.
[YMR+19] Maofan Yin, Dahlia Malkhi, Michael K Reiter, Guy Golan Gueta, and Ittai Abraham. Hotstuﬀ:
BFT consensus with linearity and responsiveness. In PODC, pages 347–356, 2019.

[TKW21]

[YML99]

Appendix A. Linear temporal logic (LTL)

The syntax of LTL formulae is given by the following syntax [Pnu77]:

φ ::= (cid:62) | p | ¬φ | φ ∧ φ | X φ | φ U φ

where
• (cid:62) stands for true,
• p ranges over a countable set AP of atomic predicates,
• ¬ and ∧ are Boolean operators negation and conjunction respectively,
• X and U are the temporal operators next and until respectively.

Other Boolean operators ∨, ⇒, and ⇔ are deﬁned in the standard way. We also use ⊥
(false), F (eventually), G (always) to abbreviate ¬(cid:62), (cid:62) U φ , and ¬((cid:62) U ¬φ) respectively.
Let us consider an LTL formula φ over propositions in AP and a word w : N → 2AP.

We deﬁne the relation w (cid:15) φ (the word w satisﬁes the formula φ) inductively as follows.
• w (cid:15) (cid:62) for all w
• w (cid:15) p if p ∈ w [0]
• w (cid:15) ¬φ if not w (cid:15) φ
• w (cid:15) φ1 ∧ φ2 if w (cid:15) φ1 and w (cid:15) φ2
• w (cid:15) X φ if w [1...] (cid:15) φ where w [k ...] denotes the suﬃx w [k ]w [k + 1] . . .
• w (cid:15) φ1 U φ2 if there exists j ≥ 0 such that w [j ...] (cid:15) φ2 and for all 0 ≤ i < j , w [i ...] (cid:15) φ1
Two words w and w (cid:48) are stuttering equivalent if there are two inﬁnite sequences of
numbers 0 = i0 < i1 < i2 < . . . and 0 = j0 < j1 < j2 < . . . such that for every (cid:96) ≥ 0, it holds
wi(cid:96) = wi(cid:96)+1 = . . . = wi(cid:96)+1−1 = w (cid:48)
j(cid:96)+1 = . . . = w (cid:48)
j(cid:96)

j(cid:96)+1−1 [CJGK+18].

= w (cid:48)

In this paper, we deal with properties in LTL\X (LTL minus the next operator).
Importantly, all LTL properties that are invariants under stuttering equivalence can be
expressed without the next operator X [PW97].

This work is licensed under the Creative Commons Attribution License. To view a copy of this
license, visit https://creativecommons.org/licenses/by/4.0/ or send a letter to Creative
Commons, 171 Second St, Suite 300, San Francisco, CA 94105, USA, or Eisenacher Strasse
2, 10777 Berlin, Germany

