Transaction Placement in Sharded Blockchains

1st Liuyang Ren
University of Waterloo
Waterloo, Canada
l27ren@uwaterloo.ca

2nd Paul A. S. Ward
University of Waterloo
Waterloo, Canada
pasward@uwaterloo.ca

2
2
0
2

n
u
J

9

]

C
D
.
s
c
[

3
v
0
7
6
7
0
.
9
0
1
2
:
v
i
X
r
a

Abstract—While many researchers adopt a sharding approach
to design scaling blockchains, few works have studied the trans-
action placement problem incurred by sharding protocols. The
widely-used hashing placement algorithm renders an overwhelm-
ing portion of transactions as cross-shard. In this paper, we ana-
lyze the high cost of cross-shard transactions and reveal that most
Bitcoin transactions have simple dependencies and can become
single-shard under a placement algorithm taking transaction
dependencies into account. In addition, we perform a case study
of OptChain, which is the state-of-the-art transaction placement
algorithm for sharded blockchains, and ﬁnd a shortcoming of it.
A simple ﬁx is proposed, and our evaluation results demonstrate
that the proposed ﬁx effectively helps OptChain overcome the
shortcoming and signiﬁcantly improve the system performance
under a special workload. The authors of OptChain made some
revisions to the algorithm description after noticing our work.
Their updated algorithm does not exhibit the shortcoming under
the workloads employed by this paper.

Index Terms—blockchain, sharding, transaction dependencies,

transaction placement

I. INTRODUCTION

Conventional blockchain systems suffer from low perfor-
mance due to the PoW consensus protocol, which requires
all nodes to duplicate the works from each other. To improve
the performance, various designs have been proposed—e.g.,
shortening block intervals [1], incorporating off-chain blocks
[2] [3], allowing one miner to consecutively propose multiple
blocks [4], sharding [5] [6] [7] [8], journaling aggregated
transaction effects to blockchains [9] [10], etc. Among these
techniques, sharding is a promising approach and has been
explored by many researchers. The high-level idea of sharding
is to partition a system into multiple shards and distribute
its workloads to different shards for parallel processing so
that the system performance scales with the number of nodes.
However, because each shard usually stores a disjoint subset
of the system state [6] [7] [8], transactions modifying more
than one such subsets would inevitably incur cross-shard
communication. Speciﬁcally, such cross-shard transactions
rely on Atomic Commit Protocols (ACPs) to guarantee state
consistency between shards. In addition to network bandwidth
consumption, ACPs also put extra computational burdens on
the involved shards, especially in trustless environments (i.e.,
public blockchains), where expensive digital signatures are
employed to prove message authenticity.

While many previous works focus on blockchain sharding
protocols, few researchers have paid attention to transaction
placement, which is about selecting a shard to process a given
transaction. Transaction placement algorithms have a major
impact on the number of cross-shard transactions and conse-
quently the system performance. The transaction placement
algorithm used by most, if not all, sharding protocols is the
Hashing Placement (HP) [5]. HP places transactions to shards
based on the preﬁx matching of transaction IDs and shard IDs.
Because transaction IDs are hash values (e.g., SHA256 values
in Bitcoin), and hash values are uniformly distributed over the
output range of the corresponding hash function [11], HP is
equivalent to placing transactions randomly. As a result, HP
produces a considerable number of cross-shard transactions.
Fig. 1 illustrates the placement outcome for the 1.57 million
non-coinbase1 transactions in the ﬁrst 150k Bitcoin blocks.
When the system involves more than 32 shards, almost all
non-coinbase transactions are cross-shard.

Figure 1: A high percentage of transactions are cross-shard
under the hashing placement algorithm.

This work has three contributions: 1) revealing that the
overwhelming majority of Bitcoin transactions have only one
parent transaction; 2) identifying the root cause of the high cost
of cross-shard transactions; and 3) identifying a shortcoming
in OptChain [12], a state-of-the-art blockchain transaction
placement algorithm, and proposing an effective ﬁx.

II. BACKGROUND

A blockchain is an ordered set of blocks, each of which
contains an ordered set of transactions. Every node maintains
a local copy of the whole blockchain, executes the transactions
in the order speciﬁed by the blockchain, and thus ends up with
the same system state as other nodes.

1Coinbase transactions have no input UTXOs and credit newly “minted”

This research is supported in part by a Ripple Graduate Fellowship.

UTXOs to miners. Non-coinbase transactions spend existing UTXOs.

0255075100125150Number of shards0255075100Percentage ofcross-shardtransactions (%) 
 
 
 
 
 
A. Unspent Transaction Output (UTXO) Model

Unlike conventional banking systems, cryptocurrencies like
Bitcoin use a UTXO model to express their system states in-
stead of the account-balance model. Accordingly, a transaction
spends input UTXOs and generates output UTXOs. Figure 2
demonstrates the transaction execution in Bitcoin. Bob sends
1.5 BTC to Alice by creating a transaction that spends his
2-BTC UTXO and generates a 1.5-BTC UTXO for Alice as
well as a 0.5-BTC UTXO for himself. Once the transaction
gets executed, the 2-BTC UTXO (i.e., UTXO B in Fig. 2) does
not exist anymore. All transactions have at least one input
UTXO, except for coinbase transactions, which spend nothing
and credit output UTXOs to miners.

Figure 2: Transaction execution

The transaction placement problem in a UTXO-based sys-
tem is to ﬁnd a shard to process a transaction and store the
output UTXOs of the transaction. This shard is called the
output shard of this transaction. Similarly, a shard storing at
least one input UTXO of this transaction is called an input
shard.

B. Blockchain Sharding Protocols

In this section, we focus on describing the sharding protocol
OmniLedger [6] and brieﬂy introduce other sharding protocols
because OmniLedger is used by OptChain for evaluation.

Blockchain sharding protocols divide nodes into shards that
process transactions in parallel. OmniLedger shards maintain
their own respective ledgers. Every shard produces blocks
extending from its individual ledger, and the blockchain is the
union of the ledgers of all shards. Shard members are selected
using Proof-of-Work (PoW) to protect the system from Sybil
attacks and periodically reconﬁgured so that attackers cannot
corrupt a shard by attacking a small and ﬁxed group of
nodes. Within a shard, nodes run the Practical Byzantine Fault
Tolerance (PBFT) protocol [13] to agree on the validity and
the execution order of transactions.

Cross-shard transactions rely on atomic commit protocols
(ACPs) to be either unanimously committed or unanimously
aborted. The problem of guaranteeing transaction atomicity
dates back to the late 1970s [14] [15]. Among various ACPs,

the two-phase commit protocol (2PC) [14] is the most widely
used one in the industry and academia [16] [17]. OmniLedger
has proposed a similar protocol called Atomix for atomi-
cally processing transactions across shards. The basic idea of
Atomix is shown in Fig. 3. The client requests the input shards
to lock the input UTXOs of its cross-shard transaction, and the
input shards reply with signed lock results. If all input shards
reply with positive lock results, the client then sends the output
shard a COMMIT request along with signatures from the input
shards as proofs of successful locking. The output shard adds
the output UTXO to its system state, provided all signatures
of the input shards are valid. If any input shard cannot lock
an input UTXO, it informs the client about the failure with
a signed message, and the client will use the message as a
proof to request other input shards to unlock their respective
input UTXOs. In blockchain environments, it is challenging
to ﬁnd an ACP coordinator, whose misbehavior may lead to
forever-locked UTXOs. OmniLedger chooses clients as the
coordinators of their own transactions so that coordinators are
incentivized to conform to the ACP protocol.

Like OmniLedger, Elastico [5] and AHL [8] also employ
PBFT as their intra-shard consensus protocol. RapidChain
[7], on the other hand, uses a variant of the synchronous
consensus protocol proposed by Ren et al. [18] to tolerate the
same number of faulty nodes with a smaller shard size than
PBFT. In terms of ACPs, Dang et al. [8] incorporates 2PC
and leverages an entire Byzantine fault-tolerant committee
as the coordinator. RapidChain [47] processes a cross-shard
transaction by splitting it into multiple sub-transactions, each
of which spends UTXOs belonging to the same shard (i.e.,
every sub-transaction has only one input shard). Elastico
is fundamentally different from other sharding protocols in
that it does not partition system states despite the fact that
transactions are partitioned. In other words, every Elastico
node still maintains the whole system state (i.e., all UTXOs).
As a result, there are no cross-shard transactions in Elastico.
Table I summarizes these sharding protocols.

III. TRANSACTION CHARACTERISTICS

Understanding transaction characteristics allows us to de-
termine whether carefully placing transactions to shards can
achieve substantial performance improvement. We are partic-
ularly interested in two characteristics: 1) how many transac-
tions can be easily turned into single-shard transactions, and
2) how expensive a cross-shard transaction is when compared
with a single-shard transaction. A transaction placement algo-
rithm can only beneﬁt the system performance if cross-shard
transactions cost a lot more than their single-shard counterparts
and can be greatly reduced by the algorithm.

A. Transaction Dependencies

If transaction tx2 spends the UTXO(s) produced by trans-
action tx1, then tx1 is called the parent transaction and tx2
is the child transaction. Given a transaction, the number of
its parent transactions directly affects its probability of being
single-shard. For example, a transaction with only one parent

UTXO	A:	value	=	1	BTC,	owner	=	AliceUTXO	B:	value	=	2	BTC,	owner	=	BobUTXO	A:	value	=	1	BTC,	owner	=	AliceUTXO	C:	value	=	0.5	BTC,	owner	=	BobUTXO	D:	value	=	1.5	BTC,	owner	=	AliceTransactionOld system stateNew system stateInput:UTXO	BOutput:UTXO	C	(0.5	BTC,	Bob)UTXO	D	(1.5	BTC,	Alice)(a) A cross-shard transaction

(b) Lock-success scenario in Atomix

Figure 3: An example of OmniLedger’s Atomix protocol

Table I: Comparison of Various Blockchain Shading Protocols

Protocol
Elastico
OmniLedger
RapidChain
AHL

Intra-shard Consensus
PBFT
PBFT
Practical synchronous byzantine consensus [18]
PBFT

ACP
N/A
Atomix [6]
Transaction Splitting [7]
2PC

ACP Coordinator
N/A
Client
PBFT leader of output shard
Dedicated BFT committee

Transaction Placement
Hashing placement
Hashing placement
Hashing placement
Hashing placement

can be a single-shard transaction if it is placed to the same
shard as its parent. In contrast, a transaction with 100 parents
is very unlikely to be single-shard since that requires all of
the 100 parents have been placed to the same shard. Thus,
we analyze parent counts for the 1,119,794 transactions in the
601001st to 601500th Bitcoin block (coinbase transactions are
excluded since they have no parents and are guaranteed to be
single-shard). Because Bitcoin blocks are usually referred to
using heights, which are indices starting from zero, we refer
to the (k + 1)-th block as block k in the rest of this paper.

Figure 4: Distribution of parent transaction counts

Figure 5: The percentage of transactions with one parent

Fig. 4 shows that parent transaction counts conform to a

power-law distribution, which means that transactions with
a few parents occur more often than transactions with many
parents. We are particularly interested in transactions with one
parent because a placement algorithm can easily make such
transactions single-shard. By analyzing block 0∼680k (mined
in April 2021 [19]), we found that one-parent transactions
account for a signiﬁcant proportion throughout the history of
Bitcoin and remain approximately 75% since block 420k as
shown in Fig. 5. The percentage changes a lot at heights lower
than 100k because blocks include only a few transactions at
the start of Bitcoin as shown by the blue bars in Fig 5.

B. Cost of Cross-shard Transactions

In this section, we compare the execution time of single-
shard transactions and cross-shard transactions by quantitative
measurements. An OmniLedger-like sharding protocol is im-
plemented based on Bitcoin Core [20], and 27k Bitcoin trans-
actions (from block 601000 to block 601009) are replayed in
a 2-shard environment. More details about the implementation
and the testbed will be given in Section V. For a single-
shard transaction, the client sends a TX request containing
the transaction directly to the output shard. For a cross-shard
transaction, the client sends a LOCK request to every input
shard and a COMMIT request to the output shard, provided
all input shards reply with positive locking results (see Fig.
3). The measurement results show that the median processing
time for a TX request, a LOCK request, and a COMMIT request
are 211 µs, 438 µs, and 259 µs, respectively.

To understand why LOCK and COMMIT requests take a
longer time to process than TX requests, we further measure
the processing time of each step in request execution. In an
UTXO-based blockchain, a node checks for three conditions
when verifying a transaction: 1) the input UTXOs exist and are
unspent, 2) the total input value is not less than the total output
value, and 3) the transaction includes the correct signatures
of the input UTXO owners. Provided the transaction meets

Cross-shard transaction txInput:UTXO1 (shard1)UTXO2 (shard2)Output:UTXO3 (shard3)ClientShard1Shard2Shard3LOCK <tx>LOCK <tx>ClientShard1Shard2Shard3LOCK-OK<sigs1>LOCK-OK<sigs2>ClientShard1Shard2Shard3COMMIT<sigs1, sigs2>UTXO1UTXO2UTXO3100101102103Parent transaction count101103105Frequency0100k200k300k400k500k600k700kBlock height020406080100Percentage of one-parenttransactions (%)012345678Transactions per 20k blocks1e7all three conditions, the node will execute it by removing
the input UTXOs and add the output UTXOs to the system
state. In Fig. 6b, the UTXO exist value label corresponds to
the ﬁrst two transaction veriﬁcation steps, the Sig label to
the third veriﬁcation step, and the Spend add label to the
system state update. Fig. 6b shows that checking signatures of
input UTXOs dominates the processing time of a single-shard
transaction. In Fig. 6c, the UTXO exist label corresponds to
the ﬁrst transaction veriﬁcation step. Note that LOCK request
processing does not include value checking because an input
shard is not aware of the value of input UTXOs in other
input shards. Thus, value checking is done by the output shard
during COMMIT request processing. Similarly, system state
update is separated into two parts: removing input UTXOs
in LOCK request processing, and adding the output UTXOs
in COMMIT request processing. Compared with TX request
processing, LOCK request processing includes two additional
steps: signing the lock result (labeled as Sign), and sending
the result to the client (labeled as Send). These two steps
are comparable in processing time to input UTXO signature
checking. Lastly, COMMIT request processing is dominated by
verifying the signatures of lock results, which are produced by
input shards. The step is labeled as Shard sig in Fig. 6d.

As a result, if a one-parent transaction becomes cross-shard
as a result of being placed to a different shard than its parent,
its processing time would be more than tripled due to input
shard authentication and communication overhead.

(a) TX, LOCK, and COMMIT

(b) Breakdown of TX

A. Overview of OptChain

We summarize the design principles of OptChain in this
section. The goal of OptChain is to reduce cross-shard trans-
actions while maintaining load balance. To reduce cross-
shard transactions, OptChain builds a transaction graph with
transactions as vertices and transaction dependencies as edges.
Therefore, from the perspective of graph theory, the transaction
placement problem is a streaming graph partitioning problem
[21]. OptChain associates each transaction with a ﬁtness-score
array of size ns, which is the number of shards in the system.
Each element in the array reﬂects the ﬁtness between the
transaction and the corresponding shard. Based on PageRank
[22], OptChain computes a child transaction’s ﬁtness-score
array as a weighted sum of its parents’ ﬁtness-score arrays.
For example, in Fig. 7, when a new transaction x arrives in a
two-shard system, OptChain calculates the ﬁtness score of the
ﬁrst shard as fx1 = wdfd1 + wefe1, since transaction d and e
are the two parents of x. The weight of the a parent is 1/nc,
where nc is the number of child transactions of this parent;
so, in the example, the weights of both parent transactions,
namely wd and we, equal one. The ﬁtness score of the second
shard fx2 is calculated the same way.

To account for load balance, OptChain divides a ﬁtness
score by the corresponding partition size (i.e., the number
of transactions placed to the shard), and calls the resultant
value the Transaction-to-Shard (T2S) score of the shard.
In addition, OptChain requires clients to frequently sample
servers for communication latency and server-side transaction
queue length in order to balance loads dynamically. We refer to
this design as feedback load balancing because it resembles the
idea of feedback control in control theory—use the measured
shard latency to adjust how many transactions should be placed
to the shard. The T2S score and feedback load balancing
jointly determine the output shard of a given transaction.

(c) Breakdown of LOCK

(d) Breakdown of COMMIT

Figure 6: Request processing time (2 shards)

Figure 7: Principle of OptChain. The ﬁtness-score array of x
is a weighted sum of the ﬁtness-score arrays of x’s parents.

IV. CASE STUDY: OPTCHAIN

OptChain is a client-side blockchain transaction placement
algorithm. A client runs the algorithm to compute the output
shard ID before sending its transaction to servers. OptChain
has been proven to have better performance than Metis, an
ofﬂine graph partitioning algorithm, and a greedy algorithm
that places transactions to the shard with most of its parents.

B. Partitioning Quality

We assess partitioning quality using two metrics: cross-
shard transaction ratio, and load imbalance, which is deﬁned
as the maximum partition size minus the minimum partition
size. To study whether OptChain can produce high-quality
partitions under various workloads, we employ four transac-
tion sets that are detailed in Table II to evaluate OptChain-
T2S, which is Optchain without feedback load balancing.

TXLOCKCOMMIT02004006008001000Time(us)UTXO_exist_valueSigSpend_add02004006008001000Time (s)UTXO_existSigSpendSignSend02004006008001000Time (s)Shard_sigUTXO_valueAdd02004006008001000Time (s)abced[ fa1, fa2 ]x[ fb1, fb2 ][ fc1, fc2 ][ fd1, fd2 ][ fe1, fe2 ][ fx1 = wd fd1 + we fe1,   fx2 = wd fd2 + we fe2 ]Table II: Four datasets

Block heights
Name
[0, 200k)
dataset 1
[200k, 227k)
dataset 2
[227k, 252k)
dataset 3
dataset 4
[252k, 275k)
aCoinbase trancations are excluded.

Transaction counta
7,316,308
7,371,053
7,316,337
7,238,332

OptChain-T2S is used instead of OptChain because the feed-
back load balancing feature demands running servers, whereas
OptChain-T2S is independent of server states, enabling us to
obtain the partitioning quality without running servers. This
independence is particularly convenient when evaluating the
partition quality under a large ns. Besides, OptChain-T2S
is the core of OptChain; therefore, understanding the perfor-
mance of OptChain-T2S is deﬁnitely helpful in understanding
the performance of OptChain. We will show the impact of
feedback load balancing in Section V. Placement results for
transactions prior to the start block height of a dataset are
generated using OptChain-T2S beforehand.

Fig. 8 and Fig. 9 compare the cross-shard transaction
ratio and load imbalance of OptChain-T2S and HP. For all
datasets, OptChain-T2S produces signiﬁcantly fewer cross-
shard transactions than HP. From Fig. 9, one can see that HP
does extremely well at load balancing. Although Optchain-
T2S does not evenly distribute transactions to shards,
the
load imbalance decreases as the number of shards increases.
However, in Fig. 9d, some shard still receives considerably
more transactions than others even with 128 shards. Con-
sidering the fact that OptChain-T2S produces noticeably less
cross-shard transactions for dataset 4 than for the other three
datasets as shown in Fig 8, we suspect that dataset 4 may have
some special traits that break Optchain-T2S’s load balancing
mechanism and cause the vast majority of transactions to be
placed to the same shard.

(a) dataset 1

(b) dataset 2

(a) dataset 1

(b) dataset 2

(c) dataset 3

(d) dataset 4

Figure 9: Load imbalance

shard loads in a 4-shard environment as illustrated in Fig. 10,
which implies that OptChain-T2S fails to balance loads since
block 253k. Unsurprisingly, HP balances loads remarkably
well in that every shard constantly receives about 25% of the
transactions. In Fig. 10a, the three small spikes between block
200k and 260k are the starting points of datasets 2∼4, and
the glitches at the beginning result from small block sizes.
Another observation is that, in Fig. 10b, all curves are quite
ﬂat in range of block [0, 50k) and block [125k, 175k), but
ﬂuctuate a lot in the range of [70k, 120k) and [180, 250k).
We ﬁnd that this pattern occurs with transactions spending
the output UTXOs of their immediate predecessors, which
are ordered right before them in the same block. OptChain-
T2S tends to place such transactions to the same shard as
their predecessors. As a result, a sequence of such transactions
causes a shard to receive more transactions than other shards
temporarily. For example, starting from the 326th transaction
in block 177253, each of the 267 subsequent transactions is
a child of its immediate predecessors [23]. Table III shows
that such transactions account for a relatively high percentage
whenever the shard load curves ﬂuctuate drastically.

Table III: Percentage of Transactions Consuming the UTXO
Produced by their Immediate Predecessors

Block height

[0, 50k)
[70k, 120k)
[125k, 175k)
[180k, 250k)
[253k, 275k)

Transactions depending on their
immediate predecessors
0.1%
18.6%
6.1%
21.3%
14.6%

(c) dataset 3

(d) dataset 4

Figure 8: Cross-shard transaction ratio

To conﬁrm the above hypothesis, we analyze the dynamic

To further understand why OptChain-T2S suddenly loses
its load balancing capability, we analyze transaction ﬁtness
scores and ﬁnd that some transactions have abnormally high
ﬁtness scores since block 251750 (see Fig. 11). These high
ﬁtness scores are created by transactions that “aggregate”
many previous transactions placed to the same shard. Fig. 12

416128Number of shards020406080Percentage of cross-shardtransactions (%)HPOptChain-T2S416128Number of shards0255075100Percentage of cross-shardtransactions (%)HPOptChain-T2S416128Number of shards0255075100Percentage of cross-shardtransactions (%)HPOptChain-T2S416128Number of shards0255075100Percentage of cross-shardtransactions (%)HPOptChain-T2S416128Number of shards104105106Load imbalance(# transactions)HPOptChain-T2S416128Number of shards104105106Load imbalance(# transactions)HPOptChain-T2S416128Number of shards103104105106Load imbalance(# transactions)HPOptChain-T2S416128Number of shards103104105106Load imbalance(# transactions)HPOptChain-T2S(a) HP

Figure 12: An example of an aggregating transaction

(a) x ampliﬁes ﬁtness scores.

(b) x dominates y’s placement result.

(b) OptChain-T2S

Figure 10: Dynamic shard loads (4 shards)

Figure 13: Tainted transactions and aggregating transactions

illustrates a simpliﬁed scenario of such, where transaction x
has 10 parents whose ﬁtness-score array are all [0, 1] (i.e., the
system has two shards, and the second shard has the higher
ﬁtness score for all the parents). x’s ﬁtness-score array can
be computed as [0, 10] by following the rules described in
Section IV-A. Note that the second element of x’s ﬁtness-
score array is 10 times higher than that of its parents. In Fig.
12b, transaction y is a child transaction of x, and its ﬁtness-
score array is [3, 10]. Provided the two shards have the same
load, y will be placed to the second shard even though three
out of four of its parents are in the ﬁrst shard. Moreover, y
gets “tainted” by x (i.e., y inherits the high ﬁtness score of
the second shard from x) and will propagate the high ﬁtness
score to its children. Between block 251750 and block 251840,
many transactions aggregate recently tainted transactions (Fig.
13) and collectively amplify the ﬁtness score by 50 orders of
magnitude. In other words, aggregating transactions amplify
ﬁtness scores, and the resultant high ﬁtness scores propagate
to other transactions through dependencies. By comparing Fig.
13 with Fig. 11, one can see that 1) whenever there are tainted
transactions, the ﬁtness score in Fig. 11 is at a high level,
and 2) whenever there are transactions that aggregate recently
tainted transactions, the ﬁtness score grows.

Figure 11: Variation in OptChain ﬁtness score

OptChain-T2s’s failure to handle dataset 4 proves that
PageRank is not completely suitable for the transaction place-

ment problem. PageRank is originally designed by Google to
identify important websites. A website referenced by a lot of
other websites is deemed important. However, this notion does
not apply to the transaction graph. A transaction with many
parent transactions should not be important and dominates the
placement result of its child transactions. Besides, in PageR-
ank, a website is also deemed important if it is referenced by
an important website. When mapped from a website graph
to a transaction graph, this rule becomes “a transaction is
important if one of its parent transactions is important”. Based
on this rule, a transaction inherits high ﬁtness scores from its
aggregating parents and heavily “attract”s its descendants to
its shard.

Figure 14: Dynamic shard loads of OptNorm (4 shards)

Knowing the shortcoming of OptChain-T2S, we propose a
quick ﬁx—OptNorm, which normalizes ﬁtness scores. Specif-
ically, given a transaction, OptNorm computes the ﬁtness
score array and selects the output shard in the same way as
OptChain-T2S does. Next, however, OptNorm normalizes the
ﬁtness-score array, i.e., dividing each element by the sum of
all elements. The normalization guarantees future transactions
will have parent transactions of equal importance since every
parent transaction’s ﬁtness score array has an element-wise
sum of one. Fig. 14 illustrates that OptNorm balance loads
better than OptChain-T2S and can survive aggregating trans-
actions.

050000100000150000200000250000Block height020406080100Load (% txnsper 1000 blocks)Shard0Shard1Shard2Shard3050000100000150000200000250000Block height020406080100Load (% txnsper 1000 blocks)Shard0Shard1Shard2Shard3240000245000250000255000260000265000270000275000Block height1016103510541073Max OptChain fitness score per 100 blockstx0x[0, 1][fx1 = 0,  fx2 = 10]tx2[0, 1]...tx9[0, 1]...xtx20tx21[0, 10]tx22[1, 0][1, 0][1, 0]y[fy1 = 3,  fy2 = 10]240000245000250000255000260000265000270000275000Block height0255075100Tainted txns(% txns per 100 blocks)−2000200400600Txns aggregatingrecently tainted txns% of tainted txnAggregating txn count050000100000150000200000250000Block height020406080100Load (% txnsper 1000 blocks)Shard0Shard1Shard2Shard3V. EVALUATION

We implemented OptChain as well as an OmniLedger-like
sharding protocol based on Bitcoin Core [20]. We made the
same change to the OmniLedger protocol as the OptChain
paper does to overcome the bandwidth limit—clients send
transactions directly to the input and output shards instead
of gossiping the transaction. Experiments are done on a local
cluster. 64 VMs (each with 2 CPUs and 12GB memory) are
created on 16 machines, each of which has dual Xeon E5-
2620 at 2.1 GHz (12 cores) and 64GB RAM. Each VM runs
an instance of our modiﬁed Bitcoin Core and is used as a
blockchain node. One client runs on another machine with
dual Xeon E5-2630 at 2.6 GHz (12 cores, 2 hyperthreads per
core) and 256GB RAM. The client reads historical transactions
in Bitcoin block [250k, 260k) with 2.9 million transactions
in total, and sends them to the peers at a rate of 4.5k tps.
Transactions in this range are used in order to evaluate the
impact of aggregating transactions on system performance. A
latency of 100 ms is imposed on every link between peers, and
the bandwidth is limited to 500 Mbps. We use this relatively
high bandwidth because we notice that OptChain-T2S places
most transactions in one shard, and low network bandwidth
will be a bottleneck for that shard.

Fig. 15a demonstrates that feedback load balancing miti-
gates the performance degradation of OptChain-T2S but can-
not eliminate the degradation. By comparing Fig. 15c and 15d,
one can see that, although the load of the largest partition
under OptChain is lower than that under OptChain-T2S, it
still surges at around 200s, exactly when the throughput starts
to drop. In contrast, OptNorm distributes load fairly evenly
it can effectively overcome
at 200s, which conﬁrms that
the aggregating transaction issue of OptChain. The overall
throughput of HP and OptNorm are 865 tps and 3487 tps,
respectively, which means OptNorm improves the system
performance by 4x.

The authors of OptChain noticed our research and created a
new version of the OptChain paper to update their algorithm
description (referred to as OptChainV2) [24]. Speciﬁcally,
OptChainV2 allows multiple edges between two vertices in
the transaction graph, and changes the deﬁnition of Nin
(Nout) from a set of input (output) transactions to a multiset
of input (output) transactions. For completeness, this paper
also evaluates the performance of OptChainV2 using Bitcoin
block [250, 260) and compares the result with OptNorm
and OptChain. To measure latency, all transactions must be
completed within a reasonable amount of time, so we reduce
link delay to 10ms and warm up database cache before each
test. This testing environment modiﬁcation equally beneﬁts all
placement algorithms. Fig. 16 shows, when the client sends
transactions at a rate of 3.5k tps, both OptChainV2 and Opt-
Norm can achieve a 3.5k-tps throughput, whereas OptChain
can reach only 2.2k tps. Also, the 50th percentile latency of
OptChainV2 and OptNorm are almost the same, both 99.9%
shorter than the 50th percentile latency of OptChain. On the
other hand, when the system is overloaded with a 5k-tps
transaction rate, OptChainV2 achieves 4% higher throughput
than OptNorm.

(a) Throughput

(b) Latency (3.5k-tps transaction rate)

Figure 16: Performance comparison (16 shards)

VI. CONCLUSION

In conclusion, cross-shard transactions are expensive due
to input shard authentication and communication overhead.
Placement algorithms considering transaction dependencies
can signiﬁcantly reduce cross-shard transaction ratio and thus
boost system performance. The original OptChain does not
balance loads well under workloads that include many ag-
gregating transactions and their descendants. The proposed
OptNorm is a simple yet effective ﬁx. OptChainV2 does not
exhibit the shortcoming.

(a) Throughput

(b) OptNorm

REFERENCES

(c) OptChain-T2S

(d) OptChain

Figure 15: Throughput and loads comparisons (16 shards)

[1] K. Croman, C. Decker, I. Eyal et al., “On scaling decentralized
blockchains,” in International conference on ﬁnancial cryptography and
data security. Springer, 2016, pp. 106–125.

[2] Y. Lewenberg, Y. Sompolinsky, and A. Zohar, “Inclusive block chain
protocols,” in International Conference on Financial Cryptography and
Data Security. Springer, 2015, pp. 528–547.

[3] C. Li, P. Li, D. Zhou, W. Xu, F. Long, and A. Yao, “Scaling nakamoto
consensus to thousands of transactions per second,” arXiv preprint
arXiv:1805.03870, 2018.

[4] I. Eyal, A. E. Gencer, E. G. Sirer, and R. Van Renesse, “Bitcoin-ng:
A scalable blockchain protocol,” in 13th {USENIX} Symposium on
Networked Systems Design and Implementation ({NSDI} 16), 2016, pp.
45–59.

0200400600Time (s)0100000200000300000Txns per 50 secondsHPOptNormOptChain-T2SOptChain0200400600Time (s)0200004000060000Load (txns per 10s)Largest partitionSmallest partition0200400600Time (s)0200004000060000Load (txns per 10s)Largest partitionSmallest partition0200400600Time (s)0200004000060000Load (txns per 10s)Largest partitionSmallest partition3000400050006000Transaction rate (tps)010002000300040005000Throughput (tps)OptChainOptChainV2OptNorm102100102Latency (s)020406080100Cumulativepercentage (%)OptChainOptChainV2OptNorm[5] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena,
“A secure sharding protocol for open blockchains,” in Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 2016, pp. 17–30.

[6] E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly, E. Syta, and
B. Ford, “Omniledger: A secure, scale-out, decentralized ledger via
sharding,” in 2018 IEEE Symposium on Security and Privacy (SP).
IEEE, 2018, pp. 583–598.

[7] M. Zamani, M. Movahedi, and M. Raykova, “Rapidchain: Scaling
blockchain via full sharding,” in Proceedings of the 2018 ACM SIGSAC
Conference on Computer and Communications Security, 2018, pp. 931–
948.

[8] H. Dang, T. T. A. Dinh, D. Loghin, E.-C. Chang, Q. Lin, and B. C. Ooi,
“Towards scaling blockchain systems via sharding,” in Proceedings of
the 2019 International Conference on Management of Data, 2019, pp.
123–140.

[9] C. Decker and R. Wattenhofer, “A fast and scalable payment network
with bitcoin duplex micropayment channels,” in Symposium on Self-
Stabilizing Systems. Springer, 2015, pp. 3–18.

[10] J. Poon and T. Dryja, “The bitcoin lightning network: Scalable off-chain

instant payments,” 2016.

[11] D. R. Stinson, Cryptography: theory and practice.

Chapman and

Hall/CRC, 2005.

[14] B. Lampson and H. E. Sturgis, “Crash recovery in a distributed data

storage system,” 1979.

[15] J. N. Gray, “Notes on data base operating systems,” in Operating

Systems. Springer, 1978, pp. 393–481.

[16] R. Guerraoui and J. Wang, “How fast can a distributed transaction
commit?” in Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI
Symposium on Principles of Database Systems, 2017, pp. 107–122.
[17] D. Skeen, “Nonblocking commit protocols,” in Proceedings of the 1981
ACM SIGMOD international conference on Management of data, 1981,
pp. 133–142.

[18] L. Ren, K. Nayak, I. Abraham, and S. Devadas, “Practical synchronous

byzantine consensus,” arXiv preprint arXiv:1704.02397, 2017.

[19] Blockchain.com, “Bitcoin Explorer,” https://www.blockchain.com/btc/

block/680000, accessed: 2021-09-09.

[20] B. C. Developers. Bitcoin core integration/staging tree. Last accessed
15 Jun 2020. [Online]. Available: https://github.com/bitcoin/bitcoin
[21] I. Stanton and G. Kliot, “Streaming graph partitioning for large dis-
tributed graphs,” in Proceedings of the 18th ACM SIGKDD international
conference on Knowledge discovery and data mining, 2012, pp. 1222–
1230.

[22] L. Page, S. Brin, R. Motwani, and T. Winograd, “The pagerank citation
ranking: Bringing order to the web.” Stanford InfoLab, Tech. Rep., 1999.
[23] Blockchain.com, “Bitcoin Explorer,” https://www.blockchain.com/btc/

[12] L. N. Nguyen, T. D. Nguyen, T. N. Dinh, and M. T. Thai, “Optchain:
optimal transactions placement for scalable blockchain sharding,” in
2019 IEEE 39th International Conference on Distributed Computing
Systems (ICDCS).

IEEE, 2019, pp. 525–535.
[13] M. Castro, B. Liskov et al., “Practical byzantine fault tolerance,” in

tx/91c40e195524962aa3e6cd588e2038b392368382d0815aba7034f51c3ce2579b,
accessed: 2021-09-08.

[24] L. N. Nguyen, T. D. Nguyen, T. N. Dinh, and M. T. Thai, “Optchain:
optimal transactions placement for scalable blockchain sharding,” arXiv
preprint arXiv:2007.08596v2, 2021.

OSDI, vol. 99, 1999, pp. 173–186.

