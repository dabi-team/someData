1
2
0
2

l
u
J

9

]
T
G
.
s
c
[

1
v
3
9
3
4
0
.
7
0
1
2
:
v
i
X
r
a

Game theory on the blockchain: a model for
games with smart contracts

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

Department of Computer Science, Aarhus University

Abstract. We propose a model for games in which the players have
shared access to a blockchain that allows them to deploy smart con-
tracts to act on their behalf. This changes fundamental game-theoretic
assumptions about rationality since a contract can commit a player to
act irrationally in speciﬁc subgames, making credible otherwise non-
credible threats. This is further complicated by considering the inter-
action between multiple contracts which can reason about each other.
This changes the nature of the game in a nontrivial way as choosing
which contract to play can itself be considered a move in the game.
Our model generalizes known notions of equilibria, with a single con-
tract being equivalent to a Stackelberg equilibrium, and two contracts
being equivalent to a reverse Stackelberg equilibrium. We prove a num-
ber of bounds on the complexity of computing SPE in such games with
smart contracts. We show that computing an SPE is PSPACE-hard in
the general case. Speciﬁcally, in games with k contracts, we show that
computing an SPE is ΣP
k -hard for games of imperfect information. We
show that computing an SPE remains PSPACE-hard in games of perfect
information if we allow for an unbounded number of contracts. We give
an algorithm for computing an SPE in two-contract games of perfect
information that runs in time O(mℓ) where m is the size of the game
tree and ℓ is the number of terminal nodes. Finally, we conjecture the
problem to be NP-complete for three contracts.

1

Introduction

This paper is motivated by the games that arise on permissionless blockchains
such as Ethereum [22] that oﬀer “smart contract” functionality: in these permis-
sionless systems, parties can deploy smart contracts without prior authorization
by buying the “tokens” required to execute the contract. By smart contracts, we
mean arbitrary pieces of code written in a Turing-complete language1 capable of
maintaining state (including funds) and interact with other smart contracts by
invoking methods on them. Essentially, smart contracts are objects in the Java
sense. Parties can also invoke methods on the smart contracts manually. Note
that the state of all smart contracts is public and can be inspected by any party
at any time. This changes fundamental game-theoretic assumptions about ratio-
nality: in particular, it might be rational for a player to deploy a contract that

1 However the running time of the contracts is limited by the execution environment.

 
 
 
 
 
 
2

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

commits them to act irrationally in certain situations to make credible otherwise
non-credible threats. This gives rise to very complex games in which parties can
commit to strategies, that in turn depend upon other players’ committed strate-
gies. Reasoning about such equilibria is important when considering games that
are meant to be played on a blockchain, since the players - at least in princi-
ple - always have the option of deploying such contracts. In the literature, this
is known as a Stackelberg equilibrium where a designated leader commits to a
strategy before playing the game. In general, because of ﬁrst-mover advantage,
being able to deploy a contract ﬁrst is never a disadvantage, since a player can
choose to deploy the empty contract that commits them to nothing. It is well-
known that it is hard to compute the Stackelberg equilibrium in the general
case [12], though much less is known about the complexity when there are sev-
eral of these contracts in play: when there are two contracts, the ﬁrst contract
can depend on the second contract in what is known as a reverse Stackelberg
equilibrium [2,21,9]. This is again strictly advantageous for the leader since they
can punish the follower for choosing the wrong strategy. In this paper, we present
a model that generalizes (reverse) Stackelberg games, that we believe captures
these types of games and which may be of wider interest. In practical terms,
we believe that our model is of interest when analyzing distributed systems for
”game-theoretic security” in settings where the players naturally have the ability
to deploy smart contracts. Potential examples include proof-of-stake blockchains
themselves and ﬁnancial applications that build upon these systems.

Contracts Players Information

Strategies

0

0

1

1

1

2

3

k

2

2

2

2

2

2

3

perfect

imperfect

perfect

perfect

imperfect

perfect

perfect

2 + k

imperfect

unbounded

-

perfect

pure

mixed

pure

mixed

-

pure

pure

pure

pure

Lower bound
P-hard [20]

Upper bound

O(m) [16]

PPAD-complete [7,6]

P-hard [20]

O(mℓ) [4]

NP-complete [13]
NP-complete [13]

P-hard [20]
Conjectured NP-hard
Σp

k-hard [Theorem 2]
PSPACE-hard [Theorem 4]

O(mℓ) [Theorem 3]
NP [Theorem 3]

?

?

Fig. 1. An overview of some existing bounds on the complexity of computing an SPE
in extensive-form games and where our results ﬁt in. Here, m is the size of the tree,
and ℓ is the number of terminal nodes.

Our results We propose a game-theoretic model for games in which players
have shared access to a blockchain that allows the players to deploy smart con-
tracts to act on their behalf in the games. Allowing a player to deploy a smart

Game theory on the blockchain: a model for games with smart contracts

3

contract corresponds to that player making a ‘cut’ in the tree, inducing a new ex-
panded game of exponential size containing as subgames all possible cuts in the
game. We show that many settings from the literature on Stackelberg games can
be recovered as special cases of our model, with one contract being equivalent to
a Stackelberg equilibrium, and two contracts being equivalent to a reverse Stack-
elberg equilibrium. We prove bounds on the complexity of computing an SPE in
these expanded trees. We prove a lower bound, showing that computing an SPE
in games of imperfect information with k contracts is ΣP
k -hard by reduction from
the true quantiﬁed Boolean formula problem. For k = 1, it is easy to see that a
contract can be veriﬁed in linear time, establishing NP-completeness. In general,
we conjecture ΣP
k -completeness for games with k contracts, though this turns
out to reduce to whether or not contracts can be described in polynomial space.
For games of perfect information with an unbounded number of contracts, we
also establish PSPACE-hardness from a generalization of 3-coloring. We show
an upper bound for k = 2 and perfect information, namely that computing an
SPE in a two-contract game of size m with ℓ terminal nodes (and any number of
players) can be computed in time O(mℓ). For k = 3, the problem is clearly in NP
since we can verify a witness using the algorithm for k = 2, and we conjecture
the problem to be NP-complete. Finally, we discuss various extensions to the
model proposed and leave a number of open questions.

2 Games with smart contracts

In this section, we give our model of games with smart contracts. We mostly
assume familiarity with game theory and refer to [16] for more details. For sim-
plicity of exposition, we only consider a somewhat restricted class of games,
namely ﬁnite games in extensive form, and consider only pure strategies in these
games. In addition, we will assume games are in generic form, meaning the util-
ities of all players are unique. This has the eﬀect that the resulting subgame
perfect equilibrium is unique. Equivalently, we use a tie breaking algorithm to
decide among the diﬀerent subgame perfect equilibria, and slightly perturb the
utilities of the players to match the subgame perfect equilibrium chosen by the
tie breaker.

Formally, an extensive-form game G is a ﬁnite tree T . We denote by L ⊆ T
the set of leaves in T , i.e. nodes with no children, and let m denote the number
of nodes in T . Each leaf ℓ is labeled by a vector u(ℓ) ∈ Rn that denotes the
utility ui(ℓ) obtained by party Pi when terminating in the leaf ℓ. In addition,
the game consists of a ﬁnite set of n players. We consider a ﬁxed partition of
the non-leaves into n sets, one for each player. The game is played by starting
at the root, letting the player who owns that node choose a child to recurse
into, this is called a move. We proceed in this fashion until we reach a leaf and
distribute its utility vector to the players. When there is perfect information,
a player always knows exactly which subgame they are playing, though more
generally we may consider a partition of the non-leafs into information sets,
where each player is only told the information set to which their node belongs.

4

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

When all information sets are singletons we say the game has perfect information.
The players are assumed to be rational, that is they choose moves to maximize
their utility: we say a strategy for each player (a strategy proﬁle) constitutes
a (Nash) equilibrium if no unilateral deviation by any party results in higher
utility for that party. Knowing the other players are rational, for games of perfect
information, at each branch a player can anticipate their utility from each of its
moves by recursively determining the moves of the other parties. This process is
called backward induction, and the resulting strategy proﬁle is a subgame perfect
equilibrium. A strategy proﬁle is an SPE if it is an equilibrium for every subgame
of the game. For games of perfect information, computing the SPE takes linear
time in the size of the tree and can be shown to be P-complete [20]. Later, we
will show a lower bound, namely that adding a contract to the tree moves this
computation up (at least) a level in the polynomial hierarchy. Speciﬁcally, we
show that computing the SPE in k-contract games is ΣP
k -hard in the general
case with imperfect information.

2.1 Smart contract moves

We now give our deﬁnition of smart contracts in the context of ﬁnite games. We
add a new type of node to our model of games, a smart contract move. Intuitively,
whenever a player has a smart contract move, they can deploy a contract that
acts on their behalf for the rest of the game. The set of all such contracts is
countably inﬁnite, but fortunately, we can simplify the problem by considering
equivalence classes of contracts which “do the same thing”. Essentially, the only
information relevant to other players is whether or not a given action is still
possible to play: it is only if the contract dictates that a certain action cannot
be played, that we can assume a rational player will not play it. In particular,
any contract which does not restrict the moves of a player is equivalent to the
player not having a contract. Such a restriction is called a cut. A cut c(i) for
player Pi is deﬁned to be a union of subtrees whose roots are childen of Pi-
nodes, such that: (1) every node in T \ c(i) has a path going to a leaf; a cut is
not allowed to destroy the game by removing all moves for a player, and (2) c(i)
respects information sets, that is it ‘cuts the same’ from each node in the same
information set.

In other words, deploying a smart contract corresponds to choosing a cut in
the game tree. This means that a smart contract node for player Pi in a game
T is essentially syntactic sugar for the expanded tree that results by applying
the set of all cuts c(i) to T and connecting the resulting games with a new node
belonging to Pi at the top. Computing the corresponding equilibrium with smart
contracts then corresponds to the SPE in this expanded tree. Note that this tree
is uniquely determined. See Fig. 2 for an example. We use the square symbol in
ﬁgures to denote smart contract moves. When a game contains multiple smart
contract moves, we expand the smart contract nodes recursively in a depth-ﬁrst
manner using the transformation described above.

Game theory on the blockchain: a model for games with smart contracts

5

P1

P2

=

P2

P1

P2

P2

P1

(1, −1)

P1

(1, −1)

P1

(1, −1)

P1

(1, −1)

(−∞, −∞)

(0, 0)

(−∞, −∞)

(0, 0)

(0, 0)

(−∞, −∞)

Fig. 2. Expanding a smart contract node for a simple game. The square symbol is a
smart contract move for player P1. We compute all P1-cuts in the game and connect
them with a node belonging to P1. The ﬁrst coordinate is the leader payoﬀ, and the
second is the follower payoﬀ. The dominating paths are shown in bold. We see that the
optimal strategy for P1 is to commit to choosing (−∞, −∞) unless P2 chooses (1, −1).

2.2 Contracts as Stackelberg equilibria

As mentioned earlier, the idea to let a party commit to a strategy before playing
the game is not a new one: in 1934, von Stackelberg proposed a model for
the interaction of two business ﬁrms with a designated market leader [18]. The
market leader holds a dominant position and is therefore allowed to commit to
a strategy ﬁrst, which is revealed to the follower who subsequently decides a
strategy. The resulting equilibrium is called a Stackelberg equilibrium. In this
section we show that the Stackelberg equilibrium for a game with leader P1 and
follower P2 can be recovered as a special case of our model where P1 has a smart
contract. We use the deﬁnition of strong Stackelberg equilibria from [11,5]. We
note that since the games are assumed to be in generic form, the follower always
has a unique response, thus making the requirement that the follower break ties
in favor of the leader unnecessary.

Let T be a game tree. A path p ⊆ T is a sequence of nodes such that for each
j, pj+1 is a child of pj. If p is a path, we denote by p(i) ⊆ p the subset of nodes
owned by player Pi. Now suppose T has a horizon of h. We let p = (pj)h
j=1 ⊆ T
denote the dominating path of the game deﬁned as the path going from the root
p1 to the terminating leaf ph in the SPE of the game.

Deﬁnition 1. Let i ∈ [n] be the index of a player, and let f (si) be the best
response to si for players other than Pi. We say (s∗
i )) is a Stackelberg
equilibrium with leader Pi if the following properties hold true:
i , f (s∗
– Leader optimality. For every leader strategy si, ui(s∗
– Follower best response. For every j 6= i, and every s−i, uj(s∗

i , f (s∗

i )) ≥ ui(si, f (si)).
i , f (s∗
i )) ≥
⋄

uj(s∗

i , s−i).

Proposition 1. The Stackelberg equilibrium with leader Pi is equivalent to Pi
having a smart contract move.

Proof. We show each implication separately:

6

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

⇒ SPE in the expanded tree T induces a Stackelberg equilibrium in the corre-
sponding Stackelberg game where Pi commits to all moves in p(i). It is not
hard to see that the follower best response f (s∗
i ) is deﬁned by the SPE of
the subgame arising after Pi makes the move p1 choosing the contract in T .
⇐ A Stackelberg equilibrium induces a SPE in the expanded tree T with the
i )) be a Stackelberg equilibrium, observe that s∗
same utility: let (s∗
i
corresponds to a cut c(i) ⊆ T where Pi cuts away all nodes in T not
dictated by s∗
i . By letting the ﬁrst move p1 of Pi correspond to c(i), the
best follower response f (s∗
i ) is the SPE in the resulting subgame, and hence
i , f (s∗
u(p) = u(s∗
⊓⊔

i , f (s∗

i )).

Multi-leader/multi-follower contracts Several variants of the basic Stack-
elberg game has been considered in the literature with multiple leaders and/or
followers [17,14]. We can model this using smart contracts by forcing some of
the contracts to independent of each other: formally, we say a contract is in-
dependent if it makes the same cut in all subgames corresponding to diﬀerent
contracts. It is not hard to see that multiple leaders can be modelled by adding
contracts for each leader, where the contracts are forced to be independent. ⋄

Reverse Stackelberg contracts The reverse Stackelberg equilibrium is an
attempt to generalize the regular Stackelberg equilibrium: here, the leader does
not commit to a speciﬁc strategy a priori, rather they provide the follower with
a mapping f from follower actions to best response leader actions, see e.g. [19,1]
for a deﬁnition in the continuous setting. When the follower plays a strategy
s−i, the leader plays f (s−i). This is strictly advantageous for the leader since as
pointed out in [9], they can punish the follower for choosing the wrong strategy.
In the following, if p is a path of length ℓ, we denote by Gs(p) the subgame

whose root is pℓ.

Deﬁnition 2. Let i be the index of the leader, and −i the index of the follower.
We say (f (s∗
−i) is a reverse Stackelberg equilibrium with leader i if the
following holds for every leader strategy si and follower strategy s−i, it holds:

−i), s∗

– Leader best response: ui(f (s∗
– Follower optimality: u−i(f (s∗

−i), s∗
−i), s∗

−i) ≥ ui(si, s∗
−i) ≥ u−i(f (s−i), s−i).

−i).

⋄

Proposition 2. The reverse Stackelberg equilibrium for a two-player game with
leader Pi is equivalent to adding two smart contract moves to the game, one for
Pi, and another for P−i (in that order).

Proof. We show each implication separately:

⇒ The SPE in the expanded tree induces a reverse Stackelberg equilibrium: for
every possible follower strategy s−i, we deﬁne f (s−i) as the leader strategy in
the SPE in the subgame Gs(hp1, s−ii) after the two moves, where we slightly
abuse notation to let s−i mean that P−i chooses a cut where their SPE is

Game theory on the blockchain: a model for games with smart contracts

7

s−i. Leader best response follows from the observation that p1 corresponds
to the optimal set of cuts of Pi moves in response to every possible cut of of
P−i moves.

−i), s∗

⇐ A reverse Stackelberg equilibrium induces an SPE in the expanded tree: let
(f (s∗
−i) be a reverse Stackelberg equilibrium and let f be the strategy
of Pi in the reverse Stackelberg game, then Pi has a strategy in the two-
contract game with the same utility for both players: namely, Pi’s ﬁrst move
is choosing the subgame in which for every second move s−i by P−i they
make the cut f (s−i).
⊓⊔

3 Computational complexity

Having deﬁned our model of games with smart contracts, in this section we study
the computational complexity of computing equilibria in such games. Note that
we can always compute the equilibrium by constructing the expanded tree and
performing backward induction in linear time. The problem is that the expanded
tree is very large: the expanded tree for a game of size m with a single contract
has 2O(m) nodes since it contains all possible cuts. For every contract we add, the
complexity grows exponentially. This establishes the rather crude upper bound
of ΣEXP
for computing SPE in games with perfect information and k contracts.
k
The question we ask if we can do better than traversing the entire expanded
tree.

In terms of feasibility, our results are mostly negative: we show a lower bound
that computing an SPE, in general, is infeasible for games with smart contracts.
We start by considering the case of imperfect information where information
sets allow for a rather straightforward reduction from CircuitSAT to games with
one contract, showing NP-completeness for single-contract games of imperfect
information. This generalizes naturally to the k true quantiﬁed Boolean formula
problem (k-TQBF), establishing ΣP
k -hardness for games of imperfect information
with k contracts. On the positive side, we consider games of perfect information
where we provide an algorithm for games and two contracts that runs in time
O(mℓ). However, when we allow for an unbounded number of contracts, we show
the problem remains PSPACE-complete by reduction from the generalization of
3-coloring described in [3]. We conjecture the problem to be NP-complete for
three contracts.

3.1 Games with imperfect information, NP-completeness

We start by showing NP-completeness for games of imperfect information by re-
duction from CircuitSAT. We consider a decision problem version of SPE: namely,
whether or not a designated player can obtain a utility greater than the target
value.

Reduction. Let C be an instance of CircuitSAT. Note that we can start from
any complete basis of Boolean functions, so it suﬃces to suppose the circuit

8

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

C consists only of NAND with fanin 2 and fanout 1. We will now construct a
game tree for the circuit: we will be using one player to model the assignment of
variables, say player 1. The game starts with a contract move for player 1 who
can assign values to variables by cutting the bottom of the tree: we construct
the game such that player 1 only has moves in the bottom level of the tree.
In this way, we ensure that every cut corresponds to assigning truth values to
the variables. We adopt the convention that a payoﬀ of 1 for player 1 is true
(⊤), while a payoﬀ of 0 for player 1 is false (⊥). All nodes corresponding to
occurrences of the same variable get grouped into the same information set,
which enforces the property that all occurrences of the same variable must be
assigned the same value.

1

· · ·

· · ·

1

1

1

1

⊤

⊥

⊤

⊥

⊤

⊥

⊤

⊥

...

3

2

′

⊥

′

⊤

T R

T L

Fig. 3. The basic structure of the reduction. Player 1 has a smart contract that can
be used to assign values to the variables. The dashed rectangle denotes an information
set and is used when there are multiple occurrences of a variable in the circuit. On
the right, we see the NAND-gate gadget connecting the left subgame T L and the right
subgame T R. We implement the gadget by instantiating the utility vectors such that
player 2 chooses ⊥′ if only if both T L and T R propagate a utility vector encoding true.

For the NAND-gate, we proceed using induction: let T L, T R be the trees
obtained by induction, we now wish to construct a game tree gadget with NAND-
gate logic. To do this we require two players which we call player 2 and player 3.
Essentially, player 2 does the logic, and player 3 converts the signal to the right
format. The game tree will contain multiple diﬀerent utility vectors encoding
true and false, which vary their utilities for players 2 and 3. Each NAND-gate
has a left tree and a right tree, each with their own utilities for true and false:
⊥L, ⊥R; ⊤L, ⊤R. The gadget starts with a move for player 3 who can choose to
continue the game, or end the game with a true value ⊤′. If they continue the
game, player 2 has a choice between false ⊥′ or playing either T L or T R. To
make the gadget work like a NAND-gate we need to instantiate the utilities to
make backward induction simulate its logic. The idea is to make player 2 prefer
both ⊥L and ⊥R to ⊥′, which they, in turn, prefer to ⊤L and ⊤R. As a result,

Game theory on the blockchain: a model for games with smart contracts

9

player 2 propagates ⊥′ only if both T L, T R are true, otherwise, it propagates
⊥L or ⊥R. Finally, we must have that player 3 prefers ⊤′ to both ⊥L and ⊥R,
while they prefer ⊥′ to ⊤′, ⊤L and ⊤R. This gives rise to a series of inequalities:

2 > ⊥′
⊥L
2 > ⊥′
⊥R

2 > ⊤L
2
2 > ⊤R
2

⊤′
⊤′

3 > ⊥L
3
3 > ⊥R
3

⊥′
⊥′

3 > ⊤L
3
3 > ⊤R
3

⊥′

3 > ⊤′

3

We can instantiate this by deﬁning ⊤, ⊥. For the base case corresponding to a
leaf, we let ⊥ = (0, 1, 0), ⊤ = (1, 0, 0). We then deﬁne recursively:

1, 0, 1 + max(⊤L
(cid:0)
2 , ⊥R
min(⊥L

3 , ⊤R
3 )
(cid:1)
2 ) + max(⊤L

2 , ⊤R
2 )

⊤′ =

⊥′ =

0,

(cid:18)

2

, 2 + max

3 , ⊤R
3

⊤L
(cid:0)

(cid:19)
(cid:1)

It is not hard to verify that these deﬁnitions make the above inequalities hold
true. As a result, the gadget will propagate a utility vector corresponding to true
if and only if not both subtrees propagate true.

Theorem 1. Computing an SPE in three-player single-contract games of im-
perfect information is NP-complete.

Proof. We consider the decision problem of determining whether or not in the
SPE, player 1 has a utility of 1. By construction of the information sets, any
strategy is a consistent assignment of the variables. It now follows that player
1 can get a payoﬀ > 0 if and only if there is an assignment of the variables
such that the output of the circuit is true. This shows NP-hardness. Now, it is
easily seen that this problem is in NP, since a witness is simply a cut that can
be veriﬁed in linear time in the size of the tree. Completeness now follows using
our reduction from CircuitSAT.
⊓⊔

Remark 1. Our reduction also applies to the two-player non-contract case by
a reduction from circuit value problem. This can be done in logspace since all
the gadgets are local replacements. In doing so, we reestablish the result of [20],
showing that computing an SPE on two-player games is P-complete.
⋄

3.2 Games with imperfect information, PSPACE-hardness

In this section, we show that computing the SPE in a game with k contract moves
is ΣP
k -complete, in the general case with imperfect information. Generalizing the
previous result of NP-hardness to k contracts is fairly straightforward. Our claim
is that the resulting decision problem is ΣP
k -hard so we obtain a series of hardness
results for the polynomial hierarchy. This is similar to the results obtained in
[10] where the value problem for a competitive analysis with k + 1 players is
shown to be hard for ΣP
k .

Formally, we consider the following decision problem with target value V for
a game tree T with k contract players: let T ′ be the expanded tree with contracts

10

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

for players P1, P2, . . . Pk in ascending order. Can player P1 make a cut in T ′ such
that their payoﬀ is ≥ V ?

To show our claim, we proceed using reduction from the canonical ΣP
k -

complete problem k-TQBF, see e.g. [8] for a formal deﬁnition.

Theorem 2. Computing an SPE in 2+k player games of imperfect information
is ΣP

k -hard.

Proof (sketch). We extend our reduction from Theorem 1 naturally to the quan-
tiﬁed satisﬁability problem. In our previous reduction, the contract player wanted
to satisfy the circuit by cutting as to assign values to the variables in the formula.
Now, for each quantiﬁer in ψ, we add a new player with a contract, whose moves
range over exactly the variables quantiﬁed over. The players have contracts in the
same order speciﬁed by their quantiﬁers. The idea is that players corresponding
to ∀ try to sabotage the satisﬁability of the circuit, while those corresponding
to ∃ try to ensure satisﬁability. We encode this in the utility vectors by giving
∃-players a utility of 1 in ⊤ and 0 utility in ⊥, while for the ∀-players, it is the
opposite. It is not hard to see that ψ is true, only if P1 can make a cut, such
that for every cut P2 makes, there exists a cut for P3 such that, ..., the utility
of P1 is 1. This establishes our reduction.
⊓⊔

Remark 2. We remark that it is not obvious whether or not the corresponding
decision problem is contained within ΣP
k . It is not hard to see we can write
a Boolean formula equivalent to the smart contract game in a similar manner
as with a single contract. The problem is that it is unclear if the innermost
predicate φ can be computed in polynomial-time. It is not hard to see that some
smart contracts do not have a polynomial description, i.e. we can encode a string
x ∈ {0, 1}∗ of exponential length in the contract. However, there might be an
equivalent contract that does have a polynomial-time description. By equivalent,
we mean one that has the same dominating path. This means that whether or
not ΣP
k is also an upper bound essentially boils down to whether or not every
⋄
contract has an equivalent contract with a polynomial description.

3.3 Games with perfect information, two contracts, upper bound

In this section, we consider two-player games of perfect information and provide
a polynomial-time algorithm for computing an SPE in these games. Speciﬁcally,
for a game tree of size m with ℓ terminal nodes with two contract players (and
an arbitrary number of non-contract players), we can compute the equilibrium
in time O(mℓ). Our approach is similar to that of [15], in that we compute the
inducible region for the ﬁrst player, deﬁned as the set of leaves they are able to
‘induce’ by making cuts in the game tree.

Let A, B be two sets. We then deﬁne the set of outcomes from A reachable

using a threat against player i from outcomes in B as follows:

threateni(A, B) = {x ∈ A | ∃ y ∈ B. xi > yi}

Game theory on the blockchain: a model for games with smart contracts

11

As mentioned, we will compute the inducible region for the player with the ﬁrst
contract, deﬁned as the set of outcomes reachable with a contract. Choosing the
optimal contract is then reduced to a supremum over this region.
Deﬁnition 3. Let G be a ﬁxed game. We denote by R(P1) (resp. R(P1, P2))
the inducible region of P1, deﬁned as the set of outcomes reachable by making a
cut in G in all nodes owned by P1. R(P1) is a tuple (u, c1) where u ∈ Rn is the
utility vector, and c1 is the contract (a cut) of Pi.
⋄

Algorithm. Let G be the game tree in question and let k be a ﬁxed integer.
As mentioned, we assume without loss of generality that G is in generic form,
meaning all non-leafs in G have out-degree exactly two and that all utilities for a
given player are distinct such that the ordering of utilities is unique. We denote
by P1, P2 the players with contracts and assume that Pi has the ith contract.
We will compute the inducible regions in G for P1 (denoted S for self ), and for
(P1, P2) (denoted T for together ) by a single recursive pass of the tree. In the
base case with a single leaf with label u we have S = T = {u}. For a non-leaf, we
can recurse into left and right child, and join together the results. The procedure
is detailed in Algorithm 1.

Algorithm 1: InducibleRegion(G)

switch G do

case Leaf(u):

return ({u}, {u})

case Node(GL, GR, i):

(SL, T L) ← InducibleRegion(GL)
(SR, T R) ← InducibleRegion(GR)
if i = 1 then

T ← T L ∪ T R
S ← SL ∪ SR ∪ threaten2(T L ∪ T R, SL ∪ SR)

else if i = 2 then
T ← T L ∪ T R
S ← threaten2(T L, SR) ∪ threaten2(T R, SL)

else

T ← threateni(T L, T R) ∪ threateni(T R, T L)
S′ ← threateni(SL, SR) ∪ threateni(SR, SL)
S ← S′

∪ threaten2(T, S′

)

end
return (S, T )

end

Theorem 3. An SPE in two-contract games of perfect information can be com-
puted in time O(mℓ).

12

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

Proof. First, the runtime is clearly O(mℓ) since the recursion has O(m) steps
where we need to maintain two sets of size at most ℓ. For correctness, we
show something stronger: let R(P1) be the inducible region for P1 in the ex-
panded tree and R(P1, P2) be the inducible region of (P1, P2). Now, let (S, T ) =
InducibleRegion(G). Then we show that S = R(P1) and T = R(P1, P2). This
implies that argmaxu∈S u1 is the SPE. The proof is by induction on the height
h of the tree. As mentioned, we assume that games are in generic form. This
base case is trivial so we consider only the inductive step.

Necessity follows using simple constructive arguments: for S and i = 1, then
for every (u, c) ∈ Sℓ, we can form contract where P1 chooses left branch and
plays c. And symmetrically for SR. Similarly, for every (u, c1, c2) ∈ T L and
(v, c′) ∈ SL can form contract where P1 plays c1 in all subgames where P2 plays
c2; and plays c′ otherwise. Then u is dominating if and only if u2 > v2. Similar
arguments hold for the remaining cases.
For suﬃciency, we only show the case of i = 1 as the other cases are similar.
Assume (for contradiction) that there exists (u, c1) ∈ R(P1) \ S, i.e. there is a
P1-cut c1 such that u is dominating. Then,

(u, c1) ∈ (T L ∪ T R) \ (SL ∪ SR ∪ threaten2(T L ∪ T R, SL ∪ SR))
= {v ∈ (T L ∪ T R) \ (SL ∪ SR) | ∀v′ ∈ SL ∪ SR. v2 < v′
2}

That is, u must be a utility vector that P1 and P2 can only reach in cooperation
in a one of the two sub-games, say by P2 playing c2. However, for every cut
that P1 makes, the dominating path has utility for P2 that is > u2, meaning P2
strictly beneﬁts by not playing c2. But this is a contradiction since we assumed
⊓⊔
u was dominating.

3.4 Games with perfect information, unbounded contracts,

PSPACE-hardness

We now show that computing an SPE remains PSPACE-complete when consid-
ering games with an arbitrary number of contract players. We start by showing
NP-hardness and generalize to PSPACE-hardness in a similar manner as we did
for Theorem 2. The reduction is from 3-coloring: let (V, E) be an instance
of 3-coloring and assume the colors are {R, G, B}. The intuition behind the
NP-reduction is to designate a coloring player Pcolor, who picks colors for each
vertex u ∈ V by restricting his decision space in a corresponding move using a
contract. They are the ﬁrst player with a contract. This is constructed using a
small stump for every edge e ∈ E with three leaves Ru, Gu, Bu. We also have
another player Pcheck whose purpose is to ensure no two adjacent nodes are col-
ored the same. We attach all stumps to a node owned by Pcheck such that Pcheck
can choose among the colors chosen by Pcolor. If Pcolor are able to assign colors
such that no adjacent nodes share a color, then Pcolor maximizes their utility,
however, if no such coloring exists then Pcheck can force a bad outcome for Pcolor.
It follows that Pcolor can obtain good utility if and only there is a valid coloring.

Game theory on the blockchain: a model for games with smart contracts

13

Pcheck

Pcolor

Pu1,R

Pu2,R

...

Pu1,R

...

Pu2,R

Pcheck

⊤(u1,u2),R ⊥(u1,u2),R

Pcolor

Pcolor

· · ·

Pcolor

Ru1 Gu1 Bu1

Ru2 Gu2 Bu2

Run Gun Bun

Fig. 4. The structure of the reduction. First, Pcolor is allowed to assign a coloring of
all vertices. If there is no 3-coloring of the graph, there must be some vertex (u1, u2)
where both vertices are colored the same color c. In this case, Pcheck can force both
cu1 , cu2 , which are undesirable to Pu1,c, resp. Pu2,c: then in every Pu1,c-contract where
they do not commit to choosing Pu2,c, Pcheck cuts as to ensure cu1 and analogously
for P2. It follows that Pcheck can get ⊥ if and only if the graph is not 3-colored. Then
Pcolor can get a diﬀerent outcome from ⊥ if and only if they can 3-color the graph.

Reduction. We add six contract players for every edge in the graph. Speciﬁcally,
for every edge (u, v) ∈ E and every color c ∈ {R, G, B}, we introduce two new
contract players Pu,c and Pv,c who prefer any outcome except cu (resp. cv) being
colored c. That is, if c = R, then the leaf Ru has a poor utility for Pu,R. We
add moves for Pu,c and Pv,c at the top of the tree, such that if they cooperate,
they can get a special utility vector ⊥u,v which has a poor utility for Pcolor
and great utility for Pcheck, though they themselves prefer any outcome in the
tree (except cu, resp. cv) to ⊥u,v. We ensure that Pcheck has a contract directly
below Pcolor in the tree. If no coloring exists, then Pcheck can force a bad outcome
for both Pu,c, Pv,c in all contracts where they do not commit to choosing ⊥u,v.
Speciﬁcally, Pcheck ﬁrst threatens Pu,c with the outcome cu, and subsequently
threatens Pv,c with cv. Though they prefer any other node in the tree to ⊥u,v,
they still prefer ⊥u,v to cu, cv, meaning they will comply with the threat. This
means Pcolor will receive a poor outcome if the coloring is inconsistent. It follows

14

Mathias Hall-Andersen and Nikolaj I. Schwartzbach

that Pcolor will only receive a good payoﬀ if they are able to 3-color the graph,
see e.g Section 3.4 for an illustration.

Theorem 4. Computing an SPE in smart contract games of perfect information
is PSPACE-hard when we allow for an unbounded number of contract players.

Proof. Let (V, E) be an instance of 3-coloring. Our above reduction works
immediately for k = 1, showing NP-hardness. To show PSPACE-hardness we
reduce from a variant of 3-coloring as described in [3] where players alternately
color an edge and use a similar trick as Theorem 2 by introducing new players
between Pcolor and Pcheck.
⊓⊔

It remains unclear where the exact cutoﬀ point is, though we conjecture it to
be for three contracts: clearly, the decision problem for three-contract games of
perfect information is contained in NP as the witness (a cut for the ﬁrst contract
player) can be veriﬁed by Algorithm 1.

Conjecture 1. Computing an SPE for three-contract games is NP-complete.

⋄

4 Conclusion

In this paper, we proposed a game-theoretic model for games in which players
have shared access to a blockchain that allows them to deploy smart contracts.
We showed that our model generalizes known notions of equilibria, with a single
contract being equivalent to a Stackelberg equilibrium and two contracts equiva-
lent to a reverse Stackelberg equilibrium. We proved a number of bounds on the
complexity of computing an SPE in these games with smart contracts, showing,
in general, it is infeasible to compute the optimal contract.

References

1. Averboukh, Y.: Inverse stackelberg solutions for games with many followers. Math-

ematics 6 (04 2014). https://doi.org/10.3390/math6090151

2. Basar, T., Selbuz, H.: Closed-loop stackelberg strategies with applications in the
optimal control of multilevel systems. IEEE Transactions on Automatic Control
AC-24, 166 – 179 (04 1979)

3. Bodlaender, H.L.: On the complexity of some coloring games. In: M¨ohring, R.H.
(ed.) Graph-Theoretic Concepts in Computer Science. pp. 30–40. Springer Berlin
Heidelberg, Berlin, Heidelberg (1991)

4. Boˇsansk´y, B., Brˆanzei, S., Hansen, K.A., Lund, T.B., Miltersen, P.B.: Computation
of stackelberg equilibria of ﬁnite sequential games. ACM Trans. Econ. Comput.
5(4) (Dec 2017). https://doi.org/10.1145/3133242

5. Breton, M., Alj, A., Haurie, A.: Sequential stackelberg equilibria in two-person
games. Journal of Optimization Theory and Applications 59(1), 71–97 (Oct 1988).
https://doi.org/10.1007/BF00939867

6. Chen, X., Deng, X.: Settling the complexity of two-player nash equilibrium. In: 2006
47th Annual IEEE Symposium on Foundations of Computer Science (FOCS’06).
pp. 261–272 (2006). https://doi.org/10.1109/FOCS.2006.69

Game theory on the blockchain: a model for games with smart contracts

15

7. Daskalakis, C., Goldberg, P., Papadimitriou, C.: The complexity of com-
puting a nash equilibrium. SIAM J. Comput. 39, 195–259 (02 2009).
https://doi.org/10.1137/070699652

8. Garey, M.R., Johnson, D.S.: Computers and Intractability; A Guide to the Theory

of NP-Completeness. W. H. Freeman & Co., USA (1990)

9. Ho, Y., Olsder, G.: Aspects of the stackelberg problem — incentive, bluﬀ, and
hierarchy1. IFAC Proceedings Volumes 14(2), 1359–1363 (1981), 8th IFAC World
Congress on Control Science and Technology for the Progress of Society, Kyoto,
Japan, 24-28 August 1981

10. Jeroslow, R.G.: The polynomial hierarchy and a simple model

for com-
petitive analysis. Mathematical Programming 32(2), 146–164 (Jun 1985).
https://doi.org/10.1007/BF01586088

11. Leitmann, G.: On generalized

stackelberg

strategies.

Journal

timization
https://doi.org/10.1007/BF00933155

Theory

and Applications

26(4),

637–643

(Dec

of Op-
1978).

12. Letchford, J.: Computational Aspects of Stackelberg Games. Ph.D. thesis, Duke

University, Durham, NC, USA (2013)

13. Letchford, J., Conitzer, V.: Computing optimal strategies to commit to in
extensive-form games. In: Proceedings of the 11th ACM Conference on Electronic
Commerce. p. 83–92. EC ’10, Association for Computing Machinery, New York,
NY, USA (2010). https://doi.org/10.1145/1807342.1807354

14. Liu, B.: Stackelberg-nash equilibrium for multilevel programming with multiple
followers using genetic algorithms. Computers & Mathematics with Applications
36(7), 79–89 (1998)

15. Luh, P.B., Chang, S.C., Chang, T.S.: Brief paper: Solutions and properties of

multi-stage stackelberg games. Automatica p. 251–256 (Mar 1984)

16. Osborne, M.J., Rubinstein, A.: A course in game theory. The MIT Press (1994),

electronic edition

17. Sherali, H.D.: A multiple leader stackelberg model and analysis. Operations Re-

search 32(2), 390–404 (1984)

18. von Stackelberg, H.: Marktform und Gleichgewicht. Verlag von Julius Springer

(1934)

19. Stankova, K.: On Stackelberg and Inverse Stackelberg Games & Their Applications
in the Optimal Toll Design Problem, the Energy Market Liberalization Problem,
and in the Theory of Incentives. Post-Print hal-00391650, HAL (Feb 2009)

20. Szymanik, J.: Backward induction is ptime-complete. In: Logic, Rationality, and
Interaction - 4th International Workshop, LORI 2013, Hangzhou, China, October
9-12, 2013, Proceedings. Lecture Notes in Computer Science, vol. 8196, pp. 352–
356. Springer (2013)

21. Tolwinski, B.: Closed-loop stackelberg solution to a multistage linear-quadratic
game. Journal of Optimization Theory and Applications 34, 484 – 501 (08 1981)
22. Wood, G.: Ethereum: A secure decentralised generalised transaction ledger.

Ethereum project yellow paper 151, 1–32 (2014)

