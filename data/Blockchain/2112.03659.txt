BlockGC: A Joint Learning Framework for Account Identity Inference
on Blockchain with Graph Contrast

Jiajun Zhou1, Chenkai Hu1, Shenbo Gong1, Jiaying Xu1, Jie Shen1, Qi Xuan1 *
1Zhejiang University of Technology, Hangzhou, China,
{jjzhou, shenj, xuanqi}@zjut.edu.cn, {ckhu0122, jshmhsb, JiayingXu1279}@gmail.com

1
2
0
2

c
e
D
7

]

R
C
.
s
c
[

1
v
9
5
6
3
0
.
2
1
1
2
:
v
i
X
r
a

Abstract

Blockchain technology has the characteristics of decentral-
ization, traceability and tamper proof, which creates a re-
liable decentralized transaction mode, further accelerating
the development of the blockchain platforms. However, with
the popularization of various ﬁnancial applications, security
problems caused by blockchain digital assets, such as money
laundering, illegal fundraising and phishing fraud, are con-
stantly on the rise. Therefore, ﬁnancial security has become
an important issue in the blockchain ecosystem, and identify-
ing the types of accounts in blockchain (e.g. miners, phishing
accounts, Ponzi contracts, etc.) is of great signiﬁcance in risk
assessment and market supervision. In this paper, we con-
struct an account interaction graph using raw blockchain data
in a graph perspective, and proposes a joint learning frame-
work for account identity inference on blockchain with graph
contrast. We ﬁrst capture transaction feature and correlation
feature from interaction graph, and then perform sampling
and data augmentation to generate multiple views for account
subgraphs, ﬁnally jointly train the subgraph contrast and ac-
count classiﬁcation task. Extensive experiments on Ethereum
datasets show that our method achieves signiﬁcant advan-
tages in account identity inference task in terms of classiﬁ-
cation performance, scalability and generalization.

Introduction
The past few years have witnessed the application of
blockchain technology in new technological and industrial
revolutions, such as cryptocurrency, supply chain manage-
ment, ﬁnancial services, etc. As a distributed data stor-
age technology, blockchain is decentralized, traceable and
tamper-proof, which guarantees the ﬁdelity and security of
a record of data and generates trust without the need for
a trusted third party. Beneﬁtting from these characteristics,
blockchain has attracted considerable attention, and are best
known for its crucial role in cryptocurrency systems, such as
Bitcoin and Ethereum.

However, while the anonymity mechanism of

the
blockchain achieves decentralization, it also magniﬁes the
security risk of cryptoasset. Blockchain is most widely used
in ﬁnancial transaction, making it a tempting target for hack-
ers and other cybercriminals. At present, the weak super-

*Qi Xuan is the corresponding author.

Copyright © 2022, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

vision of blockchain platforms has led to endless illegal
criminal activities such as money laundering, gambling and
phishing scams, making cryptocurrency crimes a constraint
for the industry and regulation. Therefore, ﬁnancial market
security has become an important issue in the blockchain
ecosystem, and it is of great signiﬁcance to study security
technology for public blockchain in application scenarios
such as risk assessment and market supervision.

The biggest challenge for

security supervision on
blockchain is anonymity, which means that the identity in-
formation of each account need not to be disclosed or ver-
iﬁed, resulting in the difﬁculty in mining privacy of ac-
count holders. On the public blockchain, pseudonymous ac-
counts created by criminals can protect their identity infor-
mation to a certain extent and shelter their illegal activi-
ties from supervision. On the other hand, the openness and
transparency of blockchain provides access to all transac-
tion information, which also creates conditions for the de-
anonymization of accounts. Recently, several related work
has focused on using the public information available on
blockchain platforms to analyze the behavior patterns of ac-
counts and mine the identity information behind them, thus
deriving a de-anonymization task – account identity infer-
ence. This task aims to infer the possible identity of accounts
in blockchain, such as exchanges, phishing accounts, min-
ers, Ponzi schemes, by using the public information about
transaction, contract calls, etc. Existing methods of account
identity inference mainly concentrate on manual feature en-
gineering, graph modeling and mining, which are effective
but suffer from several shortcomings and challenges. First,
manual feature engineering relies on the prior knowledge of
the designers, is not capable of capturing the underlying in-
formation in blockchain data, such as transaction patterns,
resulting in low feature utilization and unsound expressive-
ness. In addition, manual features have weak universality
across different blockchain platforms due to the technical
differences among them. For example, Ethereum has fea-
tures associated with smart contract invocation that are not
present in Bitcoin, which greatly limits the reusability of
manually features. Second, the scale of transaction graph in
terms of the number of accounts and transactions is huge,
resulting in high memory and time consumption when ap-
plying graph embedding algorithms based on random walks
or graph neural network (GNN) to large-scale interaction

 
 
 
 
 
 
graph. Meanwhile, the growing number of transactions on
the blockchain means the frequent update in the interaction
graph in terms of nodes and edges, which is not conducive to
whole-graph learning. Lastly, the annotated data of account
identity published by third-party sites is relatively scarce, re-
sulting in a poor generalization of supervised models.

In our work, we present an end-to-end joint learning
framework for account identity inference on Blockchain
with Graph Contrast (BlockGC). Speciﬁcally, we ﬁrst col-
lect and collate large amounts of data involving transaction,
contract invocation and public annotation data of account
identity from the Ethereum and other third-party platforms.
Then we construct an account interaction graph using raw
blockchain data. Based on the assumption that the behavior
patterns of different accounts are hidden in their neighbor-
hood interaction subgraphs, we then extract neighborhood
subgraphs of accounts from the interaction graph and pack
them as batches as the input of model. There exist few ac-
count identity labels in the existing blockchain data, which
may lead to poor generalization of model during supervised
learning. So we introduce graph self-supervised learning for
account identity inference. To be speciﬁc, several graph data
augmentation strategies are ﬁrstly used to generate multi-
ple weak annotation views of account subgraphs, and then
a subgraph contrast process is used to learn the correlation
between account subgraphs in different views. Finally we
jointly train the subgraph contrast and account classiﬁcation
task to realize the end-to-end account identity inference.

Related Work
Account identity inference in blockchain has received more
and more attention with the purpose of detecting abnormal
and illegal accounts. Previous methods concentrate on man-
ual feature engineering. Toyoda et al. (Toyoda, Ohtsuki, and
Mathiopoulos 2018) extracted seven statistical features such
as the rate of bitcoin coinbase transactions to infer account
identity. Lin et al. (Lin et al. 2019) enriched the amount of
features greatly and analyze the importance of each manual
feature. Bartoletti et al. (Bartoletti, Pes, and Serusi 2018) de-
signed the Gini coefﬁcient and the characteristics of possible
abnormal behavior patterns to infer the accounts of the Ponzi
scheme in the transaction network. Some emerging public
blockchains contain smart contracts, providing new features.
Huang et al.(Huang et al. 2020) considered the calling infor-
mation of smart contract to expand the feature space, and
realized the identiﬁcation of bot accounts in EOSIO.

Detecting abnormal users and learning their behavior pat-
terns through transaction graph can be regarded as a node
classiﬁcation task in a graph perspective. Therefore, the
account identity inference method based on graph mod-
eling emerged, providing convenience for analyzing com-
plex transaction data. Li et al.(Li et al. 2020) considered
topological features of accounts and found the difference
in the topology between the Ponzi scheme accounts and
the ordinary accounts. Yuan et al.(Yuan et al. 2020) ap-
plied DeepWalk(Perozzi, Al-Rfou, and Skiena 2014) and
Node2vec(Grover and Leskovec 2016) to learn account fea-
tures in transaction graph. Yuan et al.(Yuan, Yuan, and Wu
2020) extracted the subgraphs for each target account and

embedded their transaction topology into feature vector via
Graph2Vec(Narayanan et al. 2017).

Account Interaction Graph Model

Ethereum and Block Data
In this paper, we mainly focus on accounts in Ethereum
which is the second largest blockchain platform after Bit-
coin. Ethereum allows users to conduct more complex trans-
actions based on smart contracts, which are applications that
run on ethereum virtual machines. An account in Ethereum
is an entity that owns ether, and can be divided into two cate-
gories: external accounts (EOA) and contract accounts (CA).
The EOA is controlled by user who owns the private key cor-
responding to the account, and can initiate transactions. The
CA is controlled by code of smart contract, which cannot
initiate transactions actively and can only be executed ac-
cording to the pre-written code of smart contract after being
triggered. In Ethereum, there are usually two types of inter-
actions: transaction and contract call. The transaction must
be initiated by EOA, and the receiver can be EOA or CA.
Contract call refers to the process of triggering the smart
contract code in CA to perform many different operations
when an EOA initiates a transaction to the CA.

The Ethereum blockchain is a succession of blocks, each
block contains a set of transactions T and contract calls C.
The raw block data of Ethereum is structured and provides a
wealth of information, as listed in Appendix 2.

Figure 1: Account interaction graph and lightweight version.

Account Interaction Graph
The raw block data is informative and provides the details of
transactions and contract calls, by which we can construct a
Account Interaction Graph (AIG), as deﬁned below.

Deﬁnition 1. (Account Interaction Graph): An Account In-
teraction Graph (AIG) is a directed and weighted multi-
graph G = (VEOA, VCA, ET , EC, Y ), where VEOA and
VCA are the set of EOA and CA respectively, ET =
{eT :d
, d, w)} is the directed edge set con-
structed from transaction information, and EC = {eC:d
ij =
(vEOA+CA
, d, f )} is the directed edge set constructed
from contract call information. The three edge attributes d,

ij = (vEOA

, vEOA
j

, vCA
j

i

i

𝑣3𝑣1𝑣2𝑣3𝑣1𝑣2𝑡𝑤𝑓𝑑𝑣3𝑣1𝑣2𝑣3𝑣1𝑣2𝑑𝑤𝑓𝑡缩小后原图w, f represent the ﬁelds timestamp, value and callingFunc-
tion respectively. The AIG is partially labeled, i.e., a few ac-
counts have identity labels and can compose the annotation
node set VY = {(vi, yi) | vi ∈ VEOA ∪ VCA, yi ∈ Y }.

The original AIG is a multigraph which has a dense con-
nection, as shown in Figure 1. We further ligntweight the
AIG by edge coarsening and feature pruning to reduce the
task complexity.

i

, t, ˜w)} and EC = {eC

ij = (vEOA
i
, vCA
j

Deﬁnition 2. (Lightweight Account Interaction Graph): An
Lightweight AIG (Lw-AIG) is a directed and weighted
graph G = (VEOA, VCA, ˜ET , ˜EC, Y ), where ˜ET =
{eT
, vEOA
ij =
j
(vEOA+CA
, t)}. The edge attribute t denotes the num-
ber of directed interactions from vi to vj, and the edge at-
tribute ˜w denotes total amounts of transaction from vi to vj.
Notably, the edge coarsening operation will merge all
edges between any two nodes vi, vj and generate an edge
weight t = |{e∗:d
ij }|. And the feature pruning will take effect
with the edge coarsening, removing the two edge attribute
of timestamp d and function name f .

Figure 2: Illustration of constructing account attribute fea-
ture for contract call.

Contract Call Feature
The behavioral characteristics of an account are not only re-
lated to its transaction object, transaction amount and fre-
quency, but also related to the smart contracts it calls. Dif-
ferent types of accounts have a certain correlation to dif-
ferent smart contracts. Therefore, the contract call situation
of accounts can be treated as an account attribute feature,
as illustrated in Figure 2. We can construct a feature matrix
X ∈ Rn×F for the EOA in AIG to represent the preference
for contract calls, and F is the number of types of contracts.

Methodology
In this section, we give the details of the proposed frame-
work BlockGC, as schematically depicted in Figure 3. Our
framework is mainy composed of the following components:
(1) a subgraph extractor which captures the subgraphs cen-
tered on target accounts from the Lw-AIG topology; (2)
a subgraph augmentor which generates a series of variant
graph views using various transformations on attributes and
structure of subgraphs; (3) a GNN model which jointly trains
the subgraph contrast and account classiﬁcation tasks. Next,
we describe the details of each component.

Figure 3: The architecture of BlockGC.

Subgraph Sampling
The raw data contained tens of millions of blocks, making
AIG a large-scale graph. Some hub nodes such as exchange
accounts have a large amount of transaction ﬂows, which
will affect both the computation efﬁciency and training ef-
fect. Even though the lightweight process greatly sparses the
connections of AIG, it does not reduce the number of nodes.
On the other hand, existing account identity inference meth-
ods based on random walk or graph embedding generally
accept the whole graph as input and rely on full-graph train-
ing, which restricts their scalability on large-scale graphs for
node representation learning. In this work, we consider sub-
graph sampling strategies (Chiang et al. 2019; Zeng et al.
2020) which are commonly used for large-scale graph com-
putation to improve the scalability of our framework.

The Lw-AIG has two edge attributes: the number of in-
teractions t and the total amount of transactions ˜w. Vari-
ous subgraphs can be obtained by sampling according to
different attributes. We use Topk sampling to obatin the h-
hop subgraph for each account, and convert the full-graph
training to subgraph mini-batch training. Speciﬁcally, for a
target account node vi, we sample 1-hop neighbors accor-
ing to edge attributes with top-k largest t or ˜w, and again
sample the 1-hop neighbors for each nodes sampled at the
previous hop, and recursive ones in the downstream hops.
After h iterations, we obtain the node set Vi sampled from
Lw-AIG, and the subgraph gi of account vi can be induced
by Vi from the Lw-AIG. Figure 4 illustrates the process of
subgraph sampling according to difference edge attributes.
For a set of target accounts VY , we get the subgraph for
each target account in VY and all the subgraphs form a set:
D = {(gi, yi) | vi ∈ VY , yi ∈ Y }.

Subgraph Contrastive Learning
BlockGC utilizes subgraph-level contrastive learning to
train a GNN encoder f which is capable of characterizing
the interaction pattern of accounts. In our contrastive learn-
ing framework, for each account subgraph gi, its two cor-
related views ˆg1
i are generated by undergoing two
augmentation operators t1 and t2, where ˆg1
i = t1(gi) and
ˆg2
i = t2(gi). The correlated augmented views are fed into
a GNN encoder fθ with max pooling layer, producing the
whole subgraph representations h1
i , which are then
mapped into an embedding space via a projection head fφ,
yielding z1
i . Note that θ and φ are the parameters of
graph encoder and projection head respectively. The repre-

i and ˆg2

i and h2

i and z2

t=5𝑣1Contract 1Contract 2Contract 3253缩小后的图𝑣1t=5Contract 1Contract 2Contract 3253原图𝑨𝒗/𝑨𝒕𝑿GCN LayerGCN Layer෡𝑨𝒗𝟏/෡𝑨𝒕𝟏෡𝑿𝟏෡𝑨𝒗𝟐/෡𝑨𝒕𝟐෡𝑿𝟐Max PoolingLinear LayerProject HeadPredictive  lossContrastivelossAccountsubgraph缩小后的图𝑨𝒗/𝑨𝒕𝑿GCN LayerGCN Layer෡𝑨𝒗𝟏/෡𝑨𝒕𝟏෡𝑿𝟏෡𝑨𝒗𝟐/෡𝑨𝒕𝟐෡𝑿𝟐Max PoolingLinear LayerProject Head+Predictive lossContrastivelossAccountsubgraphGraphAugmentationGraphAugmentation原图+Model Training

We achieve account identity inference by classifying ac-
count subgraphs which consist of target account subgraphs
and their corresponding augmented views, yielding a classi-
ﬁcation loss:

Lpred =

1
3

(LD + LDaug1 + LDaug2),

(4)

where LD, LDaug1 and LDaug2 are the cross entropy loss
computed by D, Daug1 and Daug2, respectively.

The subgraph contrast is treated as pretext task, and the
encoder in BlockGC is jointly trained with the pretext and
subgraph classiﬁcation tasks. The loss function consists of
both the self-supervised and classiﬁcation task loss func-
tions, as formularized below:

L = Lpred + λ · Lself .

(5)

where λ is a trade-off hyper-parameter controls the contri-
bution of self-supervision term.

Figure 4: Illustration of Topk sampling according to differ-
ent edge attributes.

sentation of an account subgraph, z, is treated as the rep-
resentation of its central target account. Finally, the goal of
subgraph-level contrast is to maximize the consistency be-
tween two correlated augmented views of subgraphs in the
embedding space via Eq. (1):

Lself =

1
n

n
(cid:88)

i=1

Li,

(1)

Experiments

where n is the number of subgraphs in a batch (i.e., batch
size). The loss for each subgraph Li can be computed as:

Li = − log

es(z1
i )/τ
i ,z2
j=1,j(cid:54)=i es(z1

(cid:80)n

i ,z2

j)/τ

,

(2)

i , z2

i /(cid:107)z1

i ) = z1
i

where s(·, ·) is the cosine similarity function having
(cid:62) · z2
s(z1
i (cid:107)(cid:107)z2
i (cid:107), and τ is the temperature
i and z2
parameter. The two correlated views z1
i of account
subgraph gi are treated as positive pair while the rest view
pairs in the batch are treated as negative pairs. The objec-
tive aims to maximize the consistency of positive pairs as
opposed to negative ones.

Graph Augmentation
Contrastive learning relies heavily on well-designed data
augmentation strategies for view generation. So far, com-
monly used graph augmentation techniques concentrate on
structure-level and attribute-level augmentation. In this pa-
per, we use two existing augmentation methods, Node Drop-
ping and Feature Masking.

Feature Masking (FM)
It was proposed in (Zhu et al.
2020). During feature masking, each dimension of node at-
tributes has a certain probability p to be set as zero.

Node Dropping (ND)
It was proposed in (You et al.
2020). During node dropping, each node has a certain prob-
ability p to be dropped from gi.

During graph augmentation, we generate two augmented
i for each target account subgraph gi, and assign

views ˆg1
the label of target account to them as a pseudo label:

i , ˆg2

Dataset Description

We intercepte the ﬁrst 10 million block data (the time in-
terval is between “2015-07-03” to “2020-05-04”) from the
Xblock website1. Within this time interval, we can ex-
tract in total 309010831 transactions and 175,351,541 con-
tract calls, involving 90,193,755 EOA and 16,221,914 CA.
Account
labels are obtained from Ethereum blockchain
browser2, including 193 Exchange, 73 ICO-wallets, 65 Min-
ing and 2,535 Phish-hack. These four types of accounts
are common in cryptocurrency networks, and have received
widespread attention. It is of sufﬁcient practical signiﬁcance
to inference whether an account belongs to these types, es-
pecially to identify phishing and hacker accounts.

Experimental Settings

Comparison Methods To illustrate the effectiveness, we
compare the model with the following methods: man-
ual features (see Appendix B), DeepWalk (Perozzi, Al-
Rfou, and Skiena 2014), Node2Vec (Grover and Leskovec
2016), Struc2vec (Figueiredo, Ribeiro, and Saverese 2017),
I2BGNN (Shen et al. 2021).

Parameter Conﬁguration For BlockGC, we set the sub-
graph hop h to 2 and sample k = 20 neighbors per hop. We
apply 2 layers of GCNs with output dimensions both equal
to 128, and set {λ, eopchs, batch size, dropout} to be {0.2,
200, 150, 0.3}, respectively. We repeat 3-fold cross valida-
tion for 10 times and report the average F1-score. More de-
tails of parameter conﬁgurations for baselines are available
in Appendix D.

Daug1 = (cid:8)(cid:0)ˆg1
Daug2 = (cid:8)(cid:0)ˆg2

i , yi
i , yi

(cid:1) | vi ∈ VY , yi ∈ Y (cid:9) ,
(cid:1) | vi ∈ VY , yi ∈ Y (cid:9) .

(3)

1http://xblock.pro/
2https://etherscan.io/

ෝ𝑤𝑡𝑘=3𝑘=3缩小后的图Figure 5: Performance gain (absolute improvement in F1 score) under different subgraph scales and data augmentation combi-
nations, compared to I2BGNN which stands for a no-augmentation baseline.

Table 1: Results of identity inference for four types of ac-
counts in Ethereum.

Method

Sampling ETH-E ETH-I ETH-M ETH-P

Manual Feature

DeepWalk

Node2Vec

Struc2Vec

I2BGNN

BlockGC

ND-FM

ND

FM

–

˜w
t
˜w
t
˜w
t

˜w
t

˜w
t

˜w
t

˜w
t

87.34

72.87
77.61
80.79
80.45
72.01
75.11

87.94
89.06

89.49
90.87

89.66
89.49

89.58
91.30

70.29

57.82
61.88
66.21
75.28
56.24
57.60

90.48
89.80

91.84
91.28

91.38
91.61

90.48
90.25

77.15

56.65
57.46
69.51
78.84
74.36
66.41

89.48
90.27

89.72
92.76

89.46
91.78

90.51
93.07

78.60

88.73
89.33
89.30
92.24
64.27
63.63

96.07
95.43

95.95
96.21

96.03
96.05

96.28
96.29

Results and Analysis
Table 1 reports the performance comparison between
BlockGC and baselines, from which we can observe that
BlockGC signiﬁcantly outperforms other methods across
four types of accounts. For instance, we achieve 91.30%,
91.84%, 93.07% and 96.29% F1-score, respectively, which
are 2.52%, 1.5%, 3.1% and 0.23% relative improvement
over previous state-of-the-art.

We further investigate the impact of two data augmenta-
tion techniques and the subgraph sampling strategy in our
framework on Ethereum datasets, as illustrated in Figure 5.
And we list the following Observations. More results will
be discussed in Appendix.

Obs. 1. Data augmentation is crucial, and feature mask-
ing beneﬁts more. Composing an original and its FM
view can beneﬁt the inference task and achieve the best per-
formance in 3 out of 4 experiments, judging from Table 1.
Since that the initial features of accounts in Lw-AIG is con-
structed from contract call information, which can reﬂect the
behavioral preferences of accounts. Masking such features
can facilitate model learning the correlation between differ-

ent behavioral views and help in identity inference. Such re-
sult is also consistent with (You et al. 2020), that is, feature
masking performs better on dense graphs, like our AIG.

Obs. 2. Smaller subgraphs contain more critical identity-
related pattern information.
It is generally better to in-
fer from 1-hop subgraphs than from 2-hop ones, judging
from Figure 5. Since AIG is a dense graph, the 2-hop sub-
graphs are large-scale, resulting in an over-smoothing in
GNN. Moreover, the anonymity of blockchain also ensures
that accounts in AIG only have partial knowledge of the 1-
hop neighborhood accounts, resulting in a failure of message
propagation from 2-hop neighbors.

Obs. 3. Contrastive self-supervision facilitates the learn-
ing of account features. By contrastive learning, it seems
that accounts of different classes on BlockGC with 2-
dimensional embedding are more separated as compared to
the embedding of I2BGNN.

Figure 6: The t-SNE visualization of the embedding features
obtained by I2BGNN and our BlockGC.

Conclusion
In this paper, we construct an account interaction graph us-
ing raw blockchain data collected from Ethereum in a graph
perspective, and proposes a joint learning framework for ac-
count identity inference on blockchain with graph contrast,
which integrate scalability, generalization and end-to-end
architecture together. Extensive experiments on Ethereum
datasets show the superiority of our method.

1-31-51-101-151-202-32-52-102-152-20Hop - TopKETH-E-wETH-E-tETH-M-wETH-M-tETH-I-wETH-I-tETH-P-wETH-P-tDataset - EdgeAttribute0.0390.0210.0090.0030.0110.0190.0110.0030.0190.0150.0270.0210.0090.0110.0090.0210.0250.0160.0180.0180.0430.0980.0380.0360.0380.008-0.0210.013-0.0160.0020.0830.0410.0250.0690.0670.0180.015-0.0100.0090.0250.0660.0110.0270.0340.0090.0020.0020.0180.0070.0140.0450.0110.0270.0480.0140.0200.0090.0180.0090.016-0.000-0.002-0.008-0.006-0.0100.006-0.0030.0000.001-0.001-0.002-0.000-0.007-0.010-0.010-0.011-0.0010.0020.0030.008NodeDrop - FeatureMask1-31-51-101-151-202-32-52-102-152-20Hop - TopK0.0380.0270.0200.0130.0150.014-0.0020.0110.0010.0160.0160.0100.0070.0090.0230.0140.0130.0170.0060.0220.0870.1100.0110.0410.0260.003-0.015-0.0210.0070.0100.0640.0490.0360.0790.0720.0040.0070.010-0.0030.0280.0660.0090.0270.0200.059-0.0070.0070.0020.0000.0000.0380.0140.0000.0410.0290.0230.0250.0200.0250.004-0.0140.000-0.007-0.004-0.0080.000-0.007-0.0000.000-0.000-0.006-0.003-0.006-0.003-0.010-0.0160.0030.0060.0010.006Identity - NodeDrop1-31-51-101-151-202-32-52-102-152-20Hop - TopK0.0280.0010.0090.0030.0150.014-0.0020.0090.0070.0170.0170.015-0.0030.0090.0060.0190.0110.0150.0050.0040.0430.1080.0240.0280.0720.005-0.0200.013-0.005-0.0000.1000.0430.0430.0560.0280.003-0.0030.0080.0050.0150.0840.0160.0250.0380.038-0.0020.0160.0180.0110.0090.0540.009-0.0070.0410.0500.0250.0200.0160.0200.018-0.013-0.001-0.010-0.003-0.0060.003-0.005-0.0070.0030.002-0.0050.003-0.012-0.007-0.003-0.008-0.0000.0050.0040.009Identity - FeatureMask0.000.050.10I2BGNNBlockGCYuan, Z.; Yuan, Q.; and Wu, J. 2020. Phishing Detection
on Ethereum via Learning Representation of Transaction
Subgraphs. In International Conference on Blockchain and
Trustworthy Systems, 178–191. Springer.
Zeng, H.; Zhou, H.; Srivastava, A.; Kannan, R.; and
Prasanna, V. 2020. GraphSAINT: Graph Sampling Based
In In Proceedings of the 8th
Inductive Learning Method.
International Conference on Learning Representations.
Zhu, Y.; Xu, Y.; Yu, F.; Liu, Q.; Wu, S.; and Wang, L.
2020. Deep graph contrastive representation learning. arXiv
preprint arXiv:2006.04131.

References
Bartoletti, M.; Pes, B.; and Serusi, S. 2018. Data Mining
for Detecting Bitcoin Ponzi Schemes. In 2018 Crypto Val-
ley Conference on Blockchain Technology (CVCBT), 75–84.
IEEE.
Chiang, W.-L.; Liu, X.; Si, S.; Li, Y.; Bengio, S.; and Hsieh,
C.-J. 2019. Cluster-gcn: An efﬁcient algorithm for training
deep and large graph convolutional networks. In Proceed-
ings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 257–266.
Figueiredo, D. R.; Ribeiro, L. F. R.; and Saverese, P. H.
2017. struc2vec: Learning node representations from struc-
tural identity. CoRR.
Grover, A.; and Leskovec, J. 2016. node2vec: Scalable fea-
ture learning for networks. In Proceedings of the 22nd ACM
SIGKDD International Conference on Knowledge Discov-
ery and Data Mining, 855–864.
Huang, Y.; Wang, H.; Wu, L.; Tyson, G.; Luo, X.; Zhang,
R.; Liu, X.; Huang, G.; and Jiang, X. 2020. Understanding
(mis) Behavior on the Eosio Blockchain. Proceedings of the
ACM on Measurement and Analysis of Computing Systems,
4(2): 1–28.
Li, Y.; Cai, Y.; Tian, H.; Xue, G.; and Zheng, Z. 2020. Iden-
In Interna-
tifying Illicit Addresses in Bitcoin Network.
tional Conference on Blockchain and Trustworthy Systems,
99–111. Springer.
Lin, Y.-J.; Wu, P.-W.; Hsu, C.-H.; Tu, I.-P.; and Liao, S.-w.
2019. An Evaluation of Bitcoin Address Classiﬁcation based
on Transaction History Summarization. In 2019 IEEE In-
ternational Conference on Blockchain and Cryptocurrency
(ICBC), 302–310. IEEE.
Narayanan, A.; Chandramohan, M.; Venkatesan, R.; Chen,
graph2vec: Learn-
L.; Liu, Y.; and Jaiswal, S. 2017.
ing distributed representations of graphs. arXiv preprint
arXiv:1707.05005.
Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk:
Online learning of social representations. In Proceedings of
the 20th ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, 701–710.
Shen, J.; Zhou, J.; Xie, Y.; Yu, S.; and Xuan, Q. 2021. Iden-
tity Inference on Blockchain using Graph Neural Network.
arXiv preprint arXiv:2104.06559.
Toyoda, K.; Ohtsuki, T.; and Mathiopoulos, P. T. 2018.
Multi-class Bitcoin-enabled Service Identiﬁcation based on
Transaction History Summarization. In 2018 IEEE Interna-
tional Conference on Internet of Things (iThings) and IEEE
Green Computing and Communications (GreenCom) and
IEEE Cyber, Physical and Social Computing (CPSCom) and
IEEE Smart Data (SmartData), 1153–1160. IEEE.
You, Y.; Chen, T.; Sui, Y.; Chen, T.; Wang, Z.; and Shen, Y.
2020. Graph contrastive learning with augmentations. vol-
ume 33, 5812–5823.
Yuan, Q.; Huang, B.; Zhang, J.; Wu, J.; Zhang, H.; and
Zhang, X. 2020. Detecting Phishing Scams on Ethereum
based on Transaction Records. In 2020 IEEE International
Symposium on Circuits and Systems (ISCAS), 1–5. IEEE.

A. Ethereum Raw Block Data Information
The raw block data collected from Ethereum is structured
and provides a wealth of information, as listed in Table 2.

• avg received tx day: the average number of transactions

that the account has received ether per day.

• avg output: the average value of the ether spent by the

Table 2: Ethereum raw block data information.

Data
Field

Custom
Symbol

blockNumber
timestamp
from
to
fromIsContract
toIsContract
callingFunction
value

-
d
v
v
-
-
f
w

Deﬁnition

The ID of block where the transcation is located
The timestamp of the transaction
The account that initiates the transaction
The account that receives the transaction
Whether the transaction is initiated from a CA
Whether the transaction is received by a CA
The name of function called if there is a contract call
The transaction amount

B. Manual Feature Details
Manual feature engineering is the most common and sim-
plest way for account identity inference. According to the
characteristics of raw transaction data and prior knowledge,
we design 16 manual features for Ethereum accounts, as
shown in Table 3.

Table 3: Statistics of the average of manual feature for vari-
ous accounts in Ethereum.

Manual Features

Phish-Hack

Exchange

Mining

ICO-Wallets Common

active days
total received
num received tx
inter acct received
total output
num output tx
inter acct output
avg received
avg received day
avg received tx day
avg output
avg output day
avg output tx day
times contract called
times contract called day
num contract called

76.94
110.84
27
23.29
124.03
29.91
8.18
29.52
11.66
1.51
30.58
14.66
0.66
11.68
0.5
3.29

703.35
1551629.77
88490.39
29985.26
2309107.24
88285.11
46692.69
2002.55
1748.8
113.5
1453.75
2213.77
101.26
66682.01
82.66
2031.6

595.98
5470.67
68.55
13.6
367339.66
818877.92
16825.85
49.79
6.55
0.16
249.95
389.08
633.21
61002.03
41.84
1256.31

547.84
6642.11
279.86
218.77
33824.02
62.84
37.53
854.35
11.36
0.49
4399.06
80.3
0.2
690.93
1.07
3.26

14.49
245.38
4.13
0.4
370.21
4.56
1.48
7.06
4.93
0.03
9.46
5.39
0.03
1.52
0.02
0.13

The features are described as follows:

• active days: the number of days the account has been ac-

tive.

• total received: the sum of ether received by the account.
• num received tx: the number of transactions that the ac-

count has received ether.

• inter acct received: the number of others interacted with
the account in the transactions that the account has re-
ceived ether.

• total output: the value of ether spent by the account.
• num output tx: the number of transactions that the ac-

count has spent ether.

• inter acct output: the number of others interacted with
the account in the transactions that the account has spent
ether.

• avg received: the average value of the ether received by

the account.

account.

• avg output day: the average value of the ether spent by

the account per day.

• avg output tx day: the average number of transactions

that the account has spent ether per day.

• times contract called: the times the account has called

the smart contract.

• times contract called day:

the times the account has

called the smart contract per day.

• num contract called: the number of contracts called by

the account.

C. Subgraph Details

For each type of account identity label (Exchange, ICOw-
allets, Mining, PhishHack), we sample the subgraphs of all
accounts with that label, as well as the same number of sub-
graphs of other types of accounts. We perform Topk sam-
pling for each labeled accounts according to the transaction
amounts ( ˜w) or interaction times (t), yielding two types of
subgraphs (“-w”, “-t”) for each account. We sample up to
20 neighbors for each account per hop, and the statistics of
sampled subgraphs (k = 20) are shown in Table 4.

Table 4: Statistics of sampled subgraphs from Ethereum for
accounts of different classes. |G| is the number of subgraphs,
Avg. |N | and Avg. |E| are the average number of nodes and
edges in subgraphs respectively, and |F | is the number of
features of accounts in subgraphs.

Dataset

Abbr.

|G|

Avg. |N | Avg. |E|

|F |

ETH-Exchange-w
ETH-Exchange-t
ETH-ICOwallets-w
ETH-ICOwallets-t
ETH-Mining-w
ETH-Mining-t
ETH-PhishHack-w
ETH-PhishHack-t

386
ETH-E-w
386
ETH-E-t
146
ETH-I-w
146
ETH-I-t
130
ETH-M-w
ETH-M-t
130
ETH-P-w 5070
5070
ETH-P-t

88.46
101.77
81.79
83.08
94.31
94.96
59.23
59.76

215.01
278.59
180.75
198.77
225.84
228.45
124.92
130.62

14885
14885
14885
14885
14885
14885
14885
14885

D. Details of Parameter Conﬁguration

For manual feature engineering, we design 16 manual fea-
tures, as described in Appendix B. For DeepWalks and
Struc2Vec, we set the length of walks to 20, the number of
walks to 40, and the context size to 3. For Node2Vec, we
set the return parameter p and in-out parameter q to 0.25
and 0.4, respectively. For all the above baselines , we imple-
ment account identity inference by using Logistic Regres-
sion classiﬁer.

For I2BGNN, we set the output dimensions of 2 hidden

layers both to 128.

• avg received day: the average value of ether received by

For all the baseline based on graph embedding, we set the

the account per day.

dimension of output embedding to 128.

Figure 7: The t-SNE visualization of the embedding features obtained by I2BGNN and our BlockGC in terms of four classes
of accounts.

I2BGNN  :  tI2BGNN  :  wBlockGC  :  tBlockGC  :  wE. More Results and Analysis
Obs. 4. Subgraphs sampled with interaction times bene-
ﬁts more. As we can see from Table 1, infering with sub-
graphs sampled according to t achieve better performance
than those sampled with ˜w in 20 out of 28 experiments
across all methods. Since that interaction times t reﬂects the
frequency of transactions and contract invocations, while the
transaction amounts ˜w refers only to the transaction process,
and the former reﬂects more information for identity infer-
ence.

Obs. 5. Contrastive self-supervision improve the gener-
alization of model in learning account features. As we
can see frim Figure 7, that accounts of different classes on
BlockGC with 2-dimensional embedding tend to be more
separated as compared to the embedding of I2BGNN, show-
ing clearer decision boundaries, which facilitate the classiﬁ-
cation of account identity labels. Moreover, the feature em-
bedding learned by BlockGC has a more uniform distribu-
tion, reﬂecting a more powerful generalization.

