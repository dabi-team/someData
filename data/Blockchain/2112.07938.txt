Analysis and Evaluation of Synchronous and
Asynchronous FLchain

Francesc Wilhelmi, Lorenza Giupponi and Paolo Dini

1

2
2
0
2

p
e
S
5

]

G
L
.
s
c
[

3
v
8
3
9
7
0
.
2
1
1
2
:
v
i
X
r
a

Abstract—Motivated by the heterogeneous nature of devices
participating in large-scale federated learning (FL) optimization,
we focus on an asynchronous server-less FL solution empowered
by blockchain technology. In contrast to mostly adopted FL
approaches, which assume synchronous operation, we advocate
an asynchronous method whereby model aggregation is done as
clients submit their local updates. The asynchronous setting ﬁts
well with the federated optimization idea in practical large-scale
settings with heterogeneous clients. Thus, it potentially leads to
higher efﬁciency in terms of communication overhead and idle
periods. To evaluate the learning completion delay of BC-enabled
FL, namely FLchain, we provide an analytical model based on
batch service queue theory. Furthermore, we provide simulation
results to assess the performance of both synchronous and
asynchronous mechanisms. Important aspects involved in the BC-
enabled FL optimization, such as the network size, link capacity,
or user requirements, are put together and analyzed. As our
results show, the synchronous setting leads to higher prediction
accuracy than the asynchronous case. Nevertheless, asynchronous
federated optimization provides much lower latency in many
cases, thus becoming an appealing solution for FL when dealing
with large datasets, tough timing constraints (e.g., near-real-time
applications), or highly varying training data.

Index
blockchain,
theory

Terms—Asynchronous/synchronous
operation,
federated learning, machine learning, queuing

I. INTRODUCTION

A. The rise of federated learning

Motivated by the decentralization of machine learning (ML)
training, federated learning (FL) has emerged as a popular
solution by providing low communication overhead and en-
hanced user privacy and security [1]. Different from traditional
ML methods, with training data centralized in data centers,
FL proposes an innovative scheme whereby training is held
at end devices (also referred to as clients) without the need
for data exchange. Instead, model parameters are exchanged
to optimize a global function distributively, which allows for
preserving privacy among participants.

Federated optimization has opened the door to an unprece-
dented way of sharing insights on data among interested par-
ties (e.g., users with sensitive information or organizations that
are reluctant to disclose proprietary data), thus accelerating the
proliferation of collaborative ML models with rich datasets.
Accordingly, FL may represent a key enabler for efﬁciently
and securely handling the vast quantity of information that is

(e-mail:

F. Wilhelmi

(e-mail:
fwilhelmi@cttc.cat)
paolo.dini@cttc.es) are with Centre Tecnol`ogic de Telecomunicacions
de Catalunya (CTTC/CERCA). This work was done when L. Giupponi
(lorenza.giupponi@cttc.es) was with CTTC.

P. Dini

and

now used for monitoring, controlling, and optimizing opera-
tions in different sectors. Examples can be found in different
areas, such as medicine [2], [3] and telecommunications [4].
In the telecom sector, the emergence of ML for networking
has led to an increasing need for handling massive amounts
of data [5], so FL can potentially reduce network congestion
while preserving privacy [6]. Some prominent use cases are
autonomous driving [7], unmanned aerial vehicle (UAV)-based
wireless networks [8], edge computing [9], or Internet-of-
Things (IoT) intelligence [10].

B. Motivation

Despite the huge interest in FL, its mainstream setting has a
number of disadvantages that prevent adoption in challenging
(real-world) scenarios with thousands to millions of hetero-
geneous nodes. Such limitations stem from the centralized
orchestration of FL, whereby a server is responsible for
gathering FL local updates, aggregating them to generate a
global model output, and sending the model back to clients.
To tackle the serious implications of centralization in FL
(summarized in Table I), blockchain has recently emerged
as an appealing solution thanks to key properties like decen-
tralization, immutability, traceability, and security [11]. First,
blockchain is based on distributed ledger technologies (DLT),
which allows disregarding the ﬁgure of the central server to
hand over the control to a decentralized network, with the
positive consequences that this brings to FL (e.g., improving
resilience, removing the single point of failure). As for the FL
operation, the decentralization property of blockchain is very
useful to mitigate the impact of stragglers [12], which are slow
nodes that hamper the learning procedure by incurring high
waiting delays. Blockchain naturally leads to an asynchronous
FL operation [13], whereby FL devices can concurrently
write and read the contents of a distributed ledger without
coordination, thus reducing the iteration time while providing
high accuracy [14], [15]. Likewise, together with transparency
and auditability, decentralized blockchains enhance democra-
tization and ensure fairness to the FL operation.

Additional beneﬁts of blockchain for FL are related to
security and privacy. In particular, a blockchain concatenates
blocks of information through advanced cryptography tech-
niques, which allows for providing immutability [16]. For
instance, by combining hashing techniques (e.g., SHA-256)
with digital signatures, mining mechanisms like Proof-of-
Work (PoW) allow the creation of tamper-proof sequences
of blocks. Thanks to the chaining of blocks through hashing,
any slight change in data generates an avalanche effect that

 
 
 
 
 
 
invalidates the rest of the chain. Immutability and transparency
are also very important to keep track of the training procedure
in FL, which enhances trustworthiness and contributes to
explainability. Other unresolved security issues in traditional
FL lie in data integrity and privacy. The fact is that mali-
cious nodes can inject incorrect data to hamper the training
operation [17] or can infer sensitive information from raw data
exchanged during the FL procedure [18]. Blockchain can solve
these issues in different manners. One prominent way stems
from collective monitoring, which would allow any participant
to detect and report malicious activities. In [19], for instance,
smart contracts are used for rewarding FL participants that
verify the model gradients submitted to the blockchain.

Finally, another important issue in FL is the lack of incen-
tives for participation, given that some FL devices may decide
not to participate in the training operation to save computa-
tional resources or not to help competitors by sharing insights
on their data. Such a lack of participation can have negative
implications on the scalability of FL, so as in the achieved
model’s accuracy [20]. In this regard, blockchain provides a
suitable environment to incentivize participation, as it is built
upon embedded economic incentives (e.g., transaction fees)
and programmable agreements [21]. Related to incentives in
blockchain-enabled FL, game theory has been shown to be an
appealing solution for optimizing aspects like model accuracy,
completion time, or energy consumption [22].

TABLE I
ISSUES IN CENTRALIZED FL ADDRESSED BY BLOCKCHAIN.

Issue in centralized FL

Solution provided by blockchain

Straggler nodes [12]

Lack of democratization and
learning bias [23]

Security bottleneck [18]

Participation of malicious nodes
(e.g., local model poisoning [17])

Privacy issues [18]

Lack of participation [20]

Decentralized and asynchronous
data writing/reading operations [14], [15]

Pure decentralized control [24]

Tamper-proof properties, data
integrity, and strong network resilience [25]
Data veriﬁcation and network consensus
for banning malicious participants [19]
Enhanced privacy via digital signatures
and anonymity [26]
Mechanisms for incentivizing participation
through rewards [21]

Due to the apparent beneﬁts provided by blockchain to FL,
its implementation has recently led to a new paradigm named
FLchain [27], [28], built on the foundations of decentraliza-
tion, democratization, security, scalability, and trust. The intro-
duction of blockchain to FL applications has, however, well-
documented weaknesses [29], including scalability, storage,
and security aspects. Although blockchain removes the ﬁgure
of the server and its associated computation and communica-
tion costs, it entails other non-negligible operational overheads
(e.g., related to mining [30]). For that reason, the analysis and
evaluation of blockchain FL are crucial for assessing the future
and feasibility of FLchain solutions.

C. Contributions

To contribute to shedding light on the feasibility of FLchain,
in this paper, we focus on performance and scalability aspects.
To this end, we ﬁrst develop an analytical model for charac-
terizing the end-to-end FLchain latency, including the new set

2

of delays incurred by blockchain technology. Based on the
latency model, we evaluate the server-less FLchain operation
and delve into the asynchronicity inherited from blockchain
decentralization. The asynchronous FLchain solution (namely,
a-FLchain) is compared with a synchronous implementation
of blockchain-enabled FL (namely, s-FLchain), which can
be seen as a realization of traditional FL, but without the
ﬁgure of the central server. The evaluation provided in this
paper allows studying the trade-off between the training time
and achieved accuracy. While s-FLchain potentially achieves
high accuracy, a-FLchain provides timely ML optimizations
in large, heterogeneous deployments. The contributions of this
paper are summarized as follows:

1) We provide a tutorial-type overview of the integration
of blockchain and FL technologies, namely FLchain.

2) We develop an analytical

framework to derive the
blockchain latency associated with FLchain, which can
be applied to both synchronous and asynchronous set-
tings. A key aspect of the proposed framework is the
batch-service queue model for measuring the queuing
delay in a blockchain system, which is essential
to
capture asynchronous model updates.

3) We evaluate the performance of FLchain solutions, in-
cluding the synchronous (s-FLchain) and asynchronous
(a-FLchain) training settings, through extensive simu-
lations. Our focus is on the learning completion time
and achieved accuracy. The analysis also serves to study
the effect that blockchain parameters have on server-less
FL. In particular, we adopt the EMNIST [31] dataset
to evaluate two different federated models, which range
from low to high complexity.

The rest of the paper is structured as follows: Section II
overviews the related work on implementations and character-
ization of FLchain. Section III introduces FL and blockchain
technologies, as well as the FLchain paradigm. Section IV
describes the system model and Section V provides the latency
framework for FLchain. Section VI provides numerical results
of FLchain. Section VII concludes the paper.

II. RELATED WORK

With the emergence of infrastructure-less network scenarios,
FL optimization is moving out of the central server to be
handled in a decentralized manner [32], [33]. To enable decen-
tralized server-less FL, blockchain technology has been intro-
duced as an appealing solution, providing trust, transparency,
and immutability [34], [35]. In this regard, the concept of
FLchain was ﬁrstly coined in [27], [28], where blockchain was
proposed to store model updates in blocks, therefore removing
the ﬁgure of the central server. FLchain has been embraced
for 5G and beyond applications [36], including use cases such
as data sharing in industrial IoT [37], enabling data-driven
cognitive computing in Industry 4.0 [38], or enhancing trust
in autonomous vehicles [39], [40] (e.g., mobility veriﬁcation,
trafﬁc prediction).

FLchain can be implemented both in synchronous or asyn-
chronous modes, depending on how local models are trans-
ferred and the degree of cooperation of FL devices. In the

synchronous setting, before generating a block, all the local
models need to be gathered from the set of selected FL
devices. This, while providing control, may entail high latency
overheads, as the FL iteration time is determined by the
slowest user. The straggler effect can be worsened in heteroge-
neous networks, where devices have different communication
and computation capabilities [41]. Moreover, generating large
blocks (including information from a huge number of users)
contributes to the instability of the blockchain, given that
forks are more likely to occur as the block propagation time
increases [42]. As a result, including many synchronized local
updates in a single block (as done in [43], [44]) may lead
to severe performance issues as the number of participating
FL nodes increases. Regarding asynchronous FLchain [45],
[46], it has been shown to provide signiﬁcant latency im-
provements in heterogeneous settings concerning synchronous
algorithms [47]. In fact, the FL asynchronous operation ﬁts
well with FLchain implementations, given the distributed
nature of blockchain systems (e.g., public blockchains running
PoW). For instance, the works in [36], [48] proposed a PoW-
based asynchronous FLchain solution for data sharing among
vehicles. In this scenario, real-time communication becomes
very challenging due to vehicles’ unavailability and potential
bandwidth constraints, so asynchronous operation is a better
ﬁt, compared to synchronous solutions.

In the literature, we ﬁnd several works analyzing and
evaluating various FLchain solutions. In [43], an end-to-end
latency model is provided by identifying the necessary steps
both for FL (compute model updates, transmit updates, and
model aggregation) and blockchain (mining, validation, and
block propagation). Similarly,
the work in [39] follows a
step analysis to derive the delay incurred by the blockchain
to FL training. Another relevant work is [49], which ana-
lyzes the transaction conﬁrmation latency of an asynchronous
blockchain-enabled FL application for IoT.

Different from existing works, our approach provides a more
detailed blockchain delay analysis, including the queuing delay
and the effect of both forks and timers, which have a notorious
impact on the transaction conﬁrmation time. Similarly to what
we previously proposed in [30], in this paper, we develop a
novel batch-service queue model to characterize the latency
of FLchain. Blockchain queue theory is an emerging ﬁeld
that has been recently introduced in [50], followed by the
approaches in [51]–[53]. The work in [50] proposed a batch
service queue model to understand the stochastic behavior
of the transaction-conﬁrmation process in Bitcoin. In a batch
service queue, packets leave the queue in batches, rather than
individually. This property is useful to capture the life-cycle
of transactions in a blockchain, which are gathered before
being served (mined). The batch-service queue approach has
been further extended and evaluated in [51], [52]. Unlike
the existing literature on batch-service queuing, our model
characterizes timers and forks. While timers are employed to
guarantee a maximum time between mined blocks, forks are a
direct consequence of the consensus protocol used by miners.
As a result, disregarding the effects of timers and forks may
lead to poor accuracy when deriving the blockchain queue
status (e.g., the number of transactions in it) and the expected

3

delay.

III. ENABLING SECURE, DECENTRALIZED FEDERATED
LEARNING THROUGH BLOCKCHAIN

A. Federated learning

Formally, the goal of an FL algorithm is to solve a su-
pervised learning optimization problem in a distributed (fed-
erated) manner. To that purpose, a set of K = {1, 2, ..., K}
clients attempt to simultaneously optimize the global model
parameters w ∈ Rd by using their local data Dk with size
Nk. Clients’ local losses, given by lk(w, Dk), are combined
to minimize a global ﬁnite-sum cost function l(·):

min
w∈Rd

l(w) = min
w∈Rd

K
(cid:88)

k=1

Nk
N

lk(w, Dk)

(1)

To address the optimization problem in Eq. (1), in traditional
FL, a server iteratively interacts with clients that, in each iter-
ation, provide local model updates that result from training on
local (unshared) datasets. In a FL iteration, the server pushes
a global model (e.g., parameters) to a set of clients, which
perform on-device training (e.g., training a neural network for
several epochs, based on different local data partitions) and
upload their model updates. Once model updates are collected
and aggregated by the server, a new global update is calculated.
More iterations are run until convergence.

The federated averaging (FedAvg) method [54] has been
widely adopted to address FL optimization, mostly because
of its effectiveness for non-convex problems and to its abil-
ity to reduce the communication overhead for synchronized
stochastic gradient descent (SGD). In FedAvg, FL clients run
multiple epochs of SGD before sending their locally computed
gradients to the server, which updates the global model ac-
cordingly. As for the aggregation of model parameters, this is
typically done by a central server (as illustrated in Fig. 1),
which collects and averages clients’ updates to generate a
global model. Beyond FedAvg, other optimization mechanisms
like FedSGD or FedProx have been proposed to improve on
convergence and efﬁciency aspects in FL [55].

Fig. 1. Model aggregation in federated learning. Clients submit local models
to the server, which are then aggregated through averaging.

Central server..............................Client 1Client 2Client KAnother important aspect of federated optimization lies
in the communication with/among clients (either for client-
server or decentralized D2D architectures), as convergence
depends on the acceptance of a general model over a typically
high number of different local distributions. For synchronized
methods to achieve consensus, assumptions such as IIDness
(statistical heterogeneity on clients’ data) or strong convexity
of the loss function (to be twice-continuously differentiable)
are typically required [9], [56], [57]. However, these properties
may not hold in more challenging scenarios, where datasets
are heterogeneous, clients’ availability is highly variable, or
updates are provided asynchronously [45], [58]. Under these
circumstances, it is challenging to provide convergence proofs,
but several works advocate for speeding up performance
through complementary tools like estimating the missing local
updates through DL [56].

B. Blockchain technology

Blockchain is a type of DLT that collects information in
the form of transactions, which are gathered in blocks that are
chained one after the other based on advanced cryptographic
techniques. In essence, each block uses the hash value from
the previous block to deﬁne its own structure (the ﬁrst block
is referred to as genesis block), thus leading to a tamper-
proof sequence of information. To agree on the status of the
chain (e.g., when adding a new block), a set of participating
nodes (typically referred to as miners) apply certain predeﬁned
operations (e.g., solving a mathematical puzzle), commonly
referred to as mining. In addition,
the implementation of
consensus protocols (e.g.,
longest chain) ensures that any
malicious change on data (e.g., for double-spending purposes)
would not be accepted by the majority.

Figure 2 summarizes the steps carried out to add transac-
tions to a blockchain. First (point 1, in blue), users submit
transactions to the miners, which are responsible for validation
and propagating them to the rest of the miners (point 2, in red).
Once a new block is ready to be appended to the blockchain,
miners run a given mining algorithm for deciding the node
responsible for updating the chain. In the example shown in
the ﬁgure, Miner #3 wins the mining competition and appends
a block to its ledger (point 3, in green). Finally, the newly
generated block is propagated throughout the P2P blockchain
network (point 4, in yellow). Regarding the mining operation,
it is important to notice that forks may occur if two or more
miners come across the solution of a block at the same time,
which may lead to ledger inconsistencies across miners. When
a fork occurs, the longest chain prevails and invalidates the
transactions included in secondary chains.

As noticed, mining and consensus are the core of blockchain
technology since they allow for securely and reliably ex-
changing data in a decentralized (and sometimes unreliable)
network. Some of the most important mining mechanisms are
Proof-of-Work (PoW) [11], Proof-of-Stake (PoS) [59], Prac-
tical Byzantine Fault Tolerance (PBFT) [60], or Ripple [61].
Throughout this work, we focus on PoW since it provides a
high level of decentralization and raises interesting challenges
in large-scale blockchain deployments.

4

Fig. 2. Overview of the procedure for mining transactions in a blockchain.

C. Blockchain for federated learning (FLchain)

The realization of server-less FL through blockchain tech-
nology is often referred to as FLchain [24], [27]. In FLchain,
a blockchain keeps track of the individual model updates
(e.g., gradients), which allows performing model aggregation
without using a central server. Notice that the global model
can be built either by the clients or by some intermediary
nodes (e.g., edge servers acting as miners), which allows for
a fully decentralized learning procedure. In [43], for instance,
the local FL model updates are included in blocks, to be later
aggregated by individual devices. In contrast, in [62], local
updates are ﬁrst spread and pre-processed by miners using
Gossip, and then global updates are recorded in blocks.

Taking into account the integration of blockchain into the
FL operation, we identify the following iterative steps, which
are executed either synchronously or asynchronously:

1) Local computation: using local data, each client up-
dates the model parameters by running a certain opti-
mization mechanism (e.g., SGD).

2) Transactions gathering: the local model updates gen-
erated by clients are sent
to miners in the form of
transactions, which are spread throughout the entire P2P
network.

3) Block generation: once enough valid transactions are
collected (determined by the maximum block size), or if
a maximum waiting time is exceeded, a candidate block
is generated to be mined.

4) Block mining: a mining operation (e.g., solving a puz-
zle) is applied to decide the next block to be appended
to the blockchain.

5) Block propagation: the mined block is propagated
throughout the P2P network. For the sake of simplicity,
we assume that blocks are simultaneously sent to all
the clients once they are valid and accepted by all the
miners.

6) Global model aggregation: using the information in-
cluded in accepted blocks (i.e., local model updates),
a global model update is derived. This step could be
done locally or by devices with enough computational
power (e.g., edge servers). In [43], [62], for instance,

M#2Ledger copy (M#2)HashPrev. hashNonceTimest.DifficultyMerkle rootPayloadBlock structureTransactions listM#3Ledger copy (M#4)Propagate transactions2Ledger copy (M#1)Miner 1(M#1)Submit  transactionLedger copy (M#3)Client 1 (C#1)C#2M#41C#3Mine a block3Propagate block4Trans. poolHeadereach client updates the global model by itself.

7) Block download: clients download the latest block
from the closest miner, which contain the global model
update, wt+1.

on their local data. In the traditional FL setting, local updates
are sent to the server. In contrast, for FLchain, the updates are
included in candidate blocks to be mined. For a single epoch,
the local model parameters are updated by client k as follows:

5

The FLchain operation from the perspective of a miner
is illustrated in Fig. 3, and applies for both synchronous
and asynchronous settings. Notice that local model training
is carried out by FL devices either in parallel (a-FLchain)
or along with miners’ operations (s-FLchain). In s-FLchain,
FL devices need to wait for the latest block to start
the
computation of a new local update. Likewise, the block size
(SB) needs to be adapted in s-FLchain to accommodate all
the participating clients in a single block (which contains the
global model). In a-FLchain, in contrast, clients perform local
computation and submit local updates asynchronously, thus
working in parallel to the blockchain. A new block is generated
when the maximum block size (SB) is reached, or when a
predeﬁned waiting timer (τ ) expires.

Fig. 3. Flowchart of FLchain miner’s operation.

IV. SYSTEM MODEL

A. Federated learning model

Let K (with size K = |K|) be a set of clients or learners
attempting to optimize a global model w ∈ Rd by minimizing
a loss function l(w). Each client k ∈ K has a local dataset
Dk of size Nk, which is a subset of the entire dataset (of
size N ) available across all the clients X = ∪K
k=1Dk. During
t ∈ {1, 2, ..., T } iterations, a subset of clients Kt ∈ K with
computational power ξFL
is sampled to compute local model
k
updates wt+1
, ∀k ∈ Kt, which are later aggregated to provide
a global model update wt+1. The FL operation stops after an
arbitrary horizon or when |l(wt) − l(wt−1)| ≤ ε, being ε ∈ R
a small error tolerance constant.

k

FedAvg with SGD is applied to compute the global model
parameters. Under this setting, clients run E epochs of SGD

wt+1

k = wt − ηl∇lk(wt, Dk),

(2)

where ηl is the learning rate for local updates (we use η for
global updates), and ∇lk(wt, Dk) is the average loss gradient
of client k, based on the local dataset Dk, with respect to the
global model wt. By aggregating the local updates wt+1
, ∀k ∈
Kt from the clients participating in an FL round, a new global
model is provided as follows:

k

wt+1 =

(cid:88)

k∈Kt

Nk
N

wt+1
k

,

(3)

Notice that the contribution of each participating client is
weighted by the size of its dataset, but other approaches are
possible. One prominent alternative is FedProx [41], which
performs model aggregation by considering partial contribu-
tions from heterogeneous nodes. FedProx has been shown to
be superior to FedAvg in the presence of stragglers.

B. FLChain model

We consider a public blockchain for publishing the FL local
parameters in the form of transactions, each of size Str, to
be aggregated in blocks of size SB (including headers). The
P2P network maintaining the blockchain is formed by a set
M = {1, 2, ..., M } miners, each one running PoW in parallel.
Miners are considered to be at the edge of the network, so that
they can collect transactions (i.e., model updates) from clients.
Moreover, communication among miners is done through a
mesh network. In PoW, the ﬁrst miner to correctly solve and
propagate the answer of a puzzle is allowed to create a new
block for the blockchain, which is to be accepted by the
majority of blockchain nodes. Other mechanisms in the litera-
ture [63] suit a wide range of applications (e.g., public/private
governance, small/big P2P networks, high/low transparency,
etc.), but PoW grants a high degree of decentralization and
offers robustness in massively operated blockchains.

As a result of the PoW operation,

the performance of
the blockchain can be hindered by forks. A fork is a split
of the blockchain into different states, and can potentially
compromise the overall agreement among participants, and
thus threaten stability. Forks typically occur when two or
more miners solve the nonce of a candidate block almost
simultaneously, i.e., before the block has been propagated
by a single miner. For a ﬁxed mining difﬁculty (D) and
miners’ computational power (ξM
m), assuming the synchronous
operation of M miners and given the block propagation delay
δbp (see the following sections for more details), we deﬁne the
fork probability as:

pfork = 1 − e−λ(M −1)δbp

(4)

Note that

the mining procedure, as widely adopted in
the literature [64], follows an exponential distribution with
parameter λ (the expected block generation time is 1/λ), so the

Update the localledger & propagatethe blockGather FL updatesfrom devices andother minersTransactionspoolStartIs max. block size reached?Did the timer  expire?Restart/initiatethe timerYesYesMine block withtransactionsCheck pool oftransactionsCheck the timerNoReceive blockfrom other minerNoFL modelaggregationSend model to FLdevicesInterrupttime between mined blocks can be represented by a Poisson
inter-arrival process.

The synchronous and the asynchronous versions of FLchain,
s-FLchain and a-FLchain, are described in detail in Algo-
rithm 1 and Algorithm 2, respectively.

Algorithm 1: Implementation of s-FLchain
1 Initialize: t = 1, ηl, η, wt = w0, ε
2 while |l(wt) − l(wt−1)| > ε do
3

Kt ∼ U(K)
for ∀k ∈ Kt (in parallel) do

(cid:46) sample random clients from K

4

5

6

7

8

9

10

11

Download wt
wt+1
SubmitLocalUpdate(Str, Ck)

k ← LocalUpdate(wt, E, ηl, Dk)

end
MineBlock(λ)
PropagateBlock(SB, CP2P)
wt+1 ← GlobalUpdate(wt, wt+1
t ← t + 1

k

, η)

12
13 end
14 LocalUpdate(wt, E, ηl, Dk): E epochs of SGD are

executed to optimize lk(·)

15 GlobalUpdate(wt, wt+1
local updates wt+1

k
to generate a global model wt
16 SubmitLocalUpdate(Str, Ck): transactions with size

, η): the server aggregates the

k

Str are sent through a link with capacity Ck
17 MineBlock(λ): blocks are mined with block

generation rate λ

18 PropagateBlock(SB, CP2P): blocks with size SB are

sent through a link with capacity CP2P

6

Algorithm 2: Implementation of a-FLchain
1 Initialize: t = 1, ηl, η, wt = w0, ε, τ
2 while |l(wt) − l(wt−1)| > ε do
3

k ← LocalUpdate(wt, E, ηl, Dk)

ut ← 0 Clients (asynchronously):
Download wt
wt+1
SubmitLocalUpdate(Str, Ck)
ut ← ut + 1
Blockchain (in parallel):
if |ut| ≥ SB or τ has expired then

MineBlock(λ)
PropagateBlock(min(|ut|, SB), CP2P)
wt+1 ← GlobalUpdate(wt, wt+1
, η)
t ← t + 1
Restart τ

k

else

Wait

4

5

6

7

8

9

10

11

12

13

14

15

16

end

17
18 end
19 LocalUpdate(wt, E, ηl, Dk): E epochs of SGD are

executed to optimize lk(·)

20 GlobalUpdate(wt, wt+1
local updates wt+1

k
to generate a global model wt
21 SubmitLocalUpdate(Str, Ck): transactions with size

, η): the server aggregates the

k

Str are sent through a link with capacity Ck
22 MineBlock(λ): blocks are mined with block

generation rate λ

23 PropagateBlock(SB, CP2P): blocks with size SB are

sent through a link with capacity CP2P

In s-FLchain, miners must wait for all the local updates
before building a block. As for a-FLchain, the waiting time is
affected by the transaction arrivals and the maximum waiting
time τ , among other parameters. In particular, we model the
arrivals process through a Poisson distribution with parameter
ν, which is a function of the clients’ activity (it depends
on the size of their local datasets and their computation and
communication capabilities). We deﬁne ν as follows:

C. Communication model

We consider P orthogonal wireless channels under fre-
quency division multiple access (FDMA)
for supporting
the communication among clients and miners. For a given
transmitter-receiver pair {i, j}, the data rate of the link Ri,j,
depends on the bandwidth bi allocated to the transmitter and
the signal-to-interference-plus-noise ratio (SINR), γj, at the
receiver:

(cid:114)

(cid:16)

K

ν =

E[δDL

B ] + NkξFL + E[δUL
tr

]

(cid:17)−1

,

Ri,j = bi log2(1 + γj)

(5)

The SINR at node j can be expressed as follows:

where δDL

B and δUL
tr

are random variables characterizing the
delays to download the global model in a block and to upload a
local update in the form of a transaction, respectively, and ξFL
is the required amount of CPU cycles to process a single FL
training data point. We would like to remark that the parameter
ν is hard to estimate because it depends on the transaction
conﬁrmation latency, which also depends on ν. Notice that
submitting a transaction (a model update) to the blockchain is
a blocking process from the point of view of a single node:
once a transaction is submitted, it needs to wait until the next
mined block before generating a new local update (a global
model update is required before computing and submitting the
next local update).

γj =

PiGi,j
∀l(cid:54)=i,j PlGl,j + σ0

(cid:80)

,

where Pi is the power used by transmitter i, Gi,j is the
channel gain, and σ0 is the noise power. Regarding the path-
loss model, the loss at distance d is given by:

P L(d) = Pt − P L0 + 10α log10(d) +

σ
2

+

d
10

ζ
2

,

(8)

where Pt is the power at the output of the transmitter’s
antenna, P L0 is the loss at the reference distance, α is the
path-loss exponent, σ is the shadowing factor, and ζ is the
obstacles factor. As for the links among miners in the P2P
network, they are assumed to have ﬁxed capacity.

(6)

(7)

7

time τ is exceeded. To capture the block ﬁlling latency in
the asynchronous case, we focus on queue theory and derive
the batch-service queue model illustrated in Fig. 4. As shown
in the ﬁgure, the block ﬁlling procedure is determined by
the block size SB, the arrivals rate ν, and by the maximum
waiting time τ . If the number of arrivals is enough for ﬁlling a
block before τ expires, then a block with size SB is generated
following PoW. Otherwise (the timer expires), a lower number
of transactions than SB is included to the candidate block.

Fig. 4. Batch-service queue model for a-FLchain.

We model the states of a ﬁnite queue (with size S) through
a Markov chain, with states indicating the queue occupancy
(number of transactions) just before a departure. In particular,
the state of the batch service queue at the n-th departure instant
is given by:

(cid:110)

qn = min

qn−1 + a(qn−1) − d(qn−1), S − d(qn−1)

, (11)

(cid:111)

where qn−1 is the state of the queue before the previous
departure, a(qn−1) is the number of new arrivals during the
inter-departure epoch, and d(qn−1) is the number of
last
packets delivered in a batch. The queue state after departures
is illustrated in Fig. 5, which considers a simple example of
a queue with SB = 2.

V. DELAY ANALYSIS OF BLOCKCHAIN-ENABLED
FEDERATED LEARNING

A. FLchain iteration latency

To measure the necessary time to perform the s-FLchain and
a-FLchain procedures deﬁned in Section III-C, we identify the
following delays:

1) Block ﬁlling delay (δbf): a block is ﬁlled with trans-
actions (i.e., local updates) from clients. This includes
local model computation (clients run gradient descent on
their own dataset to update the local model) and local
model upload (clients submit their local updates to the
closest miner).

2) Block generation delay (δbg): miners run PoW to ﬁnd
the block’s nonce, or until receiving a new valid mined
block.

3) Block propagation delay (δbp): mined blocks are prop-
agated throughout the entire P2P network. We assume
that all the miners receive the propagated blocks simul-
taneously.

4) Global model aggregation delay (δagg): a global model
update is generated by aggregating the local updates
from the latest mined block. The aggregation procedure
can either be done by clients (fully decentralized) or by
miners (edge computing-based). In case aggregation is
performed by clients, the block download procedure is
done ﬁrst.

5) Block download delay (δbd): clients download the latest
propagated block from miners, containing either the
local updates from the previous iteration or the updated
global model, depending on the model aggregation ap-
proach.

Gathering all the delays in FLchain, and by taking into
the negative implications of forks, we deﬁne the

account
expected iteration time (Titer) as:

Titer =

(δbf + δbg + δbp)
1 − pfork

+ δagg + δbd,

(9)

Notice that the block ﬁlling, the block generation, and the
block propagation operations are affected by forks. Therefore,
these steps may potentially be repeated in case conﬂicts arise.

B. Batch-service queue model for a-FLchain

In s-FLchain, all the devices are assumed to be synchro-
nized, so the time for gathering transactions in a block is
deterministic and depends on the slowest node:

δsync
bf = max
k∈K

(δk

c + δk

ul),

Fig. 5.

Inter-departure states in a batch-service queue with SB = 2.

(10)

c and δk

where δk
ul are the local computation and local model
upload delays, respectively, at the k-th client. These delays
depend on each device’s computation and communication
capabilities.

In contrast, in a-FLchain, transactions are collected asyn-
chronously, following a random distribution that depends on
the clients’ activity. In particular, a block is generated when
enough transactions have been collected by miners (which
depends on the block size SB), or when a maximum waiting

As shown in the ﬁgure, the queue status at the beginning
is q0 = 0 (the queue is empty). During the inter-departure
time, we observe an arrival, which occurred during the block
generation period. In this case, τ expired before noticing
any arrival during the block ﬁlling time, thus no packets are
included in the mined block. During the next inter-departure
period (starting from q1 = 1) we ﬁnd one more arrival that
completes the block, so block generation is performed before
the timer expires. Finally, a new arrival is noticed during the
mining time, so the queue ends up in q2 = 1.

Candidate blockClientsInter-arrival time...Mined blocksQueue sizeTransactionsready to be minedEmptyslotsTrans. inqueueArrivalsArrival(1 pkt)Departures (2 pkt)...tInter-departure time(initial state, SB = 2)Arrivals(2 pkt)The departure probability distribution πd is obtained by
solving πd = πdP (with normalization condition πd1T = 1),
where P is the transition-probability matrix for departure
states. Assuming that arrivals and departures follow indepen-
dent Poisson and exponential distributions, respectively, the
transition probabilities in P, for any pair of states (i, j), are
obtained as follows:

pi,j =






(cid:16) ν
λ+ν

λ
λ+ν

(cid:17)j−(i−d(i))

,

[i − d(i)]+ ≤ j < S − d(i)

1 − (cid:80)S−d(i)−1
l=0

pi,l,

j = S − d(i)

0,

otherwise

(12)

(cid:16) ν
λ+ν

λ
λ+ν

(cid:17)j−(i−d(i))

The ﬁrst part of Eq. (12),

, indicates
the probability of going from state i to j, provided that the
queue is not ﬁlled completely. This is obtained from the new
distribution resulting from the combination of Poisson arrivals
and exponentially distributed departures, i.e., (cid:82) ∞
0 e−λt (λt)j
·
µe−µtdt. The second part, 1 − (cid:80)S−d(i)−1
pi,l, instead, refers
to the single case where the maximum queue length is reached,
which also considers arrivals exceeding the total queue size.
Finally, the last case depicts the set of non-feasible transitions
(e.g., j ≥ S − d(i)).

l=0

j!

Next, we obtain the steady-state queue distribution πs by
differentiating between the cases where the timer expires (with
probability τ ) or not (τ ). First, the Poisson arrivals see time
averages (PASTA) property is used when the timer does not
expire, i.e., when blocks are ﬁlled with transactions. The cases
where the timer expires are treated differently, and require to
consider the probability of observing each possible number of
packets in the queue on the conditional τ time is required to
prepare a block. With that, we compute πs for states s < S
as follows:

πs =

1
νE[T ]

s
(cid:88)

(cid:18)

(cid:16)

ς τ,i

πd
i

S−d(i)
(cid:88)

(cid:17)

pi,j

j=s−d(i)+1

i=0
(cid:16) SB−1
(cid:88)

+ ςτ,i

P(n = j − i|τ )(cid:0)

S−d(j−i)
(cid:88)

(cid:1)(cid:17)(cid:19)

,

pj,l

j=i

l=s−d(j−i)+1

where E[T ] is the expected inter-departure time, ςτ,i is the
timer expiration probability from departure state i (ς τ,i =
1−ςτ,i), which is non-zero for i < SB. The steady-state proba-
bility of ﬁnding the queue full is given by πS = 1−(cid:80)S−1
s=0 πs.
Finally, using Little’s law [65], the expected queue delay is

computed as:

δasync
bf =

(cid:80)S

s=0 sπs
ν(1 − πS)

(14)

Notice, as well, that all the transactions included in the
block(s) involved in forks are added twice to the blockchain.
This is a worst-case scenario that has implications in the queue
occupancy, thus contributing to increasing the queuing delay.
Nevertheless, the consistency among the set of transactions
proposed by each miner relies on the underlying commu-
nication capabilities (i.e., how transactions are propagated

8

throughout the P2P network), on the behavior of miners (e.g.,
malicious miners may temporarily hold transactions to mine
the next block with higher probability), and on the incentives
offered by each user willing to submit a transaction (e.g.,
paying a fee for including a transaction in the next block).

VI. PERFORMANCE EVALUATION

In this section, we evaluate the performance of FLchain and
provide insights on its suitability.1 First, we analyze aspects
of the blockchain and assess the sensitivity of this technology
on various important parameters, such as the arrivals rate
(ν), the block size (SB), or the block generation rate (λ).
Then, we evaluate both s-FLchain and a-FLchain solutions.
The simulation parameters are collected in Table II.

TABLE II
SIMULATION PARAMETERS.

Description

Parameter
Str
Sh
M
τ
S

Transaction size
Block header size
Number of miners
Max. waiting time
Queue length
dmin/dmax Min/max distance client-BS
Bandwidth
Carrier frequency
Antenna gain
Transmit power
Loss at the reference dist.
Path-loss exponent
Shadowing factor
Obstacles factor
Ground noise
Capacity P2P links
Learning algorithm
Number of hidden layers
Activation function
Optimizer
Loss function
Learning rate (local/global)
Epochs number
Batch size
CPU cycles to process a data point
Clients’ clock speed

b
Fc
G
Pt
P L0
α
σ
ζ
σ0
CP2P
A
hl
a
o
l
ηl/η
E
B
ξFL
ξFL
k

n

i
a
h
c
k
c
o
l
B

n
o
i
t
a
c
i
n
u
m
m
o
C

g
n
i
n
r
a
e
L

.

d
e
F

Value
5 Kbits
200 Kbits
10
1,000 s
1,000
0 / 4.15 m
180 kHz
2 GHz
0 dBi
20 dBm
5 dB
4.4
9.5
30
-95 dBm
5 Mbps
Neural Network
2
ReLU
SGD
Cat. Cross-Entropy
0.01/1
5
20
10−5
1 GHz

(13)

A. Blockchain queue delay

Fig. 6 shows the average queue performance, including the
expected delay, average occupancy, and fork probability, for
different block generation rates, block sizes, and arrival rates.
As expected, the queue occupancy decreases as λ increases,
which allows processing transactions faster. However, the fork
probability also increases with λ, which may compromise the
performance of the blockchain.

Alternatively, Fig. 7 analyzes the impact of the block size on
the queuing delay, for representative ν (low and high trafﬁc,
respectively) and λ values ({0.05, 0.2, 1} Hz). As shown in the
ﬁgure, the behavior of the queue delay differs for different ν
values. On the one hand, for a high arrivals rate (e.g., ν = 20),
the queue delay is very high for short block sizes, as the queue
is ﬁlled with transactions that cannot be delivered in time. The
effect is the opposite for a few arrivals (ν = 0.2), where the

1All the source code used in this project is open-access and can be ac-
cessed at www.github.com/fwilhelmi/blockchain enabled federated learning,
commit: 648ead5. Accessed: July 29, 2022.

9

The fact is that transactions involved in forks need to be re-
included in the queue, which becomes critical as λ increases.
In contrast, high CP2P values allow mitigating the effect of
forks and reducing the transaction conﬁrmation latency.

Finally, Fig. 9 plots the transaction conﬁrmation latency as
a function of the block size and the arrivals rate. In particular,
we show the results obtained by using λ = {0.05, 0.2, 1} Hz
with CP2P = 5 Mbps.

Fig. 6. Mean blockchain queuing delay as a function of λ. The queue
occupancy and the fork probability (pfork) are also plotted. Different arrival
rates ν and block sizes SB are considered and averaged in each data point.

queue delay increases with the block size because the queued
transactions need to wait until a block is ﬁlled.

Fig. 7. Blockchain queue delay as a function of the block size (SB). Different
ν (in transactions per second) and λ values are considered.

B. Blockchain transaction conﬁrmation latency

We focus on the transaction conﬁrmation latency, which
includes transmission times (transaction and block propaga-
tion) and the re-transmissions caused by forks, as captured
in (9). Fig. 8 illustrates the blockchain’s average transaction
conﬁrmation latency (TBC), together with the fork probability,
for different block generation rates. In addition, different
blockchain P2P network capacities have been displayed, in-
cluding capacities of CP2P = {5, 20, 50} Mbps.

Fig. 8. Blockchain transaction conﬁrmation latency (TBC) and fork probability
as a function of the block generation rate (λ).

Fig. 9. Blockchain transaction conﬁrmation latency (TBC) as a function of
the block size (SB) and the arrivals rate (ν), for λ = {0.05, 0.2, 1} Hz.

Again, the relationship between the transaction conﬁrmation
latency and the block size behaves differently for different
block generation ratios. For a low mining capacity (i.e.,
λ = 0.05 Hz), using a small block size leads to very high
delays, so that queue overﬂow occurs when heavy loads (e.g.,
ν = {2, 20} transactions per second) cannot be absorbed. In
contrast, for higher λ values, the behavior varies and the trade-
off between the block size and the fork probability becomes
more evident. In any case, the proper election of the block
size is essential for the sake of efﬁciency.

C. s-FLchain vs a-FLchain

for

To evaluate the s-FLchain and a-FLchain solutions, we
use a popular dataset
federated image classiﬁcation:
EMNIST [31]. The EMNIST dataset contains images of hand-
written digits, distributed across 3,383 different users. More
speciﬁcally, it includes 341,873 training examples and 40,832
test samples for evaluation. We solve the classiﬁcation task
using two different deep learning models. In such a way,
we characterize two classes of problems, ranging from low
to high complexity. For that purpose, we use a simple out-
of-the-box feed-forward neural network (FNN) and a more
complex convolutional neural network (CNN) [66] to solve
the handwritten image recognition problem posed by EMNIST.
These two models, as a result of their size,2 are expected to
be impacted differently by the blockchain. Table III provides
a summary of the models’ architecture.

In our evaluation, we split the dataset into several partitions
to focus on a total of K = {10, 50, 100, 200} random clients.
Furthermore, to assess the impact of the asynchronous method,

Similar to the queue delay in Fig. 6, the blockchain trans-
action conﬁrmation latency has a concave shape, but now the
effect of forks is exacerbated (especially for low capacities).

2The proposed FNN and CNN models have 203,530 and 2,374,506 param-
eters, respectively. Considering that each parameter can be represented by a
2-bytes int, their corresponding size is 0.407 MB and 4.749 MB.

TABLE III
SUMMARY OF MODELS’ ARCHITECTURE.

Model

Layer (activation) Output shape

FNN

CNN

Input
Dense (ReLU)
Output (Softmax)
Input
Conv2D (ReLU)
Conv2D (ReLU)
Dense (ReLU)
Output (Softmax)

784
256
10
784
(26, 26, 32)
(24, 24, 32)
512
10

# of param.
0
299,969
2,570
0
320
9,248
2,359,808
5,130

we adjust the block size in each FL round to consider smaller
subsets of users. So, we deﬁne Υ as the percentage of users
required to construct a block, assuming that all
the local
updates have the same size. Notice that the synchronized case
corresponds to Υ = 100% since all the considered clients’
updates are included in a single block. The timer τ is set to
an arbitrarily high value to disregard its effect and focus on
the block size only.

Global model evaluation is carried out throughout each FL
round at Keval = 50 different clients, which are independent
of K and are randomly sampled from the entire dataset in
each iteration. Furthermore, we use two variations of the
EMNIST dataset, corresponding to independent and identically
distributed (IID) and non-IID properties. Clients typically have
a rich number of samples for all the classes in the original
dataset [48], so we break such an IIDness and restrict each
client dataset to 3 classes only (uniformly selected at random)
in the non-IID case. The IID case includes all the original
samples in each client, containing data from up to 10 classes.
In summary, each client has an average of 101.02 (30.32 in the
non-IID setting) and 12.06 images for training and evaluation,
respectively.

Fig. 10 shows the mean evaluation accuracy achieved by the
FNN and CNN models throughout 200 FL rounds, for both s-
FLchain and a-FLchain settings, and IID and non-IID datasets
distributions. Furthermore, we provide the baseline results
obtained by the centralized counterparts of FNN and CNN,
trained using the entire EMNIST dataset (i.e., taking samples
the clients) in a single location. The centralized
from all
counterpart of each model uses the same architecture and
hyper-parameters as in the federated settings. However, it is
important to notice that the centralized setting is expected to
provide higher accuracy than the federated one as a result of
using all the examples in the dataset for training. In FL, in
contrast, a smaller number of clients is sampled overall.

As shown in Fig. 10(a), the FNN achieves an acceptable
accuracy for all the block sizes (represented by Υ) in the IID
setting, which is improved as K increases. However, in the
non-IID case, the performance of FNN drops dramatically,
especially for low K and Υ values (e.g., for K = 10 and
Υ = 10%). As for the performance achieved by the CNN
(see Fig. 10(b)), it is very close to the centralized baseline
when data is IID. Nevertheless, the performance drops in the
non-IID setting are not as meaningful as for the FNN model.
The analyzed models have been shown to achieve a higher
accuracy as Υ increases, being s-FLchain the best-performing
method. Let us now focus on the blockchain latency and the

10

(a)

(b)

Fig. 10. Mean evaluation accuracy obtained by FNN and CNN models during
the last 50 of 200 FL rounds on EMNIST: (a) FNN, (b) CNN. The IID (dashed
bars) and non-IID (solid bars) versions of the EMNIST dataset are evaluated
for a different number of clients K and client sub-sampling percentages Υ.
The results of the centralized counterpart of each mechanism are represented
by a black dashed line.

temporal performance obtained by each model throughout the
considered R = 200 FL rounds. For that, we use the model
provided in Section V to compute the iteration time in each of
the applied mechanisms for each block size. Taking this into
account, Fig. 11 illustrates the evaluation accuracy and loss
with respect to the time each method takes to complete the
200 rounds, for both IID and non-IID settings.

As shown in Fig. 11, the longer the block size (determined
by the total number of users, K, and the percentage of
users participating in each round, Υ), the higher the training
time for completing the considered 200 FL rounds. This
makes a-FLchain more efﬁcient than s-FLchain in terms of
iteration time (especially for low Υ values), provided that the
synchronized method requires a lot of time to include all the
local updates to a single block. However, there is a trade-
off between accuracy and training time. Regarding the models
used, we observe that the CNN achieves higher accuracy in
all the cases than FNN (see Fig. 11(a) and Fig. 11(b)), but
at the cost of requiring much more time for exchanging the
models through the blockchain. Interestingly, the CNN is able
to provide acceptable accuracy in the non-IID setting (see
Fig. 11(d)), even for small block sizes (e.g., K = 10 and
Υ = 25%). This is not the case for the FNN model (see
Fig. 11(c)), which performs poorly in the non-IID setting when
the block size is small.

Next, to further analyze the accuracy versus training time

11

(a)

(c)

(b)

(d)

Fig. 11. Evaluation accuracy obtained by s-FLchain and a-FLchain on the EMNIST dataset after T = 200 rounds, for different number of clients K and
client sub-sampling percentages Υ: (a) FNN (IID), (b) CNN (IID), (c) FNN (non-IID), (d) CNN (non-IID). The centralized counterpart of each method is
shown by a black dashed line.

TABLE IV
AVERAGE ACCURACY PER SECOND ACHIEVED BY THE FNN AND CNN MODELS IN EMNIST IID (EMNIST NON-IID).

K = 10

K = 50

K = 100

K = 200

FNN
CNN
FNN
CNN
FNN
CNN
FNN
CNN

Υ = 10%
86 · 10−3 (26.5 · 10−2)
10.89 · 10−2 (48.9 · 10−2)
15.3 · 10−2 (4.7 · 10−2)
19 · 10−2 (8.7 · 10−2)
8 · 10−2 (2.5 · 10−2)
10.1 · 10−2 (4.5 · 10−2)
4 · 10−2 (1.2 · 10−2)
5.1 · 10−2 (2.3 · 10−2)

Υ = 25%
21.3 · 10−2 (7.1 · 10−2)
26 · 10−2 (15.5 · 10−2)
5.6 · 10−2 (1.9 · 10−2)
6.8 · 10−2 (4 · 10−2)
3 · 10−2 (1 · 10−2)
3.7 · 10−2 (2.2 · 10−2)
1.5 · 10−2 (5 · 10−3)
1.9 · 10−2 (1.1 · 10−2)

Block size

Υ = 50%
11.2 · 10−2 (4.9 · 10−2)
13.2 · 10−2 (8.1 · 10−2)
2.8 · 10−2 (1.2 · 10−2)
3.3 · 10−2 (2 · 10−2)
1.4 · 10−2 (6 · 10−3)
1.7 · 10−2 (1 · 10−2)
7 · 10−3 (3 · 10−3)
8 · 10−3 (5 · 10−3)

Υ = 75%
6.2 · 10−2 (2.9 · 10−2)
7.4 · 10−2 (4.9 · 10−2)
1.6 · 10−2 (8 · 10−3)
1.9 · 10−2 (1.3 · 10−2)
8 · 10−3 (4 · 10−3)
1 · 10−2 (6 · 10−3)
4 · 10−3 (1 · 10−3)
4 · 10−3 (3 · 10−3)

Υ = 100%
4.4 · 10−2 (2.2 · 10−2)
5.3 · 10−2 (3.4 · 10−2)
1.2 · 10−2 (6 · 10−3)
1.4 · 10−2 (9 · 10−3)
6 · 10−3 (3 · 10−3)
7 · 10−3 (5 · 10−3)
2 · 10−3 (1 · 10−3)
3 · 10−3 (2 · 10−3)

trade-off, Table IV provides the results on the training efﬁ-
ciency achieved by each method in every scenario. The train-
ing efﬁciency is computed as the average accuracy achieved
by each method divided by the iteration time.

Table IV highlights the efﬁciency of the asynchronous
mechanism, provided that efﬁciency decreases as K and Υ in-
crease. For instance, the highest achieved efﬁciency is obtained
by the FNN in the scenario where a-FLchain with Υ = 10%
is applied for K = 10 users. This is an important conclusion
that suggests that a-FLchain is an appealing solution when
dealing with large distributed datasets in FL. In those cases,

maintaining a strict synchronization among FL clients is coun-
terproductive in terms of efﬁciency. However, the accuracy-
time trade-off must be carefully considered when selecting a
model and the type of blockchain to be used. Regarding the
application of more complex models in FLchain, the CNN is
shown to be more efﬁcient than the FNN in a more challenging
situation like the non-IID setting, where the simplicity of the
FNN fails at capturing insightful patterns from data.

Despite more complex models can provide higher accuracy
than simpler ones, as shown with the examples of FNN
and CNN models, their size may inﬂict very high delays to

the training procedure. In our evaluation, the most complex
considered model was the CNN, which has a size of 4.749 MB.
Nevertheless, much more complex deep learning models are
used nowadays to solve more challenging problems (e.g.,
CIFAR-100 [67]). Two prominent examples of very deep mod-
els are residual neural networks (ResNet) and visual geometry
group (VGG) [68]. The Resnet50 and VGG19 implementa-
tions use 23,792,612 and 39,316,644 parameters, respectively,
thus requiring 47.58 MB and 78.63 MB of storage. These
values throw into question the feasible implementation of
very complex models in federated settings, as they entail
a huge communication overhead. Figure 12 shows the FL
iteration delay of each of the abovementioned ML models for
different numbers of participating users in FL. For the sake of
illustration, the iteration time is shown on a logarithmic scale.

12

revealing the accuracy versus training time trade-off. In this
regard, the development of high-performing lightweight ML
models becomes of utmost importance to truly enable the
distributed learning paradigm.

Future research directions include innovative mechanisms
and architectural solutions for FLchain, able to address the
challenges raised by either blockchain implementations (e.g.,
capacity,
latency) or the device and data heterogeneity in
asynchronous training. Another remarkable topic for future
research is on the evaluation of the security properties of
the FLchain solution. Blockchain security is a broad topic
that involves many operations (e.g., cryptography of users’
identities, decentralized consensus) and its application to FL
can satisfy multiple purposes (e.g., validation of models, users’
reputation, mitigating poisoning attacks). Furthermore, de-
pending on the adopted blockchain solution, different security
properties would be granted.

ACKNOWLEDGMENT

This work was funded by the IN CERCA grant from
the Secretaria d’Universitats
i Recerca del departament
d’Empresa i Coneixement de la Generalitat de Catalunya,
and partially from the Spanish grant PID2020-113832RB-
C22(ORIGIN)/MCIN/AEI/10.13039/5011000110, by the grant
CHIST-ERA-20-SICT-004, by the Spanish grant PCI2021-
122043-2A/AEI/10.13039/501100011033.

Fig. 12. Comparison of the iteration delays achieved by different ML models
in the blockchained FL setting.

REFERENCES

As shown, deep learning models result in very high de-
lays when trained through a blockchained FL solution, being
VGG19 up to four levels of magnitude with respect to FNN.
The high differences are due to the big overheads experienced
in the distributed blockchain system, which include phe-
nomena like forks, whereby the conﬁrmation time increases
exponentially with the size of the exchanged transactions.

VII. CONCLUSIONS

This paper has addressed an emerging topic regarding
distributed federated optimization and has proposed the usage
of blockchain technology to realize it in a secure, transpar-
ent, and reliable manner. To assess the feasibility of this
blockchain-enabled solution, a blockchain latency framework
has been developed, including a novel queuing model suit-
able to blockchain technology. Based on this framework,
synchronous and asynchronous methods (s-FLchain and a-
FLchain) are evaluated in terms of accuracy and latency.
While the synchronous version of models like FNN and CNN
allow obtaining a high accuracy for both IID and non-IID
datasets, their iteration time becomes very high as the number
of participating users increases. This prevents the adoption of
this kind of mechanism in massive deployments, thus lacking
scalability. In contrast,
the asynchronous FL optimization
solution keeps communication overheads low, as it allows
for reducing the number of local updates included in each
iteration. However, the accuracy of asynchronous models is
tied to the contributions made by individual FL devices, thus

[1] J. Koneˇcn`y, H. B. McMahan, F. X. Yu, P. Richt´arik, A. T. Suresh, and
D. Bacon, “Federated learning: Strategies for improving communication
efﬁciency,” arXiv preprint arXiv:1610.05492, 2016.

[2] Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, “Fedhealth: A federated
transfer learning framework for wearable healthcare,” IEEE Intelligent
Systems, vol. 35, no. 4, pp. 83–93, 2020.

[3] D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, and A. Y.
Zomaya, “Federated learning for covid-19 detection with generative
adversarial networks in edge cloud computing,” IEEE Internet of Things
Journal, 2021.

[4] W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks:
A comprehensive survey,” IEEE Comm. Surveys & Tutorials, vol. 22,
no. 3, pp. 2031–2063, 2020.

[5] F. Wilhelmi, S. Barrachina-Munoz, B. Bellalta, C. Cano, A. Jonsson,
and V. Ram, “A ﬂexible machine-learning-aware architecture for future
wlans,” IEEE Comm. Mag., vol. 58, no. 3, pp. 25–31, 2020.

[6] S. Niknam, H. S. Dhillon, and J. H. Reed, “Federated learning for
wireless communications: Motivation, opportunities, and challenges,”
IEEE Comm. Mag., vol. 58, no. 6, pp. 46–51, 2020.

[7] Z. Du, C. Wu, T. Yoshinaga, K.-L. A. Yau, Y. Ji, and J. Li, “Federated
learning for vehicular internet of things: Recent advances and open
issues,” IEEE Open Journal of the Computer Society, vol. 1, pp. 45–61,
2020.

[8] B. Brik, A. Ksentini, and M. Bouaziz, “Federated learning for uavs-
enabled wireless networks: Use cases, challenges, and open problems,”
IEEE Access, vol. 8, pp. 53 841–53 849, 2020.

[9] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and
K. Chan, “Adaptive federated learning in resource constrained edge
computing systems,” IEEE JSAC, vol. 37, no. 6, pp. 1205–1221, 2019.
[10] J. Mills, J. Hu, and G. Min, “Communication-efﬁcient federated learning
for wireless edge intelligence in iot,” IEEE Internet Things J., vol. 7,
no. 7, pp. 5986–5994, 2019.

[11] S. Nakamoto, “Bitcoin: A Peer-to-Peer electronic cash system,” Tech.

Rep., 2008.

[12] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” IEEE Signal Processing
Magazine, vol. 37, no. 3, pp. 50–60, 2020.

[13] M. R. Sprague, A. Jalalirad, M. Scavuzzo, C. Capota, M. Neun,
L. Do, and M. Kopp, “Asynchronous federated learning for geospatial
applications,” in Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer, 2018, pp. 21–28.
[14] H. R. Feyzmahdavian, A. Aytekin, and M. Johansson, “An asynchronous
mini-batch algorithm for regularized stochastic optimization,” IEEE
Trans. Autom. Control, vol. 61, no. 12, pp. 3740–3754, 2016.

[15] C. Xu, Y. Qu, P. W. Eklund, Y. Xiang, and L. Gao, “Baﬂ: an efﬁcient
blockchain-based asynchronous federated learning framework,” in 2021
IEEE Symposium on Computers and Communications (ISCC).
IEEE,
2021, pp. 1–6.

[16] D. C. Nguyen, P. N. Pathirana, M. Ding, and A. Seneviratne, “Bedge-
health: A decentralized architecture for edge-based iomt networks using
blockchain,” IEEE Internet of Things Journal, vol. 8, no. 14, pp. 11 743–
11 757, 2021.

[17] M. Fang, X. Cao, J. Jia, and N. Gong, “Local model poisoning attacks
to {Byzantine-Robust} federated learning,” in 29th USENIX Security
Symposium (USENIX Security 20), 2020, pp. 1605–1622.

[18] V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha,
and G. Srivastava, “A survey on security and privacy of federated
learning,” Future Generation Computer Systems, vol. 115, pp. 619–640,
2021.

[19] D. C. Nguyen, P. N. Pathirana, M. Ding, and A. Seneviratne,
“Blockchain for secure ehrs sharing of mobile cloud based e-health
systems,” IEEE access, vol. 7, pp. 66 792–66 806, 2019.

[20] Y. Zhan, P. Li, Z. Qu, D. Zeng, and S. Guo, “A learning-based incentive
mechanism for federated learning,” IEEE Internet of Things Journal,
vol. 7, no. 7, pp. 6360–6368, 2020.

[21] N. B. Somy, K. Kannan, V. Arya, S. Hans, A. Singh, P. Lohia, and
S. Mehta, “Ownership preserving ai market places using blockchain,”
in 2019 IEEE International Conference on Blockchain (Blockchain).
IEEE, 2019, pp. 156–165.

[22] X. Tu, K. Zhu, N. C. Luong, D. Niyato, Y. Zhang, and J. Li, “Incentive
mechanisms for federated learning: From economic and game theoretic
perspective,” IEEE Transactions on Cognitive Communications and
Networking, 2022.

[23] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N.
Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings et al.,
“Advances and open problems in federated learning,” Foundations and
Trends® in Machine Learning, vol. 14, no. 1–2, pp. 1–210, 2021.
[24] D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le,
A. Seneviratne, J. Li, D. Niyato, and H. V. Poor, “Federated learning
meets blockchain in edge computing: Opportunities and challenges,”
IEEE Internet Things J., 2021.

[25] X. Li, P. Jiang, T. Chen, X. Luo, and Q. Wen, “A survey on the security
of blockchain systems,” Future Generation Computer Systems, vol. 107,
pp. 841–853, 2020.

[26] Y. Zhao, J. Zhao, L. Jiang, R. Tan, D. Niyato, Z. Li, L. Lyu, and Y. Liu,
“Privacy-preserving blockchain-based federated learning for iot devices,”
IEEE Internet of Things Journal, vol. 8, no. 3, pp. 1817–1829, 2020.

[27] U. Majeed and C. S. Hong, “Flchain: Federated learning via mec-enabled

blockchain network,” in 2019 APNOMS.

IEEE, 2019, pp. 1–4.

[28] X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu, “Flchain: A blockchain
for auditable federated learning with trust and incentive,” in 2019
BIGCOM.

IEEE, 2019, pp. 151–159.

[29] Z. Zheng, S. Xie, H.-N. Dai, X. Chen, and H. Wang, “Blockchain
challenges and opportunities: A survey,” Int. Journal of Web and Grid
Services, vol. 14, no. 4, pp. 352–375, 2018.

[30] F. Wilhelmi and L. Giupponi, “Discrete-time analysis of wireless

blockchain networks,” arXiv preprint arXiv:2104.05586, 2021.

[31] G. Cohen, S. Afshar, J. Tapson, and A. V. Schaik, “Emnist: Extending
mnist to handwritten letters,” 2017 International Joint Conference on
Neural Networks (IJCNN), 2017.

[32] A. Lalitha, S. Shekhar, T. Javidi, and F. Koushanfar, “Fully decentralized

federated learning,” in NeurIPS, 2018.

[33] I. Heged˝us, G. Danner, and M. Jelasity, “Decentralized learning works:
An empirical comparison of gossip learning and federated learning,”
Journal of Parallel and Distributed Computing, vol. 148, pp. 109–124,
2021.

[34] Y. Liu, J. Peng, J. Kang, A. M. Iliyasu, D. Niyato, and A. A. Abd El-
Latif, “A secure federated learning framework for 5g networks,” IEEE
Wireless Commun., vol. 27, no. 4, pp. 24–31, 2020.

[35] D. Hou, J. Zhang, K. L. Man, J. Ma, and Z. Peng, “A systematic
literature review of blockchain-based federated learning: Architectures,
applications and issues,” in 2021 ICTC.

IEEE, 2021, pp. 302–307.

13

[36] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, “Blockchain
and federated learning for 5g beyond,” IEEE Network, vol. 35, no. 1,
pp. 219–225, 2020.

[37] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, “Blockchain and
federated learning for privacy-preserved data sharing in industrial iot,”
IEEE Trans. Ind. Informat., vol. 16, no. 6, pp. 4177–4186, 2019.
[38] Y. Qu, S. R. Pokhrel, S. Garg, L. Gao, and Y. Xiang, “A blockchained
federated learning framework for cognitive computing in industry 4.0
networks,” IEEE Trans. Ind. Informat., vol. 17, no. 4, pp. 2964–2973,
2020.

[39] S. R. Pokhrel and J. Choi, “Federated learning with blockchain for
autonomous vehicles: Analysis and design challenges,” IEEE Trans.
Commun., vol. 68, no. 8, pp. 4734–4746, 2020.

[40] Y. Qi, M. S. Hossain, J. Nie, and X. Li, “Privacy-preserving blockchain-
based federated learning for trafﬁc ﬂow prediction,” Future Generation
Computer Systems, vol. 117, pp. 328–337, 2021.

[41] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,
“Federated optimization in heterogeneous networks,” Proceedings of
Machine Learning and Systems, vol. 2, pp. 429–450, 2020.

[42] F. Wilhelmi and L. Giupponi, “On the performance of blockchain-
enabled ran-as-a-service in beyond 5g networks,” arXiv preprint
arXiv:2105.14221, 2021.

[43] H. Kim, J. Park, M. Bennis, and S.-L. Kim, “Blockchained on-device
federated learning,” IEEE Comm. Lett., vol. 24, no. 6, pp. 1279–1283,
2019.

[44] Y. Liu, Y. Qu, C. Xu, Z. Hao, and B. Gu, “Blockchain-enabled
asynchronous federated learning in edge computing,” Sensors, vol. 21,
no. 10, p. 3335, 2021.

[45] C. Xie, S. Koyejo, and I. Gupta, “Asynchronous federated optimization,”

arXiv preprint arXiv:1903.03934, 2019.

[46] C. Xu, Y. Qu, Y. Xiang, and L. Gao, “Asynchronous federated learning
on heterogeneous devices: A survey,” arXiv preprint arXiv:2109.04269,
2021.

[47] X. Lian, W. Zhang, C. Zhang, and J. Liu, “Asynchronous decentralized
parallel stochastic gradient descent,” in International Conference on
Machine Learning. PMLR, 2018, pp. 3043–3052.

[48] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, “Blockchain
empowered asynchronous federated learning for secure data sharing in
internet of vehicles,” IEEE Trans. Veh. Technol., vol. 69, no. 4, pp.
4298–4311, 2020.

[49] L. Feng, Y. Zhao, S. Guo, X. Qiu, W. Li, and P. Yu, “Blockchain-based
asynchronous federated learning for internet of things,” IEEE Trans.
Comput., 2021.

[50] Y. Kawase and S. Kasahara, “Transaction-conﬁrmation time for bitcoin:
A queueing analytical approach to blockchain mechanism,” in Int. Conf.
on Queueing Theory and Network Applications.
Springer, 2017, pp.
75–88.

[51] Y. Kawase and S. Kasahara, “A batch-service queueing system with
general input and its application to analysis of mining process for bitcoin
blockchain,” in 2018 IEEE iThings and IEEE GreenCom and IEEE
CPSCom and IEEE SmartData.

IEEE, 2018, pp. 1440–1447.

[52] Q.-L. Li, J.-Y. Ma, and Y.-X. Chang, “Blockchain queue theory,” in Int.
Conf. on Comput. Social Networks. Springer, 2018, pp. 25–40.
[53] S. Geissler, T. Prantl, S. Lange, F. Wamser, and T. Hossfeld, “Discrete-
time analysis of the blockchain distributed ledger technology,” in ITC
31.

IEEE, 2019, pp. 130–137.

[54] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efﬁcient learning of deep networks from decentralized
data,” in Artiﬁcial intelligence and statistics. PMLR, 2017, pp. 1273–
1282.

[55] S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Koneˇcn`y,
S. Kumar, and H. B. McMahan, “Adaptive federated optimization,” arXiv
preprint arXiv:2003.00295, 2020.

[56] M. Chen, H. V. Poor, W. Saad, and S. Cui, “Convergence time opti-
mization for federated learning over wireless networks,” IEEE Trans.
Wireless Commun., vol. 20, no. 4, pp. 2457–2471, 2020.

[57] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,
“Federated optimization in heterogeneous networks,” arXiv preprint
arXiv:1812.06127, 2018.

[58] Y. Chen, Y. Ning, M. Slawski, and H. Rangwala, “Asynchronous online
federated learning for edge devices with non-iid data,” in 2020 IEEE
Int. Conf. on Big Data.

IEEE, 2020, pp. 15–24.

[59] F. Saleh, “Blockchain without waste: Proof-of-stake,” The Review of

ﬁnancial studies, vol. 34, no. 3, pp. 1156–1190, 2021.

[60] M. Castro, B. Liskov et al., “Practical byzantine fault tolerance,” in

OSDI, vol. 99, no. 1999, 1999, pp. 173–186.

14

[61] D. Schwartz, N. Youngs, A. Britto et al., “The ripple protocol consensus

algorithm,” Ripple Labs Inc White Paper, vol. 5, no. 8, p. 151, 2014.

[62] C. Ma, J. Li, M. Ding, L. Shi, T. Wang, Z. Han, and H. V. Poor,
“When federated learning meets blockchain: A new distributed learning
paradigm,” arXiv preprint arXiv:2009.09338, 2020.

[63] G.-T. Nguyen and K. Kim, “A survey about consensus algorithms used
in blockchain,” Journal of Information processing systems, vol. 14, no. 1,
pp. 101–128, 2018.

[64] C. Decker and R. Wattenhofer, “Information propagation in the bitcoin

network,” in IEEE P2P 2013 Proceedings.

IEEE, 2013, pp. 1–10.

[65] J. F. Shortle, J. M. Thompson, D. Gross, and C. M. Harris, Fundamentals

of queueing theory.

John Wiley & Sons, 2018, vol. 399.

[66] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.

[67] A. Krizhevsky, G. Hinton et al., “Learning multiple layers of features

from tiny images,” 2009.

[68] K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” arXiv preprint arXiv:1409.1556, 2014.

Francesc Wilhelmi holds a Ph.D. in information
and communication technologies (2020), from Uni-
versitat Pompeu Fabra (UPF). He is currently work-
ing as a postdoctoral researcher in the Mobile Net-
works department at Centre Tecnol`ogic de Teleco-
municacions de Catalunya (CTTC).

Lorenza Giupponi received her Ph.D. degree from
UPC, Barcelona, Spain, in 2007. In 2003, she joined
the Radio Communications Group, UPC, with a
grant of the Spanish Ministry of Education. From
2006 to 2007, she was an Assistant Professor with
UPC. In September 2007, she joined CTTC, where
she was a Research Director within the Mobile
Networks Department. Between 2007 and 2011 she
also was a member of the Executive Committee of
CTTC, where she acted as the Director of Institu-
tional Relations. She was a co-recipient of the IEEE
CCNC 2010, the IEEE 3rd International Workshop on Indoor and Outdoor
Femto Cells 2011, and the IEEE WCNC 2018 Best Paper Award. Between
2015 and 2011, she was a member of the Executive Committee of ns-3
Consortium in charge of coordinating 3GPP related developments. Since 2021
she is a Standardization Researcher in Ericsson.

Paolo Dini
received M.Sc. and Ph.D. from the
Universit‘a di Roma La Sapienza, in 2001 and 2005,
respectively. He is currently a Senior Researcher
with the Centre Tecnologic de Telecomunicacions
de Catalunya (CTTC). His current research interests
include sustainable networking and computing, dis-
tributed optimization and optimal control, machine
learning, multi-agent systems and data analytics.
His research activity is documented in almost 90
peer-reviewed scientiﬁc journals and international
conference papers. He received two awards from the
Cisco Silicon Valley Foundation for his research on heterogeneous mobile
networks, in 2008 and 2011, respectively. He has been involved in more than
20 research and development projects. He is currently the Coordinator of
CHIST-ERA SONATA project on sustainable computing and communication
at the edge and the Scientiﬁc Coordinator of the EU H2020 MSCA Greenedge
European Training Network on edge intelligence and sustainable computing.
He serves as a TPC in many international conferences and workshops and as a
reviewer for several scientiﬁc journals of the IEEE, Elsevier, ACM, Springer,
Wiley.

