1
2
0
2

c
e
D
4
1

]

R
C
.
s
c
[

3
v
4
3
5
4
1
.
9
0
1
2
:
v
i
X
r
a

A Veriﬁed Algebraic Representation of
Cairo Program Execution

Jeremy Avigad1, Lior Goldberg2, David Levit2, Yoav Seginer1, and Alon Titelman2

1Carnegie Mellon University
2StarkWare Industries Ltd.

December 16, 2021

Abstract

Cryptographic interactive proof systems provide an eﬃcient and scalable means of verifying
the results of computation on blockchain. A prover constructs a proof, oﬀ-chain, that the
execution of a program on a given input terminates with a certain result. The prover then
publishes a certiﬁcate that can be veriﬁed eﬃciently and reliably modulo commonly accepted
cryptographic assumptions. The method relies on an algebraic encoding of execution traces of
programs. Here we report on a veriﬁcation of the correctness of such an encoding of the Cairo
model of computation with respect to the STARK interactive proof system, using the Lean 3
proof assistant.

1

Introduction

The execution of smart contracts [30] on blockchain makes it possible to carry out transactions
such as cryptocurrency exchanges and auctions in the absence of institutional oversight. But the
technology faces a scaling problem: distributed blockchain protocols require anyone verifying the
integrity of the blockchain to carry out the computation associated with the contract, constituting
a draw on resources.

Seminal work of Babai, Fortnow, and Lund [8] showed that interactive proof protocols, introduced
to complexity theory in the mid-1980s [7, 20], allow for eﬃcient veriﬁcation of computational claims.
They provide protocols by which a computationally powerful prover can convince a computationally
limited veriﬁer that the execution of a program on a given input yields a certain result, without
requiring the veriﬁer to execute the program itself. The original protocols rely on a source of
randomness to convince the veriﬁer that the claim holds with high probability. Contemporary
variants replace the use of randomness by the use of cryptographic methods and assumptions.

Here we focus on the use of one particular cryptographic protocol, the STARK protocol [10], to
verify claims about execution in one particular Turing-complete model of computation, the Cairo
machine [19]. The Cairo model of computation is a machine with a small instruction set and the
ability to read from a bank of memory consisting of values in a ﬁnite ﬁeld. Roughly speaking, the
STARK protocol allows a prover to eﬃciently convince a veriﬁer that the prover possesses a table
of values from a large ﬁnite ﬁeld, such that tuples from the table satisfy a family of polynomials

1

 
 
 
 
 
 
that is shared by both the prover and veriﬁer. In our case, this table of values encodes the trace of
an execution of the Cairo machine.

To employ the STARK protocol, claims about the execution of a Cairo program on a given
partial assignment to memory are encoded using an algebraic intermediate representation (AIR).
Speciﬁcally, the claim that a program terminates successfully is expressed as a claim about the
existence of a solution to a family of polynomials, which is exactly the type of claim that can be
veriﬁed by the STARK protocol.

When the execution of a smart contract can have substantial ﬁnancial repercussions, it is im-
portant to have prior conﬁdence that the outcome will be as intended. In that respect, there are at
least three aspects of the process just described that are open to formal veriﬁcation. First, one may
wish to verify the claimed properties of STARKs, that is, the claim that the protocol establishes
the existence of the data satisfying the polynomial constraints with high probability, under the
relevant cryptographic assumptions. Second, one may wish to verify the algebraic representation
of program execution, that is, the claim that the existence of data satisfying the AIR implies the
existence of an execution trace of the corresponding program. Finally, one may wish to verify claims
that particular Cairo programs meet their speciﬁcations, for example, that the successful execution
of a program correctly determines the outcome of an exchange.

Although the ﬁrst task would constitute an interesting formalization project, we take the other
two tasks to be more pressing. Cryptographic protocols have been well-studied and the papers on
STARKs and related protocols have appeared in peer-reviewed journals, so it seems reasonable to
treat the protocol as a black box for now. Work on the third task is in progress, but we will not
report on that here. This paper reports on the successful completion of the second task, a fully
veriﬁed proof that data satisfying the AIR implies the corresponding computational claim. The AIR
veriﬁed by the proof is directly generated from the Cairo implementation, allowing for continuous
veriﬁcation of the AIR used in production.

When formal veriﬁcation and computational complexity come together, the phrase “interactive
proof system” is used in two unrelated ways. In formal veriﬁcation, it refers to a computational proof
assistant, whereas in complexity theory and cryptography, it refers to the kind of interactive proof
protocols described above. The terminology is standard in both communities, and it is generally
not hard to resolve the ambiguity in context.

Our formalization follows the informal proofs—some presented in detail, others sketched—in
what we will refer to as the Cairo whitepaper [19]. The most up-to-date version of the formalization,
as well as instructions for compiling or browsing it in Lean, can be found at

https://github.com/starkware-libs/formal-proofs.

In the PDF version of this paper, all .lean ﬁle references are hyperlinked to the ﬁles in this
repository.

2 The Formalization Platform

Our formalization is carried out in the Lean 3 proof assistant [16] with its associated library, mathlib
[26]. Lean’s axiomatic foundation is a version of dependent type theory with inductive types and a
type of propositions. The core logic is constructive, but we (and mathlib) make free use of classical
logic.

Our formalization does not depend heavily on the speciﬁcs of Lean and mathlib, however. We use
basic facts from the library about natural numbers, integers, ﬁnite indexing types, bitvectors, and

2

ﬁnite ﬁelds. Perhaps the most mathematically involved fact we need is that a degree n polynomial
over a ﬁeld has at most n roots. We also make moderate use of automation. Lean’s simpliﬁer, which
does conditional term rewriting with a battery of tagged and/or explicitly enumerated rewrite rules,
has been helpful, especially for the parts of the formalization described in Section 8. We use a tactic,
norm-num, that carries out veriﬁed numeric calculations.

3 The Cairo CPU

The successful run of a Cairo program on a given input is meant to convince a skeptical veriﬁer of
some claim about those inputs. An unusual feature of the model of computation is that memory
is read only. When executing a Cairo program and preparing the data needed for the interactive
proof protocol, it is the prover’s obligation to arrange data in memory so that the program executes
successfully.

The computation model is based on a CPU with three registers, a program counter (pc), an
allocation pointer (ap), and a frame pointer (fp), each of which points to locations in the read-only
memory. The program counter contains the memory address of the instruction that is about to be
executed. By convention, the allocation pointer points to a yet-unused memory cell, and it usually
only increases as a program executes. The frame pointer is used to point to a function’s local
memory. When a function is called, the frame pointer is set equal to the allocation pointer, and
when the function returns, the frame pointer is restored to the value it had before the previous call,
that is, the address of the calling function’s local memory.

In the Cairo model, register values, as well as values in memory, are elements of a ﬁnite ﬁeld,
F . As a result, there is no order on the elements; a program can test equality of elements but
cannot compare them to determine which is greater. Using a ﬁeld means that we can add, subtract,
multiply, and divide. Program instructions are 63 bits long, and so can be represented by an integer
less than 263. The semantics assumes (and the algebraic data presented to the veriﬁer guarantees)
that the characteristic of the underlying ﬁeld is greater than 263, which means that instructions have
a unique representation in the ﬁeld. But algebraic constraints are needed to guarantee that a given
ﬁeld element represents an instruction in such a way, as well as to reason about the instruction’s
components. We will explain how this works in Section 7.

The fact that memory is read only means that we do not need to verify claims about memory
management. Another consequence of the intended use is that we do not need to prove that a
program terminates; the algebraic data veriﬁed by the interactive proof system guarantees that the
program has run for a certain number of steps, after which the program counter reached a certain
value. That is not to say that it would not be helpful to also have general guarantees that high-level
Cairo programs terminate and manage memory appropriately; such completeness claims guarantee
that the prover can publish the desired proofs. At present, extensive testing and code review is
used for that purpose, and establishing soundness, i.e. the fact that the proofs do what they are
supposed to, is the more pressing concern.

There are a few basic types of Cairo machine instructions:

• assert statements, which assert equality between two values
• conditional and unconditional jumps, the former based on a test for zero
• call and return
• an instruction to advance the allocation pointer.

3

Arguments can refer to the contents of memory locations using oﬀsets from the frame pointer or
allocation pointer. They also support addition and multiplication. Each instruction contains three
bitvectors of length 16, which can provide, for example, memory oﬀsets for the operands and result
of an assert. Each instruction also contains 15 1-bit ﬂags, which determine things like the type of
instruction, the nature of the operands, and whether the allocation pointer should be augmented
after the instruction.

An instruction is formally represented in Lean as follows:

structure instruction :=
(off_dst : bitvec 16)
(off_op0 : bitvec 16)
(off_op1 : bitvec 16)
: bitvec 15)
(flags

For example, in the Cairo assembly language, we might write an instruction as follows:

[ap + 10] = [fp] * [fp - 1].

This asserts that the value in memory at location ap + 10 is the product of the values at locations
fp and fp - 1, where ap and fp denote the allocation pointer and frame pointer, respectively. This
instruction is encoded in the structure above by setting the ﬂags to specify that the operation is
an assert, that the relevant operation is multiplication, that the operands are addressed by oﬀset
from fp, and that the result is addressed by oﬀset from fp. The values of off_dst, off_op0, and
off_op1 represent 10, 0, and -1, respectively. The instruction is ultimately converted to a number,
which, in turn, is stored in memory as an element of F . Some instructions also require an immediate
value, which is stored in the next element of memory.

The register state is represented formally as follows:

structure register_state (F : Type*) :=
(pc : F) (ap : F) (fp : F)

A single state of the virtual Cairo machine is given by the contents of memory, which we model as
a function from F to F , and the current register state. Given such a state, the Cairo whitepaper
[19] speciﬁes the potential successor states. The successful execution of a well-formed instruction
leads to a unique successor state. But there may not be a successor state, for example, when
an assertion fails because in the given state the asserted equality doesn’t hold. And ill-formed
instructions result in undeﬁned behavior, giving rise to the possibility of multiple successor states.
We therefore use a next-state relation to model the step semantics. The ﬁle cpu.lean, less than 200
lines, is a straightforward formalization of the whitepaper description, culminating in the following
deﬁnitions:

def instruction.next_state (i : instruction) (mem : F → F)

(s t : register_state F) : Prop :=

(i.next_pc mem s).agrees t.pc ∧
(i.next_ap mem s).agrees t.ap ∧
(i.next_fp mem s).agrees t.fp ∧
i.asserts mem s

def next_state (mem : F → F)

(s t : register_state F) : Prop :=

4

∃ i : instruction, mem s.pc = ↑i.to_nat ∧ i.next_state mem s t

The ﬁrst deﬁnition says that t is a successor state to s assuming i is the current instruction. It
relies on auxiliary deﬁnitions that specify the next program counter, the next allocation pointer, the
next frame pointer, and any assertions associated with the instruction. Notation such as i.next_pc
relies on a nice bit of Lean syntax known as “anonymous projections”: given i of type instruction
and a deﬁnition instruction.next_pc in the environment, Lean interprets i.next_pc mem s as
(In this example, i is inserted as the ﬁrst argument of type
instruction.next_pc i mem s.
instruction.) Each of the functions next_pc, next_ap, and next_fp returns an element of an
option type, equal to none if the instruction results in undeﬁned behavior. If x is an element of an
option type, the relation x.agrees a says that if x is of the form some b, then a is equal to b.

The second deﬁnition, the next_state relation, simply asserts that the memory at the program
counter contains the cast of an instruction to the ﬁeld and that the next state agrees with the one
corresponding to that instruction.

Other deﬁnitions specify the way that the value of the next state is determined based on the
instruction ﬂags and oﬀset values. For example, the next value of the frame pointer depends on
whether the current instruction is a call, a return, an assert, or none of the above. The speciﬁcation
has the following shape, where the auxiliary function instruction.dst mem s determines the
appropriate value for restoring the frame pointer on the return from a function call.

def next_fp : option F :=

match i.opcode_call, i.opcode_ret,

i.opcode_assert_eq with
| ff, ff, ff := some s.fp
| tt, ff, ff := some (s.ap + 2)
| ff, tt, ff := some (i.dst mem s)
| ff, ff, tt := some s.fp
| _,
end

:= none

_,

_

The function is a case distinction on the settings of the corresponding ﬂags of the instruction. After
a call instruction, for example, the frame pointer is set to the current allocation pointer plus 2.
After a return instruction, the next value of the frame pointer is computed using the function
instruction.dst. The other instructions do not change the frame pointer.

The Cairo toolchain allows programmers to write Cairo programs in an assembly language that

is close to the machine code, with instructions like these:

[ap] = [fp + (-4)] + [fp + (-3)]; ap++
jmp rel 4 if [ap + (-1)] != 0
call rel -16

The ﬁrst instruction says that the value of the memory location referenced by the allocation pointer
is equal to the sum of the values at two locations referenced using the frame pointer. The ap++
suﬃx speciﬁes that the instruction also increments the allocation pointer. The next instruction is
a conditional relative jump, and the third executes a call to the function at the current program
counter minus 16.

The Cairo toolchain also allows programmers to write programs in a higher-level language with
function deﬁnitions, data structures, conditional blocks, and recursive function calls. These are

5

compiled to assembly instructions, which are encoded as machine instructions and ultimately as
ﬁeld elements that are shared with the veriﬁer.

4 The AIR

In the intended scenario, the prover and the veriﬁer agree on a Cairo program of interest and
the input to that Cairo program. The prover wants to convince the veriﬁer that executing the
program on the inputs yields a certain output. The prover does this by publishing a proof, a
suitable certiﬁcate, at which point the veriﬁer executes an algorithm that uses the certiﬁcate to
ascertain the correctness of the claim. The catch is that, in the intended usage, the certiﬁcate will
be published on blockchain and the veriﬁer will be executed as part of a smart contract, so we want
the certiﬁcate to be small and the veriﬁcation to be substantially more eﬃcient than executing the
Cairo program itself.

Whereas the original interactive proof systems made use of randomness to achieve such goals,
blockchain protocols rely on the use of cryptographic hash functions instead of coin ﬂips. The
eﬀectiveness of the proof relies on the assumption that a dishonest but computationally-bounded
prover does not have a substantially better than random chance of gaming the use of a hash.

Our method relies on the STARK protocol, which works roughly as follows. Fix a large prime
number p, and let Fp be the ﬁnite ﬁeld of integers modulo p. The STARK protocol allows the prover
to convince the veriﬁer that the prover is in possession of a two-dimensional table of ﬁeld elements
of Fp that satisﬁes a constraint system that the prover and veriﬁer agree on. The constraint system
is given as a list of polynomials P1(~x1), . . . , Ps(~xs) over Fp, and a corresponding list of domains
D1, . . . , Ds, which are periodic subsets of the row indices. The arguments of the polynomials can
be taken from multiple rows and multiple columns of the table. We say that the constraint system
is satisﬁed by a certain table with N rows if for every j = 1, . . . , s and every r ∈ Dj, we have
Pj(~x(r)
is ~xj shifted by r rows. For example, a polynomial P (~x) might involve
variables in two consecutive rows, and the corresponding set D might specify that the constraint
holds at every row in the table, or that it holds at every other row, or that it holds at every fourth
row. In our application, the polynomials are ﬁxed modulo some ﬁeld parameters that the prover
and veriﬁer share. The veriﬁcation algorithm runs in time polynomial in the logarithm of N and
the size of the parameters that the prover and veriﬁer share, and it provides high assurance that
the result is correct.

j ) = 0, where ~x(r)

j

To meet our goals, it therefore suﬃces to design a sequence of polynomials P1(~x1), . . . , Ps(~xs)
such that, for parameters corresponding to the Cairo program, input data, and output in question,
and for a suitable N , the existence of a table of data meeting the criteria described in the previous
paragraph implies the existence of an execution sequence of the given Cairo program on the given
input data, yielding the given output.

For the purposes of this paper, the details of the STARK protocol and the precise complexity
and probabilistic claims can be treated as a black box. Our goal here is to describe the polynomials
P1, . . . , Ps and to describe a formal proof that the existence of the table of data implies the existence
of the desired execution sequence. Assuming the veriﬁer trusts the STARK protocol, the successful
run of the veriﬁcation algorithm yields a strong guarantee of the existence of a table of data
satisfying the constraints, and our formal proof turns this into a strong guarantee that the Cairo
program executes as claimed.

The constraints P1, . . . , Ps and the relevant parameters are listed in constraints_autogen.lean.

6

As the name suggests, this ﬁle is automatically generated. In fact, it is generated by the same code
that produces the code for the veriﬁer. This, together with the speciﬁcation of the CPU semantics
in cpu.lean, are the only two ﬁles that the statement of our ﬁnal theorem depends on, other than
general basic facts about data structures, ﬁelds, and so on in the library. The desired conclusion,
namely, the existence of an execution trace consistent with the given partial assignment to mem-
ory, relies on the fact that the STARK certiﬁcate that is veriﬁed on the blockchain is correct with
respect to these polynomial constraints and parameters. A skeptic can inspect the smart contract
that performs the veriﬁcation to ensure that this is the case.

The fact that the Cairo program, the input, and the output are all stored in memory allows us
to simplify the description of the veriﬁcation task. It suﬃces for the prover and veriﬁer to agree on
a partial assignment of values to the memory that includes that data and the initial state of the
CPU. In fact, we share that information, the length of the execution trace, and the ﬁnal value of
the program counter and allocation pointer; the polynomial constraints ensure that the initial value
of the frame pointer is equal to the initial value of the allocation pointer. This data is represented
as follows:

structure input_data (F : Type*) :=
(trace_length : nat)
(initial_ap : nat) (initial_pc : nat)
(final_ap : nat) (final_pc : nat)
(m_star : F → option F)

The name m_star corresponds to the fact that the partial assignment is written as m∗ in the
whitepaper, and the return type, option F, means that the function can either return an element
of the type some a, where a is an element of F, or none.

The publicly shared parameters also include additional data, including information about range

checked elements and the interaction elements; these are explained in Sections 9–11 below.

structure public_data (F : Type*) :=
(memory_perm_interaction_elm : F)
(memory_hash_interaction_elm0 : F)
(memory_public_memory_prod : F)
(rc16_perm_interaction_elm : F)
(rc16_perm_public_memory_prod : F)
(rc_min : nat) (rc_max : nat)
(initial_rc_addr : nat)

The correctness proof assumes that this data satisﬁes certain assumptions that can be easily con-
ﬁrmed by the veriﬁer.

structure public_constraints

(inp : input_data F)
(pd : public_data F) : Prop :=

(rc_max_lt : pd.rc_max < 2^16)
(trace_length_le_char : inp.trace_length ≤ ring_char F)
. . .

Suppose the Cairo program terminates after T steps. The execution trace then consists of T + 1
register states, including the start state and end state, and depends on T -many instructions in

7

the memory along the way. Without loss of generality, we can assume that T + 1 is a power of
two, since, by convention, Cairo programs “terminate” by entering an inﬁnite loop. The data in
the Algebraic Intermediate Representation (AIR) consists of a list of 16(T + 1)-many tuples, each
consisting of 25 columns. These are used to encode the execution trace, the instructions, and the
contents of memory, in ways that we will describe below. The parameter trace_length in the
structure input_data indicated above is actually 16(T + 1), corresponding to the parameter N
described earlier in this section. We recover T by dividing by 16 and subtracting one. We often
refer to the elements of the AIR as trace cells, since they encode the states of the execution trace,
as well as memory accesses along the way and auxiliary data.

We can now state our main result: our formal proof shows that satisfaction of the polynomial
constraints guarantees that the encodings have the claimed meaning with respect to the formal
semantics. In other words, the existence of a table of data satisfying the contraints implies the
existence of an execution trace that is consistent with the agreed-upon partial assignment to memory.
For the protocol, it is important that the prover commit to the ﬁrst 23 columns of data before
“random” interaction elements are computed based on a cryptographic hash of the ﬁrst columns;
the remaining 2 columns then depend on the result of these interaction elements. From the published
data the veriﬁer can ensure that this is, in fact, the case, and in the next section we will see how
they are incorporated into the correctness proof.

The Cairo whitepaper describes the relevant polynomials and encoding of data without specify-
ing exactly how the data is laid out in the 16(T + 1) × 25 array. This makes the constraints easier to
read and understand. Our initial formalization followed the whitepaper; the ﬁle constraints.lean
formalizes those constraints, and the ﬁle correctness.lean proves the correctness theorem in those
terms. We then incorporated a ﬁle glue.lean that mediates between the two representations, re-
sulting in the end-to-end correctness proof in final_correctness.lean.

5 The Correctness Theorem

The statement of the ﬁnal correctness theorem depends only on the speciﬁcation of the Cairo execu-
tion semantics in cpu.lean and the autogenerated ﬁle of constraints, constraints_autogen.lean.
The full statement of the theorem is presented in Figure 1.

In the statement of the theorem, F is assumed to be a ﬁnite ﬁeld of characteristic at least 263.

We are given the shared input data, inp : input_data F, and the remaining public data, pd :
public_data F, assumed to satisfy the required constraints. We are also given c: columns F, a
structure that consists of 23 columns named c.column0 to c.column22.

Based on this data, we assert the existence of three “bad” subsets bad1, bad2, bad3 of the
ﬁeld F . Letting T ′ be the shared input parameter inp.trace_length, these are asserted to have
cardinality at most (T ′/2)2, T ′/2, and T ′, respectively. The idea is that for the execution sequences
that arise in practice, these values will be substantially smaller than the cardinality of F , so that a
randomly chosen element of the ﬁeld is unlikely to land in the bad sets. As we explain in Section 9,
if the prover has encoded the relevant data honestly, these sets are all empty, but if the prover
is dishonest, the prover will be caught in the lie unless the interaction elements happen to return
values in these small sets. Once these bad sets are determined, the prover commits to the ﬁnal two
columns, ci : columns_inter F.

The theorem then says that if the columns c and ci satisfy all the polynomial constraints, and
assuming that the generated interaction elements are not in the small bad sets, then there exists
an execution trace of the Cairo program meeting the agreed-upon speciﬁcation.

8

In greater detail, we assume that the data c, ci, inp, and pd satisﬁes the autogenerated con-

straints

• cpu__decode,
• cpu__operands,
• cpu__update_registers,
• cpu__opcodes,
• memory,
• rc16,
• public_memory, and
• initial_and_final.

We will describe the contents of these below. We also assume that the interaction elements have
landed outside the small bad sets that depend only on the ﬁrst 23 columns. Under the cryptographic
assumptions, this occurs with high probability. Let T be (T ′ − 1)/16. The theorem then asserts
that there exists an assignment to the memory that extends the agreed-upon partial assignment
and an execution trace of the Cairo program, for that memory assignment, that starts at the start
state, runs for T steps, and ends at the end state. In other words, the ﬁrst and last state of the
execution trace are as claimed, and each successive state follows the previous one according to the
machine semantics speciﬁed in cpu.lean.

What needs to be trusted? The polynomials that are found in constraints_autogen.lean
should match the polynomials used by the veriﬁer. Since the deﬁnition of a ﬁeld, the deﬁnition of
integers, ﬁnite sequences, and so on come into the deﬁnition of the semantics and the statement of
correctness, one needs to assume that they have been formalized correctly, so that, for example, a
statement about a ﬁnite ﬁeld really is a statement about a ﬁnite ﬁeld. Since the formalization says
something about the CPU semantics, we have to accept that the formalization of that semantics
matches our informal understanding. However, if we are later able to prove that programs meet high
level speciﬁcations with respect to the semantics (which we intend to do, as described in Section 1),
at that point only the higher-level speciﬁcation matters; the execution semantics becomes only
a stepping-stone to the ﬁnal result. Of course, we have to trust the soundness of the axiomatic
foundation and its implementation in Lean. Finally, as described in Section 1, an implementation
of the method also requires trusting the STARK protocol and the means used to verify the STARK
certiﬁcates.

Once we trust the formalization, we do not need to worry about why or how the polynomial
constraints guarantee the existence of the ﬁnal execution trace. The formal proof establishes that
it does. From the point of view of the design of the system, however, and from the point of view of
veriﬁcation, this is the most interesting part. The details are spelled out in the Cairo whitepaper
[19]. In the sections that follow we sketch the proof and provide some indications as to how it is
formalized.

6 Summary of the Constraints

Altogether, the Cairo algebraic intermediate representation of an execution trace is encoded by the
following constraints:

• constraints for specifying and decoding instructions;

9

• constraints that specify the next-step relation, and, in particular, specify the operands for an
assert statement and the values of the program counter, frame pointer, and allocation pointer,
all in terms of the current instruction and values in memory;

• constraints that show that the prover has an assignment of values to memory that is consistent
with program execution and extends the partial assignment that the prover and veriﬁer have
agreed upon; and

• constraints that guarantee that memory addresses and instruction components are integers

in the required range.

We describe each of these categories, in turn, in the sections that follow.

The full list of constraints is found in Section 9.10 of the Cairo whitepaper [19]. They are stated
as local hypotheses in the ﬁles throughout the formalization, and they are gathered into structures
in the ﬁle constraints.lean. That ﬁle provides the parameters and hypotheses that are used in the
statement of the correctness theorem in correctness.lean. The ﬁle constraints_autogen.lean
contains a description of the constraints that is generated automatically from the Cairo source code,
and so reﬂects the data that is used to generate the STARK certiﬁcate. It is these latter constraints
that the veriﬁer can check using the STARK protocol. We therefore use the ﬁle glue.lean to
instantiate the structures and hypotheses in constraints.lean, and the ﬁnal correctness theorem
in Figure 1 is stated in terms of the autogenerated constraints. This means that the veriﬁer does not
have to trust any aspect of the implementation: the STARK certiﬁcate ensures that the constraints
are met, and the formal theorem shows that this implies the existence of the claimed execution
trace.

7 Decoding Instructions

In Section 8, we will discuss polynomial constraints that, given an instruction i, the contents of
memory m, and a register state s, specify that another register state t follows s according to i.
For that purpose, however, we need to reason about the components of i. We also need to ensure
that the ﬁeld element i is, in fact, a valid instruction, which is to say, it is the result of casting an
integer in [0, 263) to the ﬁnite ﬁeld. Note that we can always use auxiliary elements of the AIR
when writing constraints. These are existentially quantiﬁed by the STARK protocol.

Remember that an instruction contains three 16-bit numbers, oﬀdst, oﬀop0, and oﬀop1. These
are intended to denote integer oﬀsets in [−215, 215), but in the AIR we store the corresponding
oﬀ∗ = oﬀ∗ + 215 (where ∗ is one of op0, op1, or dst). We also need to reason about the
elements
f
ﬂags f0, . . . , f14. Rather than using trace elements of the AIR for these, we deﬁne ˜fi = P
j=i 2j−i ·fj
and store ˜f0, . . . , ˜f15. Note that this means that ˜f0 = Pj<15 2j · fj is the integer in [0, 215) with
bits f0, . . . , f14, and that ˜f15 = 0. We can recover the bits fi with the identity fi = ˜fi − 2 ˜fi+1.

14

In Section 10 we explain how the AIR can constrain the values

oﬀ∗ to be integers in the range
f
[0, 216). Setting that aside, the AIR should therefore assert that elements ˜fi encode a sequence
of 0s and 1s via the identity above, and that the value representing the instruction is equal to
oﬀdst + 216 ·
f

oﬀop1 + 248 · ˜f0. These constraints are written in Lean as follows:
f

oﬀ op0 + 232 ·
f

variable h_instruction : inst = off_dst_tilde + 2^16 * off_op0_tilde +

2^32 * off_op1_tilde + 2^48 * f_tilde 0

variable h_bit : ∀ i : fin 15, f_tilde.to_f i * (f_tilde.to_f i - 1) = 0

10

variable h_last_value : f_tilde h15, by norm_numi = 0

To make sense of this, note that in Lean, a hypothesis is encoded as a variable whose type is the
statement in question. The type fin 15 consists of the numbers from 0 to 14, which are used to
index the bits. In contrast, the variables ˜fi are indexed by elements of fin 16, and the Lean idiom
h15, by norm_numi is used to denote the last element of this type and automatically ﬁll in the
proof that 15 is less than 16. The to_f function in the expression f_tilde.to_f i computes the
value of fi from the tuple ˜f via the identity above.

Theorem 1 of the whitepaper asserts that with these constraints (and the ones that ensure
oﬀ ∗ are integers in the right range) there is a unique instruction such that the
that the values
f
In our formalization, we generally need to refer to
ﬁeld element inst encodes that instruction.
the instruction encoded by inst on the assumption that these constraints are met. Therefore, our
formalization takes the following form. First, we deﬁne a function

def the_instruction : instruction := . . .

oﬀ∗ and ˜f . (In Lean, when variables and hypotheses are
This speciﬁes the instruction from the data
f
declared in a ﬁle, deﬁnitions that use them can leave the dependence implicit. The dependencies
are part of the deﬁnition, however, and are displayed when the user asks Lean to show an expression
or its type.) Then, we prove that, assuming the constraints are met, the ﬁeld element is equal to
the cast (to the ﬁeld) of the natural number encoding of the instruction, and the trace elements
oﬀ∗ are the results of casting the components of the instruction to the ﬁeld. For example:
f

theorem inst_eq : inst = ↑(the_instruction . . .).to_nat

theorem off_dst_tilde_eq : off_dst_tilde =
↑(the_instruction . . .).off_dst.to_natr

Here, we have omitted the arguments to the_instruction and the proofs of the theorems. The up
arrow, which indicates the cast, can often be left implicit. The ﬁrst theorem says that if we take
the instruction computed from the constraints, encode it as a natural number less than 263 in the
natural way, and cast it to the ﬁnite ﬁeld, the result is exactly inst. The second theorem says,
similarly, that the AIR element off_dst_tilde is the ﬁeld element corresponding to the off_dst
bitvector component of the instruction. The function to_natr translates the given bitvector to a
natural number; the “r” at the end reﬂects the fact that the to_nat function in Lean’s standard
library takes 0 to be the most signiﬁcant bit rather than the least signiﬁcant bit, whereas to_natr
does the opposite. We also prove uniqueness:

theorem inst_unique (i : instruction) (h : inst = i.to_nat) :

i = the_instruction . . .

Interestingly, uniqueness is not required for the correctness theorem in Figure 1. The possibility
that a ﬁeld element might represent diﬀerent instructions would make the next-state relation non-
deterministic, but it would not violate the theorem. But it is independently important to know
that this nondeterminism does not arise, and we use that fact in subsequent work, when we want to
prove that particular programs meet their speciﬁcations. For that purpose, we need to know that
the original instruction can be recovered from its representation in the ﬁeld.

11

8 The Next State Relation

The constraints that relate one state to the next are rather straightforward. The AIR has cells
associated to each step i ≤ T of the execution trace. There are values api, fpi, and pci representing
the allocation pointer, frame pointer, and program counter at step i. There are also auxiliary
values dst i and res i for destination and result values associated with some of the instructions, as
described by the CPU speciﬁcation, and auxiliary values used in the constraints, as described by
the Cairo whitepaper. Some of the auxiliary values are used to express the constraints as quadratic
expressions, as required by the protocol.

For example, to say that the ﬁeld value next_fp represents the correct value of the next frame
pointer given the current register values, the state of memory, and the current instruction, the AIR
uses the following constraint:

variable h_next_fp : next_fp =

f_tilde.f_opcode_ret * dst + f_tilde.f_opcode_call * (ap + 2) +

(1 - f_tilde.f_opcode_ret - f_tilde.f_opcode_call) * fp

f_tilde.f_opcode_ret and f_tilde.f_opcode_call are the values of the corresponding ﬂags,
which were decoded by the instruction constraints. If the opcode_ret bit is 1 and the opcode_call
bit is 0, the constraint requires that the next frame pointer has the value dst; if opcode_ret is 0
and opcode_call is 1, the constraint requires that the next frame pointer has the value ap + 2; if
both are 0, the constraint requires that the frame pointer remains unchanged. Remember that if,
for example, both ﬂags are 1, the CPU semantics says that the next frame pointer can be anything
at all; it is nondeterministic in that sense. This is not problematic, because the program itself
is part of the speciﬁcation shared by the prover and the veriﬁer. The veriﬁer can check that the
instructions are indeed well-formed, and an end-to-end veriﬁcation that a Cairo program meets its
speciﬁcation will generally prove that fact along the way.

The claim that this constraint together with the constraints governing instructions, calculation
of dst , memory access, and so on all imply that the calculated next state agrees with the CPU
semantic speciﬁcation is stated simply as follows:

theorem next_fp_agrees : (inst.next_fp mem hpc, ap, fpi).agrees next_fp

The parameters and hypotheses are left implicit, which is a good thing, because there are a lot of
them, even for a simple fact like this one. Asking Lean to display the theorem statement shows
that there are ﬁve hypotheses involving eight ﬁeld values, the memory assignment, the instruction,
and the associated tuple of ﬂags. As one might expect, one of the most useful roles that the proof
assistant played in our formalization was keeping track of the large array of data and assumptions,
and making sure all the intermediate results were glued together correctly. The proof of this
particular theorem involving little more than casing on the values of the ﬂags, invoking previous
results, and simplifying, with about eight lines of tactics.

9 Permutations

There are two types of constraints left to describe. Deﬁning the next-step relation requires, in
certain places, statements to the eﬀect that a memory location a contains a value v. The prover
needs not only to encode this information in the AIR but also to convince the veriﬁer that there
is an assignment of values to the read-only memory that is consistent with these claims. The

12

constraints that do this are described in Section 11. The correctness of the execution trace also
requires knowing that address oﬀsets stored in an instruction are integers in the interval [0, 216),
and the Cairo compiler allows programmers to make similar assertions in their code. These range
checks are handled by constraints described in Section 10. Both the memory constraints and range
check constraints rely on an additional feature of the interactive proof protocol, the interaction step,
that was alluded to in Section 4. In this section we explain how it works.

Suppose the prover has a sequence a0, a1, . . . , an−1 of values in the ﬁeld, uniformly spaced in the
data, so that the prover can express uniform claims about these values using polynomial constraints.
Remember that in general the veriﬁer will not see this data; the prover will merely use the interactive
proof system to convince the veriﬁer of its existence.

Now suppose that to establish further claims about the data, the prover needs to list the elements
n−1, with additional polynomial

in a diﬀerent order. The prover adds a permutation a′
constraints expressed in terms of those elements.

1, . . . , a′

0, a′

To establish correctness, the prover needs to convince the veriﬁer that the second sequence is
a permutation of the ﬁrst. This is not easy to do. A STARK makes it possible to write down a
constraint that relates, say, each pair (ai, a′
i+1), but the statement that
the sequence (ai)i<n is a reordering of (a′
i)i<n cannot be expressed using local constraints of that
form.

i) to the next pair (ai+1, a′

This is where the interaction step comes in. Let p(x) be the polynomial given by p(x) =
Qi<n(x − ai), and let p′(x) = Qi<n(x − a′
i)i<n,
then p(x) − p′(x) is the zero polynomial. If it isn’t, then p(x) − p′(x) is a polynomial of degree at
most n, and so has at most n roots in the ﬁeld. Suppose n is much smaller than the size of the ﬁeld,
and let α be a randomly chosen element. Suppose also that the prover convinces the veriﬁer that
p(α) − p′(α) = 0. Then the veriﬁer knows that either (ai)i<n really is a permutation of (a′
i)i<n, or
the prover was very lucky that the choice of α did not disprove that claim.

i). If the sequence (ai)i<n is a permutation of (a′

The interactive proof protocol uses a cryptographic hash instead of randomness. The STARK
protocol enables the prover to commit to a0, a1, . . . , an−1 and a′
n−1 and publish a certiﬁ-
cate that these values meet the publicly shared constraints. Once it is published, a cryptographic
hash α is generated. The prover then publishes a certiﬁcate that establishes that p(α) − p′(α) = 0.
To implement the argument in Lean, given any pair of ﬁnite tuples a and b indexed over a ﬁnite

1, . . . , a′

0, a′

type n, we deﬁne the set of misleading choices of α as follows:

variables {F : Type*} [field F] [fintype F]
variables {n : Type*} [fintype n]
variables (a b : n → F)

def exceptional_set : finset F :=

if ∀ z, Q i, (z - a i) = Q i, (z - b i) then ∅
else univ.filter (λ z : F, Q i : n, (z - a i) = Q i, (z - b i))

If the two polynomials are equal, the exceptional set is the empty set, which is to say, there are no
misleading values. Otherwise, the exceptional set is the ﬁnite set of values that make the two sides
equal. The facts we need to establish are, ﬁrst, that the cardinality of the exceptional set is less
than that of n, and, second, that unless the ﬁeld element z is in the exceptional set, equality of the
two polynomials at z implies that they are always equal.

theorem card_exceptional_set_le : card (exceptional_set a b) ≤ fintype.card n

13

theorem all_eq_of_not_mem_exceptional_set {z : F}

(h1 : z /∈ exceptional_set a b)
(h2 : Q i : n, (z - a i) = Q i, (z - b i)) :

∀ z, Q i, (z - a i) = Q i, (z - b i)

The ﬁrst claim is proved by cases on the deﬁnition of the exceptional set. If it is the empty set, the
claim is trivial, and otherwise the claim follows from the fact that the elements of the exceptional
set are the roots of a nonzero polynomial of degree at most the cardinality of n. The second claim
is immediate from the deﬁnition of the exceptional set, since the hypotheses imply that it cannot
be equal to the second branch of the conditional.

In the proof of the ﬁnal theorem in Figure 1, the existential quantiﬁers over bad2 and bad3
are witnessed by instances of exceptional_set. (We take bad1 to be the set of zeros of another
polynomial, described in Section 11.) Note that the statement of the ﬁnal theorem doesn’t depend
on the deﬁnition of exceptional_set or the details of how the bad sets are constructed. The
theorem simply asserts the existence of ﬁnite sets that depend on the ﬁrst 23 columns of data and
not the ﬁnal two, with the properties that (1) they are small, and (2) as long as the values of the
interaction elements are outside those sets, the desired conclusion is guaranteed to hold.

10 Range Checks

We have seen that specifying that a trace cell represents a well-formed instruction requires in
particular showing that certain other trace cells are ﬁeld elements that are casts of integers in the
interval [0, 216). Suppose a0, a1, . . . , an−1 are the relevant values, let rcmin be the minimum value,
and let rcmax be the maximum value. We can, without loss of generality, assume that every value
between rcmin and rcmax occurs on the list, by padding the list with extra elements if necessary.
We can convince the veriﬁer that all the values are between rcmin and rcmax by dedicating another
sequence of trace values a′
n−1, making rcmin and rcmax available to the veriﬁer, and
establishing the following claims:

1, . . . , a′

0, a′

• The sequence (a′
• For each i < n − 1, either ai+1 = ai or ai+1 = ai + 1.
• a′

i)i<n is a permutation of (ai)i<n.

0 = rcmin and a′

n−1 = rcmax.

The ﬁrst of these is handled as described in Section 9. We designate a sequence of trace elements
p0, p1, . . . , pn−1 with the declaration p : fin (n + 1) → F, and we add the following constraints:

(z - a' 0) * p 0 = z - a 0
∀ i : fin n, (z - a' i.succ) * p i.succ =

(z - a i.succ) * p i.cast_succ

p (fin.last n) = 1

Here i.succ is Lean notation for i+1 as a value of type fin (n + 1), and i.cast_succ is notation
for i as a value of type fin (n + 1). These constraints guarantee that we have Qi<n(z − ai) =
Qi<n(z − a′
i), and if z is generated by a hash, this equation oﬀers the veriﬁer a strong guarantee
that the ﬁrst condition is met. As described in Section 9, given

def bad_set_3 (a a' : fin (n + 1) → F) : finset F :=
polynomial_aux.exceptional_set a a'

14

and the hypothesis z /∈ bad_set_3 a a', we have

lemma rc_permutation : ∀ i, ∃ j, a i = a' j

For the second and third conditions, we simply add the following constraints:
∀ i : fin n, (a' i.succ - a' i.cast_succ) *

(a' i.succ - a' i.cast_succ - 1) = 0

a' 0 = rc_min
a' (fin.last n) = rc_max

With the ultimate arrangement of data in the AIR, the values off_op0_tilde are included along
the values a j with an explicit embedding:

∀ i, a (embed_off_op0 i) = off_op0_tilde i

With this, and the assumption rc_max < 2^16, we have

theorem off_op0_in_range (i : fin T) :

∃ k : N, k < 2^16 ∧ off_op0_tilde i = ↑k

We also have the analogous properties for off_op0_tilde and off_dst_tilde, which were assumed
in Section 7.

11 Memory

During the course of its execution, a Cairo program will access memory locations a0, a1, . . . , an−1.
The prover has to establish the existence of a list of suitable values v0, v1, . . . , vn−1 for those memory
locations. The constraints described in Section 8 guarantee that the values chosen by the prover
are consistent with the semantics of the program execution. For example, if a program asserts the
equality of the values in memory at locations ai and aj, the constraints will guarantee that vi is
equal to vj.

But the prover also has to establish the values are consistent with each other, which is to say,
there exists an assignment m of values to the memory with the property that m(ai) = vi for every
i < n. This is equivalent to saying that for every i and j less than n, if ai = aj, then vi = vj.

The constraints in the AIR that ensure this are similar to the range check constraints discussed
in Section 10, with two additional twists. As in Section 10, we can assume that the set of values
{a0, a1, . . . , an−1} is an interval by assigning 0 to unused memory locations between the smallest
and largest values. If we designate trace elements a′
n−1, it suﬃces
to establish the following:

n−1 and v′

1, . . . , v′

1, . . . , a′

0, v′

0, a′

• The sequence of pairs (a′
i, v′
• For each i < n − 1, either a′
• For each i < n − 1, if a′

i+1 = a′

i or a′
i, then v′

i+1 = a′
i+1 = v′
i.

i)i<n is a permutation of the sequence of pairs (ai, vi)i<n.
i+1 = a′

i + 1.

The second and third of these are ensured by the following constraints:

∀ i : fin n, (a' i.succ - a' i.cast_succ) *

(a' i.succ - a' i.cast_succ - 1) = 0

∀ i : fin n, (v' i.succ - v' i.cast_succ) *

(a' i.succ - a' i.cast_succ - 1) = 0

15

Notice that the ﬁrst of these constraints is needed to establish that the second one works as adver-
tised.

The ﬁrst twist is that to establish the ﬁrst condition, it suﬃces to establish that the values
i + αv′
(a′
i)i<n are a permutation of the values (ai + αvi)i<n, provided that α has the property that
i is not equal to ai + αvi unless a′
a′
i + αv′
i = vi. But if the two quantities are equal and
i 6= vi, we have α = (a′
v′
i). Assuming n is much smaller than the characteristic of F ,
there are a relatively small number of values α in the ﬁeld with this property. So if we have the
identity

i − ai)/(vi − v′

i = ai and v′

Y
i<n

(z − (ai + αvi)) = Y
i<n

(z − (a′

i + αv′

i))

for a randomly chosen α and a randomly chosen z, then ﬁrst condition holds with high probability.
This explains the expressions bad1 and bad2 in the statement of the ﬁnal correctness theorem: the
ﬁrst is the small set of possibly misleading αs, and the second is the small set of possibly misleading
zs. These are similar to the set bad3 deﬁned for the range checks.

The second twist is that our global speciﬁcation assumes that the prover and the veriﬁer both
have access to a partial speciﬁcation m∗ of values to memory locations. Remember, this is generally
used to specify the Cairo program that has been executed, the agreed-upon inputs, and the claimed
output. The prover has to convince the veriﬁer that there is a memory function m that not only
maps ai to vi for each i < n but is also consistent with m∗. One solution is to add the set of pairs
{(a, m∗(a))}a∈dom(m∗) to the list of pairs (a0, v0), (a1, v1), . . . , (an−1, vn−1), but that is ineﬃcient,
because it requires adding an additional pair of constraints for each element of the domain of
m∗. Instead, we add |dom(m∗)| pairs (0, 0) to the sequence . . . (ai, vi) . . ., and then we change the
constraints to say that the sequence (a′
i)i<n is a permutation of the sequence that results from
replacing these pairs (0, 0) by the pairs (a, m∗(a)). As explained by the whitepaper, it suﬃces to
change the ﬁnal constraint in Section 10 from p (fin.last n) = 1 to the following:

i, v′

p (fin.last n) * Q a : mem_dom mem_star, (z - (a.val + alpha * mem_val a)) =

z^(fintype.card (mem_dom mem_star))

Assuming all the constraints are met, we deﬁne a function m from the sequences (a′

i)i<n and (v′

i)i<n:

def mem (a' v' : fin (n + 1) → F) : F → F :=
λ addr, if h : ∃ i, a' i = addr then v' (classical.some h) else 0

If a value addr occurs in the sequence a', we deﬁne mem addr to be the corresponding value of v'.
We later show that the constraints imply that this value is unique. If addr does not occur in the
sequence, we return 0.

Given this deﬁnition of m (i.e. mem in the formalization), we then show that the memory con-

straints imply the following:

• The memory assignment mem extends the partial assignment mem_star, which is ultimately

speciﬁed in the inp parameter in the ﬁnal correctness theorem in Figure 1.

• The pairs of values a i, v i referred to in the one-step constraints satisfy mem (a i) = v i.

We ultimately have to be explicit as to where the various memory accesses referred to in the cpu
semantics are embedded in the list of pairs (ai, vi). This information is speciﬁed in glue.lean, which
relates the automatically generated polynomial constraints to the informal ones in the whitepaper
description.

This concludes our description of the constraints and our presentation of the main theorem.

16

12 Conclusions

We have veriﬁed the correctness of an algebraic encoding of the Cairo CPU semantics. The encoding
is used to publish, on blockchain, eﬃcient proofs of the correctness of claims about machine-code
execution with respect to that semantics. The veriﬁcation is valuable in its own right, but it is also
an important stepping-stone toward veriﬁcation of higher-level programs in the Cairo programming
language with respect to higher-level descriptions of their behavior.

A notable feature of our work is that the encoding that we have veriﬁed is already in commercial
use.
It is used by the StarkEx platform to carry out cryptocurrency exchanges eﬃciently, and
it is used by StarkNet, which enables developers to implement similarly eﬃcient computational
transactions on blockchain. This places a high premium on establishing the correctness of the
encoding. The whitepaper proof is quite technical, since it requires reasoning about a number
of algebraic constraints and ﬁtting a number of small results together in just the right way.
It
is therefore reassuring that the veriﬁcation of the whitepaper went through straightforwardly and
conﬁrmed the correctness of the implementation.

13 Related Work

The formalization we report on here only addresses the relationship between the machine semantics
and its algebraic representation. It is therefore similar to projects that model processor instruction
sets, such as the x86 instruction set [18, 15] and the Ethereum virtual machine [21, 22, 5].
In
comparison to x86 and even EVM, however, the Cairo machine model is fairly simple. We have
described some of the novel features of the model, such as the fact that it has a read-only memory
and operates on values from a ﬁnite ﬁeld.

We do not know of any project that veriﬁes an algebraic encoding of execution traces. Another
approach to verifying computation using cryptographic protocols involves compiling each individual
program to a set of polynomial constraints that describe its execution, unrolling loops and bounding
the number of iterations, and so on. This method suﬀers from some well-known drawbacks, discussed
in [19, Section 1.1]. Fournet et al. [17] verify the correctness of such transformations, as carried out
by Pinocchio [14, 27].

The more general goal of verifying smart contracts in various senses has become too big an in-
dustry to survey here [31]. Jiao et al. [23] and Ribeiro et al. [28] verify programs written in a subset
of Solidity with respect to a high-level description of the semantics, and Bhargavan et al. [11] verify
smart contracts written in Solidity by translating them to F⋆. Annenkov et al. [6] provide means of
deﬁning and verifying smart contracts in Coq and then extracting code for various blockchain plat-
forms. A number of systems provide means of verifying the correctness of cryptographic protocols
and their implementations, including [1, 2, 3, 9, 12, 4, 29].

Our long-term goal of verifying Cairo programs with respect to a machine semantics (and hence,
with the results here, with respect to the ﬁnal STARK certiﬁcates) makes it similar to other projects
that are designed to verify software with respect to a machine level semantics, such as CompCert
[25], CakeML [24], and VST [13]. Once again, the speciﬁcs of the Cairo platform and its applications
give rise to novel aspects of the veriﬁcation task that we will continue to report on in the future.

17

References

[1] Carmine Abate, Philipp G. Haselwarter, Exequiel Rivas, Antoine Van Muylder, Th´eo Winter-
halter, Catalin Hritcu, Kenji Maillard, and Bas Spitters. SSProve: A foundational framework
for modular cryptographic proofs in Coq. pages 1–15, 2021.

[2] Jos´e Bacelar Almeida, Endre Bangerter, Manuel Barbosa, Stephan Krenn, Ahmad-Reza
Sadeghi, and Thomas Schneider. A certifying compiler for zero-knowledge proofs of knowl-
edge based on sigma-protocols. In Dimitris Gritzalis, Bart Preneel, and Marianthi Theohari-
dou, editors, European Symposium on Research in Computer Security (ESORICS) 2010, pages
151–167. Springer, 2010.

[3] Jos´e Bacelar Almeida, Manuel Barbosa, Endre Bangerter, Gilles Barthe, Stephan Krenn, and
Santiago Zanella B´eguelin. Full proof cryptography: veriﬁable compilation of eﬃcient zero-
knowledge protocols. In Ting Yu, George Danezis, and Virgil D. Gligor, editors, Conference
on Computer and Communications Security (CCS) 2012, pages 488–500. ACM, 2012.

[4] Jos´e Bacelar Almeida, Manuel Barbosa, Manuel L. Correia, Karim Eldefrawy, St´ephane
Graham-Lengrand, Hugo Pacheco, and Vitor Pereira. Machine-checked ZKP for NP relations:
Formally veriﬁed security proofs and implementations of mpc-in-the-head. In Yongdae Kim,
Jong Kim, Giovanni Vigna, and Elaine Shi, editors, Computer and Communications Security
(CCS) 2021, pages 2587–2600. ACM, 2021.

[5] Sidney Amani, Myriam B´egel, Maksym Bortin, and Mark Staples. Towards verifying ethereum
In June Andronick and Amy P. Felty, editors,

smart contract bytecode in Isabelle/HOL.
Certiﬁed Programs and Proofs (CPP) 2018, pages 66–77. ACM, 2018.

[6] Danil Annenkov, Mikkel Milo, Jakob Botsch Nielsen, and Bas Spitters. Extracting smart
contracts tested and veriﬁed in Coq. In Catalin Hritcu and Andrei Popescu, editors, Certiﬁed
Programs and Proofs (CPP) 2021, pages 105–121. ACM, 2021.

[7] L´aszl´o Babai. Trading group theory for randomness.

In Robert Sedgewick, editor, ACM

Symposium on Theory of Computing (SToC) 1985, pages 421–429. ACM, 1985.

[8] L´aszl´o Babai, Lance Fortnow, and Carsten Lund. Non-deterministic exponential time has

two-prover interactive protocols. Comput. Complex., 1:3–40, 1991.

[9] Gilles Barthe, Daniel Hedin, Santiago Zanella B´eguelin, Benjamin Gr´egoire, and Sylvain Her-
aud. A machine-checked formalization of sigma-protocols. In Computer Security Foundations
Symposium (CSF) 2010, pages 246–260. IEEE Computer Society, 2010.

[10] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable, transparent, and
post-quantum secure computational integrity. IACR Cryptol. ePrint Arch., 2018:46, 2018.

[11] Karthikeyan Bhargavan, Antoine Delignat-Lavaud, C´edric Fournet, Anitha Gollamudi,
Georges Gonthier, Nadim Kobeissi, Natalia Kulatova, Aseem Rastogi, Thomas Sibut-Pinote,
Nikhil Swamy, and Santiago Zanella B´eguelin. Formal veriﬁcation of smart contracts: Short
paper. In Toby C. Murray and Deian Stefan, editors, Programming Languages and Analysis
for Security (PLAS) 2016, pages 91–96. ACM, 2016.

18

[12] David Butler, Andreas Lochbihler, David Aspinall, and Adri`a Gasc´on. Formalising ς-protocols

and commitment schemes using crypthol. J. Autom. Reason., 65(4):521–567, 2021.

[13] Qinxiang Cao, Lennart Beringer, Samuel Gruetter, Josiah Dodds, and Andrew W. Appel.
Vst-ﬂoyd: A separation logic tool to verify correctness of C programs. J. Autom. Reason.,
61(1-4):367–422, 2018.

[14] Craig Costello, C´edric Fournet, Jon Howell, Markulf Kohlweiss, Benjamin Kreuter, Michael
Naehrig, Bryan Parno, and Samee Zahur. Geppetto: Versatile veriﬁable computation.
In
Symposium on Security and Privacy (SP) 2015, pages 253–270. IEEE Computer Society, 2015.

[15] Sandeep Dasgupta, Daejun Park, Theodoros Kasampalis, Vikram S. Adve, and Grigore Rosu.
A complete formal semantics of x86-64 user-level instruction set architecture. In Kathryn S.
McKinley and Kathleen Fisher, editors, Programming Language Design and Implementation
(PLDI) 2019, pages 1133–1148. ACM, 2019.

[16] Leonardo Mendon¸ca de Moura, Soonho Kong, Jeremy Avigad, Floris van Doorn, and Jakob von
Raumer. The lean theorem prover (system description). In Amy P. Felty and Aart Middeldorp,
editors, Conference on Automated Deduction (CADE) 2015, pages 378–388. Springer, Berlin,
2015.

[17] C´edric Fournet, Chantal Keller, and Vincent Laporte. A certiﬁed compiler for veriﬁable com-
In Computer Security Foundations Symposium (CSF) 2016, pages 268–280. IEEE

puting.
Computer Society, 2016.

[18] Shilpi Goel, Anna Slobodov´a, Rob Sumners, and Sol Swords. Verifying x86 instruction imple-
mentations. In Jasmin Blanchette and Catalin Hritcu, editors, Certiﬁed Programs and Proofs
(CPP) 2020, pages 47–60. ACM, 2020.

[19] Lior Goldberg, Shahar Papini, and Michael Riabzev.

Cairo — a turing-complete
Cryptology ePrint Archive, Report 2021/1063, 2021.

stark-friendly cpu architecture.
https://ia.cr/2021/1063.

[20] Shaﬁ Goldwasser, Silvio Micali, and Charles Rackoﬀ. The knowledge complexity of interactive

proof systems. SIAM J. Comput., 18(1):186–208, 1989.

[21] Everett Hildenbrandt, Manasvi Saxena, Nishant Rodrigues, Xiaoran Zhu, Philip Daian, Dwight
Guth, Brandon M. Moore, Daejun Park, Yi Zhang, Andrei Stefanescu, and Grigore Rosu.
KEVM: A complete formal semantics of the ethereum virtual machine. In Computer Security
Foundations Symposium (CSF) 2018, pages 204–217. IEEE Computer Society, 2018.

[22] Yoichi Hirai. Deﬁning the ethereum virtual machine for interactive theorem provers. In Michael
Brenner, Kurt Rohloﬀ, Joseph Bonneau, Andrew Miller, Peter Y. A. Ryan, Vanessa Teague,
Andrea Bracciali, Massimiliano Sala, Federico Pintore, and Markus Jakobsson, editors, Finan-
cial Cryptography and Data Security (FC) 2017, pages 520–535. Springer, 2017.

[23] Jiao Jiao, Shuanglong Kan, Shang-Wei Lin, David San´an, Yang Liu, and Jun Sun. Semantic
understanding of smart contracts: Executable operational semantics of solidity. In Security
and Privacy (SP) 2020, pages 1695–1712. IEEE, 2020.

19

[24] Ramana Kumar, Magnus O. Myreen, Michael Norrish, and Scott Owens. Cakeml: a veri-
ﬁed implementation of ML. In Suresh Jagannathan and Peter Sewell, editors, Principles of
Programming Languages (POPL) 2014, pages 179–192. ACM, 2014.

[25] Xavier Leroy. Formal veriﬁcation of a realistic compiler. Commun. ACM, 52(7):107–115, 2009.

[26] The mathlib community. The lean mathematical library. In Jasmin Blanchette and Catalin
Hritcu, editors, Certiﬁed Programs and Proofs (CPP) 2020, pages 367–381. ACM, 2020.

[27] Bryan Parno, Jon Howell, Craig Gentry, and Mariana Raykova. Pinocchio: nearly practical

veriﬁable computation. Commun. ACM, 59(2):103–112, 2016.

[28] Maria Ribeiro, Pedro Ad˜ao, and Paulo Mateus. Formal veriﬁcation of ethereum smart con-
tracts using isabelle/hol. In Vivek Nigam, Tajana Ban Kirigin, Carolyn L. Talcott, Joshua D.
Guttman, Stepan L. Kuznetsov, Boon Thau Loo, and Mitsuhiro Okada, editors, Logic, Lan-
guage, and Security - Essays Dedicated to Andre Scedrov on the Occasion of His 65th Birthday,
pages 71–97. Springer, 2020.

[29] Nikolaj Sidorenco, Sabine Oechsner, and Bas Spitters. Formal security analysis of mpc-in-the-
head zero-knowledge protocols. In Computer Security Foundations Symposium (CSF) 2021,
pages 1–14. IEEE, 2021.

[30] Nick Szabo. Formalizing and securing relationships on public networks. First Monday, 2(9),

1997.

[31] Palina Tolmach, Yi Li, Shang-Wei Lin, Yang Liu, and Zengxiang Li. A survey of smart contract

formal speciﬁcation and veriﬁcation. ACM Comput. Surv., 54(7), 2021.

20

theorem final_correctness

{F : Type} [field F] [fintype F]
(char_ge : ring_char F ≥ 2^63)
/- public data -/
(inp : input_data F)
(pd : public_data F)
(pc : public_constraints inp pd)
(c
: columns F) :
/- sets to avoid -/

∃ bad1 bad2 bad3 : finset F,

bad1.card ≤ (inp.trace_length / 2)^2 ∧
bad2.card ≤ inp.trace_length / 2 ∧
bad3.card ≤ inp.trace_length ∧

∀ ci : columns_inter F,

/- autogenerated constraints-/
cpu__decode c ∧
cpu__operands c ∧
cpu__update_registers c inp ∧
cpu__opcodes c ∧
memory inp pd c ci ∧
rc16 inp pd c ci ∧
public_memory c ∧
initial_and_final inp c ∧
/- probabilistic constraints -/
pd.hash_interaction_elm0 /∈ bad1 ∧
pd.interaction_elm /∈ bad2 ∧
pd.interaction_elm 6= 0 ∧
pd.rc16__perm__interaction_elm /∈ bad3 →
/- the conclusion -/
let T := inp.trace_length / 16 - 1 in
∃ mem : F → F,

option.fn_extends mem inp.m_star ∧
∃ exec : fin (T + 1) → register_state F,

(exec 0).pc = inp.initial_pc ∧
(exec 0).ap = inp.initial_ap ∧
(exec 0).fp = inp.initial_ap ∧
(exec (fin.last T)).pc = inp.final_pc ∧
(exec (fin.last T)).ap = inp.final_ap ∧
∀ i : fin T,

next_state mem (exec i.cast_succ)

(exec i.succ)

Figure 1: The ﬁnal correctness theorem.

21

