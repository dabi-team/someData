2
2
0
2

n
a
J

0
3

]

C
D
.
s
c
[

1
v
9
0
8
2
1
.
1
0
2
2
:
v
i
X
r
a

OverChain: Building a robust overlay with a blockchain

Vijeth Aradhya*

Seth Gilbert*

Aquinas Hobor*

February 1, 2022

Contents

1 Introduction

2 Model

3 Stable Network Size
3.1 Directories .
.
.
3.2 Node joins and lifetimes .
.
3.3

Setting parameters

.

.

.

.

.

.

.

.

.

.
.
.

.
.
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Dynamic Network Size

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
4.1 Network size estimation .
4.2 Resetting parameters .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
4.3 Changing dimensions of hypercube . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.

.
.

.

5 Recovery

6 Lower Bound for Half-life

7 Related Work

8 Discussion

9 Full Analysis

9.1 Recovery analysis .

.

.

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

A More on Recovery

B Pseudocodes for Sub-routines

*National University of Singapore, Singapore. email: {varadhya,seth.gilbert,hobor}@comp.nus.edu.sg.

1

2

6

7
8
9
13

14
15
15
15

17

19

20

24

25
35

43

46

 
 
 
 
 
 
Abstract

Blockchains use peer-to-peer networks for disseminating information among peers, but these networks
currently do not have any provable guarantees for desirable properties such as Byzantine fault tolerance,
good connectivity and small diameter. This is not just a theoretical problem, as recent works have ex-
ploited unsafe peer connection policies and weak network synchronization to mount partitioning attacks
on Bitcoin. Cryptocurrency blockchains are safety critical systems, so we need principled algorithms to
maintain their networks.

Our key insight is that we can leverage the blockchain itself to share information among the peers,
and thus simplify the network maintenance process. Given that the peers have restricted computational
resources, and at most a constant fraction of them are Byzantine, we provide communication-efﬁcient
protocols to maintain a hypercubic network for blockchains, where peers can join and leave over time.
Interestingly, we discover that our design can recover from substantial adversarial failures. Moreover, these
properties hold despite signiﬁcant churn.

A key contribution is a secure mechanism for joining the network that uses the blockchain to help
new peers to contact existing peers. Furthermore, by examining how peers join the network, i.e., the
“bootstrapping service,” we give a lower bound showing that (within log factors) our network tolerates
the maximum churn rate possible. In fact, we can give a lower bound on churn for any fully distributed
service that requires connectivity.

1 Introduction

Blockchains, distributed ledgers, and most other distributed services rely on an “overlay network” to facili-
tate communication among the users of the service. For example, cryptocurrencies like Bitcoin [Nak08] rely
on the peer-to-peer network to provide timely and efﬁcient communication among the peers. The primary
goal of this paper is to give a new Byzantine-resilient algorithm for maintaining an overlay designed for
blockchain networks with high rates of churn, proving it correct, robust, and efﬁcient.

The overlay network is speciﬁcally designed to integrate with a blockchain; in fact, the key insight in this
paper is that by leveraging the blockchain itself to share critical information, we can develop a protocol that
is simpler and more efﬁcient than existing solutions. (In some ways, this is a “cross-layer optimization,”
with the overlay protocol relying on the blockchain for which it provides the underlying communication.)
For example, by using the blockchain, the overlay protocol does not have to pay the cost of running its own
consensus protocols, and does not have to rely on complicated Byzantine-resilient structures. Instead, it
can focus on the simpler task of maintaining an efﬁcient communication network.
Obstacles for overlay maintenance.
Three main challenges arise while building and maintaining an
overlay network designed for use by a (public) blockchain: high rates of churn, the problem of introducing
new peers, and malicious behavior.

When peers join and leave the network, the overlay needs to adapt, integrating the new peers and
removing the departing peers, while maintaining the good properties of the network, e.g., small diame-
ter and small degree. Worse, joins and leaves do not necessarily happen one at a time: many peers can
(concurrently) join and leave the network at any given instant. This poses a unique challenge for peers to
continually reconstruct the network in an efﬁcient way.

In fact, how new peers securely join the network is itself a critical aspect of a peer-to-peer system,
commonly referred to as the “bootstrapping problem” [CDKR02, CH07, DG08]. To join, new peers need
to contact some existing (honest) peers, and since overlay networks are decentralized, it is often not clear
as to who should be responsible for helping new peers. Currently, cryptocurrency blockchains offer two
main options for bootstrapping peers: (1) via DNS seeding and (2) hard-coded IP addresses (in the shipped
software) [LQ19]. Hard-coded seeds are usually a fallback mechanism if the DNS seeding mechanism
fails, as hard-coded IP addresses may become obsolete after a period of time. DNS seeding itself requires
trusting a few sources to respond with random IP addresses that are within the network. Moreover, if
there is a bandwidth constraint on each peer or DNS server, and there are only a handful of DNS servers
responsible for bootstrapping, then the system cannot withstand high churn.

2

The challenge of overlay maintenance is only made worse by malicious behavior. Malicious peers can
create a large number of identities, allowing them to attack an overlay in a myriad of ways. They might
attack the underlying maintenance protocol, conveying bad information about network structure and the
peers joining or leaving. Or they might attack the overlay itself by strategically being concentrated in one
part of the network, possibly with an aim to partition the network (or isolate a single peer), for e.g., as in an
eclipse attack [SCDR04, S+06].

In an eclipse attack, the attackers isolate a subset of peers, and by taking over the connections of those
peers, the adversary is able to control the information ﬂow between them and the rest of the network. In
the context of cryptocurrency blockchains, this attack can be used as a primitive for other attacks such as
double spending, reducing effective honest resources (by forcing a signiﬁcant fraction of peers to mine on
top of an orphan block), and selﬁsh mining [NKMS16, ES14].

Early eclipse attacks [HKZG15, MHG18] exploited unsafe peer storage and connection policies. The ad-
versary set up many incoming connections with the victim peer from diverse IP addresses and propagated
many bogus addresses. Then, there was a high likelihood that the victim would initiate all its outgoing con-
nections with the adversary once the victim restarted. Recently, Saad et al. [SARM21] exploited Bitcoin’s
weak synchronization to create a partition by selectively broadcasting blocks to disjoint groups of miners.
In a parallel work, Saad et al. [SCM21] exploit churn, and partition existing and newly arriving peers. The
adversary occupies all the incoming connections of existing peers, and as peers depart and new peers join,
they only connect with adversarial peers from the sample provided by the DNS seeds.
Prior work. The traditional approach for providing resilience against Byzantine interference in the well-
studied distributed hash table (DHT) literature is replication [NW07, FS07, AS09]. Thus, our starting point
is a virtual network, speciﬁcally a hypercube, in which each vertex of the hypercube is implemented in a
replicated fashion by a set of peers. We will refer to the set of peers that collectively replicate a vertex as
a committee. Such a replication method is useful for ensuring that there are a sufﬁcient number of honest
peers in each committee.

However, replication alone is not enough to guarantee robustness in networks where peers can join and
leave over time [AS04]. For example, a subset of honest peers can stay for a long time, while other honest
peers experience churn, and the Byzantine peers repeatedly rejoin to isolate those honest peers. The join
algorithm becomes crucial in such a setting as it is not only used to maintain the overall network structure
but also in ensuring that the malicious peers are well-spread throughout the committees. Even if there exists
a join algorithm that places a new peer in a random committee, Byzanine peers can overwhelm a committee
with just a linear number of rejoins [Sch05]. Therefore, join algorithms are typically complemented by
“perturbing” the network, where a small number of (existing) peers are shufﬂed among some committees
[Sch05, AS09, GHK13].

Unfortunately, existing solutions to such join-leave attacks are fairly expensive, both from a latency and
message complexity perspective (cf. Table 1). For instance, consider integrating a new peer and placing
it in a random committee. The system would have to run heavy-weight protocols such as distributed
coin ﬂipping [AS04, FSY05, AS09], or rely on random walks [GHK13], to sample a random committee. Or
if the new peer locally uses a hash function to compute a random committee, then the network needs to
continually generate a (global) random string as a (partial) input to avoid pre-computation attacks [JPS+18].
Furthermore, the new peer also needs to be routed to the appropriate committee. Such protocols involve a
logarithmic join latency1, and are hard to implement in practice.

Moreover, existing works do not address the bootstrapping problem, which is crucial for the join algo-
rithms. They make strong assumptions such as the existence of trusted peers that can initiate an unlimited
number of joins, or access to random peers within the network. Jaiyeola et al. [JPS+18] point out that
secure bootstrapping would aid their algorithms and other prior solutions to robust overlay maintenance.
Our goal is to include the bootstrapping process as in integral part of the overlay protocol.

As with any long-lived system, it is possible eventually for something to go wrong. Consider excep-

1As in [JPS+18], we employ a Sybil defense mechanism to control the number of malicious identities. Other prior works [AS04,
FSY05, AS09, GHK13] are also vulnerable to Sybil attacks but they assume such a Sybil mechanism already exists. Join latency does
not include the time taken to solve the puzzle given for Sybil defense.

3

Join latency
(in rounds)

Join comm.
complexity

Group spreading [AS04]
S-Chord [FSY05]
Cuckoo rule [AS09]
NOW [GHK13]
OverChain

O(log N)
O(log N)
O(log N)
O(log4 N)
O(1)

O(log3 N)
O(log3 N)
O(log3 N)
O(log6 N)
O(log3 N)

Polynomial
variation in
network size
(cid:55)
(cid:55)
(cid:55)
(cid:51)
(cid:51)

Recovery
(catastrophic
failures)
(cid:55)
(cid:55)
(cid:55)
(cid:55)
(cid:51)

Table 1: Comparison under different performance metrics.

tional scenarios, termed as catastrophic failures (cf. Section 5), where malicious peers instantly overwhelm a
large number of committees. The existing solutions [AS04, FSY05, AS09, GHK13, JPS+18] heavily rely on
honest majority in committees for the correctness of their algorithms, thus making it hard to recover from
such a scenario. One of the interesting properties of our design is that the overlay recovers fairly naturally
from such disasters.

Our approach

In general, overlay maintenance amidst churn and Byzantine interference requires considerable coordina-
tion among peers. Our insight is that this coordination issue is exactly what blockchains are designed to
solve! Thus, we store auxiliary data on the blockchain to efﬁciently maintain the overlay. The idea of ex-
ploiting on-chain information to simplify and facilitate off-chain distributed algorithms already exists in
practice. For example, payment channel networks2 such as Bitcoin’s Lightning Network [PD16], enable
fast transaction conﬁrmation if users are willing to lock funds in them.

An existing model that captures something of the same idea is a “public bulletin board” [Mit00] where
entities within the system can write information that can be read by everyone. A cryptocurrency blockchain
differs from a typical bulletin board in three ways: (1) the amount of auxiliary information in a block must
be small, (2) the rate at which information can be shared is limited by the block interval, and (3) the network
may never be fully synchronized where each peer holds the same chain. Thus, one of our contributions is
to carefully distill the properties provided by the blockchain in a way that the overlay algorithms can be
concisely described while not losing track of real world implementation.

An important question to ask, then, is how much information overlay algorithms need to store on the
blockchain. We could, for example, try to store the entire membership and topology information — but we
would then be spending a large majority of our blockchain bandwidth in handling the overlay! Instead, our
goal is to use only a constant number of entries per block. Speciﬁcally, each block stores the identity of only
one peer in the overlay. To maintain a virtual hypercube with at most N peers, we rely on a set of about
Θ(
N) peers, which we refer to collectively as
a directory. The fairness of the blockchain ensures that not too many of these peers will be malicious. Each
peer in the directory is responsible for a subset of the committees, and keeps tracks of the members of those
committees.

N) of the most recent blocks which store a set of about Θ(

√

√

A crucial observation is that cryptocurrency blockchains are publicly available, and their contents can be
read by anyone. Speciﬁcally, a recent copy of the blockchain is available to the public at all times, and this
provides an entry point to the service. Blockchain explorers [bit20, blo20, eth20] satisfy this requirement to
some extent; multiple copies may be available but the conﬁrmed3 chain ensures some synchronization, i.e.,
there might be some disagreement about the last few blocks among those explorers.

2They (and most other Layer-2 solutions) make implicit assumptions regarding blockchain not forking (safety) and the maximum

time taken to conﬁrm a transaction on the blockchain (liveness).

3In the blockchain literature, there exists a notion of a “conﬁrmed” chain for which the sequence of blocks (up to that point) will

not change in the future.

4

Figure 1: A new node requesting information about existing nodes in a committee from a set of directory
nodes.

Another problem we face is that malicious peers can create a large number of identities and take control
of the overlay. Again, the blockchain has already solved this problem, typically via proof-of-work. We
adopt the same mechanism for limiting the rate at which new peers join the network.
Overview.
In this way, most of the coordination required by the overlay is handled simply by storing a
small amount of information on each block, leading to a signiﬁcantly simpler approach than is typical for
Byzantine-resilient overlay protocols. A new peer gets a public copy of the blockchain, and computes a
proof-of-work puzzle that determines its (random) committee. The peer then contacts a small number of
directory members to quickly obtain information about existing peers in that committee. The committees
(or directory members) do not need to run a consensus protocol, perform random walks, or do any other
sort of coordination. Figure 1 gives a pictorial overview of our design.
Churn. Furthermore, we seek to understand the limits of the rate of churn. We adopt the half-life approach
to churn rate for honest peers: if there are H peers in the system, then over a speciﬁc interval of time, the
half-life, at most H/2 new peers can join or at most H/2 peers can depart. This allows for highly bursty
behavior, with large numbers of concurrent joins and departures. (Malicious peers can stay for as long as
they like, and can create new identities as fast as the proof-of-work mechanism will let them.) We provide
a lower bound for the feasible half-life that depends on the rate of churn and the bandwidth constraints.

As new blocks are installed on the blockchain, and as existing blocks age, the members of the directory
change, handing off information from old directory members to new directory members in a controlled
process. Similarly, when the number of peers changes signiﬁcantly, the size of the virtual hypercube has to
change, migrating information to new directory members. Both of these processes of information exchange
have to be carefully managed to avoid Byzantine interference.
Recovery. Finally, the blockchain is not just an alternative interface for new peers to join, it also aids the
overlay to recover from catastrophic failures. As long as most of the committees and directory are still func-
tioning properly, our observation is that the overlay operates sufﬁciently well to continue installing new
blocks, to continue replacing directory and committee members, and restoring the fully correct operation
of the overlay, i.e., to ensure that there are again sufﬁcient number of honest peers in every committee.

Summary of results

We exploit the blockchain for bootstrapping peers, (global) coordination among peers (for e.g., agreement
on new topology, etc.) and recovery from arbitrary committee failures. We summarize our contributions
(that hold with high probability4), in the context of a network with at most N peers, where the average
block interval is β.

4In this paper, “with high probability” (abbreviated as “whp”) refers to a probability of at least 1 − N−k where N is the number of

peers and k > 1 is an appropriate constant.

5

1. We design protocols to maintain a dynamic hypercubic network of Θ(log N)-sized committees, where

the half-life is α = Θ(β

N log N) and the network size can vary polynomially over time.

√

2. We prove that the graph formed by the honest peers remains connected for polynomial number of

rounds, and each peer sends/receives only O(log3 N) messages per round.

3. We show that even when catastrophic failures occur (e.g., a constant fraction of committees and their
corresponding directory members are instantly corrupted), the overlay recovers within a small num-
ber of half-lives.

4. We give a lower bound, barring log-factors, for minimum feasible half-life, α = (cid:101)Ω((cid:112)βN), showing
that it is impossible to tolerate higher rates of churn, even if peers share a public bulletin board that
can be used for joining.

2 Model

Entities. A peer is the real-world entity that participates in the blockchain network. There are two types of
peers: (1) honest peers that follow the speciﬁed protocols, and (2) Byzantine peers that may deviate from
the protocols in an arbitrary way. The network size refers to the total number of peers within the network.
The maximum network size is denoted by N, though a peer can control multiple identities or nodes within
the network.
Communication. The system proceeds in synchronous rounds; in each round, in addition to local computa-
tion, a message that is sent at the beginning of a round by a peer is assumed to reach its neighbours by the
end of that round. Each peer maintains a set of neighbouring peers that it is said to be connected with, i.e.,
those peers are used for sending and receiving information.
Computational restriction. The peers are associated with a hash power constraint, i.e., each peer owns one
unit of hash power that allows the peer to query a hash function (modelled as a random oracle) q > 1 times
in a round [GKL15, PSS17]. (If some entity has more hash power, then it can be viewed as a coalition of
peers.) Given an input of any length, the hash function is assumed to provide a random output of (ﬁxed)
length κ = Θ(log N).
Blockchain.
If there is a graph (where vertices are honest peers and edges are connections) of at least
µn(1 − ρ)n honest peers5 with a diameter of ∆ ≤ 2 log N, and there are at most ρn Byzantine peers, for
appropriate constants ρ < µn < 1, where n is the current number of peers, then the blockchain is guaranteed
to provide the following properties for those honest peers with probability at least 1 − 2−κ.

Safety. There exists a notion of conﬁrmed chain6 Cr

u for any honest peer u in round r.

• (∆-Synchronization) If |Cr

u| is the length of the conﬁrmed chain of honest peer u at round r, then by

round r + ∆, every honest peer’s conﬁrmed chain’s length is at least |Cr

u|.

• (Consistency) Cr
is a preﬁx of Cr

u is always a preﬁx of Cr(cid:48)
v, and for a large enough constant µs, |Cr

u| − |Cr

v| ≤ µs.

u for any round r(cid:48) ≥ r. At any round r, if |Cr

u| ≤ |Cr

v|, then Cr
u

Liveness. For large enough T and constant µb, any consecutive T ≥ Ω(1) blocks are included in any

conﬁrmed chain in [Tβ/µb, Tµbβ] rounds, where β is said to be the average block interval.

δ-Approximate Fairness. Any set of honest peers controlling a ϕ fraction of hash power own at least a

(1 − δ)ϕ fraction of the blocks in any Ω(κ/δ) length segment of the chain [PS17].

Public Availability. There exists an introductory service I that provides a copy of an existing honest
peer’s blockchain. (In practice, this typically means that there exist a set of publicly available blockchains,

5We consider a (large) subset of honest peers because the network can get split into multiple components during a catastrophic

failure (cf. Section 5).

6We do not delve into details of how to obtain this conﬁrmed chain as this may be blockchain-speciﬁc, for example, Bitcoin deems

a block to be conﬁrmed if it is at least 6 blocks deep.

6

of which at least some are honest. The analysis holds if the public copies are slightly outdated, say by a
constant number of blocks.)
Adversary. We consider Byzantine peers that can collude and arbitrarily deviate from the speciﬁed proto-
cols. In any round, the number of Byzantine peers is at most a ρ fraction of the network size. They know
the entire network topology in any round, but they cannot modify or delete messages sent by honest peers.
The goal of Byzantine peers is to disturb the normal functioning of the overlay, for e.g., isolate a subset of
honest peers by occupying all their connections, or increase the diameter of the overlay, etc.
Churn. We consider an adversary [AS09, GHK13] that speciﬁes the join/leave sequence σ for honest peers
in advance. But it can choose to adaptively join/leave a Byzantine peer. In particular, after the ﬁrst i events
in σ are executed, the adversary can either choose to join/leave a Byzantine peer or initiate the (i + 1)th
event in σ. (This models scenarios such as an honest peer h stays for a long time, and the other honest
peers are subjected to churn, and Byzantine peers can adaptively rejoin until h’s neighbouring peers are
Byzantine.)
Churn rate. We consider the half-life measure [LNBK02] to model the churn rate for honest peers. Formally,
at any given round r, the halving time is the number of rounds taken for half the number of honest peers
(which were alive at round r) to leave the network; similarly, the doubling time is the number of rounds
required for the number of honest peers to double.

An epoch, denoted by α, is deﬁned as the smallest halving time or doubling time over all rounds in the
execution. Furthermore, we assume that the epoch is much greater than the average block interval; in other
words, α (cid:29) β log N.
Honest peer failure. By the churn rate assumption, at most half of the honest peers that are alive at round
r can leave (fail) by the end of r + α rounds. (We do not make any distinction between a leave event and
a failure.) Since the adversary has to obliviously specify the join/leave sequence for honest peers (and
they are initially assigned random identities), each honest peer is assumed to (independently) fail with a
probability p f ≤ 0.5 in each epoch, where pf is the fraction of honest nodes that leave during the epoch.
Change of network size. The network size can change by a factor of at most 2 in any epoch. It can polyno-
mially vary over time; the number of peers at any round r, Nr ∈ [N1/y, N] for some constant y > 1.

3 Stable Network Size

In this section, we assume that the total number of peers is ﬁxed and equal to Θ(N). In Section 4, this
assumption is relaxed, where we allow a polynomial variation in network size over time. (For simplicity,
we avoid using ﬂoor/ceiling repeatedly unless necessary.) We describe the protocols for a peer by making
use of the access to its conﬁrmed chain. We now describe the overlay structure and our high-level approach.
Nodes. Each peer generates and controls Θ(log N) (virtual) nodes in the overlay. Each peer participates
(sends and receives messages) in the network through its nodes. All peers are required to perform proof-
of-work to generate nodes. Each node has a lifetime after which it will be considered invalid (or removed).
There are two roles of a node: a (1) directory node, and a (2) non-directory node. Every node is initially a
non-directory node, but some nodes become directory nodes as well, playing both roles.
Committees. Our protocols maintain a structured network of committees, speciﬁcally, a hypercube whose
In total, there are C = N committees, each consisting of Θ(log N)
vertices correspond to committees.
nodes. (Logarithmic redundancy is used to show that each committee has a sufﬁcient number of honest
peers amidst churn, so that the hypercube structure is maintained.) Each committee is identiﬁed by a
(unique) committee ID of log N bits. As a peer may be controlling multiple nodes, it may be present in
multiple committees.
Directory node. A peer that successfully adds a block to the blockchain promotes one of its nodes to a
directory node. While trying to mine for blocks, each peer adds its network address into the prospective
block. The directory nodes are responsible for helping incoming new nodes to join a (random) committee.
(Recall that a new node can contact directory nodes as a copy of the blockchain is publicly available.) They
do so by providing the network addresses of the required committee members.

7

High-level overview. Byzantine peers can repeatedly join and leave until they get placed in a speciﬁc set
of committees. This can result in most of an honest node’s neighbours being Byzantine over time, as other
honest neighbours can leave (due to churn). We enforce a limited lifetime (that is close to the half-life of
honest peers) for all nodes so that an honest node would have to leave and rejoin some other (random)
committee, whilst some of its neighbours are still honest. The technical difﬁculty lies in designing a secure
bootstrapping mechanism while handling churn, bandwidth-constraints and Byzantine interference.

3.1 Directories

Directory nodes are critical for maintaining membership information of nodes in the network. A directory
comprises B consecutive “buckets”, and each bucket consists of consecutive λd log2 N blocks, where λd is
a suitable constant. Each peer that creates a block added to the conﬁrmed chain becomes part of one of the
buckets in the directory (via one of its nodes). A directory node can be associated with its block number.
The total number of directory nodes is equal to K = Bλd log2 N.

Since directory nodes help new peers join the network, we need to show that there always exists enough
honest directory nodes in each bucket amidst churn. Using the fairness assumption, it turns out that
Θ(log2 N) bucket size is sufﬁcient to show that there are Ω(log N) honest peers.
Functions. Each bucket is responsible for a set of committees, i.e., all the directory nodes in that bucket are
supposed to help new nodes join a speciﬁc set of committees. There are two main functions of a directory
node.

1. A directory node stores information about nodes belonging to a set of committees. Speciﬁcally, if a
new node joins one of those committees, then it stores the new node’s entry information7 (that includes
network address, etc.).

2. A directory node sends information about committees that the directory node is responsible for. It
sends entry information about all the existing nodes in the committee that the new node belongs to,
or its neighbouring committees.

Phases of a bucket. The buckets can belong to one of the following four phases; the directory nodes are also
classiﬁed into those four phases in the same way as buckets. We describe a directory node’s functions at
each phase, since its inception in the conﬁrmed chain. This is summarized in Table 2. (The chain is divided
into buckets since the beginning, resulting in periods where the chain length may not be an integral multiple
of λd log2 N. Except in infant phase, a bucket in every other phase has all the λd log2 N blocks conﬁrmed.)
1. Infant. A bucket in which at least one block (out of λd log2 N) is conﬁrmed, but not all the λd log2 N
blocks are conﬁrmed yet. The nodes do not store the incoming new nodes’ entry information. They
do not respond to the incoming new nodes about any committees.

2. Middle-aged. These nodes store incoming new node entry information, and reply to them about the

relevant committees’ information that they know about.

3. Veteran. These nodes do not store new nodes’ entry information, but they do reply about the relevant

committees’ information known to them.

4. Dead. These nodes (as in infant phase) neither store any new node information, nor reply to new

nodes about any committee information.

Phase transitions. As new blocks are added, new directory nodes take over the functions of old directory
nodes. For a peer within the network, we detail the transitioning of a directory node from one phase to
another. (In the transitions, there is a delay of ∆ rounds is to ensure that the conﬁrmed chains of honest
peers reach the same height before making those transitions.)

7See JOIN protocol description in Section 3.2 for the exact deﬁnition. The word “entry” may be dropped when the context is clear.

A committee’s information refers to the set of all its nodes’ entry information.

8

Store entry info Reply entry info

Phase
Infant
Middle-aged
Veteran
Dead

(cid:55)
(cid:51)
(cid:55)
(cid:55)

(cid:55)
(cid:51)
(cid:51)
(cid:55)

Table 2: Phases and functions of a directory node.

1. Infant to Middle-aged. If all λd log2 N blocks of the bucket are conﬁrmed in the blockchain, then the

bucket transitions to middle-aged phase.

2. Middle-aged to Veteran. If the bucket is not among the most recent (conﬁrmed) B buckets, then the

bucket transitions to veteran phase after a delay of ∆ rounds.

3. Veteran to Dead. If the bucket is not among the most recent (conﬁrmed) Bact buckets, then the bucket

transitions to dead phase after waiting for ∆ rounds.

Committee-Directory mapping. There exists a predetermined mapping M : [C] → [B] from committees to
buckets for a directory. The mapping is set such that each bucket is responsible for (almost) the same num-
ber of committees, and the sets of committees that any two buckets (in the same directory) are responsible
for, are disjoint. (This is done so that the join requests are load balanced across the directory.) This mapping
is useful for new nodes joining the network, to know which directory nodes to contact, to get information
about relevant committees.
Active directory. The active directory, also known as bootstrapping service, is the most recent Bact consecu-
tive (conﬁrmed) buckets. Due to phase transitioning, the most recent B consecutive (conﬁrmed) buckets,
forming an entire directory, are middle-aged. The rest of the buckets, forming one or more directories, are
veteran. This means that there are multiple buckets (across different directories) that are responsible for
a given set of committees (but only one of them being in middle-age phase). The number of blocks and
number of buckets in an active directory are denoted as Kact and Bact respectively.

New nodes ﬁgure out the sequence of buckets in the active directory (using the introductory service’s
chain, block numbers and committee-directory mapping), and contact the relevant buckets to get the re-
quired committees’ entry information for joining the network. The delay of ∆ rounds in transitions makes
up for any lag in the chain provided by the introductory service. An example of an active directory with its
buckets in different phases is illustrated in Figure 2.

A new node must provide a proof for joining the network. The directory nodes only interact with a
new node if its proof is valid. Section 3.2 provides details on the proof for joining and storing/sending
committee entry information to a new node. Algorithm 1 provides a succinct description of the protocol
followed by a directory node, from Infant to Dead phase, including the functions and transitions. The
pseudocodes for the subroutines VERIFY_PROOFS, STORE_INFO and REPLY_INFO are given in Appendix B,
though they are self-explanatory in the given context.

3.2 Node joins and lifetimes

Our network utilizes proof-of-work as Sybil defense to limit the number of nodes controlled by any peer in
any round, requiring peers to continuously mine for nodes, in addition to blocks.
Proof for joining. Let Nc be the nonce, ˆBl be the hash of the latest conﬁrmed block Bl, and net_addr be the
network address of the peer. Then, the peer evaluates, Pjoin = H( ˆBl (cid:107) net_addr (cid:107) Nc), to join the network
through a new node. If Pjoin < Tjoin, where Tjoin is the mining target for joining the network, then the node
is considered to be a “valid” node, which means that the peer would be able to communicate with the
bootstrapping service to register that node, and join the network. (A directory node rejects the proof if Bl is

9

Figure 2: An illustration of an active directory of length equal to two directories, wherein each directory
has four buckets. The bucket numbers are denoted inside the bucket. The blue buckets, which are the
most recent 4 (fully formed) buckets in the blockchain, are middle-aged. They both store and respond
with committee information. The purple buckets, which are the next 4 buckets in the active directory, are
veteran. They only respond with committee information. The grey buckets and the ones after them, are
dead and do not participate in bootstrapping of new nodes. The green blocks being formed towards the
end, are part of the infant bucket. They start functioning once they become middle-aged.

not among the most recent µs blocks in its conﬁrmed chain, as every pair of honest peers’ conﬁrmed chains
differ by at most µs blocks.)
Joining the network. A node’s entry information constitutes its network address, the nonce Nc and the block
number of the block that was used while mining for that node. Recall that a new peer gets a copy of the
blockchain by the introductory service. We now describe the steps taken by a peer p to generate and join a
new node q into the network. See Algorithm 2 for the pseudocode of JOIN protocol.

1. Solve puzzle. The peer expends computational resources to generate a valid node q. The leftmost log N
bits of Pjoin represent the ID of the (random) committee, denoted by c, to which this new node would
belong to. Let Crel be the set of neighbouring committees of c, including c.

2. Store info. Let bc

m be the middle-aged bucket responsible for committee c. Peer p sends (JOINING, entry

information of q) to all nodes in bc

m. (The directory nodes in bc
3. Request info. Let Bc be set of all buckets responsible for committee c. For each k in Crel and each b in Bc,
peer p sends (REQ_INFO, k, entry information of q) to λj log N nodes that are sampled uniformly and
independently from b, where λj is a suitable constant. (For each k in Crel and each b in Bc, a directory
node in b sends a COMM_INFO message consisting of its knowledge of entry information of nodes in k,
if it received a REQ_INFO message from q.)

m store q’s entry information.)

4. Handle ∆-synchrony. Let b1 and b2 be the ﬁrst and (B + 1)th conﬁrmed buckets (i.e., most recent middle-
aged and veteran buckets). If the number of blocks conﬁrmed after bucket b1 is at most µs, and if b1 is
responsible for committee c, then send (JOINING, entry information of q) to all nodes in b2.

5. Join committee. Node q takes the union of entry information in the COMM_INFO messages for each com-
mittee (as the adversary can only underrepresent the nodes in a committee). Node q sends (JOINING,
entry information of q) to the nodes in each committee c in Crel.

The key observation is that a constant fraction of directory nodes in a bucket are honest and available at
any time, due to the logarithmic redundancy in buckets and blockchain fairness. Thus, it is sufﬁcient for the
new node needs to hear back information from O(log N) directory nodes in each bucket (Step 3), reducing
the communication complexity of join down to O(log3 N), i.e., the new node contacts at most log N buckets,
wherein O(log N) directory nodes in each bucket reply with committee information of O(log N) nodes.
Perturbing the network.
To avoid Byzantine peers repeatedly rejoining to populate a speciﬁc set of
committees, while exploiting the churn of honest peers, a standard solution is to employ a limited lifetime

10

Algorithm 1 DIR protocol
Require: A peer runs this protocol for its node that is embedded in block b in its conﬁrmed chain, after b
becomes part of a bucket bkt (end of infant phase). Let M1 be the set of all JOINING messages received
in a round. Let M2 be the set of all REQ_INFO messages received in a round.

Ensure: Contribute to the bootstrapping service via its directory node.

V1 ← VERIFY_PROOFS(M1), V2 ← VERIFY_PROOFS(M2).
STORE_INFO(V1).
REPLY_INFO(V2).

V1 ← VERIFY_PROOFS(M1), V2 ← VERIFY_PROOFS(M2).
STORE_INFO(V1).
REPLY_INFO(V2).

1: while bkt ∈ most recent conﬁrmed B buckets do
2:
3:
4:
5: end while
6: for ∆ rounds do
7:
8:
9:
10: end for
11: while bkt ∈ most recent conﬁrmed Bact buckets do
12:
13:
14: end while
15: for ∆ rounds do
16:
17:
18: end for

V ← VERIFY_PROOFS(M2).
REPLY_INFO(V).

V ← VERIFY_PROOFS(M2).
REPLY_INFO(V).

for the nodes (and force them to rejoin) [AS04]. As this would keep the system in a hyperactive state, the
node lifetime should be as large as possible. However, if the node lifetime is too large compared to the half-
life, then the adversary may be able to isolate peers. Thus, we set the node lifetime to be Θ(α/β) blocks,
which amounts to Θ(α) rounds (constant number of half-lives) due to blockchain liveness. This helps us
show that at most a constant fraction of any honest peer’s neighbours are Byzantine at any time.
Entry time. Peers attach the hash of the most recent conﬁrmed block Bl (given by the introductory service)
as part of the input to the hash function when they are mining a new node. The proof for joining conve-
niently records the new node’s “entry time” (in terms of block number). This helps other peers to keep
track of a node’s “age” as they would have received its entry information in their ﬁrst interaction with the
node.
Lifetime of non-directory node. The lifetime of a non-directory node is Tl = λlα/β blocks, where λl is a
suitable constant. The node u that had joined at block bl would be considered invalid after block bl + Tl is
conﬁrmed, where bl is the block number of block Bl, at which point the peer stops controlling that node u,
and all the other peers that had node u as its neighbour remove u from their nodes’ neighbour list.
Lifetime of directory node. If a node is promoted to a directory node, then it obtains another life (separate
from the non-directory life). When a node becomes a directory node, it continues to perform the functions
of a non-directory node as long as the non-directory role is considered to be valid. The directory node is
considered to be alive for Tdl blocks since the block in which it is embedded in. We set Tdl to be λdlα/β
blocks, where λl < λdl is some constant.

A directory node’s lifetime is determined by how long it needs to stay in each of its phases. Firstly, if a
directory node is the ﬁrst node to be part of a bucket, then it needs to be alive for λd log2 N blocks (size of a
bucket). Secondly, a directory node stays in the middle-aged phase until the next bucket that is responsible
for the same set of committees is formed, and this takes K blocks. Finally, a directory node needs to be in
veteran phase only until some (non-directory) node in one of the committees that it is responsible for, is still
valid. And this takes at most Tl blocks. The lifetime of directory node Tdl is slightly more than Kact because
there is a delay of ∆ rounds in the transitions. Thus, Tdl > (1 + B)λd log2 N + Tl.

11

Algorithm 2 JOIN protocol
Require: Chain provided by introductory service I. Let Bc be set of all buckets responsible for a committee
m be the middle-aged bucket responsible for a committee c. Let b1 and b2 be the ﬁrst and (B + 1)th

c. Let bc
conﬁrmed buckets. Let H(.) denote the hash function.

Bl ← Most recent conﬁrmed block of the chain given by I.
ˆBl ← H(Bl).
Pjoin ← H( ˆBl (cid:107) net_addr (cid:107) Nc).

Ensure: To generate and register a node in the active directory, and join the network.
1: Pjoin ← ∞.
2: Nc ← 0.
3: while Pjoin ≥ Tjoin do
4:
5:
6:
7: Nc ← Nc + 1.
8: end while
9: c ← Leftmost log N bits of Pjoin.
10: Crel ← Set of neighbouring committees of committee c, including c.
11: SEND (JOINING, entry information of q) to all nodes in bc
m.
12: if number of blocks conﬁrmed after bucket b1 ≤ µs then
if b1 is responsible for a committee in Crel then
13:
14:

SEND (JOINING, entry information of q) to all nodes in b2.

end if

15:
16: end if
17: for each committee k in Crel do
18:
19:
20:

for each bucket b in Bc do

R ← λj log N nodes sampled uniformly and independently from b.
SEND (REQ_INFO, k, entry information of q) to all nodes in R.

end for

21:
22: end for
23: for each committee c in Crel do
24:
25: U ← Union of entry information in the received COMM_INFO messages.
26:
27: end for

SEND (JOINING, entry information of q) to all nodes in U.

RECEIVE (COMM_INFO, c) from each Bc.

12

Node generation rate. Let pn be the difﬁculty threshold for node mining. It is the probability that a single
hash query is successful in generating a valid node. Tjoin is set such that, in each epoch, the expected number
of valid nodes that can be generated is equal to pnqαN = λn N log N, where λn is a suitable constant, so that
each committee has Θ(log N) nodes at any time. This is because in every epoch, about Θ(N log N) nodes
join, while a similar number of them leave due to limited lifetime (set to be a constant number of epochs).

3.3 Setting parameters

Constraints on α and B. The ﬁrst constraint between α and B arises due to the lifetime of a non-directory
node,

B ≤ Θ

(cid:32)

(cid:33)

α
β log2 N

.

(1)

Furthermore, a natural constraint on α and B arises due to the entry of new nodes. Due to node generate
rate, the system must be able to allow λn N log N nodes to enter the network in any α (consecutive) rounds.
As a new node sends the (same) join request to all directories within the active directory (as it contacts
both middle-aged and veteran buckets), it sufﬁces to focus on the number of join requests handled by one
directory. (Here, “join request” can be JOINING or REQ_INFO message of a valid new node.)

Due to the Sybil defense mechanism, we can ensure that the join requests are load-balanced across all
the rounds in an epoch. Let λjr be the highest number of join requests that can be handled by a bucket
per round. For any directory, we calculate the total number of join requests that need to be handled in any
round to be

Bλjr ≥ Θ

(cid:33)

(cid:32)

βN log2 N
α

,

(2)

where LHS of the inequality is the total number of join requests that can be handled in a round, and RHS
represents the minimum number of join requests that need to be handled in a round. We now provide an
explanation for the extra β and log N factors, i.e., the half-life and number of buckets in a directory are
appropriately increased to handle some extra join messages such that for any peer, the total communication
complexity per round is O(log3 N). (Refer to Lemma 9.12 for the full details.)

• Recall that a directory node accepts the proof if the block used for the puzzle is among the µs most
recent conﬁrmed blocks. Thus, the adversary can launch a pre-computation attack of join messages
generated over a period of constant number of block intervals, which amounts to about Θ(β) rounds
(due to blockchain liveness).

• The extra log N factor arises due to new nodes having to contact O(log N) buckets while joining.

√

Setting α and B. Ideally, the overlay needs to be robust for the smallest possible half-life, so that the network
can withstand the limits of churn. Due to the aforementioned constraints, and to ensure a bandwidth cost
of O(log3 N) messages per round for a peer for overlay maintenance, we get that α = Θ(β
N log N) and
B = Θ(
N/ log N). It may seem that the churn rate is rather low, but in Section 6, we show that this value
of α is close to optimal. Speciﬁcally, we show that any dynamic system where peers have a bandwidth-
constraint of polylog(N) messages per round, that uses a blockchain as an entry point in bootstrapping,
must have α = (cid:101)Ω((cid:112)βN).

√

Bootstrapping network

In this work, we only focus on maintaining the overlay, and make an assumption that at time zero, the
network has formed a hypercube structure of committees, with Θ(log N) honest peers in each committee,
and Θ(log2 N) honest nodes in each bucket of the ﬁrst (active) directory, and each peer controlling at most
O(log N) nodes. If N0 is the number of peers in the beginning of the execution, then the number of com-
mittees C = N0. In each committee, the honest nodes are connected to each other, and each honest node

13

is connected to Ω(log N) honest nodes in each neighbouring committee. Each directory node knows en-
try information of the required committees. Moreover, the node difﬁculty threshold is appropriately set,
pn = (λn log N)/(qα). At this point, the network allows dynamic participation and satisﬁes the required
properties.

4 Dynamic Network Size

In this section, we augment the protocols described in Section 3 to handle changing numbers of peers.
The main problem caused by polynomial variation in network size is that the peer redundancy factor in
committees gets affected, i.e., the system needs to adapt to maintain logarithmic redundancy. One way to
deal with the problem, is to keep the number of committees ﬁxed and change the node difﬁculty threshold,
pn. But if the network size keeps decreasing, then each peer would need to simulate too many nodes at any
time in order for the system to maintain Θ(log N) nodes in every committee. And if the network size keeps
increasing, then some peers may not be able to participate in the network all the time because they may
take too long to generate nodes. Therefore, we ﬁx pn = (λn log N)/(qα), and provide protocols to switch
to a new hypercube of a different dimension.

Our key insight is that the switch to a new topology can be carried out in a straightforward manner
by exploiting the global coordination provided by the blockchain. We begin by providing a high-level
intuition of our approach. The ﬁrst step is to efﬁciently estimate the network size in every constant number
of epochs (cf. Section 4.1). First, each node keeps track of new nodes that joined its committee in a span of
ﬁxed number of blocks. Then, all the nodes of a (random) committee broadcast the entry information of all
new nodes that joined that committee. Finally, using a balls-and-bins argument, all the peers can get a good
estimate of the network size, and they simply use the blockchain to agree on it. This estimate is used for the
next two components of handling varying network size: (1) resetting overlay parameters and (2) changing
dimension of the hypercube.

Each peer computes the overlay parameters, namely, trigger for dimension change and number of com-
mittees (in the next hypercube), using the network size estimate. Using the blockchain fairness property, all
the peers arrive at a consensus on the parameters by taking the majority over Θ(log N) consecutive blocks
(cf. Section 4.2). During dimension change, the directory goes into a “split state” for about an epoch, serv-
ing committees in the current hypercube and also constructing committees in the next hypercube (i.e., new
nodes also get placed in the next hypercube). Until each committee in the next hypercube has sufﬁcient
number of new (honest) nodes, the overlay operates in the old hypercube. The directory then stops serving
committees in the old hypercube, and the network adopts the new hypercube for broadcasting blocks (cf.
Section 4.3).

Time in terms of b-epochs

Our protocols, in contrast to the ones described in the previous section, require considerable coordination
among the peers at regular intervals. To describe the protocols, we divide a period of Θ(α) rounds into two
“phases”. Phase 1 is called the estimation phase, where the existing peers calculate an estimate of the total
number of nodes that joined in that phase to get a good estimate of the network size. There are α1 rounds
in phase 1. Phase 2 is called the agreement phase, where the peers reach an agreement (via blockchain) on
the new difﬁculty threshold and the decision to change dimension. There are α2 rounds in phase 2. These
two phases make up the epoch, α = α1 + α2. The length of phase 2 is actually much smaller than the length
of phase 1 (by design, see Section 4.2), i.e., α2 (cid:28) α1; in particular, α1 = Θ(α).

Analogous to an epoch, we say that α/(µbβ) consecutive blocks is called a b-epoch. The number of

rounds elapsed during that period of block intervals is

, α

due to blockchain liveness. Similarly, the

(cid:21)

(cid:20)

α
µ2
b β

phase 1 of a b-epoch consists of α1/(µbβ) consecutive blocks. The peers rely on the most recent conﬁrmed
block number to establish: (1) the start of a b-epoch, and (2) the end of the ﬁrst phase of a b-epoch. The idea
is to ﬁx multiples of an appropriate block number to mark the start and the end of phase 1 of a b-epoch.

14

Thus, using blockchain safety, the honest peers can run the protocols at (approximately) the same time,
albeit at most ∆ rounds delay.

4.1 Network size estimation

The peers require a good estimate of the network size for changing the dimension of the hypercube. This is
done in phase 1 of every b-epoch. Algorithm 3 provides the pseudocode of NET_SIZE_EST protocol.

1. Each node keeps track of the set of (new) nodes that join its committee from start of a b-epoch e to end

of phase 1 of b-epoch e.

2. Let bk

e be the block that marks the end of phase 1 of b-epoch e. Let the leftmost (cid:100)log Ce(cid:101) bits of H(bk
e )
determine a random committee s (due to random oracle assumption), where Ce is the number of
committees in b-epoch e.

3. All the nodes belonging to committee s broadcast the entry information of nodes that joined commit-

tee s in phase 1.

4. The peers in the other committees take the union of the responses to obtain the set of nodes that joined

committee s in phase 1. Let He be the total number of those nodes.

5. G(cid:48)

e = HeCe is the estimate of total number of new nodes that joined in phase 1. Using this estimate,
e = µbG(cid:48)

the nodes calculate the network size estimate M(cid:48)

e/(pnα1).

4.2 Resetting parameters

Once a peer gets a good estimate of the network size after phase 1, it can (locally) determine the overlay
parameters for the next b-epoch. ch_dim is a parameter that controls whether a dimension change is to be
triggered; if it is, then ch_dim speciﬁes dimension increase or decrease, and otherwise, ch_dim speciﬁes no
change. (Section 4.3 provides details on how ch_dim is determined.) Ce+1 is changed to λsC if the dimension
is to be increased in the next b-epoch, or to Ce/λs if the dimension is to be decreased in the next b-epoch,
where λs is a large constant; otherwise, remains the same as Ce. This helps the new nodes joining in the
b-epoch e, to know the committee-directory mapping Me for JOIN protocol.

When a peer mines a block after phase 1 of b-epoch e, in the next λlb log N = α2/µbβ blocks, it adds
the overlay parameters onto the block, where λlb is a suitable constant. Due to blockchain fairness, we can
ensure that the majority of those blocks belong to honest peers, which helps in reaching consensus on those
values by the end of the epoch. Since α (cid:29) β log N (Section 2), as previously mentioned, α1 = Θ(α). (Note
that if β log N is greater than or close to the half-life, then the network size can change signiﬁcantly during
the time required for reaching an agreement over its estimate.)

4.3 Changing dimensions of hypercube

The challenge is to carry out a smooth transition to a new hypercube having a different committee-directory
mapping, with sufﬁcient number of nodes in each committee, whose information is held by the associated
directory nodes. The key idea is to trigger a dimension change at the end of a b-epoch, wait for one b-epoch
wherein new nodes get assigned to (random) committees of the new hypercube (while the system functions
using the existing hypercubic overlay), and then switch to the new hypercube in the next b-epoch. The
advantage of waiting for one b-epoch for the network to get “reconstructed”, is that the directory nodes can
simply perform their functions for both hypercubic overlays until the new hypercube is adopted, avoiding
complicated entry information transfer between buckets.

There is a delay of one b-epoch in switching to the next hypercube of a different dimension, i.e., if the
peers decide to change the dimension during phase 2 of a b-epoch e, and they wait for one b-epoch, and
then adopt the next hypercube in b-epoch e + 2. The b-epoch before which the next hypercube is actually

15

Algorithm 3 NET_SIZE_EST protocol
Require: Start this protocol at the beginning of a b-epoch e. Let l and k denote the block numbers of the
most recent conﬁrmed block and block that marks the end of phase 1 of b-epoch e respectively. Let
bt denote the block in the conﬁrmed chain with block number t. Let the node u running this protocol
belong to committee c. Let M be the set of all JOINING messages received in a round.
e ∈ [(1 − δerr)(1 − ρ)ML

e are min-
imum and maximum network sizes in phase 1 of b-epoch e, and δerr < 1 is a small positive constant.

e /µb, (1 + δerr)µb MH

Ensure: Output M(cid:48)

e such that M(cid:48)

e ] where ML

e and MH

Cu ← {}.
while l < k do

(cid:83) V. // Store entry information of nodes that join committee c.

V ← VERIFY_PROOFS(M).
Cu ← Cu
end while
s ← Leftmost (cid:100)log Ce(cid:101) bits of H(bk). // Pick random committee.
Wait for ∆ rounds. // All honest peers reach end of phase 1.
if s is c then

He ← |Cu|. // Number of phase 1 node joins in committee c.
BROADCAST (EST_INFO, Cu).

else

Wait for ∆ rounds. // Wait for the broadcast to be completed.
RECEIVE (EST_INFO, Cv) where Cv is a set of JOINING messages broadcasted by some node v in com-
mittee s.
Cs ← (cid:83) Cv. // All phase 1 node joins in committee s (cid:54)= c.
He ← |Cs|.

end if
G(cid:48)
e ← HeCe. // Estimate of total number of phase 1 node joins.
e ← µbG(cid:48)
M(cid:48)
e/(pnα1). // Estimate of network size.
Output M(cid:48)
e.

16

adopted, is called a transformation b-epoch. The decision to trigger a dimension change is taken in b-epoch
e assuming a worst-case change of factor of 2 to the network size over the next two epochs; the decision
depends on whether there is a possibility that the network size in b-epoch e + 2 is not in [Ce/λs, λsCe] using
the estimate in b-epoch e. We now explain the functions of directory, new nodes and existing nodes during
a dimension change.
Directory. For each (possible) dimension, the committee-directory mapping is predetermined such that no
two buckets in the directory are responsible for the same committee, and that each bucket is responsible for
(almost) the same number of committees (cf. Section 3.1). We describe the behaviour of different buckets
during a dimension change.

• All the buckets formed in a transformation b-epoch e, including the middle-aged buckets at the start of
the b-epoch e, are said to be in a split state because they serve committees in two committee-directory
mappings Me and Me+1 for the current hypercube and the next hypercube, which have Ce and Ce+1
committees respectively. In other words, the directory nodes in those buckets, run DIR protocol for
both hypercubes simultaneously.

• The buckets formed after the transformation b-epoch e, only serve the next hypercube.

• The buckets formed before the transformation b-epoch e that are not in split state (i.e., veteran buckets

at the start of transformation b-epoch e), stop functioning from b-epoch e + 2.

New nodes. The new nodes that join the network during the transformation b-epoch e, get a node in both
the hypercubes by considering the leftmost log Ce and log Ce+1 bits of Pjoin. But they only (temporarily)
operate in the old hypercube (with old mapping Me) in the transformation b-epoch e. Then, from the next
b-epoch e + 1, that node (in the old hypercube) would be considered invalid, and they start operating using
the node in the next hypercube.

The new nodes contact the split state buckets and the buckets formed before them, for the entry informa-
tion of nodes that joined before the transformation b-epoch e using the old committee-directory mapping
Me. And they contact the split state buckets and the buckets that are formed after them, for registering,
and getting entry information about nodes that joined in or after the transformation b-epoch e, using the
new committee-directory mapping Me+1.
Old nodes. All non-directory nodes that joined the network before the transformation epoch e are consid-
ered invalid from the start of b-epoch e + 2. (We resorted to simplicity by not dealing with moving the old
nodes to the next hypercube, as this is sufﬁcient for us to ensure good network connectivity. In fact, this
also helps us show that switching to a new topology can be securely done during catastrophic failures. See
Section 9.1.)
Handle ∆-synchrony. The above dimension change algorithm works well if all the peers are fully syn-
chronized. Since some peers may reach the end of a b-epoch sooner than the others, we need to ensure that
our overlay structure is maintained during a transition to the new topology. Thus, µs blocks are added to
phase 2 (that includes the λlb log N blocks for agreement on overlay parameters). A peer functions both in
old and new hypercube (through its nodes) during those µb blocks. Finally, after the end of b-epoch, the
peer completely shifts to the new hypercube by ceasing to use its nodes in the old hypercube.

5 Recovery

Since blockchain protocols are executed indeﬁnitely, there could be exceptional scenarios where the net-
work may fail to provide the proven robustness guarantees simply due to very bad luck. These scenarios
must be especially addressed for networks that provide probabilistic robustness guarantees. Moreover,
open networks can be vulnerable to denial-of-service (DoS) attacks where a targeted set of (honest) peers
instantly stop functioning, for e.g., Gnutella ﬁle sharing system, while resilient to random failures, could be
split into large number of disconnected components after a targeted attack [SGG01].

17

Catastrophic failure. We say that a bucket fails if more than 1/2 fraction of honest peers in it get cor-
rupted. And we say that a committee fails if it has less than, say 20 log N honest peers. Moreover, if a bucket
has failed, then the committees that the bucket is responsible for, are also said to have failed. Here, the
corruption could be fail-stop where the honest peers stop functioning (i.e., leave), or Byzantine where the
adversary starts to control the honest peers. Consider the notion of “catastrophic failure”8 where a large set
of committees and/or buckets may have failed, and in total, at most a constant fraction of honest peers get
corrupted, but there still exists a subgraph of honest peers of a large size and low diameter for which boot-
strapping can be securely done. Such failures model exceptional scenarios that occur in practice wherein the
network is split into multiple components, resulting in considerable wastage of honest peers’ hash power
over time.
Recovery. Our goal is to provably show that the network recovers from such catastrophic failures in a
short period of time. Here, we naturally deﬁne recovery as the event at which the overlay retains its native
properties (that the overlay originally had before the catastrophic failure). There are two basic requirements
for the overlay to recover from a catastrophic failure. First, a large fraction of honest peers can run the
blockchain protocol9 (ensuring the blockchain provides the same guarantees), albeit some honest peers
may end up unable to participate fully (i.e., effective honest hash power is reduced) for a brief period of
time. Secondly, the introduction service is not affected by the failure, i.e., it continues to return the most
updated blockchain (among all the chains).

As long as those requirements are satisﬁed, the blockchain continues to make progress. Our insight is
that blockchain naturally provides recovery within a constant number of half-lives, due to limited lifetime
of nodes and new blocks (and nodes) being generated, a new directory will eventually be formed (replacing
the failed buckets) facilitating new (honest) node joins to (failed) committees. Although our design intu-
itively encourages recovery, proving the same is non-trivial if the network size is allowed to signiﬁcantly
vary, where the peers need to actively coordinate with each other (cf. Section 4). For instance, estimating
network size and changing dimensions after a catastrophic failure need to be carefully done and analyzed.
Extent of catastrophic failures. We can rely on the fault-tolerant properties of the underlying topology
to defend against massive catastrophic failures. The n-node hypercube is fault-tolerant against a linear
number of random (independent) node failures [HL89, CDP96], i.e., with high probability, it has a broadcast
time of O(log n). However, if a linear number of adversarial node failures are allowed, then it is known
log n [HL89]. Datar [Dat02]
that the hypercube can be split into components having size no more than n/
showed that in a n-node multihypercube10 (where the node degree is only a constant factor more than the
node degree in hypercube), at least n − O( f ) nodes can reach at least n − O( f ) nodes via log n-sized paths,
no matter which f nodes are removed.

(cid:112)

By utilizing a multi-hypercube, recovery can be ensured even if an adversary can cause failures in up
to a constant fraction of buckets including the committees that they are responsible, resulting in failures
amounting up to a constant fraction of honest peers. In other words, for recovery, we can allow failures of
any constant fraction of committees, provided that the buckets responsible for the remaining committees,
do not experience failures. The security arguments in prior work on join-leave attacks [AS04, FSY05, AS09,
GHK13, JPS+18], particularly for join protocol, heavily rely on honest majority in committees. In Appendix
A, we highlight the inherent difﬁculty of such fully localized algorithms to recover from committee failures,
and provide attacks by a small number of committees having malicious majority, to keep maintaining the
majority over time (which can also be used to increase the number of failed committees).

8Refer to Deﬁntion 9.26 (and the previous deﬁnitions) in Section 9.1.
9To allow for catastrophic failures that can instantly increase the fraction of peers that are Byzantine, and isolate some existing
honest peers from the large component, we assume that the blockchain provides the required guarantees if there are least µn(1 − ρ)n
honest peers and at most ρn Byzantine peers. Refer to Section 2.

10Recall that a hypercube can be visualized by treating a row in a butterﬂy topology as a node, a multihypercube can similarly be

visualized via a multibutterﬂy topology. Refer to the work of Datar [Dat02] for more details.

18

6 Lower Bound for Half-life

In the context of dynamic overlay networks, there is always a problem of bootstrapping a new peer into the
network. How does a new peer contact an existing peer within the network? We consider the implementa-
tion of bootstrapping service S that has two properties:

1. Secure. Responds with at least one honest peer that is within the network.

2. Bandwidth-constrained. Each peer in S expends only O(polylog(N)) bits in any round.

Let the total number of peers within the network is N in any round. As the best case scenario, all the
peers are considered to be honest. The amount of information required to uniquely represent a peer’s
network address is Ω(log N) bits, i.e., there exists no encoding scheme to compress network addresses.
Bulletin board. All the peers are given write access to a bulletin board that provides read access to everyone
(including the public) [Mit00]. Each peer can write O(log N) bits to the board per write operation. However,
there is a constraint on the number of write operations per unit time. An arbitrary peer is selected to write
to the board at every β rounds. More importantly, this bulletin board is the only interface through which
the peers can disseminate information to the public.
Bootstrapping service. Since the system is dynamic, the peers must utilize the bulletin board to regularly
update the peers that are responsible for new peers to join the network. The peers follow some algorithm
to construct a bootstrapping service S using the bulletin board. For e.g., peers may write their network
addresses onto the bulletin board.
Joining the network. There exists some join algorithm for new peers to contact the service and join the
network. The minimum requirement for a new peer to join the network is to obtain a response from the
bootstrapping service.

Theorem 6.1. Any dynamic system that implements a bootstrapping service S using a public bulletin board, can
support a half-life of only (cid:101)Ω(β

N).

√

Proof. For a new peer to obtain a response from the bulletin board, it must send a message to a network
address that is on that board. We note that information representing a network address is “useful” only if it
is “recent”. This would mean that we can restrict our attention to the network addresses in the most recent
W bits of the bulletin board.

No honest peer would be alive after Ω(α log N) rounds with a high probability. Recall that an honest
peer fails with probability 1/2 in any epoch. For some suitable constant c1, after c1 log N number of epochs,
an honest peer would fail with a high probability. Therefore, if there is a network address that is c1α log N
rounds old, then there is a high probability that the peer controlling that network address has left. Since the
system allows O(log N) bits to be written every β rounds, we get the following upper bound on W,

W = O(α log2 N/β).

There can be other information in the most recent W bits; if there are more (distinct) network addresses,
then the bootstrapping service can help in joining more new peers in a ﬁxed period of time. Therefore, as
the best case scenario, we assume that those W bits of information consists of only network addresses.

Let λjr be the highest number of join requests that a peer can handle. As the best case scenario, we
assume that all the peers in the service are distinct, and each response message is equivalent to a successful
join. Recall that in any α consecutive rounds, at least N/2 new peers must be able to join the network. Let
K be the number of distinct network addresses in the most recent W bits on the board,

αKλjr ≥ N/2.

(cid:18)(cid:114)

(cid:19)

βN
λjr log N

If α = o

rounds.

, then in total, the system can handle much less than N/2 join requests in α consecutive

19

7 Related Work

There has been a large body of work on robust and efﬁcient overlay networks in various models of churn
and failure, especially in the context of distributed hash table. First, we discuss early designs in different
models of failures. Then, we discuss prior work on the Byzantine join-leave attack. We also survey practical
partitioning attacks and network designs pertaining to blockchain P2P networks.
Early designs. Many overlay networks were designed to be robust against random failures, where each
peer (independently) has a bounded probability of being Byzantine [NW03, HK03, DHVR07, JRVJ15]. Fire-
ﬂies [DHVR07, JRVJ15] utilizes a pseudorandom mesh structure to provide each peer with a view of the
entire membership under moderate churn. Peers need to actively monitor each other by gossiping “accusa-
tion” and “rebuttal” messages. However, it is unclear how Fireﬂies performs in highly dynamic and large-
scale systems. DHTs are made robust by replication of each data item over a logarithmic number of peers,
of which a majority are honest peers [FS02, SFG+02, NW03, HK03]. More speciﬁcally, peers are randomly
mapped to [0, 1) interval, forming neighbour connections under the rules of an efﬁcient routable topology
[NW03, NW07]. A peer would be responsible for data items hashed along a segment of Θ(log n/n) length,
where n is the number of peers. Queries are routed to the destination through a majority vote at each hop.
Fiat and Saia [FS02] designed a robust content addressable network against an adversary that can adap-
tively corrupt up to a constant fraction of peers. They utilize the butterﬂy topology, where each vertex is
simulated by a logarithmic number of peers. They heavily exploit properties of bipartite expanders to show
that all but εn peers can search successfully for all but εn of the data items, for a positive constant ε. The
drawback is that their topology is ﬁxed and does not account for peers joining and leaving. It was modiﬁed
[SFG+02] to handle adversarial deletions under a restricted form of churn, where during any period of time
in which the adversary deletes An peers, then at least Bn new peers join the network for positive constants
B > A, and a new peer joins via a random peer in the network. Moreover, the join algorithm can be ex-
pensive in terms of communication cost, involving a broadcast to the entire network. Leighton and Maggs
[LM89] showed that if an adversary chooses k switches to fail in an n-input multibutterly [Upf92], then
there will be at least n − O(k) inputs and n − O(k) outputs connected by log n-length paths. Datar [Dat02]
observed that the fault-tolerance of multibutterﬂy networks can be used to show that a n-node multihy-
percubic network can withstand a linear number of adversarial failures. For instance, it can be shown
that at least n − 3 f /2 nodes can reach at least n − 3 f /2 nodes via log n-length paths, where an adversary
can remove up to f nodes. Datar [Dat02] built a content addressable network, having adversarial deletion
fault-tolerant guarantees similar to [FS02], improving on the communication and storage costs, where a
query requires O(log n) messages and the data is replicated in O(1) nodes. However, Datar’s design is not
resilient against Byzantine failures.
Join-leave attacks. Replication of a data item over a logarithmic number of peers is only helpful if there
is a majority of honest peers among them. This is because the integrity of the data item is veriﬁed by
considering the majority of the responses. Thus, an adversary that can overwhelm a particular region of
the [0, 1) interval with many peers, can potentially cause harm to the system, for e.g., by transmitting false
versions of a data item. In a dynamic system, where peers can join and leave, even if newly joining peers
are placed in a random location in the [0, 1) interval, with just O(n) join (and leave) attempts, Byzantine
peers can occupy a particular Θ(log n/n) length with high probability, obtaining the majority of peers in
that region (cf. Lemma 2.1 in [Sch05]).

Consequently, Awerbuch and Scheideler [AS04] considered a class of attacks called join-leave attacks,
where Byzantine peers collectively try to populate speciﬁc regions of the overlay topology. In this line of
work, the main goal is to design a combination of join algorithm and “network perturbation” mechanism
to continuously redistribute the Byzantine peers as new peers join the network. Here, by network pertur-
bation, we mean that for each new peer join, some (existing) peers are placed in new (typically random)
locations in the network. More formally [AS09], for every interval I ⊆ [0, 1) of size at least (c log n)/n for a
constant c > 0 and any polynomial number of join/leave events in n, the following two conditions need to
be met:

• Balancing condition: I contains Θ(|I| · n) nodes.

20

• Majority condition: honest nodes in I are in the majority.

Of course, all the honest nodes in a segment of size Θ(log n/n) could be asked to leave, in which case,
the majority condition cannot be met. Therefore, the churn adversary is required to specify the join/leave
sequence σ for honest nodes in advance. But it can choose to adaptively join/leave a Byzantine node. In
particular, after the ﬁrst i events in σ are executed, the churn adversary can either choose to join/leave a
Byzantine node or initiate the (i + 1)th event in σ. (In the beginning, all nodes are randomly placed in [0, 1).)
It is easy to see that if for each join, if all the peers are placed in random locations, then the Byzan-
tine peers always remain well-distributed in the network. But that would be quite expensive in terms of
communication cost. Therefore, “small” perturbations per join, typically of polylog(n) peers, is reason-
able. Translating this model in the context of eclipse attacks, our goal is to design an efﬁcient network for
blockchains, formally analyze the join algorithm, and provide theoretical guarantees on connectivity over
large (typically polynomial) number of join/leave events.

The key performance metrics, so far, have been join latency, join communication cost, and the capability
to handle polynomial variation in network size over time. In this work, we also introduce a new metric
called recovery from catastrophic failures (cf. Section 5). Refer to Table 1 for a comparison of OverChain
with prior work.

Awerbuch and Scheideler [AS04] utilize the Chord topology [SMK+01] with each peer simulating at
most O(log n) nodes at any time. They assume that at most a O(1/ log n) fraction of peers can be adver-
sarial at any time. Each node is connected to every other node in a “region“ of size Θ(log n/n) around it,
where every region is ensured to have Θ(log n) nodes11. The join algorithm, places a new peer (node) in a
random location via a distributed random number generation (RNG) protocol run by nodes within a region
(initiated by an honest node) and secure routing of the new peer to the appropriate location (through honest
majority in regions). For network perturbation, they employ a limited lifetime of O(log n) rounds for each
node. This work is a starting point for OverChain though our join algorithm is completely different. (We
explain the choice of limited lifetime for network perturbation at a later stage.) Although they can with-
stand a high join rate of O(n/ log n), they make a strong assumption of the existence of “trusted gateway
peers” that can initiate unlimited join protocols at any time. If a peer needs to leave the network, then it
needs to wait until all its nodes’ lifetimes have expired, i.e., for Ω(log n) rounds, in which time the entire
network gets reconstructed (as in our work, where the network gets reconstructed every Θ(α) rounds) due
to node lifetime being set to O(log n) rounds. Using this design, the authors show that the network pro-
vides robustness (i.e., meets both the aforementioned conditions) for a polynomial number of join/leave
events with high probability.

Bootstrapping and churn rate in prior work. Awerbuch and Scheideler [AS04] are able to endure a high join
rate due to the assumption of gateway peers that can help place a new peer (node) in a random location. But
those gateway peers can experience churn and have limited bandwidth, leading to the lower bound proved
in Section 6. Subsequent works in this model, analyze a single join/leave event and provide guarantees on a
series of join and leave events, all occurring one after another, for ease of exposition. Secure bootstrapping
is somewhat swept under the hood. They can handle concurrent join and leave events too. And much
like [AS04], by making assumptions that provide load-balancing of join events across the network (such
as existence of gateway peers), they can also handle n/polylog(n) join rate because the join algorithm
(including network perturbation) takes polylog(n) work (in terms of latency and communication cost for
peers involved in a join event). In this work, we go one step further and make a weaker bootstrapping
assumption of the existence of a reasonably-updated blockchain (instead of access to random or trusted
peers), and provide bounds on the churn (join) rate for the system.

Catastrophic failures in prior work. The work of Awerbuch and Scheideler [AS04] and subsequent works
heavily rely on honest majority in regions12 for join/leave algorithms. If there is a large adversarial attack
(as in Section 5), then the Byzantine peers easily can control majority in most of the regions over time. In

11As previously mentioned, such Θ(log n)-sized groups of nodes act as the functional units of the network, cancelling out effects of

Byzantine peers.

12They are also referred to as quorums [AS04, AS09] or swarms [FSY05] or clusters [GHK13] in the literature.

21

Section A, we argue that the existing class of algorithms fail to provide recovery guarantees for catastrophic
failures.

Subsequent works assume that at most a constant fraction of the peers are malicious. Fiat, Saia and
Young [FSY05] also use Chord [SMK+01] as the underlying topology combined with similar logarithmic
redundancy for peers. They employ the k-rotation strategy [Sch05] (for k = 3) for perturbing the network
during a join event. A random location r ∈ [0, 1) is ﬁrst chosen (by the region contacted by the new peer)
using similar distributed RNG techniques. Two peers p1 and p2 are selected randomly using the algorithm
in [KS04]. Then, the joining peer, p1 and p2 are “rotated” in that the joining peer takes the position of p1, p1
takes the position of p2 and p2 takes the position r. They are able to provide robustness for a linear number
of join and leave events with high probability, as there exist adversarial strategies (against the k-rotation
strategy) to populate a Θ(log n/n) segment [AS09]. However, they avoid the limited lifetime method,
which puts the network in a hyperactive state where peers have to (continuously) rejoin.

In a seminal work, Awerbuch and Scheideler [AS09] introduced the cuckoo rule for network perturba-
tion, that provides robustness for a polynomial number of join/leave events with high probability, without
the need for limited lifetime for peers. As in previous works, a random location r ∈ [0, 1) is chosen (by
the region contacted by the new peer) using similar distributed RNG techniques. Then, the new peer is
placed in r and all the peers situated in the segment of size k/n around r, where k is an appropriate con-
stant (depending on the constant ρ, where the number of Byzantine peers are at most ρn), are relocated
to points in [0, 1) chosen uniformly and independently at random. They use the dynamic de Bruijn graph
as the underlying topology. In the works discussed so far, the network size was assumed to change by at
most a constant factor. While we believe that these algorithms can be augmented to provide robustness
against polynomial variation in network size, it does not seem trivial to do so. (For instance, global coordi-
nation, such as network-wide agreement, does seem inevitable for a topology that is able to adapt to both
polynomial network size variation and catastrophic failures.)

Guerraoui, Huc and Kermarrec [GHK13] utilize a random graph drawn from Erd˝os-Rényi model for the
underlying topology, and employ a technique known as OVER (Over-Valued Erd˝os Rényi graph) for han-
dling a sequence of vertex addition and deletions polynomial in n whp. The underlying graph is ensured
to have small degree and good expansion. Each vertex is simulated by a cluster of O(log n) size containing
more than two thirds of honest peers. They heavily rely on random walks (that mix in polylog(n) rounds)
for their join algorithm and network perturbation. In this work, a random cluster Cr is ﬁrst chosen (by
the cluster contacted by the new peer) using a distributed RNG algorithm. The new peer is introduced to
the peers in Cr and the neighbouring clusters. Then, (for network perturbation) Cr exchanges all its peers
with peers chosen at random from other clusters. The updated set of peers of Cr is then conveyed to the
neighbouring clusters (through majority rule) by the old peers. The key contribution of this work is that
they handle polynomial number of join/leave events when the network size is allowed to polynomially
vary. They achieve it by splitting and merging clusters based on thresholds on cluster size. For example,
if the cluster size is more than k log n for some constant k, then the cluster partitions its set of peers into
two, informs the updated set of peers to the neighbouring clusters, and then “adds” the other partition
to the network (using vertex addition of OVER). (Note that the security arguments heavily rely on honest
majority in clusters.) Whenever a peer leaves, a similar process is carried out by the corresponding cluster.
The drawback is that these algorithms require a much higher communication and round complexity than
the other works. (See Table 1 for the comparison.)

Why limited lifetime method of network perturbation in OverChain? Let us say that there is a catastrophic
failure caused by a “DoS adversary” in the overlay. The network becomes split into multiple components,
but there exists one component consisting of Ω(n) honest peers with diameter O(log n). Observe that if the
network experiences little-to-no churn at this stage, even if the blockchain progresses over time, there will
be very less (new) peers joining the network (due to low join rate). This is deﬁnitely possible in the model
because each honest peer is assumed to fail independently with probability at most pf . (More precisely,
half-life α deﬁnition is worst-case in that there could just be one period of α rounds in a long period of time,
say a couple of years, that 1/2 fraction of peers join/leave the network.) And there could be no new peers
joining the network for a period of time.

22

In this scenario, the honest peers stuck in the smaller components keep wasting their resources because
their blocks may never be propagated to that large component (whose chain is essentially the main chain).
Note that catastrophic failure can stealthily happen in the real world, in which case the peers may not know
that the network is actually split. This is problematic because after a sufﬁcient period of time, the DoS
adversary may regain the resources to cause another large-scale adversarial attack (before the network is
fully rebuilt)! Thus, compared to cuckoo rule or local splitting/merging method of network perturbation,
the limited lifetime method forces rejoins of honest nodes, enabling recovery of the entire network in a
constant number of half-lives. Of course, this comes at a cost of keeping the network in a hyperactive
state if there is small churn on average. We argue that open peer-to-peer systems are inherently dynamic
in nature, i.e., if the average half-life is close to α, then the system is indeed in a natural state (and not a
hyperactive state), in which case, the limited lifetime method would be (asymptotically) comparable to the
other methods of network perturbation.

Do redundancy and robustness go hand in hand? The works discussed so far, have retained some form of
logarithmic redundancy in terms of data integrity or secure routing to thwart the effects of malicious peers
and churn. Jaiyeola et al. [JPS+18] address the robustness guarantees that can provided with O(log log n)
redundancy. A peer is associated with a “group” in the interval [0, 1), similar to regions in [AS04]. Us-
ing group sizes of O(log log n), they show that all but an O(1/polylog(n))-fraction of groups have hon-
est majority, and that all but an O(1/polylog(n))-fraction of peers can successfully search for all but an
O(1/polylog(n))-fraction of data items over a polynomial number of join/leave events with high probabil-
ity. A drawback is that they have a rather complicated join algorithm, where the network is reconstructed
every “epoch”, where the epoch length is set according to the departure rate of peers (as in our work).
They make a strong bootstrapping assumption of the existence of “bootstrapping groups”. Since the group
size is O(log log n), there exists O(1/polylog(n))-fraction of groups, termed as “bad”, that do not have
the required number of honest peers. To avoid increase in the number of bad groups during network re-
construction, they place the peers in two networks (that exist in tandem) in two (separate) [0, 1) intervals
(where each of them is based on an efﬁcient topology). We remark that their approach for network recon-
struction is rather complicated; they heavily rely on the bootstrapping groups for placement of a (new) peer,
creating neighbour links, and moreover, updating links as (more) peers join and become a better match as
a neighbour (for e.g., they can lie closer to the neighbour points determined by the underlying topology).
Similar to our work, the authors use proof-of-work to defend against Sybil attacks. (Note that the works
discussed so far, in the join-leave model, made explicit assumptions regarding the number of malicious
peers.) The caveat is that their network needs to continually generate (and agree on) a global random string
as a (partial) input to the proof-of-work puzzles. Otherwise, the adversary can launch a pre-computation
attack generating too many identities, overwhelming all the groups. Our reliance on the most recent block
for proof-of-work puzzles is a signiﬁcantly simpler approach than a network-wide distributed RNG algo-
rithm.
Partitioning attacks. Heilman et al. [HKZG15] ﬁrst demonstrated eclipse attacks on the Bitcoin network.
Their idea is to form many incoming connections with the victim node from attacker-controlled addresses
(from diverse IP address ranges), propagate many irrelevant (i.e., not part of the Bitcoin network) addresses,
and wait for the victim node to restart. Once the victim node restarts, it would likely form all its outgoing
connections with attacker-controlled addresses. Marcus et al.
[MHG18] carried out a similar attack on
Ethereum’s P2P network with signiﬁcantly less resources by exploiting the fact that the public key of a
node was its node identiﬁer. In other words, many node identiﬁers could be run with just a single machine
(with the same IP address). This made it easy to suitably generate and store attacker-controlled addresses
in the victim node, so that after restarting, it would form all its outgoing connections with the attacker. In
both papers, the authors suggested countermeasures involving the process of storing network addresses
and connecting to new peers, to increase the cost of such attacks. Saad et al. [SCN+19] outline partitioning
attacks by different adversaries such has an AS/ISP that can route Bitcoin trafﬁc away from a target AS
by BGP hijacking, a malicious mining pool that can exploit knowledge about weakly synchronized nodes
to fork the network, and a software developer capable of exploiting bugs in Bitcoin client can aid other
partitioning attacks.

23

While the previously mentioned works aimed to capture victim connections by sending many attacker-
controlled (and bogus) addresses, they don’t directly exploit churn or synchronization of honest peers. Saad
et al. [SARM21] identiﬁed that Bitcoin suffered from weak network synchronization; in a block interval
of 10 mins, on average, only ≈39% of the nodes had an up-to-date blockchain. The authors identify all
mining nodes, which also suffered from varying network reachability. They describe a partitioning attack
with a 26% hash power adversary, by selectively broadcasting blocks to disjoint groups of miners after
carefully exploiting the block propagation patterns13. On the contrary, Baek et al. [BNO+21] highlight the
limitations of their network monitoring systems, and assert that the block propagation in Bitcoin is indeed
fast. Nonetheless, the work of Saad et al. [SARM21] shows that weak synchronization can be exploited to
create partitions. Our aim is to design a network that would allow for fast block propagation with at most
logarithmic hops, thereby strengthening network synchronization and also paving the way for decreasing
the average block interval.

Saad et al. [SCM21] primarily exploit churn in Bitcoin network to create a partition between existing and
newly arriving nodes. First, the adversary occupies all the incoming connections of existing nodes, which is
done by exploiting the node eviction policy that favors nodes with longer connection times. Then, as nodes
depart and new nodes join, they only connect with adversarial nodes from the sample of nodes provided
by the DNS seeds due to unavailability of connection slots in other nodes. This gradually creates a partition
between existing and newly arriving nodes. The authors suggest several countermeasures to increase the
cost of such attacks such as introducing a fork resolution mechanism, restricting the number of connections
from the same IP address, improving the eviction policy, etc. We argue that a theoretical framework that
appropriately captures churn and malicious behaviour, is needed to analyze the security against partition-
ing attacks. There have also been practical attacks that consider strong network infrastructure adversaries
[AZV17, TCM+20], which are beyond the scope of our model.
Blockchain network designs.
In light of these issues, there have been new network design proposals
for blockchains. Kadcast [RT19] further builds on Kademlia [RT19] and proposes a structured broadcast
protocol for disseminating blocks with at most a logarithmic number of hops and constant overhead in
congestion. It is unclear how this protocol performs with respect to continuous node churn and change in
network size. In Perigree [MDV+20], a peer retains the “best” subset of neighbours after regular intervals,
and also continuously connects to a small set of random peers to explore potentially better-connected peers.
But Perigree may actually be more prone to eclipse attacks because the adversary can easily monopolize
victim peer’s connections by providing well-connected peers.

8 Discussion

We have shown that the maintenance of robust overlay networks, in the context blockchains, can be made
simpler and more efﬁcient than fully localized algorithms. Here, we address some clariﬁcations, limitations
and natural extensions to this work.
Implementation. As a ﬁrst step, we show the theoretical results as clearly as possible, while making
minimal assumptions on the blockchain and providing a clear comparison to existing algorithms and their
guarantees in our model. We also include the average block interval, β, in the discussion, in addition to
the interplay between churn rate, communication cost and number of Byzantine peers. We believe that
a proper implementation with extensive experiments on the parameters, and a comparison with existing
implementations, including the unstructured Bitcoin network, is a separate project on its own.
Incentives. Our work considers the honest vs Byzantine model of peers to deal with worst-case failures.
But this model omits the analysis of rational behaviour of peers. The peers currently get reward for mining
blocks through block rewards and transaction fees. But for any peer to participate as a directory node and
incorporate new peers into the network, it needs to expend a certain amount of communication bandwidth.
If there is no incentive to do so, the peer may not follow the protocols. A key observation of our algorithm

13This type of partitioning attack is possible because Bitcoin (by default) uses a local tie-breaking rule for equal-length chains, i.e., a

miner chooses to mine on the chain (or block) that was received ﬁrst.

24

is that the communication cost is proportional to the amount of hash power owned by a peer. Thus, the
next step is to design incentive-compatible overlay maintenance algorithms that are robust to churn and
Byzantine failures. Such a design would promote independent peers to mine and participate in overlay
maintenance.
Bootstrapping assumptions. We make an assumption that the blockchain held by any honest peer (which
can be outdated by a constant number of blocks compared to a fully updated blockchain) within the net-
work is publicly available. This abstracts out the numerous public blockchain explorers and tie-breaking
criteria (that are blockchain-speciﬁc) to consider the best among them. Note that this is not a solution to the
bootstrapping problem of how a new peer can ﬁnd existing peers, as some peers within the network must
maintain such blockchain explorers, thus acting as an interface for entities outside and inside the network.
We claim that our bootstrapping assumption is weaker than assumptions made by current (practical
and theoretical) designs. Currently, the bootstrapping process is highly centralized (and static), with only
a handful of peers responsible for providing information about random peers14 to new peers. More im-
portantly, there is no way of verifying the randomness of given peers. On the other hand, we utilize the
properties of blockchain such as safety, liveness and fairness15 to ensure that the overlay structure is (prov-
ably) maintained.
Join latency. Our algorithm allows a peer to join the network in constant number of rounds, in contrast
to previous algorithms that required logarithmic number of rounds. It is important for us to dissociate
the time taken by a peer to mine a new node and the time taken for a node to join the network. Note
that the node mining is only done to regulate the join rate of peers, to prevent a Sybil attack. Prior works
[AS04, FSY05, AS09, GHK13] subsume such a Sybil mechanism and makes explicit assumptions on the
In other words, we could remove the node mining
number of peers joining in a given period of time.
aspect, and just use the hash function for associating a node with a random committee. Thus, the join
latency, a key performance metric in overlay maintenance, is the time taken for a peer to join a committee
and obtain information about all its neighbouring peers.
Heterogeneous peers.
In our work, a peer generates nodes (to facilitate overlay maintenance) and blocks
(which are also tied to overlay maintenance via directory nodes). In other words, a peer is also (necessarily)
a miner. (This design is suitable for proof-of-work blockchains because 2-for-1 PoW mining [GKL15, PS17]
can be used for simultaneously mining for both blocks and nodes.) But in practice, peers part of the
blockchain P2P network, can be signﬁcantly different from each other in terms of (1) half-life (for e.g., there
could be a few long-lived honest peers which can be exploited to make the overlay protocols efﬁcient), (2)
hash power (for e.g., non-miners vs lone miners vs mining pools), (3) blockchain veriﬁcation (for e.g., full
nodes vs SPV clients in Bitcoin), (4) bandwidth (for e.g., a few peers can endure high communication cost),
etc. Thus, an important research direction is to come up with a theoretical framework that models the peer
heterogeneity, and then design robust overlay maintenance algorithms.
Beyond PoW for Sybil defense. There are two components of OverChain: (1) Sybil defense mechanism
to regulate the number of new nodes generated per round, (2) and overlay maintenance features such as
placing new nodes in random committees (using the output of a hash function), handling join requests,
broadcasting network information (including blocks), etc. The latter component can be translated onto any
type of blockchain without any changes. The challenge is to design an efﬁcient Sybil defense mechanism
(for node mining), possibly by making use of the same restricted resource (of the blockchain).

9 Full Analysis

The overlay network has certain desirable properties that are subsequently proven in this section. The
blockchain properties are important for the proofs. Blockchain fairness is used for showing a bound on the
communication cost due to JOIN protocol, bound on the number of honest nodes in any bucket of the active

14In unstructured networks such as Bitcoin, it is important that new peers get connected to random peers for the network to simulate

a random graph that has desirable connectivity properties.

15Blockchain protocols do not provide strong guarantees such as a block is produced by a random peer. In that case, having a

network address in each block trivially provides access to random peers.

25

directory, and reaching an agreement on the overlay parameters via honest majority in the blocks of phase 2
of a b-epoch. Both blockchain safety and liveness are implicitly required, for e.g., if the blockchain provided
by the introductory service is different from the chains within the network, then the JOIN protocol would
not work. Besides that, blockchain liveness is explicitly used for obtaining the (approximate) time taken
for adding a large set of consecutive blocks onto the conﬁrmed chain. Although a sequence of b-epochs
is well-deﬁned with respect to a peer (and its conﬁrmed chain), we divide the time into b-epochs (for the
system as a whole) even for the analysis. We consider that a b-epoch ends if any of the honest peer reaches
the end of the b-epoch.

Symbols
N
ρ
α
B
K
Bact
Kact
Tl
Tdl
λjr
Ce
L(cid:48)
e

Le
M(cid:48)
e

ML
e
MH
e
G(cid:48)
e
Ge
δerr

Meaning

Maximum network size
Fraction of total number of peers that are malicious
Number of rounds in one epoch
Number of buckets in one directory
Number of blocks in one directory
Number of buckets in the active directory
Number of buckets in the active directory
Lifetime of a non-directory node (in terms of number of blocks)
Lifetime of a directory node (in terms of number of blocks)
Highest number of join requests handled by a directory node per round
Number of committees in b-epoch e
Estimate of the network size at the end of b-epoch e that is agreed
upon by all the honest peers
Network size at the end of b-epoch e
Estimate of the network size after phase 1 of b-epoch e that is agreed
upon by all the honest peers
Minimum network size in phase 1 of b-epoch e
Maximum network size in phase 1 of b-epoch e
Estimate of the number of nodes that joined in phase 1 of b-epoch e
Number of nodes that joined in phase 1 of b-epoch e
Error parameter (that is less than 1) for network size estimation

Table 3: Important symbols and their meaning.

Deﬁnition 9.1. The active directory (bootstrapping service) is considered to be robust if it satisﬁes the following
properties:

1. Each bucket has at least λb log2 N honest nodes where λb is some positive constant.

2. The entry information of any honest node that is part of the network, is held by (the honest directory nodes of)

the appropriate bucket (determined by the committee-directory mapping).

Deﬁnition 9.2. The JOIN protocol, for a new node q generated by peer u, is said to be successful if it satisﬁes the
following properties:

1. Peer u must get entry information about all (honest) nodes of the committee that node q is going to join, and

about all (honest) nodes of the neighbouring committees.

2. Peer u sends node q’s entry information to all the (honest) nodes in the committee that q is going to join, and to

all the (honest) nodes of the neighbouring committees.

Deﬁnition 9.3. The overlay network is considered to be partition-resilient if it satisﬁes the following properties:

26

1. Each committee has O(log N) nodes and at least λp log N honest peers for a positive constant λp.

2. In each committee, every pair of honest nodes are connected.

3. Each honest node has Ω(log N) honest neighbours in each of its neighbouring committee.

Deﬁnition 9.4. A b-epoch e is said to be bandwidth-adequate if each (honest) peer needs to send or receive
O(log3(N)) messages for overlay maintenance in all rounds of b-epoch e.

Deﬁnition 9.5. Let the quantity Re = Le/L(cid:48)
have a good estimate ratio if,

e be deﬁned as the estimate ratio of b-epoch e. A b-epoch e is said to

Re =

Le
L(cid:48)
e

∈

(cid:20)

1
2µb(1 + δerr)

,

2µb
(1 − ρ)(1 − δerr)

(cid:21)

.

Deﬁnition 9.6. A b-epoch e is said to be a stable b-epoch if the number of peers in any round r of b-epoch e, denoted
by Nr

e ∈ [Ce/λs, λsCe], for some positive constant λs.

e , is Nr

Remark 9.7. The expected number of new nodes that can be generated in a stable b-epoch, is in [(λn(1 −
ρ)Ce log N)/(µ2
bλs), λnλsCe log N]. This is because the node difﬁculty threshold, pn = (λn log N)/(qα), is
ﬁxed, the number of rounds in a b-epoch is bounded using blockchain liveness, and the network size is
bounded in a stable b-epoch.

Deﬁnition 9.8. A b-epoch e is said to be synchronized if:

1. All honest peers calculate M(cid:48)
1, as speciﬁed in Algorithm 3.

e such that M(cid:48)

e ∈ [(1 − δerr)(1 − ρ)ML

e /µb, (1 + δerr)µb MH

e ] at the end of phase

2. Ce+1 and ch_dim are added to each honest block conﬁrmed after phase 1.

3. There is an honest majority among the blocks conﬁrmed in phase 2.

Lemma 9.9. If the b-epochs e, e − 1, . . . , z where z = max(1, e − (cid:100)λlµb(cid:101)), are stable b-epochs, then whp, every
committee can have O(log N) nodes.

Proof. The nodes generated before the previous λlµb b-epochs are considered invalid since the start of b-
epoch e (due to blockchain liveness and non-directory node lifetime). Therefore, by Chernoff bounds, the
total number of nodes in the system during b-epoch e is at most O(Ce log N) with high probability (due
to Remark 9.7 and the fact that the network size can change by at most a constant factor over a constant
number of epochs). By using a balls-and-bins argument, each committee can have O(log N) nodes with
high probability, for a large enough λn.

Lemma 9.10. If the b-epochs e, e − 1, . . . , z where z = max(1, e − (cid:100)λlµb(cid:101)), are stable b-epochs, then each peer
controls at most O(log N) non-directory nodes in the network and at most cm non-directory nodes in any committee
in b-epoch e, whp, where cm > 3 is some constant.

Proof. We examine the probability that a constant number of all nodes controlled by a peer joining a partic-
ular committee.

Recall that a node is valid for Tl blocks, amounting to at most λlµbα rounds due to blockchain liveness.
The node difﬁculty threshold, pn = (λn log N)/(qα), is ﬁxed. To calculate the number of nodes controlled
by a peer, we need to look back for at most λlµbα consecutive rounds before round r, as nodes generated
before it will not be considered valid in round r. Applying a Chernoff bound, whp, a peer can control at
most D = O(log N) nodes in any round r. Applying a union bound over all peers and α rounds, this holds
for all peers during the entire b-epoch e.

Each of these D new nodes generated by the peer get mapped to a random committee (by random oracle
assumption). This can be viewed as throwing D balls in Ce ≥ N1/y/λs bins. Let the upper bound for the

27

number of balls in a bin be some large enough constant cm > 3. Let Zk be the random variable that denotes
the number of nodes in committee k. By Chernoff bounds and large enough N1/y (minimum network size),

Pr[Zk ≥ cm] ≤ ecm ·

(cid:19)cm

(cid:18) D
Ce

≤

(cid:18) 1
Ce

(cid:19)cm/2

,

committee k has at most cm nodes with high probability. By applying a union bound on the number of
committees, every committee has less than cm nodes controlled by the peer with high probability. Finally,
applying a union bound over the total number of peers, each peer controls at most cm nodes in any com-
mittee.

Lemma 9.11. For e ≥ 2 and constant λp > 0, if b-epochs e − 1 and e are stable, then in b-epoch e, each committee
has at least λp log N honest peers mapped to it with high probability.

Proof. Recall that the node difﬁculty threshold, pn = (λn log N)/(qα), is ﬁxed. By stable epoch-property,
blockchain liveness (for number of rounds in a b-epoch), and the fact that at most ρ fraction are Byzantine,
the expected number of new honest nodes, in b-epoch e − 1, is at least (λnCe−1(1 − ρ) log N)/(µ2
bλs). By
Chernoff bounds, except with exponentially low probability, the total number of honest nodes generated
is at least Θ(λnCe−1 log N). (We drop the other constants unless necessary, as λn controls the failure prob-
ability.) These nodes get randomly mapped to Ce committees. (Note that Ce = Θ(Ce−1) as b-epochs e − 1
and e are stable, and the network size can change by at most a constant factor over a constant number of
epochs.) Using a balls-and-bins argument, for large enough λn, the number of honest nodes mapped to a
committee is at least Θ(λn log N) with high probability. By Lemma 9.10, since each honest peer controls at
most cm number of nodes in a committee, the number of honest peers mapped to a committee is at least
m = Θ(λn log N) with high probability. (We drop cm in m too because an increase in λn does not require cm
also be increased by the same factor for 9.10 to hold, for large enough N1/y.)

Every node (in its committee) survives until the end of the next b-epoch once it enters the network,
whether there is a dimension change or not. (If b-epoch e − 1 is a transformation b-epoch, then nodes get
mapped to a new hypercube. If b-epoch e is transformation b-epoch, then the node is considered valid
until the end of b-epoch e.) Our aim, in this lemma, is only to bound the number of honest nodes that
(We are not yet considering the success of
get mapped and survive until the end of the next b-epoch.
join protocol, dimension change, etc.) But the peer controlling a node can leave the network. Thus, after
two b-epochs, amounting up to two half-lives (via blockchain liveness), the expected number of honest
peers in a committee is at least m1/4. Applying a Chernoff bounds on survivability of an honest peer in a
committee (since their failure is independent of other honest peers), the number of honest peers mapped
to that committee that survive until the end of b-epoch e, is Θ(λn log N) with high probability. Finally,
applying a union bound on all the committees, the lemma holds with high probability, for a large enough
constant λn.

Lemma 9.12. If b-epoch e is a stable epoch, then each peer receives at most O(log2 N) JOINING and O(log2 N)
REQ_INFO messages in any round in b-epoch e with high probability.

Proof. As this proof is quite involved, we provide a high-level intuition. Let a directory node receive at
most R REQ_INFO messages in a round. Let T be the number of directory nodes controlled by an honest peer.
Then, that honest peer needs to send O(TR log N) node entry information (through COMM_INFO messages)
if there are O(log N) nodes in each committee. As we shall subsequently prove, it turns out that T =
O(log N). R must be O(log N) so that the overall communication cost per round for the peer is O(log3 N).
We set λjr = O(log2 N), the number of (valid) new nodes mapped to a bucket, so that on expectation, a
directory node in that bucket needs to handle O(log N) REQ_INFO messages. We focus on getting an upper
bound on the join requests for any bucket per round. (We use the term “join request” in place of a new
(valid) node.) Then, ﬁnally, we bound the number of REQ_INFO messages using the bound on the join
requests and the random sampling used for sending REQ_INFO messages (cf. Algorithm 2).

28

√

√

We split the proof into two cases: (1) the network size is at most c1

N log2 N but greater than N1/y
(minimum network size) in all rounds of b-epoch e, where c1 is some constant, and (2) the network size is
greater than Ω(
N log2 N) in any round. In case 1, the network size is comparable to the number of blocks
in the directory. This means that a peer may control many blocks in the active directory, but the overall
join rate (per round) itself turns out to be quite low. This is because about (cid:101)Θ(
N) nodes join in a b-epoch
(which is (cid:101)Θ(β
N) rounds due to blockchain liveness). In case 2, however, the join rate per round can go up
√
to (cid:101)Θ(
N). But due to blockchain fairness, it turns out that a peer controls at most O(log N) blocks in the
active directory, as the network size is considerably higher than the number of blocks in the active directory.
This means that (cid:101)Θ(
N) buckets in
the active directory, where there are sufﬁcient peers to handle them. The tricky part is, of course, bounding
the communication cost within the required log factors.

N) join requests generated per round get load-balanced across the (cid:101)Θ(

√

√

√

√

In a stable b-epoch e, the expected number of node join requests that can be generated per round (due to
pn) is at most d = Θ((Ce log N)/α). Let Dr be the actual number of valid join requests generated per round
r in b-epoch e.

√

Case 1. A single peer may control many blocks in a directory, as the network size is comparable to the
number of blocks in the active directory. However, the communication cost for an entire directory is low
because the join rate (per round) is low.

The expected number of join requests per round is d = O((log2 N)/β) because Ce = O(

N log2 N) (as
the network size changes by at most a constant factor over a constant number of epochs, and a b-epoch
is at most a constant number of epochs due to blockchain liveness). The adversary can choose to conduct
a pre-computation attack, wherein it can send all its (valid) join requests right before the next block is
conﬁrmed. Due to blockchain liveness, the next block is conﬁrmed in at most O(β) rounds.
In such a
scenario, the expected number of join requests over a period of one block is O(log2 N) (via linearity of
expectation). In other words, the expected number of join requests in any round r is O(log2 N). This means
that Dr = O(log2 N) whp, by Chernoff bounds. Applying a union bound over all rounds in b-epoch e, the
join rate (per round) is O(log2 N) whp. Note that this is for an entire directory (and there are at most a
constant number of directories in the active directory).

Case 2. Due to the fairness property, for the case in which the network size is Ω(

N log2 N), we show
that the number of blocks held by a single peer in a directory is low. Let Nr be the network size in round
r in b-epoch e. Let x be the fraction of blocks generated by one peer in a segment of the chain of length L,
then whp, by fairness property, for δ > 0 and a constant c2,

√

x ≤ 1 − (1 − δ)

(cid:19)

(cid:18) Nr − 1
Nr

1 − δ
Nr

.

≤ δ +

≤

c2κ
L

√

√

N log N) (by Section 3.3) and Nr = Ω(
Since L = Kact = Θ(α/β) = Θ(
N log2 N), the second term in
the second inequality can be neglected for a large enough constant c2. That peer gets at most xL ≤ c2κ =
O(log N) blocks. (As the worst case scenario, assume that these blocks occur in different buckets.) This
needs to hold for all the peers and across all the O(α) rounds in the b-epoch. Applying a union bound on
all the peers and rounds, each peer has at most O(log N) blocks in the active directory in any round, with a
high probability.

Let us calculate an upper bound for the number of valid join requests per bucket. Let Cb be the set of
committees that the bucket b is responsible for. We will split this analysis into two subcases. First, we will
upper bound the number of join requests for the committees in Cb. Then, we will upper bound the number
of join requests arising from the neighbouring committees of each committee in Cb.

Before that, let us get an upper bound on Dr for any round r as it is required for the analysis of the two

29

subcases. Using the stable b-epoch property, and when the network size is Ω(

√

N log2 N),

d = Θ

(cid:19)

(cid:18) Ce log N
α

= Ω

(cid:18) log N
β

(cid:19)

.

As the worst case scenario (for obtaining an upper bound), the adversary can conduct a similar pre-
computation attack as in Case 1. In such a scenario, the above expected number of join requests over a
period of O(β) rounds (via blockchain liveness), gets multiplied by a factor of O(β) (via linearity of expec-
tation). This means that for a large enough constant λn, Dr = Θ((βCe log N)/α) with high probability (via
Chernoff bounds).

Case 2, Subcase 1. Let the upper bound for the expected number of join requests for bucket b in round
r be denoted as ur. Recall that the network size can be at most N (and Ce ≤ λs N due to stable b-epoch
property). Applying the upper bound on the network size, and using λjr = O(log2 N),

ur ≤

Dr
B

= Θ

(cid:19)

(cid:18) βCe log N
αB

(cid:32)

= Θ

(cid:33)

βCeλjr log N
βN log2 N

= O(log N).

Applying Chernoff bounds (via balls-and-bins argument), the number of JOINING requests for each direc-
tory node in bucket b is O(log N) in a round of b-epoch e.

Case 2, Subcase 2. Let the set of all neighbouring committees of each committee in Cb be denoted as Nb.
Let the upper bound for the expected number of join requests arising from committees in Nb be denoted as
un
r . Let us denote the number of links of a committee c in Nb to committees in Cb, as wc. If a join request
is sent for committee c, then wc requests are sent to bucket b (as part of getting to know the neighbouring
committees’ nodes). Let the maximum number of neighbouring links for a committee in the topology be
M = log N. Thus, the sum of wc over all committees c belonging to Nb is at most M|Cb|.

Let X(j) be the random variable that takes input Pjoin of a valid join request, and is equal to wc/M if the
join request j maps the node to committee c ∈ Nb, and 0 otherwise. Note that X(j) over the join requests
are independent and belong to [0, 1]. Recall that the committee-directory mapping (in any dimension) is set
such that for any bucket b, |Cb| ≈ Ce/B. The expected value of X(j) for a join request j is,

Summing over all join requests,

1
Ce

·

wc
M

=

M|Cb|
Ce M

= O

(cid:19)

.

(cid:18) 1
B

∑
c∈Nb

E[X(j)] ≤ O

∑
j

(cid:19)

(cid:18) Dr
B

= O(log N),

where the last equation is from the analysis of subcase 1. Applying Chernoff bounds, the summation is
O(log N) with high probability. Now, multiplying the summation by M, which is O(log2 N), gives the total
number of new nodes that send REQ_INFO message to directory nodes in that bucket. On expectation, a
directory node in that bucket receives at most O(log N) (due to random sampling in Algorithm 2). And
ﬁnally, by applying Chernoff bounds and union bound, each directory node receives at most O(log N)
REQ_INFO messages whp.

Byzantine peers may not do the random sampling. But it can be enforced by the usage of hash function
(i.e., veriﬁable randomness). The directory nodes in the bucket are ordered by the block numbers. Thus,
(log log N) bits are necessary to represent each of them. Appending 1, 2, . . . , O(log log N) to the input that
provided the valid node, and applying the hash function, provides O(log N log log N) random bits, that
can be used to sample O(log N) directory nodes in the bucket. Note that q, which is the maximum number
of hash queries by a peer per round, is quite large in practice. These extra polylog(N) hash queries per

30

round are negligible, compared to the number of hash queries required to mine a node (which is set by the
difﬁculty threshold).

Since a peer controls at most O(log N) directory nodes in the active directory in any round, then the

total number of JOINING and REQ_INFO requests for a peer is at most O(log2 N) per round.

Applying a union bound over all peers and rounds, each peer receives at most O(log2 N) JOINING

messages and O(log2 N) REQ_INFO messages with high probability.

Theorem 9.13. If the b-epochs e, e − 1, . . . , z, where z = max(1, e − (cid:100)λlµb(cid:101)), are stable b-epochs, then whp, b-epoch
e is bandwidth-adequate.

Proof. We ﬁrst show that the communication cost for the non-directory nodes and directory nodes con-
trolled by any honest peer is O(log3 N) with high probability. Moreover, any newly joining node also sends
or receives at most O(log3 N) messages with high probability. In other words, there is sufﬁcient bandwidth
for peers to correctly execute the overlay protocols.

By Lemma 9.9, each committee can have at most O(log N) nodes with high probability.
Non-directory node. By Lemma 9.10, any honest peer controls at most O(log N) nodes in the network and
at most cm nodes in any committee in b-epoch e. This allows an honest peer to broadcast O(log N) messages
from a committee and simultaneously relay O(1) messages from all its nodes (in different committees), to all
neighbouring nodes. For example, during network size estimation, after phase 1, all nodes of a (random)
committee broadcast the entry information of the nodes that joined the committee during phase 1.
In
that case, a node in that committee would be broadcasting entry information of O(log N) nodes to all the
O(log2 N) neighbouring nodes in a single round.

Directory node. By Lemma 9.12, any honest peer receives at most O(log2 N) JOINING and REQ_INFO
messages in any round of b-epoch e. A directory node has to respond to a REQ_INFO with a COMM_INFO
message consisting of entry information of nodes in a committee. Thus, the communication cost for a peer
due to COMM_INFO is O(log3 N).

Joining node. The node sends JOINING messages to all directory nodes in one middle-aged bucket. This
amounts to O(log2 N) messages in total, as there are O(log N) directory nodes in a bucket. The commu-
nication cost due to REQ_INFO messages is the same as that of JOINING messages, as they are sent to just
O(log N) directory nodes in O(log N) buckets. As shown above, honest peers within the network can han-
dle all the join requests, and send back (valid) committee entry information in COMM_INFO messages, which
amounts to O(log3 N) messages (by Lemma 9.9). Finally, the node sends JOINING messages to all nodes in
O(log N) committees, resulting in O(log2 N) messages (by Lemma 9.9).

Theorem 9.14. If the b-epochs e, e − 1, . . . , z where z = max(1, e − (cid:100)λdlµb(cid:101)), are bandwidth-adequate b-epochs,
then in b-epoch e, the active directory is robust with high probability.

Proof. For achieving property 2 of a robust active directory (Deﬁntion 9.1) over a period of b-epoch, there
are two key requirements: (1) the entry information of a new node q should be stored by honest nodes in
the appropriate middle-aged bucket b, and (2) throughout the lifetime of a node u, its entry information is
stored by honest nodes in bucket b. For the ﬁrst requirement, the honest peers controlling those directory
nodes should have enough bandwidth to receive all the join requests. This can be ensured as it is already
given that b-epoch e and the last (cid:100)λdlµb(cid:101) b-epochs are bandwidth-adequate. And both requirements are
contingent on the fact that there are a sufﬁcient number of honest nodes in each bucket. Therefore, we focus
on proving that property 1 of a robust active directory (Deﬁntion 9.1) is achieved with high probability.

Let us calculate the probability that any honest directory node does not leave before completing the
lifetime of a directory node. Since the lifetime is set to be Tdl blocks, which amounts to at most λdlµb
epochs. The probability that an honest directory node would stay, denoted by P, is at least 2−λdlµb .

A constant fraction of the directory nodes in a bucket are honest using blockchain fairness. The number
of honest blocks (or directory nodes) in a bucket, denoted by M, is at least (1 − ρ)(1 − δ)λd log2 N, with
high probability, for some δ ≤ O(1/ log N).

31

Again, due to blockchain fairness, any peer controls at most O(log N) directory nodes in a bucket. Let
us say x is the fraction of blocks generated by one peer in one bucket, then whp by fairness property, for a
small δ(cid:48) > 0, and where L = λd log2 N is the number of blocks in a bucket and Nr is the network size in
round r in b-epoch e,

x ≤ 1 − (1 − δ)

(cid:19)

(cid:18) Nr − 1
Nr

1 − δ
Nr

≤ δ(cid:48) +

≤ c

κ
L

,

for some suitable constant c > 0. Note that the second term in the second inequality is negligible, as
Nr ≥ N1/y in any round. Thus, the number of blocks generated is at most xL ≤ cκ = c1 log N, where
c1 > 0 is a constant, and κ = O(log N). Applying a union bound on all the peers, each peer has at most
m = O(log N) blocks in a bucket.

Let us now show that there are always at least λb log2 N honest directory nodes in a bucket. Let N(p)
be the number of blocks generated by an honest peer p in a certain bucket. (Note that this is ﬁxed once
the bucket is formed.) Let X(p) be the random variable that is equal to N(p)/m if p stays for the entire
directory node lifetime, otherwise equal to 0. The expected value of the summation over all the honest
peers is ∑p(PN(p))/m = (PM)/m. For large enough λd, applying a Chernoff bound, the value of the
summation is Θ((PM)/m) with high probability. (Note that if λd is increased, then the size of the bucket
increases, but this can be compensated by a constant factor decrease in the number of buckets leading to a
constant factor increase in the bandwidth cost.) Multiplying the summation by m, gives the total number
of honest nodes that stay for the entire directory node lifetime, which is λb log2 N.

Applying a union bound on the Bact buckets at the start of b-epoch e and the buckets generate in b-
epoch e, this holds for all the buckets in the active directory in b-epoch e. Thus, property 1 holds with
high probability. As discussed earlier, property 2 automatically follows if property 1 is satisﬁed for all the
required buckets.

Lemma 9.15. If a b-epoch is bandwidth-adequate and the active directory is robust in that b-epoch, then the JOIN
protocol is successful with high probability.

Proof. Recall that an implication of a b-epoch being bandwidth-adequate is that the directory nodes can
handle, i.e., receive and respond to all join requests sent to them. Moreover, since the active directory is
robust, the (honest) directory nodes in each bucket have the correct membership information.

Let us ﬁrst focus on any one bucket that the new node sends to join request to. The probabilistic guar-
antee of the success of JOIN protocol because of the random directory node sampling done for REQ_INFO
messages. If an honest directory node in that bucket receives REQ_INFO, then it sends the required entry
information to the new node. This is sufﬁcient because the Byzantine directory nodes can only under-
represent the committee nodes.

Thus, we calculate the probability that the new node samples an honest directory node in that bucket.
Since it picks λj log N uniform and independent samples, for large enough λj, the probability that none of
Nc , for some constant c > 2.
Applying a union bound over all the O(log N) buckets that the new node contacts, the JOIN protocol is

them honest nodes is

1 − λb
λd

(cid:105)λj log N

≤ 1

(cid:104)

successful with a high probability.

Theorem 9.16. If the b-epochs e, e − 1, . . . , z where z = max(1, e − (cid:100)λlµb(cid:101)), are stable and bandwidth-adequate,
and if the active directory is robust in those b-epochs, then whp, the overlay network is partition-resilient in b-epoch e.

Proof. Since the last λlµb b-epochs are stable, the ﬁrst property of partition-resilience is ensured with high
probability by Lemma 9.9 and 9.11, for a large enough λn. (For the ﬁrst b-epoch, there exists at least λp

32

honest peers in each committee if the network is correctly bootstrapped.) Observe that if the join protocols
of all the nodes that joined in the last λlµb are successful, then the requirements for the connections among
peers are also ensured. Since the last λlµb b-epochs are bandwidth-adequate and the active directory is
robust, then by Lemma 9.15, all the (honest) nodes are successful with high probability, for a large enough
λj.

Lemma 9.17. If b-epoch e is stable and bandwidth-adequate, and the network is partition-resilient in b-epoch e, then
e such that M(cid:48)
whp, the (honest) peers can calculate the quantity M(cid:48)
e /µb, (1 + δerr)µb MH
e ].
Proof. Unlike other protocols, the network size estimation protocol is minimally affected by ∆-synchrony.
(Recall that there can be a difference of µb blocks in the chain lengths of honest peers.) This is because the
node joins are bound to the block used in their proofs. Thus, the existing peers consider all the node joins
in phase 1 even though they may start and end the phase 1 of b-epoch at possibly different times. Let G(cid:48)
e
and Ge be the estimate and actual number of nodes that joined in phase 1 of b-epoch e respectively. First,
let us show that whp, all the honest peers can calculate the quantity G(cid:48)
e ∈ [(1 − δ1)Ge, (1 + δ1)Ge]
where δ1 < 1 is a small positive constant.

e ∈ [(1 − δerr)(1 − ρ)ML

e, and G(cid:48)

Let Je be the expected number of new nodes that can be generated in phase 1 of b-epoch e. Recall that
the node difﬁculty threshold, pn = (λn log N)/(qα), is ﬁxed. Since by design, phase 1 of a b-epoch is
Θ(α), for a large enough λn, using Chernoff bounds, Ge ∈ [(1 − δ2)(1 − ρ)Je, (1 + δ2)Je], for a small positive
constant δ2 < 1. The lower bound has a factor of (1 − ρ) because the Byzantine peers may choose not to
join any of their nodes (or even mine for nodes). For ease of exposition, let the aforementioned bounds be
Ge ∈ [C1λnCe log N, C2λnCe log N], where C1 and C2 are appropriate constants.

Note that kc ≥ 1 random committees broadcast the newly joined node IDs (Step 3 of Algorithm 3
description in Section 4.1). All the peers get to know the number of new nodes that have joined each
of those kc committees in at most ∆ rounds because the network is partition-resilient and b-epoch e is
bandwidth-adequate. The peers need to estimate Ge from that information. This is analogous to showing
that if m = Ge balls are (uniform) randomly thrown into n = Ce bins. If kc bins are (uniform) randomly
picked to see the number of balls in them, then the estimate of m is within a (ﬁxed) multiplicative error of
δ1 ∈ (0, 1], whp, assuming m/n ≥ C1λn log N.

Let Xi,j be a Bernoulli random variable such that Xi,j = 1 if the ith ball is thrown into bin j, and Xi,j = 0
otherwise. For a given ball i, Xi,1, Xi,2, . . . , Xi,n are zero-one random variables, meaning that ∀j, Xi,j ∈ {0, 1},
and their sum being equal to 1, ∑j Xi,j = 1. By Lemma 8 in [DR96], these random variables are negatively
associated. Let Xi = {Xi,j}j=n
j=1 , then it is easy to see that Xi and Xj, for i (cid:54)= j, are independent. Then, by
Proposition 7 in [DR96], the full vector, {Xi,j}i=m,j=n

i=1,j=1 , is also negatively associated.

Since kc bins are (uniform) randomly picked, by symmetry, let them be the ﬁrst kc bins. Let He =
∑i=m,j=k
i=1,j=1 Xi,j. Since for all j, E[∑i=m
i=1 Xi,j] = m/n, by linearity of expectation, E[He] = kcm/n. Using both
sides of Chernoff bounds,

Pr[He (cid:54)∈ [(1 − δ1)mkc/n, (1 + δ1)mkc/n]] = Pr[HeCe/kc (cid:54)∈ [(1 − δ1)Ge, (1 + δ1)Ge]]

≤ 2 exp(−mkcδ2
≤ 2 exp(−C1λnkc log Nδ2

1/3n)

1/3).

For a large enough λn, C1λnkcδ2
e, and G(cid:48)
G(cid:48)

e ∈ [(1 − δ1)Ge, (1 + δ1)Ge] where δ1 < 1 is a small positive constant.

1/3 > 1. This proves that whp, all the honest peers can calculate the quantity

Recall that the actual number of nodes that are generated in phase 1 of b-epoch e is Ge ∈ [(1 − δ2)(1 −
b rounds
e , and this implies that Ge ∈ [(1 − δ2)(1 −
e are the minimum and maximum network sizes in phase
e ∈ [(1 −

ρ)Je, (1 + δ2)Je]. By blockchain liveness, the time elapsed in phase 1 of any b-epoch is at least α1/µ2
and at most α1 rounds. Hence, pnα1 ML
e ] where ML
b, (1 + δ2)pnα1 MH
ρ)pnα1 ML
1 of b-epoch e. If the constants δ1 and δ2 are appropriately chosen, and it is given to us that G(cid:48)
δ1)Ge, (1 + δ1)Ge], this would imply that G(cid:48)

e ∈ [(1 − δerr)(1 − ρ)pnα1 ML

e /µ2
e and MH

b ≤ Je ≤ pnα1 MH

b, (1 + δerr)pnα1 MH
e ].

e /µ2

e /µ2

33

Since pn, α1 and µb are known to all the peers, the (honest) peers calculate the quantity M(cid:48)

e = G(cid:48)

eµb/pnα1

so that M(cid:48)

e ∈ [(1 − δerr)(1 − ρ)ML

e /µb, (1 + δerr)µb MH

e ], thus proving the lemma.

Theorem 9.18. If b-epoch e is stable and bandwidth-adequate, and the network is partition-resilient in b-epoch e,
then whp, b-epoch e is synchronized.

Proof. After phase 1 of b-epoch e, all the honest peers receive the set of nodes that joined a (randomly
selected) committee (Step 3 of Algorithm 3 description in Section 4.1) as the network is partition-resilient
and b-epoch e is bandwidth-adequate. In Step 3 of Algorithm 3 description in Section 4.1, due to Lemma
9.17, whp, all the honest peers can calculate the quantity M(cid:48)
e /µb, (1 +
δerr)µb MH
e ].

e ∈ [(1 − δerr)(1 − ρ)ML

e such that M(cid:48)

Finally, by the fairness assumption, with high probability, in a segment of length of L = λlb log N, the
fraction of blocks held by the honest peers is at least (1 − δ(cid:48))(1 − ρ), where δ(cid:48) is a small constant that
depends on λlb. The parameters are set such that (1 − δ(cid:48))(1 − ρ) > 0.5, which means that there is an honest
majority of blocks.

Lemma 9.19. If b-epoch e is synchronized, then b-epoch e has a good estimate ratio.

e ∈ [(1 − δerr)(1 − ρ)ML

e = M(cid:48)
e,
e are the minimum and maximum
e /2 ≤ Le ≤
e as the network size can change by a multiplicative factor of 2 in any b-epoch. (This is because the

Proof. All (honest) peers adopt the network size estimate after phase 1 of b-epoch e by setting L(cid:48)
where M(cid:48)
network sizes in phase 1 of b-epoch e and δerr < 1 is a small positive constant. Notice that MH
2ML
number of rounds in any b-epoch is at most α rounds by the blockchain liveness.)

e /µb, (1 + δerr)µb MH

e ], and ML

e and MH

To maximize the estimate ratio of b-epoch e, we need to minimize L(cid:48)

e and maximize Le,

Le
L(cid:48)
e

=

2ML
e

(1 − δerr)(1 − ρ)ML

e /µb

=

2µb
(1 − ρ)(1 − δerr)

.

This upper bound is actually attained when the Byzantine peers do not join their nodes in phase 1 (thereby
reducing the total estimate of the hash power by a factor (1 − ρ)) and the total hash rate remains the same
until phase 1, and increases by a factor of 2 by the end of the b-epoch (which means that this increase in
hash rate was not captured by the estimation algorithm in phase 1).

To minimize the estimate ratio of b-epoch e, we need to maximize L(cid:48)

e and minimize Le,

Le
L(cid:48)
e

=

MH
e
2(1 + δerr)µb MH
e

=

1
2µb(1 + δerr)

.

And this lower bound is actually attained when all the Byzantine peers (mine and) join their nodes in phase
1 and the total hash rate remains the same until phase 1, and decreases by a factor of 2 by the end of the
b-epoch.

Theorem 9.20. If the network is partition-resilient in b-epochs e − 1 and e − 2, and if b-epochs e − 1 and e − 2 are
synchronized, and if the b-epochs e − 1 is bandwidth-adequate, then b-epoch e is a stable b-epoch, for e ≥ 3. If the
network is appropriately bootstrapped (Section 3), then b-epochs 1 and 2 are stable b-epochs.

Proof. Let us ﬁrst consider a b-epoch e ≥ 3. For b-epoch e to be a stable b-epoch, the dimension of the
hypercube should be appropriately set according to the network size in any round in b-epoch e. Since there
is a “lag” of one b-epoch in increasing the dimension (see Section 4.3), the decision to change the dimension
of the hypercube must be taken by all the peers at the end of b-epoch e − 2; this can be done because the b-
epoch e − 2 is synchronized. By the end of b-epoch e − 1, the new number of committees is agreed upon by
all peers again because the b-epoch e − 2 is synchronized. As the b-epoch e − 1 is bandwidth-adequate, and
the network is partition-resilient in b-epoch e − 1, the appropriate dimension of the hypercube in b-epoch
e is adopted such that the network size in any round r of b-epoch e satisﬁes the bounds given in Deﬁnition
9.6.

34

Section 3 provides details about bootstrapping the network such that Deﬁnition 9.6 is satisﬁed. More-
over, the dimension of the hypercube need not be changed in both b-epoch 1 and 2 because the network
size can change by at most a factor of 2 (as there are at most α rounds in a b-epoch via blockchain liveness).
In other words, the network size will remain within the bounds given in Deﬁnition 9.6. Thus, b-epoch 1
and 2 are stable.

Theorem 9.21. The overlay network is partition-resilient and each honest peer sends or receives O(log3 N) messages
per round, for a polynomial number of rounds with high probability.

Proof. The goal is to maintain partition-resilience over a polynomial number of b-epochs once the network
is appropriately bootstrapped at time zero. We carefully exploit the dependencies of the theorems described
so far to prove the statement. We describe a series of events that turn out to be useful.

• Pi is the event that the network is partition-resilient in b-epoch i.

• Qi is the event that b-epoch i is synchronized.

• Ri is the event that b-epochs i, i − 1, . . . , z where z = max(1, i − (cid:100)λlµb(cid:101)), are stable.

• Ti is the event that b-epochs i, i − 1, . . . , z where z = max(1, i − (cid:100)λdlµb(cid:101)), are bandwidth-adequate.

• Ui is the event that the active directory is robust in b-epochs i, i − 1, . . . , z where z = max(1, i − (cid:100)λlµb(cid:101)).

• Si is the event that b-epoch i is “successful”, meaning that, Si = Pi ∩ Qi ∩ Ri ∩ Ti ∩ Ui.

Both b-epoch 1 and 2 do not require dimension change if the network is correctly bootstrapped (Section
3). As mentioned in Theorem 9.20, b-epoch 1 is a stable b-epoch, i.e., R1 occurs. If R1 happens, then T1
occurs with high probability by Theorem 9.13. And if T1 happens, then Ui occurs with high probability due
to Theorem 9.14. If R1, T1 and Ui happen, then P1 happens with high probability because of Theorem 9.16.
This also means that Q1 happens with high probability due to Theorem 9.18. Therefore, applying a union
bound, S1 happens with high probability. The same chain of arguments also holds for b-epoch 2.

For a b-epoch i where i ≥ 2, if there is a dimension change, the system, intuitively, gets bootstrapped
again (during the transformation b-epoch). The key observation in Lemma 9.11 and Theorem 9.16 is that
the lower bound on the number of honest peers for partition resilience relies only on the honest node joins
of previous b-epoch. This is important because even though after a dimension change (adopting the new
hypercube), the nodes that joined before the transformation b-epoch are considered invalid, Lemma 9.11
and Theorem 9.16 still apply to ensure partition-resilience for the nodes in the new hypercube.

Given that the events Si and Si−1 have occurred, by Theorem 9.20, Pi ∩ Qi ∩ Ri and Pi−1 ∩ Qi−1 ∩ Ri−1
imply that b-epoch i + 1 is a stable b-epoch, in other words, event Ri+1 happens. Once Ri+1 has taken place,
then again, by a similar chain of arguments, the event Si+1 happens with high probability. Applying a union
bound over a polynomial number of b-epochs, the network is partition-resilient and each honest peer sends
or receives O(log3 N) messages, with a high probability.

9.1 Recovery analysis

Deﬁnition 9.22. An honest peer is said to be corrupted if it either stops functioning (i.e., leaves the network) or
becomes Byzantine in which case it is controlled by the adversary.

Deﬁnition 9.23. A bucket is said to have failed if more than 1/2 fraction of honest peers in it are corrupted.

Deﬁnition 9.24. Let the set of buckets in the active directory that are responsible for a committee C be denoted as BC.
A committee C is said to be safe if:

1. It has at least 20 log N honest peers.

2. No bucket in BC has failed.

35

Deﬁnition 9.25. Two committees C1 and C2 are said to be connected if:
1. Each honest peer in C1 is connected to Ω(log N) honest peers in C2.
2. Each honest peer in C2 is connected to Ω(log N) honest peers in C1.

Deﬁnition 9.26. Let S denote a set of safe committees. Let GS be the graph where vertices correspond to safe commit-
tees in S and edges represent the connection between two safe committees. The overlay network is said to experience
an (ε, δ)-catastrophic failure in b-epoch e if the following events occur.

1. There are at least (1 − ε)Ce safe committees for a small constant ε > 0.

2. At most δ fraction of peers get corrupted for a small constant δ > 0.

3. There exists a graph GS with a diameter at most 2 log N, in which at least µna fraction of honest peers are
present16, where |S| ≥ abµnCe for a > 1/(1 − ε(cid:48)) and b = 1/(1 − ε(cid:48)(cid:48)) for an arbitrarily small positive
constant ε(cid:48) and ε(cid:48)(cid:48) ≤ O((log1/2 N)/N1/2y).

Lemma 9.27. (Restated, Theorem 1 of [Dat02]) No matter which f nodes are made faulty in a multi-hypercube with
n nodes and (α, β) expansion, there are at least n − β f
α(β−1) ,
such that all the nodes in the path are not faulty.

β−1 nodes that have log n-length path to at least n − f

Lemma 9.28. (Restated, Lemma 4.6 of [FS07]) Let l, l(cid:48), r,(cid:48) r, d, k, λ and n be any positive values where l(cid:48) ≤ l, r(cid:48) ≤ r,
0 < λ < 1 and

d ≥

2r
r(cid:48)l(cid:48)(1 − λ)2

(cid:18)

l(cid:48) ln

(cid:19)

(cid:18) le
l(cid:48)

+ r(cid:48) ln

(cid:17)

(cid:16) re
r(cid:48)

(cid:19)

+ k ln n

Let G be a random bipartite multigraph with left side L and right side R where |L| = l, |R| = r and each node in L
has d random neighbours in R. Then, with probability at least 1 − n−k, for any subset of L(cid:48) ⊂ L where |L(cid:48)| = l(cid:48),
there is no set R(cid:48) ⊂ R where |R(cid:48)| ⊂ R, such that all nodes in R(cid:48) share less than λl(cid:48)d/r edges with L(cid:48).

Lemma 9.29. No matter which f nodes are made faulty in a multi-hypercube with n nodes and (α, β) expansion,
there exists a connected component of at least n − 3 f /2 non-faulty nodes with a diameter of at most 2 log n, for
α(β − 1) ≥ 2/3 and β ≥ 3.

Proof. This follows directly from Lemma 9.27. Viewing the multi-hypercube as a n-node multi-butterﬂy

network where a row of switches is simulated by a node, the theorem says that any of the

(cid:16)

(cid:17)

n − f
. For α(β − 1) ≥ 2/3 and β ≥ 3, consider a
faulty) inputs can reach any of the (non-faulty)
connected component c of any one such (non-faulty) input and the n − 3 f /2 (non-faulty) outputs including
the intermediate switches; each pair of them can reach other by a path of length at most 2 log n. In case of a
multi-hypercube, since a row (consisting of one input, one output and log n switches) is simulated by one
node, there are at least n − 3 f /2 distinct nodes (because one output is simulated by one node and there are
n − 3 f /2 such outputs) in c that have a diameter of at most 2 log n.

α(β−1)

(cid:16)

n − β f
β−1

(cid:17)

(non-

Lemma 9.30. For e ≥ 2 and constant λp > 0, if at most δ fraction of peers are corrupted in a stable b-epoch e − 1,
then in b-epoch e, there are at least (1 − ε(cid:48))Ce committees that are assigned with at least λp log N honest peers with
high probability, where ε(cid:48) ≤ O(1/ log N) and δ < 1 is a small positive constant.

Proof. First, we get a lower bound on the number of honest peers that stay in the entire b-epoch e − 1. By
stable b-epoch property and the fact that at most ρ fraction are Byzantine, this is at least (1 − ρ)Ce−1/λs.
Then, we ﬁnd a lower bound on the number of new nodes generated in b-epoch e − 1 by each of these

16For example, a blockchain protocol may progress with 70% of total honest peers but no Byzantine peers, or with 90% of total
honest peers and 20% of total peers being Byzantine. µn, which depends on the maximum number of Byzantine peers, captures the
fact that the blockchain provides its guarantees even if not all the honest peers participate. Note this is a minimal requirement to
recover from a (massive) eclipse attack.

36

peers. Recall that the node difﬁculty threshold, pn = (λn log N)/(qα), is ﬁxed. By blockchain liveness (for
number of rounds in a b-epoch), the expected number of new honest nodes, in b-epoch e − 1, is at least
(λn log N)/µ2
b. Applying Chernoff bounds and union bound, the total number of honest nodes by each of
those peers generated is at least d = Θ(λn log N) with high probability. (We drop the other constants unless
necessary, as λn controls the failure probability.)

These nodes get randomly mapped to Ce committees. (Note that Ce = Ce−1 if b-epoch e − 1 is not a
transformation b-epoch, and even otherwise, Ce = Θ(Ce−1).) Here, in Lemma 9.28, we can consider these
peers as the left side L and the committees in b-epoch e as the right side R where each vertex in L has at
least d random neighbours in R. In other words, with probability less than n−k for some constant k > 2,
there exists a set L(cid:48) ⊂ L such that l(cid:48) = δl and a set R(cid:48) ⊂ R of size (1 − ε(cid:48))Ce where each vertex has less than
λpcm log N nodes, for a positive constant cm. Speciﬁcally, λn is set large enough so that λl(cid:48)d/r ≥ λpcm log N.
As every other parameter is ﬁxed, obeying the condition of Lemma 9.28 by (again) setting λn large enough,
with high probability, we get that there are at least (1 − ε(cid:48))Ce committees that are assigned with at least
λpcm log N honest nodes even after δ fraction of peers get corrupted.

Finally, by Lemma 9.10, each peer controls at most cm nodes in a committee with a high probability.
Thus, in b-epoch e, there are at least (1 − ε(cid:48))Ce committees that are assigned with at least λp log N honest
peers with high probability.

Lemma 9.31. In any round r, if there are at least µnaI honest peers in a set S of committees, the following statements
hold with high probability, where |S|, |S(cid:48)| ≥ µnabC, C is the number of committees, µnab < 1, a > 1/(1 − ε(cid:48)) and
b = 1/(1 − ε(cid:48)(cid:48)) for ε(cid:48)(cid:48) ≤ O((log1/2 N)/N1/2y) and an arbitrarily small positive constant ε(cid:48). Here, I is the total
number of honest peers at round r. Jr(cid:48) and Lr(cid:48) are the number of new honest peers that joined the network and the
number of peers that left the network respectively, from round r to r(cid:48).

1. There are at least µna(I + Jr1 − Lr1 ) honest peers at round r + r1 for any α/µ2
2. For any round r ≤ r2 ≤ α, there are at least µn(I + Jr2 − Lr2 ) honest peers in the set S of committees.

b ≤ r1 ≤ α in set S(cid:48) of committees.

Proof. The Lemma says that there exists a large enough set of committees that can be replenished with a
set of distinct honest peers in a span of a b-epoch. And that in any round in the b-epoch, despite joins and
leaves, a certain fraction of honest peers are maintained in those set of committees. Note that this Lemma
does not deal with successful joins, robust active directory, etc., but only talks about peers getting assigned
to committees. (They will be dealt with in Theorem 9.32.)

Let us prove the ﬁrst property. Let L1

by round r1. Let L2
left the network by round r1. Thus, Lr1 = L1
r1
and stayed till round r1. Let J2
Thus, Jr1 = J1
r1

+ J2
r1.

r1 be the number of honest peers in round r that left the network
r1 be the number of honest peers from the set of peers that joined in subsequent rounds
r1 be the number of (new) honest peers that joined
r1 be the number of (new) honest peers that joined and left the network by r1.

r1. Let J1

+ L2

− L1
r1

− L1
r1

). For a large enough λn, each of the (I − L1
Note that (I + Jr1 − Lr1 ) = (I + J1
) get at least one
r1
r1
new (valid) node with high probability (via Chernoff bounds). Since J1
r1 peers joined the network, they
must have joined with at least one (valid) node. Thus, out of the (I + J1
− L1
) peer joins, on expectation,
r1
r1
) go to the set S(cid:48) of committees (as each node is randomly mapped to a committee). Thus,
µnab(I + J1
r1
applying Chernoff bounds, for ε(cid:48)(cid:48) ≤ O((log1/2 N)/N1/2y), there are at least µna(I + Jr1 − Lr1 ) honest peers
at round r + r1 with high probability.

Consider a large enough s = Θ(log N). We batch together s leaves and s joins over the rounds until
round r2 to prove the second property. Batching the joins together is not difﬁcult as they are independent
of each other. Batching the leaves together requires a little care. Recall that the sequence of honest leaves
are obliviously speciﬁed by the churn adversary. Let us say that there are n peers at round r. And, for
some round r(cid:48) ≥ r, there are l honest peer leaves and j honest peer joins from round r until round r(cid:48). Then,
focusing on r(cid:48), we can claim that any set of l honest peers (out of n + j peers) has equal probability of having
left.

37

Applying Chernoff bounds for a batch of s honest leaves, there are at most (1 + ε(cid:48))µnas honest leaves
from the set S of committees with high probability for a small ε(cid:48) > 0 and large enough s. Similarly, applying
Chernoff bounds for a batch of s honest joins, there are at least µnab(1 − ε(cid:48))s ≥ µna(1 − ε(cid:48))s honest joins
from the set S of committees with high probability for a small ε(cid:48) > 0 and large enough s.

Let the number of honest peers at round r in the set S of committees be denoted as Hr. Then, for any

round r ≤ r2 ≤ α,

Hr2 ≥ µnaI − µna(1 + ε(cid:48))Lr2 − O(log N) + µna(1 − ε(cid:48))Jr2 − O(log N)

= µn(I + (a − 1)I − Lr2 − (a(1 + ε(cid:48)) − 1)Lr2 + Jr2 + (a(1 − ε(cid:48)) − 1)Jr2 ) − O(log N)
= µn(I − Lr2 + Jr2 ) + µn((a − 1)I − (x(1 + ε(cid:48)) − 1)Lr2 + (a(1 − ε(cid:48)) − 1)Jr2 ) − O(log N).

For a ≥ 1/(1 − ε(cid:48)), we can ignore the second join term as that would only increase the RHS,

Hr2 ≥ µn(I − Lr2 + Jr2 ) + µn((a − 1)I − (a(1 + ε(cid:48)) − 1)Lr2 ) − O(log N).

By using the fact that if the number of honest peers at round r is I, then at any r ≤ r2 ≤ α, then at most half
the number of those peers can leave the network, i.e., considering all peers are honest (which maximizes
Lr2), we get that Lr2 ≤ I/2. Thus, for a > 1/(1 − ε(cid:48)),

Hr2 ≥ µn(I − Lr2 + Jr2 ) + µn I((a − 1) − (a(1 + ε(cid:48)) − 1)/2) − O(log N)
(cid:18) 1 − ε(cid:48)
2

≥ µn(I − Lr2 + Jr2 ) + µn I

− O(log N)

1
2

−

(cid:19)

(cid:18)

(cid:19)

a

≥ µn(I − Lr2 + Jr2 ).

Theorem 9.32. If the overlay network experiences an (ε, δ)-catastrophic failure, then it becomes partition-resilient in
a constant number of epochs with high probability.

Proof. The high-level intuition for attaining recovery is to replace the entire active directory by a new one
(that has no bucket failures). If that is posssible, then new active directory facilitates honest nodes joins to
committees as required. Catastrophic failure is deﬁned in a way that there is one large connected compo-
nent of sufﬁcient number of honest peers with a low diameter, that is responsible for the progress of the
blockchain. First, we need to prove that the component gets replenished with new (honest) peers as peers
join and leave. Then, we focus on that component of committees and show that the lemmas and theorems
in Section 9 hold for them, albeit for some small changes. If we can show that the overlay can rely on
those subset of committees until a new active directory is formed, then after one additional b-epoch, the
overlay reverts to being (fully) partition-resilient as in Section 9. (Recall that an active directory consists
of O(α/β) blocks, amounting up to a O(α) rounds, via blockchain liveness.) The main technical difﬁculty
lies in handling dimension change and showing that the new topology has a large connected component of
committees with a low diameter, having a sufﬁcient number of honest peers. And to handle that difﬁculty,
we rely on the properties of multi-hypercube [Dat02] and bipartite expanders [FS02, FS07].

Let us say that it takes at most K half-lives for an active directory to be formed. We split the proof into

three cases. (Case 2 and 3 can be merged together, but we keep them separate for ease of understanding.)

Case 1. In this case, the overlay does not initiate a dimension change in any b-epoch e, e + 1, . . . , e + K + 1.
If µnab < (1 − ε) in Lemma 9.31 where a, b as in Deﬁnition 9.26, the set S of committees have a sufﬁcient
number of honest peers in b-epoch e and the subsequent b-epochs with high probability. We now focus
on the set S of committees (and their buckets) and show that the lemmas and theorems in Section 9 also
hold after a catastrophic failure. The lemmas related to bounds on the number of node assignments to
committees, number of nodes controlled by a peer and the number of join requests handled by a peer
(and the total communication cost) apply here without any change.
Instead of showing that the entire
active directory is robust, Theorem 9.14 can be used to show that the non-failed buckets have the required

38

properties of robustness (Deﬁnition 9.1). This can be done by increasing λd by a factor of 2, after which
the same analysis holds in Theorem 9.14, as at most 1/2 fraction of honest peers in a non-failed bucket get
corrupted. Thus, the node joins for those buckets are successful.

The network is not partition-resilient, even for the set S of committees, because by deﬁnition, safe com-
mittees have at least 20 log N honest peers (and not at least λp log N honest peers). As the safe committees
have at least 20 log N honest peers, by Chernoff and union bounds, at least Ω(log N) in each safe commit-
tee would stay for another 2 b-epochs with high probability. Thus, connectivity among committees in S
maintained during those two b-epochs. Then, by Lemma 9.11, using the node joins in b-epoch e + 1, we can
show that the properties of partition resilience (Deﬁnition 9.3) hold for the set S of committees from b-epoch
e + 2 onwards. (The deﬁnition of partition-resilience is deliberately made to be topology-oblivious, as in, it
can also apply to any subset of committees.)

The tricky part is to show that partition-resilience properties can be maintained for S if network size
is allowed to signiﬁcantly vary over time. Speciﬁcally, a small modiﬁcation is required for Algorithm 3
used to estimate the network size. A random committee is selected using the hash of the block that de-
termines the end of phase 1 of that b-epoch. Instead of choosing a random committee, we make a small
modiﬁcation to the protocol to choose Θ(log N) random committees. (For example, this can be done by
appending 1, 2, . . . , log N to the input, consisting of hash of the block, for the hash function, and obtaining
the output for each of those inputs. In other words, the hash function can be used to generate the required
veriﬁable randomness, where the computational cost is negligible. Recall that each peer can query the hash
function q > 0 number of times in a round, where q is substantially large.) Once a node receives the entry
information of the nodes that belonged to those committees, it chooses the committee that encountered
the maximum number of node joins. If this modiﬁcation is done, then with a high probability, that chosen
committee would belong to S because |S| > Ce. (The nodes consider the committee with maximum num-
ber of node joins because the failed committees can only under-represent node joins.) Thus, the rest of the
lemmas and theorems regarding network size estimation and b-epoch synchronization hold if the network
size estimation can be done securely. (Also, network size estimation is required for the subsequent cases in
which dimension change needs to be done.)

Case 2. In this case, b-epoch i is a transformation b-epoch for i > e. The proof arguments from Case 1
also carry over to this case until b-epoch i. The tricky part is to handle dimension change, as it is important
to maintain a set S(cid:48) in the new topology that has similiar properties as S so that the proof arguments
from Case 1 can also apply from b-epoch i + 1 onwards. Our ﬁrst observation is that at most ε fraction of
buckets have failed in a directory. This is because if there are more bucket failures, then this would result
in a number of committee failures greater than εCe. Since this applies to all the directories in the active
directory, at most ε buckets fail in the active directory during a catastrophic failure. This means that at most
ε committees have failed in the next topology as well, as the committee-directory mappings are such that
each bucket is responsible for the same number of committees, and the sets of committees that any two
buckets are responsible for, are disjoint. We now rely on the guarantees provided by the multi-hypercube.
By Lemma 9.27, at least Ci+1(1 − (3ε/2)) form a connected component17 with a diameter of at most 2 log N.
If (1 − (3ε/2)) > µnab as in Deﬁnition 9.26, then using Lemma 9.31, the same arguments carry over to the
next topology. This applies to multiple dimension changes that can occur over the K + 1 b-epochs.

Case 3.

In this case, b-epoch e itself is a transformation b-epoch. We cannot just rely on the multi-
hypercube as the honest peers that replenish the committees in S(cid:48) in the next topology, may get corrupted
during (or towards the end of) b-epoch e. We ﬁrst compute an upper bound on the number of committees
that can have less than λp log N honest peers if in total δ fraction of honest peers are corrupted. By Lemma
9.30, there are at most δ(cid:48) ≤ O(1/ log N) fraction of committees that have less than λp log N honest peers.
Thus, if (1 − (3ε/2) − δ(cid:48)) ≥ µnab as in Deﬁnition 9.26, then using Lemma 9.31, there are a sufﬁcient number
of honest peers in S(cid:48) throughout b-epoch i + 1 by Lemma 9.31 with high probability. In other words, the
overlay can rely on the set S(cid:48) for the progress of the blockchain for b-epoch i + 1. Moreover, as in previous
case, there are at most ε fraction of committees fail due to bucket failures. From b-epoch i + 2 onwards,
the committees that had less than λp log N honest peers in b-epoch i + 1, but whose buckets had not failed,

17Refer to Deﬁnition 9.24 for connectivity between committees.

39

have at least λp log N honest peers with high probability by Lemma 9.11. Thus, the set S(cid:48) again resorts
to the large connected component of committees guaranteed by the multi-hypercube. Then, from b-epoch
i + 2 onwards, the overlay can rely on that set of committees for the progress of the blockchain, where the
same proof arguments of Case 1 apply.

Thus, in all these cases, the overlay network becomes partition-resilient in a constant number of b-

epochs with high probability.

References

[AS04]

BARUCH AWERBUCH and CHRISTIAN SCHEIDELER. Group spreading: A protocol for provably
secure distributed name service. In International Colloquium on Automata, Languages, and Program-
ming, pages 183–195. Springer, 2004. 3, 4, 11, 18, 20, 21, 23, 25, 43, 44, 45

[AS09]

———. Towards a scalable and robust dht. Theory of Computing Systems, 45(2):234–260, 2009. 3,
4, 7, 18, 20, 21, 22, 25, 43, 44, 45

[AZV17] MARIA APOSTOLAKI, AVIV ZOHAR, and LAURENT VANBEVER. Hijacking bitcoin: Routing attacks
on cryptocurrencies. In 2017 IEEE Symposium on Security and Privacy (SP), pages 375–392. IEEE,
2017. 24

[bit20]

BitInfoCharts - Bitcoin Explorer, 2020 (accessed August 28, 2020). 4

[blo20]

Blockchain.com Explorer, 2020 (accessed August 28, 2020). 4

[BNO+21] SEUNGJIN BAEK, HOCHEOL NAM, YONGWOO OH, MUOI TRAN, and MIN SUK KANG. On
the claims of weak block synchronization in bitcoin. Cryptology ePrint Archive, Report 2021/1282,
2021. https://ia.cr/2021/1282. 24

[CDKR02] MIGUEL CASTRO, PETER DRUSCHEL, ANNE-MARIE KERMARREC, and ANTONY ROWSTRON.
One ring to rule them all: Service discovery and binding in structured peer-to-peer overlay networks. In
Proceedings of the 10th workshop on ACM SIGOPS European workshop, pages 140–145. 2002. 2

[CDP96]

BOGDAN S CHLEBUS, KRZYSZTOF DIKS, and ANDRZEJ PELC. Reliable broadcasting in hypercubes
with random link and node failures. Combinatorics, Probability and Computing, 5(4):337–350,
1996. 18

[CGJ+17] ARKA RAI CHOUDHURI, MATTHEW GREEN, ABHISHEK JAIN, GABRIEL KAPTCHUK, and IAN
MIERS. Fairness in an unfair world: Fair multiparty computation from public bulletin boards.
In
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pages
719–728. 2017.

[CH07]

[Dat02]

[DG08]

MICHAEL CONRAD and HANS-JOACHIM HOF. A generic, self-organizing, and distributed bootstrap
service for peer-to-peer networks. In International Workshop on Self-Organizing Systems, pages 59–72.
Springer, 2007. 2

MAYUR DATAR. Butterﬂies and peer-to-peer networks. In European Symposium on Algorithms, pages
310–322. Springer, 2002. 18, 20, 36, 38

CHRIS GAUTHIER DICKEY and CHRISTIAN GROTHOFF. Bootstrapping of peer-to-peer networks. In
2008 International Symposium on Applications and the Internet, pages 205–208. IEEE, 2008. 2

[DHVR07] DANNY DOLEV, EZRA N HOCH, and ROBBERT VAN RENESSE. Self-stabilizing and byzantine-
tolerant overlay network. In International Conference On Principles Of Distributed Systems, pages
343–357. Springer, 2007. 20

40

[DR96]

[ES14]

DEVDATT P DUBHASHI and DESH RANJAN. Balls and bins: A study in negative dependence. BRICS
Report Series, 3(25), 1996. 33

ITTAY EYAL and EMIN GÜN SIRER. Majority is not enough: Bitcoin mining is vulnerable. In In-
ternational conference on ﬁnancial cryptography and data security, pages 436–454. Springer, 2014.
3

[eth20]

Etherchain - The Ethereum Blockchain Explorer, 2020 (accessed August 28, 2020). 4

[FS02]

[FS07]

AMOS FIAT and JARED SAIA. Censorship resistant peer-to-peer content addressable networks.
SODA, volume 2, pages 94–103. 2002. 20, 38

In

———. Censorship resistant peer-to-peer networks. Theory of Computing, 3(1):1–23, 2007. 3, 36,
38

[FSY05]

AMOS FIAT, JARED SAIA, and MAXWELL YOUNG. Making chord robust to byzantine attacks. In
European Symposium on Algorithms, pages 803–814. Springer, 2005. 3, 4, 18, 21, 22, 25, 43, 44, 45

[GHK13] RACHID GUERRAOUI, FLORIAN HUC, and ANNE-MARIE KERMARREC. Highly dynamic dis-
tributed computing with byzantine failures. In Proceedings of the 2013 ACM symposium on Principles
of distributed computing, pages 176–183. 2013. 3, 4, 7, 18, 21, 22, 25, 43, 44, 45

[GKL15]

[HK03]

JUAN GARAY, AGGELOS KIAYIAS, and NIKOS LEONARDOS. The bitcoin backbone protocol: Anal-
ysis and applications. In Annual International Conference on the Theory and Applications of Crypto-
graphic Techniques, pages 281–310. Springer, 2015. 6, 25

KIRSTEN HILDRUM and JOHN KUBIATOWICZ. Asymptotically efﬁcient approaches to fault-tolerance
in peer-to-peer networks.
In International Symposium on Distributed Computing, pages 321–336.
Springer, 2003. 20

[HKZG15] ETHAN HEILMAN, ALISON KENDLER, AVIV ZOHAR, and SHARON GOLDBERG. Eclipse attacks
on bitcoin’s peer-to-peer network. In 24th {USENIX} Security Symposium ({USENIX} Security 15),
pages 129–144. 2015. 3, 23

[HL89]

JOHAN HASTAD and THOMSON LEIGHTON. Fast computation using faulty hypercubes. In Pro-
ceedings of the twenty-ﬁrst annual ACM symposium on Theory of computing, pages 251–263. 1989.
18

[JPS+18] MERCY O JAIYEOLA, KYLE PATRON, JARED SAIA, MAXWELL YOUNG, and QIAN M ZHOU. Tiny
groups tackle byzantine adversaries. In 2018 IEEE International Parallel and Distributed Processing
Symposium (IPDPS), pages 1030–1039. IEEE, 2018. 3, 4, 18, 23, 44

[JRVJ15] HÅVARD D JOHANSEN, ROBBERT VAN RENESSE, YMIR VIGFUSSON, and DAG JOHANSEN. Fire-
ﬂies: A secure and scalable membership and gossip service. ACM Transactions on Computer Systems
(TOCS), 33(2):1–32, 2015. 20

[KS04]

[LM89]

VALERIE KING and JARED SAIA. Choosing a random peer. In Proceedings of the twenty-third annual
ACM symposium on Principles of distributed computing, pages 125–130. 2004. 22

TOM LEIGHTON and BRUCE MAGGS. Expanders might be practical: Fast algorithms for routing
around faults on multibutterﬂies. In 30th Annual Symposium on Foundations of Computer Science,
pages 384–389. IEEE Computer Society, 1989. 20

[LNBK02] DAVID LIBEN-NOWELL, HARI BALAKRISHNAN, and DAVID KARGER. Analysis of the evolution of
peer-to-peer systems. In Proceedings of the twenty-ﬁrst annual symposium on Principles of distributed
computing, pages 233–242. 2002. 7

41

[LQ19]

ANGELIQUE FAYE LOE and ELIZABETH ANNE QUAGLIA. You shall not join: A measurement study
of cryptocurrency peer-to-peer bootstrapping techniques.
In Proceedings of the 2019 ACM SIGSAC
Conference on Computer and Communications Security, pages 2231–2247. 2019. 2

[MDV+20] YIFAN MAO, SOUBHIK DEB, SHAILESHH BOJJA VENKATAKRISHNAN, SREERAM KANNAN, and
KANNAN SRINIVASAN. Perigee: Efﬁcient peer-to-peer network design for blockchains. In Proceedings
of the 39th Symposium on Principles of Distributed Computing, pages 428–437. 2020. 24

[MHG18] YUVAL MARCUS, ETHAN HEILMAN, and SHARON GOLDBERG. Low-resource eclipse attacks on
ethereum’s peer-to-peer network. Cryptology ePrint Archive, Report 2018/236, 2018. https://
eprint.iacr.org/2018/236. 3, 23

[Mit00]

MICHAEL MITZENMACHER. How useful is old information? IEEE Transactions on Parallel and
Distributed Systems, 11(1):6–20, 2000. 4, 19

[Nak08]

SATOSHI NAKAMOTO. Bitcoin: A peer-to-peer electronic cash system (white paper). 2008. 2

[NKMS16] KARTIK NAYAK, SRIJAN KUMAR, ANDREW MILLER, and ELAINE SHI. Stubborn mining: Gen-
eralizing selﬁsh mining and combining with an eclipse attack. In 2016 IEEE European Symposium on
Security and Privacy (EuroS&P), pages 305–320. IEEE, 2016. 3

[NW03] MONI NAOR and UDI WIEDER. A simple fault tolerant distributed hash table.
Workshop on Peer-to-Peer Systems, pages 88–97. Springer, 2003. 20

In International

[NW07] ———. Novel architectures for p2p applications: the continuous-discrete approach. ACM Transactions

on Algorithms (TALG), 3(3):34–es, 2007. 3, 20

[PD16]

[PS17]

[PSS17]

[RT19]

[S+06]

JOSEPH POON and THADDEUS DRYJA. The bitcoin lightning network: Scalable off-chain instant
payments, 2016. 4

RAFAEL PASS and ELAINE SHI. Fruitchains: A fair blockchain. In Proceedings of the ACM Sympo-
sium on Principles of Distributed Computing, pages 315–324. 2017. 6, 25

RAFAEL PASS, LIOR SEEMAN, and ABHI SHELAT. Analysis of the blockchain protocol in asyn-
chronous networks.
In Annual International Conference on the Theory and Applications of Crypto-
graphic Techniques, pages 643–673. Springer, 2017. 6

ELIAS ROHRER and FLORIAN TSCHORSCH. Kadcast: A structured approach to broadcast in
blockchain networks. In Proceedings of the 1st ACM Conference on Advances in Financial Technologies,
pages 199–213. 2019. 24

ATUL SINGH et al. Eclipse attacks on overlay networks: Threats and defenses. In In IEEE INFOCOM.
Citeseer, 2006. 3

[SARM21] MUHAMMAD SAAD, AFSAH ANWAR, SRIVATSAN RAVI, and DAVID MOHAISEN. Revisiting
nakamoto consensus in asynchronous networks: A comprehensive analysis of bitcoin safety and chain-
In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications
quality.
Security, pages 988–1005. 2021. 3, 24

[SCDR04] ATUL SINGH, MIGUEL CASTRO, PETER DRUSCHEL, and ANTONY ROWSTRON. Defending
In Proceedings of the 11th workshop on ACM SIGOPS

against eclipse attacks on overlay networks.
European workshop, pages 21–es. 2004. 3

[Sch05]

CHRISTIAN SCHEIDELER. How to spread adversarial nodes? rotate!
seventh annual ACM symposium on Theory of computing, pages 704–713. 2005. 3, 20, 22, 44, 45

In Proceedings of the thirty-

42

[SCM21] MUHAMMAD SAAD, SONGQING CHEN, and DAVID MOHAISEN. Syncattack: Double-spending in
bitcoin without mining power. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and
Communications Security, pages 1668–1685. 2021. 3, 24

[SCN+19] MUHAMMAD SAAD, VICTOR COOK, LAN NGUYEN, MY T THAI, and AZIZ MOHAISEN. Parti-
tioning attacks on bitcoin: Colliding space, time, and logic. In 2019 IEEE 39th International Conference
on Distributed Computing Systems (ICDCS), pages 1175–1187. IEEE, 2019. 23

[SFG+02]

JARED SAIA, AMOS FIAT, STEVE GRIBBLE, ANNA R KARLIN, and STEFAN SAROIU. Dynamically
fault-tolerant content addressable networks. In International Workshop on Peer-to-Peer Systems, pages
270–279. Springer, 2002. 20

[SGG01]

STEFAN SAROIU, P KRISHNA GUMMADI, and STEVEN D GRIBBLE. Measurement study of peer-
to-peer ﬁle sharing systems. In Multimedia Computing and Networking 2002, volume 4673, pages
156–170. International Society for Optics and Photonics, 2001. 17

[SMK+01]

ION STOICA, ROBERT MORRIS, DAVID KARGER, M FRANS KAASHOEK, and HARI BALAKR-
ISHNAN. Chord: A scalable peer-to-peer lookup service for internet applications. ACM SIGCOMM
Computer Communication Review, 31(4):149–160, 2001. 21, 22

[TCM+20] MUOI TRAN, INHO CHOI, GI JUN MOON, ANH V VU, and MIN SUK KANG. A stealthier par-
In IEEE Symposium on Security and Privacy

titioning attack against bitcoin peer-to-peer network.
(S&P). 2020. 24

[Upf92]

ELI UPFAL. An o (log n) deterministic packet-routing scheme. Journal of the ACM (JACM), 39(1):55–
70, 1992. 20

[YKGK10] MAXWELL YOUNG, ANIKET KATE, IAN GOLDBERG, and MARTIN KARSTEN. Practical robust
communication in dhts tolerating a byzantine adversary. In 2010 IEEE 30th International Conference
on Distributed Computing Systems, pages 263–272. IEEE, 2010. 43

A More on Recovery

In this section, we argue that the existing solutions for join-leave attacks cannot easily recover from the
committee failures considered in Section 5. Their join (and leave) protocols depend on the honest majority
of committees18. Once a committee loses the honest majority, it can initiate new (malicious) joins, either to
replenish itself with more malicious peers or make other committees fail. In particular, even when a small
number of committees, say O(log N) committees have a malicious majority, then the network can continue
to have at least Ω(log N) committees with malicious majority over time. Before delving into the technical
details, we strive to provide a high-level intuition for vulnerability to arbitrary committee failures in the
existing solutions.

First, we specify the combination of network and join protocols for which recovery is hard to achieve.
We are interested in a virtual network (that has low diameter, low degree and good expansion) of commit-
tees of Θ(log N) peers. Typically, this is termed as a “quorum topology” [YKGK10]. More speciﬁcally, the
committees are functional units of the (virtual) network. We recall a few important invariants of a quorum
topology [YKGK10].

Deﬁnition A.1. An overlay network is said to have a quorum topology if it satisﬁes the following invariants.

1. Network of committees. The overlay network is deﬁned by a virtual graph of committees GC where vertices

are committees and edges between nodes represent connections between committees.

2. Committee size. Each committee consists of Θ(s) peers where s = Ω(log N).

18They are also referred to as quorums [AS04, AS09] or swarms [FSY05] or clusters [GHK13] in the literature.

43

3. Membership. Every peer belongs to at least one committee.

4. Intra-committee communication. Every peer can communicate with all other members of its committees.

5. Inter-committee communication. If Ci and Cj share an edge in GC, then a peer belonging to Ci can commu-

nicate directly with any member of Cj and vice-versa.

In addition to the ﬁve invariants mentioned in Deﬁnition A.1, the challenge is to maintain honest ma-
jority in each committee despite churn and a constant fraction of peers being Byzantine. The committees
themselves form connections amongst themselves according to rules of an efﬁcient network such as Chord
[AS04, FSY05], de Bruijn graph [AS09], an expander graph [GHK13] etc. Here, two committees are said to
be connected if each peer of a committee is connected to every other peer in the other committee (and vice
versa). Thus, each committee is connected with a small number of other committees; we say that those
other committees are its “neighbouring” committees.

Although it is difﬁcult to generalize the join protocols in the literature, we identify a few important steps
or invariants that are central to all the existing join protocols (including this work) without getting to the
details of how they are achieved.

Deﬁnition A.2. The JOIN protocol for a network with a quorum topology is said to be churn-resilient if it consists
of the following steps (in the same order).

1. Random ID. Firstly, when a peer p joins the network, it is assigned a random committee Cr.

2. Placement. Peers in Cr and its neighbouring committees are informed about the new peer p after which they

verify that p actually belongs to Cr.

3. Perturbation. After the new peer gets placed in a random committee, the network is “perturbed” where at

most O(polylogN) peers shift to different (typically random) committees.

To get an idea of how each of those steps can be achieved, we delve deeper into the existing solutions.

1. Random ID. Typically, a new peer p is assumed to know the contact address of an existing (honest)
peer q. Peer q belonging to committee Cq informs all the peers in Cq about the new peer p. For struc-
tured routable topologies [AS04, FSY05, AS09], the peers within the committee Cq run a distributed
random number generation (RNG) protocol to determine a random location in the network. (We use
the term “location” because the previous solutions are based on placement of peers in the virtual
(continuous) interval [0, 1).) For the expander topology [GHK13], the authors heavily rely on random
walks over committees. A committee internally runs a distributed RNG protocol to determine the
next walk step (random neighbour) until the walk ends. In our work and in [JPS+18], a peer gets
bound to a random committee via hash function (which can be veriﬁed by any other peer).
Placement. In structured routable topologies [AS04, FSY05, AS09], the peers in Cr are informed about
p by Cq through an efﬁcient route. Then, peers in Cr send their contact information to peer p, and also
inform their neighbouring committees about the membership of peer p. In the expander topology
[GHK13], the path used in the random walk is used to do the same. In our work, the bootstrapping
service directly helps p in contacting the Cr and its neighbouring committees.
Perturbation. Shufﬂing peers between committees is necessary upon join and leaves to maintain hon-
est majority in all the committees against adaptive join-leave attacks [AS04, GHK13]. Typically, this
pertubation of network should be “small”. For e.g., every peer can be assigned a random committee
whenever a new peer joins the network, to maintain honest majority in all committees. But that would
not be efﬁcient at all. There are different ways to achieve small perturbation: adopting limited life-
time for peers [AS04], k-rotation [Sch05, FSY05], cuckoo rule [AS09], and exchange all peers in Cr with
other random peers in the network [GHK13]. In our work, we rely on the limited lifetime method.
The limited lifetime method is indeed a small perturbation per join because the lifetime depends on
churn rate (half-life) of the system. In other words, there is a linear number of joins and leaves in a
half-life period, and therefore, setting a lifetime of a constant number of half-lives, essentially perturbs
the network (forces re-joins) over a “batch” of joins and leaves.

44

The fundamental problem in the existing solutions is that steps in Deﬁnition A.2 heavily depends on
the committees having honest majority. For example, the distributed RNG protocol is secure only if the
committee has an honest majority. Moreover, the (random) placement of a new peer is veriﬁed through
“majority vote” routing, i.e., when a committee receives a join request of a new peer from a majority of
peers in one of its neighbouring committees, it veriﬁes the randomness of the placement assuming such a
majority vote occurred at each committee in the route, until the committee that executed the distributed
RNG protocol. The majority vote veriﬁcation is required for random walks solution too. Thus, honest
majority of committees becomes crucial in proving the security of such join protocols. To this end, we strive
to deﬁne “committee-based” joins that heavily rely on honest majority of committees.

Deﬁnition A.3. A churn-resilient JOIN protocol for a network with quorum topology is said to be committee-based
if it has the following properties.

1. A peer p joins the network by contacting another peer q which in turn informs its committee Cq (introducing
committee). Cq initiates the random ID generation protocol so that p gets placed in a random committee Cr
(placed committee).

2. Honest majority in committees is required for carrying out and verifying the steps of the JOIN protocol (as

mentioned in Deﬁnition A.2).

3. The introducing and placed committees (Cq and Cr) are responsible for initiating and carrying out network

perturbation if it is not done via limited lifetime method.

Our work primarily differs in random ID and placement of the joining peer. The insight is that blockchain
provides a globally known, network-generated and unpredictable input to the hash function. If the input
is globally known, then the hash function output can be veriﬁed by any peer. If the input is unpredictable,
then the adversary cannot launch a pre-computation attack to populate a committee. If the input is gener-
ated by a set of committees (and not by the entire network), then that input can be corrupt if those set of
committees have a malicious majority. Such an input is hard to generate using completely localized algo-
rithms. The hash function is used to map the new peer to a random committee. The new peer is then placed
in that committee by a secure bootstrapping service, constructed using the blockchain. Finally, by making
use of the limited lifetime method to perturb the network, we do not rely on honest majority of committees
for the security of join protocol.

As it is difﬁcult to devise a single attack that works for the family of network and join protocols, we
provide attacks to the existing solutions (primarily exploiting the reliance on honest majority). We want to
show that a small number, say, O(log N) committees that have malicious majority to continually maintain
malicious majority with low cost. Let CM be the committee having malicious majority that needs to get
replenished with more malicious peers.

1. Structured routable topologies [AS04, FSY05, AS09]. The key idea is that the O(log N) malicious
majority committees simply route new malicious peers to CM with a join request. This attack is sufﬁ-
cient to keep adding new malicious peers into CM in [AS04]. In the k-rotation paper [Sch05, FSY05],
the introducing committee selectively picks three locations to add and shift peers. In the cuckoo rule
paper [AS09], the other O(log N) malicious majority committees pick disjoint constant-length arcs in
CM for placing new malicious peers so that the perturbation does not affect the newly added peers.

2. Expander network topology [GHK13]. Malicious committees can have edges amongst themselves to
create join requests via random walks. Committee CM informs its neighbours about a new (malicious)
peer. Instead of actually exchanging all other peers in CM, malicious peers in CM can reserve a small
fraction of the peers for exchanges between legitimate committees and replaces the rest of the peers
with new malicious peers, thereby maintaining a malicious majority. More importantly, as new ma-
licious peers get added to CM, the committee can get split into two committees, each with malicious
majority. (Locally splitting/merging is done to expand/shrink the network as the network size can
vary polynomially over time.)

45

For some speciﬁc attacks, statistical measures such as join rate, message rate, etc., can be used in practice,
to detect and mitigate the effects of committee failures. However, not only are those measures not consistent
over time in open P2P networks but even effectively carrying out such system-wide measurements is a hard
problem. If committees are given the power of rejecting new peers, protesting against other committees,
etc., then malicious majority committees can easily misuse such powers. Thus, recovery from arbitrary
committee failures in networks that heavily rely on honest majority in committees, is difﬁcult to achieve.

B Pseudocodes for Sub-routines

Algorithm 4 VERIFY_PROOFS protocol
Require: Let R be the set of messages of the form (m, e) received in this round, where m is either JOINING
and REQ_INFO and e is the entry information of the node that sent the message. Let H(.) denote the hash
function. Let Blk(i) be a function that returns the block from the conﬁrmed chain with block number i if
it exists, otherise, returns ∅. Let l be the block number of the most recent block in the conﬁrmed chain.

Ensure: Return the subset of R in which each message has a valid proof.

V ← {}.
for each (m, e) ∈ R do

blk_num, Nc, net_addr ← e. // Retrieve entry information.
blk ← Blk(blk_num).
Pjoin ← H(H(blk) (cid:107) net_addr (cid:107) Nc).
c ← Leftmost (cid:100)log Ce(cid:101) bits of Pjoin.
valid_blk ← (l − blk_num) ≤ µs and (blk is not ∅).
if the veriﬁcation is for the directory then

Cn ← Set of IDs of neighbouring committees of committee c.
Crel ← {c} (cid:83) Cn.
C ← Set of all IDs of committees that the directory node is responsible for.

else

Crel ← {c}.
C ← Singleton set of ID of the committee that the node belongs to.

(cid:84) C is not ∅ and valid_blk then

end if
if Pjoin < Tjoin and Crel
V ← V (cid:83){(m, e)}.

end if
end for
Return V.

46

Algorithm 5 STORE_INFO protocol
Require: Set V consisting of all the valid JOINING messages in this round. Let Ci be set of all the tuples of
JOINING message and network address of valid nodes (that this directory node is aware of) in committee
i. Let H(.) denote the hash function. Let Blk(i) be a function that returns the block from the conﬁrmed
chain with block number i if it exists, otherwise, returns ∅.

Ensure: Store entry information of all the nodes that provided a valid proof in this round.

for each (JOINING, e) ∈ V do

blk_num, Nc, net_addr ← e. // Retrieve entry information.
blk ← Blk(blk_num).
Pjoin ← H(H(blk) (cid:107) net_addr (cid:107) Nc).
c ← Leftmost (cid:100)log Ce(cid:101) bits of Pjoin.
Cc ← Cc

(cid:83){e}.

end for

Algorithm 6 REPLY_INFO protocol
Require: Set V consisting of all the valid REQ_INFO messages in this round. Let Ci be set of all the tuples of
REQ_INFO message and network address of valid nodes (that this directory node is aware of) in committee
i.

Ensure: Send committee entry information to nodes that provided a valid proof in this round.

for each (REQ_INFO, c, e) ∈ V do

SEND (COMM_INFO, Cc) to the node with network address net_addr.

end for

47

