1
2
0
2

n
u
J

7
2

]

G
L
.
s
c
[

1
v
5
6
2
4
1
.
6
0
1
2
:
v
i
X
r
a

Reward-Based 1-bit Compressed Federated Distillation on
Blockchain

LEON WITT, Tsinghua University, China and Fraunhofer Heinrich Hertz Institute, Germany
USAMA ZAFAR, Tsinghua University, China
KUOYEH SHEN, Tsinghua University, China
FELIX SATTLER, Fraunhofer Heinrich Hertz Institute, Germany
DAN LI, Tsinghua University, China
WOJCIECH SAMEK, Fraunhofer Heinrich Hertz Institute, Germany

The recent advent of various forms of Federated Knowledge Distillation (FD) paves the way for a new generation
of robust and communication-efficient Federated Learning (FL), where mere soft-labels are aggregated, rather
than whole gradients of Deep Neural Networks (DNN) as done in previous FL schemes. This security-per-
design approach in combination with increasingly performant Internet of Things (IoT) and mobile devices
opens up a new realm of possibilities to utilize private data from industries as well as from individuals as input
for artificial intelligence model training. Yet in previous FL systems, lack of trust due to the imbalance of power
between workers and a central authority, the assumption of altruistic worker participation and the inability to
correctly measure and compare contributions of workers hinder this technology from scaling beyond small
groups of already entrusted entities towards mass adoption. This work aims to mitigate the aforementioned
issues by introducing a novel decentralized federated learning framework where heavily compressed 1-bit
soft-labels, resembling 1-hot label predictions, are aggregated on a smart contract. In a context where workersâ€™
contributions are now easily comparable, we modify the Peer Truth Serum for Crowdsourcing mechanism
(PTSC) for FD to reward honest participation based on peer consistency in an incentive compatible fashion.
Due to heavy reductions of both computational complexity and storage, our framework is a fully on-blockchain
FL system that is feasible on simple smart contracts and therefore blockchain agnostic. We experimentally
test our new framework and validate its theoretical properties.

Additional Key Words and Phrases: Federated Learning, Blockchain, Reward Mechanism, Federated Distillation,
Decentralized Machine Learning

1 INTRODUCTION
The increasing demand for confidential Machine Learning (ML) led to the advent of Federated
Learning (FL), where complex models such as Deep Neural Networks (DNNs) are trained in parallel
on end devices while data remains local at all times. Federated Averaging (FedAvg) [5] is a widely
applied algorithm for FL, where locally trained models ğœƒğ‘– get aggregated on a central location
to form a global model. Even though first use-cases [16, 52, 73] hint at the potential of utilizing
untapped raw data and computational power, communication overhead due to the gradient size of
modern DNNs remains - among other issues [36] - a major bottleneck of FedAvg. Beyond technical
issues, the lack of trust due to the imbalance of authority between workers and the central server as
well as the lack of a practical reward system for contributions of a worker hinder this technology
from scaling beyond small groups of already entrusted entities towards mass adoption. As we will
demonstrate in this paper, these limitations can be overcome.

Blockchain to ensure equal power. General purpose blockchain systems [2, 70, 71] have
the potential to mitigate the first issue by ensuring trust through their inherent properties of

Authorsâ€™ addresses: Leon Witt, Tsinghua University, Beijing, China, Fraunhofer Heinrich Hertz Institute, Berlin, Germany,
leonmaximilianwitt@gmail.com; Usama Zafar, Tsinghua University, Beijing, China, usamazf@outlook.com; KuoYeh Shen,
Tsinghua University, Beijing, China, kuoyehs@gmail.com; Felix Sattler, Fraunhofer Heinrich Hertz Institute, Berlin, Germany,
felix.sattler@hhi.fraunhofer.de; Dan Li, Tsinghua University, Beijing, China, tolidan@tsinghua.edu.cn; Wojciech Samek,
Fraunhofer Heinrich Hertz Institute, Berlin, Germany, wojciech.samek@hhi.fraunhofer.de.

 
 
 
 
 
 
2

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

immutability and transparency of a distributed ledger, thereby enabling decentralized federations
to mitigate dependencies on a central authority [17, 28, 61, 67, 68].

Mechanism Design to incentivize participation. In order to incentivize participation, work-
ers have to be rewarded for their contributions. An appropriately designed mechanism ensures
a desired equilibrium when every worker acts rationally and in its own best interest. Such a
mechanism has low complexity and is self-organizing, avoiding the need for Trusted Execution En-
vironments [7] or cryptographic schemes. In a FL context, this demands a carefully designed reward
strategy based on the quality of contributions. Yet, comparing and evaluating workers gradient-
updates of FedAvg remains challenging [48]. So far, few holistic decentralized gradient-aggregation
based FL system with reward mechanisms have been introduced [4, 40, 61, 68].

Federated Distillation to reduce communication overhead. As it is costly to store large
amounts of data or perform complex computations on Blockchain due to its shared ledger archi-
tecture in which every node has to replicate every computation and all stored information, the
data intensive gradient aggregation process of FedAvg typically can not be embedded in simple
and lightweight Smart Contract Architectures on-chain. The aggregation process therefore either
requires novel application specific blockchain systems (ASBS) [4, 40, 61, 68] or off-chain aggregation
and evaluation [65]. Both paradigms cause drawbacks: ASBS for FL cause huge overhead in terms
of storage and complexity and therefore restrict practicality. Paradigms where the data is being
aggregated off-chain face a potential data availability problem, lack of a decentralized reward
mechanism or a single point of failure. Recently proposed Federated Knowledge Distillation (FD)
frameworks [19, 39, 59] introduce an alternative paradigm to gradient-aggregation schemes like
FedAvg. The FD process aggregates soft-label predictions on a public unlabelled dataset ğ‘‹ ğ‘ğ‘¢ğ‘ with
communication proportional to O (cid:0)|ğ‘‹ ğ‘ğ‘¢ğ‘ | dim C(cid:1) instead of gradients O (|ğœƒ |) in FedAvg, where
|ğ‘‹ ğ‘ğ‘¢ğ‘ | is the size of the public unlabelled dataset and dim C is the dimension of the soft-labels,
e.g. the number of different classes that are predicted. The amount of information necessary to be
exchanged can be orders of magnitude lower in FD compared to FedAvg and recent works of [56]
suggests that the soft-labels of a classification task within the FD process can be further compressed
to 1bits without sacrificing top-1 accuracy, as long as |ğ‘‹ ğ‘ğ‘¢ğ‘ | is sufficiently large. This not only
reduces the default float32 soft-labels by 32-fold, but 1-bit quantized soft-labels resemble a 1-hot
prediction for a specific task, which therefore allows for efficient encoding schemes (e.g. integer
encoding) necessary for blockchain architectures where floating point numbers are not supported
[71]. Most importantly, contributions by workers become deterministic and easily comparable.

This paper introduces a novel reward-based Federated Learning paradigm based on Federated
Knowledge Distillation of 1-bit quantized soft-labels. With the aformentioned reductions of storage
and complexity by orders of magnitude, our framework is able to aggregate and reward participation
within a blockchain agnostic smart contract without the need for ASBS. Capitalizing on the
comparability of contributions, we further introduce a peer consistency based mechanism called Peer
Truth Serum for Federated Distillation (PTSFD), extending the Peer Truth Serum for Crowdsourcing
(PTSC) [50] for FD context. PTSFD ensures a strategy profile in which all workers exert high effort
and report their results truthfully as the most profitable equilibrium, paving the way for potential
mass adoption of confidential and robust FL. We theoretically validate the presence of an incentive
compatible equilibrium and perform a systematic experimental evaluation, demonstrating that (i)
under different FL environments participation in the federation leads to a substantial increase in
local model accuracy for every worker (even if the data is non-iid), (ii) the reward distribution is
positively correlated with exerted effort and (iii) the framework is robust against collusion and
malicious behavior.

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

3

2 BACKGROUND AND RELATED WORK

2.1 Federated Averaging
The classical algorithmic approach to Federated Learning problems is Federated Averaging. In
Federated Averaging the training is conducted in multiple communication rounds following a three
step protocol:

(1) At the beginning of each round, the central server selects a subset of the client population

and broadcasts a common model initialization ğœƒ to them.

(2) Starting from the common initialization, the selected clients individually perform iterations
of stochastic gradient descent over their local data to improve their local models, resulting in
an updated model ğœƒğ‘– on every client.

(3) The updated models are then communicated back to the server, where they are aggregated
(e.g. by an averaging operation) to create a global model, which is used as initialization point
for the next communication round.

Every communication round of Federated Averaging thus involves the upstream and down-
stream communication of a complete parametrization of the jointly trained model ğœƒ between all
participating clients. In many practical applications these neural network parametrizations may
contain multiple millions to billions of individual parameters. For instance, the widely popular
ResNet-5 8 contains over 23 million parameters. For natural language processing tasks even larger
models are used, with the carefullys GPT-3 9 clocking in at .5 billion parameters. Generally, both
theoretical [9, 27] and empirical [18] evidence suggests that the performance of neural network
models correlates positively with their size. Although a wide variety of methods to reduce the
model size in Federated Averaging have been proposed like neural network pruning [33] , and
other lossy [11, 31, 35, 57, 58, 72], and loss-less compression techniques [47, 69], the fundamental
issue of scaling to larger models persists in prohibiting the use of Distributed Ledger Technologies
for storing or aggregating models.

Fig. 1. Federated Learning vs. Decentral 1-bit Compressed Federated Distillation on Blockchain.

2.2 Federated Distillation
Federated Distillation [19, 21, 39] is a recently developed FL algorithm implementing a very different
knowledge exchange strategy. Here, soft-label predictions ğ‘Œ ğ‘ğ‘¢ğ‘
obtained by applying the updated
local model to a public distillation dataset ğ‘‹ ğ‘ğ‘¢ğ‘ are the carrier of information about the local model

ğ‘–

   ServerClient 1Client 2Client ntrainSmart ContractClient 1trainpredictdistillaggregate3.)6.)1.)aggregateClient 2Client nFederated AveragingDecentral 1-bit Compressed Federated Distillation1.)2.)3.)2.)5.)4.)4.)........In FA, clients andserver exchangemodel parameters.FD requires accessto unlabeled publicdata. In FD, clients maytrain different modelarchitectures.........The aggregatedlabels are then usedto further improvethe model4

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

improvement (ğœƒğ‘– â†’ ğœƒğ‘– + Î”ğœƒğ‘– ), i.e.,

ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘–

= {ğ‘“ğœƒğ‘– +Î”ğœƒğ‘– (ğ‘¥) | ğ‘¥ âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘ }.
Since this type of knowledge communication scales with the size of the distillation dataset and
not with the number of model parameters, it can lead to a significant reduction in communication
overhead [56], especially for very large models. Furthermore, Federated Distillation allows clients
with different model architectures to participate in the joint training process.

(1)

Different variants of Federated Distillation have been proposed in the scientific literature. In this
work, we will modify a recently proposed, highly communication-efficient FD method [56], termed
Compressed Federated Distillation (CFD), which is based on the multi-round protocol developed
in [19, 21]. In our modified version of CFD, every client performs the following steps in each
communication round:

(1) Train on local datasets and improve model ğœƒğ‘– = ğœƒ + Î”ğœƒğ‘– by using ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£
(2) Predict labels ğ‘Œ 1ğ‘ğ‘–ğ‘¡

by using the improved model ğœƒğ‘– on ğ‘‹ ğ‘ğ‘¢ğ‘ to compute soft-labels ğ‘Œ ğ‘ğ‘¢ğ‘

ğ‘–
and perform 1bit quantization ğ‘Œ 1ğ‘ğ‘–ğ‘¡

= ğ‘„1ğ‘ğ‘–ğ‘¡ (ğ‘Œ ğ‘ğ‘¢ğ‘
(3) Upload the integer encoded compressed soft-labels to the smart contract (in a two step

, ğ‘Œ ğ‘ğ‘Ÿğ‘–ğ‘£
ğ‘–

).

.

ğ‘–

ğ‘–

ğ‘–

ğ‘–

commit-reveal fashion outlined in Algorithm 2).

ğ‘ğ‘”ğ‘”ğ‘Ÿ by majority vote over all ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ from the blockchain.

(4) (Blockchain) Aggregate predictions ğ‘Œ ğ‘ğ‘¢ğ‘
(5) Download the aggregated predictions ğ‘Œ ğ‘ğ‘¢ğ‘
(6) Distill the current model ğœƒ by using ğ‘‹ ğ‘ğ‘¢ğ‘ and ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ .
The authors of [56] showed that CFD largely reduces the information necessary for exchange by
quantization ğ‘„ and the use of small public distillation dataset (e.g., random subset selection). The
savings are in the order of two orders of magnitude when compared to Federated Distillation, and
more than four orders of magnitude when compared to parameter averaging based techniques like
Federated Averaging. The possibility to apply binary soft-label quantization, i.e., ğ‘„ğ‘ with ğ‘ = 1,
ensure three important properties for a decentralized CFD on Blockchain, namely

.

ğ‘–

â€¢ It reduces the amount of information processed in the aggregation process heavily.
â€¢ It makes contributions by workers explicit and comparable.
â€¢ It supersedes the need for additional encryption like noise inducing Differential Privacy or

computational heavy secure multiparty computation.

2.3 Blockchain Technology in FL context
Blockchain was initially introduced with Bitcoin by Satoshi Nakamoto in 2008 [46]. Blockchain is
referred to as a distributed ledger managed by nodes in a peer to peer network, where cryptographic
links of information ensure resistance to modification and immutability. The network is governed
by a consensus mechanism [62] among peers which supersedes the need for central coordination.
The advent of general purpose blockchains [71] with smart contract functionality supporting
Turing-completeness allow for a decentralized, immutable and transparent business logic atop
of blockchain. This technology is able to mitigate open problems of FL environments due to its
inherent properties, namely:

(1) Decentralization. In server-worker architectures, workers are exposed to a power imbalance
and single point of failure. A malicious server could (i) exclude workers arbitrarily or (ii)
withhold reward payments. Furthermore, a server-worker design is not suitable for an
environment where multiple entities share a common and equal interest in advancing their
respective models. The decentral property of blockchain systems ensures a federal systems
for entities with equal power without the need for a central server.

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

5

(2) Transparency and Immutability. Since every peer in the system shares the same data,
data on blockchain can only be updated and never deleted. A transparent and immutable
reward logic in an FL context ensures trust on the worker side. On the other hand, each
worker is audited and can therefore be held accountable for malicious behavior.

(3) Cryptocurrency. Many general-purpose blockchain systems come with cryptocurrency
functionality, e.g. the option to implement payment schemes within the business logic of the
smart contract. Based on a reward mechanism of the FL system, workers can be rewarded
immediately, automatically and deterministically.

To analyze Blockchain systems, we categorize into Application Specific Blockchain Systems (ASBS)
and General Purpose Blockchain Systems (GPBS). Both systems can be either permissioned or public.
Blockchains which have to be adopted to a specific use-case require a novel infrastructure which
causes overhead in terms of complexity at the development, deployment and operations level of such
a system. GPBS are limited due to restricted virtual machines and predefined consensus layers but
allow for easy development, deployment and operation utilizing already existing frameworks, e.g.,
[2, 6, 20, 25, 70]. Due to large gradient sizes, complex comparability measures of contributions as well
as cryptographic methods to ensure confidentiality of FedAvg, holistic blockchain based decentral
FL systems require ASBS [4, 61, 68]. On the contrary, our decentral FL system is based on 1bit
compressed FD instead of FedAvg, which reduces storage and computational complexity by orders
of magnitude in comparison, makes contributions easily comparable and mitigates vulnerability to
model inversion attacks and therefore may supersede the need for additional cryptography. These
properties allow our holistic, completely on-blockchain framework to be blockchain agnostic and
reside atop of even heavily restricted GBPS like Ethereum [71]. Even though theoretically possible,
many promising public blockchain projects are still in their technological infancy, e.g. either are
yet to implement smart contract functionality (e.g. Cardano [26], IOTA [60]) or face scalablility
restrictions (e.g. Ethereum), which makes it economically infeasible and causing scalability issues
to deploy our system atop of public blockchains as of now, for the high cost of transaction fee and
the limitation of transaction per second. Technical advancements on Ethereum like sharding1 or
layer 2 solutions for off-chain computation like optimistic rollups2 and zero-knowledge rollups3
may change that in the short-term future.

2.4 Related Work
Our proposed FL framework combines a (i) Reward Mechanism and (ii) Decentralization. The task
to classify ğ‘‹ ğ‘ğ‘¢ğ‘ resembles a (iii) Crowdsourcing Contest.

Crowdsourcing Contests. A crowdsourcing contest describes a game-theoretic framework
where workers invest irreversible and costly efforts towards winning a reward from the requester,
which is allocated based on relative performance [45]. In a crowdsourcing environment, workers
are recruited anonymously through the Internet, so a major issue is how to ensure that their
answers are accurate. Recent works on Peer Prediction [1, 50, 63] have been studied to elicit truthful
information from agents without any objective ground truth against which to score reports. In
addition, many works have analyzed the optimal strategies between maximizing requesters utility
and workers profit [3, 8, 15, 43, 44, 54]. The authors of [3] showed that in an all-pay contest
with heterogeneous risk-averse workers, multiple prizes should be rewarded to maximize the
requesters utility. In contrast [43] and [54] demonstrated that in an asymmetric all-pay auction-
based contest of heterogeneous workers, requesters can maximize the contribution by rewarding

1Ethereum Sharding endevours https://ethereum.org/en/eth2/shard-chains/
2https://docs.ethhub.io/ethereum-roadmap/layer-2-scaling/optimistic_rollups/
3https://docs.ethhub.io/ethereum-roadmap/layer-2-scaling/zk-rollups/

6

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

only the top workers [43]. However, a winner-takes-all reward distribution may discourage risk-
averse workers.[44] mitigated this problem by introducing a lottery mechanism to give every player
a strictly positive chance of winning as long as they participate. [15] analyzed equilibrium and
optimal reward distribution for online Q&A forums and competition platforms. [8] proposed an
optimal reward policy (base salary + bonus) to optimize requesters profit where workers are selected
based on workload demands and past performances. [64] proposed an optimal price setting for
crowdsourcing by minimizing regret, varified on a Human Intelligent Task on Amazon Mechanical
turk. [53] conducted large-scale real experiments to investigate how competitive and lottery reward
policies affect the cost and time efficiency of crowdsourcing. [34] conducted a series of experiments
using contests to understand the effect of the workersâ€™ strategy and determine whether they should
participate in contests.

Applied Mechanism Designs in Federated Learning. Other works investigated different
mechanism designs in FL context to incentivize participation, namely correlated agreement [41],
contract theory [13, 23, 24], stackelberg games [49], multidimensional auction games [32, 75] and
Vickrey-Clarke-Groves design [29]. [76, 77] used deep reinforcement learning (DLR) mechanism to
find the optimal pricing strategy for the central server in context of information asymmetry. [74]
invented a novel FL incentive mechanism addressing the problem of temporary delay between
contributions of workers and future rewards of an increased model, ensuring long-term fairness of
distributing profit over time with multiple contributions. However, all of the aforementioned works
assume a trustworthy central server/aggregator and do not allow for a decentralized architecture
with equal power among peers.

Decentralized Federated Learning. Several works investigated Blockchain in FL as a tool
to mitigate central coordination [28, 38, 67, 68] while improving security and robustness [17, 38,
68].[67] introduced a decentral and confidential machine learning framework (swarm learning) on
blockchain, showcasing that collaboration leads to better results on confidential medical data. [42]
introduced an incentivized crowdsourcing protocol atop public blockchains for machine learning
tasks, where a purchaser can buy NN parameters of a trained model from workers. A mechanism
design prevents workers from acting maliciously by being evaluated against coworkers. The imple-
mentation design and the theoretical analysis of the proposed MD lack detail. [65] introduced a
blockchain enabled FL framework incentivizing workers while utilizing contest theory to determine
the optimal reward distribution. Applying FedAvg, every worker has to peer review models of
every other worker in order to send his vote of the best workers to the smart contract, causing
overhead on the workersâ€™ side while preventing the model from scaling. [68] invented a novel
blockchain system for Federated Learning, providing data confidentiality and auditability. During
the FedAvg training process, all gradients are encrypted and stored on the permissioned blockchain,
causing computational and storage overhead. How contributions are evaluated for the reward
mechanism is not explicitly specified. [23] introduce a novel mechanism, combining contract theory
and reputation to incentivize high performance workers to participate. The blockchain serves as
auxiliary entity storing the reputation of each worker. [4] introduces a novel decentralized FL
framework (FLChain) to replace the parameter server, where workers get rewarded. How workers
contributions are evaluated is not specified. [40] invented a new blockchain consensus system,
where FedAvg participation is rewarded based on the Shapley Value (marginal contribution) by
miners. [61] proposed a blockchain-based privacy preserving ML platform, where model updates
are stored on the blockchain, applying Shamir secrets for a secure gradient aggregation and differ-
ential privacy on the gradients. Table 1 outlines the differences regarding the Federated Learning
algorithm, the applied MD/incentive mechanism, the type of blockchain, whether the framework
allows for different NN architectures on the client side, whether the framework induces a single

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

7

Table 1. Blockchain based Federated Learning Systems with Incentives.

FL

Reward Mechanism

Blockchain

NN agnostic

SPF

Scalability

[67]
[42]
[65]
[68]
[23]
[4]
[40]
[61]
[28]
this work

ASBS
agnostic
agnostic
ASBS

N/A
peer review
contest theory
value based/no MD

FedAvg
N/A
FedAvg
FedAvg
FedAvg contract theory/reputation (BC not for FL)
FedAvg
FedAvg
FedAvg
FedAvg
FD

no MD
Shapley value
N/A
N/A
PTSC

ASBS
ASBS
ASBS
ASBS
agnostic

no
N/A
no
no
no
no
no
no
no
yes

no
yes
no
no
yes
no
no
no
no
no

limited
N/A
limited
limited
limited
limited
limited
limited
limited
good

point of failure (SPF) and whether the additional Blockchain system causes overhead.

3 PROBLEM STATEMENT AND REWARD MECHANISM

3.1 Problem Statement
We assume a federation F of workers W who have a common interest in advancing their private
Neural Networks based on (i) additional data of other participants and (ii) the unlabelled public
dataset ğ‘‹ ğ‘ğ‘¢ğ‘ through Federated Distillation (FD). We consider an environment where all participants
of F have equal power, e.g. no central entity such as a central server should have the power to
either censor or manipulate the reward distribution. Each worker participating in the training is
responsible for submitting predictions on public dataset ğ‘‹ ğ‘ğ‘¢ğ‘ based on locally trained model, and
label distribution ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– of the predictions. To enable decentralization, a smart contract atop
of a blockchain will replace the central server (i) to aggregate the workerâ€™s predictions and (ii) to
calculate the rewards considering other contributions. To ensure accountability and to prevent
free-riding, each worker has to stake a deposit ğ·ğ‘– . D = (cid:205)ğ‘– âˆˆ F ğ·ğ‘– will be used to pay Â¯ğœğ‘– for each
contribution at the end of the training process. Note that Â¯ğœğ‘– â‰¥ ğ·ğ‘– in case worker ğ‘–â€™s contributions are
above average to F and Â¯ğœğ‘– â‰¤ ğ·ğ‘– otherwise. Malicious behavior like (i) withholding after committing,
(ii) committing a wrong label distribution ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– will result in slash of deposit and exclusion
from F . The worker selection process is beyond the scope of this work, reputation [23, 66] or
required registrations may be feasible solutions.

3.2 Reward Mechanism Motivation
As no entity is in possession of the true labels of ğ‘‹ ğ‘ğ‘¢ğ‘ in the decentralized Federated Learning
setting, workersâ€™ evaluations cannot be verified. This might encourage workers to report random
data without actually classifying ğ‘‹ ğ‘ğ‘¢ğ‘. This can be mitigated by rewarding peer consistency, e.g.
the reward depends on its consistency with the label given by other workers. However, the best
strategy in such schemes is for all workers to report the same answer without investing effort in
finding the real label. The solution to these issues is to set up a mechanism, where the expected
profit for each individual worker is maximized, if they put high effort into solving the task while
acting truthful.

In contrast to a server-worker relationship, our framework assumes multiple stakeholders with
common interest in improving their respective model. The initially staked deposit ğ· which will be

8

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

Table 2. Notation Table

Definition

Governing smart contract deployed blockchain
Set of classes of the public dataset ğ‘‹ ğ‘ğ‘¢ğ‘
Set of registered workers who register and deposit to the smart contract S
Subset of workers contributing in training the model.W â€² âŠ† W
Federation of all possible workers
Reward staked by worker ğ‘–
Total deposit by all workers on the smart contract D = (cid:205)ğ‘– Dğ‘–
Reward paid to worker ğ‘–
Total reward paid out: V = (cid:205)ğ‘– ğ‘‰ğ‘–
Size of the public dataset ğ‘š = |ğ‘‹ ğ‘ğ‘¢ğ‘ |
Number of workers contributing to the training process. ğ‘› = |W â€²|
Number of peer workers who classify the same sample ğ‘—
Class prediction of worker ğ‘– on sample ğ‘—, ğ‘¥ âˆˆ C

Vector of occurences of each class in ğ‘Œ 1ğ‘ğ‘–ğ‘¡
Discrete density function of class ğ‘¥ âˆˆ C in ğ‘‹ ğ‘ğ‘¢ğ‘, ğ‘…(ğ‘¥) = labelCount(ğ‘¥)
(cid:205)ğ‘¦ labelCount(ğ‘¦)

of worker ğ‘–

ğ‘–

, âˆ€ğ‘¦ âˆˆ C

R(x) without worker ğ‘–â€™s contribution
Worker ğ‘– âˆˆ W
Sample ğ‘— of the public dataset ğ‘‹ ğ‘ğ‘¢ğ‘
Parameter of the Dirichlet distribution to control data distribution
Penalty term of the reward function
Reward scaling parameter. We set ğœ† = 1 across all experiments
Reward for worker ğ‘– for the classification of sample ğ‘—
Total reward for worker ğ‘–
Heuristic to approximate certainty of the evaluated label ğ‘—
Exerted effort by worker ğ‘–
Variable cost incurred by exerting effort to classify ğ‘‹ ğ‘ğ‘¢ğ‘
Implicit cost for having access to ğ‘Œ ğ‘ğ‘¢ğ‘
Public dataset
Private dataset of worker ğ‘–

ğ‘ğ‘”ğ‘”ğ‘Ÿ

Soft (float) predictions of worker ğ‘– on ğ‘‹ ğ‘ğ‘¢ğ‘. ğ‘Œ ğ‘ğ‘¢ğ‘
Labels of the private dataset of worker ğ‘–

ğ‘–

= Rğ‘›Ã—| C |
+

Integer encoded 1 bit quantized predictions of worker ğ‘– on ğ‘‹ ğ‘ğ‘¢ğ‘. ğ‘Œ 1ğ‘ğ‘–ğ‘¡
Aggregated 1-bit labels on smart contract S by majority vote. ğ‘Œ ğ‘ğ‘¢ğ‘

= Cğ‘›
ğ‘–
ğ‘ğ‘”ğ‘”ğ‘Ÿ = Cğ‘›

256bit SHA-3 Hash Function
A random number

Symbol

S
C
W
W â€²
F
ğ·ğ‘–
D
ğ‘‰ğ‘–
V
ğ‘š
ğ‘›
ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘ 
ğ‘—
ğ‘¥ğ‘– ğ‘—
ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–
ğ‘…(ğ‘¥)
ğ‘…ğ‘– (ğ‘¥)
ğ‘–
ğ‘—
ğ›¼
ğ›½
ğœ†
ğœğ‘– ğ‘—
Â¯ğœğ‘–
Ağ‘– ğ‘—
ğ‘’ğ‘–
ğ‘ğ‘– (ğ‘’ğ‘– )
ğ‘ ğ‘“ ğ‘–ğ‘¥
S
ğ‘‹ ğ‘ğ‘¢ğ‘
ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£
ğ‘–
ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘–
ğ‘Œ ğ‘ğ‘Ÿğ‘–ğ‘£
ğ‘–
ğ‘Œ 1ğ‘ğ‘–ğ‘¡
ğ‘–
ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ

H (Â·)
ğ‘ ğ‘ğ‘™ğ‘¡ğ‘–

used to pay ğœ manifests this mutual interest. Yet, contributions may be of different quality to the
overall federation. Low quality workers may even have a negative effect on the overall federation
even if their intention is truthful. At the same time, some classes in ğ‘‹ ğ‘ğ‘¢ğ‘ may be less common and
therefore are more important to classify correctly. Hence, a mechanism is required to:

(1) incentivize only workers with the best abilities for the task

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

9

(2) incentivize these workers to invest their utmost effort in obtaining the most accurate answer
(3) incentivize workers who are able to classify uncommon samples in ğ‘‹ ğ‘ğ‘¢ğ‘ with higher rewards
We introduce the Peer Truth Serum for Federated Distillation (PTSFD), adopting Peer Truth
Serum for Crowdsourcing (PTSC) [50] for the Federated Distillation environment. PTSC combines
the reward mechanism of [12] with the idea of Peer Truth Serum [14, 22] to ensure incentive
compatibility over a non binary solution space for heterogeneous workers. Because payment is a
secondary motivation for workers, PTSFD introduces a penalty term ğ›½. Workers get rewarded for
each sample according to

ğœğ‘– ğ‘— (cid:0)ğ‘¥ğ‘– ğ‘— (cid:1) = ğœ† Â·

(cid:32)

1
ğ‘›peers

âˆ‘ï¸

ğ‘

(cid:33)

ğœ0

(cid:0)ğ‘¥ğ‘– ğ‘—, ğ‘¥ğ‘ ğ‘— (cid:1) âˆ’ ğ›½

(2)

where ğœ† is a scaling parameter to adjust the magnitude of payment, ğ›½ scales the reward-accuracy
ratio and total reward Â¯ğœğ‘– = (cid:205)ğ‘— âˆˆğ‘‹ ğ‘ğ‘¢ğ‘ ğœğ‘– ğ‘— and

ğœ0

(cid:0)ğ‘¥ğ‘– ğ‘—, ğ‘¥ğ‘ ğ‘— (cid:1) =

(cid:40)

1
ğ‘…ğ‘– (ğ‘¥ğ‘– ğ‘— )
0

if ğ‘¥ğ‘– ğ‘— = ğ‘¥ğ‘ ğ‘—
if ğ‘¥ğ‘– ğ‘— â‰  ğ‘¥ğ‘ ğ‘—

(3)

ğ‘…ğ‘– (ğ‘¥) : C â†¦â†’ [0, 1], (cid:205)ğ‘¥ âˆˆ C ğ‘…ğ‘– (ğ‘¥) = 1 represents the discrete density function, excluding worker

ğ‘–â€™s contribution, where ğ‘…ğ‘– (ğ‘¥) denotes the fraction of reported labels ğ‘…ğ‘– (ğ‘¥) =

labelCount(ğ‘¥)
(cid:205)ğ‘¦âˆˆC labelCount(ğ‘¦) .

3.3 Gametheoretic Analysis
Task. We consider a crowdsourcing scenario in which a group of workers solves n statistically
independent tasks, where a task refers to classifying every sample ğ‘— for all ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘. The setting
can be considered a two staged game. In stage 1, workers choose the amount of effort ğ‘’ they want
to invest in classifying ğ‘‹ ğ‘ğ‘¢ğ‘, e.g. the complexity of the NN, the amount of data, the number of
training rounds, etc. In stage 2, workers decide on what to report. To simplify the analysis, we
assume two levels of effort high ğ‘’1 and low ğ‘’0, where ğ‘’1 is the best work possible exerted by an
honest worker and ğ‘’0 can intuitively be seen as a random answer without any effort put into it.
The baseline model assumes each worker solves every task. Without loss of generality, workers can
be randomly allocated to solve tasks s.t. each sample of ğ‘‹ ğ‘ğ‘¢ğ‘ is classified by at least two different
workers.

Workers. We assume workers to be individually rational, aiming to maximize expected profit

Î ğ‘– = ğ‘…ğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘ ğ‘– âˆ’ ğ¶ğ‘œğ‘ ğ‘¡ğ‘ ğ‘– :

max E (Î ğ‘– ) = ğ‘ˆğ‘– (ğœƒ ğ‘–ğ‘šğ‘ğ‘Ÿğ‘œğ‘£ğ‘’ğ‘‘

ğ‘–

) + ğ‘ˆğ‘–

(cid:16)
Â¯ğœğ‘– âˆ’ [ğ‘ğ‘– (ğ‘’ğ‘– ) + ğ‘ ğ‘“ ğ‘–ğ‘¥
S ]

(cid:17)

(4)

ğ‘–

ğ‘ˆğ‘– represents the expected utility function of worker ğ‘–, which can be different for every worker.
The expected rewards of contributing to the federation F are twofold: (i) the expected utility of
the own improved model ğœƒ ğ‘–ğ‘šğ‘ğ‘Ÿğ‘œğ‘£ğ‘’ğ‘‘
and (ii) the utility of the expected monetary reward from S
for contributing to classify ğ‘‹ ğ‘ğ‘¢ğ‘. The training process causes variable costs ğ‘ğ‘– (ğ‘’ğ‘– ), where ğ‘ğ‘– is an
increasing function of effort ğ‘’ğ‘– , that is ğ‘ğ‘– (ğ‘’ğ‘–,1) > ğ‘ğ‘– (ğ‘’ğ‘–,0), where ğ‘’ğ‘–,0 denotes no effort and ğ‘’ğ‘–,1 denotes
high effort of worker ğ‘–. Without loss of generality, effort represents the quality and quantity of
private data, the quality of the model, number of training iterations, etc. In addition to the variable
costs of actively contributing to the federation, fixed participation costs ğ‘ ğ‘“ ğ‘–ğ‘¥
S are required to offset
free-riding of inactive but registered workers of S who reap the benefit of an improved model
ğ‘ˆğ‘– (ğœƒ ğ‘–ğ‘šğ‘ğ‘Ÿğ‘œğ‘£ğ‘’ğ‘‘
) without contributing to the benefit of F . Note that the initially staked Deposit will
ğ‘–

10

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

be used to pay for contributing workers, therefore ğ‘ ğ‘“ ğ‘–ğ‘¥
costs for having access to ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ .

S = ğ·ğ‘ğ‘’ ğ‘“ ğ‘œğ‘Ÿğ‘’

ğ‘–

âˆ’ ğ·ğ‘ğ‘“ ğ‘¡ğ‘’ğ‘Ÿ
ğ‘–

describes the implicit

Incentive Compatibility. In order to evaluate PTSFD in game theoretic terms, we analyze each
workers expected profit Î ğ‘– = ğ‘…ğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘ ğ‘– âˆ’ğ¶ğ‘œğ‘ ğ‘¡ğ‘ ğ‘– . We assume individual rationality (IR), e.g. workers
try to maximize their expected profit and do not participate if Î  â‰¤ 0. For the sake of simplicity, we
further assume that the gain in model improvement ğ‘ˆğ‘– (ğœƒ ğ‘–ğ‘šğ‘ğ‘Ÿğ‘œğ‘£ğ‘’ğ‘‘
) is offset by ğ‘ˆğ‘– (ğ‘ ğ‘“ ğ‘–ğ‘¥
C ). When a
worker classifies a sample, it obtains an evaluation ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
which can be different from the reported
value ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡

. In stage two, workers face three different strategies âˆ€ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘ [50]:
and report honestly, s.t. ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡
but reports ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡

(1) Honest Invest high effort ğ‘’1 to obtain ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
(2) Strategic Invest high effort ğ‘’1 to obtain ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
(3) Heuristic Do not invest any effort ğ‘’0 and randomly report ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡

ğ‘—
â‰  ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘—

based on the a-priori

= ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘—

ğ‘–

ğ‘—

ğ‘—

ğ‘—

ğ‘—

ğ‘—

ğ‘—

known distribution of labels in ğ‘‹ ğ‘ğ‘¢ğ‘

We define the mechanism to be incentive compatible, if the honest strategy is the dominant
strategy for every worker. We use an equilibrium analysis to determine the resulting behavior of
each worker. In particularly, ğœ = (ğœ1, ğœ2, . . . , ğœğ‘›) represents a strategy profile of each worker. This
profile is an equilibrium Â¯ğœ if for any worker ğ‘– âˆˆ W, the workers expected profit is maximized
with the honest strategy profile Â¯ğœ. Suppose that worker ğ‘– believes that the peer workers are honest
and their answer on a given sample ğ‘— is positively correlated with the worker ğ‘–â€™s answer x, when
obtained with high effort ğ‘’1. Specifically, worker ğ‘– believes that answer x is not less likely for sample
ğ‘— than in the distribution over all tasks.

Honest Strategy. For every sample ğ‘— in ğ‘‹ ğ‘ğ‘¢ğ‘, the worker calculates the probability scores over
all possible classes in C (output of the softmax layer of a NN). Let us further assume worker ğ‘– is
in possession of a trained model ğœƒğ‘– , with an overall accuracy ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğœƒğ‘– . We define the relative
certainty Ağ‘– ğ‘— of any prediction of client i on an element ğ‘— of ğ‘‹ ğ‘ğ‘¢ğ‘ as the product of the local
classifier accuracy and the sample-specific maxprobabilityscore.

Ağ‘– ğ‘— = ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğœƒğ‘– Â· ğ‘€ğ‘ğ‘¥ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ‘– ğ‘—

(5)

Under the assumption that the local client data ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£

is representative of the entire data dis-
tribution D, this metric will give a heuristic measure for the data specific certainty in the model
prediction. Based on this metric, each worker will make the decision whether to report predicted
labels, discarding those for which reward is expected to be negative. This leads to the expected
profit

ğ‘–

E(Î ğ‘– ğ‘— ) = Ağ‘– ğ‘— Â· ğœ†

+ (1 âˆ’ Ağ‘– ğ‘— ) Â· ğœ†(âˆ’ğ›½) âˆ’ ğ‘ğ‘– (ğ‘’ğ‘– )

(6)

(cid:18)

(cid:19)

1
ğ‘…(ğ‘¥ğ‘– ğ‘— )

âˆ’ ğ›½

Assuming individual rationality, E(Î ğ‘–,ğ‘— ) â‰¥ 0 in order to incentive worker ğ‘– to submit a vote on

sample ğ‘—. Following 6, we can derive minimum prediction quality

Ağ‘– ğ‘— â‰¥ ğ‘…(ğ‘¥ğ‘– ğ‘— ) Â·

(cid:18)ğ‘ğ‘– (ğ‘’ğ‘– )
ğœ†

(cid:19)

+ ğ›½

(7)

required to incentivize worker ğ‘– to participate, e.g. Î ğ‘– â‰¥ 0. Notice that the federation can set the
overall quality threshold by adjusting hyperparameter ğœ† and ğ›½ appropriately, assuming similar
variable costs ğ‘ (ğ‘’) on the workers side.

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

11

Heuristic Strategy. The heuristic strategy assumes worker ğ‘– does not put in any effort to
obtain ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
= ğ‘¥ âˆˆ C. The expected reward depends on the probability of matching the peerâ€™s
answer, where the answer x is independent of the task. Thus, the probability of matching a peer
coincidentally is equal to the frequency of an answer ğ‘¥ âˆˆ C.

ğ‘—

E(Î ğ‘– ğ‘— ) = ğ‘…(ğ‘¥ğ‘– ğ‘— ) Â·

(cid:18)

1
ğ‘…(ğ‘¥ğ‘– ğ‘— )

(cid:19)

âˆ’ ğ›½

+ (1 âˆ’ ğ‘…(ğ‘¥ğ‘– ğ‘— )) Â· (âˆ’ğ›½) = 1 âˆ’ ğ›½

(8)

Note that the expected profit for ğ›½ = 1 is 0 and strictly negative for ğ›½ > 1, independent from what
the answer x is, or what the worker knows about the distribution ğ‘…(ğ‘¥) for each label over ğ‘‹ ğ‘ğ‘¢ğ‘.
Since the noise added to classifying ğ‘‹ ğ‘ğ‘¢ğ‘ will lower overall model quality, following Equation 6,
we can expect that a rational worker will not elect to participate in case ğ›½ â‰¥ 1.

Strategic Strategy. Under the assumption of honest participation of other workers, exerting

ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘—

while reporting ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡

ğ‘—

â‰  ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘—

will result in a negative expected profit âˆ€ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘

E(Î ğ‘– ğ‘— ) = ğœ† Â· (âˆ’ğ›½) âˆ’ ğ‘ğ‘– (ğ‘’ğ‘– )

as long as the self-predicting condition [50] holds, e.g.

ğ´ğ‘– ğ‘— (ğ‘¥ |ğ‘¥)
ğ‘…(ğ‘¥)

>

ğ´ğ‘– ğ‘— ( Â¯ğ‘¥ |ğ‘¥)
ğ‘…( Â¯ğ‘¥)

, âˆ€Â¯ğ‘¥ â‰  ğ‘¥

Let us consider the case when workers collude, that is, they report x when ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
= ğ‘¦. However, R will change accordingly, that is ğ‘…ğ‘ğ‘œğ‘™ (ğ‘¥) = ğ‘…(ğ‘¥) + ğ‘…(ğ‘¦)

ğ‘—

ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘—

(9)

(10)

= ğ‘¥ and when

E(Î ğ‘– ğ‘— ) =

(cid:16)

(cid:16)

Ağ‘– ğ‘— Â· ğœ†

Ağ‘– ğ‘— Â· ğœ†

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

1

ğ‘…ğ‘– (ğ‘¥ğ‘– ğ‘— )+ğ‘…ğ‘– (ğ‘¦ğ‘– ğ‘— ) âˆ’ ğ›½
ğ‘…ğ‘– (ğ‘¥ğ‘– ğ‘— )+ğ‘…ğ‘– (ğ‘¦ğ‘– ğ‘— ) âˆ’ ğ›½

1

(cid:17)

(cid:17)

+ (1 âˆ’ Ağ‘– ğ‘— ) Â· ğœ†(âˆ’ğ›½) âˆ’ ğ‘ğ‘– (ğ‘’ğ‘– )
+ (1 âˆ’ Ağ‘– ğ‘— ) Â· ğœ†(âˆ’ğ›½) âˆ’ ğ‘ğ‘– (ğ‘’ğ‘– )

if ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘– ğ‘—
if ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘– ğ‘—

= ğ‘¥ğ‘– ğ‘—

= ğ‘¦ğ‘– ğ‘—

(11)

and exactly offset the gain in matching probability. Therefore, only honest strategy with a high
quality model will lead to a positive expected reward for the respective worker. This leads to an
equilibrium Â¯ğœâ„ğ‘œğ‘›ğ‘’ğ‘ ğ‘¡ of the PTSFD mechanism, which proves incentive compatibility.

4 1-BIT COMPRESSED FEDERATED DISTILLATION FRAMEWORK WITH SMART

CONTRACT LOGIC

The protocol contains the following steps: (i) Task Specification & Contract Deployment, (ii)
Worker Registration & Deposit, (iii) Local Model Training, (iv) Hash Commit Submission, (v) Reveal
Predictions, (vi) Aggregation & Reward Distribution, and (vii) Knowledge Distillation from ğ‘‹ ğ‘ğ‘¢ğ‘.

12

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

Fig. 2. Iterative Process of on-blockchain Federated Distillation.

4.1 Task Specification & Smart Contract Deployment
In order to form Federation F , participants with similar interests need to agree upon the require-
ments and specifics of a FD task, namely:

(1) Task description and data distribution (e.g. images of a certain type).
(2) Reference to a public data set ğ‘‹ ğ‘ğ‘¢ğ‘ and possible classes C for the Federated Distillation
pipeline, which will later be used by the workers to predict the labels on each sample of the
dataset.

(3) Reference to the address of S.
(4) Deposit amount ğ·ğ‘– which has to be staked by every worker.
(5) PTSFD and reward mechanism details (ğœ† and ğ›½ values).

Once a federation F is formed, either an external third party or any of the workers of F deploys
the governing smart contract S and stakes the required deposit ğ·ğ‘– , the addresses of all viable
workers âˆˆ F as well as the aggregation and PTSFD logic of the FD task.

4.2 Worker Registration & Deposit Submission
Based on the task specifications, interested workers register on the smart contract S with their
respective blockchain address (public key) and match the required deposit ğ·ğ‘– . S checks whether
the applying worker is part of the federation. Assuming |F | >> |W|, PTSFD encourages workers
of high value for F in terms of data and computational capacity to participate while discouraging
low quality workers as we will show in Section 4.5. To prevent free-riding from workers in F who
are not registered to participate should not have access to S. This can be achieved by deploying S
on an appropriate blockchain system or through shuffling of ğ‘‹ ğ‘ğ‘¢ğ‘ s.t. only participating clients
have access to the correct indices.

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

13

ğ‘–

, ğ‘Œ ğ‘ğ‘Ÿğ‘–ğ‘£
ğ‘–

ğ‘ğ‘”ğ‘”ğ‘Ÿ as the last step of the protocol, as outlined

4.3 Local Model Training and Prediction
The total training process contains two phases, local model training phase on local data ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£
and the Knowledge Distillation phase from ğ‘‹ ğ‘ğ‘¢ğ‘, ğ‘Œ ğ‘ğ‘¢ğ‘
in Section 2.2.
Training on Local Data. Each worker is either in possession of a pre-trained model or starts
training a NN locally on their respective private data until convergence (optional: until an initially
agreed minimum accuracy among F ). Note that in contrast to FedAvg, FD does not require the same
shared NN architecture among all workers, which allows workers to choose an optimal architecture
with respect to their computational resources.
Label Prediction. After the the training process, workers will then calculate the soft labels
ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘–
Label Count. Because the PTSFD mechanism requires information about the label distribu-
tion ğ‘…(ğ‘¥) over ğ‘‹ ğ‘ğ‘¢ğ‘ to calculate rewards, each worker ğ‘– is required to calculate the label count
ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– âˆˆ N | C | of each label found in ğ‘‹ ğ‘ğ‘¢ğ‘, to mitigate computational overhead on blockchain
(outlined in Algorithm 1). The additional validation function to check the correct calculation of
ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– depends on the underlying blockchain system and is beyond the scope of this work.

= {ğ‘“ğœƒğ‘– +Î”ğœƒğ‘– (ğ‘¥) | ğ‘¥ âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘ } and then quantize these to 1bit ğ‘Œ 1ğ‘ğ‘–ğ‘¡

= ğ‘„1ğ‘ğ‘–ğ‘¡ (ğ‘Œ ğ‘ğ‘¢ğ‘

).

ğ‘–

ğ‘–

Algorithm 1: Local label count for worker ğ‘–

input : Integer encoded class votes ğ‘¥ğ‘– ğ‘— , where ğ‘– âˆˆ W â€² âŠ† W
output :ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–

1 init ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–
2

var ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– âˆˆ N| C | = (0, 0, . . . , 0)

3 foreach ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘ do
4
5 return ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–

ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– (ğ‘¥ğ‘– ğ‘— ) += 1

// iterate over data samples

4.4 Commit and Reveal
Information on blockchain is transparent to every node. Even in a private blockchain setup, workers
in W could wait for peers to publish ğ‘Œ 1ğ‘ğ‘–ğ‘¡
and copy their results without putting in any effort. To
prevent copying and to force workers to exert effort to classify ğ‘‹ ğ‘ğ‘¢ğ‘, we apply a two-step commit
and reveal scheme.

ğ‘

ğ‘–

(1) Commit. Before publishing the results to S where all peer workers would be able to see the
, ğ‘ ğ‘ğ‘™ğ‘¡ğ‘–, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– (cid:1) is calculated
submission, a cryptographic hash â„ğ‘ğ‘ â„ğ¶ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘– = H (cid:0)ğ‘Œ 1ğ‘ğ‘–ğ‘¡
ğ‘–
to obfuscate ğ‘Œ 1ğ‘ğ‘–ğ‘¡
and ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– . The property of pre-image resistancy of a cryptographic
hash function (e.g. it should be difficult to find any message m such that ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘– = H (ğ‘š))
as well as the property of collision resistance (e.g. it should be difficult to find two different
messages ğ‘š1 and ğ‘š2 such that H (ğ‘š1) = H (ğ‘š2)) ensures that no worker can either recover
ğ‘Œ 1ğ‘ğ‘–ğ‘¡
. Each worker ğ‘– sends â„ğ‘ğ‘ â„ğ¶ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘–
ğ‘–
to S as soon as it finishes training. Note that the commit phase on S ends once |W â€²| âŠ† |W|
workers have registered on S or the maximum time ğ‘‡ ğ‘šğ‘ğ‘¥

nor later change their previously committed ğ‘Œ 1ğ‘ğ‘–ğ‘¡

ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ has elapsed.

ğ‘–

(2) Reveal. The reveal phase on S requires each worker who successfully committed in the
commit-phase to reveal ğ‘Œ 1ğ‘ğ‘–ğ‘¡
ğ‘Ÿğ‘’ğ‘£ğ‘’ğ‘ğ‘™ through a transaction
function call on S. To prevent withholding attacks, a worker deposit ğ·ğ‘– gets slashed if worker

, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– and ğ‘ ğ‘ğ‘™ğ‘¡ğ‘– within time ğ‘‡ ğ‘šğ‘ğ‘¥

ğ‘–

14

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

ğ‘– does not reveal within a sufficiently large time ğ‘‡ ğ‘šğ‘ğ‘¥
the commit is viable, s.t. H (ğ‘Œğ‘–, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–, ğ‘ ğ‘ğ‘™ğ‘¡ğ‘– ) == â„ğ‘ğ‘ â„ğ¶ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘– .

ğ‘Ÿğ‘’ğ‘£ğ‘’ğ‘ğ‘™ . The smart contract checks whether

Algorithm 2 outlines the pseudo code of such a scheme in Solidity on the Ethereum blockchain.

Algorithm 2: Commit and Reveal Protocol
Data: 32byte â„ğ‘ğ‘ â„ğ¶ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘– â† H (cid:0)ğ‘Œ 1ğ‘ğ‘–ğ‘¡

ğ‘–

, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–, ğ‘ ğ‘ğ‘™ğ‘¡ğ‘– (cid:1)

1 Init
2

3

var commitments â† Mapping(ğ‘ğ‘‘ğ‘‘ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘– => byte32) âˆ€ğ‘– âˆˆ W
var userIsCommitted â† Mapping(ğ‘ğ‘‘ğ‘‘ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘– => bool) âˆ€ğ‘– âˆˆ W

4 Phase I commit(hashCommit)
foreach ğ‘– âˆˆ W â€² do
5

6

7

8

9

require(userIsRegistered(msg.sender))
require(!userIsCommited(msg.sender))
ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘šğ‘’ğ‘›ğ‘¡ğ‘ .ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘ (ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘– )
ğ‘–ğ‘ ğ¶ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘‘ (ğ‘šğ‘ ğ‘”.ğ‘ ğ‘’ğ‘›ğ‘‘ğ‘’ğ‘Ÿ ) = ğ‘‡ğ‘Ÿğ‘¢ğ‘’

// registered in W

10 Phase II reveal(ğ‘Œ 1ğ‘ğ‘–ğ‘¡
foreach ğ‘– âˆˆ W â€² do
11

ğ‘–

, ğ‘ ğ‘ğ‘™ğ‘¡)

12

13

require(userIsCommitted(msg.sender))
require(H (cid:0)ğ‘Œ 1ğ‘ğ‘–ğ‘¡

, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–, ğ‘ ğ‘ğ‘™ğ‘¡ğ‘– (cid:1) == ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡ğ‘šğ‘’ğ‘›ğ‘¡ğ‘  (ğ‘šğ‘ ğ‘”.ğ‘ ğ‘’ğ‘›ğ‘‘ğ‘’ğ‘Ÿ ))

ğ‘–

4.5 Aggregation & Reward Distribution
We apply PTSFD to calculate the reward distribution for each worker. In order to calculate the
rewards, S aggregates ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– across all workers ğ‘– âˆˆ W â€² first to obtain the global label count
ğº = (cid:205)

Wâ€² ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– âˆˆ N| C | . G is a helper variable to calculate ğ‘…ğ‘– :

ğ‘…ğ‘– =

1
ğ‘š Ã— ğ‘›

Ã— (ğº âˆ’ ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– )

(12)

The worker is rewarded for its prediction on sample ğ‘— with respect to itâ€™s peers regarding Equation 2.
The final rewardScore for worker ğ‘– is a sum of all individual rewards over ğ‘‹ ğ‘ğ‘¢ğ‘, given by

Â¯ğœğ‘– = ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ (ğ‘–) = ğœ† Â·

(cid:32)

1
ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘ 
ğ‘—

âˆ‘ï¸

âˆ‘ï¸

ğ‘—

ğ‘

(cid:33)

ğœ0(ğ‘¥ğ‘– ğ‘—, ğ‘¥ğ‘ ğ‘— )

âˆ€ğ‘– âˆˆ W â€²

(13)

where parameter ğœ† describes a scaling parameter for the reward and ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘ 
of peer workers who also submitted a label prediction on ğ‘—. The aggregated predictions ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ are
calculated by majority vote of ğ‘Œ 1ğ‘ğ‘–ğ‘¡
âˆ€ğ‘– âˆˆ W â€². We merge the reward computation and aggregation
into a single algorithm as outlined in Algorithm 3. Note that implementation details may differ
fundamentally depending on the underlying blockchain architecture.

describes the number

ğ‘–

ğ‘—

4.6 Knowledge Distillation on Public Dataset
Finally, workers download the aggregated predictions ğ‘Œ ğ‘ğ‘¢ğ‘
epochs of knowledge distillation using ğ‘‹ ğ‘ğ‘¢ğ‘, ğ‘Œ ğ‘ğ‘¢ğ‘

ğ‘ğ‘”ğ‘”ğ‘Ÿ from the blockchain and perform several
â†’

ğ‘ğ‘”ğ‘”ğ‘Ÿ to improve their respective model (ğœƒ ğ‘–ğ‘šğ‘ğ‘Ÿğ‘œğ‘£ğ‘’ğ‘‘

ğ‘–

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

15

Algorithm 3: Peer Truth Serum for Federated Distillation (PTSFD)

input : Integer encoded class votes ğ‘¥ğ‘– ğ‘— , and ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– where âˆ€ğ‘– âˆˆ W â€² âŠ† W,

âˆ€ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘

output :ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’, ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘ 

1 init ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’, ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘ , ğ‘‰ ğ‘œğ‘¡ğ‘’ğ‘ , ğº, ğ‘€, ğ‘…ğ‘– , ğœ0
2

var ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ âˆˆ Rğ‘›

// reward share of each worker

var ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘  âˆˆ Nğ‘š = (cid:0)0,

0,

. . .

0(cid:1)

// final labels for ğ‘‹ ğ‘ğ‘¢ğ‘

3

4

5

6

7

8

14

15

18

19

20

21

22

23

24

25

26

27

28

29

30

31

0
...
(cid:170)
(cid:174)
(cid:174)
0
(cid:172)

0
...
0

0
...
0

Â· Â· Â·

Â· Â· Â·

. . .
. . .

0(cid:1)
0(cid:1)

var ğ‘‰ ğ‘œğ‘¡ğ‘’ğ‘  âˆˆ Nğ‘šÃ—| C | = (cid:169)
(cid:173)
(cid:173)
(cid:171)

var ğ‘€ âˆˆ Nğ‘› = (cid:0)0,
var ğº âˆˆ N | C | = (cid:0)0,

0,
0,

9
10 foreach ğ‘– âˆˆ W â€² do
ğº += ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘–
11
foreach ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘ do
if ğ‘ğ‘– ğ‘— â‰  NULL then

12

13

ğ‘‰ ğ‘œğ‘¡ğ‘’ğ‘  [ ğ‘—, ğ‘¥ğ‘– ğ‘— ] += 1
ğ‘€ [ğ‘–] += 1

16 foreach ğ‘— âˆˆ ğ‘‹ ğ‘ğ‘¢ğ‘ do
17

foreach ğ‘– âˆˆ W â€² do

if ğ‘ğ‘– ğ‘— = NULL then
continue

ğ‘…ğ‘– =

1
ğ‘› Â· ğ‘€ [ğ‘–]

Ã— (ğº âˆ’ ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– )

ğœ0 = 0
ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘  = 0
foreach ğ‘ âˆˆ W â€² â‰  ğ‘– do
if ğ‘ğ‘ ğ‘— = NULL then

continue

ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘  += 1
(cid:40) 1
ğ‘…ğ‘– [ğ‘¥ğ‘– ğ‘— ] âˆ’ ğ›½
âˆ’ğ›½

ğœ0 +=

ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ [ğ‘–] += ğœ† Â·

if ğ‘¥ğ‘– ğ‘— = ğ‘¥ğ‘ ğ‘—
otherwise.

(cid:20)

1
ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘ 

(cid:21)

Ã— ğœ0

for ğ‘ = 0; ğ‘ â‰¤ |C|; ğ‘ + + do

if ğ‘‰ ğ‘œğ‘¡ğ‘’ğ‘  [ ğ‘—, ğ‘] > ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘  [ ğ‘—] then

ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘  [ ğ‘—] = ğ‘

32 return ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’, ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘ 

// placeholder: aggregated votes

// placeholder: # of predictions
// placeholder: data distribution

// iterate over selected workers

// iterate over data samples
// count only if predicted

// iterate over data samples
// iterate over selected workers

// skip if no prediction

// iterate over peers
// skip if no prediction

// reward only if a match

// reward worker ğ‘– for sample ğ‘—

// compute majority for sample ğ‘—

16

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

ğœƒğ‘– + Î”ğœƒğ‘– ). Optionally, "Local Model Training" -> "Hash Commit & Aggregation Phase" -> "Reward
Distribution" -> "Federated Distillation" can be repeated until a specific threshold is achieved as
specified in the Smart Contract S. Note that ğœ† should decrease for every consecutive round since
most evaluated labels will not change. The details of the FD training process of each client is shown
in Section 2.2.

4.7 Complexity Analysis
Since we are running this protocol on-blockchain, it is imperative that the required computational
and storage costs are well understood. Hence, in this section we discuss the overhead in terms of
the computation and storage cost that our proposed algorithm incurs. Note again that the actual
implementation on a general purpose Blockchain system may differ, depending on the underlying
virtual machine. Yet, our PTSFD implementation illustrated in Algorithm 3 serves as a reference to
approximate the complexity.

4.7.1 Computational Complexity. In Algorithm 3, we first compute global label distribution and
count class votes across all workers, this is done in first section (line 7 - 12) of the algorithm. The
computation overhead is O (ğ‘š Â· ğ‘›) where ğ‘š = |ğ‘‹ ğ‘ğ‘¢ğ‘ | and ğ‘› = |W â€²|. Next we go over each data
sample in ğ‘‹ ğ‘ğ‘¢ğ‘ and reward/penalize a worker based on its peers. We also compute aggregated class
label for each sample in this part of the algorithm (line 13 - 29). The process of computing reward
ğ‘›ğ‘ğ‘’ğ‘’ğ‘Ÿğ‘  (cid:1).
for each worker based on its peers incurs a computational overhead as given by O (cid:0)ğ‘š Â· (cid:205)ğ‘›
ğ‘–=1
The global label calculation incurs an additional cost of O (ğ‘š Â· |C|). In the baseline case, since each
worker works on all data samples of the public dataset making it a peer of every other worker, the
overall computation cost is given by Equation 14.

O (ğ‘š Â· (ğ‘›2 + |C|))

(14)

For more practical solutions we distribute samples of public dataset among workers in a way
that each sample is classified by a maximum of two workers. The computational cost of this
implementation of PTSFD would reduce the overhead as described in Equation 15.

O (ğ‘š Â· (2ğ‘› + |C|))

(15)

Storage Complexity. There are two types of storage cost associated with the proposed
4.7.2
algorithm. One is the permanent storage cost, the other is that of non-permanent memory variables.
ğ‘‰ ğ‘œğ‘¡ğ‘’ğ‘ , ğ‘€, ğ‘†, ğ‘…ğ‘– , ğœ0 require memory storage as part of the computation incurring O (|C| Â· (ğ‘š + 2) + ğ‘›)
of additional memory storage. Whether reported frequencies ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘– or final reward share
of each worker ğ‘Ÿğ‘’ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ have to be stored permanently on the blockchain depends on the
requirements of the underlying blockchain system. In the optimal case, only ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘  = ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ
is stored permanently on the blockchain. Therefore, the minimum bits of data required for each
round is illustrated by Equation 16, where ğœ‚ describes the additional overhead due to encoding
requirements.

bğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘  = ğ‘› Ã— |C| Ã— 1ğ‘ğ‘–ğ‘¡ + ğœ‚

(16)

4.8 Limitations
Despite the advantages of the introduced decentral FD protocol, our framework is restricted by the
following limitations.

(1) Public Dataset. Even though Federated Distillation introduces many advantages like reduced
information exchange and independent NN architectures, the FD training process requires

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

17

access to a public dataset ğ‘‹ ğ‘ğ‘¢ğ‘ which might not be available for some use-cases. While [37]
have shown that highly dissimilar data distributions can be sufficient for FD, relying on Ağ‘– ğ‘—
as a heuristic for the evaluation certainty of a sample restricts the divergence of distributions
between ğ‘‹ ğ‘ğ‘¢ğ‘ and ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£. The scoring method introduced by [55] seems promising in this
context.

(2) Public Blockchains. Despite the heavy reduction of computational and storage require-
ments, our framework is not suitable for contemporary public blockchain systems due to (i)
high costs induced by the storage capacity of ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ and computational overhead of PTSFD
as well as (ii) transparency of ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ for nodes which are not part of W âˆˆ F and therefore
did not deposit. Both problems might be mitigated by future developments in the public
blockchain domain.

(3) Self Predicting Condition. PTSFD is incentive compatible and leads to an optimal solution
if workers act honestly. Yet, if Equation 10 holds, then the mechanism is incentive compatible.
If classes are equally distributed over ğ‘‹ ğ‘ğ‘¢ğ‘ the conditions always hold true. Example: Let
Pr(x=a)=0,8 and Pr(x=b)=0,2 but R(a)=0,9 and R(b)=0.1. Even though worker ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
= ğ‘, their
expected reward would be higher if ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡

= ğ‘ since 0,8

0,9 âˆ’ ğ›½ < 0,2

0,1 âˆ’ ğ›½.

ğ‘–

ğ‘–

5 EXPERIMENTS
In this section we empirically evaluate the PTSFD framework and analyze the reward distribution
under different levels of effort as well as its robustness in the event of malicious behavior. In this
analysis, we do not consider explicit variable costs ğ‘ğ‘– (ğ‘’) since these are hard to quantify in most
realistic scenarios. We further set the reward scaling parameter ğœ† = 1 for all experiments. We do not
consider lagging workers, therefore W â€² = W across all experiments. All experiments are based on
a single round of the proposed protocol.

Specifically, we experimentally validate the following properties of PTSFD:

(1) Performance. Choosing to participate in the federation should lead to a significant improve-

ment in model accuracy for each worker.

(2) Fairness. The more effort a worker exerts in terms of training accuracy and amount of

training data, the better the reward.

(3) Robustness. Malicious workers are rewarded substantially less, even under high collusion

rates.

5.1 Data sets and models
We analyze the decentralized 1-bit compressed FD with PTSFD protocol on a federated image
classification problem, using EMNIST / MNIST data sets [10]. Our Federation consists of 10 workers.
We split the training data among workers according to a Dirichlet distribution with dirichlet
parameter ğ›¼. Figure 3 illustrates the data distribution of 10 labels over 10 different workers for
ğ›¼ = 100, ğ›¼ = 1 and ğ›¼ = 0.1.
We first train LeNet locally on ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£ (which is EMNIST digits data set in our case) and then perform
Knowledge distillation using the MNIST dataset as public ğ‘‹ ğ‘ğ‘¢ğ‘ data set. Even though in real world
PTSFD application, workers may train different model architectures and different local training
epochs according to their own hardware constraints, we use only one default NN architecture
for simplicity reasons and simulate heterogeneity through varying local training accuracy (early
stopping), non-iid data and different sizes of ğ‘‹ ğ‘ğ‘¢ğ‘. Note that the distribution of the distillation data
deviates from the one of the worker data, as it would in realistic Federated Learning scenarios
(MNIST contains handwritten digits, EMNIST contains different set of handwritten numbers). We

18

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

use Adam optimizer [30] with a fixed learning rate of 0.001 for both the distillation and training
process. We minimize cross-entropy loss for local model training on ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£, ğ‘Œ ğ‘ğ‘Ÿğ‘–ğ‘£ and minimize
Kullback-Leibler Divergence on ğ‘‹ ğ‘ğ‘¢ğ‘, ğ‘Œ ğ‘ğ‘¢ğ‘
ğ‘ğ‘”ğ‘”ğ‘Ÿ .

Fig. 3. Non-iid data distribution case for different ğ›¼ values of Dirichlet Distribution.

5.2 Performance Improvement
In this section we evaluate participating workers for improvement in local model quality with
varying the size of local training dataset and distillation dataset. We note a substantial increase in
model quality for each worker after they run Knowledge distillation round. We also note that local
training dataset size matters more than the distillation dataset size but cannot be ignored especially
for non-iid distribution case.

Figure 4 illustrates this increase in accuracy with respect to to the size of local dataset |ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£ | and
the public dataset |ğ‘‹ ğ‘ğ‘¢ğ‘ | on EMNIST / MNIST with non-iid distribution (ğ›¼ = 0.1 & ğ›¼ = 1.0) and
with iid distribution (ğ›¼ = 100).

Fig. 4. The influence of ğ‘‹ ğ‘ğ‘¢ğ‘ and ğ‘‹ ğ‘ğ‘Ÿğ‘–ğ‘£ on model accuracy under different ğ›¼ setting.

5.3 Fair Effort-Reward Correlation
Heterogeneous Effort. For a realistic FL scenario, PTSFD allows for different levels of quality
in terms of contributions. PTSFD workers can train different local model architectures with dif-
ferent number of training epochs according to their own hardware constraints. To mimic this

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

19

Fig. 6. Effect of confidence based predictions on reward with different ğ›½ (penalty) using LeNet on MNIST.

heterogeneous behavior, we train 10 workers with different early stopping criteria. A high local
training accuracy resembles high effort hence should yield better reward. We observe this in our
experiments as shown by Figure 5.

Heterogeneous Data Quantity. The amount of private data as well as the respective quality
of this data may vary and lead to different qualities of contribution. We assume similar data quality
and assess different data quantities. Figure 5 illustrates reward distribution under heterogeneous
data and accuracy measures. (left) shows the reward distribution of 10 workers with varying
training accuracy under different ğ›½ values. (right) illustrates the effect of different amounts of local
training data on the reward distribution. The results suggest that high training accuracy and a
large local dataset lead to a higher reward.

Fig. 5. Effect of Local Training Accuracy & Local Data Size on Reward.

20

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

5.4 Robustness of PTSFD
In order to ensure a desired quality of label predictions, the federation can decide upon parameter
ğœ† to scale the reward with respect to itâ€™s underlying collateral (we use ğœ† = 1 in all cases) and ğ›½ to
tweak the penalty for wrong answers and therefore adjust the confidence necessary for individually
rational workers (Equation 7) to submit a prediction. The initially staked deposit serves as safety
mechanism against malicious behavior, since malicious behavior can result in negative gains. We
design an experiment where each worker can choose to pass the report if they have low confidence
in their predicted results. Fig 6 shows the reward with different penalty factor ğ›½ under different
confidence levels. In this experiment, we split the local training data according to a dirichlet
distribution with dirichlet parameter ğ›¼ = 0.1 simulating a real world scenario where workers may
not be in possession of homogeneous data. Therefore, a workerâ€™s local model may have a low ability
to predict some classes previously not available to them. Workers will only report their result when
their confidence on the most possible label exceeds a certain threshold. The results suggest that
PTSFD can prevent low quality workers from polluting the federated training process by adjusting
ğ›½ appropriately.

5.5 Robustness in the case of Malicious Behavior
Finally, we experimentally verify the findings of the game-theoretic analysis presented in Sec-
tion 3.3 in a real FL context. We have theoretically proven that the heuristic behavior (skipping
local training and reporting labels randomly on public dataset) as well as strategic behavior such
as collusion results in an expected reward of 1 âˆ’ ğ›½. The experiments verify our theoretical findings.

Figure 8 shows the average reward gained by heuristic workers versus the reward gained by
honest participants. Heuristic workers predict on public dataset randomly instead of putting in any
effort to train local model.

Figure 7 illustrates the reward gains for colluding workers vs honest workers. Collusion is carried
out by making predictions such that

ğ‘Œ ğ‘Ÿğ‘’ğ‘ğ‘œğ‘Ÿğ‘¡
ğ‘–

=

(cid:26) 0
9

if ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘–
if ğ‘Œ ğ‘’ğ‘£ğ‘ğ‘™
ğ‘–

âˆˆ {0, 1, 2, 3, 4}
âˆˆ {5, 6, 7, 8, 9}

Both results suggest that honest participation yields the highest reward even if a large portion
of workers act maliciously. An analysis where the additional costs are taken into consideration
remains for future work.

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

21

Fig. 7. Average reward with varying ratio of colluding workers under different penalty ğ›½. Federated Learning
setting with 10 workers running LeNet on EMNIST digits for 10 epochs. For all experiments, 40000 data points
from the MNIST data set were used as public dataset ğ‘‹ ğ‘ğ‘¢ğ‘ .

Fig. 8. Average reward with varying ratio of heuristic workers under different penalty ğ›½. Federated Learning
setting with 10 workers running LeNet on EMNIST digits for 10 epochs. For all experiments, 40000 data points
from the MNIST data set were used as public dataset ğ‘‹ ğ‘ğ‘¢ğ‘ .

6 CONCLUSION
In this work we have introduced a novel decentral and reward based 1-bit compressed Federated
Distillation scheme on blockchain. We have shown, under various FL and non-iid conditions,
that our proposed framework can lead to a substantial increase in model performance for every
participant in the federation after only one round of participation. The 1-bit compression ensures
explicit comparability between contributions, necessary to automatically compute rewards on a
smart contract on top of a general purpose blockchain system in an environment where each worker
is treated as an equal part of a federation. We have demonstrated that the reward distribution based
on PTSFD, an adapted version of PTSC [50] is incentive compatible and enables the federation to
adjust to different thresholds of contribution quality by adjusting ğ›½. Both theoretical considerations
and experimental evidence suggest that our proposed mechanism is robust against random reporting
and collusion. We believe that our findings will help to scale Federated Learning tasks in fully
decentralized environments where entities have an equal interest in improving their models.

ACKNOWLEDGMENTS
This work was partly supported by the German Federal Ministry of Education and Research (BMBF)
through the BIFOLD - Berlin Institute for the Foundations of Learning and Data (ref. 01IS18025A

22

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

and ref. 01IS18037I) and the European Unionâ€™s Horizon 2020 Research and innovation Programme
under Grant Agreement No. 957059.

REFERENCES
[1] Arpit Agarwal, Debmalya Mandal, David C. Parkes, and Nisarg Shah. 2017. Peer Prediction with Heterogeneous Users.
In Proceedings of the 2017 ACM Conference on Economics and Computation (Cambridge, Massachusetts, USA) (EC â€™17).
Association for Computing Machinery, New York, NY, USA, 81â€“98. https://doi.org/10.1145/3033274.3085127

[2] Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin, Konstantinos Christidis, Angelo De Caro, David
Enyeart, Christopher Ferris, Gennady Laventman, Yacov Manevich, Srinivasan Muralidharan, Chet Murthy, Binh
Nguyen, Manish Sethi, Gari Singh, Keith Smith, Alessandro Sorniotti, Chrysoula Stathakopoulou, Marko VukoliÄ‡,
Sharon Weed Cocco, and Jason Yellick. 2018. Hyperledger Fabric: A Distributed Operating System for Permissioned
Blockchains. In Proceedings of the Thirteenth EuroSys Conference (Porto, Portugal) (EuroSys â€™18). Association for
Computing Machinery, New York, NY, USA, Article 30, 15 pages. https://doi.org/10.1145/3190508.3190538

[3] Nikolay Archak and Arun Sundararajan. 2009. Optimal Design of Crowdsourcing Contests. ICIS 2009 Proceedings -

Thirtieth International Conference on Information Systems, 200.

[4] X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu. 2019. FLChain: A Blockchain for Auditable Federated Learning with Trust
and Incentive. In 2019 5th International Conference on Big Data Computing and Communications (BIGCOM). 151â€“159.
https://doi.org/10.1109/BIGCOM.2019.00030

[5] H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise AgÃ¼era y Arcas. 2017. Communication-
efficient learning of deep networks from decentralized data. In Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics, AISTATS 2017. arXiv:1602.05629

[6] Vitalik Buterin. 2013. Ethereum: A Next-Generation Smart Contract and Decentralized Application Platform. https:

//github.com/ethereum/wiki/wiki/White-Paper.

[7] Somnath Chakrabarti, Thomas Knauth, Dmitrii Kuvaiskii, Michael Steiner, and Mona Vij. 2020. Chapter 8 - Trusted
execution environment with Intel SGX. In Responsible Genomic Data Sharing, Xiaoqian Jiang and Haixu Tang (Eds.).
Academic Press, 161â€“190. https://doi.org/10.1016/B978-0-12-816197-5.00008-5

[8] X. Chen and K. Xiong. May.2017. A payment scheme in crowdsourcing. In in Proc. IEEE Int. Conf. Commun. 1â€“6.
[9] Kai Fong Ernest Chong. 2020. A closer look at the approximation capabilities of neural networks. In 8th International
Conference on Learning Representations (ICLR). OpenReview.net. https://openreview.net/forum?id=rkevSgrtPr
[10] Gregory Cohen, Saeed Afshar, Jonathan Tapson, and AndrÃ© van Schaik. 2017. EMNIST: an extension of MNIST to

handwritten letters. arXiv:1702.05373 [cs.CV]

[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. 2015. BinaryConnect: Training Deep Neural Networks
with binary weights during propagations. In Advances in Neural Information Processing Systems (NeurIPS), Vol. 28.
3123â€“3131.

[12] Anirban Dasgupta and Arpita Ghosh. 2013. Crowdsourced Judgement Elicitation with Endogenous Proficiency. In
Proceedings of the 22nd International Conference on World Wide Web (Rio de Janeiro, Brazil) (WWW â€™13). Association
for Computing Machinery, New York, NY, USA, 319â€“330. https://doi.org/10.1145/2488388.2488417

[13] N. Ding, Z. Fang, and J. Huang. 2020. Incentive Mechanism Design for Federated Learning with Multi-Dimensional
Private Information. In 2020 18th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless
Networks (WiOPT). 1â€“8.

[14] Boi Faltings, Jason Jingshi Li, and Radu Jurca. 2014. Incentive Mechanisms for Community Sensing. IEEE Trans.

Comput. 63, 1 (2014), 115â€“128. https://doi.org/10.1109/TC.2013.150

[15] A. Ghosh and P. McAfee. 2012. Crowdsourcing with endogenous entry. In in Proc. 21st Int. Conf. World Wide Web

(WWW). 999â€“1008.

[16] Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, FranÃ§oise Beaufays, Sean Augenstein, Hubert
(2018).

Eichner, ChloÃ© Kiddon, and Daniel Ramage. 2018. Federated Learning for Mobile Keyboard Prediction.
arXiv:1811.03604 http://arxiv.org/abs/1811.03604

[17] Yifan Hu, Wei Xia, Jun Xiao, and Chao Wu. 2020. GFL: A Decentralized Federated Learning Framework Based On

Blockchain. (2020). arXiv:2010.10996 http://arxiv.org/abs/2010.10996

[18] Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Xu Chen, HyoukJoong Lee, Jiquan
Ngiam, Quoc V. Le, Yonghui Wu, and Zhifeng Chen. 2019. GPipe: Efficient Training of Giant Neural Networks using
Pipeline Parallelism. In Advances in Neural Information Processing Systems (NeurIPS), Vol. 32. 103â€“112.

[19] Sohei Itahara, Takayuki Nishio, Yusuke Koda, Masahiro Morikura, and Koji Yamamoto. 2020. Distillation-based
semi-supervised federated learning for communication-efficient collaborative training with non-IID private data. arXiv
(2020), 1â€“11. arXiv:2008.06180

[20] Ethan Buchman Jae Kwon. [n.d.]. Cosmos Whitepaper. https://cosmos.network/resources/whitepaper/.

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

23

[21] Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong-Lyun Kim. 2018. Communication-
efficient on-device machine learning: Federated distillation and augmentation under non-iid private data. arXiv preprint
arXiv:1811.11479 (2018). http://arxiv.org/abs/1811.11479

[22] Radu Jurca, Google Inc, Switzerland, and Boi Faltings. 2011. Incentives for Answering Hypothetical Questions. (01

2011).

[23] J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang. 2019. Incentive Mechanism for Reliable Federated Learning: A Joint
Optimization Approach to Combining Reputation and Contract Theory. IEEE Internet of Things Journal 6, 6 (2019),
10700â€“10714. https://doi.org/10.1109/JIOT.2019.2940820

[24] J. Kang, Z. Xiong, D. Niyato, H. Yu, Y. Liang, and D. I. Kim. 2019. Incentive Design for Efficient Federated Learning in
Mobile Networks: A Contract Theory Approach. In 2019 IEEE VTS Asia Pacific Wireless Communications Symposium
(APWCS). 1â€“5. https://doi.org/10.1109/VTS-APWCS.2019.8851649

[25] Stephen Buttolph Kevin Sekniqi, Daniel Laine and Emin GÂ¨un Sirer. [n.d.]. Avalanche Platform. https://www.avalabs.

org/whitepapers.

[26] A. Kiayias, A. Russell, B. David, and R. Oliynykov. Aug.2017. Ouroboros: A provably secure proof-of-stake blockchain

protocol. In Proc. 37th Annu. Int. Cryptol. Conf. (CRYPTO). 357â€“388.

[27] Patrick Kidger and Terry J. Lyons. 2020. Universal Approximation with Deep Narrow Networks. In Conference on

Learning Theory (COLT) (Proceedings of Machine Learning Research, Vol. 125). 2306â€“2327.

[28] H. Kim, J. Park, M. Bennis, and S. Kim. 2020. Blockchained On-Device Federated Learning. IEEE Communications

Letters 24, 6 (2020), 1279â€“1283. https://doi.org/10.1109/LCOMM.2019.2921755

[29] S. Kim. 2020. Incentive Design and Differential Privacy Based Federated Learning: A Mechanism Design Perspective.

IEEE Access 8 (2020), 187317â€“187325. https://doi.org/10.1109/ACCESS.2020.3030888

[30] Diederik P. Kingma and Jimmy Ba. 2017. Adam: A Method for Stochastic Optimization. arXiv:1412.6980 [cs.LG]
[31] Jakub KoneÄn`y, H Brendan McMahan, Felix X Yu, Peter RichtÃ¡rik, Ananda Theertha Suresh, and Dave Bacon. 2016.
Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 (2016).
[32] Tra le, Nguyen Tran, Yan Kyaw, Zhu Han, and Choong Seon Hong. 2020. Auction based Incentive Design for Efficient

Federated Learning in Cellular Wireless Networks. 1â€“6. https://doi.org/10.1109/WCNC45663.2020.9120773

[33] Yann LeCun, John S. Denker, and Sara A. Solla. 1990. Optimal Brain Damage. In Advances in Neural Information

Processing Systems (NeurIPS), Vol. 2. 598â€“605.

[34] P. Levy and D. Sarne. 2018. Understanding over participation in simple contests. In in Proc. AAAI Conf. Artif. Intell.

1571â€“1578.

[35] Fengfu Li, Bo Zhang, and Bin Liu. 2016. Ternary Weight Networks. arXiv preprint arXiv:1605.04711 (2016).
[36] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2019. Federated Learning: Challenges, Methods, and

Future Directions. (2019), 1â€“21. arXiv:1908.07873 http://arxiv.org/abs/1908.07873

[37] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2020. Federated Learning: Challenges, Methods, and

Future Directions. IEEE Signal Processing Magazine 37, 3 (2020), 50â€“60. https://doi.org/10.1109/MSP.2020.2975749

[38] Y. Li, C. Chen, N. Liu, H. Huang, Z. Zheng, and Q. Yan. 2021. A Blockchain-Based Decentralized Federated Learning
Framework with Committee Consensus. IEEE Network 35, 1 (2021), 234â€“241. https://doi.org/10.1109/MNET.011.2000263
[39] Tao Lin, Lingjing Kong, Sebastian U. Stich, and Martin Jaggi. 2020. Ensemble Distillation for Robust Model Fusion in

Federated Learning. arXiv NeurIPS (2020). arXiv:2006.07242

[40] Yuan Liu, Zhengpeng Ai, Shuai Sun, Shuangfeng Zhang, Zelei Liu, and Han Yu. 2020. FedCoin: A Peer-to-Peer Payment
System for Federated Learning. In Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
Intelligence and Lecture Notes in Bioinformatics). https://doi.org/10.1007/978-3-030-63076-8_9 arXiv:2002.11711

[41] Yang Liu and Jiaheng Wei. 2020.

Incentives for Federated Learning: a Hypothesis Elicitation Approach. CoRR

abs/2007.10596 (2020). arXiv:2007.10596 https://arxiv.org/abs/2007.10596

[42] Yuan Lu, Qiang Tang, and Guiling Wang. 2018. On Enabling Machine Learning Tasks atop Public Blockchains: A

Crowdsourcing Approach. 81â€“88. https://doi.org/10.1109/ICDMW.2018.00019

[43] T. Luo, S. S. Kanhere, S. K. Das, and H.-P. Tan. Sep. 2016. Incentive mechanism design for heterogeneous crowdsourcing

using all-pay contests. IEEE Trans. Mobile Comput. 15, 9 (Sep. 2016), 2234â€“2246.

[44] T. Luo, S. S. Kanhere, H.-P. Tan, F. Wu, H. Wu A. Ghosh, and P. McAfee. Apr.2015. Crowdsourcing with tullock contests:

A new perspective. In in Proc. IEEE Conf. Comput. Commun. (INFOCOM). 2515â€“2523.

[45] M.VojnoviÄ‡. Apr. 2017. Contesttheory. Commun.ACM 60, 5 (Apr. 2017), 70â€“80.
[46] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. Consulted 1 (2008), 2012.
[47] David Neumann, Felix Sattler, Heiner Kirchhoffer, Simon Wiedemann, Karsten MÃ¼ller, Heiko Schwarz, Thomas
Wiegand, Detlev Marpe, and Wojciech Samek. 2020. DeepCABAC: Plug & Play Compression of Neural Network
Weights and Weight Updates. In 2020 IEEE International Conference on Image Processing (ICIP). 21â€“25.

[48] T. Nishio, R. Shinkuma, and N. B. Mandayam. 2020. Estimation of Individual Device Contributions for Incentivizing
Federated Learning. In 2020 IEEE Globecom Workshops (GC Wkshps. 1â€“6. https://doi.org/10.1109/GCWkshps50303.

24

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

2020.9367484

[49] S. R. Pandey, N. H. Tran, M. Bennis, Y. K. Tun, Z. Han, and C. S. Hong. 2019. Incentivize to Build: A Crowdsourcing
Framework for Federated Learning. In 2019 IEEE Global Communications Conference (GLOBECOM). 1â€“6. https:
//doi.org/10.1109/GLOBECOM38437.2019.9014329

[50] Goran Radanovic, Boi Faltings, and Radu Jurca. 2016. Incentives for Effort in Crowdsourcing Using the Peer Truth
Serum. ACM Trans. Intell. Syst. Technol. 7, 4, Article 48 (March 2016), 28 pages. https://doi.org/10.1145/2856102
[51] Goran Radanovic, Boi Faltings, and Radu Jurca. 2016. Incentives for effort in crowdsourcing using the peer truth serum.

ACM Transactions on Intelligent Systems and Technology 7 (2016). Issue 4.

[52] Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, and FranÃ§oise Beaufays. 2019. Federated Learning for Emoji

Prediction in a Mobile Keyboard. (2019). arXiv:1906.04329 http://arxiv.org/abs/1906.04329

[53] M. Rokicki, S. Chelaru, S. Zerr, and S. Siersdorfer. 2014. Competitive game designs for improving the cost effectiveness

of crowdsourcing. In in Proc. 23rd ACM Int. Conf. Conf. Inf. Knowl. Manage. (CIKM). 1469â€“1478.

[54] D. Sarne and M. Lepioshkin. 2017. Effective prize structure for simple crowdsourcing contests with participation costs.

In in Proc. AAAI Conf. Hum. Comput. Crowdsourcing (HCOMP). 167â€“176.

[55] Felix Sattler, Tim Korjakow, Roman Rischke, and Wojciech Samek. 2021. FedAUX: Leveraging Unlabeled Auxiliary

Data in Federated Learning. arXiv:2102.02514

[56] Felix Sattler, Arturo Marban, Roman Rischke, and Wojciech Samek. 2020. Communication-efficient federated distillation.

(2020). arXiv:2012.00632

[57] Felix Sattler, Simon Wiedemann, Klaus-Robert MÃ¼ller, and Wojciech Samek. 2019. Sparse Binary Compression: Towards
Distributed Deep Learning with minimal Communication. In International Joint Conference on Neural Networks (IJCNN).
1â€“8.

[58] Felix Sattler, Simon Wiedemann, Klaus-Robert MÃ¼ller, and Wojciech Samek. 2020. Robust and Communication-Efficient
Federated Learning from Non-IID Data. IEEE Transactions on Neural Networks and Learning Systems 31, 9 (2020),
772â€“785.

[59] Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, and Seong Lyun Kim. 2020. Federated knowledge distillation.

arXiv (2020), 1â€“30. arXiv:2011.02367

[60] Ethan Buchman Serguei Popov. [n.d.]. The tangle. https://iotatoken.com/IOTA_Whitepaper.pdf.
[61] Muhammad Shayan, Clement Fung, Ivan Beschastnikh, and Chris J.M. Yoon. 2018. Biscotti: A ledger for private and

secure peer-to-peer machine learning. arXiv (2018). arXiv:1811.09904

[62] S. S. Shetty, C. A. Kamhoua, and L. L. Njilla. 2019. Distributed Consensus Protocols and Algorithms. 25â€“50. https:

//doi.org/10.1002/9781119519621.ch2

[63] Victor Shnayder, Arpit Agarwal, Rafael Frongillo, and David C. Parkes. 2016. Informed Truthfulness in Multi-Task Peer
Prediction. In Proceedings of the 2016 ACM Conference on Economics and Computation (Maastricht, The Netherlands) (EC
â€™16). Association for Computing Machinery, New York, NY, USA, 179â€“196. https://doi.org/10.1145/2940716.2940790
[64] A. Singla and A. Krause. 2013. Truthful incentives in crowdsourcing tasks using regret minimization mechanisms. In

in Proc. 22nd Int. Conf. World Wide Web(WWW). 1167â€“1178.

[65] K. Toyoda, J. Zhao, A. N. S. Zhang, and P. T. Mathiopoulos. 2020. Blockchain-Enabled Federated Learning With

Mechanism Design. IEEE Access 8 (2020), 219744â€“219756. https://doi.org/10.1109/ACCESS.2020.3043037

[66] M. H. ur Rehman, K. Salah, E. Damiani, and D. Svetinovic. 2020. Towards Blockchain-Based Reputation-Aware
Federated Learning. In IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM
WKSHPS). 183â€“188. https://doi.org/10.1109/INFOCOMWKSHPS50562.2020.9163027

[67] Stefanie Warnat-Herresthal, Hartmut Schultze, Krishnaprasad Lingadahalli Shastry, Sathyanarayanan Manamohan,
Saikat Mukherjee, Vishesh Garg, Ravi Sarveswara, Kristian HÃ¤ndler, Peter Pickkers, N Ahmad Aziz, Sofia Ktena, Florian
Tran, Michael Bitzer, Stephan Ossowski, Nicolas Casadei, Christian Herr, Daniel Petersheim, Uta Behrends, Fabian
Kern, Tobias Fehlmann, Philipp Schommers, Clara Lehmann, Max Augustin, Jan Rybniker, Janine AltmÃ¼ller, Neha
Mishra, Joana P Bernardes, Benjamin KrÃ¤mer, Lorenzo Bonaguro, Jonas Schulte-Schrepping, Elena De Domenico,
Christian Siever, Michael Kraut, Milind Desai, Bruno Monnet, Maria Saridaki, Charles Martin Siegel, Anna Drews,
Melanie Nuesch-Germano, Heidi Theis, Jan Heyckendorf, Stefan Schreiber, Sarah Kim-Hellmuth, Paul Balfanz, Thomas
Eggermann, Peter Boor, Ralf Hausmann, Hannah Kuhn, Susanne Isfort, Julia Carolin Stingl, GÃ¼nther Schmalzing,
Christiane K Kuhl, Rainer RÃ¶hrig, Gernot Marx, Stefan Uhlig, Edgar Dahl, Dirk MÃ¼ller-Wieland, Michael Dreher,
Nikolaus Marx, Jacob Nattermann, Dirk Skowasch, Ingo Kurth, Andreas Keller, Robert Bals, Peter NÃ¼rnberg, Olaf RieÃŸ,
Philip Rosenstiel, Mihai G Netea, Fabian Theis, Sach Mukherjee, Michael Backes, Anna C Aschenbrenner, Thomas
Ulas, Angel Angelov, Alexander BartholomÃ¤us, Anke Becker, Daniela Bezdan, Conny Blumert, Ezio Bonifacio, Peer
Bork, Bunk Boyke, Helmut Blum, Thomas Clavel, Maria Colome-Tatche, Markus Cornberg, Inti Alberto De La Rosa
VelÃ¡zquez, Andreas Diefenbach, Alexander Dilthey, Nicole Fischer, Konrad FÃ¶rstner, SÃ¶ren Franzenburg, Julia-Stefanie
Frick, Gisela Gabernet, Julien Gagneur, Tina Ganzenmueller, Marie Gauder, Janina GeiÃŸert, Alexander Goesmann,
Siri GÃ¶pel, Adam Grundhoff, Hajo Grundmann, Torsten Hain, Frank Hanses, Ute Hehr, AndrÃ© Heimbach, Marius

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

25

Hoeper, Friedemann Horn, Daniel HÃ¼bschmann, Michael Hummel, Thomas Iftner, Angelika Iftner, Thomas Illig, Stefan
Janssen, JÃ¶rn Kalinowski, RenÃ© Kallies, Birte Kehr, Oliver T Keppler, Christoph Klein, Michael Knop, Oliver Kohlbacher,
Karl KÃ¶hrer, Jan Korbel, Peter G Kremsner, Denise KÃ¼hnert, Markus Landthaler, Yang Li, Kerstin U Ludwig, Oliwia
Makarewicz, Manja Marz, Alice C McHardy, Christian Mertes, Maximilian MÃ¼nchhoff, Sven Nahnsen, Markus NÃ¶then,
Francine Ntoumi, JÃ¶rg Overmann, Silke Peter, Klaus Pfeffer, Isabell Pink, Anna R Poetsch, Ulrike Protzer, Alfred PÃ¼hler,
Nikolaus Rajewsky, Markus Ralser, Kristin Reiche, Stephan Ripke, Ulisses Nunes da Rocha, Antoine-Emmanuel Saliba,
Leif Erik Sander, Birgit Sawitzki, Simone Scheithauer, Philipp Schiffer, Jonathan Schmid-Burgk, Wulf Schneider, Eva-
Christina Schulte, Alexander Sczyrba, Mariam L Sharaf, Yogesh Singh, Michael Sonnabend, Oliver Stegle, Jens Stoye,
Janne Vehreschild, Thirumalaisamy P Velavan, JÃ¶rg Vogel, Sonja Volland, Max von Kleist, Andreas Walker, JÃ¶rn Walter,
Dagmar Wieczorek, Sylke Winkler, John Ziebuhr, Monique M B Breteler, Evangelos J Giamarellos-Bourboulis, Matthijs
Kox, Matthias Becker, Sorin Cheran, Michael S Woodacre, Eng Lim Goh, Joachim L Schultze, COVID-19 Aachen Study
(COVAS), and Deutsche COVID-19 Omics Initiative (DeCOI). 2021. Swarm Learning for decentralized and confidential
clinical machine learning. Nature 594, 7862 (2021), 265â€“270. https://doi.org/10.1038/s41586-021-03583-3

[68] J. Weng, J. Weng, J. Zhang, M. Li, Y. Zhang, and W. Luo. 2019. DeepChain: Auditable and Privacy-Preserving Deep
IEEE Transactions on Dependable and Secure Computing (2019), 1â€“1.

Learning with Blockchain-based Incentive.
https://doi.org/10.1109/TDSC.2019.2952332

[69] Simon Wiedemann, Heiner Kirchhoffer, Stefan Matlage, Paul Haase, Arturo MarbÃ¡n, Talmaj Marinc, David Neumann,
Tung Nguyen, Heiko Schwarz, Thomas Wiegand, Detlev Marpe, and Wojciech Samek. 2020. DeepCABAC: A Universal
Compression Algorithm for Deep Neural Networks. IEEE J. Sel. Top. Signal Process. 14, 4 (2020), 700â€“714.

[70] Dr. Gavin Wood. [n.d.]. Polkadot: Vision For A Heterogeneous Multi-Chain Framework. https://polkadot.network/

PolkaDotPaper.pdf.

[71] Gavin Wood. [n.d.]. Ethereum: A secure decentralised generalised transaction ledger. ([n. d.]).
[72] Jinjin Xu, Wenli Du, Ran Cheng, Wangli He, and Yaochu Jin. 2020. Ternary Compression for Communication-Efficient

Federated Learning. arXiv preprint arXiv:2003.03564 (2020).

[73] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019. Federated machine learning: Concept and applica-
tions. ACM Transactions on Intelligent Systems and Technology 10, 2 (2019), 1â€“19. https://doi.org/10.1145/3298981
arXiv:1902.04885

[74] Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Mingshu Cong, Xi Weng, Dusit Niyato, and Qiang Yang. 2020. A
Fairness-Aware Incentive Scheme for Federated Learning. In Proceedings of the AAAI/ACM Conference on AI, Ethics,
and Society (New York, NY, USA) (AIES â€™20). Association for Computing Machinery, New York, NY, USA, 393â€“399.
https://doi.org/10.1145/3375627.3375840

[75] Rongfei Zeng, Shixun Zhang, Jiaqi Wang, and Xiaowen Chu. 2020. FMore: An incentive scheme of multi-dimensional

auction for federated learning in MEC. https://doi.org/10.1109/ICDCS47774.2020.00094 arXiv:2002.09699

[76] Y. Zhan, P. Li, Z. Qu, D. Zeng, and S. Guo. 2020. A Learning-Based Incentive Mechanism for Federated Learning. IEEE

Internet of Things Journal 7, 7 (2020), 6360â€“6368. https://doi.org/10.1109/JIOT.2020.2967772

[77] Yufeng Zhan and Jiang Zhang. 2020. An Incentive Mechanism Design for Efficient Edge Learning by Deep Reinforcement
Learning Approach. In IEEE INFOCOM 2020 - IEEE Conference on Computer Communications (Toronto, ON, Canada).
IEEE Press, 2489â€“2498. https://doi.org/10.1109/INFOCOM41043.2020.9155268

Reward-Based 1-bit Compressed Federated Distillation on Blockchain

1

A GAME THEORETIC ANALYSIS
The proposed framework requires each worker to stake a fixed amount ğ·ğ‘– to avoid malicious
behavior. Unlike in crowdsourcing tasks where the reward can only be positive or zero, here any
worker might be penalized with a negative reward (ğ›½ > 1). We follow the proof in [51] and assume:

(1) Self-predicting condition

(2) Workers are rational agents aim to maximize expected reward
In Section 3.2 we introduced the PTSFD mechanism with the reward function:

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥)
ğ‘ƒğ‘ (ğ‘¥)

> ğ‘ƒğ‘ |ğ‘¤ (ğ‘¦ |ğ‘¥)
ğ‘ƒğ‘ (ğ‘¦)

, âˆ€ğ‘¦ â‰  ğ‘¥

ğœğ‘– ğ‘— (cid:0)ğ‘¥ğ‘– ğ‘—, ğ‘¥ğ‘ ğ‘— (cid:1) = ğœ† Â·

ğœ0

(cid:0)ğ‘¥ğ‘– ğ‘—, ğ‘¥ğ‘ ğ‘— (cid:1) =

(cid:32)

(cid:40)

(cid:33)

ğœ0

(cid:0)ğ‘¥ğ‘– ğ‘—, ğ‘¥ğ‘ ğ‘— (cid:1) âˆ’ ğ›½

1
ğ‘›peers

âˆ‘ï¸

ğ‘

1
ğ‘…ğ‘– (ğ‘¥ğ‘– ğ‘— )
0

if ğ‘¥ğ‘– ğ‘— = ğ‘¥ğ‘ ğ‘—
if ğ‘¥ğ‘– ğ‘— â‰  ğ‘¥ğ‘ ğ‘—

Suppose that worker ğ‘¤ believes that the other workers are honest. The expected reward of worker
ğ‘¤ for reporting ğ‘¦ while worker ğ‘¤ evaluates ğ‘¥ is equal to

ğœ†(

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¦ |ğ‘¥)
ğ‘ƒğ‘ (ğ‘¦) âˆ’ ğ›½)

Where ğ‘ƒğ‘ |ğ‘¤ (ğ‘¦|ğ‘¥) represents the probability of peer ğ‘ reporting ğ‘¦ under the condition that worker
ğ‘¤â€™s evaluation is ğ‘¥. ğ‘ƒğ‘ (ğ‘¦) represents the probability of the peer ğ‘ reporting ğ‘¦. Based on the initial
self-predicting condition, worker ğ‘¤ will always report ğ‘¥ when the other workers are honest, as
long as

ğœ†(

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥)
ğ‘ƒğ‘ (ğ‘¥) âˆ’ ğ›½) > ğœ†(

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¦ |ğ‘¥)
ğ‘ƒğ‘ (ğ‘¦) âˆ’ ğ›½)

Suppose that worker ğ‘¤ believes that the other workers adopt a strategy described by a distribution
ğ‘„ğ‘ |ğ‘ (strategic or heuristic strategies). ğ‘„ğ‘ |ğ‘¤ (ğ‘¦|ğ‘¥) represents the probability of peer ğ‘ reporting ğ‘¦
under the condition that worker ğ‘¤â€™s evaluation is ğ‘¥

ğ‘„ğ‘ |ğ‘¤ (ğ‘¦|ğ‘¥) = (cid:205)ğ‘§ âŠ‚ğ‘‹ ğ‘„ğ‘ |ğ‘ (ğ‘¦|ğ‘§)ğ‘ƒğ‘ |ğ‘¤ (ğ‘§|ğ‘¥)
ğ‘„ğ‘ (ğ‘¦) represents the probability of peer ğ‘ reporting ğ‘¦. ğ‘„ğ‘ (ğ‘¦) = (cid:205)ğ‘§ âŠ‚ğ‘‹ ğ‘„ğ‘ |ğ‘ (ğ‘¦|ğ‘§)ğ‘ƒğ‘ (ğ‘§). The expected
reward of worker ğ‘¤ for reporting ğ‘¦ while worker ğ‘¤ evaluate as ğ‘¥ is therefore equal to
ğœ†(

ğ‘„ğ‘ |ğ‘¤ (ğ‘¦ |ğ‘¥)
ğ‘„ğ‘ (ğ‘¦) âˆ’ ğ›½)

We can rewrite the expected reward of worker ğ‘¤ whose evaluation is ğ‘¥ for reporting ğ‘¦

ğ‘„ğ‘ |ğ‘¤ (ğ‘¦ |ğ‘¥)
ğ‘„ğ‘ (ğ‘¦) âˆ’ ğ›½) = ğœ†(
We can further expand the above equation into two terms.(ğ‘§ = ğ‘¥ and ğ‘§ â‰  ğ‘¥ )

(cid:205)ğ‘§ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).ğ‘ƒğ‘ |ğ‘¤ (ğ‘§ |ğ‘¥)
(cid:205)ğ‘§ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).ğ‘ƒğ‘ (ğ‘§) âˆ’ ğ›½)

ğœ†(

ğœ†(

ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘¥).ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥)+(cid:205)ğ‘§â‰ ğ‘¥ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).ğ‘ƒğ‘ |ğ‘¤ (ğ‘§ |ğ‘¥)
ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘¥).ğ‘ƒğ‘ (ğ‘¥)+(cid:205)ğ‘§â‰ ğ‘¥ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).ğ‘ƒğ‘ (ğ‘§)

âˆ’ ğ›½)

= ğœ†(

ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘¥)âˆ—ğ‘ƒğ‘ (ğ‘¥).

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥ )

ğ‘ƒğ‘ (ğ‘¥ ) +(cid:205)ğ‘§â‰ ğ‘¥ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).

ğ‘ƒğ‘ |ğ‘¤ (ğ‘§|ğ‘¥ )
ğ‘ƒğ‘ (ğ‘§)

.ğ‘ƒğ‘ (ğ‘§)

ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘¥).ğ‘ƒğ‘ (ğ‘¥)+(cid:205)ğ‘§â‰ ğ‘¥ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).ğ‘ƒğ‘ (ğ‘§)

âˆ’ ğ›½)

2

Witt et al. - Reward-Based 1-bit Compressed Federated Distillation on Blockchain

â‰¤ ğœ†(

ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘¥).ğ‘ƒğ‘ (ğ‘¥).

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥ )

ğ‘ƒğ‘ (ğ‘¥ ) +(cid:205)ğ‘§â‰ ğ‘¥ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥ )
ğ‘ƒğ‘ (ğ‘¥ )

.ğ‘ƒğ‘ (ğ‘§)

ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘¥).ğ‘ƒğ‘ (ğ‘¥)+(cid:205)ğ‘§â‰ ğ‘¥ ğ‘„ğ‘ |ğ‘ (ğ‘¦ |ğ‘§).ğ‘ƒğ‘ (ğ‘§)

âˆ’ ğ›½)

= ğœ†(

ğ‘ƒğ‘ |ğ‘¤ (ğ‘¥ |ğ‘¥)
ğ‘ƒğ‘ (ğ‘¥) âˆ’ ğ›½)

In the second line of the above equation we multiply and divide ğ‘ƒğ‘ (ğ‘¥) in the numerator. By
applying the self-predicting condition on the second term in the numerator, we can get inequality
in line three. We conclude that the maximum expected reward is obtained for honest reporting.

