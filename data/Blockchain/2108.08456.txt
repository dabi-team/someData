1
2
0
2

g
u
A
9
1

]

G
L
.
s
c
[

1
v
6
5
4
8
0
.
8
0
1
2
:
v
i
X
r
a

Blockchain Phishing Scam Detection via Multi-channel
Graph Classiﬁcation

Dunjie Zhang1 and Jinyin Chen1,2

1 College of Information Engineering, Zhejiang University of Technology, Hangzhou
310023,China
2 Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou,310023,China

Abstract. With the popularity of blockchain technology, the ﬁnancial security is-
sues of blockchain transaction network have become increasingly serious. Phish-
ing scam detection methods will protect possible victims and build a healthier
blockchain ecosystem. Usually, the existing works deﬁne phishing scam detec-
tion as a node classiﬁcation task by learning the potential features of users through
graph embedding methods such as random walk or graph neural network (GNN).
However, these detection methods are suffered from high-complexity due to the
large scale of the blockchain transaction network, ignoring temporal information
of the transaction. Addressing to this problem, we deﬁned the transaction pat-
tern graphs for users and transformed the phishing scam detection into a graph
classiﬁcation task. To extract richer information from the input graph, we pro-
posed a multi-channel graph classiﬁcation model (MCGC) with a multiple fea-
ture extraction channels for GNN. The transaction pattern graphs and MCGC are
more able to detect potential phishing scammers by extracting the transaction pat-
tern features of the target users. Extensive experiments on seven benchmark and
Ethereum datasets demonstrate that the proposed MCGC can not only achieve the
state-of-the-art performance in graph classiﬁcation task, but also achieve effective
phishing scam detection based on the target users’ transaction pattern graphs.

Keywords: Blockchain; Ethereum; Phishing detection; Graph classiﬁcation.

1

INTRODUCTION

As one of the most successful applications of blockchain[1], cryptocurrency[2,3] has
promoted the rapid development of blockchain technology. The ﬁnancial security[4,5]
of cryptocurrency has also become an important prerequisite for healthy development
of blockchain technology. According to a report of Chainalysis, 30,287 victims en-
countered ﬁnancial scams on the Ethereum platform in the ﬁrst half of 2017, including
phishing scams, Ponzi schemes, ransomwares, etc., with a total economic loss of $225
million[6]. Among these scams, more than 50% can be classiﬁed as phishing scams that
take the cryptocurrency as the phishing target.

Traditional phishing scam detection methods[7] are usually applied to the identiﬁ-
cation of phishing emails or phishing webpages, to reduce the possibility of scams by
warning users or directly blocking content. Due to the openness of the blockchain[1],
the transaction records of all users are publicly available. By extracting the transaction

 
 
 
 
 
 
2

D. Zhang et al.

records on blockchain, we can construct a large graph-structured transaction data, bene-
ﬁts from which it is possible to discover the identity features of different users from the
blockchain transaction data through graph analysis methods[8]. Modeling as different
graph analysis tasks, such as node classiﬁcation[9,10], graph classiﬁcation[11,12], and
link prediction[13,14], can help us identify potential scammers and provide assistance
in solving ﬁnancial scam on blockchain.

The existing works[15,16,17,18] regard the phishing scam detection task as node
classiﬁcation. According to the transaction records between the target user and others,
they extract the identity feature of the target user from the transaction information such
as transaction address, transaction amount and timestamp. The unsupervised graph em-
bedding methods[15,16] based on random walk determine the process of random walk
according to the transaction amount and timestamp. Based on graph neural network
(GNN), [17] and [18] transform phishing scam detection task into a supervised dy-
namic node classiﬁcation problem by learning the structural and dynamic features of
the blockchain transaction network. It is worth noting that although these methods have
achieved satisfying performance on blockchain phishing scam detection, they are suf-
fered from high computational complexity since the node classiﬁcation task often takes
the transaction network containing all user nodes and transaction records as the input.
Considering the high-complexity of graph analysis on large-scale data, it is still a
challenge to propose a low-complexity phishing scam detection model. From the per-
spective of the graph-structured data, the two nodes with a larger shortest path length
can affect each other by transmitting messages through the edges. However, for the tar-
get node, it is often the node set in its neighborhood that has the greatest impact on
it. Since the GNN-based graph classiﬁcation methods[11,12] have achieved satisfying
performance in the real-world datasets. It may be a feasible solution to construct trans-
action pattern graphs based on the neighbor transaction records of the target user. We
transform the node classiﬁcation task with the whole large-scale transaction network
as input into a graph classiﬁcation task with multiple small-scale transaction pattern
graphs as input, which helps to achieve efﬁcient phishing scam detection. The main
contributions of our work are summarized as follows:

• We ﬁrstly deﬁned the transaction pattern graphs for blockchain transaction users.
Each user has its own small-scale transaction pattern graph, which makes it pos-
sible to detect potential phishing scammers with less computational complexity
through graph classiﬁcation.

• We proposed a multi-channel graph classiﬁcation model, namely MCGC. The
proposed MCGC has a multi-channel GNN architecture, which can automatically
extract richer information from the different pooling graphs.

• Extensive experiments conducted on seven benchmark and an Ethereum datasets
demonstrate that the MCGC achieves the state-of-the-art performance in graph
classiﬁcation task and can effectively detect the phishing nodes according to the
transaction pattern graphs.

Blockchain Phishing Scam Detection via Multi-channel Graph Classiﬁcation

3

2 RELATED WORK

Our work builds upon two categories of recent research: phishing scam detection and
graph classiﬁcation.

2.1 Phishing Scam Detection

Phishing scam detection methods can identify phishing scammers before the scam oc-
curs, or provide early warning for possible victims. In this section, we brieﬂy review
phishing scam detection methods, mainly categorized into random walk-based methods
and GNN-based methods.

Random walk-based methods. Wu et al.[16] proposed a novel network embedding
algorithm called trans2vec, which is composed of random walk sampling and node se-
quence embedding. According to the transaction amount and timestamp, trans2vec per-
forms biased random walk in the network to obtain a large number of node sequences,
which are used to extract the users’ node features. Wu et al.[15] further proposed T-
EDGE, whose main structure is similar to the main structure of trans2vec. The main
improvement of T-EDGE is to ensure the sequence of nodes during the random walk,
and it also solves the problem of multiple edges in the transaction network.

GNN-based methods. To make full use of the powerful learning representation abil-
ity of GNN, Pareja et al.[17] proposed EvolveGCN, which adapts the graph convolu-
tional network (GCN) model along the temporal dimension without resorting to node
embeddings. EvolveGCN captures the dynamism of the graph sequence through us-
ing an recurrent neural network (RNN) to evolve the GCN parameters. Tam et al.[19]
proposed a new message passing mechanism named EdgeProp, which allows multi-
dimensional continuous edge features propagating into node embeddings when per-
forming node classiﬁcation task.

In summary, whether it is a random walk or a GNN-based method, existing work
regards phishing scam detection as a node classiﬁcation task. When applied to the
blockchain transaction network, the huge number of nodes and transaction records lead
to the high-complexity of these detection methods.

2.2 Graph Classiﬁcation

Graph classiﬁcation can predict the graph-level labels of small-scale graphs, which has
achieved satisfying performance in real-world datasets such as bioinformatics and chem
-otherapy informatics. Here we brieﬂy introduce graph classiﬁers.

Narayanan et al.[20] proposed a neural embedding framework named Graph2vec to
learn data-driven distributed representations of arbitrary sized graphs. Graph2vec can
solve the problem of poor generalization ability of graph kernel methods[21,22] in an
unsupervised manner. Ying et al.[11] proposed a differentiable graph pooling method
named Diffpool, which aggregates the nodes into a new cluster as the input of the next
layer by the cluster assignment matrix. Due to the high complexity of the learning
cluster assignment matrix, the self-attention graph pooling (SAGPool)[23] considers
both node features and graph topology. SAGPool selects top-K nodes based on a self-
attention mechanism to form the induced subgraph for the next input layer. OTCOARS-
ENING proposed by Ma et al.[24] designs a coarsening strategy based on hierarchical

4

D. Zhang et al.

abstraction through minimizing discrepancy along the hierarchy, which can be com-
bined with unsupervised learning methods. GMN[25] introduces an efﬁcient memory
layer for GNNs that can jointly learn node representations and coarsen the graph.

3 PRELIMINARY

This section introduces the problem deﬁnition of the graph classiﬁcation and the phish-
ing scam detection on blockchain. We represent a graph as G = (V, E, A), where V
is the node set with |V | = N , ei,j =< vi, vj >∈ E is the edge between the node vi
and vj. A ∈ RN ×N is the adjacency matrix, where Ai,j (cid:54)= 0 denotes node vi directly
connected with vj while Ai,j = 0 otherwise. The graph G may contain an attribute
vector of each node in some case, here we denote the attribute vector of graph G as
A ∈ RN ×D, where D is the dimension of X. Generally, the adjacency matrix A con-
tains the information of V and E on graph G, so we use G = (A, X) to represent a
graph more concisely.

DEFINITION 1 (Graph classiﬁcation). For a graph classiﬁcation dataset Gset, it in-
cludes M graphs {G1, G2, ..., GM }. The graph classiﬁcation task aims to predict the
categories of unlabeled graph Gu ⊂ Gset through the model f graph
(·) trained by the
labeled graphs Gl = Gset − Gu with its corresponding label Y = (cid:2)y1, · · · , y|Gl|
DEFINITION 2 (Phishing scam detection on blockchain). On blockchain transaction
network, the node set V represents the users of the blockchain trading platform, and
E represents the transaction record set between different users. Here, there may be n
transactions {e0
i,j} between users vi and vj. The phishing scam detection
task aims to predict the categories of unlabeled nodes Vu ⊂ V f phishing
(·) trained by
the labeled nodes Vl = V − Vu with its corresponding label F = [τ1, · · · , τl], where
τi is the ground truth label of vi. τi = 1 denotes the node vi is a phishing node while
τi = 0 otherwise.

i,j, ..., en

i,j, e1

(cid:3).

θ

θ

4 METHODOLOGY

To transform the high-complexity node classiﬁcation task into a lower-complexity graph
classiﬁcation task on blockchain transaction network, we deﬁne the user transaction pat-
tern graphs for the ﬁrst time. Speciﬁcally, we take the whole graph-level representation
of the transaction pattern graph as the target user’s transaction pattern feature, which
provides a more efﬁcient method for phishing node detection. Additionally, to extract
richer information from the transaction pattern graphs, we propose MCGC, a graph
classiﬁcation model with a multi-channel GNN architecture, which aggregates the in-
formation of pooling graphs in multiple channels in a trainable manner, thus achieving
better graph classiﬁcation performance.

4.1 Transaction Pattern Graph Construction

In this part, we introduced the construction process of the transaction pattern graphs
for the Ethereum trading platform. We collected Ethereum transaction data from the

Blockchain Phishing Scam Detection via Multi-channel Graph Classiﬁcation

5

Ethereum trading platform (https://etherscan.io/) through Ethereum clients Geth and
Parity. Each transaction data in this website contains dozens of attributes, among which
the transaction timestamp, transaction sending and receiving address, and transaction
amount are the key information for constructing a transaction network. The sending
address and receiving address correspond to the nodes in the transaction network, the
transaction timestamp and the transaction amount indicate the existence edges and their
information between the corresponding node pairs. We reserve these transaction in-
formation from the original data to construct the transaction pattern graphs. The par-
tial transaction records and the process of constructing a transaction pattern graph are
shown in Fig.1. Fig.1(a) shows the partial transaction records of the target node v0 that
marked in red, and Fig.1(b) shows the construction process of the ﬁrst-order transaction
pattern graph of v0. The 4 transaction records in Fig.1(a) contain 4 different addresses,
corresponding to 4 edges and 4 nodes in the transaction graph.

Fig. 1. The process of Ethereum transaction pattern graph construction.

Through the above steps, we took the target node v0 as the central node, and ex-
tracted the user address of the other party as the ﬁrst-order transaction node based on the
transaction records. Then, the ﬁrst-order transaction nodes are regarded as the central
nodes, the second-order transaction nodes are extracted according to the same method.
Repeat this step until the designated K-order transaction pattern graph is constructed.
Different from a large-scale Ethereum transaction network used for node classiﬁca-
tion task, we constructed independent small-scale transaction pattern graph for each
node. There may be multiple transaction records between two transaction addresses on
blockchain transaction data, In this case, we merge multiple transaction records into
one transaction, taking the summed transaction amount as a new transaction amount
information, and the average timestamp as the new edge information.

Here, we choose the 1259 phishing nodes marked in [16] and the same number
of active normal nodes randomly selected in the same period as our target node set.
Besides, we set K = 4 to ensure that the transaction pattern graphs still contain enough
information after merging multiple transaction records.

4.2 Multi-channel Graph Classiﬁcation

Our proposed approach, MCGC, utilizes a multi-channel architecture to fuse the node-
level representations of different pooling graphs. The speciﬁc architecture of multi-
channel architecture is shown in Fig.2. The key intuition is that for each hierarchical

0123Transaction HashTimestampFromToValue00x3c7ca79ec6640c2f32c33db51e13817f7fa3a2e3678d12ec9f46726cc684c09315309303310x7c9bf15770f2fb6f769075fd632e9031a428c1620x516c3aa607d5bc41a5aa62192f72a3732261fd873.5465372510x2c6845395033cdfa7893db02d9b5ef692fca5acdcba321631e485733b2ade53d15315357380x7c9bf15770f2fb6f769075fd632e9031a428c1620x516c3aa607d5bc41a5aa62192f72a3732261fd878.5305675920x2db024dd7d285cfbfc1bb9851bad00181dc5f62f661361b1d1ce8cf96a835f3915431116880xe9063a1fcd386a818f67fadf03333efc0703e6980x516c3aa607d5bc41a5aa62192f72a3732261fd8730.55077930x612cae31c3b27617235903913e5824d8bcde3ed8933177d308459916d061595d15597286240x516c3aa607d5bc41a5aa62192f72a3732261fd870x855624b67a191cfa8489eb3b6bb93326e65e0795151.789728……v1v2v3v46

D. Zhang et al.

graph pooling layer of MCGC, we introduce a trainable node importance weights to
aggregate the node-level representations to the graph-level. Thus, we can capture the
important structural information for graph classiﬁcation from different pooling graphs.
After that, MCGC learns effective features from these structural information and out-
puts the ﬁnal graph classiﬁcation results.

Fig. 2. The speciﬁc illustration of multi-channel architecture in MCGC.

Hierarchical graph pooling. MCGC aggregates the nodes in the input graph into a
new node cluster through the node aggregation operation of the graph pooling layer,
thus obtaining the coarsened pooling graph structure. Multiple graph pooling layers
can extract different crucial hierarchical structure information of the input graph, which
helps us extract multi-level user transaction pattern information. In addition, the pool-
ing layer can be combined with GNNs to form an end-to-end training model, and has
demonstrated good performance on many real-world graph classiﬁcation datasets.

Speciﬁcally, MCGC employs the propagation function to implement the convolu-
tion layer for extracting the l-th node-level representation, which can be expressed as:

H l,k = σ( ˆAlH l,k−1W l,k)

(1)

2 ˜Al ˜D− 1

2 , Al is the l-th adjacency matrix of input graph G, and ˜Al =
where ˆAl = ˜D− 1
N is the adjacency matrix of the l-th pooling graph Gl with self-connections. I l
Al + I l
N
ij denotes the degree matrices of ˜Al. W l,k is the
is the identity matrix and ˜Dii = (cid:80)
parameters of the k-th propagation function in the l-th architecture. σ is the Relu active
function. When k = 1, H l,0 is the node attribute X l of the l-th architecture.

˜Al

j

The (l + 1)-th node-level representation H l+1 is usually obtained by running K
iterations of Eq.1. To achieve effective graph convolution with lower complexity, here
we choose K = 3. The convolution layer of the l-th architecture is denoted as:

H l+1 = GN Ncov(Al, X l; θl)
where H l+1 is computed computed from the l-th adjacency matrix Al and node attribute
X l. θl is the parameters set of the l-th architecture. The input A0 and X 0 are the original
adjacency matrix and node attributes on graph, i.e., A0 = A, X 0 = X, respectively.

(2)

Pooling directionPooling graphsGNNcovGNNcovGNNcovMulti-channel aggregationConcatenateFully connected layer LabelBlockchain Phishing Scam Detection via Multi-channel Graph Classiﬁcation

7

For the pooling layer, it calculates the cluster assignment matrix C l ∈ Rnl×nl+1
according to the topological structure and node representation of the current graph. The
cluster assignment matrix of the l-th architecture is:

C l = sof tmax (cid:0)GN Npool(Al, X l)(cid:1)

(3)

where GN Npool has the same structure as GN Ncov. nl and nl+1 represent the num-
ber of nodes in the l-th and the (l + 1)-th pooling graphs, respectively . Each row in
the C l represents the probability that the node is assigned to each node cluster in the
l +1-th layer. Generally, nl > nl+1, the pooling layer can coarsen the graph into a pool-
ing graph with a smaller number of nodes, which is helpful for extracting the crucial
structure of the original graph.

According to the adjacency matrix Al and node attribute X l of the l-th pooling
graph, the convolutional layer and the pooling layer obtain the node-level representation
H l and cluster assignment matrix C l of the l-th layer, respectively. Then the pooling
adjacency matrix Al+1 and the node attribute X l+1 of (l + 1)-th layer are calculated
by:

X l+1 = C lT

H l ∈ Rnl+1×d

Al+1 = C lT

AlC l ∈ Rnl+1×nl+1

(4)

(5)

where d denotes the feature dimension of each node. Eq. 4 aggregates the H l accord-
ing to the cluster assignments C l, generating a new pooling node attribute for each of
nl+1 clusters. Similarly, Eq. 5 generates a new pooling adjacency matrix based on the
adjacency matrix Al, denoting the connectivity strength between each pair of clusters.

Multi-channel structure. MCGC extracts L pooling graphs {G1(A1, X 1), ..., GL(AL,
X L)} from the original graph G(A, X) through L hierarchical graph pooling lay-
ers. The topological structure and node-level representations of these pooling graphs
reﬂect the multiple channel representations of G. Intuitively, the crucial graph struc-
tures learned by the pooling graphs of different channels are also different. We hope
to capture the relationship between different channels and graph-level representations
in a learnable manner, instead of simply using mean-pooling or max-pooling to ob-
tain graph-level representation. For the above considerations, we introduce a trainable
node importance weights for each pooling graph to learn its graph-level representation.
Speciﬁcally, for the l-th pooling graph, MCGC obtains its node-level representation
through the graph convolutional layer GN Ncov. The importance values of different
nodes in the current pooling graph are learned by the proposed trainable node impor-
tance weights, and then we aggregate the node-level representation of the pooling graph
into the graph-level by weighted summation, which can be expressed as:

Sl =

(cid:80) θl(i) · Zl(i)
(cid:80) θl

(6)

where Sl ∈ Rd denotes the graph-level representation of the l-th pooling graph.

Then, we combine the graph-level representations of the original graph and the
pooling graphs. MCGC preserves the multi-channel information of the graph as much

8

D. Zhang et al.

as possible by concatenating the graph-level representations of different pooling graphs
together. The global-level representation S ∈ R(L+1)d is denotes as:

S = concat(normal(S0), ...normal(SL))

(7)

where concat(·) denotes the concatenate function, which stitches the graph-level repre-
sentations of the original graph and the L − 1 pooling graphs. normal(Sl) = Sl/ (cid:80) Sl
is a normalization function, which converts the graph-level representation of each pool-
ing graph into a identity vector. It can avoid the inconsistency of the scope of graph-level
representations caused by the difference of the number of nodes.

Finally, we get the prediction probability of the input graph through the fully con-

nected layer with a softmax classiﬁer:

O = sof tmax(SW + b)
(8)
where W ∈ R(L+1)|Y | and b ∈ R|Y | denote the weight and bias of the fully connected
layer, respectively. |Y | is the number of labels in the graph dataset Gset.

Training procedure. The entire MCGC is an end-to-end model that can be trained
by stochastic gradient descent. For a set of graphs Gset, we employ the following loss
function L to train our MCGC, which can be represented as:

L = −

|Gset|
(cid:88)

|Y |
(cid:88)

Gi∈Gset

j=1

Qij ln Oij (Ai, Xi) +

L
(cid:88)

nl(cid:88)

l=1

i=1

1
nl

H(Cl(i))

(9)

(cid:9) is the category set of the graphs, Qij is the ground truth
where Y = (cid:8)y1, ..., y|Y |
with Qij = 1 if graph Gi belongs to category yj and Qij = 0 otherwise. Oij denotes
the predicted probability that graph Gi belongs to yj, which is calculated by Eq.8 and
can be considered as a function of Ai and Xi, thus we denote it as Oij (Ai, Xi). H(·)
denotes the information entropy function.

L consists of two parts. The ﬁrst part represents the cross-entropy of the classiﬁca-
tion prediction probability and the ground truth label, which can guide the prediction
probability to be closer to the ground truth label. The second part represents the infor-
mation entropy constraint of the cluster assignment matrix of the l-th layer, which helps
the row vector of the cluster assignment matrix to approach the ont-hot vector and better
learn the mapping relationship between nodes.

5 EXPERIMENTS

To verify the performance of MCGC, we conduct graph classiﬁcation experiments on
several benchmark graph classiﬁcation and an Ethereum transaction datasets. For each
dataset, we perform 10-fold cross-validation and report the average accuracy. In our
MCGC, we implement three hierarchical graph pooling layers, i.e., we set L = 3.
We use the Adam optimizer to optimize the model, and the learning rate is searched in
0.1,0.01,0.001. The feature dimension d is set by a hyper-parameter search in {32, 64, 12
8, 256, 512}. We implement our proposed MCGC with PyTorch, and our experimen-
tal environment consists of i7-7700K 3.5GHzx8 (CPU), TITAN Xp 12GiB (GPU),
16GBx4 memory (DDR4) and Ubuntu 16.04 (OS).

Blockchain Phishing Scam Detection via Multi-channel Graph Classiﬁcation

9

5.1 Datasets

To verify whether the multi-channel structure can better aggregate node-level repre-
sentation and the phishing node detection performance of MCGC, we select seven
benchmark and an Ethereum transaction datasets for our graph classiﬁcation experi-
ments. Among the benchmark datasets, two datasets are social network datasets, in-
cluding IMDB-BINARY and REDDIT-BINARY. The others are about bio-informatics
and chemo-informatics. Each dataset is composed of two classes of graphs. The basic
statistics are summarized in Table 1.

5.2 Baselines

To verify the performance of MCGC, we compare it with 5 advanced graph classiﬁca-
tion methods including Graph2vec[20], Diffpool[11], SAGPool[23], OTCOARSENING[24]
and GMN[25]. The speciﬁc method is introduced as follows:
Graph2vec. It establishes the relationship between a network and the rooted subgraphs.
It extracts rooted subgraphs and provides corresponding labels into the vocabulary, and
then trains a skipgram model to obtain the representation of the network.
DIFFPOOL. It learns a differentiable soft cluster assignment for nodes at each layer,
and generates hierarchical representations of graphs in an end-to-end manner.
SAGPool. Based on self-attention, It uses graph convolution to capture both node fea-
tures and graph topology. Compared with DIFFPOOL, this algorithm can learn hierar-
chical representations of graphs with fewer parameters.
OTCOARSENING. It designs a coarsening strategy based on hierarchical abstraction
through minimizing discrepancy along the hierarchy, which can be combined with un-
supervised learning methods.
GMN. It designs an efﬁcient memory layer for GNNs that can jointly learn node repre-
sentations and coarsen the graph. It consists of a multi-head array of memory keys and
a convolution operator to aggregate the soft cluster assignments from different heads.

Table 1. The basic statistics of eight datasets.

Dataset
MUTAG [26]
PTC [27]
PROTEINS [28]
NCI1 [29]
NCI109 [29]
IMDB-BINARY [21]
REDDIT-BINARY [21]
Ethereum

#Graphs #Classes #Ave nodes #Ave edges

188
344
1113
4110
4127
1000
2000
2518

2
2
2
2
2
2
2
2

17.92
14.29
39.06
29.87
29.69
19.77
429.63
120.43

20.42
14.69
72.82
32.30
32.13
96.53
497.75
130.08

10

D. Zhang et al.

5.3 Evaluation Metrics

The datasets in our experiment are all binary datasets, in which the number ratio of
positive examples to negative examples tends to 1. Therefore, we only use the accuracy
to evaluate the performance of different algorithm, which can be expressed as:

Accuracy =

T P + T N
T P + T N + F P + F N

(10)

where TP and TN are the number of positive and negative examples predicted correctly,
respectively. FP and FN are the number of positive and negative examples predicted
incorrectly, respectively.

5.4 Graph Classiﬁcation Performance

To better detect phishing nodes on blockchain transaction network through the powerful
learning representation ability of GNN, we transform the phishing detection task into a
graph classiﬁcation task with a smaller graph scale and lower training complexity. We
ﬁrst verify the performance of the proposed MCGC in the benchmark graph classiﬁca-
tion datasets. Compared with the baselines in Table 2, the proposed MCGC achieves
state-of-the-art performance among all benchmark datasets. Additionally, the perfor-
mance improvement of MCGC on the REDDIT-BINARY is more obvious. This may
be due to the most intuitive connection between the label of REDDIT-BINARY and
the topological structure of the graph. The graph structure generated by Q & A interac-
tion is usually similar to a star network, while the graphs of user discussion interaction
usually have no obvious central node.

Table 2. The graph classiﬁcation performance of seven datasets by various methods.

MUTAG PTC PROTEINS NCI1 NCI109 IMDB-BINARY REDDIT-BINARY

Methods
Graph2vec
Diffpool
SAGPool

83.15 61.59
80.60 62.00
78.60 61.39
OTCOARSENING 85.60 63.57
90.53 64.59
91.67 64.71

GMN
MCGC

73.30
75.90
73.30
74.90
75.78
78.91

73.22 74.26
74.29 74.10
74.18 74.06
76.18 68.50
73.17 73.26
76.54 76.36

62.74
75.20
72.20
74.60
77.00
77.00

59.07
86.19
73.90
76.53
87.36
91.00

Generally, the graph classiﬁcation performance of various graph classiﬁcation meth-
ods is different on bioinformatics datasets and social network datasets. For bioinfor-
matics datasets, the classiﬁcation results obtained by different methods are relatively
close. Since MUTAG, PTC, PROTEINS, NCI1, and NCI109 are all small-scale graphs,
they usually only contain dozens of nodes. The simple topology makes it easy to ex-
tract the structure information of these graphs. However, the hierarchical representa-
tion learning of graph begins to show its advantages for social network datasets with
complex structure. The classiﬁcation accuracy of Diffpool and other hierarchical graph
classiﬁcation methods on IMDB-BINARY and REDDIT-BINARY is 8%-10% higher

Blockchain Phishing Scam Detection via Multi-channel Graph Classiﬁcation

11

than Graph2vec. Since MCGC is based on the hierarchical structure of Diffpool, it ag-
gregates multi-channel hierarchical graph structure information in a learning manner,
which helps to better aggregate the node-level representation of hierarchical pooling
graphs into the graph-level, thus obtaining better graph classiﬁcation performance.

5.5 Phishing Node Detection on Blockchain Network

The blockchain account information based on the hash value of the public key makes
users further obscure the identity attribute information on the basis of pseudonyms.
This makes it difﬁcult to deﬁne a user’s identity features based on information other
than his account transaction records. Considering that it is still a huge challenge to
analyze large-scale data in deep GNN models, we transform the phishing scam detec-
tion into a small-scale graph classiﬁcation task. We learn the potential features of the
users by building transaction pattern graphs centered on these user nodes. In this part,
we conduct the graph classiﬁcation experiments on the transaction pattern graphs of
phishing and normal nodes. The performance of the proposed MCGC and baselines
are shown in Fig.3. We can see that in the Ethereum transaction network, MCGC can
still achieve state-of-the-art performance, which indicates that the proposed MCGC can
better extract the potential identity features of the transaction users.

Fig. 3. The graph classiﬁcation accuracy of Ethereum dataset.

To further investigate the reason why the hierarchical graph classiﬁcation methods
perform well on the Ethereum dataset, we visualize the topological structure of the
transaction pattern graphs of phishing nodes and normal nodes, respectively. Fig.4 (a)
are two transaction pattern examples of phishing nodes, and (b) are two transaction
pattern examples of normal nodes. The red node is the target user, the gray node is its
neighboring node, the red edge are the transaction records of the target user, and the gray
edges are the transaction records between neighboring nodes. Compared with normal
users, phishing users have fewer direct trading users. The nodes directly connected to
the phishing nodes often have a larger node degree value. They are usually exchange
addresses, which are used for asset management, currency exchange, and so on.

Hierarchical graph classiﬁcation methods such as MCGC can effectively aggregate
the nodes with a larger node degree value and their neighbor node sets. Normal nodes
are more likely to be aggregated, while phishing nodes tend to exist as independent
nodes in the next pooling graph. When the node-level representations are aggregated

MCGCGMNOTCOARSENINGSAGPoolDiffpool7374767577787980818212

D. Zhang et al.

into the graph-level, the feature vector of the phishing node tends to account for a larger
proportion, which instructs the graph classiﬁer to classify the input graph into the phish-
ing transaction pattern class.

Fig. 4. The visualization of phishing and normal transaction mode graphs.

5.6 Time Efﬁciency of Phishing Detection

In this part, we verify the time efﬁciency of the GNN-based phishing detector and
MCGC on the blockchain transaction network. Since EvolveGCN[17] and EdgeProp[19]
consider dynamic information or edge information based on GCN, respectively. They
have higher complexity than the traditional GCN. Therefore, we take the simplest GCN[9]
as an example to detect phishing scam on the blockchain transaction network. Speciﬁ-
cally, we select multiple nodes as the central nodes at the same time, and construct the
whole K-order transaction graph by the construction process in Section 4.1, which is
used in the GCN-based phishing scam detector.

Fig.5 shows the time efﬁciency of phishing scam detection under different node
scales for GCN and MCGC. When the number of nodes is small, GCN has higher time
efﬁciency. However, as the number of nodes increases, the computational complexity
of GCN increases rapidly. When the number of nodes exceeds 40k, the complexity of
MCGC is relatively lower. In addition, facing users newly added to the transaction net-
work, the phishing scam detectors based on node classiﬁcation may need to reconstruct
the transaction graph for retraining, while our MCGC can detect any newly added user
transaction pattern graph without retraining.

Fig. 5. The training time in each iteration when detecting different sizes of transction network.

(a) Phishing transaction pattern graphs(b) Normal transaction pattern graphs0102030405060708012345678GCNMCGC80706050403020100Training time (s)248610204080Number of nodes （k）Blockchain Phishing Scam Detection via Multi-channel Graph Classiﬁcation

13

6 CONCLUSION

In this paper, we ﬁrstly deﬁne the transaction pattern graphs for blockchain transaction
data, and propose a graph classiﬁcation model with a multi-channel GNN architecture,
named MCGC. To reduce the computational complexity of the phishing scam detection,
we transform the blockchain phishing scam detectopm into a graph classiﬁcation task,
and build the independent transaction pattern graphs for the target blockchain transac-
tion users. Moreover, to extract richer transaction pattern features from the transaction
pattern graphs, we regard the pooling graphs learned from different hierarchical graph
pooling layers as the multi-channel representations, and introduce a trainable node im-
portance weights to better aggregate the information of multi-channel pooling graphs.
Experiments on seven benchmark and an Ethereum datasets demonstrate that MCGC
can not only achieve the state-of-the-art performance in graph classiﬁcation task, but
also achieve effective phishing scam detection based on the target users transaction pat-
tern graphs.

References

1. M. Iansiti and K. R. Lakhani, “The truth about blockchain:,” Harvard business review,

vol. 95, no. 1, pp. 118–127, 2017.

2. Y. Yuan and F.-Y. Wang, “Blockchain and cryptocurrencies: Model, techniques, and appli-
cations,” IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 48, no. 9, pp.
1421–1428, 2018.

3. G. Wood et al., “Ethereum: A secure decentralised generalised transaction ledger,” Ethereum

project yellow paper, vol. 151, no. 2014, pp. 1–32, 2014.

4. W. Chen, Z. Zheng, J. Cui, E. Ngai, P. Zheng, and Y. Zhou, “Detecting ponzi schemes on
ethereum: Towards healthier blockchain technology,” in Proceedings of the 2018 World Wide
Web Conference, 2018, pp. 1409–1418.

5. M. Bartoletti, S. Carta, T. Cimoli, and R. Saia, “Dissecting ponzi schemes on ethereum:
identiﬁcation, analysis, and impact,” Future Generation Computer Systems, vol. 102, pp.
259–277, 2020.

6. EtherScamDB, “Etherscamdb.” [Online]. Available: https://blog.chainalysis.com/reports/

the\-rise-of-cybercrime-on-ethereum

7. M. Khonji, Y. Iraqi, and A. Jones, “Phishing detection: a literature survey,” IEEE Communi-

cations Surveys & Tutorials, vol. 15, no. 4, pp. 2091–2121, 2013.

8. Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, “A comprehensive survey on
graph neural networks,” IEEE transactions on neural networks and learning systems, 2020.
9. T. N. Kipf and M. Welling, “Semi-supervised classiﬁcation with graph convolutional net-
works,” in International Conference on Learning Representations, Toulon, France, 2017.
10. X. Wang, M. Zhu, D. Bo, P. Cui, C. Shi, and J. Pei, “Am-gcn: Adaptive multi-channel graph
convolutional networks.” New York, NY, USA: Association for Computing Machinery,
2020.

11. R. Ying, J. You, C. Morris, X. Ren, W. L. Hamilton, and J. Leskovec, “Hierarchical graph
representation learning with differentiable pooling,” in Proceedings of the 32nd International
Conference on Neural Information Processing Systems, ser. NIPS’18. Red Hook, NY, USA:
Curran Associates Inc., 2018, p. 4805C4815.

12. H. Wang, P. Zhang, X. Zhu, I. W.-H. Tsang, L. Chen, C. Zhang, and X. Wu, “Incremental
subgraph feature selection for graph classiﬁcation,” IEEE Transactions on Knowledge and
Data Engineering, vol. 29, no. 1, pp. 128–142, 2016.

14

D. Zhang et al.

13. L. Duan, S. Ma, C. Aggarwal, T. Ma, and J. Huai, “An ensemble approach to link prediction,”
IEEE Transactions on Knowledge and Data Engineering, vol. 29, no. 11, pp. 2402–2416,
2017.

14. C. Fu, M. Zhao, L. Fan, X. Chen, J. Chen, Z. Wu, Y. Xia, and Q. Xuan, “Link weight predic-
tion using supervised learning methods and its application to yelp layered network,” IEEE
Transactions on Knowledge and Data Engineering, vol. 30, no. 8, pp. 1507–1518, 2018.
15. J. Wu, D. Lin, Z. Zheng, and Q. Yuan, “T-edge: Temporal weighted multidigraph embedding

for ethereum transaction network analysis,” arXiv preprint arXiv:1905.08038, 2019.

16. J. Wu, Q. Yuan, D. Lin, W. You, W. Chen, C. Chen, and Z. Zheng, “Who are the phish-
ers? phishing scam detection on ethereum via network embedding,” IEEE Transactions on
Systems, Man, and Cybernetics: Systems, 2020.

17. A. Pareja, G. Domeniconi, J. Chen, T. Ma, T. Suzumura, H. Kanezashi, T. Kaler, T. Schardl,
and C. Leiserson, “Evolvegcn: Evolving graph convolutional networks for dynamic graphs,”
in Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 34, no. 04, 2020, pp.
5363–5370.

18. W. Chen, X. Guo, Z. Chen, Z. Zheng, and Y. Lu, “Phishing scam detection on ethereum:
Towards ﬁnancial security for blockchain ecosystem,” in International Joint Conferences on
Artiﬁcial Intelligence Organization, pp. 4506–4512.

19. D. S. Handason Tam, W. Cheong Lau, B. Hu, Q. F. Ying, D. M. Chiu, and H. Liu, “Identifying
illicit accounts in large scale e-payment networks–a graph representation learning approach,”
arXiv e-prints, pp. arXiv–1906, 2019.

20. A. Narayanan, M. Chandramohan, R. Venkatesan, L. Chen, Y. Liu, and S. Jaiswal,
preprint

representations

distributed

graphs,”

arXiv

of

“graph2vec: Learning
arXiv:1707.05005, 2017.

21. P. Yanardag and S. Vishwanathan, “Deep graph kernels,” in Proceedings of the 21th ACM
SIGKDD international conference on knowledge discovery and data mining, 2015, pp. 1365–
1374.

22. S. V. N. Vishwanathan, N. N. Schraudolph, R. Kondor, and K. M. Borgwardt, “Graph ker-

nels,” Journal of Machine Learning Research, vol. 11, pp. 1201–1242, 2010.

23. J. Lee, I. Lee, and J. Kang, “Self-attention graph pooling,” International Conference on Ma-

chine Learning, pp. 3734–C3743, 2019.

24. T. Ma and J. Chen, “Unsupervised learning of graph hierarchical abstractions with differen-

tiable coarsening and optimal transport,” arXiv preprint arXiv:1912.11176, 2019.

25. A. H. Khasahmadi, K. Hassani, P. Moradi, L. Lee, and Q. Morris, “Memory-based graph

networks,” arXiv preprint arXiv:2002.09518, 2020.

26. A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch,
“Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds.
correlation with molecular orbital energies and hydrophobicity,” Journal of medicinal chem-
istry, vol. 34, no. 2, pp. 786–797, 1991.

27. H. Toivonen, A. Srinivasan, R. D. King, S. Kramer, and C. Helma, “Statistical evaluation of
the predictive toxicology challenge 2000–2001,” Bioinformatics, vol. 19, no. 10, pp. 1183–
1193, 2003.

28. K. M. Borgwardt, C. S. Ong, S. Sch¨onauer, S. Vishwanathan, A. J. Smola, and H.-P. Kriegel,
“Protein function prediction via graph kernels,” Bioinformatics, vol. 21, no. suppl 1, pp. i47–
i56, 2005.

29. N. Shervashidze, P. Schweitzer, E. J. Van Leeuwen, K. Mehlhorn, and K. M. Borgwardt,
“Weisfeiler-lehman graph kernels.” Journal of Machine Learning Research, vol. 12, no. 9,
2011.

