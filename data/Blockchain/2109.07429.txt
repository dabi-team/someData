Towards a Game-Theoretic Security Analysis of
Off-Chain Protocols

Sophie Rain
TU Wien, Austria

Georgia Avarikioti
TU Wien, Austria

Laura Kov´acs
TU Wien, Austria

Matteo Maffei
Christian Doppler Lab Blockchain
Technologies for the Internet of Things
TU Wien, Austria

2
2
0
2

p
e
S
5
1

]

R
C
.
s
c
[

4
v
9
2
4
7
0
.
9
0
1
2
:
v
i
X
r
a

Abstract—Off-chain protocols constitute one of

the most
promising approaches to solve the inherent scalability issue of
blockchain technologies. The core idea is to let parties transact
on-chain only once to establish a channel between them, lever-
aging later on the resulting channel paths to perform arbitrar-
ily many peer-to-peer transactions off-chain. While signiﬁcant
progress has been made in terms of proof techniques for off-chain
protocols, existing approaches do not capture the game-theoretic
incentives at the core of their design, which led to overlooking
signiﬁcant attack vectors like the Wormhole attack in the past.
In this work we take a ﬁrst step towards a principled game-
theoretic security analysis of off-chain protocols by introducing
the ﬁrst game-theoretic model that is expressive enough to reason
about their security. We advocate the use of Extensive Form
Games (EFGs) and introduce two instances of EFGs to capture
security properties of the closing and the routing of the Lightning
Network. Speciﬁcally, we model the closing protocol, which relies
on punishment mechanisms to disincentivize parties to upload
old channel states on-chain. Moreover, we model the routing
protocol, thereby formally characterizing the Wormhole attack, a
vulnerability that undermines the fee-based incentive mechanism
underlying the Lightning Network.

This work is the extended version of our CSF 2023 paper
”Towards a Game-Theoretic Security Analysis of Off-Chain
Protocols”.

Index Terms—game theory, off-chain protocols, security, ratio-

nal players, Lightning Network

I. INTRODUCTION

Blockchain technologies are emerging as a revolutionary
paradigm to perform secure decentralized ﬁnancial applica-
tions. Nevertheless, a widespread adoption of cryptocurrencies,
such as Bitcoin [1] and Ethereum [2], is severely hindered by
their inherent limitations on transaction throughput [3], [4].
For instance, while Bitcoin can support tens of transactions per
second and the conﬁrmation time is about an hour, traditional
credit networks like Visa can comfortably handle up to 47,000
transactions per second.

Off-chain protocols [5] are recognized as one of the most
promising scalability solutions, achieving a seemingly contra-
dictory property: the bulk of transactions is performed off-
chain, and yet in a secure fashion. The idea is to leverage the
blockchain only in case of disputes, resorting otherwise to off-
chain, peer-to-peer transactions. Bitcoin’s Lightning Network
[6] is the most widely adopted off-chain instantiation, hosting
at the time of writing bitcoins worth more than 170M USD,
in a total of more than 27,000 nodes and more than 76,000
channels. In a nutshell, parties deposit money in a shared

address, called channel, and can later on perform arbitrarily
many off-chain transactions with each other by redistributing
the deposit on the channel. In the end, the channel can be
closed and the latest state (i.e., deposit distribution) is posted
on-chain. Off-chain transactions are not limited to the end-
point of the channel, but
they can be routed over paths
of channels (so-called multi-hop payments). Besides such
payment channel networks, an entire ecosystem of off-chain
protocols [5] (virtual channels, watchtowers, payment-channel
hubs, state channels, side-chains, etc.) is under development
for Bitcoin [7]–[12], Ethereum [13]–[16], as well as other
cryptocurrencies [17].

The cryptographic protocols underlying these off-chain con-
structions are rather sophisticated and, most importantly, rely
on game-theoretic arguments to discourage malicious behavior.
For instance, the Lightning Network relies on a punishment
mechanism to disincentivize parties to publish old states on-
chain and on an unlocking mechanism where parties ﬁrst pay
a neighbor and then retrieve the paid amount from the other
to ensure the atomicity of multi-hop payments (i.e., either all
channels are consistently updated or none is).

Off-chain protocols are typically subject to rigorous secu-
rity analyses, which however concentrate on cryptographic
properties and do not capture the game-theoretic ones. In
particular, most protocols are proven secure in the Universal
Composability framework [18], proving that the cryptographic
realization simulates the ideal functionality. This framework,
however, was developed to reason about security in the classi-
cal honest/Byzantine setting: in particular, the ideal function-
ality has to model all possible parties’ behavior, rational and
irrational, otherwise it would not be simulatable, but reasoning
on whether or not certain behavior is rational is outside of the
model and thus left to informal arguments. This is not just a
theoretical issue, but a practical one, as there is the risk to
let attacks pass undetected: for instance, the Wormhole attack
[7] constitutes a rational behavior in the Lightning Network,
which is thus admitted in any faithful model thereof although
it undermines its incentive mechanism. The ﬁrst step towards
closing this gap in cryptographic proofs is to come up with a
faithful game-theoretic model for off-chain protocols in order
to reason about security in the presence of rational parties.
We address this challenge in this paper, advocating the use of
Extensive Form Games (EFGs) for the game-theoretic security
analysis of off-chain protocols. In particular, we introduce two

 
 
 
 
 
 
instances of EFGs to model the closing and the routing of the
Lightning Network.

A. Related Work

A game-theoretic model for off-chain protocols is initiated
and introduced in [19]. This work suffers, however, from
several limitations, which make it unsuitable to conduct faith-
ful security analyses. Firstly, the game model considers only
honest closing of channels, i.e., all deviations – such as posting
an old state – are ignored: this makes it impossible to reason
about
the security of basic channel operations. Secondly,
the pay-offs are represented as constants, which neglects the
dependency of the channel’s balance on its security properties.
Further, fees are not considered at all, thereby ignoring their
impact on Lightning protocols. For instance, the routing game
to model the security of multi-hop payments fails to capture
already identiﬁed attacks in payment channel networks, like
the Wormhole attack [7] that targets the fee distribution among
players. Additionally, Lightning is vulnerable to the Grieﬁng
attack [20], where a signiﬁcant amount of money is locked.
In our work, we overcome the aforementioned limitations,
by deﬁning a stronger closing phase model, by aligning the
utilities to the monetary outcome, by considering all possible
deviations of parties during closing, and by revising the
relevant security properties. We demonstrate the importance
of precision in game-theoretic protocol models by modeling
the Wormhole attack, as well as the Grieﬁng attack.

Our work further complements other game-theoretic ad-
vancements in the area, most prominently the following lines
of research.

a) Incentivizing Watchtowers: A major drawback of
payment channel protocols is that channel participants must
frequently be online and watch the blockchain to prevent
cheating. To alleviate this issue, the parties can employ third
parties, or so-called watchtowers, to act on their behalf in
case their counterparty misbehaves. Correctly aligning the
incentives of watchtowers to yield a secure payment channel
protocol is, however, challenging. This is the main focus of
several works [11], [15], [16], [21]. As their objective is to
incentivize external parties, their models does not apply in
our work.

b) Payment Channel Network Creation Games: Avariki-
oti et al. [22], [23] study payment channel networks as network
creation games. Their goal is to determine which channels a
rational node should establish to maximize its proﬁt. Ersoy
et al. [24] undertake a similar task; they formulate the same
problem as an optimization problem, show it is NP-hard, and
present a greedy algorithm to approximate it. Similarly to our
work, all these works assume rational participants. However,
we aim to model the security of the protocols, in contrast to
these works that study the network creation problem graph-
theoretically.

c) Blockchains with Rational Players: Blockchains in-
centivize miners to participate in the network via monetary
rewards [1]. Therefore, analyzing blockchains under the lens of
rational participants is critical for the security of the consensus

layer. There are multiple works in this direction: Badertscher
et al. [25] present a rational analysis of the Bitcoin protocol.
Eyal and Garay [26] introduce an attack on the Nakamoto
consensus, effectively demonstrating that rational miners will
not faithfully follow the Bitcoin protocol. This attack is
generalized in [27], [28]. Consequently, Kiayias et al. [29]
analyze how miners can deviate from the protocol to optimize
their expected outcome. Later, Chen et al. [30] investigate
the reward allocation schemes in longest-chain protocols and
identify Bitcoin’s allocation rule as the only one that satisﬁes
a speciﬁc set of desired properties. On a different note, several
works study the dynamics of mining pools from a game-
theoretic perspective [31], [32] or introduce network attacks
that may increase the proﬁt of rational miners [33], [34]. An
overview of game-theoretic works on blockchain protocols can
be found in [35].

All these works, however, focus on the consensus layer
(Layer-1) of blockchains and as both the goals and assump-
tions are different from the application layer (Layer-2), the
models introduced there cannot be employed for our purposes.
For instance, payment channel protocols occur off-chain and
thus game-based cryptographic assumptions of the blockchain
do not apply. In addition, consensus protocols investigate the
expected reward of miners which is a probabilistic problem,
whereas we ask if any honest player could lose money,
which depends on the behavior of the other players and is
fundamentally deterministic.

Game-based deﬁnitions have also been proposed for the
security analysis of smart contracts [36], [37]. These models,
however, target an on-chain setting and are thus not suitable
to reason about the speciﬁcs of off-chain constructions (e.g.,
closing games, routing games, etc.).

B. Our Contributions

In this work, we take the ﬁrst steps towards closing the
gap between security and game-theoretic analysis of off-chain
protocols. Speciﬁcally, we introduce the ﬁrst game-theoretic
models that are expressive enough to reason about the security
of off-chain protocols. We model off-chain protocols as games
and then analyze whether or not certain security properties
are satisﬁed. The design of our models is driven by two
principles: (a) all possible actions should be represented and
(b) the utility function should mirror the monetary outcome
realistically. We aim to ensure that honest participants do not
suffer any damage (P1), whereas deviating from the protocol
yields a worse outcome for the adversary (P2) We will
use weak immunity (Deﬁnition II.4) to implement (P1), and
collusion resilience (Deﬁnition III.8) together with practicality
(Deﬁnition III.7) for (P2). While we believe that our approach
of implementing principles (a) and (b) is easily extensible
to other off-chain protocols, in this work we focus on the
Bitcoin Lightning Network, which constitutes the most widely
adopted off-chain protocol. Our technical contributions can be
summarized as follows:

2

• We reﬁne existing game-theoretical concepts in order to
reason about the security of off-chain protocols (Sec-
tion III).

• We introduce the Closing Game Gc,

the ﬁrst game-
theoretic security model that accurately captures the clos-
ing phase of Lightning channels, encapsulating arbitrary
deviations from the protocol speciﬁcation (Section IV).
• We perform a detailed security analysis of Gc, formalize
folklore security corner cases of Lightning, and present
the strategy that rational parties should follow to close
their channels in order to maximize their expected out-
come relative to the current and previous distribution
states (Section V).

• We identify limitations in prior work [19] on game-
based modeling of multi-hop payments, putting forward
a new game-based deﬁnition that is precise enough to
cover the Wormhole and the Grieﬁng attack (Section VI).
We further show how to model Fulgor protocol [38], a
variant of Lightning’s routing that prevents the Wormhole
attack. Our formalization leverages game theory concepts
introduced in Section III and Section IV, thereby demon-
strating the theoretical expressiveness of our framework
to analyze complex protocols. .

In conclusion, our work brings game-theoretical foundations
to enforce security of off-chain protocols, by providing a rigor-
ous analysis over security properties expressed through formal
requirements over game strategies. We believe, the provided
rigor in our paper opens up new venues for automating security
analysis via game-theoretic arguments, a challenge which we
aim to tackle in future work.1

II. BACKGROUND AND PRELIMINARIES

A. Payment Channel Networks

A payment channel [8] can be seen as an escrow (or multi-
signature), into which two parties Alice A and Bob B transfer
their initial coins with the guarantee that their coins are not
locked forever and the agreed balance can be withdrawn at
any time. After that, A and B can pay each other off-chain
by signing and exchanging messages that reﬂect the updated
balances in the escrow. These signatures can be used at any
time to close the channel and distribute the coins on-chain
according to the last channel state. In order to discourage
parties from posting an old state on-chain, a punishment
mechanism is in place. In particular, in Lightning [6], once
A closes the channel, she has to wait a mutually agreed time
before getting her coins. Meanwhile, B has the opportunity to
withdraw all the coins in the channel (by posting a so-called
revocation transaction), including the ones assigned to A, if the
state posted on-chain by A is not the last one they mutually
agreed on. Such a punishment mechanism is of game-theoretic
nature: parties can indeed post an old state on-chain, yet they
are discouraged to do so.

1We refer the interested reader to the appendix for the complete deﬁnitions

and proofs.

In particular, Lightning payment channels operate as fol-
lows: First, Alice and Bob create a funding transaction where
they input their respective coins; the funding transaction has
if both A and B
a single output
that can only be spent
provide their signature (2-out-of-2 multi-signature). Then, the
two parties create the ﬁrst commitment transaction, i.e., a
transaction that spends the output of the funding transaction
and returns the initial coins to both parties. In other words,
the input of the commitment transaction is the output of the
funding transaction while the output of the ﬁrst commitment
transaction is two-fold: the ﬁrst output returns the coins to
A and the second output to B. However, the commitment
transaction each party holds is not the same. Speciﬁcally,
the commitment transaction of A has an additional spending
condition, a timelock t that signiﬁes the revocation period and
is pre-agreed between the two parties; in A’s commitment
transaction B’s output is spendable immediately. Symmetri-
cally, in B’s commitment transaction B’s output has a timelock
t while A’s output is spendable immediately. Note that a
timelock t is a condition that allows the coins of the output
to be spent on-chain only after time t has elapsed from the
publication of the transaction. After A and B sign and exchange
the respective ﬁrst commitment transactions, they proceed to
signing the funding transaction and publishing it on-chain.
This order is important to avoid hostage situations2. As soon
as the funding transaction is securely published on-chain, A
and B can transact off-chain by creating every time a new
commitment transaction that depicts the current balance of
the joint capital among the two parties. Every time a new
commitment transaction is created, the parties reveal a secret
to their counterparty that allows their counterparty to spend
their own coins immediately (e.g., A can spend B’s coins
from the previous commitment) if the previous commitment
transaction appears on chain (revocation transaction). To close
a Lightning channel, the two parties can either collaborate
and spend the output of the funding transaction, or each of
them can close the channel unilaterally by publishing the last
commitment transaction. Since the commitment transactions
each party hold have a timelock, in case of cheating, i.e.,
publication of a previous commitment transaction on-chain,
the counterpart can immediately spend the cheating party’s
coins, claiming all the coins of the channel, thus punish the
cheating party for misbehaving.

Technically, A and B do not just lock their initial funds
but also a certain small amount which will be used as a fee
for the closing transaction of the channel. Note that every on-
chain transaction requires such a fee f . The fee for the opening
transaction is paid upon the opening of the channel and is thus
irrelevant to our consideration. However, in case A posts an
old state on-chain and B performs the revocation transaction
– which is an on-chain transaction – to prove it, B has to
carry the additional transaction fee alone. These facts have an
important impact on our game-theoretic models.

2If the funding transaction is published on-chain before the ﬁrst commit-
ment transactions are signed, a party may hold the other hostage since none
of the parties can close the channel unilaterally but only in collaboration.

3

A

(m + 3 f ,y,t1)

2.

9.

x

E1

(m + 2 f ,y,t2)

3.

8.

x

y

I

(m + f ,y,t3)

4.

7.

x

1.

E2

(m,y,t4)

5.

6.

x

B

A

E1

(m + 2 f ,y,t2)

3.

(m + 3 f ,y,t1)

2.

8.

x

1.

E2

(m + f ,y,t3)

4.

7.

y

I

x

B

(m,y,t4)

5.

6.

x

Fig. 1. Routing in Lightning using HTLCs.

Fig. 2. Wormhole Attack in Lightning.

In the following, we refer to honest closing when a party
unilaterally closes the channel by posting the last commitment
transaction or when the parties close collaboratively, where
both parties sign to spend the funding transaction output
directly.

Off-chain transactions are not limited to the end-points of
a channel, as they can be performed whenever sender and
receiver are connected by a path of channels with enough
capacity. The cryptographic approach to do so exploits hash-
time-locked-contracts (HTLC) [12]. Assume players A and B
do not share a channel. Instead, A has a channel with E1; E1
has a channel with I; I has a channel with E2; and E2 has a
channel with B, as illustrated in Figure 1. Player A can now
send an amount m to player B via the intermediaries E1, I and
E2, where each intermediary charges a fee f for the routing
service, hence A should pay m + 3 f . The core idea is that A
pays E1, E1 pays I, and so forth, until B gets paid.

A key security property in multi-hop payments is atomicity:
either all payments are successful, and the deposit in each
channel is updated accordingly, or none is. To achieve this
property, the Lighting protocol proceeds as follows. First, the
receiver B generates a secret x and sends its hash h(x) = y to
the sender A (see action 1 in Figure 1). Then A creates an
HTLC for E1, where she locks m + 3 f with lock y and time-
out t1. That means only E1 can claim the money and only
by providing a value whose hash is y within time t1 (action
2 in Figure 1). Although E1 does not know such a value yet
and can therefore not unlock, E1 can nevertheless proceed by
creating another HTLC for I also locked with y and a time-
out t2 (action 3 in Figure 1). Thereafter, I and E2 continue
in the same way (actions 4 – 5 in Figure 1). Actions 1 – 5
of Figure 1 are called the locking phase. Note that in order
to allow everybody to unlock their HTLCs in the subsequent
steps, the time-outs have to be decreasing t1 > t2 > t3 > t4.
Once B receives the conditional payment, he can reveal x to E2
and the conditional payment is unlocked (action 6 in Figure 1).
The others can now unlock the HTLCs one after the other from
right to left (actions 7 – 9 in Figure 1), which is called the
unlocking phase. Finally, A paid m + 3 f , B received m and
each intermediary was rewarded with f .

a) The Wormhole Attack: The aforementioned routing
protocol is proven to be vulnerable to the Wormhole attack [7],
which is depicted in Figure 2. The attack is as follows: E1
and E2 collude, and bypass I in the unlocking phase, thus
stealing I’s participation reward f . Until actions 6 in Figure 1
and Figure 2, the behavior is identical. Then, E2, knowing x,
forwards x to E1 (ofﬂine) instead of unlocking the HTLC from
I (action 7 in Figure 2). This way, E1 can unlock A’s HTLC
and claim the money (action 8), but I will never be able to
unlock. After a certain time the remaining HTLCs time-out
and the locked money returns to the creators.

Therefore, the parties A and B are not affected. However,
E1 and E2 collectively earn 3 f instead of the 2 f they deserve,
stealing the fee f from I, who locked resources in the locking
phase of the protocol. This attack undermines the incentive of
intermediaries to route payments.

b) The Grieﬁng Attack: It describes the scenario when a
player, assume B for simplicity, ignores the proposed payment
and refuses to proceed [20]. This way, money is locked in
the conditional payments for a considerable amount of time.
While [39] studies the Grieﬁng attack through probabilistic
modelling and [40] provides mitigation techniques, to the best
of our knowledge there is no formal security analysis of this
attack at present. Our work addresses this limitation and shows
that Lightning’s routing module is indeed susceptible to the
Grieﬁng attack.

In the sequel we consider the behavior as illustrated in

Figure 1 as the only honest routing behavior.

B. Game-Theoretic Deﬁnitions

We now introduce the game-theoretic concepts relevant for
our formalization. We denote real numbers by R and tuples
as σ = (σ1, ...,σn). We write σ[σ′
i /σi] to denote the tuple
resulting from substituting σi by σ′
i in σ, that is σ[σ′
i /σi] =
(σ1, ...,σi−1,σ′
i ,σi+1, ...,σn). We understand games as static
objects in which ﬁnitely many players can choose ﬁnitely
many times from a ﬁnite set of actions. A game yields a certain
positive or negative utility for each player. We brieﬂy overview
the very common Normal Form Games, also called Strategic
Games [41], in which each player chooses an action only once,
called strategy.

We note that atomicity is achieved by a game-theoretic
argument: intermediaries can, in principle, stop the protocol
either in the locking phase or in the unlocking phase. In the
former, they would lose the transaction fee f , while in the
latter, they would lose the payment amount m, m + f , m + 2 f
respectively. Thus, they are incentivized to act once they have
committed to participate.

Deﬁnition II.1 (Normal Form Game – NFG). A Normal Form
Game (NFG) is a tuple Γ = (N, S , u), where N is the set of
game players, S = "p∈NSp the set of joint strategies σ and
u the utility function:

• Sp is the non-empty set of strategies player p can choose
from. Thus, a joint strategy σ ∈ S is a tuple of strategies
σ = (σp1, ...,σp|N|), with σpi ∈ Spi.

4

TABLE I
NFG ΓC WITH PLAYERS A,B.

B

A
U
C
I

U

C

I

(1/2,1/2)
(1,0)
(1,0)

(0,1)
(1,1)
(−1,−1)

(0,1)
(−1,−1)
(−1,−1)

• u = (up1, . . . , upn), where upi : S → R assigns player pi

its utility for every joint strategy σ ∈ S .

In what follows we ﬁx an arbitrary game Γ and give all
deﬁnitions relative to it. To formalize an optimal outcome on
game strategies, we use Nash Equilibria.

Deﬁnition II.2 (Nash Equilibrium – NE). A Nash Equilibrium
is a joint strategy σ ∈ S s.t. no player pi can increase
their utility by unilaterally deviating from σ = (σp1, ...,σp|N|),
Formally,

∀p ∈ N ∀σ′

p ∈ Sp : up(σ) ≥ up( σ[σ′
Another important concept is weakly dominated strategies,
expressing the strategies a rational player would not play since
they yield worse utilities.

p/σp] ) .

(1)

Deﬁnition II.3 (Weakly Dominated Strategy). A strategy σd
Sp of player p is called weakly dominated by strategy σ′
Sp, if it always yields a utility at most as good as σ′
strictly worse utility at least once:
∀σ ∈ S : up( σ[σd
∃σ ∈ S : up( σ[σd

p /σp] ) ≤ up( σ[σ′
p /σp] ) < up( σ[σ′

p/σp] ) and
p/σp] ) .

p ∈
p ∈
p and a

(2)

(3)

Example II.1. Consider the NFG ΓC in Table I, which was
introduced in [19] to model closing. In this game ΓC, there
are two players N = {A, B} and each players can choose from
the same strategy set SA = SB = {U,C, I}. Here, strategy U
captures unilateral closing, that is publishing the latest state
on-chain. Further, strategy C corresponds for closing collab-
oratively, that is publishing a mutually signed transaction.
Finally, strategy I stands for ignoring, that is doing nothing.
The utility for each joint strategy is given in Table I, where
player A’s strategies are listed in the left column of Table I
and the strategies of B are given in the top row of Table I.

Applying Deﬁnition II.2, the joint strategies (C,C), (U, I)
and (I,U) are Nash Equilibria: for each of
these joint
strategies, neither A nor B can deviate in order to increase
their own utility. Comparing the second and the third row of
Table I, we see that A’s utility is always as least as good in
the second row as it is in the third row. Hence, strategy C
weakly dominates strategy I for player A, by Deﬁnition II.3;
the same property also holds for player B. By comparing the
other pairs of rows/columns of Table I, we see that there is no
other weak dominance in ΓC.

C. Game-Theoretic Security Properties of Off-Chain Protocols

We now present existing game-theoretic concepts [19],
[41] implying security properties of off-chain protocols. In
Section III, we extend these concepts towards another type of

5

games, called Extensive Form Games, enabling our security
analysis in Section IV. We focus on two security properties
ensuring that (P1) honest players do not suffer damage, and
(P2) subgroups of rational players do not deviate from a
respective strategy. A protocol is compliant to these properties,
if the strategy implementing the intended behavior satisﬁes
them; we call such a strategy an honest strategy.

(P1) No Honest Loss. As the utility function of a game is
supposed to display the monetary and intrinsic value of
a certain joint strategy, property (P1) is expressed using
weak immune strategies deﬁned next.

Deﬁnition II.4 (Weak Immunity). A joint strategy σ ∈ S in
an NFG Γ is called weak immune, if every player p that
follows σ gets utility at least 0, regardless of how the other
players behave:

∀p ∈ N ∀σ′ ∈ S :

up( σ′[σp/σ′

p] ) ≥ 0 .

(4)

Example II.2. In the game ΓC of Table I, the only weakly
immune strategy is (U,U). This is the case, because as long
as A chooses U, player B can take any strategy and A will
never get negative utility (similarly, vice-versa).

(P2) No Deviation. Even though the concept of Nash Equi-
libria seems to be a good candidate to ensure (P2) at
ﬁrst glance, they have two crucial shortcomings. First,
a Nash Equilibrium only ensures that a single player
cannot proﬁt from deviating, but does not imply that two
or more players cannot do so. Second, there might be
Nash Equilibria, which are weakly dominated by another
strategy for a speciﬁc player. Such Nash Equilibria will
therefore not be played by rational parties and hence
should not be considered to satisfy (P2).

The solution proposed for NFGs in [19] is to consider
if they are both strongly
strategies σ compliant
resilient (ﬁxing the former shortcoming) and practical (ﬁxing
the latter) as deﬁned subsequently.

to (P2),

Strong resilience extends Nash Equilibria by considering

deviations of multiple players.

Deﬁnition II.5 (Strong Resilience – SR). A joint strategy
σ ∈ S in an NFG Γ is strongly resilient (SR) if no proper
subgroup of players S := {s1, ..., s j} has an incentive in
deviating:

∀S ⊂ N ∀σ′

si ∈ Ssi ∀p ∈ S :

up(σ) ≥ up( σ[σ′

s1 /σs1, ...,σ′

s j /σs j ] ) .

(5)

We note that in games with two players (i.e. two-player
games), strong resilience and Nash Equilibrium are identical.
As such, in ΓC from Table I, the joint strategies (C,C), (U, I)
and (I,U) of Example II.1 are also strongly resilient.

To deﬁne practicality of a strategy, we ﬁrst introduce the
concept of iterated deletion of weakly dominated strategies
(IDWDS).

TABLE II

III. EFG-BASED MODELING OF OFF-CHAIN PROTOCOLS

NFG Γ′

C OBTAINED FROM IDWDS OVER TABLE I.

B

A
U
C

U

C

(1/2,1/2)
(1,0)

(0,1)
(1,1)

Deﬁnition II.6 (Iterated Deletion of Weakly Dominated Strate-
gies – IDWDS). The iterated deletion of weakly dominated
strategies (IDWDS) of an NFG Γ is deﬁned as iteratively
rewriting Γ by omitting all weakly dominated strategies of all
players. This is repeated until no strategy is weakly dominated
any more. The resulting game Γ′ is thus a subgame of Γ.

Note that, when IDWDS is applied to a game Γ, then every
Nash Equilibrium of the resulting game Γ′ is also a Nash
Equilibrium of Γ. Since all weakly dominated strategies of
every player are removed at each step, the generated game is
unique. Details and proofs can be found in [41].

We now deﬁne practical strategies, in order to ensure that

no single strategy is weakly dominated at any iteration.

Deﬁnition II.7 (Practicality). A strategy is practical if it is
a Nash Equilibrium of the NFG Γ′ after iterated deletion of
weakly dominated strategies.

Example II.3. Let us consider ΓC from Table I. We know from
Example II.1 that only I is weakly dominated for both A and
B. Therefore, according to Deﬁnition II.6, strategy I has to be
removed from both player’s strategy set. This yields the game
Γ′
C as listed Table II.
Note that there are no weakly dominated strategies in Γ′

C .
Thus, any Nash Equilibrium of Γ′
C is also practical strategy
of ΓC. By comparing utilities, we derive that the only Nash
Equilibrium of Γ′
C is the joint strategy (C,C).

An alternative approach for expressing (P2) is by requiring
a strategy σ to be both a strong Nash Equilibrium (a property
similar to SR) and practical, instead of SR and practical.

Deﬁnition II.8 (Strong Nash Equilibrium – sNE). A joint
strategy σ is a strong Nash Equilibrium (sNE) if for every
group of deviating players S := {s1, ..., s j} and all possible
si ∈ Ssi, i ∈ {1, ..., j} at least one player p ∈ S
deviations σ′
has no incentive to participate, that is
si ∈ Ssi ∃p ∈ S :

∀S ⊆ N, S 6= /0 ∀σ′

up(σ) ≥ up( σ[σ′

s1/σs1, ...,σ′

s j /σs j ]).

(6)

Example II.4. In ΓC from Table I, all NE are also sNE. For
the joint strategy (C,C), this is easy to see. However, it is also
the case for (U, I) and (I,U), since any deviation yields a
utility of at most 1. Thus, at least one player’s utility does not
increase by deviating from (U, I), (I,U) respectively.

A detailed comparison of the various concepts ensuring
(P2) including their strengths and weaknesses, is given in
Section III.

So far we considered games in which each party takes only
one action. We now extend our deﬁnitions to handle adaptive
strategies, i.e., games in which parties take several actions
and choose at each step which action to take based on the
actions previously chosen by other parties. As we will see,
this is necessary for faithfully modeling off-chain protocols
and overcoming the limitations of previous work [19]. For
that, we overview the concept of extensive form games (EFGs)
in Section III-A. We show how to lift NFG-based security
deﬁnitions to EFGs in Section III-B. Finally, we show that
these deﬁnitions do not yet sufﬁce to yield an accurate security
model of off-chain protocols, and introduce a reﬁned security
deﬁnition based on the concept of collusion resilience in
Section III-C.

A. Extensive Form Games (EFG)

To formalize strategies where players make multiple choices
one after the other, we advocate the usage of Extensive Form
Games (EFGs) [41], which extend NFGs as follows.

Deﬁnition III.1 (Extensive Form Game – EFG). An Extensive
Form Game (EFG) is a tuple Γ = (N, H , P, u), where N and u
are as in NFGs. The set H captures game histories, T ⊆ H
is the set of terminal histories, and P denotes the next player
function, satisfying the following properties.

• The set H of histories is a set of sequences of actions

with
1) /0 ∈ H ;
2) if the action sequence (ak)K
k=1 ∈ H ;

also (ak)L

3) a history is terminal (ak)K
aK+1 with (ak)K+1
k=1 ∈ H .
• The next player function P

k=1 ∈ H and L < K, then

k=1 ∈ T , if there is no action

history (ak)K

1) assigns the next player p ∈ N to every non-terminal
k=1 ∈ H \ T , that is P((ak)K
2) after a non-terminal history h = (ak)K

k=1) = p;
k=1 ∈ H , it is
player P(h)’s turn to choose an action from the action
set A(h) = {a : (h, a) ∈ H }.

A strategy of player p is a function σp mapping every h ∈ H
with P(h) = p to an action from A(h). Formally,

σp : {h ∈ H : P(h) = p} → {a : (h, a) ∈ H , ∀h ∈ H } ,
such that σp(h) ∈ A(h). The set of all strategies of a player p
is Sp, and the set of all joint strategies is S = "p∈NSp.

Note that

the set of terminal histories T is uniquely
determined by H and therefore does not explicitly occur in
the tuple Γ. Since histories h are just sequences of actions
h = (ak)K
k=1 = (a1, ..., aK), we denote histories by the variable
h,
k=1, or the explicit sequence
(a1, ..., aK), depending on the context in which they are used.
We note that EFGs can conveniently be represented as trees,
as described below.

the abstract sequence (ak)K

Deﬁnition III.2 (EFG as Tree). Considering an EFG Γ =
(N, H , P, u), the following tree G = (V, E) represents Γ.

6

a

A

b

c

B

(2, 2)

(3, 1)

d

e

A

(1, 1)

f

g

B

i

(0, 1)

(0, 2)

By adjusting the concept of Nash Equilibrium to subgames,

we derive the following property of joint strategies.

Deﬁnition III.4 (Subgame Perfect Equilibrium). A subgame
perfect equilibrium is a joint strategy σ = (σ1, ...,σn) ∈ S ,
s.t. σ|h = (σ1|h, ...,σn|h) is a Nash Equilibrium of the subgame
Γ(h), for every h ∈ H . The strategies σi|h are functions that
map every h′ ∈ H|h with P|h(h′) = i to an action from A|h(h′).

Fig. 3. An EFG ΓE .

B. EFG Extensions for Security Properties

• For every history h ∈ H , there exists exactly one node
vh ∈ V . This is labeled by P(h), the next player, if h is not
terminal (h /∈ T ), or by u(σ), the joint utility of playing
a game with history h, if h is terminal (h ∈ T ) and the
joint strategy σ yields history h.

• Two nodes vh, vh′ ∈ H are connected via an oriented
edge (vh, vh′) ∈ E iff h′ = (h, a). This edge is labeled a.

Let us illustrate EFGs and their tree-based representation

through the following example.

tree

III.1. The game

Example
in Figure 3 results
from the extensive form game ΓE = (N, H , P, u) with
the two players N = {A, B}, where the set of histories
is H = { /0, (a), (b), (b, c), (b, d), (b, d, e), (b, d, f ), (b, d, f , g),
(b, d, f , i)}. The next player function P assigns player A after
histories /0 and (b, d), and player B after (b) and (b, d, f ).
Finally, the utility function u assigns joint utility (2, 2) to
strategies that yield history (a), utility (3, 1) for strategies with
history (b, c), utility (1, 1) for strategies with history (b, d, e),
and (0, 2) for strategies resulting in (b, d, f , i). A strategy
σ = (σA,σB) in ΓE is for example: A chooses a after history
/0: σA( /0) = a; and f after (b, d): σA((b, d)) = f ; B takes c
after (b): σB((b)) = c, and g after (b, d, f ): σB((b, d, f )) = g.
Following this strategy until we read a leaf yields history (a).
A different strategy σ′ = (σ′
A,σ′
B), which also yields history
A((b, d)) = e and σ′
A( /0) = a, σ′
(a), is for example σ′

B = σB.

As depicted in the tree-based representation of Figure 3, we
note that the utility of joint strategies in an EFG is uniquely
determined by their associated history (i.e., path).
In the
context of EFGs, the concept of Nash Equilibria remains as
given in Deﬁnition II.2. In addition to Nash Equilibria, another
useful concept for EFGs is the Subgame Perfect Equilibrium,
which we will use to characterize the strategies played in
practice by rational parties. To this end, we ﬁrst introduce the
notion of subgames of EFGs. A subgame of an EFGs can be
seen as a subtree determined by a certain history (i.e., whose
root note is the last history node), and is formalized below.

Deﬁnition III.3 (Subgame of EFG). The subgame of an
EFG Γ = (N, H , P, u) associated to history h ∈ H is the
EFG Γ(h) = (N, H|h, P|h, u|h) deﬁned as follows: H|h :=
{h′ | (h, h′) ∈ H }, P|h(h′) := P(h, h′), and u|h(h′) := u(h, h′).

Example III.2. Consider the EFG ΓE from Figure 3 . The
subgame of ΓE associated to history (b, d) is the subtree rooted
in A.

7

While EFGs enable us to incorporate choices made at dif-
ferent times yielding different options for the next player, they
come with the following limitation. The intended (i.e., honest)
behaviors in off-chain protocols only specify a terminal history
(i.e., a path from root to leaf), rather than a strategy. For
instance, an honest history may specify to close the channel
collaboratively, but it does not capture a player’s behavior once
a player deviated. To address this limitation, we introduce the
following notion of an extended strategy in EFGs.

Deﬁnition III.5 (Extended Strategy). Let β be a terminal
history in an EFG Γ. Then, all strategies σβ that result in
history β are extended strategies of β.

Example III.3. Recall Figure 3. In Example III.1, we consider
the terminal history (a) and provide two extended strategies
of (a), they are σ and σ′. A strategy, which is not an extended
strategy of (a) is for instance σ′′ = (σ′′
A ,σ′′
A ( /0) =
b, σ′′
B = σB. This is the case because by
following the choices of A and B in σ′′, we end up in (b, c).

A ((b, d)) = e and σ′′

B ), where σ′′

While EFGs can in principle be translated to NFGs, as
explained in [41], analyzing the security properties (P1)-(P2)
over the translated NFGs may yield unexpected results. We
shortly exemplify this point in Example III.4, but similar issues
occur also in larger games. We thus lift NFG-based deﬁnitions
to EFGs, enabling the analysis of (P1) and (P2). Since EFGs
have a utility function just as NFGs do, which assigns values
after the game, the NFG concepts of weak immunity, strong
resilience and sNE remain the same for EFGs.

Deﬁnition III.6 (EFG Properties). A joint strategy σ ∈ H
of an EFG Γ is called weak immune, strongly resilient, or
a strong Nash Equilibrium,
it satisﬁes the formulae of
if
Deﬁnition II.4, Deﬁnition II.5 or Deﬁnition II.8 respectively.

Practicality in NFGs, however, relies on IDWDS, which
fails to incorporate the sequential nature of EFGs, and hence
must be adjusted for EFGs. This is because NFG actions
happen simultaneously, while EFG players choose their actions
sequentially. We ﬁrst present an example to showcase that
applying the NFG deﬁnition of practicality to an EFG, by
using its translation to an NFG, leads to overlooking rational
strategies.

Example III.4. Let us consider the EFG ΓE from Figure 3,
with two players A and B. The compact translation of ΓE
to an NFG ΓN is given in Table III. Histories of Figure 3,
where players choose twice, such as (b, d, f ), are translated

TABLE III
COMPACT VIEW OF ΓE , TRANSLATED TO AN NFG ΓN .

the utilities of the deviating parties, since rational players may
collude or be controlled by the same entity.

B

A
a
b;e
b; f

c

d;g

d;i

(2,2)
(3,1)
(3,1)

(2,2)
(1,1)
(0,1)

(2,2)
(1,1)
(0,2)

to Table III as the joint strategy (b; f , d). Hence, the NFG
strategy b; f of player A means choosing action b ﬁrst, and,
if A gets to choose again, A takes f . Player A’s strategies
are displayed in the rows, whereas player B’s are shown in
the columns of Table III. Strategy d; g for example denotes
choosing d in the ﬁrst turn and g in the second turn, unless
the game ends before. For readability, strategies with identical
utilities in any case are merged together, e.g., having only a
instead of both a; e and a; f .

According to deﬁnition of practicality for NFGs (see Deﬁ-
nition II.7), the only practical strategy in ΓN is (a, d; i), which
results in a utility of (2, 2). This is because for A strategy b; e
weakly dominates b; f and for B strategy d; i weakly dominates
both c and d; g. After deleting those (in blue), the red strategy
b; e of A becomes weakly dominated by a. Thus, after removing
b; e only the joint strategy (a, d; i) remains and is therefore a
Nash Equilibrium of the resulting game.

However, in the EFG ΓE the comparison of strategies has
a certain order, as not all choices are made simultaneously.
Thus, when it comes to B choosing between option c and d,
choosing c is also a rational action because in any case B
gets utility 1. This is the case, since the subgame following
after d, will end in the subgame perfect and practical (1, 1),
if played by rational players. Following this argumentation,
we claim that (b; e, c), yielding history (b, c) should also be
considered rational and thus practical.

Example III.4 demonstrates that it is advisable to adapt
the NFG concept of practicality for EFGs, and that a n¨aive
application can be problematic since information may be lost
during the transformation from EFG to NFG [41]. We there-
fore propose to use subgame perfect equilibria for comparing
EFG strategies, and deﬁne practicality for EFGs as follows.

Deﬁnition III.7 (Practicality for EFG). A strategy of an EFG
Γ is practical if it is a subgame perfect equilibrium of Γ.

C. Security Strategies for Off-Chain Protocols

We now leverage the previously introduced EFG-based def-
initions (Section III-B) to faithfully model the security of off-
chain protocols.
In particular, we propose the novel concept
of collusion resilience for addressing (P2), and compare it to
existing formalizations of property (P2).

In [19], strong resilience and practicality were used to model
the no deviation property of (P2): We identify unwanted prop-
erties of strong resilience and we thus investigate variations
of it. Speciﬁcally, we show that strong Nash Equilibria do
not imply strong resilience nor vice-versa (Lemma III.1), and
therefore deﬁne the collusion resilience property of a joint
strategy. Intuitively, collusion resilience considers the sum of

Deﬁnition III.8 (Collusion Resilience – CR). A joint strategy
σ ∈ S in an EFG/NFG Γ is called collusion resilient (CR)
if no strict subgroup of players S := {s1, ..., s j} has a joint
incentive in deviating from σ. That is,
si ∈ Ssi :
up(σ) ≥ ∑
p∈S

∀S ⊂ N ∀σ′
∑
p∈S

s1/σs1, ...,σ′

s j /σs j ] ).

up( σ[σ′

(7)

In addition, we also consider a slight adaption of strong
resilience, SR⊆, where the deviation of the entire set of players
N is also allowed, as it is for sNE.

Deﬁnition III.9 (Strong Subset Resilience – SR⊆). A joint
strategy σ ∈ S is called strongly subset resilient (SR⊆), if no
player of any subgroup S ⊆ N, S := {s1, ..., s j} has an incentive
to deviate from σ:

∀S ⊆ N ∀σ′

si ∈ Ssi ∀p ∈ S :

up(σ) ≥ up( σ[σ′

s1 /σs1, ...,σ′

s j /σs j ] ) .

(8)

We now formalize how the resilience properties relate to

each other, which motivates our deﬁnition of (P2).

Lemma III.1 (Resilience Properties). Let σ ∈ S be a joint
strategy. The following and only the following implications
hold.

1) σ is SR⊆ ⇒ σ is SR, CR, sNE.
2) σ is SR ⇒ σ is CR.

SR

SR⊆

CR

sNE

The next example further motivates why we decided to

formalize (P2) in terms of collusion resilience.

Example III.5. Consider the games Γ1 and Γ2, respectively
deﬁned in Tables IV-V. The games Γ1 and Γ2 show that
there exist cases where both strong resilience and strong Nash
Equilibria fail to correctly state whether rational players will
deviate, while collusion resilience does not.

Let us study Γ1 ﬁrst. There are three players P1 on the
left, P2 in the “3rd dimension” who only has one possible
strategy, and P3 at the top. Let us consider the joint strategy
σ = (H1, H2, H3). Since P2 does not have another choice, P2
can never deviate. Player P1 deviating alone yields the same
utility as σ and is thus irrelevant. The same holds for P3. The
only deviation that makes a difference, is if P1 and P3 change
strategy together to (D1, H2, D3). By doing so, P1 proﬁts and
receives 5 instead of 1, but P3 looses by getting −2 instead
of 1. Thus, P3 does not have an incentive to do so, unless
the two players collude for their mutual beneﬁt and share
their payoffs. This way they receive 1.5 each instead of 1
each, which poses a serious thread to σ and should thus not
be considered satisfying (P2). However, (H1, H2, H3) is sNE,
since P3 has no incentive in deviating with P1, if their utilities

8

TABLE IV
THREE PLAYER GAME Γ1.

TABLE V
THREE PLAYER GAME Γ2.

H 2
H1
D1

H3
(1,1,1)
(1,1,1)

D3
(1,1,1)
(5,0,−2)

H 2
H1
D1

H3
(1,1,1)
(1,1,1)

D3
(1,1,1)
(3,0,−2)

are not shared, but it is not CR, since

2 = uP1(H1, H2, H3) + uP3(H1, H2, H3)

(9)
(10)

< uP1(D1, H2, D3) + uP3(D1, H2, D3) = 3 .
In the similar game Γ2, on the contrary, P3 has no incentive
in deviating from σ = (H1, H2, H3) together with P1, also if
their utilities are shared. Such a deviation yields 0.5 each,
instead of 1 each in σ. Hence, there is no incentive to change
strategy for one or more players and therefore (H1, H2, H3)
should be considered satisfying (P2). Nevertheless, according
to Deﬁnition II.5, (H1, H2, H3) is not SR, since at least one of
the deviating parties P1, P3 proﬁts from choosing (D1, H2, D3),
although P3 has no reason to play along. However, in Γ2,
(H1, H2, H3) is CR as

2 = uP1(H1, H2, H3) + uP3(H1, H2, H3)

≥ uP1(D1, H2, D3) + uP3(D1, H2, D3) = 1 .

(11)
(12)

Remark 1 (Formalizing ((P1) and (P2)). Based on the re-
silience properties of Lemma III.1, we say (P2) is satisﬁed by
a joint strategy σ, if σ is CR and practical. In addition, a
joint strategy σ satisﬁes (P1), if σ is weak immune, as in
[19].

We conclude this section by deﬁning secure game strate-

gies/histories, as follows.

Deﬁnition III.10 (Secure Strategy). A strategy σ of an
NFG/EFG is secure if it is weak immune, practical and CR.

When discussing security in the setting of EFGs, we are
interested mainly in assessing whether a history is secure, as
the protocol only deﬁnes an honest history instead of a full
strategy. By applying Deﬁnition III.5, we state the following
security characterization.

Deﬁnition III.11 (Secure History). A terminal history β of
an EFG is secure if there exist extended strategies σ1, σ2, and
σ3 of β, such that σ1 is weak immune, σ2 is practical and σ3
is CR.

We note that we do not have to ﬁnd a secure extended
strategy for the history to be secure, as aiming for one joint
secure strategy in an EFG would be unnecessarily restrictive.
Instead, our goal is to make sure that rational parties follow
the honest history, no matter what their actual strategy is.
In particular, an honest player follows the honest history
by default, a rational player does so because of practicality
and collusion resistance. Weak immunity further ensures that
honest players as well as rational one cannot be damaged by
Byzantine players while following the honest history. Hence,
the strategy each player has in mind does not matter, since
in a secure protocol weak immune, practical, and collusion

9

resistant, strategies are overlapping along the honest history.
This is the case because in Deﬁnition III.11 we require σ1,
σ2, and σ3 to all yield the same history, namely β. We can
therefore admit that an honest player has a weak immune
strategy in mind, while a rational player has a practical one,
as long as these overlap on the honest history.

IV. CLOSING GAMES OF OFF-CHAIN PROTOCOLS

We now deﬁne a new two-player EFG, called the Closing
Game Gc, in order to model closing phase properties of off-
chain protocols, in particular of the Lightning Network. As
explained in Section II-A, to close a channel a party can
unilaterally publish a channel state on-chain, which does not
necessarily have to be the latest one. The one who closes,
however, has to wait a certain amount of time until the money
can be used. Meanwhile, the other party can steal all the money
from the channel in case the state published on-chain is not
the latest one: this ensures that rational players close their
channel only with the latest state. Alternatively, the parties
can collaboratively sign a new transaction to split the money.
In this case no one has to wait.

Our closing game overcomes the limitations of previous
work [19] in representing dishonest closing attempts, by mod-
eling how closing can be achieved after a failed collaborative
closing attempt and by also considering the additional fee f
to be paid in a revocation transaction.

To the best of our knowledge, our closing game Gc is the
most accurate model for the security analysis of off-chain
protocols, notably of the Lightning Network. In our model
of the closing phase we make the following assumptions for
a channel between A and B at the moment where the closing
phase is initiated.

• The fair split of the channel’s funds is a → A, b → B and

a > 0, b > 0.

• The beneﬁt of closing the channel is α. Closing a channel

yields a beneﬁt, since it unlocks assets.

• The opportunity cost of having to wait for one’s funds

upon closing is ε.

• When both players agree to update the channel we assume
a fair deal in the background which yields a proﬁt of ρ
for both parties.

• Publishing a revocation transaction on-chain costs a fee

f > 0.

Further, to properly model utilities in the closing game
Gc, we deﬁne the following total order, which is crucial for
analyzing security properties of Gc. For capturing total order
properties in the setting of Gc, we extend the set R of real
numbers by the inﬁnitesimal numbers α, ε and ρ.

Deﬁnition IV.1 (Utility Order). We consider the total or-
der (U, 4), where U is the group resulting from closing
R ˙∪ {α,ε,ρ} under addition. The total ordering 4 is uniquely
deﬁned by the following conditions.

1) On R, the relation 4 is the usual less than or equal

relation 4 |R := ≤.

TABLE VI
POSSIBLE ACTIONS IN Gc(A).

H Close unilaterally and honestly without reacting to a previous move,

such as a collaborative closing attempt.

D Close unilaterally but dishonestly (without reacting to a previous move)
with a proﬁt of dA ∈ (0,b] in A’s case, dB ∈ (0,a] in B’s case.
Ch Try to close collaboratively and honestly, that is proposing a fair split.
Cc Try to close collaboratively but by cheating the other party by c ∈

S
I
P

(0,b], that means proposing an unfair split.
Signing the collaborative closing attempt of the other player.
Ignore the previous action and do nothing.
Prove other party tried to close dishonestly. That means stating a
revocation transaction. We assume its publication requires a fee of
f > 0 and that the attempt to do so is always successful, that is that
the miners behave honestly.

U + Propose an update of the channel where player A’s balance is increased

by pA ∈ (0,b].

U − Propose an update where player A’s balance is decreased by pB ∈

(0,a].

A Agree to a proposed update.

2) The values α, ε and ρ are greater than 0,

∀ξ ∈ {α,ε,ρ} : −ξ ≺ 0 ≺ ξ .

(13)

3) The values α, ε and ρ are closer to 0 than any real

number,

∀x ∈ R,ξ ∈ {α,ε,ρ}, x > 0 : ξ ≺ x, −x ≺ −ξ.

(14)

4) Additionally, α, ε and ρ have the order ρ ≺ ε ≺ α.

In general, unlocking funds gives additional ﬁnancial free-
dom even if there is some processing delay; therefore, we
choose ε ≺ α in Deﬁnition IV.1. Additionally, once the parties
initiate the closing phase, it is reasonable to assume that no
potential update signiﬁcantly beneﬁts both parties. In contrast,
both parties are interested in avoiding the opportunity cost,
i.e., the cost of having to wait for their funds upon closing,
therefore, we set ρ ≺ ε in Deﬁnition IV.1.

Remark 2. While the ordering conditions of Deﬁnition IV.1
may seem to be restrictive,
lifting them comes with the
burden of considering a high number of possible vari-
able orderings. In particular, one would need to consider
(number of variables)! orderings, which would highly com-
plicate the formal analysis task. Approximating or clustering
the number of orderings, while weakening conditions in Deﬁ-
nition IV.1, is an interesting venue for future work.

Based on the utility ordering of Deﬁnition IV.1, we intro-

duce our Closing Game for Player A below.

Deﬁnition IV.2 (Closing Game Gc(A) of Player A). The Clos-
ing Game Gc(A) = (N, H , P, u) is an EFG with two players
N = {A, B}. The tree representation of Gc(A) in Figure 4
deﬁnes H , P and u3, with the actions of the game being
summarized in Table VI.

Note that the utility function u of Gc(A) in Figure 4 assigns
player p ∈ N the money player p received minus the money
player p deserved based on the latest channel state. The
values of closing (α), updating (ρ) and waiting (−ε) are also

3The subgames Si, S′

i are given in the appendix.

A

D

P

H

Ch

B

I

Cc

(−a, a − f + α)

B

(dA + α− ε, −dA + α)

(α,α − ε)

(α,α − ε)

H

D

U+

U−

S′
3

S

I

(α− ε,α)

B

H

D

U+

S3

U−

I

S

S4

(α,α)

A

A

(c + α, −c + α)

S′
4

P

P

I

I

(b − f + α, −b)

(b − f + α, −b)

A

(−dB + α, dB + α− ε)

(−dB + α, dB + α− ε)

A

H

I

S2

D

B

U−

U+

S1

P

I

(α− ε,α)

(α− ε,α)

(−a, −b)

(−a, −b)

H

I

S′
2

U−

U+

D

B

S′
1

P

I

(−a, a − f + α)

(−a, a − f + α)

(dA + α− ε, −dA + α)

(dA + α− ε, −dA + α)

Fig. 4. Closing Game Gc(A).

considered in Figure 4. As discussed in Section II-A, the fee
needed for the closing transaction is assumed to have been
reserved among the locked funds in the channel all the time
and is spent upon closing, therefore not affecting the players’
channel balance.

The closing game for player B, Gc(B) is deﬁned similarly
to Gc(A), with the roles of A and B being swapped in
Deﬁnition IV.2. Based on the closing games Gc(A) and Gc(B),
we consider the closing phase in an off-chain channel as given
in Figure 5 and deﬁned below.

Deﬁnition IV.3 (Closing Phase). The closing phase of an off-
chain channel modeled by a closing game Gc(A) is initiated
in one of three ways: (i) A starts with a closing action C, and
thus triggers the closing game Gc(A); (ii) A does not start a
closing action, thus performing action ignore I, but B starts
with a closing action C and triggers Gc(B); or (iii) none of
the players A and B ever start closing, that is B also choosing
action I, in which case the money stays locked in the channel.
Then, we get the EFG ΓC from Figure 5 modeling the closing
phase of Gc(A) and Gc(B).

10

A

C

I

B

C

Gc(A)

Gc(B)

I

(−a, −b)

Fig. 5. Closing Phase ΓC.

V. CLOSING GAMES FOR SECURE LIGHTNING CHANNELS

We now show that the closing games from Deﬁnition IV.2
precisely capture secure closing phases in Lightning chan-
nels [6]. Namely, the following two terminal histories of clos-
ing games model the honest behavior of Lightning: (i) history
(H) from Figure 4 represents unilateral honest closing of A,
yielding utility (α−ε,α); and (ii) history (Ch, S) captures the
attempt of A to close collaboratively and honestly, while B
signs, with a utility of (α,α). Our security analysis focuses
on these two honest histories of Lightning channels.

Deﬁnition V.1 (Honest Closing). The only honest histories in
the closing game Gc(A) are the terminal histories (H) honest
unilateral closing and (Ch, S) honest collaborative closing. All
strategies yielding one of the two histories are considered
honest strategies.

In the following, the values dA (resp. dB) deﬁned in Table VI
(line D) represent the difference of funds between the latest
state and the old one that is dishonestly posted on chain by
A (resp. B). In other words, if (a, b) is the latest state, the
one posted on chain is (a + dA, b − dA) (resp. (a − dB, b + dB)),
thus enabling dishonest closing attempts of proﬁt dA for A
(resp. dB for B). The values pA,B (Table VI, lines U +, U −)
and c (Table VI, line Cc) can respectively be chosen by A
and B at the time of the action and do not depend on previous
distribution states. Based on this setting, we derive the security
properties (P1) and (P2) of Lightning channels as given below.
The omitted proofs are given in the appendix.

Theorem V.1 (Weak Immunity of Honest Behavior – (P1)).
The terminal histories (H) of honest unilateral closing, and
(Ch, S) of honest collaborative closing of Gc(A) are weak
immune,
the channel balances are higher than the fee
required in a revocation transaction, that is if a ≥ f and b ≥ f .

if

Theorem V.1 implies that as long as both players have a
minimal balance of f
in the channel, no honest player can
lose money. As such, Theorem V.1 establishes the security
property (P1) ensuring “no honest loss” in the channel.

Further, to ensure the security property (P2) of “no devia-

tion”, we require that

a − pB + dA ≥ f
b − pA + dB ≥ f .

and

(15)
(16)

To understand the inequations (15)-(16) consider the history
(Ch, I,U −, A, D) in Figure 4, respectively S′
1. This history for-
malizes the case where A attempts honest collaborative closing
(action Ch) and B ignores it (action I). Then A proposes an
update (action U −) from state (a, b) to state (a − pB, b + pB)
and B agrees (action A). Finally, A closes dishonestly (action

D) using the old distribution state (a − pB + dA, b + pB − dA).
Let us also study the options B has. By ignoring A’s behavior
(action I), B receives b + pB − dA instead of the fair amount
b + pB,
leaving B with a loss of dA. By publishing the
revocation transaction (action P), B receives a + b but has to
pay the fee f for pushing it on the blockchain, which leads
to a win of a − pB − f . Therefore, the win should be greater
than the loss; hence

a − pB − f ≥ −dA ⇔ a − pB + dA ≥ f ,

(17)

in order for a rational B to publish the revocation transaction.
This in turn yields a loss for A and hence discourages A
from closing dishonestly, which is necessary for the incentive
compatibility (P2) of Lightning’s closing phase. By swapping
A’s and B’s roles, we get
the prerequisite formulated in
(16). These extreme cases of dishonest closing subsume the
others. Thus, the only preconditions we need in the following
Theorem V.2 are (15)–(16). In summary, formulas (15)–(16)
ensure that ignoring any dishonest closing attempt is worse
than publishing the revocation transaction. Property (P2) is
then established by the following theorem.

Theorem V.2 (Incentive-Compatibility – (P2)). If a − pB +
dA ≥ f and b − pA + dB ≥ f , then

1) honest unilateral closing (H) is CR, but not practical.
2) honest collaborative closing (Ch, S) is CR. It is practical

iff c 6= pA.

Remark 3 (Explanation of c 6= pA). The condition c 6= pA
in Theorem V.2 has the following relevance. Player A can
in principle choose to propose dishonest collaborative closing
(action Cc), providing A an unfair advantage of value c. Then,
either B (action U +) or A (B choosing action I to ignore
ﬁrst, then A taking action U +) can propose a channel update
(a, b) 7→ (a + c, b − c). The value of the update pA is now
equal to the amount player A cheated with in Cc: pA = c.
In this special case, the closing game behaves differently.
The described histories (Cc, I,U +) and (Cc,U +) lead to the
subgames S′
3 with
pA = c.

3 respectively. Let us consider S′

1 and S′

Assume A agrees to the update, action A, and player B
signs the initially unfair collaborative closing attempt of A.
Since in the meantime the channel was updated by the exact
amount that A tried to cheat with, the pending collaborative
closing now contains the fair split. Therefore, both players
proﬁt from this course of action, yielding utility (ρ+α,ρ+α).
The analog can be achieved in subgame S′
1 with the history
(A, I, S). In fact, for pA = c, those histories are the only
practical ones and provide the mutually best outcome possible.
However, updating to (a + c, b − c) ﬁrst and then closing
honestly and collaboratively yields the exact same result. This
is why we study the closing game without the possibility of up-
dating after a closing attempt in the next section Section V-A.

We now state our ﬁrst main security theorem. Since (H)
is not practical, a rational player will not play it. Hence,
the terminal history (H) is not secure. We get the following

11

security result instead for (Ch, S).

Theorem V.3 (Security of Gc(A)). If a ≥ f , b ≥ f , a − pB +
dA ≥ f , b − pA + dB ≥ f , and c 6= pA, then the closing game
Gc(A) together with the honest behavior (Ch, S) is secure.

Proof. As a ≥ f and b ≥ f , we have that (Ch, S) is weak
immune (Theorem V.1). Since a − pB + dA ≥ f , we derive
b − pA + dB ≥ f and c 6= pA, we have that (Ch, S) is also
practical and CR (Theorem V.2). Hence, by Deﬁnition III.11,
(Ch, S) is secure.

Theorem V.3 implies that for honest and rational players the
action of collaborative closing followed by signing (Ch, S) is
the best way to close an off-chain channel. It also implies, that
rational adversaries will cooperate. Further, Byzantine players
represent no threat as long as their channel balances are high
enough and they do not engage in special cases of channel
updates after a collaborative closing attempt.

We note that for proving our security properties (P1)-(P2)
in Theorem V.1–Theorem V.3, we rely on a succinct analysis
of the ﬁnite graph properties of the closing game GC(A)
from Figure 4. While automated approaches analyzing a ﬁnite
number of graph properties exist, see e.g. [42], [43], these
approaches cannot handle (game) graphs where graph leaves
contain variables, instead of speciﬁc numerical values, which
is the case of GC(A). For such cases, automated reasoning
tools, such as theorem provers, need to be combined with
graph-theoretic manipulations of GC(A), an approach we aim
to investigate as a future work towards automating the security
analysis (and proofs) of closing games.

A. Closing Games without Updates

We will now consider a variation of closing games without
updates, as updating is not beneﬁcial for at least one player
upon closing. Furthermore, we avoid special cases such as
the one described in Remark 3, which should be equivalent
to updating before initiating Gc(A), and then closing honestly
and collaboratively. As such, the closing game Gc(A) without
updates results from removing all actions U + and U − in
Figure 4. For the resulting closing game Gc(A) without updates
we get the following security result similar to Theorem V.3.

Theorem V.4 (Security of Gc(A) without Updates). If a ≥ f
and b ≥ f , then the closing game Gc(A) without updates and
together with both honest histories (H) and (Ch, S) is secure.

Proof. We respectively ﬁx honest strategies σ and σ′ for
histories (H) and (Ch, S); let σ′ have A choosing Ch initially, P
after (Ch, D) and H after (Ch, I), and then B choosing S after
(Ch), P after (D) and H after (Cc). Infer that the deviation of A
causes negative utility for B, whereas the deviation of B leads
to non-negative utility for A as b − f ≥ 0. By Theorem V.1 we
thus have that σ′, and therefore (Ch, S), are weak immune. In
addition, Theorem V.1 implies that also (H) is weak immune.
To show practicality, we compute all subgame perfect
terminal histories. From a ≥ f and b ≥ f we have a + dA ≥ f
and b + dB ≥ f . Since closing with a dishonest behavior yields

utility a − f + α, b − f + α respectively, whereas ignoring
a dishonest behavior leads to −dA + α and −dB + α, we
conclude that the best choice after action D is always P. Thus,
A’s best choice after (Ch, I) and (Cc, I) is H. Therefore, B has
the two subgame perfect options I and S after (Ch), and only
I after (Cc), yielding thus the following practical histories:
history (Ch, S) with utility (α,α); and (Ch, I, H), (Cc, I, H),
and (H) each with utility (α−ε,α). Therefore, both (H) and
(Ch, S) are practical.

Note that every practical terminal history is a Nash Equi-
librium, since if a deviation could beneﬁt a player, the player
would have chosen differently already. As CR is equivalent
to Nash Equilibria in two-player games (by Deﬁnition II.5
and Lemma III.1), we use Deﬁnition III.7 and Lemma III.1 to
conclude that practicality of (H) and (Ch, S) implies collusion
resistance CR of (H) and (Ch, S). As (H) and (Ch, S) are both
weak immune, practical and CR, by Deﬁnition III.11 we infer
that they are also secure.

Remark 4. Note that the analysis of utilities in the closing
game Gc(A) crucially depends on constraints of the under-
lining ordering that we set in Deﬁnition IV.1, and thus on
the values of variables a, b, c, dA,B, f in Table VI. In general,
the bigger ε gets in Deﬁnition IV.1, the more discouraged
is closing unilaterally in Table VI, and hence in Figure 4.
Further, B is more likely to accept a dishonest collaborative
closing attempt Cc, as it is better to lose c than to lose ε.

We further study what happens if a player has almost no
funds left in a channel. In particular, we show that security
properties, in particular weak immunity and practicality, are
violated in this case, thereby formalizing the following folklore
in the community.

Theorem V.5 (Little Funds). If a < f , then only terminal
histories that involve an explicit cheating attempt are weak
immune in the closing game Gc(A) without updates. A terminal
history involves an explicit cheating attempts if one of its
actions is Cc or D.

Proof. Let σ be any strategy, yielding a history that does not
involve an explicit cheating attempt. Then A can deviate to a
strategy where A chooses D as its ﬁrst action. In this case, the
honest B gets negative utility, no matter whether B chooses P
or I, since a < f . Hence, only histories that involve explicit
cheating attempts can be weak immune.

We next derive the following results on security properties.

Corollary 1. If there exists an old channel state (a + dA, b −
dA), with a + dA < f , then neither history (H) nor (Ch, S) is
weak immune nor practical, but CR.

Corollary 2. A rational party should never, in any channel,
let the opponent’s balance fall below f , because at that point
the other party can always cause ﬁnancial loss by closing
dishonestly and unilaterally4.

4The special edge cases a = 0 or b = 0 are considered in the appendix.

12

Proof. Once the opponent’s balance is below f , that party can
start the closing game, therefore the opponent becoming A.
Thus, by applying Theorem V.5, it follows that the opponent
can make the rational player lose money by closing unilaterally
and dishonestly. If it is not the ﬁrst time that A’s balance is
below f and the respective old state contains a higher balance
for A than the latest one, then we are even in the situation
of Corollary 1. It is thus rational of A (practical) to close
dishonestly.

B. Optimal Strategy for Closing Off-Chain

To summarize, our security analysis based on closing
games for Lightning channels yields the following results.
Theorem V.4-Theorem V.5, together with with Corollary 1-
Corollary 2, allow us to derive the optimal strategy for closing
an off-chain channel for a rational and suspicious player. We
next describe and illustrate this optimal strategy, highlighting
the main steps of our security analysis based on Theorem V.4-
Theorem V.5.

Without loss of generality, we assume the current state of

the channel is (a, b).

The player, assumed to be player A, who initiated the closing
phase shall:

• try to close honestly and collaboratively (action Ch), if
there does not exist an old state (a + dA, b − dA), where
dA > 0 and a + dA < 0. In case the other player, that is
player B, does not sign (action S), player A shall close
honestly and unilaterally (action H).
If player B closed dishonestly and unilaterally (action D),
player A shall:
– state the revocation transaction (action P), if the state
used for cheating was (a − dB, b + dB), where dB > 0
and b + dB ≥ f .

– ignore the cheating otherwise (action I), as it yields

less loss.

• close dishonestly and unilaterally (action D), if there
exists an old state (a + dA, b − dA), where dA > 0 and
a + dA < f . In this case, player A shall use the old
distribution state (a + d′
A > 0
that still satisﬁes a + d′

A, b − dA), with the highest d′
A < f .
The reacting player, in this case assumed to be player B, shall:
• sign the collaborative honest closing attempt (action S), if
applicable, if there is no old state (a − dB, b + dB), dB > 0
in which the funds of player B are less then f , that is if
b + dB < f .

• close honestly and unilaterally (action H), in case of a
dishonest collaborative closing attempt (action Cc). This
holds, if there is no old state (a − dB, b + dB), dB > 0
in which the player B’s funds are less then f , that is
b + dB < f .

• otherwise ignore (action I) the collaborative and hon-
if applicable, and close
est/dishonest closing attempt,
dishonestly and unilaterally (action D), using the old state
(a − d′
B > 0 that still satisﬁes
b + d′

B), with the highest d′

B, b + d′
B < f .

• state the revocation transaction (action P), if player A
tried to close dishonestly and unilaterally (action D) with
state (a + dA, b − dA), where dA > 0 and a + dA ≥ f .
• ignore (action I) if player A closed dishonestly (action
D), in the case where a + dA < f , as it yields less loss.

Example V.1. Let players A and B share a channel with initial
balance (5, 5) and let us assume the fee for publishing a
revocation transaction f = 2. After the ﬁrst update let their
state be (3, 7). The optimal way for A to close now is Ch and
for B to sign. Dishonest closing would cause B to publish the
revocation transaction, yielding a loss of 3 for A and a proﬁt
of 3 − 2 = 1 for B.

The next update could be (1.8, 8.2). The best way to close
for A is still Ch. Dishonest closing using (3, 7), for example,
would still cause B to publish the revocation transaction.
Player B would in this case lose 1.8 − 2 = −0.2, but he would
lose more, 7 − 8.2 = −1.2, by ignoring it.

Another update could be (1, 9). Now the optimal strategy
for A to close is D, using the old state (1.8, 8.2). Ignoring the
dishonest closing (action I) brings B −0.8, but proving A’s
cheating (action P) leads to 1 − 2 = −1. Hence, a rational B
will choose to ignore (action I), that means B does not publish
the revocation transaction.

VI. BEYOND CLOSING GAMES FOR OFF-CHAIN SECURITY

Our game-theoretic analysis so far focused on using closing
games to capture security properties of off-chain channels
(Section IV), and in particular of Lightning channels (Sec-
tion V). In this section, we show that our game-theoretic
formalism from Section III is expressive enough to analyse
more complex protocols than just closing phases in Lightning
channels. In particular, we introduce a new EFG, called
the Routing Game in Section VI-A, and use this game in
Section VI-B to disprove security of Lightning’s routing
mechanism amid the Wormhole and Grieﬁng attacks [7], [20].
We also discuss a natural extension of our analysis to model
other off-chain protocols in Section VI-C.

A. Routing Games for Lightning’s Routing Module

We ﬁrst propose a new EFG, called the Routing Game,
showing that EFGs can capture actual attacks, in this case the
Wormhole attack [7] and the Grieﬁng attack [20], which were
overlooked for example in [19]. Speciﬁcally, the below deﬁned
routing game considers fees f , and supports actions allowing
the intermediaries to choose not to claim their money using
the secret x but instead to forward it to another intermediary
(as explained in Section II-A). Additionally, other deviations
such as creating a conditional payment (i.e. HTLC) with a
different hash value, a different amount, or a different time-
out than expected are also considered. For simplicity, we chose
to model our routing game below with ﬁve players; however,
an arbitrary number of intermediaries can be modeled.

Deﬁnition VI.1 (Routing Game Grout). The routing game
Grout = (Nr, Hr, Pr, ur) is an EFG with ﬁve players N =
{A, E1, I, E2, B}, where

13

(ρ, m + 3 f − ε, −ε, −m, ρ)

I

I

U

SSI

(ρ, f , m + 2 f − ε, −m,ρ)

I

(ρ, m + 3 f − ε, −ε, −m, ρ)

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

I

B

U

B

I

(0, 0, 0, 0, 0)

SS
S1

S1

SH

I

(0, 0, 0, 0, 0)

S1

LH

LT

A

LA
S1

I

S2

S2

L

LT

LH

E1
LA
S2

I

(−ε, 0, 0, 0, 0)

(−ε, −ε, 0, 0, 0)

S3

L

LT

I

S3

LH

S4

S4

L

LT

LH

LA
S3

I

E2
LA
S4

L

I

(−ε, −ε, −ε, 0, 0)

(−ε, −ε, −ε, −ε, 0)

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

I

SSI

B

SSE1

E1

SSI

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

I

I

I

U

E1

E1

U

U

I

(ρ, m + 3 f − ε, −ε, −m,ρ)

(ρ, f , m + 2 f − ε, −m,ρ)

SSE1

(m + 3 f + ρ− ε, −m − 2 f , m + 2 f − ε, −m,ρ)

B

U

SS
S2

I

E2
SS
S3

U

I

E2

SSE1

S5

I

(m + 3 f + ρ− ε, −m − 2 f , f , f ,ρ)

I

E1

U

I

SS
S4
E1

U

U

(ρ, f , f , f ,ρ)

I

(ρ, m + 3 f − ε, −m − f , f ,ρ)

(ρ, f , m + 2 f − ε, −m,ρ)

E1

U

I

U

I

SSE1

I

(m + 3 f + ρ− ε, −m − 2 f , m + 2 f − ε, −m,ρ)

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

B

SSE1

E1

I

I

U

(ρ, m + 3 f − ε, −ε, −m,ρ)

S6

B

SSE1

(m + 3 f + ρ− ε, −ε, −m − f , f ,ρ)

I

(m + 3 f + ρ− ε, −ε, −m − f , f ,ρ)

E1

U

I

(m + 3 f + ρ− ε, −ε, −m − f , f ,ρ)

(ρ, m + 3 f − ε, −m − f , f ,ρ)

Fig. 6. Partial Deﬁnition of the Lightning’s Routing Grout and the Fulgor Model GFul. The olive colored subtree only applies for Grout.

• the histories Hr, the next player function Pr, and the
utility function ur are deﬁned via the tree representation
of Figure 6. The utility tuples in Figure 6 assign the ﬁrst
value to A, the second to E1, the third to I, the fourth to
E2, and the last to B;

• the actions of Grout are as listed in Table VII.

We note that our Routing Game Grout has four types of
subgames, as modeled in Figure 6 and described next: (i)
subgames that result from sending the secret to another player
Si; (ii) subgames that result from locking a wrong amount of
money in the HTLC Si; (iii) subgames that result from using a
wrong time-out in an HTLC Si; and (iv) subgames that result
from using a wrong hash value as lock in the HTLC Si. We
further note that Figure 6 only gives a partial model, as not all
subgames are presented in Figure 6. However, within one type
of subgame, the game trees are similar. Therefore, we provide
only one instance of each type in the appendix, which are the
subgames S1, S2, and S3. An instance of a secret forwarding
subgame capturing the Wormhole attack can be seen in Grout,
as the subtree after history (SH , L, L, L, L,U, SSE1

).

Let us emphasize that the utility function ur of Grout assigns
each player p ∈ N the relative proﬁt of their routing actions

and does not mirror the individual channel balances. It also
takes the value ρ of a successful payment and the opportunity
cost ε into account.

As in the closing games Gc(A) and Gc(B), we aim to align
utility and monetary outcome as tight as possible. We adjust
the ordering (U, 4) of Deﬁnition IV.1 by not assuming that
ρ ≺ ε, since achieving an update is the ultimate goal of the
routing protocol. We also consider the utility relative to the
amount due to each party.

B. Security Analysis of Lightning’s Routing Module

Let us recall Figure 1 and Figure 2, where player A wants
to pay another player B money of value m. Since, A and B
do not share a channel, the three intermediaries E1, I,and E2
support the payment, with each receiving a fee f > 0 for their
collaboration if the payment is successful. Each player who
creates an HTLC locks her money for a given time, yielding
an opportunity cost of ε if the money is returned.
If the
transaction fails, before anyone has unlocked an HTLC, all
parties get utility 0 or −ε, depending on whether they created
an HTLC or not. Otherwise, the intermediaries’ utilities are
according to their ﬁnancial win/loss. The parties A and B both
receive ρ once B is paid. Should the transaction fail after B

14

is paid, but before A has paid, she has utility m + 3 f + ρ− ε;
once E1 collects the money, A’s utility is ρ.

In the sequel, we consider the behavior from Figure 1 as

the only honest history in Grout, as also formalized next.

Deﬁnition VI.2 (Honest Routing). The only honest history in
the routing game Grout is the history (SH , L, L, L, L,U,U,U,U).
All strategies yielding this history are considered honest
strategies.

1.

A

y2,x2,ZKP2

y3,x3,ZKP3

y4,x4,ZKP4

x1 + x2 + x3 + x4

E1

(m + 3 f ,y1,t1)

2.

9.

x1

(m + 2 f ,y2,t2)

3.

8.

x1 + x2

I

(m + f ,y3,t3)

4.

7.
x1 + x2 + x3

E2

(m,y4,t4)

5.

6.

B

x1 + x2 + x3 + x4

Using our model Grout and its honest behavior, we derive

Fig. 7. Routing in Fulgor.

the following result.

Theorem VI.1 (Vulnerability of Grout to Wormhole Attacks).
The honest behavior (SH, L, L, L, L,U,U,U,U) of the Routing
Game Grout is not CR.

Proof. The utility of the honest behavior of the routing module
(SH , L, L, L, L,U,U,U,U) is (ρ, f , f , f ,ρ) (as indicated in red
in Figure 6). Let us compare this behavior and utility to
,U, I) with
the deviating terminal history (SH, L, L, L, L,U, SSE1
a utility of (ρ, m + 3 f − ε, −ε, −m, ρ) (given in blue in
Figure 6). It is not hard to argue that the collusion of E1 and E2
(and B by not sending the secret to I) strictly proﬁts from the
deviation, which yields a joint utility of 3 f − ε + ρ, whereas
the honest behavior only yields a joint utility of 2 f + ρ. As
such, collusion resistance CR is violated, since no honest
player can prevent the Wormhole attack from happening by
following any honest strategy (that is, a strategy σ whose
history is the honest behavior (SH , L, L, L, L,U,U,U,U)).

In conclusion, Theorem VI.1 formally proves that Light-
ning’s routing module is susceptible to the Wormhole attack.
We further extend this result by noting that not only can Grout
capture the Wormhole attack, but also the Grieﬁng attack, as
stated below.

Theorem VI.2 (Vulnerability of Grout
to Grieﬁng Attack).
The honest behavior (SH, L, L, L, L,U,U,U,U) of the Routing
Game Grout is not weak immune.

Proof. For showing that history (SH, L, L, L, L,U,U,U,U) is
not weak immune, we prove that no strategy which yields this
history is weak immune. Let us consider any such strategy

TABLE VII
POSSIBLE ACTIONS IN GROUT .

SH Sharing the secret’s Hash to enable the others to create HTLCs (action

1 in Figure 1, Section II-A).
L
Lock money, as deﬁned in actions 2–5 in Figure 1, in an HTLC.
U Unlocking the money from an HTLC (actions 6–9 in Figure 1). Thereby

I

the secret is revealed to the HTLC’s creator.
Ignoring all the previous actions and do nothing. If applicable, until
the unlockable HTLC has timed out.

SS Sending the Secret to another player. If it is sent to a speciﬁc player
(not leading to Si) this player is indicated by another subscript.
LH Locking money in an HTLC, that uses a different Hash-lock than

described in Figure 1.

LA Locking a different Amount of money in an HTLC, than described in

Figure 1.

LT Locking money in an HTLC, whose Time-out is different from the

values described in Figure 1.

σ. Then, player A has to choose action L after B sent her
the secret, that is history (SH ). Assume now E1 deviates and
chooses to ignore (action I). Then A’s utility is −ε ≺ 0. Hence,
history (SH, L, L, L, L,U,U,U,U) is not weak immune.

We also obtain the following result as an immediate conse-

quence of Theorem VI.1 and Theorem VI.2.

Corollary 3 (Security of Routing Module). The honest be-
havior (SH , L, L, L, L,U,U,U,U) of the Routing Game Grout is
not secure. Hence, the Routing Game Grout is not secure.

C. Further Routing Protocols Beyond the Lightning Network

We conclude this paper by arguing that our EFG games,
either closing or routing games, are not restricted to Lightning
networks but can be used for other protocols as well. In
the remaining of this section, we illustrate how to model
Fulgor [38], a payment channel network protocol that ﬁxes
the Wormhole attack, but not the Grieﬁng attack.

The routing mechanisms used in Fulgor is similar to Light-
ning’s routing, and is similarly based on HTLCs. The main
difference lies in the structure of the secrets and their hashes.
Indeed, while Lightning uses the same secret x for every
HTLC, Fulgor provides a different secret and hash lock for
each player.

Fulgor’s routing mechanism is illustrated in Figure 7, where
player A generates different secrets and hash locks at the
beginning. The secrets and the hashes relate in the following
way: h(x1) = y1, h(x1 + x2) = y2, h(x1 + x2 + x3) = y3 and
h(x1 + x2 + x3 + x4) = y4. Therefore, a player only gets to
know a sum of secrets when the right-hand party unlocks
and subtracts the secret value received from A to unlock
their HTLC. A also provides a zero-knowledge-proof ZKPi
for each intermediary [44] to prove that the secrets and hashes
constructed this way guarantee successful unlocking of the left
HTLC, which is essential to not lose funds.

The game-theoretical (EFG) model of Fulgor GFul
re-
ported in Figure 6 looks similar to the routing game Grout,
yet, with one signiﬁcant difference. Consider the history
) in Figure 6, which enables player E1
(SH, L, L, L, L,U, SSE1
to unlock (action U) the HTLC created by A. In Fulgor, the
same history does not enable E1 to unlock the HTLC. As
Figure 7 shows, the secrets that E2 can share after action 6
are x4 and x1 + x2 + x3 + x4. Further, E1 only knows x2, thus
there is no way to compute x1. This is however the value
needed to unlock the HTLC created by A.
Indeed, Fulgor is

15

not affected by the Wormhole attack. Nevertheless, similarly
to Theorem VI.2, the honest behavior of Fulgor is not weak
immune, as it is vulnerable to the Grieﬁng attack.

VII. CONCLUSIONS

Our work advocates the use of Extensive Form Games
(EFGs) for the game-theoretic security analysis of off-chain
protocols. In particular, we introduce two instances of EFGs to
model the closing and the routing of the Lightning Network.
By doing so, we take the ﬁrst step towards closing the gap
existing security proof techniques have due to using informal
arguments about rationality. We express security properties as
formal requirements over joint strategies in EFGs, allowing us
to establish optimal strategies for closing off-chain and capture
security vulnerabilities amid attacks. Given the theoretical ex-
pressiveness of our EFGs, future work includes the deﬁnitions
of new games to capture a wider range of off-chain protocols.
To overcome the burden of tedious manual analysis, we
also plan to leverage SMT solving and/or automated theorem
proving in order to provide automated security proofs.

Acknowledgments. We thank our anonymous reviewers for
their valuable feedback. The work was partially supported by
the European Research Council (ERC) under the ERC CoG
ARTIST 101002685 and the ERC CoG BROWSEC 71527;
by the TU Wien Doctoral College SecInt; by the Austrian
Science Fund (FWF) projects PROFET P31621 and LogiCS
W1255-N23; by the Austrian Research Promotion Agency
(FFG) (COMET K1 SBA, COMET K1 ABC); by the Vienna
Business Agency project Vienna Cybersecurity and Privacy
Research Center (VISP); by the Austrian Federal Ministry
for Digital and Economic Affairs; the National Foundation
for Research, Technology and Development; and the Christian
Doppler Research Association through CDL-BOT.

REFERENCES

[1] S. Nakamoto, “Bitcoin: A Peer-to-Peer Electronic Cash System,”

https://bitcoin.org/bitcoin.pdf, 2008.

[2] G. Wood, “Ethereum: A Secure Decentralised Generalised Transaction

Ledger,” https://gavwood.com/paper.pdf, 2014.

[3] A. Haﬁd, A. Senhaji Haﬁd, and M. Samih, “Scaling Blockchains: A
Comprehensive Survey,” IEEE Access, pp. 125 244 – 125 262, 2020.
[4] A. Chauhan, O. Malviya, M. Verma, and T. Singh Mor, “Blockchain

and Scalability,” in QRS-C, 2018, pp. 122–128.

[5] L. Gudgeon, P. Moreno-Sanchez, S. Roos, P. McCorry, and A. Gervais,
“SoK: Layer-Two Blockchain Protocols,” in FC, 2020, pp. 201–226.

[6] J. Poon and T. Dryja, “The Bitcoin Lightning Network: Scalable

Off-Chain Instant Payments,” 2016,
https://lightning.network/lightning-network-paper.pdf.

[7] G. Malavolta, P. Moreno-Sanchez, C. Schneidewind, A. Kate, and

M. Maffei, “Anonymous Multi-Hop Locks for Blockchain Scalability
and Interoperability,” in NDSS, 2019.

[8] L. Aumayr, O. Ersoy, A. Erwig, S. Faust, K. Hostakova, M. Maffei,

P. Moreno-Sanchez, and S. Riahi, “Generalized Channels from Limited
Blockchain Scripts and Adaptor Signatures,” in AsiaCrypt, 2021.

[9] L. Aumayr, M. Maffei, O. Ersoy, A. Erwig, S. Faust, S. Riahi,

K. Hostakova, and P. Moreno-Sanchez, “Bitcoin-Compatible Virtual
Channels,” in SP, 2021, pp. 901–918.

[10] L. Aumayr, P. Moreno-Sanchez, A. Kate, and M. Maffei, “Blitz:

Secure Multi-Hop Payments Without Two-Phase Commits,” in Usenix
Security, 2021, pp. 4043–4060.

[11] Z. Avarikioti, E. K. Kogias, R. Wattenhofer, and D. Zindros, “Brick:

Asynchronous Incentive-Compatible Payment Channels,” in FC, 2021,
pp. 209–230.

[12] C. Decker and R. Wattenhofer, “A Fast and Scalable Payment Network
with Bitcoin Duplex Micropayment Channels,” in SSS, 2015, pp. 3–18.

[13] S. Dziembowski, L. Eckey, S. Faust, and D. Malinowski, “Perun:

Virtual Payment Hubs over Cryptocurrencies,” in SP, 2019, pp.
106–123.

[14] S. Dziembowski, L. Eckey, S. Faust, J. Hesse, and K. Host´akov´a,

“Multi-Party Virtual State Channels,” in EuroCrypt, 2019, pp. 625–656.
[15] P. McCorry, S. Bakshi, I. Bentov, S. Meiklejohn, and A. Miller, “Pisa:
Arbitration Outsourcing for State Channels,” in AFT, 2019, pp. 16–30.
[16] Z. Avarikioti, O. S. T. Litos, and R. Wattenhofer, “Cerberus Channels:
Incentivizing Watchtowers for Bitcoin,” in FC, 2020, pp. 346–366.
[17] S. A. K. Thyagarajan, G. Malavolta, F. Schmidt, and D. Schr¨oder,

“PayMo: Payment Channels For Monero,” IACR Cryptol. ePrint Arch.,
2020.

[18] R. Canetti, Y. Dodis, R. Pass, and S. Walﬁsh, “Universally

Composable Security with Global Setup,” in TCC, 2007, pp. 61–85.

[19] P. Zappal`a, M. Belotti, M. Potop-Butucaru, and S. Secci, “Game

Theoretical Framework for Analyzing Blockchains Robustness,” IACR
Cryptol. ePrint Arch., 2020.

[20] A. Khosla, E. Schwartz, and A. Hope-Bailie, “Connector Risk

Mitigations–Interledger RFCs, 0018,” 2019. [Online]. Available:
https://interledger.org/rfcs/0018-connector-risk-mitigations/

[21] G. Avarikioti, F. Laufenberg, J. Sliwinski, Y. Wang, and

R. Wattenhofer, “Towards Secure and Efﬁcient Payment Channels,”
arXiv preprint, 2018. [Online]. Available:
https://arxiv.org/abs/1811.12740

[22] Z. Avarikioti, L. Heimbach, Y. Wang, and R. Wattenhofer, “Ride the

Lightning: The Game Theory of Payment Channels,” in FC, 2020, pp.
264–283.

[23] G. Avarikioti, R. Scheuner, and R. Wattenhofer, “Payment Networks as

Creation Games,” in CBT, 2019, pp. 195–210.

[24] O. Ersoy, S. Roos, and Z. Erkin, “How to Proﬁt from Payments

Channels,” in FC, 2020, pp. 284–303.

[25] C. Badertscher, J. Garay, U. Maurer, D. Tschudi, and V. Zikas, “But

why does it Work? A Rational Protocol Design Treatment of Bitcoin,”
in Eurocrypt, 2018, pp. 34–65.

[26] I. Eyal and E. G. Sirer, “Majority is not Enough: Bitcoin Mining is

Vulnerable,” in FC, 2014, pp. 436–454.

[27] Y. Kwon, D. Kim, Y. Son, E. Vasserman, and Y. Kim, “Be Selﬁsh and
avoid Dilemmas: Fork after Withholding (faw) Attacks on Bitcoin,” in
CCS, 2017, pp. 195–209.

[28] A. Sapirshtein, Y. Sompolinsky, and A. Zohar, “Optimal Selﬁsh
Mining Strategies in Bitcoin,” in FC, 2016, pp. 515–532.
[29] A. Kiayias, E. Koutsoupias, M. Kyropoulou, and Y. Tselekounis,

“Blockchain Mining Games,” in EC, 2016, pp. 365–382.

[30] X. Chen, C. Papadimitriou, and T. Roughgarden, “An Axiomatic
Approach to Block Rewards,” in AFT, 2019, pp. 124–131.

[31] I. Eyal, “The Miner’s Dilemma,” in IEEE S&P, 2015, pp. 89–103.
[32] J. Teutsch, S. Jain, and P. Saxena, “When Cryptocurrencies Mine their

own Business,” in FC, 2016, pp. 499–514.

[33] E. Heilman, A. Kendler, A. Zohar, and S. Goldberg, “Eclipse Attacks
on Bitcoin’s Peer-to-Peer Network,” in {USENIX} Security, 2015, pp.
129–144.

[34] K. Nayak, S. Kumar, A. Miller, and E. Shi, “Stubborn Mining:

Generalizing Selﬁsh Mining and Combining with an Eclipse Attack,”
in EuroS&P, 2016, pp. 305–320.

[35] Z. Liu, C. Nguyen, W. Wang, D. Niyato, P. Wang, Y.-C. Liang, and

D. I. Kim, “A Survey on Blockchain: A Game Theoretical
Perspective,” IEEE Access, pp. 47 615–47 643, 2019.

[36] K. Chatterjee, A. K. Goharshady, and Y. Velner, “Quantitative

Analysis of Smart Contracts,” in ESOP, 2018, pp. 739–767.
[37] K. Chatterjee, A. Goharshady, and A. Pourdamghani, “Probabilistic
Smart Contracts: Secure Randomness on the Blockchain,” in ICBC,
2019, pp. 403–412.

[38] G. Malavolta, P. Moreno-Sanchez, A. Kate, M. Maffei, and S. Ravi,

“Concurrency and Privacy with Payment-Channel Networks,” in CCS,
2017, p. 455–471.

[39] S. Mazumdar, P. Banerjee, A. Sinha, S. Ruj, and B. Roy, “Strategic
Analysis to Defend against Grieﬁng Attack in Lightning Network,”
2022. [Online]. Available: https://arxiv.org/abs/2203.10533
[40] P. Banerjee, S. Mazumdar, and S. Ruj, “Grieﬁng-Penalty:

Countermeasure for Grieﬁng Attack in Bitcoin-compatible PCNs,”
CoRR, vol. abs/2005.09327, 2020. [Online]. Available:
https://arxiv.org/abs/2005.09327

16

[41] M. J. Osborne, Introduction to Game Theory. Oxford University

Press USA, 2004.

[42] R. Mckelvey, A. McLennan, and T. Turocy, “Gambit: Software Tools

for Game Theory,” 2005.

[43] R. Savani and B. von Stengel, “Game Theory Explorer - Software for
the Applied Game Theorist,” CoRR, vol. abs/1403.3969, 2014.

[44] O. Goldreich and Y. Oren, “Deﬁnitions and Properties of

Zero-Knowledge Proof Systems,” J. of Cryptology, vol. 7, no. 1, pp.
1–32, 1994.

APPENDIX

A. Proof of the Resilience Properties

We restate the results for better readability.

Lemma III.1 (Resilience Properties). Let σ ∈ S be a joint
strategy. The following and only the following implications
hold.

1) σ is SR⊆ ⇒ σ is SR, CR, sNE.
2) σ is SR ⇒ σ is CR.

SR

SR⊆

CR

sNE

s1/σs1, ...,σ′
s1 /σs1, ...,σ′

Proof. We start by showing property (2). Let σ be SR and
S ∈ SS be arbitrary but ﬁxed. Then,
let S = {s1, ..., s j} ⊂ N, σ′
for all p ∈ S we have up(σ) ≥ up(σ[σ′
s j /σs j ])
and thus also ∑p∈S up(σ) ≥ ∑p∈S up(σ[σ′
s j /σs j ]).
Hence σ is CR and the implication is proven. For implication
(1) we see that SR⊆ ⇒ SR is trivial. If the property is
satisﬁed for every S ⊆ N, then it is also satisﬁed for every
S ⊂ N. By (2) and the transitivity of implication we also get
SR⊆ ⇒ CR. For the last implication let σ be SR⊆ and let
S ∈ SS be arbitrary but ﬁxed.
S = {s1, ..., s j} ⊆ N, S 6= /0 and σ′
Then there exists some p ∈ S and by deﬁnition all p ∈ S satisfy
up(σ) ≥ up(σ[σ′

s j /σs j ]). Therefore, σ is sNE.

s1/σs1, ...,σ′

To prove that no other implication holds between those four
concepts, we provide three counterexamples. An overview of
which game disproves which implication is given in Table IX.
The three-player NFG Γ1 in Table IV shows a joint strategy
(H1, H2, H3) that is sNE, but not CR (refer to Example III.5).
Using the just proven (1) and (2), we get that (H1, H2, H3) is
also not SR nor SR⊆.

The three-player game Γ2 (Table V) shows a strategy
(H1, H2, H3) that is CR, but not SR (see Example III.5) and
thus also not SR⊆ (property (1)). It is, however, sNE: The
only relevant deviation from (H1, H2, H3) is (D1, H2, D3), as it
yields a different utility (3, 0, −2) instead of (1, 1, 1). While
player P1 proﬁts in this case, player P3 does not. One deviating
player not proﬁting sufﬁces for a strong Nash Equilibrium,
thus (H1, H2, H3) is sNE.

To prove the remaining implications incorrect, we consider
the two-player game Γ3 in Table VIII. We can easily see
that (H1, H2) is not SR⊆, nor sNE. This is the case, as all
players {P1, P2} can deviate to play (D1, D2) which yields a
strict increase for both. However, since no player proﬁts from
deviating alone, (H1, H2) is still SR and CR.

B. Results of Security Analysis and Their Proofs

In this section all omitted proofs of the results from Section
the results Theorem A.1,
V are provided. Additionally,
Theorem A.2 and Theorem A.3 about edge cases are stated

TABLE VIII
GAME Γ3.

H2
(1,1)
(1,1)

D2
(1,1)
(2,2)

H1
D1

17

TABLE IX
OVERVIEW OF IMPLICATIONS AND COUNTEREXAMPLES.

→

SR

SR⊆

sNE

CR

SR

X

Γ1

Γ2

SR⊆

Γ3

Γ1

Γ2

sNE

CR

X

X

Γ1

Γ3

X

Γ3

and proven.

Theorem V.1 (Weak Immunity of Honest Behavior – (P1)).
The terminal histories (H) of honest unilateral closing, and
(Ch, S) of honest collaborative closing of Gc(A) are weak
immune,
the channel balances are higher than the fee
required in a revocation transaction, that is if a ≥ f and b ≥ f .

if

Proof. Let a, b ≥ f . For history (H), we consider any strategy
σ, where A chooses H after the empty history /0, B chooses
S after (Ch), P after (D) and H after (Cc). Such a strategy
σ yields terminal history (H). If we can show that σ is
weak immune, also history (H) is weak immune by Deﬁnition
III.11. Assume, player A honestly follows σ, i.e., choosing
(H), then B’s deviation from σ cannot affect the outcome.
Thus, A’s utility remains non-negative. The other way around,
if B follows σ, A can deviate to any initial action Ch, D or Cc,
player B’s utility never drops below 0, by following strategy
σ, as a ≥ f . Since honest players cannot get negative utility,
σ is weak immune.

Similarly, for (Ch, S), we consider any strategy σ′, where
A chooses Ch initially, player B chooses S after (Ch), P after
(D) and H after (Cc). Further, player A takes P after (Ch, D)
and H after (Ch, I), (Ch,U +) and (Ch,U −). This strategy σ′
yields terminal history (Ch, S). Deviation of A has the same
effects as before, never causing the honest B, who follows σ,
negative utility. If B deviates now to one of U +, U −, I, D,
or H, honest A, following σ, also never gets negative utility,
since b ≥ f . Therefore, σ′ and hence history (Ch, S) are weak
immune.

Theorem V.2 (Incentive-Compatibility – (P2)). If a − pB +
dA ≥ f and b − pA + dB ≥ f , then

1) honest unilateral closing (H) is CR, but not practical.
2) honest collaborative closing (Ch, S) is CR. It is practical

iff c 6= pA.

Proof. Let us ﬁrst prove collusion resilience CR of (H) and
(Ch, S). As in the previous proof, we only have to ﬁnd a
strategy σ that yields history (H) and another strategy σ′
yielding history (Ch, S), that are CR, to prove (H) and (Ch, S)
CR, as deﬁned in Deﬁnition III.11. Additionally, collusion
resilience is deﬁned on strict subsets of players. Thus, in a
two-player game, it considers only deviations of single players
and since the summation over one value is the value itself,

CR is equivalent to being a Nash Equilibrium in this case.
We therefore only have to check whether σ and σ′ are Nash
Equilibria.

1, S′

For (H), we consider a strategy σ, where player A chooses
H initially, player B chooses I after (Ch), and I after (Cc).
Additionally, player B always chooses P after a history
(..., D), where the last action was D. Player A takes action
H after (Ch, I) and (Cc, I). Further, B takes action I after
(Ch/c, I,U +/−) (subgames S1, S2, S′
2 in Figure 10). For A,
we ﬁnally assume she takes action H after (Ch/c, I,U +/−, I).
This strategy yields history (H). Deviations from σ of player
B cannot change the utility, hence in particular cannot increase
his utility. Let us consider deviations of player A. A deviation
to D at any point in the game, leads to A losing all her funds
a, which is a strict decrease in utility. This is the case because
in σ player B always chooses P after D. Therefore this option
is not a threat. If A deviates to Ch or Cc initially, we end up in
(Ch, I), (Cc, I) respectively. Closing honestly (action H) here
leads to the same utility as not deviating. Also a deviation to
I does not lead to a better utility. The options she has left is
taking U + or U −. Either way, B takes I and leaves A similar
choices to before: action H or action I, both of which do
not yield a better utility for her. Since no player can increase
their utility by deviating from σ, it is a Nash Equilibrium, and
hence (H) is too.

To show that (Ch, S) is a Nash Equilibrium, we consider a
strategy σ′, where A picks Ch initially, B chooses S after (Ch),
P after (D) and H after (Cc). Further, let A pick P after (Ch, D),
H after (Ch, I) and (Ch,U +/−) (subgames S3, S4 in Figure 11).
This strategy σ′ has terminal history (Ch, S). A deviation of
player B, results in either the same utility (choosing action I,
U +, or U − after (Ch) and having A taking H) or in strictly
worse utility (choosing H or D, where A takes P). Every other
deviation has no impact on the resulting history. Similarly,
player A cannot proﬁt from deviating. Choosing action H or
D initially, leads to a strict loss, as B plays P, whereas taking
action Cc yields the same utility for A (as B will take action
H). Every other deviation has no impact on the history. Hence,
no player can increase their utility by deviating, which makes
σ′ and therefore (Ch, S) a Nash Equilibrium.

To prove the practicality properties, we compute all sub-
game perfect equilibria of Gc(A). We compute subgame per-
fect equilibria bottom-up. That is, we start comparing the
utility of subtrees with leaves only. In Gc(A), these are for
example the subgames after history (Ch, I, D) or (Cc, D). For
the latter, A is the player to choose the action. To compute the
subgame perfect equilibrium, we have to compare all possible
utilities for A after (Cc, D). We then replace this internal node
labelled A, by the utility that yields the best value for A and
proceed until we reach the root. If there is no single best choice
for a player, then all actions resulting in best utility have to
be considered. Applying this procedure to the subgames S1-S4
4 we get subgame perfect terminal history (A, H) with
and S′
utility (ρ+α−ε,ρ+α) for S1. For S2 we get terminal history
(S) yielding (α,α) and (I, H), yielding (α−ε,α). For S3 and
S4 it is (I, S) with (α,α). The subgame S′
1 has practical history

1-S′

18

(I, H), with (α−ε,α) if c > pA, (A, I, S) with (ρ+α,ρ+α)
if c = pA and (A, H) with (ρ + α − ε,ρ + α) if c < p. The
2 has practical history (I, H), yielding (α − ε,α).
subgame S′
4 in Figure 11 we get (I, H) with (α,α − ε)
For S′
3 and S′
3, if c = p, we also have (A, S) yielding
and additionally for S′
(ρ + α,ρ + α). All of these results are based on the facts
a − pB + dA ≥ f and b − pA + dB ≥ f , since this causes the
revocation transaction always to be better than ignoring the
dishonest unilateral closing attempt.

Based on these preliminary results, we can now com-
pute the subgame perfect equilibria for Gc(A) considering
multiple practical histories and case splits as stated: If c =
pA, then (Cc,U +, A, S) and (Cc, I,U +, A, I, S) are practical,
both yielding (ρ + α,ρ + α). If c > pA,
then the histo-
ries (Ch, S), (Ch,U +, I, S), (Ch,U −, I, S) and (Ch, I,U −, S) all
leading to (α,α) are practical, as well as terminal history
(Ch, I,U +, I, H), yielding (ρ + α − ε,ρ + α). For c < pA,
all the histories and their utilities from c > pA are practical.
Additionally (Cc, I,U +, A, H) is subgame perfect in this case
and also results in utility (ρ+ α− ε,ρ+ α).

This shows,

that (H) is never practical and (Ch, S) is

practical if and only if c 6= pA.

1) Results without Updates:

Corollary 1. If there exists an old channel state (a + dA, b −
dA), with a + dA < f , then neither history (H) nor (Ch, S) is
weak immune nor practical, but CR.

Proof. We ﬁx the old distribution state such that the difference
dA to the latest state is the value of A’s dishonest closing
attempt in the closing game. As a + dA < f
implies a < f ,
Theorem V.5 applies. Therefore, neither (H) nor (Ch, S) are
weak immune.

In order to show that they are also not practical, we prove
instead, that the only practical history is (D, I). Since a + dA <
f , I is the best choice for B after (D), (Ch, I, D) and (Cc, I, D).
Consequently, A will choose D after (Ch, I) and (Cc, I). If
now b + dB ≥ f , then A’s best choice is P after (Ch, D) and
(Cc, D). Thus, B will take S after (Ch) and H after (Cc). In the
other case, b + db < f , A’s best option is I after (Ch, D) and
(Cc, D), thus B’s best choice after (Ch) and (Cc) is D, which
yields a negative utility for A. Therefore, in both cases A’s
only subgame perfect action is D. Hence, (D, I) is the unique
subgame perfect history.

For CR, we show instead that there exist extensions (Deﬁni-
tion III.11) σ of (H) and σ′ of (Ch, S) that are Nash Equilibria.
Let σ be the strategy, where A chooses H, everyone chooses
P after a dishonest closing attempt D, B chooses I after (Ch)
and (Cc) and A chooses H after (Ch, I) and (Cc, I). Then,
player B’s deviations have no impact, thus cannot not increase
his utility, and player A’s deviations either lead to the same
utility as σ, or to the strictly worse utility −a. Anyway, no
player can deviate to increase their utility and therefore σ
and thus (H) is CR. To prove (Ch, S) is CR, we consider the
strategy σ′, which is the same as σ, except A initially chooses
Ch and B chooses S after (Ch). A deviation of A either leads

to utility α − ε for her, which is worse than σ’s utility, or
to utility −a, which is even worse. For B, a deviation either
leads to the same utility α (taking I after (Ch)), to a slightly
worse α− ε (choosing H after (Ch)) or to the way worse −b
(D after (Ch)). Every other deviation has no impact on the
history. Hence, as nobody proﬁts from deviating, σ′ is also a
Nash Equilibrium.

We present an additional theorem, discussing the case where
player B has little funds left in the channel. Since the roles of
player A and B are arbitrary, it is of little importance because
the results give stronger security guarantees as for the case
where A has a low balance. Nevertheless, we state it for the
sake of completeness.

Theorem A.1. If there exists an old state with b + dB < f , but
a ≥ f , then

1) (H) is secure.
2) (Ch, S) is not practical, not weak immune, but CR.

Proof. To prove (1), we start by showing weak immunity for a
strategy σ with history (H). Consider σ, where A takes action
H initially, player B chooses P after (D), S after (Ch) and H
after (Cc). Then σ and thus (H) is weak immune, because B’s
deviations have no impact on the history and A’s deviations
can never bring B’s utility below zero.

Next, we prove the practicality of (H) by computing all
subgame perfect equilibria. Since a ≥ f , the subgame perfect
choice after (D), (Ch, I, D) and (Cc, I, D) is P. Thus, A chooses
H after (Ch, I) and (Cc, I). Due to b + dB < f , A’s best option
after (Ch, D) and (Cc, D) is I. Hence B’s unique subgame
perfect choice after (Cc) and (Ch) is D. Thus, A’s only best
response is H. Therefore, (H) is the only practical history. As
practicality implies CR in our case, (H) is secure.

For (2), we just showed that (Ch, S) cannot be practical.
Additionally, (Ch, S) is not weak immune, since B could
deviate to D after (Ch), in which case A gets negative utility
for sure, because of b + dB < f .

Finally, we consider the strategy σ′, with history (Ch, S),
where A initially chooses Ch, B chooses S after (Ch), both
take P in case of a dishonest unilateral closing attempt D,
B takes H after (Cc), similarly A takes H after (Ch, I) and
(Cc, I). Using similar argumentation as before, we conclude
that any deviation of a player leads a utility as most as good as
σ′ for them, but never better. Hence, σ′ is a Nash Equilibrium
yielding terminal history (Ch, S).

2) Results for Edge Cases: So far, we only considered
cases where both balances a and b were strictly greater than
zero. This is not necessarily the case. Therefore, we consider
these cases here. In the ﬁrst case, a = 0, B cannot close
dishonestly, as there is no old state that increases his balance.
The corresponding simpliﬁed game is presented in Figure 8.
If b = 0 (Figure 9), player A cannot close dishonestly, as she
cannot take any money from B. Thus, both dishonest unilateral
closing D and proposing an unfair split in a collaborative
closing attempt Cc are not possible.

Finally, we present results about the two edge cases.

19

(0,α)

H

Ch

Cc

A

D

B

P

B

H

S

I

(0,α)

I

(0, − f + α)

(dA + α− ε, −dA + α)

(0,α− ε)

(0,α− ε)

B

I

H

S

(c + α, −c + α)

A

D

H

I

(0, −b)

B

P

(0,α)

(0,α)

A

D

H

I

(0, −b)

P

B

I

(0, − f + α)
(dA + α− ε, −dA + α)

(0, − f + α)
(dA + α− ε, −dA + α)

I

Fig. 8. Closing game Gc(A) with a = 0.

A

H

Ch

B

(α− ε, 0)

I

H

S

D

A

(α, 0)

(α, 0)

I

H

A

P

I

(−a, 0)

(α− ε, 0)

(− f + α, 0)

(−dB + α, dB + α− ε)

Fig. 9. Closing game Gc(A) with b = 0.

Theorem A.2. If a = 0 and b > 0 (Figure 8), then only
histories that involve an explicit cheating attempt are weak
immune. Additionally, (H) and (Ch, S) are practical if and
only if dA ≥ f in every previous state (dA, b − dA). In any case
they are CR.

Proof. We ﬁrst show that only histories that involve an explicit
cheating attempt can be weak immune. Let us consider a
history h without a D or Cc action, then A does not initially
choose D in h. However, if A deviates to D, then B’s utility is
negative. Thus, any such history h is not weak immune.

To show both (H) and (Ch, S) are CR, it sufﬁces to show
they are Nash Equilibria as before. We therefore consider any
strategy σ, where A initially chooses H, player B chooses P
after (D), S after (Ch) and H after (Cc). Further, player A takes
action H after (Ch, I). The strategy σ yields history (H). No
matter how player A deviates, she always gets utility 0, as
she does in σ. Thus, she has no incentive to deviate. Since
player B’s deviations cannot change the history, also he has
no incentive to do so. Therefore, σ and hence (H) is a Nash
Equilibrium. Adapting σ, by making A ﬁrst choice Ch we
get strategy σ′ which leads to history (Ch, S). As before, A’s
utility stays 0 no matter how she deviates from σ′. Also player

20

B cannot improve his utility by changing strategy. Hence, also
σ′ and therefore (Ch, S) is a Nash Equilibrium.

Towards practicality, we now compute all subgame perfect
equilibria. Let dA ≥ f . In which case P is the subgame best
choice for B after (D), (Ch, I, D) and (Cc, I, D). Further, after
history (Cc, I), S it is never a best option for B, because it
is strictly dominated by H. Therefore, A will get utility zero
in any case. This makes (H) a practical history. Similarly for
(Ch, S), since S is subgame perfect for B after (Ch).

If now dA < f , then I is subgame perfect for B after D.
Thus, with similar argumentation as before, (D, I) is the only
practical history.

Theorem A.3. If a > 0 and b = 0 (Figure 9), then

1) (H) is secure.
2) (Ch, S) is not weak immune, but CR. It is practical iff

dB ≥ f in every previous state (a − dB, dB).

Proof. We prove (1.) ﬁrst. The history (H) is weak immune,
as B’s strategy does not effect the history, since A’s initial
choice has to be H. Further, A’s deviation is irrelevant for B,
as he can never get negative utility in this game.

Practicality of (H). We compute subgame perfect equilibria.
After history (Ch, D) the subgame perfect choice of A depends
on whether dB ≥ f . In any case, D is subgame perfect for B
after history (Ch). If A chose P, then it is as good as any other
choice, yielding 0, otherwise it is the only best option resulting
in a positive utility. Thus, A either gets − f +α or −dB +α if
she chooses Ch, both of which is negative. Hence A’s subgame
perfect and therefore practical choice is H, yielding the history
(H).

The fact that (H) is CR follows from practicality. This

shows that (H) is secure, if b = 0.

For (2), we start showing (Ch, S) is not weak immune. We
consider any strategy σ′ yielding the history (Ch, S). Assume
now, B deviates to D after (Ch), then no matter what A’s choice
is, she will get a negative utility, thus (Ch, S) is not weak
immune.

The collusion resilience of (Ch, S), can be shown by consid-
ering a strategy σ′ with history (Ch, S), where we additionally
ﬁx that A chooses P after (Ch, D). Then B has no incentive to
deviate as he always gets utility 0, and A has no incentive as
α, which is her utility in σ′, is the best possible outcome for
her.

To ﬁnally show that (Ch, S) is practical iff dB ≥ f , we
consider A’s choice after (Ch, D). The option P is subgame
perfect iff dB ≥ f . Thus, S is subgame perfect for B iff
dB ≥ f . For dB < f , D is the better option for B, yielding
(−dB +α, dB +α−ε). Therefore Ch is subgame perfect for A
iff dB ≥ f , in which case the resulting history is (Ch, S).

The weak immunity result of (H) might be misleading, as
B can actually close dishonestly immediately (before A takes
action). This is not represented here, but in Gc(B), which is
analog to Gc(A) but with swapped roles.

(α,α− ε)

I

B

H

S

P

(−a, a − f + α)
(dA + α− ε, −dA + α)

I

B

I

D

H

A

(y + α, −y + α)

D

A

(−a, −b) (α− ε,α)

(−dB + α, dB + α− ε)

(b − f + α, −b)

I

P

H

(ρ+ α− ε,ρ+ α)

(dA + ρ+ α− ε, −dA + ρ+ α)

I

P

(−a−x + ρ, a+x − f + ρ+ α)

(y − x + ρ+ α, −y + x + ρ+ α)

S

I

H

(−a−x + ρ, −b+x + ρ)

(ρ+ α,ρ+ α− ε)

A

D

I

A

B

B

D

A

(α− ε,α)

H

I

A

P

(b − f + α, −b)
(−dB + α, dB + α− ε)

I

A

I

D

H

B

S

D

(y + α, −y + α)

A

(−a, −b)

(α,α− ε)

(dA + α− ε, −dA + α)

I

P

(−a, a − f + α)

S

H

(y − x + ρ+ α, −y + x + ρ+ α)

(ρ+ α,ρ+ α− ε)

B

A

B

D

I

(−dB + ρ+ α, dB + ρ+ α− ε)

I

P

(b−x − f + ρ+ α, −b+x + ρ)

I

H

(−a−x + ρ, −b+x + ρ)

(ρ+ α− ε,ρ+ α)

D

A

B

(b−x − f + ρ+ α, −b+x + ρ)

P

I

(−a−x + ρ, a+x − f + ρ+ α)

P

I

(−dB + ρ+ α, dB + ρ+ α− ε)

(dA + ρ+ α− ε, −dA + ρ+ α)

Fig. 10. Subgames S1,2, S′

1,2 with Update (a,b) 7→ (a + x,b − x).

Fig. 11. Subgames S3,4, S′

3,4 with Update (a,b) 7→ (a + x,b − x).

HTLC. Action Lz describes the reusing of hash lock z in the
next HTLCs. Lastly, subgame S3 in Appendix D handles the
case, where player I uses a time-out t3 of the HTLC which is
later than the previous ones t1 and t2, thereby neglecting the
decreasing ordering of time outs. In Appendix D, the action Ut2
means unlocking the HTLC before t2 times out, thus enabling
the other players to unlock too. The action U>t1 stands for
unlocking after both t1 and t2 timed out, therefore I and E1
cannot unlock their respective HLTCs any more. Finally, action
U[t2,t1] means unlocking after t2 has timed out, but the HTLC
with time-out t1 can still be unlocked.

C. Subgames of the Closing Game

In the following all the subgames needed for the closing
game Gc(A) are deﬁned. The subgames S1,2 and S′
1,2 in
Figure 10 cover the case where a channel update is proposed
by A, although A has already signed a collaborative closing
attempt. In S1 the closing attempt was honest, hence y = 0
and the update is from channel state (a, b) to (a + pA, b − pA),
hence x = pA. In S2 also y = 0 the suggested update is
(a − pB, b + pB), thus x = −pB. In S′
1,2 the closing attempt
was dishonest, therefore y = c. The channel updates are as
before, thus x = pA for S′
2. Similarly,
subgames S3,4 and S′
3,4 in Figure 11 cover the case where
a channel update is proposed by B, although A has already
signed a collaborative closing attempt. As in the ﬁrst case, we
have y = 0 for the honest closing attempt in S3,4 and y = c for
3,4. Further in S3 and S′
dishonest collaborative closing in S′
3,
the proposed update is (a + pA, b − pA), hence x = pA, whereas
in S4 and S′
4 it is (a − pB, b + pB), thus x = −pB.

1 and x = −pB for S′

D. Subgames of the Routing Game

In this section, one subgame of each type is detailed. First,
subgame S1 in Figure 12 describes the case where player A
locks an amount of money in the HTLC which deviates from
the expected m + 3 f . The action Lw means that the subsequent
player follow along and forward the deviation of −w to player
B. Subgame S2 in Figure 13 illustrates the case that player E1
creates her own secret and uses its hash z as the lock of her

21

(w + ρ, f , m − w + 2 f − ε, −m + w, −w + ρ)

(m + 3 f + ρ− ε, −m + w − 2 f , m − w + 2 f − ε, −m + w, −w + ρ)

E1
LA
S5
(−ε, 0, 0, 0, 0)

I

S5

S5

LT

LH

S6

S6

LH

S7

S7

Lw

LT

LH

Lw

LT

I

I

LA
S6
(−ε, −ε, 0, 0, 0)

E2
LA
S7
(−ε, −ε, −ε, 0, 0)

I

S11

S10

B

SS
S7

Lw

I

(−ε, −ε, −ε, −ε, 0)

(m + 3 f + ρ− ε, −ε, −m + w − f , f , −w + ρ)

(w + ρ, m − w + 3 f − ε, −m + w − f , f , −w + ρ)

(m + 3 f + ρ− ε, −ε, −m + w − f , f , −w + ρ)

U

I

B

SSE1

E1

U

E1

U

SSE1

I

I

SSI

SSE1

U

B

I

E2
SS

S8

I

I

(w + ρ, m − w + 3 f − ε, −ε, −m + w, −w + ρ)

SSE1

E1

U

I

B

I

(m + 3 f + ρ− ε, −ε, −ε, −m + w, −w + ρ)

I

(m + 3 f + ρ− ε, −ε, −ε, −m + w, −w + ρ)

(m + 3 f + ρ− ε, −ε, −ε, −m + w, −w + ρ)

U

I

I

E2

I

U

SS
S9

SSE1
E1

U

I

(m + 3 f + ρ− ε, −m + w − 2 f , f , f , −w + ρ)
E1

I

U

(w + ρ, f , f , f , −w + ρ)

(w + ρ, m − w + 3 f − ε, −m + w − f , f , −w + ρ)

(m + 3 f + ρ− ε, −ε, −m + w − f , f , −w + ρ)

Fig. 12. Subgame S1 with locked amount m − w + 3 f .

S8

LT

I

S8

LH

S9

S9

Lz

LT

LH

Lz

I

LA
S8
(−ε, −ε, 0, 0, 0)

E2
LA
S9
(−ε, −ε, −ε, 0, 0)

I

E1
SS
S12
(−ε, −ε, −ε, −ε, 0)

I

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

S16

I

SSB

SS

B

B

U

I

(m + 3 f + ρ− ε, −m − 2 f , f , f ,ρ)

I

SS
S13
(−ε, −ε, −ε, −ε, 0)

E2
SS
S14

I

U

I

I

B

SS

(m + 3 f + ρ− ε, −ε, −m + f , f ,ρ)

S17

I

U

(m + 3 f + ρ− ε, −m − 2 f , f , f ,ρ)

B

U

SS
S15

I

U

E1

(ρ, f , f , f ,ρ)

Fig. 13. Subgame S2 with used hash lock z.

S12

S10

LT

LH

S21

Lw

B

E2
LA
S11
(−ε, −ε, −ε, 0, 0)

I

I

SS
S18
(−ε, −ε, −ε, −ε, 0)

S22

SS

B

U[t2,t1]

U

U>t1

E2
SS
S19

SSE1

SSI

I

E2

(m + 3 f + ρ− ε, −ε, −m − f , f ,ρ)

(m + 3 f + ρ− ε, −ε, −ε, −m,ρ)

I

U<t2

SS

U

I

I

S20

E1

I

E2

(m + 3 f + ρ− ε, −m − 2 f , f , f ,ρ)

I

U

(ρ, f , f , f ,ρ)

(m + 3 f + ρ− ε, −ε, −m − f , f ,ρ)

S23

SSE1

B

I

S24

SSE1

(m + 3 f + ρ− ε, −ε, −m − f , f ,ρ)

Fig. 14. Subgame S3 with time-out ordering t3 > t1 > t2 > t4.

22

This figure "SubgameS1p.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

This figure "SubgameS3p.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

This figure "SubgamesS2p3.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

This figure "SubgameS4.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

This figure "SubgameS4p.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

This figure "SubgamesS12.png" is available in "png"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

This figure "closinggame.PNG" is available in "PNG"(cid:10) format from:

http://arxiv.org/ps/2109.07429v4

