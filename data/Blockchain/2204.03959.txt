2
2
0
2

r
p
A
1
1

]
I

A
.
s
c
[

2
v
9
5
9
3
0
.
4
0
2
2
:
v
i
X
r
a

Blockchain as an Enabler for Transfer Learning
in Smart Environments

Amin Anjomshoaa[0000−0001−6277−742X] and Edward Curry[0000−0001−8236−6433]

Lero – the Irish Software Research Centre ,
National University of Ireland, amin.anjomshoaa,edward.curry@mu.ie

Abstract. The knowledge, embodied in machine learning models for
intelligent systems, is commonly associated with time-consuming and
costly processes such as large-scale data collection, data labelling, net-
work training, and ﬁne-tuning of models. Sharing and reuse of these
elaborated models between intelligent systems deployed in a diﬀerent
environment, which is known as transfer learning, would facilitate the
adoption of services for the users and accelerates the uptake of intelli-
gent systems in environments such as smart building and smart city ap-
plications. In this context, the communication and knowledge exchange
between AI-enabled environments depend on complicated networks of
systems, system of systems, digital assets, and their chain of dependen-
cies that hardly follows the centralized schema of traditional information
systems. Rather, it requires an adaptive decentralized system architec-
ture that is empowered by features such as data provenance, workﬂow
transparency, and validation of process participants. In this research,
we propose a decentralized and adaptive software framework based on
blockchain and knowledge graph technologies that supports the knowl-
edge exchange and interoperability between IoT-enabled environments,
in a transparent and trustworthy way.

Keywords: Smart Environment · Blockchain · Machine Learning · Knowl-
edge Graph.

1

Introduction

Internet of Things (IoT) and cognitive computing are the two major enabling
technologies in smart environment solutions such as smart home, smart build-
ing, and smart oﬃce use cases. Thanks to the proliferation of networking and
communication trends and since the emergence of IoT, deploying the IoT infras-
tructure for sensing and monitoring of spaces is rather a straightforward practice.
However, cognitive knowledge cannot be explicitly deﬁned and is acquired by ob-
servation and experimentation. An example of this type of cognitive knowledge
is machine learning models that are taught to undertake complex tasks and to
create explicit and actionable knowledge from descriptive knowledge.

The IoT-enabled systems are typically built following a three-layer model
that consists of: (i) a sensing layer, which acquires the observation of interest

 
 
 
 
 
 
2

A. Anjomshoaa et al.

from the environment; (ii) a cognitive layer, which is concerned with context
acquisition, modeling, and reasoning; and (iii) an actuate layer that triggers an
action or invokes a service according to some predeﬁned logic. The main eﬀort
required for automatic change management in a private IoT space is hidden in the
cognitive layer. Unlike the sense and actuate layers which typically undertake
straightforward tasks, the creation and conﬁguration of the context layer is a
complicated task which is not necessarily based on a syntactic or deterministic
model. Instead, it needs a deep understanding of incoming events as well as the
context of those events. Currently, human intervention is necessary to interpret
the incoming data from the sensor layer and add the missing semantics about
the events and their context.

Fig. 1. Three-layer model of an IoT-based system including sensing, context, and ac-
tuation layers.

In order to beneﬁt the services of our IoT-enabled environments, we need to
calibrate and conﬁgure them based on space-speciﬁc properties and semantics.
These personalized conﬁgurations are commonly captured in dedicated informa-
tion resources such as service compositions, sense-actuate cycles, and well-trained
machine-learning models. In this context, the smart space services, embodied in
machine learning models, are commonly associated with time-consuming and
costly processes such as large-scale data collection, data labeling, network train-
ing, and ﬁne-tuning models. Increasing access to the cognitive knowledge held
by these models unlocks the value of transfer learning in smart environment and
enables sustainable and autonomous growth of IoT-enabled environment.

In the context of smart built environments, machine learning methods beneﬁt
from the huge amount of data in IoT-enabled spaces in their training processes.
Such models could yield signiﬁcant proﬁt over the lifetime of a building but due
to the high cost of training and the need of large amounts of training and testing
data sets, the uptake of machine learning applications in built environments is
rather slow. For instance, in a smart environment a speech recognition model
could be trained based on a rather big and elaborated dataset. However, the
model might not be used in diﬀerent spaces as it should be retrained to cope
with the surrounding noise of the target space. This gives smart environments

Blockchain as an Enabler for Transfer Learning in Smart Environments

3

an incentive to reuse and re-purpose the existing models via techniques such as
transfer learning where models trained on one task are re-purposed for a second
related task.

Currently, machine learning processes are commonly built for intra-organization

purposes and tailored towards speciﬁc use cases with the assumption of inte-
grated model repositories and feature pools. In order to unleash the power of
these resources, they need to be shared and reused in a trustworthy and trans-
parent way which requires an adaptive decentralized system architecture that
is empowered by features such as data provenance, workﬂow transparency, and
validation of process participants.

In order to make the machine learning processes for intelligent systems and
their digital assets the ﬁrst-class citizens of a decentralized and peer-to-peer
ecosystem, the following challenges should be addressed:

1. Integrity: As we move beyond the borders of ML model’s source environ-
ments (e.g. space, building, or city), we would need to fortify the integrity
and traceability of adopted digital assets such as training datasets or trans-
ferred models.

2. Transparency and trust: in a decentralized process, the transparency and
trustworthiness of actors and digital assets are of great importance. Although
the transparency and trustworthiness are the main drivers behind the shift
to blockchain technology, but issues such as communication between private
and public blockchains and inter-organizational trust networks needs to be
investigated via a holistic approach that takes the speciﬁc characteristics of
machine learning pipelines into account.

3. Explainable machine learnig chains: the transfer learning processes are
commonly undertaken by a human who is able to understand the implicit
semantics of environments, features, as well as the relevant information re-
sources and services. Therefore, self-explaining and machine-understandable
digital assets (e.g. features and models) are the key requirements to enable
transfer learning beyond the organizational borders.

In this research, we propose a decentralized and adaptive software framework
based on blockchain and knowledge graph technologies for reliable and decen-
tralized transfer of machine learning digital assets between AI-enabled smart
environments such as smart buildings and smart city, in a transparent and trust-
worthy way. The proposed approach in this research follows the principles of
Inter-Space Learning (ISL) framework [1] that was presented ion our previous
work. Using ISL framework, smart environment resources are processed, aligned,
and reconciled to create a uniform and interconnected information space that
facilitates provisioning of the Inter-space learning. This research an adaptive
intelligent system architecture and advances the ISL framework by:

1. Establishing a decentralized feature space that provides context for machine
learning processes and makes their digital assets explainable and interoper-
able for transfer learning purposes. This will be achieved by creating and

4

A. Anjomshoaa et al.

maintaining a knowledge graph that is aware of both machine learning fea-
tures, their semantics, and the models trained based on those features. The
knowledge graph includes also the evaluation indicators of machine learning
models which facilitate the sharing and reuse of models beyond the organi-
zation boundaries.

2. Integration of blockchains into machine learning pipelines in order to safe-
guard the data integrity and trustworthiness in cross-organization transfer
learning scenarios. To this end, we exploit blockchain technology to capture
the interaction between machine learning digital assets including raw data,
features, and models.

3. Creating a collaborative and adoptive framework based on public and private
blockchains where participants can continually share, reuse, and evaluate
machine learning assets in a reliable and incentive-oriented manner. As such,
the participants will be able to beneﬁt from publicly-traceable ML pipelines
and integrate them in their secure intra-organization processes.

1.1 Building Industry as a Motivational Use Case

Improvement of the energy performance of buildings is a major contributor for
achieving the goals of the EU 2030 climate and energy framework 1. By 2050 at
least 75% of today’s buildings will still exist and as a result, renovation of ex-
isting buildings and making them energy-eﬃcient will have signiﬁcant economic
and environmental impacts. The majority of legacy buildings were mainly built
without considering the energy performance requirements and there is a high
potential of saving in operational energy costs. Furthermore, by renovating the
legacy buildings, the embodied energy of new constructions which makes up a
major part of the total energy use in buildings, could be avoided.

Current renovation processes commonly extend the existing buildings with
additional intelligence in order to optimize the operational costs. In this context,
the major enabling technologies are IoT and cognitive computing. While deploy-
ing IoT infrastructure during the renovation processes is rather a straightforward
practice, the implementation of cognitive components that beneﬁt from gener-
ated data of IoT infrastructure is a complicated task that should be elaborated
based on the speciﬁc attributes of tasks and buildings.

In smart buildings, such cognitive components can be realized via machine
learning models that are taught to undertake complex tasks. The high costs
of creating such models which require large amounts of training and testing
datasets, gives smart environments the incentive to share and reuse the exist-
ing models. This research aims to investigate the potential of communication
and reuse of cognitive knowledge between smart environments using blockchain
technology.

1 https://ec.europa.eu/energy/sites/ener/files/documents/1.final_report.

pdf

Blockchain as an Enabler for Transfer Learning in Smart Environments

5

2 Knowledge Graph

In our previous work, we introduced the Inter-Space Learning Framework (ISL)
[1] Which uses knowledge graph as an eﬃcient medium for communicating the
semantics of smart environments and bridging the information gap among IoT
infrastructure, spaces, and machine learning processes.

As such the digital assets of machine learning processes are presented in an
explainable and interoperable way which will facilitate the transfer of cognitive
components. The proposed knowledge graph in ISL is aware of IoT infrastructure
of target environments as well as machine learning features, their semantics, and
the models trained based on those features. The knowledge graph includes also
the evaluation indicators of machine learning models which facilitate the sharing
and reuse of models beyond the organization boundaries.

As depicted in Figure 2, machine learning processes can be characterized
based on their input data, output model, and model evaluation measures such
as Mean Absolute Error (MAE) or Mean Squared Error (MSE) of learning pro-
cesses. Furthermore, each model is dedicated to a speciﬁc task deﬁned by ML-
Schema which helps spaces to ﬁnd the relevant models shared by other spaces.
As such, the models are presented in a self-explainable and interpretable way to
both human users as well as space agents (machines).

The training process depicted in Figure 2 undertakes a transfer learning
process. In this speciﬁc case, the process includes a ﬁne-tuning process which
takes the trained model of another room (model of Room-2) as input and retrain
it based on a small ﬁne-tuning dataset of target room (Room 3).

Fig. 2. Deﬁnition of a model in Knowledge Graph

6

A. Anjomshoaa et al.

The ISL frameworks envisions communication between multiple ISL nodes
where each node represents the underlying knowledge of corresponding smart
environment captured in the knowledge graph using a common schema of build-
ing assets (i.e. semantics of sensors, services, etc.). Based on this conﬁguration
users will be able to query services that match the characteristics of a given
space (i.e., IoT devices such as sensors and actuators). As shown in Figure 3,
in a model query scenario, user can match the IoT speciﬁcation of target space
with the oﬀered models and retrieve the feasible models. For instance, in case
of room occupancy detection based on CO2 sensors, the target room should be
equipped with a CO2 sensor and all retrieved models should also accept CO2
data as input. In the next step, the retrieved models can be ranked based on
quality indicators which are also available in knowledge graph and are oﬀered
by the ISL framework. As an extra step and if some training data is available in
the target space, the model can be ﬁne-tuned for a better performance.

Fig. 3. Model query and reuse process.

3 Proposed Approach

In order to realize this requirements, the ISL resources needs to be shared and
advertised on blockchain by ISL nodes. These resources are usually not deter-
ministic which contradicts with the nature of blockchain. The technical solution
to address this issue is to use an Oracle Smart Contract which is responsible
to retrieve and verify external data for blockchain and smart contracts through
methods such as web APIs or data feeds.

In our case, we would need an oracle to interact with external ISL nodes that
are willing to share and reuse machine learning models and their corresponding
assets. In our implementation, the oracle smart contract is created by the network
owner and manages list of trustworthy ISL nodes. It also allows the trustworthy
ISL nodes to add their resources and maintains a registry of shared resources.

In this section, we formally deﬁne the knowledge sharing framework and
outline how we use the blockchain technology to facilitate the communication
and knowledge exchange between ISL nodes.

Blockchain as an Enabler for Transfer Learning in Smart Environments

7

Let N be the set of ISL nodes representing the digital twins of smart en-
vironments that are supposed to take part in transfer learning use cases. Each
ISL node α ∈ N is then characterized by its knowledge graph that we denote
by Gα and captures the description of machine learning assets such as training
datasets and ML models. We deﬁne a local dataset as a dataset that is captured
in Gα and owned by the corresponding ISL node.

We denote the collection of local datasets introduced in knowledge graph Gα
by D|Gα . Additionally, the subset of local datasets that are shared by the ISL
node α are denoted by D|
and we refer to them as blockchain-enabled datasets.
Further, we denote the set of all blockchain-enabled datasets as D∗ and deﬁne
it as follows:

Gα

D∗ = {D∗|Gn : n ∈ N }

Consequently, the models that are introduced in Gα can be trained using the
available local or blockchain-enabled datasets to achieve a speciﬁc task. The set
of all models introduced by the knowledge graph Gα is deﬁned as:

M|Gα = {Mi(cid:104)task, dataset, model uri, base model(cid:105) : i = 1, 2, . . . , m}

Where task is an instance of class Task deﬁned in the knowledge graph;
model uri is the identiﬁer of the target model ﬁle; and dataset is selected from
D|Gα ∪ D∗. Furthermore, in case of models that are trained from scratch, no
base model is needed and we set the base-model to null. However, in a transfer
learning case, the new model reuses an existing base model that either resides on
the same ISL node as the new model, or comes from the pool of shared models
from other ISL nodes. Similar to shared datasets, we denote the subset of local
models that are shared by the ISL node α as M∗|Gα. We also denote the set of
all blockchain-enabled models as M∗ and deﬁne it as follows:

M∗ = {M∗|Gn : n ∈ N }

So, the base model in a transfer learning case is selected from M|Gα ∪ M∗.
As such, each model Mn depends on its training/ﬁne-tuning dataset Dn and
its base model (if any) Mn−1. Then the dependency chain of model Mn that
include a number of blockchain-enabled models and datasets, can be constructed
as follows:

∅ D0−−→ M0

D1−−→ M1 → . . . Dn−−→ Mn

At the root of all dependency chains, we have a model created based on a null
model and using a speciﬁc dataset. This indicates that this model is created from
scratch trained based on the speciﬁed dataset. Following this presentation, the
collection of all dependency chains can be captured as a directed acyclic graph
where vertices represent models and edges represent the corresponding dataset.
Furthermore, all vertices, except for the root vertex, have in-degree one. An
example of such dependency graph is depicted in Figure 4 where shared models
are shown as red boxes. It’s important to note that all assets of a shared model

8

A. Anjomshoaa et al.

including ancestor models and the datasets used for training/ﬁne-tuning in the
dependency chain are required to be shard as well. In this way, one can easily
trace back all the used assets of each model and investigate the authenticity of
models and datasets.

Fig. 4. Example of model dependency graph.

As depicted in Figure 5, the blockchain is used as shared medium between
service providers and service consumers on ISL network to store the metadata
of machine learning assets.

Fig. 5. Process of sharing and consuming of cognitive resources between smart datas-
paces.

Our proposed blockchain solution, includes an Oracle smart contract that
keeps track of sharing resources and their dependency chains. More speciﬁcally,
the Oracle at its basic level is deﬁned as follows:

Oracle = (cid:104)D∗, M∗, task index(cid:105)

Blockchain as an Enabler for Transfer Learning in Smart Environments

9

Where task index maps task instances to models and facilitates searching for

appropriate models.

The resource providers register their models and dataset via the Oracle smart
contract as shown in Figure 6. To this end, the network owner needs to introduce
the ISL node to blockchain by registering them to the oracle smart contract.
Then, registered ISL nodes will be able to add the metadata of their resources
to the oracle smart contract. In return, they receive a unique identiﬁer that will
be added to knowledge graph for further queries.

Fig. 6. Sharing resources on blockchain

On the other hand, as shown in Figure 7, the resource consumers can query
the Oracle smart contract for the machine learning models that fulﬁll a speciﬁc
task. Then, the consumer can negotiate the corresponding resource owners (ISL
nodes) for ﬁnding the qualiﬁed resources. In the next step, the consumer will pay
for the resource and receives the resource address and access token to retrieve
the requested resource.

4

Implementation

As proof of concept, we have implemented a prototype based on the proposed
methodology. In this section, we provide an overview of the technical architec-
ture which is depicted in Figure 8 extends our previous implementation of ISL
framework for knowledge sharing between smart environments [1].

At the core of ISL framework, we have the knowledge graphs of ISL nodes
that include the description of spaces, IoT conﬁgurations, and machine learning
assets. The knowledge graphs are maintained by each ISL node and stored using
Cayley2, an open-source database for Linked Data. The node implementation
oﬀers APIs for communication between ISL nodes as well as a web interface for

2 https://github.com/cayleygraph

10

A. Anjomshoaa et al.

Fig. 7. Consuming blockchain resources.

displaying and visualizing the knowledge graph assets and entities. In the new
implementation, we leverage the existing knowledge graphs in order to store the
relevant information of blockchain environment and blockchain-enabled assets.
This includes the information of blockchain accounts as well as the blockchain
addresses of shared resources such as datasets and models.

Fig. 8. Architecture of implemented prototype.

In order to make the ISL nodes blockchain-enabled, the ISL nodes web
application is upgraded to a decentralized application(dApp) implemented on

Blockchain as an Enabler for Transfer Learning in Smart Environments

11

Ethereum test network. We have used Ganache 3 environment to develop and
test the required smart contracts. To this end, each ISL nodes is equipped with
a unique account address that is used to identify the corresponding ISL node on
the blockchain. The implementation includes the following two smart contracts
that are implemented in Solidity programming language [3]:

– ISL smart contract which provides an interface for interaction between ISL
nodes and organizes transactions such as acquiring resources (e.g.; datasets
and models) and performing payment transactions if required.

– Oracle smart contract which is responsible for governance of participating
ISL nodes and manages dedicated lists of shared resources. This smart con-
tract also includes the account number of the oracle owner who has the
authority to register new ISL nodes. As such, only trusted ISL nodes will be
allowed to contribute their resources or acquire the shared resources from
other trusted ISL nodes.

In this architecture, each ISL node stores its resources oﬀ-chain in a local
ﬁle repositories which is only accessible to the ISL node itself. However, when
the resource is shared on blockchain, we would need to provide access to the
resource ﬁles to external ISL nodes. To this end, we use InterPlanetary File
System (IPFS) which is a protocol and peer-to-peer network for storing and
sharing data in a distributed ﬁle system. In our case, whenever an ISL node
shares a resource such as dataset of model on blockchain, the underlying ﬁles
will be stored on IPFS. Then, the unique content-address which is assigned by
IPFS will be added to both the local knowledge graph and the corresponding list
in oracle smart contract. Since the IPFS provides a universally unique address
for each resource, the resources cannot be shared twice. As such, the ownership
rights of resources can be checked and preserved by the oracle smart contract.
Figure 9 demonstrates the representation of a blockchain-enabled dataset in
the knowledge graph which includes the URI of the local dataset ﬁle, the URI of
shared dataset on IPFS, and the unique transaction identiﬁer which is assigned
by the oracle smart contract.

5 Related Work

There is a handful of methodologies and platforms that facilitate knowledge
management and data sharing for machine learning scenarios. In this section,
we explore a number of existing solution and research work that are expanded
on the ﬁelds of machine learning, blockchain, and data sharing frameworks.

5.1 Blockchain-based Machine Learning Approaches

Machine learning solutions are commonly designed to be used within organiza-
tion boundaries. However due to the costly approached for creating elaborated

3 https://www.truﬄesuite.com/ganache

12

A. Anjomshoaa et al.

Fig. 9. Structure of blockchain-enabled resources in knowledge graph.

models, it makes sense to share and reuse the machine learning assets beyond or-
ganization borders. In this context we would need a trustworthy and sustainable
approach to make the machine learning models accessible to external entities.

Recently, several research works have used blockchain as share and reuse
medium in machine learning use cases. For instance, DInEMMo [11] proposes a
solution that combines machine learning and blockchain frameworks to create
a marketplace for machine learning models that enables to reward both model
creators as well as actors that contribute to enhance existing models. In [13], au-
thors present BlockDeepNet, a Blockchain-based secure deep learning solution
that combines deep learning and blockchain technologies to support secure col-
laborative learning in IoT environments. the work in [8] proposes a framework
for participants to collaboratively build a dataset and use smart contracts to
host a continuously updated model. This work also presents ﬁnancial and non-
ﬁnancial (gamiﬁed) incentive structures for providing good data and includes a
prototype implemented on Ethereum blockchain.

Another study on secure and resilient machine learning adoption for making
blockchain-based smart applications has been presented in [15] where traditional
machine learning techniques are applied to analyze the attacks on a blockchain-
based network. The study also discusses how these technologies can be applied in
applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), health-
care, and smart cities. The work in [17] proposes a solution for data trading
based on smart contract using blockchain to protect the rights and interests of
the data owner, and oﬀ-chain machine learning methods for addressing the data
availability controversies.

The work in [10] have proposed a protocol based on the anonymous and
distributed nature of smart contracts, and the problem-solving aspect of ma-
chine learning which helps users obtain machine learning models for a given fee.
The protocol does not require trust and works completely on a decentralized
blockchain. The work in [6] presents a conﬁgurable framework for training a
model and collecting data on blockchain.

Blockchain as an Enabler for Transfer Learning in Smart Environments

13

Decentralized machine learning protocol (DML) [4] project focuses on on-
device machine learning, blockchain and federated learning technologies. It un-
leashes untapped data usage without extraction and idle processing power of user
computers for machine learning. Algorithms will be crowdsourced from a devel-
oper community through the marketplace resulting innovation from periphery.
The GNY’s decentralized machine learning solution [5] aims to bring a secure,
collaborative platform for machine learning, data capture and analysis to the
Lisk blockchain project.

5.2 Artifact Sharing in Machine Learning Environments

Machine learning solution consist of multiple sequential steps that range from
data processing and feature engineering to model training and deployment. There
is a handful of existing solutions and research work for managing the life cycle
of machine learning processes and pipelines.

ModelDB [16] is an open source model management system that oﬀers ser-
vices for saving models and their associated metadata. It also includes services
for measuring the performance of machine learning models and querying models.
ModelHUB [12] is another platform for managing the lifecycle of deep learning
models that provides services for model storage and keeps track of associated
metadata and accuracy scores. Although these solutions facilitate the communi-
cation between team members and support pipelines for creating and managing
machine learning workﬂows, however such solutions does not cross the organiza-
tion borders and it is not easy to share the artifacts in a reliable and trustworthy
way.

Another project in this context is TensorFlow Extended (TFX) [2] which
a solution built around is the Google’s TensorFlow, an end-to-end open source
platform for machine learning. By integrating various machine learning artifacts
into one platform, it provides a standardize way to manage and access machine
learning assets and artifacts which facilitates the platform conﬁguration, and
reduce the time to production signiﬁcantly, while providing platform stability.

Michelangelo [7] platform is the Uber’s solution for building, deploying, and
operating machine learning workﬂows in a collaborative environment and cov-
ers areas such as data management, model training, and model deployment,
evaluation, and monitoring. An integral part of the Michelangelo platform is
a sub-system called Gallery [14] that manages the lifecycle of machine learning
models by orchestrating the ﬂow of models across diﬀerent stages in the lifecycle.
There are also other solutions that are more focused on data pipelines and
feature management aspects. For instance, Hopsworks Feature Store [9] provides
an open data management ecosystem for machine learning features, including
the feature engineering code and the feature data.

6 Conclusions and Future Work

Increasing access to machine learning artifacts held by various organizations will
accelerate the uptake of use cases and solutions for smart environments such

14

A. Anjomshoaa et al.

as smart home and smart buildings. Due to increasing number of IoT-enabled
environments and the costs associated with machine learning processes, sharing
and reuse of machine learning assets and artifacts beyond organization borders
are plausible solutions. In this paper, we proposed a decentralized and adaptive
software framework based on blockchain and knowledge graph technologies that
supports the knowledge exchange and interoperability between smart environ-
ments, in a transparent and trustworthy way. The proposed architecture can be
used in ways that increase communication between smart environments, enable
sustainable growth of IoT solutions, and drive sharing of cognitive knowledge via
transfer learning. In this context, self-explaining and machine-understandable
digital assets (e.g., features and models) are the key requirements to enable
transfer learning beyond the organizational borders. Also, blockchain technol-
ogy and smart contracts foster transparent and trustworthy sharing of machine
learning assets and advance cross-organization communication between smart
environments.

7 Acknowledgement

This work was supported with the ﬁnancial support of the Science Foundation
Ireland grant 13/RC/2094 and co-funded under the European Regional Develop-
ment Fund through the Southern & Eastern Regional Operational Programme
to Lero - the Irish Software Research Centre (www.lero.ie).

References

1. Anjomshoaa, A., Curry, E.: Transfer learning in smart environments. Machine

Learning and Knowledge Extraction 3(2), 318–332 (2021)

2. Baylor, D., Breck, E., Cheng, H.T., Fiedel, N., Foo, C.Y., Haque, Z., Haykal, S.,
Ispir, M., Jain, V., Koc, L., et al.: Tfx: A tensorﬂow-based production-scale ma-
chine learning platform. In: Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. pp. 1387–1395 (2017)

3. Dannen, C.: Introducing Ethereum and solidity, vol. 318. Springer (2017)
4. DML, D.: Decentralized machine

protocol

learning

(dml),

https:

//decentralizedml.com/, [Online; accessed 15-July-2021]

5. GNY: Gny decentralized machine learning), https://www.gny.io/, [Online; ac-

cessed 15-July-2021]

6. Harris, J.D., Waggoner, B.: Decentralized and collaborative ai on blockchain. In:
2019 IEEE International Conference on Blockchain (Blockchain). pp. 368–375.
IEEE (2019)

7. Hermann, J., Del Balso, M.: Meet michelangelo: Uber’s machine learning platform.

URL https://eng. uber. com/michelangelo (2017)

8. Justin, D., Harris, B.: Decentralized & collaborative ai on blockchain. In: Pro-
ceedings of the 2019 IEEE International Conference on Blockchain (Blockchain),
Atlanta, GA, USA. pp. 14–17 (2019)

9. Kakantousis, T., Kouzoupis, A., Buso, F., Berthou, G., Dowling, J., Haridi, S.:
Horizontally scalable ml pipelines with a feature store. In: Proc. 2nd SysML Conf.,
Palo Alto, USA (2019)

Blockchain as an Enabler for Transfer Learning in Smart Environments

15

10. Kurtulmus, A.B., Daniel, K.: Trustless machine learning contracts; evaluating and
exchanging machine learning models on the ethereum blockchain. arXiv preprint
arXiv:1802.10185 (2018)

11. Marathe, A., Narayanan, K., Gupta, A., Manoj, P.: Dinemmo: Decentralized in-
centivization for enterprise marketplace models. In: 2018 IEEE 25th International
Conference on High Performance Computing Workshops (HiPCW). pp. 95–100.
IEEE (2018)

12. Miao, H., Li, A., Davis, L.S., Deshpande, A.: Modelhub: Deep learning lifecycle
management. In: 2017 IEEE 33rd International Conference on Data Engineering
(ICDE). pp. 1393–1394. IEEE (2017)

13. Rathore, S., Pan, Y., Park, J.H.: Blockdeepnet: A blockchain-based se-
3974 (Jul 2019).

cure deep learning for iot network. Sustainability 11(14),
https://doi.org/10.3390/su11143974, http://dx.doi.org/10.3390/su11143974
14. Sun, C., Azari, N., Turakhia, C.: Gallery: A machine learning model management

system at uber. In: EDBT. pp. 474–485 (2020)

15. Tanwar, S., Bhatia, Q., Patel, P., Kumari, A., Singh, P.K., Hong, W.C.: Machine
learning adoption in blockchain-based smart applications: The challenges, and a
way forward. IEEE Access 8, 474–488 (2019)

16. Vartak, M., Subramanyam, H., Lee, W.E., Viswanathan, S., Husnoo, S., Mad-
den, S., Zaharia, M.: Modeldb: a system for machine learning model management.
In: Proceedings of the Workshop on Human-In-the-Loop Data Analytics. pp. 1–3
(2016)

17. Xiong, W., Xiong, L.: Smart contract based data trading mode using blockchain

and machine learning. IEEE Access 7, 102331–102344 (2019)

