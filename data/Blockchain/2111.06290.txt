Fairness, Integrity, and Privacy in a Scalable Blockchain-based
Federated Learning System

Timon R¨uckel a,∗, Johannes Sedlmeir b,c , Peter Hofmann b,c

a University of Bayreuth, Bayreuth, Germany
b FIM Research Center, University of Bayreuth, Bayreuth, Germany
c Project Group Business & Information Systems Engineering of the Fraunhofer FIT, Bayreuth, Germany

∗ Corresponding author: timonrueckel@hotmail.de

This is the accepted version of an article with the same name, published in the
Special Issue “Federated Learning and Blockchain Supported Smart Networking in
Beyond 5G (B5G) Wireless Communication” in Computer Networks.

Abstract

Federated machine learning (FL) allows to collectively train models on sensitive data as only the

clients’ models and not their training data need to be shared. However, despite the attention that

research on FL has drawn, the concept still lacks broad adoption in practice. One of the key reasons

is the great challenge to implement FL systems that simultaneously achieve fairness, integrity,

and privacy preservation for all participating clients. To contribute to solving this issue, our

paper suggests a FL system that incorporates blockchain technology, local diﬀerential privacy, and

zero-knowledge proofs. Our implementation of a proof-of-concept with multiple linear regression

illustrates that these state-of-the-art technologies can be combined to a FL system that aligns

economic incentives, trust, and conﬁdentiality requirements in a scalable and transparent system.

Keywords: Blockchain, Diﬀerential Privacy, Distributed Ledger Technology, Federated Machine

Learning, Zero-Knowledge Proof

1
2
0
2

v
o
N
1
1

]

R
C
.
s
c
[

1
v
0
9
2
6
0
.
1
1
1
2
:
v
i
X
r
a

Preprint accepted for publication at Computer Networks

November 12, 2021

 
 
 
 
 
 
Highlights

• Fairness, integrity, and privacy are important requirements for federated learning.

• It is challenging to achieve all of these requirements at the same time.

• With blockchain, diﬀerential privacy, and zero-knowledge proofs we can satisfy them.

• We provide a proof of concept for the case of multiple linear regressions.

• Our evaluation indicates that the architecture is practical and scalable.

1•  Vortragender•  Vortragstitel© FIM Research CenterZero-knowledgeproofsensure that clients cannot submit fraudulent information (i.e., weights or model cost) to the federated learning network to inappropriately benefit from the incentive mechanism or harm the model.PrivacyFair IncentivesIntegrityABlockchain eliminates the need for a centralized authority, provides transparency, enforces the federated learning protocol, and provides a decentralized infrastructure for the collection of fees and the distribution of rewards.An Incentive Mechanismcompensates and motivates clients to participate in the federated learning training process by rewarding them for training and submitting local models. The reward payment is calculated based on the client’s performance contribution to the global model.Differential privacyfurther increases the clients'privacy by perturbing weights before uploading their local models to the blockchain. In doing so, differential privacy avoids deep leakage from publicly available weights and, thus, ensures clients' ultimate privacy.Ablockchain eliminates the need for a centralized authority, provides transparency, enforces the federated learning protocol, and provides a decentralized infrastructure for the collection of fees and the distribution of rewards.An incentive mechanismcompensates and motivates clients to participate in the federated learning training process by rewarding them for training and submitting local models. The reward payment is calculated based on the clients' performance contribution to the global model.Federated learningenables multiple clients to jointly train a machine learning model without disclosing their private data.1. Introduction

The application of machine learning (ML) promises far-reaching potentials across industries [1].

ML has already proven successful in many areas, such as web search or recommender systems in

e-commerce, in which a lot of high-quality data exists [2]. While researchers address ML’s growing

demand for compute power and use of data with, e.g., distributed ML approaches where multiple

computing nodes share their resources [3, 4, 5] and quality issues with data processing, access to

data is not only a technical issue. Both traditional ML and distributed ML approaches assume

that their training data is centralized by nature, preventing the applicability of ML approaches to

domains in which data is sensitive and distributed at the same time. To avoid that ML approaches

must rely on data to which only a centralized organization or individual has full access, federated

machine learning (FL) can aggregate the less sensitive ML models that were independently and lo-

cally trained by individual clients [6, 7]. Consequently, FL can enable the use of ML applications in

domains with strong privacy requirements and contribute to solving the challenge of limited access

to sensitive data without invading participating clients’ privacy [8, 9]. For instance, researchers

at Google aimed to improve next word predictions for mobile devices based on private user data,

i.e., the words users are typing [10].

In the case of autonomous driving, FL could reduce the

data transmission overhead in vehicular networks while still respecting privacy requirements [11].

These examples demonstrate FL’s capability to avoid the obligation to centralize data. Thus, FL

approaches improve functionality or even enable new value creation scenarios for ML.

Despite these promising applications and developments, FL in practice has not yet encountered

broad adoption [12]. This can be traced to a variety of design requirements that have not been

met simultaneously so far. For example, FL systems require, amongst others, privacy guarantees

exceeding FL’s privacy by design [13] as well as high degrees of fairness and integrity [12, 14]. Com-

pared to centralized ML, FL already ensures a certain level of privacy for participating clients [12].

However, even when replacing centralized data with clients’ model updates in a FL system, these

public model updates can still leak insights on private client data [13, 15, 16, 17, 18, 19]. While

research has addressed this issue with diﬀerent approaches, there are tradeoﬀs in terms of perfor-

mance and integrity, as plausibility checks of the contributed models cannot be made any more

when the individual model updates are obfuscated. Second, FL systems can be subject to malicious

client attacks that try to harm the global model performance by submitting model updates that

have been trained on data sets unequal to the client’s actual data (or even generated on purpose to

harm the quality of the aggregate global model). So-called data-poisoning attacks can reduce model

performance by up to 90 % [9, 12]. Third, the above application examples assume that users con-

tribute their data, computation, and communication resources unconditionally. However, scaling

1

FL to broad adoption in practice requires fair and transparent incentive mechanisms to appropri-

ately remunerate clients for their contribution to the global model performance [4, 12, 14, 20, 21].

FL can be subject to free-riding attacks in which malicious clients fraudulently beneﬁt from the

incentive mechanism by submitting model updates that are not based on the respective client’s

private data [12, 14]. Moreover, in a conventional FL setting, clients are forced to trust the central

entity to remunerate all clients fairly without being able to check whether this central entity acts

truthfully or maliciously.

Satisfying the described privacy, integrity, and fairness requirements in a FL system whilst still

being scalable requires an interdisciplinary discourse that bundles up a combination of technologies

within a FL system [4, 6]. Even though a vast amount of research in various disciplines already

exists, there are, to the best of our knowledge, no systems that jointly deliver privacy, integrity,

and fair incentives. Thus, we explore the following research question:

How can a FL system achieve fairness, integrity, and privacy whilst still being practical

and scalable?

To answer this research question, we propose a FL system that levers blockchain technology,

local diﬀerential privacy (LDP), and zero-knowledge proofs (ZKPs). We thus integrate these emerg-

ing technologies to provide a novel and smart FL-based architecture with the following properties:

• Fair incentives: Our proposed FL architecture measures the individual contribution to

the global model performance per client based on the client’s actual parameters (i.e., with-

out the LDP-noise) and incentivizes each client accordingly. By building our FL system

based on blockchain, a smart contract enforces the transparent and veriﬁable distribution of

incentives [22, 23].

• Integrity: Non-interactive ZKPs enable clients to validate that fellow clients have truth-

fully trained their submitted model updates based on private data that they committed to

earlier, potentially including a proof of provenance (e.g., from a certiﬁed sensor). In doing

so, these fellow clients do not have to reveal any of their private data, yet we can guarantee

that they do the training and evaluation for their incentive truthfully. Further, we build our

FL system based on blockchain. In the resulting decentralized setting, there is no trust in

a central authority needed regarding censorship and the correct aggregation as well as the

availability of the global model. Research has already pointed out that a blockchain can be a

suitable replacement for intermediaries in a collaborative process and help achieve standard-

2

ized communication between participants [24]. Besides, the blockchain-based design ensures

neutrality amongst all clients, the immutability of transactions, and the full transparency of

the architecture for all clients.

• Privacy: To make sure that clients’ model updates cannot leak information on patterns

within their private data, we leverage LDP to perturb each clients’ model update with Lapla-

cian noise.

We discuss and instantiate our architecture for multiple linear regression (LR) as FL model.

For the implementation, we use succinct non-interactive arguments of knowledge (SNARKs) im-

plemented in circom and snarkjs as well as smart contracts deployed on an Ethereum virtual

machine (EVM) implemented in Solidity. Through implementing and testing the system, we

demonstrate that a realization of our architecture can achieve reasonable performance and scal-

ability. Moreover, we gain valuable insights into how the combination of FL, LDP, ZKPs, and

blockchain can be applied to more sophisticated ML models beyond FL. By proposing our FL

system that integrates several emerging technologies in a novel way, we contribute a solution that

demonstrates that fairness, integrity, and privacy requirements can be solved in practical settings

and thus also improve the real-world applicability of existing FL approaches. As we pointed out

that using FL approaches alone is not practical for some application scenarios, we contribute to

overcoming relevant hurdles towards applicability. The developed FL system is scalable, ensures

integrity, and attracts clients to participate through fair incentives as well as data privacy guaran-

tees.

We structure this paper as follows: In Section 2, we brieﬂy present the technical building blocks

of our FL system (i.e., FL, LDP, ZKPs, and blockchain technology) and discuss related work on

the design of FL systems. Afterward, we present the architecture and implementation of our FL-

system in Section 3 and evaluate it in Section 4. Finally, we discuss our results, describe our

research’s limitations, and outline future research opportunities in Section 5.

2. Foundations

2.1. Federated Learning

Federated machine learning describes the concept of training local ML models on distributed

and private client data without transferring the data beyond the client’s reach. After training the

local parameters, clients in the FL system submit model updates derived from their locally trained

parameters to a server that aggregates all local model updates to a global model [4]. The types of

potential clients are diverse and range from organizations and mobile devices equipped with sensors

3

to autonomous vehicles. Research has recently applied FL systems in several domains including

health, the internet of things (IoT), vehicular networks, ﬁnance, sales, or smart homes [6, 9]. By

bringing the computation to the data, FL improves clients’ privacy [6]. Besides, FL can increase

the eﬃciency of existing infrastructure and devices by avoiding the transfer of large data sets to

a central server and by utilizing the computational power of edge devices like smartphones or

wearables [21]. In doing so, FL is typically associated with the following optimization problem [6]:

min
wg

F (wg) = min
wg





|I|
(cid:88)



biFi(wg)

 ,

(1)

i=1

where |I| is the total number of clients, bi ≥ 0, (cid:80)
|I| bi = 1 denotes the client’s relative impact,
and Fi(w) is the local objective function. The global, aggregated weight wg is mostly derived from

the local updates wi using federated averaging (FedAvg), an aggregation scheme that computes

a weighted average of the local weights wi [25]. When training on independent and identically

distributed (i.i.d.) data, FedAvg achieves similar results to centralized learning [25].

2.2. Local Diﬀerential Privacy

Diﬀerential privacy (DP) has been developed by Dwork et al. [26] to allow for analyzing sensitive

and private data in a secure way: Consider a trusted central authority that holds a data set

containing sensitive client information. The key idea of DP is to develop a query function on

the sensitive data set that returns the true answer plus random noise following a carefully chosen

distribution [27]. For example, in a study that asks participants to report a certain personal

property, participants report their binary answer by tossing a coin: They respond truthfully if

tails and if heads, the participants toss the coin again and report “yes” if heads and “no” if

tails. In this simple example, the participants’ privacy stems from the plausible deniability of any

reported value [27].

The driving force for this privacy guarantee is randomization since the guarantee must hold

regardless of all present or even future sources of background information (e.g., from the internet

or newspapers). Achieving this requires understanding the input and output space of random-

ized algorithms. Formally, a randomized algorithm M with domain A and (discrete) range B is

associated with a mapping from A to ∆(B), the probability simplex over B:

(cid:40)

∆(B) =

x ∈ R|B| : xi ≥ 0 for all i and

(cid:41)

xi = 1

.

|B|
(cid:88)

i=1

(2)

Then, on input a ∈ A and given that the probability space is over the coin ﬂips of M, the

randomized algorithm M outputs M(a) = b with probability (M(a))b for every b ∈ B [27]. Before

4

deﬁning DP, note that DP aims to sanitize a query function such that the presence or absence of

an individual in the analyzed data set cannot be determined by just observing the output of the

query. Now consider two data sets D and D(cid:48), that are either equal or diﬀer only in the presence

or absence of one individual, as histograms. Moreover, a histogram over a universe X is an object
in N|X |. Then, both data sets D, D(cid:48) ∈ N|X | are called adjacent if for the (cid:96)1-norm, (cid:107)D − D(cid:48)(cid:107)1 ≤ 1

holds. Eventually, Dwork et al. [26] deﬁne DP as follows:

Deﬁnition. A randomized algorithm M with domain N|X | and range R satisﬁes (cid:15)-diﬀerential

privacy if for every adjacent data sets D, D(cid:48) ∈ N|X | and any subset S ⊆ R we have

Pr[M(D) ∈ S] ≤ e(cid:15) Pr[M(D(cid:48)) ∈ S],

(3)

where (cid:15) > 0 is a privacy parameter.

A common way to achieve DP for a numeric function f is to add noise following a Laplacian

distribution:

L(x | 0, λ) =

1
2λ

(cid:18)

exp

−

(cid:19)

.

|x|
λ

(4)

When a user wants to learn f (x) = (cid:80)

i xi with x ∈ {0, 1}, i.e., the total number of 1’s in the data

set, (cid:15)-DP can be achieved by adding Laplacian noise [27, 28]:

˜f (x) =

(cid:88)

xi + q,

i

(cid:18)

where q ∼ L

0,

(cid:19)

.

∆f
(cid:15)

(5)

and ∆f denotes the sensitivity of f , i.e., the maximum diﬀerence of f on data sets that diﬀer in

only one element [28]. There are many practical algorithms for providing DP; and in general, they

have many characteristics beyond ε that have an impact on privacy or utility [29]. One special

case of DP is local diﬀerential privacy (LDP), where the confusion (i.e., random perturbation) is

performed locally by clients and not by a central authority [30]. By doing so, the central authority

cannot infer or access the actual client data. According to Deﬁnition 2.2, anyone accessing S

cannot distinguish whether the true data set is D or D(cid:48) with conﬁdence (controlled by (cid:15) – the

lower (cid:15), the higher the privacy and the lower the accuracy and vice versa). Thus, LDP ensures

plausible deniability for the clients [31].

2.3. Veriﬁable Computation and Zero-Knowledge Proofs

The notion of ZKPs was ﬁrst introduced by Goldwasser et al. [32]. ZKPs are a special form of

protocols between a so-called prover and a veriﬁer in which the prover wants to convince the veriﬁer

that she/he knows some value with a speciﬁc property (more formally, an element of a language).

5

ZKPs have the additional property that the prover learns nothing beyond this statement. The most

important properties beyond zero-knowledgeness that we build upon in this paper are completeness

(an honest prover will convince the veriﬁer with high probability if the statement is correct) and

soundness (any and in particular a malicious prover will convince the veriﬁer of a false statement

only with a small probability). By replacing the veriﬁer with a random oracle such as a hash

function, a large class of interactive proofs can be transferred to non-interactive proofs (using the

so-called Fiat-Shamir heuristic [33]). As opposed to interactive ZKPs, prover and veriﬁer do not

have to interact with each other in non-interactive ZKPs. Notably, there are succinct ZKP, which

means that both the proof size as well as the computational complexity of the proof veriﬁcation

is considerably smaller than the complexity of checking the statement by conducting the original

computation [34].

Since the introduction of ZKP, there has been a lot of research on them, but practical imple-

mentations or even applications remained rare before the beginning of the 2010s. However, starting

with Groth et al. [35], a period of rapid development of ZKP towards practical implementations

delivered signiﬁcant performance improvements, e.g., in [36]. In recent years, diﬀerent ﬂavors of

non-interactive ZKPs have emerged, for example, Bulletproofs [37], SNARKs [38], scalable trans-

parent arguments of knowledge (STARKs) [39], or hybrid constructions. While they diﬀer in

scaling properties and cryptographic assumptions, they all allow creating proofs for the correct

execution of a program without displaying all inputs, outputs or intermediate steps. Often, Merkle

proofs for the inputs are revealed to commit the prover to the usage of unknown but ﬁxed variables.

Domain-speciﬁc languages such as Circom or Cairo allow compiling programs into arithmetic cir-

cuits. From these, polynomials are constructed, which in turn can be translated into proving and

veriﬁcation programs through libraries such as libsnark or snarkjs. As such generic tools for ZKP

have signiﬁcantly matured over the last years, they have increasingly been used in ﬁrst applications;

often associated with blockchains and distributed ledgers, where due to redundant execution, cheap

veriﬁcation without revealing sensitive data is important [39]. However, the generality to which

the correctness of computations can be proved with these frameworks is often limited to prime

ﬁeld operations, complemented by libraries that provide, e.g., circuits for basic cryptographic and

arithmetic operations such as hash functions, signature schemes, and comparators.

2.4. Blockchains and Distributed Ledger Technology

Blockchain and, more general, distributed ledger technology builds upon peer-to-peer networks

in which all data is replicated, shared, and distributed across multiple servers (‘nodes’) [40]. In

blockchains, an append-only structure connects batches of transactions (‘blocks’) linearly through

6

hash-pointers (‘chain’) and thus achieves decentralized yet synchronized data management. A so-

called consensus mechanism that typically combines cryptographic techniques with economic or

social incentives allows deciding which blocks to append as well as the order of transactions within a

block [41]. If a majority of the network in a speciﬁc metric like hash rate (proof of work), the share

of cryptocurrency (proof of stake), or the number of accounts in a permissioned network (voting-

based consensus mechanisms) is honest, this guarantees the correct execution of simple payments

and programming logic (“smart contracts”) and the practical immutability of the ledger [41]. The

conﬁdence that a majority of the network behaves as intended without the need to rely on the

honesty of a distinguished entity is often referred to as digital trust [42]. Consequently, blockchains

allow avoiding dependencies on one or a few distinct entities on digital platforms [43, 44]. The

literature distinguishes between permissionless blockchains (such as those used in cryptocurrencies)

where anyone can participate and permissioned blockchains where participation is limited, e.g., to

an industry consortium or the public sector [45].

Since the release of the Bitcoin whitepaper [46], blockchain technology has been used in various

applications, e.g., cryptocurrencies, decentralized ﬁnance with derivatives and non-fungible tokens,

or industry applications. One early and popular permissionless blockchain that supports a Turing-

complete programming language for smart contracts is Ethereum.

It provides a decentralized

virtual machine environment, namely the Ethereum virtual machine (EVM), for executing smart

contracts. Ethereum smart contracts are usually implemented in Solidity, a high-level programming

language with syntax similar to JavaScript [47]. Two special properties of Solidity are the lack

of non-deterministic libraries (that would otherwise conﬂict with the necessarily deterministic

design of a blockchain that ﬁrst orders and then executes transactions) and that the complexity of

execution has a price, counted in so-called gas. This avoids not only inﬁnite loops but facilitates

fair competition for the limited capacity.

However, as blockchains and distributed ledgers exhibit redundant storage and computation,

they suﬀer from major challenges. While a high energy consumption is often presumed, in fact,

only proof of work blockchains are problematic in this regard [48]. Two other issues that arise

directly from replicated transaction storage and execution are considerably more fundamental:

Scalability [49] and privacy [50]. Yet, there are innovative approaches to mitigate these challenges.

For scalability, countermeasures range from restricting participation and demanding high compu-

tational power, storage, and bandwidth from the participating nodes to sharding and oﬀ-chain

computations. Oﬀ-chain computations are also good for privacy, but lead to the challenge of veri-

ﬁcation in a system with malicious participants. On the other hand, methods for privacy are tech-

nologies like LDP, fully homomorphic encryption (FHE), or multiparty computation (MPC) [51].

7

ZKPs can be regarded as a special case of veriﬁable MPC where only one participant contributes

private data but the result is veriﬁed by all blockchain nodes. Yet, ZKPs are arguably signiﬁcantly

closer to broad adaption and have been leveraged by many blockchain projects so far, starting

with Z-Cash and now also covering many scalability and privacy projects, many of which are

implemented on Ethereum (e.g., Tornado-Cash, Loopring, Aztec, StarkDEX).

2.5. Related Work

Since the term federated machine learning was introduced by McMahan et al.

[52], re-

search has focused on improving, amongst others, performance, privacy, integrity, and incentive-

mechanisms [12, 14]. To improve the clients’ privacy beyond the level that FL inherently oﬀers,

research came up with three main strategies, namely homomorphic encryption, MPC, and DP,

which aim to prevent public model updates from leaking private client information. Due to its

low complexity and strong privacy guarantee [4], DP is widely used [6], even though deploying

DP in ML leads to a trade-oﬀ between maximizing privacy (i.e., adding noise with high variance)

and maximizing accuracy. In practice, instead of uploading the actual weights, clients can add

DP noise to their weights. For example [53] developed a FL system for vehicular networks that

combines LDP with gradient descent to avoid attacks that leak private information from publicly

available ML model updates.

Instead of perturbing model parameters, LDP noise can also be

added to the training data [7]. However, this approach cannot provide privacy protection since it

is not suﬃcient to make any single record unnoticeable [54].

Besides, many works have adopted game-theoretic approaches to motivate clients’ participation

in a FL system and ensure fairness amongst them. As an example, Khan et al. [55] implemented a

Stackelberg game to incentivize clients for contributing to training a model and, at the same time,

maximize the model’s performance. Since clients must trust the central authority to incentivize

all clients fairly in a traditional FL setting and to provide a decentralized incentive layer for data

sharing in general [56], researchers have suggested using blockchains and smart contracts for model

aggregation (e.g., [57]) and client remuneration (e.g., [58] or [59]). Sun et al. [60] propose a FL

architecture that leverages a blockchain for transparency and incentivizing clients and combines it

with homomorphic encryption in the aggregation smart contract to prevent leakage from clients’

contributions. However, in all these frameworks, oﬀering incentives to clients also puts the system’s

integrity at risk as malicious clients may try to fraudulently beneﬁt from the incentive mechanism,

e.g., through free-riding attacks [12, 14].

The transparency of smart contracts could help achieve integrity by allowing clients to recal-

culate the weights that fellow clients submitted. However, even when ignoring the corresponding

8

privacy and scalability challenges, such an approach would lead to a “veriﬁer’s dilemma” [61],

where clients weigh up between accepting the costs of recalculation or trusting other clients. ZKPs

could oﬀer an eﬃcient solution to the “veriﬁer’s dilemma” in FL and, thus, pave the way to achiev-

ing fairness, integrity, and privacy at the same time. Despite ZKPs’ potential for FL systems and

their increasing adoption (especially in the blockchain domain), it remains an open question how

ZKPs can be used in the context of FL [4]. Wu et al. [62] have implemented a SNARK that

proves the correctness of LR parameters by recalculating them. In the case of LR, this can be

done only using matrix multiplications. However, this approach includes rounding a matrix inverse

and, hence, requires further measures to ensure full tamper protection (as we will show in detail in

Section 3.1.1). Feng et al. [63] introduced a toolchain to produce veriﬁable and privacy-preserving

SNARKs that prove correct inference in classiﬁcation and recognition tasks by taking an existing

neural network as input. Also Zhang [64] as well as Weng et al. [65] implemented ZKPs that allow

verifying whether a particular prediction by a trained ML model has been computed truthfully

without providing any information about the ML model itself. Even though also Weng et al. [65]’s

work implements a ZKP merely for ML model inference, they improved ZKPs’ eﬃciency to prove

the correctness of matrix multiplications and ZKPs’ application to ﬂoating point arithmetic, which

are both essential ingredients for training ML models.

Despite the advancement that these works generate for combining ZKPs and ML, it remains,

to the best of our knowledge, still unclear how recent progress in ZKPs, blockchain technology,

and DP can be combined as a technology stack that achieves full privacy, integrity, and fairness in

FL systems.

3. Architecture and Implementation

We organize Section 3 as follows: In Section 3.1 we explain how our suggested FL system is built

up formally. To do so, we divide the FL process into four diﬀerent sections, namely Compute and

Prove Model Weight (Section 3.1.1), Model Aggregation (Section 3.1.2), Compute and Prove Model

Cost (Section 3.1.3), and Compute Incentives (Section 3.1.4). Table 1 introduces the notation that

we use throughout this section.

3.1. Conceptual Architecture

3.1.1. Compute and Prove Model Weight

At the start, participating clients ui can register at the smart contract Clients. To do

so, they must commit to the Merkle root rtD
i

of their private data set Di = (Xi Yi) =

9

Symbol Explanation

I
ui
k
n
d
Xi
Yi
Zi
Di
Dtest
rtD
i
rtDtest
i
ltrain
ltest
εµ
εσ
εinverse
εw
εw(cid:48)
ϑX(cid:124)Y
ϑZ
M
wi
w(cid:48)
i
˜wi
˜w(cid:48)
i
wg
εLR
L
dL
q
hj

(cid:124)
i Xi)−1

’s Merkle tree (number of levels)

Set of indices, i ∈ {1, . . . , |I|}
Client i, i ∈ I
Number of features of the linear regression
Sample size per client of the linear regression (set globally)
Accuracy of rounded inputs
n × (k + 1) Matrix of input data including all independent variables
n-dimensional vector of input data containing all dependent variables
Approximate inverse of (X
Private data set of ui – an n × (k + 2) matrix: (Xi,0, Xi,1 . . . Xi,k Yi)
Public test data set
Merkle tree root of Di
Merkle tree root of Dtest
Depth of Di’s Merkle tree (number of levels)
Depth of Dtest
i
Upper bound for µ · n
Upper bound for σ · n
Upper bound for (cid:107)(X(cid:124)X)Z − 1(cid:107)
Upper bound for (cid:107)w − ˜w(cid:107)
Upper bound for (cid:107)w(cid:48) − ˜w(cid:48)(cid:107)
Upper bound for (cid:107)X(cid:124)Y (cid:107)
Upper bound for (cid:107)Z(cid:107)
Model (corresponds to respective weight vector)
Weight vector of ui, corresponding to Mi
Weight vector including LDP noise
Recalculated weight vector
Recalculated weight vector including LDP noise
Weight vector of global model Mg
Error term of LR
Vector including Laplacian LDP noise
Accuracy of the Laplacian LDP noise
LDP noise
Hash serving as random noise for q

hash alg Hash algorithm, i.e., 0 for ‘MiMC’ or 1 for ‘Poseidon’

C
V
B
π(a, b)
Gen(π)
Ver(π)

Vector of ui’s cost: (c1, . . . , c|I|)
Vector of ui’s incentive payment: (v1, . . . , v|I|)
Admission fee payable upon joining the system
ZKP for statement a with witness b
Construct the ZKP π (with the proving key)
Verify ZKP π (with the veriﬁcation key)

Table 1: Notation used in this paper.

(Xi,0 Xi,1 . . . Xi,k Yi) ∈ Rn×(k+2) ∼ Rn(k+2) with

Xi =














xi,0,1

xi,1,1

· · · xi,k,1

xi,0,2
...

xi,1,2
...

· · · xi,k,2
. . .

...

xi,0,n xi,1,n

· · · xi,k,n














=

and














1 xi,1,1

1 xi,1,2
...
...

1 xi,1,n














· · · xi,k,1

· · · xi,k,2
. . .

...

· · · xi,k,n

∈ Rn×(k+1)

Yi = (yi,1, . . . , yi,n)

(cid:124)

∈ Rn.

10

Prior to computing rtD
i

and training their LR weights, clients must normalize their input

data Di, such that every Xi,1, . . . , Xi,k, Yi has expectation value µ = 0 and standard devia-

tion σ = 1 (in line with, e.g., Witten et al. [66]). Subsequently, clients train their LR weight
wi = (βi,0 βi,1 . . . βi,k)(cid:124) ∈ Rk by computing

Equation (6) optimizes

wi = (X

(cid:124)
i Xi)−1 X

(cid:124)
i Yi.

min(RSS) = min
w∈Rk

((Yi − Xiwi)(cid:124)(Yi − Xiwi)) = (cid:107)εLR,i(cid:107)2

(6)

(7)

where Yi = Xiwi + εLR,i and εLR,i denotes the LR’s error term. Constructing the ZKP πw that

ensures that ui computed wi truthfully (i.e., truly computed the wi that minimizes the residual

sum of squares (RSS) using (7) based on ui’s originally committed data) requires adapting the

protocol to circom’s capabilities that are restricted to prime ﬁeld operations and, thus, to non-

negative integer inputs. To do so, we decide to generally round and subsequently scale all (public

and private) ZKP inputs A|S|×|T| = (as,t)s=1,...,|S|; t=1,...,|T | as in general we cannot assume that
as,t ∈ N0. For example, we convert the input as,t = 2.5347725 to 2.53477 · 105 = 253477 = ˜as,t in

the cae of d = 5. Further, to input only positive integers, we introduce a matrix Sign(A) whose

elements indicate the signs of A’s coeﬃcients: (Sign(A))s,t = sign(as,t) where

sign : Z → {−1, 1},

x (cid:55)→




0



1

if x ≥ 0

.

if x < 0

Then we can write the ZKP inputs as

˜A = 10−d Sign(A) ◦ ˜A+

where

s,t ∈ N0.
˜a+

(8)

Moreover, (cid:107) ˜A − A(cid:107) ≤ c · 10−d, where c depends on the choice of matrix norm. For example. if we

use the maximum norm, c can be 0.5 times the number of columns of A.

After this transformation, ui can compute the ZKP. However, as constructing proofs is compu-

tationally expensive, designing the ZKP generation requires speciﬁc consideration and optimiza-

tions. For better readability, we will refrain from using client indices i in the following description.

First, to make sure that the client’s input data is standardized, we introduce an upper bound for

the mean µ. Note that since circom does not allow for non-integer divisions, we apply the upper

bound controlling µ to the sum of all elements in Y and X1, . . . Xk:

µXj · n =

(cid:88)

xj,l ≤ εµ

l=1,...n
(cid:88)

µY · n =

l=1,...n

yl ≤ εµ

11

∀ j ∈ {1, . . . , k}.

(9)

Similarly, we regulate the data set’s variance σ2 by applying an upper bound to the squared sums:

σ2
Xj

· n =

(cid:88)

(xj,l − µ)2 ≤ εσ

l=1,...n
(cid:88)

σ2
Y · n =

l=1,...n

(yl − µ)2 ≤ εσ

∀ j ∈ {1, . . . , k}.

(10)

Hence, εµ and εσ must be set with respect to n.

Recalling (6), our initial attempt was to compute the inverse (X(cid:124)X)−1 within a circuit of the

respective ZKP by introducing two integers, a denominator and a numerator, per input value.
This procedure would allow us to calculate (X(cid:124)X)−1 in the circuit (as divisions leading to non-

integer values can be replaced by multiplications) without rounding errors (given the input values

are precise). However, the approach turned out to have one signiﬁcant shortcoming: Computing
(X(cid:124)X)−1 within a circuit using Gaussian elimination quickly results in overﬂow (i.e., a numerator or

denominator can quickly get larger than the size of the prime ﬁeld). Finding common denominators

often requires multiplying all denominators repeatedly. For example, already computing the inverse
of (X(cid:124)X)5×5 matrices with d = 5 can cause an overﬂow (in general, this will depend on the choice

of d and k, but 2k · d will probably be larger than 78 in many practical applications). On the

other hand, reducing fractions or rounding (using range proofs) before overﬂow would add further

complexity in the Gaussian elimination algorithm. Besides, more complex operations demanded

by more sophisticated ML algorithms would require to hand-craft a fast numerical solver, so the

method does not generalize well. Eventually, this approach would hardly scale to more complicated

optimization algorithms.

As matrix inversion inside the circuit or inverting within circom’s prime ﬁeld is expensive, we

decided to follow the approach of Wu et al. [62] to solve the problem by letting clients calculate
and provide an inverse Z ≈ (X(cid:124)X)−1 outside the circuit through a standard solver such as typical

matrix inversion tools in Javascript, Python, or MATLAB. We then give this inverse as private

input to the circuit (again complying with the above-described conversion to non-negative integer

entries). However, due to the ﬁnite precision of the matrix inversion, we cannot assume that

equality holds. Thus, we apply a slightly diﬀerent method and only prove the proximity of the

calculated inverse to the true inverse. To do so, we check the approximation error of the provided

numerical inverse using the following range constraint:

(cid:107)(X(cid:124)X)Z − (X(cid:124)X)(X(cid:124)X)−1(cid:107) = (cid:107)(X(cid:124)X)Z − 1(cid:107) ≤ εinverse < 1.

(11)

As matrix norm, the maximum norm is a convenient choice, i.e., the inequality can be checked

index-wise (respecting k). Through this bound, we can both control for the eﬀect that the replace-
ment of (X(cid:124)X)−1 with its approximation Z has and ensure that the system remains protected

12

against malicious client attacks. To do so, we estimate an upper bound for the approximation

eﬀects on the distance from w to ˜w, with the latter being calculated based on Z, via

(cid:107)w − ˜w(cid:107) ≤ (cid:107)(X(cid:124)X)−1X(cid:124)Y − ZX(cid:124)Y (cid:107)

≤ (cid:107)(X(cid:124)X)−1 − Z(cid:107) · (cid:107)X(cid:124)Y (cid:107) ≤ εw,

(12)

where we use the submultiplicativity of (cid:107) · (cid:107). Even though all entries of X(cid:124) and Y are normalized,
i.e., X1, . . . , Xk, Y have expectation value µ = 0 and the standard deviation σ = 1, (cid:107)X(cid:124)Y (cid:107) might
still yield large entries. Thus, to control the error (cid:107)w − w(cid:48)(cid:107) between the true weights and the
client’s approximative result, we desire upper bounds for both (cid:107)(X(cid:124)X)−1 − Z(cid:107) and (cid:107)X(cid:124)Y (cid:107).

First, we introduce a simple range proof to ensure that (cid:107)X(cid:124)Y (cid:107) is bounded:

(cid:107)X(cid:124)Y (cid:107) ≤ ϑX(cid:124)Y where ϑX(cid:124)Y ≡ ϑX(cid:124)Y (k, d) .

(13)

In general, the probability that (cid:107)X(cid:124)Y (cid:107) is large is very small as the normal distribution decays

fast; if by coincidence a single value is big, d might need to be adjusted to increase the accuracy

of rounded inputs.

Second, we recall that the true inverse can essentially be replaced by the approximative inverse

as long as the approximate inverse is bounded [67]. More precisely, given any matrix norm (cid:107) · (cid:107), a
square nonsingular matrix A and its approximate inverse Z such that (cid:107)AZ − 1(cid:107) ≤ εrange < 1, the

bound

(cid:107)A−1 − Z(cid:107) ≤

(cid:107)Z(cid:107) × (cid:107)AZ − 1(cid:107)
1 − (cid:107)AZ − 1(cid:107)

(14)

holds. However, it is not clear that X(cid:124)X is non-singular, and checking this inside the circuit, e.g.,

through computing the determinant, would become expensive already for moderate k. Fortunately,

we can relax the assumption by reconsidering the argument in the derivation of the result in New-

man [67]: Provided the candidate for the approximate inverse satisﬁes (cid:107)R(cid:107) < 1 for R := AZ − 1,

then the Neumann-series 1 + R + R2 + . . . converges. Consequently, using the argument in the

paper,

AZ · (1 + R + R2 + . . .) = (1 − R) · (1 + R + R2 + . . .) = 1.

(15)

It follows that Z(1+R+R2 +. . .) is a right-inverse of the quadratic matrix A and hence its unique

(left- and right-) inverse, i.e., A is non-singular. In particular, we learn that if A was non-singular,
we could not ﬁnd an approximate inverse that satisﬁes (11). Applied to A := X(cid:124)X, our circuit
already implicitly guarantees that X(cid:124)X is invertible through checking (11), and (14) yields

(cid:107)(X(cid:124)X)−1 − Z(cid:107) ≤

(cid:107)Z(cid:107) × (cid:107)(X(cid:124)X)Z − 1(cid:107)
1 − (cid:107)(X(cid:124)X)Z − 1(cid:107)

≤ ϑZ · εinverse ,

(16)

13

where

(cid:107)Z(cid:107) ≤ ϑZ and ϑZ ≡ ϑZ (k, d).

Before uploading w to the EVM storage, clients must perturb their weight by adding Laplacian

LDP-noise (recall (4) and (5)) to avoid deep leakage [19]:

w(cid:48) = w + q,

λ =

∆
(cid:15)

=

1
(cid:15)

(max βi,j − min βi,j)

i ∈ {1, . . . , |I|}, j ∈ {0, . . . , k}.

q ∼ L(0, λ), q ∈ Rk

(17)

(18)

Note that every entry in q is drawn separately, following L(0, λ). Moreover, since we perturb

client weights that will be aggregated, we must set the LDP security parameter (cid:15) globally. As

no fellow βi,j will be available to any client before uploading the client’s own w, we must set an

estimation for ∆ globally. Recalling that all w are computed based on normalized data, we know

that β0, . . . , βk ∈ [-1; 1] holds. Therefore, we set ∆ = 2 · 10d as a proxy. Moreover, to generate πw,

we must ensure that we can reproduce every entry in q while keeping its choice random. Achieving

this requires a twofold approach.

First, since circom does not have tools to compute a Laplace-distributed random variable
directly, we discretize L(0, λ), introducing a variable dL = 10x with x ∈ N that deﬁnes the interval

of a discrete distribution DL(0, λ) of L(0, λ) (i.e., DL’s accuracy). We then construct a vector

L ∈ RdL−1 whose entries are given by the inverse cumulative distribution function of DL(0, λ):

L(p) := −λ sgn

p −

(cid:18)

(cid:19)

(cid:18)

ln

(cid:12)
(cid:12)
(cid:12)p −
1 − 2

1
2

(cid:19)

(cid:12)
(cid:12)
(cid:12)

1
2

,

p = {1, . . . , dL − 1}.

(19)

The ﬁnite nature of machines leads to some form of discretization of distributions, which makes DP

mechanisms generally vulnerable to attacks [68]. Therefore, there is a research stream dedicated

to exploring the eﬀects of discretization on LDP (e.g., Balcer and Vadhan (2019), Canonne et al.

(2021)). However, in our system, the parameters are currently set in a way that the limitation

through dL will be stricter than that of the precision typically achieved in computer programs.

Second, we draw the underlying randomness p from the random oracle hj that results from

hashing a solid source of entropy like the current block hash of the blockchain and the entry of Y

that corresponds to the βj that is being perturbed:

hj = H (current block hash | yj) ,

j = {0, . . . , k}.

(20)

So, for example, when perturbing β(cid:48)

0 = β0 + q0, the corresponding entry of Y is y0. The resulting

hj is a 256-bit number. We derive every p by computing

p = hj mod dL,

j = {0, . . . , k}.

(21)

The noise that results from a particular value of p, as well as its distribution (which is close

to the true Laplace distribution with λ = 1, is illustrated in Figures 1a and 1b). Essentially,

14

we generate veriﬁable randomness (similar as used, e.g., in Algorand for electing block producers)

deterministically in the circuit by combining entropy from the blockchain and from the training data

that was the client previously committed to. This approach ensures that clients cannot inﬂuence

their LDP-noise q whilst fellow clients cannot reproduce the q (which would allow them to leak the

‘unperturbed’ w) and verify that the noise was produced purely at random: As the client could not

predict the entropy taken from the blockchain at the time of committing to Di, and consequently

not try diﬀerent values for Y that yield the desired noise. Additionally, by inputting L, πw’s

circuits can verify p. Now the clients are ready to generate their ZKPs that allows for verifying

(a) Value of the noise depending on p.

(b) Histogram of the discretized Laplacian noise.

Figure 1: Derivation of the discretized Laplacian noise.

the validity of the clients’ local computations of w(cid:48). Given the proposed architecture, the ZKP

πw(a, b) with statement a and witness b that proves that u has truthfully calculated w(cid:48) has the

following characteristic:

πw (cid:0)(cid:0)w(cid:48), rtD, εµ, εσ, εw(cid:48), εinverse, ϑX(cid:124)Y , ϑZ

(cid:1) , (D, Z)(cid:1) .

(22)

Besides the above-described range proofs and computation checks, πw ensures a globally set range

εw(cid:48) for the submitted w(cid:48):

(cid:107)w(cid:48) − ˜w(cid:48)(cid:107) ≤ εw(cid:48).

Please refer to Section 3.2 for a detailed description of how we implement πw.

Using a smart contract and through snarkjs’ export solidityverifier command, clients can,

subsequently to compiling the circuit and generating the proof, upload their w(cid:48) to the EVM. The

smart contract veriﬁes the proof and, if valid, uploads the client’s w(cid:48).

3.1.2. Model Aggregation

For every successfully uploaded w(cid:48)

i, the smart contract Clients updates wg by aggregating
all weights that have been submitted to the smart contract so far using FedAvg. For a globally

15

-5-4-3-2-1012345102030405060708090noisep0510152025-5-4,75-4-3,5-3-2,5-2-1,5-1-0,500,511,522,533,544,55absolute frequencynoiseconstant sample size n in a LR setting, the respective aggregation formula equals

wg =

(cid:80)|I|

i=1 wi
|I|

≈

(cid:80)|I|

i=1 w(cid:48)
i
|I|

= w(cid:48)
g,

(23)

depending on (cid:15) and |I|. Heuristically, the noise is i.i.d. with expectation value 0 and ﬁnite variance

2λ2, so by the law of large numbers, the probability that wg diﬀers signiﬁcantly from w(cid:48)
(in fact, the deviation is approximately normally distributed with standard deviation 2λ2√
|I|

.

g is small

3.1.3. Compute and Prove Model Cost

After submitting and proving their LDP-weights w(cid:48), clients test their unperturbed w on a
global and public data set Dtest = (Xtest Ytest) = (Xtest,0 Xtest,1 . . . Xtest,k Ytest) ∈ Rntest×(k+2)
with Xtest = (1, ..., 1)(cid:124), distributed via a public channel (e.g., a cloud provider). Clients have

to prove that they computed their model cost c truthfully based on Dtest and using their w by

constructing a ZKP πc with the following characteristic.

πc (cid:0)(cid:0)c, rtD, rtDtest, εw

(cid:1) , (D, Z, w)(cid:1) .

(24)

πc ensures that clients used the private input w (i.e., their true and unperturbed weight) to compute

c by ﬁrst reproducing ˜w in a circuit of the ZKP and performing the range proof (recall (12))

(cid:107)w − ˜w(cid:107) ≤ εw .

Note that the SC Clients requires that clients have uploaded a valid w prior to submitting and
proving c, such that the standardization of rtD as well as the eﬀects of approximating (cid:107)X(cid:124)Y (cid:107)

through (cid:107)Z(cid:107) are already controlled by πw. Then, as w is a private input to πc, we can compute ˜c

in a circuit of πc and make sure that

˜c = (cid:0)Ytest − ˆYtest

(cid:1)(cid:124)(cid:0)Ytest − ˆYtest

(cid:1) = c

(25)

with ˆYtest = Xtest · w holds.

Second, by including rtDtest as a statement, πc can compute the respective Merkle tree on the
Dtest equals rtDtest , with the latter being

test data set Dtest and require that the resulting root ˜rt

stored in the EVM. Since Dtest is publicly available, all clients can easily check its standardization,
Dtest = rtDtest is suﬃcient. This approach allows the system to guarantee
such that checking ˜rt

truthful submissions of c without having to store Dtest onchain, which would, depending on k and
ntest be costly and challenging. A detailed implementation of πc is again included in Section 3.2.

3.1.4. Compute Incentives

To translate C = (c1, . . . , c|I|)(cid:124) transparently into each client’s incentive payment vi, we choose
an eﬃcient approach that can be computed on-chain by the Clients smart contract. First, we

16

normalize all submitted and validated ci’s to a vector Cnorm ∈ R|I| that has expectation value

µ = 0 and the standard deviation σ = 1. We multiply all entries in Cnorm with (−1) as lower ci

implies higher model performance and, subsequently, replace negative entries with 0 (i.e., ensure

that all cnorm,i that are higher than the mean of all ci are not incentivized). Next, we scale the

data such that
can distribute the incentive payments V = (v1, . . . , v|I|)(cid:124) ∈ R+ as follows:

cnorm,i = 1. Upon entry, clients have to pay an admission fee B, such that we

|I|
(cid:80)
i=0

V = B · |Ivalid| · Cnorm

(26)

where |Ivalid| is the number of clients with valid w(cid:48)

i and ci. The payments are distributed by the
function reward_clients() which can only be executed by the client who has initially deployed

the Clients smart contract. Moreover, by using Solidity’s mapping, every client (i.e., address)

can only register once as the data would be overwritten when joining multiple times and a new

clientID would be set. We summarize the system outlined above in Table 2.

3.2. Implementation

In this section, we describe the implementation of our architecture. Please note that, following

circom terminology and in contrast to Section 3.1, we will now refer to single ‘circuits’ that are

callable with input and output signals as ‘templates’, whereas we refer to a set of ‘templates’ that

make up a ZKP as ‘circuits’. ‘Signals’ (signal) are the basis for deﬁning constraints (using ===)

and can only be assigned a value once (using <-- or -->). Both <== and ==> declare a constraint

and assign a signal’s value at the same time. On the other hand, circom also includes conventional

variables (var). As we use snarkjs and hence a framework for proof creation and veriﬁcation based

on SNARKs, a so-called trusted setup is required initially. It consists of two phases, one of which

is independent of the circuit (‘powers of tau’1) and that we could just import, as well as one that

is circuit-speciﬁc. For implementation purposes, we conducted the trusted setup alone. However,

for practical applications, a group of trusted parties would need to conduct an MPC such that the

participants in the FL system would be conﬁdent that at least one group member deleted their

input to the MPC.

1The ‘powers of tau’ ceremony, also referred to as ‘phase 1 trusted setup’, is a circuit-agnostic MPC ceremony

where multiple independent parties collaboratively construct common parameters from their secret random values.

The parameters allow to obtain a proving and a veriﬁcation key in a later stage. Note that the SNARK protocol’s

integrity guarantee (“soundness”) is compromised if all parties’ random values are exposed. It is, however, important

to note that while information about the private inputs to the MPC would allow to create fake proofs and hence to

violate the integrity of our artifact, the privacy of the participants’ data would still be ensured even in this case [71].

17

Step Client ui

Smart Contract

Training phase

1

Join system: Join the system by fetching the model Mi

(i.e., number of features k and the sample size n), hashing
ui’s database, writing rtD
i
admission fee B

into storage, and paying the

2

3

4

5

6

7

8

9

10

Train model: Train Mi by computing wi

Compute and upload LDP weight w(cid:48)
upload diﬀerentially private (LDP) weight w(cid:48)
i

i: Compute and

Compute and submit weight proof πw
i :
Gen(πw
i and upload πw
into storage if πw
is valid
i

i ) → πw

i . w(cid:48)

i will only be uploaded

Verify all LDP weights:
Ver(πw
storage if πw

i has been validated

i ) ∀ i ∈ {1, . . . , |I|}. Write every w(cid:48)

i into

Testing phase

Compute ui’s cost ci: Fetch the public test data set

and evaluate own model performance (RSS) using ui’s

true weight wi. Submit own accuracy as ui’s cost ci

Global model aggregation: Aggregate all w(cid:48)
i
to w(cid:48)

g ≈ wg and write w(cid:48)

g into storage

Compute and upload cost proof πc
i :
Gen(πc
into storage if πc

i and upload πc
i is valid

i ) → πc

i . ci will only be uploaded

Verify all cost proofs:
Ver(πc

i ) ∀ i ∈ {1, . . . , |I|}

Compute incentives: Compute and distribute

incentive payments V according to C

Table 2: Steps of our protocol for private, fair, and honest FL.

We will include several, truncated source code excerpts throughout the following section. Please

ﬁnd the whole project on GitHub2. Note that some templates are taken from iden3’s circomlib.

2github.com/timon131/ma webstorm v4

18

3.2.1. Weight Proof πw

We start by explaining the implementation of πw’s circuit, namely LinRegParams(...). First,

we deﬁne the private and public inputs according to (24). The main template execution requires

various variables (cf.

listing 1), some of which are also input signals to the circuit for circom-

speciﬁc reasons. Providing an untruthful value for some of these variables might make adversarial

attacks possible. To make sure that these critical input variables are correct, the circuit requires

the respective values as input signals to check equality. Listing 2 provides an overview of the

implementation of πw. The circuit as the basis for the ZKP is structured into ﬁve parts:

• Step 1 – Range proofs for εµ and εσ:

To ensure that D’s mean µ ≈ 0 and variance σ ≈ 1, a certain accuracy is set by εµ and εσ

respectively. Based on both values, LinRegParams checks the accuracy of all µ and σ for

X1, . . . , Xk and Y . For example, setting in_require_meanxn_acc = 3 would require that
the absolute value of every µ · n is smaller than εµ = 10−3 (taking into account the conversion

in (8) using d). Analogously, in_require_varxn sets the upper bound for σ · n via εσ.

• Step 2 – Check rtD:

This step rebuilds D’s Merkle tree with one data point (a prime ﬁeld element as matrix

entry) at each leaf. To improve the system’s performance, we do not hash the particular

leaves on the lowest level since hashing is costly. This works because the hashing algorithm

operates on big numbers that can be suﬃciently large to cover any prime ﬁeld element. After

computing the tree, the template ensures that the computed root equals the public input

rtD, which will be compared to the commitment speciﬁed at registration when calling the

smart contract’s method Clients.

• Steps 3 and 6 – Range proofs for εinverse and εw(cid:48):

To verify the upper bound on εinverse, the template checks the proximity of every entry in
((X(cid:124)X)Z − 1) to 0. For example, setting in_require_XX_acc = 3 would require that the

absolute value of every entry is smaller than εinverse = 10−3 (again taking into account the
conversion in (8) using d). The same applies to in_require_b_noisy_acc, εw(cid:48), and w(cid:48) − ˜w(cid:48).

• Steps 4 and 5 – Range proofs for ϑZ and ϑX(cid:124)Y

Both ϑZ and ϑX(cid:124)Y must be provided as inputs to the template in absolute numbers. The

main template ﬁrst ﬁnds the largest (by absolute value) entry in the matrix or vector using

the maximum norm:

(cid:107)A(cid:107) = k · max
s,t

|as,t|

(27)

19

where A can be either Z ∈ N(k+1)×(k+1) or X(cid:124)Y ∈ Nk+1. Then it checks whether

0 ≤ (cid:107)A(cid:107) ≤ ϑA holds for both choices of A.

Note that along with these six steps, the template performs the computation of w(cid:48) iteratively.

The LDP noise is added in the last step by generating hj using (20), choosing the respective LDP

noise q from L using (19) and (21), as well as adding q as in (17).

3.2.2. Cost Proof πc

Next, we outline the implementation of πc in our proposed system, for which LinRegCost(...)

is the main template. πc’s private inputs (cf. lines 3 to 10 in Listing 3) resemble those of πw except

for w+ and Sign(wi), which are required to reproduce c as outlined in Section 3.1.3. Note that the

inputs of Dtest in lines 12 to 15 of Figure 3 are declared as private signals due to performance

reasons (cf. Section 4 for details), even though they are publicly available. Also πc consists of ﬁve

major steps to make sure that clients compute and submit their cost c truthfully (cf. Listing 4):

• Steps 1 and 2 – Check rtD and rtDtest :

In addition to checking the Merkle tree root rtD (as in LinRegProof(...)), πc also ensures

that clients calculate their c based on the test data set Dtest = (Xtest Ytest) by requiring
Dtest = rtDtest . Dtest is a standardized, publicly available, and central data set that is
˜rt
made available to all clients through a cloud service. Besides, D’s standardization does not
D

need to be checked again, as πw already ensures its standardization and πc veriﬁes that ˜rt

equals rtD.

• Step 3 – Range proof for εw:

Similar to step 5 in LinRegProof(...), we allow controlling (cid:107)w − ˜w(cid:107) by performing a range

proof using the input εw. This means that essentially, the computation of the unperturbed

weight ˜w is repeated and, subsequently, its proximity to w is checked analogous to πw’s range

proof for εw(cid:48).

• Steps 4 and 5 – Check c:

First, as in (25), step 4 estimates ˆYtest. Second, step 5 derives ˜c and ensures that ˜c equals

the submitted c.

3.2.3. Smart Contract

After introducing LinRegProof(...) and LinRegCost(...), this section provides an overview

of the governance structure implied by the main smart contract, namely Clients. To reduce

Clients’s size, we implemented lib as a support library. lib deﬁnes all structs required by

20

Clients (cf. Listing 5) and repeatedly used methods like, e.g., proof veriﬁcation calls. We will

brieﬂy introduce both major structs FL_client and FL_generic:

• FL_generic: Contains all global variables for, e.g., deﬁning k, n, rtDtest , L, or the variables

to control the range proofs. The client that initially deploys the Clients smart contract

must instantiate fl_generic, which will be the only global instance of the struct.

• FL_client: Upon registering, all clients are assigned to an instance fl_client (implemented

via a mapping mapclient from the particular client’s address to the respective instance

fl_client). FL_client includes all client-speciﬁc data as, for example, w(cid:48)

i, rtD

i , and both

proofs.

To register, clients call the smart contract’s registerClient(...) function. As depicted in

Listing 6, calling registerClient(...) requires rtD

i as input, since clients must commit to their
data set Di upon joining the system. Further, they have to pay the admission fee B deﬁned in

fl_generic which will be used to distribute the incentive payments later. Moreover, a clientID,

a mapping mapID to connect the clients’ addresses with their clientID, and the current block hash

(at the time of registering) serving as source of public randomness for deriving their LDP noise p

will be set automatically.

Subsequently, clients can upload their w(cid:48)

i by calling the function uploadBeta(...) and deliv-

ering the following inputs:

• t_betaverifier: Address of the deployed weight veriﬁer contract. The client must deploy

this contract before calling uploadBeta(...) and provide the respective address such that

other clients and uploadBeta(...) itself can verify the client’s weight proof.

• betaproof: This struct (cf. Listing 5) contains the actual proof, which is also the ﬁrst part

of the call data for verifying the weight proof.

• beta_noisy_true is the struct containing the submitted w(cid:48)
i.

uploadBeta(...) will collect the respective public inputs (cf. Listing 1) and, together with the

provided betaproof, verify the proof πw onchain. Successfully verifying the proof requires correct

tion of w(cid:48)

input data Di, the correct approximate inverse Z (accuracy controlled by d), and correct computa-
i. If successful, uploadBeta(...) saves the submitted beta (i.e., the client’s w(cid:48)
i), sets the
client’s betaproof_valid to true, and updates betaglobal (i.e., wg). The procedure is analogous

(except for updating betaglobal) when submitting the cost ci by calling uploadCost(...), such

that we will not further describe the function.

21

Eventually,

to

trigger

the

distribution

of

incentive

payments,

only

the

ini-

tial

client

t_initialclient

can

call

the

function

Incentivize_clients(...).

Incentivize_clients(...) will calculate the incentive payments V and distribute them

to those clients, who have successfully submitted their w(cid:48)

i, according to their contribution as
described in Section 3.1.4. However, as this requires trust in the initial client (as only she/he can

prompt the incentive payment by calling Incentivize_clients(...)), this way of triggering the

payoﬀ is probably not suitable in all scenarios. To make the trigger more trustless, the initial

client could also specify ways to prompt the payoﬀ. For example, any client could trigger it as

soon as a certain threshold of participants is reached, or a certain amount of time (measured in

the block number) has passed.

4. Evaluation

To evaluate our system, we ran several tests with diﬀerent parameters. k and n are mainly

inﬂuencing the complexity of our system, since they determine the number of Merkle tree leaves

and, thus, the number of hashes that we compute in a SNARK. Note that more speciﬁcally,

(k + 1) · n for πw and (k + 1) · (n + ntest) for πc determines the number of leaves since we leave out

X0,i = (1, . . . , 1) and instead only hash X1,i, . . . , Xk,i as well as Yi. Besides the number of leaves,

also the choice of the hashing function can have a signiﬁcant impact on the system performance. For

example, when switching from ‘Poseidon’ [72] to ‘MiMC’ [73] hashing, the number of constraints

of our system roughly increases by a factor 4. Since this factor remains approximately the same

when increasing circuit complexity (i.e., the number of constraints), we tested our artifact only

with ‘Poseidon’ hashes on an AWS instance (Ubuntu 20.04, 16 virtual CPU cores, and 64 GB

RAM). Instead of snarkjs’ default web assembly compiler, we used a native compiler3 (C++) that

can handle larger circuits.

Table 3 provides an excerpt of our test results (Tables 4 and 5 in the appendix contain the

entire test data for πw and πc respectively). Note that we used rapidsnark to generate the proofs

(cf. “proof gen duration”). Besides, due to their similar implementation (cf. Section 3.2), the cost

proof’s performance test results do not diﬀer signiﬁcantly from the weight proof’s results. We will,

therefore, mainly focus on the weight proof’s results: Before analyzing our system’s performance,

we describe an essential optimization that prior tests suggested: We found that the recomputations

of the Merkle trees are the artifact’s dominating operations in terms of constraints. Therefore, we

optimized the computation of rtD and rtDtest by hashing six instead of two data points at the

3snarkit by Fluidex

22

key gen

proof gen

veriﬁcation

circuit

veriﬁcation

k

n

(k + 1) · n

# con-

straints

4

4

4

4

4

4

100

250

500

750

1,000

1,500

500

89,819

1,250

208,162

2,500

404,962

3,750

601,520

5,000

798,659

7,500

1,190,620

duration

duration

duration

(s)

177

337

659

1089

1360

2571

(s)

8.641

19.410

36.868

57.042

74.945

120.736

(s)

0.236

0.237

0.237

0.237

0.232

0.263

size

(MB)

46

102

198

310

391

614

key size

proof

size

(kB)

(bytes)

25

25

25

25

25

25

708

709

708

705

705

705

Table 3: Evaluation of essential parameters for building and verifying the πw circuit depending on k and n.

leaf level at once and hard-coding ‘empty’ leaf hashes to avoid additional hashing in those Merkle

trees that are not entirely ﬁlled with data points on the leaf level (depending on k, n, and ntest,

not every leaf necessarily represents a data point as the bottom level must – given our Merkle tree

optimization – always contain 2 depth · 3 leaves). This optimization reduced the circuit complexity

by roughly 50%. Then, computing the circuit-speciﬁc trusted setup for a LR on a training data

set with k = 4 features and sample size n = 1, 000 per client in a FL setting takes roughly 23

minutes each for πw (cf. Table 3) and πc (cf. Table 5 in the appendix). Note that, as outlined

above, the circuit-speciﬁc trusted setup must only be computed once and can then be used by

all clients for a particular FL learning task. Using the proving key from the trusted setup, every

client must spend roughly 2.5 minutes on computing both proofs that allow fellow clients to verify

their submitted weight w and cost c (for k = 4 and n = 1, 000). In practical FL applications, the

proof generation likely runs on less sophisticated machines than our AWS instance. We, therefore,

also tested the proof duration on a single CPU core (also for combinations other than k = 4

and n = 1, 000). The results reveal that the witness generation duration was not sensitive to

this limitation, whereas the duration for generating the proof using rapidsnark increased seven

times from 4.3 to 29.4 seconds and the proof veriﬁcation duration four times from 0.24 to 0.97

seconds. In total, the proof duration grew 1.4 times from around 75 to 103 seconds. Moreover, the

RAM required to generate and validate proofs remains below 4 GB and agnostic to the number

of constraints. Looking at the performance of the system’s smart contract on the EVM, we ﬁnd

gas cost of around 2.2 million for all πw-related on-chain operations and 920, 000 for all πc-related

operations. This translates into a total of roughly USD 1270 for all on-chain operations (USD 900

for πw operations and USD 370 for πc operations) per client, given a gas price of 100 gwei and a

rate of 1 ETH = USD 4,000. While in absolute terms this is prohibitively expensive, it is only 21%

of the current public Ethereum target block capacity as well as 10.5% of the block limit. Note that

23

the πc operations are signiﬁcantly cheaper than the πw operations, mainly since the latter requires

the vector L as public input and updates wg. As long as operations on public blockchains are that

costly, using a permissioned blockchain like Quorum can allow not only to reduce costs but also

allowing for considerably higher throughput [74].

To assess our system’s scalability, we focus on analyzing the impacts of increasing k, n, and

ntest on the circuit-speciﬁc trusted setup, the proof generation and veriﬁcation, as well as the gas

cost of the smart contract. Both Figure 2 and Table 3 show results that are in line with the

expected scaling properties of SNARKs: The computation of the circuit-speciﬁc trusted setups

(i.e., ‘key gen duration’) as well as the time it takes to generate the proofs (i.e., ‘proof duration’)

scale linearly with (k + 1) · n or (k + 1) · (n + ntest) (cf. Table 5 in the appendix). Moreover,

veriﬁcation duration, veriﬁcation key size, and proof size do not signiﬁcantly change when increas-

ing the circuit complexity. Thus, increasing k, n, or ntest will have only minor eﬀects on the

system’s overall computation eﬀort, since the proof duration might grow for an individual client

whilst the redundant on-chain proof storage and veriﬁcation cost will remain constant. Even when

translating our results to circuits as huge as those in the Hermez project (the project also used

circom with snarkjs and manages to compute a proof for around 100 million constraints in few

minutes on a server with 64 virtual cores and 1 TB RAM [75]), we ﬁnd promising scaling perfor-

mance: Given the test results, we expect that πw and πc with (k + 1) · n = 600, 000 data points

and ntest = 0.1 · n = 6, 000 would result in roughly 100 million constraints and hence be feasible to

prove in a few minutes to hours per proof (depending on the hardware used; in our setup roughly

2.5 hours with 16 CPU cores or approximately 3.5 hours with one core) whilst handling a huge

sample size (e.g., k = 5 and n = 100, 000). In this case, the one-time trusted setups would take

a few hours to a few days for each participant of the trusted setup (which we assume will not

necessarily be conducted by the clients in practice, but a small to medium-sized group or maybe

also research institutions, as could be observed for the trusted setup used in Z-Cash, zkSync, etc.).

Besides, we expect the veriﬁcation duration, veriﬁcation key size, and proof size to remain constant

in this scenario.

Also, the gas cost for the EVM operations is independent of the proof complexity. The only

data that must be stored on-chain to verify a proof are the proof itself, the veriﬁcation key, and

the public inputs. Both the proof size as well as the veriﬁcation key size are constant for every k,

n, and ntest. The public inputs’ volume only increases when either the number of features k or the

LDP noise discretization interval dL grows, since this leads to an increase in the number of entries

in the weight vector w(cid:48) or the LDP noise vector L. Thus, raising w(cid:48) or L increases the payload

size, which in turn leads to a rise in gas cost. However, for moderate k and dL, the total gas cost

24

(a) Scaling of the circuit complexity (i.e., the number of con-

(b) Scaling of the veriﬁcation duration, veriﬁcation key size,

straints) with (k + 1) · n.

and proof size with the number of constraints.

Figure 2: πw scalability analysis (client perspective).

remains small since the respective proof veriﬁcation itself is responsible for the major part of the

gas cost. Therefore, both proofs can be stored as well as veriﬁed cheaply on-chain also for large

circuits and the particular gas cost remains, as mentioned above, approximately at 2.2 million

for all πw-related on-chain operations and 920, 000 for all πc-related operations. Eventually, a

clients’ eﬀort does not grow with the size of other clients’ underlying data sets or the number of

participating clients. Further, the number of on-chain transactions only grows linearly with the

number of clients and is independent of the size of the clients’ training data as well as the central

test data. These results promise high potential also for more sophisticated ML applications that

require higher data volumes.

Eventually, we refrain from testing the accuracy of our FL system. The only diﬀerence regarding

accuracy between our and a plain FL system is the LDP noise that we add to the clients’ weights;

and since aggregation is an average over all local weights plus noise, this diﬀerence is just an

average of i.i.d. Laplacian-distributed random variables, which has mean 0 and standard deviation

proportional to

ε√

|I|

. The value of ε and |I| hence completely determine the change in accuracy

of our approach compared to the literature.

5. Discussion and Conclusion

Our paper aims at answering the research question of how a FL system can achieve fairness,

integrity, and privacy simultaneously whilst still being practical and scalable. After identifying

a business need for these requirements and arguing that related work so far has not proposed

an architecture that satisﬁes them, we described our proposed system in Section 3 based on a

combination of blockchain, ZKP, and LDP. Our conceptual discussion of the architecture and the

25

LinRegProof0200000400000600000800000100000012000001400000010002000300040005000600070008000# of constraints(k+1)·nLinRegProof0500010000150002000025000300000.00.10.20.30.40.50.60.70.80.91.00200000400000600000800000100000012000001400000size(bytes)duration(s)# of constraintsverification duration (s)verification key size (bytes)proof size (bytes)experiments that we describe in Section 4 suggest that our implementation indeed oﬀers a practical

solution to conﬁdential, fair, and tamper-resistant FL that achieves reasonable performance and

scalability properties for LRs. Next to suggesting a pathway to eﬀectively combining FL with

blockchain, ZKP, and LDP, we develop a system that allows clients to verifying that other clients

truthfully trained their local model and received a fair compensation for participating in the case

of LR. Thus, we go beyond existing research that has suggested ZKPs for verifying ML model

inference based on already trained models.

However, our research is not without limitations and reveals potential for future research that

we will outline in this section to conclude our paper. First, even though our suggested system does

currently only support LRs, we tried to design it as generic as possible to allow for adapting the

system to other classes of ML protocols. Speciﬁcally, we move computationally intensive parts (in
our case, the inversion of X(cid:124)X) outside the circuit and only check certain properties of the result

(in our case, that the approximate inverse that must be provided as private input to the ZKP is

indeed close to the true inverse, cf. Section 3.1.1) rather than recomputing the result. For the case

of LR, we derived an error bound (see (16)) that allowed us to signiﬁcantly reduce the complexity

of the respective circuit while maintaining full tamper resistance. The approach of only proving

speciﬁc properties that the local weights need to satisfy to indicate the integrity of training may

be generalizable to further classes of ML models, also considering the recent advancement in using

ZKPs for frequent operations in ML (e.g., [65]). Since training ML models often involves solving a

convex optimization problem where optimality can be checked locally (e.g., all partial derivatives in

the allowed directions are 0) [76], we encourage future research to adapt the suggested architecture

to more sophisticated classes of ML models beyond LR. Furthermore, the aggregation of weights in

federated learning is often linear [25], so our concept of perturbing the local weights with veriﬁable

noise is applicable beyond multiple LRs: Assuming that the training data is i.i.d. (a common

assumption in FL applications), the local weights are also i.i.d.. Moreover, as we construct the

clients’ LDP noise from a random oracle, the noise is also i.i.d. and has mean 0 and ﬁnite variance

by construction. Since the weights and the noise applied to them are by construction independent,

by the linearity of the averaging algorithm FedAvg, the error in the global model is a weighted

average of local noise and the random variable (noise times weight) is i.i.d. with expectation value

0 and ﬁnite variance. By the law of large numbers, the error in the aggregated global model hence

converges to 0. Thus, for a large number of clients, the error term in the aggregate model as

introduced by LDP is typically small. It follows that our approach of using LDP (which has been

proposed by several other scholars but is particularly relevant in our system because we can prove

26

not only the correct training but also the correct addition of noise) extends to more sophisticated

ML models beyond LR.

To further improve the performance and practicality of our system, we aim at implementing

the ZKPs via STARKs for improved proof creation performance, post-quantum security, and elim-

inating the need for a trusted setup in the future. Further, the system’s scalability would further

beneﬁt from a recursive veriﬁcation mechanism that reduces the complexity of verifying weight

and cost proofs. This could be implemented by building on batching techniques [77] or recursive

proofs [78, 79] and would facilitate scalability by hierarchical aggregation (e.g., only log(|I|) veri-

ﬁcation steps would be required on-chain). Besides, even though recalculating w in πc is not the

proof’s main complexity driver, we see optimization potential there: One could commit a hash of

the weight (without noise) and some random salt in the smart contract (proving that the hash was

computed like that), so for computing the costs we only need to prove that we used the pre-image

of this hash (without salt) for the computation. This can further reduce the cost proof’s number of

constraints. Next to optimizations of our own code and the performance improvements in libraries

that support the generation of ZKP (e.g., STARKs or circom 2.0), we are also conﬁdent that

hardware acceleration for faster ZKP-related operations and particularly proving will be available

soon, as research in this area is already conducted, e.g., by projects that build on Ethereum and

that leverage ZKPs [80]. This may allow getting even shorter proof times also on devices that are

computationally more restricted than a Laptop.

Moreover, we acknowledge that there are still some attacks on integrity: When clients know the

learning task (i.e., in our case, the parameters stored on fl_generic) prior to committing their

data when joining the system, they could attack the system by manipulating their data set before

committing to it. However, reverse engineering the data in order to get a desired (malicious) result

for the weights is likely more eﬀort than just contributing arbitrarily chosen weights. Moreover,

we expect many use cases for our proposed system to be built on sensor data (e.g., from vehicular

networks or health applications). Given this, and the availability of certiﬁed sensors (e.g., by

means of a crypto-chip on the sensor and a certiﬁcate of the manufacturer), as are emerging,

for example, in Germany’s Smart Meter rollout [81], the ZKP-based approach could handle this

issue by including a proof of authenticity (i.e., a proof that the data was signed by a private key

that is bound to a certiﬁcate that was in turn signed by a trusted, publicly known entity) for

the sensor input data when committing to it. This would be easy to integrate at the costs of

an additional signature veriﬁcation per Merkle tree leaf (around 5,000 constraints per leaf for a

Schnorr signature). This still does not protect against physical manipulation (imagine putting a

27

temperature sensor to a place where it is not supposed to be), but may oﬀer a reasonable degree

of trust in data provenance in many practical scenarios.

Our current incentive mechanism relies on the existence of a central and public data set as

described in Section 3.1.4. Since we acknowledge that this hypothesis is not always feasible in

practice, we will work on developing other, eﬀective incentive mechanisms. In doing so, we intend

to ensure the mechanisms’ fairness by incorporating the research of Shapley [82]. In doing so, our

construction allows us to perform the local evaluation of each client on their actual weights with

and without noise, so we get new degrees of freedom for proving the correct evaluation and deriving

fair incentives.

Lastly, to ensure the system’s applicability in practice, we plan a twofold approach. First, as

we are currently training the test model on the California Housing Prices data set, we will also

run accuracy tests to assess how our conceptual approach translates into data-related performance

in practice. Second, we will evaluate the perspective of enterprises on the new features that the

combination of FL with blockchain technology, LDP, and ZKP oﬀers.

We believe that the convergence of emerging technologies like ML and blockchains in the

context of data generated by the IoT, as Guggenberger et al. [83] or Singh et al. [84] suggest, com-

bined with privacy-enhancing technologies in the context of sensor data sharing or derived models

in data markets [51], has the potential to facilitate many new use cases as well as business models

and can inspire the ﬁeld of computer science. As all these aspects are relevant for FL, we are

expecting interesting results that further extend our design to more complex models in the future.

Acknowledgment: We want to thank Orestis Papageorgiou, who pointed us to the work

of Newman [67], and Jordi Baylina and the iden3-Team for their great work on circom and

snarkjs and their helpful responses to our questions. Moreover, we thank Matthias Babel, Jonas

Berweiler, Dennis Jelito, and Michael Reichle for their ad-hoc problem-solving support. We also

gratefully acknowledge the Bavarian Ministry of Economic Aﬀairs, Regional Development and

Energy for their funding of the project “Fraunhofer Blockchain Center (20-3066-2-6-14)” that

made this paper possible.

References

[1] Marco Iansiti and Karim R. Lakhani. Competing in the age of AI: How machine intelligence

changes the rules of business. Harvard Business Review, 2020. URL https://hbr.org/2020

/01/competing-in-the-age-of-ai.

28

[2] Yann LeCun, Yoshua Bengio, and Geoﬀrey Hinton. Deep learning. Nature, 521(7553):436–444,

2015. doi: https://doi.org/10.1038/nature14539.

[3] Alex Galakatos, Andrew Crotty, and Tim Kraska. Distributed machine learning. In Encyclo-

pedia of Database Systems, 2018.

[4] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur´elien Bellet, Mehdi Bennis, Ar-

jun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings,

Rafael G. L. D’Oliveira, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett,

Adri`a Gasc´on, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Za¨ıd Harchaoui, Chaoyang

He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri

Joshi, Mikhail Khodak, Jakub Konecn´y, Aleksandra Korolova, Farinaz Koushanfar, Sanmi

Koyejo, Tancr`ede Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer
¨Ozg¨ur, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn

Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian

Tram`er, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X.

Yu, Han Yu, and Sen Zhao. Advances and open problems in federated learning, 2019. URL

https://arxiv.org/abs/1912.04977.

[5] Joost Verbraeken, Matthijs Wolting, Jonathan Katzy, Jeroen Kloppenburg, Tim Verbelen,

and Jan S. Rellermeyer. A survey on distributed machine learning, 2019. URL http://arxi

v.org/abs/1912.09789.

[6] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Chal-

lenges, methods, and future directions. IEEE Signal Processing Magazine, 37(3):50–60, 2020.

doi: https://doi.org/10.1109/MSP.2020.2975749.

[7] Xuefei Yin, Yanming Zhu, and Jiankun Hu. A comprehensive survey of privacy-preserving

federated learning: A taxonomy, review, and future directions. ACM Computing Surveys, 54

(6), 2021. doi: https://doi.org/10.1145/3460427.

[8] David B. Larson, David C. Magnus, Matthew P. Lungren, Nigam H. Shah, and Curtis P. Lan-

glotz. Ethics of using and sharing clinical imaging data for artiﬁcial intelligence: A proposed

framework. Radiology, 295(3):675–682, 2020. doi: https://doi.org/10.1148/radiol.2020192536.

[9] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning:

Concept and applications. ACM Transactions on Intelligent Systems and Technology, 10(2),

2019. doi: https://doi.org/10.1145/3298981.

29

[10] Andrew Hard, Kanishka Rao, Rajiv Mathews, Fran¸coise Beaufays, Sean Augenstein, Hubert

Eichner, Chlo´e Kiddon, and Daniel Ramage. Federated learning for mobile keyboard predic-

tion, 2018. URL http://arxiv.org/abs/1811.03604.

[11] Ahmet M. Elbir, Burak Soner, and Sinem Coleri. Federated learning in vehicular networks,

2020. URL https://arxiv.org/abs/2006.01412.

[12] Mohammed Aledhari, Rehma Razzak, Reza M. Parizi, and Fahad Saeed. Federated learning:

A survey on enabling technologies, protocols, and applications. IEEE Access, 8:140699–140725,

2020. doi: https://doi.org/10.1109/ACCESS.2020.3013541.

[13] Georgios A. Kaissis, Marcus R. Makowski, Daniel R¨uckert, and Rickmer F. Braren. Secure,

privacy-preserving and federated machine learning in medical imaging. Nature Machine In-

telligence, 2(6):305–311, 2020. doi: https://doi.org/10.1038/s42256-020-0186-10.

[14] Qiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tianjian Chen, and Han Yu. Federated

learning. Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning, 13(3), 2019. doi:

https://doi.org/10.2200/S00960ED2V01Y201910AIM043.

[15] Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz. Deep models under the GAN.

In Proceedings of the SIGSAC Conference on Computer and Communications Security, pages

603–618. ACM, 2017. doi: https://doi.org/10.1145/3133956.3134012.

[16] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov. Exploiting

unintended feature leakage in collaborative learning. In Symposium on Security and Privacy.

IEEE, 2019. URL https://doi.org/10.1109/SP.2019.00029.

[17] Milad Nasr, Reza Shokri, and Amir Houmansadr. Comprehensive privacy analysis of deep

learning: Passive and active white-box inference attacks against centralized and federated

learning. In Symposium on Security and Privacy, pages 739–753. IEEE, 2019. doi: https:

//doi.org/10.1109/SP.2019.00065.

[18] Le Trieu Phong, Yoshinori Aono, Takuya Hayashi, Lihua Wang, and Shiho Moriai. Privacy-

preserving deep learning via additively homomorphic encryption. IEEE Transactions on In-

formation Forensics and Security, 13(5):1333–1345, 2018. doi: https://doi.org/10.1109/TIFS

.2017.2787987.

[19] Ligeng Zhu and Song Han. Deep leakage from gradients. In Federated Learning, pages 17–31.

Springer, 2020. doi: https://doi.org/10.1007/978-3-030-63076-8 2.

30

[20] Boi Faltings and Goran Radanovic. Game theory for data science: Eliciting truthful informa-

tion. Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning, 11(2), 2017. URL

https://doi.org/10.2200/S00788ED1V01Y201707AIM035.

[21] Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin. A review of applications in federated learning.

Computers & Industrial Engineering, 149, 2020. doi: https://doi.org/10.1016/j.cie.2020.106

854.

[22] A. Besir Kurtulmus and Kenny Daniel. Trustless machine learning contracts; evaluating

and exchanging machine learning models on the ethereum blockchain, 2018. URL https:

//arxiv.org/abs/1802.10185.

[23] Vaikkunth Mugunthan, Ravi Rahman, and Lalana Kagal. BlockFLow: An accountable and

privacy-preserving solution for federated learning, 2020. URL https://arxiv.org/abs/20

07.03856.

[24] Anthony Junior Bokolo. Distributed ledger and decentralised technology adoption for smart

digital transition in collaborative enterprise. Enterprise Information Systems, 2021. doi:

https://doi.org/10.1080/17517575.2021.1989494.

[25] Adrian Nilsson, Simon Smith, Gregor Ulm, Emil Gustavsson, and Mats Jirstrand. A perfor-

mance evaluation of federated learning algorithms. In Proceedings of the Second Workshop on

Distributed Infrastructures for Deep Learning. ACM, 2018. doi: https://doi.org/10.1145/32

86490.3286559.

[26] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to

sensitivity in private data analysis.

In Theory of Cryptography, pages 265–284. Springer,

2006. doi: https://doi.org/10.1007/11681878 14.

[27] Cynthia Dwork and Aaron Roth. The algorithmic foundations of diﬀerential privacy. Foun-

dations and Trends in Theoretical Computer Science, 9(3–4):211–407, 2014. doi: https:

//doi.org/10.1561/0400000042.

[28] Cynthia Dwork and Adam Smith. Diﬀerential privacy for statistics: What we know and

what we want to learn. Journal of Privacy and Conﬁdentiality, 1(2), 2010. doi: https:

//doi.org/10.29012/jpc.v1i2.570.

[29] Gonzalo Munilla Garrido, Joseph Near, Aitsam Muhammad, Warren He, Roman Matzutt, and

Florian Matthes. Do I get the privacy I need? Benchmarking utility in diﬀerential privacy

libraries, 2021. URL https://arxiv.org/abs/2109.10789.

31

[30] Cynthia Dwork and Kobbi Nissim. Privacy-preserving datamining on vertically partitioned

databases. In Advances in Cryptology, pages 528–544. Springer, 2004. doi: https://doi.org/

10.1007/978-3-540-28628-8 32.

[31] Thˆong T Nguyˆen, Xiaokui Xiao, Yin Yang, Siu Cheung Hui, Hyejin Shin, and Junbum Shin.

Collecting and analyzing data from smart device users with local diﬀerential privacy, 2016.

URL https://arxiv.org/abs/1606.05053.

[32] Shaﬁ Goldwasser, Silvio Micali, and Charles Rackoﬀ. The knowledge complexity of interactive

proof systems. SIAM Journal on Computing, 18(1):186–208, 1989.

[33] Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to identiﬁcation and

signature problems. In Conference on the Theory and Application of Cryptographic Techniques,

pages 186–194. Springer, 1986. doi: https://doi.org/10.1007/3-540-47721-7 12.

[34] Nir Bitansky, Alessandro Chiesa, Yuval Ishai, Omer Paneth, and Rafail Ostrovsky. Succinct

non-interactive arguments via linear interactive proofs. In Theory of Cryptography Conference,

pages 315–333. Springer, 2013. doi: https://doi.org/10.1007/978-3-642-36594-2 18.

[35] Jens Groth, Rafail Ostrovsky, and Amit Sahai. Perfect non-interactive zero knowledge for

NP. In Annual International Conference on the Theory and Applications of Cryptographic

Techniques, pages 339–358. Springer, 2006. doi: https://doi.org/10.1007/11761679 21.

[36] Eli Ben-Sasson, Alessandro Chiesa, Daniel Genkin, Eran Tromer, and Madars Virza. SNARKs

for C: Verifying program executions succinctly and in zero knowledge. In Annual Cryptology

Conference, pages 90–108. Springer, 2013. doi: https://doi.org/10.1007/978-3-642-40084-1 6.

[37] Benedikt B¨unz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and Greg

Maxwell. Bulletproofs: Short proofs for conﬁdential transactions and more. In Symposium on

Security and Privacy, pages 315–334. IEEE, 2018. doi: https://doi.org/10.1109/SP.2018.00

020.

[38] Rosario Gennaro, Craig Gentry, Bryan Parno, and Mariana Raykova. Quadratic span pro-

grams and succinct NIZKs without PCPs.

In Annual International Conference on the

Theory and Applications of Cryptographic Techniques, pages 626–645. Springer, 2013. doi:

https://doi.org/10.1007/978-3-642-38348-9 37.

[39] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable zero knowl-

edge with no trusted setup. In Annual International Cryptology Conference, pages 701–732.

Springer, 2019. doi: https://doi.org/10.1007/978-3-030-26954-8 23.

32

[40] Bert-Jan Butijn, Damian A Tamburri, and Willem-Jan van den Heuvel. Blockchains: A

Systematic Multivocal Literature Review. ACM Computing Surveys, 53(3), 2020. doi: https:

//doi.org/10.1145/3369052.

[41] Y. Xiao, N. Zhang, W. Lou, and Y. T. Hou. A survey of distributed consensus protocols for

blockchain networks. IEEE Communications Surveys Tutorials, 22(2):1432–1465, 2020. doi:

https://doi.org/10.1109/COMST.2020.2969706.

[42] Michael Nofer, Peter Gomber, Oliver Hinz, and Dirk Schiereck. Blockchain. Business &

Information Systems Engineering, 59(3):183–187, 2017. doi: https://doi.org/10.1007/s12599

-017-0467-3.

[43] Rainer Alt. Electronic markets on blockchain markets. Electronic Markets, 30(2):181–188,

2020. doi: https://doi.org/10.1007/s12525-020-00428-1.

[44] Gilbert Fridgen, Sven Radszuwill, Nils Urbach, and Lena Utz. Cross-organizational workﬂow

management using blockchain technology – Towards applicability, auditability, and automa-

tion. In 51st Hawaii International Conference on System Sciences, pages 3507–3517, 2018.

doi: https://doi.org/10.24251/HICSS.2018.444.

[45] Karl W¨ust and Arthur Gervais. Do you need a blockchain? In Crypto Valley Conference on

Blockchain Technology, pages 45–54. IEEE, 2018. doi: https://doi.org/10.1109/CVCBT.2018

.00011.

[46] Satoshi Nakamoto. A peer-to-peer electronic cash system, 2008. URL https://bitcoin.or

g/bitcoin.pdf.

[47] Maximilian Wohrer and Uwe Zdun. Smart Contracts: Security patterns in the Ethereum

ecosystem and Solidity. In International Workshop on Blockchain Oriented Software Engi-

neering. IEEE, 2018. doi: https://doi.org/10.1109/IWBOSE.2018.8327565.

[48] Johannes Sedlmeir, Hans Ulrich Buhl, Gilbert Fridgen, and Robert Keller. The energy con-

sumption of blockchain technology: Beyond myth. Business & Information Systems Engi-

neering, 62(6):599–608, 2020. doi: https://doi.org/10.1007/s12599-020-00656-x.

[49] Lewis Gudgeon, Pedro Moreno-Sanchez, Stefanie Roos, Patrick McCorry, and Arthur Gervais.

Sok: Layer-two blockchain protocols. In International Conference on Financial Cryptography

and Data Security, pages 201–226. Springer, 2020. doi: https://doi.org/10.1007/978-3-030-

51280-4 12.

33

[50] Rui Zhang, Rui Xue, and Ling Liu. Security and privacy on blockchain. ACM Computing

Surveys, 52(3), 2019. URL https://doi.org/10.1145/3316481.

[51] Gonzalo Munilla Garrido, Johannes Sedlmeir, ¨Omer Uluda˘g, Ilias Soto Alaoui, Andre Luckow,

and Florian Matthes. Revealing the landscape of privacy-enhancing technologies in the context

of data markets for the IoT: A systematic literature review, 2021. URL https://arxiv.or

g/abs/2107.11905.

[52] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.

Communication-eﬃcient learning of deep networks from decentralized data. In Proceedings of

the 20th International Conference on Artiﬁcial Intelligence and Statistics, volume 54, pages

1273–1282. PMLR, 2017.

[53] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang. Diﬀerentially private asynchronous

federated learning for mobile edge computing in urban informatics. IEEE Transactions on

Industrial Informatics, 16(3):2134–2143, 2020. doi: https://doi.org/10.1109/TII.2019.29421

79.

[54] Josep Domingo-Ferrer, David S´anchez, and Alberto Blanco-Justicia. The limits of diﬀerential

privacy (and its misuse in data release and machine learning). Communications of the ACM,

64(7):33–35, 2021. doi: https://doi.org/10.1145/3433638.

[55] Latif U. Khan, Shashi Raj Pandey, Nguyen H. Tran, Walid Saad, Zhu Han, Minh N. H.

Nguyen, and Choong Seon Hong. Federated learning for edge networks: Resource optimization

and incentive mechanism. IEEE Communications Magazine, 58(10):88–93, 2020. doi: https:

//doi.org/10.1109/MCOM.001.1900649.

[56] Vikas Jaiman, Leonard Pernice, and Visara Urovi. User incentives for blockchain-based data

sharing platforms, 2021. URL https://arxiv.org/abs/2110.11348.

[57] P. Ramanan and K. Nakayama. BAFFLE : Blockchain based aggregator free federated learn-

ing.

In International Conference on Blockchain, pages 72–81. IEEE, 2020. doi: https:

//doi.org/10.1109/Blockchain50366.2020.00017.

[58] K. Toyoda and A. N. Zhang. Mechanism design for an incentive-aware blockchain-enabled

federated learning platform. In International Conference on Big Data, pages 395–403, 2019.

doi: https://doi.org/10.1109/BigData47090.2019.9006344.

[59] J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang. Incentive mechanism for reliable federated

learning: A joint optimization approach to combining reputation and contract theory. IEEE

34

Internet of Things Journal, 6(6):10700–10714, 2019. doi: https://doi.org/10.1109/JIOT.201

9.2940820.

[60] Jin Sun, Ying Wu, Shangping Wang, Yixue Fu, and Xiao Chang. A permissioned blockchain

frame for secure federated learning. IEEE Communications Letters, 2021. doi: https://doi.or

g/10.1109/LCOMM.2021.3121297.

[61] Loi Luu, Jason Teutsch, Raghav Kulkarni, and Prateek Saxena. Demystifying incentives in

the consensus computer. In Proceedings of the 22nd SIGSAC Conference on Computer and

Communications Security, pages 706–719. ACM, 2015. doi: https://doi.org/10.1145/281010

3.2813659.

[62] Howard Wu, Wenting Zheng, Alessandro Chiesa, Raluca Ada Popa, and Ion Stoica. DIZK:

A distributed zero knowledge proof system. In 27th {USENIX} Security Symposium, pages

675–692. {USENIX}, 2018. URL https://www.usenix.org/system/files/conference/u

senixsecurity18/sec18-wu.pdf.

[63] Boyuan Feng, Lianke Qin, Zhenfei Zhang, Yufei Ding, and Shumo Chu. ZEN: Eﬃcient zero-

knowledge proofs for neural networks, 2021. URL https://eprint.iacr.org/2021/087.

[64] Yupeng Zhang. Zero-knowledge proofs for machine learning. In Proceedings of the Workshop

on Privacy-Preserving Machine Learning in Practice. ACM, 2020. doi: https://doi.org/10.1

145/3411501.3418608.

[65] Chenkai Weng, Kang Yang, Xiang Xie, Jonathan Katz, and Xiao Wang. Mystique: Ef-

ﬁcient conversions for zero-knowledge proofs with applications to machine learning.

In

30th {USENIX} Security Symposium ({USENIX} Security 21), pages 501–518, 2021. URL

https://www.usenix.org/system/files/sec21-weng.pdf.

[66] Ian H. Witten, Eibe Frank, Mark A. Hall, and Christopher J. Pal. Data Mining. Elsevier,

2017. URL https://doi.org/10.1016/c2015-0-02071-8.

[67] M. Newman. How to determine accuracy of the output of a matrix inversion program. Journal

of Research of the National Bureau of Standards, Section B: Mathematical Sciences, 78B(2):

65–68, 1974.

[68] Ilya Mironov. On signiﬁcance of the least signiﬁcant bits for diﬀerential privacy. In Proceedings

of the Conference on Computer and Communications Security, page 650–661. ACM, 2012. doi:

https://doi.org/10.1145/2382196.2382264.

35

[69] Victor Balcer and Salil Vadhan. Diﬀerential privacy on ﬁnite computers, 2019. URL https:

//arxiv.org/abs/1709.05396.

[70] Cl´ement L. Canonne, Gautam Kamath, and Thomas Steinke. The discrete Gaussian for

diﬀerential privacy, 2021. URL https://arxiv.org/abs/2004.00010.

[71] How To Generate SNARK Parameters Securely. Wilcox, zooko, 2021. URL https://electr

iccoin.co/blog/snark-parameters/.

[72] Lorenzo Grassi, Dmitry Khovratovich, Christian Rechberger, Arnab Roy, and Markus

Schofnegger. Poseidon: A new hash function for zero-knowledge proof systems.

In 30th

{USENIX} Security Symposium. {USENIX}, 2021. URL https://www.usenix.org/syste

m/files/sec21summer grassi.pdf.

[73] Martin Albrecht, Lorenzo Grassi, Christian Rechberger, Arnab Roy, and Tyge Tiessen. Mimc:

Eﬃcient encryption and cryptographic hashing with minimal multiplicative complexity. In In-

ternational Conference on the Theory and Application of Cryptology and Information Security,

pages 191–219. Springer, 2016. doi: https://doi.org/10.1007/978-3-662-53887-6 7.

[74] Johannes Sedlmeir, Philipp Ross, Andr´e Luckow, Jannik Lockl, Daniel Miehle, and Gilbert

Fridgen. The DLPS: A framework for benchmarking blockchains. In Proceedings of the 54th

Hawaii International Conference on System Sciences, pages 6855–6864, 2021. doi: https:

//doi.org/10.24251/HICSS.2021.822.

[75] Hermez Network. Open sourcing an ultra-fast zk prover: Rapidsnark, 2021. URL https:

//blog.hermez.io/open-sourcing-ultra-fast-zk-prover-rapidsnark/.

[76] S´ebastien Bubeck. Convex optimization: Algorithms and complexity, 2014. URL https:

//arxiv.org/abs/1405.4980.

[77] Nicolas Gailly, Mary Maller, and Anca Nitulescu. SnarkPack: Practical SNARK aggregation,

2021. URL https://eprint.iacr.org/2021/529.pdf.

[78] Sean Bowe, Alessandro Chiesa, Matthew Green, Ian Miers, Pratyush Mishra, and Howard Wu.

ZEXE: Enabling decentralized private computation. In Symposium on Security and Privacy,

pages 947–964. IEEE, 2020. doi: https://doi.org/10.1109/SP40000.2020.00050.

[79] Alessandro Chiesa, Dev Ojha, and Nicholas Spooner. Fractal: Post-quantum and transparent

recursive proofs from holography.

In Annual International Conference on the Theory and

36

Applications of Cryptographic Techniques, pages 769–793. Springer, 2020. doi: https://doi.or

g/10.1007/978-3-030-45721-1 27.

[80] Alex Gluchowski. World’s ﬁrst practical hardware for zero-knowledge proofs acceleration,

2020. URL https://medium.com/matter-labs/worlds-first-practical-hardware-for

-zero-knowledge-proofs-acceleration-72bf974f8d6e.

[81] Alexander Djamali, Patrick Dossow, Michael Hinterstocker, Benjamin Schellinger, Johannes

Sedlmeir, Fabiane V¨olter, and Lukas Willburger. Asset logging in the energy sector: A scalable

blockchain-based data platform. Energy Informatics, 4(3), 2021. doi: https://doi.org/10.118

6/s42162-021-00183-3.

[82] Lloyd Stowell Shapley. A value for n-person games. In Contributions to the Theory of Games

(AM-28), Volume II, chapter 17, pages 307–318. Princeton University Press, 1953.

[83] Tobias Guggenberger, Jannik Lockl, Maximilian R¨oglinger, Vincent Schlatt, Johannes

Sedlmeir, Jens-Christian Stoetzer, Nils Urbach, and Fabiane V¨olter. Emerging digital

technologies to combat future crises: Learnings from covid-19 to be prepared for the fu-

ture. International Journal of Innovation and Technology Management, 2021. doi: https:

//doi.org/10.1142/S0219877021400022.

[84] Sushil Kumar Singh, Shailendra Rathore, and Jong Hyuk Park. Blockiotintelligence: A

blockchain-enabled intelligent IoT architecture with artiﬁcial intelligence. Future Generation

Computer Systems, 110:721–743, 2020.

37

Appendix

5.1. Selected Code Snippets

1 template LinRegParams (k , n , dec , l_train , require_meanxn_acc , require_varxn_acc , require_XX_acc

, require_XX_inv_maxnorm , require_X_trans_Y_maxnorm , require_b_noisy_acc , hash_alg , DP_acc )

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

{

signal private input in_x_pos [ k ][ n ];

signal private input in_x_sign [ k ][ n ];

signal private input in_y_pos [ n ][1];

signal private input in_y_sign [ n ][1];

signal private input in_xx_inv_pos [ k ][ k ];

signal private input in_xx_inv_sign [ k ][ k ];

// public inputs :

signal input in_k ;

signal input in_n ;

signal input in_dec ;

signal input i n _ m e r k l e ro o t _ t r a i n ;

signal input in_Lap_X_pos [ DP_acc - 1];

signal input in_DP_acc ;

signal input in_hash_BC ;

signal input i n _ b _ n o i s y_ t r u e _ p o s [ k ][1];

signal input i n _ b _ n o i s y _ t r u e _ s i g n [ k ][1];

signal input i n _ r e q u i r e _ m e a n x n _ a c c ;

signal input i n _ r e q u i r e _ v a r x n _ a c c ;

signal input in_ req uir e_X X_a cc ;

signal input i n _ r e q u i r e _ X X _ i n v _ m a x n o r m ;

signal input i n _ r e q u i r e _ X _ t r a n s _ Y _ m a x n o r m ;

signal input i n _ r e q u i r e _ b _ n o i s y _ a c c ;

...

// (Xi)+
// Sign(X)i
// (Yi)+
// Sign(Yi)
// (Zi)+
// Sign(Z)i

// k

// n

// d
// rtD
i

// L

// dL

// block hash or other source of public randomness
// (w(cid:48)
i)+
// Sign(w(cid:48))i
// ∼ εµ

// ∼ εσ

// ∼ εinverse

// ϑZ

// ϑX(cid:124)Y
// ∼ εw(cid:48)

Listing 1: Excerpt from the circuit for the weight proof πw – Input signals. The default visibility for inputs is

public.

...

// 1. step | Check data normalization ( i . e . , εµ ≈ 0 and εσ ≈ 1)

component check_mean = Check_MeanXY (k , n , dec , r eq u ir e _m e a n xn _ a c c ) ;

...

// make sure that range_meanxn_acc . out is within the bound εµ

component range_meanxn_acc = GreaterEqThan (...) ;

...

1 === range_meanxn_acc . out ;

...

component check_var = Check_VarXY (k , n , dec , ... , re q uir e _v ar x n _a cc ) ;

...

// make sure that range_varxn_acc . out is within the bound εσ

component range_varxn_acc = GreaterEqThan ( b i t s _ r a n g e _ v a r x n _ a c c ) ;

...

38

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

1 === range_varxn_acc . out ;

// 2. step | Check rtD
i

component m erk lepr oof _tr ain = MerkleProof_s ix (k , n , l_train , hash_alg ) ;

...
// make sure that rtD
i

is correct

i n _ m e rk l e r o o t _ t r ai n === m erk lep roof _tr ain . out ;

...

// 3. step | range proof εinverse

component XX_rangeproof = XX_RangeProof (k , n , require_XX_acc , dec ) ;

...

// make sure that range_XX_acc . out is within the bound εinverse

component range_XX_acc = GreaterEqThan (...) ;

...

1 === range_XX_acc . out ;

// 4. step | range proof ϑZ

component m a x e l e m e n t _ X X _ i n v _ p o s = NormMaxElement (k , k , ...) ;

...

// make sure that k · range XX inv norm.out is within the bound ϑZ

component r ang e_XX _in v_n orm = LessEqThan (...) ;

1 === ra nge _XX _in v_n orm . out ;

// 5. step | range proof ϑX(cid:124)Y

// compute X

(cid:124)
i Yi

component X_trans_Y_mult = MatrixMult (n , k , 1) ;

...

component m a x e l e m e n t _ X _ t r a n s _ Y _ p o s = V e c t o r N o r m M a x E l e m e n t (k , ...) ;

...
// make sure that (\ textcolor { gray }{ $ * k \:\ cdot \: $maxelement \ _X \ _trans \ _Y \ _pos . out$ is within

the bound $ \ vartheta_ {\ mathbf { X }^{\ intercal } Y } $ }*)

component r a n g e _ X _ t r a n s _ Y _ n o r m = LessEqThan (...) ;

1 === r a n g e _ X _ t r a n s _ Y _ n o r m . out ;

// 6. step | range proof εw(cid:48)
component b_ ra n ge p ro of _ no i sy = b_ n o i s y _ Ra n ge P ro of (k , n , require_b_noisy_acc , hash_alg ,

dec , DP_acc ) ;

...

// make sure that r ange _b_ noi sy_ acc . out is within the bound εw(cid:48)
component r ang e_b_ noi sy_ acc = GreaterEqThan ( r e q u ir e _ b _ n o i s y _a c c ) ;

1 === ra nge _b_ noi sy_ acc . out ;

58 }

59 component main = LinRegParams (...) ;

Listing 2: Excerpt from the circuit for the weight proof πw – Main part.

1 template LinRegCost (k , n , n_test , dec , l_train , l_test , hash_alg , require_b_acc ) {

2

3

signal private input in_x_pos [ k ][ n ];

// (Xi)+

39

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

signal private input in_x_sign [ k ][ n ];

signal private input in_y_pos [ n ][1];

signal private input in_y_sign [ n ][1];

signal private input in_b_true_pos [ k ][1];

signal private input in_b_true_sign [ k ][1];

signal private input in_xx_inv_pos [ k ][ k ];

// Sign(X)i
// (Yi)+
// Sign(Yi)
// (wi)+
// Sign(wi)
// (Zi)+
// Sign(Z)i

signal private input in_xx_inv_sign [ k ][ k ];
//Dtest is not set as public to reduce onchain data volume

signal private input in_x_test_pos [ k ][ n_test ];

signal private input in_x_test_sign [ k ][ n_test ];

signal private input in_y_test_pos [ n_test ][1];

signal private input in_y_test_sign [ n_test ][1];

// (Xtest)+
// Sign(X)test
// (Ytest)+
// Sign(Y )test

// public inputs :

signal input in_ cos t_s ubm itt ed ;

signal input in_k ;

signal input in_n ;

signal input in_n_test ;

signal input in_dec ;

signal input i n _ m e r k l e ro o t _ t r a i n ;

signal input i n_ m er kl e ro o t_ t es t ;

signal input in_require_b_acc ;

...

// ci

// k

// n

// ntest

// d
// rtD
i
// rtDtest

// ∼ εw

Listing 3: Excerpt from the circuit for the cost proof πc – Input signals. The default visibility for inputs is public.

...

// 1. step | Check rtD
i

component m erk lepr oof _tr ain = MerkleProof_s ix (k , n , l_train , hash_alg ) ;

...
// make sure that rtD
i

is correct

i n _ m e rk l e r o o t _ t r ai n === m erk l ep roof _ tr ain . out ;

// 2. step | Check rtDtest

component merkleproof_test = Merkle Proof _six (k , n_test , l_test , hash_alg ) ;

...
// make sure that rtDtest is correct

i n _ m er kl e ro o t_ te s t === merkleproof_test . out ;

// 3. step | range proof wi

component b_rangeproof = b_RangeProof (k , n , require_b_acc , hash_alg , dec ) ;

...

// make sure that range_b_true_acc . out is within the bound εw

component range_b_true_acc = GreaterEqThan (...) ;

1 === range_b_true_acc . out ;

// 4. step | compute ˆYtest,i
// compute X(cid:124)

signal x_test_trans_pos [ n_test ][ k ];

signal x_ tes t_t ran s_s ign [ n_test ][ k ];

40

...
// calculate ˆYtest,i
component y_est_mult = MatrixMult (k , n_test , 1) ;

...

// 5. step | compute ˜ci

...

signal y_est [ n_test ];

signal y_test [ n_test ];

signal y_test_tmp [ n_test ];

component cost_sum = SigSum ( n_test ) ;

...

// make sure that ci = ˜ci

i n _ co st_ sub mitt ed === cost_sum . out ;

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40 }

Listing 4: Excerpt from the circuit for the cost proof πc – Main part.

1 library lib {

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

...

// beta

struct Beta {

uint [] beta_pos ;

uint8 [] beta_sign ;

// (w(cid:48)
i)+
// Sign(w(cid:48))i

}

struct BetaGlobal {

Beta beta ;

uint16 I_round ;

}

struct Proof {

uint [2] a ;

uint [2][2] b ;

uint [2] c ;

}

// cost struct

struct FL_cost {

uint [] cost ;

address payable [] t_cost ;

}

// client struct

struct FL_client {

uint16 clientID ;

// wg
// number of participants with valid πw
i

// proof . json

// C

uint merkleroot_train ;

// rtDi

uint hash_BC ;

// current block hash

Beta beta_noisy_true ;

address t_betaverifier ;

Proof betaproof ;

bool betaproof_valid ;

// (w(cid:48)
i)

41

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60 }

uint cost ;

// ci

address t_costverifier ;

Proof costproof ;

}

// generic struct

struct FL_generic {

uint admission_fee ;

// k in wei

uint8 k ;

uint n ;

uint n_test ;

uint8 dec ;

uint DP_acc ;

uint merkleroot_test ;

uint [] Lap_X_pos ;

uint8 re q ui re _ me a nx n_ a cc ;

uint8 r equ ire _va rxn_ acc ;

// k

// n

// ntest

// d

// dL
// rtDtest
// (L)+

// ∼ εµ

// ∼ εσ

uint8 require_XX_acc ;

// ∼ εinverse

uint r e q u i r e _ X X _ i n v _ m a x n o r m ;

// ϑZ

uint8 r e q u ir e _ b _ n o i s y _a c c ;

uint r e q u i r e _ X _ t r a n s _ Y _ m a x n o r m ; // ϑX(cid:124)Y
// ∼ εw(cid:48)
// ∼ εw

uint8 require_b_acc ;

uint8 hash_alg ;

// hash alg

}

...

Listing 5: Excerpt from the client smart contract – Support library.

1 ...

2 contract Clients {

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

// generic variables

uint16 public count ;

uint32 constant b e t a p r o o f _ p u b l i c i n p u t _ l e n g t h = 119;

address public t_initialclient ;

uint [] public incentives ;

// initialize structs

lib . FL_generic fl_generic ;

lib . BetaGlobal betaglobal ;

lib . FL_cost fl_cost ;

// mappings

mapping ( address = > lib . FL_client ) public mapclient ;

mapping ( uint = > address ) public mapID ;

constructor ( lib . FL_generic memory _fl_generic ) {

count = 0;

42

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

t_initialclient = msg . sender ;

fl_generic = _fl_generic ;

}

//

// functions

//

function registerClient ( uint _me rkl ero ot _ tra i n ) public payable {

count ++;

mapID [ count ] = msg . sender ;

mapclient [ msg . sender ]. clientID = count ;

mapclient [ msg . sender ]. merkleroo t_ tr ai n = _ me r kle r oo t _tr a in ;

mapclient [ msg . sender ]. hash_BC = uint ( blockhash ( block . number ) ) ;

// require that fee has been paid

require ( msg . value >= fl_generic . admission_fee , " Pay fee " ) ;

}

function uploadBeta ( lib . Proof memory _betaproof , lib . Beta memory _beta_noisy_true , address

_t_betaverifier ) public {

// upload proof

mapclient [ msg . sender ]. t_betaver ifier = _t_be taver ifier ;

// address of deployed

verifier SC

mapclient [ msg . sender ]. betaproof = _betaproof ;

// upload beta

mapclient [ msg . sender ]. beta_nois y_tru e = _beta_nois y_ tr ue ;

// verify beta proof

bool proof = lib . verifyBeta ( fl_generic , mapclient [ msg . sender ]) ;

require ( proof , " proof failed " ) ;

// no beta will be stored if proof fails

mapclient [ msg . sender ]. betaproof _vali d = proof ;

// update betaglobal

lib . Beta [] memory beta_all_valid = new lib . Beta []( count ) ;

uint16 i_valid = 0;

for ( uint16 i = 1; i <= count ; i ++) {

if ( mapclient [ getClientAddress ( i ) ]. betap roof_valid ) {

beta_all_valid [ i_valid ] = mapclient [ ge tC li en tA dd re ss ( i ) ]. beta_noisy_true ;

i_valid ++;

}

}

betaglobal = lib . genBetaMean ( beta_all_valid ) ;

}

function uploadCost ( lib . Proof memory _costproof , uint _cost , address _t_costverifier )

public {

// make sure that client contributed

require ( mapclient [ msg . sender ]. betaproof_valid , " no beta " ) ;

43

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101 }

// upload proof

mapclient [ msg . sender ]. t_costver ifier = _t_co stver ifier ;

// address of deployed

verifier SC

mapclient [ msg . sender ]. costproof = _costproof ;

// upload cost

mapclient [ msg . sender ]. cost = _cost ;

// verify cost proof

bool proof = lib . verifyCost ( fl_generic , mapclient [ msg . sender ]) ;

require ( proof , " proof failed " ) ;

// no cost will be stored if proof fails

// upload to fl_cost

fl_cost . cost . push ( _cost ) ;

fl_cost . t_cost . push ( payable ( msg . sender ) ) ;

}

function I n ce n t i v i z e _ c li e n t s () public payable {

// make sure that only initial client can trigger incentive distribution

require ( msg . sender == t_initialclient , " only initclient " ) ;

// get incentives

incentives = lib . calcIncentive s ( fl_cost . cost , fl_generic . admission_fee ) ;

// pay incentives

require ( address ( this ) . balance >= incentives . length * fl_generic . admission_fee , " low

balance " ) ;

for ( uint16 i = 0; i < count ; i ++) {

fl_cost . t_cost [ i ]. transfer ( incentives [ i ]) ;

}

}

...

Listing 6: Excerpt from the client smart contract – Main part.

44

5.2. Performance of the πw circuit

k

n

(k + 1) · n

key gen

proof gen

veriﬁcation

circuit

veriﬁcation

key size

proof

size

# con-

straints

26,894

34,340

42,834

50,272

89,819

128,362

100

150

200

250

500

750

1,000

168,619

1,250

208,162

1,500

246,658

1,750

286,670

2,000

325,975

2,250

364,709

2,500

404,962

2,750

444,030

3,000

482,522

3,250

522,775

3,500

562,317

3,750

601,520

4,000

640,825

4,500

718,864

5,000

798,659

7,500

1,190,620

duration

duration

duration

(s)

84

93

113

117

177

213

294

337

372

508

558

627

659

713

803

990

1070

1089

1148

1246

1360

2571

(s)

2.981

3.619

4.530

5.091

8.641

12.080

15.996

19.410

22.400

27.322

31.217

33.409

36.868

40.447

43.499

49.498

54.096

57.042

59.630

70.394

74.945

120.736

(s)

0.238

0.239

0.245

0.239

0.236

0.238

0.241

0.237

0.241

0.241

0.241

0.238

0.237

0.242

0.246

0.242

0.236

0.237

0.236

0.234

0.232

0.263

size

(MB)

15

20

23

26

46

62

86

102

118

150

166

182

198

241

230

246

294

310

326

358

391

614

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

4

20

30

40

50

100

150

200

250

300

350

400

450

500

550

600

650

700

750

800

900

1,000

1,500

(kB)

(bytes)

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

25

707

710

707

705

708

706

706

709

706

707

707

707

708

708

707

707

704

705

710

706

705

705

Table 4: Evaluation of essential parameters for building and verifying the πw circuit depending on k and n.

45

5.3. Performance of the πc circuit

k

n

ntest

(k + 1) ·

# con-

(n+ntest)

straints

20

30

40

50

100

150

200

250

500

10

10

10

10

10

15

20

25

50

150

200

250

300

550

825

20,959

26,940

33,971

39,952

72,194

105,940

1,100

141,684

1,375

176,240

2,750

349,881

4

4

4

4

4

4

4

4

4

4

key gen

proof gen

veriﬁcation

circuit

veriﬁcation

duration

duration

duration

key size

(s)

82

90

108

114

174

206

293

339

659

(s)

3.005

3.472

4.439

4.951

8.152

11.108

15.439

18.568

36.949

(s)

0.243

0.237

0.241

0.250

0.244

0.243

0.243

0.247

0.244

0.243

size

(MB)

11

13

18

21

38

51

74

88

174

346

proof

size

(kB)

(bytes)

4.2

4.2

4.2

4.2

4.2

4.2

4.2

4.2

4.2

4.2

707

706

704

710

705

708

707

704

708

705

1,000

100

5,500

697,265

1380

73.696

Table 5: Evaluation of essential parameters for building and verifying the πc circuit depending on k, n, and ntest.

46

