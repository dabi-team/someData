ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

1

Latency Optimization for Blockchain-Empowered Federated
Learning in Multi-Server Edge Computing

Dinh C. Nguyen, Member, IEEE, Seyyedali Hosseinalipour, Member, IEEE, David J. Love, Fellow, IEEE,
Pubudu N. Pathirana, Senior Member, IEEE, and Christopher G. Brinton, Senior Member, IEEE

2
2
0
2

l
u
J

4

]

G
L
.
s
c
[

2
v
0
7
6
9
0
.
3
0
2
2
:
v
i
X
r
a

Abstractâ€”In this paper, we study a new latency optimization
problem for blockchain-based federated learning (BFL) in multi-
server edge computing. In this system model, distributed mobile
devices (MDs) communicate with a set of edge servers (ESs) to
handle both machine learning (ML) model training and block
mining simultaneously. To assist the ML model training for
resource-constrained MDs, we develop an ofï¬‚oading strategy that
enables MDs to transmit their data to one of the associated ESs.
We then propose a new decentralized ML model aggregation
solution at the edge layer based on a consensus mechanism to
build a global ML model via peer-to-peer (P2P)-based blockchain
communications. Blockchain builds trust among MDs and ESs to
facilitate reliable ML model sharing and cooperative consensus
formation, and enables rapid elimination of manipulated models
caused by poisoning attacks. We formulate latency-aware BFL as
an optimization aiming to minimize the system latency via joint
consideration of the data ofï¬‚oading decisions, MDsâ€™ transmit
power, channel bandwidth allocation for MDsâ€™ data ofï¬‚oading,
MDsâ€™ computational allocation, and hash power allocation. Given
the mixed action space of discrete ofï¬‚oading and continuous
allocation variables, we propose a novel deep reinforcement
learning scheme with a parameterized advantage actor critic
algorithm. We theoretically characterize the convergence prop-
erties of BFL in terms of the aggregation delay, mini-batch
size, and number of P2P communication rounds. Our numerical
evaluation demonstrates the superiority of our proposed scheme
over baselines in terms of model training efï¬ciency, convergence
rate, system latency, and robustness against model poisoning
attacks.

Index Termsâ€”Federated learning, Blockchain, edge comput-

ing, actor-critic learning, network optimization.

I. INTRODUCTION

In recent years, the demand for deploying machine learning
(ML) in wireless networks and Internet of Things (IoT) appli-
cations has increased dramatically. However, due to growing
concerns associated with data privacy, it is infeasible to trans-
mit all collected data from IoT edge devices to a central loca-
tion (e.g., a datacenter) for model training. Federated learning
(FL) has emerged as a popular approach for distributed ML
which allows for model training without requiring data sharing
[1], [2]. Under FL, devices operate as workers to train local
ML models using their own datasets, and exchange their model
updates with an aggregator, e.g., an edge server (ES), over
multiple communication rounds to converge on a global model.
While FL distributes the data processing step across devices,

Dinh C. Nguyen, Seyyedali Hosseinalipour, David J. Love, and Christopher
G. Brinton are with the Elmore Family School of Electrical and Computer
Engineering, Purdue University, USA (e-mails: {nguye772, hosseina, djlove,
cgb}@purdue.edu)
Pubudu N.

Pathirana

is with

School

the

of

Ponds, VIC 3216, Australia

Engineering,
(e-mail:

Deakin University, Waurn
pubudu.pathirana@deakin.edu.au).

the model aggregation step is still often carried out at a single
location, which imposes security issues including single-point-
of-failure and server malfunction. Additionally,
this poses
scalability restrictions for ML training processes, especially as
the number of IoT devices involved and their geographic reach
continue to expand [3]. Therefore, it is desirable to develop
a more decentralized FL architecture for realizing scalable
model training while preserving security in next-generation
intelligent networks.

In this context, blockchain is a promising technology for
enabling reliable decentralized FL via its peer-to-peer (P2P)
networking topology empowered by an immutable, transparent
and tamper-proof data ledger [4]. The use of blockchain in
FL can mitigate the single-point-of-failure issue, and builds
trust between devices and multiple servers for secure ML
model
training [5]. Given these beneï¬ts, blockchain-based
federated learning (BFL) has been recently investigated in
different domains, such as vehicular communications [6] and
mobile crowdsensing [7]. To implement BFL systems, devices
need to interface with decentralized servers in settings where
communication and computation resources are limited, which
will impact the ML model training quality. Moreover, each
device exhibits interest in participating in block mining to
further gain blockchain rewards, e.g., cryptocurrency tokens,
which in turn enhances the reliability and security for FL. This
leads to the concept of mobile mining which has been adopted
in practical BFL environments [8], [9]. The concurrence of
both ML model training and block mining introduces new
challenges to network service latency and resource man-
agement, motivating a holistic optimization architecture for
efï¬cient BFL in wireless networks.

A. Related Works

We summarize related works in latency optimization and

resource allocation for standard FL and decentralized BFL.

1) Standard FL: Latency optimization has recently received
signiï¬cant attention in FL research. The work in [10] proposed
a joint device scheduling and bandwidth allocation frame-
work for wireless FL to improve the convergence rate of
ML model training. Another study in [11] investigated semi-
asynchronous FL, focusing on the convergence analysis of
model training under edge heterogeneity and non-independent
and identically distributed (non-IID) data distributions across
the edge devices. An asynchronous FL scheme was considered
in [12] for unmanned aerial vehicles (UAVs)-assisted networks
to minimize the model exchange latency and ML training
learning (DRL). To mitigate
loss via deep reinforcement

 
 
 
 
 
 
ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

2

Table I: Comparison of methodology design features between
our paper and related works in latency optimization and
resource allocation for FL.

Features

[10]

[13]

consensus-based

ofï¬‚oading-assisted

FL design in multi-edge
servers
Data
FL
P2P
model aggregation
Blockchain-based FL de-
sign
DRL-based resource allo-
cation
Parameterized A2C design
FL latency optimization

(cid:88)

(cid:88)

(cid:88)

Our
work

(cid:88)

(cid:88)

(cid:88)

(cid:88)

[22]

[25]

[26]

(cid:88) (cid:88)

[27],
[28]

(cid:88) (cid:88)

[18],
[19]

(cid:88)

(cid:88)

(cid:88)

(cid:88) (cid:88)

(cid:88)
(cid:88)

(cid:88)

straggler effects caused by resource-limited clients, the authors
in [13] presented a partial ofï¬‚oading-assisted FL scheme using
game theory. A partial ofï¬‚oading-based FL solution was also
proposed in [14] for edge computing, focusing on the delay
analysis of the data ofï¬‚oading and model update. Similarly, a
convex optimization approach was applied in [15] to minimize
the energy consumption of model updating and sharing.

2) Decentralized and Blockchain-based FL: Several recent
works have considered techniques for decentralizing FL aggre-
gation schemes. The authors in [16] introduced a decentralized
FL scheme based on model segmentation with a gossip pro-
tocol for client sampling in each model aggregation round.
In [17], a decentralized FL solution was proposed using the
device-to-device (D2D) concept in serverless edge networks,
with a graph-coloring based scheduling policy to characterize
the data communications between two devices. Our recent
works in [18], [19] developed D2D-based semi-decentralized
and hybrid FL frameworks, where we jointly modeled com-
munication efï¬ciency and statistical heterogeneity of data and
obtained new convergence bounds for distributed ML.

Recently, the integration of blockchain into FL has been
investigated. The study in [20] analyzed end-to-end latency
for ML model training, update transmission and block mining
in a BFL system. [21] analyzed the communication latency and
consensus delays for BFL-based vehicular networks, deriving
an optimal block arrival rate for vehicles based on system
dynamics. The authors in [22] focused on developing a band-
width allocation and device scheduling solution for digital
twin-enabled BFL. Moreover,
the work in [23] proposed
a BFL-based privacy-preserving UAV network to optimize
the energy consumption of UAVs, vehicular device service
coverage and a composite service hit ratio. In recent work
[24], a dynamic resource allocation framework for BFL was
proposed with a focus on maximizing the training data size
with respect to energy usage constraints.

B. Motivations and Key Contributions

Despite such research efforts, several limitations still exist

in current BFL works, which are highlighted below:

â€¢ Most current standard FL [10], [11], [14] and decen-
tralized FL frameworks [18] still rely on a single ES
to coordinate model aggregations. In these architectures,

single-point-of-failure bottlenecks may disrupt the entire
FL system if the server is attacked. Only the work in [22]
has considered a multi-server edge computing model for
BFL, but its model aggregation still follows traditional
FL.

â€¢ End-to-end latency optimization,

i.e., for both model
training and block mining, remains understudied in cur-
rent BFL systems [20]â€“[22]. Existing works mostly aim
to characterize, rather than optimize, BFL latency. More-
over, the beneï¬ts of blockchain to support robust BFL
training against model attacks have not been yet investi-
gated.

â€¢ The potential beneï¬ts of edge computing have not been
well exploited in existing BFL schemes. Most works
[12], [15], [24] have not considered practical resource
constraints of mobile IoT devices and the potential for
ESs to mitigate resulting straggler effects. Only [13], [14]
have considered such a scenario, with the focus instead
on partial ofï¬‚oading for traditional FL.

â€¢ None of the existing works have analyzed the conver-
gence properties of BFL in a multi-server system. A
comprehensive theoretical analysis will provide insights
into BFL operations, leading to potential optimization
techniques.

Motivated by the aforementioned limitations, we propose a
novel consensus-based BFL model for efï¬cient and robust ML
model training via blockchain. Speciï¬cally, we develop a new
cooperative ofï¬‚oading-assisted model learning and resource
trading-assisted block mining framework for FL. We then
propose a partial model aggregation solution for facilitating
global model aggregations at the edge layer using blockchain-
enabled P2P communications. Blockchain is important for
our methodology in two key ways: (i) it builds trust among
MDs and ESs to facilitate reliable ML model sharing and
cooperative consensus formation for our federated learning ap-
proach; and (ii) it allows for rapid elimination of manipulated
models from compromised ESs caused by poisoning attacks,
thereby enhancing the robustness of global model training.
The system latency is subsequently formulated by considering
both model learning latency and block mining latency, which is
then optimized by a parameterized actor-critic algorithm. The
comparison of our paper with related works in terms of several
key design features is summarized in Table I. In summary, the
unique contributions of this paper are:

1) We propose a multi-server-assisted BFL architecture,
where geo-distributed mobile devices (MDs) commu-
nicate with a set of ESs for ML model training and
block mining simultaneously. To mitigate straggler ef-
fects caused by resource-constrained MDs, an ofï¬‚oading
strategy is proposed that enables MD data transmission
to an ES for ML model training. Moreover, we develop a
resource trading strategy to alleviate block mining latency
from resource-limited MDs.

2) We provide a holistic convergence analysis of BFL. In
doing so, we consider a new partial model aggregation
solution for facilitating global model aggregations at the
edge layer via P2P-based blockchain communications.

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

3

Our resulting bound reveals the impact of the aggregation
delay, mini-batch size, and number of P2P communica-
tion rounds on the convergence rate.

3) We formulate a new system latency minimization prob-
taking into account both ofï¬‚oading-assisted ML
lem,
model
training latency, model consensus latency and
block mining latency. This optimization couples data
ofï¬‚oading decisions, MD transmit powers, and the allo-
cation of channel bandwidth, MD computation, and hash
power resources to minimize latency with a model quality
constraint.

4) To solve the resulting optimization over a mixed dis-
crete and continuous solution space, we propose a novel
DRL method based on a parameterized advantage actor
critic (A2C) algorithm. We provide a holistic design of
the actor,
including ofï¬‚oading and allocation policies
empowered by trust region policy optimization (TRPO),
along with a critic for the state-value training.

5) We

experiments

conduct numerical

for both our
consensus-based BFL and parameterized A2C schemes.
The results reveal
that our BFL scheme outperforms
existing FL approaches in terms of model loss and accu-
racy convergence in both IID and non-IID data settings.
Our proposed parameterized A2C scheme also helps
lower the system latency by up to 38% compared with
state-of-the-art DRL schemes. Moreover, our blockchain-
empowered BFL scheme shows high robustness against
model poisoning attacks.

C. Paper Organization

The remainder of this paper is organized as follows. Sec-
tion II presents the BFL architecture and its different compo-
nents including the ML training and model aggregation pro-
cedures. Moreover, we conduct an analysis of the BFL model
training to characterize the impact of different system parame-
ters on learning convergence. In Section III, we formulate the
corresponding system latency minimization problem, taking
into account ofï¬‚oading-assisted ML model training latency,
model consensus latency, and block mining latency. To solve
the formulated problem, we propose a DRL method based
on a parameterized advantage actor critic (A2C) algorithm
in Section IV, where the utility measure captures the latency
objective and the action space is restricted by the learning
and resource constraints. We present experiments comparing
latency and accuracy obtained by our methodology against
several baselines in Section V. Finally, Section VI concludes
the paper. The key acronyms and notations used in this paper
are summarized in Table II and Table III, respectively.

II. SYSTEM MODEL
In this section, we describe our BFL system and detail the
BFL task model, and then analyze its convergence properties.

A. Overall System Architecture

Our proposed BFL architecture is illustrated in Fig. 1. Each
ES is located at a base station (BS) to provide computation

Table II: List of key acronyms.

Acronym Deï¬nition
FL
BFL

Acronym Deï¬nition
ML
MD

Machine learning
Mobile device

Federated learning
Blockchain-based
federated learning
Edge server
Unmanned aerial vehicle

Deep reinforcement learn-
ing
Trust region policy opti-
mization
Deep neural network

P2P
IID

A2C

SGD

DDPG

ES
UAV

DRL

TRPO

DNN

MSPBE

Mean Squared Projected
Bellman Error

KL

Peer-to-peer
Independent and identi-
cally distributed
Advantage actor critic

Stochastic gradient de-
scent
Deep deterministic policy
gradient
Kullbackâ€“Leibler

Table III: List of key notations.

Notation
M
K
f (cid:96)
n
pn
Ï‘
Â¯h
pm(cid:48)
xn,m,g
w
T oï¬€,(k)
n,m
T loc,(k)

n

T update,(k)

m

T cons,(k)

Deï¬nition
Number of ESs
Number of sub-channels
MDâ€™s CPU workload
MDsâ€™ transmit power
MDâ€™s model size
Hash amount of a block
ESâ€™s transmit power
MDâ€™s ofï¬‚oading decision
ML model parameter
MDâ€™s ofï¬‚oading latency
MDâ€™s local data process-
ing latency
ESâ€™s model updating la-
tency
Total model consensus la-
tency

Notation
N
Dn
fm
bn,g
Î¨n
bm(cid:48)
g
k
xm
T exe,(k)
m
T up,(k)
n,m

T learn,(k)

T mine,(k)

n

Deï¬nition
Number of MDs
MDâ€™s Data size
ESâ€™s CPU workload
MDâ€™s bandwidth
MDâ€™s hash rate
ESâ€™s bandwidth
Wireless channel
Global aggregation round
ESâ€™s gradient
ESâ€™s execution latency
MDâ€™s model uploading la-
tency
Total learning latency

Total mining latency

services for multiple MDs concurrently. We consider N MDs
gathered in the set N , N = |N |, which are connected to
M ESs collected in the set M, M = |M|, in a multi-server
edge computing network. The goal of the system is to train
an ML model, with training proceeding through a series of
global aggregation rounds collected via set K. In each round
k âˆˆ K, each MD n possesses a dataset D(k)
n , which may vary
n = |D(k)
from one round to the next, with size D(k)
n |. Each
dataset D(k)
contains multiple data samples, each consisting
n
of an input feature vector and (e.g., supervised learning) a
label. The MDs employ these datasets for local training in
round k, formalized in Section II-B. The total dataset is given
nâˆˆN D(k)
by the set D(k) = âˆªnâˆˆN D(k)
n .
The interactions between MDs, ESs, and blockchain com-

n with size D(k) = (cid:80)

ponents of our BFL system are summarized as follows:

Fig. 1: Our proposed BFL architecture in multi-server edge
computing.

Edge Server (ESs)Mobile Device (MDs)SGD local trainingMiningğ·!ğ·"ğ·#ğ·$ğ·%â€¦ğ‘¤%ğ‘¤!ğ‘¤"ğ‘¤&â€¦Data offloadingEdge trainingP2P communicationBlockchainBlockchainBSDatasetğ‘¤!ğ‘¤"ğ‘¤#ğ‘¤$Share block to MDs for miningBlockPerform consensus among ESs over !â–½ğ¹!to build final gradient â–½ğ¹!Compute accumulated gradient !â–½ğ¹!from ğ‘¤!and local model ğ‘¤"Compute the global model and add to block: ğ‘¤#=ğ‘¤(#%&)-ğœ‚#%&.â–½ğ¹!!%&(#%&)ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

4

g in round k, and x(k)
n,m,g = 0 otherwise. Each dataset can
be either trained locally at the MD or ofï¬‚oaded to the ES
under a feasible ofï¬‚oading policy X (k) = {x(k)
n,m,g âˆˆ
{0, 1}, âˆ€n âˆˆ N , m âˆˆ M, g âˆˆ G}. In each training round, the
BFL operation consists of four key steps, as depicted in Fig. 1:

n,m,g|x(k)

1) Data Ofï¬‚oading and Processing: Depending on its avail-
able resource, each MD can choose to ofï¬‚oad its data
to one of the nearby ESs for edge learning, or learn the
model locally via local data processing. We assume that
the model learning process begins once the ofï¬‚oading
phase is completed [14]. This assumption is realistic in
practical scenarios, where each MD needs to obtain an
ofï¬‚oading policy on whether it should ofï¬‚oad the data to
an ES or not, before it allows the associated ES to train
its data. For both training cases, MDs and ESs conduct
stochastic gradient descent (SGD) iterations and synchro-
nize their model parameters through block mining. After
model training, a MD uploads its ML model parameters
to its nearby ES via blockchain. Considering an ES, if
it receives data from MDs, it allocates its resources to
conduct ML model training.

2) Partial Model Aggregation and Consensus Update: Each
ES combines its computed ML model with models re-
ceived from its associated MDs to perform a partial
model aggregation. Then, ESs will
join a consensus
update process in which they conduct multiple rounds of
blockchain-enabled peer-to-peer (P2P) communications
to exchange their models. After the consensus update,
an ES will be randomly sampled to work as a leader
and build an unveriï¬ed block that contains the aggregated
model for mining.

3) Block Mining: The leader ES broadcasts the block via the
blockchain to the connected ESs and MDs for mining. In
this work, we are mostly interested in the mining latency
from the usersâ€™ perspective, and thus we analyze the
mining process at the MDs. Given resource constraints
at
the MDs, we develop a resource trading strategy
where MDs can purchase hash power from the edge/cloud
service provider (ESP) (e.g., Amazon cloud services) to
run the mining task [29].

4) Block Generation: After receipt of the unveriï¬ed block,
the MD that is the ï¬rst to successfully verify the block
will append it to the blockchain and receive a reward.
Then, each MD downloads the veriï¬ed block via its
blockchain account [29] that contains the global model,
and uses this for local model synchronization to begin
the next round of model training.

B. Federated Learning Model

Let f (w, i) âˆˆ R denote the loss function of the ML model
(e.g., neural network) associated with data point i, where
w âˆˆ Rd is the parameter vector (e.g., weights on neurons).
In this work, we consider a scenario of full ML training at
MDs, i.e., each MD either keeps its entire data locally or
ofï¬‚oads it completely to an ES. When the MD keeps its data
local, it ofï¬‚oads the entire trained ML model to the ES. We

Fig. 2: A block architecture in our blockchain for global model
sharing, where a global model w(k) is embedded into the
transaction of a block. The transaction is also used to transfer
the local gradient âˆ‡F C,(k)
m of
ESs in the model uploading and model consensus processes,
respectively.

of MDs and edge gradient x(l)

n

â€¢ MDs participate in ML model training in a federated
manner to serve their intelligence applications (e.g.,
object detection). Moreover,
they work as blockchain
nodes to mine blocks containing global models in each
communication round to support BFL model sharing.
â€¢ ESs assist in MD model training by providing computa-
tion resources through the ofï¬‚oading process. They also
coordinate the model aggregation process to build the
global model that is shared with MDs via blockchain.
â€¢ Blockchain allows MDs to securely transmit their com-
puted local model to ESs via blockchain. It also facil-
itates the model consensus process between ESs with
a traceable data ledger. Moreover, blockchain enables
secure global model sharing from ESs to MDs. After the
model aggregation process completes, the global model
is added to the blockchain, where mining is executed
for secure model sharing. Speciï¬cally, an ES will be
randomly sampled to function as a leader node and build
an unveriï¬ed block which contains the global model.
This block is then shared with other ESs and MDs for
mining. Subsequently, each MD downloads the veriï¬ed
block from the blockchain to extract the global model
which is used for the next training round. As illustrated
in Fig. 2, each block includes (i) a header, with a hash and
cryptographic nonce, and (ii) the data part. To construct a
block, an ES generates a transaction using its aggregated
model and hashes it, resulting in an output of a ï¬xed
length. The block is then shared with the MDs for model
training.

We let G, G = |G|, denote the set of available sub-
channels for communication at a BS. We assume that uplink
communications between MDs and ESs follow an OFDMA-
based protocol, where each MD is assigned to a sub-channel
g âˆˆ G to ofï¬‚oad its data in each time slot, and thus each
ES can serve at most G MDs in every ofï¬‚oading period. We
deï¬ne the data ofï¬‚oading policy, which incorporates the uplink
sub-channel scheduling,
n,m,g,
(n âˆˆ N , m âˆˆ M, g âˆˆ G), where x(k)
n,m,g = 1 indicates that
data D(k)
from MD n is ofï¬‚oaded to ES m via sub-channel
n

through a binary variable x(k)

â€¦Previous hashNonceTime stampBlock headerData hashBlock datağ‘¤("#$)TransactionBlock i-1Global model at round (k-1)â€¦Previous hashNonceTime stampBlock headerData hashBlock datağ‘¤(")TransactionBlock iGlobal model at round (k)Previous hashNonceTime stampBlock headerData hashBlock datağ‘¤("&$)TransactionBlock i+1Global model at round (k+1)ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

5

measure the online loss function of each MD n at each global
aggregation round k as

the number of data points) of its cumulative gradient and that
of its associated MDs, as

F (k)

n (w) =

1
D(k)
n

(cid:88)

iâˆˆD(k)

n

f (w, i),

(1)

âˆ‡F A,(k)

m =

(cid:88)

nâˆˆN loc,(k)
m

D(k)
n
D(k)e(k)
n

âˆ‡F C,(k)

n +

D(k)
m
D(k)e(k)
m

âˆ‡F C,(k)

m . (8)

and subsequently deï¬ne the online global loss as

F (k)(w) =

1
D(k)

(cid:88)

nâˆˆN

D(k)

n F (k)

n (w), D(k) =

(cid:88)

nâˆˆN

D(k)

n . (2)

In our BFL system, each ES processes datasets ofï¬‚oaded
from a portion of MDs, and also receives the computed ML
models uploaded from another portion of nearby MDs which
had chosen local processing. We denote N oï¬€,(k)
and N loc,(k)
m
as the sets of MDs engaged in data ofï¬‚oading and model
uploading with ES m, respectively (N oï¬€,(k)
âŠ† N
and N oï¬€,(k)
D(k)
m
n
denote ES mâ€™s dataset received from MDs, with size D(k)
m ,
the loss at ES m is given as

, N loc,(k)
m
m
= âˆ…). Letting D(k)
m = âˆªnâˆˆN oï¬€,(k)

âˆ© N loc,(k)
m

m

m

F (k)

m (w) =

1
D(k)
m

(cid:88)

iâˆˆD(k)
m

f (w, i).

(3)

We now formalize the ML model training procedure at
ESs and MDs. Each model training round k starts with the
broadcast of a global model, w(k), from one of the ESs. During
round k, each ES m performs e(k)
m iterations of SGD over
its local/ofï¬‚oaded dataset, which may vary from one ES to
another, where the evolution of its local model parameters is
given by

w(k),e

m = w(k),eâˆ’1

m

âˆ’

Î·k
B(k)
m

(cid:88)

âˆ‡f (w(k),eâˆ’1
m

, d),

(4)

dâˆˆB(k),e
m

m

where Î·k > 0 is the step-size and e âˆˆ {1, Â· Â· Â· , e(k)
n } is the
= w(k). In (4), B(k),e
index of local iteration with w(k),0
denotes the set of data points sampled at the e-th iteration from
the local dataset of the respective MD to perform mini-batch
SGD. We assume that the mini-batch size B(k)
m |, âˆ€e,
is ï¬xed during each local model training round k for each ES
m. The local model training at each MD n is also similar to
(4), where each MD n performs e(k)
iterations of SGD with
n
local updates as

m = |B(k),e

m

w(k),e = w(k),eâˆ’1

n

âˆ’

Î·k
B(k)
n

(cid:88)

dâˆˆB(k),e
n

âˆ‡fn(w(k),eâˆ’1
n

, d)

(5)

After model training, each ES m computes its cumulative
gradient:

âˆ‡F C,(k)

m = (w(k) âˆ’ w(k),e(k)

m

m

)/Î·k .

Similarly, each MD n also obtains its gradient:

âˆ‡F C,(k)
n

= (w(k) âˆ’ w(k),e(k)

n

n

)/Î·k .

(6)

(7)

Subsequently, the MDs ofï¬‚oad their cumulative gradients
to their associated ES via blockchain. Each ES m âˆˆ M
subsequently acquires its aggregated gradient, which is a
scaled sum (with respect to the number of SGD iterations and

The ESs then engage in P2P communications for cooper-
ative consensus formation among their aggregated gradients.
For this purpose, we assume that they exploit linear distributed
consensus iterations [30], where during training round k, each
ES m âˆˆ M conducts Ï†(k) âˆˆ N consensus rounds of P2P
communications with its neighboring ESs. During each round
l = 0, Â· Â· Â· , Ï†(k) âˆ’ 1 of P2P communications, the evolution of
the local gradient of ES m âˆˆ M can be expressed as:

m = Î»(k)
x(l+1)

m,mx(l)

m +

(cid:88)

m,m(cid:48)x(l)
Î»(k)
m(cid:48),

(9)

m(cid:48)âˆˆ(cid:37)(m)

m
(Ï†(k))
m

m = âˆ‡F A,(k)

is ES mâ€™s initial local aggregated

where x(0)
gradient, and x
denotes the local gradient after the
consensus process concludes. In (9), (cid:37)(m) âŠ† M denotes the
set of ESs in the neighborhood of ES m, and Î»(k)
m,m(cid:48) âˆˆ [0, 1],
m(cid:48) âˆˆ {m} âˆª (cid:37)(m) are the consensus weights employed at m.

(Ï†(k))
m

Let âˆ‡F L,(k)

m = x

denote the ï¬nal local gradient at ES
m after the P2P communication process for training round k
concludes, which can be expressed as

âˆ‡F L,(k)

m =

(cid:88)

âˆ‡F A,(k)
m

+c(k)
m ,

(10)

mâˆˆM
(cid:124)

(cid:123)(cid:122)
(a)

(cid:125)

where term (a) is the perfect average of the local aggregated
gradients and c(k)
m denotes the error of consensus caused by
ï¬nite P2P rounds. The selected ES at aggregation round k,
denoted by mk âˆˆ M, then adds a boosting coefï¬cient to its
local gradient âˆ‡F L,(k)
mk , forming the vector
n e(k)
n
D(k)

âˆ‡F L,(k)
mk

D(k)

(k)
mk

(11)

âˆ‡F

(cid:88)

(cid:88)

=

,

mâˆˆM

nâˆˆN (k)
m

and updates the global model parameter as follows:

w(k+1) = w(k) âˆ’ Î·kâˆ‡F

(k)
mk

.

(12)

w(k+1) is then broadcast across the ESs and MDs via block
mining to begin the next round of local model training. The
training procedure of our BFL scheme is summarized in Algo-
rithm 1. At the beginning of each global communication round,
each MD makes a training decision: edge model
training
at the ESs or local model training, which is an output of
Algorithm 2 (line 5) that will be developed in Section IV. In
the case of edge model training, the MD ofï¬‚oads its data to its
associated ES (line 7); otherwise, the MD trains its data locally
(lines 9-14). After receiving all models from local MDs, each
training (lines 17-21). Once the
ES performs edge model
local training and edge training processes are completed, ESs
collaborate to perform P2P-based consensus on aggregated
gradients to update the global model (lines 23-35). Finally,
the mining is executed, where an ES leader adds the global
model parameter to an unveriï¬ed block and broadcasts it to

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

6

other ESs and MDs. In particular, each MD performs resource
trading to purchase hash power from the ESP to run the Proof-
of-Work-based mining. The conï¬rmed block is then appended
into the blockchain for global model sharing, where each MD
downloads the block for the next round of training (lines 36-
40).

C. Convergence Analysis of ML Model Training

We now study the convergence of our BFL scheme. We
ï¬rst make a few assumptions and deï¬ne some quantities of
interest. To obtain convergence guarantees for the distributed
consensus process, we make the following assumptions on the
consensus weights in (9):

Assumption 1 (Conditions on Consensus Weights [30], [31]).
The consensus matrix Î›(k) = [Î»(k)
m,m(cid:48)]m,m(cid:48)âˆˆM(k) satisï¬es the
following properties: (i) Î»(k)
m,m(cid:48) = 0 if ESs m and m(cid:48) are
not connected, (ii) Î›(k)1 = 1, (iii) Î›(k) = Î›(k),(cid:62), and
â‰¤ Î»(k) < 1, where 1 represents the
(iv) Ï
1sâ€™s vector and Ï(A) deï¬nes Aâ€™s spectral radius.

Î›(k) âˆ’ 11(cid:62)
|M(k)|

(cid:16)

(cid:17)

If Î»(k)

m,m = 1 âˆ’ d|(cid:37)(m)| and Î»(k)

m,m(cid:48) = d, m (cid:54)= m(cid:48), 0 < d <
1/M [30], the conditions in Assumption 1 hold. These weights
can be distributedly obtained at the ESs given a predeï¬ned d.

Deï¬nition 1 (Gradient Divergence). The divergence of local
aggregated gradients across the ESs at global aggregation
round k, denoted by Î(k), is deï¬ned as follows:

(cid:13)
(cid:13)âˆ‡F A,(k)
(cid:13)

m âˆ’ âˆ‡F A,(k)

m(cid:48)

(cid:13)
(cid:13) â‰¤ Î(k), âˆ€m, m(cid:48) âˆˆ M.
(cid:13)

(14)

Assumption 2 (Smoothness of the Loss Functions [32], [33]).
For each MD n that conducts local model training during
aggregation round k, the local loss function F (k)
is Î²-smooth:

n

(cid:107)âˆ‡F (k)

n (w) âˆ’ âˆ‡F (k)

n (w(cid:48))(cid:107)â‰¤ Î²(cid:107)w âˆ’ w(cid:48)(cid:107), âˆ€w, w(cid:48).

(15)

Also, for each ES m that conducts model training, the loss
function F (k)
m is assumed to be Î²-smooth, which veriï¬es that
the global loss function F (k) achieves Î²-smoothness.

m

m = N loc,(k)

Let y âˆˆ N âˆª M denote the index of an arbitrary MD/ES.
Also, let N (k)
âˆª {m} denote a set containing the
devices which conduct local model training and ofï¬‚oad their
cumulative gradients to ES m as well as ES m itself. We
measure the heterogeneity of data across the MDs/ESs via the
following assumption [33]:

Assumption 3 (Bounded Dissimilarity of Local Loss Func-
tions). The ï¬nite constants Î¶1 â‰¥ 1, Î¶2 â‰¥ 0 exist for which the
following inequality deï¬ned on the gradient of the local loss
in (2) and (3) holds for any set of coefï¬cients {ay â‰¥ 0} where
(cid:80)

(cid:80)

mâˆˆM

yâˆˆN (k)
m

ay = 1:

(cid:88)

(cid:88)

ay(cid:107)âˆ‡F (k)

y

(w)(cid:107)2

mâˆˆM

yâˆˆN (k)
m
(cid:13)
(cid:13)
(cid:13)

â‰¤ Î¶1

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

ayâˆ‡F (k)

y

(w)

(cid:13)
2
(cid:13)
(cid:13)

+ Î¶2, âˆ€k.

(17)

As can be seen, Î¶1 = 1 and Î¶2 = 0 in (17) correspond to a
scenario in which the data across the MDs/ESs is completely
homogeneous, and Î¶1 and Î¶2 increase as the heterogeneity
across the datasets increases. We next quantify the hetero-
geneity of data inside each local dataset:

Deï¬nition 2 (Local Data Variability). The local data vari-
ability at each MD/ES y is denoted by Î˜y â‰¥ 0, which âˆ€w, k
satisï¬es
(cid:107)âˆ‡fy(w, d) âˆ’ âˆ‡fy(w, d(cid:48))(cid:107)â‰¤ Î˜y(cid:107)d âˆ’ d(cid:48)(cid:107), âˆ€d, d(cid:48) âˆˆD(k)

n .(18)

We further deï¬ne Î˜ = maxyâˆˆN âˆªM{Î˜y}.

Additionally, we let (Ïƒ(k)
y )2 denote the variance across the
feature vectors of dataset D(k)
at ES/MD y which conducts
local model training. We further quantify the dynamics of local
datasets via their impact on the ML performance [26]:

y

Deï¬nition 3 (Model/Concept Drift). For each MD/ES y, we
calculate the model/concept drift between two FL rounds
k âˆ’ 1 and k, âˆ†(k)
y âˆˆ R, which characterizes the local lossâ€™s
variation induced by data arrival/departure at the MDs and
data collection at the ESs, as follows:

F (k)
y

D(k)
y
D(k)

D(kâˆ’1)
y
D(kâˆ’1)
We next present one of our main results,

(w) â‰¤ âˆ†(k)

F (kâˆ’1)

(w) âˆ’

y

y , âˆ€w.

(19)

the general

convergence behavior of BFL:

let e(k)

avg = (cid:80)

Theorem 1 (Convergence Characteristics). Let N (k), N (k) =
|âˆªmâˆˆMN (k)
m | denote the set of all MDs and ESs en-
gaged in model training during the k-th local model train-
y }, e(k)
max = maxyâˆˆN (k){e(k)
ing round. Also,
avg =
(cid:80)
y e(k)
yâˆˆN (k) e(k)
yâˆˆN (k) D(k)
y /D(k).
avg â‰¤ Ë†e(k)
avg â‰¤ Ë†emax
Assume that emin
avg ,
âˆ€k, where emin
avg are four ï¬nite positive
âˆ†(k)
y . In
constants. Further,
conducting K global aggregation rounds,
the step size
satisï¬es Î·k =
, where Î± is chosen such that Î·k â‰¤
(cid:110) 1
2Î²

y /N (k), and Ë†e(k)
avg â‰¤ e(k)
avg , Ë†emin

avg â‰¤ emax
avg and Ë†emax
let âˆ†(k) = (cid:80)

avg and Ë†emin

yâˆˆN (k)
m
if

avg , emax

, then the

min

(cid:17)(cid:17) ,

mâˆˆN

(cid:80)

(cid:114)

(cid:111)

(cid:113)

(cid:16)

(cid:16)

Î±
Ke(k)
avg
1
e(k)
max

D(k)
yâˆˆN D(k)

y e(k)
y

e(k)
maxâˆ’1

(4Î¶1+1)

2Î² (cid:80)

convergence characteristics of the global loss function under
BFL follow the bound in (13).

Proof. See Appendix A.

The bound in (13) reveals the impact of different de-
vice/network conï¬gurations on the ML model performance.
In particular, the impact of model drift is captured in term
(a). Also, the divergence of the global model caused by bias
of the local models due to the heterogeneity of data across
the MDs/ESs is captured via term (c) which encapsulates Î¶2.
Larger daatset heterogeneity captured via Î¶1 imposes a stricter
condition on the step size Î·k described in the statement of
the theorem as well. Terms (b) and (e) in (13) capture the
impact of local data heterogeneity ({Î˜y}) and mini-batch sizes
({B(k)
y }) on the performance of the model. Finally, term (d)
captures the impact of imperfect local aggregations caused
by ï¬nite P2P rounds (Ï†(k)) and divergence of gradients Î(k),

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

7

1
K

Kâˆ’1
(cid:88)

k=0

(cid:104)
(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)

E

â‰¤

8(cid:112)emax
avg
âˆš
Î±Ë†emin
avg

K

(cid:16)

F (0)(w(0)) âˆ’ F (k)(cid:63) (cid:17)

+

8(cid:112)emax
avg
âˆš
Î±Ë†emin
avg
(cid:124)

K

Kâˆ’1
(cid:88)

k=1

(cid:123)(cid:122)
(a)

âˆ†(k)

(cid:125)

+

80Î²2Î±2
K2emin
avg

Kâˆ’1
(cid:88)

(cid:88)

(cid:88)

k=0

mâˆˆM

yâˆˆN

(k)
m

(cid:16)
e(k)
y âˆ’ 1

(cid:17)

(cid:32)

1 âˆ’

D(k)
y
D(k)

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Kâˆ’1
(cid:88)

k=0

80Î²2Î±2
K2emin
avg
(cid:124)

Î˜2
y

+

(cid:125)

(cid:123)(cid:122)
(c)

(cid:16)
e(k)
max

Î¶2

(cid:17) (cid:16)

e(k)
max âˆ’ 1

(cid:17)

(cid:124)

1
K

(cid:124)

+

Kâˆ’1
(cid:88)

k=0

(cid:123)(cid:122)
(b)

24M (Î»(k))2Ï•(k) (cid:16)

Î(k)(cid:17)2

+

(cid:123)(cid:122)
(d)

(cid:125)

(cid:124)

16Î²Î±Ë†emax
avg
âˆš
(cid:113)

K

K

emin
avg

Kâˆ’1
(cid:88)

(cid:88)

(cid:88)

k=0

mâˆˆM

yâˆˆN

(k)
m

ï£«

ï£¬
ï£­

D(k)
y
(cid:113)

e(k)
y

D(k)
(cid:123)(cid:122)
(e)

ï£¶

2

(cid:32)

ï£·
ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

1
K

Kâˆ’1
(cid:88)

k=0

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)
(cid:104)

E

â‰¤

+

80Î²2Î±2
Kemin
avg

K

8(cid:112)emax
avg
âˆš
Î±Ë†emin
avg
80Î²2Î±2
Kemin
avg

(emax âˆ’ 1) Ï‘ +

Î¶2 (emax) (emax âˆ’ 1) +

(cid:16)

F (0)(w(0)) âˆ’ F (k)(cid:63) (cid:17)

+

8Î¥(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg
16Î²Î±Ë†emax
avg
âˆš
(cid:113)

+

K

emin
avg

Ï‘

24Î¾
âˆš

K

(cid:125)

Î˜2
y

.

(cid:125)

(13)

(16)

where the consensus matrixâ€™s spectral radius across the ESs
(Î»(k) < 1) deï¬ned in Assumption 1 determines the rate under
which the consensus error decays to zero with respect to the
number of P2P rounds Ï†(k).

We derive Theorem 1 to obtain conditions for the online

global gradient under BFL converges:

(cid:18)

1 âˆ’

B(k)
y
D(k)
y

Corollary 1 (Convergence under Proper Choice of Mini-batch
Size and P2P Communication Rounds). Besides conditions
in Theorem 1, we assume that (i) the model/concept drift is
small enough such that âˆ†(k) â‰¤ Î¥
K , âˆ€k, for some positive
constant Î¥, (ii) the choice of mini-batch size B(k)
at each
y
(cid:19) (Ïƒ(k)
y )2
B(k)
y

y â‰¤
Ï‘, âˆ€k, where Ï‘ is a ï¬nite positive constant, and (iii)
e(k)
the
max â‰¤ emax, âˆ€k for some positive constant emax. If
number of P2P communications among the ESs at each
i.e., Ï†(k), satisï¬es Ï•(k) â‰¥
global aggregation round k,
(cid:19)(cid:21)+

MD/ES y ensures a uniï¬ed bound

Î¾
K(Î(k))2

for some positive constant Î¾,

1
2
where Î»(k) is deï¬ned in Assumption 1, the gradient of the
global loss under BFL satisï¬es the upper bound in (16), which
E (cid:2)(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:3) = O
implies 1
, and thus
K
E (cid:2)(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:3) â†’ 0.
limKâ†’âˆ

(cid:80)Kâˆ’1
k=0
(cid:80)Kâˆ’1
k=0

(cid:20)
logÎ»(k)

(cid:16) 1âˆš

Î˜2

m(k)

(cid:18)

(cid:17)

K

âˆš

1
K

Proof. See Appendix B.

III. SYSTEM LATENCY MODEL

In this section, we analyze the latencies of the model
training and block mining processes in detail, and present our
latency optimization problem.

A. Latency of Model Training in BFL

In our BFL system, an MD can ofï¬‚oad its data to the ES
for edge learning or choose to train the ML model locally
in each global aggregation k âˆˆ K. In the case of ofï¬‚oading
(x(k)
n,m,g = 1), the latency for model training consists of data
communication latency and execution latency at the ES. The

Algorithm 1 Proposed BFL algorithm

1: Input: Global communication rounds K, local training round en, âˆ€n âˆˆ
N , edge training round em, âˆ€m âˆˆ M, number of MDs N , number of
ESs M

Determine each training decision xn,m,g via Algorithm 2
if xn,m,g = 1 then

for each MD n âˆˆ N do

Ofï¬‚oad dataset D(k)

2: Initialization: Initialize global model w(0)
3: for each global communication round k âˆˆ K do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:

Perform local model training on local dataset D(k)
for each local training epoch e âˆˆ en do
Update local parameters w(k),e

end for
Compute the cumulative gradient via (7)
Add the gradient
framework deï¬ned in Fig. 2 to transfer to an ES

n to ES m

via (5)

else

n

n

to a transaction based on the blockchain

15:
16:
17:
18:
19:
20:
21:
22:
23:

24:
25:
26:
27:
28:

29:
30:

31:
32:
33:
34:
35:
36:

37:
38:

39:
40:

end if

end for
for each ES m âˆˆ M do

for each edge training epoch e âˆˆ em do
Update local parameters w(k),e

m via (4)

end for
Compute its cumulative gradient via (6)

end for
Each ES m âˆˆ M computes an aggregated gradient: âˆ‡F A,(k)
âˆ‡F C,(k)
m
m
Set x(0)
m = âˆ‡F A,(k)
for each P2P consensus round l âˆˆ Ï†(k) do

and âˆ‡F C,(k)
m

via (8)

m

using

for each ES m âˆˆ M do

for each neighboring ES m(cid:48) âˆˆ (cid:37)(m) of ES m do

Transmit the gradient x(l)
blockchain framework deï¬ned in Fig. 2 to ES m

m(cid:48) via a transaction based on the

end for
ES m downloads the block of all transactions to obtain neigh-
boring ESsâ€™ gradients and computes its gradient x(l+1)
via (9)

m

end for

(Ï†(k))
m

m = x
(k)
mk

end for
Obtain the ï¬nal local gradient at ES m: âˆ‡F L,(k)
Add a boosting coefï¬cient to âˆ‡F L,(k)
m to form âˆ‡F
Update the global model parameter w(k+1) via 12
Add the global model parameter to an unveriï¬ed block B by the ES
leader and broadcast it to other ESs and MDs for mining
Each MD trades hash resource Î¨(k)
n from the ESP to mine the block
The fastest MD propagates the veriï¬ed block to ESs and other MDs
for conï¬rmation
Add the block to the blockchain for global model sharing
Each MD downloads the block to obtain the global model for next
round of training

via (11)

41: end for
42: Output: Final global model w(K)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

8

data communication latency of MD n when ofï¬‚oading its data
D(k)
n

to ES m is given by

ES via blockchain. The latency of this model uploading can
be given as

T oï¬€,(k)
n,m =

x(k)
n,m,g

(cid:88)

gâˆˆG

D(k)
n
R(k)
n,m

, âˆ€n âˆˆ N ,

(20)

T up,(k)
n,m =

ï£­1 âˆ’

ï£«

ï£¶

x(k)
n,m,g

ï£¸

(cid:88)

gâˆˆG

Ï‘
R(k)
n,m

, âˆ€n âˆˆ N , m âˆˆ M, (23)

(cid:17)

,

1 +

gâˆˆG x(k)

n,m,gb(k)

n,g log2

n h(k)
p(k)
n,m,g
(cid:16)
j,m,gp(k)
x(k)
j h(k)
(cid:17)
j h(k)

n,m is

where R(k)
from MD n to ES m, which is given by R(k)
(cid:80)

transmission

rate

the

(in

bits/s)
n,m =
(cid:19)

(cid:18)

j,m,g

n,g|0 < b(k)

Ïƒ2+(cid:80)
jâˆˆN \N oï¬€
m
(cid:16)
j,m,gp(k)
x(k)
jâˆˆN \N oï¬€
m
(N \ N oï¬€
m )

j,m,g
interference (cid:80)
caused
under
by a group of MDs
that are associated
with other ESs on sub-channel g. Here, b(k)
is
the
n,g
bandwidth (in Hz) allocated to channel g under
the
policy B(k) = {b(k)
n,g â‰¤ W, âˆ€n âˆˆ N , g âˆˆ G, k âˆˆ K},
where W is the maximum system bandwidth constraint.
Further, p(k)
n is transmission power (in Watts) of MD n in the
ofï¬‚oading subject to the power constraint Pn under a policy
P (k) = {p(k)
n â‰¤ Pn, n âˆˆ N oï¬€
m , âˆ€m âˆˆ M}, and
h(k)
n,m,g is the gain of wireless channel between the MD m and
ES n on sub-channel g. Accordingly, the energy consumption
for data ofï¬‚oading at aggregation round k at MD n is given
n T oï¬€,(k)
as Eoï¬€(k)
n,m .
After the ofï¬‚oading process, ES m receives a combined
dataset D(k)
m =
|D(k)
m | from MDs engaged in data ofï¬‚oading. Then, the ES
allocates its computational resource to perform the SGD-based
model training. The data processing latency at ES m is thus
given by

m (as deï¬ned in Section II-B) with size D(k)

n |0 < p(k)

n,m = (cid:80)

gâˆˆG x(k)

n,m,gp(k)

T exe,(k)
m

=

x(k)
n,m,g

(cid:88)

gâˆˆG

m e(k)
m

m (cid:37)(k)
CmD(k)
fm

, m âˆˆ M,

(21)

where Cm represents how many CPU cycles is required to
calculate the gradient per data point at ES m, and (cid:37)(k)
m âˆˆ
(0, 1] is the mini-batch size ratio, from which the size of SGD
mini-batches can be written as B(k)
m . Moreover,
e(k)
m is the number of SGD iterations, and fm is the ï¬xed
computational capability of ES m (in CPU cycles/s).

m = (cid:37)(k)

m D(k)

On the other hand, each MD n can also choose to locally
process its data, implying x(k)
n,m,g = 0, âˆ€m, g. We denote f (cid:96),(k)
as the computational capability of MD n (in CPU cycles/s)
allocated to train the data given maximum capacity Fn, which
is represented via a policy: F (k) = {f (cid:96),(k)
â‰¤
n
Fn, âˆ€n âˆˆ N }. The latency of model training over e(k)
n SGD
iterations at MD n is given by

|0 < f (cid:96),(k)

n

n

ï£«

T loc,(k)
n

=

ï£­1 âˆ’

ï£¶

x(k)
n,m,g

ï£¸

(cid:88)

gâˆˆG

CnD(k)

n e(k)
n

n (cid:37)(k)
f (cid:96),(k)
n

,

(22)

where (cid:37)(k)
n âˆˆ (0, 1] is the SGD mini-batch ratio, and Cn is the
number of CPU cycles required to compute the gradient per
data point at MD n. Also, the local energy consumption of MD
1 âˆ’ (cid:80)
n is given by Eloc,(k)
)2Cn,
where Îº is the energy coefï¬cient depending on the chip
architecture. After completing the local model training, MD n
then transmits the computed model âˆ‡F A,(k)
to its associated

gâˆˆG x(k)

Îº(f (cid:96),(k)
n

n,m,g

=

(cid:16)

(cid:17)

n

n

where Ï‘ is the gradient/model size (in bits) that is the same
across the MDs. Based on above formulations, the total latency
of model training of the BFL system at each global aggregation
k is

T learn,(k) =

(cid:88)

(cid:88)

T oï¬€,(k)
n,m +

(cid:88)

T exe,(k)
m

nâˆˆN
(cid:88)

mâˆˆM
T loc,(k)
n

+

+

(cid:88)

mâˆˆM
(cid:88)

T up,(k)
n,m , âˆ€k âˆˆ K.

(24)

nâˆˆN

nâˆˆN

mâˆˆM

After the model training process, the ESs in the edge layer
perform the P2P-based consensus on the computed model.
An ES performs the model updating where the neighbours
exchange their aggregated gradients deï¬ned in (8) via P2P
communications. The latency of parameter updating at ES m
in each P2P communication round l is determined by

T update,(k)
m

(l) = max

m(cid:48)âˆˆÎ(m)

Ï‘
R(k)
m,m(cid:48)(l)

,

(25)

m,m(cid:48)(l) is the transmission rate from ES m(cid:48)

where R(k)
to
ES m via wired communications. Thus the updating latency
of each ES m over Ï• consensus rounds is T cons,(k)
=
(cid:80)Ï•
(l). Finally, the latency of the model consen-

l=1 T update,(k)

m

m

sus is determined by the slowest ES as below:

T cons,(k) = max
mâˆˆM

T cons,(k)
m

= max
mâˆˆM

(cid:35)

T update,(k)
m

(l)

. (26)

(cid:34) Ï•
(cid:88)

l=1

B. Latency of Block Mining in BFL

After model consensus among ESs, an ES will be selected
to work as a leader that builds an unveriï¬ed block B and
broadcasts it to all connected ESs and participating MDs for
universal block mining. This selection can be based on the
ESsâ€™ reputation in the previous aggregation round from the
P2P collaboration process, where the reputation evaluation
methodology can be used to quantify each ESâ€™s contribution
to block generation [34]. Inspired by our previous work [35],
we adopt mining latency as the reputation metric: an ES which
generates the fastest block in the previous mining round will
have the highest reputation and is selected as the leader for
mining coordination in the current mining round.

After leader selection,

the mining process is executed.
Similar to existing works [8], [9], we focus on mobile mining
analysis, where the mining latency at MDs is considered, and
thus the mining analysis at ESs is ignored. We adopt the
popular Proof-of-Work mining mechanism [6], [7] for our
BFL, where MDs compete to mine the block. The adoption of
other mining mechanisms in BFL will be considered in future
works. Conceptually, the mining latency at each MD n mainly
consists of block generation latency and block propagation

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

latency [24]. Due to resource constraints, we allow MDs to
implement resource trading to buy hash power from the ESP to
assist their mining. Accordingly, MDs compete with each other
to gain the maximum hash power allocation from the ESPâ€™s
hash resource pool, aiming to increase the probability of be-
coming the mining winner for gaining rewards. In every global
aggregation round k, each MD n speciï¬es its mining demand
to trade hash resource, denoted as Î¨(k)
n (Hash/sec) subject to
the constraint of the total hash power of the BFL system Î¨max
under a policy Î¨(k) = {Î¨(k)
n â‰¤ Î¨max, âˆ€n âˆˆ N }.
Let Â¯h(k) denote the hash amount (in hash) required to mine
the block B (which also represents the size) in aggregation
round k, the block generation latency at MD n can be speciï¬ed
as T gen,(k)
. Thus, the energy consumption for block
n
generation at MD n can be given as Egen,(k)
= ÎnÂ¯h(k), where
În is the power efï¬ciency of the mining rig of MD n (J/hash).

n |0 < Î¨(k)

= Â¯h(k)
Î¨(k)
n

n

After generating a block, MD n will propagate it
to
ESs and other MDs for conï¬rmation. The latency of this
block propagation process can be determined as T prop,(k)
=
Î¾(B|LM +N âˆ’1|)(k), where Î¾ is a parameter to quantify the ef-
ï¬ciency of block veriï¬cation. Further, B|LM +N âˆ’1| represents
the average delay of the repeated veriï¬cation on the block B
of all entities except MD n [35]. Therefore, the mining latency
at an MD can be given as T mine,(k)

+ T prop,(k)
n

= T gen,(k)
n

n

n

.

However, in the block mining process, there is the pos-
sibility that a MU n generates the block and propagates
it slower than other miners which will discard this block
from blockchain. This issue is called forking and such a
block is called an orphaned one. The forking probability can
be determined as Pfork = 1 âˆ’ eâˆ’Î¹Ï†(sn), where Î¹ is set to
Î¹ = 1/600(sec) [29]. Moreover, sn represents how many
transactions are included in the block mined by MD n, and
Ï†(sn) is a function of block size. Therefore, the mining latency
at MD n can be rewritten as

T mine,(k)
n

= Î¶(T gen,(k)
n

+ T prop,(k)
n

), âˆ€k âˆˆ K,

(27)

where Î¶ is the number of forking occurrences in each global
training round. Therefore, the total mining latency of BFL
system can be given as T mine,(k) = (cid:80)

nâˆˆN T mine,(k)

n

.

C. Formulation of System Latency Problem

Our objective is to optimize the total latency of the BFL
system from the user perspective as the sum of model training
latency, model consensus latency and block mining latency at
a certain aggregation round k:

minimize
X,P ,B,F ,Î¨

1
K

Kâˆ’1
(cid:88)

k=0

(cid:16)

T learn,(k) + T cons,(k) + T mine,(k)(cid:17)

(28a)

s.t.

x(k)
n,m,g âˆˆ {0, 1}, âˆ€n âˆˆ N , m âˆˆ M, g âˆˆ G,
(cid:88)
x(k)
n,m,g â‰¤ 1, n âˆˆ N ,

(cid:88)

gâˆˆG
mâˆˆM
0 < p(k)
n â‰¤ Pn, âˆ€n âˆˆ Nn,
0 < b(k)
n,g â‰¤ W, âˆ€n âˆˆ N , g âˆˆ G,
0 < f (cid:96),(k)
â‰¤ Fn, âˆ€n âˆˆ N ,
n

(28b)

(28c)

(28d)

(28e)

(28f)

9

(28g)

, âˆ€n âˆˆ Nn, (28h)

0 < Î¨(k)
0 < Elearn,(k)
n
Kâˆ’1
(cid:88)

n â‰¤ H, âˆ€n âˆˆ Nn,
+ Egen,(k)
n
(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)
(cid:104)

E

1
K

â‰¤ Emax,(k)
n

â‰¤ (cid:15),

(28i)

k=0
Elearn,(k)
(cid:17)

(cid:80)

n

+

n,m

the

n,m,g

gâˆˆG x(k)

=
Eloc,(k)
n

gâˆˆG x(k)
n,m,gEoï¬€,(k)
where
(cid:16)
1 âˆ’ (cid:80)
energy consumption
is
for model training. Here, constraints (28b) and (28c) imply
that each dataset can be either trained locally or ofï¬‚oaded
to at most one ES via a sub-channel. (28d) ensures the
transmit power constraint of each MD. Constraint
(28e)
guarantees that each MD n is allocated a feasible bandwidth
resource for data ofï¬‚oading. The MD also allocates a positive
computational resource to train its ML model with respect
to the maximum CPU capability Fn, as indicated in (28f).
Constraint (28g) guarantees that
the hash power allocated
to each MD is limited by the total system hash resource.
Further, constraint (28h) implies that the energy consumption
of MD n for model training and blockchain mining is limited
by its battery energy level. Finally, the global loss function
should be less than a desirable value (cid:15) to ensure the required
training quality, as indicated in constraint (28i).

The optimization problem in (28) is non-convex with respect
to the mixed discrete ofï¬‚oading and continuous allocation
variables. Due to the time-varying nature of system states,
such as channel condition and computational availability, it
is challenging to directly solve the formulated problem via
conventional optimization approaches such as Lyapunov opti-
mization [24]. Therefore, we will propose to use a learning-
based approach, where a new DRL algorithm is developed to
well capture the dynamics of system and integrate them into
the solution design.

IV. DRL DESIGN WITH PARAMETERIZED A2C FOR BFL
Different from the existing DRL algorithms which consider
either purely discrete [22], [36], [27] or purely continuous
actions [12], [37], [28], we here study a more practical DRL
setting with a hybrid discrete-continuous action for improving
the training performance. Even though such a hybrid action
setting has been previously mentioned in a few related works
such as [38], a holistic investigation on the sampling of
discrete and continuous actions has not been given. Therefore,
we propose a parameterized advantage actor critic (A2C) algo-
rithm to optimize the system latency, as illustrated in Fig. 3.
We consider a hybrid discrete and continuous action space,
where the resource allocation variables in (28) are continuous,
while the ofï¬‚oading decision variables are discrete. The actor
is designed to train both ofï¬‚oading and resource allocation
policies, which we demonstrate in Section IV-C. The critic is
then designed to evaluate the efï¬ciency of the actor policy
training, which we present in Section IV-D. We also include
the advantage function in the critic design as it has been shown
to reduce the variance in actor policy training compared with
conventional actor-critic approaches [28], [39]. Finally, we
develop a training procedure to optimize the long-term system
utility of our developed A2C algorithm (Section IV-E), which
corresponds to minimizing the long-term BFL system latency.

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

10

Fig. 3: The proposed parameterized A2C architecture for our BFL environment.

A. DRL Formulation

We consider a single-agent DRL problem setting [12],
[28], where a virtual centralized agent
interacts with the
BFL environment induced by the interaction between MDs
and ESs during model training and block mining. Our DRL
scheme aims to optimize the total system latency in (28a)
consisting of model training latency, consensus latency and
block mining latency. To handle the formulated optimization
problem, we build a centralized agent which deï¬nes its reward
based on the total utility, and restricts its action space based
on the resource allocation and learning constraints in (28).
With a comprehensive view of the model training and block
mining processes, the agent can obtain the system state and
employ it to take efï¬cient actions via well-trained data of-
ï¬‚oading and resource allocation policies that are observed to
minimize the system latency. We consider a parameterized
Markov Decision process characterized by M =< S, A, r >.
Here, S = {s1, ..., sN } and A = {a1..., aN } are the ï¬nite
sets of state and parameterized action, respectively. Further,
r(s, a) : S Ã— A â†’ [âˆ’Ro, Ro], (Ro âˆˆ R>0) denotes the
bounded system reward. We also denote P (s(cid:48)|s, a) as the
probability of transition executed by action a of the agent
from s to s(cid:48).

In our BFL latency optimization problem, the ofï¬‚oading
decisions for ML model training at MDs are closely associated
with resource allocation variables. For instance, to ofï¬‚oad the
data to an ES, an MD needs to tune its transmit power and
determine channel availability; or to execute data locally, it
should determine its computational utilization. We consider a
parameterized action space: a ï¬nite set of discrete ofï¬‚oading
action a âˆˆ Aa = {a1, a2, ..., an} deï¬ned via a discrete-
action policy Ï€d(a|s) and each an has a set of continuous
parameters {c âˆˆ Ac} deï¬ned via an action-parameter policy
Ï€c(c|s, x). Thus,
the joint action is given by conditional
probability (a, c) âˆ¼ Ï€Î¸(a, c|s) = Ï€d
(c|s, a), where
Î¸d
Î¸ is the parameter of the overall action policy, and Î¸d and
Î¸c are parameters of discrete action policy and parameter
policy, respectively, with Î¸ = [Î¸d, Î¸c]. To simplify the notation,
Ï€Î¸(a, c|s) is expressed by Ï€Î¸(a, s) in the rest of the paper.

(a|s)Ï€c
Î¸c

At each time step t, the agent at state st takes an action

at to transition to the next state st+1 and observe a reward
rt+1 â† r(st, at, st+1). As a result, the training data for DRL
is produced in a form of trajectory where each data point on
the trajectory can be represented by tuple {st, at, rt, st+1}.
Given a policy Ï€, the long-term discounted system reward is
characterized by the state-value function V Ï€Î¸ (s) : A â†’ R
and the action-value function QÏ€Î¸ (s, a) : S Ã— A â†’ R, which
are V Ï€Î¸ (s) = EÏ€Î¸ [(cid:80)âˆ
t=0 Î³trt+1|st = s] and QÏ€Î¸ (s, a) =
EÏ€Î¸ [(cid:80)âˆ
t=0 Î³trt+1|st = s, at = a], where Î³t âˆˆ [0, 1] is the dis-
count value and EÏ€Î¸ [.] represents expectation of the executed
reward function under policy Ï€. By using the Bellman optimal-
ity equation, the Q-value associated with a state-action pair can
also be expressed by QÏ€Î¸ (st, at) = EÏ€Î¸ [rt+1 + Î³V Ï€Î¸ (st+1)].
In this paper, we focus on the A2C model
that can be
characterized by the advantage function AÏ€Î¸ (s, a)

AÏ€Î¸ (st, at) = QÏ€Î¸ (st, at) âˆ’ V Ï€Î¸ (st)

= rt+1 + Î³V Ï€Î¸ (st+1) âˆ’ V Ï€Î¸ (st), âˆ€s âˆˆ S, a âˆˆ A.

(29)

It is worth noting that the proposed A2C algorithm training
is performed in a certain FL aggregation round k to allow
the agent to obtain an optimal latency-aware ofï¬‚oading and
allocation strategy for MDs. Based on the well trained A2C
model, we then deploy it into the BFL environment to guide
the FL training across aggregation rounds. Therefore, the index
k is dropped for the simplicity of notations in our DRL
formulation. In the following, we deï¬ne state, action and
reward for our DRL algorithm.

1) State:

In our BFL environment,

the system state
consists of ï¬ve components: data state Sdata(t), channel
state Schannel(t), bandwidth state Sband(t), computation state
Scomp(t), and hash power state Shash(t). Therefore, the system
state is deï¬ned as:

s(t) = {Sdata(t), Schannel(t), Sband(t), Scomp(t), Shash(t)}.

(30)
Here, Sdata(t) is deï¬ned as Sdata(t) = {Dn(t)}nâˆˆN . Fur-
ther, Schannel(t) = {qn,g(t)}nâˆˆN ,gâˆˆG indicates whether the
sub-channel g is used by MD n at
time slot t. If yes,
qn,g(t) = 1, otherwise qn,g(t) = 0. The bandwidth state
Sband(t) can be given Sband(t) = {bn,g(t)}nâˆˆN ,gâˆˆG under

BFL Environment =ğ’“ğ’•+ Î³V(ğ’”ğ’•"ğŸ) -V(ğ’”ğ’•)  Critic updateCriticActorğ‘ $ğ‘Ÿ%ğ‘ $,ğ‘ $ğœ‹%(x|s)ğœ‹&(c|s,x)ğ…(x,c|s)=     *Action samplingV(s)Action samplingğ‘%Discrete offloading action policyContinuous allocation parameter policyE(Ï‰) = ğŸğŸ||V(Ï‰)âˆ’Î›B.V(Ï‰)||ğŸMSPBE LossGradient descent-based minimizationPolicy objective =    *Trust region optimizationSurrogate objectiveActor updateAdvantageBacktracking line searchTransformxAction-parameter policyACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

11

the total radio system bandwidth W . The computation state
Scomp(t) contains the information of current computational
resource Scomp(t) = {f (cid:96)
n(t)}nâˆˆN . Lastly, the hash power
state Shash(t) presents the current hash power Î¨n of all MDs:
Shash(t) = {Î¨1(t), Î¨2(t), ..., Î¨N (t)}.

2) Action: Our BFL system features a parameterized action
space with ofï¬‚oading or local execution, as elaborated below:

â€¢ Ofï¬‚oading (transmit power, channel bandwidth allo-
cation, hash power allocation): When MD n chooses
the ofï¬‚oading mode xn,m,g = 1,
it must determine
relevant parameters, i.e., transmit power pn and channel
bandwidth bn,g that are needed for ofï¬‚oading. Also,
MDs perform mining regardless of their learning sta-
tus, and thus we also involve a hash power allocation
parameter Î¨n. Therefore, the joint action on each MD
can be expressed by an = {xn,m,g, pn, bn,g, Î¨n} and
the complete system action in this mode is a(t) =
xn,m,g(t), pn(t), bn,g(t), Î¨n(t), âˆ€n âˆˆ N , m âˆˆ M, g âˆˆ
G.

â€¢ Local Execution (computational allocation, hash power
allocation): When MD n chooses the local execution
mode xn,m,g = 0,
it must specify its necessary pa-
rameters to execute the model training, e.g., f (cid:96)
n. More-
over, similar
the parameter
to the ofï¬‚oading mode,
of hash power allocation is also involved to support
the block mining task executed after the model learn-
ing. Therefore, the joint action on each MD is an =
{xn,m,g, f (cid:96)
n, Î¨n} and the complete action for the BFL
system in this local execution mode is given by a(t) =
xn,m,g(t), f (cid:96)

n(t), Î¨n(t), âˆ€n âˆˆ N , m âˆˆ M, g âˆˆ G.

3) System Reward Function: The reward in our BFL system
comes from the joint model learning and block mining, by
maximizing the system returns in the long run. However,
in the optimization problem (28), our objective is to min-
imize the system latency in a certain aggregation round,
which requires a negative multiplication before being used
i.e., we deï¬ne the reward as r(st, at) =
as the reward,
âˆ’ (cid:0)T learn + T cons + T mine(cid:1). For better presentation, we trans-
form the latency minimization problem into a system utility
optimization problem by using a simple exponential equation:

(cid:32)

ï£®

U =

ï£°e

(T learn+T cons+T mine)
Ï„

1âˆ’

(cid:33)

ï£¹

âˆ’ 1

ï£» ,

(31)

where Ï„ denotes an upper bound of the system latency. (31)
implies that
the lower system latency results in a higher
system utility. Therefore, instead of minimizing the latency,
we are keen on maximining the system utility which better
characterizes the efï¬ciency of our algorithm. Accordingly, we
transform (28) to the following optimization problem:

maximize
X,P ,B,F ,Î¨
s.t.

U

28b âˆ’ 28i.

(32a)

(32b)

B. Policy Gradient Update for A2C

We ï¬rst analyze the policy gradient update necessary for the
design of actor and critic components that will be elaborated
later. In the BFL environment, the agent tries to search among
the set of parameterized ofï¬‚oading policies to obtain the
optimal policy Ï€âˆ—
Î¸ (a, s) that can return the maximum reward,
i.e., system utility. However, in practice the search space may
be very large and the agent may not be able to ï¬nd the optimal
policy. Thus, we restrict the policy set by a vector Î¸ âˆˆ Rz for
some integer z > 0 and perform the optimization over the
group of the parameterized policies Ï€Î¸(a, s). To facilitate our
analysis, the following assumptions are introduced.

Assumption 4. The policy Ï€Î¸ and P(s(cid:48)|s, a) guarantee an ir-
reducible and aperiodic Markov chain described by P Ï€Î¸ (s(cid:48)|s),
âˆ€Î¸. Therefore, there exists a stationary distribution deï¬ned as
dÏ€Î¸ (s) on policy Î¸.

Assumption 4 is a common assumption for actor-critic
algorithms [28], [39]. Accordingly, we deï¬ne J(Ï€Î¸) = r(Ï€Î¸),
where r is the system reward deï¬ned in Section IV-A3, as the
performance function with respect to the policy parameterized
by Î¸. Accordingly, the objective function with linear Q-value
function approximation is given by

J(Ï€Î¸) =

(cid:88)

sâˆˆS

dÏ€Î¸ (s)QÏ€Î¸ (s, a).

(33)

Next, similar to [39], we make an assumption on the policy
Ï€Î¸(a, s).

Assumption 5. The following assumptions are made on the
policy function:

â€¢ Positive policy function: Ï€Î¸(a|s) > 0, âˆ€Î¸ âˆˆ Rd
â€¢ Bounded policy gradient:

||âˆ‡ log Ï€Î¸(a|s)||2< GÏ€, âˆ€Î¸, âˆ€s, âˆ€a, GÏ€ > 0

â€¢ (cid:96)-Lipschitz policy gradient:

||âˆ‡ log Ï€Î¸1 âˆ’ âˆ‡ log Ï€Î¸2||2â‰¤ (cid:96)||Î¸1 âˆ’ Î¸2||2, âˆ€Î¸1, âˆ€Î¸2

Here, the regularity conditions in Assumption 5 can be
satisï¬ed by using the Gibbs softmax distribution network, e.g.,
in deep neutral networks, for action selection in the actor.
Under this assumption, the policy gradient Ï€Î¸ can be updated
as âˆ‡J(Ï€Î¸) = Esâˆ¼dÏ€Î¸ (.),aâˆ¼Ï€Î¸(.|s) [QÏ€Î¸ (s, a)âˆ‡ log Ï€Î¸(a|s)].

C. Actor Design

In our A2C-based DRL algorithm, the actor aims to update
the parameter Î¸ over time-step iterations to ï¬nd the optimal
policy Ï€âˆ—
Î¸ that characterizes the best trajectory for our system
utility optimization problem. In other words,
the actor is
expected to make optimal model learning and block mining
decisions in a fashion that the long-term reward (i.e., system
utility) is maximized. In doing so, the actor needs to use the
gradient âˆ‡J(Ï€Î¸) to optimize its policy

J(Ï€Î¸) = Esâˆ¼dÏ€Î¸ (.) [Ï€Î¸(a|s)AÏ€Î¸ (s, a)] ,

(34)

max
Î¸âˆˆRd

Thus, we re-deï¬ne the system reward as a result of executing
the action with given states as r(st, at) = U (t).

the policy is optimized via a vanilla policy
Traditionally,
gradient algorithm by direct policy search over the entire

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

12

exploration space which is known to be inefï¬cient. Instead,
we use trust region policy optimization (TRPO) to improve
policy optimization by maximizing a surrogate objective over
a trust-region [40]. Accordingly, (34) can be re-written

max
Î¸âˆˆRd

J(Ï€Î¸) = EÏ€Î¸

(cid:20) Ï€Î¸new (a|s)
Ï€Î¸(a|s)

AÏ€Î¸ (s, a)

(cid:21)

,

(35)

subject to Es [KL (Ï€Î¸(.|s)||Ï€Î¸new (.|s))] â‰¤ (cid:15)KL,

for some (cid:15)KL > 0. In (35), Es represents the state visitation
distribution induced by Ï€Î¸, and Î¸ and Î¸new are the vectors of
policy parameters before and after each update, respectively.
By enforcing a Kullback-Leibler (KL)-divergence constraint
KL, the probability distributions of the policy before and
after the update will be kept closely in the parameter space
to avoid divergence in the gradient update. Considering our
parameterized action space including the ofï¬‚oading actions
and their parameters, the optimization objective function can
(a|s)Ï€c
Î¸new
be expressed as EÏ€Î¸
c
(a|s)Ï€c
Î¸c
To solve (35), we construct a closed form solution for
computing the KL-divergence between the distributions of
the discrete ofï¬‚oading action policy and the action-parameter
policy for our BFL problem as follows:

(c|s,a) AÏ€Î¸(cid:48) (s, a)

(cid:20) Ï€d
Î¸new
d
Ï€d
Î¸d

(c|s,a)

(cid:21)
.

Es[KL(Ï€Î¸(a,c|s)||Ï€Î¸new (a,c|s))]
(cid:17)

(cid:16)

(cid:104)

=Es

KL

=Es

(cid:104)

KL

(cid:16)

Ï€d
Î¸new
d
Ï€d
Î¸new
d
EsE

(a|s)||Ï€d
Î¸d

(a|s)

+KL

(cid:16)

Ï€c
Î¸new
c

(c|s,a)||Ï€c
Î¸c

(cid:17)(cid:105)

(c|s,a)

(a|s)||Ï€d
Î¸d

(a|s)

(cid:17)(cid:105)

+

aâˆ¼Ï€d
Î¸new
d

(a|s)

(cid:104)

KL

(cid:16)

Ï€c
Î¸new
c

(c|s,a)||Ï€c
Î¸c

(c|s,a)

(cid:17)(cid:105)
.

(36)

By using the analytical form of the discrete ofï¬‚oading action
policy Ï€d
d (a|s) via its trajectory probability, we can further
Î¸new
reduce the variance of the KL-divergence in the last term
of (36) as

Es[KL(Ï€Î¸(a,c|s)||Ï€Î¸new (a,c|s))]â‰ˆEs
(cid:16)

(cid:104)(cid:16)

(cid:17)

+Es

âˆ’ log(Ï€d
Î¸new
d

(a|s))

KL

Ï€c
Î¸new
c

(a|s)||Ï€d
Î¸d

Ï€d
Î¸new
d
(c|s,a)||Ï€c
Î¸c

(cid:104)

KL

(cid:16)

(cid:17)(cid:105)

(a|s)

(c|s,a)

(cid:17)(cid:105)
.

(37)

Based on the above approximation steps, the optimization of
the original policy in (34) is transformed into a conjugate gra-
dient form which allows for estimating the expectations of the
policy objective in (35) with policy improvement guarantees.
In this regard, the update direction can be approximated by
Î½ â‰ˆ Ë†H âˆ’1âˆ‡Î¸J(Ï€Î¸), where Ë†H âˆ’1 is the Hessian-vector product
of sampled KL-divergence. Finally, the actor parameter is
updated via backtracking line search [41] subject to the KL
constraint as follows:

Î¸t+1 = Î¸t + Î³a
t

(cid:114) 2(cid:15)KL
Î½(cid:62) Ë†HÎ½

Î½,

(38)

where Î³a
t âˆˆ (0, 1) is the backtracking step-size parameter
which controls the line search for guaranteeing the conjugate
gradient improvement given the KL divergence constraint. It
is desirable to set up a fairly large step size Î³a
t to initialize the
line search space on the policy, and gradually shrink Î³a
t until
a Armijo-Goldstein condition [41] is satisï¬ed where a critical
(optimal) point is obtained.

D. Critic Design

The role of the critic is to estimate the state-value function
V Ï€Î¸ (s) to guide the update of the actor by approximating its
state-value function. Speciï¬cally, a feature function Ï† : S (cid:55)â†’
Rn is created as a full-ranked matrix with I dimensions to
create i-dimensional features (i â‰¤ I) for any state s âˆˆ S, i.e.,
Ï†(s) = (cid:0)Ï†1(s), ..., Ï†i(s)(cid:1)(cid:62)
. Given a state s, the state-value
function is thus approximated by a linear function VÏ‰(s) â‰ˆ
Ï‰Ï†(s)(cid:62), where Ï‰ âˆˆ Rm is a parameter vector used to update
the state-value function. By function approximation, the critic
provides an inexact temporal difference (TD) solution to the
value function V Ï€Î¸ (s) under policy Ï€Î¸. This naturally results
in the minimization of TD error as a loss function, i.e., the
Mean Squared Projected Bellman Error (MSPBE) deï¬ned by

EÎ¸(Ï‰) =

1
2

||VÏ‰ âˆ’ Î›BÎ¸VÏ‰||2,

(39)

where Î› = Ï†(cid:62)(Ï†M Ï†(cid:62))âˆ’1Ï†H is the projector with H âˆˆ
R|S|Ã—|S| being a diagonal matrix whose elements are within
the stationary state distribution dÏ€Î¸ generated according to the
policy Ï€Î¸ when the entire state space is irreducible. Also,
BÎ¸ denotes the Bellman operator implied by BÎ¸V (s) â†
r(s, a) + Î³P Î¸(s, s(cid:48), a)V (s), where V (s) is the state value,
r(s, a) is reward with discount Î³ âˆˆ (0, 1), and P Î¸(s, s(cid:48), a) is
the transition probability as deï¬ned in IV-A. During the value
function evaluation process, the critic aims to minimize the
loss function in (39) to obtain a ï¬xed point of the projected
Bellman operator by gradient TD learning, where the Lipschitz
continuity property of the MSPBE loss function in (39) is
signiï¬cant to guarantee a successful policy-parameter update.
Note that the loss function in is quadratic and thus convex
with respect to Î¸.

1. Given

Lemma
(cid:0)Ï†1(s), ..., Ï†i(s)(cid:1)(cid:62)
with (cid:96) = (1 + Î³)2 maxi||Ï†i||2

feature
the EÎ¸(Ï‰)â€™s gradient
2, where i âˆˆ I.

the

,

vector Ï†(s)

=
is (cid:96)-Lipschitz

Proof. See Appendix C.

Based on the stochastic gradient descent on EÎ¸(Ï‰) with
respect to parameter Ï‰, the critic update can be achieved by

Ï‰t+1 = Ï‰t + Î³c

t AÏ€Î¸ (st, at)âˆ‡Ï‰VÏ‰(st),

(40)

where Î³c

t âˆˆ (0, 1) is a step-size parameter.

E. Training Procedure of Parametrized A2C Algorithm in BFL

The training procedure of our A2C algorithm is summarized
in Algorithm 2. To prepare for the training, we build a BFL
environment where multiple MDs participate in the FL training
and block mining with a set of ESs connected via wireless
links. The objective function in the system utility optimization
problem built in (32) is selected as a system DRL reward that
is obtained via iterative training with parameterized actions
and system states for an optimal ofï¬‚oading policy Ï€âˆ—
Î¸ to
maximize the reward R in the long run with a initial system
state (line 5). We build an actor that consists of a deep neural
network (DNN) for ofï¬‚oading decision sampling and another
DNN for parameter sampling. At each timestep, we randomly
sample a set of discrete ofï¬‚oading actions for all MDs via

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

13

Algorithm 2 Training procedure of our A2C algorithm
1: Input: Time budget T , discount factor Î³, BFL environment env
2: Output: Optimal parameterized action policy Ï€âˆ—

Î¸ and maximum reward

R

3: Initialization: Initialize ofï¬‚oading policy parameters Î¸d, parameterized
allocation policy parameter Î¸c, critic parameter Ï‰, actorâ€™s learning rate
Î³a, criticâ€™s learning rate Î³c, discount parameter Î³, initial reward R = 0

Set up initial state s0
for timestep t = 1, 2, ..., T do

4: for each episode do
5:
6:
7:
8:
9:

Perform action sampling using Ï€d(.|s) and Ï€c(.|s)
for each MD n âˆˆ N do

Sample the discrete ofï¬‚oading action with policy xn âˆ¼
Ï€d
nÎ¸d (.|s)
Sample continuous allocation parameters for the selected of-
ï¬‚oading action xn
(cid:40)

(pn, bn,g, Î¨n) âˆ¼ Ï€c
Î¸c
(f (cid:96)
(.|s, xn),

n, Î¨n) âˆ¼ Ï€c
Î¸c

(.|s, xn),

if xn,m,g = 1
if xn,m,g = 0

cn =

end for
Execute the parameterized action at â† (xn,m,g,t, cn,t), âˆ€n âˆˆ N
in the BFL environment
Obtain reward rt and next state st+1: (rt, st+1) â† env.step(at)

for

the policy gradient

Calculate the accumulated reward Rt+1 â† rt + Î³t âˆ— Rt
Compute the advantage function AÏ€Î¸ (s, a) using (29) based on rt
and V Ï€Î¸ (s)
Estimate
Esâˆ¼dÏ€Î¸ (.),aâˆ¼Ï€Î¸ (.|s) [AÏ€Î¸ (s, a)âˆ‡Ï€ log Ï€Î¸(a|s)]
Optimize the actor policy via TRPO in (35) with computed ad-
vantage value and update its parameter with KL constraint in (38):
(cid:113) 2(cid:15)KL
Î¸t+1 = Î¸t + Î³a
t
Î½(cid:62) Ë†HÎ½
Calculate the MSPBE loss for critic via (39)
Optimize VÏ‰ for the critic and update its policy in (40) via TD
error Ïƒt: Ï‰t+1 = Ï‰t + Î³c

t AÏ€Î¸ (st, at).âˆ‡Ï‰VÏ‰(st)

actor: âˆ‡J(Ï€Î¸) =

the

Î½

10:

11:
12:

13:

14:
15:

16:

17:

18:
19:

end for

20:
21: end for

a DNN-empowered policy Ï€d(.|s). Then we also sample a
set of continuous allocation parameters based on the sampled
ofï¬‚oading decision using another policy Ï€c
(.|s, xn) as deï¬ned
Î¸c
in IV-A (lines 7-11). With the result of the action sampling
step, we generate a complete set of parameterized actions for
all MDs which is ready to be executed in the BFL environment
(line 12). This allows us to obtain the reward, i.e., system
utility, to calculate the long-term return and the agent moves
to the next state needed for the following step of training
(lines 13-14). Then, the actor and critic updates their policy
(lines 15-19): (i) the actor computes the policy gradient via its
advantage function and TRPO to optimize its policy, and (ii)
the critic computes the MSPBE loss function and updates its
gradient via TD error learning.

V. SIMULATIONS AND PERFORMANCE EVALUATION

A. Parameter Settings

We conduct numerical experiments to verify our method
under various parameter settings. Inspired by related works
[12], [14], [15], [24], [29], [35], we set up all necessary
parameters for our BFL environment as listed in Table IV.

We consider a BFL system with 3 ESs and 10 MDs
which aim to collaboratively train two popular image datasets:
SVHN1
(including 73,257 training instances and testing

Table IV: Simulation parameters.

Parameter
Number of ESs M
Number of MDs N
Number of sub-channels at each ES K
Data size Dn
CPU workload of MDs and ESs
MDsâ€™ transmit power pn
MDâ€™s computational capability f (cid:96)
n
ESâ€™s computational capability fm
Background noise variance
Maximum system bandwidth W
MDâ€™s model size Ï‘
MDâ€™s energy coefï¬cient Îº
MDâ€™s hash rate Î¨n
MDâ€™s mining power efï¬ciency În
Hash amount of a block Â¯h
Block broadcasting rate Î¾
Number of forking occurrences Î¶
MDâ€™s maximum latency Ï„n
Noise power spectral density N0
ESâ€™s bandwidth bm(cid:48)
ESâ€™s transmit power pm(cid:48)

Value
5
[20-100]
5
[0.5-2] MB
[0.7-1.1] Gcyles
[10-30] dBm
[0,2-2] GHz
5 GHz
-100 dBm
20 MHz
5 KB
5 âˆ— 10âˆ’27
[100-1000] GHash/s
5 âˆ— 10âˆ’8 J/hash
50 GHash
0.005
3
3 sec
-174 dBm/Hz
5 MHz
[100-120] dBm

26,032 instances) and Fashion-MNIST2 (including 60,000
training instances and testing 10,000 instances), where each
dataset contains 10 labels/classes. For the SVHN dataset, we
deploy a convolutional neural network (CNN) with two 2-
D convolutional layers followed by two hidden layers (the
ï¬rst with 256 units and the second with 72 units) with ReLU
activation. The CNN architecture used for the Fashion-MNIST
dataset is similar, with the ï¬rst hidden layer with 320 units and
the second hidden layer with 50 units. We investigate the FL
performance under both IID and non-IID data settings. In IID
data setting, each MD possesses datapoints from all the 10
labels, while in non-IID data setting, each MD contains data
samples from three of 10 labels for the SVHN dataset and
two of 10 labels for the Fashion-MNIST dataset. We employ
the Adam optimizer with mini-batch size of 25 and 10 SGD
iterations.

In our A2C algorithm, the actor has two DNNs, one for
the discrete ofï¬‚oading policy with two hidden neural layers
{ 64 and 32 in sizes} and one for the continuous allocation
parameter policy with two layers {128 and 64 in sizes}. For
the output layers, we used Softmax to generate ofï¬‚oading
decisions for MDs and adopted Tanh to produce allocation
parameters given the discrete ofï¬‚oading policy. The KL diver-
gence constraint (cid:15)KL is set to 0.01 for the TRPO-based actor
policy optimizer [40]. The critic was also built by a DNN
that contains two hidden layers of sizes {200, 100} to train
the state-value function of our A2C scheme with the Adam
optimizer. To implement our parameterized A2C algorithm,
we set up a virtual agent that is allowed to interact with a pre-
deï¬ned BFL environment to learn the parameterized ofï¬‚oading
policy for all MDs and observe the return, i.e., system utility,
after each iteration. We trained the agent over 10000 episodes
with 100 timesteps per each episode. All numerical results
are averaged over 10 independent simulation runs.

B. Evaluation of FL Performance

We evaluate the classiï¬cation accuracy and loss perfor-
mance of our proposed BFL scheme (with 5 consensus rounds)

1http://uï¬‚dl.stanford.edu/housenumbers/

2https://github.com/zalandoresearch/fashion-mnist

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

14

(a) Accuracy under IID setting.

(b) Accuracy under non-IID set-
ting.

(a) Accuracy under IID setting.

(b) Accuracy under non-IID set-
ting.

(c) Loss under IID setting.

(d) Loss under non-IID setting.

(c) Loss under IID setting.

(d) Loss under non-IID setting.

Fig. 4: Comparison of different FL approaches on SVHN
dataset.

Fig. 6: Comparison of BFL performance with different con-
sensus rounds on Fashion-MNIST dataset.

(a) Accuracy under IID setting.

(b) Accuracy under non-IID set-
ting.

(a) System rewards with different
actor learning rates.

(b) System rewards with different
critic learning rates.

(c) Loss under IID setting.

(d) Loss under non-IID setting.

Fig. 5: Comparison of different FL approaches on Fashion-
MNIST dataset.

and compare it with two related schemes. The ï¬rst one is
a traditional FL scheme [1], where ESs work independently
and each only aggregates the models of its associated MDs
and then broadcasts the resulting model across devices. The
second one is a traditional BFL without P2P consensus [4], in
which each ES runs an averaging algorithm by collaborating
with its MDs to build its aggregated model, and then a
random ES is selected as a leader that builds a global model
based on its local aggregated model without conducting P2P
consensus. Fig. 4 illustrates the performance when training
the SVHN dataset, showing the considerable improvements in
terms of higher accuracy and lower loss compared with the
counterparts. Although the performance degrades when the
dataset becomes non-IID, our consensus-based BFL scheme
still outperforms other algorithms. The BFL scheme without
consensus achieves a better training performance than the

Fig. 7: Evaluation of the training performance.

traditional FL scheme since its randomized leader ES selection
avoid local model bias across the clients. Moreover,
the
performance gap between our scheme and the others becomes
larger in the non-IID case which demonstrates the beneï¬t of
consensus-based model aggregation over existing approaches.
The advantages of our scheme are also veriï¬ed on the Fashion-
MNIST dataset in both IID and non-IID settings, as indicated
in Fig. 5. For example, in the IID setting, our consensus-
based BFL scheme improves the accuracy rate by 8% and
14% in comparison with the traditional BFL scheme without
consensus and the traditional FL scheme, respectively.

Fig. 6 investigates the impact of P2P consensus rounds
(i.e., 5, 10, and 15 rounds) on the learning performance. We
can see that the increase of consensus rounds signiï¬cantly
improves the performance. Under the non-IID setting, the role
of consensus on the model training becomes more signiï¬cant
with a larger performance gap, for example, between 5 rounds
and 15 rounds, which shows the efï¬ciency of our consensus-
based BFL design for federated model training.

C. Evaluation of DRL Training Performance

We ï¬rst investigate the training system reward (i.e., sys-
tem utility as deï¬ned in (32)) performance by changing the
learning rates at both actor and critic, which is important to
determine a reliable parameter set for our later simulations,
as shown in Fig. 7. If the learning rate is too small, the

020406080100Communication rounds0.750.800.850.900.95Test AccuracyProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.250.300.350.400.450.500.550.60Test AccuracyProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.00.10.20.30.4LossProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.10.20.30.40.50.60.7LossProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.40.50.60.70.8Test AccuracyProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.10.20.30.40.50.60.7Test AccuracyProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.40.60.81.01.21.4LossProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.60.81.01.21.41.61.8LossProposed consensus-based BFLTraditional BFL without consensusTraditional FL020406080100Communication rounds0.600.650.700.750.800.85Test AccuracyBFL with 15 consensus roundsBFL with 10 consensus roundsBFL with 5 consensus rounds020406080100Communication rounds0.30.40.50.60.7Test AccuracyBFL with 15 consensus roundsBFL with 10 consensus roundsBFL with 5 consensus rounds020406080100Communication rounds0.60.81.01.2LossBFL with 15 consensus roundsBFL with 10 consensus roundsBFL with 5 consensus rounds020406080100Communication rounds0.30.40.50.60.70.80.91.0LossBFL with 15 consensus roundsBFL with 10 consensus roundsBFL with 5 consensus rounds020406080100Training episodes (x102)0.500.751.001.251.501.752.00System rewardActor learning rate = 0.001Actor learning rate = 0.003Actor learning rate = 0.005020406080100Training episodes (x102)1.21.41.61.82.0System rewardCritic learning rate = 0.01Critic learning rate = 0.02Critic learning rate = 0.03ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

15

transmit power variable of MD n is discretized into Z levels as
(cid:17) 1

Pn =

(cid:20)
0, pmin, pmin.

(cid:16) pmax
pmin

(cid:21)
, where pn = 0

|Z|âˆ’2 , ..., pmax

(a) System reward with different
action spaces.

(b) System reward with different
learning schemes.

Fig. 8: Comparison of system reward via learning curves.

(a) System latency with different
numbers of MDs.

(b) System latency versus consen-
sus rounds.

Fig. 9: Comparison of system latency between different
schemes.

policy training probably requires long time to achieve an
optimal solution. However, if we set a large learning rate,
the training may become unstable and possibly diverge. In
A2C algorithms, since the actor updates slower than the
critic with a timestep, we set up the actor with a learning
rate smaller than the criticâ€™s learning rate. We ï¬rst evaluate
the impacts of the actor learning rate, i.e., the backtracking
step-size parameter Î³a
t which controls the policy update in
the trust region in each iteration of TRPO under the KL
divergence constraint. Fig. 7(a) reveals that the learning rate
of 0.003 exhibits the highest system reward with the fastest
convergence, compared to the case of Î³a
t = 0.001 which shows
the slowest convergence rate. However, when the learning rate
is relatively high (Î³a
t = 0.005), the learning process becomes
unstable and diverges. Similar to the actor part, we also set
up a learning procedure by considering various critic learning
rates. As indicated in Fig. 7(b), the learning rate Î³c
t = 0.02 has
the most stable training performance with a quick convergence,
compared to other learning settings. Thus, we will use learning
rates Î³a
t = 0.02 for the following simulations.
Next, we compare the reward performance obtained by
our proposed parameterized A2C algorithm against two base-
line schemes: A2C with relaxed action space [35] and A2C
with approximated action space [36]. For the ï¬rst baseline
scheme, we ï¬rst relax the discrete ofï¬‚oading vector into
a continuous set by deï¬ning a relaxed space as Aa =
{f (x1, ), f (x2), ..., f (xN )}, where f (.) is a probability soft-
max function, and then re-normalize them to approximate
discrete ofï¬‚oading vectors for execution. Compared with our
proposed parameterized scheme, this method signiï¬cantly in-
creases the sampling complexity on the joint action space. For
the second baseline scheme, we discretize each of continuous
allocation vectors into a discrete subset. For example, the

t = 0.003 and Î³c

implies the local execution mode. This discretization process
creates a large number of quantization levels for convenient
action sampling but also results in quantization noise.

From Fig. 8(a), our proposed scheme can achieve the
best reward performance compared with baseline approaches,
thanks to a ï¬‚exible parameterized action sampling solution
where both discrete ofï¬‚oading decisions and allocation vari-
ables are directly trained without relaxation or approximation.
Meanwhile, the A2C scheme with relaxed action space suffers
a reward decrease with high training variance since the ofï¬‚oad-
ing action selection must be converted into a continuous space
of allocation vectors, leading to an extremely high complexity
in the action sampling and thus making the training inefï¬cient.
Moreover, its complex action sampling requires longer time
to reach convergence, i.e., after 4000 episodes compared to
2500 episodes in our proposed scheme. The lowest reward
the approximated scheme, where the
gain is observed at
approximation of action space introduces the quantization
error which degrades the policy training.

We then compare our scheme with state-of-the-art DRL
approaches: (i) A2C [12], as in our method but only using the
vanilla gradient update at the actor without policy optimization
improvement; (ii) deep deterministic policy gradient (DDPG),
using actor-critic with deterministic policy training over the
continuous action space [35]; (iii) standard actor-critic [28],
i.e., without using advantage function in the policy estimation;
and (iv) deep Q-network [22], which uses action sampling
approximation. From Fig. 8(b), we ï¬nd that our proposed
parameterized A2C method is better than baselines in terms
of system reward and convergence rate and stability. This
is due to the efï¬cient action sampling and improved policy
optimization based on trust region enforcement which helps
avoiding possible gradient divergence. Thus, a faster and more
reliable policy search is achieved toward an optimal solution.
The DDPG scheme has a lower reward convergence speed
due to the relaxation of the discrete ofï¬‚oading action space.
This increases action sampling complexity and thus makes the
policy training less efï¬cient compared with our parameterized
A2C. On the other hand, we see that DDPG outperforms
standard A2C, which demonstrates the importance of the
policy optimization improvement step employed in our scheme
over a hybrid continuous and discrete action space. Although
the standard A2C scheme achieves a relatively stable reward
performance, its reward gain is lower than that of our approach
due to the natural gradient descent with greedy policy update.

D. Evaluation of System Latency Performance

In this subsection, we evaluate the system latency per-
formance under networking scenarios. Based on the system
reward (utility) computed via the above training process, it
is straightforward to calculate the system latency via their
mathematical relation as mentioned in (31) and (32).

We investigate the latency performance when varying the
numbers of MDs from 20 to 100 in Fig. 9(a). The system
latency obtained by our proposed parameterized A2C scheme

020406080100Training episodes (x102)0.60.81.01.21.41.61.82.02.2System rewardProposed A2C with parameterized action spaceA2C with approximated action spaceA2C with relaxed action space020406080100Training episodes (x102)0.81.01.21.41.61.82.0System rewardProposed parameterized A2CStandard A2C DDPGStandard actor-criticDeep Q-network2030405060708090100Number of MDs6080100120140160180200220System latency (second)Proposed parameterized A2C schemeA2C schemeDDPG schemeStandard actor-critic schemeDeep Q network0.02.55.07.510.012.515.017.520.0Number of consensus rounds5075100125150175200225250System latency (second)Proposed parameterized A2C schemeA2C schemeDDPG schemeStandard actor-critic schemeDeep Q networkACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

16

(a) System latency versus transmit power
allocation.

(b) System latency versus bandwidth alloca-
tion.

(c) System latency versus mining hash allo-
cation.

Fig. 10: Comparison of system latency with different resource allocation settings.

is the lowest across the considered methods. As expected, the
latency of each method increases with the number of MDs,
due to a higher ofï¬‚oading and mining latency caused by a
higher competition on bandwidth and hash allocation among
MDs, our proposed scheme still achieves the best latency
performance when the number of MDs increases. For instance,
with 100 MDs, the system latency of our scheme is 11%, 13%,
25% and 38% lower than that of the DDPG, A2C, actor-critic,
and deep Q-network schemes, respectively.

the edge layer enhances the model

We then investigate the impact of P2P rounds on the system
latency, as indicated in Fig. 9(b). We change the number of
P2P rounds from 0 to 20, where 0 implies the traditional BFL
scheme without consensus. Although the use of consensus
training
procedure at
performance, it potentially increases the system latency due
to the additional delay of P2P model aggregation among ESs.
However, with our advanced DRL design, the proposed param-
eterized A2C scheme achieves the minimal latency compared
with other baselines. The increase of P2P rounds requires more
time for model aggregation, leading to a higher system latency,
but our approach still has the best performance.

We also investigate the latency performance under different
resource allocation scenarios in Fig. 10 in a BFL environment
with 5 ESs and 30 MDs. We ï¬rst vary the maximum transmit
power Pn at each MD n between 10 and 30 dBm and then
measure the latency of ofï¬‚oading and mining. As shown in
Fig. 10(a), the latency of all schemes decreases with respect
to the increasing amount of allocated transmit power. This is
because a larger transmit power improves the data transmission
rate that helps reduce the data ofï¬‚oading latency. Notably,
compared with other schemes, our method achieves the most
signiï¬cant and stable latency decrease due to our efï¬cient
and robust parameterized policy training to obtain the better
ofï¬‚oading trajectory. Another interesting observation is that
when the maximum transmit power exceeds 20 dBm, the
system latency reduces at a slower rate. This is due to the
less impact of such a large power allocation on the ofï¬‚oading
latency savings given a certain number of MDs and data sizes.

Moreover, we investigate the latency trends of different
algorithms when the maximum system bandwidth W varies
from 20 to 30 MHz in Fig. 10(b). Similar to the power
allocation scenario, more bandwidth would help mitigate the
ofï¬‚oading latency. In our simulation setting, the impact of
bandwidth on the system latency is signiï¬cant before the

threshold of 25 MHz, where our scheme shows the best latency
savings. Compared with DDPG, A2C and actor-critic schemes,
our parameterized A2C scheme can reduce the latency by 7%,
8% and 17%, respectively, and achieves a 60% lower latency
compared with the deep Q-network baseline.

Finally, we compare the latency performance with respect to
the changes of mining hash power capability Î¨max. A higher
hash allocation would help reduce the block generation latency
for a lower mining and system latency. By increasing the hash
budget, each MD has a higher chance to obtain sufï¬cient hash
power to run the block mining. As can be seen in Fig. 10(c),
our proposed scheme outperforms other baselines in terms of
system latency in each hash allocation setting. The simulation
results thus demonstrate the efï¬ciency of our proposed A2C
algorithm design in the system latency minimization.

E. Attack Evaluation

1) Attack Model and Security Analysis with Blockchain:
A major concern in conventional FL with a single centralized
aggregation server is that the server may become compromised
via model poisoning attacks launched by adversaries. In this
section, we investigate how blockchain can help mitigate
impact of model poisoning attacks on the ML model training
performance, which as discussed in Section I-B is one of
our motivations for integrating blockchain with FL. Model
poisoning attacks mainly consist of untargeted model poison-
ing attacks and targeted model poisoning attacks [42]. The
former category aims to degrade the accuracy of the global
model training, whereas the latter aims to control the model
deviation towards their target. Here, we focus on untargeted
model poisoning attacks on our BFL system.

We assume that at a certain global FL round k, an ES can
be compromised by a model poisoning attack following two
steps. First, the attacker injects certain random noise v(k) to the
aggregated global model w(k) obtained via 12 to manipulate
the global model update w(k) â† w(k) + v(k). Here we adopt
Gaussian noise, i.e., v(k) = âˆ’(cid:36)q(k), where (cid:36) is a scaling
factor which characterizes the magnitude of the compromised
model, and q(k) is a random vector sampled from the Gaussian
distribution N (0, I). Next, the attacked ES broadcasts the
compromised global model to local MDs.

In our BFL system, blockchain replaces the centralized
authority in FL with a decentralized tamper-proof data ledger

10.012.515.017.520.022.525.027.530.0Maximum transmit power (dBm)304050607080System latency (second)Proposed parameterized A2C schemeA2C schemeDDPG schemeStandard actor-critic schemeDeep Q network202224262830Maximum system bandwidth (MHz)1020304050607080System latency (second)Proposed parameterized A2C schemeA2C schemeDDPG schemeStandard actor-critic schemeDeep Q network2004006008001000Mining hash power capability (GHash/s)1020304050607080System latency (second)Proposed parameterized A2C schemeA2C schemeDDPG schemeStandard actor-critic schemeDeep Q networkACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

17

to monitor the model consensus process as well as mitigate
single-point-of-failure. By deploying a blockchain over the
edge layer, any model update event over consensus rounds
at a certain ES is automatically traced by other ESs. If a
poisoning attack takes place at an ES, other ESs can detect
this behavior via transaction logs. Here, we adopt the attack
detection score metric [43], which characterizes the abnormal
gradient deviation caused by the poisoning attacker at a certain
FL round, to detect the occurrence of a model attack at a
certain ES. Since all gradient update information including
the compromised gradient is recorded on the digital ledger,
blockchain can identify the compromised ES and temporarily
disregard it from the ES network, while the global model
aggregation process continues.

2) Attack Simulation: We investigate the training perfor-
mance of different FL methods under model poisoning attacks
on the two considered datasets. We consider an attack scenario
where an adversary compromizes an ES and deploys model
poisoning attacks by injecting random noise at the global
rounds of 20 and 60 during the model consensus process
among ESs. Our proposed consensus-based BFL scheme with
blockchain is compared with other three baselines: consensus-
based FL without blockchain, BFL without consensus, and
traditional FL. For the consensus-based schemes, we consider
that there are 5 consensus rounds and the attacker poisons the
model at round 3. For the BFL scheme without consensus, the
attacker poisons one of the ESs during the global model ag-
gregation process. For the traditional FL scheme, the attacker
poisons the centralized aggregator.

As illustrated in Fig. 11 for the SVHN dataset, the ac-
curacy performance of all schemes is dropped when the
attack occurs (i.e., at aggregation rounds 20 and 60). How-
ever, our consensus-based BFL scheme achieves the best
accuracy rate and highest robustness against the poisoning
attack in both IID and non-IID data distribution settings.
For instance, from Fig. 11(a), we see that the accuracy of
our scheme at the onset of an attack only drops by 3.7%,
as opposed to 7.6%, 16.9%, and 32.1% in the consensus-
based FL without blockchain, BFL without consensus, and
traditional FL schemes, respectively. The traceable data ledger
of blockchain records all the global updating behaviors of ESs
across consensus rounds, which allows blockchain to rapidly
detect the poisoning attack. Since all ESs are connected on
the shared ledger, the blockchain disregards this ES from the
consensus process to protect model training. The consensus-
based FL scheme without blockchain has the second highest
performance. The poisoned model is involved in the consensus
process, which degrades the overall model aggregation, though
the impact is dampened since the poisoned model is only
one participating in the consensus process. The other two
non-consensus-based methods show lower accuracy and less
robustness against the attack. The BFL scheme without con-
sensus shows lower training robustness since the attack at one
of the ESs signiï¬cantly affects the global model aggregation at
that particular server and its associated MDs. In the traditional
FL scheme with a centralized server, the model training is
degraded after the attack since the attacker directly poisons
these experiments
the only model aggregator. We repeat

(a) Accuracy under IID setting.

(b) Accuracy under non-IID setting.

Fig. 11: Comparison of different FL approaches under model
poisoning attacks (SVHN dataset).

(a) Accuracy under IID setting.

(b) Accuracy under non-IID setting.

Fig. 12: Comparison of different FL approaches under model
poisoning attacks (Fashion-MNIST dataset).

on the Fashion-MNIST dataset in Fig. 12 which indicates
qualitatively similar results. For example, in Fig. 12(a), the
accuracy rate of our BFL scheme with blockchain only reduces
by 2.67%, compared with 5.6% in the consensus-based FL
without blockchain, 6.8% in the BFL without consensus, and
16.7% in the traditional FL scheme at the onset of poisoning
attack.

VI. CONCLUSION

This paper studied a decentralized BFL system in multi-
server edge computing with a holistic design of both
ofï¬‚oading-assisted ML model training and mobile block min-
ing schemes. A model aggregation solution has been developed
via P2P-based consensus among ESs to build a global model
that is shared with MDs via Blockchain for reliable model
learning empowered by block mining. We aimed to minimize
the system latency by a parameterized A2C algorithm with a
careful design of actor and critic. A comprehensive analysis
of the convergence properties of our proposed BFL model
was given. Numerical simulations veriï¬ed the superior per-
formance of our proposed consensus-based BFL scheme over
state-of-the-art schemes in terms of higher accuracy and lower
loss. The proposed parameterized A2C algorithm exhibited the
faster convergence rate and lower system latency, compared
with the existing DRL schemes. Our blockchain-empowered
BFL scheme also achieved high robustness against model
poisoning attacks.

REFERENCES

[1] S. Wang et al., â€œAdaptive federated learning in resource constrained edge
computing systems,â€ IEEE J. Sel. Areas in Commun., vol. 37, no. 6, pp.
1205â€“1221, 2019.

[2] D. C. Nguyen et al., â€œFederated learning for Internet of Things: A
comprehensive survey,â€ IEEE Commun. Surveys & Tutorials, vol. 23,
no. 3, pp. 1622â€“1658, 2021.

020406080100Communication rounds0.450.500.550.600.650.700.750.800.85Test AccuracyProposed consensus-based BFL with blockchainConsensus-based FL without blockchainBFL without consensusTraditional FL020406080100Communication rounds0.20.30.40.50.60.70.8Test AccuracyProposed consensus-based BFL with blockchainConsensus-based FL without blockchainBFL without consensusTraditional FL020406080100Communication rounds0.450.500.550.600.650.700.750.80Test AccuracyProposed consensus-based BFL with blockchainConsensus-based FL without blockchainBFL without consensusTraditional FL020406080100Communication rounds0.350.400.450.500.550.600.650.70Test AccuracyProposed consensus-based BFL with blockchainConsensus-based FL without blockchainBFL without consensusTraditional FLACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

18

[3] C. Ma, J. Li, M. Ding, H. H. Yang, F. Shu, T. Q. Quek, and H. V. Poor,
â€œOn safeguarding privacy and security in the framework of federated
learning,â€ IEEE Net., vol. 34, no. 4, pp. 242â€“248, 2020.

[4] F. Ayaz, Z. Sheng, D. Tian, and Y. L. Guan, â€œA blockchain based
federated learning for message dissemination in vehicular networks,â€
IEEE Trans. Vehicular Techno., 2021.

[5] V. Mothukuri et al., â€œFabricï¬‚: Blockchain-in-the-loop federated learning

for trusted decentralized systems,â€ IEEE Systems J., 2021.

[6] Y. He, K. Huang, G. Zhang, F. R. Yu, J. Chen, and J. Li, â€œBift:
A blockchain-based federated learning system for connected and au-
tonomous vehicles,â€ IEEE Internet of Things J., 2021.

[7] Q. Hu et al., â€œBlockchain and federated edge learning for privacy-
preserving mobile crowdsensing,â€ IEEE Internet of Things J., 2021.
[8] Y. Zhao, J. Zhao, L. Jiang, R. Tan, D. Niyato, Z. Li, L. Lyu, and
Y. Liu, â€œPrivacy-preserving blockchain-based federated learning for IoT
devices,â€ IEEE Internet of Things J., vol. 8, no. 3, pp. 1817â€“1829, 2020.
[9] D. C. Nguyen et al., â€œFederated learning meets blockchain in edge
computing: Opportunities and challenges,â€ IEEE Inter. Things J., 2021.
[10] W. Shi et al., â€œJoint device scheduling and resource allocation for
latency constrained wireless federated learning,â€ IEEE Trans. Wireless
Commun., vol. 20, no. 1, pp. 453â€“467, 2020.

[11] Q. Ma et al., â€œFedSA: A semi-asynchronous federated learning mecha-
nism in heterogeneous edge computing,â€ IEEE J. Sel. Areas in Commun.,
vol. 39, no. 12, pp. 3654â€“3672, 2021.

[12] H. Yang et al., â€œPrivacy-preserving federated learning for UAV-enabled
networks: Learning-based joint scheduling and resource management,â€
IEEE J. Sel. Areas in Commun., 2021.

[13] C. W. Zaw, S. R. Pandey, K. Kim, and C. S. Hong, â€œEnergy-aware
resource management for federated learning in multi-access edge com-
puting systems,â€ IEEE Access, vol. 9, pp. 34 938â€“34 950, 2021.
[14] Z. Ji, L. Chen, N. Zhao, Y. Chen, G. Wei, and F. R. Yu, â€œComputation
ofï¬‚oading for edge-assisted federated learning,â€ IEEE Trans. Vehicular
Techno., vol. 70, no. 9, pp. 9330â€“9344, 2021.

[15] Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, â€œEnergy
efï¬cient federated learning over wireless communication networks,â€
IEEE Trans. Wireless Commun., vol. 20, no. 3, pp. 1935â€“1949, 2020.

[16] C. Hu, J. Jiang, and Z. Wang, â€œDecentralized federated learning: A

segmented gossip approach,â€ arXiv:1908.07782, 2019.

[17] H. Xing, O. Simeone, and S. Bi, â€œDecentralized federated learning via
SGD over wireless D2D networks,â€ in Proc. IEEE 21st Inter. Workshop
on Signal Processing Advances in Wireless Commun., 2020, pp. 1â€“5.

[18] F. P.-C. Lin et al., â€œSemi-decentralized federated learning with cooper-
ative D2D local model aggregations,â€ IEEE J. Sel. Areas in Commun.,
vol. 39, no. 12, pp. 3851â€“3869, 2021.

[19] S. Hosseinalipour et al., â€œMulti-stage hybrid federated learning over
large-scale D2D-enabled fog networks,â€ IEEE/ACM Trans. Net., 2022.
[20] H. Kim et al., â€œBlockchained on-device federated learning,â€ IEEE

Commun. Lett., vol. 24, no. 6, pp. 1279â€“1283, 2019.

[21] S. R. Pokhrel and J. Choi, â€œFederated learning with blockchain for
autonomous vehicles: Analysis and design challenges,â€ IEEE Trans.
Commun., vol. 68, no. 8, pp. 4734â€“4746, 2020.
[22] Y. Lu, X. Huang, K. Zhang, S. Maharjan,

and Y. Zhang,
â€œCommunication-efï¬cient
permissioned
blockchain for digital twin edge networks,â€ IEEE Internet of Things J.,
vol. 8, no. 4, pp. 2276â€“2288, 2020.

federated

learning

and

[23] M. Aloqaily, I. Al Ridhawi, and M. Guizani, â€œEnergy-aware blockchain
and federated learning-supported vehicular networks,â€ IEEE Trans.
Intell. Transpor. Systems, 2021.

[24] X. Deng et al., â€œOn dynamic resource allocation for blockchain assisted

federated learning over wireless channels,â€ arXiv:2105.14708, 2021.

[25] B. Ganguly et al., â€œMulti-edge server-assisted dynamic federated learn-
ing with an optimized ï¬‚oating aggregation point,â€ arXiv preprint
arXiv:2203.13950, 2022.

[26] S. Hosseinalipour et al., â€œParallel successive learning for dynamic
training over heterogeneous wireless networks,â€

distributed model
arXiv:2202.02947, 2022.

[27] X. Xiong, K. Zheng, L. Lei, and L. Hou, â€œResource allocation based
on deep reinforcement learning in IoT edge computing,â€ IEEE J. Sel.
Areas in Commun., vol. 38, no. 6, pp. 1133â€“1146, 2020.

[28] S. Chen et al., â€œMulti-agent deep reinforcement learning-based coop-
erative edge caching for ultra-dense next-generation networks,â€ IEEE
Trans. Commun., vol. 69, no. 4, pp. 2441â€“2456, 2020.

[29] D. C. Nguyen et al., â€œPrivacy-preserved task ofï¬‚oading in mobile
blockchain with deep reinforcement learning,â€ IEEE Trans. Net. and
Service Manag., vol. 17, no. 4, pp. 2536â€“2549, 2020.

[30] L. Xiao and S. Boyd, â€œFast linear iterations for distributed averaging,â€

Systems & Control Lett., vol. 53, no. 1, pp. 65â€“78, 2004.

[31] L. Xiao, S. Boyd, and S.-J. Kim, â€œDistributed average consensus
with least-mean-square deviation,â€ J. Parallel and Distributed Comput.,
vol. 67, no. 1, pp. 33â€“46, 2007.

[32] C. T. Dinh, N. H. Tran, M. N. Nguyen, C. S. Hong, W. Bao, A. Y.
Zomaya, and V. Gramoli, â€œFederated learning over wireless networks:
Convergence analysis and resource allocation,â€ IEEE/ACM Trans. Net.,
vol. 29, no. 1, pp. 398â€“409, 2020.

[33] J. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor, â€œTackling the
objective inconsistency problem in heterogeneous federated optimiza-
tion,â€ Proc. Advances in Neural Infor. Processing Systems, vol. 33, pp.
7611â€“7623, 2020.

[34] C. Huang et al., â€œZkrep: A privacy-preserving scheme for reputation-
based blockchain system,â€ IEEE Internet of Things J., vol. 9, no. 6, pp.
4330â€“4342, 2021.

[35] D. C. Nguyen et al., â€œCooperative task ofï¬‚oading and block mining in
blockchain-based edge computing with multi-agent deep reinforcement
learning,â€ IEEE Trans. Mobile Comput., 2021.

[36] F. Meng, P. Chen, L. Wu, and J. Cheng, â€œPower allocation in multi-
user cellular networks: Deep reinforcement learning approaches,â€ IEEE
Trans. Wireless Commun., vol. 19, no. 10, pp. 6255â€“6267, 2020.
[37] H. Lu et al., â€œEdge QoE: Computation ofï¬‚oading with deep reinforce-
ment learning for internet of things,â€ IEEE Internet of Things J., vol. 7,
no. 10, pp. 9255â€“9265, 2020.

[38] M. Akbari et al., â€œAge of information aware VNF scheduling in
industrial IoT using deep reinforcement learning,â€ IEEE J. Sel. Areas in
Commun., 2021.

[39] S. Qiu et al., â€œOn ï¬nite-time convergence of actor-critic algorithm,â€

IEEE J. Sel. Areas in Info. Theory, vol. 2, no. 2, pp. 652â€“664, 2021.

[40] L. Shani et al., â€œAdaptive trust region policy optimization: Global
convergence and faster rates for regularized MDPS,â€ in Proc. AAAI Conf.
Artiï¬cial Intell., vol. 34, no. 04, 2020, pp. 5668â€“5675.

[41] S. Vaswani et al., â€œPainless stochastic gradient: Interpolation,

line-
search, and convergence rates,â€ Proc. Advances in Neural Infor. Pro-
cessing Systems, vol. 32, pp. 3732â€“3745, 2019.

[42] M. Fang et al., â€œLocal model poisoning attacks to Byzantine-robust
federated learning,â€ in Proc. 29th USENIX Security Symposium, 2020,
pp. 1605â€“1622.

[43] A. Mondal, H. Virk, and D. Gupta, â€œBeas: Blockchain enabled asyn-
chronous & secure federated machine learning,â€ Proc. Third AAAI
WRKSH Privacy-Preserving Artif. Intel., 2022.

[44] H.-T. Wai et al., â€œProvably efï¬cient neural GTD for off-policy learning,â€
Proc. Advances in Neural Infor. Processing Systems, vol. 33, pp. 10 431â€“
10 442, 2020.

[45] S. L. Lohr, Sampling: Design and Analysis: Design And Analysis. CRC

Press, 2019.

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

19

A. Brief Recap of ML Model Training

APPENDIX A
PROOF OF THEOREM 1

Let set N (k)

m contain the devices associated with ES m during global aggregation k and also the ES m itself. Also, let y
denote the index of an arbitrary ES/MD. Each ES m at global aggregation k acquires its local aggregated gradient, which
is then normalized by the total number of data points D(k) to form âˆ‡F A,(k)
according to (8), which can be written in the
compact form as

m

Then, the ESs engage in consensus process, where the ï¬nal parameter at each ES m can be expressed as

âˆ‡F A,(k)

m =

(cid:88)

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,k
y

.

âˆ‡F L,(k)

m =

(cid:88)

mâˆˆM

âˆ‡F A,(k)

m + c(k)

m =

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

+ c(k)
m ,

(41)

(42)

m denotes the error of consensus, which is caused by ï¬nite rounds of P2P communications. The selected ES at

where c(k)
aggregation round k, denoted by mk, then adds a boosting coefï¬cient (cid:80)
the following vector:

(cid:80)

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

mâˆˆM

to its local gradient to form

âˆ‡F

(k)
mk

=

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

âˆ‡F L,(k)
mk

=

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)

y +

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

The aggregator ES mk then updates the global model parameter as follows:

w(k+1) = w(k) âˆ’ Î·kâˆ‡F

(k)
mk

.

B. Convergence Analysis

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

c(k)
mk

.

(43)

(44)

Using the Î²-smoothness of the global loss function (Assumption 2), we have:
w(k+1) âˆ’ w(k)(cid:17)

F (k)(w(k+1)) â‰¤ F (k)(w(k)) + âˆ‡F (k)(w(k))

(cid:62) (cid:16)

+

Î²
2

(cid:13)
(cid:13)

(cid:13)w(k+1) âˆ’ w(k)(cid:13)

2
(cid:13)
(cid:13)

.

(45)

Using the updating rule of w(k+1) and taking the conditional expectation (with respect to data sampling conducted via

mini-batch SGD at the last aggregation instance), we have

(cid:104)

Ek

F (k)(w(k+1))

(cid:105)

ï£®

â‰¤ F (k)(w(k))âˆ’

âˆ‡F (k)(w(k))

(cid:62)Ek

ï£°Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

+ Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¹

c(k)
mk

ï£»

+

Î²
2

Ek

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

+ Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

c(k)
mk

2ï£¹

ï£º
ï£» .

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Since âˆ‡F C,(k)

y

= âˆ’

(cid:18)

(k),e(k)
w
y

y

âˆ’ w(k)

(cid:19) (cid:46)

Î·k, we have

âˆ‡F C,(k)
y

=

1
B(k)
y

e(k)
y
(cid:88)

(cid:88)

âˆ‡f (w(k),eâˆ’1
y

, d),

e=1

dâˆˆB(k),e
y

(46)

(47)

y

where B(k),e
the mini-batch size is ï¬xed during local SGD iterations at each global aggregation round, we deï¬ned B(k)
Noting that SGD is unbiased it can be easily shown that

denotes the set of data points selected to form the mini-batch at the e-th local SGD iteration at ES/MD y. Since
|, âˆ€e.

y = |B(k),e

y

(cid:104)

Ek

âˆ‡F C,(k)
y

(cid:105)

=

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

).

(48)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

20

c(k)
mk

2ï£¹

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(49)

ï£º
ï£» .

c(k)
mk

2ï£¹

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(50)

ï£º
ï£» .

Replacing the above result in (46), we get

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤F (k)(w(k)) âˆ’ âˆ‡F (k)(w(k))

(cid:104)

(cid:62)Ek

Î·k

(cid:88)

(cid:88)

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:105)

c(k)
mk

(cid:88)

(cid:88)

+ Î·k

y(cid:48)âˆˆN (k)
m

mâˆˆM
ï£®

+

Î²
2

Ek

ï£¯
ï£°

Î·k

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

+ Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

Using the linearity of expectation and inner product, we can simplify the above expression as follows:

(cid:104)

(cid:105)
F (k)(w(k+1))

Ek

â‰¤F (k)(w(k)) âˆ’ âˆ‡F (k)(w(k))

ï£®

(cid:62)Ek

ï£°Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

ï£¹

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

ï£»

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

âˆ‡F (k)(w(k))

(cid:104)

(cid:62)Ek

âˆ’c(k)
mk

(cid:105)

(cid:88)

(cid:88)

+ Î·k

y(cid:48)âˆˆN (k)
m

mâˆˆM
ï£®

+

Î²
2

Ek

ï£¯
ï£°

Î·k

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

+ Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

Using Cauchy-Schwartz and Youngâ€™s inequalities, we have

a(cid:62)b â‰¤

Î±
2

(cid:107)a(cid:107)2+

1
2Î±

(cid:107)b(cid:107)2, Î± âˆˆ R++

(51)

for two real valued vectors a and b, implying a(cid:62)b â‰¤ (cid:107)a(cid:107)2+ 1

4 (cid:107)b(cid:107)2. Using this inequality in (50) yields

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤F (k)(w(k)) âˆ’ âˆ‡F (k)(w(k))

ï£®

(cid:62)Ek

ï£°Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

ï£¹

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

ï£»

+

Î·k
4

(cid:88)

(cid:88)

y(cid:48)âˆˆN (k)
m

mâˆˆM
ï£®

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

yâˆˆN (k)
m
D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(52)
Further, for any two real valued vectors a and b, we have: 2a(cid:62)b = (cid:107)a(cid:107)2+(cid:107)b(cid:107)2âˆ’(cid:107)a âˆ’ b(cid:107)2. Using this equality in (52) results

D(k)
y
D(k)e(k)

y(cid:48) e(k)
y(cid:48)
D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

âˆ‡F C,(k)
y

y(cid:48)âˆˆN (k)
m

y(cid:48)âˆˆN (k)
m

yâˆˆN (k)
m

D(k)

D(k)

c(k)
mk

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ Î·k

mâˆˆM

mâˆˆM

mâˆˆM

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

Ek

Î²
2

ï£¯
ï£°

Î·k

+

y

ï£º
ï£» .

2ï£¹

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

21

in the following bound:

(cid:104)

(cid:105)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) âˆ’

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

Ek

ï£®

ï£¯
ï£¯
ï£°

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

âˆ’

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

2 ï£¹
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£º
ï£»

+

Î·k
4

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

+

Ek

(cid:88)

(cid:88)

+ Î·k

y(cid:48)âˆˆN (k)
m

mâˆˆM
ï£®

Î²Î·2
k
2

Ek

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

+

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

c(k)
mk

2ï£¹

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£» .

(53)

Applying the Cauchy-Schwarz inequality (i.e., (cid:107)a + b(cid:107)2â‰¤ 2(cid:107)a(cid:107)2+2(cid:107)b(cid:107)2) on the last term of the above bound yields

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) âˆ’

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

Ek

ï£®

ï£¯
ï£¯
ï£°

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

âˆ’

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2 ï£¹
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£º
ï£»

+

Î·k
4

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:88)

(cid:88)

+ Î·k

mâˆˆM
y(cid:48)âˆˆN (k)
m
ï£®
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

Ek

mâˆˆM

ï£¯
ï£°

+ Î²Î·2
k

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

y(cid:48)âˆˆN (k)
m

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

(cid:124)

(cid:123)(cid:122)
(a)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2ï£¹

ï£º
ï£»

(cid:125)

ï£«

+Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

2

Ek

ï£¸

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

.

(54)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

22

Focusing on term (a) in (54), using (47), we upper bound it as follows:

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Ek

(cid:88)

(cid:88)

(cid:88)

(cid:88)

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

mâˆˆM

y(cid:48)âˆˆN (k)
m

mâˆˆM

ï£«

=

ï£­

ï£«

=

ï£­

ï£«

=

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

Ek

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

Ek

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

Ek

ï£«

â‰¤ 2

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

2ï£¹

ï£º
ï£»

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

(cid:88)

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

(cid:88)

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

e(k)
y
(cid:88)

e=1

e(k)
y
(cid:88)

e=1

(cid:88)

mâˆˆM

(cid:88)

mâˆˆM

ï£®

ï£¯
ï£°

yâˆˆN (k)
m
(cid:13)
ï£®
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
ï£®

ï£¯
ï£°

ï£¯
ï£°

ï£®

(cid:88)

mâˆˆM

(cid:88)

dâˆˆB(k),e
y
ï£«

(cid:88)

ï£¬
ï£­

ï£«

ï£¬
ï£­

dâˆˆB(k),e
y

(cid:88)

dâˆˆB(k),e
y
ï£«

(cid:88)

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

, d)

2ï£¹

ï£º
ï£»

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

, d)

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

, d)

âˆ’ âˆ‡F (k)

y

(w(k),eâˆ’1
y

) + âˆ‡F (k)

y

(w(k),eâˆ’1
y

âˆ’ âˆ‡F (k)

y

(w(k),eâˆ’1
y

) + âˆ‡F (k)

y

(w(k),eâˆ’1
y

ï£¶

ï£·
)
ï£¸

ï£¶

ï£·
)
ï£¸

2ï£¹

ï£º
ï£»

2ï£¹

ï£º
ï£»

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£¶
2

ï£¸

Ek

(cid:124)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£¯
ï£°

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

ï£¬
ï£­

dâˆˆB(k),e
y

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

, d)

âˆ’ âˆ‡F (k)

y

(w(k),eâˆ’1
y

)

ï£·
ï£¸

ï£¶

2ï£¹

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£»

(cid:125)

ï£«

+ 2

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

Ek

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

(cid:123)(cid:122)
(a)

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2ï£¹

ï£º
ï£» .

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

(55)
where the last inequality is obtained via Cauchy-Schwarz inequality. Note that (cid:80)
) in
the above expression corresponds to the noise of SGD at local iteration i at device y, which is zero mean and iid across the
devices and the iterations. Using these facts in term (a) in (55) implies

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

(w(k),eâˆ’1
y

âˆ’ âˆ‡F (k)

dâˆˆB(k),e
y

,d)

y

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Ek

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

2ï£¹

ï£º
ï£»

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£«

=

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

2

ï£¸

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

(cid:33)2

(cid:32)

D(k)
y
D(k)e(k)

y

Ek

(cid:124)

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

e(k)
y
(cid:88)

e=1

ï£«

ï£¬
ï£­

(cid:88)

dâˆˆB(k),e
y

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

, d)

(cid:123)(cid:122)
(a)

âˆ’ âˆ‡F (k)

y

(w(k),eâˆ’1
y

)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£·
ï£¸

ï£¶

2ï£¹

ï£«

+

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

2

ï£¸

Ek

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

2ï£¹

ï£º
ï£» .

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Using Lemma 2 (Appendix D) and the fact that SGD noise is zero mean, expanding term (a) in (56) yields

ï£º
ï£»

(cid:125)

(56)

(cid:88)

(cid:88)

Ek

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

âˆ‡F C,(k)
y

2ï£¹

ï£º
ï£»

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
ï£«

(cid:88)

(cid:88)

â‰¤

ï£­

mâˆˆM

y(cid:48)âˆˆN (k)
m

ï£«

+

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

ï£¶
2

ï£¸

ï£¶
2

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:88)

(cid:88)

mâˆˆM
ï£®

yâˆˆN (k)
m
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

mâˆˆM

(cid:88)

ï£¸

Ek

ï£¯
ï£°

(cid:32)

D(k)
y
D(k)e(k)

y

(cid:33)2 e(k)
(cid:88)

y

(cid:32)

2

1 âˆ’

e=1

(cid:33)

B(k)
y
D(k)
y

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

(cid:88)

yâˆˆN (k)
m

âˆ‡F (k)
y

(w(k),eâˆ’1
y

(Ïƒ(k)
y )2
B(k)
y
2ï£¹

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£» .

Î˜2
y

(57)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

23

Replacing the above result back in (54), we get

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) âˆ’

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

Ek

ï£®

ï£¯
ï£¯
ï£°

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

âˆ’

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2 ï£¹
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£º
ï£»

+

Î·k
4

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:88)

(cid:88)

+ Î·k

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

ï£«

+ Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

(cid:88)

(cid:88)

mâˆˆM

(cid:32)

D(k)
y
D(k)e(k)

y

(cid:33)2 e(k)
y
(cid:88)

(cid:32)

2

1 âˆ’

e=1

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y

ï£«

+ Î²Î·2
k

ï£­

ï£«

+ Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

Ek

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

Ek

ï£¸

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

.

With rearranging the terms in the above bound, we get

yâˆˆN (k)
m
2ï£¹
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

ï£º
ï£»

(w(k),eâˆ’1
y

(58)

(59)

(cid:104)

Ek

F (k)(w(k+1))

(cid:105)

â‰¤ F (k)(w(k)) âˆ’

ï£«

ï£­

Î·k
4

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

ï£¶

ï£«

Î²Î·k

ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£­
(cid:124)

+ Î·k

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

âˆ’

1
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£·
ï£·
ï£·
ï£·
ï£·
ï£·
ï£¸
(cid:125)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£«

+

ï£­

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

(cid:123)(cid:122)
(a)

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)

ï£«

ï£­1 + Î²Î·k

(cid:88)

(cid:88)

(cid:88)

(cid:88)

+ Î·k

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£«

+ Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

mâˆˆM

y(cid:48)âˆˆN (k)
m
(cid:32)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

D(k)

yâˆˆN (k)
m
ï£¶
ï£¸ Ek

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

D(k)
y
D(k)e(k)

y

(cid:33)2 e(k)
y
(cid:88)

(cid:32)

2

1 âˆ’

e=1

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

Assuming Î·k â‰¤

D(k)

2Î² (cid:80)

mâˆˆM

(cid:80)

y(cid:48)âˆˆN

(k)
m

D(k)

y(cid:48) e(k)
y(cid:48)

makes term (a) in the above expression negative and also implies 1 +

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

24

Î²Î·k

(cid:80)

mâˆˆM

(cid:80)

y(cid:48)âˆˆN (k)
m

D(k)
y(cid:48) e(k)
D(k) â‰¤ 3
y(cid:48)

2 . Replacing these results in the above bound gives us

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) âˆ’

ï£«

ï£­

Î·k
4

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

ï£«

+

ï£­

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)
(cid:124)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

e(k)
y
(cid:88)

e=1

D(k)
y
D(k)e(k)
(cid:123)(cid:122)
(a)

y

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:125)

+

3
2

Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

ï£«

+ 2Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

We next aim to bound term (a) in (60) as follows:

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

(60)

=

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

âˆ‡F (k)
y

(w(k)) âˆ’

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

2
(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

â‰¤

â‰¤

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

Ek

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
y
(cid:13)
(cid:13)

(w(k)) âˆ’

1
e(k)
y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)
(cid:13)

2ï£¹

ï£º
ï£»

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

(cid:20)(cid:13)
(cid:13)âˆ‡F (k)
(cid:13)

y

Ek

(w(k)) âˆ’ âˆ‡F (k)

y

(w(k),eâˆ’1
y

2(cid:21)

(cid:13)
(cid:13)
)
(cid:13)

â‰¤ Î²2 (cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

(cid:20)(cid:13)
(cid:13)w(k) âˆ’ w(k),eâˆ’1
(cid:13)

y

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

,

Ek

(61)

where we used Jensensâ€™s inequality and Î²-smoothness of the loss functions.

We then bound the last term in the above bound as follows:

(cid:20)(cid:13)
(cid:13)w(k) âˆ’ w(k),eâˆ’1
(cid:13)

y

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

=Î·2
k

Ek

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

(cid:88)

e(cid:48)=1

dâˆˆB(k),e(cid:48)

y

âˆ‡f (w(k),e(cid:48)âˆ’1
y
B(k)
y

, d)

2ï£¹

ï£º
ï£»

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ï£®

ï£¯
ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

(cid:16) (cid:88)

e(cid:48)=1

dâˆˆB(k),e(cid:48)

y

âˆ‡f (w(k),e(cid:48)âˆ’1
y
B(k)
y

, d)

âˆ’ âˆ‡F (k)

y

(w(k),e(cid:48)âˆ’1

y

) + âˆ‡F (k)

y

(w(k),e(cid:48)âˆ’1

y

ï£¹

ï£º
ï£º
ï£»

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:17)
)

= Î·2
k

Ek

â‰¤2Î·2
k

Ek

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

(cid:88)

dâˆˆB(k),e(cid:48)

y

e(cid:48)=1
ï£®

âˆ‡f (w(k),e(cid:48)âˆ’1
y
B(k)
y

, d)

âˆ’ âˆ‡F (k)

y

(w(k),e(cid:48)âˆ’1

y

)

2ï£¹
(cid:13)
(cid:13)
ï£» + 2Î·2
ï£º
(cid:13)
(cid:13)
(cid:13)

k

Ek

ï£®

ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

e(cid:48)=1

âˆ‡F (k)
y

(w(k),e(cid:48)âˆ’1

y

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)

2ï£¹

ï£»

=2Î·2
k

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

dâˆˆB(k),e(cid:48)

y

âˆ‡f (w(k),e(cid:48)âˆ’1
y
B(k)
y

, d)

âˆ’ âˆ‡F (k)

y

(w(k),e(cid:48)âˆ’1

y

2ï£¹
(cid:13)
(cid:13)
ï£» + 2Î·2
ï£º
(cid:13)
)
(cid:13)
(cid:13)

k

Ek

ï£®

ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

e(cid:48)=1

âˆ‡F (k)
y

(w(k),e(cid:48)âˆ’1

y

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)

2ï£¹

(cid:32)

â‰¤ 4(e âˆ’ 1)Î·2
k

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y + 2Î·2
k

Ek

ï£®

ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

e(cid:48)=1

âˆ‡F (k)
y

(w(k),e(cid:48)âˆ’1

y

(cid:124)

(cid:123)(cid:122)
(a)

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)

2ï£¹

,
ï£»

(cid:125)

ï£»

(62)

where we used Cauchyâ€“Schwarz inequality, the fact that noise of SGD is zero mean, and Lemma 2. We then bound term (a)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

25

in (62) as follows:

2Î·2
k

Ek

ï£®

ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eâˆ’1
(cid:88)

e(cid:48)=1

âˆ‡F (k)
y

(w(k),e(cid:48)âˆ’1

y

(cid:13)
(cid:13)
(cid:13)
)
(cid:13)
(cid:13)

2ï£¹
ï£» â‰¤ 2Î·2

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

(w(k),e(cid:48)âˆ’1

y

) âˆ’ âˆ‡F (k)

y

(w(k)) + âˆ‡F (k)

y

â‰¤4Î·2

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

â‰¤ 4Î·2

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

ï£°

ï£®

ï£°

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)
ï£®

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)
ï£®

(w(k),e(cid:48)âˆ’1

y

) âˆ’ âˆ‡F (k)

y

(w(k))

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(w(k))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(w(k),e(cid:48)âˆ’1

y

) âˆ’ âˆ‡F (k)

y

2ï£¹
ï£» + 4Î·2

(cid:13)
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(cid:13)
2
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

â‰¤ 4Î·2

kÎ²2(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

ï£°

(cid:13)
(cid:13)
w(k),e(cid:48)âˆ’1
(cid:13)
(cid:13)
(cid:13)

y

âˆ’ w(k)

2ï£¹
ï£» + 4Î·2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(cid:13)
2
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

,

ï£®

ï£°

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)
2ï£¹
ï£» + 4Î·2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2ï£¹

(cid:13)
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

ï£»

(63)

where we used Cauchy-Schwarz inequality repeatedly and applied the Î²-smoothness of the loss function. Replacing the above
expression in (62) yields

(cid:20)(cid:13)
(cid:13)w(k) âˆ’ w(k),eâˆ’1
(cid:13)

y

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

(cid:32)

â‰¤4(e âˆ’ 1)Î·2
k

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

+ 4Î·2

kÎ²2(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

which implies:

Î˜2
y

(Ïƒ(k)
y )2
B(k)
y
(cid:13)
(cid:13)
w(k),e(cid:48)âˆ’1
(cid:13)
(cid:13)
(cid:13)

y

ï£®

ï£°

âˆ’ w(k)

2ï£¹
ï£» + 4Î·2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k(e âˆ’ 1)

eâˆ’1
(cid:88)

e(cid:48)=1

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(cid:13)
2
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

,

(64)

e(k)
y
(cid:88)

e=1

(cid:20)(cid:13)
(cid:13)w(k) âˆ’ w(k),eâˆ’1
(cid:13)

y

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

â‰¤ 4Î·2
k

(cid:32)

(e âˆ’ 1)

1 âˆ’

e(k)
y
(cid:88)

e=1

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y

+ 4Î·2

kÎ²2

e(k)
y
(cid:88)

(e âˆ’ 1)

e=1

eâˆ’1
(cid:88)

e(cid:48)=1

Ek

ï£®

ï£°

(cid:13)
(cid:13)
w(k),e(cid:48)âˆ’1
(cid:13)
(cid:13)
(cid:13)

y

âˆ’ w(k)

2ï£¹
ï£» + 4Î·2
k

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

e(k)
y
(cid:88)

(e âˆ’ 1)

e=1

eâˆ’1
(cid:88)

e(cid:48)=1

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(cid:13)
2
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

â‰¤ 4Î·2
k

(cid:16)

e(k)
y

(cid:17) (cid:16)

e(k)
y âˆ’ 1

(cid:17)

+ 4Î·2

kÎ²2 (cid:16)

e(k)
y

(cid:17) (cid:16)

e(k)
y âˆ’ 1

(cid:17)

(cid:33)

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y

(cid:32)

B(k)
y
D(k)
y
ï£®

Ek

ï£°

1 âˆ’

e(k)
y
(cid:88)

e=1

(cid:13)
(cid:13)
w(k),eâˆ’1
(cid:13)
(cid:13)
(cid:13)

y

âˆ’ w(k)

2ï£¹
ï£» + 4Î·2
k

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:16)

e(k)
y

(cid:17) (cid:16)

e(k)
y âˆ’ 1

(cid:17)

e(k)
y
(cid:88)

e=1

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(w(k))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

,

(65)

Assuming Î·k â‰¤

2Î²

(cid:18)

(cid:113)

y (e(k)
e(k)

y âˆ’ 1)

(cid:19)âˆ’1

, âˆ€n, we get

e(k)
y
(cid:88)

e=1

(cid:20)(cid:13)
(cid:13)w(k) âˆ’ w(k),eâˆ’1
(cid:13)

y

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

â‰¤

Ek

(cid:16)

e(k)
y

4Î·2
k

(cid:17) (cid:16)

e(k)
y âˆ’ 1

(cid:17) (cid:18)

1 âˆ’

B(k)
y
D(k)
y

(cid:19) (Ïƒ(k)
y )2
B(k)
y

Î˜2
y

1 âˆ’ 4Î·2

kÎ²2e(k)

y

(cid:16)

(cid:17)

e(k)
y âˆ’ 1
(cid:17)

(cid:16)

e(k)
y

4Î·2
k

(cid:17)2 (cid:16)

1 âˆ’ 4Î·2

kÎ²2e(k)

y

+

e(k)
y âˆ’ 1
(cid:16)

e(k)
y âˆ’ 1

(cid:17)

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(cid:13)
2
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

.

(66)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

26

Replacing the above expression in (61), we get:

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

âˆ‡F (k)
y

(w(k),eâˆ’1
y

)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

â‰¤ Î²2 (cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

e(k)
y
(cid:88)

e=1

(cid:20)(cid:13)
(cid:13)w(k) âˆ’ w(k),eâˆ’1
(cid:13)

y

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

(cid:13)
(cid:13)
(cid:13)
âˆ‡F (k)(w(k)) âˆ’
(cid:13)
(cid:13)
(cid:13)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m
ï£®

â‰¤ Î²2 (cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

ï£¯
ï£¯
ï£°

(cid:17) (cid:16)

(cid:16)

e(k)
y

e(k)
y âˆ’ 1

4Î·2
k

(cid:17) (cid:18)

1 âˆ’

B(k)
y
D(k)
y

(cid:19) (Ïƒ(k)
y )2
B(k)
y

Î˜2
y

1 âˆ’ 4Î·2

kÎ²2e(k)

y

(cid:16)

(cid:17)

e(k)
y âˆ’ 1

(cid:16)

e(k)
y

4Î·2
k

(cid:17)2 (cid:16)

1 âˆ’ 4Î·2

kÎ²2e(k)

y

(cid:17)

e(k)
y âˆ’ 1
(cid:16)

e(k)
y âˆ’ 1

(cid:17)

(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

(cid:13)
2
(cid:13)
(w(k))
(cid:13)
(cid:13)
(cid:13)

ï£¹

ï£º
ï£º
ï£»

4Î²2Î·2

ke(k)

y

(cid:16)

(cid:17) (cid:18)

e(k)
y âˆ’ 1

1 âˆ’

B(k)
y
D(k)
y

(cid:19) (Ïƒ(k)
y )2
B(k)
y

Î˜2
y

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)e(k)

y

1 âˆ’ 4Î·2
(cid:16)

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

4Î²2Î·2

y

ke(k)
kÎ²2e(k)

y

e(k)
y âˆ’ 1
(cid:16)
e(k)
y âˆ’ 1

1 âˆ’ 4Î·2

4Î²2Î·2

ke(k)

y

(cid:16)

e(k)
y âˆ’ 1

1 âˆ’ 4Î·2

(cid:88)

(cid:88)

(cid:17)

mâˆˆM

yâˆˆN (k)
m
(cid:17) (cid:18)

(cid:16)

4Î²2Î·2
k

e(k)
y âˆ’ 1

1 âˆ’ 4Î·2

kÎ²2e(k)

y

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m
ke(k)
kÎ²2e(k)

max

max

4Î²2Î·2

1 âˆ’ 4Î·2

D(k)
y
D(k)e(k)
(cid:16)

y

(cid:17)

e(k)
max âˆ’ 1
(cid:16)

e(k)
max âˆ’ 1

(cid:88)

(cid:88)

D(k)
y
D(k)

mâˆˆM

(cid:16)

yâˆˆN (k)
m
ke(k)
kÎ²2e(k)

max

max

4Î²2Î·2

1 âˆ’ 4Î·2

(cid:17)

e(k)
max âˆ’ 1
(cid:16)

e(k)
max âˆ’ 1

(cid:16)
e(k)
y âˆ’ 1

(cid:17)

y

kÎ²2e(k)
(cid:17)
(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)
(cid:17) (cid:18)

(cid:17)

(w(k))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:19) (Ïƒ(k)
y )2
B(k)
y

Î˜2
y

1 âˆ’

B(k)
y
D(k)
y

(cid:16)
e(k)
y âˆ’ 1

(cid:17)

y

kÎ²2e(k)
(cid:13)
(cid:13)
âˆ‡F (k)
(cid:13)
(cid:13)
y
(cid:13)

D(k)
y
D(k)

(w(k))

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1 âˆ’

(cid:19) (Ïƒ(k)
y )2
B(k)
y
(cid:17)

B(k)
y
D(k)
y
(cid:16)
e(k)
y âˆ’ 1

Î˜2
y

(cid:18)

Î¶1

(cid:17)

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

(cid:19)

+ Î¶2

,

+

=

+

â‰¤

+

â‰¤

+

where we used e(k)
expression in (60) gives us

max = maxnâˆˆN {e(k)

(67)
y }, and the bounded dissimilarity of local gradients (Assumption 3). Replacing the above

(cid:104)

(cid:105)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) âˆ’

ï£«

ï£­

Î·k
4

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

ï£«

+

ï£­

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

ï£®

ï£¯
ï£¯
ï£°

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

(cid:16)

e(k)
y âˆ’ 1

(cid:17) (cid:18)

1 âˆ’

4Î²2Î·2
k

1 âˆ’ 4Î·2

kÎ²2e(k)

y

(cid:16)

(cid:19) (Ïƒ(k)
y )2
B(k)
y
(cid:17)

B(k)
y
D(k)
y
e(k)
y âˆ’ 1

Î˜2
y

4Î²2Î·2

+

1 âˆ’ 4Î·2

(cid:16)

max

ke(k)
kÎ²2e(k)

max

(cid:17)

(cid:18)

e(k)
max âˆ’ 1
(cid:16)

e(k)
max âˆ’ 1

(cid:17)

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

Î¶1

+ Î¶2

(cid:19)

ï£¹

ï£º
ï£º
ï£»

+

3
2

Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

ï£«

+ 2Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y,

(68)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

27

which implies

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) +

Î·k
2

(cid:88)

nâˆˆN

D(k)

y e(k)
y
D(k)

ï£«

ï£­

+

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£«

ï£¬
ï£¬
ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

e(k)
max

4Î·2

kÎ²2 (cid:16)
1 âˆ’ 4Î·2

max

kÎ²2e(k)
(cid:17) (cid:18)

1 âˆ’

(cid:17) (cid:16)

(cid:17)

e(k)
max âˆ’ 1
(cid:16)

e(k)
max âˆ’ 1
(cid:19) (Ïƒ(k)
y )2
B(k)
y
(cid:17)

B(k)
y
D(k)
y
e(k)
max âˆ’ 1

1 âˆ’ 4Î·2

kÎ²2e(k)

max

(cid:16)

(cid:16)

4Î²2Î·2
k

e(k)
y âˆ’ 1

ï£¶

ï£¸

1
2

(cid:13)
(cid:13)
2
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

(cid:17) Î¶1 âˆ’

Î˜2
y

+

4Î¶2Î·2

kÎ²2 (cid:16)
1 âˆ’ 4Î·2

(cid:17) (cid:16)

e(k)
max

(cid:17)

e(k)
max âˆ’ 1
(cid:17)

e(k)
max âˆ’ 1

(cid:16)

kÎ²2e(k)

max

+

3
2

Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

ï£«

+ 2Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

B(k)
y
D(k)
y

ï£¶

ï£·
ï£·
ï£¸

(cid:33)

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

(69)

Assuming

4Î·2

1âˆ’4Î·2

kÎ²2(e(k)
max)(e(k)
maxâˆ’1)
(cid:16)
kÎ²2e(k)
e(k)
maxâˆ’1
max
(cid:114)

size choice of Î·k â‰¤ 1
2Î²

(cid:16)

(4Î¶1+1)

1
e(k)
max

(cid:16)

e(k)
maxâˆ’1

(cid:17)(cid:17) , we get

(cid:17) Î¶1 â‰¤ 1

4 , implying

1
kÎ²2e(k)

max

1âˆ’4Î·2

(cid:16)

e(k)
maxâˆ’1

(cid:17) â‰¤ 1+4Î¶1

Î¶1

â‰¤ 5, which can be obtained under the step

(cid:105)
(cid:104)
F (k)(w(k+1))

Ek

â‰¤ F (k)(w(k)) âˆ’

1
8

Î·k

(cid:13)
(cid:13)
2 (cid:88)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)
(cid:13)
(cid:13)

nâˆˆN

D(k)

y e(k)
y
D(k)

+

Î·k
2

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£«

ï£¬
ï£¬
ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

20Î²2Î·2
k

(cid:16)

e(k)
y âˆ’ 1

(cid:17)

(cid:32)

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y + 20Î¶2Î·2

kÎ²2 (cid:16)

e(k)
max

(cid:17) (cid:16)

e(k)
max âˆ’ 1

(cid:17)

ï£¶

ï£·
ï£·
ï£¸

+

3
2

Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

ï£«

+ 2Î²Î·2
k

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶
2

ï£¸

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

(70)

Rearranging the terms of the above bound gives the following bound on the norm of gradient:

(cid:13)
(cid:13)âˆ‡F (k)(w(k))
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

â‰¤

Î·k

F (k)(w(k)) âˆ’ Ek
(cid:80)
(cid:80)

mâˆˆM

(cid:88)

(cid:88)

+

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

80Î²2Î·2
k

(cid:16)

(cid:17)

e(k)
y âˆ’ 1

(cid:2)F (k)(w(k+1))(cid:3)
y(cid:48) e(k)
D(k)
y(cid:48) /(8D(k))
(cid:33)
(Ïƒ(k)
B(k)
y )2
y
B(k)
D(k)
y
y

Î˜2

y(cid:48)âˆˆN (k)
m

(cid:32)

1 âˆ’

y + 80Î¶2Î·2

kÎ²2 (cid:16)

e(k)
max

(cid:17) (cid:16)

e(k)
max âˆ’ 1

(cid:17)

+ 24Ek

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

+ 16Î²Î·k

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

(71)

Note that F (k)(w(k)) in the ï¬rst term on the right hand side of the above bound is in fact the loss under which the global
aggregation started from, i.e., F (k)(w(k)|, D(k)) and F (k)(w(k+1)) is the loss under which the global aggregation concludes,
i.e., F (k)(w(k+1)|D(k)). We next ï¬nd the connection between F (k)(w(k)|D(k)) and the actual loss under which iteration k âˆ’ 1
has been concluded, i.e., F (kâˆ’1)(w(k)|D(kâˆ’1)). Using the deï¬nition of model/concept drift in Deï¬nition 3, since the global
loss is deï¬ned as the loss per data point we have:

F (k)(w(k)|D(k)) =

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

(cid:88)

(cid:88)

mâˆˆM
(cid:88)

yâˆˆN (k)
m
(cid:88)

mâˆˆM

yâˆˆN (k)
m

â‰¤

=

(cid:34)

D(k)
y
D(k)

F (k)
y

(w(k)|D(k)

y ) âˆ’

D(kâˆ’1)
y
D(kâˆ’1)

F (kâˆ’1)

y

(w(k)|D(kâˆ’1)

y

) +

D(kâˆ’1)
y
D(kâˆ’1)

F (kâˆ’1)

y

(w(k)|D(kâˆ’1)

y

)

(cid:35)

âˆ†(k)

y +

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(kâˆ’1)
y
D(kâˆ’1)

F (kâˆ’1)

y

(w(k)|D(kâˆ’1)

y

)

âˆ†(k)

y + F (kâˆ’1)(w(k)|D(kâˆ’1)) = âˆ†(k) + F (kâˆ’1)(w(k)), k â‰¥ 1.

(72)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

28

Taking total expectation from both hand sides of (71) and taking the summation over global aggregation index implies

1
K

Kâˆ’1
(cid:88)

k=0

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)
(cid:104)

E

â‰¤

1
K

F (0)(w(0)) âˆ’ F (0)(w(1))

Î·k

(cid:80)

mâˆˆM

(cid:80)

y(cid:48)âˆˆN (k)
m

âˆ†(k)

D(k)

y(cid:48) e(k)

y(cid:48) /(8D(k))

+

1
K

Kâˆ’1
(cid:88)

k=1

F (kâˆ’1)(w(k)) âˆ’ F (k)(w(k+1))

(cid:80)

Î·k

mâˆˆM

(cid:80)

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)

y(cid:48) /(8D(k))

Kâˆ’1
(cid:88)

+

1
K

k=1

Î·k

(cid:80)

mâˆˆM

(cid:80)

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)

+

1
K

Kâˆ’1
(cid:88)

(cid:88)

(cid:88)

k=0

mâˆˆM

yâˆˆN (k)
m

D(k)
y
D(k)

(cid:16)

80Î²2Î·2
k

y(cid:48) /(8D(k))
(cid:32)

(cid:17)

e(k)
y âˆ’ 1

1 âˆ’

B(k)
y
D(k)
y

(cid:33)

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y +

1
K

Kâˆ’1
(cid:88)

k=0

80Î¶2Î·2

kÎ²2 (cid:16)

e(k)
max

(cid:17) (cid:16)

e(k)
max âˆ’ 1

(cid:17)

+

1
K

Kâˆ’1
(cid:88)

k=0

24Ek

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)

mk

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

+

1
K

Kâˆ’1
(cid:88)

k=0

ï£«

ï£­

16Î²Î·k

(cid:88)

(cid:88)

mâˆˆM

y(cid:48)âˆˆN (k)
m

D(k)

y(cid:48) e(k)
y(cid:48)
D(k)

ï£¶

ï£¸

ï£«

ï£­

(cid:88)

(cid:88)

mâˆˆM

yâˆˆN (k)
m

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y.(73)

Assuming the choice of step size Î·k =

(cid:113)

Î±
Ke(k)
avg

devices, we get:

, where e(k)

avg denotes the average number of local iterations across the participating

1
K

Kâˆ’1
(cid:88)

k=0

(cid:104)

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)

E

â‰¤

+

80Î²2Î±2
K 2emin
avg

Kâˆ’1
(cid:88)

(cid:88)

k=0

mâˆˆM

(cid:88)

yâˆˆN (k)
m

8(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg
D(k)
y
D(k)

(cid:16)

(cid:16)

F (0)(w(0)) âˆ’ F (k)(cid:63) (cid:17)

+

8(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg

(cid:17)

e(k)
y âˆ’ 1

(cid:32)

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y +

Kâˆ’1
(cid:88)

âˆ†(k)

k=1
80Î²2Î±2
K 2emin
avg

Kâˆ’1
(cid:88)

k=0

(cid:16)

Î¶2

e(k)
max

(cid:17) (cid:16)

(cid:17)

e(k)
max âˆ’ 1

+

1
K

Kâˆ’1
(cid:88)

k=0

24 Ek

(cid:124)

mk

(cid:20)(cid:13)
(cid:13)c(k)
(cid:13)
(cid:123)(cid:122)
(a)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

+

(cid:125)

16Î²Î±Ë†emax
avg
âˆš
(cid:113)

K

K

emin
avg

Kâˆ’1
(cid:88)

(cid:88)

(cid:88)

k=0

mâˆˆM

yâˆˆN (k)
m

ï£«

ï£­

D(k)
y
(cid:113)

D(k)

e(k)
y

ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

(74)

We next aim to bound term (a) in (74). Let (cid:103)âˆ‡F

gradient and the gradient of its associated users, and (cid:100)âˆ‡F
communications concludes.

(k)
m denote the initial local aggregated gradient at ES m, containing its own
(k)
m denote the gradient at ES m after the consensus through P2P

As explained in (42), we have

âˆ‡F L,(k)

m =

(cid:88)

mâˆˆM

âˆ‡F A,(k)

m + e(k)
m .

On the other hand, the evolution of the local gradient during the consensus process can be described as

âˆ‡F L,(k) =

(cid:16)

Î›(k)(cid:17)Ï•(k)

âˆ‡F A,(k),

(75)

(76)

where âˆ‡F L,(k) âˆˆ RdÃ—d denotes a matrix,3 with its row m containing the ï¬nal vector of gradient at ES m (i.e., âˆ‡F L,(k)
and âˆ‡F A,(k) âˆˆ RdÃ—d denotes a matrix, with its row m containing the initial gradient vector at ES m (i.e., âˆ‡F A,(k)
Î›(k) = [Î»(k)
aggregation round k.

m ),
m ). In (76),
i,j ]i,jâˆˆM is the consensus matrix across the ES network and Ï•(k) denotes the rounds of P2P communications at the

Let matrix âˆ‡F P,(k) denote the matrix of true/perfect average of the gradient vectors across the ESs, which is given by

âˆ‡F P,(k) =

1M 1(cid:62)

M âˆ‡F A,(k)

m

M

.

(77)

Also, let âˆ‡F P,(k)
1(cid:62) (cid:16)

âˆ‡F L,(k) âˆ’ âˆ‡F A,(k)(cid:17)

m denote the m-th row of âˆ‡F P,(k). Since the consensus error is zero mean [30] across the ESs, we have

= 0 implying that (11(cid:62))

(cid:16)

âˆ‡F L,(k) âˆ’ âˆ‡F A,(k)(cid:17)

= 0. Thus, we get

âˆ‡F L,(k) âˆ’ âˆ‡F P,(k) =

=

=

(cid:19) (cid:16)

(cid:18)

(cid:18)

I âˆ’

I âˆ’

11(cid:62)
M
11(cid:62)
M
Î›(k)(cid:17)Ï•(k)

(cid:18)(cid:16)

âˆ’

(cid:19) (cid:18)(cid:16)

Î›(k)(cid:17)Ï•(k)
(cid:19) (cid:16)

11(cid:62)
M

3d denotes the size/length of the gradient vector.

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)

,

âˆ‡F L,(k) âˆ’ âˆ‡F P,(k)(cid:17)

=

(cid:18)

I âˆ’

11(cid:62)
M
Î›(k)(cid:17)Ï•(k)

(cid:19) (cid:18)(cid:16)

Î›(k)(cid:17)Ï•(k)
(cid:19)

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)

(cid:19)

(78)

âˆ‡F P,(k)

âˆ‡F A,(k) âˆ’

(cid:16)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

29

where the above derivations are obtained based on the following properties: (i) (cid:0)Î›(k)(cid:1)Ï•(k)
11(cid:62)
M

(cid:0)Î›(k)(cid:1)Ï•(k)

= 11(cid:62)

M . We ï¬nally get
(cid:32)

(cid:107)c(k)

m (cid:107)2 â‰¤ trace

(cid:16)

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)(cid:62) (cid:18)(cid:16)

Î›(k)(cid:17)Ï•(k)

âˆ’

(cid:19)2

11(cid:62)
M

(cid:16)

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)

(cid:33)

âˆ‡F P,(k) = âˆ‡F P,(k), and (ii)

(cid:32)

(cid:16)

= trace

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)(cid:62) (cid:18)(cid:16)

Î›(k)(cid:17)Ï•(k) (cid:20)

I âˆ’

(cid:21)(cid:19)2

11(cid:62)
M

(cid:16)

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)

(cid:33)

ï£«

(cid:16)

ï£¬
ï£­

= trace

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)(cid:62)

ï£«

ï£­

(cid:16)

Î›(k)(cid:17)Ï•(k) (cid:20)

I âˆ’

2

(cid:21)Ï•(k)ï£¶
ï£¸

(cid:16)

11(cid:62)
M

ï£¶

âˆ‡F A,(k) âˆ’ âˆ‡F P,(k)(cid:17)

ï£·
ï£¸

(79)

â‰¤ (Î»(k))2Ï•(k) (cid:88)

(cid:107)âˆ‡F A,(k)

m(cid:48) âˆ’ âˆ‡F P,(k)

m(cid:48)

(cid:107)2

â‰¤

1
M

m(cid:48)âˆˆM

(Î»(k))2Ï•(k) (cid:88)

m(cid:48),m(cid:48)(cid:48)âˆˆM

(cid:107)âˆ‡F A,(k)

m(cid:48) âˆ’ âˆ‡F A,(k)

m(cid:48)(cid:48) (cid:107)2

â‰¤ M (Î»(k))2Ï•(k)

max
m(cid:48),m(cid:48)(cid:48)âˆˆM

(cid:107)âˆ‡F A,(k)

m(cid:48) âˆ’ âˆ‡F A,(k)

m(cid:48)(cid:48) (cid:107)2 â‰¤ M (Î»(k))2Ï•(k) (cid:16)

Î(k)(cid:17)2

.

Replacing the above result back in (74), we get the ï¬nal result

1
K

Kâˆ’1
(cid:88)

k=0

(cid:104)

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)

E

â‰¤

+

80Î²2Î±2
K 2emin
avg

Kâˆ’1
(cid:88)

(cid:88)

k=0

mâˆˆM

(cid:88)

yâˆˆN (k)
m

8(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg
D(k)
y
D(k)

(cid:16)

(cid:16)

F (0)(w(0)) âˆ’ F (k)(cid:63) (cid:17)

+

8(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg

(cid:17)

e(k)
y âˆ’ 1

(cid:32)

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y +

Kâˆ’1
(cid:88)

âˆ†(k)

k=1
80Î²2Î±2
K 2emin
avg

+

1
K

Kâˆ’1
(cid:88)

k=0

24M (Î»(k))2Ï•(k) (cid:16)

Î(k)(cid:17)2

+

16Î²Î±Ë†emax
avg
âˆš
(cid:113)

K

K

emin
avg

Kâˆ’1
(cid:88)

(cid:88)

(cid:88)

k=0

mâˆˆM

yâˆˆN (k)
m

ï£«

ï£­

D(k)
y
(cid:113)

D(k)

e(k)
y

Kâˆ’1
(cid:88)

(cid:16)

Î¶2

e(k)
max

(cid:17) (cid:16)

(cid:17)

e(k)
max âˆ’ 1

k=0
ï£¶

2 (cid:32)

ï£¸

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2
y.

(80)

Assuming âˆ†(k) â‰¤ Î¥

K and considering the assumption

y â‰¤ Ï‘ simpliï¬es the bound in (13) as follows:

APPENDIX B
PROOF OF COROLLARY 1
B(k)
y
D(k)
y

(cid:19) (Ïƒ(k)
y )2
B(k)
y

1 âˆ’

(cid:18)

Î˜2

1
K

Kâˆ’1
(cid:88)

k=0

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)
(cid:104)

E

â‰¤

F (0)(w(0)) âˆ’ F (k)(cid:63) (cid:17)
(cid:16)

+

8Î¥(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg

+

K (emax âˆ’ 1) Ï‘ +

24M (Î»(k))2Ï•(k) (cid:16)

Î(k)(cid:17)2

+

80Î²2Î±2
K 2emin
avg
Kâˆ’1
(cid:88)

k=0

+

1
K

KÎ¶2 (emax) (emax âˆ’ 1)

16Î²Î±Ë†emax
avg
âˆš
(cid:113)

K

K

emin
avg

KÏ‘.

8(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg
80Î²2Î±2
K 2emin
avg

Assuming Ï•(k) â‰¥ 1
2

(cid:18)

(cid:20)
logÎ»(k)

âˆš

Î¾

K(Î(k))2

M (k)

(cid:19)(cid:21)+

implies that (note that Î»(k) < 1)

(cid:32)

2Ï•(k) â‰¥ logÎ»(k)

âˆš

Î¾

(cid:33)

K (cid:0)Î(k)(cid:1)2

M (k)

â‡’ (Î»(k))2Ï•(k)

â‰¤

âˆš

Î¾

â‡’ M (k)(Î»(k))2Ï•(k) (cid:16)

K (cid:0)Î(k)(cid:1)2
Î(k)(cid:17)2

M (k)
âˆš

â‰¤ Î¾/

K.

Replacing this result back in (81) yields

1
K

Kâˆ’1
(cid:88)

k=0

(cid:104)

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)

E

â‰¤

8(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg

(cid:16)

F (0)(w(0)) âˆ’ F (k)(cid:63) (cid:17)

+

8Î¥(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg

(81)

(82)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

30

+

80Î²2Î±2
Kemin
avg

(emax âˆ’ 1) Ï‘ +

80Î²2Î±2
Kemin
avg

Î¶2 (emax) (emax âˆ’ 1) + 24

Î¾
âˆš
K

+

16Î²Î±Ë†emax
avg
âˆš
(cid:113)

K

emin
avg

Ï‘,

and thus

1
K

Kâˆ’1
(cid:88)

k=0

(cid:104)

(cid:107)âˆ‡F (k)(w(k))(cid:107)2(cid:105)

E

= O

+ O

(cid:18) Î²2Î±2
Kemin
avg

Î¶2 (emax) (emax âˆ’ 1)

(cid:16)

âˆš

1/

(cid:17)

,

K

= O

which concludes the proof.

(cid:32) (cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg
(cid:18) Î¾
âˆš
K

+ O

(cid:19)

(cid:33)

+ O

(cid:33)

(cid:32) Î¥(cid:112)emax
avg
âˆš
Î±Ë†emin
K
avg

+ O

(cid:18) Î²2Î±2
Kemin
avg

(cid:19)

(emax âˆ’ 1) Ï‘

(cid:19)

+ O

ï£«

ï£­

Î²Î±Ë†emax
avg
(cid:113)

âˆš

K

emin
avg

ï£¶

Ï‘

ï£¸

(83)

APPENDIX C
CHARACTERIZATION OF THE GRADIENT OF THE CRITICâ€™S LOSS

Inspired by [44], our proof for the Lipschitz continuity property of the MSPBE loss functionâ€™s gradient is presented as

below. First, the loss function in (39) can be re-written as

EÎ¸(Ï‰) =

1
2

||VÏ‰ âˆ’ Î›(BÎ¸VÏ‰)||2=

1
2

||Î›(VÏ‰ âˆ’ BÎ¸VÏ‰)||2, (since VÏ‰ = Î›VÏ‰),

which is upper-bounded by its expectation value given by the loss across the entire system state vector H:

EÎ¸(Ï‰) â‰¤

1
2

||Î›(VÏ‰ âˆ’ BÎ¸VÏ‰)||2

H ,

(84)

(85)

where H is the diagonal matrix whose elements are within the stationary system state distribution dÏ€Î¸(s), âˆ€s âˆˆ S as deï¬ned
in section IV-D. Under this stationary condition, (85) can be further analyzed as:

EÎ¸(Ï‰) =

1
2

[Î›(VÏ‰ âˆ’ BÎ¸VÏ‰)](cid:62) H [Î›(VÏ‰ âˆ’ BÎ¸VÏ‰)]

=

=

1
2
1
2

(VÏ‰ âˆ’ BÎ¸VÏ‰)(cid:62)Î›(cid:62)HÎ›(VÏ‰ âˆ’ BÎ¸VÏ‰)

âˆš

||Â¯Î›

H(VÏ‰ âˆ’ BÎ¸VÏ‰)||2
2,

âˆš

where Â¯Î› =
of the loss function is given by

HÏ†(cid:62)(Ï†HÏ†(cid:62))âˆ’1Ï†

âˆš

H is an orthogonal projector of a column element of

H(Ï‰) = Ï†(I âˆ’ Î³P )(cid:62)

âˆš

âˆš

H Â¯Î›

H(I âˆ’ Î³P )Ï†(cid:62),

(86)

(87)

(88)

âˆš

HÏ†(cid:62). Then, the Hessian product

(89)

where I âˆˆ R|S|Ã—|S| is the identity matrix, and P is the transition probability as deï¬ned in Section IV-A. Since EÎ¸(Ï‰) is
convex, its gradient is (cid:96)-Lipschitz if

holds. Indeed, we have

Ï‰(cid:62)H(Ï‰)Ï‰ â‰¤ l||Ï‰||2
2

âˆš

âˆš

H Â¯Î›

H(I âˆ’ Î³P )Ï†(cid:62)Ï‰

Ï‰(cid:62)H(Ï‰)Ï‰ = Ï‰(cid:62)Ï†(I âˆ’ Î³P )(cid:62)
= ||Â¯Î›
âˆš
= ||

âˆš

H(I âˆ’ Î³P )Ï†(cid:62)Ï‰||2
2

âˆš

âˆš

2 âˆ’ 2Î³Ï‰(cid:62)Ï†HP Ï†(cid:62)Ï‰ + Î³2||Â¯Î›
âˆš
2 âˆ’ 2Î³Ï‰(cid:62)Ï†HP Ï†(cid:62)Ï‰ + Î³2||

HÏ†Ï‰||2
HÏ†Ï‰||2
H(I âˆ’ Î³P )Ï†(cid:62)Ï‰||2
2.

â‰¤ ||

= ||

âˆš

HP Ï†(cid:62)Ï‰||2
2

HP Ï†(cid:62)Ï‰||2
2

Using the Cauchy-Schwartz inequality, we have

Ï‰(cid:62)H(Ï‰)Ï‰ â‰¤

â‰¤

(cid:16)

(cid:16)

âˆš

||

âˆš

||

HÏ†(cid:62)Ï‰||2 + Î³||

âˆš

(cid:17)2

HP Ï†(cid:62)Ï‰||2
(cid:17)2

HÏ†(cid:62)Ï‰||2

âˆš

HÏ†(cid:62)Ï‰||2
âˆš

2 + Î³||

= (1 + Î³)2||

HÏ†(cid:62)Ï‰||2
2.

(90)

(91)

(92)

ACCEPTED TO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS

Here, we have

âˆš

||

HÏ†(cid:62)Ï‰||2

2 = ||Ï†(cid:62)Ï‰||2

P =

(cid:88)

di (cid:16)

(cid:62)

(Ï†i)

Ï‰

(cid:17)2

(cid:88)

â‰¤

iâˆˆ|S|

di||Ï‰i||2

2||Î¸i||2

2 â‰¤

iâˆˆ|S|

(cid:16)

max
i

||Ï†i||2
2

(cid:17)

||Î¸i||2
2.

Thus, we get

Ï‰(cid:62)H(Ï‰)Ï‰ â‰¤ (1 + Î³)2 (cid:16)

max
i

||Ï†i||2
2

(cid:17)

||Î¸i||2
2,

which leads to 90, and completes our proof.

31

(93)

(94)

APPENDIX D
MINI-BATCH SGD NOISE CHARACTERIZATION
Lemma 2. During each aggregation round t, for each MD/ES y âˆˆ N âˆª M, the variance of stochastic gradient during
mini-batch gradient descent iteration k, i.e., (cid:101)âˆ‡F (t)
y (x) is upper-bounded by

E

ï£®

ï£¯
ï£°

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

dâˆˆB(k),e
y

âˆ‡f (w(k),eâˆ’1
y
B(k)
y

, d)

âˆ’ âˆ‡F (k)

y

(w(k),eâˆ’1
y

)

2ï£¹

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32)

ï£º
ï£» â‰¤ 2

1 âˆ’

(cid:33)

B(k)
y
D(k)
y

(Ïƒ(k)
y )2
B(k)
y

Î˜2

y, âˆ€e,

(95)

where Ïƒ(k)

y

denotes the sampled variance of data at the respective node.

Proof. The proof can be easily carried out using the result on the variance of of simple random sampling in [45] and our
deï¬nition of the data variability in Deï¬nition 2, and thus omitted for brevity.

