This article has been accepted for publication in a future issue of Australasian Computer Science Week 2022 (ACSW 2022), but has not been fully edited  Content may change prior to final publication 
Citation information: DOI  JO  1145/3511616 3513100, ACSW 2022 

Initial Submission on  November 29, 2021 ; Initial Acceptance on  December 18, 2021; Final Submission on January 26, 2022; Presented in Australasian  Information 
Security Conference {AISC  2022) on  February 14, 2022, date of publication in ACM Digital Library XXXX 00, 0000, date of current version  February 26, 2022. 

Digital Object identifier 10.1145/3511616.3513100 

Privacy of Fitness Applications and Consent Management in 
Blockchain 

May Alhajri*1, Ahmad Salehi S.*§,  and Carsten Rudolph* 
*Monash University, Melbourne, Australia, §RMIT University, Melbourne, Australia, 
1King Faisal University, Al-Ahsa, Saudi Arabia 
{may.alhajri,ahmad.salehishahraki,carsten.rudolph}@monash.edu 
{ahmad.salehi.shahraki@rmit.edu.au},{mnalhajri@kfu.edu.sa} 

ABSTRACT 
The rapid advances in fitness wearable devices are redefining pri 
vacy around interactions. Fitness wearables devices record a con 
siderable amount of sensitive and private details about exercise, 
blood oxygen level, and heart rate. Privacy concerns have emerged 
about the interactions between an individual's raw fitness data and 
data analysis by the providers of fitness apps and wearable devices. 
This paper describes the importance of adopting and applying legal 
frameworks within the fitness tracker ecosystem. In this review, 
we describe the studies on the current privacy policies of fitness 
app providers, heuristically evaluate the methods for consent man 
agement by fitness providers, summarize the gaps identified in our 
review of these studies, and discuss potential solutions for filling 
the gaps identified. We  have identified four main problems related 
to preserving the privacy of users of fitness apps: lack of system 
transparency, lack of privacy policy legibility, concerns regarding 
one-time consent, and issues of noncompliance regarding consent 
management. After discussing feasible solutions, we conclude by 
describing how blockchain is  suitable for  solving these  privacy 
issues. 

CCS CONCEPTS 
• Security and privacy; • Networks; 

KEYWORDS 
Privacy, Data Protection, Legal Framework, Consent Management, 
Consent Criteria, Fitness Data, Fitness Provider, Wearable Devices 

ACM Reference Format: 
May Alhajri'1 , Ahmad Salehi s.•§, and Carsten Rudolph' . 2022. Privacy 
of Fitness Applications and Consent Management in Blockchain. In Aus 
tralasian Computer Science Week 2022 (ACSW 2022), February 14-18, 2022, 
Brisbane, Australia. ACM, New York, NY, USA, 9 pages. https://doi.org/ 10. 
1145/3511616.35!3 100 

INTRODUCTION 

1 
The recent proliferation of wearable fitness technologies (e.g., smart 
watches, fitness trackers) enables people to generate quantities of 

Permission to make digital or hard copies of all or part of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. Copyrights for components of this work owned by others than ACM 
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, 
to post on servers or to redistribute to lists, requires prior specific permission and/or a 
fee. Request permissions from permissions@acm.org. 
ACSW 2022, February  14-18, 2022, Brisbane, Australia 
©  2022 Association for Computing Machinery. 
ACM ISBN 978-1-4503-9606-6/22/ 02 .. . $15.00 
https://doi.org/10.1145/3511616.3513100 

valuable data about their health [25]. These wearable devices cap 
ture various data about physical activity and health-related data 
including information about sleep quality and quantity, number of 
steps and distance, and blood pressure [ 42]. In the context of health, 
the use of these technologies supports individuals, physicians, and 
clinical researchers by enabling accurate diagnoses and evidence 
of patients' self-reported data (20, 41]. However, as occurs with the 
adoption of any technology, some challenges have emerged. 

The main issue surrounding the data collected by wearable tech 
nologies relate to the ownership and privacy of personal health 
information. Many users have limited or no control over their data, 
knowledge about the purposes for which the data are used, or their 
rights  [25].  Privacy can be defined as the ability of users to con 
trol the sharing, collecting, and processing of their data with other 
entities (36, 39]. Privacy is an essential element for protecting an 
individual's data,  and this concept creates a significant issue for 
service providers [ 49]. For example, in the context of data sharing, 
data requestors and processors must comply with the relevant rules, 
such as the European Union's General Data Protection Regulation 
(GDPR)  [1], which makes obtaining the subject's consent essential 
to collecting, processing, and sharing their data. The GDPR  [1] im 
poses on data processors (e.g., fitness app providers) data protection 
requirements that empower users to take control of their fitness 
data. 

Researchers have highlighted privacy concerns around the use 
of fitness apps (2,  23- 25,  30- 32, 35, 47], which this review covers 
in detail. Although these  studies  have  thoroughly analyzed  the 
privacy issues related to the use of fitness apps, none were found to 
have addressed the privacy issues related to fitness apps in terms 
of dynamic consent management that uses a transparent, legally 
compliant system. Considering these challenges, studies in various 
domains  have shown empirically that blockchain technology is 
suitable for mitigating issues related to the preservation of privacy 
by managing the individual user's consent using a smart contract [7, 
16, 21, 22,  28, 38]. 

Blockchain and smart contracts have been used for consent man 
agement in different contexts and should provide a system that is 
both human centric and legally compliant. The design of the exist 
ing systems enables the management of user consent both before 
and after collecting, processing, and sharing data between the data 
subject and data requester. Smart contracts can be leveraged to man 
age user consent by allowing the user to grant or deny requests for 
access to individual health data. This is  important because the use 
of fitness data can play a significant role in improving the functions 
of various entities, including health-care providers and other orga 
nizations [ 40, 44]. For example, these data may be used by clinicians 

This work is licensed under a ACM' s traditional copyright transfer agreement  For more information, see https://authors acm org/author-services/author-rights 

This article has been accepted for publication in a fu\ure issue of Austtalasian Compu\er Science Week 2022 (ACSW 2022), but h as no\ been fully edited  Conten\ may change prior to final publica\ion 
Citation information: DOI  IO  1145/3511616 3513100, ACSW 2022 

ACSW 2022,  February 14-18, 2022,  Brisbane, Australia 

May Alhajri'"1, Ahmad Salehi s.•§, and  Carsten  Rudolph• 

to improve diagnoses, by workplace wellness programs [13], and to 
reduce health insurance costs [12], all of which may be vulnerable 
to unlawful disclosure of health data without subject's consent. 

As first step in our analysis, we reviewed the relevant data pro 
tection legal frameworks and data categorizations used by wearable 
fitness devices. We used this information to identify concerns about 
privacy issues around the use of fitness apps reported in the litera 
ture that has assessed fitness apps and privacy issues. We aimed 
to identify the privacy issues related to the consent-management 
practices of fitness apps by identifying the requirements in the ex 
isting legal frameworks for protecting fitness data and to compare 
the current privacy policies of fitness app providers with these level 
requirements. 

1.1  Our contribution 

The main research contribution of our paper are as follows. 

a)  to identify and understand the importance of adopting legal 
frameworks in the fitness tracker ecosystem and to summa 
rize the valid consent criteria under the GDPR, 

b)  to review studies that have assessed  the current privacy 
policies used by fitness  app providers,  in particular their 
consent management practices, 

c)  to evaluate heuristically the consent management of fitness 
providers that implement user consent by comparing their 
practices with the GDPR' s criteria for valid consent, and 
d)  to summarize the issues identified in the reviewed studies 
that trigger the need for feasible solutions to fill the identified 
gaps. 

1.2  Organization of this Review 
This paper is organized as follows. In Section 2, we discuss the back 
ground knowledge and related works, present a literature review of 
the current privacy policies of fitness app providers, and explain the 
current legal frameworks and importance of comp liance with these 
frameworks. In Section 3, we discuss the state of privacy used by 
fitness app providers and present our views based on the findings 
of assessments of the privacy of these wearable technologies. After 
a  synthesis of the literature, in Section 4 we identify gaps in the 
literature and, in Section 5, we discuss feasible solutions that may 
help to fill the gaps identified. In Section 6, we conclude with a 
short discussion of the overall topic. 

2  BACKGROUND 
This section presents background knowledge and discusses the cur 
rent state of knowledge about the privacy policies used by fitness 
app providers in the context of the data protection legal framework. 
It includes the authors' views and findings from several types of as 
sessments on privacy policies used by these wearable technologies. 
We focus on understanding how data processing is bound to prior 
user consent and whether this consent is valid under the GDPR [ 1] 
criteria. Then, we describe our analysis of various issues that range 
from understanding the legal frameworks that protect fitness data 
to the state of privacy current! y used by fitness apps. This review 
p aper  is organized around the following main topics. 

Legal frameworks for data protection and fitness data cat 
egorization (Section 2).  Fitness apps deal directly with individ 
ual users' information, such as health data, which are classified 
as highly sensitive data [10, 14, 31]. Hence, a  legal framework is 
needed to protect users from unwanted disclosures. 
Current state of privacy policy used by fitness app providers 
(Section 3).  Researchers have rrused serious privacy concerns about 
the use of data by fitness apps [2, 23- 25, 30- 32, 35, 47]. These con 
cerns include linguistic assessment of the privacy policies of fitness 
apps, behavioral assessment of the privacy practice of fitness apps, 
and heuristic evaluation of consent practice related to fitness apps. 
Open issues,  challenges,  and recommendations  (Section  5). 
There is no uniform standard for the data format and content col 
lected by wearable devices, and this lack of standardization may 
hinder methods to achieve consent for the management of these 
data. We discuss the existing research on consent management and 
system interoperability. Finally, we encourage future researchers to 
examine the feasibility of blockchain for addressing the problems 
identified. 

In the following section, we explore the foundational concepts for 
the fitness tracker devices and legal frameworks for data protection. 
We then discuss the initial concept of fitness data categorization. 

2.1  Legal Frameworks for Data Protection and 

Fitness Data Categorization 

Different countries have various regulations and privacy require 
ments to protect an indiv idual's data. Some of these regulations, 
including the GDPR [I], protect all forms of personal information, 
whereas others have limited scope, such as the Health Insurance 
Portability and Accountability Act 1996 (HIPAA) [33], which applies 
only to protected health information collected or held by an HIPAA 
covered entity [50]. As more information  moves to electronic form, 
increasing concern about privacy protection is expected [6]. Ac 
cordingly, several data-protection regulations and standards, in 
cluding the HIPAA to Health Level 7 (HL7), have been introduced 
to address privacy concerns and to standardize electronic informa 
tion [ 6]. However, these standards remain insufficient for meeting 
the various data types generated and rapid growth  of wearable 
fitness devices [ 15]. 

Because they are considered "noncovered entities;' fitness and 
health apps  do not need to comply w ith the HIPAA,  although 
they  may need to achieve  compliance once they  interact  with 
"covered entities" such as insurance companies and health-care 
providers  [50] . The independence of designers, technologists, and 
policymakers has created a  significant gap in which fitness  app 
providers struggle to provide human-centered system s, achieve reg 
ulation compliance, and meet the technical aspects of their services 
all at once. Many experience noncompliance issues by designing 
systems with technological functions in mind w hile overlooking 
other aspects  such  as policy requirements relating to data protec 
tion. 

Although law studies [9, 31] have argued and criticized the exist 
ing legal framework as ineffective for protecting individual health 
and fitness data from potential misuse, especial! y when gathered us 
ing wearable technologies, this paper  focuses only on the technical 
asp ects of the state of privacy w ithin the existin g legal framework. 

This work is licensed under a ACM's ttadilional copyright transfer agreemen\  For more information, see https://aulhors acm org/aulhor-services/aulhor-rights 

This article has been accepted for  publlc.ition ma furure ,ssue o f AustralasLlll Computer Science W eek 2022 (ACSW 2022), but has not been fully echted  Content may change prior to final publlc.ation 
Citation information: DOI 10 1145/3511616 3513100, ACSW 2022 

Privacy of Fitness Applications and Consent Management  in  Blockchain 

ACSW 2022, February  14-18. 2022,  Brisbane, Australia 

This form of noncompliance is a new and challenging research av 
enue. Section 3 focuses on the associated issues that fitness tracker 
providers have with privacy preservation in processing individual 
data. 

2.1. 1  Privacy Protection Through the GDPR.  The European Union's 
GDPR [1], which came into effect in May 2018, identifies six lawful 
bases for the processing of personal data to ensure that it is lawful, 
fair, and transparent. One of these legal bases, and the main focus 
of this review, is individual  consent,  which is  considered valid 
under the GDPR [1] when it fulfills certain criteria; that is, consent 
must be unambiguous,  informed, freely given,  and specific  (2]. 
Comprehensive summaries by Breen et al.  [ II) and Carvalho et 
al.  (11)  have identified all characteristics of valid consent under 
the GDPR (1). For the purpose of consistency and clarity in this 
review paper, all related aspects of valid consent characteristics 
mentioned in the aforementioned studies (8,  11 ), and the relevant 
Consent number are summarized in Table 1. 

2.1 2  Privacy Protection Through the H 1PM. Although other coun 
tries in the European Union have expanded protection to cover all 
individual data,  recent law studies  (29,  50)  suggest that the reg 
ulations in the United States, such as the HIPAA, are inefficient 
at protecting fitness data. The HIPAA was passed by the US Con 
gress in 1996 to expand health insurance coverage,  reduce costs, 
and improve quality of health care in the United States. However, 
the HIPAA is considered to lack sufficient data protection because 
it applies only to "covered entities," which are defined as "health 
plans, health care clearinghouses and a  health care provider who 
transmits any health information in electronic form" (29]. Accord 
ingly, the US Department of Health and Human Services does not 
view fitness providers as covered entities unless the fitness provider 
works directly with a covered entity as defined under the HIPAA. 
For example, in the HIPAA, fitness data are not protected unless a 
person shares data with a physician, and then only that shared copy 
is protected by the HIPAA. Against this background, this review 
paper focuses on whether current device providers are compliant 
with the GDPR, which protects health and personal data, as defined 
in GDPR's Article 4 definition l  as "personal data means any infor 
mation relating to an identified or identifiable natural person"  (1, 
p. 3). 

2.2  Fitness Data Categorization 
The consent criteria vary depending on the type of data being pro 
cessed and whether it is sensitive. For example, in Article 9 in the 
GDPR  (1 ), which discusses the process.ing of special categories of 
personal data, health data generated from wearable devices falls 
under "special categories:• As noted by Mulder (31), this data cat 
egory requires explicit C7 as well as standard informed consent 
C2  (1). Colombo and Ferrari (14) have categorized the data type 
generated from wearable  devices  into four categories: identifier, 
quasi-identifier, sensitive, and generic. The authors derived these 
categories from privacy legislation, such  as the GDPR [ 1) and data 
protection literature. These are depicted in Fig ure  1 and Table 2. 
Carminati et al.  (10)  applied Colombo and Ferrari's ( 14)  four 
data categories to fitness internet of things(IoT) applications, as 
shown in Table 2. This categorization shows that the data for most 

Data that direclly 
reveal individual 
Identity. 

Identifier 

Qllasi 
identifier 

Data auributes that in 
combination can 
uniquely identify 
individuals 

Data that reveals 
sensitive aspects 
of individual 
private life such as 
health data. 

Data that does not 
fall under the other 
three categories. 

Fig ure 1: Data categorization [ 14, 48). 

fitness apps range from generic data to sensitive and personal data, 
which indicates the need for a strong data protection privacy policy. 
The consent criteria in the GDPR [1) aim to shift personal data 
control back to users, which creates a huge burden for the service 
provider  (49). For example, wearables such as Fitbit and Apple 
Watch rely on processing personal data, including sensitive infor 
mation, as summarized in Table 2. The nature of these data indicate 
that implied consent, as in C7, is not sufficient but, instead, Cl con 
sent must be obtained explicitly through •a clear affirmative action." 
Therefore, request implied consent is not sufficient and it must be 
explicitly given C7 through "a clear affirmative action" Cl [1, p. 10). 
Fitness app providers must comply with regulations such as the 
GDPR  (1) to achieve legitimate grounds for processing users' data 
and thereby avoiding future disputes. Even w ith the existing legal 
frameworks such as the GDPR [ 1) and HIPAA (50), when aiming 
to ensure transparency and privacy with the use of fitness devices, 
providers often neglect or misrepresent  legal specifications, w hich 
has led to ongoing concerns about privacy and data (25). The fol 
lowing section investigates the state of the privacy policies used by 
fitness app providers. 

3  STATE OF PRIVACY POLICIES USED BY 

FilNESS APP PROVIDERS 

This section discusses  the state of the privacy policies  used by 
providers of fitness apps and the importance of transparency, which 
is often considered a core element for achieving both privacy and 
compliance. The GDPR [ 1] and the Australian Privacy Act 1988 (34) 
foster transparent da ta processing practices to enhance trust in pri 
vacy protection. In technical  terms,  Seneviratne and Kagal  [ 43) 
developed privacy-enabling transparent systems that rely on trans 
parency as a critical component, in which all processes are audited. 
To ensure that there are no policy violations, the subject is given a 
clear view of how their data are used. Seneviratne and Kagal's  (43] 
approach and the legal frameworks stress the .importance of trans 
parency in any system. Hence, we define the transparency of the 
system based on three fundamental pillars, as shown in Figure 2. 
Thus, for fitness app providers to establish legitimate processing 
grounds in this context, a con sent management mechanism that 
complies with the GDPR [ 1) is required to improve the transparency 
of the data flow and to control whether consent has been  granted, 
denied, or revoked. To ensure data flows in a  privacy-preserving 
manner,  user consent can be  integrated into the processing  [ 6, 

This work is licensed under a ACM' s  traditional copyright transfer agreement  For more information, see https://authors acm orgiaulhor-se:rv:ices/author-rights 

This article has been accepted for publication in a future issue of Australasian Computer Science Week 2022 (ACSW 2022), but has not been fully edited  Content may change prior to final publication 
Citation information:  DOI  JO  1145/3511616 3513100, ACSW 2022 

ACSW  2022,  February 14-18, 2022,  Brisbane, Australia 

May Alhajri',, Ahmad Salehi s.•!, and Carsten  Rudolph' 

Consent  Consent  character- Definition 
num-
her 
Cl 

Unambiguous 

is tics 

C2 

C3 

Informed 

Freely given 

C4 

Specific 

cs 

C6 

C7 

Auditable 

Withdrawal 

Explicit 

Preselected options or opt-out requests are invalid, as consent must be through "a clear 
affirmative action"; i.e., the practices of ticking the box to agree to terms and conditions 
is problematic. 
The data subject must be aware of all information associated with processing their data 
before the data processed. This also requires this information should be understandable 
using a clear and plain language. 
Consent should be given on a voluntary basis. Data subject must be aware of all consent 
effects. Consent presumed to be invalid if there is any coercion or obligation. i.e., require 
non-negotiable consent. 
The consent request for  processing  data must be granular and  the purpose must be 
specified. Thus, data subject must be fully aware of the intended purposes and the used 
method to process their data. Hence, an opt-in option should be given for each purpose 
separately instead of a blanket consent. 
All consent requests, grants, and revokes;  and other details, must be stored for  future 
auditing which can be used later as valid proof. 
Consent request should also include the method to withdraw from granted consent and 
it should be easy to withdraw. 
Consent should verify that consent was given by the data subject, and it should include 
detailed information on what data consented, thus explicit consent must be verifiable to 
be validated. 

GDPR's 
Recital 

GDPR's 
Article 

32 

32, 42 

7,  2 

32, 42, 43 

7, 4 

32 

7,  2 

42 

51,  71 

7, 3 

9,  2 

Table 1: A summary table of valid consent characteristics under the GDPR [1, 8, 11]. 

Data category 
Identifier 

Definition 
Data that directly reveal individual identity. 

Quasi identifier 

Data attributes that in combination can uniquely identify individuals. 

Sensitive 

Data that reveals sensitive aspects of individual private life such as health data. 

Generic 

Data that does not fall  under the other three categories. 

Fitness data 

•  Name 
•  Location 
•  Phone number 

•  Birth date 

•  Health: Physical state, blood pres sure, 
heart rate, weight, height, and psycholog 
ical state. 
•  Position 

•  Fitness: Walking and running steps 

Table 2: A summary of fitness data categorization [10, 14, 48]. 

38].  Therefore, a  solution is  needed that ensures coverage of all 
fundamental pillars of transparent system by complying with the 
GDPR and integrating consent to preserve privacy. The next section 
focuses on the issues associated with privacy policies used by fitness 
apps. 

3.1  Linguistic Assessment of Privacy Policies 

Used by Fitness Apps 

Research  into  fitness  apps  have  revealed  a  gap  between  users' 
understanding of consent and subsequent data usage by service 
providers [25,  31, 47]. Thus, consent given to privacy policies must 
be  written  in  clear and plain language to  achieve  transparency. 

Although transparency is a crucial when processing personal data, 
the assessment of Sunyaev et al. [ 4 7] of the privacy policies of the 
top 300 health apps in the Apple and Android app stores provides 
contrary evidence. They found that the sharing practice of individ 
ual personal data on these health apps is far from transparent and 
that, because of the lack of clarity, the overwhelming amount of 
text makes it difficult for users to find and understand the privacy 
policies. 

A recent law study by Mulder [31] examined the privacy policies 
of 31  health apps,  including fitness  tracking apps,  such as Fitbit, 
Strava, and Nike Running, and compared these with the GDPR. The 
authors focused on identifying noncompliance in the policies and 
the legal consequences. The findings suggest that the key reasons 

This work is licensed under a ACM's traditional copyright transfer agreement  For more information, see https://authors acm org/author-services/author-rights 

This article has been accepted for  publication in a future issue of Australasian Computer Science Week 2022 (ACSW 2022), but bas not been fully edited  Content may change prior to final pubhcation 
Citation information: DOI 101 14513511616 3513100. ACSW 2022 

Privacy of Fitness Applications and Consent Management in  Blockchain 

ACSW 2022, February 14-18.  2022, Brisbane, Australia 

Legal 
Framework 

\ 

Transparent\ \  

System 

Compliance 

\ rivacy Policy 

Figure 2: Fundamental pillars of a  transparent system. 

for users' lack of knowledge about the consent process is that policy 
statements are lengthy and use complex language [31]. Failure to 
state clearly the purpose of processing personal data violates the 
GDPR criteria, which state that consent  must be informed C2 and, 
if not, it is unlawful to process the user's data [ 1). These findings 
suggest the need to adopt a more transparent system that clearly 
communicates the purpose of data requests 

3.2  Assessment of the Behavior of Privacy 

Practices Used by Fitness Apps 

In addition to linguistic assessments, other types of assessments 
have focused on privacy risk analysis of the behavior of health and 
fitness apps [2, 23, 24, 30, 32). A  descriptive study by Grundy et 
al. [23]  used network analysis of data-sharing links among fitness 
apps and found significant privacy concerns because of the central 
position of fitness apps in mHealth data-sharing ecosystems such 
as Jawbone UP, Apple Healthl<it, Fitbit, and Strava The high inter 
connectivity of these apps indicates the potential for the sharing 
of user data with third parties in an unanticipated and involuntary 
manner [23). However, this analysis did not distinguish whether fit 
ness apps collected user data passively or through prior agreement 
with users. 

Further analyses have been conducted to assess the privacy of 
sharing user data based on traffic analysis and user review [24, 30). 
For example, using the proposed system "AntMonitor" of Shuba 
et al. [24], Hatamian et al. [24)  performed traffic analysis to detect 
any leaks of sensitive data to a  remote server without the user' s 
consent. This traffic analysis examined whether there was data 
transmission to a  third party when the user was not interacting 
with the device [24, 45). Using their standalone "MARS analysis," 
these authors also analyzed the correlation between the user' s 
perception of privacy and the real behavior of health and fitness 
apps. Hatamian et al. [24) confirmed that current privacy practice 
among fitness apps is problematic in terms of accessing sensitive 
data without transparent reasons. 

Momen at al. [30] extended the work ofHatamian et al. [24) by 
comparing privacy-related complaints against fitness apps from 
before to after the GDPR went into effect. Most of the complaints 

related to overprivileged apps that request permission unrelated 
to their functionality. The findings of Momen  et al. [30] suggest a 
positive impact of the GDPR on app behavior. Based on the ethical 
principles of autonomy and competence, Ahmed et al.  [2]  used 
the conceptual model of informed consent proposed by Friedman 
et al. [ 19] to analyze the status of consent management in online 
social networks. Ahmed et al.  [2]  found that a common practice 
among service providers is based on Hobson' s choice; that is, data 
subjects are required to agree entirely with all privacy policies or be 
prohibited from using the service. Similarly, Neisse et al. [32) found 
that most apps use end-user license agreements as a convenient 
way to seek user  consent, which is  not always practical in the 
current use of wearable devices. This form of one-time consent is 
not truly voluntary or generic and, therefore, it violates the criteria 
that consent is freely given C3 and specific C4; in addition, users 
should not be affected if they decide not to grant permission [ 1). 
These behavior  assessment findings suggest  that fitness apps 
share user data with other entities involuntarily. This is because 
of the  unclear one-time consent used to obtain user consent and 
the lack of the user's right of withdrawal. These issues should be 
addressed by a new system that records all exchanged data activity 
while requiring with user consent. 

3.3  Heuristic Ev aluation of Fitness App 

Consent Practices 

The previous noncompliant practices were for fitness apps that 
use one-time consent to obtain users'  consent to process their 
data [2, 32). Some fitness apps have moved from traditional one 
time consent  to more flexible management of user consent. This 
subsection critically compares the privacy policies of the three top 
fitness apps shown in Table 3 (Fitbit, Apple Watch, and Strava) to 
understand their consent culture with more specific reference to 
the criteria for consent validity under the GDPR (Table 1). The qual 
itative approach used in this evaluation is based on the heuristics 
framework of Hutton et al. [25) (Figure 3}. We examined the state of 
privacy in these fitness tracking apps using this framework, which 
is used to assist both researchers and data controllers to conduct 
impact assessments for both privacy and data protection. 

QS 
privacy 
heuristics 

The comparison in this 
section will focus only o n 
this part of Hutton et al's 
framework (to heuristically 
evalua te fitness tracking 
app privacy). 

QS meerup data 

Google Play 

Hardware market 
data 

QS 
privacy 
heuristics 

Figure 3: He uristic framework of Hutton et  a l. [25). 

This work is licensed under a ACM' s traditional copyright transfer agreement For more information, see https://authors acm org/author-services/author-rights 

This article has been accepted for publication in a fu\ure issue of Austtalasian Compu\er Science Week 2022 (ACSW 2022), but has no\ been fully edited  Conten\ may change prior to final publica\ion 
Citation information: DOI  IO  1145/3511616 3513100, ACSW 2022 

ACSW 2022, February 14-18, 2022, Brisbane, Australia 

May Alhajri'"1, Ahmad Salehi s.•§, and  Carsten  Rudolph• 

Our pilot evaluation of the fitness app consent practices included 
in Table 3 showed that none of the three fitness app providers offer 
a fully dynamic consent mechanism. Although they give the user 
the right to withdraw, they do not update this consent when new 
data are collected or if purpose of the request changes. Moreover, 
these apps do  not use one-time consent and do not give the user the 
right to choose which data can be processed, which is important 
because wearable devices generate different types of data, some 
of which are sensitive. For the providers of fitness apps, avoiding 
noncompliance is a  rational decision and is more cost-efficient 
than dealing with the consequences of unwanted disclosures of 
personal data [ 4 7]. Devising a consent model is an important step 
in ensuring compliance wit h t he GDPR and helping fitness app 
providers to meet privacy requirements related to the processing 
of individual data [35]. Therefore, a solution that uses a dynamic 
consent mechanism to address these issues is  required. 

4  SUMMARY OF THE STATE OF THE ART 
This section summarizes the current understanding of the privacy 
p olicies of fitness apps and the gaps identified in this review. This 
review paper started by discussing the legal frameworks for pri 
vacy protection and summarizing the valid consent criteria under 
the GDPR, and then described the importance of adopting legal 
frameworks in the fitness-tracker ecosystem. This summary of valid 
consent criteria used throughout this review paper was used to 
investigate compliance issues related to consent management prac 
tice. We have reviewed the current state of privacy policies used by 
fitness app providers, particularly their consent-management prac 
tices. This review has discussed three types of assessment of fitness 
app privacy policies: linguistic assessment, behavior assessment, 
and heuristics evaluation. 

We have identified the research gaps in the area, such as lack 
of system transparency, lack  of privacy policy legibility, privacy 
concerns associated with one-time consent, and noncompliance 
with the adopted consent management solution. Thus, our identified 
problems and its relevant number, are stated as follows. 

Pl Lack of system transparency Fitness app privacy policies lack 
transparency in their consent practice. To overcome this 
issue, consent management mechanisms that comply with 
GDPR [ l ] are required. To ensure that data flow in a privacy 
preserving manner, user consent should be integrated [ 6, 38 ]. 
A  solution that ensures that all  fundamental pillars  of a 
transparent system that comply with the GDPR and integrate 
consent to preserve privacy is needed. 

P2  Lack of fitness app privacy policy legibility The findings from 
linguistic assessment of fitness app privacy policies suggest 
the n eed  to adopt a more  transparent system  that  clearly 
communicates the purpose of requesting data. A solution 
that enhances the consent' s legibility by ensuring consent is 
obtained using plain language that includes the attributes 
and detailed information related to the purpose of each data 
request separately is required. 

P3  Concerns  with one-time consent. The findings from behav 
ior assessments suggest  that fitness  apps share user data 
with other entities involuntarily. This occurs because of the 
unclear one-time consent required of users and the lack of 

their right to withdraw consent. Therefore, it is  crucial to 
address these issues by proposing a system that records all 
exchanged data activity tied to user consent. A solution that 
allows the user to withdraw or update consent at any time 
is needed. 

P4  Noncompliance issues with new consent management. Although 

some fitness apps have moved from traditional one-time con 
sent to flexible consent, noncompliance issues remain. Our 
findings from the heuristics evaluation suggests fitness apps 
do not offer a  fully dynamic consent mechanism, nor do 
they update consent when new data are collected or if the 
purpose of the request changes. They also do not give the 
user the right to  determine which data can be processed.  A 
solution that identifies specific data to be shared, as well as 
not shared without user consent, is required. 

In Section 5,  we review  the current solutions to  address the 
aforementioned gaps in different domains in terms of consent man 
agement; these include open issues, challenges, and our recommen 
dations. 

5  OPEN ISSUES, CHALLENGES, AND 

RECOMMENDATIONS 

In this section, we discuss the potential of existing solutions to 
address the problems identified as Pl , P2, P 3 and P4 in Section 4, 
including but not limited to centralized and decentralized authority, 
and distributed technology. Given that consent is defined as the 
method for asking for the user's permission to read and edit their 
health records [6], the solutions must address the privacy issue by 
obtaining the individual user's consent. 

5.1  Open Issues and Challenges: 
5. 1. 1  Centralized Authority  Bacchus [ 6]  has presented a  novel 
protocol for managing consent requesters, known as consent-based 
access control (CBAC). This protocol aims to switch the control 
of patients' sensitive health data back to their original owner, the 
patient. This suggested CBAC approach involves, first, negotiat 
ing with the patient to gain access to their health  data and then, 
once an agreement has been reached, the data requester is issue d 
a consent token that allows access to that information. Although 
this proposed approach helps to solve the lack of patient control 
over access to their h ealth records, it remains a one-time consent 
management P3 and it places the ultimate trust in a single author 
ity Pl . There are risks associated with trusting a single authority, 
such as  malicious acts, lack of transparency, and forged consent. 
This approach  also means that users must blindly trust a  single 
authority to handle their data rather than trusting the technology 
behind it.  By contrast, implementing a system that uses distributed 
technology rather than a centralized authority can resolve trust 
issues. Blockchain technology  introduces many built-in features 
that make this technology a suitable candidate for consent man 
agement. Subsection 5.1.2 discusses the potential of this distributed 
technology to solve issues P l , P2, P3 and P4. Thus, now turn to 
the discussion of blockchain solutions  for con sent management 
and interoperability issues associated with fitness apps. 

This work is licensed under a ACM's ttadilional copyright transfer agreemen\  For more information, see https://aulhors acm org/aulhor-services/aulhor-rights 

This article has been accepted for publication in a future issue of Australasian Computer Science Week 2022 (ACSW 2022), but has not been fully edited  Content may change prior to final publication 
Citation information:  DOI  JO 1145/351 1616 3513100, ACSW 2022 

Privacy of Fitness Applications and Consent Management in  Blockchain 

ACSW  2022,  February 14-18, 2022,  Brisbane, Australia 

Heuristic 

GDPR 

Fitbit 

Apple 
watch 

Strava 

de-

Category 
scription 
Choice or Consent 
HB 
H9 
HlO 

Hll 

H12 

H13 

H14 

Consent acquired before data shared with remote actor. 
C2 
Consent is explicitly opt-in: no pre-ticked checkboxes, etc. 
Cl 
Can choose which data types are automatically collected from sensors or other sources,  C4 
for example, connect a finance app to a single bank account or track steps but not heart 
rate. 
Data collection consent is dynamic: if new types of data are being collected, consent is  C6,  C2, 
renewed in situ. 
Data processing consent is dynamic: if the purpose of processing changes, consent is  C6,  C2, 
renewed. 
Data distribution consent is dynamic: if the actors' data are distributed changes, consent  C6,  C2 
is renewed. 
Consent to store and process data can be revoked at any time: with the service and any  C6 
other actors. 
Can control where data are stored. 

C4 

C4 

X 

✓ 

X 

X 

X 

✓ 

X 

✓ 

X 

X 

X 

X 

✓ 

✓ 

X 

X 

X 

X 

✓ 

✓ 

✓ 

X 

x 

X 

x 

X 

x 

H15 
Additional consent characteristics check 
H16 

keep record of all consent processes (demonstrating consent) 

C5 

Table 3: Comparison ofGDPR and the privacy policies ofFitbit [18], Apple Watch [3] and Strava [46] in the choice and consent 
category [25] and auditing criteria. 

5. 7.2  Blockchain and Interoperability Issues.  Although the studies 
described in Section 3 highlight the importance of adopting a trans 
parent consent mechanism in any system to address noncompliance 
issues, many have discussed the lack of interoperability between 
wearables platforms [2, 23- 25, 30- 32, 35, 47], which creates a huge 
barrier to their widespread use and limits the exchange of personal 
data with other entities [15, 26]. The problem relates to the great 
heterogeneity of fitness data representations that remain confined 
to fitness provider platforms, which makes the integration of these 
data silos with other entities difficult [26, 37]. 

Research studies have recommended joint action across the wear 
able ecosystem to overcome this interoperability issue [17, 20, 37, 
42]. Saripalle [42] proposed a solution for integrating fitness data 
with other entities such as electronic health records (EHRs) by lever 
aging the HL7 Fast Healthcare Interoperability Resources (FHIR) 
standard [ 42]. 

We  note that the FHIR  standard is  currently used in some re 
search blockchain designs in the health-care context. Rupasinghe et 
al.  [38] used an FHIR consent resource in their proposed design to 
avoid integration failures with EHRs. According to their literature 
review, only five  of 23 proposed solutions addressed interoperabil 
ity issues in their consent management [5, 16, 27, 51]. Additionally, 
some health apps such as Apple's Health Records app use FHIR to 
allow users to download data from their health-care providers [ 4]. 
Although designing a system in an interoperable manner is  impor 
tant for being able to combine fitness data, there is still no common 
standard for consumer fitness devices  [ 15]. This is because interop 
erability standards go through a series of approvals before being 
piloted, but wearable fitness devices go to market faster than the 
relevant standards are developed [15]. The capacity to share indi 
vidual personal data depends on obtaining the individual's consent, 
and this in itself is hindered by interoperability issues. 

5.2  Recommendations and Future Work 
To improve users' control over the processing of their fitness data 
while simultaneously enabling fitness tracker providers to comply 
with the GDPR obligations, we have identified and investigated past 
and existing privacy-preserving practices of fitness apps to suggest 
suitable solutions for  the problems identified. As an emerging tech 
nology, blockchain has outstanding advantages for resolving these 
consent-management privacy concerns. We propose a blockchain 
based consent mechanism, which we suggest can improve privacy 
by designing a human-centric and legally compliant system that 
manages user consent  dynamically around the  sharing,  collect 
ing, and processing of fitness data between the requester and user 
under the  GDPR's validity criteria. By leveraging the problems 
identified as Pl , P2, P3 and P4 (Section 4) from our review of the 
literature and our discussed solutions (Section 5. 1), we encourage 
future research to investigate empirically our proposed fitness app 
consent-management requirements (as listed below) through the 
lens of the advantages ofblockchain: 

R 1  Trust or security 
R2  Transparency 
R3  Scalability 
R4  Auditability 
R5  Preservation of the original functionality 
R6  GDPR compliance 

Based on our findings (Section 5.1) of the existing solutions for 
preserving user privacy and blockchain's potential to address the 
problems identified as Pl, P2, P3 and P4 (Section 4), we recommend 
further research to examine the feasibility of using blockchain to 
manage user consent through some or all of our recommended re 
quirements Rl , R2, R3, R4, R5 and R6. Researchers might manage 
user consent by leveraging smart contracts to automate the pro 
cesses of consent grants and revoke actions. In addition, blockchain 

This work is licensed under a ACM's traditional copyright transfer agreement  For more information, see https://authors acm org/author-services/author-rights 

This article has been accepted for publication in a fu\ure issue of Austtalasian Compu\er Science Week 2022 (ACSW 2022), but h as no\ been fully edited  Conten\ may change prior to final publica\ion 
Citation information: DOI  IO  1145/3511616 3513100, ACSW 2022 

ACSW 2022, February  14-18, 2022, Brisbane, Australia 

May Alhajri'"1, Ahmad Salehi s.•§, and  Carsten Rudolph• 

and smart contracts might also be used as tools to detect misbehav 
ior by fitness providers if they process or share data in an unantici 
pated and involuntary manner. 

6  CONCLUSION 
This review paper aimed to identify the importance of adopting 
legal frameworks in the fitness-tracker ecosystem by reviewing 
data protection legal frameworks and the relevant literature, and by 
identifying the problems inherent in the compliance with existing 
legal frameworks of the privacy policies of fitness apps. The studies 
reviewed included linguistic, behavioral, and heuristic assessments 
of the consent practices of fitness apps. From our analysis, it is clear 
that there are serious privacy concerns associated with the use of 
fitness apps. Our analysis identified four problems related to the 
preservation of privacy of fitness data: lack of system transparency, 
lack of privacy policy legibility, concerns regarding one-time con 
sent, and issues of noncompliance regarding consent management. 
Identifying these problems enabled us to review and discuss the 
existing solutions including the centralized and decentralized au 
thority that might be feasible for addressing these identified gaps 
and improving the user's control over the processing of their fit 
ness data. Blockchain' s built-in features make it a suitable candidate 
for solving the problems identified. However, further research is 
needed to examine the feasibility of using blockchain to manage 
user consent. 

REFERENCES 
[1]  Regulation (EU) 2016/679. 2016. The European Parliament and of the Council of 
27 April 2016 on the protection of natural persons v.rith regard to the processing 
of personal data and on the free  movement of such data, and repealing Directive 
95146/EC (General Dala Protection Regulation).  Official Journal of the European 
Union.  119 (2016), 1-88.  https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/ 
?uri=CELEX:02016R0679-20160504&from=EN 

[2]  Javed Ahmed,  Sule Yildirim, Mariusz Nowostaki, Raghvendra Ramachandra, 
Ogerta Elezaj, and Mohamad Abomohara. 2020.  GDPR Compliant Consent 
Driven Data Protection in Online Social Networks: A Blockchain-Based Approach. 
[n 2020 3rd International Conference on Information and Computer Technologies 
(ICICT). IEEE, Sanjose, CA, USA,  307-312.  https://doi.org/l0.1109/ICICT50521. 
2020.00054 

[3]  Apple. 2020.  Apple Privacy Policy. Apple,  https://www.apple.com/legal/privacy/ 

en-ww/ 

[4]  Apple. 2021.  Healthcare.  Apple.  https:// www.apple.com/healthcare/health 

records/ 

[5]  Asaph Azaria, Ariel Ekblaw, Thiago Vieira. and Andrew Lippman. 2016.  Medrec: 
Using blockchain for medical data access and permission management. [n 2016 
2nd International Conference on Open and Big Data (OBD).  IEEE, Vienna, Austria, 
25-30.  https,//doi.org/ 10.1109/OBD.2016.11 

[6]  Abel Bradley Saed Bacchus. 2017.  Towards secure and privacy preserving e-health 
data exchanges through consent based access control Ph.D. Dissertation. University 
of Ontario Institute of Technology (Canada). 

[7)  Kumar  Bhaskaran, Peter Ilfrich, Dain Liffinan,  Christian Vecchio la.,  Praveen 
Jayachandran, Apurva Kumar, Fabian Lim, Karthik Nandakumar, Zhengquan 
Qin, Venkatraman Ramakrishna, et al. 2018. Double-blind consent-driven data 
sharing on blockchain. In 2018 IEEE International Conference on Cloud Engineering 
(IC2E). IEEE, Orlando, FL, USA, 385-391. 

[8]  Stephen Breen, Karim Ouazzane, and Preeti Patel, 2020. GDPR: ls your consent 
valid? Business Information Review 37, 1 (2020). 19-24.  https://doi.org/10.1177/ 
0266382120903254 

[9]  Elizabeth A Brown. 201 6.  The Fitbit fault line: two proposals to protect health 

and fitness data at work.  Yale].  Health Pol'y L.  & Ethics 16 (2016), I. 

[10]  Barbara Carminati, Pietro Colombo, Elena Ferrari, and Gokhan Sagirlar. 2016. 
Enhancing  user control on personal data usage in internet of things ecosystems. 
[n 2016 IEEE. International Conference on Services Computing (SCC). IEEE, San 
Francisco. CA, USA, 291-298.  https://doi.org/ 10.1109/SCC.2016.45 

[11]  Ana C  Carvalho, Rolando Martins. and Luis Antunes. 2018.  How-lo express 
explicit and audit able conscnt. ln 2018 16th Annual Conference on Priva~ Security 
and Trust (PST).  IEEE, Belfast, Ireland, 1- 5.  h ttps:/(doi.org/10.1109/PST.2018. 
8514204 

[12]  Mads Christophersen, Peter M0rck, Tue Odd Langhoff, andPemille Bj0rn. 2015. 
Unforeseen Challenges. ln Universal Access in Human-Computer Interaction. Ac 
cess  to Learning, Health and Well-Being, Margherita Antona and Constantine 
Stephanidis (Eds.). Springer International Publishing, Cham. 288-299. 

[ 13]  Chia-Fang Chung, Nanna Gorm, Irina A Shklovski, and Sean Munson. 2017. Find 
ing the right fit: underslanding health tracking in workplace wellness programs, 
In Proceedings of the 2017 CHI conference on  human factors in computing systems, 
Association for Computing Machinery. Colorado, Denver, USA, 4875-4886. 
[ 141  Pietro Colombo and Elena Ferrari. 2015.  Efficient enforcement of action-aware 
purpose-based access control within relational database management systems. 
IEEE  Transactions on Knowledge and Data Engineering 27, 8 (2015),  2134-2147. 
https,// doi.org/10.1109/TKDE.2015.2411595 

[15]  A Cortez. P Hsii, E Mitchel]. V Riehl. and P Smith. 2018.  Conceptualizing a data 
infrastructure }Or the capture, use,  and sharing of patient-generated health data 
in care delivery and research  through 2024.  Technical Report. the Office of the 
National Coordinator for Health Information Technology.  https://www.healthit. 
gov/sites/default/files/one _pghd _fin.al_ white _paper.pdf 

[ 16]  Gaby G Dagher, Jordan Mohler, Matea Milojkovic, and Praneeth Babu Marella. 
2018. Ancile: Privacy-preserving framework for access control and interoperabil 
ity of dectronic hc:alth records using blockchain kchnology.  Sustainable cities 
and society 39 (2018), 283-297.  http s://doi.org/10.1016/j.scs.2018.02.014 
[17]  Catherine Dinh-Le, Rachel Chuang. Sara Chokshi, and Devin Mann. 2019. Wear 
able health technology and electronic health record  integration: scoping re 
view  and future  directions.  ]MIR  mHealth  and uHealth 7,  9  (2019),  el2861. 
https,/ /doi.org/10.2196/12861 

[18]  titbit. 2020.  Fitbit Privacy Policy. fitbit.  https://www.fitbit.com/global/au/legal/ 

privacrpolicy#your•rights- to -access 

[19]  Batya Friedman, Edward Fdlen, and Lynelle I Millett. 2000.  Informed consent 
online: A  conceptual model and design principles.  University of Washington 
Computer Science &  Engineering Technical Report 00- 12- 2  8  (2000), 00- 12- 2. 
https,//dada.cs. washington.edu/research/tr/ 2000/12/UW· CSE-00-12-02.pdf 
[20]  Valerie Gay and Peter Leijdekkers. 2015. Bringing health and fitness data together 
for connected health care: mobile apps as enablers of interoperability.  Journal af 
medical Internet research 17, 11 (2015), e260.  https://doi.org/ 10.2196/jmir.5094 

[21]  Philippe Genestier, Sajida Zouarhi, Pascal Limeu,. David Excoffier, Alain Proia, 
Stephane Sandon, and Jean-Marc Temerson. 2D17.  Blockchain for consent man• 
agement in the  ehealth environment: A nugget for privacy and security chal• 
lenges.  Journal of the International Society for Telemedicine and eHeaith 5 (2D17), 
GKR- e24( 1- 4).  https://journals.ukzn.ac.za/index.php/JISITeH/article/view/269 
[22]  Shlok Gilda and Maanav Mehrotra.  2018.  Blockchain for  student data privacy 
and consent. [n 2018 International Conference on  Computer Communication and 
Informatics (ICCCI).  IEEE, Coimbatore, India, 1-5. 

[23]  Quinn Grundy, FabianP Held, and Lisa A llero. 2017. Tracing the potential flow of 
conswner data: a  network analysis of prominent health and fitness apps. Journal 
of medical Internet research 19, 6 (2017). e233.  https,//doi.org/10.2196/ jmir.7347 
[24)  Majid Hatamian,Jetzabel Serna, and Kai Rrumenberg. 2019. Revealing the unre 
vealed: Mining smartphone users privacy perception on app markets.  Computers 
& Security ~3  (2019), 332- 353.  https,//doi,org/10.1016/j.cose.2019,02.010 
[25]  Luke Hutton, Blaine A Price, Ryan Kelly, Ciaran McCormick. Arosha K Bandara, 
Tally Hatzakis, Maureen Meadows, and Bashar Nuseibeh. 2018.  Assessing the 
privacy of mhealth apps for self-tracking: heuristic evaluation approach. ]Mm 
mHealth and uHealth 6, 10 (2018), el 85.  https:/ /doi.org/ 10.2196/mhealth.9217 

[26]  DaweiJiang and Guoquan Shi.  2021.  Research on Data Security and Privru:y Pro 
tection of Wearable Equipment in Healthcare.  Journal of Healthcare Engineering 
2021 (2021), 1-97.  https://doi.org/10.1155/2021/6656204 

[27]  Harleen Kaur. M Afshar Alam, Roshan Jameel, Ashish Kumar Mourya, and Victor 
Chang. 2018.  A  proposed sol ution and future direction for blockchain-based 
heterogeneous medicare data in cloud environment.  Journal of me dical systems 
42, 8 (2018),  1-11.  https,//doi.org/10.1007/s10916-018-1007-5 

[28]  Xueping Liang, Juan Zhao, Sachln Shetty, Jihong Liu, and Danyi Li. 2017.  In 
tegrating blockchain for data  sharing  and collaboration in mobile healthcare 
app lications. [n 2017 IE.EE 28th annual international symposium on personal. indoor, 
and mobile radio communications (PIMRC).  IEEE, Montreal, QC, Canada, t-5. 

[29]  Anna Mizzi. 2020.  Profiting on Your Pulse: Modernizing HIPM to Regulate 
Companies' Use of Patient-Consmncr Health Infonnation.  Geo.  Wash. L. Rev. 88 
(2020), 481. 

l3DJ  Nurul Momen, Majid Hatamian,  and Lothar Fritsch. 2019.  Did App pri vacy 
improve after the GDPR?  IEEE Security & Privacy 17, 6 (2019), 10-20,  https: 
//doi.org/10.1109/MSEC.2019.2938445 

[31]  Trix Mulder. 2019.  Health apps, their privacy policies and the GDPR.  European 
Journal of Law and Technology 10, 1 (2019), 1-20.  https://ssm.com/abstract= 
3506805 

[32]  Ricardo Neisse, Gianmarco Baldini, Gary Sleri, Yutaka Miyake, Shinsaku Kiy· 
omoto. and Abdur Rahim Biswas. 2015. An agent-based framework for informed 
consent in the internet of things.  In  2015 IEEE  2nd Warld Forum on Internet 
of Things (WP-loT). IEEE, Milan, Italy, 789-794,  https://doi.org/10.1109/WF 
loT.2015.7389154 

This work is licensed under a ACM's ttadilional copyright transfer agreemen\  For more information, see https://authors acm org/author-services/author-rights 

This article has been accepted for publication in a fu\ure issue of Austtalasian Compu\er Science Week 2022 (ACSW 2022), but h as no\ been fully edited  Conten\ may change prior to final publica\ion 
Citation information: DOI  IO  1145/3511616 3513100, ACSW 2022 

Privacy of Fitness Applications and Consent Management in  Blockchain 

ACSW 2022. February 14-18, 2022, Brisbane, Australia 

[33)  US  Department of Health, Human Services, et al.  2016.  Examining oversight 
of the privacy & security of health data collected by entities not regulated by 
HIPM. 
https://www.healthit.gov/sites/default/files/non-covered_entities_ 
reportjune_l 7 _2016.pdf 

[34]  Office of the Australian Information Commissioner(OAIC). 2018.  Australian enti 
ties and theEUGeneralDataProtectionRegulation (GDPR). Office of the Australian 
Information Commissioner(OAIC).  https://www.oaic.gov.au/privacy/guidance 
and-advice/australian-entities-and-the-eu-general-data-protection-regulation 
[35]  Dijana Peras. 2018.  Guidelines for GDPR Compliant Consent and Data Manage 
ment Model in ICT Businesses. In Central European Conference on Information and 
Intelligent Systems. Faculty of Organization and Informatics Varazdin, CECIIS, 
Varazdin, Croatia, 113-121. 

[361  Andreas Pfitzmann and Marit Hansen. 2010.  A terminology for talking about 
privacy by data minimization: Anonymity, Unlink.ab ility, Undetectability, Un 
observability, Pseudonymity, and Identity  Management. 
http://dud.inf.tu 
dresden.de/literatur/ Anon_ Tenninology _ v0.34.pdf v0.34. 

[37]  Roberto Reda, Filippo Piccinini, and Antonella Carbonaro. 2018. Towards con 

sistent data representation in the loT healthcare landscape. ln Proceedings of 
the 2018 International Conference on Digital Health.  Association for Computing 
Machinery, Lyon, France, 5-10.  https://doi.org/10.11 45/3194658.3194668 
[38]  Tharuka Rupasinghe, Frada Burstein, and  Ca,sten Rudolph. 2019.  Blockchain 
based Dynamic Patient Consent: A Privacy-Preserving Data Acquisition Architec 
ture for Clinical Data Analytics .. In ICIS 2019 Proceedings AIS Electronic, Munich, 
1-9.  https://icis2019.aisconferences.org/ 

[39]  Ahmad Salehi, Carsten Rudolph, and Marthie Grabler. 2020.  Attribute-Based 
Data Access Control for Multi-Authority System. ln 202 0 IEEE 19th International 
Conference on  Trust. Securlty and Privacy in  Computing  and Communications 
(TrustCom). IEEE,  Guangzhou, China, 1834-1841. 

[40]  Ahmad S Salehi, Carsten Rudolph, and Marthie Grobler. 2019.  A  dynamic cross 
domain access control model for collaborative  healthcare application. In 2019 
IFII'IIEEE Sy mposium on Integrated Network and Service Management (IM), IEEE, 
Arlington, VA, USA, 643-648. 

[41]  Robert Sallis. 2011. Developing healthcare systems to support exercise: exercise 
as the fifth vital sign. British Association of Sport and Excercise Medicine 45 (2011), 
473-474.  https://doi.org/10.1136/bjsm.2010.083469 

[42]  Rishi Kanth Saripalle. 2019.  Leveraging FHIR to integrate activity data with 
electronic health record.  Health and Technology 2020, 10 (2019), 1-12.  https: 

//doi.org/ 10.1007 Is 12553-019-00316-5 

[43]  Oshani Seneviratne and  Lalana Kagal, 2014,  Enabling privacy  through trans 
parency. In 2014 Twelfth Annual International Conference on Privacy, Security and 
Trust.  IEEE, Toronto, ON, Canada, 121-128.  https://doi.org/10.1109/PST.2014. 
6890931 

[44]  Ahmad Salehi Shahraki, Carsten Rudolph, and Marthie Grabler. 2019. A dynamic 
access control policy model for sharing of healthcare data in multiple domains. 
ln  2019  18th JEE£ International Conference On  Trust,  Security And Privacy  In 
Computing And Communications/13th IEEE International Conference On Big Data 
Science And Eng ineering (TrustCom/BigDataSE). IEEE, Rotorua,  New Zealand, 
618-625, 

[45]  Anastasia Shuba, Anh Le, Minas Gjoka, Janus Varmarken, Simon Langhoff, and 
Athina Markopoulou. 2015.  Antmonitor: Network  traffic monitoring  and real 
time prevention of privacy leaks in mobile devices.  [n Proceedings of  the 2015 
Workshop on Wireless of the Students,  by the Students, & for the Students. Associ 
ation for Computing Machinery, Paris, France, 25- 27.  https://doi.org/10.1145/ 
2801694.2801707 

[46]  Strava. 2020.  Strava Priv acy  Policy.  StravaPP.  https://www.strava.com/legal/ 

privacy#full_policy 

[47]  Ali Sunyaev,  Tobias Dehling, Patrick  L Taylor,  and Kenneth D  Mandi.  2015. 
Availab ility and quality of mobile health app pr ivacy p olicies.  Journal of  the 
American Medical Informatics Association 22, el (201 5), e28-e33.  https://doi.org/ 
10.1136/ amiajnl-2013-002605 

[48]  Latanya Sweeney. 2002.  k-anonymity: A  model for protecting privacy.  Inter 
national Journal ofUncerlainty, Fuzziness and Knowledge-Based Systems 10, OS 
(2002), 557-570.  https://doi.org/10.1142/S02 18488502001648 

[49]  Colin Tankard. 2016. What the GDPR means for businesses.  Network Security 

2016, 6 (2016),  5-8.  https://doi.org/10.1016/S1353-4858(16)30056-3 

[50)  Alexandra Troiano. 2016. Wearables and personal h ealth data: putting a premiwn 
on your privacy. Brooklyn Law Review 82, 4 (2016), 1715.  https://he inonline.org/ 
HOL/P?h=hein.journals/brklr82&i=l75 9 

[51]  Hanqing Wu,Jiannong Cao, Shan Jiang, Ruosong Yang, Yanni Yang, andJianfei 
Hey. 2018. TSAR, a fully-distributed Trust less data ShARing platform. In 2018 IEEE 
International Conference Qn Smart Computing (SMARTCOlvtP). IEEE, Taormina., 
Italy, 350-355.  https:/ / doi.org/l0.1109/SMARTCOMP.2018.00028 

This work is licensed under a ACM 's ttadilional copyright \!ansfer agreement  For more infonnation, see https://authors acm org/author-services/author-rights 

