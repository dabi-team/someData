THE BEDROCK OF BYZANTINE FAULT TOLERANCE: A UNIFIED
PLATFORM FOR BFT PROTOCOL DESIGN AND IMPLEMENTATION

2
2
0
2

g
u
A
3

]

C
D
.
s
c
[

2
v
4
3
5
4
0
.
5
0
2
2
:
v
i
X
r
a

Mohammad Javad Amiri1 Chenyuan Wu1 Divyakant Agrawal2
Amr El Abbadi2 Boon Thau Loo1 Mohammad Sadoghi3
1Department of Computer and Information Science, University of Pennsylvania
2Department of Computer Science, University of California Santa Barbara
3Department of Computer Science, University of California Davis
1{mjamiri, wucy, boonloo}@seas.upenn.edu, 2{agrawal, amr}@cs.ucsb.edu, 3 msadoghi@ucdavis.edu

ABSTRACT

Byzantine Fault-Tolerant (BFT) protocols have recently been extensively used by decentralized data
management systems with non-trustworthy infrastructures, e.g., permissioned blockchains. BFT pro-
tocols cover a broad spectrum of design dimensions from infrastructure settings such as the commu-
nication topology, to more technical features such as commitment strategy and even fundamental so-
cial choice properties like order-fairness. The proliferation of diÔ¨Äerent BFT protocols has rendered
it diÔ¨Écult to navigate the BFT landscape, let alone determine the protocol that best meets applic-
ation needs. This paper presents BEDROCK, a uniÔ¨Åed platform for BFT protocols design, analysis,
implementation, and experiments. BEDROCK proposes a design space consisting of a set of design
choices capturing the trade-oÔ¨Äs between diÔ¨Äerent design space dimensions and providing funda-
mentally new insights into the strengths and weaknesses of BFT protocols. BEDROCK enables users
to analyze and experiment with BFT protocols within the space of plausible choices, evolve current
protocols to design new ones, and even uncover previously unknown protocols. Our experimental
results demonstrate the capability of BEDROCK to uniformly evaluate BFT protocols in new ways that
were not possible before due to the diverse assumptions made by these protocols. The results validate
BEDROCK‚Äôs ability to analyze and derive BFT protocols.

1

Introduction

Large-scale data management systems rely on fault-tolerant protocols to provide robustness and high availability
[41,54,60,82,94,132,181]. While cloud systems, e.g., Google‚Äôs Spanner [82], Amazon‚Äôs Dynamo [94], and Facebook‚Äôs
Tao [60], rely on crash fault-tolerant protocols, e.g., Paxos [150], to establish consensus, a Byzantine fault-tolerant
(BFT) protocol is a key ingredient in decentralized data management systems with non-trustworthy infrastructures.
In particular, a BFT protocol is the core component of the most recent large-scale data management system, permis-
sioned blockchains [1‚Äì3, 24, 27, 29, 30, 43, 64, 78, 116‚Äì118, 125, 148, 197, 204, 207]. BFT protocols have also been used
in permissionless blockchains [61, 140, 142, 168, 231], distributed Ô¨Åle systems [13, 70, 80], locking service [81], Ô¨Åre-
walls [52, 112, 113, 203, 214, 229], certiÔ¨Åcate authority systems [235], SCADA systems [39, 139, 189, 234], key-value
datastores [50, 98, 115, 128, 203], and key management [171].

BFT protocols use the State Machine Replication (SMR) technique [149,205] to ensure that non-faulty replicas execute
client requests in the same order despite the concurrent failure of ùëì Byzantine replicas. BFT SMR protocols are diÔ¨Äerent
along several dimensions, including the number of replicas, processing strategy (i.e., optimistic, pessimistic, or robust),
supporting load balancing, etc. While dependencies and trade-oÔ¨Äs among these dimensions lead to several design
choices, there is currently no unifying tool that provides the foundations for studying and analyzing BFT protocols‚Äô
design dimensions and their trade-oÔ¨Äs. We envision that such a unifying foundation will be based on an in-depth
understanding of existing BFT protocols and trade-oÔ¨Äs among dimensions; and include an API that allows protocol
designers to choose among several dimensions, and Ô¨Ånd a protocol that best Ô¨Åts the characteristics of their applications.

This paper presents BEDROCK, a uniÔ¨Åed platform that enables us to design, analyze, discover, implement, and exper-
iment with partially asynchronous SMR BFT protocols within the design space of possible variants. It provides an

 
 
 
 
 
 
API that enables BFT protocol designers to analyze and experiment with BFT protocols and their trade-oÔ¨Äs and even
derive new protocols. Application developers also can query their required BFT protocol characteristics where the
platform responds with a list of candidate BFT protocols that match the given query and enables them to choose the
BFT protocol that best Ô¨Åts the characteristics of their applications.

BEDROCK presents a design space to characterize BFT protocols based on diÔ¨Äerent dimensions that capture the environ-
mental settings, protocol structure, QoS features, and performance optimizations. Each protocol is a plausible point in
the design space. Within the design space, BEDROCK deÔ¨Ånes a set of design choices that demonstrate trade-oÔ¨Äs between
diÔ¨Äerent dimensions. For example, the communication complexity can be reduced by increasing the number of com-
munication phases or the number of phases can be reduced by adding more replicas. Each design choice expresses a
one-to-one transformation function to map a plausible input point (i.e., a BFT protocol) to a plausible output point (i.e.,
another BFT protocol) in the design space.

BEDROCK can be used to analyze and navigate the evergrowing BFT landscape to principally compare and diÔ¨Äerentiate
among BFT protocols. On one hand, BEDROCK design space and its design choices give fundamentally new insights
into the strengths and weaknesses of existing BFT protocols. On the other hand, BEDROCK enables new ways to experi-
mentally evaluate BFT protocols by providing a uniÔ¨Åed deployment and experimentation environment, resulting in the
ability to compare diÔ¨Äerent protocols proposed in diverse settings and contexts under one uniÔ¨Åed framework.

The BEDROCK tool has several practical uses:

‚Ä¢ Analyze and experiment with existing BFT protocols. First, BEDROCK supports within one uniÔ¨Åed platform
a wide range of existing BFT protocols, e.g., PBFT [71], SBFT [120], HotStuÔ¨Ä [230], Kauri [186], Themis
[135], Tendermint [63], Prime [22], PoE [123], CheapBFT [133], Q/U [4], FaB [174], and Zyzzyva [143].
‚Ä¢ Evolve an existing protocol to derive new variants. Second, a key beneÔ¨Åt of BEDROCK is in evolving existing
protocols to propose new variants. This incremental design paradigm allows one to adapt a BFT implement-
ation over time to suit the deployment environment. For example, we can derive new protocol variants from
the well-known PBFT [71] protocol using a subset of design choices.

‚Ä¢ Uncover new protocols. Finally, BEDROCK can also enable us to discover new protocols in the design space
simply by combining diÔ¨Äerent design choices not previously explored. As a proof of concept, we present two
new protocol instances: a Fast Linear BFT protocol (FLB), that establishes consensus in two linear commu-
nication phases, and a Fast Tree-based balanced BFT protocol (FTB) that supports load balancing.

The paper makes the following contributions.

‚Ä¢ UniÔ¨Åed design space. A design space for BFT protocols and a set of design choices is proposed. The pro-
posed design space captures fundamentally new insights into the characteristics, strengths and weaknesses of
BFT protocols and their design trade-oÔ¨Äs. Moreover, studying the design space of BFT protocols leads to
identifying several plausible points that have not yet been explored.

‚Ä¢ UniÔ¨Åed platform. We present the design and implementation of BEDROCK, a tool that aims to unify all BFT
protocols within a single platform. BEDROCK derives valid BFT protocols by combining diÔ¨Äerent design
choices.

‚Ä¢ Implementation and evaluation. Within BEDROCK, a wide range of BFT protocols are implemented and
evaluated. This uniÔ¨Åed deployment and experimentation environment provides new opportunities to evaluate
and compare diÔ¨Äerent existing BFT protocols in a fair and more eÔ¨Écient manner (e.g., identical programming
language, used libraries, cryptographic tools, etc).

The rest of this paper is organized as follows. Section 2 introduces BEDROCK. The design space of BEDROCK and its
design choices are presented in Sections 3 and 4. Section 5 maps some of the known BFT protocols and two new BFT
protocols, FLB and FTB, to the design space. The implementation of BEDROCK is introduced in Section 6. Section 7
shows the experimental results, Section 8 discusses the related work, and Section 9 concludes the paper.

2 The BEDROCK Overview

System model. A BFT protocol runs on a network consisting of a set of nodes that may exhibit arbitrary, potentially
malicious, behavior. BFT protocols use the State Machine Replication (SMR) algorithm [149, 205] where the system
provides a replicated service whose state is mirrored across diÔ¨Äerent deterministic replicas. At a high level, the goal of a
BFT SMR protocol is to assign each client request an order in the global service history and execute it in that order [210].
In a BFT SMR protocol, all non-faulty replicas execute the same requests in the same order (safety) and all correct client

2

) specify valid points (i.e., BFT protocols) while red dots (

Figure 1: A simpliÔ¨Åed design space with two dimensions: number of replicas and number of commitment phases. Green dots
(
) show invalid points (i.e., impossible protocols). A design choice,
i.e., phase reduction (through redundancy), is a one-to-one transformation function that maps a protocol in its domain to another
protocol in its range.

requests are eventually executed (liveness). In an asynchronous system, where replicas can fail, there are no consensus
solutions that guarantees both safety and liveness (FLP result) [109]. As a result, asynchronous consensus protocols
rely on diÔ¨Äerent techniques such as randomization [46, 67, 198], failure detectors [76, 169], hybridization/wormholes
[83, 188] and partial synchrony [100, 103] to circumvent the FLP impossibility result.

BEDROCK assumes the partially synchrony model as it is used in most practical BFT protocols. In the partially synchrony
model, there exists an unknown global stabilization time (GST), after which all messages between correct replicas are
received within some unknown bound Œî. BEDROCK further inherits the standard assumptions of existing BFT protocols.
First, while there is no upper bound on the number of faulty clients, the maximum number of concurrent malicious
replicas is assumed to be ùëì . Second, replicas are connected via an unreliable network that might drop, corrupt, or
delay messages. Third, the network uses point-to-point bi-directional communication channels to connect replicas.
Fourth, the failure of replicas is independent of each other, where a single fault does not lead to the failure of multiple
replicas. This can be achieve by either diversifying replica implementation (e.g., n-version programming) [38, 110]
or placing replicas at diÔ¨Äerent geographic locations (e.g., datacenters) [49, 104, 213, 223]. Finally, a strong adversary
can coordinate malicious replicas and delay communication. However, the adversary cannot subvert cryptographic
assumptions.

Usage model. BEDROCK aims to help application developers experimentally analyze BFT protocols within one uniÔ¨Åed
platform and Ô¨Ånd the BFT protocol that Ô¨Åts the characteristics of their applications. To achieve this goal, the BEDROCK
tool makes available the design dimensions of BFT protocols and diÔ¨Äerent design choices, i.e., trade-oÔ¨Äs between di-
mensions, to application developers to tune. Figure 1 illustrates an example highlighting the relation between design
space, dimensions, design choices, and protocols in BEDROCK. For the sake of simplicity, we present only two dimen-
sions of the design space, i.e., number of replicas and number of commitment phases (the design space of BEDROCK
consists of more than 10 dimensions as described in Section 3). Each dimension, e.g., number of replicas, can take
diÔ¨Äerent values, e.g., 3ùëì + 1, 5ùëì + 1, 7ùëì + 1, etc. A BFT protocol is then a point in this design space, e.g., (3, 3ùëì + 1).
Note that each dimension not presented in this Ô¨Ågure also takes a value, e.g., communication strategy is assumed to be
pessimistic.
Moreover, a subset of points is valid and represents BFT protocols. In Figure 1, green dots ( ) specify valid points (i.e.,
BFT protocols) while red dots ( ) show invalid points (i.e., impossible protocols). For example, there is no (pessimistic)
BFT protocol with 3ùëì + 1 nodes that commits requests in a single commitment phase. A design choice (Section 4)
is then a one-to-one function that maps a BFT protocol in its domain to another protocol in its range. For example,
phase reduction (through redundancy) maps a BFT protocol with 3ùëì + 1 nodes and 3 phases of communication, e.g.,
PBFT [71], to a BFT protocol with 5ùëì + 1 nodes and 2 phases of communication, e.g., FaB [174] (assuming both
protocols are pessimistic and follow clique topology). The domain and range of each design choice is a subset of BFT
protocols in the design space.

In a BFT protocol, as presented in Figure 2, clients communicate with a set of replicas that maintain a copy of the
application state. A replica‚Äôs lifecycle consists of ordering, execution, view-change, checkpointing, and recovery stages.
The goal of the ordering stage is to establish agreement on a unique order, among requests executing on the application
state. In leader-based consensus protocols, which are the focus of this paper, a designated leader node proposes the
order, and to ensure fault tolerance, needs to get agreement from a subset of the nodes, referred to as a quorum. In
the execution stage, requests are applied to the replicated state machine. The view-change stage replaces the current
leader. Checkpointing is used to garbage-collect data and enable trailing replicas to catch up, and Ô¨Ånally, the recovery
stage recovers replicas from faults by applying software rejuvenation techniques.

3

Figure 2: DiÔ¨Äerent stages of replicas in a BFT protocol

3 Design Space

In BEDROCK, each BFT protocol can be analyzed along several dimensions. These dimensions (and values associated
with each dimension) collectively help to deÔ¨Åne the overall design space of BFT protocols supported by BEDROCK.
The dimensions are categorized into four families: environmental settings and protocol structure that present the core
dimensions of BFT protocols and are shared among all BFT protocols, a set of optional QoS features including order-
fairness and load balancing that a BFT protocol might support, and a set of performance optimizations for tuning BFT
protocols. In the rest of this section, we describe these families of dimensions in greater detail. As we describe each
dimension, we preÔ¨Åx label them with "E" for environmental settings, "P" for protocol structure, etc. Hence, "E 1" refers
to the Ô¨Årst dimension in the environmental settings dimensions family.

This section is not meant to provide a fully exhaustive set of dimensions, but rather to demonstrate the overall meth-
odology used to deÔ¨Åne dimensions usable in BEDROCK.

3.1 Environmental Settings

Environmental settings broadly speaking encompass the deployment environment for a BFT protocol, e.g., network
size. These input parameters help scope the class of BFT protocols that can be supported to best Ô¨Åt each deployment
environment.

E 1: Number of replicas. Our Ô¨Årst dimension concerns selecting BFT protocols based on the number of replicas (i.e.,
network and quorum size) used in a deployment. In the presence of ùëì malicious failures, BFT protocols require at
least 3ùëì +1 replicas to guarantee safety [56, 57, 86, 103, 156]. Using trusted hardware, however, the malicious behavior
of replicas can be restricted. Hence, 2ùëì + 1 replicas are suÔ¨Écient to guarantee safety [79, 85, 87, 200, 223, 223, 224].
Prior proposals on reducing the required number of replicas to 2ùëì + 1 [14‚Äì16] involve either leveraging new hardware
capabilities or using message-and-memory models. Increasing the number of replicas to 5ùëì + 1 [174] (its proven lower
bound, 5ùëì ‚àí 1 [11, 147]) or 7ùëì + 1 [212], on the other hand, reduces the number of communication phases. A BFT
protocol might also optimistically assume the existence of a quorum of 2ùëì + 1 active non-faulty replicas to establish
consensus [96, 133]. Using both trusted hardware and active/passive replication, the quorum size is further reduced to
ùëì + 1 during failure-free situations [96, 97, 133].
E 2: Communication topology. BEDROCK allows users to analyze BFT protocols based on communication topologies
including: (1) the star topology where communication is strictly from a designated replica, e.g., the leader, to all other
replicas and vice-versa, resulting in linear message complexity [143,230], (2) the clique topology where all (or a subset
of) replicas communicate directly with each other resulting in quadratic message complexity [71], (3) the tree topology
where the replicas are organized in a tree with the leader placed at the root, and at each phase, a replica communicates
with either its child replicas or its parent replica causing logarithmic message complexity [140, 141, 186], or (4) the
chain topology where replicas construct a pipeline and each replica communicates with its successor replica (constant
message complexity) [35].

E 3: Authentication. Participants authenticate their messages to enable other replicas to verify a message‚Äôs origin.
BEDROCK support both signatures, e.g., RSA [202] and authenticators [71], i.e., vectors of message authentication
codes (MACs) [219]. Constant-sized threshold signatures [67, 208] have also been used to reduce the size of a set
(quorum) of signatures. Signatures are typically more costly than MACs. However, in contrast to MACs, signatures
provide non-repudiation and are not vulnerable to MAC-based attacks from malicious clients. A BFT protocol might
even use diÔ¨Äerent techniques (i.e., signatures and MACs) in diÔ¨Äerent stages to authenticate messages sent by clients,
by replicas in the ordering stage, and by replicas during view-change.

E 4: Responsiveness, Synchronization and Timers. A BFT protocol is responsive if its normal case commit latency
depends only on the actual network delay needed for replicas to process and exchange messages rather than any (usually
much larger) predeÔ¨Åned upper bound on message transmission delay [34, 192, 193, 209]. Responsiveness might be

4

sacriÔ¨Åced in diÔ¨Äerent ways. First, when the rotating leader mechanism is used, the new leader might need to wait for
a predeÔ¨Åned time before initiating the next request to ensure that it receives the decided value from all non-faulty but
slow replicas, e.g., Tendermint [148] and Casper [65]. Second, optimistically assuming all replicas are non-faulty,
replicas (or clients) need to wait for a predeÔ¨Åned upper bound to receive messages from all replicas, e.g., SBFT [120]
and Zyzzyva [143].

BFT protocols need to guarantee that all non-faulty replicas will eventually be synchronized to the same view with a
non-faulty leader enabling the leader to collect the decided values in previous views and making progress in the new
view [59, 182, 183]. This is needed because a quorum of 2ùëì + 1 replicas might include ùëì Byzantine replicas and
the remaining ùëì "slow" non-faulty replicas might stay behind (i.e., in-dark) and may not even advance views at all.
View synchronization can be achieved in diÔ¨Äerent ways such as integrating the functionality with the core consensus
protocol, e.g., PBFT [71], or assigning a distinct synchronizer component, e.g., Pacemaker in HotStuÔ¨Ä [230], and
hardware clocks [5].

Depending on the environment, network characteristics, and processing strategy, BFT protocols use diÔ¨Äerent timers
to ensure responsiveness and synchronization. Protocols can be conÔ¨Ågured with the following timers by BEDROCK to
achieve these goals.

. Waiting for reply messages, e.g., Zyzzyva [143],
. Triggering (consecutive) view-change, e.g., PBFT [71],
. Detecting backup failures, e.g., SBFT [120],
. Quorum construction in an ordering phase, e.g., prevote and precommit timeouts in Tendermint [62],
. Synchronization for view change, e.g., Tendermint [62],
. Finishing a (preordering) round, e.g., Themis [135],
. Performance check (heartbeat timer), e.g., Aardvark [81],
. Atomic recovery (watchdog timer) to periodically hand control to a recovery monitor [69], e.g., PBFT [70].

ùúè1
ùúè2
ùúè3
ùúè4
ùúè5
ùúè6
ùúè7
ùúè8

3.2 Protocol Structure

Our next family of dimensions concerns customization of the protocol structure by BEDROCK, which will further deÔ¨Åne
the class of protocols permitted.

P 1: Commitment strategy. BEDROCK supports BFT protocols that process transactions in either an optimistic, pess-
imistic, or robust manner. Optimistic BFT protocols make optimistic assumptions on failures, synchrony, or data
contention and might execute requests without necessarily establishing consensus. An optimistic BFT protocol might
make a subset of the following assumptions:

ùëé1
ùëé2
ùëé3
ùëé4
ùëé5
ùëé6

. The leader is non-faulty, assigns a correct order to requests and sends it to all backups, e.g., Zyzzyva [143],

. The backups are non-faulty and actively and honestly participate in the protocol, e.g., CheapBFT [133],

. All non-leaf replicas in a tree topology are non-faulty, e.g., Kauri [186],

. The workload is conÔ¨Çict-free and concurrent requests update disjoint sets of data objects, e.g., Q/U [4],

. The clients are honest, e.g., Quorum [35], and

. The network is synchronous (in a time window), and messages are not lost or highly delayed, e.g., Tendermint

[62].

Optimistic protocols are classiÔ¨Åed into speculative and non-speculative protocols. In non-speculative protocols, e,g.,
SBFT [120] and CheapBFT [133], replicas execute a transaction only if the optimistic assumption holds. Speculative
protocols, e.g., Zyzzyva [143] and PoE [123], on the other hand, optimistically execute transactions. If the assumption is
not fulÔ¨Ålled, replicas might have to rollback the executed transactions. Optimistic BFT protocols improve performance
in fault-free situations. If the assumption does not hold, the replicas, e.g., SBFT [120], or clients, e.g., Zyzzyva [143],
detect the failure and use the fallback protocol.

Pessimistic BFT protocols, on the other hand, tolerate the maximum number of possible concurrent failures ùëì without
making any assumptions on failures, synchrony, or data contention. In pessimistic BFT protocols, replicas communicate
to agree on the order of requests. Finally, robust protocols, e.g., Prime [22], Aardvark [81], R-Aliph [35], Spinning [222]
and RBFT [36], go one step further and consider scenarios where the system is under attack.

5

In summary, BFT protocols demonstrate diÔ¨Äerent performance in failure-free, low failure, and under attack situations.
Optimistic protocols deliver superior performance in failure-free situations. However, in the presence of failure, their
performance is signiÔ¨Åcantly reduced especially when the system is under attack. On the other hand, pessimistic proto-
cols provide high performance in failure-free situations and are able to handle low failures with acceptable overhead.
However, they show poor performance when the system is under attack. Finally, robust protocols are designed for
under-attack situations and demonstrate moderate performance in all three situations.

P 2: Number of commitment phases. The number of commitment (ordering) phases or good-case latency [11] of a
BFT SMR protocol is the number of phases needed for all non-faulty replicas to commit when the leader is non-faulty,
and the network is synchronous. We consider the number of commitment phases from the Ô¨Årst time a replica (typically
the leader) receives a request to the Ô¨Årst time any participant (i.e., leader, backups, client) learns the commitment of
the request, e.g., PBFT executes in 3 phases.

P 3: View-change. BFT protocols follow either the stable leader or the rotating leader mechanism to replace the
current leader. The stable leader mechanism [71, 120, 143, 174] replaces the leader when the leader is suspected to
be faulty by other replicas. In the rotating leader mechanism [19, 64, 72‚Äì74, 81, 114, 127, 141, 148, 222, 223, 230], the
leader is replaced periodically, e.g., after a single attempt, insuÔ¨Écient performance, or an epoch (multiple requests).

Using the stable leader mechanism, the view-change stage becomes more complex. However, the routine is only ex-
ecuted when the leader is suspected to be faulty. On the other hand, the rotating leader mechanism requires ensuring
view synchronization frequently (whenever the leader is rotated). Rotating the leader has several beneÔ¨Åts such as balan-
cing load across replicas [44,45,222], improving resilience against slow replicas [81], and minimizing communication
delays between clients and the leader [104, 173, 223].

P 4: Checkpointing. The checkpointing mechanism is used to Ô¨Årst, garbage-collect data of completed consensus
instances to save space and second, restore in-dark replicas (due to network unreliability or leader maliciousness) to
ensure all non-faulty replicas are up-to-date [71, 95, 123]. The checkpointing stage typically is initiated after a Ô¨Åxed
checkpoint window in a decentralized manner without relying on a leader [71].

P 5: Recovery. When there are more than ùëì failures, BFT protocols, apart from some exceptions [79,164], completely
fail and do not give any guarantees on their behavior [95]. BFT protocols perform recovery using reactive or proactive
mechanisms (or a combination [214]). Reactive recovery mechanisms detect faulty replica behavior [126] and recover
the replica by applying software rejuvenation techniques [90,130] where the replica reboots, reestablishes its connection
with other replicas and clients, and updates its state. On the other hand, proactive recovery mechanisms recover replicas
in periodic time intervals. Proactive mechanisms do not require any fault detection techniques, however, they might
unnecessarily recover non-faulty replicas [95]. During recovery, a replica is unavailable. A BFT protocol can rely on
3ùëì + 2ùëò + 1 replicas to improve resilience and availability during recovery where ùëò is the maximum number of servers
that rejuvenate concurrently [214]. To prevent attackers from disrupting the recovery process, each replica requires a
trusted component, e.g., secure coprocessor [70], a synchronous wormhole [221] or a virtualization layer [97,200], that
remains operational even if the attacker controls the replica and a read-only memory that an attacker cannot manipulate.
The memory content remains persistent (e.g., on disk) across machine reboots and includes all information needed for
bootstrapping a correct replica after restart [95].

P 6: Types of Clients. BEDROCK supports three types of clients: requester, proposer, and repairer. Requester clients
perform a basic functionality and communicate with replicas by sending requests and receiving replies. A requester
client might need to verify the results by waiting for a number of matching replies, e.g., ùëì + 1 in PBFT [71], 2ùëì + 1
in PoE [123] and PBFT [71] (for read-only requests) , or 3ùëì + 1 is Zyzzyva [143]. Using trusted components, e.g.,
Troxy [161], or threshold signatures, e.g., SBFT [120], the client does not even need to wait for and verify multiple
results from replicas. Clients might also play the proposer role by proposing a sequence number (acting as the leader)
for its request [4, 119, 170, 172]. Repairer clients, on the other hand, detect the failure of replicas, e.g., Zyzzyva [143],
or even change the protocol conÔ¨Åguration, e.g., Scrooge [206], Abstract [35], and Q/U [4].

3.3 Quality of Service

There are some optional QoS features that BEDROCK can analyze. We list two example dimensions.

, then ùë°1

Q 1: Order fairness. Order-fairness deals with preventing adversarial manipulation of request ordering [40, 135, 136,
145, 146, 233]. Order-fairness is deÔ¨Åned as: "if a large number of replicas receives a request ùë°1
before another request
" [136]. Order fairness has been partially addressed using diÔ¨Äerent techniques:
ùë°2
(1) monitoring the leader to ensure it does not initiate two new requests from the same client before initiating an old
request of another client, e.g., Aardvark [81], (2) adding a preordering phase, e.g., Prime [22], where replicas order
the received requests locally and share their own ordering with each other, (3) encrypting requests and revealing the

should be ordered before ùë°2

6

contents only once their ordering is Ô¨Åxed [33, 66, 177, 216], (4) reputation-based systems [33, 93, 142, 159] to detect
unfair censorship of speciÔ¨Åc client requests, and (5) providing opportunities for every replica to propose and commit
its requests using fair election [8, 33, 114, 137, 159, 192, 228].

Q 2: Load balancing. The performance of fault-tolerant protocols is usually limited by the computing and bandwidth
capacity of the leader [17, 53, 77, 179, 180, 186, 226]. The leader coordinates the consensus protocol and multic-
asts/collects messages to all other replicas in diÔ¨Äerent protocol phases. Load balancing is deÔ¨Åned as distributing the
load among the replicas of the system to balance the number of messages any single replica has to process.

Load balancing can be partially achieved using the rotating leader mechanism, multi-layer, or multi-leader BFT proto-
cols. When the rotating leader mechanism is used, one (leader) replica still is highly loaded in each consensus instance.
In multi-layer BFT protocols [23,125,165,185,187] the load of the leader is distributed between the leaders of diÔ¨Äerent
clusters. However, the system still suÔ¨Äers from load imbalance between the leader and backup replicas in each cluster.
In multi-leader protocols [20, 31, 37, 124, 215, 225], all replicas can initiate consensus to partially order requests in
parallel. However, slow replicas still aÔ¨Äect the global ordering of requests.

3.4 Performance Optimization Dimensions

Finally, we present a set of optimization dimensions that target the performance of a BFT protocol.

O 1: Out-of-order processing. The out-of-order processing mechanism enables the leader to continuously propose
new requests even when previous requests are still being processed by the backups [123]. Out-of-order processing of
requests is possible if the leader does not need to include any certiÔ¨Åcate or hash of the previous request (block) in its
next request.

O 2: Request pipelining. Using request pipelining, the messages of a new consensus instance are piggybacked on
the second round messages of the previous instance [186, 230]. This technique is especially eÔ¨Écient when a protocol
rotates the leader after every consensus instance.

O 3: Parallel ordering. Client requests can be ordered in parallel by relying on a set of independent ordering groups
[44, 45, 162] where each group orders a subset of client requests and then all results are deterministically merged into
the Ô¨Ånal order. Similarly, in multi-leader protocols [20, 31, 32, 37, 105, 124, 162, 178, 215, 225, 225], diÔ¨Äerent replicas
are designated as the leader for diÔ¨Äerent consensus instances in parallel and then a global order is determined.

O 4: Parallel execution. Transactions can be executed in parallel to improve the system‚Äôs overall performance. One
approach is to detect non-conÔ¨Çicting transactions and execute them in parallel [25, 108, 144]. This approach requires a
priori knowledge of a transaction‚Äôs read-set and write-set. Switching the order of agreement and execution stages and
optimistically executing transactions in parallel is another approach [30, 134]. If the execution results are inconsistent
(due to faulty replicas, conÔ¨Çicting transactions, or nondeterministic execution), replicas need to rollback their states
and sequentially and deterministically re-execute the requests. switching the order of agreement and execution stages
also enables replicas to detect any nondeterministic execution [30, 134].

O 5: Read-only requests processing. In pessimistic protocols, replicas can directly execute read-only requests without
establishing consensus. However, since replicas may execute the read requests on diÔ¨Äerent states, even non-faulty
replicas might not return identical results. To resolve this, the number of required matching replies for both normal and
read-only requests needs to be increased from ùëì + 1 to 2ùëì + 1 in order to ensure consistency (i.e., quorum intersection
requirement) [70]. This, however, results in a liveness challenge because ùëì non-faulty replicas might be slow (or in-
dark) and not receive the request. As a result, the client might not be able to collect 2ùëì + 1 matching responses (since
Byzantine replicas may not send a correct reply to the client).

O 6: Separating ordering and execution. The ordering and execution stages can be separated and implemented in
diÔ¨Äerent processes. This separation leads to several advantages [95] such as preventing malicious execution replicas
from leaking conÔ¨Ådential application state to clients [102,229], enabling large requests to bypass the ordering stage [80],
moving application logic to execution virtual machine [97, 200, 227] or simplifying the parallel ordering of requests
[44, 47]. Moreover, while 3ùëì +1 replicas are needed for ordering, 2ùëì + 1 replicas are suÔ¨Écient to execute transactions
[229].

O 7: Trusted hardware. Using Trusted execution environments (TEEs) such as Intel‚Äôs SGX [175], Sanctum [89], and
Keystone [158], the number of required replicas can be lowered to 2ùëì + 1 because the trusted component prevents
a faulty replica from sending conÔ¨Çicting messages to diÔ¨Äerent replicas without being detected. A trusted component
may include an entire virtualization layer [97, 200, 223], a multicast ordering service executed on a hardened Linux

7

Figure 3: DiÔ¨Äerent stages of PBFT protocol

kernel [84, 85], a centralized conÔ¨Åguration service [201], a trusted log [79], a trusted platform module, e.g., counter
[223, 224], a smart card TrInc [160], or an FPGA [96, 133].

O 8: Request/reply dissemination. A client can either multicast its request to all replicas [51, 91, 222] where each
replica relays the request to the leader or optimistically send its request to a contact replica, typically the leader. The
contact replica is known to the client through a reply to an earlier request [71, 143]. If the client timer for the request
(ùúè1
) expires, the client multicasts its request to all replicas. This optimistic mechanism requires fewer messages to be
sent from clients to the replicas. However, this comes at the cost of increased network traÔ¨Éc between replicas, because
the leader needs to disseminate the full request to other replicas to enable them to eventually execute it.

On the other hand, all replicas can send the results to clients in their reply messages. This, however, leads to signiÔ¨Åcant
network overhead for large results. A protocol can optimistically rely on a designated responder replica (chosen by the
client or servers) to send the full results. Other replicas then either send the hash of the results to the client or send a
signed message to the responder enabling the responder to generate a proof for the results, e.g., SBFT [120]. While
this technique reduces network overhead, the client might not receive the results if the responder replica is faulty, the
network is unreliable, or the responder replica was in-dark and skipped the execution and applied a checkpoint to catch
up [95].

4 Design Choices Landscape

Given a set of speciÔ¨Åed dimension values in Section 3, BEDROCK generates a set of valid protocols that meet a user
query. Each protocol represents a point in the BEDROCK design space. In this section, using the classical PBFT [70, 71]
as a driving example, we demonstrate how diÔ¨Äerent points in the design space lead to diÔ¨Äerent trade-oÔ¨Äs. Each design
choice is a one-to-one function that maps a valid input point (i.e., a BFT protocol) to another valid output point in the
design space. The domain of each function (design choice) is a subset of the valid points in the design space. These
design choices enable BEDROCK to generate valid BFT protocols.

4.1 Background on PBFT

PBFT, as shown in Figure 3, is a leader-based protocol that operates in a succession of conÔ¨Ågurations called views
[106, 107]. Each view is coordinated by a stable leader (primary) and the protocol pessimistically processes requests.
In PBFT, the number of replicas, ùëõ, is assumed to be 3ùëì + 1 and the ordering stage consists of pre-prepare, prepare,
and commit phases. The pre-prepare phase assigns an order to the request, the prepare phase guarantees the uniqueness
of the assigned order and the commit phase guarantees that the next leader can assign order in a safe manner.
During a normal case execution of PBFT, clients send their signed request messages to the leader. In the pre-prepare
phase, the leader assigns a sequence number to the request to determine the execution order of the request and multicasts
a pre-prepare message including the full request to all backups. Upon receiving a valid pre-prepare message from
the leader, each backup replica multicasts a prepare message to all replicas and waits for prepare messages from 2ùëì
diÔ¨Äerent replicas (including the replica itself) that match the pre-prepare message. The goal of the pre-prepare phase
is to guarantee safety within the view, i.e., a majority of non-faulty replicas received matching pre-prepare messages
from the leader replica and agree with the order of the request. Each replica then multicasts a commit message to all
replicas. Once a replica receives 2ùëì + 1 valid commit messages from diÔ¨Äerent replicas including itself) that match the
pre-prepare message, it commits the transaction. The goal of the commit phase is to ensure safety across views, i.e., the
request has been replicated on a majority of non-faulty replicas. The second and third phases of PBFT follow the clique
topology, i.e., have Óàª(ùëõ2) message complexity. If the replica has executed all requests with lower sequence numbers,
it executes the transaction and sends a reply to the client. The client waits (timer ùúè1
) for ùëì + 1 matching results from
diÔ¨Äerent replicas.

8

), backups exchange
In the view change stage, upon detecting the failure of the leader of view ùë£ using timeouts (timer ùúè2
view-change messages including transactions that have been received by the replicas. After receiving 2ùëì + 1 view-
change messages, the designated stable leader of view ùë£ + 1 (the replica with ID = ùë£ + 1 mod ùëõ) proposes a new view
message including a list of transactions that should be processed in the new view.

In PBFT replicas periodically generate and send checkpoint messages to all other replicas. If a replica receives 2ùëì + 1
matching checkpoint messages, the checkpoint is stable. PBFT also includes a proactive recovery mechanism that
periodically (timer ùúè8
PBFT uses either signatures [71] or MACs [70] for authentication. Using MACs, replicas need to send view-change-
ack messages to the leader after receiving view-change messages. Since new view messages are not signed, these
view-change-ack enable replicas to verify the authenticity of new view messages.

) rejuvenates replicas one by one.

4.2 Expanding the Design Choices of PBFT

Using the PBFT protocol and our design dimensions as a baseline, we illustrate a series of design choices that expose
diÔ¨Äerent trade-oÔ¨Äs BFT protocols need to make. Each design choice acts as a one-to-one function that changes the
value of one or multiple dimensions to map a BFT protocol, e.g., PBFT, to another BFT protocol.

Design Choice 1: Linearization. This function explores a trade-oÔ¨Ä between communication topology and communic-
ation phases. The function takes a quadratic communication phase, e.g., prepare or commit in PBFT, and split it into
two linear phases: one phase from all replicas to a collector (typically the leader) and one phase from the collector to
all replicas, e.g., SBFT [120], HotStuÔ¨Ä [230]. The output protocol requires (threshold) signatures for authentication.
The collector collects a quorum of (typically ùëõ ‚àí ùëì ) signatures from other replicas and broadcasts its message including
the signatures as the certiÔ¨Åcate of receiving messages to every replica. Using threshold signatures [66, 67, 199, 208]
the collector message size can be further reduced from linear to constant.

Design Choice 2: Phase reduction through redundancy. This function explores a trade-oÔ¨Ä between the number of
ordering phases and the number of replicas. The function transforms a protocol with 3ùëì + 1 replicas and 3 ordering
phases (i.e., one linear, two quadratic), e.g., PBFT, to a fast protocol with 5ùëì + 1 replicas and 2 ordering phases
(one linear, one quadratic), e.g., FaB [174]. In the second phase of the protocol, matching messages from a quorum
of 4ùëì + 1 replicas are required. Recently, 5ùëì ‚àí 1 has been proven as the lower bound for two-step (fast) Byzantine
consensus [11,147]. The intuition behind the 5ùëì ‚àí1 lower bound is that in an authenticated model, when replicas detect
leader equivocation and initiate view-change, they do not include view-change messages coming from the malicious
leader reducing the maximum number of faulty messages to ùëì ‚àí 1 [11, 147].
Design Choice 3: Leader rotation. This function replaces the stable leader mechanism with the rotating leader mech-
anism, e.g., HotStuÔ¨Ä [230] where the rotation happens after each request or epoch or due to low performance. The
function eliminates the view-change stage and adds a new quadratic phase or 2 linear phases (using the linearization
function) to the ordering stage to ensure that the new leader is aware of the correct state of the system.

Design Choice 4: Non-responsive leader rotation. This function replaces the stable leader mechanism with the rotat-
ing leader mechanism without adding a new ordering phase (in contrast to design choice 3) while sacriÔ¨Åcing respons-
iveness. The new leader optimistically assumes that the network is synchronous and waits for a predeÔ¨Åned known
upper bound Œî (Timer ùúè4
) before initiating the next request. This is needed to ensure that the new leader is aware of
the highest assigned order to the requests, e.g., Tendermint [63, 148] and Casper [65].

Design Choice 5: Optimistic replica reduction. This function reduces the number of involved replicas in consensus
from 3ùëì + 1 to 2ùëì + 1 while optimistically assuming all 2ùëì + 1 replicas are non-faulty (assumption ùëé2
). In each phase
of a BFT protocol, matching messages from a quorum of 2ùëì + 1 replicas is needed. If a quorum of 2ùëì + 1 non-faulty
replicas is identiÔ¨Åed, they can order (and execute) requests without the participation of the remaining ùëì replicas. Those
ùëì replicas remain passive and are needed if any of the 2ùëì + 1 active replicas become faulty [96, 133]. Note that ùëõ is
still 3ùëì + 1.
Design Choice 6: Optimistic phase reduction. Given a linear BFT protocol, this function optimistically eliminates
two linear phases (i.e., equal to the quadratic phase prepare) assuming all replicas are non-faulty, e.g., SBFT [120].
The leader (collector) waits for signed messages from all 3ùëì + 1 replicas in the second phase of ordering, combines
signatures and sends a signed message to all replicas. Upon receiving the signed message from the leader, each replica
ensures that all non-faulty replicas has received the request and agreed with the order. As a result, the third phase of
communication can be omitted and replicas can directly commit the request. If the leader has not received 3ùëì + 1
), the protocol fall backs to its slow path and runs the third phase of ordering.
messages after a predeÔ¨Åned time (timer ùúè3

9

Table 1: Comparing selected BFT protocols based on diÔ¨Äerent dimensions of BEDROCK design space

Protocol

PBFT [71]

Zyzzyva [143]

Zyzzyva5 [143]

PoE [123]

SBFT [120]

HotStuÔ¨Ä [230]

Tendermint [63]

Themis [135]

Kauri [186]

CheapBFT [133]

FaB [174]

Prime [22]

Q/U [4]

FLB

FTB

E1.
Replicas

E2.
Topo.

E3.
Auth.

E4.
Timers

3ùëì + 1

3ùëì + 1

5ùëì + 1

3ùëì + 1

3ùëì + 1

3ùëì + 1

3ùëì + 1

4ùëì + 1

3ùëì + 1

2ùëì + 1

5ùëì + 1

3ùëì + 1

5ùëì + 1

5ùëì ‚àí 1

clique

MAC || Sign

star

star

star

star

star

clique

star

tree

clique

clique

clique

star

clique

MAC || Sign

MAC || Sign

MAC || T-Sign

T-Sign

T-Sign

Sign

T-Sign

T-Sign

MAC

(Sign)

Sign

MAC

Sign

ùúè1

ùúè1

ùúè1

, ùúè2
, ùúè8
, ùúè2
ùúè1
, ùúè2
, ùúè2
ùúè1
, ùúè2
, ùúè3
, ùúè2
ùúè1
, ùúè5
, ùúè2
, ùúè6
, ùúè2
, ùúè6
ùúè1
, ùúè2
ùúè1
, ùúè2
, ùúè2
, ùúè6
, ùúè2
, ùúè2
, ùúè2

ùúè1
, ùúè2
ùúè1

, ùúè7

ùúè1

ùúè1

ùúè1

ùúè1

P1.
Strategy

pessimistic

optimis: ùëé1

, ùëé2

|Spec

optimis: ùëé1
optimis: ùëé2

|Spec

|Spec

optimis: ùëé2
pessimistic

optimis: ùëé6
pessimistic

optimis: ùëé3
optimis: ùëé2
pessimistic

robust

optimis: ùëé4

, ùëé5
pessimistic

P2.
Phases

P3.
V-change

3

1 (3)

1 (3)

3

3 (5)

7

3

1 + 7

7‚Ñé

3

2

6

1 (3)

2

stable

stable

stable

stable

stable

rotating

rotating

rotating

stable*

stable

stable

stable

stable

stable

P5.
Recov.

pro.

-

-

-

-

-

-

-

-

-

-

-

-

-

P6.
Client

Q1.
Fair.

Q2.
Load.

Design
Choices

Req.

Rep.

Rep.

Req.

Req.

Req.

Req.

Req.

Req.

Req.

Req.

Req.

Rep.

Req.

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ†

‚ñ°

‚ñ°

‚ñ°

‚ó™

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ†

‚ñ°

‚ñ°

‚ñ°

‚ñ°

‚ñ°

(11)

8, (11)

8, 10, (11)

1, 7, 11

1, 6, 11

1, 3, 11

4, 11

1, 3, 13, 11

(3), 14, 11

5

2

11, 12

9, 10

1, 2, 11

5ùëì ‚àí 1

optimis: ùëé3
Hint: T-Sign is used for threshold signatures. Speculative optimistic protocols are speciÔ¨Åed by Spec. The number of phases in slow-path of optimistic protocols is
shown within parenthesis. While Kauri is implemented on top of HotStuÔ¨Ä, it does not use the rotating leader mechanism. Prime provides partial fairness.

T-Sign

stable

Req.

tree

3‚Ñé

ùúè1

‚ñ°

‚ñ†

-

1, 2, 14, 11

Design Choice 7: Speculative phase reduction. This function, similar to the previous one, optimistically eliminates
two linear phases of the ordering stage assuming that non-faulty replicas construct the quorum of responses, e.g.,
PoE [123]. Th main diÔ¨Äerence is that the leader waits for signed messages from only 2ùëì + 1 replicas in the second
phase of ordering and sends a signed message to all replicas. Upon receiving a message signed by 2ùëì + 1 replicas
from the leader, each replica speculatively executes the transaction, optimistically assuming that either (1) all 2ùëì + 1
signatures are from non-faulty replicas or (2) at least ùëì + 1 non-faulty replicas received the signed message from the
leader. If (1) does not hold, other replicas receive and execute transaction during the view-change. However, if (2)
does not hold, the replica might have to rollback the executed transaction.

Design Choice 8: Speculative execution. This function eliminates the prepare and commit phases while optimistically
assuming that all replicas are non-faulty (optimistic assumptions ùëé1
), e.g., Zyzzyva [143]. Replicas speculatively
execute transactions upon receiving them from the leader. If the client does not receive 3ùëì + 1 matching replies after
a predeÔ¨Åned time (timer ùúè1
) or it receives conÔ¨Çicting messages, the client detects failures (repairer) and communicates
with replicas to receive 2ùëì + 1 commit messages (two linear phases).

and ùëé2

Design Choice 9: Optimistic conÔ¨Çict-free. Assuming that requests of diÔ¨Äerent clients are conÔ¨Çict-free (assumption
), there is no need for a total order among all transactions. The function eliminates all three ordering phases while
ùëé4
optimistically assuming that requests are conÔ¨Çict-free and all replicas are non-faulty. The client becomes the proposer
and sends its request to all (or a quorum of) replicas where replicas execute the client requests without any further
communication [4, 91].

Design Choice 10: Resilience. This function increases the number of replicas by 2ùëì to enable the protocol to tolerate ùëì
more failure with the same safety guarantees. In particular, optimistic BFT protocols that assume all 3ùëì + 1 replicas are
non-faulty (quorum size is also 3ùëì + 1) tolerate zero failures. By increasing the number of replicas to 5ùëì + 1 replicas,
such BFT protocols can provide the same safety guarantees with quorums of size 4ùëì + 1 while tolerating ùëì failures,
e.g., Zyzzyva5 [143], Q/U [4]. Similarly, a protocol with 5ùëì + 1 can tolerates ùëì more faulty replicas by increasing the
network size to 7ùëì + 1 [212].
The function can also be used to provide high availability during the (proactive) recovery stage by increasing the number
of replicas by 2ùëò (the quorum size by ùëò) where ùëò is the maximum number of servers that recover in parallel [214].
Design Choice 11: Authentication. This function replaces MACs with signatures for a given stage of a protocol. If a
protocol follows the star communication topology where a replica needs to include a quorum of signatures as a proof
of its messages, e.g., HotStuÔ¨Ä [230], ùëò signatures can be replaced with a single threshold signature. Note that in such
a situation MACs cannot be used (MACs do not provide non-repudiation).

10

Figure 4: Overview of BFT protocols

Design Choice 12: Robust. This function makes a pessimistic protocol robust by adding a preordering stage to the
protocol, e.g., Prime [22]. In the preordering stage and, upon receiving a request, each replica locally orders and
broadcasts the request to all other replica. All replicas then acknowledge the reception of the request in an all-to-all
communication phase and add the request to their local request vector. Replicas periodically share their vectors with
each other. The robust function provides (partial) fairness as well. Note that robustness has also been addressed in
other ways, e.g., using the leader rotation and a blacklisting mechanism in Spinning [222] or isolating the incoming
traÔ¨Éc of diÔ¨Äerent replicas, and check the performance of the leader in Aardvark [81].

Design Choice 13: Fair. This function transforms an unfair protocol, e.g., PBFT, to a fair protocol by adding a pre-
ordering phase to the protocol. In the preordering phase, clients send transactions to all replicas and once a round ends
), all replicas send a batch of requests in the order received1 to the leader. The leader then initiates consensus
(timer ùúè5
on the requests following the order of transactions in received blocks. Depending on the order-fairness parameter ùõæ
(0.5 < ùõæ ‚â§ 1) that deÔ¨Ånes the fraction of replicas receiving the transactions in that speciÔ¨Åc order, at least 4ùëì +1 replicas
(ùëõ > 4ùëì
2ùõæ‚àí1

) replicas are needed to provide order fairness [135, 136] 2.

Design Choice 14: LoadBalancer. This function explores a trade-oÔ¨Ä between communication topology and load
balancing where load balancing is supported by organizing replicas in a tree topology, with the leader placed at the
root, e.g., Kauri [186]. The function takes a linear communication phase, and splits it into ‚Ñé communication phases
where ‚Ñé is the height of the tree. Each replica then uniformly communicates with its child/parent replicas in the
).
tree. Using the tree topology, the protocol optimistically assumes all non-leaf replicas are non faulty (assumption ùëé3
Otherwise the tree needs to be reconÔ¨Ågured (i.e., view change).

5 Deriving, Evolving and Inventing Protocols

This section demonstrate how BEDROCK is used to derive a wide range of BFT protocols using design choices. Figure 5
demonstrates the derivation of a wide spectrum of classical and recent BFT protocols from PBFT using design choices.
Table 1 provides insights into how each BFT protocol maps into the BEDROCK design space. The table also presents
the design choices used by each BFT protocol.

5.1 Case Studies on Protocol Evolution

In the following case studies, we provide insights into how each BFT protocol maps into the BEDROCK design space,
and relate to one another through using design choices. For illustrative purposes, we describe each protocol relative
to PBFT along one or more design choices. Figure 4 focuses on diÔ¨Äerent stages of replicas and demonstrates the
communication complexity of each stage. The Ô¨Ågure presents: (1) the preordering phases used in Themis and Prime,
), (3) the execution
(2) the three ordering phases, e.g., pre-prepare, prepare or commit in PBFT (labeled by ùëú1

, and ùëú3

, ùëú2

1The request propagation time can be estimated by measuring network latency or relying on client timestamps for non-Byzantine

clients

2Order fairness can be provided using 3ùëì + 1 replicas, however, as shown in [135], it either requires a synchronized clock [233]

or does not provide censorship resistance [145].

11

Zyzzyva5 [143]

10. Resilience

Zyzzyva [143]

Tendermint [63]

PoE [123]

SBFT [120]

Kauri [186]

Q/U [4]

10. Resilience

8. Speculative
execution

4. Non-responsive
leader rotation

7. Speculative phase
reduction

6. Optimistic
phase reduction

14. Load
Balancer

Quorum [35]

5. Robust

9. Optimistic
conÔ¨Çict-free

PBFT [70]

1. Linearization

Linear PBFT

3. Leader
Rotation

HotStuÔ¨Ä [230]

Prime [22]

5. Optimistic
replica reduction

2. Phase
reduction

2. Phase
reduction

13. Fair

CheapBFT [133]

Bosco [212]

10. Resilience

FaB [174]

1. Linearization

FLB

14. Load
Balancer

FTB

Themis [135]

Figure 5: Derivation of protocols from PBFT using design choices

Figure 6: Zyzzyva

Figure 7: Zyzzyva (slow)

Figure 8: Zyzzyva5

Figure 9: Zyzzyva5 (slow)

stage, (4) the view-change stages consisting of view-change and new-view phases (labeled by ùë£1
), and (5) the
checkpointing stage. As can be seen, some protocols do not have all three ordering phases, i.e., using diÔ¨Äerent design
choices, the number of ordering phases is reduced. The dashed boxes present the slow-path of protocols, e.g., the third
ordering phase of SBFT is used only in its slow-path. Finally, the order of stages might be changed. For example,
HotStuÔ¨Ä runs view-change (leader rotation) for every single message and this leader rotation phase takes place at the
beginning of a consensus instance to synchronize nodes within a view.

and ùë£2

Next, we describe each BFT protocol.
Zyzzyva [143]. Zyzzyva3 (Figure 6) can be derived from PBFT using the speculative execution function (design choice
8) of BEDROCK where assuming the primary and all backups are non-faulty, replicas speculatively execute requests
without running any agreement and send reply messages to the client. The client waits for 3ùëì + 1 matching replies
to accept the results. If the timer ùúè1
is expired and the client received matching replies from between 2ùëì + 1 and 3ùëì
replicas, as presented in Figure 7, two more linear rounds of communication is needed to ensure that at least 2ùëì + 1
replicas have committed the request. Finally, Zyzzyva5 is derived from Zyzzyva by using the resilience function (design
choice 10) where the number of replicas is increased to 5ùëì + 1 and the protocol is able to tolerate ùëì and 2ùëì failures
during its fast and slow path respectively (presented in (Figures 8 and 9) AZyzzyva [35, 119] also uses the fast path of
Zyzzyva (called ZLight) in its fault-free situations.

PoE [123]. PoE Figure 12 uses the linearization and speculative phase reduction functions (design choices 1 and 7).
PoE does not assumes that all replicas are non-faulty and constructs quorum of 2ùëì + 1 replicas possibly including
Byzantine replicas. However, since a client waits for 2ùëì + 1 matching reply messages, all 2ùëì + 1 replicas constructing
the quorum need to be well-behaving to guarantee client liveness in the fast path.
SBFT [120]. BEDROCK derives SBFT4 from PBFT using the linearization and optimistic phase reduction functions
(design choices 1 and 6). SBFT presents an optimistic fast path (Figure 13) assuming all replicas are non-faulty. If
the primary does not receive messages from all backups (in the prepare phase) and its timer is expired (i.e., non-
responsiveness timer ùúè3
), SBFT switches to its slow path (Figure 14) and requires two more linear rounds of commu-
nication (commit phase). The Twin-path nature of SBFT requires replicas to sign each message with two schemes (i.e.,

3the view-change stage of the Zyzzyva protocol has a safety violation as described in [6]
4SBFT tolerates both crash and Byzantine failure (ùëõ = 3ùëì + 2ùëê + 1 where ùëê is the number of crashed replicas).Since the focus

of this paper is on Byzantine failures, we consider a variation of SBFT where ùëê = 0.

12

Figure 10: HotStuÔ¨Ä

Figure 11: Kauri

Figure 12: PoE

Figure 13: SBFT

Figure 14: SBFT (Linear PBFT)

2ùëì + 1 and 3ùëì + 1). To send replies to the client, a single (collector) replica receives replies from all replicas and sends
a single (threshold) signed reply message.

HotStuÔ¨Ä [230]. HotStuÔ¨Ä (Figure 10) can be derived from PBFT using the linearization and leader rotation functions
(design choices 1 and 3) of BEDROCK. The Chained HotStuÔ¨Ä (performance optimization 2) beneÔ¨Åts from pipelining to
reduce the latency of request processing.
Tendermint [62, 63, 148]. Tendermint5 leverages the non-responsive leader rotation function (design choice 4) to
rotate leader without adding any new phase. The new leader, however, needs to wait for a predeÔ¨Åned time (timer ùúè4
),
i.e., the worst-case time it takes to propagate messages over a wide-area peer-to-peer gossip network, before proposing
a new block. Tendermint also uses timers in all phases where a replica discard the request if it does not receive 2ùëì + 1
messages before the timeout (timer ùúè6
). Note that the original Tendermint uses a gossip all-to-all mechanism and has
Óàª(ùëõ log ùëõ) message complexity.
Themis [135]. Themis is derived from HotStuÔ¨Ä using the fair function (design choice 13). Themis add a new all-to-all
preordering phase where replicas send a batch of requests in the order they received to the leader replica and the leader
propose requests in the order received (depending on the order-fairness parameter ùõæ) [136]. Themis requires at least
4ùëì + 1 replicas (if ùõæ = 1) to provide order fairness.
Kauri [186]. Kauri (Figure 11) can be derived from HotStuÔ¨Ä using the loadbalancer function (design choice 14) that
maps the star topology to the tree topology. The height of the tree is ‚Ñé = logùëë ùëõ where ùëë is the fanout of each replica.
CheapBFT [133]. CheapBFT (Figure 15) and its revised version, REBFT [96] is derived from PBFT using the optim-
istic replica reduction function (design choice 5). Using trusted hardware (performance optimization O7), a variation of
REBFT, called RWMINBFT, processes requests with ùëì + 1 active and ùëì passive replicas in its normal case (optimistic)
execution.
FaB [174]. FaB6 (Figure 16) uses the phase reduction function (design choice 2) to reduce one phase of communication
while requiring 5ùëì + 1 replicas. Fab does not use authentication in its ordering stage, however, requires signatures for
the view-change stage (design choice 11). Note that using authentication, 5ùëì ‚àí 1 replicas is suÔ¨Écient to reduce one
phase of communication [11, 147].

Prime [22]. Prime is derived from PBFT using the robust functions (design choice 12). In prime a preordering stage
is added where replicas exchange the requests they receive from clients and periodically share a vector of all received
requests, which they expect the leader to order request following those vectors. In this way, replicas can also monitor
the leader to order requests in a fair manner.

5Tendermint uses a Proof-of-Stake variation of PBFT where each replica has a voting power equal to its stake (i.e., locked coins).
6FaB similar to a family of Paxos-like protocol separates proposers from acceptors. In our implementation of FaB, however,

replicas act as both proposers and acceptors.

13

Figure 15: CheapBFT

Figure 16: FaB

Figure 17: Q/U

Figure 18: Q/U (Normal)

Figure 19: FLB

Figure 20: FTB

Q/U [4]. Q/U (Figure 17) utilizes optimistic conÔ¨Çict-free and resilience functions (design choices 9 and 10). Clients
play the proposer role and replicas immediately execute an update request if the object has not been modiÔ¨Åed since the
client‚Äôs last query. Since Q/U is able to tolerate ùëì faulty replicas, a client can optionally communicate with a subset
(4ùëì + 1) of replicas (preferred quorum). The client communicate with additional replicas only if it does not received
reply from all replicas of the preferred quorum (Figure 18). Both signatures (for large ùëõ) and MACs (for small ùëõ) can
be used for authentication in Q/U. Quorum [35] uses a similar technique with 3ùëì + 1 replicas, i.e., only the conÔ¨Çict-free
function (design choices 9) has been used.

5.2 Deriving Novel BFT Protocols

The previous case studies demonstrate the value of BEDROCK in providing a uniÔ¨Åed platform for analyzing the strengths
and weaknesses of a range of existing BFT protocols. BEDROCK‚Äôs utility goes beyond an experimental platform towards
a discovery tool as well. The system provides a systematic way to explore new valid points in the design space and help
BFT researchers uncover novel BFT protocols. We uncover several such new protocols, although not all are necessarily
practical or interesting. For example, simply making a protocol fair by adding the preordering phase of fairness results
in a new protocol. While this is an interesting insight, the resulting protocol may have limited practical impact. We
select as highlights two new BFT protocols (FLB and FTB) that are new and have practical value that we have uncovered
using BEDROCK.

Fast Linear BFT (FLB). FLB is a fast linear BFT protocol that commits transactions in two phases of communication
with linear message complexity. To achieve this, FLB uses the linearization and phase reduction through redundancy
functions (design choices 1 and 2). FLB requires 5ùëì ‚àí 1 replicas (following the lower bound results on fast Byzantine
agreement [11, 147]). The ordering stage of FLB is similar to the fast path of SBFT in terms of the linearity of
communication and the number of phases. However, FLB expands the network size to tolerate ùëì failures (in contrast
to SBFT, which optimistically assumes all replicas are non-faulty).

Fast Tree-based balanced BFT (FTB). A performance bottleneck of consensus protocols is the computing and band-
width capacity of the leader. While Kauri [186] leverages a tree communication topology (design choice 14) to dis-
tribute the load among all replicas, Kauri requires 7‚Ñé phases of communication to commit each request, where ‚Ñé is the
height of the communication tree. FTB reduces the latency of Kauri based on two observations. First, we noticed that
while Kauri is implemented on top of HotStuÔ¨Ä, it does not use the leader rotation mechanism. As a result, it does not
need the two linear phases of HotStuÔ¨Ä (2‚Ñé phases in Kauri) that are added for the purpose of leader rotation (design
choice 3). Second, similar to FLB, we can use the phase reduction through redundancy function (design choice 2) to
further reduce 2‚Ñé more phases of communication. FTB establishes agreement with 5ùëì ‚àí 1 replicas in 3‚Ñé phases. FTB
also uses the pipelining stretch mechanism of Kauri, where the leader continuously initiates consensus instances before
receiving a response from its child nodes for the Ô¨Årst instance. This is similar to the out-of-order processing mechanism
(performance optimization O 1) used by many BFT protocols.

14

Figure 21: Part of a decision tree constructed by the constraint checker

6

Implementation

BEDROCK enables users, e.g., application developers, to analyze and navigate the BFT landscape by querying their
required BFT protocol characteristics. Using a constraint checker, BEDROCK Ô¨Ånds all plausible points (i.e., BFT pro-
tocols) in the design space that satisfy the input query. Moreover, BEDROCK provides an execution engine that enables
users to implement diÔ¨Äerent BFT protocols.

Constraint checker. The constraint checker uses a decision tree-like algorithm to Ô¨Ånd all plausible points in the design
space where each node of the tree is labeled with a dimension, and outgoing edges represent possible values for that
particular dimension. A user issues a query that indicates, for each dimension, an assigned value (chosen from a preset
of values) that characterizes the requirements of their application. The user can customize some dimensions while
leaving the rest unspeciÔ¨Åed. For example the user might search for a pessimistic BFT protocol with 3f+1 nodes and
linear message complexity. Based on the initial query, the constraint checker begins with the dimensions that the
end-user has speciÔ¨Åed, e.g., processing strategy, the number of replicas, and topology in Figure 21, and then checks
plausible values for unspeciÔ¨Åed dimensions, e.g., since the end-user has chosen the star topology, the constraint checker
chooses signatures for authentication to be able to provide non-repudiation. The leaf nodes of the decision tree specify
the candidate BFT protocols. If some queries do not match any points in the design space (e.g. an impossible protocol
such as a pessimistic linear BFT protocol with 2 communication phases and 3f+1 replicas), the empty set is returned
to the user.

Execution engine. The user receives a list of BFT protocols, e.g., HotStuÔ¨Ä [230] is returned as a pessimistic linear
protocol with 3f+1 nodes. BEDROCK maintains a library including the implementation of common BFT protocols.
When a protocol is chosen by the user, BEDROCK simply returns it if the protocol implementation already exists. Oth-
erwise, the system generates a protocol config Ô¨Åle for the protocol, including all dimensions and the chosen value
for each dimension. The config Ô¨Åle is then used by BEDROCK to implement the stateMachine of the protocol. The
stateMachine includes diÔ¨Äerent states and their transitions for each role (leader, backups, and clients), exchange mes-
sages, quorum conditions, etc. The execution engine takes the stateMachine and a set of related classes that are deÔ¨Åned
outside the stateMachine and handles environmental conditions such as message exchanges, timers, clocks, message
validation, etc. to implement the protocol. Once the protocol implementation is completed, the execution engine initial-
izes replicas and clients (based on the system conÔ¨Åg), deploys the stateMachine on nodes, coordinates key exchange,
etc. At this point, the system is ready to run experiments.

BEDROCK is implemented in Java. The modular design of BEDROCK enables a fair and eÔ¨Écient evaluation of BFT pro-
tocols using identical libraries, cryptographic functions, etc. In particular, we use java.security and javax.crypto
libraries for cryptographic operations, the eo-YAML library to facilitate the storage and retrieval of BFT protocol con-
Ô¨Åguration Ô¨Åles, protocol buÔ¨Äers (com.google.protobuf) to serialize data, and Java streams for parallel processing.

7 Experimental Evaluation

Our evaluation studies the practical impact of the design dimensions and the exposed trade-oÔ¨Äs presented as design
choices on the performance of BFT protocols to reveal the strengths and weaknesses of existing BFT protocols. The
goal is to test the capability of the BEDROCK design space to analyze the performance of diÔ¨Äerent protocols that were
proposed in diverse settings and diÔ¨Äerent contexts under one uniÔ¨Åed framework. We evaluate the performance of BFT
protocols in typical experimental scenarios used for existing BFT protocols and permissioned blockchains, including
(1) varying the number of replicas, (2) under a backup failure, (3) multiple request batch sizes, and (4) a geo-distributed
setup.

All protocols listed in Table 1 are implemented in BEDROCK. Using the platform, we also experimented with many
new protocols resulting from the combination of design choices. Due to space limitations, we present the performance
evaluation of a subset of protocols. In particular, we evaluate PBFT, Zyzzyva, SBFT, FaB, PoE, (Chained) HotStuÔ¨Ä,
Kauri, Themis, and two of the more interesting new variants (FLB and FTB). This set of protocols enables us to see
the impact of design choices 1, 2, 3, 6, 7, 8, 10, 11, 13, and 14 (discussed in Section 4). We also use the out-of-
order processing technique (optimization O1) for protocols with a stable leader and the request pipelining technique

15

250

200

150

100

50

]
c
e
s
/
s
n
a
r
t
k
[

t
u
p
h
g
u
o
r
h
T

4

16

PBFT

64

32
Number of replicas
Zyzzyva

SBFT

]
s

m

[

y
c
n
e
t
a
L

120

90

60

30

0

100

4

16

32
Number of replicas

64

100

PoE

FaB

HotStuÔ¨Ä

Kuari

Themis

FLB

FTB

Figure 22: Performance with diÔ¨Äerent number of replicas

(optimization O2) for protocols with a rotating leader. In our experiments, Kauri and FTB are deployed on trees of
height 2 and the order-fairness parameter ùõæ of Themis is considered to be 1 (i.e., ùëõ = 4ùëì + 1). Kauri does not use the
rotating leader mechanism (although it was developed as an extension of HotStuÔ¨Ä). We use 4 as the base pipelining
stretch for both Kauri and FTB and change it depending on the batch size and deployment setting (local vs. geo-
distributed).

The experiments were conducted on the Amazon EC2 platform. Each VM is a c4.2xlarge instance with 8 vCPUs
and 15GB RAM, Intel Xeon E5-2666 v3 processor clocked at 3.50 GHz. When reporting throughput, we use an
increasing number of client requests until the end-to-end throughput is saturated and state the throughput and latency
just below saturation. The results reÔ¨Çect end-to-end measurements from the clients. Clients execute in a closed loop.
We use micro-benchmarks commonly used to evaluate BFT systems, e.g., BFT-SMART. Each experiment is run for
120 seconds (including 30 s warm-up and cool-down). The reported results are the average of Ô¨Åve runs.

7.1 Fault Tolerance and Scalability

In the Ô¨Årst set of experiments, we evaluate the throughput and latency of the protocols by increasing the number of
replicas ùëõ in a failure-free situation. We vary the number of replicas in an experiment from 4 to 100. For some protocols,
the smallest network size might diÔ¨Äer, e.g., FaB requires 5ùëì + 1 = 6 replicas. We use batching with the batch size of
400 (we discuss this choice in later experiments) and a workload with client request/reply payload sizes of 128‚àï128
byte. Figure 22 reports the results.

Zyzzyva shows the highest throughput among all protocols in small networks due to its optimistic ordering stage that
does not require any communication among replicas (design choice 8). However, as ùëõ increases, its throughput signi-
Ô¨Åcantly reduces as clients need to wait for reply from all replicas. Increasing the number of replicas also has a large
impact on PBFT and FaB (65% and 63% reduction, respectively) due to their quadratic message complexity.
On the other hand, the throughput of Kauri and FTB is less aÔ¨Äected (31% and 32% reduction, respectively) by increasing
ùëõ because of their tree topology (design choice 14) that reduced the bandwidth utilization of each replica. Similarly,
PoE, SBFT and HotStuÔ¨Ä incur less throughput reduction (39%, 55% and 45% respectively) compared to PBFT and
FaB due to their linear message complexity (design choice 1). It should be noted that in BEDROCK, chained HotStuÔ¨Ä
has been implemented using the pipelining technique (optimization O 2). Hence, the average latency of requests has
been reduced. In comparison to HotStuÔ¨Ä, SBFT has slightly lower throughput in large networks (e.g., 8% lower when
ùëõ = 100) because the leader waits for messages from all replicas. SBFT, on the other hand, shows higher throughput
compared to HotStuÔ¨Ä in smaller networks (e.g., 12% higher when ùëõ = 4) due to its fast ordering stage (design choice
6). PoE demonstrates higher throughput compared to both SBFT and HotStuÔ¨Ä, especially in larger networks (e.g., 39%
higher than SBFT and 26% higher than HotStuÔ¨Ä when ùëõ = 100). This is expected because, in PoE, the leader does
not need to wait for messages from all replicas and optimistically combines signatures from 2ùëì + 1 replicas (design
choice 7). Compared to PBFT, while HotStuÔ¨Ä demonstrates better throughput (e.g., 48% higher when ùëõ = 64), the
latency of PBFT is lower (e.g., 32% lower when ùëõ = 64). One reason behind the high latency of HotStuÔ¨Ä is its extra
communication round (design choice 3).
Supporting order-fairness (design choice 13) leads to deÔ¨Åcient performance of Themis compared to HotStuÔ¨Ä (83%
lower throughput when ùëõ = 5). In Themis, replicas need to order transactions and send batches of transactions to the
leader, and the leader needs to generate a fair order. As the number of replicas increases, Themis incurs higher latency

16

250

200

150

100

50

]
c
e
s
/
s
n
a
r
t
k
[

t
u
p
h
g
u
o
r
h
T

]
c
e
s
/
s
n
a
r
t
k
[

t
u
p
h
g
u
o
r
h
T

160

120

80

40

0

]
s

m

[

y
c
n
e
t
a
L

80

60

40

20

1

5

PBFT

10
ùëì value
Zyzzyva

20

0

1

5

SBFT

PoE

FaB

HotStuÔ¨Ä

Kuari

10
ùëì value
Themis

20

FLB

FTB

Figure 23: Performance with diÔ¨Äerent ùëì value

]
s
m

[
y
c
n
e
t
a
L

120

90

60

30

0

4

16

32
Number of replicas

64

100

4

16

32
Number of replicas

64

100

PBFT

Zyzzyva

SBFT

PoE

FaB

HotStuÔ¨Ä

Kuari

Themis

FLB

FTB

Figure 24: Performance with faulty backups

(the latency increases from 9 ms to 137 as the ùëõ increases from 5 to 101). One main source of latency is the time
the leader takes to generate the dependency graph and reach a fair order. It should also be noted that in the BEDROCK
implementation of Themis, ZKP has not been used and the leader sends all transaction orderings received from replicas
to all of them in the prepare phase. This might slightly increase the latency. Using design choice 2 and reducing the
number of communication phases results in 41% higher throughput and 46% lower latency of FTB compared to Kauri
in a setting with 99 replicas (100 for Kauri).
Finally, in FLB, by combining design choices 1 and 2 demonstrates high throughput and low latency for large value of
ùëõ (2.25x throughput and 0.55x latency compared to PBFT). This is expected because Ô¨Årst, FLB reduces both message
complexity and communication phases, and second, in contrast to SBFT and Zyzzyva, replicas in FLB do not need to
wait for responses from all other replicas.

Figure 22 demonstrates the performance of protocols with diÔ¨Äerent numbers of replicas. However, with the same
number of replicas, diÔ¨Äerent protocols tolerate diÔ¨Äerent numbers of failures. For instance, PBFT requires 3ùëì + 1 and
when ùëõ = 100 tolerates 33 failures while FaB requires 5ùëì + 1 and tolerates 19 failures with ùëõ = 100. To compare
protocols based on the maximum number of tolerated failures, we represent the results of the Ô¨Årst experiments in
Figure 23. When protocols tolerate 20 failures, Themis incurs the highest latency. This is because Themis requires 81
(4ùëì + 1) replicas and deals with the high cost of achieving order-fairness.

7.2 Performance with Faulty Backups

In this set of experiments, we force a backup replica to fail and repeat the Ô¨Årst set of experiments. Figure 24 reports
the results. Zyzzyva is mostly aÔ¨Äected by failures (82% lower throughput) as clients need to collect responses from
all replicas. A client waits for Œî = 5ùëöùë† to receive reply from all replicas and then the protocol switches to its normal
path).

17

]
c
e
s
/
s
n
a
r
t
k
[

t
u
p
h
g
u
o
r
h
T

200

150

100

50

0

]
s

m

[

y
c
n
e
t
a
L

48

36

24

12

200

400
batch size

800

200

400
batch size

800

PBFT

Zyzzyva

SBFT

PoE

FaB HotStuÔ¨Ä Kuari

Themis

FLB

FTB

Figure 25: Impact of request batching

We also run this experiment with and without faulty backups on Zyzzyva5 to validate design choice 10, i.e., tolerating
ùëì faulty replicas by increasing the number of replicas. With a single faulty backup, Zyzzyva5 incurs only 8% lower
throughput when ùëõ = 6.
Backup failure reduces the throughput of SBFT by 42%. In the fast path of SBFT, all replicas need to participate, and
even when a single replica is faulty, the protocol falls back to its slow path that requires two more phases. Interestingly,
while the throughput of PoE is reduced by 26% in a small network (4 replicas), its throughput is not signiÔ¨Åcantly aÔ¨Äected
in large networks. This is because the chance of the faulty replica (which participates in the quorum construction but
does not send reply messages to the clients) to be a member of the quorum is much higher in small networks.
Faulty backups also aÔ¨Äect the performance of HotStuÔ¨Ä, especially in small networks. This is expected because HotStuÔ¨Ä
uses the rotating leader mechanism. When ùëõ is small, the faulty replica is the leader of more views during the exper-
iments, resulting in reduced performance. HotStuÔ¨Ä demonstrates its best performance when ùëõ = 31 (still, 36% lower
throughput and 2.7x latency compared to the failure-free scenario). While Themis uses HotStuÔ¨Ä as its ordering stage,
a single faulty backup has less impact on its performance compared to HotStuÔ¨Ä (25% reduction vs. 66% reduction in
throughput). This is because Themis has a larger network size (4ùëì + 1 vs. 3ùëì + 1) that reduces the impact of the faulty
replica. In Kauri and FTB, we force a leaf replica to fail in order to avoid triggering a reconÔ¨Åguration. As a result,
the failure of a backup does not signiÔ¨Åcantly aÔ¨Äect their performance (e.g., 3% lower throughput with 31 replicas in
Kauri). Finally, in small networks, FLB demonstrates the best performance as it incurs only 8% throughput reduction.

7.3

Impact of Request Batching

In the next set of experiments, we measure the impact of request batching on the performance of diÔ¨Äerent protocols
implemented in BEDROCK. We consider three scenarios with batch size of 200, 400 and 800. The network includes 16
replicas (17 replicas for Themis, 14 replicas for FLB and FTB) and all replicas are non-faulty. Figure 25 depicts the
results for three batch sizes of 200, 400 and 800.
Increasing the batch size from 200 to 400 requests improves the performance of all protocols. This is expected because,
with larger batch sizes, more transactions can be committed while the number of communication phases and exchanged
messages is the same and the bandwidth and computing resources are not fully utilized yet. DiÔ¨Äerent protocols behave
diÔ¨Äerently when the batch size increases from 400 to 800. First, Kauri and FTB still process a higher number of trans-
actions (42% and 34% higher throughput). This is because Kauri and FTB balance the load and utilize the bandwidth
of all replicas. Second, SBFT and FaB demonstrate similar performance as before; a trade-oÔ¨Ä between smaller con-
sensus quorums and higher cost of signature veriÔ¨Åcation and bandwidth utilization. Third, the performance of Themis
decreases (24% lower throughput and 3.16x latency) compared to a batch size of 400 due to two main reasons. First,
the higher cost of signature veriÔ¨Åcation and bandwidth utilization, and second, the higher complexity of generating fair
order for a block of 800 transactions (CPU utilization).

7.4

Impact of a Geo-distributed Setup

We measure the performance of diÔ¨Äerent protocols in a wide-area network. Replicas are deployed in 4 diÔ¨Äerent AWS
regions, i.e., Tokyo (TY), Seoul (SU), Virginia (VA), and California (CA) with an average Round-Trip Time (RTT) of

18

120

90

60

30

]
c
e
s
/
s
n
a
r
t
k
[

t
u
p
h
g
u
o
r
h
T

4

16

32
Number of replicas

64

100

]
s
[

y
c
n
e
t
a
L

3

2

1

0

4

16

32
Number of replicas

64

100

PBFT

Zyzzyva

SBFT

PoE

FaB

HotStuÔ¨Ä

Kuari

Themis

FLB

FTB

Figure 26: Performance with a geo-distributed setup

TY ‚áå SU: 33 ms, TY ‚áå VA: 148 ms, TY ‚áå CA: 107 ms, SU ‚áå VA: 175 ms, SU ‚áå CA: 135 ms, and VA ‚áå CA: 62 ms.
The clients are also placed in Oregon (OR) with an average RTT of 97, 126, 68 and 22 ms from TY, SU, VA and CA
respectively. We use a batch size of 400 and perform experiments in a failure-free situation. In this experiment, the
pipelining stretch of Kauri and FTB is increased to 6. Figure 26 depicts the results.
Zyzzyva demonstrates the best performance when ùëõ is small. However, when ùëõ increases, its performance is signi-
Ô¨Åcantly reduced (87% throughput reduction and 115x latency when ùëõ increases from 4 to 100). This is because, in
Zyzzyva, clients need to receive reply messages from all replicas. Similarly, SBFT incurs a signiÔ¨Åcant reduction in its
performance due to its optimistic assumption that all replicas participate in a timely manner. In both protocols, replicas
(client or leader) wait for Œî = 500 ms to receive responses from all replicas before switching to the normal path.
This reduction can be seen in PBFT as well (84% throughput reduction when ùëõ increases to 100) due to its quadratic
communication complexity. PoE incurs a smaller throughput reduction (51%) in comparison to Zyzzyva, SBFT, and
PBFT because it does not need to wait for all replicas and it has a linear communication complexity. Increasing the
number of replicas does not signiÔ¨Åcantly aÔ¨Äect the throughput of FTB compared to other protocols (36% throughput
reduction when ùëõ increases to 99) due to its logarithmic message complexity and pipelining technique.
In HotStuÔ¨Ä, the leader of the following view must wait for the previous view‚Äôs decision before initiating its value.
Even though Chained HotStuÔ¨Ä is implemented in BEDROCK, the leader still needs to wait for one communication round
(an RTT). As a result, in contrast to the single datacenter setting where each round takes ‚àº1 ms, request batches are
proposed on average every ‚àº190 ms. In this setting, a larger batch size possibly improves the performance of HotStuÔ¨Ä.
Similarly, in Themis and FLB, the leader must wait for certiÔ¨Åcates from ùëõ ‚àí ùëì replicas before initiating consensus
on the next request batch. In Themis, network latency also aÔ¨Äects achieving order-fairness as replicas might propose
diÔ¨Äerent orders for client requests. This result demonstrates the signiÔ¨Åcant impact of the out-of-order processing of
requests (optimization O1) on the performance of the protocol, especially in a wide area network.

7.5 Evaluation Summary

We summarize some of the evaluation results as follows. First, optimistic protocols that require all nodes to participate,
e.g., Zyzzyva and SBFT, do not perform well in large networks, especially when nodes are far apart. In small networks
also, a single faulty node signiÔ¨Åcantly reduces the performance of optimistic protocols. Second, the performance
of pessimistic protocols highly depends on the communication topology. While the performance of protocols with
quadratic communication complexity, e.g., PBFT and FaB, is signiÔ¨Åcantly reduced by increasing the network size,
the performance of protocols with linear complexity, e.g., HotStuÔ¨Ä, and especially logarithmic complexity, e.g., Kauri
and FTB, is less aÔ¨Äected. Interestingly in small networks, protocols that use the leader rotation mechanism show poor
performance. This is because the chance of the faulty node becoming the leader is relatively high. Third, increasing the
request batch size enhances the performance of all protocols to the point where the bandwidth and computing resources
are fully utilized. However, the load-balancing techniques, e.g., tree topology, enable a protocol to process larger
batches. Finally, in a wide area network, out-of-order processing of transactions signiÔ¨Åcantly improves performance.
In such a setting, protocols that require a certiÔ¨Åcate of the previous round to start a new round, e.g., HotStuÔ¨Ä, show
poor performance even with pipelining techniques.

19

8 Related Work

SMR regulates the deterministic execution of client requests on multiple replicas, such that every non-faulty replica
executes every request in the same order [149, 205]. Several approaches [150, 191, 205] generalize SMR to support
crash failures. CFT protocols [18, 58, 75, 77, 99, 129, 129, 131, 151, 152, 154, 155, 157, 163, 166, 184, 190, 191, 194, 220]
utilize the design trade-oÔ¨Äs between diÔ¨Äerent design dimensions. For instance, Fast Paxos [152] adds ùëì more replicas
to reduce one phase of communication.

Byzantine fault tolerance refers to nodes that behave arbitrarily after the seminal work by Lamport, et al. [156]. BFT
protocols have been analyzed in several surveys and empirical studies [6, 7, 21, 26, 42, 48, 51, 68, 88, 95, 111, 122, 195,
210, 232]. We discuss some of the more relevant studies.

Berger and Reiser [48] present a survey on BFT protocols used in blockchains where the focus is on the scalability tech-
niques. Similarly, a survey on BFT protocols consisting of classical protocols, e.g., PBFT, blockchain protocols, e.g.,
PoW, and hybrid protocols, e.g., OmniLedger [142], and their applications in permissionless blockchains, is conducted
by Bano et al. [42]. Platania et al. [195] classify BFT protocols into client-side and server-side protocols depending on
the client‚Äôs role. The paper compares these two classes of protocols and analyzes their performance and correctness
attacks. Three families of leader-based, leaderless, and robust BFT protocols with a focus on message and time com-
plexities have been analyzed by Zhang et al. [232]. Finally, Distler [95] analyzes BFT protocols along several main
dimensions: architecture, clients, agreement, execution, checkpoint, and recovery. The paper shares several dimensions
with BEDROCK.

A recent line of work [9‚Äì12] also study good-case latency of BFT protocols. BEDROCK, in contrast to all these survey and
analysis papers, provides a design space, systematically discusses design choices (trade-oÔ¨Äs), and, more importantly,
provides a tool to experimentally analyze BFT protocols.

BFTSim [210] is a simulation environment for BFT protocols that leverages declarative networking system. The paper
also compares a set of representative protocols using the simulator. Abstract [35] presents a framework to design and re-
conÔ¨Ågure BFT protocols where each protocol is developed as a sequence of BFT instances. Abstract presents AZyzzyva,
Aliph, and R-Aliph as three BFT protocols. Each protocol itself is a composition of Abstract instances presented to
handle diÔ¨Äerent situations (e.g., fault-free, under attack). For instance, R-Aliph is a composition of Quorum, Chain,
and Aardvark. In contrast to such studies, BEDROCK attempts to develop a uniÔ¨Åed design space for BFT protocols,
enabling end-users to choose a protocol that best Ô¨Åts their application requirements.

In addition to CFT and BFT protocols, consensus with multiple failure modes has also been studied for both syn-
chronous [138, 176, 211, 218], and partial synchronous [28, 80, 120, 167, 196, 206] models. Finally, leaderless proto-
cols [55, 92, 101, 121, 153, 177, 217] have been proposed to avoid the implications of relying on a leader.

9 Conclusion

We present BEDROCK, a toolkit that uniÔ¨Åes all BFT protocols within a platform for analysis, design, implementation,
and experimentation. In using BEDROCK, we demonstrate how diÔ¨Äerent BFT protocols relate to one another within a
design space and evaluate BFT protocols under a uniÔ¨Åed deployment and experimentation environment in a fair and
eÔ¨Écient manner. By providing a uniÔ¨Åed platform for all the diÔ¨Äerent BFT protocols, BEDROCK is able to highlight
the strengths and weaknesses of diverse properties, e.g., optimistic vs. pessimistic. The tool also provides a basis for
discovering protocols not previously proposed.

While this paper focuses on the platform, the ultimate decision process lies with the end-user for selecting and gener-
ating the BFT protocol. As future work, we plan to explore incorporating automatic selection strategies in BEDROCK
based on deployment environment and application requirements. Machine learning techniques may be useful here in
aiding the user in selecting the appropriate BFT protocol, or evolving one protocol to another at runtime as system para-
meters are updated. Furthermore, we will extend BEDROCK by enabling protocol designers to deÔ¨Åne new dimensions
and values systematically.

References

[1] Chain. http://chain.com.

[2] Corda. https://github.com/corda/corda.

[3] Hyperledger iroha. https://github.com/hyperledger/iroha.

20

[4] M. Abd-El-Malek, G. R. Ganger, G. R. Goodson, M. K. Reiter, and J. J. Wylie. Fault-scalable byzantine fault-

tolerant services. Operating Systems Review (OSR), 39(5):59‚Äì74, 2005.

[5] I. Abraham, S. Devadas, D. Dolev, K. Nayak, and L. Ren. Synchronous byzantine agreement with expected o(1)
rounds, expected ùëú(ùëõ2) communication, and optimal resilience. In Int. Conf. on Financial Cryptography and
Data Security, pages 320‚Äì334. Springer, 2019.

[6] I. Abraham, G. Gueta, D. Malkhi, L. Alvisi, R. Kotla, and J.-P. Martin. Revisiting fast practical byzantine fault

tolerance. arXiv preprint arXiv:1712.01367, 2017.

[7] I. Abraham, D. Malkhi, et al. The blockchain consensus layer and bft. Bulletin of EATCS, 3(123), 2017.
[8] I. Abraham, D. Malkhi, K. Nayak, L. Ren, and A. Spiegelman. Solida: A blockchain protocol based on re-
conÔ¨Ågurable byzantine consensus. In 21st Int. Conf. on Principles of Distributed Systems (OPODIS). Schloss
Dagstuhl-Leibniz-Zentrum fuer Informatik, 2017.

[9] I. Abraham, D. Malkhi, K. Nayak, L. Ren, and M. Yin. Sync hotstuÔ¨Ä: Simple and practical synchronous state
machine replication. In 2020 IEEE Symposium on Security and Privacy (SP), pages 106‚Äì118. IEEE, 2020.
[10] I. Abraham, K. Nayak, L. Ren, and Z. Xiang. Brief announcement: Byzantine agreement, broadcast and state
In Int. Symposium on Distributed Computing (DISC).

machine replication with optimal good-case latency.
Schloss Dagstuhl-Leibniz-Zentrum f√ºr Informatik, 2020.

[11] I. Abraham, K. Nayak, L. Ren, and Z. Xiang. Good-case latency of byzantine broadcast: a complete categoriz-

ation. In Symposium on Principles of distributed computing (PODC), pages 331‚Äì341. ACM, 2021.

[12] I. Abraham, L. Ren, and Z. Xiang. Good-case and bad-case latency of unauthenticated byzantine broadcast: A

complete categorization. arXiv preprint arXiv:2109.12454, 2021.

[13] A. Adya, W. J. Bolosky, M. Castro, G. Cermak, R. Chaiken, J. R. Douceur, J. Howell, J. R. Lorch, M. Theimer,
and R. P. Wattenhofer. {FARSITE}: Federated, available, and reliable storage for an incompletely trusted
environment. In 5th Symposium on Operating Systems Design and Implementation (OSDI 02), 2002.

[14] M. K. Aguilera, N. Ben-David, I. Calciu, R. Guerraoui, E. Petrank, and S. Toueg. Passing messages while
sharing memory. In ACM Symposium on Principles of Distributed Computing (PODC), pages 51‚Äì60, 2018.
[15] M. K. Aguilera, N. Ben-David, R. Guerraoui, V. Marathe, and I. Zablotchi. The impact of rdma on agreement.

In ACM Symposium on Principles of Distributed Computing (PODC), pages 409‚Äì418, 2019.

[16] M. K. Aguilera, N. Ben-David, R. Guerraoui, D. Papuc, A. Xygkis, and I. Zablotchi. Frugal byzantine computing.

In Int. Symposium on Distributed Computing, 2021.

[17] A. Ailijiang, A. Charapko, and M. Demirbas. Dissecting the performance of strongly-consistent replication

protocols. In SIGMOD Int Conf on Management of Data, pages 1696‚Äì1710, 2019.

[18] A. Ailijiang, A. Charapko, M. Demirbas, and T. Kosar. Wpaxos: Wide area network Ô¨Çexible consensus. IEEE

Transactions on Parallel and Distributed Systems, 31(1):211‚Äì223, 2019.

[19] A. S. Aiyer, L. Alvisi, A. Clement, M. Dahlin, J.-P. Martin, and C. Porth. Bar fault tolerance for cooperative

services. In ACM symposium on Operating systems principles (SOSP), pages 45‚Äì58, 2005.

[20] S. Alqahtani and M. Demirbas. Bigbft: A multileader byzantine fault tolerance protocol for high throughput. In

Int Performance Computing and Communications Conf (IPCCC), pages 1‚Äì10. IEEE, 2021.

[21] S. Alqahtani and M. Demirbas. Bottlenecks in blockchain consensus protocols. In Int Conf. on Omni-Layer

Intelligent Systems (COINS), pages 1‚Äì8. IEEE, 2021.

[22] Y. Amir, B. Coan, J. Kirsch, and J. Lane. Prime: Byzantine replication under attack. Transactions on Dependable

and Secure Computing, 8(4):564‚Äì577, 2011.

[23] Y. Amir, C. Danilov, D. Dolev, J. Kirsch, J. Lane, C. Nita-Rotaru, J. Olsen, and D. Zage. Steward: Scaling
byzantine fault-tolerant replication to wide area networks. IEEE Transactions on Dependable and Secure Com-
puting, 7(1):80‚Äì93, 2008.

[24] M. J. Amiri, D. Agrawal, and A. El Abbadi. Caper: a cross-application permissioned blockchain. Proc. of the

VLDB Endowment, 12(11):1385‚Äì1398, 2019.

[25] M. J. Amiri, D. Agrawal, and A. El Abbadi. Parblockchain: Leveraging transaction parallelism in permissioned
blockchain systems. In Int. Conf. on Distributed Computing Systems (ICDCS), pages 1337‚Äì1347. IEEE, 2019.
[26] M. J. Amiri, D. Agrawal, and A. El Abbadi. Modern large-scale data management systems after 40 years of

consensus. In Int. Conf. on Data Engineering (ICDE), page 1. IEEE, 2020.

21

[27] M. J. Amiri, D. Agrawal, and A. El Abbadi. Sharper: Sharding permissioned blockchains over network clusters.

In SIGMOD Int. Conf. on Management of Data, pages 76‚Äì88. ACM, 2021.

[28] M. J. Amiri, S. Maiyya, D. Agrawal, and A. El Abbadi. Seemore: A fault-tolerant protocol for hybrid cloud

environments. In 36th Int. Conf. on Data Engineering (ICDE), pages 1345‚Äì1356. IEEE, 2020.

[29] M. J. Amiri, B. Thau Loo, D. Agrawal, and A. El Abbadi. Qanaat: A scalable multi-enterprise permissioned

blockchain system with conÔ¨Ådentiality guarantees. Proc. of the VLDB Endowment, 15(11):1, 2022.

[30] E. Androulaki, A. Barger, V. Bortnikov, C. Cachin, et al. Hyperledger fabric: a distributed operating system for

permissioned blockchains. In European Conf. on Computer Systems (EuroSys), page 30. ACM, 2018.

[31] B. Arun, S. Peluso, and B. Ravindran. ezbft: Decentralizing byzantine fault-tolerant state machine replication.

In Int Conf on Distributed Computing Systems (ICDCS), pages 565‚Äì577. IEEE, 2019.

[32] B. Arun and B. Ravindran. Scalable byzantine fault tolerance via partial decentralization. Proc. of the VLDB

Endowment, 15(9):1739‚Äì1752, 2022.

[33] A. Asayag, G. Cohen, I. Grayevsky, M. Leshkowitz, O. Rottenstreich, R. Tamari, and D. Yakira. A fair consensus
protocol for transaction ordering. In Int. Conf. on Network Protocols (ICNP), pages 55‚Äì65. IEEE, 2018.
[34] H. Attiya, C. Dwork, N. Lynch, and L. Stockmeyer. Bounds on the time to reach agreement in the presence of

timing uncertainty. Journal of the ACM (JACM), 41(1):122‚Äì152, 1994.

[35] P.-L. Aublin, R. Guerraoui, N. Kne≈æeviƒá, V. Qu√©ma, and M. Vukoliƒá. The next 700 bft protocols. Transactions

on Computer Systems (TOCS), 32(4):12, 2015.

[36] P.-L. Aublin, S. B. Mokhtar, and V. Qu√©ma. Rbft: Redundant byzantine fault tolerance. In Int. Conf. on Dis-

tributed Computing Systems (ICDCS), pages 297‚Äì306. IEEE, 2013.

[37] Z. Avarikioti, L. Heimbach, R. Schmid, L. Vanbever, R. Wattenhofer, and P. Wintermeyer. Fnf-bft: Exploring

performance limits of bft protocols. arXiv preprint arXiv:2009.02235, 2020.

[38] A. Avizienis. The n-version approach to fault-tolerant software. IEEE Transactions on software engineering,

(12):1491‚Äì1501, 1985.

[39] A. Babay, J. Schultz, T. Tantillo, S. Beckley, E. Jordan, K. Ruddell, K. Jordan, and Y. Amir. Deploying intrusion-
tolerant scada for the power grid. In Int. Conf. on Dependable Systems and Networks (DSN), pages 328‚Äì335.
IEEE, 2019.

[40] L. Baird. The swirlds hashgraph consensus algorithm: Fair, fast, byzantine fault tolerance. Swirlds Tech Reports

SWIRLDS-TR-2016-01, Tech. Rep, 2016.

[41] J. Baker, C. Bond, J. C. Corbett, J. Furman, A. Khorlin, J. Larson, J.-M. Leon, Y. Li, A. Lloyd, and V. Yushprakh.
Megastore: Providing scalable, highly available storage for interactive services. In Conf. on Innovative Data
Systems Research (CIDR), 2011.

[42] S. Bano, A. Sonnino, M. Al-Bassam, S. Azouvi, P. McCorry, S. Meiklejohn, and G. Danezis. Sok: Consensus
in the age of blockchains. In ACM Conf. on Advances in Financial Technologies, pages 183‚Äì198, 2019.
[43] M. Baudet, A. Ching, A. Chursin, G. Danezis, F. Garillot, Z. Li, D. Malkhi, O. Naor, D. Perelman, and A. Son-

nino. State machine replication in the libra blockchain. The Libra Assn., Tech. Rep, 2019.

[44] J. Behl, T. Distler, and R. Kapitza. Consensus-oriented parallelization: How to earn your Ô¨Årst million.

In

Proceedings of the 16th Annual Middleware Conference, pages 173‚Äì184, 2015.

[45] J. Behl, T. Distler, and R. Kapitza. Hybrids on steroids: Sgx-based high performance bft. In Proceedings of the

Twelfth European Conference on Computer Systems, pages 222‚Äì237, 2017.

[46] M. Ben-Or. Another advantage of free choice: Completely asynchronous agreement protocols (extended ab-
stract). In Proceedings of the 2nd ACM Annual Symposium on Principles of Distributed Computing, Montreal,
Quebec, pages 27‚Äì30, 1983.

[47] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev. Scalable zero knowledge with no trusted setup. In Annual

international cryptology conference, pages 701‚Äì732. Springer, 2019.

[48] C. Berger and H. P. Reiser. Scaling byzantine consensus: A broad analysis. In Proceedings of the 2nd Workshop

on Scalable and Resilient Infrastructures for Distributed Ledgers, pages 13‚Äì18, 2018.

[49] C. Berger, H. P. Reiser, J. Sousa, and A. Bessani. Resilient wide-area byzantine consensus using adaptive

weighted replication. In Symposium on Reliable Distributed Systems (SRDS), pages 183‚Äì18309. IEEE, 2019.

[50] A. Bessani, M. Correia, B. Quaresma, F. Andr√©, and P. Sousa. Depsky: dependable and secure storage in a

cloud-of-clouds. Transactions on Storage (TOS), 9(4):12, 2013.

22

[51] A. Bessani, J. Sousa, and E. E. Alchieri. State machine replication for the masses with bft-smart.

In 2014
44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, pages 355‚Äì362. IEEE,
2014.

[52] A. N. Bessani, P. Sousa, M. Correia, N. F. Neves, and P. Verissimo. The crutial way of critical infrastructure

protection. IEEE Security & Privacy, 6(6):44‚Äì51, 2008.

[53] M. Biely, Z. Milosevic, N. Santos, and A. Schiper. S-paxos: OÔ¨Ñoading the leader for high throughput state
machine replication. In Symposium on Reliable Distributed Systems (SRDS), pages 111‚Äì120. IEEE, 2012.
[54] K. P. Birman, T. A. Joseph, T. Raeuchle, and A. El Abbadi. Implementing fault-tolerant distributed objects.

Trans. on Software Engineering, (6):502‚Äì508, 1985.

[55] F. Borran and A. Schiper. A leader-free byzantine consensus algorithm. In International Conference on Dis-

tributed Computing and Networking, pages 67‚Äì78. Springer, 2010.

[56] G. Bracha. An asynchronous [(n-1)/3]-resilient consensus protocol. In Symposium on Principles of distributed

computing, pages 154‚Äì162, 1984.

[57] G. Bracha and S. Toueg. Asynchronous consensus and broadcast protocols. Journal of the ACM (JACM),

32(4):824‚Äì840, 1985.

[58] F. Brasileiro, F. Greve, A. Most√©faoui, and M. Raynal. Consensus in one communication step. In Int. Conf. on

Parallel Computing Technologies (PaCT), pages 42‚Äì50. Springer, 2001.

[59] M. Bravo, G. Chockler, and A. Gotsman. Making byzantine consensus live. In 34th International Symposium

on Distributed Computing (DISC 2020). Schloss Dagstuhl-Leibniz-Zentrum f√ºr Informatik, 2020.

[60] N. Bronson, Z. Amsden, G. Cabrera, P. Chakka, P. Dimov, H. Ding, J. Ferris, A. Giardullo, S. Kulkarni, H. Li,
et al. Tao: Facebook‚Äôs distributed data store for the social graph. In Annual Technical Conf. (ATC), pages 49‚Äì60.
USENIX Association, 2013.

[61] R. G. Brown, J. Carlyle, I. Grigg, and M. Hearn. Corda: an introduction. R3 CEV, August, 1(15):14, 2016.
[62] E. Buchman. Tendermint: Byzantine fault tolerance in the age of blockchains. PhD thesis, 2016.
[63] E. Buchman, J. Kwon, and Z. Milosevic. The latest gossip on bft consensus. arXiv preprint arXiv:1807.04938,

2018.

[64] Y. Buchnik and R. Friedman. Fireledger: A high throughput blockchain consensus protocol. Proceedings of the

VLDB Endowment, 13(9).

[65] V. Buterin and V. GriÔ¨Éth. Casper the friendly Ô¨Ånality gadget. arXiv preprint arXiv:1710.09437, 2017.
[66] C. Cachin, K. Kursawe, F. Petzold, and V. Shoup. Secure and eÔ¨Écient asynchronous broadcast protocols. In

Annual Int. Cryptology Conf., pages 524‚Äì541. Springer, 2001.

[67] C. Cachin, K. Kursawe, and V. Shoup. Random oracles in constantinople: Practical asynchronous byzantine

agreement using cryptography. Journal of Cryptology, 18(3):219‚Äì246, 2005.

[68] C. Cachin and M. Vukoliƒá. Blockchain consensus protocols in the wild.

Computing (DISC), pages 1‚Äì16, 2017.

In Int. Symposium on Distributed

[69] M. Castro and B. Liskov. Proactive recovery in a byzantine-fault-tolerant system. In Symposium on Operating

Systems Design and Implementation (OSDI), 2000.

[70] M. Castro and B. Liskov. Practical byzantine fault tolerance and proactive recovery. Transactions on Computer

Systems (TOCS), 20(4):398‚Äì461, 2002.

[71] M. Castro, B. Liskov, et al. Practical byzantine fault tolerance. In Symposium on Operating systems design and

implementation (OSDI), volume 99, pages 173‚Äì186. USENIX Association, 1999.

[72] B. Y. Chan and E. Shi. Streamlet: Textbook streamlined blockchains. In Proceedings of the 2nd ACM Conf. on

Advances in Financial Technologies, pages 1‚Äì11, 2020.

[73] T. H. Chan, R. Pass, and E. Shi. Pala: A simple partially synchronous blockchain. Cryptology ePrint Archive,

2018.

[74] T. H. Chan, R. Pass, and E. Shi. Pili: An extremely simple synchronous blockchain. Cryptology ePrint Archive,

2018.

[75] T. D. Chandra, R. Griesemer, and J. Redstone. Paxos made live: an engineering perspective. In Proceedings of
the twenty-sixth annual ACM symposium on Principles of distributed computing, pages 398‚Äì407, 2007.
[76] T. D. Chandra and S. Toueg. Unreliable failure detectors for reliable distributed systems. Journal of the ACM

(JACM), 43(2):225‚Äì267, 1996.

23

[77] A. Charapko, A. Ailijiang, and M. Demirbas. Pigpaxos: Devouring the communication bottlenecks in distributed

consensus. In SIGMOD Int Conf on Management of Data, pages 235‚Äì247, 2021.

[78] J. M. Chase. Quorum white paper, 2016.

[79] B.-G. Chun, P. Maniatis, S. Shenker, and J. Kubiatowicz. Attested append-only memory: Making adversaries

stick to their word. In Operating Systems Review (OSR), volume 41-6, pages 189‚Äì204. ACM SIGOPS, 2007.

[80] A. Clement, M. Kapritsos, S. Lee, Y. Wang, L. Alvisi, M. Dahlin, and T. Riche. Upright cluster services. In

Symposium on Operating systems principles (SOSP), pages 277‚Äì290. ACM, 2009.

[81] A. Clement, E. L. Wong, L. Alvisi, M. Dahlin, and M. Marchetti. Making byzantine fault tolerant systems
tolerate byzantine faults. In Symposium on Networked Systems Design and Implementation (NSDI), volume 9,
pages 153‚Äì168. USENIX Association, 2009.

[82] J. C. Corbett, J. Dean, M. Epstein, A. Fikes, et al. Spanner: Google‚Äôs globally distributed database. Transactions

on Computer Systems (TOCS), 31(3):8, 2013.

[83] M. Correia, N. F. Neves, L. C. Lung, and P. Ver√≠ssimo. Low complexity byzantine-resilient consensus. Distrib-

uted Computing, 17(3):237‚Äì249, 2005.

[84] M. Correia, N. F. Neves, L. C. Lung, and P. Ver√≠ssimo. Worm-it‚Äìa wormhole-based intrusion-tolerant group

communication system. Journal of Systems and Software, 80(2):178‚Äì197, 2007.

[85] M. Correia, N. F. Neves, and P. Verissimo. How to tolerate half less one byzantine nodes in practical distributed

systems. In Int. Symposium on Reliable Distributed Systems (SRDS), pages 174‚Äì183. IEEE, 2004.

[86] M. Correia, N. F. Neves, and P. Ver√≠ssimo. From consensus to atomic broadcast: Time-free byzantine-resistant

protocols without signatures. The Computer Journal, 49(1):82‚Äì96, 2006.

[87] M. Correia, N. F. Neves, and P. Verissimo. Bft-to: Intrusion tolerance with less replicas. The Computer Journal,

56(6):693‚Äì715, 2013.

[88] M. Correia, G. S. Veronese, N. F. Neves, and P. Verissimo. Byzantine consensus in asynchronous message-
passing systems: a survey. International Journal of Critical Computer-Based Systems, 2(2):141‚Äì161, 2011.
[89] V. Costan, I. Lebedev, and S. Devadas. Sanctum: Minimal hardware extensions for strong software isolation. In

USENIX Security Symposium, pages 857‚Äì874, 2016.

[90] D. Cotroneo, R. Natella, R. Pietrantuono, and S. Russo. A survey of software aging and rejuvenation studies.

ACM Journal on Emerging Technologies in Computing Systems (JETC), 10(1):1‚Äì34, 2014.

[91] J. Cowling, D. Myers, B. Liskov, R. Rodrigues, and L. Shrira. Hq replication: A hybrid quorum protocol for
byzantine fault tolerance. In Symposium on Operating systems design and implementation (OSDI), pages 177‚Äì
190. USENIX Association, 2006.

[92] T. Crain, V. Gramoli, M. Larrea, and M. Raynal. Dbft: EÔ¨Écient leaderless byzantine consensus and its ap-
plication to blockchains. In Int. Symposium on Network Computing and Applications (NCA), pages 1‚Äì8. IEEE,
2018.

[93] T. Crain, C. Natoli, and V. Gramoli. Red belly: a secure, fair and scalable open blockchain. In Symposium on

Security and Privacy (S&P‚Äô21). IEEE, 2021.

[94] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. Pilchin, S. Sivasubramanian,
P. Vosshall, and W. Vogels. Dynamo: amazon‚Äôs highly available key-value store. In Operating Systems Re-
view (OSR), volume 41, pages 205‚Äì220. ACM SIGOPS, 2007.

[95] T. Distler. Byzantine fault-tolerant state-machine replication from a systems perspective. ACM Computing

Surveys (CSUR), 54(1):1‚Äì38, 2021.

[96] T. Distler, C. Cachin, and R. Kapitza. Resource-eÔ¨Écient byzantine fault tolerance. Transactions on Computers,

65(9):2807‚Äì2819, 2016.

[97] T. Distler, I. Popov, W. Schr√∂der-Preikschat, H. P. Reiser, and R. Kapitza. Spare: Replicas on hold. In Network

and Distributed System Security Symposium (NDSS, 2011.

[98] D. Dobre, G. Karame, W. Li, M. Majuntke, N. Suri, and M. Vukoliƒá. Powerstore: Proofs of writing for eÔ¨Écient
In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications

and robust storage.
security, pages 285‚Äì298, 2013.

[99] D. Dobre, M. Majuntke, M. SeraÔ¨Åni, and N. Suri. Hp: Hybrid paxos for wans.

Computing Conf. (EDCC), pages 117‚Äì126. IEEE, 2010.

In European Dependable

24

[100] D. Dolev, C. Dwork, and L. Stockmeyer. On the minimal synchronism needed for distributed consensus. Journal

of the ACM (JACM), 34(1):77‚Äì97, 1987.

[101] S. Duan, M. K. Reiter, and H. Zhang. Beat: Asynchronous bft made practical. In ACM SIGSAC Conference on

Computer and Communications Security (CCS), pages 2028‚Äì2041, 2018.
[102] S. Duan and H. Zhang. Practical state machine replication with conÔ¨Ådentiality.

Distributed Systems (SRDS), pages 187‚Äì196. IEEE, 2016.

In Symposium on Reliable

[103] C. Dwork, N. Lynch, and L. Stockmeyer. Consensus in the presence of partial synchrony. Journal of the ACM

(JACM), 35(2):288‚Äì323, 1988.

[104] M. Eischer and T. Distler. Latency-aware leader selection for geo-replicated byzantine fault-tolerant systems. In

Int. Conf. on Dependable Systems and Networks Workshops (DSN-W), pages 140‚Äì145. IEEE, 2018.

[105] M. Eischer and T. Distler. Scalable byzantine fault-tolerant state-machine replication on heterogeneous servers.

Computing, 101(2):97‚Äì118, 2019.

[106] A. El Abbadi, D. Skeen, and F. Cristian. An eÔ¨Écient, fault-tolerant protocol for replicated data management. In

SIGACT-SIGMOD symposium on Principles of database systems, pages 215‚Äì229. ACM, 1985.

[107] A. El Abbadi and S. Toueg. Availability in partitioned replicated databases. In SIGACT-SIGMOD symposium

on Principles of database systems, pages 240‚Äì251. ACM, 1985.

[108] I. A. Escobar, E. Alchieri, F. L. Dotti, and F. Pedone. Boosting concurrency in parallel state machine replication.

In Int. Middleware Conf., pages 228‚Äì240, 2019.

[109] M. J. Fischer, N. A. Lynch, and M. S. Paterson. Impossibility of distributed consensus with one faulty process.

Journal of the ACM (JACM), 32(2):374‚Äì382, 1985.

[110] S. Forrest, A. Somayaji, and D. H. Ackley. Building diverse computer systems. In Workshop on Hot Topics in

Operating Systems, pages 67‚Äì72. IEEE, 1997.

[111] F. Gai, A. Farahbakhsh, J. Niu, C. Feng, I. Beschastnikh, and H. Duan. Dissecting the performance of chained-

bft. In Int Conf on Distributed Computing Systems (ICDCS), pages 595‚Äì606. IEEE, 2021.

[112] M. Garcia, N. Neves, and A. Bessani. An intrusion-tolerant Ô¨Årewall design for protecting siem systems.

In
2013 43rd Annual IEEE/IFIP Conference on Dependable Systems and Networks Workshop (DSN-W), pages
1‚Äì7. IEEE, 2013.

[113] M. Garcia, N. Neves, and A. Bessani. Sieveq: A layered bft protection system for critical services.

Transactions on Dependable and Secure Computing, 15(3):511‚Äì525, 2016.

IEEE

[114] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich. Algorand: Scaling byzantine agreements for
cryptocurrencies. In Proceedings of the 26th symposium on operating systems principles, pages 51‚Äì68, 2017.
[115] G. R. Goodson, J. J. Wylie, G. R. Ganger, and M. K. Reiter. EÔ¨Écient byzantine-tolerant erasure-coded storage.
In International Conference on Dependable Systems and Networks, 2004, pages 135‚Äì144. IEEE, 2004.
[116] C. GorenÔ¨Ço, L. Golab, and S. Keshav. Xox fabric: A hybrid approach to transaction execution. In Int. Conf. on

Blockchain and Cryptocurrency (ICBC), pages 1‚Äì9. IEEE, 2020.

[117] C. GorenÔ¨Ço, S. Lee, L. Golab, and S. Keshav. Fastfabric: Scaling hyperledger fabric to 20,000 transactions per

second. In Int. Conf. on Blockchain and Cryptocurrency (ICBC), pages 455‚Äì463. IEEE, 2019.
Multichain private blockchain-white paper.

[118] G. Greenspan.

URl:

http://www. multichain.

com/download/MultiChain-White-Paper. pdf, 2015.

[119] R. Guerraoui, N. Kne≈æeviƒá, V. Qu√©ma, and M. Vukoliƒá. The next 700 bft protocols. In Proceedings of the 5th

European conference on Computer systems, pages 363‚Äì376, 2010.

[120] G. G. Gueta, I. Abraham, S. Grossman, D. Malkhi, B. Pinkas, M. K. Reiter, D.-A. Seredinschi, O. Tamir, and
A. Tomescu. Sbft: a scalable decentralized trust infrastructure for blockchains. In Int. Conf. on Dependable
Systems and Networks (DSN), pages 568‚Äì580. IEEE/IFIP, 2019.

[121] B. Guo, Z. Lu, Q. Tang, J. Xu, and Z. Zhang. Dumbo: Faster asynchronous bft protocols. In Proceedings of the

2020 ACM SIGSAC Conference on Computer and Communications Security, pages 803‚Äì818, 2020.

[122] D. Gupta, L. Perronne, and S. Bouchenak. Bft-bench: Towards a practical evaluation of robustness and ef-
fectiveness of bft protocols. In IFIP International Conference on Distributed Applications and Interoperable
Systems, pages 115‚Äì128. Springer, 2016.

[123] S. Gupta, J. Hellings, S. Rahnama, and M. Sadoghi. Proof-of-execution: Reaching consensus through fault-

tolerant speculation. In Int Conf. on Extending Database Technology (EDBT), pages 301‚Äì312, 2021.

25

[124] S. Gupta, J. Hellings, and M. Sadoghi. Rcc: Resilient concurrent consensus for high-throughput secure trans-

action processing. In Int Conf on Data Engineering (ICDE), pages 1392‚Äì1403. IEEE, 2021.

[125] S. Gupta, S. Rahnama, J. Hellings, and M. Sadoghi. Resilientdb: Global scale resilient blockchain fabric.

Proceedings of the VLDB Endowment, 13(6):868‚Äì883, 2020.

[126] A. Haeberlen, P. Kouznetsov, and P. Druschel. The case for byzantine fault detection. In HotDep, 2006.
[127] T. Hanke, M. Movahedi, and D. Williams. DÔ¨Ånity technology overview series, consensus system. arXiv preprint

arXiv:1805.04548, 2018.

[128] J. Hendricks, G. R. Ganger, and M. K. Reiter. Low-overhead byzantine fault-tolerant storage. ACM SIGOPS

Operating Systems Review, 41(6):73‚Äì86, 2007.

[129] H. Howard, D. Malkhi, and A. Spiegelman. Flexible paxos: Quorum intersection revisited. In 20th International

Conference on Principles of Distributed Systems, 2017.

[130] Y. Huang, C. Kintala, N. Kolettis, and N. D. Fulton. Software rejuvenation: Analysis, module and applications.

In Int. symposium on fault-tolerant computing. Digest of papers, pages 381‚Äì390. IEEE, 1995.

[131] F. P. Junqueira, B. C. Reed, and M. SeraÔ¨Åni. Zab: High-performance broadcast for primary-backup systems.
In 2011 IEEE/IFIP 41st International Conference on Dependable Systems & Networks (DSN), pages 245‚Äì256.
IEEE, 2011.

[132] R. Kallman, H. Kimura, J. Natkins, A. Pavlo, A. Rasin, S. Zdonik, E. P. Jones, S. Madden, M. Stonebraker,
Y. Zhang, et al. H-store: a high-performance, distributed main memory transaction processing system. Proc. of
the VLDB Endowment, 1(2):1496‚Äì1499, 2008.

[133] R. Kapitza, J. Behl, C. Cachin, T. Distler, S. Kuhnle, S. V. Mohammadi, W. Schr√∂der-Preikschat, and K. Stengel.
Cheapbft: resource-eÔ¨Écient byzantine fault tolerance. In European Conf. on Computer Systems (EuroSys), pages
295‚Äì308. ACM, 2012.

[134] M. Kapritsos, Y. Wang, V. Quema, A. Clement, L. Alvisi, M. Dahlin, et al. All about eve: Execute-verify
In Symposium on Operating systems design and implementation (OSDI),

replication for multi-core servers.
volume 12, pages 237‚Äì250. USENIX Association, 2012.

[135] M. Kelkar, S. Deb, S. Long, A. Juels, and S. Kannan. Themis: Fast, strong order-fairness in byzantine consensus.

Cryptology ePrint Archive, 2021.

[136] M. Kelkar, F. Zhang, S. Goldfeder, and A. Juels. Order-fairness for byzantine consensus. In Annual Int. Crypto-

logy Conf., pages 451‚Äì480. Springer, 2020.

[137] A. Kiayias, A. Russell, B. David, and R. Oliynykov. Ouroboros: A provably secure proof-of-stake blockchain

protocol. In Annual Int. Cryptology Conf., pages 357‚Äì388. Springer, 2017.

[138] R. M. Kieckhafer and M. H. Azadmanesh. Reaching approximate agreement with mixed-mode faults. Transac-

tions on Parallel and Distributed Systems, 5(1):53‚Äì63, 1994.

[139] J. Kirsch, S. Goose, Y. Amir, D. Wei, and P. Skare. Survivable scada via intrusion-tolerant replication. IEEE

Transactions on Smart Grid, 5(1):60‚Äì70, 2013.

[140] E. K. Kogias, P. Jovanovic, N. Gailly, I. KhoÔ¨É, L. Gasser, and B. Ford. Enhancing bitcoin security and per-
In Security Symposium, pages 279‚Äì296. USENIX

formance with strong consistency via collective signing.
Association, 2016.

[141] E. Kokoris-Kogias. Robust and scalable consensus for sharded distributed ledgers.
[142] E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly, E. Syta, and B. Ford. Omniledger: A secure, scale-out,

decentralized ledger via sharding. In Symposium on Security and Privacy (SP), pages 583‚Äì598. IEEE, 2018.

[143] R. Kotla, L. Alvisi, M. Dahlin, A. Clement, and E. Wong. Zyzzyva: speculative byzantine fault tolerance.

Operating Systems Review (OSR), 41(6):45‚Äì58, 2007.

[144] R. Kotla and M. Dahlin. High throughput byzantine fault tolerance. In International Conference on Dependable

Systems and Networks, pages 575‚Äì584. IEEE, 2004.

[145] K. Kursawe. Wendy, the good little fairness widget: Achieving order fairness for blockchains.

Advances in Financial Technologies, pages 25‚Äì36. ACM, 2020.

In Conf. on

[146] K. Kursawe. Wendy grows up: More order fairness. In Int. Conf. on Financial Cryptography and Data Security

(FC), pages 191‚Äì196. Springer, 2021.

[147] P. Kuznetsov, A. Tonkikh, and Y. X. Zhang. Revisiting optimal resilience of fast byzantine consensus.

In

Symposium on Principles of distributed computing (PODC), pages 343‚Äì353. ACM, 2021.

26

[148] J. Kwon. Tendermint: Consensus without mining. 2014.
[149] L. Lamport. Time, clocks, and the ordering of events in a distributed system. Communications of the ACM,

21(7):558‚Äì565, 1978.

[150] L. Lamport. Paxos made simple. ACM Sigact News, 32(4):18‚Äì25, 2001.
[151] L. Lamport. Generalized consensus and paxos. 2005.
[152] L. Lamport. Fast paxos. Distributed Computing, 19(2):79‚Äì103, 2006.
[153] L. Lamport. Brief announcement: Leaderless byzantine paxos. In Int. Symposium on Distributed Computing

(DISC), pages 141‚Äì142, 2011.

[154] L. Lamport. The part-time parliament. In Concurrency: the Works of Leslie Lamport, pages 277‚Äì317. 2019.
[155] L. Lamport and M. Massa. Cheap paxos. In Int. Conf. on Dependable Systems and Networks (DSN), pages

307‚Äì314. IEEE, 2004.

[156] L. Lamport, R. Shostak, and M. Pease. The byzantine generals problem. Transactions on Programming Lan-

guages and Systems (TOPLAS), 4(3):382‚Äì401, 1982.

[157] B. Lampson. The abcd‚Äôs of paxos. In PODC, volume 1, page 13. Citeseer, 2001.
[158] D. Lee, D. Kohlbrenner, S. Shinde, K. Asanoviƒá, and D. Song. Keystone: An open framework for architecting

trusted execution environments. In European Conference on Computer Systems (EuroSys, pages 1‚Äì16, 2020.

[159] K. Lev-Ari, A. Spiegelman, I. Keidar, and D. Malkhi. Fairledger: A fair blockchain protocol for Ô¨Ånancial
In 23rd Int. Conf. on Principles of Distributed Systems (OPODIS). Schloss Dagstuhl-Leibniz-

institutions.
Zentrum f√ºr Informatik, 2019.

[160] D. Levin, J. R. Douceur, J. R. Lorch, and T. Moscibroda. Trinc: Small trusted hardware for large distributed

systems. In NSDI, volume 9, pages 1‚Äì14, 2009.

[161] B. Li, N. Weichbrodt, J. Behl, P.-L. Aublin, T. Distler, and R. Kapitza. Troxy: Transparent access to byzantine

fault-tolerant systems. In Int. Conf. on Dependable Systems and Networks (DSN), pages 59‚Äì70. IEEE, 2018.

[162] B. Li, W. Xu, M. Z. Abid, T. Distler, and R. Kapitza. Sarek: Optimistic parallel ordering in byzantine fault

tolerance. In European Dependable Computing Conf. (EDCC), pages 77‚Äì88. IEEE, 2016.

[163] H. C. Li, A. Clement, A. S. Aiyer, and L. Alvisi. The paxos register. In 2007 26th IEEE International Symposium

on Reliable Distributed Systems (SRDS 2007), pages 114‚Äì126. IEEE, 2007.

[164] J. Li and D. Mazi√©res. Beyond one-third faulty replicas in byzantine fault tolerant systems. In Symposium on

Networked Systems Design and Implementation (NSDI). USENIX Association, 2007.

[165] W. Li, C. Feng, L. Zhang, H. Xu, B. Cao, and M. A. Imran. A scalable multi-layer pbft consensus for blockchain.

Transactions on Parallel and Distributed Systems, 32(5):1146‚Äì1160, 2020.

[166] B. Liskov and J. Cowling. Viewstamped replication revisited. 2012.
[167] S. Liu, P. Viotti, C. Cachin, V. Qu√©ma, and M. Vukolic. Xft: Practical fault tolerance beyond crashes.

In
Symposium on Operating systems design and implementation (OSDI), pages 485‚Äì500. USENIX Association,
2016.

[168] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. A secure sharding protocol for open
blockchains. In SIGSAC Conf. on Computer and Communications Security (CCS), pages 17‚Äì30. ACM, 2016.
[169] D. Malkhi and M. Reiter. Unreliable intrusion detection in distributed computations. In Computer Security

Foundations Workshop, pages 116‚Äì124. IEEE, 1997.

[170] D. Malkhi and M. Reiter. Byzantine quorum systems. Distributed computing, 11(4):203‚Äì213, 1998.
[171] D. Malkhi and M. K. Reiter. Secure and scalable replication in phalanx.

In Proceedings Seventeenth IEEE

Symposium on Reliable Distributed Systems (Cat. No. 98CB36281), pages 51‚Äì58. IEEE, 1998.

[172] D. Malkhi and M. K. Reiter. Survivable consensus objects. In IEEE Symposium on Reliable Distributed Systems

(SRDS), pages 271‚Äì279. IEEE, 1998.

[173] Y. Mao, F. P. Junqueira, and K. Marzullo. Towards low latency state machine replication for uncivil wide-area

networks. In Workshop on Hot Topics in System Dependability. Citeseer, 2009.

[174] J.-P. Martin and L. Alvisi. Fast byzantine consensus. Transactions on Dependable and Secure Computing,

3(3):202‚Äì215, 2006.

[175] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. ShaÔ¨Å, V. Shanbhogue, and U. R. Savagaonkar.

Innovative instructions and software model for isolated execution. Hasp@ isca, 10(1), 2013.

27

[176] F. J. Meyer and D. K. Pradhan. Consensus with dual failure modes. Transactions on Parallel and Distributed

Systems, (2):214‚Äì222, 1991.

[177] A. Miller, Y. Xia, K. Croman, E. Shi, and D. Song. The honey badger of bft protocols. In ACM SIGSAC Conf.

on Computer and Communications Security (CCS), pages 31‚Äì42, 2016.

[178] Z. Milosevic, M. Biely, and A. Schiper. Bounded delay in byzantine-tolerant state machine replication. In Int.

Symposium on Reliable Distributed Systems (SRDS), pages 61‚Äì70. IEEE, 2013.

[179] I. Moraru, D. G. Andersen, and M. Kaminsky. Egalitarian paxos. In ACM Symposium on Operating Systems

Principles, 2012.

[180] I. Moraru, D. G. Andersen, and M. Kaminsky. There is more consensus in egalitarian parliaments. In ACM

Symposium on Operating Systems Principles (SOSP), pages 358‚Äì372, 2013.

[181] L. E. Moser, P. M. Melliar-Smith, P. Narasimhan, L. A. Tewksbury, and V. Kalogeraki. The eternal system: An
architecture for enterprise applications. In Int. Enterprise Distributed Object Computing Conf. (EDOC), pages
214‚Äì222. IEEE, 1999.

[182] O. Naor, M. Baudet, D. Malkhi, and A. Spiegelman. Cogsworth: Byzantine view synchronization. arXiv preprint

arXiv:1909.05204, 2019.

[183] O. Naor and I. Keidar. Expected linear round synchronization: The missing link for linear byzantine smr. In

Int.l Symposium on Distributed Computing (DISC). Schloss Dagstuhl-Leibniz-Zentrum f√ºr Informatik, 2020.

[184] F. Nawab, D. Agrawal, and A. El Abbadi. Dpaxos: Managing data closer to users for low-latency and mobile
applications. In Proceedings of the 2018 International Conference on Management of Data, pages 1221‚Äì1236.
ACM, 2018.

[185] F. Nawab and M. Sadoghi. Blockplane: A global-scale byzantizing middleware. In 2019 IEEE 35th Int. Conf.

on Data Engineering (ICDE), pages 124‚Äì135. IEEE, 2019.

[186] R. Neiheiser, M. Matos, and L. Rodrigues. Kauri: Scalable bft consensus with pipelined tree-based dissem-
ination and aggregation. In ACM SIGOPS Symposium on Operating Systems Principles (SOSP), pages 35‚Äì48,
2021.

[187] R. Neiheiser, D. Presser, L. Rech, M. Bravo, L. Rodrigues, and M. Correia. Fireplug: Flexible and robust n-
version geo-replication of graph databases. In Int Conf on Information Networking (ICOIN), pages 110‚Äì115.
IEEE, 2018.

[188] N. F. Neves, M. Correia, and P. Verissimo. Solving vector consensus with a wormhole. IEEE Transactions on

Parallel and Distributed Systems, 16(12):1120‚Äì1131, 2005.

[189] A. Nogueira, M. Garcia, A. Bessani, and N. Neves. On the challenges of building a bft scada. In Int. Conf. on

Dependable Systems and Networks (DSN), pages 163‚Äì170. IEEE, 2018.

[190] B. M. Oki and B. H. Liskov. Viewstamped replication: A new primary copy method to support highly-available
distributed systems. In Symposium on Principles of distributed computing (PODC), pages 8‚Äì17. ACM, 1988.
[191] D. Ongaro and J. K. Ousterhout. In search of an understandable consensus algorithm. In Annual Technical Conf.

(ATC), pages 305‚Äì319. USENIX Association, 2014.

[192] R. Pass and E. Shi. Hybrid consensus: EÔ¨Écient consensus in the permissionless model. In 31 Int. Symposium

on Distributed Computing, page 6, 2017.

[193] R. Pass and E. Shi. Thunderella: Blockchains with optimistic instant conÔ¨Årmation. In Annual Int. Conf. on the

Theory and Applications of Cryptographic Techniques, pages 3‚Äì33. Springer, 2018.

[194] F. Pedone. Boosting system performance with optimistic distributed protocols. Computer, 34(12):80‚Äì86, 2001.
[195] M. Platania, D. Obenshain, T. Tantillo, Y. Amir, and N. Suri. On choosing server-or client-side solutions for bft.

ACM Computing Surveys (CSUR), 48(4):1‚Äì30, 2016.

[196] D. Porto, J. Leit√£o, C. Li, A. Clement, A. Kate, F. Junqueira, and R. Rodrigues. Visigoth fault tolerance. In

European Conf. on Computer Systems (EuroSys), page 8. ACM, 2015.

[197] J. Qi, X. Chen, Y. Jiang, J. Jiang, T. Shen, S. Zhao, S. Wang, G. Zhang, L. Chen, M. H. Au, et al. Bidl: A
high-throughput, low-latency permissioned blockchain framework for datacenter networks. In Symposium on
Operating Systems Principles (SOSP), pages 18‚Äì34. ACM SIGOPS, 2021.

[198] M. O. Rabin. Randomized byzantine generals. In Symposium on Foundations of Computer Science (SFCS),

pages 403‚Äì409. IEEE, 1983.

28

[199] H. V. Ramasamy and C. Cachin. Parsimonious asynchronous byzantine-fault-tolerant atomic broadcast.

In

International Conference On Principles Of Distributed Systems, pages 88‚Äì102. Springer, 2005.

[200] H. P. Reiser and R. Kapitza. Hypervisor-based eÔ¨Écient proactive recovery.

Distributed Systems (SRDS), pages 83‚Äì92. IEEE, 2007.

In Int. Symposium on Reliable

[201] R. v. Renesse, C. Ho, and N. Schiper. Byzantine chain replication. In International Conference On Principles

Of Distributed Systems, pages 345‚Äì359. Springer, 2012.

[202] R. L. Rivest, A. Shamir, and L. M. Adleman. A method for obtaining digital signatures and public key cryptosys-

tems. Routledge, 2019.

[203] T. Roeder and F. B. Schneider. Proactive obfuscation. ACM Transactions on Computer Systems (TOCS), 28(2):1‚Äì

54, 2010.

[204] P. Ruan, D. Loghin, Q.-T. Ta, M. Zhang, G. Chen, and B. C. Ooi. A transactional perspective on execute-order-

validate blockchains. In SIGMOD Int. Conf. on Management of Data, pages 543‚Äì557. ACM, 2020.

[205] F. B. Schneider. Implementing fault-tolerant services using the state machine approach: A tutorial. Computing

Surveys (CSUR), 22(4):299‚Äì319, 1990.

[206] M. SeraÔ¨Åni, P. Bokor, D. Dobre, M. Majuntke, and N. Suri. Scrooge: Reducing the costs of fast byzantine
replication in presence of unresponsive replicas. In Int. Conf. on Dependable Systems and Networks (DSN),
pages 353‚Äì362. IEEE, 2010.

[207] A. Sharma, F. M. Schuhknecht, D. Agrawal, and J. Dittrich. Blurring the lines between blockchains and database
systems: the case of hyperledger fabric. In SIGMOD Int. Conf. on Management of Data, pages 105‚Äì122. ACM,
2019.

[208] V. Shoup. Practical threshold signatures. In International Conference on the Theory and Applications of Cryp-

tographic Techniques, pages 207‚Äì220. Springer, 2000.

[209] N. Shrestha, I. Abraham, L. Ren, and K. Nayak. On the optimality of optimistic responsiveness. In ACM SIGSAC

Conf. on Computer and Communications Security (CCS), pages 839‚Äì857, 2020.

[210] A. Singh, T. Das, P. Maniatis, P. Druschel, and T. Roscoe. Bft protocols under Ô¨Åre. In NSDI, volume 8, pages

189‚Äì204, 2008.

[211] H.-S. Siu, Y.-H. Chin, and W.-P. Yang. A note on consensus on dual failure modes. Transactions on Parallel

and Distributed Systems, 7(3):225‚Äì230, 1996.

[212] Y. J. Song and R. van Renesse. Bosco: One-step byzantine asynchronous consensus. In Int. Symposium on

Distributed Computing (DISC), pages 438‚Äì450. Springer, 2008.

[213] J. Sousa and A. Bessani. Separating the wheat from the chaÔ¨Ä: An empirical design for geo-replicated state

machines. In Symposium on Reliable Distributed Systems (SRDS), pages 146‚Äì155. IEEE, 2015.

[214] P. Sousa, A. N. Bessani, M. Correia, N. F. Neves, and P. Verissimo. Highly available intrusion-tolerant services
with proactive-reactive recovery. IEEE Transactions on Parallel and Distributed Systems, 21(4):452‚Äì465, 2009.
[215] C. Stathakopoulou, T. David, and M. Vukolic. Mir-bft: High-throughput bft for blockchains. arXiv preprint

arXiv:1906.05552, 2019.

[216] C. Stathakopoulou, S. R√ºsch, M. Brandenburger, and M. Vukoliƒá. Adding fairness to order: Preventing front-
running attacks in bft protocols using tees. In Int Symp on Reliable Distributed Systems (SRDS), pages 34‚Äì45.
IEEE, 2021.

[217] F. Suri-Payer, M. Burke, Z. Wang, Y. Zhang, L. Alvisi, and N. Crooks. Basil: Breaking up bft with acid
(transactions). In ACM SIGOPS Symposium on Operating Systems Principles (SOSP), pages 1‚Äì17, 2021.
[218] P. Thambidurai, Y.-K. Park, et al. Interactive consistency with multiple failure modes. In Symposium on Reliable

Distributed Systems (SRDS), pages 93‚Äì100. IEEE, 1988.

[219] G. Tsudik. Message authentication with one-way hash functions. ACM SIGCOMM Computer Communication

Review, 22(5):29‚Äì38, 1992.

[220] R. Van Renesse, N. Schiper, and F. B. Schneider. Vive la diÔ¨Ä√©rence: Paxos vs. viewstamped replication vs. zab.

IEEE Transactions on Dependable and Secure Computing, 12(4):472‚Äì484, 2014.

[221] P. E. Ver√≠ssimo. Travelling through wormholes: a new look at distributed systems models. ACM SIGACT News,

37(1):66‚Äì81, 2006.

[222] G. S. Veronese, M. Correia, A. N. Bessani, and L. C. Lung. Spin one‚Äôs wheels? byzantine fault tolerance with

a spinning primary. In Int. Symposium on Reliable Distributed Systems (SRDS), pages 135‚Äì144. IEEE, 2009.

29

[223] G. S. Veronese, M. Correia, A. N. Bessani, and L. C. Lung. Ebawa: EÔ¨Écient byzantine agreement for wide-area
networks. In Int. Symposium on High Assurance Systems Engineering (HASE), pages 10‚Äì19. IEEE, 2010.
[224] G. S. Veronese, M. Correia, A. N. Bessani, L. C. Lung, and P. Verissimo. EÔ¨Écient byzantine fault-tolerance.

Transactions on Computers, 62(1):16‚Äì30, 2013.

[225] G. Voron and V. Gramoli. Dispel: Byzantine smr with distributed pipelining. arXiv preprint arXiv:1912.10367,

2019.

[226] M. Whittaker, A. Ailijiang, A. Charapko, M. Demirbas, N. Giridharan, J. M. Hellerstein, H. Howard, I. Stoica,
and A. Szekeres. Scaling replicated state machines with compartmentalization. Proceedings of the VLDB
Endowment, 14(11):2203‚Äì2215, 2021.

[227] T. Wood, R. Singh, A. Venkataramani, P. Shenoy, and E. Cecchet. Zz and the art of practical bft execution. In

Conf. on Computer systems, pages 123‚Äì138. ACM, 2011.

[228] D. Yakira, A. Asayag, G. Cohen, I. Grayevsky, M. Leshkowitz, O. Rottenstreich, and R. Tamari. Helix: A fair
blockchain consensus protocol resistant to ordering manipulation. IEEE Transactions on Network and Service
Management, 18(2):1584‚Äì1597, 2021.

[229] J. Yin, J.-P. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin. Separating agreement from execution for

byzantine fault tolerant services. Operating Systems Review (OSR), 37(5):253‚Äì267, 2003.

[230] M. Yin, D. Malkhi, M. K. Reiter, G. G. Gueta, and I. Abraham. HotstuÔ¨Ä: Bft consensus with linearity and
responsiveness. In Symposium on Principles of Distributed Computing (PODC), pages 347‚Äì356. ACM, 2019.
[231] M. Zamani, M. Movahedi, and M. Raykova. Rapidchain: Scaling blockchain via full sharding. In SIGSAC Conf.

on Computer and Communications Security, pages 931‚Äì948. ACM, 2018.

[232] G. Zhang, F. Pan, M. Dang‚Äôana, Y. Mao, S. Motepalli, S. Zhang, and H.-A. Jacobsen. Reaching consensus in
the byzantine empire: A comprehensive review of bft consensus algorithms. arXiv preprint arXiv:2204.03181,
2022.

[233] Y. Zhang, S. Setty, Q. Chen, L. Zhou, and L. Alvisi. Byzantine ordered consensus without byzantine oligarchy.
In USENIX Symposium on Operating Systems Design and Implementation (OSDI), pages 633‚Äì649, 2020.
[234] L. Zhou, F. Schneider, R. VanRenesse, and Z. Haas. Secure distributed on-line certiÔ¨Åcation authority, Aug. 22

2002. US Patent App. 10/001,588.

[235] L. Zhou, F. B. Schneider, and R. Van Renesse. Coca: A secure distributed online certiÔ¨Åcation authority. ACM

Transactions on Computer Systems (TOCS), 20(4):329‚Äì368, 2002.

30

