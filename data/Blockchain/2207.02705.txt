Incentivizing Proof-of-Stake Blockchain for
Secured Data Collection in UAV-Assisted IoT:
A Multi-Agent Reinforcement Learning Approach

Xiao Tang, Xunqiang Lan, Lixin Li, Yan Zhang, and Zhu Han

1

2
2
0
2

l
u
J

6

]
I

N
.
s
c
[

1
v
5
0
7
2
0
.
7
0
2
2
:
v
i
X
r
a

Abstract—The Internet of Things (IoT) can be conveniently
deployed while empowering various applications, where the IoT
nodes can form clusters to ﬁnish certain missions collectively.
In this paper, we propose to employ unmanned aerial vehicles
(UAVs) to assist the clustered IoT data collection with blockchain-
based security provisioning. In particular, the UAVs generate
candidate blocks based on the collected data, which are then au-
dited through a lightweight proof-of-stake consensus mechanism
within the UAV-based blockchain network. To motivate efﬁcient
blockchain while reducing the operational cost, a stake pool is
constructed at the active UAV while encouraging stake investment
from other UAVs with proﬁt sharing. The problem is formulated
to maximize the overall proﬁt through the blockchain system in
unit time by jointly investigating the IoT transmission, incentives
through investment and proﬁt sharing, and UAV deployment
strategies. Then, the problem is solved in a distributed manner
while being decoupled into two layers. The inner layer incorpo-
rates IoT transmission and incentive design, which are tackled
with large-system approximation and one-leader-multi-follower
Stackelberg game analysis, respectively. The outer layer for UAV
deployment is undertaken with a multi-agent deep deterministic
policy gradient approach. Results show the convergence of the
proposed learning process and the UAV deployment, and also
demonstrated is the performance superiority of our proposal as
compared with the baselines.

Index Terms—Internet of Things, unmanned aerial vehicle,
proof-of-stake blockchain, Stackelberg game, multi-agent deep
deterministic policy gradient

I. INTRODUCTION

I NTERNET of Things (IoT) is the enabling technology for

ubiquitous sensing, computation, and communication to-
wards future wireless networks [1]. IoT devices usually feature
low-cost, low-power operations with massive and convenient
deployment, thus empowering different applications ranging
from agriculture, industry, city management, and beyond [2].
Towards this vision, the data generated by the massive IoT
nodes provides the fundamental ingredients, and thus efﬁcient
and secure data collection and processing are of signiﬁcant
importance. However, as IoT devices can be deployed in a
wide area, the data collection can be quite challenging, and

X. Tang, X. Lan and L. Li are with the School of Electronics
and Information, Northwestern Polytechnical University, Xi’an 710072,
China. (email: tangxiao@nwpu.edu.cn, lanxunqiang@mail.nwpu.edu.cn, lil-
ixin@nwpu.edu.cn)

Y. Zhang is with the Department of Informatics, University of Oslo, 0316

Oslo, Norway. (email: yanzhang@ieee.org)

Z. Han is with the Department of Electrical and Computer Engineering
at the University of Houston, Houston, TX 77004 USA, and also with the
Department of Computer Science and Engineering, Kyung Hee University,
Seoul 446-701, South Korea. (email: hanzhu22@gmail.com)

the data processing is usually beyond the local computation
capability of IoT devices [3]. Further, the direct data feedback
to the core network is difﬁcult due to the limited resources of
IoT devices, and data transmissions can be endangered due to
various security threats [4].

With the rapid development of unmanned aerial vehicle
(UAV) technology in recent years, UAVs have been playing
an increasingly important role in wireless communications to
extend network coverage to three-dimensional space and larger
areas [5]. Attracted by the wide and ﬂexible applications of
UAVs, we can dispatch UAVs to reach the vicinity of IoT
devices and establish communications therein without con-
ventional network infrastructures, enabling UAV-assisted IoT.
With the help of UAVs, an IoT network can be conveniently
extended to remote areas with diverse applications. The high
mobility of UAVs with ﬂexible deployment and ﬂying provides
a new dimension for network optimization to enhance the
performance [6]. In this regard, with UAV-assisted IoT, not
only the capital and operational expenditures can be saved, but
also the efﬁciency and performance of various IoT applications
can be improved.

Despite the facilitation by UAVs in IoT operations, addi-
tional strategies are required to address the security issues,
since there are various attacks that the defense may be beyond
the capability-limited IoT devices. Moreover, the distributed
nature of IoT hinders conventional centralized security man-
agement relying on network infrastructure [7]. Towards this
issue, blockchain technology has emerged as a radical solution
that provides a transparent, cryptographic, and immutable
data structure [8]. Blockchain has dispersed its application
and momentum in various areas and brought paradigm shifts
therein [9]. Meanwhile, Due to the decentralized nature of
blockchain, applications of blockchain in the context of IoT
have been recognized as an effective solution for security en-
hancement, identity protection, privacy, and trust management.
Supported by blockchain technology, various IoT data can
be immutably recorded and encapsulated into blocks to be
shared and synchronized among all participants in a distributed
manner [10].

Fascinated by the advantages of blockchain technology,
is expected to provide an effective solution to the se-
it
curity provisioning in UAV-assisted IoT. However, the con-
ventional blockchain with proof-of-work (PoW) consensus
is computation-intensive and storage-demanding, whose re-
quirements may be beyond the resource-limited IoT devices
In this respect, an external
and dynamic IoT scenarios.

 
 
 
 
 
 
computing server is usually leveraged to assist blockchain
operations. Alternatively, we can resort to the proof-of-stake
(PoS) blockchain that features mild cost, sufﬁcient scalability,
and short delay in the IoT context. For UAV-assisted IoT
data collection, a PoS blockchain can be established at the
aerial collectors, allowing decentralized tamper-proof security
provisioning while effectively avoiding the single-point fail-
ure under conventional centralized approaches. Further, the
ﬂexible mobility of UAVs can be exploited as an additional
dimension for optimization with joint consideration upon IoT
transmissions, in order to reduce the latency in different stages
of blockchain operations. However, an extensive literature re-
view indicates that the existing studies on blockchain-secured
IoT more often leverage external resources for PoW or migrate
PoS directly, while lacking consideration and exploitation of
the network dynamics. Therefore, there is an urgent need
for a lightweight and efﬁcient blockchain solution specially
designed for UAV-IoT scenarios for secured data collection.

Towards the aforementioned issues, we propose a UAV-
assisted IoT data collection scheme that is secured through PoS
blockchain with incentive design. In particular, we consider a
clustered IoT with a UAV collecting data for each cluster. The
UAVs constitute a blockchain network with block generation
from collected data and block audition with the PoS consen-
sus mechanism. In particular, the main contributions can be
summarized as follows:

• For

the proposed PoS blockchain-secured UAV-IoT
data collection, we consider the obtained proﬁt in the
blockchain system through block generation and stake
investment, as well as the time consumed for all stages
in blockchain operations, and formulate the problem to
maximize the system utility as the achieved proﬁt in unit
time.

• For each UAV-IoT cluster pair,

the IoT transmission
strategy is designed based on large-system analysis. Then,
to facilitate the PoS consensus with reduced operational
cost, we propose to construct a stake pool at the active
UAV, allowing stake investment and proﬁt-sharing with
other UAVs. The incentive process is formulated within
a one-leader-multi-follower Stackelberg game framework
with equilibrium analysis.

• At the networked scale, the distributed UAV deployment
is investigated as a multi-agent Markov game, where the
instantaneous reward is determined based on the obtained
utility from the blockchain system, and the deployment
is solved through a multi-agent deep deterministic policy
gradient (MADDPG) approach.

The rest of this paper is organized as follows. In Sec. II,
we review the related works. In Sec. III, we introduce the
system model of blockchain-secured IoT data collection with
UAVs. In Sec. IV, the problem is formulated to optimize the
system utility in terms of the obtained proﬁt in unit time. In
Sec. V, the inner problem is solved for the IoT transmission
strategy and incentive design. In Sec. VI, the outer problem
for UAV deployment is solved with the MADDPG approach.
Sec. VII provides the simulation results to demonstrate the
performance, and ﬁnally Sec. VIII concludes this paper.

2

II. RELATED WORKS

UAV-facilitated data collection naturally appears as a ﬂex-
ible and effective solution for IoT applications and thus has
attracted research interests in various topics [6]. In [11], the au-
thors investigate the UAV trajectory and resource management
for time-sensitive IoT data collection while maximizing the
number of served IoT devices. In [12], the authors optimize the
three-dimensional deployment of multiple UAVs with network
interference management
to minimize the uplink transmit
power of IoT devices. In [13], the authors jointly consider
the UAV trajectory, IoT transmission, and scheduling towards
energy-efﬁcient data collection. Meanwhile, security guaran-
teeing rises as a fundamental issue in UAV-IoT scenarios, and
also has been investigated in different aspects ranging from
physical-layer secrecy to upper-layer cryptography. In [14],
the authors propose to safeguard the UAV-IoT communica-
tions in the physical layer, where the secrecy performance is
investigated in the presence of randomly located eavesdroppers
with stochastic geometry-based analysis. In [15], the authors
propose an access control strategy for UAV-assisted IoT for
environment surveillance. In [16], the authors propose a trust
evaluation model for IoT data collection, where the UAV-
collected data is cleaned to avoid malicious mobile collectors.
In [17], the authors consider the UAV-assisted federated learn-
ing with the incentive-compatible contract design to protect the
privacy of IoT devices. The work above suggests that UAVs
can be exploited as ﬂexible yet powerful roles to improve the
performance of IoT in various aspects, laying the foundation
for our proposed UAV-facilitated IoT security in this work.

Since the decentralized operation of blockchain naturally
ﬁts the IoT scenarios, there have emerged many recent works
that apply blockchain in various aspects in the context of IoT.
In [18], the authors employ a blockchain-enabled distributed
data storage scheme for IoT, where the mining process is
exploited for transaction veriﬁcation as an alternative for the
conventional centralized server. In [19], the authors propose
an untrusted mobile edge computing PoW scheme for a
blockchained IoT system, with fair computing resource alloca-
tion among the IoT nodes. In [20], the authors propose a game-
based pricing solution between the computation-sensitive node
and the cloud server to reach the consensus. However, for
the aforementioned works with the public blockchain archi-
tecture, they may not be readily extended to UAV-assisted IoT
due to the resource-demanding PoW consensus mechanism.
In contrast, lightweight solutions requiring relatively lower
computing capability and smaller storage are propounded to
ﬁt the resource-constrained IoT systems [21]. In [22], the
authors propose a soft security scheme for PoS Internet of
vehicles based on reputation and contract design. In [23], the
authors propose a trading model that allows UAVs to conduct
blockchain operations for IoT data in exchange for coins to get
recharged. In [24], the authors propose a UAV virtualization
scheme with a partially decentralized blockchain model to
secure industry IoT on a pay-per-use basis. In [25], the authors
employ contract theory to balance the stakes and efforts in
blockchain IoT towards the maximum proﬁt while tackling the
practical scenarios with hidden information and hidden action.

3

III. SYSTEM MODEL

We consider a IoT network located within an area denoted
by Λ. The IoT devices form clusters for certain missions,
where the single-point IoT device can be regarded as a special
case for the clustered operations. Here, the IoT clusters may
belong to different owners and thus work independently. Con-
sider that there are J clusters, denoted as J = {1, 2, · · · , J},
and for notation simplicity, we use J−j to denote all elements
in J other than j, i.e., J \{j}. For the j-th cluster, there are
Ij IoT nodes, denoted as Ij = {1, 2, · · · , Ij}. For the i-th
node in the j-th cluster with i ∈ Ij and j ∈ J , it coordinates
(cid:105)
within Λ are denoted by wji =
. To facilitate
the IoT operations, one rotary-wing UAV is deployed for each
cluster to collect the data, where the UAV also works as a
delegate for further data processing in the blockchain system.
The UAVs are assumed to hover at a ﬁxed altitude of H and
the one for the j-th cluster is of a horizontal coordinates of
vj =
. The system model is illustrated as Fig. 1.

ji , w(y)
w(x)

(cid:104)

(cid:105)

(cid:104)

ji

v(x)
j

, v(y)
j

A. IoT Transmission Model

For the considered system, the IoT nodes use single-antenna
due to their limited size and capability. Meanwhile, the UAV
has K antennas to enhance the receptions. In this respect, the
uplink transmissions from the j-th cluster to the serving UAV
form an Ij × K dimensional virtual multiple-input-multiple-
output (MIMO), for which the transmission model is given
as

yj = Hjxj + zj,

(1)

where xj, yj, and zj are the Ij-dimensional
transmitted
signal, K-dimensional received signal, and background noise,
respectively, and Hj ∈ CK×Ij is the virtual MIMO channel.
Based on the large-system analysis technique [36], the channel
can be further decomposed as

Hj = SjLj,

(2)

Fig. 1. System model.

In [26], the authors apply the consortium blockchain with
delegated PoS consensus to achieve traceable and anonymous
the authors propose a drone-based
vehicular IoT. In [27],
delegated PoS for IoT to enhance decentralized security with
reduced latency. These studies intend for specially designed
blockchain systems to ﬁt the lightweight IoT network, the
effort is mostly devoted to the consensus mechanism. While
in UAV-assisted IoT, the UAV-facilitated dynamics can be
actively exploited to improve the performance of blockchain,
which is seldom addressed and thus deserves further investi-
gation.

Meanwhile, the rapid development of artiﬁcial intelligence
has advocated the learning-based solution in the wireless
area [28]. In [29], the authors combine deep reinforcement
learning and blockchain techniques for IoT data collection,
where the former is for the highest throughput while the latter
is for security. In [30], the authors propose to exploit deep
reinforcement learning to fog network optimization to support
IoT. In [31], the authors propose to exploit blockchain in the
deep learning operations in the IoT system to safeguard the
learning procedure. In [32], the authors propose a privacy-
preserving framework for the cooperative Internet of vehicles
with blockchain-secured data and deep learning-based pre-
diction. In [33], the authors design a deep Q-network-based
sharded blockchain for massive IoT services, where the shards
improve the system scalability and the deep network ﬁnds the
optimal throughput conﬁguration. In [34], the authors propose
to employ federated learning to protect the IoT data privacy
while the learning process is integrated into the consensus
process of permissioned blockchain. In [35], the authors ad-
dress the priced resource sharing in IoT with blockchain tasks
and UAV-based edge computing, and the formulated stochastic
game is tackled by hierarchical deep learning techniques. The
work above demonstrates the effectiveness of learning tech-
niques in wireless applications, inspiring us to jointly exploit
the conventional optimization as well as learning approaches
to reach an efﬁcient solution in the UAV-IoT context.

IoT data collection Inactive clusterPoS blockchainUAV-j(Leader)UAV-k(Followers)…StakeStake pool-jIoT data transmissionVerifierVerifier…VerifierVerifier……MinerStake investmentto the poolMiner selectionMiner generates a new block containing IoT dataThe new block is propagated  for verificationBlock confirmation for chaining or discard the blockActive clusterIoT nodesConsensus processData collectionBlockchainCandidate block...Block nBlock n-1Block n-2Block n…Block n-1Transactions(IoT data)Block headTransactions(IoT data)Block headBlock n…Block n-1Transactions(IoT data)Block headTransactions(IoT data)Block headUAVwhere Lj is the large-scale component and Sj corresponds to
the small-scale fading. Speciﬁcally, Lj is an Ij-dimensional

diagonal matrix given as diag

ji =
d−2
ji 10−δji/10, where dji is the distance between the IoT node
and UAV as

i∈Ij

with (cid:96)1/2

(cid:18)(cid:104)

(cid:105)

(cid:96)1/2
ji

(cid:19)

(cid:113)

dji =

(cid:107)wji − vj(cid:107)2 + H 2,

(3)

and

δji = 20 log10

(cid:18) 4πf
c

(cid:19)

+

ηLoS − ηNLoS
1 + a exp (−b(φji − a))

+ ηNLoS

(4)
is the combined effect of line-of-sight (LoS) and non-LoS
(NLoS) fading with f and c being the carrier frequency and
speed of light, respectively, ηLos, ηNLos, a, and b depending on
the propagation environment, and φji = 180

π arcsin H
dji

For the IoT data collection, at each time instant there is
only one active cluster, and thus the data collection process is
inter-cluster interference-free. This corresponds to the practical
scenarios where IoT data is in small amount and thus the
transmission can ﬁnish rather quickly. For node-i in cluster-j,
the transmit power is pji and limited by the power constraint
given by

.

and

0 ≤ pji ≤ pmsk

j

,

∀i ∈ Ij,

pji ≤ pmax

j

,

(cid:88)

i∈Ij

(5)

(6)

j

and pmax

where pmsk
are the per-node and per-cluster maximum
power, respectively. Then, the transmission rate in cluster-j is
obtained as

j

(cid:40)

(cid:32)

r(ag)
j = ESj

B(ag) log2 det

IK +

SjLjPjLT

j ST
j

(cid:33)(cid:41)

σ2
0

, (7)

where B(ag) is the bandwidth with superscript indicating air-
ground transmissions, Pj = diag (cid:0)[pji]i∈Ij
(cid:1) collects the trans-
mit power of all nodes in cluster-j, IK is a K-dimensional
identity matrix, σ2
0 is the background noise power, and the
expectation is conducted with respect to small-scale fading.

B. Blockchain Model

For the UAV-assisted IoT model, we consider that trust has
been established in each cluster between the IoT nodes and
UAV, yet they have no information regarding the legitimacy of
other clusters. Thus, to defend against the data tampering by
the potential malicious adversaries, blockchain is introduced
to process the collected IoT data to guarantee the security and
integrity in a decentralized manner. The blockchain is estab-
lished among the UAVs, where the PoS consensus mechanism
is employed with mild operational cost while being convenient
to incorporate the incentive designs. As a complete model
for PoS blockchain operations can be rather cumbersome, and
thus we concentrate on the principle components incurring the
latency to reach the consensus, including transmission, mining,
propagation, veriﬁcation, and conﬁrmation. Assume the data
amount collected from cluster-j is denoted by Ψj (in bit), the

4

following time components need to be consumed for the data
to be bundled, audited, and chained to the existing ledger.

1) Transmission time: Given the transmission model intro-
duced before for the IoT uplink in cluster-j, the time consumed
for Ψj bits to reach the serving UAV is

τ (tx)
j =

Ψj
r(ag)
j

,

is obtained from (7).

(8)

where r(ag)

j

2) Mining time: When the UAV ﬁnishes the data collection
from the served IoT cluster, the mining process is conducted to
generate candidate blocks with data regarded as transactions.
The time consumed in this part depends on the computation
capability of the UAV, given as

τ (mn)
j

=

Ψj
ζ

ν,

(9)

for cluster-j, where ζ is the computation rate (in bit/s), and
ν is the coefﬁcient of computation complexity for mining.
Note that
the data size for mining is slightly larger than
Ψj considering the required block header. But for a general
case, the IoT data (transactions) dominates the overall size
and we can safely use Ψj as the mining data size. This
assumption is also applied for propagation and veriﬁcation
time modelings. As we adopt the PoS consensus mechanism,
the mining complexity can be largely alleviated.

3) Time for propagation and veriﬁcation: For the mined
blocks by the current UAV, they will be propagated to other
UAVs in the blockchain network for veriﬁcation and only the
veriﬁed blocks can be chained. In this process, the mining
UAV broadcasts the candidate blocks, for which the propaga-
tion delay is given as

τ (pv)
j =

Ψj

min
j,k∈J

r(aa)
j,k

,

(10)

where r(aa)
j,k is the transmission rate from UAV-j to UAV-k with
superscript indicating air-to-air links. Evidently, the propaga-
tion delay depends on the inter-UAV communications with the
lowest transmission rate. While the inter-UAV communication
experiences LoS air-to-air propagation model and thus the rate
from UAV-j to UAV-k can be deﬁned as

(cid:32)

r(aa)
j,k = B(aa) log2

1 +

KPj (cid:107)vj − vk(cid:107)−2
σ2
0

(cid:33)

,

(11)

where B(aa) is the bandwidth, Pj is the transmit power of
UAV-j, K arises as the array gain at the receiving UAV with
K antennas. Here, the interference is not explicitly incor-
porated regarding the inter-UAV communications due to the
asynchronized blockchain operations among the UAVs. Then,
the propagated candidate block is veriﬁed at other UAVs. As
the veriﬁcation corresponds to certain hash calculation that can
be done rather quickly, the time consumed can be neglected
as compared with propagation time, and thus is not explicitly
considered here.

4) Time for conﬁrmation and chaining: When the block
veriﬁcation is ﬁnished, the results are fed back to conﬁrm that

the block is valid through the air-to-air links among the UAVs.
The candidate block is then chained into the current ledger and
the local version of the ledger at all client updates correspond-
ingly. This process includes some lightweight transmission and
computation, the time required is denoted by τ (cc)
, which can
be assumed to be a constant.

j

IV. PROBLEM FORMULATION AND DECOMPOSITION

Given the basic models regarding the IoT data transmission
and blockchain operation, we utilize an efﬁcient PoS procedure
with incentive design. According to the PoS procedure, in each
round there will be a leader, say UAV-k ∈ J , to conduct
the blockchain operation for the IoT data in cluster-j that is
currently active. In this process, an amount of Ψj IoT data
induces an overall payment of Φ + ρΨj (in coin), where Φ is
the ﬁxed payment for each valid block and ρ is the coefﬁcient
(in coin/bit) for transactions fees. Meanwhile, the blockchain
operation with respect to the data in cluster-j incurs a cost,
denoted by Ωj,k, when the leader processing the blockchain is
UAV-k. Note that the IoT data originated from cluster-j can be
bundled into blocks by any UAV, yet there require additional
procedures for UAV-j as the collector to relay the data to UAV-
k for blockchaining, and thus we assume that Ωj,j < Ωj,k for
all k ∈ J−j.

Moreover, based on the principle of PoS, the probability for
a UAV as the stakeholder to generate a block (i.e., mining),
is proportional to its amount of stakes. The stake can be the
coin deposit allocated by the network operators to facilitate the
blockchain operations. Here, we denote the available stake at
UAV-j as Υj, j ∈ J . In accordance with the aforementioned
payment and cost models, we encourage the UAV serving the
currently active cluster to conduct the mining process, which
helps reduce the system cost. To this end, we propose to
construct a stake pool at the currently active UAV. Without
loss of generality, we assume cluster-j is active, and then a
pool is constructed at UAV-j. Meanwhile, other UAVs also
contribute to the pool with part of their stakes. We assume that
the ratio of invested stake at UAV-k is αj,k ∈ [0, 1], k ∈ J−j,
then the probability for the pool, i.e., UAV-j to generate the
block is
Υj + (cid:80)
k∈J−j
(cid:80)
j∈J

αj,kΥk

qj,j =

(12)

Υj

,

where UAV-j naturally devotes all its stakes in the pool. Then,
the probability for other UAVs being the miner is

qj,k =

(1 − αj,k) Υk

(cid:80)
j∈J

Υj

,

∀k ∈ J−j.

(13)

In accordance with the pool construction at UAV-j, the
investment of other UAVs should be rewarded to incentivize
their cooperation. In particular, UAV-j splits a portion of its
potential payment for block generation to be shared with
its investors, where the returned payment is proportional to
the investment. Denote the portion of payment to reward the
investors as βj ∈ [0, 1] at UAV-j. If the pool successfully
works as the miner receiving a payment of Φ+ρΨj, it obtains a

5

(cid:80)

k∈J−j

αj,kΥk

αj,kΥk

proﬁt of (1 − βj) (Φ + ρΨj) − Ωj,j, corresponding to the pre-
served payment while taking out the cost. Meanwhile, UAV-
βj (Φ + ρΨj),
k in ∈ J−j obtains a proﬁt of
corresponding to the investment-proportional payment at no
cost. Also, there are also possibilities that UAV-k in ∈ J−j
creates a candidate block. Then, this UAV obtains a proﬁt of
(Φ + ρΨj) − Ωj,k, earning all the payment with the corre-
sponding cost. Therefore, the expected proﬁt for the pool, i.e.,
UAV-j, is given as
Υj + (cid:80)
k∈J−j
(cid:80)
j∈J

[(1 − βj) (Φ + ρΨj) − Ωj,j] .

αj,kΥk

Θj,j =

Υj

(14)

Also, the expected proﬁt for other UAVs is

Θj,k =

(1 − αj,k) Υk

(cid:80)
j∈J

Υj

[(Φ + ρΨj) − Ωj,k]

αj,kΥk

Υj + (cid:80)
k∈J−j
(cid:80)
j∈J

Υj

+

αj,kΥk

αj,kΥk

(cid:80)
k∈J−j
∀k ∈ J−j.

βj (Φ + ρΨj) ,

(15)
Note that the above discussions are based on the assumption
that the IoT data originates from cluster-j, and the formulation
can be readily extended to the cases when other clusters are
active.

Based on the modeling of the proﬁt gaining and time
consumed over the blockchain operations with respect to IoT
data, we can then deﬁne the utility achieved by processing the
data from cluster-j as

Θj,j + (cid:80)
k∈J−j
j + τ (pv)

τ (tx)
j + τ (mn)

Θj,k

j + τ (cc)

j

Uj =

,

(16)

the proﬁt

where the proﬁt of all parties including the pool and other
followers is incorporated. With the proposed incentive mech-
anism,
is obtained not only from mining as a
conventional blockchain but also from stake investment. In
this regard, the incentive design introduces an implicit altru-
istic effect in the blockchain system. Then, the problem is
formulated to optimize the overall system utility by jointly
considering the IoT transmissions, stake investment and proﬁt
sharing, and the UAV deployment, speciﬁed as

max
{vj ,pj ,βj ,αj }j∈J

s.t.

U =

(cid:88)

Uj

(17a)

∀j ∈ J ,

j∈J
vj ∈ Λ,
(5), (6),
βj ∈ [0, 1],
(17d)
αj,k ∈ [0, 1], ∀j ∈ J , ∀k ∈ J−j, (17e)

∀j ∈ J ,

∀j ∈ J ,

(17b)

(17c)

where pj = [pji]i∈Ij
αj = [αj,k]k∈J−j

is the power vector in cluster-j and

is the vector of stake investment portion.

For the formulated problem, we can see that the considered
factors affect system performance in a coupled and compli-
cated manner. Particularly, the IoT transmissions constitute

the basic ingredient for block generation. The incentives with
investment and proﬁt-sharing affect the achieved proﬁt. The
UAV deployment and network topology inﬂuence the time
for blockchain operations such as data transmission and block
propagation. Then, it can be rather cumbersome to tackle the
problem directly. Moreover, as the optimization in (17) appears
in a centralized manner, the corresponding algorithm design
violates the decentralized operations of the UAV-assisted IoT
and blockchain system. Therefore, we will then decompose
the problem to facilitate the distributed solution.

Revisit the formulated problem to maximize the sum utility
within a distributed perspective, we ﬁrst allow each UAV-
IoT cluster to determine their own strategies. Then, by an-
alyzing the relation between the optimization variables and
the objective, we have the following observations. The IoT
transmission and incentive strategies can be investigated at
each UAV-IoT-pair basis since transmissions occur within the
current pair while the incentive needs to be designed with
respect to the pool constructed for the current pair. In contrast,
the UAV deployment affects the performance in the networked
scale, as the movement of one UAV not only affects the
IoT data transmission in its own cluster, but also the block
propagation to other clusters. Therefore, we tackle the problem
in a distributed manner to allow the individual and independent
decision-making at each UAV-IoT cluster pair. Further, the
problem at each UAV-IoT cluster pair is decomposed into two
layers where the outer layer solves for the UAV deployment
while the inner layer for IoT transmissions and incentive
designs. The inner problem can be solved independently for
each UAV-IoT cluster pair where the transmission optimization
corresponds to the minimization of the denominator of the
utility function in (16), while the incentive design maximizes
the nominator. The outer problem is solved through a multi-
agent reinforcement learning process for individual optimality
at each UAV. Correspondingly, the problem in (17) is then
solved in a decentralized manner allowing the individual
decision-making at each party to facilitate the implementation.

V. INNER PROBLEM SOLVING FOR IOT TRANSMISSION
AND INCENTIVE DESIGN

Based on the problem decomposition introduced before, we
consider the inner problem at each UAV-IoT cluster basis to
solve for the transmission and incentive strategy, with ﬁxed
UAV deployment at the outer layer. The inner problem intends
to maximize the individual utility function in (16), where the
transmission strategy minimizes the denominator of the utility
and the incentive design tackles the nominator. Thus, these
two subproblems can be addressed independently as detailed
below.

A. IoT Transmission Strategy

In accordance with the problem in (17), the maximum IoT
transmission rate corresponds to the minimized transmission
time in (8),
leading to the maximization of the objective
function in (17). As has been noted, the transmission strategy
then the
is independently determined at each IoT cluster,
problem is formulated to maximize the rate in (7) with respect

6

to the power constraint in (5) and (6). For this problem, we ﬁrst
tackle the expectation operation with large-system analysis
technique [36] and approximate the transmission rate as

r(ag)
j = B(ag)





(cid:88)

i∈Ij

log2(1 +

1
σ2
0

K(cid:96)j,ipjiω−1

j

)

(18)

+ K log2(ωj) − K log2 e(1 − ω−1

j

)(cid:3) ,

where ωj is the newly introduced auxiliary variable satisfying

ωj = 1 +

Ij
(cid:88)

i=1

(cid:96)j,ipji
0 + K(cid:96)j,ipjiω−1
σ2

j

.

Then, the IoT transmission problem becomes

max
pj ,ωj
s.t.

r(ag)
j

(5), (6), and (19),

(19)

(20a)

(20b)

for cluster-j ∈ J . For this problem, we can adopt
the
alternating optimization to tackle the power optimization and
auxiliaries in an iterative manner. In particular, with ﬁxed aux-
iliaries, the power allocation is evidently a convex optimization
and thus we can leverage the Lagrange multiplier method to
obtain that

p(cid:63)
ji =

(cid:18)

µj −

ωjσ2
0
K(cid:96)ji

(cid:19)pmsk

j

0

(21)

i∈Ij

p(cid:63)
ji = pmax

with ( · )b
a indicating min(max(·, a), b) and µj being the
multiplier satisfying the equality (cid:80)
. Mean-
while, the auxiliaries optimization with ﬁxed power allocation
can be obtained through the ﬁxed-point iteration in the form
of (19). The geometry programming can be also exploited to
solve the auxiliary optimization, as shown in [13]. Finally, the
convergence of the alternating optimization processes between
power allocation and auxiliaries induces the optimal IoT
transmission strategy.

j

B. Incentive Design

The incentive design incorporates stake investment and
proﬁt-sharing optimization to achieve the highest proﬁt for
UAVs in the blockchain network, which is consistent with
the objective function in (17). However, for the practical
blockchain system operation, all the concerned parties work in
a decentralized manner without explicit outsider coordination.
Correspondingly, we intend to design the incentive mechanism
from a distributed perspective through game-based analysis,
with each concerned party maximizing its own proﬁt.

Without loss of generality, we consider the IoT data to be
blockchained originate from cluster-j. In accordance with the
previous discussions to reduce the system operation overhead,
we encourage UAV-j as the currently active data collector
working as the miner to generate candidate blocks based on
its collected data. To this end, UAV-j constructs a stake pool
that allows other UAVs to invest their stakes, while the stake
pool shares its obtained payment in return for the investment.
In this regard, the pool determines the portion of payment
sharing while other UAVs decide their ratio of investment,
which leads to a one-leader multi-follower Stackelberg game

7

formulation detailed below. Speciﬁcally, the problem at the
leader can be written as

max
βj
s.t.

Θj,j (βj; αj)

βj ∈ [0, 1],

(22a)

(22b)

where αj = [αj,k]k∈J−j
is the vector of followers’ decision
variable, and Θj,j is given in (14). Here we explicitly indicate
the arguments to show the interplay between different partici-
pants in the game. For the followers in the game, the problem
is speciﬁed as

strategies of all followers and is convex with respect to its own
strategy. The proof is omitted here for space limitation while
interested readers can refer to the second-order derivative and
the conclusion readily follows. Based on the study in [37], we
know that a convex game must admit a Nash equilibrium. To
derive the equilibrium, we resort to the best-response strategy,
i.e., the optimal strategy of one player on the condition of
ﬁxed strategies of others. Given the convexity of the proﬁt
function, by nulling the ﬁrst-order derivative, we can derive
the best response for UAV-k ∈ J−j given as (27), where ζj
and ξj,k deﬁned as

Θj,k (αj,k; αj,−k, βj)

max
αj,k
s.t. αj,k ∈ [0, 1],

(23a)

(23b)

ζj =

Υj

(cid:80)
j∈J

Υj

βj (Φ + ρΨj) ,

(28)

for k ∈ J−j, where Θj,k is given in (15) and αj,−k =
[αj,k(cid:48)]k(cid:48)∈J−j \{k} corresponds to all rest followers other than
follower-k.

Then, the problem in (22) at the leader and problems in (23)
at all followers constitute the Stackelberg game, denoted by G,
which incorporates one leader and J −1 followers. In the game
context, the problem in (22) and problems in (23) are coupled,
and thus we cannot directly solve them independently. In
particular, for a Stackelberg game, the leader takes action ﬁrst,
followed by the action of the followers, and the solution to the
game is deﬁned by the Stackelberg equilibrium. In accordance
with the hierarchical structure of decision makings in the
Stackelberg game, the equilibrium is also layered. Denote the
equilibrium as (β(cid:63)
j ), and then it satisﬁes the following
conditions

j , α(cid:63)

Θj,k

and

(cid:0)α(cid:63)

j,k; α(cid:63)

j,−k, β(cid:63)
j

(cid:0)αj,k; α(cid:63)

(cid:1) ≥ Θj,k
∀αj,k ∈ [0, 1],

(cid:1) ,
j,−k, β(cid:63)
j
∀k ∈ J−j,

Θj,j

(cid:0)β(cid:63)

j ; α(cid:63)
j

(cid:1) ≥ Θj,j

(cid:0)βj; α(cid:63)

j

(cid:1) ,

(24)

(25)

which denote the lower equilibrium for the followers and
upper equilibrium for the leader, respectively. Then the lower
equilibrium in (24) indicates that no follower will unilaterally
deviate from the equilibrium strategy given the leader’s action,
while the upper equilibrium in (25) implies that the equilib-
rium strategy at the leader is optimal on condition that the
lower equilibrium is also achieved among the followers.

We then ﬁnd the Stackelberg equilibrium to determine
the investment and payment sharing. For Stackelberg games,
we employ the backward induction approach to achieve the
Stackelberg equilibrium. In this regard, we ﬁrst analyze the
lower equilibrium among the followers while assuming a ﬁxed
strategy at the leader, i.e., to ﬁnd the individually optimal in-
vestment with respect to ﬁxed proﬁt sharing. Correspondingly,
the followers compete to maximize their own proﬁt function,
inducing a generic Nash game model given as

¯Gj(βj) = (cid:8)J−j, [0, 1]J−1, {Θj,k}k∈J−j
where subscript-j speciﬁes the current leader as UAV-j and
this game is parameterized by βj as the leader’s strategy.
For the Nash game ¯Gj, we can easily verify that
is a
convex game that the strategy space is compact and convex,
the
and the proﬁt function in (15) is continuous against

(26)

(cid:9) ,

it

and

ξj,k =

1
(cid:80)
j∈J

Υj

[(1 − βj) (Φ + ρΨj) − Ωj,k] ,

(29)

are constants obtained by rearranging the terms in the proﬁt
functions to simplify the notation.

With the best-response strategy derived in (27), specifying
the optimal strategy for the current followers with respect to
the strategies of all other followers, we can then achieve the
lower equilibrium through an iterative strategy update process
among all followers. However, by revisiting the best-response
strategy, we can rearrange the terms in (27) as
(cid:80)
k(cid:48)∈J−j \{k}

αj,k(cid:48)Υk(cid:48)

ζj

(cid:33)2 = ξj,k.

(30)

(cid:32)

(cid:80)
k(cid:48)∈J−j

αj,k(cid:48)Υk(cid:48)

By further summing up the equation in (30) over all followers,
we arrive at

ζj (J − 2)
ξj,k(cid:48)

(cid:80)
k(cid:48)∈J−j

(cid:88)

=

k(cid:48)∈J−j

αj,k(cid:48)Υk(cid:48).

(31)

The equality above has an implicit assumption that all fol-
lowers have positive investment at the lower equilibrium. In
the case that certain followers are of no investment, then they
are regarded as inactive and thus excluded from the competi-
tion. Accordingly, the number of remaining active users then
replaces the number of followers during the derivation. Then,
the equality above is substituted into the equilibrium condition
in (27), and we obtain the following equilibrium

α(cid:63)

j,k =

1
Υk

ζj (J − 2)
ξj,k(cid:48)

(cid:80)
k(cid:48)∈J−j




1 −




 ,

ξj,k (J − 2)
ξj,k(cid:48)

(cid:80)
k(cid:48)∈J−j

(32)

for k ∈ J−j, which is further extended as (33). Finally,
the lower equilibrium in (33) is in closed-form and can be
calculated directly without iterations. In this regard, comparing
the original equilibrium in (27) as individual best response
requiring iterations, the results in (32) are achieved due to
the special structure of the lower problem and facilitates the
calculation of the lower equilibrium.

(cid:40)

min

1
Υk

(cid:32)

(cid:114) ζj
ξj,k

α(cid:63)

j,k =






(cid:80)
k(cid:48)∈J−j \{k}

αj,k(cid:48)Υk(cid:48) − (cid:80)

k(cid:48)∈J−j \{k}

(cid:33)

(cid:41)

αj,k(cid:48)Υk(cid:48)

, 1

,

0,

(cid:34)

(J − 2) βjΥj (Φ + ρΨj)

α(cid:63)

j,k =

(1 − βj) (Φ + ρΨj) − (cid:80)

Cj,k(cid:48) + (J − 2)Cj,k

k(cid:48)∈J−j

(cid:35)

(cid:32)

(J − 1) (Φ + ρΨj) (1 − βj) − (cid:80)

Υk

(cid:33)2

Cj,k(cid:48)

k(cid:48)∈J−j

8

if

ζj
ξj,k

≥ (cid:80)

k(cid:48)∈J−j \{k}

αj,k(cid:48)Υk(cid:48)

(27)

otherwise

(33)

(cid:0)β(cid:63)

With the lower equilibrium obtained in (33), we can then
substitute it into the leader’s utility function in (14), whose
maximization induces the leader’s optimal strategy while in-
corporating the lower equilibrium into consideration. We can
adopt one-dimensional search to ﬁnd the upper equilibrium
for the leader, denoted by β(cid:63)
j . We then substitute the leader’s
strategy β(cid:63)
j into (33), leading to the actual lower equilibrium,
(cid:1)(cid:3)
(cid:1). Finally, the strategy set (cid:2)β(cid:63)
denoted by α(cid:63)
j
constitutes the Stackelberg equilibrium of the incentive game,
where β(cid:63)
j speciﬁes the portion of proﬁt sharing at UAV-
(cid:1) corresponds to the portion
(cid:0)β(cid:63)
j (the stake pool), and α(cid:63)
j
j
of invested stakes at other UAVs. As a further note, based
on the deviations above, we can see that
the Stackelberg
equilibrium uniquely exists, as the leader’s problem in (22)
admits the optimum, while the followers’ strategy is then
uniquely determined based on the closed-form expression
speciﬁed in (33).

j , α(cid:63)
j

(cid:0)β(cid:63)

j

j

s ∈ S, each agent-j uses the policy µj : Oj (cid:55)→ Aj to select an
action. Then, the agents interact with the environment by exe-
cuting the action to achieve a new state, S ×A1×...×AJ (cid:55)→ S.
In this regard, agent-j receives a reward Rj : S × Aj (cid:55)→ R
according to the state and its own action, along with an updated
observation. The goal of each agent is to maximize the long-
term expected reward Γj = (cid:80)T
t=0 γtRj, where γ ∈ (0, 1) is a
discount factor, and t ∈ [0, T ] denotes the epoch with T being
the time horizon. To be speciﬁc, the main elements regarding
the formulated Markov game are deﬁned as follows:

• State space S: A state s (t) ∈ S corresponds to the
system environment state at epoch-t, including channel
state information, and the horizontal coordinates of UAVs
and IoT nodes, speciﬁed as
(cid:110)
{wji (t)}i∈Ij ,j∈J , {vj (t)}j∈J ,
(cid:111)

s (t) =

(34)

{(cid:96)ji (t)}i∈Ij ,j∈J

.

VI. OUTER PROBLEM SOLVING FOR UAV DEPLOYMENT

In this section, we consider the outer problem for UAV
deployment. Similarly, we adopt
the distributed decision-
making at the UAVs in accordance with the nature of the
blockchained IoT system. However, different from the inner
problem that can be tackled at each UAV-IoT cluster basis,
the UAV deployment affects the blockchain system operation
over the whole network, and thus the mutual inﬂuence of the
strategy at different UAVs needs to be addressed.

A. UAV Deployment as a Markov Game

For certain UAV deployment, it is likely to affect the IoT
operations in multiple rounds. Such a relatively long-term
effect can be tracked by the Markov decision process (MDP).
Meanwhile, each UAV determines the location based on its
own observation of the network, while inﬂuencing each other.
Therefore, the networked problem can be modeled as a par-
tially observable Markov game, which incorporates the deploy-
ment of each UAV as a partially observable MDP [38]. The
Markov game with UAVs as J agents can be represented by a
set of states S, a set of observations O = {O1, ..., Oj, ..., OJ },
a set of actions A = {A1, ..., Aj, ..., AJ }, and a reward
function for each agent. The state includes the location of
IoT nodes and the deployment of UAVs, the observation of an
agent is its private version regarding the state, and the action is
the decision on an update of deployment. For the current state

• Observation space O: Considering that there is no central
coordinator for information exchange among UAVs, the
UAVs only have the information regarding their own
cluster, and thus the observation oj (t) is extended as

oj (t) =

(cid:110)
{wji (t)}i∈Ij

, vj (t) , {(cid:96)ji (t)}i∈Ij

(cid:111)

.

(35)

• Action space A: The UAVs take actions to update their
deployment. Given current neural network parameter θµ
j ,
the policy µj(oj (t) |θµ
j ) induces an actions aj (t) de-
ﬁned as the change on location between two successive
epochs, i.e., aj (t) = vj (t) − vj(t − 1).

• Reward R: The reward measures the effect of the action
taken by an agent for a given state, which further guides
the agent to ﬁnd the best deployment strategy. Corre-
spondingly, it needs to be designed in accordance with
the system objective. Here we deﬁne the reward function
as

Rj = Uj (t) − Uj (t − 1) ,

(36)

where Uj is given in (16) as the achieved utility from the
blockchain system given current deployment. In consis-
tence with the deﬁnition of action, here we also use the
difference between two epochs for the reward function.

B. MADDPG-Based Algorithm

For problems with high-dimensional state space and con-
tinuous action space, the DDPG-based learning can be more

9

local observation oj (t), and obtain the immediate reward
value Rj (t) with an updated observation o(cid:48)
j (t). Then, store
(oj (t) , aj (t) , Rj (t) , o(cid:48)
j (t)) for all the agents and constitute
a transition in the reply buffer as (s (t) , a (t) , R (t) , s(cid:48) (t)),
where a (t) = [aj (t)]j∈J and R (t) = [Rj (t)]j∈J . After
sufﬁcient training, D group of transitions (sd, ad, Rd, s(cid:48)d) are
randomly selected from the experience pool D for learning.
The training goal of the critic network is to reduce the error
between the target network parameters and the estimation
network parameters, and accurately evaluate the action-value
function. Thus the network parameters are updated by mini-
mizing the loss function deﬁned as

(cid:17)

(cid:16)

θQ
j

L

=

1
D

D
(cid:88)

d=1

(cid:0)yd

j − Qj

(cid:0)sd, ad(cid:1)(cid:1)2

,

(37)

where

j = Rd
yd

j + γQ(cid:48)
j

(cid:0)s(cid:48)d, a(cid:48)

1, ..., a(cid:48)
J

(cid:1) |a(cid:48)

j =µ(cid:48)

j(o(cid:48)d

j ),

(38)

Qj and Q(cid:48)
j are action-value functions that take as input the
action a and the state s of all agents, and output the Q-value
for agent j, D is the number of transitions from the minibatch.
Then, the actor network maximizes the cumulative reward and
updates the network parameters through the gradient ascent
method:

∆θµ

j

J =

1
D

D
(cid:88)

d=1

(cid:79)

θµ
j

µ (cid:0)od

j

(cid:1) (cid:79)aj Qj

(cid:0)xd, ad(cid:1) |aj =µj(od
j ).
(39)

Finally, the MADDPG network parameters are updated as
j + (1 − σ) θQ(cid:48)
j ,

θQ(cid:48)
j ← σθQ

σ (cid:28) 1,

(40)

and

θµ(cid:48)
j ← σθµ

j + (1 − σ) θµ(cid:48)
j ,

σ (cid:28) 1,

(41)

Fig. 2. The framework of MADDPG algorithm.

effective as compared with conventional approaches such
as deep Q-learning (DQN) or deterministic policy gradient
(DPG). For our considered problem that each agent determines
the deployment on their own in a competitive manner based on
their local observation, the DDPG approach will be employed
at each party involved and thus constitute the MAGGPG
framework, which allows independent learning procedure at
each UAV while reﬂecting the interactions with the environ-
ment.

The proposed MADDPG framework is shown in Fig. 2,
including a parallel of deep reinforcement learning agents
adopting DDPG in an independent while interactive manner.
The DDPG learning features an actor-critic architecture, where
the actor network based on policy gradient solves the problems
with continuous action space, and the critic network based
on DQN solves the problems of high-dimensional state space.
The actor network determines an action based on the currently
observed state and strategy, and the critic network evaluates the
action produced by the actor network based on the state-action
function. In addition, DDPG also integrates the experience
playback of the DQN and the target network, where the experi-
ence playback improves the utilization of data and downgrades
the correlation of data samples and the target network delays
neural network parameter updates and improves the stability
of the overall algorithm.

The MADDPG-based algorithm design is detailed as Alg. 1.
The critical procedures are explained as follows. First, ini-
(cid:111)
j , θQ(cid:48)
tialize all neural network with parameters
for the evaluation actor network, target actor network, eval-
uation critic network, target critic network, respectively, at
all agent. Also initialize the environment parameters and
state before the start of each episode. Secondly, each agent-
j ∈ J selects and executes actions aj (t) according to its

j , θµ(cid:48)
θµ

j , θQ

(cid:110)

j

Critic-jMinimizeMSETarget network:QθUpdate1(,,...,)djNQsaaSoft update1(,,...,)dddjNQsaaActor-jEvaluation network:θPolicy gradientTarget network:θUpdateSoft update=)djjj(ao=)djjj(ao=)djjj(ao{,,,}ddddsaRsEvaluation network:QθUAV Agent-jReplay Buffer...1(,,...,)dddjNQsaaIoT EnvironmentActor-1Critic-1UAV Agent-1O1a1Actor-JCritic-JUAV Agent-JOjajOJaJ1[(),...,()]JRtRt......())jjt(o1[(),...,()]Jttoo()jto11())t(o1()to())JJt(o()Jto...Algorithm 1 MADDPG for UAV Deployment
Training process:
1: Initialize Critic networks and actor networks for all agents
j , θµ(cid:48)

j , θQ(cid:48)
θQ

(cid:110)

(cid:111)

;

j

with weights

j , θµ
2: Initialize the reply buffer D;
3: for episode = 1 to max-episode do
4:
5:
6:

j∈J

action aj (t)

Initialize a random process N for action exploration;
Initialize the environment with initial state s0;
for t = 1 to max-epoch do
agent-j
selects
(cid:0)oj (t) |θµ

an
Each
(cid:1) + N according to the
µj
neural network with an exploration noise;
Execute the action a (t) = [aj (t)]j∈J , obtain reward
R (t) = [Rj (t)]j∈J , and reach a new state s(cid:48) (t);
Store transition (s (t) , a (t) , R (t) , s(cid:48) (t)) in D;
Update the state for the environment;
if sufﬁcient transitions collected then

=
current

j

for agent j = 1 to J do

j , Rd

Sample a random minibatch of D transitions
(sd, ad
j , s(cid:48)d) from D;
Set target Q-value according to (38);
Update critic by minimizing the loss in (37);
Update actor using the sampled policy gradient
as (39);

end for
Update target network parameters for each agent
based on (40) and (41);

7:

8:

9:
10:
11:
12:
13:

14:
15:
16:

17:

18:

end if
end for

19:
20:
21: end for
Execution process:
1: Load the trained models of critic networks and actor

networks of all agents;

2: Initialize the environment with initial state s0;
3: for t= 1 to max-step do
4:

(cid:1);

(cid:0)oj (t) |θµ

Each agent selects action according to aj (t) =
µj
Execute actions a (t) = (a1 (t) , .., aJ (t)), reach a new
state s(cid:48) (t);
Update the state of all agents;

j

5:

6:
7: end for
8: Output: UAV deployment strategy.

according to the soft update rule, which helps improve the
stability of learning.

VII. SIMULATION RESULTS

In this section, we present the simulation results to show
the performance. We consider an area of 1,000 m × 1,000 m.
There are 6 IoT clusters while each cluster incorporates 10
IoT nodes and a serving UAV. The nodes are randomly
located within the area. The main simulation parameters are
summarized in Table I, used as defaults unless otherwise noted.

TABLE I
SIMULATION PARAMETERS

Parameter

Description

Number of antennas at UAV

Altitude of UAV

Bandwidth for IoT uplink

Bandwidth between UAVs

Maximum power per cluster

Maximum power per node

Transmit power of each UAV

Noise power

Carrier frequency

10

Value

4

90 m

100 kHz

100 kHz

1 W

0.4 W

0.5 W

-110 dBm

2 GHz

Environment factor

(9.613, 0.158)

LoS and NLoS attenuation

(1 dB, 20 dB)

Time for conﬁrmation

0.5 s

Available stake at the UAVs

∼ U (90,100)

IoT data size

Fixed reward for blockchain

Transaction fee per bit

Blockchain operational cost

Critic learning rate

Actor learning rate

Discounted factor

Batch size

Buffer capacity

Maximum epoch

8 M

200
5×10-6

(30, 60)

1×10-5
1×10-4

0.90

128
106

250

5000

K

H
B(ag)
B(aa)
pmax
pmsk

P
σ2
0
f

(a, b)

(ηLoS, ηNLoS)
τ (cc)

Υ

Ψ

Φ

ρ

(Ωj,j , Ω j,k

)

(j(cid:54)=k)

rc

ra

γ

min-batch

|D|

max-step

max-episode

Maximum episode

A. Convergence of MADDPG and UAV Deployment

We ﬁrst show the convergence of the proposed MADDPG
approach in Figs. 3 and 4, where the cumulative reward
under the MADDPG algorithm is shown with different actor
network learning rates and different critic network learning
rates. It can be readily seen that the training process eventually
converges, while the learning rate has a signiﬁcant impact
on the convergence rate. During the training process, if the
learning rate is too large, it is likely to induce an overﬁtted
neural network after training, and thus the cumulative reward
will ﬂuctuate or may even diverge. On the contrary, if the
learning rate is too small, it leads to slow convergence during
the training process. Therefore, setting an appropriate learning
rate is crucial for actual algorithm implementation. Also, it
should be noted that with proper learning rates, the proposed
approach can solve our formulated problem effectively.

In Figs. 5 and 6, we show the UAV deployment through the
proposed MADDPG approach with different network settings
and topology, where the cases with 4 clusters and 6 clusters
are shown. We also explicitly indicate the geographic centers
for the areas for each cluster. The results depict two trends
regarding the UAV deployment for the blockchain-secured IoT.
The UAV tends to hover at the location with more nodes
gathering. In this regard, the UAV can establish the IoT uplink

11

Fig. 3. Cumulative reward with different learning rate of the actor network.

Fig. 5. An illustration of UAV deployment with 4 IoT clusters.

Fig. 4. Cumulative reward with different learning rate of the critic network.

Fig. 6. An illustration of UAV deployment with 6 IoT clusters.

with improved channel quality so as to facilitate the data col-
lection with reduced transmission time and improve the system
utility. Meanwhile, the UAVs as blockchain users, tend to
locate close to each other. In this regard, the UAVs have closer
air transmission distances, for which the block propagation
and veriﬁcation can be more conveniently conducted, further
reducing the blockchain operation latency and improving the
system utility. While these two trends sometimes coincide, as
shown in Fig. 5, sometimes compromise is needed, as shown
in Fig. 6, which reveals that the multiple factors affecting the
UAV deployment need to be well balanced for the optimized
system performance.

B. Performance Comparison

In Fig. 7, we show the obtained proﬁt through the proposed
incentive mechanism. In particular, each row corresponds to
the case with one active IoT cluster. For example, for the ﬁrst
row, cluster-1 is now actively conducting IoT transmission and
thus UAV-1 constructs a stake pool allowing the investment
from others. In this regard, we can see that at the Stackelberg

equilibrium, UAV-1 with the pool obtains a proﬁt of 48.4
coins, while other UAVs have a proﬁt at about 30 coins.
Similar results can be observed in cases with different active
IoT clusters and pool constructions. Note that the Stackelberg
game with leader-follower architecture allows the leader to
take action ﬁrst and achieve an advantageous position in
the game, and the pool has a relatively higher proﬁt as
compared with the followers. Note for the case without pools,
all UAVs have an equal position in the game and thus there
are no leader’s advantages. Since the expected proﬁt considers
the cases for other UAVs working as the miner to get the
payment for blockchain operation as well as the reward for
investment. In this regard, even the pool is constructed, the
mining process does not necessarily occur here. However, the
pool construction does induce a higher expected proﬁt, even
though the pool needs to share its payment for the investment.
Therefore, we can see that the proposed investment mechanism
is quite effective in improving the utility at the pool constructor
with reduced cost, which further improves the system utility
of the overall blockchain system.

In Fig. 8, we show the results comparing the proposed

12

Fig. 7. Expected proﬁt at the UAVs with incentive design.

Fig. 8. Performance comparison with different approaches.

MADDPG approach with global search as well as the results
with random UAV deployment as baselines. As we mainly
address the deployment
through MADDPG, and thus we
adopt the IoT transmit power allocation and incentive design
as analyzed in Sec. V to facilitate the discussion, and use
UAV altitude as the ranking variable. For all considered
approaches, the achieved system utility ﬁrst increases and then
decreases as the UAVs reach higher. This can be explained
by the IoT-UAV transmission link quality that ﬁrst improves
and then downgrades, inducing a larger probability for LoS
transmissions while worsened channel quality as the UAV
altitude increases. Thus, there exists a tradeoff in terms of UAV
altitude for the system performance. Meanwhile, as expected,
the global search provides the best performance, while our
proposed MADDPG can effectively approach the optimum,
while there is an evident performance gap with random UAV
deployment as compared with other approaches. Particularly,
we can see that our proposal more closely approximates the
optimum when the UAVs ﬂy higher. This is because, with
higher UAV altitude, the location of IoT nodes in each cluster
has a smaller impact over the UAV deployment, since the
transmission link from the UAV to the IoT nodes tends to be
the same. In this regard, the UAV deployment will emphasize
more on the blockchain system and thus locate closer to
each other to facilitate the blockchain operations. Therefore,
the results for UAV deployment tend to be the same even
different approaches are exploited. Moreover, we emphasize
that the global search as a centralized approach requires ex-
plicit coordination among different UAVs and clusters, which
the distributed nature of IoT and blockchain
goes against
system. In contrast, our proposed MADDPG approach can be
implemented in a distributed manner, which is thus not only
effective but also convenient.

In Fig. 9, we compare the performance under our proposal
with the cases with the different transmission, incentive, and
deployment strategies, as speciﬁed in the legend of the ﬁgure.
The performance indicator is the system utility deﬁned as the
objective function in (17). Similar to the results in Fig. 8, the
performance ﬁrst improves and then downgrades as the UAV

altitude increases, due to the tradeoff between LoS probability
and channel propagation for the air-ground transmissions.
Meanwhile, our proposal results in the best performance as
compared with the baselines, regardless of the UAV altitude.
Comparing the results under different approaches, we can see
the performance gain through the learning-based deployment
(solid curves vs dashed curves), incentive design (curves with
circle markers and curves with square markers), and the IoT
transmission optimization (curves with triangle markers and
the others). Overall, as the UAV becomes higher, the link
quality from different IoT nodes to the UAV becomes closer,
and thus the performance gap among different approaches
shrinks. An interesting observation is that, as we compare the
results from MADDPG without the pool and geographic center
deployment with pool constructions, we can see that the former
outperforms the latter when the UAV altitude is relatively
low. This is because, when the UAV is relatively lower, the
difference in channel quality from different IoT nodes to
the UAV becomes more evident due to the stronger NLoS
components. In this regard, the UAV deployment can more
signiﬁcantly inﬂuence the overall performance as deployment
through learning is generally superior to the geographic center
deployment. Then, the performance gain from deployment
optimization outweighs that from the pool construction. In
contrast, when the UAV altitude becomes higher, the differ-
ence in IoT transmission links in the same cluster becomes
smaller. In this regard, the deployment through MADDPG
approximates the geographic center deployment. Meanwhile,
the beneﬁt brought by pool construction becomes more evident
due to the improved blockchain proﬁt and reduced cost.

Fig. 10 shows the performance comparison considering
the number of IoT nodes per cluster, where the baselines
are similarly deﬁned as those in Fig. 9. Also similarly, we
can see that our proposal with joint deployment, incentive,
and transmission optimization outperforms the rest. Also, the
system utility is improved with an increasing number of nodes
in the IoT cluster for all approaches. This is as expected since
more IoT nodes induce improved IoT uplink transmissions
to facilitate the blockchain operations. For the results from

13

Fig. 9. System utility with respect to UAV altitude.

Fig. 10. System utility with respect to number of nodes in a cluster.

different approaches, we observe the performance gained by
different factors. In particular, the design of the stake pool
increases the average proﬁt obtained by blockchain partici-
pants, thereby attracting more stakeholders to participate in the
investment, and improving the performance of the blockchain
network. Further, the UAV deployment and pool construction
both have signiﬁcant impact on the overall performance, since
the deployment affects the IoT transmission as well as the
blockchain operations while pool construction direct affects
the proﬁt. Moreover, with more IoT nodes, the performance
gap between different approaches becomes larger. This is
because, where there are more nodes, the transmission link
difference between IoT nodes becomes more signiﬁcant, which
allows a larger space for the optimization in different aspects,
including the deployment,
to
demonstrate their effectiveness and superiority.

incentive, and transmissions,

VIII. CONCLUSION

In this paper, we proposed a UAV-assisted data collection
for clustered IoT with PoS blockchain-based security, where
the IoT transmission, incentive for PoS, and UAV deploy-
ment were jointly considered. The proposed MADDPG was
exploited for the UAV-IoT cluster pair to learn their strat-
egy, facilitating the implementation in a distributed manner.
We particularly proposed the incentive design for the PoS
procedure with stake pool construction allowing investment-
based proﬁt sharing. The numerical results indicated that
implicit coordination is required for IoT transmission and
blockchain operation in terms of UAV deployment for the
optimized system performance. Moreover, the construction of
a stake pool not only facilitated the PoS consensus procedure
for blockchain, but also worked as an effective incentive
mechanism to improve the overall system utility.

REFERENCES

[1] S. Dang, O. Amin, B. Shihada, and M.-S. Alouini, “What should 6G

be?” Nat. Electron., vol. 3, no. 1, pp. 20–29, 2020.

[2] L. Chettri and R. Bera, “A comprehensive survey on internet of things
(IoT) toward 5G wireless systems,” IEEE Internet Things J., vol. 7,
no. 1, pp. 16–32, Jan. 2020.

[3] N. C. Luong, D. T. Hoang, P. Wang, D. Niyato, D. I. Kim, and Z. Han,
“Data collection and wireless communication in internet of things (IoT)
using economic analysis and pricing models: A survey,” IEEE Commun.
Surveys Tuts., vol. 18, no. 4, 4th Quart. 2016.

[4] X. Tang, R. Zhang, W. Wang, L. Cai, and Z. Han, “Robust secrecy com-
petition with aggregate interference constraint in small-cell networks,”
IEEE Trans. Wireless Commun., vol. 20, no. 4, pp. 2325–2340, Apr.
2021.

[5] A. Fotouhi, H. Qiang, M. Ding, M. Hassan, L. G. Giordano, A. Garcia-
Rodriguez, and J. Yuan, “Survey on UAV cellular communications:
Practical aspects, standardization advancements, regulation, and security
challenges,” IEEE Commun. Surveys Tuts., vol. 21, no. 4, pp. 3417–3442,
4th Quart. 2019.

[6] R. Shakeri, M. A. Al-Garadi, A. Badawy, A. Mohamed, T. Khattab,
A. K. Al-Ali, K. A. Harras, and M. Guizani, “Design challenges of multi-
UAV systems in cyber-physical applications: A comprehensive survey
and future directions,” IEEE Commun. Surveys Tuts., vol. 21, no. 4, pp.
3340–3385, 4th Quart. 2019.

[7] F. Meneghello, M. Calore, D. Zucchetto, M. Polese, and A. Zanella,
“IoT: Internet of threats? a survey of practical security vulnerabilities in
real IoT devices,” IEEE Internet Things J., vol. 6, no. 5, pp. 8182–8201,
May 2019.

[8] Z. Xiong, Y. Zhang, D. Niyato, P. Wang, and Z. Han, “When mobile
blockchain meets edge computing,” IEEE Commun. Mag., vol. 56, no. 8,
pp. 33–39, Aug. 2018.

[9] H. Huang, W. Kong, S. Zhou, Z. Zheng, and S. Guo, “A survey of
state-of-the-art on blockchains: Theories, modelings, and tools,” ACM
Comput. Surv., vol. 54, no. 2, pp. 1–42, Mar. 2021.

[10] B. Cao, Y. Li, L. Zhang, L. Zhang, S. Mumtaz, Z. Zhou, and M. Peng,
“When internet of things meets blockchain: Challenges in distributed
consensus,” IEEE Netw., vol. 33, no. 6, pp. 133–139, Nov. 2019.
[11] M. Samir, S. Sharafeddine, C. M. Assi, T. M. Nguyen, and A. Ghrayeb,
“UAV trajectory planning for data collection from time-constrained IoT
devices,” IEEE Trans. Wireless Commun., vol. 19, no. 1, pp. 34–46, Jan.
2020.

[12] Y. Liu, K. Liu, J. Han, L. Zhu, Z. Xiao, and X.-G. Xia, “Resource
allocation and 3-D placement for UAV-enabled energy-efﬁcient IoT
communications,” IEEE Internet Things J., vol. 8, no. 3, pp. 1322–1333,
Mar. 2021.

[13] X. Tang, W. Wang, H. He, and R. Zhang, “Energy-efﬁcient data collec-
tion for UAV-assisted IoT: Joint trajectory and resource optimization,”
Chin. J. Aeronaut., 2021, to appear.

[14] H. Lei, D. Wang, K.-H. Park, I. S. Ansari, J. Jiang, G. Pan, and M.-
S. Alouini, “Safeguarding UAV IoT communication systems against
randomly located eavesdroppers,” IEEE Internet Things J., vol. 7, no. 2,
pp. 1230–1244, Feb. 2020.

[15] B. Bera, A. K. Das, S. Garg, M. J. Piran, and M. S. Hossain, “Ac-
cess control protocol for battleﬁeld surveillance in drone-assisted IoT
environment,” IEEE Internet Things J., 2022, to appear.

[16] M. Huang, A. Liu, N. N. Xiong, and J. Wu, “A UAV-assisted ubiquitous
trust communication system in 5G and beyond networks,” IEEE J. Sel.
Areas Commun., vol. 39, no. 11, pp. 3444–3458, Nov. 2021.

14

[17] W. Y. B. Lim, S. Garg, Z. Xiong, Y. Zhang, D. Niyato, C. Leung, and
C. Miao, “UAV-assisted communication efﬁcient federated learning in
the era of the artiﬁcial intelligence of things,” IEEE Netw., vol. 35, no. 5,
pp. 188–195, Sep. 2021.

[18] R. Li, T. Song, B. Mei, H. Li, X. Cheng, and L. Sun, “Blockchain for
large-scale Internet of things data storage and protection,” IEEE Trans.
Services Comput., vol. 12, no. 5, pp. 762–771, Sep. 2019.

[19] Y. Zuo, S. Jin, and S. Zhang, “Computation ofﬂoading in untrusted
MEC-aided mobile blockchain IoT systems,” IEEE Trans. Wireless
Commun., vol. 20, no. 12, pp. 8333–8347, Dec. 2021.

[20] Z. Xiong, S. Feng, W. Wang, D. Niyato, P. Wang, and Z. Han,
“Cloud/fog computing resource management and pricing for blockchain
networks,” IEEE Internet Things J., vol. 6, no. 3, pp. 4585–4600, Jun.
2019.

[21] K. Huang, X. Zhang, Y. Mu, X. Wang, G. Yang, X. Du, F. Rezaeibagha,
Q. Xia, and M. Guizani, “Building redactable consortium blockchain for
industrial Internet-of-things,” IEEE Trans. Ind. Informat., vol. 15, no. 6,
pp. 3670–3679, Jun. 2019.

[22] J. Kang, Z. Xiong, D. Niyato, D. Ye, D. I. Kim, and J. Zhao, “Toward
secure blockchain-enabled Internet of vehicles: Optimizing consensus
management using reputation and contract theory,” IEEE Trans. Veh.
Technol., vol. 68, no. 3, pp. 2906–2920, Mar. 2019.

[23] X. Xu, H. Zhao, H. Yao, and S. Wang, “A blockchain-enabled energy-
efﬁcient data collection system for UAV-assisted IoT,” IEEE Internet
Things J., vol. 8, no. 4, pp. 2431–2443, Feb. 2021.

[24] N. Pathak, A. Mukherjee, and S. Misra, “Aerialblocks: Blockchain-
enabled UAV virtualization for industrial IoT,” IEEE Internet Things
Mag., vol. 4, no. 1, pp. 72–77, Mar. 2021.

[25] J. Li, T. Liu, D. Niyato, P. Wang, J. Li, and Z. Han, “Contract-theoretic
pricing for security deposits in sharded blockchain with internet of things
(IoT),” IEEE Internet Things J., vol. 8, no. 12, pp. 10 052–10 070, Jun.
2021.

[26] J. Cui, F. Ouyang, Z. Ying, L. Wei, and H. Zhong, “Secure and efﬁcient
data sharing among vehicles based on consortium blockchain,” IEEE
Trans. Intell. Transp. Syst., 2021, to appear.

[27] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, H. Karimipour, G. Sri-
vastava, and M. Aledhari, “Enabling drones in the Internet of things
with decentralized blockchain-based security,” IEEE Internet Things J.,
vol. 8, no. 8, pp. 6406–6415, Aug. 2021.

[28] Y. Sun, M. Peng, Y. Zhou, Y. Huang, and S. Mao, “Application of
machine learning in wireless networks: Key techniques and open issues,”
IEEE Commun. Surveys Tuts., vol. 21, no. 4, pp. 3072–3108, 4th Quart.
2019.

[29] C. H. Liu, Q. Lin, and S. Wen, “Blockchain-enabled data collection
and sharing for industrial IoT with deep reinforcement learning,” IEEE
Trans. Ind. Informat., vol. 15, no. 6, pp. 3516–3526, Jun. 2019.
[30] Y. Sun, M. Peng, and S. Mao, “Deep reinforcement learning-based mode
selection and resource management for green fog radio access networks,”
IEEE Internet Things J., vol. 6, no. 2, pp. 1960–1971, Apr. 2019.
[31] S. Rathore and J. H. Park, “A blockchain-based deep learning approach
for cyber security in next generation industrial cyber-physical systems,”
IEEE Trans. Ind. Informat., vol. 17, no. 8, pp. 5522–5532, Aug. 2021.
[32] R. Kumar, P. Kumar, R. Tripathi, G. P. Gupta, N. Kumar, and M. M. Has-
san, “A privacy-preserving-based secure framework using blockchain-
enabled deep-learning in cooperative intelligent transport system,” IEEE
Trans. Intell. Transp. Syst., 2022, to appear.

[33] J. Yun, Y. Goh, and J.-M. Chung, “DQN-based optimization framework
for secure sharded blockchain systems,” IEEE Internet Things J., vol. 8,
no. 2, pp. 708–722, Jan. 2021.

[34] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, “Blockchain and
federated learning for privacy-preserved data sharing in industrial IoT,”
IEEE Trans. Ind. Inform., vol. 16, no. 6, pp. 4177–4186, Jun. 2020.

[35] A. Asheralieva and D. Niyato, “Distributed dynamic resource manage-
ment and pricing in the IoT systems with blockchain-as-a-service and
UAV-enabled mobile edge computing,” IEEE Internet Things J., vol. 7,
no. 3, pp. 1974–1993, Mar. 2020.

[36] W. Feng, J. Wang, Y. Chen, X. Wang, N. Ge, and J. Lu, “UAV-aided
MIMO communications for 5G Internet of things,” IEEE Internet Things
J., vol. 6, no. 2, pp. 1731–1740, Apr. 2019.

[37] Z. Han, D. Niyato, W. Saad, and T. Bas¸ar, Game Theory for Next
Generation Wireless and Communication Networks. Cambridge, UK:
Cambridge University Press, 2019.

[38] R. Lowe, Y. Wu, A. Tamar, J. Harb, P. Abbeel, and I. Mordatch, “Multi-
agent actor-critic for mixed cooperative-competitive environments.” in
Conf. Neural Inf. Process. Syst. (NIPS), Los Angeles, CA, Dec. 2017,
pp. 6379–6390.

