2
2
0
2

y
a
M
5
2

]
T
G
.
s
c
[

2
v
4
6
0
4
0
.
2
0
2
2
:
v
i
X
r
a

Parallel Contests for Crowdsourcing Reviews: Existence and
Quality of Equilibria∗

Georgios Birmpas1, Lyudmila Kovalchuk2, 4, Philip Lazos4, and Roman Oliynykov3, 4

1Sapienza University of Rome
birbas@diag.uniroma1.it
2National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”
3V.N.Karazin Kharkiv National University
4IOHK
{lyudmila.kovalchuk, philip.lazos, roman.oliynykov}@iohk.io

May 27, 2022

Abstract

Part of the design of many blockchains and cryptocurrencies includes a treasury, which peri-
odically allocates collected funds to various projects that could be beneﬁcial to their ecosystem.
These projects are then voted on and selected by the users of the respective cryptocurrency. To
better inform the users’ choices, the proposals can be reviewed, in distributed fashion. Motivated
by these intricacies, we study the problem of crowdsourcing reviews for diﬀerent proposals, in
parallel. During the reviewing phase, every reviewer can select the proposals to write reviews
for, as well as the quality of each review. The quality levels follow certain very coarse com-
munity guidelines (since the review of the reviews has to be robust enough, even though it is
also crowdsourced) and can have values such as ‘excellent’ or ‘good’. Based on these scores and
the distribution of reviews, every reviewer will receive some reward for their eﬀorts.
In this
paper, we consider a simple and intuitive reward scheme and show that it always has pure Nash
equilibria, under two diﬀerent scenarios. In addition, we show that these equilibria guarantee
constant factor approximations for two natural metrics: the total quality of all reviews, as well
as the fraction of proposals that received at least one review, compared to the optimal outcome.

1

Introduction

Since the invention of Bitcoin [26] in 2009, cryptocurrencies and other blockchain platforms have
enjoyed a massive increase in popularity and market capitalization. Their development came with
a promise for decentralization; instead of having a selected group of people manage their current
operation and future direction, the users themselves should eventually express their preferences and
guide every decision. This was ﬁrst achieved just for the consensus layer. More recent platforms

∗ This work was supported by the ERC Advanced Grant 788893 AMDROMA “Algorithmic and Mechanism Design
Research in Online Markets”, and the MIUR PRIN project ALGADIMAR “Algorithms, Games, and Digital Markets”.

1

 
 
 
 
 
 
such as Tezos and Polkadot have implemented forms of on-chain governance. In addition to having
a public discourse about their development on GitHub or in internet forums, there are formal
governance processes and voting procedures to elect councils, hold referenda and adopt new changes
into the protocol’s codebase. The next piece missing in the puzzle of decentralization is how to fund
the necessary new features, with the ﬁnal decision coming directly from aggregating user preferences.
Some blockchains such as Cardano and Dash take this approach, having a publicly controlled
treasury which allocates funds to proposals generated by the community. This process requires
the careful design of many mechanisms, drawing from areas such as Crowdsourcing, Participatory
Budgeting [10] and Distortion [5]. In this work, we focus on one important part of this process:
how to provide the right incentives for the community to produce high quality reviews across many
proposals.

We provide a high level description of the relevant modules of Project Catalyst, the mechanism
used by Cardano’s treasury, as motivation for our modelling, assumptions, and results. A new
funding round takes place every 12 weeks. The latest (ongoing as of May 2022) Fund8 allocated
about $16, 000, 000 worth of ADA (Cardano’s native currency), with 5% of the total given as
rewards to reviewers. After the members of the community submit their proposals, there are 2
kinds of entities involved in the reviewing process: veteran community advisors (vCA’s), community
advisors (CA’s). The CA’s start by writing reviews for proposals. The reviews contain a written
evaluation of the proposal, as well as a numerical score. The reviews (following some ﬁltering for
profanity, plagiarism, etc) are published immediately under the CA’s pseudonym, while the true
identity of the person is usually secret. Then, the vCA’s write meta-reviews (i.e., they review the
reviews submitted by the CA’s). This evaluation is only on the quality of the review itself, not
its score or subjective opinion. The evaluation follows speciﬁc, well-known guidelines and is very
coarse: reviews can either be ‘excellent’, ‘good’ or ‘ﬁltered out’ (which are discarded). The CA’s
are then rewarded based on the quality of their reviews, as well as their choice over proposals to
review, relative to actions of the other CA’s.

The restrictions faced by Project Catalyst would apply to most blockchain solutions. Due to
the crowdsourced nature of the process and their anonymous nature any mechanism used needs to
be simple, clearly fair, and robust. Contrary to the approach possible in budget feasible mechanism
design, or the use of the revelation principle in the contest literature, it is very diﬃcult to elicit
truthful information from the voters: there is no way to charge them for not delivering on their
promise or to ﬁnely diﬀerentiate their quality of service. Additionally, requiring them to ‘lock’
a certain amount of funds prior to producing the reviews would be highly unpopular as well, in
In that regard, even users who might not
a platform whose goal is to maximize participation.
be equally skilled should have a reason to participate and develop their skill. Finally, the voters
themselves can select which proposals to write reviews for, given their motivation, expertise and
time restrictions.

1.1 Contributions

We study a problem where reviews are crowdsourced from a set of agents. These agents, based on
their skills, chose the proposals for which they will write a review, as well as the quality that their
reviews will have. In this setting, a mechanism takes the decision of the agents as an input, and
rewards them according to the quality of their eﬀorts. We stress that the agents actions are not to
report their skills or any private information (as this would be infeasible in a distributed setting, as
explained above), but the reviews themselves. Given this restriction, we are interested in the design

2

of mechanisms that always have pure Nash equilibria, while in addition, we desire these equilibria
to have good performance with respect to certain meaningful objectives.

Our contribution can be summarized as follows: We focus on a very simple mechanism for
this problem, study its equilibria under two diﬀerent scenarios, and investigate their performance
with respect to the cumulative review quality (quality objective), and the number of proposals that
acquire at least one review (coverage objective). More speciﬁcally:

• In the ﬁrst scenario (Section 3), we assume that there is only one proposal, and the agents
can choose between writing an excellent, a good, or no review at all. We prove, that our
mechanism always has pure Nash equilibria in this case, and we show that at every such
equilibrium, an 1

4 -approximation to the optimal quality objective is guaranteed.

• In the second scenario (Section 4), we assume that there are multiple proposals and every
agent can write a review for any subset of proposals they want. However, their overall ‘work’
needs to respect a time constraint, otherwise this case would reduce to the ﬁrst one. As
before, we show the existence of pure Nash equilibria, all of which provide a 1
3 -approximation
to the optimal coverage objective. However, this guarantee only holds if our mechanisms has
access to twice the budget for rewards that the optimal has. Otherwise, we show that there
are instances where the coverage achieved at any equilibrium is arbitrarily bad.

In both cases, the guarantees are provided against an optimal algorithm that knows everything
about the agents (including how capable they are at reviewing each proposal) and rewards each
of them with just enough to cover their cost. Our mechanisms never learns anything private: the
agents just write the reviews directly and share the rewards following our rules.

We want to point out that, as mentioned in the introduction, the formulation of our model is
based on real life scenarios and actual challenges that blockchain initiatives have to face. The same
goes for the motivation behind the mechanism we are focusing on, as a version of it is currently
used by Cardano’s treasury in order to resolve such problems. Our main goal is to investigate which
are the theoretical guarantees that Project Catalyst provides under the aforementioned scenarios,
and whether they match its real life performance (some examples of which are presented in Section
5). To our knowledge, the model that we consider has not been explored so far, although similar
problems have been studied in the context of proﬁt sharing games, crowdsourcing through contests,
and budget feasible mechanism design. We provide a summary of indicative related papers from
these areas, along with a discussion regarding similarities and diﬀerences in the next section.

1.2 Related Work

Our work is closely related to the area of crowdsourcing through contests [32].
In this type of
problems, there is usually an organizer that announces some tasks that need to be completed,
along with a reward for the winning contestant(s). Then the contestants submit their solutions
and the organizer decides who will be the winner(s). The goal is usually the design of mechanisms,
the stable states of which provide good performance guarantees according to the desired objective.
It is an area of problems that is also connected to the one of all-pay auctions, as indicated by
several papers [13, 14, 23, 28], while there are also some parallels with mining for proof-of-work
cryptocurrencies such as Bitcoin [7]. Although there is vast amount of works in the area, ours has
In particular, Chan et al. [12] study the
several diﬀerences with most of the related literature.
Price of Anarchy in Tullock contests in a setting that is similar to ours, with some of the main

3

diﬀerences to be that each agent can choose one contest to participate in, and the behaviour of the
agents is not aﬀected by time constraints as in our case. The problem that they consider is also
similar to the one presented in [23], although the latter regards the incomplete information setting.
For other works that consider the incomplete information setting on problems of contest design,
some relevant papers are from Chawla et al. [13], Moldovanu and Sela [24], Elkind et al. [15], and
Glazer and Hassin [17]. Besides the diﬀerence in the information setting, these works along with
other examples [30], focus on objectives that are diﬀerent than ours. One common diﬀerence is
that typically, the reward paid by the designer is subtracted from the objective, and the quality of
work produced by the participants can be measured accurately. In addition, our model also diﬀers
on how the strategy space of the agents is deﬁned, as we assume that it is discretized, given the
coarse, crowdsourced nature of the evaluations. For papers that study objectives that are more
aligned to ours, the reader should consider the works of Archak and Sundararajan [6], and Gavious
and Minchuk [16].

The problem of crowdsourcing agents (subject to budget constraints) so that certain tasks are
completed, has also been studied in the context of truthful budget feasible mechanism design,
initiated by Singer [29]. In these problems there is usually a single buyer, that wants to hire a
set of workers that are able to complete certain tasks. Each worker can perform a single task
and has a cost for it, which is her private information, while the buyer has a valuation function
deﬁned over the power set of the set of tasks. Although similar in principle to the problem that
we study, there are also some key diﬀerences on how it is approached. In particular, the workers
in this model declare their costs for performing the tasks, and the produced outcome is based on
these declarations (they are the input to the designed mechanism). In contrast, in our case the
agents can freely choose which tasks (reviews) they will complete, and each worker is not bounded
by completing just a single task. In addition, the goal in budget feasible mechanism design, is the
design of truthful (from the side of the workers) mechanisms that respect the budget constraints,
and maximize the valuation function of the buyer. In our case, the objectives for which we require
good performance are of diﬀerent nature, and they can also be aﬀected by the eﬀort that each agent
decides to spend on the tasks that she performs (i.e., the strategy space is diﬀerent). For more on
this topic, we refer the reader to the following indicative works [1–3, 18, 20, 22].

Finally, we want to mention that similar problems have been considered in the context of
proﬁt sharing games [4, 8, 9], utility games [19, 31], and project games [11, 27]. In most of the
aforementioned examples, agents select a set of projects-tasks to participate in, and then they are
rewarded according to their contribution. The goal is once again the design of mechanisms that
perform well in their stable states. Although there are several diﬀerences to the setting that we
study, i.e., strategy space of the agents, targeted objective for maximization, the way that the
utility of an agent is deﬁned (usually it is assumed that an agent’s utility depends only to the
reward that she gets, while the cost that she has for performing the task is not considered), etc,
most of the related literature studies (among others) the performance of simple mechanisms that
proportionally allocate the rewards, and thus follows an approach that is quite similar to ours.

2 Preliminaries

1, 2, 3, . . . , n
{

be the
Let V =
}
R>0 the total available budget that is distributed equally among the
set of proposals, and B
proposals. The role of the CA’s is to write reviews for the proposals. These reviews can be of

be the set of community advisors (CA’s), P =

P1, P2, P3, . . . , Pm}
{

∈

4

, with a quality q = 0 encoding that a CA did
0, 1, . . . , Q
varying quality, indicated by q
}
{
not submit a review for the respective proposal and Q being the highest possible quality.

∈ Q

=

In total, the strategy of CA i is selecting a vector qi = [qi1, qi2, . . . , qim], where qij is the quality
of the the review that she will write for a proposal j. We combine all strategy vectors to form the
strategy matrix q = (q1, q2, . . . , qn). We also use qj = [q1j, q2j, . . . , qnj] to denote the qualities of
R≥0,
the reviews that proposal j gathered from the CA’s at q. Moreover, we use function f : [Q]
to describe how much work is needed to write a review of a speciﬁc quality. We specify here that
) is a strictly increasing function on q, and f (0) = 0 as not submitting a review takes zero eﬀort.
f (
·
Note that function f is CA independent. In addition, every CA i has a private vector of positive
parameters, si = [si1, si2, . . . , sim], that describes her skill for reviewing each one of the proposals.
Therefore, f (qij)
sij can be seen as the cost that CA i has for writing a review of quality qij for
proposal j1. Note that the skills sij are only known to the CA’s. As with q, we use s for the matrix
of all skill vectors. Since the reviewing period has a ﬁxed duration T , every CA has to spend their
V :
eﬀort within this timeframe. We call this the maximum eﬀort constraint. Formally, for every i

→

·

∈

f (qij)

sij ≤

·

T.

Xj∈P

(1)

A mechanism

M
outputs a payment vector p = p(q)
More speciﬁcally, as the budget is distributed equally among the proposals, for every j
desire:

takes as input only the CA’s strategies q (without the individual skills) and
≥0. We require that the mechanism is budget feasible.
P , we

Rn

∈

∈

Given the strategy vector q, the utility of CA i is:

pij(q)

≤

B
m

= β

n

Xi=1

uM
i (q) = pi(q)

m

−

Xj=1

f (qij),

sij ·

(2)

(3)

M
i ∈ Q
uM
i (q)

that is, the payment received given the actual quality of the submitted reviews minus the eﬀort of
if, for
producing them. Given a mechanism
every CA i and possible deviation q′

, we say that q is a pure Nash equilibrium of
, we have that:

M

i (q′
uM

i, q−i).

≥

(4)

Feasible(s, B, T ) if Equation (1) and Equation (2) are satisﬁed. Moreover, we use
, in

PNE(s, B, T ) for the set of outcomes that are the pure Nash equilibria of mechanism

∈

We use q
q
addition to being feasible.

∈

M

2.1 Objectives

The ideal mechanism
would, at a pure Nash equilibrium, ensure that the ﬁnal outcome provides
a good cumulative review quality. In addition it should also motivate the CA’s to write reviews in
a way, so that the number of proposals that receive at least one review is as big as possible. We
formally deﬁne these two objectives below.

M

1For a crude analogy, imagine that f (q) is the number of words required for a review of quality q and sij is the

minutes-per-word possible by CA i for proposal j

5

Quality.

It is desirable that the total cumulative review quality is maximized:

Qual(q) =

qij.

Xi∈V Xj∈P

(5)

Coverage. Additionally, it is desirable to maximize the number of proposals that acquire at least
one review:

2.2 Price of Anarchy

Cov(q) =

P

j

(

∈

|

qij ≥

Xi∈V

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2.

1
)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(6)

To quantify the performance of a mechanism for an objective (in our case either quality or coverage),
we want to compare the outcome that is produced at its worst pure Nash equilibrium, with the
optimal possible outcome. For the optimal outcome we consider the non-strategic version of the
problem, i.e., which would be the optimal solution if we were able to purchase reviews directly,
at exactly the cost required to produce them by the corresponding agents 3. In that sense, when
someone considers the non-strategic version of the problem, the budget feasibility constraint of
Equation (2), can be translated as follows: We say that a vector q respects the budget feasibility
requirements if for every j

P , we have

∈

f (qij)

sij ·

≤

B
m

= β.

(7)

n

Xi=1

∈

nsFeasible(s, B, T ) if Equation (1) and Equation (7) are satisﬁed. With these in
We use q
hand, we can use the notion of Price of Anarchy (PoA) [21] in order to quantify the performance
for an objective Obj
of a mechanism. In particular, given V, P , and f , the PoA of mechanism
is deﬁned as:

M

PoA(

) = max

s

max
q

min
q′

Obj(q)
Obj(q′)

,

(8)

where q
PNE(s, B, T ). Intuitively, given an objective, this metric
describes the ratio between the optimal outcome, over the worst case equilibrium, for the worst
possible selection of skills s.

∈

∈

M
nsFeasible(s, B, T ), and q′

Resource Augmentation. Sometimes, as PoA results can be overly pessimistic, it might be
worth investigating if they can be improved, when a mechanism has access to additional resources
(in our case, to a larger budget).

Speciﬁcally, we would like to explore how the optimal outcome, for a speciﬁc objective, compares
with the worst possible outcome that a mechanism produces at a pure Nash equilibrium, when it
has access to a larger budget. To this end, we introduce the notion of PoAk, which is formally
deﬁned as follows:

M
nsFeasible(s, B, T ), and q⋆

PoAk(

) = max

max
q

min
q⋆

s

Obj(q)
Obj(q⋆)

PNE(s, k

B, T ), for k

∈

·

≥

where q

∈

,

1.

(9)

2Notice that the minimum quality of a review is 1.
3In the strategic setting on the other hand, there is some ineﬃciency because the agents participating in this

procedure have incentives, and thus want to maximize their rewards.

6

2.3 A Simple Proportional Mechanism

As we already mentioned, a mechanism in this setting simply takes as an input the strategy vector
q of the CA’s, and outputs a payment vector p(q). In this work, we focus on the study and the
analysis of a very simple and intuitive mechanism that basically rewards the CA’s in a proportional
manner. In particular, recall that each proposal j has an available budget β, that eventually will be
distributed to CA’s that write a review for it. In addition, as we pointed out, function f (
) deﬁnes
·
how much work a review of a speciﬁc quality needs. Our interest is in mechanisms that reward the
agents in a fair way, depending on how much they worked for their reviews. To this end, we study
the following proportional reward scheme, that also deﬁnes the mechanism that we focus on:

pi(q) =

β

·

Xj∈P

f (qij)
i∈V f (qij)

(10)

Intuitively, this is a mechanism with which we try to ‘match’ the diﬃculty of producing a review
of a speciﬁc quality, by providing a proportional reward for each case.

P

For the remainder of the paper, we refer to this mechanism as the proportional mechanism, and
we focus on the performance of its equilibria (with respect to the objectives that we deﬁned), under
two diﬀerent scenarios. From this point on-wards, we will also refer to the CA’s as agents.

3 A Single Proposal: The Quality Objective

In this section we study the proportional mechanism under the simple scenario where there is only
, for some α > 1. This set of possible
0, 1, α
one proposal, and for every i
}
qualities can be interpreted as writing no review, writing a ’good’ review, and writing an ’excellent’
review respectively. Notice that the intuition behind our formulation is that for the designer, an
excellent review is α times better than a good one. Since there is only one proposal, the interesting
question under this scenario is to explore how our mechanism performs under the quality objective.
So the ﬁrst step is to examine whether this mechanism always has pure Nash equilibria.

V , we have that qi ∈ {

∈

Before we begin, we point out that for the remainder of this section we rename the agents so

that si ≤

) to be:
si+1 for every i. Finally, to keep things simple, we choose function f (
·

f (qi) = 


0,
1,
α,

if qi = 0
if qi = 1
if qi = α

for every i

V , and α

∈

≥

2, indicating that the eﬀort for writing a review is analogous to its quality.



Theorem 1. When there is only one proposal, and for every i
then the proportional mechanism always has at least one pure Nash equilibrium.
Proof. Let iλ to be the largest i for which we have si ≤
where every agent in G0 =
i
≤
|
{
does not write a review. Now notice that the utility of an agent i

writes a good review, while every agent in Z0 =

β
i . We begin by deﬁning an initial state
i > iλ

V we have that qi ∈ {

,
0, 1, α
}

i
{

iλ

∈

}

}

G0 is

i

|

∈

f (1)
β
·
i≤iλ f (1) −

1 =

si ·

β
iλ −

0,

si ≥

P

7

(11)

1

as iλ is the largest index for which we have si ≤
G0. In addition,
the utility of the agents in Z0 is zero by deﬁnition. We will construct a pure Nash equilibrium by
repeatedly updating the agents; best responses 4 given the current set of reviews, starting from G0.
V be the sets of the agents that wrote an excellent, a good,
and no review respectively at step t. Assume for now that the utilities of the agents of every set is
non-negative, and let g(Et, Gt, Zt) be a function which reﬁnes the current strategies of the agents.
Speciﬁcally g(Et, Gt, Zt) = (Et+1, Gt+1, Zt+1) such that:

V , and Zt ⊆

i , and si ≤

Let Et ⊆

V , Gt ⊆

for every i

sλ
i

∈

• Let i′ be the agent with the minimum index in set Gt. If for i′ is beneﬁcial to convert her good
i′
. Notice that if this conversion is not beneﬁcial
review to an excellent, then Et+1 = Et ∪ {
}
for agent i′, then it is not beneﬁcial for any i
si. Moreover, observe that if agent
∈
i′ is not able to write an excellent review (although it is beneﬁcial for her) due to constraint
T , then the same holds for any agent in Gt.

Gt, as s′

i ≤

−

• Let i1 > i2 > . . . > iα−1 be the largest α

1 indices in Gt. For them, it may be the case
that a good review yields a negative utility, now that an excellent review has been added.
The reason for this is that after the conversion of one review from excellent to good, the
denominator of the reward has been increased by an additional factor of α
1. This implies
1 agents from Gt now have negative utilities, and it must be the case that
that at most α
1 of these
they are also the ones with the highest si’s. Starting from i1, we remove up to α
agents from Gt to Zt. Therefore, we obtain Gt+1, where every agent obtains a non-negative
utility from their review, as well as Zt+1 which contains every agent in Zt, along with the
newly added players that were removed from Gt.

−

−

−

), it is clear that repeated application on the inputs (Et, Gt, Zt)
By the deﬁnition of function g(
·
would eventually reach a steady state (i.e., a ﬁxpoint) (EF , GF , ZF ), such that g(EF , GF , ZF ) =
(EF , GF , ZF ). This is clear as after each application, the sets Et+1, Zt+1 are supersets of sets Et
and Zt respectively, while Gt+1 is a subset of Gt. Since the number of agents is ﬁnite this procedure
G0) (our initial
will eventually stop. We will show that the ﬁxpoint of g(
, G0, V
) starting from (
∅
·
conﬁguration) is in fact a pure Nash equilibrium. So let (Et, Gt, Zt) = gt(
G0) be the sets
, G0, V
∅
resulting from t composed applications of g, where g0 is the identity function.

\
\

Gt. Clearly, for t = 0 this is true as E0 =

Using induction, we will ﬁrst show that for every t, the agents in Et are always playing a best
response and in addition, ie < ih for any ie ∈
Et, ih ∈
∅
i.e., it does not contain any agent. For the induction hypothesis, we assume that the our claim
holds for t. Now let i′ = mini Gt be the agent who deviates to writing an excellent review instead
of a good one: by deﬁnition, this is her best response. We need to show that for the rest of the
agents in Et+1, i.e, Et+1
= Et, writing an excellent review remained a best response. To this
Et: we will prove that for her, that writing an excellent review is better than writing
end, let ie ∈
either a good review or no review at all. This will be done in two steps: ﬁrst we will show that this
holds after applying the ﬁrst part of g(
), before the set Gt is updated. At this point, we compare
·
the current utility of ie with the one of i′:

i′
\ {

}

α
·
Et+1

β
+

α

sie ≥

α
·
Et+1

β
+

α

si′

·

0,

α

·
−
i′ from the inductive hypothesis, while in addition, ie ≤

because ie ≤
si′ by the deﬁnition
of the si. Therefore, writing an excellent review is at least as good as writing nothing for agent ie,
4A best response of an agent i is the best strategy that she can follow, given the strategies of the other agents.

≥
sie ≤

Gt|
|

Gt|
|

⇒

−

· |

· |

i′

α

|

|

8

thus we just need to compare with the payoﬀ of a good review. Since writing an excellent review
is a best response for i′:

α

·

−

si′

≥

α

α

α

α

⇒

⇒

α
·
Et+1
α
·
Et+1
α
·
Et+1

· |

· |

· |

β
+
|
β
+
|
β
+

|

Gt|
|

Gt|
|

−

α

|

Et+1

· |
sie ≥

·

α

−

Gt|
|

β
Gt| −
|

+

α + 1 ≥

β
Gt| −
|

+

si′

α + 1 −

(α

1)

si′

·

−

≥

(α

−

1)

·

sie

sie,

α + 1 −

|

Et+1
· |
β
Gt| −
|

+

α

Et+1

· |

|

with the last inequality showing that writing an excellent review is a best response for ie.

All that is left to show, is that removing some good reviews will not cause any of the agents in

Et+1 to deviate to writing a good review instead. For any ie ∈
β
β
Gt| −
+
|

sie ≥

Gt|
|

· |

+

−

α

α

α

|

·

sie

α + 1 −

Et+1, we have that:

Et+1
· |
1
+

Gt| −
|

α + 1

(12)

⇒

α

· |

+

Gt|
|

≥

α

Et+1

· |

|

|

By the induction hypothesis we also have that:

α
·
Et+1
|
α
Et+1

α

β
+

α
·
Gt|
Et|
|
· |
Since at most α

−

α

sie ≥

·

α

Et|
· |

+

β
Gt| −
|

α + 1 −

sie ⇒

α

α
Et|
· |

+

Gt|
|

≥

α

Et|
· |

+

1
Gt| −
|

.

α + 1

(13)

1 players will leave Gt, we have that:

−

Et|
· |
For any α > 1 there is a unique solution to the equation

Gt| ≤
|

Gt+1
|

Et+1

+

+

· |

α

α

|

| ≤

α

Et+1

· |

+

.
Gt|
|

|

(14)

α
x

=

1
α + 1

x

−

≥

for x
α, and the order of the inequality changes from either side of the root. Combining this
with (12), (13) and (14), we show that even after some agents leave Gt, writing an excellent review
remains the best response of the agents in Et+1.

Now let us argue about the agents in Gt. For this set of agents is suﬃcient to show 5 that for
every t their utility is non-negative, thus they do not want to move to set Zt. Again, by using
induction, the statement trivially holds for set G0 by deﬁnition. By the induction hypothesis we
), the minimum indexed
know that this is also true for Gt. After the application of function g(
·
agent will write an excellent review instead of a good one, and this may make at most a
1 agents
from Gt to end up with a negative utility. However, recall that set Gt+1 is formed by moving this
set of agents to Zt (thus forming Zt+1). Therefore, set Gt+1 is a subset of Gt that only contains
agents with non-negative utility.

−

Finally, the last set that remains is Zt. We want to show that for any t, the agents in Zt will
have a non-positive utility if they try to write either an excellent, or a good review. Initially, notice

5The reason for this is that when we reach set GF , we know that either it is not beneﬁcial for any of the agents

of this set to write an excellent review, or they cannot due to constraint T .

9

that in general, an agent i that writes no reviews and at the same time has a negative utility by
writing a good review, she has also an negative utility by writing an excellent review. The reason
is that if

this implies that

α

E

· |

+

G
|
|

|

−

β

si < 0,

α
·
+

|

β
G
|
|

α

E

· |

+ 1 −

si < 0

α

·

⇒

α
(α + 1)

β
E

·
· |

α

·

−

si < 0,

+

G
|
|

|

where E, G, the sets of agents that write excellent and good reviews respectively. We proceed in
proving the statement inductively. For t = 0, no agent i
Z0 wants to write a good review by
deﬁnition, as

∈

β

iλ + 1 −

si <

si < 0

β
iλ −

for every i > iλ. Thus, they do not want to deviate to writing an excellent review as well. Now
observe that the reward to an agent decreases as t grows (as the denominator of the reward increases
each time an agent writes an excellent instead of a good review). Set Zt+1, consists of the agents
from Zt, and the agents that were removed from Gt since they did not want write a good review.
By using the inductive hypothesis and the observation that the reward at step t + 1 is smaller than
the reward at step t, it is easy to see that the agents of Zt+1 by deviating to either writing an
excellent or a good review, derive a negative utility.

Putting everything together, we know that at the ﬁxpoint (EF , GF , ZF ) all the agents are
playing their best response. Therefore, the proportional mechanism always has at least one pure
Nash equilibrium.

Remark 1. We would like to point out that the pure Nash equilibrium described by the procedure
in proof of Theorem 1 is not unique. In particular, consider the following example: Suppose that
14 , and s3 = s4 = 1
we have an instance with 4 agents and skills s1 = s2 = 1
8 .
In addition, let α = 3, B = 1, and T = 1
2 . For this instance, there are at least two pure Nash
equilibria, and the quality guarantees that they provide are diﬀerent. Initially, notice that due to
constraint T , agents 1 and 2 cannot write excellent reviews, as 3
2 . Thus, in any pure
Nash equilibrium the only available options for them is to either write a good review, or not write
a review at all. We proceed in describing two diﬀerent pure Nash equilibria.

4 + ε for some 0 < ε < 1

( 1
4 + ε) > 1

·

• For the ﬁrst one, consider the state where every agent writes a good review. The utility of
1
agents 1 and 2 is 1
4 + ε > 0, therefore this is a best response for them. Regarding agents
3 and 4, their utility is 1
8 > 0, so the only meaningful deviation for each one them
is to write an excellent review. In that case their utility becomes 3
8 , and therefore
this deviation is not proﬁtable as the utility is the same as before. We conclude that this is
a pure Nash equilibrium that provides a total quality of 4.

8 = 1

8 = 1

6 −

4 −

4 −

1

3

• For the second one, consider the state where agents 3 and 4 write an excellent review, while
agents 1 and 2 do not write a review. The only possible deviation of agents 1 and 2 is
to write a good review. In case any of them deviates to this strategy, her utility becomes
1
1
4 + ε < 0, thus there is no incentive in doing so. The utility of agents 3 and 4 at this state
7 −
is 3
8 > 0. Therefore the only meaningful deviation for each one them is to write a
6 −

8 = 1

3

10

good review. In that case, their utility becomes 1
8 . So once again, this deviation is not
proﬁtable as the utility remains the same. We conclude that this is a pure Nash equilibrium
that provides a total quality of 6.

8 = 1

4 −

1

3.1 Quality Approximation Guarantees

We proceed in studying how the proportional mechanism performs at its pure Nash equilibria with
respect to the quality objective. For this, we will ﬁrst need to explore the properties of the optimal
outcome when the constraint T does not exist. Given our assumption that an excellent review is α
times more useful than a good review, we could ﬁrst deﬁne the optimal outcome of the problem,
without the T constraint, as follows:

Deﬁnition 1 (Optimal Outcome). Given a budget of β and agents with skills s1
the optimal outcome, when constraint T does not exist, is:

s2

≤

sn,

≤ · · · ≤

maximize α
subject to

E
+
· |
|
i∈E α

·

G
|
|
si +

i∈G si≤

β,

P
where E and G are the sets of agents that write excellent and good reviews respectively.

P

We continue with the following lemma, that shows how the optimal outcome can be computed.

Lemma 1. The optimal outcome can be found using the following greedy algorithm:

• Starting from s1, add excellent reviews until no more can be added without exceeding the

budget.

• Fill the remaining budget with good reviews.

Proof. Assume that sets E⋆ and G⋆ are the sets of agents that write excellent and good reviews
at the optimal solution respectively. Let j′ = mini G and i′ = maxi E. Now suppose that j′ < i′.
Then, this would imply that by exchanging i′ and j′, a solution of the same value would be produced,
but with a lower cost, as

α

·

Xi∈E⋆\{i′}

si + α

si′ +

·

Xi∈G⋆\{j′}

si −

sj′

α

·

≤

Xi∈E⋆\{i′}

si + α

sj′ +

·

Xi∈G⋆\{j′}

si −

si′.

Repeated applications of the same procedure, either will lead to a contradiction (as the cost of the
solution decreases each time), or will eventually give us the greedy solution.

Remark 2. Notice that the same algorithm computes the optimal outcome even if there is a
constraint T by following the same arguments.

We can now use the previous lemma, in order to upper bound the value of the optimal solution,

when the constraint T is not present.

Lemma 2. For any set of skills
where i⋆ is the largest index such that

s1, . . . , sn}
{
i⋆

, the value of the optimal solution is at most α

(i⋆ + 1),

·

α

si ≤

·

β.

Xi=1

11

Proof. Initially notice that the value of optimal solution is always the same, regardless of the way
it is computed. Consider the optimal solution produced by the algorithm described above, and
let Eg and Gg to be the sets of agents that write excellent and good reviews in this solution
respectively. Now suppose that
and
j′, j′ + 1, . . . , j′ + α
Gg

∪ {
represent a solution with the same value but lower cost as:

α and let j′ = mini Gg. Then, the sets Eg

Gg
|

| ≥

j′

}

\ {

1
}

−

si + αsj′ +

α

·

Xi∈Eg

Xi∈Gg

si −

sj′

−

sj′+1

−

. . . sj′+α−1 = α

α

≤

·

·

Xi∈Eg

Xi∈Eg

si +

Xi∈Gg

α

si −

·

sj′

−

si +

si.

Xi∈Gg

j′+α−1

si

Xi=j′

Notice that this is a contradiction due to how the greedy algorithm works. Therefore, there are at
1 good reviews in an optimal solution. Thus, we can conclude that the optimal solution
most α
produced by the greedy algorithm is of the form Eg =
,
}
where j

i + 1, i + 2, . . . , i + j
{

1, 2, . . . , i⋆
{

, Gg =
}

−

1.

α

≤

−

·

> α, and

Remark 3. Notice that if i⋆ = 0, which means that for every i we have that α
si > β, this implies
that the value of the optimal solution is at most α, something that is consistent with the statement
of Lemma 2. To see this, observe that if the optimal solution’s value was greater than α, since
it is not possible for any agent to write an excellent review (due to the budget constraint), this
value would be attained by agents that write reviews of good quality. The latter would mean that
G⋆
|

|
We proceed with the following theorem where we bound the PoA of the proportional mechanism,
with respect of the quality objective. At several steps throughout the proof, we compare the quality
achieved at a pure Nash equilibrium in PNE(s, B, T ), with the quality of the optimal solution when
constraint T does not exist. To avoid confusion, for any instance, we deﬁne OPT to be the value of
optimal solution of the instance when the T constraint is not present, and OPTT the value of the
optimal solution of the instance when the T constraint exists. Obviously, OPTT

β. This implies that α

mini∈G⋆ si ≤

β, a contradiction.

i∈G⋆ si ≤

OPT.

P

·

≤

Theorem 2. The PoA of the proportional mechanism when there is a single proposal and for every
i

, is at most 4 (up to an additive factor of at most 6
0, 1, α
}

V , we have qi ∈ {

α).

∈

·

Proof. Consider a pure Nash equilibrium of quality x, and let i∗ be the largest index such that
β 6, if we do not take into account the constraint T . We begin the proof by considering

i⋆
i=1 α

si ≤

·

two special cases separately:
P

• If x = 1, then exactly one good review is written at the pure Nash equilibrium. Suppose
that for OPTT, three or more reviews are written. Since OPTT has to respect the budget, it
must be that there exist two agents k1, k2 writing a review for OPTT such that sk1, sk2 < β/2.
One of these two is not writing any review at the pure Nash equilibrium, and would beneﬁt
by deviating to a good review, getting reward β/2, something that leads to a contradiction.
Therefore, in this case the value of OPTT is at most 2
α, and thus the approximation guarantee
is covered by the additive factor.

·

6In case i⋆ = 0, then Remark 3 applies and we refer the reader to Proposition 1 for the respective approximation

guarantees.

12

• If 0 < i⋆ < 6, then Lemma 2 implies that OPTT

covered by the additive factor.

α

·

≤

(i⋆ + 1)

6

·

≤

α, which once again is

For the rest of the proof, we will consider the case where 2

6. Suppose that the
i⋆
quality of the pure Nah equilibrium is x < α·i⋆
4 does
not write an excellent review at this pure Nash equilibrium. So say that i′ is the minimum indexed
such agent. The latter means that every agent i < i′ writes an excellent review at the pure Nash
equilibrium that we consider. By Lemma 2, we know that

4 . This implies that at least one agent i

≤

≥

≤

x and i⋆

i⋆

Xi=1

α

si ≤

·

β

⇒

⇒

⇒

i⋆

si < β

α

·

Xi=i⋆/4
α

si⋆/4

·

si′ <

3
4 ·
β

α

·

(cid:18)

4
3 ·

(cid:19)
i⋆ ,

i⋆

< β

(15)

where the last two inequalities hold as the si’s are positive and increasing in i. We will break the
proof into cases that depend on how much agent i′ is aﬀected by the constraint T .

·

si′

T . We split this case into two sub-cases. In the ﬁrst, agent i′ does not write
Case 1: α
a review at the pure Nash equilibrium, while in the second, she writes a good review. In either
case, we show that deviating to writing an excellent review increases agent i′’s utility, leading to a
contradiction.

≤

Case 1a: Suppose that agent i′ does not write a review at the pure Nash equilibrium. It is easy
to see that in this case, by deviating to writing a review of good quality, she would attain a utility
of

β

x + 1 −

si′

≥

β
α·i⋆
4 + 1 −

si′ =

α

β

4
·
i⋆ + 4 −

·

si′.

By (15), this deviation is beneﬁcial if the following inequality holds:

which is true for α
≥
for agent i′, leading to a contradiction.

≥

α
2 and i⋆

·

β

4
·
i⋆ + 4 ≥

4
3 ·

α

β

·

i⋆ ⇒

α

·

1
i⋆ + 4 ≥

1
3 ·

α

1

·

i⋆ ,

1. Therefore, writing a good review would yield positive utility

Case 1b: Now, assume that agent i′ writes a good review at the pure Nash equilibrium. This
implies that her utility for deviating to writing an excellent review would be lower:

β
x −

si′

≥

x

α

β

·
1 + α −

α

si′

·

(α

1)

si′

·

−

≥

β

⇒

α
1 + α −

1
x

(cid:19)

x

· (cid:18)

−
1
Let’s call f (x) = α
x the function appearing at the right hand side of inequality (16). By
straightforward calculus, one can show that it is strictly increasing and then strictly decreasing for
x > 0, with the inﬂection point at x = √α + 1. In addition, for α

6 we have that

x−1+α −

2 and i⋆

−

.

(16)

√a + 1

α

i⋆
·
4 ⇒

≤

α

f

≥

(cid:18)

f

√a + 1

(cid:1)

(cid:0)
13

≥

≥
i⋆

·
4

(cid:19)

(17)

and that

f (2)

f

≥

α

i⋆

·
4

.

(cid:19)

(cid:18)

(18)

These inequalities are more succinctly presented in Figure 1.

f (x)

α
x−1+α −

1
x

0

1

2

√a + 1

x

i⋆/4

α

·

Figure 1: The behaviour of f (x) = α

x−1+α −

By (15), it should also hold that:

1
x

α

1
a·i⋆
4

= f

a

i⋆
·
4

,

(cid:19)

(cid:18)

(α

1)

−

4
3 ·

·

α

β

·

i⋆ ≥

β

α
1 + α −

1
x

(α

1)

1

4
3 ·

x

−

· (cid:18)
i⋆/4. Note that this inequality cannot hold for any α

1 + α −

(cid:19) ⇒

−

·

·

α

i⋆ ≥

α·i⋆
4 −

·

6.
substituting x for α
Additionally, by (17), (18) and the previous monotonicity observations, this inequality cannot hold
for any 2
6 (i.e. at least 6 excellent
reviews are written in the optimal outcome), agent i′ would have a proﬁtable deviation by writing
an excellent review, leading to a contradiction.

i⋆/4. Concluding, as long as x

2 and i⋆

≥

≥

≥

≤

≤

≥

α

x

·

2 and i⋆

Therefore, we have that:

α

i⋆

.

·
4

x

≥

By Lemma 2, we know that the optimal quality that can be achieved when T does not exist is at

14

most α

·

(i⋆ + 1), leading to:

α

i⋆
·
4 ⇒

x

≥

⇒

⇒

x

x

x

≥

≥

≥

α
4

−

(i⋆ + 1)

α

·

OPT

4

4 −

OPTT

4 −

α
4
α
4

.

Case 2:
or good review respectively at OPTT. Notice set E contains only agents i < i′.

si′. We split the agents into E and G, based on if they write an excellent

T < α

si′

≤

·

E

OPTT
2 . By the deﬁnition of i′ we know that every i < i′ writes an excellent review
Case 2a: α
at the pure Nash equilibrium that we consider. The latter implies a implies a half-approximation
of OPTT. In case i′ = 1, then again, by the deﬁnition of i′ we get that E =
. Due to the case that
∅
currently consider, this means that the value of OPTT is 0.

| ≥

·|

| ≥

G
|

OPTT
2 . Assume that at the pure Nash equilibrium, a total quality of x < |G|
Case 2b:
2
G to contain half of the agents in G, and in particular the ones with the
is achieved. Let G1
⊆
smallest indices (thus, the ones with the smallest si’s). Notice that at least some i′′
G1 does not
write either a good review or an excellent at the pure Nash equilibrium, as otherwise we would
have that x
i∈E α

|G|
2 . Let il = maxi G1. Since

β, it is easy to see that

si +

∈

≥

P
i∈E α
G
P
|
|
as otherwise the sum of the skills of the agents in G
G1, would exceed the available budget. So the
only thing that remains to show, is that agent i′′ is better oﬀ by writing a good review, something
that will lead to contradiction. The latter, is true as

sil <

(19)

si′′

P
2

(β

≤

−

\

·

,

·

·

i∈G si ≤
si)

where last inequality holds from Equation (19).

ui′′ =

β

x + 1 −

si′′

≥

2

β
·
G
|
|

−

si′′ > 0,

(20)

Case 3: T < si′: Once again, we split the agents into E and G, based on if they write an excellent
i′ writes a review at OPTT due to
or good review respectively at OPTT. Now notice that no agent i
constraint T , while by the deﬁnition of i′, every agent i < i′ writes an excellent review at the pure
Nash equilibrium that we consider. The latter implies an 1-approximation of OPTT. In case i′ = 1,
then for every agent i

i. Therefore, we get that the value of OPTT is 0.

≥

s

′

= i′ we have that si ≥

Remark 4. Notice that the additive factor that appears on the approximation guarantee of the
pure Nash equilibrium, captures some corner cases where the appearance of parameter α cannot
be avoided. An easy example that demonstrates this is the following: Consider an instance where
there is only one agent with skill si = 1
α , B = 1, and T = 1 + ε for some ε > 0. The utility of this
agent when she writes a good review is 1
α
α = 0, her utility when
1 −
she writes an excellent review. The ﬁrst state describes a pure Nash equilibrium of quality 1, while
the second state describes the optimal solution of quality α.

α > 0, which is more than α

α −

1

15

6
We would like to point out that if one considers the special version of this case of the problem,
where the available strategies for the agents are writing reviews of qualities 0 and 1 7, then a tight
PoA bound of 2 can be guaranteed. The existence of pure Nash equilibria for this case can directly
be derived by the ﬁrst paragraph of the proof of Theorem 1 8. It is also clear that the optimal
1, . . . , iµ
to write a good
quality in this version of the problem can be achieved by letting agents
{
review, where iµ is the largest index for which
T . The latter implies that
the quality of optimal outcome is iµ.

P
Proposition 1. The PoA of the proportional mechanism when there is a single proposal and for
every i

iµ
i=1 si ≤

β, and sµ

i ≤

}

V , we have qi ∈ {

, is 2. Moreover, this is tight.
0, 1
}

∈

Proof. Consider a pure Nash equilibrium and suppose for contradiction that its quality is x < iµ
2 .
iµ
2 does not write a review at this pure Nash equilibrium.
This implies that at least one agent i
Say that i′ is the minimum indexed such agent. From the previous discussion, we know that

≤

iµ

Xi=1

β

si ≤

⇒

⇒

⇒

iµ

si < β

iµ

< β

Xi=iµ/2
siµ/2

si′ <

1
2 ·
(cid:18)
1
2 ·

(cid:19)
β
iµ ,

(21)

where the last two inequalities hold as the si’s are positive and increasing in i. Since agent i′ does
not write a review at the pure Nash equilibrium, it is easy to see that in this case that by deviating
to writing a review of good quality, she would attain a utility of

β

x + 1 −

si′

β

≥

iµ
2 + 1 −

si′ =

β
2
iµ + 2 −

·

si′.

By (21), this deviation is beneﬁcial if the following inequality holds:

β
2
iµ + 2 ≥

·

1
2 ·

β
iµ ⇒

1

iµ + 2 ≥

1
2 ·

1
iµ ,

which is true for any iµ
agent i′, leading to a contradiction.

≥

2 9. Therefore, writing a good review would yield positive utility for

Regarding tightness, consider an instance with 2 agents, skills s1 = 0.4, and s2 = 0.6, and
ﬁnally B = T = 1. It is easy to see that both of them participate in the optimal outcome, which
has a total quality of 2, while only one of the can write a review at a pure Nash equilibrium, since
otherwise agent 2 ends up with a negative utility as her reward is 1
2 in that case. This implies a
quality of 1 in any pure Nash equilibrium.

7A more general version of this case, where there are more that one proposals, is presented in the next section.
8For an alternative proof, we refer the reader to Theorem 3.
9Notice that if iµ = 1, then this implies that the optimal solution provides a total quality of 1. It is straightforward
to see that any pure Nash equilibrium provides a total quality of either 1 or 0. The latter case captures the scenario
where an agent is indiﬀerent between writing a review or not, as in both cases her utility is 0. Although this implies
an inﬁnite PoA if we measure the performance of the equilibrium according to the deﬁnition, as this is the only case
that something like that can happen, we view it as having an additive loss of 1.

16

4 Multiple Proposals: The Coverage Objective

In this section we go beyond the case of the single proposal, and we turn our attention on the
performance of the proportional mechanism with respect to the coverage objective. Speciﬁcally, we
are interested in the number of proposals that end up with at least one review at an equilibrium
state of the proportional mechanism, in comparison with the respective optimal solution. Since
our priority is to maximize the number of proposals that are covered with at least one review, the
evaluation of the quality of these reviews takes a back seat. This leads to a version of the problem
, i.e., an agent i, either writes a review for a proposal j, or she doesn’t, while for
0, 1
where qij ∈ {
}
) we have
the eﬀort function f (
·

f (qi) =

0,
1,

(

if qi = 0
if qi = 1

V . We begin by exploring the existence of pure Nash equilibria under this setting.

for every i
Theorem 3. When there are multiple proposals and qij ∈ {
mechanism always has a pure Nash equilibrium.

∈

0, 1
}

for every i, j, then the proportional

Proof. Our goal is to prove that the procedure of writing reviews under the proportional reward
scheme, can be seen as a game that admits a potential function. We start by associating each of
) : qj
the proposals Pj, with a function Φj(
·
Φj(qj) = β

R. More speciﬁcally, we deﬁne Φj(
) as follows:
·

si,

→

Hk −

·

Xi∈K

⊆

V , with

where K
K
|
Harmonic number deﬁned as Hk = 1 + 1

+ 1
k .
· · ·
i , qj
Now consider the strategy vectors qj = (qj
−i), and

2 +

|

= k, is the set of agents for which we have qj

strategy from qj

i to

qj = (
−i), where agent i changes her
qj
i , while the strategies of the rest of the agents remain the same. We have that:
b

i , qj
qj

i = 1 in qj, and Hk is the k-th

b

Φj(qj

i , qj

−i)

−

Φj(

i , qj
qj

which implies that,Φj(qj
every Pj and Φj.

i , qj

−i)

−

b
i , qj
qj

Φj(

We proceed by deﬁning function Φ(q) =

b

that:

si,
β
k+1 ,

β
k −
−i) = 
si −

0,
i , qj
−i) = ui(qj


−i)

−

ui(

b
if qj
i = 1,
if qj
i = 0,
if qj
qj
i =
i
i , qj
qj

b

qj
i = 0
qj
i = 1
b

b

−i). Observe that this holds for

m
j=1 Φj(qj). Notice that for every reviewer i, we have

b

Φ(qi, q−i)

−

Φ(

qi, q−i) =

b

=

[Φj(qj

i , qj

−i)

Φj(

i , qj
qj

−i)]

−

Xj=1
m

[ui(qj

i , qj

−i)

Xj=1

b
i , qj
qj

−i)]

ui(

−

= ui(qi, q−i)

ui(

b
qi, q−i).

−
) is an exact potential function and thus, there always exists at least one
Therefore, function Φ(
·
pure Nash equilibrium [25].

b

P

m

17

4.1 Coverage Approximation Guarantees

In this section, we explore the performance of the proportional mechanism with respect to the
coverage objective. Unfortunately, as the following lemma shows, the guarantees that it provides
at a pure Nash equilibrium can be as bad n-approximate to the optimal coverage outcome.

Proposition 2. The PoA obtained by the proportional mechanism can be as bad as n.

Proof. Suppose that we have an instance with n agents and n proposals, where the available budget
is B = n, and the maximum eﬀort constraint is T = 1. In addition, let every agent i to have a very
small skill parameter for the ﬁrst proposal, i.e., si1 = ε > 0, and a skill parameter of 1 for the rest
of the proposals, i.e., sij = 1 for Pj ∈
Initially, notice that in any feasible q, each agent writes at most one review, as otherwise the
maximum eﬀort constraint is violated. Thus, the optimal solution with respect to the coverage
objective is produced when each agent writes one review, and at the same time each proposal has
exactly one review. The aforementioned family of assignments guarantees a coverage of n.

P1.

P

\

Let us now turn our attention to the proportional mechanism. Recall that the available budget
is distributed equally among the proposals, so for the described instance we have that β = 1 for any
P . Consider the case where every agent writes a review for the ﬁrst proposal. The derived
Pj ∈
utility of every agent i is ui = 1
ε. It is easy to see that this is a pure Nash equilibrium, as
every agent can write at most one review, and if any agent tries to deviate to either not writing
a review, or writing a review for a diﬀerent proposal, then her utility becomes zero. Notice that
for this speciﬁc example, the described assignment is the only possible pure Nash equilibrium, as if
there are less than n reviews for the ﬁrst proposal, this implies that there is an agent i that has not
written a review for it. Thus, by playing qi1 = 1 and qij = 0 for j
= 1, she achieves a higher utility.
Therefore, there is only one pure Nash equilibrium on this instance and the coverage guarantee
that it provides is 1.

n −

As the result of Proposition 2 is negative, the next natural direction would be to explore the
performance of the proportional mechanism under augmented resources. Our goal, is to investigate
whether by increasing the budget, the proportional mechanism can achieve at its equilibrium states,
a total coverage that is identical to the coverage of the optimal (under the original budget) solution.

Proposition 3. There are instances where the the optimal coverage cannot be achieved at a pure
Nash equilibrium, no matter the increase in the budget.

Proof. Suppose that we have 2 agents and 3 proposals. The skill parameters of both the agents
are as follows: si1 = si2 = ε, for some 0 < ε < 1
. Moreover, let the
1, 2
}
total budget be B = 3
1, and notice that this implies that the β is the available
·
). Finally let T = 1. It is easy to see that in the optimal coverage
1, 2, 3
reward for every j
}
solution, every proposal ends up with one review, i.e., one of the agents writes a review for the ﬁrst
two proposals, while the other writes for the third one. Thus, we achieve a total coverage of 3.

2 , and s3 = 1, for i

β, for some β

∈ {

∈ {

≥

Now consider an outcome where both agents write a one review for each of the ﬁrst two pro-
posals. Thus, their utilities are ui = 2
. It is easy
1, 2
ε) = β
}
to conﬁrm that this is a pure Nash equilibrium. Since the utility of both agents is positive in
this allocation, the only possible options for both them are either to write a review for one of the
ﬁrst two proposals (something that leads to a lower utility), or to write just one review for the

ε > 0, for every i

( β
2 −

∈ {

−

2

·

·

18

6
·

2

2

−

−

1
2 < β

third proposal (as constraint T dictates). The latter deviation provides an agent with a utility of
β

1 = β
By the above discussion we get that the aforementioned pure Nash equilibrium, only two out
10. The statement follows from
1, so the overall available budget does not aﬀect the coverage

of three proposals are covered, something that implies a PoA= 3
2
the fact that this holds for any β
guarantee that a pure Nash equilibrium can achieve.

≥

−

ε.

·

We conclude this section with a positive result. Although, as Proposition 3 demonstrates, the
optimal coverage cannot be achieved at a pure Nash equilibrium regardless of the increase in the
budget, we show that doubling the budget is enough for a PoA of 3 to be guaranteed.

Theorem 4. The proportional mechanism guarantees a PoA2 = 3. Moreover, this result is tight.

⊆

Proof. Let cOPT(B) to be the optimal coverage solution of an instance under budget B. Assume
P is covered with at least one review, and let q to be a
that at cOPT(B), a set of proposals K
strategy vector that deﬁnes a pure Nash equilibrium under budget 2
P , to be the
set of proposals that are covered at cOPT(B) and not at the pure Nash equilibrium deﬁned by q.
V as the set of agents that at cOPT(B), write at least one review for a
In addition, deﬁne D
non-empty set of proposals in S. Finally, let Aopt
S be the set of proposals for which an agent
i

D writes a review in cOPT(B).
Now for the remainder of the proof, it is crucial to deﬁne set D⋆

D, which will be a suﬃciently
small subset of agents, the reviews of which in the optimal solution cOPT(B), cover every proposal
in S with at least one review. We build set D⋆ according to the following greedy procedure.

B. Let S

i ⊆

⊆

⊆

⊆

∈

·

Procedure 1 Greedy Set Construction (D, S)
1: D⋆ =
2: while S⋆
3:

∅
= S do
h = arg maxi∈D\D⋆

; S⋆ =
∅

(S
of proposals in S that are currently uncovered. Break ties arbitrarily.

i ∩

\

S⋆)
|

Aopt
|

// Find the agent from D, that covers the highest number

S⋆ = S⋆
∪
D⋆ = D⋆
∪ {

4:
5:
6: return D⋆

Aopt
h
h
}

S
|

Our main goal is to ﬁnd a subset of agents in D, the cardinality of which is at most

, and by
|
considering the reviews that this subset writes in the optimal solution, every proposal in S can be
covered with at least on review. To this end, we start by deﬁning set S⋆ as the set of the currently
covered proposals (which is empty in the beginning). We then proceed by considering set D⋆ which
is also initially empty. At each step we add to it the agent from set D that covers (according to the
optimal solution) the highest number of proposals in S that are currently uncovered (we break the
ties arbitrarily), and we update set S⋆ accordingly. The procedure stops when S⋆ becomes equal
to S. It is easy to see that this will happen after at most
steps, as otherwise this would mean
where an agent that covered zero non-covered proposals was added to
that there is a step j
set D⋆. However, since at each step we add the agent that covers the highest number of uncovered
proposals, this would imply that at every step j′ > j, the agent that is added to set D⋆ does
not contribute to the coverage of set S, and thus that set D cannot cover set S, a contradiction.

S
|

≤ |

S

|

|

10Notice that this is actually the only pure Nash equilibrium of this instance.

19

6
D⋆
|

| ≤ |

.
|

Therefore, since at each step, an agent is added, and the procedure takes at most
that

S

steps, we get

S
|

|

We proceed by exploring some structural properties of the the pure Nash equilibrium q. Initially,
D⋆ writes at least one review at the pure Nash equilibrium q, as

notice that every agent i
∈
otherwise, by writing reviews for the proposals in Aopt

she would end up with a utility of,

i

ui =

β

2

·

−

sij ≥

Xj∈Aopt

i

Xj∈Aopt

i

Xj∈Aopt

i

β

2

·

−

Xj∈Aopt

i

β > 0,

where the ﬁrst inequality holds due to the fact that for each j
otherwise cOPT(B) would not be budget feasible.

From the previous argument, we get that every agent i

deﬁned by q, writes at least one review for a subset of proposals in K
this subset of proposals Apne
gathers at the pure Nash equilibrium. For every i
gives us the following:

∈

i

. Finally, let nj to be the number of reviews that a proposal j

Aopt
i

∈

β, as

, we have that sij ≤
D⋆ in the pure Nash equilibrium
D⋆, name
S
K
D⋆, the deﬁnition of the pure Nash equilibrium

S. For every i

∈

∈

∈

\

\

(22)

(23)

2
β
·
nj −

sij

! ≥

(2

β

·

−

sij) .

Xj∈Aopt

i

Xj∈Apne

i

At the same time, we have

sij >

sij −

min
j∈Aopt
i

sij,

Xj∈Apne
as otherwise, agent i would be able to write a review for every j
argminj∈Aopt
tradicts the pure Nash equilibrium assumption.

, plus a review for
sij, without violating T . This however would improve utility, something that con-

Xj∈Aopt

Apne
i

∈

i

i

i

By combining equations (22) and (23), we get

β
2
·
nj −

min
j∈Aopt
i

Xj∈Apne

i

sij >

2

β

·

⇒

i

Xj∈Aopt
D⋆, we have

Since this holds for every agent i

∈

β
2
·
nj

>

Xj∈Apne

i

β

2

·

−

min
j∈Aopt
i

sij.

Xj∈Aopt

i

Now notice that,

2
β
·
nj

>

Xi∈D⋆

Xj∈Apne

i

Xi∈D⋆

Xj∈Aopt

i

β

2

·

−

sij.

min
j∈Aopt
i

Xi∈D⋆

2
β
·
nj ≤

Xi∈V Xj∈Apne

i

2
β
·
nj

= 2

β

·

K

· |

S

,
|

\

Xi∈D⋆

Xj∈Apne

i

D⋆, while the the sum in
where the ﬁrst inequality holds because we sum over all agents in V
the right hand side of the inequality also represents the sum of the payments that the agents derive
for each proposal, which is equal to 2

β (per proposal). Additionally,

⊇

·

20

 
β

2

·

β

2

·

S

· |

,
|

≥

Xi∈D⋆

Xj∈Aopt

i

as we know that the agents in D⋆, cover every proposal in S with at least one review in cOPT(B).
Therefore, we derive that,

β

2

·

K

· |

S

|

\

> 2

β

S

· |

·

| −

min
j∈Aopt
i

sij ⇒

Xi∈D⋆

⇒

min
j∈Aopt
i

min
j∈Aopt
i

sij > 2

sij > 2

β

β

·

·

·

·

S
(
|

K

| − |

S

)
|

\

(2

S

· |

K

| − |

).
|

Xi∈D⋆

Xi∈D⋆

On the other hand, we have that

min
j∈Aopt
i

Xi∈D⋆

D⋆

sij ≤ |
S

≤ |

max
i∈D⋆

min
j∈Aopt
i

| ·

sij

max
i∈D⋆

min
j∈Aopt
i

sij

β.

| ·

| ·

The statement follows from the fact that if

S

≤ |

β

2

·

·

(2

S

· |

K

| − |

) >
|

S
|

| ·

β

S

⇐⇒ |

K
2
|
3

|

,

>

|

then we have a contradiction.

·

k

k

≥

1 agents and 3

L1 has sij = ε for j

2. The total budget is 3

Regarding tightness, consider the following example: there are 3

1
1, thus β = 1 for each proposal, and ﬁnally
proposals, where k
1 and k respectively, while
T = 1. The agents are split in sets L1 and L2, with cardinalities 2
1 respectively. Every agent
the proposals are split in sets F1 and F2, with cardinalities k and 2
L2 has
i
sij = 1 for j
F2. Under this conﬁguration, it is clear that the agents of L2
cannot write more than one reviews, as T = 1. Now it is easy to see that at cOPT(B) every agent in
L1 writes one review for just one proposal in F2 so that every proposal in F2 has exactly one review,
while every agent in L2 writes one review for just one proposal in F1 so that every proposal in F1,
once again has exactly one review. Therefore, every proposal is covered in the optimal solution.

−
−
F2. On the other hand, every agent i

∈
F1, and sij = 3 for j

F1, and sij = 1 for j

k
k

−

−

−

∈

∈

∈

∈

∈

·
·

k

·

·

·

Now consider the strategy vector q (under budget 2

B) that deﬁnes the following allocation:
every agent in L1 writes one review for every proposal in F1, while every agent in L2 does not write
a review. Initially, notice that for the agents of L2. there is no proﬁtable deviation as they cannot
write a review for the proposals in F2, and if they try to write a review for a proposal in F1, their
utility is 2
1 < 0. As for the agents of L1, their only meaningful deviation is to write one review
ε = ui, where
k
for a proposal in F2, but this provides them with a utility of 2
2·k−1 −
B 11, that is also
ui is their current one. Thus, this is a pure Nash equilibrium under budget 2
·
1
3 -approximate to cOPT(B) 12.
11It is easy to conﬁrm that this is also a pure Nash equilibrium under budget B.
12Notice that if we further increase the budget, this is no longer a pure Nash equilibrium.

1 < 2·k

2·k −

−

·

21

5 Performance with Real Data

A commercially important application of the previous model is Project Catalyst, which was outlined
in the introduction of this work (and additional information can be found here). Following our
model, the community advisors (CA) who write reviews for the proposals take up the role of
the reviewers. Each of them can write as many reviews as they like, for any community generated
proposal they are prefer. These reviews are then reviewed again by the veteran community advisors
(vCA) and are assigned a grade that can be either ‘excellent’, ‘good’ or ‘ﬁltered out’, for reviews
found to be below the minimum quality threshold. The CA’s know the public guidelines that
deﬁne the requirements of the diﬀerent qualities and should, at the time of submission, have a good
estimate of the grade that their review could get. According the terminology of our model, the
parameter α = 3 is used to increase the rewards given to excellent reviews (i.e. a ‘good’ review
contributes 1 to the quality and an excellent contributes 3). Following the reviewing phase, the
voters can cast a ‘Yes’, ‘No’ or ‘Abstain’ vote for each proposal, with every vote having weight
proportional to the users’ stake in ADA, the currency used by Cardano. More details about the
voting process (and it’s cryptographic guarantees) can be found in [33].

We present the data from Fund7, the latest completed (as of May 2022) round of funding. The

data set is publicly available here. From the total amount of $8,000,000:

• $6,400,000 were rewarded to funded proposals.

• $320,000, spread across the 712 candidate proposals, were used to pay for CA reviews.

• $80,000 were awarded to vCA’s for reviewing the CA reviews.

There were 541 CA’s who submitted at least one (possibly ‘ﬁltered out’) review. In total, they
produced:

• 357 ‘excellent’ reviews.

• 4,832 ‘good’ reviews.

• 3,971 ‘ﬁltered Out’ reviews (including many that were duplicates, algorithmically generated

or empty).

On average, there were 5.5 reviews per proposal, with total quality 6.3.

6 Conclusion and Future Directions

Our work leaves several intriguing open questions. In particular, it would be interesting to further
explore both of the presented scenarios, and see whether our results can be extended when the set
of the available strategies is richer. Although it might initially seem that this is the case, even
answering the question of whether pure Nash equilibria exist in such cases seems challenging, as
the potential function that we provide in Section 4 no longer works, and a proper modiﬁcation is
not trivial. In addition, for the case of multiple proposals, a natural direction would be to examine
if our mechanism can also achieve some guarantees with respect to the quality objective as well,
and in general, whether these two objectives are compatible-can be achieved (at some degree) at
the same time. Finally, it would be interesting to see whether our mechanism is the optimal one
under this setting, or if it is possible to provide better guarantees by applying diﬀerent payment
schemes.

22

References

[1] G. Amanatidis, G. Birmpas, and E. Markakis. Coverage, matching, and beyond: New results
on budgeted mechanism design. In Y. Cai and A. Vetta, editors, Web and Internet Economics
- 12th International Conference, WINE 2016, Montreal, Canada, December 11-14, 2016, Pro-
ceedings, volume 10123 of Lecture Notes in Computer Science, pages 414–428. Springer, 2016.

[2] G. Amanatidis, G. Birmpas, and E. Markakis. On budget-feasible mechanism design for
In N. R. Devanur and P. Lu, editors, Web and Internet
symmetric submodular objectives.
Economics - 13th International Conference, WINE 2017, Bangalore, India, December 17-20,
2017, Proceedings, volume 10660 of Lecture Notes in Computer Science, pages 1–15. Springer,
2017.

[3] N. Anari, G. Goel, and A. Nikzad. Mechanism design for crowdsourcing: An optimal 1-1/e
competitive budget-feasible mechanism for large markets. In 55th IEEE Annual Symposium
on Foundations of Computer Science, FOCS 2014, Philadelphia, PA, USA, October 18-21,
2014, pages 266–275. IEEE Computer Society, 2014.

[4] E. Anshelevich and J. Postl. Proﬁt sharing with thresholds and non-monotone player utilities.

Theory Comput. Syst., 59(4):563–580, 2016.

[5] E. Anshelevich, A. Filos-Ratsikas, N. Shah, and A. A. Voudouris. Distortion in social choice
problems: The ﬁrst 15 years and beyond. In Z. Zhou, editor, Proceedings of the Thirtieth In-
ternational Joint Conference on Artiﬁcial Intelligence, IJCAI 2021, Virtual Event / Montreal,
Canada, 19-27 August 2021, pages 4294–4301. ijcai.org, 2021.

[6] N. Archak and A. Sundararajan. Optimal design of crowdsourcing contests.

In J. F. N.
Jr. and W. L. Currie, editors, Proceedings of the International Conference on Information
Systems, ICIS 2009, Phoenix, Arizona, USA, December 15-18, 2009, page 200. Association for
Information Systems, 2009.

[7] N. Arnosti and S. M. Weinberg. Bitcoin: A natural oligopoly.

In A. Blum, editor, 10th
Innovations in Theoretical Computer Science Conference, ITCS 2019, January 10-12, 2019,
San Diego, California, USA, volume 124 of LIPIcs, pages 5:1–5:1. Schloss Dagstuhl - Leibniz-
Zentrum für Informatik, 2019.

[8] J. Augustine, N. Chen, E. Elkind, A. Fanelli, N. Gravin, and D. Shiryaev. Dynamics of

proﬁt-sharing games. Internet Math., 11(1):1–22, 2015.

[9] Y. Bachrach, V. Syrgkanis, and M. Vojnovic. Incentives and eﬃciency in uncertain collab-
orative environments. In Y. Chen and N. Immorlica, editors, Web and Internet Economics
- 9th International Conference, WINE 2013, Cambridge, MA, USA, December 11-14, 2013,
Proceedings, volume 8289 of Lecture Notes in Computer Science, pages 26–39. Springer, 2013.

[10] G. Benade, S. Nath, A. D. Procaccia, and N. Shah. Preference elicitation for participatory

budgeting. Management Science, 67(5):2813–2827, 2021.

[11] V. Bilò, L. Gourvès, and J. Monnot. Project games.

In P. Heggernes, editor, Algorithms
and Complexity - 11th International Conference, CIAC 2019, Rome, Italy, May 27-29, 2019,
Proceedings, volume 11485 of Lecture Notes in Computer Science, pages 75–86. Springer, 2019.

23

[12] H. Chan, D. C. Parkes, and K. R. Lakhani. The price of anarchy of self-selection in tul-
lock contests. In A. E. F. Seghrouchni, G. Sukthankar, B. An, and N. Yorke-Smith, editors,
Proceedings of the 19th International Conference on Autonomous Agents and Multiagent Sys-
tems, AAMAS ’20, Auckland, New Zealand, May 9-13, 2020, pages 1795–1797. International
Foundation for Autonomous Agents and Multiagent Systems, 2020.

[13] S. Chawla, J. D. Hartline, and B. Sivan. Optimal crowdsourcing contests. Games Econ.

Behav., 113:80–96, 2019.

[14] D. DiPalantino and M. Vojnovic. Crowdsourcing and all-pay auctions. In J. Chuang, L. Fort-
now, and P. Pu, editors, Proceedings 10th ACM Conference on Electronic Commerce (EC-
2009), Stanford, California, USA, July 6–10, 2009, pages 119–128. ACM, 2009.

[15] E. Elkind, A. Ghosh, and P. W. Goldberg. Contest design with threshold objectives. In Web
and Internet Economics - 17th International Conference, WINE 2021, Potsdam, Germany,
December 14-17, 2021, Proceedings, volume 13112 of Lecture Notes in Computer Science, page
554. Springer, 2021.

[16] A. Gavious and Y. Minchuk. Revenue in contests with many participants. Oper. Res. Lett.,

42(2):119–122, 2014.

[17] A. Glazer and R. Hassin. Optimal contests. Economic Inquiry, 26(1):133–143, 1988.

[18] G. Goel, A. Nikzad, and A. Singla. Mechanism design for crowdsourcing markets with het-
erogeneous tasks. In J. P. Bigham and D. C. Parkes, editors, Proceedings of the Seconf AAAI
Conference on Human Computation and Crowdsourcing, HCOMP 2014, November 2-4, 2014,
Pittsburgh, Pennsylvania, USA. AAAI, 2014.

[19] S. Gollapudi, K. Kollias, D. Panigrahi, and V. Pliatsika. Proﬁt sharing and eﬃciency in utility
games. In K. Pruhs and C. Sohler, editors, 25th Annual European Symposium on Algorithms,
ESA 2017, September 4-6, 2017, Vienna, Austria, volume 87 of LIPIcs, pages 43:1–43:14.
Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2017.

[20] N. Gravin, Y. Jin, P. Lu, and C. Zhang. Optimal budget-feasible mechanisms for additive
valuations. In A. Karlin, N. Immorlica, and R. Johari, editors, Proceedings of the 2019 ACM
Conference on Economics and Computation, EC 2019, Phoenix, AZ, USA, June 24-28, 2019,
pages 887–900. ACM, 2019.

[21] E. Koutsoupias and C. H. Papadimitriou. Worst-case equilibria. Comput. Sci. Rev., 3(2):

65–69, 2009.

[22] S. Leonardi, G. Monaco, P. Sankowski, and Q. Zhang. Budget feasible mechanisms on matroids.

Algorithmica, 83(5):1222–1237, 2021.

[23] T. Luo, S. K. Das, H. P. Tan, and L. Xia. Incentive mechanism design for crowdsourcing: An
all-pay auction approach. ACM Transactions on Intelligent Systems and Technology (TIST),
7(3):1–26, 2016.

[24] B. Moldovanu and A. Sela. The optimal allocation of prizes in contests. American Economic

Review, 91(3):542–558, 2001.

24

[25] D. Monderer and L. S. Shapley. Potential games. Games and Economic Behavior, 14(1):

124–143, 1996.

[26] S. Nakamoto.

Bitcoin:

A peer-to-peer electronic cash system.

2008.

URL

https://bitcoin.org/bitcoin.pdf.

[27] G. Polevoy, S. Trajanovski, and M. de Weerdt. Nash equilibria in shared eﬀort games.

In
A. L. C. Bazzan, M. N. Huhns, A. Lomuscio, and P. Scerri, editors, International conference
on Autonomous Agents and Multi-Agent Systems, AAMAS ’14, Paris, France, May 5-9, 2014,
pages 861–868. IFAAMAS/ACM, 2014.

[28] R. Siegel. All-pay contests. Econometrica, 77(1):71–92, 2009.

[29] Y. Singer. Budget feasible mechanisms. In 51th Annual IEEE Symposium on Foundations of
Computer Science, FOCS 2010, October 23-26, 2010, Las Vegas, Nevada, USA, pages 765–774.
IEEE Computer Society, 2010.

[30] C. Taylor. Digging for golden carrots: an analysis of research tournaments. American Economic

Review, 85(4):872–90, 1995.

[31] A. Vetta. Nash equilibria in competitive societies, with applications to facility location, traﬃc
routing and auctions. In 43rd Symposium on Foundations of Computer Science (FOCS 2002),
16-19 November 2002, Vancouver, BC, Canada, Proceedings, page 416. IEEE Computer Soci-
ety, 2002.

[32] M. Vojnovic. Contest Theory: Incentive Mechanisms and Ranking Methods. Cambridge Uni-

versity Press, 2016.

[33] B. Zhang, R. Oliynykov, and H. Balogun. A treasury system for cryptocurrencies: Enabling
In 26th Annual Network and Distributed System Security
better collaborative intelligence.
Symposium, NDSS 2019, San Diego, California, USA, February 24-27, 2019. The Internet
Society, 2019.

25

