Proof-of-Stake Mining Games with Perfect
Randomness

Matheus V. X. Ferreira∗1 and S. Matthew Weinberg†1

1Computer Science, Princeton University

December 15, 2021

Abstract

Proof-of-Stake blockchains based on a longest-chain consensus protocol are an attractive
energy-friendly alternative to the Proof-of-Work paradigm. However, formal barriers to “get-
ting the incentives right” were recently discovered, driven by the desire to use the blockchain
itself as a source of pseudorandomness [4].

We consider instead a longest-chain Proof-of-Stake protocol with perfect, trusted, exter-

nal randomness (e.g. a randomness beacon). We produce two main results.

First, we show that a strategic miner can strictly outperform an honest miner with just
32.5% of the total stake. Note that a miner of this size cannot outperform an honest miner
in the Proof-of-Work model [22]. This establishes that even with access to a perfect ran-
domness beacon, incentives in Proof-of-Work and Proof-of-Stake longest-chain protocols are
fundamentally different.

Second, we prove that a strategic miner cannot outperform an honest miner with 30.8%
of the total stake. This means that, while not quite as secure as the Proof-of-Work regime,
desirable incentive properties of Proof-of-Work longest-chain protocols can be approximately
recovered via Proof-of-Stake with a perfect randomness beacon.

The space of possible strategies in a Proof-of-Stake mining game is significantly richer
than in a Proof-of-Work game. Our main technical contribution is a characterization of poten-
tially optimal strategies for a strategic miner, and in particular, a proof that the corresponding
infinite-state MDP admits an optimal strategy that is positive recurrent.

1
2
0
2

c
e
D
4
1

]
T
G
.
s
c
[

2
v
9
6
0
4
0
.
7
0
1
2
:
v
i
X
r
a

∗Contact: mvxf@cs.princeton.edu
†Supported by NSF CAREER Award CCF-1942497

 
 
 
 
 
 
Contents

1 Introduction

1.1 Brief Overview of Model
.
1.2 Brief Technical Overview .
.
1.3 Related Work .
.
.
1.4 Roadmap .

.
.

.
.

.
.

.
.

.
.

.
.

.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

2 Model
2.1
2.2 Capitulating a State .
.
2.3 Recurrence .

Payoff as Fractional of Blocks in the Longest Path .
.
.
.
.
.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.

.

.

.

3 Enhancing Selfish Mining with Nothing-at-Stake

4 Trimming the Strategy Space
.
.

.
Step 1: Timeserving .
Step 2: Orderly .
.
.
Step 3: Longest Chain Mining .
.
Step 4: Trimmed .

4.1
4.2
4.3
4.4

.
.

.
.

.
.

.
.

.

.

.

.

.

.

.

.

.

.
.
.
.

5 Trimming the State Space

5.1 Checkpoints and Weak Recurrence
.
5.2
.
5.3
.
5.4

Step 1: Checkpoint Preserving .
.
Step 2: Opportunistic .
.
.
Step 3: Strong Recurrence .

.
.

.
.

.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

6 Nash Equilibrium

7 Conclusion

A Real Analysis Background

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.

.
.
.
.

.
.
.
.

B Probability Theory Background

B.1 Convergence of Random Variables .
.
B.2 Laws of Large Numbers .

.

.

.

.

.

C Markov Decision Process

D Omitted Proofs from Section 3

E Omitted Proofs from Section 4
.
E.1 Timeserving Reduction .
E.2 Orderly Reduction .
.
.
E.3
E.4 Trimmed Strategies .

.
.
Longest Chain Mining Reduction .
.

.
.

.
.

.
.

.
.

.

.

.

.

.

.

.

.

.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

1
2
3
4
4

4
8
9
10

11

15
15
16
17
17

18
18
20
21
21

22

23

26

27
27
27

27

31

34
34
35
39
43

.

.

.

.

.

F Omitted Proofs from Section 5
.

F.1 Checkpoints .
.
.
F.2 Checkpoint Preserving Reduction .
.
Preliminaries
.
.
.

.
F.2.1
.
.
.
.
F.2.2 The Reduction .
F.3 Opportunistic Reduction .
.
F.4 The Strong Recurrence Theorem .

.
.
.

.
.
.

.
.
.

.
.

.

.

.

.

G Omitted Proofs From Section 6

H Table of Notation

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

44
44
45
46
48
55
59

63

76

1 Introduction

Blockchains have been a resounding success as a disruptive technology. However, the most suc-
cessful implementations (including Bitcoin [19] and Ethereum [23]) are built on a concept called
proof-of-work. That is, participants in the protocol are selected to update the blockchain propor-
tionally to their computational power. The consensus protocols underlying Bitcoin and Ethereum
(and many other proof-of-work cryptocurrencies) have been secure in practice, and robust against
strategic manipulation. There is even a theoretical foundation supporting this latter property:
honestly following the Bitcoin protocol is a Nash equilibrium in a stylized model when no miner
controls more than αPoW
0.329 of the total computational power in the network [22, 16] (we
will use the notation αmodel to denote the supremum α such that whenever no miner is selected
to create the next block with probability bigger than α, it is a Nash equilibrium for all miners to
follow the longest-chain protocol in the referenced model).1

≈

However, one major drawback of proof-of-work blockchains is their massive energy con-
sumption. For example, Bitcoin currently consumes more electricity than all but 26 countries
annually.2 The need for specialized hardware and low-cost electricity/cooling/etc. also leads to
concentration of the mining process among the few entities who have access to the necessary
technology [1]. One popular emerging alternative is a paradigm termed proof-of-stake, where
participants are selected proportionally to their stake in the currency itself.

Proof-of-stake cryptocurrencies do not suffer from this drawback, but raise new technical
challenges, especially from the incentives perspective. Indeed, Brown-Cohen et al. [4] identifies
several formal barriers to designing incentive compatible longest-chain proof-of-stake cryptocur-
rencies (that is, proof-of-stake protocols “like Bitcoin”). Their work highlights one key barrier:
in existing proof-of-stake protocols, the blockchain itself serves as a source of pseudorandomness,
whereas in proof-of-work protocols the pseudorandom selection of participants is completely inde-
pendent of the blockchain. Specifically, they pose a stylized model with No External Randomness
and show that it is never a Nash equilibrium for all miners to honestly follow the longest-chain
protocol no matter how small they are (that is, αPoSNER = 0).

In this work, we investigate the incentive compatibility of longest-chain proof-of-stake pro-
tocols with access to perfect external randomness, completely independent of the blockchain, often
termed a randomness beacon [21] (for brevity of notation, we’ll refer to this model simply as PoS).
We provide two main results, which give a fairly complete picture:

• We establish that αPoS < 0.325 < αPoW. That is, even with access to perfect external ran-
domness, longest-chain proof-of-stake protocols admit richer strategic manipulation than their
proof-of-work counterparts. We do this by designing a new strategic deviation that we term
nothing-at-stake selfish mining, and establish that it is strictly more profitable than honest
behavior for any miner with (cid:39) 0.325 of the total stake (Theorem 3.4).

• We prove that αPoS (cid:39) 0.308 (Theorem 6.1). In particular, this means that access to a ran-
domness beacon fundamentally changes longest-chain proof of stake protocols: without
one αPoSNER = 0, and any miner can profit by deviating. With a randomness beacon, the
incentives are (quantitatively) almost as good as proof-of-work.

1Kiayias et al. [16] proves that αPoW (cid:39) 0.308, and [22] estimates αPoW to high precision as
2Source: https://cbeci.org/. Accessed 3/25/2021.

≈

0.329.

1

We now provide a high-level overview of our model (a significantly more detailed descrip-
tion of the model appears in Section 2), a brief overview of the key technical highlights, and an
overview of related work.

1.1 Brief Overview of Model
Seminal work of Eyal and Sirer poses an elegant abstraction of the Bitcoin protocol (that we call
the PoW model) [10]. Specifically, the game proceeds in infinitely many discrete rounds. In each
round, a single miner is chosen proportionally to their computational power, and creates a block.
Immediately upon creating a block, the miner must choose its contents (including its predecessor
in the blockchain). The strategic decisions a miner makes are: a) which predecessor to select
when they create a block, and b) when to publish that block to the other miners. The fact that
predecessors must be chosen upon creation of the block captures that the contents of a block
created via proof-of-work are fixed upon creation.

∞

A key concept in Bitcoin is the longest-chain protocol. Specifically, the longest chain is the
published block with the most ancestors.3 Each miner’s reward is equal to the fraction of blocks
they produce in the longest chain (taking a limit as rounds go to
). A miner honestly follows
the longest-chain protocol if: a) they always select the (current) longest chain as the predecessor
of any created node, and b) they publish all created blocks during the round in which it’s cre-
ated. Eyal and Sirer [10] establishes that αPoW
1/3 (previously, it was believed that αPoW = 1/2
as proposed in [19]), and follow-up work further nailed down αPoW

0.329 [22].

Brown-Cohen et al. [4] modify this model to capture proof-of-stake with no external random-
ness. In their model, a random coin is selected in each round independently for each block. That
is, for each round, and each block B, an independent random miner is selected who is eligible to
create a block with B as a predecessor with probability equals to their fraction of all the coins
in the system. This captures that the protocol must use the chain itself as a source of pseudo-
randomness. Their work establishes that αPoSNER = 0: it is never a Nash equilibrium to honestly
follow the longest-chain protocol in their model. This result is entirely driven by the fact that
the protocol has no external randomness, and therefore, miners can make non-trivial predictions
about future pseudorandomness.

≈

≤

Our model lies between these two, and captures proof-of-stake with perfect external random-
ness. Specifically, in each round a single coin is chosen to create a block. Thus a single miner is
chose to create a block (just as in PoW) with probability proportional to their fraction of the coins
in the system. The strategic decisions are now better phrased as: a) when to publish a created
block, and b) which predecessor to select when publishing. Our model captures the following:
perfect external randomness allows the protocol to select a random miner independently of all
previous selected miners and all previously published blocks. The distinction to proof-of-work is
that it is now computationally tractable to set the contents of the block, including its predecessor,
at any point before it is published.

Note that our model does stipulate that the winner of round t can publish a single block
with timestamp t. In a proof-of-stake protocol, there is no technical barrier to creating and pub-
lishing any number of blocks using the same timestamp (indeed, this is precisely because it is

3An ancestor is any block that can be reached by following a path of predecessors. Observe that because each

block has a single predecessor, there is a single path of predecessors out of any block.

2

computationally efficient to produce blocks in proof-of-stake). However, it will be immediately
obvious to the rest of the network that a miner has deviated from the longest-chain protocol in
this specific way, and it will be immediately obvious which miner cheated.4 A common solution
to strongly disincentivize such behavior is a slashing protocol: any miner can include pointers to
two blocks created using the same timestamp and the cheating miner will be steeply fined. While
we will not rigorously model the incentives induced by a slashing protocol, our model implicitly
assumes a sufficiently strong disincentive for miners to publish multiple blocks (and capture this
in our model by simply hard-coding that miners must publish at most a single block with each
timestamp).

To get intuition for the types of protocols our stylized model aims to capture, below is a sample

(simplified) protocol to have in mind:5

• In order to be eligible to mine, a coin must be frozen for (large) T rounds, along with a
deposit equal to (large) L times its value (that is, the coin and its deposit must be owned by
the same miner for T rounds in a row).

• After being used for mining, a coin and its deposit must be frozen for T rounds.

• During each round t, the randomness beacon outputs a random number. This is mapped to
a random eligible coin, and its owner is the selected miner at round t. The selected miner
can create blocks with timestamp t.

• If a miner ever publishes distinct blocks with the same timestamp, any other miner can
include pointers to those two blocks in a block of their own. This will cause the deviant
miner to lose their entire deposit (if desired, a 1
ε fraction of it can be destroyed, and an
−
ε fraction can be awarded to the altruistic miner).

Importantly, we are claiming neither that randomness beacons exist (either in theory or in prac-
tice), nor that slashing protocols that perfectly disincentivize detectable cheating (without af-
fecting any other incentives) exist. Theorem 3.4 shows that even if these primitives existed, a
longest-chain proof-of-stake protocol assuming them would still be (slightly) more vulnerable to
strategic manipulation than a proof-of-work protocol. On the other hand, Theorem 6.1 establishes
in some sense a reduction from proof-of-stake protocols that nearly match the incentive guaran-
tees of proof-of-work protocols to the design of randomness beacons and slashing protocols.

1.2 Brief Technical Overview
Theorem 3.4 (αPoS (cid:47) 0.325) follows by designing our nothing-at-stake selfish mining strategy, and
analyzing its expected payoff. While the insights to design our strategy are novel, the analysis is

4Observe that deviations from the longest-chain protocol that select strategic predecessors or publish at strategic
times cannot be definitively attributed to a cheating miner, as these deviations have an innocent explanation: latency.
That is, perhaps the reason a miner chose the wrong predecessor is because news of the true longest chain had not
yet reached them. Alternatively, perhaps the miner tried to publish their block during the correct round, but it only
propagated through the network several rounds later due. Like all prior work, we do not rigorously model latency,
and stick to the elegant model proposed in [10].

5We are not claiming that this protocol is secure in a rich model, nor will we reason formally about properties
of the proposed slashing mechanism. We provide this just to give intuition for why our stylized model captures the
salient features of a longest-chain protocol with trusted external randomness.

3

similar to those used in prior work to analyze the payoff of the resulting Markov Decision Process
(MDP). We defer to Section 3 a description of our strategy and intuition for why it succeeds.

The proof of Theorem 6.1 is the bulk of our technical work. To start, we observe that our
model admits an infinite-state MDP (just as in [22]). However, the space of strategies available
to a miner in our setting is significantly richer than in the PoW model. We provide several exam-
ples demonstrating why counterintuitive behavior (such as orphaning one’s own blocks) could a
priori be part of an optimal strategy. So our main technical results characterize possible optimal
strategies for this infinite-state MDP, culminating in a strong enough characterization to lower
bound the optimal payoff for Theorem 6.1 and concluding αPoS

0.308.

≥

1.3 Related Work
The most related work is already overviewed above: Eyal and Sirer [10] provide the PoW model,
develop the selfish mining attack, and prove that αPoW
1/3. Sapirshtein et al. [22] estimates
αPoW
0.329 by solving the associated MDP to high precision, and Kiayias et al. [16] prove
that αPoW (cid:39) 0.308. Brown-Cohen et al. [4] study a related proof-of-stake model with no external
randomness, and show that αPoSNER = 0. Other works also study similar questions in variants of
this model (e.g. [5, 20]).

≤

≈

There is a rapidly-growing body of work at the intersection of mechanism design and cryp-
tocurrencies [18, 6, 1, 14, 11]. Some of these works further motiviate the consideration of proof-
of-stake cryptocurrencies [1], while others motivate the choice to restrict attention to Bitcoin’s
proportional reward scheme [6, 18], but there is otherwise little overlap between our works.

In practice, implementing a random beacon is a complex task [2, 3, 7] and is outside the scope
of this paper. As previously noted, our results can be viewed either as a reduction to designing
a randomness beacon (Theorem 6.1), or an impossibility result even under the assumption of a
randomness beacon (Theorem 3.4).

Finally, it is worth noting that many existing proof-of-stake protocols fit the longest-chain
paradigm [17, 13, 8], while others are fundamentally different [12]. Protocols based on Byzantine
consensus are a growing alternative to the longest-chain paradigm, although both paradigms are
well-represented in theory and in practice. Byzantine consensus protocols are outside the scope
of our analysis.

1.4 Roadmap
Section 2 provides a very detailed description of our model, along with examples to help illustrate
its distinction from proof-of-work. Section 3 provides our nothing-at-stake selfish mining, and
Theorem 3.4. Sections 5 and 4 narrow the space of optimal strategies through a series of reduc-
tions. Section 6 overviews Theorem 6.1. Various helpful examples and all omitted proofs are in
the appendix.

2 Model

A mining protocol is a Nash equilibrium if no miner wishes to unilaterally change their strategy
provided all miners are following the intended protocol. Thus it suffices to consider a two-player

4

|

(cid:105)

}

U

U

∈ {

n∈N+

n
{

γn
(cid:104)

1(B),

γn = i

1, 2
}

. We denote by γ :=

game between Miner 1 and Miner 2. Think of Miner 2 as the “rest of the network”, which is
honestly executing the longest-chain protocol, and think of Miner 1 as the “potential attacker”
that optimizes his strategy provided Miner 2 is honest. Following [10, 16, 22] and subsequent
works, the game proceeds in discrete time steps (abstracting away the exponential rate at which
blocks are found) which we call rounds, and the rounds are indexed by N+. The state B of the
game is a tuple (Tree(B),
2(B), T1(B), T2(B)) (each of these terms will be explained
subsequently).
Rounds. During every round n, a single miner creates a new block, and we denote that miner
by γn
the full ordered list of miners for each round. In
an execution of the game, each γn is drawn i.i.d., and equal to 1 with probability α < 1/2. We
as the rounds during which Miner i creates a new block. Ti(B) denotes
let Ti :=
all blocks created by Miner i at state B. We abuse notation and might refer to n as the state at
round n (after block n is created and all actions are taken, but before round n + 1 starts). That is,
(Tree(n),
Blocks. The second basic element is a block. Each block has a label in N. Blocks are totally ordered
by their labels and we say block s was created before block v if s < v. We overload notation and
also use n to refer to the block produced in round n. All blocks are initially unpublished, and can
later become published due to actions of the miners. Once a block n is published, it has a pointer
to exactly one predecessor n(cid:48) created earlier (that is n(cid:48) < n) and we write n
Block Tree. Because all published blocks have a pointer to an earlier block, this induces, at all
rounds, a block tree Tree. We will also refer to V, E as the nodes and edges in Tree = (V, E).
Here, the nodes are all blocks which have been published. Every node has exactly one outgoing
(directed) edge towards its predecessor. Before the game begins, the block tree contains only
block 0, which we refer to as the genesis block and not created by Miner 1 nor Miner 2. We let
i
U
denote the set of blocks which have been created by Miner i, but are not yet published. We refer
to

2(n), T1(n), T2(n)) is the state at round n.

1(n),

n(cid:48).

→

U

U

(1)

,

,

,

∅

∅

∅

∈

),

)
∅

B0 := ((
{

,
0
∅
}
as the initial state before any blocks are created and the block tree contains only the genesis block.
Ancestor Blocks. We say that block a is an ancestor of block b
V if there is a directed path
from b to a (so b is an ancestor of itself). We write A(b) to denote the set of all ancestors of b
(observe that a block can never gain new ancestors, so this is well-defined without referencing
the particular state S, or the round, etc.). We use h(b) :=
1 as short-hand for the height
of block b (the genesis block is the only block with height 0).
Longest Chain. The longest chain
is the leaf in V with the longest path
h(b)
}
to the genesis block, breaking ties in favor of the first block published, and then in favor of the
) with height i and we refer
earliest-indexed block. We use Hi to refer to the block in v
to A(
), but a new
A(
C
block
Successor blocks. We say block a is a successor of block b
from
Actions. During round n, Miner i knows γ(cid:96) for all (cid:96)

) as the longest path. We say a block q is forked (or orphaned) when q
(cid:48) becomes the longest chain and q

to b. We write Succ(b) to denote the set of successors of b.

n, and can take the following actions:

= b is in the unique path

:= arg maxb∈V

A(b)
|

V if a

A(
C

C
C

| −

A(

(cid:48)).

(cid:54)∈

∈

∈

∈

C

C

C

{

≤

1. Wait: wait for the next round, and do nothing.

5

(cid:54)
2. PublishSet(V (cid:48), E(cid:48)): publish a set of blocks V (cid:48) with pointers E(cid:48). This adds V (cid:48) to V , E(cid:48) to E,
and changes all blocks in V (cid:48) from unpublished to published. To be valid, it must be that:

• V (cid:48)
⊆ U
• For all v
• For all v
• For all v
pointer).

i (Miner i actually has blocks V (cid:48) to publish).

∈

V (cid:48), v(cid:48)

E(cid:48), v
∪
E(cid:48), v > v(cid:48) (pointers are to earlier blocks).

v(cid:48)
v(cid:48)
V (cid:48), there is exactly one outgoing edge in E(cid:48) (every block has exactly one

V (cid:48) (syntax check for edges in E(cid:48)).

∈

∈

∈

V

→

→

∈

−

Clarifying Order of Operations. At the beginning of round n, there is a block tree Tree =
Tree(n

1), and each miner i has a set of unpublished blocks

1). Then:

i =

i(n

1. γn is drawn, and equal to 1 with probability α, and 2 with probability 1
1).
. For the other miner,

3−γn :=

3−γn(n

γn :=

γn(n

1)

α. This updates

−

U

U

−

n
}

∪ {

U

−

2. Miner 2 takes an action. If that action is PublishSet(V (cid:48), E(cid:48)), add the nodes V (cid:48) and edges E(cid:48)

U

−

U

U

3. Miner 1 takes an action. If that action is PublishSet(V (cid:48), E(cid:48)), add the nodes V (cid:48) and edges E(cid:48)

to Tree, and update

to Tree, and update

2 :=

U

2

U

\

1 :=

U

1

U

\

V (cid:48).

V (cid:48).

4. At this point, round n is over, so Tree(n) := Tree,

i(n) :=

U

i, etc.

U

U

1),

2(n

(n),

(n),

U
−

Half
2

Half(n)) as the subsequent state to (Tree(n

Predecessor state. For state B, we define BHalf as the state prior to B before Miner 1 took
their most recent action and after Miner 2 took their most recent action. Similarly, we de-
fine (TreeHalf(n),
(n
1),
−
takes their action.

Half
1
−
1)) after block n was created, Miner 2 takes their action and before Miner 1

U
Recall that Miner 2 acts first in every round, so the second tie-breaker in deciding what is the
longest chain is only used to distinguish between two blocks of Miner 1 published during the same
round, and will never be invoked in a “reasonable” strategy for Miner 1 (see Observation 4.3).6
Like Kiayias et al. [16], we use FRONTIER to refer to the honest strategy, which never forks and
it will be Miner 2’s strategy.

1(n

1),

−

U

C

C

Definition 2.1 (Frontier Strategy). During all rounds n, the FRONTIER strategy for miner i does
the following:

• If γn

= i, Wait.

• If γn = i, PublishSet(

) (publishes the new block pointing to the longest chain).
Definition 2.2 (Rewards). For any two states B and B(cid:48), define Miner k’s reward as the integer-
valued function rk from state B to B(cid:48) as the difference between the number of blocks created by
Miner k in the longest path at state B(cid:48) and B. That is,

→ C}

n
{

n
{

,
}

rk(B, B(cid:48)) :=

Tk(B(cid:48))
6Eyal and Sirer [10] also considers the case where Miner 1 wins a tie-breaking with probability β. In principle,
[0, 1], but we focus on the case β = 0 since it is the most pessimistic for

.
Tk(B)
|

A(
C
|

A(
C

(B(cid:48)))

(B))

| − |

∩

∩

(2)

our model can easily accommodate any β
the attacker.

∈

6

(cid:54)
Payoffs. As in [10] and follow-up work, miners receive steady-state revenue proportional to their
fraction of blocks in the longest chain. Recall that in our notation,
(n) denotes the longest chain
after the conclusion of round n, A(
(n), and Ti denotes all blocks
(n)) denotes the ancestors of
created by Miner i. Therefore, we define the payoff to Miner 1, when Miner i uses strategy πi as:

C
C

C

Rev(n)

γ (π1, π2) := |

(n))

A(
C
h(
C

∩
(n))

T1

,

|

and

Rev(π1, π2) := Eγ

(cid:20)

lim inf
n→∞

Rev(n)

(cid:21)
γ (π1, π2)

,

α.

where the expectation is taken over γ, recalling that each γn is i.i.d. and equals to 1 with proba-
bility α, and 2 with probability 1

We will study in particular the payoff of strategies π1 against FRONTIER. For simplicity
1 (because FRONTIER has no unpublished blocks, so
of notation later, we will refer to
U
2 is unnecessary), π := π1 (because π2 := FRONTIER). We will also list all states only as
U
(n), T1(n)) (because the other variables can be inferred from these, conditioned on
(Tree(n),
π2 := FRONTIER). We further define:

:=

−

U

U

Rev(n)

γ (π1) := Rev(n)

γ (π1, FRONTIER), Rev(π1) := Rev(π1, FRONTIER).

(3)

A strategy π∗ is optimal if Rev(π∗) = maxπ Rev(π). Thus FRONTIER is a Nash equilibrium if
FRONTIER is an optimal strategy for Miner 1.
Proof-of-Work vs. Proof-of-Stake. Our model, as stated, captures Proof-of-Stake protocols
with perfect/trusted external randomness. Importantly, this means that once a miner knows they
created a block during round n, they do not need to decide precisely the contents of that block
until they publish it (because there is no computational difficulty to produce a block). In Proof-
of-Work and the model of Eyal and Sirer [10], the miner of block n must decide in round n the
contents of that block (because the contents are locked in as soon as the miner succeeds in proving
work). Crucially, the miner must decides the ancestor of block n during time t = n while in our
model, the miner decides the ancestor of block n any time t
n before block n is published. This
is the only difference between the two models. Observe that any Proof-of-Work strategy is also
valid in our model: this would just be a strategy which chooses the pointer for block n in round
n, and does not change it when publishing later. Example 2.3 helps illustrate this distinction.

≥

Example 2.3 (Proof-of-Work vs Proof-of-Stake). Consider the following 6-round example where
Miner 1 creates blocks 1, 4 and 5, and Miner 2 create blocks 2, 3 and 6 as depicted in Figure 1. If
Miner 1 was following the Selfish Mining strategy [10] (Definition 3.1), they would decide to create
0. At this point, Miner 1
and withhold 1
→
→
0 and we say block 1 becomes permanently orphan. Next, Miner
would never attempt to publish 1
3 (at t = 4) and 5
1 creates and withhold 4
3,
Miner 1 publishes 5
3 (at t = 6), forking block 6 from the longest path. This nets 2 blocks in
4
the longest path for Miner 1, and 2 for Miner 2.

→
4 (at t = 5). When Miner 2 publishes 6

0 (at time t = 1). Miner 2 would then publish 3

→
→

→

→

→

→

2

Here is a viable strategy in the Proof-of-Stake mining game: Miner 1 still withholds block 1 (but
does not yet decide where it will point), and it is still initially orphaned when Miner 2 publishes
blocks 2 and 3. When Miner 1 creates block 4, they withhold it (but does not yet decide where it
will point). When they create block 5, they decide to publish block 4 (deciding only now to point
to block 1) and block 5 (deciding only now to point to block 4). This creates a new longest path.
5. This nets 3 blocks in the longest path for Miner 1, and 1 for Miner 2.
Miner 2 then publishes 6

→

7

Figure 1: Diagram representing the mining
game in Example 2.3. We use double circles
for blocks owned by Miner 1 and single cir-
cles for blocks owned by Miner 2. The gene-
sis block—block 0—is not owned by neither
Miner 1 nor Miner 2. The time stamps near
the solid edges represent the round where
the edge was published, and the number in-
side the circle represents the round when
the block was created. The dashed edges
represent some edges that could have been
created (edges from any nodes in
to
4, 5
}
{
any nodes in
are also feasible —
i.e., any edge from a later node to an earlier
node is feasible).

0, 1, 2, 3
}

{

Importantly, observe that in the proof-of-work model, it would be exceptionally risky for Miner
1 to pre-emptively decide to point block 4 to block 1 at time t = 4 without knowing that they will
create block 5 (because maybe Miner 2 creates block 5, and then they would be an additional block
behind). But in the proof-of-stake model, Miner 1 can wait to gather more information before deciding
where to point. In particular, if they happened to instead create block 6 but not 5, they could have
published 6
3. In proof-of-stake, Miner 1 has the flexibility to make this decision later. In
proof-of-work, they have to decide immediately whether to have block 4 pointing to 1 or 3.

→

→

4

Reminder of Notation. Table 1 in Appendix H is a reminder of our notation.

2.1 Payoff as Fractional of Blocks in the Longest Path
Eyal and Sirer [10] motivates the use of the fraction of blocks as a miner’s utility due to the diffi-
culty adjustment in Bitcoin’s PoW protocol: Bitcoin adjusts PoW difficult so that, on expectation,
miners create one block every 10 minutes and the creator of each block receives new Bitcoins as
block reward. Thus a miner maximizes their expected number of blocks in the longest path up to
time T by maximizing their expected fraction of blocks in the longest path up to time T .

For PoS, a random beacon outputs a random string at a fixed rate, independent of the blockchain
state.7 Although difficult adjustment is absent in proof-of-stake, the probability of a miner cre-
ating the next block is proportional to α, their fraction of coins in the system. Although α is
approximately constant over short time horizons, over long time horizons, α will depend on the
fraction of block rewards Miner 1 collects. Thus, in the long-term, Miner 1 will maximize block
rewards by maximizing their fraction of blocks in the longest path.

In Figure 2, we simulate the fraction of coins owned by Miner 1 overtime when Miner 1
follows FRONTIER or the Nothing-at-Stake Selfish Mining (NSM in Definition 3.3) and Miner
2 follows FRONTIER. From the simulation, we observe NSM allows Miner 1 to add a higher

7The National Institute of Standards and Technology (NIST) random beacon outputs 512 bits every 60 sec-

onds [15].

8

fraction of blocks in the longest path when compared with FRONTIER as long as Miner 1 owns
more than 32.8% of the coins. We confirm this empirical result in Theorem 3.4. This allows Miner
1 to eventually own an arbitrarily large fraction of the coins. Thus the security of a longest chain
proof-of-stake protocol depend on a formal guarantees that no strategy is more profitable than
FRONTIER when a profit maximizing miner is maximizing their fraction of blocks in the longest
path. We accomplish this task in Theorem 6.1.

Figure 2: Simulation of Miner 1’s dynamic stake over one million rounds when Miner 1 either
follow FRONTIER or the Nothing-at-Stake Selfish Mining (NSM) strategy for distinct initial values
of α. As initial condition, the system has 100 thousand coins with Miner 1 initialing owning α
fraction of the coins. We observe when following FRONTIER, Miner 1 cannot increase their
fraction of the stake. We also observe NSM allows Miner 1 to increase their fraction of the stake
when they initially own 32.8% of the coins, but NSM is not profitable when Miner 1 owns less
than 32.4%, as we find in Theorem 3.4.

2.2 Capitulating a State
For some states of the game, Miner 1 might follow a strategy that will never fork some blocks
from the block tree. Then, it is safe to say that Miner 1 deletes those blocks from the state (or
treats the one with highest height as the new genesis block) and consider a trimmed version of
the state variable. As example, define B0,1 where Miner 2 creates and publishes block 1. Thus

,

,

1

).

),

→

0
}

0, 1
B0,1 := ((
{
}
{
If Miner 1 never forks block 1, then it is safe to say that in the view of Miner 1 state B0,1 is
equivalent to state B0 (after treating block 1 as the new genesis block). Then, we say Miner 1
capitulates from state B0,1 to B0. Since Miner 1 can induce the mining game to return to prior
states, it is convenient to think of Miner 1 optimizing an underlying Markov Decision Process.
Next, we provide a definition and formalize the payoff of the MDP in Appendix C.
Markov Decision Process. A Markov Decision Process (MDP) for the mining game where Miner
1 follows strategy π and Miner 2 follows FRONTIER is a sequence (Xt)t≥0 where Xt is a random

∅

∅

(4)

9

02468time×1060.00.20.40.60.81.0AdversaryFractionoftheCoinsDynamicStakeFRONTIER(α=0.328)NSM(α=0.333)NSM(α=0.328)NSM(α=0.3)variable representing the state by the end of round t and before any actions have been take in
round t + 1. Unless otherwise stated, we initialize X0 = B0 (Equation 1). The game transitions
from state Xt to Xt+1 once the next block is created followed by Miner 2 taking their action
followed by Miner 1 taking their action.

For a mining game (Xt)t≥0 that starts at state X0 = B0, let

τ := min
{

t

≥

1 : State Xt is equivalent to state B0 in the view of Miner 1
}

(5)

be the first time step Miner 1 capitulates to state B0. Similary, let τ (cid:48) be the second time step Miner
1 capitulates to state B0. Then, the sequences of rewards

rk(X0, X1), rk(X1, X2), . . . , rk(Xτ −1, Xτ ),

rk(Xτ , Xτ +1), rk(Xτ +1, Xτ +2), . . . , Xτ (cid:48)−1, Xτ (cid:48))
are independent and identically distributed for k = 1, 2. One fundamental question is to under-
stand if E[τ ] <
when Miner 1 is following an optimal strategy (that is, does Miner 1 capitulate
to state B0 at some point with probability 1?). In the proof-of-stake setting, this is not obviously
true, and Example 2.3 gives some intuition why: while a proof-of-work Selfish Miner capitulates
to state B0 at round 3 (allowing Miner 2 to keep block 2 in the longest path), a Proof-of-Stake
miner might prefer to wait for an opportunity to use block 1, and it is not a priori clear at what
point it is safe to conclude that any optimal strategy would have given up on block 1 by now.

∞

2.3 Recurrence
Definition 2.4 (Recurrence). Consider a mining game starting at state X0 = B0 where Miner 1
follows strategy π. Let E be the event Miner 1 capitulates to state B0 at some time τ <
. We say
π is

∞

• Transient if P r [E] < 1.

• Recurrent if P r [E] = 1.

• Null recurrent if it is recurrent and E [τ ] =

.
∞
• Positive recurrent if it is recurrent and E [τ ] <

.

∞

Observe Miner 1 never forks the longest chain when using FRONTIER. Thus Miner 1 capitu-

lates to state B0 at every time step and τ = 1.

Observation 2.5. FRONTIER is positive recurrent.

For Proof-of-Work mining games, Kiayias et al. [16] and Sapirshtein et al. [22] assumes Miner
1 will always follow a positive recurrent strategy. To motivate this technical assumption, they
assume Miner 1 will never fork a block published by himself, which is sensible because Miner
1 can only mine on a single branch of the blockchain. This is not the case for Proof-of-Stake
blockchains, and it is not a priori clear that Miner 1 will never fork a block that they created
themselves. To see why this may occur, consider the following example.

10

First, define Bk,0, for k

[k]. Thus

≥

0, as the state where Miner 1 creates and withhold blocks

Then define B1,1 as the state after B1,0 where Miner 2 creates block 2 and publishes 2

Bk,0 := ((
0
}
{

,

∅

), [k], [k]).

=

1, 2, . . . , k
{

}
(6)

0. Thus

→

(7)

B1,1 := ((
{

,
0, 2
}

2

),

0
}

,
1
}

).

1
}

4

{

{

10

→

→

→

→

→

→

. . .

{
Example 2.6. Consider a game at state B1,1. After round 2, Miner 2 creates blocks 3, 4, . . . , 9, 10, 12
2 and Miner 1 creates and withholds blocks
and publishes 12
3
9
10 (this follows the classical
11, 13, 14, . . . , 24. At time step 13, Miner 1 publishes 13
→
selfish mining strategy: it gives up on block 1, but publishes 11
11 to fork block 12).
This is reasonable, because it is unlikely that Miner 1 can add block 1 to longest path and Miner 1
risks losing blocks 11 and 13 if Miner 2 creates and publishes block 14. However, in the event Miner 1
is lucky and creates blocks 14, 15, . . . , 24, Miner 1 can fork all blocks from the current longest path
(including his own blocks 11 and 13), resulting in a new longest path with blocks 1, 14, 15, . . . , 24
(consisting entirely of Miner 1’s blocks). Indeed, upon creating block 14, Miner 1 need not immediately
decide whether to make its predecessor 13, or whether to wait and see if they get an extremely lucky
run to override the entire chain.

→
10 and 13

→

→

→

11

Note that we are not claiming that this is the optimal decision for Miner 1 from this state, or even
that an optimal strategy may ever find itself in this state.8 However, this example helps demonstrate
that a significantly richer space of strategies are potentially optimal in our model, as compared to
proof-of-work.

This example shows that we must be careful to not exclude optimal strategies when claiming
any restrictions on strategies considered by Miner 1. We will eventually address this by introduc-
ing the notion of a checkpoint, Section 5.1, and prove that there are some conditions that allow
us to claim that any optimal strategy for Miner 1 will not fork a checkpoint (however, we do not
prove that Miner 1 will never consider forking their own blocks).

3 Enhancing Selfish Mining with Nothing-at-Stake

In this section, we show explicitly an strategy that outperforms FRONTIER even when α = 0.325.
From Sapirshtein et al. [22], FRONTIER is optimal for Proof-of-Work mining games when Miner 1
has mining power α
0.329). Thus our strategy witnesses that Proof-of-Stake
mining games admits strategies that are more profitable than any strategy in a Proof-of-Work
mining game – that is, will establish αPoS < αPoW.

0.329 (i.e., αPoW

≈

≤

Our strategy will be a subtle modification from the Selfish Mining strategy of Eyal and Sirer

[10] that leverages the Nothing-at-Stake vulnerability in Proof-of-Stake blockchains.9

8For example, if this were the optimal decision from this state, it would likely be because α is small, and Miner
1 should just take whatever opportunities they have to publish blocks. However, if α is small, that may mean it is
better for Miner 1 to just be honest, and they would never find themselves in this situation. The point is that some
quantitative comparison is necessary in order to determine whether the optimal strategy for Miner 1 would ever
take this action.

9The nothing-at-stake vulnerability refers to the fact the algorithm for which a miner can verify a block validity
is computationally efficient. Thus miners have no cost to choosing the block content (including its ancestor) at the
moment the block is about to be published .

11

→

Let’s first define the states of interest for our strategy. Recall B0 is the state where the block
tree contains only the genesis block; B1,0 is the state after Miner 1 creates and withholds block
1 (Equation 6); B2,0 is the state after Miner 1 creates and withholds blocks 1 and 2 (Equation 6);
0 (Equation 4); B1,1 is the state after B1,0 if Miner 2
B0,1 is the state after Miner 2 publishes 1
publishes 2

→
0 (Equation 7). Additionally, define the following states.

• B1,2 is the state after B1,1 if Miner 2 creates block 3 and publishes 3

2:

→

B1,2 := ((
1
}
{
• B2,2 is the state after B1,2 if Miner 1 creates and withhold block 4:

0, 2, 3
}

,
1
}

0
}

3
{

→

→

),

{

{

2

,

).

→
These and other relevant states are depicted in Figure 3.

→

B2,2 := ((
{

0, 2, 3
}

,

3
{

2

),

0
}

,
1, 4
}

1, 4
}
{

{

).

(8)

(9)

Figure 3: Diagram representing states B0, B0,1, B0,2, B1,0, B1,1, B1,2 and B2,2. Block 0 has no
owner. All double circles are Miner 1’s hidden blocks. All circles are Miner 2’s published blocks.
Dashed lines are edges Miner 1 can publish.

12

Definition 3.1 (Selfish Mining [10]). Let (Xt)t≥0 be a mining game starting at state X0 = B0.
Miner 1 uses the Selfish Mining (SM) strategy, Figure 4, which takes the following actions:

• Wait at states B0 and B1,0.

• At state B0,1, capitulate to state B0.

• If X2 = B1,1 and Miner 1 creates block 3, publishes 3

1

→

→

0, then capitulates to state B0.

• If X2 = B1,1 and Miner 2 creates block 3 and publishes 3

state B0.

2, then Miner 1 capitulates to

→

• If X2 = B2,0, Miner 1 plays Wait until the first time step τ

1.
T2(Xτ )
|
(Xτ ) = T1(Xτ ) pointing to 0 and forking T2(Xτ ),

T1(Xτ )
|

3 where

|−

≥

=

|

At time step τ , Miner 1 publishes all of
then capitulates to state B0.

U

Figure 4: Markov chain representing the Selfish Mining strategy (left) and the Nothing-at-Stake
Selfish Mining strategy (right).

Theorem 3.2 (Equation 8 in [10]). For the selfish mining strategy

−
Moreover, Rev(SM) > α = Rev(FRONTIER) for α > 1/3.

−

Rev(SM) =

α2(4α2
α3

−
2α2

9α + 4)
α + 1

.

→

Our Nothing-at-Stake Selfish Mining is similar, with one key difference: In Selfish Mining,
Miner 1 capitulates immediately after a loss (specifically, if Miner 2 creates block 3 and publishes
2 from state B1,1, Miner 1 immediately accepts that block 1 is now permanently orphaned
3
and capitulates to B0). Nothing-at-Stake Selfish Mining instead remembers this orphaned block,
and considers bringing it back later. Importantly, Nothing-at-Stake Selfish Mining can wait to see
whether it finds many blocks (in which case it will try to publish the block 1) or not (in which case
it will let block 1 remain orphaned) before deciding what to do. Below is a formal description.

Definition 3.3 (Nothing-at-Stake Selfish Mining). Let (Xt)t≥0 be a mining game starting at state
X0 = B0. Miner 1 uses the Nothing-at-Stake Selfish Mining (NSM) strategy , right of Figure 4,
which takes the following actions:

• Wait at states B0, B1,0 and B1,2.

13

• At state B0,1, capitulate to state B0.

• If Xt = B1,1 and Miner 1 creates block 3, publishes 3

1

→

→

0, then capitulates to state B0.

• If Xt = B1,2 and Miner 2 creates block 4 and publishes 4

state B0.

3, then Miner 1 capitulates to

→

• If Xt = B2,2 and Miner 1 creates block 5, publishes 5

to state B0.

1

4

→

→

→

0, then Miner 1 capitulates

• If Xt = B2,2 and Miner 2 creates block 5 and publishes 5

3, Miner 1 capitulates to state
B1,1. That is, Miner 1 allows Miner 2 to walk away with blocks 2 and 3 and forgets about
unpublished block 1, but remembers unpublished block 4 in the hope of forking block 5 in the
future. The resulting state is equivalent to B1,1 since we can relabel block 3 as 0, 4 as 1 and 5
as 2.

→

• If X2 = B2,0, Miner 1 plays Wait until the first time step τ

1.
T2(Xτ )
|
(Xτ ) = T1(Xτ ) pointing to 0 forking blocks T2(Xτ ),

T1(Xτ )
|

3 where

|−

≥

=

|

At time step τ , Miner 1 publishes all of
then Miner 1 capitulates to state B0.

U

Let’s quickly understand why this strategy is not possible in the proof-of-work model. Zero
in on Miner 1’s behavior at B2,2. If Miner 1 creates block 5, Miner 1 publishes blocks 1, 4, 5, and
in particular has their block 4 point to block 1. However, if Miner 2 creates block 5, Miner 1
capitulates to state B1,1. From here, if Miner 1 creates block 6, they immediately publish 4 and 6,
having block 4 point to block 3.

That is, while using this strategy, Miner 1 does not decide where block 4 will point upon
mining it, but only upon publishing it. In a Proof-of-Work blockchain, Miner 1 must commit to
the ancestor of block 4 at time step 4, so this strategy cannot be used. Intuitively, a nothing-at-
stake selfish miner remembers an orphaned block to see if they might get lucky in the future.
Importantly, in the PoS model they can still wait to decide whether to try and bring this block
into the longest chain even after finding their next block (but before deciding where to publish it).
This extra power enables not only a slight improvement over standard selfish mining but also a
strategy the is strictly better than any other valid strategies for the Proof-of-Work mining game.

Theorem 3.4. For the nothing-at-stake selfish mining strategy,

Rev(NSM) =

4α2
−
α
1
−

α4 + 7α5

8α3
−
2α2 + 3α4

3α6
3α5 + α6 .
−

−

−
Moreover Rev(NSM) > α for α > 0.324718.

Recall Sapirshtein et al. [22] estimates αP oW

0.329. Thus Theorem 3.4 implies

≈

αP oS < 0.325 < 0.329

αP oW .

≈

Interestingly, Nothing-at-Stake Selfish Mining is not better than Selfish Mining for all α. In
Rev(SM) as a function of α, we observe Selfish

Figure 6, by plotting the difference Rev(NSM)
Mining is better than Nothing-at-Stake Selfish Mining for α > 0.458.

−

14

To get intuition why this happens, consider how SM and NSM differs in the event Miner 1
creates blocks 1, 4, 5 and Miner 2 creates blocks 2 and 3. By the end of the 5-th round, SM is at
state B2,0 while NSM just moved from state B2,2 to B0. The main intuition is that being at state
B2,0 is a highly profitable for Miner 1 when α is large. In the proof of Theorem 3.2, Appendix D,
blocks from the moment the game reaches state
we show Miner 1 creates, on expectation,
B2,0 until the moment the game first returns to state B0. Moreover, SM has a bigger probability
of being at state B2,0 than NSM because SM capitulates to state B0 once it reaches state B1,2 but
NSM does not.

α
1−2α

5:

Figure
Payoff comparison between
FRONTIER and Nothing-at-Stake Selfish
Mining.

Figure 6: Payoff comparison between Selfish
Mining and Nothing-at-Stake Selfish Mining.
Observe NSM is slightly better than SM for α
close to 1/3, but SM outperforms NSM for α >
0.458.

4 Trimming the Strategy Space

Analyzing the revenue of all possible strategies for Miner 1 is quite unwieldy. Therefore, our
first goal is to reduce the space of possible strategies to ones which are simpler to analyze while
guaranteeing that this simpler space still contains an optimal strategy. We accomplish this through
a series of reductions. This section provides a series of three “elementary” reductions which build
upon each other. That is, the conclusions in each section should not be surprising, although it
is challenging to rigorously prove this (examples throughout Appendix E are used to highlight
the challenges). Sections 4.1 through 4.3 provide our three reductions. Section 4.4 provides the
main theorem statement of this section: there is an optimal trimmed strategy. Many proofs are
omitted, and can be found in Appendix E.

4.1 Step 1: Timeserving
We first show that, w.l.o.g., every strategy only publishes blocks which will be ancestors of the
longest chain at the end of that round.

15

00.10.20.30.40.5,00.20.40.60.81Rev(:)Frontier vs NSMNothing-at-Stake Selfish MiningFrontier00.10.20.30.40.5,-4-202468Rev(NSM) - Rev(SM)#10-3SM vs NSMDefinition 4.1 (Timeserving). The action PublishSet(V (cid:48), E(cid:48)) is Timeserving if all blocks in V (cid:48)
immediately enter the longest chain (formally: if the action is taken during round n, then V (cid:48)
A(
PublishSet(V (cid:48), E(cid:48)) actions it takes are Timeserving.

⊆
(n))). A strategy is Timeserving if when played against FRONTIER, with probability 1, all

C

It is easy to see that FRONTIER is itself Timeserving: it publishes at most a single block at a
time, and that block is the new unique longest chain. We first argue that there exists an optimal
strategy against FRONTIER which is also Timeserving.

Theorem 4.2 (Timeserving). For any strategy π, there is a strategy ˜π that is Timeserving, takes a
γ (˜π) = Rev(n)
valid action at every step, and satisfies Rev(n)

γ (π) for all γ and n

N.

∈

We now state three basic properties of Timeserving strategies.

Observation 4.3. If π is Timeserving, then

(i) Whenever π publishes blocks, it publishes a single path. Formally, whenever π takes action
(bi < bi+1 for all i), then E(cid:48) contains
b for some b

PublishSet(V (cid:48), E(cid:48)) in round n, with V (cid:48) =
bi for all i
an edge bi+1

b1, . . . , bk
{
1], and an edge b1

V .

[k

∈
−
(ii) There are never two leaves of the same height. Formally, for all leaves q
= ˜q

→

∈

}
→

V , h(q)

= h(˜q).

∈

PublishSet(V (cid:48), E(cid:48)) which removes the old longest chain from the longest path, then

(iii) Whenever π forks, it publishes at least two blocks. Formally, whenever π takes the action
2.
Observation 4.3 gives us some nice structure about Timeserving strategies (and Theorem 4.2
asserts that it is w.l.o.g. to study such strategies). In particular, we only need to consider strategies
which publish a single path at a time. Formally, we may w.l.o.g. replace the action PublishSet(V (cid:48), E(cid:48))
with the action:

V (cid:48)
|

| ≥

Definition 4.4 (PublishPath). Taking action PublishPath(V (cid:48), u) with u
is equiv-
⊆ U
alent to taking action PublishSet(V (cid:48), E(cid:48)), where E(cid:48) contains an edge from the minimum element of
V (cid:48) to u, and an edge from v to the largest element of V (cid:48) strictly less than v, for all other v

V and V (cid:48)

V (cid:48).

∈

∈

→

4.2 Step 2: Orderly
Section 4.1 provides structure on when we may assume blocks are announced, but it does not
yet provide structure on which blocks are announced. Specifically, for all we know right now it
= k, the
could still be that when a strategy chooses to take action PublishPath(V (cid:48), u), and
precise k blocks it chooses to publish matter (e.g. in state B2,0 it could choose to publish 2
0
versus 1
0). Our next reduction shows that it is without loss to consider only strategies which
are Orderly, and always publish the earliest legal blocks. Intuitively, this gives the strategy more
S to refer to
flexibility later on. For simplicity of notation, we introduce the terms min(k)
the min
largest
S
S
|
|
{
elements in S.
Definition 4.5 (Orderly). The action PublishPath(V (cid:48), u) is Orderly if V (cid:48) = min(|V (cid:48)|)(
)).
blocks it could have possibly pub-
That is, an action is Orderly if it publishes the smallest
lished on top of u. A strategy is Orderly if when played against FRONTIER, with probability 1,
all PublishPath(

} ⊆
S to refer to the min
k,
{

smallest elements in S and max(k)

V (cid:48)
|

V (cid:48)
|

S
{

} ⊆

U ∩

(u,

∞

→

k,

|}

|}

S

{

|

|

,
·

) actions it takes are Orderly.
·

16

(cid:54)
(cid:54)
∈

Theorem 4.6 (Orderly). Let π be any Timeserving strategy. Then there is a valid, Timeserving,
Orderly strategy ˜π that satisfies Rev(n)

γ (π) for all γ and n

γ (˜π) = Rev(n)

N.

We conclude this section by noting that, after restricting attention to Orderly strategies, we

can further replace the action PublishPath(V (cid:48), u) with the action:
Definition 4.7 (Publish). Taking action Publish(k, u) with k
taking the action PublishPath(min(k)(

)), u).

(u,

∈

U ∩

∞

N+ and u

V is equivalent to

∈

4.3 Step 3: Longest Chain Mining
We now have structure on when blocks are published, and which blocks are published, but not yet
on where those blocks are published. Specifically, an orphaned chain is a path in Tree that used to
be part of the longest path A(
) but was overtaken by another path. Intuitively, a chain can only
C
be orphaned by Miner 1 and if Miner 1 is playing according to an optimal strategy, publishing
blocks which build on top of orphaned chains should be sub-optimal. We define a strategy as
Longest Chain Mining if it never publishes on top of a block in an orphaned chain.

A(

Definition 4.8 (Longest Chain Mining). Action Publish(k, u) is Longest Chain Mining (LCM) if
) is a block in the longest path. That is, an action is LCM if it builds on top of some block
u
within the longest path (not necessarily the leaf). A strategy is LCM if, with probability 1, every
Publish action it takes against FRONTIER is LCM.

∈

C

Previous work on Proof-of-Work mining games [16, 22] assume all strategies are LCM. For
Proof-of-Stake mining games, Theorem 4.9 proves that it is w.l.o.g. to assume an LCM strategy.

Theorem 4.9 (LCM). Let π be any Timeserving, Orderly strategy. Then there is a ˜π that is Time-
γ (π) for all
serving, Orderly, LCM, takes a valid action at every step, and satisfies Rev(n)
γ and n

γ (˜π)

Rev(n)

N.

≥

∈

4.4 Step 4: Trimmed
With Theorems 4.2, 4.6 and 4.9, we can immediately conclude that there exists an optimal strategy
satisfying several structural properties. We wrap up by showing one final property, and will show
that there exists an optimal strategy which is Trimmed.

Definition 4.10 (Trimmed Action). Action Publish(k, v) is Trimmed if v
is not the longest chain (that is, v
was created by Miner 2 (that is, u

), and u is the unique node in A(
C

C
T2).

=

) and whenever v
) with an edge to v, then u

A(
C

∈

Put another way, every Publish(k, v) either builds on top of the longest chain (in which case
it is vacuously Trimmed), or kicks out the successors of v. In the latter case, an action is Trimmed
if and only if the minimum successor of v was created by Miner 2.
Definition 4.11 (Trimmed Strategy). A strategy is Trimmed if every action it takes is either Wait
or Trimmed.

∈

We now conclude our main theorem of this section.

Theorem 4.12 (Trimming). For all strategies π, there is a Trimmed strategy ˜π that take valid actions
in every step, and Rev(n)

Rev(n)

N.

γ (π) for all γ and n

γ (˜π)

≥

∈

17

(cid:54)
5 Trimming the State Space

So far, we have greatly simplified strategies which we need to consider. However, we still have
not even established that there exists an optimal strategy which is recurrent. That is, for all we
know so far, the optimal strategy might need to store not only the entire longest chain, but also
all blocks which have ever been published, and all unpublished blocks which they ever created.
The goal in this section is to establish that an optimal strategy exists which is recurrent: it will
eventually (with probability 1) reach a “checkpoint” which the strategy treats as a new genesis
block that will never be overridden.

5.1 Checkpoints and Weak Recurrence
We iteratively define a sequence of blocks P0, P1, . . . in the longest path A(
C
as follows.

) to be checkpoints

Definition 5.1 (Checkpoints). Based on the current state, checkpoints are iteratively defined as
follows.

• The first checkpoint, P0, is the genesis block.

• If Pi−1 is undefined, then Pi is undefined as well.

• If Pi−1 is defined, then v is a potential ith checkpoint if:

– v > Pi−1.
).
– v
– Among blocks that Miner 1 created between Pi−1 and v (including v, not including Pi−1),

A(

∈

C

more are in the longest chain than unpublished. That is,

A(
C
|

)

∩

(Pi−1, v]

T1

∩

| ≥

1

|U

∩

.
(Pi−1, v]
|

• If there are no potential ith checkpoints, then Pi is undefined.

• Else, then Pi is defined to be the minimum potential ith checkpoint.
Note that each Pi is again a random variable, meaning that a priori Pi might change over
time, including from undefined to defined. For example, Pi(n) would denote the ith checkpoint,
as defined by the state after the conclusion of the nth round (we will later prove that there exists
an optimal strategy which never changes or undefines Pi once it is defined. But this will be a
result, and not a definition).

Figure 7: Example of a state and its
checkpoints. Blocks with thicker lines
denote blocks that are checkpoints and
blocks with thinner lines denote blocks
that are not checkpoints. From Defini-
tion 5.1, blocks 0, 1, 5, and 7 are check-
points.

18

Example 5.2. Consider the state in Figure 7 where blocks 0, 1, 5, and 7 are the checkpoints. By
definition, block 0 is the base-case and is always a checkpoint. Block 1 is a checkpoint because Miner
1 has no unpublished blocks in the interval (0, 1]. Block 2 is unpublished and thus not a checkpoint.
Block 3 is not a checkpoint because Miner 1 has one unpublished block in the interval (1, 3] and zero
published block in the path from 3
1 (not counting block 1). From a similar reasoning, blocks
4 and 6 are not checkpoints. Block 5 is a checkpoint because Miner 1 has one unpublished block in
the interval (1, 5] and one block in the path 5
1 (not counting block 1). Block 7 is a
checkpoint because Miner 1 has no unpublished blocks in the interval (5, 7].

→

→

→

→

3

4

The main result of this section is stated below, and claims that there exists an optimal strategy

which treats checkpoints like the genesis block.

Definition 5.3 (Checkpoint Recurrent). A strategy π is Checkpoint Recurrent if when π is played
against FRONTIER:

• For all i

N, if Pi changes from undefined to defined, Pi never changes again (in particular,

this implies that once Pi is defined, it remains in A(

) forever).

∈

C

• Immediately when Pi becomes defined, neither player has any unpublished blocks > Pi.

When bullet one is satisfied, checkpoints are never overridden. Given that bullet one holds,
bullet two implies that immediately when Pi is defined, it is essentially a genesis block (because
bullet one holds, no unpublished blocks < Pi can ever enter the longest chain. If bullet two also
holds, then there are no unpublished blocks > Pi, so there are no relevant unpublished blocks,
and Pi is in the longest chain forever, just like the genesis block in round 0). This implies that
when optimizing over Checkpoint Recurrent strategies, it suffices to consider only strategies that
reset its state space whenever a new checkpoint is defined. That is, whenever a new checkpoint
is defined Miner 1 capitulates to state B0.

Theorem 5.4 (Weak-Recurrence). There exists an optimal strategy which is checkpoint recurrent.

The weak-recurrence theorem provides a useful tool to reduce the state space of optimal
strategies; however, it does not say how often (if ever) the block tree reaches a new checkpoint.
Fortunately, each new checkpoint give us important information about the payoff of a strategic
miner: if the block tree never reaches a checkpoint, then at all times Miner 1 has at least half of their
blocks unpublished. Next, we check such strategies are not better than FRONTIER before diving
into the proof of the weak-recurrence theorem.

Proposition 5.5. If π is checkpoint recurrent and P1 is never defined, then Rev(π)

Rev(FRONTIER).

≤

As a first step toward proving upper bounds in the revenue, we will require a simply but

useful fact about rate of growth of the block tree.

Lemma 5.6 (Minimum Growth Rate). For any mining game starting at state X0 = B0,

lim inf
n→∞

h(
C

(Xn))
n

1

−

≥

α, with probability 1.

(10)

Corollary 5.7. For any optimal strategy π, Rev(FRONTIER) = α

Rev(π)

.

α
1−α

≤

≤

19

Both Lemma 5.6 and Corollary 5.7 will be useful to prove Proposition 5.5. We need to un-
derstand one property of checkpoints, and then we can complete the proof. Intuitively, Proposi-
tion 5.8 and Corollary 5.9 just apply the definition of checkpoints to relate the number of blocks
that Miner 1 has unpublished vs. published in the longest path.

Proposition 5.8. For all v

A(

),

∈
(i) If v is a checkpoint, then for all checkpoints Pi > v,

C

(v, Pi]

T1

)

A(
C
|
, then

(ii) If v is not a checkpoint and Pi = max
Pj : Pj < v
{

∩
.
A(
|
C
|
(iii) If v is not a checkpoint, then for all checkpoints Pi > v,
.
(v, Pi]
A(
)
|
C
|
) is not a checkpoint and let Pi be the highest checkpoint below v.
Corollary 5.9. Suppose v
Then Miner 1 publishes in the longest path less than half of all blocks they created from time Pi + 1
< |T1∩(Pi,v]|
to v. That is,
2
∩
Proof. Bullet (ii), Proposition 5.8, implies

∩
(v, Pi]

∩
(Pi, v]

| ≥ |U ∩

A(
C
|

∩
T1

A(
C

(Pi, v]

|U ∩

|U ∩

T1

T1

>

<

∩

∈

∩

∩

}

)

)

|

|

|

.

.
(v, Pi)
|
(Pi, v]

)

(Pi, v]

A(
C
|

.
A(
> 2
C
|
|
∩
. Then, the number of unpublished
Suppose for contradiction
| ≥
blocks plus blocks in the longest path would be strictly bigger than the number of blocks Miner
1 created, a contradiction.

(Pi, v]
|
|T1∩(Pi,v)|
2

|
(Pi, v]

A(
C
|

(Pi, v]

|U ∩

T1

T1

T1

+

∩

∩

∩

∩

∩

)

)

Proof of Proposition 5.5. From the strong law of large numbers, Corollary 5.9 and Lemma 5.6,

|

≤

T1

(Xn))

lim sup
n→∞

lim sup
n→∞

∩
(Xn))
|

A(
C
|
A(
|

|T1∩(0,n]|
2n
|A(C(Xn))|
n

|T1∩(0,n]|
2n
|A(C(Xn))|
C
n
where the last inequality uses the fact α
1/2. Intuitively, if Miner 1 never reaches a checkpoint,
≤
then they are publishing at most αn/2 blocks in expectation by round n (and clearly at most αn/2
α)n blocks
of these can be in the longest path). But Lemma 5.6 asserts that there are at least (1
in expectation in the longest path by round n. Therefore, the fraction produced by Miner 1 cannot
be too high (and in particular, honesty would have been better in expectation).

lim supn→∞
lim inf n→∞

α) ≤

α/2

α.

(1

−

≤

≤

−

We prove Theorem 5.4 in two steps, Section 5.2 and Section 5.3.

5.2 Step 1: Checkpoint Preserving
The first step is to show the existence of an optimal strategy that never forks a checkpoint. For
that, we will give an explicitly procedure f to transform any strategy π that could fork check-
points into another strategy f (π) that does not fork checkpoints satisfying Rev(f (π))
Rev(π).
) reaches finality with respect to strategy π if, with
Definition 5.10 (Finality). A block q
probability 1, π takes no action that removes q from longest path.
Definition 5.11 (Checkpoint Preserving). A strategy π is checkpoint preserving if whenever a
new checkpoint Pi is defined, Pi reaches finality with respect to π.
Theorem 5.12. For every strategy π, there is a trimmed, checkpoint preserving strategy f (π) with
Rev(f (π))

Rev(π).

A(
C

≥

∈

≥

20

5.3 Step 2: Opportunistic
We have shown the existence of an optimal strategy that would never fork the longest chain
C
when it becomes a checkpoint. However, to be checkpoint recurrent, we must also show Miner 1
when the longest chain is a checkpoint. The converse can
has no unpublished blocks bigger than
only happen when Miner 1 is about to take action PublishPath(Q, v) and max Q will reach finality
with respect to Miner 1’s strategy, but Miner 1 would leave an unpublished block q > max Q.
The intuition is that Miner 1 can wait instead of publishing Q pointing to v in current round. If
Miner 1 creates the next block, Miner 1 can publish Q pointing to v as before. If Miner 2 creates
the next block, Miner 1 can still take action PublishPath(Q
to the longest
path.

, v) adding Q
}

∪{

∪{

C

}

q

q

Definition 5.13 (Opportunistic). Let π be a strategy and let B be a state. Action PublishPath(Q, v)
is opportunistic with respect to B and π if

• PublishPath(Q, v) is a valid action at state B.

• If π takes action PublishPath(Q, v) where max Q reaches finality with respect to π (Defini-

tion 5.10), then Q =

(B)

(v,

∩

U

).
∞

Strategy π is opportunistic if at all states B, π waits or takes an opportunistic action with respect to
B and π.

Theorem 5.14. For any strategy π, there is a valid, trimmed, checkpoint preserving and opportunis-
tic strategy f (π) with Rev(f (π))

Rev(π).

≥

Proof of Theorem 5.4. Theorem 5.14 directly implies the weak-recurrence theorem since a check-
point preserving and opportunistic strategy is also checkpoint recurrent.

5.4 Step 3: Strong Recurrence
So far, we have shown that there exist an optimal strategy that is checkpoint recurrent. That is,
once we reach a state Xt where
(Xt) is a checkpoint, Miner 1 capitulates to state B0. Next, we
will aim for a stronger result.

C

Theorem 5.15 (Strong recurrence). There exists an optimal checkpoint recurrent and positive re-
current strategy.

For a proof sketch, observe the Weak Recurrence Theorem implies there exists an optimal
strategy π that is checkpoint recurrent. We will assume π is not positive-recurrent (i.e., the
expected time E [τ ] to define a new checkpoints is infinite) and derive that Rev(π)
α =
with prob-
Rev(FRONTIER). The case where Miner 1 never defines checkpoint P1 – i.e., τ =
ability 1 in Proposition 5.5 – give us intuition why the claim should hold to the more general
case where E [τ ] =
Rev(FRONTIER), we just observe FRONTIER is
≤
checkpoint and positive recurrent. Thus there exists an optimal checkpoint and positive recurrent
strategy.

. Once we proof Rev(π)

∞

∞

≤

21

6 Nash Equilibrium

We briefly give intuition behind our second main result, which leverages Theorem 5.15 to lower
bound αPoS.

Theorem 6.1. For α
FRONTIER.

≤

0.308, FRONTIER is an optimal strategy for Miner 1 when Miner 2 follows

→

We defer the proof to Appendix G. The main idea behind the proof is to show that Nothing-
at-Stake Selfish Mining is almost optimal when α < 1/3. The following proof-sketch highlights
the main insights of the proof.
Selfish Mining is optimal when Miner 2 creates the first block (when α < 1/3). We know that there
is an optimal checkpoint recurrent strategy, Theorem 5.15. Therefore, it is optimal for Miner 1
to capitulate to state B0 if Miner 2 creates and publishes 1
0 (which is exactly what selfish
mining does).
Selfish Mining is optimal after Miner 1 creates and withholds blocks 1 and 2. Starting from state
B2,0, selfish mining will wait until the first time step τ when the lead decrease to a single block
to fork all of Miner 2 blocks. We show that waiting until time τ is indeed optimal for any value
of α (which is not surprising). Less obvious is why Miner 1 must publishes all his blocks at time
τ when they still have a lead of a single block. Indeed we should not expect this to be optimal for
all values of α. If Miner 1 waits at time τ and creates the next block, they will again have a lead
blocks
of two blocks and can resume to “selfish mine”. Here, we shown that Miner 1 creates
on expectation from the time they have a lead of two blocks to the moment the lead decreases
to a single block. This quantity can be arbitrarily large but it is at most 1 when α < 1/3 so it
is a risky action for Miner 1. That is because if (instead) Miner 2 creates next block, there is a
tie (Miner 1 does not have enough blocks to fork the longest chain) and we can show that the
. Formally,
probability Miner 1 will ever publish any blocks created before time τ is at most α
1−α
we will prove Miner 1 maximizes rewards by waiting until time τ and immediately publishing all
unpublished blocks (which is what selfish mining does).
There is little window to improve Selfish Mining when Miner 1 creates and withhold block 1 and Miner
2 publishes 2
0. Winning the tie-breaking at state B1,1 is another source of revenue for Miner
1. In fact, the only improvement that Nothing-at-Stake Selfish Mining provides over standard
Selfish Mining is increasing the probability that Miner 1 wins the tie-breaking between blocks
1 and 2. From a similar argument from previous bullet, we can show the probability of adding
. Next, we observe Miner 1 has no more advantage of
block 1 to the longest path is at most α
1−α
2 at state B1,1 than being the creator of the block at
being the creator of the block at height (cid:96)
height (cid:96)
1 at state B0. We formalize this intuition by showing that, by ignoring blocks 1 and
2, any action taken on a state reachable from B1,1 can be converted into an action for an state
reachable from B0. The only advantage state B1,1 provides over state B0 is that Miner 1 has a
probability (of at most α
1−α
Wrapping up. From the discussion above, state B1,1 is the only state where we could possible
search for a better strategy than Nothing-at-Stake Selfish Mining when α < 1/3, but there is
little window to improve Miner 1’s action at state B1,1. As a result, we will obtain FRONTIER is
optimal when α

) of adding block 1 to the longest path.

0.308 as desired.

α
1−2α

→

≥

−

≤

22

7 Conclusion

We study miner incentives in longest-chain proof-of-stake protocols with perfect external ran-
domness. We show both that such protocols are strictly more vulnerable to manipulation than
those based on proof-of-work (Theorem 3.4), but also that it is a Nash equilibrium for all min-
ers to follow the longest-chain protocol as long as no miner has more than
0.308 of the total
stake (Theorem 6.1). Our main technical results characterize potentially optimal strategies in a
complex, infinite-state MDP (Theorem 5.15). Our work motivates several natural open problems:

≈

• Theorem 5.15, combined with the analysis in Theorem 6.1, provides strong structure on
optimal strategies. It is therefore conceivable that a simulation-based approach with MDP
solvers (as in [22]) could estimate αPoS to high precision.

• Our Theorem 6.1 provides a reduction from incentive-compatible longest-chain proof-of-
stake protocols to designing a randomness beacon and a slashing protocol. Clearly, it is
important for future work to construct these primitives, although these are well-known
and ambitious open problems. In our setting, it is further important to understand what
are the minimal assumptions on a randomness beacon or slashing protocol necessary to
leverage Theorem 6.1.

References

[1] Nick Arnosti and S. Matthew Weinberg. Bitcoin: A natural oligopoly. In 10th Innovations
in Theoretical Computer Science Conference, ITCS 2019, January 10-12, 2019, San Diego, Cal-
ifornia, USA, volume 124 of LIPIcs, pages 5:1–5:1. Schloss Dagstuhl - Leibniz-Zentrum f¨ur
Informatik, 2019.

[2] Dan Boneh, Joseph Bonneau, Benedikt B¨unz, and Ben Fisch. Verifiable delay functions. In

Annual international cryptology conference, pages 757–788. Springer, 2018.

[3] Joseph Bonneau, Jeremy Clark, and Steven Goldfeder. On bitcoin as a public randomness

source. IACR Cryptol. ePrint Arch., 2015:1015, 2015.

[4] Jonah Brown-Cohen, Arvind Narayanan, Alexandros Psomas, and S Matthew Weinberg.
Formal barriers to longest-chain proof-of-stake protocols. In Proceedings of the 2019 ACM
Conference on Economics and Computation, pages 459–473, 2019.

[5] Miles Carlsten, Harry A. Kalodner, S. Matthew Weinberg, and Arvind Narayanan. On the
In Proceedings of the 2016 ACM SIGSAC
instability of bitcoin without the block reward.
Conference on Computer and Communications Security, Vienna, Austria, October 24-28, 2016,
pages 154–167. ACM, 2016.

[6] Xi Chen, Christos H. Papadimitriou, and Tim Roughgarden. An axiomatic approach to block
rewards. In Proceedings of the 1st ACM Conference on Advances in Financial Technologies, AFT
2019, Zurich, Switzerland, October 21-23, 2019, pages 124–131. ACM, 2019.

23

[7] Jeremy Clark and Urs Hengartner. On the use of financial data as a random beacon.

EVT/WOTE, 89, 2010.

[8] Phil Daian, Rafael Pass, and Elaine Shi. Snow white: Robustly reconfigurable consensus and
applications to provably secure proof of stake. In Financial Cryptography and Data Security
- 23rd International Conference, FC 2019, Frigate Bay, St. Kitts and Nevis, February 18-22, 2019,
Revised Selected Papers, volume 11598 of Lecture Notes in Computer Science, pages 23–41.
Springer, 2019.

[9] Rick Durrett. Probability: theory and examples, volume 49. Cambridge university press,

2019.

[10] Ittay Eyal and Emin G¨un Sirer. Majority is not enough: Bitcoin mining is vulnerable.

In
International conference on financial cryptography and data security, pages 436–454. Springer,
2014.

[11] Matheus V. X. Ferreira, Daniel J. Moroz, David C. Parkes, and Mitchell Stern. Dynamic
In Proceedings of
posted-price mechanisms for the blockchain transaction-fee market.
the 3rd ACM conference on Advances in Financial Technologies, AFT ’21, New York, NY,
USA, 2021. Association for Computing Machinery. URL https://arxiv.org/abs/
2103.14144.

[12] Yossi Gilad, Rotem Hemo, Silvio Micali, Georgios Vlachos, and Nickolai Zeldovich. Algo-
rand: Scaling byzantine agreements for cryptocurrencies. In Proceedings of the 26th Sympo-
sium on Operating Systems Principles, pages 51–68, 2017.

[13] LM Goodman. Tezos: A self-amending crypto-ledger position paper. Aug, 3:2014, 2014.

[14] Gur Huberman, Jacob Leshno, and Ciamac Moallemi. Monopoly without a monopolist: An
economic analysis of the bitcoin payment system. Review of Economic Studies, 2020.

[15] John Kelsey, Lu´ıs TAN Brand˜ao, Rene Peralta, and Harold Booth. A reference for random-
ness beacons: Format and protocol version 2. Technical report, National Institute of Stan-
dards and Technology, 2019.

[16] Aggelos Kiayias, Elias Koutsoupias, Maria Kyropoulou, and Yiannis Tselekounis. Blockchain
mining games. In Proceedings of the 2016 ACM Conference on Economics and Computation,
pages 365–382, 2016.

[17] Aggelos Kiayias, Alexander Russell, Bernardo David, and Roman Oliynykov. Ouroboros:
A provably secure proof-of-stake blockchain protocol. In Annual International Cryptology
Conference, pages 357–388. Springer, 2017.

[18] Jacob Leshno and Philipp Strack. Bitcoin: An impossibility theorem for proof-of-work based

protocols. American Economics Review: Insights, 2020.

[19] Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system. Technical report, 2007.

24

[20] Michael Neuder, Daniel J. Moroz, Rithvik Rao, and David C. Parkes.

ior in the tezos proof-of-stake protocol. Cryptoeconomic Systems, 0(1), 4 2021.
10.21428/58320208.27350920.
pubpub.org/pub/neuder-selfish-behavior-tezos.
https://cryptoeconomicsystems.pubpub.org/pub/neuder-selfish-behavior-tezos.

Selfish behav-
doi:
URL https://cryptoeconomicsystems.

[21] Michael O Rabin. Transaction protection by beacons. Journal of Computer and System

Sciences, 27(2):256–267, 1983.

[22] Ayelet Sapirshtein, Yonatan Sompolinsky, and Aviv Zohar. Optimal selfish mining strategies
in bitcoin. In International Conference on Financial Cryptography and Data Security, pages
515–532. Springer, 2016.

[23] Gavin Wood et al.

Ethereum: A secure decentralised generalised transaction ledger.

Ethereum project yellow paper, 151(2014):1–32, 2014.

25

In Appendix A, we give relevant real analysis background. In Appendix B, we give relevant
probability theory background. In Appendix C, we introduce the Markov Decision Process for-
mulation. In Appendix H, we provide a table of notation. In the remaining sections, we provide
omitted proves.

A Real Analysis Background

Let a1, a2, . . . be a sequence of real numbers. The limit of a sequence a1, a2, . . . exists if the
sequence converges to a

R. We write

∈

The limit inferior and limit superior of a sequence a1, a2, . . . is defined as

a,

or

an

→

lim
n→∞

an = a.

lim inf
n→∞

an := lim
n→∞

inf
k≥n

ak := sup
n≥1

inf
k≥n

ak,

lim sup
n→∞

an := lim
n→∞

sup
k≥n

ak := inf
n≥1

sup
k≥n

ak,

respectively. The limit of a1, a2, . . . exists and is equals to a if and only if

lim inf
n→∞

an = lim sup

n→∞

an = a.

Lemma A.1 (Properties of lim inf and lim sup). Whenever the right hand side is well-defined (not
of the form

).

+

or 0

±∞

∓∞

· ±∞

(i) Supperadditivity. lim inf n→∞(an + bn)

(ii) Subadditivity. lim supn→∞(an + bn)
(iii) Supermultiplicativity. lim inf n→∞(an

≤

lim inf n→∞ an + lim inf n→∞ bn.

≥
lim supn→∞ an + lim supn→∞ bn.

bn)

·
bn)

lim inf n→∞ an

≥
lim supn→∞ an

lim inf n→∞ bn.

lim supn→∞ bn.

·

·

(iv) Submultiplicativity. lim supn→∞(an
(v) If an

a, lim inf n→∞ an + bn = a + lim inf n→∞ bn.

≤

·

→

(vi) If an

(vii) If an

(viii) If an

→

→

→

a, lim supn→∞ an + bn = a + lim supn→∞ bn.
a and bn is bounded, lim inf n→∞ anbn = a lim inf n→∞ bn.

a and bn is bounded, lim supn→∞ anbn = a lim supn→∞ bn.

26

B Probability Theory Background

B.1 Convergence of Random Variables
Definition B.1 (Almost sure convergence). We say a sequence of random variables X1, X2, . . .
converges almost surely to random variable X (and we write Xn

X) if

a.s.
→

Proposition B.2. The following are equivalent:

P r

(cid:104)

lim
n→∞

Xn = X

(cid:105)

= 1.

X.

• Xn

a.s.
→
• limn→∞ P r [

• limn→∞ P r [

∞
i=n {|
∞
i=n {|

Xi

Xi

X

X

−

−

1/k

| ≥

< 1/k

|

] = 0 for any k
}
] = 1 for any k
}

≥

≥

1.

1.

∪

∩

B.2 Laws of Large Numbers
Definition B.3 (Absolutely Integrable). A random variable X is absolutely integrable if E [

.
∞
Lemma B.4 (Strong Law of Large Numbers (SSLN), Theorem 2.4.1 in [9]). Let X1, X2, ... be an
i.i.d. sequence of copies of absolutely integrable random variable X. Then

X
|

] <
|

1
n

n
(cid:88)

i=1

Xi

a.s.
→

E [X] .

∞

and P r [X

0] = 1, then 1
n

Remark: The strong law can be generalized for the case where X is non-negative and not absolutely
integrable. That is, if E [X] =
Definition B.5 (Counting Process). The interarrival times τ1, τ2, ... is an i.i.d. sequence of positive
and absolutely integrable random variables. Let Xn = (cid:80)n
i=1 τi with X0 = 0. The random variable
Nn = (cid:80)∞
Observation B.6. If Nn = (cid:80)∞
Lemma B.7 (SLLN for Counting Processes, Theorem 2.4.7 in [9]). If Nn = (cid:80)∞
ing process, then

1Xi≤n denotes the counting proces associated with interarrival times τ1, τ2, . . ..
1Xi≤n is a counting process, for all n

n < XNn+1.
1τi≤n is a count-

N, XNn ≤

a.s.
→ ∞

i=1 Xi

(cid:80)n

≥

i=1

i=1

i=1

∈

.

Nn
n

a.s.
→

1
E[τi]

.

C Markov Decision Process

In this section, we show we can obtain a closed form for the revenue of positive recurrent strate-
gies by using the strong law of large numbers. See Appendix B for basic background on probabil-
ity theory. A sequence of random variables X1, X2, . . . converges almost surely (or with probability
1) to random variable X (and we write Xn
X) if P r[limn→∞ Xn = X] = 1. Our first result,
is a generalization of Corollary 9 in [22] to Proof-of-Stake mining games with positive recurrent
strategies.

a.s.
→

27

Theorem C.1. Let X0, X1, . . . be a mining game starting at state X0 = B0 where Miner 1 follows
a positive recurrent strategy. Let Rk = (cid:80)τ
t=1 rk(Xt−1, Xt) be Miner k’s total reward before the first
time step τ

1 where Miner 1 capitulates to state B0. Then

≥

(i) For k = 1, 2, |A(C(Xn))∩Tk|

n

E[Rk]
E[τ ]

.

a.s.
→

(ii) Rev(π) =

E[R1]
E[R1+R2]

.

Proof. Without loss of generality assume X0 = B0 and let n0 = 0. Let Xn1, Xn2, . . . be the
be Miner k’s reward from time
sequence of states where Miner 1 capitulates to state B0. Let Rk
i
step ni−1 to time ni. That is,
Rk
2, . . . and n1

A(
|
C
Observe Rk
n0, n2
Miner 1 capitulates to state B0 at time step ni). Additionally E [ni+1
∞
1’s strategy is positive recurrent. Thus define the counting process Nn = (cid:80)∞
Observation B.6, nNn ≤
of Miner 1’s blocks in the longest path is an increasing function of time. Thus

Tk
n1, . . . are i.i.d. sequences of random variables (because
because Miner
1ni≤n. From
n < nNn+1, and since Miner 2 never forks Miner 1’s blocks, the number

(Xni−1))

(Xni))

A(
C

1, Rk

ni] <

| − |

i =

Tk

.
|

−

−

−

i=1

∩

∩

Observe (cid:80)Nn

i=1 Rk

i =

A(
|

C

(XnNn ))
n

T1

|

∩

A(
|

C

(Xn))
n

T1

|

∩

≤

A(
|

C

(XnNn+1))
n

T1

|

.

∩

≤
Tk

∩

|
A(
C
|

(XNn))
i=1 R1
i
Nn

A(
C
|
(cid:80)Nn
Nn
n
as n

is a telescoping sum. Thus

(Xn))
n

T1

|

∩

Nn + 1
n

(cid:80)Nn+1

i=1 R1
i
Nn + 1

.

Observe Nn

E[τ ] <
(because Miner 1’s strategy is positive recurrent). From the SLLN for Counting Processes

≤
(because Miner 1’s strategy is recurrent) and E[Rk]

→ ∞

→ ∞

≤

≤

∞
(Lemma B.7) and SLLN (Lemma B.4),

Nn
n

1
Nn

Nn(cid:88)

i=1

Rk
i

a.s.
→

E[Rk]
E[τ ]

and Nn
n

1
Nn + 1

Nn+1
(cid:88)

i=1

Rk
i

a.s.
→

E[Rk]
E[τ ]

.

From the Sandwich Theorem,

A(
|

C

(Xn))
n

T1

|

∩

E[R1]
E[τ ]

.

a.s.
→

Observe the height of the block tree is also a increasing function of time. Thus with an similar
(Xn)) between h(
argument from above, we sandwich h(
C
h(

(XnNn+1)) to get

(XnNn )) and h(

C

C

Nn
n

C

(Xn))
n

a.s.
→

.

E[R1 + R2]
E[τ ]
E[R2]
E[τ ]

a.s.
→

From linearity of expectation, we get |A(C(Xn))∩T2|
first bullet,

n

. This proves the first bullet. From the

Rev(π) = E

(cid:20)

lim inf
n→∞

This proves the second bullet.

A(

1
n |

C

1
n|
(Xn)
∩

A(
C
T1
|

(Xn)
+ 1
n |

∩
A(

|
(Xn))

T1

C

(cid:21)

=

E[R1]
E[R1] + E[R2]

.

T2

|

∩

28

Theorem C.1 will be useful to study the revenue of positive recurrent strategies such as the
nothing-at-stake selfish mining strategy—which will be positive recurrent by design. It also come
in hand when studying optimal strategies; however, it require us to assume the existence an opti-
mal positive recurrent strategy. In fact, Sapirshtein et al. [22] and Kiayias et al. [16] relies on the
structure of proof-of-work mining games to conjecture the existence an optimal positive recur-
rent strategy. In proof-of-stake, there is no obvious incentives for a miner to forget unpublished
blocks. Thus it is not clear if an optimal strategy would be (positive) recurrent (recall Exam-
ple 2.6 where Miner 1 might be motivated to fork their own blocks). As one of our technical
contributions, Theorem 5.15 proves proof-of-stake mining games admits optimal strategies that
are positive recurrent.

Additionally, Sapirshtein et al. [22] uses Theorem C.1 to compute an optimal positive recurrent
strategy by optimizing a Markov Decision Process (MDP). Instead of explicitly computing optimal
strategies, we will use their MDP to give sufficient conditions on α for which FRONTIER is an
optimal strategy (Theorem 6.1). Given a parameter λ, their MDP defines the real-valued function
rλ as the reward from transition from state B to B(cid:48):

Definition C.2 (Mining Game Reward). For λ
function rλ from states B and B(cid:48) to

∈

R, the mining game reward is the real-valued

rλ(B, B(cid:48)) := (1

λ)r1(B, B(cid:48))

λr2(B, B(cid:48)).

−

−

(11)

Remark: For any states Xt, Xt+1, and Xt+2, the mining game reward function satisfy the identity

rλ(Xt, Xt+1) + rλ(Xt+1, Xt+2) = rλ(Xt, Xt+2).

(12)

Definition C.3 (Value Function). The objective function for mining game (Xt)t≥0 is a real-value
function

from state B to

V
(cid:12)
(cid:12)X0 = B(cid:3) = E (cid:2)rλ(X0, X1) +
π(B) := E (cid:2)rλ(X0, Xτ )
λ

λ
π(X1)

V

1τ (cid:54)=1

X0 = B(cid:3) ,
|

·

(13)

λ
π

V

the expected game reward from a mining game starting at state X0 = B and stopping at state Xτ
where τ
as the
1 is the first time step Miner 1 capitulates to state B0. Define the value function
real-valued function from state B to

≥

V

where λ∗ = maxπ Rev(π) and π∗ is an optimal positive recurrent strategy.

(B) :=

V

λ∗
π∗(B)

V

(14)

First, they observed that by setting λ∗ = maxπ Rev(π), any positive recurrent strategy π that

maximizes

λ∗
π (B0) is an optimal positive recurrent strategy.

Lemma C.4. Let π∗ be an optimal positive recurrent strategy and let λ∗ = Rev(π∗). Then π∗
arg maxπ

(B0) = 0.

λ∗
π (B0) and

∈

V

V

V

Proof. Given two positive recurrent strategies π and π(cid:48), the following claim allow us to compare
their revenue.

Claim C.5. For positive recurrent strategies π and ˜π,

29

λ

(i)

V

π(B0) = 0 if and only if λ = Rev(π).
Rev(˜π)
π

(ii) Rev(π) > Rev(˜π) if and only if

(B0) > 0.

V

(iii) Rev(π) < Rev(˜π) if and only if

V

Rev(˜π)
π

π(B0) < 0.

Proof. Recall τ denotes the first time step Miner 1 capitulates to state B0, Equation 5, and let
Rk = (cid:80)τ

t=1 rk(Xt−1, Xt). Observe

λ

π(B0) = E (cid:2)(1

λ)R1

λR2

X0 = B0
|

−

−

(cid:3) .

V

From Theorem C.1,

E [R1] E [R2]
E [R1] + E [R2]

= Rev(π)E (cid:2)R2(cid:3)

and

E [R1] E [R2]
E [R1] + E [R2]

= (1

−

Rev(π))E (cid:2)R1(cid:3) .

Taking the difference and setting λ = Rev(π),

Rev(π)
π

V

(B0) = E (cid:2)(1

Rev(π))R1

(1

Rev(π))R2(cid:3)

−
E [R1] E [R2]
E [R1] + E [R2] −

−
−
E [R1] E [R2]
E [R1] + E [R2]

= 0.

=

This proves (i). Rewrite

λ

π(B0) as

V

λ

π(B0) = E(cid:2)R1]

V

−

λE[R1 + R2].

Note that E[R1 + R2] is the expected height of the block tree at time τ . Since τ
2 mines a block with probability 1
α > 1/2. Thus
least 1

1 and Miner
α > 0, the expected height of the block tree at time τ is at

π(B0) is strictly decreasing function of λ. This proves (ii), and (iii).

≥

−

λ

−

Thus if π∗ is an optimal positive recurrent strategy with λ∗ = Rev(π∗), we directly obtain
(B0) = 0. Therefore,

λ∗
π∗(B0) = 0. For any positive recurrent strategy π,

λ∗
π (B0)

(B0) =

V

≤ V

states Xt. As a corollary, we recover the well known Bellman’s principle of optimality.

V

λ∗
π (B0) (Equation 13), then π must maximize

λ∗
π (Xt) for all subsequent

Lemma C.6 (Bellman’s Principle of Optimality). For all states B, for all positive recurrent strategies
π,

(B).

(B)

maxπ Rev(π)
π

V

≥ V

Proof. Let π∗ be an optimal positive recurrent strategy with λ∗ = Rev(π∗). Let (X π
t )t≥0 be a
mining game starting from state X0 = B0 when Miner 1 follows strategy π. From Definition C.3,

λ∗

(B0) =

V

V

and from Lemma C.4,
and let π : π(Xt) be all strategies conditioned on π taking action π(Xt) at state X Half

1 ) + V (X π∗
X π∗
1 )
|
λ∗
π (B0) = 0. Let π(Xt) be the action π takes at state X Half
. Note X π
t

π∗(B0) = E (cid:2)rλ∗(B0, X π∗

(B0) = maxπ

0 = B0

(cid:3) ,

V

V

t

t

30

V
π∗

V
arg maxπ

λ∗
π (B0).
∈
Thus if π maximizes

V

V

V

depends only on actions taken up to time t. Thus

(B0) = max

π

V

= max
π(X0)

= max
π(X0)

E (cid:2)rλ∗(B0, X π

1 ) +

(cid:20)

E

V
rλ∗(B0, X π(X0)

1

(cid:104)

E

rλ∗(B0, X π(X0)

1

) +

λ∗
X π
π (X π
1 )
|

0 = B0

(cid:3)

) + max

λ∗

π (X π(X0)

1

X π(X0)
)
0
|

π:π(X0) V
(X π∗
1 )

V

X π(X0)
0
|

(cid:105)

= B0

.

(cid:21)

= B0

The last line observes the expected value takes its maximum by taking action π(X0) = π∗(X0).
Thus

λ∗
π (B) for all positive recurrent π and states B.

(B) = maxπ

λ∗
π (B)

V

V

≥ V

We will use Lemma C.6 to witnesses when a particular action is optimal for a particular state
B. That is, we can guess a particular strategy π takes an optimal action at state B and assume
the optimal strategy π∗ takes a distinct action. By deriving
(B), we conclude that
π’s action at state B is indeed optimal.

λ∗
π (B)

≥ V

V

D Omitted Proofs from Section 3

First, we compute the expected number of blocks Miner 1 creates from the moment it reaches
state X2 = B2,0 until they capitulate to state B0. For that, we will define a coupling between the
mining game X2, X3, . . . , Xτ with a biased one-dimensional random walk.

1, Nt = Nt−1 + 1 with probability α; otherwise, Nt = Nt−1

Lemma D.1. Let (Nt)t≥0 be a biased one-dimensional random walk with initial state N0
for t
≥
1 : Nt = N0
−
1. Let X = (cid:80)τ
Nt
−
Y = (cid:80)τ

≥
. We say the state Nt increments if Nt+1 = Nt + 1 and decrements if Nt+1 =
1Nt=Nt−1+1 be the number of state increments up to time τ . Similarly let

1Nt=Nt−1−1 be the number of state decrements up to time τ . Then

∈
1. Let τ = min

Z and
t

1
}

−

t=1

{

t=1

α

E [Y ] =

E [X] =

α
2α
2α
2α
1 and X = 0, Y = 1 (with probability 1

1
Proof. For the case N1 = N0
α). For the case
N1 = N0 + 1 (with probability α), the expected number of state increments until the Markov
process first returns to state N0 is equals to E [X]. Once the Markov process first returns to state
N0, the expected number of time steps until the Markov process first reaches state N0
1 is also
E [X]. Thus

E [τ ] =

−
−

1
1

−

−

−

−

−

1

1

.

E [X] = α(1 + E [X] + E [X])
= α + 2αE [X] .

Solving for E [X] proves E [X] = α
X + Y , linearity of expectation proves E [τ ] = 1

1−2α

as desired.

1−2α

. A similar argument proves E [Y ] = 1−α
1−2α

. Since τ =

Lemma D.2. Let X0 = B2,0 and let τ = min
. Then the
T2(Xτ )
+ 1
}
|
|
{
|
expected number of blocks Miner 1 creates from time 1 to τ is E [
. Moreover,
1] = α
T1(Xτ )
1−2α
| −
|
.
the expected number of blocks Miner 2 creates from time 1 to τ is 1−α
1−2α

T1(Xτ )
|

1 :

≥

=

t

31

Proof. Define the biased one-dimensional random walk Yt =
1 for t
0.
| −
≥
Then τ is the first time step where Yτ = 0 (observe Y0 = 1). The random variable
T1(Xt)
2
| −
|
τ . Thus from Lemma D.1, the
counts the number of time steps where Yt = Yt−1 + 1 for t
expected number of blocks Miner 1 creates from time 1 to τ is E [
and the
2] = α
T1(Xt)
|
as desired.
expected number of blocks Miner 2 creates from time 1 to τ is 1−α
1−2α

T1(Xt)
|

T2(Xt)

| − |

| −

1−2α

≤

Proof of Theorem 3.2. Let (Xt)t≥0 be a mining game starting at state X0 = B0 where Miner 1 uses
1 be the first time step where Miner 1 capitulates to
the SM strategy (Definition 3.1). Let τ
state B0. If Miner 1 did not capitulate by time step t = 3, it is because X2 = B2,0. In this case,
. Thus SM is positive
τ =
T2(Xτ )
|
recurrent and from Lemma C.4,

≥
1. From Lemma D.2, E[τ ] < 3+ 2α
1−2α

T1(Xτ )
= 2
|

T1(Xτ )
|

|−

+

|

|

where λ = Rev(SM). To compute this quantity, we consider the following events:

SM(B0) = E [rλ(B0, Xτ )
λ

0 =

V

X0 = B0]
|

• When the game reaches state B0,1, Miner 1 capitulates to state B0. Miner 2 owns one block

in the longest path. Thus the reward is rλ(B0, Xτ ) =

λ.

−

• When the game reaches state B2,0, Miner 1 wait until the first time step τ where

=
1, then Miner 1 publishes blocks T1(Xτ ) and capitulates to state B0. Miner 1

T2(Xτ )
|

|

blocks in the longest path. From Lemma D.2, the expected reward is

T1(Xτ )
|
owns

| −
T1(Xτ )
|

|

E [rλ(B0, Xτ )

X2 = B2,0] = E [T1(Xτ )
X2 = B2,0] (1
|
|

−

• When the game reaches state B1,1, we consider two cases:

(cid:18)

λ) =

2 +

(cid:19)

α

2α

1

−

λ).

(1

−

– Miner 1 creates block 3, publishes 3

owns two blocks in the longest path. Thus the reward is 2(1

1

→

→

0 and capitulates to state B0. Miner 1
λ).

– Miner 2 publishes 3

2, then Miner 1 capitulates to state B0. Miner 2 owns two

→
blocks in the longest path. Thus the reward is

−

2λ.

−

Substituting in the equation above,

λ
SM(B0) = α2

(cid:18)

2 +

α

(cid:19)

(1

1

2α

−

0 =

V

λ) + 2α2(1

α)(1

−

λ)

−

2α(1

−

α)2λ

(1

−

−

α)λ.

−

−
Solving for λ and observing λ = Rev(SM) proves the theorem.

Proof of Theorem 3.4. Consider the mining game starting at state X0 = B0. Let τ
1 be the
first time step Miner 1 capitulates to state B0. Let’s first check the Markov chain induced by the
NSM strategy (Definition 3.3) is positive recurrent. If Miner 1 did not capitulate by time step 2,
1. From
X2
B2,0, B1,1
T2(Xτ )
|
|
Lemma D.2, E [τ
. For the case X2 = B1,1, the probability that the
α).
Markov process returns to state B0 before returning to state B1,1 is α + (1

. For the case X2 = B2,2, τ =
}
X2 = B2,2] = 3 + 2α
|

| −
α)2 + α2(1

T1(Xτ )
= 2
|

T1(Xτ )
|

1−2α <

∈ {

∞

≥

+

|

−

−

32

Thus E [τ
X2 = B1,1] = 2 +
|
and from Lemma C.4,

1
α+(1−α)2+α2(1−α) <

. Thus the Markov chain is positive recurrent

∞

where λ = Rev(NSM). To compute the expected value above, we consider the following events:

0 =

NSM(B0) = E [rλ(B0, Xτ )
λ
X0 = B0]
|

V

• When X1 = B0,1, Miner 1 capitulates to state B0. Miner 2 owns one block in the longest

path. Thus the reward is

λ.

−
• When X2 = B2,0, Miner 1 waits until the first time step τ

T1(Xτ )
T2(Xτ )
|
|
|
1, then Miner 1 publishes blocks T1(Xτ ) and capitulates to state B0. Miner 1 owns
blocks in the longest path at time τ . From Lemma D.2, the expected reward is

3 where

|−
T1(Xτ )
|
|

≥

=

X2 = B2,0] = E [T1(Xτ )
E [rλ(B0, Xτ )
|

X2 = B2,0] (1
|

−

(cid:18)

λ) =

2 +

(cid:19)

α

2α

1

−

λ).

(1

−

• When the game reaches state Xt equivalent to state B1,1, there is four scenarios:

– Miner 1 creates block 3, then publishes 3

1 owns two blocks in the longest path. Thus the reward is 2(1

1

→

→

0 and capitulates to state B0. Miner
λ).

– Miner 2 publishes 4

3
three blocks in the longest path. Thus the reward is

→

→

2, then Miner 1 capitulates to state B0. Miner 2 owns

3λ.
−
2 while Miner 1 creates block 4 and 5. Then Miner 1 publishes
0 and capitulates to state B0. Miner 1 owns three blocks in the longest

→

– Miner 2 publishes 3

– Miner 2 publishes 5

λ).
2 while Miner 1 creates and withholds block 4. Then
Miner 1 capitulates to state B1,1 allowing Miner 2 to stay with blocks 2 and 3. Thus
the reward is

2λ (repeat until Miner 1 capitulates to state B0).

→

→

−

3

4

5
→
path. Thus the reward is 3(1

→

→

1

−

−
From the work above, the reward when X2 = B1,1 is

E [rλ(X0, Xτ )
X2 = B1,1] =
|
∞
(cid:88)

(α(1

α)2)i(1

α(1

−

−

i=0

α)2) (E [rλ(X0, Xτ )
X2 = B1,1, Xτ = B0]
|

−

−

2iλ)

where E [rλ(X0, Xτ )
X2 = B1,1, Xτ = B0] is the expected reward conditioned on Miner 1 capit-
|
ulating to Xτ = B0 given X2 = B1,1. Thus

E [rλ(X0, Xτ )
X2 = B1,1, Xτ = B0] =
|

2α(1

λ)

−

−

3(1
−
1
−

α)2λ + 3α2(1
α(1

α)2

−

α)(1

λ)

.

−

−

To get a closed form, recall the geometric series (for x < 1)

∞
(cid:88)

i=0

xi =

1

−

1

x

∞
(cid:88)

i=1

ixi =

x

−

(1

x)2 .

and

33

Substituting in the equation above, we get

λ
NSM(B0) = α2

0 =

V

+

α(1

α)

−
α(1

α)2

−

1

−

(cid:18)

2 +

α

2α

(cid:18)

1

−
2α(1

(cid:19)

λ)

(1

−

−

(1

−

α)λ

λ)

−

−

3(1

−

α)2λ + 3α2(1

α)(1

λ)

−

−

−

2α(1

−

(cid:19)
.

α)2λ

Solving for λ and observing λ = Rev(NSM) proves

Rev(NSM) =

as desired.

4α2
−
α
1
−

−

α4 + 7α5

8α3
−
2α2 + 3α4

3α6
3α5 + α6

−

−

E Omitted Proofs from Section 4

E.1 Timeserving Reduction
We will now define a reduction that takes as input a strategy π, and produces a new strategy ˜π.
The strategy ˜π will simulate π, which we clarify below.

Definition E.1 (Simulating a strategy). A strategy ˜π may wish to simulate π, and take actions
based on this simulation. Specifically, we will add a subscript of π to random variables like Tree, V,
,
C
etc. to denote the state of this simulation. Formally, Xπ denotes “what the state of variable X would
have been, had Miner 1 been using strategy π all along (with the same γ)”.

If there is no subscript of π, then these variables retain their original meaning (and refer to the

state when Miner 1 uses their actual strategy ˜π).

Definition E.2 (Timeserving Reduction). For any strategy π, define the Timeserving Reduction
of π to take the following action during round n:

• If A(
C

π(n))

published, don’t publish further.

∩ U

∅

(n) =

, then Wait. That is, if the longest chain from simulating π is already

• Else, PublishSet(A(
(n)
C
in Eπ(n). That is, if the longest chain from simulating π is not yet published, publish whatever
part of the chain is not yet published.

(n), E(cid:48)), where E(cid:48) contains all pointers leaving A(
C

π(n))

π(n))

∩U

∩U

Essentially, the Timeserving Reduction of π simply holds off on publishing blocks which are
not yet in the longest chain, and only publishes them when necessary to support a longest chain.
Below, note that the conclusion of Theorem 4.2 does not necessarily hold against arbitrary strate-
gies for Miner 2, but it does hold against FRONTIER (so we must necessarily use properties of
FRONTIER in the proof).

Proof of Theorem 4.2. Let ˜π denote the Timeserving Reduction of π. Here is the main idea: all
actions taken by the FRONTIER strategy only depend on the longest chain, and not on what other
nodes are published. This is formally stated in the following observation.

34

Observation E.3. Let π, ˜π be two strategies such that when used against FRONTIER, with proba-
bility 1, for all n,
˜π(n). Then in every round FRONTIER takes identical actions against π
and ˜π.

π(n) =
C

C

It is clear that π and ˜π have the same longest chain at the end of each round, by definition of ˜π.
Specifically, ˜π will never publish a block that has not yet been published by π, and it makes sure
the longest chain under π is always published. Therefore, FRONTIER will take the same actions
against both. Because FRONTIER is taking the same actions, and the longest chain is the same at
the end of each round, this guarantees that Rev(π) = Rev(˜π).

Finally, it is clear that ˜π is Timeserving. The longest chain at the end of round n is indeed

π(n), and ˜π only publishes ancestors of

π(n) (if it publishes at all).

C

C
Proof of Observation 4.3. Proof of (i). Ancestors of the longest chain form a single path. If π does
not publish a single path, then it is not possible for all of these nodes to immediately be ancestors
of the longest chain.
Proof of (ii). Suppose for contradiction there is some state where Tree has two distinct leaves
= ˜q with the same height, and consider when this first happens. First, q and ˜q can’t have been
q
published by the same action by Property (i). If they are published during distinct actions, then
w.l.o.g. let q be published before ˜q (and therefore the most recent action to update Tree must
have published ˜q).

) unless it is

Because q has the same height as ˜q and was published first, ˜q is not in

. Also, because ˜q is
itself. Therefore, no Timeserving strategy could have
a leaf, it cannot be in A(
published ˜q (because Miner 1 is Timeserving, and FRONTIER only publishes a longest chain no
matter what), a contradiction.
Proof of (iii). Suppose for contradiction Miner 1 forks by publishing a single block q on top of r.
If Miner 1 can fork the longest chain with a single block, then there must have previously been
two leaves of the same height, a contradiction to (ii).

C

C

C

E.2 Orderly Reduction
Example E.4. Consider the game in Figure 8 where Miner 1 creates blocks 1, 2, 3, 4 and 5. Looking at
, 0) taken in round 5 is not Orderly.
strategy π on the left, observe that the action PublishPath(
4, 5
}
{
Instead, if an Orderly action is to publish two blocks pointing to 0 in round 5, it must publish 2
1
switch is shown in the center.

→
0. This initially suggests a local fix: simply swap the roles of 1 and 4, and also 2 and 5. This

→
Unfortunately, there is a problem: while it is certainly safe to publish 1

0
(this makes it only easier to build later blocks, as 1 < 4), it is not safe to publish 4 where 1 used
to be.
, 0) in round 6, and then the action
1
}
{
, 1) in round 7. Simply swapping all the 1s and 4s results in an infeasible action
PublishPath(
3, 6
}
{
in round 7 because the edge 3

Indeed, π previously used the action PublishPath(

0 instead of 4

4 is invalid.

the action PublishPath(
, 0) is itself not Orderly, and should instead be changed to PublishPath(
{
as is done in ˜π on the right of Figure 8. The same reduction should again be applied in round 7.

Instead, what we want is to apply this reduction ad infinitum. Indeed, the key observation is that
3
}
This example illustrates our reduction (defined formally in Definition E.5), but also establishes

4
}
{

→

→

→

the importance of doing a reduction “all at once” rather than a sequence of local changes.

35

, 0),

(cid:54)
Figure 8: Mining game with a strategy π (left) where the action in round 5 is not Orderly. An
intermediate “reduction” which is infeasible (center), and a transformed strategy ˜π (right) where
all actions are feasible and Orderly.

We now provide our Orderly Reduction, which generalizes the ideas in Example E.4.

Definition E.5 (Orderly Reduction). Let π be any timeserving strategy. The Orderly Reduction of
π is the strategy ˜π which does the following:

• Maintain a mapping σ : N+

N+. Initialize σ(b) = b for all b

N+.

→
• During round n + 1, if π takes action Wait from state TreeHalf

∈
(n), then Wait. That is, if π

π

waits in the simulation, then also wait.

• Else, if π takes the action PublishPath(V (cid:48), u) from state TreeHalf

(n), let V (cid:48)(cid:48) := min|V (cid:48)|(
)). Take the action PublishPath(V (cid:48)(cid:48), σ(u)), and make the following updates to σ:

(σ(u),

π

U ∩

∞
– For all v

V (cid:48), if v is the (cid:96)th smallest element of V (cid:48), update σ(v) to be the (cid:96)th smallest
element of V (cid:48)(cid:48). That is, update σ so that it maps newly-published blocks under π to
newly-published blocks under ˜π, and is monotone increasing within this domain.

∈

– For all v

)π, if v is the (cid:96)th smallest element of (
U

)π, update σ(v) to be the (cid:96)th
. That is, update σ so that it maps still-unpublished blocks under π

smallest element of
to still-unpublished blocks under ˜π, and is monotone increasing within this domain.

(
U

∈

U

Intuitively, this reduction hard-codes that every PublishPath(
) action is Orderly, and uses
,
·
·
) to remember which “new blocks” after the reduction correspond to the “old blocks” before
σ(
·
the reduction. Specifically, the intent of σ is to be an isomorphism between Treeπ and Tree, and
at all times. Note
to also map the (cid:96)th smallest element of (
that the second bullet updating σ(
) as a useful helper for proofs, and
) is simply to maintain σ(
·
·
not necessary to actually execute the reduction.
Observe that, by definition, whenever ˜π takes a PublishPath(
,
·

) action, that action is Orderly
·
(as long as it is valid). So our only task is to confirm that every action is valid, and also that the
payoffs are identical against FRONTIER. Observe further that the only way the PublishPath(
)
·

)π to the (cid:96)th smallest element of

,
·

U

U

36

∞

action could be invalid is if there simply aren’t
(σ(u),

) clearly come after σ(u), so the action would otherwise be valid.

elements of

V (cid:48)
|

(σ(u),

∩

U

|

i

): all elements of

∞

We first prove a helper lemma, which describes how σ evolves over time. In this lemma (and
subsequent proofs), it will be helpful to introduce the following notation. Observe that every
) changes. In order to cleanly
time a PublishPath action is taken by Miner 1, that the function σ(
·
). In order to
reference “the state of σ(
), before the action was taken”, we use the notation σold(
·
·
cleanly reference “the state of σ(
). More
·
generally, we will add a subscript of old to reference the state of a variable before a referenced
action is taken, and new to reference the state of a variable after a referenced action is taken.

), after the action was taken”, we use the notation σnew(
·

Lemma E.6. Consider any action PublishPath(V (cid:48), u) action taken by Miner 1 using π. If it further
V (cid:48), σold(v) > σold(u), then for all v, the following hold:
holds that for all v

∈

• If v is already published, then σnew(v) = σold(v).

• If v

∈
• If v /
∈

V (cid:48), then σnew(v)

V (cid:48), then σnew(v)

σold(v).

σold(v).

≤

≥

|

Proof. Observe that bullet one clearly holds, as we don’t change σ(v) for any v which is already
published. The two interesting bullets will follow from the following observation: If for all v
V (cid:48),
σold(v) > σold(u), then the set σold(V (cid:48)) is valid to publish on top of σold(u). Because V (cid:48)(cid:48) is the smallest
V (cid:48),
elements which are valid to publish on top of σold(u), this immediately implies: For all v
V (cid:48)
|
if v is the (cid:96)th smallest element of V (cid:48), then the (cid:96)th smallest element of V (cid:48)(cid:48) is at most σold(v). As
σnew(v) is exactly the (cid:96)th smallest element of V (cid:48)(cid:48), we conclude bullet two.

k)th smallest element of ((

Now that we have bullet two, bullet three readily follows. Consider when v was previously
)π)old. If there are k elements smaller than v in V (cid:48), then v is now
the (cid:96)th smallest element of ((
k elements smaller than σold(v) in
the ((cid:96)
−
)new is at least as large as the (cid:96)th smallest element
V (cid:48)(cid:48), then the ((cid:96)
)old (which is exactly σold(v)). Observe, however, that there are exactly k elements smaller
of (
than σold(v) in σold(V (cid:48)). By bullet two, this means that there are indeed at least k elements smaller
than σold(v) in V (cid:48)(cid:48), and we conclude bullet three.

U
k)th smallest element of (

)π)new. If there are

≥

−

∈

∈

U

U

U

We use this technical lemma to conclude the following, which describes how Treeπ and Tree

evolve isomorphically over time.

Corollary E.7. At all points in time, the following hold:

• The graphs Treeπ and Tree are isomorphic. Specifically:

– For all v

Vπ, σ(v) is published by ˜π during the same round that v is publishedby π,

∈

and these are the only nodes in V .
Eπ, (σ(u), σ(v))

– For all (u, v)

∈

∈

• σ(

) is injective and surjective (from N+ onto N+).
·

• For all v created by Miner 2, σ(v) = v.

37

E, and these are the only edges in E.

• For any v /
∈

Vπ, and any u

N+, v > u

σ(v) > σ(u).

∈

⇒
Proof. We’ll prove the claim by induction. Clearly at initialization, all claims hold because both
Treeπ and Tree contain just the genesis block and σ(b) = b for all b.

Now assume that all four claims hold prior to an action being taken (in the execution with
π) for inductive hypothesis, and we will establish that all four claims continue to hold after the
action is taken. Clearly, if that action is Wait, then the execution with ˜π is also wait, and neither
the graphs nor σ change, so the claim still holds.

If that action is a PublishPath action taken by Miner 2, it will publish a single block r on top of
π).
the longest chain
= σ(
C
Therefore, Miner 2 will take the action PublishPath(
π)). This
{
maintains that σ maps Treeπ to Tree. Because no changes are made to σ, bullets two, three, and
four continue to hold.

π. Observe that by inductive hypothesis, specifically bullet one, that
C
, σ(
C

) := PublishPath(
{

C

C

}

}

r

r

,

The interesting case to consider is if the action taken is PublishPath V (cid:48)u by Miner 1 using
π. Then the action taken by ˜π is PublishPath(V (cid:48)(cid:48), σ(u)). Because we update σ(V (cid:48)) := V (cid:48)(cid:48) upon
publishing (while being monotone increasing), this would guarantee that the first bullet continues
to hold, if we can guarantee that the action PublishPath(V (cid:48)(cid:48), σ(u)) is valid. However, bullet four
readily lets us claim this. Indeed, because PublishPath(V (cid:48), u) is valid for π, we have both: (a)
V (cid:48). Bullet four immediately yields that
all v
σold(v) > σold(u) for all v
nodes which can be published
on top of σold(u), and therefore PublishPath(V (cid:48)(cid:48), σold(u)) is valid. This establishes that bullet one
continues to hold.

V (cid:48) are not in (Vπ)old and (b) v > u for all v

V (cid:48), meaning that there are at least

V (cid:48)
|

∈

∈

∈

|

Now we just need to confirm that the three bullets regarding σ(

) continue to hold. It is easy
·
to see that σ remains injective and surjective. It is also easy to see that σ remains unchanged
for any blocks created by Miner 2, so bullet three continues to hold. It is also easy to verify that
bullet four continues to hold when both v and u are unpublished. This is simply because σ(
) maps
·
the (cid:96)th smallest unpublished element under π to the (cid:96)th smallest unpublished element under ˜π. If
u is published, then we will use Lemma E.6.

Indeed, the fact that bullet four previously held lets us conclude that v > u

σold(v) >
σold(v) (if v was not published, and therefore
σold(u) prior to the action. By Lemma E.6, σnew(v)
≥
σold(u) if u is published by the action (or was
(Vπ)new). By the same Lemma E.6, σnew(u)
/
∈
≤
already published). Therefore, we get the following chain of inequalities (the outer two are by
Lemma E.6, the middle inequality is by inductive hypothesis).

⇒

v /
∈

(Vπ)new AND u

(Vπ)new AND v > u

σnew(v)

σold(v) > σold(u)

σnew(u),

∈

⇒
as desired. We have now completed the inductive step, and shown that if all four properties
hold prior to an action, they all hold after that action as well. Because they all hold at initialization,
they hold at all times.

≥

≥

Proof of Orderly Theorem 4.6. The proof readily follows from bullet one of Corollary E.7. Indeed,
because Treeπ and Tree are isomorphic, and because σ(b) is published by ˜π during the same
action that π publishes b for all b, it’s always the case that
π). The fact that they
are isomorphic also implies that every action taken by ˜π is valid), and also that for all n, γ:
Rev(n)

= σ(
C

C

γ (π) = Rev(n)

γ (˜π).

38

E.3 Longest Chain Mining Reduction
As in the previous sections, we devise a reduction from any strategy which is Timeserving, and
Orderly, but not LCM, to one which is Timeserving, Orderly, and LCM.

Definition E.8 (LCM Reduction). Let π be any Timeserving, Orderly strategy. The LCM Reduction
of π for Player 1 is the strategy ˜π which does the following:

• During round n + 1, if π takes action Wait from state TreeHalf

(n), then Wait. That is, if π

π

waits in the simulation, then also wait.

• Else, if π takes the action Publish(k, u) from state TreeHalf
) with hπ(u) = h(v). Take the action Publish(k, v).

A(

π

C

(n), let v be the unique block in

In bullet two above, it should be clear that the desired block v is unique if it exists. It is not

immediately obvious that v exists (but we will prove that it does).

Figure 9: Instance example for the Fork Ownership Lemma. Empty squares represent blocks that
are irrelevant to the claim. Lemma E.10 states that if Miner 1 plays a strategy which is Timeserving
and LCM, and q is a block in the longest chain, and there is a block ˜q with the same height as q,
then Miner 1 must have created q and w (but perhaps not r, and perhaps not ˜q).

The following observation will be useful, both in proving Theorem 4.9, and in drawing con-

clusions from it.

Observation E.9. Let π be any LCM strategy. Then if v is ever published, but not in the longest
chain, v will never again enter the longest chain (formally, if v
)
for the rest of the game).

), then v /
∈

V has v /
∈

A(
C

A(

∈

C

Proof. If v /
), then all of v’s descendants are also not in A(
C
∈
can point to v or any of its descendants, and the longest chain will never contain v.

A(
C

). Therefore, no LCM action

Next, we prove a helper lemma stating that Miner 1 must have created all blocks in the longest
chain since the most recent fork. Figure 9 provides an example illustrating the claims of the lemma.
The intuition is as follows: if Miner 1 is using a Timeserving, LCM strategy, and ˜q was published,
then ˜q was at some point in the longest chain. Therefore, Miner 2 (using FRONTIER) would not
publish elsewhere (so if a new longest chain is created, it must have come entirely from Miner 1).

Lemma E.10 (Fork Ownership Lemma). Let π be any Timeserving, LCM strategy. Let q
be a block in the longest chain, and let ˜q
q, h(˜q) = h(q)). If r
between r and q (including q, not necessarily including r). Formally, A(
C

)
C
=
) is the least common ancestor of ˜q and q, then Miner 1 created all blocks

A(
V be another block of the same height (formally: ˜q

(r, q]

T1.

A(

⊆

∈

∩

∈

∈

C

)

39

(cid:54)
Proof. Observe that if we can prove the lemma when ˜q is a leaf, then we will have in fact proved
the lemma for all ˜q (for arbitrary ˜q, simply pick any leaf ˜q2 which is a descendent of ˜q, and apply
the lemma statement with q2, the node in A(
) with h(q2) = h(˜q2). The lemma statement for
q2, ˜q2 implies the lemma statement for q, ˜q). So we proceed assuming that ˜q is a leaf.

C

(r, ˜q] denote the ancestors of ˜q (including ˜q, up to but not including r).
(r, q] denote the same for q. Recall that as r is the least common ancestor of q, ˜q,

∩

Let now ˜Q := A(˜q)

Let Q := A(q)
these two sets are disjoint.

∩

Observe before continuing that because Miner 1 is Timeserving (and Miner 2 is using FRONTIER,

which is also Timeserving), and that ˜q is a leaf, that ˜q is the longest chain immediately following
the action in which it is published. In particular, this means that ˜q is published before q.

∈
Q, so w

Our goal is to prove that Miner 1 created every block in Q, so assume for contradiction that
Q which was created by Miner 2. First, observe that w clearly was not published
Q,

there exists a w
during the same action as ˜q, as FRONTIER publishes only a single block at a time (and w
while ˜q /
∈

Observe also that w cannot have been published before ˜q. Indeed, if w were published before
˜q, then immediately after ˜q is published, w is both published and not in the longest chain. By
Observation E.9, w would never again be in the longest chain, contradicting that q becomes the
longest chain.

= ˜q).

∈

r

}

r
∪ {

Finally, we show that w cannot be published by an action after ˜q. Indeed, once ˜q is published,
can possibly be the longest chain (because ˜q is longer), and therefore
no element of Q
FRONTIER would publish on top of ˜q rather than any block in Q
. Therefore, Miner 2
}
could not possibly have published a block w in Q (which necessarily would point to a block in
Q

) after ˜q was already published.

∪ {
In summary, we have shown that no block w

Q could have been created by Miner 2 during
∈
the same round that ˜q was published (because Miner 2 is using FRONTIER), after ˜q was published
(also because Miner 2 is using FRONTIER), or before ˜q was published (because Miner 1 and Miner
2 are both LCM). Therefore, Miner 2 cannot have created any blocks w
Q, and Miner 1 must
have created them all, completing the proof.

r
∪ {

} \ {

∈

}

q

From here, a complete proof of Theorem 4.9 becomes unwieldy to do entirely in one shot
(like Theorem 4.6). Instead, we will complete the proof by changing π one action at a time, and
interleaving these changes with the Orderly Reduction. Specifically, we will need the following
definitions:

Definition E.11 (N -LCM and N -Orderly). A strategy is N -LCM if, when played against FRONTIER,
every action it takes up to and including round N is LCM (with probability 1). A strategy is N -
Orderly if, when played against FRONTIER, every action it takes up to and including round N is
Orderly.

Observe that a strategy is LCM/Orderly if and only if it is N -LCM/N -Orderly for all N .

Towards Theorem 4.9, we will now define a simpler one-step reduction. Importantly, note

that we return to the language PublishPath instead of simply Publish.

Definition E.12 (Step-N LCM Reduction). Let π be any Timeserving, N -Orderly, N -LCM strategy.
The Step-N LCM Reduction of π for Player 1 is the strategy ˜π which does the following:

40

(cid:54)
• During round any round

= N + 1, if π takes the action Wait, then also Wait. If π takes the

action PublishPath(V (cid:48), u), take action PublishPath(V (cid:48), u).

• During round N + 1, if π takes action Wait from state TreeHalf

(N ), then Wait. That is, if π

π

would have waited, then also wait.

• Else, if π takes the action PublishPath(V (cid:48), u) from state TreeHalf

(n), let v be the unique block
) with hπ(u) = h(v). That is, let v be the block of height hπ(u) within the longest chain

in A(
C
of TreeHalf(n). Take the action PublishPath(V (cid:48), u).

π

Figure 10: On the left is the history for a Timeserving and Orderly strategy π. In the middle is
the Step-9 LCM Reduction of π, which is not 10-Orderly. The history on the right further applies
the Orderly Reduction.

Importantly, observe that the Step-N Reduction only changes the action taken in step N + 1,
and in a very simple way: it tries to publish exactly the same blocks, just on top of a different
node. This makes it significantly simpler to prove claims about validity. See Figure 10 for an
example.

Lemma E.13. Let π be any Timeserving, N -Orderly, N -LCM strategy, and let ˜π be its Step-N LCM
Reduction. Then ˜π is Timeserving, N -Orderly, (N + 1)-LCM, and takes a valid action during every
γ (π).
step. Moreover, for all γ, n: Rev(n)
Proof. Observe, importantly, that ˜π takes identical actions to π except during round N + 1, and
moreover that during round N + 1 π attempts to publish the exact same path at the exact same

γ (˜π)

Rev(n)

≥

41

    (cid:54)
≤

height (just perhaps at a different location). This means that all the desired properties immediately
follow if we can prove that the action taken in round N + 1 is valid. Indeed, as long as ˜π can
publish the same path (just perhaps in a different location), this implies that the longest chain will
be the same (just perhaps with different ancestors), and therefore that Miner 2 using FRONTIER
will use the same action in every future round, and therefore that all actions taken by Miner 1
will be Timeserving and valid in future rounds. It is also clear that if the action taken by ˜π is
valid, then it is LCM. Also note that we have not claimed that ˜π is (N + 1)-Orderly.

So, to confirm that the action taken during round N + 1 is valid, we just need to confirm that
whenever π tries to publish a set of nodes V (cid:48) on top of u (and this is valid), that it is also valid to
publish the same V (cid:48) on top of v (where v
) has the same height as u). Note that if we knew
that v

u, the claim would be trivial, but we might have v > u.

A(
C

∈

∩

∩

⊆ U

(N )

(N )

(r, v] =

, and V (cid:48)
∅

(N ), and w > u > r for all w

To this end, we use Lemma E.10 and the fact that π is N -Orderly. Let r denote the least
common ancestor of v and u. Then whenever v
= u, Lemma E.10 asserts that Miner 1 published
not only v, but the entire path from v to r (not necessarily including r). Moreover, because π
(r, v] (otherwise, π must have previously
is N -Orderly, there must not be any blocks in
U
taken a non-Orderly action). But now, as u > r, this immediately implies that any V (cid:48)
(N )
⊆ U
which is valid to publish on top of u is also valid to publish on top of v. Specifically, because
V (cid:48) as well.
U
This concludes the first half of Lemma E.13: we have just shown in the previous path that the
action taken in round N + 1 is valid. The previous paragraphs establish that this implies that
all actions taken in all rounds are valid, Timeserving, and LCM. Because no actions are changed
during the first N rounds, ˜π is still N -Orderly. The remaining step is to confirm that for all γ, n:
Rev(n)

γ (˜π)
To see this, observe we have just argued that
= A(

(n) for all n. The only difference is
that perhaps A(
π(n))
C
contains the path (r, u], while A(
(n)) contains instead the path (r, v], but they must otherwise be
C
the same. Fortunately, Lemma E.13 also asserts that Miner 1 created every node in (r, u]. Therefore,
we have both that
T1
π(n))
A(
|
|
for all n. This directly implies that Rev(n)
γ (˜π)

C
(n)). In fact, the only potential difference is that perhaps A(
C

A(
C
|
γ (π) for all γ, n.

for all n, and also that

V (cid:48), w > v for all w

γ (π).

(n))
|

A(
C
|

π(n) =

A(
C

Rev(n)

Rev(n)

π(n))

π(n))

| ≥ |

(n))

T1

≥

=

∩

∈

∈

∩

C

C

C

|

≥

Now, we can complete the proof of Theorem 4.9.

Proof of Longest Chain Mining Theorem 4.9. The proof will boil down to showing that we can al-
ternate between the Step-N LCM Reduction and the Orderly Reduction to implement the LCM
reduction. Specifically, recursively define π0 := π, and πN +1 to be the Orderly Reduction applied
to the Step-N LCM Reduction applied to πN . We make a series of observations.
Observation E.14. For all N , πN is Orderly, N -LCM, and Timeserving.

Proof. We prove by induction. π0 is clearly Orderly, 0-LCM, and Timeserving. Assume then that
πN is Orderly, N -LCM, and Timeserving. Then the Step-N LCM Reduction applied to πN results
in a strategy which is (N + 1)-LCM, and Timeserving. The Orderly Reduction applied to this
strategy does not change where blocks are published (up to the isomorphism), but only which
blocks are published. Therefore, the Orderly reduction preserves Timeserving and (N + 1)-LCM,
but makes the strategy Orderly, as desired.

Observation E.15. For all N , and all n

≤

N + 1, ˜π and πN take the same action during round n.

42

(cid:54)
(cid:54)
Proof. We also prove this by induction. The claim clearly holds for N = 0. Assume now that it
holds for some N and we will prove it for N + 1. πN and πN +1 take the same actions for the
first N + 1 rounds, so the inductive hypothesis immediately implies the desired conclusion for
all n
N + 1. We just need to prove that the action taken in round N + 2 by ˜π and πN +1 are the
same. Indeed, they will publish the same number of blocks, and at the same location. Because
both are Orderly, they will publish the same set of blocks as well.

≤

By the two observations above, we immediately conclude that for all N , ˜π takes a valid action
during round N , and is also N -LCM. Therefore, ˜π takes a valid action during every step, and
is LCM. Also, it is clear that as long as ˜π takes a valid action during each timestep that ˜π is
Timeserving and Orderly.

E.4 Trimmed Strategies
Proof of Theorem 4.12. We can immediately apply Theorems 4.2, 4.6 and 4.9 to conclude that there
exists a strategy ˆπ such that every non-Wait action it takes satisfies bullet (i) of being Trimmed.
We just need to show that ˆπ can be modified to also satisfy bullet (ii).

So consider any action ˆπ takes which does not satisfy bullet (ii). This means that the action
) with an edge to v, but u was created
) created by Miner
), which terminates at v, where every node is
1.

is of the form Publish(k, v), u is the unique node in A(
C
by Miner 1. Let us further consider the entire set of descendents of v in A(
1. That is, let U denote the maximal path in A(
C
created by Miner 1. By hypothesis that the taken action violates bullet (ii), we have that
Let w denote the maximal node in U (that is, the other end of the path).

U
|

| ≥

C

− |

We know that, because ˆπ is Timeserving, that k >

. Consider instead taking the action
U
|
|
Publish(k
, w). Observe first that this action is valid, because ˆπ is Orderly. Indeed, not only
U
− |
|
of Miner 1’s unpublished nodes be placed on top of w, but the exact same set of k
can k
U
|
nodes which could be placed on top of u can be placed on w (if not, this would violate Orderly).
Moreover, now that this action is valid, it is also Trimmed (because w does not have an immediate
descendant in A(
C

We just need to confirm that all future actions can be modified to be valid after this change,
and that the reward to Miner 1 is the same. Intuitively, this occurs because the new longest chain
has exactly the same height as the original, the owners of each block along the path are exactly the
, all created by Miner 1 with U ,
same as the original (i.e .we replaced one sub-chain of length
U
|
|
another sub-chain of length
, all created by Miner 1), and those new blocks were only created
U
|
|
earlier than the original blocks, making them easier to build upon.

) created by Miner 1, by definition).

Indeed, we claim that taking actions in all future rounds according to the LCM reduction of ˆπ
results in feasible actions and identical payoffs. Indeed, the reward immediately after this action
is swapped does not change. In all future rounds, because every block in U was created before
every block originally published, every future action is still valid. And moreover, the rewards of
all future rounds are also identical. Because this holds pointwise, for all rounds, we can apply
the same reduction ad infinitum to swap all non-Trimmed actions for Trimmed actions without
changing the payoff at all.

43

F Omitted Proofs from Section 5

1

C

C

i=1

(cid:80)n

(cid:80)n

1i∈T2

F.1 Checkpoints
Proof of Lemma 5.6. Observe a miner following the FRONTIER strategy never publishes two blocks
at the same height. This implies that h(
(Xn)) is at least the number of blocks mined by Miner 2
(note that these blocks are not necessarily themselves in the longest path, but some block of the
. From the Strong Law of Large Numbers,
same height must be). Thus h(
a.s.
1
n
→
Proof of Corollary 5.7. For the lower bound, we use FRONTIER to witness that Rev(π)
α be-
cause Rev(FRONTIER) = α. If both miners follow the FRONTIER strategy, all blocks Miner 1
. From the
and Miner 2 creates are part of the longest path. Thus Rev(n)
Strong Law of Large Numbers, 1
n

(Xn))
i=1
α. This proves Lemma 5.6.

γ (FRONTIER) =

1i∈T1
i=1
n

, for any strategy π, with prob-
ability 1. Observe the number of blocks Miner 1 owns in the longest path is at most the number
of blocks Miner 1 creates. Moreover, Miner 2 never publishes two blocks at the same height
implying the height of the longest chain is at least the number of blocks Miner 2 creates. Then

a.s.
→
For the upper bound, we claim lim supn→∞

α.
Rev(n)

γ (π)

1i∈T1

1i∈T2

α
1−α

(cid:80)n

≥

≥

≤

−

i=1

(cid:80)n

Rev(n)

γ (π)

1
n
1
n

≤

(cid:80)n
(cid:80)n

i=1

i=1

1i∈T1
1i∈T2

.

From the Strong Law of Large Numbers,

1
n
1
n

(cid:80)n
(cid:80)n

i=1

i=1

1i∈T1
1i∈T2

a.s.
→

α
1−α

as desired.

Proof of Proposition 5.8. Proof of (i). The proof is clear from recursively applying the checkpoint
definition.
Proof of (ii). Assume the converse. If Pi is the highest checkpoint bellow v, v is a checkpoint, a
contradiction.
Proof of (iii). Let Pk = min
Pj : Pj > v
{
(v, Pk]

(Pk−1, Pk]

. Then

)

A(
C
|

∩

)
∩
(Pk−1, Pk]
(v, Pk].

| − |
| − |U ∩

A(
)
∩
C
(Pk−1, v]
|

(Pk−1, v]
|

}
A(
C
|
|U ∩
|U ∩

|

=
>

=

The second line follows from (i) and (ii). The inequality above and (i) implies

A(
C
|

)

∩

(v, Pi]

T1

|

∩

=
>

=

A(
|
C
|U ∩
|U ∩

(v, Pk]
+

)
∩
(v, Pk]
|
(v, Pi]
|

T1

∩
|U ∩

)

A(
+
C
|
|
(Pk, Pi]
|

∩

(Pk, Pi]

T1

|

∩

as desired.

44

F.2 Checkpoint Preserving Reduction
The next example highlights the main ideas behind the proof.

Figure 11: The mining game from non-checkpoint preserving (left) and transformation to a check-
point preserving strategy (right). Double circles denote blocks created by Miner 1 and single
circles denote blocks created by Miner 2. Thicker blocks denote blocks that were checkpoints at
some point in time.

0. Then Miner 1 publishes 3

Example F.1. In Figure 11, consider a mining game where Miner 1 creates and withhold blocks 2
and 3, and Miner 2 creates block 1 and publishes 1
0 during
the third round forking the checkpoint P1 = 1. To transform the original strategy into a checkpoint
preserving strategy, observe that a new strategy could publishes 3
0.
Note Miner 1 has an advantage of two blocks over Miner 2 so there is no risk into waiting to publishing
1. Therefore, to further improve the new strategy, let the new strategy wait until the first
3
time step where Miner 1’s advantage reduces to a single block. For example, if Miner 1 creates and
1, Miner 1 can safely
withhold block 4 and Miner 2 creates blocks 5 and 6 and publishes 6
publish 4

→
1 forking blocks 5 and 6 during the sixth round.

1 instead of 3

→

→

→

→

→

→

→

→

→

→

2

5

2

3

2

2

2

→

→

→

Remark. Note it is not at all obvious the transformation in Example F.1 guarantees the new
strategy is at least as good as the original one. It is true the number of blocks Miner 1 owns in
the longest path increases; however, the number of blocks Miner 2 owns in the longest path also
increases. Thus the main challenge in proving Theorem 5.12 is showing that on expectation, the
payoff of the new strategy is at least as good as the payoff of the original one.

To show the transformed strategy in Example F.1 is at least as good as the initial strategy,
we will show that whenever Miner 1 takes PublishPath(Q, v) (at time t) and forks a checkpoint
c

),

A(
C

∈

45

  • PublishPath(Q

(c,

∩

), c) is a valid trimmed action Miner 1 can take instead.

∞

• Regardless if Miner 1 takes action PublishPath(Q, v) or PublishPath(Q

will becomes a checkpoint in the subsequent state.

(c,

∩

), c), max Q

∞

By taking PublishPath(Q

), c) instead of PublishPath(Q, v), we show

(c,

∩

∞

• The number of blocks Miner 1 does not publish
Q
∩
|
created by Miner 1 that Miner 1 does not fork
A(
)
∩
C
|
least the same reward by taking PublishPath(Q
(c,
∩
∞
(v, c]

• If Miner 2’s reward increases by k =

)

Succ(v)

(v, c), then Miner 1 has a lead of k + 1 blocks. That is

A(
C
|

∩

T2

|

∩

(0, c)

is at most the number of blocks
|
. Thus Miner 1 receives at
(v, c]
|
), c) instead of PublishPath(Q, v).

T1

∩

when Miner 1 does not fork

∩

)
| ≥ |
Thus instead of taking action PublishPath(Q
until the first time step

∞

Q
|

(c,

∩

+ k + 1

Succ(c)
|
), c) at time t, Miner 1 can safely wait

(c,

∩

∞

τ = min
{

t(cid:48)

t :

T2
|

∩

≥

(t, t(cid:48)]

=

|

T1
|

∩

(t, t(cid:48)]
|

+ k

}

where Miner 2 creates k more blocks than Miner 1 (since time t + 1). At time τ , we let
Miner 1 take PublishPath((Q
(t, t(cid:48)]).
(T1
∪
We show the expected number of blocks Miner 1 creates from time t + 1 to τ , outweighs
the cost of allowing Miner 2 to walk away with k additional blocks at time t.

(t, t(cid:48)]), c) forking Succ(c)

(T2

(c,

∞

))

∩

∪

∩

∩

F.2.1 Preliminaries

A(

Next, we define a transformation of trimmed action PublishPath(Q, v) that forks a checkpoint
) into another trimmed action PublishPath(Q(cid:48), v(cid:48)) that does not forks a checkpoint (with
c
C
∈
Q and v(cid:48) > v). Recall PublishPath(Q, v) is trimmed if it is timeserving – i.e., Q becomes
Q(cid:48)
Succ(v)
part of the longest path which requires

+ 1.

⊆

Q
|

| ≥ |

|

Definition F.2 (Lift). For valid, timeserving PublishPath(Q, v) action, let Q(cid:48)
If PublishPath(Q(cid:48), v(cid:48)) is timeserving, then PublishPath(Q(cid:48), v(cid:48)) is a lift of PublishPath(Q, v).

Q and v(cid:48)

⊆

∈

Succ(v).

Definition F.3 (Safe Lift). PublishPath(Q(cid:48), v(cid:48)) is a safe lift of PublishPath(Q, v) if PublishPath(Q(cid:48), v(cid:48))
is a lift of PublishPath(Q, v) and taking action PublishPath(Q(cid:48), v(cid:48)) gives at least the same reward as
taking action PublishPath(Q, v). That is,

Succ(v(cid:48)))

Q(cid:48)

Q

T1

(Succ(v)
|

\

∩

| ≥ |

\

.
|

Definition F.4 (Checkpoint Lift). Let PublishPath(Q, v) be a trimmed action and assume Succ(v)
contains a checkpoint. Let cv := max
be the most recent
Pi > v : Pi
{
checkpoint. Define PublishPath(Q
(cv,
∞

), cv) as the checkpoint lift of PublishPath(Q, v).

) is a checkpoint
}

A(
C

Lemma F.5 (Checkpoint Lift Lemma). Suppose Miner 1’s strategy is trimmed. If PublishPath(Q(cid:48), v(cid:48))
is the checkpoint lift of trimmed action PublishPath(Q, v), then PublishPath(Q(cid:48), v(cid:48)) is trimmed and
a safe lift of PublishPath(Q, v).

∩

∈

Proof. By assumption, Succ(v) contains a checkpoint and v(cid:48) be the most recent checkpoint in
Succ(v). To show that PublishPath(Q(cid:48), v(cid:48)) is trimmed we need to show that

46

1. If v(cid:48) has any successors, min Succ(v(cid:48)) was created by Miner 2.

2. PublishPath(Q(cid:48), v(cid:48)) is timeserving.

For (1), suppose Miner 1 created min Succ(v(cid:48)). Then min Succ(v(cid:48)) is a checkpoint because Miner
1’s strategy is orderly, a contradiction to v(cid:48) being the most recent checkpoint. This proves (1). For
(2), suppose for contradiction PublishPath(Q(cid:48), v(cid:48)) is not timeserving. Then

Q
|
|

=

Q
|
∩
≤ |U ∩

+
+

(v, v(cid:48)]
|
(v, v(cid:48)]
|
(v, v(cid:48)]
|
(v, v(cid:48)]
|
| ⇒⇐

+

|

Q
|
Q
|

(v(cid:48),
(v(cid:48),

∩
∩
Succ(v(cid:48))

)
|
∞
)
|
∞

|
Succ(v(cid:48))

+
.

|

|

≤ |U ∩
A(
)
∩
C
Succ(v)

≤ |
=
|

Because PublishPath(Q, v) is orderly.
From the assumption PublishPath(Q(cid:48), v(cid:48)) is not time-
serving.
From Proposition 5.8 and the fact v(cid:48) is a checkpoint.

The chain of inequalities contradicts the assumption that PublishPath(Q, v) is timeserving. This
proves (2) and proves PublishPath(Q(cid:48), v(cid:48)) is trimmed. Next, we show PublishPath(Q(cid:48), v(cid:48)) is a safe
lift. Because v(cid:48) is a checkpoint,

(Succ(v)
|

\

Succ(v(cid:48)))

T1

|

∩

=

A(
|
C
≥ |U ∩
Q
∩
≥ |
Q
=
\
|

(v, v(cid:48)]

)
∩
(v, v(cid:48)]
|
(v, v(cid:48)]
|
Q(cid:48)

|

T1

|

∩

From Proposition 5.8.
Because PublishPath(Q, v) is orderly.
Because Q(cid:48) = Q
).

(v(cid:48),

∩

∞

v

{

The chain of inequalities witnesses PublishPath(Q(cid:48), v(cid:48)) is a safe lift of PublishPath(Q, v).
Lemma F.6 (Checkpoint Override Lemma). Let PublishPath(Q, v) be a trimmed action. If
} ∪
Succ(v) contains a checkpoint, the new longest chain becomes a checkpoint after Miner 1 plays
PublishPath(Q, v).
Proof. We divide the proof into two cases:
Case 1. If v is a checkpoint, all blocks Miner 1 publishes become checkpoints because PublishPath(Q, v)
is orderly.
Case 2. If v is not a checkpoint, let s = max
be the most re-
{
cent checkpoint smaller than v and let c = min
be the oldest
{
checkpoint bigger than v. Let t
Q be the block that would take the height of c in the longest
∈
It suffices to show that t becomes a checkpoint because if t
v is published.
path once Q
becomes a checkpoint, max Q becomes a checkpoint because PublishPath(Q, v) is orderly (i.e.,
(
U \
it suffices to show that

Q)
Because s < v, s will continue to be a checkpoint and to show that t becomes a checkpoint,

A(v) : c is a checkpoint
}
Succ(v) : c is a checkpoint
}

(t, max Q) =

∈
∈

c
c

→

∩

).

∅

(A(
|

C

)

∩

(s, v]

T1)

∪

∩

)

(A(
C
|
∩
(v, t])
(Q

∩

(v, t])

Q)

(
U \

. Indeed,
(s, t]
|

∩

| ≥ |

T1

|

∩

Because s and c are checkpoints.

(s, v]

T1)

∪

(Q

∩
(s, c]

| ≥ |

∩
A(
C
≥ |U ∩
(
U \
≥ |
(
U \
≥ |

)
∩
(s, c]
|
Q)
∩
Q)
∩

(s, c]
|
(s, t]
|

47

The first line observes t will have the same height as c and Miner 1 will be the creator of all blocks in
the path v
t. For the fourth line, the case where t < c is clear. For the case where t > c,
we claim (
(c, t), q > v because v is ancestor of c.
(c, t) =
(
∈
Thus q < t is a block Miner 1 could have published pointing to v instead of t, a contradiction to
PublishPath(Q, v) being orderly. This proves t (and max Q) becomes a checkpoint as desired.

. If there exists q

. . .
Q)

→
U \

→
∩

U \

Q)

∩

∅

F.2.2 The Reduction

In this section, we proof Theorem 5.12.

Definition F.7 (Potential reward). For a state B, let B(cid:48) be a successor of B if there is a valid
action Miner 1 can take at state B such that the subsequent state is B(cid:48). Let Succs(B) be the set of
all successors of B. The potential reward δk of Miner k maps a state B to the maximum absolute
reward Miner k can obtain from state B to a successor of B. That is

δk(B) = max

B(cid:48)∈Succs(B) |

rk(B, B(cid:48))

.
|

Proposition F.8. Let π be a trimmed strategy. Let B be a state satisfying the bullets:

• B is reachable from a mining game starting at state B0 with Miner 1 following strategy π.

• At B, π takes trimmed action PublishPath(Q, v) forking the most recent checkpoint Pi.

• Block v reached finality with respect to π.

Then there exists a valid, trimmed strategy f (π) where f (π) take the same actions as π up to state
B and forks no checkpoint at state B. To define f (π) at state B onward, let (X f (π)
)t≥0 be a mining
game starting at X f (π)

0 = B and where Miner 1 follows strategy f (π). Let N = max V(B) and

t

Zt =
Let τ = min
t
{
let f (π) take action

SuccB(Pi)
|

+
0 : Wt = 0
}

≥

|

Qt =

+

T1(X f (π)
t
|

)
|
∞
(N, N + t]
)

Q
(Pi,
|
∩
T2(X f (π)
t
|
. At state (X Half

∩

|

t

)

∩

(N, N + t]

,
|

and

)f (π), for t < τ , let f (π) wait. At state (X Half

)f (π),

τ

Wt = Qt

Zt

1.

−

−

PublishPath(Q

)
∞
forking blocks SuccB(Pi)
(N, N + τ ]. To define f (π)’s actions in future states, let
B(cid:48) be the subsequent state to B after π publishes blocks Q. Let (Xt)t≥τ be a mining game starting
at Xτ = B(cid:48) and where Miner 1 follows strategy π. Complete the sequence (Xt)t≥0 with

∩
T2(X f (π)
t

(N, N + τ ], Pi)

(Pi,

∪

∪

∩

∩

)

)

T1(X f (π)
τ

X0 = B

and

X1 = X2 = . . . = Xτ −1 = B(cid:48).

Let (Xt, X f (π)
t

t

≥

τ + 1, at state (X Half
Given the coupling (Xt, X f (π)

t

t

)t≥0, for all t

)t≥τ be a coupling where Miner k creates block t

)f (π), let f (π) take the same actions π takes at state X Half

t

τ + 1 in both games. For all
.

≥

Rev(t)

γ (f (π))

≥

(Xt))

T1
|
C
(Xt)) + 1t≥τ

∩

A(
|
h(
C

·

(cid:80)W0

·
W0 + (cid:80)W0

δ1(Xt)
i=1 Zi
·
−
(cid:17)
+ δ1(Xt)
i=1 Zi

11≤t<τ
11≤t<τ

.

0,
≥
+ 1t≥τ
(cid:16)

where W0

≥

1 and (Zi)W0
i=1

are i.i.d. random variables with expected value

48

·
α
1−2α

.

Proof. First, we show W0
Claim F.9. W0

1.
SuccB(v)

≥

≥ |

SuccB(Pi)

Q

(v, Pi]

| − |

∩

1.

| ≥

\

Proof. Because PublishPath(Q, v) is timeserving, Q successfully becomes part of the longest path
SuccB(v)
once π publishes Q which implies
|

+ 1. Then

Q
|

SuccB(Pi)

| ≥ |
1
SuccB(Pi)

| −

W0 =
=

Q
|
Q
|

∩

(Pi,
Q

)
∞
| − |
(v, Pi]

| − |
∩
SuccB(v)

| − |
SuccB(Pi)

| − |

SuccB(v)

SuccB(Pi)

≥ |
=

1

| −

| − |
Q

Q

(v, Pi]
|

∩
.
(v, Pi]
|

Because PublishPath(Q, v) is time-
serving.

|

\

| − |

∩
This proves the first inequality. To show the second inequality, recall PublishPath(Q
), Pi)
is the checkpoint lift of PublishPath(Q, v) (and thus a safe lift according to Lemma F.5), then, at
state B, the number of blocks Miner 1 would add to the longest path by taking action PublishPath(Q
), Pi) is at least the number of blocks Miner 1 would add to the longest path by taking ac-
(Pi,
tion PublishPath(Q, v). That is

(Pi,

∞

∞

∩

∩

(SuccB(v)

\

SuccB(Pi))

T1

Q

.
(v, Pi]
|

∩

| ≥ |

∩

(15)

Note SuccB(v) is non-empty (since it contains a checkpoint). The fact π is trimmed implies the
immediate successor of block v was created by Miner 2. Therefore,

(SuccB(v)
|

\

SuccB(Pi))

T2

∩

| ≥

1.

Combining the work above

SuccB(v)

|

\

SuccB(Pi)

| − |

(v, Pi]

Q

∩

| ≥ |

SuccB(v)

SuccB(Pi)

\
(SuccB(v)

|
SuccB(Pi))
T2

SuccB(Pi))

\

T1

|

∩

|

∩

− |

(SuccB(v)
|
1

\

=

≥

The chain of inequalities witnesses W0

1 as desired.

(Xτ ). Suppose the converse. By assumption, v reached finality with
Observe π never forks
C
(Xτ ), π takes some action PublishPath(Q(cid:48), v(cid:48)) where v(cid:48) is in the
respect to π. Thus if π forks
path from v to
(Xτ ) only contain blocks created by Miner
1 which implies the immediate successor of block v(cid:48) was created by Miner 1, a contradiction to π
being trimmed. This proves π never forks

(Xτ ); however, the path from v to

(Xτ ) as desired. Next, observe

C

C

C

(Xτ )

(Xτ ),

(
C

=

(X f (π)
τ

)

(X f (π)
τ

),

(
C

.
)
|
∞

|U

∩
Therefore, up to relabeling of blocks, states Xτ and X f (π)
strategy π. Thus it is valid for f (π) to take the same actions as π after time τ .

∩
are equivalent with respect to trimmed

Let’s check f (π) is valid and trimmed. By inspection, f (π) is valid because π is valid. Up to
1)-th step,

state B, f (π) is trimmed since f (π) is equals to π up to state B. From first to (τ

|U

τ

−

≥

C
)
|
∞

49

f (π) publishes no blocks and at step τ , f (π) publishes blocks pointing to Pi. If Succ(Pi) is the
empty-set, f (π)’s action is clearly trimmed. If Succ(Pi) is non-empty, min Succ(Pi) is a block
created by Miner 2. Suppose the contrary, then min Succ(Pi) existed at state B (since this is the
first time f (π) publishes blocks since state B). But B was reachable from a trimmed (and orderly)
strategy which implies min Succ(Pi) is also a checkpoint, a contradiction to Pi being the most
recent checkpoint at state B. Thus f (π) is trimmed up to time τ . After time τ , f (π) takes the
same actions as π which, by assumption, is a trimmed strategy. This proves f (π) is a trimmed
strategy as desired.

Let’s now compare the revenue of f (π) with π. From the first to (τ

pointing to v, but f (π) publishes no blocks. During the same time interval, in (X f (π)
publishes all blocks created from time 1 to time τ
from time 1 to τ . Since δ1(X f (π)
Xt,

1)-th step, π publishes Q
)t≥0, Miner 2
1 while in (Xt)t≥0, Miner 2 creates no blocks
) denotes the maximum reward Miner 1 can obtain from state

−

−

t

t

h(
C
At the τ -th step, f (π) publishes Q
T2(X f (π)
SuccB(Pi)
τ

)

A(
C
|

)

|
))

(X f (π)
t

T1
))
∩
(X f (π)
t

+ δ1(X f (π)
t
δ1(X f (π)
)
t
≤
T1(X f (π)
)
τ
(N, N + τ ]. At the same time, π publishes no blocks. Thus

h(
C
(N, N + τ ] pointing to Pi and forking

A(
C
(Xt)).

−
)
∞

(Xt))

(Pi,

≥ |

T1

.
|

∩

∩

∩

∪

SuccB(v)

+

|

|

\

SuccB(Pi)

T1

|

∩

∪
(X f (π)
t

A(
|

C

∩

))

T1

|

∩

=

A(
|

C
+

T1
(Xt))
∩
T1(X f (π)
t
|
T1
(Xt))

)

∩

Q

(v, Pi]

| − |

∩
(N, N + τ ]
T1(X f (π)
t
|

|
)

∩
+

|

A(
C

≥ |

Adding

(X f (π)
A(
t
C
|
(X f (π)
t

))

))

∩
T1

|

∩

A(
C
|
(X f (π)
t

h(
C

)) =

A(
|
= h(

(N, N + τ ]

From Equation 15.

|

∩
(SuccB(v)
|

\

+

T2

T2

|
T2

SuccB(Pi))

∩
))

(Xt))
C
(X f (π)
t

.
|
, the height of the longest path is
|
(X f (π)
A(
T1
))
+
t
C
∩
|
|
SuccB(Pi)
SuccB(v)
|

(v, Pi]
|

T2
∩
+

|
Q
|

∩

∩

∩

|

∩

(N, N + τ ]

|

From Claim F.9.

C

=

T2

|
and

A(
|
A(
|
(X f (π)
t
C
(Xt)) +
|
T1(X f (π)
t
∩
|
(Xt)) + W0 +

))

C
+

)

\
(N, N + τ ]
T1(X f (π)
t
|
T1(X f (π)
t
|
= (cid:80)W0
(N, N + τ ]

∩

)

)

|

h(

≤

C

are i.i.d. random variables with

We will now derive a closed form for

Claim F.10.
expected
α
1−2α

T1(X f (π)
t
|
.

)

∩

(N, N + τ ]

.
|
i=1 Zi where (Zi)W0

i=1

Proof. Observe (Wt)t≥0 is a one-dimensional biased random walk since Wt increments whenever
Miner 1 creates a block (with probability α) and decrements whenever Miner 2 creates a block
(with probability 1

α). That is,

−

(cid:40)

Wt =

Wt−1 + 1 with probability α,
1 with probability 1
Wt−1

−

α.

−

50

0, let τi = min
{

For i
0 : Wt = W0
≥
−
random walk takes to first reach state W0
−
Let Zi+1 =
(N + τi, N + τi+1]
)

, then τi+1
i
}
i since the first time step it reached stated W0
and note Z1, Z2, . . . are i.i.d. with

τi denotes the number of time steps the
i + 1.

−

−

≥

t

T1(X f (π)
t
|

∩

|

T1(X f (π)
t
|

)

∩

(N, τW0]

=

|

W0(cid:88)
i=1 |

T1(X f (π)
t

(N + τi−1, N + τi]

)

∩

W0(cid:88)

i=1

=

|

Zi.

From Lemma D.1, E

(cid:104)

T1(X f (π)
t
|

)

(cid:105)
(N + τi, N + τi+1]

= α

1−2α

as desired.

∩
Combining the inequalities above, we obtain that for all t

0,

≥

Rev(t)

γ (f (π)) = |

T1

|

(X f (π)
A(
))
t
∩
C
(X f (π)
h(
))
t
C
T1
A(
(Xt))
C
|
(Xt)) + 1t<τ
h(
C

∩

·

| −

1t<τ
·
δ1(X f (π)
t

δ1(X f (π)
t
) + 1t≥τ

(cid:80)W0

) + 1t≥τ
(cid:16)

·
W0 + (cid:80)W0

i=1 Zi
(cid:17)
i=1 Zi

·

≥

as desired.

by deriving that δ1(Xt)

t

0.

a.s.
→

To simplify the expression for the revenue of f (π), we first show δ1(Xt) is a negligible term

Lemma F.11 (Asymptotic Reward Lemma). Let (Xt)t≥0 be a mining game starting at state X0 =
B0. For any (cid:15) > 0, P r (cid:2)

e−Ω(n). Moreover,

(cid:3)

∞
i=n{

δ1(Xi) > i(cid:15)
}

∪

≤

• δ1(Xn)
n

0.

a.s.
→

• r1(Xn−1,Xn)
n

0.

a.s.
→

Proof. Event δ1(Xi) > i(cid:15) implies there is a timeserving action PublishPath(Q, v) Miner 1 can take
at time step i with
> i(cid:15). The fact PublishPath(Q, v) is timeserving implies Miner 1 creates
Q
|
|
more blocks than Miner 2 from time v to i. To derive an upper bound on v, observe at most i
blocks were created by time i. Therefore,
> i(cid:15).
+ v
Thus

i which implies v < (1

(cid:15))i since

Q
|
|

Q
|
|

≤

−

P r (cid:2)

∞
i=n

∪

(cid:8)δ1(Xi) > i(cid:15)(cid:9)(cid:3)

∞
(cid:88)

i=n

≤

P r (cid:2)δ1(Xi) > i(cid:15)(cid:3)

∞
(cid:88)

i=n

P r [

v < (1

∃

(cid:15))i,

T1
|

∩

−

(v, i] >

T2
|

∩

(v, i]

]
|

∞
(cid:88)

(1−(cid:15))i
(cid:88)

i=n

v=0

P r [

T1
|

∩

(v, i] >

T2
|

∩

(v, i]

]
|

≤

≤

From union bound.

From union bound.

Observe

Tk
|
P r [j
1
∈
To bound P r

j=v+1

= (cid:80)i
(v, i]
∩
T2] = α. Thus event
(cid:104)(cid:80)i

1j∈Tk
T1
|
(cid:105)
1j∈T1 > i−v

−

|

j=v+1

2

is the sum of Bernoulli random variables where P r [j

(v, i]

>

T2
|

(v, i]
|

∩
, we will use the Chernoff bound and the fact α < 1/2.

∩

|

j=v+1

is equivalent to (cid:80)i

T1] =
∈
1j∈T1 > i−v
.

2

51

Theorem F.12 (Chernoff Bound). If X1, X2, . . . , Xn are independent indicator random variables
where E [Xi] = µ, then for any δ > 0,

P r

(cid:34) n

(cid:88)

i=1

(cid:35)

Xi

≥

(1 + δ)µ

≤

e− δ2µ
2+δ .

Claim F.13. Let X1, X2, . . . , Xn be i.i.d. copies of Bernoulli random variable X where E[X] = α <
1/2. Then P r[(cid:80)n
Proof. Let µ = E[(cid:80)n
α < 1/2,

2α)/(2α). From Chernoff Bound and the fact

i=1 Xi] = αn and δ = (1

i=1 Xi > n/2]

e− (1−2α)n

−

≤

4

P r

(cid:34) n

(cid:88)

i=1

(cid:35)

Xi > n/2

= P r

(cid:34) n

(cid:88)

i=1

(cid:35)

Xi > µ(1 + δ)

≤

e− δ2µ

2+δ < e− (1−2α)n

4

.

Therefore, P r
is the fact v < (1

(cid:104)(cid:80)i

j=v+1

1j∈T1 > i−v

2

(cid:15))i. We conclude

−

(cid:105)

≤

e−(1−2α)(i−v)/2 < e−(1−2α)(cid:15)i where the last inequality

P r (cid:2)
∪

∞
i=n

(cid:8)δ1(Xi) > i(cid:15)(cid:9)(cid:3)

∞
(cid:88)

(1−(cid:15))i
(cid:88)

≤

i=n

v=0

e−(1−2α)(cid:15)i

∞
(cid:88)

i=n

≤

e−Ω(i) = e−Ω(n)

as desired. For the ”Moreover” part, we just observe δ1(Xn)

n

0 is equivalent to

a.s.
→

lim
n→∞

P r (cid:2)
∪

∞
i=n

(cid:8)δ1(Xi) > i(cid:15)(cid:9)(cid:3) = 0

for all (cid:15) > 0.

This is clear since e−Ω(n)
created; therefore, r1(Xn−1, Xn)

→

δ1(Xn) + 1. Thus

≤

0. For the second part, note from state Xn−1 to Xn, a single block is

r1(Xn−1, Xn)
n

δ1(Xn) + 1
n

a.s.
→

0

≤

as desired.

Proof of Theorem 5.12. Let π be a trimmed strategy. We claim there exists a strategy f (π) that is
checkpoint preserving. We will interactively transform π into f (π). Initialize f (π) to be equal to
π.

Step 1. Whenever f (π) reaches a state B where f (π) is about to take action PublishPath(Q, v)
where Succ(v) contains a checkpoint, we will transform f (π) so that it is does not fork a check-
point. We consider two cases:

Case 1. Consider the case block v reached finality with respect to f (π). Then f (π) and B
satisfy the conditions for Proposition F.8. Thus there is a trimmed strategy π(cid:48) where π(cid:48) is equals to
f (π) up to state B and at state B, π(cid:48) follows the algorithm in Proposition F.8. Redefine f (π) to be
equal to π(cid:48) and repeat until f (π) reaches another state where f (π) is about to fork a checkpoint.
If no such state exists, f (π) is checkpoint preserving.

52

Case 2. Consider the case block v does not reach finality with respect to f (π). From Lemma F.6,
max Q becomes a checkpoint after f (π) publishes Q pointing to v. Observe that in the future,
f (π) will take action PublishPath(Q(cid:48), v(cid:48)) with h(v(cid:48)) < h(v) at most h(v) times; otherwise, there
is a state where f (π) takes action PublishPath(Q(cid:48), v(cid:48)) and the immediate successor of block v(cid:48)
was created by Miner 1, a contradiction to f (π) being trimmed. Let B(cid:48) be the last state reachable
from B where f (π) takes action PublishPath(Q(cid:48), v(cid:48)) with h(v(cid:48)) < h(v). Clearly v(cid:48) reaches finality
with respect to f (π). Note f (π) forks a checkpoint by publishing Q(cid:48) pointing to v(cid:48) since max Q
became a checkpoint and any action thereafter that forks max Q induces the longest chain to
become a checkpoint. Thus state B(cid:48) and strategy f (π) satisfy the conditions for Proposition F.8.
Thus there is a trimmed strategy π(cid:48) that is equals to f (π) up to state B(cid:48) and at state B(cid:48), π(cid:48) follows
the algorithm in Proposition F.8. Redefine f (π) to be equal to π(cid:48) and return to Step 1 with strategy
f (π) and state B.

Since we visit Case 2 with state B at most h(v) times, eventually, block v reaches finality with
respect to f (π) and we execute Case 1. Once Case 1 is executed with strategy f (π) and state
B, f (π) becomes checkpoint preserving on a larger set of states. Ad infinitum f (π) becomes
checkpoint preserving as desired.

This proves there is a strategy f (π) that is valid, trimmed and checkpoint preserving as
Rev(π). Let (X f (π)
)t≥0 be a mining game starting at
= B0 and where Miner 1 follows f (π). Let ti be the i-th time step where f (π) would
Succ(v), but, instead, we execute
ti where f (π) publishes
1τi≤t and observe

desired. Next, we check Rev(f (π))
X f (π)
0
take action PublishPath(Q, v) and fork a checkpoint Pi
the algorithm in Proposition F.8. That is, f (π) waits until time τi
(Q
∩
τNt ≤
Corollary F.14. For any strategy π, there is a trimmed, checkpoint preserving strategy f (π) where

(ti, τi]) pointing to Pi. Let τ0 = 0, Nt = (cid:80)∞

(Pi,
∪
∞
t < τNt+1.

(T1(X f (π)

≥

≥

i=1

∩

∈

])

τi

)

t

Rev(t)

γ (f (π))

≥

A(
(Xt))
T1
∩
C
|
|
(Xt)) + (cid:80)Nt
j=1 W j

j=1

+ (cid:80)Nt
0 + (cid:80)Nt

j=1

i=1 Z j
(cid:80)W j

i −
i=1 Z j

δ1(Xt)
i + δ1(Xt)

0

.

(cid:80)W j

0

h(
C

where (Xt)t≥0 is a mining game with X0 = B0 where Miner 1 follows π. For all j, W j
(Z j

i )i,j are i.i.d random variables with expected value

.

α
1−2α

0 ≥

1 and

Proof. The work above transform a strategy π into a trimmed, checkpoint preserving strategy
f (π). The revenue of f (π) with respect to the initial strategy π follows from applying Proposi-
tion F.8 each time Case 1 is executed.

From supperaddivity of lim inf,

lim inf
t→∞

≥
(cid:0)Rev(t)

lim inf
t→∞

Rev(t)

γ (f (π))

Rev(t)

γ (π) + lim inf
t→∞

(cid:0)Rev(t)

γ (f (π))

Rev(t)

γ (π)(cid:1)

−

It suffices to show lim inf t→∞
γ (f (π)).
lower bound on Rev(t)

γ (f (π))

Rev(t)

γ (π)(cid:1)

−

≥

0. Note Corollary F.14 provides a

Proposition F.15. lim inf t→∞

(cid:32)

|A(C(Xt))∩T1|+(cid:80)Nt
j=1

(cid:80)W

j
0

h(C(Xt))+(cid:80)Nt

j=1 W j

0 +(cid:80)Nt

j=1

i=1 Zj
(cid:80)W

i −δ1(Xt)
j
0

i=1 Zj

i +δ1(Xt) −

(cid:33)

Rev(t)

γ (π)

0.

≥

53

Proof. Recall Miner 2 never publishes two block at the same height; therefore, h(
C
is the sum of t i.i.d. random variables with expected value 1
. Since
T2(Xt)
T2(Xt)
|
−
|
|
|
the strong law of large numbers

(Xt))
≥
α, from

T2(Xt)
|
|
t

a.s.
→

1

−

α

and

T1(Xt)
|
|
t

t

=

− |

T2(Xt)
|
t

α

a.s.
→

From Lemma F.11,

δ1(Xt)
h(C(Xt))

a.s.
→

0 and

(cid:80)W j

0

j=1

+ (cid:80)Nt
0 + (cid:80)Nt
+ (cid:80)Nt
0 + (cid:80)Nt

j=1

j=1

j=1

i=1 Z j
(cid:80)W j

0

(cid:80)W j

i −
i=1 Z j
i=1 Z j
i
(cid:80)W j

0

δ1(Xt)
i + δ1(Xt) −



Rev(t)

γ (π)



T1



|



(Xt))

∩
(Xt))

A(
C
|
h(
C

0

i=1 Z j

i

−

lim inf
t→∞

C

A(
(Xt))
T1
∩
C
|
(Xt)) + (cid:80)Nt
j=1 W j


 |
h(
C

A(
(Xt))
T1
∩
 |
|
(Xt)) + (cid:80)Nt
j=1 W j
h(
C
(cid:80)Nt
j=1 W j
j=1 W j
·
(Xt)) (cid:80)Nt
(cid:16)

h(
C

(cid:80)W j

(cid:80)Nt

j=1

t

t

·

0

0

= lim inf
t→∞

= lim inf
t→∞





0

i=1 Z j
i − |
(Xt)) + (cid:80)Nt

A(
C
j=1 W j

(Xt))
T1
∩
0 + (cid:80)Nt

j=1

h(

C

(cid:16)(cid:80)Nt

j=1 W j
(cid:17)

|
(cid:80)W j

0

i=1 Z j

i

0 + (cid:80)Nt

j=1

(Xt))

h(
C

(cid:80)W j

0

i=1 Z j

i



(cid:17)




= lim inf
t→∞

at.

First, consider the case limt→∞ Nt <

which implies

∞

lim sup
t→∞

Nt(cid:88)

W j
0(cid:88)

j=1

i=1

Z j
i

and

lim sup
t→∞

Nt(cid:88)

j=1

W j

0 <

.
∞

Thus

(cid:80)Nt
j=1
h(
C

(cid:80)W j

0

i=1 Z j

i

(Xt))

a.s.
→

0

(cid:80)Nt

j=1 W j
0
(Xt))

h(

C

a.s.
→

0.

Therefore, lim inf t→∞ at = 0 as desired. Next, we consider the case limt→∞ Nt =
supermultiplicativity of lim inf,

h(C(Xt)) (cid:80)Nt
j=1

lim inf t→∞

j
0

(cid:80)W

i=1 Zj

i −|A(C(Xt))∩T1|

(cid:32)

(cid:80)Nt

j=1 W j

0 +(cid:80)Nt

j=1

j
0

(cid:80)W

i=1 Zj

i

t·(cid:80)Nt

j=1 W j

0

lim inf
t→∞

at

≥

lim supt→∞

=

lim inf t→∞ bt
lim supt→∞ ct

.

(cid:32)

h(C(Xt))+(cid:80)Nt

j=1 W j

0 +(cid:80)Nt

j=1

j
0

(cid:80)W

i=1 Zj

i

(cid:33)

h(C(Xt))

t·(cid:80)Nt

j=1 W j

0

54

. From

∞

(cid:33)

Next, we check lim inf t→∞ bt
lim supt→∞ ct
by 0 and lim supt→∞ ct is bounded away from 0. Recall lim inf t→∞
Thus

is well-defined. For that, we will show lim inf t→∞ bt is lower bounded
α almost surely.

h(C(Xt))
t

−

≥

1

lim sup
t→∞

ct = lim sup

n→∞

h(
C

(Xt) + (cid:80)Nt

0 + (cid:80)Nt

j=1

j=1 W j
(cid:80)Nt

j=1 W j

0

(cid:80)W j

0

i=1 Z j

i

h(

C

(Xt))
t

1

−

≥

α > 0.

From Proposition F.8, (cid:80)Nt
j=1
value

(cid:80)W j
. From the strong law of large numbers,

is the sum of (cid:80)Nt

i=1 Z j

i

0

j=1 W j

0

α
1−2α

i.i.d. random variables with expected

h(

C

(Xt))
t

(cid:80)Nt
j=1
(cid:80)Nt

(cid:80)W j

0

i=1 Z j

i

j=1 W j

0

T2(Xt)
|
|
(cid:80)W j
(cid:80)Nt
i=1 Z j
0
j=1

i

≥

a.s.
→

(1

α)

1

−

.

α

2α

−

Observe A(
C

(Xt)

T1

∩

A(
C
|

(Xt))
t

∩

T1

|

T1(Xt). Then

⊆
(cid:80)Nt

j=1 W j

0 + (cid:80)Nt
(cid:80)Nt
j=1 W j

j=1

0

(cid:80)W j

0

i=1 Z j

i

T1(Xt)
|
|
t

(cid:18)

α

1 +

≥

a.s.
→



1 +

(cid:80)Nt
j=1
(cid:80)Nt

(cid:80)W j

0

i=1 Z j

i

j=1 W j

0





(cid:19)

α

2α

1

−

The work above proves

lim inf
t→∞

bt = lim inf
t→∞

(Xt)) (cid:80)Nt

j=1

h(
C

α(1
1

≥

α)
−
2α −

α(1
α)
−
2α
1
0 as desired.

−

≥

−
Thus lim inf t→∞ at

(cid:80)W j

0

i=1 Z j

i − |

(cid:16)(cid:80)Nt

j=1 W j

0 + (cid:80)Nt

j=1

(cid:80)W j

0

i=1 Z j

i

(cid:17)

A(
C
t

(Xt))
(cid:80)Nt

T1
|
∩
j=1 W j

0

·

= 0

From Proposition F.15, lim inf t→∞ Rev(t)
Rev(π) as desired.

value proves Rev(f (π))

γ (f (π))

≥

lim inf t→∞ Rev(t)

γ (π). Taking the expected

≥

F.3 Opportunistic Reduction
First, we give an example that highlights the main ideas of the proof.

55

Figure 12: In the left, we have a checkpoint preserving strategy π that is not 1-Opportunistic. In
the center and right, we have transform π into a 1-Opportunistic strategy ˆπ. In the center, we
consider the case where Miner 1 creates block 3 and in the right, we consider the case where
Miner 2 creates block 3.

→

Example F.16. In the left of Figure 12, consider a state where Miner 1 withholds blocks 1 and 2 and
0 with block 1 reaching finality – that is, Miner 1 is following a strategy that will
publishes only 1
never fork block 1. Thus Miner 1’s strategy is not opportunistic because block 2 remains unpublished.
To transform Miner 1’s strategy into an opportunistic one, Miner 1 will wait during the second round.
For future rounds, we consider two cases depending on whom creates the third block.
Case 1. Consider the case Miner 1 creates block 3 (center of Figure 12). Let Miner 1 publish 1
and copy all the future actions of the original strategy as if nothing happened.
Case 2. Consider the case Miner 2 creates block 3 (right of Figure 12). Let the new strategy publish
s the original strategy
2
s because u
publishes except when u = 2 or s = 3. If u = 2, the new strategy ignores edge u
s
→
was already published. That is, the original strategy must be publishing edge 2
1 (because block
→
1 during the second round. If s = 3,
1 reached finality), but the new strategy already published 2
the new strategy publishes u
2 instead. The only difference between the game trees is that block
3 is replaced by block 2 (which was created by Miner 1).

0. In future rounds, the new strategy will publishes all edges u

→

→

→

→

→

→

→

0

1

Proposition F.17. Let π be a trimmed strategy. Let B be a state where:

• State B is reachable from a mining game starting at state B0 with Miner 1 following strategy

π.

• π takes action PublishPath(Q, v).

• v reached finality with respect to π.

• Q

(B)

(v,

).
∞

∩

⊂ U

Then there is a trimmed strategy f (π) that is equals to π up to state B. At state B, f (π) waits. Let
N = max V (B) + 1. To define f (π) at future states, let (X π
)t≥0 be mining games
0 = B. Define the coupling
where Miner 1 follows strategy π and f (π) respectively with X π
Q.
(X π
(B)

t )t≥0 and (X f (π)
0 = X f (π)

)t≥0 where Miner k creates block t

N in both games. Let q = min (

(v,

t , X f (π)

))

t

t

U

∩

∞

\

≥

56

If Miner 1 creates block N , at state (X Half
Q
q
}
∪ {
the cases:

pointing to v. Moreover, at all time steps t

1

≥

)f (π), let f (π) publish Q pointing to v. Else, let f (π) publish
s, we consider

1, whenever π publishes u

→

• If u = q, f (π) does not publish.

• If s = N , f (π) publishes u

q instead.

• If u

= q and s

→
= N , f (π) also publishes u

s.

→

Then, for all time steps t

0,

≥

Rev(t)

γ (f (π))

≥

(X π

t ))

A(
|

C

1t=N −1
t ))

| −
(X π

·

δ1(B)

.

T1
∩
h(
C

Proof. Let’s check f (π) is a trimmed and valid strategy. Up to state B, f (π) is equals to π which,
by assumption, is trimmed and valid. At state B, we consider the case where Miner 1 or Miner 2
creates block N separately. For the case Miner 1 creates block N , f (π) is equals to π except f (π)
delays one round to publish Q pointing to v. Then f (π) copy all future actions of π. Thus for the
case Miner 1 creates block N , f (π) is trimmed and valid since π is trimmed and valid.

For the case Miner 2 creates block N , f (π) first publishes Q
(v,

pointing to v at step N . Let’s
Q is well-defined since, by
check this action is valid and trimmed. Note q = (
). Moreover, the immediate successor of block v
assumption, Q is a strict subset of
∞
∩
must be a block created by Miner 2; otherwise, PublishPath(Q, v) would not be a trimmed action
at state B. Thus, at step N , publishing Q

pointing to v is valid and trimmed action.

∪{
∞

q
}
))

(B)

(B)

(v,

∩

U

U

\

q

Next, still considering the case Miner 2 creates block N , we proof the simulations of π and
)) are identical except
f (π) satisfy the invariant that the longest paths A(
C
max Q. In π’s longest path, z is either equals to q or N , while in f (π)’s longest
for the edge z
path, z is always equals to q. The invariant is clearly satisfied after π publishes Q
pointing to
v so we need to check that, in the future, the invariant is preserved whenever π or f (π) publishes
blocks.

t )) and A(

(X f (π)
t

(X π

∪{

→

C

}

q

∪ {

}

First, observe all blocks Q reached finality with respect to π. To check, by assumption, v
reached finality with respect to π and the fact π is trimmed implies π would never take an action
v (since v
PublishPath(Q(cid:48), v(cid:48)) where the immediate successor of block v(cid:48) is in Q. Since v(cid:48)
reached finality), we must have v(cid:48)
max Q. This proves max Q (in fact all blocks in Q) reached
finality with respect to π. Next, we prove the invariant and f (π)’s actions are valid and trimmed.
Consider the event π publishes u

s. We divide the proof into three cases:

≥

≥

→

• u = q. For this case, we claim s = max Q. The fact max Q reached finality with respect
to π implies s
max Q. Because q was an unpublished block at state B an π is about
≥
s < q < N . Thus s is block created by Miner 1
to publish q
s, we have max Q
→
since any blocks Miner 2 publishes pointing to max Q are bigger or equal than N . Note
, v) was an orderly action at state B since PublishPath(Q, v) was an
PublishPath(Q
q
}
Q. Thus π has no unpublished
orderly action at state B and q = min
(B)
)
∞
∩
blocks between max Q and q which implies s = max Q. This proves π is publishing edge
max Q as desired. Observe f (π) already published this edge at step N . Because π is
q
max Q is about to become an edge in the longest path (and N
timeserving, q
max Q

∪ {

(v,

→

≤

U

\

→

→

57

(cid:54)
(cid:54)
is about to become an orphaned edge) as desired. Once q becomes part of the longest path, q
reaches finality with respect to π since max Q reached finality with respect to π. To check,
observe the fact π is trimmed implies π would never take an action PublishPath(Q(cid:48), max Q)
since the immediate successor of max Q would be block q (a block created by Miner 1).

• s = N . Recall max Q must still be a block in the longest path since max Q reached
max Q is still an edge in the longest path while,
finality with respect to π. Thus N
→
max Q is the equivalent edge in the longest path of
by the inductive hypothesis, q
f (π)’s simulation. By the inductive hypothesis, the immediate successor of block N and q
are identical. Moreover, the immediate successor of block N is a block created by Miner 2
(since π is trimmed and π is about to publish edge u
q is a
→
N preserves
trimmed action for f (π). Moreover, publishing edge u
the invariant as desired.

N ). Thus publishing u

q instead of u

→

→

→

→

• u

= q and s

= N . First, we claim s > max Q. Recall block max Q reached finality
max Q. If s = max Q, then u = q because π is trimmed
with respect to π. Then s
(and orderly) and q was one of π’s unpublished blocks at state B. This contradicts u
= q
and proves s > max Q as desired. From the inductive hypothesis, s is also a block in the
s is a valid and trimmed
longest path of f (π)’s simulation. Therefore, publishing edge u
action for f (π) that preserves the invariant.

→

≥

This proves f (π) is valid and trimmed and proves the invariant that the longest path in π’s and
max Q, in π’s simulation, is replaced by
f (π)’s simulation are identical except when edge N
→
edge q
max Q, in f (π)’s simulation. Let’s now compare the revenue of f (π) and π. Clearly,
the height of the longest path in f (π) is at most the height of the longest path in π. In fact, the
1)-th step, the height can be
heights are identical until the (N
−
strictly lower for f (π) when f (π) waits but π publishes Q pointing to v. After the N -th step, the
longest paths have the same height.

2)-th step. During the (N

→

−

2)-th
Let’s now compare how many blocks π and f (π) have in the longest path. Until the (N
step, both π and f (π) have the same number of blocks in the longest path. During the (N
1)-th
step, f (π) can have less blocks in the longest path when f (π) waits, but π publishes Q pointing
to v; however, the difference is bounded by δ1(B), Definition F.7, the maximum reward f (π)
can obtain from state B. After the N -th step, f (π) have at least the same number of blocks
in the longest path as π.
In fact, f (π) can have one more block when Miner 2 creates block
N and edge N
|A(C(X π

max Q. Thus for all t, Rev(t)

max Q is replaced by edge q

γ (f (π))

−
−

→

→

≥

t ))∩T1|−1t=N −1·δ1(B)
t ))

h(C(X π

as desired.

Proof of Theorem 5.14. Without loss of generality, let π be a trimmed, checkpoint preserving strat-
egy. Otherwise, from Theorem 5.12, there is a valid, trimmed strategy with the same revenue as
π. Initialize f (π) to be equal to π. To transform f (π) into a trimmed, checkpoint preserving and
opportunistic strategy execute the following procedure.

Step 1. While f (π) is not opportunistic, there is a state B where f (π) takes action PublishPath(Q, v)

). Let B be the first of such
where v reaches finality with respect to π, but Q
states that f (π) encounters during a mining game starting at state B0. From Proposition F.17,
there exists a strategy that is equals to f (π) up to state B and at state B onward, such strat-
egy executes the algorithm described in Proposition F.17. Update f (π) to be such strategy. Note

⊂ U

(B)

(v,

∞

∩

58

(cid:54)
(cid:54)
(cid:54)
f (π) is trimmed and both opportunistic and checkpoint preserving up to state B, but might not
be opportunistic nor checkpoint preserving on subsequent states. From Proposition F.8, there is
a strategy that is equals to f (π) up to state B and is checkpoint preserving on all subsequent
states. Let f (π) be such strategy. At this point f (π) is trimmed, checkpoint preserving, and
opportunistic up to state B, then return to Step 1.

Each time we execute Step 1, f (π) is trimmed, checkpoint preserving, and opportunistic on a
larger set of states. Therefore, ad infinitum f (π) becomes an opportunistic strategy. Observe the
end result of executing Step 1 ad infinitum is that whenever Miner 1 was about to take a non-
opportunistic action with a lead of k blocks, Miner 1 waits until the lead reduces to a single block,
then Miner 1 publishes. This sequence of actions is equivalent to the selfish mining strategy at
state B2,0.

Next, we compare the revenue of f (π) and π. Let (Xt)t≥0 be a mining game with initial state
X0 = B0 where Miner 1 follows strategy π. From Proposition F.17 and Corollary F.14, the revenue
of f (π) with respect to π is given by

Rev(t)

γ (f (π))

≥

h(

C

C

A(
(Xt))
T1
∩
|
|
(Xt)) + (cid:80)Nt
j=1 W j

j=1

+ (cid:80)Nt
0 + (cid:80)Nt

j=1

i=1 Z j
(cid:80)W j

i −
i=1 Z j

δ1(Xt)
i + δ1(Xt)

0

.

(cid:80)W j

0

where Nt denotes the number of times f (π) was transformed by Proposition F.8, W j
(Z j

i )i,j are i.i.d random variables with expected value

α
1−2α

1 and

0 ≥
. From superadditivity of lim inf
(cid:0)Rev(t)

Rev(t)

γ (π)(cid:1) .

γ (f (π))

−

lim inf
t→∞

Rev(t)

γ (f (π))

≥

lim inf
t→∞

Rev(t)

γ (π) + lim inf
t→∞

From Proposition F.15 and our lower bound on Rev(t)

lim inf
t→∞

(cid:0)Rev(t)

γ (f (π))

γ (f (π)),
γ (π)(cid:1)
Rev(t)

0.

−

≥
Rev(π) as desired.

Taking the expected value proves Rev(f (π))

≥

F.4 The Strong Recurrence Theorem
For a mining game (Xt)t≥0 starting at state X0 = B0 where Miner 1 follows optimal checkpoint
recurrent strategy π, define t0 = 0 and let t1, t2, . . . be the sequence of time steps where Miner
ti−1 and recall (τi)i≥1 is an i.i.d. sequence of positive random
1 capitulates to B0. Let τi = τi
variables. Thus Nn = (cid:80)∞
1ti≤n (with t0 = 0) is a counting process (Definition B.5) and satisfy
i=1
the following zero-one law.
Claim F.18 (Zero-One Law). One of the following holds,
• If Miner 1’s strategy is transient, P r [limn→∞ Nn <
• If Miner 1’s strategy is recurrent, P r [limn→∞ Nn =

] = 1.

] = 1.

∞

−

Proof. Without loss of generality, let X0 = B0. Let p be the probability that Miner 1 capitulates
to state B0 at time τ

1. If Miner 1’s strategy is transient, p < 1 and we get

∞

(cid:104)

P r

lim
n→∞

Nn <

≥

(cid:105)
∞

∞
(cid:88)

(cid:104)

P r

=

If p = 1, P r [limn→∞ Nn <

∞

(cid:105)

∞
(cid:88)

pi(1

p) = (1

1

p)

1

−

= 1.

p

lim
n→∞

Nn = i

=

−
i=0
] = 0 which implies limn→∞ Nn =

i=1

−
almost surely.

∞

59

For the case where Miner 1’s strategy is transient, Claim F.18 implies that with probability
1, the game will reach a time step ti where Miner 1 never defines another checkpoint. From the
definition of checkpoints, this implies Miner 1 never publishes more than half of all the blocks
they creates after time step ti. This simple observation suffices to witness that FRONTIER has at
least the same payoff as π.

Claim F.19. If π is checkpoint recurrent and transient, Rev(π)
Proof. Recall tNn ≤
almost surely as n

(because Nn <

α.

≤

n < tNn+1 (because Nn is a counting process). From Claim F.18, tNn <

∞

→ ∞

Rev(n)

γ (π) = |

A(
C

∞
(XtNn ))

∩

T1

almost surely as n
+ (cid:80)n
|
h(
C
t=tNn +1 r1(Xt−1, Xt)
h(

(Xn))

(Xn))

.

C

tNn + (cid:80)n

≤

). Thus

→ ∞
t=tNn +1 r1(Xt−1, Xt)

During time step tNn ≤
publishes at most half of all blocks created from time tNn + 1 to t:

t < tNn+1, Miner 1 has not yet reached a new checkpoint. Thus Miner 1

n
(cid:88)

t=tNn +1

r1(Xt−1, Xt)

1
2

n
(cid:88)

i=1

≤

1i∈T1

where the inequality is Corollary 5.9. Recall the height of the longest path h(
C
at least (cid:80)n
– the number of blocks Miner 2 creates up to time t. Thus

1i∈T2

i=1

(Xt)) at time t is

tNn + (cid:80)n

r1(Xt−1, Xt)

t=tNn+1
h(
C

(Xn))

1i∈T1

1i∈T1

(cid:80)n

tNn + 1
i=1
2
h(
(Xn))
C
(cid:80)n
tNn + 1
2
(cid:80)n
n tNn + 1
2n
(cid:80)n

i=1

i=1

1

1i∈T2
(cid:80)n
1i∈T2

i=1

i=1

1
n

1i∈T1

≤

≤

=

a.s.
→

α/2
α
1

−

The last step observes tNn
n
α, and P r [i

T2] = 1

0, and uses the strong law of large numbers and the fact P r [i

a.s.
→
α. Since α < 1/2, we get Rev(π)

α.

T1] =

∈

∈

−

≤

Next, we consider the case where π is checkpoint recurrent and null recurrent which implies

E [τi] =

for i

≥

∞

1. To see that that Rev(π)

Rev(FRONTIER), let
≤
(cid:15) (cid:80)
i∈S τi
S
|

|

AS =

1≤i≤N into DN =

τi
≤
{
DN . From the strong law of large numbers, we obtain A[N ]

for any (cid:15) > 0. Then partition
[N ]
Interestingly, this implies mini∈DN τi

\
Recall Miner 1 capitulates to state B0 at time steps ti and ti+1 (whenever Miner 1 defines a
new checkpoint). Let ki be the number of blocks Miner 1 creates from time ti + 1 to ti+1. By

and FN =
}
because π is null recurrent.

i
≤
a.s.
→ ∞
A[N ].

since mini∈DN τi

N : τi > A[N ]

a.s.
→ ∞

1
{

≥

}

60

−

1; otherwise,
definition, Miner 1 does not define a new checkpoint from time ti + 1 to ti+1
1. Thus up to time
Miner 1 would have capitulated to state B0 between time ti + 1 and ti+1
step ti+1
1, Miner 1 publishes less than ki/2 blocks (Corollary 5.9). If we hope for Miner 1’s
strategy to be better than FRONTIER, Miner 1’s strategy must publish a significant fraction (cid:15)ki,
for some (cid:15) > 0, of their blocks at time step ti+1. We expect the probability of Miner 1 publishing
(cid:15)ki blocks diminishes exponentially in ki because Miner 1 must create more blocks than Miner
2 (but Miner 2 has probability 1
α > 1/2 of creating each block). Lemma F.11 formalizes this
intuition.

−

−

−

Claim F.20. If π is checkpoint and null recurrent, Rev(π)
Proof. Recall tNn ≤

n < tNn+1 (because Nn is a counting process). Thus

α.

≤

(Xn))

A(
|

C

T1

|

∩

=

n
(cid:88)

t=1

r1(Xt−1, Xt)

(16)

=

Nn−1
(cid:88)

j=0

(cid:18)

r1(Xtj+1−1, Xtj+1) +

tj+1−1
(cid:88)

t=tj +1

r1(Xt−1, Xt)

(cid:19)

+

n
(cid:88)

t=tNn

r1(Xt−1, Xt).

(17)

From time step tj + 1 to tj+1, for j
0, Miner 1 publishes only blocks created from time step
tj + 1 to tj+1 (because Miner 1 capitulates to state B0 at time steps tj and tj+1). Observe Miner
1 did not reached a new checkpoint by time step tj+1
1 (because the strategy is checkpoint
recurrent). This implies Miner 1 publishes less than half of all the blocks created from time step
tj + 1 to tj+1

1. From Corollary 5.9, we get

1 by time step tj+1

−

≥

−

−

tj+1−1
(cid:88)

t=tj +1

r1(Xt−1, Xt)

1
2

≤

tj+1
(cid:88)

i=tj +1

1i∈T1.

(18)

From (16) and (18),

(Xn))

A(
|

C

T1

∩

| ≤

1
2

n
(cid:88)

i=1

1i∈T1 +

Nn(cid:88)

i=1

r1(Xti−1, Xti).

Recall the height of the longest chain is at least the number of blocks Miner 2 creates. That is
h(
C

1i∈T2

(Xn))

. Thus

(cid:80)n

≥

t=1

Rev(π) = E

(cid:104)
lim inf
n→∞

Rev(n)

γ (π)

(cid:105)

E

≤

(cid:34)

1
2n

(cid:80)n

i=1

lim inf
n→∞

1i∈T1 + 1
n
(cid:80)n

(cid:80)Nn

j=1 r1(Xti−1, Xti)
1i∈T2

i=1

(cid:35)

1
n

(cid:34)

= E

lim inf
n→∞

α

2 + 1

n

(cid:80)Nn

j=1 r1(Xti−1, Xti)
1

α

−

(cid:35)

(cid:34)

α + E

≤

lim inf
n→∞

1
n

Nn(cid:88)

i=1

r1(Xti−1, Xti)

Because α < 1/2.

(cid:35)

From the strong law of large numbers.

From the Zero-One Law there is there is a sequence of time steps t1, t2, . . . where Miner 1 capitu-
1. For a subset of t1, t2, . . .,
lates to state B0 (and t0 = 0). Fix any (cid:15) > 0. Let τi = ti

ti−1 for i

−

≥

61

N, CS = (cid:80)

i∈S τi and AS = (cid:15)CS
let S
|S|
(because Nn is a counting process). Then

⊂

and observe C[N ] = τN for all N

N. Note n

tNn

≥

∈

1
n

Nn(cid:88)

i=1

r1(Xti−1, Xti)

≤

=

1
tNn

Nn(cid:88)

i=1

r1(Xti−1, Xti) =

1
C[Nn]

Nn(cid:88)

i=1

r1(Xti−1, Xti)

1
C[Nn]

Nn(cid:88)

i=1

(cid:16)
r1(Xti−1, Xti)

·

1τi<A[Nn] + r1(Xti−1, Xti)

1τi≥A[Nn]

(cid:17)

.

·

To bound the first term, note from time ti−1 + 1 to ti, Miner 1 only publishes blocks created from
time ti−1 + 1 to ti (and at most τi blocks were created in this time interval). Thus

1
C[N ]

N
(cid:88)

i=1

r1(Xti−1, Xti)

1τi<A[N ] ≤

·

1
C[N ]

N
(cid:88)

i=1

τi

·

1τi<A[N ] <

N A[N ]
C[N ]

= (cid:15).

To bound the second term,

1
C[N ]

N
(cid:88)

i=1

r1(Xti−1, Xti)

1τi≥A[N ] =

·

1
C[N ]

N
(cid:88)

i=1

τi

r1(Xti−1, Xti)
τi

·

1τi≥A[N ]

(cid:80)N

i=1 τi
C[N ]

≤

max
i∈[N ]

r1(Xti−1, Xti)
τi

·

1τi≥A[N ]

= max
i∈[N ]

r1(Xti−1, Xti)
τi

·

1τi≥A[N ]

By definition C[N ] =

N
(cid:88)

i=1

τi

Next, we claim maxi∈[N ]
·
variables τi and the fact Miner 1’s strategy is null recurrent implies E [τi] =
a.s.
strong law of large numbers, A[N ]
→ ∞

. Therefore, the event

0. Recall A[N ] is the average of i.i.d. random
. Thus from the

1τi≥A[N ]

∞

r1(Xti−1,Xti )
τi

a.s.
→

(cid:26)

lim sup
N →∞

max
i∈[N ]

r1(Xti−1, Xti)
τi

·

(cid:27)

1τi≥A[N ] > 0

implies there is a mining game (Yt)t≥0 where lim supt→∞
r1(Yt−1,Yt)
t

0. Summing up,

a.s.
→

r1(Yt−1,Yt)
t

> 0; however, from Lemma F.11,

Rev(π)

≤

α + (cid:15) + E

(cid:20)

lim inf
N →∞

max
i∈[N ]

r1(Xti−1, Xti)
τi

·

(cid:21)

1τi≥A[N ]

= α + (cid:15)

as desired.

Proof of Strong Recurrence Theorem 5.15. From the Weak Recurrence Theorem 5.4 there exists an
optimal strategy π that is checkpoint recurrent. Recall FRONTIER is a potential candidate since
FRONTIER is checkpoint and positive recurrent (Observation 2.5), and Rev(FRONTIER) = α
(Corollary 5.7). From Claim F.19 and Claim F.20, Rev(π)
α unless π is positive recurrent. Thus
there exists an optimal strategy π that is checkpoint and positive recurrent. Suppose not, then
Rev(π)

α = Rev(FRONTIER) which witnesses FRONTIER is optimal.

≤

≤

62

G Omitted Proofs From Section 6

The main observation to show FRONTIER is optimal (for sufficiently small α) is to note that any
mining game starting at state B0 will transition to either state B0,1 or state B1,0 (see Figure 3).
(B0) = 0 (Lemma C.4). From the
Recall the value faction
recursive definition of the value function,

(Definition C.3) evaluated at B0 is

V

V

(B0) = E [rλ∗(X0, Xτ )] = α

0 =

V

(B1,0) + (1

V

α)(

V

−

(B0,1)

−

λ∗)

where λ∗ = maxπ Rev(π) and τ
1 is the first time step where Miner 1 capitulates to state B0.
Note block 1 is a checkpoint in state B0,1. From Theorem 5.15, Miner 1 has an optimal strategy
that never forks a checkpoint (or block 1 in state B0,1). Therefore, there is an optimal strategy
that capitulates to state B0 from state B0,1. The following results will give us a closed form for
the value function

evaluated at state B0,1.

≥

V

Proposition G.1. For any state B,

(B)

V

≥

0.

Proof. From Bellman’s principle of optimality (Lemma C.6),

(B)

λ∗
π (B)

V

≥ V
for any positive recurrent strategy π. Let π be a strategy that capitulates to state B0 from state
B. From state B, Miner 1 can follow any optimal strategy π∗ as if it was at state B0 by treating
the longest chain

≥ V
Proposition G.2. If there is an optimal positive recurrent strategy that capitulates to state B0 from
state B,

(B) = 0.

(B) as block 0. Thus

(B0) = 0.

(B)

V

C

Proof. Let π∗ be an optimal strategy that capitulates to state B0 from state B. From state B0, Miner
1 can follow strategy π∗ as if it was at state B by treating block 0 as the longest chain
(B). Then
0 =

(B). From Proposition G.1,

(B) = 0 as desired.

0. Thus

(B)

(B0)

C

V

≥

V

Corollary G.3. Once at state B0,1, the optimal action for Miner 1 is to capitulate to state B0. Thus

V

V

≥ V

(B0,1) = 0.

V
Proof. From the strong recurrence theorem, it is optimal for Miner 1 to capitulate to state B0 from
state B0,1. Thus state B0,1 satisfy the conditions for Proposition G.2 and

(B0,1) = 0.

V

To show FRONTIER is optimal (for sufficiently small α), it suffices to show that

(B1,0) is
maximized when Miner 1 publishes 1
0 and capitulates to state B0. Then there is an optimal
strategy taking the same actions as FRONTIER and capitulates to state B0 every round as desired.
0 and capitulates to state B0.
λ∗ since Miner 1 adds one block to the longest path. From

Formally, consider a strategy that, at state B1,0, publishes 1

→

→

V

The game reward (Definition C.2) is 1
Bellman’s principle of optimality,

−

Next, suppose strategy π does not publish 1

≤
(B1,0) (when α is sufficiently small), we will derive a certificate that there is an optimal strategy
0 at state B1,0. For that, we observe that starting from state B1,0, and under the

V
that publishes 1

→

≤

−

V

λ∗
π (B1,0)

1

λ∗

(B1,0)

1

λ∗.

V

−

≥
0 at state B1,0. By showing

→

63

assumption Miner 1 does not publishes any blocks until at least the next round, the subsequent
state is either B2,0 = ((
) when Miner 1 creates and withhold block 2, or
,
),
0
∅
}
{
,
),
0, 2
B1,1 = ((
1
0
}
{
}
{
}
{
λ∗
π (B1,0) = α

1, 2
{
}
) when Miner 2 creates block 2 and publishes 2
1
→
}
{
λ∗
π (B2,0) + (1

→
(B1,1)

(B2,0) + (1

λ∗
π (B1,1)

1, 2
}
{

0. Then

λ∗)

λ∗)

α)(

α)(

α

2

,

,

V

≤
where the inequality is Bellman’s principle of optimality.

−

−

V

V

V

−

V

−

As a warmup, we will show how we can derive the upper bound of

. As a
thought experiment, image Miner 1 never forks block 2. Then block 1 is “useless” since it cannot
point to any block
2. We would like to formalize what it means for Miner 1 to “forget” blocks
≥
1 and 2 from state B1,1. Once we forget blocks 1 and 2 from state B1,1, state B1,1 is equivalent to
B0 (or Miner 1 capitulates to state B0).

(B1,1)

α
1−α

≤

V

At state B, we say a block q

(B) can reach height (cid:96) (from state B) if one of the

(B)

∈ V

∪ U

two holds:

• If q

∈ V

(B) was already published, then h(q)

(cid:96).

≥

• If q

(B) is unpublished, then there is an action that Miner 1 can take from state B such

∈ U
that h(q)

≥

(cid:96) in the subsequent state.

Recall any blocks created in the future can point to any block
q cannot point
to any block > q. Thus if block q cannot reach height (cid:96) from state B, then q cannot reach height
(cid:96) from any state reachable from B.

q but any block

≤

≤

,

Example G.4. At state B2,0 = ((
{
Miner 1 can publish 2
V be any subset of
Definition G.5 (Induced Subgraph). Let G = (V, E) be a graph and let S
the vertices of G. The induced subgraph G[S] is the graph whose vertex set is S and whose edge set
consists of all edges in E with both end points in S.

,
1, 2
}
{
0, but block 2 cannot reach height

), block 2 can reach heights 1 and 2 because

1, 2
}

),
∅

0
}

→

→

3.

≥

⊆

{

1

Definition G.6 (State Capitulation). Let B = (Tree,
D
0
}
∪ U \ {
c-Capitulation of B as the state

A(
C

⊆

)

as the set of blocks that cannot reach height

U

≥

, T1) be a state and let c

(B)). Define
h(
C
c + 1 from state B. Define the

≤

B[V

\

D] := (Tree[V

D],

\

U \

D, T1

D)

\

\

D] is an induced subgraph of Tree obtained by deleting blocks D.

where Tree[V
), its 1-Capitulation
Example G.7. For state B2,2 = ((
1, 4
1, 4
3
}
{
}
deletes blocks 1 and 2, but not blocks 3 (since it is already at height 2) and 4 (since it can reach height
3 if Miner 1 publishes 4
2). Thus the 1-Capitulation of
state B2,2 is the state

,
0, 2, 3
0
}
{
}
{
3 or height 2 if Miner 1 publishes 4

→

→

→

→

),

{

2

,

B2,2[
→
Additionally, we could capitulate at height 2 to get state

3, 4
}
{

0, 3
}
{

] = ((

{

3

,

),

0
}

,

4
}

4
}
{

{

).

),
0
∅
}
since block 4 can reach height 3 if Miner 1 publishes 4
height 3.

4
}
{

] = ((

B2,2[

{

,

→

,

)
4
}

4
{
}
3, but all other blocks can only reach up to

{

64

Recall Hi(B) denotes the block at height i in state B – i.e., h(Hi(B)) = i. Next, we show

how to upper bound

(B) in terms of

V

Lemma G.8. Let B be a state, c

h(

C

≤

(B(cid:48)) where B(cid:48) is the c-Capitulation of B.

V
(B)), and let B(cid:48) be its c-Capitulation. Then

(B)

V

≤ V

(B(cid:48)) + rλ∗(B0, B(cid:48))

rλ∗(B0, B) +

−

c
(cid:88)

i=1

(P r [Hi(Xτ )

T1

X0 = B]
|

−

∈

λ∗)

(19)

where λ∗ = maxπ Rev(π) is the optimal revenue, and τ is the first time step Miner 1 capitulates
to state B0 in mining game (Xt)t≥0 starting from state X0 = B where Miner 1 follows an optimal
strategy.

strategy at state B by ignoring everything that happens at height
of optimality,

For intuition behind Lemma G.8, observe a possible strategy at state B(cid:48) is to copy the optimal
c. From Bellman’s principle
(B(cid:48)) is lower bounded by the reward obtained by such strategy. Second, observe
(B) + rλ∗(B0, B) is equals to the expected number of blocks Miner 1 has in the longest path
V
(B) into
at Xτ minus the length of the longest path times λ∗. Finally, Lemma G.8 breaks down
V
four pieces: the first and second terms count the contributions from height > c which is at most
c that our strategy

(B(cid:48)) + rλ∗(B0, B(cid:48)); the fourth term, counts the contributions from heights

≤

V

≤

V
for B(cid:48) ignores.

Example G.9. Consider B where Miner 1 has on unpublished block 1, and Miner 2 has published
(B(cid:48)) is 0, rλ∗(B0, B(cid:48)) is
4
2
→
0 and rλ∗(B0, B) is

0. Let c = 3, then the c-Capitulation B(cid:48) of B is B0. Note

3λ∗. Thus Lemma G.8 implies

→

→

V

3

−

(B)

V

≤

0 + 0 + 3λ∗ +

3
(cid:88)

i=1

(P r [Hi(Xτ )

T1

X0 = B]
|

−

∈

λ∗)

3.

≤

T1(B), T2(B)
}
{

Proof of Lemma G.8. Let T = max
be the last block created at B. Define the
mining game (Xt)t≥0 starting at state X0 = B with Miner 1 following any optimal strategy π.
Without loss of generality, π is a trimmed, positive recurrent strategy π (Theorem 5.15). Define
the mining game (X (cid:48)
0 = B(cid:48) with Miner 1 following a strategy π(cid:48) (that will
1, Miner 1 creates block
depend on π). Define a coupling between each game where at time t
t + T with probability α in both games; otherwise, Miner 2 creates block t + T in both games.
Define π(cid:48) as follows:

t)t≥0 starting at state X (cid:48)

≥

• If π plays Wait in state X Half

t

, π(cid:48) plays Wait in state X (cid:48)Half

t

.

• If π capitulates to state B0 from state Xt, π(cid:48) capitulates to state B0 from state X (cid:48)
t

.

• If π plays PublishPath(Q, v) at state X Half

t

, we will consider two distinct cases. Let

Q(cid:48) =

Then, at state X (cid:48)Half

t

∈

q

{
,

Q : h(q)

c + 1 after π plays PublishPath(Q, v)
}

≥

– If h(v) > c, π(cid:48) plays PublishPath(Q(cid:48), v).

65

– If h(v)

c, π(cid:48) plays PublishPath(Q(cid:48), 0).

≤

For the graph Tree(B) = (V(B), E(B)), V(B) denote the set of blocks that were already pub-
lished at state B. Let S(Xt) be the blocks q
t) =
V(X (cid:48)
t)

V(Xt) with height h(q)

c + 1 and let S(X (cid:48)

≥
t)t≥0 induces

∈

. Then for all t, the coupling between (Xt)t≥0 and (X (cid:48)
t)] = Tree(Xt)[S(Xt)].
t)[S(X (cid:48)

Tree(X (cid:48)

0
}

(20)

\ {

≥

1 be the time step Miner 1 capitulates to state B0. Recall that for a state B(cid:48)(cid:48) reachable from
Let τ
state B, rλ(B, B(cid:48)(cid:48)) denotes the game reward obtained from state B to B(cid:48)(cid:48). If B(cid:48) is an intermediate
state between B and B(cid:48)(cid:48), we naturally have rλ(B, B(cid:48)) + rλ(B(cid:48), B(cid:48)(cid:48)) = rλ(B, B(cid:48)(cid:48)).
Observation G.10. For any λ

R and states B, B(cid:48), and B(cid:48)(cid:48),

∈
rλ(B, B(cid:48)) + rλ(B(cid:48), B(cid:48)(cid:48)) = rλ(B, B(cid:48)(cid:48)).

From definition of

V

(B) and Observation G.10,

Observation G.11. For any states B and B(cid:48),

V

rλ∗(B0, B) +

(B) = E [rλ∗(B0, B) + rλ∗(X0, Xτ )] = E [rλ∗(B0, Xτ )] .

(21)

rλ(B, B(cid:48)) =
A(
C
|
From Observation G.11,

(B(cid:48)))

T1

A(

C

| − |

∩

(B))

∩

T1

| −

λ (h(

C

(B(cid:48)))

h(

C

−

(B)))

E [rλ∗(B0, Xτ )] = E





h(C(Xτ ))
(cid:88)

i=1



1Hi(Xτ )∈T1 −

λ∗h(
C

(Xτ ))



= E





c
(cid:88)

i=1

1Hi(Xτ )∈T1 −

λ∗c +

h(C(Xτ ))
(cid:88)

i=c+1

λ∗(h(

C

(Xτ ))

−



c)



1Hi(Xτ )∈T1 −


h(C(X (cid:48)
(cid:88)

τ ))

1Hi(X (cid:48)

τ )∈T1 −

λ∗h(
C

i=1


 From (20).

(X (cid:48)

τ ))

=

c
(cid:88)

i=1

(P r [Hi(Xτ )

T1]

−

∈

λ∗) + E

From Observation G.11,




 = E [rλ∗(B0, X (cid:48)

τ )]

(X (cid:48)

τ ))

λ∗h(

C

h(C(X (cid:48)
(cid:88)

τ ))





E

1Hi(X (cid:48)

τ )∈T1 −

i=1
= E [rλ∗(B0, X (cid:48)
= rλ∗(B0, B(cid:48)) +
rλ∗(B0, B(cid:48)) +

0) + rλ∗(X (cid:48)
λ∗
π(cid:48) (B(cid:48))
(B(cid:48))

V
V

0, X (cid:48)

τ )]

≤
This proves

From Observation G.10,

From Lemma C.6.

(B)

V

≤ V

(B(cid:48)) + rλ∗(B0, B(cid:48))

rλ∗(B0, B) +

−

c
(cid:88)

i=1

(P r [Hi(Xτ )

T1]

−

∈

λ∗)

as desired.

66

(B1,1)

V

α
1−α

≤

We are ready to show

. First, we will observe that the probability Miner 1 adds

block 1 to the longest path once the game reaches state B1,1 is at most α
1−α
2 blocks to fork

Lemma G.12. Suppose at state B Miner 1 needs at least 0
(B)
h(v) +
(B))
v
∩
X0 = B, the probability Miner 1 removes
C

(B)), h(
C

)
|
∞

(B)—i.e., for all
1. Then for a mining game starting a state

C
≤
(v,
(B) from the longest path is at most (cid:0) α

+ (cid:96)

(cid:1)(cid:96).

A(

1−α

|U

≤

−

≥

∈

C

(cid:96)

.

For the proof, we will use a well known fact about one-dimensional random walks.

Lemma G.13. Let (Mt)t≥0 be a biased one-dimensional random walk with initial state M0 = i
and for t
and Mt = Mt−1 + 1 otherwise. Then the
−
probability Mτ = 0 for some τ

1 with probability α < 1
2
(cid:1)i.

1, Mt = Mt−1

0 is (cid:0) α

≥

≥
Proof. Let En =
n
Mt = 0
t=0{
}
∪
denotes the event where Mτ = 0 for some τ
theorem for probabilities implies

1−α

≥

be the event Mτ = 0 for some 0

τ

0. Since En

≤
≤
En+1 for all n

⊆

n. Note limn→∞ En
0, the continuity

≥

P r

(cid:104)

lim
n→∞

En

(cid:105)
M0 = i
|

= lim
n→∞

P r [En

M0 = i] .
|

Let pi = P r [En

Clearly p0 = 1 and pi = 0 for i

M0 = i]. Thus it suffices to compute pi and take the limit of n
|
i

n + 1 (since Mn

1). For 1

n

i

.
→ ∞
n,
≤

≤

≥
pi = αpi−1 + (1

≥

≥
−
α)pi+1.

−

Writing pi = αpi + (1

α)pi, we get

−

α

pi

pi+1 =

−
pi+1 = (cid:0) α

1−α

1

−
(1

(cid:1)i

(pi−1

pi).

−

α

Claim G.14. For 1

i

n, pi

−
Proof. The proof is by induction. For the base, i = 1, we have p1
i

2, the inductive hypothesis gives pi−1

pi = (cid:0) α

(cid:1)i−1

(1

≤

≤

−

1−α

p1).

≥

pi+1 =

pi

−

−
(cid:18) α
1
−
(cid:18) α
1

−

=

−

(cid:19)

(pi−1

pi)

−

(cid:19)i

p1).

(1

−

α

α

p2 = (1
−
p1). Then

−

p1)α/(1

−

α). For

Note (cid:80)n

i=1(pi

pi+1) = p1

−

−

pn+1 = p1. Thus

p1 =

n
(cid:88)

(pi

i=1

−

pi+1) = (1

p1)

−

n
(cid:88)

i=1

(cid:19)i

(cid:18) α
1

α
−
α) (cid:0) α
2α

−
1

1−α

−

(cid:1)n+1

.

(1

α

−

p1)

= (1

−

67

−
(cid:19)i−1

, (cid:0) α
1−α

(cid:1)n

Because α < 1
2
Next, we claim that pi−1 = (cid:0) α
statement holds for i

0. Rearranging and taking the limit of n
2 as n
1 (where the base case is implied from p1 = α
1−α

(cid:1)i−1 for i

→ ∞

→

1−α

≥

, proves p1 = α
1−α
. As inductive hypothesis, assume the

→ ∞

.

). From Claim G.14,

pi = pi−1

(cid:18) α
1

−

−

α

p1) =

(1

−

(cid:19)i−1

(cid:18) α
1

−

α

(cid:18) α
1

−

−

α

(cid:19)i−1 (cid:18)
1

(cid:19)(cid:19)

(cid:18) α
1

−

α

−

=

(cid:19)i

.

(cid:18) α
1

−

α

1−α

(cid:1)i as desired.

This proves pi = (cid:0) α
Proof of Lemma G.12. Consider a mining game starting at state X0 = B. Let (Yt)t≥0 be biased
1 if Miner 1 creates block
one-dimensional random walk with Y0 = (cid:96). For t
t and Yt = Yt−1 + 1 if Miner 2 creates block t. Miner 1 can only remove block
(B) from the
longest path if Miner 1 creates (cid:96) more blocks than Miner 2 since the beginning of the game. In
other words, we must have Yt = 0 for some t
(B)
is at most the probability Yt = 0 for some t

0. Thus, the probability Miner 1 forks block
≥
0. From Lemma G.13,
≥

1, let Yt = Yt−1

≥

−

C

C

P r [

∞
t=1{

∪

Yt = 0
}

] =

(cid:19)(cid:96)

.

(cid:18) α
1

−

α

Proposition G.15.

(B1,1)

V

α
1−α .

≤

Proof. The 1-Capitulation of state B1,1 is the state B0 because blocks 1 and 2 can only be at height
1. From the Lemma G.8,

(B1,1)

V

rλ∗(B0, B0) +

≤
= lim
t→∞

V
P r [H1(Xt)

(B0) + lim
t→∞

P r [H1(Xt)

T1

X0 = B1,1]
|

−

∈

λ∗

−

rλ∗(B0, B1,1)

T1

X0 = B1,1]
|

∈

The equality observes rλ∗(B0, B0) = 0,
λ∗. At
−
state B1,1, Miner 2 owns block 2 at height 1 and Miner 1 can only own the block at height 1 if
Miner 1 removes block 2 from the longest path. For that, we must have a time t
1 where Miner
1 creates one more block than Miner 2 from time 1 to t. From Lemma G.12, the probability of this
event is at most α
α
1−α
1−α

(B0) = 0 (Lemma C.4) and rλ∗(B0, B1,1) =

which proves

as desired.

(B1,1)

≥

V

V

≤

,

{

}

(
{

0
}

), [k], [k]
∅

Next, we will show that it is optimal for Miner 1 to wait at state B2,0. More generally, consider
(Equation 6) as the state where Miner 1 creates and withholds blocks
Bk,0 :=
1, 2, . . . , k. Intuitively, there is no advantage for Miner 1 to publish at Bk,0, for k
2, because
Miner 1 can safely wait to publish in the subsequent state. That is, even if Miner 2 publishes
the subsequent block, Miner 1 would still have sufficient blocks to fork the block Miner 2 just
published. We can further extend this intuition for a larger class of states where Miner 2 has
published blocks in the longest path. Formally, we define Ca(B) as the collection of states B(cid:48)
where

≥

• Miner 1 has no blocks in the longest path.

• Miner 1 has h(
C

(B(cid:48))) hidden blocks that cannot reach height > h(
C

(B(cid:48))).

68

• Capitulating B(cid:48) at the longest chain result at state B. That is, if Miner 1 forgets all blocks
(B(cid:48))), we obtain state B.

that cannot reach height > h(
C

In other words,

Ca(B) :=

{

B(cid:48) is a state :

(B(cid:48)))

A(
C
T1(B(cid:48))
|
h(

,
= h(
C
(B(cid:48)))-Capitulation of B(cid:48) is state B

T1 =
∅
T1(B)
|

∩
| − |

(B(cid:48))),

C

.
}

As an example, consider a state B
∈
publishes block 4
0. Observe if B
∈
→
when Miner 1 creates and withholds the next block or B(cid:48)
and publishes the next blocks. When k
at state B
strategy is to publish all blocks and fork the whole longest path when α is sufficiently small.

Ca(B2,0) where Miner 1 creates blocks 1, 2, 3 and Miner 2
Ca(Bk+1,0)
Ca(Bk−1,0) when Miner 2 creates
2, we will show there is an optimal strategy that waits
Ca(B1,0). Once at state B(cid:48), the optimal

Ca(Bk,0) until the game reaches a state B(cid:48)

Ca(Bk,0), then the subsequent state is B(cid:48)

≥

∈

∈

∈

∈

Let’s check why the three conditions for a state B to belong to Ca(Bk,0) might be necessary
for this result. The condition that Miner 1 has no blocks in the longest path hints that forking all
the blocks in the longest path is optimal since Miner 1 has no blocks in there. The condition that
Miner 1 could fork all blocks in the longest path at B will imply it is optimal for Miner 1 to wait
at state B. For example, consider the state where Miner 1 withholds blocks 1, 5, 6 and Miner 2
published 3
0. This state satisfy the first and third conditions, but not the second. As a
2 is not optimal. The condition Bk,0
result, it is not clear how to argue that publishing 6
is the capitulation of B gives the property that the subsequent state is either in Ca(Bk−1,0) or
Ca(Bk+1,0).

→

→

→

→

5

2

Proposition G.16. Let α
Wait.

≤

1
2(3

−

√5). At state B

Ca(Bk,0), for k

∈

≥

2, it is optimal to play

t)t≥0 starting at state X (cid:48)

Proof. Define a mining game (X (cid:48)
0 = B where Miner 1 follows an optimal
positive recurrent strategy π∗. Define a mining game (Xt)t≥0 starting at state X0 = B where
Miner 1 follows a positive recurrent strategy π (to be defined later). Couple the mining games
(Xt)t≥0 and (X (cid:48)
1 + max V(B) in the first game if and
only if Miner k creates block n in the second game. Let τ (respectively τ (cid:48)) be the first time step
Miner 1 capitulates to state B0 in game (Xt)t≥0 (respectively (X (cid:48)
t)t≥0). Without loss of generality,
assume τ (cid:48)
Ca(B1,0). Define π as follows:

t)t≥0 so that Miner k creates block n

τ . Let T be the first time step t

1 where X Half

≥

≥
• For all t

• If X Half
T
state B0.

T

1, note X Half

t

∈

≤
−
= X (cid:48)Half
T

≥
Ca(Bk,0) with k

∈

t
2. Then π plays Wait at state X Half

.

t

≥

, π plays PublishPath(T1(XT ), 0) at state X Half

T

. Then π capitulates to

• If X Half

T = X (cid:48)Half

T

, π plays the same action as π∗ at state X Half

for all t

T .

To show it is optimal for Miner 1 to play Wait at state B
∈
optimal strategy. It is without loss of generality to assume B
for a game starting at B
for k

∈

2.

Ca(B2,0), π is also optimal for a game starting at state B

t

≥
Ca(Bk,0), it suffices to show π is an
Ca(B2,0) because if π is optimal
Ca(Bk,0),

∈

∈

≥

69

(cid:54)
Let E be the event X (cid:48)Half

= X Half
T

and let Ec be the complement of E. If X (cid:48)Half

T
0 since π∗ played the same actions as π up to time T

= X Half
,
T
T
1 and π plays

t = Xt for all t

then X (cid:48)
the same actions as π∗ after time T (inclusive). Then

≥

−

0, X (cid:48)

E [rλ∗(X (cid:48)

E] = E [rλ∗(X0, Xτ )
E] .
τ (cid:48))
|
|
(X (cid:48)Half
)) (because they published at
T
1). Next, we consider separately the case where Miner 1 has at
)) and the case where Miner 1 has at least two

, Miner 1 owns at least one block in A(
C

If X (cid:48)Half
= X Half
T
T
least one block up to time T
−
most one block in the longest path A(
C
(X (cid:48)Half
blocks in the longest path A(
)).
T
C
Case 1: Consider the case Miner 1 has at most one block in the longest path A(
C
this case, h(
X (cid:48)Half
T

(X (cid:48)Half
. Using the fact B0 is the h(
T1(XT )
)) =
T
|
|
in Lemma G.8 gives

(X (cid:48)Half
)). For
T
))-Capitulation of state

(X (cid:48)Half
T

(X (cid:48)Half
T

C

C

rλ∗(X (cid:48)

0, X (cid:48)Half

T

(X (cid:48)Half
T

)

) +

V

≤

rλ∗(B0, B0) +
h(C(X (cid:48)Half
))
T
(cid:88)

+

(B0)

V

(P r[Hi(X (cid:48)

τ (cid:48))

T1]

λ∗) + λ∗h(
C

−

∈

(B))

T1(XT )

i=1
(1
|

λ∗) + λ∗h(
C

(B)).

≤ |

−
(B0) = 0 (Lemma C.4) and rλ∗(B0, B0) = 0.

The second line observes
Case 2: Consider the case Miner 1 has at least two blocks in the longest path A(
k = 1, 2, let Mk =
{
the longest path A(
C
in Lemma G.8 gives

(X (cid:48)Half
)) : Hi(X (cid:48)Half
T
}
)). Using the fact B0 is the h(

)). For
C
be the heights Miner k owns blocks in
))-Capitulation of state X (cid:48)Half
(X (cid:48)Half
T

i
h(
C
≤
(X (cid:48)Half
T

(X (cid:48)Half
T

Tk

∈

V

C

)

T

T

rλ∗(X (cid:48)

0, X (cid:48)Half

T

(X (cid:48)Half
T

)

) +

V

≤

rλ∗(B0, B0) +

(cid:88)

+

i∈M1∪M2

V

(B0)
(P r [Hi(X (cid:48)

τ (cid:48))

T1]

λ∗) + λ∗h(
C

−

∈

(B))

=

M1
|

(1
|

−

(cid:88)

λ∗) +

(P r [Hi(X (cid:48)

τ (cid:48))

T1]

λ∗) + λ∗h(
C

−

(B))

T1(XT )

≤ |

(1
|

−

i∈M2
λ∗) + λ∗h(

T1(XT )

≤ |

(1
|

−

λ∗) + λ∗h(

T1(XT )
(1
|

≤ |

−

λ∗) + λ∗h(

∈
(cid:88)

i∈M2

(cid:88)

i∈M2

(B)) +

(B)) +

(B))

C

C

C

(P r [Hi(X (cid:48)

τ (cid:48))

T1]

α)

−

∈

(cid:32)(cid:18) α
1

−

α

(cid:19)2

(cid:33)

α

−

|

τ (cid:48))

T1 for i

is at most the number of blocks Miner 1 creates up to time τ
The second line observes
M1
|
α because Rev(FRONTIER) = α. For the third line, note the event
and λ∗ = maxπ Rev(π)
≥
M2 implies Miner 1 forks the longest chain
) at some point in
Hi(X (cid:48)
(X (cid:48)Half
the future. Because Miner 1 publishes at least two blocks in the longest path A(
)) and
T
C
(X (cid:48)Half
X Half
). Thus
T
T
C
(cid:1)2. The last line
from Lemma G.12, the probability of Hi(X (cid:48)
observes (cid:0) α
1−α

∈
Ca(B1,0), Miner 1 needs at least two blocks to fork the longest chain
M2 is at most (cid:0) α
τ (cid:48))

√5). This concludes the proof of the second case.

(X (cid:48)Half
T

T1 for i

0 for α

1
2(3

1−α

(cid:1)2

∈

∈

∈

∈

α

C

−

≤

≤

−

70

(cid:54)
Case 1 and 2 proves

E [rλ∗(X (cid:48)

0, X (cid:48)

Ec] = E (cid:2)rλ∗(X (cid:48)
0, X (cid:48)Half
τ (cid:48))
|
= E (cid:2)rλ∗(X (cid:48)
0, X (cid:48)Half
τ
E [
T1(XT )
(1
|
|

≤

−

τ

) + rλ∗(X (cid:48)Half
, X (cid:48)
τ (cid:48))
τ
Ec(cid:3)
(X (cid:48)Half
)
) +
τ
|
V
Ec]
λ∗) + λ∗h(
(B))
|

C

Ec(cid:3)
|

as desired. We claim

E [rλ∗(X0, Xτ )

Ec] = E [
|

T1(XT )
(1
|
|

λ∗) + λ∗h(
C

Ec] .
(B))
|

−

Recall, at state X Half
X Half
= X (cid:48)Half
T
T
adds
T1(XT )
|
|
removed from the longest path. Thus

T
. The game reward from state X0 to Xτ is
blocks in the longest path, plus λ∗h(

, π takes action PublishPath(T1(XT ), 0) and capitulates to state B0 whenever
λ∗), because Miner 1
(B)) blocks

(1
|
(B)), because Miner 2 has h(
C

T1(XT )
|

−

C

λ∗) + λ∗h(

Ec]
(B))
|

C

≥

−

E [rλ∗(X (cid:48)

0, X (cid:48)

Ec] .
τ (cid:48))
|

Ec] = E [
E [rλ∗(X0, Xτ )
T1(XT )
(1
|
|
|
λ∗
π (B)

We conclude

(B). From Bellman’s principle of optimality, π is optimal.

V
Because B2,0

∈

≥ V

Ca(B2,0), we proved that once the mining game reaches state B2,0, Miner 1

will prefer to wait until it reaches a state in B
∈
∈
Ca(B1,0), it is optimal for Miner 1 to publish all their hidden blocks (when α is sufficiently small).

Ca(B1,0). Next, we prove that at state B

Proposition G.17. Let α
1
2(3
Wait or PublishPath(T1(B), 0).

≤

−

√5). At state B

∈

Ca(B1,0), it is either optimal to take action

Proof. If waiting at state B is not optimal, then one of the following is optimal:

1. Miner 1 takes action PublishPath(T1(B), 0).

2. Miner 1 takes action PublishPath(Q, v) for some Q

T1(B).

⊂

We will show the action in the first case is strictly better than the action in the second case.

In the first case, let B(cid:48) be the subsequent state after Miner 1 plays PublishPath(T1(B), 0).
0 since Miner 1 can capitulate to state B0 from state B(cid:48). The
(B)) of Miner 2’s
(B)) + 1 blocks

From Proposition G.2,
≥
game reward from state B to B(cid:48) is λ∗h(
C
blocks in the longest path, plus (1
λ∗)(h(
C
in the longest path. Thus the game reward from state B until Miner 1 capitulates to state B0 is

C
(B)) + 1), because Miner 1 adds h(
C

(B)), because Miner 1 removes h(

(B(cid:48))

−

V

(B)

h(
C

≥

V

(B)) + (1

λ∗) +

(B(cid:48))

V

h(

C

≥

−

(B)) + (1

λ∗).

−

In the second case, let B(cid:48) be the subsequent state after Miner 1 takes action PublishPath(Q, v).
be the heights of the blocks Miner k owns in the longest
Let Mk =

(B(cid:48))) : Hi(B(cid:48))

Tk

h(

i
{

≤

C

∈

}

71

(cid:54)
path A(
C

(B(cid:48))). The h(
C
(B) = rλ∗(B, B(cid:48)) +

V

(B(cid:48)))-Capitulation of B(cid:48) is the state B0. Thus from Lemma G.8,

(B(cid:48)) = rλ∗(B0, B(cid:48)) +

(B(cid:48))

V
rλ∗(B0, B0) +

(B0) +

(cid:88)

−
V
(P r [Hi(Xτ )

rλ∗(B0, B)

T1

X0 = B(cid:48)]
|

−

∈

λ∗)

−

rλ∗(B0, B)

≤

=

M1
|

(1
|

−

λ∗) +

V

(cid:88)

i∈M2

(cid:88)

i∈M1∪M2

(P r [Hi(Xτ )

(cid:32)(cid:18) α
1

(cid:19)2

α

−

M1

≤ |

(1
|

−

λ∗) +

i∈M2
λ∗) + λ∗h(
λ∗)

(1
|
−
(B)) + (1

(B))

C

M1

≤ |
= h(
C

∈

T1

X0 = B(cid:48)]
|
(cid:33)

λ∗) + λ∗h(
C

−

(B))

α

−

+ λ∗h(
C

(B))

V

α and Miner 1 needs at least 2 blocks to fork

−
The third line observes
(B0) = 0 (Lemma C.4) and rλ∗(B0, B0) = 0. The fourth line observes
λ∗ = maxπ Rev(π)
(B(cid:48)) from the longest path.
Thus from Lemma G.8, the probability Miner 1 will own the block at height i
M2 is at most
(cid:0) α
√5). The sixth line observes Miner 1
1−α
(B)) + 1 blocks in the longest path. The chain of inequalities wit-
owns at most
nesses taking action PublishPath(T1(B), 0) is strictly better than taking action PublishPath(Q, v)
for some Q

≥
(cid:1)2. The fifth line observes (cid:0) α
1−α

T1(B)
|
|
T1(B).

α for α

= h(

1
2(3

(cid:1)2

≤

−

≤

∈

C

C

⊂

We are ready to show that for any state B
∈
PublishPath(T1(B), 0) (when α is sufficiently small).

Ca(B1,0), it is optimal for Miner 1 to play

Proposition G.18. Let α(1−α)2
for Miner 1 to take action PublishPath(T1(B), 0).

c + 1 where c = h(
C

(1−2α)2 ≤

(B)). At state B

∈

Ca(B1,0), it is optimal

Proof. Let λ∗ = maxπ Rev(π). The proof will be by induction on c. For the base case, we will
C where C is an absolute constant. Then we will prove the
proof the statement holds for c
≥
2, . . . , 0. If Miner 1 takes action PublishPath(T1(B), 0), the game
statement when c = C
reward is (1
= c + 1 blocks in the longest path, plus
λ∗c, because Miner 2 has c blocks removed from the longest path. Therefore,

−
λ∗)(c + 1), because Miner 1 adds

T1(B)
|
|

1, C

−

−

(B)

c + (1

λ∗) +

(B(cid:48))

c + (1

λ∗)

V

V

≥

−

≥
0 because Miner 1 can capit-
where B(cid:48) is the subsequent state. The inequality observes
(B(cid:48))
0.
ulate to B0 from state B(cid:48) (Proposition G.2). By assumption α(1
α)2
√5). From Proposition G.17, the only alternative to
Solving the inequality gives α
playing PublishPath(T1(B), 0) is to play Wait. Let π be any positive recurrent strategy that plays
Wait at state B. Let Z1
Ca(B2,0) be the subsequent state if Miner 1 creates and withholds the
∈
next block and let Z2
Ca(B0) be the subsequent state when Miner 1 creates and publishes the
next block. Then

2α)2 since c

≥
−

1
2(3

(1

≥

−

−

≤

−

≤

∈

V

λ∗
π (B) = α

V

V

λ∗
π (Z1) + (1

α)(

V

−

(Z2)

−

λ∗)

α

V

≤

(Z1) + (1

α)(

V

−

(Z2)

−

λ∗)

72

where the inequality observes
Observe the (c + 1)-Capitulation of state Z2 is state B0. Then from Lemma G.8,

(B(cid:48)) for any states B(cid:48) and strategies π (Lemma C.6).

≤ V

λ∗
π (B(cid:48))

V

rλ∗(B0, B0) +

(B0) +

V

c+1
(cid:88)

i=1

(P r [Hi(Xτ )

T1

X0 = Z2]
|

−

∈

λ∗)

−

rλ∗(B0, Z2)

(P r [Hi(Xτ )

T1

X0 = Z2]
|

−

∈

λ∗) + λ∗(c + 1)

(Z2)

V

≤

=

≤

c+1
(cid:88)

i=1

(c + 1)

1

α

−

.

α

The first line is Lemma G.8 applied to states Z2 and B0. The second line observes Miner 2 owns
λ∗(c + 1). The third line observes Miner 1
c + 1 blocks in the longest path. Thus rλ∗(B0, Z2) =
will only own the block at height i
(Z2). But Miner
1 needs at least one block to fork the longest chain
(Z2). From Lemma G.12, the probability
Miner 1 forks

c + 1 if Miner 1 can fork the longest chain

≤
.

−

C

C

(Z1). Observe the c-Capitulation of state Z1 is state B2,0. From

(Z2) is at most α
1−α

C
Next, we upper bound

Lemma G.8,

V

V

≤

(Z1)

rλ∗(B0, B2,0) +

rλ∗(B0, Z1) =
Recall the revenue λ∗ = maxπ Rev(π) of the optimal strategy is at least α and at most
(Corollary 5.7). Then

(B2,0) + c(1

(B2,0)

−

−

λ∗) + λ∗c =

V

V

V

(B2,0) + c

α
1−α

(22)

α
The bounds on λ∗, allow us to derive an upper bound on

≤

≤

−

1

α

λ∗

α

(B2,0).

V

Claim G.19.
Proof. At state B0, the subsequent state is either B1,0 or B0,1. Then

(B1,0)

≤

V

1.

From Proposition G.1,

V

V
(B0,1)

V
0. Thus

≥

0 =

(B0) = α

(B1,0) + (1

α)(

V

−

(B0,1)

−

λ∗).

(B1,0) = λ∗ 1

α
−
α ≤

1.

V

Claim G.20.
Proof. At state B1,0, if Miner 1 takes action Wait, the subsequent state is either B2,0 or B1,1. Then

(B2,0)

≤

V

1

α + 1.

1

(B1,0)

α

(B2,0) + (1

α)(

(B1,1)

λ∗)

α

(B2,0)

(1

α)λ∗

≥

≥ V

V
The first inequality is Claim G.19. The second inequality is Bellman’s principle of optimality
(Lemma C.6). The third inequality uses the fact
(B2,0)
gives

0 (Proposition G.1). Solving for

(B1,1)

−

≥

≥

−

−

−

V

V

V

(B2,0)

V

1
α

≤

+

α

λ∗

1
α

≤

−
α

+ 1

V
1

73

From Claim G.20, we obtain

Combining the upper bounds for

(Z1)

V
(Z1) and

V

+ 1 + c

1
α
≤
(Z2), we obtain

V

λ∗
π (B)

V

≤

1 + α + αc + α(c + 1)

λ∗(1

α)

−

−

α2

c + (1

λ∗) + 2α +

c(1

2α).

−

≤
(B). Unfortunately, the above upper bound on

−

−

α −

1

We would like to conclude by saying V λ∗

π (B) <
λ∗
π (B) is not strong enough for all c. Fortunately, for sufficiently large c, we obtain
λ∗
π (B) <

(B).

V

V

V

V

as desired. By Bellman’s principle of optimality, we have a certificate that it is sub-optimal to wait
at state B. The intuition is that Miner 1 risks not publishing blocks T1(B) by waiting at state B
(because if Miner 2 creates and publish the next block, the probability Miner 1 can publish T1(B)
1 is large, the cost of not publishing T1(B) outweighs
is at most α
1−α
the expected gain from not publishing T1(B) at state B.

). Thus when c =

T1(B)
|

To extend the proof to smaller c, we will do induction on c. The work above proves the
base case for any c > α(2−α)
. As inductive hypothesis, assume for all states B(cid:48)
Ca(B1,0)
with h(
c + 1, it is optimal for Miner 1 to take action PublishPath(T1(B(cid:48)), 0). Note
C
max T1(B(cid:48)) becomes a checkpoint. From Theorem 5.15, there is an optimal checkpoint recurrent
strategy which implies Miner 1 capitulates to state B0 once a new checkpoint is defined. Thus

(1−α)(1−2α)

(B(cid:48)))

| −

≥

∈

(B(cid:48)) = h(
C

V

(B(cid:48))) + (1

λ∗).

−

C

Ca(B1,0) and c = h(

(B)). To improve our upper bound on

λ∗
As before, let B
π (B), we will
∈
(Z1). In fact, our inductive hypothesis will allow us to derive a
improve our upper bound on
V
closed form on
Ca(B2,0). Let (Xt)t≥0 be a mining game starting at state X0 =
(Z1). Recall Z1
Z1. From Proposition G.16, Miner 1 will wait until the first time step τ where X Half
Ca(B1,0).
Note h(
c + 1 because Miner 2 published at least one block in the longest path since
C
state X0. From the inductive hypothesis, Miner 1 will take action PublishPath(T1(Xτ ), 0) at state
X Half
and
τ

V
(X Half
τ

≥

))

∈

∈

V

τ

From state Z1 to X Half
from state Z1 to X Half

τ

τ

V

(X Half
) = h(
τ
C
, Miner 2 publishes h(
C
is

(X Half
τ
(Xτ ))

h(
C

−

)) + (1

λ∗).

−
(Z1)) blocks. Thus the game reward

rλ∗(Z1, X Half

τ

) =

λ∗(h(
C

(X Half
τ

))

(Z1))).

h(
C

))

(X Half
τ

h(
C
−
Ca(B2,0) until state X Half
))

The random variable h(
state Z1
h(
C
whenever Miner 1 creates the block at time t (with probability α); otherwise, Yt = Yt−1
h(
C
number of blocks Miner 2 creates). Thus

−
(Z1)) denotes the number of blocks Miner 2 creates from
Ca(B1,0). From Lemma D.2, we can construct a coupling
1, Yt = Yt−1 + 1
1. Then
−
1 (i.e., the

(Z1)) with a random walk starting at state Y0 = 1 and for t

(Z1)) counts the number of time steps t

τ where Yt = Yt−1

∈
(X Half
τ

(X Half
τ

h(
C

h(
C

C
∈

≥

≤

−

−

−

−

))

τ

E (cid:2)h(

C

(X Half
τ

))

h(

C

−

(Z1))(cid:3) =

74

α
2α

.

1
1

−
−

Note h(
C
the work above, we derive

(Z1)) = h(
C

(B)) = c since no blocks are published from state B to state Z1. Combining

(Z1) = E (cid:2)rλ∗(Z1, X Half
τ
(Z1)) + (1

V

) +

= E (cid:2)h(
C
= c + (1

λ∗)

−

−
α
2α

1
1

−
−

)(cid:3)
(X Half
τ

(X Half
τ
V
λ∗)(h(
C
λ∗)

+ (1

−

))

h(
C

−

(Z1))) + (1

λ∗)(cid:3)

−

Substituting

(Z1) and our upper bound for

(Z2) in our upper bound for

λ∗
π (B),

V

= αc + (1

α)c

−

−

α)c + (1

λ∗) + α(1

λ∗)

−

−

−

+ α(c + 1)

(1

−

−

α)

λ∗
π (B)

V

≤

V
α

V
(cid:18)

(Z1) + (1

α

c + (1

−

≤

c + (1

−

≤

λ∗) + α

(B) + α

≤ V

(1
1

By assumption, α(1−α)2

(1−2α)2 ≤

V
λ∗)

(Z2)
α
2α

−
+ 1

−
λ∗)

α)(
1
1

V
−
−
(1

α)2
2α −

c(1

(c + 1)(1

−

−
−

(1
1
α)2
2α −

−
−
c + 1. Then

(cid:19)

λ∗

−

+ (1

α)

−

(cid:18)

(c + 1)

+ 1

λ∗

−

−

α

(cid:19)
1

α

−

1
α
2α

1
1

−
−

2α)

(1

−

−

−
2α) Because

2α) Because λ∗

α

≥

(B)

V

≥

c + (1

−

λ∗).

≤ V
as desired. The inequality witnesses that it is optimal for Miner 1 to take action PublishPath(T1(B), 0)
at state B

Ca(B1,0).

V

∈

λ∗
π (B)

(B)

We can now conclude that for α

≤

0.307979, FRONTIER is an optimal strategy.

→

→

Proof of Theorem 6.1. Assume Miner 1 follows an optimal strategy. From Theorem 5.15, it is with-
out loss of generality to assume such strategy is checkpoint recurrent and positive recurrent.
Starting from state B0, the subsequent state is either B0,1 when Miner 2 creates block 1 and pub-
lishes 1
0, or B1,0 when Miner 1 creates block 1, but yet did not decide between publishing
0 or waiting for the next round. From Corollary G.3, at state B0,1, it is optimal for Miner 1
1
to capitulate to state B0 (for any α). At Proposition G.18, let B = B1,0. Then c = 0 and as long
1. Thus it is optimal for Miner 1 to publish
as α
(1−2α)2 ≤
≤
0 at B1,0. Once Miner 1 take this action, from Definition 5.1, block 1 becomes a checkpoint.
1
Since Miner 1’s strategy is checkpoint recurrent, Miner 1 capitulates to state B0 once block 1 be-
comes a checkpoint. Thus Miner 1 capitulates to state B0 by the end of round 1 with probability
1. Additionally, up to round 1, Miner 1 is taking the same actions as FRONTIER. This witnesses
FRONTIER is an optimal strategy as desired.

0.307979, we satisfy the condition α(1−α)2

→

75

H Table of Notation

Symbol

Domain

Usage

Table 1: Notation.

n
γn
Ti
Tree

V
E

i

U
A(b)
Succ(b)
h(b)

C
Hi
(B)
BHalf

rk(B, B(cid:48))

rλ(B, B(cid:48))

Rev(π)

N+
1, 2
}
{
2N+
Directed trees
with a single sink
N+
N+
N+
2N
2N+
N+
N+
N+
N/A

N/A

N

R

R+

Succs(B)

Set of states

δk(B)

λ
π(B)

V

(B)

V

N

R

R

Round, or block created during a round
The miner during round n
The set of rounds where Miner i mines
Set of all published blocks, evolves over time

}

C

C

V

i,

U

∈

| −

V
V

V with highest

A(
Tree, V, E,

) with height i = h(v).

∈
∈
1, height of block b

Nodes in Tree
Edges in Tree
Blocks created by Miner i, but not yet published, evolves
over time
Ancestors of block b
Successors of block b
A(b)
:=
∈
|
The longest chain and the block v
height
Block v
∈
to denote its state at B.
Modifies
, H
{
Denote prior state prior to state B after the most recent
block was created, Miner 2 has acted, but Miner 1 has not.
(B))
Tk
:=
from state B to B(cid:48)
:= (1
−
state B to B(cid:48)
(cid:104)
:= E
of strategy π
:=
}
B when Miner 1 takes a single action at B.
, Miner k potential reward
:= maxB(cid:48)∈Succs(B)
|
at state B.
:= E (cid:2)rλ(X0, Xτ ) ¯X0 = B(cid:3) where τ is the first time step
Miner 1 capitulates to state B0
:= V

, Miner k reward
|
λr2(B, B(cid:48)), game reward from

(B) where π∗ = arg maxπ Rev(π)

, all states B(cid:48) reachable from state

r1(X0,Xn)
r1(X0,Xn)+r2(X0,Xn) |

B(cid:48) : (B(cid:48))Half = B
{

rk(B, B(cid:48))
|

(cid:105)
, revenue

λ)r1(B, B(cid:48))

lim inf n→∞

X0 = B0

A(
C
|

A(
C

(B(cid:48)))

Rev(π∗)
π∗

| − |

Tk

−

∩

∩

76

