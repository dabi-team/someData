1
2
0
2

t
c
O
2
1

]

C
D
.
s
c
[

1
v
3
0
0
6
0
.
0
1
1
2
:
v
i
X
r
a

Impact of delay classes on the data structure in IOTA

Andreas Penzkofer, Olivia Saa and Daria Dziubałtowska

IOTA Foundation, Berlin, Germany

Abstract. In distributed ledger technologies (DLTs) with a directed acyclic graph (DAG) data
structure, a message-issuing node can decide where to append that message and, consequently,
how to grow the DAG. This DAG data structure can typically be decomposed into two pools
of messages: referenced messages and unreferenced messages (tips). The selection of the parent
messages to which a node appends the messages it issues, depends on which messages it considers
as tips. However, the exact time that a message enters the tip pool of a node depends on the delay
of that message. In previous works, it was considered that messages have the same or similar
delay; however, this generally may not be the case. We introduce the concept of classes of delays,
where messages belonging to a certain class have a speciﬁc delay, and where these classes coexist
in the DAG. We provide a general model that predicts the tip pool size for any ﬁnite number of
diﬀerent classes.
This categorisation and model is applied to the ﬁrst iteration of the IOTA 2.0 protocol (a.k.a.
Coordicide), where two distinct classes, namely value and data messages, coexist. We show that
the tip pool size depends strongly on the dominating class that is present. Finally, we provide a
methodology for controlling the tip pool size by dynamically adjusting the number of references
a message creates.

1

Introduction

Distributed Ledger Technologies (DLTs) have gained much attention as a means to process and conﬁrm
data and transactions in a decentralised fashion. A fundamental component is the underlying data
structure, which records messages either totally or partially ordered. Many DLTs, such as Bitcoin
[1], employ a blockchain structure, in which transactions are accumulated in blocks. These blocks are
appended to each other creating a totally-ordered child-parent relationship, which makes the fate of
the child block dependent on the parent. Certain DLTs such as IOTA, Nano, or Avalanche employ
a more complex, partially-ordered Directed Acyclic Graph structure (DAG) [2], [3], [4], in which a
message (or block) appends to several parent messages (or blocks), see Fig. 1a).

Typically, it is assumed that messages require similar time for propagation, processing and creation,
which can be summarized by a generic delay [5]. While this may be reasonably precise when messages
have the same content and similar size, this assumption may not hold in scenarios where diﬀerent types
of messages exist or even when messages have similar content but diﬀerent sizes ; ﬁrst, messages can
have diﬀerent roles and content —such as utility messages, value transactions, or only generic data—,
which can lead to diﬀerences in the processing time. For example, a value transaction will have to
pass additional checks compared to generic data, since a value transfer aﬀects the token ownership
in the ledger. Second, the propagation time may also depend on other factors, such as message size
or prioritization of messages on the communication layer (as an example, in Bitcoin, the propagation
time of a block depends on the byte size of the content [6]). which Third, for rate control purposes,
messages may have to be created with a proof of consumption of a scarce resource. Typically, the
proofs of consumption used are Proof of Work (PoW) or Veriﬁable Delay Functions (VDFs) which,
due to the computation time, add a delay. If several types of devices are present in the network, or
messages require diﬀerent diﬃculty levels for the PoW/VDF, the times for the message creation may
diﬀer signiﬁcantly.

Fig. 1b) illustrates how the introduction of a new class of (yellow) messages with larger delay can
extend the time until ﬁrst reference, alter the DAG structure and the size of the tip pool —i.e., the pool

1

 
 
 
 
 
 
of messages that were not referenced yet. Speciﬁcally, the yellow class of messages will be added to the
tip pool at a much later time compared to their issuance time, thus, eﬀectively contributing to the DAG
much later than the original class of messages. Moreover, the delay in the addition of this message to
the tip pool implies a delay in the removal of its parents from the tip pool (messages are removed from
the tip pool during inclusion of messages referencing them). Thus, a second message with a smaller
delay can also reference those same parents. Since this second message can be eﬀectively added to the
DAG before the old (and delayed) ﬁrst message, the delayed message might not contribute to the tip
pool removal at all. Generally, the larger the delay of a message in comparison to other messages, the
smaller the contribution it has to the removal of tips from the tip pool. These alterations in the DAG
growth dynamics can lead to a signiﬁcant change in some variables of interest, such as the number of
tips or the width of the DAG. Since these attributes can have a major impact on the performance of
the DLT, their accurate prediction and control are of vital importance.

Overview of the paper. In sections 2 and 3, we will focus on the ﬁrst iteration of the IOTA 2.0
protocol [7] (a.k.a. Coordicide), and describe how it introduces two speciﬁc classes of messages with
distinct delay times. Since the Coordicide is still an ongoing research project, progressing through
several iterative development stages, it is worth noting that the substance of the delay classes may
be signiﬁcantly altered in subsequent protocol implementations. However, the implementation details
described in this paper are aligned with the initially proposed protocol [7]. Due to the generic depen-
dency on the delay of messages, the derived results can be readily transferred to other scenarios and
DLTs, where messages with diﬀering delay times are present.

In general, there can be several classes of messages with diﬀerent delay times, which are introduced
in Section 4. We provide a generic model for n diﬀerent classes, that accurately predicts the tip pool

a) One delay class of message.

b) Two delay classes of messages.

Fig. 1: The illustrations show a DAG data structure, where messages are displayed as blocks, and child-parent
relationships are displayed as arrows. Messages are sorted from left to right by their time of issuance. In a)
all messages have a similar delay, while in b) a new class of message is introduced (marked in yellow) with
noticeably increased delay, thus extending the typical time diﬀerence between parent and child.

2

size, and validate it against simulation and experimental results. Finally, in Section 5 we apply the
model by describing a mechanism that enables the control of the tip pool size.

2 Types of messages and their processing

In the IOTA 2.0 protocol,1 two diﬀerent classes of messages coexist: data messages and value messages.
The ﬁrst type consists of messages containing a payload with only data (called data payload), whereas
the second one may also contain information about the transfer of funds and its associated unlock
data, such as signatures. A payload containing this additional information is called a value payload.
Value messages are required to pass additional checks, which expose them to a voting mechanism if
double-spends are attempted [8,9]. In this section, we brieﬂy explain how these messages get handled
and why transactions have to pass an additional voting ﬁlter. This will lead to Section 3, where the
introduction of an additional delay time for value messages is explained.

Inclusion of messages into the ledger. For messages to be considered ﬁnal, a mechanism to
ensure the permanent addition to the ledger is required. If the majority of nodes processes the same
(or similar) parts of the DAG, this requirement will be satisﬁed whenever a proportion θ of messages
in the tip pool directly or indirectly references the message (since honest nodes would keep growing
this same part of the DAG). We call this the inclusion criterion.

In this paper, we assume there are no restrictions for the addition of data messages to the ledger.
Thus, data messages can be considered ﬁnal once the inclusion criteria is satisﬁed. For value messages,
the situation is more complicated, as we will see in the following section and Section 3.2.

Voting ﬁlter. In IOTA 2.0, the transfer and allocation of funds are handled through an unspent
transaction output (UTXO) model, which implies that an unspent output can only be spent once in
the ledger, being considered thereafter as consumed. In an honest setting and without the existence of
errors, we could apply the same as for data messages and assume that the inclusion criteria could be
suﬃcient to consider transactions as ﬁnal. However, due to user errors or in the presence of a malicious
actor, it is possible that there are multiple transactions that attempt to spend the same output. These
types of conﬂicting messages are called double-spends, and their occurrence requires the network to
come to agreement on which transaction shall be accepted, or whether all should be rejected. This
agreement is achieved by employing a voting protocol. Since the voting protocol eﬀectively selects out
certain transactions it forms a type of ﬁlter, i.e. the voting ﬁlter. Once the voting ﬁlter validates a given
value message, its inclusion will be guaranteed with high probability: since the nodes in the network
have added the value message to their tip pool, the transaction should be eventually picked up by the
tip selection algorithm and referenced by a majority of the network within a reasonable time.

For the vast majority of situations, this is a suﬃcient ﬁnality criterion when dealing with double-
spendings. However, it may be possible that a node may have an agreement failure on a transaction,
thus, forming a wrong opinion about its inclusion into the ledger [9]. It is, therefore, reasonable to also
require that the message inclusion criteria deﬁned in the previous section should be satisﬁed.

In IOTA, the role of the voting ﬁlter is performed by the Fast Probabilistic Consensus (FPC)
protocol [8,9]. On a more fundamental level, FPC constitutes the pre-consensus protocol, that allows
nodes to come to an initial agreement on the state of a bit, by querying a random subset of nodes.
With very high probability (see [8]), after a ﬁnite number of rounds, the FPC will ﬁnalize on a boolean
value, which is utilized for the decision on accepting or rejecting the transaction.

A message that is rejected by the voting ﬁlter cannot enter the tip pool and must become orphaned,
which means it should not be accounted for in the ledger. Note that any message that references the
rejected transaction should not be included to the normal tip pool. Without any rescue mechanism for

1 https://github.com/iotaledger/IOTA-2.0-Research-Speciﬁcations

3

the referencing messages, such as re-attachments, these would also become orphaned. This orphanage
issue can be avoided to a large extent by introducing a quarantine time on value messages, which is
discussed in the following section.

3 Delay time for value messages

Messages are subject to several delay vectors before they can enter the tip pool of a node. First, the
broadcast in the network does not happen instantly, but rather is dominated by a natural network
delay that depends on several factors, such as geographical distance and distance in the P2P virtual
network [10]. Second, messages also need to be processed locally, are members in a waiting pool before
being processed, or depend on messages that have not yet arrived. All of this adds together to a delay
time, which results in an average delay time h.

In this section, we introduce and reason for an additional delay (or quarantine time) dQ for value
messages, which eﬀectively extends the delay time h to d = h + dQ. Speciﬁcally, in Section 3.1, we
provide the setup of synchronicity assumptions that shape the requirements for the quarantine, whereas
in Section 3.2, we describe some implementation details for the quarantine procedure.

3.1 Synchronicity assumptions

For simplicity, we require in this paper that messages are delivered within a bound dQ/2. Thus, in this
paper, we do not treat the case where the network is partitioned for a time window larger than dQ/2.
We set dQ such that it is much larger than the average network delay and processing time of messages
h. In more realistic conditions, this situation is more complicated, since packet losses may occur or
faulty nodes might be present. However, due to the interconnection and dependencies of messages,
which are mapped by the DAG structure, nodes can identify missing messages and request them to
their peers. This decreases the likelihood that a given node does not receive a message before dQ/2.

For the dependencies on FPC, it is suﬃcient for a super-majority of messages to arrive within
dQ/2 to maintain the integrity of the initial opinion. Moreover, for the FPC opinion exchange —which
is not part of the normal gossiping of messages—, the protocol will correctly ﬁnalize even if a part
of those messages are lost. Thus, for the opinion exchange, it is suﬃcient to assume a probabilistic
synchronous model, where we require that a large majority of opinion exchanges arrive within some
bound time t < dQ/2. The probabilistic character of this type of synchronicity assumption is given
by the requirement that the large majority of communication occurs within this window, w.h.p. [9]. If
the synchronicity assumption is not met (e.g. if a node did not receive a minimum required number
of FPC responses), the node may ignore a voting round. In this sense, the security of the consensus
protocol is ensured, while the liveness is temporarily halted.

3.2 Quarantine procedure

The protocol component that is tasked with quarantining a transaction also oversees the initial opinion
setting, and delegates whether the message is immediately added to the tip pool, if it ﬁrst must pass
the voting ﬁlter, or if it is rejected even before being processed by the voting ﬁlter. In theory one could
also forward all transactions to the voting ﬁlter instead of employing a quarantine time. However, since
the communication overhead for the voting protocol could become excessive, this option is not feasible
if there are many transactions issued. Furthermore, even non-double spending transactions would have
to pass the voting ﬁlter, which would impose an excessive delay time, i.e. much larger than dQ.

Initial opinion setting. The output that the voting ﬁlter provides on a given transaction is given
in the form of a boolean value, liked (for accepting the transaction) or disliked (for rejecting the
transaction). We can further decrease the probability for agreement failures by introducing an initial

4

time window of length dQ/2, during which a transaction’s like-status is unknown. The transaction is
set to liked, only if no other double-spending transaction arrives within dQ/2. This ensures that, if
there are double-spending transactions, at most one of them can be liked by a large proportion of the
nodes. We apply the following rules:

1. A transaction is liked after dQ/2 if no other double-spending transaction arrives within dQ/2, and

disliked otherwise.

2. A transaction is disliked on arrival if there is already a transaction that is spending the same

output.

Tip inclusion and voting ﬁlter activation. We enforce a quarantine time dQ on an arriving
transaction, during which the voting is not yet enabled and the transaction is not included to the tip
pool yet. Once the quarantine time has elapsed, the transaction has to pass a tip inclusion check, which
either will immediately pass the transaction to the tip pool or will initiate the voting ﬁlter instead.
The outcome of the ﬁlter then determines whether the transaction is ﬁnally included into the tip pool.
We apply the following rules:

1. If no double spend transaction arrives within dQ, the transaction passes a tip inclusion check and

is added to the tip pool.

2. If a double spend transaction arrives within dQ, it fails the tip inclusion check, and it is only added

to the tip pool if it is liked by the voting ﬁlter.

Note that the time between setting the like status and performing the tip inclusion check is dQ/2,
which satisﬁes the requirements for the probabilistic synchronicity. Due to this window, a node that
applies rule number 1) can be certain that the nodes that applied 2) —instead of 1)— will eventually
like the transaction, since it was already liked by a super-majority of nodes that applied 1). Thus,
FPC guarantees that the initially liked transaction will become the winning transaction w.h.p.. The
combined approach of rules 1) and 2) must be required, since value transactions must not enter the
tip pool pre-maturely and get disliked retrospectively. Contrarily, assume a transaction enters the tip
pool and is approved by the node, but the transaction is later disliked, then the transaction (as well
as its referencing message) must be orphaned, i.e. fail to be included into the ledger.

4 Delay classes and tip pool model

In the previous sections we showed, using the example of the IOTA 2.0 protocol, how the existence of
diﬀerent types of messages can result in diﬀering delay times for them. In this section, we describe an
analytical model of the tip pool size for the case where n diﬀerent classes are present. Furthermore,
we investigate the case for n = 2, which applies to the previous sections, in more detail.

The dynamics and message relationships within the DAG data structure aﬀect several metrics that
have an impact on the performance of the DLT. For example, the time and order in which messages
arrive aﬀect the number of references that they obtain. Generally speaking, nodes do not share a global
view and, as a consequence, if a certain node considers a certain message as unreferenced, this may
not be the case from the point of view of another node. The underlying cause of this is the existence
of delays until a message is processed, which also diﬀers from node to node. Furthermore, the tip
pool size is also correlated to the time until ﬁrst reference and, ultimately, the time until ﬁnalization
of messages. In this paper, we will focus on the tip pool size. We introduce delay classes Ci, where
the messages with this classiﬁcation have a speciﬁc delay time di. The introduction of delay classes
creates a more complex scenario, where not always the ﬁrst message to select a tip will be the message
to remove this message from the tip pool. Since the delay introduced by the quarantine time of the
value messages is order of magnitudes larger than the network and other processing-related delays,
we can introduce —in the case described in the previous section— two delay classes Cvalue and Cdata,

5

i.e. value and data messages, with strongly distinct and constant delay times. This can lead to the
situation that, if a fraction pvalue of the issued messages are value messages (which have an extended
delay), the probability of a tip being removed from the tip pool by a value message can be signiﬁcantly
smaller than pvalue. This aﬀects the tip pool size and the time until the ﬁrst reference of messages.

4.1 General model for the tip pool size

Let C = {Ci}i=1,...,n be the family of classes of messages. For each class Ci, we deﬁne the following
variables:

– di: delay of a message of class Ci (w.l.g., we assume di ≤ di+1)
– ki: number of referenced messages, (i.e. parents), of each message of class Ci
– pi: fraction of messages of class Ci (thus, (cid:80)n

i=1 pi = 1)

To issue a message, a node must select a certain number of messages ki as parents for it. The
relation created through these parent-child references forms the DAG structure. We now proceed to
calculate the average tip pool size L. We model the diﬀerent classes of messages’ arrival as independent
Poisson processes of rates piλ, for i = 1, . . . , n. Thus, assuming that the size of the tip pool does not
excessively deviate from the average value L, each new message of class Ci will have a probability ki/L
of referencing a given message in the tip pool (here, we implicitly assume that L (cid:29) ki, so that the
probability of a tip being referenced by two or more references of the same incoming message is low).
Thus, a tip sees the incoming references as independent Poisson processes of rates µi := piλki/L (for
i = 1, . . . , n). Generally, the number of references (i.e., children) a message receives can vary; however,
since we are only interested in the tip status of a message, we are also only interested in the reference
that removes the message from the tip pool. Now, let Si
1 be the time until the ﬁrst event of the Poisson
process describing the reference arrival of class Ci (from the point of view of a single tip). Then, the
time T until the removal of this tip from the tip pool will be given by the minimum between di + Si
1
for i = 1, . . . , n. Thus, we have

FT (x) = 1 −

n
(cid:89)

(cid:104)

i=1

1 − Fdi+Si

1

(x)

(cid:105)

where

Fdi+Si

1

By equations (1) and (2) and letting ai = (cid:80)i

(x) = [1 − exp(−µi(x − di))] 1(x>di)
j=1 µj and bi = (cid:80)i

j=1 µjdj:

(1)

(2)

FT (x) =

n−1
(cid:88)

i=1

[1 − exp (−aix + bi))] 1(di<x≤di+1) + [1 − exp (−anx + bn)] 1(dn<x)

Finally, the expected value of T will be given by

E(T ) =

(cid:90)

R+

xfT (x)dx = d1 +

1
a1

−

n
(cid:88)

i=2

exp (−diai−1 + bi−1)

(cid:19)

(cid:18) 1
ai−1

−

1
ai

By Little’s Law, we have L = E(T )λ, implying the following implicit equation:

(cid:18)

L

1 −

(cid:19)

1
p1k1

= d1λ −

n
(cid:88)

i=2

e− λ

L

(cid:80)i−1

j=1 pj kj (di−dj )

(cid:32)

L
(cid:80)i−1
j=1 pjkj

−

L
j=1 pjkj

(cid:80)i

(cid:33)

(3)

6

4.2 Experimental and simulation validation

In the case of the IOTA 2.0 protocol, a total of n = 2 diﬀerent delay classes with constant number of
parents k are observed. Applying the model developed in the last section to this speciﬁc case, we have
the following implicit equation for the expected tip pool size L (where p := pvalue):

L = hλ +

L
k(1 − p)

(cid:20)

(cid:18)

1 − p exp

−

(cid:19)(cid:21)

(1 − p)λkdQ
L

(4)

We proceed by ﬁnding the critical value p∗, that divides the domain in two regions [0, p∗) and [p∗, 1]
with diﬀerent dominating classes of delays. We begin by linearising the solution of (4) around p = 0
which gives us an approximate value of L close to this point of

L ≈

λhk
k − 1

+ p

λhk
(k − 1)2

(cid:20)

(cid:18)

1 − exp

−

(cid:19)(cid:21)

dQ(k − 1)
h

≈

k
k − 1

λh = L−

(5)

Analogously to the case above, if p is large enough the tip pool size is increasingly controlled by
value messages. As p increases it becomes more likely that a given message is removed by a value
message rather than a data message. More speciﬁcally, for large values of p, we have

L ≈ L+ =

kλ
k − 1

(h + pdQ) −

kλd2
Q
2(dQ + h)

(1 − p)

(6)

The intersection of the curves for equations (5) and (6) provides the approximate proportion of
value messages p∗, for which the value messages start to have a noticeable impact on the tip pool size.
Taking L−(p∗) = L+(p∗), we have:

p∗ =

dQ(k − 1)
(2h + (k + 1)dQ)

(7)

In order to validate the analytical derived equations above (speciﬁcally, 4), we compare them against
experimental as well as simulation results. We run simulations for the Tangle for the 2-class message
model, where one class has a ﬁxed lower delay of h, and the second class has a ﬁxed higher delay of d.
Messages arrive randomly through a Poisson process. For each parameter set, we run the simulations
for 1,000,000 message arrivals.

Experimental values are obtained by measuring the tip pool of a node connected to a network that
operates with the prototype implementation GoShimmer of the IOTA 2.0 protocol2. GoShimmer is a
full node software, that is developed to test and validate the IOTA 2.0 solution for a fully decentralized
DLT. For each parameter set, we issue messages at a combined rate for value and data of 200 messages
per second (Mps). We remove the data obtained for the ramp-up and down phase, which underestimates
the tip pool size, since the data is not obtained from the stable phase, where the tip pool size stays
constant.

Fig. 2 shows the tip pool size as a function of the proportion of value messages p, comparing
the analytical, simulated (2a), and experimental (2b) results. The total rate of incoming messages
λ is measured in Mps. A good agreement between analytical prediction, experimental results, and
simulation results can be observed. From the ﬁgure and by referring to equation (4) we can see that
the tip pool size has a small and roughly constant slope close to p = 0, i.e. the tip pools size is strongly
dominated by the data messages in this region. Analogously, if p is large enough the tip pool size is
increasingly controlled by value messages. As p increases it becomes more likely that a given message
is removed by a value message rather than a data message. Furthermore, when k is increased the tip
pool can be kept stable for an increased proportion of value messages.

2 https://github.com/iotaledger/goshimmer

7

(a) Simulation

(b) Experiment

Fig. 2: Tip pool size as a function of the proportion of value messages. We show data from simulations (a),
experiments (b), as well as analytical results for the parameters λ = 200M ps, h = 0.1s and dQ = 40h. In ﬁgure
a) we provide values for two diﬀerent numbers of referenced messages k. The standard deviation is <3% for
the simulation. In ﬁgure b) results are marked along with their error for a conﬁdence level of 95%.

5 Controlling the tip pool size

As we show in the previous section, the tip pool can vary signiﬁcantly depending on the dominant
class of messages. However, the tip pool size aﬀects some important performance metrics in the DAG.
For example, with an increased tip pool size, the width of the DAG increases, which, in turn, aﬀects
the time until the inclusion criterion is fulﬁlled. Therefore, it is desirable to keep the tip pool small.
This must be ensured even in the presence of ﬂuctuations of incoming data and value messages, which
can change which class of message is dominant.

Applying this to the results of the previous section, we can observe that for a ﬁxed number of parents
k, p can exceed the critical value p∗ occasionally. During such periods of excess of value messages, the
tip pool size and the time until ﬁrst reference could, therefore, increase substantially, if the parent
number is ﬁxed.

From (7) we can see that for h (cid:28) dQ the value for p∗ is independent of h, dQ and the absolute
values of the transaction rates. By measuring a moving average of the value and data message rates,
and calculating the moving average of the proportion of value messages ¯p, a node can locally adapt
k —up to a predeﬁned maximum value kmax— in its tip selection algorithm, such that p∗(k) > ¯p.
Algorithm 1 shows the pseudo code that should be called before selecting the parents.

Algorithm 1: Adaptive parent number control

1 Input: ¯p
2 k=2
3 while p∗(k)<¯p AND k<kmax do
4

k ++

5 return k

Note that increasing k may increase the message size, since the parents have to explicitly be
mentioned. Furthermore, increasing k may also increase the processing time of the data messages and
thus eﬀectively increase h. However, this increase is negligible, since h is typically dominated by other

8

Fig. 3: Tip pool size as a function of the proportion of value messages, when the number of parents is adapted
and controlled (blue). The tip pool size is also indicated for the cases where the parent number is ﬁxed (dashed).
λ = 200M ps, h = 0.1s and dQ = 40h.

factors, such as the propagation time of the message through the network. If the majority of nodes
in the network adopt this strategy, the tip pool sizes and the time for inclusion can be kept low in
exchange for a minimally increased parent number. Fig. 3 shows how the tip pool size would vary with
the proportion of value messages, if the parent number can be variably controlled up to a maximum
number of parents of kmax = 8. For reference, the curves representing a ﬁxed number of parents are
also indicated. We show that using this procedure the tip pool can be kept stable at a small size for a
much larger proportion of value messages.

6 Conclusion

Messages in DAG-based DLTs are appended to each other through parent-child relations. Certain
aspects of the DAG structure created through this append process —such as the width of the DAG
and the pool of non-referenced messages—, depend on the delay of these messages. Since messages can
have diﬀerent purposes, such as transfer of value, utility, or generic data transfer, the processing time
and delivery may create distinct classes in terms of perceived delay.

In order to model the eﬀects of the delay classes, we develop an analytical model for the generic case
of n distinct classes that can accurately predict certain metrics of the DAG structure, such as the tip
pool size. We apply the model to the IOTA 2.0 protocol, in which value messages are treated diﬀerently
compared to plain data messages. We show that simulation and experimental results agree well with
the predicted values. For the simulation the standard deviation is <3%, while for the experiment the
error for a conﬁdence level of 95% is <3.3% and <28.9% when the tip pool size is large and small,
respectively. The shown validity of the model suggests that the model is suitable to study also other
DAG scenarios, and where there is more than one message type present.

Through the analysis we show that the tip pool size depends on which class of message is dominant.
The tip pool remains stable as long as a suﬃcient amount of the message class with a shorter delay
is present. However, at some point, the tip pool may signiﬁcantly increase due to the second class
with a larger delay. Furthermore, a greater amount of messages with large delays can be supported,

9

if the parent number is increased. This can be done statically, or dynamically through an adaptive
mechanism.

References

1. S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system.” 2008.
2. H. Pervez, M. Muneeb, M. U. Irfan, and I. U. Haq, “A comparative analysis of dag-based blockchain
architectures,” in 2018 12th International Conference on Open Source Systems and Technologies (ICOSST),
2018, pp. 27–34.

3. F. M. Benčić and I. Podnar Žarko, “Distributed ledger technology: Blockchain compared to directed acyclic

graph,” pp. 1569–1570, 2018.

4. X. Boyen, C. Carr, and T. Haines, “Blockchain-free cryptocurrencies: A framework for truly decentralised

fast transactions,” Cryptology ePrint Archive, Report 2016/871, 2016.

5. S. Popov, “The tangle,” 2015.
6. C. Decker and R. Wattenhofer, “Information propagation in the bitcoin network,” in IEEE P2P 2013

Proceedings, 2013, pp. 1–10.

7. S. Popov, H. Moog, D. Camargo, A. Capossele, V. Dimitrov, A. Gal, A. Greve, B. Kusmierz, S. Mueller,

A. Penzkofer, O. Saa, W. Sanders, L. Vigneri, W. Welz, and V. Attias, “The coordicide,” 2020.

8. S. Popov and W. J. Buchanan, “FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures,”

2019.

9. A. Capossele, S. Müller, and A. Penzkofer, “Robustness and eﬃciency of voting consensus protocols within

byzantine infrastructures,” Blockchain: Research and Applications, vol. 2, no. 1, p. 100007, 2021.

10. Y. Mao, S. Deb, S. B. Venkatakrishnan, S. Kannan, and K. Srinivasan, “Perigee: Eﬃcient peer-to-peer net-
work design for blockchains,” Proceedings of the 39th Symposium on Principles of Distributed Computing,
p. 428–437, 2020.

10

