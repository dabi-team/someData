2
2
0
2

y
a
M
3

]

R
C
.
s
c
[

2
v
5
6
7
7
0
.
1
0
2
2
:
v
i
X
r
a

Towards Situational Aware Cyber-Physical Systems:
A Security-Enhancing Use Case of Blockchain-based
Digital Twins

Sabah Suhaila,1,, Saif Ur Rehman Malikb, Raja Jurdakc, Rasheed Hussaind,
Raimundas Matuleviˇciuse, Davor Svetinovica,f

aResearch Institute for Cryptoeconomics, Information Systems and Operations
Management, Vienna University of Economics and Business, Vienna, Austria.
bCybernetica AS, Tallinn, Estonia.
cQueensland University of Technology, Brisbane, Australia.
dBristol Digital Futures Institute (BDFI) and Smart Internet Lab, University of Bristol,
Bristol, UK.
eUniversity of Tartu, Tartu, Estonia.
fCenter for Cyber–Physical Systems, Electrical Engineering and Computer Science, Khalifa
University of Science and Technology, Abu Dhabi, UAE.

Abstract

The complexity of cyberattacks in Cyber-Physical Systems (CPSs) calls for

a mechanism that can evaluate critical infrastructures’ operational behaviour

and security without aﬀecting the operation of live systems.

In this regard,

Digital Twins (DTs) provide actionable insights through monitoring, simulat-

ing, predicting, and optimizing the state of CPSs. Through the use cases, in-

cluding system testing and training, detecting system misconﬁgurations, and

security testing, DTs strengthen the security of CPSs throughout the prod-

uct lifecycle. However, such beneﬁts of DTs depend on an assumption about

data integrity and security. Data trustworthiness becomes more critical while

integrating multiple components among diﬀerent DTs owned by various stake-

holders to provide an aggregated view of the complex physical system. This

article envisions a blockchain-based DT framework as Trusted Twins for Se-

curing Cyber-Physical Systems (TTS-CPS). With the automotive industry as a

Email addresses: sabah.suhail@wu.ac.at (Sabah Suhail), saif.rehmanmalik@cyber.ee

(Saif Ur Rehman Malik), r.jurdak@qut.edu.au (Raja Jurdak),
rasheed.hussain@bristol.ac.uk (Rasheed Hussain), raimundas.matulevicius@ut.ee
(Raimundas Matuleviˇcius), davor.svetinovic@wu.ac.at (Davor Svetinovic)

Preprint submitted to Elsevier

May 4, 2022

 
 
 
 
 
 
CPS use case, we demonstrate the viability of the TTS-CPS framework through

a proof of concept. To utilize reliable system speciﬁcation data for building the

process knowledge of DTs, we ensure the trustworthiness of data-generating

sources through Integrity Checking Mechanisms (ICMs). Additionally, Safety

and Security (S&S) rules evaluated during simulation are stored and retrieved

from the blockchain, thereby establishing more understanding and conﬁdence

in the decisions made by the underlying systems. Finally, we perform formal

veriﬁcation of the TTS-CPS.

Keywords: Anomaly detection, Blockchain, Cyber-Physical Systems (CPSs),

Digital Twins (DTs), Industrial Control Systems (ICSs), Internet of Things

(IoT), Industry 4.0

1. Introduction

Characterized by computation, networking, and physical components, Cyber-

Physical Systems (CPSs) interface the digital and physical worlds [1] to enable

the realization of the Industry 4.0 vision [2]. Due to the fact that Industrial Con-

trol System (ICS)-a subset of CPSs have a direct impact on the environment

they operate in, ensuring that such systems meet speciﬁc security and safety re-

quirements is paramount [3]. Several seminal examples of ICS-tailored malware

have demonstrated how severe the consequences of these incidents can be [3, 4].

For instance, the cyber attack on the Ukrainian power grid in 2015 (BlackEn-

ergy3) [5] and a follow-up attack in 2016 (Industroyer) [6] disconnected several

substations, causing a power outage. Similarly, Stuxnet [7] targeting Iran ura-

nium enrichment plant and Triton [8] targeting a petrochemical plant in Saudi

Arabia are among the most prominent examples of cyber espionage. By ex-

ploiting loopholes in the system infrastructure, the attackers gain a foothold

and launch covert attacks or Advanced Persistent Threats (APTs) [2]. Conse-

quently, such attacks degrade the overall system performance, cause signiﬁcant

economic loss, and pose human safety risks. Therefore, the speciﬁcally de-

signed ICS-tailored covert attacks require a solution that, without obstructing

2

the ongoing operations, can monitor and analyze the physical process to detect

security loopholes in the CPS at an early stage (for instance, design phase),

thereby reducing incident response time [2].

Digital Twins (DTs) are considered one such solution. Being the virtual

replicas of their physical counterparts, DTs share the expected operational be-

haviour of the underlying systems [2] and provide a sustainable strategy for

analyzing, monitoring, and predicting the behaviour of a system [9]. To do so,

DTs collect data from multiple sources, such as installed sensors and actuators

at the factory ﬂoor, historical production data derived from product lifecycle

data, and domain knowledge. Following a closed feedback loop, DT inspects

for data inconsistencies between the physical entity and virtual entity and feed

back the simulation data to the physical entity to adopt better calibration and

testing strategies [10]. To fully harness the features of DT, the data used by

the DT needs to be trustworthy and secure. For instance, reasoning about the

current state of a data object entails a complete lineage of processes chain [11].

Additionally, the requirement of data trustworthiness becomes more critical as

it may aﬀect the next system generation where DT data can be used as historical

data. Unreliable data used as historical data in guiding future system iterations

can lead to signiﬁcant deviations from the system’s desired behaviour. In this

regard, leveraging blockchain technology allows industries to manage data on

a distributed ledger while ensuring trusted DT data coordination [4, 12]. A

provenance-enabled blockchain-based DT assure the traceability and solidity of

data, thereby establishing more conﬁdence in the decisions made by the under-

lying systems [2]. Thus, combining blockchain and DT can reshape the industry

such that blockchain ensures secure data management and DTs use reliable data

as input to extract actionable insights [10].

In the information security domain, the concept of building the process

knowledge of DTs is primarily based on either utilizing (i) system speciﬁcation

data to model the physical counterpart based on engineering artifacts [13, 14,

18], or (ii) Machine learning methods to learn security-related aspects based on

sensor data [21, 22] without obtaining process knowledge from DTs [2]. Focusing

3

Table 1: Existing works on speciﬁcation-based digital twins: A summary.

Year Ref.

Framework /

Proof Of Concept (POC)

Objective of DTs

2018 [13] POC

2018 [14] POC

Detect security and safety rule violations

State-based intrusion detection

2019 [15] Framework

Risk assessment, Incident handling

2019 [16] Framework

Secure data sharing

2020 [17] Framework

ICS security

2020 [18] POC

2021 [19] POC

2021 [20] POC

Incident analysis

Attack detection and localization

Utilizing cyber ranges for training security

analysts

on speciﬁcation-based DTs, present works do not consider whether data sources

are trustworthy, which is critical to ensure input data quality. Similarly, the

need for data storage is also not given due attention. Thus, trustworthy process

knowledge for DTs is required to address the limitation in current knowledge.

We focus on the existing research work covering the initial development

phase of DTs, which consists of obtaining process knowledge through system

speciﬁcation approaches. Most importantly, we narrow down the existing works

based on the objective of using DT, i.e., a situational awareness enabler. Table 1

summarizes relevant works on speciﬁcation-based DTs. Moreover, Table 1 also

shows that in recent years there has been an increased interest in using DTs

to secure CPSs. The speciﬁcation-based approaches (summarized in Table 1)

utilize technical, topological, and control artefacts of the underlying system

that are maintained throughout the system engineering process [2]. There exist

many works on blockchain-based DTs. [4] provides a comprehensive review of

the design solutions for blockchain-based DTs in the industrial domain. How-

ever, the existing blockchain-based schemes lack the details on how the DTs are

constructed and how DT security operation modes can be used to secure CPSs.

4

Table 2: Notations and their explanation.

Notation

Explanation

Notation

Explanation

SID

AID

Ac
ω

χ

RID

EID

τ

R

d

Sensor ID

Ds,t

Timestamped sensor data

Asset ID

Asset current status

Conﬁguration settings

Rule ID

Entity ID

Threshold

Set of rules

Delay

Aδ

Ah
ω

DP

RD

PID

(cid:15)

Td

V

Asset capacity

Asset history status

Provenance data

Rule description

Process ID

Process-speciﬁc settings

task duration

Velocity

Furthermore, they vary in terms of utilizing DTs and are therefore beyond the

scope of this paper. [16] proposed only a theoretical blockchain-based framework

while neglecting the prototypical implementation.

Compared to the existing works, the proposed TTS-CPS scheme ensures

that the generation of a virtual environment through system speciﬁcation data

is based on trustworthy data-generating sources owing to Integrity Checking

Mechanisms (ICMs). Additionally, integrating blockchain makes the simulation

environment reliable. In this work, we investigate the signiﬁcance of integrat-

ing blockchain-based DTs in the CPS. We focus on speciﬁcation-based DTs.

More precisely, we propose an blockchain-based DTs framework for supporting

security-enhancing use case of DTs in the CPS. Our main contributions can be

summarized as follows:

• To support a situational-aware environment, we propose a blockchain-

based DT framework as Trusted Twins for Securing Cyber-Physical Sys-

5

tems (TTS-CPS). By leveraging blockchain with DTs, we can track the

accountable entity for adding or updating the Safety and Security (S&S)

rules and ensure the trustworthiness of data generating sources through

ICMs.

• Through a prototypical implementation supporting the simulated network

topology, Human Machine Interfaces (HMIs), Programmable Logic Con-

trollers (PLCs), and physical devices (e.g., robotic arm, motor), we demon-

strate the feasibility of the TTS-CPS framework for an assembly line in

the automotive industry.

• We perform formal veriﬁcation of the TTS-CPS.

The rest of the paper is organized as follows. Table 2 lists all the acronyms

used in the paper. Section 2 outlines the proposed framework for the CPS.

Section 3 presents the evaluation results and discusses the formal modelling and

veriﬁcation of the proposed approach. Finally, Section 4 concludes the paper

with an outlook on future research directions.

2. Framework Design: Trusted Twins for Securing Cyber-Physical

Systems (TTS-CPS)

This section describes the design of a blockchain-based DT framework called

Trusted Twins for Securing Cyber-Physical Systems (TTS-CPS). We ﬁrst present

an overview of the TTS-CPS framework in Section 2.1. Then we provide a de-

tailed discussion on the main components of the TTS-CPS, including compari-

son with existing frameworks in Section 2.2, ICMs in Section 2.3, digital-physical

mapping in Section 2.4, and blockchain-based DTs in Section 2.5.

2.1. Overview of the proposed framework

Fig. 1 illustrates the high-level framework of the TTS-CPS. Firstly, the Phys-

ical Environment (PE) showcases the physical process. Secondly, the Virtual

Environment (VE) showcases the twinned process. The physical process and

6

Figure 1: A high-level framework of TTS-CPS.

its clone counterparts span engineering to operational lifecycle phases. Thirdly,

the data layer connects the physical and virtual environment by utilizing be-

havioural data. The behavioural data can be either static data (such as the

range of sensor data) or dynamic data (such as real-time sensor data). The

7

 Engineering and Operational lifecycle phasesPhysical Environment (PE)Data layerRobotic armHMIONManualAuto FunctionsAxisOFFPLCAuto_ONOFFActionActionSensorsHMIPLCSwitchSensorRoboticarmAnomaly-based  intrusion detectionDigital twin as situational-aware enablerSensorsPhysical processVirtual Environment (VE)KnowledgebaseRule Generator (RG) Integrity Checking Mechanisms (ICMs) Engineering Knowledge  (EK) Domain Knowledge  (DK)Behavioral data Static & dynamic dataTwinned processInterfaceData / Security analystStorage layer (Blockchain)TTS-CPSprocess knowledge of the DT is acquired from the speciﬁcation-based artefacts.

Fourthly, the storage layer stores data in the knowledge base, which other layers

can utilize. Finally, the interface allows data/security analysts to repeat and

reproduce simulations based on user-speciﬁed parameters and feedback during

repetitive testing. Generally, the role of data/security analysts is (i) to uti-

lize the controlled, supportive virtual environment during replication (record

and replay events [15]) and simulation (trial and error) modes, and (ii) to spot

deviations from a deﬁned or learned baseline to alert system. Among various

security-enhancing use cases of DTs, including security testing, incident re-

sponse, automated security, etc. [2], we are using DTs as an anomaly detection

tool. More speciﬁcally, the objective of DT is to identify data inconsistencies

between PE and VE.

To further elaborate the connection between the components of the proposed

framework, we refer to Fig. 2. The framework comprises three key components,

including (i) ICMs, (ii) PE and VE, and (iii) data storage (blockchain-based

DTs). The ICMs provide design speciﬁcations of the CPS necessary to gener-

ate the network setup of the virtual environment in addition to implicit S&S

rules. Based on ICMs components including Engineering Knowledge (EK), Do-

main Knowledge (DK), and Rule Generator (RG), a digital-physical mapping

between PE and its clone counterpart VE to ensure data consistency between

the two spaces is performed. The DT operation modes (simulation, replication,

and data analytics) that support monitoring, behavioural analysis, and replay-

ing of CPS events are part of the VE component. The blockchain ledger enforces

secure data management by storing data and recalling data or events.

In the following, we compare the proposed TTS-CPS framework with ex-

isting solutions closely aligned with our scope, i.e., securing CPS and using

speciﬁcation-based process knowledge for DTs.

2.2. Comparison with existing frameworks

The DT paradigm qualiﬁes for diﬀerent enterprises to various implementa-

tion degrees [23] mainly due to (i) application-speciﬁc building blocks (such as

8

Figure 2: Blockchain-based digital twins: a secure CPS framework.

assets, process knowledge, data sources) of DTs, (ii) objective of using DTs

(such as cyber-situational awareness, predictive maintenance, resource opti-

mization), and (iii) the level of details and granularity. Considering the ob-

jective of using DTs to secure CPS, existing solutions such as CPS Twinning

framework( [15, 24]) utilize system speciﬁcation data (i.e., EK and DK) to

model the physical counterpart. However, these frameworks lack the concept

of trusted twins, i.e., trustworthy process knowledge for DTs due to the ab-

sence of blockchain-based storage in addition to the approach of leveraging

system speciﬁcation data as ICMs. TTS-CPS (adapted from [15, 24]) also

uses speciﬁcation-based process knowledge for DTs. However, we put emphasis

on data trustworthiness and security which is the critical parameter in DT-

based CPS security. Therefore, in addition to EK and DK, we have considered

additional components such as RG and blockchain-based data storage. More

9

Integrity Checking Mechanisms (ICMs)Storage (Blockchain)Data analytics &optimizationSimulationReplicationDTs operation modesPhysical Environment (PE)HMI-1PLC-1Switch-1Sensor-1Roboticarm-1Retrieve ICMsStore ICMsTTS-CPSProvide EKProvide DKVirtual Environment (VE)HMI-1PLC-1Switch-1Sensor-1Roboticarm-1Access  ModeRetrieve ICMs  and add/update S&S Engineering Knowledge (EK) DeviceconfigurationsNetworksettingsDomain Knowledge (DK)Lifecycle dataThresholddataS & S rulesRule Generator  (RG)ExpertknowledgeProvenancedataConsistencychecksGenerate rulesRetrieve behavioral dataspeciﬁcally, we have used EK, DK, and RG (together as ICMs) to establish

trusted twins.

Note that for TTS-CPS, we have mainly considered critical components to

establish trusted twins. However, there could be additional components de-

pending on the objectives of using DTs or application-speciﬁc requirements.

For instance, with the similar objective of anomaly detection, [10] envisioned

a blockchain-based DT framework for the Industrial Internet of Things (IIoT).

The main components of their proposed framework include (i) data wrangler

(responsible for data conversion and data cleaning to transform the data into

a uniﬁed form), (ii) data fusion (responsible for accumulating data from mul-

tiple DTs to cross-validate the observations to increase data consistency and

trustworthiness), and (iii) data synchronization (responsible for digital-physical

mapping and checking for data inconsistencies between physical and virtual

space).

In this paper, we focus on the TTS-CPS components that promote

trusted twins, and we reﬂect on the need for additional components, such as

those in [10], for future research in Section 4.

2.3. Integrity Checking Mechanisms (ICMs)

The data layer mainly consists of ICMs. In the following, we discuss sub-

components of the ICMs in detail. The quality of the data matters at par

with quantity for ensuring precise predictions and decision-making in critical

infrastructures operating under the presence of a complex threat landscape and

high volume and variety of big data [4]. Although stringent security guaran-

tees are inherited from the blockchain, ensuring the trustworthiness of data-

generating sources is equally essential for critical CPS [2]. Since DTs act as the

input data sources, DTs need to be built on reliable data. Therefore, a tri-fold

ICMs is deﬁned by the TTS-CPS framework. Firstly, Engineering Knowledge

(EK) provides the design speciﬁcations of the underlying CPS infrastructure

to identify known devices and connections, authorized addressing and routing

information, and expected behaviour of the process. Moreover, Calibration and

Veriﬁcation (C&V) identify the root cause of aberrant device behaviour or erro-

10

neous data before data collection. Secondly, Domain Knowledge (DK) provides

domain-speciﬁc knowledge and system history data to predict equipment fault.

Thirdly, Rule Generator (RG) cross-validate the device data with overlapping

ﬁelds of view by comparing pre-deﬁned device performance parameters, S&S

rules, and provenance data.To give an example, RG takes input from EK and

DK to generate S&S rules while taking into account the provenance data to

obtain the trustworthiness of data. To sum up, ICMs provide reliable system

speciﬁcation data for building the process knowledge of DT at design phase.

Based on speciﬁcation-based process knowledge, DT acts as an anomaly de-

tection tool. Additionally, the virtual network setup retrieves data from the

blockchain, which establishes more understanding and conﬁdence in the deci-

sions made by the underlying systems.

2.3.1. Engineering Knowledge (EK)

Engineering Knowledge (EK) provides the design speciﬁcations of the techni-

cal, topological, and control artefacts at device-level, network-level, and system-

level that are essential to generating the virtual environment’s network setup.

The device-level information includes construction details (e,g., name, type,

make, model), functional details (e.g., operating conditions in terms of stan-

dards), and conﬁguration details (e.g., IP and MAC address, I/O channels, con-

trol logic). The network-level information includes topology and communication

path through logical connections and endpoints. The system-level information

includes relationships among components/processes concerning data aggrega-

tion, conditional rules, and constraints. Each asset (including sensors) can be

identiﬁed with asset ID (AID) and sensor ID (SID), whereas the associated

conﬁguration settings can be represented as χ.

Sensors are notoriously prone to calibration errors and arguably explain the

root cause of aberrant behaviour or erroneous data. Ignoring such minor vari-

ations in the system behaviour may collapse the whole system or may incur

drastic eﬀects on the system’s long-term behaviour. Calibration errors mani-

fest when sensors report values that are oﬀset from the ground truth. Given

11

that factory calibration conditions may not necessarily be relevant to physical

environment needs and sensors wear out over time, calibration is necessary to

increase the sensor’s accuracy and resiliency against random errors [25]. There-

fore, to ensure data quality before data collection, sensors and actuators must be

calibrated to ensure the measurement accuracy according to a known standard

and veriﬁed to ensure the correct operation according to operating speciﬁca-

tions. Exercising C&V operations of Internet of Things (IoT) sensors must be

carried out periodically for ageing management and fault diagnosis.

Each type-k sensor s(k) ∈ K where K = {1, . . . , k, . . . , K} collects times-

tamped sensor data Ds(k),t. To ensure that Ds(k),t are within the predeﬁned

bounds, the following Consistency Check (CC) is performed:

s(k) ≤ Ds(k),t ≤ τ max
τ min
s(k) ,

∀s(k) ∈ K,

(1)

where both τ min

s(k) and τ max

s(k) ∈ τ deﬁne the lower and upper bounds respectively.

2.3.2. Domain Knowledge (DK)

Domain Knowledge (DK) provides domain-speciﬁc knowledge from experts

in various ﬁelds such as engineers (electrical, mechanical, instrumentation and

control), supply chain participating entities, security professionals in Security

Operations Center (SOC), etc. Moreover, it also includes asset historical data

(Ah

ω) derived from lifecycle data (such as design and development; operation

and maintenance; and decommissioning). Once generated, DK can be used as

a reference by diﬀerent organizations and tailored accordingly to meet their

speciﬁc needs.

2.3.3. Rule Generator (RG)

Rule Generator (RG) takes input from EK and DK to generate S&S rules

while taking into account the provenance data (DP ). Depending on the un-

derlying CPS infrastructure, S&S rules can be based on threshold data (upper
s(k) and lower τ min
τ max
s(k) bounds), consistency checks (pre-deﬁned performance pa-
rameters), and constraints (data accessibility and auditability) [2]. For instance,

12

trends/patterns (e.g., heat or vibration), consistency checks (e.g., conveyor belt

speed-variable), conditional limits for device data (e.g., minimum and maxi-

mum temperature), access control (e.g., authentication and authorization based

on roles and access levels), etc.

To detect the presence of malicious or accidental disruptions, the system

needs to respond eﬀectively by invoking the appropriate defence mechanisms,

whereas the inability to impose such strategy results in long-term loss. There-

fore, to detect misconﬁgurations and malicious activities, S&S rules must be

integrated into a CPS. S&S rules monitor and analyze the device or process in

the virtual environment and learn about the presence of an attack or abnormal

behaviour by collecting data over such events. Based on the incident data, the

derived patterns as S&S rules can be formulated, tested, and transmitted to

the physical environment. Thus, monitoring the physical system state through

time, outliers, and changes can uncover anomalies or malicious activities by en-

abling the detection of possible S&S rules violations in terms of deviations or

patterns from a deﬁned benign behaviour.

Introducing S&S rules at DT’s design and development phase can lower secu-

rity and incident-response costs. Moreover, it makes later lifecycle phases (such

as operation and maintenance; and decommissioning) less prone to errors and

incidents [17]. To do so, S&S rules can be deﬁned at device-level or process-level.

For instance, through EK deﬁning a safe state based on the regular operation

of the device, verifying the speciﬁc service provided by the process, deriving

a white-list from network-level monitoring based on the authorized addressing

and routing information, detecting unknown devices, identifying unidentiﬁed

connections, determining abnormal changes in the control logic, enforcing ﬁne-

coarse- grained policies and constraints, etc. [4]. Similarly, rules can also be

extracted from thresholds or consistency checks deﬁned during the calibration

phase and equipment history data from product lifecycle data.

While reasoning about the current state and the chained actions on a data

object (such as who, when, where, why, and how ), provenance data (DP ) can

aid in generating device-, network-, and system-level rules. DP is a complete

13

process lifecycle along with environment settings, input parameters, action and

events performed on data [26] and can be constructed as suggested in [11]. The

key role of DP is to enforce traceability in the CPSs while traversing through

the process and can be stored on the blockchain to reconstruct the process chain

on demand. DP can be reconstructed based on the data provided by EK, C&V,

and DK. Additionally, it can also serve as a basis for implicit security rules.

For instance, DP under a process-speciﬁc settings (PID) can identify who is the

accountable entity EID generating or updating rule RID deﬁned as RD for AID

or SID.

P (cid:15)

ID = {RID, RD, EID, AID, SID},

∀R ∈ R.

(2)

Similarly, DP can be derived from EK, C&V, and DK to construct rules

as follows. From EK, what are the conﬁguration settings (χ) deﬁned for SID

aﬃxed to AID?

DEK

P = {AID, SID, χ}.

(3)

From C&V, which threshold settings (τ ) are optimal for AID based on Ac
ω

(i.e., on/oﬀ, run rate, speed) and Ds,t from SID?

DC&V
P

= {AID, Ac

ω, SID, Ds,t, τ }.

From DK, how AID behaved under χ?

DDK

P = {AID, Ah

ω, χ}.

(4)

(5)

Depending on the severity of the cyber situation, S&S rules needs to be

generated or updated to make the system respond eﬀectively and avoid long-

term loss.

Algorithm 1 illustrates the steps of generating or updating rules. Based

on access control model such as Role-based Access Control (RBAC) [27], ﬁrst

check whether the entity ID (EID) has rights to generate or update rules. In

case of a new rule R, a unique ID (RID) is assigned. Then R is associated with

respective asset or sensor for which it has been deﬁned. In case of existing rule,

14

Algorithm 1 Rules
Input: EID, RD

Output: R in S&S rules

1: Check access control rights of EID

2: if (R != R) then

3:

4:

5:

6:

Assign RID

RID ← RD

Associate RID with AID and/or SID

Store RID at blockchain

7: else

8:

9:

Update RD of RID

Store RID at blockchain

10: end if

rule description (RD) is updated. Finally, the newly generated or updated rules

are stored in the blockchain.

2.4. Digital-physical mapping

In CPSs, as physical assets start operating, DTs run synchronously with

their physical counterparts while integrating data from multiple sources, such

as EK, DK, PE, to generate an abstract view of overall phenomena with the

key objective to track data inconsistencies between PE and VE. Inconsistencies

between the two spaces call for the adoption of better strategies that evolve DTs

and physical counterparts to support accurate prediction and optimization of

the underlying processes [2, 28].

To describe the process, its corresponding actors, systems and artefacts,

Fig. 3 shows a process-based framework, expressed in Business Process Model

and Notation (BPMN). The process consists of three key phases, see Fig. 3a,

1. Save speciﬁcation data, 2. Generate S&S rules, and 3. Deploy S&S rules.

In the ﬁrst phase, see Fig. 3b, the security analyst receives the speciﬁcation

data from the physical device and saves this data to the knowledge base. The

15

(a) Legend

(b) Save speciﬁcation data.

(c) Generate S&S rules.

(d) Deploy S&S rules.

Figure 3: Process-based framework for TTS-CPS based on digital twin security sim-

ulations.

16

goal of the second phase, see Fig. 3c, is to produce the S&S rules. The DT

runs the simulation (see task 2.4. Run simulation) using the asset data and

user-speciﬁc parameters to achieve this goal.

If the incident happens during

the simulation, the incident data and the incident actors are submitted to the

security analyst for the setting tune (see task 2.7 Tune settings). The new

user-speciﬁc parameters are generated and submitted to the DT for the next

simulation run. If the simulation does not generate any incident, the S&S rules

are created and saved (see task 2.10 Save generated S&S rules) to the knowledge

base. Finally, in the third phase, see Fig. 3d, the system analyst sends the S&S

rules to the physical device for deployment.

2.4.1. Digital twins operation modes

DTs operate in the three operation modes to support the comprehension of

emergent system behaviour, namely replication, simulation, and data analytics.

Figure 4: Replication mode of digital twin.

For replication mode (as showcased in Fig. 4), VE and PE must be con-

stantly connected such that VE must continuously provide digital tracing of PE

events by mirroring data through log ﬁles, sensor measurements, network com-

munication, etc. Depending on the underlying process requirements, VE data

can be recorded and replay after a speciﬁc time interval or even oﬄine. Based

on closed-loop operation between the digital-physical mapping, the replication

mode can provide testing and training platform where system can be trained

17

Twinned environmentPhysical device/processState synchronizationPhysical_state 1, tPhysical_state 2, tPhysical_state 3, tInput dataKnowledge basePhysical environmentInput dataInput knowledge  StorageTwin device/processTwin_state 1, tTwin_state 2, tTwin_state 3, t Feedback Data / Securityanalyston how to respond against advanced stealthy attacks, and defensive strategies

can be tested before transmitting to real-world systems, for instance, red-blue

team exercises for cybersecurity training opportunities and cyber ranges [29].

The simulation mode (as showcased in Fig. 5) runs independently of its phys-

ical counterparts by allowing running tests repeatedly by resetting the model

under a broad range of speciﬁed conditions. While supporting security by design

approach, simulation mode can perform security tests within the virtual envi-

ronment to analyze process changes, test devices, or detect misconﬁgurations,

predict the possibility of attacks or system malfunctioning to carry out what-if

analysis.

Figure 5: Simulation mode of digital twin.

Data analytics and optimization use asset’s behavioural data, sensor data,

and system current state or history data as valuable input to extract actionable

insights while utilizing the predictive capability of machine learning algorithms

available through threat intelligence. Threat intelligence can analyze the mas-

sive volume of data in real-time, learn useful patterns, and detect the presence

of vulnerabilities, threat actors or inadvertent disruptions in the system, and

can trigger the appropriate defence mechanisms autonomously to minimize the

threat landscape [2].

For instance, threat intelligence can be integrated into the Security Informa-

tion and Event Management (SIEM) [18] to check the adherence of S&S rules.

Note that we only focus on the simulation mode of speciﬁcation-based DT in

18

Twinned environmentTwin  process / deviceInput dataUser-specified parameters Knowledge baseStorageData / SecurityanalystFeedback the current work.

2.4.2. Scenario speciﬁcation

In the following, we demonstrate the use case scenario of the automotive

industry. For the sake of simplicity, we divide it in two sub-scenarios showcased

in Fig. 6 and Fig. 7.

Figure 6: Scenario speciﬁcation of assembly line in the automotive industry.

Fig. 6 illustrates the exemplary physical process where we consider an as-

sembly line in the automotive industry. The assembly line has multiple stations

equipped with machinery for performing dedicated tasks. The motor-driven

conveyor system moves the objects (chassis) from Station A (chassis loading

point) to Station B (chassis welding point) for performing a physical task (such

as spot welding). Initially, the motor is oﬀ. Firstly, the chassis are required to

be loaded on the belt (as shown in Fig. 6) at Station A and their presence is

being detected by a proximity sensor (Sensor2: Object Detection). To do so, the

velocity (Sensor1: Velocity) of the conveyor system must be monitored against

a certain threshold based on the following conditions: (i) detect and load only

a speciﬁc number of chassis on the belt, and (ii) maintain a safe distance to

avoid collision between two adjacent chassis on the assembly line. Based on a

pre-deﬁned task duration, the chassis at Station A can be moved to Station B

19

Station BStation AHMI1Automotive assembly lineVelocity25ConveyorbeltPLC1Motor ONOFFONOFFbeltbeltmotor controlCar chassis move fromstation A to station B timeSensor1: VelocitySensor2: Object detectionSensorswhile more chassis can be loaded at Station A.

Figure 7: Scenario speciﬁcation of robotic arm at the assembly line in the automotive

industry. (Adapted from [2]).

Secondly, the welding operation on the chassis is performed by a robotic

arm at Station B (as shown in Fig. 7). To do so, the welding gun applies ap-

propriate current and pressure at the welding spot measured through Sensor3:

Current and Sensor4: Pressure. Another sensor (Sensor5: Temperature) mea-

sures the temperature during the welding process and is bounded by a threshold

to avoid material deterioration. To monitor tool wear data, the robotic arm

is equipped with sensors (such as vibration, force cutting, acoustic emission).

During manufacturing processes, machine unavailability (equipment deteriora-

tion or machine malfunctioning) and uncertain disturbances (due to urgent job

arrival or job tardiness) usually occur, leading to performance and production

disruption. Therefore, we keep monitoring tool wear data of robotic arms op-

erating in the service station of the assembly line. Recording such data ensures

continual assembly line operation while triggering suitable time for machine

maintenance or timely rescheduling for dynamic job-shop scheduling. We may

calculate tool wear data based on the robotic arm’s number of objects (chas-

sis) welded. To command and control physical processes (for instance, turning

motor and robotic arm on/oﬀ, setting the velocity of the motor, or setting cur-

20

Station BStation AHMI1RoboticarmAutomotive assembly lineVelocity25ConveyorbeltPLC1HMI2ONMotor ManualAuto FunctionsAxisOFFONOFFONOFFbeltbeltmotor controlPLC2Auto_ONOFFActionActionSensorsCar chassis move fromstation A to station B timeSensor1: VelocitySensor2: Object detectionSensor3: CurrentSensor4: PressureSensorsSensor5: Temperaturerent and pressure of robotic arm, etc.) through conveyor belt and robotic arm,

PLC1, HMI1, PLC2, HMI2 are used.

To illustrate how to achieve optimal operating conditions ((cid:15)∗) for a given

process (PID), we discuss the following three conditions (i) how to maintain a

safe distance (can be achieved through d) between adjacent vehicles frame on

the conveyor belt and how to maintain temperature bounded by a threshold to

avoid material deterioration during welding process by robotic arm?, (ii) how

to enforce data consistency between PE and VE?, and (iii) how to estimate the

asset capacity (A(cid:15)) for the next production process (P next

ID )? in Algorithm 2,
Algorithm 3, and Algorithm 4. The simulation results are presented in Sec-

tion 3.1.

Algorithm 2 Simulation mode: conveyor belt

Input: V , τ min

v

, τ max
v

, Ds,o, d, ocount = 0, τ min

o

, τ max
o

Output: (cid:15)∗

1: V = 0

2: Assume τ min

, d, τ min
o

, τ max
v
v
≤ V ≤ τ max

v

3: Set τ min

v

4: do

(cid:46) motor is oﬀ.

, τ max
o

under (cid:15)i where i ∈ {1, 2, . . . , n}

(cid:46) Sensor1: Velocity. Input V through HMI

(cid:46) Sensor2: Object Detection

(cid:46) count loaded object.

5:

6:

7:

8:

9:

10:

11:

Check Ds,o

if Ds,o == TRUE then

ocount = ocount + 1

Check τ min

o

≤ o ≤ τ max

o

Set d = t seconds

end if

(cid:15)i+1

12: while ((cid:15)∗==TRUE)

13: Call Algorithm 1

14: Update PE settings based on (cid:15)∗

In simulation mode, the current physical state of the system is not known,

hence it has to rely on user-speciﬁed settings and parameters. Therefore, we

21

assume (cid:15)i values of velocity thresholds (τ min
for number of objects on the belt (τ min

, τ max
v
v
, τ max
o

o

), delay (d), and thresholds

) (as outlined in Algorithm 2).

Through (cid:15)∗, test repetitions can be realized by resetting the values and rerun-

ning the simulation until the optimal operating conditions. Initially, the motor’s

velocity is 0, i.e., the conveyor belt is not operating. User can set set motor’s

velocity (V ) through HMI whereas V should be within the predeﬁned thresh-

olds (τ min

v

, τ max
v

). Sensor1: Velocity tracks the speed of the motor. Once

the belt start operating, the objects can be loaded on the belt (as shown in

Fig. 8d). The objects arrival at Station A on the belt can be detected through

sensor (Sensor1: Object Detection). Moreover, to minimize the makespan and

to enforce production optimization we can also track the number of objects on

belt through thresholds for number of objects on the belt (τ min

o

, τ max
o

). A safe

distance can be maintained between two adjacent chassis on the assembly line

by adjusting the velocity of the conveyor system and delay (d). Furthermore,

S&S can be generated or updated based on the velocity of the conveyor system

that must be monitored against a certain threshold to maintain a safe distance

and avoid collision.

To simulate the spot welding by robotic arm, we assume current thresholds

(τ min
c

, τ max
c

), pressure thresholds (τ min

p

, τ max
p

), and delay (d). Initially the task

status is set as zero. The user sets the values of current (C) and pressure (P )

through HMI (as shown in Fig. 9a) bounded by respective thresholds (τ min

c

,

τ max
c

) and (τ min

p

, τ max
p

) (as outlined in Algorithm 3). As the robotic arms

starts welding task, current sensor (Ds,c) and pressure sensor (Ds,c) collect the

respective data. The temperature sensor (Ds,t) keeps monitoring the object
temperature (otemp) to make sure it stays between predeﬁned bounds (τ min
τ max
t
on C and P . For example, if the inputted values of C and P are closer to τ max

) whereas to simulate the increase in otemp we assume value of ∆t based

,

,

t

c,p

the value of ∆t will be higher which is ideally an appropriate assumption. We

based our task completion (task status == 1) on a pre-deﬁned task duration,

i.e., delay (d) so that the object moves to the next Station (for instance, paint

shop) to undergo the next physical process. After the task completion, otemp

22

begins to decrease until it reaches at room temperature (init temp) as shown

in Fig. 9d.

Algorithm 3 Simulation mode: robotic arm

Input: C, τ min

c

, τ max
c

, Ds,c, P , τ min

p

, τ max
p

, otemp

Output: τ min

t

≤ Ds,t ≤ τ max

t

, task status==1

1: P = 0, C = 0, ocount = 0, otemp = init temp, task status == 0,

(cid:46) Initial

conditions of the physical process

2: Set τ min

c

≤ C ≤ τ max

c

3: Set τ min

p

≤ P ≤ τ max

p

(cid:46) Sensor3: Current. Input C through HMI

(cid:46) Sensor4: Pressure. Input P through HMI

4: do

5:

6:

7:

Start welding task

otemp = init temp + ∆t

(cid:46) ∆t is decided based on C and P .

Check τ min

t

≤ otemp ≤ τ max

t

(cid:46) Sensor5: Temperature.

8: while (d = t seconds)

9: task status == 1

10: ocount = ocount + 1
11: if ocount ≤ Amax

λ

then

(cid:46) Aλ can be deﬁned as serving 5 objects.

12:

Check equipment health

13: end if

During the welding process, the welding gun is exposed to heat and pressure,

thereby causing deformation of the welding electrodes [30]. Since maintaining

equipment health deﬁnes the production quality, reduce production downtime

and utility cost; therefore, we also record tool wear data. For the sake of sim-

plicity, we based our asset capacity (Aλ) on the number of objects (ocount) being

welded by the robotic arm. Upon reaching the maximum asset capacity (Amax

λ

),

the equipment health should be monitored before initiating the next production

process.

In replication mode, the input knowledge (for example, actions and events in

PE) are required to reproduce the same stimuli in the VE. Therefore, the real-

time sensor data (Ds(k),t) and asset current state (Ac

ω) from PE and threshold

23

Algorithm 4 Replication mode

Input: τ min

s(k) , τ max
s

(k)

Output: Data consistency between PE and VE

1: Get predeﬁned values of τ min

s(k) and τ max
s(k)

from C&V

2: Get Ac

ω of AID from PE

3: Get Ds(k),t of SID from PE

4: do

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

CC = (τ min

s(k) ≤ Ds(k),t ≤ τ max

s(k) ) AND (Ac

ω == on )

if (CC!=TRUE) then

Invoke S&S

if (R!=S&S) then

Call scheduling service

(cid:46) Check for fault diagnosis in the

equipment or the aﬃxed sensor

else

Call process calibration service

(cid:46) Calibrate the process settings

at VE

end if

Call Algorithm 1

end if

15: while (CC==TRUE)

values (τ min

s(k) and τ max

s(k) ) from ICMs are recorded. The recorded events are then
replayed in VE. Given that the PE is mirrored to VE by its conﬁguration set-

tings, speciﬁcation, and current events, the DT’s replication mode should deliver

the same results. To do so, data consistency checks are induced between the PE

and the VE as outlined in Algorithm 4. The consistency checks (CCs), for ex-

ample, speed-variable CC, can be harnessed for a variety of security monitoring

and operations purposes. If any inconsistent event is encountered, for instance,

Ds(k),t exceeds lower or upper bounds, the CC fails to meet the deﬁned opera-

tional behaviour of the system. Since we pre-deﬁne S&S rules for our situational

aware CPS framework, therefore, the appropriate rules can be triggered to deal

24

with such abnormal situations. However, in the course of advanced stealthy

attacks, S&S rules might be limited to detecting known misbehaviour. There-

fore, under such circumstances, depending on attack intensity, the scheduling

service is called to inspect device or network log data for fault diagnosis or pro-

cess calibration service is called to reconﬁgure the settings. In the worst-case

scenario, the aﬀected device or service can be switched oﬀ to avoid further loss.

The suggested measures are tested and veriﬁed ﬁrst at the VE and afterwards

regulated on the PE. Note that, the degree of state replication accuracy between

PE and VE depends on the trade-oﬀ between budget and ﬁdelity [31]. S&S can

be generated or updated based on the new incident data.

2.5. Data storage: blockchain-based digital twins

DTs control and program the lifecycle of physical assets to support product

servitization to end-users [2]. However, such advantages of DT are based on an

assumption about data trust, security, and integrity [2]. Data trustworthiness

matters more for safety-critical systems where slight dysfunction due to erro-

neous data may lead to wrong decisions that could imply loss of life or economic

disaster. Maliciously or mistakenly, in real-life scenarios, data breaches could

occur due to several reasons [4]. Therefore, mining actionable insights from the

collected data demands a data storage infrastructure to disseminate reliable and

secure data [10]. In this regard, provenance-enabled blockchain-based DTs can

be used to ensure trustworthy DTs throughout the product lifecycle [10].

While ensuring eﬃcient data retrieval, the next question is what should

be stored on the blockchain. Data-driven CPS primarily relies on the critical

data and data-generating sources that can facilitate track and trace solutions,

in addition to user- or application-speciﬁc requirements. By following [10], in

TTS-CPS, we limit the time-consuming frequent access to the blockchain-based

storage system by explicitly separating the less dynamic (or static) data and the

real-time dynamic data. For instance, data from the ICMs can be considered

less dynamic data as it infrequently changes with time along the lifecycle of the

physical counterpart, such as provenance data, device conﬁguration settings,

25

system’s historical data, policies and access levels. Similarly, to strengthen

the rationale for integrating blockchain with DT, S&S rules must be stored

and retrieved from the ledger (as shown in Fig. 2) to ensure their reliability.

In essence, blockchain inherently retains the history of modiﬁcations and thus

can circumvent illegal data modiﬁcation that may lead to other data-related

problems.

Being the virtual replicas of their physical counterparts, the DTs shares the

operational behaviour of the underlying physical process or device [3, 2]. On

the ﬂip side, the attackers may exploit the valuable knowledge about the sys-

tem accessible through DTs to put DTs into a malicious state [4, 32]. Thus

to avoid DTs use case as abuse case, DTs can be audited (for instance, chang-

ing the simulation setup parameter or state data) by using provenance-aware

blockchain-based solutions.

3. Implementation and Evaluation

In order to evaluate the proposed framework, a simulation for a DT of an

assembly line is implemented. The proof of concept demonstrates that the

virtual environment conforms to the deﬁned ICMs. Additionally, for building

the process knowledge of DTs, acquiring reliable system speciﬁcation data from

blockchain establishes conﬁdence in the DTs, thereby avoiding DT abuse cases.

In the following, we demonstrate the viability of the proposed framework in a

proof of concept, including the generation of DTs and the formal veriﬁcation.

3.1. Simulation and results

For our use case scenario showcased in Fig. 6 and Fig 7, we use MiniCPS [33]

which is built on Mininet [34]-a prototyping environment for networks. MiniCPS

extents Mininet to emulate and simulate CPS network components, including

PLCs, HMIs, and industrial network communication over EtherNet/IP or Mod-

bus/TCP. We based our work on the prototype available on GitHub 1. To create

1https://github.com/FrauThes/DigitalTwin-ConveyorBelt

26

(a) Human Machine Interface (HMI).

(b) Excerpt of HMI log.

(c) Programmable Logic Controller

(PLC) parameters.

(d) Physical process.

Figure 8: Scenario I: Conveyor belt

the virtual environment (discussed in Section 2.4.2), the main input is obtained

from the engineering- and domain-knowledge (Section 2.3.1 and Section 2.3.2

respectively.) The initial simulation setup must conform to the deﬁned rules

(Section 2.3.3). The system events are logged to a ﬁle. For example, Fig. 8b

shows excerpt of HMI log. Similarly, log ﬁles are maintained for PLCs and

other processes. The purpose of logged statements is to alert plant operators

27

(a) Human Machine Interface (HMI).

(PLC) parameters.

(b) Programmable Logic Controller

(c) Physical process-a

(d) Physical process-b

Figure 9: Scenario II: Robotic arm operating on the conveyor belt.

or security professionals about the system’s abnormal condition to carry out

the investigation by tracking and tracing the entities. Additionally, the log ﬁles

acquired from multiple instances of simulation can be scrutinize to gain more

insights into the underlying events. The log ﬁles can be used to generate or up-

date rules upon the execution of simulation. The logged events can be further

utilized by Security Information and Event Management (SIEM) [18] and/or

threat hunting [2].

We have used Hyperledger Fabric- a permissioned blockchain to store and

28

retrieve ICMs and other information signiﬁcant to the process. The simulation

mode runs independently of its physical counterpart and provide trial and er-

ror approach [2] while monitoring the states or events of the physical process.

Therefore, speciﬁcation data can be retrieved and stored before and after the

simulation, respectively. After repeatedly resetting the model through a broad

range of speciﬁed conditions, the obtained results can be used to update the

twin and eventually the physical asset. Fig. 8 showcases a conveyor belt sce-

nario, whereas Fig. 9 showcases a robotic arm operating on a conveyor belt.

The simulation setup is implemented based on the speciﬁcation data (such as

ICMs).

3.2. Formal veriﬁcation of the TTS-CPS

This section presents the formal veriﬁcation of our blockchain-based DT

model. In the veriﬁcation process, we demonstrate the correctness of the base

system. We need system speciﬁcation and properties to verify a proposed model

or a system [35]. We have used bounded model checking to evaluate the cor-

rectness of the underlying properties. The simulation model of conveyor belt

and robotic arm (as discussed in Section 2.4.2) is ﬁrst translated into Satisﬁ-

ability Modulo Theories Library (SMT-Lib) and then the Z3 Solver is used to

perform the veriﬁcation. More details about SMT-Lib and Z3 Solver can be

obtained from [35] and [36]. In bounded model checking, the goal is to evaluate

the correctness of the system inputs that drives the system into a state where

the system always terminates after a ﬁnite number of steps. Formally, bounded

model checking is deﬁned as a Kripke Structure and a bound k, where the prob-

lem is to ﬁnd M |=k Ef . In bounded model checking problem, an execution

path is tried to be searched in a Kripke structure M of length k that satisﬁes a

formula f . We have veriﬁed the blockchain-based DT framework by proving the

correctness of conveyor belt and robotic arm stated in Algorithm 2 and Algo-

rithm 3 respectively. We have translated the aforesaid algorithms into SMT-Lib

and then deﬁned certain correctness properties to verify the algorithms using

the Z3 solver.

29

SMT has their roots in Boolean Satisﬁability (SAT) Solvers.

It is gener-

ally used and is a part of automated deduction in for satisﬁability of formulas

over some theories on interests [37]. A common benchmark framework and

input platform is provided by the SMT that usually helps in evaluating the

systems [38]. The SAT and SMT solver performs diﬀerently in a way that SAT

evaluates the satisﬁability of propositional formulas. On the other hand, SMT

performs the satisﬁability of ﬁrst-order logic formulas based on underlying the-

ories. [39]. Deductive veriﬁcation is one of the many ﬁelds in which SMT has

been used. Considering the sensitive nature of recent computer sciences appli-

cations, which involves modeling and planning, performing formal analysis and

veriﬁcation through SMT is considered an important task. [38]. Some examples

are available in [40] and [41]. Several solvers supports the implementation of

SMT-lib. Some examples includes NuSMV, CVC4, OpenSMT, and SathSAT5.

The classiﬁcation of the solvers can be done based on the underlying theories,

logic, and interface [39]. In our study, we have used a theorem prover, namely

Z3, which is developed by Microsoft for checking automated satisﬁability.

It

evaluates if the model satisﬁes the properties speciﬁed in SMT-lib. More infor-

mation regarding the use and application of Z3 can be found in [42].

Deﬁnition 1 (Bounded Model Checking [43]) Formally, given a Kripke

Structure (S, So, R, L) and a k bound, the bounded model checking problem is to

ﬁnd M |=k Ef where: S is the ﬁnite set of states, So is a set of initial states,

R is the set of transitions, such that R ⊆ S × SL is the set of labels.

The bounded model checking problem is to ﬁnd an execution path in M of

length k that satisﬁes a formula f . Kripke structure, which is a state transi-

tion graph, is used to represent the behaviour of the system [35].

In Kripke

structure nodes are the set of reachable states of the system, edge represents

the transitions, and label functions map nodes to the set of properties hold in

the state. A path in a Kripke structure can be stated as an inﬁnite sequence of

states represented ρ = S1, S2, S3 . . . such that for ∀i ≥ 0, (Si, Si+1) ∈ R. The

model M may produce a path set = S1, S2, S3 . . . . To describe the property of

30

a model some formal language, such as Computation Tree Logic (CTL*), CTL,

or Linear Temporal Logic (LTL) can be used.

Deﬁnition 2 (SMT Solver [44]) Given a theory (cid:105) and a formula f , the SMT

solvers perform a check whether f satisﬁes (cid:105) or not.

To perform the veriﬁcation of the models using Z3 (an SMT Solver), we

unroll the model M and the formula f that provides Mk and fk, respectively.

Moreover, the said parameters are then passed to Z3 to check if Mk |=Γ fk [38].

The solver will perform the veriﬁcation and provide the results as satisﬁable

(sat) or unsatisﬁable (unsat). If the answer is sat, then the solver will generate

a counterexample, which depicts the violation of the property or formula f .

Moreover, if the answer is unsat, then the formula or the property f holds in

M up to the bound k (in our case, k is execution time).

We have identiﬁed certain properties, which we have veriﬁed in the conveyor

belt and robotic arm algorithm. The properties are as follows.

Property 1. (Time) “Does the welding performed by the robotic arm follows

the speciﬁed timeline, i.e., d = t”?

Property 2. (Temperature) “Does the robotic arm violates the welding tem-

perature range, i.e., τ min

t

≤ otemp ≤ τ max

t

”?

Property 3. (Velocity) “Does the conveyor belt moves according to the spec-

iﬁed range, i.e., τ min

v

≤ V ≤ τ max

v

”?

The veriﬁcation results of the properties are shown in Fig. 10. The time on

y-axis represents the execution time taken by the solver to verify each property.

As stated above, if the properties are not violated, the solver generates “unsat”,

which depicts that the solver was unable to ﬁnd any sequence of executions

within the models that violate the stated properties.

4. Conclusion and Outstanding Challenges

In this work, we have targeted two critical challenges, i.e., (i) how to estab-

lish a situational-aware and secure CPS through DTs and (ii) how to establish

31

Figure 10: Veriﬁcation results of robotic arm and conveyor belt algorithms.

the trustworthy generation of speciﬁcation-based DTs. To address these issues,

we have proposed a TTS-CPS framework. We demonstrate the feasibility of the

TTS-CPS framework for an assembly line in the automotive industry through a

prototypical implementation supporting the simulated network topology, PLCs,

HMIs, and physical devices. Moreover, we perform formal modelling and veri-

ﬁcation of the TTS-CPS.

An interesting direction for future work is to investigate how to construct a

fault-tolerant system. In other words, in the course of undesirable incidents, it is

essential to improve the system resilience during which the system enters a fail-

safe state and maintain an adequate control of the physical process. Another

open direction is to extend our work to carry out localization of attack, i.e.,

upon anomaly detection, ﬁnding the root cause of the deviation and localizing

the compromised node (sensor or actuator). Furthermore, we plan to incorpo-

rate smart contracts to automate event-based processes such as triggering the

appropriate defence mechanisms through S&S rules and modifying simulation

setup parameters [4]. Such automation ensures the benign behaviour of DTs,

particularly during the replication mode due to cyclic updates.

In general, several other technical challenges need to be addressed, for in-

stance, data trustworthiness, particularly in hierarchical DTs or a combination

of DT instances that mimic the bigger picture of the CPS. Such issues become

32

00,10,20,30,40,50,60,7TimeTemperatureVelocityExec. Time taken by the solver to prove the propertiesTime (secs)more challenging due to data fusion from multimodal systems and uncertain

scenarios due to the dynamism and complexity of underlying (sub) systems.

Other issues such as data storage and performance implications stemming from

blockchain and DTs’ integration also need due attention. [4] provides a de-

tailed discussion on the challenges that impede the successful implementation

of blockchain-based DTs in the industry.

References

[1] R. Baheti, H. Gill, Cyber-physical systems, The impact of control technol-

ogy 12 (1) (2011) 161–166.

[2] S. Suhail, R. Jurdak, Towards trusted and intelligent cyber-physical sys-

tems: A security-by-design approach, CoRR abs/2105.08886.

arXiv:

2105.08886.

URL https://arxiv.org/abs/2105.08886

[3] M. Eckhart, A. Ekelhart, Digital Twins for Cyber-Physical Systems Se-

curity: State of the Art and Outlook, Springer International Publishing,

Cham, 2019, pp. 383–412. doi:10.1007/978-3-030-25312-7 14.

[4] S. Suhail, R. Hussain, R. Jurdak, A. Oracevic, K. Salah, C. S. Hong,

R. Matuleviˇcius, Blockchain-based digital twins: Research trends, issues,

and future challenges, ACM Comput. Surv.Just Accepted. doi:10.1145/

3517189.

URL https://doi.org/10.1145/3517189

[5] R. Khan, P. Maynard, K. McLaughlin, D. Laverty, S. Sezer, Threat analysis

of blackenergy malware for synchrophasor based real-time control and mon-

itoring in smart grid, in: 4th International Symposium for ICS & SCADA

Cyber Security Research 2016 4, 2016, pp. 53–63.

[6] N. Kshetri, J. Voas, Hacking power grids: A current problem, Computer

50 (12) (2017) 91–95. doi:10.1109/MC.2017.4451203.

33

[7] R. Langner, Stuxnet: Dissecting a cyberwarfare weapon, IEEE Security

Privacy 9 (3) (2011) 49–51. doi:10.1109/MSP.2011.67.

[8] S. Miller, N. Brubaker, D. K. Zafra, D. Caban, Triton actor ttp proﬁle,

custom attack tools, detections, and att&ck mapping (2019).

URL

https://www.fireeye.com/blog/threat-research/2019/04/

triton-actor-ttp-profile-custom-attack-tools-detections.html

[9] A. Corallo, V. Del Vecchio, M. Lezzi, P. Morciano, Shop ﬂoor digital twin

in smart manufacturing: A systematic literature review, Sustainability

13 (23). doi:10.3390/su132312987.

[10] S. Suhail, R. Hussain, R. Jurdak, C. S. Hong, Trustworthy digital twins in

the industrial internet of things with blockchain, IEEE Internet Computing

(2021) 1–10doi:10.1109/mic.2021.3059320.

[11] S. Suhail, R. Hussain, A. Khan, C. S. Hong, Orchestrating product prove-

nance story: When IOTA ecosystem meets the electronics supply chain

space, Computers in Industry 123 (2020) 103334. doi:https://doi.org/

10.1016/j.compind.2020.103334.

[12] W. Shen, T. Hu, C. Zhang, S. Ma, Secure sharing of big digital

twin data for

smart manufacturing based on blockchain,

Jour-

nal of Manufacturing Systems 61 (2021) 338–350.

doi:https:

//doi.org/10.1016/j.jmsy.2021.09.014.

URL

https://www.sciencedirect.com/science/article/pii/

S0278612521002004

[13] M. Eckhart, A. Ekelhart, Towards security-aware virtual environments for

digital twins, in: Proceedings of the 4th ACM Workshop on Cyber-Physical

System Security, CPSS ’18, Association for Computing Machinery, New

York, NY, USA, 2018, p. 61–72. doi:10.1145/3198458.3198464.

[14] M. Eckhart, A. Ekelhart, A speciﬁcation-based state replication approach

for digital twins, in: Proceedings of the 2018 Workshop on Cyber-Physical

34

Systems Security and PrivaCy, CPS-SPC ’18, Association for Comput-

ing Machinery, New York, NY, USA, 2018, p. 36–47.

doi:10.1145/

3264888.3264892.

[15] M. Eckhart, A. Ekelhart, E. Weippl, Enhancing cyber situational awareness

for cyber-physical systems through digital twins, in: 2019 24th IEEE In-

ternational Conference on Emerging Technologies and Factory Automation

(ETFA), 2019, pp. 1222–1225. doi:10.1109/ETFA.2019.8869197.

[16] M. Dietz, B. Putz, G. Pernul, A distributed ledger approach to digital twin

secure data sharing, in: IFIP Annual Conference on Data and Applications

Security and Privacy, Vol. 11559, Springer, Cham, 2019, pp. 281–300. doi:

https://doi.org/10.1007/978-3-030-22479-0 15.

[17] M. Dietz, G. Pernul, Unleashing the digital twin’s potential for ICS se-

curity, IEEE Security & Privacy 18 (4) (2020) 20–27.

doi:10.1109/

MSEC.2019.2961650.

[18] M. Dietz, M. Vielberth, G. Pernul, Integrating digital twin security sim-

ulations in the security operations center,

in: Proceedings of the 15th

International Conference on Availability, Reliability and Security, ARES

’20, Association for Computing Machinery, New York, NY, USA, 2020.

doi:10.1145/3407023.3407039.

[19] A. Patel, T. Schenk, S. Knorn, H. Patzlaﬀ, D. Obradovic, A. B. Hal-

blaub, Real-time, simulation-based identiﬁcation of cyber-security attacks

of industrial plants,

in: 2021 IEEE International Conference on Cy-

ber Security and Resilience (CSR), 2021, pp. 267–272.

doi:10.1109/

CSR51186.2021.9527938.

[20] M. Vielberth, M. Glas, M. Dietz, S. Karagiannis, E. Magkos, G. Pernul, A

digital twin-based cyber range for SOC analysts, in: K. Barker, K. Ghazi-

nour (Eds.), Data and Applications Security and Privacy XXXV, Springer

International Publishing, Cham, 2021, pp. 293–311.

35

[21] M. Groshev, C. Guimar˜aes, J. Mart´ın-P´erez, A. de la Oliva, Toward in-

telligent cyber-physical systems: Digital twin meets artiﬁcial intelligence,

IEEE Communications Magazine 59 (8) (2021) 14–20.

doi:10.1109/

MCOM.001.2001237.

[22] V. Damjanovic-Behrendt, A digital twin-based privacy enhancement mech-

anism for the automotive industry, in: 2018 International Conference on In-

telligent Systems (IS), 2018, pp. 272–279. doi:10.1109/IS.2018.8710526.

[23] M. Dietz, G. Pernul, Digital twin: Empowering enterprises towards a

system-of-systems approach, Business & Information Systems Engineering

62 (2) (2020) 179–184.

[24] M. Eckhart, A. Ekelhart, R. Eisl, Digital twins for cyber-physical threat

detection and response, ERCIM News: Special Theme Smart and Circular

Cities 127 (2021) 12–13.

[25] K. Ni, N. Ramanathan, M. N. H. Chehade, L. Balzano, S. Nair, S. Zahedi,

E. Kohler, G. Pottie, M. Hansen, M. Srivastava, Sensor network data fault

types, ACM Trans. Sen. Netw. 5 (3). doi:10.1145/1525856.1525863.

[26] F. Zafar, A. Khan, S. Suhail, I. Ahmed, K. Hameed, H. M. Khan, F. Jabeen,

A. Anjum, Trustworthy data: A survey, taxonomy and future trends of

secure provenance schemes, Journal of Network and Computer Applications

94 (2017) 50–68. doi:https://doi.org/10.1016/j.jnca.2017.06.003.

[27] R. Sandhu, D. Ferraiolo, R. Kuhn, et al., The nist model

for role-

based access control: towards a uniﬁed standard, in: ACM workshop on

Role-based access control, Vol. 10, 2000. doi:https://doi.org/10.1145/

344287.344301.

[28] F. Tao, M. Zhang, Digital twin shop-ﬂoor: a new shop-ﬂoor paradigm

towards smart manufacturing, IEEE Access 5 (2017) 20418–20427.

[29] A. B´ecue, Y. Fourastier, I. Pra¸ca, A. Savarit, C. Baron, B. Gradussofs,

E. Pouille, C. Thomas, Cyberfactory#1 — securing the industry 4.0 with

36

cyber-ranges and digital twins, in: 2018 14th IEEE International Workshop

on Factory Communication Systems (WFCS), 2018, pp. 1–4. doi:10.1109/

WFCS.2018.8402377.

[30] T. Hong, M. Ghobakhloo, W. Khaksar, 6.04 - robotic welding technol-

ogy, in: S. Hashmi, G. F. Batalha, C. J. Van Tyne, B. Yilbas (Eds.),

Comprehensive Materials Processing, Elsevier, Oxford, 2014, pp. 77–99.

doi:https://doi.org/10.1016/B978-0-08-096532-1.00604-X.

URL

https://www.sciencedirect.com/science/article/pii/

B978008096532100604X

[31] R. Bitton, T. Gluck, O. Stan, M. Inokuchi, Y. Ohta, Y. Yamada, T. Yagyu,

Y. Elovici, A. Shabtai, Deriving a cost-eﬀective digital twin of an ics

to facilitate security evaluation, in: European Symposium on Research

in Computer Security, Springer, Cham, 2018, pp. 533–554. doi:https:

//doi.org/10.1007/978-3-319-99073-6 26.

[32] S. Suhail, R. Jurdak, R. Hussain, D. Svetinovic, Security attacks and so-

lutions for digital twins, arXiv: 2202.12501. [Online]. Available: https:

//arxiv.org/abs/2202.12501 (2022).

[33] D. Antonioli, N. O. Tippenhauer, Minicps: A toolkit for security re-

search on cps networks, in: Proceedings of the First ACM Workshop on

Cyber-Physical Systems-Security and/or PrivaCy, CPS-SPC ’15, Associ-

ation for Computing Machinery, New York, NY, USA, 2015, p. 91–100.

doi:10.1145/2808705.2808715.

URL https://doi.org/10.1145/2808705.2808715

[34] B. Lantz, B. Heller, N. McKeown, A network in a laptop: Rapid pro-

totyping for software-deﬁned networks, in: Proceedings of the 9th ACM

SIGCOMM Workshop on Hot Topics in Networks, Hotnets-IX, Associa-

tion for Computing Machinery, New York, NY, USA, 2010. doi:10.1145/

1868447.1868466.

37

[35] S. U. R. Malik, S. U. Khan, S. K. Srinivasan, Modeling and analysis of state-

of-the-art vm-based cloud management platforms, IEEE Transactions on

Cloud Computing 1 (1) (2013) 1–1. doi:10.1109/TCC.2013.3.

[36] S. U. R. Malik, K. Bilal, S. U. Khan, B. Veeravalli, K. Li, A. Y. Zomaya,

Modeling and analysis of the thermal properties exhibited by cyberphysical

data centers, IEEE Systems Journal 11 (1) (2017) 163–172. doi:10.1109/

JSYST.2015.2493565.

[37] L. de Moura, N. Bjørner, Satisﬁability modulo theories: An appetizer, in:

M. V. M. Oliveira, J. Woodcock (Eds.), Formal Methods: Foundations and

Applications, Springer Berlin Heidelberg, Berlin, Heidelberg, 2009, pp. 23–

36.

[38] Smt-lib, Available at: https://smtlib.cs.uiowa.edu/ (Accessed on Jan.

04, 2022).

[39] M. J. Frade, J. S. Pinto, Veriﬁcation conditions for source-level imperative

programs, Computer Science Review 5 (3) (2011) 252–277.

[40] S. U. R. Malik, S. K. Srinivasan, S. U. Khan, L. Wang, A methodology for

ospf routing protocol veriﬁcation, in: Proceedings of the 12th International

Conference on Scalable Computing and Communications (ScalCom), Dec.

2012.

[41] S. Malik, S. Srinivasan, S. Khan, Convergence time analysis of open shortest

path ﬁrst routing protocol in internet scale networks, Electronics letters

48 (19) (2012) 1188–1190.

[42] L. de Moura, N. Bjørner, Z3: An eﬃcient smt solver, in: C. R. Ramakr-

ishnan, J. Rehof (Eds.), Tools and Algorithms for the Construction and

Analysis of Systems, Springer Berlin Heidelberg, Berlin, Heidelberg, 2008,

pp. 337–340.

[43] A. Biere, A. Cimatti, E. M. Clarke, O. Strichman, Y. Zhu, Bounded model

checking, Advances in Computers 58 (2003) 121––125.

38

[44] L. Cordeiro, B. Fischer, J. Marques-Silva, Smt-based bounded model check-

ing for embedded ansi-c software, IEEE Transactions on Software Engineer-

ing 38 (4) (2011) 957–974.

39

