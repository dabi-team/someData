Blockchain-based Federated Learning: A
Comprehensive Survey

Zhilin Wang, Qin Hu

1

1
2
0
2

t
c
O
5

]

R
C
.
s
c
[

1
v
2
8
1
2
0
.
0
1
1
2
:
v
i
X
r
a

Abstract—With the technological advances in machine learn-
ing, effective ways are available to process the huge amount
of data generated in real life. However, issues of privacy and
scalability will constrain the development of machine learning.
Federated learning (FL) can prevent privacy leakage by assigning
training tasks to multiple clients, thus separating the central
server from the local devices. However, FL still suffers from
shortcomings such as single-point-failure and malicious data. The
emergence of blockchain provides a secure and efﬁcient solution
for the deployment of FL. In this paper, we conduct a com-
prehensive survey of the literature on blockchained FL (BCFL).
First, we investigate how blockchain can be applied to federal
learning from the perspective of system composition. Then, we
analyze the concrete functions of BCFL from the perspective
of mechanism design and illustrate what problems blockchain
addresses speciﬁcally for FL. We also survey the applications of
BCFL in reality. Finally, we discuss some challenges and future
research directions.

Index Terms—Blockchain, federated learning, machine learn-

ing.

I. INTRODUCTION

Nowadays, machine learning (ML) has been applied in
every ﬁeld, profoundly changing human life. Daily generated
data can be gathered from massive end users to train ML
models which bring beneﬁts in terms of providing better
services to improve our quality of life. However, the current
ML framework usually requires end devices to transfer the
collected data to the central server for model training, thus
causing two challenges. First, data transferring may consume
a large amount of communication resources. Second,
the
submission of raw data increases the risk of privacy leakage,
making data owners reluctant to upload data to the central
server for security concern.

To address the above concerns, Google proposed a novel
ML framework named federated learning (FL), which can
effectively protect the privacy of users while allowing multiple
end devices to collaboratively train an ML model [1]. Different
from the conventional ML framework, FL does not require
data owners, i.e., clients, to transfer the raw data to the central
server for model training, but only upload the parameters of the
model trained by the local data. This prevents privacy leakage
caused by the data transferring and reduces the transmission
cost. In the past few years, FL has been studied well and
developed rapidly [2], [3]. However, the traditional FL frame-
work still faces some problems which undermine the reliability

Zhilin Wang and Qin Hu are with the Department of Computer Science,
Indiana University-Purdue University Indianapolis, Indiana, USA. E-mail:
{wangzhil, qinhu}@iu.edu.

of the whole system [1], [4], [5] and can be summarized as
follows.

• Single point of failure. In an FL paradigm, a cen-
tral server, which is usually named as aggregator, is
employed to perform the integration of local training
results so as to update the global model. However, the
aggregator is not always reliable. Once the centralized
aggregator is compromised, the whole FL system will
fail. Some potential problems of the aggregator include
intentionally dishonest aggregation, accidental network
connection failure, unexpected external attacks, etc.
• Malicious clients and false data. Given the large num-
ber of participants in FL, it is impossible to hold the
assumption that all clients are honest and will train the
local models according to the predeﬁned FL protocols.
Therefore, there may exist dishonest clients submitting
false data about their local training results. The perfor-
mance of the global model can be heavily affected by the
contamination of invalid data, and the whole FL system
might be attacked by malicious clients via other means,
such as training the local models using partial datasets.
• The lack of incentives. In the traditional FL, clients
are considered to be contributing their computing powers
without receiving any payments, leading to the difﬁculty
of encouraging clients to follow the protocol honestly
and provide reliable data. More importantly, since FL
usually requires multiple devices to work collaboratively,
especially for the data-intensive training tasks in need
of a large number of participants,
the traditional FL
framework may fail to attract enough number of clients
engaging in the FL training due to the lack of incentives.

Clearly, the above deﬁciencies prevent FL from working
efﬁciently and reliably. Therefore, improvements to the tra-
ditional FL become essential. Blockchain, as an emerging
technology, functions with several attractive properties, such as
decentralization, anonymity, and traceability, which has been
applied in lots of ﬁelds [6]–[8]. Recently, blockchain has also
been utilized to address the challenges faced by the conven-
tional FL. First, decentralization can be realized by deploying
blockchain in FL, which means that the central aggregator can
be replaced by the peer-to-peer blockchain system and the job
of aggregating the global model can be handled by blockchain
nodes, thus avoiding the unreliability of the whole FL system
caused by the failure of the centralized server [9]. Moreover,
blockchain can provide veriﬁcation mechanisms for FL in the
name of transaction veriﬁcation, by which the unqualiﬁed or
even malicious local model updates can be removed before

 
 
 
 
 
 
the global model is aggregated [10]. Further, blockchain can
effectively distribute rewards to FL clients for encouraging
their participation and honest behaviors [11]. Based on our
investigation, we argue that blockchained FL framework has
at least the following merits:

• Single-point-failure can be avoided by taken the place
of central aggregator with blockchain. In a blockchained
FL system, the model aggregation will executed by more
than one client.

• Unreliable data can be ﬁltered out by the veriﬁcation
mechanism. Before the local model updates are being
aggregated, the unreliable data will be detected, and only
valid data can be added to the global model.

• More participates and computational resources can be
attracted through the incentive mechanisms. Economical
incentives (e.g., cryptocurrency) can not only encourage
more devices to participate in the model training but also
encourage clients to behave following the rules.

• Learning data can be stored and shared on the distributed
ledger. Once the data are recorded on the distributed
ledger, they can be hardly tampered. Meanwhile, autho-
rized clients can access to the distributed ledger to retrieve
the public data, improving the training efﬁciency.

From existing research, despite the excellent performance of
BCFL in terms of decentralization and providing incentives,
new problems such as resource allocation, communication
delays, and external attacks arising from the combination of
the two still need to be addressed in future research.

To the best of our knowledge, our paper is the ﬁrst com-
prehensive investigation of BCFL. Following are the main
contributions of our work:

• We investigate the current research of blockchained FL,
and analyse the motivations of applying blockchain to
FL.

• We detail the foundations of BCFL, including the BCFL
architecture, blockchain types, and training devices. We
ﬁrst propose that BCFL architectures can be classiﬁed
into three types based on coupling: fully coupled BCFL,
ﬂexibly coupled BCFL, and loosely coupled BCFL.
• We present the functions of BCFL from the perspective
of veriﬁcation mechanism, global model aggregation,
distributed ledger and incentive mechanism. The analysis
of these functions explains the changes that blockchain
can bring to FL.

• We analyze the current challenges of BCFL and discuss

the future research directions.

The rest of this article is organized as follows. In Section II,
we introduce the basics of FL and blockchain; we present the
foundations of BCFL in Section III. In Section IV, we detail
the four functions of BCFL; and in Section V, we investigate
the applications of BCFL in different domains; discussions of
the current challenges and future research directions of BCFL
are presented in Section VI; and we conclude the paper in
Section VII.

II. BACKGROUND KNOWLEDGE
In this chapter, we will go through the basic principles of

blockchain and FL, respectively.

2

A. Brief Introduction to FL

In real life, mobile devices with smart sensors are used
extensively and subsequently generate a massive amount of
data. Based on training such data for improving the per-
formance of devices, artiﬁcial intelligence has been greatly
developed. The data in multiple devices is usually unbalanced
and non-independent and identically distributed (Non-IID),
and the communication cost among devices is expensive since
the devices are massively distributed [12]–[14]. In addition,
storing all the data in a centralized manner is not a secure
choice. In these cases, Google introduced a novel distributed
machine learning framework termed FL to address the above
issues of machine learning on mobile devices [1], [15], [16].
FL is a distributed machine learning technique that trains
data on local devices, then the local devices upload the local
model updates, i. e., weights and gradients of the local models,
to a central server and runs a predeﬁned aggregation algorithm
to obtain a global model. The topology of FL is shown in
Figure 1. Usually, the local devices are referred to clients,
and the central sever is termed aggregator. The basic merit
of FL is that it requires no access to the raw data on local
devices directly [1]. FL allows the privacy of the raw data
to be preserved effectively, and also reduces the cost of data
transmission and extent the availability of mobile devices [17].
The workﬂow of traditional FL is described as follows [3],
[16], [18]:

• Clients Selection Clients are selected based on deﬁnite
protocols, and then they download the latest global model
before the training task starts.

• Local Model Training Clients train the local data and
update the trained local models based on predeﬁned
algorithms (e.g., Stochastic Gradient Decent (SGD)) in-
dependently.

• Upload Local Model Updates Clients transfer the local

model updates to the aggregator.

• Global Model Aggregation Global model is calculated
in the aggregator by executing the aggregation algorithms
such as FederatedAveraging (FedAvg).

In [19], FL is classiﬁed into three categories, i.e., Horizontal
FL, Vertical FL, Federated Transfer Learning, based on the
characteristics of raw data distribution. The details of the
categories of FL are as below.

• Horizontal FL The datasets have the same characteristics

with varying samples.

• Vertical FL The datasets have the same sample space

while the feature space is various.

• Federated Transfer Learning In the case where both
datasets have less overlapping samples and features,
transfer learning is used to overcome the lack of data
or labels without slicing the data.

In FL, privacy and communication effectiveness are often
the primary concerns [14]. [20] surveys the research related to
the privacy issues of FL, illustrating several attacks which will
lead to the leakage of data privacy, e.g., membership inference
attack and GAN-based(a deep learning algorithm) inference
attack. Meanwhile, authors introduce several countermeasures
such as Differential Privacy(DP) and Secure Multi-party Com-

3

interactions in the supervised learning tasks.

B. Brief Introduction to Blockchain

In 2008, Nakamoto introduced a peer to peer payment
system termed Bitcoin which is totally decentralized and
transparent [35]. Now Bitcoin is the largest cryptocurrency
in the world. The technology backed Bitcoin is blockchain,
which provides traceable and immutable records for every
transaction and deliver
rewards to working nodes based
on their contributions. Figure 2 indicates the topology of
blockchain. Blockchain technology has been widely used in
cryptocurrency(e.g., Bitcoin, Ethereum [36]), healthcare [37],
[38], smart city [39], [40], Internet of Things(IoT) [41], etc.
Typically, blockchain has the following properties [42], [43].
• Decentralization Since blockchain utilizes the P2P net-
work, there is no need for a third party or a single central
node to assist in network propagation. In this way, all
nodes are equal. For example, Bitcoin, ﬁrst proposed by
Nakamoto in 2008, was designed to avoid third-party
payment platforms interfering with transactions.

• Traceable The data on the blockchain can be traced back
to its source due to the special structure of the blockchain.
• Anonymity In blockchain, although data on chain is
public, privacy can be prevented from being obtained by
others through the encryption of private information of
users.

• Immutability Data stored through the blockchain struc-

ture is very difﬁcult to be altered.

Blockchain is a distributed ledger which empowered by
participated devices named miners. Each miner keeps one
replica of the entire ledger locally, and competes to win the
opportunity to generate new block which contains a package
of transactions.

Bitcoin system is public, which means everyone can join
or leave without permissions. While other systems based
blockchain are private, allowing only the certiﬁed users to
participate. Typically, blockchain can be roughly classiﬁed
into three categories,
i.e., private blockchain, consortium
blockchain and public blockchain.

• Public Blockchain In public blockchain, everyone can
join or leave without permissions, and participate in
consensus process and access to the public ledger. Bitcoin
and Ethereum are public blockchain. Public blockchain
is entirely decentralized without central authority who
may control the network, leaving the records on public
blockchain immutable. However, the speed of proceeding
the transactions on public blockchain is limited since nu-
merous users are on that chain and transactions required
to process are in large amount.
• Private Blockchain In contrast

to public blockchain,
nodes on private blockchain are under supervision, which
means that only the authorized nodes can join in that
network and access to the shared ledger. Meanwhile,
nodes on private blockchain are public to other nodes,
allowing all
the actions on that blockchain traceable.
However, private blockchain is not totally decentralized
to some extent.

Fig. 1. Topology of traditional FL

putation(SMC). DP is a commonly applied technology which
preserves privacy by adding noises to private information, i.e.,
the local model updates that required to be uploaded to the
central server. DP reduces the possibility of the data being
reverse inferred without too signiﬁcant loss of data quality.
Now DP is widely used in FL to protect the privacy of clients
[21]–[23].

To the concern of communication, Sattler et al [4] argue that
the methodology of collaborative training protects data privacy
but causes communication challenges, e.g.,
the increasing
of communication costs. They propose a novel compression
algorithm termed Sparse Ternary Compression(STC) which
derived from top-k (a technology used to compression) to
address the above issue. The experiment results indicate that
STC is effective in general situations. Besides, FedPAQ,
i.e., FL method with periodic averaging and quantization,
is another methodology designed to overtake the challenges
of communication bottleneck and scalability and guarantee
the accuracy at the meantime in FL [24]. FedPAQ allows
partial nodes to participate in the local training and then nodes
transfer the quantized updates to the parameter server, which
averages the global model periodically.

Since FL framework was proposed by Google in 2016, it
has been used in practice in many areas, including wireless
devices [25]–[27], healthcare [28]–[30], Internet of Things
[31], [32], smart city [33], [34], business and ﬁnance [19].
According to [1], the following situations are appropriate for
the implementation of FL.

• The beneﬁt of training the raw data from local devices
compared to training the agent data in the central server
is signiﬁcant.

• The data to be trained is sensitive or the size of the data
is large, and uploading such data to the data center is not
appropriate to protect privacy of the devices.

• The labels of the data can be deduced based on the user

4

blockchain network, including P2P network mechanism,
information propagation mechanism, and data veriﬁcation
mechanism. With P2P network, the risks caused by partial
nodes or network failures can be avoided because the
nodes communicate with each other. When a transaction
is created, it will subsequently be propagated to all nearby
nodes for validation. If the validation is approved, it
will be propagated to other nodes. Through the prop-
agation mechanism and validation mechanism, invalid
transactions can be effectively ﬁltered out, and only valid
transactions can move to the next mining process.

• Consensus Layer Since the blockchain is composed by
a large number of nodes, each node can validate trans-
actions, so it is necessary to determine who can generate
the new block. This is a process of reaching consensus
among nodes, both to be democratic (avoiding author-
itative centers) and efﬁcient (enabling all nodes to be
willing to reach consensus). Many consensus mechanisms
are currently used, such as PoW [47], [48], PoS [49],
etc. Proof of Working (PoW), for example, is the most
commonly used consensus mechanism, which is adopted
by Bitcoin. It works by each working node (miner)
performing a mining process on the block which contains
a package of transactions, i. e., solving a mathematical
puzzle, and the node which solves it ﬁrstly will get the
opportunity to generate new block. The process of mining
consumes a lot of computing power, but provides robust
security. Usually, the choice of consensus mechanism
is determined by the speciﬁc needs of the designed
blockchain.

• Incentive Layer Nodes on a blockchain do not all
voluntarily provide the computing power to generate new
blocks, unless incentives are offered. In incentive layer,
miners will be rewarded based on deﬁned protocols.
Typically, the rewards are available when a new block is
generated, or the rewards are obtained by charging fees
for transactions. By offering economical rewards, miners
can be encouraged to participate in mining honestly.

• Contract Layer The contract

layer provides various
types of code, scripts and smart contracts that control
the operation of the blockchain. Smart contracts are
written into the blockchain through computer language
with trigger conditions for certain events, and once these
events are triggered, the smart contracts are automatically
executed according to deﬁned rules. Smart contracts can
automatically handle issues on the blockchain network,
requiring no third-party intervention and making the
blockchain more independent and transparent.

• Application Layer The uppermost

the
blockchain, i.e., the application layer, provides the chan-
nel for the blockchain to connect with the real world.
Blockchain-based applications are deployed in the ap-
plication layer, such as various types of applications
developed on Ethereum.

layer of

We should notice that not all the layers mentioned above
must be equipped on the blockchain. The three lower layers
can be seen as concordance layers, which are essential; the

Fig. 2. Structure of block.

• Consortium Blockchain Consortium blockchain is par-
tially decentralized and controlled by several predeﬁned
or selected nodes(i.e., authorities who have the rights to
generate new blocks). Typically, consortium blockchain is
private blockchain with different authority mechanisms.

Generally, private blockchain and consortium blockchain
can be termed permissioned blockchain since both of them
required permissions before the potential users register in the
blockchain network. In the applications of blockchain, what
kind of blockchain should be adopted is determined by the
purpose of the usages.

From the perspective of structure, blockchain is composed
by six layers, i.e., data layer, network layer, consensus layer,
incentive layer, constract
layer and application layer [39],
[44]–[46]. Next, we will discuss the details of each layer of
blockchain.

• Data Layer This is the fundamental layer of blockchain.
Within each block, block header and block body are
included. The block header contains the hash of the
parent block, which is used to connect two blocks. When
multiple blocks are generated and connected, they form
a blockchain, as shown in Figure 2. In the block header,
the data related to mining, such as timestamp, Nonce,
and difﬁculty value are also included, and the Merkle
root is the hash value obtained from the Merkle tree in
the block body. In the body of block, the transactions
are encrypted and stored by a Merkle tree, which can
facilitate data query.

• Network Layer The network layer mainly provides
mechanisms of information exchange for each node in the

upper three layers are not required for all blockchains.

We take a real-life payment application of Bitcoin as an

example to illustrate the workﬂow of the blockchain.

• First, user A pays a certain amount of bitcoins to user B

and this transaction is recorded.

• The nearby node propagates this transaction to other
nodes, and these nodes will verify whether the transaction
is valid or not.

• If the veriﬁcation result is valid, the transaction will be

put into a block; otherwise, it will be discarded.

• All nodes that receive the transaction execute PoW, and
the one who wins will have the right to generate a new
block.

• The new block will be broadcast to other nodes and added

to the blockchain.

III. FOUNDATIONS OF BCFL

In this paper, we investigate the implementation of several
new features in the FL model through blockchain, so as to
address some existing problems of FL. In this section, we
explore BCFL as a whole system, describing and classifying
its architectures. Our work is based on the perspective of the
components of the BCFL model. At the beginning, We propose
a methodology to classify the architectures of BCFL according
to the coupling between blockchain and FL. Next, we analyze
blockchain and FL in this system respectively. Since the
blockchain has different types, various properties that BCFL
models have on different types of chains are discussed. We
notice that the participants of the model training of BCFL
are distinct, which will affect the deployment of BCFL in
speciﬁc applications. We will also provide lessons learned in
each subsection to illustrate more concretely how BCFL model
works. Table I shows the summery of the relevant literatures.
For rigorous expression in this paper, some terminologies

of blockchained FL are listed and explained below:

• Clients: devices that work in FL system to collect data

and train local models.

• Nodes: members in blockchain network to provide com-
puting powers and generate new blocks, which can also
be called miners.

• Aggregator: server or other powerful enough equipments

to aggregate the global model.

• Distributed ledger: a traceable and audible database
distributed across multiple nodes in blockchain network,
storing data for retrieve or audit.

• Transaction: data records in each block.
• Local Model updates: gradients and weights computed

by clients based on local raw data.

A. Architectures of BCFL

Before we design the BCFL model, a clear understanding
of its architecture is necessary. No relevant studies have been
conducted on the architecture of BCFL, in our paper, we will
ﬁll this gap. We group the architectures of BCFL into three
categories: fully coupled BCFL, ﬂexibly coupled BCFL and
loosely coupled BCFL, based on different coupling.

5

1) Fully Coupled BCFL: We can deﬁne the the framework
as the fully coupled blockchain-based FL model (FuC-BCFL)
when the clients of FL are the nodes of blockchain, in other
words, the clients not only train the local models, but also
verify the updates and generate new blocks. The topology of
FuC-BCFL is shown in Figure 3. We can derived from the
deﬁnition of FuC-BCFL that FL model is decentralized since
every node on blockchain has chance to participate in the local
model training and global model aggregation, thus the role of
central aggregator can be take place by the blockchain. In
such a framework, there are two methodologies to average the
global model: i) some selected nodes collect the validated local
model updates and then conduct the aggregation algorithm; ii)
all the nodes can participate in the global model aggregation.
The distributed ledger contains the training data, including
the veriﬁed local model updates, global model updates and
other data produced during the learning process. Typically, the
workﬂow of the FuC-BCFL can be summarized as follows:

Fig. 3. Topology of fully coupled BCFL.

• Clients collect data and train the models locally.
• Local model updates are veriﬁed by the (selected) clients.
• Veriﬁed local updates are collected by (selected) clients

and then the global model will be updated.

• New block which stores the veriﬁed model updates is

added into the distributed ledger.

• According to incentive mechanism, rewards will be dis-

tributed to participates.

FuC-BCFL has been mentioned in various studies. In [62],
clients of FL are edge sides which can sensor data and provide
computing powers, and they are responsible for data collecting
and data training. The blockchain in that framework works as
the distributed ledger to record the training data as well. In
that system, the integrity of the raw data is protected and the
malicious clients are prevented.

[56] proposed a FL system based on blockchain, all
participates competed to generate new blocks, and then the
winner will collect the model parameters and update them
into the blockchain. Since no raw data is shared during the

f
o

y
n
o
r
h
c
n
y
s
a

e
h
t

s
s
e
r
d
d
a

o
t

)
L
F
-
G
A
D

(

s
u
s
n
e
s
n
o
c

L
F

d
e
s
a
b

h
p
a
r
g

c
i
l
c
y
c
a

t
c
e
r
i
d

a

d
e
c
u
d
o
r
t
n
I

L
F
C
B

f
o

n
o
i
t
c
e
t
e
d

y
l
a
m
o
n
a

d
n
a

s
e
c
i
v
e
d

e
e
t
t
i

m
m
o
c

d
n
a

s
s
e
c
o
r
p

g
n
i
n
i
a
r
t

e
h
t

,
s
n
e
t
t
a
p

e
g
a
r
o
t
s

l
e
d
o
m
e
h
t

s
e
n
ﬁ
e
d

h
c
i
h
w
C
L
F
B

d
e
s
o
p
o
r
P

g
n
i
v
r
e
s
e
r
p
-
y
c
a
v
i
r
p

d
n
a

d
e
z
i
a
r
t
n
e
c
e
d

y
l
l
u
f

s
i

t
a
h
t

m
e
t
s
y
s

L
F

e
l
b
a
t
n
u
o
c
c
a

n
a

s
i

w
o
l

F
k
c
o
l
B

n
o
i
t
c
e
t
e
d

y
l
a
m
o
n
a

o
d

o
t

L
F

d
e
n
i
a
h
c
k
c
o
l
b

d
e
n
o
i
s
s
i

m
r
e
p

a

d
e
s
o
p
o
r
P

s
e
c
i
v
e
d

T
o
I

r
o
f

a
t
a
d

e
v
e
i
r
t
e
r

d
n
a

e
r
a
h
s

o
t

L
F

d
e
n
i
a
h
c
k
c
o
l
B

r
o
t
a
g
e
r
g
g
a

l
a
r
t
n
e
c

e
h
t

f
o

e
c
a
l
p

e
k
a
t

o
t

t
c
a
r
t
n
o
c

t
r
a
m

s

d
e
g
a
r
e
v
e
L

m
s
i
n
a
h
c
e
m
e
v
i
t
n
e
c
n
i

e
v
i
t
i
t
e
p
m
o
c

a

d
e
n
g
i
s
e
D

s
u
s
n
e
s
n
o
c

d
o
h
t
e
m
n
o
i
t
c
e
l
e
s

e
d
o
n

d
n
a

d
o
h
t
e
m
g
n
i
t
h
g
i
e
w
g
n
i
n
r
a
e
l

l
a
c
o
l

d
e
s
a
b

n
o
i
t
i
n
g
o
c
e
r

e
d
o
n

d
e
s
o
p
o
r
P

l
e
d
o
m
e
t
a
g
e
r
g
g
a

o
t

e
i
t

f
o

e
t
a
t
s

l
e
d
o
m

l
a
b
o
l
g

d
n
a

s
l
e
d
o
m
n
i
a
r
t

o
t

s
l
e
n
n
a
h
c

d
e
g
a
r
e
v
e
L

s
i
s
y
l
a
n
a

y
c
n
e
t
a
l

d
n
a

s
e
t
a
d
p
u

l
e
d
o
m
y
f
i
r
e
v

d
n
a

e
g
n
a
h
c
x
e

o
t

L
F

d
e
n
i
a
h
c
k
c
o
l
B

L
F
C
B

n
o

d
e
s
a
b

a
i
t
r
o
s
n
o
c

e
r
a
c
h
t
l
a
e
h

d
e
v
r
e
s
e
r
p
-
y
c
a
v
i
r
P

r
e
n
w
o

l
e
d
o
m
e
h
t

r
o
f

s
n
o
i
s
i
c
e
d

l
a
m

i
t
p
o

e
h
t

e
v
i
r
e
d

o
t

g
n
i
n
r
a
e
l

t
n
e
m
e
c
r
o
f
n
i
e
r

p
e
e
d

d
e
s
U

n
o
i
t
a
g
e
r
g
g
a

l
a
b
o
l
g

e
r
o
f
e
b

s
e
t
a
d
p
u

l
e
d
o
m

l
a
c
o
l

n
i
a
r
t

o
t

n
i
a
h
c
k
c
o
l
b

d
e
g
a
r
e
v
e
L

n
i
a
h
c
k
c
o
l
b

e
h
t

o
t
n
o
m
e
t
s
y
s

g
n
i
c
r
u
o
s
d
w
o
r
c

e
r
i
t
n
e

e
h
t

d
e
t
n
a
l
p
s
n
a
r
T

n
i
a
h
c
k
c
o
l
b

y
b

d
e
c
a
l
p
e
r

s
a
w

r
e
v
e
s

l
a
r
t
n
e
c

e
h
T

S
o
P
D
n
o

d
e
s
a
b

n
i
a
h
c
k
c
o
l
b

d
e
n
o
i
s
s
i
m
r
e
p

r
o
f

e
m
e
h
c
s

n
o
i
t
a
c
ﬁ
i
r
e
v

t
h
g
i
e
w
t
h
g
i
l

a

d
e
p
o
l
e
v
e
D

g
n
i
t
n
u
o
c
c
a

y
b

s
k
c
a
t
t
a

l
a
i
r
a
s
r
e
v
d
a

r
e
t
e
d

o
t

L
F
C
B

a

d
e
s
o
p
o
r
P

r
o
t
a
g
e
r
g
g
a

l
a
r
t
n
e
c

e
h
t

e
c
a
l
p
e
r

o
t

n
i
a
h
c
k
c
o
l
b

e
h
t

d
e
s
U

L
F
C
B

n
o

d
e
s
a
b
m
e
t
s
y
s

r
a
l
u
c
i
h
e
v

s
u
o
m
o
n
o
t
u
A

s
r
e
s
u

d
r
a
w
e
r

d
n
a

r
e
n
n
a
m
e
l
b
a
l
a
c
s

a

n
i

s
e
t
a
d
p
u

d
e
d
a
o
l
p
u

d
r
o
c
e
r

o
t

S
F
P
I

d
n
a

C
B

S
O
E

g
n
i
s
U

t
s
o
c

a
t
a
d

g
n
i
n
i
a
r
t

n
o

d
e
s
a
b

g
n
i
t
u
p
m
o
c

e
g
d
e

t
n
e
g
i
l
l
e
t
n
i

r
o
f

L
F
C
B

n
i

e
g
a
k
a
e
l

y
t
r
e
p
o
r
p

d
e
d
n
e
t
n
i
n
u

e
h
t

d
e
z
y
l
a
n
a

T
o
I

n
i

a
t
a
d

e
r
a
h
s

o
t

L
F

s
u
o
n
o
r
h
c
n
y
s
a

d
n
a

n
i
a
h
c
k
c
o
l
b

d
i
r
b
y
h

d
e
p
o
l
e
v
e
D

k
r
o
w
e
m
a
r
f

e
c
n
e
f
e
d

g
n
i
t
u
p
m
o
c

d
e
t
u
b
i
r
t
s
i
d

r
e
y
a
l
-
i
t
l
u
m
a

d
e
s
o
p
o
r
P

e
e
r
t

e
l
k
r
e

M

a

d
l
i
u
b

o
t

l
o
c
o
t
o
r
p

g
n
i
r
o
h
c
n
a

n
a

d
e
n
g
i
s
e
D

d
n
a

s
l
e
d
o
m

f
o

s
m
r
e
t

n
i

s
n
o
i
t
c
a
s
n
a
r
t

e
h
t

s
d
r
o
c
e
r

t
a
h
t

r
e
g
d
e
l

d
e
t
u
b
i
r
t
s
i
d

a

s
a

s
e
v
r
e
s

n
i
a
h
c
k
c
o
l
B

n
i
a
h
c
k
c
o
l
b

n
o

d
e
s
a
b
m
s
i
n
a
h
c
e
m
e
v
i
t
n
e
c
n
i

d
n
a

t
n
e
m
e
g
a
n
a
m
n
o
i
t
a
t
u
p
e
R

L
F

d
e
n
i
a
g
-
e
n
ﬁ

e
r
a
w
a
-
n
o
i
t
a
t
u
p
e
r

d
e
s
a
b

n
i
a
h
c
k
c
o
l
b

a

d
e
n
g
i
s
e
D

s
k
c
a
t
t
a

e
c
n
e
r
e
f
n
i

p
i
h
s
r
e
b
m
e
m
d
n
a

g
n
i
n
o
s
i
o
p

d
e
t
n
e
v
e
r
P

c
i
r
t
e
m
a

s
a

d
e
c
u
d
o
r
t
n
i

s
i

n
o
i
t
a
t
u
p
e
r

f
o

t
p
e
c
n
o
c

e
h
T

s
l
a
t
i
p
s
o
h

n
i

a
t
a
d

e
v
e
i
r
t
e
r

o
t

n
i
a
h
c
k
c
o
l
b

d
e
g
a
r
e
v
e
L

s
r
e
t
e
m
a
r
a
p

g
n
i
n
i
a
r
t

s
l
e
d
o
m
g
n
i
n
r
a
e
l

e
n
i
h
c
a
m
e
r
a
h
s

d
n
a

r
e
f
s
n
a
r
t

,
e
r
o
t
s

o
t

n
i
a
h
c
k
c
o
l
b

d
e
s
U

V
o
I

n
i

n
o
i
t
a
m
r
o
f
n
i

e
r
a
h
s

o
t

L
F
C
B

l
a
c
i
h
c
r
a
r
e
i
H

C
B

n
o

d
e
s
a
b
m
s
i
n
a
h
c
e
m
e
v
i
t
n
e
c
n
i

n
e
v
i
r
d
-
e
u
l
a
v

a

s
e
d
i
v
o
r
p

n
i
a
h
C
p
e
e
D

k
c
o
l
B
-
L
F

n
o

d
e
s
a
b

g
n
i
t
u
p
m
o
c

g
o
f

n
i

e
r
u
l
i
a
f

t
n
i
o
p

e
l
g
n
i
s

d
e
t
n
e
v
e
r
P

s
r
e
n
i
a
r
t

g
n
o
m
a

e
v
i
t
n
e
c
n
i

d
n
a

t
s
u
r
t

e
t
u
b
i
r
t
s
i
d

o
t

n
i
a
h
C
L
F

d
e
s
o
p
o
r
P

6

r
i
e
h
t

g
n
i
y
f
i
r
e
v

e
l
i
h
w
s
e
t
a
d
p
u

l
e
d
o
m

l
a
c
o
l

s
’
e
c
i
v
e
d

g
n
i
g
n
a
h
c
x
e

s
e
l
b
a
n
e

k
r
o
w
t
e
n

n
i
a
h
c
k
c
o
l
b

e
h
T

t
n
a
v
e
l
e
r

d
n
a

y
h
t
r
o
w
t
s
u
r
t

s
i

k
r
o
w
t
e
n

e
h
t

n
i

s
l
e
d
o
m
n
i
a
r
t

o
t

d
e
s
u

a
t
a
d

e
h
t

d
e
r
u
s
n
E

g
n
i
t
u
p
m
o
c

e
g
d
e

n
i

L
F

r
o
f

m
e
t
s
y
s

d
e
n
i
a
h
c
k
c
o
l
b

d
i
r
b
y
h

e
h
t

d
e
g
a
r
e
v
e
L

k
r
o
w

.
e
r
u
t
a
r
e
t
i
l

t
a
h
t

n
i

d
e
n
o
i
t
n
e
m
y
l
r
a
e
l
c

t
o
n

s
i

n
o
i
t
a
m
r
o
f
n
i

t
n
a
v
e
l
e
r

e
h
t

t
a
h
t

s
n
a
e
m

/

o
N

o
N

o
N

o
N

o
N

o
N

o
N

o
N

o
N

o
N

o
N

o
N

s
e
Y

o
N

o
N

s
e
Y

s
e
Y

s
e
Y

s
e
Y

o
N

o
N

o
N

s
e
Y

o
N

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

s
e
Y

o
N

s
e
Y

n
o
i
t
u
b
i
r
t
n
o
C

r
o
t
a
g
e
r
g
g
a

l
a
r
t
n
e
C

s
u
s
n
e
s
n
o
C

l
o
c
o
t
o
r
p

s
e
p
y
t

n
i
a
h
c
k
c
o
l
B

Q
o
P

d
e
n
o
i
s
s
i

m
r
e
P

L
F
-
G
A
D

C
o
P

/

M
C
C

d
e
n
o
i
s
s
i

m
r
e
P

d
e
n
o
i
s
s
i

m
r
e
P

c
i
l
b
u
P

c
i
l
b
u
P

A
o
P

d
e
n
o
i
s
s
i

m
r
e
p

/
c
i
l
b
u
P

-
e
s
i
w
k
c
o
l
b

K
o
P

/

/

/

A
B

/

W
o
P

W
o
P

W
o
P

/

W
o
P

S
o
P
D

/

S
o
P
W
o
P

W
o
P

S
o
P
D

W
o
P

c
i
l
b
u
P

c
i
l
b
u
P

/

c
i
l
b
u
P

c
i
l
b
u
p

c
i
l
b
u
P

/

/

d
e
n
o
i
s
s
i

m
r
e
P

c
i
l
b
u
P

/

d
e
n
o
i
s
s
i

m
r
e
P

d
e
n
o
i
s
s
i

m
r
e
P

c
i
l
b
u
P

d
e
n
o
i
s
s
i

m
r
e
P

/

Q
o
P
S
o
P

/

d
e
n
o
i
s
s
i

m
r
e
P

/

c
i
l
b
u
p

/
d
e
n
o
i
s
s
i

m
r
e
P

g
n
i
n
r
a
e
L

s
e
c
i
v
e
d

e
c
i
v
e
D

e
c
i
v
e
D

/

/

/

/

/

e
g
d
E

/

e
c
i
v
e
D

e
c
i
v
e
D

e
g
d
E

e
c
i
v
e
D

e
c
i
v
e
D

e
g
d
E

/

/

e
c
i
v
e
D

e
g
d
E

e
c
i
v
e
D

e
c
i
v
e
D

/

/

/

c
i
l
b
u
P

e
c
i
v
e
D

C
o
P

S
o
P
D

W
o
P

S
o
P

W
o
P

/

/

/

/

/

/

I

C
o
P

W
o
P

T
F
B
P

d
e
n
o
i
s
s
i

m
r
e
p

/
c
i
l
b
u
P

d
e
n
o
i
s
s
i

m
r
e
P

d
e
n
o
i
s
s
i

m
r
e
P

/

/

d
e
n
o
i
s
s
i

m
r
e
P

d
e
n
o
i
s
s
i

m
r
e
P

d
e
n
o
i
s
s
i

m
r
e
P

c
i
l
b
u
P

c
i
l
b
u
P

/

/

e
g
d
E

e
g
d
E

e
g
d
E

/

e
g
d
E

e
c
i
v
e
D

e
g
d
E

e
g
d
E

e
g
d
E

e
g
d
E

e
g
d
E

/

I

E
L
B
A
T

L
F

D
E
N

I

A
H
C
K
C
O
L
B

O
T

D
E
T
A
L
E
R

E
R
U
T
A
R
E
T
I
L

E
H
T

F
O

E
L
B
A
T

n
i
a
h
c
k
c
o
l
B

.
f
e
R

n
i
a
h
C

i
t
l
u
M

m
u
e
r
e
h
t
E

/

/

]
0
5
[

]
1
5
[

]
2
5
[

]
3
5
[

/

]
4
5
[

m
u
e
r
e
h
t
E

m
u
e
r
e
h
t
E

/

/

/

/

/

/

m
u
e
r
e
h
t
E

m
u
e
r
e
h
t
E

m
u
e
r
e
h
t
E

/

/

m
u
e
r
e
h
t
E

/

/

/

m
u
e
r
e
h
t
e
/
c
i
r
b
a
f

r
e
g
d
e
l
r
e
p
y
H

]
9
[

]
5
5
[

]
0
1
[

]
6
5
[

]
7
5
[

]
8
5
[

]
9
5
[

]
0
6
[

]
1
6
[

]
2
6
[

]
3
6
[

]
4
6
[

]
5
6
[

]
6
6
[

]
7
6
[

]
8
6
[

]
9
6
[

]
0
7
[

m
u
e
r
e
h
t
E

/

/

/

]
3
7
[

]
4
7
[

]
5
7
[

]
6
7
[

m
u
e
r
e
h
t
E

]
7
7
[

m
u
e
r
e
h
t
E

m
u
e
r
e
h
t
E

m
u
e
r
e
h
t
E

/

/

/

/

]
1
1
[

]
8
7
[

]
9
7
[

]
0
8
[

]
1
8
[

]
2
8
[

]
3
8
[

S
O
E

]
2
7
[

/

]
1
7
[

d
e
l
p
u
o
c

y
l
l
u
F

d
e
l
p
u
o
c

y
l
b
i
x
e
l

F

d
e
l
p
u
o
c

y
l
e
s
o
o
L

c
i
l
b
u
P

e
c
i
v
e
D

m
u
e
r
e
h
t
E

]
4
8
[

training process, the system can preserve the data privacy in
a secure manner.

The FL platform with blockchain is designed in [55],
assuming all the participates can work rationally under the
competition incentive mechanism. This platform can deal with
any kind of raw data such as texts, audio, and images, etc.
Before local model updates are uploaded, several workers will
be selected to go through the security procedure under the
smart contract to choose the valid data.

BAFELE is a blockchained FL framework which is central
aggregator free and thus decentralized [9]. By delineating the
FL mechanism into various rounds and collecting the local
model updates and then updating the global model, BAFELE
can achieve the same model training result performance as the
conventional FL model. Meanwhile, it costs less computational
resources.

From the above discussions, we can conclude the following

merits and demerits of FuC-BCFL framework.

Merits of FuC-BCFL:
• The single-point-failure can be avoided effectively as the
framework is decentralized and every node has an copy
of the distributed ledger.

• No data are required to transfer to any central server,
avoiding the data privacy leakage and reducing commu-
nication cost.

Demerits of FuC-BCFL:
• More computational resources are required due to the
operations of both blockchain and FL are running on the
same network. Clients not only perform local training,
but also integrate the global model.

• The communication bandwidth of blockchain network
is limited, so the latency of communication could be a
challenge to FuC-BCFL.

2) Flexibly Coupled BCFL: We proposed the ﬂexi-
bly coupled blockchain-based FL model (FlC-BCFL) when
blockchain and FL system are in distinct networks. It means
that the clients of FL are not the nodes of blockchain (miners).
The topology of the ﬂexibly coupled BCFL is shown in Figure
4. From the topology we can see that clients are responsible
for local data collecting and training, while the local model
updates veriﬁcation will be done by miners on blockchain. FL
can also manipulate blockchain to store the model updates,
and the miners on blockchain can also aggregate the global
model, making the central aggregator free in that system.

• Clients collect local data and train the local models, and

then upload the local model updates to blockchain.

• Miners on blockchain perform veriﬁcation mechanism
and only the validated updates can be used to update
the global model.

• After the global model is aggregated, all the data will be

stored on distributed ledger.

• Rewards are allocated to participates according to their

performances.

In [67], a reliable and self-motivated FlC-BCFL system is
illustrated, which designs a smart contract to publish task and
calculate the global model. Nodes train models locally, while
miners aggregate the global model on the blockchain. Miners

7

Fig. 4. Topology of ﬂexibly coupled BCFL.

update the global model according to the algorithm deﬁned in
smart contract.

In [68], blockchain is used to aggregate the global model
and the FL process is executing locally to get the local model
updates. All the base stations as miners on blockchain and
execute the global model aggregation process, while the work
in [65] leverages one Macro Base Station to integrate the
global model.

Kim et al [10] proposed BlockFL to exchange and verify lo-
cal model updates on blockchain. BlockFL focus on removing
the central aggregator of FL model, making it decentralized.
Miners associated with clients are randomly selected, and local
model updates are cross veriﬁed among miners. In that paper,
the latency of communication on BlockFL is analyzed.

Reference [85] adopts a similar framework with BlockFL
which combines autonomous vehicles and miners. The uni-
form random vehicle-miner association scheme is proposed in
that framework, ensuring all the participates can be trusted.
To prevent privacy leakage on internet of things devices,
the model in [71] is composed by manufactures, customers
and blockchain. Manufactures establish the learning task and
gain the ﬁnal global model, and customers provide their
computational powers to train local models, meanwhile, the
blockchain verify and store the model updates.

We summarise the merits and demerits of ﬂexibly coupled

BCFL as below.

Merits of ﬂexibly coupled BCFL:
• FL and blockchain running on different networks and
devices, reducing communication pressure and latency.
• The raw data remains on the clients, reducing the risk
of data leakage caused by malicious attacks on the
blockchain network.

• Blockchain can provide data sharing for FL, which is

more efﬁcient than conventionally FL.

Demerits of ﬂexibly coupled BCFL
• Blockchain and FL belong to two different systems, so it

is hard to coordinate the management of them.

• Single-point-failure still occurs when the central aggre-

gator remains.

3) Loosely Coupled BCFL: In [86] and [78], reputation as
a crucial criteria is introduced to measure the reliability and
trustworthiness of the participates in blockchained FL system.
Blockchain in loosely coupled BCFL framework (LoC-BCFL)
is used to verify model updates and manage the reputation of
participates, and only the reputation related data can remain on
distributed ledger. Veriﬁcation of the updates and reputation
management are a part of incentive mechanisms to ensure the
participates can behave honestly. We describe the framework
of loosely coupled BCFL as show in Figure 3-3. The workﬂow
of loosely coupled BCFL is as follows:

Fig. 5. Topology of loosely coupled BCFL.

• Clients train models locally and upload the local model

updates to blockchain.

• Miners verify the local model updates,

then generate

reputation opinions for the clients.

• Miners compete to generate new block which contains
the reputation related data, and the new block will be
added into the distributed ledger.

• Aggregator collects the veriﬁed updates and then execute

the global model aggregation algorithm.

• Rewards and penalties are depended on the reputation

opinions of clients.

In [86], reputation and contract theory are combined to
support the incentive mechanism for FL. The reputation is
calculated by the task publisher according to their historical
reputation records in that system. The reputation opinions are
stored on reputation blockchain after the selected workers
ﬁnish their proof work. Then the selected workers can can start
FL process, after training the model locally, workers upload
the local model updates to task publisher for veriﬁcation and

8

global aggregation. In that system, reputation is manipulated to
choose qualiﬁed devices as the workers to conduct federating
learning.

Reference [78], a reputation-aware ﬁne-gained FL system is
proposed to establish a trustworthy computational environment
for mobile edges. Reputation of each participate is calculated
by public blockchain and smart contracts. The details of other
related literature can be fond on Table 3-1.

Merits of loosely coupled BCFL:
• Blockchain and FL are completely independent, and FL
retains its data better on its members than the previous
two architectures.

• The reputation management mechanism enables better
management of participants, ensures the quality of data
submitted during model training, and improves the accu-
racy of the model; it also prevents malicious participants
from attacking the system.
Demerits of loosely BCFL:
• Blockchain is rarely involved in the FL process and only
responsible for veriﬁcation and reputation management,
thus the FL model is not decentralized, the risks suck as
privacy data leakage and single-point-failure still exist.
• Maintaining blockchain and FL independently, resulting

in inefﬁcient utilization of resources.

4) Summerized Lessons: We classify the blockchain based
FL frameworks into three categories as mentioned above.
We exploit their topology, workﬂow, merits and demerits. To
better understand the characteristics of different structures of
BCFL, we summarise the lessons we learned from the above
discussions.

• We can design different BCFL structures according to
speciﬁc demands. If the system needs to be aggregator
free, then the fully coupled BCFL framework is recom-
mended. The ﬂexibly coupled BCFL is suggested when
the FL network is not appropriate to run on blockchain
network while needs blockchain to assist its learning pro-
cess for higher model accuracy or data sharing. We can
also manipulate blockchain to do reputation management
to restrain the behaviors of participates, in this situation,
the loosely coupled BCFL will be a good choice.

• Despite the fact

that we can classify them and they
can exhibit different properties,
is currently rather
challenging to indicate which structure of the BCFL is
the safest and most reliable. We argue that the safety and
reliability of BCFL should be evaluated in the perspective
of speciﬁc computing needs and environments.

it

• Resource constraint and communication latency are im-
pediments to the efﬁcient operation of BCFL and must
be addressed regardless of the architecture.

B. Blockchain Types in BCFL

In this subsection, we will analyze two kinds of blockchain
used to assist FL system: public blockchain and permissioned
blockchain. We are going to introduce their properties, related
works, merits and demerits, respectively. To summarize this
subsection, some learned lessons are provided as well.

1) Public Chain: Public blockchain is widely used in
blockchain-based FL system since it’s decentralized and trans-
parent. Nodes on public blockchain can be any devices which
are willing and have enough powers to take part in the learning
process without further certiﬁcation.

Reference [67] proposes a FL system named BC-FL which
runs on a public blockchain network. Training nodes and
miners can engage in the system without permission and work
together to train a global model. Miners on that network
take Proof of Work (PoW) as their veriﬁcation consensus to
generate new block. The BlockFL model advocated in [87]
manipulates public blockchain to verify model updates, the
miners are any devices which can provide with sufﬁcient
computational powers. Miners compete to complete the PoW,
and then the newly generated block will be added to distributed
ledger. To attract more vehicles and base stations to provide
data and computational resources, the FL system runs on a
public blockchain network [57]. Proof of knowledge (PoK), a
lightweight consensus which combines machine learning with
blockchain consensus to avoid complicated computation, is
illustrated in that system. In the above models, lowering the
barrier to engagement enables more computational resources
and more data, however,
invalid data and
malicious nodes due to less discussion towards misbehaviour
detection.

there are still

To tackle the security issues of public blockchain used
for FL, researchers manipulated protocol designs to prevent
misbehaviour from malicious workers to ensure the quality
of the learned model. BlockFlow in [52] is a FL system
aided by a public blockchain, however,
in order to avoid
the malicious clients, the system requires every participate to
evaluate each other. Subsequently, a scoring procedure which
maintained in smart contract conduct is implemented to reﬂect
the training performance of the clients. By doing these, clients
are encouraged to provide high-quality training behaviours
to that system. The model in [55] indicates a generic full-
ﬂedged protocol to improve the reliability of FL system via
permissionless blockchain. Workers are not likely to sabotage
the learning process due to the competitive model update
methodology is designed.

Following are the merits and demerits of public blockchain

in BCFL.

Merits of public blockchain in BCFL:
• More data resources and computational powers can be
attracted to collaboratively train a common model , thus
large scale FL task can be realized.

• Public blockchain is totally decentralized and transparent,
thus the learning process is traceable and auditable.

Demerits of public blockchain in BCFL:
• Opening to all devices can lead to difﬁcult to hinder the

law-quality data and malicious behaviours.

• Public blockchain in BCFL generally requires complex
consensus, e.g. PoW and PoS, to validate model updates
and to create new blocks, causing a signiﬁcant consump-
tion of computing resources.

2) Permissioned Chain: In contrast to public blockchain,
permissioned blockchain is only available to authorised clients.

9

In the BCFL system, before the devices are registered in the
FL, they will be selected based on their computational re-
sources, participation willingness, and historical performances.
The current research about permissioned blockchain used in
BCFL is mainly focus on node selection, i.e, which node can
be a part of that chain to continue the learning process. The
devices that are intended to be included are usually evaluated
before the blockchain starts to operate. In addition, the devices
stay or leave at the end of the training depending on their
performance. In [54], alliance chain is leveraged to enable
i.e, nodes management, gradients validation and
authority,
block generation. Committee Consensus Mechanism (CCM)
is designed to validate gradients. The committee is composed
by a few honest nodes, and they are responsible for charging
the veriﬁcation process. CCM requires less computational
resources than PoW, meanwhile can perform as a secure
and reliable consensus mechanism. Reference [59] introduces
FLChain to settle a reliable and auditable FL ecosystem.
Trainers registered on the blockchain are the entities who
are willing to get involved into the training process. Before
local model training, miners will be selected according to their
reliability and motivation. Malicious trainer’s misbehavior will
be detected and punished by the authority in FLChain. In
[50], FL and permissioned blockchain are integrated. End IoT
devices, i.e, base stations and road side unites, are called super
nodes on that chain. The local model is trained by committee
parties, which are those related registered devices can meet the
request of data sharing. Meanwhile, permissioned blockchain
remains the data sharing records for audit.

The following is about

the merits and demerits of the

permissioned blockchain as applied to BCFL systems.
Merits of permissioned blockchain in BCFL:
• The permissioned blockchain offers a platform for a
light-weight consensus protocol, which reduces resource
consumption while keeping the system secure.

• The exposure of the system to malicious attacks is
reduced by excluding unauthorised devices from the
training of the model.

• The performances of authorised nodes can be constrained
to guarantee the accuracy of the model, due to the evalu-
ation scheme that usually exists within the permissioned
blockchain.

Demerits of permissioned blockchain in BCFL:
• Less attractive to devices and computing resources than

public blockchain.

• Reduced applicability of the system due to threshold of

access by users.

3) Summerized Lessons: When designing a BCFL system,
it is necessary to decide which type of blockchain to use. By
using the different blockchains, the system’s different model
training needs can be realised. With the above discussion we
will conclude with some lessons about blockchain types.

• We argue that the types of blockchain intrinsically de-
termine the number as well as the quality of the BCFL
system’s users. Due to the fact that in some computing
environments more computing resources and more par-
ticipants are required, the task of establishing FL on the

public chain can be chosen. However, if the training of a
model for FL needs to be implemented on a small scale,
the permissioned blockchain can be chosen

• The public blockchain and the commissioned blockchain
can be used in conjunction with each other, and in [9],
[70], [82], they assist in the training of the model by pro-
viding a distinct role for the BCFL system respectively.

C. Learning Devices in BCFL

In this part we will explore the devices in BCFL system,
i.e. on which devices FL will run. We argue that, based
on the current literature, BCFL can be used for either end
devices, such as mobile phones and smart cars, which can
sense external data, or edge nodes [88], such as base stations,
routers and other devices with high computing powers. In the
following content, we will discuss the deployment of BCFL
on end devices and edge nodes respectively.

1) End Devices: Mobile devices such as mobile phones and
automated vehicles generally have computing capabilities, so
in order to improve computing efﬁciency, on-device machine
learning is used. On device machine learning requires more
data than single device’s local data, and the data sharing in
devices is necessary [1], [15]. FL as a technique for distributed
learning is designed to address the above mentioned issues.
The end devices gather external data and train it locally when
they are involved in FL. Raw data is not transferred to the
sever, but only the local model updates to the aggregator. When
blockchain is used in the above situation, it usually serves
to provide decentralization function or as distributed ledgers
for FL. This not only guarantees the data privacy of the end
devices, but also improves the security of the entire system.

For now, end devices are looking for convenience and
intelligence, so it is inevitable that some storage capacity
and computing capability is constrained. Current research
focuses on the issues that exist when BCFL is used on on
devices, for such things as communication delays, security
leakage, and computing resource allocation. In [48], [62], on-
device blockchained FL model is proposed. This paper focuses
on data exchanges and veriﬁcation, and arguers that end-to-
end latency is an obstacle of BCFL, and that adjusting the
blockchain generation rate could be helpful. However, com-
puting capabilities limitation of end device is not mentioned.
The model in [64] considers the above issues and designs a
deep reinforcement learning methodology to help the machine
learning model owner to make the optimal decisions to reduce
transmission delay and arrangement the energy consumption.
Reference [50] leverages blockchain to prevent privacy leakage
to secure the data sharing process of the distributed devices.
Numerical results shows that the proposed data sharing scheme
performs accurately and effectively.

The merits and demerits of applying BCFL on end devices

are listed as below.

Merits of on-device based BCFL:
• Raw data is not required to be transferred to any other
devices, reducing the resources consumed by data trans-
mission, while data security is ensured.

• The usage of end devices is widespread, thus attracting
more users and generating more data for model training.

10

Demerits of on-device based BCFL:
• End devices have limited computing, storage and commu-
nication capacity to undertake complex local computing.
• An end device is not only responsible for local data
collection, model training and data storage, but also for
providing the resources to keep the blockchain network
running, which may result in the device being unable to
do other tasks properly.

2) Edge Nodes:

In [89]–[91], FL technology is used to
support edge computing. In conventional edge computing
scheme, raw data is sent to nearby edge node, which can
be considered as the central sever where raw data will be
proceed. Despite FL can avoid the transmission of raw data
by training the raw data locally and uploading the model
updates to the edge node or central server, the risks of FL
itself such as single-point-failure and privacy leakage still
remain. By leveraging blockchain to support the FL based
edge computing, the whole system can be more secure and
reliable. In the system which combines edge computing, FL
and blockchain, all the end devices collect the raw data and
then sent them to the nearby edge nodes for model training;
blockchain provides data veriﬁcation and data sharing for edge
nodes; and the veriﬁed model updates will be transmitted to
central server for global model aggregation.

Reference [77] introduces a system named CREAT, which
adopts blockchain to help the edge computing to catch content
during the FL process. IoT devices transfer collected data to
blockchain, and each edge node downloads the data and then
computes the gradients independently. The original purpose
of applying FL model to edge computing is to ensure edge
nodes can collaboratively learn the features of users and ﬁles
the catch hit rate can be promoted by predicting
so that
popular ﬁles. Blockchain is incorporated to secure the data
transmission and sharing. In [82], edge nodes equipped with
computational powers and storage can receive the data from
end devices, and train the deep learning model collaboratively.
Public blockchain and permissioned blockchain provide the
collaboratively and auction mechanism to the FL system,
respectively.

Here are the merits and demerits of learning devices of

BCFL.

Merits of edge nodes based BCFL:
• Edge nodes based BCFL is able to provide sufﬁcient

storage capacity and computational resources.

• Edge computing can be more secure and reliable, and it’s

application is wider.

Demerits of edge nodes based BCFL:
• Raw data needs to be transferred, which reduces security
and increases the consumption of the resources required
for transmission.

3) Summerized Lessons:

• The distribution of edge nodes is not as widespread as
end devices, which may limit the application of BCFL.
In this section we explore the
scenario when BCFL is deployed on end devices and edge
nodes respectively. Besides inconsistent workﬂows, different
devices can affect the overall performance of the system. We
will conclude this subsection in the following.

• The overall difference between the ways in which end
devices and edge nodes are involved in a BCFL system
is that the former keeps raw data local, while the latter
needs to collect raw data from multiple devices.

some of

• From the blockchain level,

the models’
blockchains are maintained via edge nodes, while others
are maintained via end devices. The blockchain, as a
technology that assists FL to be secure and communica-
tionally enhanced, can have participants, i.e. nodes, that
are not devices directly involved in the training process
of FL. This is noticed in Section III-A.

IV. FUNCTIONS OF BCFL

In this section, we investigate the speciﬁc functions of
BCFL with the perspective regarding its workﬂow, including
veriﬁcation of model updates, aggregation of global model,
utilization of the distributed ledger, and incentive mechanism.

A. Veriﬁcation of Model Updates

To train a well performed global model, FL needs to ensure
that all the devices engaged in the model training process work
honestly and provide reliable data. This problem is not well
tackled in traditional FL models. To address this issue, we
can take advantage of blockchain to verify the submitted data,
excluding the dishonest and unreliable data.

1) Veriﬁcation Protocol: In each round, the local devices
transmit the trained local model updates to the miners for
further validation (no data transfer is required in FuC-BCFL
framework). Therefore, a suitable validation mechanism needs
to be designed to verify the validity of the data and reduce the
time and resources consumed.

Current research places signiﬁcant emphasis on veriﬁcation
mechanisms. The work in [86] proposes a Proof of Verifying
(PoV) consensus to ensure the uploaded local model updates
are valid before the global model aggregation. The main idea
of PoV is to prepare the testing dataset in advance and set a
threshold for accuracy. According to PoV, the testing dataset
which is reliable and provided by the task publisher will be
prepared on the blockchain, and then the miners utilize this
dataset to verify the uploaded updates. The qualiﬁed updates
are selected based on a given accuracy threshold and put
into blocks as transactions. The threshold can be determined
empirically, but the selection of testing dataset is a challenge
because it is hard to use the previous data for valuation once
a new learning environment is situated.

The veriﬁcation process in [54] is similar to the PoV men-
tioned above, and the miners in a committee are responsible
for verifying the updates and scoring them, while the details
of how to score the updates are not mentioned.

Reference [77] designs smart contracts to verify the trans-
actions storing the local model updates. The whole process
requires the randomly selected consortium members to vote
whether the updates are reliable or not, and the decision is
based on the number of received votes. Although randomly
selected members are required to participate in the voting, it
is hard to show that this avoids the inﬂuence of subjectivity,
so more evidence is needed to support this methodology.

11

[73] designs a two-stage veriﬁcation scheme, which ma-
nipulates cumulatively calculated reputations based on the
accuracy of the updates and nodes on the blockchain to
evaluate the quality of the transactions.

Although the importance of validation mechanisms is men-
tioned in some studies, no speciﬁc descriptions of the work-
ﬂows are provided [10], [85].
2) Summerized Lessons:
• The veriﬁcation mechanism can be designed in various
forms, but it is more common to ﬁlter the updates before
conducting model aggregation to avoid unreliable data
from affecting the global model. Of course, it is also
possible to manage the updates through the feedback after
model aggregation.

• By validating the updates, the veriﬁcation mechanism
can not only ﬁlter out the unreliable data, but also the
data providers can be constrained to behave. In addition,
the results of veriﬁcation can also be used for the later
guidance of rewards allocation.

• Based on our research, although researchers realized the
importance of the veriﬁcation of model updates before
aggregating them, studies about the design of effective
validation mechanisms are lacking.

B. Aggregation of Global Model

The basic idea of FL is to distribute model training tasks to
numerous local devices and then to integrate the local models
through a central aggregator. Therefore, model integration is a
crucial component of the FL process. In the following section,
we will explore how can we utilize blockchain technology to
assist the aggregation of global model for FL. Based on our
investigation of current research, our analysis will focus on the
members who are engaged in model integration in the BCFL
framework. In Section 3.A, we discussed the architectures of
BCFL, and we found that in some BCFL models, the central
aggregator are still remained since the blockchain and FL are
coupled in different ways [63], [65]. In the following content,
we are not going to discuss this kind of situation because
we are rather interested in knowing how decentralized model
integration is enabled via the application of blockchain.

1) Selected Blockchain Nodes:

In some models, after
the local model updates are veriﬁed by the nodes on the
blockchain, only the selected nodes participate in global model
integration. Those selected nodes are usually well equipped
with enough computational resources or have good historical
performance records.

In [54], the authors propose a committee consensus mecha-
nism to verify the local model updates and then aggregate the
global model. They argue that the election of the committee
is crucial to performance of the global model, and they also
introduce three kinds of committee election methodologies,
including random election, sorting by score, multi-factor op-
timization. The experimental results show that
the model
under this mechanism can obtain similar performance as the
conventional FL model.

In [50], the committee nodes are responsible for model
training and aggregation, which are selected according to their

registration records. This kind of election of committee lacks
the evaluation of data provider’s reliability, leaving the quality
of raw data uncertain.

By selecting some nodes to participate in the model in-
tegration, on the one hand, it can avoid the existence of a
central node and achieve decentralization; on the other hand,
the selected nodes are usually more reliable, and the overall
resource consumption can be reduced by implementing them
to complete the model aggregation.

2) All Blockchain Nodes: When all the data providers or
miners are independently involved in the aggregation of the
model, such a framework is decentralized and avoids any
authority center completely. This is the most commonly used
framework for applying blockchain to FL.

Fully decentralized global model aggregation is usually
done by miners or data providers on the blockchain, i.e., local
devices. In ﬂexibly coupled BCFL models, miners and data
providers are not the same, and each miner aggregates the
global model via aggregation algorithms after ﬁnishing the
veriﬁcation of local data updates [62], [67]. While in the fully
coupled BCFL framework, the local devices are usually the
miners, so they not only collect the data and then train the
local models, they also verify the updates and calculate the
global model [53], [55].

By replacing the central aggregator with the blockchain,
the task of model integration is delegated to nodes on the
blockchain, which can be miners or data providers, depending
on the different coupling framework. In that case, the BCFL
can be completely decentralized that every node can participate
in model aggregation, avoiding single-point-failure effectively.

3) Summerized Lessons:
• Blockchain allows FL to modify the process of model
aggregation, leaving central aggregator unnecessary.

• No matter the global model

is computed by partial
nodes or all nodes, the integration of the model can be
effectively decentralized.

C. Utilization of the Distributed Ledger

In the conventional FL model introduced by Google [92],
the raw data are kept on the local devices while the local
model updates shall upload to the central aggregator. With
the help of blockchain technology, FL can work effectively
without the central aggregator. When the miners ﬁnish the
veriﬁcation work, the new block will be generated and added
to a blockchain where the validated local model updates and
the aggregated global model are stored [10]. In this process,
blockchain works as the distributed ledger, which stores the
model updates and provides an accessible platform for all the
qualiﬁed participates to retrieval the data. In this subsection,
we will discuss the two aspects of blockchain as the distributed
ledger in the BCFL model: data storage and data sharing.

1) Data Storage: In conventional FL, local model updates
are generally transferred to the central aggregator and then
stored, requiring more transferring cost and storage capacity.
By incorporating blockchain for assisting FL, the data storage
issue in the training process can be effectively ameliorated. To
some extent, blockchain is a distributed ledger that can provide

12

a secure, traceable, and immutable way to store data. All the
training related data, including the local model updates, global
model updates and reputation of the participates, are treated
as the transactions of blockchain and needed to be veriﬁed by
the miners. First only the validated data can be recorded in the
newly generated block, and then the block will be added to
a blockchain. By this design, the data in distributed ledger is
traceable and immutable, which means once the transaction is
added to the blockchain, it is nearly impossible for any device
to change the records.

Current research is less concerned about the concrete struc-
ture of the blockchain in BCFL. The work in [74] describes
details of the structure of the blocks in the blockchain used
for FL. A block consists of a block header, which contains
information such as model ID, data ID, timestamp and data
types, and a block body, which holds model updates.

In [54],

the recommended system chooses the alliance
blockchain to store the data, allowing only the authorized par-
ticipates to access to the ledger. The blocks on that blockchain
are varied, and they are two kinds of them: one is used to store
the global model for each round and is called model block; and
the other one is named update block, which is implemented to
store the local model updates and other learning information
such as address of devices and update scores.

2) Data Sharing: In Google’s conventional FL model, only
the central aggregator can get the updates from the devices
[16], [92], while in blockchained FL model, all the qualiﬁed
participates can access to the blockchain to retrieval and share
the data to support model training. Blockchain provides a data
sharing platform for FL to train a machine learning model with
better generalization capability. What’s more, the data shared
during the training process are the local model updates and
other related data(i.e, reputation, IP address, timestamp and
so on.) rather than the raw data [67], [78], [93]. In this case,
the data privacy can be well protected and the efﬁciency of
model training can be improved.

Some research focus on designing the scheme of data
sharing based on blockchained FL [50], [73]. For example,
reference [50] builds a permissioned blockchain-based FL
environment to share the data among distributed industrial
IoT devices. In permissioned blockchain network, there are
two kinds of transactions should be proceed:data retrieval
and data sharing. The local devices communicate through
the blockchain, which can ensure the security of data trans-
mission. The super nodes on the permissioned blockchain,
i.e., routers, base stations, and other facilities with strong
computing powers, keep the records of the local devices of the
IoT after being encrypted. In addition, in order to improve the
efﬁciency of data retrieval and model training, local devices
with the same data type are grouped in a community. In each
committee, the ID information of each participant is public. By
this design, the data can be shared in an efﬁcient and secure
way. The authors argue that the encryption methodology for
data sharing can’t avoid data leakage,
thus they design a
request and reply protocol between the data requester and the
permissioned blockchain. After the requester sends a request
the blockchain members will ﬁrst check
for data sharing,
whether there are already records that match the request, and

return the result directly if there are; if not, they will train the
model through the relevant committee nodes and ﬁnally return
the result. In this model, blockchain provides the platform to
store data and retrieve it securely. However, since this data
sharing framework involves storing the model for retrieval in
advance and keeping the data of local devices through super
nodes, further research is needed to investigate whether it can
effectively prevent external attacks.

3) Summerized Lessons:
• From the perspective of learning process, blockchain
provides distributed data storage and public data sharing
for FL. Instead of storing the data generated during the
learning process in the central aggregator, federal learning
only needs to store this data through the blockchain,
which can make the relevant data freely available to all
authenticated participants.

• From the perspective of data security, the blockchain it-
self can be seen as a distributed ledger with characteristics
such as immutability, auditability and decentralization.
Blockchain can record all necessary data and also prevent
malicious nodes from altering it. And only authenticated
participants can access the data related to FL, preventing
the privacy leakage.

D. Incentive Mechanism

This subsection will discuss how the incentive mechanism
in BCFL ensure that participants work honestly according to
the protocol, ensuring the ﬁnal trained global model reliable.
1) Incentive Mechanism Design: FL offers a distributed
computing solution for machine learning. However,
tradi-
tional federation learning models cannot guarantee that all
participating clients are reliable. Blockchain can address this
issue by distributing the corresponding rewards to nodes that
have contributed in the generation of blocks based on their
contributions. In this way, by incorporating a blockchain into
the FL model and rewarding the participants (local devices
and miners) according to a certain scheme, participants can
be motivated to provide reliable training data. In addition,
the incentive mechanism can also penalize dishonest nodes,
ﬁltering out the malicious participates.

Incentive mechanisms have been emphasized in the existing
studies. The work in [58] designs a payment-based incentive
mechanism to encourage participates to collaboratively train a
deep learning model. Two properties of that incentive mech-
anism are introduced, i.e, compatibility and liveness. Com-
patibility assumes that all the participates can get maximum
rewards based on their contributions, and liveness means that
all the participates have the willingness to update both the
local model and global model. After the ﬁnal global model is
updated, the rewards will distribute to local devices and miners
according to their contributions.

In [55], repeated competition is implemented to motivate
the workers to obey the rules of the protocol in order to
obtain the maximum proﬁts. The basic idea is to introduce
a mechanism for workers to compete for the opportunity
to update models at each training round and to constrain
their subsequent performance through a voting scheme. The

13

distribution of the returns will be determined by sorting the
records of the votes.

Reference [70] argues that monetary is most popular incen-
tive for participates in BCFL, and illustrates a penalty scheme
which requires each participate to deposit a certain amount
of cryptocurrency on the blockchain. When the global model
is well trained, the deposits will return to the participates,
and additional rewards are distributed to encourage honest
behavior. The rewards are determined by the average time
participants take to submit data, with faster submissions being
awarded more. On the contrary, if one participate is found
being dishonest, then it’s deposits will lost.

In other studies, there are distributions of returns based on
calculating the contribution of participants in model training
[54], [76], and participant management based on reputation
[71], [78], [79]. These studies provide ideas for future re-
search.

2) Summerized Lessons:
• Incorporating an incentive mechanism into the FL model
to give participants certain rewards can effectively reg-
ulate and discipline their behaviors and can encourage
participants to provide reliable training data.

• Current research lacks in-depth study on how to allocate
rewards. On the one hand, a decentralized evaluation
system needs to be designed; on the other hand, some
defects of the blockchain itself should be taken into
account when designing incentive mechanism.

V. APPLICATIONS OF BCFL

FL and blockchain are already being applied in many
ﬁelds. Instead of exploring the real-life applications of both
separately, this subsection will investigate the applications of
BCFL, a joint technology. According to the current research,
BCFL has been initially applied in the ﬁelds of Internet of
Things, smart city, ﬁnancial payment, and healthcare, etc.
Even though these research are all based on speciﬁc usage
environments to apply BCFL, there is no general framework
for it yet.

A. BCFL for IoT

In IoT area, devices are decentralized, so model training
on them requires timely and secure data and strong model
generalization capability. FL in the Internet of Things(IoT)
can collaboratively train a global model by numerous devices,
avoiding the leakage of private raw data for each device
[31], [94]. However FL itself has several deﬁciencies (e.g.
single-point-failure and lack of incentives), and blockchain
technology can make the training of models for IoT devices
more secure.

Research on the applications of BCFL in the IoT domain
focuses on data security, resource planning, communication,
and failure detection, all with the aim of enabling IoT devices
to jointly train a model with good performance.

The work in [73] introduces a BCFL model to protect the
privacy in Internet of Vehicles (IoV), and in [68], communi-
cation efﬁciency and resource limitation in IoT devices based
on the BCFL framework are investigated. In industrial IoT

14

(IIoT), the data heterogeneity in failure detection challenges
the reliability of the whole system. In [76], a blockchain-based
FL model is proposed for failure detection in IIoT. First, a FL
model is deployed among IoT devices and a central server
is set up for model integration; then, data from local devices
is stored via blockchain, which also provides incentives. In
the aspect of failure detection, a new aggregation algorithm
is designed to reduce the impact of data heterogeneity by
considering the distance between positive and negative classes
in each dataset.

B. BCFL for Healthcare

In healthcare area, data of patients are sensitive thus both
patients and hospitals are reluctant to share their heal data.
FL can help train the model distributively, while the data
leakage is the biggest challenge [30], [95]. Blockchain can be
implemented among patients or hospitals, allowing participates
to share data without privacy disclosure.

Passerat-Palmbach et al. [63] point out that the protection
of patient privacy constrains researchers from analyzing health
data, and the existing tools are insufﬁcient to address the issue,
so they suggest to use both blockchain and FL for healthcare
integration,
consortia. In their model, data access, model
weight encryption, and auditing of the learning process are
emphasized. However, this study is speciﬁc to consortia and
is not appropriate for most health problems and lacks concrete
solutions which can be operated.

In contrast to [63], Kumar et al. [80] offer an speciﬁc
solution for COVID-19 detection via BCFL models. Hospitals
train the local model based on their own private data and
share only the weights and gradients, and blockchain records
the learning process and related data. Researchers highlights
the privacy of patients, and BCFL framework can protect
the privacy when the global model is training. That paper
builds a secure and decentralized data sharing platform among
hospitals, enabling the automatic detection of COVID-19 in a
secure manner.

The research used BCFL in healthcare are rare now, but
the research direction is promising since a large amount of
medical data have to be proceed and BCFL can offer secure
learning environments.

In addition, BCFL can be applied in the areas of ﬁnancial
investment, for example, the processing of ﬁnancial big data.
Data from customers of ﬁnancial companies is sensitive,
customers do not want to disclose their data to the concern of
privacy, and companies are obliged to keep their customers’
conﬁdential. Therefore, companies can deploy BCFL to obtain
data and train models to develop more accurate market-
oriented ﬁnancial products, while protecting customer privacy.

D. BCFL for Smart City

The construction of a smart city requires a large amount
of data, and by training these data and getting reasonable
models, it can provide better services to citizens. Similar to
many machine learning situations, privacy and security have
been constraints to the development of smart cities.

BCFL can provide a secure big data training architecture,
while offering rewards based on user contributions to motivate
users to provide more data. Imagine this scenario, when gov-
ernment departments need to optimize urban trafﬁc and need
multiple devices and users to provide data and collaboratively
train models. Traditional machine learning frameworks cannot
guarantee privacy and provide incentives at the same time.
However, with BCFL, the requirements can be met.

The major advantage of BCFL for smart cities is not only
that it can protect privacy and deliver incentives, but also that
it can allow more devices to join, adapting to the large number
of devices and users in a smart city.

VI. CHALLENGES AND FUTURE RESEARCH DIRECTIONS

While BCFL has many advantages, some challenges that
may hinder the operations of the BCFL model cannot be
ignored. In this section, we will analyze the current research
deﬁciencies of BCFL, and then we also suggest some potential
future research topics. We argue that a good BCFL model
should have high security, high training efﬁciency and low
computational cost. The design of BCFL is a trade-off between
these three aspects, and our following analysis will be carried
out from them.

C. BCFL for Business and Finance

Blockchain ﬁrst emerged as the basis for Bitcoin, and the
explosion of various blockchain-based virtual currencies in re-
cent years in particular has elevated the status of blockchain as
an underlying technology in ﬁnance and business. Meanwhile,
FL can offer a distributed machine learning framework. There-
fore, BCFL can provide secure and decentralized applications
for the ﬁnancial and business ﬁelds.

The most direct application of BCFL in the ﬁnance and
business ﬁeld is to provide a monetary payment method.
FedCoin, introduced in [11], provides a peer-to-peer payment
system based blockchain for FL. FedCoin is different
to
Bitcoin, which depends on PoW,
it utilizes the proof of
Sharpley (PoSap) to generate new blocks. Such a payment
system can be applied to a commercial system based on FL.

A. Privacy and Security

Security and privacy are of importance to the BCFL model,
and although both blockchain and FL have privacy-preserving
properties,
issues that may lead to privacy
leakage.

there are still

1) Anonymity:

In the conventional FL model, only the
central center knows the sources of the local model updates.
However, the addresses of clients are public in BCFL, and
other clients obtain the training behaviors based on the public
information from blockchain. What’s more, clients generally
do not communicate with each other addresses are private
information. While in BCFL, since identity information such
as public addresses, clients may be able to communicate with
each other, increasing the risk of collusion among clients.

2) Shared Data: Blockchain stores the blocks which con-
tain the model updates through a chained structure, and all
members within the blockchain can access the data from the
public distributed ledger as well as download the data. In
BCFL, clients can get information about other members from
blockchain. In BCFL using public blockchain, since there is no
access restriction, information of members may be available
to external devices,
threatening the security of the whole
system. Data sharing can improve the speed of model training
and facilitate clients to perform model updates, but the risks
associated with data security cannot be ignored.

3) Malicious Attack:

In the decentralized BCFL model,
there is no authority center to regulate the behaviors of
participates, therefore the risks of being attacked by potential
the attacks
malicious participates exist. On the one hand,
may come from blockchain system, such as forking, double
spending, and selﬁsh mining, etc. Forking is one of most
common attacks launched by attackers, which tries to obtain
more proﬁts by replacing the most trusted chain (i.e., longest
chain) with an alternative chain. Double spending occurs when
a currency is spent twice. Selﬁsh mining attack, also named
block withholding attack, happens when an entity validates
one block but does not broadcast it to the network. On the
other hand, attacks from FL system will hinder the deployment
of BCFL, including data poisoning, inference attacks, etc.
Malicious users can launch data poisoning attack by utilizing
dirty data to train the local models, and then upload the biased
leading the parameters of
local models to the aggregator,
global model inaccurate. Even though the uploaded parameters
are encrypted, malicious users can still deduce the really
information by analyzing them, so inference attacks may cause
the leakage of privacy in FL system.

Since malicious attacks deteriorate the reliability of BCFL,
future research can focus on the combination of the two
technologies to reduce the risk of being attacked. For example,
reasonable mechanisms can be designed to use blockchain for
the selection of users and data.

B. Training Efﬁciency

The goal of FL is to train a global model through the
collaborative work of multiple devices, not only the accuracy
of the global model, but also the time and computational cost
consumed by training, should be taken into account.

1) Reliability of Data: Since we cannot guarantee that all
participants are honest, it is unreasonable to assume that all
data are reliable. We cannot ignore the impact of unreliable
data on the global model. At least three measures are consid-
ered to improve the reliability of data:

• Perform clients selection before training to exclude po-
tentially dishonest nodes. The impact of the types of
blockchain needs to be considered in the selection of
clients. When BCFL uses public blockchain, any device
can join the training without permission. In this case, the
selection scheme can be designed to decide whether allow
those devices to continue to participate in the training
based on the performance of the clients in the previous
round. It requires to evaluate the device performance

15

in single or multiple rounds. In fact, many veriﬁcation
mechanisms have adopted this approach. As for the
permissionsed blockchain, since potential devices need to
obtain permissions to join the training, malicious attacks
and invalid data can be reduced to some extent.

• Design efﬁcient veriﬁcation mechanisms to speed up the
processing so as to reduce the time consumption, and
improve the accuracy of veriﬁcation to ensure that only
qualiﬁed data can participate in model integration. The
current research lacks a detailed study of the process
of the veriﬁcation mechanism. Devices involved in the
veriﬁcation mechanism need to be considered. No matter
data are veriﬁed among clients or through miners on the
blockchain, privacy needs to be prevented from being
leaked. Different veriﬁcation mechanisms can affect the
security of the model.

• A reasonable incentive mechanism should be designed
to encourage participants to provide truthful data, and
penalizing those who are dishonest. Most of the current
research focuses on how to distribute rewards, and we
believe that innovation can be made from the perspective
of punishment. In the blockchain ecosystem, behavior
of clients can be constrained by depositing a portion
of virtual currency (e.g., bitcoin and ethereum) before
training.

2) Communication Latency: Communication latency oc-
curs in both FL and blockchain networks, which are also
a constraint to the development of these two technologies.
Latency analysis has been given enough attention in BCFL,
and a number of studies have already proposed solutions, for
example, Kim et al. [10]]suggests reducing the computational
difﬁculty of PoW to lower latency.

3) Asynchrony: During the training process, the time of
participates entering and exiting affects the effectiveness of
the training. The time to join training can be speciﬁed by
designing a participant selection mechanism, however, several
factors can cause participants to drop out of training early, such
as network issues, damaged devices, limited storage space,
etc. The above-mentioned problem affects the distribution of
rewards apart from the correctness of the global model.

C. Training Cost

1) Storage: In the conventional federation learning model,
local model updates are stored on the aggregator, while in
BCFL, data are stored through the blockchain. Meanwhile,
every clients can also keep a copy of the blockchain locally
and update it continuously, increasing the storage cost. For
devices with insufﬁcient storage capacity, they may not be
able to continue to participate in training as the data stored
in the blockchain grows. In addition to the storage of data, it
will be a research direction how the clients and miners can
efﬁciently retrieve data on blockchain.

2) Computing Consumption: FL usually requires multiple
rounds of iterations to get the ﬁnal global model, so the cost
of model training is usually related to the number of training
iterations. The trade-off between model accuracy and cost
has been a topic for researchers. Compared with traditional

FL models, BCFL requires not only local model training,
model aggregation and updating, but also data validation and
block generation. These activities consume a large amount
of computational resources and increase the cost of training
models.

In FlC-BCFL model, miners and clients are different de-
vices, and the cost calculation needs to be based on different
roles. For miners, a signiﬁcant amount of computations will
be used to run consensus protocols, i.e., mining, which is an
arithmetic-intensive process, so light-weight consensus proto-
cols can be designed to reduce the computational difﬁculty. In
addition, the overall cost can be lower by reducing the cost of
data veriﬁcation. For clients, reducing the number of training
sessions while ensuring the training quality can reduce the
cost.

The training cost of the model is not only related to the
accuracy of the global model, but also affects the security
of the whole BCFL model. For example, if the difﬁculty of
generating blocks is reduced or the process of veriﬁcation is
simpliﬁed, although the computational cost can be reduced, it
may lead to security problems. In addition, from the overall
perspective of BCFL, the blockchain and FL need to operate
in a coordinated manner, and how to allocate resources will
also affect the computational cost. Therefore, computational
cost is a topic that needs to be addressed gradually in future
research.

VII. CONCLUSION

In this paper, a detailed investigation of blockchained FL
(BCFL) is provided. We ﬁrst introduce blockchain and FL
respectively. Then we investigate the foundations of BCFL,
including the architecture of BCFL, the blockchain on BCFL,
and the devices on BCFL. We also analyze four functions
of BCFL,
i.e., veriﬁcation of model updates, aggregation
of global model, utilization of the distributed ledger, and
incentive mechanism. After that, we survey the applications of
BCFL in real life. Finally, we discuss the existing challenges
of BCFL and give the corresponding future research directions.
Blockchain and FL are both emerging technologies, and
their combination can efﬁciently address the security and
privacy issues of distributed machine learning. This paper is
the ﬁrst detailed survey on BCFL, and we believe that BCFL
will be used more often in the future. We hope our work will
bring new ideas for future BCFL research.

REFERENCES

[1] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. Communication-efﬁcient
learning of deep
networks from decentralized data. In Artiﬁcial Intelligence and Statistics,
pages 1273–1282. PMLR, 2017.

[2] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba,
Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Koneˇcn´y, Ste-
fano Mazzocchi, H. Brendan McMahan, Timon Van Overveldt, David
Petrou, Daniel Ramage, and Jason Roselander. Towards Federated
Learning at Scale: System Design. 2019.

[3] Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy,
Franc¸oise Beaufays, Sean Augenstein, Hubert Eichner, Chlo´e Kiddon,
and Daniel Ramage. Federated learning for mobile keyboard prediction.
arXiv, 2018.

16

[4] Felix Sattler, Simon Wiedemann, Klaus Robert Muller, and Wojciech
Samek. Robust and Communication-Efﬁcient Federated Learning from
Non-i.i.d. Data. IEEE Transactions on Neural Networks and Learning
Systems, 31(9):3400–3413, 2020.

[5] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and
Vitaly Shmatikov. How to backdoor federated learning. arXiv, 108,
2018.

[6] Umesh Bodkhe, Sudeep Tanwar, Karan Parekh, Pimal Khanpara, Sud-
hanshu Tyagi, Neeraj Kumar, and Mamoun Alazab. Blockchain for
industry 4.0: A comprehensive review. IEEE Access, 8:79764–79800,
2020.

[7] Julie Frizzo-Barker, Peter A Chow-White, Philippa R Adams, Jennifer
Mentanko, Dung Ha, and Sandy Green. Blockchain as a disruptive
technology for business: A systematic review. International Journal of
Information Management, 51:102029, 2020.

[8] Mehrdokht Pournader, Yangyan Shi, Stefan Seuring, and SC Lenny
Koh. Blockchain applications in supply chains, transport and logistics: a
systematic review of the literature. International Journal of Production
Research, 58(7):2063–2081, 2020.

[9] Paritosh Ramanan and Kiyoshi Nakayama. BAFFLE : Blockchain Based

Aggregator Free Federated Learning. 2019.

[10] You Jun Kim and Choong Seon Hong. Blockchain-based node-aware
dynamic weighting methods for improving federated learning perfor-
mance. In 2019 20th Asia-Paciﬁc Network Operations and Management
Symposium (APNOMS), pages 1–4. IEEE, 2019.

[11] Yuan Liu, Shuai Sun, Zhengpeng Ai, Shuangfeng Zhang, Zelei Liu,
and Han Yu. FedCoin: A Peer-to-Peer Payment System for Federated
Learning. 2020.

[12] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and
Vikas Chandra. Federated learning with non-iid data. arXiv, 2018.
[13] Kai Yang, Tao Jiang, Yuanming Shi, and Zhi Ding. Federated learning
via over-the-air computation. IEEE Transactions on Wireless Commu-
nications, 19(3):2022–2035, 2020.

[14] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur´elien Bellet,
Mehdi Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles,
Graham Cormode, Rachel Cummings, Rafael G. L. D’Oliveira, Salim El
Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adri`a Gasc´on,
Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui,
Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu,
Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Koneˇcn´y,
Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancr`ede
Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer
¨Ozg¨ur, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage,
Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng
Sun, Ananda Theertha Suresh, Florian Tram`er, Praneeth Vepakomma,
Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu,
and Sen Zhao. Advances and Open Problems in Federated Learning.
pages 1–105, 2019.

[15] Jakub Koneˇcn`y, H Brendan McMahan, Daniel Ramage, and Peter
Richt´arik. Federated optimization: Distributed machine learning for on-
device intelligence. arXiv preprint arXiv:1610.02527, 2016.

[16] Jakub Koneˇcn´y, H. Brendan McMahan, Felix X. Yu, Peter Richt´arik,
Ananda Theertha Suresh, and Dave Bacon. Federated Learning: Strate-
gies for Improving Communication Efﬁciency. pages 1–10, 2016.
[17] Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair

Resource Allocation in Federated Learning. pages 1–20, 2019.

[18] Takayuki Nishio and Ryo Yonetani. Client Selection for Federated
Learning with Heterogeneous Resources in Mobile Edge. IEEE Inter-
national Conference on Communications, 2019-May, 2019.

[19] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated
machine learning: Concept and applications. ACM Transactions on
Intelligent Systems and Technology, 10(2):1–19, 2019.

[20] Viraaji Mothukuri, Reza M. Parizi, Seyedamin Pouriyeh, Yan Huang,
Ali Dehghantanha, and Gautam Srivastava. A survey on security and
privacy of federated learning. Future Generation Computer Systems,
115(October):619–640, 2021.

[21] Robin C. Geyer, Tassilo Klein, and Moin Nabi. Differentially Private
Federated Learning: A Client Level Perspective. (Nips):1–7, 2017.
[22] Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa
Sylla, Yoonyoung Park, Grace Hsu, and Amar Das. Differential privacy-
enabled federated learning for sensitive health data. arXiv, (NeurIPS):1–
6, 2019.

[23] Stacey Truex, Thomas Steinke, Nathalie Baracaldo, Heiko Ludwig,
Yi Zhou, Ali Anwar, and Rui Zhang. A hybrid approach to privacy-
preserving federated learning. Proceedings of the ACM Conference on
Computer and Communications Security, pages 1–11, 2019.

17

[24] Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jad-
babaie, and Ramtin Pedarsani. FedPAQ: A Communication-Efﬁcient
Federated Learning Method with Periodic Averaging and Quantization.
(2), 2019.

[47] Marko Vukoli´c. The quest for scalable blockchain fabric: Proof-of-
work vs. bft replication. In International workshop on open problems
in network security, pages 112–125. Springer, 2015.

[48] PRACTICAL IMPLEMENTATION OF BLOCKCHAIN ENABLED

[25] Mingzhe Chen, H. Vincent Poor, Walid Saad, and Shuguang Cui.
Convergence Time Minimization of Federated Learning over Wireless
Networks. IEEE International Conference on Communications, 2020-
June:1–30, 2020.

[26] Solmaz Niknam, Harpreet S. Dhillon, and Jeffrey H. Reed. Federated
Learning for Wireless Communications: Motivation, Opportunities, and
Challenges. IEEE Communications Magazine, 58(6):46–51, 2020.
[27] Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin. A review of applications in
federated learning. Computers & Industrial Engineering, page 106854,
2020.

[28] Jie Xu and Fei Wang. Federated learning for healthcare informatics.

arXiv preprint arXiv:1911.06270, 2019.

[29] Theodora S Brisimi, Ruidi Chen, Theofanie Mela, Alex Olshevsky,
Ioannis Ch Paschalidis, and Wei Shi. Federated learning of predictive
models from federated electronic health records. International journal
of medical informatics, 112:59–67, 2018.

[30] Yiqiang Chen, Xin Qin, Jindong Wang, Chaohui Yu, and Wen Gao. Fed-
health: A federated transfer learning framework for wearable healthcare.
IEEE Intelligent Systems, 2020.

[31] Zhaoyang Du, Celimuge Wu, Tsutomu Yoshinaga, Kok Lim Alvin Yau,
Yusheng Ji, and Jie Li. Federated Learning for Vehicular Internet of
Things: Recent Advances and Open Issues. IEEE Computer Graphics
and Applications, 1(April):45–61, 2020.

[32] Latif U Khan, Walid Saad, Zhu Han, Ekram Hossain, and Choong Seon
Hong.
Federated learning for internet of things: Recent advances,
taxonomy, and open challenges. arXiv preprint arXiv:2009.13012, 2020.
[33] Basheer Qolomany, Kashif Ahmad, Ala Al-Fuqaha, and Junaid Qadir.
Particle swarm optimized federated learning for industrial iot and smart
city services. arXiv preprint arXiv:2009.02560, 2020.

[34] Ji Chu Jiang, Burak Kantarci, Sema Oktug, and Tolga Soyata. Federated
learning in smart city sensing: Challenges and opportunities. Sensors,
20(21):6230, 2020.

[35] Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system.

Technical report, Manubot, 2019.

[36] Gavin Wood et al.

Ethereum: A secure decentralised generalised
transaction ledger. Ethereum project yellow paper, 151(2014):1–32,
2014.

[37] Cornelius C Agbo, Qusay H Mahmoud, and J Mikael Eklund.
Blockchain technology in healthcare: a systematic review. In Healthcare,
volume 7, page 56. Multidisciplinary Digital Publishing Institute, 2019.
[38] Sudeep Tanwar, Karan Parekh, and Richard Evans. Blockchain-based
electronic healthcare record system for healthcare 4.0 applications.
Journal of Information Security and Applications, 50:102407, 2020.

[39] Junfeng Xie, Helen Tang, Tao Huang, F. Richard Yu, Renchao Xie, Jiang
Liu, and Yunjie Liu. A Survey of Blockchain Technology Applied to
Smart Cities: Research Issues and Challenges. IEEE Communications
Surveys and Tutorials, 21(3):2794–2830, 2019.

[40] Gagangeet Singh Aujla, Maninderpal Singh, Arnab Bose, Neeraj Kumar,
Guangjie Han, and Rajkumar Buyya. Blocksdn: Blockchain-as-a-service
IEEE
for software deﬁned networking in smart city applications.
Network, 34(2):83–91, 2020.

[41] Qin Wang, Xinqi Zhu, Yiyang Ni, Li Gu, and Hongbo Zhu. Blockchain
for the iot and industrial iot: A review. Internet of Things, 10:100081,
2020.

[42] Iuon Chang Lin and Tzu Chun Liao. A survey of blockchain security
International Journal of Network Security,

issues and challenges.
19(5):653–659, 2017.

[43] M. Niranjanamurthy, B. N. Nithya, and S. Jagannatha. Analysis of
Blockchain technology: pros, cons and SWOT. Cluster Computing,
22(2):14743–14757, 2019.

[44] Ruzhi Xu, Lu Zhang, Huawei Zhao, and Yun Peng. Design of
network media’s digital rights management scheme based on blockchain
technology. In 2017 IEEE 13th International Symposium on Autonomous
Decentralized System (ISADS), pages 128–133. IEEE, 2017.

[45] Fei Richard Yu, Jianmin Liu, Ying He, Pengbo Si, and Yanhua Zhang.
IEEE Access,

Virtualization for distributed ledger technology (vdlt).
6:25019–25028, 2018.

[46] Yong Yuan and Fei-Yue Wang. Towards blockchain-based intelligent
In 2016 IEEE 19th International Conference
transportation systems.
on Intelligent Transportation Systems (ITSC), pages 2663–2668. IEEE,
2016.

FEDERATED LEARNING.pdf.

[49] Fahad Saleh. Blockchain without waste: Proof-of-stake. The Review of

Financial Studies, 2018.

[50] Yunlong Lu, Xiaohong Huang, Yueyue Dai, Sabita Maharjan, and Yan
Zhang. Blockchain and Federated Learning for Privacy-Preserved Data
Sharing in Industrial IoT. IEEE Transactions on Industrial Informatics,
16(6):4177–4186, 2020.

[51] Mingrui Cao, Long Zhang, and Bin Cao. Towards on-device federated
arXiv

learning: A direct acyclic graph-based blockchain approach.
preprint arXiv:2104.13092, 2021.

[52] Vaikkunth Mugunthan, Ravi Rahman, and Lalana Kagal. BlockFLow:
An Accountable and Privacy-Preserving Solution for Federated Learn-
ing. 2020.

[53] Davy Preuveneers, Vera Rimmer, Ilias Tsingenopoulos, Jan Spooren,
Wouter Joosen, and Elisabeth Ilie-Zudor. Chained anomaly detection
models for federated learning: An intrusion detection case study. Applied
Sciences (Switzerland), 8(12):1–21, 2018.

[54] Yuzheng Li, Chuan Chen, Nan Liu, Huawei Huang, Zibin Zheng, and
Qiang Yan. A Blockchain-based Decentralized Federated Learning
Framework with Committee Consensus. pages 1–7, 2020.

[55] Kentaroh Toyoda and Allan N. Zhang. Mechanism Design for An
Incentive-aware Blockchain-enabled Federated Learning Platform. Pro-
ceedings - 2019 IEEE International Conference on Big Data, Big Data
2019, pages 395–403, 2019.

[56] Gaofeng Hua, Li Zhu, Jinsong Wu, Chunzi Shen, Linyan Zhou, and
Qingqing Lin. Blockchain-Based Federated Learning for Intelligent
Control in Heavy Haul Railway. IEEE Access, 8:176830–176839, 2020.
[57] Haoye Chai, Supeng Leng, Yijin Chen, and Ke Zhang. A Hierarchi-
cal Blockchain-Enabled Federated Learning Algorithm for Knowledge
IEEE Transactions on Intelligent
Sharing in Internet of Vehicles.
Transportation Systems, pages 1–12, 2020.

[58] Jiasi Weng, Jian Weng, Jilian Zhang, Ming Li, Yue Zhang, and Weiqi
Luo. Deepchain: Auditable and privacy-preserving deep learning with
IEEE Transactions on Dependable and
blockchain-based incentive.
Secure Computing, 2019.

[59] Xianglin Bao, Cheng Su, Yan Xiong, Wenchao Huang, and Yifei Hu.
FLChain: A Blockchain for Auditable Federated Learning with Trust
and Incentive. Proceedings - 5th International Conference on Big Data
Computing and Communications, BIGCOM 2019, pages 151–159, 2019.
[60] Youyang Qu, Longxiang Gao, Tom H. Luan, Yong Xiang, Shui Yu, Bai
Li, and Gavin Zheng. Decentralized privacy using blockchain-enabled
federated learning in fog computing. IEEE Internet of Things Journal,
7(6):5171–5183, 2020.

[61] Umer Majeed and Choong Seon Hong. FLchain: Federated Learning
via MEC-enabled Blockchain Network. 2019 20th Asia-Paciﬁc Network
Operations and Management Symposium: Management
in a Cyber-
Physical World, APNOMS 2019, pages 1–4, 2019.

[62] Jiasi Weng, Jian Weng, Jilian Zhang, Ming Li, Yue Zhang, and Weiqi
Luo. DeepChain: Auditable and Privacy-Preserving Deep Learning with
IEEE Transactions on Dependable and
Blockchain-based Incentive.
Secure Computing, 14(8):1–1, 2019.

[63] Jonathan Passerat-Palmbach, Tyler Farnan, Robert Miller, Marielle S
Gross, Heather Leigh Flannery, and Bill Gleim.
A blockchain-
orchestrated federated learning architecture for healthcare consortia.
arXiv preprint arXiv:1910.12603, 2019.

[64] Nguyen Quang Hieu, Tran The Anh, Nguyen Cong Luong, Dusit Niyato,
Dong In Kim, and Erik Elmroth. Resource Management for Blockchain-
enabled Federated Learning: A Deep Reinforcement Learning Approach.
2020.

[65] Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan
Zhang. Low-latency Federated Learning and Blockchain for Edge As-
sociation in Digital Twin empowered 6G Networks. IEEE Transactions
on Industrial Informatics, 3203(c):1–1, 2020.

[66] Ziyuan Li, Jian Liu, Jialu Hao, Huimei Wang, and Ming Xian.
CrowdSFL: A secure crowd computing framework based on blockchain
and federated learning. Electronics (Switzerland), 9(5), 2020.

[67] Chuan Ma, Jun Li, Ming Ding, Long Shi, Taotao Wang, Zhu Han, and
H. Vincent Poor. When Federated Learning Meets Blockchain: A New
Distributed Learning Paradigm. pages 1–8, 2020.

[68] Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan
Zhang. Communication-efﬁcient Federated Learning and Permissioned
Blockchain for Digital Twin Edge Networks. IEEE Internet of Things
Journal, 4662(c):1–1, 2020.

18

learning in resource constrained edge computing systems. IEEE Journal
on Selected Areas in Communications, 37(6):1205–1221, 2019.
[90] Xiaofei Wang, Yiwen Han, Chenyang Wang, Qiyang Zhao, Xu Chen,
In-edge ai: Intelligentizing mobile edge computing,
IEEE Network,

and Min Chen.
caching and communication by federated learning.
33(5):156–165, 2019.

[91] Yongfeng Qian, Long Hu, Jing Chen, Xin Guan, Mohammad Mehedi
Hassan, and Abdulhameed Alelaiwi. Privacy-aware service placement
for mobile edge computing via federated learning. Information Sciences,
505:562–570, 2019.

[92] Jakub Koneˇcn´y, H. Brendan McMahan, Daniel Ramage, and Peter
Richt´arik. Federated Optimization: Distributed Machine Learning for
On-Device Intelligence. pages 1–38, 2016.

[93] Sana Awan, Fengjun Li, Bo Luo, and Mei Liu. Poster: A reliable and
accountable privacy-preserving federated learning framework using the
blockchain. Proceedings of the ACM Conference on Computer and
Communications Security, pages 2561–2563, 2019.

[94] Latif U. Khan, Walid Saad, Zhu Han, Ekram Hossain, and Choong Seon
Hong. Federated Learning for Internet of Things: Recent Advances,
Taxonomy, and Open Challenges. pages 1–30, 2020.

[95] Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa
Sylla, Yoonyoung Park, Grace Hsu, and Amar Das. Differential privacy-
arXiv preprint
enabled federated learning for sensitive health data.
arXiv:1910.02578, 2019.

Zhilin Wang received his B.S.
in Management
from Nanchang University in 2020. He is currently
pursuing his Ph.D. degree of Computer and Infor-
mation Science In Indiana University-Purdue Uni-
versity Indianapolis (IUPUI). His research interests
include blockchain, federated learning, and Internet
of Things (IoT).

Qin Hu received her Ph.D. degree in Computer
Science from the George Washington University
in 2019. She is currently an Assistant Professor
with the Department of Computer and Informa-
tion Science, Indiana University-Purdue University
research interests in-
Indianapolis (IUPUI). Her
clude wireless and mobile security, edge computing,
blockchain, and crowdsourcing/crowdsensing.

[69] Shiva Raj Pokhrel and Jinho Choi. Federated Learning with Blockchain
IEEE

for Autonomous Vehicles: Analysis and Design Challenges.
Transactions on Communications, 68(8):4734–4746, 2020.

[70] Harsh Bimal Desai, Mustafa Safa Ozdayi, and Murat Kantarcioglu.
BlockFLA: Accountable Federated Learning via Hybrid Blockchain
Architecture, volume 1. Association for Computing Machinery, 2020.

[71] Yang Zhao, Jun Zhao, Linshan Jiang, Rui Tan, Dusit Niyato, Zengxiang
Li, Lingjuan Lyu, and Yingbo Liu. Privacy-Preserving Blockchain-Based
Federated Learning for IoT Devices. IEEE Internet of Things Journal,
pages 1–1, 2020.

[72] Ismael Martinez, Sreya Francis, and Abdelhakim Senhaji Haﬁd. Record
and reward federated learning contributions with blockchain. Proceed-
ings - 2019 International Conference on Cyber-Enabled Distributed
Computing and Knowledge Discovery, CyberC 2019, pages 50–57, 2019.
[73] Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan
Zhang. Blockchain Empowered Asynchronous Federated Learning for
IEEE Transactions on
Secure Data Sharing in Internet of Vehicles.
Vehicular Technology, 69(4):4298–4311, 2020.

[74] Pradip Kumar Sharma, Jong Hyuk Park, and Kyungeun Cho. Blockchain
and federated learning-based distributed computing defence frame-
Sustainable Cities and Society,
work for
59(March):102220, 2020.

sustainable society.

[75] Meng Shen, Huan Wang, Bin Zhang, Liehuang Zhu, Ke Xu, Qi Li, and
Xiaojiang Du. Exploiting Unintended Property Leakage in Blockchain-
IEEE
Assisted Federated Learning for Intelligent Edge Computing.
Internet of Things Journal, 4662(c):1–1, 2020.

[76] Weishan Zhang, Qinghua Lu, Qiuyu Yu, Zhaotong Li, Yue Liu, Sin Kit
Lo, Shiping Chen, Xiwei Xu, and Liming Zhu. Blockchain-based
Federated Learning for Failure Detection in Industrial IoT. pages 1–
11, 2020.

[77] Laizhong Cui, Xiaoxin Su, Zhongxing Ming, Ziteng Chen, Shu Yang,
Yipeng Zhou, and Wei Xiao. CREAT: Blockchain-assisted Compression
Algorithm of Federated Learning for Content Caching in Edge Comput-
ing. IEEE Internet of Things Journal, 4662(c):1–1, 2020.

[78] Muhammad Habib Ur Rehman, Khaled Salah, Ernesto Damiani, and
Davor Svetinovic. Towards blockchain-based reputation-aware federated
learning. IEEE INFOCOM 2020 - IEEE Conference on Computer Com-
munications Workshops, INFOCOM WKSHPS 2020, (February):183–
188, 2020.

[79] Jiawen Kang, Zehui Xiong, Dusit Niyato, Shengli Xie, and Junshan
Incentive mechanism for reliable federated learning: A joint
theory.

Zhang.
optimization approach to combining reputation and contract
IEEE Internet of Things Journal, 6(6):10700–10714, 2019.

[80] Rajesh Kumar, Abdullah Aman Khan, Sinmin Zhang, WenYong Wang,
Yousif Abuidris, Waqas Amin, and Jay Kumar. Blockchain-Federated-
Learning and Deep Learning Models for COVID-19 detection using CT
Imaging. 14(8):1–12, 2020.

[81] Jiawen Kang, Zehui Xiong, Dusit Niyato, Yuze Zou, Yang Zhang, and
Mohsen Guizani. Reliable Federated Learning for Mobile Networks.
IEEE Wireless Communications, 27(2):72–80, 2020.

[82] Sizheng Fan, Hongbo Zhang, Yuchen Zeng, and Wei Cai. Hybrid
blockchain-based resource trading system for federated learning in edge
computing. IEEE Internet of Things Journal, 2020.

[83] Ronald Doku and Danda B. Rawat. IFLBC: On the Edge Intelligence
Using Federated Learning Blockchain Network. Proceedings - 2020
IEEE 6th Intl Conference on Big Data Security on Cloud, BigDataSe-
curity 2020, 2020 IEEE Intl Conference on High Performance and Smart
Computing, HPSC 2020 and 2020 IEEE Intl Conference on Intelligent
Data and Security, IDS 2020, pages 221–226, 2020.

[84] Anudit Nagar. Privacy-Preserving Blockchain Based Federated Learning

with Differential Data Sharing. 2019.

[85] Shiva Raj Pokhrel and Jinho Choi. Federated Learning with Blockchain
IEEE

for Autonomous Vehicles: Analysis and Design Challenges.
Transactions on Communications, 68(8):4734–4746, 2020.

[86] Jiawen Kang, Zehui Xiong, Chunxiao Jiang, Yi Liu, Song Guo, Yang
Zhang, Dusit Niyato, Cyril Leung, and Chunyan Miao. Scalable and
Communication-efﬁcient Decentralized Federated Edge Learning with
Multi-blockchain Framework. 2, 2020.

[87] Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong Lyun Kim.
IEEE Communications

Blockchained on-device federated learning.
Letters, 24(6):1279–1283, 2020.

[88] Xiaofei Wang, Yiwen Han, Victor C.M. Leung, Dusit Niyato, Xueqiang
Yan, and Xu Chen. Convergence of Edge Computing and Deep
IEEE Communications Surveys
Learning: A Comprehensive Survey.
& Tutorials, pages 1–1, 2020.

[89] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung,
Christian Makaya, Ting He, and Kevin Chan. Adaptive federated

