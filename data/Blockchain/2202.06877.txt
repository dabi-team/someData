A Review of zk-SNARKs

Thomas Chen∗, Hui Lu†, Teeramet Kunpittaya‡, and Alan Luo§

2
2
0
2

y
a
M
6
1

]

R
C
.
s
c
[

3
v
7
7
8
6
0
.
2
0
2
2
:
v
i
X
r
a

Abstract

A zk-SNARK is a protocol that lets one party, the prover, prove to another party, the veriﬁer, that a
statement about some privately-held information is true without revealing the information itself. This
paper describes technical foundations, current applications, and some novel applications of zk-SNARKs.
Regarding technical foundations, we go over the Quadratic Arithmetic Program reduction and the
Pinocchio protocol. We then go over ﬁnancial security applications like Zcash and Tornado Cash, and
zk-Rollup applications like zkEVM and Darkforest. We propose novel zk-SNARK protocols for private
auctions and decentralized card games on the blockchain, providing code for the proposed applications.
We conclude by touching on promising zk-SNARK innovations, such as zk-STARKs.

1

Introduction

zk-SNARKs (Zero-Knowledge Succinct Non-interactive Arguments of Knowledge) have gained increasing
amounts of interest due to their uses in scaling blockchain throughput and providing secure ways to perform
transactions [1, 2, 3, 4]. The goals of this review are to provide a technical understanding of zk-SNARKs, to
describe their key current applications, and to propose zk-SNARK protocols for two novel applications.

First, we provide a history of the development of zk-SNARKs in section (1.1). In section (2), we give a
detailed dive into the technical workings of zk-SNARKs – in particular the Pinocchio protocol [5]. Sections
(3) and (4) are dedicated to ﬁnancial and rollup applications of zk-SNARKs respectively, two of the most
important current applications. In section (5), we propose novel (to our knowledge) circuits that use zk-
SNARKs in two applications: private auctions and decentralized card games. We also provide code for
these proposed applications in the appendix (8). Finally, in (6) we conclude the review by describing new
innovations on zk-SNARKs: zk-STARKs and recursive SNARKs.

As a motivating example, zk-SNARKs are useful for blockchain rollups where the prover wants to keep
the witness of their computation a secret. Suppose Alice runs some computation oﬀ-chain, and in her
computation, she obtains some secret witness, such as the details of a ZCash transaction, or the location of
a newly-generated planet in the zk-game, Dark Forest [4]. Alice would like the blockchain to commit the
state changes her computation made, without revealing her secret witness and without the chain rerunning
her entire computation on-chain. To this end, she would like a protocol where she, the prover, can convince
the chain, the veriﬁer, that a statement is true, but reveal nothing else. Such proof systems are called zero
knowledge.

The following is a concrete example of a zero knowledge proof system, for the graph 3-coloring problem
(G3COL). A prover P and veriﬁer V both know a graph G. P wants to convince V that she has a valid
3-coloring of G, without disclosing her coloring. The following protocol can be used [6]:

∗Columbia University, thomas.chen@columbia.edu
†Columbia University, abby.lu@columbia.edu
‡Columbia University, teeramet.kunpittaya@columbia.edu
§Columbia University, al3856@columbia.edu

1

 
 
 
 
 
 
1. P randomly permutes the colors of the vertices of G (e.g. all red vertices becomes blue, all blue become
green, and all green become red). Then, P commits the colors of all vertices using a commitment-scheme.

2. V randomly chooses an edge ei,j ∈ E and asks P for the colors of the two vertices, i and j.

3. P reveals the committed colors of i and j to V .

4. V repeats steps (1) – (3) n times and accepts if and only if each of his n queries were answered with

two distinct colors.

If P has a true 3-coloring of G, she will convince V with probability 1. In contrast, if P ’s coloring
contains at least one edge whose vertices are the same color, she will convince V with probability at most
p = (1 − 1/E)n. Thus, after a suﬃcient number of repetitions, n = O(E ln 1
δ ), V is conﬁdent that P has a
true graph coloring with probability 1 − δ.

The above is an interactive proof system, where two parties’ interactions enable them to recognize some
language, L. The proof system should be such that any statement x ∈ L has a proof causing V to accept it,
while any statement x /∈ L has no proof that causes V to accept it. The protocol should also not reveal x to
V –– only convince V that P has a member of L. These three key properties of zero-knowledge proof systems
are deﬁned below. Formal deﬁnitions can be found in the appendix (8).

1. Completeness: Every statement with a valid witness has a proof that convinces the veriﬁer.

2. Soundness: A statement with an invalid witness does not have a proof that convinces the veriﬁer.

3. Zero-knowledge: The proof only conveys information about the validity of the statement and nothing

about the prover’s witness.

1.1 History

Zero-Knowledge interactive proof protocols were the starting point of zk-SNARKs. Goldwasser, Mi-
cali, and Racknoﬀ [7] ﬁrst introduced sound, complete, and zero-knowledge interactive proof systems
for Quadratic − Residuosity and Quadratic − Nonresiduosity, two languages in not known to be eﬃciently
recognizable [7].

Subsequently, Blum, Feldman, and Micali developed non-interactive zero-knowledge (NIZK) proofs [8],
using shared randomness to create a common reference string (CRS). Unlike the protocol for G3COL, a non-
interactive protocol requires just one message to be sent from prover to veriﬁer, cutting out the back-and-forth
interaction. This feature is especially important in blockchain rollups, so that the prover does not need to be
around every time someone wants to verify their proof.

The next key innovation was in reducing the size of the proof sent. Kilian [9] gave an interactive protocol
for sublinear zero-knowledge arguments that sent fewer bits than the size of the statement to be proved.
Micali then created the ﬁrst sublinear-size NIZK proofs [10].

The next goal was to make proofs constant size. Groth, Ostrovsky, and Sahai [11, 12] introduced
pairing-based NIZK proofs. Using these ideas, Groth developed the ﬁrst constant-size NIZK arguments
system for Circuit − SAT, an NP-complete language [13]. Groth’s protocol used pairings to eﬃciently check
polynomial relationships between the discrete logs (the decoded versions) of the prover’s encoded messages,
without needing to know the decoded messages themselves. The proof is created so that checking a particular
polynomial relationship between elements of the proof is equivalent to verifying that prover has a satisfying
assignment for the circuit, a core idea in current zk-SNARKs.

2

Continuing on with the idea of verifying polynomial equations, Gennaro, Gentry, Parno, and Raykova
[14] introduced the now-popular Quadratic Span program (QSP) and Quadratic Arithmetic Program (QAP)
reductions, where an NP-statement is reduced to a statement about QSPs. Their method’s proof size, proof
generation complexity, and CRS setup complexity were much more eﬃcient than Groth’s constant-size NIZK
arguments system [14].

The Pinocchio protocol used QAP reductions to create a constant-size NIZK arguments protocol with
CRS and proof generation time linear in the circuit size. Moreover, veriﬁcation in Pinocchio is takes less
than 10 ms, a 5 − 7 order of magnitude improvement from previous work [5]. Pinocchio is protocol Zcash
ﬁrst used [15, 5]. Subsequently, the Groth-16 protocol [16] improved on Pinocchio’s proof size and veriﬁer
complexity, having just 3 group elements in its proof. It has since become the state-of-the-art, used in Zcash
and Circom [17].

The crucial improvements to make zero-knowledge proofs non-interactive and succinct made them practical
for blockchains. In contrast, the example graph 3-coloring proof system is interactive, and the proof size is
linear in E. We will now describe how a zk-SNARK achieves all these properties, for proving NP-statements
(statements in NP, e.g. that a graph is in G3COL) about a wide range of computations.

2

zk-SNARK Construction

2.1 Preliminaries

Deﬁnition 1. (Arithmetic Circuit) A directed acyclic graph, with nodes as addition and multiplication gates,
and edges as wires, over a ﬁnite ﬁeld Fp. Wires connect the outputs of one gate to the inputs of another.
Each gate has two inputs and one output wire, and the circuit has one ﬁnal output wire. Figure (1) is an
example of an arithmetic circuit.

Figure 1: Arithmetic circuit for f (s1, s2, s3) = (s1 · s2) · s3

For an m-gate, n-wire circuit, deﬁne a witness s = (s1, s2, ..., sn) to be the assignments to the n wires
of the circuit such that each gate’s inputs and outputs satisfy the constraint deﬁned by the gate operation.
An m-gate, n-wire arithmetic circuit deﬁnes a relation over witnesses s = (s1, s2, ..., sn) such that for some

3

constants {ui,q, vi,q, wi,q}1≤i≤n,1≤q≤m,

n
(cid:88)

i=1

siui,q ·

n
(cid:88)

i=1

sivi,q =

n
(cid:88)

i=1

siwi,q ∀1 ≤ q ≤ m

(1)

The constraints above are a set of m rank-1 constraints, which model the relationships a circuit’s
multiplication gates enforces over its input and output wires. An example of a particular rank-1 constraint is
s1 · s2 − s3 = 0, corresponding to a multiplication gate that takes as input s1, s2 and outputs s3. A set of m
rank-1 constraints can be generalized into a quadratic arithmetic program, which makes QAPs natural to
reduce arithmetic circuits to.
Deﬁnition 2. (Quadratic Arithmetic Program) Pick target points r1, r2, ...rm ∈ Fp. Deﬁne t(x) = (cid:81)m
rq). Further, let ui(x), vi(x), wi(x) be degree m − 1 polynomials such that for 1 ≤ i ≤ n, 1 ≤ q ≤ m

q=1(x −

ui(rq) = ui,q
vi(rq) = vi,q
wi(rq) = wi,q

Then, a Quadratic Arithmetic Program is a relation over s = (s1, s2, ..., sn) such that

n
(cid:88)

i=1

siui(x) ·

n
(cid:88)

i=1

sivi(x) −

n
(cid:88)

i=1

siwi(x) ≡ 0

(mod t(x))

(2)

(3)

(4)

(5)

Each target point corresponds to a gate in the circuit. For each target point rq, the QAP constructs
3n polynomials that when evaluated at rq, yield the 3n constants of the qth gate’s rank-1-constraint. The
QAP expresses the m rank-1 constraints as a QAP as a single equation over the polynomials. Thus, checking
polynomial equality in Equation (5) is equivalent to checking the m rank-1 constraints simultaneously. We
will eventually see that this is crucial to make our proofs succinct.

Checking particular equality and divisibility conditions about QAPs is key to our zk-SNARK protocols.

To do these checks in an encrypted manner, we introduce the following two concepts:
Deﬁnition 3. (Homomorphic Encoding) An injective homomorphism E : Fp → G such that it is hard to
ﬁnd x given E(x).

For a cyclic group G of prime order p and multiplication as the group operation, we will use the encoding
E(a) = ga, for a generator g of G. This is homomorphic and injective. Moreover, by the hardness of the
discrete logarithm problem, it is also hard to ﬁnd x given E(x).

Deﬁnition 4. (Pairing Function) Suppose G1, G2, and GT are groups of prime order p. A pairing function,
or bilinear map, is a function

e : G1 × G2 → GT

(6)

such that if g, h, are generators of G1 and G2 respectively, then e(g, h) (cid:54)= 1 is a generator of GT and

e(ga, hb) = e(g, h)ab.

Below, we list some basic properties about bilinear maps.

e(u, vw) = e(ga, hbhc) = e(g, h)a(b+c) = e(ga, hb)e(ga, hb) = e(u, v)e(u, w)
e(vw, u) = e(v, u)e(w, u)
e(ux, v) = e(g, h)xab = e(u, vx)

(7)

(8)

(9)

4

For the Pinocchio implementation, we use symmetric bilinear maps, where G := G1 = G2 [5].

In addition to these preliminaries for the Pinocchio protocol, we’ve included more formal deﬁnitions for
soundness, completeness, and zero-knowledge in the appendix (8), as well as the subtle diﬀerence between a
proof system and an argument system.

2.2 Reducing Arithmetic Circuits to QAP

Arithmetic-Circuit Satisﬁability is an NP-complete language [16]. Therefore, for any NP-computation that a
prover and a veriﬁer both agree on beforehand, they can construct an arithmetical circuit for that computation
such that a witness satisfying the circuit is a witness for the original computation. It is possible to build
circuits for a variety of useful NP-computations, such as the language of valid terrains according to some
terrain-generation algorithm, or the language of valid transactions according to some transaction protocol.

Thus, for an arbitrary arithmetic circuit, the prover needs a way to prove to the veriﬁer that they have a
witness, without revealing it. Since Pinocchio take as input an instance of QAP, we ﬁrst must show how to
reduce an arithmetic circuit to a QAP, such that an NP-statement about satisﬁability of an arithmetic circuit
can be made into an equivalent NP-statement about satisﬁability of a QAP. This reduction should further be
such that the witness of the arithmetic circuit is a witness of the constructed QAP. Then, verifying that the
prover has a witness for the QAP is equivalent to verifying the original computation was done correctly.

2.2.1 An Example Reduction

Consider the arithmetic circuit in ﬁgure (1). Both veriﬁer V and prover P know this circuit, but only P
knows a set of assignments (s1, s2, s3, s4, s5) for the wires that satisﬁes each gate’s rank-1 constraint. P would
like to reduce proving that s1 · s2 = s4 and s3 · s4 = s5 into proving a statement about polynomial divisibility,
as the latter can be done succinctly.

Label the two multiplication junctions in the circuit with labels x = 1 and x = 2, which we call our
target points. For each junction i, deﬁne polynomials Li(x), Ri(x), Oi(x), corresponding to the left, right,
and output wires of junction i, respectively. The key requirement is that these polynomials must equal 1 at
x = i, and 0 for other values of x. This interpolation property will be useful soon. To this end, let

L1(x) = R1(x) = O1(x) = 2 − x
L2(x) = R2(x) = O2(x) = x − 1

(10)

(11)

Notice that L1, R1, O1 are 1 at x = 1 and 0 at x = 2, and the opposite interpolation for L2, R2, O2. Label
the wires j ∈ {1, 2, 3, 4, 5} and deﬁne l(i) = j if j is left wire into junction i; that is, its left wire’s assignment
is sj. Deﬁne r(i) = j if j is right wire into junction i. Deﬁne o(i) = j if j is output wire of junction i. Now
consider the polynomial,

2
(cid:88)

P (x) := (

2
(cid:88)

sl(i)Li) · (

sr(i)Ri) −

i=1

i=1

(cid:16)

=

s1(2 − x) + s4(x − 1)

(cid:17)

(cid:16)

·

2
(cid:88)

i=1

so(i)Oi

s2(2 − x) + s3(x − 1)

(cid:17)

(cid:16)

−

s4(2 − x) + s5(x − 1)

(cid:17)

(12)

(13)

The interpolation properties becomes useful because requiring that P have zeros at all target points (at

5

x = 1, 2) yields the circuit’s rank-1 constraints.

P (1) = s1 · s2 − s4 = 0
P (2) = s4 · s3 − s5 = 0

(14)

(15)

Therefore, proving that P (1) = P (2) = 0 would imply that the rank-1 constraint at each gate is satisﬁed
by the assignment. Proving that the polynomial t(x) = (x − 1)(x − 2) divides P (x) is equivalent to proving
P (1) = P (2) = 0, which importantly oﬀers a succinct way for the prover to convince the veriﬁer that it
possesses a valid assignment for the QAP. The crux of Pinocchio and Groth-16 is to prove this polynomial
divisbility property holds without revealing the witnesses.

Figure 2: Circuit from Figure 1, annotated with target points and polynomial interpolates

2.2.2 The General Reduction

The following reduction is adapted from [18].

1. Suppose our circuit has n wires and m gates. Our witness is s = (s1, s2, ..., sn) ∈ Rn.

2. For all 1 ≤ i ≤ m and ai, bi, ci ∈ Rn, a triple (ai, bi, ci) represents a rank-1-constraint for s, requiring
that (s · ai) × (s · bi) − s · ci = 0. There is one such constraint for each multiplication junction of our
circuit.

3. Stack the m constraints vectors to obtain matrices A, B, C ∈ Rm×n, where

A =








aT
1
aT
2
...
aT
m








B =








C =








bT
1
bT
2
...
bT
m








cT
1
cT
2
...
cT
m








(16)

4. Using Langrange Interpolation [19], ﬁnd 3 sets of n polynomials {ui}n

i=1, {vi}n

i=1, {wi}n

i=1 such that for

all i ∈ [n] and x ∈ [m],

6

ui(x) = A[x][i]
vi(x) = B[x][i]
wi(x) = C[x][i]

(17)

(18)

(19)

5. Find the polynomial h(x) such that

(cid:16) (cid:80)n

i=1 siui(x)

(cid:17)

(cid:16) (cid:80)n

(cid:17)
i=1 sivi(x)

·

(cid:16) (cid:80)n

(cid:17)
i=1 siwi(x)

−

= h(x)t(x)

where t(x) = (x − 1)(x − 2)...(x − n).

The reduction is complete. Now P can apply the Pinocchio protocol to prove to V that she knows a
witness s that satisﬁes (5), without revealing her witness.

2.3 Pinocchio Protocol for QAP

2.3.1 Non-zero-knowledge Pinocchio Protocol Construction

We start by illustrating the workings for the Pinocchio protocol, without zero knowledge. Afterwards, we will
state the modiﬁcation to make the protocol zero knowledge.

Let G be a group of prime order p. Let E : Fp → G be a homomorphic encoding. In particular, E(x) = gx,
for a generator g. Let e : G × G → GT be a elliptic curve bilinear map. Suppose the prover P knows a witness
{si}n

i=1 for the original arithmetic circuit. By the reduction, she knows some polynomials such that

(cid:16) n
(cid:88)

i=1

(cid:17)

siui(x)

(cid:16) n
(cid:88)

·

i=1

(cid:16) n
(cid:88)

(cid:17)

−

(cid:17)

siwi(x)

sivi(x)

= h(x)t(x)

i=1

(20)

i=1 sivi(z), w(z) = (cid:80)n

for the values of the polynomials above. P is queried for the value of the u(z) = (cid:80)n
(cid:80)n

The main idea of the protocol is as follows. Intuitively, V would like to test P at a random point z ∈ Fp
i=1 siui(z), v(z) =
i=1 siwi(z), and h(z) at some random z ∈ Fp. P will homomorphically encode
these values and send them to V . Due to homomorphic and bilinear map properties, V can verify that the
homomorphically encoded values satisfy the same equation (20). If they do, she can be conﬁdent P truly
knows a witness, without learning the witness itself. Below are more details of the main idea just described.

The ﬁrst step of the protocol is to generate a common reference string (CRS), which contains homomorphic
encodings of speciﬁc multiples of z. The CRS serves two purposes: First, P can generate her homomorphic
encodings for her proof using linear combinations of the group elements of the CRS without needing to know
z. Second, setting up the CRS obviates the need for V to manually generate a z, and send a message with
the encodings of z to P . This enables this proof to be purely non-interactive, as after the CRS is generated,
P has enough to generate a convincing proof.

We can think of the CRS as two sets of public group elements: the evaluation key, which contains the
group elements needed to construct the proof, and the veriﬁcation key, which contains the elements needed
to verify.

Common Reference String:

Pick random α, βu, βv, βw, γ, z ∈ F∗

p. Publish the CRS below, then discard all of the sampled group

elements used in its generation (the toxic waste).

7

Evaluation key:

Veriﬁcation key:

i=0, {E(αzi)}n

i=0

• {E(zi)}n
• {E(ui(z)}n
• {E(vi(z)}n
• {E(wi(z)}n

i=1, {E(αui(z)}n
i=1, {E(αvi(z)}n
i=1, {E(αwi(z)}n

i=1, {E(βuui(z)}n
i=1, {E(βvvi(z)}n
i=1
i=1, {E(βwwi(z)}n

i=1

i=1

• E(1), E(α), E(t(z))

• E(γ), E(βuγ), E(βvγ), E(βwγ)

Prover’s message:

Assuming the prover has polynomials

(cid:16) (cid:80)n

i=1 siui(x)

(cid:17)

(cid:16) (cid:80)n

(cid:17)
i=1 sivi(x)

·

(cid:16) (cid:80)n

(cid:17)
i=1 siwi(x)

−

= h(x)t(x),

ﬁrst the prover computes h(x). Then the prover’s proof consists of the following:

• E(u(z)), E(αu(z)), where u(z) = (cid:80)n
• E(v(z)), E(αv(z)), where v(z) = (cid:80)n
• E(w(z)), E(αw(z)), where w(z) = (cid:80)n

i=1 siui(z)

i=1 sivi(z)

i=1 siwi(z)

• E(h(z)), E(αh(z))

• E(βuu(z) + βvv(z) + βww(z))

Veriﬁcation:

Upon receiving the prover’s proof, the veriﬁer ﬁrst checks that the terms u(z), v(z), w(z), h(z) were

constructed as linear combinations of terms in the CRS, performing the following 4 checks.

e(E(u(z)), E(αu1(z))) = e(E(αu(z)), E(u1(z)))
e(E(v(z)), E(αv1(z))) = e(E(αv(z)), E(v1(z)))
e(E(w(z)), E(αw1(z))) = e(E(αw(z)), E(w1(z)))
e(E(h(z)), E(α)) = e(E(αh(z)), E(1))

(21)

(22)

(23)

(24)

Next, check that each term u(z), v(z), w(z) was generated using the same linear coeﬃcients, {si}n
i sivi(z) and w(z) = (cid:80)

i=1. That
i siwi(z). This can be checked by verifying the

i siui(z), then v(z) = (cid:80)

is, if u(z) = (cid:80)
following equation:

e(E(βuu(z) + βvv(z) + βww(z)), E(γ)) = e(E(u(z)), E(βuγ))e(E(v(z)), E(βvγ))e(E(w(z)), E(βwγ))

(25)

Finally, we check the key condition that characterizes the polynomial divisibility criterion:

e(E(u(z)), E(v(z))) = e(E(w(z)), E(1)) · e(E(t(z)), E(h(z)))

(26)

Accept if and only if all the checks (21)-(26) hold.

8

2.3.2 Non-zero-knowledge Pinocchio Protocol Analysis

We will provide intuition for why this protocol works, deferring formal argument to the Pinocchio paper[5].
To begin, it is crucial to understand the following cryptographic assumption in order to understand the role
the random oﬀsets α, βu, βv, βw.

Claim 1. (Knowledge of Exponent Assumption [20]) Suppose Alice is given a pair of group elements (x, αx).
Let’s call such a pair α−separated. Then it is computationally intractable for her to come up with another
α−separated pair (y, αy), except by deriving it as follows

(y, αy) = (γx, γαx)

(27)

An extension to this is that given n α−separated pairs, if Alice returns a diﬀerent α−separated pair, it

must be a linear combination of the original α−separated pairs with high probability [20].

Back to our protocol, the key condition that V needs to check is the polynomial-divisibility condition:

u(z)v(z) − w(z) = t(z)h(z)

(28)

However, in addition to this equation, there need to be other equations that the veriﬁer also checks. This
is because it is possible for P to forge values that satisfy this equation, but that were not generated from a
true witness s for the circuit. To this end, V needs a way to check that the polynomials P uses are truly a
linear combination of the basis polynomials in the CRS.

The Knowledge-of-Exponent assumption is useful because if a pair of group elements that P sends and a
given pair are both α− separated, P ’s pair must be generated as linear combination of the given α− separated
pairs. Thus, V can use a pairing function to eﬃciently check that these two pairs are both α− separated, to
ensure P produced her proof from an actual satisfying assignment of the circuit. More concretely, for two
pairs (x, αx), (y, αy), the following is true:

E(x) = gx

e(E(x), E(αy)) = e(g, g)xαy = e(E(αx), E(y))

(29)

(30)

V can use this to produce the following check:

1. e(E(u(z)), E(α)) = e(E(αu(z)), E(1)) =⇒ u(z) is a linear combination of {ui(z)}n

i=1

2. e(E(u(z)), E(α)) (cid:54)= e(E(αu(z)), E(1)) =⇒ u(z) is not a linear combination of {ui(z)}n

i=1

Using this idea, the veriﬁer needs to verify three things

1. u(z)v(z) − w(z) = t(z)h(z)

2. u(z) (resp. v(z), w(z)) is a linear combination of {ui(z)}n

i=1 (resp. {vi(z)}n

i=1, {wi(z)}n

i=1).

3. u(z) is a linear combination with the same coeﬃcients as v(z) and w(z) (i.e. produced in linear

combinations using the same witness s).

9

We are now ready to describe why Pinocchio satisﬁes completeness and soundness.

Completeness

Regarding completeness, we are always able to generate such a proof from QAP. It remains to show that

if P ’s polynomials satisfy

(cid:16) n
(cid:88)

i=1

(cid:17)

siui(x)

(cid:16) n
(cid:88)

·

i=1

(cid:16) n
(cid:88)

(cid:17)

−

(cid:17)

siwi(x)

sivi(x)

= h(x)t(x)

i=1

(31)

then the veriﬁcation checks (21)-(26) hold. That is, the proof is valid and will be accepted with probability

1.

Equations (21)-(24) hold if P honestly produces her polynomials from the CRS basis polynomials, due to

the knowledge-of-exponent assumption.

Equations (25) holds if P uses the same {si}i as linear coeﬃcients for her polynomials. This is evident as:

e(E(βuu(z) + βvv(z) + βww(z)), E(γ)) = e(E(βuu(z)), E(γ))e(E(βvv(z)), E(γ))e(E(βww(z)), E(γ))
= e(E(u(z)), E(βuγ))e(E(βvv(z)), E(γ))e(E(βww(z)), E(γ))
= e(E(u(z)), E(βuγ))e(E(v(z)), E(βvγ))e(E(w(z)), E(βwγ))

(32)

(33)

(34)

Equations (26) holds due to the divisibility condition, Equation (5)

Soundness

Regarding soundness, if P does not have a valid witness, then when P constructs polynomials u, v, w,
and h, then u(x)v(x) − w(x) (cid:54)= h(x)t(x). Thus, it is enough to argue that if P does not have polynomials
satisfying Equation (5), then V will reject with high probability.

Suppose u(x)v(x) − w(x) (cid:54)= h(x)t(x). First, the degree of u and v is m − 1, since they are the sum of
polynomials who, constructed through Lagrange interpolation, go through m pre-determined points (one
for each junction in the arithmetic circuit). The degree of t(x) is m. Therefore, the degree of h(x) is m − 2.
Then, u(x)v(x) − w(x) and h(x)t(x) are two polynomials degree 2m. By the Schwartz-Zippel Lemma [21],
two diﬀerent polynomials degree at most 2m intersect in at most 2m points. Thus, u(x)v(x) − w(x) and
h(x)t(x) intersect in at most 2m points. Because z ∈ Fp has p possible values, then with probability at least
1 − 2m
p , equation (26) will fail and V will reject P ’s proof. This probability can be made arbitrarily close to 1
by taking p to be large.

Proof and Veriﬁcation Complexity

The proof size is 9 group members, from section (2.3.1). Regarding veriﬁer complexity, the veriﬁer spends
8 pairings to verify equations (21)-(24). It spends 4 pairings verifying (25), and 3 pairings for (26). In total,
this implementation of Pinocchio uses 15 pairings. The CRS setup and the proof generation take time linear
in the size of the original computation [5].

Finally, the Pinocchio paper presents reﬁned protocols that use 11 pairings with a proof size of 8 group

elements [16].

10

2.3.3 Zero-knowledge Pinocchio Protocol Modiﬁcation

In principle, if the veriﬁer V came up with their own witness s(cid:48) = (s(cid:48)
n), they can compute
E(u(cid:48)(z)), E(v(cid:48)(z)), E(w(cid:48)(z)), E(h(cid:48)(z)) following the prover’s protocol.
If these values are diﬀerent from
E(u(z)), E(v(z)), E(w(z)), E(h(z)), which the prover computed using s, then the veriﬁer concludes that the
prover’s witness is not s(cid:48) [21].

2, ..., s(cid:48)

1, s(cid:48)

To eliminate this zero-knowledge violation, the prover P adds on a random shift to the polynomials u, v,
and w [5]. The random shift will be a multiple of t(x), so that everything is still the same mod t(x). For
random δ1, δ2, δ3 ∈ Fp,

uz(x) = u(x) + δ1t(x)
vz(x) = v(x) + δ2t(x)
wz(x) = w(x) + δ3t(x)

(35)

(36)

(37)

Then, P will evaluate these at z using the CRS, and send over the shifted terms in its proof in the place

of the corresponding unshifted terms.

2.4 Groth-16 Protocol for QAP

Groth-16 is a recent, more succinct zk-SNARK protocol that has replaced Pinocchio in many applications
such as Zcash and Circom. It works on similar principles to Pinocchio, but both the proof size and the veriﬁer
complexity is signiﬁcantly lower in Groth-16.

For an arithmetic circuit, let n be the number of wires, m be the number of gates, P denote a pairing,
and E denote an exponentiation. Table (1), taken from [16], compares the complexity of important quantities
between Groth-16 and Pinocchio.

Table 1: Comparison between Groth-16 and Pinocchio [16]

Pinocchio
Groth-16

CRS size
7n + m G
n + 2m G

Proof size Prover complexity Veriﬁer complexity

8 G
3 G

7n + m E
n + 3m E

11 P
3 P

3 Application: Financial Security

One of the most common use-cases for zero-knowledge proofs is for increased ﬁnancial security. Although
blockchains are already secure and decentralized, we can make even stronger security guarantees using
zero-knowledge proofs, which allow us to, for instance, hide transaction amounts. In this section, we discuss
two of the most common applications that deploy zero-knowledge proofs for ﬁnancial security: Zcash and
Tornado Cash.

3.1 Zcash

Zcash is a Layer 1 (L1) token that allows for privacy protection [15]. Zcash allows both private and public
addresses, as well as both private and public coins. Coins can be “shielded” or “unshielded” by sending them
from public to private or private to public addresses. In the following sections, we will examine a simpliﬁed
form of Zcash with the strongest security guarantees – a Bitcoin-like private ledger where coins cannot be

11

traced back to the sender, the amount of each coin is shielded, and coins can be withdrawn from the ledger.
[22, 23]

To create a private transaction, Zcash uses a similar approach as Bitcoin, which validates the transactions
by linking the sender address, receiver address, and the transaction’s input and output values on the public
blockchain. However, each of these values are shielded. Intuitively, one can imagine a naive implementation
of Zcash that copies Bitcoin’s unspent transaction output (UTXO) model, but where each UTXO’s data is
kept oﬀ-chain. In its place, a hash is kept on-chain, and a zero-knowledge proof is used to prove that some
address has the right to consume the UTXO. We will construct the Zcash model piece by piece.

The explanations in this section are largely derived from the Zcash whitepaper [1].

3.1.1 Protocol Construction

The most naive model for Zcash would be as essentially an unordered set of commitments. To mint a coin, we
sample some random ri and publish ci = h(ri) for some hash function h. To allow Bob to spend ci, we simply
have to send Bob ri oﬀ-chain, and Bob can provide a zero-knowledge proof that his ri hashes to ci, allowing
him to consume the coin. The obvious diﬃculty here is that Alice still retains knowledge of ri through this
process. The remainder of this section formalizes and elaborates on this basic idea.

Step 1: Anonymity with Fixed-Value Coins. Let’s begin with a model where all coins are discrete
and have the same value. Each coin has a public serial number sn, together with with a secret randomness r.
We then deﬁne a coin commitment as cm := commr(sn). A coin is then deﬁned as the tuple c :=(r, sn, cm).
comm is a one-way function such that sn cannot be recovered from cm.

Now, consider the scenario where Alice wants to send a coin to Bob in a private transaction. To do this,

the sender Alice submits the coin cm, and sends a corresponding coin to an escrow pool (e.g. 1 BTC).

To withdraw the coin, Bob will reveal sn, together with a zero-knowledge proof of the following statement:
“I know r such that commr(sn) = cm.” If the proof is valid, then the 1 BTC gets withdrawn from the escrow
pool and sent to Bob’s address. sn gets added to a list of revealed coins, so that no future spender may
withdraw the same coin. So, for Alice to send the coin to Bob, she simply needs to send him r, sn privately.

Note that the original sender is anonymous. Although Alice’s address is associated with a transaction
containing cm, in order to associate cm with sn one would have to invert commr(sn), which is assumed to
be infeasible.

Step 2: Problems with Naive Implementation.

However, this implementation has many ﬂaws. For instance, although we checked that c wasn’t spent
before, we do not check that the c belongs to Alice. In this model, once Alice puts a coin into the escrow
pool, its original ownership is essentially erased, and anyone who knows r, sn can withdraw the coin. This
has a secondary problem, which is that when Alice sends the coin’s information to Bob, Alice still retains the
ability to spend the coin. One way to ﬁx this is to transfer coins in pairs of transactions – Bob spends coin c
and immediately mints c(cid:48) in the same block to protect himself. But this implementation is unwieldy.

This method also cannot be extended to a Bitcoin-like general-purpose ledger, since the coins are all
ﬁxed-size. Sending 100 BTC would require minting 100 of these transactions, which is also unwieldy. Moreover,
it is impossible to create coins with value of less than 1 BTC. Both of these issues will be resolved with
further uses of zero-knowledge proofs.

Step 3: General-Purpose Anonymous Payments.

To implement all of this, we redeﬁne our commitments as follows. For a seed x, we deﬁne deterministic
x to generate serial

to generate public keys from secret keys, and prfsn

pseudo-random functions prfaddr

x

12

numbers. We deﬁne:

pk = prfaddr
sn = prfsn

(0)
sk (p)

sk

(38)

(39)

Each user u generates a public key and secret key pair pk, sk. The coins owned by u contain pk and can
(0).

only be spent by proving knowledge of sk. sk is randomly sampled, and pk is related to it by pk = prfaddr
This allows us to generate a zero-knowledge proof relating pk to sk.

sk

To mint a coin of value v, the user ﬁrst samples some randomness p, which is related to sn as sn := prfsn
sk (p).
Again, this allows for a zero-knowledge proof to verify that sn was generated validly, without revealing sk
or p. u then commits to (pk, v, p) in two phases: (i) u computes k := commr(pk||p) for a random r; (ii) u
computes cm := comms(v||k) for a random s. This creates a nested commitment, which allows us to act on
v and k without revealing the components of k. In particular, this allows a user to verify that a coin has
value v without actually revealing pk or sn, which are a part of k.

We then deﬁne the pour function, which is a protocol the user follows to consume a bitcoin UTXO
and is the main means by which our coins are exchanged. Suppose that u with (pk, sk) wants to consume
c = (pk, v, p, r, s, cm) and produce two new coins c(cid:48)
1, pk(cid:48)
1, c(cid:48)
2.
The user follows a two-step process for computing c(cid:48)
2. This yields the coins
1), c(cid:48)
1 = (pk(cid:48)
c(cid:48)

2 which satisfy v(cid:48)
1, c(cid:48)
2. First, they sample p(cid:48)
2, cm(cid:48)
2).

2 = v targeted at addresses pk(cid:48)

2 = (pk(cid:48)

1, cm(cid:48)

1 + v(cid:48)

2, v(cid:48)

1, v(cid:48)

2, p(cid:48)

1, p(cid:48)

1, p(cid:48)

2, r(cid:48)

1, r(cid:48)

1, s(cid:48)

2, s(cid:48)

As part of the pour protocol, the user then provides a proof of each of the following four points to the

veriﬁer (the blockchain):

Given the serial number sn, and commitments cm(cid:48)

1, cm(cid:48)

2, I know c, c(cid:48)

1, c(cid:48)

2 and secret key sk such that:

• The coins are well-formed: for c, k = commr(pk||p), cm = comms(v||k), and similarly for c(cid:48)
• The secret key and public key match: pk = prfaddr

(0)

1, c(cid:48)
2

sk

• The serial number is well-formed: sn = prfsn

sk (p)

• The values match: v = v(cid:48)

1 + v(cid:48)
2

Upon executing this function, u has mapped the value v at some UTXO to two new UTXO’s whose value
add up to the original. This is the essence of a transaction. Thus, zero-knowledge proofs allow us to construct
a decentralized payments protocol.

Note that the pour function also accomplishes a secondary purpose of allowing us to make coins harder
to track. In particular, Zcash is backed using an escrow pool. This means that transactions can possibly be
tracked by cross-referencing coin amounts to withdrawn amounts. Thus, pour also allows us to “mix” the
tokens.

For this reason, in actual implementation we also modify pour to take two inputs and two outputs,
which becomes a ﬂexible general-purpose function that allows us to mix arbitrary inputs to produce arbitrary
outputs, making them very diﬃcult to trace. This allows us to more generally produce any number of inputs
and any number of outputs, as we can also make input or output coins null. But for the purposes of this
discussion, we will assume that pour only has one input.

Step 4: Public Payments

As described, the Zcash ledger can only be used for maintaining a private ledger of transactions. But this
isn’t very useful because in order to actually use any of these tokens, we need to withdraw coins from the

13

shielded network at some point. Thus, to send coins to an unshielded address, we add an additional ﬁeld vpub
to pour which represents a public payment; the value-equation to prove now becomes v = v(cid:48)
2 + vpub.
The address of this public payment is stored in transaction metadata, which is hashed on commitment and
revealed on consumption. The public output is also optional, in which case vpub = 0.

1 + v(cid:48)

Step 5: Merkle trees

Zcash provides one ﬁnal innovation makes it more secure and scalable. Rather than directly proving
knowledge of a coin, users will instead prove knowledge that this coin exists in the set of all commitments
using a Merkle tree. The contract maintains a state root rt, and when we pour the coin c, we need to also
provide a zero-knowledge proof of the Merkle proof that rt contains c. By doing so, the Merkle tree is never
revealed oﬀ-chain; it can be maintained by nodes or validators on the network.

The Merkle tree has an additional property of further masking transactions. It’s possible by careful
inspection to trace the history of a transaction. For instance, suppose that a coin is consumed and the entire
value is made public. An attacker could trace the history of that coin and possibly see its source commitment.
By putting this transaction data in a Merkle tree, we can entirely discard the commitments, meaning that at
any given time, not only can adversaries inspecting the network not know the state of the ledger, they cannot
even know its total size.

3.1.2 Zcash Limitations

Although Zcash is a novel and interesting concept, it still has many security risks. For instance, security is
only oﬀered at the level of the ledger. The nodes and the network can still be attacked. Even though public
keys cannot be associated with private keys, an insecure IP address can still be associated with a public key.

Additionally, since Zcash is a Layer 1 Bitcoin-like token, it has a hard time bootstrapping value into its
own network. Unlike Tornado Cash (discussed in the next section), which is built on Ethereum, Zcash doesn’t
beneﬁt from the battle-tested security of Ethereum. Users need to trust Zcash and its fairly centralized
bridges and comparatively smaller network of validators. The security concept is novel but not clearly useful
enough to demand an entirely new network. Indeed, only about 6% of transactions on Zcash actually use the
shielding functionality at all [24], suggesting that for the most part, Zcash functions largely as yet another
layer 1 token.

Finally, though the use of Merkle trees also allows for further security on hiding transaction data, the
implementation of them is diﬃcult. In particular, the circuits get much more complicated, as the zero-
knowledge proofs now also need to include Merkle proofs for both old coins. In addition, these Merkle proofs
need to update along with the global state root. If a user waits a hundred years to unshield my Zcash coin,
whatever original Merkle proofs they had are no longer valid. This means that there needs to be some sort of
additional layer to maintain the Merkle trees, and the current implementation of Zcash simply ignores this by
leaving the responsibility of tree maintenance to the nodes [1].

3.2 Tornado Cash

Tornado Cash has a similar objective to Zcash, but rather than having private tokens that can be moved
around and unshielded, only one transaction type is supported – sending some amount of ETH untraceably
from a sender to a receiver. However, on Tornado Cash, it’s harder to trace the original transaction due to
the use of a liquidity pool. The “mixing” caused by this pool is what gives the Tornado protocol its name.
(Zcash technically has some amount of mixing since each transaction mixes at least two inputs, but it’s not
as powerful as Tornado’s single liquidity pool.) Zcash can be thought of as a bitcoin-like ledger where the
state of the ledger is unknown but proofs of valid state transitions are published. However, each coin still
has its own transaction history, and is in a sense non-fungible, since it has a serial number. On the other

14

hand, Tornado Cash is much simpler, using a single giant liquidity pool that can only be deposited into and
withdrawn from.

Speciﬁcally, we would like to be able to send an N ETH note to an address t without anyone to be able
to trace where the transaction came from. In Zcash this is not quite possible, since we can think of Zcash as
being essentially a shielded UTXO model. When each UTXO is consumed, the history of that consumption
still exists somewhere on the blockchain – it’s just that the speciﬁc details of these actions are shielded.
However, on Tornado Cash, the N -ETH funds are deposited into a liquidity pool on the contract. Users are
able to view the total size of the liquidity pool, but not the size of the N -ETH notes that comprise it. This
makes the transaction truly untraceable, as the original deposit transaction is not even stored anywhere on
the contract.

The analysis in this section is largely drawn from the Tornado Cash whitepaper [2].

3.2.1 Protocol

Formally, we allow a coin to be deﬁned as (k, r), where k is a n-bit nulliﬁer and r is a n-bit randomness;
k, r ∈ Bn where B := {0, 1}. Let T represent a tuple of transaction data, chieﬂy including the designated
address and the amount of ether sent. Let H denote a hash function (MiMC, in our case).

When I deposit a coin, I generate k, r with my desired transaction T and compute C = H(k||r||T ). I

send C to the contract, which stores it in a Merkle tree as a non-zero leaf node.

When I withdraw a coin, I need to provide k, r, T , C = H(k||r||t), together with a zero-knowledge proof
that C has been computed properly. Additionally, I need to provide a proof that C is actually a member of
the Merkle root currently stored in the contract. k, T become public, while r is kept private. In particular, k
is added to an array of nulliﬁer hashes, which indicates which deposited coins have been withdrawn, so that
no two coins can be withdrawn twice.

This protocol claims the following security guarantees:

• Only coins deposited into the contract can be withdrawn

• No coin can be withdrawn twice

• Any coin can be withdrawn if (k, r, T ) are known

• Coins cannot be traced to their sender

3.2.2 Tornado Cash Limitations

There are still a few potential issues with the implementation. First of all, since the liquidity pool is entirely
backed by these deposited notes, it’s technically possible to track the source of a transaction simply by looking
at changes in size of the liquidity pool, since users can track the total size of the pool on the contract. For
instance, if the pool initially has 0 ETH, one can track a single transaction that moves the liquidity pool
from zero to a nonzero value, inferring that some address must initiate a transaction that moves the liquidity
pool. This could possibly be resolved by having a large buy-in to the pool during setup phase, i.e. if the pool
is initiated with 10000 ETH, changes of 1 ETH would be hard to track, since one could assume there would
be many transactions of comparable size entering and leaving the pool, and moreover since these transactions
would only be a fraction of the pool’s total size.

However, very speciﬁc numbers could still be traced. For instance, one block causes the pool to increase by
3.267 ETH, then a later withdraw transaction that decreases the pool by the same amount can be reasonably

15

assumed to be linked. This could be resolved by some sort of transaction-mixing operation. For instance, a
trusted 3rd-party relayer node could wait to receive a ﬁxed size batch of transactions. That is, they could
wait until 10 ETH of transactions are submitted, then only make commitments of 10 ETH at once while
providing a proof that the sum of the transactions is 10 ETH, perhaps supplying some of its own liquidity to
round oﬀ. Similarly, a relayer could also take a large transaction and split it into smaller ones, e.g. a 50 ETH
transaction could be split into 5 smaller ones of 10 ETH each.

Unfortunately, both of these changes require some higher-powered cryptographic tools. Abstractly, one
wants to generate a SNARK that proves a valid state transition has occurred on the ledger, but which can
encompass multiple transactions at once. This is certainly not impossible, and is in fact the same principle
that rollups are built on, but it’s not straightforward and detracts from the elegance of the Tornado Cash
protocol.

Another issue is that transactions can be front-run. A front-run attack is when a node, who receives
information from a client and is asked to execute a transaction, uses this information to their advantage.
In this construction anyone who knows (k, r, T ) can force the transaction to occur. This diﬀers from Zcash,
where the user’s address is actually taken into account in each transaction. Here, as long as the contract is
provided with a valid proof, a coin can be released. While not typically an issue, since the recipient of the
coin is encoded in the coin itself, this is still a potential security vulnerability in the sense that at an attacker
is allowed to interfere with a process where neither party wants that attacker involved. One could imagine,
for instance, if a large amount of funds are sent, that an attacker could force a transaction before the receiver
sets up a secure way to receive the large amount of funds, such as a multisig or a hardware wallet.

3.2.3 Comparison to Zcash

Tornado Cash’s key improvements on Zcash, are

1. The use of a liquidity pool to help mask transaction histories

2. The storage of some of the Merkle tree on the contract

3. The move to a simple smart contract model rather than a complex layer-2 solution, which solves the

issue of unmasking hidden coins when a user wants to withdraw them from privacy.

It’s worthwhile to compare these two solutions, which have similar end goals. The liquidity pool is certainly
a very powerful innovation. On Zcash, it would be quite easy to trace a small number of tokens around just
by following commitments manually, but with a liquidity pool, every transaction is truly untraceable. This,
in addition to the fact that Zcash is built as a smart contract on top of Ethereum, which is an extremely
well-trusted token with huge amounts of capital locked up, makes Tornado cash the platform of choice for
most people, especially for sending large amounts of USD anonymously (since ETH is more popular than
ZEC).

The use of a smart contract also means that consensus details can be handled by Ethereum, which allows
the Tornado cash protocol to be much more elegant than Zcash’s, as evidenced by the length of the protocol
itself. This means that users don’t need to trust smaller Zcash nodes but can instead place their trust in the
Ethereum ecosytem as a whole.

However, the downside of this is that Tornado cash cannot entirely abstract the Merkle tree away from
the protocol. Rather, it attempts to store some of the Merkle history in the contract. But this is not
straightforward. In particular, it’s not suﬃcient to simply store the root of the Merkle tree – one also needs
to store enough of a leaf path that the next leaf on the tree can be computed. This presents a possible
security issue, since part of the guarantee Tornado cash makes is that transaction data is discarded, but in

16

this case some amount of data needs to be retained so that the Merkle tree can be computed on the contract
side. In particular, it stores the previous 100 Merkle roots [2], and a withdrawer can provide a Merkle proof
to any of these Merkle roots. But since Merkle roots are recomputed each transaction, this means that a
withdrawer needs to constantly update its Merkle proof: the withdrawer needs to provide a proof that the
provided transaction is a leaf of the given Merkle root, so when the root changes, the proof changes. Then, if
the withdrawer stops receiving state updates from the contract for 101 root updates, it will no longer have
enough information to actually withdraw the coin, unless it receives the leaf path from a trusted 3rd party.

In any case, the use of a Merkle tree is actually subtly complicated here, which is the reason the nulliﬁer
is used – rather than updating the Merkle tree to indicate when a coin has been consumed, it’s easier to
simply keep a list of all transactions that have ever been consumed. This seems rather inelegant; as this
history will scale linearly with the number of coins ever consumed on the contract.

4 Application: Rollups

In this section, we discuss ZK rollups. Rollups are tools to optimize blockchain transaction throughput
by executing some portion of the transaction computation oﬀ-chain and using zero-knowledge proofs to
verify these executions on-chain. Since it’s faster to verify computations than execute them, this provides
a signiﬁcant speedup to the blockchain. Technically, a majority of current solutions for blockchains are
only “validity rollups,” and don’t exhibit perfect zero knowledge (8). However, most of these rollups are
implemented using libraries that do provide the zero-knowledge property, so we will call them ZK rollups.

These rollups are divided into two categories: constructions for application-speciﬁc rollups, where a
particularly expensive part of an application is put into a rollup, and general rollups, which can generate
validity proofs for any state transition on the EVM, scaling the entire Ethereum network. The former type of
rollup is the kind that Zcash and Tornado Cash implement. In this section, we will start with a few more
examples of application-speciﬁc rollups, like Dark Forest, and try to work towards a possible construction for
general-purpose rollups, zkEVM.

4.1 Validity Rollups and Validium

First, we will introduce the intuition for rollups by discussing at a high-level how one might use general-purpose
rollup to speed up Ethereum, assuming that one has a construction. Additionally, it’s worth discussing
the diﬀerence between two ﬂavors of rollup. More broadly, one could categorize these as Validity-style and
Validium-style, after the proposition for Validium as discussed in [25]. Both application-speciﬁc rollups and
general rollups can be categorized into either of these types.

To begin, consider the problem we are trying to solve: although Ethereum is the most popular Turing-
complete blockchain infrastructure on which people can build apps, the Ethereum block rate is merely 15
second/block which can barely serve the billions of users it purports to serve. This leads to gas fees that
often exceed hundreds of dollars.

For rollups, the key idea is that we allow users to compute transaction state changes oﬀ-chain. These
computations are managed in a second network, called an L2, as opposed to direct on-chain (L1) computations.
Moreover, there is a smart contract on L1 that links with L2, bridges tokens between the two, and veriﬁes
that L2 transactions happen correctly.

One way to implement this L2 scaling is called Optimistic Rollup, where we just assume that every L2
transaction is valid until someone refutes it. The contract holds for some period, giving users a chance to
submit a fraud proof saying that a transaction was done incorrectly. We can see how optimistic rollup can
scale Ethereum, but at the same time still relies on people submitting fraud proof to make sure that the

17

transactions are secure.

ZK or Validity Rollup follows much the same architecture [3], only instead of waiting for users to submit
fraud proofs, Zero-Knowledge proofs are used to verify that transaction state changes are applied correctly
[26]. The general protocol is as follows:

• Users do their activities including signing transactions on L2 and submit those transactions to validators,

which act as a bridge between L1 and L2

• Validators aggregate (“roll up”) thousands of submitted transactions together into a single batch and

submit the following to an L1 main chain smart contract:

– A new L2 state root

– A zk-SNARKs to prove the correctness of the state root

– Transaction headers for each transaction in the batch

– A Merkle root of the transaction batch, allowing users to check whether or not a transaction was

really in this batch

• The main chain, thanks to zk-SNARKs, veriﬁes both the validity of all the transactions included in the

block and the validity of the proposed state transition on the Merkle root

zk-SNARKs veriﬁcation is much more eﬃcient than verifying every transaction individually. Also, storing
the state oﬀ-chain is signiﬁcantly cheaper than storing it on EVM, enabling boost of mainnet capacity and
saving on transaction fees.

Validium essentially makes the minor change that even transaction headers are not stored, the SNARK
instead proving that the state transition is valid, but not providing any information about what led to that
state transition. We can think of validity rollups as being a proof of computation, and Validium as being
both a proof of knowledge and of computation. The same diﬀerentiation exists for application-style rollups,
too: one can roll up only an expensive computation but retain the data on-chain, or one can also discard the
data and put it oﬀ-chain. We will call rollups as in the protocol described above Validity-style, and protocols
that also discard data Validium-style [25].

4.2 Dark Forest

Dark Forest [4] is the ﬁrst fully on-chain game built on Ethereum, and is powered largely by zk-SNARKs.
In the game, planet coordinates are kept private. Planet data is public, but is indexed by the hash of the
planet’s coordinates. The game is inspired by the highly adversarial nature of science-ﬁction novels but also
of the Ethereum ecosystem more broadly. In particular, revealing one’s coordinates can be seen as being akin
to a declaration of war, since it invites other players to attack that planet.

Games, especially an MMORTS (massively multiplayer online real-time strategy games) like Dark Forest,
are a very interesting use case for rollups. In particular, due to the thousands of transactions that players
execute when the game is in action, any amount of computation or storage that can be saved is incredibly
valuable, since blocks will nearly always be entirely saturated. We will discuss two uses of rollups in Dark
Forest.

In the game, each planet has cartesian coordinates (x, y) and a planet ID h := H(x, y) for some hash
function H. Additionally, planets have certain properties, such as biome, computed from a Perlin noise
function, denoted here as n := p(x, y) for a Perlin function p [4].

A zk-SNARK is used to verify that h = H(x, y). This not only protects the values of (x, y), but also
allows (x, y) to not be stored on the contract. This, in a sense, is a Validium-style rollup. Perhaps more

18

interestingly, Perlin noise can actually be quite expensive to compute on-chain, and it is computed oﬀ-chain
in a Validium-style rollup.

The ﬂow for generating a new planet thus is as follows: when a new planet is discovered, the user makes a
transaction to the contract providing a proof that they know (x, y) for some declared h such that h = H(x, y),
and that the planet’s Perlin value n is also related to (x, y) by n = p(x, y). The contract veriﬁes the ﬁrst
proof, and if it is successful, veriﬁes the second proof. It then uses this value of n and references it with a
table of planet generation data, returning a planet with diﬀerent properties depending on the value of n.

The full implementation of Perlin noise is not discussed here, but we will quickly give a construction for
sampling a random gradient vector (one step in the Perlin noise process), since the example is illuminating.
The typical way to do this would be by sampling a random angle and then calculating its sine and cosine.
However, sine and cosine are not easy to linearize into an arithmetic circuit - they have Taylor series
approximations, but those converge very slowly. The technique here is to use the hash of the coordinates to
pseudorandomly generate an index from 0 to 7 as in r(x, y) % 8, which is used to sample one of 8 pre-generated
vectors corresponding to iπ/4 for 0 ≤ i < 8.

This construction shows how a speciﬁcally-engineered solution can provide a large speedup to a particular
problem and reveals an obstacle for general-purpose rollups: generic algorithms for creating circuits are rarely
as fast as speciﬁcally-engineered ones.

4.3 zkEVM - Turing-Complete Rollups

Here, we will discuss a particular implementation for general-purpose ZK rollups, as implemented by zkSync.
This problem is often referred to as zkEVM, in the sense that we want to embed all state changes on the EVM
into a circuit. We will begin with naive implementations, then describe the problems with them, moving
towards a solution that is actually deployed onto Ethereum Mainnet [27].

We can essentially state the problem as such: for any given block, comprised of transactions that make
calls to any number of contracts, we want to generate a zero-knowledge proof of the EVM state transition
induced by the block.

4.3.1 TinyRAM

The most naive way to implement this is to ﬁrst compile the block and its transactions down to its
corresponding opcodes, then provide an arithmetic circuit node for each opcode. This is trivially easy to
do, since this compilation must occur at some point, and since opcodes are read like a stack, it’s easy to
create a long circuit that simply reads opcodes oﬀ sequentially. zkSync in particular implements a TinyRAM
architecture, which has a small instruction set, and thus can easily be converted into a circuit.

The problem with this implementation is that it’s incredibly slow. Simple operations like array accessing
might get compiled down to a very large number of opcodes – incrementing pointers, etc. Because of this,
TinyRAM has an average of over 1000x overhead compared to direct circuit implementation, like the one
given above for Dark Forest [27].

Table 2: Comparison of circuit complexity for hardwired circuit vs TinyRAM [27]

Operation
Add
Sub
Poseidon hash
SHA256 hash
Keccak hash

# Gates: hardwired # Gates: TinyRAM

1 K
1 K
> 250 K
> 25 M
unreasonably large

1
128
250
25 K
300 K

19

4.3.2 Recursive Aggregation

The next attempt would be to use a more powerful cryptographic tool called recursive SNARKs, discussed in
section (6.2). Using elliptic-curve properties, it’s possible to combine two SNARKs into one SNARK of the
same size. The proposition here is for each contract to provide its own zero-knowledge proof, and thus a
transaction would be able to aggregate a SNARK across each contract in a way similar to a Merkle tree.

For instance, consider a block comprised of 4 transactions: t1, t2, t3 and t4 together with proofs π1, π2, π3, π4.
Recursive aggregation would allow us to generate π12 from π1, π2 and π34 from π3, π4, then ﬁnally πblock
from π12, π34. We continue this process for every transaction in a block to generate a proof for the whole
block. Recursive aggregation is shown in the below ﬁgure:

Figure 3: Recursively aggregated SNARK

A crucial issue with this idea is that recursion-friendly cryptography isn’t actually possible on the EVM–it’s
possible to implement, but there are no pre-compiles issued in the protocol. One possible solution is to
use PLONK, a construction to generate a recursive SNARK, which was implemented by Matter Labs [27]
on January 2021. But the problem here is that PLONK is not Turing-complete. In particular, it cannot
implement jumps or recursion, similar to a shader or other parallel operations.

4.3.3 Heterogeneous Mixing

The insight that allows zkSync to fully implement zkEVM is to use a mix of all three rollup solutions:
hardwired circuits, TinyRAM, and recursively aggregated PLONK. This works because Ethereum opcodes
tend to be distributed in cost as a power-law. That is, a small number of opcodes are more expensive than
the rest combined: SSTORE costs 20000 GWEI while ADD costs 3 [28].

The result of this is that in most transactions, 99.9% of the gas costs comes simply from memory and
signatures. Thus, a naive solution to zkEVM is to write hardwired circuits just for the diﬃcult operations
(storage and signatures) while using TinyRAM for everything else.

The problem with this naive solution is that circuits themselves also have a capacity. There’s a maximum
number of constraints that can be encoded into the arithmetic circuit, and these need to be allocated between
these two solutions in some way. A naive ﬁxed 50/50 split doesn’t work well because blocks tend to be fairly

20

heterogenous. One block might comprise of many hashes, while the next comprises of SSTOREs. The result
is that circuits will usually not end up being fully saturated, making the rollup ineﬃcient.

The solution to this, and the solution that zkSync deploys for zkEVM, is hetereogenous mixing – the use
of recursive aggregation to regulate the ratio between hardwired circuits and TinyRAM circuits. In essence,
it combines all three of the discussed solutions for a maximally optimized rollup.

To see this in practice, suppose as in the previous example that we have t1, t2, t3 and t4 together with
proofs π1, π2, π3, π4. We can think of each πi as being comprised of πt
i , referring to subroutines
that deal with TinyRAM operations, hashes, and storage respectively (the three largest types of proofs).
Recursive aggregation allows for each πt
i to be aggregated into one large πt, and similarly for πh and πs.
πblock is then aggregated from πt, πh, and πs. This situation is illustrated in the below ﬁgure:

i , and πs

i , πh

Figure 4: Hetereogenous mixing for SNARKs

In summary, combining these various techniques allows us to generate Turing-complete zero-knowledge
proofs. This, together with application-speciﬁc rollups, will allow Ethereum to scale signiﬁcantly over the
coming years.

5 ZK Circuits for Novel Applications

This section provides novel circuit designs for two applications: private auctions and decentralized card games.
These protocols use zk-SNARKs to provide unique guarantees that are necessary for these applications. Code
for these designs can be found in the appendix (8.2.1).

5.1 Private Auction

5.1.1 Motivation

Zero knowledge private auctions aim to simulate an anonymous auction process where buyers can submit
bids without revealing their identity or funds available. Maintaining such private information is crucial in an
auction. In a recent event involving ConstitutionDAO, a group of crypto holders collected over 40 million

21

dollars in ETH to bid for one of the earliest copies of US Constitution available. However, because their total
funds were publicly viewable on the blockchain, another group in the auction outbid their maximum by a
small amount and won the auction [29].

Creating a decentralized private auction is complicated for multiple reasons. First, the identity of the
accounts need to be private because revealing the account reveals their available funds for the auction. Second,
the auction needs to prevent malicious users from submitting bids beyond their available funds. There should
be penalty if the user fails to pay the winning bid.

A naive solution to these two problems is where the user pays their bid upfront for each bid they make.
However, this creates many additional transactions and results in an overly complicated protocol. Any form
of transaction between the money holding account and the auction contract reveals information about the
bidder. By searching for the auction contract on Etherscan [30], people can view all transactions and the
originated addresses. Hence, the bidding process cannot involve a direct transfer of funds to the contract
performing the auction.

Our proposed solution involves a proof-of-stake process where the bidders stake a certain amount of coins
upfront, an auction entry fee. If the bidder did not win the auction, the coins can be reclaimed. If the bidder
wins the auction, they needs to pay the remaining amount on top of the staked coins within a given time
period to avoid the coins getting slashed.

5.1.2 Accounts

Each user should have two accounts. First, they have a staking account, which is public and is used to
transfer the entry-fee coins up front. Additionally, the seller may choose to double the staking coins in the
middle of the auction, which will require the bidder to transfer more coins to the auction from the staking
account. The money transfer in between accounts can be untraceable with use of Tornado Cash.

Second, each bidder also has a private account. This account holds the actual funds the bidder will use
to fulﬁll the winning bid. Because this account is separate from the staking account, a third party cannot
determine the maximum a bidder can bid from the transaction from their staking account. Also, to protect
the interests of the seller, zero knowledge cryptography should be used to prevent the bidder from submitting
bids higher than the actual funds.

5.1.3 Protocol

The protocol should consist of the following steps.

1. The users pre-commit the MiMC hash of the account address and the MiMC hash of funds available to
the Merkle Tree. The zero knowledge proof will verify that the user indeed owns the account, and that
the pre-images of the commited MiMC hashes are equal to the public account address and the available
funds. Account addresses to the Merkle tree cannot be duplicated.

2. Before a bidder submits a bid, the contract veriﬁes the previous bidder’s account. The previous bidder
cannot be the same as the current bidder, to prevent one account artiﬁcially inﬂating the price. Although
this mechanism does not prevent a person from having two staking accounts and two private accounts,
there is a deterrent to this behavior: having two accounts will reduce the fund available in each account
and therefore reduce the possibility of winning the auction, as transfer of funds into the private account
is not possible after commitment to Merkle tree.

22

3. A zero knowledge proof will be submitted to verify that the bidder owns a fund that is higher than the

bid. The input to the circom circuit includes

(1) pre-image of the account address

(2) pre-image of the available funds

(3) bid submitted to the contract.

A comparator circuit is used to compare the available funds with the bid submitted to the contract. If
the comparator zero-knowledge circuit returned True, the bid is valid. Else, the bid is invalid. The
circuit also consists intermediary checks to prevent tempering the witness ﬁle. The circuit also checks
that the MiMC hash of account address and available funds is in the Merkle tree. As such, we can have
a complete protocol of a private decentralized auction process.

There are possible attacks against this protocol. For example, a person can use alternative sources like
Etherscan to look for accounts with most funds. MiMC hash is not reversible, but it will be easy to compute
the MiMC hash of the top 1000 available funds. If all the 1000 funds are not part of the auction, this will give
some upper bounds on the amount of funds available in the merkle tree accounts. If one or more of the funds
are part of the auction, a lower bound on the amount of funds can also be calculated. With prior knowledge
on the possible participating funds, it is easily veriﬁable if a given fund participate in the auction or not.

One idea to prevent this attack is for the user to each to commit a salt – a large random number that will
be added together with the account address and fund available inputs. This will make the attack invalid
because knowing the address itself does not generate the hash - the pre-image of the salt needs to be known
too.

Our implementation of the above protocol can be found in the appendix (8.2.1).

5.2 Decentralized Card Games

5.2.1 Motivation

We provide a set of protocols that can be used to play incomplete information games on chain (games where
the players don’t have full information of the game state). For example, in poker the player’s hand is private
information, and the card drawing process is completely private as well. Incomplete information is interesting
because it allows for game theory, heuristic reasoning, bluﬃng, and other complex strategies, even outside
the context of card games. For instance, given the recent popularity with non-fungible tokens (NFTs), it may
be interesting to see players using NFTs as their “cards” to play various games of incomplete information.

However, incomplete information games are hard to simulate on chain. It is diﬃcult to simultaneously
prevent cheating and ensure privacy in games, as the hidden cards have to be stored and drawn locally
without explicit commitment to the smart contract.

The current card games use a commit and reveal approach to achieve privacy and anti-cheating. Players
commit each action they take in a game by committing the hashes. For example, if a player claim that they
have played the card 5, then they must commit the hash of their remaining hand on chain. At the end of
the game, all hands are revealed publicly and veriﬁed at each step to ensure that no players are lying in the
game. If any discrepancies are found in the process, the entire game is rolled back to the beginning.

The commit and reveal process is problematic for two reasons. Firstly, there is no way to verify that rules
were followed before the end of the game. There is no way to catch players lying on the spot, and any slight
discrepancies or misplay will have to void the entire game. The roll-back process is costly and frustrating,
especially if players deliberately try to void the game. Secondly, the commit and reveal approach requires

23

that all cards be shown publicly at the end, revealing each player’s bluﬃng strategy. Bluﬃng is a key strategy
in a poker game and information about players’ strategies should not be revealed if it can be avoided.

An interesting question is whether we can leverage zero knowledge proofs to solve these two problems. For
this, we provide the following decentralized card game protocols that don’t have the two issues mentioned
above.

5.2.2 Decentralized Card Game Subroutines

Generating Randomness

Randomness is required during the card draw process to get a card. Suppose the card deck is a public
array with integers 1 to 13. Then, the following process ensures a random card is drawn. The following
protocol can be used to generate public and private source of randomness.

1. A public source of randomness is given by previous block’s hash. Whenever a new block is committed,
its block hash can be assumed to be pseudo-random. However, relying solely on previous block hash
can lead to bias. Players can choose when they play the card, depending on if the previous blockhash is
would yield a favorable draw.

2. The private source of randomness is given by a seed hash committed by the player prior to the start of
the game. The player is able to choose a random number k, and the MiMC hash, MiMC(k), will be
pre-committed on chain. During the game, the player is able to prove their knowledge of the pre-image
of MiMC(k) without revealing k itself. The number k constitutes private source of randomness.

Random and Private Card Draw

With the ability to simulate randomness, the random and private card draw is fairly straight forward. A
random number can be generated from previous block hash and player’s pre-commited hash, possibly as an
addition of the two numbers. The card drawn will be given as:

card = (previous block hash + k)%(number of cards)

(40)

To further reduce the bias of the game, it is also possible for each player to set the secret seed k for their

opponents. Such protocol is able to achieve unbiased random card draw while ensuring privacy.

Check Hand Consistency

While it is straightforward to draw a card, the process where a hand is updated is not as obvious. Note
that the player’s hand is also private. When a card is drawn, the hand needs to be updated, and the hash of
the new hand needs to be committed on chain. The zero knowledge protocol needs to achieve three purposes.

1. The protocol needs to ensure that the old hand corresponds to the previous committed hash.

2. It needs to prove transition between the old hand and new hand.

3. It needs to ensure that the committed hash corresponds to the hash of the new hand.

While the ﬁrst and third steps are a simple implementation of MiMC module in Circom [17], the second
step is not as obvious, where we need to prove transition between old hand to new hand. With this challenge,
a permutation protocol can be used where we prove the (old hand + card drawn) is a permutation of the

24

(new hand + empty card). The card drawn process is seen as a exchange between an empty card from old
hand with the new card drawn.

Private Card Play

During private card play, a card can be publicly shown. The zero knowledge proof process is fairly similar
to the previous steps. The player needs to go through three-stage proof process similar to the previous parts.
Firstly, prove the old hand is the pre-image of the committed hash. Secondly, prove transition from old hand
to new hand through permutation. (old hand + empty card) is the permutation of (new hand + card played).

With these subroutines, we now have the necessary building blocks to generate many possible decentralized

card games on chain. A proof of concept implementation can be found in the appendix (8.2.2).

6 Future of ZK

6.1 zk-STARKs

Although success of zk-SNARKs is shown through various applications such as Zcash and zk-Rollups, they
still have exploitable weaknesses. zk-SNARKs require a trusted setup, which means that it needs a certain
secret key to create the common reference string, on which proof and veriﬁcation is based. This private key is
called “toxic waste” because it needs to be disposed or securely kept. If an attacker obtains this secret, he
can utilize the secret to forge the transaction [31].

One common way to mitigate the risk of attacker acquiring the toxic waste is via Multi-Party Computation,
where we require a set of multiple participants to cooperatively construct the key. Each of them holds a
shard of private key which is for constructing a shard of public key (CRS) that can be combined to get public
key [32]. In this setup, the exploit is minimized since having at least one of participants successfully deleting
their private key shards is enough to make it impossible for an attacker to acquire toxic waste. However, this
approach can be cumbersome. Another concern of SNARKs is that it is not quantum-computer resistant.

zk-STARKs was created by Eli Ben-Sasson, Iddo Bentov, Yinon Horeshy in 2018 [33]. Unlike zk-SNARKs,
the base technology for zk-STARKs relies on collision-resistant hash functions. As a result, zk-STARKs
doesn’t require an initial trusted setup and also achieve quantum-resistance. However, zk-STARKs proof
has a far bigger size of the proofs compared to zk-SNARKs, resulting in much longer veriﬁcation time
than zk-SNARKs and costing more gas. Although the developer documentation, tools, and community of
zk-STARKs is far smaller than zk-SNARKS, zk-STARKs is a promising, emerging technology, as seen from
the fact that the Ethereum Foundation gave STARKware, a zk-STARKs based scaling solutions, a $12 million
grant.

6.2 Recursive SNARKs

Although SNARKs can be applied to various applications, there are some applications that naive SNARKs
is not suitable. For example, in case that we want to prove the correctness of a function after t iterated
execution on it. With SNARKs, we need to prove all t executions at once. This “monolithic” execution can
cause many problems. For instance we may not know number of t in advance or the whole t executions are too
big for memory [34]. This problem becomes clearer when we want to implement an application like private
but veriﬁable elections. In these elections, people should be able to vote without exposing their identity, and
the protocol can count the votes and verify that the vote result is correct. As we’ve discussed above, this
application is almost impossible with naive SNARKs since we are unable to process all the proofs of each
individual voter all at once.

25

As a result, another version of SNARKs is developed, called “recursive SNARKs.” With recursive SNARKs,
it is possible to apply SNARKs at each iterated execution to prove that execution and the correctness of prior
proof. Hence, we don’t need to wait to aggregate all executions to prove at once. With this, the election
problem becomes a lot easier since people can submit the proof of their vote and the vote-counter can just
aggregate the vote and verify the intermediary result of voting. When more people votes are sent, we can
just apply recursive SNARKs again to update and verify the new voting result[35].

26

7 Acknowledgments

The authors would like to thank Tim Roughgarden and Maryam Bahrani for their support in teaching the
material necessary to write this paper.

8 Appendix

8.1 Formal Deﬁnitions

This section provides formal deﬁnitions for soundness, completeness, zero-knowledge, touching on the diﬀerence
between computational and perfect versions of these deﬁnitions. The following deﬁnitions are directly quoted
from Groth, Ostrovsky, and Sahai’s 2011 paper [12].

Let R be an eﬃciently computable binary relation. For (x, w) ∈ R, we call x the statement and w the
witness. L is the language consisting of statements in R. A non-interactive proof system for relation R
consists of a common reference string generation algorithm K, a prover P , and a veriﬁer V . These algorithms
are all probabilistic non-uniform polynomial time algorithms. K produces a CRS σ of length Ω(k). The
prover takes (σ, x, w) and produces a proof π. The veriﬁer takes (σ, x, π) and outputs 1 if and only if the
proof is accepted.

Denote 1k as a unary string of 1’s of length k. Denote σ ← K(1k) as σ being assigned the output of
K(1k), with probability equal to the probability that K outputs σ. (K, P, V ) is a non-interactive proof
system for R if it has completeness and soundness properties below:

Deﬁnition 5. (Perfect Completeness) A proof system is complete if for all adversaries A

P [σ ← K(1k); (x, w) ← A(σ); π ← P (σ, x, w) : V (σ, x, π) = 1 if (x, w) ∈ R] = 1

(41)

Deﬁnition 6. (Perfect Soundness) A proof system is sound if for all polynomial size families {xk} of
statements xk /∈ L and all adversaries A,

P [σ ← K(1k); π ← A(σ, xk) : V (σ, xk, π) = 1] = 0

(42)

Deﬁnition 7. (Computational Soundness) A proof system is computationally sound if for all polynomial size
families {xk} of statements xk /∈ L and all non-uniform polynomial time adversaries A, if k is suﬃciently
large,

P [σ ← K(1k); π ← A(σ, xk) : V (σ, xk, π) = 1] ≤ k−c, ∀c > 0

(43)

Deﬁnition 8. (Computational Zero Knowledge)

A non-interactive proof (K, P, V ) is computational zero-knowledge if

1. There exists a polynomial time simulator S = (S1, S2) where S1 returns a simulated CRS σ with a
simulation trapdoor τ that enables S2 to simulate proofs without access to the witness. In particular, if
(x, w) ∈ R, S(σ, τ, x, w) = S2(σ, τ, x). If (x, w) /∈ R, both oracles output “failure”.

2. For all non-uniform polynomial time adversaries A,

27

P [σ ← K(1k) : AP (σ,·,·)(σ) = 1] ≈ P [(σ, τ ) ← S1(1k) : AS(σ,τ,·,·)(σ) = 1]

(44)

The notation AP (σ,·,·) and AS(σ,τ,·,·) mean that A has access to an oracle that on input (x, w) returns a
proof π. The adversary only sees the inputs and outputs of the oracle, and does not know which type of
oracle it has access to.

Intuitively, the adversary A plays the role of a distinguisher between the distributions over proofs generated
by the simulator and by the actual prover. The more perfectly some simulator can simulate the prover, the
more the proof is zero knowledge, because then the prover does not reveal anything to the veriﬁer that would
help the veriﬁer compute anything much faster than before [7]. Everything the veriﬁer sees from the prover is
something the prover could have computed for herself if she knew that (x, w) ∈ R.

Taking this idea further, if the two probabilities in (44) are exactly equal, then (K, P, V ) is Perfect Zero

Knowledge.

There is an important distinction between the computational and perfect versions of soundness and
zero-knowledge. Computational soundness is weaker than perfect soundness, requiring that only non-uniform
polynomial time adversaries cannot provide accepted proofs for false statements with non-negligible probability.
Similarly, computational zero-knowledge is weaker than perfect zero-knowledge, requiring that the information
the veriﬁer sees, called its View [7], is distributed similarly to that of some polynomial time simulator.

With these deﬁnitions, the distinction between proof systems and argument systems is as follows. Proof
systems require perfect soundness––a computationally unbounded prover cannot make proofs for false
statements. On the other hand, argument systems only require computational soundness.

This distinction is made because diﬀerent notions of zero-knowledge are achievable in argument systems
versus in proof systems. Fortnow [36] showed that unless PH collapses, there do not exist perfect zero-
knowledge proof systems for NP complete problems. In fact, even interactive proof systems cannot have both
perfect soundness and perfect zero knowledge. In contrast, there are perfect zero-knowledge (and additionally,
non interactive) argument systems for NP complete problems, namely the zk-SNARK protocols [13, 12].

8.2 Code for Novel Applications

8.2.1 Private Auctions

As a proof of concept, we implemented a minimalistic version of zero-knowledge private auction in Circom
with accompanying contracts. The zero knowledge proof below veriﬁes if a given bid is valid at each instance.
The circuits veriﬁes Merkle Tree identitiy inclusion for a given user, as well as proving bid validity.

To prove the Merkle tree inclusion, the inputs to the circuit consists of (a) the leaf node, (b) the root
node, (c) pathElements, (d) pathIndices. This information is either committed on chain or can be easily
generated when user commits to Merkle tree. pathIndices consist of a list of 0 or 1 that indicates if a given
pathElement is on the left or right of the Merkle Tree. By continuously hashing the current node with the
pathElements, we are able move up in the Merkle Tree till the root node. Then, the inclusion check is valid if
the calculate root node is equal to the public root node, suggesting that a path exists to move from the leaf
node to the root node. This part of the circuit is generated with reference to Tornado Cash and Semaphore
implementation of the Merkle tree. Since the use of MiMC hash function exceeds the number constraints
given by Circom, Poseidon hash [37] is used as an alternative, a more zk-SNARKs-friendly version of the
hash function.

To prove the validity of the bid, we need to ensure that the given bid is lower than the funds available.
The inputs to the circuit consists of (a) pre-image of the account, (b) pre-image of the fund available, (c)

28

submitted bid. The Poseidon hash of the pre-image of the account and pre-image of the fund available will
be checked against the publicly committed hash, which in our case is the leaf node. If equal, we can verify
that the bidder is indeed the owner of a participating account. Then, a comparator circuit is used to verify
that the fund available is larger than the bid. This prevents overbidding to take place, which can hurt the
decentralized auction ecosystem.

The output the circuit mainly consists of (a) outValid, which indicates if the available fund is higher
than the bid, (b) ﬁnalBid, which is strictly equal to the bid submitted to the user. Note that the outputs of
Circom is directly fed into the smart contract. By having ﬁnalBid as an output, this ensures that the smart
contract only accepts the bids that goes through the zero knowledge proof circuit in Circom.

i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s / mimcsponge . c i r c o m ” ;
i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s / p o s e i d o n . c i r c o m ” ;
i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s /mux1 . c i r c o m ” ;
i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s / c ompar ator s . c i r c o m ”

t e m p l a t e PoseidonHashT3 ( ) {

var n I n p u t s = 2 ;
s i g n a l
i n p u t
s i g n a l output out ;

i n p u t s [ n I n p u t s ] ;

component h a s h e r = Poseidon ( n I n p u t s ) ;
i ++) {
f o r

( var
h a s h e r . i n p u t s [ i ] <== i n p u t s [ i ] ;

i < n I n p u t s ;

i = 0 ;

}
out <== h a s h e r . out ;

}

// Computes PoseidonHash ( [ l e f t ,
t e m p l a t e HashLeftRight ( ) {
l e f t ;
i n p u t
s i g n a l
s i g n a l
r i g h t ;
i n p u t
s i g n a l output hash ;

r i g h t ] )

component h a s h e r = PoseidonHashT3 ( ) ;
h a s h e r . i n p u t s [ 0 ] <== l e f t ;
h a s h e r . i n p u t s [ 1 ] <== r i g h t ;
hash <== h a s h e r . out ;

}

s == 0 r e t u r n s
// i f
// i f
s == 1 r e t u r n s
t e m p l a t e DualMux ( ) {

[ i n [ 0 ] ,
[ i n [ 1 ] ,

i n [ 1 ] ]
i n [ 0 ] ]

s i g n a l
s i g n a l
s i g n a l output out [ 2 ] ;

i n [ 2 ] ;
s ;

i n p u t
i n p u t

s ∗ ( 1 − s ) === 0
out [ 0 ] <== ( i n [ 1 ] − i n [ 0 ] ) ∗ s + i n [ 0 ] ;
out [ 1 ] <== ( i n [ 0 ] − i n [ 1 ] ) ∗ s + i n [ 1 ] ;

}

29

t e m p l a t e B i d V e r i f i e r ( l e v e l s ) {

s i g n a l
s i g n a l
s i g n a l
s i g n a l

l e a f ;
r o o t ;

i n p u t
i n p u t
i n p u t pathElements [ l e v e l s ] ;
i n p u t p a t h I n d i c e s [ l e v e l s ] ;

s i g n a l p r i v a t e i n p u t a c c o u n t ;
s i g n a l p r i v a t e i n p u t v a l u e ;
s i g n a l p r i v a t e i n p u t b i d ;

i n c l u s i o n check

s e l e c t o r s [ l e v e l s ] ;

// Merkle t r e e
component
component h a s h e r s [ l e v e l s ] ;
s i g n a l output hashP ;
s i g n a l output o u t V a l i d ;
f i n a l B i d ;
s i g n a l output

i = 0 ;

i < l e v e l s ;

( var
s e l e c t o r s [ i ] = DualMux ( ) ;
s e l e c t o r s [ i ] . i n [ 0 ] <== i == 0 ? l e a f
s e l e c t o r s [ i ] . i n [ 1 ] <== pathElements [ i ] ;
s e l e c t o r s [ i ] . s <== p a t h I n d i c e s [ i ] ;

i ++) {

: h a s h e r s [ i − 1 ] . hash ;

h a s h e r s [ i ] = HashLeftRight ( ) ;
h a s h e r s [ i ] . l e f t <== s e l e c t o r s [ i ] . out [ 0 ] ;
h a s h e r s [ i ] . r i g h t <== s e l e c t o r s [ i ] . out [ 1 ] ;

f o r

}

r o o t === h a s h e r s [ l e v e l s − 1 ] . hash ;

// Bid v a l i d i t y check
component h a s h e r = PoseidonHashT3 ( ) ;
h a s h e r . i n p u t s [ 0 ] <== a c c o u n t ;
h a s h e r . i n p u t s [ 1 ] <== v a l u e ;
hashP <== h a s h e r . out ;
hashP === l e a f ;

component g r e a t e r = LessThan ( 1 1 ) ;
g r e a t e r . i n [ 0 ] <== v a l u e ;
g r e a t e r . i n [ 1 ] <== b i d ;

o u t V a l i d <== g r e a t e r . out ;
f i n a l B i d <== b i d ;

}

component main = B i d V e r i f i e r ( 1 6 ) ;

30

8.2.2 Decentralized Card Games

We implemented a simpliﬁed poker game to demonstrate the randomness simulation and card playing process.
The simpliﬁed game rule consists of a player drawing a card and comparing the card with the dealer’s card.
The person with the larger card number wins the game.

There are two main circuits involved in the process. The ﬁrst circuit is used to randomly and privately
draw a card. It takes in the blockhash and private seed as inputs. Using the module circuit, it is able to
divide (seed + blockhash) by 13 and uses the remainder as the card drawn. The output seedCommit can be
used to veriﬁed against the previously committed hash on chain. The output cardCommit can be used to
directly commit the new card hash on smart contract.

i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s / mimcsponge . c i r c o m ”
i n c l u d e ” . . / . . / modulus . c i r c o m ”

t e m p l a t e Main ( ) {

s i g n a l p r i v a t e i n p u t
s i g n a l

i n p u t b l o c k h a s h ;

s e e d ;

s i g n a l output cardCommit ;
s i g n a l output seedCommit ;

s i g n a l c a r d ;

component c a r d C a l c u l a t o r = Modulo ( 1 6 , 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ) ;

c a r d C a l c u l a t o r . d i v i d e n d <== s e e d + b l o c k h a s h ;
c a r d C a l c u l a t o r . d i v i s o r <== 1 3 ;

c a r d <== c a r d C a l c u l a t o r . r e ma in de r + 1 ;

component cardHash = MiMCSponge ( 1 , 2 2 0 , 1 ) ;
cardHash . i n s [ 0 ] <== c a r d ;
cardHash . k <== 0 ;
cardCommit <== cardHash . o u t s [ 0 ]

component seedHash = MiMCSponge ( 1 , 2 2 0 , 1 ) ;
seedHash . i n s [ 0 ] <== s e e d ;
seedHash . k <== 0 ;
seedCommit <== seedHash . o u t s [ 0 ] ;

}

component main = Main ( ) ;

The second circuit involves comparing the player’s card with the dealer’s card to determine the winner.
MiMC hash of the playerCard is compared with the previously committed hash. A comparator circuit is
used to determine if the playerCard is larger than the dealer’s card. It is interesting to note that the player’s
card is a private input and remains hidden throughout the game. There is no reveal step during the entire
decentralized card game.

i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s / mimcsponge . c i r c o m ”
i n c l u d e ” . . / . . / node modules / c i r c o m l i b / c i r c u i t s / c ompar ator s . c i r c o m ”

31

t e m p l a t e Main ( ) {

s i g n a l p r i v a t e i n p u t p l a y e r C a r d ;
s i g n a l
s i g n a l

i n p u t playerCardCommit ;
i n p u t d e a l e r C a r d ;

s i g n a l output outCardCommit ;
s i g n a l output o u t V a l i d ;

/∗

∗/

V e r i f y t h a t
e q u a l
i s

t h e c a l c u l a t e d hash o f x ( outCardCommit )

t o t h e i n p u t t e d hash ( playerCardCommit )

component mimc = MiMCSponge ( 1 , 2 2 0 , 1 ) ;
mimc . i n s [ 0 ] <== p l a y e r C a r d ;
mimc . k <== 0 ;

outCardCommit <== mimc . o u t s [ 0 ] ;
outCardCommit === playerCardCommit ;

/∗

∗/

V e r i f y t h a t p l a y e r c a r d i s
o u t V a l i d = 1 i f x l e s s
o u t V a l i d = 1 i f x >= t h r e s h o l d

l a r g e r
than t h r e s h o l d ;

than t h r e s h o l d

component g r e a t e r = LessThan ( 1 1 ) ;
g r e a t e r . i n [ 0 ] <== p l a y e r C a r d ;
g r e a t e r . i n [ 1 ] <== d e a l e r C a r d ;

o u t V a l i d <== g r e a t e r . out ;

}

component main = Main ( ) ;

32

References

[1] Eli Ben-Sasson et al. Zerocash: Decentralized Anonymous Payments from Bitcoin. url: http : / /

zerocash-project.org/media/pdf/zerocash-extended-20140518.pdf.

[2] Roman Storm Alexey Pertsev Roman Semenov. Tornado Cash Privacy Solution. url: https : / /

tornado.cash/Tornado.cash_whitepaper_v1.4.pdf.

[3] ZK Rollup Architecture. url: https://zksync.io/faq/tech.html#zk-rollup-architecture.
[4] Dark Forest Team. Announcing Dark Forest. url: https://blog.zkga.me/announcing-darkforest.
[5] Bryan Parno et al. Pinocchio: Nearly Practical Veriﬁable Computation.
[6] Vipul Goyal and Colin Kelly. Zero-Knowledge Proofs III. url: https://www.cs.cmu.edu/~goyal/

s18/15503/scribe_notes/lecture23.pdf.

[7] Shaﬁ Goldwasser, Silvio Micali, and Charles Rackoﬀ. “The Knowledge Complexity of Interactive Proof

Systems”. In: SIAM J. Comput. 18 (1 1989).

[8] Manuel Blum et al. NONINTERACTIVE ZERO-KNOWLEDGE*. 1991, pp. 1084–1118.

[9] Joe Kilian. A note on eﬃcient zero-knowledge proofs and arguments. (extended abstract).

[10] Silvio Micali and Siam J Comput. COMPUTATIONALLY SOUND PROOFS *. 2000, pp. 1253–1298.

url: https://epubs.siam.org/page/terms.

[11] Jens Groth, Rafail Ostrovsky, and Amit Sahai. Non-interactive Zaps and New Techniques for NIZK.

[12] Jens Groth, Rafail Ostrovsky, and Amit Sahai. New Techniques for Non-interactive Zero-Knowledge -.

2011.

[13] Jens Groth. Short Pairing-based Non-interactive Zero-Knowledge Arguments.

[14] Rosario Gennaro et al. Quadratic Span Programs and Succinct NIZKs without PCPs.
[15] What are zk-SNARKs? url: https://z.cash/technology/zksnarks/.
[16] Jens Groth. “On the Size of Pairing-based Non-interactive Arguments”. In: Advances in Cryptology –
EUROCRYPT 9666 (2016). Ed. by Marc Fischlin and Jean-S´ebastien Coron. doi: 10.1007/978-3-
662-49896-5.

[17] Circom 2 Documentation. url: https://docs.circom.io/background/background/.
[18] Vitalik Buterin. Quadratic Arithmetic Programs: From Zero to Hero. url: https://medium.com/

@VitalikButerin/quadratic-arithmetic-programs-from-zero-to-hero-f6d558cea649.

[19] Jim Lambers. Lagrange Interpolation. url: https://www.math.usm.edu/lambers/mat772/fall10/

lecture5.pdf.

[20] Vitalik Buterin. Zk-SNARKs: Under the Hood. url: https://medium.com/@VitalikButerin/zk-

snarks-under-the-hood-b33151a013f6.

[21] Ariel Gabizon. Explaining SNARKs Part VI: The Pinocchio Protocol. url: https://electriccoin.

co/blog/snark-explain6/.

[22] Zcash Protocol Speciﬁcation. url: https : / / github . com / zcash / zips / blob / main / protocol /

protocol.pdf.

[23] Paige Peterson. Anatomy of a Zcash Transaction. url: https://electriccoin.co/blog/anatomy-

of-zcash/.

[24] Ariel Gabizon. How Transactions Between Shielded Addresses Work. url: https://electriccoin.co/

blog/zcash-private-transactions/.

[25] Ethereum Foundation. Validium. url: https : / / ethereum . org / en / developers / docs / scaling /

validium/.

33

[26] Vitalik Buterin. Incomplete Guide to Rollups. url: https://vitalik.ca/general/2021/01/05/

rollup.html.

[27] Alex Gluchowski. zkEVM. url: https://www.youtube.com/watch?v=6wLSkpIHXM8.
[28] Trail of Bits. Ethereum Opcodes. url: https://github.com/crytic/evm-opcodes.
[29] Danny Nelson and Eli Tan. ConstitutionDAO Outbid for First Printing of America’s Founding Document
in Sotheby’s Auction. url: https : / / www . coindesk . com / tech / 2021 / 11 / 19 / constitutiondao -
outbid-for-first-printing-of-americas-founding-document-in-sothebys-auction/.

[30] Etherscan. url: https://etherscan.io/.
[31] Mattison Asher and Coogan Brennan. Zero Knowledge Proofs: STARKs vs SNARKs. url: https:
//consensys.net/blog/blockchain-explained/zero-knowledge-proofs-starks-vs-snarks/.
[32] Zooko Wilcox. The Design of the Ceremony. url: https://electriccoin.co/blog/the-design-of-

[33]

the-ceremony/.
zk-SNARKs and zk-STARKs Explained. url: https://academy.binance.com/en/articles/zk-
snarks-and-zk-starks-explained.

[34] Alessandro Chiesa. An overview of Recursive SNARKs. url: https://www.youtube.com/watch?v=

[35]

_XwMgSUN8cE.
Izaak Meckler. Inductive Proof Systems and Recursive SNARKs. url: https://zkproof.org/2020/
06/08/recursive-snarks/.

[36] Lance Fortnow. “COMPLEXITY OF PERFECT ZERO-KNOWLEDGE.” In: Conference Proceedings
of the Annual ACM Symposium on Theory of Computing (1987), pp. 204–209. issn: 07349025. doi:
10.1145/28395.28418.

[37] Lorenzo Grassi et al. POSEIDON: A New Hash Function for Zero-Knowledge Proof Systems. 2020.

url: https://github.com/shamatar/poseidon_hash.

34

