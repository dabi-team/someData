1

Self-Supervised and Interpretable Anomaly
Detection using Network Transformers

Daniel L. Marino 1, Chathurika S. Wickramasinghe 1, Craig Rieger 2, Milos Manic 1
1 Virginia Commonwealth University, Richmond, VA, USA
2 Idaho National Laboratory, Idaho Falls, Idaho, USA
marinodl@vcu.edu, brahmanacsw@vcu.edu, craig.rieger@inl.gov, misko@ieee.org

2
2
0
2

b
e
F
5
2

]

G
L
.
s
c
[

1
v
7
9
9
2
1
.
2
0
2
2
:
v
i
X
r
a

Abstract—Monitoring trafﬁc in computer networks is one
of the core approaches for defending critical
infrastructure
against cyber attacks. Machine Learning (ML) and Deep Neural
Networks (DNNs) have been proposed in the past as a tool to
identify anomalies in computer networks. Although detecting
these anomalies provides an indication of an attack, just detecting
an anomaly is not enough information for a user to understand
the anomaly. The black-box nature of off-the-shelf ML models
prevents extracting important information that is fundamental to
isolate the source of the fault/attack and take corrective measures.
In this paper, we introduce the Network Transformer (NeT), a
DNN model for anomaly detection that incorporates the graph
structure of the communication network in order to improve
interpretability. The presented approach has the following ad-
vantages: 1) enhanced interpretability by incorporating the graph
structure of computer networks; 2) provides a hierarchical set of
features that enables analysis at different levels of granularity;
3) self-supervised training that does not require labeled data.
The presented approach was tested by evaluating the successful
detection of anomalies in an Industrial Control System (ICS). The
presented approach successfully identiﬁed anomalies, the devices
affected, and the speciﬁc connections causing the anomalies,
providing a data-driven hierarchical approach to analyze the
behavior of a cyber network.

Index Terms—Anomaly Detection, Self-Supervised learning,
Interpretable Machine Learning, Transformers, Cybersecurity.

I. INTRODUCTION
The use of Information and Communication Technologies
(ICTs) in Industrial Control Systems (ICSs) has been driven by
the need for better efﬁciency and connectivity [1]. However,
ICTs have also opened the door to cyber criminals, harming
security and resilience [2]. Network trafﬁc monitoring is one
of the core technologies for maintaining a secure and reliable
network. As such, it is a valuable asset to secure critical
infrastructure that relies on ICTs.

Figure 1 shows an example of using ML for network trafﬁc
monitoring in an ICS network [1], [3], [4]. In this example, a
packet-sniffer is connected to a switch in order to monitor the
communication between devices in the network. The sniffer is
connected to a switch port analyzer (SPAN port). All incoming

This work was supported in part by the Department of Energy through the
U.S. DOE Idaho Operations Ofﬁce under Contract DE-AC07-05ID14517, in
part by the Resilient Control and Instrumentation Systems (ReCIS) Program
of Idaho National Laboratory
This work was supported in part by the Commonwealth Cyber Initiative,
an investment in the advancement of cyber R&D, innovation and workforce
development. For more information about CCI, visit cyberinitiative.org.

Preprint. Under review.

Fig. 1: Anomaly detection in network trafﬁc monitoring

and outgoing communication passing through the switch is
mirrored to the SPAN port, allowing the packet sniffer to
have access to all packets communicated through the switch.
The data acquired by the sniffer is analysed in order to ﬁnd
anomalies. The data is processed ﬁrst by performing packet
dissection. A rolling window is used to analyze sections of
the data, extracting a series of manually engineered features
to be used as inputs to ML anomaly detection systems. The
normal behavior of the system is learned by ML algorithms
such that any behaviors that are different from previously seen
data are ﬂagged as anomalies.

Existing approaches demonstrate the capability of ML mod-
els to identify abnormal cyber behavior [3], [5]–[7]. However,
these approaches often lack the interpretability of the results as
they only report an anomaly without any further information
about the source or cause of the anomaly. This is an issue,
specially if the approach is applied in monitoring applications.
Reporting the detection of an anomaly alone does not provide
enough information for an operator to isolate the source of the
problem and plan corrective measures. Many off-the-shelf ML
models used for anomaly detection follow a black-box design,
where the inner workings of the model are usually not under-
stood by the user [8]. Running these models without taking
advantage of the structure in the data leads to approaches that
obfuscate exploratory analysis. Designing an approach that not
only detects anomalies but also aids on exploratory analysis
is fundamental for improving interpretability. Preserving the
graph structure of the problem provides a representation that

Packet dissectionSPAN portData preprocessing /Feature extractionAnomaly detectionSwitchAttackcomputerWorkstationField deviceGridData historian/HMIField deviceField devicePacket sniffer 
 
 
 
 
 
2

Type

Feature

Description

Binary
Binary
Binary
Binary
Binary
Categorical

direction
tcp syn
tcp ack
tcp psh
tcp urg
protocol

Categorical

service

Numerical
Numerical

len
delta time

Numerical
Numerical
Numerical
Numerical
Numerical
Numerical
Numerical

source port
dest. port
tcp seq
tcp ttl
tcp window
port 22 len
port 23 len

Direction of the packet: 0 for i to j, 1 for j to i.
TCP SYN ﬂag
TCP acknowledgment ﬂag.
TCP push function.
TCP urgent ﬂag.
Layer of communication: ARP, IP, IPv6, TCP, or
UDP.
Service (inferred from port used): DNP3, ftp,
http, git, telnet, ssh, x11, etc.
Size (number of bytes) of the packet.
Difference in seconds between current packet and
previous packet.
Port used by the source device.
Port used by the destination device.
TCP sequence number.
TCP time to live.
TCP window.
Size of the packet (bytes) when using port 22.
Size of the packet (bytes) when using port 23.

TABLE I: Packet features when using TCP dissection.

Type

Feature

Description

Binary
Categorical

direction
protocol

Numerical
Numerical

len
delta time

Numerical

bytes

Direction of the packet: 0 for i to j, 1 for j to i.
Layer of communication: ARP, IP, IPv6, TCP, or
UDP.
Size (number of bytes) of the packet.
Difference in seconds between current packet and
previous packet.
List of bytes extracted from the packet (0-512).

TABLE II: Packet features when using raw Bytes.

for anomaly detection. The hierarchical features include global
features representing the entire graph, node features repre-
senting each node, and edge features representing individual
connections. The approach uses Transformer Neural Networks
[9], which are currently the state-of-the-art ML model for
sequence modeling tasks. The hierarchical network features
introduced in this paper are inspired by Graph Networks [10].
The following subsections will expand the description of each
one of the aforementioned components.

A. Graph packet dissection

The approach starts by dissecting packet windows in order
to identify the source and destination addresses. Packets are
grouped by their respective source-destination pairs. A graph is
constructed where each node represents an IP address. Edges
consist of the list of packets communicated between nodes.
Each packet is dissected in order to create an initial feature
representation that is suitable for a ML model. We considered
two sets of features: TCP features and raw Byte features.
TCP features are presented in table I. Raw Byte features are
presented in table II.

B. Embedded packet representations, Transformer, and self-
supervised training

The Transformer Neural Network model is presented in
Figure 4. We use the Transformer as it is the current state-of-
the-art model for sequence modeling. The Transformer uses
attention layers that allow capturing long-range dependencies
directly [11]. Attention layers also improve the efﬁciency
of the training algorithm as sequences can be processed in
parallel; this is in contrast to LSTM and GRU models whose

Fig. 2: A graph model allows to provide an abstract represen-
tation that is shared between human and machine

opens the door for better interpretability and diagnosis.

This paper presents the Network Transformer (NeT), a
ML model that uses graph representations to improve the
interpretability of anomaly detection in network trafﬁc moni-
toring. The presented model allows to identify anomalies while
also providing a series of hierarchical features that allow to
identify devices affected by the anomalies and the connections
responsible for the anomalies. The approach leverages self-
supervised learning to train the model using unlabeled data.
A multi-processing pipeline is presented as a prototype for
scalability to large datasets. The rest of the paper is organized
as follows: section II describes the presented Network Trans-
former approach; section III presents the experimental evalu-
ation; section IV presents related work; section V concludes
the paper.

II. INTERPRETABLE ANOMALY DETECTION: NETWORK
TRANSFORMER

In order to create an interpretable model for anomaly
detection, we design an approach that leverages the graph
structure of computer networks. As shown in Figure 2, the
idea is to have an abstract model of the problem that
is
shared by the human and the machine learning model. The
abstract model in this case is the graph representation of
the computer network being monitored. By embedding this
abstract model into the ML approach, we are able to leverage
our understanding of the system as a graph in order to extract
useful information about the anomalies detected in the system.
Figure 3 shows the overview of the presented Network
Transformer (NeT) approach. The approach consists of: a)
a packet dissector that groups packages by their respective
source and destination addresses; b) an embedded representa-
tion obtained using a Transformer Neural Network; c) an Ag-
gregator that extracts a series of hierarchical network features
that represent the communication graph. The features extracted
by the NeT model are fed to anomaly detection algorithms
to identify anomalies at different levels of granularity. The
approach uses the IP address of the devices in the network
to represent the nodes in a graph. The packets communicated
between the devices are used to represent the edges of the
graph. The hierarchical network features are ultimately used

MachineLearningAbstract ModelHuman3

Fig. 3: Diagram of the presented Network Transformer (NeT) model. The model allows the extraction of a series of hierarchical
network features to represent the monitored computer network as a graph.

network to extract packet features zn from the edges of the
graph II-A.

As shown in Figure 4, the model is composed of four types

of layers:

• Linear: applies an afﬁne transformation f (x) = W x + b
of the input using a weight matrix W and a bias vector
b.

• Feed Forward: applies an non-linear transformation using
stacked layers f (x) = σ(W x+b) where σ is an activation
function. We use the ReLU activation function.

• Add & Norm: this layer adds a residual connection [13]

followed by Layer Normalization [14].

• Multi-Head Attention: this layer consists of several scaled
dot-product attention models that evaluate the input in
parallel. The scaled dot-product attention is a function
that performs an evaluation of a query matrix (Q) over a
series of key (K) value (V ) matrices:

Attention(Q, K, V ) = softmax

(cid:18) QK T
√
dz

(cid:19)

V

where dz is the dimension of the encoded feature rep-
resentations, which is speciﬁed when instantiating the
Transformer model.

Figure 4 shows W 0, which is a vector used at the beginning
of the target sequence to shift the position of the packets on
the right. Shifting the input to the right allows the Decoder to
predict the next packet given the series of previously predicted
symbols, making the Transformer model auto-regressive [9].
In our implementation, the vector W 0 is a trainable parameter
that is learned when training the Transformer model. The po-
sition encoding in Figure 4 uses the sine and cosine functions
presented in [9].

The loss function in Figure 4 is used to evaluate the
performance of the Transformer network to predict the fu-
ture window of packets. As shown in Tables I and II, the
packets are represented by a series of binary, categorical, and
numerical values. We use this distinction to evaluate the loss
depending on the type of the predicted value. Numerical values
use a quadratic loss, while binary and categorical values use
a cross-entropy loss.

Fig. 4: Transformer model and self-supervised training.

inherently sequential nature precludes parallelization [9]. We
use a modiﬁed version of the Transformer model presented in
[9], which was originally used to train language models. Like
a sentence is composed of a sequence of words, the edges in
our network are composed of a sequence of packets. Thus, we
use the Transformer to encode the list of packets pk in each
edge to a latent representation z(i,j).

The Transformer model used in this work is trained using
a self-supervised learning approach [12]. The Transformer is
trained to predict the next n packets (unobserved) given the
sequence of past k packets (observed). As shown in Figure
4, the Transformer consists of an Encoder-Decoder network.
The Encoder network encodes the input packets into a set
of embedded representations that are used by the decoder to
predict a series of future packets. This approach allows us to
leverage unlabeled data as the input-output packet sequence
can be extracted by dividing unlabeled packet windows into
two. Once the Transformer is trained, we use the Encoder

12431243TransformerAggregatorAnomaly Detectiona) Graph packet dissectionb) Embedded representationc) Hierarchical network featuresLossLinearPositionalEncodingLinearMulti-HeadAttentionAdd & NormFeedForwardAdd & NormPositionalEncodingMaskedMulti-HeadAttentionAdd & NormMulti-HeadAttentionAdd & NormFeedForwardAdd & NormLinearvsEmbedded  packetrepresentationEncoderDecoderInput packetfeature windowFuture packetfeature window4

Transformer model, the hierarchical graph features provide
a structure that is easy to understand. This structure can be
exploited in order to extract information such as devices and
connections involved in an anomaly.

D. Scalability

Network packet data is often characterized by a very high
volume of samples. Attacks such as network scans and DOS
often ﬂood the computer network with a high volume of
packets. As a result, ML algorithms need to be designed in
order to handle large quantities of data. Performing the graph
packet dissection and training of the Network Transformer
required the development of a multiprocessing pipeline in
order to scale to these types of datasets.

Figure 6 shows the developed multiprocessing pipeline used
to train the Network Transformer. The pipeline pre-processes a
series of packet capture ﬁles (PCAP) into a series of features
formatted as tensors (multi-dimensional arrays), ready to be
consumed by Tensorﬂow. The ﬁrst stage consists of extracting
windows of consecutive raw packets using a rolling window.
In our case, we used a window of 30 seconds, but this can
be tuned depending on the application. The second processing
stage consists of TCP/UDP dissection, which groups packets
by the source-destination IP address. The third processing
stage extracts features according to tables I and II. These
features are grouped using the source-destination address and
then packaged in a tensor representation. These tensor feature
representations are then managed by Tensorﬂow-Datasets, a
library that creates a cache of the pre-processed values in
order to be consumed efﬁciently when training the Network
Transformer. The training uses Stochastic Gradient Descent,
more speciﬁcally the ADAM algorithm [15], which scales to
very large datasets. Once the NeT is trained, the features can
be used for downstream ML operations without re-training
the model. The pre-processing pipeline in this work was
implemented using Python multiprocessing library, but the
same approach can be horizontally scaled with libraries such
as Hadoop or Spark.

III. EXPERIMENTS

This section presents the experimental analysis of the Net-
work Transformer. We used packet captures from a real ICS
system to evaluate the performance of the presented Network
Transformer approach. We evaluate the performance on an
anomaly detection task and the ability of the model to provide
an indication of devices and connections related to an anomaly.

A. Data Collection

The presented approach was evaluated using a dataset of
packet captures collected in an ICS. The data was provided
by Idaho National Laboratory (INL). The ICS network is
presented in Figure 7. The network is composed of two attack
computers, two protection relays, one power quality meter,
one real-time automation controller (RTAC), one satellite
synchronized network clock, and one SCADA PC. All devices
are connected using two network switches. The RTAC is using

Fig. 5: Hierarchical graph features: Global, Node, and Edge
features.

C. Hierarchical Graph Features

Figure 5 shows the hierarchical graph features used to repre-
sent the monitored network. The graph features are computed
on encoded packet windows obtained with the Transformer
encoder. A packet window is a list of packets obtained during
a speciﬁed time window (30 seconds in this paper). The
hierarchical graph features consist of: global, node, and edge
features. The speciﬁcation of the features is inspired by Graph
Nets [10]. To compute the features, we start with encoded
packet features zn, which are obtained using the Encoder
from the Transformer model (see Fig. 4). Edge features e(i, k)
represent individual connections between devices. The value
of e(i, k) is obtained by summing the list of encoded packets
zn communicated between nodes i and k. Node features are
obtained by summing the Edge feature values e(i,k) attached
to the node. Global features u are obtained by summing all
Edge features in the graph.

The graph features represent the computer network in a
given time window. They represent the network in different
layers of abstraction, using a format that is easy to interpret
and exploit in order to extract information. We train anomaly
detection algorithms for each level of abstraction (global,
nodes, edges) in order to detect anomalies and extract infor-
mation in different levels of granularity. The algorithms are
trained using only data collected during the normal operation
of the system. In this paper, we consider three anomaly
detection algorithms: Local Outlier Factor (LOF), One-Class
SVM (OCSVM), and Autoencoders (AE).

Global features provide the highest level of abstraction by
representing the entire network for a given window of packets.
Global features provide a way to identify anomalies effectively
without dealing directly with individual nodes or connections.
This serves as the ﬁrst indication of anomalous behavior that
considers the network as a whole.

Node features are used to characterize the behavior of
individual devices. They provide the next level of abstraction
after global features. After an anomaly is detected with the
global features, node features are used to identify the devices
involved in the anomalous event. Edge features provide the
next level of abstraction after Node features. Edge features
allow us to identify exactly which connections are exhibiting
anomalous behavior. Even when we are using a complex DNN

Hierarchical GraphFeaturesGlobal features: - Represent the entire graph.  - Used as first line ofindication for anomalydetection.Node features:  - Represent individualdevices.  - Used to identify devicesaffected by an anomaly.Edge features:  - Represent individualconnections between devices.- Used to identify anomalousconnections between devices.5

Fig. 6: Data pre-processing pipeline

Fig. 7: ICS testbed used to collect data. Testbed and data
collection operated by POWER Engineers Inc.

the DNP3 protocol to communicate with the relays, the meter,
and the SCADA PC. A sniffer is connected to a SPAN port
in the switch. The SPAN port forwards all the packet data
passing through the switch to the sniffer, which stores the
data in PCAP ﬁles for later analysis. In total, the collected
data consisted of 6.036.046 packets.

For experimental evaluation, ﬁve types of scenarios were

considered:

• Normal scenario: Consist of normal operation of the
system without any cyber disturbance/attack executed.
• Flood attack: Launches a ﬂood of packets using hpin3
command with random source IP address. The attack is
launched from the PC1 attack device. The attack targets
Relay 1 and Relay 2.

• Scan attack: Launches a network scan using nmap. The
attack is launched from the PC1 attack device. The attack
targets Relay 1 and Relay 2. Two attacks are launched.
The ﬁrst attack consists of a nmap OS ﬁngerprint scan.
The second attack launches a TCP SYN port scan.

• Failed Authentication: An unauthorized user attempts to
access remote devices, failing to get access after three
attempts. The scenario is launch from PC2 and targets
Relay 1 and Relay 2 through ssh and telnet. After three
unsuccessful login attempts, the relays pulse a series of
alarms that are communicated through DNP3.

• Setting change: An unauthorized user successfully ac-
cesses Relays 1 and 2 from PC2 and makes changes in
the settings of each device. The setting changes include
changing the current transformer ratio, phase instanta-
neous overcurrent level, and relay trip equations. When
the user logs into the device, the relay pulses an alarm

Fig. 8: Global features visualized using the T-SNE algorithm

which is communicated through DNP3 to the RTAC
device. After the setting change is executed, the relay
pulses another alarm which is also communicated through
DNP3.

B. Global features: anomaly detection

As described in section II-C, global features are used to
characterize the behavior of the entire network. Figure 8 shows
a visualization of the NeT global features. The visualization
is obtained with the T-SNE algorithm [16]. The ﬁgure shows
each anomaly scenario (red) along with data from normal
operations (blue). The ﬁgure provides a visual reference of
how different each scenario is with respect to the normal
behavior of the system. We observe that features from ﬂood
and scan scenarios are signiﬁcantly different from normal
behavior. Failed authentication and setting change have more
subtle differences from normal data. This behavior follows our
expectations as ﬂood and scan attacks have a large impact on
the network as both introduce a large volume of packets. This
visual representation of the global features serves as an initial
understanding of the data, providing a tool to understand the
similarity between different scenarios.

Table III shows the anomaly detection results obtained with
the NeT global features. Three anomaly detection algorithms
were considered in this analysis: Local Outlier Factor (LOF),
One-Class SVM (OCSVM), and Autoencoder (AE). These

Raw packetreaderRollingwindowTCP/UDP dissectiongroup packets bysource-destination Worker 1Worker 2Worker 3Worker 4Tensorflow-Datasets(TFDS) QueueCached data (TFDS)Network TransformerTraining Batching andNormalizationWorker 1Worker 2Worker 3Worker 4TCP/UDP dissectionGroup packets bysource-destinationQueueFeature extraction  Tensor representationPCAP  filesPre-processingTrainingPC1AttackPC2AttackSwitchSwitchMeter: PowerQuality Relay 1:Protectionand control  Packet-snifferSCADA PCClock: Satellite-SynchronizedNetwork Clock Relay 2:Protection andcontrolRTAC:  Real-TimeAutomationControllerSPANportPCAPfiles100500501001007550250255075100FloodNormal100500501001007550250255075100ScanNormal100500501001007550250255075100FailedAuthenticationNormal100500501001007550250255075100SettingChangeNormal6

FPR train

FPR test

ADR

Flood

Failed Auth

Scan

Setting Change

Baseline LOF
Baseline OCSVM
Baseline AE

NeT-LOF
NeT-OCSVM
NeT-AE

NeTB-LOF
NeTB-OCSVM
NeTB-AE

0.0931
0.0998
0.0092

0.0896
0.1005
0.0036

0.0907
0.1001
0.0097

0.1009
0.1062
0.0363

0.1010
0.1046
0.0336

0.1019
0.1001
0.0327

0.7486
0.7023
0.6923

0.8232
0.5124
0.8249

0.8471
0.2341
0.8339

0.8855
0.8655
0.8648

0.9270
0.7954
0.9609

0.9514
0.2805
0.9670

0.3791
0.3059
0.2934

0.3677
0.2495
0.2848

0.3465
0.2495
0.1980

0.8439
0.8105
0.7915

0.8423
0.1131
0.8492

0.8634
0.1099
0.8539

0.7063
0.6267
0.616148

0.6090
0.2732
0.5128

0.6634
0.2804
0.599073

TABLE III: False Positive Rate (FPR) and Anomaly Detection Rate (ADR) for Network Transformer (NeT) model.

anomaly detection algorithms run on top of the NeT global
features. The baseline uses the same three anomaly detection
algorithms, but it considers a series of hand-engineering sta-
tistical features found in the literature [4], [17]. These features
are computed across packet windows of 30 seconds. NeT
refers to the Network Transformer using the TCP features from
Table I. NeTB refers to the Network Transformer using the raw
Bytes features from Table II. NeT and NeTB report anomalies
detected using packet windows of 30 seconds as well. The
AE model uses the reconstruction error to identify anomalies
[4]. The table shows the performance measured using False
Positive Ratio (FPR) and Anomaly Detection Ratio (ADR).
Results are measured using 5-fold cross-validation. The FPR
measures the rate of anomalies for normal scenarios. The ADR
measures the rate of anomalies during attack scenarios. We
report ADR measured across all scenarios and for each attack
scenario separately. Values of FPR closer to zero and high
values of ADR indicate better anomaly detection performance.
It is worth clarifying that the ADR may not necessarily be
one, as the anomalous scenarios contain a mix of normal and
abnormal data [4].

When looking at the overall results presented in Table III,
AE provided the lowest FPR while achieving comparable ADR
performance. NeTB and NeT provided slightly better FPR with
higher ADR when compared with the baseline. We observed
a higher ADR for Flood and Scan scenarios using NeTB and
NeT models. However, the baseline provided a slightly better
performance on failed authentication and setting change sce-
narios. NeT-AE and Baseline-AE provided comparable results
for failed authentication, with NeTB-AE providing the lowest
performance. For setting change, NeTB-AE and Baseline AE
provided comparable results, with NeT-AE having the lowest
performance in this scenario. The baseline and the NT models
have speciﬁc features indicating activity on ssh and telnet,
which helps to explain why they perform better in the failed
authentication scenario. On the other hand, setting change is
characterized by larger payloads than failed authentication,
which helps to explain the better performance of NeTB as
it includes the raw 512 bytes of the payload.

Table III shows that the presented NeT and NeTB models
provide comparable or better performance in anomaly de-
tection than the baseline. Furthermore, the baseline has no
mechanisms to explore which devices and connections are
involved in the anomalies. The following experiments show the
capability of NeT to provide an indication of devices affected

Fig. 9: Anomalies in each device. Anomalies are obtained
using an AE with NeT node features.

and anomalous connections using the Node and Edge features.
Given the leading performance of AE over LOF and OCSVM,
the following sections use AE for all experiments.

C. Node features: Identify devices affected

Node features are used to characterize the behavior of each
device in the network. These features can be used to identify
the devices affected by an anomaly. Figure 9 shows the results
of devices affected obtained by analyzing the Node features.
The ﬁgure shows the number of anomalies per device for each
one of the attack scenarios.

First, we observe that the presented approach is able to
recognize which PC is launching the attack. As described in
section III-A, Flood and Scan attacks are launched by PC1
while Failed authentication and Setting Change are launched
by PC2. Figure 9 clearly shows a high anomaly rate for PC1
in Flood and Scan scenarios while PC2 shows no anomaly.
For Failed authentication and Setting Change, PC2 shows a
high anomaly rate while PC1 shows no anomalies. Figure 9
also shows a high anomaly ratio for Relay1 and Relay2. These
relays are the devices targeted by the attacker, evidencing how

PC1 AttackPC2 AttackMeterRelay 1RTACRelay 2ClockSCADA PC0100200300400500Anomalies per noded) Setting ChangePC1 AttackPC2 AttackMeterRelay 1RTACRelay 2ClockSCADA PC0250500750100012501500Anomalies per nodeb) ScanPC1 AttackPC2 AttackMeterRelay 1RTACRelay 2ClockSCADA PC020040060080010001200Anomalies per nodea) FloodPC1 AttackPC2 AttackMeterRelay 1RTACRelay 2ClockSCADA PC020406080100120Anomalies per nodec) Failed Auth.7

layers thanks to the graph structure embedded in the presented
approach. Thanks to the equivalence between the learned graph
representation and the real device network communication, it
is easy for an expert to exploit the learned model in order to
extract useful and more detailed information.

IV. RELATED WORK
Anomaly detection refers to identifying patterns in data
which does not confront the expected behavior of a system
[18]. Anomaly detection can be addressed in many different
forms such as out-of-distribution detection, outlier detection,
and novelty detection [19], [20]. A common approach for
anomaly detection in computer networks is to use unsuper-
vised ML models with features extracted from log ﬁles, includ-
ing network trafﬁc, kernel logs, SCADA logs, among others
[6], [7]. Hand engineered statistical and temporal features are
also commonly used as an input to ML anomaly detection
algorithms [1], [4], [21].

This paper used three unsupervised ML algorithms to
perform anomaly detection from the Network Transformer
hierarchical features. These algorithms are One-Class Support
Vector Machines (OCSVMs), Local Outlier Factor (LOFs),
and Autoencoders (AEs). The main reason for using these
they do not require labeled data.
three algorithms is that
The labeling process is expensive, requires expertise on the
data itself, and in the case of anomaly detection, it requires
abnormal data, which is in many scenarios very hard to obtain
[4], [22], [23]. OCSVMs are extensions of Support Vector
Machines (SVMs) [24], [25]. They have been successfully
used in anomaly detection for network trafﬁc [1], [26]. LOF
has also been extensively used in anomaly detection for cyber-
physical systems [27]–[29]. Autoencoders (AEs) are a popular
Neural Network architecture. They have been successfully
used in several anomaly detection applications as well [30],
[31].

Self-supervised learning has increasingly gained attention
for Out of Distribution (OoD) detection [32]–[34]. OoD is
a problem closely related to anomaly detection, where the
objective is to detect samples that do not belong to the
distribution of a given dataset. One such example is presented
in [32], where authors perform contrastive learning alongside
OCSVM to detect OoD samples.

Explainable AI is another area that has gained attention in
recent years [35]. LIME and SHAP [36], [37] are popular
algorithms that can be used to perform local explanations
of Transformer models. Incorporating domain knowledge in
the inductive bias of ML algorithms is another approach to
improve interpretability [38] Graph nets provide a ﬂexible
approach to embed relational inductive bias in ML [10]. Graph
Neural Networks (GNNs) have been recently proposed to learn
the structure of existing relationships between variables while
performing anomaly detection in time-series sensor data [39].
GNNs have also been proposed to identify anomalous edges
in dynamic graphs [40].

V. CONCLUSION
This paper presented the Network Transformer, a ML
model that uses graph-based representations to incorporate

Fig. 10: Anomalous connections inspected with the NeT
model. Anomalies are detected using AE on NeT edge fea-
tures.

the presented approach is able to detect the devices being
targeted.

Figure 9 also shows a high number of anomalies for the
RTAC device during Failed authentication and Setting Change.
Although the RTAC device was not targeted by the cyber
attacks, the relays communicate with the RTAC whenever
there is a failed authentication or a setting change. This
communication happens using the DNP3 protocol, and it is
described in section III-A. This is an interesting observation
because it shows how the presented approach not only detects
the attacker and target devices but also detects side effects
from the attack.

D. Edge features: Identify anomalous connections

Edge features are used to characterize each connection
between devices in the network. By running anomaly detection
on the Edge features, we are able to identify the connections
responsible for an anomaly. Figure 10 shows the results
of anomalous connections obtained by analyzing the Edge
features. The ﬁgure shows that the presented approach is able
to identify the connections responsible for the anomalies. For
the Flood and Scan scenarios, we observe that the approach
successfully reports the anomalous connections between the
attacker (PC1) and the relays. For Failed Authentication and
Setting Change, the presented approach is able to identify that
the anomalous connections involve PC2 and the relays.

Figures 8, 9, and 10 demonstrate how the presented ap-
proach allows to extract information from several abstraction

0250500750Anomalies per connection(other, other)(RTAC, SCADA PC)(Relay 1, RTAC)(Meter, RTAC)(RTAC, other)(Relay 2, RTAC)(Relay 1, PC2 Attack)(Relay 2, PC2 Attack)d) Setting Change(PC2 Attack, other)050010001500Anomalies per connection(RTAC, SCADA PC)(Relay 1, RTAC)(RTAC, other)(Meter, RTAC)(Relay 2, RTAC)(Relay 2, PC1 Attack )(Relay 1, PC1 Attack )b) Scan0250500750Anomalies per connection(Relay 1, RTAC)(Relay 1, PC2 Attack )(RTAC, SCADA PC)(RTAC, other)(Meter, RTAC)(Relay 2, RTAC)(Relay 1, PC1 Attack )(Relay 2, PC1 Attack )a) Flood0100200Anomalies per connection(RTAC, SCADA PC)(Meter, RTAC)(PC2 Attack , other)(other, other)(Relay 2, RTAC)(Relay 1, RTAC)(Relay 1, PC2 Attack )(Relay 2, PC2 Attack )c) Failed Auth.the structure of a monitored computer network. The presented
model uses self-supervised learning in order to train the model
without the need for labeled data. The Network Transformer
provides an approach to extract a series of hierarchical graph
features for down-stream ML analysis. In this paper, we
demonstrated the use of the extracted hierarchical features
for anomaly detection. The Network Transformer successfully
identiﬁed anomalies in an ICS network while being able to
report devices affected and connections compromised, demon-
strating its ability for enhanced interpretability by facilitating
the extraction of more detailed information about the anoma-
lies.

The presented approach provided an end-to-end differen-
tiable model for analysing network packet data, starting from
potentially raw byte values up to a global representation
of the network graph. Although we used a complex DNN
Transformer, the hierarchical design of the approach allows
to backtrack and analyze the predictions of the model
in
different levels of granularity. In the experimental evaluation
we demonstrated this analysis starting from a global repre-
sentation followed by an analysis of individual nodes and
connections. The presented analysis demonstrates how the
graph structure can be exploited to not only identify anomalies
but extract useful information of what devices the anomaly
is affecting and which connections are responsible for the
anomaly. Because the Transformer Encoder processes potential
raw binary data, the approach can be used as a uniﬁed end-to-
end methodology for network trafﬁc monitoring that goes from
a global view up to individual bytes. Future work will explore
the use of existing explainable algorithms such as LIME or
SHAP to provide explanations at the packet and possibly byte
level.

REFERENCES

[1] D. L. Marino, C. S. Wickramasinghe, V. K. Singh, J. Gentle, C. Rieger,
and M. Manic, “The virtualized cyber-physical testbed for machine
learning anomaly detection: A wind powered grid case study,” IEEE
Access, vol. 9, pp. 159 475–159 494, 2021.

[2] B. Vaagensmith, V. K. Singh, R.

Ivans, D. L. Marino, C. S.
Wickramasinghe, J. Lehmer, T. Phillips, C. Rieger, and M. Manic,
“Review of design elements within power infrastructure cyber–physical
test beds as threat analysis environments,” Energies, vol. 14, no. 5,
2021. [Online]. Available: https://www.mdpi.com/1996-1073/14/5/1409
[3] D. Marino, C. Wickramasinghe, K. Amarasinghe, H. Challa, P. Richard-
son, A. Jillepalli, B. Johnson, C. Rieger, and M. Manic, “Cyber and
physical anomaly detection insmart-grids,” in IEEE Resilience Week
(RW) 2019. ACM, 2019.

[4] D. L. Marino, C. S. Wickramasinghe, B. Tsouvalas, C. Rieger, and
M. Manic, “Data-driven correlation of cyber and physical anomalies
for holistic system health monitoring,” in IEEE ACCESS.
IEEE, 2021.
[5] D. L. Marino, C. S. Wickramasinghe, C. Rieger, and M. Manic, “Data-
driven stochastic anomaly detection on smart-grid communications using
mixture poisson distributions,” in IECON 2019-45th Annual Conference
of the IEEE Industrial Electronics Society, vol. 1.
IEEE, 2019, pp.
5855–5861, ©2019 IEEE.

[6] Z. Zhao, C. Xu, and B. Li, “A lstm-based anomaly detection model for
log analysis,” Journal of Signal Processing Systems, vol. 93, no. 7, pp.
745–751, 2021.

[7] F. Skopik, M. Landauer, M. Wurzenberger, G. Vormayr, J. Milosevic,
J. Fabini, W. Pr¨uggler, O. Kruschitz, B. Widmann, K. Truckenthanner
et al., “synergy: Cross-correlation of operational and contextual data to
timely detect and mitigate attacks to cyber-physical systems,” Journal
of Information Security and Applications, vol. 54, p. 102544, 2020.

[8] D. Gunning, “Explainable artiﬁcial

intelligence (xai),” Defense Ad-

vanced Research Projects Agency (DARPA), nd Web, vol. 2, 2017.

8

[9] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, L. u. Kaiser, and I. Polosukhin, “Attention is all you
Information Processing Systems,
need,” in Advances
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates,
Inc., 2017.
[Online]. Available: https://proceedings.neurips.cc/paper/
2017/ﬁle/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf

in Neural

[10] P. Battaglia, J. B. C. Hamrick, V. Bapst, A. Sanchez, V. Zambaldi,
M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner,
C. Gulcehre, F. Song, A. Ballard, J. Gilmer, G. E. Dahl, A. Vaswani,
K. Allen, C. Nash, V. J. Langston, C. Dyer, N. Heess, D. Wierstra,
P. Kohli, M. Botvinick, O. Vinyals, Y. Li, and R. Pascanu, “Relational
inductive biases, deep learning, and graph networks,” arXiv, 2018.
[Online]. Available: https://arxiv.org/pdf/1806.01261.pdf

[11] X. Wang, R. Girshick, A. Gupta, and K. He, “Non-local neural net-
works,” in Proceedings of the IEEE conference on computer vision and
pattern recognition, 2018, pp. 7794–7803.

[12] X. Liu, F. Zhang, Z. Hou, L. Mian, Z. Wang, J. Zhang, and J. Tang,
“Self-supervised learning: Generative or contrastive,” IEEE Transactions
on Knowledge and Data Engineering, 2021.

[13] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.

[14] J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,” arXiv

preprint arXiv:1607.06450, 2016.

[15] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
in 3rd International Conference on Learning Representations (ICLR),
May 2015.

[16] L. Van der Maaten and G. Hinton, “Visualizing data using t-sne.” Journal

of machine learning research, vol. 9, no. 11, 2008.

[17] D. L. Marino, C. S. Wickramasinghe, K. Amarasinghe, H. Challa,
P. Richardson, A. A. Jillepalli, B. K. Johnson, C. Rieger, and M. Manic,
“Cyber and physical anomaly detection in smart-grids,” in 2019 Re-
silience Week (RWS), vol. 1, 2019, pp. 187–193.

[18] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A
jul 2009. [Online].

survey,” ACM Comput. Surv., vol. 41, no. 3,
Available: https://doi.org/10.1145/1541880.1541882

[19] I. Golan and R. El-Yaniv, “Deep anomaly detection using geometric
transformations,” in Advances
Information Processing
Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-
Bianchi, and R. Garnett, Eds., vol. 31. Curran Associates, Inc.,
2018.
[Online]. Available: https://proceedings.neurips.cc/paper/2018/
ﬁle/5e62d03aec0d17facfc5355dd90d441c-Paper.pdf

in Neural

[20] A. Bl´azquez-Garc´ıa, A. Conde, U. Mori, and J. A. Lozano, “A
review on outlier/anomaly detection in time series data,” ACM
Comput. Surv., vol. 54, no. 3, apr 2021.
[Online]. Available:
https://doi.org/10.1145/3444690

[21] D. Marino, K. Amarasinghe, M. Anderson, N. Yancey, Q. Nguyen,
K. Kenney, and M. Manic, “Data driven decision support for reliable
biomass feedstock preprocessing,” in 2017 Resilience Week (RWS), Sep.
2017, pp. 97–102.

[22] M. L¨angkvist, L. Karlsson, and A. Loutﬁ, “A review of unsupervised
feature learning and deep learning for time-series modeling,” Pattern
Recognition Letters, vol. 42, pp. 11–24, 2014.

[23] C. S. Wickramasinghe, D. L. Marino, and M. Manic, “Resnet autoen-
coders for unsupervised feature learning from high-dimensional data:
Deep models resistant to performance degradation,” IEEE Access, vol. 9,
pp. 40 511–40 520, 2021.

[24] B. Sch¨olkopf, R. C. Williamson, A. J. Smola, J. Shawe-Taylor, J. C. Platt
et al., “Support vector method for novelty detection.” in NIPS, vol. 12.
Citeseer, 1999, pp. 582–588.

[25] B. Sch¨olkopf, J. C. Platt, J. Shawe-Taylor, A. J. Smola, and R. C.
Williamson, “Estimating the support of a high-dimensional distribution,”
Neural computation, vol. 13, no. 7, pp. 1443–1471, 2001.

[26] S. Teng, N. Wu, H. Zhu, L. Teng, and W. Zhang, “Svm-dt-based adaptive
and collaborative intrusion detection,” IEEE/CAA Journal of Automatica
Sinica, vol. 5, no. 1, pp. 108–118, 2018.

[27] R. Sandhya, J. Prakash, and B. V. Kumar, “Comparative analysis of
clustering techniques in anomaly detection wind turbine data.” Journal
of Xi’an University of Architecture & Technology, vol. 12, no. 3, pp.
5684–5694, 2020.

[28] M. Ahmed, A. Anwar, A. N. Mahmood, Z. Shah, and M. J. Maher, “An
investigation of performance analysis of anomaly detection techniques
for big data in scada systems.” EAI Endorsed Trans. Indust. Netw. &
Intellig. Syst., vol. 2, no. 3, p. e5, 2015.

9

[29] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander, “Lof: identifying
density-based local outliers,” in Proceedings of the 2000 ACM SIGMOD
international conference on Management of data, 2000, pp. 93–104.

[30] C. Zhou and R. C. Paffenroth, “Anomaly detection with robust deep
autoencoders,” in Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, ser. KDD ’17.
New York, NY, USA: Association for Computing Machinery, 2017, p.
665–674.

[31] C. S. Wickramasinghe, D. L. Marino, K. Amarasinghe, and M. Manic,
“Generalization of deep learning for cyber-physical system security: A
survey,” in IECON 2018-44th Annual Conference of the IEEE Industrial
Electronics Society.
IEEE, 2018, pp. 745–751.

[32] K. Sohn, C.-L. Li, J. Yoon, M. Jin, and T. Pﬁster, “Learning and eval-
uating representations for deep one-class classiﬁcation,” arXiv preprint
arXiv:2011.02578, 2020.

[33] C.-L. Li, K. Sohn, J. Yoon, and T. Pﬁster, “Cutpaste: Self-supervised
learning for anomaly detection and localization,” in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2021, pp. 9664–9674.

[34] M.-I. Georgescu, A. Barbalau, R. T. Ionescu, F. S. Khan, M. Popescu,
and M. Shah, “Anomaly detection in video via self-supervised and
multi-task learning,” in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 2021, pp. 12 742–12 752.

[35] D. Gunning and D. Aha, “Darpa’s explainable artiﬁcial intelligence (xai)

program,” AI Magazine, vol. 40, no. 2, pp. 44–58, 2019.

[36] M. T. Ribeiro, S. Singh, and C. Guestrin, “” why should i trust you?”
explaining the predictions of any classiﬁer,” in Proceedings of the 22nd
ACM SIGKDD international conference on knowledge discovery and
data mining, 2016, pp. 1135–1144.

[37] S. M. Lundberg and S.-I. Lee, “A uniﬁed approach to interpreting
model predictions,” in Advances in Neural Information Processing
Systems 30,
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, Eds. Curran Associates,
Inc., 2017, pp. 4765–4774. [Online]. Available: http://papers.nips.cc/
paper/7062-a-uniﬁed-approach-to-interpreting-model-predictions.pdf

[38] ©[2021] IEEE. Reprinted, with permission from D. L. Marino and
M. Manic, “Physics enhanced data-driven models with variational gaus-
sian processes,” IEEE Open Journal of the Industrial Electronics Society,
vol. 2, pp. 252–265, 2021.

[39] A. Deng and B. Hooi, “Graph neural network-based anomaly detection
in multivariate time series,” in Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, vol. 35, no. 5, 2021, pp. 4027–4035.

[40] L. Cai, Z. Chen, C. Luo, J. Gui, J. Ni, D. Li, and H. Chen, “Structural
temporal graph neural networks for anomaly detection in dynamic
graphs,” in Proceedings of the 30th ACM International Conference on
Information & Knowledge Management, 2021, pp. 3747–3756.

