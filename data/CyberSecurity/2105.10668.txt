1
2
0
2

v
o
N
8
1

]

R
C
.
s
c
[

2
v
8
6
6
0
1
.
5
0
1
2
:
v
i
X
r
a

Runtime Enforcement of Programmable Logic Controllers

RUGGERO LANOTTE, Universit√† degli Studi dell‚ÄôInsubria, Italy
MASSIMO MERRO, Universit√† degli Studi di Verona, Italy
ANDREI MUNTEANU, Universit√† degli Studi di Verona, Italy

With the advent of Industry 4.0, industrial facilities and critical infrastructures are transforming into an ecosys-
tem of heterogeneous physical and cyber components, such as programmable logic controllers, increasingly
interconnected and therefore exposed to cyber-physical attacks, i.e., security breaches in cyberspace that may
adversely affect the physical processes underlying industrial control systems.

In this paper, we propose a formal approach based on runtime enforcement to ensure specification compliance
in networks of controllers, possibly compromised by colluding malware that may tamper with actuator
commands, sensor readings, and inter-controller communications. Our approach relies on an ad-hoc sub-class
of Ligatti et al.‚Äôs edit automata to enforce controllers represented in Hennessy and Regan‚Äôs Timed Process
Language. We define a synthesis algorithm that, given an alphabet P of observable actions and a timed
correctness property ùëí, returns a monitor that enforces the property ùëí during the execution of any (potentially
corrupted) controller with alphabet P, and complying with the property ùëí. Our monitors correct and suppress
incorrect actions coming from corrupted controllers and emit actions in full autonomy when the controller
under scrutiny is not able to do so in a correct manner. Besides classical requirements, such as transparency
and soundness, the proposed enforcement enjoys deadlock- and diverge-freedom of monitored controllers,
together with scalability when dealing with networks of controllers. Finally, we test the proposed enforcement
mechanism on a non-trivial case study, taken from the context of industrial water treatment systems, in which
the controllers are injected with different malware with different malicious goals.

CCS Concepts: ‚Ä¢ Security and privacy ‚Üí Formal security models; Cyber-physical systems security.

Additional Key Words and Phrases: Runtime enforcement, control systems security, PLC malware

1 INTRODUCTION
Industrial Control Systems (ICSs) are physical and engineered systems whose operations are moni-
tored, coordinated, controlled, and integrated by a computing and communication core [53]. They
represent the backbone of Critical Infrastructures for safety-critical applications such as electric
power distribution, nuclear power production, and water supply.

The growing connectivity and integration in Industry 4.0 has triggered a dramatic increase in
the number of cyber-physical attacks [31] targeting ICSs, i.e., security breaches in cyberspace that
adversely affect the physical processes. Some notorious examples are: (i) the Stuxnet worm, which
reprogrammed Siemens PLCs of nuclear centrifuges in the nuclear facility of Natanz in Iran [35];
(ii) the CRASHOVERRIDE attack on the Ukrainian power grid, otherwise known as Industroyer [58];
(iii) the recent TRITON/TRISIS malware that targeted a petrochemical plant in Saudi Arabia [19].

One of the key components of ICSs are Programmable Logic Controllers, better known as PLCs.
They control mission-critical electrical hardware such as pumps or centrifuges, effectively serving
as a bridge between the cyber and the physical worlds. PLCs have an ad-hoc architecture to execute
simple repeating processes known as scan cycles (IEC 61131-3 [1]). Each scan cycle consists of three
phases: (i) reading of sensor measurements of the physical process; (ii) execution of the controller

Authors‚Äô addresses: Ruggero Lanotte, Universit√† degli Studi dell‚ÄôInsubria, Dipartimento di Scienze Umane e dell‚ÄôInnovazione
per il Territorio, via Sant‚ÄôAbbondio 12, Como, 22100, Italy, ruggero.lanotte@uninsubria.it; Massimo Merro, Universit√†
degli Studi di Verona, Dipartimento di Informatica, strada Le Grazie 15, Verona, 37134, Italy, massimo.merro@univr.it;
Andrei Munteanu, Universit√† degli Studi di Verona, Dipartimento di Informatica, strada Le Grazie 15, Verona, 37134, Italy,
andrei.munteanu@univr.it.

 
 
 
 
 
 
2

R. Lanotte, M. Merro, A. Munteanu

Fig. 1. A network of compromised PLCs: ùë¶ùëñ denote genuine sensor measurements, ùë¶a
measurements, ùë¢a

ùëñ are corrupted sensor
ùëñ denote corrupted inter-controller communications.

ùëñ corrupted actuator commands, and ùëêa

code to compute how the physical process should evolve; (iii) transmission of commands to the
actuator devices to govern the physical process as desired.

Due to their sensitive role in controlling industrial processes, successful exploitation of PLCs
can have severe consequences on ICSs. In fact, although modern controllers provide security
mechanisms to allow only legitimate firmware to be uploaded, the running code can be typically
altered by anyone with network or USB access to the controllers (see Figure 1). Published scan data
shows how thousands of PLCs are directly accessible from the Internet to improve efficiency [52].
Thus, despite their responsibility, controllers are vulnerable to several kinds of attacks, including
PLC-Blaster worm [59], Ladder Logic Bombs [28], and PLC PIN Control attacks [5].

Extra trusted hardware components have been proposed to enhance the security of PLC architec-
tures [45, 46]. For instance, McLaughlin [45] proposed a policy-based enforcement mechanism to
mediate the actuator commands transmitted by the PLC to the physical plant. Mohan et al. [46]
introduced a different architecture, in which every PLC runs under the scrutiny of a monitor which
looks for deviations with respect to safe behaviours. Both architectures have been validated by
means of simulation-based techniques. However, as far as we know, formal methodologies have
been rarely used to model and formally verify security-oriented architectures for ICSs.

Runtime enforcement [22, 40, 56] is a formal verification/validation technique aiming at correcting
possibly-incorrect executions of a system-under-scrutiny (SuS). It employs a kind of monitor [23]
that acts as a proxy between the SuS and the environment interacting with it. At runtime, the
monitor transforms any incorrect executions exhibited by the SuS into correct ones by either
replacing, suppressing or inserting observable actions on behalf of the system. The effectiveness of
the enforcement depends on the achievement of the two following general principles [40, 56]:

‚Ä¢ transparency, i.e., the enforcement must not alter correct executions of the SuS;
‚Ä¢ soundness, i.e., incorrect executions of the SuS must be prevented.
In this paper, we propose a formal approach based on runtime enforcement to ensure specification
compliance in networks of controllers possibly compromised by colluding malware that may tamper
with actuator commands, sensor readings, and inter-controller communications. combined with
automatic recovery mechanisms.

Our goal is to enforce potentially corrupted controllers using secure proxies based on a sub-
class of Ligatti et al.‚Äôs edit automata [40]. These automata will be synthesised from enforceable
timed correctness properties to form networks of monitored controllers, as in Figure 2. The proposed
enforcement will enjoy both transparency and soundness together with the following features:
‚Ä¢ determinism preservation, i.e., the enforcement should not introduce nondeterminism;
‚Ä¢ deadlock-freedom, i.e., the enforcement should not introduce deadlocks;

PLCnuan,can,yanPLC1ua1,ca1,ya1ca1canFieldCommunicationsNetworkya1yanSupervisoryControlNetworkynuanua1y1¬∑¬∑¬∑¬∑¬∑¬∑Runtime Enforcement of PLCs

3

Fig. 2. A network of monitored controllers.

‚Ä¢ divergence-freedom, i.e., the enforcement should not introduce divergencies;
‚Ä¢ mitigation of incorrect/malicious activities;
‚Ä¢ scalability, i.e., the enforcement mechanism should scale to networks of controllers.

Obviously, when a controller is compromised, these objectives can be achieved only with the
introduction of a physically independent secure proxy, as advocated by McLaughlin and Mohan
et al. [45, 46], which does not have any Internet or USB access, and which is connected with the
monitored controller via secure channels. This may seem like we just moved the problem over
to securing the proxy. However, this is not the case because the proxy only needs to enforce a
timed correctness property of the system, while the controller does the whole job of controlling the
physical process relying on potentially dangerous communications via the Internet or the USB
ports. Thus, any upgrade of the control system will be made to the controller and not to the secure
proxy. Of course, by no means runtime reconfigurations of the secure proxy should be allowed as
its enforcing should be based on the physics of the plant itself and not on the controller code.

Contribution. Fist of all, we define the attacker model and the attacker objectives in an enforced
ICS architecture such as that depicted in Figure 2. Then, we introduce a formal language to
specify controller programs. For this very purpose, we resort to process calculi, a successful and
widespread formal approach in concurrency theory for representing complex systems, such as mobile
systems [16] and cyber-physical systems [39], and used in many areas, including verification of
security protocols [3, 4] and security analysis of cyber-physical attacks [38]. Thus, we define a simple
timed process calculus, based on Hennessy and Regan‚Äôs Timed Process Language (TPL) [29], for
specifying controllers, finite-state enforcers, and networks of communicating monitored controllers.
Then, we define a simple description language to express timed correctness properties that should
hold for a (possibly unbounded) number of scan cycles of the monitored controller. This will allow
us to abstract over controllers implementations, focusing on general properties which may even be
shared by completely different controllers. In this regard, we might resort to one of the several logics
existing in the literature for monitoring timed concurrent systems, and in particular cyber-physical
systems (see, e.g., [9, 24]). However, the peculiar iterative behaviour of controllers convinced us to
adopt the sub-class of regular expressions that can be recognised by finite automata whose cycles
always contain at least one final state; this is the largest class of regular properties that can be
enforced by finite-state Ligatti et at.‚Äôs edit automata (see Beauquier et al.‚Äôs work [10]). In Section 5,
we express a wide class of correctness properties for controllers in terms of (our) regular properties.
After defining a formal language to describe controller properties, we provide a synthesis function
‚ü®| ‚àí |‚ü© P that, given an alphabet P of observable actions (sensor readings, actuator commands, and

PLCnuan,can,yanPLC1ua1,ca1,ya1proxy1ua1/u1ca1/c1y1/y1proxynyn/yncan/cnuan/unua1ca1y1yncanuanc1cnFieldCommunicationsNetworky1ynSupervisoryControlNetworkynunu1y1¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑4

R. Lanotte, M. Merro, A. Munteanu

inter-controller communications) and a deterministic regular property ùëí combining events of P,
returns an edit automaton ‚ü®| ùëí |‚ü© P. The resulting enforcement mechanism will ensure the required
features mentioned before: transparency, soundness, determinism preservation, deadlock-freedom,
divergence-freedom, mitigation and scalability. Then, we propose a non-trivial case study, taken
from the context of industrial water treatment systems, and implemented as follows: (i) the physical
plant is simulated in Simulink [44]; (ii) the open source PLCs are implemented in OpenPLC [8] and
executed on Raspberry Pi; (iii) the enforcers run on connected FPGAs. In this setting, we test our
enforcement mechanism when injecting the PLCs with 5 different malware, with different goals.

Outline. Section 2 describes the attacker model and the attacker objectives. Section 3 gives a
formal language for monitored controllers. Section 4 defines the case study. Section 5 provides a
language of regular properties to express controller behaviours; it also contains a taxonomy of
properties expressible in the language. Section 6 contains the algorithm to synthesise monitors
from regular properties, together with the main results. Section 7 discusses the implementation of
the case study when exposed to five different attacks. Section 8 is devoted to related work. Section 9
draws conclusions and discusses future work. Technical proofs can be found in the appendix.

2 ATTACKER MODEL AND ATTACKER OBJECTIVES
In the following sections, we will propose an enforcement-based architecture for ICSs (as those
depicted in Figure 2) to counter attacks complying with the following attacker model:

‚Ä¢ malware injected in one or more PLCs may forge/drop actuator commands, modify sensor

readings coming from the plant, forge/drop inter-controller communications;

‚Ä¢ malware injected in different PLCs of the same field communications network may collabo-

rate/communicate with each other to achieve common objectives;

‚Ä¢ the attacker runtime behaviour may vary as it may depend on the received sensor signals

and the communications with other PLCs;

‚Ä¢ malicious alterations of sensor signals at network level, or within the sensor devices, are not

allowed (they are out of the scope of this paper);

‚Ä¢ scan cycles must be completed within a specific time, called maximum cycle limit, which
depends on the controlled physical process; if this time limit is violated then the controller
stops and throws an exception [59]; we assume that the injected malware never violates the
maximum cycle limit because not interested in causing the immediate shutdown of a PLC;
‚Ä¢ the enforcers added in the architecture are physically independent secure proxies with no
Internet or USB access, and connected with the controller via secure channels; as a consequence,
the measurements transmitted to the supervisory control network will not be corrupted;

‚Ä¢ runtime reconfigurations of secure proxies are not allowed.

Thus, in general, the attacker objectives can be resumed in alteration/forgery of PLC actuator
commands and/or communication messages between PLCs to eventually affect the evolution of the
controlled physical processes, and/or transmit fake signals to the supervisory control network.

3 A FORMAL LANGUAGE FOR MONITORED CONTROLLERS
In this section, we introduce the Timed Calculus of Monitored Controllers, called TCMC, as an abstract
formal language to express networks of controllers integrated with edit automata sitting on the
network interface of each controller to monitor/correct their interactions with the rest of the system.
Basically, TCMC extends Hennessy and Regan‚Äôs Timed Process Language (TPL) [29] with monitoring
edit automata. Like TPL time proceeds in discrete time slots separated by tick-actions.

Let us start with some preliminary notation. We use ùë†, ùë†ùëò ‚àà Sens to name sensor signals; ùëé, ùëéùëò ‚àà Act

to indicate actuator commands; ùëê, ùëêùëò ‚àà Chn for channels; ùëß, ùëßùëò for generic names.

Runtime Enforcement of PLCs

5

Controllers. In our setting, controllers are nondeterministic sequential timed processes evolving
through three main phases: sensing of sensor signals, communication with other controllers, and
actuation. For convenience, we use five different syntactic categories to distinguish the five main
states of a controller: Ctrl for initial states, Sleep for sleeping states, Sens for sensing states,
Com for communication states, and Act for actuation states. In its initial state, a controller is a
recursive process waiting for signal stabilisation in order to start the sensing phase:

Ctrl ‚àã ùëÉ

::= ùëã

Sleep ‚àã ùëä ::=

tick.ùëä (cid:12)
(cid:12)

ùëÜ

The main process describing a controller consists of some recursive process defined via equations
of the form ùëã = tick.ùëä , with ùëä ‚àà Sleep; here, ùëã is a process variable that may occur (free) in ùëä . For
convenience, our controllers always have at least one initial timed action tick to ensure time-guarded
recursion, thus avoiding undesired zeno behaviours [30]: the number of untimed actions between
two tick-actions is always finite. Then, after a determined sleeping period, when sensor signals get
stable, the sensing phase can start.

During the sensing phase, the controller waits for a finite number of admissible sensor signals. If
none of those signals arrives in the current time slot then the controller will timeout moving to the
following time slot (we adopt the TPL construct ‚åä¬∑‚åã¬∑ for timeout). The syntax is the following:

Sens ‚àã ùëÜ

::=

‚åä(cid:205)ùëñ ‚ààùêº ùë†ùëñ .ùëÜùëñ ‚åãùëÜ

(cid:12)
(cid:12) ùê∂

where (cid:205)ùëñ ‚ààùêº ùë†ùëñ .ùëÜùëñ denotes the standard construct for nondeterministic choice. Once the sensing
phase is concluded, the controller starts its calculations that may depend on communications with
other controllers governing different physical processes. Controllers communicate with each other
for mainly two reasons: either to receive notice about the state of other physical sub-processes or
to require an actuation on a physical process which is out of their control. As in TPL, we adopt
a channel-based handshake point-to-point communication paradigm. Note that, in order to avoid
starvation, communication is always under timeout. The syntax for the communication phase is:

Comm ‚àã ùê∂

‚åä(cid:205)ùëñ ‚ààùêº ùëêùëñ .ùê∂ùëñ ‚åãùê∂ (cid:12)
(cid:12)
In the actuation phase a controller eventually transmits a finite sequence of commands to
actuators, and then, it emits a fictitious system signal end to denote the end of the scan cycle. After
that, the whole scan cycle can restart. Formally,

‚åäùëê.ùê∂‚åãùê∂ (cid:12)

(cid:12) ùê¥

::=

Act ‚àã ùê¥

::=

ùëé.ùê¥ (cid:12)
(cid:12)

end.ùëã

Remark 1 (Scan cycle duration and maximum cycle limit). The scan cycle of a PLC must
be completed within a specific time, called maximum cycle limit, which depends on the controlled
physical process; if this time limit is violated the the controller stops and throws an exception [59]. Thus,
the signal end must occur well before the maximum cycle limit of the controller. We actually work
under the assumption that our controllers successfully complete their scan cycle in less than half of
the maximum cycle limit. The reasons for this assumption will be clarified in Remark 4. Please, notice
that it is easy to statically derive the maximum duration of a scan cycle expressed in our calculus by
simply counting the maximum number of tick-prefixes occurring between two subsequent end-prefixes.
The operational semantics in Table 1 is along the lines of Hennessy and Regan‚Äôs TPL [29]. In
the following, we use the metavariable ùõº to range over the set of all (observable) controller actions:
{ùë†, ùëé, ùëê, ùëê, tick, end}. These actions denote: sensor readings, actuator commands, channel transmissions,
channel receptions, passage of time, and end of scan cycles, respectively. Notice that at our level of
abstraction we represent only the observable behaviour of PLCs: internal computations are not
modelled within PLCs; although, we do have ùúè-actions to express communications between two
PLCs, as the reader will notice in Table 2.

6

R. Lanotte, M. Merro, A. Munteanu

‚àí
tick.ùëä tick‚àí‚àí‚àí‚àí‚àí‚Üí ùëä

(Rec)

ùëã = tick.ùëä
ùëã tick‚àí‚àí‚àí‚àí‚àí‚Üí ùëä

(Sleep)

(ReadS)

(InC)

(OutC)

(WriteA)

ùëó ‚àà ùêº
‚åä(cid:205)ùëñ ‚ààùêº ùë†ùëñ .ùëÜùëñ ‚åãùëÜ
ùëó ‚àà ùêº
‚åä(cid:205)ùëñ ‚ààùêº ùëêùëñ .ùê∂ùëñ ‚åãùê∂

‚àí

ùëê
‚àí‚àí‚àí‚Üí ùê∂

‚åäùëê.ùê∂‚åãùê∂ ‚Ä≤
‚àí
ùëé
‚àí‚àí‚àí‚Üí ùê¥

ùëé.ùê¥

ùë† ùëó
‚àí‚àí‚àí‚àí‚Üí ùëÜ ùëó

(TimeoutS)

ùëê ùëó
‚àí‚àí‚àí‚àí‚Üí ùê∂ ùëó

(TimeoutInC)

(TimeoutOutC)

‚àí
‚åä(cid:205)ùëñ ‚ààùêº ùë†ùëñ .ùëÜùëñ ‚åãùëÜ

tick‚àí‚àí‚àí‚àí‚àí‚Üí ùëÜ
‚àí
‚åä(cid:205)ùëñ ‚ààùêº ùëêùëñ .ùê∂ùëñ ‚åãùê∂ tick‚àí‚àí‚àí‚àí‚àí‚Üí ùê∂
‚àí
tick‚àí‚àí‚àí‚àí‚àí‚Üí ùê∂ ‚Ä≤

‚åäùëê.ùê∂‚åãùê∂ ‚Ä≤

(End)

‚àí
end.ùëã end‚àí‚àí‚àí‚àí‚àí‚Üí ùëã

Table 1. LTS for controllers.

Remark 2 (Attacker model and end-signal). In our abstract representation of PLCs, the end-signal
is not really part of the (possibly compromised) PLC program but it is rather a system signal denoting
the end of a scan cycle. As a consequence, in accordance with our attacker model, we assume that this
fictitious signal cannot be dropped or forged by the attacker.

Monitored controllers. The core of our enforcement relies on (timed) finite-state Ligatti et al.‚Äôs
edit automata [40], i.e., a particular class of automata specifically designed to allow/suppress/insert
actions in a generic system in order to preserve its correct behaviour. The syntax is as follows:

::=

Edit ‚àã E, F

go (cid:12)
The special automaton go will admit any action of the monitored system. The edit automaton
(cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ enforces an action ùúÜùëñ , and then continues as Eùëñ , for any ùëñ ‚àà ùêº , with ùêº finite. Here, the
symbol ùúÜ ranges over: (i) ùõº to allow the action ùõº, (ii) ‚àíùõº to suppress the action ùõº, and (iii) ùõº1 ‚â∫ ùõº2, for
ùõº1 ‚â† ùõº2, to insert the action ùõº1 before the action ùõº2. Recursive automata X are defined via equations
of the form X = E, where the automata variable X may occur (free) in E.

(cid:12) (cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ

(cid:12)
(cid:12) X

The operational semantics of our edit automata is given via the following transition rules:

(Go)

‚àí
ùõº
‚àí‚àí‚àí‚Üí go

go

(Edit)

ùëó ‚àà ùêº

(cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ

ùúÜ ùëó
‚àí‚àí‚àí‚àí‚Üí Eùëó

(recE)

ùúÜ
‚àí‚àí‚àí‚Üí E‚Ä≤

X = E E
ùúÜ
‚àí‚àí‚àí‚Üí E‚Ä≤

X

Our monitored controllers, written E ‚ä≤‚ä≥ {ùêΩ }, consist of a controller ùêΩ , for ùêΩ ‚àà Ctrl ‚à™ Sleep ‚à™
Sens ‚à™ Comm ‚à™ Act, and an edit automaton E enforcing the behaviour of ùêΩ , according to the
following transition rules, presented in the style of [42]:

(Allow)

ùõº
‚àí‚àí‚àí‚Üí E‚Ä≤ ùêΩ

ùõº
‚àí‚àí‚àí‚Üí ùêΩ ‚Ä≤
ùõº
‚àí‚àí‚àí‚Üí E‚Ä≤ ‚ä≤‚ä≥ {ùêΩ ‚Ä≤}

E
E ‚ä≤‚ä≥ {ùêΩ }

(Suppress)

‚àíùõº
‚àí‚àí‚àí‚àí‚Üí E‚Ä≤ ùêΩ

ùõº
‚àí‚àí‚àí‚Üí ùêΩ ‚Ä≤
ùúè
‚àí‚àí‚àí‚Üí E‚Ä≤ ‚ä≤‚ä≥ {ùêΩ ‚Ä≤}

E
E ‚ä≤‚ä≥ {ùêΩ }

(Insert) E

ùõº1 ‚â∫ ùõº2
‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚Üí E‚Ä≤ ùêΩ
E ‚ä≤‚ä≥ {ùêΩ }

ùõº2‚àí‚àí‚àí‚àí‚Üí ùêΩ ‚Ä≤
ùõº1‚àí‚àí‚àí‚àí‚Üí E‚Ä≤ ‚ä≤‚ä≥ {ùêΩ }

Rule (Allow) is used for allowing observable actions emitted by the controller under scrutiny. By
an application of Rule (Suppress), incorrect actions ùõº emitted by (possibly corrupted) controllers
ùêΩ are suppressed, i.e., converted into (silent) ùúè-actions. Rule (Insert) is used to insert an action ùõº1
before an action ùõº2 of the controller. In the following, the metavariable ùõΩ will range over the same
set of actions as ùõº, together with the silent action ùúè.

Runtime Enforcement of PLCs

7

ùëÅ1

ùëÅ1 ‚à• ùëÅ2

ùõº
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤
1
ùõº
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤
1 ‚à• ùëÅ2

ùëÅ1

ùëê
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤

(ChnSync)

ùëÅ1 ‚à• ùëÅ2
ùëÅ2 ‚à• ùëÅ1

(ParL)

(ParR)

1 ùëÅ2
ùúè
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤
ùúè
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤

ùëê
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤
2
1 ‚à• ùëÅ ‚Ä≤
2
2 ‚à• ùëÅ ‚Ä≤
1
tick‚àí‚àí‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤
tick‚àí‚àí‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤

ùëÅ1 ‚à• ùëÅ2

ùëÅ2

ùõº
‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤
2
ùõº
‚àí‚àí‚àí‚Üí ùëÅ1 ‚à• ùëÅ ‚Ä≤
2

2 ùëÅ1 ‚à• ùëÅ2
1 ‚à• ùëÅ ‚Ä≤
2
Table 2. LTS for field communications networks of monitored controllers.

1 ùëÅ2
ùëÅ1 ‚à• ùëÅ2

(TimeSync)

tick‚àí‚àí‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤

ùëÅ1

ùúè
‚àí‚àí‚àí‚ÜíÃ∏

Here, we wish to stress that, like Ligatti et al. [40], we are interested in deterministic (and hence
implementable) enforcement. With the following technical definitions we extract from enforcer
actions ùúÜ both: (i) the controller triggering actions, and (ii) the resulting output actions.

Definition 1. Let ùúÜ ‚àà {ùõº, ‚àíùõº, ùõº1 ‚â∫ ùõº2} be an arbitrary action for edit automata, we write
trigger (ùúÜ) to denote the controller action triggering ùúÜ, defined as: trigger (ùõº) = ùõº, trigger (‚àíùõº) = ùõº and
trigger (ùõº1 ‚â∫ ùõº2) = ùõº2. Similarly, we write out (ùúÜ) to denote the output action prescribed by ùúÜ, defined
as: out (ùõº) = ùõº, out (‚àíùõº) = ùúè and out (ùõº1 ‚â∫ ùõº2) = ùõº1. Given a trace ùë° = ùúÜ1 ¬∑ ¬∑ ¬∑ ùúÜùëõ, we write out (ùë°) for
the trace out (ùúÜ1) ¬∑ ¬∑ ¬∑ out (ùúÜùëõ).

Now, we provide a definition of deterministic enforcer along the lines of Pinisetty at al. [50].

Definition 2 (Deterministic enforcer). A edit automaton E ‚àà Edit is said to be deterministic
iff in every term (cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ that appears in E there are no ùúÜùëò and ùúÜ ùëó , for ùëò, ùëó ‚àà ùêº , ùëò ‚â† ùëó, such that
trigger (ùúÜùëò ) = trigger (ùúÜ ùëó ) and out (ùúÜùëò ) = out (ùúÜ ùëó ).

Finally, we can easily generalise the concept of monitored controller to a field communications
network of parallel monitored controllers, each one acting on different actuators, and exchanging
information via channels. These networks are formally defined via a straightforward grammar:

FNet ‚àã ùëÅ ::= E ‚ä≤‚ä≥ {ùêΩ }

(cid:12)
(cid:12) ùëÅ ‚à• ùëÅ

with the operational semantics defined in Table 2.

Notice that monitored controllers may interact with each other via channel synchronisation
(see Rule (ChnSync)). Moreover, via rule (TimeSync) they may evolve in time only when channel
synchronisation may not occur (our controllers do not admit zeno behaviours). This ensures
maximal progress [29], a desirable time property when modelling real-time systems: channel
communications will never be postponed.

Definition 3 (Execution traces). Given three finite execution traces ùë°c = ùõº1 . . . ùõºùëò , ùë°e = ùúÜ1 . . . ùúÜùëô ,
and ùë°m = ùõΩ1 . . . ùõΩùëõ, for controllers, edit automata and monitored controllers, respectively. We write: (i)
ùë°e
‚àí‚àí‚àí‚Üí E‚Ä≤, as an abbreviation for
ùëÉ

ùë°c
‚àí‚àí‚àí‚Üí ùëÉ ‚Ä≤, as an abbreviation for ùëÉ = ùëÉ0

ùõºùëò‚àí‚àí‚àí‚àí‚Üí ùëÉùëò = ùëÉ ‚Ä≤; (ii) E

ùõº1‚àí‚àí‚àí‚àí‚Üí ¬∑ ¬∑ ¬∑

E = E0

ùúÜ1‚àí‚àí‚àí‚àí‚Üí ¬∑ ¬∑ ¬∑

ùúÜùëô‚àí‚àí‚àí‚àí‚Üí Eùëô = E‚Ä≤; (iii) ùëÅ

ùë°m‚àí‚àí‚àí‚àí‚Üí ùëÅ ‚Ä≤, as an abbreviation for ùëÅ = ùëÅ0

ùõΩ1

‚àí‚àí‚àí‚àí‚Üí ¬∑ ¬∑ ¬∑

ùõΩùëõ
‚àí‚àí‚àí‚àí‚Üí ùëÅùëõ = ùëÅ ‚Ä≤.

In the rest of the paper we adopt the following notations.

Notation 1. As usual, we write ùúñ to denote the empty trace. Given a trace ùë° we write | ùë° | to denote
the length of ùë°, i.e., the number of actions occurring in ùë°. Given a trace ùë° we write ÀÜùë° to denote the trace
obtained by removing the ùúè-actions. Given two traces ùë° ‚Ä≤ and ùë° ‚Ä≤‚Ä≤, we write ùë° ‚Ä≤ ¬∑ ùë° ‚Ä≤‚Ä≤ for the trace resulting
from the concatenation of ùë° ‚Ä≤ and ùë° ‚Ä≤‚Ä≤. For ùë° = ùë° ‚Ä≤ ¬∑ ùë° ‚Ä≤‚Ä≤ we say that ùë° ‚Ä≤ is a prefix of ùë° and ùë° ‚Ä≤‚Ä≤ is a suffix of ùë°.

8

R. Lanotte, M. Merro, A. Munteanu

Fig. 3. A simplified Industrial Water Treatment System.

4 USE CASE: THE SWAT SYSTEM
In this section, we describe how to specify in TCMC a non-trivial network of PLCs to control (a
simplified version of) the Secure Water Treatment system (SWaT) [43].

SWaT represents a scaled down version of a real-world industrial water treatment plant. The
system consists of 6 stages, each of which deals with a different treatment, including: chemical
dosing, filtration, dechlorination, and reverse osmosis. For simplicity, in our use case, depicted
in Figure 3, we consider only three stages. In the first stage, raw water is chemically dosed and
pumped in a tank ùëá1, via two pumps pump1 and pump2. A valve connects ùëá1 with a filtration unit
that releases the treated water in a second tank ùëá2. Here, we assume that the flow of the incoming
water in ùëá1 is greater than the outgoing flow passing through the valve. The water in ùëá2 flows into
a reverse osmosis unit to reduce inorganic impurities. In the last stage, the water coming from the
reverse osmosis unit is either distributed as clean water, if required standards are met, or stored
in a backwash tank ùëá3 and then pumped back, via a pump pump3, to the filtration unit. Here, we
assume that tank ùëá2 is large enough to receive the whole content of tank ùëá3 at any moment.

The SWaT system has been used to provide a dataset containing physical and network data
recorded during 11 days of activity [27]. Part of this dataset contains information about the execution
of the system in isolation, while a second part records the effects on the system when exposed
to different kinds of cyber-physical attacks. Thus, for instance, (i) drops of commands to activate
pump2 may affect the quality of the water, as they would affect the correct functioning of the
chemical dosing pump; (ii) injections of commands to close the valve between ùëá1 and ùëá2, may give
rise to an overflow of tank ùëá1 if this tank is full; (iii) integrity attacks on the signals coming from the
sensor of the tank ùëá3 may result in damages of the pump pump3 if it is activated when ùëá3 is empty.
Each tank is controlled by its own PLC. The programs of the three PLCs, expressed in terms of

ladder logic, are given in Figure 4. In the following, we give their descriptions in TCMC.

Let us start with the code of the controller PLC1 managing the tank ùëá1. Its definition is given in
terms of two equations to deal with the case when the two pumps, pump1 and pump2, are both off
and both on, respectively. Intuitively, when the pumps are off, the level of water in ùëá1 drops until it
reaches its low level (event ùëô1); when this happens both pumps are turned on and they remain so

T1h1‚àím1‚àí...l1‚àím1‚àí..../valve≈ìpump1≈ìchemicaldosingpump2rawwaterT2h2‚àíl2‚àíFiltrationunitT3h3‚àíl3‚àí≈ìpump3ReverseosmosisunitcleanwaterPLC1PLC2PLC3l1,m1,h1on1,on2,openoÔ¨Ä1,oÔ¨Ä2,closel2,h2l3,h3on3oÔ¨Ä3openreq,closereqRuntime Enforcement of PLCs

9

Fig. 4. Ladder logics of the three PLCs controlling the system in Figure 3.

until the tank is refilled, reaching its high level (event ‚Ñé1). Formally,

1 = tick.(cid:0) ‚åäùëô1.on1.on2.close.end.ùëÉ on
ùëÉ off
1

+ ùëö1. ‚åäopen_req.off1.off2.open.end.ùëÉ off
+ ‚Ñé1. ‚åäopen_req.off1.off2.open.end.ùëÉ off
‚åã (off1.off2.close.end.ùëÉ off

1 )(cid:1)
1 = tick.(cid:0) ‚åäùëô1.on1.on2.close.end.ùëÉ on
ùëÉ on
1

+ ùëö1. ‚åäopen_req.on1.on2.open.end.ùëÉ on
+ ‚Ñé1. ‚åäopen_req.off1.off2.open.end.ùëÉ off
‚åã (off1.off2.close.end.ùëÉ on

1 )(cid:1)

1 + close_req.off1.off2.close.end.ùëÉ off
1 + close_req.off1.off2.close.end.ùëÉ off

1 ‚åã (off1.off2.close.end.ùëÉ off
1 )
1 ‚åã (off1.off2.close.end.ùëÉ off
1 )

1 + close_req.on1.on2.close.end.ùëÉ on
1 + close_req.off1.off2.close.end.ùëÉ off

1 ‚åã (on1.on2.close.end.ùëÉ on
1 )
1 ‚åã (off1.off2.close.end.ùëÉ off
1 )

Thus, for instance, when the pumps are off the PLC1 waits for one time slot (to get stable sensor
signals) and then checks the water level of the tank ùëá1, distinguishing between three possible states.
If ùëá1 reaches its low level (signal ùëô1) then the pumps are turned on (commands on1 and on2) and the
valve is closed (command open_req). Otherwise, if the tank ùëá1 is at some intermediate level between
low and high (signal ùëö1) then PLC1 listens for requests arriving from PLC2 to open/close the valve.
Precisely, if the PLC gets an open_req request then it opens the valve, letting the water flow from ùëá1
to ùëá2, otherwise, if it gets a close_req request then it closes the valve; in both cases the pumps remain
off. If the level of the tank is high (signal ‚Ñé1) then the requests of water coming from PLC2 are
served as before, but the two pumps are eventually turned off (commands off1 and off2).

PLC2 manages the water level of tank ùëá2. Its code consists of the two equations to model the

filling (state ‚Üë) and the emptying (state ‚Üì) of the tank. Formally,
2 ‚åãend.ùëÉ ‚Üë
2 ‚åãend.ùëÉ ‚Üì

ùëÉ ‚Üë
2 = tick.( ‚åäùëô2. ‚åäopen_req.end.ùëÉ ‚Üë
ùëÉ ‚Üì
2 = tick.( ‚åäùëô2. ‚åäopen_req.end.ùëÉ ‚Üë

2 + ùëö2. ‚åäopen_req.end.ùëÉ ‚Üë
2 + ùëö2. ‚åäclose_req.end.ùëÉ ‚Üì

2 ‚åãend.ùëÉ ‚Üë
2 ‚åãend.ùëÉ ‚Üì

2 + ‚Ñé2. ‚åäclose_req.end.ùëÉ ‚Üì
2 + ‚Ñé2. ‚åäclose_req.end.ùëÉ ‚Üì

2 ‚åãend.ùëÉ ‚Üë
2 ‚åãend.ùëÉ ‚Üì

2 ‚åãend.ùëÉ ‚Üë
2 )
2 ‚åãend.ùëÉ ‚Üì
2 )

Here, after one time slot, the level of ùëá2 is checked. If the level is low (signal ùëô2) then PLC2 sends
a request to PLC1, via the channel open_req, to open the valve that lets the water flow from ùëá1 to ùëá2,
and then returns. Otherwise, if the level of tank ùëá2 is high (signal ‚Ñé2) then PLC2 asks PLC1 to close
the valve, via the channel close_req, and then returns. Finally, if the tank ùëá2 is at some intermediate
level between ùëô2 and ‚Ñé2 (signal ùëö2) then the valve remains open (respectively, closed) when the
tank is refilling (respectively, emptying).

Finally, PLC3 manages the water level of the backwash tank ùëá3. Its code consists of two equations

to deal with the case when the pump pump3 is off and on, respectively. Formally,

ùëÉ off
3 = tick.( ‚åäùëô3.off3.end.ùëÉ off
ùëÉ on
3 = tick.( ‚åäùëô3.off3.end.ùëÉ off

3 + ùëö3.off3.end.ùëÉ off
3 + ùëö3.on3.end.ùëÉ on

3 + ‚Ñé3.on3.end.ùëÉ on
3 + ‚Ñé3.on3.end.ùëÉ on

3 ‚åã (off3.end.ùëÉ off
3 ‚åã (off3.end.ùëÉ off

3 ))

3 ))

10

R. Lanotte, M. Merro, A. Munteanu

Here, after one time slot, the level of tank ùëá3 is checked. If the level is low (signal ùëô3) then PLC3
turns off the pump pump3 (command off3), and then returns. Otherwise, if the level of ùëá3 is high
(signal ‚Ñé3) then the pump is turned on (command on3) until the whole content of ùëá3 is pumped back
into the filtration unit of ùëá2.

Examples of correctness properties and attacks. In a system similar to that described above, one
would expect a number of properties capturing the correct functioning of system components.
Let us provide a few examples of such correctness properties and some specific attacks that may
potentially invalidate these properties.

A first property might say that if PLC1 receives a request to open the valve between tanks ùëá1
and ùëá2 then the same valve will be eventually closed early enough to prevent water overflow in
tank ùëá2. This property certainly holds when the system is not exposed to any attack. However,
a malware injected in PLC1 might try to undermine this property by tampering either with the
actuator dedicated to the valve or with the requests of PLC2 to open/close the valve. In particular, a
malicious request to open the valve might be forged by an attacker injected in PLC2. Thus, another
desired correctness property might say that whenever the tank ùëá2 is full then PLC2 will never ask
for incoming water from tank ùëá1. Finally, another expected property might say that pump3 will
never work without enough water in tank ùëá3. Again, an attacker injected in PLC3 might try to
undermine this property by tampering either with the actuator dedicated to the pump or with the
sensor measuring the level of tank ùëá3.

In Section 7.3 we will provide formal definitions for patterns template of structured correctness

properties that are suitable for enforcing correct behaviours of our PLCs.

5 A FORMAL LANGUAGE FOR CONTROLLER PROPERTIES
In this section, we provide a simple description language to express correctness properties that we
may wish to enforce at runtime in our controllers. As discussed in the Introduction, we resort to (a
sub-class of) regular properties as they allow us to express interesting classes of properties referring
to one or more scan cycles of a controller. The proposed language distinguishes between two kinds
of properties: (i) global properties, ùëí ‚àà PropG, to express general controllers‚Äô execution traces;
(ii) local properties, ùëù ‚àà PropL, to express traces confined to a finite number of consecutive scan
cycles. The two families of properties are formalised via the following regular grammar:

ùëí ‚àà PropG
ùëù, ùëû ‚àà PropL

::=
::=

ùëù‚àó | ùëí1 ‚à© ùëí2
ùúñ | ùëù1; ùëù2 | ‚à™ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ

| ùëù1 ‚à© ùëù2

where ùúãùëñ ‚àà Events ‚âú Sens ‚à™ Act ‚à™ Chn‚àó ‚à™ {tick} ‚à™ {end} denote atomic properties, called events, that
may occur as prefix of a property. With an abuse of notation, we use the symbol ùúñ to denote both
the empty property and the empty trace.

The semantics of our logic is naturally defined in terms of sets of execution traces which satisfy

a given property; its formal definition is given in Table 3.

However, the syntax of our logic is a bit too permissive with respect to our intentions, as it allows
us to describe partial scan cycles, i.e., cycles that have not completed. Thus, we restrict ourselves to
considering properties which builds on top of local properties associated to complete scan cycles,
i.e., scan cycles whose last action is an end-action. Formally,

Definition 4. Well-formed properties are defined as follows:
‚Ä¢ the local property end.ùúñ is well formed;
‚Ä¢ a local property of the form ùëù1; ùëù2 is well formed if ùëù2 is well formed;
‚Ä¢ a local property of the form ùëù1 ‚à© ùëù2 is well formed if both ùëù1 and ùëù2 are well formed;

Runtime Enforcement of PLCs

11

ùëù‚àó
(cid:74)
(cid:75)
ùëí1 ‚à© ùëí2
(cid:74)
(cid:75)
ùúñ
(cid:74)
(cid:75)
ùëù1 ‚à© ùëù2
(cid:74)
ùëù1; ùëù2
(cid:74)
(cid:75)
(cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ
(cid:74)

(cid:75)

(cid:75)

, for 1 ‚â§ ùëñ ‚â§ ùëõ}
(cid:75)

}

ùëù
(cid:74)

ùëí2
(cid:74)

and ùë° ‚àà

‚âú {ùúñ} ‚à™ (cid:208)ùëõ ‚ààN+ {ùë° | ùë° = ùë°1 ¬∑ . . . ¬∑ ùë°ùëõ, with ùë°ùëñ ‚àà
‚âú {ùë° | ùë° ‚àà
ùëí1
(cid:75)
(cid:75)
(cid:74)
‚âú {ùúñ}
‚âú {ùë° | ùë° ‚àà
ùëù2
ùëù1
}
(cid:75)
(cid:74)
(cid:74)
(cid:75)
‚âú {ùë° | ùë° = ùë°1 ¬∑ ùë°2, with ùë°1 ‚àà
ùëù1
(cid:75)
(cid:74)
‚âú (cid:208)ùëñ ‚ààùêº {ùë° | ùë° = ùúãùëñ ¬∑ ùë° ‚Ä≤, with ùë° ‚Ä≤ ‚àà
Table 3. Trace semantics of our regular properties.

and ùë°2 ‚àà
ùëùùëñ
}
(cid:74)

and ùë° ‚àà

ùëù2
(cid:74)

(cid:75)

(cid:75)

}

‚Ä¢ a local property of the form ‚à™ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ is well formed if either ùúãùëñ .ùëùùëñ = end.ùúñ or ùëùùëñ is well formed,

for any ùëñ ‚àà ùêº ;

‚Ä¢ a global property ùëù‚àó is well formed if ùëù is well-formed;
‚Ä¢ a global property ùëí1 ‚à© ùëí2 is well-formed if both ùëí1 and ùëí2 are well-formed.

In the rest of the paper, we always assume to work with well-formed properties. Moreover, we

adopt the following notations and/or abbreviations on properties.

Notation 2. We omit trailing empty properties, writing ùúã instead of ùúã .ùúñ. For ùëò > 0, we write ùúãùëò .ùëù as
a shorthand for ùúã .ùúã ...ùúã .ùëù, where prefix ùúã appears ùëò consecutive times. Given a local property ùëù we write
events(ùëù) ‚äÜ Events to denote the set of events occurring in ùëù; similarly, we write events(ùëí) ‚äÜ Events
to denote the set of events occurring in a global property ùëí ‚àà PropG. Given a set of events A ‚äÜ Events
and a local property ùëù, we use A itself as an abbreviation for the property ‚à™ùúã ‚ààAùúã .ùúñ, and A.ùëù as an
abbreviation for the property ‚à™ùúã ‚ààAùúã .ùëù. Given a set of events A, with end ‚àâ A, we write A ‚â§ùëò , for
ùëò ‚â• 0, to denote the well-formed property defined as follows: (i) A ‚â§0 ‚âú end; (ii) A ‚â§ùëò ‚âú end ‚à™ A.A ‚â§ùëò‚àí1,
for ùëò > 0. Thus, the property A ‚â§ùëò captures all possible sequences of events of A whose length is at
most ùëò, for ùëò ‚àà N. We write PEvents to denote the set of pure events, i.e., Events \ {end}. Finally, we
write PUEvents to denote the set of pure untimed events, i.e., Events \ {end, tick}.

Note that our properties are in general nondeterministic. However, since we are interested in

deterministic enforcers, in the following we will focus on deterministic enforcing properties.

Definition 5 (Deterministic properties). A global property ùëí ‚àà PropG is said to be deter-

ministic if for any sub-term ‚à™ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ appearing in ùëí, we have ùúãùëò ‚â† ùúã‚Ñé, for any ùëò, ‚Ñé ‚àà ùêº , ùëò ‚â† ‚Ñé.

5.1 Local properties
As already said, local properties describe execution traces which are limited to a finite number of scan
cycles. Let us present a number of significant local properties that can be expressed in our language
of regular properties. In the following, we assume a fixed maximum number of actions, maxa, that
may occur within a single scan cycle of our controllers, i.e., between two subsequent end-actions.

5.1.1 Basic properties. They prescribe conditional, eventual and persistent behaviours.

Conditional. These properties say that when a (pure) untimed event ùúã occurs in the current scan
cycle then some property ùëù should be satisfied. More generally, for ùúãùëñ ‚àà PUEvents and ùëùùëñ ‚àà PropL,
we write Case( ‚à™ùëñ ‚ààùêº {(ùúãùëñ, ùëùùëñ )}) to denote the property ùëûùëò , for ùëò = maxa, defined as follows:

‚Ä¢ ùëûùëò ‚âú end ‚à™ (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ ‚à™ (PEvents\ (cid:208)ùëñ ‚ààùêº {ùúãùëñ }).ùëûùëò‚àí1, for 0 < ùëò ‚â§ maxa
‚Ä¢ ùëû0 ‚âú end.
When there is only one triggering event ùúã ‚àà PUEvents and one associated local property
ùëù ‚àà PropL, we have a simple conditional property defined as follow: Cnd(ùúã, p) ‚âú Case({(ùúã, ùëù)}).

12

R. Lanotte, M. Merro, A. Munteanu

Fig. 5. A trace satisfying a persistent conditional property PCndm (ùúã, p).

Conditional properties Cnd(ùúã, p) define a cause-effect relation in which the triggering event
ùúã is searched in the current scan cycle; one may think of a more general property PCndm (ùúã, p),
in which the cause-effect relation persists for ùëö > 0 consecutive scan cycles, i.e., the search for
the triggering event ùúã continues for at most ùëö consecutive scan cycles. Of course, the triggered
local property ùëù may span over a finite number of scan cycles (see Figure 5). Formally, we write
PCndm (ùúã, p), for ùúã ‚àà PUEvents, ùëù ‚àà PropL and ùëö > 0, for the property ùëûùëö
defined as follows:

maxa

maxa ‚à™ ùúã .ùëù ‚à™ (PEvents\{ùúã }).ùëû‚Ñé

ùëò‚àí1

, for 1 < ‚Ñé ‚â§ ùëö and 0 < ùëò ‚â§ maxa

‚âú end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
ùëò
0 ‚âú end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
maxa
‚Ä¢ ùëû1
ùëò
‚Ä¢ ùëû1
0 ‚âú ùúñ.

, for 1 < ‚Ñé ‚â§ ùëö

‚âú end ‚à™ ùúã .ùëù ‚à™ (PEvents\{ùúã }).ùëû1

, for 0 < ùëò ‚â§ maxa

ùëò‚àí1

Obviously, Cnd(ùúã, p) = PCnd1(ùúã, p).

Bounded eventually. In this case, an event ùúã must eventually occur within ùëö scan cycles. Formally,

for ùúã ‚àà PUEvents and ùëö > 0, we write BEm (ùúã) to denote the property ùëûùëö
maxa ‚à™ ùúã .PEvents‚â§ùëò‚àí1 ‚à™ (PEvents\{ùúã }).ùëû‚Ñé

ùëò‚àí1

maxa

, for 1 < ‚Ñé ‚â§ ùëö and 0 < ùëò ‚â§ maxa

defined as follows:

‚âú end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
ùëò
0 ‚âú end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
maxa
‚Ä¢ ùëû1
ùëò
‚Ä¢ ùëû1
0 ‚âú ùúã .end.

, for 1 < ‚Ñé ‚â§ ùëö
‚âú ùúã .PEvents‚â§ùëò‚àí1 ‚à™ (PEvents\{ùúã }).ùëû1

, for 0 < ùëò ‚â§ maxa

ùëò‚àí1

Bounded persistency. While in BEm (ùúã) the event ùúã must eventually occur within ùëö scan cycles,
bounded persistency prescribes that an event ùúã must occur in all subsequent ùëö scan cycles. Formally,
for ùúã ‚àà PUEvents and ùëö > 0, we write BPm (ùúã) to denote the property ùëûùëö

defined as follows:

maxa

‚âú ùúã .PEvents‚â§ùëò‚àí1; ùëû‚Ñé‚àí1

maxa ‚à™ (PEvents\{ùúã }).ùëû‚Ñé

ùëò‚àí1

, for 1 < ‚Ñé ‚â§ ùëö and 0 < ùëò ‚â§ maxa

‚Ä¢ ùëû‚Ñé
ùëò
0 ‚âú ùúã .end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
maxa
‚Ä¢ ùëû1
ùëò
‚Ä¢ ùëû1
0 ‚âú ùúã .end.

, for 1 < ‚Ñé ‚â§ ùëö

‚âú ùúã .PEvents‚â§ùëò‚àí1 ‚à™ (PEvents\{ùúã }).ùëû1

, for 0 < ùëò ‚â§ maxa

ùëò‚àí1

Bounded absence. The negative counterpart of bounded persistency is bounded absence. This
property says that an event ùúã must not appear in all subsequent ùëö scan cycles. Formally, for ùúã ‚àà
PUEvents and ùëö > 0, we write BAm (ùúã) to denote the property ùëûùëö defined as follows:

‚Ä¢ ùëû‚Ñé ‚âú (PEvents\{ùúã }) ‚â§maxa; ùëû‚Ñé‚àí1, for 0 < ‚Ñé ‚â§ ùëö
‚Ä¢ ùëû0 ‚âú ùúñ.

5.1.2 Compound conditional properties. The properties above can be combined together to express
more detailed PLC behaviours. Let us see a few examples with the help of the use case of Section 4.

Conditional bounded eventually. According to this property, if a triggering event ùúã1 occurs then a
second event ùúã2 must eventually occur between the ùëö-th and the ùëõ-th scan cycle, with 1 ‚â§ ùëö ‚â§ ùëõ.
Formally, for ùúã1, ùúã2 ‚àà PUEvents and 1 ‚â§ ùëö ‚â§ ùëõ, we define CBE[m,n] (ùúã1, ùúã2) as follows:

CBE[m,n] (ùúã1, ùúã2) ‚âú Cnd(ùúã1 , (PEvents‚â§maxa)m‚àí1; BEn‚àím+1 (ùúã2)).

Runtime Enforcement of PLCs

13

Intuitively, if the event ùúã1 occurs then the event ùúã2 must eventually occur between the scan cycles
ùëö and ùëõ. In case we would wish that ùúã2 should not occur before the ùëö-th scan cycle, then the
property would become: Cnd(ùúã1 , BAm‚àí1(ùúã2); BEn‚àím+1(ùúã2)).

As an example, we might enforce a conditional bounded eventually property in PLC1 of our use
case in Section 4 to prevent water overflow in the tank ùëá2 due to a misuse of the valve connecting
the tanks ùëá1 and ùëá2. Assume that ùëß ‚àà N is the time (expressed in scan cycles) required to overflow
the tank ùëá2 when the valve is open and the level of tank ùëá2 is low. We might consider to enforce a
property of the form CBE[1,w ] (open_req, close), with ùë§ << ùëß, saying that if PLC1 receives a request to
open the valve, then the valve will be eventually closed within at most ùë§ scan cycles (including
the current one). This will ensure that if a water request coming from PLC2 is received by PLC1
then the valve controlling the flaw from ùëá1 to ùëá2 will remain open for at most ùë§ scan cycles, with
ùë§ << ùëß, preventing the overflow of ùëá2.

Conditional bounded persistency. Another possibility is to combine conditional with bounded
persistency to prescribe that if a triggering event ùúã1 occurs then the event ùúã2 must occur in the ùëö-th
scan cycle and in all subsequent ùëõ ‚àí ùëö scan cycles, for 1 ‚â§ ùëö ‚â§ ùëõ. Formally, for ùúã1, ùúã2 ‚àà PUEvents
and 1 ‚â§ ùëö ‚â§ ùëõ, we write CBP[m,n] (ùúã1, ùúã2) to denote the property defined as:

CBP[m,n] (ùúã1, ùúã2) ‚âú Cnd(ùúã1 , (PEvents‚â§maxa)m‚àí1; BPn‚àím+1(ùúã2)).
As an example, we might enforce a conditional bounded persistency property in PLC3 of our use
case in Section 4 to prevent damages of pump3 due to lack of water in tank ùëá3. Assume that ùëß ‚àà N
is the minimum time (in terms of scan cycles) required to fill ùëá3, i.e., to pass from level ùëô3 to level
‚Ñé3, when pump3 is off. We might consider to enforce a property of the form CBP[1,z] (l3, off3), to
prescribe that if the tank reaches its low level (event ùëô3) then pump3 must remain off (event off3) for
ùëß consecutive scan cycles. This will ensure enough water in tank ùëá3 to prevent damages on pump3.
Notice that all previous properties have a single triggering event ùúã1; in order to deal with multiple

triggering events it is enough to replace the conditional operator with the case construct.

Conditional bounded absence (also called Absence timed [24]). Finally, we might consider to
combine conditional with bounded absence to formalise a property saying that if a triggering
event ùúã1 occurs then another event ùúã2 must not occur in the ùëö-th scan cycle and in all subsequent
ùëõ ‚àí ùëö scan cycles, with 1 ‚â§ ùëö ‚â§ ùëõ. Formally, for ùúã1, ùúã2 ‚àà PUEvents and 1 ‚â§ ùëö ‚â§ ùëõ, we write
CBA[m,n] (ùúã1, ùúã2) to denote the property defined as follows:

CBA[m,n] (ùúã1, ùúã2) ‚âú Cnd(ùúã1, (PEvents‚â§maxa)m‚àí1; BAn‚àím+1 (ùúã2)).
Intuitively, if the triggering event ùúã1 occurs then the event ùúã2 must not occur in the time interval
between the ùëö-th and the ùëõ-th scan cycle.

As an example, we might enforce a conditional bounded absence property in PLC2 of our use
case in Section 4 to prevent water overflow in the tank ùëá2 due to a misuse of the valve connecting
the tanks ùëá1 and ùëá2. Assume that ùëß ‚àà N is the time (expressed in scan cycles) required to empty
the tank ùëá2 when the valve is closed and the tank ùëá2 reaches its high level ‚Ñé2. Then, we might
consider to enforce a property of the form CBA[1,w ] (h2, open_req), for ùë§ < ùëß, to prescribe that if the
tank reaches its high level (event ‚Ñé2) then PLC2 may not send a requests to open the valve (event
open_req) for the subsequent ùë§ scan cycles. This ensures us that when ùëá2 reaches its high level then
it will not ask for incoming water for at least ùë§ scan cycles, so preventing tank overflow.

5.1.3 Compound persistent conditional properties. Now, we formalise in our language of regular
properties a number of correctness properties used by Frehse et al. for the verification of hybrid
systems [24]. More precisely, we formalise bounded versions of their properties.

14

R. Lanotte, M. Merro, A. Munteanu

Fig. 6. A trace satisfying a minimum duration property MinD(ùúã1, ùúã2, m, n), for ùëö = ùëõ = 3.

Bounded minimum duration. When a triggering event ùúã1 occurs, if a second event ùúã2 occurs
within ùëö scan cycles then this event must appear in at least all subsequent ùëõ scan cycles (see
Figure 6). Formally, we can express this property as follows:

MinD(ùúã1, ùúã2, m, n) ‚âú Cnd(ùúã1, PCndm (ùúã2, BPn (ùúã2))).

Note that the property MinD(ùúã1, ùúã2, m, n) is satisfied each time CBP[m,m+n] (ùúã1, ùúã2) is. The vice
versa does not hold as in CBP[m,m+n] (ùúã1, ùúã2) the event ùúã2 is required to occur in the whole time
interval [ùëö, ùëö+ùëõ], while, according to MinD(ùúã1, ùúã2, m, n), the event ùúã2 might not occur at all.

Bounded maximum duration. When an event ùúã1 occurs, if a second event ùúã2 occurs within ùëö
scan cycles then the same event ùúã2 may occur in at most all subsequent ùëõ scan cycles. Formally, we
can represent this property as follows:

MaxD(ùúã1, ùúã2, m, n) ‚âú Cnd(ùúã1, PCndm (ùúã2, (PEvents‚â§maxa)n; BA1 (ùúã2))).
The property MaxD(ùúã1, ùúã2, m, n) is satisfied each time the property CBP[m,m+n] (ùúã1, ùúã2); BA1 (ùúã2) is.
Again, the vice versa does not hold.

Bounded response. When an event ùúã1 occurs, if a second event ùúã2 occurs within ùëö scan cycles
then a third event ùúã3 appears within ùëõ scan cycles. Formally, we can express this property as
follows:

BR(ùúã1, ùúã2, ùúã3, m, n) ‚âú Cnd(ùúã1, PCndm (ùúã2, BEn (ùúã3))).

Bounded invariance. Whenever an event ùúã1 occurs, if ùúã2 occurs within ùëö scan cycles then ùúã3 will

persistently occur for at least ùëõ scan cycles. Formally, we can express this property as follows:

BI(ùúã1, ùúã2, ùúã3, m, n) ‚âú Cnd(ùúã1, PCndm (ùúã2, BPn (ùúã3))).

5.1.4 Bounded mutual exclusion. A different class of properties prescribes the possible occurrence
of events ùúãùëñ ‚àà PEvents, for ùëñ ‚àà ùêº , in mutual exclusion within ùëö consecutive scan cycles. Formally,
for ùúãùëñ ‚àà PUEvents, ùëñ ‚àà ùêº and ùëö ‚â• 1, we write BMEm ( (cid:208)ùëñ ‚ààùêº {ùúãùëñ } ), for the property ùëûùëö
defined as:

maxa

maxa ‚à™ (cid:208)ùëñ ‚ààùêº ùúãùëñ .((cid:209)ùëó ‚ààùêº \{ùëñ } BAh (ùúãj)) ‚à™ (PEvents\ (cid:208)ùëñ ‚ààùêº {ùúãùëñ }).ùëû‚Ñé

ùëò‚àí1

, for 1 < ‚Ñé ‚â§ ùëö and

, for 1 < ‚Ñé ‚â§ ùëö

‚âú end ‚à™ (cid:208)ùëñ ‚ààùêº ùúãùëñ .((cid:209)ùëó ‚ààùêº \{ùëñ } BA1(ùúãj)) ‚à™ (PEvents\ (cid:208)ùëñ ‚ààùêº {ùúãùëñ }).ùëû1

, for 0 < ùëò ‚â§ maxa

ùëò‚àí1

‚âú end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
ùëò
0 < ùëò ‚â§ maxa
0 ‚âú end.ùëû‚Ñé‚àí1
‚Ä¢ ùëû‚Ñé
maxa
‚Ä¢ ùëû1
ùëò
‚Ä¢ ùëû1
0 ‚âú ùúñ.

As an example, we might enforce a bounded mutual exclusion property in the PLC1 of our use case
of Section 4 to prevent chattering of the valve, i.e., rapid opening and closing which may cause
mechanical failures on the long run. In particular, we might consider to enforce a property of the
form BME3 ({open, close}) saying that within 3 consecutive scan cycles the opening and the closing
of the valve (events open and close, respectively) may only occur in mutual exclusion.

In Table 4, we summarise all local properties represented and discussed in this section.

Runtime Enforcement of PLCs

15

Case:
Persistent conditional:
Bounded eventually:
Bounded persistency:
Bounded absence:
Conditional bounded eventually:
Conditional bounded persistency:
Conditional bounded absence:
(Bounded) Minimum duration:
(Bounded) Maximum duration:
Bounded response:
Bounded invariance:
Bounded mutual exclusion

if ùúãùëñ occurs then ùëùùëñ should be satisfied, for ùëñ ‚àà ùêº
for ùëö scan cycles, if ùúã occurs then ùëù should be satisfied
event ùúã must eventually occur within ùëö scan cycles
event ùúã must occur in all subsequent ùëö scan cycles
even ùúã must not occur in all subsequent ùëö scan cycles
if ùúã1 occurs then ùúã2 must eventually occur in the scan cycles [ùëö, ùëõ]
if ùúã1 occurs then ùúã2 must occur in all scan cycles of [ùëö, ùëõ]
if ùúã1 occurs then ùúã2 must not occur in all scan cycles of [ùëö, ùëõ]
when ùúã1, if ùúã2 in [1, ùëö] then ùúã2 persists for at least ùëõ scan cycles
when ùúã1, if ùúã2 in [1, ùëö] then ùúã2 persists for at most ùëõ scan cycles
when ùúã1, if ùúã2 in [1, ùëö] them ùúã3 appears within ùëõ scan cycles
when ùúã1, if ùúã2 in [1, ùëö] then ùúã3 persists for at least ùëõ scan cycles
events ùúãùëñ may only occur in mutual exclusion within ùëõ scan cycles

Table 4. Overview of local properties.

Fig. 7. A trace satisfying the just mentioned property for some ùëö, ùëõ = ùëö + 4 and ùëë = 4.

5.2 Global properties
As expected, the previously described local properties become global ones by applying the Kleene-
operator ‚àó. Once in this form, we can put these properties in conjunction between them. Here, we
show two global properties, the first one is built top of conditional bounded persistency properties
and the second one is built on top of a conditional bounded eventually property.

As a first example, we might consider a global property saying that whenever an event ùúã occurs
then all events ùúãùëñ , for ùëñ ‚àà ùêº , must occur in the ùëö-th scan cycle and in all subsequent ùëõ ‚àí ùëö scan
cycles, for 1 ‚â§ ùëö ‚â§ ùëõ. Formally, for ùúã, ùúãùëñ ‚àà PUEvents, ùëñ ‚àà ùêº , and 1 ‚â§ ùëö ‚â§ ùëõ: (cid:209)ùëñ ‚ààùêº (CBP[m,n] (ùúã, ùúãi))‚àó.
We might enforce this kind of property in PLC1 of our use case of Section 4. Assume ùëß ‚àà N
being the time (expressed in scan cycles) required to overflow the tank ùëá1 when the level of
the tank ùëá1 is low and both pumps are on and the valve is closed. Then, the property would be
(CBP[1,w ] (l1, on1))‚àó ‚à© (CBP[1,w ] (l1, on2))‚àó, with ùë§ < ùëß, saying that if the tank ùëá1 reaches its low level
(event ùëô1) then both pump1 and pump2 must be on (events on1 and on2) in all subsequent ùë§ scan
cycles, starting from the current one.

As a second example, we might consider a more involved global property relying on conditional
bounded eventually, persistent conditional, and bounded persistency. Basically, the property says
that whenever an event ùúã1 occurs then a second event ùúã2 must eventually occur between the ùëö-th
scan cycle and the ùëõ-th scan cycle, with 1 ‚â§ ùëö ‚â§ ùëõ; moreover, it must occur for ùëë consecutive scan
cycles, for 1 ‚â§ ùëë (see Figure 7). Formally, the property is the following:

(cid:0)CBE[m,n] (ùúã1, ùúã2)(cid:1) ‚àó ‚à© (cid:0)Cnd(ùúã1, PCndn (ùúã2, PEvents‚â§maxa; BPd‚àí1(ùúã2)))(cid:1) ‚àó
for ùúã1, ùúã2 ‚àà PUEvents, with 1 ‚â§ ùëö ‚â§ ùëõ and ùëë ‚â• 1. Intuitively, the property (CBE[m,n] (ùúã1, ùúã2))‚àó
requires that when ùúã1 occurs the event ùúã2 must eventually occur between the ùëö-th scan cycle and
the ùëõ-th scan cycle. The remaining part of the property says if the event ùúã2 occurs within the ùëõ-th
scan cycle (recall that ùëö ‚â§ ùëõ) then it must persist for ùëë scan cycles.

16

R. Lanotte, M. Merro, A. Munteanu

In this manner, we might strengthen the conditional bounded eventually property given in
Section 5.1 for PLC1 of our use case to prevent water overflow in the tank ùëá2. Let ùëß ‚àà N be the time
(expressed in scan cycles) required to overflow the tank ùëá2 when the valve is open and the level of
tank ùëá2 is low. The property is the following:

(cid:0)CBE[1,w ] (open_req, close)(cid:1)‚àó ‚à© (cid:0)Cnd(open_req, PCndw (close, PEvents‚â§maxa; BPd‚àí1 (close)))(cid:1)‚àó

where ùë§ << ùëß, and ùëë ‚àà N is the time (expressed in scan cycles) required to release in ùëá3 the
(maximum) quantity of water that the tank ùëá2 may accumulate in ùë§ scan cycles. The first part of
the property says that if PLC1 receives a request to open the valve (event open_req) then the valve
must be eventually closed (event close must eventually occur) within at most ùë§ scan cycles. The
remaining part of the property says that when PLC1 receives a request to open the valve (event
open_req), if the valve gets closed (event close) within the ùë§-th scan cycle, then it must remain closed
for the ùëë consecutive scan cycles. Here, ùëë depends both on the maximum level of water reachable
in ùëá2 in ùë§ scan cycles and on the physical law governing the water flow from ùëá2 to ùëá3.

6 MONITOR SYNTHESIS
In this section, we provide an algorithm to synthesise monitors from regular properties whose events
are contained in (the set of events associated to) a fixed set P of observable controller actions.
More precisely, given a global property ùëí ‚àà PropG the algorithm returns an edit automaton
‚ü®| ùëí |‚ü© P ‚àà Edit that is capable to enforce the property ùëí during the execution of a generic controller
whose possible actions are confined to those in P. The synthesis algorithm is defined in Table 5
by induction on the structure of the global/local property given in input; as we distinguish global
properties from local ones, we define our algorithm in two steps.

Remark 3. We recall that, according to the operational semantics defined in Table 1, all controller
actions ùõº are observable and they basically coincide with the set Events used to build up the enforcing
properties defined in Section 5. As a consequence, we will synthesise enforcing monitors that may
observe any action of the controller under scrutiny and may act consequently.

X = ‚ü®| ùúñ |‚ü© P

is given by the automaton ‚ü®| ùëù1 |‚ü© P
Z

The monitor ‚ü®| ùëù‚àó |‚ü© P associated to a global property ùëù‚àó is an edit automaton defined via the
recursive equation X = ‚ü®| ùëù |‚ü© P
, to recursively enforce the local property ùëù. The monitor ‚ü®| ùëí1 ‚à© ùëí2 |‚ü© P
X
is given by the cross product between the edit automata ‚ü®| ùëí1 |‚ü© P and ‚ü®| ùëí2 |‚ü© P, to accept only
traces that satisfy both ùëí1 and ùëí2; the definition of the cross product between two edit automata
recalls that for finite state automata, and it is reported in the appendix in Table 6. The monitor
. The
and ‚ü®| ùëù2 |‚ü© P
is given by the cross product between the edit automata ‚ü®| ùëù1 |‚ü© P
‚ü®| ùëù1 ‚à© ùëù2 |‚ü© P
X
X
X
; basically Z ties the
monitor ‚ü®| ùëù1; ùëù2 |‚ü© P
X
final states of the automaton enforcing ùëù1 with the initial state of the automaton enforcing ùëù2 (e.g.,
‚ü®| ùúñ; ùëù2 |‚ü© P
). The monitor associated to a union property ‚à™ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ
does the following: (i) allows all actions associated to the events ùúãùëñ , (ii) inserts an action associated
to some admissible event ùúãùëñ only when the controller wishes to prematurely complete the scan
cycle, i.e., it emits an end-action, and (iii) suppresses any other action except for tick- and end-actions.
Thus, the mitigation of the enforcement is actually implemented in the monitors synthesised
from union properties. In practise, when the controller under scrutiny complies with the property
enforced by the monitor, the two components, monitor and controller, evolve in a tethered fashion
(by applying rule (Allow)), moving through related correct states. However, if the controller gets
somehow corrupted (for instance, due to the presence of a malware) then the two components
will get misaligned reaching unrelated states. In this case, the enforcer mitigates the attack by
suppressing the remaining actions emitted by the controller (by applying rule (Suppress)) until the

Z = Z, for Z = ‚ü®| ùëù2 |‚ü© P

, where Z = ‚ü®| ùëù2 |‚ü© P
X

X

Runtime Enforcement of PLCs

17

‚ü®| ùëù‚àó |‚ü© P ‚âú X, for X = ‚ü®| ùëù |‚ü© P
X

‚ü®| ùëí1 ‚à© ùëí2 |‚ü© P ‚âú ProdP
X

(‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P ), X fresh

‚ü®| ùúñ |‚ü© P
X
‚ü®| ùëù1 ‚à© ùëù2 |‚ü© P
X
‚ü®| ùëù1; ùëù2 |‚ü© P
X
‚ü®| (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ |‚ü© P
X

‚âú X
‚âú ProdP
X
‚âú ‚ü®| ùëù1 |‚ü© P
Z
‚âú Z, for
Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

Z =

(‚ü®| ùëù1 |‚ü© P
, ‚ü®| ùëù2 |‚ü© P
)
X
X
, for Z = ‚ü®| ùëù2 |‚ü© P
, Z fresh
X

ùúãùëñ ‚â∫ end.‚ü®| ùëùùëñ |‚ü© P
X

ùúãùëñ .‚ü®| ùëùùëñ |‚ü© P
X
ùúãùëñ .‚ü®| ùëùùëñ |‚ü© P
X

(cid:205)
ùëñ‚ààùêº
(cid:205)
ùëñ‚ààùêº
where Q = P\(‚à™ùëñ‚ààùêº ùúãùëñ ‚à™{tick,end})

+ (cid:205)
ùëñ‚ààùêº
+ (cid:205)
ùõº ‚ààQ

‚àíùõº .Z, otherwise

+ (cid:205)
ùõº ‚ààQ

‚àíùõº .Z, if end ‚àâ ‚à™ùëñ ‚ààùêº ùúãùëñ

Table 5. Monitor synthesis from properties in PropG and PropL.

controller reaches the end of the scan cycle, signalled by the emission of the end-action1. After that,
if monitor and controller are not aligned the monitor will command the insertion of a safe trace,
without any involvement of the controller, via one or more applications of the rule (Insert). Safe
traces inserted in full autonomy by our enforcers always terminate with an end. Thus, when both
the controller and the monitor will be aligned, at the end of the scan cycle, they will synchronise
on the action end, via an application of the rule (Allow), and from then on they may continue in a
tethered fashion.

Remark 4. Note that even whe the controller is completely unreliable and the monitor inserts an
entire safe trace, the assumption made in Remark 1 ensures us that the enforced scan cycle always
ends well before a violation of the maximum cycle limit.

Now, we calculate the complexity of the synthesis algorithm based on the number of occurrences
of the operator ‚à© in ùëí and the dimension of ùëí, dim(ùëí), i.e., the number of all operators occurring in
ùëí. Intuitively, the size of a property is given by the number of operators occurring in it.

Definition 6. Let dim() : PropG ‚à™ PropL ‚Üí N be a property-size function defined as:

dim(ùëù‚àó)
dim(ùúñ)
dim(ùëù1 ‚à© ùëù2) ‚âú dim(ùëù1) + dim(ùëù2) + 1

‚âú dim(ùëù) + 1
‚âú 1

dim(ùëí1 ‚à© ùëí2)
dim(ùëù1; ùëù2)
dim((cid:208)ùëñ ‚ààùêº ùõºùëñ .ùëùùëñ ) ‚âú | ùêº | + (cid:205)ùëñ ‚ààùêº dim(ùëùùëñ ).

‚âú dim(ùëí1) + dim(ùëí2) + 1
‚âú dim(ùëù1) + dim(ùëù2) + 1

Proposition 1 (Complexity). Let ùëí ‚àà PropG be a global property and P be a set of actions
such that events(ùëí) ‚äÜ P. The complexity of the algorithm to synthesise ‚ü®| ùëí |‚ü© P is O (|P | ¬∑ ùëöùëò+1), with
ùëö = dim(ùëí) and ùëò being the number of occurrences of the operator ‚à© in ùëí.

In the following, we prove that the enforcement induced by our synthesised monitors enjoys the
properties stated in the Introduction: determinism preservation, transparency, soundness, deadlock-
freedom, divergence-freedom, and scalability. In this section, with a small abuse of notation, given a
set of observable actions P, we will use P to denote also the set of the corresponding events.

Given a deterministic global property ùëí, our synthesis algorithm returns a deterministic enforcer

(according to Definition 2), i.e., an enforcer that can be effectively implemented. Formally,

Proposition 2 (Deterministic preservation). Given a deterministic global property ùëí ‚àà

PropG over a set of events P. The edit automaton ‚ü®| ùëí |‚ü© P is deterministic.
1As said in Section2, a malware that aims to take control of the plant has no interest in delaying the scan cycle and risking
the violation of the maximum cycle limit whose consequence would be the immediate shutdown of the controller [59].

18

R. Lanotte, M. Merro, A. Munteanu

Let us move to transparency. Intuitively, the enforcement induced by a deterministic property
ùëí ‚àà PropG should preserve any execution trace satisfying ùëí itself (Definition 2 at pag. 5 of [40]).

Theorem 1 (Transparency). Let ùëí ‚àà PropG be a deterministic global property, P be a set of
observable actions such that events(ùëí) ‚äÜ P, and ùëÉ ‚àà Ctrl be a controller. Let ùë° = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëõ be a trace
of the controller ùëÉ with ùë° ‚àà
. Then, (1) ùë° is a trace of the edit automaton ‚ü®| ùëí |‚ü© P, and (2) there is no
trace ùë° ‚Ä≤ = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëò ¬∑ ùúÜ for ‚ü®| ùëí |‚ü© P such that 0 ‚â§ ùëò < ùëõ and ùúÜ ‚àà {‚àíùõºùëò+1, ùõº ‚â∫ ùõºùëò+1}, for some ùõº.

ùëí
(cid:74)

(cid:75)

Basically, conclusion (1) says that all execution trace ùë° (of a controller ùëÉ) satisfying the enforcing
property ùëí are allowed by the associated enforcer ‚ü®| ùëí |‚ü© P, while conclusion (2) says that allowing the
trace ùë° is the only possible option in the enforcement (this follows by the determinism of ùëí).

Another important property of our enforcement is soundness [40]. Intuitively, a controller under
the scrutiny of a monitor ‚ü®| ùëí |‚ü© P should only yield execution traces which satisfy the enforced
property ùëí, i.e., execution traces which are consistent with its semantics

(up to ùúè-actions).

Theorem 2 (Soundness). Let ùëí ‚àà PropG be a global property, P be a set of observable actions
such that events(ùëí) ‚äÜ P, and ùëÉ ‚àà Ctrl be a controller. If ùë° is a trace of the monitored controller
‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ } then ÀÜùë° is a prefix of some trace in

(see Notation 1 for the definition of the trace ÀÜùë°).

Here, it is important to stress that in general soundness does not ensure deadlock-freedom of the
monitored controller. That is, it may be possible that the enforcement of some property ùëí causes a
deadlock of the controller ùëÉ under scrutiny. In particular, this may happen in our controllers only
when the initial sleeping phase does not match the enforcing property (e.g., ùëÉ = tick.ùëê.end.ùëÉ and
ùëí = (ùëê.end)‚àó). Intuitively, a local property will be called a ùëò-sleeping property if it allows ùëò initial
time instants of sleep. Formally,

ùëí
(cid:74)

(cid:75)

ùëí
(cid:74)

(cid:75)

Definition 7. For ùëò ‚àà N+, we say that ùëù ‚àà PropL is a ùëò-sleeping local property, only if
ùëò ¬∑ùë° ‚Ä≤
ùëñ , and 1 ‚â§ ùëñ ‚â§ ùëõ}. We say that ùëù‚àó is a
ùëù
(cid:74)
ùëò-sleeping global property only if ùëù is, and ùëí = ùëí1 ‚à© ùëí2 is ùëò-sleeping only if both ùëí1, ùëí2 are ùëò-sleeping.

= {ùë° | ùë° = ùë°1 ¬∑ ... ¬∑ ùë°ùëõ, for ùëõ > 0, s.t. ùë°ùëñ = tick

ùëñ ¬∑end, end ‚àâ ùë° ‚Ä≤

(cid:75)

The enforcement of ùëò-sleeping properties does not introduce deadlocks in ùëò-sleeping controllers.
This is because our synthesised monitors suppress all incorrect actions of the controller under
scrutiny, driving it to the end of its scan cycle. Then, the controller remains in stand-by while the
monitor yields a safe sequence of actions to mimic a safe completion of the current scan cycle.

Theorem 3 (Deadlock-freedom). Let ùëí ‚àà PropG be a ùëò-sleeping global property, and P be a
ùëò .ùëÜ

set of observable actions such that events(ùëí) ‚äÜ P. Let ùëÉ ‚àà Ctrl be a controller of the form ùëÉ = tick
whose set of observable actions is contained in P. Then, ‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ } does not deadlock.

Another important property of our enforcement mechanism is divergence-freedom. In practice, the
enforcement does not introduce divergence: monitored controllers will always be able to complete
their scan cycles by executing a finite number of actions. This is because we limit our enforcement
to well-formed properties (Definition 4) which always terminates with an end event. In particular,
the well-formedness of local properties ensures us that in a global property of the form ùëù‚àó the
number of events within two subsequent end events is always finite.

Theorem 4 (Divergence-freedom). Let ùëí ‚àà PropG be a global property, P be a set of observable
actions such that events(ùëí) ‚äÜ P, and ùëÉ ‚àà Ctrl be a controller. Then, there exists a ùëò ‚àà N+ such that
whenever ‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ }

ùë° ‚Ä≤
‚àí‚àí‚àí‚Üí E‚Ä≤ ‚ä≤‚ä≥ {ùêΩ ‚Ä≤}, with | ùë° ‚Ä≤ |‚â• ùëò, then end ‚àà ùë° ‚Ä≤.

ùë°
‚àí‚àí‚Üí E ‚ä≤‚ä≥ {ùêΩ }, if E ‚ä≤‚ä≥ {ùêΩ }

Notice that all properties seen up to now scale to field communications networks of controllers.
This means that they are preserved when the controller under scrutiny is running in parallel with
other controllers in the same field communications network. As an example, by an application

Runtime Enforcement of PLCs

19

Fig. 8. Some physical components of our implementation.

of Theorems 1 and 2, we show how both transparency and soundness scale to field networks. A
similar result applies to the remaining properties.

Corollary 1 (Scalability to networks of PLCs). Let ùëí ‚àà PropG be a global property and P
be a set of observable actions, such that events(ùëí) ‚äÜ P. Let ùëÉ ‚àà Ctrl be a controller and ùëÅ ‚àà FNet
be a field network. If (‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ }) ‚à• ùëÅ
ùë° ‚Ä≤
‚àí‚àí‚àí‚Üí ùêΩ , with ùë° ‚Ä≤ = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëõ ‚àà

, the trace ùë° ‚Ä≤ is a trace of ‚ü®| ùëí |‚ü© P and there is no trace
ùëí
(cid:75)
(cid:74)
ùë° ‚Ä≤‚Ä≤ = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëò ¬∑ ùúÜ of ‚ü®| ùëí |‚ü© P such that 0 ‚â§ ùëò < ùëõ and ùúÜ ‚àà {‚àíùõºùëò+1, ùõº ‚â∫ ùõºùëò+1}, for some ùõº;

ùë°
‚àí‚àí‚àí‚Üí (E ‚ä≤‚ä≥ {ùêΩ }) ‚à• ùëÅ ‚Ä≤, for some ùë°, E, ùêΩ and ùëÅ ‚Ä≤, then

‚Ä¢ whenever ùëÉ

‚Ä¢ whenever ‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ }

ùë° ‚Ä≤
‚àí‚àí‚àí‚Üí E ‚ä≤‚ä≥ {ùêΩ } the trace (cid:98)ùë° ‚Ä≤ is a prefix of some trace in

.

ùëí
(cid:74)

(cid:75)

7 OUR ENFORCEMENT MECHANISM AT WORK
In this section, we propose an implementation of our enforcement mechanism in which monitors,
running on field-programmable gate arrays (FPGAs) [61], enforce open source PLCs [8], running on
Raspberry Pi devices [25], and governing a physical plant simulated in Simulink [44]. The section has
the following structure. In Section 7.1, we argue why FPGAs are good candidates for implementing
secure proxies. In Section 7.2, we describe how we implemented the whole enforcement architecture
for the use case of Section 4. In Section 7.3, we test our implementation injecting the enforced PLCs
with five different malware aiming at causing three different physical perturbations: tank overflow,
valve damage, and pump damage. The attacks have been chosen to cover as much as possible the
attacker model of Section 2. In particular, they include: a drop of the actuator commands of the
valve, an integrity attack on the water-level sensors, a forgery of the actuator commands of the
valve, a forgery of the message requests to open/close the valve, and a forgery of the actuator
commands of the pumps. Section 7.4 discusses the performance of our implementation.

7.1 FPGAs as secure proxies for ICSs
Field-programmable gate arrays (FPGAs) are semiconductor devices that can be programmed to
run specific applications. An FPGA consists of (configurational) logic blocks, routing channels and
I/O blocks. The logic blocks can be configured to perform complex combinational functions and are
further made up of transistor pairs, logic gates, lookup tables and multiplexers. The applications
are written using hardware description languages, such as Verilog [60]. Thus, in order to execute
an application on the FPGA, its Verilog code is converted into a sequence of bits, called bitstream,
that is loaded into the FPGA.

FPGA are assumed to be secure when the adversary does not have physical access to the device, i.e.,
the bitstream cannot be compromised [32]. Recent FPGAs support remote updates of the bitstream
by relying on authentication mechanisms to prevent unauthorised uploads of malicious logic [32].

20

R. Lanotte, M. Merro, A. Munteanu

Fig. 9. An implementation in Simulink of the plant of the SWaT system.

Nevertheless, as said in the Introduction and advocated by McLaughlin and Mohan [45, 46], any
form of runtime reconfiguration should be prevented. Summarising, under the assumption that the
adversary does not have physical access to the FPGA and she cannot do remote updates, FPGAs
represent a good candidate for the implementation of secure enforcing proxies.

7.2 An implementation of the enforcement of the SWaT system of Section 4
The proposed implementation adopts different approaches for plant, controllers and enforcers.

Plant. The plant of the SWaT system is simulated in Simulink [44], a framework to model,
simulate and analyse cyber-physical systems, widely adopted in industry and research. A Simulink
model is given by blocks interconnected via wires. Our Simulink model contains blocks to simulate
water tanks, actuators (i.e., pumps and valves) and sensors (see Figure 9). In particular, water-tank
blocks implement the differential equations that model the dynamics of the tanks according to
the physical constraints obtained from [27, 43]. Actuation blocks receive commands from PLCs,
whereas sensor blocks send measurements to PLCs. For simplicity, state changes of both pumps
and valves do not occur instantaneously; they take 1 second. We ran our Simulink model on a
laptop with 2.8 GHz Intel i7 7700 HQ, 16GB memory, and Linux Ubuntu 20.04 LTS OS.

Controllers. Controllers are defined in OpenPLC [8], an open source PLC capable of running user
programs in all five IEC61131-3 defined languages [1]. Additionally, OpenPLC supports standard
SCADA protocols, such as Modbus/TCP, DNP3 and Ethernet/IP. OpenPLC can run on a variety of
hardware, from a simple Raspberry Pi to robust industrial boards. We installed OpenPLC on three
Raspberry Pi 4 [55]; each instance runs one of the three ladder logics seen in Figure 4.

Enforcers. Enforcers are implemented using three NetFPGA-CML development boards [63]. Our
synthesis algorithm is implemented in Python to return enforcers written in Verilog, and checked
for correctness using ModelSim. The Verilog code is then compiled into a bitstream and executed
in the FPGA. More precisely, our algorithm in Python takes as input a JSON file containing the
property to be synthesised and other relevant informations, such as the number of input/output
signals and a fixed priority among admissible safe output signals. Then, the property is parsed by
means of the ANTLR parser [48]. After the parsing, our algorithm implements the synthesis of
Table 5 to derive the enforcing edit automaton; this is written down into a JSON file. At this stage,
the derived edit automaton is still somewhat abstract, as both end- and tick-actions are explicitly
represented. Finally, the algorithm compiles the edit automaton into an enforcer written in Verilog,
where the above abstractions are implemented. In particular, the passage of time (i.e., tick-actions)
is represented and monitored via clock variables, while the end of scan cycles (i.e., end-actions) is
implemented via specific code to synchronise enforcers and controllers, relying on clock variables.
Thus, before each scan cycle the enforcer forwards the current inputs (coming from the plant) to
the controller. Then, when the scan cycle is completed, it receives from the controller all the current

pump1pump2valveleveloutTank	1inleveloutTank	2inpumpleveloutTank	3indirty	waterclean	water	Water	filterClean	waterpump1pump2valveActuators	tank	1levelSensor	tank	1levelSensor	tank	2levelSensor	tank	3pumpActuator	tank	3Runtime Enforcement of PLCs

21

Fig. 10. Tank overflow: Ladder Logic of the first (left) and the second attack (right).

outputs, and forwards them to the actuators. In the meanwhile, the enforcer monitors the passage
of time via its clock variables, and when the scan cycle is completed (i.e., the controller sends all
outputs) it moves to the state corresponding to the following scan cycle. Finally, in our FPGAs we
also write some code to implement an UDP-based network connecting together enforcers, PLCs,
and the simulated plant.

The code of the three PLCs, the algorithm in Python, the enforcers written in Verilog, and the

Simulink simulations can be found at: https://bitbucket.org/formal_projects/runtime_enforcement.

7.3 The enforced SWaT system under attack
In this section, we consider five different attacks targeting the PLCs of the SWaT system to achieve
three possible malicious goals: (i) overflow the water tanks, (ii) damage of the valve, (iii) damage
of the pumps. In order to simulate the injection of malware in the PLCs, we reinstall the original
PLC ladder logics with compromised ones, containing some additional logic intended to disrupt
the normal operations of the PLC [28]. In the following, we will discuss these attacks, grouped by
goals, showing how the enforcement of specific properties mitigates the attacks by preserving the
correct behaviour of the monitored PLCs.

Tank overflow. Our first attack is a DoS attack targeting PLC1 by dropping the commands to close
the valve. In the left-hand side of Figure 10 we show a possible implementation of this attack in
ladder logic. Basically, the malware remains silent for 500 seconds and then it sets true a malicious
drop variable (highlighted in yellow). Once the variable drop becomes true, the valve variable is
forced to be false (highlighted in red), thus preventing the closure of the valve.

In order to prevent attacks aiming at overflowing the tanks, we propose the following three

enforcing properties, one for each PLC, respectively:

‚Ä¢ ùëí1 ‚âú (CBP[1,m] (h1, off1))‚àó ‚à© (CBP[1,m] (h1, off2))‚àó, an intersection between two conditional
bounded persistency properties to enforce PLC1 to prevent water overflow in ùëá1. This property
ensures that both pumps pump1 and pump2 are off, for ùëö consecutive scan cycles, when the
level of ùëá1 is high (measurement ‚Ñé1). Here, ùëö < ùëõ for ùëõ ‚àà N is the number of scan cycles
required to empty ùëá1 when its level is high, both pumps are off, and the valve is open.

‚Ä¢ ùëí2 ‚âú (CBP[1,u] (h2, close_req))‚àó, a conditional bounded persistency property for PLC2 ensuring
that requests to close the valve (event close_req) are sent for ùë¢ consecutive scan cycles when
the level of water in tank ùëá2 is high (measurement ‚Ñé2). Here, ùë¢ < ùë£ for ùë£ ‚àà N is the number of
scan cycles required to empty the tank ùëá2 when the level is high and the valve is closed.
‚Ä¢ ùëí3 ‚âú (CBP[1,w ] (h3, on3))‚àó, a conditional bounded persistency property for PLC3 to ensure
that pump3 is on for ùë§ consecutive scan cycles when the level of water in tank ùëá3 is high

22

R. Lanotte, M. Merro, A. Munteanu

Fig. 11. Tank overflow: DoS attack on PLC1 when enforcing ùëí1, ùëí2, ùëí3 (up) and ùëí ‚Ä≤

1, ùëí2, ùëí3 (down).

(measurement ‚Ñé3). Here, ùë§ < ùëß for ùëß ‚àà N is the time (expressed in scan cycles) required to
empty the tank ùëá3 when the level is high and pump3 is on.

Now, let us analyse the effectiveness of the enforcement induced by these three properties. For
instance, in the upper graphs of Figure 11 we report the impact on the tanks ùëá1 and ùëá2 of the DoS
attack previously described, when enforcing the three properties ùëí1, ùëí2 and ùëí3 in the corresponding
PLCs. Here, the red region denotes when the attack becomes active. As the reader may notice,
despite repeated requests to close the valve coming from PLC2, the compromised PLC1 never closes
the valve causing the overflow of tank ùëá2. So, the enforced property ùëí1 is not up the task.

In order to prevent this attack, we must guarantee that PLC1 closes the valve when PLC2
requests so. Thus, we should enforce in PLC1 a more demanding property ùëí ‚Ä≤
1 defined as follows:
ùëí1 ‚à© CBE[1,1] (close_req, close). Basically, the last part of the property ensures that every request to
close the valve is followed by an actual closure of the valve in the same scan cycle. The impact of
the malware on PLC1 when enforcing the properties ùëí ‚Ä≤
1, ùëí2, ùëí3 is represented in the lower graphs of
Figure 11. Now, the correct behaviour of PLC1 is ensured, thus preventing the overflowing of the
water tank ùëá2. In these graphs, the green highlighted regions denote when the monitor detects the
attack and mitigates the activities of the compromised PLC1. In particular, the monitor inserts the
commands to close the valve on behalf of PLC1 when PLC2 sends requests to close the valve.

Having strengthened the enforcing property for PLC1 one may think that the enforcement of ùëí2
in PLC2 is now superfluous to prevent water overflow in ùëá2. However, this is not the case if the
attacker can compromise PLC2. Consider a second attack to PLC2, an integrity attack that adds an
offset of ‚àí30 to the measured water level of ùëá2. We show a ladder logic implementation of such
attack in the right-hand side of Figure 10 where, for simplicity, we omit the initial silent phases
lasting 500 seconds. The impact on the tanks ùëá1 and ùëá2 of the malware injected in PLC2 in the
presence of the enforcing of the properties ùëí ‚Ä≤
1 and ùëí3, respectively, is represented on the upper
graphs of Figure 12. Again, the red region shows when the attack becomes active. As the reader
may notice, the compromised PLC2 never sends requests to close the valve causing the overflow
1, ùëí2, ùëí3 in the three
of the water tank ùëá2. On the other hand, when enforcing the three properties ùëí ‚Ä≤

Runtime Enforcement of PLCs

23

Fig. 12. Tank overflow: integrity attack on PLC2 when enforcing ùëí ‚Ä≤

1, ùëí3 (up) and ùëí ‚Ä≤

1, ùëí2, ùëí3 (down).

Fig. 13. Valve damage: Ladder logic of the first (left) and the second attack (right).

PLCs, the lower graphs of Figure 12 shows that the overflow of tank ùëá2 is prevented. Again, the
green highlighted regions denote when the monitor detects the attack and mitigates the commands
of the compromised PLC2. Here, the monitor inserts the request to close the valve on behalf of PLC2
when ùëá2 reaches a high level.

Valve damage. We now consider attacks whose goal is to damage the valve via chattering, i.e.,
rapid alternation of openings and closings of the valve that may cause mechanical failures on the
long run. In the left-hand side of Figure 13 we show a possible ladder logic implementation of a
third attack that does injection of the commands to open and close the valve. In particular, the attack
repeatedly alternates a stand-by phase, lasting 70 seconds, and a injection phase, lasting 30 seconds
(yellow region); then, in the injection phase the valve is opened and closed rapidly (red region).
With no enforcement, the impact of the attack on the tanks ùëá1 and ùëá2 is represented on the upper
graphs of Figure 14, where the red region denotes when the attack becomes active. From the graph

24

R. Lanotte, M. Merro, A. Munteanu

Fig. 14. Valve damage: injection attack on PLC1 in the absence (up) and in the presence (down) of enforcement.

associated to the execution of ùëá1 the reader can easily see that the valve is chattering. Note that
this is a stealthy attack as the water level of ùëá2 is maintained within the normal operation bounds.
In order to prevent this kind of attacks, we might consider to enforce in PLC1 a bounded mutual
1 ‚âú (BME10000 {open, close})‚àó to ensure that within 10000 consecutive
exclusion property of the form ùëí ‚Ä≤‚Ä≤
scan cycles (10 seconds) openings and the closings of the valve may only occur in mutual exclusion.
1 is enforced in PLC1, the lower graphs of Figure 14 shows that the chattering
When the property ùëí ‚Ä≤‚Ä≤
of the valve is prevented. In particular, the green highlighted regions denote when the monitor
detects the attack and mitigates the commands on the valves of the compromised PLC1.

A fourth attack with the same goal of chattering the valve may be launched on PLC2, by sending
rapidly alternating requests to open and close the valve. This can be achieved by means of an
integrity attack on the sensor of the tank ùëá2 by rapidly switching the measurements between low
and high. In the right-hand side of Figure 13 we show parts of the ladder logic implementation of
this attack on PLC2, where, for simplicity, we omit the machinery for dealing with the alternation
of phases. Again, the attack repeatedly alternates between a stand-by phase, lasting 70 seconds, and
a active phase, lasting 30 seconds. When the attack is in the active phase (red region) the measured
water level of ùëá2 rapidly switches between low and high, thus, sending requests to PLC1 to rapidly
open and close the valve in alternation.

The impact of this attack targeting on PLC2 in the absence of an enforcing monitor is represented
in the upper graphs of Figure 15, where the red region shows when the attack becomes active.
Notice that the rapid alternating requests originating from PLC2 cause a chattering of the valve.
On the other hand, with the enforcement of the property ùëí ‚Ä≤‚Ä≤
1 in PLC1 , the lower graph of Figure 15
shows that the correct behaviour of tanks ùëá1 and ùëá2 is ensured. In that figure, the green highlighted
regions denote when the enforcer of PLC1 detects the attack and mitigates the commands (on the
valve) of the compromised PLC2. Notice that in this case no enforcement is required in PLC2.

Pump damage. Finally, we consider attacks whose goal is the damage of the pumps, and in
particular pump3. In that case, an attacker may force the pump to start when the water tank ùëá3 is

Runtime Enforcement of PLCs

25

Fig. 15. Valve damage: integrity attack on PLC2 in the absence (up) and in the presence (down) of enforcement.

empty. This can be done with a fifth attack that injects commands to turn on the pump based on a
ladder logic implementation similar to that seen in Figure 10. The impact of this attack to tank ùëá3
in the absence of enforcement is represented on the left-hand side graphs of Figure 16, where the
red region shows when the attack becomes active. As the reader may notice, pump3 is turned on
when ùëá3 is empty.

Now, we can prevent damage on pump3 by enforcing on PLC3 the following conditional bounded
3 ‚âú (CBP[1,w ] (l3, off3))‚àó. The enforcement of this property ensures that pump3
persistent property: ùëí ‚Ä≤
is off for ùë§ consecutive scan cycles when the level of water in tank ùëá3 is low, for ùë§ < ùëß and ùëß ‚àà N
being the time (expressed in scan cycles) required fill up tank ùëá3 when the pump is off. Thus, when
the enforcement of the ùëí ‚Ä≤
3 is active, the lower graphs of Figure 16 shows that the correct behaviour
of ùëá3 is ensured, thus preventing pump damage. In that figure, the green highlighted regions denote
when the monitor detects the attack and mitigates the commands (of the pumps) of the compromised
PLC3. More precisely, the enforcer suppresses the commands to turn on the pump when the tank is
empty, for ùë§ consecutive scan cycles.

7.4 Discussion
In this section, we rely on the Vivado Design Suite 15.2 analysis tool to do a performance analysis
of our implementation.

As to the hardware resources used by our FPGAs, we measured them in terms of lookup tables
and registers used during the enforcement. The number of them depends on the number of states
of the enforcers implemented in the FPGAs. And this number is proportional to the number of scan
cycles involved in the enforced (local) property. In particular, for each scan cycle, the number ùëò of
states of the enforcer depends on the monitored input/output signals and their admissible values.
For instance, for scan cycles taking 10 ms (0.1kHz), an enforced local property lasting 10 seconds
will cover 1000 consecutive scan cycles, and the synthesised enforcer would have ùëò ‚àó 1000 states. In
our experiments, when enforcing properties covering 1000 scan cycles the hardware resource use
reaches 5%; for 10000 scan cycles the resource use rises to 13%.

26

R. Lanotte, M. Merro, A. Munteanu

Fig. 16. Pump damage: injection attack on PLC3 in the absence (up) and in the presence (down) of enforcement.

As for the execution speed of the enforcement, in general all FPGAs are capable of running at a
speed of 100 MHz (or higher). The actual execution speed depends on the complexity of the underly-
ing code, in our case the enforcer, plus some extra code to implement the network communication
protocol (UDP). In our experiments, FPGAs ran with a frequency of 1 MHz while PLCs ran with a
frequency of 0.1-1kHz. Thus, the overhead introduced by the FPGAs is negligible, independently
on the size (the number of states) of the enforcer implemented in the FPGAs. We recall that in
Remark 1 we assumed that our enforced controllers successfully complete their scan cycle in less
than half of the maximum cycle limit (just in case the scan cycle should be entirely corrected by
the enforcer). However, using FPGAs as enforcers this constraint can be actually relaxed.

Finally, concerning the communication latency between enforcers, many FPGAs support high
speed and low latency communications, which are the ones used in industrial control contexts [47].
We used FPGAs with Ethernet ports supporting 1 Gbps speed, i.e., with 100 microseconds latency.
Furthermore, thanks to our result of scalability (Corollary 1), a network of enforcing FPGAs
introduces a negligible overhead in terms of communication latency and hardware resources.

8 RELATED WORK
The notion of runtime enforcement was introduced by Schneider [56] to enforce security policies via
truncation automata, a kind of automata that terminates the monitored system in case of violation
of the property. Thus, truncation automata can only enforce safety properties. Furthermore, the
resulting enforcement may obviously lead to deadlock (actually termination) of the monitored
system with no room for mitigation.

Ligatti et al. [40] extended Schneider‚Äôs work by proposing the notion of edit automata, i.e., an
enforcement mechanism able of replacing, suppressing and inserting system actions. Edit automata
are capable of enforcing instances of safety and liveness properties, along with other properties such
as renewal properties [12, 40]. In general, Ligatti et al.‚Äôs edit automata are deterministic automata
with an enumerable number of states, whereas in the current paper we restrict ourselves to finite-
state edit automata equipped with Martinelli and Matteucci‚Äôs operational semantics [42]. Ligatti
et al. [40] studied a hierarchy of enforcement mechanisms, each with different transformational
capabilities: Schneider‚Äôs truncation automata, suppression automata, insertion automata, and finally,
edit automata that combine the power of suppression and insertion automata. They defined different
notions of enforcement, and in particular the so called precise enforcement (Definition 2, pag. 5)
which basically corresponds to the combination of our notion of transparency and soundness,
proved in Theorems 1 and 2, respectively.

Bielova and Massacci [12, 13] provided a stronger notion of enforceability by introducing a
predictability criterion to prevent monitors from transforming invalid executions in an arbitrary
manner. Intuitively, a monitor is said predictable if one can predict the number of transformations

Runtime Enforcement of PLCs

27

used to correct invalid executions. In our setting, in case of injection of a malware which may act
in an unpredictable manner, this approach appears unfeasible.

Falcone et al. [21, 22] proposed a synthesis algorithm, relying on Streett automata, to translate
most of the property classes defined within the safety-progress hierarchy [41] into (a slight variation
of) edit automata. In the safety-progress hierarchy, our global properties can be seen as guarantee
properties for which all execution traces that satisfy a property contain at least one prefix that still
satisfies the property. However, it should be noticed that they consider untimed properties only; as
already pointed out before, timed actions play a special role in our enforcement and they cannot be
treated as untimed actions.

Beauquier et al. [10] proved that finite-state edit automata (i.e. those edit automata we are actually
interested in) can only enforce a sub-class of regular properties. Actually they can enforce all and
only the regular properties that can be recognised using finite automata whose cycles always
contain at least one final state. This is the case of our enforced regular properties, as well-formed
local properties in PropL always terminate with the ‚Äúfinal‚Äù atomic property end.

Pinisetty and Tripakis [51] studied the compositionality of the enforcement of different regular
properties ùëù1, . . . , ùëùùëõ at the same time, by composing the associated enforcing monitors. The idea is
to replace a monolithic approach, in which a monitor is sinthesised from the property ùëù1 ‚à© . . . ‚à© ùëùùëõ,
with a compositional one, where the ùëõ monitors enforcing the properties ùëùùëñ are somehow put
together to enforce ùëù1 ‚à© . . . ‚à© ùëùùëõ. The authors of [51] proved that runtime enforcement is not
compositional with respect to general regular properties, neither with respect to serial nor parallel
composition. On the other hand compositionality holds for certain sub-classes of regular properties
such as safety (or co-safety) properties. Here, we wish to point out that our notion of scalability is
different from their notion of compositionality, as we aim at scaling our enforcement on a network
of PLCs and not on multiple regular properties on the same PLC.

Bloem et al. [14] defined a synthesis algorithm that given a safety property returns a monitor,
called shield, to enforce untimed properties in reactive systems (which have many aspects in common
with control systems). Their algorithm rely on a notion called ùëò-stabilization: when the design
reaches a state where a property violation becomes unavoidable for some possibile future inputs,
the shield is allowed to deviate for at most ùëò ‚àà N steps; if a second violation happens during
the ùëò-step recovery phase, the shield enters a fail-safe mode where it only enforces correctness,
but no longer minimises the deviation. However, The ùëò-stabilizing shield synthesis problem is
unrealisable for many safety-critical systems, because a finite number of deviations cannot be
guaranteed. Humphrey et al. [33] addressed this problem by proposing the notion of admissible
shields which was extended and generalised in K√∂nighofer et al. [34] by assuming that systems
have a cooperative behaviour with respect to the shield, i.e., the shield ensures a finite number of
deviations if the system chooses certain outputs. The authors presented a synthesis procedure that
maximises the cooperation between system and environment for satisfying the required enforced
properties. This approach has some similarities with our enforcement in which a violation of a
property during a scan cycle induces the suppression of all subsequent controller actions until
the PLC reaches the end of the scan, so the monitor can insert a safe trace before permitting the
completion of the scan cycle.

Pinisetty et al. [50] proposed a bi-directional runtime enforcement mechanism for reactive systems,
and more generally for cyber-physical relying on Berry and Gonthier‚Äôs synchronous hypothesis [11],
to correct both inputs and outputs. Pinisetty et al. express safety properties in terms of Discrete
Timed Automata (DTA) which are more expressive than our class of regular properties. Thus, an
execution trace satisfies a required property only if it ends up on a final state of the corresponding
DTA. However, as not all regular properties can be enforced [10], they proposed a more permissive
enforcement mechanism that accepts execution traces as long as there is still the possibility of

28

R. Lanotte, M. Merro, A. Munteanu

reaching a final state. Furthermore, due to the instantaneity of the synchronous approach, their
enforcement actions are applied in the same reaction step to ensure reactivity. On the contrary, in
our approach the enforcement takes places before the conclusion of scan cycles which are clearly
delimited via end-actions. Our notion of deterministic enforcers is taken from Pinisetty et al. [50].
Moreover, when inserting safe actions, our synthesised enforcers follows Pinisetty et al.‚Äôs random
edit approach, where the inserted safe action is randomly chosen from a list of admissible actions.
Pearce et al. [49] proposed a bi-directional runtime enforcement over valued signals for PLCs, by
introducing smart I/O modules (similar to our secure proxy) between the PLCs and the controlled
physical processes, to act as an effective line of defence. The authors express security properties in
terms of Values Discrete Timed Automata (VDTA), inspired by the DTA of Pinisetty et al. [50]. Unlike
DTA, VDTA support valued signals, internal variables, and guard conditions. As in Pinisetty et
al. [50], the paper adopts the synchronous hypothesis [11] to correct both inputs and outputs; thus,
their enforcement actions are applied in the same reaction step to ensure instantaneous reactivity.
The authors do not consider attacks that may tamper with inter-controller communications: their
attackers may only manipulate sensor signals and/or actuator commands. Finally, their semantics
requires that every enforcer knows the state of all relevant signals and commands in a given system.
Thus, as written by the same authors, a networked system featuring multiple I/O modules may
significantly complicate the enforcement, as pertinent I/O for a security policy may not be locally
available. As a consequence, unlike us, their enforcement does not naturally scale to networks of
controllers; we believe this is basically due to the fact that they do bi-directional enforcement. Last
but not least, like them, we implement enforcers via FPGAs to ensure efficiency and security at the
same time. In particular, when inserting safe actions our implementation fixes a priority between
admissible safe actions, similarly to their selected edit approach. However, our implementation
differs from theirs in at least the following aspects: (1) our FPGAs do enforce PLC transmissions
(with a negligible latency); (2) our enforcement is uni-directional and hence our FPGAs need to know
only the state of signals and commands of the corresponding enforced PLCs; (3) as a consequence,
our FPGAs can be networked to monitor field communications networks paying only negligible
overhead in terms of computational resources and communication latency.

Aceto et al. [6] developed an operational framework to enforce properties in HML logic with
recursion (ùúáHML) relying on suppression. More precisely, they achieved the enforcement of a safety
fragment of ùúáHML by providing a linear automated synthesis algorithm that generates correct
suppression monitors from formulas. Enforceability of modal ùúá-calculus (a reformulation of ùúáHML)
was previously tackled by Martinelli and Matteucci [42] by means of a synthesis algorithm which
is exponential in the length of the enforceable formula. Cassar [18] defined a general framework
to compare different enforcement models and different correctness criteria, including optimality.
His works focuses on the enforcement of a safety fragment of ùúáHML, paying attention to both
uni-directional and bi-directional notions of enforcement. More recently, Aceto et al. [7] developed
an operational framework for bi-directional enforcement and used it to study the enforceability of
the aforementioned safety fragment of HML with recursion, via a specific type of bi-directional
enforcement monitors called action disabling monitors.

As regards papers in the context of control system security closer to our objectives, McLaugh-
lin [45] proposed the introduction of an enforcement mechanism, called C2, similar to our secure
proxy, to mediate the control signals ùë¢ùëò transmitted by the PLC to the plant. Thus, like our secured
proxy, C2 is able to suppress commands, but unlike our proxy, it cannot autonomously send com-
mands to the physical devices in the absence of a timely correct action from the PLC. Furthermore,
C2 does not seem to cope with inter-controller communications, and hence with colluding malware
operating on PLCs of the same field network.

Runtime Enforcement of PLCs

29

Mohan et al. [46] proposed a different approach by defining an ad-hoc security architecture,
called Secure System Simplex Architecture (S3A), with the intention to generalise the notion of
‚Äúcorrect system state‚Äù to include not just the physical state of the plant but also the cyber state
of the PLCs of the system. In S3A, every PLC runs under the scrutiny of a side-channel monitor
which looks for deviations with respect to safe executions, taking care of real-time constraints,
memory usage, and communication patterns. If the information obtained via the monitor differs
from the expected model(s) of the PLC, a decision module is informed to decide whether to pass the
control from the ‚Äúpotentially compromised‚Äù PLC to a safety controller to maintain the plant within
the required safety margins. As reported by the same authors, S3A has a number of limitations
comprising: (i) the possible compromising of the side channels used for monitoring, (ii) the tuning
of the timing parameters of the state machine, which is still a manual process.

The present work is a revised extension of the conference version appeared in [36]. Here, we
provide a detailed comparison with that paper. In Section 2 we specified the attacker model and the
attacker objectives. In Section 3, we adopted a simplified operational semantics for edit automata,
in the style of Martinelli and Matteucci [42]. In Section 5, we have extended our language of
regular properties with intersection of both local and global properties. With this extension we
have expressed a wide family of correctness properties that can be combined in a modular fashion;
these properties include and extend the three classes of properties appearing in the conference
paper. In Section 6, we have extended our synthesis algorithm to deal with our extended properties:
both local and global intersection of properties are synthesised in terms of cross products of edit
automata. Notice that, compared to the conference paper, our enforcement mechanism does not rely
anymore on an ad-hoc semantic rule (Mitigation) to insert safe actions at the end of the scan cycle,
but rather on the more standard rule (Insert) together with the syntactic structure of synthesised
enforcers. As stated in Proposition 1, now our synthesis algorithm depends on the size and the
number of occurrences of intersection operators of the property in input. Last but not least, in this
journal version we provide an implementation of our use case based on: (i) Simulink to simulate
the physical plant, (ii) OpenPLC on Raspberry Pi to run open PLCs, and (iii) FPGAs to implement
enforcers. We have then exposed our implementation to five different attacks targeting the PLCs
and discussed the effectiveness of the proposed enforced mechanism.

In a preliminary work [37], we proposed an extension of our process calculus with an explicit
representation for malware code. In that paper, monitors are synthesised from PLC code rather than
correctness properties. The focus of that paper was mainly on: (i) deadlock-free enforcement, and
(ii) intrusion detection via secure proxies. Here, it is worth pointing out that the work in [37] shares
some similarities with supervisory control theory [15, 54], a general theory for automatic synthesis
of controllers (supervisors) for discrete event systems, given a plant model and a specification for the
controlled behaviour. Fabian and Hellgren [20] have pointed out a number of issues to be addressed
when adopting supervisory control theory in industrial PLC-based facilities, such as causality,
incorrect synchronisation, and choice between alternative paths. However, as our syntheses regard
only logical devices (no plant involved), we are not affected from similar problems.

Finally, Yoong et al. [62] proposed a synchronous semantics for functions blocks, a component-
oriented model at the core of the IEC 61499 international standard [2] used to design distributed
industrial process measurement and control systems. In contrast to the scan cycle model followed
in the current paper (IEC 61131 [1]) prescribing the execution of a sequential portion of code at each
scan cycle, the event-driven model for function blocks relies on the occurrence of asynchronous
events to trigger program execution. Yoong et al. [62] adopted a synchronous approach to define
an execution semantics to function blocks by translating them into a subset of Esterel [11], a
well-known synchronous language. Here, we wish to point out that our PLC specification is given

30

R. Lanotte, M. Merro, A. Munteanu

at a more abstract level compared to that of [62], and it complies with the sequential scan cycle
standard IEC 61131, rather than the event-driven standard IEC 61499.

9 CONCLUSIONS AND FUTURE WORK
We have defined a formal language to express networks of monitored controllers, potentially
compromised with colluding malware that may forge/drop actuator commands, modify sensor
readings, and forge/drop inter-controller communications. The enforcing monitors have been
expressed via a finite-state sub-class of Ligatti et al.‚Äôs edit automata. In this manner, we have
provided a formal representation of field communications networks in which controllers are
enforced via secure monitors, as depicted in Figure 2. The room of manoeuvre of attackers is
defined via a proper attacker model. Then, we have defined a simple description language to
express timed regular properties that are recognised by finite automata whose cycles always contain
at least one final state (denoted via an end-action). We have used that language to build up formal
definitions for pattern templates suitable for expressing a broad family of correctness properties that
can be combined in a modular fashion to prescribe precise controller behaviours. As an example,
our description language allows us to capture all (bounded variants of the) controller properties
studied in Frehse et at. [24]. Once defined a formal language to describe controller properties,
we have provided a synthesis function ‚ü®| ‚àí |‚ü© that, given an alphabet P of observable controller
actions and a deterministic regular property ùëí consistent with P, returns a finite-state deterministic
edit automaton ‚ü®| ùëí |‚ü© P. The resulting enforcement mechanism will ensure the required features
advocated in the Introduction: transparency, soundness, deadlock-freedom, divergence-freedom,
mitigation and scalability.

As a final contribution, we have provided a full implementation of a non-trivial case study in the
context of industrial water treatment, where enforcers are implemented via FPGAs. In this setting,
we showed the effectiveness our enforcement mechanism when exposed to five carefully-designed
attacks targeting the PLCs of our use case.

As future work, we wish to test our enforcement mechanism in different domains, such as
industrial and cooperative robotic arms (e.g., Kuka, ABB, Universal Robots, etc) which are endowed
with control architectures working at a fixed rate [57]. More generally, we would like to consider
physical plants with significant uncertainties, in terms of measurements noise and physical process
uncertainty. This is because significant plant perturbations might falsely indicate that the monitored
controller is under attack, inducing our enforcers to take erroneous correcting actions. To address
such challenges we would like to implement in our enforcers well-know control-theory algorithms,
based on linear difference equations, to correctly estimate the state of the physical plant even when
affected by significant uncertainties. Finally, we would like to enhance our enforcers to deal with
malicious alterations of sensor measurements due to compromised sensor devices. In order to do so,
we intend to integrate our secured proxies with physics-based attack detection mechanisms [17, 26].

ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful and careful reviews. We thank Adrian
Francalanza, Yuan Gu, Marjan Sirjani and Davide Sangiorgi for their comments on early drafts of
the paper. The authors have been partially supported by the project ‚ÄúDipartimenti di Eccellenza
2018‚Äì2022‚Äù funded by the Italian Ministry of Universities and Research (MUR).

REFERENCES
[1] Int‚Äôl Standard IEC 61131-3. 2003. Programmable Controllers - Part 3: Programming Languages. second ed., Int‚Äôl

Electrotechnical Commission.

Runtime Enforcement of PLCs

31

[2] Int‚Äôl Standard IEC 61499-1. 2005. Function Blocks - Part 1: Architecture. first ed., Int‚Äôl Electrotechnical Commission.
[3] M. Abadi, B. Blanchet, and C. Fournet. 2018. The Applied Pi Calculus: Mobile Values, New Names, and Secure

Communication. Journal of the ACM 65, 1 (2018), 1:1‚Äì1:41.

[4] M. Abadi and A. D. Gordon. 1997. A Calculus for Cryptographic Protocols: The Spi Calculus. In CCS. ACM, 36‚Äì47.
[5] A. Abbasi and M. Hashemi. 2016. Ghost in the PLC Designing an Undetectable Programmable Logic Controller Rootkit

via Pin Control Attack. In Black Hat. 1‚Äì35.

[6] L. Aceto, I. Cassar, A. Francalanza, and A. Ing√≥lfsd√≥ttir. 2018. On Runtime Enforcement via Suppressions. In CONCUR.

Schloss Dagstuhl - Leibniz-Zentrum f√ºr Informatik, 34:1‚Äì34:17.

[7] L. Aceto, I. Cassar, A. Francalanza, and A. Ing√≥lfsd√≥ttir. 2021. On Bidirectional Runtime Enforcement. In FORTE (LNCS,

Vol. 12719). Springer, 3‚Äì21.

[8] T. R. Alves, M. Buratto, F. M. de Souza, and T. R. Rodrigues. 2014. OpenPLC: An open source alternative to automation.

In GHTC 2014. 585‚Äì589.

[9] E. Bartocci, J. V. Deshmukh, A. Donz√©, G. E. Fainekos, O. Maler, D: Nickovic, and S. Sankaranarayanan. 2018.
Specification-Based Monitoring of Cyber-Physical Systems: A Survey on Theory, Tools and Applications. In Lectures
on Runtime Verification - Introductory and Advanced Topics. LNCS, Vol. 10457. Springer, 135‚Äì175.

[10] D. Beauquier, J. Cohen, and R. Lanotte. 2013. Security policies enforcement using finite and pushdown edit automata.

International Journal of Information Security 12, 4 (2013), 319‚Äì336.

[11] G. Berry and G. Gonthier. 1992. The Esterel Synchronous Programming Language: Design, Semantics, Implementation.

Science of Computer Programming 19, 2 (1992), 87‚Äì152.

[12] M. Bielova. 2011. A theory of constructive and predictable runtime enforcement mechanisms. Ph.D. Dissertation.

University of Trento.

[13] N. Bielova and F. Massacci. 2011. Predictability of Enforcement. In Engineering Secure Software and Systems. 73‚Äì86.
[14] R. Bloem, B. K√∂nighofer, R. K√∂nighofer, and C. Wang. 2015. Shield Synthesis: - Runtime Enforcement for Reactive

Systems. In TACAS (Lecture Notes in Computer Science, Vol. 9035). Springer, 533‚Äì548.

[15] W. M. Brandin, B. A. Wonham. 1994. Supervisory control of timed discrete-event systems. IEEE Trans. Automat. Control

39, 2 (1994), 329‚Äì342.

[16] L. Cardelli and A. Gordon. 2000. Mobile Ambients. TCS 240, 1 (2000), 177‚Äì213.
[17] A.A. C√°rdenas, S. Amin, Z. Lin, Y. Huang, C. Huang, and S. Sastry. 2011. Attacks against process control systems: risk

assessment, detection, and response. In ASIACCS. 355‚Äì366.

[18] I. Cassar. 2020. Developing Theoretical Foundations for Runtime Enforcement. Ph.D. Dissertation. University of Malta

and Reykjavik University.

[19] A. Di Pinto, Y. Dragoni, and A. Carcano. 2018. TRITON: The First ICS Cyber Attack on Safety Instrument Systems. In

Black Hat USA 2018. 1‚Äì28.

[20] M. Fabian and A. Hellgren. 1998. PLC-based implementation of supervisory control for discrete event systems. In CDC,

Vol. 3. IEEE, 3305‚Äì3310.

[21] Y. Falcone, J-C. Fernandez, and L. Mounier. 2012. What can you verify and enforce at runtime? International Journal

on Software Tools for Technology Transfer 14, 3 (2012), 349‚Äì382.

[22] Y. Falcone, L. Mounier, J. Fernandez, and J. Richier. 2011. Runtime enforcement monitors: composition, synthesis, and

enforcement abilities. Formal Methods in System Design 38, 3 (2011), 223‚Äì262.

[23] A. Francalanza. 2021. A theory of monitors. Information and Computation (2021), 104704.
[24] G. Frehse, N. Kekatos, D. Nickovic, J. Oehlerking, S. Schuler, A. Walsch, and M. Woehrle. 2018. A Toolchain for

Verifying Safety Properties of Hybrid Automata via Pattern Templates. In ACC. 2384‚Äì2391.

[25] Warren Gay. 2014. Mastering the raspberry PI. Apress.
[26] J. Giraldo, D. I. Urbina, A. Cardenas, J. Valente, M. Faisal, J. Ruths, N. O. Tippenhauer, H. Sandberg, and R. Candell. 2018.
A Survey of Physics-Based Attack Detection in Cyber-Physical Systems. ACM Comput. Surv. 51, 4 (2018), 76:1‚Äì76:36.
[27] J. Goh, S. Adepu, K. N. Junejo, and A. Mathur. 2017. A Dataset to Support Research in the Design of Secure Water

Treatment Systems. In CRITIS (LNCS, Vol. 10242). Springer, 88‚Äì99.

[28] N. Govil, A. Agrawal, and N. O. Tippenhauer. 2018. On Ladder Logic Bombs in Industrial Control Systems. In

SECPRE@ESORICS 2017 (LNCS, Vol. 10683). Springer, 110‚Äì126.

[29] M. Hennessy and T. Regan. 1995. A Process Algebra for Timed Systems. Inf. Comput. 117, 2 (1995), 221‚Äì239.
[30] M. Heymann, F. Lin, G. Meyer, and S. Resmerita. 2005. Analysis of Zeno behaviors in a class of hybrid systems. IEEE

Trans. Autom. Control. 50, 3 (2005), 376‚Äì383.

[31] Y. Huang, A. A. C√°rdenas, S. Amin, Z. Lin, H. Tsai, and S. Sastry. 2009. Understanding the physical and economic

consequences of attacks on control systems. IJCIP 2, 3 (2009), 73‚Äì83.

[32] T. Huffmire, C. Irvine, T. D. Nguyen, T. Levin, R. Kastner, and T. Sherwood. 2010. Handbook of FPGA design security.

Springer Science & Business Media.

32

R. Lanotte, M. Merro, A. Munteanu

[33] L. R. Humphrey, B. K√∂nighofer, R. K√∂nighofer, and U. Topcu. 2016. Synthesis of Admissible Shields. In HVC (Lecture

Notes in Computer Science, Vol. 10028). 134‚Äì151.

[34] B. K√∂nighofer, M. Alshiekh, R. Bloem, L. Humphrey, R. K√∂nighofer, U. Topcu, and C. Wang. 2017. Shield synthesis.

Formal Methods in System Design 51, 2 (2017), 332‚Äì361.

[35] David Kushner. 2013. The real story of STUXnet. IEEE Spectrum 50, 3 (2013), 48 ‚Äì 53.
[36] R. Lanotte, M. Merro, and A. Munteanu. 2020. Runtime Enforcement for Control System Security. In CSF. IEEE,

246‚Äì261.

[37] R. Lanotte, M. Merro, and A. Munteanu. 2021. A process calculus approach to detection and mitigation of PLC malware.

Theoretical Computer Science 890 (2021), 125‚Äì146.

[38] R. Lanotte, M. Merro, A. Munteanu, and Vigan√≤, L. 2020. A Formal Approach to Physics-based Attacks in Cyber-physical

Systems. ACM Transactions on Privacy and Security 23, 1 (2020), 3:1‚Äì3:41.

[39] R. Lanotte, M. Merro, and S. Tini. 2020. A Probabilistic Calculus of Cyber-Physical Systems. Inf. Comput. (2020).
[40] J. Ligatti, L. Bauer, and D. Walker. 2005. Edit automata: enforcement mechanisms for run-time security policies.

International Journal of Information Security 4, 1-2 (2005), 2‚Äì16.

[41] Z. Manna and A. Pnueli. 1987. A Hierarchy of Temporal Properties. Technical Report. Stanford University.
[42] F. Martinelli and I. Matteucci. 2007. Through Modeling to Synthesis of Security Automata. ENTCS 179 (2007), 31‚Äì46.
[43] A. P. Mathur and N. O. Tippenhauer. 2016. SWaT: a water treatment testbed for research and training on ICS security.

In CySWater@CPSWeek. IEEE Computer Society, 31‚Äì36.

[44] MATLAB. 2018. 9.7.0.1190202 (R2019b). The MathWorks Inc., Natick, Massachusetts.
[45] S. E. McLaughlin. 2013. CPS: stateful policy enforcement for control system device usage. In ACSAC. ACM, 109‚Äì118.
[46] S. Mohan, S. Bak, E. Betti, H. Yun, L. Sha, and M Caccamo. 2013. S3A: secure system simplex architecture for enhanced

security and robustness of cyber-physical systems. In HiCoNS. ACM, 65‚Äì74.

[47] G. Nikolakopoulos and S. Manesis. 2018. Introduction to Industrial Automation. Taylor & Francis Group.
[48] Terence Parr. 2013. The definitive ANTLR 4 reference. Pragmatic Bookshelf.
[49] H. Pearce, S. Pinisetty, P. S. Roop, M. M. Y. Kuo, and A. Ukil. 2020. Smart I/O Modules for Mitigating Cyber-Physical

Attacks on Industrial Control Systems. IEEE Transactions on Industrial Informatics 16, 7 (2020), 4659‚Äì4669.

[50] S. Pinisetty, P.S. Roop, S. Smyth, N. Allen, S. Tripakis, and R.V. Hanxleden. 2017. Runtime Enforcement of Cyber-Physical

Systems. ACM TECS 16, 5s (2017), 178:1‚Äì178:25.

[51] S. Pinisetty and S. Tripakis. 2016. Compositional Runtime Enforcement. In NFM (LNCS, Vol. 9690). Springer, 82‚Äì99.
[52] B. Radvanovsky. 2013. Project shine: 1,000,000 internet-connected SCADA and ICS stystems and counting. (2013).

Tofino Security.

[53] R. Rajkumar, I. Lee, L. Sha, and J. A. Stankovic. 2010. Cyber-physical systems: the next computing revolution. In DAC.

ACM, 731‚Äì736.

[54] P. J. Ramadge and W. M. Wonham. 1987. Supervisory Control of a Class of Discrete Event Processes. SIAM J. Control

Optim. 25, 1 (1987), 206‚Äì230.

[55] Raspberry Pi. 2019. Raspberry Pi 4 Model B. https://www.raspberrypi.org/products/raspberry-pi-4-model-b/
[56] F. B. Schneider. 2000. Enforceable security policies. ACM Trans. Inf. Syst. Secur. 3, 1 (2000), 30‚Äì50.
[57] Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani, and Giuseppe Oriolo. 2009. Modelling, planning and control. Advanced

Textbooks in Control and Signal Processing. Springer, (2009).

[58] J. Slowik. 2018. Anatomy of an attack: Detecting and defeating CRASHOVERRIDE. VB2018, October (2018).
[59] R. Spenneberg, M. Br√ºggerman, and H. Schwartke. 2016. PLC-Blaster: A Worm Living Solely in the PLC. In Black Hat.

1‚Äì16.

[60] D. Thomas and P. Moorby. 2008. The Verilog¬Æ Hardware Description Language. Springer Science & Business Media.
[61] W. Wolf. 2004. FPGA-based system design. Pearson education.
[62] L. H. Yoong, P. S. Roop, V. Vyatkin, and Z. A. Salcic. 2009. A Synchronous Approach for IEC 61499 Function Block

Implementation. IEEE Trans. Computers 58, 12 (2009), 1599‚Äì1614.

[63] N. Zilberman, Y. Audzevich, G. Kalogeridou, N. Manihatty-Bojan, J. Zhang, and A. Moore. 2015. NetFPGA: Rapid
prototyping of networking devices in open source. ACM SIGCOMM Comput. Commun. Rev. 45, 4 (2015), 363‚Äì364.

A PROOFS
In order to prove the results of Section 6, in Table 6 we provide the technical definition of cross prod-
uct between two edit automata used in the synthesis of Table 5. As the first three cases are straightfor-
Z ((cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ, (cid:205)ùëó ‚ààùêΩ ùúà ùëó .Eùëó )
ward, we explain only the fourth case, the cross product associated to ProdP
Here, we use the abbreviation ùúÜ.E ‚äï ùúÜ‚Ä≤.E to denote the automaton ùúÜ.E + ùúÜ‚Ä≤.E, if ùúÜ ‚â† ùúÜ‚Ä≤, and, the
automaton ùúÜ.E, if ùúÜ = ùúÜ‚Ä≤. Thus, the product does the intersection of those addends ùúÜùëñ .Eùëñ and ùúà ùëó .Eùëó ,

Runtime Enforcement of PLCs

33

ùúÜùëñ .Eùëñ )

(X1, X2)

ProdP
Z
(X, (cid:205)
ProdP
Z
ùëñ‚ààùêº
( (cid:205)
ProdP
ùúÜùëñ .Eùëñ, X)
Z
ùëñ‚ààùêº
ùúÜùëñ .Eùëñ, (cid:205)
( (cid:205)
ùëó ‚ààùêΩ
ùëñ‚ààùêº

ùúàùëó .Fùëó )

ProdP
Z

‚âú

‚âú

‚âú

‚âú

ùúÜùëñ .Eùëñ ), if X = E

(E1, E2), if X1 = E1 and X2 = E2
(E, (cid:205)
ùëñ‚ààùêº
( (cid:205)
ùúÜùëñ .Eùëñ, E), if X = E
ùëñ‚ààùêº
(ùúÜùëñ .Xùëñ,ùëó ‚äï ùúàùëó .Xùëñ,ùëó ) + (cid:205)
ùõº ‚ààQ

ProdP
Z
ProdP
Z
ProdP
Z
(cid:205)
(ùëñ,ùëó ) ‚ààùêª
Xùëñ,ùëó = ProdP
Xùëñ,ùëó
Q = ( P \ {tick, end}) \ (cid:208)
ùêª = { (ùëñ, ùëó) ‚ààùêº √óùêΩ : out (ùúÜùëñ )=out (ùúàùëó )‚â†ùúè and ProdP
Xùëñ,ùëó

(ùëñ,ùëó ) ‚ààùêª {ùúÜùëñ, ùúàùëó }

‚àíùõº .Z, for

(Eùëñ, Fùëó )

(Eùëñ, Fùëó ) ‚â†

(cid:205)
ùõº ‚ààP\{tick,end}

‚àíùõº .Xùëñ,ùëó }

Table 6. Cross product between two edit automata with alphabet P.

with (ùëñ, ùëó) ‚àà ùêª , for which: (a) the prefixes have the same output (e.g., ùúÜùëñ = ùõº and ùúà ùëó = ùõº < ùõº ‚Ä≤), (b)
the prefixes are not suppressions, (c) the product of their continuations Eùëñ and Eùëó ‚Äúis not empty‚Äù, i.e.,
it is not a suppression-only automaton. For the other addends ùúÜùëñ .Eùëñ and ùúà ùëó .Eùëó which do not comply
with the above conditions (i.e., (ùëñ, ùëó) ‚àâ ùêª ), the product results in a suppression-only automaton.

Let us prove the complexity of the synthesis algorithm formalised in Proposition 1. For that we
need three technical lemmata. The first lemma shows that our synthesis algorithm always returns
an edit automaton in a specific canonical form.

Lemma 1 (Canonical Form). Let ùëí ‚àà PropG and P be a set of actions such that events(ùëí) ‚äÜ P.

Then, either ‚ü®| ùëí |‚ü© P = E or ‚ü®| ùëí |‚ü© P = Z, with Z = E, for E of the following form:

E =

ùõºùëñ .Eùëñ + (cid:205)
ùõºùëñ .Eùëñ + (cid:205)

ùëñ‚ààùêº

ùõº ‚ààQ

(cid:205)
ùëñ‚ààùêº
(cid:205)
ùëñ‚ààùêº

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

ùõºùëñ ‚â∫ end.Eùëñ + (cid:205)

‚àíùõº .F, if end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ

ùõº ‚ààQ

‚àíùõº .F, otherwise.

where ùõºùëñ ‚àà P, Q = P \ (‚à™ùëñ ‚ààùêº ùõºùëñ ‚à™ {tick, end}), and Eùëñ and F edit automata. A similar result holds when
ùëí is replaced with some local property ùëù ‚àà PropL.

Proof. The proof is by induction on the structure of the property ùëí. The most interesting case
X (‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P). By inductive hypothesis,

is when ùëí = ùëí1 ‚à© ùëí2. Then, ‚ü®| ùëí1 ‚à© ùëí2 |‚ü© P returns ProdP
‚ü®| ùëí1 |‚ü© P and ‚ü®| ùëí2 |‚ü© P have the required form. We prove the case when
ùõºùëñ ‚â∫ end.Eùëñ + (cid:205)
ùõº ‚ààQ1

‚Ä¢ ‚ü®| ùëí1 |‚ü© P = (cid:205)

‚àíùõº .E‚Ä≤, with Q1 = P \ (‚à™ùëñ ‚ààùêº ùõºùëñ ‚à™ {tick, end}) and end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ

ùëñ‚ààùêº

‚Ä¢ ‚ü®| ùëí2 |‚ü© P = (cid:205)

‚àíùõº .F‚Ä≤, with Q2 = P \ (‚à™ùëñ ‚ààùêº ùõºùëñ ‚à™ {tick, end}) and end ‚àà ‚à™ùëó ‚ààùêΩ ùõº ùëó .

ùõºùëñ .Eùëñ + (cid:205)
ùõº ùëó .Fùëó + (cid:205)
ùõº ‚ààQ2

ùëñ‚ààùêº

ùëó ‚ààùêΩ

The other cases are similar or simpler. For any ùëñ ‚àà ùêº and ùëó ‚àà ùêΩ , we have: (i) out (ùõºùëñ ) = out (ùõº ùëó ) if and
only if ùõºùëñ = ùõº ùëó ; (ii) out (ùõºùëñ ‚â∫ end) = out (ùõº ùëó ) holds if and only if ùõºùëñ = ùõº ùëó . We recall that out (‚àíùõº) = ùúè.
Thus, the set ùêª of the definition of cross product in Table 6 for ProdP
X (‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P) is equal to
{(ùëñ, ùëó) ‚àà ùêº √ó ùêΩ : ùõºùëñ = ùõº ùëó and ProdP
(Eùëñ, Fùëó ).
Xùëñ,ùëó
As a consequence, we derive

‚àíùõº .Xùëñ,ùëó }, with Xùëñ,ùëó = ProdP
Xùëñ,ùëó

(Eùëñ, Fùëó ) ‚â† (cid:205)ùõº ‚àà P\{tick,end}

ProdP

X (‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P) =

‚àëÔ∏Å

(ùëñ,ùëó) ‚ààùêª

ùõºùëñ .Xùëñ,ùëó +

‚àëÔ∏Å

(ùëñ,ùëó) ‚ààùêª

ùõºùëñ ‚â∫ end.Xùëñ,ùëó +

‚àíùõº .X

‚àëÔ∏Å

ùõº ‚ààQ

with Q = P \ (‚à™(ùëñ,ùëó) ‚ààùêª ùõºùëñ ‚à™ {tick, end}). It remains to prove that end ‚àâ ‚à™(ùëñ,ùëó) ‚ààùêª ùõºùëñ . Since end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ and
end ‚àà ‚à™ùëó ‚ààùêΩ ùõº ùëó , then there is no (ùëñ, ùëó) ‚àà ùêª such that ùõºùëñ = end. Thus, end ‚àâ ‚à™(ùëñ,ùëó) ‚ààùêª ùõºùëñ , as required. ‚ñ°

34

R. Lanotte, M. Merro, A. Munteanu

By an application of Lemma 1, we derive a second lemma which extends a classical result on the
complexity of the cross product of finite state automata to the cross product of (synthetised) edit
automata.

Lemma 2. Let ùëí1, ùëí2 ‚àà PropG and P be a set of observable actions. Let ùë£1, ùë£2 be the number
of derivatives of ‚ü®| ùëí1 |‚ü© P and ‚ü®| ùëí2 |‚ü© P, respectively.2 The complexity of the algorithm to compute
ProdP
X (‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P) is O (|P | ¬∑ ùë£1 ¬∑ ùë£2). A similar result holds for edit automata derived from local
properties ùëù1, ùëù2 ‚àà PropL.

The third lemma provides an upper bound to the number of derivates of the automaton ‚ü®| ùëí |‚ü© P.

Lemma 3 (Upper bound of number of derivatives). Let ùëí ‚àà PropG be a global property with
ùëö = dim(ùëí), and P be a set of observable actions. Then, the number of derivatives of ‚ü®| ùëí |‚ü© P is at most
ùëöùëò+1, where ùëò is the number of occurrences of the symbol ‚à© in ùëí.

2

Proof. The proof is by structural induction on ùëí. Let ùëí ‚â° ùëí1 ‚à© ùëí2 and ùëö = dim(ùëí1 ‚à© ùëí2). By defini-
tion, the synthesis function recalls itself on ùëí1 and ùëí2. Obviously, ùëö1 +ùëö2 = ùëö ‚àí 1 with ùëö1 = dim(ùëí1)
and ùëö2 = dim(ùëí2). Let ùëò, ùëò1 and ùëò2 be the number of occurrences of the symbol ‚à© in ùëí1 ‚à©ùëí2, ùëí1 and ùëí2,
respectively. We deduce that ùëò1+ùëò2 = ùëò‚àí1. By inductive hypothesis, ‚ü®| ùëí1 |‚ü© P has at most ùëöùëò1+1
deriva-
tives, and, ‚ü®| ùëí2 |‚ü© P has at most ùëöùëò2+1
derivatives. As the synthesis returns the cross product between
¬∑ ùëöùëò2+1
‚ü®| ùëí1 |‚ü© P and ‚ü®| ùëí2 |‚ü© P, we derive that the resulting edit automaton will have at most ùëöùëò1+1
2
derivatives. The result follows because ùëöùëò1+1
¬∑ ùëöùëò2+1
‚â§ ùëöùëò1+1 ¬∑ ùëöùëò2+1 ‚â§ ùëöùëò1+ùëò2+2 ‚â§ ùëöùëò‚àí1+2 ‚â§ ùëöùëò+1.
2
Let ùëí ‚â° ùëù‚àó, for ùëù ‚àà PropL. In order to analyse this case, as ùëö = dim(ùëù‚àó) = dim(ùëù) + 1 and
‚ü®|ùëù‚àó|‚ü© P ‚âú X, for X = ‚ü®| ùëù |‚ü© P
, we proceed by structural induction of ùëù ‚àà PropL. We focus on
X
the most significant case ùëù ‚â° (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ . We have that ùëö ‚àí 1 = dim((cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ ). By definition the
synthesis produces | ùêº | derivatives, one for each ùúãùëñ ‚àà ùêº , and also the derivative Z. Furthermore, the
synthesis algorithm re-calls itself | ùêº | times on ùëùùëñ , with ùëöùëñ = dim(ùëùùëñ ) such that ùëö‚àí1 =| ùêº | + (cid:205)ùëñ ‚ààùêº ùëöùëñ ,
for ùëñ ‚àà ùêº . Let ùëò and ùëòùëñ be the number of occurrences of ‚à© in ùëù and in ùëùùëñ , respectively, for ùëñ ‚àà ùêº . We
deduce that (cid:205)ùëñ ‚ààùêº ùëòùëñ = ùëò. By inductive hypothesis, the synthesis produces ùëöùëòùëñ +1
derivatives on each
property ùëùùëñ , for ùëñ ‚àà ùêº . Summarising, in this case the number of derivatives is 1+ | ùêº | + (cid:205)ùëñ ‚ààùêº ùëöùëòùëñ +1
.
Finally, the thesis follows as 1+ | ùêº | + (cid:205)ùëñ ‚ààùêº ùëöùëòùëñ +1
‚ñ°

‚â§ (cid:205)ùëñ ‚ààùêº ùëöùëòùëñ +1 ‚â§ ùëöùëò+1.

1

1

1

ùëñ

ùëñ

ùëñ

Proof of Proposition 1 (Complexity). For any property ùëí ‚àà PropG and any set of observ-
able actions P, we prove that the recursive structure of the function returning ‚ü®| ùëí |‚ü© P can be char-
acterised in the following form: ùëá (ùëö) = ùëá (ùëö ‚àí 1) + |P | ¬∑ ùëöùëò , with ùëö = dim(ùëí), and ùëò the number
of occurrences of ‚à© in ùëí. The result follows because ùëá (ùëö) = ùëá (ùëö ‚àí 1) + |P | ¬∑ ùëöùëò is O (|P | ¬∑ ùëöùëò+1).
The proof is by case analysis on the structure of ùëí, by examining each synthesis step in which the
synthesis process ùëö = dim(ùëí) symbols.

Case ùëí ‚â° ùëí1 ‚à© ùëí2. Let ùëö = dim(ùëí1 ‚à© ùëí2). By definition, the synthesis ‚ü®| ùëí1 ‚à© ùëí2 |‚ü© P call itself on ùëí1
and ùëí2, with ùëö1 = dim(ùëí1) and ùëö2 = dim(ùëí2) symbols, respectively, where ùëö1 + ùëö2 = ùëö ‚àí 1. Let ùëò
be the number of occurrences of ‚à© in ùëí and ùëò1, ùëò2 be the number of occurrences of ‚à© in ùëí1 and ùëí2,
respectively. We deduce that ùëò1 + ùëò2 = ùëò ‚àí 1. By an application of Lemma 2, the complexity of the
algorithm to compute ProdP
X (‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P) is O (|P | ¬∑ ùë£1 ¬∑ ùë£2), where ùë£1 and ùë£2 are the number
of derivatives of ‚ü®| ùëí1 |‚ü© P and ‚ü®| ùëí2 |‚ü© P, respectively. By an application of Lemma 3, we have that
ùë£1 ‚â§ ùëöùëò1+1
and ùë£2 ‚â§ ùëöùëò2+1
. Thus, the number of operations required for the cross product between
‚ü®| ùëí1 |‚ü© P and ‚ü®| ùëí2 |‚ü© P is O (|P | ¬∑ ùëöùëò1+1
). Thus, we can characterise the recursive structure as:
ùëá (ùëö) = ùëá (ùëö1) + ùëá (ùëö2) + |P | ¬∑ ùëöùëò1+1
. We notice that the complexity of this recursive form is
smaller than the complexity of ùëá (ùëö ‚àí 1) + |P | ¬∑ ùëöùëò .

¬∑ ùëöùëò2+1
2
¬∑ ùëöùëò2+1
2

2

1

1

1

2These numbers are finite as we deal with finite-state edit automata.

Runtime Enforcement of PLCs

35

Case ùëí ‚â° ùëù‚àó. In order to prove this case, as ùëö = dim(ùëù‚àó) = dim(ùëù) + 1 and ‚ü®|ùëù‚àó|‚ü© P ‚âú X, for
, we proceed by case analysis on ùëù ‚àà PropL. Thus, we consider the local properties ùëù ‚àà
X = ‚ü®| ùëù |‚ü© P
X
PropL. We focus on the most significant case ùëù ‚â° (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ . We have that ùëö‚àí1 = dim((cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ ).
By definition, the synthesis ‚ü®| (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ |‚ü© P consumes all events ùúãùëñ , for ùëñ ‚àà ùêº . The synthesis algorithm
re-calls itself | ùêº | times on ùëùùëñ , with dim(ùëùùëñ ) symbols, for ùëñ ‚àà ùêº . Furthermore, let ùëô be the size
of the set P, the algorithm performs at most ùëô operations due to a summation over over ùõº ‚àà
P \ ((cid:208)ùëñ ‚ààùêº ùúãùëñ ‚à™ {tick, end}), with | P \ ((cid:208)ùëñ ‚ààùêº ùúãùëñ ‚à™ {tick, end}) |< ùëô. Thus, we can characterise the
recursive structure as ùëá (ùëö) = (cid:205)ùëñ ‚ààùêº ùëá (dim(ùëùùëñ )) + ùëô. Since (cid:205)ùëñ ‚ààùêº dim(ùëùùëñ ) = ùëö ‚àí 1 ‚àí | ùêº | ‚â§ ùëö ‚àí 1. The
resulting complexity is smaller than that of ùëá (ùëö ‚àí 1) + |P | ¬∑ ùëöùëò .
‚ñ°

Proof of Proposition 2 (Deterministic preservation). We reason by contradiction. Suppose
there is a sum (cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ appearing in ‚ü®| ùëí |‚ü© P such that trigger (ùúÜùëò ) = trigger (ùúÜ ùëó ) and out (ùúÜùëò ) =
out (ùúÜ ùëó ), for some ùëò, ùëó ‚àà ùêº , ùëò ‚â† ùëó. We proceed by case analysis on the structure of the property ùëí.
Let us focus on the case ùëí = (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ . The other cases are simpler. Then, ‚ü®| ùëí |‚ü© P is equal to Z, for

Z =

(cid:205)
ùëñ‚ààùêº
(cid:205)
ùëñ‚ààùêº

ùúãùëñ .‚ü®| ùëùùëñ |‚ü© P
X
ùúãùëñ .‚ü®| ùëùùëñ |‚ü© P
X

+ (cid:205)
ùëñ‚ààùêº
+ (cid:205)
ùõº ‚ààQ

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

ùúãùëñ ‚â∫ end.‚ü®| ùëùùëñ |‚ü© P
X

+ (cid:205)
ùõº ‚ààQ

‚àíùõº .Z, if end ‚àâ ‚à™ùëñ ‚ààùêº ùúãùëñ

‚àíùõº .Z, otherwise

and Q = P \ (‚à™ùëñ ‚ààùêº ùúãùëñ ‚à™ {tick, end}). Since ùëí is deterministic (Definition 5) it follows that ùúã‚Ñé ‚â† ùúãùëô , for
any ‚Ñé, ùëô ‚àà ùêº , ‚Ñé ‚â† ùëô. As a consequence, it cannot be ùúÜùëò = ùúã‚Ñé ‚â∫ end, for ‚Ñé ‚àà ùêº , and ùúÜ ùëó = ùúãùëô ‚â∫ end, for ùëô ‚àà ùêº ,
‚Ñé ‚â† ùëô, because out (ùúÜùëò ) = ùúã‚Ñé ‚â† ùúãùëô = out (ùúÜ ùëó ). Thus, the only chance for Z to be nondeterministic
is that ùúÜùëò = ùúã‚Ñé, for ‚Ñé ‚àà ùêº , and ùúÜ ùëó = ùúãùëô ‚â∫ end, for ùëô ‚àà ùêº , in the case end ‚àâ ‚à™ùëñ ‚ààùêº ùúãùëñ . However, this is not
‚ñ°
admissible because end ‚àâ ‚à™ùëñ ‚ààùêº ùúãùëñ implies trigger (ùúÜùëò ) = ùúã‚Ñé ‚â† end = trigger (ùúÜ ùëó ).

In order to prove Theorem 1, we need prove that the cross product between edit automata
satisfies a standard correctness result saying that any execution trace associated to the intersection
of two regular properties is also a trace of the the cross product of the edit automata associated to
the two properties, and vice versa.

Lemma 4 (Correctness of Cross Product). Let ùëí1, ùëí2 ‚àà PropG (resp., ùëù1, ùëù2 ‚àà PropL) and
P be a set of actions such that events(ùëí1 ‚à© ùëí2) ‚äÜ P (resp., events(ùëù1 ‚à© ùëù2) ‚äÜ P). Then, it holds that:
)), then (cid:155)out (ùë°) is prefix of

‚Ä¢ If ùë° is a trace of ProdP
X

, ‚ü®| ùëù2 |‚ü© P
X

some trace in the semantics

‚Ä¢ If ùë° is a trace in
(resp., ProdP
X

ùëí1 ‚à© ùëí2
(cid:74)
(‚ü®| ùëù1 |‚ü© P
X

(‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P ) (resp., ProdP
X
ùëù1 ‚à© ùëù2
(cid:74)

(resp.,

ùëí1 ‚à© ùëí2
(cid:74)
(resp.,
, ‚ü®| ùëù2 |‚ü© P
X

(cid:75)

(cid:75)
ùëù1 ‚à© ùëù2
(cid:74)

(cid:75)
)) such that (cid:155)out (ùë° ‚Ä≤) = ùë°.

(‚ü®| ùëù1 |‚ü© P
X
).

) then there exists a trace ùë° ‚Ä≤ of ProdP
X

(cid:75)

(‚ü®| ùëí1 |‚ü© P, ‚ü®| ùëí2 |‚ü© P )

Proof of Theorem 1 (Transparency). We prove a stronger result. Let ùëí ‚àà PropG be a global
ùë°
‚àí‚àí‚Üí ùêΩ , for some trace ùë° = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëõ.

deterministic property and ùëÉ ‚àà Ctrl be a controller such that ùëÉ
If ùë° is the prefix of some trace in the semantics
ùëí
(cid:75)
(cid:74)
ùë°
‚àí‚àí‚àí‚Üí E where either E = ‚ü®| ùëù ‚Ä≤ |‚ü© P
(1) There exists a unique E such that ‚ü®| ùëí |‚ü© P
X

then the following sub-results hold:

or E = Z, with

Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X

(2) There is a trace ùë° ‚Ä≤ ‚àà
(3) There is no trace ùë° ‚Ä≤‚Ä≤ = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëò ¬∑ ùúÜ for ‚ü®| ùëí |‚ü© P such that 0 ‚â§ ùëò < ùëõ and ùúÜ ‚àà {‚àíùõºùëò+1, ùõº ‚â∫ ùõºùëò+1},

, for some ùëù ‚Ä≤ ‚àà PropL and some automaton variable X.
ùëí
(cid:74)

such that ùë° ¬∑ ùë° ‚Ä≤ is a prefix of some trace in

ùëù ‚Ä≤
(cid:74)

(cid:75)

(cid:75)

.

for some ùõº.

These three sub-results imply the required result. We proceed by induction on the length ùëõ of trace ùë°.
- Base case: ùëõ = 1. That is ùë° = ùõº, with ùõº ‚àà Sens ‚à™ Chn‚àó ‚à™ Act ‚à™ {tick, end}. We proceed by induction
on the structure of ùëí.

Case ùëí ‚â° ùëù‚àó, for some ùëù ‚àà PropL. We prove the following three results:

36

R. Lanotte, M. Merro, A. Munteanu

‚Ä¢ i) there exists a unique E such that ‚ü®| ùëù |‚ü© P
X‚Ä≤

ùõº
‚àí‚àí‚àí‚Üí E and either E = ‚ü®| ùëù ‚Ä≤ |‚ü© P

X‚Ä≤ or E = Z, with

Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P

‚Ä¢ ii) there is a trace ùë° ‚Ä≤ ‚àà
ùëù ‚Ä≤
(cid:74)
‚Ä¢ iii) there is no ùúÜ ‚àà {‚àíùõº, ùõº ‚Ä≤ ‚â∫ ùõº } such that ‚ü®| ùëù |‚ü© P
X‚Ä≤

X‚Ä≤ , for some ùëù ‚Ä≤ ‚àà PropL and some automaton variable X‚Ä≤;
such that ùõº ¬∑ ùë° ‚Ä≤ is a prefix of some trace in
ùúÜ
(cid:75)
‚àí‚àí‚àí‚Üí E‚Ä≤, for some E‚Ä≤.
As ‚ü®| ùëù‚àó |‚ü© P ‚âú X, with X = ‚ü®| ùëù |‚ü© P
, results i) and ii) and iii) imply the required facts (1) and (2) and
X
(3) for ùëí = ùëù‚àó. We proceed as follows: first, we prove items i) and ii) by induction on the structure
of ùëù, and then we prove item iii) by contradiction.

ùëù
(cid:74)

(cid:75)

;

We prove items i) and ii). We focus on the most significant cases: ùëù = (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ and ùëù ‚â° ùëù1 ‚à© ùëù2.

The other cases are similar or simpler.
Let ùëù ‚â° (cid:208)ùëñ ‚ààùêº ùúãùëñ .ùëùùëñ . In this case, ùõº is a prefix of some trace in

and ‚ü®| ùëù |‚ü© P
X

ùëù
(cid:74)
‚àíùõº ‚Ä≤‚Ä≤.Z‚Ä≤, if end ‚àâ ‚à™ùëñ ‚ààùêº ùúãùëñ

(cid:75)

returns Z‚Ä≤, for

Z‚Ä≤ =

ùúãùëñ .‚ü®| ùëùùëñ |‚ü© P
X
ùúãùëñ .‚ü®| ùëùùëñ |‚ü© P
X

(cid:205)
ùëñ‚ààùêº
(cid:205)
ùëñ‚ààùêº

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

ùúãùëñ ‚â∫ end.‚ü®| ùëùùëñ |‚ü© P
X

+ (cid:205)
ùõº‚Ä≤‚Ä≤‚ààQ
‚àíùõº ‚Ä≤‚Ä≤.Z‚Ä≤, otherwise.

+ (cid:205)
ùëñ‚ààùêº
+ (cid:205)
ùõº‚Ä≤‚Ä≤‚ààQ

where Q = P \ (‚à™ùëñ ‚ààùêº ùúãùëñ ‚à™ {tick, end}). Since ùõº is a prefix of some trace in
and ùëí is deterministic, then we derive that ùõº = ùúãùëò , for a unique index ùëò ‚àà ùêº .

ùëù
(cid:74)

(cid:75)

and ùúãùëñ ‚â† ùúñ, for any ùëñ ‚àà ùêº ,

‚Ä¢ Let us prove ii). Since ùëÉ

‚Ä¢ Let us prove i). Since ùëò is the unique index such that ùõº = ùúãùëò , we derive that ‚ü®| ùëù |‚ü© P
X

the unique transition labeled ùõº such that either E = ‚ü®| ùëùùëò |‚ü© P

ùõº
‚àí‚àí‚àí‚Üí ùêΩ and ùõº = ùúãùëò , by inductive hypothesis there exists ùë° ‚Ä≤ ‚àà
(cid:75)
, as required.
and the synthesis ‚ü®| ùëù |‚ü© P
X

, and hence also in

ùëù
(cid:74)

ùõº
‚àí‚àí‚àí‚Üí E is
Z‚Ä≤ or E = Z1, with Z1 = ‚ü®| ùëùùëò |‚ü© P
Z‚Ä≤.
ùëùùëò
(cid:74)

(cid:75)

Let ùëù ‚â° ùëù1 ‚à© ùëù2. In this case, we have that ùõº is prefix of some trace in
returns the edit automaton Eùëù = ProdP

).

ùëù
(cid:74)

(cid:75)

such that ùõº ¬∑ ùë° ‚Ä≤ is a prefix of some trace in

ùúãùëò .ùëùùëò
(cid:74)
(cid:75)
, ‚ü®| ùëù2 |‚ü© P
X

X (‚ü®| ùëù1 |‚ü© P

X

‚ü®| ùëù1 |‚ü© P

‚Ä¢ Let us prove i). By definition of cross product in Table 6, the most interesting case is when
X = (cid:205)ùëó ‚ààùêΩ ùúà ùëó .Fùëó . In this case,
‚àëÔ∏Å
, ‚ü®| ùëù2 |‚ü© P

X = (cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ and ‚ü®| ùëù2 |‚ü© P

(ùúÜùëñ .Xùëñ,ùëó ‚äï ùúà ùëó .Xùëñ,ùëó ) +

Eùëù = ProdP

‚àíùõº .Z,

‚àëÔ∏Å

X (‚ü®| ùëù1 |‚ü© P

X

X ) =

(ùëñ,ùëó) ‚ààùêª

ùõº ‚àà Q

(cid:205)
ùõº ‚àà P\{tick,end}
ùëù1
(cid:74)

for Xùëñ,ùëó = ProdP
Xùëñ,ùëó
out (ùúÜùëñ ) = out (ùúà ùëó ) ‚â† ùúè and ProdP
Xùëñ,ùëó

(Eùëñ, Fùëó ) ‚â†

(Eùëñ, Fùëó ) and Q = (P \ {tick, end}) \ (cid:208)

(ùëñ,ùëó) ‚ààùêª {ùúÜùëñ, ùúà ùëó } and ùêª = {(ùëñ, ùëó) ‚àà ùêº √óùêΩ :
‚àíùõº .Xùëñ,ùëó }. Now, since ùõº is a prefix of

(cid:75)

(cid:75)

and

ùëù
(cid:74)

1 |‚ü© P
X

, for some ùëù ‚Ä≤

, then ùõº is a prefix of some trace in both

ùõº
‚àí‚àí‚àí‚Üí F, and either F = ‚ü®| ùëù ‚Ä≤

. Thus, since ùëÉ
ùëù2
ùõº
(cid:74)
‚àí‚àí‚àí‚Üí E, and either E = ‚ü®| ùëù ‚Ä≤

2 |‚ü© P
X
X = (cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ and ‚ü®| ùëù2 |‚ü© P

ùõº
‚àí‚àí‚àí‚Üí ùêΩ , by
some trace in
(cid:75)
inductive hypothesis there exists a unique E such that ‚ü®| ùëù1 |‚ü© P
1 |‚ü© P
X
X
1 ‚àà PropL. Similarly, there exists unique F such that
or E = Z1, with Z1 = ‚ü®| ùëù ‚Ä≤
2 ‚àà PropL.
or F = Z2, with Z2 = ‚ü®| ùëù ‚Ä≤
2 |‚ü© P
‚ü®| ùëù2 |‚ü© P
X
X
X = (cid:205)ùëó ‚ààùêΩ ùúà ùëó .Fùëó , then we have that there exist ùëñ ‚àà ùêº and
Since ‚ü®| ùëù1 |‚ü© P
ùëó ‚àà ùêΩ such that E = Eùëó and F = Fùëó By Lemma 4 and by definition of cross product, we have
ùõº
‚àí‚àí‚àí‚Üí Xùëñ,ùëó , with Xùëñ,ùëó = ProdP
(Eùëñ, Fùëó ) = ProdP
that (ùëñ, ùëó) ‚àà ùêª , ùõº = ùúÜùëñ and Eùëù
(E, F). Thus,
Xùëñ,ùëó
Xùëñ,ùëó
ùõº
‚àí‚àí‚àí‚Üí Xùëñ,ùëó is the only possible transition for Eùëù
since E and F are unique, it follows that Eùëù
with label ùõº. Finally, we have that ProdP
,
2 |‚ü© P
, ‚ü®| ùëù ‚Ä≤
Xùëñ,ùëó
X
as required.

(E, F) = ProdX(‚ü®| ùëù ‚Ä≤

, for some ùëù ‚Ä≤

) = ‚ü®| ùëù ‚Ä≤

1 ‚à© ùëù ‚Ä≤

1 |‚ü© P
X

2 |‚ü© P
X

‚Ä¢ Let us prove ii). As Eùëù
Lemma 4 we derive that
follows that Eùëù
trace in

ùõº
‚àí‚àí‚àí‚Üí ProdP
Xùëñ,ùëó
1 ‚à© ùëù ‚Ä≤
ùëù ‚Ä≤
2
ùõº
(cid:75)
(cid:74)
‚àí‚àí‚àí‚Üí ProdP
1 |‚ü© P
X (‚ü®| ùëù ‚Ä≤
X
, as required.
(cid:75)

ùëù1 ‚à© ùëù2
(cid:74)

(E, F) = ProdP
X (‚ü®| ùëù ‚Ä≤
‚â† ‚àÖ. Thus, there exists ùë° ‚Ä≤ ‚àà

, by
1 |‚ü© P
2 |‚ü© P
, ‚ü®| ùëù ‚Ä≤
1 ‚à© ùëù ‚Ä≤
X
X
. Again, by Lemma 4 it
1 ‚à© ùëù ‚Ä≤
ùëù ‚Ä≤
2
ùë° ‚Ä≤
(cid:75)
(cid:74)
‚àí‚àí‚àí‚Üí E‚Ä≤, for some E‚Ä≤, with ùõº ¬∑ ùë° ‚Ä≤ prefix of some

) = ‚ü®| ùëù ‚Ä≤

2 |‚ü© P
X

, ‚ü®| ùëù ‚Ä≤

)

2 |‚ü© P
X

We have proved items i) and ii), for any ùëù ‚àà PropL. It remains to prove item iii) namely, if
ùúÜ
‚àí‚àí‚àí‚Üí F, for some F. By Lemma 1 we
‚ü®| ùëù |‚ü© P
X‚Ä≤

ùõº
‚àí‚àí‚àí‚Üí E then there is no ùúÜ ‚àà {‚àíùõº, ùõº ‚Ä≤ ‚â∫ ùõº } such ‚ü®| ùëù |‚ü© P
X‚Ä≤

Runtime Enforcement of PLCs

37

have that ‚ü®| ùëù |‚ü© P

X‚Ä≤ = Z, with Z = E‚Ä≤ for
ùõºùëñ ‚â∫ end.Eùëñ + (cid:205)
ùõº‚Ä≤‚Ä≤‚ààQ

X‚Ä≤ = E‚Ä≤ or ‚ü®| ùëù |‚ü© P
Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

(cid:205)
ùëñ‚ààùêº
(cid:205)
ùëñ‚ààùêº

E‚Ä≤ =

ùõºùëñ .Eùëñ + (cid:205)
ùõºùëñ .Eùëñ + (cid:205)
ùõº‚Ä≤‚Ä≤‚ààQ

ùëñ‚ààùêº

‚àíùõº ‚Ä≤‚Ä≤.E‚Ä≤‚Ä≤, otherwise.

‚àíùõº ‚Ä≤‚Ä≤.E‚Ä≤‚Ä≤, if end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ

ùõº
for ùõºùëñ ‚àà P, Q = P \ (‚à™ùëñ ‚ààùêº ùõºùëñ ‚à™ {tick, end}), and Eùëñ and E‚Ä≤‚Ä≤ edit automata. Since ‚ü®| ùëù |‚ü© P
‚àí‚àí‚àí‚Üí E
X‚Ä≤
ùúÜ
it follows that ùõº = ùõºùëò , for some ùëò ‚àà ùêº . Let us assume by contradiction that ‚ü®| ùëù |‚ü© P
‚àí‚àí‚àí‚Üí F,
X‚Ä≤
for some ùúÜ ‚àà {‚àíùõº, ùõº ‚Ä≤ ‚â∫ ùõº } and automata F. Since ùõº = ùõºùëò , with ùëò ‚àà ùêº , we derive that ùõº ‚àâ Q =
P \ (‚à™ùëñ ‚ààùêº ùõºùëñ ‚à™ {tick, end}), that is ùúÜ is an insertion, ùúÜ = ùõº ‚Ä≤ ‚â∫ ùõº, for some ùõº ‚Ä≤. As in E‚Ä≤ the only insertions
are of the form ùõºùëñ ‚â∫ end, it follows that ùõº = end and end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ . However, since end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ it
follows that ùõº = ùõºùëò ‚â† end. Contradiction.

Case ùëí ‚â° ùëí1 ‚à© ùëí2, for some ùëí1, ùëí2 ‚àà PropG. This case can be proved with a reasoning similar to

ùë°
‚àí‚àí‚Üí ùêΩ such that ùë° is a prefix of some trace in

that of the case ùëù1 ‚à© ùëù2.
- Inductive case: ùëõ > 1, for ùëõ ‚àà N. Suppose ùëÉ
ùëõ > 1, ùëÉ
then ùë° ‚Ä≤ is a prefix of some trace in

ùë° ‚Ä≤
‚àí‚àí‚àí‚Üí ùêΩ ‚Ä≤

ùõº
‚àí‚àí‚àí‚Üí ùêΩ , for some trace ùë° ‚Ä≤ such that ùë° = ùë° ‚Ä≤ ¬∑ ùõº. As ùë° is a prefix of some trace in

(cid:75)
as well. Thus, by inductive hypothesis we have that:
‚àí‚àí‚àí‚Üí E‚Ä≤, and either E‚Ä≤ = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X

(cid:75)
or E‚Ä≤ = Z, with

(1) There exists a unique E‚Ä≤ such that ‚ü®| ùëí |‚ü© P ùë° ‚Ä≤

Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X

, for some ùëù ‚Ä≤ ‚àà PropL and some automaton variable X.
such that ùë° ‚Ä≤ ¬∑ ùë° ‚Ä≤‚Ä≤ is a prefix of some trace in

(2) There is a trace ùë° ‚Ä≤‚Ä≤ ‚àà
(3) There is no trace ùë° ‚Ä≤‚Ä≤‚Ä≤ = ùõº1 ¬∑ ¬∑ ¬∑ ùõºùëò ¬∑ùúÜ for ‚ü®| ùëí |‚ü© P such that 0 ‚â§ ùëò < ùëõ‚àí1 and ùúÜ ‚àà {‚àíùõºùëò+1, ùõº ‚Ä≤ ‚â∫ ùõºùëò+1},

ùëù ‚Ä≤
(cid:74)

ùëí
(cid:74)

ùëí
(cid:74)

(cid:75)

(cid:75)

(cid:75)

.

ùëí
(cid:74)

. Since
ùëí
(cid:74)

for some ùõº ‚Ä≤.

Since from (1) E‚Ä≤ is unique and either E‚Ä≤ = ‚ü®| ùëù ‚Ä≤ |‚ü© P
or E‚Ä≤ = Z, with Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
X
ùõº
‚àí‚àí‚àí‚Üí E‚Ä≤‚Ä≤, and either E‚Ä≤‚Ä≤ = ‚ü®| ùëù ‚Ä≤‚Ä≤ |‚ü© P
i) there exists a unique E‚Ä≤‚Ä≤ such that ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
Z = ‚ü®| ùëù ‚Ä≤‚Ä≤ |‚ü© P
such that ùõº ¬∑ ùë° ‚Ä≤ is a prefix of some trace in
ùëù ‚Ä≤
(cid:74)
(cid:75)
for some F. These three facts can be proved as previously done for the base case, ùëõ = 1.

X‚Ä≤ , for some ùëù ‚Ä≤‚Ä≤ ‚àà PropL and some automaton variable X‚Ä≤; ii) there is a trace ùë° ‚Ä≤ ‚àà

, we have to prove:
X‚Ä≤ or E‚Ä≤‚Ä≤ = Z, with
ùëù ‚Ä≤‚Ä≤
(cid:74)
(cid:75)
ùúÜ
‚àí‚àí‚àí‚Üí F,
‚ñ°

; iii) there is no ùúÜ ‚àà {‚àíùõº, ùõº ‚Ä≤ ‚â∫ ùõº }, such ‚ü®| ùëù ‚Ä≤ |‚ü© P
X

In order to prove Theorem 2 we need a couple of technical lemmata.

Lemma 5 (Soundness of the synthesis). Let ùëí ‚àà PropG be a global property and P be a set
ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí E be an arbitrary execution

of observable actions such that events(ùëí) ‚äÜ P. Let ‚ü®| ùëí |‚ü© P
trace of the synthesised automaton ‚ü®| ùëí |‚ü© P. Then,

ùúÜ1‚àí‚àí‚àí‚àí‚Üí . . .

(1) for ùë° = out (ùúÜ1) ¬∑ . . . ¬∑ out (ùúÜùëõ) the trace ÀÜùë° is a prefix of some trace in
(2) either E = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X

or E = Z, with Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X

;
(cid:75)
, for some ùëù ‚Ä≤ ‚àà PropL and some automaton

ùëí
(cid:74)

variable X.

Proof. We proceed by induction on the length of the execution trace ‚ü®| ùëí |‚ü© P

ùúÜ1‚àí‚àí‚àí‚àí‚Üí . . .
ùúÜ
‚àí‚àí‚àí‚Üí E. We proceed by induction on the structure of ùëí.

Base case: ùëõ = 1. In this case, ‚ü®| ùëí |‚ü© P

ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí E.

Case ùëí ‚â° ùëù‚àó, for some ùëù ‚àà PropL. We prove by induction on the structure of ùëù the following two
results: i) for ùõΩ = out (ùúÜ), ÀÜùõΩ is a prefix of some trace in
X‚Ä≤ or E = Z, with
ùëù
(cid:74)
X‚Ä≤ , for some ùëù ‚Ä≤ ‚àà PropL and some automaton variable X‚Ä≤. As ‚ü®| ùëù‚àó |‚ü© P ‚âú X, for X = ‚ü®| ùëù |‚ü© P
Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
results i) and ii) imply the required results (1) and (2), for ùëí = ùëù‚àó. We show the cases ùëù ‚â° ùëù1; ùëù2 and
ùëù ‚â° ùëù1 ‚à© ùëù2, the others cases are similar or simpler.
Let ùëù ‚â° ùëù1; ùëù2 and ‚ü®| ùëù1; ùëù2 |‚ü© P
X
simpler. By definition, ‚ü®| ùëù1; ùëù2 |‚ü© P
X
from ùëù1 ‚â† ùúñ and ‚ü®| ùëù1; ùëù2 |‚ü© P
X

ùúÜ
‚àí‚àí‚àí‚Üí E. We prove the two results i) and ii) for ùëù1 ‚â† ùúñ, the case ùëù1 = ùúñ is
, and Z‚Ä≤ ‚â† X. As a consequence,

, and ii) either E = ‚ü®| ùëù ‚Ä≤ |‚ü© P
(cid:75)

ùúÜ
‚àí‚àí‚àí‚Üí E it follows that ‚ü®| ùëù1 |‚ü© P
X

ùúÜ
‚àí‚àí‚àí‚Üí E1, for some E1.

Z‚Ä≤, for Z‚Ä≤ = ‚ü®| ùëù2 |‚ü© P

returns ‚ü®| ùëù1 |‚ü© P

X

,

ùúÜ

‚àí‚àí‚àí‚Üí E1, by inductive hypothesis we have that ÀÜùõΩ is a prefix of

‚Ä¢ Let us prove i). Since ‚ü®| ùëù1 |‚ü© P
X

some trace in

ùëù1
(cid:74)

. Thus, ÀÜùõΩ is a prefix of some trace in
(cid:75)

, as required.

ùëù1; ùëù2
(cid:74)

(cid:75)

38

R. Lanotte, M. Merro, A. Munteanu

‚Ä¢ Let us prove ii). Again, since ‚ü®| ùëù1 |‚ü© P
X

or E1 = Z1, with Z1 = ‚ü®| ùëù ‚Ä≤
us analyse E1 = ‚ü®| ùëù ‚Ä≤
with Z‚Ä≤ = ‚ü®| ùëù2 |‚ü© P
X
as required.

1 |‚ü© P

Z‚Ä≤ (the case E1 = Z1, with Z1 = ‚ü®| ùëù ‚Ä≤

1 |‚ü© P
, by definition of the synthesis algorithm it follows that E1 = ‚ü®| ùëù ‚Ä≤

ùúÜ
‚àí‚àí‚àí‚Üí E1, by inductive hypothesis either E1 = ‚ü®| ùëù ‚Ä≤

1 |‚ü© P
Z‚Ä≤
1 ‚àà PropL and some automaton variable Z‚Ä≤. Let
1 |‚ü© P
Z‚Ä≤
,
1; ùëù2 |‚ü© P
X

Z‚Ä≤, is similar). As E1 = ‚ü®| ùëù ‚Ä≤

Z‚Ä≤, for some ùëù ‚Ä≤

1 |‚ü© P

Let ùëù ‚â° ùëù1‚à©ùëù2 and ‚ü®| ùëù1 ‚à© ùëù2 |‚ü© P
X
returns Eùëù = ProdX (‚ü®| ùëù1 |‚ü© P
, ‚ü®| ùëù2 |‚ü© P
X
X
‚Ä¢ Result i) follows directly from Lemma 4.
‚Ä¢ Let us prove ii). By inspection of the definition of cross product in Table 6, the most interesting

ùúÜ
‚àí‚àí‚àí‚Üí E. By definition, the synthesis algorithm applied to ‚ü®| ùëù1 ‚à© ùëù2 |‚ü© P
X

). Let us prove the results i) and ii).

case is when ‚ü®| ùëù1 |‚ü© P

X = (cid:205)ùëó ‚ààùêΩ ùúà ùëó .Fùëó . In this case,
X = (cid:205)ùëñ ‚ààùêº ùúÜùëñ .Eùëñ and ‚ü®| ùëù2 |‚ü© P
‚àëÔ∏Å
‚àëÔ∏Å
, ‚ü®| ùëù2 |‚ü© P
(ùúÜùëñ .Xùëñ,ùëó ‚äï ùúà ùëó .Xùëñ,ùëó ) +

‚àíùõº .Z

X ) =

Eùëù = ProdX (‚ü®| ùëù1 |‚ü© P
X

(ùëñ,ùëó) ‚ààùêª

ùõº ‚àà Q

(ùëñ,ùëó) ‚ààùêª {ùúÜùëñ, ùúà ùëó } and ùêª = {(ùëñ, ùëó) ‚àà ùêº √óùêΩ :
‚àíùõº .Xùëñ,ùëó }. Hence Eùëù has following

for Xùëñ,ùëó = ProdP
Xùëñ,ùëó
out (ùúÜùëñ ) = out (ùúà ùëó ) ‚â† ùúè and ProdP
Xùëñ,ùëó

(Eùëñ, Fùëó ) and Q = (P\{tick, end})\ (cid:208)
(cid:205)
(Eùëñ, Fùëó ) ‚â†
ùõº ‚àà P\{tick,end}
ùúÜ
‚àí‚àí‚àí‚Üí Xùëñ,ùëó , for ùúÜ ‚àà (cid:208)

(ùëñ,ùëó) ‚ààùêª {ùúÜùëñ, ùúà ùëó }; (b) Eùëù

‚àíùõº
two (families of) transitions: (a) Eùëù
‚àí‚àí‚àí‚àí‚Üí Z, for
ùõº ‚àà Q. We prove the result for the case (a); the case (b) can be proved in a similar manner.
Since ùúÜ ‚àà (cid:208)
(ùëñ,ùëó) ‚ààùêª {ùúÜùëñ, ùúà ùëó } we have that ùúÜ = ùúÜùëñ or ùúÜ = ùúà ùëó , for some (ùëñ, ùëó) ‚àà ùêª . By defi-
ùúàùëó
‚àí‚àí‚àí‚Üí Eùëó , with out (ùúÜùëñ ) =
nition of cross product, it holds that ‚ü®| ùëù1 |‚ü© P
X
out (ùúà ùëó ) = out (ùúÜ). Thus, by inductive hypothesis we have that: (1) either Eùëñ = ‚ü®| ùëù ‚Ä≤
or
Eùëñ = Z1, with Z1 = ‚ü®| ùëù ‚Ä≤
or Fùëó = Z2, with
1 |‚ü© P
X
2 ‚àà PropL. Therefore, by definition of cross product we derive that
, for some ùëù ‚Ä≤
2 |‚ü© P
Z2 = ‚ü®| ùëù ‚Ä≤
X
ProdP
). Finally, by definition of our synthesis it follows
2 |‚ü© P
(Eùëñ, Fùëó ) = ProdX (‚ü®| ùëù ‚Ä≤
Xùëñ,ùëó
X
that ProdX (‚ü®| ùëù ‚Ä≤
1 |‚ü© P
2 |‚ü© P
2 |‚ü© P
1 ‚à© ùëù ‚Ä≤
X
X
X
Case ùëí = ùëí1 ‚à© ùëí2 for some ùëí1, ùëí2 ‚àà PropG. This case can be proved with a reasoning similar to

1 ‚àà PropL; (2) either Fùëó = ‚ü®| ùëù ‚Ä≤

ùúÜùëñ‚àí‚àí‚àí‚Üí Eùëñ and ‚ü®| ùëù2 |‚ü© P

1 |‚ü© P
, ‚ü®| ùëù ‚Ä≤
X
) = ‚ü®| ùëù ‚Ä≤

, as required.

, for some ùëù ‚Ä≤

1 |‚ü© P
X

2 |‚ü© P
X

, ‚ü®| ùëù ‚Ä≤

X

that seen in the proof of case ùëù1 ‚à© ùëù2.

. . .

ùúÜùëõ‚àí1‚àí‚àí‚àí‚àí‚àí‚àí‚Üí E‚Ä≤

ùúÜ1‚àí‚àí‚àí‚àí‚Üí . . .
ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí E. Thus, by induction, we have that:

Inductive case: ùëõ > 1, for ùëõ ‚àà N. Suppose ‚ü®| ùëí |‚ü© P
ùúÜùëõ‚àí1‚àí‚àí‚àí‚àí‚àí‚àí‚Üí E‚Ä≤
(1) for ùë° ‚Ä≤ = out (ùúÜ1) ¬∑ . . . ¬∑ out (ùúÜùëõ‚àí1) the trace (cid:98)ùë° ‚Ä≤ is a prefix of some trace in
(2) either E‚Ä≤ = ‚ü®| ùëù ‚Ä≤ |‚ü© P
or E‚Ä≤ = Z, with Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
X
variables Z and X.
Since either E‚Ä≤ = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
prove that given ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
For that we resort to the proof of the base case.

or E‚Ä≤ = Z, with Z = ‚ü®| ùëù ‚Ä≤ |‚ü© P
X
ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí E and ùõΩùëõ = out (ùúÜùëõ), it holds that ÀÜùõΩùëõ is a prefix of some trace in

, then to conclude the proof it is sufficient to
.
ùëù ‚Ä≤
(cid:75)
(cid:74)
‚ñ°

, for some ùëù ‚Ä≤ ‚àà PropL and some automaton

ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí E, for ùëõ > 1. ‚ü®| ùëí |‚ü© P

ùúÜ1‚àí‚àí‚àí‚àí‚Üí

, and

ùëí
(cid:74)

(cid:75)

In the next lemma, we prove that, given the execution traces of a monitored controller, we can
always extract from them the traces performed by its edit automaton and its monitored controller
in isolation.

Lemma 6 (Trace decomposition). Let E ‚àà Edit be an edit automaton and ùêΩ ‚àà Ctrl be a
ùõΩùëõ
‚àí‚àí‚àí‚àí‚Üí Eùëõ ‚ä≤‚ä≥ {ùêΩùëõ }, with E0 = E and ùêΩ0 = ùêΩ ,
ùõºùëñ‚àí‚àí‚àí‚àí‚Üí ùêΩùëñ , with ùõºùëñ = trigger (ùúÜùëñ ), or

ùúÜùëñ‚àí‚àí‚àí‚Üí Eùëñ , with ùõΩùëñ = out (ùúÜùëñ ), and (2) either ùêΩùëñ‚àí1

controller. Then, for any execution trace E0 ‚ä≤‚ä≥ {ùêΩ0}
it hold that (1) Eùëñ‚àí1
ùêΩùëñ = ùêΩùëñ‚àí1, for 1 ‚â§ ùëñ ‚â§ ùëõ.

ùõΩ1
‚àí‚àí‚àí‚àí‚Üí . . .

Proof. The transition Eùëñ‚àí1 ‚ä≤‚ä≥ {ùêΩùëñ‚àí1}

ùõΩùëñ
‚àí‚àí‚àí‚àí‚ÜíEùëñ ‚ä≤‚ä≥ {ùêΩùëñ }, for 1 ‚â§ ùëñ ‚â§ ùëõ, can be only derived by applying
one of the following rule: (Allow), (Insert), (Suppress). In the case of an application of rule (Allow),
ùõºùëñ‚àí‚àí‚àí‚àí‚ÜíùêΩùëñ with ùõΩùëñ = ùõºùëñ = ùúÜùëñ . Hence,
Eùëñ‚àí1 ‚ä≤‚ä≥ {ùêΩùëñ‚àí1}

ùõΩùëñ
‚àí‚àí‚àí‚àí‚ÜíEùëñ ‚ä≤‚ä≥ {ùêΩùëñ } derives from Eùëñ‚àí1

ùõºùëñ‚àí‚àí‚àí‚àí‚Üí Eùëñ and ùêΩùëñ‚àí1

Runtime Enforcement of PLCs

39

out (ùúÜùëñ ) = trigger (ùúÜùëñ ) = ùõºùëñ , as required. In the case of rule (Insert), Eùëñ‚àí1 ‚ä≤‚ä≥ {ùêΩùëñ‚àí1}
ùõº ‚â∫ùõºùëñ
from Eùëñ‚àí1
‚àí‚àí‚àí‚àí‚àí‚àí‚Üí Eùëñ and ùêΩùëñ‚àí1
and ùêΩùëñ = ùêΩùëñ‚àí1, as required. Finally, in the case of rule (Suppress), Eùëñ‚àí1 ‚ä≤‚ä≥ {ùêΩùëñ‚àí1}
‚àíùõºùëñ‚àí‚àí‚àí‚àí‚àí‚Üí Eùëñ and ùêΩùëñ‚àí1
from Eùëñ‚àí1
trigger (ùúÜùëñ ) = ùõºùëñ , as required.

ùõΩùëñ
‚àí‚àí‚àí‚àí‚ÜíEùëñ ‚ä≤‚ä≥ {ùêΩùëñ } derives
ùõºùëñ‚àí‚àí‚àí‚àí‚ÜíùêΩ , for some ùõº and ùêΩ , with ùõΩùëñ = ùõº. Thus, out (ùúÜùëñ )=out (ùõº ‚â∫ ùõºùëñ ) = ùõΩùëñ
ùõΩùëñ
‚àí‚àí‚àí‚àí‚ÜíEùëñ ‚ä≤‚ä≥ {ùêΩùëñ } derives
ùõºùëñ‚àí‚àí‚àí‚àí‚ÜíùêΩùëñ , for some ùõºùëñ , with ùõΩùëñ = ùúè and ùúÜùëñ = ‚àíùõºùëñ . Hence, out (ùúÜùëñ ) = ùúè and
‚ñ°

Proof of Theorem 2 (Soundness). Let ùë° = ùõΩ1¬∑ . . . ¬∑ ùõΩùëõ be a trace s.t. ‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ }

ùë°
‚àí‚àí‚Üí E ‚ä≤‚ä≥ {ùêΩ },
for some E ‚àà Edit and some controller ùêΩ . By an application of Lemma 6 there exist Eùëñ ‚àà Edit
ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí Eùëõ = E, with ùõΩùëñ = out (ùúÜùëñ ). Thus,
and ùúÜùëñ , for 1 ‚â§ ùëñ ‚â§ ùëõ, such that: ‚ü®| ùëí |‚ü© P
ùë° = out (ùúÜ1) ¬∑ . . . ¬∑ out (ùúÜùëõ). By Lemma 5, ÀÜùë° is a prefix of some trace in
‚ñ°
, as required.

ùúÜ2‚àí‚àí‚àí‚àí‚Üí . . .

ùúÜ1‚àí‚àí‚àí‚àí‚Üí E1

Proof. Given an arbitrary execution ‚ü®| ùëí |‚ü© P

Lemma 7 (Deadlock-freedom of the synthesis). Let ùëí ‚àà PropG be a global property and P
be a set of observable actions s.t. events(ùëí) ‚äÜ P. Then the edit automaton ‚ü®| ùëí |‚ü© P does not deadlock.
ùúÜùëõ‚àí‚àí‚àí‚àí‚Üí E, the proof is by induction on the
or
, for ùëù ‚àà PropL and some automaton variable X. Hence, the result follows
‚ñ°

length ùëõ of the execution trace. By an application of Lemma 5 we have that either E = ‚ü®| ùëù |‚ü© P
X
E = Z, with Z = ‚ü®| ùëù |‚ü© P
X
by inspection of the synthesis function of Table 5 and by induction on the structure of ùëù.

ùúÜ1‚àí‚àí‚àí‚àí‚Üí . . .

ùëí
(cid:74)

(cid:75)

Proof of Theorem 3 (Deadlock-freedom). Let ùë° be a trace such that ‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ }

ùë°
‚àí‚àí‚Üí E ‚ä≤‚ä≥ {ùêΩ },
for some edit automaton E and controller ùêΩ . By contradiction we assume that E ‚ä≤‚ä≥ {ùêΩ } is in deadlock.
Notice that, by definition, our controllers ùêΩ never deadlock. By Lemma 7 the automaton ‚ü®| ùëí |‚ü© P
ùõº
never deadlock as well. Consequently, we have that for any transition ùêΩ
‚àí‚àí‚àí‚Üí ùêΩ ‚Ä≤ there is no action ùúÜ
for E, such that the monitored controller E ‚ä≤‚ä≥ {ùêΩ } may progress according to one of the rules: (Allow),
or E = Z, with
(Suppress) and (Insert). By an application of Lemma 5, we have that either E = ‚ü®| ùëù |‚ü© P
X
, for some ùëù ‚àà PropL and some automaton variable X. Now, by Lemma 1, we have that
Z = ‚ü®| ùëù |‚ü© P
X

‚ü®| ùëù |‚ü© P

X =

ùõºùëñ .Eùëñ + (cid:205)
ùõºùëñ .Eùëñ + (cid:205)

ùëñ‚ààùêº

ùõº ‚ààQ

(cid:205)
ùëñ‚ààùêº
(cid:205)
ùëñ‚ààùêº

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

ùõºùëñ ‚â∫ end.Eùëñ + (cid:205)

‚àíùõº .F, if end ‚àâ ‚à™ùëñ ‚ààùêº ùõºùëñ

ùõº ‚ààQ

‚àíùõº .F, otherwise.

‚Ñé.ùëÜ, for 0 < ‚Ñé ‚â§ ùëò. Since tick-actions cannot be suppressed, we have that ùë° = ùë° ‚Ä≤ ¬∑ tick

for ùõºùëñ ‚àà P, Q = P \ (‚à™ùëñ ‚ààùêº ùõºùëñ ‚à™ {tick, end}), and Eùëñ and F edit automata. In both the cases ‚ü®| ùëù |‚ü© P
may
X
only deadlock the enforcement when the controller may only perform tick-actions. From this fact, we
ùëò‚àí‚Ñé,
derive ùêΩ = tick
for some possibly empty trace ùë° ‚Ä≤ terminating with an end. By Theorem 2, ùë° = ùë° ‚Ä≤ ¬∑ tick
. And
‚Ñé.ùëù ‚Ä≤, for some ùëù ‚Ä≤. Since ‚ü®| ùëí |‚ü© P is sound (Lemma 5) we derive
since ùëí is ùëò-sleeping we derive ùëù = tick
tick‚àí‚àí‚àí‚àí‚àí‚Üí E‚Ä≤, for some E‚Ä≤, in contradiction
that E = ‚ü®| ùëù |‚ü© P
X = ‚ü®| tick
‚ñ°
with what stated four lines above.

. Finally, ‚Ñé > 0 implies E

‚Ñé.ùëù ‚Ä≤ |‚ü© P
X

ùëò‚àí‚Ñé ‚àà

ùëí
(cid:74)

(cid:75)

Proof of Theorem 4 (Divergence-freedom). Let ùëí ‚àà PropG be a global property in its gen-
eral form, given by the intersection of ùëõ ‚â• 1 global properties ùëù‚àó
ùëõ, for ùëùùëñ ‚àà PropL,
with 1 ‚â§ ùëñ ‚â§ ùëõ. As ùëí is well-formed, according to Definition 4 also all local properties ùëùùëñ are
well-formed. This means that they all terminate with an end event. Thus, in all global properties
ùëñ , for 1 ‚â§ ùëñ ‚â§ ùëõ, the number of events within two subsequent end events is always finite. The
ùëù‚àó
ùë°
same holds for the property ùëí. Now, let ùë° be an arbitrary trace such that ‚ü®| ùëí |‚ü© P ‚ä≤‚ä≥ {ùëÉ }
‚àí‚àí‚Üí E ‚ä≤‚ä≥ {ùêΩ },
for some edit automaton E and controller ùêΩ . And let ùëò = max1‚â§ùëñ ‚â§ùëõùëòùëñ , where ùëòùëñ is the length of the
ùë° ‚Ä≤
‚àí‚àí‚àí‚Üí E‚Ä≤ ‚ä≤‚ä≥ {ùêΩ ‚Ä≤}, with | ùë° ‚Ä≤ |‚â• ùëò, and since by
, for 1 ‚â§ ùëñ ‚â§ ùëõ. Thus, if E ‚ä≤‚ä≥ {ùêΩ }
longest trace of
‚ñ°
Theorem 2 we have that ùë° ¬∑ ùë° ‚Ä≤ is a prefix of some trace
ùëí
(cid:74)

, then end ‚àà ùë° ‚Ä≤.

1 ‚à© ¬∑ ¬∑ ¬∑ ‚à© ùëù‚àó

ùëùùëñ
(cid:74)

(cid:75)

(cid:75)

