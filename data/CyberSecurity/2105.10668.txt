1
2
0
2

v
o
N
8
1

]

R
C
.
s
c
[

2
v
8
6
6
0
1
.
5
0
1
2
:
v
i
X
r
a

Runtime Enforcement of Programmable Logic Controllers

RUGGERO LANOTTE, UniversitÃ  degli Studi dellâ€™Insubria, Italy
MASSIMO MERRO, UniversitÃ  degli Studi di Verona, Italy
ANDREI MUNTEANU, UniversitÃ  degli Studi di Verona, Italy

With the advent of Industry 4.0, industrial facilities and critical infrastructures are transforming into an ecosys-
tem of heterogeneous physical and cyber components, such as programmable logic controllers, increasingly
interconnected and therefore exposed to cyber-physical attacks, i.e., security breaches in cyberspace that may
adversely affect the physical processes underlying industrial control systems.

In this paper, we propose a formal approach based on runtime enforcement to ensure specification compliance
in networks of controllers, possibly compromised by colluding malware that may tamper with actuator
commands, sensor readings, and inter-controller communications. Our approach relies on an ad-hoc sub-class
of Ligatti et al.â€™s edit automata to enforce controllers represented in Hennessy and Reganâ€™s Timed Process
Language. We define a synthesis algorithm that, given an alphabet P of observable actions and a timed
correctness property ğ‘’, returns a monitor that enforces the property ğ‘’ during the execution of any (potentially
corrupted) controller with alphabet P, and complying with the property ğ‘’. Our monitors correct and suppress
incorrect actions coming from corrupted controllers and emit actions in full autonomy when the controller
under scrutiny is not able to do so in a correct manner. Besides classical requirements, such as transparency
and soundness, the proposed enforcement enjoys deadlock- and diverge-freedom of monitored controllers,
together with scalability when dealing with networks of controllers. Finally, we test the proposed enforcement
mechanism on a non-trivial case study, taken from the context of industrial water treatment systems, in which
the controllers are injected with different malware with different malicious goals.

CCS Concepts: â€¢ Security and privacy â†’ Formal security models; Cyber-physical systems security.

Additional Key Words and Phrases: Runtime enforcement, control systems security, PLC malware

1 INTRODUCTION
Industrial Control Systems (ICSs) are physical and engineered systems whose operations are moni-
tored, coordinated, controlled, and integrated by a computing and communication core [53]. They
represent the backbone of Critical Infrastructures for safety-critical applications such as electric
power distribution, nuclear power production, and water supply.

The growing connectivity and integration in Industry 4.0 has triggered a dramatic increase in
the number of cyber-physical attacks [31] targeting ICSs, i.e., security breaches in cyberspace that
adversely affect the physical processes. Some notorious examples are: (i) the Stuxnet worm, which
reprogrammed Siemens PLCs of nuclear centrifuges in the nuclear facility of Natanz in Iran [35];
(ii) the CRASHOVERRIDE attack on the Ukrainian power grid, otherwise known as Industroyer [58];
(iii) the recent TRITON/TRISIS malware that targeted a petrochemical plant in Saudi Arabia [19].

One of the key components of ICSs are Programmable Logic Controllers, better known as PLCs.
They control mission-critical electrical hardware such as pumps or centrifuges, effectively serving
as a bridge between the cyber and the physical worlds. PLCs have an ad-hoc architecture to execute
simple repeating processes known as scan cycles (IEC 61131-3 [1]). Each scan cycle consists of three
phases: (i) reading of sensor measurements of the physical process; (ii) execution of the controller

Authorsâ€™ addresses: Ruggero Lanotte, UniversitÃ  degli Studi dellâ€™Insubria, Dipartimento di Scienze Umane e dellâ€™Innovazione
per il Territorio, via Santâ€™Abbondio 12, Como, 22100, Italy, ruggero.lanotte@uninsubria.it; Massimo Merro, UniversitÃ 
degli Studi di Verona, Dipartimento di Informatica, strada Le Grazie 15, Verona, 37134, Italy, massimo.merro@univr.it;
Andrei Munteanu, UniversitÃ  degli Studi di Verona, Dipartimento di Informatica, strada Le Grazie 15, Verona, 37134, Italy,
andrei.munteanu@univr.it.

 
 
 
 
 
 
2

R. Lanotte, M. Merro, A. Munteanu

Fig. 1. A network of compromised PLCs: ğ‘¦ğ‘– denote genuine sensor measurements, ğ‘¦a
measurements, ğ‘¢a

ğ‘– are corrupted sensor
ğ‘– denote corrupted inter-controller communications.

ğ‘– corrupted actuator commands, and ğ‘a

code to compute how the physical process should evolve; (iii) transmission of commands to the
actuator devices to govern the physical process as desired.

Due to their sensitive role in controlling industrial processes, successful exploitation of PLCs
can have severe consequences on ICSs. In fact, although modern controllers provide security
mechanisms to allow only legitimate firmware to be uploaded, the running code can be typically
altered by anyone with network or USB access to the controllers (see Figure 1). Published scan data
shows how thousands of PLCs are directly accessible from the Internet to improve efficiency [52].
Thus, despite their responsibility, controllers are vulnerable to several kinds of attacks, including
PLC-Blaster worm [59], Ladder Logic Bombs [28], and PLC PIN Control attacks [5].

Extra trusted hardware components have been proposed to enhance the security of PLC architec-
tures [45, 46]. For instance, McLaughlin [45] proposed a policy-based enforcement mechanism to
mediate the actuator commands transmitted by the PLC to the physical plant. Mohan et al. [46]
introduced a different architecture, in which every PLC runs under the scrutiny of a monitor which
looks for deviations with respect to safe behaviours. Both architectures have been validated by
means of simulation-based techniques. However, as far as we know, formal methodologies have
been rarely used to model and formally verify security-oriented architectures for ICSs.

Runtime enforcement [22, 40, 56] is a formal verification/validation technique aiming at correcting
possibly-incorrect executions of a system-under-scrutiny (SuS). It employs a kind of monitor [23]
that acts as a proxy between the SuS and the environment interacting with it. At runtime, the
monitor transforms any incorrect executions exhibited by the SuS into correct ones by either
replacing, suppressing or inserting observable actions on behalf of the system. The effectiveness of
the enforcement depends on the achievement of the two following general principles [40, 56]:

â€¢ transparency, i.e., the enforcement must not alter correct executions of the SuS;
â€¢ soundness, i.e., incorrect executions of the SuS must be prevented.
In this paper, we propose a formal approach based on runtime enforcement to ensure specification
compliance in networks of controllers possibly compromised by colluding malware that may tamper
with actuator commands, sensor readings, and inter-controller communications. combined with
automatic recovery mechanisms.

Our goal is to enforce potentially corrupted controllers using secure proxies based on a sub-
class of Ligatti et al.â€™s edit automata [40]. These automata will be synthesised from enforceable
timed correctness properties to form networks of monitored controllers, as in Figure 2. The proposed
enforcement will enjoy both transparency and soundness together with the following features:
â€¢ determinism preservation, i.e., the enforcement should not introduce nondeterminism;
â€¢ deadlock-freedom, i.e., the enforcement should not introduce deadlocks;

PLCnuan,can,yanPLC1ua1,ca1,ya1ca1canFieldCommunicationsNetworkya1yanSupervisoryControlNetworkynuanua1y1Â·Â·Â·Â·Â·Â·Runtime Enforcement of PLCs

3

Fig. 2. A network of monitored controllers.

â€¢ divergence-freedom, i.e., the enforcement should not introduce divergencies;
â€¢ mitigation of incorrect/malicious activities;
â€¢ scalability, i.e., the enforcement mechanism should scale to networks of controllers.

Obviously, when a controller is compromised, these objectives can be achieved only with the
introduction of a physically independent secure proxy, as advocated by McLaughlin and Mohan
et al. [45, 46], which does not have any Internet or USB access, and which is connected with the
monitored controller via secure channels. This may seem like we just moved the problem over
to securing the proxy. However, this is not the case because the proxy only needs to enforce a
timed correctness property of the system, while the controller does the whole job of controlling the
physical process relying on potentially dangerous communications via the Internet or the USB
ports. Thus, any upgrade of the control system will be made to the controller and not to the secure
proxy. Of course, by no means runtime reconfigurations of the secure proxy should be allowed as
its enforcing should be based on the physics of the plant itself and not on the controller code.

Contribution. Fist of all, we define the attacker model and the attacker objectives in an enforced
ICS architecture such as that depicted in Figure 2. Then, we introduce a formal language to
specify controller programs. For this very purpose, we resort to process calculi, a successful and
widespread formal approach in concurrency theory for representing complex systems, such as mobile
systems [16] and cyber-physical systems [39], and used in many areas, including verification of
security protocols [3, 4] and security analysis of cyber-physical attacks [38]. Thus, we define a simple
timed process calculus, based on Hennessy and Reganâ€™s Timed Process Language (TPL) [29], for
specifying controllers, finite-state enforcers, and networks of communicating monitored controllers.
Then, we define a simple description language to express timed correctness properties that should
hold for a (possibly unbounded) number of scan cycles of the monitored controller. This will allow
us to abstract over controllers implementations, focusing on general properties which may even be
shared by completely different controllers. In this regard, we might resort to one of the several logics
existing in the literature for monitoring timed concurrent systems, and in particular cyber-physical
systems (see, e.g., [9, 24]). However, the peculiar iterative behaviour of controllers convinced us to
adopt the sub-class of regular expressions that can be recognised by finite automata whose cycles
always contain at least one final state; this is the largest class of regular properties that can be
enforced by finite-state Ligatti et at.â€™s edit automata (see Beauquier et al.â€™s work [10]). In Section 5,
we express a wide class of correctness properties for controllers in terms of (our) regular properties.
After defining a formal language to describe controller properties, we provide a synthesis function
âŸ¨| âˆ’ |âŸ© P that, given an alphabet P of observable actions (sensor readings, actuator commands, and

PLCnuan,can,yanPLC1ua1,ca1,ya1proxy1ua1/u1ca1/c1y1/y1proxynyn/yncan/cnuan/unua1ca1y1yncanuanc1cnFieldCommunicationsNetworky1ynSupervisoryControlNetworkynunu1y1Â·Â·Â·Â·Â·Â·Â·Â·Â·4

R. Lanotte, M. Merro, A. Munteanu

inter-controller communications) and a deterministic regular property ğ‘’ combining events of P,
returns an edit automaton âŸ¨| ğ‘’ |âŸ© P. The resulting enforcement mechanism will ensure the required
features mentioned before: transparency, soundness, determinism preservation, deadlock-freedom,
divergence-freedom, mitigation and scalability. Then, we propose a non-trivial case study, taken
from the context of industrial water treatment systems, and implemented as follows: (i) the physical
plant is simulated in Simulink [44]; (ii) the open source PLCs are implemented in OpenPLC [8] and
executed on Raspberry Pi; (iii) the enforcers run on connected FPGAs. In this setting, we test our
enforcement mechanism when injecting the PLCs with 5 different malware, with different goals.

Outline. Section 2 describes the attacker model and the attacker objectives. Section 3 gives a
formal language for monitored controllers. Section 4 defines the case study. Section 5 provides a
language of regular properties to express controller behaviours; it also contains a taxonomy of
properties expressible in the language. Section 6 contains the algorithm to synthesise monitors
from regular properties, together with the main results. Section 7 discusses the implementation of
the case study when exposed to five different attacks. Section 8 is devoted to related work. Section 9
draws conclusions and discusses future work. Technical proofs can be found in the appendix.

2 ATTACKER MODEL AND ATTACKER OBJECTIVES
In the following sections, we will propose an enforcement-based architecture for ICSs (as those
depicted in Figure 2) to counter attacks complying with the following attacker model:

â€¢ malware injected in one or more PLCs may forge/drop actuator commands, modify sensor

readings coming from the plant, forge/drop inter-controller communications;

â€¢ malware injected in different PLCs of the same field communications network may collabo-

rate/communicate with each other to achieve common objectives;

â€¢ the attacker runtime behaviour may vary as it may depend on the received sensor signals

and the communications with other PLCs;

â€¢ malicious alterations of sensor signals at network level, or within the sensor devices, are not

allowed (they are out of the scope of this paper);

â€¢ scan cycles must be completed within a specific time, called maximum cycle limit, which
depends on the controlled physical process; if this time limit is violated then the controller
stops and throws an exception [59]; we assume that the injected malware never violates the
maximum cycle limit because not interested in causing the immediate shutdown of a PLC;
â€¢ the enforcers added in the architecture are physically independent secure proxies with no
Internet or USB access, and connected with the controller via secure channels; as a consequence,
the measurements transmitted to the supervisory control network will not be corrupted;

â€¢ runtime reconfigurations of secure proxies are not allowed.

Thus, in general, the attacker objectives can be resumed in alteration/forgery of PLC actuator
commands and/or communication messages between PLCs to eventually affect the evolution of the
controlled physical processes, and/or transmit fake signals to the supervisory control network.

3 A FORMAL LANGUAGE FOR MONITORED CONTROLLERS
In this section, we introduce the Timed Calculus of Monitored Controllers, called TCMC, as an abstract
formal language to express networks of controllers integrated with edit automata sitting on the
network interface of each controller to monitor/correct their interactions with the rest of the system.
Basically, TCMC extends Hennessy and Reganâ€™s Timed Process Language (TPL) [29] with monitoring
edit automata. Like TPL time proceeds in discrete time slots separated by tick-actions.

Let us start with some preliminary notation. We use ğ‘ , ğ‘ ğ‘˜ âˆˆ Sens to name sensor signals; ğ‘, ğ‘ğ‘˜ âˆˆ Act

to indicate actuator commands; ğ‘, ğ‘ğ‘˜ âˆˆ Chn for channels; ğ‘§, ğ‘§ğ‘˜ for generic names.

Runtime Enforcement of PLCs

5

Controllers. In our setting, controllers are nondeterministic sequential timed processes evolving
through three main phases: sensing of sensor signals, communication with other controllers, and
actuation. For convenience, we use five different syntactic categories to distinguish the five main
states of a controller: Ctrl for initial states, Sleep for sleeping states, Sens for sensing states,
Com for communication states, and Act for actuation states. In its initial state, a controller is a
recursive process waiting for signal stabilisation in order to start the sensing phase:

Ctrl âˆ‹ ğ‘ƒ

::= ğ‘‹

Sleep âˆ‹ ğ‘Š ::=

tick.ğ‘Š (cid:12)
(cid:12)

ğ‘†

The main process describing a controller consists of some recursive process defined via equations
of the form ğ‘‹ = tick.ğ‘Š , with ğ‘Š âˆˆ Sleep; here, ğ‘‹ is a process variable that may occur (free) in ğ‘Š . For
convenience, our controllers always have at least one initial timed action tick to ensure time-guarded
recursion, thus avoiding undesired zeno behaviours [30]: the number of untimed actions between
two tick-actions is always finite. Then, after a determined sleeping period, when sensor signals get
stable, the sensing phase can start.

During the sensing phase, the controller waits for a finite number of admissible sensor signals. If
none of those signals arrives in the current time slot then the controller will timeout moving to the
following time slot (we adopt the TPL construct âŒŠÂ·âŒ‹Â· for timeout). The syntax is the following:

Sens âˆ‹ ğ‘†

::=

âŒŠ(cid:205)ğ‘– âˆˆğ¼ ğ‘ ğ‘– .ğ‘†ğ‘– âŒ‹ğ‘†

(cid:12)
(cid:12) ğ¶

where (cid:205)ğ‘– âˆˆğ¼ ğ‘ ğ‘– .ğ‘†ğ‘– denotes the standard construct for nondeterministic choice. Once the sensing
phase is concluded, the controller starts its calculations that may depend on communications with
other controllers governing different physical processes. Controllers communicate with each other
for mainly two reasons: either to receive notice about the state of other physical sub-processes or
to require an actuation on a physical process which is out of their control. As in TPL, we adopt
a channel-based handshake point-to-point communication paradigm. Note that, in order to avoid
starvation, communication is always under timeout. The syntax for the communication phase is:

Comm âˆ‹ ğ¶

âŒŠ(cid:205)ğ‘– âˆˆğ¼ ğ‘ğ‘– .ğ¶ğ‘– âŒ‹ğ¶ (cid:12)
(cid:12)
In the actuation phase a controller eventually transmits a finite sequence of commands to
actuators, and then, it emits a fictitious system signal end to denote the end of the scan cycle. After
that, the whole scan cycle can restart. Formally,

âŒŠğ‘.ğ¶âŒ‹ğ¶ (cid:12)

(cid:12) ğ´

::=

Act âˆ‹ ğ´

::=

ğ‘.ğ´ (cid:12)
(cid:12)

end.ğ‘‹

Remark 1 (Scan cycle duration and maximum cycle limit). The scan cycle of a PLC must
be completed within a specific time, called maximum cycle limit, which depends on the controlled
physical process; if this time limit is violated the the controller stops and throws an exception [59]. Thus,
the signal end must occur well before the maximum cycle limit of the controller. We actually work
under the assumption that our controllers successfully complete their scan cycle in less than half of
the maximum cycle limit. The reasons for this assumption will be clarified in Remark 4. Please, notice
that it is easy to statically derive the maximum duration of a scan cycle expressed in our calculus by
simply counting the maximum number of tick-prefixes occurring between two subsequent end-prefixes.
The operational semantics in Table 1 is along the lines of Hennessy and Reganâ€™s TPL [29]. In
the following, we use the metavariable ğ›¼ to range over the set of all (observable) controller actions:
{ğ‘ , ğ‘, ğ‘, ğ‘, tick, end}. These actions denote: sensor readings, actuator commands, channel transmissions,
channel receptions, passage of time, and end of scan cycles, respectively. Notice that at our level of
abstraction we represent only the observable behaviour of PLCs: internal computations are not
modelled within PLCs; although, we do have ğœ-actions to express communications between two
PLCs, as the reader will notice in Table 2.

6

R. Lanotte, M. Merro, A. Munteanu

âˆ’
tick.ğ‘Š tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘Š

(Rec)

ğ‘‹ = tick.ğ‘Š
ğ‘‹ tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘Š

(Sleep)

(ReadS)

(InC)

(OutC)

(WriteA)

ğ‘— âˆˆ ğ¼
âŒŠ(cid:205)ğ‘– âˆˆğ¼ ğ‘ ğ‘– .ğ‘†ğ‘– âŒ‹ğ‘†
ğ‘— âˆˆ ğ¼
âŒŠ(cid:205)ğ‘– âˆˆğ¼ ğ‘ğ‘– .ğ¶ğ‘– âŒ‹ğ¶

âˆ’

ğ‘
âˆ’âˆ’âˆ’â†’ ğ¶

âŒŠğ‘.ğ¶âŒ‹ğ¶ â€²
âˆ’
ğ‘
âˆ’âˆ’âˆ’â†’ ğ´

ğ‘.ğ´

ğ‘  ğ‘—
âˆ’âˆ’âˆ’âˆ’â†’ ğ‘† ğ‘—

(TimeoutS)

ğ‘ ğ‘—
âˆ’âˆ’âˆ’âˆ’â†’ ğ¶ ğ‘—

(TimeoutInC)

(TimeoutOutC)

âˆ’
âŒŠ(cid:205)ğ‘– âˆˆğ¼ ğ‘ ğ‘– .ğ‘†ğ‘– âŒ‹ğ‘†

tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘†
âˆ’
âŒŠ(cid:205)ğ‘– âˆˆğ¼ ğ‘ğ‘– .ğ¶ğ‘– âŒ‹ğ¶ tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ¶
âˆ’
tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ¶ â€²

âŒŠğ‘.ğ¶âŒ‹ğ¶ â€²

(End)

âˆ’
end.ğ‘‹ endâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘‹

Table 1. LTS for controllers.

Remark 2 (Attacker model and end-signal). In our abstract representation of PLCs, the end-signal
is not really part of the (possibly compromised) PLC program but it is rather a system signal denoting
the end of a scan cycle. As a consequence, in accordance with our attacker model, we assume that this
fictitious signal cannot be dropped or forged by the attacker.

Monitored controllers. The core of our enforcement relies on (timed) finite-state Ligatti et al.â€™s
edit automata [40], i.e., a particular class of automata specifically designed to allow/suppress/insert
actions in a generic system in order to preserve its correct behaviour. The syntax is as follows:

::=

Edit âˆ‹ E, F

go (cid:12)
The special automaton go will admit any action of the monitored system. The edit automaton
(cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘– enforces an action ğœ†ğ‘– , and then continues as Eğ‘– , for any ğ‘– âˆˆ ğ¼ , with ğ¼ finite. Here, the
symbol ğœ† ranges over: (i) ğ›¼ to allow the action ğ›¼, (ii) âˆ’ğ›¼ to suppress the action ğ›¼, and (iii) ğ›¼1 â‰º ğ›¼2, for
ğ›¼1 â‰  ğ›¼2, to insert the action ğ›¼1 before the action ğ›¼2. Recursive automata X are defined via equations
of the form X = E, where the automata variable X may occur (free) in E.

(cid:12) (cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘–

(cid:12)
(cid:12) X

The operational semantics of our edit automata is given via the following transition rules:

(Go)

âˆ’
ğ›¼
âˆ’âˆ’âˆ’â†’ go

go

(Edit)

ğ‘— âˆˆ ğ¼

(cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘–

ğœ† ğ‘—
âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘—

(recE)

ğœ†
âˆ’âˆ’âˆ’â†’ Eâ€²

X = E E
ğœ†
âˆ’âˆ’âˆ’â†’ Eâ€²

X

Our monitored controllers, written E âŠ²âŠ³ {ğ½ }, consist of a controller ğ½ , for ğ½ âˆˆ Ctrl âˆª Sleep âˆª
Sens âˆª Comm âˆª Act, and an edit automaton E enforcing the behaviour of ğ½ , according to the
following transition rules, presented in the style of [42]:

(Allow)

ğ›¼
âˆ’âˆ’âˆ’â†’ Eâ€² ğ½

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ½ â€²
ğ›¼
âˆ’âˆ’âˆ’â†’ Eâ€² âŠ²âŠ³ {ğ½ â€²}

E
E âŠ²âŠ³ {ğ½ }

(Suppress)

âˆ’ğ›¼
âˆ’âˆ’âˆ’âˆ’â†’ Eâ€² ğ½

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ½ â€²
ğœ
âˆ’âˆ’âˆ’â†’ Eâ€² âŠ²âŠ³ {ğ½ â€²}

E
E âŠ²âŠ³ {ğ½ }

(Insert) E

ğ›¼1 â‰º ğ›¼2
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Eâ€² ğ½
E âŠ²âŠ³ {ğ½ }

ğ›¼2âˆ’âˆ’âˆ’âˆ’â†’ ğ½ â€²
ğ›¼1âˆ’âˆ’âˆ’âˆ’â†’ Eâ€² âŠ²âŠ³ {ğ½ }

Rule (Allow) is used for allowing observable actions emitted by the controller under scrutiny. By
an application of Rule (Suppress), incorrect actions ğ›¼ emitted by (possibly corrupted) controllers
ğ½ are suppressed, i.e., converted into (silent) ğœ-actions. Rule (Insert) is used to insert an action ğ›¼1
before an action ğ›¼2 of the controller. In the following, the metavariable ğ›½ will range over the same
set of actions as ğ›¼, together with the silent action ğœ.

Runtime Enforcement of PLCs

7

ğ‘1

ğ‘1 âˆ¥ ğ‘2

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ‘ â€²
1
ğ›¼
âˆ’âˆ’âˆ’â†’ ğ‘ â€²
1 âˆ¥ ğ‘2

ğ‘1

ğ‘
âˆ’âˆ’âˆ’â†’ ğ‘ â€²

(ChnSync)

ğ‘1 âˆ¥ ğ‘2
ğ‘2 âˆ¥ ğ‘1

(ParL)

(ParR)

1 ğ‘2
ğœ
âˆ’âˆ’âˆ’â†’ ğ‘ â€²
ğœ
âˆ’âˆ’âˆ’â†’ ğ‘ â€²

ğ‘
âˆ’âˆ’âˆ’â†’ ğ‘ â€²
2
1 âˆ¥ ğ‘ â€²
2
2 âˆ¥ ğ‘ â€²
1
tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘ â€²
tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘ â€²

ğ‘1 âˆ¥ ğ‘2

ğ‘2

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ‘ â€²
2
ğ›¼
âˆ’âˆ’âˆ’â†’ ğ‘1 âˆ¥ ğ‘ â€²
2

2 ğ‘1 âˆ¥ ğ‘2
1 âˆ¥ ğ‘ â€²
2
Table 2. LTS for field communications networks of monitored controllers.

1 ğ‘2
ğ‘1 âˆ¥ ğ‘2

(TimeSync)

tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ ğ‘ â€²

ğ‘1

ğœ
âˆ’âˆ’âˆ’â†’Ì¸

Here, we wish to stress that, like Ligatti et al. [40], we are interested in deterministic (and hence
implementable) enforcement. With the following technical definitions we extract from enforcer
actions ğœ† both: (i) the controller triggering actions, and (ii) the resulting output actions.

Definition 1. Let ğœ† âˆˆ {ğ›¼, âˆ’ğ›¼, ğ›¼1 â‰º ğ›¼2} be an arbitrary action for edit automata, we write
trigger (ğœ†) to denote the controller action triggering ğœ†, defined as: trigger (ğ›¼) = ğ›¼, trigger (âˆ’ğ›¼) = ğ›¼ and
trigger (ğ›¼1 â‰º ğ›¼2) = ğ›¼2. Similarly, we write out (ğœ†) to denote the output action prescribed by ğœ†, defined
as: out (ğ›¼) = ğ›¼, out (âˆ’ğ›¼) = ğœ and out (ğ›¼1 â‰º ğ›¼2) = ğ›¼1. Given a trace ğ‘¡ = ğœ†1 Â· Â· Â· ğœ†ğ‘›, we write out (ğ‘¡) for
the trace out (ğœ†1) Â· Â· Â· out (ğœ†ğ‘›).

Now, we provide a definition of deterministic enforcer along the lines of Pinisetty at al. [50].

Definition 2 (Deterministic enforcer). A edit automaton E âˆˆ Edit is said to be deterministic
iff in every term (cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘– that appears in E there are no ğœ†ğ‘˜ and ğœ† ğ‘— , for ğ‘˜, ğ‘— âˆˆ ğ¼ , ğ‘˜ â‰  ğ‘—, such that
trigger (ğœ†ğ‘˜ ) = trigger (ğœ† ğ‘— ) and out (ğœ†ğ‘˜ ) = out (ğœ† ğ‘— ).

Finally, we can easily generalise the concept of monitored controller to a field communications
network of parallel monitored controllers, each one acting on different actuators, and exchanging
information via channels. These networks are formally defined via a straightforward grammar:

FNet âˆ‹ ğ‘ ::= E âŠ²âŠ³ {ğ½ }

(cid:12)
(cid:12) ğ‘ âˆ¥ ğ‘

with the operational semantics defined in Table 2.

Notice that monitored controllers may interact with each other via channel synchronisation
(see Rule (ChnSync)). Moreover, via rule (TimeSync) they may evolve in time only when channel
synchronisation may not occur (our controllers do not admit zeno behaviours). This ensures
maximal progress [29], a desirable time property when modelling real-time systems: channel
communications will never be postponed.

Definition 3 (Execution traces). Given three finite execution traces ğ‘¡c = ğ›¼1 . . . ğ›¼ğ‘˜ , ğ‘¡e = ğœ†1 . . . ğœ†ğ‘™ ,
and ğ‘¡m = ğ›½1 . . . ğ›½ğ‘›, for controllers, edit automata and monitored controllers, respectively. We write: (i)
ğ‘¡e
âˆ’âˆ’âˆ’â†’ Eâ€², as an abbreviation for
ğ‘ƒ

ğ‘¡c
âˆ’âˆ’âˆ’â†’ ğ‘ƒ â€², as an abbreviation for ğ‘ƒ = ğ‘ƒ0

ğ›¼ğ‘˜âˆ’âˆ’âˆ’âˆ’â†’ ğ‘ƒğ‘˜ = ğ‘ƒ â€²; (ii) E

ğ›¼1âˆ’âˆ’âˆ’âˆ’â†’ Â· Â· Â·

E = E0

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’ Â· Â· Â·

ğœ†ğ‘™âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘™ = Eâ€²; (iii) ğ‘

ğ‘¡mâˆ’âˆ’âˆ’âˆ’â†’ ğ‘ â€², as an abbreviation for ğ‘ = ğ‘0

ğ›½1

âˆ’âˆ’âˆ’âˆ’â†’ Â· Â· Â·

ğ›½ğ‘›
âˆ’âˆ’âˆ’âˆ’â†’ ğ‘ğ‘› = ğ‘ â€².

In the rest of the paper we adopt the following notations.

Notation 1. As usual, we write ğœ– to denote the empty trace. Given a trace ğ‘¡ we write | ğ‘¡ | to denote
the length of ğ‘¡, i.e., the number of actions occurring in ğ‘¡. Given a trace ğ‘¡ we write Ë†ğ‘¡ to denote the trace
obtained by removing the ğœ-actions. Given two traces ğ‘¡ â€² and ğ‘¡ â€²â€², we write ğ‘¡ â€² Â· ğ‘¡ â€²â€² for the trace resulting
from the concatenation of ğ‘¡ â€² and ğ‘¡ â€²â€². For ğ‘¡ = ğ‘¡ â€² Â· ğ‘¡ â€²â€² we say that ğ‘¡ â€² is a prefix of ğ‘¡ and ğ‘¡ â€²â€² is a suffix of ğ‘¡.

8

R. Lanotte, M. Merro, A. Munteanu

Fig. 3. A simplified Industrial Water Treatment System.

4 USE CASE: THE SWAT SYSTEM
In this section, we describe how to specify in TCMC a non-trivial network of PLCs to control (a
simplified version of) the Secure Water Treatment system (SWaT) [43].

SWaT represents a scaled down version of a real-world industrial water treatment plant. The
system consists of 6 stages, each of which deals with a different treatment, including: chemical
dosing, filtration, dechlorination, and reverse osmosis. For simplicity, in our use case, depicted
in Figure 3, we consider only three stages. In the first stage, raw water is chemically dosed and
pumped in a tank ğ‘‡1, via two pumps pump1 and pump2. A valve connects ğ‘‡1 with a filtration unit
that releases the treated water in a second tank ğ‘‡2. Here, we assume that the flow of the incoming
water in ğ‘‡1 is greater than the outgoing flow passing through the valve. The water in ğ‘‡2 flows into
a reverse osmosis unit to reduce inorganic impurities. In the last stage, the water coming from the
reverse osmosis unit is either distributed as clean water, if required standards are met, or stored
in a backwash tank ğ‘‡3 and then pumped back, via a pump pump3, to the filtration unit. Here, we
assume that tank ğ‘‡2 is large enough to receive the whole content of tank ğ‘‡3 at any moment.

The SWaT system has been used to provide a dataset containing physical and network data
recorded during 11 days of activity [27]. Part of this dataset contains information about the execution
of the system in isolation, while a second part records the effects on the system when exposed
to different kinds of cyber-physical attacks. Thus, for instance, (i) drops of commands to activate
pump2 may affect the quality of the water, as they would affect the correct functioning of the
chemical dosing pump; (ii) injections of commands to close the valve between ğ‘‡1 and ğ‘‡2, may give
rise to an overflow of tank ğ‘‡1 if this tank is full; (iii) integrity attacks on the signals coming from the
sensor of the tank ğ‘‡3 may result in damages of the pump pump3 if it is activated when ğ‘‡3 is empty.
Each tank is controlled by its own PLC. The programs of the three PLCs, expressed in terms of

ladder logic, are given in Figure 4. In the following, we give their descriptions in TCMC.

Let us start with the code of the controller PLC1 managing the tank ğ‘‡1. Its definition is given in
terms of two equations to deal with the case when the two pumps, pump1 and pump2, are both off
and both on, respectively. Intuitively, when the pumps are off, the level of water in ğ‘‡1 drops until it
reaches its low level (event ğ‘™1); when this happens both pumps are turned on and they remain so

T1h1âˆ’m1âˆ’...l1âˆ’m1âˆ’..../valveÅ“pump1Å“chemicaldosingpump2rawwaterT2h2âˆ’l2âˆ’FiltrationunitT3h3âˆ’l3âˆ’Å“pump3ReverseosmosisunitcleanwaterPLC1PLC2PLC3l1,m1,h1on1,on2,openoï¬€1,oï¬€2,closel2,h2l3,h3on3oï¬€3openreq,closereqRuntime Enforcement of PLCs

9

Fig. 4. Ladder logics of the three PLCs controlling the system in Figure 3.

until the tank is refilled, reaching its high level (event â„1). Formally,

1 = tick.(cid:0) âŒŠğ‘™1.on1.on2.close.end.ğ‘ƒ on
ğ‘ƒ off
1

+ ğ‘š1. âŒŠopen_req.off1.off2.open.end.ğ‘ƒ off
+ â„1. âŒŠopen_req.off1.off2.open.end.ğ‘ƒ off
âŒ‹ (off1.off2.close.end.ğ‘ƒ off

1 )(cid:1)
1 = tick.(cid:0) âŒŠğ‘™1.on1.on2.close.end.ğ‘ƒ on
ğ‘ƒ on
1

+ ğ‘š1. âŒŠopen_req.on1.on2.open.end.ğ‘ƒ on
+ â„1. âŒŠopen_req.off1.off2.open.end.ğ‘ƒ off
âŒ‹ (off1.off2.close.end.ğ‘ƒ on

1 )(cid:1)

1 + close_req.off1.off2.close.end.ğ‘ƒ off
1 + close_req.off1.off2.close.end.ğ‘ƒ off

1 âŒ‹ (off1.off2.close.end.ğ‘ƒ off
1 )
1 âŒ‹ (off1.off2.close.end.ğ‘ƒ off
1 )

1 + close_req.on1.on2.close.end.ğ‘ƒ on
1 + close_req.off1.off2.close.end.ğ‘ƒ off

1 âŒ‹ (on1.on2.close.end.ğ‘ƒ on
1 )
1 âŒ‹ (off1.off2.close.end.ğ‘ƒ off
1 )

Thus, for instance, when the pumps are off the PLC1 waits for one time slot (to get stable sensor
signals) and then checks the water level of the tank ğ‘‡1, distinguishing between three possible states.
If ğ‘‡1 reaches its low level (signal ğ‘™1) then the pumps are turned on (commands on1 and on2) and the
valve is closed (command open_req). Otherwise, if the tank ğ‘‡1 is at some intermediate level between
low and high (signal ğ‘š1) then PLC1 listens for requests arriving from PLC2 to open/close the valve.
Precisely, if the PLC gets an open_req request then it opens the valve, letting the water flow from ğ‘‡1
to ğ‘‡2, otherwise, if it gets a close_req request then it closes the valve; in both cases the pumps remain
off. If the level of the tank is high (signal â„1) then the requests of water coming from PLC2 are
served as before, but the two pumps are eventually turned off (commands off1 and off2).

PLC2 manages the water level of tank ğ‘‡2. Its code consists of the two equations to model the

filling (state â†‘) and the emptying (state â†“) of the tank. Formally,
2 âŒ‹end.ğ‘ƒ â†‘
2 âŒ‹end.ğ‘ƒ â†“

ğ‘ƒ â†‘
2 = tick.( âŒŠğ‘™2. âŒŠopen_req.end.ğ‘ƒ â†‘
ğ‘ƒ â†“
2 = tick.( âŒŠğ‘™2. âŒŠopen_req.end.ğ‘ƒ â†‘

2 + ğ‘š2. âŒŠopen_req.end.ğ‘ƒ â†‘
2 + ğ‘š2. âŒŠclose_req.end.ğ‘ƒ â†“

2 âŒ‹end.ğ‘ƒ â†‘
2 âŒ‹end.ğ‘ƒ â†“

2 + â„2. âŒŠclose_req.end.ğ‘ƒ â†“
2 + â„2. âŒŠclose_req.end.ğ‘ƒ â†“

2 âŒ‹end.ğ‘ƒ â†‘
2 âŒ‹end.ğ‘ƒ â†“

2 âŒ‹end.ğ‘ƒ â†‘
2 )
2 âŒ‹end.ğ‘ƒ â†“
2 )

Here, after one time slot, the level of ğ‘‡2 is checked. If the level is low (signal ğ‘™2) then PLC2 sends
a request to PLC1, via the channel open_req, to open the valve that lets the water flow from ğ‘‡1 to ğ‘‡2,
and then returns. Otherwise, if the level of tank ğ‘‡2 is high (signal â„2) then PLC2 asks PLC1 to close
the valve, via the channel close_req, and then returns. Finally, if the tank ğ‘‡2 is at some intermediate
level between ğ‘™2 and â„2 (signal ğ‘š2) then the valve remains open (respectively, closed) when the
tank is refilling (respectively, emptying).

Finally, PLC3 manages the water level of the backwash tank ğ‘‡3. Its code consists of two equations

to deal with the case when the pump pump3 is off and on, respectively. Formally,

ğ‘ƒ off
3 = tick.( âŒŠğ‘™3.off3.end.ğ‘ƒ off
ğ‘ƒ on
3 = tick.( âŒŠğ‘™3.off3.end.ğ‘ƒ off

3 + ğ‘š3.off3.end.ğ‘ƒ off
3 + ğ‘š3.on3.end.ğ‘ƒ on

3 + â„3.on3.end.ğ‘ƒ on
3 + â„3.on3.end.ğ‘ƒ on

3 âŒ‹ (off3.end.ğ‘ƒ off
3 âŒ‹ (off3.end.ğ‘ƒ off

3 ))

3 ))

10

R. Lanotte, M. Merro, A. Munteanu

Here, after one time slot, the level of tank ğ‘‡3 is checked. If the level is low (signal ğ‘™3) then PLC3
turns off the pump pump3 (command off3), and then returns. Otherwise, if the level of ğ‘‡3 is high
(signal â„3) then the pump is turned on (command on3) until the whole content of ğ‘‡3 is pumped back
into the filtration unit of ğ‘‡2.

Examples of correctness properties and attacks. In a system similar to that described above, one
would expect a number of properties capturing the correct functioning of system components.
Let us provide a few examples of such correctness properties and some specific attacks that may
potentially invalidate these properties.

A first property might say that if PLC1 receives a request to open the valve between tanks ğ‘‡1
and ğ‘‡2 then the same valve will be eventually closed early enough to prevent water overflow in
tank ğ‘‡2. This property certainly holds when the system is not exposed to any attack. However,
a malware injected in PLC1 might try to undermine this property by tampering either with the
actuator dedicated to the valve or with the requests of PLC2 to open/close the valve. In particular, a
malicious request to open the valve might be forged by an attacker injected in PLC2. Thus, another
desired correctness property might say that whenever the tank ğ‘‡2 is full then PLC2 will never ask
for incoming water from tank ğ‘‡1. Finally, another expected property might say that pump3 will
never work without enough water in tank ğ‘‡3. Again, an attacker injected in PLC3 might try to
undermine this property by tampering either with the actuator dedicated to the pump or with the
sensor measuring the level of tank ğ‘‡3.

In Section 7.3 we will provide formal definitions for patterns template of structured correctness

properties that are suitable for enforcing correct behaviours of our PLCs.

5 A FORMAL LANGUAGE FOR CONTROLLER PROPERTIES
In this section, we provide a simple description language to express correctness properties that we
may wish to enforce at runtime in our controllers. As discussed in the Introduction, we resort to (a
sub-class of) regular properties as they allow us to express interesting classes of properties referring
to one or more scan cycles of a controller. The proposed language distinguishes between two kinds
of properties: (i) global properties, ğ‘’ âˆˆ PropG, to express general controllersâ€™ execution traces;
(ii) local properties, ğ‘ âˆˆ PropL, to express traces confined to a finite number of consecutive scan
cycles. The two families of properties are formalised via the following regular grammar:

ğ‘’ âˆˆ PropG
ğ‘, ğ‘ âˆˆ PropL

::=
::=

ğ‘âˆ— | ğ‘’1 âˆ© ğ‘’2
ğœ– | ğ‘1; ğ‘2 | âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘–

| ğ‘1 âˆ© ğ‘2

where ğœ‹ğ‘– âˆˆ Events â‰œ Sens âˆª Act âˆª Chnâˆ— âˆª {tick} âˆª {end} denote atomic properties, called events, that
may occur as prefix of a property. With an abuse of notation, we use the symbol ğœ– to denote both
the empty property and the empty trace.

The semantics of our logic is naturally defined in terms of sets of execution traces which satisfy

a given property; its formal definition is given in Table 3.

However, the syntax of our logic is a bit too permissive with respect to our intentions, as it allows
us to describe partial scan cycles, i.e., cycles that have not completed. Thus, we restrict ourselves to
considering properties which builds on top of local properties associated to complete scan cycles,
i.e., scan cycles whose last action is an end-action. Formally,

Definition 4. Well-formed properties are defined as follows:
â€¢ the local property end.ğœ– is well formed;
â€¢ a local property of the form ğ‘1; ğ‘2 is well formed if ğ‘2 is well formed;
â€¢ a local property of the form ğ‘1 âˆ© ğ‘2 is well formed if both ğ‘1 and ğ‘2 are well formed;

Runtime Enforcement of PLCs

11

ğ‘âˆ—
(cid:74)
(cid:75)
ğ‘’1 âˆ© ğ‘’2
(cid:74)
(cid:75)
ğœ–
(cid:74)
(cid:75)
ğ‘1 âˆ© ğ‘2
(cid:74)
ğ‘1; ğ‘2
(cid:74)
(cid:75)
(cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘–
(cid:74)

(cid:75)

(cid:75)

, for 1 â‰¤ ğ‘– â‰¤ ğ‘›}
(cid:75)

}

ğ‘
(cid:74)

ğ‘’2
(cid:74)

and ğ‘¡ âˆˆ

â‰œ {ğœ–} âˆª (cid:208)ğ‘› âˆˆN+ {ğ‘¡ | ğ‘¡ = ğ‘¡1 Â· . . . Â· ğ‘¡ğ‘›, with ğ‘¡ğ‘– âˆˆ
â‰œ {ğ‘¡ | ğ‘¡ âˆˆ
ğ‘’1
(cid:75)
(cid:75)
(cid:74)
â‰œ {ğœ–}
â‰œ {ğ‘¡ | ğ‘¡ âˆˆ
ğ‘2
ğ‘1
}
(cid:75)
(cid:74)
(cid:74)
(cid:75)
â‰œ {ğ‘¡ | ğ‘¡ = ğ‘¡1 Â· ğ‘¡2, with ğ‘¡1 âˆˆ
ğ‘1
(cid:75)
(cid:74)
â‰œ (cid:208)ğ‘– âˆˆğ¼ {ğ‘¡ | ğ‘¡ = ğœ‹ğ‘– Â· ğ‘¡ â€², with ğ‘¡ â€² âˆˆ
Table 3. Trace semantics of our regular properties.

and ğ‘¡2 âˆˆ
ğ‘ğ‘–
}
(cid:74)

and ğ‘¡ âˆˆ

ğ‘2
(cid:74)

(cid:75)

(cid:75)

}

â€¢ a local property of the form âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– is well formed if either ğœ‹ğ‘– .ğ‘ğ‘– = end.ğœ– or ğ‘ğ‘– is well formed,

for any ğ‘– âˆˆ ğ¼ ;

â€¢ a global property ğ‘âˆ— is well formed if ğ‘ is well-formed;
â€¢ a global property ğ‘’1 âˆ© ğ‘’2 is well-formed if both ğ‘’1 and ğ‘’2 are well-formed.

In the rest of the paper, we always assume to work with well-formed properties. Moreover, we

adopt the following notations and/or abbreviations on properties.

Notation 2. We omit trailing empty properties, writing ğœ‹ instead of ğœ‹ .ğœ–. For ğ‘˜ > 0, we write ğœ‹ğ‘˜ .ğ‘ as
a shorthand for ğœ‹ .ğœ‹ ...ğœ‹ .ğ‘, where prefix ğœ‹ appears ğ‘˜ consecutive times. Given a local property ğ‘ we write
events(ğ‘) âŠ† Events to denote the set of events occurring in ğ‘; similarly, we write events(ğ‘’) âŠ† Events
to denote the set of events occurring in a global property ğ‘’ âˆˆ PropG. Given a set of events A âŠ† Events
and a local property ğ‘, we use A itself as an abbreviation for the property âˆªğœ‹ âˆˆAğœ‹ .ğœ–, and A.ğ‘ as an
abbreviation for the property âˆªğœ‹ âˆˆAğœ‹ .ğ‘. Given a set of events A, with end âˆ‰ A, we write A â‰¤ğ‘˜ , for
ğ‘˜ â‰¥ 0, to denote the well-formed property defined as follows: (i) A â‰¤0 â‰œ end; (ii) A â‰¤ğ‘˜ â‰œ end âˆª A.A â‰¤ğ‘˜âˆ’1,
for ğ‘˜ > 0. Thus, the property A â‰¤ğ‘˜ captures all possible sequences of events of A whose length is at
most ğ‘˜, for ğ‘˜ âˆˆ N. We write PEvents to denote the set of pure events, i.e., Events \ {end}. Finally, we
write PUEvents to denote the set of pure untimed events, i.e., Events \ {end, tick}.

Note that our properties are in general nondeterministic. However, since we are interested in

deterministic enforcers, in the following we will focus on deterministic enforcing properties.

Definition 5 (Deterministic properties). A global property ğ‘’ âˆˆ PropG is said to be deter-

ministic if for any sub-term âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– appearing in ğ‘’, we have ğœ‹ğ‘˜ â‰  ğœ‹â„, for any ğ‘˜, â„ âˆˆ ğ¼ , ğ‘˜ â‰  â„.

5.1 Local properties
As already said, local properties describe execution traces which are limited to a finite number of scan
cycles. Let us present a number of significant local properties that can be expressed in our language
of regular properties. In the following, we assume a fixed maximum number of actions, maxa, that
may occur within a single scan cycle of our controllers, i.e., between two subsequent end-actions.

5.1.1 Basic properties. They prescribe conditional, eventual and persistent behaviours.

Conditional. These properties say that when a (pure) untimed event ğœ‹ occurs in the current scan
cycle then some property ğ‘ should be satisfied. More generally, for ğœ‹ğ‘– âˆˆ PUEvents and ğ‘ğ‘– âˆˆ PropL,
we write Case( âˆªğ‘– âˆˆğ¼ {(ğœ‹ğ‘–, ğ‘ğ‘– )}) to denote the property ğ‘ğ‘˜ , for ğ‘˜ = maxa, defined as follows:

â€¢ ğ‘ğ‘˜ â‰œ end âˆª (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– âˆª (PEvents\ (cid:208)ğ‘– âˆˆğ¼ {ğœ‹ğ‘– }).ğ‘ğ‘˜âˆ’1, for 0 < ğ‘˜ â‰¤ maxa
â€¢ ğ‘0 â‰œ end.
When there is only one triggering event ğœ‹ âˆˆ PUEvents and one associated local property
ğ‘ âˆˆ PropL, we have a simple conditional property defined as follow: Cnd(ğœ‹, p) â‰œ Case({(ğœ‹, ğ‘)}).

12

R. Lanotte, M. Merro, A. Munteanu

Fig. 5. A trace satisfying a persistent conditional property PCndm (ğœ‹, p).

Conditional properties Cnd(ğœ‹, p) define a cause-effect relation in which the triggering event
ğœ‹ is searched in the current scan cycle; one may think of a more general property PCndm (ğœ‹, p),
in which the cause-effect relation persists for ğ‘š > 0 consecutive scan cycles, i.e., the search for
the triggering event ğœ‹ continues for at most ğ‘š consecutive scan cycles. Of course, the triggered
local property ğ‘ may span over a finite number of scan cycles (see Figure 5). Formally, we write
PCndm (ğœ‹, p), for ğœ‹ âˆˆ PUEvents, ğ‘ âˆˆ PropL and ğ‘š > 0, for the property ğ‘ğ‘š
defined as follows:

maxa

maxa âˆª ğœ‹ .ğ‘ âˆª (PEvents\{ğœ‹ }).ğ‘â„

ğ‘˜âˆ’1

, for 1 < â„ â‰¤ ğ‘š and 0 < ğ‘˜ â‰¤ maxa

â‰œ end.ğ‘â„âˆ’1
â€¢ ğ‘â„
ğ‘˜
0 â‰œ end.ğ‘â„âˆ’1
â€¢ ğ‘â„
maxa
â€¢ ğ‘1
ğ‘˜
â€¢ ğ‘1
0 â‰œ ğœ–.

, for 1 < â„ â‰¤ ğ‘š

â‰œ end âˆª ğœ‹ .ğ‘ âˆª (PEvents\{ğœ‹ }).ğ‘1

, for 0 < ğ‘˜ â‰¤ maxa

ğ‘˜âˆ’1

Obviously, Cnd(ğœ‹, p) = PCnd1(ğœ‹, p).

Bounded eventually. In this case, an event ğœ‹ must eventually occur within ğ‘š scan cycles. Formally,

for ğœ‹ âˆˆ PUEvents and ğ‘š > 0, we write BEm (ğœ‹) to denote the property ğ‘ğ‘š
maxa âˆª ğœ‹ .PEventsâ‰¤ğ‘˜âˆ’1 âˆª (PEvents\{ğœ‹ }).ğ‘â„

ğ‘˜âˆ’1

maxa

, for 1 < â„ â‰¤ ğ‘š and 0 < ğ‘˜ â‰¤ maxa

defined as follows:

â‰œ end.ğ‘â„âˆ’1
â€¢ ğ‘â„
ğ‘˜
0 â‰œ end.ğ‘â„âˆ’1
â€¢ ğ‘â„
maxa
â€¢ ğ‘1
ğ‘˜
â€¢ ğ‘1
0 â‰œ ğœ‹ .end.

, for 1 < â„ â‰¤ ğ‘š
â‰œ ğœ‹ .PEventsâ‰¤ğ‘˜âˆ’1 âˆª (PEvents\{ğœ‹ }).ğ‘1

, for 0 < ğ‘˜ â‰¤ maxa

ğ‘˜âˆ’1

Bounded persistency. While in BEm (ğœ‹) the event ğœ‹ must eventually occur within ğ‘š scan cycles,
bounded persistency prescribes that an event ğœ‹ must occur in all subsequent ğ‘š scan cycles. Formally,
for ğœ‹ âˆˆ PUEvents and ğ‘š > 0, we write BPm (ğœ‹) to denote the property ğ‘ğ‘š

defined as follows:

maxa

â‰œ ğœ‹ .PEventsâ‰¤ğ‘˜âˆ’1; ğ‘â„âˆ’1

maxa âˆª (PEvents\{ğœ‹ }).ğ‘â„

ğ‘˜âˆ’1

, for 1 < â„ â‰¤ ğ‘š and 0 < ğ‘˜ â‰¤ maxa

â€¢ ğ‘â„
ğ‘˜
0 â‰œ ğœ‹ .end.ğ‘â„âˆ’1
â€¢ ğ‘â„
maxa
â€¢ ğ‘1
ğ‘˜
â€¢ ğ‘1
0 â‰œ ğœ‹ .end.

, for 1 < â„ â‰¤ ğ‘š

â‰œ ğœ‹ .PEventsâ‰¤ğ‘˜âˆ’1 âˆª (PEvents\{ğœ‹ }).ğ‘1

, for 0 < ğ‘˜ â‰¤ maxa

ğ‘˜âˆ’1

Bounded absence. The negative counterpart of bounded persistency is bounded absence. This
property says that an event ğœ‹ must not appear in all subsequent ğ‘š scan cycles. Formally, for ğœ‹ âˆˆ
PUEvents and ğ‘š > 0, we write BAm (ğœ‹) to denote the property ğ‘ğ‘š defined as follows:

â€¢ ğ‘â„ â‰œ (PEvents\{ğœ‹ }) â‰¤maxa; ğ‘â„âˆ’1, for 0 < â„ â‰¤ ğ‘š
â€¢ ğ‘0 â‰œ ğœ–.

5.1.2 Compound conditional properties. The properties above can be combined together to express
more detailed PLC behaviours. Let us see a few examples with the help of the use case of Section 4.

Conditional bounded eventually. According to this property, if a triggering event ğœ‹1 occurs then a
second event ğœ‹2 must eventually occur between the ğ‘š-th and the ğ‘›-th scan cycle, with 1 â‰¤ ğ‘š â‰¤ ğ‘›.
Formally, for ğœ‹1, ğœ‹2 âˆˆ PUEvents and 1 â‰¤ ğ‘š â‰¤ ğ‘›, we define CBE[m,n] (ğœ‹1, ğœ‹2) as follows:

CBE[m,n] (ğœ‹1, ğœ‹2) â‰œ Cnd(ğœ‹1 , (PEventsâ‰¤maxa)mâˆ’1; BEnâˆ’m+1 (ğœ‹2)).

Runtime Enforcement of PLCs

13

Intuitively, if the event ğœ‹1 occurs then the event ğœ‹2 must eventually occur between the scan cycles
ğ‘š and ğ‘›. In case we would wish that ğœ‹2 should not occur before the ğ‘š-th scan cycle, then the
property would become: Cnd(ğœ‹1 , BAmâˆ’1(ğœ‹2); BEnâˆ’m+1(ğœ‹2)).

As an example, we might enforce a conditional bounded eventually property in PLC1 of our use
case in Section 4 to prevent water overflow in the tank ğ‘‡2 due to a misuse of the valve connecting
the tanks ğ‘‡1 and ğ‘‡2. Assume that ğ‘§ âˆˆ N is the time (expressed in scan cycles) required to overflow
the tank ğ‘‡2 when the valve is open and the level of tank ğ‘‡2 is low. We might consider to enforce a
property of the form CBE[1,w ] (open_req, close), with ğ‘¤ << ğ‘§, saying that if PLC1 receives a request to
open the valve, then the valve will be eventually closed within at most ğ‘¤ scan cycles (including
the current one). This will ensure that if a water request coming from PLC2 is received by PLC1
then the valve controlling the flaw from ğ‘‡1 to ğ‘‡2 will remain open for at most ğ‘¤ scan cycles, with
ğ‘¤ << ğ‘§, preventing the overflow of ğ‘‡2.

Conditional bounded persistency. Another possibility is to combine conditional with bounded
persistency to prescribe that if a triggering event ğœ‹1 occurs then the event ğœ‹2 must occur in the ğ‘š-th
scan cycle and in all subsequent ğ‘› âˆ’ ğ‘š scan cycles, for 1 â‰¤ ğ‘š â‰¤ ğ‘›. Formally, for ğœ‹1, ğœ‹2 âˆˆ PUEvents
and 1 â‰¤ ğ‘š â‰¤ ğ‘›, we write CBP[m,n] (ğœ‹1, ğœ‹2) to denote the property defined as:

CBP[m,n] (ğœ‹1, ğœ‹2) â‰œ Cnd(ğœ‹1 , (PEventsâ‰¤maxa)mâˆ’1; BPnâˆ’m+1(ğœ‹2)).
As an example, we might enforce a conditional bounded persistency property in PLC3 of our use
case in Section 4 to prevent damages of pump3 due to lack of water in tank ğ‘‡3. Assume that ğ‘§ âˆˆ N
is the minimum time (in terms of scan cycles) required to fill ğ‘‡3, i.e., to pass from level ğ‘™3 to level
â„3, when pump3 is off. We might consider to enforce a property of the form CBP[1,z] (l3, off3), to
prescribe that if the tank reaches its low level (event ğ‘™3) then pump3 must remain off (event off3) for
ğ‘§ consecutive scan cycles. This will ensure enough water in tank ğ‘‡3 to prevent damages on pump3.
Notice that all previous properties have a single triggering event ğœ‹1; in order to deal with multiple

triggering events it is enough to replace the conditional operator with the case construct.

Conditional bounded absence (also called Absence timed [24]). Finally, we might consider to
combine conditional with bounded absence to formalise a property saying that if a triggering
event ğœ‹1 occurs then another event ğœ‹2 must not occur in the ğ‘š-th scan cycle and in all subsequent
ğ‘› âˆ’ ğ‘š scan cycles, with 1 â‰¤ ğ‘š â‰¤ ğ‘›. Formally, for ğœ‹1, ğœ‹2 âˆˆ PUEvents and 1 â‰¤ ğ‘š â‰¤ ğ‘›, we write
CBA[m,n] (ğœ‹1, ğœ‹2) to denote the property defined as follows:

CBA[m,n] (ğœ‹1, ğœ‹2) â‰œ Cnd(ğœ‹1, (PEventsâ‰¤maxa)mâˆ’1; BAnâˆ’m+1 (ğœ‹2)).
Intuitively, if the triggering event ğœ‹1 occurs then the event ğœ‹2 must not occur in the time interval
between the ğ‘š-th and the ğ‘›-th scan cycle.

As an example, we might enforce a conditional bounded absence property in PLC2 of our use
case in Section 4 to prevent water overflow in the tank ğ‘‡2 due to a misuse of the valve connecting
the tanks ğ‘‡1 and ğ‘‡2. Assume that ğ‘§ âˆˆ N is the time (expressed in scan cycles) required to empty
the tank ğ‘‡2 when the valve is closed and the tank ğ‘‡2 reaches its high level â„2. Then, we might
consider to enforce a property of the form CBA[1,w ] (h2, open_req), for ğ‘¤ < ğ‘§, to prescribe that if the
tank reaches its high level (event â„2) then PLC2 may not send a requests to open the valve (event
open_req) for the subsequent ğ‘¤ scan cycles. This ensures us that when ğ‘‡2 reaches its high level then
it will not ask for incoming water for at least ğ‘¤ scan cycles, so preventing tank overflow.

5.1.3 Compound persistent conditional properties. Now, we formalise in our language of regular
properties a number of correctness properties used by Frehse et al. for the verification of hybrid
systems [24]. More precisely, we formalise bounded versions of their properties.

14

R. Lanotte, M. Merro, A. Munteanu

Fig. 6. A trace satisfying a minimum duration property MinD(ğœ‹1, ğœ‹2, m, n), for ğ‘š = ğ‘› = 3.

Bounded minimum duration. When a triggering event ğœ‹1 occurs, if a second event ğœ‹2 occurs
within ğ‘š scan cycles then this event must appear in at least all subsequent ğ‘› scan cycles (see
Figure 6). Formally, we can express this property as follows:

MinD(ğœ‹1, ğœ‹2, m, n) â‰œ Cnd(ğœ‹1, PCndm (ğœ‹2, BPn (ğœ‹2))).

Note that the property MinD(ğœ‹1, ğœ‹2, m, n) is satisfied each time CBP[m,m+n] (ğœ‹1, ğœ‹2) is. The vice
versa does not hold as in CBP[m,m+n] (ğœ‹1, ğœ‹2) the event ğœ‹2 is required to occur in the whole time
interval [ğ‘š, ğ‘š+ğ‘›], while, according to MinD(ğœ‹1, ğœ‹2, m, n), the event ğœ‹2 might not occur at all.

Bounded maximum duration. When an event ğœ‹1 occurs, if a second event ğœ‹2 occurs within ğ‘š
scan cycles then the same event ğœ‹2 may occur in at most all subsequent ğ‘› scan cycles. Formally, we
can represent this property as follows:

MaxD(ğœ‹1, ğœ‹2, m, n) â‰œ Cnd(ğœ‹1, PCndm (ğœ‹2, (PEventsâ‰¤maxa)n; BA1 (ğœ‹2))).
The property MaxD(ğœ‹1, ğœ‹2, m, n) is satisfied each time the property CBP[m,m+n] (ğœ‹1, ğœ‹2); BA1 (ğœ‹2) is.
Again, the vice versa does not hold.

Bounded response. When an event ğœ‹1 occurs, if a second event ğœ‹2 occurs within ğ‘š scan cycles
then a third event ğœ‹3 appears within ğ‘› scan cycles. Formally, we can express this property as
follows:

BR(ğœ‹1, ğœ‹2, ğœ‹3, m, n) â‰œ Cnd(ğœ‹1, PCndm (ğœ‹2, BEn (ğœ‹3))).

Bounded invariance. Whenever an event ğœ‹1 occurs, if ğœ‹2 occurs within ğ‘š scan cycles then ğœ‹3 will

persistently occur for at least ğ‘› scan cycles. Formally, we can express this property as follows:

BI(ğœ‹1, ğœ‹2, ğœ‹3, m, n) â‰œ Cnd(ğœ‹1, PCndm (ğœ‹2, BPn (ğœ‹3))).

5.1.4 Bounded mutual exclusion. A different class of properties prescribes the possible occurrence
of events ğœ‹ğ‘– âˆˆ PEvents, for ğ‘– âˆˆ ğ¼ , in mutual exclusion within ğ‘š consecutive scan cycles. Formally,
for ğœ‹ğ‘– âˆˆ PUEvents, ğ‘– âˆˆ ğ¼ and ğ‘š â‰¥ 1, we write BMEm ( (cid:208)ğ‘– âˆˆğ¼ {ğœ‹ğ‘– } ), for the property ğ‘ğ‘š
defined as:

maxa

maxa âˆª (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .((cid:209)ğ‘— âˆˆğ¼ \{ğ‘– } BAh (ğœ‹j)) âˆª (PEvents\ (cid:208)ğ‘– âˆˆğ¼ {ğœ‹ğ‘– }).ğ‘â„

ğ‘˜âˆ’1

, for 1 < â„ â‰¤ ğ‘š and

, for 1 < â„ â‰¤ ğ‘š

â‰œ end âˆª (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .((cid:209)ğ‘— âˆˆğ¼ \{ğ‘– } BA1(ğœ‹j)) âˆª (PEvents\ (cid:208)ğ‘– âˆˆğ¼ {ğœ‹ğ‘– }).ğ‘1

, for 0 < ğ‘˜ â‰¤ maxa

ğ‘˜âˆ’1

â‰œ end.ğ‘â„âˆ’1
â€¢ ğ‘â„
ğ‘˜
0 < ğ‘˜ â‰¤ maxa
0 â‰œ end.ğ‘â„âˆ’1
â€¢ ğ‘â„
maxa
â€¢ ğ‘1
ğ‘˜
â€¢ ğ‘1
0 â‰œ ğœ–.

As an example, we might enforce a bounded mutual exclusion property in the PLC1 of our use case
of Section 4 to prevent chattering of the valve, i.e., rapid opening and closing which may cause
mechanical failures on the long run. In particular, we might consider to enforce a property of the
form BME3 ({open, close}) saying that within 3 consecutive scan cycles the opening and the closing
of the valve (events open and close, respectively) may only occur in mutual exclusion.

In Table 4, we summarise all local properties represented and discussed in this section.

Runtime Enforcement of PLCs

15

Case:
Persistent conditional:
Bounded eventually:
Bounded persistency:
Bounded absence:
Conditional bounded eventually:
Conditional bounded persistency:
Conditional bounded absence:
(Bounded) Minimum duration:
(Bounded) Maximum duration:
Bounded response:
Bounded invariance:
Bounded mutual exclusion

if ğœ‹ğ‘– occurs then ğ‘ğ‘– should be satisfied, for ğ‘– âˆˆ ğ¼
for ğ‘š scan cycles, if ğœ‹ occurs then ğ‘ should be satisfied
event ğœ‹ must eventually occur within ğ‘š scan cycles
event ğœ‹ must occur in all subsequent ğ‘š scan cycles
even ğœ‹ must not occur in all subsequent ğ‘š scan cycles
if ğœ‹1 occurs then ğœ‹2 must eventually occur in the scan cycles [ğ‘š, ğ‘›]
if ğœ‹1 occurs then ğœ‹2 must occur in all scan cycles of [ğ‘š, ğ‘›]
if ğœ‹1 occurs then ğœ‹2 must not occur in all scan cycles of [ğ‘š, ğ‘›]
when ğœ‹1, if ğœ‹2 in [1, ğ‘š] then ğœ‹2 persists for at least ğ‘› scan cycles
when ğœ‹1, if ğœ‹2 in [1, ğ‘š] then ğœ‹2 persists for at most ğ‘› scan cycles
when ğœ‹1, if ğœ‹2 in [1, ğ‘š] them ğœ‹3 appears within ğ‘› scan cycles
when ğœ‹1, if ğœ‹2 in [1, ğ‘š] then ğœ‹3 persists for at least ğ‘› scan cycles
events ğœ‹ğ‘– may only occur in mutual exclusion within ğ‘› scan cycles

Table 4. Overview of local properties.

Fig. 7. A trace satisfying the just mentioned property for some ğ‘š, ğ‘› = ğ‘š + 4 and ğ‘‘ = 4.

5.2 Global properties
As expected, the previously described local properties become global ones by applying the Kleene-
operator âˆ—. Once in this form, we can put these properties in conjunction between them. Here, we
show two global properties, the first one is built top of conditional bounded persistency properties
and the second one is built on top of a conditional bounded eventually property.

As a first example, we might consider a global property saying that whenever an event ğœ‹ occurs
then all events ğœ‹ğ‘– , for ğ‘– âˆˆ ğ¼ , must occur in the ğ‘š-th scan cycle and in all subsequent ğ‘› âˆ’ ğ‘š scan
cycles, for 1 â‰¤ ğ‘š â‰¤ ğ‘›. Formally, for ğœ‹, ğœ‹ğ‘– âˆˆ PUEvents, ğ‘– âˆˆ ğ¼ , and 1 â‰¤ ğ‘š â‰¤ ğ‘›: (cid:209)ğ‘– âˆˆğ¼ (CBP[m,n] (ğœ‹, ğœ‹i))âˆ—.
We might enforce this kind of property in PLC1 of our use case of Section 4. Assume ğ‘§ âˆˆ N
being the time (expressed in scan cycles) required to overflow the tank ğ‘‡1 when the level of
the tank ğ‘‡1 is low and both pumps are on and the valve is closed. Then, the property would be
(CBP[1,w ] (l1, on1))âˆ— âˆ© (CBP[1,w ] (l1, on2))âˆ—, with ğ‘¤ < ğ‘§, saying that if the tank ğ‘‡1 reaches its low level
(event ğ‘™1) then both pump1 and pump2 must be on (events on1 and on2) in all subsequent ğ‘¤ scan
cycles, starting from the current one.

As a second example, we might consider a more involved global property relying on conditional
bounded eventually, persistent conditional, and bounded persistency. Basically, the property says
that whenever an event ğœ‹1 occurs then a second event ğœ‹2 must eventually occur between the ğ‘š-th
scan cycle and the ğ‘›-th scan cycle, with 1 â‰¤ ğ‘š â‰¤ ğ‘›; moreover, it must occur for ğ‘‘ consecutive scan
cycles, for 1 â‰¤ ğ‘‘ (see Figure 7). Formally, the property is the following:

(cid:0)CBE[m,n] (ğœ‹1, ğœ‹2)(cid:1) âˆ— âˆ© (cid:0)Cnd(ğœ‹1, PCndn (ğœ‹2, PEventsâ‰¤maxa; BPdâˆ’1(ğœ‹2)))(cid:1) âˆ—
for ğœ‹1, ğœ‹2 âˆˆ PUEvents, with 1 â‰¤ ğ‘š â‰¤ ğ‘› and ğ‘‘ â‰¥ 1. Intuitively, the property (CBE[m,n] (ğœ‹1, ğœ‹2))âˆ—
requires that when ğœ‹1 occurs the event ğœ‹2 must eventually occur between the ğ‘š-th scan cycle and
the ğ‘›-th scan cycle. The remaining part of the property says if the event ğœ‹2 occurs within the ğ‘›-th
scan cycle (recall that ğ‘š â‰¤ ğ‘›) then it must persist for ğ‘‘ scan cycles.

16

R. Lanotte, M. Merro, A. Munteanu

In this manner, we might strengthen the conditional bounded eventually property given in
Section 5.1 for PLC1 of our use case to prevent water overflow in the tank ğ‘‡2. Let ğ‘§ âˆˆ N be the time
(expressed in scan cycles) required to overflow the tank ğ‘‡2 when the valve is open and the level of
tank ğ‘‡2 is low. The property is the following:

(cid:0)CBE[1,w ] (open_req, close)(cid:1)âˆ— âˆ© (cid:0)Cnd(open_req, PCndw (close, PEventsâ‰¤maxa; BPdâˆ’1 (close)))(cid:1)âˆ—

where ğ‘¤ << ğ‘§, and ğ‘‘ âˆˆ N is the time (expressed in scan cycles) required to release in ğ‘‡3 the
(maximum) quantity of water that the tank ğ‘‡2 may accumulate in ğ‘¤ scan cycles. The first part of
the property says that if PLC1 receives a request to open the valve (event open_req) then the valve
must be eventually closed (event close must eventually occur) within at most ğ‘¤ scan cycles. The
remaining part of the property says that when PLC1 receives a request to open the valve (event
open_req), if the valve gets closed (event close) within the ğ‘¤-th scan cycle, then it must remain closed
for the ğ‘‘ consecutive scan cycles. Here, ğ‘‘ depends both on the maximum level of water reachable
in ğ‘‡2 in ğ‘¤ scan cycles and on the physical law governing the water flow from ğ‘‡2 to ğ‘‡3.

6 MONITOR SYNTHESIS
In this section, we provide an algorithm to synthesise monitors from regular properties whose events
are contained in (the set of events associated to) a fixed set P of observable controller actions.
More precisely, given a global property ğ‘’ âˆˆ PropG the algorithm returns an edit automaton
âŸ¨| ğ‘’ |âŸ© P âˆˆ Edit that is capable to enforce the property ğ‘’ during the execution of a generic controller
whose possible actions are confined to those in P. The synthesis algorithm is defined in Table 5
by induction on the structure of the global/local property given in input; as we distinguish global
properties from local ones, we define our algorithm in two steps.

Remark 3. We recall that, according to the operational semantics defined in Table 1, all controller
actions ğ›¼ are observable and they basically coincide with the set Events used to build up the enforcing
properties defined in Section 5. As a consequence, we will synthesise enforcing monitors that may
observe any action of the controller under scrutiny and may act consequently.

X = âŸ¨| ğœ– |âŸ© P

is given by the automaton âŸ¨| ğ‘1 |âŸ© P
Z

The monitor âŸ¨| ğ‘âˆ— |âŸ© P associated to a global property ğ‘âˆ— is an edit automaton defined via the
recursive equation X = âŸ¨| ğ‘ |âŸ© P
, to recursively enforce the local property ğ‘. The monitor âŸ¨| ğ‘’1 âˆ© ğ‘’2 |âŸ© P
X
is given by the cross product between the edit automata âŸ¨| ğ‘’1 |âŸ© P and âŸ¨| ğ‘’2 |âŸ© P, to accept only
traces that satisfy both ğ‘’1 and ğ‘’2; the definition of the cross product between two edit automata
recalls that for finite state automata, and it is reported in the appendix in Table 6. The monitor
. The
and âŸ¨| ğ‘2 |âŸ© P
is given by the cross product between the edit automata âŸ¨| ğ‘1 |âŸ© P
âŸ¨| ğ‘1 âˆ© ğ‘2 |âŸ© P
X
X
X
; basically Z ties the
monitor âŸ¨| ğ‘1; ğ‘2 |âŸ© P
X
final states of the automaton enforcing ğ‘1 with the initial state of the automaton enforcing ğ‘2 (e.g.,
âŸ¨| ğœ–; ğ‘2 |âŸ© P
). The monitor associated to a union property âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘–
does the following: (i) allows all actions associated to the events ğœ‹ğ‘– , (ii) inserts an action associated
to some admissible event ğœ‹ğ‘– only when the controller wishes to prematurely complete the scan
cycle, i.e., it emits an end-action, and (iii) suppresses any other action except for tick- and end-actions.
Thus, the mitigation of the enforcement is actually implemented in the monitors synthesised
from union properties. In practise, when the controller under scrutiny complies with the property
enforced by the monitor, the two components, monitor and controller, evolve in a tethered fashion
(by applying rule (Allow)), moving through related correct states. However, if the controller gets
somehow corrupted (for instance, due to the presence of a malware) then the two components
will get misaligned reaching unrelated states. In this case, the enforcer mitigates the attack by
suppressing the remaining actions emitted by the controller (by applying rule (Suppress)) until the

Z = Z, for Z = âŸ¨| ğ‘2 |âŸ© P

, where Z = âŸ¨| ğ‘2 |âŸ© P
X

X

Runtime Enforcement of PLCs

17

âŸ¨| ğ‘âˆ— |âŸ© P â‰œ X, for X = âŸ¨| ğ‘ |âŸ© P
X

âŸ¨| ğ‘’1 âˆ© ğ‘’2 |âŸ© P â‰œ ProdP
X

(âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P ), X fresh

âŸ¨| ğœ– |âŸ© P
X
âŸ¨| ğ‘1 âˆ© ğ‘2 |âŸ© P
X
âŸ¨| ğ‘1; ğ‘2 |âŸ© P
X
âŸ¨| (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– |âŸ© P
X

â‰œ X
â‰œ ProdP
X
â‰œ âŸ¨| ğ‘1 |âŸ© P
Z
â‰œ Z, for
ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

Z =

(âŸ¨| ğ‘1 |âŸ© P
, âŸ¨| ğ‘2 |âŸ© P
)
X
X
, for Z = âŸ¨| ğ‘2 |âŸ© P
, Z fresh
X

ğœ‹ğ‘– â‰º end.âŸ¨| ğ‘ğ‘– |âŸ© P
X

ğœ‹ğ‘– .âŸ¨| ğ‘ğ‘– |âŸ© P
X
ğœ‹ğ‘– .âŸ¨| ğ‘ğ‘– |âŸ© P
X

(cid:205)
ğ‘–âˆˆğ¼
(cid:205)
ğ‘–âˆˆğ¼
where Q = P\(âˆªğ‘–âˆˆğ¼ ğœ‹ğ‘– âˆª{tick,end})

+ (cid:205)
ğ‘–âˆˆğ¼
+ (cid:205)
ğ›¼ âˆˆQ

âˆ’ğ›¼ .Z, otherwise

+ (cid:205)
ğ›¼ âˆˆQ

âˆ’ğ›¼ .Z, if end âˆ‰ âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘–

Table 5. Monitor synthesis from properties in PropG and PropL.

controller reaches the end of the scan cycle, signalled by the emission of the end-action1. After that,
if monitor and controller are not aligned the monitor will command the insertion of a safe trace,
without any involvement of the controller, via one or more applications of the rule (Insert). Safe
traces inserted in full autonomy by our enforcers always terminate with an end. Thus, when both
the controller and the monitor will be aligned, at the end of the scan cycle, they will synchronise
on the action end, via an application of the rule (Allow), and from then on they may continue in a
tethered fashion.

Remark 4. Note that even whe the controller is completely unreliable and the monitor inserts an
entire safe trace, the assumption made in Remark 1 ensures us that the enforced scan cycle always
ends well before a violation of the maximum cycle limit.

Now, we calculate the complexity of the synthesis algorithm based on the number of occurrences
of the operator âˆ© in ğ‘’ and the dimension of ğ‘’, dim(ğ‘’), i.e., the number of all operators occurring in
ğ‘’. Intuitively, the size of a property is given by the number of operators occurring in it.

Definition 6. Let dim() : PropG âˆª PropL â†’ N be a property-size function defined as:

dim(ğ‘âˆ—)
dim(ğœ–)
dim(ğ‘1 âˆ© ğ‘2) â‰œ dim(ğ‘1) + dim(ğ‘2) + 1

â‰œ dim(ğ‘) + 1
â‰œ 1

dim(ğ‘’1 âˆ© ğ‘’2)
dim(ğ‘1; ğ‘2)
dim((cid:208)ğ‘– âˆˆğ¼ ğ›¼ğ‘– .ğ‘ğ‘– ) â‰œ | ğ¼ | + (cid:205)ğ‘– âˆˆğ¼ dim(ğ‘ğ‘– ).

â‰œ dim(ğ‘’1) + dim(ğ‘’2) + 1
â‰œ dim(ğ‘1) + dim(ğ‘2) + 1

Proposition 1 (Complexity). Let ğ‘’ âˆˆ PropG be a global property and P be a set of actions
such that events(ğ‘’) âŠ† P. The complexity of the algorithm to synthesise âŸ¨| ğ‘’ |âŸ© P is O (|P | Â· ğ‘šğ‘˜+1), with
ğ‘š = dim(ğ‘’) and ğ‘˜ being the number of occurrences of the operator âˆ© in ğ‘’.

In the following, we prove that the enforcement induced by our synthesised monitors enjoys the
properties stated in the Introduction: determinism preservation, transparency, soundness, deadlock-
freedom, divergence-freedom, and scalability. In this section, with a small abuse of notation, given a
set of observable actions P, we will use P to denote also the set of the corresponding events.

Given a deterministic global property ğ‘’, our synthesis algorithm returns a deterministic enforcer

(according to Definition 2), i.e., an enforcer that can be effectively implemented. Formally,

Proposition 2 (Deterministic preservation). Given a deterministic global property ğ‘’ âˆˆ

PropG over a set of events P. The edit automaton âŸ¨| ğ‘’ |âŸ© P is deterministic.
1As said in Section2, a malware that aims to take control of the plant has no interest in delaying the scan cycle and risking
the violation of the maximum cycle limit whose consequence would be the immediate shutdown of the controller [59].

18

R. Lanotte, M. Merro, A. Munteanu

Let us move to transparency. Intuitively, the enforcement induced by a deterministic property
ğ‘’ âˆˆ PropG should preserve any execution trace satisfying ğ‘’ itself (Definition 2 at pag. 5 of [40]).

Theorem 1 (Transparency). Let ğ‘’ âˆˆ PropG be a deterministic global property, P be a set of
observable actions such that events(ğ‘’) âŠ† P, and ğ‘ƒ âˆˆ Ctrl be a controller. Let ğ‘¡ = ğ›¼1 Â· Â· Â· ğ›¼ğ‘› be a trace
of the controller ğ‘ƒ with ğ‘¡ âˆˆ
. Then, (1) ğ‘¡ is a trace of the edit automaton âŸ¨| ğ‘’ |âŸ© P, and (2) there is no
trace ğ‘¡ â€² = ğ›¼1 Â· Â· Â· ğ›¼ğ‘˜ Â· ğœ† for âŸ¨| ğ‘’ |âŸ© P such that 0 â‰¤ ğ‘˜ < ğ‘› and ğœ† âˆˆ {âˆ’ğ›¼ğ‘˜+1, ğ›¼ â‰º ğ›¼ğ‘˜+1}, for some ğ›¼.

ğ‘’
(cid:74)

(cid:75)

Basically, conclusion (1) says that all execution trace ğ‘¡ (of a controller ğ‘ƒ) satisfying the enforcing
property ğ‘’ are allowed by the associated enforcer âŸ¨| ğ‘’ |âŸ© P, while conclusion (2) says that allowing the
trace ğ‘¡ is the only possible option in the enforcement (this follows by the determinism of ğ‘’).

Another important property of our enforcement is soundness [40]. Intuitively, a controller under
the scrutiny of a monitor âŸ¨| ğ‘’ |âŸ© P should only yield execution traces which satisfy the enforced
property ğ‘’, i.e., execution traces which are consistent with its semantics

(up to ğœ-actions).

Theorem 2 (Soundness). Let ğ‘’ âˆˆ PropG be a global property, P be a set of observable actions
such that events(ğ‘’) âŠ† P, and ğ‘ƒ âˆˆ Ctrl be a controller. If ğ‘¡ is a trace of the monitored controller
âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ } then Ë†ğ‘¡ is a prefix of some trace in

(see Notation 1 for the definition of the trace Ë†ğ‘¡).

Here, it is important to stress that in general soundness does not ensure deadlock-freedom of the
monitored controller. That is, it may be possible that the enforcement of some property ğ‘’ causes a
deadlock of the controller ğ‘ƒ under scrutiny. In particular, this may happen in our controllers only
when the initial sleeping phase does not match the enforcing property (e.g., ğ‘ƒ = tick.ğ‘.end.ğ‘ƒ and
ğ‘’ = (ğ‘.end)âˆ—). Intuitively, a local property will be called a ğ‘˜-sleeping property if it allows ğ‘˜ initial
time instants of sleep. Formally,

ğ‘’
(cid:74)

(cid:75)

ğ‘’
(cid:74)

(cid:75)

Definition 7. For ğ‘˜ âˆˆ N+, we say that ğ‘ âˆˆ PropL is a ğ‘˜-sleeping local property, only if
ğ‘˜ Â·ğ‘¡ â€²
ğ‘– , and 1 â‰¤ ğ‘– â‰¤ ğ‘›}. We say that ğ‘âˆ— is a
ğ‘
(cid:74)
ğ‘˜-sleeping global property only if ğ‘ is, and ğ‘’ = ğ‘’1 âˆ© ğ‘’2 is ğ‘˜-sleeping only if both ğ‘’1, ğ‘’2 are ğ‘˜-sleeping.

= {ğ‘¡ | ğ‘¡ = ğ‘¡1 Â· ... Â· ğ‘¡ğ‘›, for ğ‘› > 0, s.t. ğ‘¡ğ‘– = tick

ğ‘– Â·end, end âˆ‰ ğ‘¡ â€²

(cid:75)

The enforcement of ğ‘˜-sleeping properties does not introduce deadlocks in ğ‘˜-sleeping controllers.
This is because our synthesised monitors suppress all incorrect actions of the controller under
scrutiny, driving it to the end of its scan cycle. Then, the controller remains in stand-by while the
monitor yields a safe sequence of actions to mimic a safe completion of the current scan cycle.

Theorem 3 (Deadlock-freedom). Let ğ‘’ âˆˆ PropG be a ğ‘˜-sleeping global property, and P be a
ğ‘˜ .ğ‘†

set of observable actions such that events(ğ‘’) âŠ† P. Let ğ‘ƒ âˆˆ Ctrl be a controller of the form ğ‘ƒ = tick
whose set of observable actions is contained in P. Then, âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ } does not deadlock.

Another important property of our enforcement mechanism is divergence-freedom. In practice, the
enforcement does not introduce divergence: monitored controllers will always be able to complete
their scan cycles by executing a finite number of actions. This is because we limit our enforcement
to well-formed properties (Definition 4) which always terminates with an end event. In particular,
the well-formedness of local properties ensures us that in a global property of the form ğ‘âˆ— the
number of events within two subsequent end events is always finite.

Theorem 4 (Divergence-freedom). Let ğ‘’ âˆˆ PropG be a global property, P be a set of observable
actions such that events(ğ‘’) âŠ† P, and ğ‘ƒ âˆˆ Ctrl be a controller. Then, there exists a ğ‘˜ âˆˆ N+ such that
whenever âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ }

ğ‘¡ â€²
âˆ’âˆ’âˆ’â†’ Eâ€² âŠ²âŠ³ {ğ½ â€²}, with | ğ‘¡ â€² |â‰¥ ğ‘˜, then end âˆˆ ğ‘¡ â€².

ğ‘¡
âˆ’âˆ’â†’ E âŠ²âŠ³ {ğ½ }, if E âŠ²âŠ³ {ğ½ }

Notice that all properties seen up to now scale to field communications networks of controllers.
This means that they are preserved when the controller under scrutiny is running in parallel with
other controllers in the same field communications network. As an example, by an application

Runtime Enforcement of PLCs

19

Fig. 8. Some physical components of our implementation.

of Theorems 1 and 2, we show how both transparency and soundness scale to field networks. A
similar result applies to the remaining properties.

Corollary 1 (Scalability to networks of PLCs). Let ğ‘’ âˆˆ PropG be a global property and P
be a set of observable actions, such that events(ğ‘’) âŠ† P. Let ğ‘ƒ âˆˆ Ctrl be a controller and ğ‘ âˆˆ FNet
be a field network. If (âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ }) âˆ¥ ğ‘
ğ‘¡ â€²
âˆ’âˆ’âˆ’â†’ ğ½ , with ğ‘¡ â€² = ğ›¼1 Â· Â· Â· ğ›¼ğ‘› âˆˆ

, the trace ğ‘¡ â€² is a trace of âŸ¨| ğ‘’ |âŸ© P and there is no trace
ğ‘’
(cid:75)
(cid:74)
ğ‘¡ â€²â€² = ğ›¼1 Â· Â· Â· ğ›¼ğ‘˜ Â· ğœ† of âŸ¨| ğ‘’ |âŸ© P such that 0 â‰¤ ğ‘˜ < ğ‘› and ğœ† âˆˆ {âˆ’ğ›¼ğ‘˜+1, ğ›¼ â‰º ğ›¼ğ‘˜+1}, for some ğ›¼;

ğ‘¡
âˆ’âˆ’âˆ’â†’ (E âŠ²âŠ³ {ğ½ }) âˆ¥ ğ‘ â€², for some ğ‘¡, E, ğ½ and ğ‘ â€², then

â€¢ whenever ğ‘ƒ

â€¢ whenever âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ }

ğ‘¡ â€²
âˆ’âˆ’âˆ’â†’ E âŠ²âŠ³ {ğ½ } the trace (cid:98)ğ‘¡ â€² is a prefix of some trace in

.

ğ‘’
(cid:74)

(cid:75)

7 OUR ENFORCEMENT MECHANISM AT WORK
In this section, we propose an implementation of our enforcement mechanism in which monitors,
running on field-programmable gate arrays (FPGAs) [61], enforce open source PLCs [8], running on
Raspberry Pi devices [25], and governing a physical plant simulated in Simulink [44]. The section has
the following structure. In Section 7.1, we argue why FPGAs are good candidates for implementing
secure proxies. In Section 7.2, we describe how we implemented the whole enforcement architecture
for the use case of Section 4. In Section 7.3, we test our implementation injecting the enforced PLCs
with five different malware aiming at causing three different physical perturbations: tank overflow,
valve damage, and pump damage. The attacks have been chosen to cover as much as possible the
attacker model of Section 2. In particular, they include: a drop of the actuator commands of the
valve, an integrity attack on the water-level sensors, a forgery of the actuator commands of the
valve, a forgery of the message requests to open/close the valve, and a forgery of the actuator
commands of the pumps. Section 7.4 discusses the performance of our implementation.

7.1 FPGAs as secure proxies for ICSs
Field-programmable gate arrays (FPGAs) are semiconductor devices that can be programmed to
run specific applications. An FPGA consists of (configurational) logic blocks, routing channels and
I/O blocks. The logic blocks can be configured to perform complex combinational functions and are
further made up of transistor pairs, logic gates, lookup tables and multiplexers. The applications
are written using hardware description languages, such as Verilog [60]. Thus, in order to execute
an application on the FPGA, its Verilog code is converted into a sequence of bits, called bitstream,
that is loaded into the FPGA.

FPGA are assumed to be secure when the adversary does not have physical access to the device, i.e.,
the bitstream cannot be compromised [32]. Recent FPGAs support remote updates of the bitstream
by relying on authentication mechanisms to prevent unauthorised uploads of malicious logic [32].

20

R. Lanotte, M. Merro, A. Munteanu

Fig. 9. An implementation in Simulink of the plant of the SWaT system.

Nevertheless, as said in the Introduction and advocated by McLaughlin and Mohan [45, 46], any
form of runtime reconfiguration should be prevented. Summarising, under the assumption that the
adversary does not have physical access to the FPGA and she cannot do remote updates, FPGAs
represent a good candidate for the implementation of secure enforcing proxies.

7.2 An implementation of the enforcement of the SWaT system of Section 4
The proposed implementation adopts different approaches for plant, controllers and enforcers.

Plant. The plant of the SWaT system is simulated in Simulink [44], a framework to model,
simulate and analyse cyber-physical systems, widely adopted in industry and research. A Simulink
model is given by blocks interconnected via wires. Our Simulink model contains blocks to simulate
water tanks, actuators (i.e., pumps and valves) and sensors (see Figure 9). In particular, water-tank
blocks implement the differential equations that model the dynamics of the tanks according to
the physical constraints obtained from [27, 43]. Actuation blocks receive commands from PLCs,
whereas sensor blocks send measurements to PLCs. For simplicity, state changes of both pumps
and valves do not occur instantaneously; they take 1 second. We ran our Simulink model on a
laptop with 2.8 GHz Intel i7 7700 HQ, 16GB memory, and Linux Ubuntu 20.04 LTS OS.

Controllers. Controllers are defined in OpenPLC [8], an open source PLC capable of running user
programs in all five IEC61131-3 defined languages [1]. Additionally, OpenPLC supports standard
SCADA protocols, such as Modbus/TCP, DNP3 and Ethernet/IP. OpenPLC can run on a variety of
hardware, from a simple Raspberry Pi to robust industrial boards. We installed OpenPLC on three
Raspberry Pi 4 [55]; each instance runs one of the three ladder logics seen in Figure 4.

Enforcers. Enforcers are implemented using three NetFPGA-CML development boards [63]. Our
synthesis algorithm is implemented in Python to return enforcers written in Verilog, and checked
for correctness using ModelSim. The Verilog code is then compiled into a bitstream and executed
in the FPGA. More precisely, our algorithm in Python takes as input a JSON file containing the
property to be synthesised and other relevant informations, such as the number of input/output
signals and a fixed priority among admissible safe output signals. Then, the property is parsed by
means of the ANTLR parser [48]. After the parsing, our algorithm implements the synthesis of
Table 5 to derive the enforcing edit automaton; this is written down into a JSON file. At this stage,
the derived edit automaton is still somewhat abstract, as both end- and tick-actions are explicitly
represented. Finally, the algorithm compiles the edit automaton into an enforcer written in Verilog,
where the above abstractions are implemented. In particular, the passage of time (i.e., tick-actions)
is represented and monitored via clock variables, while the end of scan cycles (i.e., end-actions) is
implemented via specific code to synchronise enforcers and controllers, relying on clock variables.
Thus, before each scan cycle the enforcer forwards the current inputs (coming from the plant) to
the controller. Then, when the scan cycle is completed, it receives from the controller all the current

pump1pump2valveleveloutTank	1inleveloutTank	2inpumpleveloutTank	3indirty	waterclean	water	Water	filterClean	waterpump1pump2valveActuators	tank	1levelSensor	tank	1levelSensor	tank	2levelSensor	tank	3pumpActuator	tank	3Runtime Enforcement of PLCs

21

Fig. 10. Tank overflow: Ladder Logic of the first (left) and the second attack (right).

outputs, and forwards them to the actuators. In the meanwhile, the enforcer monitors the passage
of time via its clock variables, and when the scan cycle is completed (i.e., the controller sends all
outputs) it moves to the state corresponding to the following scan cycle. Finally, in our FPGAs we
also write some code to implement an UDP-based network connecting together enforcers, PLCs,
and the simulated plant.

The code of the three PLCs, the algorithm in Python, the enforcers written in Verilog, and the

Simulink simulations can be found at: https://bitbucket.org/formal_projects/runtime_enforcement.

7.3 The enforced SWaT system under attack
In this section, we consider five different attacks targeting the PLCs of the SWaT system to achieve
three possible malicious goals: (i) overflow the water tanks, (ii) damage of the valve, (iii) damage
of the pumps. In order to simulate the injection of malware in the PLCs, we reinstall the original
PLC ladder logics with compromised ones, containing some additional logic intended to disrupt
the normal operations of the PLC [28]. In the following, we will discuss these attacks, grouped by
goals, showing how the enforcement of specific properties mitigates the attacks by preserving the
correct behaviour of the monitored PLCs.

Tank overflow. Our first attack is a DoS attack targeting PLC1 by dropping the commands to close
the valve. In the left-hand side of Figure 10 we show a possible implementation of this attack in
ladder logic. Basically, the malware remains silent for 500 seconds and then it sets true a malicious
drop variable (highlighted in yellow). Once the variable drop becomes true, the valve variable is
forced to be false (highlighted in red), thus preventing the closure of the valve.

In order to prevent attacks aiming at overflowing the tanks, we propose the following three

enforcing properties, one for each PLC, respectively:

â€¢ ğ‘’1 â‰œ (CBP[1,m] (h1, off1))âˆ— âˆ© (CBP[1,m] (h1, off2))âˆ—, an intersection between two conditional
bounded persistency properties to enforce PLC1 to prevent water overflow in ğ‘‡1. This property
ensures that both pumps pump1 and pump2 are off, for ğ‘š consecutive scan cycles, when the
level of ğ‘‡1 is high (measurement â„1). Here, ğ‘š < ğ‘› for ğ‘› âˆˆ N is the number of scan cycles
required to empty ğ‘‡1 when its level is high, both pumps are off, and the valve is open.

â€¢ ğ‘’2 â‰œ (CBP[1,u] (h2, close_req))âˆ—, a conditional bounded persistency property for PLC2 ensuring
that requests to close the valve (event close_req) are sent for ğ‘¢ consecutive scan cycles when
the level of water in tank ğ‘‡2 is high (measurement â„2). Here, ğ‘¢ < ğ‘£ for ğ‘£ âˆˆ N is the number of
scan cycles required to empty the tank ğ‘‡2 when the level is high and the valve is closed.
â€¢ ğ‘’3 â‰œ (CBP[1,w ] (h3, on3))âˆ—, a conditional bounded persistency property for PLC3 to ensure
that pump3 is on for ğ‘¤ consecutive scan cycles when the level of water in tank ğ‘‡3 is high

22

R. Lanotte, M. Merro, A. Munteanu

Fig. 11. Tank overflow: DoS attack on PLC1 when enforcing ğ‘’1, ğ‘’2, ğ‘’3 (up) and ğ‘’ â€²

1, ğ‘’2, ğ‘’3 (down).

(measurement â„3). Here, ğ‘¤ < ğ‘§ for ğ‘§ âˆˆ N is the time (expressed in scan cycles) required to
empty the tank ğ‘‡3 when the level is high and pump3 is on.

Now, let us analyse the effectiveness of the enforcement induced by these three properties. For
instance, in the upper graphs of Figure 11 we report the impact on the tanks ğ‘‡1 and ğ‘‡2 of the DoS
attack previously described, when enforcing the three properties ğ‘’1, ğ‘’2 and ğ‘’3 in the corresponding
PLCs. Here, the red region denotes when the attack becomes active. As the reader may notice,
despite repeated requests to close the valve coming from PLC2, the compromised PLC1 never closes
the valve causing the overflow of tank ğ‘‡2. So, the enforced property ğ‘’1 is not up the task.

In order to prevent this attack, we must guarantee that PLC1 closes the valve when PLC2
requests so. Thus, we should enforce in PLC1 a more demanding property ğ‘’ â€²
1 defined as follows:
ğ‘’1 âˆ© CBE[1,1] (close_req, close). Basically, the last part of the property ensures that every request to
close the valve is followed by an actual closure of the valve in the same scan cycle. The impact of
the malware on PLC1 when enforcing the properties ğ‘’ â€²
1, ğ‘’2, ğ‘’3 is represented in the lower graphs of
Figure 11. Now, the correct behaviour of PLC1 is ensured, thus preventing the overflowing of the
water tank ğ‘‡2. In these graphs, the green highlighted regions denote when the monitor detects the
attack and mitigates the activities of the compromised PLC1. In particular, the monitor inserts the
commands to close the valve on behalf of PLC1 when PLC2 sends requests to close the valve.

Having strengthened the enforcing property for PLC1 one may think that the enforcement of ğ‘’2
in PLC2 is now superfluous to prevent water overflow in ğ‘‡2. However, this is not the case if the
attacker can compromise PLC2. Consider a second attack to PLC2, an integrity attack that adds an
offset of âˆ’30 to the measured water level of ğ‘‡2. We show a ladder logic implementation of such
attack in the right-hand side of Figure 10 where, for simplicity, we omit the initial silent phases
lasting 500 seconds. The impact on the tanks ğ‘‡1 and ğ‘‡2 of the malware injected in PLC2 in the
presence of the enforcing of the properties ğ‘’ â€²
1 and ğ‘’3, respectively, is represented on the upper
graphs of Figure 12. Again, the red region shows when the attack becomes active. As the reader
may notice, the compromised PLC2 never sends requests to close the valve causing the overflow
1, ğ‘’2, ğ‘’3 in the three
of the water tank ğ‘‡2. On the other hand, when enforcing the three properties ğ‘’ â€²

Runtime Enforcement of PLCs

23

Fig. 12. Tank overflow: integrity attack on PLC2 when enforcing ğ‘’ â€²

1, ğ‘’3 (up) and ğ‘’ â€²

1, ğ‘’2, ğ‘’3 (down).

Fig. 13. Valve damage: Ladder logic of the first (left) and the second attack (right).

PLCs, the lower graphs of Figure 12 shows that the overflow of tank ğ‘‡2 is prevented. Again, the
green highlighted regions denote when the monitor detects the attack and mitigates the commands
of the compromised PLC2. Here, the monitor inserts the request to close the valve on behalf of PLC2
when ğ‘‡2 reaches a high level.

Valve damage. We now consider attacks whose goal is to damage the valve via chattering, i.e.,
rapid alternation of openings and closings of the valve that may cause mechanical failures on the
long run. In the left-hand side of Figure 13 we show a possible ladder logic implementation of a
third attack that does injection of the commands to open and close the valve. In particular, the attack
repeatedly alternates a stand-by phase, lasting 70 seconds, and a injection phase, lasting 30 seconds
(yellow region); then, in the injection phase the valve is opened and closed rapidly (red region).
With no enforcement, the impact of the attack on the tanks ğ‘‡1 and ğ‘‡2 is represented on the upper
graphs of Figure 14, where the red region denotes when the attack becomes active. From the graph

24

R. Lanotte, M. Merro, A. Munteanu

Fig. 14. Valve damage: injection attack on PLC1 in the absence (up) and in the presence (down) of enforcement.

associated to the execution of ğ‘‡1 the reader can easily see that the valve is chattering. Note that
this is a stealthy attack as the water level of ğ‘‡2 is maintained within the normal operation bounds.
In order to prevent this kind of attacks, we might consider to enforce in PLC1 a bounded mutual
1 â‰œ (BME10000 {open, close})âˆ— to ensure that within 10000 consecutive
exclusion property of the form ğ‘’ â€²â€²
scan cycles (10 seconds) openings and the closings of the valve may only occur in mutual exclusion.
1 is enforced in PLC1, the lower graphs of Figure 14 shows that the chattering
When the property ğ‘’ â€²â€²
of the valve is prevented. In particular, the green highlighted regions denote when the monitor
detects the attack and mitigates the commands on the valves of the compromised PLC1.

A fourth attack with the same goal of chattering the valve may be launched on PLC2, by sending
rapidly alternating requests to open and close the valve. This can be achieved by means of an
integrity attack on the sensor of the tank ğ‘‡2 by rapidly switching the measurements between low
and high. In the right-hand side of Figure 13 we show parts of the ladder logic implementation of
this attack on PLC2, where, for simplicity, we omit the machinery for dealing with the alternation
of phases. Again, the attack repeatedly alternates between a stand-by phase, lasting 70 seconds, and
a active phase, lasting 30 seconds. When the attack is in the active phase (red region) the measured
water level of ğ‘‡2 rapidly switches between low and high, thus, sending requests to PLC1 to rapidly
open and close the valve in alternation.

The impact of this attack targeting on PLC2 in the absence of an enforcing monitor is represented
in the upper graphs of Figure 15, where the red region shows when the attack becomes active.
Notice that the rapid alternating requests originating from PLC2 cause a chattering of the valve.
On the other hand, with the enforcement of the property ğ‘’ â€²â€²
1 in PLC1 , the lower graph of Figure 15
shows that the correct behaviour of tanks ğ‘‡1 and ğ‘‡2 is ensured. In that figure, the green highlighted
regions denote when the enforcer of PLC1 detects the attack and mitigates the commands (on the
valve) of the compromised PLC2. Notice that in this case no enforcement is required in PLC2.

Pump damage. Finally, we consider attacks whose goal is the damage of the pumps, and in
particular pump3. In that case, an attacker may force the pump to start when the water tank ğ‘‡3 is

Runtime Enforcement of PLCs

25

Fig. 15. Valve damage: integrity attack on PLC2 in the absence (up) and in the presence (down) of enforcement.

empty. This can be done with a fifth attack that injects commands to turn on the pump based on a
ladder logic implementation similar to that seen in Figure 10. The impact of this attack to tank ğ‘‡3
in the absence of enforcement is represented on the left-hand side graphs of Figure 16, where the
red region shows when the attack becomes active. As the reader may notice, pump3 is turned on
when ğ‘‡3 is empty.

Now, we can prevent damage on pump3 by enforcing on PLC3 the following conditional bounded
3 â‰œ (CBP[1,w ] (l3, off3))âˆ—. The enforcement of this property ensures that pump3
persistent property: ğ‘’ â€²
is off for ğ‘¤ consecutive scan cycles when the level of water in tank ğ‘‡3 is low, for ğ‘¤ < ğ‘§ and ğ‘§ âˆˆ N
being the time (expressed in scan cycles) required fill up tank ğ‘‡3 when the pump is off. Thus, when
the enforcement of the ğ‘’ â€²
3 is active, the lower graphs of Figure 16 shows that the correct behaviour
of ğ‘‡3 is ensured, thus preventing pump damage. In that figure, the green highlighted regions denote
when the monitor detects the attack and mitigates the commands (of the pumps) of the compromised
PLC3. More precisely, the enforcer suppresses the commands to turn on the pump when the tank is
empty, for ğ‘¤ consecutive scan cycles.

7.4 Discussion
In this section, we rely on the Vivado Design Suite 15.2 analysis tool to do a performance analysis
of our implementation.

As to the hardware resources used by our FPGAs, we measured them in terms of lookup tables
and registers used during the enforcement. The number of them depends on the number of states
of the enforcers implemented in the FPGAs. And this number is proportional to the number of scan
cycles involved in the enforced (local) property. In particular, for each scan cycle, the number ğ‘˜ of
states of the enforcer depends on the monitored input/output signals and their admissible values.
For instance, for scan cycles taking 10 ms (0.1kHz), an enforced local property lasting 10 seconds
will cover 1000 consecutive scan cycles, and the synthesised enforcer would have ğ‘˜ âˆ— 1000 states. In
our experiments, when enforcing properties covering 1000 scan cycles the hardware resource use
reaches 5%; for 10000 scan cycles the resource use rises to 13%.

26

R. Lanotte, M. Merro, A. Munteanu

Fig. 16. Pump damage: injection attack on PLC3 in the absence (up) and in the presence (down) of enforcement.

As for the execution speed of the enforcement, in general all FPGAs are capable of running at a
speed of 100 MHz (or higher). The actual execution speed depends on the complexity of the underly-
ing code, in our case the enforcer, plus some extra code to implement the network communication
protocol (UDP). In our experiments, FPGAs ran with a frequency of 1 MHz while PLCs ran with a
frequency of 0.1-1kHz. Thus, the overhead introduced by the FPGAs is negligible, independently
on the size (the number of states) of the enforcer implemented in the FPGAs. We recall that in
Remark 1 we assumed that our enforced controllers successfully complete their scan cycle in less
than half of the maximum cycle limit (just in case the scan cycle should be entirely corrected by
the enforcer). However, using FPGAs as enforcers this constraint can be actually relaxed.

Finally, concerning the communication latency between enforcers, many FPGAs support high
speed and low latency communications, which are the ones used in industrial control contexts [47].
We used FPGAs with Ethernet ports supporting 1 Gbps speed, i.e., with 100 microseconds latency.
Furthermore, thanks to our result of scalability (Corollary 1), a network of enforcing FPGAs
introduces a negligible overhead in terms of communication latency and hardware resources.

8 RELATED WORK
The notion of runtime enforcement was introduced by Schneider [56] to enforce security policies via
truncation automata, a kind of automata that terminates the monitored system in case of violation
of the property. Thus, truncation automata can only enforce safety properties. Furthermore, the
resulting enforcement may obviously lead to deadlock (actually termination) of the monitored
system with no room for mitigation.

Ligatti et al. [40] extended Schneiderâ€™s work by proposing the notion of edit automata, i.e., an
enforcement mechanism able of replacing, suppressing and inserting system actions. Edit automata
are capable of enforcing instances of safety and liveness properties, along with other properties such
as renewal properties [12, 40]. In general, Ligatti et al.â€™s edit automata are deterministic automata
with an enumerable number of states, whereas in the current paper we restrict ourselves to finite-
state edit automata equipped with Martinelli and Matteucciâ€™s operational semantics [42]. Ligatti
et al. [40] studied a hierarchy of enforcement mechanisms, each with different transformational
capabilities: Schneiderâ€™s truncation automata, suppression automata, insertion automata, and finally,
edit automata that combine the power of suppression and insertion automata. They defined different
notions of enforcement, and in particular the so called precise enforcement (Definition 2, pag. 5)
which basically corresponds to the combination of our notion of transparency and soundness,
proved in Theorems 1 and 2, respectively.

Bielova and Massacci [12, 13] provided a stronger notion of enforceability by introducing a
predictability criterion to prevent monitors from transforming invalid executions in an arbitrary
manner. Intuitively, a monitor is said predictable if one can predict the number of transformations

Runtime Enforcement of PLCs

27

used to correct invalid executions. In our setting, in case of injection of a malware which may act
in an unpredictable manner, this approach appears unfeasible.

Falcone et al. [21, 22] proposed a synthesis algorithm, relying on Streett automata, to translate
most of the property classes defined within the safety-progress hierarchy [41] into (a slight variation
of) edit automata. In the safety-progress hierarchy, our global properties can be seen as guarantee
properties for which all execution traces that satisfy a property contain at least one prefix that still
satisfies the property. However, it should be noticed that they consider untimed properties only; as
already pointed out before, timed actions play a special role in our enforcement and they cannot be
treated as untimed actions.

Beauquier et al. [10] proved that finite-state edit automata (i.e. those edit automata we are actually
interested in) can only enforce a sub-class of regular properties. Actually they can enforce all and
only the regular properties that can be recognised using finite automata whose cycles always
contain at least one final state. This is the case of our enforced regular properties, as well-formed
local properties in PropL always terminate with the â€œfinalâ€ atomic property end.

Pinisetty and Tripakis [51] studied the compositionality of the enforcement of different regular
properties ğ‘1, . . . , ğ‘ğ‘› at the same time, by composing the associated enforcing monitors. The idea is
to replace a monolithic approach, in which a monitor is sinthesised from the property ğ‘1 âˆ© . . . âˆ© ğ‘ğ‘›,
with a compositional one, where the ğ‘› monitors enforcing the properties ğ‘ğ‘– are somehow put
together to enforce ğ‘1 âˆ© . . . âˆ© ğ‘ğ‘›. The authors of [51] proved that runtime enforcement is not
compositional with respect to general regular properties, neither with respect to serial nor parallel
composition. On the other hand compositionality holds for certain sub-classes of regular properties
such as safety (or co-safety) properties. Here, we wish to point out that our notion of scalability is
different from their notion of compositionality, as we aim at scaling our enforcement on a network
of PLCs and not on multiple regular properties on the same PLC.

Bloem et al. [14] defined a synthesis algorithm that given a safety property returns a monitor,
called shield, to enforce untimed properties in reactive systems (which have many aspects in common
with control systems). Their algorithm rely on a notion called ğ‘˜-stabilization: when the design
reaches a state where a property violation becomes unavoidable for some possibile future inputs,
the shield is allowed to deviate for at most ğ‘˜ âˆˆ N steps; if a second violation happens during
the ğ‘˜-step recovery phase, the shield enters a fail-safe mode where it only enforces correctness,
but no longer minimises the deviation. However, The ğ‘˜-stabilizing shield synthesis problem is
unrealisable for many safety-critical systems, because a finite number of deviations cannot be
guaranteed. Humphrey et al. [33] addressed this problem by proposing the notion of admissible
shields which was extended and generalised in KÃ¶nighofer et al. [34] by assuming that systems
have a cooperative behaviour with respect to the shield, i.e., the shield ensures a finite number of
deviations if the system chooses certain outputs. The authors presented a synthesis procedure that
maximises the cooperation between system and environment for satisfying the required enforced
properties. This approach has some similarities with our enforcement in which a violation of a
property during a scan cycle induces the suppression of all subsequent controller actions until
the PLC reaches the end of the scan, so the monitor can insert a safe trace before permitting the
completion of the scan cycle.

Pinisetty et al. [50] proposed a bi-directional runtime enforcement mechanism for reactive systems,
and more generally for cyber-physical relying on Berry and Gonthierâ€™s synchronous hypothesis [11],
to correct both inputs and outputs. Pinisetty et al. express safety properties in terms of Discrete
Timed Automata (DTA) which are more expressive than our class of regular properties. Thus, an
execution trace satisfies a required property only if it ends up on a final state of the corresponding
DTA. However, as not all regular properties can be enforced [10], they proposed a more permissive
enforcement mechanism that accepts execution traces as long as there is still the possibility of

28

R. Lanotte, M. Merro, A. Munteanu

reaching a final state. Furthermore, due to the instantaneity of the synchronous approach, their
enforcement actions are applied in the same reaction step to ensure reactivity. On the contrary, in
our approach the enforcement takes places before the conclusion of scan cycles which are clearly
delimited via end-actions. Our notion of deterministic enforcers is taken from Pinisetty et al. [50].
Moreover, when inserting safe actions, our synthesised enforcers follows Pinisetty et al.â€™s random
edit approach, where the inserted safe action is randomly chosen from a list of admissible actions.
Pearce et al. [49] proposed a bi-directional runtime enforcement over valued signals for PLCs, by
introducing smart I/O modules (similar to our secure proxy) between the PLCs and the controlled
physical processes, to act as an effective line of defence. The authors express security properties in
terms of Values Discrete Timed Automata (VDTA), inspired by the DTA of Pinisetty et al. [50]. Unlike
DTA, VDTA support valued signals, internal variables, and guard conditions. As in Pinisetty et
al. [50], the paper adopts the synchronous hypothesis [11] to correct both inputs and outputs; thus,
their enforcement actions are applied in the same reaction step to ensure instantaneous reactivity.
The authors do not consider attacks that may tamper with inter-controller communications: their
attackers may only manipulate sensor signals and/or actuator commands. Finally, their semantics
requires that every enforcer knows the state of all relevant signals and commands in a given system.
Thus, as written by the same authors, a networked system featuring multiple I/O modules may
significantly complicate the enforcement, as pertinent I/O for a security policy may not be locally
available. As a consequence, unlike us, their enforcement does not naturally scale to networks of
controllers; we believe this is basically due to the fact that they do bi-directional enforcement. Last
but not least, like them, we implement enforcers via FPGAs to ensure efficiency and security at the
same time. In particular, when inserting safe actions our implementation fixes a priority between
admissible safe actions, similarly to their selected edit approach. However, our implementation
differs from theirs in at least the following aspects: (1) our FPGAs do enforce PLC transmissions
(with a negligible latency); (2) our enforcement is uni-directional and hence our FPGAs need to know
only the state of signals and commands of the corresponding enforced PLCs; (3) as a consequence,
our FPGAs can be networked to monitor field communications networks paying only negligible
overhead in terms of computational resources and communication latency.

Aceto et al. [6] developed an operational framework to enforce properties in HML logic with
recursion (ğœ‡HML) relying on suppression. More precisely, they achieved the enforcement of a safety
fragment of ğœ‡HML by providing a linear automated synthesis algorithm that generates correct
suppression monitors from formulas. Enforceability of modal ğœ‡-calculus (a reformulation of ğœ‡HML)
was previously tackled by Martinelli and Matteucci [42] by means of a synthesis algorithm which
is exponential in the length of the enforceable formula. Cassar [18] defined a general framework
to compare different enforcement models and different correctness criteria, including optimality.
His works focuses on the enforcement of a safety fragment of ğœ‡HML, paying attention to both
uni-directional and bi-directional notions of enforcement. More recently, Aceto et al. [7] developed
an operational framework for bi-directional enforcement and used it to study the enforceability of
the aforementioned safety fragment of HML with recursion, via a specific type of bi-directional
enforcement monitors called action disabling monitors.

As regards papers in the context of control system security closer to our objectives, McLaugh-
lin [45] proposed the introduction of an enforcement mechanism, called C2, similar to our secure
proxy, to mediate the control signals ğ‘¢ğ‘˜ transmitted by the PLC to the plant. Thus, like our secured
proxy, C2 is able to suppress commands, but unlike our proxy, it cannot autonomously send com-
mands to the physical devices in the absence of a timely correct action from the PLC. Furthermore,
C2 does not seem to cope with inter-controller communications, and hence with colluding malware
operating on PLCs of the same field network.

Runtime Enforcement of PLCs

29

Mohan et al. [46] proposed a different approach by defining an ad-hoc security architecture,
called Secure System Simplex Architecture (S3A), with the intention to generalise the notion of
â€œcorrect system stateâ€ to include not just the physical state of the plant but also the cyber state
of the PLCs of the system. In S3A, every PLC runs under the scrutiny of a side-channel monitor
which looks for deviations with respect to safe executions, taking care of real-time constraints,
memory usage, and communication patterns. If the information obtained via the monitor differs
from the expected model(s) of the PLC, a decision module is informed to decide whether to pass the
control from the â€œpotentially compromisedâ€ PLC to a safety controller to maintain the plant within
the required safety margins. As reported by the same authors, S3A has a number of limitations
comprising: (i) the possible compromising of the side channels used for monitoring, (ii) the tuning
of the timing parameters of the state machine, which is still a manual process.

The present work is a revised extension of the conference version appeared in [36]. Here, we
provide a detailed comparison with that paper. In Section 2 we specified the attacker model and the
attacker objectives. In Section 3, we adopted a simplified operational semantics for edit automata,
in the style of Martinelli and Matteucci [42]. In Section 5, we have extended our language of
regular properties with intersection of both local and global properties. With this extension we
have expressed a wide family of correctness properties that can be combined in a modular fashion;
these properties include and extend the three classes of properties appearing in the conference
paper. In Section 6, we have extended our synthesis algorithm to deal with our extended properties:
both local and global intersection of properties are synthesised in terms of cross products of edit
automata. Notice that, compared to the conference paper, our enforcement mechanism does not rely
anymore on an ad-hoc semantic rule (Mitigation) to insert safe actions at the end of the scan cycle,
but rather on the more standard rule (Insert) together with the syntactic structure of synthesised
enforcers. As stated in Proposition 1, now our synthesis algorithm depends on the size and the
number of occurrences of intersection operators of the property in input. Last but not least, in this
journal version we provide an implementation of our use case based on: (i) Simulink to simulate
the physical plant, (ii) OpenPLC on Raspberry Pi to run open PLCs, and (iii) FPGAs to implement
enforcers. We have then exposed our implementation to five different attacks targeting the PLCs
and discussed the effectiveness of the proposed enforced mechanism.

In a preliminary work [37], we proposed an extension of our process calculus with an explicit
representation for malware code. In that paper, monitors are synthesised from PLC code rather than
correctness properties. The focus of that paper was mainly on: (i) deadlock-free enforcement, and
(ii) intrusion detection via secure proxies. Here, it is worth pointing out that the work in [37] shares
some similarities with supervisory control theory [15, 54], a general theory for automatic synthesis
of controllers (supervisors) for discrete event systems, given a plant model and a specification for the
controlled behaviour. Fabian and Hellgren [20] have pointed out a number of issues to be addressed
when adopting supervisory control theory in industrial PLC-based facilities, such as causality,
incorrect synchronisation, and choice between alternative paths. However, as our syntheses regard
only logical devices (no plant involved), we are not affected from similar problems.

Finally, Yoong et al. [62] proposed a synchronous semantics for functions blocks, a component-
oriented model at the core of the IEC 61499 international standard [2] used to design distributed
industrial process measurement and control systems. In contrast to the scan cycle model followed
in the current paper (IEC 61131 [1]) prescribing the execution of a sequential portion of code at each
scan cycle, the event-driven model for function blocks relies on the occurrence of asynchronous
events to trigger program execution. Yoong et al. [62] adopted a synchronous approach to define
an execution semantics to function blocks by translating them into a subset of Esterel [11], a
well-known synchronous language. Here, we wish to point out that our PLC specification is given

30

R. Lanotte, M. Merro, A. Munteanu

at a more abstract level compared to that of [62], and it complies with the sequential scan cycle
standard IEC 61131, rather than the event-driven standard IEC 61499.

9 CONCLUSIONS AND FUTURE WORK
We have defined a formal language to express networks of monitored controllers, potentially
compromised with colluding malware that may forge/drop actuator commands, modify sensor
readings, and forge/drop inter-controller communications. The enforcing monitors have been
expressed via a finite-state sub-class of Ligatti et al.â€™s edit automata. In this manner, we have
provided a formal representation of field communications networks in which controllers are
enforced via secure monitors, as depicted in Figure 2. The room of manoeuvre of attackers is
defined via a proper attacker model. Then, we have defined a simple description language to
express timed regular properties that are recognised by finite automata whose cycles always contain
at least one final state (denoted via an end-action). We have used that language to build up formal
definitions for pattern templates suitable for expressing a broad family of correctness properties that
can be combined in a modular fashion to prescribe precise controller behaviours. As an example,
our description language allows us to capture all (bounded variants of the) controller properties
studied in Frehse et at. [24]. Once defined a formal language to describe controller properties,
we have provided a synthesis function âŸ¨| âˆ’ |âŸ© that, given an alphabet P of observable controller
actions and a deterministic regular property ğ‘’ consistent with P, returns a finite-state deterministic
edit automaton âŸ¨| ğ‘’ |âŸ© P. The resulting enforcement mechanism will ensure the required features
advocated in the Introduction: transparency, soundness, deadlock-freedom, divergence-freedom,
mitigation and scalability.

As a final contribution, we have provided a full implementation of a non-trivial case study in the
context of industrial water treatment, where enforcers are implemented via FPGAs. In this setting,
we showed the effectiveness our enforcement mechanism when exposed to five carefully-designed
attacks targeting the PLCs of our use case.

As future work, we wish to test our enforcement mechanism in different domains, such as
industrial and cooperative robotic arms (e.g., Kuka, ABB, Universal Robots, etc) which are endowed
with control architectures working at a fixed rate [57]. More generally, we would like to consider
physical plants with significant uncertainties, in terms of measurements noise and physical process
uncertainty. This is because significant plant perturbations might falsely indicate that the monitored
controller is under attack, inducing our enforcers to take erroneous correcting actions. To address
such challenges we would like to implement in our enforcers well-know control-theory algorithms,
based on linear difference equations, to correctly estimate the state of the physical plant even when
affected by significant uncertainties. Finally, we would like to enhance our enforcers to deal with
malicious alterations of sensor measurements due to compromised sensor devices. In order to do so,
we intend to integrate our secured proxies with physics-based attack detection mechanisms [17, 26].

ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful and careful reviews. We thank Adrian
Francalanza, Yuan Gu, Marjan Sirjani and Davide Sangiorgi for their comments on early drafts of
the paper. The authors have been partially supported by the project â€œDipartimenti di Eccellenza
2018â€“2022â€ funded by the Italian Ministry of Universities and Research (MUR).

REFERENCES
[1] Intâ€™l Standard IEC 61131-3. 2003. Programmable Controllers - Part 3: Programming Languages. second ed., Intâ€™l

Electrotechnical Commission.

Runtime Enforcement of PLCs

31

[2] Intâ€™l Standard IEC 61499-1. 2005. Function Blocks - Part 1: Architecture. first ed., Intâ€™l Electrotechnical Commission.
[3] M. Abadi, B. Blanchet, and C. Fournet. 2018. The Applied Pi Calculus: Mobile Values, New Names, and Secure

Communication. Journal of the ACM 65, 1 (2018), 1:1â€“1:41.

[4] M. Abadi and A. D. Gordon. 1997. A Calculus for Cryptographic Protocols: The Spi Calculus. In CCS. ACM, 36â€“47.
[5] A. Abbasi and M. Hashemi. 2016. Ghost in the PLC Designing an Undetectable Programmable Logic Controller Rootkit

via Pin Control Attack. In Black Hat. 1â€“35.

[6] L. Aceto, I. Cassar, A. Francalanza, and A. IngÃ³lfsdÃ³ttir. 2018. On Runtime Enforcement via Suppressions. In CONCUR.

Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik, 34:1â€“34:17.

[7] L. Aceto, I. Cassar, A. Francalanza, and A. IngÃ³lfsdÃ³ttir. 2021. On Bidirectional Runtime Enforcement. In FORTE (LNCS,

Vol. 12719). Springer, 3â€“21.

[8] T. R. Alves, M. Buratto, F. M. de Souza, and T. R. Rodrigues. 2014. OpenPLC: An open source alternative to automation.

In GHTC 2014. 585â€“589.

[9] E. Bartocci, J. V. Deshmukh, A. DonzÃ©, G. E. Fainekos, O. Maler, D: Nickovic, and S. Sankaranarayanan. 2018.
Specification-Based Monitoring of Cyber-Physical Systems: A Survey on Theory, Tools and Applications. In Lectures
on Runtime Verification - Introductory and Advanced Topics. LNCS, Vol. 10457. Springer, 135â€“175.

[10] D. Beauquier, J. Cohen, and R. Lanotte. 2013. Security policies enforcement using finite and pushdown edit automata.

International Journal of Information Security 12, 4 (2013), 319â€“336.

[11] G. Berry and G. Gonthier. 1992. The Esterel Synchronous Programming Language: Design, Semantics, Implementation.

Science of Computer Programming 19, 2 (1992), 87â€“152.

[12] M. Bielova. 2011. A theory of constructive and predictable runtime enforcement mechanisms. Ph.D. Dissertation.

University of Trento.

[13] N. Bielova and F. Massacci. 2011. Predictability of Enforcement. In Engineering Secure Software and Systems. 73â€“86.
[14] R. Bloem, B. KÃ¶nighofer, R. KÃ¶nighofer, and C. Wang. 2015. Shield Synthesis: - Runtime Enforcement for Reactive

Systems. In TACAS (Lecture Notes in Computer Science, Vol. 9035). Springer, 533â€“548.

[15] W. M. Brandin, B. A. Wonham. 1994. Supervisory control of timed discrete-event systems. IEEE Trans. Automat. Control

39, 2 (1994), 329â€“342.

[16] L. Cardelli and A. Gordon. 2000. Mobile Ambients. TCS 240, 1 (2000), 177â€“213.
[17] A.A. CÃ¡rdenas, S. Amin, Z. Lin, Y. Huang, C. Huang, and S. Sastry. 2011. Attacks against process control systems: risk

assessment, detection, and response. In ASIACCS. 355â€“366.

[18] I. Cassar. 2020. Developing Theoretical Foundations for Runtime Enforcement. Ph.D. Dissertation. University of Malta

and Reykjavik University.

[19] A. Di Pinto, Y. Dragoni, and A. Carcano. 2018. TRITON: The First ICS Cyber Attack on Safety Instrument Systems. In

Black Hat USA 2018. 1â€“28.

[20] M. Fabian and A. Hellgren. 1998. PLC-based implementation of supervisory control for discrete event systems. In CDC,

Vol. 3. IEEE, 3305â€“3310.

[21] Y. Falcone, J-C. Fernandez, and L. Mounier. 2012. What can you verify and enforce at runtime? International Journal

on Software Tools for Technology Transfer 14, 3 (2012), 349â€“382.

[22] Y. Falcone, L. Mounier, J. Fernandez, and J. Richier. 2011. Runtime enforcement monitors: composition, synthesis, and

enforcement abilities. Formal Methods in System Design 38, 3 (2011), 223â€“262.

[23] A. Francalanza. 2021. A theory of monitors. Information and Computation (2021), 104704.
[24] G. Frehse, N. Kekatos, D. Nickovic, J. Oehlerking, S. Schuler, A. Walsch, and M. Woehrle. 2018. A Toolchain for

Verifying Safety Properties of Hybrid Automata via Pattern Templates. In ACC. 2384â€“2391.

[25] Warren Gay. 2014. Mastering the raspberry PI. Apress.
[26] J. Giraldo, D. I. Urbina, A. Cardenas, J. Valente, M. Faisal, J. Ruths, N. O. Tippenhauer, H. Sandberg, and R. Candell. 2018.
A Survey of Physics-Based Attack Detection in Cyber-Physical Systems. ACM Comput. Surv. 51, 4 (2018), 76:1â€“76:36.
[27] J. Goh, S. Adepu, K. N. Junejo, and A. Mathur. 2017. A Dataset to Support Research in the Design of Secure Water

Treatment Systems. In CRITIS (LNCS, Vol. 10242). Springer, 88â€“99.

[28] N. Govil, A. Agrawal, and N. O. Tippenhauer. 2018. On Ladder Logic Bombs in Industrial Control Systems. In

SECPRE@ESORICS 2017 (LNCS, Vol. 10683). Springer, 110â€“126.

[29] M. Hennessy and T. Regan. 1995. A Process Algebra for Timed Systems. Inf. Comput. 117, 2 (1995), 221â€“239.
[30] M. Heymann, F. Lin, G. Meyer, and S. Resmerita. 2005. Analysis of Zeno behaviors in a class of hybrid systems. IEEE

Trans. Autom. Control. 50, 3 (2005), 376â€“383.

[31] Y. Huang, A. A. CÃ¡rdenas, S. Amin, Z. Lin, H. Tsai, and S. Sastry. 2009. Understanding the physical and economic

consequences of attacks on control systems. IJCIP 2, 3 (2009), 73â€“83.

[32] T. Huffmire, C. Irvine, T. D. Nguyen, T. Levin, R. Kastner, and T. Sherwood. 2010. Handbook of FPGA design security.

Springer Science & Business Media.

32

R. Lanotte, M. Merro, A. Munteanu

[33] L. R. Humphrey, B. KÃ¶nighofer, R. KÃ¶nighofer, and U. Topcu. 2016. Synthesis of Admissible Shields. In HVC (Lecture

Notes in Computer Science, Vol. 10028). 134â€“151.

[34] B. KÃ¶nighofer, M. Alshiekh, R. Bloem, L. Humphrey, R. KÃ¶nighofer, U. Topcu, and C. Wang. 2017. Shield synthesis.

Formal Methods in System Design 51, 2 (2017), 332â€“361.

[35] David Kushner. 2013. The real story of STUXnet. IEEE Spectrum 50, 3 (2013), 48 â€“ 53.
[36] R. Lanotte, M. Merro, and A. Munteanu. 2020. Runtime Enforcement for Control System Security. In CSF. IEEE,

246â€“261.

[37] R. Lanotte, M. Merro, and A. Munteanu. 2021. A process calculus approach to detection and mitigation of PLC malware.

Theoretical Computer Science 890 (2021), 125â€“146.

[38] R. Lanotte, M. Merro, A. Munteanu, and ViganÃ², L. 2020. A Formal Approach to Physics-based Attacks in Cyber-physical

Systems. ACM Transactions on Privacy and Security 23, 1 (2020), 3:1â€“3:41.

[39] R. Lanotte, M. Merro, and S. Tini. 2020. A Probabilistic Calculus of Cyber-Physical Systems. Inf. Comput. (2020).
[40] J. Ligatti, L. Bauer, and D. Walker. 2005. Edit automata: enforcement mechanisms for run-time security policies.

International Journal of Information Security 4, 1-2 (2005), 2â€“16.

[41] Z. Manna and A. Pnueli. 1987. A Hierarchy of Temporal Properties. Technical Report. Stanford University.
[42] F. Martinelli and I. Matteucci. 2007. Through Modeling to Synthesis of Security Automata. ENTCS 179 (2007), 31â€“46.
[43] A. P. Mathur and N. O. Tippenhauer. 2016. SWaT: a water treatment testbed for research and training on ICS security.

In CySWater@CPSWeek. IEEE Computer Society, 31â€“36.

[44] MATLAB. 2018. 9.7.0.1190202 (R2019b). The MathWorks Inc., Natick, Massachusetts.
[45] S. E. McLaughlin. 2013. CPS: stateful policy enforcement for control system device usage. In ACSAC. ACM, 109â€“118.
[46] S. Mohan, S. Bak, E. Betti, H. Yun, L. Sha, and M Caccamo. 2013. S3A: secure system simplex architecture for enhanced

security and robustness of cyber-physical systems. In HiCoNS. ACM, 65â€“74.

[47] G. Nikolakopoulos and S. Manesis. 2018. Introduction to Industrial Automation. Taylor & Francis Group.
[48] Terence Parr. 2013. The definitive ANTLR 4 reference. Pragmatic Bookshelf.
[49] H. Pearce, S. Pinisetty, P. S. Roop, M. M. Y. Kuo, and A. Ukil. 2020. Smart I/O Modules for Mitigating Cyber-Physical

Attacks on Industrial Control Systems. IEEE Transactions on Industrial Informatics 16, 7 (2020), 4659â€“4669.

[50] S. Pinisetty, P.S. Roop, S. Smyth, N. Allen, S. Tripakis, and R.V. Hanxleden. 2017. Runtime Enforcement of Cyber-Physical

Systems. ACM TECS 16, 5s (2017), 178:1â€“178:25.

[51] S. Pinisetty and S. Tripakis. 2016. Compositional Runtime Enforcement. In NFM (LNCS, Vol. 9690). Springer, 82â€“99.
[52] B. Radvanovsky. 2013. Project shine: 1,000,000 internet-connected SCADA and ICS stystems and counting. (2013).

Tofino Security.

[53] R. Rajkumar, I. Lee, L. Sha, and J. A. Stankovic. 2010. Cyber-physical systems: the next computing revolution. In DAC.

ACM, 731â€“736.

[54] P. J. Ramadge and W. M. Wonham. 1987. Supervisory Control of a Class of Discrete Event Processes. SIAM J. Control

Optim. 25, 1 (1987), 206â€“230.

[55] Raspberry Pi. 2019. Raspberry Pi 4 Model B. https://www.raspberrypi.org/products/raspberry-pi-4-model-b/
[56] F. B. Schneider. 2000. Enforceable security policies. ACM Trans. Inf. Syst. Secur. 3, 1 (2000), 30â€“50.
[57] Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani, and Giuseppe Oriolo. 2009. Modelling, planning and control. Advanced

Textbooks in Control and Signal Processing. Springer, (2009).

[58] J. Slowik. 2018. Anatomy of an attack: Detecting and defeating CRASHOVERRIDE. VB2018, October (2018).
[59] R. Spenneberg, M. BrÃ¼ggerman, and H. Schwartke. 2016. PLC-Blaster: A Worm Living Solely in the PLC. In Black Hat.

1â€“16.

[60] D. Thomas and P. Moorby. 2008. The VerilogÂ® Hardware Description Language. Springer Science & Business Media.
[61] W. Wolf. 2004. FPGA-based system design. Pearson education.
[62] L. H. Yoong, P. S. Roop, V. Vyatkin, and Z. A. Salcic. 2009. A Synchronous Approach for IEC 61499 Function Block

Implementation. IEEE Trans. Computers 58, 12 (2009), 1599â€“1614.

[63] N. Zilberman, Y. Audzevich, G. Kalogeridou, N. Manihatty-Bojan, J. Zhang, and A. Moore. 2015. NetFPGA: Rapid
prototyping of networking devices in open source. ACM SIGCOMM Comput. Commun. Rev. 45, 4 (2015), 363â€“364.

A PROOFS
In order to prove the results of Section 6, in Table 6 we provide the technical definition of cross prod-
uct between two edit automata used in the synthesis of Table 5. As the first three cases are straightfor-
Z ((cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘–, (cid:205)ğ‘— âˆˆğ½ ğœˆ ğ‘— .Eğ‘— )
ward, we explain only the fourth case, the cross product associated to ProdP
Here, we use the abbreviation ğœ†.E âŠ• ğœ†â€².E to denote the automaton ğœ†.E + ğœ†â€².E, if ğœ† â‰  ğœ†â€², and, the
automaton ğœ†.E, if ğœ† = ğœ†â€². Thus, the product does the intersection of those addends ğœ†ğ‘– .Eğ‘– and ğœˆ ğ‘— .Eğ‘— ,

Runtime Enforcement of PLCs

33

ğœ†ğ‘– .Eğ‘– )

(X1, X2)

ProdP
Z
(X, (cid:205)
ProdP
Z
ğ‘–âˆˆğ¼
( (cid:205)
ProdP
ğœ†ğ‘– .Eğ‘–, X)
Z
ğ‘–âˆˆğ¼
ğœ†ğ‘– .Eğ‘–, (cid:205)
( (cid:205)
ğ‘— âˆˆğ½
ğ‘–âˆˆğ¼

ğœˆğ‘— .Fğ‘— )

ProdP
Z

â‰œ

â‰œ

â‰œ

â‰œ

ğœ†ğ‘– .Eğ‘– ), if X = E

(E1, E2), if X1 = E1 and X2 = E2
(E, (cid:205)
ğ‘–âˆˆğ¼
( (cid:205)
ğœ†ğ‘– .Eğ‘–, E), if X = E
ğ‘–âˆˆğ¼
(ğœ†ğ‘– .Xğ‘–,ğ‘— âŠ• ğœˆğ‘— .Xğ‘–,ğ‘— ) + (cid:205)
ğ›¼ âˆˆQ

ProdP
Z
ProdP
Z
ProdP
Z
(cid:205)
(ğ‘–,ğ‘— ) âˆˆğ»
Xğ‘–,ğ‘— = ProdP
Xğ‘–,ğ‘—
Q = ( P \ {tick, end}) \ (cid:208)
ğ» = { (ğ‘–, ğ‘—) âˆˆğ¼ Ã—ğ½ : out (ğœ†ğ‘– )=out (ğœˆğ‘— )â‰ ğœ and ProdP
Xğ‘–,ğ‘—

(ğ‘–,ğ‘— ) âˆˆğ» {ğœ†ğ‘–, ğœˆğ‘— }

âˆ’ğ›¼ .Z, for

(Eğ‘–, Fğ‘— )

(Eğ‘–, Fğ‘— ) â‰ 

(cid:205)
ğ›¼ âˆˆP\{tick,end}

âˆ’ğ›¼ .Xğ‘–,ğ‘— }

Table 6. Cross product between two edit automata with alphabet P.

with (ğ‘–, ğ‘—) âˆˆ ğ» , for which: (a) the prefixes have the same output (e.g., ğœ†ğ‘– = ğ›¼ and ğœˆ ğ‘— = ğ›¼ < ğ›¼ â€²), (b)
the prefixes are not suppressions, (c) the product of their continuations Eğ‘– and Eğ‘— â€œis not emptyâ€, i.e.,
it is not a suppression-only automaton. For the other addends ğœ†ğ‘– .Eğ‘– and ğœˆ ğ‘— .Eğ‘— which do not comply
with the above conditions (i.e., (ğ‘–, ğ‘—) âˆ‰ ğ» ), the product results in a suppression-only automaton.

Let us prove the complexity of the synthesis algorithm formalised in Proposition 1. For that we
need three technical lemmata. The first lemma shows that our synthesis algorithm always returns
an edit automaton in a specific canonical form.

Lemma 1 (Canonical Form). Let ğ‘’ âˆˆ PropG and P be a set of actions such that events(ğ‘’) âŠ† P.

Then, either âŸ¨| ğ‘’ |âŸ© P = E or âŸ¨| ğ‘’ |âŸ© P = Z, with Z = E, for E of the following form:

E =

ğ›¼ğ‘– .Eğ‘– + (cid:205)
ğ›¼ğ‘– .Eğ‘– + (cid:205)

ğ‘–âˆˆğ¼

ğ›¼ âˆˆQ

(cid:205)
ğ‘–âˆˆğ¼
(cid:205)
ğ‘–âˆˆğ¼

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

ğ›¼ğ‘– â‰º end.Eğ‘– + (cid:205)

âˆ’ğ›¼ .F, if end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘–

ğ›¼ âˆˆQ

âˆ’ğ›¼ .F, otherwise.

where ğ›¼ğ‘– âˆˆ P, Q = P \ (âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– âˆª {tick, end}), and Eğ‘– and F edit automata. A similar result holds when
ğ‘’ is replaced with some local property ğ‘ âˆˆ PropL.

Proof. The proof is by induction on the structure of the property ğ‘’. The most interesting case
X (âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P). By inductive hypothesis,

is when ğ‘’ = ğ‘’1 âˆ© ğ‘’2. Then, âŸ¨| ğ‘’1 âˆ© ğ‘’2 |âŸ© P returns ProdP
âŸ¨| ğ‘’1 |âŸ© P and âŸ¨| ğ‘’2 |âŸ© P have the required form. We prove the case when
ğ›¼ğ‘– â‰º end.Eğ‘– + (cid:205)
ğ›¼ âˆˆQ1

â€¢ âŸ¨| ğ‘’1 |âŸ© P = (cid:205)

âˆ’ğ›¼ .Eâ€², with Q1 = P \ (âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– âˆª {tick, end}) and end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘–

ğ‘–âˆˆğ¼

â€¢ âŸ¨| ğ‘’2 |âŸ© P = (cid:205)

âˆ’ğ›¼ .Fâ€², with Q2 = P \ (âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– âˆª {tick, end}) and end âˆˆ âˆªğ‘— âˆˆğ½ ğ›¼ ğ‘— .

ğ›¼ğ‘– .Eğ‘– + (cid:205)
ğ›¼ ğ‘— .Fğ‘— + (cid:205)
ğ›¼ âˆˆQ2

ğ‘–âˆˆğ¼

ğ‘— âˆˆğ½

The other cases are similar or simpler. For any ğ‘– âˆˆ ğ¼ and ğ‘— âˆˆ ğ½ , we have: (i) out (ğ›¼ğ‘– ) = out (ğ›¼ ğ‘— ) if and
only if ğ›¼ğ‘– = ğ›¼ ğ‘— ; (ii) out (ğ›¼ğ‘– â‰º end) = out (ğ›¼ ğ‘— ) holds if and only if ğ›¼ğ‘– = ğ›¼ ğ‘— . We recall that out (âˆ’ğ›¼) = ğœ.
Thus, the set ğ» of the definition of cross product in Table 6 for ProdP
X (âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P) is equal to
{(ğ‘–, ğ‘—) âˆˆ ğ¼ Ã— ğ½ : ğ›¼ğ‘– = ğ›¼ ğ‘— and ProdP
(Eğ‘–, Fğ‘— ).
Xğ‘–,ğ‘—
As a consequence, we derive

âˆ’ğ›¼ .Xğ‘–,ğ‘— }, with Xğ‘–,ğ‘— = ProdP
Xğ‘–,ğ‘—

(Eğ‘–, Fğ‘— ) â‰  (cid:205)ğ›¼ âˆˆ P\{tick,end}

ProdP

X (âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P) =

âˆ‘ï¸

(ğ‘–,ğ‘—) âˆˆğ»

ğ›¼ğ‘– .Xğ‘–,ğ‘— +

âˆ‘ï¸

(ğ‘–,ğ‘—) âˆˆğ»

ğ›¼ğ‘– â‰º end.Xğ‘–,ğ‘— +

âˆ’ğ›¼ .X

âˆ‘ï¸

ğ›¼ âˆˆQ

with Q = P \ (âˆª(ğ‘–,ğ‘—) âˆˆğ» ğ›¼ğ‘– âˆª {tick, end}). It remains to prove that end âˆ‰ âˆª(ğ‘–,ğ‘—) âˆˆğ» ğ›¼ğ‘– . Since end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– and
end âˆˆ âˆªğ‘— âˆˆğ½ ğ›¼ ğ‘— , then there is no (ğ‘–, ğ‘—) âˆˆ ğ» such that ğ›¼ğ‘– = end. Thus, end âˆ‰ âˆª(ğ‘–,ğ‘—) âˆˆğ» ğ›¼ğ‘– , as required. â–¡

34

R. Lanotte, M. Merro, A. Munteanu

By an application of Lemma 1, we derive a second lemma which extends a classical result on the
complexity of the cross product of finite state automata to the cross product of (synthetised) edit
automata.

Lemma 2. Let ğ‘’1, ğ‘’2 âˆˆ PropG and P be a set of observable actions. Let ğ‘£1, ğ‘£2 be the number
of derivatives of âŸ¨| ğ‘’1 |âŸ© P and âŸ¨| ğ‘’2 |âŸ© P, respectively.2 The complexity of the algorithm to compute
ProdP
X (âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P) is O (|P | Â· ğ‘£1 Â· ğ‘£2). A similar result holds for edit automata derived from local
properties ğ‘1, ğ‘2 âˆˆ PropL.

The third lemma provides an upper bound to the number of derivates of the automaton âŸ¨| ğ‘’ |âŸ© P.

Lemma 3 (Upper bound of number of derivatives). Let ğ‘’ âˆˆ PropG be a global property with
ğ‘š = dim(ğ‘’), and P be a set of observable actions. Then, the number of derivatives of âŸ¨| ğ‘’ |âŸ© P is at most
ğ‘šğ‘˜+1, where ğ‘˜ is the number of occurrences of the symbol âˆ© in ğ‘’.

2

Proof. The proof is by structural induction on ğ‘’. Let ğ‘’ â‰¡ ğ‘’1 âˆ© ğ‘’2 and ğ‘š = dim(ğ‘’1 âˆ© ğ‘’2). By defini-
tion, the synthesis function recalls itself on ğ‘’1 and ğ‘’2. Obviously, ğ‘š1 +ğ‘š2 = ğ‘š âˆ’ 1 with ğ‘š1 = dim(ğ‘’1)
and ğ‘š2 = dim(ğ‘’2). Let ğ‘˜, ğ‘˜1 and ğ‘˜2 be the number of occurrences of the symbol âˆ© in ğ‘’1 âˆ©ğ‘’2, ğ‘’1 and ğ‘’2,
respectively. We deduce that ğ‘˜1+ğ‘˜2 = ğ‘˜âˆ’1. By inductive hypothesis, âŸ¨| ğ‘’1 |âŸ© P has at most ğ‘šğ‘˜1+1
deriva-
tives, and, âŸ¨| ğ‘’2 |âŸ© P has at most ğ‘šğ‘˜2+1
derivatives. As the synthesis returns the cross product between
Â· ğ‘šğ‘˜2+1
âŸ¨| ğ‘’1 |âŸ© P and âŸ¨| ğ‘’2 |âŸ© P, we derive that the resulting edit automaton will have at most ğ‘šğ‘˜1+1
2
derivatives. The result follows because ğ‘šğ‘˜1+1
Â· ğ‘šğ‘˜2+1
â‰¤ ğ‘šğ‘˜1+1 Â· ğ‘šğ‘˜2+1 â‰¤ ğ‘šğ‘˜1+ğ‘˜2+2 â‰¤ ğ‘šğ‘˜âˆ’1+2 â‰¤ ğ‘šğ‘˜+1.
2
Let ğ‘’ â‰¡ ğ‘âˆ—, for ğ‘ âˆˆ PropL. In order to analyse this case, as ğ‘š = dim(ğ‘âˆ—) = dim(ğ‘) + 1 and
âŸ¨|ğ‘âˆ—|âŸ© P â‰œ X, for X = âŸ¨| ğ‘ |âŸ© P
, we proceed by structural induction of ğ‘ âˆˆ PropL. We focus on
X
the most significant case ğ‘ â‰¡ (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– . We have that ğ‘š âˆ’ 1 = dim((cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– ). By definition the
synthesis produces | ğ¼ | derivatives, one for each ğœ‹ğ‘– âˆˆ ğ¼ , and also the derivative Z. Furthermore, the
synthesis algorithm re-calls itself | ğ¼ | times on ğ‘ğ‘– , with ğ‘šğ‘– = dim(ğ‘ğ‘– ) such that ğ‘šâˆ’1 =| ğ¼ | + (cid:205)ğ‘– âˆˆğ¼ ğ‘šğ‘– ,
for ğ‘– âˆˆ ğ¼ . Let ğ‘˜ and ğ‘˜ğ‘– be the number of occurrences of âˆ© in ğ‘ and in ğ‘ğ‘– , respectively, for ğ‘– âˆˆ ğ¼ . We
deduce that (cid:205)ğ‘– âˆˆğ¼ ğ‘˜ğ‘– = ğ‘˜. By inductive hypothesis, the synthesis produces ğ‘šğ‘˜ğ‘– +1
derivatives on each
property ğ‘ğ‘– , for ğ‘– âˆˆ ğ¼ . Summarising, in this case the number of derivatives is 1+ | ğ¼ | + (cid:205)ğ‘– âˆˆğ¼ ğ‘šğ‘˜ğ‘– +1
.
Finally, the thesis follows as 1+ | ğ¼ | + (cid:205)ğ‘– âˆˆğ¼ ğ‘šğ‘˜ğ‘– +1
â–¡

â‰¤ (cid:205)ğ‘– âˆˆğ¼ ğ‘šğ‘˜ğ‘– +1 â‰¤ ğ‘šğ‘˜+1.

1

1

1

ğ‘–

ğ‘–

ğ‘–

Proof of Proposition 1 (Complexity). For any property ğ‘’ âˆˆ PropG and any set of observ-
able actions P, we prove that the recursive structure of the function returning âŸ¨| ğ‘’ |âŸ© P can be char-
acterised in the following form: ğ‘‡ (ğ‘š) = ğ‘‡ (ğ‘š âˆ’ 1) + |P | Â· ğ‘šğ‘˜ , with ğ‘š = dim(ğ‘’), and ğ‘˜ the number
of occurrences of âˆ© in ğ‘’. The result follows because ğ‘‡ (ğ‘š) = ğ‘‡ (ğ‘š âˆ’ 1) + |P | Â· ğ‘šğ‘˜ is O (|P | Â· ğ‘šğ‘˜+1).
The proof is by case analysis on the structure of ğ‘’, by examining each synthesis step in which the
synthesis process ğ‘š = dim(ğ‘’) symbols.

Case ğ‘’ â‰¡ ğ‘’1 âˆ© ğ‘’2. Let ğ‘š = dim(ğ‘’1 âˆ© ğ‘’2). By definition, the synthesis âŸ¨| ğ‘’1 âˆ© ğ‘’2 |âŸ© P call itself on ğ‘’1
and ğ‘’2, with ğ‘š1 = dim(ğ‘’1) and ğ‘š2 = dim(ğ‘’2) symbols, respectively, where ğ‘š1 + ğ‘š2 = ğ‘š âˆ’ 1. Let ğ‘˜
be the number of occurrences of âˆ© in ğ‘’ and ğ‘˜1, ğ‘˜2 be the number of occurrences of âˆ© in ğ‘’1 and ğ‘’2,
respectively. We deduce that ğ‘˜1 + ğ‘˜2 = ğ‘˜ âˆ’ 1. By an application of Lemma 2, the complexity of the
algorithm to compute ProdP
X (âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P) is O (|P | Â· ğ‘£1 Â· ğ‘£2), where ğ‘£1 and ğ‘£2 are the number
of derivatives of âŸ¨| ğ‘’1 |âŸ© P and âŸ¨| ğ‘’2 |âŸ© P, respectively. By an application of Lemma 3, we have that
ğ‘£1 â‰¤ ğ‘šğ‘˜1+1
and ğ‘£2 â‰¤ ğ‘šğ‘˜2+1
. Thus, the number of operations required for the cross product between
âŸ¨| ğ‘’1 |âŸ© P and âŸ¨| ğ‘’2 |âŸ© P is O (|P | Â· ğ‘šğ‘˜1+1
). Thus, we can characterise the recursive structure as:
ğ‘‡ (ğ‘š) = ğ‘‡ (ğ‘š1) + ğ‘‡ (ğ‘š2) + |P | Â· ğ‘šğ‘˜1+1
. We notice that the complexity of this recursive form is
smaller than the complexity of ğ‘‡ (ğ‘š âˆ’ 1) + |P | Â· ğ‘šğ‘˜ .

Â· ğ‘šğ‘˜2+1
2
Â· ğ‘šğ‘˜2+1
2

2

1

1

1

2These numbers are finite as we deal with finite-state edit automata.

Runtime Enforcement of PLCs

35

Case ğ‘’ â‰¡ ğ‘âˆ—. In order to prove this case, as ğ‘š = dim(ğ‘âˆ—) = dim(ğ‘) + 1 and âŸ¨|ğ‘âˆ—|âŸ© P â‰œ X, for
, we proceed by case analysis on ğ‘ âˆˆ PropL. Thus, we consider the local properties ğ‘ âˆˆ
X = âŸ¨| ğ‘ |âŸ© P
X
PropL. We focus on the most significant case ğ‘ â‰¡ (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– . We have that ğ‘šâˆ’1 = dim((cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– ).
By definition, the synthesis âŸ¨| (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– |âŸ© P consumes all events ğœ‹ğ‘– , for ğ‘– âˆˆ ğ¼ . The synthesis algorithm
re-calls itself | ğ¼ | times on ğ‘ğ‘– , with dim(ğ‘ğ‘– ) symbols, for ğ‘– âˆˆ ğ¼ . Furthermore, let ğ‘™ be the size
of the set P, the algorithm performs at most ğ‘™ operations due to a summation over over ğ›¼ âˆˆ
P \ ((cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– âˆª {tick, end}), with | P \ ((cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– âˆª {tick, end}) |< ğ‘™. Thus, we can characterise the
recursive structure as ğ‘‡ (ğ‘š) = (cid:205)ğ‘– âˆˆğ¼ ğ‘‡ (dim(ğ‘ğ‘– )) + ğ‘™. Since (cid:205)ğ‘– âˆˆğ¼ dim(ğ‘ğ‘– ) = ğ‘š âˆ’ 1 âˆ’ | ğ¼ | â‰¤ ğ‘š âˆ’ 1. The
resulting complexity is smaller than that of ğ‘‡ (ğ‘š âˆ’ 1) + |P | Â· ğ‘šğ‘˜ .
â–¡

Proof of Proposition 2 (Deterministic preservation). We reason by contradiction. Suppose
there is a sum (cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘– appearing in âŸ¨| ğ‘’ |âŸ© P such that trigger (ğœ†ğ‘˜ ) = trigger (ğœ† ğ‘— ) and out (ğœ†ğ‘˜ ) =
out (ğœ† ğ‘— ), for some ğ‘˜, ğ‘— âˆˆ ğ¼ , ğ‘˜ â‰  ğ‘—. We proceed by case analysis on the structure of the property ğ‘’.
Let us focus on the case ğ‘’ = (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– . The other cases are simpler. Then, âŸ¨| ğ‘’ |âŸ© P is equal to Z, for

Z =

(cid:205)
ğ‘–âˆˆğ¼
(cid:205)
ğ‘–âˆˆğ¼

ğœ‹ğ‘– .âŸ¨| ğ‘ğ‘– |âŸ© P
X
ğœ‹ğ‘– .âŸ¨| ğ‘ğ‘– |âŸ© P
X

+ (cid:205)
ğ‘–âˆˆğ¼
+ (cid:205)
ğ›¼ âˆˆQ

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

ğœ‹ğ‘– â‰º end.âŸ¨| ğ‘ğ‘– |âŸ© P
X

+ (cid:205)
ğ›¼ âˆˆQ

âˆ’ğ›¼ .Z, if end âˆ‰ âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘–

âˆ’ğ›¼ .Z, otherwise

and Q = P \ (âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– âˆª {tick, end}). Since ğ‘’ is deterministic (Definition 5) it follows that ğœ‹â„ â‰  ğœ‹ğ‘™ , for
any â„, ğ‘™ âˆˆ ğ¼ , â„ â‰  ğ‘™. As a consequence, it cannot be ğœ†ğ‘˜ = ğœ‹â„ â‰º end, for â„ âˆˆ ğ¼ , and ğœ† ğ‘— = ğœ‹ğ‘™ â‰º end, for ğ‘™ âˆˆ ğ¼ ,
â„ â‰  ğ‘™, because out (ğœ†ğ‘˜ ) = ğœ‹â„ â‰  ğœ‹ğ‘™ = out (ğœ† ğ‘— ). Thus, the only chance for Z to be nondeterministic
is that ğœ†ğ‘˜ = ğœ‹â„, for â„ âˆˆ ğ¼ , and ğœ† ğ‘— = ğœ‹ğ‘™ â‰º end, for ğ‘™ âˆˆ ğ¼ , in the case end âˆ‰ âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– . However, this is not
â–¡
admissible because end âˆ‰ âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– implies trigger (ğœ†ğ‘˜ ) = ğœ‹â„ â‰  end = trigger (ğœ† ğ‘— ).

In order to prove Theorem 1, we need prove that the cross product between edit automata
satisfies a standard correctness result saying that any execution trace associated to the intersection
of two regular properties is also a trace of the the cross product of the edit automata associated to
the two properties, and vice versa.

Lemma 4 (Correctness of Cross Product). Let ğ‘’1, ğ‘’2 âˆˆ PropG (resp., ğ‘1, ğ‘2 âˆˆ PropL) and
P be a set of actions such that events(ğ‘’1 âˆ© ğ‘’2) âŠ† P (resp., events(ğ‘1 âˆ© ğ‘2) âŠ† P). Then, it holds that:
)), then (cid:155)out (ğ‘¡) is prefix of

â€¢ If ğ‘¡ is a trace of ProdP
X

, âŸ¨| ğ‘2 |âŸ© P
X

some trace in the semantics

â€¢ If ğ‘¡ is a trace in
(resp., ProdP
X

ğ‘’1 âˆ© ğ‘’2
(cid:74)
(âŸ¨| ğ‘1 |âŸ© P
X

(âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P ) (resp., ProdP
X
ğ‘1 âˆ© ğ‘2
(cid:74)

(resp.,

ğ‘’1 âˆ© ğ‘’2
(cid:74)
(resp.,
, âŸ¨| ğ‘2 |âŸ© P
X

(cid:75)

(cid:75)
ğ‘1 âˆ© ğ‘2
(cid:74)

(cid:75)
)) such that (cid:155)out (ğ‘¡ â€²) = ğ‘¡.

(âŸ¨| ğ‘1 |âŸ© P
X
).

) then there exists a trace ğ‘¡ â€² of ProdP
X

(cid:75)

(âŸ¨| ğ‘’1 |âŸ© P, âŸ¨| ğ‘’2 |âŸ© P )

Proof of Theorem 1 (Transparency). We prove a stronger result. Let ğ‘’ âˆˆ PropG be a global
ğ‘¡
âˆ’âˆ’â†’ ğ½ , for some trace ğ‘¡ = ğ›¼1 Â· Â· Â· ğ›¼ğ‘›.

deterministic property and ğ‘ƒ âˆˆ Ctrl be a controller such that ğ‘ƒ
If ğ‘¡ is the prefix of some trace in the semantics
ğ‘’
(cid:75)
(cid:74)
ğ‘¡
âˆ’âˆ’âˆ’â†’ E where either E = âŸ¨| ğ‘ â€² |âŸ© P
(1) There exists a unique E such that âŸ¨| ğ‘’ |âŸ© P
X

then the following sub-results hold:

or E = Z, with

Z = âŸ¨| ğ‘ â€² |âŸ© P
X

(2) There is a trace ğ‘¡ â€² âˆˆ
(3) There is no trace ğ‘¡ â€²â€² = ğ›¼1 Â· Â· Â· ğ›¼ğ‘˜ Â· ğœ† for âŸ¨| ğ‘’ |âŸ© P such that 0 â‰¤ ğ‘˜ < ğ‘› and ğœ† âˆˆ {âˆ’ğ›¼ğ‘˜+1, ğ›¼ â‰º ğ›¼ğ‘˜+1},

, for some ğ‘ â€² âˆˆ PropL and some automaton variable X.
ğ‘’
(cid:74)

such that ğ‘¡ Â· ğ‘¡ â€² is a prefix of some trace in

ğ‘ â€²
(cid:74)

(cid:75)

(cid:75)

.

for some ğ›¼.

These three sub-results imply the required result. We proceed by induction on the length ğ‘› of trace ğ‘¡.
- Base case: ğ‘› = 1. That is ğ‘¡ = ğ›¼, with ğ›¼ âˆˆ Sens âˆª Chnâˆ— âˆª Act âˆª {tick, end}. We proceed by induction
on the structure of ğ‘’.

Case ğ‘’ â‰¡ ğ‘âˆ—, for some ğ‘ âˆˆ PropL. We prove the following three results:

36

R. Lanotte, M. Merro, A. Munteanu

â€¢ i) there exists a unique E such that âŸ¨| ğ‘ |âŸ© P
Xâ€²

ğ›¼
âˆ’âˆ’âˆ’â†’ E and either E = âŸ¨| ğ‘ â€² |âŸ© P

Xâ€² or E = Z, with

Z = âŸ¨| ğ‘ â€² |âŸ© P

â€¢ ii) there is a trace ğ‘¡ â€² âˆˆ
ğ‘ â€²
(cid:74)
â€¢ iii) there is no ğœ† âˆˆ {âˆ’ğ›¼, ğ›¼ â€² â‰º ğ›¼ } such that âŸ¨| ğ‘ |âŸ© P
Xâ€²

Xâ€² , for some ğ‘ â€² âˆˆ PropL and some automaton variable Xâ€²;
such that ğ›¼ Â· ğ‘¡ â€² is a prefix of some trace in
ğœ†
(cid:75)
âˆ’âˆ’âˆ’â†’ Eâ€², for some Eâ€².
As âŸ¨| ğ‘âˆ— |âŸ© P â‰œ X, with X = âŸ¨| ğ‘ |âŸ© P
, results i) and ii) and iii) imply the required facts (1) and (2) and
X
(3) for ğ‘’ = ğ‘âˆ—. We proceed as follows: first, we prove items i) and ii) by induction on the structure
of ğ‘, and then we prove item iii) by contradiction.

ğ‘
(cid:74)

(cid:75)

;

We prove items i) and ii). We focus on the most significant cases: ğ‘ = (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– and ğ‘ â‰¡ ğ‘1 âˆ© ğ‘2.

The other cases are similar or simpler.
Let ğ‘ â‰¡ (cid:208)ğ‘– âˆˆğ¼ ğœ‹ğ‘– .ğ‘ğ‘– . In this case, ğ›¼ is a prefix of some trace in

and âŸ¨| ğ‘ |âŸ© P
X

ğ‘
(cid:74)
âˆ’ğ›¼ â€²â€².Zâ€², if end âˆ‰ âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘–

(cid:75)

returns Zâ€², for

Zâ€² =

ğœ‹ğ‘– .âŸ¨| ğ‘ğ‘– |âŸ© P
X
ğœ‹ğ‘– .âŸ¨| ğ‘ğ‘– |âŸ© P
X

(cid:205)
ğ‘–âˆˆğ¼
(cid:205)
ğ‘–âˆˆğ¼

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

ğœ‹ğ‘– â‰º end.âŸ¨| ğ‘ğ‘– |âŸ© P
X

+ (cid:205)
ğ›¼â€²â€²âˆˆQ
âˆ’ğ›¼ â€²â€².Zâ€², otherwise.

+ (cid:205)
ğ‘–âˆˆğ¼
+ (cid:205)
ğ›¼â€²â€²âˆˆQ

where Q = P \ (âˆªğ‘– âˆˆğ¼ ğœ‹ğ‘– âˆª {tick, end}). Since ğ›¼ is a prefix of some trace in
and ğ‘’ is deterministic, then we derive that ğ›¼ = ğœ‹ğ‘˜ , for a unique index ğ‘˜ âˆˆ ğ¼ .

ğ‘
(cid:74)

(cid:75)

and ğœ‹ğ‘– â‰  ğœ–, for any ğ‘– âˆˆ ğ¼ ,

â€¢ Let us prove ii). Since ğ‘ƒ

â€¢ Let us prove i). Since ğ‘˜ is the unique index such that ğ›¼ = ğœ‹ğ‘˜ , we derive that âŸ¨| ğ‘ |âŸ© P
X

the unique transition labeled ğ›¼ such that either E = âŸ¨| ğ‘ğ‘˜ |âŸ© P

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ½ and ğ›¼ = ğœ‹ğ‘˜ , by inductive hypothesis there exists ğ‘¡ â€² âˆˆ
(cid:75)
, as required.
and the synthesis âŸ¨| ğ‘ |âŸ© P
X

, and hence also in

ğ‘
(cid:74)

ğ›¼
âˆ’âˆ’âˆ’â†’ E is
Zâ€² or E = Z1, with Z1 = âŸ¨| ğ‘ğ‘˜ |âŸ© P
Zâ€².
ğ‘ğ‘˜
(cid:74)

(cid:75)

Let ğ‘ â‰¡ ğ‘1 âˆ© ğ‘2. In this case, we have that ğ›¼ is prefix of some trace in
returns the edit automaton Eğ‘ = ProdP

).

ğ‘
(cid:74)

(cid:75)

such that ğ›¼ Â· ğ‘¡ â€² is a prefix of some trace in

ğœ‹ğ‘˜ .ğ‘ğ‘˜
(cid:74)
(cid:75)
, âŸ¨| ğ‘2 |âŸ© P
X

X (âŸ¨| ğ‘1 |âŸ© P

X

âŸ¨| ğ‘1 |âŸ© P

â€¢ Let us prove i). By definition of cross product in Table 6, the most interesting case is when
X = (cid:205)ğ‘— âˆˆğ½ ğœˆ ğ‘— .Fğ‘— . In this case,
âˆ‘ï¸
, âŸ¨| ğ‘2 |âŸ© P

X = (cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘– and âŸ¨| ğ‘2 |âŸ© P

(ğœ†ğ‘– .Xğ‘–,ğ‘— âŠ• ğœˆ ğ‘— .Xğ‘–,ğ‘— ) +

Eğ‘ = ProdP

âˆ’ğ›¼ .Z,

âˆ‘ï¸

X (âŸ¨| ğ‘1 |âŸ© P

X

X ) =

(ğ‘–,ğ‘—) âˆˆğ»

ğ›¼ âˆˆ Q

(cid:205)
ğ›¼ âˆˆ P\{tick,end}
ğ‘1
(cid:74)

for Xğ‘–,ğ‘— = ProdP
Xğ‘–,ğ‘—
out (ğœ†ğ‘– ) = out (ğœˆ ğ‘— ) â‰  ğœ and ProdP
Xğ‘–,ğ‘—

(Eğ‘–, Fğ‘— ) â‰ 

(Eğ‘–, Fğ‘— ) and Q = (P \ {tick, end}) \ (cid:208)

(ğ‘–,ğ‘—) âˆˆğ» {ğœ†ğ‘–, ğœˆ ğ‘— } and ğ» = {(ğ‘–, ğ‘—) âˆˆ ğ¼ Ã—ğ½ :
âˆ’ğ›¼ .Xğ‘–,ğ‘— }. Now, since ğ›¼ is a prefix of

(cid:75)

(cid:75)

and

ğ‘
(cid:74)

1 |âŸ© P
X

, for some ğ‘ â€²

, then ğ›¼ is a prefix of some trace in both

ğ›¼
âˆ’âˆ’âˆ’â†’ F, and either F = âŸ¨| ğ‘ â€²

. Thus, since ğ‘ƒ
ğ‘2
ğ›¼
(cid:74)
âˆ’âˆ’âˆ’â†’ E, and either E = âŸ¨| ğ‘ â€²

2 |âŸ© P
X
X = (cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘– and âŸ¨| ğ‘2 |âŸ© P

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ½ , by
some trace in
(cid:75)
inductive hypothesis there exists a unique E such that âŸ¨| ğ‘1 |âŸ© P
1 |âŸ© P
X
X
1 âˆˆ PropL. Similarly, there exists unique F such that
or E = Z1, with Z1 = âŸ¨| ğ‘ â€²
2 âˆˆ PropL.
or F = Z2, with Z2 = âŸ¨| ğ‘ â€²
2 |âŸ© P
âŸ¨| ğ‘2 |âŸ© P
X
X
X = (cid:205)ğ‘— âˆˆğ½ ğœˆ ğ‘— .Fğ‘— , then we have that there exist ğ‘– âˆˆ ğ¼ and
Since âŸ¨| ğ‘1 |âŸ© P
ğ‘— âˆˆ ğ½ such that E = Eğ‘— and F = Fğ‘— By Lemma 4 and by definition of cross product, we have
ğ›¼
âˆ’âˆ’âˆ’â†’ Xğ‘–,ğ‘— , with Xğ‘–,ğ‘— = ProdP
(Eğ‘–, Fğ‘— ) = ProdP
that (ğ‘–, ğ‘—) âˆˆ ğ» , ğ›¼ = ğœ†ğ‘– and Eğ‘
(E, F). Thus,
Xğ‘–,ğ‘—
Xğ‘–,ğ‘—
ğ›¼
âˆ’âˆ’âˆ’â†’ Xğ‘–,ğ‘— is the only possible transition for Eğ‘
since E and F are unique, it follows that Eğ‘
with label ğ›¼. Finally, we have that ProdP
,
2 |âŸ© P
, âŸ¨| ğ‘ â€²
Xğ‘–,ğ‘—
X
as required.

(E, F) = ProdX(âŸ¨| ğ‘ â€²

, for some ğ‘ â€²

) = âŸ¨| ğ‘ â€²

1 âˆ© ğ‘ â€²

1 |âŸ© P
X

2 |âŸ© P
X

â€¢ Let us prove ii). As Eğ‘
Lemma 4 we derive that
follows that Eğ‘
trace in

ğ›¼
âˆ’âˆ’âˆ’â†’ ProdP
Xğ‘–,ğ‘—
1 âˆ© ğ‘ â€²
ğ‘ â€²
2
ğ›¼
(cid:75)
(cid:74)
âˆ’âˆ’âˆ’â†’ ProdP
1 |âŸ© P
X (âŸ¨| ğ‘ â€²
X
, as required.
(cid:75)

ğ‘1 âˆ© ğ‘2
(cid:74)

(E, F) = ProdP
X (âŸ¨| ğ‘ â€²
â‰  âˆ…. Thus, there exists ğ‘¡ â€² âˆˆ

, by
1 |âŸ© P
2 |âŸ© P
, âŸ¨| ğ‘ â€²
1 âˆ© ğ‘ â€²
X
X
. Again, by Lemma 4 it
1 âˆ© ğ‘ â€²
ğ‘ â€²
2
ğ‘¡ â€²
(cid:75)
(cid:74)
âˆ’âˆ’âˆ’â†’ Eâ€², for some Eâ€², with ğ›¼ Â· ğ‘¡ â€² prefix of some

) = âŸ¨| ğ‘ â€²

2 |âŸ© P
X

, âŸ¨| ğ‘ â€²

)

2 |âŸ© P
X

We have proved items i) and ii), for any ğ‘ âˆˆ PropL. It remains to prove item iii) namely, if
ğœ†
âˆ’âˆ’âˆ’â†’ F, for some F. By Lemma 1 we
âŸ¨| ğ‘ |âŸ© P
Xâ€²

ğ›¼
âˆ’âˆ’âˆ’â†’ E then there is no ğœ† âˆˆ {âˆ’ğ›¼, ğ›¼ â€² â‰º ğ›¼ } such âŸ¨| ğ‘ |âŸ© P
Xâ€²

Runtime Enforcement of PLCs

37

have that âŸ¨| ğ‘ |âŸ© P

Xâ€² = Z, with Z = Eâ€² for
ğ›¼ğ‘– â‰º end.Eğ‘– + (cid:205)
ğ›¼â€²â€²âˆˆQ

Xâ€² = Eâ€² or âŸ¨| ğ‘ |âŸ© P
ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

(cid:205)
ğ‘–âˆˆğ¼
(cid:205)
ğ‘–âˆˆğ¼

Eâ€² =

ğ›¼ğ‘– .Eğ‘– + (cid:205)
ğ›¼ğ‘– .Eğ‘– + (cid:205)
ğ›¼â€²â€²âˆˆQ

ğ‘–âˆˆğ¼

âˆ’ğ›¼ â€²â€².Eâ€²â€², otherwise.

âˆ’ğ›¼ â€²â€².Eâ€²â€², if end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘–

ğ›¼
for ğ›¼ğ‘– âˆˆ P, Q = P \ (âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– âˆª {tick, end}), and Eğ‘– and Eâ€²â€² edit automata. Since âŸ¨| ğ‘ |âŸ© P
âˆ’âˆ’âˆ’â†’ E
Xâ€²
ğœ†
it follows that ğ›¼ = ğ›¼ğ‘˜ , for some ğ‘˜ âˆˆ ğ¼ . Let us assume by contradiction that âŸ¨| ğ‘ |âŸ© P
âˆ’âˆ’âˆ’â†’ F,
Xâ€²
for some ğœ† âˆˆ {âˆ’ğ›¼, ğ›¼ â€² â‰º ğ›¼ } and automata F. Since ğ›¼ = ğ›¼ğ‘˜ , with ğ‘˜ âˆˆ ğ¼ , we derive that ğ›¼ âˆ‰ Q =
P \ (âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– âˆª {tick, end}), that is ğœ† is an insertion, ğœ† = ğ›¼ â€² â‰º ğ›¼, for some ğ›¼ â€². As in Eâ€² the only insertions
are of the form ğ›¼ğ‘– â‰º end, it follows that ğ›¼ = end and end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– . However, since end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– it
follows that ğ›¼ = ğ›¼ğ‘˜ â‰  end. Contradiction.

Case ğ‘’ â‰¡ ğ‘’1 âˆ© ğ‘’2, for some ğ‘’1, ğ‘’2 âˆˆ PropG. This case can be proved with a reasoning similar to

ğ‘¡
âˆ’âˆ’â†’ ğ½ such that ğ‘¡ is a prefix of some trace in

that of the case ğ‘1 âˆ© ğ‘2.
- Inductive case: ğ‘› > 1, for ğ‘› âˆˆ N. Suppose ğ‘ƒ
ğ‘› > 1, ğ‘ƒ
then ğ‘¡ â€² is a prefix of some trace in

ğ‘¡ â€²
âˆ’âˆ’âˆ’â†’ ğ½ â€²

ğ›¼
âˆ’âˆ’âˆ’â†’ ğ½ , for some trace ğ‘¡ â€² such that ğ‘¡ = ğ‘¡ â€² Â· ğ›¼. As ğ‘¡ is a prefix of some trace in

(cid:75)
as well. Thus, by inductive hypothesis we have that:
âˆ’âˆ’âˆ’â†’ Eâ€², and either Eâ€² = âŸ¨| ğ‘ â€² |âŸ© P
X

(cid:75)
or Eâ€² = Z, with

(1) There exists a unique Eâ€² such that âŸ¨| ğ‘’ |âŸ© P ğ‘¡ â€²

Z = âŸ¨| ğ‘ â€² |âŸ© P
X

, for some ğ‘ â€² âˆˆ PropL and some automaton variable X.
such that ğ‘¡ â€² Â· ğ‘¡ â€²â€² is a prefix of some trace in

(2) There is a trace ğ‘¡ â€²â€² âˆˆ
(3) There is no trace ğ‘¡ â€²â€²â€² = ğ›¼1 Â· Â· Â· ğ›¼ğ‘˜ Â·ğœ† for âŸ¨| ğ‘’ |âŸ© P such that 0 â‰¤ ğ‘˜ < ğ‘›âˆ’1 and ğœ† âˆˆ {âˆ’ğ›¼ğ‘˜+1, ğ›¼ â€² â‰º ğ›¼ğ‘˜+1},

ğ‘ â€²
(cid:74)

ğ‘’
(cid:74)

ğ‘’
(cid:74)

(cid:75)

(cid:75)

(cid:75)

.

ğ‘’
(cid:74)

. Since
ğ‘’
(cid:74)

for some ğ›¼ â€².

Since from (1) Eâ€² is unique and either Eâ€² = âŸ¨| ğ‘ â€² |âŸ© P
or Eâ€² = Z, with Z = âŸ¨| ğ‘ â€² |âŸ© P
X
X
ğ›¼
âˆ’âˆ’âˆ’â†’ Eâ€²â€², and either Eâ€²â€² = âŸ¨| ğ‘ â€²â€² |âŸ© P
i) there exists a unique Eâ€²â€² such that âŸ¨| ğ‘ â€² |âŸ© P
X
Z = âŸ¨| ğ‘ â€²â€² |âŸ© P
such that ğ›¼ Â· ğ‘¡ â€² is a prefix of some trace in
ğ‘ â€²
(cid:74)
(cid:75)
for some F. These three facts can be proved as previously done for the base case, ğ‘› = 1.

Xâ€² , for some ğ‘ â€²â€² âˆˆ PropL and some automaton variable Xâ€²; ii) there is a trace ğ‘¡ â€² âˆˆ

, we have to prove:
Xâ€² or Eâ€²â€² = Z, with
ğ‘ â€²â€²
(cid:74)
(cid:75)
ğœ†
âˆ’âˆ’âˆ’â†’ F,
â–¡

; iii) there is no ğœ† âˆˆ {âˆ’ğ›¼, ğ›¼ â€² â‰º ğ›¼ }, such âŸ¨| ğ‘ â€² |âŸ© P
X

In order to prove Theorem 2 we need a couple of technical lemmata.

Lemma 5 (Soundness of the synthesis). Let ğ‘’ âˆˆ PropG be a global property and P be a set
ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ E be an arbitrary execution

of observable actions such that events(ğ‘’) âŠ† P. Let âŸ¨| ğ‘’ |âŸ© P
trace of the synthesised automaton âŸ¨| ğ‘’ |âŸ© P. Then,

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’ . . .

(1) for ğ‘¡ = out (ğœ†1) Â· . . . Â· out (ğœ†ğ‘›) the trace Ë†ğ‘¡ is a prefix of some trace in
(2) either E = âŸ¨| ğ‘ â€² |âŸ© P
X

or E = Z, with Z = âŸ¨| ğ‘ â€² |âŸ© P
X

;
(cid:75)
, for some ğ‘ â€² âˆˆ PropL and some automaton

ğ‘’
(cid:74)

variable X.

Proof. We proceed by induction on the length of the execution trace âŸ¨| ğ‘’ |âŸ© P

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’ . . .
ğœ†
âˆ’âˆ’âˆ’â†’ E. We proceed by induction on the structure of ğ‘’.

Base case: ğ‘› = 1. In this case, âŸ¨| ğ‘’ |âŸ© P

ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ E.

Case ğ‘’ â‰¡ ğ‘âˆ—, for some ğ‘ âˆˆ PropL. We prove by induction on the structure of ğ‘ the following two
results: i) for ğ›½ = out (ğœ†), Ë†ğ›½ is a prefix of some trace in
Xâ€² or E = Z, with
ğ‘
(cid:74)
Xâ€² , for some ğ‘ â€² âˆˆ PropL and some automaton variable Xâ€². As âŸ¨| ğ‘âˆ— |âŸ© P â‰œ X, for X = âŸ¨| ğ‘ |âŸ© P
Z = âŸ¨| ğ‘ â€² |âŸ© P
X
results i) and ii) imply the required results (1) and (2), for ğ‘’ = ğ‘âˆ—. We show the cases ğ‘ â‰¡ ğ‘1; ğ‘2 and
ğ‘ â‰¡ ğ‘1 âˆ© ğ‘2, the others cases are similar or simpler.
Let ğ‘ â‰¡ ğ‘1; ğ‘2 and âŸ¨| ğ‘1; ğ‘2 |âŸ© P
X
simpler. By definition, âŸ¨| ğ‘1; ğ‘2 |âŸ© P
X
from ğ‘1 â‰  ğœ– and âŸ¨| ğ‘1; ğ‘2 |âŸ© P
X

ğœ†
âˆ’âˆ’âˆ’â†’ E. We prove the two results i) and ii) for ğ‘1 â‰  ğœ–, the case ğ‘1 = ğœ– is
, and Zâ€² â‰  X. As a consequence,

, and ii) either E = âŸ¨| ğ‘ â€² |âŸ© P
(cid:75)

ğœ†
âˆ’âˆ’âˆ’â†’ E it follows that âŸ¨| ğ‘1 |âŸ© P
X

ğœ†
âˆ’âˆ’âˆ’â†’ E1, for some E1.

Zâ€², for Zâ€² = âŸ¨| ğ‘2 |âŸ© P

returns âŸ¨| ğ‘1 |âŸ© P

X

,

ğœ†

âˆ’âˆ’âˆ’â†’ E1, by inductive hypothesis we have that Ë†ğ›½ is a prefix of

â€¢ Let us prove i). Since âŸ¨| ğ‘1 |âŸ© P
X

some trace in

ğ‘1
(cid:74)

. Thus, Ë†ğ›½ is a prefix of some trace in
(cid:75)

, as required.

ğ‘1; ğ‘2
(cid:74)

(cid:75)

38

R. Lanotte, M. Merro, A. Munteanu

â€¢ Let us prove ii). Again, since âŸ¨| ğ‘1 |âŸ© P
X

or E1 = Z1, with Z1 = âŸ¨| ğ‘ â€²
us analyse E1 = âŸ¨| ğ‘ â€²
with Zâ€² = âŸ¨| ğ‘2 |âŸ© P
X
as required.

1 |âŸ© P

Zâ€² (the case E1 = Z1, with Z1 = âŸ¨| ğ‘ â€²

1 |âŸ© P
, by definition of the synthesis algorithm it follows that E1 = âŸ¨| ğ‘ â€²

ğœ†
âˆ’âˆ’âˆ’â†’ E1, by inductive hypothesis either E1 = âŸ¨| ğ‘ â€²

1 |âŸ© P
Zâ€²
1 âˆˆ PropL and some automaton variable Zâ€². Let
1 |âŸ© P
Zâ€²
,
1; ğ‘2 |âŸ© P
X

Zâ€², is similar). As E1 = âŸ¨| ğ‘ â€²

Zâ€², for some ğ‘ â€²

1 |âŸ© P

Let ğ‘ â‰¡ ğ‘1âˆ©ğ‘2 and âŸ¨| ğ‘1 âˆ© ğ‘2 |âŸ© P
X
returns Eğ‘ = ProdX (âŸ¨| ğ‘1 |âŸ© P
, âŸ¨| ğ‘2 |âŸ© P
X
X
â€¢ Result i) follows directly from Lemma 4.
â€¢ Let us prove ii). By inspection of the definition of cross product in Table 6, the most interesting

ğœ†
âˆ’âˆ’âˆ’â†’ E. By definition, the synthesis algorithm applied to âŸ¨| ğ‘1 âˆ© ğ‘2 |âŸ© P
X

). Let us prove the results i) and ii).

case is when âŸ¨| ğ‘1 |âŸ© P

X = (cid:205)ğ‘— âˆˆğ½ ğœˆ ğ‘— .Fğ‘— . In this case,
X = (cid:205)ğ‘– âˆˆğ¼ ğœ†ğ‘– .Eğ‘– and âŸ¨| ğ‘2 |âŸ© P
âˆ‘ï¸
âˆ‘ï¸
, âŸ¨| ğ‘2 |âŸ© P
(ğœ†ğ‘– .Xğ‘–,ğ‘— âŠ• ğœˆ ğ‘— .Xğ‘–,ğ‘— ) +

âˆ’ğ›¼ .Z

X ) =

Eğ‘ = ProdX (âŸ¨| ğ‘1 |âŸ© P
X

(ğ‘–,ğ‘—) âˆˆğ»

ğ›¼ âˆˆ Q

(ğ‘–,ğ‘—) âˆˆğ» {ğœ†ğ‘–, ğœˆ ğ‘— } and ğ» = {(ğ‘–, ğ‘—) âˆˆ ğ¼ Ã—ğ½ :
âˆ’ğ›¼ .Xğ‘–,ğ‘— }. Hence Eğ‘ has following

for Xğ‘–,ğ‘— = ProdP
Xğ‘–,ğ‘—
out (ğœ†ğ‘– ) = out (ğœˆ ğ‘— ) â‰  ğœ and ProdP
Xğ‘–,ğ‘—

(Eğ‘–, Fğ‘— ) and Q = (P\{tick, end})\ (cid:208)
(cid:205)
(Eğ‘–, Fğ‘— ) â‰ 
ğ›¼ âˆˆ P\{tick,end}
ğœ†
âˆ’âˆ’âˆ’â†’ Xğ‘–,ğ‘— , for ğœ† âˆˆ (cid:208)

(ğ‘–,ğ‘—) âˆˆğ» {ğœ†ğ‘–, ğœˆ ğ‘— }; (b) Eğ‘

âˆ’ğ›¼
two (families of) transitions: (a) Eğ‘
âˆ’âˆ’âˆ’âˆ’â†’ Z, for
ğ›¼ âˆˆ Q. We prove the result for the case (a); the case (b) can be proved in a similar manner.
Since ğœ† âˆˆ (cid:208)
(ğ‘–,ğ‘—) âˆˆğ» {ğœ†ğ‘–, ğœˆ ğ‘— } we have that ğœ† = ğœ†ğ‘– or ğœ† = ğœˆ ğ‘— , for some (ğ‘–, ğ‘—) âˆˆ ğ» . By defi-
ğœˆğ‘—
âˆ’âˆ’âˆ’â†’ Eğ‘— , with out (ğœ†ğ‘– ) =
nition of cross product, it holds that âŸ¨| ğ‘1 |âŸ© P
X
out (ğœˆ ğ‘— ) = out (ğœ†). Thus, by inductive hypothesis we have that: (1) either Eğ‘– = âŸ¨| ğ‘ â€²
or
Eğ‘– = Z1, with Z1 = âŸ¨| ğ‘ â€²
or Fğ‘— = Z2, with
1 |âŸ© P
X
2 âˆˆ PropL. Therefore, by definition of cross product we derive that
, for some ğ‘ â€²
2 |âŸ© P
Z2 = âŸ¨| ğ‘ â€²
X
ProdP
). Finally, by definition of our synthesis it follows
2 |âŸ© P
(Eğ‘–, Fğ‘— ) = ProdX (âŸ¨| ğ‘ â€²
Xğ‘–,ğ‘—
X
that ProdX (âŸ¨| ğ‘ â€²
1 |âŸ© P
2 |âŸ© P
2 |âŸ© P
1 âˆ© ğ‘ â€²
X
X
X
Case ğ‘’ = ğ‘’1 âˆ© ğ‘’2 for some ğ‘’1, ğ‘’2 âˆˆ PropG. This case can be proved with a reasoning similar to

1 âˆˆ PropL; (2) either Fğ‘— = âŸ¨| ğ‘ â€²

ğœ†ğ‘–âˆ’âˆ’âˆ’â†’ Eğ‘– and âŸ¨| ğ‘2 |âŸ© P

1 |âŸ© P
, âŸ¨| ğ‘ â€²
X
) = âŸ¨| ğ‘ â€²

, as required.

, for some ğ‘ â€²

1 |âŸ© P
X

2 |âŸ© P
X

, âŸ¨| ğ‘ â€²

X

that seen in the proof of case ğ‘1 âˆ© ğ‘2.

. . .

ğœ†ğ‘›âˆ’1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Eâ€²

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’ . . .
ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ E. Thus, by induction, we have that:

Inductive case: ğ‘› > 1, for ğ‘› âˆˆ N. Suppose âŸ¨| ğ‘’ |âŸ© P
ğœ†ğ‘›âˆ’1âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Eâ€²
(1) for ğ‘¡ â€² = out (ğœ†1) Â· . . . Â· out (ğœ†ğ‘›âˆ’1) the trace (cid:98)ğ‘¡ â€² is a prefix of some trace in
(2) either Eâ€² = âŸ¨| ğ‘ â€² |âŸ© P
or Eâ€² = Z, with Z = âŸ¨| ğ‘ â€² |âŸ© P
X
X
variables Z and X.
Since either Eâ€² = âŸ¨| ğ‘ â€² |âŸ© P
X
prove that given âŸ¨| ğ‘ â€² |âŸ© P
X
For that we resort to the proof of the base case.

or Eâ€² = Z, with Z = âŸ¨| ğ‘ â€² |âŸ© P
X
ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ E and ğ›½ğ‘› = out (ğœ†ğ‘›), it holds that Ë†ğ›½ğ‘› is a prefix of some trace in

, then to conclude the proof it is sufficient to
.
ğ‘ â€²
(cid:75)
(cid:74)
â–¡

, for some ğ‘ â€² âˆˆ PropL and some automaton

ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ E, for ğ‘› > 1. âŸ¨| ğ‘’ |âŸ© P

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’

, and

ğ‘’
(cid:74)

(cid:75)

In the next lemma, we prove that, given the execution traces of a monitored controller, we can
always extract from them the traces performed by its edit automaton and its monitored controller
in isolation.

Lemma 6 (Trace decomposition). Let E âˆˆ Edit be an edit automaton and ğ½ âˆˆ Ctrl be a
ğ›½ğ‘›
âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘› âŠ²âŠ³ {ğ½ğ‘› }, with E0 = E and ğ½0 = ğ½ ,
ğ›¼ğ‘–âˆ’âˆ’âˆ’âˆ’â†’ ğ½ğ‘– , with ğ›¼ğ‘– = trigger (ğœ†ğ‘– ), or

ğœ†ğ‘–âˆ’âˆ’âˆ’â†’ Eğ‘– , with ğ›½ğ‘– = out (ğœ†ğ‘– ), and (2) either ğ½ğ‘–âˆ’1

controller. Then, for any execution trace E0 âŠ²âŠ³ {ğ½0}
it hold that (1) Eğ‘–âˆ’1
ğ½ğ‘– = ğ½ğ‘–âˆ’1, for 1 â‰¤ ğ‘– â‰¤ ğ‘›.

ğ›½1
âˆ’âˆ’âˆ’âˆ’â†’ . . .

Proof. The transition Eğ‘–âˆ’1 âŠ²âŠ³ {ğ½ğ‘–âˆ’1}

ğ›½ğ‘–
âˆ’âˆ’âˆ’âˆ’â†’Eğ‘– âŠ²âŠ³ {ğ½ğ‘– }, for 1 â‰¤ ğ‘– â‰¤ ğ‘›, can be only derived by applying
one of the following rule: (Allow), (Insert), (Suppress). In the case of an application of rule (Allow),
ğ›¼ğ‘–âˆ’âˆ’âˆ’âˆ’â†’ğ½ğ‘– with ğ›½ğ‘– = ğ›¼ğ‘– = ğœ†ğ‘– . Hence,
Eğ‘–âˆ’1 âŠ²âŠ³ {ğ½ğ‘–âˆ’1}

ğ›½ğ‘–
âˆ’âˆ’âˆ’âˆ’â†’Eğ‘– âŠ²âŠ³ {ğ½ğ‘– } derives from Eğ‘–âˆ’1

ğ›¼ğ‘–âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘– and ğ½ğ‘–âˆ’1

Runtime Enforcement of PLCs

39

out (ğœ†ğ‘– ) = trigger (ğœ†ğ‘– ) = ğ›¼ğ‘– , as required. In the case of rule (Insert), Eğ‘–âˆ’1 âŠ²âŠ³ {ğ½ğ‘–âˆ’1}
ğ›¼ â‰ºğ›¼ğ‘–
from Eğ‘–âˆ’1
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘– and ğ½ğ‘–âˆ’1
and ğ½ğ‘– = ğ½ğ‘–âˆ’1, as required. Finally, in the case of rule (Suppress), Eğ‘–âˆ’1 âŠ²âŠ³ {ğ½ğ‘–âˆ’1}
âˆ’ğ›¼ğ‘–âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘– and ğ½ğ‘–âˆ’1
from Eğ‘–âˆ’1
trigger (ğœ†ğ‘– ) = ğ›¼ğ‘– , as required.

ğ›½ğ‘–
âˆ’âˆ’âˆ’âˆ’â†’Eğ‘– âŠ²âŠ³ {ğ½ğ‘– } derives
ğ›¼ğ‘–âˆ’âˆ’âˆ’âˆ’â†’ğ½ , for some ğ›¼ and ğ½ , with ğ›½ğ‘– = ğ›¼. Thus, out (ğœ†ğ‘– )=out (ğ›¼ â‰º ğ›¼ğ‘– ) = ğ›½ğ‘–
ğ›½ğ‘–
âˆ’âˆ’âˆ’âˆ’â†’Eğ‘– âŠ²âŠ³ {ğ½ğ‘– } derives
ğ›¼ğ‘–âˆ’âˆ’âˆ’âˆ’â†’ğ½ğ‘– , for some ğ›¼ğ‘– , with ğ›½ğ‘– = ğœ and ğœ†ğ‘– = âˆ’ğ›¼ğ‘– . Hence, out (ğœ†ğ‘– ) = ğœ and
â–¡

Proof of Theorem 2 (Soundness). Let ğ‘¡ = ğ›½1Â· . . . Â· ğ›½ğ‘› be a trace s.t. âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ }

ğ‘¡
âˆ’âˆ’â†’ E âŠ²âŠ³ {ğ½ },
for some E âˆˆ Edit and some controller ğ½ . By an application of Lemma 6 there exist Eğ‘– âˆˆ Edit
ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ Eğ‘› = E, with ğ›½ğ‘– = out (ğœ†ğ‘– ). Thus,
and ğœ†ğ‘– , for 1 â‰¤ ğ‘– â‰¤ ğ‘›, such that: âŸ¨| ğ‘’ |âŸ© P
ğ‘¡ = out (ğœ†1) Â· . . . Â· out (ğœ†ğ‘›). By Lemma 5, Ë†ğ‘¡ is a prefix of some trace in
â–¡
, as required.

ğœ†2âˆ’âˆ’âˆ’âˆ’â†’ . . .

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’ E1

Proof. Given an arbitrary execution âŸ¨| ğ‘’ |âŸ© P

Lemma 7 (Deadlock-freedom of the synthesis). Let ğ‘’ âˆˆ PropG be a global property and P
be a set of observable actions s.t. events(ğ‘’) âŠ† P. Then the edit automaton âŸ¨| ğ‘’ |âŸ© P does not deadlock.
ğœ†ğ‘›âˆ’âˆ’âˆ’âˆ’â†’ E, the proof is by induction on the
or
, for ğ‘ âˆˆ PropL and some automaton variable X. Hence, the result follows
â–¡

length ğ‘› of the execution trace. By an application of Lemma 5 we have that either E = âŸ¨| ğ‘ |âŸ© P
X
E = Z, with Z = âŸ¨| ğ‘ |âŸ© P
X
by inspection of the synthesis function of Table 5 and by induction on the structure of ğ‘.

ğœ†1âˆ’âˆ’âˆ’âˆ’â†’ . . .

ğ‘’
(cid:74)

(cid:75)

Proof of Theorem 3 (Deadlock-freedom). Let ğ‘¡ be a trace such that âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ }

ğ‘¡
âˆ’âˆ’â†’ E âŠ²âŠ³ {ğ½ },
for some edit automaton E and controller ğ½ . By contradiction we assume that E âŠ²âŠ³ {ğ½ } is in deadlock.
Notice that, by definition, our controllers ğ½ never deadlock. By Lemma 7 the automaton âŸ¨| ğ‘’ |âŸ© P
ğ›¼
never deadlock as well. Consequently, we have that for any transition ğ½
âˆ’âˆ’âˆ’â†’ ğ½ â€² there is no action ğœ†
for E, such that the monitored controller E âŠ²âŠ³ {ğ½ } may progress according to one of the rules: (Allow),
or E = Z, with
(Suppress) and (Insert). By an application of Lemma 5, we have that either E = âŸ¨| ğ‘ |âŸ© P
X
, for some ğ‘ âˆˆ PropL and some automaton variable X. Now, by Lemma 1, we have that
Z = âŸ¨| ğ‘ |âŸ© P
X

âŸ¨| ğ‘ |âŸ© P

X =

ğ›¼ğ‘– .Eğ‘– + (cid:205)
ğ›¼ğ‘– .Eğ‘– + (cid:205)

ğ‘–âˆˆğ¼

ğ›¼ âˆˆQ

(cid:205)
ğ‘–âˆˆğ¼
(cid:205)
ğ‘–âˆˆğ¼

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

ğ›¼ğ‘– â‰º end.Eğ‘– + (cid:205)

âˆ’ğ›¼ .F, if end âˆ‰ âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘–

ğ›¼ âˆˆQ

âˆ’ğ›¼ .F, otherwise.

â„.ğ‘†, for 0 < â„ â‰¤ ğ‘˜. Since tick-actions cannot be suppressed, we have that ğ‘¡ = ğ‘¡ â€² Â· tick

for ğ›¼ğ‘– âˆˆ P, Q = P \ (âˆªğ‘– âˆˆğ¼ ğ›¼ğ‘– âˆª {tick, end}), and Eğ‘– and F edit automata. In both the cases âŸ¨| ğ‘ |âŸ© P
may
X
only deadlock the enforcement when the controller may only perform tick-actions. From this fact, we
ğ‘˜âˆ’â„,
derive ğ½ = tick
for some possibly empty trace ğ‘¡ â€² terminating with an end. By Theorem 2, ğ‘¡ = ğ‘¡ â€² Â· tick
. And
â„.ğ‘ â€², for some ğ‘ â€². Since âŸ¨| ğ‘’ |âŸ© P is sound (Lemma 5) we derive
since ğ‘’ is ğ‘˜-sleeping we derive ğ‘ = tick
tickâˆ’âˆ’âˆ’âˆ’âˆ’â†’ Eâ€², for some Eâ€², in contradiction
that E = âŸ¨| ğ‘ |âŸ© P
X = âŸ¨| tick
â–¡
with what stated four lines above.

. Finally, â„ > 0 implies E

â„.ğ‘ â€² |âŸ© P
X

ğ‘˜âˆ’â„ âˆˆ

ğ‘’
(cid:74)

(cid:75)

Proof of Theorem 4 (Divergence-freedom). Let ğ‘’ âˆˆ PropG be a global property in its gen-
eral form, given by the intersection of ğ‘› â‰¥ 1 global properties ğ‘âˆ—
ğ‘›, for ğ‘ğ‘– âˆˆ PropL,
with 1 â‰¤ ğ‘– â‰¤ ğ‘›. As ğ‘’ is well-formed, according to Definition 4 also all local properties ğ‘ğ‘– are
well-formed. This means that they all terminate with an end event. Thus, in all global properties
ğ‘– , for 1 â‰¤ ğ‘– â‰¤ ğ‘›, the number of events within two subsequent end events is always finite. The
ğ‘âˆ—
ğ‘¡
same holds for the property ğ‘’. Now, let ğ‘¡ be an arbitrary trace such that âŸ¨| ğ‘’ |âŸ© P âŠ²âŠ³ {ğ‘ƒ }
âˆ’âˆ’â†’ E âŠ²âŠ³ {ğ½ },
for some edit automaton E and controller ğ½ . And let ğ‘˜ = max1â‰¤ğ‘– â‰¤ğ‘›ğ‘˜ğ‘– , where ğ‘˜ğ‘– is the length of the
ğ‘¡ â€²
âˆ’âˆ’âˆ’â†’ Eâ€² âŠ²âŠ³ {ğ½ â€²}, with | ğ‘¡ â€² |â‰¥ ğ‘˜, and since by
, for 1 â‰¤ ğ‘– â‰¤ ğ‘›. Thus, if E âŠ²âŠ³ {ğ½ }
longest trace of
â–¡
Theorem 2 we have that ğ‘¡ Â· ğ‘¡ â€² is a prefix of some trace
ğ‘’
(cid:74)

, then end âˆˆ ğ‘¡ â€².

1 âˆ© Â· Â· Â· âˆ© ğ‘âˆ—

ğ‘ğ‘–
(cid:74)

(cid:75)

(cid:75)

