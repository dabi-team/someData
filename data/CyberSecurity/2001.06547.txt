0
2
0
2

n
a
J

7
1

]

Y
C
.
s
c
[

1
v
7
4
5
6
0
.
1
0
0
2
:
v
i
X
r
a

Predictability limit of partially observed systems

Andr´es Abeliuk,1 Zhishen Huang,2 Emilio Ferrara,1

∗ Kristina Lerman,1

∗

1Information Sciences Institute, University of Southern California, Marina del Rey, CA, 90292, USA
2University of Colorado Boulder, Boulder, CO, 80302, USA

∗To whom correspondence should be addressed; E-mail: emiliofe@usc.edu, lerman@isi.edu

Applications from ﬁnance to epidemiology and cyber-security require accu-

rate forecasts of dynamic phenomena, which are often only partially observed.

We demonstrate that a system’s predictability degrades as a function of tem-

poral sampling, regardless of the adopted forecasting model. We quantify the

loss of predictability due to sampling, and show that it cannot be recovered by

using external signals. We validate the generality of our theoretical ﬁndings

in real-world partially observed systems representing infectious disease out-

breaks, online discussions, and software development projects. On a variety of

prediction tasks—forecasting new infections, the popularity of topics in online

discussions, or interest in cryptocurrency projects—predictability irrecover-

ably decays as a function of sampling, unveiling fundamental predictability

limits in partially observed systems.

1

 
 
 
 
 
 
Introduction

Forecasting complex dynamic phenomena — from inﬂuenza outbreaks to public opinions, stock

market, and cyberattacks — is central to many policy and national security applications (1). Pre-

diction is also the standard framework in evaluating models of complex systems learned from

data (2). Time series forecasting, which underpins popular models of dynamic phenomena,

represents a process as a sequence of observations (discrete or continuous numbers of events)

at regular time intervals. After learning parameters from past observations, the models can

be used to predict future observations (3). Forecasting models based on stochastic and self-

exciting point processes, autoregressive and hidden Markov models, have been developed to

predict crime (4, 5), social unrest (6), terrorism (7), epidemics (8), human mobility (9), per-

sonal correspondence (10), online activity (11,12), dynamics of ecological systems (13,14) and

more (15).

A fundamental challenge to modeling efforts is the fact that complex systems are seldom

fully observed. For example, when estimating opinions in a social system, it is not practical

nor feasible to interview every individual in the population; instead, polling is used to elicit

responses from a representative sample of a population. When social media is used as a proxy

of opinions, it is similarly impractical to collect all relevant posts; instead, a (pseudo-random)

sample (e.g., the Twitter Decahose), is often used. Further biases can emerge when data is

deliberately manipulated or deleted, e.g., to obfuscate or censor content or activity (16). In

short, the data used to learn predictive models of complex phenomena often represents a highly

ﬁltered and incomplete view.

How does data loss due to sampling affect the predictability of complex systems and the ac-

curacy of models learned from the data? Statisticians have developed a number of approaches

to compensate for data loss, including data imputation (17) to ﬁll in missing values and evalu-

2

ating the representativeness of the sample (18, 19). Few of these approaches apply to temporal

data. To quantify the predictability of dynamic systems, researchers use measures such as au-

tocorrelation and permutation entropy. The former measures similarity between a time series

and its own time-lagged versions. Recently, permutation entropy was introduced as a model-

free, nonlinear indicator of the complexity of data (20, 21). Permutation entropy represents the

complexity of a time series through statistics of its ordered sub-sequences, also known as mo-

tifs, and has been adopted to model predictability of ecological systems (13, 22) and epidemic

outbreaks (8). However, the impact of sampling on these measures of predictability of complex

systems is not known.

As the ﬁrst step towards addressing this question, we model incomplete observation as a

stochastic sampling process that selects events at random with some probability p and drops the

remaining events from observations of a system. This allows us to theoretically characterize

how sampling decreases the autocorrelation of a time series. We then empirically show that

sampling also reduces the predictability of a dynamic process according to both autocorrelation

and permutation entropy. Moreover, the loss of predictability cannot be fully recovered from

some external signal, even using data highly correlated with the original unsampled process. As

a result, forecasts made by autoregressive models may be no better than predictions of simpler,

less accurate models that assume independent events. We validate these ﬁndings with both

synthetic and real-world data representing complex social and techno-social systems. Without

any modeling assumptions on the data, we show how sampling systematically degrades the

predictability of these systems.

Researchers increasingly predict complex systems and social network dynamics (1,2,23,24)

to learn the principles of human and machine behavior (25, 26). Practitioners and lawmakers

alike often base their decisions on such insights (27, 28), including for public health (29, 30)

and public policy (31–34). As some pointed out (35, 36), however, caution should be used

3

when drawing conclusions from incomplete data. Sampling, even random sampling, distorts

the observed dynamics of a process, reducing its predictability. We formalize and quantify this

common, yet understudied, source of bias in partially observed systems.

Results

Model

Consider a dynamic process generating events, for example, social media posts mentioning a

particular topic, or newly infected individuals during an epidemic. We can represent the process

as a time series of event counts, X = [X1, X2, . . . , XT ], each entry representing the number of

observations of X at time t. We refer to this time series as the ground truth signal.

Observers of this process may not see all events. Twitter, for example, makes only a small

fraction (

≤

10%) of messages posted on its platform programmatically available. Similarly,

hospitals may delay reporting new cases of a disease or under-count them altogether when, for

various reasons, people do not seek medical help after getting sick. We refer to the time series of

observed events Y = [Y1, Y2, . . . , YT ] as the observed signal. Intuitively, Y represents a sample

of events present in the ground truth signal X.

We model partial observation as a stochastic sampling process, where each event has some

probability to be observed, independent of other events. This allows us to formalize how the

time series of the ground truth and the observed signals are related. Figure 1 illustrates this

paradigm.

Deﬁnition 1. We deﬁne sampling rate p

∈

[0, 1] as the percentage of events that are preserved

by the observation process. Let X and Y be two time series related by

B([X], p),

Y

∼

where B([X], p) is a Binomial process with [X] trials, each with success probability p.

4

Figure 1: Sampling paradigm as a representation of a partially observed dynamic process. Here,
X, the ground truth signal, represents the actual events, e.g., Twitter posts mentioning a par-
ticular topic; Y represents the observed subset of events. The funnel illustrates the sampling
process. The probability of an event being observed is p. The Binomial distribution B(X, p) is
used to model the observed signal Y .

The factors driving the system may also produce some external events that may help predict

the observed system. For example, rising temperatures associated with climate change may

help better forecast epidemics that are made more virulent by changes in climate. Similarly,

news reports may be associated with increased social media posts on speciﬁc topics, since both

are driven by world events. Temperatures and news reports may provide important signals for

predicting future events.

Deﬁnition 2. We deﬁne the external signal as the time series S = S1, S2, . . . , ST that may

provide information about the ground truth signal.

Quantifying the Loss of Predictability

Researchers have devised measures of predictability of complex systems. At the simplest level,

autocorrelation captures how well a time series representing a complex system is correlated

with its own time-lagged versions. This indicator of predictability is popular in ﬁnance (37).

In ecology and physics, permutation entropy is used to measure predictability (13, 38). Per-

5

mutation entropy (PE) captures the complexity of a time series through statistics of its ordered

sub-sequences, or motifs (see Materials & Methods). The higher the permutation entropy, the

more diverse the motifs, which in turn renders the time series less predictable. Permutation

entropy was shown to be strongly related to Kolmogorov-Sinai (KS) entropy (39), a theoretical

measure quantifying the complexity of a dynamical system. KS is not easy to reliably estimate

from data; however, for one dimensional time-series, KS and permutation entropy are known to

be equivalent under a variety of conditions (20). Using different forecasting models, Garland

et al. (13) demonstrated an empirical correlation between predictability of the models and per-

mutation entropy (21). Since then, PE has been used as a model-free indicator of predictability

of infectious disease outbreaks (8), human mobility (9), ecological systems (22), and anomaly

detection in paleoclimate records (14). Besides autocorrelation and PE, we also use prediction

error as a measure of predictability (13). However, since prediction error depends on the fore-

casting model, we explore it in detail only with synthetic data (SI, Synthetic Data Experiments).

We show that sampling reduces predictability of a signal, and the more data is ﬁltered out,

the less predictable the signal becomes. The loss of predictability cannot be recovered using an

informative external signal, even if it is highly correlated with the original ground truth signal.

We develop a framework for quantifying predictability loss due to sampling and validate it

empirically using all measures of predictability.

Our main theoretical contribution is an analytical characterization of the covariance matrix

of the observed signal Y in terms of the ground truth signal X and the sampling rate p (cf.,

Materials & Methods, Theorem 1). Theorems and their proofs are presented in the SI. Based on

this characterization, we derive two results stating the effects of sampling on the predictability

of the observed signal Y :

Decay of autocorrelation of the observed signal. The autocorrelation (deﬁned as Pearson cor-

relation between values of the signal at different times) of the observed signal Y decays

6

monotonically at lower sampling rates (Corollary 2, Materials & Methods).

Decay of covariance with the external signal. The correlation between the observed and ex-

ternal signals degrades linearly at lower sampling rates (Corollary 3, Materials & Meth-

ods).

Speciﬁcally, to quantify the impact of sampling on the predictability of a signal, we ﬁrst

derive the autocorrelation of the observed signal as a function of the sampling rate p (cf., Corol-

lary 1, Materials & Methods). When p = 1 (i.e., complete observation), we recover the auto-

correlation of the ground truth signal X. At lower sampling rates, the autocorrelation decays as

postulated above. In parallel, we demonstrate empirically that sampling degrades predictability

as measured using permutation entropy.

A forecasting model may compensate for the loss of predictability by leveraging an infor-

mative external signal. For example, auto-regressive forecasting models allow for additional

covariates to improve predictions (40). However, according to our second result, predictability

cannot be fully recovered with an external signal, even one that is highly correlated with the

ground truth signal.

Empirical Results

We show that sampling irreversibly degrades the predictability of real-world complex systems,

studying three phenomena: disease outbreaks, online discussions, and software collaborations.

Sampling reduces predictability according to both autocorrelation and permutation entropy

measures, and the observed decay of autocorrelation agrees with theoretical predictions.

Predictability cannot be fully recovered using an informative external signal. In addition to

co-variance, we use mutual information (MI) to measure the shared information between the

external and the observed signals (41). Mutual information quantiﬁes the reduction in uncer-

tainty about one random variable due to the presence of another (42), and like PE it captures the

7

non-linearities in the data that covariance cannot measure. We empirically ﬁnd that sampling

reduces both the covariance and MI with the external signal.

Epidemics. Scarpino & Petri (8) used permutation entropy to show that predictability of dis-

ease outbreaks decreases over longer time periods, suggesting changes in the behavior of epi-

demics over time. Here, we show that the predictability of epidemics is also affected by how

partially or fully observed the new infections are.

We study eight diseases (Chlamydia, Gonorrhea, Hepatitis A, Inﬂuenza, Measles, Mumps,

Polio, and Whooping cough), representing each disease outbreak as a time series of the weekly

number of reported infections in each US state. We ﬁnd that at lower sampling rates, the permu-

tation entropy (PE), over one-year moving windows (although the results are robust to longer

windows, see SI Figure 17), of the times series increases (Figure 2 (top-left)) and the auto-

correlation decreases (Figure 2 (top-right)). Given that each disease has a different base PE

and autocorrelation coefﬁcient (see SI, Figures 14 and 15 for the absolute values), we normal-

ized the predictability measure of the sampled time series by the corresponding measure of the

ground truth time series (i.e., with full information, corresponding to sampling rate p = 1) to

capture the relative change. The observed loss of autocorrelation for each disease outbreak at

different sampling rates (Figure 2 (bottom)) agrees well with the theoretical predictions derived

by Equation 3. Our ﬁndings suggest that observing only a subset of the new infections distorts

the observed dynamics of the disease, making the outbreak less predictable.

8

Figure 2: Loss of predictability of disease outbreaks due to sampling. The plots show a decrease
in permutation entropy (top-left) and an increase in autocorrelation (top-right) of the outbreak
time series for increasing sampling rates. For each of the eight diseases, we selected 100 random
one-year time windows and calculated the relative weighted permutation entropy and autocor-
relation for different sampling rates over that window. The solid line represents the median ratio
across all states between the original time series and the sampled one; shaded regions mark the
inter-quartile ranges. The bottom plot supports our theoretical results by plotting Equation 3
against the empirical autocorrelation of the sampled time series at different sampling rates for
each disease.

9

0.00.20.40.60.81.0Sampling rate0.91.01.11.21.31.4Relative Permutation Entropy (HP/HP0)HepatitisInfluenzaMeaslesChlamydiaPolioMumpsWhooping0.00.20.40.60.81.0Sampling rate0.20.40.60.81.0Relative Autocorrelation (/0)HepatitisInfluenzaMeaslesChlamydiaPolioMumpsWhooping0.00.20.40.60.81.0Theoretical Autocorrelation 0p2Var(X)p2+p(1p)E[X]0.00.20.40.60.81.0Empirical Autocorrelation ()HepatitisInfluenzaMeaslesMumpsWhoopingChlamydiaPolioFigure 3: Decay of covariance between ground truth and external signals. For each state, we
selected 100 random one-year time windows and calculated the median covariance (left) and
Pearson’s correlation (right) between Google Flu trends and the inﬂuenza activity at different
sampling rates. Shaded regions mark the inter-quartile ranges for each state; the solid line
represents the average coefﬁcient across all states.

Next, we use inﬂuenza data to validate Corollary 3, which states that an external signal

becomes less informative (i.e., has lower covariance) about the ground truth data at lower sam-

pling rates. As an external signal S, we use state-level Google Flu trends (43), which estimate

inﬂuenza activity based on search queries. Figure 3 (left) shows a linear growth of covariance

for each state’s inﬂuenza time series with increasing sampling rate. However, as depicted on the

right plot, there is no observed loss of correlation for lower sampling rates. This is due to the

large variance relative to the mean exhibited by inﬂuenza activity. From Theorem 1, we have

that the standard deviation of the observed signal Y is

(cid:112)

σY =

p2Var(X) + p(1

p)E[X]

−

p σX

≈

when Var(X)

(cid:29)

E[X]. Then, it follows from Corollary 3 and the deﬁnition of Pearson’s

10

0.00.20.40.60.81.0Samplingrate0.00.20.40.60.8Covariance(Cov(Y,S))×1070.00.20.40.60.81.0Samplingrate0.10.20.30.40.50.60.70.8Pearson’scorrelationcorrelation ρ, that

ρY,S =

Cov(Y, S)

σY σS ≈

p Cov(X, S)
p σXσS

= ρX,S.

Thus, the linear decrease of covariance is offset by a linear decrease of the standard devia-

tion. However, this is not always the case, as we later show with the cryptocurrency popularity

scenario.

Supplementary Figure 16 shows that mutual information between Google Flu Trends and

inﬂuenza activity also decreases, suggesting that the former becomes less informative about

inﬂuenza activity the more it is sampled.

Social Media. Next we consider the problem of predicting social media activity. We analyze

the popularity of hashtags on Twitter, deﬁned as the daily number of posts using that hashtag.

We focus on the 100 most frequently used hashtags in our data (cf., Material & Methods), and

for each hashtag, we sample from all posts mentioning the hashtag several times at different

rates to produce multiple sampled time series.

11

Figure 4: Empirical and theoretical effects of sampling on autocorrelation of hashtag popularity.
(left) Median autocorrelation relative to the original time series for 100 most popular hashtags;
shaded regions mark the inter-quartile ranges; the black line represents the average autocorre-
lation across all hashtags. (right) Accuracy of the theoretical prediction according to Equation
3.

Figure 4 (left) shows the effects of sampling at different rates on the autocorrelation of hash-

tags’ popularity. The plot shows the median autocorrelation loss relative to the original time

series. For each ground truth signal, we found the most signiﬁcant autocorrelation time lag,

which is kept ﬁxed during the down sampling process to calculate autocorrelation at different

sampling rates; then, we plotted the median ratio between the original and sampled autocor-

relation. Although the curvatures are different for each hashtag, all time series are accurately

characterized by our theoretical results (Equation 3): Figure 4 (right) shows that the empirical

loss of autocorrelation ﬁts the theoretical predictions. Figure 21 (SI) reports the results for the

sampled time series of Twitter user activity, measured by the daily number of user’s posts.

The loss of predictability is also seen when using permutation entropy with the same sam-

pling strategy. Figures 18 and 19 (SI) show a clear trend in entropy increase (i.e., decrease of

predictability) for both user activity and popularity of hashtags. The loss of predictability for

12

0.00.20.40.60.81.0Sampling rate0.20.40.60.81.0Relative Autocorrelation (/0)0.20.40.60.81.0Theoretical Autocorrelation p2Var(X)p2+p(1p)E[X]0.20.30.40.50.60.70.80.91.0Empirical Autocorrelation (/0)user activity, for instance, happens in 63% of the users, while the rest of the cases comprise of

time-series whose PE mostly do not change, except for low sampling rates (see Figure 20 (SI)).

Note that, in many applications, researchers use data from the Twitter Decahose or the

streaming API, which capture approximately 10% and 1% sample of tweets, i.e., sampling

rates of 0.1 and 0.01 respectively (18). Considering that, at such low sampling rates, relative

autocorrelation may be half of its value using the complete Twitter stream (Firehose), care

should be taken when drawing conclusions from the partially observed system.

Cryptocurrency Popularity. We present additional ﬁndings regarding loss of correlation be-

tween a sampled time series and an external signal. We study the effect of the price of cryp-

tocurrencies on the adoption of said technology by software developers. To measure interest

in the technology behind a cryptocurrency, we track the popularity of Github projects whose

description is associated to that cryptocurrency. The four most popular cryptocurrencies dur-

ing the collection period spanning January 2015 to March 2015 were Bitcoin (BTC), Litecoin

(LTC), Monero (XMR) and Ripple (XRP). Some cryptocurencies, like Ethereum, were also

popular, but since they were not yet publicly launched, we excluded them from the following

analysis.

Figure 5 explores the effect that sampling has on the correlation. The left plot shows a

clear decrease in the relative covariance for lower sampling rates, corroborating our theoretical

results. As opposed to the behavior of inﬂuenza outbreaks (cf., Fig. 3), in Figure 5 (Right) we

can see that a decay of covariance tends to induce a loss of correlation, especially for those

coins with low variance relative to their mean. Supplementary Figure 22 depicts a decrease in

mutual information for BTC and LTC, while the other two coins are independent of the external

signal.

13

Figure 5: Loss of correlation between cryptocurrencies repository popularity and their prices for
different sampling rates. Each point is the median Pearson’s correlation coefﬁcient over 1000
samples. Error bars show the standard deviation. For each cryptocurrency, we calculated over
the 1000 samples, (left) the median normalized covariance Cov(Y,S)
Cov(X,S) and (right) the Pearson’s
correlation coefﬁcient between the price and the popularity of related Github repositories at
different sampling rates. Shaded regions mark the inter-quartile ranges for each coin.

Synthetic Data. Finally we investigate the impact of sampling on the predictability of syn-

thetic data generated by an auto-regressive process (SI, Synthetic Data Experiments). In addi-

tion to autocorrelation and permutation entropy, we measure the error of forecasts made by an

auto-regressive model trained on the sampled data. Similar to other metrics that demonstrate

a loss of predictability, prediction error grows at lower sampling rates (SI, Figure 7). As a re-

sult, the forecasts made by auto-regressive models from data collected at low sampling rates

are no more accurate than forecasts made by a Poisson model that assumes independent events.

Sampling further distorts the observed dynamics of the auto-regressive process by introducing

heteroskedasticity into the sampled time series. The time-varying variance causes predictions

to deteriorate (SI, Synthetic Data Experiments, Proposition S2).

14

0.00.20.40.60.81.0Sampling rate0.00.20.40.60.81.01.2Normalized Covariance Cov(Y,S)Cov(X,S)BTCLTCXMRXRP0.00.20.40.60.81.0Sampling rate0.050.100.150.200.250.300.35Pearson's CorrelationBTCLTCXMRXRPMaterials and Methods

Permutation Entropy (PE). We use permutation entropy as a model-free measure of pre-

dictability of a time series (13, 21, 38). Permutation entropy captures the complexity of a time

series via statistics of its ordered sub-sequences of the type s = [xt, xt+τ , . . . , xt+(d−1)τ ], given

embedding dimension d and a temporal delay τ . Let

d,τ be the collection of all d! permutations

S

π of size d and temporal delay τ . For each π

d,τ , we determine the relative frequency P (π)

∈ S

of that permutation occurring in the time series. The permutation entropy of order d

delay τ

≥

1 is deﬁned as

H P(d, τ ) =

(cid:88)

−

π∈Sd,τ

P (π) log2 P (π)

2 and

≥

(1)

We use weighted permutation entropy (21) to lessen the inﬂuence of observational noise on the

ordinal pattern of the signal, in which weights with respect to a sub-sequence with a certain

ordinal pattern are introduced to reﬂect the importance of ordinal changes in large amplitudes.

Finally, we normalize weighted permutation entropy by dividing it by log2(d!), log of the num-

ber of possible permutations. See SI, Permutation Entropy Criterion, for a formal deﬁnition.

To estimate PE of a time series we need to specify the order d and time delay τ . The optimal

parameters will depend on the speciﬁc properties of the time series, for example, the periodic

behavior of the system relates to the delay parameter (44). Here, we follow the approach de-

scribed in (8), which performs a grid search over the pairs (d, τ ), 2

d

≤

≤

5 and 1

τ

≤

≤

7

searching for the values that minimize H P(d, τ ). However, for the parameter search, PE is nor-

malized by the number of observed permutations instead of the possible permutations, given

that otherwise, H P(d, τ ) is decreasing as a function of d. Finally, the parameters found for each

ground truth signal are used to compute the PE of the corresponding sampled time series.

15

Mutual Information Mutual information characterizes the amount of information one ran-

dom variable contains about another, speciﬁcally capturing the reduction in the uncertainty of

one random variable due to the knowledge of the other. The mutual information between two

random variables is deﬁned as I(X; Y ) = Ep(x,y) ln

p(X, Y )
p(X)p(Y )

.

Here we consider the mutual information between two time series. We calculate the mutual

information between two time series with PyInform (45).

Loss of autocorrelation of the Sampled Signal. Our ﬁrst theoretical result shows that sam-

pling reduces the auto-covariance of the observed signal, i.e., the covariance of the time series

Y and its time-lagged version.

Theorem 1. The time series X, Y are related by Y

B([X], p), where B([X], p) is a Bernoulli

∼

random process with success rate p.

The covariance matrices ΣX and ΣY are related as

ΣY = p2ΣX + p(1

p)E[X]I

−

(2)

where I is the identity matrix.

We can use the expression in Theorem 1 to approximate the autocorrelation of the sampled

time series Y as a function of the ground truth signal X. Autocorrelation is deﬁned as Pearson

correlation between values of the signal at different times, i.e., ρXi,Xj = Cov(Xi,Xj )

σXi σXj

. For sake of

simplicity, we assume that the ground truth process is stationary.

Corollary 1. The autocorrelation of sampled time series Y is

p2Cov(Xi, Xj)

ρYi,Yj ≈

p2Var(X) + p(1

p)E[X]

.

(3)

of the observed signal Y , increases

Corollary 2. The magnitude of autocorrelation

−
ρYi,Yj |
|
monotonically as a function of the sampling rate p.

16

Corollary 3. The covariance between the observed signal Y and an arbitrary external signal

S is related to the covariance between the ground truth signal X and the same external signal

S by,

Cov(Y, S) = p Cov(X, S).

(4)

Epidemics Data. Weekly state-level data for all diseases was obtained from Scarpino & Petri

(8) and originally compiled by the USA National Notiﬁable Diseases Surveillance System (see

SM, Table 1 for statistics of the data). For the covariance experiment, we used inﬂuenza data

from 2010-2015 obtained for the US Outpatient Inﬂuenza-like Illness Surveillance Network

(ILINet) that overlaps with Google Flu Trends Data.

Twitter Data. The social media data used in this study was collected from Twitter in 2014.

Starting with a set of 100 users who were active discussing ballot initiatives during the 2012

California election, we expanded this set by retrieving the accounts of the users they followed,

for a total of 5,599 seed users. We collected all posts made by the seed users and their friends

(i.e., users they followed on Twitter) over the period of June–November 2014, a total of over

600 thousand users. We extracted time series of the activity for 100 most popular hashtags and

150 most active users in this data (see SM, Tables 2 and 3 for statistics of the data).

GitHub Data. The GitHub data we analyzed contains anonymized records of user activities

over a time period spanning from January 1st, 2015 to March 31st, 2015. The activities rep-

resent the actions users performed on the repositories, including watching the repositories to

receive notiﬁcations about project activity. We used watches, forks, and create event activity as

a measure of popularity of a repository in Github. Overall, our dataset captures 43, 962 Github

activity events by 5, 509 users on 2, 036 repositories (see Supplementary Information (SI), Ta-

ble 4 for additional statistics). Cryptocurrencies’ historical prices were obtained from publicly

17

available Kaggle datasets.

Discussion

We presented a framework to analyze the effects of partial observation of a dynamic process,

showing that sampling degrades the predictability of the process. Using empirical data from

three domains, namely epidemics, social systems, and software collaborations, we highlighted

how this fundamental predictability limit affects the forecasting of disease outbreaks, social

media content popularity, and emergence of cryptocurrency technologies. We showed that even

when events making up the temporal signal are sampled at random, sampling qualitatively

changes the observed dynamics of the process, decreasing the autocorrelation and increasing

permutation entropy. Moreover, the predictability loss is irreversible: even a highly informative

external signal does not help to fully recover predictability lost to sampling. These ﬁndings

were corroborated by experiments on synthetic data.

Our work is motivated by applications requiring the forecasting of partially observed, or

sampled, complex systems. Such situations may occur, for example, when country-wide fore-

casts of inﬂuenza have to be made based on reports by a few hospitals; when longitudinal opin-

ion polls of a population are used to predict an election; or when researchers avail of random

samples of social media activity to characterize complex social dynamics. Beyond prediction,

models learned from data can also elucidate social behaviors (2). Scientists developed tech-

niques for temporal data analysis, based on anomaly detection (46) and regression discontinuity

design (47), to uncover natural experiments that yield insights into the mechanisms of human

decision making. As we showed in this paper, however, these techniques may be systemati-

cally biased by temporal sampling. It is, therefore, imperative to account for potential sampling

biases in the study of social dynamics, so that no results are erroneously attributed to the phe-

nomena under study. Thus, it is important for future research to focus on statistical tools and

18

sampling methods that can correct for these possible biases.

Our work suggests that partial observability not only diminishes the predictability of a dy-

namic process, but also introduces a source of heterogeneous random noise that can potentially

mislead causal inference methods and threaten their validity. For example, interrupted time se-

ries (ITS) analyses is one of the most widely applied approaches to evaluate natural experiments

in health interventions (48). ITS consists of a sequence of counts over time, with one or more

well-deﬁned change points that correspond to the introduction of an intervention. The effect of

the intervention can be estimated by ﬁtting a linear regression model with a dummy variable for

the before/after intervention, and additional variables to control for time-varying confounders.

Only recently, researches have addressed methodological issues associated with ITS analysis

caused by over-dispersion of time series data and autocorrelation (49). For instance, a study

estimating the impact of a ban on the offer of multipurchase discounts by retailers in Scotland,

found a 2% decrease in alcohol sales after controlling for seasonal autocorrelation, compared

with a previous study’s ﬁnding no impact (50). Our work provides a theoretical framework to

understand and quantify new sources of biases that sampling creates that can affect intervention

studies.

Code Availability

Codes to generate the results of the paper are available on https://github.com/aabeliuk/
Predictability-partially-observed.

Data Availability

This work uses publicly available data. Links to data repositories can be found in the Methods section.

Acknowledgments

The authors thank Linhong Zhu for collecting the Twitter data and America Mazuela for the illustration.
Funding: This work was supported by the Ofﬁce of the Director of National Intelligence (ODNI) and
the Intelligence Advanced Research Projects Activity (IARPA) via the Air Force Research Laboratory
(AFRL) contract number FA8750-16-C- 0112, and by the Defense Advanced Research Projects Agency

19

(DARPA), contract number W911NF-17-C-0094. The U.S. Government is authorized to reproduce and
distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Dis-
claimer: The views and conclusions contained herein are those of the authors and should not be inter-
preted as necessarily representing the ofﬁcial policies or endorsements, either expressed or implied, of
ODNI, IARPA, AFRL, DARPA, or the U.S. Government. Authors contributions: All authors concep-
tualized the study; ZH carried out formal analysis; AA carried out validations with empirical data; ZH
and AA carried out validations with synthetic data; all authors contributed to writing and reviewing the
manuscript. Competing interests: Authors declare no competing interests.

References

1. A. Vespignani, Science 325, 425 (2009).

2. J. M. Hofman, A. Sharma, D. J. Watts, Science 355, 486 (2017).

3. C. Chatﬁeld, Time-series forecasting (Chapman and Hall/CRC, 2000).

4. M. B. Short, et al., Mathematical Models and Methods in Applied Sciences 18, 1249 (2008).

5. G. O. Mohler, M. B. Short, P. J. Brantingham, F. P. Schoenberg, G. E. Tita, Journal of the American

Statistical Association 106, 100 (2011).

6. N. Ramakrishnan, et al., Proceedings of the 20th ACM SIGKDD International Conference on Knowl-

edge Discovery and Data Mining (2014), pp. 1799–1808.

7. V. Raghavan, A. Galstyan, A. G. Tartakovsky, The Annals of Applied Statistics pp. 2402–2430

(2013).

8. S. V. Scarpino, G. Petri, Nature communications 10, 898 (2019).

9. C. Song, Z. Qu, N. Blumm, A.-L. Barab´asi, Science 327, 1018 (2010).

10. R. D. Malmgren, D. B. Stouffer, A. S. Campanharo, L. A. N. Amaral, Science 325, 1696 (2009).

11. T. Hogg, K. Lerman, EPJ Data Science 1, 5 (2012).

12. G. Stoddard, Ninth International AAAI Conference on Web and Social Media (2015).

13. J. Garland, R. James, E. Bradley, Physical Review E 90, 052910 (2014).

14. J. Garland, et al., Entropy 20, 931 (2018).

15. N. I. Sapankevych, R. Sankar, IEEE Computational Intelligence Magazine 4, 24 (2009).

16. G. King, J. Pan, M. E. Roberts, Science 345, 1251722 (2014).

17. R. J. Little, D. B. Rubin, Statistical analysis with missing data, vol. 793 (Wiley, 2019).

20

18. F. Morstatter, J. Pfeffer, H. Liu, K. M. Carley, Seventh international AAAI conference on weblogs

and social media (2013).

19. D. Ruths, J. Pfeffer, Science 346, 1063 (2014).

20. C. Bandt, G. Keller, B. Pompe, Nonlinearity 15, 1595 (2002).

21. B. Fadlallah, B. Chen, A. Keil, J. Pr´ıncipe, Physical Review E 87, 022911 (2013).

22. F. Pennekamp, et al., bioRxiv p. 350017 (2018).

23. D. G. Rand, S. Arbesman, N. A. Christakis, Proceedings of the National Academy of Sciences 108,

19193 (2011).

24. V. Sekara, A. Stopczynski, S. Lehmann, Proceedings of the national academy of sciences 113, 9977

(2016).

25. D. Lazer, et al., Science 323, 721 (2009).

26. I. Rahwan, et al., Nature 568, 477 (2019).

27. S. Athey, Science 355, 483 (2017).

28. D. J. Watts, Nature Human Behaviour 1, 0015 (2017).

29. J. Blumenstock, G. Cadamuro, R. On, Science 350, 1073 (2015).

30. A. D. Pananos, et al., Proceedings of the National Academy of Sciences 114, 13762 (2017).

31. N. F. Johnson, et al., Science 352, 1459 (2016).

32. P. Deville, et al., Proceedings of the National Academy of Sciences 113, 7047 (2016).

33. C. A. Bail, et al., Proceedings of the National Academy of Sciences 115, 9216 (2018).

34. D. A. Scheufele, N. M. Krause, Proceedings of the National Academy of Sciences 116, 7662 (2019).

35. D. Lazer, R. Kennedy, G. King, A. Vespignani, Science 343, 1203 (2014).

36. R. M. Shiffrin, Proceedings of the National Academy of Sciences 113, 7308 (2016).

37. K.-P. Lim, W. Luo, J. H. Kim, Applied Economics 45, 953 (2013).

38. C. Bandt, B. Pompe, Phys. Rev. Lett. 88, 174102 (2002).

39. A. Politi, Physical review letters 118, 144101 (2017).

40. G. E. Box, G. C. Tiao, Journal of the American Statistical association 70, 70 (1975).

41. L.-Y. Leung, G. R. North, Journal of Climate 3, 5 (1990).

42. T. DelSole, Journal of the atmospheric sciences 61, 2425 (2004).

21

43. J. Ginsberg, et al., Nature 457, 1012 (2009).

44. M. Riedl, A. M¨uller, N. Wessel, The European Physical Journal Special Topics 222, 249 (2013).

45. D. G. Moore, G. Valentini, S. I. Walker, M. Levin, Frontiers in Robotics and AI 5, 60 (2018).

46. D. R. Dewhurst, et al., arXiv preprint arXiv:1906.11710 (2019).

47. W. Herlands, E. McFowland III, A. G. Wilson, D. B. Neill, Proceedings of the 24th ACM SIGKDD

International Conference on Knowledge Discovery & Data Mining (ACM, 2018), pp. 1512–1520.

48. P. Craig, S. V. Katikireddi, A. Leyland, F. Popham, Annual review of public health 38, 39 (2017).

49. J. L. Bernal, S. Cummins, A. Gasparrini, International journal of epidemiology 46, 348 (2017).

50. M. Robinson, et al., Addiction 109, 2035 (2014).

51. R. F. Engle, Econometrica: Journal of the Econometric Society pp. 987–1007 (1982).

22

Supplementary Information (SI)

Proofs to Propositions and Corollaries

Proof of Theorem 1

Theorem 2 (Restatement of Theorem 1). The time series X, Y are related by Y
B([X], p), where
B([X], p) is a Bernoulli random process with success rate p. The covariance matrices ΣX and ΣY are
related as

∼

where I is the identity matrix.

ΣY = p2ΣX + p(1

p)E[X]I

−

Proof. First, we compute the off-diagonal elements of covariance matrices ΣY and ΣX , i.e., the relation
between Cov(Xi, Xj) and Cov(Yi, Yj).

Cov(Yi, Yj) = E[YiYj]

EX

(cid:2)EY [Yi

Xi](cid:3)EX
|

(cid:2)EY [Yj

Xj](cid:3)
|

E[Yi]E[Yj]
−
(cid:2)EY [YiYj
Xi, Xj](cid:3)
= EX
|
(cid:2)EY [Yi
= EX
Xi]EY [Yj
|
(cid:2)EY [Yi
Xi](cid:3)EX
EX
|
(cid:2)p2[Xi][Xj](cid:3)
= EX
= p2(cid:0)E(cid:2)[Xi][Xj](cid:3)
p2Cov(Xi, Xj)

−

≈

−
Xj](cid:3)
|
−
(cid:2)EY [Yj
Xj](cid:3)
|
(cid:2)p[Xi](cid:3)EX
EX
−
E(cid:2)[Xi](cid:3)E(cid:2)[Xj](cid:3)(cid:1)

(cid:2)p[Xj](cid:3)

Next, we discuss diagonal elements, i.e., the relation between Var[Y ] and Var[X]. Without loss of gen-
erality, normal approximation will be used: Y

∼

B([X], p) is approximated by Y
(0, 1), then Z2 =

Y 2

−

∼ N
2pY X + p2X 2
p)X
p(1

([X]p, [X]p(1
−
χ2(1), i.e.,

∼

−

p)). Thus, for ﬁxed X, Z

≡

pX

Y
−
(cid:112)p(1

−

p)X ∼ N

(cid:20) Y 2

E[Z2] = E

This gives E[Y 2

X] = p(1

|

p)X + 2pE[Y

X]X
|

−
Var[Y ] = Cov(Y, Y ) = E[Y 2]

−

(cid:21)

= 1

2pY X + p2X 2
p)X
p(1

−

−
p2X 2 = p(1

p)X + p2X 2

−
E[Y ]2
(cid:2)EY [Y

−
EX

(cid:2)EY [Y 2

= EX
= EX [p(1
= EX [p(1
= p(1

X](cid:3)
|
−
p)X + p2X 2]
p)X + p2X 2]
−
p)E[X] + p2Var[X]

−

−

−

−

X](cid:3)2
|
EX [pX]2
p2EX [X]2

(5)

(6)

Equations (5) and (6) give the desired result.

23

Proof of Corollary 1

Proof. Autocorrelation is deﬁned as Pearson correlation between values of the signal at different times,
i.e.,

ρXi,Xj =

Cov(Xi, Xj)
σXiσXj

.

This yields the following expression for autocorrelation of the time series Y :

ρYi,Yj =

Cov(Yi, Yj)
σYiσYj

=

(cid:112)p2Var(Xi) + p(1

p2Cov(Xi, Xj)
p)E[Xi](cid:112)p2Var(Xj) + p(1

−

.

(7)

p)E[Xj]

−

The last equality comes from replacing Equation 5 in the numerator and Equation 6 in the denomina-
tor. Finally, we assume the ground truth process is stationary, i.e., the process has a time-independent
variance (Var(Xj)

i, j), yielding the desired result:

Var(Xj)

≈

i, j) and mean (E(Xj)
∀
ρYi,Yj ≈

E(Xj)
≈
p2Cov(Xi, Xj)

p2Var(X) + p(1

∀

p)E[X]

−

.

(8)

Proof of Corollary 2

Proof. Based on Corollary 1, the autocorrelation of the sampled signal Y between times i and j, which
is a function of sampling rate p, is deﬁned as

−

≥

R(p) = ρYi,Yj =

(cid:112)p2Var(Xi) + p(1

p2Cov(Xi, Xj)
p)E[Xi](cid:112)p2Var(Xj) + p(1

.

p)E[Xj]

(9)

−

1, 1], and we want to prove that its magnitude increases as a
The autocorrelation lies in the range [
−
function of p. Hence, next we show that d
dp R2(p)

0,

1.

p

0
∀

≤

≤

d
dp

R2(p) = p Cov(Xi, Xj)2 Var(Xi)E[Xj]p + E[Xi]Var(Xj)p + 2E[Xi]E[Xj](1

p)

(Var(Xi)p

E[Xi]p + E[Xi])2 (Var(Xj)p

−

where both the numerator and denominator are trivially positive for all values in 0
E[X]

0, and the result follows.

≥

E[Xj]p + E[Xj])2 ,
−
p

−

≤

≤

1 given that

(10)

Proof of Corollary 3

Proof. We compute the covariance between sampled signal Y and external signal S as

Cov(Y, S) = E(Y

EY )(S

ES)

−
= E[Y S]
−
(cid:2)SEY [Y
= EX,S
= EX,S[SXp]
= p(cid:0)E[SX]
−
= p Cov(X, S)

−

E[Y ]E[S]
S, X](cid:3)
EX
−
|
EX [Xp]E[S]

−
E[X]E[S](cid:1)

(cid:2)EY [Y

X](cid:3)E[S]
|

(11)

24

Permutation Entropy Criterion

Entropy measures the uncertainty of a random variable, which intuitively serves as an indicator of pre-
dictability of a stochastic event.
In statistical physics, entropy characterizes the amount of possible
microscopic state in a system, thus the more microscopic states exist in a system, the more chaotic a
system is, and the harder it becomes to predict its behavior.

Deﬁnition 3 (Shannon entropy). For a random variable, the (Shannon) entropy is deﬁned as

discrete case: H(p) =

−

(cid:88)

p(x) ln p(x)

continuous case: H(p) =

p(x) ln p(x) dx

x∈X
(cid:90)

−

S

(12)

(13)

p(x) is the probability distribution of the random variable. In the discrete case,
is the collection of
all possible values of the random variable. In the continuous case, S is the support set of the random
variable.

X

In both discrete and continuous case, the larger the entropy value is, the more uncertain a random
variable is, thus rendering the stochastic event a random variable represents harder to predict. A variant
form of entropy is the permutation entropy, which depicts the complexity of a time series through the
statistics of of the values of its subsequences using ordinal analysis. The complexity can be interpreted as
the diversity of the trends among the subsequences of certain length. Therefore, the higher the entropy,
the more different trends exist in the time series, which renders its prediction more difﬁcult.

Permutation entropy has been used in various ﬁelds to characterize the predictability of time series
under interest (13, 39). Interestingly, this quantity has also been used as a forensic tool to inspect and
identify potential corruption in the source data (14).

Deﬁnition 4 (Permutation Entropy). Given a time series
permutations π of order d. For each π
N
t=1:
occurring in

∈ S

d be the collection of all d!
S
d, determine the relative frequency of that permutation

xt
{

N
t=1. Let

}

t

t

|

≤

N

−

d, φ(xt+1,
d + 1
N

−

, xt+d) = π

]

}

=

(cid:88)

· · ·

t≤N −d

N

1
d + 1

δ(cid:0)φ(x(d)

t+1), π(cid:1)

xt
{

}
Card[
{

P (π) =

where P (π) quantiﬁes the frequency of an ordinal pattern π, and δ(a, b) =

The permutation entropy of order d

2 is deﬁned as

≥
H P(d) =

(cid:88)

−

π∈Sd

P (π) log2 P (π)

(14)

The ordinal pattern means the relative magnitude relation among successive time series values. As
is

an example, if x1 = 3, x2 = 6, x3 = 1, then the ordinal pattern of this subsequence
x2.
φ(x1, x2, x3) = (312) because x3

x1, x2, x3

x1

}

{

Besides the order d, the more general deﬁnition of permutation entropy (1) has one more parameter:
temporal delay τ . The ordinal pattern can be deﬁned in the same way with respect to the subsequence

≤

≤

25

−
(cid:40)

1,
0,

if a = b
if a
= b

.

(cid:54)
xt, xt+1τ , xt+2τ ,
we present results from continuous intervals by ﬁxing τ = 1.

· · ·

, xt+(d−1)τ , which gives permutation entropy H P(d, τ ). To facilitate interpretation,

To lessen the inﬂuence of observational noise on the ordinal pattern of the signal, the weight w.r.t.
a subsequence with certain ordinal pattern is introduced to reﬂect the importance of ordinal changes in
large amplitude. For a subsequence of length/order d consisting times series values from xt+1 to xt+d,
which is denoted as x(d)

t+1 with arithmetic mean value ¯x(d)

t+1, its weight is deﬁned (21) as

w(x(d)

t+1) =

1
d

t+d
(cid:88)

(xj

j=t+1

¯x(d)
t+1)2

−

As a result, the weighted frequency of a permutation is deﬁned as

Pw(π) =

(cid:18)

(cid:88)

t≤N −d

t+1)

w(x(d)
t(cid:48)≤N −d w(x(d)

t(cid:48)+1)

(cid:80)

(cid:19)

δ(cid:0)φ(x(d)

t+1), π(cid:1)

The weighted permutation entropy is deﬁned as

H P

(w)(d) =

(cid:88)

−

π∈Sd

Pw(π) log2 Pw(π)

(15)

Here we normalize the weighted permutation entropy by the log-number of the factorial of the observed
permutations. Thus, the weighted permutation entropy takes value between 0 and 1.

Synthetic Data Experiments

Here, we validate our ﬁndings on synthetically generated time series data. We show that predictability
diminishes as data is lost to sampling. We ﬁrst consider an idealized scenario, where X represents an
autoregressive process, from which events are sampled at random to create the observed sampled signal
Y .

Synthetic Time Series Generation

External Signal First, we generate an external signal S. To assure autocorrelation, we generate it
using the autoregressive integrated moving average (ARIMA) model:

S +

k
(cid:88)

i=1

αES

i St−i = εt +

l
(cid:88)

j=1

βES
j εt−j.

(16)

ARIMA coefﬁcients satisfy the stationarity conditions, so that the external signal S is second-order
stationary. The stationarity conditions require that all roots of the polynomials α(x) = 1 + α1x +
+
αkxk and β(x) = 1 + β1x +
> 1; i.e., all roots of these two polynomials are
z
|
|
located outside the unit disk. We enforce the second order stationarity by determining roots of α(x) and
β(x) ﬁrst and then solving for the corresponding regression coefﬁcients
, which specify
the model.

+ blxl satisfy

βj
{

and

· · ·

· · ·

αi

}

}

{

26

Ground Truth Signal We generate the ground truth signal X in a similar manner, except that the
generation model entails a term for the external signal S. This ensures that the ground truth and the
external signals are correlated. Speciﬁcally, we assume the ground truth signal is deﬁned as:

X +

K
(cid:88)

i=1

αGT

i Xti = εt +

L
(cid:88)

j=1

βGT
j εt−j + S.

(17)

When generating the ground truth signal time series, we require that the autocorrelation of the ground
truth signal is strong enough so that it can be distinguished from the random white noise.

Observed signal We sample the ground truth data X to obtain the time series of observed events,
Y . The sampling rate p characterizes the probability of sampling an event. Because the count process
is described by the ARIMA model, which inevitably gives real-number-valued count instead of integer-
valued count, the decimal part of the count X is treated as a separate instance, and if the decision is made
to keep it, its original value will be added to the posterior data. In other words, each instance of Y obeys
the Binomial distribution B(X, p).

Due to the stochastic nature of sampling, we generate ten different samples Y based on the ground
truth signal with the same sampling rate p. In each experiment, the sampled signal Y is split into a
training and testing data set, with training data used to train a predictor ˆY to predict the test data. The
accuracy of the predictor for a given sampling rate is then averaged over the ten experiments.

Model Training Training an ARIMA model consists of two steps: First, a grid search is performed to
ﬁnd the best hyper-parameters (k, l), where k is the order of the autoregressive model, and l is the order
of the moving-average model. For each input signal, we search over the grid for the set of parameters
resulting in the lowest AIC score. Next, the corresponding coefﬁcients of the ﬁxed-order ARIMA model
are ﬁtted to the data.

After the best ARIMA order parameters are determined, we do step by step prediction over a speci-
ﬁed time range. At each prediction step, the data from the previous step is incorporated into the known
data as new input signal, and consequently, the model is retrained to ﬁnd the updated parameters.

Prediction In order to compare predictions at different sampling rates, we use normalized rooted-
mean-square error (NRMSE) to measure how accurately we predict the observable Y . Given the pre-
dicted values ˆyt with respect to time series Y , NRMSE is deﬁned as

NRMSE(yt, ˆyt) =

=

(cid:115)

(cid:80)T

i=1(yi
T
(cid:115)

1
(cid:80)T
i=1 yi

1
¯y

1
T

ˆyi)2

−

(cid:80)T

i=1(yi
T

ˆyi)2

−

(18)

27

Figure 6: Synthetic time series showing ground truth signal (top) and the observed signal sam-
pled at sampling rates 90% (middle) and 50% (bottom).

Numeric Experiments

First, we illustrate all our theoretical claims using one instance of an ARIMA process generated with an
external signal. Second, we present aggregated results of the prediction task, using multiple randomly
generated ARIMA time series.

For the ﬁrst set of results on the synthetic data, we generated an external signal S with the ARIMA

of order (3,0,2) and length 365, representing a full year of event counts.

Meanwhile, the ground truth signal X assumes the ARIMA order(5,0,1).

Figure 6 shows the ground truth and the sampled signals. Notice that with a simple visual inspection of
the plot, one can observe that many of the temporal patterns present in the unsampled data seem to have
disappeared in the sampled signal.

Predictors We train three predictors for Y , each of which can be used with or without an external
signal. The predictors are:

Poisson predictor assumes that events in Y are generated independently of each other at some rate.

This predictor estimates the Poisson intensity as the average of counts of all available past data.

ˆYt uses the sampled signal to predict the observable Y .

ˆXt uses the unsampled signal to predict the observable Y . i.e., the ARIMA parameters are ﬁtted to X,

and then used to predict the future values of Y given its past values.

28

0501001502002503003504006100612061406160050100150200250300350400550055505600050100150200250300350400300031003200Figure 7: Prediction accuracy in terms of NRMSE, and the difference in prediction performance
among different predictors versus Sampling Rate Plot. Here we use three predictors to estimate
sampled counting process Y .

Prediction Accuracy Figure 7 shows normalized prediction errors (normalized RMSE) as a func-
tion of sampling rate to demonstrate the nonlinear decrease of the prediction error. As sampling rate
decreases, prediction error grows. We study the performance of the predictor ˆY , which is trained on the
history of the observed signal Y , as it is often employed in practice.

Performance of the predictor ˆX, trained on the full signal X, is almost always better (lower NRMSE)
than performance of predictor ˆY (the plot show difference between predictors on the log scale). This
phenomenon reveals that sampling weakens prediction accuracy. Moreover, our results suggest that the
sampled process’ increased noise and low autocorrelation obfuscates the underlying dynamic, making
it harder to be described by an ARIMA model. Using an informative external signal S in prediction
helps recover some of the lost information, shrinking the gap between ˆX and ˆY predictors, as well as the
overall prediction error.

When little information is lost (i.e., at high sampling rate), predictors ˆX and ˆY outperform the
Poisson predictor, since they are able to leverage the autocorrelation of the signal with the ARIMA
model. In addition, by comparing the gaps between predictors at high sampling rates (note the log scale),
we see that adding external signal makes the Poisson predictor less competitive than the other predictors.
On the other hand, Poisson predictor performs almost as well as ˆY and ˆX when much of the information
is lost (i.e., at low sampling rate). This indicates that Poisson predictors are strong baselines for the
observable Y at low sampling rates.

Loss of autocorrelation Figure 8 shows that the autocorrelation of the sampled signal increases with
sampling rate, consistent with Corollary 2. This ﬁgure shows that sampling at low rate quickly destroys
the innate autocorrelation of the signal, fundamentally altering the properties of the signal and rendering
the prediction task harder. We also see that the correlation between sampled ground truth signal Y and
the external signal gradually increases in agreement with Corollary 3. As a consequence of the loss of
autocorrelation and correlation with the external signal, we can observe in Figure 7, that at low sampling

29

00.5110-310-210-100.5110-310-210-1Figure 8: Loss of predictability due to sampling. (left) autocorrelation of sampled time series
decreases at low sampling rates. (right) Covariance of the external signal and observed signal
decreases at low sampling rates.

rates, the accuracy of the Poisson predictor is competitive to the ARIMA predictors.

Figure 9: Loss of predictability due to sampling for the synthetic data shown in Figure 6. Nor-
malized weighted permutation entropy with respect to sampling rate increases at low sampling
rates, showing the system becomes less predictable. Parameter d is the embedded time dimen-
sion used to compute corresponding weighted permutation entropy H P
(w). The delay dimension
is set to τ = 1.

Increase in Permutation Entropy Figure 9 shows that the weighted permutation entropy decreases
at high sampling rates, when more of the signal is retained. This shows the loss of predictability of the

30

00.51-1-0.500.5100.5100.10.20.30.40.50.600.20.40.60.810.50.60.70.80.91process at low sampling rates. The trends in the ﬁgure imply that even when little of the signal is ﬁltered
out, its predictability signiﬁcantly degrades.

Figure 10: Decay of mutual information between the external signal and the sampled signal.
Although the external signal in this illustration is highly correlated with the original (unﬁltered)
ground truth signal, sampling leads to a sharp loss of information about the original signal.

Decrease in Mutual Information The loss of predictability cannot be offset using an informative
external signal. This is because even if the external signal is highly correlated with the ground truth
signal, sampling reduces its utility in predictive tasks. Figure 10 shows this decay in mutual information
between the external and observed signals at low sampling rates. The informative external signal does
not reduce the uncertainty of the observed signal.

Nonstationarity of Prediction Errors

Another quantity that characterizes the impact of sampling on the predictability of a time series is the
covariance of the prediction error at different times, as the prediction error can intuitively reﬂect how well
one can predict the event count. We show that sampling the time-series will introduce an autocorrelation
into the prediction error and render it dependent on the evolution of the counting process, with errors
growing larger or smaller depending on the type of process. Next, we provide an example to motivate
how sampling can induce a correlation between variances of predictions at different times.

Proposition S2. Consider an auto-regressive (AR) process: Xt = αXt−1 + εt, with εt white noise. The
variance at the next step is given by,

Xt) = αVar(Yt−1
|
Proof. The information ﬁlter can be described as a Binomial distribution, Y
Var(Yt−1

p) using the fact that Yt−1

Xt−1) + ε(cid:48)
t.
|

Var(Yt

B(X, p). Hence,
Xt−1 is a Bernoulli random variable. Then,

∼

Xt−1) = Xt−1p(1
|

−

|

31

00.10.20.30.40.50.60.70.80.9111.522.533.544.5Figure 11: p-Value versus time lag

the variance at the next step is given by,

Var(Yt

Xt) =Xtp(1
|

p)

−
= (αXt−1 + εt) p(1
=αXt−1p(1
=αVar(Yt−1

−
p) + ε(cid:48)
t
−
Xt−1) + ε(cid:48)
t.

p)

|

Proposition S2 shows that the variances of the sampled process, Y , are related by the exact same AR
model that generated the process X. In other words, the conditional variance of the sampled process
is autocorrelated. Notice, that this is not true for the unsampled data, given that Var(Xt
Xt−1) =
|
Var(εt) = σ2.

Proposition S2 shows that sampling a time series may introduce autoregressive conditional het-
eroskedasticity (ARCH) of the variance into the time series. This is usually tested by analyzing the
residuals of the model. We use Engle’s Langrage Multiplier test to demonstrate the appearance of ARCH
effects in the residual signal. Figure 11 shows that sampling does result in the introduction of ARCH
effects to the residuals of predictions.

We have applied Engle’s Lagrange Multiplier (ELM) test (51) on the residual ˆY

Y , which is
evaluated at time t, t
L where L = 100 is the maximum time lag we consider, to examine
the existence of ARCH behavior. Under the null hypothesis that there is no ARCH effect, the test statistic
used in ELM test has the asymptotic distribution χ2(L). When p-value is less than the signiﬁcance level
˜α = 0.05, the ELM test says that we can reject the null hypothesis with 95% conﬁdence.

· · ·

1,

, t

−

−

−

From Figure 11, we see that for the original time-series (top-left plot) there is no heteroskedasticity,
p-values are largely over the signiﬁcant level threshold 0.05 for most of time lags under consideration.
In the case of q = 0, ELM test does not provide us enough evidence to reject the hypothesis that ARCH

32

05010000.5105010000.5105010000.5105010000.51Figure 12: Change of prediction accuracy (RMSE) with respect to sampling rate for various
ground truth signals, when the sampled GTs are predicted without knowing external signal S.

effect does not exist. However, when we ﬁlter the original signal, as we see in the case q = 0.1, 0.5, 0.8
respectively, the p-value for time lags from 6 to 40 are mostly below the signiﬁcance level bar, which, by
ELM test, strongly suggests that the null hypothesis be rejected. In other words, ELM test suggests with
95% conﬁdence that ARCH effect exists in the residual of prediction records on the ﬁltered time-series.

Generalizability

So far, we have explored methodically one example where we have validated our theoretical results as
well as provided new insights about the unpredictability of sampled time series. Here we show the
average loss of predictability across many randomly generated ground truth time series.

We generate multiple external signal–ground truth signal pairs, and apply ARIMA and Poisson mod-
els on these data sets to test if the tendencies we have observed previously (i.e. nonlinear decrease
of NRMSE with respect to sampling rate) will also appear in signals of different ARIMA orders. We
observe in Figure 12 similar behavior across multiple data sets:

1. Increasing prediction error (NMRSE) despite small discrepancy at high sampling rates. This gen-
eral behavior is partially due to the normalization by sample mean when we evaluate the NRMSE;

2. The autoregressive model outperforms the non-autoregressive Poisson model for higher sampling

rates, but, this difference fades out for lower sampling rates as a consequence of sampling.

We further postulate that this decreasing tendency between increasing sampling rate and NRMSE
bears generality with respect to any combination of ARIMA orders of external signal–ground truth data
pair. When predicting Y with the external signal S, we observe a very similar tendency of NRMSE—
sampling rate relationship as in Figure 12. Albeit noticeable difference in the high end of sampling rate

33

00.20.40.60.8100.010.020.030.040.050.060.070.0800.20.40.60.8100.010.020.030.040.050.060.070.08spectrum, the decreasing tendency, decreasing speed and the amplitude of NRMSE are by large the same
as in the not-using-S case.

In the general setting of ARIMA model, we show a decreasing prediction error w.r.t. the sampling
rate, and the shrinking of the advantage of autoregressive model in prediction accuracy over Poisson
model as sampling rate becomes smaller.

We demonstrated the decoupling of the external signal and the ﬁltered signal as a prevalent phe-
nomenon in the generic ARIMA setting. We observe in Figure 13 that for all ground truth-external
signal pairs, the lower the sampling rate is, the smaller mutual information becomes. Therefore, we
postulate that the positive correlation between sampling rate and mutual information can always be ob-
served, thus implying that the knowledge of external signal cannot help recover the predictability of the
ground truth signal.

Figure 13: Change of mutual information (MI) with respect to sampling rate for various (ground
truth, external signal) pairs.

34

00.10.20.30.40.50.60.70.80.911234567Supplementary Figures

Epidemics.

Figure 14: Theoretical and empirical Loss of autocorrelation in outbreaks due to sampling for
all diseases. The plot depicts a decrease on the autocorrelation as drop-out rate increase. For
each of the eight weekly, state-level diseases, we selected 100 random points and calculated the
entropy and autocorrelation for different drop-out rates over a one year window. The solid line
represents the median, shaded region marks the interquartile range.

Figure 15: Loss of predictability due to sampling for all diseases. The plot shows and increase
on the permutation entropy as drop-out rate increase. For each of the eight weekly, state-level
diseases, we selected 100 random points and calculated the entropy and autocorrelation for
different drop-out rates over a one year window. The solid line represents the median, shaded
region marks the interquartile range.

35

0.00.20.40.60.81.0Sampling rate0.20.40.60.8Autocorrelation ()HepatitisInfluenzaMeaslesChlamydiaPolioMumpsWhooping0.00.20.40.60.81.0Sampling rate0.40.50.60.70.8Permutation Entropy (HP)HepatitisInfluenzaMeaslesChlamydiaPolioMumpsWhoopingFigure 16: Decay of mutual information with external signal due to sampling of the inﬂuenza
activity. For each state, we selected 100 random one-year time windows and calculated the
median mutual information (45) between Google Flu trends and the inﬂuenza activity at differ-
ent sampling rates. Shaded regions mark the inter-quartile ranges for each state; the solid line
represents the average coefﬁcient across all states.

36

0.20.40.60.81.0Sampling rate5.05.15.25.35.45.55.65.7Mutual InformationFigure 17: Loss of predictability of disease outbreaks due to sampling. The plots show a de-
crease in permutation entropy (top-left) and an increase in autocorrelation (top-right) of the
outbreak time series for increasing sampling rates. For each of the eight diseases, we selected
100 random two-year time windows and calculated the relative weighted permutation entropy
and autocorrelation for different sampling rates over that window. The solid line represents
the median ratio across all states between the original time series and the sampled one; shaded
regions mark the inter-quartile ranges. The bottom plot supports our theoretical results by plot-
ting Equation 3 against the empirical autocorrelation of the sampled time series at different
sampling rates for each disease.

37

0.00.20.40.60.81.0Sampling rate0.91.01.11.21.3Relative Permutation Entropy (HP/HP0)HepatitisInfluenzaMeaslesChlamydiaPolioMumpsWhooping0.00.20.40.60.81.0Sampling rate0.20.40.60.81.0Relative Autocorrelation (/0)HepatitisInfluenzaMeaslesChlamydiaPolioMumpsWhooping0.00.20.40.60.81.0Theoretical Autocorrelation 0p2Var(X)p2+p(1p)E[X]0.00.20.40.60.81.0Empirical Autocorrelation ()HepatitisInfluenzaMeaslesMumpsWhoopingChlamydiaPolioSocial Media.

Figure 18: Loss of predictability in social media due to sampling on user’s activity (posts made
by the user). The plot shows the median weighted permutation entropy relative to the original
time series for each of the top 100 most popular hashtags.

38

0.00.20.40.60.81.0Sampling rate0.91.01.11.21.31.4Relative Permutation Entropy (HP/HP0)0.00.20.40.60.81.0Sampling rate0.91.01.11.21.31.4Relative Permutation Entropy (HP/HP0)Hashtag (Popularity)#ferguson(111223)#gaza(61332)#ff(55148)#worldcup(48054)#usa(28397)#tcot(25615)#win(23866)#mtvhottest(23797)#quote(20078)#ger(19709)#israel(19155)#edchat(18804)#socialmedia(18682)#giveaway(17790)#1(17452)#tbt(17268)#gazaunderattack(16940)#leadership(16569)#travel(16247)#worldcup2014(15082)#rt(13735)#mikebrown(13624)#marketing(13203)#edtech(12799)#art(12605)#sdcc(12497)#uniteblue(12140)#nyc(12101)#bra(12062)#isis(11901)#auspol(11654)#icebucketchallenge(11580)#ebola(11433)#startup(11241)#breaking(11052)#usmnt(11025)#arg(10997)#photography(10967)#free(10300)#iraq(10161)#wine(10076)#follow(9551)#ukraine(9535)#music(9534)#iste2014(9286)#p2(9162)#love(8710)#retweet(8605)#business(8550)#pjnet(8494)#alsicebucketchallenge(8404)#health(8143)#ad(7889)#nowplaying(7811)#indyref(7736)#emmys(7629)#asmsg(7557)#startups(7519)#amwriting(7506)#hobbylobby(7452)#inspiration(7394)#quotes(7360)#jobs(7353)#summer(7290)#toronto(7273)#bigdata(7244)#ned(7217)#education(6984)#fashion(6935)#tech(6926)#hamas(6909)#bb16(6811)#cdnpoli(6771)#chicago(6626)#food(6618)#design(6473)#facebook(6297)#syria(6291)#london(6281)#selfie(6272)#teamfollowback(6159)#competition(6112)#entrepreneur(6087)#s(6041)#climate(5926)#innovation(5788)#m(5751)#twitter(5728)#mobile(5627)#vmas(5596)#2(5583)#scotus(5526)#cloud(5459)#fitness(5449)#writing(5346)#cancer(5337)AverageFigure 19: Loss of predictability in social media due to sampling on user’s activity (posts made
by the user). The plot shows the median weighted permutation entropy relative to the original
time series for each of the top 100 most active users.

Figure 20: Clustering the permutation entropy behavior from Figure 19. We use, K-means
clustering to depict the three most characteristics types of behaviors exhibited when computing
predictability in social media as a function of sampling on user’s activity.

39

0.00.20.40.60.81.0Sampling rate0.70.80.91.01.11.21.31.41.5Relative Permutation Entropy (HP/HP0)0.20.40.60.81.0Sampling rate21012N=420.20.40.60.81.0Sampling rate32101N=370.20.40.60.81.0Sampling rate321012N=210.20.40.60.81.0Sampling rate0.30.40.50.60.70.80.91.0AutocorrelationN=420.20.40.60.81.0Sampling rate0.20.30.40.50.60.70.80.91.0AutocorrelationN=370.20.40.60.81.0Sampling rate0.20.30.40.50.60.70.80.91.0AutocorrelationN=21Figure 21: Empirical and theoretical effects of sampling on autocorrelation of user’s activity.
The left plot shows the median autocorrelation relative to the original time series for each of
the top 100 most active users; shaded region marks the interquartile ranges; the black line
represents the average autocorrelation across all users. The right plot shows the accuracy of
the theoretical prediction according to Equation 3. The line depicts the identity function to
represent an accurate ﬁt to the data.

Cryptocurrencies.

Figure 22: Decay of mutual information between the popularity of cryptocurrencies repositories
and their prices for different sampling rates. For each cryptocurrency, and each sampling rate,
we obtained 100 samples, and calculated the median mutual information (45) between the price
and the popularity of related Github repositories. The solid line represents the median mutual
information for each coin. Shaded region marks the interquartile ranges for each coin.

40

0.00.20.40.60.81.0Sampling rate0.20.40.60.81.01.2Relative Autocorrelation (/0)0.00.20.40.60.81.0Theoretical Autocorrelation p2Var(X)p2+p(1p)E[X]0.00.20.40.60.81.0Empirical Autocorrelation (/0)0.20.40.60.81.0Sampling rate3.03.54.04.5Mutual InformationBTC0.20.40.60.81.0Sampling rate0.020.040.060.080.10LTC0.20.40.60.81.0Sampling rate0.040.020.000.020.04XMR0.20.40.60.81.0Sampling rate0.040.020.000.020.04XRPSupplementary Tables

Disease

Years

Total Infections

Infections/Year (SD)

Infections/week (SD)

Hepatitis
Inﬂuenza
Measles
Chlamydia
Polio
Gonorrhea
Mumps
Whooping cough

1966-2014
1919-1951
1909-2001
2006-2014
1921-1971
1972-2014
1967-2014
1909-2014

742, 554
6, 498, 817
18, 430, 036
4, 882, 110
505, 246
3, 701, 913
866, 965
2, 220, 008

15, 154 (18, 905)
196, 934 (198, 551)
198, 172 (247, 833)
542, 456 (80, 216)
9, 907 (13, 134)
86, 091 (210, 930)
18, 061 (35, 054)
20, 943 (47, 835)

14, 011 (2, 643)
122, 619 (163, 348)
347, 737 (310, 744)
92, 115 (18, 487)
9, 532 (10, 676)
69, 847 (13, 426)
16, 357 (9, 180)
41, 887 (7, 296)

Table 1: Epidemics data: descriptive statistics.

Hashtags

Users

Tweets

Tweets/hashtag (SD) Tweets/User (SD) Tweets/Day (SD)

100

233, 108

1, 269, 348

12, 693 (13, 561)

5.4 (12)

11, 135 (6, 941)

Table 2: Twitter hashtag activity descriptive statistics. Top 100 most popular hashtags.

Users

Tweets Hashtags Tweets/User (SD) Tweets/hashtag (SD) Tweets/Day (SD)

150

167, 654

20, 990

1, 118 (13, 561)

8.0 (41.6)

1, 552 (1, 668)

Table 3: Twitter user activity descriptive statistics. Top 150 most active users.

Cryptocurrency Events Repositories Users Events/Day (SD) Events/Repo (SD)

Bitcoin (BTC)
Ripple (XRP)
Litecoin (LTC)
Monero (XMR)

40, 038
2, 963
1, 222
370

1, 962
7
137
15

5, 324
86
302
54

460 (116)
35.3 (27.7)
14 (11)
5.7 (6.3)

20.4 (138.4)
423.2 (1, 115)
8.9 (19.2)
24.7 (55.8)

Table 4: Github data: descriptive statistics.

41

