1

I Can Read Your Mind:
Control Mechanism Secrecy of Networked
Dynamical Systems under Inference Attacks

Jianping He†, Senior Member IEEE, Yushan Li†, Student Member IEEE, Lin Cai‡, Fellow IEEE,
and Xinping Guan†, Fellow IEEE

2
2
0
2

y
a
M
7

]

Y
S
.
s
s
e
e
[

1
v
6
5
5
3
0
.
5
0
2
2
:
v
i
X
r
a

Abstract—Recent years have witnessed the fast advance of
security research for networked dynamical system (NDS). Con-
sidering the latest inference attacks that enable stealthy and
precise attacks into NDSs with observation-based learning, this
article focuses on a new security aspect,
i.e., how to protect
control mechanism secrets from inference attacks, including state
information, interaction structure and control laws. We call this
security property as control mechanism secrecy, which provides
protection of the vulnerabilities in the control process and ﬁlls the
defense gap that traditional cyber security cannot handle. Since
the knowledge of control mechanism deﬁnes the capabilities to
implement attacks, ensuring control mechanism secrecy needs
to go beyond the conventional data privacy to cover both
transmissible data and intrinsic models in NDSs. The prime goal
of this article is to summarize recent results of both inference
attacks on control mechanism secrets and countermeasures. We
ﬁrst introduce the basic inference attack methods on the state
and structure of NDSs, respectively, along with their inference
performance bounds. Then, the corresponding countermeasures
and performance metrics are given to illustrate how to preserve
the control mechanism secrecy. Necessary conditions are derived
to guide the secrecy design. Finally, thorough discussions on the
control laws and open issues are presented, beckoning future
investigation on reliable countermeasure design and tradeoffs
between the secrecy and control performance.

I. INTRODUCTION

In the last decades, traditional control systems are becoming
increasingly diverse, networked, and integrated with numerous
physical and cyber components. Networked dynamical sys-
tems (NDSs) are characterized by the locality of information
exchange between individual nodes (subsystems) and the co-
ordinated capability to implement control and safety-critical
tasks with high-reliability requirements [1], such as multi-
robot systems [2], [3], vehicle and trafﬁc networks [4], [5].

While NDSs have many promising applications, the net-
worked working nature and physical openness make NDSs
vulnerable to a wide range of security risks. It arises as an
urgent and critical problem to secure NDSs under various
cyber/physical attacks [6]. Speciﬁcally, from the perspective
of external observations, the state, structure, and control laws
of NDSs are critical elements to evaluate and analyze the

(a) Multi-component type NDS, such as manufacturing indus-
tries, oil reﬁneries, and smart homes.

(b) Multi-agent type NDS, such as smart grid, robot formation, automo-
biles, VANETs and etc.

Fig. 1. Two common types of NDSs.

operating performance (we call the three elements as control
mechanism). This article reveals that, with the rapid devel-
opment of artiﬁcial intelligence, external attackers/adversaries
can infer the control mechanism based on a small number
to read the mind of
of observations, which is equivalent
the NDS systems. Furthermore, the attacker can leverage the
inferred knowledge to achieve more stealthy and intelligent
attacks. Different from the mainstream security research in
the literature, we focus on the mentioned inference attacks,
and introduce the notion of control mechanism secrecy to
investigate the security performance under inference attacks.

†: The Dept. of Automation, Shanghai Jiao Tong University, Key Lab-
oratory of System Control and Information Processing, Ministry of Ed-
ucation of China, and Shanghai Engineering Research Center of Intelli-
gent Control and Management, Shanghai, China. E-mail address: {jphe,
yushan li,xpguan}@sjtu.edu.cn.

‡: The Dept. of Electrical and Computer Engineering, University of

Victoria, BC, Canada. Email address: cai@ece.uvic.ca.

To interpret the contents of mechanism secrecy, the con-
trol mechanism needs to be speciﬁed ﬁrst. NDSs can be
categorized into two types: multi-component type and multi-
agent type, as shown in Fig. 1. For both types, they are
all composed of sensors for state measurements, commu-

A. What is Control Mechanism Secrecy

 
 
 
 
 
 
2

Fig. 2. The elements of the control mechanism. The state, structure, and control laws are deeply coupled with each other: the state evolution is a direct result
of the control laws, while the control laws need to use the state and structure to control the system behavior.

nication/transmission devices for information exchange, and
controlled actuators for driving plants. Given the common
feature, the system state, internal interaction structure, and
control laws are the fundamental three elements that charac-
terize the dynamics of NDSs. The detailed meanings are given
as follows.

• The states represent a group of speciﬁc features that
characterize the operating process, e.g., the displacement
in robotic systems. In some situations, the states cannot
be obtained directly due to environmental constraints,
but are measured by deployed/embedded sensors. These
indirectly obtained values related to the states are called
the outputs of the system.

• NDSs have two types of internal structure: i) the coupling
structure that measures the mutual inﬂuence of different
states in a single node (subsystem), and ii) the intercon-
nection structure that speciﬁes the information interaction
ﬂows between different nodes.

• The control laws of NDSs deal with two critical aspects:
i) how the system inputs are selected and used to accom-
plish the control objective, ii) how the system reacts to
the injected inputs and evolves.

An illustration of the control mechanism is shown in Fig. 2.
Accordingly, the control mechanism secrecy of NDSs has three
aspects: ﬁrst, to protect the historical states and futuristic states
from being estimated and predicted, respectively; second,
to protect
the intra-state structure and the interconnection
structure among nodes from being inferred; third, to protect the
input design and model parameters from being regressed. In
summary, the control mechanism secrecy aims to conceal the
dynamical properties against external inference attacks without
compromising the operating performance.

B. Why Control Mechanism Secrecy

According to famous Kerckhoffs’s principle [7] and Shan-
non’s maxim “the enemy knows the system” [8], it is dangerous
to assume that the attacker lacks the knowledge about the
system. The two principles have guided security research
in control systems, with rich achievements to guarantee the
system performance under various attacks. On the other hand,
a growing amount of works focus on the defense design
under the assumption that the attacker has perfect knowledge
about the system. This assumption is for worst-case attacks,

and generally leads to a passive defense manner. The worst-
case assumption can be counter-productive, which leads to
overly conservative defense strategies with compromised sys-
tem performance. This dilemma motivates us to investigate
the unsolved issues inspired by Shannon’s maxim, i.e., the
fundamental control mechanism secrecy. We need to answer
two important questions: i) under what conditions and to what
extent can the attacker infer the control mechanism, and ii) in
what way to enhance the control mechanism secrecy.

Here we use an example of multi-robot systems to illustrate
how to “read your mind”. Suppose a multi-robot system
is deployed in an unknown environment for reconnaissance,
while a malicious attacker (like an UAV or other robots
equipped with sensors) can observe the trajectories of the
robots. From the observed information, the attacker can infer
the real historical states which may contain sensitive location
information of the robot base [9], or predict the future trends
of the trajectory evolution [10]. Also, if the robots exhibit a
process of reaching certain regular pattern, then the attacker
can infer the internal interaction structure among the robots
[11], [12], and ﬁnd the critical robot that has dominant impacts
on the system [13]. Even worse, the control laws about how
the robots are driven are also likely to be learned if sufﬁcient
data of the control process are collected [14], [15]. Once these
elements of control mechanism are disclosed to the attacker,
the robot system will face more severe security risks. For
instance, the attacker can use the knowledge to launch one-
shot strike against the critical robot precisely to disrupt the
whole system [16], or choose to be a spy robot that sneaks
into the system and stealthily misguides the system [17], [18].
Based on the above analysis, if we can protect the control
mechanism secret, the capabilities of the attackers will be
substantially constrained, thereby largely reducing the defense
to investigate the control
burdens. Therefore,
mechanism secrecy, as another layer of proactive defense for
the system. Moreover, it provides much needed insights to
characterize the capabilities of the state-of-the-art inference
attacks, and is an under-explored research issue beckoning
further investigation.

is critical

it

C. Related Work

Control mechanism secrecy is not a brand new notion, as it
is inspired by numerous pioneering works. In this part, we

3

Fig. 3. Location illustration of the mechanism secrecy in the research ﬁelds. The control mechanism secrecy can be cast into the system knowledge and
disclosure resource dimensions in the attack space.

delineate how the control mechanism secrecy is associated
with and also different from the existing security research.

Perspective of the attack-defense process. In NDSs, the in-
teraction between the attack and defense can take three stages:
i) attack design, ii) attack injection and effects spreading, and
iii) attack detection and mitigation. Numerous attack models
and defense methods have been developed to address different
security aspects (see [19], [20] for a detailed review). The
previous works mainly addressed three objectives: a) attack
modeling and analysis (e.g., [21]–[25]), i.e., analyzing the at-
tack capabilities with certain system knowledge and resources,
and illustrating how to maximize the attack impacts; b) attack
detection and identiﬁcation (e.g., [26]–[30]), i.e., designing
detectors based on outputs to judge whether the system is
under attacks (like classic X 2 detector), and investigating the
limits of detection performance when the attacks are massive.
c) attack mitigation and countermeasures (e.g., [31]–[35]),
i.e., developing appropriate remedial strategies to alleviate
the attacks injected into NDSs, for instance, reconstructing
the underlying states from corrupted sensor observations or
designing attack-resilient control algorithms.

The above works on different aspects of the system security
achieved prominent results to effectively defend various types
of attacks. Nevertheless,
they rely on deterministic attack
model supported by known system knowledge, and barely
consider what exactly an attacker could know about the system
and how they can infer it. Speciﬁcally, the attack space can
be characterized as the model knowledge, disclosure, and
disruption resources [36], where the former two are indis-
pensable to achieve stealthy and powerful attack impacts. The
control mechanism secrecy is complementary to consider how
an external attacker can obtain such information to support
the attack design and what kinds of smart attack can be
launched with the learnt information, and how the defender
can protect the information from being inferred. In a word,
the control mechanism secrecy focuses on the stage before
injecting attacks, as shown in Fig. 3.

Privacy v.s. mechanism secrecy. The value of a system
element is private if an adversary cannot distinguish the real
value from its candidate value set based on the publicly
available information [37]. For control mechanism secrecy, its
state secrecy has a close relationship with the data privacy.
They both try to characterize the security of the system,

especially when the user focuses on the sensitive data in the
system. For example, many recent works have made progress
in preserving the state privacy of consensus-based NDSs
[38]–[41], which belong to the state secrecy of the control
mechanism secrecy. On the other hand, data privacy mainly
focuses on the leakage risk of transmissible and computable
data, while the mechanism secrecy also needs to deal with
the intrinsic model elements like the interaction topology and
control laws, i.e., the secrecy of the structure and control
law. In addition, privacy is mainly concerned with whether
the sensitive data in the system can be revealed to outsiders
(e.g., the state is privacy-preserving), which is more like a
binary form. The control mechanism secrecy investigates the
relationship between the inference performance and system
dynamics, including how accurate the inference methods can
achieve by speciﬁc methods and available observations, how
the inference error will affect the system dynamics, and how
to design efﬁcient countermeasures to degrade the inference
performance, et al. Most of these issues still remain unsolved
and need further investigation.

Security objective. The premise of analyzing the security lies
that we need to characterize the security into speciﬁc objec-
tives/metrics ﬁrst. In the literature, the famous conﬁdentiality-
integrity-availability (CIA) metrics are commonly used to de-
scribe the system security, which represents the unauthorized
information release, modiﬁcation and use, respectively [42].
The security issues concerned with the CIA metrics include
information monitoring, data corruption, and communication
blocking/delay, which mainly focus on the cyber aspect of the
system. Control mechanism secrecy is proposed to characterize
the deducibility of the system information (especially through
physical observations), which can be regarded as a new
security dimension along with the CIA properties in NDSs.

Methodology of the mechanism secrecy. Mechanism secrecy
is associated with many theories and techniques in control,
optimization and learning ﬁelds. Considering different settings
of the inference attack, different methods can be utilized
and tailored for problem-solving. For instance, if the model
form of the system is explicitly speciﬁed and known by the
external observer, inferring the system state and structure can
be regarded as a problem of parameter identiﬁcation. If the
model form of the system is totally unknown, then the problem
may fall into the realm of machine learning.

D. Main Points and Organization

In this article, we point out that utilizing advanced inference
and learning techniques to explore the internal properties of
NDSs is a new and critical research trend. These techniques
can be leveraged by adversaries to support highly intelligent
and stealthy attack behaviors, thus incurring severe risks for
NDSs. To characterize such security risks and ﬁll the gap
that traditional cyber security cannot handle, we propose a
new security property, namely control mechanism secrecy, and
construct a comprehensive analysis framework by surveying
the control
prior related results. Speciﬁcally, we interpret
mechanism as three critical elements: state information, inter-
action structure and control laws. Then, we demonstrate how
to infer the control mechanism and how to protect its secrecy
from the three aspects, respectively.

The contents are organized as follows. Section II introduces
the modeling of NDSs and the formulation of the mechanism
secrecy. Section III outlines the basic methods of inferring
the control mechanism. The counterpart defense strategies are
studied in Section IV. Detailed discussions on more compli-
cated scenarios and some meaningful open issues are provided
in Section V, inspiring more efforts on future investigation.
Finally, we present illustrative numerical examples in Section
VI and summarize this article in Section VII.

II. FORMULATION OF MECHANISM SECRECY

ij > 0 if (i, j) exists, and aσ

Let G = (V, E) be a directed graph that models the
networked system, where V = {1, · · · , N } is the ﬁnite set
of nodes and E ⊆ V × V is the set of interaction edges. An
edge (i, j) ∈ E indicates that i will use information from j.
The adjacency matrix Aσ = [aσ
ij]N ×N of G is deﬁned such
that aσ
ij = 0 otherwise. Denote
Ni = {j ∈ V : aσ
ij > 0} as the in-neighbor set of i, and
di = |Ni| as its in-degree. Deﬁne L = diag{Aσ1} − Aσ
as the Laplacian matrix of G, where 1 is a vector of all ones.
Then we have L1 = 0. A directed path is a sequence of nodes
{r1, r2, · · · , rj} such that (ri+1, ri) ∈ E, i = 1, 2, · · · , j − 1.
A directed graph has a (directed) spanning tree if there exists
at least a node having a directed path to all other nodes. G
must have a spanning tree to guarantee that at least one node’s
information can reach all other nodes.

A. System Model

Consider the nodes in a NDS are represented by V. For

i ∈ V, its dynamics is described by

xi(k + 1) = f (xi(k), ui(k), Xi(k), ωi(k)),

yi(k) = g(xi(k), vi(k)),

(1)

where Xi(k) = {xj(k), j ∈ N in
i } represents the state set of
node i’s all neighbors, xi ∈ Rni, yi ∈ Rmi and ui ∈ Rqi
are the state, output and input vectors of node i, respectively.
Besides, ωi(k) and vi(k) are mutually independent process and
measurement noises, which has both zero means and variances
of Σω
i , respectively. For the noises ωi(k) and vi(k),
the following assumption is commonly used.

i and Σv

4

Assumption 1 (Gaussian noise assumption). The process
noise ωi(k) ∼ N (0, Σω
i ) and the observation noise vi(k) ∼
N (0, Σv

i ) are i.i.d. zero-mean Gaussian noises.

Note that (1) is an abstract formulation that can represent
most system models in real applications. In the literature, the
linear time-invariant systems are most widely investigated, and
the nodal dynamics are given by

xi(k + 1) = Aiixi(k)+

N
(cid:88)

Aijxj(k)+Biui(k)+wi(k),

j∈N in

i

yi(k) = Cixi(k) + vi(k),

(2)

where Aij ∈ Rni×nj , Bi ∈ Rni×qi and Ci ∈ Rmi×ni.
Note that Aijxj(k) represents the effect of node j on node
i, and Biui(k) represents the internal input to make node i
accomplish speciﬁc control objectives. In a global form, the
dynamics of a NDS is given by

x(k + 1) = Ax(k) + Bu(k) + w(k),

y(k) = Cx(k) + v(k),

(3)

where x = [xT
[ωT

1 , · · · , xT
N ]T, and v = [vT

N ]T, y = [yT
1 , · · · , vT

N ]T, ω =
N ]T. In addition, we have

1 , · · · , yT

A11
...
AN 1

· · · A1N
...
. . .
· · · AN N






 , B =




B1
...
0

0
· · ·
...
. . .
· · · BN




 ,

1 , · · · , ωT


A =




B = blkdiag(B1, · · · , BN ), and C = blkdiag(C1, · · · , CN ).
Correspondingly, the canonical controllability and observabil-
ity matrices of the system are given by

Qc = (cid:2)B, AB, · · · , An−1B(cid:3) ∈ Rn×nq,
Qo = (cid:2)C T, (CA)T, · · · , (CAn−1)T(cid:3)T

∈ Rnm×n,

(4)

(5)

i=1 ni, q = (cid:80)N

where n = (cid:80)N
i=1 mi. The
system (3) is controllable if rank(Qc) = n, and observable
if rank(Qo) = n. Given time horizon T , we deﬁne the
corresponding controllability and observability matrices as

i=1 qi and m = (cid:80)N

Mc = (cid:2)B, AB, · · · , AT −1B(cid:3) ∈ Rn×T q,
Mo = (cid:2)C T, (CA)T, · · · , (CAT −1)T(cid:3)T

∈ RT m×n.

(6)

(7)

In most existing literature concerning system security, the
parameters (A, B, C) and input u are known to the system
(or at least the local information is known). For an external
attacker, the knowledge is unknown initially. Unless otherwise
speciﬁed, we mainly focus on linear system models (2) and
(3) in this article.

Next, we present asymptotically stable matrix class Sa and

the (strictly) marginally stable matrix Sm as follows:

Sa ={Z ∈ Rn×n, ρmax(Z) < 1},
Sm ={Z ∈ Rn×n, ρmax(Z) = 1 and the geometric

(8)

multiplicity of eigenvalue one is 1}.

5

TABLE I
REPRESENTATIVE NETWORKED DYNAMICAL SYSTEMS

System type

Model conditions

Representative literature

Examples

Integrated CPS

The system is controllable
and observable

[36], [43]–[45]

Industrial process control systems,
SCADA, transportation systems

Multi-sensor network

(A, B) is controllable

[46]–[49]

Interconnected subsystems

G is connected

[30], [50]–[52]

Environment monitoring,
distributed state tracking

Smart grid, water network,
chemical reactor network, robot formation

Consensus-based network

At least G has a spanning
tree and A is row-stochastic

[41], [53]–[55]

Time synchronization,
opinion agreement, ﬂocking

B. Common Models Variants

Note that in the literature, the results concerning the security
of NDSs may not always be based on a uniﬁed model like (2),
and the variant models can be used in different scenarios. We
summarize four commonly used model variants (for simplicity
we ignore the process and observation noise terms), which are
given as follows.

can be maliciously tampered. The latter two models (11) and
(12) can be both illustrated as the multi-agent type NDSs
(as shown in Fig. 1(b)). The common security risks of such
systems are presented in inter-agent forms, e.g., some agents
in the network are corrupted and transmit false information, or
the connections between agents are disturbed. More detailed
characteristics and examples are given in Table I.

• Integrated CPS:

x(k + 1) = Ax(k) + Bu(k),

y(k) = Cx(k).

(9)

is considered when the system of interest

This model
is
presented in a whole and the defender needs to analyze the
global performance under attack, which means that a central
unit with global knowledge about the system is required.

• Multi-sensor network:

x(k + 1) = Ax(k) + Bu(k),

yi(k) = Cixi(k).

(10)

The multi-sensor model can be seen as an extended version
of (9), where multiple sensors with different capabilities are
used to measure the same dynamic process.

• Interconnected subsystems:

xi(k + 1) =

N
(cid:88)

j=1

Aijxj(k) + Biui(k),

(11)

yi(k) = Cixi(k).

This model is used where one needs to consider the self-
dynamics and information locality of each subsystem.

• Consensus-based network:

xi(k + 1) =

N
(cid:88)

j=1

aijxj(k),

yi(k) = xi(k).

(12)

The consensus-based model is most common in the literature,
which mainly describes the agreement-achieving process in
distributed computing and control ﬁelds.

It is worth noting that, the former two models (9) and (10)
can be both illustrated as the multi-component type NDSs
(as shown in Fig. 1(a)). The networked characteristic of them
reﬂects in that the components are connected in wire/wireless
manners, and their security risks are usually presented in the
way where some dimensional values of the input/outputs (or
the complete output of a single one in multi-sensor cases)

C. Security Analysis

In this part, we present a detailed analysis of the control
mechanism. Generally, both the internal state x and the output
y can be regarded as the state of the system. The output is
the indirect reﬂection of the internal state, and is available
or observable in most situations. Next, we analyze how the
control mechanism can be susceptible to security breaches
when there is an external observer.

• First, the state directly reﬂects the system behavior in the
running process. When the system is observable, the state
of the system can be easily obtained from the outputs
if the system matrices A and C are also known. If the
values of A and C are unknown but their dimensions
are known, then the problem turns to the identiﬁcation of
these matrices, where the identiﬁed matrices are used to
restore the states. Even if the system is not observable,
it is possible to infer the underlying states with growing
observations, e.g., by regression or Bayesian methods.
• Second, the structure of NDSs speciﬁes the information
ﬂow between different nodes (e.g., Aij in model (2)),
and the coupling relationships between different state
dimensions of a single node (e.g., Bi in model (2)). Even
though the matrix values may not be estimated accurately
by the malicious observer, their corresponding binary at-
tributes are much easier to infer, which also leaks critical
system information and causes great risks. This security
vulnerability will be worse when the system reacts to
external inputs, or the states are fully measurable.

• Third, the control laws are the cornerstone for the running
process of the system. In practice, the design of the
control laws is determined by multiple factors, including
the stability, practical model, and control objectives (or
performance metrics) of the system. Although the control
laws of the system are generally unavailable for an ex-
ternal observer, it is highly possible that the rules can be
approximated based on observed system interactions, e.g.,

6

Fig. 4.

Illustration of the inference attack against the control mechanism of NDSs.

by state-of-the-art data-driven techniques. Consequently,
the approximated rules can be leveraged to predict the
system behavior for malicious purposes.

In a summary, the three elements determine the evolution
process and convergence performance of the system, which
are of vital importance for system implementation. Unfortu-
nately, the state-of-art information techniques have enabled an
external adversary without any prior knowledge to infer the
control mechanism. When the sensitive information is leaked
and mastered by the adversary, it increases the capabilities of
precise attacks against the system and reduces the trial-and-
error costs of attack implementation. Traditional cyber-security
countermeasures hardly take the leakage risks into account,
potentially increasing the defense costs and undermining the
efﬁciency of alleviating attack impacts. Therefore, it is essen-
tial for NDSs to develop methods that guarantee the control
mechanism secrecy.

D. Inference Attack against NDSs

We now present the setting for the external attacker, who
aims to infer the control mechanism of NDSs from external
observations. Since the control mechanism of NDSs includes
the state, structure and control laws, attacks can be launched
against these three aspects. In the following, we deﬁne the
inference attack, which is also illustrated in Fig. 4.

Deﬁnition 1 (Inference Attack). An external attacker can
access the observations {yi : i ∈ V} in the dynamics (1) and
excites the system nodes with designed inputs {ue
i : i ∈ V}.
Then, the attacker infers the control mechanism by ﬁnding the
following groups of mapping relationships

φX : {yi : i ∈ V} → {xi : i ∈ V},
φA : {yi, yj : i, j ∈ V} → {Aij : i, j ∈ V},
φU : {yi, yj, j ∈ Ni : i ∈ V} → {ui : i ∈ V}.

(13)

(14)

(15)

It is remarkable that the inference attack is oriented from
observations of the NDS and requires no prior knowledge
about the control mechanism. Therefore, this kind of attack is
pervasive in the attack-defense context for an external attacker
to master the control mechanism to a great extent. The inferred
knowledge further facilitate the attack capability, like sneaking
into the system stealthily or striking the vulnerable parts
precisely. In addition, the three inference processes (13)-(15)
about control mechanism are not necessarily independent of
each other but can be deeply coupled.

E. Example: Coordination of Mobile Robots

Finally, for better understanding, we take the coordination
problem of mobile robotic network as a typical example to
illustrate the mechanism secrecy of NDSs. In the following
example, a mobile robotic network of N agents aims to
achieve motion coordination. Let xi = [xi,1, xi,2]T be the
state of robot i, where xi,1 and xi,2 represent the position
and velocity, respectively. Based on Newton’s motion law, the
dynamics of robot i is described by

xi,1(k + 1) = xi,1(k) + T0xi,2(k) + (T 2
xi,2(k + 1) = xi,2(k) + T0uf

i (k),

0 /2)uf

i (k),

(16)

where T0 > 0 is the control period, and the feedback input
uf
i (k) is given by [56]
(cid:88)
uf
i (k) =

aij[xj,1(k) − xi,1(k) + α(xj,2(k) − xi,2(k))].

j∈N in

i

(17)

Then, substituting (17) into (16) and one has

(cid:20)xi,1(k + 1)
xi,2(k + 1)

(cid:21)

= ˜Aii

(cid:21)
(cid:20)xi,1(k)
xi,2(k)

+

(cid:88)

˜Aij

j∈N in

i

(cid:21)
(cid:20)xj,1(k)
xj,2(k)

, (18)

where

˜Aii =

and ˜Aij =

(cid:80)

(cid:34)
1 − T 2
0
2
(cid:80)
−T0

aij

j∈N in

i
j∈N in
(cid:21)

i

aij

(cid:20) T 2
0 aij
2

αaij T 2
0
2

.

T0aij αT0aij

0

T0 − αT 2
2
1 − αT0

(cid:80)
(cid:80)

j∈N in

i
j∈N in

i

aij
aij

(cid:35)

,

Note that (18) shows an autonomous control process within
the system. If the control objective is associated with other
tasks (e.g., go to a speciﬁc region), then an extra driving
control law ˜ui is required. From (18), the state-correlation
structure ˜Aii indicates that the two states of a single robot is
correlated. The node-connectivity structure Aij speciﬁes how
a robot interacts with its neighbors, where aij is critical. For
an external attacker, the position and velocity of a robot are
generally measurable in practice, and thus the state of the
robotic network is also observable. Based on the measured
trajectory information, the attacker can use many state-of-the-
art methods to infer the real states x, the structure matrix
A, and even extra control laws ˜ui if any. Therefore, there
exist severe risks that the mechanism of the robotic network
is disclosed to an attacker, and effective countermeasures are
necessary to be developed.

III. INFERRING THE CONTROL MECHANISM

In this section, we ﬁrst elaborate that the inference per-
formance of the malicious observer is closely related to the

7

TABLE II
STATE SECRECY UNDER DIFFERENT PRIOR KNOWLEDGE OF ATTACKERS AND SYSTEM PROPERTIES

Capability of
the Inference Attack

Measurable (C is invertible)

(A, C) observable

(A, C) unobservable

Properties of the System

Prior knowledge
of the Attacker
over the System

The values of (A, C)
are exactly known

x(k) can be directly obtained
given y(k)

at least n groups of observa-
tions are needed

T groups of observations such
that Mo is invertible, or only
obtain sparse solution

Only dimensions of
(A, C) are known

(A, C) are totally un-
known

the state is possible to be estimated by system identiﬁcation techniques

hard to estimate

the state cannot be estimated based on the system observability

prior information and system properties (e.g., observability and
controllability). Then, we introduce the basic methods to infer
the state and topology structure of NDSs. Both the global and
local inference cases are considered.

A. Prior Knowledge and Inference Conditions

Considering the output of the system, classic observability
is commonly used in the state estimation problem. To better
describe a major class of NDSs, we further deﬁne the mea-
surability of states as follows.

Deﬁnition 2 (Measurability of states). The state of subsys-
tem/node i is fully measurable if the observation matrix is
full-ranked, i.e.,

rank(Ci) = ni.

(19)

Note that if the states of each node are fully measurable,
then the global system is also measurable, i.e., rank(C) = n.
Consequently, if the state of the global system is measur-
able, the observability of the system is also guaranteed, i.e.,
rank(Mo) = rank(C) = n holds. Since rank(C TC) = n
for systems with fully measurable states, we directly assume
C = I for these systems in the following sections.

Given system model (3), we characterize the prior knowl-
edge of the observer into three categories: i) the values of
(A, C) are known,
ii) only the dimensions of (A, C) are
known, and iii) (A, C) are unknown. The ﬁrst situation de-
scribes the most powerful observer, while the last one presents
a totally ignorant observer. Since the available outputs are
the most critical elements for estimating the states and the
measurability and observability of the system will determine
the inference cost
to obtain the ﬁnal estimate. To better
illustrate this effect, we summarize the conclusion in Table
II. In this section, we mainly focus on the case where (A, C)
is known and the system satisﬁes the state measurability
condition, and discuss the other cases in the following sections.

B. Inferring the State

Inferring the state of NDSs can be regarded as conventional
state estimation problems, which aim to reconstruct the system
state from the obtained measurements. Considering different
observation ranges on NDSs, the problems are divided into
two types: global and local state estimation.

1) Global State Estimation: For simplicity, we ﬁrst assume
the state transition matrix, A, and the observation matrix,
C, are known. Given a time horizon T , one aims to use an
estimator φX (y(k), k = 0, · · · , T − 1) : RmT → Rn to recon-
struct the initial system state x(0). For simple expressions, the
observations and noises in T steps are organized as

yT = [yT(0), · · · , yT(T − 1)]T,
vT = [vT(0), · · · , vT(T − 1)]T.

When there is no input u and process noise w, one has

yT = Mox(0) + vT .

(20)

Based on (20), we show how the initial state is estimated in
the following theorem.

Theorem 1. Consider the observation model (20) and As-
sumption 1 holds. If rank(Mo) = n holds, then the unbiased
estimator for x(0) is given by

ˆx(0; T ) = (M T

o Mo)−1M T

o yT ,

(21)

whose estimation error satisﬁes

lim
T →∞

Pr{(cid:107)ˆx(0; T ) − x(0)(cid:107) = 0} = 1.

(22)

The estimator ˆx(0; T ) easily follows from (20) as long as the
observability matrix rank(Mo) = n is guaranteed. Apparently,
if there are no noises involved in the observations, then x(0)
can be accurately estimated. For other states x(k), 0 < k < T ,
one only needs to take x(k) as the new initial state of interest,
and use the data in the slot [k, T − 1] to calculate ˆx(k)1. The
unbiased asymptotic estimation error (22) is explained by the
following remark.

Remark 1. Under Gaussian noises, the estimator by (21) is
called the maximum likelihood estimate (MLE) of x(0), whose
estimation performance can be represented by the covariance
of the error vector (e.g., see [53]). Here, the estimation error
is given by

(cid:107)ˆx(0; T ) − x(0)(cid:107) = (cid:107)(M T

o Mo)−1M T

o vT (cid:107).

(23)

Then, the limit of (22) is derived by adopting the concentration
inequality of Gaussian matrix (see Chapter 2 in [57]), and the

1For example, let yk:T = [yT(k), yT(k + 1), · · · , yT(T − 1)]T and
. Then, x(k) can be
o (T − k)yk:T

Mo(T − k) = (cid:2)CT, (CA)T, · · · , (CAT −k−1)T(cid:3)T
estimated by ˆx(k; T ) = (cid:0)M T
when rank(Mo(T − k)) = n holds.

o (T − k)Mo(T − k)(cid:1)−1 M T

convergence rate of the estimation error is mainly determined
by the stability of A. Note that if the noises are not in Gaussian
form, (21) cannot be interpreted as MLE but the optimal
estimator with least square errors.

It is worth mentioning that if there is other available prior
knowledge about the system, the condition rank(Mo) = n
can be relaxed. For instance, in scenarios when mT < n, it
is common to assume that x(0) is a sparse vector. Then, the
state vector can be obtained by solving the compressed sensing
problem, given by

min
x(0)

(cid:107)x(0)(cid:107)0 s.t., yT = Mox(0),

(24)

whose solution is characterized by the following result

Theorem 2 (see [58]). Let ˆx(0; T ) be the solution of problem
(24) and q = (cid:107)ˆx(0; T )(cid:107)1 (1 ≤ q ≤ n). If mT > 2q and all
subsets of 2q columns of Mo are full rank, then ˆx(0; T ) is
unique.

Theorem 2 reveals the possibility of obtaining a unique
estimate of x(0) when the observations are insufﬁcient. In the
literature, this type of problem is called sparse identiﬁcation
and has received increasing attention recently [48], [59], [60].
2) Local State Estimation: Here we consider a more gen-
eral situation where only local outputs of the system are
available for the observer. Suppose the observer has access
to the outputs of node j and its in-neighbors Nj, and it aims
to estimate the initial state xi(0), i ∈ Nj. When the system is
noise-free, the output of node j is given by

yj(k) = Cjxj(k) = CjA[j, ˜Nj ]x ˜Nj
where ˜Nj = {j} ∪ Nj, A[j, ˜Nj ] = [Ajl1 , · · · , Ajl| ˜Nj |
x[ ˜Nj ] = [xl1, · · · , xl| ˜Nj |

] and
]. Recursively, it follows from (25) that

(k − 1),

(25)

yj(k) = Cj[Akx(0)]j.

(26)

Note that the observer only knows the local information Ci,
, the term [Akx(0)]j in (26) when k ≥ 2
A[j, ˜Nj ] and x ˜Nj
cannot be computed due to

[Akx(0)]j (cid:54)= [Ak][j, ˜Nj ]x ˜Nj

(0) (cid:54)= (A[j, ˜Nj ])∗kx ˜Nj

(0),

(27)

where the power exponent symbol (·)∗k represents an element-
wise power operation in the matrix. Since estimating xi(0)
from the local information of node essentially requires global
knowledge in general sense, it cannot be cast as a simple state
observability problem, but can be treated as a joint problem
combined with other techniques (e.g., system identiﬁcation
and Bayesian methods). More formally, the solvability of this
problem heavily depends on the topology of the system.

Theorem 3 (Necessity of local state estimate [53], [61], [62]).
Consider the observation model (25). To accurately estimate
xi(0) (i ∈ Nj) by the information of node j, the following
neighboring condition must be satisﬁed, given by

˜Ni ⊆ ˜Nj.

(28)

Note that the condition (28) guarantees that node j has com-
plete information of its neighbor nodes. Under this situation,

8

xi(0) can be estimated by node j with high conﬁdence. Similar
to the global estimation case, the accuracy of ˆxi(0) can be
directly represented by (cid:107)ˆxi(0) − xi(0)(cid:107). Since the focus of
this article is to characterize the mechanism secrecy under
inference attack and discuss possible countermeasures, more
detailed state estimation methods are omitted here.

In the literature, the security issues concerning the state
estimation mainly focus on how to estimate the state from
observations in the presence of sensor attacks, and further
design secure controllers to alleviate the inﬂuence of the
attacks. It is remarkable that the state estimation procedure in
these works is conducted by the system itself, which has partial
or complete knowledge about the nominal system parameters,
e.g., matrices A and C. In this article, we reveal that it is
possible that these estimation methods can be leveraged by
external adversaries to infer the sensitive state information of
the system, causing severe threats to the system.

C. Inferring the Topology Structure

The structure of NDSs contains two aspects: the coupling
structure between different states of a single node, and the
interaction topology between different nodes. For simplicity,
we begin with this one-dimensional node state case and focus
on the topology structure, by considering the following input-
free global model

x(k) = Ax(k − 1) + ω(k − 1),

y(k) = x(k) + v(k),

(29)

where ω(k) and v(k) satisfy Assumption 1.

Methods Review. Inferring the interaction topology from
observations over the NDSs emerges in various applications
in last decades, including multi-robot formation [63], social
networks [64], and brain connectivity patterns [65]. With
the topology obtained, one can trace the information ﬂow
over a social network, or identity the critical node with
maximum inﬂuence in a communication network. Generally,
the feasibility of topology inference lies in that the states of
the target systems are fully measurable, so as to establish an
explicit expression between adjacent observations. Otherwise,
one can hardly extract the underlying topology from direct
observations.

Mathematically, topology inference can be regarded as an
inverse problem. In the literature, a large body of research
has been developed to tackle the problem due to their massive
employments [77], [78]. Generally, the following four types
of methods are commonly used: Granger estimator, spectral
decomposition, kernel-based methods, and sparse identiﬁca-
tion. The basic principles and characteristics of these methods
are summarized in Table III. These works mainly focus on
symmetric topology and asymptotic inference performance.

For example, if multiple observation round are available
then the node directionality can be

over the system (3),
described by the Granger causality [66], [68], given by

Rx

1 (t) = W Rx

0 (t−1),

(30)

TABLE III
REPRESENTATIVE METHODS OF TOPOLOGY INFERENCE

Methods

Granger estimator
e.g., [66]–[68]

Spectral decomposition
e.g., [69]–[71]

Kernel method
e.g., [72]–[74]

Sparse identiﬁcation
e.g., [59], [75], [76]

Principles
utilize the node causality exhibited in
the consecutive two states in expected
sense. Multiple observation rounds
over the dynamic process are needed,
and the topology is symmetric
utilize the diagonalization of the sam-
ple matrices and reconstruct the sym-
metric topology by ﬁnding suitable
eigenvalue/eigenvector pairs
suitable for nonlinear dynamic topol-
ogy, key idea: select appropriate ker-
nel basis functions to approximate the
nonlinear dynamics
between
consider
nodes are sparse, and take the sparsity
as a priori known

connections

the

t

t−1

W = Rx

(cid:3) and R1 = E (cid:2)xtxT

(cid:3) are the auto-
where R0 = E (cid:2)xtxT
correlation and one-lag autocorrelation matrices. Accordingly,
when t → ∞, one can infer the topology by
1 )−1(∞).

1 (∞)(Rx
Note that this result is based on observations over multiple
process rounds, and the observation noises are often ignored.
In this part, we use the ordinary least square method to
illustrate how to infer a directed topology from observations in
a single round, and present their non-asymptotic performance.
1) Global Topology Inference: Since the topology to be
inferred is represented by a matrix variable and to differentiate
with the notations in the last subsection, we organize the
state/observation/noise vectors of T steps as matrices

(31)

X −
T = [x0, x2, · · · , xT −1], X +
T = [x1, x2, · · · , xT ],
T = [y0, y2, · · · , yT −1], Y +
Y −
T = [y1, y2, · · · , yT ],
ΩT = [ω0, ω1 · · · , ωT −1], ΥT = [υ1, υ2 · · · , υT ].

(32)

Then, the whole dynamic process is compactly written as
T + ΩT , Y +

T + VT .
For every two adjacent observations, it follows that

T = AX +

T = AX −

X +

(33)

9

interference noises. In fact, the observation noise will inﬂuence
the inference performance of (36).

For simplicity, we deﬁne the following sample covariance

matrix and its one-lag version as

Σ0(T ) =

1
T

(Y −

T )(Y −

T )T, Σ1(T ) =

1
T

(Y +

T )(Y −

T )T.

(37)

Then, a revised version of is given by the following theorem.

Theorem 4 (Causality in single observation round; see [79]).
Considering the systems (29) and given observations {yt}T
t=1,
if A ∈ Sa, we have

Σ1(∞) = A(Σ0(∞) − σ2

υI),

(38)

where Σ1(∞) = lim
T →∞

Σ1(T ) and Σ0(∞) = lim
T →∞

Σ0(T ).

Different from the Granger causality in (30), Theorem 4
relaxes the dependence on multiple observation rounds, and
presents the observation causality for a single round, while
taking the observation noises into account. Then, given a ﬁnite
horizon T , we propose the causality-based estimator as

ˆAc = Σ1(T )(Σ0(T ) − σ2

υI)−1.

(39)

Remark 2. We demonstrate that although the estimator ˆAc
is derived from Theorem 4 where A ∈ Sa holds, it is also
applicable when A ∈ Sm. In fact, Theorem 4 is directly
based on the Chebyshev inequality, where the bounded state
constraint precludes us from proving the convergence and
accuracy of ˆAc when A ∈ Sm. To tackle this issue, we can
resort to the concentration measure in Gaussian space.

Next, we explicitly characterize the convergence and accu-

racy of the two estimators.
Theorem 5 (Convergence speed and accuracy of ˆAo and ˆAc;
see [80]). Considering the systems (29), with probability at
least 1 − δ, the non-asymptotic bound of the OLS estimator
ˆAo satisﬁes

(cid:107) ˆAo − A(cid:107) ∼






O(

O(

(cid:114)

1
√
T

) + O(σ2

υ),

log T
T
) + O(σ2

υ),

if A ∈ Sm,

if A ∈ Sa.

(40)

yt = W xt−1 + ωt−1 + vt

= Ayt−1 − Avt−1 + ωt−1 + vt.

(34)

and the non-asymptotic bound of the causality-based estimator
ˆAc satisﬁes

Note that (34) only represents the quantitative relationship
between adjacent observations, not a causal dynamical pro-
cess. Then, the popular OLS estimator is derived solving the
following problem

(cid:107) ˆAc − A(cid:107) ∼






O(

O(

(cid:114)

log T
T

),

1
√
T

),

if A ∈ Sm,

if A ∈ Sa.

(41)

P1 : min
A

T
(cid:88)

t=1

(cid:107)yt − Ayt−1(cid:107)2 ⇒ min
A

(cid:107)Y +

T − AY −

T (cid:107)2

F (35)

Then, by ﬁnding the derivative, one obtains the optimal
solution as

ˆAo = Y +

T )T(Y −
It should be noted that, the OLS estimator essentially treats
all the terms in yt − Ayt−1 = −Aυt−1 + ωt−1 + vt as

T )T)−1.

T (Y −

T (Y −

(36)

In terms of sample scale T , Theorem 5 demonstrates the
convergence speed of the inference error bound by using ˆAo
and ˆAc. We conclude that the extra cost for the estimators
when W ∈ Sm is longer error converging time (or larger
log T ) times than
observation sample scale), requiring O(
that when W ∈ Sa. In terms of accuracy, when T → ∞, the
inference error will converge to a constant by ˆAo, while that
of ˆAc will converge to zero, which shows the latter one has
better inference accuracy.

√

Finally, we demonstrate the relationship of the causality-
based estimator ˆAc with the Granger estimator ˆAg and OLS
estimator ˆAo, by revealing the equivalence condition of their
observation matrices in single and multiple observation rounds,
respectively. Taking (cid:107)W (cid:107)2
F as the regularizator, P1 is trans-
formed to

P2 : min
A

T
(cid:88)

k=1

(cid:107)yk − Ayk−1(cid:107)2 + β(cid:107)A(cid:107)2
F ,

(42)

where β is a regularization parameter. Then, we present the
following theorem.
Theorem 6 (see [79]). Considering the systems (29), for ˆAc
and ˆAg, if A ∈ Sa, when T → ∞, we have
υI, Σ1(∞) = Rx

(43)
For ˆAc and ˆAo, ˆAc is equivalent to solving P2 with β = −σ2
υ,
which is a de-regularization form of ˆAo.

Σ0(∞) = Rx

0 (∞) + σ2

1 (∞) + σ2

υA.

This theorem is signiﬁcant in two aspects. First, it reveals
the expected state covariance matrix of T → ∞ is
that
identical with the sample covariance matrix along the single
time horizon, which is an interesting result that describes the
relationship between multiple and single observation rounds.
Second, it provides a new interpretation for using LS methods
to infer the interaction topology from the perspective of node
causality. Also, it shows the idea of how to set a reasonable
regularization term and parameters for the LS problem mod-
eling when both the input and output data are corrupted.

2) Local Topology Inference: Denote by VF the observable
and VF (cid:48) = V\VF the unobservable subsets in V, respectively.
Given the system dynamics described by (29), the inference
robot ra has only observations of VF ⊆ V. Based on this
division, the state evolution in (29) is divided into
(cid:35)

(cid:35) (cid:34)

(cid:35)

(cid:34)

(cid:34)

(cid:35)

(cid:34)

xF
k+1
xF (cid:48)
k+1

=

AF F AF F (cid:48)
AF (cid:48) F AF (cid:48) F (cid:48)

xF
k
xF (cid:48)
k

ωF
k
ωF (cid:48)
k

+

,

(44)

where xF (cid:48)
Note that
observer satisﬁes

k+1 is the state of the unobservable part VF (cid:48) = V\VF .
k } for the external

the available information {yF

k+1 = AF F yF
yF

k + ωF

k + AF F (cid:48)xF (cid:48)

k + vF

k+1 − AF F vF
k ,

(45)

which only represents the explicit relationship of every two
consecutive observations, not a real process. Then, the local
topology inference problem is to obtain the structure matrix
AF F from the observations {yF
k }. It is intuitive that one may
adopt a truncated version of (36) to calculate AF F , given by
T,F )T(Y −

ˆAF F = Y +

T,F )T)−1.

T,F (Y −

T,F (Y −

(46)

Unfortunately, (46) is far from the strict least square solution
by basic linear algebra, i.e.,

ˆAF F (cid:54)= [Y +

T (Y −

T )T(Y −

T (Y −

T )T)−1]F F .

(47)

From (45), the unequal effect is incurred by the non-negligible
terms {AF F (cid:48)yF (cid:48)
k } even when T → ∞. Hence, it is extremely
hard to infer the local topology AF F with high accuracy from
noisy {yF

k }.

10

Remark 3. Under speciﬁc conditions, it is possible to obtain
an (asymptotically) accurate estimate of the local topology
by estimator (46). Recent works [68], [81], [82] have made
some progress in deriving the conditions, for example, i) the
topology is in symmetric Erd˝os-R´enyi random graph form
with vanishing connection probability, and ii) the ratio of the
observable nodes to all nodes converges to constant as the
network goes to inﬁnity. These methods cannot infer directed
topology where the speciﬁed node conditions are not available.

To obtain a reliable local topology estimate, an alternative
method is to shrink the inference range [12]. Let VH be a
subset of VF such that

Ni ⊆ VF , ∀i ∈ VH.

(48)

Denote VH(cid:48) = VF \VH and AHF = [AHH AHH(cid:48)]. Then, the
optimal estimation of WHF in the sense of least square can be
calculated by

ˆAHF = Y +

T,F (Y −

T,H (Y −

T,F )T)−1,

T,F )T(Y −
which is free of the inﬂuence from the unobservable part VF (cid:48).
Note that a drawback of this method is that one needs to
determine the subset VH ﬁrst. In many situations where no
more prior knowledge is available, one can select a small
VH (e.g., single node) to obtain a relatively conservative
estimation.

(49)

D. Inference by Known Excitation: System Identiﬁcation

In this part, we point that if i) the system is driven by inputs
which are known to the attacker, or ii) the attacker is able to
inject self-designed excitation inputs into the system, then it is
possible to reconstruct the state and structure from the input-
output data, which can be regarded as a system identiﬁcation
(SI) problem.

In the context of SI, the attacker access the inputs and
outputs of NDSs (e.g., the velocities and positions of mobile
robot as the inputs and outputs, respectively), while the
state x, the process noise ω and the measurement noise v
are unavailable. Conventionally, the following assumption is
usually made in the literature for consistent and convergent
identiﬁcation results [83].

Assumption 2. The system (3) is controllable, observable,
and minimal realization with the system order known. The
excitation input u is persistently exciting, and the initial state
is a zero vector.

To describe the analytical relationship between the input
and output, the Markov parameter matrix G(T ) is commonly
used, which is deﬁned as

G(T ) = (cid:2)CB, CAB, · · · , CAT −2B, CAT −1B(cid:3) .

(50)

Upon deﬁning the upper-triangular Toeplitz matrices corre-
sponding to {u(k)},









UT =

u(0) u(1) u(2)
u(0) u(1)
u(0)
...
0

0
0
...
0

0
...
0

· · · u(T − 1)
· · · u(T − 2)
· · · u(T − 3)
. . .
· · ·

...
u(0)









.

the process and
Note that under Assumptions 1 and 2,
measurement noises are zero-mean and x(0) = 0. With these
in mind, one can form the following least-squares problem,

ˆG = arg min
G∈Rm×T q

(cid:107)Y −

T − GUT (cid:107)2
F .

(51)

To solve the above problem, many popular methods can be
adopted, such as the subspace method. Ideally, one wishes the
estimation error (cid:107) ˆG − G(cid:107) to be as small as possible. Many
recent works have achieved fruitful advances [84]–[86].

With the solution ˆG obtained, one can further use the
celebrated Ho-Kalman Algorithm [87] and singular value de-
composition techniques to estimate all the system parameters,
including the matrices A, B and C. It should be noted that
this derived system model is a similarity transformation of the
original system (3) but shares the same inputs and outputs.
Mathematically, it can be represented as

(cid:26) ˜x(k + 1) = ˜A˜x(k) + ˜Bu(k) + ω(k),

y(k) = ˜C ˜x(k) + v(k),

(52)

where ˜A = P −1AP , ˜B = P −1B and ˜C = CP (with P ∈
Rn×n is a nonsingular matrix). Consequently, under the model
(52), the system state x(0) is easy to estimate in the same
manner as (21) by using ˜C and ˜A. For states x(k), 0 < k < T ,
the corresponding estimates can be easily obtained from the
data in the slots [k, T − 1], by taking x(k) as the new initial
state of interest.

Compared with directly inferring the state or structure of
NDSs, the SI methods utilize the excitation input and enjoy
the merits of not relying on much prior knowledge (like A
and C need to be known in observability based methods).
Besides, both the state and structure can be simultaneously
inferred by ﬁrst estimating the Markov matrix G(T ). We
observe that the key of the SI methods is to approximate the
real Markov matrix, not the real matrices A, B, C. In other
words, the value accuracy of the obtained ˜A, ˜B, ˜C along
with the corresponding states cannot be guaranteed, as they
are essentially approximating the similarity transformations of
the real ones. Therefore, directly using SI methods may be
inappropriate if one aims to infer the real value of the system
states and matrices. However, if one only cares for the system
properties in matrix space (e.g., the supports and eigenvalues
of A), then the SI methods is an effective alternative.

IV. PRESERVING THE CONTROL MECHANISM SECRECY

Since the control mechanism is highly vulnerable to infer-
ence attacks, it is very necessary to develop effective methods
to preserve the control mechanism secrecy. In this section,
we ﬁrst present the main ideas of introducing secrecy and
related method review. Then, we demonstrate how to measure
the secrecy degree of the state and topology, and summarize
possible techniques to preserve the control mechanism secrecy.

A. Methods Review

In the literature, the encryption and noise-adding schemes
are two mainstream approaches to secure the system informa-
tion from being accurately inferred.

11

Encryption. The encryption-based mechanism is commonly
used in many communication network systems, where each
node sends cryptographic information and decodes the re-
ceived using private/public keys (see [88] for a review). The
encryption mechanism (especially homomorphic encryption)
is a powerful tool to protect data privacy during data exchange
and sharing, making the data computable by others while
unrevealed to them [89]–[93]. As encryption by cryptographic
algorithms is adopted during communication and computation
(e.g., sensor measurements and controllable signals),
is
effective against cyber attacks but not inference attacks. Since
many NDSs which are physically open in the environment,
even if the encrypted communication and computation scheme
does not reveal the data, external observations of the sys-
the
tem operation can still reveal
displacements and velocities of a mobile robotic system can
be directly observed and measured. Therefore, the encryption-
based mechanism is not effective for the control mechanism
secrecy of physically open NDSs.

the states/outputs, e.g.,

it

Noise-adding. The noise-adding scheme protects the system
information by adding admissible random signals to the local
dynamics. Due to its simple implementation, the noise-adding
scheme has received considerable attention in recent years and
is widely used for the security of NDSs [37]–[39], [54], [94].
Among these works, the notion of differential privacy has been
widely applied to design the noise-adding method and analyze
the performance [95]–[97]. Differential privacy means that the
presence or absence of any individual record in the database
will not affect the statistics signiﬁcantly. The formal deﬁnition
is given as follows.

Deﬁnition 3 (((cid:15), δ)-differential privacy). A randomized mech-
anism A with domain Ω is ((cid:15), δ)-differentially private if, for
any pair x1 and x2 (x1, x2 ∈ Ω ⊆ Rn) of σ-adjacent state
vector and any set O ⊆ Ra(A), where Ra(A) is the domain
of the output under mechanism A,

Pr{A(x1) ∈ O} ≤ e(cid:15) Pr{A(x2) ∈ O} + δ.

(53)

If δ = 0, we say A is (cid:15)-differentially private.

However, due to the distributed and dynamical nature of
NDSs, the additive noises on each node will adversely traverse
in the system, cause perturbation on the dynamic process,
and possibly make the resulting behavior deviate from the
desired one. Therefore, the differential privacy may not be
the perfect support
to design the noise, especially when
there is a tradeoff between the operational performance and
security requirements [98]. For example, [97] has proved
that the commonly used average consensus in NDSs and (cid:15)-
differential privacy guarantees are impossible to be realized
simultaneously. Based on the above analysis, an admissible
noise-additive scheme should be capable of addressing the
tradeoff between the desired dynamics and mechanism secrecy
of NDSs, which is still an open issue (more details will be
discussed in Section V-C). In this article, we mainly focus on
investigating the secrecy design using noise-adding methods
and analyzing the performance.

Inference goal

Basic setting

Estimator / Method

Performance / Conditions

TABLE IV
A SUMMARY OF TOPOLOGY INFERENCE RESULTS

12

Global state

(A, C) is known and observable

ˆx(0; T ) = (M T

o Mo)−1M T

o Y

Local state

{Ci, A} is observable, consensus model

Maximum likelihood estimator

Global structure

Consensus-based model (29)
only observations {y(k)} are available

ˆAc = Σ1(T )(Σ0(T ) − σ2

υI)−1

Local structure

∃VH ⊆ VF , ∀i ∈ VH , Ni ⊆ VF

ˆAHF = Y +

T,H (Y −

T,F )T(Y −

T,F (Y −

T,F )T)−1

lim
T →∞

Pr{(cid:107)ˆx(0; T ) − x(0)(cid:107) = 0} = 1

˜Ni ⊆ ˜Nj is necessary

lim
T →∞

Pr{(cid:107) ˆAc − A(cid:107) = 0} = 1

lim
T →∞

Pr{(cid:107) ˆAHF − AHF (cid:107) = 0} = 1

Global joint
inference

The system is controllable and observable
excitation input is available and known

System identiﬁcation procedure
infer Markov matrix G

The similar transformation of (x, A, B, C)
are derived by Ho-Kalman Algorithm

B. Preserving Initial State Secrecy by Adding Noises

In this subsection, we consider the scenario where node j
wishes to estimate the initial state of node i, i.e., xi(0). To
begin with, we focus on the consensus model where ui is
absent and xi is one-dimensional. The results can be extended
to general NDSs. Let θi(k) be the added random noise on
node i at iteration k, and x+
i (k) be the state sent out by node
i in iteration k, given by

x+
i (k) = xi(k) + θi(k).
Note that θi(k) may be dependent of the noises before iteration
k. When node i receives the information from its neighbor
nodes, its state is updated by

(54)

is named the (cid:15)-optimal distributed estimation of xi(0) at
iteration k. Then, ˆx∗
i (k) is named the (cid:15)-optimal
distributed estimation of xi(0).

i = limk→∞ ˆx∗

Note that for any estimate ˆxi satisfying |xi − ˆxi| ≤ (cid:15), we
call it as a (cid:15)-accurate estimate of xi(0). For simplicity, in
the following parts, we drop the (cid:15) and directly call ˆx∗
i as the
optimal distributed estimation. Then, to further quantify the
security degree of the noise-adding algorithm (55) and derive
the relationship between estimation accuracy and state secrecy,
we introduce the following ((cid:15), δ)-data-secrecy deﬁnition.

Deﬁnition 5 (((cid:15), δ)-state secrecy). A distributed randomized
algorithm is ((cid:15), δ)-state-secret, iff

xi(k + 1) = hi(x+

i (k), X +

i (k)),

(55)

i (k) = {x+

where X +
j (k) : j ∈ Ni} is the received neighbor
information set, and hi represents the state-transition function
of node i. The equation (55) deﬁnes a distributed iteration
algorithm that protects the state secrecy, since mixed random
noises are used for state update in each iteration.

1) Performance Metric For State Secrecy: First, we present
an uniform formulation for state secrecy. Deﬁne the output
sequences of node i in the running process until iteration k by

I out
i

(k) = {x+

i (0), ..., x+

i (k)},

(56)

Note that during the running process of any neighbor node
j ∈ Ni, it can receive the information from not only node i,
but also its own neighbors N in
j , which may contain common
neighbors of N in
that help to estimate xi(0). Therefore, we
deﬁne the information sequence of node j to estimate node i
until iteration k by
j(k) = {x+
I i

i (k), x+

(cid:96) (k) |

i

(cid:96) (0), ...., x+

i (0), x+
(cid:96) = j or (cid:96) ∈ Ni ∩ Nj},

(57)

i

i (0)}.

Apparently, when k = 0, node j only has one-step information
of node i, i.e., I i

(0) = {x+

j(0) = I out

Next, considering I i

j(k) is the only available local knowl-
edge to estimate node i, we deﬁne the (cid:15)-optimal distributed
estimation of xi(0) as follows ((cid:15) ≥ 0 is a small constant).
Deﬁnition 4 ((cid:15)-optimal distributed estimation). Let I out
(k) be
the possible output given xi(0) = ν at iteration k. Considering
(cid:15)-accurate estimate, under I i
j(k),
Pr (cid:8)I out
(k) = I out

(k) | ∀|ν − ˆxi| ≤ (cid:15)(cid:9) ,

ν

ˆx∗
i (k) = arg max
ˆxi∈Xi

ν

i

δ = Pr{|ˆx∗

i − xi(0)| ≤ (cid:15)},

(58)

where δ is the disclosure probability that the initial state xi(0)
can be successfully estimated by others using the optimal
distributed estimation in a given interval [xi(0) − (cid:15), xi(0) + (cid:15)].

Remark 4. By calling ˆx∗
i as the optimal estimation of xi(0),
we mean that it is the best estimation of xi(0) that other nodes
could ever obtain with the available information (e.g., the
network topology and updating rule are known), regardless
of the speciﬁc methods they use. Therefore, the ((cid:15), δ)-state
secrecy in fact depicts the largest probability that xi(0) is
disclosed with tolerable error (cid:15).

2) Secrecy Performance under Noise-adding Method: As
the initial states of the nodes are important and conﬁdential
variables for the system, we next focus on the performance
analysis of inferring the initial states.

Theorem 7 (see [99]). Considering the noise-adding algo-
rithm (55), under I i
j(k), the optimal distributed estimation of
xi(0) satisﬁes

i (k) = x+
ˆx∗

i (0) − eθi(0)|I i

j (k)(x+

i (0)),

(59)

where

eθi(0)|I i

j (k)(x+

i (0))

= arg

max
i (0)−Xi}

y∈{x+

(cid:90) y+(cid:15)

y−(cid:15)

fθi(1),...,θi(k)(˜θi(1), ..., ˜θi(k))

fθi(0)|θi(k)=˜θi(k),...,θi(1)=˜θi(1)(z)dz,

(60)

13

i.e., ˜θi(k) is not a deterministic
(62) cannot be obtained,
value but in a possible value set Θ˜θi(k)|I i
j (k). Third, if all
information (including the global topology used during the
iterative process) is known, the estimation accuracy of xi(0)
may be increased when the added noises are correlated with
each other, i.e., the relationships of the noises can be used to
j (k)(x+
i (0)). To better illus-
decrease the uncertainty of eθi(0)|I i
j (k)(x+
i (0)), we present a simple
trate the meaning of eθi(0)|I i
example under I i
j(0). As we can see from Fig. 5, supposing the
prior distribution over xi(0) is uniform, eθi(0)(x+
i (0)) locates
the point y which has the largest (cid:15)-shaded area over fθi(0)(z).
i (0)) is different from
Therefore, the estimation eθi(0)|I i
the classic maximum a posteriori estimation (MAP) problem
that ignores the estimation accuracy of |xi − ˆxi|.
Next, deﬁne the set of available sequence I i

j (k)(x+

j(k) that can

ensure (cid:15)-accurate estimation, given by

Si(k) ={I i

j(k) | |eθi(0)|I i

j (k)(x+

i (0)) − θi(0)| ≤ (cid:15)}.

(64)

Then, deﬁne S 1
sequence set Si(k) (i.e., all possible x+
and correspondingly deﬁne

i (k) be the set of all the ﬁrst element in the
i (0) included in Si(k)),

i (k) ={θi(0) | x+
S 0

i (0) ∈ S 1
Clearly, one has S 1
i (k) = xi(0) + S 0
i (k). The following
theorem provides properties of the disclosure probability under
I i
j(k), which is denoted by δ(k).

i (k)}.

(65)

Theorem 8 (see [99]). Considering the noise-adding algo-
rithm (55), the disclosure probability δ at iteration k satisﬁes

(cid:73)

δ(k) ≤

S 0

i (k)

fθi(0)(z)dz.

(66)

Speciﬁcally, if any of the following conditions holds,
1) the added noises are independent of each other;
2) Θ˜θi((cid:96))|I i

j ((cid:96)) ⊇ Θi or Θ˜θi((cid:96))|I i

j ((cid:96)) = R holds for (cid:96) =

1, ..., k and ∀k ≥ 1;

then the equality in (66) holds for ∀k ≥ 0, i.e.,

δ(k) = δ =

(cid:73)

Si(0)

fθi(0)(z)dz.

(67)

Theorem 8 provides the upper bound of disclosure probabil-
ity under I i
j(k), and the conditions to reach the upper bound.
Finally, we demonstrate how to design the added noises to
secure the ((cid:15), δ)-state secrecy. If node j cannot know all the
information used in the iterative process of node i (δ = 1 if
all the information is known to node i), then protecting the
security of xi(0) can be transformed to solve an unconstrained
minimization problem as follows,

min
fθi(0)(y)

(cid:73)

δ =

Si(0)

fθi(0)(y)dy,

(68)

which means that one needs to ﬁnd an appropriate distribution
form for θ. Based on the conclusion in Theorem 8, the value
of δ is determined by set Si(0), where Si(0) is bounded by
(cid:15). Therefore, it is very intuitive for one to design a fθi(0)(y)
with a large variance, such that δ is smaller than any given
small value. For instance, considering Xi = R, one has

Fig. 5. The optimal distributed estimation of eθi(0)(x+
i (0)) and the optimal
estimation of θi(0) with MAP (source: [99]). Note that under uniform prior
distribution over xi(0), the estimate by MAP is the maximum value point of
fθi(0)(z), while the optimal estimate in the sense of ((cid:15), δ)-state secrecy is
the point that has the largest (cid:15)-shaded area over fθi(0)(z).

i (k − 1), x+

i (k) − hi(x+

where ˜θi(k) = x+
j (k − 1) : j ∈
Ni), fθi(1),...,θi(k)(·) is the joint probability density func-
random variables {θi(1), ..., θi(k)}, and
tion (PDF) of
fθi(0)|θi(k)=˜θi(k),...,θi(1)=˜θi(1)(·) is the conditional PDF of
θi(0) when {θi(k) = ˜θi(k), ..., θi(1) = ˜θi(1)}.

Note that (60) is a general expression of the noise esti-
mation, whose detailed form is closely related to the noise
dependence and the connectivity relationships between differ-
ent nodes. Next, we present the explicit expression of optimal
j (k)(x+
j(k) and three scenario conditions,
eθi(0)|I i
respectively, as follows.

i (0)) under I i

Corollary 1. Considering the noise-adding algorithm (55)
and given I i
following results of
j (k)(x+
eθi(0)|I i

j(k), we have

i (0)).

the

1) If noises θi(0), ..., θi(k) are independent of each other,

eθi(0)|I i

j (k)(x+

i (0)) = eθi(0)(x+

i (0)).

(61)

2) If Ni (cid:42) Nj for ∀ j ∈ Ni or the other nodes do not know
all the information used for the updating by node i,

eθi(0)|I i

j (k)(x+

i (0))

= arg

max
i (0)−Xi}

y∈{x+

(cid:90) y+(cid:15)

(cid:73)

(cid:73)

· · ·

y−(cid:15)

Θ ˜θi(1)|Ii

j

(1)

Θ ˜θi(k)|Ii

j

(k)

fθi(1),...,θi(k)(zk, ..., z1)fθi(0)|θi(k)=zk,...,θi(1)=z1(z0)
dzk · · · dz1dz0,
(62)
j (k) is the set of all possible values of ˜θi(0).

where Θ˜θi(k)|I i

3) If Ni ⊆ Nj and Ni is known to node j,

(cid:90) y+(cid:15)

j (k)(x+

y−(cid:15)

y∈{x+

eθi(0)|I i

i (0)) = arg

From corollary 1,

max
i (0)−Xi}
fθi(0)|θi(1)=˜θi(1),...,θi(k)=˜θi(k)(z)dz.
if the added
the ﬁrst point
noises are mutually independent, the growing knowledge of
data at following iterations will not help to estimate xi(0)
better. Second, when Ni (cid:42) Nj for ∀ j ∈ Ni holds, node
the information of from Ni for node
j cannot obtain all
the exact value of ˜θi(k) in
i’s state updating. Therefore,

is that

(63)

Si(0) = [eθi(0) − (cid:15), eθi(0) + (cid:15)]. Then, a uniform distribution
with fθi(0)(y) ≤ 1

L (L is a constant) can ensure that

(cid:73)

δ =

Si(0)

fθi(0)(y)dy ≤

2(cid:15)
L

.

(69)

P3 :

This example means that for any given δ, one can always ﬁnd
a large L that makes (69) hold to achieve ((cid:15), δ)-state-security.
As for the convergence of this kind of noise-adding algorithm,
the readers are referred to [53].

and

P4 :

14

Pr{(cid:107)εx(k +1)(cid:107) ≤ (cid:15)2}, respectively, as the optimization objec-
tives to ﬁnd the optimal fηi(y). The problems are formulated
as the following two problems

min
ˆηi(k)

E[(cid:107)εx(k + 1)(cid:107)2]

max
fηi (z)
s.t. E[ηi] = 0, D[ηi] ≤ σ2
η,

Pr{(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2}

max
ˆηi(k)

min
fηi (z)
s.t. E[ηi] = 0, D[ηi] ≤ σ2
η.

(75)

(76)

Note that E[(cid:107)εx(k +1)(cid:107)2] reﬂects the mean square error of the
attacker’s prediction, while Pr{(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2} describes
the accuracy probability that the prediction error is within a
preset bound.

Remark 5. Formation of P3 and P4 can be interpreted as
follows. The best protection can be achieved in two steps. The
ﬁrst is to decide the best prediction that an attacker could
obtain, and the second step aims to ensure the best prediction
is as unreliable as possible. These two steps can be seen as a
game process between the NDS and the attacker.

1) Optimal Solution of P3: Since εh(k) and εη(k) are
mutually independent with each other, the objective function
E[(cid:107)εx(k + 1)(cid:107)2] in P3 is expanded as

E[(cid:107)εx(k + 1)(cid:107)2] =E

(cid:107)ˆhi(k) + ˆηi(k) − hi(k) − ηi(k)(cid:107)2(cid:105)
(cid:104)
h(k)(cid:3) + E (cid:2)ε2
η(k)(cid:3)
h(k)(cid:3) + D [ˆη(k)]

=E (cid:2)ε2
=E (cid:2)ε2

(77)

Then, we have the following result.

Theorem 9 (see [100]). Considering the noise-adding algo-
rithm (70), fηi(z) is the optimal distribution for P3 iff

D(ηi) = σ2
η.

(78)

The key point of deriving Theorem 9 is to utilize the
independence of εh(k) and εη(k). Although the inﬂuence
of εh(k) is unknown, it does not affect the design of η(k),
which indicates that the larger D[ηi] is, the harder an at-
tacker can make accurate predictions. This property is also
consistent with our intuitions. There are two shortcomings by
adopting E[(cid:107)εx(k + 1)(cid:107)2] as the optimization objective. First,
E[(cid:107)εx(k+1)(cid:107)2] only describes the mean prediction error, while
(cid:107)εx(k+1)(cid:107)2 may deviate a lot from the expectation error when
D(ηi) is large. Second, one can only determine the variance
of the optimal ηi(k), not clear what speciﬁc distribution form
the PDF of ηi(k) is. When solving P4, by contrast, the above
two issues can be addressed under certain conditions.

2) Optimal Solution of P4: When one aims to solve P4,
the major difference from solving P3 is that the estimation
accuracy of ˆhi(k) needs to be considered. Note that
the
objective function in P4 can be expanded as

Pr{(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2} = Pr{(cid:107)εh(k) + εη(k)(cid:107)2 ≤ (cid:15)2}
(cid:90) (cid:90)

=

fz(cid:15) (z1, z2) dz1dz2,

(79)

Ω(cid:15)

C. Making Future States Unpredictable

The historical states of NDSs contain the regularity of the
state trajectory, which can be exploited by external observers
for predicting future states. The future states reﬂect the trend
about how the system will evolve, and need to be secret to
outside. In this subsection, we investigate how to make the
future state of a node unpredictable.

Similar to the last subsection, we continue to consider the
distributed algorithm (55), with a modiﬁcation that an extra
input ηi(k) is introduced to enhance the unpredictability. Then,
the modiﬁed algorithm is given by

xi(k + 1) = hi(x+

i (k), X +

i (k)) + ηi(k),

(70)

where x+
i (k) is calculated by (54). Note that if ηi(k) is a
well-deﬁned and regular function about k, the regularity will
make the future state easy to be predicted by many mature
methods e.g., ARIMA or RNN [83]. Therefore, letting ηi(k)
be associated with randomness will be an effective method to
enhance the unpredictability. Denote by fηi(z) the probability
density function of ηi, which satisﬁes

E[ηi] = 0, D[ηi] ≤ σ2
η.

(71)

Next, we present the prediction model of xi(k +1). Slightly
different from the scenario in the last subsection where node
j wishes to infer the state of node i, here an external attacker
is assumed to have the observations of node i and all its
neighbors N in

till iteration k, which is represented by

i
a(k) = {I out
I i

i

(k), I out

j

(k), j ∈ N in

i }.

(72)

j(k), i.e., I i

a(k). Based on I i

It is easy to see that the available local information I i
a(k) no
a(k), let ˆhi(k)
less than I i
j(k) ⊆ I i
and ˆηi(k) be the (posteriori) estimates of hi(k) and ηi(k),
respectively. In this article, we assume ˆhi(k) and ˆηi(k) are
mutually independent, and their estimation errors are denoted
as εh(k) = ˆhi − hi and εη(k) = ˆηi(k) − ηi(k). Then, the
attacker’s one-step state prediction of node i at iteration k is
given by

ˆxi(k + 1|I i

a(k)) = ˆhi(k) + ˆηi(k),

whose prediction error is given by

εx(k + 1) = εh(k) + εη(k).

(73)

(74)

Apparently, the prediction accuracy is determined by the
estimation error εh(k) and εη(k), and εη(k) is closely related
to the design of ηi. To ﬁnd an appropriate design of ηi
and echo with the proposed ((cid:15), δ)-state secrecy, we introduce
the expectation E[(cid:107)εx(k + 1)(cid:107)] and the probability measure

where fz(cid:15)(z1, z2) is the PDF of the sum (εh(k) + εη(k)), and
Ω(cid:15) = {(εh(k), εη(k))|(cid:107)εh(k) + εη(k)(cid:107)2 ≤ (cid:15)2}. As we can
see, the unpredictability is not only guaranteed by the ηi, but
also closely related to the accuracy of ˆhi(k). Therefore, it is
extremely hard to obtain a general and analytical solution of
P4. Despite this intractability, we are still able to give some
useful results under certain conditions, which is presented in
the following theorem.

Theorem 10 (see [100]). Consider the noise-adding algorithm
(70). For P4, if ˆhi(k) is accurate, i.e., εh(k) = 0, then ∃¯(cid:15) >
0, ∀(cid:15) ≤ ¯(cid:15), the optimal distribution of fηi(z) is the uniform
distribution with ﬁnite maximum variances, i.e.,
√
1
√
3ση
2
0,

otherwise.

z ∈ [−

(z) =

3ση].

3ση,




(80)

f ∗
ηi



√

,

If ˆhi(k) is not accurate but deterministic, then ∃¯(cid:15) > 0, ∀(cid:15) ≤ ¯(cid:15),
fθi(z) is optimal when the distribution of the sum (εh(k) +
εη(k)) is the uniform distribution with variance σ2
η.

Theorem 10 illustrates when the considered error bound
(cid:15) is sufﬁciently small and ˆhi(k) is accurate,
the uniform
distribution with the maximum variance is optimal for fηi(z).

Remark 6. The solutions of P3 and P4 are consistent in the
sense that they both require the variance to be maximum, but
solving P4 can further give the speciﬁc PDF form of ηi(k). In
addition, considering the parameter (cid:15) represents the prediction
error bound of an attacker, if one can still guarantee the
unpredictability under a small (cid:15) (i.e., Pr{(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2}
is also small), then it demonstrates the noise-design of ηi(k)
works well. Therefore, it is meaningful to directly consider the
situation where (cid:15) is sufﬁciently small.

It is worth noting that if εh(k) (cid:54)= 0, the optimal distribution
of fηi(z) relies on the characteristic of ˆhi(k). Speciﬁcally, if
εh(k) is also with randomness, then the solution would be
much more complicated than that of a deterministic εh(k)
(as claimed in Theorem 10). Despite the coupling of εh(k)
and εη(k) , we can further illustrate that the error εh(k) will
not affect the inﬂuence of εη(k) on Pr{(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2}.
i (k) the optimal estimate of ˆhi(k), and let ˆη∗
Denote by ˆh∗
i,1(k)
and ˆη∗
i,2(k) be the optimal noise predictions associated with
ˆh∗
i,1(k) and ˆh∗
i (k)), respectively. Then, we
have the following corollary.

i,1(k) (cid:54)= ˆh∗

i (k) (ˆh∗

Corollary 2. Consider the noise-adding algorithm (70) and
εh(k) (cid:54)= 0. Given arbitrary PDF fηi(z), ∀(cid:15) > 0, one has

(cid:110)

(cid:110)

Pr

≤ Pr

(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2|fηi(z), ˆη∗

(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2|fηi (z), ˆη∗

(cid:111)
i,1(k), ˆhi,1(k)
(cid:111)
i,2(k), ˆh∗

i (k)

.

15

the sense of expected prediction error. By contrast, in the
sense of (cid:15)-accurate probability, the uniform distribution with
maximum variance for fηi(z) is optimal if (cid:15) is small and
ˆhi(k) is accurate. Second, if i) the state of a node is high-
dimensional, ii) the estimates ˆhi(k) and ˆηi(k) are correlated, or
iii) one wishes to achieve the unpredictability of long-horizon
trajectory, ﬁnding an optimal design to tackle these situations
is extremely hard due to the complicated joint PDF. How to
design better noise-adding methods and evaluation metrics for
these situations still remains an open issue.

D. Securing the Topology Structure of NDSs

Considering the risk that an external attacker can infer
the topology of NDSs based on observations, it is necessary
to protect the topology from being accurately inferred while
maintaining the normal convergence of the system dynamics.
In Section IV-B and IV-C, we have demonstrated that the
noise-adding algorithm can be utilized to protect the state
secrecy. In fact, the idea of adding noises to the states during
the iteration is also promising to secure the topology, along
with a more advanced design to guarantee the convergence
performance meanwhile. Therefore, we continue to use the
distributed noise-adding algorithm (70) for the following dis-
cussions.

Since noises θi(k) and ηi(k) in (70) are mutually indepen-
dent, for legibility, we consider the case θi(k) = 0 and focus
on the design of ηi(k). Then, the global form of (70) with
θi(k) = 0 can be explicitly rewritten as

x(k) = Ax(k − 1) + η(k − 1),

(82)

where η = [η1, · · · , ηN ]T, and the attacker has direct collec-
tions of states {x(k)}2. Ideally, when there is no noise input
injected into the system, the state will converge to a constant
vector as k → ∞, i.e.,

lim
k→∞

x(k) = xc,

(83)

where the converging state xc is determined by the setup of A
and the initial state x(0). For example, if A is doubly stochas-
tic, xc = (1Tx(0))/N . Next, we present the fundamental
conditions for η(k) to guarantee the normal convergence of
the system.

Theorem 11 (see [54]). Consider the system (82), the con-
vergence of the system is guaranteed iff

lim
k→∞

k−1
(cid:88)

l=0

W k−l−1η(l) = 0.

(84)

Speciﬁcally,
convergence of (3) is guaranteed if

for cases where A is doubly stochastic,

the

(81)

Intuitively, this corollary illustrates that even if there exists
an estimation error in ˆhi(k), it will not degrade the secrecy
performance brought by ηi(k), i.e., not making the accuracy
probability Pr{(cid:107)εx(k + 1)(cid:107)2 ≤ (cid:15)2} higher.

Based on the above analysis, we present a brief summary
of achieving the unpredictability of the states. First, a dis-
tribution with maximum variance for fηi (z) is optimal in

(cid:107)η(k)(cid:107)∞ ≤ αρk, and

∞
(cid:88)

N
(cid:88)

k=0

i=1

ηi(k) = 0,

(85)

where α > 0 and ρ ∈ [0, 1).

2Here we ignore the observation noise term v(k), as it is also independent
with η(k). By the method introduced in Section III-C, its inﬂuence can be
asymptoticall alleviated.

i }, α, ρ and kmax.

Algorithm 1 : Adjacent noise cancellation algorithm
Input: xi(0), {aij, j ∈ N in
Output: xi(kmax) for each i ∈ V.
1: Initialize x+

i (0) by (54) and send it to N out
j (0), j ∈ N in
i }.
2 , α
2: Initialize ηi(0) = ξi(0) such that ξi(0) ∈ [− α
3: while k ≤ kmax do
2 , αρk
4:

the information X +

i (0) = {x+

i

Select the auxiliary noise ξi(k) from [− αρk
designed rules.
Set ηi(k) = ξi(k) − ξi(k − 1).
Update xi(k) = hi(x+
Update x+
k = k + 1.

i (k − 1), X +
i (k) and send it to N out
.

i

5:
6:
7:
8:
9: end while

i (k − 1)) + ηi(k).

. Meanwhile, receive

2 ], and set k = 1.

2 ] by the user-

Note that (84) is the sufﬁcient and necessary condition
for the exact convergence to xc. The condition (85) in fact
provides a general noise-adding method for a class of systems
where A is doubly stochastic. Following this property, one can
develop an adjacent noise cancellation algorithm to approxi-

mate

∞
(cid:80)
k=0

N
(cid:80)
i=1

ηi(k) = 0, while making the magnitude of ηi(k)

decay to zero over time [39]. In practice, an auxiliary random
term ξ is used, and ηi(k) is commonly designed as

ηi(k) = ξi(k) − ξi(k − 1),

(86)

where (cid:107)ξi(k)(cid:107) ≤ αρk
2 . Note that the above results can be
easily extended to the cases when θi(k) (cid:54)= 0, which should
also satisfy the zero-sum and decaying conditions. The general
procedures are summarized as Algorithm 1, which iteratively
updates the state until the stopping time kmax.

Remark 7. Algorithm 1 ensures the exact convergence when
A is doubly stochastic. This is because the row-stochasticity
can ensure that each input vector will converge to a constant,
and the column-stochasticity can keep the sum of the input
vector unchanged with iterations. Meanwhile, each node does
not need any global system information or the noise informa-
tion of its neighbors.

Note that in Algorithm 1, the magnitude of the added noise
ηk is strictly bounded. From the perspective of the PDF of
ηk, this condition can be relaxed to various PDF forms while
ensuring the variance of ηk exponentially decaying with k
[38]. Under this formulation, the mean square convergence
of the state is still guaranteed. Besides,
there is another
meaningful result that connects the structure and state secrecy.
If one uses the popular differential privacy to measure the
secrecy performance of the state, there exists a contradiction
as summarized in the following corollary.

Corollary 3 (see [97]). Consider
If
the added noises satisfy the exact convergence condition
l=0 W k−l−1θ(l) = 0, then the noise-adding al-
limk→∞
gorithm cannot guarantee the the differential privacy of the
initial state.

the system (82).

(cid:80)k−1

Next, we illustrate how to add the noises to protect the
topology matrix A from being inferred accurately. Considering

that the attacker uses the aforementioned OLS estimator (36)
to infer the topology, the inference error matrix is given by

16

εA = ˆAo − A = ΦT (Y −

T )T(Y −

T (Y −

T )T)−1,

(87)

where the added noise matrix ΦT = [η(0), η(1), · · · , η(T −
1)]. Then, ﬁnding the optimal noise can be formulated as the
following maximization problem

max
ΦT
s.t.

(cid:107)εA(cid:107)2
F

lim
k→∞

x(k) = xc.

(88a)

(88b)

It is remarkable that the added η(k) will continue to inﬂuence
the following states after iteration k, and the objective function
is highly nonlinear about ΦT . Therefore, directly solving (88)
in one-step is intractable. However, we can still approximate
the optimal design in an iterative way, which is turned to solve
the following problem at each iteration

(cid:13)
(cid:13)[Φk−1, ηk] (Y −

P5 : max
η(k)
s.t. (cid:107)η(k)(cid:107)∞ ≤ αρk.

k )T(Y −

k (Y −

k )T)−1(cid:13)
2
(cid:13)

F

(89a)

(89b)

Note that in the objective function of P5, Φk−1 and Y −
k are
deterministic and given at iteration k. Then, we have the
following result.

(see
the noise

Theorem 12
(82),
if
i (k)|, |β+
max{|β−
P5, η∗(k), satisﬁes

[101]). Considering
ηi(k)

system
[β−
i (k)] where
i (k)|} ≤ αρk, then the optimal solution of

i (k), β+

the

∈

i (k) ∈ {β−
η∗

i (k), β+

i (k)}, ∀i = 1, · · · , N.

(90)

Theorem 12 shows that the added noise η(k) is optimal
when each node locally selects the boundary magnitude of its
available noise space. Note that by using Algorithm 1 with the
noise design (90), the exact convergence cannot be guaranteed
if A is not doubly stochastic. Under this situation, there will
be a deviation between the real state x(∞) and the converging
state xc, and the bound of the deviation is determined by the
parameter α and ρ. How to achieve the exact convergence
for non-doubly stochastic A while securing the topology still
needs further investigation.

V. DISCUSSION AND OPEN ISSUES

A. The Secrecy of Control Laws

Note that the control law is the utmost critical element of the
control mechanism to inﬂuence the dynamical process, which
acts as the system input. An attacker who has inferred the
the control law can easily infer the state and structure by
appropriate input modeling. The control input of NDSs can
be divided into two types: system-depend input (rely on the
state and structure) and independent input. For the former one,
if the controller has an explicit form, then the whole system
can be represented in a closed-loop form, where the input u
is replaced by the expression of x (or y) and A, e.g., the
classic state-feedback controller. In this context, it is possible
to infer the control laws by utilizing the state and structure
information, and the state-of-art data-driven methods [102] are

beneﬁcial to the investigation of this direction. For instance,
consider the Linear Quadratic Regulator (LQR) problem [103].
The optimal control law that solves

min
u,y

lim
T →∞

E

1
T

(cid:34) T

(cid:88)

k=0

(cid:0)x(k)(cid:62)Qx(k) + u(k)(cid:62)Ru(k)(cid:1)

(cid:35)

(91)

s.t. x(k + 1) = Ax(k) + Bu(k) + w(k)

is given by

u(k) = −(B(cid:62)P B + R)−1B(cid:62)P Ax(k) (cid:44) −K ∗x(k),

(92)

where P is the solution of the discrete algebraic Riccati
equation that relies on A, B, Q, R [103]. Hence, the inference
of (92) is translated to the estimation of the optimal feedback
matrix K ∗ based on the observations of the state-input pairs
{x(k), u(k)}. Then, various linear regression methods [104]
can be applied. As for the independent input, if the input is
time-invariant, we can identify the inﬂuence of the input by
using the data when the system is stable [105]. However, if the
independent input is time-varying, a more sophisticated input-
identiﬁcation procedure is required, and the latest input-output
linearization [106] technique may provide some feasible so-
lutions, which still needs further investigation. Besides, if the
external attacker has only local access to the global system,
decentralized versions of the inference methods are required
to obtain the local knowledge [107].

Another interesting scenario is that one can use self-
designed control laws to excite the system, such that more
abundant behaviors are produced to infer the system parame-
ters. The latest work [108] has made progress in improving the
inference accuracy of system models by input design, which
utilizes the subspace method in system identiﬁcation. It is
promising that we can further the designed excitation input to
differentiate the inﬂuence of the control laws of the system
itself. In addition, from the defense perspective, it is also
of necessity to protect the control laws from being inferred,
e.g., controller gains. Several latest works [109]–[112] have
achieved some progress in this direction, by considering a
speciﬁc class of NDSs. As for securing the optimal control
law (92) for problem (91), we can similarly exploit the noise-
adding mechanism by perturbing states, inputs, or both of
them with uncorrelated Laplace noises or correlated adjacent-
canceling noises. The performance can be characterized via
differential privacy [95] or ((cid:15), δ)-secrecy. However, it remains
challenging to conceal the general model type and design
secure controllers that could induce a much worse inference
result for the attacker.

B. Performance Metrics for Control Mechanism Secrecy

Establishing appropriate metrics to evaluate the risks is criti-
cal for the control mechanism secrecy. In previous sections, we
have used two kinds of metrics: regression error like (23) and
disclosure probability like (58). They both reﬂect the differ-
ence between the estimated value and the ground truth, but also
differ from each other. The regression error directly describes
the inference error of a realization of the inference attack,
which is only suitable for cases where the noise-adding method

17

is deterministic. On the contrary, the disclosure probability
characterizes the risk of information leakage by probability
measurement, which applies to situations where the noise-
adding method is with randomness. If the explicit distribution
characteristic of the added noises is hard to describe, one can
adopt the expected square error as an alternative, which is
given by

Er(ˆx) = E[(ˆx − x)T(ˆx − x)].

(93)

Note that Er(ˆx) gives the estimation error in the expectation
sense, which is suitable for both deterministic and random
cases of the system states.

In terms of the unpredictability of the state, current research
mainly focus on the inference performance of one-step predic-
tion [99], [100], which is not enough for secrecy in the long
horizon. Suppose the attacker aims to predict K-step future
state of the NDS, then the probability that the prediction error
of each step is within (cid:15) can be represented as

P(cid:15)(x[1:K]) =

K
(cid:89)

k=1

Pr{(cid:107)ˆx(k|k − 1) − x(k)(cid:107)∞ ≤ (cid:15)},

(94)

where ˆx(k|k − 1) is the prediction of x(k) at step k − 1.
Apparently, ensuring the state secrecy on the long horizon
is much more challenging. On the one hand, the inferred
target is no longer a single point but a trajectory composed of
multiple points. Consequently, the uncertainty is described by
multivariate probability density functions in high-dimension
space, making the corresponding calculation extremely hard,
let alone the possible couplings between different variables.
On the other hand, even if the uncertainty is calculable, the
result highly relies on a given system model along with its
observations. A reliable metric for state unpredictability is
desired to be independent of speciﬁc models and observations,
and is able to characterize convergence trend of P(cid:15)(x[1:K])
as K increases. How to design appropriate and analytical
transformations to ﬁll the above gap is worth further study.
To address these challenges, an interdisciplinary approach
combining model predictive control, information theory and
large deviation theory may be promising.

Last but not least, the evaluation metrics for states also
provide the foundation to characterize the metrics for the
secrecy of the structure and the control laws. Different from
the state secrecy, the other two metrics will be closely related
to the dynamical performance of NDSs (e.g., convergence and
steady points [113]). We discuss the details of these issues in
the next subsection.

C. Tradeoff Between Secrecy and Cooperation Performance

Although the noise-adding methods help to achieve the
state secrecy, they may compromise the normal dynamical
performance of NDSs. It is often required that the system
state at certain moment should meet the preset value, apart
from the secrecy requirement of state evolution. For example,
suppose the desired state at the terminal moment T is x∗
T and

we can formulate the control objective as the following linear
quadratic function

Jc(˜u0:T ) =E[(xT − x∗
(cid:34)T −1
(cid:88)

+ E

T )TH(xT − x∗

T )]

(cid:0)x(k)(cid:62)Qx(k) + ˜u(k)(cid:62)R˜u(k)(cid:1)

(cid:35)

, (95)

k=0

where ˜u(k) = u(k) + η(k) is the system input after adding
noise η(k), H is a positive semi-deﬁnite matrix, Q and R
are the same as that in (91). It is clearly from (95) that
achieving the optimal trade-off between the desired terminal
state and secrecy of the state evolution requires the random
noises {η(k)} to be well designed. What kind of distribution
of η(k) should be determined and how to design the input
u(k) coupling with η(k) are the main challenging issues for
future research.

Note that in practice, the structure of the system is also
of great
importance for system convergence and stability.
Therefore, simultaneously considering the structure disclosure
risks is essential to investigate the tradeoff between secrecy
and cooperation performance. First, the metrics considering
the state aspects are not always appropriate to describe the
inference capability. For example, in some cases, the structure
matrix is not easy to obtain by using an explicit model, and
one may be more interested in the eigenvalue spectrum of the
matrix [69], [71]. Also, the original model information of the
control laws may not be priorly known, and one needs to de-
sign other evaluation models to deal with the uncertainty. The
established metrics are supposed to be capable of describing
the error inﬂuence in the system dynamics. Therefore, there
remain many challenges in designing appropriate metrics to
fully characterize the tradeoff between mechanism secrecy and
cooperation performance.

Second, due to the fundamental convergence requirement,
the feasible space to design countermeasures is limited. Specif-
ically, as we mentioned in Section IV-D, when the structure
matrix is not doubly stochastic, there remains a challenge to
tackle with the exact convergence of the system state. The
key point lies in eliminating the asymptotical state deviation
information [101]. Furthermore,
without relying on global
if the nodes are also associated with state-independent self-
input, the coupling between the self-input and the added noise
needs to be considered for the optimal noise design. Last
but not the least, different from the state where one only
needs to focus on the value itself, the system structure is
composite system knowledge. Taking the topology matrix A
in A
as an example, although the value of each element
is sensitive and important, the eigenvalue spectrum and the
eigenvectors are also critical and valuable information, which
reﬂects the convergence performance of the system dynamics.
Therefore, simply using the error norm as in (88) is not
sufﬁcient for the structure secrecy.

18

data [114]–[116]. These methods remove the design depen-
dency on the model knowledge (e.g., speciﬁc model forms),
where state-of-the-art reinforcement learning and model-free
optimization techniques are used as main tools [117]–[120].
We point out that, when there exist interactions between the
NDSs and the environment,
the online
it
learning strategy for the system itself can also be leveraged by
external attackers to infer the control mechanism. For example,
we can formulate this process as the following model

is possible that

x(k + 1) = f (x(k), u(k), ue(k)),
y(k) = g(x(k), u(k), ue(k)),

(96)

where ue is the input describing the interaction between the
attacker and the NDS. Here, only the observations {y(k)}
and the interaction input {ue(k)} are available to the attacker,
and the mature tools in linear system cases can no longer be
utilized. A promising insight of inferring the mechanism is to
design appropriate inference objective function Φ(y, ue) for
the attacker, construct gradient estimates of Φ(y, ue) to obtain
a sequence of the interaction input {ue(k)}, thus optimizing
the inference objective function Φ(y, ue) iteratively. Note that
optimizing Φ(y, ue) is essentially optimizing the inference
error about the control dynamics. Therefore, the main direction
of this problem research is to properly deﬁne the inference
objective Φ(y, ue) at the beginning and design the interaction
strategy ue during the process.

VI. NUMERICAL EVALUATION

In this section, we present some numerical tests to verify
the theoretical results and evaluate the performance of some
approaches considered in this article.

A. Scenario Setting

For simplicity, we consider a full measurable NDS with 5
nodes, which subject to the following consensus-based model

xk+1 = Ax(k),

where

A =








0.9111
0.0444
0
0
0.0444

0.0444
0.8000
0.0667
0.0222
0.0667

0
0.0667
0.9111
0.0222
0

0
0.0222
0.0222
0.9111
0.0444








0.0444
0.0667
0
0.0444
0.8444

,

is a doubly stochastic matrix, and the initial state is x(0) =
[−26, −3, 13, 28, 17]T/2. One can easily obtain that A ∈ Sa,
and the converging state of this system xc = 2.9. For com-
parison of different noise-adding methods, we will selectively
use Gaussian, uniform, and Laplace noises to secure the
mechanism secrecy.

B. Veriﬁcation

D. Cases of Unknown Models: Incorporating with Reinforce-
ment Learning and Model-free Optimization

In recent years, plenty of works have displayed increasing
interests in designing optimal, stable and safe controllers from

Let us begin by examining the state secrecy. It is straight-
forward that the initial state x(0) can be estimated accurately
if there are no other noises involved in the system. Therefore,
we illustrate the performance of the state estimation under
different levels of noise variance σ2
v. Fig. 6 compares the

19

Fig. 6. The estimation error of x(0). The measurement noises are Gaussian
with zero mean and variances equaling to 0.12, 0.52 and 1, respectively.

Fig. 8. The topology inference performance the OLS and the causality-based
estimators. Note that the process and measurement noises both satisfy zero
mean and unit variance.

process and measurement noises satisfying Assumption 1 with
unit variances. As shown in Fig. 8, the inference errors of both
ˆAo and ˆAc decrease as the observation number grow, which
illustrates the risk that the structure of a NDS is easy to be
revealed with tolerable error. Speciﬁcally, the inference error
of ˆAc converges to zero while that of ˆAo converges to constant.
This property echoes with the conclusions in Theorem 5, and
can be observed from the upper bounds of the errors drawn
in Fig. 8.

Finally, we turn to validate the secrecy performance of
the adjacent noise cancellation methods. Fig. 9 the state
evaluation and topology inference error when using Gaus-
sian, uniform, and the optimal noises in P5, respectively.
The simulations here are conducted by letting the noises
satisfy the exponentially decaying condition and the zero-

∞
(cid:80)
k=0

N
(cid:80)
i=1

sum condition

ηi(k) = 0. Note that according to

famous 3σ-rule [121], for Gaussian distribution with zero
the variable locates in [−3σ, +3σ] with probability
mean,
0.997, and this interval is basically regarded as the actual
possible range. To have a fair comparison, we let the bound of
the uniform and designed noises of P5 be 3σηρk at iteration
k, where the decaying parameter ρ is set as 0.95. Clearly,
one can observe from Fig. 9(a) and Fig. 9(b) that, both the
convergence and accuracy of the system state are guaranteed
under the adjacent noise cancellation methods. Remarkably,
even if the convergence speed of the three kinds of noises are
likewise, the topology inference errors differ a lot, as shown
in Fig. 9(c). Speciﬁcally, the inference error brought by the
designed noise is much higher than that of the other two, which
exhibits better topology-securing performance and veriﬁes the
optimality conclusions in Theorem 12.

VII. CONCLUDING REMARKS

This article explored the disclosure risks of the fundamen-
tal information in NDSs along with their countermeasures.
The control mechanism of a NDS consists of conﬁdential
information including state, structure, and control laws. The

Fig. 7. The ((cid:15), δ)-state secrecy performance, where the added noises are
drawn from Gaussian, uniform and Laplace distributions, respectively. The
process and measurement noises both satisfy zero mean and unit variance.

inference accuracy of the state estimator (21). Clearly, the
smaller the noise variance σ2
v is, the smaller the estimation
error is. Meanwhile, the inference error will decrease with
the observation number and become stable. Fig. 7 further
shows the ((cid:15), δ)-state secrecy performance of a single node.
Note that in this test, 3000 simulation runs are conducted,
where the Gaussian, uniform, and Laplace distributed noises
are used with both zero mean and unit variance. In each
run, one node ﬁrst randomly generates a noise θi(0) with
the given distribution, while the other node obtains ˆθi(0) by
some estimation methods. Then, one can have the probability
that |ˆθi(0) − θi(0)| ≤ (cid:15) holds. Clearly, one can conclude
that uniform distribution is better than Gaussian and Laplace
distribution in the sense of ((cid:15), δ)-state secrecy.

Next, we focus on the structure secrecy performance. Sim-
ilar to the state estimation, if there is no noise involved in the
dynamic process, the attacker can accurately infer the topology
matrix A with more than T ≥ (N +1) groups of observations.
Therefore, here we validate the inference performance of the
estimator ˆAo in (36) and ˆAc in (39), by considering both

20

(a) Convergence of system states.

(b) Accuracy of the converging state.

(c) Inference error of the topology.

Fig. 9. The system evaluation and the topology inference performance under the adjacent noise cancellation methods with three different noise distributions.
The inset plots in (a) and (b) shows the detailed evaluation process before iteration 20.

control mechanism secrecy, in our opinion, plays a critical
role in the applications of NDSs, especially in those security-
related scenarios. We introduced the inference analysis from an
attacker’s view, and the protection methods from a defender’s
view. Based on the analysis, we demonstrated the inference
performance of common inference methods concerning how
to estimate the state and structure, and presented the results
about the principles and possible methods to evaluate and
secure them, such as the ((cid:15), δ)-state secrecy metric and the
adjacent noise cancellation algorithm. This collection of the
latest results can be regarded as a launching pad for deeper
investigation into more sound security methods. Furthermore,
we provided in-depth discussions on the secrecy of control
laws, and summarized potential ideas to infer and protect the
control laws, respectively.

However, we also pointed out that even the state-of-the-art
approaches in the literature cannot fully address the issues
of optimal protection designs in the context of mechanism
secrecy. Considering the situations where i) the system model
is nonlinear or high-dimensional, ii) the prior knowledge about
NDSs is not sufﬁcient, or iii) the tradeoff between nominal
system performance and the control mechanism secrecy, es-
tablishing better evaluation metrics about control mechanism
and combining the excitation-based design are promising
directions beckoning further research.

ACKNOWLEDGEMENT
The authors would like to thank Zhiyu He, Jialun Li,
Xiangyu Mao and Tao Xu for their valuable comments and
suggestions for this paper.

REFERENCES

[1] R. Olfati-Saber, J. A. Fax, and R. M. Murray, “Consensus and coop-
eration in networked multi-agent systems,” Proceedings of the IEEE,
vol. 95, no. 1, pp. 215–233, 2007.

[2] K.-K. Oh, M.-C. Park, and H.-S. Ahn, “A survey of multi-agent

formation control,” Automatica, vol. 53, pp. 424–440, 2015.

[3] H. Choi, W.-C. Lee, Y. Aafer, F. Fei, Z. Tu, X. Zhang, D. Xu, and
X. Xinyan, “Detecting attacks against robotic vehicles: A control invari-
ant approach,” in Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2018, pp. 801–816.
[4] J.-P. Hubaux, S. Capkun, and J. Luo, “The security and privacy of
smart vehicles,” IEEE Security & Privacy, vol. 2, no. 3, pp. 49–55,
2004.

[5] Y. Ni, L. Cai, J. He, A. Vinel, Y. Li, H. Mosavat-Jahromi, and J. Pan,
“Toward reliable and scalable internet of vehicles: Performance analysis
and resource management,” Proceedings of the IEEE, vol. 108, no. 2,
pp. 324–340, 2019.

[6] A. A. Cardenas, S. Amin, and S. Sastry, “Secure control: Towards
survivable cyber-physical systems,” in The 28th International Confer-
ence on Distributed Computing Systems Workshops.
IEEE, 2008, pp.
495–500.

[7] H. C. Van Tilborg and S. Jajodia, Encyclopedia of cryptography and

security. Springer Science & Business Media, 2014.

[8] C. E. Shannon, “Communication theory of secrecy systems,” The Bell

System Technical Journal, vol. 28, no. 4, pp. 656–715, 1949.

[9] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux,
“Quantifying location privacy,” in 2011 IEEE Symposium on Security
and Privacy.

IEEE, 2011, pp. 247–262.

[10] J. Li, F. Yang, M. Tomizuka, and C. Choi, “Evolvegraph: Multi-agent
trajectory prediction with dynamic relational reasoning,” Advances in
Neural Information Processing Systems, vol. 33, pp. 19 783–19 794,
2020.

[11] B. L. M. V´asquez and J. Carlo Barca, “Network topology inference in
swarm robotics,” in IEEE International Conference on Robotics and
Automation (ICRA).

IEEE, 2018, pp. 7660–7666.

[12] Y. Li, J. He, and L. Cai, “Topology inference on partially observable
mobile robotic networks under formation control,” in 2021 European
Control Conference (ECC), 2021, pp. 497–502.

[13] D. Zhang and J. P. Sterbenz, “Analysis of critical node attacks in mobile
ad hoc networks,” in 2014 6th International Workshop on Reliable
Networks Design and Modeling, 2014, pp. 171–178.

[14] M. P. Deisenroth, D. Fox, and C. E. Rasmussen, “Gaussian processes
for data-efﬁcient learning in robotics and control,” IEEE Transactions
on Pattern Analysis and Machine Intelligence, vol. 37, no. 2, pp. 408–
423, 2015.

[15] E. Tolstaya, F. Gama, J. Paulos, G. Pappas, V. Kumar, and A. Ribeiro,
“Learning decentralized controllers for robot swarms with graph neural
networks,” in Conference on Robot Learning. PMLR, 2020, pp. 671–
682.

[16] R. Quinonez, J. Giraldo, L. Salazar, E. Bauman, A. Cardenas, and
Z. Lin, “SAVIOR: Securing autonomous vehicles with robust physical
invariants,” in 29th USENIX Security Symposium (USENIX Security
20), 2020, pp. 895–912.

[17] Y. Li, J. He, C. Chen, and X. Guan, “Learning-based intelligent attack
against formation control with obstacle-avoidance,” in 2019 American
Control Conference (ACC).

IEEE, 2019, pp. 2690–2695.

[18] R. A. Licitra, Z. I. Bell, and W. E. Dixon, “Single-agent indirect herding
of multiple targets with uncertain dynamics,” IEEE Transactions on
Robotics, vol. 35, no. 4, pp. 847–860, 2019.

[19] J. Giraldo, E. Sarkar, A. A. Cardenas, M. Maniatakos, and M. Kantar-
cioglu, “Security and privacy in cyber-physical systems: A survey of
surveys,” IEEE Design and Test, vol. 34, no. 4, pp. 7–17, 2017.
[20] H. Sandberg, V. Gupta, and K. H. Johansson, “Secure networked
control systems,” Annual Review of Control, Robotics, and Autonomous
Systems, vol. 5, no. 1, pp. 072 921–075 953, 2022.

[21] A. Teixeira, I. Shames, H. Sandberg, and K. H. Johansson, “A se-

cure control framework for resource-limited adversaries,” Automatica,
vol. 51, pp. 135–148, 2015.

[22] H. Zhang, P. Cheng, L. Shi, and J. Chen, “Optimal DoS attack
scheduling in wireless networked control system,” IEEE Transactions
on Control Systems Technology, vol. 24, no. 3, pp. 843–852, 2015.

[23] M. Conti, N. Dragoni, and V. Lesyk, “A survey of man in the middle
attacks,” IEEE Communications Surveys and Tutorials, vol. 18, no. 3,
pp. 2027–2051, 2016.

[24] R. Anguluri, V. Katewa, and F. Pasqualetti, “A probabilistic approach to
design switching attacks against interconnected systems,” in American
Control Conference.

IEEE, 2019, pp. 4430–4435.

[25] H. S. S´anchez, D. Rotondo, T. Escobet, V. Puig, and J. Quevedo,
“Bibliographical review on cyber attacks from a control oriented
perspective,” Annual Reviews in Control, vol. 48, pp. 103–128, 2019.
[26] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Attack detection and identi-
ﬁcation in cyber-physical systems,” IEEE Transactions on Automatic
Control, vol. 58, no. 11, pp. 2715–2729, 2013.

[27] C.-Z. Bai, F. Pasqualetti, and V. Gupta, “Data-injection attacks in
stochastic control systems: Detectability and performance tradeoffs,”
Automatica, vol. 82, pp. 251–260, 2017.

[28] Y. Guan and X. Ge, “Distributed attack detection and secure estimation
of networked cyber-physical systems against false data injection attacks
and jamming attacks,” IEEE Transactions on Signal and Information
Processing over Networks, vol. 4, no. 1, pp. 48–59, 2017.

[29] J. Giraldo, D. Urbina, A. Cardenas, J. Valente, M. Faisal, J. Ruths, N. O.
Tippenhauer, H. Sandberg, and R. Candell, “A survey of physics-based
attack detection in cyber-physical systems,” ACM Computing Surveys,
vol. 51, no. 4, pp. 1–36, 2018.

[30] R. Anguluri, V. Katewa, and F. Pasqualetti, “Centralized versus de-
centralized detection of attacks in stochastic interconnected systems,”
IEEE Transactions on Automatic Control, vol. 65, no. 9, pp. 3903–
3910, 2020.

[31] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and control
for cyber-physical systems under adversarial attacks,” IEEE Transac-
tions on Automatic Control, vol. 59, no. 6, pp. 1454–1467, 2014.
[32] Y. Mo, S. Weerakkody, and B. Sinopoli, “Physical authentication
of control systems: Designing watermarked control inputs to detect
counterfeit sensor outputs,” IEEE Control Systems Magazine, vol. 35,
no. 1, pp. 93–109, 2015.

[33] M. Pajic, I. Lee, and G. J. Pappas, “Attack-resilient state estimation for
noisy dynamical systems,” IEEE Transactions on Control of Network
Systems, vol. 4, no. 1, pp. 82–92, 2016.

[34] A. Barboni and T. Parisini, “Towards distributed accommodation of
covert attacks in interconnected systems,” in 2020 59th IEEE Confer-
ence on Decision and Control.

IEEE, 2020, pp. 5731–5736.

[35] D. Ding, Q.-L. Han, X. Ge, and J. Wang, “Secure state estimation and
control of cyber-physical systems: A survey,” IEEE Transactions on
Systems, Man, and Cybernetics: Systems, vol. 51, no. 1, pp. 176–190,
2020.

[36] A. Teixeira, I. Shames, H. Sandberg, and K. H. Johansson, “A se-
cure control framework for resource-limited adversaries,” Automatica,
vol. 51, pp. 135–148, 2015.

[37] S. Han and G. J. Pappas, “Privacy in control and dynamical systems,”
Annual Review of Control, Robotics, and Autonomous Systems, vol. 1,
pp. 309–332, 2018.

[38] Y. Mo and R. M. Murray, “Privacy preserving average consensus,”
IEEE Transactions on Automatic Control, vol. 62, no. 2, pp. 753–765,
2016.

[39] J. He, L. Cai, C. Zhao, P. Cheng, and X. Guan, “Privacy-preserving
average consensus: Privacy analysis and algorithm design,” IEEE
Transactions on Signal and Information Processing over Networks,
vol. 5, no. 1, pp. 127–138, 2018.

[40] Y. Wang, “Privacy-preserving average consensus via state decomposi-
tion,” IEEE Transactions on Automatic Control, vol. 64, no. 11, pp.
4711–4716, 2019.

[41] M. Ruan, H. Gao, and Y. Wang, “Secure and privacy-preserving
consensus,” IEEE Transactions on Automatic Control, vol. 64, no. 10,
pp. 4035–4049, 2019.

[42] S. M. Dibaji, M. Pirani, D. B. Flamholz, A. M. Annaswamy, K. H.
Johansson, and A. Chakrabortty, “A systems and control perspective of
CPS security,” Annual Reviews in Control, vol. 47, pp. 394–411, 2019.
[43] C. Fang, Y. Qi, J. Chen, R. Tan, and W. X. Zheng, “Stealthy actuator
signal attacks in stochastic control systems: Performance and limita-
tions,” IEEE Transactions on Automatic Control, vol. 65, no. 9, pp.
3927–3934, 2020.

21

[44] T. Sui, Y. Mo, D. Marelli, X. Sun, and M. Fu, “The vulnerability of
cyber-physical system under stealthy attacks,” IEEE Transactions on
Automatic Control, vol. 66, no. 2, pp. 637–650, 2021.

[45] C. Zhou, B. Hu, Y. Shi, Y.-C. Tian, X. Li, and Y. Zhao, “A uniﬁed
architectural approach for cyberattack-resilient industrial control sys-
tems,” Proceedings of the IEEE, vol. 109, no. 4, pp. 517–541, 2021.
[46] M. S. Chong, M. Wakaiki, and J. P. Hespanha, “Observability of
linear systems under adversarial attacks,” in 2015 American Control
Conference (ACC).
IEEE, 2015, pp. 2439–2444.

[47] Y. Guan and X. Ge, “Distributed attack detection and secure estimation
of networked cyber-physical systems against false data injection attacks
and jamming attacks,” IEEE Transactions on Signal and Information
Processing over Networks, vol. 4, no. 1, pp. 48–59, 2018.

[48] Y. Mao, A. Mitra, S. Sundaram, and P. Tabuada, “On the computational
complexity of the secure state-reconstruction problem,” Automatica,
vol. 136, p. 110083, 2022.

[49] X. Ren, Y. Mo, J. Chen, and K. H. Johansson, “Secure state estimation
with Byzantine sensors: A probabilistic approach,” IEEE Transactions
on Automatic Control, vol. 65, no. 9, pp. 3742–3757, 2020.

[50] S. Weerakkody, X. Liu, S. H. Son, and B. Sinopoli, “A graph-theoretic
characterization of perfect attackability for secure design of distributed
control systems,” IEEE Transactions on Control of Network Systems,
vol. 4, no. 1, pp. 60–70, 2017.

[51] Y. Lu and M. Zhu, “On privacy preserving data release of linear

dynamic networks,” Automatica, vol. 115, p. 108839, 2020.

[52] V. Katewa, R. Anguluri, and F. Pasqualetti, “On a security vs privacy
trade-off in interconnected dynamical systems,” Automatica, vol. 125,
p. 109426, 2021.

[53] Y. Mo and R. M. Murray, “Privacy preserving average consensus,”
IEEE Transactions on Automatic Control, vol. 62, no. 2, pp. 753–765,
2017.

[54] J. He, L. Cai, P. Cheng, J. Pan, and L. Shi, “Consensus-based data-
privacy preserving data aggregation,” IEEE Transactions on Automatic
Control, vol. 64, no. 12, pp. 5222–5229, 2019.

[55] M. Yemini, A. Nedic, A. J. Goldsmith, and S. Gil, “Characterizing
trust and resilience in distributed consensus for cyberphysical systems,”
IEEE Transactions on Robotics, pp. 1–21, 2021.

[56] Y. Cao and W. Ren, “Sampled-data discrete-time coordination algo-
rithms for double-integrator dynamics under dynamic directed interac-
tion,” International Journal of Control, vol. 83, no. 3, pp. 506–515,
2010.

[57] M. J. Wainwright, High-dimensional statistics: A non-asymptotic view-

point. Cambridge University Press, 2019, vol. 48.

[58] E. J. Candes, J. K. Romberg, and T. Tao, “Stable signal recovery from
incomplete and inaccurate measurements,” Communications on Pure
and Applied Mathematics: A Journal Issued by the Courant Institute
of Mathematical Sciences, vol. 59, no. 8, pp. 1207–1223, 2006.
[59] D. Hayden, Y. H. Chang, J. Goncalves, and C. J. Tomlin, “Sparse
network identiﬁability via compressed sensing,” Automatica, vol. 68,
pp. 9–17, 2016.

[60] R. Dobbe, S. Liu, Y. Yuan, and C. Tomlin, “Blind identiﬁcation of fully
observed linear time-varying systems via sparse recovery,” Automatica,
vol. 100, pp. 330–335, 2019.

[61] N. Rezazadeh and S. S. Kia, “Privacy preservation in a continuous-
time static average consensus algorithm over directed graphs,” in 2018
American Control Conference, 2018, pp. 5890–5895.

[62] C. Altaﬁni, “A system-theoretic framework for privacy preservation
in continuous-time multiagent dynamics,” Automatica, vol. 122, p.
109253, 2020.

[63] C. Liu, J. He, S. Zhu, and C. Chen, “Dynamic topology inference via
external observation for multi-robot formation control,” in 2019 IEEE
Paciﬁc Rim Conference on Communications, Computers and Signal
Processing (PACRIM).
IEEE, 2019, pp. 1–6.

[64] A. Ahmed and E. P. Xing, “Recovering time-varying networks of
dependencies in social and biological studies,” Proceedings of the
National Academy of Sciences, vol. 106, no. 29, pp. 11 878–11 883,
2009.

[65] R. P. Monti, P. Hellyer, D. Sharp, R. Leech, C. Anagnostopoulos,
and G. Montana, “Estimating time-varying brain connectivity networks
from functional MRI time series,” NeuroImage, vol. 103, pp. 427–443,
2014.

[66] C. W. Granger, “Investigating causal relations by econometric models
and cross-spectral methods,” Econometrica: Journal of the Econometric
Society, pp. 424–438, 1969.

[67] A. Brovelli, M. Ding, A. Ledberg, Y. Chen, R. Nakamura, and
S. L. Bressler, “Beta oscillations in a large-scale sensorimotor cor-
tical network: Directional inﬂuences revealed by granger causality,”

Proceedings of the National Academy of Sciences, vol. 101, no. 26,
pp. 9849–9854, 2004.

[68] A. Santos, V. Matta, and A. H. Sayed, “Local tomography of large
networks under the low-observability regime,” IEEE Transactions on
Information Theory, vol. 66, no. 1, pp. 587–613, 2020.

[69] S. Segarra, A. G. Marques, G. Mateos, and A. Ribeiro, “Network
topology inference from spectral templates,” IEEE Transactions on
Signal and Information Processing over Networks, vol. 3, no. 3, pp.
467–483, 2017.

[70] M. T. Schaub, S. Segarra, and H.-T. Wai, “Spectral partitioning of time-
varying networks with unobserved edges,” in 2019 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP).
IEEE, 2019, pp. 4938–4942.

[71] Y. Zhu, M. T. Schaub, A. Jadbabaie, and S. Segarra, “Network
inference from consensus dynamics with unknown parameters,” IEEE
Transactions on Signal and Information Processing over Networks,
vol. 6, pp. 300–315, 2020.

[72] G. Karanikolas, G. B. Giannakis, K. Slavakis, and R. M. Leahy,
“Multi-kernel based nonlinear models for connectivity identiﬁcation of
brain networks,” in 2016 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP).
IEEE, 2016, pp. 6315–6319.
[73] G. V. Karanikolas, O. Sporns, and G. B. Giannakis, “Multi-kernel
change detection for dynamic functional connectivity graphs,” in 2017
51st Asilomar Conference on Signals, Systems, and Computers.
IEEE,
2017, pp. 1555–1559.

[74] S. Wang, E. D. Herzog, I. Z. Kiss, W. J. Schwartz, G. Bloch,
M. Sebek, D. Granados-Fuentes, L. Wang, and J.-S. Li, “Inferring
dynamic topology for decoding spatiotemporal structures in complex
heterogeneous networks,” Proceedings of the National Academy of
Sciences, vol. 115, no. 37, pp. 9300–9305, 2018.

[75] N. Shahid, N. Perraudin, V. Kalofolias, G. Puy, and P. Vandergheynst,
“Fast robust PCA on graphs,” IEEE Journal of Selected Topics in Signal
Processing, vol. 10, no. 4, pp. 740–756, 2016.

[76] M. Onuki, S. Ono, M. Yamagishi, and Y. Tanaka, “Graph signal denois-
ing via trilateral ﬁlter on graph spectral domain,” IEEE Transactions
on Signal and Information Processing over Networks, vol. 2, no. 2, pp.
137–148, 2016.

[77] G. B. Giannakis, Y. Shen, and G. V. Karanikolas, “Topology identi-
ﬁcation and learning over graphs: Accounting for nonlinearities and
dynamics,” Proceedings of the IEEE, vol. 106, no. 5, pp. 787–807,
2018.

[78] I. Brugere, B. Gallagher, and T. Y. Berger-Wolf, “Network structure
inference, a survey: Motivations, methods, and applications,” ACM
Computing Surveys, vol. 51, no. 2, pp. 1–39, 2018.

[79] Y. Li and J. He, “Topology inference for networked dynamical systems:
A causality and correlation perspective,” in 2021 60th IEEE Conference
on Decision and Control (CDC).

IEEE, 2021, pp. 1218–1223.

[80] Y. Li, J. He, C. Chen, and X. Guan, “On topology inference for
networked dynamical systems: Principles and performances,” arXiv
preprint arXiv:2106.01031, 2021.

[81] V. Matta and A. H. Sayed, “Consistent tomography under partial ob-
servations over adaptive networks,” IEEE Transactions on Information
Theory, vol. 65, no. 1, pp. 622–646, 2019.

[82] M. Cirillo, V. Matta, and A. H. Sayed, “Learning Bollob´as-Riordan
graphs under partial observability,” in 2021 IEEE International Con-
ference on Acoustics, Speech and Signal Processing (ICASSP), 2021,
pp. 5360–5364.

[83] A. Simpkins, “System identiﬁcation: Theory for the user,” IEEE
Robotics and Automation Magazine, vol. 19, no. 2, pp. 95–96, 2012.
[84] S. Oymak and N. Ozay, “Non-asymptotic identiﬁcation of LTI systems
from a single trajectory,” in 2019 American control conference (ACC).
IEEE, 2019, pp. 5655–5661.

[85] M. Simchowitz, R. Boczar, and B. Recht, “Learning linear dynamical
systems with semi-parametric least squares,” in Conference on Learn-
ing Theory. PMLR, 2019, pp. 2714–2802.

[86] Y. Zheng and N. Li, “Non-asymptotic identiﬁcation of linear dynamical
systems using multiple trajectories,” IEEE Control Systems Letters,
vol. 5, no. 5, pp. 1693–1698, 2020.

[87] B. HO and R.

E. K´alm´an,

“Effective

state-variable models

linear
Automatisierungstechnik, vol. 14, no. 1-12, pp. 545–548, 1966.
[88] A. Acar, H. Aksu, A. S. Uluagac, and M. Conti, “A survey on
homomorphic encryption schemes: Theory and implementation,” ACM
Computing Surveys, vol. 51, no. 4, pp. 1–35, 2019.

from input/output

construction

of
functions,” at-

22

[90] F. Farokhi, I. Shames, and N. Batterham, “Secure and private control
using semi-homomorphic encryption,” Control Engineering Practice,
vol. 67, pp. 13–20, 2017.

[91] M. Schulze Darup, A. Redder, and D. E. Quevedo, “Encrypted coop-
erative control based on structured feedback,” IEEE Control Systems
Letters, vol. 3, no. 1, pp. 37–42, 2019.

[92] Y. Lu and M. Zhu, “Privacy preserving distributed optimization using

homomorphic encryption,” Automatica, vol. 96, pp. 314–325, 2018.

[93] C. Zhang, M. Ahmad, and Y. Wang, “ADMM based privacy-preserving
decentralized optimization,” IEEE Transactions on Information Foren-
sics and Security, vol. 14, no. 3, pp. 565–580, 2019.

[94] Q. Geng and P. Viswanath, “The optimal noise-adding mechanism in
differential privacy,” IEEE Transactions on Information Theory, vol. 62,
no. 2, pp. 925–951, 2015.

[95] C. Dwork, “Differential privacy,” in International Colloquium on
Automata, Languages, and Programming. Springer, 2006, pp. 1–12.
[96] J. Cort´es, G. E. Dullerud, S. Han, J. Le Ny, S. Mitra, and G. J. Pappas,
“Differential privacy in control and network systems,” in 2016 55th
IEEE Conference on Decision and Control (CDC).
IEEE, 2016, pp.
4252–4272.

[97] J. He, L. Cai, and X. Guan, “Differential private noise adding mecha-
nism and its application on consensus algorithm,” IEEE Transactions
on Signal Processing, vol. 68, pp. 4069–4082, 2020.

[98] V. Katewa, F. Pasqualetti, and V. Gupta, “On privacy vs. cooperation in
multi-agent systems,” International Journal of Control, vol. 91, no. 7,
pp. 1693–1707, 2018.

[99] J. He, L. Cai, and X. Guan, “Preserving data-privacy with added
noises: Optimal estimation and privacy analysis,” IEEE Transactions
on Information Theory, vol. 64, no. 8, pp. 5677–5690, 2018.
[100] J. Li, J. He, Y. Li, and X. Guan, “Unpredictable trajectory design for
mobile agents,” in 2020 American Control Conference (ACC).
IEEE,
2020, pp. 1471–1476.

[101] Z. Wang, Y. Li, C. Fang, and J. He, “Distributed topology-preserving
collaboration algorithm against inference attack,” in 2022 American
Control Conference (ACC).

IEEE, to be published.

[102] Y. Yuan, X. Tang, W. Zhou, W. Pan, X. Li, H.-T. Zhang, H. Ding,
and J. Goncalves, “Data driven discovery of cyber physical systems,”
Nature Communications, vol. 10, no. 1, pp. 1–9, 2019.

[103] B. D. Anderson and J. B. Moore, Optimal control: Linear quadratic

methods. Courier Corporation, 2007.

[104] D. C. Montgomery, E. A. Peck, and G. G. Vining, Introduction to

linear regression analysis.

John Wiley & Sons, 2021.

[105] Q. Jiao, Y. Li, and J. He, “Topology inference for consensus-based
input,” in 2021 IEEE 94th

cooperation under time-invariant
Vehicular Technology Conference (VTC2021-Fall), 2021, pp. 1–5.

latent

[106] Y. Zheng, L. Furieri, A. Papachristodoulou, N. Li, and M. Kamgarpour,
“On the equivalence of Youla, system-level, and input-output parame-
terizations,” IEEE Transactions on Automatic Control, vol. 66, no. 1,
pp. 413–420, 2021.

[107] X. Mao and J. He, “Decentralized system identiﬁcation method for
large-scale networks,” in 2022 American Control Conference (ACC).
IEEE, to be published.

[108] X. Mao, J. He, and C. Zhao, “An improved subspace identiﬁcation
method with variance minimization and input design,” in 2022 Amer-
ican Control Conference (ACC).

IEEE, to be published.

[109] Y. Kawano and M. Cao, “Design of privacy-preserving dynamic
controllers,” IEEE Transactions on Automatic Control, vol. 65, no. 9,
pp. 3863–3878, 2020.

[110] Y. Kawano, K. Kashima, and M. Cao, “Modular control under privacy
protection: Fundamental trade-offs,” Automatica, vol. 127, p. 109518,
2021.

[111] E. Nekouei, M. Pirani, H. Sandberg, and K. H. Johansson, “A ran-
domized ﬁltering strategy against inference attacks on active steering
control systems,” IEEE Transactions on Information Forensics and
Security, vol. 17, pp. 16–27, 2022.

[112] K. Yazdani, A. Jones, K. Leahy, and M. Hale, “Differentially private
LQ control,” IEEE Transactions on Automatic Control, 2022.
[113] C. Hawkins and M. Hale, “Differentially private formation control,” in
2020 59th IEEE Conference on Decision and Control (CDC).
IEEE,
2020, pp. 6260–6265.

[114] S. Levine, “Reinforcement learning and control as probabilistic infer-

ence: Tutorial and review,” arXiv preprint arXiv:1805.00909, 2018.

[89] K. Kogiso and T. Fujita, “Cyber-security enhancement of networked
control systems using homomorphic encryption,” in 2015 54th IEEE
Conference on Decision and Control, 2015, pp. 6836–6843.

[115] C. De Persis and P. Tesi, “Formulas for data-driven control: Stabi-
lization, optimality, and robustness,” IEEE Transactions on Automatic
Control, vol. 65, no. 3, pp. 909–924, 2020.

23

She was a recipient of the NSERC Discovery Accelerator Supplement
(DAS) Grants in 2010 and 2015, respectively, and the Best Paper Awards of
IEEE ICC 2008 and IEEE WCNC 2011. She has co-founded and chaired the
IEEE Victoria Section Vehicular Technology and Communications Joint So-
cieties Chapter. She has been elected to serve the IEEE Vehicular Technology
Society Board of Governors, 2019 - 2024. She has served as an area editor for
IEEE Transactions on Vehicular Technology, a member of the Steering Com-
mittee of the IEEE Transactions on Big Data (TBD) and IEEE Transactions on
Cloud Computing (TCC), an Associate Editor of the IEEE Internet of Things
Journal, IEEE Transactions on Wireless Communications, IEEE Transactions
on Vehicular Technology, IEEE Transactions on Communications, EURASIP
Journal on Wireless Communications and Networking, International Journal
of Sensor Networks, and Journal of Communications and Networks (JCN),
and as the Distinguished Lecturer of the IEEE VTS Society and the IEEE
ComSoc Society. She has served as a TPC co-chair for IEEE VTC2020-Fall,
and a TPC symposium co-chair for IEEE Globecom’10 and Globecom’13.
She is a registered professional engineer in British Columbia, Canada.

Xinping Guan (F’18) received the B.S. degree in Mathematics from Harbin
Normal University, Harbin, China, in 1986, and the Ph.D. degree in Control
Science and Engineering from Harbin Institute of Technology, Harbin, China,
in 1999. He is currently a Chair Professor with Shanghai Jiao Tong University,
Shanghai, China, where he is the Dean of School of Electronic, Information
and Electrical Engineering, and the Director of the Key Laboratory of Systems
Control and Information Processing, Ministry of Education of China. Before
that, he was the Professor and Dean of Electrical Engineering, Yanshan
University, Qinhuangdao, China.

Dr. Guan’s current research interests include industrial cyber-physical sys-
tems, wireless networking and applications in smart factory, and underwater
networks. He has authored and/or coauthored 5 research monographs, more
than 270 papers in IEEE Transactions and other peer-reviewed journals, and
numerous conference papers. As a Principal Investigator, he has ﬁnished/been
working on many national key projects. He is the leader of the prestigious
Innovative Research Team of the National Natural Science Foundation of
China (NSFC). Dr. Guan received the First Prize of Natural Science Award
from the Ministry of Education of China in both 2006 and 2016, and the
Second Prize of the National Natural Science Award of China in both 2008 and
2018. He was a recipient of IEEE Transactions on Fuzzy Systems Outstanding
Paper Award in 2008. He is a National Outstanding Youth honored by NSF
of China, Changjiang Scholar by the Ministry of Education of China and
State-level Scholar of New Century Bai Qianwan Talent Program of China.

[116] L. Hewing, K. P. Wabersich, M. Menner, and M. N. Zeilinger,
“Learning-based model predictive control: Toward safe learning in con-
trol,” Annual Review of Control, Robotics, and Autonomous Systems,
vol. 3, pp. 269–296, 2020.

[117] C. Chen, H. Modares, K. Xie, F. L. Lewis, Y. Wan, and S. Xie,
“Reinforcement learning-based adaptive optimal exponential tracking
control of linear systems with unknown dynamics,” IEEE Transactions
on Automatic Control, vol. 64, no. 11, pp. 4423–4438, 2019.
[118] T. Westenbroek, F. Casta˜neda, A. Agrawal, S. S. Sastry, and
K. Sreenath, “Learning min-norm stabilizing control laws for systems
with unknown dynamics,” in 2020 59th IEEE Conference on Decision
and Control (CDC).
IEEE, 2020, pp. 737–744.

[119] T. Westenbroek, A. Agrawal, F. Casta˜neda, S. S. Sastry, and
K. Sreenath, “Combining model-based design and model-free policy
optimization to learn safe, stabilizing controllers,” IFAC-PapersOnLine,
vol. 54, no. 5, pp. 19–24, 2021.

[120] Z. He, S. Bolognani, J. He, F. D¨orﬂer, and X. Guan, “Model-free
nonlinear feedback optimization,” arXiv preprint arXiv:2201.02395,
2022.

[121] F. Pukelsheim, “The three sigma rule,” The American Statistician,

vol. 48, no. 2, pp. 88–91, 1994.

Jianping He (SM’19) is currently an associate professor in the Department of
Automation at Shanghai Jiao Tong University. He received the Ph.D. degree in
control science and engineering from Zhejiang University, Hangzhou, China,
in 2013, and had been a research fellow in the Department of Electrical and
Computer Engineering at University of Victoria, Canada, from Dec. 2013
to Mar. 2017. His research interests mainly include the distributed learning,
control and optimization, security and privacy in network systems.

Dr. He serves as an Associate Editor for IEEE Trans. Control of Network
Systems, IEEE Open Journal of Vehicular Technology, and KSII Trans.
Internet and Information Systems. He was also a Guest Editor of IEEE TAC,
International Journal of Robust and Nonlinear Control, etc. He was the winner
of Outstanding Thesis Award, Chinese Association of Automation, 2015. He
received the best paper award from IEEE WCSP’17, the best conference paper
award from IEEE PESGM’17, and was a ﬁnalist for the best student paper
award from IEEE ICCA’17, and the ﬁnalist best conference paper award from
IEEE VTC’20-FALL.

Yushan Li (S’19) received the B.E. degree in School of Artiﬁcial Intelligence
and Automation from Huazhong University of Science and Technology,
Wuhan, China, in 2018. He is currently working toward the Ph.D. degree
with the Department of Automation, Shanghai Jiaotong University, Shanghai,
China. He is a member of Intelligent of Wireless Networking and Cooperative
Control group. His research interests include robotics, security of cyber-
physical system, and distributed computation and optimization in multi-agent
networks.

Lin Cai (F’20) received her M.A.Sc. and Ph. D. degrees (awarded Outstanding
Achievement in Graduate Studies) in electrical and computer engineering from
the University of Waterloo, Waterloo, Canada, in 2002 and 2005, respectively.
Since 2005, she has been with the Department of Electrical and Computer
Engineering at the University of Victoria, and she is currently a Professor.
She is an NSERC E.W.R. Steacie Memorial Fellow, an Engineering Institute
of Canada (EIC) Fellow, and an IEEE Fellow. In 2020, she was elected as a
Member of the Royal Society of Canada’s College of New Scholars, Artists
and Scientists. She was also elected as a 2020 “Star in Computer Networking
and Communications” by N2Women. Her research interests span several areas
in communications and networking, with a focus on network protocol and
architecture design supporting emerging multimedia trafﬁc and the Internet
of Things.

