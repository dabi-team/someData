Security and Privacy in the Emerging Cyber-Physical World: A Survey

Zhiyuan Yu, Zack Kaplan, Qiben Yan, Ning Zhang

in IEEE Communications Surveys & Tutorials

©2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any
current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new
collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other
works. DOI:10.1109/COMST.2021.3081450

1
2
0
2

y
a
M
7
2

]

R
C
.
s
c
[

1
v
7
4
3
3
1
.
5
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
Security and Privacy in the Emerging
Cyber-Physical World: A Survey

Zhiyuan Yu, Student Member, IEEE, Zack Kaplan, Student Member, IEEE,
Qiben Yan, Senior Member, IEEE, Ning Zhang, Member, IEEE

1

Abstract—With the emergence of low-cost smart and connected
IoT devices, the area of cyber-physical security is becoming in-
creasingly important. Past research has demonstrated new threat
vectors targeting the transition process between the cyber and
physical domains, where the attacker exploits the sensing system
as an attack surface for signal injection or extraction of private
information. Recently, there have been attempts to characterize
an abstracted model for signal injection, but they primarily focus
on the path of signal processing. This paper aims to systematize
the existing research on security and privacy problems arising
from the interaction of cyber world and physical world, with
the context of broad CPS applications. The primary goals of the
systematization are to (1) reveal the attack patterns and extract
a general attack model of existing work, (2) understand possible
new attacks, and (3) motivate development of defenses against
the emerging cyber-physical threats.

Index Terms—Security, Signal Injection, Side-Channel Infor-

mation Leakage, Cyber-Physical Systems, Sensors

Fig. 1: The attacker either exploits the transition from the
physical world to the cyber domain for signal injection attacks,
or the transition from the cyber domain to the physical world
for information leakage attacks.

I. INTRODUCTION

Cyber-physical system (CPS) has been an active area of
research for a decade, integrating and connecting techniques in
embedded systems, communications, and controls to address
unique challenges in marrying cyber systems with physical
world processes [1]. In recent years, with increasingly low-
ered cost and improved computational capability, embedded
computing systems are pervasively deployed in broad ﬁelds,
such as aerospace, automotive, chemical production, civil
infrastructure, energy, healthcare, manufacturing, materials,
and transportation [2]. The recent boom in consumer-facing
Internet of Things (IoT) technology has played an important
role in the introduction of CPS into the consumer space. It
is predicted that there will be a total of 29 billion connected
devices by 2022, of which around 18 billion will be related to
IoT [3]. Furthermore, the global cyber-physical system market
is expected to witness a compound annual growth rate (CAGR)
of 8.7% from 2018 to 2028 and reach $137,566 million by the
end of 2028 [4].

As cyber-physical systems play critical roles in our day-to-
day lives, attacks on CPS can have particularly severe impacts
on human lives and the environment. Recognizing the pressing
need to understand the attacks on safety-critical cyber-physical
systems, there have been numerous efforts to systemize and
categorize the ﬁeld of attacks and defenses on CPS. For
instance, [2] and [5] quantitatively analyze the broad research

Z. Yu, Z. Kaplan, N. Zhang is with Washington University in St.
Louis, MO, USA. Email: yu.zhiyuan@wustl.edu, zack.kaplan@wustl.edu,
zhang.ning@wustl.edu. Corresponding author: Zhiyuan Yu.

Q. Yan is with Michigan State University, MI, USA. Email: qyan@msu.edu.

trend of CPS security to show the distribution of research top-
ics. [6], [7], and [8] categorize CPS research based on different
application scenarios such as power grid and industrial control
systems (ICS). From the perspective of defenses, [9] focuses
on attack detection and secure estimation techniques, while
[10] and [11] summarize automatic intrusion detection in CPS.
More recently, [12], [13], and [14] systemize the attacks that
leverage physical signals to affect the electronic components
(mainly sensors) in cyber-physical systems. However, one
of the unique properties of cyber-physical systems is their
interaction with the physical world, and it has not been the
focus of existing work to analyze the security and privacy
problems stemming from such interaction. As the cyber world
and physical world are becoming increasingly intertwined, it is
important to understand the potential security issues that arise
from this evolving threat landscape with new technological
developments.

To ﬁll this gap, we present a comprehensive survey of
attacks targeting the interaction between the cyber world and
physical world in this paper. More speciﬁcally, we explore
attacks that target the transition between phenomena in the
physical world and signals in the cyber domain, where attack-
ers exploit unintended functionality in the sensing subsystem
of CPS to deliver an attack or leverage sensors to pick
up unintended emanations from the system. As shown in
Fig. 1, we broadly refer these two attacks as signal injection
and information leakage. In a signal
the
attack goal is to manipulate the physical environment, such
as acoustic signals, so that the target system obtains a false
perception of the physical world, i.e. exploiting the transition

injection attack,

from the physical world to the cyber domain. In an information
leakage attack, the attack goal is to infer sensitive information,
such as keystrokes, cryptographic keys, or user activity by
sensing and analyzing output from unintended emanations of
the target system. Contrary to signal injection attacks, the
attacker here intends to infer physical world information by
analyzing sensor data, i.e. exploiting the transition from the
cyber domain to the physical world.

In this paper, we refer to these attacks as cyber-physical
attacks, which exhibit the following unique characteristics: (1)
the attack surface via sensors is the link between cyber and
physical domains; (2) the attackers target the transition process
between physical and cyber domains; and (3) different from
conventional cyber-domain attacks, these two types of attacks
exploit both physical and cyber domains. Therefore, we do
not include the following topics in this paper: (1) attacking
other cyber components within the CPS, such as the CAN
bus [15] [16] [17], electronic control unit (ECU) [18] [19],
networks [17] [20] [21], realtime operating systems [22], and
ﬁrmware [23] [24]; (2) using sensor properties to ﬁngerprint
devices [25] [26] [27] or physical objects [28] [29] [30].

For signal injection attacks, after describing the abstracted
model for these attacks, existing researches on signal injection
attacks are then categorized and discussed based on the physi-
cal vectors being manipulated. Despite remarkable progress in
the past few years, there are still many challenges in this area
for both attacks and defenses, thus we end the discussion with
limitations and future opportunities. For information leakage
attacks, different from signal injection, they often have more
common objectives rather than the exploited physical channels,
therefore we group and discuss them based on the attack goal.
Lastly, we conclude our review with an in-depth discussion on
new opportunities in both attacks and defenses.

Contributions - The main contributions of this paper are:
• We develop a general system model for cyber-physical
attacks, and formalize attack requirements and different
threat models.

• We categorize and discuss existing research in both
physical-to-cyber signal injection and cyber-to-physical
information leakage attacks as well as the corresponding
defenses, followed by discussion on the limitations and
opportunities in both areas.

• We highlight how latest development in computer net-
work and embedded system will change the evolving
landscape of attack and defense in the emerging tightly
connected cyber-physical world.

Organization - This paper will be organized as follows:
Section II will summarize and categorize related surveys about
CPS security. Section III will give a generalized system model
of broad CPS and outline cyber-physical interfaces. Section IV
will develop a general model for signal injection attacks and
survey the existing literature. Section V will develop a general
model for information leakage attacks and survey the exist-
ing literature. Detection methods and prevention techniques
against cyber-physical attacks are presented in Section VI.
Besides, Section VII will provide research opportunities in
both cyber-physical attacks and defenses. Finally, Section VIII
will summarize the survey and draw conclusions.

2

TABLE I: Summary of Related Surveys in CPS Security

Scope

CPS security overview

Domain-speciﬁc analysis

Algorithm-level analysis

Sensing pipeline analysis
Sensing pipeline analysis

Cyber-physical interaction

Speciﬁc Domain
CPS security summary
CPS security surveys
CPS security research trend
Power grid
Medical device
Industrial control system
Drone
Secure estimation & control
Intrusion detection
Anomaly identiﬁcation
Out-of-band injection
Transduction attack
Signal injection
& Information leakage

Reference
[31],[32],[33]
[2]
[5]
[6],[7],[34],[35]
[36],[37]
[8],[38]
[39]
[9]
[10],[11]
[40]
[12],[13]
[14]

Our survey

II. RELATED WORK

A. Existing Literature

Due to the rapid integration of various CPS into society, the
security and safety properties of these systems are gathering
increasing attention. There have been several studies that at-
tempt to systematize the security challenges and opportunities
in cyber-physical systems from different perspectives. As we
summarize in Table I, they generally fall into four categories:
CPS security overview, domain-speciﬁc analysis, algorithm-
level analysis, and sensing pipeline analysis. However, our
survey systematizes existing research from a fundamentally
different angle of cyber-physical interaction, focusing on both
attacks from the physical world to the cyber world - signal
injection, and attacks from the cyber world to the physical
world - information leakage. This difference in systematization
leads to a complementary analysis of the ﬁeld and offers a
distinct perspective for how new defenses can be constructed.
In the rest of this section, we will present these existing works
and the problems they address.

1) CPS Security Overview: The ﬁrst category of surveys
investigate and summarize the entire CPS security ﬁeld from
a high level. Some of these surveys aim to comprehen-
sively present security issues in each layer of CPS architec-
ture [31] [32] [33]. Although the threats embedded within
sensors have been included in these surveys, the discussions
are limited to provide breath on in-band injection attacks
and examine the impacts of classical attacks such as replay
attacks [33] and signal jamming [31]. Besides, as privacy
leakage from sensing components is not the focus, therefore
the discussion is minimal. Some other surveys investigate
research topic distributions and trends by quantitatively an-
alyzing the representative researches and surveyed papers.
As an example, Lun et al. [5] use systematic mapping to
create a quantitative analysis among a collection of 118
papers concerning CPS security in which publication trends,
focus of existing research, and strategies used to validate the
existing mechanisms are statistically analyzed. In the same
vein, Giraldo et al. [2] investigate existing surveys about
CPS security in terms of attacks, defenses, network security,
security level implementation, computational strategies, and
also quantitatively summarize research trends.

Gap Analysis: The related work in this area aims to provide
breath on various security issues, from network security to ap-
plication software security, from technological to operational,

and from sensors to algorithms. The large scope of the study
limits the level of detail that can be presented and analyzed in
these surveys. Our survey is different in that there is a strong
focus on cyber-physical interaction, which results in an in-
depth analysis of the embedded security issues, while other
aspects such as traditional network security are not included
in the discussion of our survey.

2) Domain-Speciﬁc Analysis: Some surveys aim to system-
atize the attacks and defenses in speciﬁc application domains
of CPS. For example, [6], [7], [34], and [35] focus on power
grids, [36] and [37] focus on medical devices, [8] and [38]
focus on ICS, [39] focuses on drones, etc.

Gap Analysis: As each of them focuses on one speciﬁc CPS
application domain, the insights and conclusions drawn are of-
ten domain-speciﬁc. For example, switching attacks targeting
circuit breakers and electricity market attacks discussed in the
context of power grids [6] [7] are highly scenario-dependent,
and are not included in the security discussions of other types
of CPS. In this work, instead of analyzing the security of a
speciﬁc domain, we organize around the physical medium with
which an attacker can target the cyber-physical systems, i.e.
the cyber-physical attack vectors. For each attack vector, we
discuss how existing works are leveraging it to compromise all
types of cyber-physical systems. Therefore, some insights into
new directions of attacks and defenses can be generalized to
cyber-physical systems in other domains with some adaptation.
3) Algorithm-Level Analysis: There are also some surveys
that focus on the exploration of different existing algorithms
for intrusion detection and anomaly mitigation. Wu et al.
[9] demonstrate recent research concerning topics of attack
detection and secure estimation and control techniques, while
[10] and [11] look into the self-detection of intrusion in CPS.
Giraldo et al. [40] summarize works where time-series models
are created via monitoring the physical world to identify
anomalies, control commands, or sensor readings. Algorith-
mic analysis for CPS primarily focuses on the detection of
deviation and mitigation of control for systems under attack.
For the algorithmic solution to be effective, there is often
an assumption about
the overall
design philosophy still generally applies. However, an implicit
assumption behind these solutions is an accurate or at least
error-bounded perception of the real world.

the physical model, but

Gap Analysis: Our survey focuses on the cyber-physical
interactions, which is a key foundation for forming an accurate
perception of the physical world. As a result, our survey and
the algorithmic approach are complementary. Approaches in
the algorithmic survey can be effective defenses against some
of the attacks we discuss, such as false data injection [41], and
the attacks in this survey can in turn inform the algorithmic
research of the emerging threat models.

4) Sensing Pipeline Analysis: Lastly, after several demon-
strations of the feasibility of the manipulation of physical
world signals to attack cyber systems [42] [43], some efforts
have been made to systematize how maliciously crafted phys-
ical environments can affect electronic components such as
sensors in cyber-physical systems. Giechaskiel et al. [13] ﬁrst
develop a general model for signal injection attacks, and then
propose an algorithm to calculate the security level of real

3

systems such as smartphones. Following this work, they go
deeper and formalize a sub-domain of signal injection, i.e.
out-of-band signal injection attacks, where the injected signal
is out of the intended range of receivers [12]. Yan et al. [14]
broaden the scope of out-of-band signal injection and consider
the problem along the entire signal processing pipeline, which
they call transduction attacks, where the victim sensor trans-
duces physical signals to analog output with the possibility of
combining effects from multiple processing stages. However,
these works focus exclusively on signal injection attacks.

Gap Analysis: While how the physical world could mali-
ciously impact cyber data is analyzed, attacks leveraging cyber
world capabilities to eavesdrop on the physical world are not
considered in these works.

B. Gap Analysis and Our Focus

While the area of CPS security has attracted signiﬁcant
attention, none of the existing work structures analysis based
on cyber-physical interfacing. Unlike traditional security is-
sues, such as network and control security,
the emerging
threats surrounding the transmission of signals from and to the
physical world, namely, physical-to-cyber signal injection at-
tacks and cyber-to-physical information leakage attacks, have
not been studied systematically yet. The absence of knowl-
edge systemization can signiﬁcantly hinder the development
of novel defenses for these new threats, where traditional
defenses have limited effectiveness on. To bridge this gap,
we aim to summarize and generalize attacks targeting sensing
components from the perspective of cyber-physical interaction.
To this effect, we develop a generalized system model of CPS
as well as an attack model for each attack, which reveals the
capabilities of these attacks when applied to broad CPS includ-
ing cellphones, autonomous vehicles, drones, UAVs, medical
implant systems, voice-controlled systems, and others. More
importantly, we provide a new way to understand and motivate
effective defenses based on our systemized threat model. By
viewing security issues from this brand new perspective with
a speciﬁc focus on signal attacks, we believe this work will
help ﬁll the knowledge gap and motivate new research in this
emerging area.

III. CPS SYSTEM MODEL

In this section, we ﬁrst discuss the abstracted CPS architec-
ture and the interaction between components. This is followed
by a description of the cyber-physical interface, which consists
of the sensing system and actuator. Lastly, we will discuss the
unique threats stemming from such cyber-physical interfacing
as compared to conventional cyber attacks on networks and
software systems.

A. High Level Architecture

As shown in Fig. 2, the general model for a CPS consists of
two layers: the application layer and the cyber-physical layer.
The application layer facilitates different ways for the cyber-
physical layer to interact with local or external applications.
The key components in the cyber-physical layer we consider

4

focus on injecting false commands in order to perform cyber-
to-physical exploitation. This false command injection can
either be realized using a false cyber-domain message, such
as an injected network message or control ﬂow hijacking in
software, or via exploitation of an unintended receiver in the
electronic component to deliver malicious signals. Besides,
as the sensor nodes are located at the border between what
belongs to CPS and what does not, these sensors are more
susceptible to attacks because of their exposure to both cyber
and physical domains [46]. Therefore, we will primarily focus
our discussion on the sensing system.

Sensors can be categorized into two types based on the way
they probe surroundings: passive sensors, and active sensors.
• Passive sensors, such as microphones and MEMS motion
sensors, receive pre-existing physical signals and do not
emit external stimuli. They are essentially listening de-
vices for physical phenomena, whose purpose is to simply
relay the measured signals to upper-layer software.

• Active sensors, such as radar and LiDAR, probe their sur-
roundings by actively emitting signals to evoke physical
responses (i.e., reﬂected signals), from some measured
entity such as surrounding objects. The reﬂected signal is
then measured by the receiver. The sensor contains an on-
board controller, which analyzes the relationship between
the transmitted and received signals to infer features
of the surrounding environment, such as the proximity,
relative angle, and shape of nearby objects.

Even given high diversity and heterogeneity of sensors, they
often consist of the same basic components: sensing mecha-
nism, ampliﬁers, ﬁlters, and analog-to-digital converters.

1) Sensing mechanism: While active sensors are more
complex in their operation, their signal reception subsystems
are similar to that of passive sensors. The sensing mecha-
nism is the component that responds to changes in a given
physical parameter, s(t), and generates an output voltage,
v(t), which is directly proportional to the physical signal.
This is mathematically represented as v(t) = α · s(t), where
α is the proportionality constant, or the sensitivity of the
sensor. This relationship is referred to as linearity, and is a
desired quality in a sensor. In reality, sensors exhibit non-
linear behavior, which means for certain ranges of the physical
signal, the sensor output is not directly proportional to the
input. Despite being a non-ideal characteristic of sensors,
attackers can actually use non-linearity to their advantage
when attempting to inject out-of-band signals. This is further
discussed in Section IV-C1.

2) Ampliﬁcation and ﬁltering: In some sensors, the voltage
signal, v(t), is ampliﬁed to reach the voltage speciﬁcation
of the microcontroller, and ﬁltered to remove any unwanted
frequency components. When injecting out-of-band signals,
the ﬁltering stage can pose a challenge for attackers, since the
injected signals can be severely attenuated by the ﬁlter.

3) Analog-to-digital conversion: The analog-to-digital con-
verter (ADC) converts the analog voltage signal to a discrete
digital signal by sampling the signal at a certain frequency,
which is a parameter known as the ADC’s sample rate, and
converts samples to certain-bit numbers, which is denoted as
its resolution. More details are presented in Section IV-C.

Fig. 2: High-level CPS architecture. CPS generally consists
of the application layer and cyber-physical layer. These two
layers communicate via networks, and the cyber-physical layer
can be further divided into cyber and physical domains.

consist of the physical environment, sensor, actuator, embed-
ded system, and IoT device. Generally, sensors will collect
physical signals from the environment and digitize them for the
embedded system, which consists of the software or hardware
controller that receives and processes digital signals from
the sensors. Based on the control algorithm, the embedded
controller then outputs the corresponding control signals to
the actuators. This feedback loop often has predictable timing
behaviors to ensure that the information is processed and acted
upon in a safe manner. If the CPS is connected to a network,
the embedded system is also responsible for transmitting
and receiving network signals to communicate with various
services via cloud technologies.

Since this paper focuses on the security problems that arise
from the cyber-physical interactions, we will focus on the
discussions relevant to the cyber-physical layer. The following
Section III-B and III-C will present how cyber data and
physical phenomena interact and the resulting unique threats.

B. Cyber-Physical World Interfacing

Sensors and actuators are the two main components that
enable cyber-physical world interfacing. Sensors in CPS gen-
erally serve as physical-interfacing nodes that interact with
environments, components, or other miscellanea that are not
a part of that system [44]. They provide usable outputs
in response to speciﬁc measurands [45], by which cyber-
physical systems form accurate perceptions of the surrounding
environment, leading to more autonomous, intelligent, and
reliable systems. Actuators, on the other hand, enable cyber
systems to change the physical state of their surroundings.
Besides traditional actuators in larger-scale CPS, emerging
IoT devices also include actuation components to affect their
environments and coordinate among various IoT devices.
However, malicious attacks are generally initiated from user
input, and the actuator doesn’t take input directly from the
physical world, therefore the majority of existing attacks still

5

Fig. 3: Taxonomy of cyber-physical attacks and defenses

C. Unique Threats of Cyber-Physical Interfacing

1) Unique Attack Vector: One unique aspect of cyber-
physical attacks is their transition from one domain to the
other domain, in other words, it is possible for a cyber attack
to have a physical effect. This unique attribute of these attacks
has a signiﬁcant impact on the risk it presents to our society.
While there have been studies pertaining to traditional cyber
security issues in the cyber-physical system applications do-
main, such as power grids [6] [7] [34] [35], it is not our focus
since they are conventional security problems. More recently,
people are increasingly aware of threats brought about by IoT
devices, such as leveraging IoT devices to perform DDoS
attacks [47] [48]. However, this remains a network security
problem, widely accessible and vulnerable IoT devices just
amplify the attack impact. In this survey, we focus on a
new attack vector, cyber-physical
is unlike
traditional network or software attacks, which are well-known
with mature defensive technologies such as ﬁrewalls, network
intrusion detection systems, and virus scanners. Attacks that
target vulnerabilities of the physical construction of computing
systems completely evade traditional cyber defenses, due to the
fundamental limitation on the amount of information received
by the cyber domain after going through layers of commu-
nication abstractions (e.g., signal demodulation). Therefore, it
is important for the community to understand this changing
landscape of threats.

interfacing. It

Fig. 3 shows a taxonomy of existing cyber-physical attacks
and defenses on CPS we systematize. The attackers can either
manipulate cyber data via injecting physical emanations, or
eavesdrop on physical information from sensor data. As the
approaches taken by the attacker are closely related to the
type of signals and adversary goals, we will formalize and

demonstrate various attacks using these attack vectors and
attack goals in the following Section IV and V. Additionally,
we summarize the existing defenses that protect CPS from
cyber-physical attacks. They are categorized based on the
domain where they are implemented because defenses in the
same domain share similar principles and limitations, which
will be further discussed in Section VI.

2) Emergence of Consumer IoT: The concept of

IoT
emerged from the radio-frequency identiﬁcation (RFID) com-
munity and initially focused on the ability to track the location
and status of physical objects [49] [50]. Today, with the rapid
development of wireless sensor networks (WSN) [51] and
cloud computing [52], the term IoT has been expanded to refer
to networked devices and systems [53] [54], and can be used to
describe systems as large as smart farms [55] [56], cities [57],
and as small as individual nodes in a sensor swarm [58].
The concept of IoT overlaps signiﬁcantly with cyber-physical
system [54]. This is because many key technologies that are
essential to CPS also form the foundation of IoT, such as
machine-to-machine (M2M) communication [59] [60], device-
to-device (D2D) communication [61], and sensing [14]. For
example, industrial internet of things (IIoT) is an important
area that intersects signiﬁcantly with CPS [62]. It is poised to
bring revolutionary changes to realize the vision of the next-
generation industrial revolution (known as Industry 4.0) [63].
With massive numbers of smart sensors and actuators inter-
connected and integrated into industrial systems, the M2M
communication and the cloud/edge intelligence play a key
role in enabling intelligent manufacturing [64] [65]. While
IIoT has become an increasingly important area where security
protection would be extremely critical [66], the attacks and
defenses discussed in our survey could be applied to systems

with physical interfaces including IIoT.

To be more precise in our discussion in this survey, we will
use IoT to refer to the consumer electronics that enable smart
connections. As consumer IoT devices become ubiquitous,
they are signiﬁcantly changing how our cyber world and
physical world interleave in day-to-day life. As a matter of
fact, while the cyber-physical interface has always been there,
the security aspect of these systems has not received much
attention until recently. The large-scale cyber-physical systems
such as aircraft and IIoT systems are often less accessible to
the general public and security researchers. As a result, much
of the existing research focuses on security problems (either
injecting signals from the physical world, or stealing physical
information from the cyber world) of IoT consumer devices.
However, the principles and techniques derived from research
on IoT devices are often generally applicable to the larger
domain of cyber-physical systems.

Lately, IoT has been in the news, either as the victim of
cyber attacks or as the enabler for attackers. Cyber-physical
attacks under study in this survey are related to these IoT
attacks. However, they are different in several respects. Cyber-
physical attacks refer to attacks on cyber-physical interfacing,
therefore traditional network attacks that compromise IoT
devices are not in the scope of cyber-physical attacks. On
the other hand, cyber-physical attacks generally apply to any
system that interfaces with the physical world, which include
consumer IoT devices.

3) Distinguish Attacks on IoT and CPS: Although attacks
can be generalized to target both IoT devices and broad cyber-
physical systems, they can differ in deployment architecture,
attack impact, and physical environment.

First, the software architecture for consumer IoT and CPS
can be signiﬁcantly different. Consumer IoT devices often
adopt the architecture with a lightweight embedded device
coupled with a cloud backend to provide smart-living services
to consumers. However, large cyber-physical systems often
have different types of desktop/server class control stations
for operational management by a dedicated team. This results
in signiﬁcant differences in the attack surface between the two
types of systems, leading to distinct exploitation and defense
techniques both technically and operationally.

Second, the impact of an attack can be different. Many
consumer IoT devices are not safety-critical, so an attack may
not directly induce signiﬁcant harm. However, for larger CPS,
many of them are critical systems, such as power grids, which
have been the unfortunate targets of multiple recent attacks
that paralyze even an entire region [67]. Notably, consumer
IoT attacks have also changed the threat model in cyberspace.
Due to their pervasive deployment, there is a large number
of unprotected IoT nodes on the Internet that can be used to
form a botnet. Unlike a cyber-physical attack that compro-
mises a single or small number of CPS within close physical
proximity, vulnerabilities in IoT can lead to manifestation of
large-scale traditional security problems, such as distributed
denial of service (DDoS) attacks on dynamic DNS (DynDNS)
service [68]. As a matter of fact, IoT devices have been the
primary force behind the DDoS botnet attacks [69], where
giant botnets formed of vulnerable IoT devices signiﬁcantly

6

increase the attack strength and the number of compromised
services [70]. Besides, attacks on IoT devices can go beyond
network security and cause widespread effects. An example
is the mobile crowdsensing system, where individual devices
contribute to a collective result of the current physical environ-
ment [71]. In this scenario, a small number of compromised
IoT nodes can launch data poisoning attack to inﬂuence the
result of the output [72] [73] [74].

Lastly, differences can also lie in the physical environment
in general cases. The physical protections for complex CPS
can vary signiﬁcantly. For example, the physical perimeter
protection for a self-driving car is different from a gas line
crossing rural regions. This diversity raises unique challenges
for a generalized cyber-physical attack and defense model.
Strategies will have to be devised for individual cases based on
the expected threat and risk if compromised. On the contrary,
consumer IoTs often have well-deﬁned environments both in
the physical world (physical perimeter of a house or worksite)
and the cyber world (lightweight frontend and cloud backend).
The homogeneity of deployment environment for consumer
IoTs makes it easier to generalize approaches for both the
attack analysis and protection.

IV. PHYSICAL TO CYBER: SIGNAL INJECTION ATTACKS

Signal injection attacks are attacks in which the attacker
injects maliciously crafted signals to the target CPS, inducing
unintended behavior of the system. On the one hand, these
attacks are designed to disrupt cyber systems via physical
signals, therefore they can be regarded as physical-to-cyber
attacks. On the other hand, the attackers have to proactively
manipulate the physical world (often the physical properties
of the signal), thus they can be regarded as active attacks.
An adversary can inject the signals directly from within the
intended reception frequency of sensors embedded in the CPS,
or outside the intended range. These two types of attacks are
coined in [12] as (1) in-band signal injection, and (2) out-of-
band signal injection, respectively.

1) In-band signal injection: Attacks in which the adversary
injects signals that are within the exploited sensor’s
intended frequency of operation, such as using a bright
LED to blind a light sensor. By injecting in-band sig-
nals, the adversary can only affect sensor readings by
manipulating the physical phenomenon being sensed.

2) Out-of-band signal

injection: The adversary exploits
a hardware ﬂaw to inject signals that are out of the
intended range into the sensing system or components
not intended as receivers, often with the goal of gaining
implicit control over the sensor’s readings. Contrary to
in-band injection attacks, the attacker does not manipu-
late the property being measured by the sensor.

Fig. 4 demonstrates these two types of attacks. Fig. 4(a)
shows an in-band signal injection attack, where the attacker is
directly manipulating the physical property being measured by
the sensor, causing the sensing mechanism to output a voltage
proportional to the sum of the injected signal, a(t), and the
physical signal, s(t). Fig. 4(b) shows an out-of-band attack,
in which the maliciously crafted signal a(t) is injected into

7

electromagnetic, and optical. As a result, the attacker is able
to induce either sensor spooﬁng or denial of service (DoS).
To put these two attacks into concrete application domains,
we will discuss them in the following attack goals subsection.
3) Attack Goals: To understand the goals of signal injection
attacks on CPS, it is important to consider how feedback
from individual sensors inﬂuences the overall behavior of the
system, i.e. how the sensor feedback affects system behavior
and the physical environment. There are two ways attacks
can manifest themselves, either by inﬂuencing the physical
world or the cyber world, which we summarize as manipulate
physical space - control actuation, and manipulate cyber space
- control application layer software. The speciﬁc outcome of
exercising either type of control over CPS is highly system-
dependent, but it is still useful to highlight the most common
outcomes of signal injection attacks.

a) Control Actuation: Many cyber-physical systems use
feedback from sensors to determine the control signals that
are sent to the actuators. Thus, if an attacker can control
the sensor readings, they can potentially trigger or control
actuation in the system, which poses a signiﬁcant threat. The
control logic can be implemented locally in the embedded
controller, such as altitude control in a drone. More complex
control and coordination can also be implemented in a more
powerful edge node or cloud node, where the data from sensors
are wirelessly transmitted to a remote node where the control
computation occurs. Depending on the processing pipeline of
the cyber-physical controls, the falsiﬁed sensor data could be
crafted to trigger unintended behavior exhibited in the ﬁnal
actuation output. For example, an attack can leverage acoustic
signals to maliciously manipulate the gyroscope on a drone,
which ultimately affects the aviation actuation [80].

• Motion control: For mobile CPS such as radio-controlled
cars (RC cars) [81] and UAV drones [80] [82] [83], sensor
feedback is used to control the system’s movement. An
attacker can inject signals into these sensors to directly
control the system’s motion.
• Physical harm to humans:

In medical devices
such as implantable deﬁbrillators and medical infusion
pumps [36] [78], sensor feedback is used to control actu-
ation that inﬂuences physiological processes. Thus, with
injected signals, an attacker can directly cause physical
harm by interfering with medical-related functionalities.

b) Control Application Layer Software: The second
type of adversary impact lies within application layer software
in the cyber world rather than inﬂuencing physical states.
For instance, both dolphin attack [75] and surﬁng attack [84]
utilize ultrasound to deliver hidden commands, which will fur-
ther be recognized by voice-controlled systems and executed
in applications. The induced actions via injected inaudible
commands include calling someone, opening websites in the
browser, turning on airplane mode, and navigation. They reveal
that with injected signals, the actions of installed applications
can be manipulated for malicious goals. The above example
demonstrates that for cyber-physical systems in which sensor
feedback is used only to inﬂuence the behavior of application
layer software, the degree to which sensor-based vulnerabil-

Fig. 4: (a) In-band signal injection attacks. The injected signal
manipulates the physical input with the same type of signals.
(b) Out-of-band signal injection attacks. The injected signal is
outside the expected range of the sensor, and can be injected
before (targeting microphones, motion sensors, etc.) or after
(targeting PCB traces) the sensing mechanism.

v(t) by either injecting into (e.g., cast ultrasound on micro-
phone [75] [76] [77]) or bypassing the sensing mechanism
(e.g., inject EMI signal into leads of ECG [78], attack voice
control systems by injecting EMI into power socket [79], etc.)

A. Threat Model

This section will develop a generalized attack model for
signal injection attacks. Speciﬁcally, we summarize the re-
quirements of the attackers, describe the attack vectors, and
present attack impacts based on sensor feedback.

1) Attack Requirements: Attack requirements are the crite-
ria that must be met for the attack to be effective. We propose
two general requirements for signal injection attacks:

• Plausible input: This requires the maliciously crafted
signals to be effectively received by the system. For
example, for in-band attacks, this requires the attacking
signals are measured by sensors as valid input; while for
out-of-band attacks, the injected signals are required to
induce effects on various unintended receivers.

• Meaningful response: This requires the injected signals
to be reﬂected in the behaviors of the system. Ultimately,
the goal of the attacker is to attack the system in a
meaningful way, so simply causing changes in the sensor
mechanism is not an attack, unless the sensor output in
some way dictates the overall behavior of the system.
For instance, casting weak light on the camera will be
received as plausible input by the CPS, but will not affect
the system behavior; contrarily, casting a strong light on
a camera will blind it and cause DoS to the target.

2) Attack Vector: In a signal injection attack, the attack
vector is described by the frequency characteristics of the
signal (in-band or out-of-band) and the type of signal. Ex-
isting work primarily focuses on three categories: acoustic,

ities pose a threat highly depends on the software’s purpose
and core functionality.

• Malicious code execution: For cyber-physical systems
that use sensor feedback to control application layer
software, an attacker can inject signals into the sen-
sor to trigger the execution of privileged or malicious
code. For example, researchers have demonstrated the
ability to inject inaudible speech into the microphones
of voice-controlled systems [85] [86] [87], which allows
an attacker to bypass permissions and run a variety of
applications on the system.

• Misleading system operators: In some human-in-the-
loop CPS, sensor feedback is presented via applications to
inform a human operator of the system’s state. By inject-
ing signals to cause false sensor readings, the attacker can
mislead the operator, imposing a false perception of the
system’s state. Typical examples include GPS spooﬁng
attacks against aircraft [88] [89], train [90], and ship
[90] [91] navigation applications, where the drivers are
misled and therefore make false driving operations.

B. Techniques for In-Band Signal Injection

In-band signal injection attacks aim to induce malicious
effects within CPS by transmitting signals at the intended
range (often frequency) of receivers. The implementation of
an in-band signal injection attack depends on the sensor being
attacked. More speciﬁcally, the attack methodology differs
depending on if the target sensor is passive or active.

1) Targeting Passive Sensors: Attacking passive sensors
using in-band signals is often less challenging depending on
the threat model and attack goal. For example, an attacker can
utilize bright light to blind camera [92] [93], or cast an intense
infrared ray to saturate an infrared sensor [94].

2) Targeting Active Sensors: Signal injection attacks tar-
geting active sensors are less trivial compared to passive
sensors, since different active sensing technologies adopt
different methods for transmitting, receiving, and processing
the probing signals. Many active sensing systems such as
LiDAR or ultrasound-based sensing leverage feedback from
echoes/reﬂections for perception. Since the speed of these
transmitted waves is known, the time difference between the
transmitted and reﬂected signals reveals the distance between
the transmitter and the object from which the received signal
is reﬂected. An attacker can create or replay reﬂected signals
from different distances and angles to fool the receiver side
of active sensors. More speciﬁcally, the attacker can transmit
pulses using a generator to cause fake echoes, thereby mislead-
ing object recognition systems to detect objects located at the
wrong place [93] or even detect objects that do not exist [82].

C. Techniques for Out-of-Band Signal Injection

Since out-of-band signals are outside of the normal operat-
ing range of the sensor, the attackers ﬁrst need to guarantee
the plausible input requirement, i.e. the injected signals must
survive the signal conditioning paths to be considered valid. To
achieve this, there must be some components in the system that
act as an unintended receiver whose imperfect design helps to

8

capture out-of-band signals; as well as a down-converter that
converts the out-of-band signal into in-band, so that it will be
considered by the system as plausible input.

The next challenge for the attacker is to meet the meaningful
response requirement. The approach taken to address this
challenge depends on the goal of the adversary. If their goal
is to simply disrupt the sensor readings by adding noise, most
of the existing works make use of an unintended receiver and
a down-converting component to inject a simple constant out-
of-band signal [80] [95] [96] [97]. In this scenario, the attacker
does not need strong control over the shape of the down-
converted signal, as long as the injected noise is crafted to
be “effective” in terms of sufﬁcient intensity or strength so as
to incite a meaningful response from the system.

On the other hand, if the attack goal is to inject a precise
waveform into the sensing system to incite a speciﬁc response
from the system,
the down-converted signal must closely
resemble a sensor output that is known to trigger some desired
behavior in the system [75] [98] [99] [100]. Thus, the injected
out-of-band signal must be shaped such that when it is down-
converted, it is transformed into the attacker’s desired sensor
output. This is generally achieved by using an out-of-band
signal as the carrier wave, with the intended sensor output
modulated over it. In this case, the down-conversion process is
better deﬁned as demodulation; a demodulator not only down-
converts the injected signal into in-band, but also recovers
the modulated intended sensor output signal. In the type of
attack where the adversary’s goal is to precisely control the
sensor output, this general approach is used by all existing
literature. Thus, the goal of this section is to consolidate the
approaches in this existing literature into a single, generalized
mathematical model for sensor spooﬁng attacks.

The remainder of this section will be organized as follows:
Section IV-C1 will propose and describe a general system
model for out-of-band signal injection attacks, and Section
IV-C2 will describe and technically characterize the various
components in the sensor’s signal conditioning path that can
act as down-converters/demodulators.

1) System Model for Out-of-Band Signal Injection: The
goal of the model is to mathematically characterize the sys-
tem’s response to injected out-of-band signals. It is based on
the model proposed in [13], but adapts its characterization
of each component’s transfer characteristic. Each component
corresponds to a component in a sensor’s signal conditioning
path, and responds to the attacker’s injected signal in a certain
way. Overall, the model consists of six main components: (1)
modulated signal to be transmitted and injected, (2) transmit-
ted signal will suffer signal attenuation, (3) transmitted signal
will be picked up by unintended receiver, and processed by
(4) ampliﬁer, (5) low-pass ﬁlter, and (6) ideal ADC.

Modulated Signal: The transmitted signal, a(t), consists
of the attacker’s intended sensor output signal, m(t), multi-
plied by an out-of-band carrier wave with frequency fc. This
represents an amplitude modulated waveform formulated as:

a(t) = (1 + m(t))Acsin(2πfct + φ).

(1)

The reason why the injected signal should be modulated for

a successfully attack will be discussed in detail below.

Signal Attenuation: In transit to the target system, the
malicious signal is attenuated by several factors that mitigate
the signal, which are integrated into and denoted as Ad. The
speciﬁc value of Ad is a function of the transmitted signal
affected by multiple factors including the physical properties
of the surrounding environment, the distance of the attacker
from the target system, etc. Therefore, the attacker has to ﬁgure
out the conﬁguration which minimizes the signal attenuation.
Unintended Receiver: The signal is then received by the
unintended receiver of the system, which is described by
its transfer function, HU R(s). It
in the
cyber-physical layer that acts as a receiver for out-of-band
signals. In the existing literature, there are three main types of
components that act as unintended receivers.

is the component

• Microphones with acoustic signals: Although micro-
phones are meant
to sense audio signals audible to
humans, they are also sensitive to higher frequency audio
signals in the ultrasonic range due to non-linearity. This
allows attackers to inject out-of-band acoustic signals in
the ultrasonic band [75] [84] [76] [77].

• MEMS sensors and HDDs with acoustic signals: MEMS
accelerometers and gyroscopes [81] [95] [98], as well as
the read/write heads of hard-disk drives (HDDs) [96], are
shown to be sensitive to acoustic signals at their natural
frequencies. These frequencies, also known as resonant
frequencies, are speciﬁc to the sensor. Once an attacker
has determined this frequency for a speciﬁc sensor, they
can play audio signals at this frequency, injecting a sensor
output that oscillates at this resonant frequency.

• PCB traces with electromagnetic interference: The PCB
traces connecting sensors to the processor have been
shown to act as unintended low gain, low power antennas,
making them vulnerable to intentional electromagnetic
interference [78]. These PCB traces also exhibit reso-
nance at certain high frequencies, the speciﬁc frequency
depending on the length of the trace. Though it is possible
to inject
in-band electromagnetic interference, signals
with non-resonant frequencies will be highly attenuated.
Therefore, in order to achieve effective attacks, the in-
jected signals must be out-of-band at resonant frequen-
cies. As such, an attacker can inject electromagnetic
signals at one such frequency, resulting in an induced
oscillating voltage signal at the output of the sensor.

In general,

the magnitude of the unintended receiver’s
frequency response, |HU R(jω)|, can be described as a band-
pass ﬁlter with a low frequency bound, fL, and a high
frequency bound, fH . Signals outside of this frequency range
are signiﬁcantly attenuated. Thus, the frequency of a(t) must
be within this range for it to be received by the system. To this
end, the injected signal must be modulated in order to pass
the band-pass ﬁlter and therefore make the attack successful.
For example, in an electromagnetic interference attack, the
wires connecting the sensors with the ADC act as unintentional
receivers and pick up signals with low gain. The frequencies
that can be effectively received are related to the inverse of
the wire length, while signals of other frequencies will be
tremendously attenuated [101]. As the resonant frequencies of

9

short wires are in the GHz range, the injected signal m(t) has
to be modulated over a high-frequency carrier wave. Then the
unintended receiver transforms the attenuated attacker signal,
ˆa(t), into an analog voltage signal, v(t).

Analog-to-Digital Converter: The analog-to-digital con-
verter is a core component in the digitization process that
converts analog signals to digital. Systems with sensors gen-
erally contain one or more ADCs, and some ADCs are
even directly integrated into the sensor chip. Although ADCs
differ from each other according to their types, each ADC
mainly consists of three basic components: (1) the track-and-
hold circuit, which is also called a sample-and-hold circuit
that conducts the sampling and holds the sampled signal for
digitization; (2) the analog-to-digital converter that transfers
signals from the analog to digital realm; and (3) the level-
comparison mechanism [102]. These three components show
different features within signal conditioning path: the sample-
and-hold circuit acts as a low-pass ﬁlter;
the ideal ADC
simply implements analog-digital conversion; and the level-
comparison mechanism functions as an ampliﬁer. Based on
their different functionalities, we model and demonstrate them
separately as independent system counterparts.

Ampliﬁer: As previously mentioned, the level-comparison
mechanism within an ADC serves as a non-linear ampliﬁer
that induces DC offsets. Besides, ampliﬁers widely exist in
most signal conditioning processes outside ADCs. The ampli-
ﬁer can be characterized by its gain, denoted by G(x). Ideally,
the ampliﬁer multiplies its input signal by a constant factor A,
meaning G(v(t)) = A · v(t). But in reality, ampliﬁers are non-
linear, and can be more accurately characterized as having a
second-order response [78] [103] [104], denoted in Eq. (2) as:

G(v(t)) = Av(t) + Bv2(t),

(2)

where A and B are the coefﬁcients that describe the degree
to which the ampliﬁer exhibits non-linear behavior, and can
depend on factors such as the frequency and magnitude of the
input signal. In this paper, a constant called the non-linearity
factor is proposed, which is denoted by α = B
A , and describes
the degree to which the ampliﬁer’s non-linear characteristic
affects its overall response under speciﬁc input conditions.

Low-Pass Filter: As mentioned before, the sample-and-
hold circuit within ADC can be modeled as a low-pass ﬁlter,
which also exists outside the ADC and constitutes various sen-
sors such as microphone and camera. It can be characterized
by a transfer function HLP (s). The most important parameter
of the low-pass ﬁlter is its cutoff frequency, denoted by fcut.
Frequencies above fcut will be highly attenuated by the ﬁlter.
Ideal ADC: The ideal ADC digitizes the induced analog
signal by sampling it at a certain frequency, which is often
done in a sample-and-hold circuit, and then converts each
sample to an N -bit number. The value of N is known as the
resolution of the ADC. The ADC is thus characterized by its
sampling frequency, denoted by Fs, and its resolution N .

2) Demodulate Out-of-Band Signals: Consider an attacker
whose goal is to induce a speciﬁc in-band voltage signal, m(t)
at the sensor’s output. As previously mentioned, this desired
in-band signal must be modulated over an out-of-band carrier,

so that the unintended receiver can respond to the injected
signal, which is then demodulated by some component in the
system to recover m(t). The speciﬁc form of the attacker’s
modulated injected waveform depends on the component in
the circuit that is used as the demodulator. In general, the two
components that can act as demodulators are the ampliﬁer and
the analog-to-digital converter.

ADCs as Demodulators: In [13], Giechaskiel et al. conduct
extensive experiments to demonstrate that all major ADCs can
demodulate amplitude-modulated (AM) signals. Assume that
the injected signal successfully passes the unintended receiver
which is modeled as a band-pass ﬁlter, in order for the attack
to succeed, the attacker-desired signal m(t) must be recovered
by the ADC when v(t) passes through it. For the sake of
simplicity, suppose that the attacker’s goal is for the sensor’s
readings to be a constant DC value, so they choose m(t) =
M . When this signal passes through the ADC, the ADC will
sample the signal at a sample rate Fs, resulting in a sampled
..., ti = i
signal with samples at t0 = 0, t1 = 1
.
Fs
Fs
Suppose the attacker chooses the carrier frequency fc to be
an integer multiple of the sampling frequency, Fs, such that
fc = n · Fs, where n is some positive integer. Then the output
of ADC can be expressed as:

, t2 = 2
Fs

V [i] = KM sin(2πni + φ),

i ∈ Z+

(3)

where K is a parameter integrating the effects of attenuation
and the band-pass ﬁlter.

Therefore, when the carrier frequency is chosen to be a
multiple of sampling frequency, the samples fall on every n’th
peak of the modulated injected signal, causing the ADC to act
as an envelope detector, effectively demodulating the signal.
As long as the ADC sampling frequency, Fs, is constant, any
m(t) can be effectively demodulated by the ADC.

This effect

is known as signal aliasing, and is caused
by under-sampling the analog signal. The Nyquist sampling
theorem states that in order to effectively recover the shape
of an analog signal by sampling, the sample rate must be at
least twice the largest frequency component of the input signal;
if this requirement is unsatisﬁed, the digitized signal will be
aliased. In signal injection attacks where the ADC is used as
a demodulator, the attacker intentionally causes the injected
signal to be aliased to directly control the sensor readings.

Therefore, there are two general requirements for an attacker
to effectively use the ADC to demodulate their injected signal:
(1) The sample rate of the ADC, Fs, is time-invariant
(2) The carrier frequency fc satisﬁes fc (cid:29) Fs and fL ≤

fc ≤ fH

The second requirement essentially states that the attacker
must be able to ﬁnd some out-of-band carrier frequency that is
a multiple of the ADC sample rate, which still resides within
the frequency response of the unintended receiver.

Ampliﬁers as Demodulators: The non-linear characteristic
of ampliﬁers described by Eq. (2) can allow the ampliﬁer to
demodulate the attacker’s signal. Suppose the injected signal
takes a similar form to the one shown in Eq. (1), while the at-
tacker’s intended sensor output signal is m(t) = sin(2πfmt).
The Fourier transform of this attack signal contains a single
spectral component at the carrier frequency, fc. Plugging Eq.

10

Fig. 5: Simulation results of demodulating out-of-band signals.
(a) The attacker’s injected signal a(t) and its spectrum; (b)
spectrum post-ampliﬁcation; (c) recovered m(t) post LPF and
its spectrum.

(1) into Eq. (2) describes the ampliﬁer’s response to this
speciﬁc input signal. Taking the Fourier transform of the
resulting output signal results in a spectral component at the
in-band frequency, fm, a spectral component at the carrier
frequency, fc, spectral components at
integer multiples of
these two frequencies (harmonics), and spectral components at
intermodulation products of these two frequencies. Thus, after
the signal passes through the non-linear ampliﬁer, its spectrum
contains the frequency components of the attacker’s intended
sensor output signal. Once the output of the ampliﬁer is low-
pass ﬁltered, frequency components above fm will be highly
attenuated, resulting in a spectrum effectively only containing
a component at fm. Thus, the non-linearity of ampliﬁers can
demodulate the attacker’s injected signal.

This is shown in Fig. 5, for which an LTSpice schematic is
used to simulate this model. In the model, a sine-wave voltage
source is used, with fm = 200Hz and fc = 20kHz. The non-
linear ampliﬁer is implemented using an arbitrary behavioral
voltage source, which transforms the input voltage using Eq.
(2), with A = 10 and B = 1. This signal is then fed into an
RC low-pass ﬁlter with a cutoff frequency of 250Hz. The Fast-
Fourier transform (FFT) is applied to the signals that before
the ampliﬁcation stage; after the ampliﬁcation stage and before
the low-pass ﬁlter; and after the low-pass ﬁlter. The resulting
frequency spectra shows the demodulating properties of non-
linear ampliﬁers when the input is judiciously modulated as
illustrated above. Note that a ﬁrst-order RC low-pass ﬁlter is
used, so the harmonics and carrier frequency components still
remain post-ﬁltering, but are highly attenuated. In real systems,
a more complex, higher-order low-pass ﬁlter is likely used,
resulting in more signiﬁcant attenuation of the harmonics and
carrier frequency components.

Another important consideration is the aforementioned non-
linearity factor of the ampliﬁer, α. As this factor approaches
larger values, the non-linear characteristics of the ampliﬁer

are increasingly dominant, and the in-band signal m(t) will
be more effectively recovered.

Based on the above results,

there are two general re-
quirements for an attacker to effectively use an ampliﬁer to
demodulate their injected signal:

(1) The non-linearity factor, α, must be sufﬁciently large to

demodulate the attacker’s injected signal.

(2) The cutoff frequency of the low-pass ﬁlter, fcut, must be
low enough to sufﬁciently attenuate frequency components at
fc, and high enough to not attenuate the important frequency
components of m(t).

If the above requirements are met, m(t) can be successfully

recovered by an ampliﬁer in the signal conditioning path.

D. Signal Injection Attacks: Known Attacks

This section will provide a survey of the existing literature
of signal injection attacks on the sensors of cyber-physical
injection
systems. Here we summarize the existing signal
work in Table II, which are discussed in more detail in the
following. Section IV-D1 will give an overview of existing in-
band signal injection attacks, while Section IV-D2 will provide
an overview of existing out-of-band signal injection attacks.

1) In-Band Attacks: By injecting in-band signals, an at-
tacker can perform either sensor spooﬁng or denial of service
attacks. The attacker can inject optical, electromagnetic, or
acoustic signals to attack the camera, radar, MEMS motion
sensor, ultrasonic sensor, LiDAR, GPS, infrared sensor, mi-
crophone, or magnetic sensor of cyber-physical systems.

a) Electromagnetic Attacks: To meet the plausible input
requirement, the attacker must have knowledge of the com-
munication protocol used, or the control logic that translates
sensor readings into meaningful inferences about the system’s
surrounding environment. Thus, electromagnetic spooﬁng at-
tacks tend to be either gray-box or white-box attacks.

Furthermore, utilizing injected electromagnetic signals to
induce denial of service is generally referred to as signal
jamming attacks. To perform a jamming attack, the adversary
must generate an attack signal a(t) that is signiﬁcantly larger
than the voltage v(t) generated by the sensed physical signal
s(t). The only necessary prior knowledge for the attacker is
the operating frequency range of the sensor; thus, jamming
attacks are generally black-box or gray-box attacks.

Radar as Target: A radar transmits radio waves and
analyzes the reﬂected waves to infer details about the distance,
velocity, and orientation of surrounding objects. One of the
demonstrated attacks is conducted on the millimeter-wave
(MMW) radar of an automobile [93], where the primary
function of the radar is for collision avoidance and pedestrian
and cyclist detection [119]. Due to the lack of protection,
an attacker can analyze the emitted radar signal to spoof
legitimate reﬂections. As a result, they are able to cause the
radar to report false distances to objects in its trajectory.

Magnetic Sensor as Target: In [105], Shoukry et al. use
electromagnetic actuators placed in the wheel of a car to
inject signals into magnetic ﬁeld sensors for anti-lock braking
systems (ABS). They perform two types of attacks, one that
is simply disruptive to the system and unreﬁned, and another

11

Fig. 6: Two typical ways to spoof GPS signals: (a) use a
signal simulator to generate legitimate spooﬁng signals [115];
(b) build a portable GPS receiver-spoofer to receive legitimate
signals and manipulate the parameters [83] [112].

that spoofs magnetic signals such that a false wheel rotation
speed is detected, leading to life-threatening situations.

GPS as Target: The GPS receivers of GPS-based navi-
gation systems have been shown to be vulnerable to spooﬁng
attacks. The protocol for the communication of GPS signals is
highly complex, and relies on speciﬁc timing and position data
related to the orbital motion of multiple transmitting satellites.
Given the complexity of GPS communication, an attacker
can take two approaches to effectively spoof legitimate GPS
signals as shown in Fig. 6. The ﬁrst approach shown in
Fig. 6(a), as demonstrated in [115], uses a commercially
available GPS signal simulator to generate legitimate GPS
signals. The simulator’s output is connected to a transmitting
antenna, which transmits the spoofed signal to the victim’s
GPS receiver. In [115], this technique is used to relay a false
location to a truck’s external tracking system, demonstrating
that an attacker could stealthily steal a vehicle without alerting
the operators of the tracking system. The main drawback of
using a GPS signal simulator is its cost; the simulator can only
be rented for around $1000/week. Zeng et al. [108] build a
cheaper spoofer with a cost at $223 that could cause the driver
to reroute to a different destination without realizing it. Using
a portable GPS spoofer and the algorithm they developed, they
show that it is possible to give fake turn-by-turn directions to
drivers navigating using GPS.

The second approach shown in Fig. 6(b) is to build a
portable receiver-spoofer, as proposed in [112]. This device
consists of a receiver to receive legitimate GPS signals, a
software layer to modify parameters of the received signal,
and a transmitter to transmit the spoofed signal. In [83] and
[120], this technique is used to spoof the position estimation
systems of UAV drones and the navigation system of a yacht.
Speciﬁcly, Kerns et al. [83] demonstrate that GPS receivers
of UAV drones can be spoofed, causing them to measure an
attacker-speciﬁed location estimate. This can allow the attacker
to exhibit motion control over the UAV and alter its course. In
[120], GPS spooﬁng is used to alter the trajectory of a large
yacht, and thus gaining full control over its navigation system.
EM DoS Attacks: GPS receivers are shown to be vulner-
able to jamming attacks [121] [122] [123]. In cyber-physical
systems, GPS works by decoding signals broadcast by multiple
satellites orbiting the Earth. Due to their large distance from

TABLE II: Summary of Existing Signal Injection Attacks

12

Target

Attack Type(s)
ID IS OD OS
(cid:88)

(cid:88)

Vector(s)

Detectable

Stealth

Distance

Ref

(cid:88)

(cid:88)

(cid:88)
(cid:88)

n
O

(cid:88)
(cid:88)
(cid:88)

Sensor
MEMS Acc, Gyro
Mag

(cid:88) (cid:88)
UlS, Radar, Camera nO☼ (cid:88) (cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

System
Actuation System
Anti-lock Braking
Autonomous Vehicle
Autonomous Vehicle
Autonomous Vehicle
Autonomous Vehicle
Car Navigation
Control System
Drones
Face Recognition
Face Recognition
Face Recognition
HDD
Headset, ECG, CIED
Kalman Filter System
Medical Infusion Pump
(Not Speciﬁed)
(Not Speciﬁed)
Object Detector
Object Recognition
Smartphone
Truck
UAVs
UAVs
Voice Control
Voice Control
Voice Control
Voice Control
Voice Control
Voice Control
Voice Control
Voice Control
Voice Control
Voice Control
ID: In-Band DoS; IS = In-Band Spooﬁng; OD = Out-of-band DoS; OS = Out-of-Band Spooﬁng; Acc = Accelerometer; Gyro =

Camera, LiDAR
LiDAR
LiDAR
GPS
Temperature Sensor
MEMS Gyro
Camera
Camera
Camera
Read/write head
Analog Sensors
Acc, Gyro, Mag
Infrared Sensor
GPS
Microphone
Camera
Camera
MEMS Acc
GPS
Camera
GPS
Microphone
Microphone
Microphone
Microphone
Microphone
Microphone
Microphone
Microphone
Microphone
Microphone

0.1-7.8m
-
10m
2m
12m
-
40-50m
0.25-16.2m
10cm
-
-
35cm
15cm
0.68-1.57m
-
12m
-
1.5m
25m
5-40ft
10cm
30ft
4-10ft
620m
0.5-1.5m
30cm
6m
-
4m
4-175cm
7.62m
3m
110m
30ft

[95]
[105]
[93]
[92]
[106]
[107]
[108]
[100]
[80]
[109]
[110]
[111]
[96]
[78]
[98]
[94]
[112]
[97]
[113]
[114]
[81]
[115]
[82]
[83]
[86]
[85]
[116]
[87]
[99]
[75][77]
[76]
[117]
[118]
[84]

Ag
A g
A×
Ag
A×
Ag
A ×
A ×
Ag
A ×
A g
A g
Ag
A ×
Ag
A×
A ×
A ×
A g
A g
A g
A ×
Ag
A ×
A g
A g
A g
A g
A×
A×
A×
A g
Ag
A×

☼
☼
☼
O
O
n
☼
☼
☼
n
O
nO
☼
O
n
☼
☼
n
O
☼
O
n
n
n
n
O
n
n
n
☼
n

(cid:88)
(cid:88) (cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

Gyroscope; UlS = Ultrasonic Sensor; Aco = Acoustic; Opt = Optical; Mag = Magnetometer;

= less stealthy;

= partially stealthy;

= stealthy; n= Acoustic; O= Electromagnetic; ☼= Optical; A= sensor detectable; A = maybe sensor detectable;
g = maybe human detectable; g= human detectable; × = not detectable;

the Earth’s surface, GPS signals suffer a transmission loss of
152dbW to 163dbW [89]. Thus, an attacker’s local jamming
signal can easily overpower the strength of legitimate signals
transmitted by the satellites. For this reason, GPS jamming
attacks represent a serious threat; simple jammers can be
bought for less than $10, and can signiﬁcantly interfere with
receivers up to a radius of 300 meters from the jamming
device [124]. Generally, these low-cost GPS jammers are used
by individuals to mislead system operators by hiding their
whereabouts from tracking systems [124]. The intention of
the attacker can be relatively harmless, such as avoiding tolls
or hiding their whereabouts from their employers’ tracking
systems. However, it can also have more severe consequences
on critical infrastructure, such as aircraft [88] [89], train [90],
and ship [90] [91] navigation systems.

Radar sensors of autonomous vehicles are targeted for
jamming attacks as well. Yan et al. [93] conduct signal jam-
ming attacks against the MMW radar sensors of autonomous
vehicles. While being jammed, the radar receiver is completely
blinded and reports no objects in its surrounding environment.

Lessons learned: The majority of existing in-band
EM attacks target on GPS. Since GPS signals can
be easy to jam, DoS often doesn’t require expensive
equipment. The signals transmitted in the air also do
not provide any authentication service, thus they can
be easily spoofed. An important future direction of
research is the defense against GPS signal spooﬁng.

b) Optical Attacks: Existing work shows that optical
sensors including cameras, LiDAR, and infrared sensors are

vulnerable to spooﬁng attacks.

Infrared Sensor as Target: Park et al. [94] demonstrate
that the infrared drop sensor in medical infusion pumps can be
exploited by performing spooﬁng attacks. They observe from
analyzing the ﬁrmware of the device that drops are detected
by falling edges in the readings of the infrared receiver.
Thus, by saturating the receiver sensor with the infrared laser,
then periodically turning off the laser, falling edges in the
intensity of the received IR radiation are detected, allowing
the researchers to spoof drops. This allows the attacker to
under-infuse the medicine by spooﬁng fake drops.

LiDAR as Target: LiDAR systems in autonomous vehicles
work by transmitting laser pulses and analyzing the reﬂected
pulses to infer the position and location to surrounding objects.
They are vulnerable to spooﬁng attacks [92] [106] [107] [125]
as well. Petit et al. [92] ﬁrst explore the LiDAR spooﬁng attack
by replaying the transmitted pulses from different locations
with a pulse generator, with which the attacker can generate
fake echoes and cause the receiver to detect real objects
as closer or further away than they actually are. They can
also use multiple attacking pulse generators to create multiple
fake objects at different distances that can be classiﬁed by
the control software as different objects, such as cars and
walls. Therefore, these attacks targeting LiDAR can be critical
because they can have a signiﬁcant impact on the autonomous
vehicle’s mission planning. Shin et al. [106] utilize a photodi-
ode, a delay component, and an infrared laser to capture the
victim’s laser pulses and craft fake point clouds with delay,
showing that the attacker is able to spoof a maximum of
10 dots in a horizontal line that appear even closer than the
spoofer. Following this work, Cao et al. [125] adopt a faster
emitting rate and a lens to focus the beam, and successfully
improve the performance by achieving around 100 spooﬁng
points in broader horizontal and vertical angles at a distance
larger than 10 meters. Furthermore,
they propose a new
adversarial machine learning methodology called Adv-LiDAR,
which constructs the input perturbation while taking the post-
processing process into consideration, and thus practically
spoof an obstacle within a range of 2-8 meters in front of the
Baidu Apollo. More recently, Tu et al. [107] attack LiDAR by
placing a well-designed 3D adversarial object on the roof of
the autonomous vehicle, and they are able to erase the whole
vehicle from LiDAR perception with a success rate of 80%.
Optical Flow Algorithm as Target: Spooﬁng attacks on
cameras mostly target the image processing algorithms that
are used to process the sensor data, such as optical ﬂow
algorithms, facial recognition, and object recognition. In [82],
Davidson et al. demonstrate that an adversary can gain control
over UAV drones by exploiting the optical ﬂow algorithm
used in the controller to prevent
the drone from drifting.
The optical ﬂow algorithm takes input from the camera, and
compares successive frames to detect if the UAV is drifting.
First, the algorithm detects features in the ground plane below
that are amenable for tracking using the Shi-Tomasi corner
detection algorithm [126]. Then, the Lucas-Kanade optical
ﬂow algorithm [127] calculates the deviation in the horizontal
position of the drone, (∆x, ∆y), using the previously cal-
culated features. The drone’s controller compensates for this

13

deviation by adjusting its horizontal position by (−∆x, −∆y).
Thus, by injecting optical signals that are interpreted by the
corner detection algorithm as features, the attacker can cause
the optical ﬂow algorithm to detect false changes in ground
plane features, which are interpreted as drifts in the drone’s
horizontal position. The researchers use laser grids projected
onto the ground plane in varying ground plane textures to
cause the detection of fake features. They then move this
projected image to cause the optical ﬂow algorithm to falsely
detect drifts in the drone’s horizontal position, causing the
controller to compensate by moving the drone in the opposite
direction. Therefore, by moving the projected ground plane
image, the attacker can obtain motion control over the drone.
Facial Recognition as Target: Some optical spooﬁng
attacks on cameras target machine learning algorithms used
for facial recognition. This is closely related to adversarial
machine learning [128], which focuses on the vulnerabilities
of machine learning algorithms. Sensor spooﬁng attacks on
cameras that target ML algorithms fall into the category of
after-training attacks using adversarial examples, which are
inputs crafted by adding small perturbations that cause an al-
ready trained ML model to misclassify [129]. In [109], Zhou et
al. demonstrate an attack in which infrared LEDs are stealthily
embedded into a hat, and are used to strategically project dots
onto the attacker’s face. By adjusting the sizes, intensities,
and positions of the dots, the attacker’s facial features are
altered so that the facial recognition algorithm misclassiﬁes
the attacker as another individual. This allows the attacker
to bypass facial recognition based authentication systems by
impersonating a target individual. Sharif et al. [110] also show
a similar attack using specially designed eyeglasses. They
propose an optimization problem, which ﬁnds the minimal
physically realizable perturbation to an individual’s face such
that the facial recognition model misclassiﬁes this individual
as another, speciﬁcally chosen individual. This perturbation
takes the form of an RGB pattern, which can be printed on a
pair of eyeglasses and worn by the attacker. By wearing these
eyeglasses, an attacker can impersonate another individual
with a high accuracy to trick the facial recognition algorithm.
A simpler, “replay attack” based approach is proposed in
[111], where a printed out image of a target individual is used
to bypass a facial recognition authentication system.

Object Recognition as Target: Some optical spooﬁng
attacks target object recognition algorithms. This can pose a
serious threat to cyber-physical systems such as autonomous
vehicles and unmanned aircraft, which apply machine learning
algorithms to optical sensor data for purposes such as object
recognition and airborne collision avoidance [130]. Eykholt et
al. [114] add small perturbations to a stop sign, which take
the form of black-and-white tape attached to the sign. By
arranging the tape in a speciﬁc pattern, they cause the object
recognition algorithm to misclassify the stop sign as a 45mph
speed limit sign. In [131], Dreossi et al. model the automatic
emergency braking system of an autonomous vehicle. The sys-
tem uses machine learning algorithms to classify objects in its
trajectory, and initiates an emergency brake when an object is
detected. They model this as a closed-loop system, and design
an algorithm that searches the input space of the classiﬁer

to ﬁnd sets of inputs that are misclassiﬁed. In [113], Zhao
et al. devise a new methodology for generating adversarial
examples to trick machine learning based object detectors.
They perform two types of attacks: a hiding attack where
the object is not recognized, and an appearing attack where
the object is classiﬁed incorrectly. For the hiding attack, they
use feature-interference reinforcement and enhanced realistic
constraints generation to improve attack performance, and in
the appearing attack they use a nested approach that takes long
and short distances into account separately and combines them.
Optical DoS Attacks: Existing optical DoS attacks have
focused on cameras, LiDAR, and infrared sensors. In [92]
and [93], the researchers perform DoS attacks on cameras
of autonomous vehicles by using bright LEDs to blind the
camera. By doing so, they can hide actual objects and fool
auto-controls. Petit et al. [92] also demonstrate a DoS attack
on the LiDAR sensor of an autonomous vehicle. By jamming
the receiver with laser pulses, it reports no surrounding objects.
Camera and LiDAR based optical attacks on autonomous
vehicles represent a signiﬁcant threat, since these sensors are
responsible for detecting objects and road signs, and thus are
critical for mission planning. Besides, infrared sensors are also
vulnerable to DoS optical attacks. In [94], a medical infusion
pump falls victim to an optical DoS attack using an infrared
laser. The infusion pump functions by counting drops, and an
IR transmitter and receiver are used to detect the drops by
measuring beam intensity. The attackers use an infrared laser
to drive the receiver into saturation, and therefore it is no
longer responsive to changes in infrared light, leading to false
reading of drops. This causes the infusion pump to over-infuse
the medicine, due to the perceived lack of drops.

Lessons learned: One main direction of in-band optical
spooﬁng attacks target facial and object recognition
systems. The attackers do not intentionally transmit
optical signals to the target CPS, but instead modify the
objects to be probed. The same opportunity might exist
for other signals, where the modiﬁcation of physical
objects could affect perceptions of machines only.

c) Acoustic Attacks: Existing in-band acoustic attacks
mainly focus on ultrasonic sensors in autonomous vehicles,
and microphones embedded in voice-controlled assistants.

Ultrasonic Proximity Sensor as Target: Yan et al. [93]
demonstrate a spooﬁng attack on the ultrasonic sensors. Ultra-
sonic sensors are used in autonomous vehicles as short-range
proximity sensors, and are generally used in parking assistance
and self-parking systems to detect nearby objects. They are
active sensors that require an ultrasonic transducer to transmit
ultrasonic signals and a receiver to receive the reﬂected waves.
In this attack, they are able to spoof reﬂected pulses in a
scenario where there are no actual objects in the detection
range, causing the ultrasonic receiver to detect and display
pseudo objects. The researchers also conduct an “acoustic
cancellation” attack, in which the spoofed reﬂected signals
are crafted in such a way that they destructively interfere with
the legitimate reﬂected pulses from nearby objects, causing
the system to fail to detect these objects.

14

Voice Assistant as Target: Fig. 7 depicts one major
direction within the ﬁeld of in-band acoustic attacks. The
attackers aim to inject perturbed voice commands that are
unintelligible to humans, but still understood by the speech
recognition algorithms used in cyber-physical systems. Most
of these attacks target voice-controlled assistants (VCAs), such
as Amazon Echo and Google Home [76] [86] [85] [117].

As shown in Fig. 7,

two types of techniques are gen-
erally adopted to conduct in-band inaudible attacks against
VCAs. The ﬁrst one shown in Fig. 7(a) is to maliciously
craft perturbed signals via a processing machine. Vaidya et
al. [85] demonstrate this technique, where the actual audio is
“mangled”, such that it is unintelligible to humans, but still
recognizable by the speech recognition algorithm. In order
to “mangle” the voice, they ﬁrst extract the Mel-Frequency
Cepstral Coefﬁcients (MFCC) [132], which are the features
commonly used to characterize human speech. They perform
transformations on the extracted MFCCs, such that the speech
recognition still correlates them with the original speech.
They then inverse the MFCC extraction process, obtaining an
audio signal that is “mangled” due to the transformed MFCC
coefﬁcients. This work takes a black-box approach, assuming
the adversary has no prior knowledge of the details of the
speech recognition algorithm.

In [87], Abdullah et al. attempt a black-box attack, by
focusing more on applying signal processing techniques to the
original signal to maintain its MFCC features, but still have
the resulting audio be highly unintelligible. To do so, they
propose four types of perturbation: (1) modify the time domain
signal, while maintaining the frequency domain spectrum; (2)
add random phase information to the phase spectrum that
still maintains the same magnitude spectrum; (3) add high-
frequency components to the signal that can overpower the
signal in the time domain, while the original signal’s frequency
component still remains in the spectrum; and (4) speed up
the audio. By combining these operations, they develop a
black-box attack against speech recognition systems where the
mangled audio is completely unintelligible to humans.

Carlini et al. [117] perform both black-box and white-box
attacks, again by maintaining MFCC features. They demon-
strate the feasibility of performing black-box attacks, and
additionally show that with more knowledge of the system
(white-box), functional audio commands that are not under-
standable to humans can be generated. To counter the pro-
posed attacks, the researchers also explore various defenses.
A passive notiﬁcation defense would alert the user when a
voice command is given, but is likely to be ignored by the
user. An active conﬁrmation defense would impact usability
of the system. However, machine learning algorithms could
be trained to recognize the difference between computer-
generated and human audio samples.

Most recently, Chen et al. [116] propose a similar attack,
again by perturbing acoustic signals, where they successfully
inject inaudible commands over-the-air into a speech recogni-
tion system. In their attack, a domain adaptation algorithm is
utilized to reﬁne the perturbation so as to improve the attack
distance and reliability.

While in [86], a different approach shown in Fig. 7(b) is

15

Fig. 7: Two typical ways to inject in-band signals into VCAs: (a) use a well-designed processing machine to generate a perturbed
signal, such as cutting the signal into pieces [85] or manipulating signal properties [87]; and (b) modulate the injected command
with a carrier wave such as music [86]. The crafted signal will then go through signal path consisting of: pre-processing that
conducts speech/non-speech segmentation, signal processing that extracts Mel-Frequency Cepstral Coefﬁcients (MFCC) [132]
features, and ﬁnally the extracted features are matched against pre-trained machine learning models for inference.

taken, where instead of generating a mangled speech signal
unintelligible to humans, Yuan et al. use music as a carrier
the
for the speech. By hiding voice commands in songs,
researchers demonstrate that it is possible to inject commands
into speech recognition systems, maintaining the integrity of
the original music such that surrounding individuals are not
alerted of the attack. The proposed attack is a white-box
attack, in which knowledge of the underlying voice recognition
system allows for mangled speech that is much less intelligible
to humans than in [85]. Since the attacker knows the details of
the speech recognition algorithm, the problem can be framed
as an optimization problem, which is solved using the gradient
descent algorithm [133]. The mangled speech generated using
this technique is fully effective against VCAs, while remaining
completely unintelligible to humans.

Acoustic DoS Attacks: In [93], Yan et al. demonstrate
an acoustic DoS attack on the ultrasonic sensors of an
autonomous vehicle. They show that by transmitting
ultrasonic signals at the operating frequency of the receiver,
the object detection system is blinded to nearby objects and
thus halting its operation.

Lessons learned: Many of the existing in-band acous-
tic attacks target voice-controlled systems, and have
attempted to hide malicious commands by perturbing
them while maintaining the MFCC features recognized
by algorithms. One possible direction for research in
this domain could be attacks where other features such
as the Linear Predictive Coefﬁcient (LPC) [134], Per-
ceptual Linear Predictive (PLP) [135], or the combi-
nation of these features are maintained to craft hidden
commands intelligible to CPS.

2) Out-of-Band Attacks: Existing literature has demon-
injection attacks using acoustic,
strated out-of-band signal
electromagnetic, and optical signals to attack microphones,
MEMS accelerometers, MEMS gyroscopes, temperature sen-
sors, and magnetic sensors of CPS. In the following, we will
discuss different types of out-of-band signal injection attacks
based on the exploited physical property.

a) Electromagnetic Attacks: As discussed in Section
IV-C1, attackers can inject out-of-band electromagnetic signals
by exploiting components in the cyber-physical layer circuitry
that act as unintentional low gain antennas. PCB traces in
the signal conditioning path are susceptible to intentional
electromagnetic interference (IEMI), but the speciﬁc range of
frequencies for which a PCB trace behaves as a receiving
antenna is highly system-dependent, and is determined by
factors such as the length of the trace and potential coupling
with other components in the circuit. Since these parameters
vary greatly across different systems, the resonant frequency
can be anywhere from the kHz to GHz range, so it is im-
practical for the attacker to simply sweep through all possible
frequencies. Thus, out-of-band signal injection attacks using
IEMI are always grey-box attacks, since the attacker must
disassemble the device in order to experimentally determine
the frequency response of the unintended receiving trace.

Medical Device as Target: In [78], Kune et al. demonstrate
a low-frequency IEMI attack on implantable medical devices
(IMD). This attack targets the leads of electrocardiograms
(ECGs) and cardiac implantable electrical devices (CIEDs).
ECGs are used to monitor cardiac activity by taking voltage
readings on the surface of the skin, while CIEDs are used
to monitor and regulate cardiac activity by sending small
electrical signals to the heart. By injecting IEMI into the leads
of these devices, they are able to spoof cardiac activity in the
case of ECGs (misleading system operators), and prevent and
deliver deﬁbrillator shocks in the case of CIEDs (physical
harm to humans). It is noteworthy that the leads are not
intended to be receivers for remotely transmitted EM signals,
thus the intentional receiving band for electromagnetic signals
can be considered as zero.

Temperature Sensor as Target: Tu et al. [100] show that
they can use EMI signals to inject spoofed readings into
various temperature sensors. In this attack, they are able to
manipulate temperature sensor readings by taking advantage of
the ampliﬁer without tampering with the system or triggering
any alarms related to abnormal temperatures. The attack is ex-
ecuted remotely, from up to 16.2 meters away. These spoofed
temperature sensor readings could have serious consequences
for temperature-sensitive systems, as they would be unable to

properly regulate the temperature without accurate readings.
Modulating With Resonant Frequency: As discussed in
Section IV-C1, if the attacker modulates the desired sensor
output, m(t), over the resonant frequency, it can potentially
be realized at the output of the sensor given there exists a
demodulating element in the circuit. Using this method, Kune
et al. [78] demonstrate a sensor spooﬁng attack on a vulnerable
Bluetooth headset. By amplitude modulating voice signals over
the resonant EM carrier, they are able to inject inaudible voice
commands into the headset’s microphone. In this attack, a
hypothetical victim uses the headset paired with a cell phone
to make a call to an automated dial-in system, which uses
the tones generated by the keypad button presses to infer the
button dialed. By injecting IEMI, they are able to generate
arbitrary tones, which are interpreted by the dial-in system as
their respective buttons being pressed. They also demonstrate
a session hijacking attack on a video chat session, in which
the Bluetooth headset is paired to the victim’s laptop. In this
attack, they are able to hijack the session by injecting voice
signals that are loud enough to overpower the victim’s voice.
A similar attack is demonstrated in [99], in which Kasmi et
al. ﬁnd that the microphone built into a pair of headphones is
vulnerable to sensor spooﬁng via IEMI. After experimentally
determining the resonant frequency of the trace connecting the
microphone to the microcontroller, they modulate voice signals
over this frequency, and transmit the resulting signal using an
antenna. The signal is injected into the trace, demodulated by
an audio ampliﬁer, and is realized at the output of the sensor as
a regular voice signal. It is demonstrated that this can be used
to inject voice commands into the voice-controlled assistants
on smartphones, such as Siri and Google Voice. This gives the
attacker control over various application layer software, which
can be used to perform tasks such as visiting websites, sending
text messages, making phone calls, etc. A main difference
between the methodologies of [78] and [99] is that in [99],
the unintentional receiver is external to the system (front-door
coupling), while in [78] the unintentional receiver is a PCB
trace internal to the system (back-door coupling).

Conducted IEMI: A recent electromagnetic signal injec-
tion attack [79] also targets voice-controlled systems, but uses
conducted IEMI. In a conducted attack, the attacker is on
the same power network as the target device, meaning that
the injected signal is transmitted via a wired connection. In
this wired connection is through a USB charger
practice,
or a power charger, and the attacker’s point of entry is
somewhere in the power network behind the power socket.
The researchers use a specially designed injection probe to
inject amplitude-modulated voice commands into the power
network, through which the injected signal eventually arrives
at the target device, where it is demodulated by the non-
linear ampliﬁer of the microphone circuit. This conducted
attack offers a few advantages over the transmitted attacks
demonstrated in [99] and [78]. First, since the attacker’s signal
is injected via a shared wired connection, the attenuation factor
Ad is much lower, meaning the power of the transmitted signal
can be much lower than in transmitted attacks. Second, in the
conducted attack, the bandwidth of the unintended receiver’s
frequency response is much wider, giving the attacker a much

16

Fig. 8: General model for out-of-band signal injection attacks
against microphones [75] [84] [76] [77]. Injected signals
(voice commands) are modulated with a high-frequency carrier
wave (e.g., ultrasound wave) and sent to the microphone. From
the victim side, the microphone as an unintended receiver
receives the modulated signal, the ampliﬁer serves as a demod-
ulator due to its non-linearity, and the low-pass ﬁlter removes
the ultrasound frequency. Therefore, the injected signal is able
to survive the signal conditioning path and induce effects.

wider range of frequencies for which the attack signal will not
be severely attenuated before reaching the target sensor.

EM DoS Attacks: EM waves can also be used for DoS
attacks. In [99], Kasmi et al. inject audio signals into the
microphones in Bluetooth headsets and webcams via IEMI,
by exploiting the fact that the PCB traces connecting the
microphone to the microcontroller are resonant to EMI at
frequencies in the MHz and GHz range. Induced voltages in
this frequency range are down-converted by the audio ampliﬁer
in the microphone circuit, and are manifested as low-frequency
noise at the output of the sensor. It is demonstrated that if the
induced oscillating voltage has a sufﬁciently large amplitude,
the resulting down-converted noise will be loud enough to
overpower legitimate audio inputs to the microphone. Thus,
the system taking input from the microphone cannot use it
reliably during the attack. A similar attack is proposed in
[78], where Kune et al. inject high power Weezer waveformed
EMI signals to overwhelm original acoustic signals without
causing distortion in the demodulated audio. As a result, they
successfully block a Skype session without being detected.

Lessons learned: Existing work has demonstrated the
feasibility of injecting out-of-band EM signals into
various applications. Many of them modulate signals
onto a carrier wave of unintended range, yet there is
less attention given to the impact of different signal
modulation techniques on the success of the attack.
Therefore, it would be an important area to investi-
gate and understand the potential impact of different
techniques.

b) Acoustic Attacks: Existing out-of-band acoustic at-
tacks either target microphones that are sensitive to ultrasound,
or MEMS accelerometers, gyroscopes, and HDDs that are sen-
sitive to acoustic signals due to resonance in their mechanical
structures.

Microphone as Target: Sensor spooﬁng attacks using
acoustic signals have been demonstrated on microphones, as
shown in Fig. 8. In the dolphin attack proposed in [75], the
voice signals that are amplitude-modulated over ultrasonic
carriers can be demodulated by the ampliﬁers connected to

smartphone microphones. Therefore, the researchers show that
using this method, inaudible voice commands can be injected
into voice-controlled assistants, such as Siri and Google Voice,
using ultrasonic transducers. Following this work, Roy et al.
[76] demonstrate that it is possible to increase the attack range
of ultrasonic signal injection on microphones. Due to non-
linearities in the speakers, the injected signal can only be
ampliﬁed to a certain extent before these non-linearities start
causing sound leakage at the transmitter side. To remedy this
issue, the researchers show that by splitting the intended voice
command’s frequency spectrum into N separate “bins”, mod-
ulating the contents of each bin over its own ultrasonic carrier,
and playing each one of these modulated signals through
a separate ultrasonic speaker, the attacker can signiﬁcantly
increase the range of the signal injection attack without any
sound leakage at the transmitter. In [77], the same researchers
from [75] propose an improvement to their attack, increasing
the attack range to 1.75m by using an ultrasonic transducer
array consisting of 40 speakers. Using this technique, they are
able to increase the attack distance signiﬁcantly, making long
range attacks on VCA feasible.

The surﬁng attack proposed by Yan et al. [84] takes a
different perspective. Instead of transmitting hidden commands
in the air, they perform attacks on smartphone voice recogni-
tion systems using ultrasonic waves transmitted through solid
materials and surfaces. This attack is inaudible to humans, and
they further explore attacks that interact with the target systems
for multiple rounds, performing attacks like making fraudulent
phone calls and stealing SMS passcode information without
alerting the user. The attack is successful on some surfaces
with a distance of 30 ft between the attacker’s emitter and the
target smartphone.

Motion Sensor as Target: Following the work of [80],
which demonstrates DoS attacks on the MEMS gyroscope
sensor on a drone, Trippel et al. [81] ﬁnd a similar acous-
tic vulnerability in MEMS accelerometers, which are also
resonant to acoustic noise at certain frequencies, often less
than 10kHz. By amplitude-modulating their desired sensor
output over the resonant carrier wave, and using the ADC as a
demodulator, the researchers show that they can inject arbitrary
signals into the output of the sensor; though, due to drifts in
the sample rate of the ADC, the attack can only be carried out
for a few seconds. This attack is conducted on a smartphone
app that uses the accelerometer to determine the motion of an
RC car, for which the attacker is able to gain motion control
of the car. This attack is also used to register fake steps into a
FitBit; due to FitBit’s rewards program, an attacker could use
this attack for ﬁnancial gain. In [95], Tu et al. build on the
previous work, and propose attacks on MEMS gyroscopes and
accelerometers. It shows that the problem of a drifting sample
rate can be partially remedied by changing the frequency of
the injected signal slightly in response to sample rate drifts,
which results in an effective phase change in the digitized
sensor output. This allows the attacker to carry out the attack
for a longer duration. They implement this attack on numerous
gyroscope-equipped systems, such as human transporters, self-
balancing robots, camera stabilizers, anti-tremor devices, 3D
mouses, and VR headsets.

17

Acoustic DoS Attacks: Acoustic signals are also used
for DoS attacks. The ﬁrst paper to demonstrate that MEMS
structures can be exploited with acoustic interference is [80],
which targets the MEMS gyroscope sensors on drones. The
researchers show that MEMS gyroscopes are resonant
to
acoustic signals at frequencies generally in the ultrasound
range (more than 20kHz). By using ultrasonic transducers
to inject signals at these frequencies, an oscillating voltage
appears at the output of the sensing mechanism. These signals
are demodulated by the ampliﬁer in the signal conditioning
path, resulting in high amplitude noise in the digitized signal.
In drones that use the feedback from the gyroscope system
in a closed-loop fashion, this noise can cause the drone to
crash. This attack is demonstrated on a drone constructed
by the researchers, which uses a PID (proportional-integral-
derivative) controller to achieve motion control. When subject
to acoustic noise at the gyroscope’s resonant frequency, the
drone crashes. In [96], Shahrad et al. show that the read/write
heads of HDDs are also resonant at certain acoustic frequen-
cies, and an attacker can inject acoustic signals into a HDD to
cause faults. These faults can lead to interruption of the process
of reads and writes. The attack is conducted on a CCTV
DVR security camera system, for which the attack results
in permanent data loss due to a memory buffer overﬂow.
The researchers also test the attack on a PC with different
operating systems, for which the attack causes a system reboot
in the case of Windows or a fully unresponsive OS in the
case of Linux-based distros. In [97], Roy et al. propose a DoS
attack that exploits ampliﬁer non-linearity to inject out-of-band
ultrasonic signals into microphones. By modulating in-band
sound noise over ultrasonic frequencies, they generate an in-
band “shadow” of the original modulated signal. They show
that this noise can serve as a jamming mechanism against
unwanted eavesdroppers.

Tu et al. [95] also show practical attacks to implicitly control
or cause DoS across many different systems using MEMS
gyroscopes or accelerometers. They use a methodology similar
to previous research using acoustic signals. To improve attacks
and make them more practical, they use two output control
methods: digital amplitude adjusting and phase pacing. As a
result, the control systems are either deceived by the MEMS
sensor readings or rendered non-functional in a DoS attack.

Lessons learned: A major research direction within
out-of-band acoustic injection attacks is to use high-
frequency acoustic signals to induce vibration of mi-
croelectromechanical components in sensors. Most of
the attacks are demonstrated on motion sensors, but
this attack can be extended to other systems where
there are sensitive components. Furthermore, research-
ing into potential defenses is also important.

c) Optical Attacks: The ﬁeld of out-of-band optical
signal injection attacks is less explored until a recent study
named LightCommands proposed in [118], where Sugawara
et al. remotely inject inaudible and invisible commands into
voice-controlled systems using light. The proposed attack is
based on the photoacoustic effect, with the speciﬁc application

that MEMS microphones may respond to light signals as if
it is sound. To exploit this, the attacker ﬁrst modulates laser
light with an intentional audio signal, and then transmits it
by aiming the laser beam at microphone ports of the target
devices. The injected optical signals will be converted back
to the original audio signal inside the target system, which
will result in the voice-controlled system executing arbitrary
commands issued by the attackers. The main limitation of this
work lies in the lack of stealthiness and difﬁculty of precise
aiming: the laser beam is visible to humans or detectable to
devices, and aiming at the small aperture of the target system
with high precision is difﬁcult while it is stationary, let alone
for moving targets.

Lessons learned: Out-of-band optical injection attacks
are relatively less explored. However, light, which is
one of the most common energies and information
transmission carriers, still presents a large attack sur-
face for both injecting signals into light sensors of
different frequency ranges or other sensors that react
to light.

d) Attacking Sensor Fusion: Many systems in practice
leverage sensor fusion from multiple instruments to construct
their perception of the physical world, such as estimating
motion or orientation from both GPS and IMU. As a result,
while it is intellectually interesting to explore new avenues
to exploit individual sensors, it is often insufﬁcient to inject
signals into a single sensor, since the overall state estimation
is generally resilient to large variations in a single sensor. The
standard in-state estimation using sensor fusion is the Kalman
Filter [136], which estimates a target state of a system in
the presence of errors. For example, in open-source drone
software, such as Ardupilot [137] and Multiwii [138], the
Extended Kalman Filter is used for sensor fusion based state
estimation. Recently, Nashimoto et al. [98] attempt to over-
come sensor fusion in signal injection attacks. In this paper,
they target the Kalman Filter based sensor fusion algorithm
for measuring a system’s inclination, which is the degree
to which an object is inclined in a global reference frame.
This is an important algorithm, often used in motion tracking
and altitude control for robots and drones. It fuses data from
the accelerometer, gyroscope, and magnetometer to estimate
the system’s overall inclination. The paper demonstrates that
by performing spooﬁng attacks with both in-band (magnetic)
and out-of-band (acoustic) vectors on all three sensors in a
speciﬁc sequence, the attacker can defeat the sensor fusion
algorithm, and control the system’s estimation of inclination.
In [41], a similar work is carried out, in which the effect
of sensor spooﬁng attacks on closed-loop control systems is
explored. Mo et al. demonstrate that for linear time-invariant
Gaussian control systems equipped with Kalman Filters for
state estimation, corrupting a subset of sensor readings is
able to destabilize the system and bypass the failure detection
mechanism.

18

Lessons learned: Sensor fusion serves as an efﬁcient
way to improve CPS performance and raise the bar for
simple signal injection attacks. However, the existing
work shows that a well-designed injection input can
still corrupt the fusion algorithm and induce malicious
effects. Potential future research for defense could in-
clude developing more robust fusion algorithms, fusing
redundant sensors, optimizing sensors to be fused, etc.

E. Limitations and Opportunities

This section will systematically analyze the existing re-
search related to signal injection attacks, outlining the limi-
tations, identifying gaps in research, and suggesting potential
directions for future work.

Spooﬁng encrypted or obfuscated signals: Spooﬁng at-
tacks become more difﬁcult
in the case of encrypted or
hidden signals. Take GPS spooﬁng as an example, general
GPS spooﬁng attack techniques are challenged by military-
used GPS P(Y) [139] and hidden markers [140], which are
proposed to hide GPS signals in the noise level with secret
keys unknown to the attackers. To reveal the signals, the keys
used for encryption are required, after which the received
signals can be validated. As a result, it becomes challenging
for the attackers to recover original navigation signals, let
alone launch spooﬁng attacks.

Lessons Learned: Therefore, the combination of sig-
nals and cryptography is another interesting direction
for effective defenses against signal spooﬁng attacks.

Overpowering high power signals: This limitation widely
exists in jamming attacks. To achieve a DoS attack,
the
attacker generally uses more powerful signals to overwhelm
the legitimate signals. However, it will raise the bar for the
attacker if the legitimate signal is already very powerful. Take
positioning system jamming attacks as an example, Becker et
al. [141] demonstrate that jamming a terrestrial positioning
system like eLORAN is much harder than jamming a satellite
based positioning system. Compared to low-powered GPS
signals, eLORAN uses high-power,
low-frequency signals.
Therefore, the attacker is dependent on physically tall or long
antennas to efﬁciently transmit low-frequency signals [142] so
as to overcome the strong eLORAN signal.

Lessons Learned: Though it may be challenging to
directly overpower all signals, the attacker can still
interfere with the normal functionality of the target
system if it can send well-crafted signals to trigger
DoS at upper layers.

Lack of stealthiness: Although most signal injection at-
tacks are contactless to the target and are conducted remotely,
it is possible for some attacks to be either noticed by hu-
mans or detected by machines. Attacks that leverage visible
light [93] [92] [118] or wearing colorful masks [110] can
lead to the suspicion of other users. For instance, Sharif et

al. [110] utilize well-designed glasses to help the attacker
evade face recognition, but the glasses might stand out. A
potential solution to this limitation is shown in another optical
attack [114] where visible perturbations are attached to road
signs to mislead object recognition systems, and the perturba-
tions are intentionally designed to mimic grafﬁti so as to “hide
in the human psyche.” This idea can be potentially applied
to other optical attacks for improvements as well, where the
attacker may disguise the visible optical signal to be some-
thing common in daily life. Acoustic attacks against voice-
controlled systems face a similar limitation. Existing attacks
try to hide malicious commands by either perturbing audio
signals [85] [87] or modulating commands with music [86]
so as to avoid raising suspicion. However, the effect of the
injection, such as a response from the voice assistant, may
still reveal the attack. To tackle this problem, a command can
be injected to minimize the observable result of the injection,
such as turning down the volume at the beginning, so that
the following responses will not be noticed by the victim
users [84].

Lessons Learned: Stealthiness is a key factor in real
world attacks, and should be taken into consideration
when developing attacks.

Short attack range: Short distance requirements between
an attacker’s equipment, which is generally signal generating
and transmitting devices, and the target CPS can also be
a limitation. Take ultrasonic injection attacks for example:
due to atmospheric attenuation, the ultrasonic DoS attacks
proposed in [93] are normally conducted within 1 meter
with the assistance of high jamming noise amplitude, and
the attack range for spooﬁng is several meters. The dolphin
attack proposed by Zhang et al. [75] achieves an attack range
of 1.75m for ultrasonic signal injection, but is still restricted
by the power of ampliﬁer. In recognition of the short range
limitation, Metamorph proposed by Chen et al. [116] achieves
an attack range of 6m, and LipRead proposed by Roy et
al. [76] extends the attack range to 7.62m by aggregating
ultrasound signals from an array of speakers. Yan et al. take
a different perspective, where they leverage solid surfaces to
propagate the malicious ultrasound signal up to 30 ft [84].

Electromagnetic injection attacks face the same limitation.
EMI signal injection attacks targeting implantable medical
devices proposed in [78] achieve an attack distance of 1 to 2
meters when placing devices in the open air, but the effective
distance decreases to under 5cm when immersing devices in
a saline bath approximating human body. Similarly, in a GPS
spooﬁng attack targeting trucks proposed in [115], the attack
range is limited to 30 feet due to the attack signal strength.

For optical injection attacks, one attack targeting LiDAR
proposed by Petit et al. [92] faces a similar challenge in which
the attacker signal will fail to reach the victim photodetector
of the target LiDAR at a distance. Park et al. [94] succeed in
an optical-based spooﬁng attack targeting infrared sensors at
a distance of 12 meters using a 30mW IR laser, but face the
challenge of precise aiming at the target.

19

Lessons Learned: Finding new methods to enable the
extension of the attack distance without signiﬁcantly
raising the attack power can be an opportunity to
overcome existing limitations.

Moving targets: This limitation exists in injection attacks
because the transmitted signals need to aim at the target, thus
constantly tracking a moving target becomes more difﬁcult.

In [93], the best performance for an ultrasonic spooﬁng
attack is achieved at a perpendicular angle, because the lon-
gitudinal sound wave will project most of its energy in the
forward direction. Though this may not be a problem for a
still target CPS and attacker, the attack becomes signiﬁcantly
more challenging when the target is constantly moving.

Also,

the spooﬁng attacks targeting LiDAR sensors of
autonomous vehicles face a similar limitation. Both [92] and
[106] mention that aiming is one of their main obstacles in
deploying practical attacks, since the attacker has to track the
target LiDAR with their device.

Similar limitations are present in the spooﬁng attack on
MEMS gyroscopes proposed in [95], where it becomes dif-
ﬁcult for the attacker to follow and aim the moving target
while manually tuning acoustic signals. Though movement
prediction may help mitigate these limitations, it is still re-
stricted to certain scenarios; an automatic tracking and aiming
system seems to be an ideal solution theoretically, but
it
will signiﬁcantly raise the attack bar and may also raise the
limitation of costly equipment.

Lessons Learned: Existing work has demonstrated that
aiming at moving targets is a general challenge for
signal injection across different physical waveforms.
Potential future directions of research may include
developing better tracking algorithms or attacks that
do not require continuous interaction with the victim.

Costly equipment: This limitation refers to the fact that
costly equipment is required in order to achieve some of
the proposed attacks. For instance, Warner et al. [115] rent
a GPS satellite simulator for $1000 per week to generate
and transmit the spoofed signal to the GPS receiver, with
an additional antenna for broadcasting and two GPS signal
ampliﬁers costing $400 in total. Similarly, in order to generate
signals at the operating frequency of the MMW radar that is
attacked in [93], the attacker must make use of a function
generator that can generate signals up to 81GHz, which has
signiﬁcant costs. It is also an important issue for the attacks
that use injected EMI; generally, the resonant frequency of the
PCB traces used as unintentional receivers is in the GHz range,
and signal generators capable of producing those frequencies
reliably are in the range of thousands of dollars.

Lessons Learned: The limitation of costly equipment
exists in some of the developed attacks, thus develop-
ing defense solutions that will drive the cost higher as
well as low-cost defenses are important directions for
future research.

Physical hazard: This limitation applies to certain attack
vectors such as infrared lasers that may cause physical harm
to human bodies. In [94], Park et al. discuss that in order
to achieve larger attack distances, the required infrared laser
with higher power is dangerous in that it can cause serious
eye damage. Zhou et al. [109] use an infrared laser to project
dots onto the attacker’s face, which they state that may lead
to potential health concerns. Sugawara et al. [118] also use
a laser beam as an attack vector to inject commands, which
may result in eye damage as well.

Lessons Learned: It is often important to consider the
potential health hazards for both the attacker and user
when considering attack and defense mechanisms.

Generalizing for environmental variability: The ambient
environment can be an important factor affecting the effec-
tiveness of some attacks. For example, both [86] and [87]
propose acoustic attacks targeting voice-controlled systems,
and they can both be impacted by environmental noise. Both
papers indicate that ambient noise will interfere with over-the-
air attack audio and degrade the malicious perturbations.

The optical attacks that mislead recognition systems using
adversarial machine learning methods face similar challenges.
For example, an optical attack targeting facial recognition is
developed in [110], in which the researchers propose to reduce
lighting variations by conducting the attack indoors.

Recognizing the lack of generalization,

there are some
efforts to take the variances into consideration. For instance,
Eykholt et al. in [114] consider the distance and angle of
a camera in an autonomous vehicle with respect to a road
sign. Similarly, Shahrad et al. in [96] also investigate the dis-
tance and angle factors inﬂuencing the proposed out-of-band
acoustic DoS attack targeting HDDs, and they discover that
the maximum distance and effective angles vary dramatically
between different HDDs.

Lessons Learned: In order to make the attack or
defense more realistic, it is important to take the pos-
sibility of environmental variations into consideration
when designing attack and defense mechanisms.

V. CYBER TO PHYSICAL: INFORMATION LEAKAGE
ATTACKS

In an information leakage attack, the sensors of a cyber-
physical system are exploited by an attacker to covertly
measure signals leaked from an individual or a system through
a vibrational, optical, acoustic, or magnetic side channel that
can be processed to recover private information. Compared to
signal injection attacks, these attacks leverage digital signal
data to eavesdrop on physical activities, therefore they can
be regarded as cyber-to-physical attacks. Also,
instead of
actively manipulating physical world signals as is done in
signal injection, these attacks tend to passively receive and
analyze the signals emanated from target systems. In this
sense, they can be regarded as passive attacks.

20

Fig. 9: Two types of information leakage attacks categorized
by the consistency between the locations where the informa-
tion leaked from and where the attacker collects data. (a) Co-
located attacks, where the signals leaked from the target CPS
are collected by sensors embedded within the same CPS. (b)
Remote attacks, where the sensors are remotely measuring
signal leakage from a nearby physical process.

In general, information leakage attacks can be divided into
two distinct categories: co-located attacks and remote attacks.

• Co-located attack: This refers to attacks in which the
source of the leaked signal is co-located with the sensor
used to measure it within a single computing system. In
this scenario, the target CPS is maliciously utilized as the
attacker’s tool as well.

• Remote attack: This refers to attacks in which the source
of the leaked signal is external to the attacker’s CPS,
which measures said signals with its sensors.

These two types of attacks are shown in Fig. 9. Both attacks
are normally carried out through trojan applications installed
on the device that collects data from the sensors, which is
processed and transmitted to the attacker. The main difference
lies in whether the attack and the victim reside in the same
computing system or not. In a co-located attack shown in
Fig. 9(a), the sensors within the CPS are maliciously utilized
to collect information emitted from CPS itself, which means
that the victim CPS itself serves as the attack tool at the same
time. For a remote attack shown in Fig. 9(b), the CPS together
with its embedded sensors are external to the target, and are
used by the attacker to collect nearby leaked information.

Modern smart devices such as smartphones are a common
target for information leakage attacks since they are equipped
with a wide range of high-precision sensors [143], and are
owned by over 67% of the global population [144], making
them a highly attractive target for attackers. Furthermore,
third-party applications often have direct access to the high-
precision sensors of the device without requiring any speciﬁc
permissions. Therefore, a large portion of existing attacks in
the literature are designed with iOS or Android apps.

A. Threat Model

This section will provide a generalized discussion of the
attack model for information leakage attacks on CPS, deﬁning
the attacker requirements, attack vectors, a generalized attack
model, and attack goals.

1) Attack Requirements: We propose three general attacker
requirements for information leakage attacks in the following:

• Covert extraction: This requires the adversary to have
access to the stream of sensor data. This can be ac-
complished by various methods such as developing apps
being secretly installed on the device through a remotely
accessible backdoor, or embedding malicious code in a
harmless-looking web page.

• Data exﬁltration: This requires that the collected sensor
data can be sent to a remote server, either directly through
the attacker’s software or through another application.
• Information recovery: This requires that the attacker
can recover the desired information from the collected
sensor data by either obtaining or training a classiﬁcation
model.

2) Attack Model: Fig. 10 shows the overall workﬂow of
an information leakage attack, which generally consists of the
following two stages:

• Data collection and transmission: In this stage, the
attacker’s malware collects raw data from the sensor. In
the context of smartphones, an important consideration is
the level of user permissions required by the platform for
accessing the targeted sensor’s data. In Android and iOS,
permissions of sensitive sensors such as microphones,
GPS sensors, and cameras are restricted, while some
other sensors such as ambient light sensors, gyroscopes,
accelerometers, and magnetometers can be accessed by
an application without explicit user permissions. The
then be transmitted to the
collected sensor data will
attacker for further analysis.

• Data analysis: The collected and transmitted data will
be processed to retrieve the attacker’s desired private
information. In the vast majority of existing literature,
machine learning techniques are used to extract
the
desired information from the collected sensor data. Thus,
this stage can be further divided into feature extraction
and classiﬁcation. Feature extraction refers to identifying
and extracting features from the raw data; the quality of
the methods used to extract features plays a large role
in the accuracy of the eventual classiﬁcation. The data
is then fed to the classiﬁer, which is ﬁrst trained with
a chosen subset of the data. Once trained, the classiﬁer
can be used by the attacker to recover the sensitive
information from the collected data.

3) Attack Vector: The attack vector for an information leak-
age attack is categorized by the type of signal measured by the
sensor. The sensor can measure signals leaked by vibrational,
electromagnetic, acoustic, and optical side channels. Besides,
based on the locality of the attacker, the attack can either be
co-located with the source of leaked information, or remote.

21

Fig. 10: Workﬂow of an information leakage attack. The
leaked signals are collected by nearby sensors and transmitted
to the attacker for further analysis. The analysis generally
contains feature extraction and classiﬁcation stages.

4) Attack Goals: The attack goal refers to the information
that is being leaked. Most of the existing literature has demon-
strated inference on keystroke, task, location, and speech.

• Keystroke inference: Users’ input, either via a mechani-
cal or touch-based keypad, generates optical, electromag-
netic, acoustic, and vibrational side-channel leakage that
can be detected by the sensors of CPS.

• Task inference: Ongoing tasks or applications on CPS, or
physical activity by the user, can generate vibrational and
electromagnetic side-channel leakage that can be detected
by the sensors of CPS.

• Location inference: Acoustic side-channel leakage can
be detected by the sensors of CPS, potentially revealing
details about a user’s location.

• Speech extraction: Human speech that generates vibra-
tional, optical, and electromagnetic signals can be picked
up by the sensors of CPS.

B. Techniques for Information Leakage

As discussed in Section V-A2, successful implementation
of an information leakage attack consists of two steps, data
collection and transmission and data analysis. These are the
core processes of an information leakage attack, and also
are the main factors determining an attacker’s requirements
and challenges. The ﬁrst challenge that the attacker faces is
to stealthily obtain data from targeted CPS. For co-located
attacks, sensors embedded in targeted CPS are used for signal
measurements and are the sources of raw data for attackers
as well. As malware becomes more widespread and affects
more users [145], it would be easy for the attacker to obtain
selected data within CPS through installed malicious soft-
ware [146]. Especially for some data that is generally not
considered highly sensitive, such as accelerometer data on
smartphones [147] [148] [149], less protection or isolation
is granted, thus making it easier for the attacker to access
sensor data without raising suspicion. However, for remote
attacks, the attacker collects data in a different way: signals
originating from user inputs are captured and measured by
nearby CPS belonging to the attacker. In this case, the main
problem for the attacker is to deploy the proper CPS at a target
location [150] [151] [152].

To further infer private information, the main processes
can be summarized as three steps: pre-processing,
feature
extraction, and classiﬁcation. Pre-processing is required as
the extracted data often contains a signiﬁcant amount of

22

a) Keystroke Inference through Vibrational Leakage:
In the case of mechanical keyboards,
the vibrational side
channel can be measured remotely by the accelerometer and/or
gyroscope of CPS that share a common surface with the
keyboard. Each keystroke generates a unique, acoustically
conducted, vibrational signature. Thus, by analyzing raw data
from these sensors, an attacker can infer the keystrokes being
typed. In the case of touch-based keyboards, the user’s input
changes the orientation of the device as well as generating
vibrations. Thus, similarly to mechanical keyboards, this side
channel can be measured by a co-located gyroscope and/or
accelerometer to infer keystrokes on a touch-based keypad.

Co-Located Keystroke Inference: Cai et al. [159] attempt
at inferring keystrokes based on co-located motion sensors
including accelerometer and gyroscope. They use a covert
application installed on a victim’s smartphone to measure raw
device orientation data based on readings from the accelerom-
eter. This data is used to train a Gaussian classiﬁer, which can
predict keystrokes with an overall accuracy of 71.5% on a 10-
digit numeric touch keypad. Following this work, Owusu et al.
[147] describe a similar attack, but develop two separate test
modes, area and character, and use a random forest classiﬁer.
More importantly, the granularity of the attack is much higher,
meaning the device’s screen is divided into up to 60 squares in
Area mode and 29 squares in character mode, rather than 10
used in [159]. Using their techniques, they are able to break 59
out of 99 passwords logged during text entry on smartphones.
Both of these attacks are performed on an Android device.

In [160],

the gyroscope and accelerometer are used in
combination to predict keystrokes across both Android and
iOS devices, including smartphones and tablets. In this paper,
Miluzzo et al. achieve a prediction accuracy up to 90%. In the
same vein, Xu et al. [161] demonstrate a similar attack, making
use of acceleration and gesture changes caused by tap events
but using a different feature extraction scheme. Furthermore,
they focus on the detection of tap events themselves with the
obtained noisy motion sensor data, which can greatly improve
the accuracy of keystroke inference in noisy environments, for
example, even when the individual is walking.

Al-Haiqi et al. [167] explore the topic of sensor fusion for
keystroke inference, using features extracted from different
combinations of the motion sensors (linear accelerometer, gy-
roscope, rotation vector sensor) and the combined accelerom-
eter and magnetometer synthetic sensor data that are fed to the
classiﬁer. They discover that contrary to what is assumed in
previous papers, using only the gyroscope’s data is beneﬁcial
to the accuracy of the keystroke prediction, compared to fusing
sensor readings. They are able to correctly predict up to 95%
of keystrokes by using only the gyroscope.

Remote Keystroke Inference: It should be noted that
the attacks discussed above are using data from co-
located inertial sensors to infer keystrokes. In other re-
searches [150] [162] [148] [164] [163] [166], remote attacks
are demonstrated in which the vibrational leakage generated
by user input is measured by the inertial sensors of a nearby
system. This attack can generally be described by one of two
attack scenarios: ﬁrst, the inertial sensors of a wearable device,
such as a smartwatch, are used to infer the keystrokes either on

Fig. 11: Overview of existing work on keystroke inference
attacks. Physical keyboards, touchscreen keyboards, POS key-
pads, and numpads have been explored as target devices, from
which vibrational, acoustic, and electromagnetic information
is leaked and picked up by corresponding sensors.

noise, and it mainly includes selecting, normalizing, and pre-
calculating to generate a modiﬁed data matrix to be used in
the following steps. Feature extraction refers to the attacker
extracting core features derived from the pre-processed data
matrix that are intended to be informative and non-redundant.
This step is intended to raise attack accuracy by discarding
less relevant data and simultaneously facilitating the following
learning step with dimensional reduction. Classiﬁcation is
the core part of the data analysis, from which the attacker
eventually gets results with the help of machine learning based
methods. Techniques from other domains such as dictionary
mapping [153], Hidden Markov Models (HMM) [154] [155],
and image deconvolution [156] [157] have also been used in
some works for private information inference.

C. Information Leakage: Known Attacks

Existing literature on information leakage using signals
will be discussed in this section. We summarize the existing
information leakage attacks in Table III and more details will
be presented in the following sections. To be more speciﬁc,
sections V-C1 to V-C4 will cover keystroke inference, task in-
ference, location inference, and speech extraction respectively.
This section is divided according to the attack goal because
methodologies used in various information leakage attacks are
more dependent on the information being leaked.

1) Keystroke Inference Attacks: Users’ input to a cyber-
physical system, either via a mechanical or touch-based key-
board, can generate acoustic, electromagnetic, and vibrational
side-channel leakage. Existing research explores using sensors
to measure this side-channel leakage to recover the user’s
keystrokes. As is shown in Fig. 11, keystrokes on various
devices including physical keyboards, touchscreen keyboards,
POS keypads, and numpads have been explored as leaked
information and are recovered from different sensor data.

TABLE III: Summary of Existing Information Leakage Attacks

23

d
e
t
a
c
o
l
-
o
Exploited Sensor c
(cid:88)

Acc, Gyro, Mag (cid:88)
Acc, Gyro, Mag (cid:88)
Acc, Gyro, Mag (cid:88)
Acc, Gyro, Mag (cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)

Acc
Acc
Acc
Acc
Acc
Acc, Gyro
Acc, Gyro
Acc, Gyro
Acc, Gyro
Acc, Gyro
Acc, Gyro
Acc, Gyro
Acc, Gyro

Antenna
Antenna
Cam
Cam
Cam
EM Probe
Gyro

e
t
o
m
e
R

Data Collection
Android phone
iPhone
Smartwatch
Android Phone
iPhone
Android phone

r
o
t
c
e
V
T
(cid:88) T
(cid:88) T
T
T
T
T Android & iPhone
T
(cid:88) T
(cid:88) T
(cid:88) T
T

Android phone
Smartwatch
Smartwatch
Smartwatch
Smartphone

(cid:88) T EBIMU24G Sensor
TO Android phone
TO Android Phone
TO Android Phone
TO Custom Sensor Array

TV Receiver

(cid:88) O
(cid:88) O Biconical Antenna
(cid:88) ☼
Cam, Telescope
(cid:88) ☼
Cam, Telescope
(cid:88) ☼
High Speed Cam
(cid:88) O
Copper Probes
T
Android Phone
`
Hard Drive

Leaked Information
TS Keyboard Presses(29)
PK on Keyboard(26)
PK on Keyboard, Numpad(26, 10)
User’s Physical Activities
User Location/Route
TS Numpad Presses(10)
TS Tap Location
TS Numpad Presses(10)
PK on Keyboard(26)
TS Numpad, Keyboard(10, 26)
PK/TS Numpad Presses(10)
User’s Physical Activities
PK Door Code(10)
TS Numpad Presses(10)
User’s Physical Activities
User Location/Route
User Activity/Location
Screen Content
PK on Keyboard(39)
LCD Screen Content
LCD Screen Content
Audio Eavesdropping
Encryption Keys
Audio, Speech
Audio Eavesdropping
Audio, Speech
Computer Activities/Behaviors
3D Printer IP
PK on Keyboard (26)
DM Printed Text
PK on Keyboard, Numpad(30, 9)
PK on Keyboards(26)
RSA Key(4096 Bit)
PK Keyboard
PK Keyboard
LCD Screen Content
User Location
Encrypted Bitstream
Audio, Speech
Processed Data on Devices
CRT Screen Content

Bayesian

LSTM
CNN

Multiple/WEKA
Graph Matching

Accuracy
59%
80%
65%
90%
-

TE Ref
Method
R [147]
Random Forest
R [150]
L/R, N/F classiﬁer
[148]
I
K-Nearest Neighbor
I
[158]
LR, MlP, SM
R [149]
Trajectory Mapping
[159]
I
71.5% Supervised Learning
[160]
I
Ensemble Learning
90%
>80%
K-means, LibSVM R [161]
[162]
30%
I
[163]
30-90% Ensemble Learning
I
[164]
59-73%
I
[165]
54-90%
I
R [166]
30-70% Logistic Regression
[167]
I
95.63% Ensemble Learning
I
30-98%
[168]
30-50%
R [169]
K-Nearest Neighbor R [170]
86%
R [171]
Re-synchronization
-
R [152]
95%
STFT
[156]
I
Human Readability
-
[172]
I
Image Deconvolution
-
[173]
I
Local Motion Signals
-
[174]
I
Key Inference
-
[175]
SVM, GMM, DTM I
6-84%
R [176]
Audio Recognition
-
[177]
53-70.4% Developed Algorithm I
I
65-95% Enrollment Vectors
[178]
R [179]
89-94%
[154]
I
40-60%
I
72-95%
[180]
[155]
I
79%
R [153]
96%
R [151]
-
I
73-90%
[181]
R [182]
72.2%
[183]
I
40-100%
[184]
I
76%
I
-
[185]
R [186]
91%
R [157]
-
[187]
I
-

MTE
Time-Frequency
HMM
Neural Network
HMM
Chosen Ciphertext
Dictionary
TDoA
CNN
K-Nearest Neighbor
Plaintext Extraction
MCFS, DTW
Classiﬁcation
Image Deconvolution

(cid:88) ☼ Electro-optical sensor
(cid:88) O
Android Phone
(cid:88) `O Android Phone
(cid:88) `
(cid:88) `
(cid:88) `
(cid:88) `
(cid:88) `
(cid:88) `
(cid:88) T
(cid:88) (cid:88) `
(cid:88)
`
(cid:88) ☼
(cid:88) O Desktop Computer
(cid:88) ☼ LED/PIN Photodiode
(cid:88) ☼ Photosensor Module

(cid:88)
HDD as Mic (cid:88)
Light bulb
Mag
Mag, Mic
Mic
Mic
Mic
Mic
Mic
Mic
Mic
Mic
Mic
Microscope
NIC
Photodiode
Photosensor
TE = Testing Environment; I = Ideal; R = Replicated Real-World Conditions; TS = Touchscreen; PK = Physical Keystrokes; IP =
Intellectual Property; Acc = Accelerometer; Gyro = Gyroscope; Mag = Magnetometer; Cam = Camera; Mic = Microphone; NIC =
Network Interface Controller; (X) = X number of unique keys; LR = Logistic Regression; SM = Straw Man; MlP = Multilayer Perception;
MTE = Mean Tendency Error; ☼= Optical; T= Vibrational; `= Acoustic; O= Electromagnetic;

Microphone
Microphone
Microphone
Microphone
Android Phone, Mic
Microphone
Smartphone
Android Phone, Mic
Video/Audio File
Optical Probing

a mechanical or touch-based keypad [148] [162] [163] [164];
second, the inertial sensors of a CPS that share a surface with
a mechanical keyboard, most commonly of a smartphone, are
used to predict keystrokes on the keyboard [150] [165] [182].

The ﬁrst remote keystroke inference attack exploiting vibra-
tional side channels targets on mechanical keyboards with iner-
tial sensors of smartphones [150]. One of the major limitations
of remote information leakage attacks is that the attacker must
place their sensor-equipped CPS within a reasonable distance
of the target device, such that the leaked side channel can
be measured with a sufﬁcient degree of precision. This often

requires special equipment, such as parabolic microphones or
high-quality antennas, so that the attack can be launched from
a far distance to remain concealed. Marquardt et al. [150]
address this limitation by suggesting an attack in which the
victim’s smartphone shares a surface with the target keyboard,
and infers keystrokes based on the leaked vibrational side
channel. It is a common scenario for an individual to put their
smartphone on the same table as their keyboard, so this attack
can be both effective and covert. In this attack, the researchers
manage to recover up to 80% of the typed content using this
method.

Following this paper, more remote keystroke inference
attacks adopt similar methodologies of exploiting a sensor-
the victim themselves brings into the
equipped CPS that
vicinity of the keyboard. Most notably, smartwatches are
equipped with inertial sensors, and can be used to carry out
keystroke inference attacks in this fashion. In [162], Wang
et al. show that it is indeed possible for a smartwatch to
leak vibrational information about a user’s keystrokes. By
combining Bayesian inference techniques with an awareness
of the structure of the English language, the researchers are
able to predict the words being typed 30% of the time ideally
and 10% to 20% practically depending on the subject. The
main limitation of this technique is that the smartwatch is only
worn on a single hand, introducing a signiﬁcant upper limit
on the accuracy of predictions. A similar attack is carried out
in [148] and [164], where the techniques are extended to POS
terminals, such as credit card machines and ATM keypads. In
[163], these techniques are also applied to the numeric touch-
based keypads of smartphones; in this case, a user wearing a
smartwatch can leak a vibrational side channel, which can be
analyzed to infer their pin. Further experiments are conducted
for comparison with different smartwatches, motion sensors,
and fusing mobile data. This attack is also extended to the
application of mobile keypads with QWERTY layout.

In [166], a unique attack is proposed in which the password
to a smart door-lock can be inferred by measuring a vibrational
side channel, where the sensor-equipped device is placed by
the attacker between the door and its frame. In this work, Ha
et al. design the device such that it is discreet but still has the
ability to exﬁltrate the collected data to the attacker’s remote
server. By measuring the leaked vibrational side channel, the
researchers demonstrate that it is possible to infer the password
to the door lock.

b) Keystroke Inference through Acoustic Leakage:

Keystroke inference through acoustic side-channel
leakage
has also been researched. It is shown that on mechanical
keyboards,
there is enough of a correlation between the
spectral signature of a keystroke and the actual key pressed for
an attacker to predict keystrokes by recording their acoustic
emanations. Asonov et al. [155] are the ﬁrst to demonstrate
this attack; by simply recording the sound of typing, extracting
time and frequency domain features via FFT, and training
a neural network, they show that it is possible to predict
keystrokes. Following this work, Zhuang et al. [153] use
MFCC features, unsupervised learning techniques (clustering),
and a HMM-based language model to predict keystrokes. They
are able to show a signiﬁcant improvement in the accuracy of
the predictions, predicting 96% of typed characters correctly.
Furthermore, Halevi et al. [154] assume that the attacker has
no access to the language model, and introduce the uncertainty
of different typing styles. The techniques used to account for
different typing styles bring the attack much closer to being
feasible in a real-world scenario.

Similarly, a context-free attack is demonstrated in [182] by
using Time Difference of Arrival (TDoA), which essentially
takes the time between consecutive keystrokes into consider-
ation. It also takes a “context-free” approach, meaning that
language models are not used. This way, the attack is also

24

effective against random words that do not follow the English
language structure, such as passwords. Using this technique,
the researchers are able to recover more than 72.2% of
keystrokes.

c) Keystroke Inference through EM Leakage: In [152],
Vuagnoux et al. show that
is also viable to eavesdrop
it
on keystrokes on physical keyboards (wireless or wired) by
leveraging electromagnetic emissions. Their attack success-
fully recovers keystrokes 95% of the time at distances up
to 20 meters between the keyboard and antennae used to
eavesdrop. The researchers use raw signals from the antennae
for their analysis, and further classify four different identifying
types of emanations from physical keyboards. They are able
to successfully perform their attack in four different scenarios,
ranging from within a shielded room to outside the building
the keyboard is in.

Lessons Learned: The majority of existing keystroke
inference attacks focus on vibrational signals, but the
possibility of optical leakage has not been explored.
It remains an open research problem how keystrokes
may create recoverable optical emanations in certain
scenarios.

2) Task Inference Attacks: In a task inference attack, the
adversary measures some leaked side channels to gather in-
formation about the state of the physical process from which
it is emanated. The recovered information can either be related
to some tasks or applications running on a device being
attacked or the activity of a nearby user. Many of the papers
discussed in this section are not security research, but still have
implications in the context of security. For example, a large
body of research explores the use of motion sensors for user
activity recognition on smartphones for use by context-aware
applications. Though this is not directly related to security, it
still describes a speciﬁc method used to recover potentially
sensitive information from a leaked vibrational side channel.
a) Task Inference through Acoustic Leakage: Existing
work has revealed that acoustic leakage contains abundant
information which can be utilized to recover cyber data (e.g.,
cryptographic keys [151]), optical
information (e.g., LCD
screen content [183]), and even physical motions (e.g., printer
nozzle motion [179]).

Genkin et al. [151] demonstrate an acoustic cryptanalysis at-
tack, in which a microphone is used to record acoustic signals
that are leaked from the vibration of electronic components
in a computer. When performing cryptographic operations,
the CPU’s power draw changes as a function of the speciﬁc
operations being performed, which is reﬂected in the vibration
of the electronic components. Thus, the private keys used
for encryption can potentially be recovered by observing the
acoustic side-channel leakage.

More recently, the same researchers from [151] show a new
attack [183], where a microphone is used to record acoustic
emanations from an LCD computer screen that can be used
to recover the contents of the screen. The momentary power
draw of the monitor’s digital circuits varies as a function
of the screen content being processed in raster order, which

affects the electrical load on the power supply components,
causing the components to vibrate and emit acoustic noise.
Thus, the acoustic signals can be processed to recover the
original contents of the screen. Advanced signal processing
techniques are utilized to extract various time and frequency
domain features from the recorded acoustic leakage, and these
features are used to train a convolutional neural network
(CNN) classiﬁer, which can eventually disclose information
such as text on the screen and websites being visited.

Backes et al. [180] show that

the acoustic emanations
from a dot-matrix printer can be measured to infer the text
being printed. This attack starts with a training phase, where
known words are printed through the printer and features
extracted from the resulting acoustic leakage are stored in a
dictionary. The word-based approach is preferred to the letter-
based approach, since the emitted sound is signiﬁcantly blurred
across adjacent letters. In addition to using the dictionary,
they also use HMM-based speech recognition techniques to
improve the accuracy of the attack. In a similar attack, Song et
al. [179] demonstrate that acoustic side-channel leakage from
a 3D printer can be measured by using a microphone and
magnetic sensor together to infer the motion of the nozzle,
which can leak the designed object.

b) Task Inference through Vibrational Leakage: Data
of motion sensors in smartphones can be used to infer users’
acivities. This is referred to as activity recognition, and is
generally useful when developing context-aware applications.
Thus, some existing literature detailing activity recognition
using motion sensors is not security research. Nonetheless, this
could pose a side-channel leakage threat in which an attacker
can potentially track a victim’s activities covertly through a
malicious application that measures this leakage.

In [158] and [168], the researchers propose various machine
learning techniques to use accelerometer and gyroscope data
to classify human activity. Current research is able to classify
activity as walking, running, climbing stairs, descending stairs,
jogging, sitting, and standing. Though leaking this information
does not pose an immediate threat to the user, this technique
could once again be used as a single step of a larger, more
substantial information leakage attack. In [165], Bartlett et al.
propose to build a large-scale dataset called AcctionNet, which
is essentially a dictionary mapping inertial sensor readings to
human activities. If an attacker chooses to exploit vibrational
leakage for task inference, this dataset could serve as a great
resource in carrying out the attack.

c) Task Inference through EM Leakage: The ﬁrst work
in this domain is proposed by Van et al. [171], where they
show that electromagnetic radiation generated by CRT TVs
when displaying video can be used to recover what was being
displayed remotely. Using a TV receiver, antennae, a signal
ampliﬁer, and a synchronization method,
they are able to
recover video information from up to a kilometer away.

In [174], Gandolﬁ et al. are able to use microscopic copper
coils as probes to read electromagnetic power radiation, and
in doing so successfully attack DES, COMP128, and RSA on
different CMOS chips. In this attack, they are able to use the
small amount of voltage induced in the coils to successfully
recover key information from these algorithms.

25

Another attack demonstrating task inference through mag-
netic leakage exploits hard disk drives by measuring magnetic
leakage with the magnetic sensor of a nearby smartphone
[178]. And thus this is a remote attack. Hard drives contain
different magnets which rapidly move the read/write head
to a target position on the disk to perform a read or a
write. The magnetic ﬁeld due to the moving head can be
picked up by a nearby smartphone; by analyzing the collected
data, Biedermann et al. show that an attacker can detect the
operating system that
is used, distinguish between known
applications being started, distinguish virtual machine activity
on a server, match ongoing network trafﬁc to a server, and
detect ﬁle caching based on disk activity.

d) Task Inference through Optical Leakage: Optical
leakage exploited to infer tasks can be categorized into
two types. One is through visible light such as a blinking
LED [157] [185] or screen [187], while another is reﬂections
on smooth surfaces [156] [172].

leakage. By using a photodetector,

Visible Light Inference: Loughry et al. [157] show that
LED indicators of various devices can act as sources of optical
side-channel
they ﬁnd
that by measuring leakage from the LEDs on the backside
of a wireless router, information about the transmitted and
received packets can be extracted. In [187], Kuhn et al. use a
photodetector to measure optical side-channel leakage from a
CRT display at a distance. They demonstrate that since the
intensity of the light emitted by a raster-scan screen as a
function of time corresponds to the video signal convolved
with the impulse response of the phosphors,
the intensity
readings measured by the photodetector can be deconvolved
to recover the text on the screen.

In [185], Tajik et al. use optical probing of FPGA boards to
infer bitstreams of data. By using precise optical equipment,
they improve on previous attacks by requiring no prior prepa-
ration or modiﬁcation of the FPGA boards. In this attack, the
plain text of securely encrypted bitstreams being processed on
the device is recovered within ten days of acquiring the board.
Reﬂection Inference: More recently, Backes et al. [156]
make use of reﬂections from computer monitors and screens
detected by cameras or telescopes, revealing the contents of
the screen. They show that teapots, eyeglasses, the human
eye itself, wine glasses, and glass bottles can reﬂect optical
emanations from screens, which can be picked up by an optical
sensor. In [172], the same researchers from [156] improve this
attack by using image deconvolution techniques to remove the
blur caused by observing optical leakage from moving objects.
Using this technique, they are able to greatly increase the
attack distance of attacks exploiting compromising reﬂections
from the human eye.

Lessons Learned: The majority of existing task infer-
ence attacks exploiting acoustic, electromagnetic, and
optical leakage are remote attacks, where the attackers
observe and collect the emanations using their own
sensing systems at a distance. It would be interesting
to explore the possibility of co-located attacks in this
domain.

3) Location Inference Attacks: This kind of attacks aim to
infer the location of the victim via acoustic or vibrational
side-channel leakage.

a) Location Inference through Acoustic Leakage: One
of the methods used for location inference through acoustic
leakage is the analysis of electro network frequency (ENF)
signals in recorded audio. ENF refers to background signals
that reﬂect the supply frequency of electric power in distribu-
tion networks of a power grid, commonly with a mean value
of 60Hz in the United States or 50Hz in most other parts of the
world. Thus, the vibrations of ENF contain time-varying and
location-sensitive information of the original audio or video
recordings. This is exploited by Jeon et al. [184] to infer a
system’s location based on data collected from a co-located
or nearby microphone. The ﬁrst step of the attack is to scrape
the web for audio recordings that contain ENF signals and
build a map correlating ENF signals with physical locations.
Thus, when the attack is actually carried out, the measured
ENF signature can be compared against the map to infer the
victim’s location.

b) Location Inference through Vibrational Leakage:

Existing work that falls into this category generally exploits
motion sensors such as gyroscopes and accelerometers, which
are sensitive to vibrations, to infer the location or routine
leaked from users’ movements.

Han et al. [149] ﬁrst demonstrate the possibility of using
accelerometers and gyroscopes to infer location. The attackers
take the approach of using motion sensor data to infer a
trajectory through space. Since idiosyncrasies in roadways
create globally unique constraints, the calculated trajectory
can then be mapped onto a global map, in which the closest
the re-
existing trajectory is found. Using this technique,
searchers show that it is possible to infer location by measuring
vibrational side-channel leakage. In a similar attack proposed
in [169], Narain et al. use a sensor fusion based approach
for location inference, and use the accelerometer, gyroscope,
and magnetometer to infer routes of the victim user. Then,
in a similar manner to the previous paper, they compare this
route to existing routes, returning the top matches for potential
locations.

It is worth mentioning that some works not focusing on
security also imply the risk of a possible attack. In [170],
inertial sensors are used to infer an individual’s position
indoors. The approach taken can be summarized as: based
on a known starting position, software can be implemented
that calculates the number of steps taken based on motion
sensor data; once the user stops, their path and location can
be inferred given a limited knowledge of the architecture of
the building that they are inside. In [188], which also does not
focus on proposing new information leakage attack, a method
called “elastic pathing” is proposed to use velocity data to
reconstruct a user’s routes, and eventually their location. This
paper focuses on the potential privacy risk posed by insurance
companies monitoring a user’s speedometer, showing the
possibility for an insurance company to track their customers
using this data. In general,
the techniques used for route
reconstruction and route mapping are similar to those used
in the proposed attacks.

26

Lessons Learned: Most of the existing location in-
ference attacks focus on predicting location or rou-
tine by analyzing motion sensor data that imply the
user’s movement. However,
the approach taken by
[184] to leverage geo-speciﬁc signals to recover victim
locations can be generally applied beyond ENF. New
attacks may pay attention to signals such as light or
EM waves that vary in different regions, with which
the attack performance can be improved.

4) Speech Extraction: In this section, we choose to focus
on unintended speech content disclosure via physical side
channels. Therefore, speech extraction attacks accomplished
by compromising a system to access the microphone are not
covered.

a) Speech Extraction through Vibrational Leakage:

Fig. 12 presents an overview of existing attacks for human
speech vibrational inference. The basic attack principle is that
the acoustic speech will cause sensitive components (such as
gyroscopes [175] and HDD heads [176]) to vibrate, and this
vibration can be recovered from sensor data. However, depends
on whether the sampling rate exceeds the Nyquist limit, the
attacker is able to recover either complete speech [176] or just
information of the speaker [175].

Michalevsky et al. [175] show that smartphone gyroscope
sensors can act as unintentional microphones. In this work, it is
shown that gyroscopes in smartphones are sensitive to acoustic
vibrations, and can thus potentially be used to recover speech.
The main limitation of this approach is that the sample rate
of the gyroscope is often below the Nyquist limit for human
speech; thus, the attack does not recover actual intelligible
speech, but rather recovers details about the speaker such as
their gender.

To address this limitation, Kwong et al. [176] utilize a hard
disk drive as an unintentional receiver for acoustic signals.
They show that since the read/write head of a hard disk drive
is sensitive to acoustic frequencies, it can also be used as a
microphone. Since the sample rate is higher, intelligible speech
is recoverable from the HDD that is even clear enough for
recorded music to be recognized by song-recognition apps
such as Shazam.

b) Speech Extraction through Optical Leakage: Davis
et al. [173] also show the possibility of eavesdropping on
human speech via optical leakage. Since many objects can
be considered as receivers of acoustic signals, vibrations in
these objects due to sound waves can be observed by a high-
precision camera. For example, a high-speed camera is used to
take a video of a bag of potato chips. By observing the slight
movement and changes in reﬂection patterns on the bag, the
researchers are able to recover audible sounds such as speech
and music.

More recently, Nassi et al. [177] state that acoustic signals
will cause ﬂuctuations of the air pressure on the surface of the
hanging bulb, therefore leading to the vibration of the bulb.
In this attack, an electro-optical sensor is placed remotely to
analyze a hanging light bulb’s frequency response to sound.

27

Fig. 12: Overview of existing work on vibrational speech extraction attacks. The main idea is to collect vibrational data from
sensitive sensors and recover speech content [175] [176]. However, if the sample rate of the adopted sensor is below the Nyquist
limit for human speech (e.g., gyroscope), it will only recover partial information such as the gender of the speaker [175].

With their developed algorithm, they are able to recover speech
and singing in real time with an intelligibility over 53%.

c) Speech Extraction through EM Leakage: One work
that extracts human speech through EM leakage is proposed
by Wang et al. [186]. In the proposed WiHear attack, the
attacker is able to capture the micro-movements of human
mouths by collecting and analyzing WiFi radio reﬂections,
with which they successfully infer up to 91% of speech
content. Furthermore, with leveraged multi-input multi-output
(MIMO) technology, they are able to infer multiple people’s
speech simultaneously with an accuracy of 74%. In this attack,
a multi-cluster/class feature selection scheme [189] is utilized
as a feature extractor, and dynamic time warping (DTW) [190]
is adopted for classiﬁcation.

Lessons Learned: Existing attacks on speech extraction
leakage
have exploited the vibrational and optical
caused by human speech. Given the threat of these
attacks, it is important to develop novel defense solu-
tions in this area.

D. Limitations and Opportunities

In this section, we will examine some limitations and

opportunities of information leakage attacks.

Dependency on stealthy malware: To successfully conduct
an attack, the ﬁrst step is to obtain raw data collected from
the target CPS. To increase the stealthiness of the attack,
the malware installed in the targeted system is designed to
behave as explicitly benign and only acquires insensitive
data as well as network access for ofﬂoading the user data.
However, there are limitations on the level of stealthiness the
malware can accomplish. These limitations are mentioned in
one paper [163], where the malicious application installed on
smartwatch runs in the background collecting data at a high
frequency, leading to high power consumption. This can be
signiﬁcant as the battery capacity of smartwatch is far smaller
than that of smartphone, thereby raising more suspicion.

Lessons Learned: This is often a limitation for many
information leakage attacks, as they are generally
dependent on malware to collect sensor data. To this
end, one possible defense against information leakage
attacks could be monitoring the power consumption
or resource usage for unique characteristics of the
malware.

Lack of generalization: Similar to the same limitation of
signal injection attacks, the attacker has to address variations in
both the user and targeted device to infer accurate information.
The proposed models in some existing research face the
challenge that they are not generalized for general targets
with large variations between them. The adversary has to
train the model separately for each possible conﬁguration
and pick the most suitable one which generates the most
sensible output. This is further validated in [164], where the
keystroke inference accuracy drops to 19% when data sets
used for training and evaluation are from different keypads,
comparing to 73% and 59% achieved in the same work when
using the same keypads. In recognition of this limitation, some
researchers test their models on several experimental devices
[160] or different users [162] to validate the generalizability.
investigation into the
variation of typing styles affecting acoustic-based keystroke
inference attacks and draw the conclusion that the strength
of the proposed acoustic eavesdropping attack is limited due
to the uncertainties brought about by different typing styles.
Similarly, Maiti et al. [163] also investigate popular typing
styles used by the public and discuss how various typing
scenarios can affect the effectiveness of vibrational keystroke
attacks, though they do not investigate the case where the user
holds the smartphone and types using both hands. In [150], the
orientation of the attacker’s deployed iPhone is shown to bring
uncertainty to the results of keystroke inference via vibrational
leakage.

Halevi et al. [154] take the ﬁrst

Lessons Learned: To the scope of this limitation, one
direction for attackers may be developing more robust
methodologies that can be applied to a wider range of
targets; or on the contrary, recognizing the relationship
between variations and user habits, collected sensor
data can be used to infer user identity as well.

Short distance for remote attacks: This limitation affects
only remote attacks. Compared to co-located attacks where the
attackers collect insensitive data from local sensor readings,
the remote attackers need to deploy their own sensing systems
within a certain distance of the target CPS. This, however,
violates the physical security of the area near the targets
and brings about a lack of stealthiness. More importantly,
the distance between deployed CPS and the target plays an
essential role that considerably affects the attack: even a small
increase in distance will dramatically reduce its effectiveness
and accuracy. Therefore, the attacker has to make a trade-off

between stealthiness and attack effectiveness. Generally, the
attacker has to place their CPS at a relatively short distance
from the target so as to reach a satisfactory attack accuracy.
Genkin et al. [151] conduct an acoustic-based task inference
attack by placing a mobile phone next to the target laptop
or a sensitive microphone at a distance of 4 meters away.
Backes et al. [180] show the results that the recognition rate
will drop to 4% with a distance of only 2 meters. Asonov et
al. [155] achieve an acoustic-based keystroke inference attack
at a maximum distance of 15 meters without physical invasion
of the target CPS. However, as is discussed in [153], similar
attacks can be defended against by ensuring the physical
security of machine as well as its surroundings. Especially
considering scenarios such as ATM pin pad entry, where
the users are sealed into a small space with effective sound
insulation, thus it becomes difﬁcult to collect acoustic data
from the outside at a distance. Marquardt et al. [150] conduct
a remote vibration-based keystroke inference attack where
they try to evade this problem by installing malware on the
victim’s iPhone placed nearby, which in turn plays the role of
the attacker’s sensing system by eavesdropping on a nearby
keyboard.

Lessons Learned: The root cause of the limitations
caused by large distance lie in the low signal-to-noise
ratio (SNR) of the collected data. One method to
compensate is to leverage machine learning to aid in
estimating the missing data.

Environmental noise: Apart from selecting equipment
sensitive enough for capturing signals, the attacker also has to
take ambient noise into consideration, which affects inference
accuracy dramatically. Although some subtle or regular noises
in the environment can be ﬁltered out by the attacker’s
malware, there still exist scenarios where noises cannot be
distinguished from target signals. Marquardt et al. [150] point
out that signiﬁcant vibrations caused by the user bouncing their
knees or tapping the desk will result in a loss of useful vibra-
tional data for keystroke inference. Though related research
such as [148] mitigates the negative inﬂuence of unexpected
movement of the user by integrating acoustic signals and
vibrations, effective mitigation remains an open problem. Also,
a task inference attack methodology is proposed in [151],
where Genkin et al. state that the typical noise environment is
concentrated at low frequencies while the acoustic leakage is
above this range, thus the attacker can easily ﬁlter out these
background noises.

Lessons Learned: From the attacker’s perspective, po-
tential interference should be taken into consideration
in the design. The very same noise, on the other hand,
can be an effective defense for the users.

Signal quality: For some attacks, the quality of signals
that are emitted by the target or received by sensing systems
is limited due to physical imperfections.

Some are limited by the sensing systems on the receiver
side. For example, in [162], the effectiveness of the proposed

28

keystroke inference attack is limited (30% ideally and less
than 20% practically) because the wearable device (i.e., smart-
watch) serving as sensing system is deployed on only one
wrist of the typist. The main problem encountered in [175]
is that the sample rate of the gyroscope embedded in user’s
phone lies below the Nyquist requirements for human speech,
resulting in the failure to recover speech content. Instead, the
attacker obtains information about the speaker, which requires
less information recovered from raw data.

Also, some attacks are limited by the target systems.
One simple method to mitigate the acoustic-based keystroke
inference attacks as discussed in [155] is for the user to
adopt a silent keyboard made of rubber, or a touch-screen
keyboard. Because the key principle behind acoustic leakage
is to differentiate sounds emanated by different keystrokes,
the attack could easily fail if acoustic signal emissions are
alleviated.

Lessons Learned: This limitation can shed light on
effective defenses against these attacks, where an ef-
fective mitigation strategy is to reduce the emanated
signal strength, such as by placing the keyboard on
a rubber layer or placing a ﬁlm over the computer
monitor.

VI. DEFENSE AGAINST CYBER-PHYSICAL ATTACKS

As cyber-physical attacks show an increasing threat across
CPS, it is as essential to investigate corresponding defenses as
to understand the principles of cyber-physical attacks. Existing
literature has demonstrated various ways to detect and prevent
attacks in the physical, cyber, cyber-physical, and application
domains. In this section, we will present existing defense
techniques corresponding to these categories.

A. Physical-Domain Defense

In the physical domain, the biggest challenge to defend
against cyber-physical attacks lies in the incapability of ma-
nipulating physical phenomena while probing them. This
brings two challenges to conventional defenses: (1) it becomes
difﬁcult to validate the authenticity of passively-sensed signals
via protected protocols or certiﬁcates like is done in networks
or software, and (2) emitted signals from CPS cannot be
encrypted or stopped from leaking sensitive information.

To handle these two challenges, two types of defenses are
proposed, which we refer to as environment veriﬁcation and
physical barriers. For the ﬁrst challenge, environment veriﬁca-
tion proposes to actively probe the surrounding environment
and validate signals with responses, while physical barriers
aim to prevent CPS from receiving speciﬁc types of signals
(e.g., EM signals) via physical isolation. On the other hand,
to prevent leaking information through signals, environment
veriﬁcation suggests that users clear the surrounding area
before interacting with CPS, and physical barriers propose to
isolate the CPS from open environments. More details about
these two types of defenses are discussed in the following.

29

Fig. 13: Filtering defense against optical information leakage using polarization mirrors. This phenomenon shows that two
linear polarization ﬁlters aligned at 90 degrees will block all light, while a single ﬁlter will let 50% of original unpolarized
light pass through. With proper set-up of polarization mirrors (one at the window and one at the screen), it will keep attackers
from eavesdropping without blocking the user’s normal use [172].

1) Environment veriﬁcation: As signal injection attacks
cause sensor readings to deviate from environment mea-
surements, one way to detect attacks is to actively probe
the environment and compare the probe reading with the
expected response. With this method, any major difference
between received signals and the expected response will be
considered as an indication of an attack. Kune et al. [78] adopt
this principle and design a defense where some investigative
actuation is cast on cardiac tissues, and cardiac signal readings
are compared to their expected values. Similarly, Muniraj
et al. [191] propose an “active detection” method where
judiciously designed excitation signals are superimposed on
control commands, thus leading to a set of acceptable behavior
for the system. Then the sensor will probe the environment,
and the aforementioned effect is expected to be reﬂected in
the sensor measurements if the system functions normally.

Also, for information leakage attacks, which generally suffer
from the limitation of short distance as discussed in Section
V-D, verifying the security of surrounding areas may be a
good choice before using devices. Zhuang et al. [153] propose
to ensure the physical security of the machine and room
by clearing bugging devices and using quieter keyboards
to prevent keystroke inference targeting physical keyboards.
Similarly, to counter the task inference attack proposed in
[172] that exploits reﬂections in human eyes, Backes et al.
suggest securing the surroundings and avoid any suitable
hiding places for a spying telescope.

2) Physical barrier: A physical barrier exterior to the target
CPS may also provide protection by offering better isolation
from the environment. To be more speciﬁc, the physical barrier
can be used both to reject exotic injected signals and to contain
sensitive information from leaking out.

An example is to use Faraday cage to protect against EM
interference, this technique is also referred to as shielding.
Besides, existing work has demonstrated some other shielding
techniques such as acoustic damping [80] [95] [81] [192],
optical isolation [94], physical separation [96] [193], and EM
shielding [13] [78] [99] [194].

Also, physical barriers have been shown to be effective
at preventing surrounding maliciously-used sensors from col-
lecting sensitive data,
thus mitigating information leakage
threats [150] [151] [180] [187]. For example, Marquardt et
al. [150] suggest placing mobile phones away from keyboards

(physical separation); Backes et al. [180] propose to mitigate
acoustic leakage from printers by either covering them with
acoustic shielding foam (acoustic damping) or keeping 2
meters of distance from sensors (physical separation); and
Genkin et al. [151] propose to use acoustic absorbers to
attenuate leaked signals (acoustic damping). This principle
has been adopted to prevent optical leakage as well. Fig. 13
shows a well-known phenomenon that two linear polarization
ﬁlters aligned at 90 degrees will block all light, while a single
ﬁlter will let 50% of original unpolarized light pass through.
With the proper set-up of polarization mirrors, it will keep
an attacker from eavesdropping without blocking the user’s
normal use [172].

On the other hand, however, the development of shielding
techniques is limited by three main drawbacks, which weaken
the effects of defenses and may even affect
the normal
functionality of target CPS.

• Imperfect isolation. In most scenarios, the isolation pro-
vided by shielding is not perfect due to physical ar-
rangement and sensor functionality. For instance, Kune
et al. [78] build a conducting shield exterior for webcams
but have to leave large holes for a number of components
including the camera lens, two large buttons on the side,
the microphone, and the mechanical stand. Similarly,
Tesche et al. [195] point out that the holes left for wires to
pass through cause a major degradation to the shielding.
• Signal blocking. People have found that while the shield
blocks external interference, it may negatively impact the
normal functionality of CPS as well. For example, it is
noted in [194] that magnetic shielding would prevent
light from reaching the sensor, and dampening foam
utilized to protect an HDD from side acoustic attacks
will signiﬁcantly reduce the HDD’s susceptibility to write
blocking [192].

• Scenario restriction. As this defense adds an exterior
barrier or physical distance to the CPS, it may not be
applicable for some scenarios. Marquardt et al. [150]
state that although distancing can achieve good perfor-
mance in preventing side-channel inference attacks with
surrounding phones, it may be too restrictive for most
corporate and home environments where mobile phones
are commonly used, and thus isolating phones from
keyboards becomes impractical.

Lessons learned: These two types of defenses are good
initial steps to leverage the physical world to defend
against cyber-physical attacks. However, challenges
still remain in two main aspects: (1) how to verify
passively sensed signals where active probing is infea-
sible (e.g., accelerometer and gyroscope); and (2) how
to prevent CPS from leaking signals without blocking
their normal functionalities.

B. Cyber-Domain Defense

Conventional cyber defenses such as ﬁrewalls [196] and
trusted execution environments (TEE) [197] are commonly
adopted to secure cyber data. However, they cannot be directly
applied to effectively defend against cyber-physical attacks
because of two challenges: (1) lack of the ability to distinguish
maliciously injected signals from benign input, as a result,
the malicious inputs cannot be processed and eliminated; (2)
inability to prevent signal
leakage, especially those previ-
ously considered as non-sensitive such as accelerometer and
gyroscope data, which has been demonstrated to have great
potential for physical activity inference.

To solve each challenge correspondingly, new method-
ologies have been proposed, which we summarize as three
general directions: (1) use signal analysis techniques to extract
the unique differences between injected signals and benign
input, therefore distinguishing the injected signals; (2) change
the way that digital signal data are processed and sent for
actuation, such as data ﬁltering and sensor fusion, in an effort
to prevent malicious signals from inducing effects on CPS. In
this way, although the injected signals are received by CPS
as plausible input, the other attack requirement of meaningful
response will not be met (Section IV-A); and (3) mask the
signal data to prevent leaking physical information, generally
via adding noise for obfuscation. These mechanisms will be
discussed in more detail in the following.

1) Signal analysis: Researchers have investigated the dif-
ferences between attack signals and legitimate signals, thus
coming up with another defense by analyzing the received
signal data to only pick the legitimate parts. Machine learning
and frequency-domain analysis are the two commonly adopted
methods for distinguishing benign and malicious signals.

• Machine learning. In this ﬁeld, machine learning tech-
niques commonly act as tools to distinguish malicious
and legitimate signals. For instance, [75] and [77] extract
15 features from audio data and utilize a supported vector
machine (SVM) as a classiﬁer, and achieve a result
of 100% true positive and true negative in detecting a
dolphin attack. Also, Tharayil et al. [198] propose two
sensor defense in-software (SDI) methods, one of which
is designed to distinguish the benign and malicious sensor
output with one-sided or two-sided classiﬁers pre-trained
on benign and spoofed traces.

• Frequency analysis. Besides machine learning methods,
researchers have discovered unique characteristics of
frequency distributions of attack signals that help with
distinction. To extract and analyze frequency properties

30

such as harmonics and frequency components, com-
monly utilized techniques include spectrograms [76] and
frequency-domain analysis [77] [199]. For instance, Roy
et al. [76] manage to detect the injected signal modulated
with ultrasound signals because of the well-understood
patterns of fundamental frequencies shown in the spectro-
gram. Similarly, Blue et al. [199] differentiate the audio
created by humans and electronic devices by identifying
the presence of low-frequency components inherent to the
speakers but outside of the human voice range.

2) Data ﬁltering: Filtering is designed to mitigate mali-
cious signal values in the cyber domain while minimizing
changes to legitimate signals. Due to the simplicity and low
cost of implementation, the adoption of ﬁltering has been
seen across literature defending against EM [13] [78] [194],
optical [92], and acoustic [95] [81] attacks. Overall,
this
technique can be categorized based on the ﬁlter type utilized
for defense as follows:

• Cutoff ﬁltering. This refers to the defense where low-
pass ﬁlters (LPF), high-pass ﬁlters (HPF), and band-pass
ﬁlters (BPF) are adopted to ﬁlter out unwanted content
in the received signal data. For example, Kune et al. [78]
successfully attenuate the injected EM signal by 40dB
with the help of LPF, while still allowing the audio signals
to pass through Bluetooth headsets. Trippel et al. [81]
suggest using LPF with a cut-off frequency of less than
half of the ADC sampling rate to prevent signal aliasing,
thus effectively preventing signal injection attacks.
Moreover, this technique will ﬁlter out leaked sensitive
data when it passes through. Michalevsky et al. [175]
state that the usage of LPF will help to ﬁlter out the
unintentionally collected speech data in motion sensors,
and therefore making it difﬁcult to extract speech from
ﬁltered signals. Another similar example is that the notion
of ﬁltering can be applied to optical signals. In [172],
optical notch-ﬁlters that serve as a band-stop ﬁlter are
adopted to ﬁlter out the narrow spectrum of LEDs.

• Adaptive ﬁltering. Different from cutoff ﬁltering where
the threshold for ﬁltering is ﬁxed, adaptive ﬁltering ﬁrst
extracts certain characteristics within attack signals, and
then ﬁlters out signals using these features. Following
the proposed cutoff ﬁltering method, Kune et al. [78] also
propose to utilize an additional wire to probe the ambient
EM level, and then cancel out the injected signals with
collected EM values.

3) Sensor fusion: One of the most popular defenses is to
fuse sensor data collected from multiple distinct sensors [200],
and this technique has been applied in various CPS such as
robots [201] [202], UAVs [203] [204], medical body sensor
networks (BSN) [205], and most commonly, autonomous vehi-
cles [206] [207]. In this category, people either add redundant
sensors of the same type, or fuse heterogeneous sensors of
different
types. As such, even if the attacker successfully
spoofs one target sensor, the inconsistency of other sensor
readings will reveal the existence of an attack. Therefore,
sensor fusion requires the attacker to attack multiple sensors
almost simultaneously and thus raises the bar for an attack.

• Redundant sensors. One method is to add redundant sen-
sors with the same type to detect and monitor unexpected
signals. Bolton et. al. [192] propose to add an additional
microphone or fuse several vibration sensors to detect an
out-of-band ultrasound injection attack. Similarly, Shin et
al. [106] propose to add multiple LiDAR sensors to form
an overlapping ﬁeld of view, and thus mitigating the effect
of saturating and spooﬁng to some extent. Though this
kind of defense is not perfect and may not prevent well-
designed attacks, it will signiﬁcantly increase the efforts
required for a successful attack.

• Fusing heterogeneous sensors. Another method is to fuse
data collected from sensors of different types, such as
combining the data of a gyroscope and a magnetometer.
One typical example is given in [198], where Tharayil et
al. determine the mathematical relationships between the
measured magnet and vibration data collected from the
magnetometer and gyroscope, with which the fused data
will identify injection attacks in the cyber domain.

4) Adding noise for obfuscation: Intentionally combining
noise with signals has been shown to be one of the simplest
and most effective methods to prevent information leakage
attacks [166] [169] [148] [151] [187]. For instance, Ha et
al. state that adding random noise to the vibration signals
makes the buttons indistinguishable for the keystroke inference
attack proposed in [166]. Their experiments show that by
adding uniform random noise varying from half to double
the magnitude of the vibration signal, the performance of
the attack sharply deteriorates. Similarly, Liu et al. [148]
propose to have the keyboard or PC/laptop speakers generating
white noise during the user’s typing, which can disturb the
malicious app which requires an accurate acoustic data stream
for inference. In the same vein, Genkin et al. [151] propose to
defend against RSA acoustic inference by masking the leaked
signals with a carefully designed acoustic noise generator.

Lessons learned: Different from traditional cyber de-
fenses, these defenses implemented in the cyber do-
main are more effective in detecting and mitigating
malicious injections, as well as masking leaked infor-
mation. With the rapid development of sensors and
IoT devices, sensor data will become increasingly in-
tertwined to better sense the physical world. However,
as it raises the bar for injecting malicious commands
via signals, it also leaves more attack surfaces for
eavesdropping. Therefore, how to preserve privacy in
the context of sensor fusion leaves an open question.

C. Cyber-Physical-Domain Defense

As sensors serving as interfaces between cyber and physical
domains are widely exploited for attacks, people are seeking
to prevent attacks by combining physical stimuli with cyber
processing techniques to reduce the system’s susceptibility to
cyber-physical attacks. It should be noted that, however, de-
fending against information leakage by improving the sensing
layer can be tricky, due to the fact that sensing surrounding
physical phenomena is what sensors are designed for.

31

For defending against signal injection attacks, the challenges
faced by defenders are similar to what is mentioned in previous
sections, i.e. how to distinguish maliciously injected signals
and how to eliminate them to prevent meaningful response. To
solve these challenges, numerous defenses have been proposed
that can be categorized into two general categories: (1) adding
non-spoofable patterns to the signal itself and the conditioning
path, such as sampling patterns and stimulus randomization,
aiming to distinguish malicious signals via users’ enriched
knowledge (i.e., signal patterns) over the attackers [81] [208];
and (2) improving the design of the cyber-physical layer to
mitigate injected signals, as described in improve sensor design
and symmetric receiver, again by preventing the attackers from
satisfying meaningful response [96] [78].

1) Sampling patterns: As discussed in Section IV-C2,
in existing literature on signal injection attacks, ADCs are
commonly exploited as demodulators due to the intentionally
caused signal aliasing effects. However, simple changes to
the sample rate (e.g., increase or decrease the sample in-
terval) may not be effective, as the attacker can still craft
corresponding signals because the demodulated signal can
be predicted according to the ﬁxed sample rate. Therefore,
researchers have added patterns to the sampling process, most
commonly randomized sampling patterns, to prevent attacks
with unpredictable demodulated signals. It is ﬁrst proposed by
Trippel et al. [81] where they protect the accelerometers by
using randomized ADC sampling, and thus the predictability
of ADC’s sampling regime is eliminated. Following this work,
Tu et al. [95] propose to adopt dynamic sampling which
has similar functionality to randomized sampling but has the
advantage of maintaining the accuracy of inertial measure-
ments. Besides, out-of-phase sampling proposed by Trippel
et al. [81] also adopt a special sampling pattern related to
the frequency such that the frequency components near the
resonant frequency are removed.

For information leakage attacks, [150], [160], [147], and
[149] propose that simply reducing the sensor sampling rate
can help mitigate side-channel inference attacks by giving out
fewer data. One extreme case is, as proposed by [160], to
completely pause the functionality of motion sensors when
the user is typing on the phone. However, it should be noted
that this approach may downgrade the normal functionality of
legitimate use of sensors.

2) Stimulus randomization: There is also a direction of
defense in which the users add random patterns to the emit-
ted stimulus in the physical domain and expect
to detect
reﬂected patterns in the received signals within the cyber
domain [106] [208] [209] [210]. With this method, an attack
will be detected if the received signal does not match the
pattern due to the attacker being unable to predict them, and
thus being unable to craft plausible signals.

• Add operating pattern. One way to add patterns is to
manually set operating patterns in sensors and systems.
Physical challenge-response authentication (PyCRA) is a
typical scheme that falls into this category where the
emitter is turned off at random instants, and any re-
ceived signals during this pause indicate a signal injection
attack [208]. Also, Shoukry et al. [208] state that the

attacker will ﬁnd it difﬁcult to take real-time actions
to blend in with the pattern (e.g., seize the transmitted
spoof signals during the pause period of sensors), as
they are limited by physical and computational delay. In
the context of medical infusion pumps, Park et al. [94]
follow PyCRA and detect spooﬁng attacks by turning
off the drop sensor at random instants. More recently,
Zhang et al. [209] propose a similar pattern to detect
electromagnetic interference attacks.

• Manipulate signal parameters. On the other hand, crafted
patterns can be achieved by manipulating signal pa-
rameters. For example, Shin et al. in [106] propose to
transmit pulses with randomized waveforms and reject
pulses different from the transmitted ones to prevent
lidar spooﬁng attacks and mitigate inter-lidar interference.
Similarly, Xu et al. [210] use this scheme to enhance
security of the ultrasound sensors in autonomous vehicles
by randomly manipulating several physical parameters of
the waveform.

3) Improve sensor designs: Besides adding more redun-
dant sensors to the target CPS, people have proposed ways
to improve the sensor design to prevent attacks. For example,
Trippel et al. [81] suggest designing a secure ampliﬁer by ei-
ther enlarging its tolerance of large amplitude inputs leveraged
by acoustic interference, or adding an LPF or band-stop ﬁlter
to conduct pre-ﬁltering before the signal enters the ampliﬁer.
Son et al. [80] propose to adopt an additional feedback
capacitor connected to the sensing electrode, with which the
resonant frequency and the magnitude of the resonance effect
can be tuned to prevent attacks.

Moreover, some vulnerable sensors can be replaced with
ones that are less susceptible to attacks but show similar func-
tionalities. For instance, both [192] and [96] propose to replace
HDDs with Solid-State Drives (SSDs) to mitigate acoustic
attacks exploiting the resonance of moving components that
are susceptible to vibration.

4) Symmetric receiver: As unintended receivers play an
important role in out-of-band signal injection attacks to meet
the plausible input requirement (Section IV-C), researchers
have found a way to mitigate injected signals by adopting sym-
metric differential circuits. The key idea is to make the target
CPS receive injected signals from two ends, thus canceling the
common mode interference present in differential inputs. One
typical example is shown in the design of a pacemaker, where
the original design of one single conductor in lead connected
to the cardiac tissue is phased out by a bipolar lead [211].
Following this work, Kune et. al [78] conduct experiments
under similar conditions and observe an attenuation of the
injected signal by 30dB using a bipolar lead.

Lessons learned: These proposed defenses in the cyber-
physical layer primarily focus on improving hardware
design in the signal conditioning path. While they are
effective in differentiating and mitigating the effects
of the injected signals, it remains an open question
how this principle can be leveraged to defend against
information leakage attacks.

32

D. Application-Domain Defense

As mentioned in Section IV-A3, sensor readings can directly
inﬂuence application behaviors. While signal injection attacks
generally happen within hardware to craft malicious sensor
output, defenses in the application layer is tricky as sensor
readings have already been disrupted. However, techniques
introduced in this domain can still be used to defend against
information leakage attacks.

1) Access permission: One key cause of the big threat
brought about by information leakage attacks is that access to
the “less” sensitive sensor data is not well protected. Therefore,
to address this problem, a proper method of authentication
and access permission control are proposed to prevent these
attacks [147] [148] [166] [163] [169].

Also, Liu et al. [148] propose two ways to prevent attacks
by either introducing new permission controlling into Android
OS and leaving the permission choice to the users, or by
adding dynamically-granted permissions mediating access to
sensors. Similarly, Ha et al. [166] propose to add a second
authentication system such as an ID card system, thereby
adding another layer of security to prevent keypress inference
attacks targeting door locks; and Xu et al. [161] propose to
modify the system such that motion sensors are considered
sensitive and require permissions to access.

2) Reduce application sampling: This refers to the defense
where the user can reduce the rate that applications sample
data collected from sensors [163]. Different from the afore-
mentioned permission control method that forbids unwanted
data access, this defense allows sensors to collect data but
reduces the application’s access to them and therefore brings
the challenge of inferring useful information with pieces of
fragmented data. It should be noted that this defense will be
effective for applications that occasionally use sensor data at a
low frequency, such as text editors, but may not be appropriate
for applications such as games which demand high-frequency
usage of sensor data for accurate and prompt feedback.

3) Parallel

task masking: As signal leakage is hard to
completely eliminate, another direction to defend against in-
formation leakage is to add parallel workloads on the target
CPS. The key idea is to mix the sensitive signals with leakage
of less important tasks or dummy tasks, thus the inference
will be inaccurate or even fail. In [151], the countermeasure
against RSA key acoustic inference is to induce additional
load on the CPU, thus the extra computation in parallel will
mask the leakage of the decryption operation. Similarly, Song
et al. [179] propose to inject dummy tasks for printer nozzles,
and thus the additional tasks with the same nozzle speed will
be convoluted with the protected printing process.

Lessons learned: Most existing application-domain de-
fenses focus on the prevention of information leakage
attacks by restricting applications’ behaviors. These
measures show effectiveness for co-located attacks,
but the attacker may still be able to launch the attack
via crafted applications on their malicious devices.
However, given the ease deployment, these defenses
are favored for real-world implementations.

33

TABLE IV: Summary of Existing Literature by Sensors

Target Sensor
Microphone
MEMS Accelerometer
MEMS Gyroscope
Camera
Temperature Sensor
Photodetector/Ambient Light Sensor
Magnetometer
GPS Sensor
Infrared Sensor
LiDAR
Radar
Ultrasonic Sensor

IB Injection
(cid:88)
×
×
(cid:88)
×
×
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

OoB Injection
(cid:88)
(cid:88)
(cid:88)
×
(cid:88)
×
×
×
×
×
×
×

Info Leakage
(cid:88)
(cid:88)
(cid:88)
(cid:88)
×
(cid:88)
(cid:88)
×
×
×
×
×

References
[86], [85] [87], [117] / [75], [97], [99], [118]
[95] [98], [81] / [167], [159], [147], [160]
[95] [80], [98] / [160] [159], [161], [167]
[82], [92], [110], [111], [114], [113] / [156], [187]
[100]
[187], [157]
[105], [98] / [178], [179], [169]
[115], [112], [83], [108]
[94]
[92], [106], [125], [107]
[93]
[93]

IB Injection = In-band signal injection, OoB Injection = Out-of-band signal injection, Info Leakage = Information leakage attack
* References in this table serve as examples of papers belonging to the categories shown in left to right order.

E. Real World Countermeasures

Besides the aforementioned efforts made by academia, in-
dustrial companies have become increasingly aware of cyber-
physical threats and multiple measures have been taken to
secure devices. As discussed in Section V, motion sensors such
as gyroscopes and accelerometers have been exploited to infer
sensitive information such as human speech and keystrokes,
and these data can be easily accessed via a browser’s API.
We investigated this issue on IOS 9/10/11/12 and found that
default access to motion sensors in Safari has been removed
since version 12.2 [212]. Additionally, Apple has implemented
adding noise for obfuscation (Section VI-B) by adding ran-
dom noise to sensor outputs in an effort to defend against
information leakage attacks. Google Chrome also developed a
new feature to inform the user of sensor data being extracted,
enabling users to block a site’s use of sensors and manage
associated permissions [213]. Other popular browsers such as
Firefox [214] and Vivaldi [215] have taken similar measures
for defense as well.

However, current real-world defenses against cyber-physical

attacks still face two challenges.

First, they rely heavily on application-domain defenses to
protect against cyber-physical attacks. However, the effective-
ness of these defenses is limited. For signal injection attacks,
they are unable to prevent injected signals from being received
by CPS, since the malicious commands are not distinguished at
the application level. For information leakage attacks, restrict-
ing applications’ sensor access on mobile apps can mitigate co-
located attacks, but the adversary may still launch the attack
with their own devices in physical proximity with the victim.
Compared to traditional cyber attacks, developers and users
have less knowledge of the low-level sensor structure and
signal processing [66], which is abstracted away intentionally
to simplify the development process. However, such a level of
understanding is critical for developing effective defenses.

Second, cyber-physical attacks vary greatly in terms of
the
working principles and techniques. For some attacks,
attacker and victim are on the same physical computing device.
For instance, the current restrictions on users’ access to motion
sensors will mitigate the threat of information leakage via
vibrational signals [175] [176], but it will not prevent the
attacker from eavesdropping through optical [173] or EM

leakage [152]. Also, the attacker is still able to manipulate
motion sensor readings by injecting acoustic signals [80].
Compared to the rich diversity in attack vectors, existing
defenses often focus on mitigating speciﬁc vectors. This is
because defenses against each vector can be signiﬁcantly
different from each other, and defenders have to resort to
prioritizing high-risk vectors ﬁrst.

Therefore, a generalized defense that tackles these chal-
lenges will likely require efforts in both academia and industry,
not only to come up with the solution but also to deploy it.

VII. FUTURE OUTLOOK OF CYBER-PHYSICAL SECURITY

Previous sections have demonstrated recent advances in the
ﬁeld of cyber-physical attacks and defenses. However, given
the limitations of existing attacks and remaining challenges
of defenses,
there is still a large space left for research.
Therefore, in this section we propose three questions to inspire
new research: (1) what potential threats can cyber-physical
attacks post to new technologies; (2) what attacks have yet
to be explored; and (3) what are the potential directions for
developing novel defenses. Although these three remain open
questions and are yet to be answered, we believe there are large
opportunities left that will require efforts from both academia
and industry to be fully explored.

A. Cyber-Physical Threats in New Era

The integration of the cyber and physical world is pro-
gressing rapidly due to recent advances in related ﬁelds such
as computer communications. While new technology such as
5G will bring unparalleled beneﬁts to society, it also enables
new attacks. In the following we will use 5G and ransomware
as examples to discuss how these two emerging technologies
could impact the attack landscape of CPS.

1) 5G communication: 5G being one of the major de-
velopments in communication technologies will have a large
impact and deployment on cyber-physical systems [216] [217],
such as virtual reality [218], autonomous vehicle [219], and
smart grid [220]. As such,
it will bring about signiﬁcant
changes in the threat landscape [221], as well as the new
defenses [222] [223]. From the communication perspective,
millimeter-wave communication and massive MIMO technol-
ogy will bring revolutionary changes to how content can be

delivered. From the network layer, software-deﬁned networks
will catalyze service-oriented architecture to enable network
utilization more efﬁciently than ever before. The massive
bandwidth and low latency communication from service-
oriented architecture will change not only the richness and
amount of content that can be delivered to a network node,
such as a self-driving car, but also change the granularity and
speed of sensing. It becomes possible for a self-driving car to
receive live updates of detailed trafﬁc information miles away
in a crowded city and take corresponding action [224].

From the security perspective, there are two key changes.
First, 5G has become the new frontier of wireless attacks.
Existing attacks on cellular networks can still be attempted by
attackers, such as attempting to obtain authentication without
the right credentials [225]. The massive MIMO and SDN
may also allow network attacks to aim to degrade perfor-
mance [226]. Second, this new architecture may change the
scale of sensor attacks, since using networks, CPS can not
only gain more sensing input, it might also utilize distributed
computing elements such as the edge and cloud to aid in the
decision process [216] [217]. In order to mislead such CPS,
a single sensor injection will most likely be unsuccessful. On
the other hand, from the information leakage perspective, the
amount of sensor data will allow for much better extraction
of physical world activity. While it helps CPS in enabling a
better decision, the amount of ﬁne-grained data can pose a
signiﬁcant threat to individual privacy [227] [228]. In the re-
cent pandemic caused by COVID-19, many regions and coun-
tries have adopted aggressive contact tracing [229] [230] and
surveillance technology [231] to ﬁght the spread of the disease.
A potential fruitful direction is to employ privacy-preserving
computation techniques to extract knowledge from data with-
out leaking information on user private data [232] [233]. In
a 5G environment, it is possible to take such surveillance
to a different level, and many have raised concern over this
to ﬁnd the delicate
privacy aspect [234]. It
balance between degradation in privacy and societal beneﬁts
when it comes to 5G-enabled sensing. We believe secure
communication technology will pave the path in this front
towards achieving the best of both.

is important

2) Ransomware: Another potential

frontier of cyber-
physical security is an attack from cyber space to the phys-
ical world in the form of ransomware [235]. As discussed
in Section V, existing work has revealed the threat where
attackers can eavesdrop on physical phenomenon via leaked
signals. Besides implicitly containing information about the
physical world, cyber data can be more valuable if they are
critical to maintaining the functionality of various devices
and infrastructures. Recently, a patient lost her life due to
a ransomware attack locking up the hospital system [236].
There have also been demonstrations of
ransomware on
automobiles [237] [238] as well as hardware-harden ran-
somware [239]. With the rapid demand and deployment of
sensors in various devices and facilities, sensor data will be
playing an increasingly important role in the control loop of
CPS. As such, ransomware attacks targeting sensor data are
likely to occur, and could cause fatal outcomes to individuals
and serious impacts on society as a whole. It is highly probable

34

that in the future where our society increasingly relies on
computing systems and sensing components, an attack from
cyberspace can easily place a ransom on the user’s well-being.
It is important to start seeking mitigation methods not just in
ensuring the availability of the data, but also the availability
of the system.

B. Evolution of the Attack Landscape

Although the ultimate goal of systemizing cyber-physical
attacks is to develop effective defenses, the exploration of new
attacks is also a vital role as it enables a better understanding
of the threats at play, thus inspiring novel defenses. Therefore,
in this section we will discuss the unexplored areas from an
offensive perspective.

As presented in Section IV and V, existing cyber-physical
attacks can be categorized based on attack vectors. Since attack
vectors are closely related to the target sensors, summarizing
existing attacks by sensors can provide a clear high-level view
of research in this area. This is shown in Table IV, which
shows that some sensors such as microphones, accelerometers,
and gyroscopes have been exploited for both signal injection
and information leakage attacks. However, some other sensors
such as temperature sensors and ultrasonic sensors have less
research on them. This leads to three directions of potential
development, which will be discussed in the following.

Firstly, attackers may develop unexplored attacks targeting
known sensors listed in Table IV (marked as ×). For in-
stance, there is only one work on injecting in-band signals
into infrared sensors, but is it possible to inject out-of-band
signals without using the optical vector? Also, how can
attackers leverage infrared sensors to eavesdrop on physical
information? Similarly, the ambient light sensor has only been
exploited to steal physical information, but how can attackers
manipulate system behavior by injecting signals into ambient
light sensors? These remain open questions.

Secondly, attackers may target new sensors. For example,
the MEMS barometer widely exists in smartphones to provide
altitude information and weather forecasting, and attackers
may exploit this sensor to conduct signal injection or informa-
tion leakage attacks. Given the rapid development and wide
deployment of new sensors, we believe new attacks can be
proposed targeting CPS and IoT devices equipped with them.
Lastly, when developing new attacks, the selection of the
attack vector is of vital importance and determines the method-
ology to be adopted. Therefore, relevant physical correlations
must be considered. As an example, the correlation between
acoustic and vibrational signals has been fully researched,
where sensitive audio can be inferred from less-protected
vibrational signals [173] [175] [176], while at the same time
injected acoustic signals can be leveraged to spoof motion
sensor output for malicious goals [80] [95]. Researchers may
attempt to discover other correlations between physical ema-
nations and exploit them as new attack surfaces. For example,
optical light contains energy that has been maliciously crafted
to induce voice commands on VCAs [118]. How can attackers
leverage this correlation to inject other out-of-band signals?

To sum up, new attacks can be inspired by unexplored attack
types, new sensor targets, and physical correlations. These
directions leave open questions to the research community.

C. Directions of Defenses

In Section VI, we present multiple limitations faced by
conventional cyber defenses when dealing with cyber-physical
attacks. For these reasons, researchers have proposed defenses
in each layer of CPS architecture to protect systems. However,
existing defenses can still be limited to certain application sce-
narios. In the following we will provide a new perspective to
understand the existing defenses based on attack requirements
and discuss potential future research directions.

As discussed in Section IV-A and V-A, there are several nec-
essary conditions for signal injection attacks and information
leakage attacks. Effective defenses can be built by preventing
the attacker from meeting one or more of these conditions.

For signal injection attacks, the attack requirements are
plausible input and meaningful response. From this perspec-
tive, some existing defenses (e.g., physical barrier) [94] [80]
propose to block CPS from receiving external signals so that
the malicious signals will not be taken by the system as
plausible inputs, i.e. the ﬁrst requirement will not be met.
However, existing defenses in this direction are still primitive
as they will harm the normal functionalities of CPS due to the
blocked sensing components. To solve this challenge, many
other defenses turn to the second requirement by detecting
or eliminating the received injected signals. Commonly used
techniques include signal analysis, signal processing (e.g.,
data ﬁltering), and improved sensing-layer designs such as
symmetric receivers and sampling patterns [81] [78]. In this
way, the malicious signals will not induce any meaningful
effects even if they are taken as plausible inputs by the CPS.
For information leakage attacks, the corresponding attack
requirements summarized in Section V-A include covert ex-
traction, data exﬁltration, and information recovery. As dis-
cussed in Section VI-E, some proposed defenses (e.g., ac-
cess permission and reduce application sampling) as well
as industrial solutions put emphasis on the ﬁrst require-
ment [147] [163]. There are also efforts that focus on the third
requirement, such as adding noise for obfuscation and parallel
task masking [151] [179]. Therefore, the existing work has
examined defenses in two categories: limit the applications’
extraction of sensor data to prevent covert extraction, and mask
the sensor data to mitigate information recovery.

In summary, although the implementation of defenses may
vary, their working principles can be understood and catego-
rized based on our proposed attack requirements. Therefore,
an in-depth understanding of the attack requirements plays an
important role in developing effective defenses. New defenses
can be inspired by the remaining challenges and unexplored
attack requirements. For signal
injection attacks, existing
defenses on plausible input will block legitimate sensing
together with malicious signals, which therefore degrades the
functionality of CPS. As such, it could be a research direction
that seeks to differentiate the malicious signals and block them
before they reach the target CPS. For example, shielding mi-
crophones from ultrasound may serve as an effective defense

35

against out-of-band acoustic attacks, which rely on ultrasound
as the carrier wave. As a result, the functionality of these
devices will not be affected as the audible sound can still
be sensed. For information leakage attacks, defenses that are
based on the second requirement, data exﬁltration, have not
been explored. Following this direction, researchers may make
use of network techniques to detect and intercept the network
trafﬁc that sends out unauthorized sensor data.

Additionally, it is noteworthy that when considering general
defenses against various cyber-physical attacks, there are two
key factors: (1) the two attack categories, signal injection
and information leakage, differ signiﬁcantly from each other
in terms of attack model, as they are conducted in reverse
directions; (2) even within the same attack category, working
principles and adopted techniques of different attacks vary ac-
cording to the attack type (e.g., in-band and out-of-band signal
injection) and vector (e.g., EM and optical). To this end, any
single defense is not a once-and-for-all solution. Especially
with an increasing number of threats that combine multiple
attack vectors, it is important to consider the composition of
defenses as well. This, therefore, raises some open questions
to be answered. What is the most effective strategy for defense
fusion? What is the optimal number of defenses? What is the
best way to correlate and communicate among these defenses
securely? These open questions are yet unexplored.

VIII. CONCLUSION

In this paper, we systemize an emerging category of cyber-
physical attacks that exploit the interface between cyber and
physical domains to perform signal injection and information
leakage attacks. Given the challenges of conventional defenses
when faced with cyber-physical attacks, we discuss and map
existing defenses in the literature to individual attack vectors.
In light of this emerging threat, gaining a fundamental
understanding of the existing cyber-physical attack surface is
of vital importance, and paves the path towards generalized
defense mechanisms for this cyber-physical interface. Partic-
ularly, during the effort of systemization, we ﬁnd unexplored
areas of attack, such as leveraging geo-speciﬁc signals to
eavesdrop on physical information. We also provide an ab-
straction of necessary conditions for cyber-physical attacks,
and discuss how defenses can be constructed by disabling
one or more of these conditions for the adversary. Through
this paper, we hope to offer our perspective on the emerging
landscape of cyber-physical security, and call for joint efforts
of academia and industry to fuel further research in the ﬁeld
to protect critical technologies of the future.

ACKNOWLEDGMENTS

The authors would like to thank the anonymous reviewers
for their constructive comments on this paper. This work was
supported in part by US National Science Foundation un-
der grants CNS-1837519, CNS1950171, CNS1949753, CNS-
1916926, and CNS-2038995.

REFERENCES

[1] M. H. Cintuglu, O. A. Mohammed, K. Akkaya, and A. S. Uluagac, “A
survey on smart grid cyber-physical system testbeds,” IEEE Commu-
nications Surveys & Tutorials, vol. 19, no. 1, pp. 446–464, 2016.
[2] J. Giraldo, E. Sarkar, A. A. Cardenas, M. Maniatakos, and M. Kantar-
cioglu, “Security and privacy in cyber-physical systems: A survey of
surveys,” IEEE Design Test, vol. 34, no. 4, pp. 7–17, Aug 2017.
[3] “Internet of things forecast - ericsson mobility report,” Jun 2019.
https://www.ericsson.com/en/mobility-report/

[Online]. Available:
internet-of-things-forecast

[4] “An incisive, in-depth analysis on the cyber physical systems market,”
[Online]. Available: https://www.futuremarketinsights.

April 2018.
com/reports/cyber-physical-systems-market

[5] Y. Z. Lun, A. D’Innocenzo, I. Malavolta, and M. D. D. Benedetto,
“Cyber-physical systems security: a systematic mapping study,” ArXiv,
vol. abs/1605.09641, 2016.

[6] H. He and J. Yan, “Cyber-physical attacks and defences in the smart
grid: a survey,” IET Cyber-Physical Systems: Theory Applications,
vol. 1, no. 1, pp. 13–27, 2016.

[7] J. Liu, Y. Xiao, S. Li, W. Liang, and C. L. P. Chen, “Cyber security and
privacy issues in smart grids,” IEEE Communications Surveys Tutorials,
vol. 14, no. 4, pp. 981–997, Fourth 2012.

[8] M. Krotoﬁl and D. Gollmann, “Industrial control systems security:
What is happening?” in 2013 11th IEEE International Conference on
Industrial Informatics (INDIN), July 2013, pp. 670–675.

[9] G. Wu, J. Sun, and J. Chen, “A survey on the security of cyber-physical
systems,” Control Theory and Technology, vol. 14, no. 1, pp. 2–10, Feb
2016. [Online]. Available: https://doi.org/10.1007/s11768-016-5123-9
[10] S. Han, M. Xie, H. Chen, and Y. Ling, “Intrusion detection in cyber-
physical systems: Techniques and challenges,” IEEE Systems Journal,
vol. 8, no. 4, pp. 1052–1062, Dec 2014.

[11] R. Mitchell and I.-R. Chen, “A survey of

intrusion detection
techniques for cyber-physical systems,” ACM Comput. Surv., vol. 46,
no. 4, pp. 55:1–55:29, Mar. 2014.
[Online]. Available: http:
//doi.acm.org/10.1145/2542049

[12] I. Giechaskiel and K. B. Rasmussen, “Sok: Taxonomy and challenges
of out-of-band signal injection attacks and defenses,” arXiv preprint
arXiv:1901.06935, 2019.

[13] I. Giechaskiel, Y. Zhang, and K. B. Rasmussen, “A framework for
evaluating security in the presence of signal injection attacks,” arXiv
preprint arXiv:1901.03675, 2019.

[14] C. Yan, H. Shin, C. Bolton, W. Xu, Y. Kim, and K. Fu, “Sok: A
minimalist approach to formalizing analog sensor security,” in 2020
IEEE Symposium on Security and Privacy (SP), pp. 480–495.
[15] K. Koscher, A. Czeskis, F. Roesner, S. Patel, T. Kohno, S. Checkoway,
D. McCoy, B. Kantor, D. Anderson, H. Shacham, and S. Savage,
“Experimental security analysis of a modern automobile,” in 2010 IEEE
Symposium on Security and Privacy, 2010, pp. 447–462.

[16] S. Woo, H. J. Jo, and D. H. Lee, “A practical wireless attack on
the connected car and security protocol for in-vehicle can,” IEEE
Transactions on Intelligent Transportation Systems, vol. 16, no. 2, pp.
993–1006, 2015.

[17] S. Nie, L. Liu, and Y. Du, “Free-fall: Hacking tesla from wireless to

can bus,” Brieﬁng, Black Hat USA, pp. 1–16, 2017.

[18] K.-T. Cho and K. G. Shin, “Viden: Attacker identiﬁcation on in-vehicle
networks,” in Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security, ser. CCS ’17. New York,
NY, USA: Association for Computing Machinery, 2017, p. 1109–1123.
[Online]. Available: https://doi.org/10.1145/3133956.3134001

[19] M. Salfer and C. Eckert, “Attack surface and vulnerability assessment
of automotive electronic control units,” in 2015 12th International Joint
Conference on e-Business and Telecommunications (ICETE), vol. 04,
2015, pp. 317–326.

[20] T. Hoppe, S. Kiltz, and J. Dittmann, “Security threats to automotive
can networks—practical examples and selected short-term countermea-
sures,” Reliability Engineering & System Safety, vol. 96, no. 1, pp.
11–25, 2011.

[21] W. Xu, K. Ma, W. Trappe, and Y. Zhang, “Jamming sensor networks:
attack and defense strategies,” IEEE network, vol. 20, no. 3, pp. 41–47,
2006.

[22] S. Checkoway and H. Shacham, “Iago attacks: Why the system call
api is a bad untrusted rpc interface,” in Proceedings of the Eighteenth
International Conference on Architectural Support for Programming
Languages and Operating Systems, ser. ASPLOS ’13. New York,
NY, USA: Association for Computing Machinery, 2013, p. 253–264.
[Online]. Available: https://doi.org/10.1145/2451116.2451145

36

[23] A. Cui, M. Costello, and S. Stolfo, “When ﬁrmware modiﬁcations

attack: A case study of embedded exploitation,” 2013.

[24] Z. Basnight, J. Butts, J. Lopez Jr, and T. Dube, “Firmware modiﬁcation
attacks on programmable logic controllers,” International Journal of
Critical Infrastructure Protection, vol. 6, no. 2, pp. 76–84, 2013.
[25] H. Bojinov, Y. Michalevsky, G. Nakibly, and D. Boneh, “Mobile device
identiﬁcation via sensor ﬁngerprinting,” ArXiv, vol. abs/1408.1416,
2014.

[26] X. Zhou, X. Ji, C. Yan, J. Deng, and W. Xu, “Nauth: Secure face-to-
face device authentication via nonlinearity,” in IEEE INFOCOM 2019 -
IEEE Conference on Computer Communications, 2019, pp. 2080–2088.
[27] J. Zhang, A. R. Beresford, and I. Sheret, “Sensorid: Sensor calibration
ﬁngerprinting for smartphones,” in 2019 IEEE Symposium on Security
and Privacy (SP), 2019, pp. 638–655.

[28] Z. Li, A. S. Rathore, C. Song, S. Wei, Y. Wang, and W. Xu,
“Printracker: Fingerprinting 3d printers using commodity scanners,”
in Proceedings of the 2018 ACM SIGSAC Conference on Computer
and Communications Security, ser. CCS ’18. New York, NY, USA:
Association for Computing Machinery, 2018, p. 1306–1323. [Online].
Available: https://doi.org/10.1145/3243734.3243735

[29] S. Belikovetsky, Y. Solewicz, M. Yampolskiy, J. Toh, and Y. Elovici,
“Detecting cyber-physical attacks in additive manufacturing using
digital audio signing,” 2017.

[30] H. Vincent, L. Wells, P. Tarazaga, and J. Camelio, “Trojan
detection and side-channel analyses for cyber-security in cyber-
physical manufacturing systems,” Procedia Manufacturing, vol. 1,
pp. 77 – 85, 2015, 43rd North American Manufacturing Research
Conference, NAMRC 43, 8-12 June 2015, UNC Charlotte, North
Carolina, United States. [Online]. Available: http://www.sciencedirect.
com/science/article/pii/S2351978915010653

[31] A. Humayed, J. Lin, F. Li, and B. Luo, “Cyber-physical systems
security—a survey,” IEEE Internet of Things Journal, vol. 4, no. 6,
pp. 1802–1831, 2017.

[32] M. Wolf and D. Serpanos, “Safety and security in cyber-physical
systems and internet-of-things systems,” Proceedings of the IEEE, vol.
106, no. 1, pp. 9–20, 2017.

[33] R. Alguliyev, Y. Imamverdiyev, and L. Sukhostat, “Cyber-physical
systems and their security issues,” Computers in Industry, vol. 100,
pp. 212–223, 2018.

[34] M. Jawurek, F. Kerschbaum, and G. Danezis, “Privacy technologies for

smart grids - a survey of options,” 2012.

[35] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Cyber-physical attacks in power
networks: Models, fundamental limitations and monitor design,” in
2011 50th IEEE Conference on Decision and Control and European
Control Conference.

IEEE, 2011, pp. 2195–2201.

[36] M. Rushanan, A. D. Rubin, D. F. Kune, and C. M. Swanson, “Sok:
Security and privacy in implantable medical devices and body area
networks,” in 2014 IEEE Symposium on Security and Privacy, May
2014, pp. 524–539.

[37] C. Camara, P. Peris-Lopez, and J. E. Tapiador, “Security and privacy
issues in implantable medical devices: A comprehensive survey,”
Journal of biomedical informatics, vol. 55, pp. 272–89, 2015.
[38] D. I. Urbina, J. Giraldo, A. A. C´ardenas, J. Valente, M. A. Faisal, N. O.
Tippenhauer, J. Ruths, R. Candell, and H. Sandberg, “Survey and new
directions for physics-based attack detection in control systems,” 2016.
[39] R. Altawy and A. M. Youssef, “Security, privacy, and safety
aspects of civilian drones: A survey,” ACM Trans. Cyber-Phys.
Syst., vol. 1, no. 2, pp. 7:1–7:25, Nov. 2016. [Online]. Available:
http://doi.acm.org/10.1145/3001836

[40] J. Giraldo, D. Urbina, A. Cardenas, J. Valente, M. Faisal, J. Ruths, N. O.
Tippenhauer, H. Sandberg, and R. Candell, “A survey of physics-based
attack detection in cyber-physical systems,” ACM Computing Surveys
(CSUR), vol. 51, no. 4, pp. 1–36, 2018.

on

[41] Y. Mo and B. Sinopoli, “False data injection attacks in control systems,”
in Preprints of the 1st workshop on Secure Control Systems, 2010, pp.
1–6.
[42] “Warning
of
https://insurancemarinenews.com/insurance-marine-news/
warning-on-gps-jamming-spooﬁng-in-strait-of-hormuz/
“Gps
discovered
circle
April
[Online]. Available:
gps-circle-spooﬁng-discovered-in-iran/

iran,”
https://www.gpsworld.com/

[43] D. Goward,
2020.

strait
Available:

jamming/spooﬁng

gps
August

hormuz,”

[Online].

spooﬁng

2019.

in

in

[44] I. Beavers, “Intelligence at the edge part 1: The edge node,” Analog

Devices, Inc, 2017.

37

[45] M. J. McGrath and C. N. Scanaill, Sensing and Sensor Fundamentals.
[Online]. Available:

Berkeley, CA: Apress, 2013, pp. 15–50.
https://doi.org/10.1007/978-1-4302-6014-1 2

[69] S.

Ikeda, “Iot-based ddos attacks are growing and making use
25 2020. [Online]. Available: https:

of common vulnerabilities,”
//www.cpomagazine.com

[46] I. Beavers and E. MacLean, “Intelligence at the edge part 4: edge node

[70] U. Cisco, “Cisco annual internet report (2018–2023) white paper,”

security,” 2019.

2020.

[47] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, “Ddos in the iot:
Mirai and other botnets,” Computer, vol. 50, no. 7, pp. 80–84, 2017.
[48] M. De Donno, N. Dragoni, A. Giaretta, and A. Spognardi, “Ddos-
capable iot malwares: Comparative analysis and mirai investigation,”
Security and Communication Networks, vol. 2018, 2018.

[49] K. Ashton et al., “That ‘internet of things’ thing,” RFID journal,

vol. 22, no. 7, pp. 97–114, 2009.

[50] J. E. Ibarra-Esquer, F. F. Gonz´alez-Navarro, B. L. Flores-Rios, L. Burt-
seva, and M. A. Astorga-Vargas, “Tracking the evolution of the inter-
net of things concept across different application domains,” Sensors,
vol. 17, no. 6, p. 1379, 2017.

[51] C. S. Raghavendra, K. M. Sivalingam, and T. Znati, Wireless sensor

networks. Springer, 2006.

[52] M. Armbrust, A. Fox, R. Grifﬁth, A. D. Joseph, R. Katz, A. Konwinski,
G. Lee, D. Patterson, A. Rabkin, I. Stoica et al., “A view of cloud
computing,” Communications of the ACM, vol. 53, no. 4, pp. 50–58,
2010.

[53] G. Brambilla, M. Picone, S. Cirani, M. Amoretti, and F. Zanichelli, “A
simulation platform for large-scale internet of things scenarios in urban
environments,” in Proceedings of the First International Conference on
IoT in Urban Space, 2014, pp. 50–55.

[54] C. Greer, M. Burns, D. Wollman, and E. Griffor, “Cyber-physical

systems and internet of things,” 2019.

[55] M. Ryu, J. Yun, T. Miao, I.-Y. Ahn, S.-C. Choi, and J. Kim, “Design
and implementation of a connected farm for smart farming system,” in
2015 IEEE SENSORS.
IEEE, 2015, pp. 1–4.

[56] P. P. Jayaraman, A. Yavari, D. Georgakopoulos, A. Morshed, and A. Za-
slavsky, “Internet of things platform for smart farming: Experiences and
lessons learnt,” Sensors, vol. 16, no. 11, p. 1884, 2016.

[57] Y. Mehmood, F. Ahmad, I. Yaqoob, A. Adnane, M. Imran, and
S. Guizani, “Internet-of-things-based smart cities: Recent advances and
challenges,” IEEE Communications Magazine, vol. 55, no. 9, pp. 16–
24, 2017.

[58] R. Gunasagaran, L. Kamarudin, A. Zakaria, E. Kanagaraj, M. M.
Alimon, A. Shakaff, P. Ehkan, R. Visvanathan, and M. Razali, “Internet
of things: Sensor to sensor communication,” in 2015 IEEE SENSORS.
IEEE, 2015, pp. 1–4.

[59] F. Theoleyre and A.-C. Pang, Internet of Things and M2M Communi-

cations. River Publishers, 2013.

[60] J. Wan, M. Chen, F. Xia, L. Di, and K. Zhou, “From machine-to-
machine communications towards cyber-physical systems,” Computer
Science and Information Systems, vol. 10, no. 3, pp. 1105–1128, 2013.
[61] O. Bello and S. Zeadally, “Intelligent device-to-device communication
in the internet of things,” IEEE Systems Journal, vol. 10, no. 3, pp.
1172–1182, 2014.

[62] H. Xu, W. Yu, D. Grifﬁth, and N. Golmie, “A survey on industrial
internet of things: A cyber-physical systems perspective,” IEEE Access,
vol. 6, pp. 78 238–78 259, 2018.

[63] Y. Lu, “Industry 4.0: A survey on technologies, applications and open
research issues,” Journal of industrial information integration, vol. 6,
pp. 1–10, 2017.

[64] F. A. Coda, R. M. Salles, H. A. Vitoi, M. A. Pessoa, L. A. Moscato,
D. J. Santos Filho, F. Junqueira, and P. E. Miyagi, “Big data on machine
to machine integration’s requirement analysis within industry 4.0,” in
Doctoral Conference on Computing, Electrical and Industrial Systems.
Springer, 2019, pp. 247–254.

[65] S. Trinks and C. Felden, “Edge computing architecture to support real
time analytic applications: A state-of-the-art within the application
area of smart factory and industry 4.0,” in 2018 IEEE International
Conference on Big Data (Big Data).

IEEE, 2018, pp. 2930–2939.

[66] A.-R. Sadeghi, C. Wachsmann, and M. Waidner, “Security and
internet of things,” in 2015 52nd
privacy challenges in industrial
ACM/EDAC/IEEE Design Automation Conference (DAC). IEEE, 2015,
pp. 1–6.

[67] D. U. Case, “Analysis of the cyber attack on the ukrainian power grid,”
Electricity Information Sharing and Analysis Center (E-ISAC), vol.
388, 2016.

[68] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis
et al., “Understanding the mirai botnet,” in 26th {USENIX} security
symposium ({USENIX} Security 17), 2017, pp. 1093–1110.

[71] X. Zhang, Z. Yang, W. Sun, Y. Liu, S. Tang, K. Xing, and X. Mao, “In-
centives for mobile crowd sensing: A survey,” IEEE Communications
Surveys & Tutorials, vol. 18, no. 1, pp. 54–67, 2015.

[72] C. Miao, Q. Li, H. Xiao, W. Jiang, M. Huai, and L. Su, “Towards
data poisoning attacks in crowd sensing systems,” in Proceedings
of the Eighteenth ACM International Symposium on Mobile Ad Hoc
Networking and Computing, 2018, pp. 111–120.

[73] F. Tahmasebian, L. Xiong, M. Sotoodeh, and V. Sunderam, “Crowd-
sourcing under data poisoning attacks: A comparative study,” in IFIP
Annual Conference on Data and Applications Security and Privacy.
Springer, 2020, pp. 310–332.

[74] C. Miao, Q. Li, L. Su, M. Huai, W. Jiang, and J. Gao, “Attack under
disguise: An intelligent data poisoning attack mechanism in crowd-
sourcing,” in Proceedings of the 2018 World Wide Web Conference,
2018, pp. 13–22.

[75] G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, and W. Xu, “Dol-
phinattack: Inaudible voice commands,” in Proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2017, pp. 103–117.

[76] N. Roy, S. Shen, H. Hassanieh, and R. R. Choudhury, “Inaudi-
ble voice commands: The long-range attack and defense,” in 15th
{USENIX} Symposium on Networked Systems Design and Implemen-
tation ({NSDI} 18), 2018, pp. 547–560.

[77] C. Yan, G. Zhang, X. Ji, T. Zhang, T. Zhang, and W. Xu, “The
feasibility of injecting inaudible voice commands to voice assistants,”
IEEE Transactions on Dependable and Secure Computing, 2019.
[78] D. F. Kune, J. Backes, S. S. Clark, D. Kramer, M. Reynolds, K. Fu,
Y. Kim, and W. Xu, “Ghost talk: Mitigating emi signal injection attacks
against analog sensors,” in 2013 IEEE Symposium on Security and
Privacy.

IEEE, 2013, pp. 145–159.

[79] C. Kasmi and J. Esteves, “Remote and silent voice command injection
on a smartphone through conducted iemi - threats of smart iemi for
information security,” 04 2018.

[80] Y. Son, H. Shin, D. Kim, Y. Park, J. Noh, K. Choi, J. Choi, and Y. Kim,
“Rocking drones with intentional sound noise on gyroscopic sensors,”
in 24th {USENIX} Security Symposium ({USENIX} Security 15), 2015,
pp. 881–896.

[81] T. Trippel, O. Weisse, W. Xu, P. Honeyman, and K. Fu, “Walnut:
Waging doubt on the integrity of mems accelerometers with acoustic
injection attacks,” in 2017 IEEE European Symposium on Security and
Privacy (EuroS&P).

IEEE, 2017, pp. 3–18.

[82] D. Davidson, H. Wu, R. Jellinek, V. Singh, and T. Ristenpart, “Con-
trolling uavs with sensor input spooﬁng attacks,” in 10th {USENIX}
Workshop on Offensive Technologies ({WOOT} 16), 2016.

[83] A. J. Kerns, D. P. Shepard, J. A. Bhatti, and T. E. Humphreys,
“Unmanned aircraft capture and control via gps spooﬁng,” Journal of
Field Robotics, vol. 31, no. 4, pp. 617–636, 2014.

[84] Q. Yan, K. Liu, Q. Zhou, H. Guo, and N. Zhang, “Surﬁngattack: Inter-
active hidden attack on voice assistants using ultrasonic guided waves,”
in Network and Distributed Systems Security (NDSS) Symposium, 01
2020.

[85] T. Vaidya, Y. Zhang, M. Sherr, and C. Shields, “Cocaine noodles:
exploiting the gap between human and machine speech recognition,”
in 9th {USENIX} Workshop on Offensive Technologies ({WOOT} 15),
2015.

[86] X. Yuan, Y. Chen, Y. Zhao, Y. Long, X. Liu, K. Chen, S. Zhang,
H. Huang, X. Wang, and C. A. Gunter, “Commandersong: A sys-
tematic approach for practical adversarial voice recognition,” in 27th
{USENIX} Security Symposium ({USENIX} Security 18), 2018, pp.
49–64.

[87] H. Abdullah, W. Garcia, C. Peeters, P. Traynor, K. R. Butler, and
J. Wilson, “Practical hidden voice attacks against speech and speaker
recognition systems,” in NDSS, 2019.

[88] “No jam tomorrow,” Mar 2011. [Online]. Available: https://www.
economist.com/technology-quarterly/2011/03/12/no-jam-tomorrow
[89] D. Schmidt, K. Radke, S. Camtepe, E. Foo, and M. Ren, “A survey
and analysis of the gnss spooﬁng threat and countermeasures,” ACM
Computing Surveys (CSUR), vol. 48, no. 4, p. 64, 2016.

[90] J. A. Volpe, “Vulnerability assessment of the transportation infrastruc-
ture relying on the global positioning system,” http://www. navcen.
uscg. gov/, 2001.

[91] “Gps spooﬁng: What’s the risk for ship navigation ...” [Online].

Available: https://www.regulus.com/news-and-media/stub1/

[92] J. Petit, B. Stottelaar, M. Feiri, and F. Kargl, “Remote attacks on
automated vehicles sensors: Experiments on camera and lidar,” Black
Hat Europe, vol. 11, p. 2015, 2015.

[93] C. Yan, W. Xu, and J. Liu, “Can you trust autonomous vehicles:
Contactless attacks against sensors of self-driving vehicle,” DEF CON,
vol. 24, 2016.

[94] Y. Park, Y. Son, H. Shin, D. Kim, and Y. Kim, “This ain’t your dose:
Sensor spooﬁng attack on medical infusion pump,” in 10th {USENIX}
Workshop on Offensive Technologies ({WOOT} 16), 2016.

[95] Y. Tu, Z. Lin,

I. Lee, and X. Hei, “Injected and delivered:
Fabricating implicit control over actuation systems by spooﬁng
inertial sensors,” in 27th USENIX Security Symposium (USENIX
Security 18). Baltimore, MD: USENIX Association, Aug. 2018, pp.
1545–1562.
[Online]. Available: https://www.usenix.org/conference/
usenixsecurity18/presentation/tu

[96] M. Shahrad, A. Mosenia, L. Song, M. Chiang, D. Wentzlaff, and
P. Mittal, “Acoustic denial of service attacks on hard disk drives,”
in Proceedings of the 2018 Workshop on Attacks and Solutions in
Hardware Security. ACM, 2018, pp. 34–39.

[97] N. Roy, H. Hassanieh, and R. Roy Choudhury, “Backdoor: Making
microphones hear inaudible sounds,” in Proceedings of the 15th An-
nual International Conference on Mobile Systems, Applications, and
Services. ACM, 2017, pp. 2–14.

[98] S. Nashimoto, D. Suzuki, T. Sugawara, and K. Sakiyama, “Sensor con-
fusion: Defeating kalman ﬁlter in signal injection attack,” in Proceed-
ings of the 2018 on Asia Conference on Computer and Communications
Security. ACM, 2018, pp. 511–524.

[99] C. Kasmi and J. L. Esteves, “Iemi threats for information security: Re-
mote command injection on modern smartphones,” IEEE Transactions
on Electromagnetic Compatibility, vol. 57, no. 6, pp. 1752–1755, 2015.
[100] Y. Tu, S. Rampazzi, B. Hao, A. Rodriguez, K. Fu, and X. Hei,
temperature-based control
“Trick or heat? manipulating critical
systems using rectiﬁcation attacks,” in Proceedings of
the 2019
ACM SIGSAC Conference on Computer and Communications
Security, ser. CCS ’19. New York, NY, USA: Association for
Computing Machinery, 2019, p. 2301–2315.
[Online]. Available:
https://doi.org/10.1145/3319535.3354195

[101] M. Leone and H. L. Singer, “On the coupling of an external electro-
magnetic ﬁeld to a printed circuit board trace,” IEEE Transactions on
Electromagnetic Compatibility, vol. 41, no. 4, pp. 418–424, Nov 1999.
Springer

[102] MarcelPelgrom, Analog-to-Digital Conversion, 3rd ed.

International Publishing, 2017.

[103] Y.-H. Sutu, “Demodulation radio frequency interference effects in

operational ampliﬁer circuits,” 1984.

[104] Y. Sutu and J. J. Whalen, “Statistics for demodulation rﬁ in operational
ampliﬁers,” in 1983 IEEE International Symposium on Electromagnetic
Compatibility, Aug 1983, pp. 1–6.

[105] Y. Shoukry, P. Martin, P. Tabuada, and M. Srivastava, “Non-invasive
spooﬁng attacks for anti-lock braking systems,” in Proceedings of
the 15th International Conference on Cryptographic Hardware and
Embedded Systems, ser. CHES’13. Berlin, Heidelberg: Springer-
Verlag, 2013, p. 55–72. [Online]. Available: https://doi.org/10.1007/
978-3-642-40349-1 4

[106] H. Shin, D. Kim, Y. Kwon, and Y. Kim, “Illusion and dazzle:
Adversarial optical channel exploits against
lidars for automotive
applications,” in International Conference on Cryptographic Hardware
and Embedded Systems. Springer, 2017, pp. 445–467.

[107] J. Tu, M. Ren, S. Manivasagam, M. Liang, B. Yang, R. Du, F. Cheng,
and R. Urtasun, “Physically realizable adversarial examples for lidar
object detection,” in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 2020, pp. 13 716–13 725.

[108] K. C. Zeng, S. Liu, Y. Shu, D. Wang, H. Li, Y. Dou,
G. Wang, and Y. Yang, “All your GPS are belong to us:
Towards stealthy manipulation of road navigation systems,” in 27th
USENIX Security Symposium (USENIX Security 18). Baltimore, MD:
USENIX Association, Aug. 2018, pp. 1527–1544. [Online]. Available:
https://www.usenix.org/conference/usenixsecurity18/presentation/zeng
[109] Z. Zhou, D. Tang, X. Wang, W. Han, X. Liu, and K. Zhang, “Invisible
mask: Practical attacks on face recognition with infrared,” CoRR, vol.
abs/1803.04683, 2018. [Online]. Available: http://arxiv.org/abs/1803.
04683

[110] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to
a crime: Real and stealthy attacks on state-of-the-art face recognition,”
in Proceedings of the 2016 ACM SIGSAC Conference on Computer
and Communications Security. ACM, 2016, pp. 1528–1540.

38

[111] D. F. Smith, A. Wiliem, and B. C. Lovell, “Face recognition on
consumer devices: Reﬂections on replay attacks,” IEEE Transactions
on Information Forensics and Security, vol. 10, no. 4, pp. 736–745,
April 2015.

[112] T. E. Humphreys, B. M. Ledvina, M. L. Psiaki, B. W. O’Hanlon,
and P. M. Kintner, “Assessing the spooﬁng threat: Development of
a portable gps civilian spoofer,” in Radionavigation laboratory confer-
ence proceedings, 2008.

[113] Y. Zhao, H. Zhu, R. Liang, Q. Shen, S. Zhang, and K. Chen,
“Seeing isn’t believing: Towards more robust adversarial attack
against real world object detectors,” in Proceedings of
the 2019
ACM SIGSAC Conference on Computer and Communications
Security, ser. CCS ’19. New York, NY, USA: Association for
[Online]. Available:
Computing Machinery, 2019, p. 1989–2004.
https://doi.org/10.1145/3319535.3354259

[114] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao,
A. Prakash, T. Kohno, and D. Song, “Robust physical-world attacks
on deep learning visual classiﬁcation,” in Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2018, pp.
1625–1634.

[115] J. S. Warner and R. G. Johnston, “A simple demonstration that the
global positioning system (gps) is vulnerable to spooﬁng,” Journal of
Security Administration, vol. 25, no. 2, pp. 19–27, 2002.

[116] T. Chen, L. Shangguan, Z. Li, and K. Jamieson, “Metamorph: Injecting
inaudible commands into over-the-air voice controlled systems,” 2020.
[117] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr,
voice
“Hidden
C.
Symposium (USENIX
commands,”
Security 16). Austin, TX: USENIX Association, Aug. 2016,
pp. 513–530. [Online]. Available: https://www.usenix.org/conference/
usenixsecurity16/technical-sessions/presentation/carlini

25th USENIX Security

Shields, D. Wagner,

and W.

Zhou,

in

[118] T. Sugawara, B. Cyr, S. Rampazzi, D. Genkin, and K. Fu, “Light
commands: laser-based audio injection attacks on voice-controllable
systems,” in 29th {USENIX} Security Symposium ({USENIX} Security
20), 2020, pp. 2631–2648.

[119] “Automotive radar.” [Online]. Available: https://www.sciencedirect.

com/topics/engineering/automotive-radar
[120] “Spooﬁng a superyacht at sea,” Aug 2018.

[Online]. Available:

https://news.utexas.edu/2013/07/30/spooﬁng-a-superyacht-at-sea/
[121] B. Iyidir and Y. Ozkazanc, “Jamming of gps receivers,” in Proceedings
of the IEEE 12th Signal Processing and Communications Applications
Conference, 2004., April 2004, pp. 747–750.

[122] Z. M. Ponos and M. L. Dukic, “Pulse jamming of gps receiver,” in 4th
International Conference on Telecommunications in Modern Satellite,
Cable and Broadcasting Services. TELSIKS’99 (Cat. No.99EX365),
vol. 2, Oct 1999, pp. 415–418 vol.2.

[123] J. Coffed, “The threat of gps jamming: The risk to an information

utility,” Report of EXELIS, pp. 6–10, 2014.

[124] P. Marks,

“Radar

gps
jammers.” [Online]. Available: https://www.newscientist.com/article/
dn23984-radar-gun-spots-vehicles-with-illegal-gps-jammers/

vehicles with

illegal

spots

gun

[125] Y. Cao, C. Xiao, B. Cyr, Y. Zhou, W. Park, S. Rampazzi, Q. A.
Chen, K. Fu, and Z. M. Mao, “Adversarial sensor attack on lidar-
based perception in autonomous driving,” in Proceedings of the 2019
ACM SIGSAC Conference on Computer and Communications Security,
2019, pp. 2267–2281.

[126] J. Shi and C. Tomasi, “Good features to track,” Cornell University,

Tech. Rep., 1993.

[127] B. D. Lucas, T. Kanade et al., “An iterative image registration technique

with an application to stereo vision,” 1981.

[128] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. D.
Tygar, “Adversarial machine learning,” in Proceedings of the 4th ACM
workshop on Security and artiﬁcial intelligence, 2011, pp. 43–58.

[129] T. Dreossi, S. Jha, and S. A. Seshia, “Semantic adversarial deep
learning,” in International Conference on Computer Aided Veriﬁcation.
Springer, 2018, pp. 3–26.

[130] K. D. Julian, M. J. Kochenderfer, and M. P. Owen, “Deep neural
network compression for aircraft collision avoidance systems,” Journal
of Guidance, Control, and Dynamics, vol. 42, no. 3, pp. 598–608, 2018.
[131] T. Dreossi, A. Donz´e, and S. A. Seshia, “Compositional falsiﬁcation of
cyber-physical systems with machine learning components,” in NASA
Formal Methods Symposium. Springer, 2017, pp. 357–372.

[132] L. Muda, M. Begam, and I. Elamvazuthi, “Voice recognition
algorithms using mel frequency cepstral coefﬁcient (MFCC) and
dynamic time warping (DTW) techniques,” CoRR, vol. abs/1003.4083,
2010. [Online]. Available: http://arxiv.org/abs/1003.4083

[133] “Gradient descent,” Aug 2019.

[Online]. Available: https://en.

wikipedia.org/wiki/Gradient descent

[134] F. Itakura, “Line spectrum representation of linear predictor coefﬁcients
of speech signals,” The Journal of the Acoustical Society of America,
vol. 57, no. S1, pp. S35–S35, 1975.

[135] H. Hermansky, “Perceptual linear predictive (plp) analysis of speech,”
the Journal of the Acoustical Society of America, vol. 87, no. 4, pp.
1738–1752, 1990.

[136] G. Welch, G. Bishop et al., “An introduction to the kalman ﬁlter,” 1995.
[Online]. Available:
[137] ArduPilot, “Ardupilot/ardupilot,” Aug 2019.

https://github.com/ArduPilot/ardupilot

[138] Multiwii, “multiwii/multiwii-ﬁrmware,” Feb 2016. [Online]. Available:

https://github.com/multiwii/multiwii-ﬁrmware

[139] L. Scott, “Anti-spooﬁng & authenticated signal architectures for civil
navigation systems,” in Proceedings of the 16th International Technical
Meeting of the Satellite Division of The Institute of Navigation (ION
GPS/GNSS 2003), 2001, pp. 1543–1552.

[140] M. G. Kuhn, “An asymmetric security mechanism for navigation
signals,” in International Workshop on Information Hiding. Springer,
2004, pp. 239–252.

[141] G. T. Becker, S. Lo, D. De Lorenzo, D. Qiu, C. Paar, and P. Enge,
“Efﬁcient authentication mechanisms for navigation systems–a radio-
navigation case study,” in Proceedings of the ION GNSS Meeting, 2009.
[142] S. Lo, B. Peterson, and P. Enge, “Assessing the security of a navigation
system: A case study using enhanced loran,” in Proc. ENC-GNSS, 2009.
and how
they work,” Aug 2018.
[Online]. Available: https://gizmodo.com/
all-the-sensors-in-your-smartphone-and-how-they-work-1797121002
[144] “1 billion more phones than people in the world! bankmycell,”
[Online]. Available: https://www.bankmycell.com/blog/

[143] D. Nield,

smartphone,

in your

sensors

“All

the

Aug 2019.
how-many-phones-are-in-the-world

google

[145] “New
8
Available:
new-google-android-malware-warning-issued-to-8-million-play-store-users

to
[Online].
https://www.forbes.com/sites/kateoﬂahertyuk/2019/10/24/

android
store

malware
users,”

warning

million

issued

2019.

play

Oct

[146] D. Damopoulos, G. Kambourakis, and S. Gritzalis, “From keyloggers to
touchloggers: Take the rough with the smooth,” Computers & security,
vol. 32, pp. 102–114, 2013.

[147] E. Owusu, J. Han, S. Das, A. Perrig, and J. Zhang, “Accessory:
in
the Twelfth Workshop on Mobile Computing
ser. HotMobile ’12. New York,
[Online]. Available: http:

Password inference using accelerometers on smartphones,”
Proceedings of
Systems &#38; Applications,
NY, USA: ACM, 2012, pp. 9:1–9:6.
//doi.acm.org/10.1145/2162081.2162095

[148] X. Liu, Z. Zhou, W. Diao, Z. Li, and K. Zhang, “When good becomes
evil: Keystroke inference with smartwatch,” in Proceedings of the 22nd
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2015, pp. 1273–1285.

[149] J. Han, E. Owusu, L. T. Nguyen, A. Perrig, and J. Zhang, “Accom-
plice: Location inference using accelerometers on smartphones,” in
2012 Fourth International Conference on Communication Systems and
Networks (COMSNETS 2012).

IEEE, 2012, pp. 1–9.

[150] P. Marquardt, A. Verma, H. Carter, and P. Traynor, “(sp) iphone: Decod-
ing vibrations from nearby keyboards using mobile phone accelerom-
eters,” in Proceedings of the 18th ACM conference on Computer and
communications security. ACM, 2011, pp. 551–562.

[151] D. Genkin, A. Shamir, and E. Tromer, “Rsa key extraction via low-
bandwidth acoustic cryptanalysis,” in Annual Cryptology Conference.
Springer, 2014, pp. 444–461.

[152] M. Vuagnoux and S. Pasini, “Compromising electromagnetic emana-
tions of wired and wireless keyboards.” in USENIX security symposium,
2009, pp. 1–16.

[153] L. Zhuang, F. Zhou, and J. D. Tygar, “Keyboard acoustic emanations
revisited,” ACM Transactions on Information and System Security
(TISSEC), vol. 13, no. 1, p. 3, 2009.

[154] T. Halevi and N. Saxena, “A closer look at keyboard acoustic ema-
nations: random passwords, typing styles and decoding techniques,”
in Proceedings of the 7th ACM Symposium on Information, Computer
and Communications Security. ACM, 2012, pp. 89–90.

[155] D. Asonov and R. Agrawal, “Keyboard acoustic emanations,” in IEEE
Symposium on Security and Privacy, 2004. Proceedings. 2004.
IEEE,
2004, pp. 3–11.

[156] M. Backes, M. D¨urmuth, and D. Unruh, “Compromising reﬂections-or-
how to read lcd monitors around the corner,” in 2008 IEEE Symposium
on Security and Privacy (sp 2008), May 2008, pp. 158–169.

39

[157] J. Loughry and D. A. Umphress, “Information leakage from optical
emanations,” ACM Transactions on Information and System Security
(TISSEC), vol. 5, no. 3, pp. 262–289, 2002.

[158] J. R. Kwapisz, G. M. Weiss, and S. A. Moore, “Activity recognition us-
ing cell phone accelerometers,” ACM SigKDD Explorations Newsletter,
vol. 12, no. 2, pp. 74–82, 2011.

[159] L. Cai and H. Chen, “Touchlogger: Inferring keystrokes on touch screen
from smartphone motion.” HotSec, vol. 11, no. 2011, p. 9, 2011.
[160] E. Miluzzo, A. Varshavsky, S. Balakrishnan, and R. R. Choudhury,
“Tapprints: your ﬁnger taps have ﬁngerprints,” in Proceedings of the
10th international conference on Mobile systems, applications, and
services. ACm, 2012, pp. 323–336.

[161] Z. Xu, K. Bai, and S. Zhu, “Taplogger: Inferring user inputs on smart-
phone touchscreens using on-board motion sensors,” in Proceedings
of the ﬁfth ACM conference on Security and Privacy in Wireless and
Mobile Networks. ACM, 2012, pp. 113–124.

[162] H. Wang, T. T.-T. Lai, and R. Roy Choudhury, “Mole: Motion leaks
through smartwatch sensors,” in Proceedings of the 21st Annual Inter-
national Conference on Mobile Computing and Networking. ACM,
2015, pp. 155–166.

[163] A. Maiti, M. Jadliwala, J. He, and I. Bilogrevic, “Side-channel infer-
ence attacks on mobile keypads using smartwatches,” IEEE Transac-
tions on Mobile Computing, vol. 17, no. 9, pp. 2180–2194, 2018.

[164] T. Beltramelli and S. Risi, “Deep-spying: Spying using smartwatch and

deep learning,” arXiv preprint arXiv:1512.05616, 2015.

[165] J. Bartlett, V. Prabhu, and J. Whaley, “Acctionnet: A dataset of human
activity recognition using on-phone motion sensors,” in Proceedings
of the 34th International Conference on Machine Learning (Sydney,
Australia, 2017).

[166] Y. Ha, S.-H. Jang, K.-W. Kim, and J. W. Yoon, “Side channel attack
on digital door lock with vibration signal analysis: longer password
does not guarantee higher security level,” in 2017 IEEE International
Conference on Multisensor Fusion and Integration for Intelligent
Systems (MFI).

IEEE, 2017, pp. 103–110.
[167] A. Al-Haiqi, M. Ismail, and R. Nordin, “Keystrokes inference attack on
android: A comparative evaluation of sensors and their fusion,” Journal
of ICT Research and Applications, vol. 7, no. 2, pp. 117–136, 2013.

[168] M. Shoaib, S. Bosch, O. Incel, H. Scholten, and P. Havinga, “Fusion of
smartphone motion sensors for physical activity recognition,” Sensors,
vol. 14, no. 6, pp. 10 146–10 176, 2014.

[169] S. Narain, T. D. Vo-Huu, K. Block, and G. Noubir, “Inferring user
routes and locations using zero-permission mobile sensors,” in 2016
IEEE Symposium on Security and Privacy (SP).
IEEE, 2016, pp.
397–413.

[170] S.-W. Lee and K. Mase, “Activity and location recognition using
wearable sensors,” IEEE pervasive computing, vol. 1, no. 3, pp. 24–32,
2002.

[171] W. Van Eck, “Electromagnetic radiation from video display units: an
eavesdropping risk?” Computers & Security, vol. 4, no. 4, pp. 269–286,
1985.

[172] M. Backes, T. Chen, M. Duermuth, H. P. Lensch, and M. Welk,
“Tempest in a teapot: Compromising reﬂections revisited,” in 2009
30th IEEE Symposium on Security and Privacy.
IEEE, 2009, pp.
315–327.

[173] A. Davis, M. Rubinstein, N. Wadhwa, G. Mysore, F. Durand, and W. T.
Freeman, “The visual microphone: Passive recovery of sound from
video,” ACM Transactions on Graphics (Proc. SIGGRAPH), vol. 33,
no. 4, pp. 79:1–79:10, 2014.

[174] K. Gandolﬁ, C. Mourtel, and F. Olivier, “Electromagnetic analysis:
Concrete results,” in International workshop on cryptographic hard-
ware and embedded systems. Springer, 2001, pp. 251–261.

[175] Y. Michalevsky, D. Boneh, and G. Nakibly, “Gyrophone: Recognizing
speech from gyroscope signals,” in 23rd {USENIX} Security Sympo-
sium ({USENIX} Security 14), 2014, pp. 1053–1067.

[176] A. Kwong, W. Xu, and K. Fu, “Hard drive of hearing: Disks that
eavesdrop with a synthesized microphone,” in Hard Drive of Hearing:
Disks that Eavesdrop with a Synthesized Microphone.

IEEE, p. 0.

[177] B. Nassi, Y. Pirutin, A. Shamir, Y. Elovici, and B. Zadov, “Lamphone:
Real-time passive sound recovery from light bulb vibrations,” BlackHat
USA, 2020.

[178] S. Biedermann, S. Katzenbeisser, and J. Szefer, “Hard drive side-
channel attacks using smartphone magnetic ﬁeld sensors,” in Inter-
national Conference on Financial Cryptography and Data Security.
Springer, 2015, pp. 489–496.

[179] C. Song, F. Lin, Z. Ba, K. Ren, C. Zhou, and W. Xu, “My smartphone
knows what you print: Exploring smartphone-based side-channel at-
tacks against 3d printers,” in Proceedings of the 2016 ACM SIGSAC

40

Conference on Computer and Communications Security. ACM, 2016,
pp. 895–907.

[180] M. Backes, M. D¨urmuth, S. Gerling, M. Pinkal, and C. Sporleder,
“Acoustic side-channel attacks on printers.” in USENIX Security sym-
posium, 2010, pp. 307–322.

[181] Y. Berger, A. Wool, and A. Yeredor, “Dictionary attacks using keyboard
acoustic emanations,” in Proceedings of the 13th ACM conference on
Computer and communications security. ACM, 2006, pp. 245–254.
[182] T. Zhu, Q. Ma, S. Zhang, and Y. Liu, “Context-free attacks using
keyboard acoustic emanations,” in Proceedings of
the 2014 ACM
SIGSAC Conference on Computer and Communications Security, ser.
CCS ’14. New York, NY, USA: ACM, 2014, pp. 453–464. [Online].
Available: http://doi.acm.org/10.1145/2660267.2660296

[201] M. Kam, Xiaoxun Zhu, and P. Kalata, “Sensor fusion for mobile robot
navigation,” Proceedings of the IEEE, vol. 85, no. 1, pp. 108–119,
1997.

[202] R. R. Murphy, “Dempster-shafer theory for sensor fusion in au-
tonomous mobile robots,” IEEE Transactions on Robotics and Automa-
tion, vol. 14, no. 2, pp. 197–206, 1998.

[203] S. Lynen, M. W. Achtelik, S. Weiss, M. Chli, and R. Siegwart,
“A robust and modular multi-sensor fusion approach applied to mav
navigation,” in 2013 IEEE/RSJ International Conference on Intelligent
Robots and Systems, 2013, pp. 3923–3929.

[204] A. Nemra and N. Aouf, “Robust ins/gps sensor fusion for uav local-
ization using sdre nonlinear ﬁltering,” IEEE Sensors Journal, vol. 10,
no. 4, pp. 789–798, 2010.

[183] D. Genkin, M. Pattani, R. Schuster, and E. Tromer, “Synesthesia:
Detecting screen content via remote acoustic side channels,” arXiv
preprint arXiv:1809.02629, 2018.

[205] R. Gravina, P. Alinia, H. Ghasemzadeh, and G. Fortino, “Multi-
sensor fusion in body sensor networks: State-of-the-art and research
challenges,” Information Fusion, vol. 35, pp. 68–80, 2017.

[184] Y. Jeon, M. Kim, H. Kim, H. Kim, J. H. Huh, and J. W. Yoon, “I’m
listening to your location! inferring user location with acoustic side
channels.” in Proceedings of the 2018 World Wide Web Conference.
International World Wide Web Conferences Steering Committee, 2018,
pp. 339–348.

[185] S. Tajik, H. Lohrke, J.-P. Seifert, and C. Boit, “On the power of
optical contactless probing: Attacking bitstream encryption of fpgas,”
in Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, ser. CCS ’17. New York, NY, USA:
Association for Computing Machinery, 2017, p. 1661–1674. [Online].
Available: https://doi.org/10.1145/3133956.3134039

[186] G. Wang, Y. Zou, Z. Zhou, K. Wu, and L. M. Ni, “We can hear you
with wi-ﬁ!” IEEE Transactions on Mobile Computing, vol. 15, no. 11,
pp. 2907–2920, 2016.

[187] M. G. Kuhn, “Optical time-domain eavesdropping risks of crt displays,”
in Proceedings 2002 IEEE Symposium on Security and Privacy.
IEEE,
2002, pp. 3–18.

[188] X. Gao, B. Firner, S. Sugrim, V. Kaiser-Pendergrast, Y. Yang, and
J. Lindqvist, “Elastic pathing: Your speed is enough to track you,”
in Proceedings of the 2014 ACM International Joint Conference on
Pervasive and Ubiquitous Computing. ACM, 2014, pp. 975–986.

[189] I. A. Gheyas and L. S. Smith, “Feature subset selection in large
dimensionality domains,” Pattern recognition, vol. 43, no. 1, pp. 5–
13, 2010.

[190] J. Wang and D. Katabi, “Dude, where’s my card? rﬁd positioning that
works with multipath and non-line of sight,” in Proceedings of the
ACM SIGCOMM 2013 conference on SIGCOMM, 2013, pp. 51–62.

[191] D. Muniraj and M. Farhood, “Detection and mitigation of actuator
attacks on small unmanned aircraft systems,” Control Engineering
Practice, vol. 83, pp. 188–202, 2019.

[192] C. Bolton, S. Rampazzi, C. Li, A. Kwong, W. Xu, and K. Fu, “Blue
note: How intentional acoustic interference damages availability and
integrity in hard disk drives and operating systems,” in 2018 IEEE
Symposium on Security and Privacy (SP).
IEEE, 2018, pp. 1048–
1062.

[193] S. Khazaaleh, G. Korres, M. Eid, M. Rasras, and M. F. Daqaq,
“Vulnerability of mems gyroscopes to targeted acoustic attacks,” IEEE
Access, vol. 7, pp. 89 534–89 543, 2019.

[194] J. Selvaraj, G. Y. Dayanıklı, N. P. Gaunkar, D. Ware, R. M. Gerdes,
M. Mina et al., “Electromagnetic induction attacks against embedded
systems,” in Proceedings of the 2018 on Asia Conference on Computer
and Communications Security. ACM, 2018, pp. 499–510.

[195] F. M. Tesche, M. Ianoz, and T. Karlsson, EMC analysis methods and

computational models.

John Wiley & Sons, 1996.

[196] D. M. Nessett and W. P. Sherer, “Multilayer ﬁrewall system,” Oct. 19

1999, uS Patent 5,968,176.

[197] E. Vetillard, “System with a trusted execution environment component

executed on a secure element,” Jan. 13 2015, uS Patent 8,935,746.

[198] K. S. Tharayil, B. Farshteindiker, S. Eyal, N. Hasidim, R. Hershkovitz,
S. Houri, I. Yoffe, M. Oren, and Y. Oren, “Sensor defense in-software
(sdi): Practical software based detection of spooﬁng attacks on position
sensor,” arXiv preprint arXiv:1905.04691, 2019.

[199] L. Blue, L. Vargas, and P. Traynor, “Hello, is it me you’re looking
for? differentiating between human and electronic speakers for voice
interface security,” in Proceedings of the 11th ACM Conference on
Security & Privacy in Wireless and Mobile Networks, 2018, pp. 123–
133.

[200] R. R. Brooks and S. S. Iyengar, Multi-sensor fusion: fundamentals and

applications with software. Prentice-Hall, Inc., 1998.

[206] L. C. Bento, U. Nunes, F. Moita, and A. Surrecio, “Sensor fusion
for precise autonomous vehicle navigation in outdoor semi-structured
environments,” in Proceedings. 2005 IEEE Intelligent Transportation
Systems, 2005.

IEEE, 2005, pp. 245–250.

[207] Q. Li, L. Chen, M. Li, S.-L. Shaw, and A. N¨uchter, “A sensor-fusion
drivable-region and lane-detection system for autonomous vehicle nav-
igation in challenging road scenarios,” IEEE Transactions on Vehicular
Technology, vol. 63, no. 2, pp. 540–555, 2013.

[208] Y. Shoukry, P. Martin, Y. Yona, S. Diggavi, and M. Srivastava, “Pycra:
Physical challenge-response authentication for active sensors under
spooﬁng attacks,” in Proceedings of the 22nd ACM SIGSAC Conference
on Computer and Communications Security, 2015, pp. 1004–1015.

[209] Y. Zhang and K. Rasmussen, “Detection of electromagnetic interfer-
ence attacks on sensor systems,” in IEEE Symposium on Security and
Privacy (S&P), 2020.

[210] W. Xu, C. Yan, W. Jia, X. Ji, and J. Liu, “Analyzing and enhancing the
security of ultrasonic sensors for autonomous vehicles,” IEEE Internet
of Things Journal, vol. 5, no. 6, pp. 5015–5029, 2018.

[211] D. L. Hayes, P. A. Friedman, and M. Lloyd, Cardiac pacing and

deﬁbrillation: a clinical approach. Wiley-Blackwell, 2000.

[212] Apple, “About

the security content of ios 12.2,” 2019. [Online].

Available: https://support.apple.com/en-gb/HT209599

[213] D. Golightly, “Google making light, motion sensor data in chrome more
private,” 2019. [Online]. Available: https://www.androidheadlines.com/
2019/03/google-light-motion-sensor-data-privacy-strengthened.html

[214] Mozilla,

“Disclosure of user

through javascript with
motion and orientation sensors,” 2016. [Online]. Available: https:
//www.mozilla.org/en-US/security/advisories/mfsa2016-43/

actions

[215] Vivaldi, “Website permissions in vivaldi,” 2020. [Online]. Available:

https://help.vivaldi.com/article/website-permissions/

[216] K. D. Singh and S. K. Sood, “5g ready optical fog-assisted cyber-
physical system for iot applications,” IET Cyber-Physical Systems:
Theory & Applications, vol. 5, no. 2, pp. 137–144, 2020.

[217] S. Ahmad and M. M. Afzal, “Deployment of fog and edge computing
in iot for cyber-physical infrastructures in the 5g era,” in International
Conference on Sustainable Communication Networks and Application.
Springer, 2019, pp. 351–359.

[218] T. Driscoll, S. Farhoud, S. Nowling et al., “Enabling mobile augmented
and virtual reality with 5g networks,” Tech. rep. Tech. Rep, Tech. Rep.,
2017.

[219] R. Molina-Masegosa and J. Gozalvez, “Lte-v for sidelink 5g v2x ve-
hicular communications: A new 5g technology for short-range vehicle-
to-everything communications,” IEEE Vehicular Technology Magazine,
vol. 12, no. 4, pp. 30–39, 2017.

[220] T. A. Zerihun, M. Garau, and B. E. Helvik, “Effect of communication
failures on state estimation of 5g-enabled smart grid,” IEEE Access,
vol. 8, pp. 112 642–112 658, 2020.

[221] C. Lai, R. Lu, D. Zheng, and X. S. Shen, “Security and privacy
challenges in 5g-enabled vehicular networks,” IEEE Network, vol. 34,
no. 2, pp. 37–45, 2020.

[222] B. Hussain, Q. Du, B. Sun, and Z. Han, “Deep learning-based ddos-
attack detection for cyber–physical system over 5g network,” IEEE
Transactions on Industrial Informatics, vol. 17, no. 2, pp. 860–870,
2020.

[223] S. Ansari, J. Ahmad, S. Aziz Shah, A. Kashif Bashir, T. Boutaleb, and
S. Sinanovic, “Chaos-based privacy preserving vehicle safety protocol
for 5g connected autonomous vehicle networks,” Transactions on
Emerging Telecommunications Technologies, vol. 31, no. 5, p. e3966,
2020.

[224] T-Mobile, “5g networks and connected vehicle future,”

24 2021.
https://www.t-mobile.com/business/resources/

[Online]. Available:
articles/5g-networks-open-new-roads-for-autonomous-vehicles
[225] M. A. Ferrag, L. Maglaras, A. Argyriou, D. Kosmanos, and H. Janicke,
“Security for 4g and 5g cellular networks: A survey of existing
authentication and privacy-preserving schemes,” Journal of Network
and Computer Applications, vol. 101, pp. 55–82, 2018.

[226] G. Choudhary and V. Sharma, “A survey on the security and the
evolution of osmotic and catalytic computing for 5g networks,” in 5G
enabled secure wireless networks. Springer, 2019, pp. 69–102.
[227] R. Borgaonkar, L. Hirschi, S. Park, and A. Shaik, “New privacy threat
on 3g, 4g, and upcoming 5g aka protocols,” Proceedings on Privacy
Enhancing Technologies, vol. 2019, no. 3, pp. 108–127, 2019.
[228] T. Kumar, M. Liyanage, I. Ahmad, A. Braeken, and M. Ylianttila,
“User privacy, identity and trust in 5g,” A Comprehensive Guide to 5G
Security, pp. 267–279, 2018.

[229] J. Li and X. Guo, “Covid-19 contact-tracing apps: A survey on the
global deployment and challenges,” arXiv preprint arXiv:2005.03599,
2020.

[230] N. Ahmed, R. A. Michelin, W. Xue, S. Ruj, R. Malaney, S. S. Kanhere,
A. Seneviratne, W. Hu, H. Janicke, and S. K. Jha, “A survey of covid-
19 contact tracing apps,” IEEE Access, vol. 8, pp. 134 577–134 601,
2020.

[231] R. A. Calvo, S. Deterding, and R. M. Ryan, “Health surveillance during

covid-19 pandemic,” 2020.

[232] Y. Xiao, N. Zhang, J. Li, W. Lou, and Y. T. Hou, “Privacyguard:
Enforcing private data usage control with blockchain and attested off-
chain contract execution,” in European Symposium on Research in
Computer Security. Springer, 2020, pp. 610–629.

[233] Y. Xiao, N. Zhang, W. Lou, and Y. T. Hou, “A survey of distributed
consensus protocols for blockchain networks,” IEEE Communications
Surveys & Tutorials, vol. 22, no. 2, pp. 1432–1465, 2020.

[234] B. Zhang, S. Kreps, N. McMurry, and R. M. McCain, “Americans’
perceptions of privacy and surveillance in the covid-19 pandemic,” Plos
one, vol. 15, no. 12, p. e0242652, 2020.

[235] R. Richardson and M. M. North, “Ransomware: Evolution, mitigation
and prevention,” International Management Review, vol. 13, no. 1,
p. 10, 2017.

[236] N. Y. Times, “Cyber attack suspected in german woman’s death,”
18 2020. [Online]. Available: https://www.nytimes.com/2020/09/18/
world/europe/cyber-attack-germany-ransomeware-death.html

[237] P. Bajpai, R. Enbody, and B. H. Cheng, “Ransomware targeting auto-
mobiles,” in Proceedings of the Second ACM Workshop on Automotive
and Aerial Vehicle Security, 2020, pp. 23–29.

[238] N. Goud, “Connected cars are vulnerable to ransomware attacks,”
Jun. 2 2017. [Online]. Available: https://www.cybersecurity-insiders.
com/connected-cars-are-vulnerable-to-ransomware-attacks/

[239] N. Zhang, R. Zhang, K. Sun, W. Lou, Y. T. Hou, and S. Jajodia,
“Memory forensic challenges under misused architectural features,”
IEEE Transactions on Information Forensics and Security, vol. 13,
no. 9, pp. 2345–2358, 2018.

41

Zhiyuan Yu (S’20) is a ﬁrst-year Ph.D. student
in the Department of Computer Science and En-
gineering at Washington University in St. Louis.
He has interests in IoT security, medical security,
and social privacy. Before that, he earned his B.S.
degree in Electrical Engineering from the Huazhong
University of Science and Technology in 2019.

Zack Kaplan (S’20) is currently a B.S./M.S. stu-
dent at Washington University in St. Louis studying
computer science, psychology, and cybersecurity. He
is a member of BEAR5HELL, a Capture the Flag
club at Washington University, and has interests in
social engineering and network security.

Qiben Yan (S’11–M’15) is an Assistant Professor
in Department of Computer Science and Engineering
of Michigan State University. He received his Ph.D.
in Computer Science department from Virginia Tech,
an M.S. and a B.S. degree in Electronic Engineering
from Fudan University in Shanghai, China. He is a
recipient of NSF CRII award in 2016. His current
research interests include wireless communication,
wireless network security and privacy, mobile and
IoT security, and big data privacy.

Ning Zhang (M’11) received his Ph.D. degree from
Virginia Tech in 2016. He is currently an Assistant
Professor in the Department of Computer Science
and Engineering at Washington University in St.
Louis. Before that, he worked in the security in-
dustry for ten years. His research focus is system
security.

