2
2
0
2

g
u
A
1

]

R
C
.
s
c
[

2
v
2
0
3
8
0
.
3
0
2
2
:
v
i
X
r
a

INTERNET-BASED SOCIAL ENGINEERING ATTACKS, DEFENSES
AND PSYCHOLOGY: A SURVEY

Theodore Longtchi1, *

Rosana Montañez Rodriguez2, *

Laith Al-Shawaf3

Adham Atyabi1

A PREPRINT

Shouhuai Xu1

August 2, 2022

1 Department of Computer Science, University of Colorado Colorado Springs, Colorado Springs, CO 80918
2 Department of Computer Science, University of Texas at San Antonio, San Antonio, TX 78249
3 Department of Psychology, University of Colorado Colorado Springs, Colorado Springs, CO 80918

* Shared ﬁrst-author

ABSTRACT

Social engineering attacks are a major cyber threat because they often serve as a ﬁrst step for an
attacker to break into an otherwise well-defended network, steal victims’ credentials, and cause
ﬁnancial losses. The problem has received due amount of attention with many publications proposing
defenses against them. Despite this, the situation has not improved.
In this paper, we aim to
understand and explain this phenomenon by looking into the root cause of the problem. To this end,
we examine the literature on attacks and defenses through a unique lens we propose — psychological
factors (PFs) and techniques (PTs). We ﬁnd that there is a big discrepancy between attacks and
defenses: Attacks have deliberately exploited PFs by leveraging PTs, but defenses rarely take either
of these into consideration, preferring technical solutions. This explains why existing defenses have
achieved limited success. This prompts us to propose a roadmap for a more systematic approach
towards designing effective defenses against social engineering attacks.

Keywords Social engineering attacks, email-based attacks, website-based attacks, online social network-based attacks,
psychological factors, psychological techniques, phishing, deception

Correspondence: sxu@uccs.edu

1

Introduction

It is often said that humans are the weakest link in cybersecurity. However, the cause of this phenomenon is poorly
understood, and solutions are elusive. These issues motivate us to take a deeper look into the following problems: (i)
What is the root cause that enables social engineering attacks? (ii) Why have existing defenses achieved very limited
success in mitigating social engineering attacks? (iii) What kinds of research need to be done in order to adequately
mitigate social engineering attacks? In order to answer these questions, we need to narrow down the scope, since human
factors are such a broad topic (see, e.g., Montañez et al. (2022)). This prompts us to focus on Internet-based social
engineering attacks to which humans often fall victim. Speciﬁcally, we will focus on three classes of social engineering
attacks: email-based, website-based, and online social network (OSN)-based social engineering attacks.

The importance of the aforementioned motivating problems in the context of Internet-based social engineering attacks
is demonstrated by the multitude of studies on the aforementioned attacks and defenses against them, and by the many
existing surveys from various perspectives of the problem (cf. Das et al. (2019a); Khonji et al. (2013); Zaimi et al.
(2020); Dou et al. (2017); Almomani et al. (2013); Basit et al. (2020); Ali et al. (2020); Jain and Gupta (2021); Sahu

 
 
 
 
 
 
Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

and Dubey (2014); da Silva et al. (2020); Alabdan (2020); Vijayalakshmi et al. (2020); Jampen et al. (2020); Chanti
and Chithralekha (2020); Rastenis et al. (2020); Gupta et al. (2018); Chiew et al. (2018); Aleroud and Zhou (2017);
Yasin et al. (2019); Montañez et al. (2020); Gupta et al. (2016); Heartﬁeld and Loukas (2015); Alharthi et al. (2020);
Salahdine and Kaabouch (2019) and the extensive list of references therein). It is also shown by the scale of ﬁnancial
losses incurred by these attacks; for example, FBI reports a $26B loss between June 2017 and July 2019 associated
with attack emails that contain instructions on approving payments to attackers and pretend to come from executives
FBI (2020). However, our examination shows that prior studies focus on technical solutions which mainly leverage
Artiﬁcial Intelligence/Machine Learning (AI/ML) to design various kinds of defense systems. This may be understood
as follows: Since these attacks often leverage information technology as a means to wage attacks (e.g., many attacks do
not have counterparts in the era prior to the emergence of cyberspace), it has been largely treated as a technological
problem. This is evidenced by the fact that most existing defenses against them leverage AI/ML techniques. As a result,
very few studies take a close look at the root causes of social engineering techniques; the present study ﬁlls this void.

Our Contributions. In this paper we systematize Internet-based social engineering attacks and defenses through the
lens of psychology. We resolve the aforementioned motivating problems with a systematic characterization of attacks
and defenses with respect to psychological factors and techniques that contribute to human susceptibility to social
engineering attacks. Speciﬁcally, we make the following contributions.

First, we systematize the human psychological factors (PFs) that have been deliberately exploited by attackers to wage
effective attacks, while noting that these factors have been scattered in the literature. The success of these attacks
suggests that attackers have to give the problem due diligence in understanding PFs, especially those factors that can
be exploited effectively. In order to deepen our understanding of how these PFs can be exploited to wage attacks, we
further systematize what we call psychological techniques (PTs), which can be seen as the means of exploiting PFs.
The PFs and PTs help understand the root cause that enable social engineering attacks from a psychological perspective.
To the best of our knowledge, this is the ﬁrst systematization of PFs and PTs with respect to social engineering attacks.

Second, we systematize Internet-based social engineering attacks, with emphasis on the PFs they exploit. This is made
possible by the “bridge” of PTs. Moreover, we systematize defenses with an emphasis on whether a defense leverages
certain PFs. We ﬁnd that very few do. This means that most defenses are designed without considering the root cause
of these attacks, which explains why current defenses have achieved limited success.

Third, the above ﬁnding prompts us to propose a research roadmap towards designing effective defenses. The roadmap
is centered at creating a psychological framework tailored to social engineering attacks. The framework aims to tailor
psychological principles to the cyber domain. The framework highlights the role and relevance of each PF, including
the relationships between each. These relationships are important because they are not necessarily independent of, or
orthogonal to, each other. The envisioned quantitative understanding will guide us to design effective defenses in the
future.

Related Work. We focus on social engineering attacks in cyberspace, which is in contrast to social engineering attacks
in the physical world Montañez et al. (2022). Table 1 contrasts the present survey with related previous surveys through
the coverage of the following attributes: PFs are the human attributes that can be exploited by social engineering attacks
(e.g., greed); PTs describe how social engineering attacks exploit PFs; Attacks waged by social engineering attackers
(e.g., whaling); Defenses which have been proposed in the literature. For example, Khonji et al. Khonji et al. (2013)
surveyed phishing deﬁnitions and detection methods. When compared with these studies, we stress two fundamentally
important aspects: PFs and PTs, because we must understand them before we can design effective defenses. Indeed,
this perspective has three immediate payoffs as shown in the paper: (i) we can map social engineering attacks to PFs
through the “bridge” of PTs; (ii) defenders largely lag behind attackers because most defenses do not adequately take
PFs into consideration, even though attacks have been regularly exploiting PFs in crafty ways, explaining the limited
success of current defenses; (iii) this understanding prompts us to propose a research roadmap towards the development
of effective defenses against social engineering attacks.

Paper Outline. Section 2 reviews some preliminary psychology knowledge and describes our methodology. Section
3 presents an overview of our study following the methodology. Section 4 systematizes PFs and PTs. Section 5
systematizes social engineering attacks. Section 6 systematizes defenses against social engineering attacks. Section 7
systematizes the relationships between PFs, PTs, social engineering attacks, and social engineering defenses. Section 8
presents a roadmap for future research directions. Section 9 concludes the present study.

2

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Attacks Defenses Relationships

Ref.
Das et al. (2019a)
Khonji et al. (2013)
Zaimi et al. (2020)
Dou et al. (2017)
Almomani et al. (2013)
Basit et al. (2020)
Ali et al. (2020)
Jain and Gupta (2021)
Sahu and Dubey (2014)
da Silva et al. (2020)
Alabdan (2020)
Vijayalakshmi et al. (2020)
Jampen et al. (2020)
Chanti and Chithralekha (2020)
Rastenis et al. (2020)
Gupta et al. (2018)
Chiew et al. (2018)
Aleroud and Zhou (2017)
Yasin et al. (2019)
Montañez et al. (2020)
Gupta et al. (2016)
Heartﬁeld and Loukas (2015)
Alharthi et al. (2020)
Salahdine and Kaabouch (2019)
The present paper

PFs
√
(6)

PTs

√

√

(19)

(18)

√

√

(19)

(2)

√

(41)

√

(13)

√
√
√
√
√
√

√
√
√
√

√
√
√
√
√
√

√
√
√
√
√

√
√
√
√
√
√
√
√
√
√
√
√
√
√

√

√

√
√
√
√
√
√

√

Table 1: Comparison between existing surveys and ours, where a number in parentheses is the number of PFs or PTs
discussed in a paper. Only Montañez et al. (2020) and the present paper systematize PFs even though Montañez et al.
(2020) only discusses 19 PFs (which are signiﬁcantly less comprehensive than the 41 discussed in the present paper) ;
the others merely mention some PFs. Only the present paper explores the relationships between the PFs, PTs, attacks,
and defenses.

2 Psychological Preliminaries and Study Methodology

2.1 Psychological Background Knowledge

We brieﬂy review the psychological background knowledge that is helpful for understanding the paper. This knowledge
serves as a baseline for guiding us in deﬁning what constitute as PFs.

Big Five Personality Traits (BFPT). The Five Factor Model of personality traits – also known as the Big Five – refers
to the ﬁve factors that constitute the basic structure of human personality Goldberg (1981). These factors, discovered
using factor analysis and other statistical techniques, are OPENNESS, CONSCIENTIOUSNESS, EXTRAVERSION, AGREE-
ABLENESS, and NEUROTICISM. The evidence for the existence and robustness of the Big Five comes from numerous
studies conducted in different languages and across cultures over the span of many decades Costa Jr and McCrae (2008);
Digman (1990); McCrae and John (1992). These basic personality traits are relatively stable across the lifespan, and
they predict life outcomes ranging from career success to likelihood of divorce to lifespan longevity Soto (2019). They
even appear to be present in other species Nettle (2006). Given this robustness and for the purposes of the present paper,
each of the ﬁve factors constitutes a PF.

Cialdini’s Principles of Persuasion. Persuasion Principles are a set of strategies used to inﬂuence individuals into
behaving in a desired way. These principles, derived from ﬁeld studies on sales and marketing Cialdini and James
(2009), include: (i) LIKING which denotes being easily inﬂuenced by those one likes or those with common beliefs as
them; (ii) RECIPROCATION which denotes feeling obliged to return a favor; (iii) SOCIAL PROOF (conformity) which
denotes imitating the behaviours of others; (iv) CONSISTENCY (commitment) which denotes consistency of behaviour
or sticking to a promise; (v) AUTHORITY, which denotes submitting to experts or obeying orders from one’s superior or
authoritative ﬁgures; and (vi) SCARCITY which denotes placing more value on things that are in short supply. When
persuasion is undetected, it encourages the use of heuristic reasoning Cialdini and James (2009); Cialdini and Trost

3

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

(1998); when persuasion is detected, it results in a negative response towards the message Kirmani and Zhu (2007). The
use of persuasion in social engineering messages has been studied extensively Lin et al. (2019a); Rajivan and Gonzalez
(2018); Ferreira and Lenzini (2015); Stajano and Wilson (2011); Van Der Heijden and Allodi (2019). For the purposes
of this paper, each of the six persuasion principles constitutes a PF.

2.2 Study Methodology

Scope. Since social engineering attacks are a broad topic, we choose to focus on Internet-based social engineering
attacks, especially the ones exploiting emails, websites, and online social networks (OSNs). Therefore, the term “social
engineering attacks” or simply “attacks” in this paper refers to these attacks. We will use terms “individuals” and “users”
interchangeably; the term “victims” refer to the users that are successfully compromised by social engineering attacks.

Methodology. In order to understand why humans are susceptible to social engineering attacks, we aim to systematize
the PFs and PTs that have been, or could be, exploited by attacks. In this paper, the term psychological factor is used
to represent the psychological attributes that can be exploited by attacks (i.e., what to exploit). In order to make our
deﬁnitions of PFs psychological sound, we leverage the afore-reviewed BFPT and Principles of Persuasion among
others from Cognitive Psychology, to deﬁne PFs to guide us in identifying other psychological attributes that can be
deemed as PFs in a psychological sense. By contrast, the term PT is used to describe how attacks exploit these factors.
This distinction turns out to be useful because the PTs will be leveraged to build a “bridge" for mapping attacks to PFs.
In other words, PTs build a bridge between the two disciplines of psychology and cybersecurity. Note that one PT can
exploit multiple PFs and one PF can be exploited by multiple PTs.

Figure 1: Methodology of our study

Figure 1 highlights our methodology, which can be adopted or adapted by others to conduct their own studies. The
methodology consists of the following ﬁve steps. First, identify the relevant literature, ideally automatically or semi-
automatically because there are so many publications. Second, manually ﬁlter the papers resulting from the previous
step according to their relevance to the purpose of the study. The preceding two steps correspond to preparation. Third,
extracting and systematizing the PFs, PTs, attacks, and defenses that are discussed in the papers resulting from the
previous step. Fourth, systematizing the relationships between the PFs, PTs, attacks, and defenses identiﬁed from
the previous step. Fifth, leveraging the understanding resulting from the systematization to draw insights into future
research directions.

Note that the methodology can have useful variants. For example, it can be adapted to search the literature in an iterative
fashion when one does not know enough information about PFs, PTs, attacks, or defenses; in this case, it may be
helpful to start the search with few well-known keywords, ﬁltering the resulting literature, and extracting other PFs,
PTs, attacks, or defenses for further search. This iteration can also be leveraged to assure whether some relevant papers
are overlooked. As another example, one can incorporate the PFs, PTs, attacks, and defenses that are known to the
investigator but are not found in the academic literature. As we will see, this is particularly relevant to attacks because
there can be attacks that are discussed by practitioners in social media but are not investigated in the academic literature
yet.

4

Searching academic publication databases with social engineering related keywordsManually filtering the papers resulting from the search according to their relevanceSystematizing psychological factors and techniquesSystematizing social engineering attacksSystematizing social engineering defenseSystematizing relationships between psychological factors and techniques, attacks and defensesLeveraging the understanding to draw insights into future research directionsInternet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

3 Systematization Overview

The overview corresponds to the ﬁve steps of the methodology. First, to identify papers for manual ﬁltering, we consider
the following digital libraries: IEEE (including IEEE Symposium on Security and Privacy and IEEE Transactions),
ACM (including ACM Conference on Computer and Communications Security and ACM Transactions), Usenix
(including Usenix Security Symposium), and Network and Distributed System Security Symposium (NDSS), Elsevier,
Springer, PlosOne, Wiley, Frontiers in Psychology, and Information & Computer Security (ICS). These venues are
selected because they are the main security venues or psychological venues that publish social engineering related
papers. We start the search with the only keyword “social engineering”, which yields thousands of papers. Since it
is infeasible to manually ﬁlter this many papers, we add another keyword “phishing” (i.e., a paper is relevant when
containing these two keywords simultaneously). We choose phishing because it is the most common social engineering
attack Touchstone (2021); kaspersky (2022) and may have been more widely studied from a psychological perspective.

Second, the search identiﬁes 663 papers. We manually examine these papers based on their treatment and relevance to
the motivation and scope of the present study, leading to 154 papers which include 24 survey/review papers (while
noting that the other references are cited for further exploration purposes, such as those published in psychology
literature). We eliminate the papers that just mention social engineering and/or phishing without presenting substantial
investigation; 268 papers fall into this category. We further eliminate the ones that do not consider speciﬁc PFs or do not
consider Internet-based social engineering attacks; 146 papers fall into this category. Finally, we look into the remaining
249 papers and eliminate the ones that do not appear to present a high-quality exploration (which is a judgement call),
ending up with the aforementioned 154 papers for systematization.

Third, given the 154 papers (including the 24 surveys), we initially identiﬁed 63 PFs from these papers where each PF is
discussed in one or multiple papers as a psychological factor that has an impact on social engineering attacks. We found
that these PFs contain some redundant ones. This prompts us to eliminate the redundant ones as follows. (i) If two
PFs are considered similar to each other in a psychological sense, we keep the PF that is investigated in a quantitative
fashion, representing a deeper understanding. (ii) If two PFs are considered redundant in a psychological sense but none
of them is investigated in a quantitative fashion, we keep the PF that is most relevance to this paper. (iii) If two PFs are
considered redundant and both are investigated in a quantitative fashion, we keep the one that is more often used in
the literature according to our psychological knowledge. This pre-processing leads to 41 PFs, which are PFs that are
widely accepted in the psychology community, as reviewed above. One example of the preceding (i) is the pair of PFs
known as "false consensus effect" and "social proof", which are considered redundant in their psychological meanings.
We keep the latter because it is investigated in a quantitative fashion Das et al. (2014). On example of the preceding
(iii) is the pair of PFs known as "inattentiveness" and "lack of vigilance", which are redundant because they essentially
represent the same psychological factor. Since they both have been investigated in a quantitative fashion Tu et al. (2019),
we keep the former because the former is used in the literature more often (perhaps because of its succinctness). After
ﬁnalizing the 41 PFs, we leverage our psychological expertise to classify them into ﬁve classes: cognitive, emotion,
social psychology, personality and individual difference, and workplace PFs. These PFs help understand the root cause
of social engineering attacks from a psychological perspective.

In addition, we systematize the 13 PTs that have been mentioned in the literature. At this point, it is not clear to us how
to further group these 13 PTs into a smaller number of categories. We hope future studies can resolve this issue. We
systematize attacks with respect to those PFs, including the PF(s) exploited by an attack and the extent to which a PF’s
impact on human susceptibility has been quantiﬁed. We systematize defenses with respect to the attacks, leading to
defenses against email-based, website-based, and OSN-based attacks, respectively.

Fourth, we systematize the relationships between the PFs, PTs, attacks and defenses by proposing mappings between
them. This is made possible because the PTs serve as a “bridge” between the attacks and the PFs. It is ironic to observe
that only one PF has been leveraged by defenses. Nevertheless, the mapping gives a succinct representation of the
state-of-the-art knowledge in this domain, and also allows us to understand the motivating problem of the cause of the
limited success of existing defenses.

Fifth, we propose a roadmap for future research to pursue the motivating problem of ﬁnding the solution to internet-
based social engineering attacks. The roadmap is prompted by the observation that very few empirical studies have
been carried out to quantify the impact of PFs on the susceptibility of humans to social engineering attacks. The few
studies that attempted quantitative studies have some drawbacks, such as involving a small number of participants (e.g.,
53 participants Welk et al. (2015)) or participants being undergraduate students Welk et al. (2015); Hong et al. (2013);
Tu et al. (2019) (rather than average users). The lack of quantitative results published in the literature (e.g., the impact
of PFs) prevents us from conducting any meta-analysis.

5

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

4 Systematizing Psychological Factors and Techniques

4.1 Systematizing Psychological Factors (PFs)

We categorize the PFs that may be exploited by Internet-based social engineering attacks into ﬁve groups, with 42
factors in total: (i) cognitive PFs, which describe how individuals process information; (ii) emotion PFs, which describe
individuals’ feelings, motivational state, and approaches or avoidance behaviors; (iii) social psychology PFs, which
describe individuals’ interpersonal attributes in various groups; (iv) personality and individual difference PFs, which are
individuals’ relatively stable attributes; and (v) workplace PFs, which describe cultural and organizational interactions
within a workplace. Note that there is more than one way to divide these factors. We have adopted this framework
because it is in line with the traditional branches and subdivisions in psychology, and because it may help readers decide
where to direct their efforts in training victims to become less vulnerable – but it is not a conclusive categorization.

It is worth mentioning that the categorization is somewhat subjective because several PFs can fall into more than one
category. For example, we have listed OVERCONFIDENCE as a cognitive PF, but it could reasonably be considered an
personality and individual difference PF because there are stable individual differences in this factor.

Cognitive PFs. These PFs describe how an individual processes information, including heuristics they may use, the
knowledge they may possess, the conﬁdence they may exhibit, and the attention they may give.

1. COGNITIVE MISER. This PF describes one’s use of decision-making heuristics, namely the use of mental
shortcuts in a decision-making process McAlaney and Benson (2020). Generally speaking, people tend to
be cognitive misers and rely more on heuristic-based processing to make decisions Kim and Lee (2021).
McAlaney and Hills McAlaney and Hills (2020) argued that people are motivated tacticians and will apply a
cognitive miser (or naÃ´rve scientist) approach based on the urgency, perceived importance and complexity of
the situation.

2. EXPERTISE. This PF describes one’s knowledge about a particular domain. Albladi and Weir Albladi and
Weir (2020) showed that EXPERTISE plays a role in raising an individual’s perception of risk associated
with online social networks, but the perceived risk does not signiﬁcantly increase individuals’ competence in
coping with these threats. Qualitatively speaking, expertise does not necessarily make one less vulnerable to
social engineering attacks Ghaﬁr et al. (2016); Das et al. (2019b); quantitatively speaking, expertise, when
effectiveness, does make one more capable in coping with social engineering attacks (i.e., incurring lower
false-positive and false-negative rates Henshel et al. (2015). Redmiles et al. Redmiles et al. (2020) show that
the EXPERTISE associated with a given social-demographic background may affect the prioritization of advice
in coping with online threats.

3. OVERCONFIDENCE. This PF describes individuals’ tendency in having too much conﬁdence in themselves
Williams et al. (2017), especially their ability to detect phishing Chen et al. (2020), which can be improved
via education and training Moody et al. (2017). This PF may correlate with too much self-conﬁdence House
and Raja (2020). In an experiment with 53 undergraduates students (34% computer science majors, 66%
psychology majors), Hong et al. Hong et al. (2013) found that approximately 92% of participants misclassiﬁed
phishing emails even though 89% had earlier indicated that they were conﬁdent of their ability to identify
phishing emails.

4. ABSENTMINDEDNESS. This PF describes the degree to which one’s attention is diverted from a particular
task. Reb et al. Reb et al. (2015) found that employees’ absentmindedness is positively related to emotional
exhaustion, which negatively affects jobs performance. Absentminded people can easily click phishing links
because they do not pay attention to what they are doing Zafar et al. (2019); Collier and Collier (2020).

It is intuitive that cognitive PFs play important roles in inﬂuencing individuals’ susceptibility to social engineering
attacks. However, our understanding is superﬁcial.

Emotion PFs. These PFs describe human feelings, motivational states, and approaches or avoidance behaviors. They
include so-called visceral triggers, which are strong internal drivers to satisfy a basic need.

1. GREED. This PF is well recognized Mondal et al. (2019); Kano and Nakajima (2021); Alyahya and Weir
(2021); Wang et al. (2017); Alabdan (2020); Chiew et al. (2018); Yasin et al. (2019) and describes one’s intense
and selﬁsh desire for something, especially wealth, power, or food. GREED is one of the persuasion tools used
in phishing attacks Siadati et al. (2017) and is often paired with need (i.e., the attacker knows what a victim
needs and present what the victim needs as a bait) Ferreira (2018). Greed is recognized by some researchers as
a human limitation when comparing human-based security versus technology-based security Salahdine and

6

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Kaabouch (2019); Adil et al. (2020). Moreover, the greedier a person is, the more likely the person will fall
victim to social engineering attacks Li et al. (2019).

2. FEAR. This PF, which tends to make people vulnerable Aldawood and Skinner (2019a); Tu et al. (2019);
Chiew et al. (2018); Jensen (2002), describes one’s belief that something painful, dangerous or threatening
may happen. It is relevant because situations that evoke fear bring about a strong avoidance reaction in both
behavioral responses and cognitive processing Ness et al. (2017). Algarni et al. Algarni et al. (2017) found that
social engineering attacks are effective against people who submit to fear toward, and orders from, inﬂuential
people. Siadati et al. Siadati et al. (2017) treated fear as one of the phishing persuasion techniques.

3. SYMPATHY. This PF describes the emotional state of individuals who understand the mental or emotional
state of another person without actually feeling the same emotion Williams et al. (2017). Sympathy is a
universally virtue that has the potential risks of making people vulnerable to social engineering attacks Wang
et al. (2021). Indeed, attackers often seek to gain people’s sympathy Gallegos-Segovia et al. (2017); Benias
and Markopoulos (2018); Kano and Nakajima (2021).

4. EMPATHY. This PF, which is one of the human vulnerability that breaks a victim’s defense Arabia-Obedoza
et al. (2020); Greavu-Serban and Serban (2014); Schürmann et al. (2020); Airehrour et al. (2018), describes
the emotional state of an individual who personally relates to the mental or emotional state of another person
based on their own experiences with the same state. For example, scammers often exploit empathy as an
intuitive behavior Abe and Soltys (2019) or a persuasion technique Siadati et al. (2017) to get what they want
from victims Williams et al. (2017); Abe and Soltys (2019).

5. LONELINESS. This PF describes one’s subjective perception of discrepancy between the desired and the
actual social companionship, connectedness, or intimacy Buecker et al. (2020). It is often exploited by social
engineering attacks because the feeling of alienation from peers makes people vulnerable Williams et al.
(2017); Lekati (2018). The psychological reason is that attackers can exploit the need for attention that
accompanies the feeling of loneliness, which may be even more relevant to elder people Lin et al. (2019b). A
study of 299 participants Deutrom et al. (2021) found that loneliness positively predicts problematic internet
uses that can be exploited by social engineering attacks.

The preceding discussion suggests that emotion PFs have been widely exploited by attacks. However, there is no deep
or quantitative understanding of their impact on individuals’ susceptibility to attacks.

Social Psychology PFs. These PFs describe one’s interpersonal behaviors and often involve connection, inﬂuence, and
demand/request interactions between the individual and one or more others. There are 8 such PFs, among which the
ﬁrst 6 are derived from Cialdini’s principles of persuasion.

1. AUTHORITY. This PF describes power or dominance over someone Aldawood and Skinner (2019b). Social
engineering attackers use AUTHORITY to lure their victims to divulge conﬁdential information, especially
through spear phishing Zheng et al. (2019). BullÃl’e et al Bullée et al. (2018) found that, out of the six
principles of persuasion, the effect of authority alone exceeds that of the other ﬁve principles together. It is
worth mentioning that attackers often exploit AUTHORITY and SCARCITY (which is described below) together
Zheng et al. (2019). An empirical study with 612 participants Workman (2007) showed that individuals who
are more obedient to authority succumb more frequently to social engineering attacks.

2. RECIPROCATION. This PF describes the tendency to pay back a favor done for them in the past Lea et al.
(2009); Lin et al. (2019b); Ghaﬁr et al. (2016). It is sometimes tied to people’s urge to CONSISTENCY
(described below) Schaab et al. (2017). BullÃl’e et al Bullée et al. (2018) found that reciprocation is the third
most used principle of persuasion exploited by social engineering attacks.

3. LIKING (SIMILARITY). This PF describes individuals’ tendency to react positively to those with whom they
hold some kind of relationship Schaab et al. (2017). It reﬂects that people may be persuaded to obey others if
they display certain favourable or familiar characteristics Frauenstein and Flowerday (2020). This PF has been
exploited to create proﬁles that portray trusted traits or appear friendly to lure victims Williams et al. (2017).
Bullee et al. Bullée et al. (2018) found that LIKING is widely exploited by social engineering attacks. Hatﬁeld
Hatﬁeld (2018) found that LIKING is an individual variable that explains a person’s tendency to fall victim to
social engineer attacks.

4. SCARCITY. This PF describes the lack of goods/services and is used to lure their victims. It has been widely
exploited in online scams Williams et al. (2017); Bullée et al. (2018) and phishing emails. For example,
Heijden et al. Van Der Heijden and Allodi (2019) found that SCARCITY is a vulnerability trigger which social
engineering attackers often craft in their phishing emails to push users to respond. This PF is often exploited
together with the AUTHORITY PF to lure victims into submitting to their demands Zheng et al. (2019); Kearney
and Kruger (2016).

7

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

5. SOCIAL PROOF. This PF describes one’s tendency to imitate others regardless of the importance or correctness
of the behavior Algarni et al. (2017); Frauenstein and Flowerday (2020); Van Der Heijden and Allodi (2019);
Moody et al. (2017); Wang et al. (2021). It can put people at risk because they tend to let down their suspicion
when everyone else appears to share the same or a similar behavior Schaab et al. (2017). In an experiment with
50,000 Facebook users, Das et al. Das et al. (2014) found that users with ten or more Facebook friends tend to
update their security settings after being informed that their friends have updated their own security settings.
6. CONSISTENCY (aka COMMITMENT). This PF describes the degree to which one is dedicated to a person,
object, task, or ideal Wang et al. (2021). Social engineering attacks use commitment to persuade their victims
Ghaﬁr et al. (2016). Algani et al. Algarni et al. (2017) found that dogmatic adherence to past decisions may
inﬂuence the decisions a person will make in the future. Social engineering attacks can exploit this consistency
to exploit victims without their knowledge Van Der Heijden and Allodi (2019); Kano and Nakajima (2021).
7. DISOBEDIENCE. This PF describes one’s dogmatic refusal to obey authority or rules set forth by authority,
which can make one susceptible to social engineering attacks Collier and Collier (2020). While it is well
known that people who are more trusting and obedient to authority are more susceptible to social engineering
attacks Jampen et al. (2020), it is less know that willful disobedience of employees can also be exploited by
social engineering attacks Kirlappos et al. (2014).

8. RESPECT. This PF describes an individual’s esteem for another, which is the degree to which they are perceived
as valuable or worthwhile to the individual in question Algarni et al. (2017). For example, an individual may
not question a suspicious request from a friend (e.g., an unsolicited email that contains a link) out of respect
for their relationship Redmiles et al. (2018). This PF may be exploited together with the aforementioned
AUTHORITY Abe and Soltys (2019); Ghaﬁr et al. (2016).

The preceding discussion suggests the following PFs have been widely exploited by social engineering attacks:
AUTHORITY, SCARCITY, LIKING (SIMILARITY), and RECIPROCATION. Deep understanding of these PFs might shed
light on the design of effective defense. For example, an effective defense may ﬁrst identify whether an incoming email
falls into the AUTHORITY category and if so tailored defenses may be used to decide whether the email is indeed from
an authority; this would be more effective than using the same detector which treats all incoming emails equally without
leveraging the PFs behind them.

Personality and Individual Difference PFs. These PFs are relatively stable and dispositional and differentiate one
individual from another. For example, some people are habitually more meticulous and attentive to detail than others,
while some people are habitually more trusting.

1. DISORGANIZATION. This PF describes the tendency of an individual to act without prior planning or to allow
their environment to become or remain unstructured or messy. These conditions may blind them to anomalies
or cues of social engineering attacks, resulting in higher susceptibility Collier and Collier (2020).

2. FREEWHEELING. This PF describes the degree of one’s disregard for rules or conventions and of their
unconstraint or disinhibition. This PF contributes to ones’ susceptibility to social engineering attacks Collier
and Collier (2020).

3. INDIVIDUAL INDIFFERENCE. This PF describes the degree to which one shows disinterest toward an assigned
or necessary task. A sustained indifference towards security can cultivate a culture of risky human behaviors,
which can be exploited by social engineering attacks Chowdhury et al. (2019).

4. NEGLIGENCE. This PF describes an individuals’ failure to take proper care during a particular task. It is
an important reason of security breaches Safa et al. (2015); Adil et al. (2020); Li et al. (2019); Ndibwile
et al. (2019). Li et al. Li et al. (2019) reported that 27% of data breaches are due to negligent employees or
contractors, who usually have remote access to organizations’ internal networks.

5. TRUST. This PF describes the tendency of one to trust or believe in someone else (i.e., not doubting the
honesty of others). People who are more trusting are more susceptible to social engineering attacks Jampen
et al. (2020), which is not surprising because developing trust is a key element of social engineering attacks
Zheng et al. (2015a); Aldawood and Skinner (2019b). Moreover, people are predisposed to trust others
they view as likable and phishers make use of this PF to scam victims Hatﬁeld (2018). In a study with 612
participants, Workman Workman (2007) found that people who are more trusting succumb more frequently to
social engineering attacks.

6. SELF CONTROL. This PF describes one’s ability to regulate their decision-making processes in the face
of strong emotions and desires. A lack of self control allows individuals to fall victim to online scammers
Williams et al. (2017). Individuals with low self-control tend to exhibit a higher willingness to take risks in
situations that violate cybersecurity principles Chowdhury et al. (2019); Van de Weijer and Leukfeldt (2017);
Holt et al. (2020).

8

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

7. VULNERABILITY. This PF describes the degree to which one is in need of special care, support, or protection
because of age, disability, or risk of abuse or neglect. In a study aiming to identify those at greater risk of
falling victim to social engineering attacks in an organization, Bullee et al. Bullee et al. (2017) ﬁnd that
employees with one year of service or less are more vulnerable to spear phishing (52.07%) victimization
compared to employees with eight years of services (23.19%).

8. IMPATIENCE. This PF describes one’s frustration while waiting for a particular event to occur or at the length
of time needed to accomplish a task. Holt et al. (2020). Impatient individuals may be more susceptible to
social engineering attacks because they do not carefully examine contents or cues of social engineering attacks,
especially when they focus on immediate gratiﬁcation Holt et al. (2020).

9. IMPULSIVITY. This PF describes the tendency of one acting without much thought Das et al. (2019a). In a
study with 53 randomly selected participants (undergraduate students), it was found that participants who
scored low on impulsivity better managed phishing emails Welk et al. (2015). In another study, it was found
that individuals who are sensation-seeking, which is a form of impulsivity, were more likely to become
scammed Whitty (2018).

10. SUBMISSIVENESS. This PF describes the degree of one’s readiness to conform to authority or will of others. In
a study with approximately 200 participants, it is found that high submissiveness implies a high susceptibility
to phishing emails Alseadoon et al. (2012).

11. CURIOSITY. This PF describes the degree at which one desires to know something. Online scammers exploit
victims’ curiosity to encourage errors in judgement and decision-making Williams et al. (2017) or serve as a
persuasion technique to lure their victims Siadati et al. (2017); Xiangyu et al. (2017).

12. LAZINESS. This PF describes the degree of one’s voluntary inability to carry out a task with the energy
required to accomplish it. Laziness makes people unwilling to do the necessary work or apply the effort to
mitigate risk, and thus makes them more susceptible to social engineering attacks Wang et al. (2020).

13. VIGILANCE. This PF describes the degree that one is watchful for possible dangers or anomalies. A high
vigilance makes one less vulnerable to social engineering attacks Tu et al. (2019); Ndibwile et al. (2019). In a
phishing experiment with 3000 university students, it was found that VIGILANCE reduced susceptibility to
scams Tu et al. (2019). However, even though an individual with a high VIGILANCE, who usually does not
want to open a suspicious email, may actually end up opening it due to spontaneous CURIOSITY Jalali et al.
(2020). This highlights the possible interactions between PFs, namely that one PFs may dominate another
under certain circumstances, which explains the difﬁculty in coping with social engineering attacks.

14. OPENNESS. This PF describes one’s active imagination and insight Cherry (2012). Individuals with high
openness are often curious about the world and other people, eager to learn new things, enjoy new experiences,
and are more adventurous and creative. High oppenness has been found to increase susceptibility to phishing
attacks Frauenstein and Flowerday (2020); Das et al. (2019a).

15. CONSCIENTIOUSNESS. This PF describes one’s thoughtfulness, impulse control, and goal-directed behaviors.
People with high conscientiousness tend to be organized, mindful of details, self-disciplined, goal-oriented,
proﬁcient planners, and considerate about how their behaviors might affect others Cherry (2012); Frauenstein
and Flowerday (2020). It is found that people with a high conscientiousness are less susceptible to spear
phishing attacks Halevi et al. (2015).

16. EXTRAVERSION. This PF, also known as EXTROVERSION, describes the degree to which one is sociable,
assertive, talkative, and emotionally expressive Cherry (2012). People with a high extraversion are outgoing
and tend to gain energy in social situations. A study found that EXTRAVERSION (and OPENNESS and
AGREEABLENESS) increase one’s susceptibility to phishing emails Alseadoon et al. (2015).

17. AGREEABLENESS. This PF describes one’s attributes related to trust, altruism, kindness, affection, and
other prosocial behaviors Cherry (2012). A study found that people with a high AGREEABLENESS (and
NEUROTICISM, which is described below) are more susceptible to phishing attacks Yuan et al. (2019).

18. NEUROTICISM. This PF describes one’s moodiness and emotional instability. People with high NEUROTI-
CISM often exhibit mood swings, anxiety, irritability, and sadness Cherry (2012). Individuals with high
NEUROTICISM are more susceptible to phishing attacks Yuan et al. (2019).

We observe that enhancing some PFs (e.g., VIGILANCE) and reducing others (e.g., OPENNESS) can reduce one’s
susceptibility to social engineering attacks. These should be leveraged to design future defenses. Moreover, the PFs
are not independent of, or orthogonal to, each other. This suggests the importance of characterizing the relationships
between them (e.g., “OPENNESS increases CURIOSITY”) because it would help identify the root cause of susceptibility
to social engineering attacks.

9

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Workplace PFs. These PFs have to do with the culture and organizational structure of workplace. This is relevant
because various workplace environments may result in various levels of stress, employee engagement, or employee
loyalty.

1. WORKLOAD. This PF describes the amount of work that one has to do. A survey of 488 employees at
three hospitals showed that the level of employee workload is positively correlated with the likelihood of
employees clicking on phishing links Jalali et al. (2020). Another study found that subjective mental workload
creates memory deﬁcit that leads to an inability to distinguish between real and fake messages, increasing
susceptibility to attacks Aldawood and Skinner (2019a).

2. STRESS. This PF describes the physical, emotional, or psychological strain on a person incurred by their
environment. It has been found that when people are stressed, their ability to notice suspicious communications
(e.g., distinguishing real from fake messages) is reduced, making them more susceptible to social engineering
attacks Williams et al. (2017); Aldawood and Skinner (2019a).

3. BUSYNESS. This PF describes the degree to which one has too much to do, which may or may not be
associated with workload. People with a high BUSYNESS are more susceptible to phishing emails as they do
not pay much attention to details Chowdhury et al. (2019) or have reduced cognitive processing Conway et al.
(2017).

4. HURRY. This PF describes the degree one is rushing to complete a task. Hurried people may not adhere to
secure practices because they reduces the amount of time available for the individual’s active task Chowdhury
et al. (2019); these people are susceptible to social engineering attacks under these circumstances Rastenis
et al. (2020).

5. AFFECTIVE COMMITMENT. This PF describes one’s emotional attachment to an organization. A study with
612 participants found that people with a high AFFECTIVE COMMITMENT more likely fall victim to social
engineering attacks Workman (2007).

6. HABITUATION. This PF describes one’s tendency to perform a particular task repeatedly. A study on how
users perceive and respond to security messages using eye-tracking with 62 participants found that people
gazed less at warnings over successive viewings (i.e., they were more habituated to the warnings) and thus
were less attentive to security warnings Brinton Anderson et al. (2016). In other words, increased habituation
increases susceptibility to attacks.

The preceding discussion suggests that workplace PFs have a signiﬁcant impact on individuals’ susceptibility to social
engineering attacks and should be taken into consideration when designing future defenses.

4.2 Systematizing Psychological Techniques (PTs)

Our analysis of the literature prompts us to consider the following 13 PTs.

1. Urgency. Urgency has an impact on cybersecurity when a victim is confronted with a situation which requires
immediate action or is ostensibly under time pressure Chowdhury et al. (2019), such as decreasing the chance
of detecting deceptive elements in a message Vishwanath et al. (2011). It leverages the COGNITIVE MISER,
FEAR and NEGLIGENCE PFs. It is often used in scareware attacks to urge users to install software to avoid
threats (e.g., viruses) or missing a plug-in which prevents them from viewing some desired contents Nelms
et al. (2016).

2. Attention Grabbing. This technique uses visual and auditory elements to prompt a victim to focus attention on
deceptive attack elements to increase compliance. It leverages the ABSENTMINDEDNESS and CURIOSITY PFs.
The malvertising, scareware, and click-baiting attacks use attention grabbing along with visceral triggers and
incentives (below) to encourage compliance Nelms et al. (2016).

3. Visual Deception. This technique repurposes benign visual elements to induce TRUST Vishwanath et al. (2011).
It leverages the OVERCONFIDENCE, TRUST, and HABITUATION PFs. The typosquatting and clone-phishing
attacks exploit this technique by creating URLs that are visually similar to benign URLs.

4. Incentive and Motivator. This technique encourages a desired behavior or compliance with a request. Incentive
provides external rewards for action, while motivator provides internal rewards (i.e., gratiﬁcation) for an
individual. In social engineering attacks, incentive often leverages visceral triggers, which are commonly used
in malvertising and click-baiting attacks as well as in the Nigerian scam Herley (2012). Motivator exploits
SYMPATHY, EMPATHY, LONELINESS, and DISOBEDIENT. Wire transfer scams exploit victims’ sympathy for
the attacker as a motivator to encourage someone to transfer money to an attacker who claims to have made an
erroneous money transfer.

10

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

5. Persuasion. This technique encourages a particular behavior by exploiting the LIKING, RECIPROCATION,
SOCIAL PROOF, CONSISTENCY, and AUTHORITY PFs. The effectiveness of each persuasion technique depends
on other things like age Lin et al. (2019b) and request type Goel and Jain (2018); Alohali et al. (2018). The use
of persuasion is prevalent in email-based attacks such as phishing Goel and Jain (2018); Ferreira and Lenzini
(2015); Wright et al. (2014).

6. Quid-Pro-Quo. Quid-Pro-Quo in Latin means "something for something". This technique attempts to make a
victim willing to take risk on exchange for a high payoff (e.g., money, free services or avoiding embarrassment).
It leverages the RECIPROCATION, GREED, and DISHONESTY PFs Stajano and Wilson (2011). For example, an
attacker can impersonate a police ofﬁcer to make a victim pay for illegal content (e.g., pornography) on the
victim’s computer Heartﬁeld and Loukas (2015); otherwise, the attacker threatens with arresting the victim for
the possession of illegal content. In the Nigerian Prince Scam (419) Herley (2012), the Quid-Pro-Quo is the
expectation that the victim give a small amount of money to receive a larger amount of money later.

7. Foot-in-the-Door. This technique attains compliance for a large request by making small requests over time
Freedman and Fraser (1966). It exploits the CONSISTENCY PF. It is commonly used in honey trap and
catﬁshing.

8. Trusted Relationship. This technique exploits an existing trust relationship by taking advantage of the
AUTHORITY, RESPECT, and TRUST PFs. For example, through LinkedIn (a trusted service provider), an
attacker posing as a recruiter can connect to employment-seeking victims Allodi et al. (2019); spamdexing
(SEO) exploits a user’s trust in a search engine provider’s (e.g., Google) results; Business Email Compromise
exploits the trusted relationship between an executive staff ofﬁcer and a subordinate employee.

9. Impersonation. This technique assumes a false identity to increase a victim’s compliance. It exploits the
AUTHORITY, RESPECT and TRUST PFs. In OSN-based attacks like Honey Trap, an attacker uses fake proﬁles
to lure victims into interacting with them Algarni et al. (2017); an attacker using Business Email Compromise
assumes the persona of a senior executive to exploit their authority by prompting a victim to transfer money to
an account Junger et al. (2020).

10. Contextualization. This technique projects an attacker as a member of the victim’s group in order to establish
commonality with potential victims and increase the success of attacks Goel et al. (2017); Rajivan and Gonzalez
(2018). It is often used in attacks like whaling, catﬁshing, and drive-by downloads Goel and Jain (2018).

11. Pretexting. This technique increases the engagement of victim with the attacker. It leverages the TRUST PF.
For example, phishing emails can use this technique to increase responsiveness by adding elements that refer
to current events like holiday festivities or news Al-Hamar et al. (2010); Goel et al. (2017).

12. Personalization. This technique uses personal information to tailor messages or express similar interest to
the victim to engender trust Hirsh et al. (2012); Jagatic et al. (2007). It exploits the PERSONALITY and
INDIVIDUAL DIFFERENCES PFs.

13. Affection trust. This technique establishes an affectionate relationship with a victim. It exploits the AFFECTIVE
COMMITMENT PF. Affection does not lower risk perceptions or increase trust, but makes an individual more
willing to take risks and thus increases compliance McAllister (1995). It is commonly used in catﬁshing and
honey traps.

As we will see, these PTs help build bridges to map social engineering attacks and the PFs they exploit.

5 Systematizing Social Engineering Attacks

This section presents the objectives of social engineering attacks and a taxonomy of them. This would help us
understand how attackers may choose speciﬁc attacks based on their objectives, which could help us design effective
defenses against threats of given objectives. It is worth mentioning that in order to see if we overlooked some literature
investigating these attack names, we conducted another round of search by using the attack names as keyword in the
digital libraries mentioned above. This leads to 6 papers which were not identiﬁed in the previous search. In addition,
we were aware of two social engineering attacks which are discussed in online materials but not academic literature,
namely Honey Trap Copado (2021) and Angler Phishing Fraudwatch (2017); Velasquez (2017), which we included as
well.

5.1 Attack Objectives

We categorize social engineering attacks according to the following four main types of attack objectives.

11

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

1. Getting access to systems. Social engineering attacks are often used as a ﬁrst step of full-ﬂedged attacks

against networked systems (e.g., advanced persistent threats).

2. Stealing money. Social engineering attacks such as phishing are often used to steal victims’ money.

3. Stealing sensitive information. Social engineering attacks such as phishing are often used to steal sensitive

information such as passwords.

4. Revenging. Social engineering attacks can be used to take revenge against enterprises, organizations, or

individuals by releasing damaging information about them Chitrey et al. (2012).

5.2 Attacks

Figure 2 highlights the taxonomy of Internet-based social engineering attacks based on the medium they leverage: email
vs. website vs. online social network (OSN). It is worth metioning that these attacks relate to each other; for example,
the below-mentioned drive-by download attack may leverage various kinds of phishing emails to deceive a victim to
visit malicious websites. These attacks are elaborated below.

Figure 2: Taxonomy of social engineering attacks exploiting emails, websites, and online social networks (OSN), where
BEC stands for Business Email Compromise.

Email-based Attacks. This category includes six attack techniques, which are varying ﬂavors of phishing. These
attacks are largely complementary to each other.

1. Traditional Phishing. In this attack, a phishing email is sent without a particular target in mind, but with the
hope that someone will fall victim to it (i.e., no personalization in such phishing emails) Ho et al. (2019);
Dou et al. (2017); Steves et al. (2019). This attack is often motivated to steal money. This attack exploits the
GREED factor because it attempts to entice victims for rewards such as in the 419 scam that promises a large
amount of money if a victim pays a small amount of money.

2. Spear Phishing. A spear phishing email contains information personalized for a speciﬁc target, usually
addressing the target by name and title. This attack is often motivated to steal money, get access to systems,
steal sensitive information, or for revenge. This attack exploits the AUTHORITY factor because it attempts to
deceive a victim into believing that the phisher/attacker is a person of authority and a victim must act promptly
Ho et al. (2017); Heartﬁeld and Loukas (2015); Goel and Jain (2018).

3. Clone Phishing. Such an email is cloned from a previously sent/received email, replaces its links and/or
attachments with malicious ones, and spoofs the legitimate sender’s email address so that the target would not
not suspect the clone email Bhavsar et al. (2018); Alam et al. (2020); Prem and Reddy (2019). This attack is
often motivated to steal money and sensitive information. This attack exploits the TRUST factor because it
attempts to make a victim think that the cloned email is a continuation of a previous communication and in
order to help comply with the attacker’s request.

4. Whaling. A whaling email is similar to a spear phishing email by targeting speciﬁc individuals. Unlike spear
phishing which can target arbitrary individuals, whaling emails target management, such as CEOs Goel and
Jain (2018); Heartﬁeld and Loukas (2015); Salahdine and Kaabouch (2019). This attack is often motivated to
steal money, get access to systems, steal sensitive information, or for revenge. This attack exploits the TRUST

12

Internet-Based Social Engineering AttacksOSNWebsite +Traditional Phishing +Spear Phishing +Clone Phishing +Whaling +Wire Transfer Scam +BEC +Scareware +Reverse SE +Typosquatting +Pharming +Spamdexing +Water Holing +Drive-by Download +Tabnabbing +Click-baiting +Ad Fraud +Malvertising+Honey Trap+Catfishing+Angler Phishing+App Spoofing+LikejackingEmailInternet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

factor because it attempts to deceive, for example, a CEO into believing in the content an email and then
following the instructions described in it, often by impersonating someone that the victim knows.

5. Wire Transfer Scam. In this attack, an email is sent to targeted individuals in order to deceive the individual
into sending money (via, for example, Western Union) to pay for services or goods Burch et al. (2015). The
attacker often impersonates a service company, such as a utility, that threatens that the victim’s services will be
cut off immediately unless a wire transfer is made, ans sometimes impersonate reputable individuals Chaganti
et al. (2021). It is motivated to steal money and exploits the FEAR factor because it threatens to cut services to
victims.

6. Business Email Compromise (BEC). This attack uses email frauds against private, government and non-proﬁt
organizations, by targeting speciﬁc employees with spoofed emails impersonating a senior colleague, such as
the CEO or a trusted customer Cidon et al. (2019); Venkatesha et al. (2021). This attack is motivated by the
objective of stealing money Cidon et al. (2019). It exploits the TRUST factor because it attempts to deceive
victims into thinking that they are paying a legitimate bill for goods/services received from a trusted party.

Website-based Attacks. This category includes 11 attacks. These attacks are not necessarily complementary or
orthogonal to each other because one attack may leverage another as a supporting technique (e.g., Ad Fraud may use
malvertizing as a support technique).

1. Scareware. This attack is to pop up a window with warning content which tells the user that the computer has
been infected by malware and that the user should click a link or call a number shown on the pop-up window
to get help. The attacker’s intent is to scare the user to click the link or to call the number shown on the pop-up
window, which will give the attacker the opportunity to access the user’s sensitive information or ask the user
to send a gift card number to have the problem ﬁxed remotely. Most scareware do not harm the computer, but
are instead used to scare victims to provide information or money to the attacker Or-Meir et al. (2019). This
attack exploits the FEAR factor because it scares victims into thinking that their computer is compromised and
needs immediate attention.

2. Typosquatting (or URL Spooﬁng). This attack takes a user to a malicious website when the user mistypes a
character in a URL, such as mistyping www.bank0famerica.com for www.bankofamerica.com, where the
former mimics the latter in terms of website content while incorporating a malicious payload Heartﬁeld and
Loukas (2015). This attack exploits the NEGLIGENCE factor because it anticipates individuals mistyping.
3. Spamdexing (or Search Engine Poisoning). This attack tricks a search engine to list a malicious website on
the top of the list returned by a search Heartﬁeld and Loukas (2015). It is effective because many users trust
the search results listed on the top and treat them as most relevant, causing them to most likely visit them. It
exploits the TRUST factor because it anticipates that users treat the websites on the top of search results as
most relevant.

4. Drive-by Download. This attack is used to compromise a vulnerable browser when it visits a malicious or
compromised website, possibly prompted by phishing emails containing the malicious URL Provos et al.
(2007). It exploits the TRUST factor because a victim may trust the website in question, or the VULNERABILITY
factor when a victim is not aware of this attack, or the NEGLIGENCE factor when a user does not update/patch
a browser or does not pay careful attention to recognize malicious websites.

5. Click-baiting. This attack is to place an enticing text/image on a web page to draw the attention of visitors
so that they click on a link to a malicious or compromised website Meinert et al. (2018). An example is a
message on a website reading "Betty reveals how she gets to 100 years of age without ever doing sports". It
exploits the CURIOSITY factor because it entices victims to click on the link to ﬁgure out more information.
6. Malvertising. This attack abuses advertisement such that when a user clicks on the advertisement, the user
may be redirected to a malicious website Chiew et al. (2018). It exploits the TRUST factor because victims
think they are getting legitimate ads. It also takes advantage of the NEGLIGENCE factor when victims do not
perform due diligence.

7. Reverse Social Engineering. This attack creates a situation causing a victim to contact the attacker Irani et al.
(2011). It exploits the TRUST factor because it puts a victim in a situation of need, thereby contacting the
attacker.

8. Pharming. This attack builds malicious websites to steal money or sensitive information from victims when
visiting them Adil et al. (2020). It exploits the TRUST factor because victims do not think these websites are
malicious and the NEGLIGENCE factor because victims do not perform due diligence.

9. Water Holing This attack exploits vulnerabilities of third party websites to attack victims when visiting them
Wang et al. (2021). This attack if often waged to steal money or sensitive information. It exploits the TRUST
factor because victims trust that the websites that they are visiting to be secure.

13

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

10. Tabnabbing. This attack attempts to deceive a victim into visiting a malicious website which mimics a
legitimate website and asks the victim to login into the malicious website, while making the victim think that
the malicious website is the legitimate website and forwarding the victim’s login credential to the legitimate
website Salahdine and Kaabouch (2019). It often leverages the same origin policy of browsers, where a second
page on a browser can access scripts from another page as long as both pages have the same origin Steffens et al.
(2019). It attempts to steal sensitive information (e.g., login credentials). It exploits the ABSENTMINDEDNESS
factor because a victim thinks that a previously visited website is asking for login credentials again.

11. Ad Fraud. This attack exploits ads to defraud advertisements, where the fraudster deceives the victims that are
using a platform to advertise their goods and services by generating fake trafﬁc (possibly via malvertising,
scareware, click-baiting, and likejacking) Kanei et al. (2020). It often attempts to steal money in the sense that
the ads do not incur real trafﬁc from real users, but forged trafﬁc instead. It exploits the TRUST factor because
victims believe that they are getting legitimate trafﬁc to their advertisements.

Online Social Network-based (OSN-based) Attacks. This category includes ﬁve attack techniques.

1. Honey Trap. This attack targets a particular victim with a love-related relationship and may be seen as the
counterpart of spear phishing. For example, John knows that Philip likes blonds and thus creates a fake proﬁle
of a blond on Instagram to like and comment on Philip’s posts; Philip sees a blond liking his posts and thinks
it is an opportunity for him to meet a blond; once a relationship is established, John can deceive Philip in
many ways, including ﬁnancial extortion Copado (2021). Our evaluation shows that this attack exploits the
LONELINESS factor because lonely people turn to the platform to seek attention.

2. Catﬁshing. This attack creates a fake persona to seek online dating to lure victims interested in the persona,
similar to the traditional phishing because the attack does not target a speciﬁc victim Simmons and Lee (2020).
For example, the attacker posts as women to lure men to send them money for made-up reasons, for example,
“My Internet service will be suspended for accumulated bills, please help me pay or I’ll not be able to chat
with you if my Internet is suspended". This attack exploits the LIKING (SIMILARITY) factor because victims
have the tendency to react positively to someone that they have some relationship with Schaab et al. (2017).

3. Angler Phishing. This attack is used to lurk among the comments posted by users on social forums, like yelp,
and then takes advantage of any comment that may need a resolution to Fraudwatch (2017). For example,
an attacker may see a comment of a customer complaining about a bank transaction or a purchase. The
attacker then poses as a customer satisfaction specialist of that company and asks the customer for detailed
information in order to address the customer’s problem Velasquez (2017). An unsuspecting customer may
give away personal information with the hopes that the problem will be resolved, not knowing that they have
been phished. This attack exploits the VULNERABILITY factor because frustrated victims desperately need
solutions and the TRUST factor that victims put in the service companies.

4. App Spooﬁng. This attack uses bogus apps to spoof legitimate ones on platforms which are less regulated than
(for example) iPhone App stores or Google Play Store. When a user uses the same credential for multiple
platforms, the attacker can steal a user’s credentials to get access to the user’s account on other platforms
Malisa et al. (2017). It exploits the OPENNESS and CURIOSITY factors because users who are open and curious
will often try new things.

5. Likejacking. This is the social media version of click-jacking attack. This attack places a transparent layer (e.g.
transparent iframe) on a legitimate webpage so that when a user clicks anywhere on the webpage, the user
is actually clicking on the transparent layer which directs the user to the attacker’s website Alabdan (2020);
Calzavara et al. (2020). In Likejacking, when a user sees the “like” button on a Facebook post, on top of which
there is a transparent layer not visible to the user, the user may click on the page and then be directed to a
malicious website. This attack exploits the LIKING AND SIMILARITY factor because the attacker sets the trap
knowing that people tend to like comments of people they follow on OSN.

5.3 Discussion

Attackers have been exploiting PFs to wage website-based social engineering attacks. For example, a phishing email
can be crafted to exploit PFs like FEAR, AUTHORITY, and CURIOSITY, causing victims to react in a manner desired by
the attacker. In principle, exploiting PFs increases the likelihood that a victim will overlook important cues of attacks.

Insight 1 Social engineering attackers have made due effort at identifying and exploiting the relevant human PFs for
waging attacks.

14

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

6 Systematizing Social Engineering Defenses

Similar to the systematization of attacks, we naturally divide defenses into three categories: email-based, website-based,
and online social network-based attacks. Although it is intuitive to present defenses with respect to each attack
mentioned above, this is less constructive because one defense may be able to defend against multiple attacks. Since
our systematization is centered on PFs, we further divide defenses into two sub-categories: those that do not leverage
PFs and those that leverage PFs. This makes it easy to recognize which PFs have been leveraged for defense purposes.

6.1 Defenses against Email-based Attacks

Defenses Not Leveraging PFs. Most studies on defenses against email-based social engineering attacks fall into this
category. Defenses against various kinds of phishing have been extensively investigated, for which we refer to previous
surveys for a large body of literature Khonji et al. (2013); Ali et al. (2020); Jain and Gupta (2021); Sahu and Dubey
(2014); Alabdan (2020). Ho et al. Ho et al. (2017) proposed using anomaly detection to identify real-time credential
spear phishing attacks in enterprise settings. Ho et al. Ho et al. (2019) proposed a classiﬁer for detecting lateral phishing
emails, which are spear phishing emails that are sent by an attacker after compromising some computers in a network
and are seemingly coming from colleagues. Cidon et al. Cidon et al. (2019) proposed a defense against Business Email
Compromise attacks by leveraging supervised learning and statistics about email histories. All these defenses, including
those which are surveyed in the previous literature, leverage technological aspects (e.g., statistical data).

Defenses Leveraging PFs. There are few studies falling into this category. These primarily focus on eye tracking,
which is related to the VIGILANCE PF. One study Pfeffel et al. (2019) leverages eye tracking to investigate gaze patterns
when individuals are reading phishing emails. However, it showed: (i) even in the best-case scenario, when individuals
are expecting phishing emails and are motivated to discover them, many cannot distinguish a legitimate email from a
phishing email; and (ii) well-crafted phishing emails can still fool 40% of the participants. This means that leveraging
eye tracking is not effective. Nevertheless, another study Heartﬁeld and Loukas (2018) shows that incorporating a
human in the defense loop can substantially reduce the success rate of some spear phishing attacks from 81% to below
10%. This highlights the importance of incorporating humans into the defense, but it is not clear how the participants
exactly achieved this and whether this can be generally applied to other settings.

6.2 Defenses against Website-based Attacks

There are many studies on detecting malicious websites, including website-based social engineering attacks. The
simplest method would be to use blacklists to ﬁlter malicious websites. However, the trustworthiness of blacklists is
questionable because they may be outdated and/or be provided in a black-box fashion without justiﬁcation Xu et al.
(2013).

Defenses Not Leveraging PFs. There are many studies in this sub-category, primarily leveraging Artiﬁcial Intelli-
gence/Machine Learning (AI/ML). For example, VisualPhishNet Abdelnabi et al. (2020) leverages visual similarities
between websites to detect phishing websites; Phishpedia Lin et al. (2021) leverages deep learning to detect phishing
websites via identity logos; Mnemosyne Allen et al. (2020) is a postmortem forensic analysis engine for accurately
reconstructing, investigating, and assessing the ramiﬁcations of watering hole attacks; Mao et al. Mao et al. (2018)
presents a method to detect phishing websites by leveraging learning-based aggregation analysis to decide page layout
similarity; Nakamura and Dabashi Nakamura and Dobashit (2019) propose to detect new phishing sites by leveraging
domain name generation and other attributes.

Another approach is to leverage hardware features. For example, Fidelius Eskandarian et al. (2019) is an architecture
which uses trusted hardware enclaves to protect sensitive user information from potentially compromised browsers and
operating systems; FIDO (First IDentity Online) is a web-authentication mechanism for mitigating phishing attacks in
real time, by leveraging one-time-password as a second factor for authentication Ulqinaku et al. (2020).

Defenses Leveraging PFs. There are few studies falling into this sub-category. One of them is Aladawy et al. (2018),
which presents a game-based training against social engineering attacks by leveraging social psychology PFs with the
help of cards. The game is designed to provide knowledge and train people through social psychology theories on
resistance to persuasion. This game is further enhanced to contain more content and to accommodate contexts Goeke
et al. (2019).

15

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

6.3 Defenses against Online Social Network-based Attacks

There are many studies on detecting OSN-based social engineering attacks. Since defenses against website-based social
engineering attacks can be leveraged to defend against some OSN-based social engineering attacks, we will focus on
the defenses that are unique to OSN-based attacks.

Defenses Not Leveraging PFs. These defenses primilarily leverage AI/ML techniques. For example, Yuan et al. Yuan
et al. (2019) present a method to Sybil accounts; Xu et al. Xu et al. (2021) present a method to detect abusive accounts
in OSNs; Wang et al. Wang et al. (2020) present a chatbot to actively collect intelligence to help detect e-commerce
frauds.

Defenses Leveraging PFs. The only study we are aware of that falls into this sub-category is Junger et al. (2017),
which investigates the effectiveness of two defense interventions: one is to prime the user with cues to raise awareness
about the dangers of social engineering attacks and the other is to warn against the disclosure of personal information.
They ﬁnd that warnings do help improve the user’s behavior but most users do not adjust their behaviors when monetary
rewards are at stake. This does suggest the importance of incorporating PFs into defenses.

6.4 Discussion

The preceding section suggests that current defenses primarily leverage technological solutions, especially AI/ML,
but rarely incorporates PFs; when a defense does incorporate a human in the loop, a much higher effectiveness can
be expected Heartﬁeld and Loukas (2018). Since social engineering attacks primarily exploit weaknesses in human
information processing, we argue that effective defenses would have to incorporate the “right” PFs because they are the
“root cause” of the problem in a sense, where the “right” factors need to be precisely pinned down in future studies.

Insight 2 Current defenses against social engineering attacks have achieved limited success because they do not
adequately take into account human PFs.

7 Systematizing the Relationships between Attacks, PTs, PFs, and Defenses

Figure 3 systematizes the aforementioned relationships.

Relationships between Defenses and Attacks. First, email-based defenses not leveraging PFs have been proposed to
defend against the following attacks: Traditional Phishing, Spear phishing, Clone Phishing, Whaling, Wire Transfer,
and BEC (Business Email Compromise). Whereas, email-based defenses leveraging PFs have been proposed to defend
against Traditional Phishing, Spear Phishing, and Clone Phishing. Second, website-based defenses not leveraging
PFs have been proposed to defend against Traditional Phishing, Scareware, Drive-by Download, and Watering Holes.
Whereas, website-based defenses leveraging PFs have been proposed to defend against Traditional Phishing, Click-
baiting, Reverse Social Engineering, Honey Trap, and Catﬁshing. Third, OSN-based defenses not leveraging PFs have
been proposed to defend against OSN-based Honey Trap, Catﬁshing, and Angler phishing. Whereas, we are not aware
of any OSN-based defenses leveraging PFs.

Relationships between Attacks and PTs. Social engineering attacks leverage PTs to take effect on PFs. In what
follows we systematize the PTs leveraged by email-based, website-basedm and OSN-based attacks, respectively.

First, PTs leveraged by email-based social engineering attacks are summarized as follows. (1) Traditional Phishing
leverages Urgency, Visual Deception, Incentive and Motivator, and Quid-Pro-Quo. (2) Spear Phishing leverages
Urgency, Visual Deception, Incentive and Motivator, Quid-Pro-Quo, Contextualization, Pretexting, and Personalization.
(3) Clone Phishing leverages Urgency, Attention Grabbing, Visual Deception, Incentive and Motivator, Persuasion,
Trusted Relationship, Impersonation, Pretexting, and Personalization. (4) Whaling leverages the Contextualization
technique. (5) Wire Transfer Scam leverages Incentive and Motivator as well as Impersonation. (6) BEC (Business
Email Compromise) leverages Trusted Relationships and Impersonation.

Second, PTs leveraged by website-based attacks are summarized as follows. (1) Scareware leverages Quid-Pro-Quo,
Incentive and Motivator, and Attention Grabbing. (2) Typosquatting leverages Visual Deception. (3) Spamdexing
leverages Trusted Relationship, Incentive and Motivator, and Attention Grabbing. (4) Drive-by Download leverages
Visual Deception. (5) Click-Baiting leverages Persuasion and Visual Deception. (6) Malvertising leverages Incentive
and Motivator, and Attention Grabbing. (7) Reverse Social Engineering leverages Incentive and Motivator as well
as Impersonation. (8) Pharming leverages Trusted Relationship. (9) Water Holing leverages Trusted Relationship.
(10) Tabnabbing leverages Visual Deception and Impersonation. (11) Ad Fraud leverages Persuasion, Incentive and
Motivator, Attention Grabbing, and Visual Deception.

16

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Figure 3: Relationships between the PFs, the defenses, the attacks, and the PTs, where the PFs are separated by dashed
lines into the aforementioned ﬁve categories described in the text. The PFs with empirical quantitative studies are
represented with a ﬁlled circle and a circle otherwise. The “+” (“-”) sign indicates that a factors increases (decreases)
susceptibility; Ind = individual, com = commitment, T = Traditional.

Third, PTs leveraged by OSN-based attacks are summarized as follows. (1) Honey Trap leverages Impersonation
and Affection Trust. (2) Catﬁshing leverages Impersonation and Affection Trust. (3) Angler Phishing leverages
Impersonation and Trusting. (4) App Spooﬁng leverages Impersonation and Visual Deception. (5) Likejacking
leverages Persuasion and Visual Deception.

Relationships between PTs and PFs. Although a PT can exploit multiple PFs, we observe that a given PT often
exploits PFs within a single psychological category. This prompts us to systematize their relationships according to the
ﬁve categories of PFs as follows. First, PTs exploiting cognition PFs are summarized as follows. (1) Attention Grabbing
exploits the ABSENTMINDEDNESS and CURIOSITY factors. (2) Visual Deception exploits OVERCONFIDENCE, TRUST,
and HABITUATION. Second, PTs exploiting emotion PFs are summarized as follows. (1) Urgency leverages COGNITIVE
MISER, FEAR and NEGLIGENCE.
(2) Incentive and Motivator leverages GREED, FEAR, SYMPATHY, EMPATHY,
LONELINESS, and DISOBEDIENT. Third, PTs exploiting social PFs are summarized as follows. (1) Persuasion leverages
the LIKING, RECIPROCATION, SOCIAL PROOF, CONSISTENCY, and AUTHORITY factors. (2) Quid-Pro-Quo leverages
RECIPROCATION, and GREED. (3) Foot-in-the-Door leverages CONSISTENCY. (4) Trusted Relationship leverages
AUTHORITY, RESPECT, and TRUST. (5) Impersonation leverages AUTHORITY, RESPECT (i.e., close relationship)
and TRUST. (6) Contextualization leverages LIKING (SIMILARITY). Fourth, PTs exploiting individual differences
and personality PFs are summarized as follows. (1) Pretexting leverages the TRUST factor. (2) Personalization
leverages DISORGANIZED, FREEWHEELING, INDIVIDUAL INDIFFERENCE, NEGLIGENCE, TRUST, SELF CONTROL,
VULNERABILITY, IMPATIENCE, IMPULSIVITY, SUBMISSIVENESS, CURIOSITY,LAZINESS, VIGILANCE, OPENNESS,
CONSCIENTIOUSNESS, EXTRAVERSION, AGREEABLENESS and NEUROTICISM. Fifth, PTs exploiting workplace PFs
are summarized as follows. The Affection Trust leverages AFFECTIVE COMMITMENT.

17

DefensesAttacksPTsPFsEmail-based defenses not leveraging psychological factorsEmail-based defenses leveraging psychological factorsWebsite-based defenses not leveraging psychological factorsWebsite-based defenses leveraging psychological factorsOSN-based defenses not leveraging psychological factorsOSN-base defenses leveraging psychological factorsT. PhishingSpearphishingClone PhishingWhalingWire Transfer ScamBusiness Email CompromiseScarewareTyposquattingSpamdexingDrive-by DownloadClick-baitingMalvertisingReverse Social Engineering PharmingWater holingTabnabbingAd FraudHoney TrapCatfishingAngler phishingApp SpoofingLikejackingCognitive miserExpertiseOverconfidenceAbsentmindednessGreedFearSympathyEmpathyLonelinessAuthorityReciprocationLiking (similarity)ScarcitySocial ProofConsistency (com.)DisobedienceRespectDisorganizationFreewheelingInd IndifferenceNegligenceTrustSelf-controlVulnerabilityImpatienceImpulsivitySubmissivenessCuriosityLazinessVigilanceOpennessConscientiousnessExtraversionAgreeablenessNeuroticismWorkloadStress BusynessHurryAff. CommitmentHabituationUrgencyAttention grabbingVisual DeceptionIncentive & MotivatorPersuasionQuid-Pro-QuoFoot-in-the-DoorTrusted RelationshipImpersonationContex-tualizationPretextingPersonalizationAffection Trust+++++++++++++++++++++++++++++++++++++++-+-++++++++++++PFsCognitive miserExpertiseOverconfidenceAbsentmindednessGreedFearSympathyEmpathyLonelinessAuthorityReciprocationLiking (similarity)ScarcitySocial ProofConsistency (com.)DisobedienceRespectDisorganizationFreewheelingInd IndifferenceNegligenceTrustSelf-controlVulnerabilityImpatienceImpulsivitySubmissivenessCuriosityLazinessVigilanceOpennessConscientiousnessExtraversionAgreeablenessNeuroticismWorkloadStress BusynessHurryAff. CommitmentHabituationInternet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Relationships between Defenses and PFs. To our knowledge, VIGILANCE is the only PF that has been considered in
defenses against email-based, website-based and OSN-based attacks Tu et al. (2019); Aldawood and Skinner (2019b,a);
Alsharnouby et al. (2015); Junger et al. (2020) . This means that much research is needed before leveraging PFs to
design effective defenses. This also prompts us to explore future research directions in the next section.

Summary. Figure 3 leads to the following. First, PTs are widely exploited for attacks but are rarely incorporated into
defenses. This discrepancy gives attackers a big advantage. Second, some PTs are leveraged by attacks more often
than others. For example, impersonation, attention grabbing and visual deception are widely used across email-based,
website-based, and OSN-based social engineering attacks. This means that future defenses should target such PTs. Third,
there is a good potential to leverage workplace PFs to design effective defenses because they cannot be manipulated by
attackers.

Insight 3 Current defenses have achieved a limited success as they rarely incorporate human PFs.

8 Future Research Directions

The preceding systematization suggests that effective defenses should be guided by psychological principles. This
prompts us to seek psychological principles that can guide the design of effective defenses.

Guiding Principle: The Theory of System 1 vs. System 2 in Human Information Processing. The human mind
processes information from the environment likely through a variety of cognitive mechanisms. A popular theory
is centered at the distinction of System 1 (heuristic) vs. System 2 (analytic) Kahneman (2011). System 1 is fast,
effortless, based on heuristics, and often thought of as error-prone; whereas, System 2 is slow, effortful, and involves
deep analytical thinking Kahneman (2011). Putting another way, the theory suggests that deliberate reasoning, which
is typically logical or mathematical, falls into the scope of System 2 Neys and Pennycook (2019). While common
in psychology, the theory does not come without criticism, especially the fact that despite the characteristics of the
two processes is often clear, but the factors that determine when an individual will think analytically or rely on their
intuition is unclear Pennycook et al. (2015). This has inspired research in cognitive psychology Lin et al. (2022) using
electroencephalography (EEG) to decipher their respective underlying neural mechanisms Williams et al. (2019), and in
improving Artiﬁcial Intelligence learning from human decision making capabilities Booch et al. (2020). There have
also been attempts to improve this dual-thinking process to a three-stage dual process model of analytic engagement
Pennycook et al. (2015). Moreover, a recent development is that humans can actually process deliberate reasoning
involving logical principles in an intuitive fashion (i.e., without deliberation) Neys and Pennycook (2019). This sheds
light on leveraging the theory to guide us in understanding social engineering attacks through the psychological lens and
in designing new defenses without forcing humans to trap into System 2 when dealing with social engineering attacks.

The preceding systematization and guiding principle prompt us to propose the following research directions: (i) use
psychological principles to guide the design of a qualitative framework to describe social engineering attacks; (ii)
conduct empirical studies to quantify the effect of PFs on human susceptibility to social engineering attacks; and (iii)
leverage these quantitative ﬁndings to guide the design of effective defenses.

8.1 Creating a Qualitative Psychological Framework Tailored to Social Engineering Attacks

Our premise is that in the context of social engineering attacks, both heuristics and analytic processing can help prevent
victimization under different conditions, and it may not be accurate to regard heuristics as uniquely error-prone. We
thus use this framework as a starting point towards a more robust framework later in the paper.

In order to design effective defenses, we need to understand how the human information processing procedure interprets
information associated with these attacks. This prompts us to propose a framework for describing human information
processing of materials associated with social engineering attacks.

Figure 4 highlights the framework we propose. It is inspired by the state-of-the-art System 1 vs. System 2 framework.
The new framework has two internal components, information processing and risk attitude, which collectively determine
one’s behavior (e.g., clicking a link in a phishing email or not) based on: (i) individual baseline, namely the PFs that
may be inﬂuenced by an attack to beneﬁt the attacker; (ii) the external attacker effort at earning one’s trust (e.g., how
real a phishing email looks); and (iii) defense alerts (e.g., one’s competence in raising suspicions against phishing
emails). The framework is elaborated below.

Risk Attitude. We propose incorporating risk attitude because studies show that it affects the likelihood of social
engineering victimization and it may be independent of human information processing Conway et al. (2017); Lea et al.
(2009). This is not surprising because risk attitude affects motivators which drive humans to act Maslow (1943). There

18

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Figure 4: A qualitative psychological framework describing human information processing of social engineering attacks.

are three well-known risk attitudes: risk seeking, risk aversion and risk-neutral. For example, even when information
processing triggers suspicions, a risk-seeking user may still comply with a malicious request because the prospect of
reward exceeds the perceived risk, explaining why some people make risky decisions in cyberspace especially when
they feel they have less to lose Conway et al. (2017); Howe et al. (2012) and why some people still fall victim even if
they recognize the risk Lea et al. (2009).

Heuristic vs. Analytic Processing. This is inspired by the System 1 vs. System 2 framework. However, our goal is to
identify the conditions that would push one into heuristic processing or analytic processing, respectively.

• Heuristic processing. This uses patterns and rules, or a trial-and-error approach, to reach a decision. Heuristics
are often used in situations of uncertainty where information or time is limited. In social engineering attacks,
non-experts are more likely to rely on heuristics to determine the credibility of the message. In addition to
rules and patterns, non-expert users also rely on previous experiences (often acquired through trial and error)
to detect social engineering messages Abbasi et al. (2016); Redmiles et al. (2018). Heuristics are useful, but
can cause errors when the rules used to determine credibility are based on elements that can be manipulated by
attackers, or when they are unable to discriminate between benign and social engineering messages.

• Analytic processing. This involves evaluating multiple factors to reach a decision. It requires that an individual
is knowledgeable on factors relevant to the outcome and have the information required to support the decision.
In social engineering attacks, individuals with cybersecurity EXPERTISE are more likely to use analytic
processing to detect social engineering messages. For example, experts would consider multiple factors to
determine the credibility of emails and attend to suspicious elements in them Kumaraguru et al. (2006).

The preceding categorization is important because attackers often attempt to deceive victims into heuristic processing
but not analytic processing to increase their chance of success. It remains to be investigated how heuristic processing
and analytic processing would work together.

Individual Baseline. These are the PFs that affect information and risk attitude. As discussed above, the following
PFs encourage the use of heuristic processing: HABITUATION, STRESS and WORKLOAD. HABITUATION because they
reduce suspicions. Moreover, a combination of STRESS and WORKLOAD increases the reliance on heuristic processing
and decreases VIGILANCE.

Attacker Effort. This is an attacker’s effort at exploiting human PFs to earn victims’ trust and encourage their
compliance. For example, an attacker can earn trust from a victim by creating emails of high quality and appealing to
the victim. This is because many users judge credibility based on superﬁcial attributes, like the professional appearance
of a website, absence of grammatical errors, or recognizable logos in emails Dhamija et al. (2006); Kim et al. (2005).
To generate an appealing message, an attacker can exploit a combination of PTs (e.g., persuasion, personalization,
contextualization). Having identiﬁed the PTs exploited by attacks, it is an important open problem to investigate how
attacks inﬂuence PFs, which in turn inﬂuences the heuristic vs. analytic processing as mentioned above.

Defense Alerts. These include the mechanisms that are employed to warn users of potential threats to trigger their
VIGILANCE. Intuitively, an effective alert would cause users to switch their attention to the warning information and
maintain their attention long enough to process it. An effective warning would trigger suspicion Montañez et al. (2020),
such as cue salience triggering attention switching Wogalter (2018). It is an important open problem to investigate how
defenses can inﬂuence PFs to offset the inﬂuence of attackers.

19

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Future research needs to conﬁrm, disputes, or reﬁne the qualitative framework.

8.2 Creating a Quantitative Psychological Framework Tailored to Social Engineering Attacks

The preceding qualitative framework, or it reﬁned version, paves a way for quantifying the effectiveness of social
engineering attacks and defenses. Speciﬁcally, we propose a hierarchical quantitative framework to describe individuals’
susceptibility to social engineering attacks as

susceptibility = f (processing_route, risk_attitude),

where f is a family of mathematical functions that are to be identiﬁed by future studies, processing_route means
the use of heuristic or analytic processing, and risk_attitude indicates how the individual trades risk for reward.
Moreover, the processing_route would be determined by

processing_route = g(individual_baseline, attacker_effort, defense_alerts).

where g is another family of mathematical functions that are to be determined by future studies, and individual_baseline,
attacker_effort and defense_alerts are deﬁned above.

Future research needs to enrich the quantitative framework, or its reﬁnement, with characteristics of the impact of the
variables, including the relevant PFs and PTs. We envision that the resulting quantitative framework will be seamlessly
incorporated into broader frameworks for investigating cybersecurity from a holistic perspective, such as Cybersecurity
Dynamics Xu (2014, 2019, 2020) which is driven by the need to quantify cybersecurity from a holistic perspective Xu
(2021); Pendleton et al. (2016); Cho et al. (2019). Indeed, human susceptibility to social engineering attacks has been
explicitly described in the mathematical models of preventive and reactive cybersecurity dynamics Li et al. (2011);
Xu et al. (2012a,b); Zheng et al. (2018); Lin et al. (2019c); Han et al. (2021). Moreover, human susceptibility to
social engineering attacks needs to be adequately incorporated into other kinds of models, such as adaptive, proactive,
and active cyber defense dynamics Xu et al. (2014); Da et al. (2014); Han et al. (2014); Xu et al. (2015b); Zheng
et al. (2015b). Since human susceptibility to social engineering attacks would not be independent from individual
to individual as shown above (e.g., people exhibiting similar PFs would be susceptible to social engineering attacks
to a similar extent), this kind of dependence needs to be explicitly considered in holistic cybersecurity models, as
highlighted in Xu and Xu (2012); Da et al. (2014); Xu et al. (2015a); Lu et al. (2013); Chen et al. (2018, 2021).

8.3 Using Psychological Principles and Quantitative Findings to Guide Design of Effective Defenses

The qualitative framework discussed above suggests approaches to designing effective defenses as follows. First, under
the premise that the standard theory of System 1 vs. System 2 is perfectly suitable for describing the phenomena
resulting from social engineering attacks, effective defense should strive to train users in enhancing their System
1 decision-making when coping with potential social engineering attacks. Moreover, if the aforementioned recent
development — humans can actually process deliberate reasoning involving logical principles in an intuitive fashion
(i.e., without deliberation) Neys and Pennycook (2019) — is true, then this insight can be leveraged to build effective
defense. These psychological principles play a fundamental role because it is not feasible to force humans to use System
2 when dealing with social engineering attacks simply because of (for example) the large amount of emails they will
process on a daily basis.

The quantitative understanding resulting from the quantitative framework mentioned above would offer insights into
designing effective defenses. The basic idea is to identify the important factors, namely the most relevant PFs and PTs,
such that defenses can be tailored to inﬂuence them to minimize individuals’ susceptibility to social engineering
attacks. For example, if TRUST turns out to be an important factor, then defenses can be tailored to minimize individuals’
TRUST (e.g., making everyone practice zero-trust on everything coming from Internet may be an effective defense
against social engineering attacks). As another example, if warnings can reduce individuals’ susceptibility, then it
is important to investigate how to make warnings effective (e.g., using dynamic warnings instead of static warnings in
order to reduce HABITUATION Brinton Anderson et al. (2016)).

8.4 Summary

The discussion presented above reﬂects our ﬁrm belief that effective defenses cannot be achieved without the guidance
of sound psychological principles that are tailored to the domain or social engineering attacks.

Insight 4 A quantitative psychological theory tailored to the social engineering domain is needed to guide the design
of effective defenses.

20

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

9 Conclusion

In order to understand why current defenses against social engineering attacks have achieved limited success, we
have systematized human PFs and PTs (psychological factors and techniques) which have been exploited by attackers
in particularly crafty ways. Our systematization of these attacks and current defenses against them highlights a key
discrepancy which can explain the limited success of current defenses: defenses do not consider human PFs to the same
degree that attacks do. This prompts us to propose a systematic roadmap for future research towards effective defenses.

Acknowledgement. We thank Eric Ficke and Shawn Emery for feedback and proofreading the paper.

References

Ahmed Abbasi, F Mariam Zahedi, and Yan Chen. 2016. Phishing susceptibility: The good, the bad, and the ugly. In

2016 IEEE Conference on Intelligence and Security Informatics (ISI). IEEE, Tucson, AZ, 169–174.

Sahar Abdelnabi, Katharina Krombholz, and Mario Fritz. 2020. VisualPhishNet: Zero-Day Phishing Website Detection
by Visual Similarity. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications
Security. Association for Computing Machinery, New York, NY, USA, 1681â ˘A ¸S1698. https://doi.org/10.
1145/3372297.3417233

Noelle Abe and Michael Soltys. 2019. Deploying Health Campaign Strategies to Defend Against Social Engineering

Threats. Procedia Computer Science 159 (2019), 824–831.

Muhammad Adil, Rahim Khan, and M Ahmad Nawaz Ul Ghani. 2020. Preventive techniques of phishing attacks
in networks. In 2020 3rd International Conference on Advancements in Computational Sciences (ICACS). IEEE,
Lahore, Pakistan, 1–8.

David Airehrour, Nisha Vasudevan Nair, and Samaneh Madanian. 2018. Social engineering attacks and countermeasures
in the new zealand banking system: Advancing a user-reﬂective mitigation model. Information 9, 5 (2018), 110.
Mariam Al-Hamar, Ray Dawson, and Lin Guan. 2010. A culture of trust threatens security and privacy in Qatar. In
2010 10th IEEE International Conference on Computer and Information Technology. IEEE, Bradford, 991–995.
Rana Alabdan. 2020. Phishing Attacks Survey: Types, Vectors, and Technical Approaches. Future Internet 12, 10

(2020), 168.

Dina Aladawy, Kristian Beckers, and Sebastian Pape. 2018. PERSUADED: ﬁghting social engineering attacks with a
serious game. In International Conference on Trust and Privacy in Digital Business. Springer, Bratislava, Slovakia,
103–118.

Mohammad Nazmul Alam, Dhiman Sarma, Farzana Firoz Lima, Ishita Saha, Sohrab Hossain, et al. 2020. Phishing
attacks detection using machine learning approach. In 2020 third international conference on smart systems and
inventive technology (ICSSIT). IEEE, Tirunelveli, India, 1173–1179.

Samar Muslah Albladi and George RS Weir. 2020. Predicting individualsâ ˘A ´Z vulnerability to social engineering in

social networks. Cybersecurity 3, 1 (2020), 1–19.

Hussain Aldawood and Geoffrey Skinner. 2019a. Reviewing Cyber Security Social Engineering Training and Awareness

Programsâ ˘AˇTPitfalls and Ongoing Issues. Future Internet 11, 3 (2019), 73.

Hussain Aldawood and Geoffrey Skinner. 2019b. A Taxonomy for Social Engineering Attacks via Personal Devices.

International Journal of Computer Applications 975 (2019), 8887.

Ahmed Aleroud and Lina Zhou. 2017. Phishing environments, techniques, and countermeasures: A survey. Computers

& Security 68 (2017), 160–196.

Abdullah Algarni, Yue Xu, and Taizan Chan. 2017. An empirical study on the susceptibility to social engineering in
social networking sites: the case of Facebook. European Journal of Information Systems 26, 6 (2017), 661–687.
Dalal N Alharthi, Mahmoud M Hammad, and Amelia C Regan. 2020. A taxonomy of social engineering defense
mechanisms. In Future of Information and Communication Conference. Springer, Vancouver, BC, Canada, 27–41.
Mohammed Mahmood Ali, Mohd S Qaseem, and Md Ateeq Ur Rahman. 2020. A Survey on Deceptive Phishing
Attacks in Social Networking Environments. In Proceedings of the Third International Conference on Computational
Intelligence and Informatics. Springer, Delhi, India, 443–452.

Joey Allen, Zheng Yang, Matthew Landen, Raghav Bhat, Harsh Grover, Andrew Chang, Yang Ji, Roberto Perdisci,
and Wenke Lee. 2020. Mnemosyne: An Effective and Efﬁcient Postmortem Watering Hole Attack Investigation
System. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security. ACM,
USA, 787–802.

21

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Luca Allodi, Tzouliano Chotza, Ekaterina Panina, and Nicola Zannone. 2019. The need for new antiphishing measures

against spear-phishing attacks. IEEE Security & Privacy 18, 2 (2019), 23–34.

Ammar Almomani, Brij B Gupta, Samer Atawneh, Andrew Meulenberg, and Eman Almomani. 2013. A survey of

phishing email ﬁltering techniques. IEEE communications surveys & tutorials 15, 4 (2013), 2070–2090.

Manal Alohali, Nathan Clarke, Fudong Li, and Steven Furnell. 2018. Identifying and predicting the factors affecting

end-usersâ ˘A ´Z risk-taking behavior. Information & Computer Security 26, 3 (2018), 306–326.

Ibrahim Alseadoon, Taizan Chan, Ernest Foo, and Juan Gonzalez Nieto. 2012. Who is more susceptible to phishing
emails?: a Saudi Arabian study. In 23rd Australasian Conference on Information Systems. Association for Information
Systems, Australia, –.

Ibrahim Alseadoon, MFI Othman, and Taizan Chan. 2015. What is the inﬂuence of usersâ ˘A ´Z characteristics on their
ability to detect phishing emails? In Advanced computer and communication engineering technology. Springer, USA,
949–962.

Mohamed Alsharnouby, Furkan Alaca, and Sonia Chiasson. 2015. Why phishing still works: User strategies for

combating phishing attacks. International Journal of Human-Computer Studies 82 (2015), 69–82.

Ahmed Alyahya and George RS Weir. 2021. Understanding Responses to Phishing in Saudi Arabia via the Theory of
Planned Behaviour. In 2021 National Computing Colleges Conference (NCCC). IEEE, Taif, Saudi Arabia, 1–6.

Maha Rita Arabia-Obedoza, Gloria Rodriguez, Amber Johnston, Fatima Salahdine, and Naima Kaabouch. 2020. Social
Engineering Attacks A Reconnaissance Synthesis Analysis. In 2020 11th IEEE Annual Ubiquitous Computing,
Electronics & Mobile Communication Conference (UEMCON). IEEE, USA, 0843–0848.

Abdul Basit, Maham Zafar, Xuan Liu, Abdul Rehman Javed, Zunera Jalil, and Kashif Kifayat. 2020. A comprehensive

survey of AI-enabled phishing attacks detection techniques. Telecommunication Systems 76 (2020), 1–16.

Nikos Benias and Angelos P Markopoulos. 2018. Hacking the human: Exploiting primordial instincts. In 2018 South-
Eastern European Design Automation, Computer Engineering, Computer Networks and Society Media Conference
(SEEDA_CECNSM). IEEE, Kastoria, Greece, 1–6.

Vaishnavi Bhavsar, Aditya Kadlak, and Shabnam Sharma. 2018. Study on phishing attacks. Int. J. Comput. Appl 182

(2018), 27–29.

Grady Booch, Francesco Fabiano, Lior Horesh, Kiran Kate, Jonathan Lenchner, Nick Linck, Andrea Loreggia,

Keerthiram Murugesan, Nicholas Mattei, Francesca Rossi, et al. 2020. Thinking fast and slow in AI. (2020).

Bonnie Brinton Anderson, Anthony Vance, C Brock Kirwan, David Eargle, and Jeffrey L Jenkins. 2016. How users
perceive and respond to security messages: a NeuroIS research agenda and empirical study. European Journal of
Information Systems 25, 4 (2016), 364–390.

Susanne Buecker, Marlies Maes, Jaap JA Denissen, and Maike Luhmann. 2020. Loneliness and the Big Five personality

traits: A meta–analysis. European Journal of Personality 34, 1 (2020), 8–28.

Jan-Willem Bullee, Lorena Montoya, Marianne Junger, and Pieter Hartel. 2017. Spear phishing in organisations

explained. Information & Computer Security 25, 5 (2017), 593–613.

Jan-Willem Hendrik Bullée, Lorena Montoya, Wolter Pieters, Marianne Junger, and Pieter Hartel. 2018. On the
anatomy of social engineering attacksâ ˘AˇTA literature-based dissection of successful attacks. Journal of investigative
psychology and offender proﬁling 15, 1 (2018), 20–45.

Greg Burch, Adrian Taylor, and Christie Yeung. 2015. Wire Transfer Email Fraud and What to Do About It. Intellectual

Property & Technology Law Journal 27, 1 (2015), 13.

Stefano Calzavara, Sebastian Roth, Alvise Rabitti, Michael Backes, and Ben Stock. 2020. A tale of two headers:
A formal analysis of inconsistent click-jacking protection on the web. In 29th {USENIX} Security Symposium
({USENIX} Security 20). USENIX, USA, 683–697.

Rajasekhar Chaganti, Bharat Bhushan, Anand Nayyar, and Azrour Mourade. 2021. Recent trends in Social Engineering

Scams and Case study of Gift Card Scam. (2021).

S Chanti and T Chithralekha. 2020. Classiﬁcation of anti-phishing solutions. SN Computer Science 1, 1 (2020), 1–18.

Huashan Chen, Hasan Cam, and Shouhuai Xu. 2021. Quantifying Cybersecurity Effectiveness of Dynamic Network
Diversity. IEEE Transactions on Dependable and Secure Computing –, – (2021), 1–1. https://doi.org/10.
1109/TDSC.2021.3107514

H. Chen, J. Cho, and S. Xu. 2018. Quantifying the security effectiveness of ﬁrewalls and DMZs. In Proc. HoTSoS’2018.

ACM, USA, 9:1–9:11.

22

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Rui Chen, Joana Gaia, and H Raghav Rao. 2020. An examination of the effect of recent phishing encounters on phishing

susceptibility. Decision Support Systems 133 (2020), 113287.

Kendra Cherry. 2012. The big ﬁve personality dimensions: 5 major factors of personality. (2012).
Kang Leng Chiew, Kelvin Sheng Chek Yong, and Choon Lin Tan. 2018. A survey of phishing attacks: Their types,

vectors and technical approaches. Expert Systems with Applications 106 (2018), 1–20.

Anubhav Chitrey, Dharmendra Singh, and Vrijendra Singh. 2012. A comprehensive study of social engineering based
attacks in india to develop a conceptual model. International Journal of Information and Network Security 1, 2
(2012), 45.

J. Cho, S. Xu, P. Hurley, M. Mackay, T. Benjamin, and M. Beaumont. 2019. STRAM: Measuring the Trustworthiness

of Computer-Based Systems. ACM Comput. Surv. 51, 6 (2019), 128:1–128:47.

Noman H Chowdhury, Marc TP Adam, and Geoffrey Skinner. 2019. The impact of time pressure on cybersecurity

behaviour: a systematic literature review. Behaviour & Information Technology 38, 12 (2019), 1290–1308.

Robert B Cialdini and Lloyd James. 2009. Inﬂuence: Science and practice. Vol. 4. Pearson education, Boston, MA.
Robert B Cialdini and Melanie R Trost. 1998. Social inﬂuence: Social norms, conformity and compliance. In The

handbook of social psychology. McGraw-Hill, USA, 151–â ˘A ¸S192.

Asaf Cidon, Lior Gavish, Itay Bleier, Nadia Korshun, Marco Schweighauser, and Alexey Tsitkin. 2019. High precision
detection of business email compromise. In 28th {USENIX} Security Symposium ({USENIX} Security 19). USENIX,
USA, 1291–1307.

Henry Collier and Alexandra Collier. 2020. The Port Z3R0 Effect! Human Behaviors Related to Susceptibility. nature

2, 3 (2020), 5.

Dan Conway, Ronnie Taib, Mitch Harris, Kun Yu, Shlomo Berkovsky, and Fang Chen. 2017. A qualitative investigation
of bank employee experiences of information security and phishing. In Thirteenth Symposium on Usable Privacy and
Security ({SOUPS} 2017). USENIX, USA, 115–129.

T Copado. 2021. 12 Types of Social Engineering Attacks to Look Out For. https://www.copado.com/devops-hub/

blog/12-types-of-social-engineering-attacks-to-look-out-for

Paul T Costa Jr and Robert R McCrae. 2008. The Revised Neo Personality Inventory (neo-pi-r). In The SAGE handbook

of personality theory and assessment. Sage Publications, Inc, USA.

G. Da, M. Xu, and S. Xu. 2014. A New Approach to Modeling and Analyzing Security of Networked Systems. In Proc.

HotSoS’14. ACM, USA, 6:1–6:12.

Carlo Marcelo Revoredo da Silva, Eduardo Luzeiro Feitosa, and Vinicius Cardoso Garcia. 2020. Heuristic-based
strategy for Phishing prediction: A survey of URL-based approach. Computers & Security 88 (2020), 101613.
Avisha Das, Shahryar Baki, Ayman El Aassal, Rakesh Verma, and Arthur Dunbar. 2019a. SoK: a comprehensive
reexamination of phishing research from the security perspective. IEEE Communications Surveys & Tutorials 22, 1
(2019), 671–708.

Sanchari Das, Andrew Kim, Zachary Tingle, and Christena Nippert-Eng. 2019b. All about phishing: Exploring user

research through a systematic literature review. (2019).

Sauvik Das, Adam DI Kramer, Laura A Dabbish, and Jason I Hong. 2014. Increasing security sensitivity with social
proof: A large-scale experimental conﬁrmation. In Proceedings of the 2014 ACM SIGSAC conference on computer
and communications security. ACM, USA, 739–749.

Jensen Deutrom, Vasilis Katos, and Raian Ali. 2021. Loneliness, life satisfaction, problematic internet use and security
behaviours: re-examining the relationships when working from home during COVID-19. Behaviour & Information
Technology 1, 1 (2021), 1–15.

Rachna Dhamija, J Doug Tygar, and Marti Hearst. 2006. Why phishing works. In Proceedings of the SIGCHI conference

on Human Factors in computing systems. ACM, Montreal, Canada, 581–590.

John M Digman. 1990. Personality structure: Emergence of the ﬁve-factor model. Annual review of psychology 41, 1

(1990), 417–440.

Zuochao Dou, Issa Khalil, Abdallah Khreishah, Ala Al-Fuqaha, and Mohsen Guizani. 2017. Systematization of
knowledge (sok): A systematic review of software-based web phishing detection. IEEE Communications Surveys &
Tutorials 19, 4 (2017), 2797–2819.

Saba Eskandarian, Jonathan Cogan, Sawyer Birnbaum, Peh Chang Wei Brandon, Dillon Franke, Forest Fraser, Gaspar
Garcia, Eric Gong, Hung T Nguyen, Taresh K Sethi, et al. 2019. Fidelius: Protecting user secrets from compromised
browsers. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, USA, 264–280.

23

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

FBI.

2020.

email
common-scams-and-crimes/business-email-compromise

compromise.

Business

https://www.fbi.gov/scams-and-safety/

Ana Ferreira. 2018. Why ransomware needs a human touch. In 2018 International Carnahan Conference on Security

Technology (ICCST). IEEE, Quebec, Canada, 1–5.

Ana Ferreira and Gabriele Lenzini. 2015. An analysis of social engineering principles in effective phishing. In 2015

Workshop on Socio-Technical Aspects in Security and Trust. IEEE, USA, 9–16.

A Fraudwatch.
cial Media
angler-phishing-the-risks-and-dangers-of-fake-social-media-brand-profiles-part-1/

So-
https://fraudwatch.com/

and Dangers

2017.
Brand

Phishing:

Proﬁles

Angler

Risks

â ˘A ¸S

Fake

Part

The

of

1.

Edwin Donald Frauenstein and Stephen Flowerday. 2020. Susceptibility to phishing on social network sites: A

personality information processing model. Computers & Security 94 (2020), 101862.

Jonathan L Freedman and Scott C Fraser. 1966. Compliance without pressure: the foot-in-the-door technique. Journal

of personality and social psychology 4, 2 (1966), 195.

Pablo L Gallegos-Segovia, Jack F Bravo-Torres, Víctor M Larios-Rosillo, Paúl E Vintimilla-Tapia, Iván F Yuquilima-
Albarado, and Juan D Jara-Saltos. 2017. Social engineering as an attack vector for ransomware. In 2017 CHILEAN
Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON).
IEEE, Chile, 1–6.

Ibrahim Ghaﬁr, Vaclav Prenosil, Ahmad Alhejailan, and Mohammad Hammoudeh. 2016. Social engineering attack
strategies and defence approaches. In 2016 IEEE 4th international conference on future internet of things and cloud
(FiCloud). IEEE, Vienna, Austria, 145–149.

Ludger Goeke, Alejandro Quintanar, Kristian Beckers, and Sebastian Pape. 2019. PROTECT–an easy conﬁgurable
serious game to train employees against social engineering attacks. In Computer Security. Springer, USA, 156–171.

Diksha Goel and Ankit Kumar Jain. 2018. Mobile phishing attacks and defence mechanisms: State of art and open

research challenges. Computers & Security 73 (2018), 519–544.

Sanjay Goel, Kevin Williams, and Ersin Dincelli. 2017. Got phished? Internet security and human vulnerability.

Journal of the Association for Information Systems 18, 1 (2017), 2.

Lewis R Goldberg. 1981. Language and individual differences: The search for universals in personality lexicons.

Review of personality and social psychology 2, 1 (1981), 141–165.

Valerica Greavu-Serban and Oana Serban. 2014. Social engineering a general approach. Informatica Economica 18, 2

(2014), 5.

Brij B Gupta, Nalin AG Arachchilage, and Kostas E Psannis. 2018. Defending against phishing attacks: taxonomy of

methods, current issues and future directions. Telecommunication Systems 67, 2 (2018), 247–267.

Surbhi Gupta, Abhishek Singhal, and Akanksha Kapoor. 2016. A literature survey on social engineering attacks:
Phishing attack. In 2016 international conference on computing, communication and automation (ICCCA). IEEE,
India, 537–540.

Tzipora Halevi, Nasir Memon, and Oded Nov. 2015. Spear-phishing in the wild: A real-world study of personality,
phishing self-efﬁcacy and vulnerability to spear-phishing attacks. Phishing Self-Efﬁcacy and Vulnerability to
Spear-Phishing Attacks (January 2, 2015) 1, 1 (2015), –.

Y. Han, W. Lu, and S. Xu. 2014. Characterizing the Power of Moving Target Defense via Cyber Epidemic Dynamics.

In HotSoS. ACM, USA, 1–12.

Y. Han, W. Lu, and S. Xu. 2021. Preventive and Reactive Cyber Defense Dynamics with Ergodic Time-dependent

Parameters Is Globally Attractive. IEEE TNSE 8, 3 (2021), 2517–2532.

Joseph M Hatﬁeld. 2018. Social engineering in cybersecurity: The evolution of a concept. Computers & Security 73

(2018), 102–113.

Ryan Heartﬁeld and George Loukas. 2015. A taxonomy of attacks and a survey of defence mechanisms for semantic

social engineering attacks. ACM Computing Surveys (CSUR) 48, 3 (2015), 1–39.

Ryan Heartﬁeld and George Loukas. 2018. Detecting semantic social engineering attacks with the weakest link:
Implementation and empirical evaluation of a human-as-a-security-sensor framework. Computers & Security 76
(2018), 101–127.

D Henshel, MG Cains, B Hoffman, and T Kelley. 2015. Trust as a human factor in holistic cyber security risk assessment.

Procedia Manufacturing 3 (2015), 1117–1124.

24

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Cormac Herley. 2012. Why do nigerian scammers say they are from nigeria?. In Workshop on the Economics of

Information Security. WEIS, Berlin,Germany, –.

Jacob B. Hirsh, Sonia K. Kang, and Galen V. Bodenhausen. 2012. Personalized Persuasion: Tailoring Persuasive
Appeals to Recipients’ Personality Traits. Psychological Science 23, 6 (2012), 578–581. https://doi.org/10.
1177/0956797611436349

Grant Ho, Asaf Cidon, Lior Gavish, Marco Schweighauser, Vern Paxson, Stefan Savage, Geoffrey M Voelker, and
David Wagner. 2019. Detecting and characterizing lateral phishing at scale. In 28th {USENIX} Security Symposium
({USENIX} Security 19). USENIX, USA, 1273–1290.

Grant Ho, Aashish Sharma, Mobin Javed, Vern Paxson, and David Wagner. 2017. Detecting credential spearphishing in
enterprise settings. In 26th {USENIX} Security Symposium ({USENIX} Security 17). USENIX, USA, 469–485.

Thomas J Holt, Johan van Wilsem, Steve van de Weijer, and Rutger Leukfeldt. 2020. Testing an integrated self-control
and routine activities framework to examine malware infection victimization. Social Science Computer Review 38, 2
(2020), 187–206.

Kyung Wha Hong, Christopher M Kelley, Rucha Tembe, Emerson Murphy-Hill, and Christopher B Mayhorn. 2013.
Keeping up with the Joneses: Assessing phishing susceptibility in an email task. In Proceedings of the Human
Factors and Ergonomics Society Annual Meeting, Vol. 57. SAGE Publications Sage, Los Angeles, CA, 1012–1016.

Deanna House and MK Raja. 2020. Phishing: message appraisal and the exploration of fear and self-conﬁdence.

Behaviour & Information Technology 39, 11 (2020), 1204–1224.

Adele E. Howe, Indrajit Ray, Mark Roberts, Malgorzata Urbanska, and Zinta Byrne. 2012. The Psychology of Security
for the Home Computer User. In Proceedings of the 2012 IEEE Symposium on Security and Privacy (SP ’12). IEEE
Computer Society, Washington, DC, USA, 209–223. https://doi.org/10.1109/SP.2012.23

Danesh Irani, Marco Balduzzi, Davide Balzarotti, Engin Kirda, and Calton Pu. 2011. Reverse social engineering attacks
in online social networks. In International conference on detection of intrusions and malware, and vulnerability
assessment. Springer, USA, 55–74.

Tom N Jagatic, Nathaniel A Johnson, Markus Jakobsson, and Filippo Menczer. 2007. Social phishing. Commun. ACM

50, 10 (2007), 94–100.

Ankit Kumar Jain and BB Gupta. 2021. A survey of phishing attack techniques, defence mechanisms and open research

challenges. Enterprise Information Systems 16, 4 (2021), 1–39.

Mohammad S Jalali, Maike Bruckes, Daniel Westmattelmann, and Gerhard Schewe. 2020. Why employees (still) click

on phishing links: investigation in hospitals. Journal of medical Internet research 22, 1 (2020), e16775.

Daniel Jampen, Gürkan Gür, Thomas Sutter, and Bernhard Tellenbach. 2020. Donâ ˘A ´Zt click: towards an effective
anti-phishing training. A comparative literature review. Human-centric Computing and Information Sciences 10, 1
(2020), 1–41.

Uwe Jensen. 2002. Probabilistic Risk Analysis: Foundations and Methods. J. Amer. Statist. Assoc. 97, 459 (2002),

925–925.

Marianne Junger, Lorena Montoya, and F-J Overink. 2017. Priming and warnings are not effective to prevent social

engineering attacks. Computers in human behavior 66 (2017), 75–87.

Marianne Junger, Victoria Wang, and Marleen Schlömer. 2020. Fraud against businesses both online and ofﬂine: crime

scripts, business characteristics, efforts, and beneﬁts. Crime Science 9, 1 (2020), 1–15.

Daniel Kahneman. 2011. Thinking, fast and slow. Macmillan, USA.

Fumihiro Kanei, Daiki Chiba, Kunio Hato, Katsunari Yoshioka, Tsutomu Matsumoto, and Mitsuaki Akiyama. 2020.
Detecting and Understanding Online Advertising Fraud in the Wild. IEICE Transactions on Information and Systems
103, 7 (2020), 1512–1523.

Yuki Kano and Tatsuo Nakajima. 2021. Trust Factors of Social Engineering Attacks on Social Networking Services. In

2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech). IEEE, Osaka, Japan, 25–28.

Security kaspersky. 2022. What is Social Engineering?

https://usa.kaspersky.com/resource-center/

definitions/what-is-social-engineering

Wayne D Kearney and Hennie A Kruger. 2016. Can perceptual differences account for enigmatic information security

behaviour in an organisation? Computers & Security 61 (2016), 46–58.

Mahmoud Khonji, Youssef Iraqi, and Andrew Jones. 2013. Phishing detection: a literature survey. IEEE Communica-

tions Surveys & Tutorials 15, 4 (2013), 2091–2121.

25

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Yunju Kim and Heejun Lee. 2021. Towards a Sustainable News Business: Understanding Readersâ ˘A ´Z Perceptions of

Algorithm-Generated News Based on Cultural Conditioning. Sustainability 13, 7 (2021), 3728.

Yong Jin Kim, Rajiv Kishore, and G Lawrence Sanders. 2005. From DQ to EQ: understanding data quality in the

context of e-business systems. Commun. ACM 48, 10 (2005), 75–81.

Iacovos Kirlappos, Simon Parkin, and M Angela Sasse. 2014. Learning from â ˘AIJShadow Securityâ ˘A˙I: Why
understanding non-compliance provides the basis for effective security. In Workshop on Usable Security. –, USA, –.

Amna Kirmani and Rui Zhu. 2007. Vigilant against manipulation: The effect of regulatory focus on the use of persuasion

knowledge. Journal of Marketing Research 44, 4 (2007), 688–701.

Ponnurangam Kumaraguru, Alessandro Acquisti, and Lorrie Faith Cranor. 2006. Trust modelling for online transactions:
a phishing scenario. In Proceedings of the 2006 International Conference on Privacy, Security and Trust: Bridge the
Gap Between PST Technologies and Business Services. ACM, Markham, Canada, 11.

Stephen EG Lea, Peter Fischer, and Kath M Evans. 2009. The psychology of scams: Provoking and committing errors

of judgement. Technical Report. Ofﬁce of Fair Trading.

Christina Lekati. 2018. Complexities in Investigating Cases of Social Engineering: How Reverse Engineering and
Proﬁling can Assist in the Collection of Evidence. In 2018 11th International Conference on IT Security Incident
Management & IT Forensics (IMF). IEEE, Hamburg, Germany, 107–109.

Tong Li, Kaiyuan Wang, and Jennifer Horkoff. 2019. Towards Effective Assessment for Social Engineering Attacks.
In 2019 IEEE 27th International Requirements Engineering Conference (RE). IEEE, Jeju Island, Korea (South),
392–397.

X. Li, P. Parker, and S. Xu. 2011. A Stochastic Model for Quantitative Security Analyses of Networked Systems. IEEE

TDSC 8, 1 (2011), 28–43.

Hause Lin, Gordon Pennycook, and David Rand. 2022. Thinking more or thinking differently? Using drift-diffusion

modeling to illuminate why accuracy prompts decrease misinformation sharing. (2022).

Tian Lin, Daniel E Capecci, Donovan M Ellis, Harold A Rocha, Sandeep Dommaraju, Daniela S Oliveira, and Natalie C
Ebner. 2019a. Susceptibility to spear-phishing emails: Effects of Internet user demographics and email content. ACM
Transactions on Computer-Human Interaction (TOCHI) 26, 5 (2019), 32.

Tian Lin, Daniel E Capecci, Donovan M Ellis, Harold A Rocha, Sandeep Dommaraju, Daniela S Oliveira, and Natalie C
Ebner. 2019b. Susceptibility to spear-phishing emails: Effects of internet user demographics and email content. ACM
Transactions on Computer-Human Interaction (TOCHI) 26, 5 (2019), 1–28.

Yun Lin, Ruofan Liu, Dinil Mon Divakaran, Jun Yang Ng, Qing Zhou Chan, Yiwen Lu, Yuxuan Si, Fan Zhang, and
Jin Song Dong. 2021. Phishpedia: A Hybrid Deep Learning Based Approach to Visually Identify Phishing Webpages.
In 30th Usenix Security Symposium. Usenix, USA, –.

Z. Lin, W. Lu, and S. Xu. 2019c. Uniﬁed Preventive and Reactive Cyber Defense Dynamics Is Still Globally Convergent.

IEEE/ACM ToN 27, 3 (2019), 1098–1111.

W. Lu, S. Xu, and X. Yi. 2013. Optimizing Active Cyber Defense Dynamics. In Proc. GameSec’13. Springer, USA,

206–225.

Luka Malisa, Kari Kostiainen, and Srdjan Capkun. 2017. Detecting mobile application spooﬁng attacks by leveraging
user visual similarity perception. In Proceedings of the Seventh ACM on Conference on Data and Application Security
and Privacy. ACM, USA, 289–300.

Jian Mao, Jingdong Bian, Wenqian Tian, Shishi Zhu, Tao Wei, Aili Li, and Zhenkai Liang. 2018. Detecting phishing

websites via aggregation analysis of page layouts. Procedia Computer Science 129 (2018), 224–230.

Abraham Harold Maslow. 1943. A theory of human motivation. Psychological review 50, 4 (1943), 370.

John McAlaney and Vladlena Benson. 2020. Cybersecurity as a social phenomenon. In Cyber Inﬂuence and Cognitive

Threats. Elsevier, USA, 1–8.

John McAlaney and Peter J Hills. 2020. Understanding phishing email processing and perceived trustworthiness

through eye tracking. Frontiers in Psychology 11 (2020), 1756.

Daniel J McAllister. 1995. Affect-and cognition-based trust as foundations for interpersonal cooperation in organizations.

Academy of management journal 38, 1 (1995), 24–59.

Robert R McCrae and Oliver P John. 1992. An introduction to the ﬁve-factor model and its applications. Journal of

personality 60, 2 (1992), 175–215.

26

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Judith Meinert, Milad Mirbabaie, Sebastian Dungs, and Ahmet Aker. 2018. Is it really fake?–Towards an understanding
of fake news in social media communication. In International Conference on Social Computing and Social Media.
Springer, USA, 484–497.

Shaheen Mondal, Diksha Maheshwari, Nilima Pai, and Ameyaa Biwalkar. 2019. A Review on Detecting Phishing
URLs using Clustering Algorithms. In 2019 International Conference on Advances in Computing, Communication
and Control (ICAC3). IEEE, Mumbai, India, 1–6.

Rosana Montañez, Edward Golob, and Shouhuai Xu. 2020. Human cognition through the lens of social engineering

cyberattacks. Frontiers in Psychology 11 (2020), –.

Rosana Montañez, Adham Atyabi, and Shouhuai Xu. 2022. Cybersecurity and Cognitive Science. Elsevier, USA,
Chapter Social Engineering Attacks and Defenses in the Physical World vs. Cyberspace: A Contrast Study, 3–41.

Gregory D Moody, Dennis F Galletta, and Brian Kimball Dunn. 2017. Which phish get caught? An exploratory study

of individuals susceptibility to phishing. European Journal of Information Systems 26, 6 (2017), 564–584.

Akihito Nakamura and Fuma Dobashit. 2019. Proactive Phishing Sites Detection. In 2019 IEEE/WIC/ACM International

Conference on Web Intelligence (WI). IEEE, Thessaloniki, Greece, 443–448.

Jema David Ndibwile, Edith Talina Luhanga, Doudou Fall, Daisuke Miyamoto, Gregory Blanc, and Youki Kadobayashi.
2019. An empirical approach to phishing countermeasures through smart glasses and validation agents. IEEE Access
7 (2019), 130758–130771.

Terry Nelms, Roberto Perdisci, Manos Antonakakis, and Mustaque Ahamad. 2016. Towards Measuring and Mitigating
Social Engineering Software Download Attacks. In 25th USENIX Security Symposium (USENIX Security 16).
USENIX Association, Austin, TX, 773–789.

Alisha M Ness, Genevieve Johnson, Michael K Ault, William D Taylor, Jennifer A Grifﬁth, Shane Connelly, Norah E
Dunbar, and Matthew L Jensen. 2017. Reactions to ideological websites: The impact of emotional appeals, credibility,
and pre-existing attitudes. Computers in Human Behavior 72 (2017), 496–511.

Daniel Nettle. 2006. The evolution of personality variation in humans and other animals. American Psychologist 61, 6

(2006), 622.

Wim De Neys and Gordon Pennycook. 2019. Logic, Fast and Slow: Advances in Dual-Process Theorizing. Current
Directions in Psychological Science 28, 5 (2019), 503–509. https://doi.org/10.1177/0963721419855658
Ori Or-Meir, Nir Nissim, Yuval Elovici, and Lior Rokach. 2019. Dynamic malware analysis in the modern eraâ ˘AˇTA

state of the art survey. ACM Computing Surveys (CSUR) 52, 5 (2019), 1–48.

M. Pendleton, R. Garcia-Lebron, J. Cho, and S. Xu. 2016. A Survey on Systems Security Metrics. ACM Comput. Surv.

49, 4 (2016), 62:1–62:35.

Gordon Pennycook, Jonathan A Fugelsang, and Derek J Koehler. 2015. What makes us think? A three-stage dual-process

model of analytic engagement. Cognitive psychology 80 (2015), 34–72.

Kevin Pfeffel, Philipp Ulsamer, and Nicholas H Müller. 2019. Where the user does look when reading phishing mails–an

eye-tracking study. In International Conference on Human-Computer Interaction. Springer, USA, 277–287.

Santi Priyanka Prem and B Indira Reddy. 2019. Phishing and anti-phishing techniques. International Research Journal

of Engineering and Technology 6, 7 (2019), 1446–1452.

N. Provos, D. McNamee, P. Mavrommatis, K. Wang, and N. Modadugu. 2007. The ghost in the browser analysis of
web-based malware. In Proceedings of the First Workshop on Hot Topics in Understanding Botnets (HotBots’07).
USENIX, USA, –.

Prashanth Rajivan and Cleotilde Gonzalez. 2018. Creative persuasion: a study on adversarial behaviors and strategies

in phishing attacks. Frontiers in psychology 9 (2018), 135.

Justinas Rastenis, Simona Ramanauskaite, Justinas Janulevicius, Antanas Cenys, Asta Slotkiene, and Kestutis Pakri-

jauskas. 2020. E-mail-Based Phishing Attack Taxonomy. Applied Sciences 10, 7 (2020), 2363.

Jochen Reb, Jayanth Narayanan, and Zhi Wei Ho. 2015. Mindfulness at work: Antecedents and consequences of

employee awareness and absent-mindedness. Mindfulness 6, 1 (2015), 111–122.

Elissa M Redmiles, Neha Chachra, and Brian Waismeyer. 2018. Examining the Demand for Spam: Who Clicks?. In
Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, Montreal,Canada, 212.

Elissa M Redmiles, Noel Warford, Amritha Jayanti, Aravind Koneru, Sean Kross, Miraida Morales, Rock Stevens, and
Michelle L Mazurek. 2020. A comprehensive quality evaluation of security and privacy advice on the web. In 29th
{USENIX} Security Symposium ({USENIX} Security 20). USENIX, USA, 89–108.

27

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Nader Sohrabi Safa, Mehdi Sookhak, Rossouw Von Solms, Steven Furnell, Norjihan Abdul Ghani, and Tutut Herawan.
2015. Information security conscious care behaviour formation in organizations. Computers & Security 53 (2015),
65–78.

Krutika Rani Sahu and Jigyasu Dubey. 2014. A survey on phishing attacks. International Journal of Computer

Applications 88, 10 (2014), –.

Fatima Salahdine and Naima Kaabouch. 2019. Social engineering attacks: a survey. Future Internet 11, 4 (2019), 89.
Peter Schaab, Kristian Beckers, and Sebastian Pape. 2017. Social engineering defence mechanisms and counteracting

training strategies. Information & Computer Security 25, 2 (2017), 206–222.

Carsten Schürmann, Lisa Hartmann Jensen, and Rósa María Sigbjörnsdóttir. 2020. Effective cybersecurity awareness
training for election ofﬁcials. In International Joint Conference on Electronic Voting. Springer, Bregenz, Austria,
196–212.

Hossein Siadati, Toan Nguyen, Payas Gupta, Markus Jakobsson, and Nasir Memon. 2017. Mind your SMSes: Mitigating

social engineering in second factor authentication. Computers & Security 65 (2017), 14–28.

Mariah Simmons and Joon Suk Lee. 2020. Catﬁshing: A Look into Online Dating and Impersonation. In International

Conference on Human-Computer Interaction. Springer, Oldenburg, Germany, 349–358.

Christopher J Soto. 2019. How replicable are links between personality traits and consequential life outcomes? The life

outcomes of personality replication project. Psychological Science 30, 5 (2019), 711–727.

Frank Stajano and Paul Wilson. 2011. Understanding scam victims: seven principles for systems security. Commun.

ACM 54, 3 (2011), 70–75.

Marius Steffens, Christian Rossow, Martin Johns, and Ben Stock. 2019. Donâ ˘A ´Zt Trust The Locals: Investigating the
Prevalence of Persistent Client-Side Cross-Site Scripting in the Wild.. In NDSS Network and Distributed System
Security Symposium. NDSS, USA, –.

Michelle P Steves, Kristen K Greene, Mary F Theofanos, et al. 2019. A phish scale: rating human phishing message

detection difﬁculty. In Workshop on usable security (USEC). NDSS, USA, –.

Security Touchstone. 2021. Social Engineering Attacks on the Rise.

https://touchstonesecurity.com/

social-engineering-attacks/

Huahong Tu, Adam Doupé, Ziming Zhao, and Gail-Joon Ahn. 2019. Users really do answer telephone scams. In 28th

{USENIX} Security Symposium ({USENIX} Security 19). USENIX, USA, 1327–1340.

Enis Ulqinaku, Hala Assal, AbdelRahman Abdou, Sonia Chiasson, and Srdjan Capkun. 2020. Is Real-time Phishing
Eliminated with FIDO? Social Engineering Downgrade Attacks against FIDO Protocols. IACR Cryptol. ePrint Arch.
2020 (2020), 1298.

Steve GA Van de Weijer and E Rutger Leukfeldt. 2017. Big ﬁve personality traits of cybercrime victims. Cyberpsychol-

ogy, Behavior, and Social Networking 20, 7 (2017), 407–412.

Amber Van Der Heijden and Luca Allodi. 2019. Cognitive triaging of phishing attacks. In 28th {USENIX} Security

Symposium ({USENIX} Security 19). USENIX, USA, 1309–1326.

Eva Velasquez. 2017. What Is Angler Phishing and How Can You Avoid It? https://www.experian.com/blogs/

ask-experian/what-is-angler-phishing-and-how-can-you-avoid-it/

Sushruth Venkatesha, K Rahul Reddy, and BR Chandavarkar. 2021. Social Engineering Attacks During the COVID-19

Pandemic. SN computer science 2, 2 (2021), 1–9.

M Vijayalakshmi, S Mercy Shalinie, Ming Hour Yang, et al. 2020. Web phishing detection techniques: a survey on the

state-of-the-art, taxonomy and future directions. IET Networks 9, 5 (2020), 235–246.

Arun Vishwanath, Tejaswini Herath, Rui Chen, Jingguo Wang, and H Raghav Rao. 2011. Why do people get phished?
Testing individual differences in phishing vulnerability within an integrated, information processing model. Decision
Support Systems 51, 3 (2011), 576–586.

Peng Wang Wang, Xiaojing Liao Liao, Yue Qin, and XiaoFeng Wang. 2020. Into the Deep Web: Understanding
E-commerceFraud from Autonomous Chat with Cybercriminals. In Proceedings of the ISOC Network and Distributed
System Security Symposium (NDSS), 2020. NDSS, USA, –.

Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander G Ororbia, Xinyu Xing, Xue Liu, and C Lee Giles. 2017.
Adversary resistant deep neural networks with an application to malware detection. In Proceedings of the 23rd ACM
sigkdd international conference on knowledge discovery and data mining. ACM, Halifax NS Canada, 1145–1153.
Zuoguang Wang, Hongsong Zhu, and Limin Sun. 2021. Social Engineering in Cybersecurity: Effect Mechanisms,

Human Vulnerabilities and Attack Methods. IEEE Access 9 (2021), 11895–11910.

28

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Allaire K Welk, Kyung Wha Hong, Olga A Zielinska, Rucha Tembe, Emerson Murphy-Hill, and Christopher B
Mayhorn. 2015. Will the â ˘AIJPhisher-Menâ ˘A˙I Reel You In?: Assessing individual differences in a phishing detection
task. International Journal of Cyber Behavior, Psychology and Learning (IJCBPL) 5, 4 (2015), 1–17.

Monica T Whitty. 2018. Do you love me? Psychological characteristics of romance scam victims. Cyberpsychology,

behavior, and social networking 21, 2 (2018), 105–109.

Chad C Williams, Mitchel Kappen, Cameron D Hassall, Bruce Wright, and Olave E Krigolson. 2019. Thinking theta

and alpha: Mechanisms of intuitive and analytical reasoning. NeuroImage 189 (2019), 574–580.

Emma J Williams, Amy Beardmore, and Adam N Joinson. 2017. Individual differences in susceptibility to online

inﬂuence: A theoretical review. Computers in Human Behavior 72 (2017), 412–421.

Michael S Wogalter. 2018. Communication-human information processing (C-HIP) model. In Forensic Human Factors

and Ergonomics. CRC Press, USA, 33–49.

Michael Workman. 2007. Gaining access with social engineering: An empirical study of the threat. Information Systems

Security 16, 6 (2007), 315–331.

Ryan T Wright, Matthew L Jensen, Jason Bennett Thatcher, Michael Dinger, and Kent Marett. 2014. Research
noteâ ˘AˇTinﬂuence techniques in phishing attacks: an examination of vulnerability and resistance. Information systems
research 25, 2 (2014), 385–400.

Liu Xiangyu, Li Qiuyang, and Sonali Chandel. 2017. Social engineering and Insider threats. In 2017 International
Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC). IEEE, Nanjing, China,
25–34.

Li Xu, Zhenxin Zhan, Shouhuai Xu, and Keying Ye. 2013. Cross-layer detection of malicious websites. In Third ACM

Conference on Data and Application Security and Privacy (CODASPY’13). ACM, USA, 141–152.

M. Xu, G. Da, and S. Xu. 2015a. Cyber Epidemic Models with Dependences. Internet Mathematics 11, 1 (2015),

62–92.

M. Xu and S. Xu. 2012. An Extended Stochastic Model for Quantitative Security Analysis of Networked Systems.

Internet Mathematics 8, 3 (2012), 288–320.

Shouhuai Xu. 2014. Cybersecurity dynamics. In Proceedings of the 2014 Symposium and Bootcamp on the Science of

Security. ACM, USA, 1–2.

S. Xu. 2019. Cybersecurity Dynamics: A Foundation for the Science of Cybersecurity. In Proactive and Dynamic

Network Defense. Springer, USA, 1–31.

Shouhuai Xu. 2020. The cybersecurity dynamics way of thinking and landscape (invited paper). In Proceedings of the

7th ACM Workshop on Moving Target Defense. ACM, USA, 69–80.

Shouhuai Xu. 2021. SARR: A Cybersecurity Metrics and Quantiﬁcation Framework (Keynote). In Science of Cyber
Security - Third International Conference (SciSec’2021) (Lecture Notes in Computer Science, Vol. 13005), Wenlian
Lu, Kun Sun, Moti Yung, and Feng Liu (Eds.). Springer, China, 3–17.

Shouhuai Xu, Wenlian Lu, and Hualun Li. 2015b. A Stochastic Model of Active Cyber Defense Dynamics. Internet

Mathematics 11, 1 (2015), 23–61.

Shouhuai Xu, Wenlian Lu, and Li Xu. 2012a. Push-and pull-based epidemic spreading in networks: Thresholds and

deeper insights. ACM Transactions on Autonomous and Adaptive Systems (TAAS) 7, 3 (2012), 1–26.

Shouhuai Xu, Wenlian Lu, Li Xu, and Zhenxin Zhan. 2014. Adaptive epidemic dynamics in networks: Thresholds and

control. ACM Transactions on Autonomous and Adaptive Systems (TAAS) 8, 4 (2014), 1–19.

S. Xu, W. Lu, and Z. Zhan. 2012b. A Stochastic Model of Multivirus Dynamics. IEEE Transactions on Dependable

and Secure Computing 9, 1 (2012), 30–45.

Teng Xu, Gerard Goossen, Huseyin Kerem Cevahir, Sara Khodeir, Yingyezhe Jin, Frank Li, Shawn Shan, Sagar Patel,
David Freeman, and Paul Pearce. 2021. Deep Entity Classiﬁcation: Abusive Account Detection for Online Social
Networks. In 30th {USENIX} Security Symposium ({USENIX} Security 21). USENIX, USA, –.

Affan Yasin, Rubia Fatima, Lin Liu, Awaid Yasin, and Jianmin Wang. 2019. Contemplating social engineering studies

and attack scenarios: A review study. Security and Privacy 2, 4 (2019), e73.

Dong Yuan, Yuanli Miao, Neil Zhenqiang Gong, Zheng Yang, Qi Li, Dawn Song, Qian Wang, and Xiao Liang. 2019.
Detecting fake accounts in online social networks at the time of registrations. In Proceedings of the 2019 ACM
SIGSAC Conference on Computer and Communications Security. ACM, USA, 1423–1438.

29

Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey

A PREPRINT

Humayun Zafar, Adriane Randolph, Saurabh Gupta, and Carole Hollingsworth. 2019. Traditional SETA no more:
investigating the intersection between cybersecurity and cognitive neuroscience. In Proceedings of the 52nd Hawaii
International Conference on System Sciences. ScholarSpace / AIS Electronic Library (AISeL), USA, –.

Rania Zaimi, Mohamed Haﬁdi, and Mahnane Lamia. 2020. Survey paper: Taxonomy of website anti-phishing solutions.
In 2020 Seventh International Conference on Social Networks Analysis, Management and Security (SNAMS). IEEE,
France, 1–8.

Jin G Zheng, Daniel Howsmon, Boliang Zhang, Juergen Hahn, Deborah McGuinness, James Hendler, and Heng Ji.
2015a. Entity linking for biomedical literature. BMC medical informatics and decision making 15, S1 (2015), S4.
Kangfeng Zheng, Tong Wu, Xiujuan Wang, Bin Wu, and Chunhua Wu. 2019. A session and dialogue-based social

engineering framework. IEEE Access 7 (2019), 67781–67794.

Ren Zheng, Wenlian Lu, and Shouhuai Xu. 2015b. Active cyber defense dynamics exhibiting rich phenomena. In

Proceedings of the 2015 Symposium and Bootcamp on the Science of Security. ACM, USA, 1–12.

R. Zheng, W. Lu, and S. Xu. 2018. Preventive and Reactive Cyber Defense Dynamics Is Globally Stable. IEEE TNSE

5, 2 (2018), 156–170.

30

