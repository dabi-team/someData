9
1
0
2

n
u
J

3

]

Y
S
.
s
c
[

4
v
0
4
2
2
0
.
9
0
8
1
:
v
i
X
r
a

Hypergames and Cyber-Physical Security for Control
Systems

Craig Bakker

Arnab Bhattacharya

Samrat Chatterjee

Draguna L. Vrabie

June 5, 2019

Abstract

The identiﬁcation of the Stuxnet worm in 2010 provided a highly publicized ex-
ample of a cyber attack used to damage an industrial control system physically. This
raised public awareness about the possibility of similar attacks against other industrial
targets – including critical infrastructure. In this paper, we use hypergames to analyze
how adversarial perturbations, like those used by Stuxnet, can be used to manipulate
a system that employs optimal control. Hypergames form an extension of game theory
that enables us to model strategic interactions where the players may have signiﬁcantly
diﬀerent perceptions of the game(s) they are playing. Past work with hypergames has
been limited to relatively simple interactions consisting of a small set of discrete choices
for each player, but here, we apply hypergames to larger systems with continuous vari-
ables. We ﬁnd that manipulating constraints can be a more eﬀective attacker strategy
than directly manipulating objective function parameters. Moreover, the attacker need
not change the underlying system to carry out a successful attack – it may be suﬃcient
It is possible to scale our approach
to deceive the defender controlling the system.
up to even larger systems, but the ability to do so will depend on the characteristics
of the system in question, and we identify several characteristics that will make those
systems amenable to hypergame analysis.

1

Introduction

1.1 Stuxnet and Cyber-Physical Security

The Stuxnet worm was identiﬁed in 2010 as a piece of malware that targeted a very speciﬁc
Industrial Control System (ICS) – namely, uranium enrichment infrastructure [1, 2]. This
may not have been the ﬁrst cyber attack to cause physical damage to an ICS, but it was
highly publicized. As such, Stuxnet brought the potential physical consequences of cyber
attacks into the public eye.

Stuxnet was highly sophisticated. Part of its sophistication lay in its strategy for ob-
taining access to its targets: it exploited four 0-day vulnerabilities, compromised two digital
certiﬁcates, and propagated itself through networks and removable devices [2]. Once it

1

 
 
 
 
 
 
reached a control system, it continued to act stealthily. Stuxnet fed fake data to the ICS
to disguise malicious actions [2, 3] and limited its attacks to avoid detection [4]. The goal
of Stuxnet was not to cause catastrophic failure, which would have been easier. Rather, it
exploited the physical vulnerabilities as well as the cyber vulnerabilities inherent in the ICS.
Stuxnet forced analysts to consider the risk associated with these kinds of cyber attacks.
If we understand risk as the product of consequence, vulnerability, and threat, we can address
each of those components separately. The potential for signiﬁcant consequence is clear: many
industrial processes, including critical infrastructure systems (e.g., the power grid), rely on
Supervisory Control and Data Acquisition (SCADA) software and ICSs. These systems are
also vulnerable. Updates can be risky because they may cause previously functional systems
to produce new errors [4], and even if this is not the case, taking the system in question
oﬄine to perform the updates may be diﬃcult or infeasible [1]. There is a tradeoﬀ between
security and ease of use, and a knowledge gap between cyber security specialists and control
engineers can compound this.

There are two more factors that increase the vulnerability of ICSs to cyber attack. Firstly,
industrial systems are often serviced by outside contractors, and the devices (computers, USB
drives, etc.) used by those contractors can provide a malware vector that bypasses traditional
cyber security measures such as air gaps [2]. Secondly, industry standardization also reduces
uncertainty for potential attackers; complexity, heterogeneity, and uncertainty make it more
diﬃcult for attackers to design successful attacks.

Most of the uncertainty regarding the risk of cyber attacks on ICSs has to do with threat.
The old consensus was that these systems were too specialized to attack [4]. Stuxnet, for
example, required a great deal of specialized knowledge about the control systems in question
[2]. In the case of terrorism, for example, it is easier to build a bomb than to write code
that will cause comparable physical destruction. However, Stuxnet showed that these kinds
of attacks are possible for those determined to carry them out.

1.2 Hypergames

Game theory is a branch of mathematics that looks at strategic interactions between ratio-
nal entities. It has seen considerable use in economic [5] and security [6] applications. A
fundamental premise of strategic games in game theory is that all of the players are seeing
and playing the same game. This is not always true, though. Belief manipulation plays
a key role in some strategic interactions. In other cases, not all player objectives may be
common knowledge. This necessitates understanding more completely players’ perceptions
of the game(s) they are playing; one way to model this is through hypergames [7].

Hypergames allow players to play diﬀerent games and can account for diﬀerences in their
perceptions of the same game without considering uncertainty probabilistically. For example,
one group of players may distinguish between certain actions while another group considers
those actions all to be identical. On the other hand, some players may not be aware of the
existence of other players in the game (or may not be aware of all of those other players’
actions). Hypergames essentially enable us to extend the concept of rationality to a bounded
information situation. This, in turn, makes it possible for a given player to exploit another
player’s misperceptions. In analyzing the (potentially) diﬀerent games that each player is
playing, though, we are still able to apply game theoretic concepts and thus build on existing

2

game theory research. We can describe a two-player game as

GA,B = (P, S, U)

P = {A, B}
S = {SA, SB}
U = {uA, uB}

(1)

(2)
(3)
(4)

where A and B are the players, SA and SB are those players’ respective action spaces, and
uA, uB : SA × SB → (cid:60) are their respective payoﬀ functions, which provide a partial ordering
over SA × SB for each player. We can describe a ﬁrst level hypergame as

HA,B (A, B, GA,B) = {p (A, GA,B) , p (B, GA,B)}

(5)

where p (A, GA,B) is A’s perception of GA,B. The condition p (A, GA,B) (cid:54)= p (B, GA,B) could
be caused by discrepancies such as p (A, {A, B}) = {A}, which would indicate that A is not
aware of B’s presence. We can also describe perceptions about perceptions. For example,
p (AB, uA) is A’s perception of B’s perception of A’s utility function. For a ﬁrst level
hypergame, there are misperceptions, but the players are not aware of those misperceptions:

p (A, GA,B) (cid:54)= p (B, GA,B)
p (AB, GA,B) = p (A, GA,B)
p (BA, GA,B) = p (B, GA,B)

(6)
(7)
(8)

For a second level hypergame, at least one player is aware of the misperceptions. For

example, if A is aware of the misperceptions but B is not, we have

p (AB, GA,B) (cid:54)= p (A, GA,B)
p (BA, GA,B) = p (B, GA,B)

(9)
(10)

Player B then plays p (B, GA,B) while A plays the hypergame

HA,AB (A, AB, GA,B) = {p (A, GA,B) , p (AB, GA,B)}

(11)

The overall solution to a hypergame can then be calculated by correctly aggregating the
equilibrium solutions to the players’ perceived (hyper)games. In a ﬁrst level hypergame, for
example, the equilibrium solution is (xA, xB), where xA is A’s equilibrium strategy for the
game p (A, GA,B) and xB is B’s equilibrium strategy for the game p (B, GA,B). For the second
level hypergame described above, xA would be A’s optimal strategy for HA,AB (A, AB, GA,B),
while xB would still be B’s equilibrium strategy for p (B, GA,B). These concepts extend

3

naturally to higher level hypergames and additional players. See Kovach et al.
Gutierrez et al. [9] for more details.

[8] and

Approaches such as reﬂexive control [10], Mirage Equilibria [11], and k-level reasoning
[12, 13] have been applied to systems that may not have common knowledge (and thereby
incorporate a kind of bounded rationality). Despite some diﬀerences in notation and nomen-
clature, these approaches all incorporate hierarchies of beliefs (e.g., Player 1’s beliefs about
Player 2’s beliefs). However, the ﬁrst two, along with hypergames, diﬀer somewhat from k-
level reasoning with respect to the accuracy of the player perceptions. In k-level reasoning,
the focus is on the degree to which one player anticipates another. In principle, this approach
does not rule out the possibility that a given player might misperceive the nature of the game
(payoﬀ structure, available actions, etc.), but in practice, this is not a key consideration. For
hypergames, this is a key consideration. The concept of a subjective game (i.e., p (A, GA,B))
is central to hypergame analysis, and belief hierarchies exist to support that; the same is
true for reﬂexive control and Mirage Equilibria.

For example, a key hypergame result is that hypergame equilibrium solutions can be
stable under misperceptions [14]. In these cases, each player does what the other players
expect – which can happen even when the players’ perceptions diﬀer or are erroneous –
and thus there is no motivation for players to update their perceptions. This is similar to a
conjectural equilibrium [11] in that players do not know what they do not know. In a repeated
hypergame context, then, these equilibria are stable, and extending belief hierarchies to
higher and higher levels would not necessarily change that. Using the formalism we employed
previously, a hypergame equilibrium is stable if p (A, xB) = xB and p (B, xA) = xA, which
need not imply that p (A, GA,B) = p (B, GA,B).

Hypergames have been used to study water resource management [15], supply chain
relationships [16], and cyber attacks [17]. Some research has also looked at connecting hy-
pergames with other branches of game theory. Kanazawa et al. [18] studied an evolutionary
version of hypergames. This included calculating evolutionarily stable strategies and deﬁn-
ing hypergame replicator dynamics. Sasaki and Kijima [19, 20] showed how hypergames can
be reformulated as Bayesian games (at least in some cases). In doing so, though, they iden-
tiﬁed reasons why it may be advantageous to avoid that reformulation. Firstly, hypergames
can provide a simpler and more natural epistemic representation of the game’s players; the
treatment of unawareness, for example, can be more convincing than in the Bayesian case.
Secondly, there are some hypergame solution concepts, such as stability under misperception,
that do not map to the Bayesian reformulation. The topic of misperception has also led to
research into how repeated hypergames can be used to improve or update perceptions [14].
House and Cybenko used both hidden Markov models and a maximum entropy approach
[17]. Takahashi et al., on the other hand, used a genetic algorithm [21]. Generally speaking,
though, the hypergame literature is relatively small; Kovach et al. provided a review of the
ﬁeld [8]. Moreover, all of the examples that we have seen have involved hypergames with a
relatively small number of discrete choices. Solving for the equilibrium solutions, then, has
involved hand calculations and/or exhaustive enumeration.

4

1.3 Aim and Motivation

The goal of this paper is to show how hypergames can be used in optimal control where the
control system in question is subject to adversarial perturbations and to demonstrate how
this analysis can apply to Stuxnet-like attacks. This research contributes to ongoing work
in optimal control by showing how manipulating controller perceptions can function as an
attacker strategy; the attacker actually uses the control system against itself. These analyses
then highlight weaknesses in the control system – weaknesses that are vulnerable to attack
even if they might not be vulnerable to random events. This research also advances hyper-
game research in two ways. Firstly, it brings hypergames to bear on a new application area
(i.e., optimal control) – one rather diﬀerent than the examples in previous papers. Secondly,
it applies hypergame concepts to systems of signiﬁcantly greater complexity than previous
hypergame research has used. The examples in this paper have continuous variables, and
the second example is a discrete-time optimal control problem with time-varying variables.
Both problems, moreover, require using numerical optimization methods to ﬁnd hypergame
equilibria. Taking hypergames to this level of complexity makes the hypergame concept
more viable as a tool for analyzing real systems and not just toy problems.

This kind of investigation is highly relevant to addressing Stuxnet-like attacks from a
control perspective. Leaving aside IT-based cyber security concerns, let us assume that an
attacker has access to at least part of an ICS. Can we then characterize the kind of damage
that that attacker could produce, and can we design control procedures that minimize that
damage? In this paper, we focus primarily on the former but touch upon the latter; we intend
to address the latter more fully in later work. ICSs provide examples of (potentially high-
impact) cyber-physical systems where control provides the connection between the ‘cyber’
and ’physical’ components. The idea behind this research, then, is not to replace traditional
cyber security methods but rather to recognize that control systems can be used to provide
another layer of robustness to attack if those control systems are designed to do so and that
the physical weaknesses accessible through cyber means can be analyzed by looking at the
control model.

2 Static Problem Formulation

To demonstrate some of the concepts of this paper, we consider a static optimization problem
constrained within an operating envelope, which is represented as an inequality constraint:

J (u, θ)

min
u
g(u, c) ≤ 0

(12)

(13)

where u is the vector of decision variables, θ is the vector of objective function parameters,
and c is the vector of operating envelope parameters. Note that g may be a vector of
constraint equations gl, l = 1, 2, . . ., in which case (13) is equivalent to gl (u, c) ≤ 0 ∀ l.

5

2.1 Objective Function Manipulation

Here, we will consider a situation where the attacker can manipulate the defender’s observa-
tion of objective function parameters; ˆθ = θ + ∆θ, where the vector ˆθ denotes the quantities
that the defender observes. The attacker optimization is then

J (ˆu∗, θ)

max
∆θ
(cid:107)∆θ(cid:107)2 ≤ δθ,max
(cid:16)

(cid:16)

(cid:17)
ˆu, ˆθ

1
2

ˆu∗ = arg min

J

: g(ˆu, c) ≤ 0

(cid:17)

(14)

(15)

(16)

ˆu

where (16) describe what the attacker expects the defender’s optimization to be and (15) is
a constraint on the attacker’s manipulations, which is a reasonable assumption in a context
of limited attack budgets or when attack detection mechanisms are present in the system.
This constitutes a second level hypergame. If A represents the attacker and D represents
the defender, we have

p (D, θ) = ˆθ (cid:54)= θ = p (A, θ)
p (D, {A, D}) = {D} = p (AD, {A, D})

If the defender knows of the attacker, this leads to a higher level hypergame, where

p (DAD, {A, D}) = p (AD, {A, D}) = {D}

The defender’s optimization is

(cid:16)

u, ˆθ − ∆θ

(cid:17)

min
u

J

g(u, c) ≤ 0

(17)
(18)

(19)

(20)

(21)

The true θ values are unknown to the defender, but the defender calculates the ∆θ values
by solving what is believed to be the attacker’s problem: (14)-(16).

J (ˆu∗, θ)

max
∆θ
(cid:107)∆θ(cid:107)2 ≤ δθ,max
(cid:16)

(cid:16)

(cid:17)
ˆu, ˆθ

1
2

ˆu∗ = arg min

J

: g(ˆu, c) ≤ 0

(cid:17)

(22)

(23)

(24)

ˆu

Given that the defender only knows ˆθ, not θ, solving the attacker’s problem to determine
∆θ will require using θ = ˆθ − ∆θ. As a further extension, we consider the scenario where the
attacker manipulates the defender’s perceptions of θ, the defender knows that the attacker

6

is doing this, and the attacker knows that the defender is anticipating the attacker’s pertur-
bations. We refer to this as a ‘double-bluﬀ’ manipulation here and in the rest of the paper.
This problem leads us to a multi-level optimization problem:

J (u∗, θ)

max
∆θ
(cid:107)∆θ(cid:107)2 ≤ δθ,max
(cid:16)

(cid:16)

(cid:17)
u, ˜θ

1
2

u∗ = arg min

J

: g(u, c) ≤ 0

(cid:17)

subject to

u

ˆu∗ = arg min

ˆu

(cid:17)
(cid:16)
ˆu∗, ˜θ

J

max
∆ˆθ
(cid:13)
(cid:13)
1
2
(cid:13)∆ˆθ
(cid:13)
(cid:13)
≤ δθ,max
(cid:13)
2
(cid:17)
(cid:16)
(cid:16)
ˆu, ˜θ + ∆ˆθ
J

: g(ˆu, c) ≤ 0

(cid:17)

(25)

(26)

(27)

(28)

(29)

(30)

where p (D, θ) = ˜θ = ˆθ − ∆ˆθ is the defender’s estimate of the true value of θ. There are
many other potential combinations of misperceptions that we could also consider. Note that
the defender’s perceived cost (i.e., objective function value) may diﬀer from the true cost in
some cases.

For the purpose of comparison, we can model the attacker manipulating the true value

of θ:

max
∆θ

min
u

J (u, θ + ∆θ)

(cid:107)∆θ(cid:107)2 ≤ δθ,max
g (u, c) ≤ 0

(31)

(32)
(33)

In this case, there are no misperceptions, and the situation is simply a zero-sum game,

not a hypergame.

2.2 Constraint Manipulation

The previous section involved the attacker manipulating parameters in the objective function.
In this case, there is a signiﬁcant diﬀerence between manipulating the true values and the
defender’s perceptions. If the attacker is manipulating the constraints, however, then the
distinction changes. If the attacker alters the constraint to be more restrictive, then it does
not matter whether the manipulation is of the real constraint or of the defender’s perceptions
– both actions lead to the same result (assuming that the defender abides by the constraint),
and the perceived cost is the true cost in both cases. If the attacker alters the constraint to be
less restrictive, the results are less clear. If the attacker manipulates the defender perception,

7

the control process may hit a physical limit and/or damage the system trying to reach an
infeasible state. This could be modelled by having some kind of large penalty function for
violations of the true constraint. Manipulating the true constraint in such a way as to relax
it may be impossible if the constraint is a physical limitation of the system. For this section,
we specify that the attacker can manipulate the defender’s perception of parameters in the
constraint (ˆc = c + ∆c are the quantities that the defender perceives). These perturbations
are then subject to a cost function as with the objective function parameter perturbations.

1
2

(cid:107)∆c(cid:107)2 ≤ δc,max

(34)

2.2.1 Maximizing Cost

If the attacker is manipulating the defender’s perceptions to maximize defender cost, this
results in a series of multi-level optimization problems, corresponding to second or higher
level hypergames, analogous to those described in the previous section. If the attacker is
deceiving an unsuspecting defender, we have

J (u∗, θ)

max
∆c
(cid:107)∆c(cid:107)2 ≤ δc,max

1
2

u∗ = arg min

(J (u, θ) : g (u, ˆc) ≤ 0)

u

If the defender is aware of the attack, we have

subject to

min
u

J (u, θ)

g (u, ˆc − ∆c) ≤ 0

J (ˆu∗, θ)

max
∆c
(cid:107)∆c(cid:107)2 ≤ δc,max

1
2

ˆu∗ = arg min

(J (ˆu, θ) : g (ˆu, ˆc) ≤ 0)

ˆu

(35)

(36)

(37)

(38)

(39)

(40)

(41)

(42)

In a situation analogous to that described in the previous section, the defender only knows
ˆc, not c, so solving the attacker’s problem to determine ∆c will require using c = ˆc − ∆c. If
the attacker is aware that the defender is anticipating an attack, the resulting problem is

8

subject to

max
∆c

J (u, θ)

(cid:107)∆c(cid:107)2 ≤ δc,max

1
2

u∗ = arg min

(J (u, θ) : g(u, ˜c) ≤ 0)

u

J (ˆu∗, θ)

max
∆ˆc
(cid:107)∆ˆc(cid:107)2 ≤ δc,max

(J (ˆu, θ) : g(ˆu, ˜c + ∆ˆc) ≤ 0)

1
2
ˆu∗ = arg min

ˆu

(43)

(44)

(45)

(46)

(47)

(48)

where p (D, c) = ˜c = ˆc − ∆c is the defender’s estimate of the true value of c.

2.2.2 Breaking the System

The attacker could also try to cause the defender to deviate maximally from the operating
envelope constraint in the interest of causing a catastrophic failure. We refer to this as
attempting to break the system. If the attacker is deceiving an unsuspecting defender, we
have

γT g (u∗, c)

max
∆c
(cid:107)∆c(cid:107)2 ≤ δc,max

1
2

u∗ = arg min

(J (u, θ) : g (u, ˆc) ≤ 0)

u

(49)

(50)

(51)

where γT g (u, c) indicates a weighted sum for a vector-valued g. If the defender is aware of
the attack, we have

min
u

J (u, θ)

g (u, ˆc − ∆c) ≤ 0

subject to

γT g (ˆu∗, c)

max
∆c
(cid:107)∆c(cid:107)2 ≤ δc,max

1
2

ˆu∗ = arg min

(J (ˆu, θ) : g (ˆu, ˆc) ≤ 0)

ˆu

9

(52)

(53)

(54)

(55)

(56)

If the attacker is aware that the defender is anticipating an attack, the resulting problem

is

subject to

γT g (u∗, c)

max
∆c
(cid:107)∆c(cid:107)2 ≤ δc,max

1
2

u∗ = arg min

(J (u, θ) : g(u, ˜c) ≤ 0)

u

γT g (ˆu∗, c)

max
∆ˆc
(cid:107)∆ˆc(cid:107)2 ≤ δc,max

1
2
ˆu∗ = arg min

(J (ˆu, θ) : g(ˆu, ˜c + ∆ˆc) ≤ 0)

(57)

(58)

(59)

(60)

(61)

(62)

ˆu

where ˜θ is deﬁned as before. There are various other possibilities in the same vein involving
asymmetric information or false beliefs.

2.3 Analytical Results

2.3.1 Objective Function Perturbations

In this section, we will show that the defender can be robust with respect to manipulated
perceptions of θ. Let us assume that g (u, c) is convex for c ≥ 0 and

J (u, θ) =

(cid:88)

k

θkfk (u)

(63)

where each fk (u) is convex. The optimization is therefore convex for θ ≥ 0, and the opti-
mality conditions

(cid:88)

k

∂fk
∂u

θk +

(cid:88)

l

λl

∂gl
∂u

= θT ∂f
∂u

+ λT ∂g
∂u

= 0

0 ≤ λl ⊥ gl (u, c) ≤ 0 ∀ l

(64)

(65)

are both necessary and suﬃcient; λ is the vector of Kuhn-Tucker multipliers. Let us also
deﬁne

10

R (u) =

(cid:26) ∂fk
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u

: k = 1, 2, . . . , nθ

(cid:27)

T (u) =

S (u) = {l : λl > 0}
S(cid:48) (u) = {l : gl (u, c) = 0}
(cid:12)
(cid:27)
(cid:12)
(cid:12)
(cid:12)u
(cid:12)
(cid:12)
(cid:12)
(cid:12)u

(cid:26) ∂gl
∂u
(cid:26) ∂gl
∂u

: l ∈ S(cid:48) (u)

: l ∈ S (u)

(cid:27)

T (cid:48) (u) =

(66)

(67)
(68)

(69)

(70)

where R and T are sets of vectors, S is a set of indices denoting the positive λl values at
u, and S(cid:48) is a set of indices denoting the active set at u. Note that S (u) ⊆ S(cid:48) (u), and
S (u) (cid:54)= S(cid:48) (u) only if there are active constraints with corresponding multipliers that are
zero.

Lemma 2.1. Assume that u∗ ∈ arg min

(J (u, θ) : g (u, c) ≤ 0) and that ˆθ = θ + ∆θ ≥ 0. If

there exists ∆λ ≥ −λ such that

u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

(cid:12)
∆θT ∂f
(cid:12)
(cid:12)
∂u
(cid:12)u∗
∆λlgl (u∗, c) = 0 ∀ l

+ ∆λT ∂g
∂u

= 0

(71)

(72)

then u∗ ∈ arg min

(cid:16)

J

(cid:16)

(cid:17)
u, ˆθ

: g (u, c) ≤ 0

(cid:17)

and ˆλ = λ + ∆λ are the new Kuhn-Tucker multi-

u

pliers.

Proof. If

then for ˆθ = θ + ∆θ

θT ∂f
∂u
∆θT ∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗
(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

= 0

(cid:12)
+ λT ∂g
(cid:12)
(cid:12)
∂u
(cid:12)u∗
(cid:12)
+ ∆λT ∂g
(cid:12)
(cid:12)
∂u
(cid:12)u∗

= 0

(cid:16)ˆθT − ∆θT (cid:17) ∂f
∂u
(cid:12)
ˆθT ∂f
(cid:12)
(cid:12)
∂u
(cid:12)u∗

+ (cid:0)λT − ∆λT + ∆λT (cid:1) ∂g
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗
+ (cid:0)λT + ∆λT (cid:1) ∂g
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

= 0

Furthermore, since ∆λ ≥ −λ and ∆λlgl (u∗, c) = 0 ∀ l,

11

(73)

(74)

(75)

(76)

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

= 0

ˆθT ∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ ˆλT ∂g
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

= 0

0 ≤ ˆλl ⊥ gl (u∗, c) ≤ 0 ∀ l

where ˆλ = λ + ∆λ. Since ˆθ ≥ 0 and J

(cid:16)

(cid:17)
u, ˆθ

and g (u, c) are convex, the optimization

(cid:16)

(cid:17)
u, ˆθ

J

min
u
g (u, c) ≤ 0

(77)

(78)

(79)

(80)

is convex, and the optimality conditions (77)-(78) are necessary and suﬃcient. u∗ satisﬁes
these conditions, so u∗ ∈ arg min

: g (u, c) ≤ 0

(cid:17)
u, ˆθ

(cid:16)

(cid:16)

(cid:17)

J

.

u

Lemma 2.2. If span (R (u∗)) ⊆ span (T (u∗)), then there exists r > 0 such that for (cid:107)∆θ(cid:107)p ≤
(J (u, θ) : g (u, c) ≤ 0) implies that u∗ ∈ arg min
r, p > 0, u∗ ∈ arg min
: g (u, c) ≤ 0

(cid:17)
u, ˆθ

(cid:16)

(cid:16)

J

(cid:17)

,

u
where ˆθ = θ + ∆θ.

u

Proof. Let us deﬁne the matrix A such that the rows of A are the vectors ∂gl
∂u ∈ T (u∗).
If span (R (u∗)) ⊆ span (T (u∗)), then any linear combination of ∂fk
∂u ∈ R (u∗) exists within
span (T (u∗)), which is the rowspace of A. This implies that for any ∆θ, there exists ∆λ
such that

(cid:88)

∆θk

k

∂fk
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

(cid:88)

+

∆λl

l∈S(u∗)

∂gl
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

= ∆θT ∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ bT A = 0

∆λl = 0, l /∈ S (u∗)

and if A+ is the Moore-Penrose pseudo-inverse of A, then

bT = −∆θT ∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

A+

satisﬁes this exactly because ∆θT ∂f
∂u

(cid:12)
(cid:12)u∗ is in the rowspace of A. Deﬁne

λmin = min
l∈S(u∗)

λl

By deﬁnition, λmin > 0. If (cid:107)∆λ(cid:107)p ≤ λmin, then

max
l

|∆λl| = (cid:107)∆λ(cid:107)∞ ≤ (cid:107)∆λ(cid:107)p ≤ λmin, p > 0

12

(81)

(82)

(83)

(84)

(85)

Therefore, (cid:107)∆λ(cid:107)p ≤ λmin implies that max

|∆λl| ≤ λmin and thus ∆λl ≥ −λmin ≥

l

−λl ∀ l. If

then

(cid:107)∆θ(cid:107)p ≤

λmin
(cid:13)
∂u A+(cid:13)
(cid:13) ∂f
(cid:13)p

= r

(cid:107)∆λ(cid:107)p =

(cid:13)
∆θT ∂f
(cid:13)
(cid:13)
∂u
(cid:13)

A+

(cid:13)
(cid:13)
(cid:13)
(cid:13)p

≤ (cid:107)∆θ(cid:107)p

(cid:13)
(cid:13)
(cid:13)
(cid:13)

∂f
∂u

A+

(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ λmin

By Lemma 2.1, u∗ ∈ arg min

(cid:16)

J

(cid:16)

(cid:17)
u, ˆθ

: g (u, c) ≤ 0

(cid:17)

.

u

(86)

(87)

Corollary 2.2.1. Deﬁne the matrix A such that the rows of A are the vectors ∂gl
T (u∗).

∂u ∈
If A is invertible, then there exists r > 0 such that for (cid:107)∆θ(cid:107)p ≤ r, p > 0,
, where

(J (u, θ) : g (u, c) ≤ 0) implies that u∗ ∈ arg min

u∗ ∈ arg min

: g (u, c) ≤ 0

(cid:17)
u, ˆθ

(cid:16)

(cid:17)

(cid:16)

J

u

ˆθ = θ + ∆θ.

u

Proof. If A is invertible, then the rows of A are linearly independent and span (T (u∗)) = Rnu,
where u ∈ Rnu, and thus span (R (u∗)) ⊆ span (T (u∗)). This satisﬁes the conditions of
Lemma 2.2, and thus the same conclusions follow.

Lemma 2.3. The set Θ (u∗) =

(cid:26)

ˆθ : u∗ ∈ arg min

(cid:16)

J

(cid:16)

(cid:17)
u, ˆθ

: g (u, c) ≤ 0

(cid:17)

(cid:27)

, ˆθ ≥ 0

is un-

bounded and convex if it is non-empty.

u

(cid:17)
u, cˆθ
Proof. J (u, θ) is linear in θ, so J
solutions are invariant with respect to scalar multiples of the objective function:

(cid:17)
u, ˆθ

= cJ

(cid:16)

(cid:16)

for any positive scalar c. Optimal

arg min
u

(cid:16)

J

(cid:16)

(cid:17)
u, ˆθ

: g (u, c) ≤ 0

(cid:17)

= arg min

(cid:16)

cJ

(cid:17)
(cid:16)
u, ˆθ

: g (u, c) ≤ 0

(cid:17)

= arg min

u

(cid:16)

J

(cid:16)

(cid:17)
u, cˆθ

u

: g (u, c) ≤ 0

(cid:17)

(88)

Therefore, for any ˆθ ∈ Θ (u∗) and any positive scalar c, cˆθ ∈ Θ (u∗). Thus, Θ (u∗) is

unbounded if it is non-empty. Furthermore, for ﬁxed u∗, the optimality conditions

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ ˆλT ∂g
∂u

(cid:12)
ˆθT ∂f
(cid:12)
(cid:12)
∂u
(cid:12)u∗
ˆλl = 0 l /∈ S(cid:48) (u∗)
ˆλl ≥ 0 l ∈ S(cid:48) (u∗)

= 0

(89)

(90)

(91)

13

form a set of linear inequalities in ˆλ and ˆθ; because u∗ is ﬁxed, we can disregard g (u∗, c) ≥ 0.
The space of ˆλ and ˆθ that satisfy these constraints is therefore convex. Since this space is
in this space
convex, for any

(cid:16)ˆθ1, ˆλ1

(cid:16)ˆθ2, ˆλ2

and

(cid:17)

(cid:17)

(cid:16)
αˆθ1 + (1 − α) ˆθ2, αˆλ1 + (1 − α) ˆλ2

(cid:17)

, α ∈ [0, 1]

(92)

remains in Θ (u∗). Thus for any ˆθ1, ˆθ2 ∈ Θ (u∗),
convex.

(cid:16)

αˆθ1 + (1 − α) ˆθ2

(cid:17)

∈ Θ (u∗), so Θ (u∗) is

Theorem 2.4. If span (R (u∗)) ⊆ span (T (u∗)) and u∗ ∈ arg minu (J (u, θ) : g (u, c) ≤ 0),
there exists a convex, unbounded set of ∆θ such that u∗ ∈ arg min
(J (u, θ + ∆θ) : g (u, c) ≤ 0).

u

Proof. By Lemma 2.2, if span (R (u∗)) ⊆ span (T (u∗)) and u∗ ∈ arg minu (J (u, θ) : g (u, c) ≤ 0),
then there exists r > 0 such that for (cid:107)∆θ(cid:107)p ≤ r, p > 0, u∗ ∈ arg min
(J (u, θ + ∆θ) : g (u, c) ≤ 0).
Therefore, the set

u

Θ (u∗) =

(cid:26)

ˆθ : u∗ ∈ arg min

(cid:16)

J

(cid:17)
(cid:16)
u, ˆθ

: g (u, c) ≤ 0

(cid:17)

(cid:27)

, ˆθ ≥ 0

(93)

u

is non-empty. By Lemma 2.3 if Θ (u∗) is non-empty, it is unbounded and convex.

(J (u, θ) : g (u, c) ≤ 0), then
(cid:17)

(cid:16)

(cid:16)

: g (u, c) ≤ 0

.

(cid:17)
u, ˆθ

Lemma 2.5. If span (R (u∗)) (cid:42) span (T (cid:48) (u∗)) for u∗ ∈ arg min

u

for any (cid:15) > 0, there exists ∆θ such that (cid:107)∆θ(cid:107) < (cid:15) and u∗ /∈ arg min

J

u

Proof. Assume that for suﬃciently small (cid:15) > 0, there is no ∆θ such that 0 < (cid:107)∆θ(cid:107) < (cid:15) and
u∗ /∈ arg min
. Then for suﬃciently small ∆θ, there exists ∆λ such

: g (u, c) ≤ 0

(cid:17)
u, ˆθ

(cid:17)

(cid:16)

(cid:16)

J

u

that

∆θT ∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ ∆λT ∂g
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗
∆λl ≥ −λl l ∈ S(cid:48) (u∗)
∆λl = 0 l /∈ S(cid:48) (u∗)

= 0

(94)

(95)
(96)

Since u∗ is ﬁxed, the active set cannot change. Let us deﬁne the matrix A such that the
∂u ∈ T (cid:48) (u∗) and deﬁne the vector b such that the elements of b

rows of A are the vectors ∂gl
are ∆λl, l ∈ S(cid:48) (u∗). Then

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

∆λT ∂g
∂u
(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

∆θT ∂f
∂u

= bT A

+ bT A = 0

14

(97)

(98)

If span (R (u∗)) (cid:42) span (T (u∗)) , l ∈ S(cid:48) (u∗), then there exists ∆θ0 such that ∆θT
0

span (T (u∗)) and therefore

∆θT
0

∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ bT A (cid:54)= 0 ∀ b

Moreover, for any such ∆θ0, there exists ∆θ = c∆θ0 such that for any c > 0

c∆θT
0

∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ bT A (cid:54)= 0 ∀ b

Since (cid:107)c∆θ0(cid:107) = c (cid:107)∆θ0(cid:107), for any (cid:15) > 0, there exists ∆θ = (cid:15)

(cid:107)∆θ0(cid:107)∆θ0 such that

∆θT ∂f
∂u

(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

+ bT A (cid:54)= 0 ∀ b

∂f
∂u /∈

(99)

(100)

(101)

Because the optimality conditions are necessary and suﬃcient, and because these condi-
(J (u, θ + ∆θ) : g (u, c) ≤ 0), and thus the lemma is

tions cannot be satisﬁed, u∗ /∈ arg min

proved by contradiction.

u

If small ∆θ values change the value of u∗ but not the active set, it is possible to calculate
the ∂u
∂∆θ for the optimal solution by diﬀerentiating the optimality conditions. This provides
us with a linear system that we can solve to calculate ∂u
∂∆θ , and u∗ (∆θ) will be smooth and
well-deﬁned as long as the active set does not change. We can therefore compare this kind of
system with one that is impervious to these small changes. For such a system, the measure
of the ‘safe’ range is conservative, but outside of it, continuous changes in ˆθ could result in
discrete jumps in u∗ as the active set changes. Furthermore, if J (u, θ) is nonlinear in θ but
still convex for all θ ≥ 0, then it may possible to produce similar proofs for this case, but
this would require further assumptions regarding the dependence of J on θ.

2.3.2 Constraint Function Manipulations

Unfortunately, manipulations of c are not subject to the same kinds of robustness that
manipulations of θ are. This is essentially a consequence of the discussion at the beginning
of Section 2.2: manipulating the defender’s perception of the constraints produces the same
change in the decision variables as changing the true constraints would as long as the defender
abides by the perceived constraints. For example,

gl (u, c) = 0, l ∈ S (u)
(cid:88)

∂gl
∂ui

∂ui
∂cj

+

∂gl
∂cj

= 0

Therefore, if ∂gl
∂cj

(cid:54)= 0, then ∂ui
∂cj

(cid:54)= 0.

i

15

(102)

(103)

2.4 Test Problem

As a demonstration, we consider minimizing power consumption for a fan in an HVAC
system. A problem like this could form a component in a larger HVAC system, possibly as a
subsystem subject to repeated optimization under changing parameter values. The baseline
defender optimization problem is

min
m,p

θ1m + θ2m2 + θ3p

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

(104)

(105)

where m is the mass ﬂow rate, p is the static pressure, the θ values are power consumption
parameters for the fan, and cm, cp, and cr are parameters deﬁning the operating envelope.
The attacker can introduce perturbations ∆θi such that ˆθi = θi + ∆θi and 1
2 ≤ δθ,max
or perturbations ∆cm, ∆cp, ∆cr such that ˆcm = cm + ∆cm, ˆcp = cp + ∆cp, ˆcr = cr − ∆cr, and
2 (cid:107)∆c(cid:107)2
1
2 ≤ δc,max. Note the negative sign in ˆcr. This deviates slightly from our convention
above, but it also helps to simplify later calculations in some ways, and it does not ultimately
change the results. In our computations in the rest of the paper, we use θ1 = θ2 = 1, θ3 = 2,
cm = cp = 5, and c2
2 constant in (105) does not change the mathematical
properties of the optimization, but it, too, simpliﬁes some of the calculations used later in
this paper; see Appendix A for these calculations.

r = 10. The 1

2 (cid:107)∆θ(cid:107)2

3 Dynamic Optimization

3.1 Model Formulation

We now bring hypergames to bear on a Model Predictive Control (MPC) problem, where
the control objective is to minimize a cost function subject to state dynamics constraints
and operational constraints over a time horizon of length τ :

min
ut

τ
(cid:88)

t=1

J(ut, xt, θ)

xt = f (xt−1, ut, αt, β)
xτ − x0 = 0
g (cid:0)xt, ut, αt, β(cid:1) ≤ 0

(106)

(107)
(108)

(109)

where ut are the control decision variables, xt are the states of the system, αt are the system
disturbances, and β are the model parameters. We assume that β and αt can be aﬀected
by adversarial perturbations. The attacker can either perturb the defender’s perception of
parameters β to maximize cost (‘Static Attack’) or perturb the defender’s perception of αt
to maximize cost (’Dynamic Attack’). The perturbations denoted ∆β, and ∆αt are bounded
by constraints, normalized as appropriate if they have diﬀerent orders of magnitude; such
constraints are then with respect to relative perturbations on those parameters.

16

(cid:20)∆β1
β1
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

∆β
β

(cid:21)T

. . .

∆β1
β1

≤ δβ,max

(cid:107)∆αt(cid:107)2

2 ≤ δα,max

∆β
β

≡

(cid:13)
1
(cid:13)
(cid:13)
2
(cid:13)
τ
(cid:88)

t=1

1
2

The static attack problem is

τ
(cid:88)

J(ut, xt, θ)

max
∆β

t=1
(cid:13)
2
∆β
(cid:13)
(cid:13)
β
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
2

≤ δβ,max

subject to

xt = f (xt−1, ut, αt, β)
ˆx0 = x0

min
ut

τ
(cid:88)

t=1

J(ut, ˆxt, θ)

ˆxt = f (ˆxt−1, ut, αt, ˆβ)
ˆxτ − ˆx0 = 0
(cid:17)
(cid:16)
ˆxt, ut, αt, ˆβ

≤ 0

g

(110)

(111)

(112)

(113)

(114)

(115)
(116)

(117)

(118)
(119)

(120)

This is a second level hypergame where p (D, β) = ˆβ (cid:54)= β. The defender optimization
is with respect to perceived values, not real values; the attacker perturbations mean that
p (D, xt) = ˆxt (cid:54)= xt even though the attacker does not directly manipulate the state variables.
The dynamic attack problem is

τ
(cid:88)

J(ut, xt, θ)

t=1
(cid:13)∆αt(cid:13)
(cid:13)
2
2 ≤ δα,max
(cid:13)

max
∆αt

1
2

(cid:88)

t

subject to

xt = f (xt−1, ut, αt, β)
ˆx0 = x0

17

(121)

(122)

(123)
(124)

min
ut

τ
(cid:88)

t=1

J(ut, ˆxt, θ)

ˆxt = f (ˆxt−1, ut, ˆαt, β)
ˆxτ − ˆx0 = 0
g (cid:0)ˆxt, ut, ˆαt, β(cid:1) ≤ 0

(125)

(126)
(127)

(128)

This, similarly, is a second level hypergame where p (D, αt) = ˆαt (cid:54)= αt. As before, we
could consider many variations on the dynamic and static attacks, but we will only look at
these two scenarios here.

3.2 Analytical Results

The analytical results derived for the static optimization problem are applicable here as well.
If the dynamic optimization is convex, there are analogous results for perturbations to θ, and
it can similarly be shown that constraint perturbations (to β and αt, in this case) cannot
exhibit the same kind of local robustness as objective function perturbations.

3.3 Test Problem

Our MPC test problem is a single-zone HVAC system with a fan, heater, and chiller. The
objective is to minimize power consumption subject to physical constraints (e.g., the zonal
temperature evolution) and operational constraints (e.g., remaining within comfort-deﬁned
temperature limits). The baseline optimal control problem for the system is

τ
(cid:88)

(cid:104)

min

θ1mt + θ2

(cid:0)mt(cid:1)2 + νhcpmt (cid:0)T t

i − dtT t

0 − (cid:0)1 − dt(cid:1) T t

n

t=1

+νncpmt (cid:0)T t
n = (1 − γ) T t−1
T t

(cid:1) + νccpmt (cid:0)T t
s,n − T t
n

i − T t
s
(cid:1) + γT t
0 + Qt
n

(cid:1)(cid:3)

s,n − T t
s
n + βmt (cid:0)T t
T τ
n − T 0
n = 0
ml ≤ mt ≤ mu
s,n − T t
T t
s ≥ 0
n ≤ T u
n ≤ T t
T l
n
dl ≤ dt ≤ du
s,n ≤ T u
s,n ≤ T t
T l
s,n
0 − (cid:0)1 − dt(cid:1) T t
i − dtT t
T t
i − T t
T t
s ≥ 0

n ≥ 0

(cid:1)

(129)

(130)

(131)
(132)
(133)

(134)
(135)

(136)

(137)
(138)

where mt is the mass ﬂow rate, T t
the air put out by the chiller, T t

i is the internal duct temperature, T t

s,n is the temperature of the air supplied to the zone, T t

s is the temperature of
n is the

18

temperature of the zone, and dt is the damper position. All of these are control variables.
T t
0 is the external temperature (set to 25◦C in this instantiation of the model); β and γ are
scalar parameters that capture the room thermal properties. Other quantities listed in the
problem description are parameters that are not aﬀected by any adversarial perturbations.
See Appendix B for more details. The fan, heater, and chiller power consumption levels at
each time step are

νhcpmt (cid:0)T t

i − dtT t

(cid:0)mt(cid:1)2

θ1mt + θ2
0 − (cid:0)1 − dt(cid:1) T t
n
νccpmt (cid:0)T t
i − T t
s

(cid:1) νncpmt (cid:0)T t
(cid:1)

s,n − T t
s

(cid:1)

(139)

(140)

(141)

respectively. In this model, the static pressure is almost constant, and thus we omit it from
the fan component of the model. The static attack manipulates the defender perception of
β and γ. The attacker goal is to maximize power consumption over the entire time horizon
given that the defender observes ˆβ = β + ∆β and ˆγ = γ + ∆γ and the attacker is constrained
by

(cid:34)(cid:18) ∆β
β

1
2

(cid:19)2

+

(cid:18)∆γ
γ

(cid:19)2(cid:35)

≤ δmax

(142)

subject to the defender optimization of the original baseline problem. Because β and γ are of
diﬀerent magnitudes, using relative perturbations, not absolute ones, avoids some potential
problems. We also highlight the previously mentioned diﬀerences between the perceived and
actual state variables values. For example, the true zone temperature, T t
n, and the defender
perception of the zone temperature, ˆT t
n, will evolve according to the equations, respectively,

T t
n = (1 − γ) T t−1
n = (1 − ˆγ) ˆT t−1
ˆT t

n + βmt (cid:0)T t
s,n − T t
n
n + ˆβmt (cid:16)
s,n − ˆT t
T t

n

(cid:1) + γT t
(cid:17)

+ ˆγT t

0 + Qt
n
0 + Qt
n

(143)

(144)

the defender’s perception of T t

There will be a similar discrepancy between T t

i . The dynamic attack manipulates
0 so that ˆT t
0)2 ≤ ∆Tmax. As in the
static parameter manipulation case, the defender will misperceive both T t
i . The full
formulations for the static and dynamic manipulation problems are provided in Appendix
B.

n and T t

0 and 1
2

0 + ∆T t

0 = T t

(∆T t

(cid:80)
t

i and ˆT t

4 Computational Implementation

The speciﬁc calculations to turn each hypergame problem into a tractable nonlinear program
(NLP) are provided in Appendices A and B. We summarize our general approach here.
Each hypergame produces a multi-level optimization problem. To solve this, we write the

19

optimality conditions of the lower level problems as complementarity conditions. In the case
of the fan optimization, we can transform these complementarity conditions into equality
constraints and then solve the resulting problem as an NLP. For the HVAC problem, we
cannot do this, and this leaves us with a Mathematical Program with Equilibrium Constraints
(MPEC) [22]. We can solve the MPEC as a series of NLPs by relaxing the complementarity
constraints and penalizing the relaxation with a progressively increasing weight. For the work
described in this paper, this was both reliable and eﬃcient. To implement our approach, we
derived the necessary optimality conditions by hand, coded up the NLPs in MATLAB [23],
and solved the NLPs using fmincon.

5 Results

5.1 Fan Optimization

Table 1: Objective Function Manipulation Results (δθ,max = 0.1)

Case
Baseline
True Manipulation
Perception Manipulation

m
2.06 3.85
2.02 3.94
2.29 3.38
Faulty Defender Anticipation 1.95 4.16

p

∆θ1
-
0.150
-0.090
-

Double-Bluﬀ Manipulation

1.89 4.42 0.00684

∆θ2
-
0.303
-0.411
-
0.259

∆θ3
-
0.292
0.151
-
-0.358

Power
13.97
16.68
14.26 (12.42)
14.08 (14.71)
14.30 (13.76)

Table 1 shows the results for the attacker manipulation of the objective function param-
eters; power consumption values in parentheses indicate the power usage perceived by the
defender where it diﬀers from the actual usage. Manipulating the true θi values produced a
notable increase in power consumption compared with the baseline. Manipulating defender
perceptions, though, proved less eﬀective. For example, when the attacker manipulated the
perceptions of an unsuspecting defender (Perception Manipulation), the gap between the per-
ceived and actual power usage was noticeable, but the actual increase in power relative to
the baseline case was small. Similarly, if the defender erroneously thought that the attacker
was manipulating the perceived values of θi (Faulty Defender Anticipation), the true power
usage was almost identical to the baseline case, though the perceived power consumption
was somewhat higher.

When manipulating the defender’s perceptions, the attacker got the defender to increase
m and decrease p (relative to the baseline case) by decreasing the perceived value of θ1 and
θ2 (∆θ1 < 0, ∆θ2 < 0) and increasing the perceived value of θ3 (∆θ3 > 0). This approach
is more beneﬁcial for the attacker than decreasing m and increasing p because the objective
is quadratic in m but only linear in p. In the double-bluﬀ situation, however, the defender
expects the attacker to employ this optimal strategy, and so the attacker does the exact
opposite (i.e., encourages the defender to increase p and decrease m), which provides a slight
additional beneﬁt over the simple manipulation case.

Fig. 1 shows the ‘Perception Manipulation’ case and why it produces so little payoﬀ for
the attacker. There, we see how the perceived objective function contours are essentially

20

Figure 1: Visualization of ‘Perception Manipulation’ attack.

a rotated version of the original objective function contours. That rotation, produced by
changes in the relative magnitudes of the θi parameters, produces a perceived (i.e., false)
optimum point that is noticeably diﬀerent from the true optimum point. However, even
a signiﬁcant diﬀerence in the solution location does not necessarily translate to a large
diﬀerence in the true objective function value because neither the constraint nor the objective
function contours have large curvatures near the true optimum – most of the translation
between the two points is parallel to the contours of the true objective function.

Manipulating constraints gave the attacker more options than manipulating the objective
function parameters. As Table 2 shows, constraint manipulation was also much more eﬀective
as an attacker strategy. For example, when the attacker attempted to maximize power
consumption against a defender who did not believe an attack was underway (Power Max,
Normal), the attacker was able to increase power consumption by almost 30% compared
with the baseline. Attempting to maximize the constraint violation (Break System, Normal)
resulted in a signiﬁcant level of violation, too.

In this case, there were also major consequences for wrongly anticipating an attack.
Anticipating a power maximization attack when there was no attack resulted in a worse
constraint violation than when the attacker was deliberately trying to break the system.
Conversely, anticipating a ‘break system’ attack when the actual attack was a ‘power max’
attack led to an increase in power consumption of almost 60% compared with the baseline.
Note that in these false anticipations, the attacker is assuming that the defender is just
playing normally (i.e., the attacker is not taking advantage of the defender’s mistake). The
double-bluﬀ strategies did not provide much beneﬁt to the attacker, though.

Table 3 also shows the perturbations used by the attacker. We can see that the attacker
strategies for maximizing power consumption and breaking the system are almost exactly
mirror opposites, which makes sense. The double-bluﬀ strategies are not that much diﬀerent

21

Table 2: Constraint Manipulation Results (δc,max = 0.1)

Defender Belief m

p

Normal
Normal
Power Max

Attacker Action
No Attack
Power Max
No Attack
No Attack
Break System
Power Max
Break System
Power Max (Double-Bluﬀ)

2.06 3.85
2.59 4.22
1.57 3.37
Break System 2.59 2.24
1.17 2.78
Break System 3.16 4.53
1.58 3.36
2.16 3.94
Break System (Double-Bluﬀ) Break System 2.05 3.87

Normal
Power Max

Power Max

Power Violation
13.97
17.76
10.79
17.76
8.11
22.21
10.79
14.71
13.97

-
-
4.92
-
4.85
-
2.20
0.406
0.003

Table 3: Constraint Manipulation Results (δc,max = 0.1)

Attacker Action
Power Max
Break System
Power Max
Break System
Power Max (Double-Bluﬀ)

∆cr
∆cp
Defender Belief ∆cm
0.301
0.316
0.097
-0.285 -0.137 -0.316
0.316
0.097
-0.285 -0.137 -0.316
0.000
0.157
0.419
Break System (Double-Bluﬀ) Break System -0.295 -0.113 -0.316

Normal
Power Max

Normal
Power Max

Break System 0.301

than the regular strategies that they correspond to, though, so it is not surprising that
the double-bluﬀ approach is not very eﬀective. Switching attack modes would be a better
option if the defender is anticipating an attack, and though we did not calculate this here,
it would be possible to calculate an optimal attack for one mode given that the defender
is expecting the other mode. Given how the two modes produce almost exactly opposite
attacker strategies, the attacker strategy would likely be quite similar to the same attack
mode employed against an unsuspecting defender.

In general, changes in constraint parameters may result in larger objective function
changes than changes in objective function parameters for two reasons. Firstly, the changes
in constraints will be multiplied by the dual variables (Lagrange or Kuhn-Tucker) associ-
ated with those constraints to produce a ﬁnal change in the objective function. Secondly,
changing constraint values may result in the active set at the optimum also changing, and
that could produce large, nonlinear changes in the objective function. All in all, this likely
makes constraint manipulation a much more attractive target for a would-be attacker than
objective function manipulation.

5.2 Single-Zone HVAC Control

In the baseline case, and for all of the adversarial perturbations, mt and dt were both at their
lower bounds for the entire optimization. Fig. 2 shows the defender strategy in more detail
for diﬀerent optimization horizon lengths. There, we see that the defender essentially allows
the zone to evolve without manipulation until the last time step. Because T t
n, this

0 > T t

22

Figure 2: Baseline temperature results.

s = T t

means that the zone warms over time, but because γ is very small, this happens slowly. At
the last time step, the defender then chills the zone back to the initial temperature. We can
see this in the sudden drop in T t
s at the end of each time horizon; note that the optimization
produces T t
s,n for each optimization. This general behaviour is seen when the attacker
manipulates defender perceptions, too. The longer the optimization time horizon, the larger
the drop in T t
If the length of the time horizon were increased
suﬃciently, eventually the system would require multiple steps of cooling, because T t
s would
hit its lower bound. T t
n never hit its upper bound, but if it did, this would also require
additional cooling prior to the end of the optimization horizon.

s at the last time step.

Table 4: Static Parameter Manipulation Results (δmax = 0.1)

Baseline Power
Actual Power
Defender Perceived Power
∆β
∆γ
λmean

5-step
14.76
15.08
15.00

20-step
58.77
60.95
59.80

10-step
29.48
30.27
29.97
-1.81e-3 -1.84e-3 -1.94e-3
9.74e-6
1.52e-5
1.64e-5
383
370
367

Table 4 shows that manipulating the defender’s perception of β and γ resulted in small
power increases, relative to the baseline, and small discrepancies between the actual and
perceived power use. The perturbations themselves also change slightly as the length of the
time horizon changes; there is a greater emphasis on ∆β as the time horizon gets longer. In
this model, β essentially measures how hard it is to change the zone temperature with the
HVAC system. Setting ∆β < 0 makes the defender think that the zone is harder to adjust
than it actually is. The γ parameter then captures the heat transfer between the zone and
the outside environment. Setting ∆γ > 0 makes the defender think that there is more heat

23

transfer than there actually is. All of this combines to increase the amount of cooling that
the defender thinks is necessary at the end. The ∆T plots in Figs. 3a and 3b show this kind
of behaviour: the defender thinks that the temperatures are higher than they actually are
and therefore overcompensates at the end. This overcompensation leads to an increase in
power use and a ﬁnal T t

n value that is actually slightly lower than it should be.

Next, we can look at the λmean values given in Table 4. λmean is the average of the
Lagrange multipliers associated with (144) and therefore provides a measure of how the ∆β
and ∆γ perturbations get multiplied. This value increases as the time horizon lengthens,
which makes sense: as the time horizon lengthens, the importance of the thermal evolution
process increases. An attacker perturbing β and γ would want this value to be as large
(positive or negative) as possible.

Table 5: Dynamic Attack Results (∆Tmax = 0.1n for n-step problem)

Baseline Power
Actual Power
Defender Perceived Power
λmean

5-step 10-step 20-step
58.77
29.48
14.76
65.68
32.85
16.35
62.27
31.20
15.58
216
218
219

Table 6: Power Consumption Comparisons relative to Baseline (%)

Static Attack (Perceived)
Static Attack (Actual)
Dynamic Attack (Perceived)
Dynamic Attack (Actual)

5-step 10-step 20-step
1.7
2.7
5.8
11.4

1.6
2.2
5.6
10.1

1.8
3.7
6.0
11.8

Table 5 shows that manipulating T t

0 provided a much larger increase in power consump-
tion as well as a larger diﬀerence between the perceived and actual power consumption.
λmean is also much smaller, and these phenomena are related. The static parameters could
only aﬀect the power consumption indirectly through the temperature evolution equation.
T t
0, however, shows up in the objective function and another constraint in addition to the
temperature evolution equation, so increasing λmean becomes less important. In this case,
misperceptions of T t
i and T t
n become smaller (see Figs. 3a and 3b) and less important to
the attacker. Instead, the attacker uses ∆T t
i , and
thus the defender ends up engaging the heater (because T t
n > 0 even
though ˆT t
n = 0) as well as the chiller. The perturbations themselves
follow a clear pattern, as shown in Fig. 4. They increase very slightly over time until the
last time step, at which point they drop to nearly zero. The last step is less valuable to the
attacker because there are no more thermal evolution steps left in the optimization at that
point. Table 6 provides an overall summary of the power consumption results. Generally
speaking, the relative payoﬀ for the attacker increases with the length of the time horizon.
The actual power consumed in the static attack scenario, relative to the baseline, is roughly

0 > 0 to get the defender to increase T t

0 − (1 − dt) ˆT t

0 − (1 − dt) T t

i − dt ˆT t

i − dtT t

24

(a) Static attack.

(b) Dynamic attack.

Figure 3: Temperature deviations, ∆T = (Ttrue − Tperceived).

25

Figure 4: Dynamic parameter manipulation temperature perturbations.

proportional to the length of the time horizon, but the other three cases in Table 6 all seem
to plateau.

6 Discussion

6.1 Stuxnet-like Attacks and Hypergames

In this paper, we showed examples of how an attacker with knowledge of the system in
question could manipulate the optimization processes of that system. These problems were
relatively small, but they were suﬃcient to show how the analysis works. Hypergames are
about strategic interactions when there are misperceptions and/or information asymmetries.
In this case, we were able to show how those asymmetries or misperceptions could aﬀect
system performance. For example, getting the defender to respond to a non-existent threat
could actually prove to be a very eﬀective attacker strategy. Conversely, it is possible for
the defender system to have a natural robustness to perturbations (though that was not the
case in these test problems). We could consider more complex interactions, and we intend to
do so in future work, but that future work will need to build upon the basics outlined here.
When we look at Stuxnet as a motivating example for this work, we can see that there are
many similarities as well as some key diﬀerences between Stuxnet and the cases considered
here. In both Stuxnet and our case studies, the attacker employed limited deviations to avoid
detection; we modelled this using the concept of an attacker budget. Both also involved fake
sensor signals (∆T t
0) and manipulated calibration values (∆θ, ∆c, ∆β, ∆γ). Our examples
each had two diﬀerent kinds of attack modes, and for the fan optimization, there were two
diﬀerent attack objectives for one of the modes, but these all involved negatively impacting
the defender’s control system in some way. Finally, Stuxnet and the attacks considered in
this paper all utilized deep knowledge of an automated decision-making system to determine
how to perform the attack.

26

There are two primary sets of diﬀerences between this paper’s case studies and Stuxnet.
Firstly, to the best of our knowledge, Stuxnet was not optimization-based, and the centrifuge
control systems did not employ optimal control. As such, the decision-making processes for
both the attacker and the defender were diﬀerent than in our paper. Secondly, Stuxnet
actually overrode the control signals and software to manipulate the centrifuges [2], whereas
our attacks only altered sensor and calibration data. If we were trying to model the Stuxnet
attack itself, these discrepancies would be problematic. Given the more general nature of our
investigation here, though, this is less of an issue. Moreover, the key similarities identiﬁed
above are ones we believe to be relevant to a wide range of control systems that might be
threatened by cyber attacks in general and APTs in particular.

6.2 Scalability Considerations

A big question in applying these techniques to real-world problems is scalability. These
problems were relatively small; even the 20-step HVAC problem had only 120 variables (six
per time step) in the baseline problem. How easy would it be to propagate the optimality
conditions and solve the resulting MPECs for larger systems? The answer has two parts.
If those optimality conditions
Firstly, there is the question of the optimality conditions.
are necessary but not suﬃcient, as in general continuous NLP problems, propagating the
optimality conditions to turn the multi-level optimization into an MPEC may run into
diﬃculties; multiple optima would be one example of this. That being said, the single-
zone HVAC system presented here was a nonconvex problem, and it had no such problems.
If there are more than two levels to the optimization, that can also cause diﬃculties, as the
optimization conditions from lower levels compound. This then leads into the question of
tractability. Adding the dual variables of lower level optimizations to the problem description
in order to solve the system as an MPEC can greatly increase the number of variables
involved; having multiple levels may exacerbate the issue. However, it is sometimes possible
to simplify the optimality conditions and thereby remove some of the dual variables (as
was done for the fan optimization problem). The NLP sequential relaxation of the MPEC
also scales well and handles the complementarity constraints eﬃciently. On the whole,
the scalability of this approach will depend on the problem in question and how many
levels of (mis)perception are of interest. Hypergames where the individual players’ games
are diﬀerentiable, convex optimization problems are likely to have the greatest amount of
success with this approach. Problems with known or constant active constraint sets will also
generally be more amenable to the multi-level optimizations than problems with active sets
that change.

6.3 Future Work

Some authors writing on Stuxnet suggest the use of heuristics to identify attacks [4, 24]. One
area of future work would be to take existing research on learning in repeated hypergames
[21, 25] and apply it to this context. For this, we would consider the defender’s ability to
detect attacks as well as the attacker’s behaviour when the non-detection constraint is en-
dogenous rather than exogenous; the attacker budget imposed here would be an example of
an exogenous detection constraint. Another area of interest would be the defender’s decision-

27

making more generally. Given the possibility of attack and the potential consequences (as
calculated in this paper), how should a defender respond if an attack is undetectable before-
hand? Hypergame results here should enable us to to evaluate and prescribe control policies
more broadly. Finally, we intend to extend this work to larger, real-world systems. Working
on such systems may then also involve more complicated attacker manipulations, but we
anticipate being able to use the same techniques demonstrated here.

7 Conclusions

In this paper, we showed how hypergames can be extended to situations with continuous
and time-varying variables. That extension allowed us to consider the eﬀects of adversarial
perturbations in an optimal control context, which can give us insights into the control
aspects of a Stuxnet-like attack. Manipulating constraints can be a more eﬀective attacker
strategy than directly manipulating objective function parameters; our analytical results
showed why we would expect this to be true more generally. Moreover, the attacker need
not change the underlying system in any way to attack successfully – it may be suﬃcient
to deceive the defender controlling the system. It is possible to scale our approach up to
larger systems, but the ability to do so will depend on the characteristics of the system in
question, and we identiﬁed several characteristics that will make larger systems amenable to
hypergame analysis.

References

[1] A. Nourian and S. Madnick, “A systems theoretic approach to the security threats
in cyber physical systems applied to stuxnet,” IEEE Transactions on Dependable and
Secure Computing, vol. 15, no. 1, pp. 2–13, 2018.

[2] N. Falliere, L. O. Murchu, and E. Chien, “W32. stuxnet dossier,” White paper, Symantec

Corp., Security Response, vol. 5, no. 6, p. 29, 2011.

[3] G. Howser and B. McMillin, “A modal model of stuxnet attacks on cyber-physical sys-
tems: A matter of trust,” in 2014 Eighth International Conference on Software Security
and Reliability (SERE), pp. 225–234, IEEE, 2014.

[4] S. Karnouskos, “Stuxnet worm impact on industrial cyber-physical system security,” in
IECON 2011-37th Annual Conference on IEEE Industrial Electronics Society, pp. 4490–
4494, IEEE, 2011.

[5] A. Roth, “The economist as engineer: Game theory, experimentation, and computation
as tools for design economics,” Econometrica, vol. 70, no. 4, pp. 1341–1378, 2002.

[6] T. Sandler, “Terrorism & game theory,” Simulation & Gaming, vol. 34, no. 3, pp. 319–

337, 2003.

[7] P. G. Bennett, “Hypergames: developing a model of conﬂict,” Futures, vol. 12, no. 6,

pp. 489–507, 1980.

28

[8] N. S. Kovach, A. S. Gibson, and G. B. Lamont, “Hypergame theory: a model for conﬂict,

misperception, and deception,” Game Theory, vol. 2015, 2015.

[9] C. N. Gutierrez, S. Bagchi, H. Mohammed, and J. Avery, “Modeling deception in in-
formation security as a hypergame–a primer,” in Proceedings of the 16th Annual Infor-
mation Security Symposium, p. 41, CERIAS-Purdue University, 2015.

[10] D. A. Novikov and A. G. Chkhartishvili, Reﬂexion and control: mathematical models.

CRC Press, 2014.

[11] J. S´akovics, “Games of incomplete information without common knowledge priors,”

Theory and decision, vol. 50, no. 4, pp. 347–366, 2001.

[12] C. F. Camerer, T.-H. Ho, and J.-K. Chong, “A cognitive hierarchy model of games,”

The Quarterly Journal of Economics, vol. 119, no. 3, pp. 861–898, 2004.

[13] D. O. Stahl and P. W. Wilson, “On players’ models of other players: Theory and
experimental evidence,” Games and Economic Behavior, vol. 10, no. 1, pp. 218 – 254,
1995.

[14] Y. Sasaki, “preservation of misperceptions–stability analysis of hypergames,” in Pro-
ceedings of the 52nd Annual Meeting of the ISSS-2008, Madison, Wisconsin, vol. 3,
2008.

[15] N. Okada, K. W. Hipel, and Y. Oka, “Hypergame analysis of the Lake Biwa conﬂict,”

Water Resources Research, vol. 21, no. 7, pp. 917–926, 1985.

[16] I. Graham, F. O’Doherty, A. McKinnon, and L. Baxter, “Hypergame analysis of the sta-
bility of relationships between computerbased logistics systems,” International Journal
of Production Economics, vol. 26, no. 1-3, pp. 303–310, 1992.

[17] J. T. House and G. Cybenko, “Hypergame theory applied to cyber attack and de-
fense,” in Sensors, and Command, Control, Communications, and Intelligence (C3I)
Technologies for Homeland Security and Homeland Defense IX, vol. 7666, p. 766604,
International Society for Optics and Photonics, 2010.

[18] T. Kanazawa, T. Ushio, and T. Yamasaki, “Replicator dynamics of evolutionary hyper-
games,” IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and
Humans, vol. 37, no. 1, pp. 132–138, 2007.

[19] Y. Sasaki and K. Kijima, “Hypergames and bayesian games: A theoretical comparison
of the models of games with incomplete information,” Journal of Systems Science and
Complexity, vol. 25, no. 4, pp. 720–735, 2012.

[20] Y. Sasaki and K. Kijima, “Hierarchical hypergames and bayesian games: A general-
ization of the theoretical comparison of hypergames and bayesian games considering
hierarchy of perceptions,” Journal of Systems Science and Complexity, vol. 29, no. 1,
pp. 187–201, 2016.

29

[21] S. Takahashi, N. Hinago, T. Inohara, and B. Nakano, “Evolutionary approach to three-
person hypergame situation,” in Systems, Man, and Cybernetics, 1999. IEEE SMC’99
Conference Proceedings. 1999 IEEE International Conference on, vol. 4, pp. 254–259,
IEEE, 1999.

[22] C. Ruiz, A. J. Conejo, J. D. Fuller, S. A. Gabriel, and B. F. Hobbs, “A tutorial review
of complementarity models for decision-making in energy markets,” EURO Journal on
Decision Processes, vol. 2, no. 1-2, pp. 91–120, 2014.

[23] MATLAB, version 9.2.0 (R2017a). Natick, Massachusetts: The MathWorks Inc., 2017.

[24] B. Bencs´ath, G. P´ek, L. Butty´an, and M. Felegyhazi, “The cousins of stuxnet: Duqu,

ﬂame, and gauss,” Future Internet, vol. 4, no. 4, pp. 971–1003, 2012.

[25] B. Gharesifard and J. Cort´es, “Evolution of the perception about the opponent in hyper-
games,” in Decision and Control (CDC), 2010 49th IEEE Conference on, pp. 1076–1081,
IEEE, 2010.

A Static Fan Optimization Calculations

A.1 Baseline Problem

The baseline defender optimization is

min
m,p

θ1m + θ2m2 + θ3p

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

(145)

(146)

Note that we include the 1/2 factor in the constraint to cancel out factors of 2 that
appear when taking the derivative of that constraint. The objective function and inequality
constraint are both convex functions, so the optimization is a convex problem and the KKT
conditions are necessary and suﬃcient to deﬁne problem optima. If we deﬁne the Lagrangian
as L and use λ as the dual variable associated with the inequality constraint, we get the
following optimality conditions:

∂L
∂m

= θ1 + 2θ2m + (m − cm) λ = 0

∂L
∂p

= θ3 + (p − cp) λ = 0

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) λ = 0

(147)

(148)

(149)

For these equations to be satisﬁed, λ (cid:54)= 0. Since λ ≥ 0, this ensures that p < cp.
Moreover, if cr is suﬃciently small, m > 0, and thus m < cm. We can then get rid of λ by
substitution, and we are left with

30

(p − cp) (θ1 + 2θ2m) − (m − cm) θ3 = 0
(cid:2)(m − cm)2 + (p − cp)2 − c2

(cid:3) = 0

r

1
2

(150)

(151)

A.2 Objective Function Manipulation

A.2.1 Attacker Manipulates True/Physical Properties and Defender Knows

The min-max problem is

min
m,p

max
∆θi

(θ1 + ∆θ1) m + (θ2 + ∆θ2) m2 + (θ3 + ∆θ3) p

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

1
2

(cid:88)

i

∆θ2

i ≤ δθ,max

(152)

(153)

(154)

We can use the attacker’s KKT conditions to transform the min-max problem into a pure
optimization problem. Deﬁne L as the Lagrangian and σ as the dual variable associated with
the attacker budget constraint. Then

∂L
∂∆θ1
∂L
∂∆θ2
∂L
∂∆θ3

= m − σ∆θ1 = 0 ⇒ ∆θ1 =

= m2 − σ∆θ2 = 0 ⇒ ∆θ2 =

= p − σ∆θ3 = 0 ⇒ ∆θ1 =

1
σ
1
σ
1
σ

m

m2

p

(155)

(156)

(157)

For ﬁnite ∆θi, we require σ (cid:54)= 0. Since we know, by deﬁnition, that σ ≥ 0, then σ > 0.

We can therefore parameterize the attacker’s decisions in terms of τ = 1/σ:

min
m,p

max
τ

(θ1 + mτ ) m + (cid:0)θ2 + m2τ (cid:1) m2 + (θ3 + pτ ) p
1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2
1
2

τ 2 (cid:0)m2 + m4 + p2(cid:1) ≤ δθ,max

(cid:3) ≤ 0

r

Given that the last constraint will always be active (σ (cid:54)= 0), we can solve for τ :

(cid:20)

τ =

2δθ,max
m2 + m4 + p2

(cid:21) 1

2

31

(158)

(159)

(160)

(161)

We are then left with the following defender optimization:

θ1m + θ2m2 + θ3p + (cid:2)2δθ,max

(cid:0)m2 + m4 + p2(cid:1)(cid:3) 1

2

min
m,p

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

A.2.2 Attacker Manipulates Defender Perceptions, Defender Unaware

The attacker is solving the problem

θ1m + θ2m2 + θ3p

∆θ2

i ≤ δθ,max

max
∆θi
1
2

(cid:88)

i

subject to the defender optimization

min
m,p

(θ1 + ∆θ1) m + (θ2 + ∆θ2) m2 + (θ3 + ∆θ3) p

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

(162)

(163)

(164)

(165)

(166)

(167)

The optimality conditions of the defender problem are the same as in the baseline case

except that we replace θi with ˆθi = θi + ∆θi:

(cid:17)
(cid:16)ˆθ1 + 2ˆθ2m

− (m − cm) ˆθ3 = 0

(cid:2)(m − cm)2 + (p − cp)2 − c2

(cid:3) = 0

r

(p − cp)
1
2

This then results in the optimization problem for the attacker:

max
∆θi,m,p

θ1m + θ2m2 + θ3p

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) = 0 (ρ)

1
2

(cid:88)

∆θ2

i ≤ δθ,max (µ)

1
2

i

(p − cp)

(cid:16)ˆθ1 + 2ˆθ2m

(cid:17)

− (m − cm) ˆθ3 = 0 (λ)

(168)

(169)

(170)

(171)

(172)

(173)

where the dual variable for each constraint is shown in brackets next to that constraint. We
can solve this directly as an optimization, but we can also use the optimality conditions to
calculate ∆θi. Deﬁne L as the optimization’s Lagrangian. Then

32

If we use τ = λ/µ, we get

∂L
∂∆θ1
∂L
∂∆θ2
∂L
∂∆θ3

= −µ∆θ1 + (p − cp) λ = 0

= −µ∆θ2 + 2 (p − cp) mλ = 0

= −µ∆θ3 − (m − cm) λ = 0

∆θ1 = τ (p − cp)

∆θ2 = 2τ (p − cp) m
∆θ3 = −τ (m − cm)

(cid:34)

τ =

2δθ,max
(p − cp)2 + (2 (p − cp) m)2 + (m − cm)2

(cid:35) 1

2

(cid:34)

=

(cid:35) 1

2

2δθ,max
4 (p − cp)2 m2 + c2
r

(174)

(175)

(176)

(177)

(178)
(179)

(180)

We know that µ > 0, but in principle λ could be positive or negative. When we solve the
optimization directly (using the parameter values speciﬁed in the main body of the paper),
we ﬁnd that λ > 0. Given that p − cp < 0 and m − cm < 0, this means that the attacker
decreases the defender-perceived values of θ1 and θ2 while raising the defender-perceived
value of θ3. This in turn results in an increased value of m and a decreased value of p
(relative to the unperturbed case). The case where λ < 0 would correspond to the opposite
behaviour.

Both options produce local maxima, for the attacker, but in general, we would expect the
λ > 0 option to produce a higher payoﬀ: the objective is linear in p but quadratic in m, so
increasing m would often provide a greater payoﬀ than increasing p. We do not have a proof
delineating when this is the case, but we would expect this not to be the case only for small
values of θ1 and θ2 (relative to θ3). For the cm, cp, cr, and δθ,max values considered in this
paper, we can empirically verify that for θ1 ∈ [0.5, 3.5], θ2 ∈ [0.5, 3.5], and θ3 ∈ [0.5, 3.5], the
λ > 0 option provides a larger attacker payoﬀ. This domain encompasses all of the true θi
values that an attacker could manipulate to produce the ˆθi values observed by the defender.
Since the defender knows the attacker budget, if the defender believes that the attacker is
attempting to perturb θi, the defender can know that the attacker is employing the attack
where τ > 0.

A.2.3 Attacker Manipulates Defender Perceptions, Defender is Aware

Using the results from the previous section, the defender can reverse engineer the true θi
values from the perceived values ˆθi if the defender is aware of an attack. The defender
believes that ˆθi has been calculated by an attacker solving the problem in Appendix A.2.2.
Therefore the defender’s optimization is

33

(cid:17)

m +

(cid:16)ˆθ2 − ∆θ2

(cid:17)

m2 +

(cid:16)ˆθ3 − ∆θ3

(cid:17)

p

min
m,p

(cid:16)ˆθ1 − ∆θ1
1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

(cid:3) ≤ 0

r

∆θ1 = τ (ˆp − cp)
∆θ2 = 2τ (ˆp − cp) ˆm
∆θ3 = −τ ( ˆm − cm)
(cid:34)

(cid:35) 1

2

τ =

2δθ,max
4 (ˆp − cp)2 ˆm2 + c2
r
(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2

(cid:3) = 0

r

(cid:17)
(cid:16)ˆθ1 + 2ˆθ2 ˆm

− ( ˆm − cm) ˆθ3 = 0

1
2
(ˆp − cp)

(181)

(182)

(183)
(184)
(185)

(186)

(187)

(188)

where ˆm and ˆp are the decision variable values that the defender thinks that the attacker
expects the defender to employ. Note that it is possible to solve

1
2
(ˆp − cp)

(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2

(cid:3) = 0

r

(cid:17)
(cid:16)ˆθ1 + 2ˆθ2 ˆm

− ( ˆm − cm) ˆθ3 = 0

(189)

(190)

once with the known ˆθi values and then use those to calculate ∆θi – these do not depend
on m or p. Once this calculation has been performed, we are left with the original convex
defender optimization problem.

A.2.4 Attacker Manipulates Defender Perceptions, Defender is Aware, At-

tacker Knows that Defender is Aware

This problem leads us to a multi-level optimization problem. At level 1, we have the attacker
optimization

max
∆θi
1
2

θ1m + θ2m2 + θ3p

(cid:88)

∆θi ≤ δθ,max

i

ˆθi = θi + ∆θi

(191)

(192)

(193)

At the next level (level 2), we have the defender optimization. The defender performs his
optimization based on the belief that the values he perceives, ˆθi has been perturbed by an
attacker solving the problem in Appendix A.2.2. Therefore the defender’s optimization is

34

min
m,p

(cid:16)ˆθ1 − ∆ˆθ1
1
2

(cid:17)

m +

(cid:16)ˆθ2 − ∆ˆθ2

(cid:17)

m2 +

(cid:16)ˆθ3 − ∆ˆθ3

(cid:17)

p

(cid:2)(m − cm)2 + (p − cp)2 − c2

(cid:3) ≤ 0

r

∆θ1 = τ (ˆp − cp)
∆θ2 = 2τ (ˆp − cp) ˆm
∆θ3 = −τ ( ˆm − cm)
(cid:34)

(cid:35) 1

2

τ =

2δθ,max
4 (ˆp − cp)2 ˆm2 + c2
r
(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2

(cid:3) = 0

r

(cid:17)
(cid:16)ˆθ1 + 2ˆθ2 ˆm

− ( ˆm − cm) ˆθ3 = 0

1
2
(ˆp − cp)

The defender’s optimality conditions (level 2) are then:

1
2

(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2

r

(cid:3) = 0

(ˆp − cp) [(θ1 + ∆θ1) + 2 (θ2 + ∆θ2) ˆm] − ( ˆm − cm) (θ3 + ∆θ3) = 0

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) = 0

(p − cp) [(θ1 + ∆θ1 − τ (ˆp − cp)) + 2 (θ2 + ∆θ2 − 2 (ˆp − cp) ˆmτ ) m]
− (m − cm) (θ3 + ∆θ3 + τ ( ˆm − cm)) = 0

(cid:34)

τ =

2δθ,max
4 (ˆp − cp)2 ˆm2 + c2
r

(cid:35) 1

2

The attacker’s optimization (level 1) is then

θ1m + θ2m2 + θ3p

∆θi ≤ δθ,max

max
∆θi
1
2

(cid:88)

i

1
2

(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2

r

(cid:3) = 0

(ˆp − cp) [(θ1 + ∆θ1) + 2 (θ2 + ∆θ2) ˆm] − ( ˆm − cm) (θ3 + ∆θ3) = 0
(cid:2)(m − cm)2 + (p − cp)2 − c2

(cid:3) = 0

r

1
2

35

(194)

(195)

(196)
(197)
(198)

(199)

(200)

(201)

(202)

(203)

(204)

(205)

(206)

(207)

(208)

(209)

(210)

(211)

(p − cp) [(θ1 + ∆θ1 − τ (ˆp − cp)) + 2 (θ2 + ∆θ2 − 2 (ˆp − cp) ˆmτ ) m]
− (m − cm) (θ3 + ∆θ3 + τ ( ˆm − cm)) = 0

(cid:34)

τ =

2δθ,max
4 (ˆp − cp)2 ˆm2 + c2
r

(cid:35) 1

2

(212)

(213)

The attacker optimization may not be convex, but each ∆θi value corresponds to a single

( ˆm, ˆp, m, p) tuple. We can show by via a sequential analysis. The equations

1
2

(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2

r

(cid:3) = 0

(ˆp − cp) [(θ1 + ∆θ1) + 2 (θ2 + ∆θ2) ˆm] − ( ˆm − cm) (θ3 + ∆θ3) = 0

(214)

(215)

deﬁne a unique solution ( ˆm, ˆp) to an instance of the unaware defender optimization. By the
logic employed in the previous section, we can calculate ∆ˆθi values from that, which then in
turn deﬁnes m and p as the unique solution to

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) = 0

(p − cp) [(θ1 + ∆θ1 − τ (ˆp − cp)) + 2 (θ2 + ∆θ2 − 2 (ˆp − cp) ˆmτ ) m]
− (m − cm) (θ3 + ∆θ3 + τ ( ˆm − cm)) = 0

(cid:34)

τ =

2δθ,max
4 (ˆp − cp)2 ˆm2 + c2
r

(cid:35) 1

2

(216)

(217)

(218)

A.3 Constraint Manipulation

In this section, for the sake of simplicity, we assume that the attacker is only manipulat-
ing the constraint parameters (not the objective function parameters). These constraint
manipulations take the form of

ˆcm = cm + ∆cm
ˆcp = cp + ∆cp
ˆcr = cr − ∆cr

The attacker is also subject to an attack budget of

1
2

(cid:0)∆c2

m + ∆c2

p + ∆c2
r

(cid:1) =

1
2

(cid:88)

i

∆c2

i ≤ δc,max

(219)
(220)
(221)

(222)

36

A.3.1 Attacker Manipulates Defender Perceptions, Defender Unaware

The attacker’s optimization is

θ1m + θ2m2 + θ3p

∆c2

i ≤ δc,max

max
∆ci
1
2

(cid:88)

i

subject to the defender optimization

min
m,p

θ1m + θ2m2 + θ3p

(cid:2)(m − cm − ∆cm)2 + (p − cp − ∆cp)2 − (cr − ∆cr)2(cid:3) ≤ 0

1
2

The defender optimality conditions are

(p − cp − ∆cp) (θ1 + 2θ2m) − (m − cm − ∆cm) θ3 = 0
(cid:2)(m − cm − ∆cm)2 + (p − cp − ∆cp)2 − (cr − ∆cr)2(cid:3) = 0

1
2

and we are left with the attacker optimization

θ1m + θ2m2 + θ3p

∆c2

i ≤ δc,max

max
δi
1
2

(cid:88)

i

(p − cp − ∆cp) (θ1 + 2θ2m) − (m − cm − ∆cm) θ3 = 0
(cid:2)(m − cm − ∆cm)2 + (p − cp − ∆cp)2 − (cr − ∆cr)2(cid:3) = 0

1
2

A.3.2 Attacker Manipulates Defender Perceptions, Defender is Aware

The defender’s optimization is

min
m,p

θ1m + θ2m2 + θ3p

(cid:2)(m − ˆcm + ∆cm)2 + (p − ˆcp + ∆cp)2 − (ˆcr + ∆cr)2(cid:3) ≤ 0

1
2

(223)

(224)

(225)

(226)

(227)

(228)

(229)

(230)

(231)

(232)

(233)

(234)

where ˆcm, ˆcp, and ˆcr are the quantities that the defender perceives (which the defender
believes to have been manipulated by the attacker). The true parameter values are unknown,
but the ∆ci values are calculated by solving the attacker problem from the previous section:

37

θ1 ˆm + θ2 ˆm2 + θ3 ˆp

∆c2

i ≤ δc,max (µ)

max
ˆm,ˆp,∆ci
1
(cid:88)
2

i

(ˆp − cp − ∆cp) (θ1 + 2θ2 ˆm) − ( ˆm − cm − ∆cm) θ3 = 0 (σ)
(cid:2)( ˆm − cm − ∆cm)2 + (ˆp − cp − ∆cp)2 − (cr − ∆cr)2(cid:3) = 0 (ρ)

1
2

(235)

(236)

(237)

(238)

where the dual variables for each constraint are shown in brackets beside the equation Deﬁne
L as the Lagrangian for this problem. The optimality conditions are then

∂L
∂ ˆm

= θ1 + 2θ2 ˆm − σ (2 (ˆp − cp − δp) θ2 − θ3) − ρ ( ˆm − cm − δm) = 0

∂L
∂ ˆp

= θ3 − σ (θ1 + 2θ2 ˆm) − ρ (ˆp − cp − δp) = 0

∂L
∂δm

= −µδm − σθ3 + ρ ( ˆm − cm − δm) = 0

= −µδp + σ (θ1 + 2θ2 ˆm) + ρ (ˆp − cp − δp) = 0

∂L
∂δp

∂L
∂δr

= −µδr − ρ (cr − δr) = 0

If we take the ﬁrst two equations and simplify using ˆci, we get

θ1 + 2θ2 ˆm − σ (2 (ˆp − ˆcp) θ2 − θ3) − ρ ( ˆm − ˆcm) = 0
θ3 − σ (θ1 + 2θ2 ˆm) − ρ (ˆp − ˆcp) = 0

We can set this up to solve for σ and ρ:

(cid:20) 2 (ˆp − ˆcp) θ2 − θ3
θ1 + 2θ2 ˆm

ˆm − ˆcm
ˆp − ˆcp

(cid:21) (cid:26) σ
ρ

(cid:27)

=

(cid:26) θ1 + 2θ2 ˆm
θ3

(cid:27)

(239)

(240)

(241)

(242)

(243)

(244)
(245)

(246)

We can get closed-form expressions for σ and ρ by solving this 2x2 system analytically,

and we can then use these expressions to calculate our ∆ci values in terms of τ = 1/µ:

∆cp = τ θ3
∆cm = τ [ρ ( ˆm − ˆcm) − σθ3]
∆cr = −τ ρˆcr

(247)
(248)
(249)

The constraint on the sum of squared ∆ci values then lets us calculate a value for τ :

38

τ 2 (cid:2)θ2

3 + (ρ ( ˆm − ˆcm) − σθ3)2 + ρ2ˆc2

r

(cid:20)

τ =

2δc,max
3 + [ρ ( ˆm − ˆcm) − σθ3]2 + ρ2ˆc2
θ2

r

(cid:3) = 2δc,max
(cid:21) 1

2

(250)

(251)

and thus we have closed-form expressions for the ∆ci values that can then be plugged back
into the original defender optimization without needing to know the true ci values. Note
that the defender can perform these calculations without knowing the true ci ahead of time
– it is suﬃcient to know ˆci.

A.3.3 Attacker Manipulates Defender Perceptions, Defender is Aware, At-

tacker Knows that Defender is Aware

The attacker’s optimization is

θ1m + θ2m2 + θ3p

∆c2

i ≤ δc,max

max
∆ci
1
2

(cid:88)

i

ˆcm = cm + ∆cm
ˆcp = cp + ∆cp
ˆcr = cr − ∆cr

(252)

(253)

(254)
(255)
(256)

subject to the defender optimization from the previous section. The optimality conditions
for the defender’s optimization are

(p − ˆcp + ∆ˆcp) (θ1 + 2θ2m) − (m − ˆcm + ∆ˆcm) θ3 = 0
(cid:2)(m − ˆcm + ∆ˆcm)2 + (p − ˆcp + ∆ˆcp)2 − (ˆcr + ∆ˆcr)2(cid:3) = 0

1
2

where

∆ˆcp = τ θ3
∆ˆcm = τ [ρ ( ˆm − ˆcm) − σθ3]
∆ˆcr = −τ ρˆcr

(cid:20)

τ =

2δc,max
3 + [ρ ( ˆm − ˆcm) − σθ3]2 + ρ2ˆc2
θ2

r

(cid:21) 1

2

(cid:20) 2 (ˆp − ˆcp) θ2 − θ3
θ1 + 2θ2 ˆm

ˆm − ˆcm
ˆp − ˆcp

(cid:21) (cid:26) σ
ρ

(cid:27)

=

(cid:26) θ1 + 2θ2 ˆm
θ3

(cid:27)

(ˆp − ˆcp) (θ1 + 2θ2 ˆm) − ( ˆm − ˆcm) θ3 = 0
(cid:2)( ˆm − ˆcm)2 + (ˆp − ˆcp)2 − ˆc2

(cid:3) = 0

r

1
2

39

(257)

(258)

(259)
(260)
(261)

(262)

(263)

(264)

(265)

A.3.4 Attacker Manipulates Defender to Break System, Defender is Unaware

In this case, the attacker wants to cause the defender to deviate maximally from the con-
(cid:3) ≤ 0 in the interest of causing a catastrophic failure.
straint 1
2
The attacker’s optimization is

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

max
∆ci

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3)

1
2

(cid:88)

i

∆c2

i ≤ δc,max

(p − cp − ∆cp) (θ1 + 2θ2m) − (m − cm − ∆cm) θ3 = 0
(cid:2)(m − cm − ∆cm)2 + (p − cp − ∆cp)2 − (cr − ∆cr)2(cid:3) = 0

1
2

A.3.5 Attacker Manipulates Defender to Break System, Defender Knows

The defender’s optimization is

min θ1m + θ2m2 + θ3p
(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

1
2

(266)

(267)

(268)

(269)

(270)

(271)

where the defender only observes ˆci and needs to calculate ∆ci. The defender knows that
the attacker is solving the problem

max
∆ci

1
2

(cid:3)

(cid:2)( ˆm − cm)2 + (ˆp − cp)2 − c2
1
2

i ≤ δc,max (µ)

∆c2

(cid:88)

r

i

(ˆp − cp − ∆cp) (θ1 + 2θ2 ˆm) − ( ˆm − cm − ∆cm) θ3 = 0 (σ)
(cid:2)( ˆm − cm − ∆cm)2 + (ˆp − cp − ∆cp)2 − (cr − ∆cr)2(cid:3) = 0 (ρ)

1
2

(272)

(273)

(274)

(275)

where the dual variables for each constraint are shown in brackets beside their respective
equations. If we deﬁne L as the Lagrangian for that problem, the optimality conditions for
this problem are

40

∂L
∂ ˆm

= ˆm − cm + σ (2θ2 (ˆp − ˆcp) + θ3) − ρ ( ˆm − ˆcm) = 0

∂L
∂ ˆp

= ˆp − cp − σ (θ1 + 2θ2 ˆm) − ρ (ˆp − ˆcp) = 0

∂L
∂∆cm

= −µ∆cm − σθ3 + ρ ( ˆm − ˆcm) = 0

∂L
∂∆cp

= −µ∆cp + σ (θ1 + 2θ2 ˆm) + ρ (ˆp − ˆcp) = 0

∂L
∂∆cr

= −µ∆cr − ρˆcr = 0

We can solve for σ, ρ, and τ = 1/µ to get expressions for ∆ci.

∆cm = τ ( ˆm − cm + 2θ2σ (ˆp − ˆcp))
∆cp = τ (ˆp − cp)
∆cr = −τ ρˆcr

(cid:27)

(cid:26) σ
ρ

=

1
−θ3 (ˆp − ˆcp) − ( ˆm − ˆcm) (θ1 + 2θ2 ˆm)

(cid:20) − (ˆp − ˆcp)
θ1 + 2θ2 ˆm

ˆm − ˆcm
θ3

(cid:21) (cid:26) ˆm − cm
ˆp − cp

(cid:27)

(cid:34)

τ =

2δc,max
( ˆm − cm + 2θ2σ (ˆp − ˆcp))2 + (ˆp − cp)2 + ρ2ˆc2
r

(cid:35) 1

2

(276)

(277)

(278)

(279)

(280)

(281)
(282)
(283)

(284)

(285)

Unlike the result in the power maximization case, solving for ∆ci requires knowing ci,

not just ˆci. The defender then has to solve

min θ1m + θ2m2 + θ3p
(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3) ≤ 0

1
2

ˆcm = cm + τ ( ˆm − cm + 2θ2σ (ˆp − ˆcp))
ˆcp = cp + τ (ˆp − cp)
ˆcr = cr + τ ρˆcr

(cid:27)

(cid:26) σ
ρ

=

1
−θ3 (ˆp − ˆcp) − ( ˆm − ˆcm) (θ1 + 2θ2 ˆm)

(cid:20) − (ˆp − ˆcp)
θ1 + 2θ2 ˆm

ˆm − ˆcm
θ3

(cid:21) (cid:26) ˆm − cm
ˆp − cp

(cid:27)

(cid:34)

τ =

(cid:35) 1

2

2δc,max
( ˆm − cm + 2θ2σ (ˆp − ˆcp))2 + (ˆp − cp)2 + ρ2ˆc2
r
(θ1 + 2θ2 ˆm) (ˆp − ˆcp) − ( ˆm − ˆcm) θ3 = 0
(cid:2)( ˆm − ˆcm)2 + (ˆp − ˆcp)2 − ˆc2

(cid:3) = 0

r

1
2

41

(286)

(287)

(288)
(289)
(290)

(291)

(292)

(293)

(294)

where ˆci is known. This is actually less complicated than it appears, though. We can
calculate ˆm and ˆp only knowing θi and ˆci (which are ﬁxed) and using

(θ1 + 2θ2 ˆm) (ˆp − ˆcp) − ( ˆm − ˆcm) θ3 = 0
(cid:2)( ˆm − ˆcm)2 + (ˆp − ˆcp)2 − ˆc2

(cid:3) = 0

r

1
2

(295)

(296)

With ˆm and ˆp known, σ and ρ are just linear functions of ci, and we have another closed-
form expression for τ . We are then left with three equations in three unknowns: solving
(288)-(290) for ci. These unknowns, moreover, do not depend on m or p.

A.4 Attacker Manipulates Defender to Break System, Defender

Knows, Attacker Knows that Defender is Aware

The attacker optimization is

max

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3)

1
2

(cid:88)

i

∆c2

i ≤ δc,max

ˆcm = cm + ∆cm
ˆcp = cp + ∆cp
ˆcr = cr − ∆cr

subject to the defender optimization

where

min θ1m + θ2m2 + θ3p
(cid:2)(m − ˜cm)2 + (p − ˜cp)2 − ˜c2

r

(cid:3) ≤ 0

1
2

ˆcm = ˜cm + τ ( ˆm − ˜cm + 2θ2σ (ˆp − ˆcp))
ˆcp = ˜cp + τ (ˆp − ˜cp)
ˆcr = ˜cr + τ ρˆcr

(cid:27)

(cid:26) σ
ρ

=

1
−θ3 (ˆp − ˆcp) − ( ˆm − ˆcm) (θ1 + 2θ2 ˆm)

(cid:20) − (ˆp − ˆcp)
θ1 + 2θ2 ˆm

ˆm − ˆcm
θ3

(cid:21) (cid:26) ˆm − cm
ˆp − cp

(cid:27)

(cid:34)

τ =

(cid:35) 1

2

2δc,max
( ˆm − cm + 2θ2σ (ˆp − ˆcp))2 + (ˆp − cp)2 + ρ2ˆc2
r
(θ1 + 2θ2 ˆm) (ˆp − ˆcp) − ( ˆm − ˆcm) θ3 = 0
(cid:2)( ˆm − ˆcm)2 + (ˆp − ˆcp)2 − ˆc2

(cid:3) = 0

r

1
2

42

(297)

(298)

(299)
(300)
(301)

(302)

(303)

(304)
(305)
(306)

(307)

(308)

(309)

(310)

The quantities with tildes on them indicate that these values are what the defender
believes to be the true values. Given that (304)-(310) not depend on m or p, the defender
optimality conditions are

(θ1 + 2θ2m) (p − ˜cp) − (m − ˜cm) θ3 = 0
(cid:2)(m − ˜cm)2 + (p − ˜cp)2 − ˜c2

(cid:3) = 0

r

1
2

The full attacker optimization is then

max

1
2

(cid:2)(m − cm)2 + (p − cp)2 − c2

r

(cid:3)

1
2

(cid:88)

i

∆c2

i ≤ δc,max

ˆcm = cm + ∆cm
ˆcp = cp + ∆cp
ˆcr = cr − ∆cr
ˆcm = ˜cm + τ ( ˆm − ˜cm + 2θ2σ (ˆp − ˆcp))
ˆcp = ˜cp + τ (ˆp − ˜cp)
ˆcr = ˜cr + τ ρˆcr

(cid:27)

(cid:26) σ
ρ

=

1
−θ3 (ˆp − ˆcp) − ( ˆm − ˆcm) (θ1 + 2θ2 ˆm)

(cid:20) − (ˆp − ˆcp)
θ1 + 2θ2 ˆm

ˆm − ˆcm
θ3

(cid:21) (cid:26) ˆm − cm
ˆp − cp

(cid:27)

(cid:34)

τ =

(cid:35) 1

2

2δc,max
( ˆm − cm + 2θ2σ (ˆp − ˆcp))2 + (ˆp − cp)2 + ρ2ˆc2
r
(θ1 + 2θ2 ˆm) (ˆp − ˆcp) − ( ˆm − ˆcm) θ3 = 0
(cid:2)( ˆm − ˆcm)2 + (ˆp − ˆcp)2 − ˆc2

(cid:3) = 0

r

1
2

(311)

(312)

(313)

(314)

(315)
(316)
(317)
(318)
(319)
(320)

(321)

(322)

(323)

(324)

B Single-Zone HVAC Control Calculations

B.1 Baseline Problem

The baseline problem is a power minimization problem for a heater, chiller, and fan together
aﬀecting a single zone of interest:

43

min

τ
(cid:88)

(cid:104)

t=1

+cpνnmt (cid:0)T t

−T t

n + (1 − γ) T t−1

θ1mt + θ2

(cid:0)mt(cid:1)2 + νhcpmt (cid:0)T t

i − dtT t

0 − (cid:0)1 − dt(cid:1) T t

n

(cid:1)

i − T t
s
0 + Qt

(cid:1)(cid:3)
n = 0 (cid:0)λt(cid:1)

(cid:1) + νccpmt (cid:0)T t
(cid:1) + γT t
s,n − T t
n
n = 0 (µτ )
(cid:1)

(cid:1)

m,u
(cid:1)

m,l

s,n − T t
s
n + βmt (cid:0)T t
n − T 0
T τ
mt − ml ≥ 0 (cid:0)σt
mu − mt ≥ 0 (cid:0)σt
s ≥ 0 (cid:0)σt
s,n − T t
T t
s
n ≥ 0 (cid:0)σt
(cid:1)
n − T l
T t
l
(cid:1)
n ≥ (cid:0)σt
n − T t
T u
dt − dl ≥ 0 (cid:0)σt
du − dt ≥ 0 (cid:0)σt
s,n ≥ 0 (cid:0)σt
s,n − T l
T t
s,n ≥ 0 (cid:0)σt
s,n − T t
T u
0 − (cid:0)1 − dt(cid:1) T t
T t
i − dtT t
s ≥ 0 (cid:0)σt
i − T t
T t

d,u

d,l

(cid:1)

is

u

(cid:1)

(cid:1)

snl

snu

(cid:1)
n ≥ 0 (cid:0)σt
(cid:1)

(cid:1)

in

(325)

(326)

(327)

(328)

(329)

(330)

(331)

(332)

(333)

(334)

(335)

(336)

(337)

(338)

where the quantities in brackets after each equation are the dual variables corresponding to
those equations. Descriptions of the model variables and the model parameters are given in
Tables 7 and 8, respectively. This is a single-zone version of a multi-zone HVAC model. The
goal of the system is to manage the temperature in that single zone. To do this, it takes in
a mixture of air from the zone and from the environment, heats that air (if necessary) at a
central heating unit, cools the air (if necessary) with a chiller, and uses a fan to send the air
through HVAC ducting. In a multi-zone model, there would be a local heater for each zone
to provide any zone-speciﬁc heating; for our single-zone model, we retain the local heater in
the interest of maintaining the same model structure.

Table 7: HVAC Control Variables

Quantity Description

mt
T t
i
dt
T t
n
T t
s,n
T t
s

Mass ﬂow rate
Temperature of air put out by central heating unit
Fraction of HVAC input air coming from environment
Zone temperature
Temperature of air supplied to zone
Output air temperature of chiller

All of the other parameters with l or u in them correspond to lower or upper bounds on

their respective variables.

44

Table 8: HVAC Model Parameters

Quantity
θ1
θ2
νh,νn,νc
cp
T t
0
β
γ
Qt
n
τ
dl,du
ml,mu
n,T u
T l
n
s,n,T u
T l
s,n

Description
Value
Fan power consumption parameter
0.1
Fan power consumption parameter
0.1
Heater and chiller eﬃciencies
0.99
Speciﬁc heat of air
1
Environment air temperature at time t
25
Parameter describing temperature evolution
0.0045
Parameter describing temperature evolution
8.4e-6
Thermal load at time t
0
Length of optimization horizon
varies
Lower and upper bounds on dt
0.2, 0.5
3.93, 13.1 Lower and upper bounds on mt
21.1, 23.9 Lower and upper bounds on T t
n
Lower and upper bounds on T t
12.7, 35

s,n

i − dtT t

0 − (1 − dt) T t

At each time step t, the fan consumes power θ1mt + θ2 (mt)2 to move air through the
i − T t
system, the chiller consumes power νccpmt (T t
s ), and the central heating unit consumes
power νhcpmt (T t
s,n − T t
s
Most of the constraints are variable upper and lower bounds or physical constraints on the
system (e.g., the temperature evolution of the room, the heater outputting air that is at least
as warm as the air it takes in). However, there is an endpoint constraint T τ
n that is
essentially a design constraint: at the end of the optimization horizon, the zone needs to be
at the same temperature it was at the beginning of the horizon. If we deﬁne the Lagrangian
for this problem as L, the optimality conditions for this problem are

n) and the zonal heater consumes power cpνnmt (cid:0)T t

n = T 0

(cid:1).

(cid:0)T t

s,n − T t
s

(cid:1) + νccp

(cid:0)T t

i − T t
s

(cid:1)

∂L
∂mt = θ1 + 2θ2mt + νhcp

(cid:0)T t
i − dtT t
+λtβ (cid:0)T t

0 − (cid:0)1 − dt(cid:1) T t
s,n − T t
n

(cid:1) + σt

n
m,u − σt

(cid:1) + cpνn

∂L

∂dt = νhcpmt (cid:0)T t

n − T t
0

(cid:1) + σt

d,u − σt

d,l − σt
in

n − T t
0

(cid:1) = 0

= νhcpmt (cid:0)dt − 1(cid:1) + λt (cid:0)−1 − βmt(cid:1) − δtτ µτ

m,l = 0
(cid:0)T t

∂L
∂T t
n
+ (1 − γ) λt+1 − σt
in
∂L
∂T t

s,n

(cid:0)dt − 1(cid:1) − σt

l + σt

u = 0

= cpνnmt + λtβmt − σt

s − σt

snl + σt

snu = 0

∂L
∂T t
s
∂L
∂T t
i

= −cpνnmt − νccpmt + σt

s + σt

is = 0

= νhcpmt + νccpmt − σt

in − σt

is = 0

(339)

(340)

(341)

(342)

(343)

(344)

plus the optimization problem constraints listed above; note that δtτ , is a Kronecker delta,
so it is 1 if t = τ and 0 otherwise. These derivative conditions can simplify down to

45

0 ≤ θ1 + 2θ2mt + νhcp

i − dtT t

(cid:0)T t
+λtβ (cid:0)T t

0 − (cid:0)1 − dt(cid:1) T t
(cid:1) + σt

(cid:1) + cpνn
m,u ⊥ mt − ml ≥ 0

(cid:0)T t

n

s,n − T t
s

s,n − T t
n
0 ≤ σt
0 ≤ dt − dl ⊥ (cid:0)σis − νccpmt(cid:1) (cid:0)T t
0 ≤ σt
0 ≤ (cid:0)σis − νccpmt(cid:1) (cid:0)dt − 1(cid:1) − λt (cid:0)1 + βmt(cid:1) − δtτ µτ + (1 − γ) λt+1 + σt

m,u ⊥ mu − mt ≥ 0
n − T t
0
d,u ⊥ du − dt ≥ 0

(cid:1) + σt

d,u ≥ 0

(cid:1) + νccp

(cid:0)T t

i − T t
s

(cid:1)

u ⊥ T t

n − T l

n ≥ 0

0 ≤ σt

u ⊥ T u

n − T t
0 ≤ λtβmt + σis − νccpmt + σt
0 ≤ σt

snu ⊥ T u

n ≥ 0
snu ⊥ T t
s,n ≥ 0

s,n − T t

s,n − T l

s,n ≥ 0

0 ≤ νhcpmt − (cid:0)σis − νccpmt(cid:1) ⊥ T t

i − dtT t
0 ≤ νncpmt − (cid:0)σis − νccpmt(cid:1) ⊥ T t
s ≥ 0

is ⊥ T t

i − T t

0 ≤ σt

0 − (cid:0)1 − dt(cid:1) T t
s,n − T t

s ≥ 0

n ≥ 0

(345)

(346)

(347)

(348)

(349)

(350)

(351)

(352)

(353)

(354)

(355)

where x ⊥ y indicate the complementarity constraint xy = 0. In general, this problem is
nonconvex. However, the parameter values speciﬁed above result in mt = ml and dt = dl for
all t. If we take these variables as constants, then the objective function and constraints are
all linear in the model variables, so the optimization is a linear program, and the optimality
conditions are then necessary and suﬃcient. More generally, as long as the fan consumes
most of the power (as it does in this case), it will be advantageous to keep mt as small as
possible, and as long as the environment temperature diﬀers from the zone temperature, the
controller will always be incentivized to minimize the amount of outside air brought in (air
that will have to be heated or cooled to reach the zone temperature).

B.2 Attacker Manipulates Defender Perceptions of Static Param-

eters

The attacker can manipulate the defender’s perception of β and γ to maximize power con-
sumption over the entire time horizon:

τ
(cid:88)

(cid:104)

max

θ1mt + 2θ2

(cid:0)mt(cid:1)2 + νhcpmt (cid:0)T t

i − dtT t

0 − (cid:0)1 − dt(cid:1) T t

n

t=1

+cpνnmt (cid:0)T t
n = (1 − γ) T t−1
T t

(cid:1) + νccpmt (cid:0)T t
s,n − T t
n

i − T t
s
(cid:1) + γT t
0 + Qt
n

(cid:1)(cid:3)

s,n − T t
s
n + βmt (cid:0)T t
ˆβ = β + ∆β
ˆγ = γ + ∆γ

(cid:1)

(356)

(357)

(358)
(359)

46

(cid:19)2(cid:35)

1
2

(cid:19)2

(cid:34)(cid:18) ∆β
β
s ⊥ T t
i − T t

(cid:18) ∆γ
γ
i − dtT t

+

0 ≤ T t

− δmax ≤ 0

0 − (cid:0)1 − dt(cid:1) T t

n ≥ 0

(360)

(361)

subject to the defender optimality conditions

0 ≤ θ1 + 2θ2mt + νhcp

(cid:0)T t

s,n − T t
s

(cid:1) + νccp

(cid:16) ˆT t

i − T t
s

(cid:17)

0 ≤ (cid:0)σis − νccpmt(cid:1) (cid:0)dt − 1(cid:1) − λt (cid:16)

− δtτ µτ + (1 − ˆγ) λt+1 + σt

u ⊥ ˆT t

n − T l

n ≥ 0

m,u ⊥ mt − ml ≥ 0

(cid:17)

(cid:16) ˆT t

n

n

+ cpνn

+ σt

+λt ˆβ

i − dtT t
(cid:16)

0 − (cid:0)1 − dt(cid:1) ˆT t
(cid:17)
s,n − ˆT t
T t
0 ≤ σt
0 ≤ dt − dl ⊥ (cid:0)σis − νccpmt(cid:1) (cid:16) ˆT t
0 ≤ σt
1 + ˆβmt(cid:17)

m,u ⊥ mu − mt ≥ 0
n − T t
0
d,u ⊥ du − dt ≥ 0

(cid:17)

+ σt

d,u ≥ 0

0 ≤ σt

u ⊥ T u

n − ˆT t
0 ≤ λt ˆβmt + σis − νccpmt + σt
0 ≤ σt

snu ⊥ T u

n ≥ 0
snu ⊥ T t
s,n ≥ 0

s,n − T t

s,n − T l

s,n ≥ 0

0 ≤ νhcpmt − (cid:0)σis − νccpmt(cid:1) ⊥ ˆT t

i − dtT t
0 ≤ νncpmt − (cid:0)σis − νccpmt(cid:1) ⊥ T t
s ≥ 0
(cid:17)

is ⊥ ˆT t
i − T t
0 ≤ σt
n + ˆβmt (cid:16)
s,n − ˆT t
T t
ˆT T
n − T 0

n + (1 − ˆγ) ˆT t−1

n = 0

n

− ˆT t

0 − (cid:0)1 − dt(cid:1) ˆT t
s,n − T t

s ≥ 0

n ≥ 0

+ ˆγT t

0 + Qt

n = 0

(362)

(363)

(364)

(365)

(366)

(367)

(368)

(369)

(370)

(371)

(372)

(373)

(374)

Note that the defender conditions are with respect to perceived/perturbed values, not
real values (hence the ˆ on certain quantities). The defender directly controls most of the
variables (e.g., mt, T t
n. These variables are essentially
functions of processes governed by other variables. As such, ˆT t
n are the defender’s
perceived values for these variables. The true equations governing the evolution of T t
n and
T t
i are, respectively,

s ) but does not directly control T t

i and ˆT t

i or T t

n = (1 − γ) T t−1
T t
i − T t
0 ≤ T t

n + βmt (cid:0)T t
i − dtT t
s ⊥ T t

(cid:1) + γT t
s,n − T t
n
0 − (cid:0)1 − dt(cid:1) T t

n

0 + Qt
n

(375)

(376)

The complementarity constraint ensures that T t
i
s , the defender spends energy to cool the air and if T t

(1 − dt) T t
n.
(1 − dt) T t
n, the defender spends energy to heat the air.

is the minimum of T t

i > T t

If T t

s and dtT t
i > dtT t

0 +
0 +

47

B.3 Attacker Manipulates Defender Perceptions of Time-Varying

Parameters

The attacker can also manipulate the defender’s perception of T t
sumption over the entire time horizon:

0 to maximize power con-

θ1mt + θ2

(cid:0)mt(cid:1)2 + νhcpmt (cid:0)T t

i − dtT t

0 − (cid:0)1 − dt(cid:1) T t

n

(cid:1)

max
∆T t
0

(cid:88)

(cid:104)

t

+cpνnmt (cid:0)T t

s,n − T t
s
(cid:88)
(cid:0)∆T t

(cid:1) + νccpmt (cid:0)T t
(cid:1)2 ≤ ∆Tmax

0

i − T t
s

(cid:1)(cid:3)

1
2

t
ˆT t
0 = T t
n + βmt (cid:0)T t
i − dtT t
s ⊥ T t

0 + ∆T t
0
(cid:1) + γT t
s,n − T t
n
0 − (cid:0)1 − dt(cid:1) T t

n = 0

0 + Qt
n ≥ 0

−T t

n + (1 − γ) T t−1
i − T t

0 ≤ T t

subject to the defender optimality conditions

n

(cid:16) ˆT t

+ cpνn

i − dt ˆT t
(cid:16)

0 ≤ θ1 + 2θ2mt + νhcp

ˆT T
n − T 0
n = 0
(cid:17)
0 − (cid:0)1 − dt(cid:1) ˆT t
(cid:17)
s,n − ˆT t
T t
0 ≤ σt
0 ≤ dt − dl ⊥ (cid:0)σis − νccpmt(cid:1) (cid:16) ˆT t
0 ≤ σt
0 ≤ (cid:0)σis − νccpmt(cid:1) (cid:0)dt − 1(cid:1) − λt (cid:0)1 + βmt(cid:1) − δtτ µτ + (1 − γ) λt+1 + σt

m,u ⊥ mu − mt ≥ 0
n − ˆT t
d,u ⊥ du − dt ≥ 0

m,u ⊥ mt − ml ≥ 0

s,n − T t
s

d,u ≥ 0

+λtβ

+ σt

+ σt

(cid:0)T t

(cid:17)

n

0

(cid:1) + νccp

(377)

(378)

(379)

(380)

(381)

(382)
(cid:17)

(383)

(384)

(385)

(386)

(cid:16) ˆT t

i − T t
s

u ⊥ ˆT t

n − T l

n ≥ 0

0 ≤ σt

u ⊥ T u

n − ˆT t
0 ≤ λtβmt + σis − νccpmt + σt
0 ≤ σt

snu ⊥ T u

n ≥ 0
snu ⊥ T t
s,n ≥ 0

s,n − T t

s,n − T l

s,n ≥ 0

0 ≤ νhcpmt − (cid:0)σis − νccpmt(cid:1) ⊥ ˆT t

i − dt ˆT t
0 ≤ νncpmt − (cid:0)σis − νccpmt(cid:1) ⊥ T t
s ≥ 0
(cid:17)

is ⊥ ˆT t
i − T t
0 ≤ σt
n + βmt (cid:16)
s,n − ˆT t
T t
ˆT T
n − T 0

n + (1 − γ) ˆT t−1

n = 0

n

− ˆT t

0 − (cid:0)1 − dt(cid:1) ˆT t
s,n − T t

s ≥ 0

n ≥ 0

+ γ ˆT t

0 + Qt

n = 0

(387)

(388)

(389)

(390)

(391)

(392)

(393)

(394)

(395)

48

