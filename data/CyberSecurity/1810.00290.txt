Noname manuscript No.
(will be inserted by the editor)

Cyber Insurance

Quanyan Zhu

9
1
0
2
c
e
D
8
2

]

Y
C
.
s
c
[

2
v
0
9
2
0
0
.
0
1
8
1
:
v
i
X
r
a

1 Introduction

Critical Infrastructures are increasingly dependent on the information and
communication technologies (ICTs) to sense, transmit, and fuse data for real-
time operations and control of the infrastructures. The heavy integration of
the ICTs has also brought many potential threat that can cause data privacy
breaches, availability of the services, and the cascading damages. The vulnera-
bilities in the ICT can arise not only from unintentional misconﬁguration and
mismanagement of the protocols and devices but also from the intentional in-
jection of the malware, spread of the worms, and the cyber attacks. Recent
cyber attacks on Iranian nuclear power plants and the Ukraine power grid
have also shown that the attacks are becoming increasingly sophisticated. For
example, advanced persistent threats (APTs) [11,22], such as Stuxnet, Flame,
and Duqu, can exploit zero-day vulnerabilities, leverage human errors and in-
sider threats, and move stealthily in the network before launching a successful
attack. These attacks are often diﬃcult to detect and prevent as they have
access to a suﬃcient amount of resources and are capable of staying in the
victim’s system for years.

Hence, cyber risks for infrastructures are of growing concerns. The cyber
risk will not only create cyber incidents including identity theft, cyber extor-
tion, and network disruption, but also can lead to the malfunction of the entire
infrastructure and its key services to users and customers. It becomes a crit-
ical issue for operators to safeguard infrastructures from the intentional and
unintentional actions that would inﬂict damage on the system. Conventional
countermeasures include installing intrusion detections, blacklisting malicious
hosts, ﬁltering/blocking traﬃc into the network. However, these methods can-
not guarantee perfect security and can be evaded by sophisticated adversaries
despite the advances in technologies. Therefore, cyber risks are inevitable and
it is essential to ﬁnd other means to mitigate the risks and impact.

New York University, Brooklyn, NY, 11201; Email: qz494@nyu.edu

 
 
 
 
 
 
2

Quanyan Zhu

Cyber insurance is an important tool in risk management to transfer risks
[46,45]. Complement to the technological solutions to cybersecurity, cyber in-
surance can mitigate the loss of the targeted system and increase the resiliency
of the victim by enabling quick ﬁnancial and system recovery from cyber inci-
dents. Such scheme is particularly helpful to small and medium size infrastruc-
ture systems that cannot aﬀord a signiﬁcant investment in cyber protection.
The market of cyber insurance is still in its infancy. U.S. penetration level
of the insured is less than 15%. Promisingly, the market is growing fast at a
30% annual growth rate since 2011. The key challenge with cyber insurance
lies in the diﬃculty to assess diﬀerent types of cyber risks and impact of the
cyber incidents that are launched by resourceful adversaries who are stealthy
and purposeful. The design of cyber insurance also needs to take into account
moral hazards and adverse selection problems. The insured tend to lack in
incentives to improve their security measures to safeguard against attacks. As
the nodes in the cyber space are increasingly connected, the unprotected cyber
risks can propagate to other uninsured nodes. With asymmetric information
of the insured, the insurer also has tendency to increase the premium rates for
higher risks, making the cyber insurance less aﬀordable to end users.

In this chapter, we aim to provide a baseline framework to understand the
interactions among the players in the cyber insurance market and leverage
it to design optimal cyber insurance for the infrastructure services. One key
application of the framework is to provide assurance to the infrastructure
managers and users and transfer their risks when the attack on power grid
fails to provide electric power to a food processing plant, when cloud servers
break down and fail to provide airline customer check-in information, and
when the trains collide due to the communication systems fail. In the examples
above, it is clear that the cyber insurance play a key role in mitigating the
cyber risks that interconnect the communications and information systems of
an infrastructure with their physical impact on the infrastructure or linked
infrastructures. The interdependencies among the infrastructures and their
operators and users can propagate the cyber risks and exacerbate the damages
on the critical infrastructures. To this end, the understanding of the cyber
insurance of interconnected players is the key to the holistic understanding of
the risk management of interdependent infrastructures.

This chapter will ﬁrst present a principal-agent game-theoretic model to
capture the interactions between one insurer and one user. The insurer is
deemed as the principal who does not have incomplete information about
user’s security policies. The user, which refers to the infrastructure opera-
tor or the customer, implements his local protection and pays a premium to
the insurer. The insurer designs an incentive compatible insurance mechanism
that includes the premium and the coverage policy, while the user determines
whether to participate in the insurance and his eﬀort to defend against at-
tacks. The chapter will also focus on an attack-aware cyber insurance model
by introducing the adversarial behaviors into the framework. The behavior of
an attacker determines the type of cyber threats, e.g. denial of service (DoS)
attacks, data breaches, phishing and spooﬁng. The distinction of threat types

Cyber Insurance

3

plays a role in determining the type of losses and the coverage policies. The
data breaches can lead to not only ﬁnancial losses but also damage of the
reputations. The coverage may only cover certain agreed percentage of the
ﬁnancial losses.

2 Background

The challenges of cyber security are not only technical issues but also eco-
nomic and policy issues [3]. Recently, the use of cyber insurance to enhance
the level of security in cyber-physical systems has been studied [19,20]. While
these works deal with externality eﬀects of cyber security in networks, few
of them take into account in the model the cyber attack from a malicious
adversary to distinguish from classical insurance models. In [26], the authors
have considered direct and indirect losses, respectively due to cyber attacks
and indirect infections from other nodes in the network. However, the cyber
attacks are taken as random inputs rather than a strategic adversary. The
moral hazard model in economics literature [12,13] deal with hidden actions
from an agent, and aims to address the question: How does a principal design
the agent’s wage contract to maximize his eﬀort? This framework is related to
insurance markets and has been used to model cyber insurance [6] as a solu-
tion for mitigating losses from cyber attacks. In addition, in [1], the authors
have studied a security investment problem in a network with externality ef-
fect. Each node determines his security investment level and competes with a
strategic attacker. Their model does not focus on the insurance policies and
hidden-action framework. In this work, we enrich the moral-hazard type of
economic frameworks by incorporating attack models, and provide a holistic
viewpoint towards cyber insurance and a systematic approach to design insur-
ance policies. The network eﬀect on security decision process has been studied
in [25]. The authors have considered a variation of the linear inﬂuence net-
works model in which each node represents a network company and directed
links model the positive or negative inﬂuence between neighbor nodes.

Game-theoretic models are natural frameworks to capture the adversar-
ial and defensive interactions between players [50,34,51, 23, 9,21,48,47,14,15].
Game theory can provide a quantitative measure of the quality of protection
with the concept of Nash equilibrium where both defender and an attacker
seek optimal strategies, and no one has an incentive to deviate unilaterally
from their equilibrium strategies despite their conﬂict for security objectives.
The equilibrium concept also provides a quantitative prediction of the secu-
rity outcomes of the scenario the game model captures. There are various
types of game models that can capture diﬀerent class of adversaries. For ex-
ample, games of incomplete information are suitable for understanding cyber
deception [28,47,14,27,29,51]; dynamic games are useful for modeling cyber-
physical system security [40,39,38,37,15,7, 23, 41]; and zerosum and Stackel-
berg games for security risk management [44, 42, 36,43,30,31]. In this work,
we build a zerosum game between an attacker and a defender to quantify the

4

Quanyan Zhu

cybersecurity risks associated with adversarial behaviors. This game model is
nested in the principle-agent game models to establish an integrated frame-
work that captures the defender, the attacker, and the insurer.

3 Three-Person Game Framework for Cyber Insurance

In this section, we introduce a principal-agent model for cyber insurance that
involve users and insurers. Users here can refer to an infrastructure operator
that manages cyber networks that face threats from an attacker, making users
vulnerable to data breaches, task failures, and severe ﬁnancial losses. The ob-
jective of the users is to ﬁnd an eﬃcient way to mitigate the loss due to the
cyber attacks. To this end, there are two main approaches. One is to deploy lo-
cal protections, such as ﬁrewalls and intrusion detection systems (IDSs) [33,4],
frequent change of passwords, timely software patching and proactive moving
target defenses [16]. These defense mechanisms can reduce the success rate of
the attacks, but cannot guarantee perfect network security for users. There are
still chances for the users to be hacked by the attackers. The other approach
is to adopt cyber-insurance. The users pay a premium fee so that the loss due
to cyber attacks can be compensated by the insurer. This mechanism provides
an additional layer of mitigation to reduce the loss further that the technical
solutions of the ﬁrst approach cannot prevent. To capture the two options in
our framework, we allow users to decide their protection levels as well as their
rational choice of participation in the insurance program.

Attackers are the adversaries who launch cyber-attacks, such as node cap-
ture attacks[35] and denial of services (DoS) attacks [17], to acquire private
data from users or cause disruptions of the network services. Hence, the ob-
jective of the attacker is to ﬁnd an eﬃcient attack strategy to inﬂict as much
damage to the users as possible. We use attack levels to represent diﬀerent at-
tack strategies to capture various types of attacks of diﬀerent levels of severity.
A higher attack level is more costly to launch, but it will create more severe
damage. Since the loss of the users not only depends on the attack strategies
but also insurance policies. The optimal strategy of the attacker will also be
inﬂuenced by the coverage levels of an insurance policy.

An insurer is a person or company that underwrites an insurance risk by
providing users an incentive compatible cyber-insurance policy that includes a
premium and the level of coverage. The premium is a subscription fee that is
paid by the users to participate in the insurance program while the coverage
level is the proportion of loss that will be compensated by the insurer as
a consequence of successful cyber attacks. The insurers have two objectives.
One is to make a proﬁt from providing the insurance, and the other one is to
reduce the average losses of the users, which is also directly related to the cost
of the insurer. An insurer’s problem is to determine the subscription fee and
the coverage levels of the insurance. Note that the average losses depend on
both users’ local protection levels and attackers’ attack levels. Moreover, the

Cyber Insurance

5

Fig. 1 Three-player game among user, attacker, and the insurer.

rational users will only enroll in the insurance when the average reduction in
the cost is higher than or equal to the premium he paid to the insurer.

The objectives of users, attackers, and insurers, and the eﬀects of their
actions are all intertwined. We use a 3-player game to capture the complex
interactions among the three parties. The conﬂicting objectives of a user and
an attacker can be captured by a local game at each node in which the user
determines a defense strategy while the adversary chooses an attack strategy.
The outcome of the local interactions at each node determines its cyber risk
and the cyber insurance is used as an additional method to further reduce the
loss due to the cyber risk. The insurers are the leaders or principals in the
framework who design insurance policies for the users while the users can be
viewed as followers or agents who determine their defense strategies under a
given insurance policy.

3.1 Attack-Aware Cyber Insurance

We ﬁrst formulate the game between the user and the attacker, then we de-
scribe the insurer’s problem under the equilibrium of the user and the at-
tacker’s game. An illustration of the cyber-insurance model is shown in Fig. 2.

6

Quanyan Zhu

Fig. 2 Illustration of the interactions between three players: The action pair (pu, pa) chosen
by the user and the attacker results in a risk level not directly observable by the insurer.
The insurer designs an insurance policy that includes a premium subscription fee and the
coverage level to cover part of the loss due to the cyber attack.

Let pu ∈ [0, 1] and pa ∈ [0, 1] denote the local protection level of the user and
the attack level of the attacker. On one hand, a large pu indicates a cautious
user while a small pu indicates that the user is reckless. A reckless user may
click on suspicious links of received spam emails, fail to patch the computer
system frequently, and leave cyber footprints for an adversary to acquire sys-
tem information. On the other hand, a large pa indicates a powerful attacker,
and a small pa indicates a powerless attacker. The abstraction of using pu
and pa captures the eﬀectiveness of a wide range of heterogeneous defense and
attack strategies without a ﬁne-grained modeling of individual mechanisms.
This will allow us to focus on the consequence of security issues and the choice
of a mechanism that induces the result.

The action pair of the user and the attacker (pu, pa) determines the risk
level of the user R ∈ R≥0. A larger pu and a smaller pa indicate a higher risk
level of the user. We use the following risk function r to denote the connections
between the user’s and the attacker’s actions and the risk level of the user.

Deﬁnition 1 Function r(pu, pa) : [0, 1]2 → R≥0 gives the risk level R of
the user with respect to the user’s local protection level pu and the attack’s
attack level pa. Moreover, it is assumed to be continuous on (0, 1]2, convex
and monotonically decreasing on pu ∈ [0, 1], and concave and monotonically
increasing in pa ∈ [0, 1].

Note that the monotonicity in pu ∈ [0, 1] indicates that a larger local protection
level of user leads to a smaller risk level of user while the monotonicity in
pa ∈ [0, 1] indicates that a larger attack level of attacker leads to a larger
risk level of user. Since r is convex on pu, the risk decreases smaller when
the user adopts larger local protection level. Since r is concave on pa, the risk
increases faster when the attacker conducts a higher attack level. Without loss
of generality, we use the following risk function,

r(pu, pa) = log

(cid:19)

+ 1

.

(cid:18) pa
pu

(1)

Cyber Insurance

7

Similar types of functions have also been widely used in jamming attacks in
wireless networks [21,2] and rate control problems [18,49]. Under the risk level
of R, the economic loss of the user can be represented as a random variable
X measured in dollars, which can be expressed as X = G(R, θ), where θ
is a random variable with probability density function g that captures the
uncertainties in the measurement or system parameters. For example, a data
breach due to the compromise of a server can be a consequence of low security
level at the user end. The magnitude of the loss depends on the content and the
signiﬁcance of the data, and the extent of the breach. The variations in these
parameters are captured by the random variable θ. Since the risks of being
attacked cannot be perfectly eliminated, the user can transfer the remaining
risks to the third party, the insurer, by paying a premium or subscription fee
T for a coverage of S(X) when he faces a loss of X, where S : R≥0 → R≥0 is
the payment function that reduces the loss of the user if he is insured. Thus,
the eﬀective loss ξ to the user becomes ξ = X − S(X).

Given the attacker’s action pa and the insurer’s coverage function S, the
user aims to minimize the average eﬀective loss by ﬁnding the optimal local
protection level p∗
u. Such objective can be captured by the following optimiza-
tion problem

min
pu∈[0,1]

E[H(ξ)] = E[H(X − S(X))],

(2)

where H : R≥0 → R≥0 is the loss function of the user, which is increasing on
ξ. Note that the expectation is taken with respect to the statistics of θ. The
subscription fee T is not included in this optimization problem, as the fee is a
constant decided by the insurer.

The loss function H(ξ) indicates the user’s risk propensity. A convex H(ξ)
indicates that the user is risk-averse, i.e., the user cares more about the risk,
while a concave H(ξ) indicates that the user is risk-taking, i.e., he cares more
about the cost, rather than the risk. A linear H(ξ) in ξ indicates that the user
is risk-neutral. In this paper, we consider a risk-averse user, and use a typical
risk-averse loss function that H(ξ) = eγξ with γ > 0, where γ indicates how
much the user cares about the loss.

Note that the cost function in (2) can be expressed explicitly as a function
of X. Thus, Problem (2) can be rewritten by taking expectations with respect
to the suﬃcient statistics of X. Let f be the probability density function of
X. Clearly, f is a transformation from the density function g (associated with
the random variable θ) under the mapping G. In addition, g also depends on
the action pair (pu, pa) through the risk variable R. Therefore, we can write
f (x|pu, pa) to capture the parameterization of the density function. Without
loss of generality, we assume that X follows an exponential distribution, i.e.,
X ∼ exp( 1
R ), where R := r(pu, pa) is the risk level of the user. The exponential
distribution has been widely used in risk and reliability analysis[24,10,5,8].

8

Quanyan Zhu

Thus the density function can be written as

f (x|pu, pa) =

1
R

e− 1

R x =

1
r(pu, pa)

e−

1

r(pu ,pa) x

=

1
log( pa
pu

+ 1)

−

e

log(

1
pa
pu

x

+1)

, ∀x ∈ R≥0.

The average amount of loss given actions pu and pa is E(X) = R = r(pu, pa) =
log( pa
+ 1). For small pu and large pa, the risk level of the user R tends to be
pu
large, which leads to a large average loss of the user. We further assume that
the insurance policy S(X) is linear in X, i.e., S(X) = sX, where s ∈ [0, 1]
indicates the coverage level of the insurance. Hence, the eﬀective loss is given
by ξ = (1 − s)X. The average eﬀective loss given the insurance coverage
level s and the action pair (pu, pa) is E(ξ) = E((1 − s)X) = (1 − s)E(X) =
(1 − s) log( pa
+ 1). When s is large, the eﬀective loss is small. As a result, we
pu
arrive at

(cid:90)

E[H(ξ)] :=

H(x − S(x))f (x|pu, pa)dx

(3)

xi∈R≥0
(cid:90) ∞

= 1
R

e[γ(1−s)− 1

R ]xdx

0

1
1−γ(1−s)R
1

1−γ(1−s) log( pa
pu

+1) .

=
=

The loss is ﬁnite when

γ(1 − s) −

1
R

< 0, i.e., 1 − γ(1 − s) log(

pa
pu

+ 1) > 0.

(4)

Otherwise, the loss will be inﬁnite, i.e., E[H(ξ)] → ∞. In this regime, no
insurance scheme can be found to mitigate the loss. Condition (4) gives a
feasible set of parameters under which cyber insurance is eﬀective and provides
a fundamental limit on the level of mitigation. Note that minimizing (3) is
equivalent as minimizing γ(1 − s) log( pa
+ 1) under the feasible equality (4).
pu
The user’s problem can be rewritten as follows:

Ju(pu, pa, s) := γ(1 − s)R = γ(1 − s) log( pa
pu

min
pu∈[0,1]
s.t. 1 − γ(1 − s) log( pa
pu

+ 1) > 0.

+ 1)

(5)

Problem (5) captures the user’s objective to minimize average eﬀective loss
given the attack level pa and the insurance coverage level s. On the other
hand, the attacker aims to ﬁnd the optimal attack level p∗
a that maximizes the
average loss of the user given user’s local protection level and insurer’s coverage
level s. Such conﬂicting interests of the user and the attacker constitutes a
zero-sum game, which takes the following minimax or max-min form,

max
min
pa∈[0,1]
pu∈[0,1]
s.t. (pu, pa) ∈ Su,a(s).

K(pu, pa, s)

or

min
max
pu∈[0,1]
pa∈[0,1]
s.t. (pu, pa) ∈ Su,a(s).

K(pu, pa, s)

(6)

Cyber Insurance

where

9

K(pu, pa, s) := γ(1−s)R+cupu−capa = γ(1−s) log(

pa
pu

+1)+cupu−capa, (7)

Su,a(s) :=

(cid:26)

(cid:12)
(cid:12)
(cid:12)1 − γ(1 − s) log(
(pu, pa)

pa
pu

(cid:27)

+ 1) > 0

.

(8)

The ﬁrst term of the objective function K captures the average eﬀective loss
given insurance coverage level s, the local protection level pu and the attack
level pa. The second and third terms indicate the cost of the user and the
attacker, respectively. cu ∈ R>0 is the cost parameter of the user. A larger cu
indicates that local protection is costly. ca ∈ R>0 denotes the cost parameter
of the attacker to conduct an attack level of pa. A larger cu indicates that a
cyber-attack is costly. Note that cu and ca can be interpreted as the market
price of local protections and cyber-attacks, and they are known by the insurer.
The constraint indicates the feasible set of the user. Note that if s, pu, and
pa are not feasible, K is taken to be an inﬁnite cost. Minimizing K(pu, pa, s)
captures the user’s objective to minimize the average eﬀective loss with the
most cost-eﬀective local protection level. Maximizing K(pu, pa, s) captures the
attacker’s objective to maximize the average eﬀective loss of the user with least
attack level. Note that the minimax form of (6) can be interpreted as a worst-
case solution for a user who uses the best security strategies by anticipating
the worst-case attack scenarios.

Furthermore, Problem (6) yields a saddle-point equilibrium (SPE) to the

insurance coverage level s which can be deﬁned as follows:

u, p∗

Deﬁnition 2 Let Su(s), Sa(s) and Su,a(s) be the action sets for the user
and the attacker given an insurance coverage level s. Then the strategy pair
(p∗
a) is a saddle-point equilibrium (SPE) of the zero-sum game deﬁned
by the triple Gz := (cid:104){U ser, Attacker}, {Su(s), Sa(s), Su,a(s)}, K(cid:105), if for all
pu ∈ Su(s), pa ∈ Sa(s), (pu, pa) ∈ Su,a(s),
u, p∗

a, s) ≤ K(pu, p∗

u, pa, s) ≤ K(p∗

K(p∗

a, s),

(9)

where K and Su,a(s) is the objective function and feasible set deﬁned in (7)
and (8).

The deﬁnition indicates that if a pair (p∗
a) satisﬁes (9), then it is a SPE of
the game between the user and the attacker to the insurer’s insurance policy.
Note that under a given insurance coverage level s, (p∗
a) must satisfy the
feasible constraint (4). Thus, we aim to look for a constrained SPE of the
zero-sum game with coupled constraints on the strategies of the players.

u, p∗

u, p∗

Proposition 1 Given an insurance coverage level s that satisﬁes

1 − γ(1 − s) log

(cid:19)

+ 1

> 0,

(cid:18) cu
ca

(10)

there exists a unique SPE of the zero-sum game deﬁned in Deﬁnition 2, given
by

u = γ(1−s)
p∗
cu+ca

, p∗

a = cuγ(1−s)
ca(cu+ca) .

(11)

10

Quanyan Zhu

Proposition 1 shows that the SPE of the zero-sum game between the user and
the attacker is related to the insurer’s policy s. Note that when s is large,
both the p∗
a is small, indicating that both the user and the attacker
will take weak actions. Moreover, we have the following observations regarding
the SPE.

u and p∗

Remark 1 (Peltzman Eﬀect) When the insure provides higher coverage level
s, the SPE of the user p∗
u tend to be smaller, i.e., the user takes a weaker local
protection. Such risky behavior of the user in response to insurance is usually
referred as Peltzman eﬀect [32].
Corollary 1 (Invariability of The SPE Ratio) The SPE satisﬁes p∗
=
a
p∗
u
cu
, i.e., the ratio of the actions of the user and the attacker is only related to
ca
cu and ca, and it is independent of the insurer’s policy s. In particular, when
cu = ca, p∗
=

= 1, i.e., the SPE becomes symmetric, as p∗

u = p∗

a = γ(1−s)
cu+ca

a
p∗
u
= γ(1−s)
2ca

.

γ(1−s)
2cu

Remark 2 (Constant Cost Determined SPE Risk) The user has a constant
saddle-point risk level R∗ = r(p∗
at the
equilibrium, which is determined by the costs of adopting protections and
launching attacks. The ratio is independent of coverage level s.

a) = log

(cid:16) p∗
a
p∗
u

(cid:16) cu
ca

u, p∗

= log

+ 1

+ 1

(cid:17)

(cid:17)

Corollary 2 At the saddle point, the average direct loss of the user is E(X) =
, the average eﬀective loss of the user is E(ξ) = E((1 −
R∗ = log
(cid:16) cu
ca

s)X) = (1 − s)E(X) = (1 − s)R∗ = (1 − s) log

(cid:16) cu
ca

+ 1

+ 1

(cid:17)

(cid:17)

of the insurer to the user is E(sX) = sE(X) = sR∗ = s log

+ 1

.

, the average payment
(cid:17)

(cid:16) cu
ca

Corollary 1 indicates the constant saddle-point strategy ratio of the user
and the attacker, which is determined only by the cost parameters cu and
ca, i.e., the market prices or costs for applying certain levels of protections
and attacks, respectively. As a result, the saddle-point risk level of the user is
constant, and only determined by the market as shown in Remark 2. Thus,
the average direct loss is constant as shown in Corollary 2. However, when the
insurance coverage level s does not satisfy (10), the insurability of the user is
not guaranteed, which is shown in the following proposition.

Proposition 2 (Fundamental Limits on Insurability) Given an insur-
a) does not satisfy
ance coverage level s that 1−γ(1−s) log
the feasible inequality (4), thus, the average direct of the user E(X) → ∞, and
the zero-sum game deﬁned in Deﬁnition 2 does not admit a SPE. Thus, the
user is not insurable, as the insurance policy cannot mitigate his loss. The
insurer will not also provide insurance to the user who is not insurable.

≤ 0, (p∗

(cid:16) cu
ca

u, p∗

+ 1

(cid:17)

Proposition 3 Under an insurable scenario, the cost parameter of the user
must satisfy cu < ca(1 − e−γ(1−s)), and the local protection level of the user
must satisfy pu > γ(1−s)

eγ(1−s).

ca

Cyber Insurance

11

Proof The ﬁrst inequality can be easily achieved from (10). From Appendix
A, given the action of the user pu, the best action of the attacker is P ∗
a (pu) =
γ(1−s)
a (pu) into the feasible inequality (4), we can get
ca

− pu. By plugging P ∗

pu > γ(1−s)

ca

eγ(1−s).

It is important to note that the user must pay a subscription fee T ∈ R≥0 to
be insured. The incentive for the user to buy insurance exists when the average
loss at equilibrium under the insurance is lower than the loss incurred without
insurance. If the amount of the payment from the insurer is low, then the user
tends not to be insured. In addition, if the payment is low, then the risk for
the insurer will be high and the user may behave recklessly in the cyber-space.

3.2 Insurer’s Problem

The insurer announces the insurance policy {s, T }, where s indicates the cov-
erage level, T indicates the subscription, and then the user’s and the attacker’s
conﬂicting interests formulates a zero-sum game, which yields a unique solu-
tion as shown in Proposition 1, with the corresponding equilibrium loss as
shown in Corollary 2. Note that T is the gross proﬁt of the insurer as he
charges it from the user ﬁrst, but when the user faces a loss X, the insurer
must pay sX to the user. The operating proﬁt of the insurer can be captured
as T − sX. The insurer cannot directly observe the actions of the user and the
attacker. However, with the knowledge of the market, i.e., the cost parameters
of the user cu and the attacker ca, the insurer aims to minimize the average
eﬀective loss of the user while maximizing his operating proﬁt.

(cid:17)

+ 1

(cid:16) cu
ca

Recall Corollary 2, the average eﬀective loss of the user at saddle-point is
E(ξ) = (1 − s)E(X) = (1 − s)R∗ = (1 − s) log
, which is monotonically
decreasing on s. When the user is under full coverage, the average loss with
the payment T is (1 − s)R∗ + T (cid:12)
(cid:12)s=1 = T . When the user does not subscribe to
an insurance, the average direct loss is R∗. Thus, the user has no incentive to
insure if the cost under fully coverage is higher than that under no insurance,
i.e., T > R∗. Moreover, for T ≤ R∗, the user will choose to insure if the
average loss under the given coverage level s is lower than under no insurance,
i.e., (1 − s)R∗ + T ≤ R∗. Therefore, we arrive at the following conditions.

Condition 1 (Individual Rationality (IR-u)) The subscription fee must
(cid:17)
satisfy T ≤ Tmax := R∗ = log
the insurance.

, so that the user prefer to subscribe

(cid:16) cu
ca

+ 1

Condition 2 (Incentive Compatibility (IC-u)) For the subscription fee
T ≤ Tmax, the user will subscribe the insurance if the coverage level s satisﬁes
s ≥ s0 = T

.

R∗ =

T
log( cu
ca

+1)

Inequalities in Condition 1 and Condition 2 are known as individual rationality
(IR-u) constraint and incentive compatibility (IC-u) constraint, respectively.

12

Quanyan Zhu

The user will enroll only when (IR-u) and (IC-u) constraints are satisﬁed.
Note that when cu is large and ca is small, i.e., the saddle-point risk level R∗
is high, Tmax is large and s0(T ) is small, i.e., when the cost of the user to put
local protections is large, and the cost of the attacker to conduct cyber-attack
is small, the price of the subscription fee is large, but the minimum coverage
is low. Note that s0 is monotonically increasing on T , moreover, when T = 0,
s = 0, i.e., the user will accept any coverage level when there is no charge for
the insurance premium. When T = Tmax, s = 1, i.e., the user only accept a
full coverage when the subscription fee is the maximum.

The insurer charges a subscription fee T from the user, i.e., the insurer has
a gross proﬁt of T . However, the insurer also pays the user an average amount
of sR∗ = s log
from Corollary 2. Thus, the average operating proﬁt
of the insurer is T − sR∗, which must be larger than or equal to 0 so that the
insurer will provide the insurance. Thus, we have the following condition.

(cid:16) cu
ca

+ 1

(cid:17)

Condition 3 (Individual Rationality (IR-i)) The insurer will provide the
insurance if T − sR∗ = T − s log

≥ 0.

+ 1

(cid:17)

(cid:16) cu
ca

Recall Proposition 2, the insurer will provide the insurance when the user is
insurable, i.e., inequality (10) must be satisﬁed. Thus, we reach the following
proposition that indicates the feasible coverage level.

Condition 4 (Feasibility (F-i)) The coverage level s is feasible, i.e., the
user is insurable, when s > 1 −

.

1
γ log( cu
ca

+1)

Condition 3 and Condition 4 indicate the individual rationality constraint
(IR-i) and the feasibility constraint (F-i) of the insurer, respectively. With the
(IR-u) and (IC-u) constraints for the user and the (IR-i) and (F-i) constraints
for the insurer, the insurer’s objective to minimize the average eﬀective loss of
the user and maximize the operating proﬁt can be captured using the following
optimization problem:

min
{0≤s≤1,T ≥0}
s.t. (IR-u), (IC-u), (IR-i), (F-i).

Ji(s, T ) := γ(1 − s) log

(cid:16) cu
ca

(cid:17)

+ 1

+ cs(s log( cu
ca

+ 1) − T )

(12)

Note that the ﬁrst term of the objective function is the average eﬀective loss
of the user under the coverage s, as the insurer also aims to reduce the loss
of the user from the attacker. Minimizing the second term of the objective
function captures the insurer’s objective of making proﬁt. Note that parameter
cs indicates the trade-oﬀ of a safer user and a larger proﬁt of the insurer.

Furthermore, the solution of Problem (12) and the corresponding SPE
deﬁned in Deﬁnition 2 yields an equilibrium for the bi-level game in Case 1
which can be deﬁned as

Deﬁnition 3 Let Si be the action set for the insurer, Su(s) and Sa(s) be
the action sets for the user and the attacker given the insurance coverage
a, {s∗, T ∗}) is called a bi-level game Nash equi-
level, the strategy pair (p∗
librium (BGNE) of the bi-level game in Case 1 deﬁned by the triple G1 :=

u, p∗

Cyber Insurance

13

(cid:104){U ser, Attacker, Insurer}, {Su(s), Sa(s), Si}, K, Ji(cid:105), if {s∗, T ∗} solves Prob-
lem (12) with the BGNE objective function J ∗
u, p∗
a)
is the SPE of the zero-sum game deﬁned in Deﬁnition 2 with the SPE objective
function K ∗ under the insurance policy {s∗, T ∗}.

i , and the strategy pair (p∗

Note that the insurer’s Problem (12) is a linear programming problem as the
objective function and all the constraints are linear in s and T . Instead of
solving this problem, we ﬁrst observe that (IR-i) and (IC-u) together indicate
that the insurance policy s and T must satisfy

T = sR∗ = s log

(cid:19)

+ 1

.

(cid:18) cu
ca

(13)

Corollary 3 Equality (13) indicates the following observations:

(i) Zero Operating Proﬁt Principle: The insurer’s operating proﬁt is always 0,

as T − sR∗ = 0.

(ii) Linear Insurance Policy Principle: The insure can only provide the insur-
ance policy s and T that satisﬁes (13), so that the user subscribes to the
insurance and the insurer provides the insurance.

Corollary 3 reveals a zero operating proﬁt principle and a linear insurance
policy principle for the insurer. These principles hold in Case 2 and 3 as well.
With (13), the linear insurance policy indicates that the ratio of the subscrip-
tion and the coverage level only depends on the saddle-point risk R∗, which is
determined by the costs seen in Remark 2. It provides a fundamental principle
for designing the insurance policy.

With (13), the optimal insurance for the insurer can be summarized using

the following proposition.

Proposition 4 The optimal insurance policy for the insurer is

s∗ = 1 T ∗ = Tmax = log

(cid:19)

+ 1

.

(cid:18) cu
ca

(14)

Proposition 4 shows that a full coverage level and a maximum subscription fee
are the optimal insurance policy of the insurer. Together with Proposition 1,
we have the following proposition of the BGNE of the bi-level game in Case
1.

u, p∗

a, {s∗, T ∗}) = (0, 0, {1, log

Proposition 5 The bi-level game of Case 1 admits a unique BGNE solution
(p∗
}). At the equilibrium, the insurer
+ 1
provides a full coverage for the user and charges a maximum subscription fee
from the user. The user and attacker have no incentives to take actions at the
equilibrium as the cost would be too high. The equilibrium also demonstrates
that cyber insurance will eﬀectively mitigate the loss.

(cid:16) cu
ca

(cid:17)

14

Quanyan Zhu

Fig. 3 Cyber insurance over interdependent infrastructures

The analysis of the bi-level structure of the game informs the optimal in-
surance policies to transfer risks from one node to the insurer. The framework
can also be extended to a scheme over interdependent infrastructures as illus-
trated in Fig. 3. The cyber risks at one node can propagate to other nodes when
there are cyber, physical, human, and social interdependencies. The insurance
of one node can play a important role in well-being of the entire system. We
can anticipate that the insurance problem should take into account network
eﬀects. This research can also be further extended to investigate the impact
of dynamic evolutions of the risks on the mechanism of insurance and the
protection behaviors of the agents.

References

1. Acemoglu, D., Malekian, A., Ozdaglar, A.: Network security and contagion. Tech. rep.,

National Bureau of Economic Research (2013)

2. Altman, E., Avrachenkov, K., Garnaev, A.: A jamming game in wireless networks with
transmission cost. In: Network Control and Optimization, pp. 1–12. Springer (2007)
3. Anderson, R., Moore, T.: The economics of information security. Science 314(5799),

610–613 (2006)

4. Axelsson, S.: Intrusion detection systems: A survey and taxonomy. Tech. rep., Technical

report Chalmers University of Technology, Goteborg, Sweden (2000)

5. Balakrishnan, K.: Exponential distribution: theory, methods and applications. CRC

press (1996)

6. Bolot, J., Lelarge, M.: Cyber insurance as an incentivefor internet security. In: Managing

information risk and the economics of security, pp. 269–290. Springer (2009)

Cyber Insurance

15

7. Chen, J., Touati, C., Zhu, Q.: A dynamic game analysis and design of infrastructure
network protection and recovery. ACM SIGMETRICS Performance Evaluation Review
45(2), 128 (2017)

8. Christoﬀersen, P., Pelletier, D.: Backtesting value-at-risk: A duration-based approach.

Journal of Financial Econometrics 2(1), 84–108 (2004)

9. Farhang, S., Manshaei, M.H., Esfahani, M.N., Zhu, Q.: A dynamic bayesian security
game framework for strategic defense mechanism design. In: International conference
on decision and game theory for security, pp. 319–328. Springer (2014)

10. Finkelstein, M.: Failure rate modelling for reliability and risk. Springer Science &

Business Media (2008)

11. Greengard, S.: The new face of war. Communications of the ACM 53(12), 20–22 (2010)
12. H¨olmstrom, B.: Moral hazard and observability. The Bell journal of economics pp. 74–91

(1979)

13. Holmstrom, B.: Moral hazard in teams. The Bell Journal of Economics pp. 324–340

(1982)

14. Hor´ak, K., Zhu, Q., Boˇsansk`y, B.: Manipulating adversary?s belief: A dynamic game
approach to deception by design for proactive network security. In: International Con-
ference on Decision and Game Theory for Security, pp. 273–294. Springer (2017)
15. Huang, L., Chen, J., Zhu, Q.: A large-scale markov game approach to dynamic protection
of interdependent infrastructure networks. In: International Conference on Decision and
Game Theory for Security, pp. 357–376. Springer (2017)

16. Jajodia, S., Ghosh, A.K., Swarup, V., Wang, C., Wang, X.S.: Moving target defense:
creating asymmetric uncertainty for cyber threats, vol. 54. Springer Science & Business
Media (2011)

17. Jhaveri, R.H., Patel, S.J., Jinwala, D.C.: Dos attacks in mobile ad hoc networks: A
survey. In: Advanced Computing & Communication Technologies (ACCT), 2012 Second
International Conference on, pp. 535–541. IEEE (2012)

18. Kelly, F.P., Maulloo, A.K., Tan, D.K.: Rate control for communication networks: shadow
prices, proportional fairness and stability. Journal of the Operational Research society
pp. 237–252 (1998)

19. Kesan, J., Majuca, R., Yurcik, W.: Cyberinsurance as a market-based solution to the

problem of cybersecurity: a case study. In: Proc. WEIS (2005)

20. Lelarge, M., Bolot, J.: A local mean ﬁeld analysis of security investments in networks.
In: Proceedings of the 3rd international workshop on Economics of networked systems,
pp. 25–30. ACM (2008)

21. Manshaei, M.H., Zhu, Q., Alpcan, T., Bac¸sar, T., Hubaux, J.P.: Game theory meets
network security and privacy. ACM Computing Surveys (CSUR) 45(3), 25 (2013)
22. McMillan, R.: Siemens: Stuxnet worm hit industrial systems. Computerworld 14 (2010)
23. Miao, F., Zhu, Q., Pajic, M., Pappas, G.J.: A hybrid stochastic game for secure control

of cyber-physical systems. Automatica 93, 55–63 (2018)

24. Minkova, L.D.: Insurance risk theory. Lecture notes, TEMPUS Project SEE doctoral

studies in mathematical sciences (2010)

25. Miura-Ko, R., Yolken, B., Mitchell, J., Bambos, N.: Security decision-making among
interdependent organizations. In: Computer Security Foundations Symposium, 2008.
CSF’08. IEEE 21st, pp. 66–80. IEEE (2008)

26. Pal, R., Golubchik, L., Psounis, K., Hui, P.: Will cyber-insurance improve network
In: INFOCOM, 2014 Proceedings IEEE, pp. 235–243.

security? a market analysis.
IEEE (2014)

27. Pawlick, J., Colbert, E., Zhu, Q.: A game-theoretic taxonomy and survey of defensive
deception for cybersecurity and privacy. arXiv preprint arXiv:1712.05441 (2017)
28. Pawlick, J., Colbert, E., Zhu, Q.: Modeling and analysis of leaky deception using sig-
naling games with evidence. IEEE Transactions on Information Forensics and Security
14(7), 1871–1886 (2018)

29. Pawlick, J., Zhu, Q.: Deception by design: evidence-based signaling games for network

defense. arXiv preprint arXiv:1503.05458 (2015)

30. Pawlick, J., Zhu, Q.: A Stackelberg game perspective on the conﬂict between machine
learning and data obfuscation. In: Information Forensics and Security (WIFS), 2016
IEEE International Workshop on, pp. 1–6. IEEE (2016). URL http://ieeexplore.
ieee.org/abstract/document/7823893/

16

Quanyan Zhu

31. Pawlick, J., Zhu, Q.: A Mean-Field Stackelberg Game Approach for Obfuscation Adop-
tion in Empirical Risk Minimization. arXiv preprint arXiv:1706.02693 (2017). URL
https://arxiv.org/abs/1706.02693

32. Peltzman, S.: The eﬀects of automobile safety regulation. The Journal of Political

Economy pp. 677–725 (1975)

33. Raiyn, J., et al.: A survey of cyber attack detection strategies. International Journal of

Security and Its Applications 8(1), 247–256 (2014)

34. Rass, S., Alshawish, A., Abid, M.A., Schauer, S., Zhu, Q., De Meer, H.: Physical in-
trusion games–optimizing surveillance by simulation and game theory. IEEE Access 5,
8394–8407 (2017)

35. Tague, P., Poovendran, R.: Modeling node capture attacks in wireless sensor networks.
In: Communication, Control, and Computing, 2008 46th Annual Allerton Conference
on, pp. 1221–1224. IEEE (2008)

36. Wang, W., Zhu, Q.: On the detection of adversarial attacks against deep neural net-
works. In: Proceedings of the 2017 Workshop on Automated Decision Making for Active
Cyber Defense, pp. 27–30. ACM (2017)

37. Xu, Z., Zhu, Q.: A cyber-physical game framework for secure and resilient multi-agent
autonomous systems. In: Decision and Control (CDC), 2015 IEEE 54th Annual Con-
ference on, pp. 5156–5161. IEEE (2015)

38. Xu, Z., Zhu, Q.: Cross-layer secure cyber-physical control system design for networked
3d printers. In: American Control Conference (ACC), 2016, pp. 1191–1196. IEEE (2016).
URL http://ieeexplore.ieee.org/abstract/document/7525079/

39. Xu, Z., Zhu, Q.: A Game-Theoretic Approach to Secure Control of Communication-
Based Train Control Systems Under Jamming Attacks.
In: Proceedings of the 1st
International Workshop on Safe Control of Connected and Autonomous Vehicles, pp.
27–34. ACM (2017). URL http://dl.acm.org/citation.cfm?id=3055381

40. Xu, Z., Zhu, Q.: Secure and practical output feedback control for cloud-enabled cyber-
physical systems. In: Communications and Network Security (CNS), 2017 IEEE Con-
ference on, pp. 416–420. IEEE (2017)

41. Yuan, Y., Zhu, Q., Sun, F., Wang, Q., Basar, T.: Resilient control of cyber-physical
systems against denial-of-service attacks. In: Resilient Control Systems (ISRCS), 2013
6th International Symposium on, pp. 54–59. IEEE (2013)

42. Zhang, R., Zhu, Q.: Secure and resilient distributed machine learning under adversarial
environments. In: 2015 18th International Conference on Information Fusion (Fusion),
pp. 644–651. IEEE (2015)

43. Zhang, R., Zhu, Q.: A game-theoretic defense against data poisoning attacks in dis-
tributed support vector machines. In: Decision and Control (CDC), 2017 IEEE 56th
Annual Conference on, pp. 4582–4587. IEEE (2017)

44. Zhang, R., Zhu, Q.: A game-theoretic approach to design secure and resilient distributed
support vector machines. IEEE Transactions on Neural Networks and Learning Systems
(2018)

45. Zhang, R., Zhu, Q.: Flipin: A game-theoretic cyber insurance framework for incentive-
compatible cyber risk management of internet of things. IEEE Transactions on Infor-
mation Forensics and Security (2019)

46. Zhang, R., Zhu, Q., Hayel, Y.: A bi-level game approach to attack-aware cyber insurance
of computer networks. IEEE Journal on Selected Areas in Communications 35(3), 779–
794 (2017)

47. Zhang, T., Zhu, Q.: Strategic defense against deceptive civilian gps spooﬁng of un-
manned aerial vehicles. In: International Conference on Decision and Game Theory for
Security, pp. 213–233. Springer (2017)

48. Zhu, Q., Clark, A., Poovendran, R., Basar, T.: Deployment and exploitation of deceptive
honeybots in social networks. In: Decision and Control (CDC), 2013 IEEE 52nd Annual
Conference on, pp. 212–219. IEEE (2013)

49. Zhu, Q., Fung, C., Boutaba, R., Ba¸sar, T.: Guidex: A game-theoretic incentive-based
mechanism for intrusion detection networks. Selected Areas in Communications, IEEE
Journal on 30(11), 2220–2230 (2012)

50. Zhu, Q., Rass, S.: On multi-phase and multi-stage game-theoretic modeling of advanced

persistent threats. IEEE Access 6, 13958–13971 (2018)

Cyber Insurance

17

51. Zhuang, J., Bier, V.M., Alagoz, O.: Modeling secrecy and deception in a multiple-period
attacker–defender signaling game. European Journal of Operational Research 203(2),
409–418 (2010)

