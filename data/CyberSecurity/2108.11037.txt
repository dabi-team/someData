IJCAI-21 1st International Workshop on Adaptive Cyber Defense

Decoys in Cybersecurity: An Exploratory Study to Test the Effectiveness of
2-sided Deception

Palvi Aggarwal∗ , Yinuo Du , Kuldeep Singh and Cleotilde Gonzalez
Carnegie Mellon University, USA
{palvia, yinuod, kuldeep2}@andrew.cmu.edu, coty@cmu.edu

1
2
0
2

g
u
A
5
2

]

R
C
.
s
c
[

1
v
7
3
0
1
1
.
8
0
1
2
:
v
i
X
r
a

Abstract

One of the widely used cyber deception techniques
is decoying, where defenders create ﬁctitious ma-
chines (i.e., honeypots) to lure attackers. Honey-
pots are deployed to entice attackers, but their ef-
fectiveness depends on their conﬁguration as that
would inﬂuence whether attackers will judge them
as “real” machines or not. In this work, we study
two-sided deception, where we manipulate the ob-
served conﬁguration of both honeypots and real
machines. The idea is to improve cyberdefense by
either making honeypots “look like” real machines
or by making real machines “look like honeypots.”
We identify the modiﬁable features of both real ma-
chines and honeypots, and conceal these features
to different degrees.
In an experiment, we study
three conditions: default features on both honey-
pot and real machines, concealed honeypots only,
and concealed both honeypots and real machines.
We use a network with 40 machines where 20 of
them are honeypots. We manipulate the features
of the machines, and using an experimental testbed
(HackIT), we test the effectiveness of the decoying
strategies against humans attackers. Results indi-
cate that: Any of the two forms of deception (con-
ceal honeypots and conceal both honeypots and
real machines) is better than no deception at all.
We observe that attackers attempted more exploits
on honeypots and exﬁltrated more data from hon-
eypots in the two forms of deception conditions.
However, the attacks on honeypots and data exﬁl-
tration were not different within the deception con-
ditions. Results inform cybersecurity defenders on
how to manipulate the observable features of hon-
eypots and real machines to create uncertainty for
attackers and improve cyberdefense.

1 Introduction
As we are increasing the number of devices available in the
network, our cyber space is continuously getting broader, big-
ger, and dramatically intensifying the potential attack surface

∗Contact Author

for adversaries. Currently, most data are digitized and stored
in the organizations’ servers, making them a valuable target
for attackers. Advanced persistent threats (APT), social en-
gineering attacks, insider attacks, and other forms of attacks
are becoming more common. Frequent strategies used in data
breaches include Ransomware, Malware, Phishing, and appli-
cation vulnerabilities [Verizon, 2021]. In 2020, more than 37
billion data records were compromised with increase of 141%
from year 2019 [Security, 2021]. According to Ponemon In-
stitute report [Institute, 2021], in the year 2020, on average,
companies required 280 days (207 days to identify and 73
days to contain) a breach. These numbers are only discussing
the attacks that were discovered. It is likely that the reality is
signiﬁcantly worse as there are unreported and undiscovered
attacks. These ﬁndings show that the organizations security
capabilities are not sufﬁcient to address current cyber threats.
According to Sun Tzu, “All warfare is based on deception.”
Deception, providing false information to the opponent, is a
powerful strategy for cyberdefense [Gonzalez et al., 2020;
Jones, 1989]. By the strategic use of deceptive techniques,
system defenders can mislead and confuse attackers, enhanc-
ing their defensive capabilities over time. Common deception
strategies used in cyberdefense include: signaling, masking,
and decoying [Gonzalez et al., 2020; Schlenker et al., 2018;
McQueen and Boyer, 2009; Whaley, 1982]. Signaling strate-
gically reveals information about a defensive strategy to the
attacker to inﬂuence the attacker’s decision making[Xu et al.,
2016; Gonzalez et al., 2020; Cranford et al., 2018]. Masking
techniques make a real object undetectable to hide informa-
tion behind benign programs (e.g., hiding information behind
an image in an email message [Aggarwal et al., 2020]), while
decoying presents a false object (i.e., honeypot) to grab atten-
tion by showcasing fake but relevant information [Spitzner,
2003].

Honeypot is perhaps the most common decoying strategy
in cybersecurity. Honeypots mimic the conﬁguration of real
machines, which might be the attacker’s target. Honeypots
are used for detection to catch illicit interactions or in pre-
vention, to assist in slowing adversaries down [Almeshekah,
2015; Almeshekah and Spafford, 2016]. The effectiveness
of honeypots depends on several factors including the con-
ﬁguration of honeypot features, the allocation of honeypots
in the network, and the number of honeypots in the net-
work. However, to make honeypots an effective cyber decep-

 
 
 
 
 
 
tion technique, they must be implemented in such a way that
they appear as real machines to cyber attackers. That is, one
needs not only a solid technical implementation behind hon-
eypots but also a solid understanding of human adversarial
behavior. For proper implementation of honeypots, defend-
ers need to carefully design the level of deception that would
most successfully exploit the trust of attackers. Previous re-
search has manipulated the amount and timing of deception,
type and frequency of signals, and the features of the hon-
eypot to exploit the attacker’s beliefs [Aggarwal et al., 2016;
Miah et al., 2020; Cranford et al., 2020]. However, past re-
search considered the abstract features of honeypots and has
not evaluated the algorithms against human attackers.

The open-source nature of honeypot software that most de-
fenders use to create honeypots makes it easy for adversaries
to identify honeypot features (i.e., attackers also have access
to such open source software). Deploying honeypots with
these features can hurt security rather than help. Moreover,
common honeypots are designed so that they look exactly
like the real machine when probed by an adversary or they
are completely different. However, this might not be neces-
sary as suggested by Miah [2020]. Instead of manipulating
the features of a honeypot to make it look like a real ma-
chine, it is possible to use 2-sided deception i.e., make hon-
eypots look like real machines and make real machines look
like honeypots. However, the effectiveness of 2-sided decep-
tion has not been tested with human adversaries. In this pa-
per, we advance past research by experimentally testing the
effectiveness of 2-sided deception. Using an experimental
testbed, HackIT, we evaluate the default conﬁguration of hon-
eypots and real nodes against concealed honeypot (1-sided
deception, i.e., making honeypots identical to real machines)
and concealed honeypots and real nodes (2-sided deception
i.e., concealing the conﬁguration of both honeypots and real
nodes).

2 Background

Honeypots have been used as an effective tool for cyberde-
ception since their inception [Spitzner, 2003]. Honeypots
have been used as a decoy machine in the network to gain an
attacker’s attention. For example, honeypots are often conﬁg-
ured with exploitable vulnerabilities so that attackers could
easily attack such machines. Honeypots are also used as a
tool to gather the behavioral patterns of malicious attackers.
To enhance the effectiveness of honeypots, research has fo-
cused on various factors such as the location of honeypots in
the network, network size and topology, and the conﬁgura-
tion.

Prior research has developed game-theoretic algorithms to
strategically allocate honeypots in the network [Bilinski et al.,
2018; Aggarwal et al., 2021; Anwar et al., 2020]. Bilinski
[2018] proposed a honeynet game to optimally allocate hon-
eypots in the network to secure high-valued resources. An-
war [2020] proposed a scalable honeypot allocation algorithm
with the importance of different machines in the network, at-
tackers and defenders cost-effectiveness, and attackers’ infor-
mation level considered.

Furthermore, research has evaluated the inﬂuence of net-

work size and network topology on adversary’s cyberattack
decisions [Katakwar et al., 2020; Achleitner et al., 2017].
The topology of the defended network in which honeypots
are deployed also matters, especially on reconnaissance mis-
sions. Achleitner [2017] proposed a reconnaissance decep-
tive virtual network topology that can be generated based on
Software Deﬁned Network (SDN) and showed its potential to
delay malicious network scans.

Research effort has also been devoted to determine the op-
timal conﬁguration of honeypots. Through masking the sys-
tems’ attributes to disguise valuable information, it is possible
to increase the attacker’s time spent in planning and compro-
mising the network. Shi [2020] proposed a solution to utilize
the feature deception problem(FDP) model and to leverage
attacker preferences known by defenders. Aggarwal [2020]
evaluated optimal masking strategies in comparison with the
random masking strategy against human adversaries. How-
ever, there is a common assumption in the literature that either
the honeypots look exactly like the real machine when probed
by an adversary or they are completely different. Thus, the
majority of the past research has focused on manipulating
the features of the honeypot to make them identical to real
machines [Shi et al., 2016]. This might not be true. There
are several side channel techniques to detect low-interaction
honeypots. Even in the case of high-interaction honeypots, if
the machine is probed from within the host (i.e., after being
compromised), there may be certain indicators (e.g., no user
activity, no network trafﬁc) that may reveal that the machine
is a decoy.

Assuming that experienced attackers would detect honey-
pots, a few researchers have studied the concept of ”fake
honeypot” i.e., creating honeypot looking systems in the
network [Rowe et al., 2007; Shi et al., 2016; Miah et al.,
2020]. Most recent work by Miah [2020] introduced a game-
theoretic model of two-sided deception that use of both fake-
honeypots and fake-real systems in the network (2-sided de-
ception). Instead of solely making honeypots look like real
systems (concealed-honeypot), a defender can modify some
features of the real machines and make them look like hon-
eypots (concealed-real). Miah [2020] numerically evaluated
the 2-sided deception model and thus, how human attackers
would make decisions with such models is still unknown.

Evaluation of these game theoretic algorithms of cyberde-
ception is comparatively rare. Ferguson [2021; 2018] stud-
ied attacker’s behavior against cyber deception using exper-
iments. A couple of platforms have been used to exper-
iment with cyber deception and dynamic honeypots. For
example, CyberVAN, HackIT, and Cybersecurity Decep-
tion Experimentation System (CDES) [Acosta et al., 2020;
Aggarwal et al., 2019; Chadha et al., 2016]. In this paper, we
will evaluate the effectiveness of cyber deception using a tool
called HackIT, i.e., a testbed to deploy deception and conduct
experiments to test different levels of deception using honey-
pots against attackers [Aggarwal et al., 2019].

3 Human Experiment

We conduct an exploratory study using an experimental
testbed called HackIT [Aggarwal et al., 2019]. HackIT pro-

Table 1: The conﬁguration of Real and Honeypot machines

Default Honeypot

Concealed-Honeypot

Default Real Machine

Concealed-Real

Features

OS

Obsolete OS

Up to date

Ports & Services

Normal Ports, Honeypot Ports Normal Ports

Exploit Info

Obsolete

Exploit Success Rate

Link Latency

Virtual/Physical Machine

100%

1ms

VM

Up to date

40%

0.2ms

Physical

Up to date

Normal Ports

Up to date

40%

0.2ms

Physical

Obsolete OS

Normal Ports, Honeypot Ports

Obsolete

80%

1ms

VM

Running Processes

2 processes

10 processes

10 processes

2 processes

File System (1 user folder
with 5∼6 sub-folders)

4∼5 empty or access-deny
folders

1 empty or access-deny
folder

1 empty or access-deny
folder

4∼5 empty or access-deny
folders

vides a capability to create a network of machines, conﬁgure
the observable features of machines to deploy deception, and
manipulate network size and topology for conducting human-
in-the-loop experiments. In this paper, we use HackIT to cre-
ate a network of 40 machines and deploy deception using dif-
ferent conﬁgurations of 20 honeypots and 20 real machines.

3.1 Features of Honeypot and Real Machines
Attackers continuously gain information about the network
during different cyber attack phases (reconnaissance - exploit
- post exploit). To acquire the information, attackers use net-
work scanning tools, specialized penetration tools, and ad-
vanced machine learning tools. These tools have different
degrees of reliability and are often used in combination.

Defenders often deploy honeypots in the network to divert
attackers from real machines to honeypots. Most of the time,
the default conﬁguration of the honeypot is well known to the
attackers and is not effective when deployed. Here we stud-
ied the default conﬁgurations of honeypots and their weak-
nesses (Honeyd, Dionaea). We also researched the features
of real machines that are modiﬁable. We selected 8 features,
i.e., Operating System (OS), ports and services, exploit infor-
mation, exploit success rate, link latency, virtual or physical
machines, number of running processes, and the ﬁle system.
These features, listed in Table 1, were used to conﬁgure the
observable features of the machines used in our study.

A default honeypot is a machine with all commonly used
features and indicators. Feature assignment listed in table 1
column default honeypot comes from the default conﬁgura-
tion of open source honeypot software such as Cowrie, Dion-
aea etc. [Cabral et al., 2019]. A typical incautiously deployed
honeypot appears to be running an obsolete operating system
and have some suspicious and default ports opened [Span-
gler, 2003; Grimes, 2006; Dahbul et al., 2017]. The default
conﬁguration of honeypots also includes exploitable vulnera-
bilities which are usually patched on real host, abnormal link
latency (round trip time), absence of necessary running pro-
cesses, and empty and inaccessible directories of ﬁle system
[Fu et al., 2006; Hayatle et al., 2012]. Virtual/sand boxed en-
vironment is another major source of ﬂaws [Chen et al., 2008;
Papazis and Chilamkurti, 2019] that inferior honeypots fail to
take care of. We select the Default Real Machine from real

working systems as listed in table 1.

Concealed-honeypots are disguised with the real machine’s
appearance, i.e., we modiﬁed the features of the honeypots to
make them look like real machines. The selected features
are veriﬁed to be either conﬁgurable or hide-able on honey-
pots [Tsikerdekis et al., 2018]. Similarly, Concealed-Real
machines are conﬁgured such as they look like honeypots
through attack surface manipulation techniques [Wang et al.,
2010; Albanese et al., 2016].

3.2 Experiment Design
In this experiment, we study the effectiveness of two-sided
deception strategy. We deﬁne three between-subject condi-
tions: default (both real and honeypots have default conﬁgu-
rations), concealed-honeypots (only honeypot’s conﬁguration
is concealed) and concealed-real-and-honeypot (both honey-
pot and real machines are concealed). Each condition con-
sists of two identical rounds. The proportion of honeypots
(20 out of 40 machines) remains the same across conditions
and rounds. The honeypots were allocated randomly in the
network.

3.3 HackIT Task
In this experiment, the participant played the role of an at-
tacker. The goal of an attacker was to steal conﬁdential ﬁles
called ”pin.txt” containing credit card pin numbers; from dif-
ferent web server systems on the network. There were 40 sys-
tems in the network and the participant’s can exploit as many
systems as they can in the network within a given time. For
the exploration and exploitation of a system on the network,
the participants were provided tools which were accessible
through commands. The commands for exploration and ex-
ploitation of systems are: (1) nmap -sL all, (2) nmap System
(3) nmap System [-rtt], (4) checkHS, (5) info exploit exploit,
(6) use exploit.

Figure 1 describes the various steps involved in the task.
The ﬁrst step in the task is information gathering. As shown
in Figure 1, attackers could use nmap, checkHS, and info
exploit commands for the information gathering phase. The
“nmap -sL all” command is to ﬁnd what web servers are
available to probe. To know about the list of ports, vulnera-
bilities present on the corresponding ports, and the operating

system “nmap System” command can be used. The “nmap
System [-rtt]” command provides the benchmark round-trip-
time of production systems and the RTT of System. To use
RTT command participants have to pay 10 seconds and this
time is deducted from the experiment remaining time of par-
ticipant. The “checkHS” command is to detect the existence
of deceptive strategies. The reliability of “checkHS” com-
mand is only 50% and it cost approximately 10 seconds to
participants. It generate a score from 0 to 1 representing the
likelihood of the system being deceptive (0 = “not decep-
tive” to 1=“deceptive”). To ﬁnd the most promising attack
path, participants can collect more detailed information, in-
cluding its disclosure date, about the presented exploits using
“info exploit exploit”. Attackers could decide to attack the
system they explored or gather more information about other
systems (step 2, Figure 1).

Once the participants are ready to exploit a machine, they
need to select an exploit as deﬁned in step 3 of Figure 1. To
exploit a vulnerability on a server, they need to execute the
“use exploit” command. The use exploit command accepts
two parameters: the vulnerability to be attacked and the tar-
get system name. For example, the participant can run the fol-
lowing command to exploit sql injection vulnerability on Sys-
tem1: ”use exploit sql injection System1”.The “use exploit”
command might require multiple tries to gain success. The
participants can also switch to another vulnerability on the
same system or another system.

Once the participants gain access to the server, they may
do further reconnaissance with the following commands-
‘ls’,‘cd’, ‘ps -A’, and ‘checkVM’ as shown in step 4 of Fig-
ure 1. The “ls” command lists the ﬁles present in the current
directory. The “cd” command helps to traverse through the
directories. The “ps -A” command lists all running processes
on the server. The “checkVM” command indicate whether the
machine is running on a physical system or in a virtual envi-
ronment. After collecting enough information and traversing
through various directories, participants may decide whether
to steal the ﬁle or leave the system without stealing the ﬁle
(step 5, Figure 1). If they decide to steal the ﬁle, they may
use the scp command to transfer the “pin.txt” ﬁle from the
server to their system. The scp command takes two parame-
ter ﬁlename and destination and works in the following way:
scp pin.txt address. The participant gets feedback about the
success of the operation and the points earned or lost in the
task (step 6, Figure 1). If participants logout without fetch-
ing the ﬁle, they gain 30 points if the exploited system was
real or lose 30 points if the exploited machine was a honey-
pot.
If participants fetched the ﬁle, the rewards and losses
were higher. The participant earns 100 points if they exploit
a real system, if they exploit a honeypot then they lose 100
points. After that, the participant’s can also choose to logout
and terminate the attack and then go on to probe, exploit, and
steal ﬁles from other servers. Participants were provided 60
minutes to complete the task. The task ends once the partic-
ipant runs out of the allowed time for the task or explores all
systems in the network.

Figure 1: The steps involved in repetitive round 1 and round 2

3.4 Participants
Participants were recruited through advertisements via vari-
ous university email groups, social media, cybersecurity tar-
geted groups, and Amazon Mechanical Turk. To be quali-
ﬁed to participate in the study, participants were required to
pass an online screening test of basic cybersecurity knowl-
edge, which included questions about network scanning, var-
ious types of attacks, etc. The question pool contains 18 ques-
tions in total, and each participant was assigned 10 questions
randomly. The participant was required to answer 7 questions
correctly. A total of 95 participated in the screening test and
71 passed with an average score of 8.4.

Qualiﬁed participants were scheduled for an online study
of 60 minutes. After qualifying the screening test on cyber-
security knowledge, 48 participants proceeded to the main
study. Participants were randomly assigned to one of the
three conditions, default (n=14), concealed-honeypot condi-
tion (n=13), and concealed-honeypot-real condition (n=21).

Table 2: Demographics

Category
Sex

Education

Degree

Cybersecurity Course

Sub-category
Male
Female
Others
Master’s
Bachelor’s
PhD
Computer Science
Electrical Engineering
STEM
Other
Yes
No

Percentage
81%
13%
6%
33.3%
60.40%
6.30%
79.15%
6.25%
12.50%
4.16%
77%
23%

Participants aged between 18 and 62 years (Mean: 33, SD:
9.9). The education and age demographics information is pre-
sented in Table 2. After the successful completion of the ex-
periment, all participants were given a base payment of $12
and could earn a bonus up to $10. The average time taken to
complete this experiment was 60 minutes.

3.5 Procedure

First, participants provided informed consent and ﬁlled the
demographic information. Next, an instruction video were
presented to them followed by text instructions regarding the
goal of the task and the general procedure (presented in Ap-
pendix A). Instructions were followed with a brief quiz to
evaluate their comprehension of the instructions. Participants
received feedback if they incorrectly answered a question in
the quiz. Once all their questions were clariﬁed, they were al-
lowed to proceed with the experiment. Participants were not
informed about the proportion of honeypots in the network.

The participants were involved in a practice round before
entering into the main section of the study. The practice
round makes the participant familiar with the tool and pro-
vides knowledge about the next main task in the study. In the
main repetitive section of the task, the participants have to use
different commands to gather information about the systems
on the network. Based on the information, the participants
have to decide regarding to exploit a system or not. And if
they decide to exploit and enter into a system, then they also
have to make another decision about stealing a conﬁdential
ﬁle from the system and transfer it to their system. After
the completion of the main task in the experiment, a feed-
back questionnaire was presented to the participants, where
participants provided their feedback about the task and the
strategies used by them during the task.

4 Results

We analyzed the attackers actions in the main task. Speciﬁ-
cally, we explored the distribution of attacks, the success of
deception by measuring the honeypot exploitation rate, data
exﬁltration rate from honeypots, and the average score earned
in each experimental condition.

4.1 Distribution of System Exploitation
To investigate the differences in the three conditions, we an-
alyzed the distribution of the number of systems exploited in
each condition in Figure 2. The median number of systems
exploited were similar in three conditions, i.e., 12 systems in
the default condition, 12 systems in the concealed-honeypots
and 13 systems in the concealed-honeypot-real conditions.
Thus, the condition does not have an impact on the median
exploitation behavior. The ﬁsher’s exact test of distribution
indicates the signiﬁcant difference in the distribution of the
three conditions (p<0.05).

Figure 2: Distribution of number of systems exploited in each con-
dition

4.2 Proportion of Honeypot Attacks
After the reconnaissance, the participant could decide to ex-
ploit the system which could be a honeypot or real. The suc-
cess of deception could be measured based on the number of
attacks on the honeypots. In our manipulation, the attempted
exploit may sometimes fail and result in a failed attack. We
analyzed the proportion of failed honeypot attacks and the
proportion of successful honeypot attacks. The failed attacks
contributed to the wasting time and resources of attackers.

We calculated the proportion of honeypot attacks as shown
in Figure 3. There is a statistically signiﬁcant difference be-
tween groups as determined by one-way ANOVA (F(2,45)
= 9.75, p = 0.0001). A Tukey post hoc test revealed that
the proportion of honeypot attacks are signiﬁcantly higher
in concealed-honeypot condition(p = 0.04) and concealed-
Honeypot-Real (p = 0.0001) condition compared to the de-
fault condition; although there is no statistically signiﬁcant
difference between the concealed-honeypot and concealed-
honeypot-real (p = 0.25). Our results suggest that any of the
two types of deception are better at increasing the attacks on
honeypots compared to using no deception at all. Addition-
ally, concealing both real and honeypot machines produces
more attacks than only concealing honeypots, although the
average difference in the proportion of attacks was not statis-
tically different.

Next, we calculated the proportion of successful honeypot
attacks in Figure 4. We observe that there was no signiﬁ-
cant difference between conditions as determined by one-way
ANOVA (F(2,45) = 0.523, p = 0.596). Although the decep-

Figure 3: Proportion of Honeypot Attacks

Figure 5: Proportion of Data exﬁltration from Honeypots

tion results in more exploitation attempts, the overall success-
ful attacks on honeypots are similar in the three conditions.

both the actions in the exploit stage and actions in the data
exﬁltration stage. Figure 6 shows the average score of partic-
ipants in the three conditions. Participants gain more points
in the default condition compared to the conceal-honeypot
and conceal-honeypot-real conditions. However, this differ-
ence was not statistically signiﬁcant as determined by one-
way ANOVA (F(2,46) = 0.216, p = 0.89). That is, in terms
of the points obtained in the game, there is no difference be-
tween conditions.

Figure 4: Proportion of Successful Honeypot Attacks

4.3 Proportion of Data Exﬁltration
After successful exploitation of any system, data exﬁltration
is the next step in the cyber kill chain cycle and shows the
In the HackIT
attacker’s lateral movement in the network.
task, we provided a goal to steal the ”pin.txt” ﬁle from the
exploited system. Figure 5 shows the proportion of data exﬁl-
tration attacks on honeypots. We observe that data exﬁltration
is higher in concealed honeypot and concealed-honeypot-real
conditions compared to the default conﬁguration condition.

There is a statistically signiﬁcant difference between
groups as determined by one-way ANOVA (F(2,44) = 3.05,
p = 0.053). A Tukey post hoc test revealed that the propor-
tion of data exﬁltration is signiﬁcantly higher in concealed-
honeypot condition(p = 0.07) and concealed-Honeypot-Real
(p = 0.10) condition compared to the default condition.
There is no statistically signiﬁcant difference between the
concealed-honeypot and concealed-honeypot-real (p = 0.91).
Our results suggest that attackers steal more data, i.e., use
SCP commands more often on concealed conditions com-
pared to the default condition.

4.4 Score
Another measure of success of deception is the average score
of participants in the three conditions. The score consists of

Figure 6: Total Score in three conditions

4.5 Time Spent on Real vs Honeypots Nodes
We analyzed the average time the participants spent on each
system in the exploit phase and the data exﬁltration phase.
Time spent in the exploit phase is calculated by the total time
spent between the attacker’s ﬁrst entry to the system or the
last scp command to the system exploitation command. The
time in the data exﬁltration phase is calculated from the sys-
tem exploitation command to the ﬁle exﬁltration command.

We observed that participants spent similar time on honey-
pots and real nodes in all conditions as shown in Figure 7 for
both exploitation and data exﬁltration phases. One likely rea-
son for this ﬁnding is that participants were under time pres-
sure and it is possible that participants are rushing through
the network instead of making informed exploit/exﬁltrate de-
cisions after full exploration. It can also be the case that the
participants can not differentiate between different types of
nodes and start to attack quickly and randomly after the ﬁrst

few exploits.

Figure 7: Average Time Usage per Target in Pre-Exploit and Exploit
phase and Post-Exploit phase

We also analyzed the time spent by participants in their ﬁrst
two exploitation attempts (shown in Figure 8). The average
time usage of the ﬁrst two attacks is larger compared to the
overall average time usage, suggesting that the participants
tend to spend less time on the latter exploits. We observed that
participants spent more time on honeypots compared to real
nodes in the default condition during the exploitation phase.
The time spent on the honeypot and real node was similar
in concealed-honeypot and concealed-honeypot-real condi-
tions. During the data exﬁltration phase, participants spent
more time on real nodes. This could be because both real and
honeypots are indistinguishable. In the concealed-honeypot-
real nodes, participants spent more time on honeypots where
the honeypots were conﬁgured to show the features of a real
node.

Figure 8: Average time spent per Target in exploitation phase and
data exﬁltration phase during ﬁrst two exploits

4.6 Post-Survey Question Analysis
After the experiment, we provided a post-survey question-
naire to participants to report their decision making strategies
in the task (appendix B). More than half of the participants
claimed that their choice of attack targets was affected by
the disclosure date of exploits and the estimation from the
“checkHS” command. Around 10% participants considered
the round-trip time information given by the “-rtt” option of
“nmap” command.

Furthermore, participants reported the factors that affected
the exﬁltration decisions were more diverse compared to the
features that affected the exploitation decisions. In the op-
tions, participants were provided both pre-exploit and exploit

features and post-exploit features. Participants reported that
the most effective features that affected their exﬁltration de-
cision include the “checkVM” command that detects a virtual
environment, “checkHS” estimation, and the number of “ac-
cess deny” encountered during post-exploit reconnaissance.

In the experiment, we provided a few costly commands to
the participants such as “rtt” and “checkHS”. Participants re-
ported that the cost for the commands was not worth. How-
ever, in the actual experiment, participants used those com-
mands quite frequently, which represents that despite the cost,
participants found those commands useful for their attack de-
cisions. We also asked participants the likely reasons for not
fetching the credential ﬁle after exploiting a node. Partici-
pants reported that they could not locate the credentials ﬁle
or they did not have time to fetch the ﬁle.

5 Discussion

Most often honeypots are deployed without changing the de-
fault features such as common ports and running processes.
Attackers could easily detect such honeypots and take advan-
tage of such situation to exploit the network. In this paper, we
conduct a human experiment using an experimental testbed
(HackIT) to study the effectiveness of 2-sided deception, i.e.,
the effect of concealing the features of both honeypots and
real machines against 1-sided deception (concealing the fea-
tures of honeypot only). We compare these two forms of de-
ception with a default condition, using the default conﬁgura-
tion of honeypots in a network.

Consistent with our hypothesis, the conditions with higher
confusion level, i.e., 1-sided deception (concealed honeypots)
and 2-sided deception (concealed real and honeypot) condi-
tions, are shown to be more effective in attaining more hon-
eypot attacks and data exﬁltration attacks on honeypots com-
pared to the default conﬁguration (no-deception). However,
the 1-sided and 2-sided conditions were not signiﬁcantly dif-
ferent. While making the exploit decisions, the attacks used
various commands that provide information about different
features in the network. We analyzed the post-survey to un-
derstand which features inﬂuence the decisions of attackers.
Participants reported that the disclosure date of an exploit
and the honeypot score inﬂuenced their exploitation decision.
Furthermore, at the data exﬁltration stage, participants re-
ported that indicators such as access denied, empty folders,
and deployment of the honeypot on a physical or virtual ma-
chine were the most important features.
In the future, we
will do a more detailed analysis on understanding how var-
ious features inﬂuence the decisions of attackers in various
conditions.

Although we tried to replicate naturalistic settings, still we
made several assumptions on the feature selection, conceal-
ing, the cost of feature modiﬁcation, and availability of tools
for attackers. In addition to the experiment design, we also
have a limited number of participants which impact the sig-
niﬁcance of some results. Yet, our results provide some in-
sights to improve the current state-of-the-art techniques of
cyberdeception for cyberdefense. Preliminary analysis of
our dataset suggests that attackers could detect the honeypots
when the default features are used. Deployment of such hon-

eypots may hurt the existing defense system of the network.
To make honeypots indistinguishable, defenders could cre-
ate confusion by making honeypots look like real machines
or making real machines look like honeypots, or both. Our
result has shown the effectiveness of concealing features on
honeypot and real machines over the default conﬁgurations.
Another limitation of our study is the participants are not red
teams or penetration testers. Research in [Ferguson-Walter et
al., 2021] hired red teams to study cyberdeception, and the
decision-making of red teams may impact the results in this
study.

We will continue elaborating on this experimental ap-
proach by running laboratory experiments that address the
various limitations of the current study. In the near future, we
plan to develop a cognitive model that replicates the attacker’s
behavior in this study. Using Instance-Based Learning The-
ory [Gonzalez et al., 2003], we can generate a computational
representation of the attacker’s decisions. Such models could
be used to generate large amounts of synthetic data to test the
effectiveness of various deception strategies.

Acknowledgments
This research was sponsored by the Combat Capabilities
Development Command, Army Research Laboratory and
was accomplished under Cooperative Agreement Number
W911NF-13-2-0045 (ARL Cyber Security CRA) and by the
Army Research Ofﬁce and accomplished under grant num-
ber W911NF-17-1-0370 (MURI Cyberdeception). The views
and conclusions contained in this document are those of the
authors and should not be interpreted as representing the ofﬁ-
cial policies, either expressed or implied, of the Combat Ca-
pabilities Development Command, Army Research Labora-
tory, or the U.S. Government. The U.S. Government is au-
thorized to reproduce and distribute reprints for government
purposes not withstanding any copyright notation here on.

A Instructions
Welcome!

This study consists of a hacking task, where you will be
playing the role of a hacker. Hackers are people knowledge-
able about computers and they use this knowledge to steal
data and private information in networks and damage systems
that are important for organizations. In this task, your goal is
to steal ﬁles called ”pin.txt” containing credit card pin num-
bers from different web server computers in a network.

You will be interacting with a network of 40 systems. Your
goal is to exploit as many systems as possible to steal as many
pin.txt ﬁles as possible (these pin.txt ﬁles contain credit-card
information and pin numbers). You will be rewarded 30
points for getting access into a system and 70 more points
for fetching the pin.txt ﬁle. However, since the pin.txt ﬁles
are highly conﬁdential, the defenders of the network may use
deception to create uncertainty. Exploitation and ﬁle transfer
on deceptive systems will cause equivalent penalty. Please be
cautious when choosing attack targets and making the deci-
sion to steal pin.txt ﬁle.

To steal a pin.txt ﬁles, you may ﬁrst probe different sys-
tems. Probing means that you try to collect information about

the open ports, and the different services running on differ-
ent web-servers. To ﬁnd what web-servers are available to
you to probe, you may ﬁrst run nmap -sL all command. This
command will show you the systems which are available for
probing. Now, to probe a system, you need to run the nmap
command the following command:

- nmap System1 [-rtt]
The output of the nmap command on System1 will also
provide a list of vulnerabilities present on the corresponding
ports, OS, and vulnerabilities. To know about the benchmark
round-trip-time of production systems and the RTT of Sys-
tem1, use option ‘-rtt‘. This will cost you approximately 10
seconds. Before attacking a server, you may use “checkHS”
command to detect the existence of deceptive strategies. The
reliability of that command is only 50% and would cost you
approximately 10 seconds . It will generate a score from 0
to 1 representing the likelihood of being a deceptive system
(0 to 1 as “impossible” to “absolute”). You may use checkHS
System1 command to get the score.

To ﬁnd a most promising attack path, you can collect more
detailed information, including its disclosure date, about pre-
sented exploits using info exploit exploitA command. To
exploit a vulnerability on a server, you need to execute the
use exploit command. The use exploit command accepts two
parameter: the vulnerability to be attacked and the target sys-
tem name. For example, you may run the following command
to exploit sql injection vulnerability on System1:

- use exploit sql injection System1
Where sql-injection is the vulnerability to be exploited and
System1 is the web-server where this vulnerability exists. The
use exploit command might require a few trials before suc-
cess. You can also switch to another vulnerability on the same
system or another system. Once succeed, you gain access into
the server and you may do further reconnaissance with com-
mand ls, ps and checkVM

- ls, cd [absolute path or relative path]
The ls command lists ﬁles present in current directory. The

cd command helps to traverse through the directories.

- ps -A
The ps command lists all running processes on the server.
- checkVM
The checkVM command simulates virtual environment
tools. Its output provide a judgement whether the server is
running in suspicious virtual environment.

After collecting enough information, you can decide
whether to steal the ﬁle or not.
If you decide to steal the
ﬁle, you may use the scp command to transfer the “pin.txt”
ﬁle between your system and the remote web-server, which
you have exploited. The scp command works in the follow-
ing way:

- scp pin.txt 172.22.31.31
In the command above, pin.txt is the credit-card pin ﬁle and
172.22.31.31 is your local machine’s IP address. Please note
down this IP address 172.22.31.31 as you will have to use
it again-and-again to copy pin.txt ﬁles from different web-
servers. Once you have copied the ﬁle from the exploited
web-server, you will get feedback on your current perfor-
mance in the task. You can also choose to logout and ter-
minate the attack anytime you like. After which you may go

on to probe, exploit and steal ﬁles from other servers.

- logout
The ﬂow of the task is also summarized in Figure 1. You
may use the help command any time in the task to list the
available commands.

B Post Survey Questions

• Q1. Pick the factors that affect your decision on attack

target (select all eligible options):

– Operating system
– Disclosure date of exploits
– checkHS estimation
– Round trip time measurement
– Other

• Q2. If other, please let us know what else affected your

decision.

• Q3. Pick the factors that affect your decision on whether

to fetch pin.txt ﬁle (select all eligible options):

– Operating system
– Disclosure date of exploits
– checkHS estimation
– Round trip time measurement
– Number of trials to get the foothold
– Empty directories encountered
– Access of directories denied
– Virtual environment detected by checkVM
– Number of running process
– Other

• Q4. If other, please let us know what else affected your

decision.

• Q5. Do you think the option -rtt of nmap command
worth the time it takes? If not, pick the largest accept-
able time cost:

– 0, – 2, – 4, – 8,

• Q6. Do you think checkHS command worth the time it

takes? If not, pick the largest acceptable time cost:

– 0, – 2, – 4, – 8,

• Q7. Pick the exploits with date that you ﬁnd too obso-

lete:

– HTTP/2 slow read, 2020-03-01
– LDAPS buffer overﬂow, 2017-04-11
– Java deserialize remote code execution, 2015-09-

29

– Remote authentication, 2012-10-23
– DoS attack, 2010-01-26
– ASUS remote code execution, 2008-03-25
– Authentication bypass, 2006-05-15
– Remote buffer overﬂow, 2001-04-04

• Q8. Have you ever given up fetching pin.txt ﬁle with
the system exploited? If so, pick the options that best
describe your reason.

– Can’t locate pin.txt ﬁle
– I had no time to fetch pin.txt
– I discover that the system is honeypot.
– To avoid further penalty

• Q9. Please provide us with your feedback about the ex-

periment (optional).

References
[Achleitner et al., 2017] Stefan Achleitner,

Thomas F
La Porta, Patrick McDaniel, Shridatt Sugrim, Srikanth V
Krishnamurthy, and Ritu Chadha. Deceiving network
reconnaissance using sdn-based virtual topologies. IEEE
Transactions on Network and Service Management,
14(4):1098–1112, 2017.

[Acosta et al., 2020] Jaime C Acosta, Anjon Basak, Christo-
pher Kiekintveld, Nandi Leslie, and Charles Kamhoua.
Cybersecurity deception experimentation system. In 2020
IEEE Secure Development (SecDev), pages 34–40. IEEE,
2020.

[Aggarwal et al., 2016] Palvi Aggarwal, Cleotilde Gonzalez,
and Varun Dutt. Cyber-security:
role of deception in
cyber-attack detection. In Advances in human factors in
cybersecurity, pages 85–96. Springer, 2016.

[Aggarwal et al., 2019] Palvi Aggarwal, Aksh Gautam,
Vaibhav Agarwal, Cleotilde Gonzalez, and Varun Dutt.
Hackit: a human-in-the-loop simulation tool for realistic
cyber deception experiments. In International Conference
on Applied Human Factors and Ergonomics, pages 109–
121. Springer, 2019.

[Aggarwal et al., 2020] Palvi Aggarwal, Omkar Thakoor,
Aditya Mate, Milind Tambe, Edward A Cranford, Chris-
tian Lebiere, and Cleotilde Gonzalez. An exploratory
study of a masking strategy of cyberdeception using cy-
bervan. HFES, 2020.

[Aggarwal et al., 2021] Palvi Aggarwal, Marcus Gutierrez,
Christopher D. Kiekintveld, Branislav Boˇsansk´y, and
Evaluating Adaptive Deception
Cleotilde Gonzalez.
Strategies for Cyber Defense with Human Adversaries.
Wiley-IEEE Press, 2021.

[Albanese et al., 2016] Massimiliano Albanese, Ermanno
Battista, and Sushil Jajodia. Deceiving attackers by cre-
ating a virtual attack surface. In Cyber Deception, pages
167–199. Springer, 2016.

[Almeshekah and Spafford, 2016] Mohammed
Almeshekah and Eugene H Spafford.
rity deception.
Springer, 2016.

H
Cyber secu-
In Cyber deception, pages 23–50.

[Almeshekah, 2015] Mohammed H Almeshekah. Using de-
ception to enhance security: A Taxonomy, Model, and
Novel Uses. PhD thesis, Purdue University, 2015.

[Anwar et al., 2020] Ahmed H Anwar, Charles Kamhoua,
and Nandi Leslie. Honeypot allocation over attack graphs
In 2020 International Con-
in cyber deception games.
ference on Computing, Networking and Communications
(ICNC), pages 502–506. IEEE, 2020.

[Bilinski et al., 2018] Mark Bilinski, Ryan Gabrys, and
Justin Mauger. Optimal placement of honeypots for net-
In International Conference on Decision
work defense.
and Game Theory for Security, pages 115–126. Springer,
2018.

[Cabral et al., 2019] Warren Cabral, Craig Valli, Leslie
Sikos, and Samuel Wakeling. Review and analysis of
cowrie artefacts and their potential to be used deceptively.
In 2019 International Conference on computational sci-
ence and computational intelligence (CSCI), pages 166–
171. IEEE, 2019.

[Chadha et al., 2016] Ritu Chadha, Thomas Bowen, Cho-
Yu J Chiang, Yitzchak M Gottlieb, Alex Poylisher, An-
gello Sapello, Constantin Serban, Shridatt Sugrim, Gary
Walther, Lisa M Marvel, et al. Cybervan: A cyber security
virtual assured network testbed. In MILCOM 2016-2016
IEEE Military Communications Conference, pages 1125–
1130. IEEE, 2016.

[Chen et al., 2008] Xu Chen, Jon Andersen, Z Morley Mao,
Michael Bailey, and Jose Nazario. Towards an understand-
ing of anti-virtualization and anti-debugging behavior in
modern malware. In 2008 IEEE international conference
on dependable systems and networks with FTCS and DCC
(DSN), pages 177–186. IEEE, 2008.

[Cranford et al., 2018] Edward A Cranford, Christian
Lebiere, Cleotilde Gonzalez, Sarah Cooney, Phebe
Vayanos, and Milind Tambe.
Learning about cyber
deception through simulations: Predictions of human
decision making with deceptive signals in stackelberg
security games. In CogSci, 2018.

[Cranford et al., 2020] Edward Cranford, Cleotilde Gonza-
lez, Palvi Aggarwal, Sarah Cooney, Milind Tambe, and
Christian Lebiere. Adaptive cyber deception: Cognitively
informed signaling for cyber defense. In Proceedings of
the 53rd Hawaii International Conference on System Sci-
ences, 2020.

[Dahbul et al., 2017] RN Dahbul, C Lim, and J Purnama.
Enhancing honeypot deception capability through network
service ﬁngerprinting. In Journal of Physics: Conference
Series, volume 801, page 012057. IOP Publishing, 2017.
[Ferguson-Walter et al., 2018] Kimberly Ferguson-Walter,
Temmie Shade, Andrew Rogers, Michael Christopher Ste-
fan Trumbo, Kevin S Nauer, Kristin Marie Divis, Aaron
Jones, Angela Combs, and Robert G Abbott. The tularosa
study: An experimental design and implementation to
quantify the effectiveness of cyber deception. Technical
report, Sandia National Lab.(SNL-NM), Albuquerque,
NM (United States), 2018.

[Ferguson-Walter et al., 2021] Kimberly J Ferguson-Walter,
Maxine M Major, Chelsea K Johnson, and Daniel H Muh-
leman. Examining the efﬁcacy of decoy-based and psy-
chological cyber deception. In 30th {USENIX} Security
Symposium ({USENIX} Security 21), 2021.

[Fu et al., 2006] Xinwen Fu, Wei Yu, Dan Cheng, Xuejun
Tan, Kevin Streff, and Steve Graham. On recognizing vir-
tual honeypots and countermeasures. In 2006 2nd IEEE

International Symposium on Dependable, Autonomic and
Secure Computing, pages 211–218. IEEE, 2006.

[Gonzalez et al., 2003] Cleotilde Gonzalez, Javier F Lerch,
and Christian Lebiere. Instance-based learning in dynamic
decision making. Cognitive Science, 27(4):591–635, 2003.
[Gonzalez et al., 2020] Cleotilde Gonzalez, Palvi Aggarwal,
Christian Lebiere, and Edward Cranford. Design of dy-
namic and personalized deception: A research framework
and new insights. In Proceedings of the 53rd Hawaii In-
ternational Conference on System Sciences, 2020.

[Grimes, 2006] Roger A Grimes. Honeypots for Windows.

Apress, 2006.

[Hayatle et al., 2012] Osama Hayatle, Amr Youssef, and
Hadi Otrok. Dempster-shafer evidence combining for
(anti)-honeypot technologies. Information Security Jour-
nal: A Global Perspective, 21(6):306–316, 2012.

[Institute, 2021] Ponemon Institute. Cost of a data breach

study. PDF, 2021.

[Jones, 1989] Reginald Victor Jones. Reﬂections on intelli-

gence. Vintage, 1989.

[Katakwar et al., 2020] Harsh Katakwar, Palvi Aggarwal,
Inﬂuence of network
Zahid Maqbool, and Varun Dutt.
size on adversarial decisions in a deception game involv-
ing honeypots. Frontiers in psychology, 11:2385, 2020.

[McQueen and Boyer, 2009] Miles A McQueen

and
Wayne F Boyer. Deception used for cyber defense of
In 2009 2nd Conference on Human
control systems.
System Interactions, pages 624–631. IEEE, 2009.

[Miah et al., 2020] Mohammad Sujan Miah, Marcus Gutier-
rez, Oscar Veliz, Omkar Thakoor, and Christopher Kiek-
intveld. Concealing cyber-decoys using two-sided feature
deception games. In HICSS, pages 1–10, 2020.

[Papazis and Chilamkurti, 2019] Kon Papazis and Naveen
Chilamkurti. Detecting indicators of deception in emu-
lated monitoring systems. Service Oriented Computing
and Applications, 13(1):17–29, 2019.

[Rowe et al., 2007] Neil C Rowe, E John Custy, and Binh T
Duong. Defending cyberspace with fake honeypots. JCP,
2(2):25–36, 2007.

[Schlenker et al., 2018] Aaron Schlenker, Omkar Thakoor,
Haifeng Xu, Milind Tambe, Phebe Vayanos, Fei Fang,
Long Tran-Thanh, and Yevgeniy Vorobeychik. Deceiving
cyber adversaries: A game theoretic approach. In Interna-
tional Conference on Autonomous Agents and Multiagent
Systems, 2018.

[Security, 2021] Risk Based Security. PDF, 2021.
[Shi et al., 2016] Leyi Shi, Junnan Zhao, Lanlan Jiang, Wen-
juan Xing, Jian Gong, and Xin Liu. Game theoretic sim-
ulation on the mimicry honeypot. Wuhan University Jour-
nal of Natural Sciences, 21(1):69–74, 2016.

[Shi et al., 2020] Zheyuan Ryan Shi, Ariel D Procaccia,
Kevin S Chan, Sridhar Venkatesan, Noam Ben-Asher,

Nandi O Leslie, Charles Kamhoua, and Fei Fang. Learn-
ing and planning in the feature deception problem. In In-
ternational Conference on Decision and Game Theory for
Security, pages 23–44. Springer, 2020.

[Spangler, 2003] Ryan Spangler. Analysis of remote active
operating system ﬁngerprinting tools. University of Wis-
consin, 2003.

[Spitzner, 2003] Lance Spitzner. Honeypots: Catching the
insider threat. In 19th Annual Computer Security Appli-
cations Conference, 2003. Proceedings., pages 170–179.
IEEE, 2003.

Tsikerdekis,

[Tsikerdekis et al., 2018] Michail

Sher-
ali Zeadally, Amy Schlesener, and Nicolas Sklavos.
Approaches for preventing honeypot detection and com-
promise. In 2018 Global Information Infrastructure and
Networking Symposium (GIIS), pages 1–6. IEEE, 2018.
[Verizon, 2021] Verizon. 2020 data breach investigations re-

port. PDF, 2021.

[Wang et al., 2010] Ping Wang, Lei Wu, Ryan Cunningham,
and Cliff C Zou. Honeypot detection in advanced botnet
International Journal of Information and Com-
attacks.
puter Security, 4(1):30–51, 2010.

[Whaley, 1982] Barton Whaley. Toward a general theory of
deception. The Journal of Strategic Studies, 5(1):178–192,
1982.

[Xu et al., 2016] Haifeng Xu, Rupert Freeman, Vincent
Conitzer, Shaddin Dughmi, and Milind Tambe. Signaling
In AAMAS, pages 150–
in bayesian stackelberg games.
158, 2016.

