C-FLAT: Control-Flow Attestation
for Embedded Systems Software

6
1
0
2

g
u
A
7
1

]

R
C
.
s
c
[

2
v
3
6
7
7
0
.
5
0
6
1
:
v
i
X
r
a

Tigist Abera1,∗ , N. Asokan2, Lucas Davi1, Jan-Erik Ekberg3,
Thomas Nyman2,3, Andrew Paverd2, Ahmad-Reza Sadeghi1, Gene Tsudik4

1

Technische Universität Darmstadt, Germany
{tigist.abera,lucas.davi,ahmad.sadeghi}@cased.de

2

Aalto University, Finland
{n.asokan,thomas.nyman,andrew.paverd}@aalto.ﬁ

Trustonic, Finland
{jan-erik.ekberg,thomas.nyman}@trustonic.com

3

4

University of California, Irvine, USA
gts@ics.uci.edu

ABSTRACT
Remote attestation is a crucial security service particularly relevant
to increasingly popular IoT (and other embedded) devices. It al-
lows a trusted party (veriﬁer) to learn the state of a remote, and
potentially malware-infected, device (prover). Most existing ap-
proaches are static in nature and only check whether benign soft-
ware is initially loaded on the prover. However, they are vulnerable
to runtime attacks that hijack the application’s control or data ﬂow,
e.g., via return-oriented programming or data-oriented exploits.

As a concrete step towards more comprehensive runtime remote
attestation, we present the design and implementation of Control-
FLow ATtestation (C-FLAT) that enables remote attestation of an
application’s control-ﬂow path, without requiring the source code.
We describe a full prototype implementation of C-FLAT on Rasp-
berry Pi using its ARM TrustZone hardware security extensions.
We evaluate C-FLAT’s performance using a real-world embedded
(cyber-physical) application, and demonstrate its efﬁcacy against
control-ﬂow hijacking attacks.

Keywords
remote attestation; control-ﬂow attacks; embedded system security

INTRODUCTION

1.
Embedded systems are becoming increasingly ubiquitous, perme-
ating many aspects of daily life. They are deployed in automotive,
medical, industrial, household and ofﬁce settings, smart cities and
factories, as well as in critical infrastructures. Unfortunately, this
increased popularity also leads to numerous security issues [43].
Securing embedded devices is challenging, particularly because
they are special-purpose and resource-constrained [22].

Remote attestation is a means of verifying integrity of software
running on a remote device. Typically, it is realized as a challenge-
response protocol allowing a trusted veriﬁer to obtain an authentic,
and timely report about the software state of a (potentially untrusted
and infected) remote device – a prover. Based on that report, a
veriﬁer checks whether prover’s current state is trustworthy, i.e.,
whether only known and benign software is loaded on the prover.

The standard trust assumption needed for authenticity of the at-
testation report requires the existence of some trusted component –
called a trust anchor – on the prover. Moreover, most attestation
schemes assume malicious software (i.e., remote malware infes-
tations) as their adversarial model. Prominent examples of trust
∗Author names are listed in alphabetical order.

anchors are secure components such as a Trusted Platform Module
(TPM). Although available on many laptops and desktops, TPMs
are too complex and expensive for deployment on low-end em-
bedded devices. Ideally, trust anchors for small embedded devices
should be light-weight, i.e., require minimal hardware features and
assumptions, in light of recent proposals such as SMART [17],
SANCUS [31], and Intel’s TrustLite [23]. The next generation of
ARM Microcontrollers (MCUs) [45] will feature TrustZone-M, a
lightweight trust anchor.

Most current remote attestation approaches are static in nature.
In such schemes, the prover’s report is typically authenticated by
means of a cryptographic signature or a MAC computed over the
veriﬁer’s challenge and a measurement (typically, a hash) of the
binary code to be attested. However, static attestation, though efﬁ-
cient, only ensures integrity of binaries and not of their execution.
In particular, it does not capture software attacks that hijack the
program’s control ﬂow [41]. These attacks tamper with the state
information on the application’s stack or heap to arbitrarily divert
execution ﬂow. State-of-the-art memory corruption attacks take
advantage of code-reuse techniques, such as return-oriented pro-
gramming, that dynamically generate malicious programs based on
code snippets (gadgets) of benign code without injecting any ma-
licious instructions [33]. As a result, the measurements (hashes)
computed over the binaries remain unchanged and the attestation
protocol succeeds, even though the prover is no longer trustwor-
thy. These sophisticated exploitation techniques have been shown
effective on many processor architectures, such as Intel x86 [38],
SPARC [8], ARM [24], and Atmel AVR [18].

The problem arises because static attestation methods do not cap-
ture a program’s runtime behavior (i.e., timely trustworthiness) of
the underlying code. In particular, recent large-scale studies have
shown [13, 10] that embedded software suffers from a variety of
vulnerabilities, including memory errors (such as buffer overﬂows),
that allow runtime exploits. To be truly effective, an attestation
technique should report the prover’s dynamic state (i.e., its current
executions details) to the veriﬁer. As we elaborate in Section 9,
there have been some proposals to enhance and extend static bi-
nary attestation [34, 19]. However, they either require involvement
of an external trusted third party, or only attest higher level of poli-
cies at the Java bytecode layer by instrumenting the Java virtual
machine. Hence, they do not capture control-ﬂow related attacks at
the binary level of embedded systems software.

Mitigation of runtime exploitation techniques has been a subject
of intensive research. Prominent defenses against control-ﬂow hi-
jacking include: control-ﬂow integrity (CFI) [1], ﬁne-grained code

 
 
 
 
 
 
randomization [12, 26], and code-pointer integrity (CPI) [25]. How-
ever, naïvely integrating these approaches into remote attestation
protocols would provide limited state information to the veriﬁer.
In particular, these techniques only report whether a control-ﬂow
attack occurred, and provide no information about the actually ex-
ecuted control-ﬂow path. Therefore, the veriﬁer can not determine
which (of the many possible) paths the prover executed. This lim-
itation allows an attacker to undermine such defenses by means of
so-called data-oriented exploits [11]. These attacks corrupt data
variables to execute a valid, yet unauthorized, control-ﬂow path. A
prominent example of this attack is the corruption of an authentica-
tion variable, allowing the attacker to execute a privileged control-
ﬂow path. Recently, Hu et al. [20] demonstrated that such attacks
allow Turing-complete malicious computation.

Goals and Contributions. This paper proposes Control-FLow
ATtestation (C-FLAT), a technique for precise attestation of the
execution path of an application running on an embedded device.
C-FLAT complements static attestation by measuring the program’s
execution path at binary level, capturing its runtime behavior. As
a new approach, C-FLAT represents an important and substantial
advance towards tackling the open problem of runtime attestation.
C-FLAT allows the prover to efﬁciently compute an aggregated
authenticator of the program’s control ﬂow, i.e., of the exact se-
quence of executed instructions, including branches and function
returns. This authenticator represents a ﬁngerprint of the control-
ﬂow path. It allows the veriﬁer to trace the exact execution path
in order to determine whether application’s control ﬂow has been
compromised. Combined with static attestation, C-FLAT can pre-
cisely attest embedded software execution so as to allow detection
of runtime attacks.

In designing C-FLAT, we focus on embedded systems. As the
initial proof-of-concept, we attest single-thread programs executed
by small IoT MCUs, since C-FLAT is not meant for arbitrary com-
plex applications. We discuss the path towards control-ﬂow attes-
tation of MCUs in Section 8.

The main contributions of this paper are:
• A novel and practical scheme for attestation of the applica-
tion’s execution path. In contrast to more traditional static
attestation, C-FLAT captures application’s runtime behav-
ior (Section 4).

• Addressing several challenges unique to control-ﬂow path
attestation, such as handling loops and call-return matching
(Section 4.2).

• A proof-of-concept implementation that features (i) a static
analysis tool to determine valid control ﬂows of an applica-
tion, (ii) a static binary instrumentation tool to extend ARM
binaries with C-FLAT functionality, and (iii) a background
service implemented as a trusted application, using ARM
TrustZone extensions, which monitors runtime control ﬂow
and generates the attestation response (Section 5).

• A systematic evaluation of C-FLAT in the context of Open

Syringe Pump, a real embedded control application for a widely-
used class of cyber-physical systems (Section 6). We also
demonstrate C-FLAT’s resilience against various runtime at-
tacks (Section 7).

We chose to initially instantiate C-FLAT using ARM TrustZone
since ARM-based platforms (particularly Raspberry Pi) are widely
available and popular for building embedded applications, e.g., the
syringe pump described in Section 6.1. Although our implemen-
tation uses TrustZone-A hardware security extensions available in
current general-purpose ARM processors, its more lightweight suc-
cessor TrustZone-M will be available on ARMv8 MCUs [45] which
are expected to come on the market soon. This will allow C-FLAT

to be easily realizable on commercial MCUs. We elaborate on the
use of embedded architectures with small trust anchors, and discuss
further performance improvements in Section 8.

Code Availability. To enable reproducibility of our results, and
to encourage further research in this area, the source code for C-
FLAT, our use-case cyber-physical programs, and the proof-of-
concept exploits are available at https://goo.gl/pTiVdU.

2. PROBLEM SETTING
Runtime attacks exploit program vulnerabilities to cause malicious
and unauthorized program actions. The most prominent example
is a buffer overﬂow, allowing the attacker to corrupt memory cells
adjacent to a buffer. The main target of these attacks is manipula-
tion of control-ﬂow information stored on the program’s stack and
heap.

Figure 1: Abstract view of runtime attacks

Figure 1 shows a generic runtime attack example of a program
that calls either a privileged or non-privileged subroutine based on
the authentication variable auth.1 Line numbers in the pseudo-
code map to CFG nodes. The example program suffers from a
control-ﬂow vulnerability at node N3 allowing the attacker to over-
write code pointers that store control-ﬂow information. (Typically,
these vulnerabilities allow the attacker to read from, and write to,
the application’s memory.) Upon encountering the corrupted code
pointer, the program’s control ﬂow is deviated to either (i) previ-
ously injected code (node NX ) [2] or (ii) existing code (node N2)
such as system functions [40] or unintended code sequences [38].
The latter is commonly referred to as code-reuse attack, one type of
which – called return-oriented programming – allows the attacker
to generate arbitrary malicious program actions based on chaining
short sequences of benign code. Since code-reuse attacks do not
require injection of malicious code, they undermine the widely-
deployed security model of data execution prevention (DEP) [30]
which aims at preventing code injection attacks by either marking
memory as writable or executable.

Code-reuse attacks have emerged as the state-of-the-art exploita-
tion technique on various processor architectures. Both control-
ﬂow integrity (CFI) [1] and code-pointer integrity (CPI) [25] aim
at mitigating these attacks. While CFI enforces the program always

1In general, any program can be abstracted through its correspond-
ing control-ﬂow graph (CFG), where nodes represent code blocks
and edges control-ﬂow transitions.

if(auth==true) then: call privileged()else: call unprivileged()terminate…privileged {…instructions…}unprivileged {…instructions…}123456N1N2N3N4N5N6unprivileged pathprivileged pathcontrol-flow attack pathcontrol-flow vulnerabilitynon-control data vulnerabilityNX(i)(ii)(iii)attacker-injected codeXfollowing a legitimate path, CPI ensures integrity of code pointers.
However, these schemes do not cover so-called non-control-data
attacks [11]. These attacks corrupt data variables which are used to
drive the control ﬂow of the program. In the example of Figure 1,
node N1 transitions the control ﬂow to either N2 or N3, based on
auth. Thus, if the program suffers from a non-control-data vulnera-
bility, the attacker can change auth from false to true, so that execu-
tion continues in the privileged path although the user has not been
authenticated to execute that path, i.e., attack path (iii) in Figure 2.
For the sake of completeness, attacks discussed thus far lead to
unintended, yet valid, program ﬂows. However, it is also possi-
ble to mount pure data-oriented programming (DOP) attacks which
only corrupt memory load and store operations, without inducing
any unintended program ﬂows [20]. Consider a program that reads
from a buffer via a data pointer and sends retrieved data over net-
work. A pure DOP attack would only manipulate the data pointer,
e.g., to reference a private key. Hence, the original program con-
trol ﬂow would lead to leakage of the private key without incurring
any suspicious control ﬂows. Since we focus on control-ﬂow at-
testation, such pure data-ﬂow attacks are beyond the scope of this
paper. As shown in Figure 1, we focus on control-ﬂow related at-
tacks launched either by manipulating control-ﬂow information, or
non-control-data, such as data variables, i.e., the attacks (i)-(iii).

3. SYSTEM MODEL
Figure 2 shows our system model: the veriﬁer Ver wants to attest
runtime control ﬂows of an application module on a remote embed-
ded system – the prover Prv. The application module is typically
an entire program or a subset thereof, such as a speciﬁc function.
Both Ver and Prv are assumed to have access to the binaries of
the underlying application.

Figure 2: Overview of C-FLAT

3.1 Overview
C-FLAT requires Ver to perform ofﬂine pre-processing: (1) gen-
erate the control-ﬂow graph (CFG) of the application module via
static analysis ((cid:182)), and (2) measure each possible control-ﬂow path
using a measurement function H, and store the result in a measure-
ment database ((cid:183)). This needs to be done only once per application
module. Since Prv is assumed to be a low-end anemic embedded
device with very limited memory, it cannot generate and store the
entire CFG. However, this can be easily done by Ver which has no
such resource limitations.
NOTE: We realize that efﬁcient computation of a generic program’s
CFG and exploration of all possible execution paths is an open
problem. However, in this paper, we focus on static embedded ap-
plication software which is typically much simpler than programs

for general-purpose computers, e.g., the syringe pump program we
analyze for our proof-of-concept consists of only 13k instructions.
In (cid:184), Ver asks Prv to execute the application by transmitting a
challenge that includes the name of the application module2 and a
nonce to ensure freshness. Next, Prv initiates execution of the ap-
plication module ((cid:185)), while a dedicated and trusted Measurement
Engine computes a cumulative authenticator Auth of the control-
ﬂow path ((cid:186)). At the end, Prv generates the attestation report
r = SigK (Auth, c), computed as a digital signature over the chal-
lenge c and Auth using a key K known only to the Measurement
Engine. Finally, Prv sends r to Ver ((cid:187)) for validation ((cid:188)).

Since Prv attests the application code (with static attestation)
and its control ﬂow (with C-FLAT), Ver can detect runtime at-
tacks, as discussed in Section 2. Any deviation from the program’s
legitimate control ﬂow results in an unrecognized measurement.
Further, non-control data attacks output an unexpected, though valid,
measurement allowing Ver to detect attacks within the applica-
tion’s valid CFG. Static attestation (not shown in Figure 2), assures
Ver that Prv is running the intended application.

3.2 Requirements and Adversarial Model
As expected of an attestation scheme, we require that the attestation
report (r) must be a fresh and authentic representation of the appli-
cation’s runtime control ﬂows. The scheme itself must therefore be
resilient against replay and masquerading attacks.

We make the following assumptions about the behavior of the

adversary, denoted by Adv.

Adv can introduce arbitrary malware into the prover. However,
we rule out physical attacks, which is a standard assumption in all
single-prover attestation protocols. We focus on attacks that hijack
the execution path of the code to be attested (see Section 2). Such
attacks are based on providing malicious inputs to Prv’s public
interfaces. Furthermore, we assume the following Prv features:

• Data execution prevention (DEP) to prevent an attacker from
injecting and executing malicious code into running processes.
All modern platforms – including embedded systems – pro-
vide hardware to support enforcement of this principle.

• A trust anchor that: (1) provides an isolated measurement en-
gine, which cannot be disabled or modiﬁed by non-physical
means (i.e., it allows measurements for both the static and
control-ﬂow path attestation), and (2) generates a fresh, au-
thenticated attestation report. In Section 8, we discuss sev-
eral concrete instantiations of this trust anchor.

These assumptions are in line with all previous work on remote
attestation3. However, we consider a stronger Adv, capable of
control-ﬂow hijacking attacks.

4. C-FLAT DESIGN
In order to perform control-ﬂow attestation, Ver asks for a mea-
surement of Prv’s execution path. This measurement should allow
Ver to efﬁciently determine and verify Prv’s control-ﬂow path.
It is clearly infeasible to record and transmit every executed in-
struction, since that would: (1) result in a very long attestation
response which Prv would have to store, and (2) require Ver to
walk through every single instruction. The same applies to another
intuitive approach that would record and transmit source and tar-
get addresses of every executed branch, since such instructions fre-
quently occur during program execution. To keep the attestation
response short and allow fast veriﬁcation, we propose a cumulative

2In practice, the veriﬁer could transmit the actual application code.
3Assuming a trust anchor is typical for remote attestation protocols.

Generate Control-Flow Graph: G=CFG(A(*))Verifier VerProver PrvChallenge cApplication Module AResponse rMeasure CFG Paths: H(G)Measurement DBApplication Module AExecute: Exec(A(input))Measure executed CFG Path: Auth=H(Exec(A(input)))Generate Authenticated Attestation Report: r=SigK(Auth,c)123456Verification of r7hash-based control-ﬂow attestation scheme that builds a hash chain
of executed control-ﬂow transitions.

4.1 C-FLAT: High-Level Description
The main idea is to extend static (hash-based) attestation of bi-
nary ﬁles to dynamic (runtime) control-ﬂow paths. Figure 3 illus-
trates this idea based on a simple control-ﬂow graph (CFG) already
shown in Section 2. Each CFG node contains a set of assembler
instructions, and each edge represents a node transition by means
of a branch instruction. Depending on the desired granularity, the
nodes can be (1) entire functions, (2) basic blocks (BBLs) ending
in an indirect branch, or (3) BBLs ending in any branch instruction,
e.g., direct or indirect jump, call and return. In this paper, we con-
sider the last case allowing Ver to precisely validate the executed
control-ﬂow path of an application on Prv’s device.

4.2 Challenges
There are several challenges in instantiating C-FLAT. First, naïvely
applying it to arbitrary code containing loops can lead to a combi-
natorial explosion of legal Auth values, since each execution in-
volving a distinct number of loop iterations would yield a different
Auth value. Furthermore, a static CFG does not capture call-return
matching, e.g., a subroutine might return to various call locations.
This would necessitate allowing too many possible Auth values
that could be exploited by Adv [15].
Loops. Figure 4 depicts a CFG and its corresponding pseudo-code
for a classic while loop, which contains an if-else statement. Note
that conditional statements (lines 2 and 3) introduce nodes (N2,
N3) with multiple outgoing edges. Hence, based on a condition
check, they follow one of these edges. The main challenge is that
the cumulative hash computed at N2 is different at each loop it-
eration, since it subsumes the cumulative hash produced after the
previous iteration. For an application that contains multiple (and
even nested) loops, the number of legal Auth values grows expo-
nentially, making control-ﬂow attestation cumbersome.

Figure 3: C-FLAT control-ﬂow attestation

C-FLAT depends on every executed branch instruction. It em-
ploys a measurement function H which takes as input: (1) node
ID of the source node Ni, and (2) previous measurement: Hi =
H(Hprev, Ni). At the beginning, when no previous measurement
is available, we start with Hprev = 0. As a result, there is a cumu-
lative measurement for each possible program path, e.g., the priv-
ileged path outputs H5, while the unprivileged path leads to H6
in Figure 3. Any unexpected measurement indicates to Ver that
an illegal path has been executed. Furthermore, based on the re-
ported measurement, Ver can easily determine whether the privi-
leged path has been executed.

Due to its speed and simplicity, we chose the cryptographic hash
function BLAKE-24 as H for cumulative hashing that yields Auth.
Hash-based measurements are already deployed in static attestation
and allow mapping of an input to a unique5 ﬁxed-size result. To
generate the ﬁnal attestation report r, Prv can use a public key
signature or a MAC over Ver’s challenge c and Auth. (Without
loss of generality, we use signatures in the rest of the paper.) In ei-
ther case, the secret (private) key is assumed to be protected within
the trust anchor.

Obviously, the number of valid measurements depends on the
complexity and size of the application module, particularly, the
number of indirect and conditional branches.
Indirect branches
may target from 1 to n nodes, and conditional branches target 2
nodes in the CFG. Loops and recursive calls also lead to a high
number of valid measurements, depending on the number of loop
iterations, or recursive calls. In Section 4.2 we address this chal-
lenge using an approach for efﬁcient loop and recursion handling,
allowing us to limit the number of possible (legal) measurements.

4https://blake2.net
5With overwhelming probability.

Figure 4: Loop Handling in C-FLAT

Our approach to tackling this problem is based on handling a
loop as a sub-program. We measure each loop execution separately
and merge its cumulative value with that of the previous execution,
at loop exit. Consider the example in Figure 4: ﬁrst, we identify
the loop starting node by means of static analysis – N2. Second,
we initiate a new computation when the loop is entered, i.e., H2a =
H(0, N2). To avoid losing the previous value, we store H1.

Our example also has an if-else statement within the loop. It di-
verts control ﬂow at N3 to either N4 or N5, depending on cond_2.
Consequently, each loop iteration can either output H6a (solid line)
or H6b (dashed line). Upon loop exit, it is also desirable to attest
the number of times a loop is executed. To do so, we track each
loop measurement separately, by storing the number of times a dis-
tinct measurement was encountered at N2, and including this result
#H6a, #H6b in Auth where #Hi reﬂects the number of loop it-
erations for each possible path. This ensures that every loop iter-
ation is attested. However, the size of Auth is now expanded by
the number of different paths inside the loop. In Section 6.2, we
demonstrate some actual Auth sizes for several sample runs of the
syringe pump application.

N1N2N3N4N5N6H1=H(0,N1)H1=H(0,N1)H3=H(H1,N3)H2=H(H1,N2)H5=H(H2,N5)H6=H(H3,N6)Auth=H4= H(H6,N4) OR H(H5,N4)unprivileged pathprivileged pathN1N2N3N4H1=H(0,N1)H2a=H(0,N2)H3=H(H2a,N3)N5N6H3=H(H2a,N3)H5=H(H3,N5)H4=H(H3,N4)N7H6a=H(H4,N6)H2b=H(H1,N2)Auth= H7, <H1,{<H6a ,#H6a>,<H6b,#H6b>}>H6b=H(H5,N6)BBL_Awhile(cond_1) {if(cond_2)then: BBL_Belse: BBL_CBBL_D } BBL_E1234567H7=H(H2b,N7)Upon loop exit, we simply take the recorded measurement of the
execution right before the loop was entered (H1) for the computa-
tion of H2b. The measurement for H2b does not capture whether
the loop has executed. However, observed loop path measurements
are reported in Auth. We denote these with < Hi, #Hi > to re-
port the loop path measurement and the number of times this mea-
surement has been observed. Since a program might enter the loop
at different execution stages, we need to separate loop counters for
each stage. Otherwise, Ver will not be able to determine the time
when the loop has been entered. For this, we maintain a reference
that indicates the program stage at which loop measurements were
taken. This is achieved by simply taking the previous measurement
right before the loop is entered, e.g., H1 in Figure 4.

This general approach also supports nested loops and recursive
function calls, since each starting node initiates a separate mea-
surement chain and the result at loop exit (or recursion return) is
reported as separate measurements in Auth. We also perform call-
return matching on Prv in order to distinguish multiple instances
of a particular loop from each other. This includes recursive calls
to subroutines that contain loops. Such loops occur in the CFG
only once but at runtime multiple loop instances might exist con-
currently. In such cases, each distinct instance is represented sep-
arately in Auth. Call-return matching also allows us to correctly
handle subroutine calls that occur within a loop body. When deter-
mining the loop exit node, we identify the basic block from which
branches to the loop entry node is no longer possible during be-
nign execution. In other words the execution of the exit node, or
subsequent basic blocks residing in memory after the exit node in,
indicates the end of a particular instance of the loop. However, con-
sider the scenario described by Figure 5. It depicts a loop that will
branch to subroutine f from N3 on each iteration. Note that the
subroutine entry N6 resides in memory after the loop, and would
therefore erroneously be considered to signify the end of the loop.
By performing call-return matching, we can detect when execution
leaves the context of the loop (i.e.
the routine in which the loop
resides) and exit nodes need not be tested for until execution of the
loop code resumes.

Figure 5: Subroutine calls within a loop body

Break Statements. Another related challenge arises when break
statements occur inside loops or switch-case statements. Once en-
countered during program execution, they immediately terminate

the innermost loop. Figure 6 shows a code example and its associ-
ated CFG for such a case. Compared to the previous loop example
in Figure 4, node N5 now executes a break instruction, where the
path leading to the break is indicated by a dotted line.

Figure 6: Handling Break Statements in C-FLAT

We need to treat break statements inside loops as special loop
exit nodes with a slightly modiﬁed measurement function, for the
following reason. Typically, loop exits only occur at the conditional
check at node N2. However, break in N5 will not return back to the
conditional statement, but immediately to N7. Hence, we slightly
extend the original measurement function to capture the fact that
the measurement right before the loop was H1 and the loop has
been terminated over the break statement. To do so, the measure-
ment at N5 indicates that the loop has been entered at N2 with the
previous hash value H1 (H2b) and terminated via N5. The same
principle is applied to goto statements that terminate a loop, e.g., a
goto from a nested loop that also terminates an outer loop.
Call-Return Matching. Function calls and returns pose another
challenge, especially, when a subroutine can be invoked from mul-
tiple calling locations. Figure 7 depicts a sample scenario where
two function calls (N2, N3) call subroutine N4. In the static CFG,
the return instruction at N4 can either target N5 or N6. However,
if the previous ﬂow is not considered, Adv can execute a malicious
path, e.g., N2 (cid:55)→ N4 (cid:55)→ N6. As recent work demonstrates, such
malicious ﬂows allow for a variety of control-ﬂow attacks [15].

To cope with this issue, we index call and return edges during
static analysis. In the CFG of Figure 7, the call from N2 (cid:55)→ N4 is
indexed with C1 and the corresponding return edge N4 (cid:55)→ N5 –
with the same index marked as R1. Hence, the only Auth values
Ver considers legal are H4a and H4b.

IMPLEMENTATION

5.
This section presents our prototype instantiation of C-FLAT and
discusses its key implementation aspects.

5.1 Architecture of Proof-of-Concept
To demonstrate the feasibility of C-FLAT, we prototyped it on a
popular embedded platform. As discussed in Section 3.2, remote
attestation requires a trust anchor on Prv. Because lightweight

N1N2N3N6H1=H(0,N1)H2a=H(0,N2)N4H3=H(H2,N3)H6=H(H3,N6)N5H4=H(H6,N4)H2b=H(H1,N2)Auth= H5, <H1,{<H4,#H4>}>BBL_Awhile(cond_1) {f()} BBL_BBBL_C123456H5=H(H2b,N5) CALL:RET:f:N1N2N3N4H1=H(0,N1)H2a=H(0,N2)H3=H(H2a,N3)N5N6H3=H(H2a,N3)H5=H(H2b,N5)H4=H(H3,N4)N7H6=H(H4,N6)H2b=H(H1,N2)Auth= H7, <H1,{<H6 ,#H6>, <H3 ,#H3>}>BBL_Awhile(cond_1) {if(cond_2)then: BBL_Belse: breakBBL_C } BBL_D1234567H7=H(H2b,N7) OR H(H5,N7)the Runtime Tracer. Further details about the instrumentation tool
can be found in Section 5.2. We note that the analysis and trans-
formations done to the target program could also be performed at
program load time, either by a trusted bootloader, or a program
loader in conﬁgurations where an embedded operating system is
present on the device.
Runtime Operation. The C-FLAT Library ((cid:182)) serves as a media-
tor between the attested program on Prv and the Measurement En-
gine. It provides an API that allows software on Prv to initiate the
attestation procedure, and obtain an attestation response from the
Measurement Engine. Speciﬁcally, cfa_init initializes a new
control-ﬂow trace for attestation, and cfa_quote generates the
attestation response from initialized trace. Once Prv receives the
challenge c from Ver, it initiates a runtime trace by executing the
cfa_init function ((cid:183)) and proceeds to execute the target pro-
gram. The attestation procedure on Prv may be initialized from
within the target program in cases where an attestation of only a
particular operation is desired. The target program can, based on
e.g., input from the veriﬁer, decide at runtime which portions of
program operation are to be attested.

As a result of the instrumentation of the target program binary,
all control-ﬂow instructions are intercepted by the Runtime Tracer
Trampolines ((cid:184)). The Runtime Tracer determines the source and
destination address of the observed branch, and the type of control-
ﬂow instruction that caused it (see Section 5.2).
It then triggers
the Measurement Engine ((cid:185)). The Measurement Engine performs
the incremental measurement of the runtime control-ﬂow path as
described in Section 4, i.e., computes the cumulative Auth (using
the BLAKE2 hash function). The Measurement Engine then trans-
fers control back to the Runtime Tracer, which in turn resumes the
execution of the target program at the destination address of the
observed branch ((cid:186)). Once the program procedure that is to be at-
tested completes, Prv executes the cfa_quote function ((cid:187)) with
the challenge c provided by Ver. This triggers the Measurement
Engine to ﬁnalize Auth and generate the attestation response.
Trust Assumptions are as follows:

• Assumption 1: The Normal World software stack, including
the attested target program and Runtime Tracer components
are covered by the static attestation from Prv to Ver.

• Assumption 2: The Measurement Engine is trusted and can-

not be disabled or modiﬁed.

Static attestation of the Normal World software stack ensures that
Adv cannot modify this without being detected by Ver. This is im-
portant because it allows Ver to detect if Adv tampers with Nor-
mal World software to manipulate the inputs to the Hash Engine
computing cumulative hashes. Isolation of the Measurement En-
gine from the Normal World is important since, in the event of a
compromised control ﬂow (even without modifying Normal World
software), Adv might attempt to inﬂuence hash computation prior
to its delivery to Ver.

It is also possible that an adversary may attempt to mount a run-
time attack against the Runtime Tracer and through this tamper the
input to the Measurement Engine. However, the Measurement En-
gine can prior to relinquishing control back to the Trampoline that
triggered the measurement validate that the actual destination of the
recorded branch matches the input to the algorithm.

We implemented the Measurement Engine as a monolithic trusted
kernel executing in the ARM TrustZone “Secure World” [3], thus
isolating it from the untrusted target program, and the Runtime
Tracer, to prevent Adv from tampering with measurements.
Node IDs. Recall that C-FLAT requires unique node IDs for CFG
nodes. There are several options for doing this: (1):
Identify en-
try and exit addresses of basic blocks. These addresses are unique

Figure 7: Call-return matching

hardware trust anchors for small embedded devices, such as Intel’s
TrustLite or ARM’s TrustZone-M, are not currently commercially
available we opted for a more powerful ARM application processor
that features TrustZone-A [3] security extensions for our prototype.
Speciﬁcally, we chose Raspberry Pi 2 as the underlying embedded
device platform. In our experimental setup, Raspberry Pi 2 is set
up to execute a bare metal, monolithic, single-purpose program in
the “Normal World” [3] of the ARM core, without a separate OS.
In Section 8, we explain why the same approach is also applicable
in systems where applications run on top of an embedded OS.

The prototype has two main components: i) a program analyzer
to compute legal measurements of the target program, and ii) a
Runtime Tracer and an isolated, trusted Measurement Engine to
trace and measure the runtime control-ﬂow path. The former can
be realized either as: (1) a static binary analyzer that generates the
program’s CFG by identifying basic blocks and their connection
through branch instructions, or (2) a dynamic analyzer that pro-
duces valid measurements for a set of inputs by tracing execution
of the target program. We opted for a dynamic analyzer. We also
developed a binary rewriting tool for ARM binaries used to instru-
ment the target program in order to allow the Runtime Tracer to in-
tercept all branches during execution. Figure 8 shows the C-FLAT
prototype architecture. Black boxes depict C-FLAT system com-
ponents. Below we describe the operation of the prototype.

Figure 8: Proof-of-concept architecture

Instrumentation Phase. Initially the program binary is analyzed
and instrumented using our instrumentation tool. During the anal-
ysis, information about direct branches and loops is collected from
the binary, and stored in the branch table and loop table data struc-
tures included as part of the Runtime Tracer in the software image
loaded onto Raspberry Pi 2. At runtime, these data structures are
made available in read-only memory to the Runtime Tracer and
Measurement Engine.

During instrumentation, each control-ﬂow instruction in the tar-
get program is modiﬁed to pass control to Trampolines belonging to

N1N2N4N5H1=H(0,N1)H4a=H(H2,N4)N6H4b=H(H3,N4)Auth=H4aOR H4bN3H1=H(0,N1)H2=H(H1,N2)H3=H(H1,N3)CALL:RET:C1C2R1R2Runtime TracerMeasurement EngineAttestationHardwareTrusted KernelHash EngineTrampolinesTarget ProgramC-FLAT LibraryBootloader13cfa_initcfa_quote5ins_Ains_Bins_Cbranch Cins_Dins_F2674and already present, without extra instrumentation. However, they
change for each run of the program, if memory layout random-
ization (ASLR) [26] is used. (2): Using labels, instrument the pro-
gram to embed a unique ID at the beginning of each basic block,
similar to label-based CFI schemes [1]. (3): Maintain a dedicated
table that maps memory addresses of basic blocks to node IDs.

We selected (1), since many embedded systems do not yet sup-
port ASLR due to lack of an MMU. However, if ASLR is used, we
can either report the base address in the attestation result, or adopt
alternative approaches.

5.2 ARM Instrumentation
Another consideration for our implementation is the instrumenta-
tion of ARM binaries. 32-bit ARM processors feature 16 general-
purpose registers. All these registers, including the program counter
(pc) can be accessed directly. In addition to a 32-bit RISC instruc-
tion set, ARM processors also support a 16-bit Thumb instruction
set. Thumb instructions act as compact shorthands for a subset of
the 32-bit ARM instructions, allowing for improved code density.
Modern ARM processors extend the Thumb instruction set with 32-
bit instructions (distinct from those in the 32-bit ARM instruction
set) that may be intermixed with 16-bit Thumb instruction. The
resulting variable-length instruction set is referred to as Thumb-2.
Programs conforming to the ARM Architecture Procedure Call
Standard (AAPCS) [4] perform subroutine calls either through a
Branch with Link (bl) or Branch with Link and eXchange (blx).
These instructions load the address of the subroutine to the pc and
the return address to the link register (lr). The non-linking vari-
ants, Branch b and Branch and eXchange, are used to direct the
control ﬂow within subroutines as they update the pc, but leave
lr untouched. The ARM architecture provides no dedicated re-
turn instruction. Instead, any instruction that is able to write to the
program counter may function as an effective return instruction.

In order to faithfully reproduce the control ﬂow of the program
being attested, our instrumentation approach needs to be able to in-
tercept all instructions sequences that affect the control ﬂow of the
monitored program. On our evaluation platform programs execute
solely in the 32-bit ARM state, allowing us to instrument the pro-
gram binary such that all control-ﬂow instructions are replaced by
instructions that transfer control to a ﬁxed piece of code belonging
to the Runtime Tracer.
Binary rewriting. In the instrumentation phase, the original branch
targets for direct branch instructions are collected from the target
program binary to be stored at runtime in the read-only branch table
data structure that resides in target program memory. Each target
address is indexed in the branch table by the location of the orig-
inal branch instruction. These locations, the locations of indirect
branches, as well as other control-ﬂow instructions are overwrit-
ten with dispatch instructions that redirect program control ﬂow to
a short piece of assembler code, the trampoline. We use the bl
instruction as the dispatch instruction. The value of lr after the
dispatch is used to identify the call site of the trampoline. Our tool
utilizes the Capstone disassembly engine6 to identify control-ﬂow
instructions for rewriting.
Trampolines. Each different type of control-ﬂow instruction re-
quires a separate trampoline, but unlike previous work [14], our
approach does not leverage a separate trampoline for each instru-
mented branch. The trampoline manages the return address regis-
ter as well as the register holding the destination address in indirect
branches. If the original instruction was a non-linking branch, the
trampoline must retain the original link register value from the prior

6http://www.capstone-engine.org/

bl originally present in the executable, and restore the program
link register (to the value it had before the dispatch instruction)
upon returning to program code.

In order to avoid overwriting values stored in lr, the target pro-
gram must not use lr as a general purpose register. This can be
enforced at compile time using appropriate compiler options7.

During program execution, the trampoline will collect the return
address from lr and determine the original branch target. For di-
rect branches, the trampoline will look up the original destination
address from the branch table. For indirect branches, the trampo-
line will consult the corresponding register holding the destination
address, and for instructions utilized as function returns, the tram-
poline will either read the destination address from the stored lr
value, or read the return address from the program stack. It will
then invoke the Measurement Engine through a Secure World tran-
sition, passing as parameters the source and destination address.
After trampoline execution resumes, control is transferred back to
the target program, to the original branch destination.
Conditional branches. All conditional branch instructions in the
ARM instruction set have a linking bl variant that updates lr.
During instrumentation, we use the bl variant to redirect execu-
tion to the corresponding trampoline, but do not change the condi-
tion under which the branch is executed. Conditional branches that
are not taken must at runtime be inferred from the branch informa-
tion collected during the instrumentation phase, or by introspecting
the program code. In C-FLAT, we make the branch table avail-
able to the Measurement Engine, and infer non-taken conditional
branches based on the start of the previous basic block known to
the Measurement Engine, and the source address of the branch that
caused us to enter the Secure World.

6. EVALUATION
We evaluated our design and prototype implementation by apply-
ing C-FLAT to a real embedded application. This section describes
our case study application, explains the attestation results, and dis-
cusses runtime performance. The practical attacks and mitigations
we demonstrated using this case study are presented in Section 7.

6.1 Case Study of a Cyber-Physical System
A syringe pump is an electromechanical system designed to dis-
pense (or withdraw) precise quantities of ﬂuid. It is used in a vari-
ety of medical applications, especially those requiring small quan-
tities of medication to be administered relatively frequently. Many
research ﬁelds, including chemical and biomedical research, also
use syringe pumps. Commercial syringe pumps are usually expen-
sive, especially if they have been certiﬁed, but there has recently
been signiﬁcant interest in producing low-cost open-source alter-
natives [44].
Functionality. A syringe pump typically consists of a ﬂuid-ﬁlled
syringe, a controllable linear actuator (e.g., using a stepper motor),
and a control system. The control system’s task is relatively sim-
ple and would typically be implemented on an MCU – it translates
the desired input value (e.g., millilitres of ﬂuid) into the control
output for the actuator (e.g., setting a digital IO line high for a cal-
culated duration). However, given its intended usage, this system
must provide a very high degree of assurance that it is operating
correctly. In both commercial and open-source designs, the control
system may be a weak point since it runs embedded software and
accepts external input (potentially from remote sources). Unde-
tectable runtime attacks affecting either the control ﬂow or critical

7For instance GCC provides the -ffixed-lr option https://gcc.
gnu.org/onlinedocs/gcc-4.6.1/gcc/Global-Reg-Vars.html

data variables could have serious consequences. This is therefore a
prime use case for C-FLAT.
Open Syringe Pump. For this case study, we used Open Syringe
Pump, an open-source, open-hardware syringe pump design.8
It
is controlled by an Arduino MCU running an embedded applica-
tion written in Arduino Script. Since C-FLAT is not yet available
for this type of MCU, we ported the application to a Raspberry
Pi, which provides the required ARM TrustZone extensions. Other
open-source syringe pump designs already use the Raspberry Pi as
a controller (e.g., [44]), but run the control software as an appli-
cation on top of a Linux OS. To retain the embedded nature of the
controller, we chose to port Open Syringe Pump as a bare-metal im-
plementation, which removes potential vulnerabilities introduced
by an OS. Our port required only minimal changes to the source
code (less than 25% of the overall application) in order to adapt it
from Arduino Script to C. Neither the functionality nor the control-
ﬂow graph (CFG) of the application was changed. In terms of func-
tionality, this application reads user input via the serial connection,
and then performs one of the following types of actions:

• set-quantity: a numeric input changes a state variable

representing the quantity of ﬂuid to be used;

• move-syringe: a trigger input causes the syringe pump

to dispense or withdraw the set quantity of ﬂuid;

These types of actions naturally have different control ﬂows, but
even for the same action, the exact control ﬂow depends on the
state variable (i.e., the user-deﬁned quantity of ﬂuid). Overall, the
compiled application has a total of 13,000 instructions, and its static
CFG contains 332 unique edges, of which 20 are loops.

6.2 Attestation Results
We evaluated the functionality of our prototype implementation by
instrumenting the syringe pump controller application and attesting
the critical section of this application. Speciﬁcally, we attested the
sequence of actions that take place immediately after an external
input is provided. This ensures that any action which exercises the
critical functionality (e.g., causes the syringe to move) is covered
by the attestation, whilst eliminating irrelevant time periods when
the state of the system does not change. We supplied a range of
different inputs and recorded the resulting Auth values.

For the set-quantity path, the maximum length of Auth
was for any input value was 1527 bytes. This path contains 16
loop invocations, and 18 unique loop paths. Similarly, for the
move-syringe path, the maximum Auth length was 1179 bytes
(12 loop invocations and 14 unique paths).

As expected, whenever the same control-ﬂow path was taken
(e.g., set-quantity or move-syringe), the same ﬁnal hash
value was obtained. These hash values therefore enable the ver-
iﬁer to determine the precise control-ﬂow path that was actually
executed. In this application, these hash values remained the same
irrespective of the quantity of ﬂuid dispensed/withdrawn by the sy-
ringe. The reason for this is that the state variable is only used to
determine how many times a critical loop should be executed. The
value of the state variable is therefore captured entirely in the addi-
tional loop information provided with the attestation. Although the
purpose of this loop handling behavior is to overcome the exponen-
tial increase in complexity caused by loops, in this application (and
others like it) this also greatly simpliﬁes the attestation output.

6.3 Performance Impact
We measured the time taken to perform C-FLAT attestation in the
syringe pump case study in order to determine (a) which factors

affect the attestation overhead, and (b) whether this overhead is tol-
erable in real applications. All timing measurements were obtained
using the hardware’s built-in performance counters. It is important
to emphasize that, in a real-world deployment, this type of attes-
tation would not be used on every execution of the program. The
veriﬁer can choose when and how frequently to attest the prover.
Attestation overhead. We measured the time required to perform
a complete attestation of the system, whilst varying the applica-
tion’s state variable through a representative range of values (i.e.,
changing the ﬂuid quantity from 1 µL to 1000 µL). We use the
term control-ﬂow event to refer to any execution of a control-ﬂow
instruction (e.g., branch, return, etc.). In other words, a control-
ﬂow event is a traversal of an edge in the CFG. Since C-FLAT
executes its algorithm on every control-ﬂow event, the overall attes-
tation time varies depending on the number of control-ﬂow events,
as shown in Figure 9.

Figure 9: Attestation overhead (average over 20 repetitions)

The attestation overhead is linearly proportional to the number
of control-ﬂow events. This is as expected, since each control-ﬂow
event results in a trampoline invocation, a context switch, and an
execution of the relevant Secure World algorithm. The type of event
also impacts the overhead (e.g., loop handling is more costly), but
this is not visible in Figure 9 due to the large number of events.
The variance of these measurements is negligible, since there is no
other software running on the platform.

The attestation overhead can be decomposed into three categories:
i) trampolines, ii) context switches, and iii) the Secure World algo-
rithm. For both the set-quantity and move-syringe paths,
the relative percentage composition of the overhead remained roughly
constant, irrespective of the state variable. For the set-quantity
path, 8.3% of the overhead came from the trampolines, 11.9% from
the context switches, and 79.8% from the algorithm itself. These
ratios were similar for the move-syringe path at 10.2%, 17.5%,
and 72.3% respectively. As expected, the majority of the overhead
is due to the algorithm itself.
Performance impact. For the intended class of applications, this
overhead would not necessarily have an impact on the real-world
performance of the application.
In cyber-physical systems, the
main timing requirements usually arise from the system’s physical
processes and components (e.g., sensors and actuators), which op-
erate on comparatively slow physical timescales. For example, in
medical applications, typical ﬂow rates for a syringe pump system
could be 0.5 ml/h, 1.0 ml/h, and 2.0 ml/h.9 In our case study,
the attestation overhead is 1.2 s for dispensing 0.5 ml, 2.4 s for
1.0 ml, and 4.8 s for 2.0 ml. Therefore, the real-world attesta-
tion overhead for these parameters ranges from 0.03% to 0.13%.

8https://hackaday.io/project/1838-open-syringe-pump

9http://www.ncbi.nlm.nih.gov/pubmed/11032282

0102030405060012Control-ﬂowevents(x103)Totaloverhead(seconds)Timescales in the order of minutes or hours are common in cyber-
physical systems, for example, a typical embedded humidity sensor
could measure and report a value once every 15 minutes10, and an
embedded thermostat would not switch on a compressor unit more
than once every three minutes.11

Even if the attestation overhead begins to affect the system’s tim-
ing requirements, various strategies can be used to ameliorate this
situation. Firstly, we expect that the attestation would be run only
occasionally, at a time determined by the veriﬁer. When the ap-
plication is not being attested, the overhead decreases signiﬁcantly
(e.g., by 72% to 80% for the syringe pump). This strategy could
also be applied to other types of systems (e.g., attesting an embed-
ded system in a car while not in use).

Secondly, the application could be adapted to accommodate this
additional overhead. The above measurements were obtained by
applying C-FLAT to an unmodiﬁed application, but if the source
code is available, minor modiﬁcations could be made to the appli-
cation to compensate for the attestation overhead (e.g., reducing the
durations of application-deﬁned delay loops).
Implementation considerations. An unavoidable side-effect of
C-FLAT is that it may affect the way an application measures time.
If the application relies on time-calibrated loops to delay for a spe-
ciﬁc duration, the calibration will change when the application is
instrumented. Since the time spent in the Secure World varies de-
pending on the type of control-ﬂow operation, more complicated
and/or experimental calibration would be required. However, this
can be easily avoided by instead using well-deﬁned timing capabil-
ities, such as system timers.

6.4 Second Case Study
To further evaluate C-FLAT, we completed a second case study
using a signiﬁcantly larger application.

We applied C-FLAT to a soldering iron temperature controller,
which allows users to specify a desired temperature and maintains
the soldering iron at that temperature using a proportional-integral-
derivative (PID) controller.12 This type of system could also be
used to control temperature in other settings, such as a building or
an industrial process, and thus is representative of a large class of
cyber-physical systems. This application is signiﬁcantly larger than
the syringe pump as it consists of 70,000 instructions and has 1,020
static control-ﬂow edges of which 40 are loops.

The security-critical functionality is the PID controller, which
continuously reads the current temperature, compares it to the de-
sired temperature, and calculates the PID output to adjust the tem-
perature. We instrumented the application to attest the control ﬂow
of this critical section, and veriﬁed that the correct hash values were
obtained. The total overhead added by C-FLAT to a single itera-
tion of the PID controller was 237 µs (average over 100 runs) with
a standard deviation of 1 µs. As before, this overhead is signif-
icantly lower than the physical timescales on which these cyber-
physical systems operate (e.g. attesting the controller once per sec-
ond results in 0.03% overhead). For this attestation, the maximum
length of Auth was 490 bytes.

7. SECURITY CONSIDERATIONS
In this section, we evaluate the security guarantees provided by C-
FLAT based on practical embedded exploits and different runtime
exploitation techniques. Note that our discussion refers to the run-

10http://vanderleevineyard.com/1/category/vinduino/1.html
11https://github.com/bbustin/climaduino/tree/develop
12https://create.arduino.cc/projecthub/sfrwmaker/
soldering-iron-controller-for-hakko-907-8c5866

time attack threat model outlined in Figure 1. The security of C-
FLAT itself is described alongside the implementation in Section 5.
As explained in that section, the integrity of the Runtime Tracer is
ensured through static attestation, and the integrity of the measure-
ment engine is protected by the trust anchor (e.g., the TrustZone
Secure World). As usual, the freshness of the attestation is guaran-
teed by the challenge-response protocol between Prv and Ver (as
described in Section 3).
Exploiting the syringe program. We constructed three exploits
that affect the move-syringe function. Our ﬁrst attack exploits
a self-implanted memory error to trigger the movement of the sy-
ringe pump although no movement has been requested. As a con-
sequence, liquid is dispensed at an unexpected time. We imple-
mented this attack by reverse-engineering the syringe program bi-
nary and searching for return-oriented gadgets that allow us to load
a function argument into ARM register r0 and transfer control to
the move-syringe function. We were able to construct a suit-
able gadget chain to implement this attack. With C-FLAT enabled,
we could detect this attack since the gadget chain leads to an unex-
pected hash measurement indicating to the veriﬁer that a malicious
program path has been executed.

Our second exploit is based on a non-control-data attack: it cor-
rupts a local state variable that controls the amount of liquid to
use. This variable is used to determine the number of iterations of
the critical loop in order to dispense the correct amount of ﬂuid.
Hence, this attack does not violate the program’s CFG. However,
for the case of the syringe program, the loop iterations indicate to
the veriﬁer how much liquid has been dispensed. Again, we can de-
tect this attack with C-FLAT since the precise loop iteration counts
are reported in the attestation response.

Our third exploit, a non-control-data attack, corrupts the static
key-map array used for processing input from the keypad. When
a key is pressed, the keypad produces an analog value in a pre-
deﬁned range, which is read by the program. The program iterates
through a key-map array of known ranges, checking whether the
analog input is the range for any recognized key. By changing the
pre-deﬁned ranges in the key-map array, our attack misleads the
program into believing that a physical key has been pressed, thus
causing the program to perform the relevant action (e.g. the right
key triggers the move-syringe function, causing the syringe to
dispense liquid). This attack can be detected by C-FLAT because
the number of iterations of the key processing loop reveals which
key appears to have been pressed. Assuming the veriﬁer knows
that the physical key has not been pressed, this can therefore be
identiﬁed as unintended behavior.
Code Injection. Conventional control-ﬂow hijacking attacks rely
on the injection and execution of malicious code [2]. For this, the
attacker needs to inject the malicious code into the data space of
an application and corrupt control-ﬂow information to redirect the
execution to the injected code. Since malicious code resembles a
new unknown node NX (see Figure 1), C-FLAT can easily detect
this attack. The reported hash value will include node NX although
it does not belong to the original control-ﬂow graph (CFG) of the
application. To undermine C-FLAT detection, an attacker may at-
tempt to overwrite an existing node, e.g., replacing the benign Node
N2 with NX . However, such an attack is not directly possible as
we target platforms (see Section 3.2) that enforce data execution
prevention (DEP). Hence, the memory area of node N2 is not ex-
ecutable and writable at the same time. Furthermore, the so-called
multi-stage exploits which deploy code-reuse attack techniques in
the ﬁrst place to mark the code region as writable and inject ma-
licious code thereafter are not feasible under C-FLAT, because

C-FLAT will report the execution of the corresponding memory
modiﬁcation system calls (hereafter denoted as mem-calls).

The only possibility to launch a code injection attack requires a
program that benignly mem-calls to change memory permissions
of code pages. For such cases, the attacker only corrupts input ar-
guments to the mem-calls so that node N2 is eventually overwritten
with NX . These attacks resemble pure data-oriented exploits since
they do not require any code pointer corruption. As such, they can-
not directly be detected by means of control-ﬂow attestation. On
the other hand, if the injected code performs unexpected calls to
benign code, C-FLAT can still detect this pure data-oriented at-
tack since an unknown hash value would be calculated.
Return-oriented programming. Code-reuse attacks that only ma-
liciously combine benign code snippets from different parts of the
program are more challenging to detect because they do not inject
any new nodes. The most prominent instantiation is return-oriented
programming [38]. It combines short code sequences, each end-
ing in a return instruction, to generate a new malicious program.
C-FLAT is able to detect return-oriented programming (includ-
ing just-in-time return-oriented programming [39]) since unknown
control-ﬂow edges are taken upon execution of a return.

In general, these attacks exploit return instructions to transfer
control to either (i) an arbitrary instruction in the middle of a CFG
node, (ii) the beginning of an arbitrary CFG node to which no valid
control-ﬂow edge exists, e.g., the attack path from N3 to N2 in Fig-
ure 1, or (iii) another valid CFG node that is not the actual caller,
i.e., originating node. Case (i) is detected by C-FLAT since no
valid measurement can be generated when a node is not executed
from its original beginning; even for nodes to which valid control-
ﬂow edges exist. For instance, if an attacker exploits the vulnera-
bility in N3 to target an instruction in the middle of the otherwise
valid node N6, the reported hash value will be different to the one
expected. This is due to the fact that our measurement includes
source and end address of each node visited.

For Case (ii), the attacker follows a control-ﬂow path that is not
part of the CFG, e.g., node N3 has no connection to node N2. Due
to the missing control-ﬂow edge, the measurement will output an
unknown hash value.

The last case is challenging to handle since the attacker targets a
valid CFG node, i.e., there exists a valid control-ﬂow edge but the
current context indicates that the control-ﬂow edge should not have
been taken. We already discussed such scenarios in Section 4.2 for
the call-return matching. C-FLAT indexes control-ﬂow edges for
function calls and returns to detect call-return mismatches. While
this strategy works without special effort for direct function calls,
indirect calls still pose an extra obstacle since static analysis may
fail in resolving their target nodes. For those calls that static analy-
sis cannot resolve, one can either leverage dynamic analysis or do
an over-approximation by allowing each return instruction to target
the instruction right after an unresolved indirect call. Note that this
trade-off is not speciﬁc to our scheme, but a general problem in
control-ﬂow analysis. However, as we have shown in Section 6.1,
embedded codes are typically tailored to a speciﬁc use-case allow-
ing us to perform precise CFG analysis.
In fact, basic dynamic
analysis quickly allowed us to identify the valid paths in our sy-
ringe pump example.
Jump-oriented programming. Another variant of return-oriented
programming are jump-oriented programming attacks [9, 6]. These
attacks exploit indirect jump and call instructions at the end of each
invoked code sequence. Similar to return-oriented programming,
C-FLAT detects these attacks since they deviate the program’s
control ﬂow to an unintended CFG node. As long as static or dy-
namic analysis identiﬁes the set of target addresses, we are able

to determine valid measurements for each indirect jump and call
thereby allowing C-FLAT to detect malicious control-ﬂow devia-
tions incurred by jump-oriented programming.
Function-reuse attacks. Function-reuse attacks invoke a mali-
cious chain of subroutines. Typically, these attacks are leveraged
to undermine mitigation schemes that speciﬁcally aim at detecting
return-oriented programming attacks. C-FLAT detects function-
reuse attacks since it attests the program’s entire control ﬂow, i.e.,
it also captures the order in which functions are executing. For in-
stance, the counterfeit object-oriented programming (COOP) [35]
exploitation technique abuses a loop gadget to invoke a chain of
C++ virtual methods. C-FLAT attests the execution within the
loop, i.e., the number of times the loop has executed, and the or-
der of virtual methods being called. Since the invoked chain does
not resemble benign program execution, the resulting hash value
will indicate to the veriﬁer that a malicious path has been executed.
Non-control-data attacks. Non-control-data attacks manipulate
variables that affect the program’s control ﬂow [11], e.g., to exe-
cute the privileged attack path (iii) in Figure 1. C-FLAT is able
to detect these attacks as each individual control-ﬂow path leads to
a different measurement. Hence, the veriﬁer Ver can immediately
recognize which path has been taken by the program at the prover’s
device Prv. Another example is our attack reported in Section 7
which only modiﬁes a data variable to manipulate the amount of
liquid dispensed through the syringe pump. Since the amount of
liquid dispensed is proportional to the number of times a loop has
executed, and that number is reported in the attestation response,
Ver can detect the malicious modiﬁcation by validating the loop
counters.

8. DISCUSSION
Towards control-ﬂow attestation of MCUs. The Raspberry Pi
series of credit card-sized single-board computers have a become
a popular platform among developers, researchers and hobbyists
for building embedded applications. Raspberry Pi 2 represents the
higher-end of the embedded device spectrum. The hardware trust
anchor for the isolation of the C-FLAT Measurement Engine is
TrustZone-A, an architectural feature in ARM application cores
that has successfully been used as a hardware base for Trusted Exe-
cution Environments in mobile phones for the last decade, and has
also made inroads in the top-end Internet of Things (IoT) processor
families.

The Microcontroller (MCU) market for embedded computing
in industry, automotive and home is rapidly moving towards 32-
bit processing cores at the expense of small 8- and 16 bit con-
trollers. For the latest version of its MCU core line (ARM-M),
ARM introduced TrustZone-M [45] – hardware primitives for iso-
lating security-critical functionality such as ﬁrmware upgrades or
secure channel establishment from the rest of the controller soft-
ware. Intel’s TrustLite [23] provide very similar functionality. Both
TrustZone-M and TrustLite can provide the necessary hardware
fundament to implement C-FLAT on IoT MCUs.
Reducing context switch overhead. There are several optimiza-
tion strategies depending on the properties of underlying secure
hardware. On platforms equipped with a full-featured TEE, the
context switch into the Secure World is expensive. In the case of
TrustZone-A on an ARMv8 Cortex-A53 the context switch is ap-
proximately 3700 cycles or 5µs at 800MHz [32]. In the TrustZone-
A architecture, the transition between the Secure and Non-Secure
modes occurs via hardware exceptions mediated by a special ex-
ception handler referred to as the Secure Monitor. The transition
can only be triggered from the Non-Secure World privileged mode.
Under these circumstances, overall performance can be increased

by caching control-ﬂow information in the Non-Secure World be-
fore transferring it in bulk to Measurement Engine in the Secure
World.

Hardware security architectures for highly resource constrained
embedded devices, such as TrustLite or TrustZone-M, reduce the
switching overhead associated with trusted application invocation
to a few cycles. For example, TrustZone-M has no need for a ded-
icated Secure Monitor context. The transition between Secure and
Non-Secure Worlds is handled by the processor circuitry indepen-
dently of software through a mechanism based on protection re-
gions with marked call gates enforced by the Memory Protection
Unit.
Embedded operating systems. While the prover in our current
prototype runs unassisted on bare-metal, many IoT devices feature
embedded operating systems. The main purpose of an embedded
OS (e.g., FreeRTOS13, Zephyr14, ChibiOS15) is to schedule tasks
or functions, often based mainly on interrupt input. The OS may
also provide memory management for the tasks and support de-
bugging. A real-time OS adds pre-emptive scheduling to provide
timing guarantees for individual tasks. However, hardware in con-
trollers traditionally do not support many processing contexts or
memory protection to achieve isolation between tasks or even be-
tween OS and application. From a security perspective, C-FLAT
on such devices should therefore consider a single isolation domain
even if an OS is present, and instrument the OS as a single bare-
metal program.
Thumb-2 instrumentation. Modern ARM-M MCUs utilize the
Thumb-2 instruction set because of its improved code density in
order to maximize the usage off on-chip Flash memory. In ongoing
work, we enhance our instrumentation approach to include support
for the variable-length Thumb-2 instructions.
Data-ﬂow attestation. As already mentioned in Section 2, we fo-
cus on control-ﬂow related attacks. On the other hand, pure data-
oriented attacks can lead to leakage of sensitive information, e.g.,
a data pointer that is processed in a network operation is altered to
point to sensitive information. Hence, in our future work we will
explore data-ﬂow attestation, i.e., mechanisms that allow us to track
data pointers and validate function arguments and return values.
Probe-based runtime attestation. In our ongoing work, we ex-
plore control-ﬂow attestation for larger and very complex programs,
i.e., programs with a complex control-ﬂow graph that contains a
large number of different program paths. These might lead to a
combinatorial explosion of valid hash values thereby rendering val-
idation cumbersome. To support such programs, we envision probe-
based attestation that (i) generates and reports a cumulative hash for
program segments, e.g., reporting an authenticator for each subrou-
tine, and (ii) allows probing a program during its execution. The
latter enables an interactive attestation protocol in which Ver can
repeatedly validate the evolution of the program execution at arbi-
trary time intervals.

9. RELATED WORK
Prior work on static attestation falls into three main categories: (1)
TPM-based, (2) software-based, and (3) hybrid. Although TPMs
and subsequent techniques (e.g., [29, 28]) are pervasive in PCs,
they are not well-suited for low-end embedded devices due to their
relatively high cost. Meanwhile, software-based methods (e.g.,
SWATT [37], Pioneer [36], and VIPER [27]) can be used – un-
der some strict assumptions – for static attestation of certain legacy

13http://www.freertos.org/
14https://www.zephyrproject.org/
15http://www.chibios.org

devices, such as peripherals. Between these two extremes, hybrid
schemes such as SMART [17], TrustLite [23], and TyTAN [7] re-
quire minimal hardware trust anchors in order to provide strong re-
mote attestation guarantees. C-FLAT is complementary to all these
schemes in that it attests runtime behavior, which is orthogonal to
static attestation.

Mitigation of runtime exploits is an ongoing research ﬁeld with
many solutions proposed over the last few years [41]. The main di-
rections are control-ﬂow integrity (CFI) [1] and ﬁne-grained code
randomization [12, 26]. The former ensures that a program only
follows a valid path in the program’s CFG. Many improvements
have been made in the last years making CFI an efﬁcient and ef-
fective mitigation technology [46, 42]. On the other hand, CFI
does not cover non-control-data attacks which lead to execution of
unauthorized but valid CFG paths. The latter randomizes the code
layout by randomizing the order of memory pages, functions, ba-
sic blocks, or instructions [26]. However, the attacker can still ex-
ploit branch instructions to jump at her target address of choice. As
such, code randomization cannot provide control-ﬂow information
which would allow Ver to attest the program’s execution. Another
scheme is code-pointer integrity (CPI) [25] which aims at ensur-
ing the integrity of code pointers. While it provides high assurance
against control-ﬂow hijacking attacks, it does not provide any in-
formation on the actual control-ﬂow path taken. As such, similar to
CFI, CPI does not cover non-control data attacks.

Property-based attestation explores behavioral characteristics be-
yond hash values of applications’ binaries [34]. However, such
schemes typically require a trusted third-party. Software-based at-
testation enables remote attestation for embedded devices without
requiring a trust anchor [37]. The measurement is based on the cal-
culation of a hash over the application’s code memory, where the
attestation is only successful if the prover responds in a certain time
interval. However, this assumes no noise on the channel, and re-
quires the hash function to be optimal. Semantic remote attestation
enables attestation of program behavior by enforcing local policies
at the Java bytecode layer [19]. Unlike C-FLAT, neither property-
based, semantic, nor software-based attestation cover control-ﬂow
attacks at the binary level.

There also exist several approaches to enable dynamic remote
attestation: ReDAS [21] explores runtime properties such as the in-
tegrity of a function’s base pointer. While checking against such
properties enhances static remote attestation, it only captures spe-
ciﬁc application ﬁelds and pointers rather than the whole control-
ﬂow path. Trusted virtual containers [5] allow control-ﬂow attes-
tation but at a coarse-grained level. That is, they only attest the
launch order of applications modules, but not the internal control
ﬂows of an application. Lastly, DynIMA [16] explores taint anal-
ysis to achieve runtime attestation. However, its implementation
only validates invariants on return instructions such as the number
of instructions executed between two consecutive returns.

10. CONCLUSION
Memory corruption attacks are prevalent on diverse computing plat-
forms and can lead to signiﬁcant damage on embedded systems that
are increasingly deployed in safety-critical infrastructures. In par-
ticular, there is not yet a mechanism that allows precise veriﬁcation
of an application’s control ﬂow to detect such attacks. C-FLAT
tackles this problem by means of control-ﬂow attestation allow-
ing a veriﬁer to detect control-ﬂow deviations launched via code
injection, code-reuse, or non-control-data attacks. Our prototype
implementation on an ARM-based Raspberry Pi demonstrates that
C-FLAT can be leveraged to detect different runtime exploitation
techniques launched against embedded software such as a syringe

pump program, i.e., C-FLAT detects when an attacker manipulates
the amount of liquid dispensed through the syringe. The source
code of C-FLAT is available at https://goo.gl/pTiVdU.

11. ACKNOWLEDGMENTS
This work was supported in part by the Intel Collaborative Insti-
tute for Secure Computing at TU Darmstadt and Aalto University.
This work was also supported in part by the Academy of Finland
(283135), Tekes (1226/31/2014), the German Science Foundation
(project S2, CRC 1119 CROSSING), the European Union’s Sev-
enth Framework Programme (643964, SUPERCLOUD), and the
German Federal Ministry of Education and Research within CRISP.
At UC Irvine, this research was supported by funding from the Na-
tional Security Agency (H98230-15-1-0276) and the Department
of Homeland Security (under subcontract from the HRL Laborato-
ries).

12. REFERENCES

[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti.

Control-ﬂow integrity: Principles, implementations, and
applications. ACM TISSEC, 13(1), 2009.

[2] Aleph One. Smashing the stack for fun and proﬁt. Phrack

Magazine, 49(14), 2000.

[3] ARM Limited. ARM Security Technology - Building a Secure

System using TrustZone Technology, 2009.

[4] ARM Ltd. Procedure call standard for the ARM architecture,

2009.

[5] K. A. Bailey and S. W. Smith. Trusted virtual containers on

demand. In ACM-CCS-STC, 2010.

[6] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang.

Jump-oriented programming: A new class of code-reuse
attack. In ACM ASIACCS, 2011.

[7] F. Brasser, B. El Mahjoub, A.-R. Sadeghi, C. Wachsmann,

and P. Koeberl. TyTAN: Tiny Trust Anchor for Tiny Devices.
In ACM/IEEE Design Automation Conference, 2015.

[8] E. Buchanan, R. Roemer, H. Shacham, and S. Savage. When
good instructions go bad: Generalizing return-oriented
programming to RISC. In ACM CCS, 2008.

[9] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi,

H. Shacham, and M. Winandy. Return-oriented programming
without returns. In ACM CCS, 2010.

[10] D. D. Chen, M. Egele, M. Woo, and D. Brumley. Towards

automated dynamic analysis for Linux-based embedded
ﬁrmware. In ISOC NDSS, 2016.

[11] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer.

Non-control-data attacks are realistic threats. In USENIX
Security, 2005.

[12] F. B. Cohen. Operating system protection through program

evolution. Computer & Security, 12(6), 1993.

[13] A. Costin, J. Zaddach, A. Francillon, and D. Balzarotti. A

large scale analysis of the security of embedded ﬁrmwares.
In USENIX Security, 2014.

[14] L. Davi, A. Dmitrienko, M. Egele, T. Fischer, T. Holz,
R. Hund, S. Nürnberger, and A.-R. Sadeghi. MoCFI: A
framework to mitigate control-ﬂow attacks on smartphones.
In ISOC NDSS, 2012.

[15] L. Davi, D. Lehmann, A.-R. Sadeghi, and F. Monrose.
Stitching the gadgets: On the ineffectiveness of
coarse-grained control-ﬂow integrity protection. In USENIX
Security, 2014.

[16] L. Davi, A.-R. Sadeghi, and M. Winandy. Dynamic integrity
measurement and attestation: towards defense against
return-oriented programming attacks. In ACM CCS-STC,
2009.

[17] K. Eldefrawy, G. Tsudik, A. Francillon, and D. Perito.

SMART: secure and minimal architecture for (establishing
dynamic) root of trust. In ISOC NDSS, 2012.

[18] A. Francillon and C. Castelluccia. Code injection attacks on

Harvard-architecture devices. In ACM CCS, 2008.
[19] V. Haldar, D. Chandra, and M. Franz. Semantic remote

attestation: A virtual machine directed approach to trusted
computing. In Virtual Machine Research And Technology
Symposium, 2004.

[20] H. Hu, S. Shinde, S. Adrian, Z. L. Chua, P. Saxena, and

Z. Liang. Data-oriented programming: On the effectiveness
of non-control data attacks. In IEEE S&P, 2016.

[21] C. Kil, E. Sezer, A. Azab, P. Ning, and X. Zhang. Remote

attestation to dynamic system properties: Towards providing
complete system integrity evidence. In IEEE/IFIP DSN,
2009.

[22] P. Kocher, R. Lee, G. McGraw, and A. Raghunathan.

Security as a new dimension in embedded system design. In
ACM/IEEE Design Automation Conference, 2004.

[23] P. Koeberl, S. Schulz, A.-R. Sadeghi, and V. Varadharajan.

TrustLite: A security architecture for tiny embedded devices.
In ACM SIGOPS EuroSys, 2014.

[24] T. Kornau. Return oriented programming for the ARM

architecture. Master’s thesis, Ruhr-University Bochum, 2009.

[25] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar,

and D. Song. Code-pointer integrity. In USENIX OSDI, 2014.

[26] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz. SoK:
Automated software diversity. In IEEE S&P, 2014.
[27] Y. Li, J. M. McCune, and A. Perrig. VIPER: Verifying the
Integrity of PERipherals’ Firmware. In ACM CCS, 2011.
[28] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor,

and A. Perrig. TrustVisor: Efﬁcient TCB reduction and
attestation. In IEEE S&P, 2010.

[29] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: An execution infrastructure for TCB
minimization. In ACM SIGOPS EuroSys, 2008.
[30] Microsoft. Data execution prevention (DEP), 2006.
[31] J. Noorman, P. Agten, W. Daniels, R. Strackx, A. V.

Herrewege, C. Huygens, B. Preneel, I. Verbauwhede, and
F. Piessens. Sancus: Low-cost trustworthy extensible
networked devices with a zero-software trusted computing
base. In USENIX Security, 2013.

[32] M. Paolino, A. Rigo, A. Spyridakis, , J. Fanguède, P. Lalov,

and D. Raho. T-KVM: A trusted architecture for KVM ARM
v7 and v8 virtual machines. In IARIA Cloud Computing,
2015.

[33] R. Roemer, E. Buchanan, H. Shacham, and S. Savage.

Return-oriented programming: Systems, languages, and
applications. ACM TISSEC, 15(1):2:1–2:34, 2012.

[34] A.-R. Sadeghi and C. Stüble. Property-based attestation for

computing platforms: Caring about properties, not
mechanisms. In NSPW, 2004.

[35] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R.
Sadeghi, and T. Holz. Counterfeit object-oriented
programming: On the difﬁculty of preventing code reuse
attacks in C++ applications. In IEEE S&P, 2015.

[36] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and

P. Khosla. Pioneer: Verifying Code Integrity and Enforcing
Untampered Code Execution on Legacy Systems. In ACM
SIGOPS Operating Systems Review, 2005.

[37] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla.

SWATT: Software-based attestation for embedded devices.
In IEEE S&P, 2004.

[38] H. Shacham. The geometry of innocent ﬂesh on the bone:

Return-into-libc without function calls (on the x86). In ACM
CCS, 2007.

[39] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko,

C. Liebchen, and A.-R. Sadeghi. Just-in-time code reuse: On
the effectiveness of ﬁne-grained address space layout
randomization. In IEEE S&P, 2013.

[40] Solar Designer. lpr LIBC RETURN exploit, 1997.
[41] L. Szekeres, M. Payer, T. Wei, and D. Song. Sok: Eternal

war in memory. In IEEE S&P, 2013.

[42] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway,

Ú. Erlingsson, L. Lozano, and G. Pike. Enforcing
forward-edge control-ﬂow integrity in GCC & LLVM. In
USENIX Security, 2014.

[43] J. Viega and H. Thompson. The state of embedded-device
security (spoiler alert: It’s bad). IEEE Security & Privacy,
10(5):68–70, 2012.

[44] B. Wijnen, E. J. Hunt, G. C. Anzalone, and J. M. Pearce.

Open-source syringe pump library. PloS one, 9(9):e107216,
jan 2014.

[45] J. Yiu. ARMv8-M architecture technical overview.

https://community.arm.com/docs/DOC-10896, 2015.
[46] M. Zhang and R. Sekar. Control ﬂow integrity for COTS

binaries. In USENIX Security, 2013.

