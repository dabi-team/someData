Secure distributed adaptive optimal coordination of
nonlinear cyber-physical systems with attack diagnosis

⋆

0
2
0
2

p
e
S
7
2

]

Y
S
.
s
s
e
e
[

1
v
9
3
7
2
1
.
9
0
0
2
:
v
i
X
r
a

Liwei An a, Guang-Hong Yang a,b

aCollege of Information Science and Engineering, Northeastern University, Shenyang 110819, P.R.China

bState Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang 110819, P.R.China

Abstract

This paper studies the problem of distributed optimal coordination (DOC) for a class of nonlinear large-scale cyber-physical
systems (CPSs) in the presence of cyber attacks. A secure DOC architecture with attack diagnosis is proposed that guarantees
the attack-free subsystems to achieve the output consensus which minimizes the sum of their objective functions, while the
attacked subsystems converge to preset secure states. A two-layer DOC structure is established with emphasis on the interactions
between cyber and physical layers, where a command-driven control law is designed that generates provable optimal output
consensus. Diﬀering from the existing fault diagnosis methods which are generally applicable to given failure types, the focus of
the attack diagnosis is to achieve detection and isolation for arbitrary malicious behaviors. To this end, double coupling residuals
are generated by a carefully-designed distributed ﬁlter. The adaptive thresholds with prescribed performance are designed
to enhance the detectability and isolability. It is theoretically guaranteed that any attack signal cannot bypass the designed
attack diagnosis methodology to destroy the convergence of the DOC algorithm, and the locally-occurring detectable attack
can be isolated from the propagating attacks from neighboring subsystems. Simulation results for the motion coordination of
multiple remotely operated underwater vehicles illustrate the eﬀectiveness of the proposed architecture.

Key words: Cyber-physical systems, distributed optimization, attack diagnosis, nonlinear systems, adaptive control.

1 Introduction

Recently, Cyber-Physical Systems (CPSs), which closely
connect cyber and physical worlds, have gained much
research interest in many ﬁelds, such as computer ﬁeld,
control ﬁeld, battle ﬁeld. By utilizing the close interac-
tion between cyber and physical parts, the “intelligence”
of physical systems can be suﬃciently enhanced in order
to fulﬁl some complex, precise or dangerous tasks, such
as remote diagnosis, deep sea exploration [1]. However,
the networked connection between cyber and physical
parts also often leads to large attack space, such that
the CPSs are vulnerable to various types of adversarial
attacks. Some famous examples such as the Maroochy
water breach [2] and Stuxnet [3] indicate the CPS secu-
rity as a fundamental issue to be studied.

With potential applications of distributed optimiza-

⋆ This paper was not presented at any IFAC meeting. Cor-
responding author: Guang-Hong Yang. Tel. +XXXIX-VI-
mmmxxi. Fax +XXXIX-VI-mmmxxv.

Email addresses: liwei.an@foxmail.com (Liwei An),
yangguanghong@ise.neu.edu.cn (Guang-Hong Yang).

tion in large-scale CPSs [21], many important results
on discrete- or continuous-time DO algorithms have
been reported [4,5,6,7,8]. In these algorithms, each in-
dividual (or said agent in multi-agent systems) only
performs the designed optimization dynamics, ignoring
its own dynamics. Note that the physical dynamic sys-
tems are usually indispensable parts for achieving DO
task, such as the cooperative search of radio sources
[9], the motion coordination [14] and the distributed
optimal power ﬂow [10,11]. Hence,
it is relevant to
study the distributed optimization problems together
with physical dynamics, termed distributed optimal co-
ordination (DOC). In fact, the DOC can be completed
based on the CPS architecture by eﬀectively combining
of cyber computation/communication and physical dy-
namics/control [12]. Recently, many important results
for DOC have been reported for multi-agent system
with various physical dynamics by designing integrated
closed-loop control laws, such as integrator-type dynam-
ics [13,14,15], continuous-time linear dynamics [16,17],
Euler-Lagrangian dynamics [12]. More references for
DOC can be found in [18]. Motivated by these and
considering the non-ignorable nonlinear uncertain dy-
namics in many physical agents [40,41,12], this paper

Preprint submitted to Automatica

29 September 2020

 
 
 
 
 
 
investigates the DOC problem for a class of certain
nonlinear large-scale systems on the CPS platforms.

Given the growing threat of malicious attacks in large-
scale (and safety-critical) CPSs, the vulnerability of
consensus-based DOC algorithms is also with respect to
cyber attacks. Hence, the other main objective of this
paper is to address the issue of security of consensus-
based DOC dynamics by providing certain safety guar-
antees based on attack diagnosis. The recent works
[20,21,22] also consider the problem of resilient DO un-
der diﬀerent adversarial models than the ones that we
consider here, and the agent’s own physical dynamics
is not considered there. Other related important works
on distributed/decentralized sensor fault diagnosis and
secure state estimation against sensor attacks for large-
scale CPSs have been reported in [24,25,26,27,28,29,30].
In the existing fault diagnosis and fault-tolerant results,
the fault detectors are in general designed for given fail-
ure types [42,43], such as loss of eﬀectiveness [27], bias
faults [24,25,26]. As we will see later, in our problem for-
mulation the attack model can be considered to contain
inﬁnite number of failure types and one cannot aﬀord to
construct a fault detector for each possible failure type.
In [28,29,30], the attack-resilient mechanisms are de-
signed in the presence of arbitrary adversarial behaviors
under the framework of distributed estimation, outside
of DOC framework.

In this paper, we propose a secure DOC architecture for
a class of nonlinear large-scale CPSs in the presence of
cyber attacks. The overall architecture consists of cy-
ber and physical parts, and each physical subsystem is
modeled as a nonlinear parametric strict-feedback sys-
tem equipped with a dedicated decision-making agent
in the cyber superstratum. The cyber core (multi-agent
network) focuses on the design of DOC and attack diag-
nosis, and the physical part performs the corresponding
optimization task following the cyber-core control com-
mand. The objective is to steer the physical systems to
achieve the output consensus at the minimizer of a given
team performance function in a distributed fashion and
provide certain safety guarantees based on attack diag-
nosis. The contributions of this paper are threefold.

The ﬁrst contribution of this paper is, diﬀering from the
existing integrated closed-loop control schemes proposed
in [12,13,14,15,16,17], to propose a two-layer DOC struc-
ture where the cyber-layer optimizer generates a con-
trol command which is transmitted to the physical-layer
control for local regulation. To overcome the diﬃculty
caused by the dynamic mismatch between the tradi-
tional DO algorithms [4,5,6,7,8] and adaptive backstep-
ping control systems [36,37,38,39], a novel command-
driven control strategy is designed. It is proved that the
proposed algorithm ensures all subsystems to achieve
the optimal consensus under the healthy (attack-free)
environment.

2

As the second contribution, we provide the design and
analysis of an attack detection and isolation (ADI)
methodology. The existing fault diagnosis schemes are
usually designed for given fault types [42,43] and can-
not guarantee the detectability for arbitrary malicious
behaviors in theory. Also, due to the coupling eﬀects of
multiple propagated attacks on the physical dynamics
and cyber dynamics which are interacted, the attack
isolation becomes more challenging. To this end, double
coupling residuals and analytical redundancy relations
(ARRs) are generated by a carefully-designed dis-
tributed ﬁlter. The adaptive thresholds with prescribed
performance are designed to enhance the detectability
and isolability. It is theoretically guaranteed that any
attack signal cannot bypass the ADI methodology to
destroy the convergence of the DOC algorithm, and
the locally-occurring detectable attacks can be isolated
from the propagating attacks from the neighboring
subsystems.

The last contribution is to develop a secure version of the
DOC protocol based on the ADI methodology, which can
provide a safety guarantee in the sense that the healthy
physical subsystems (satisfying ARRs) reach the output
consensus at the optimal solution of the sum of their ob-
jective functions, while the attacked physical subsystems
(not satisfying ARRs) converge to preset secure states.

2 Preliminaries

2.1 Notations

The symbols R and B denote the set of real and Boolean
numbers, respectively. Cn
m represents the set of n-order
diﬀerentiable m-dimension function vectors. The cardi-
nality of a set S is denoted by
stand for
the Kronecker product and Hadamard product, respec-
tively. For a given time interval Ξ, ν(Ξ) represents its
) represents the sign function.
Lebesgue measure. sgn(
·
RN . For a vector sequence
, 1]T
Denote 1N = [1,
N
Y (j)
j=1, we denote the notation Y = vec(Y (1),
,
{
Y (N )) if not speciﬁed.

and

S
|

· · ·

· · ·

⊗

∈

◦

}

|

.

2.2 Graph theory

,

{

}

G

V

=

· · ·

v1,

= (

, vN

E
, a set of edges (or links)
wij

V
an adjacency matrix A =
element wij > 0 if (vi, vj )
The neighbors of vertex vi
Ni =

A weighted undirected graph
, A) consists of
N vertices (or nodes, or agents in multi-agent networks)
and
N ×N with nonnegative
}
and wij = 0 otherwise.
are denoted by the set
. The Laplacian matrix
is deﬁned as lii =
= j. For an undirected
−
is symmetric and semi-positive. A
is a sequence

= (lij)N ×N associated with graph
N
j=1 wij and lij =

graph, the matrix
L
P
path from vertex vi to vertex vj in graph

{
∈ E
∈ V
∈ E}

E ⊂ V ×V

: (vj, vi)

wij for i

∈ V

vj

L

G

{

G

6
, (vik , vj) in the graph with
of edges (vi, vi1 ), (vi1 , vi2 ),
· · ·
. An undirected graph is connected
distinct nodes vik ∈ V
if there is a path from every vertex to other vertex in the
graph.

3 DOC architecture

· · ·

, N is described by the pair (

Consider a CPS consisting of N subsystems, which aims
at achieving the DOC task. The jth subsystem, j =
(j)
1,
C
denotes the cyber part which is responsible for task
(j) denotes the physical part
decision-making, while
which is responsible for task execution. The physical part

P
(j) is modeled as a nonlinear dynamical system

(j)), where

(j),

P

C

P

i+1(t) + ϕ(j)
i (t) =x(j)
˙x(j)
˙x(j)
n (t) =βju(j)(t) + ϕ(j)
y(j)(t) =x(j)
1 (t) + a(j)(t)

i

i (¯x(j)
(t))θj
n (x(j)(t))θj ,

Σ(j) : 


(1)



∈

(t)

∈
∈

· · ·
, x(j)

i (¯x(j)(t))

, n
−
i (t))
∈

Rm, ¯x(j)
1, x(j)
i
i
∈
Rim, x(j)(t) = vec(x(j)
1 (t),
· · ·
Rnm is the measurable state; u(j)(t)
Rm×p and βj

(t) =
where i = 1,
vec(x(j)
,
1 (t),
· · ·
x(j)
Rm is
n (t))
the control input; ϕ(j)
Rm×m
∈
Rp is unknown con-
are known nonsingular matrix; θj
Rm is the output measurement trans-
stant; y(j)(t)
∈
mitted to the cyber superstratum through a wireless
Rm denotes the cyber at-
network channel and a(j)(t)
tacks corrupting the sensor transmitting signal. In par-
ticular, in order to provide security guarantees against
worst case adversarial behavior, we allow the adversarial
attacker to know the overall system model, system state,
control input and the possible fault detector D (e.g.,
distributed adaptive observers [24,25,26]) equipped on
the CPS. Thus, the attack signal can be modeled as

∈

∈

a(j)(t) = κ(j)(t

a )φ(j)(x(t), u(t), D, t
T (j)

T (j)
a )

,

,

−

−
Rm is
where κ(j)(t) is the time proﬁle and φ(j)(
∈
·
an unknown function that occurs at the unknown time
instant T (j)
a . We make no assumption on φ(j)(
),
,
·
which may be any (such as unbounded, discontinuous)
function vector. The time proﬁle of the attack is mod-
eled as κ(j)(r) = 0 if r < 0 and κ(j)(r) = 1 otherwise.
Multiple cyber attacks may occur simultaneously or se-
quentially, for example, T (1)
N .

T (j
a with j′

)

a

·

·

·

,

·

·

·

,

,

)

′

≤ · · · ≤

≤

Remark 1. System (1) can represent many practical
systems such as mobile robots, chemical reactors, wind
tunnels, and autonomous vehicles [36]. Some extensive
researches for system (1) in presence of external dis-
turbances, actuator failures, etc., have been studied
well [37,38,39] (these are easily extended to the current
framework and thus no longer considered here). Par-
ticularly, the works in [40,41] investigated the adaptive
leader-following consensus control of system (1). In this

3

Fig. 1. Secure DOC architecture of the jth subsystem of CPS
aﬀected by cyber attacks.

paper, the problem of DOC further minimizes a given
team performance function on the basis of consensus.

Remark 2. In general, the fault detector D is designed
for given failure types and cannot guarantee the de-
tectability for arbitrary malicious behaviors in theory.
Due to adversary’s strategic design, here we can assume
that the attack signal a(j)(t) in system (1) denotes a
strategic attack model which can potentially bypass the
fault detector D to destroy the system convergence based
on the knowledge of system and detector D (see stealthy
attack design methods against various fault detectors,
e.g., [32,33,34,35] and references therein).

G

D

O

O

(j) and

The overall DOC architecture of the considered CPS
is illustrated in Fig. 1. Similar CPS architectures can
(j) consists of
also be found in [31,26]. The cyber part
C
a decision-making multi-agent network. Each decision-
(j), is responsible for send-
making agent, denoted by
D
(j)
(j) to Σ(j). The agent
ing the control command
ℑ
contains an optimization module and a monitoring mod-
(j), respectively. The mod-
ule, denoted by
M
(j) is used to optimize its local objective function,
ule
while exchanging its information with its neighbors un-
der a network topology
. Since the adversarial attackers
can perform the attack a(j)(t) to corrupt the communi-
cation y(j)(t) from physical stratum to cyber stratum,
(j)) can also be
a cyber attack in the subsystem (
propagated to neighbors via the information exchange
(j) and its neighboring agents. This
between the agent
complicates the identiﬁcation of attacked subsystems.
(j) is used to detect and
To address it, each module
isolate the cyber attack a(j). In the physical part
(j),
(j) consisting of an inner-loop stabi-
the control module
(I,j) and an outer-loop tracking module
lizing module
(O,j) drives the physical dynamics in accordance with
K
(j) coming from the decision-
the control command
(j). Fig. 1 illustrates that suﬃcient in-
making agent
teraction between cyber and physical parts in the CPS
architecture.

(j),

M

D

D

K

K

ℑ

P

P

C

Objective of this paper: Design the decision-making
(j) and
(j) (including the optimization module
agent
(j),
the monitoring module
such that

(j)) and the control agent

M

O

D

K

1) Optimality: Under the healthy (attack-free) condi-
tion, all the physical subsystems cooperatively reach the
optimal output that minimizes the following team per-
formance function:

N

min

g(j)(s), s

Rm

(2)

∈

j=1
X
R is a local performance function
where g(j) : Rm
(j); and all the closed-loop
privately known to the agent
signals of the physical system are uniformly ultimately
bounded (UUB).

→

D

2) Security: Detect and isolate multiple cyber attacks
occurring at the network communication between physi-
cal stratum and cyber superstratum, and guarantee that
the attacked subsystem
Na converges to a
given secure state y(j)
s , while the healthy subsystems
achieve the output consensus at the optimal solution of

(j), j

P

∈

min

g(j)(s), s

j∈Nh
X

Rm

∈

(3)

where Nh represents the index set of the healthy subsys-
tems, i.e., Nh =
,
and Na =

: a(j)(t) = 0,

1,
Nh.

j
{
, N

t
∀

, N

· · ·

1,

≥

}

}

0

{

· · ·

∈ {
}\

Here we consider the scenario that the communication
from physical stratum to cyber superstratum can be at-
tacked, while the communication from the cyber super-
stratum to the physical stratum is secure [35]. For ex-
ample, for the GPS spooﬁng attacks on multiple Un-
manned Aerial Vehicles (UAVs) [45], the GPS attacker
in fact can tamper with the location information trans-
mitted from the UAV to the ground station, but cannot
tamper with the control command from the ground sta-
tion to the UAV or other communications among the
ground stations. Indeed, in many practical situations,
the adversarial attackers may also tamper with the con-
(j) transmitted from cyber superstratum
trol command
to physical stratum or communication among decision-
making agents in the cyber superstratum; however, the
design of the attack diagnosis and attack-tolerant strat-
egy is beyond the scope of this paper.

ℑ

Assumption 1. The function g(j) is diﬀerentiable and
convex for all j = 1,

, N .

· · ·

Assumption 2. The graph
rected and connected.

G

of the network is undi-

Remark 3. Assumptions 1 and 2 are common in the
DO or DOC literature [8,12,13,14,15,16,17,21]. In fact,

4

many practical optimization problems can be formalized
by the current convex DOC problem or approximated
by it using convex relaxation, such as the motion co-
ordination [14], target aggregation [12], search of radio
sources [12], optimal power ﬂow [10], and so on. The
DOC problems for pure-integrator dynamics [13,14,15],
Euler-Lagrangian systems [12] and linear time-invariant
systems [16,17] have been studied well. This paper fur-
ther considers more complex nonlinear case (system (1)).
Note that a simple combination of traditional DO al-
gorithms [4,5,6,7,8] and adaptive backstepping controls
[36,37,38,39] will cause the mismatch between (cyber)
optimization dynamics and physical dynamics and re-
sultantly cannot guarantee the overall convergence.

r denote the estimate of agent

Let y(j)
(j) about the value
, yN
of the solution to (3) and denote yr = vec(y1
r )
r ,
and L =

Im. Then problem (3) is equivalent to

· · ·

D

L ⊗

min g(yr) =

N

j=1
X

g(j)(y(j)

r ), subject to Lyr = 0

(4)

Since g(yr) is convex and the constraint in (4) is linear,
the constrained optimization problem is feasible. The
following lemma gives the analysis on the optimal solu-
tion of (4).

Lemma 1 [8]. Under Assumptions 1 and 2, deﬁne by

G(y, v) = g(y) + yT Lv +

yT Ly.

1
2

Then G is diﬀerentiable and convex in its ﬁrst argument
and linear in its second, and:

(i) if (y∗, v∗) is a saddle point of G, then y∗ is a solution
of (4);

(ii) if y∗ is a solution of (4), then there exists v∗ with
g(y∗) such that (y∗, v∗) is a saddle point of G.
Lv∗ =

−∇

In what follows, we present the resilient DOC scheme by
three steps. First, under the healthy conditions, we pro-
vide a basic version of DOC protocol (Section 4); Second,
under the adversarial conditions, an ADI methodology
is proposed to identify the attacked subsystems (Section
5); Third, the ﬁnal secure DOC scheme is derived by for-
mulating appropriate ADI-based attack countermeasure
strategy for the basic version (Section 6).

D

Remark 4. In the cyber superstratum, all the decision-
(j) themselves are assumed to be
making agents
healthy in the sense that they will follow any algorithm
that we prescribe. However, due to the occurrence of
cyber attack a(j), the agent
(j) and its neighbors will
receive false measurements y(j) and thus be induced
as “malicious” agents in network topology. Moreover,

D

these agents also send false data to other healthy agents
and cause cascading failures [19]. These tamped mea-
surements allow the corrupted agents to update their
states to arbitrary values such that the corresponding
physical subsystems follow false decision commands. In
this paper, a resilient DOC algorithm will be developed,
where the corresponding secure countermeasure based
on an ADI method can eﬀectively avoid the occurrences
of “malicious agents” and cascading failures.

Inner-loop control

•

(I,j)(x(j),

(j))

ℑ

K

α(j)
1,I =

−

1 z(j)
c(j)

−

z(j)
i −

α(j)
i,I =
u(j)
I = β−1
−
h

j

ˆρ(j)z(j)

1 −
1 −
ω(j)
i z(j)
c(j)
i
i −
n z(j)
c(j)

z(j)
n −

n −

ω(j)
1

ˆλ(j) + ˆπ(j)

S

−

ˆλ(j) + Λ(j)
ω(j)
n

i
ˆλ(j) + Λ(j)
n

i

4 Basic DOC under healthy environment

The corresponding update laws are given as

(j) and control agent

This section deals with the designs of the optimization
(j) that form a basic
module
K
DOC scheme under healthy conditions, i.e., a(j)(t) = 0
for any t
. In the sequel, we drop
the time argument of the signals for notational brevity.

0 and j

∈ {

, N

· · ·

O

1,

≥

}

4.1 DOC control algorithm

The model of the optimization module
as the following algorithm

O

(j) is designed

where

˙ˆλ(j) = Γ(j)τ (j)
n
˙ρ(j) = γ(j)
z(j)
0 k
1 k
˙π(j) = γ(j)
1 z(j)
1

2

z(j)
1
δ(j)

!

(7)

(8)

(9)

(10)

(11)

˙y(j)
r =

g(j)(y(j)
r )

− ∇

(1 + η)

Nj

˜v

−
wji(y(j)

−

˙v(j) =

i∈Nj
X
(j) =(y(j)
r ,

ℑ

i∈Nj
X
wji(y(j)

y(i))

−

g(j)(y(j)

r ), ˜v

Nj )

∇

y(i))

−

(5)

(j) :

O






v(i))

wji(v(j)

Rm, and y(j)
r

where ˜vNj =
Rm and v(j)

−

P
∈

i∈Nj
∈
Rm represent the agent state vectors;
g(j) is the gradient of g(j) and η > 0 is a design pa-
∇
Rm is the output that
Rm
rameter, and
ℑ
serves as a control command transmitted to the phys-
ical subsystem

∈
(j).

Rm

×

×

(j)

∈

P

Next, we present the design of control agent
consists of inner-loop module
ule
ℑ
deﬁne the following changes of coordinates

(O,j) following the control command

(j) which
(I,j) and outer-loop mod-
(j). First, we

K

K

K

1 = x(j)
z(j)

1 −

r , zi = x(j)
y(j)

i −

α(j)
i−1,

i = 2,

· · ·

, n (6)

i,I + α(j)

i = α(j)

where α(j)
i,O is the virtual control function
determined at the ith step and spitted into two parts:
inner-loop control α(j)
i,I and outer-loop control α(j)
i,O. Sim-
I + u(j)
ilarly, u(j) = u(j)
O is the control input consisting of
inner-loop control u(j)
I and outer-loop control u(j)
O . They
can be respectively expressed as follows:

5

1 = ω(j)
τ (j)

1 z(j)

1 , τ (j)

i−1 + ω(j)

i z(j)

i

i−1

i = τ (j)
∂α(j)
i−2,I
∂x(j)
k

ψ(j)
k

i = ψ(j)
ω(j)

i −

Λ(j)

i =

i−1

k=1
X
i−1

k=1
X
∂α(j)
i−1,I
∂x(j)
k
∂α(j)
k−1,I
∂ˆλ(j)

x(j)
k+1 +

∂α(j)
i−1,I
∂ˆλ(j)

Γ(j)τ (j)
i

+

=

S

z(j)
1
δ(j)

!

k=2
X
1
2

ln

Γ(j)w(j)

i z(j)

k +

1 +

z(j)
1
δ(j)

1
2

! −

ln

1

˙ˆπ(j)

∂α(j)
i−1,I
∂ ˆπ(j)
z(j)
1
δ(j)

−

!

b

|

{

· · ·

1 ), 0

with δ(j)(t) being an exponentially decaying function
z(j)
with lower bound k(j)
< δ(j)(0), and
such that
1,s(0)
|
z(j)
, m) element of z(j)
1,s denotes the sth (s = 1,
1 ;
i ), z(j)
i (¯x(j)
ϕ(j)
, ψ(j)
1 (x(j)
ϕ(j)
ψ(j)
i = diag
1 = diag
i }
{
}
, N ; and ˆλ(j), ˆρ(j) and ˆπ(j) are the estimates
for i = 2,
· · ·
of λ(j) =: [θT
j , µ]T with µ =: ((1 + η)2
3)Π2/2,
v(i)
ρ(j) := (2n
∗ ),
respectively, where Π is deﬁned in the appendix; Γ(j)
P
0 , γ(j)
is a positive deﬁnite matrix and γ(j)
for
, n are positive constants, all chosen by users.
i = 1,
Here the nonlinear function S(
) is introduced to con-
·
strain the bound of tracking error z(j)
1 , motivated by the
prescribed performance technique [39], which will play
an important role in enhancing the sensitivity and ro-
bustness of the ADI scheme (refer to Remark 7).

+
L
k
k
(v(j)
∗ −

and π(j) =:

1 + η)
k

and c(j)

k
i∈Nj

· · ·

−

L

L

k

k

1

i

 
 
 
 
Outer-loop control

•

(O,j)(

ℑ

K

(j))

g(j)(y(j)
r )

Nj

2˜v

α(j)
1,O =

α(j)
i,O =

u(j)
O =

−

− ∇

∂α(j)
i−1,O
∂y(j)
∇
r
h
∂α(j)
n−1,O
∂y(j)
r

β−1
j

−

−

g(j)(y(j)

r ) + ˜v

Nj

i

g(j)(y(j)

r ) + ˜v

Nj

∇
h

(12)

(13)

(14)

i

ℑ

K

It can be seen that, the DOC structure consists of two-
(j) and the
layer dynamics: the optimization dynamics
O
(j)) which interact with each
physical dynamics (Σ(j),
other over the communication signals y(j) and
(j) (see
Fig. 1). Such an architecture also illustrates the CPS’s
feature that the cyber and physical worlds are inte-
(I,j), a traditional adaptive
grated. In the inner-loop
K
backstepping controller [36] (i.e., let
= 0) with slight
k
k
modiﬁcations is applied to stabilize the nonlinear strict-
(O,j), a tracking
feedback system; In the outer-loop
controller is constructed in order to guarantee that the
system output can well track the control command y(j)
r
coming from the cyber superstratum. It can be seen that
the control laws of the physical systems do not change
with the change of the control commands. Summarizing
the above procedure (5)-(14), we derive Algorithm 1 for
the DOC of the overall CPS under healthy environment.

K

L

4.2 Convergence analysis

In the section, we discuss the convergence of the pro-
posed DOC algorithm. The main result is stated in the
following theorem whose proof is placed in Appendix I.

P

(j),

(j)) with (

Theorem 1. Under Assumptions 1 and 2, the closed-
loop CPS (
, N
achieves output consensus at an optimal solution y⋆ of
problem (2), i.e., limt→∞ y(j)(t) = y⋆ and all the closed-
loop signals are UUB in the absence of cyber attacks if
η > 2(n

(j)), j = 1,

(j),

1).

· · ·

O

K

C

−

Remark 5. Diﬀering from the previous works [12,13,14,15,16,17]
where the integrated closed-loop control laws are de-
signed, this paper presents a new two-layer control struc-
ture based on the traditional DO algorithms [4,5,6,7,8]
and adaptive backstepping controls [36,37,38,39]. Note
that the main challenge focuses on how to eliminate the
dynamics mismatch between two layers and generate
provable optimal consensus. From the proof of Theorem
1 (see (50), (55) and (60)), the dynamics compensation
(j) and physical dynamics
between cyber dynamics
O
(Σ(j),
(j)) guarantees the convergence of the overall
K
CPS, where the adaptive mechanism (9)–(11) plays a
key role.

6

Algorithm 1: DOC under healthy environment
DO algorithm (Module O(y)):

˙yr = − ∇g(yr) − Lv − (1 + η)Ly
˙v =Ly
ℑ =(yr, ∇g(yr), ˜v)

(15)

where ∇g(yr) = vec(∇g(1)(y(1)
vec(˜vN1 , · · · , ˜vNN ).
Adaptive tracking control (Module K(x, ℑ)):
Inner-loop control KI (x, ℑ):

r ), · · · , ∇g(N)(y(N)

r

)) and ˜v =

α1,I = − C1z1 − ˆρz1 − ω1ˆλ + ˆπ − S

αi,I = − zi − Cizi − ωi ˆλ +

i−1

+

∂αi−1
∂ˆλ

n−1

Γτi +

k=1
X
∂αk−1
∂ˆλ

k=2
X
−zn − Cnzn − ωnˆλ +
"

uI =B−1

z1
δ

(cid:17)
xk+1

(16)

(cid:16)
∂αi−1
∂xk

Γwizk +

∂αi−1
∂ ˆπ

˙ˆπ

(17)

∂αn−1
∂xk

xk+1

n−1

k=1
X

+

∂αn−1
∂ˆλ

n−1

Γτn +

∂αk−1
∂ˆλ

Γwizk +

∂αn−1
∂ ˆπ

˙ˆπ

#

(18)

k=2
X
, · · · , c(N)

i

where Ci = diag{c(1)
}, ˆρ = diag{ˆρ(1), · · · , ˆρ(N)},
i
Γ = diag{Γ(1), · · · , Γ(N)}, B = diag{β1, · · · , βN }, S(z1/δ) =
[S(z(1)
},
ωi = diag{ω(1)

/δ(N))], ψi = diag{ψ(1)
} and

1 /δ(1)), · · · , S(z(N)
, · · · , ω(N)

, · · · , ψ(N)

1

i

i

i

i

τ1 = ω1z1
τi = τi−1 + ωizi

ωi = ψi −

∂αi−2
∂xk

ψk

i−1

k=1
X

Outer-loop control KO(ℑ):

α1,O = − ∇g(yr) − 2Lv

αi,O = −

∂αi−1,O
∂yr
uO = − B−1 ∂αn−1,O

∂yr

[∇g(yr) + Lv]

[∇g(yr) + Lv]

where i = 2, · · · , n − 1 and Γ0 = diag{γ(1)
Update laws:

0 , · · · , γ(N)

0

˙λ = Γτn
˙ρ = Γ0z1 ◦ z1
˙π = Γ1z1

(19)

(20)

(21)

(22)
(23)
(24)

}.

where Γ0 = diag{γ(1)
γ(N)
1

}.

0 , · · · , γ(N)

0

} and Γ1 = diag{γ(1)

1 , · · · ,

5 Distributed ADI

}

1,

· · ·

M

∈ {

(j), j

This section deals with the design of the monitoring
module
. The ADI structure fol-
, N
lows the standard one of fault detection and isolation
(FDI), formulated by the ARRs of residuals and detec-
tion thresholds, e.g., [26,25]. However, in this section we
will focus on achieving the detection and isolation for
arbitrary malicious behaviors by constructing new resid-
uals and thresholds. Also, due to the coupling eﬀects of
multiple propagated attacks on the physical dynamics
and optimization dynamics, the design of attack diag-
nosis becomes more challenging.

Before giving the main result of this section, we make
the following assumption.

Assumption 3. The unknown parameter vector Z :=
vec(y∗, v∗, θ,

) lies in a known bounded convex set

L

k

k

ΥZ =

Z

{

∈

RN (2m+p)+1 : σ(Z)

0

}

≤

where σ(Z) is a convex function.

Assumption 3 is common in the existing results for
fault diagnosis [25,26,37], and this is also necessary to
detect the attack in transient response phase. It im-
plies that the upper bounds of y∗, v∗, θ and
, say,
yM , vM , θM , LM , can be obtained, respectively. Noting
that V (0) depends on the unknown vector Z, then we
deﬁne function Ω(Z) := V (0) and ¯Ω := supZ∈ΥZ Ω(Z),
where V is the Lyapunov function deﬁned in proof of
Theorem 1.

L

k

k

5.1 Design of ADI methodology

The ADI methodology consists of detection ﬁlter, adap-
tive threshold and decision logic. Next, we will give de-
tailed design procedures.

5.1.1 Detection ﬁlter and residual generation

Now, we design a distributed ﬁlter to generate residuals
for detecting attacks. According to the dynamics struc-
(j) is designed
ture (5) of
as

(j), the monitoring module

M

O

˙ˆy(j)
r =

g(j)(ˆy(j)
r )

− ∇

(1 + η)

Nj

˜v

−
wji(ˆy(j)

−

˙ˆv(j) =

i∈Nj
X

i∈Nj
X
wji[(ˆy(j)
r −

y(i))

r −

y(i))

−

(v(j)

−

ˆv(j))]

(j) :

M






∈

Rm and ˆv(j)

Rm are the estimates of y(j)
where ˆy(j)
r
r
and v(j) (even y(j)
(j)), re-
r
spectively, based on the local communication signals y(i)
and v(i), i
Nj. Further, we deﬁne two residuals

and v(j) are available for

M

∈

j

∈ {

} ∪

e(j)
r = y(j)
v = v(j)
e(j)

r −
−

ˆy(j)
r
ˆv(j)

(26)

(27)

Taking (5) and (25) into account, the error dynamics can
be expressed as

˙e(j)
r =

˙e(j)
v =

−

−

−

[
∇
η(j)(e(j)
wNj (e(j)

g(j)(y(j)
r )
− ∇
r + z(j)
1 )
−
e(j)
r −

v −

g(j)(ˆy(j)
r )]
η(j)a(j)
z(j)
1 ) + wNj a(j)

(28)

(29)

where wNj =

i∈Nj

wji and η(j) = (1 + η)wNj .

P

It is noted that the error dynamics (28)–(29) has a de-
centralized form where only own information is used in
each error dynamics. The feature means that the cou-
pling eﬀects of the propagated attacks a(i), i
Nj on
the residuals e(j)
and e(j)
caused by the optimization
v
r
dynamics have been removed such that the locally oc-
curring attack a(j) can be isolated. Later, we will further
address the coupling eﬀects of the propagated attacks
on the residuals caused by the physical dynamics z(j)
1 .
Moreover, to enhance the attack detectability and re-
move the existence of stealthy attacks, double coupling
residuals have been used here.

∈

If the sensor transmitted information y(j) is not aﬀected
by local attack a(j), the error dynamics under healthy
r,H , e(j)
conditions, denoted by (e(j)
v,H), can be expressed by

g(j)(ˆy(j)

r )]

˙e(j)
r,H =

˙e(j)
v,H =

−

−

−

[
∇
η(j)(e(j)
wNj (e(j)

g(j)(y(j)
r )
− ∇
r,H + z(j)
1 )
e(j)
r,H −

v,H −

z(j)
1 )

(30)

(31)

The stability of the estimation error dynamics under
healthy conditions is analyzed in the following lemma
whose proof is placed in Appendix II.

Lemma 2. The residuals under the healthy conditions
r,H(t) and e(j)
e(j)

v,H (t) satisfy

e(j)
r,H(t)
k
e(j)
v,H(t)

k

k ≤

k ≤

e−η(j)te(j)
r,H(0) + Ψ(η(j), z(j)
j te(j)
e−wN
v,H(0)
+ Ψ(wNj , e(j)

r,H(t) + z(j)

1 (t), 0, t)

1 (t), 0, t)

(32)

(33)

(25)

where Ψ(a, h(t), t0, t) := a

t
τ =t0

ea(τ −t)

h(τ )
k

k

dτ .

R

7

5.1.2 Construction of adaptive thresholds

Thus, we deﬁne the two adaptive thresholds

The jth detection thresholds, denoted by ¯e(j)
r,H (t) and
¯e(j)
v,H(t), are designed based on the bounds of residuals
r (t) and e(j)
e(j)
v (t) under the healthy conditions, respec-
tively. It is noted that the right-hand sides of (32) and
(33) cannot be directly used as the thresholds because
y(j)
1 = x(j)
z(j)
1 ) is unavailable for the mod-
r (
(j) due to the existence of cyber attack
ules
a(j). To derive an available and reasonable threshold, a
heuristic idea is to give a robust design w.r.t. the un-
known “disturbance-like” term z(j)
1 which, intrinsically,
reﬂects the eﬀects of physical dynamics on the residuals.
Hence, we bound the jth tracking error z(j)
1 under the
healthy conditions in the following lemma whose proof
is placed in Appendix III.

1 −
(j) and

= ˜z(j)

M

O

Lemma 3. Under Assumption 3, the servo tracking er-
ror z(j)
1 under healthy conditions (i.e., a(j) = 0) satis-
z(j)
ﬁes
1 (t)
1 and
k
k
z(j)
1 (t)
k

2/(2c(j)
1 ) +
< √mδ(j)(t).

t
τ =0 k
R

z(j)
1 (τ )
k

¯Ω/c(j)

2dτ

≤

k

−

:= y(j)

1 = z(j)

Remark 6. An intuitive method for the ADI design may
assess the change of error signal ˜z(j)
y(j)
r based
1
on Lemma 3, because ˜z(j)
1 under the healthy con-
1 = z(j)
ditions and ˜z(j)
1 + a(j) under cyber attacks. How-
ever, we emphasize that the error ˜z(j)
cannot be directly
1
used as the residual to detect and isolate the cyber at-
tacks because y(j)
r may be simultaneously aﬀected by
multiple propagated attacks a(i), i
Nj and the locally
occurring attack a(j). The adversarial attacker may co-
operatively design the stealthy attacks to degrade the
system performance while avoiding detection [32,33,34].

∈

Next, we design the detection threshold based on the
bound of z(j)
1 (t) under the healthy condition. To be
speciﬁc, from Lemma 3, one has z(j)
z where
1 (t)
∈
t
∆δ(j)
Cn
1
2dτ
2 +
z
2c(j)
τ =0 k
∈
≤
1 k
¯Ω
√mδ(j)(t)
. Substituting the relation into
R
c(j)
}
k ≤
1
(32) and (33) yields that

∆δ(j)
z(τ )
k

{
z(t)

z(t)
k

z(t)

m :

:=

k

,

e(j)
r,H(t)

k ≤

k

e(j)
v,H(t)

k ≤

k

+

e−η(j)te(j)

r,H(0)
sup
1 (t)∈∆δ(j)
z(j)
j te(j)
e−wN
v,H (0)

z

Ψ(η(j), z(j)

1 (t), 0, t)

+

sup
1 (t)∈∆δ(j)
z(j)

z

Ψ(wNj , e(j)

r,H(t) + z(j)

1 (t), 0, t)

8

r,H (t) = e−η(j)te(j)
¯e(j)
¯e(j)
j te(j)
v,H (t) = e−wN

r,H(0) + ¯Ψ(j)
∆δ(j)
z
v,H(0) + ¯Ψ(j)

(η(j), 0, t)

(wNj , 0, t)

∆δ(j)
ez

where ∆δ(j)
ez
¯Ψ(j)

k ≤
{
∆δ(j) (a, t0, t) := suph(t)∈∆δ(j) a

k

:=

e + z :

e

¯e(j)
r,H, z
t
τ =t0

∈
ea(τ −t)

∆δ(j)
z }
h(τ )
k

k

and

dτ .

R

K

Remark 7. From (28) and (29), multiple propagated
and e(j)
attacks have coupling eﬀects on residuals e(j)
v
r
over the physical dynamics. To address it, in the inner-
(I,j) the modiﬁed prescribed per-
loop control module
formance technique is used to restrict the bound of track-
ing error z(j)
(introduce the nonlinear function S into
1
α(j)
1,I ). As a result, the detection thresholds, or further
the proposed ADI method, are robust against the mul-
tiple propagated attacks. Especially, the prescribed per-
< √mδ(j)(t) is in-
formance bound constraint
k
corporated and contributes to smaller thresholds (from
the deﬁnition of ¯Ψ(j)
(a, t0, t)) and restrain the cou-
Nj on e(j)
r
such that the sensitivity and isolability to the

∆δ(j)
z
pling eﬀects of propagated attacks a(i), i
and e(j)
v
cyber attacks are improved.

z(j)
1 (t)
k

∈

5.1.3 Decentralized ADI decision logic

The ADI decision logic implemented in each module
(j) is based on the ARR, denoted by ℧(j)(t), which is

M
deﬁned as

℧(j)(t) = ℧(j,r)(t)

℧(j,v)(t)

∪

(34)

where

℧(j,r)(t) :
℧(j,v)(t) :
If ℧(j)(t) is violated,

k

k ≤

¯e(j)
e(j)
r,H(t)
r,H(t)
¯e(j)
e(j)
v,H(t).
v,H(t)
k
(j) will generate an alarm.

k ≤

M

The decentralized ADI decision logic is formulated by
considering the sensitivity w.r.t local cyber attacks a(j)
and the isolability w.r.t propagated cyber attacks a(i),
Nj, which are summarized in the following theorem.
i

∈

Theorem 2. Consider the ARR ℧(j)(t) deﬁned in (34).
The following statements are satisﬁed:

a) Attack sensitivity: If there is a time instant T (j)
d ) is not satisﬁed, then the occurrence

when ℧(j)(T (j)
of the local cyber attack a(j) is guaranteed.

d

b) Attack isolability: If the transmitted sensor infor-
mation y(j) is not aﬀected by cyber attack a(j), then
the ARR ℧(j)(t) is always satisﬁed even in the pres-
ence of the propagated cyber attacks a(i), i

Nj.

∈

6
Proof. a) For sake of contradiction, we suppose that no
communication attack a(j) has occurred, then ℧(j)(t) is
always satisﬁed according to Lemma 2.

b) Under the condition that a(j) = 0, even though the
propagated cyber attack a(i) may exist, i
Nj, the es-
timation error dynamics (28)-(29) reduces to (30)-(31),
respectively. Then (32) and (33) are valid and, conse-
(cid:4)
quently, ℧(j)(t) is always satisﬁed.

∈

Compared with the existing FDI results [24,25,26], we
have introduced the following techniques to improve the
detectability and isolability for attacks:

•

•

Double coupling residuals are adopted, which will play
a key role in removing stealthy attacks (see Lemma 6).
The modiﬁed prescribed performance technique is ap-
plied to enhance the sensitivity and isolability to the
cyber attacks (See Remark 7).

5.2 Detectability analysis and avoidance of stealthy at-

tacks

In this section, we will evaluate the attack detectability
of the proposed ADI methodology. We ﬁrst give some
properties of functions ¯Ψ(j)
(a, t0, t)
∆(j)
z
in the adaptive thresholds, which are important for ana-
lyzing the detectability performance of the ADI method-
ology.

(a, t0, t) and ¯Ψ(j)
∆(j)
ez

Lemma 4. Let δ(j)(t) = (k(j)
0 , k(j)
k(j)
and c(j)(
z(j)
1,s(0)
such that
|

b )/√m, where
= a) are positive design parameters
< δ(j)(0), s = 1,

0 e−c(j)t + k(j)

, m. Then

· · ·

|

b

(a) ¯Ψ(j)

∆δ(j)
z

(a, 0, t)

k(j)
b (1

−

≤

e−at)+

ak(j)
a−c(j) (e−c(j)t
0

e−at);

−

(b) ¯Ψ(j)

∆δ(j)
ez

e−at) + a

(a, 0, t)

k(j)
b +

(cid:20)

2k(j)

b (1
≤
−
ak(j)
a−c(j) + e(j)
0

te−at;

r,H(0)
(cid:21)

e−at)+ (2a−c(j))ak(j)

0

(a−c(j))2

(e−c(j)t

−

¯Ψ(j)2
∆δ(j)
z

∞
(c)
t=0
2 ¯Ω/c(j)
R
1 .

(a, 0, t)dt

¯Ω/c(j)
1 ,

∞
t=0

¯Ψ(j)2
∆δ(j)
ez

≤

(a, 0, t)dt

≤

R

Proof. (a) Note that Ψ(j)(a, h(t), 0, t) increases as
h(t)
k
k
k(j)
0 e−c(j)t + k(j)

increases. Based on the constraint

, we have

k ≤

h(t)

k

b

¯Ψ(j)

∆δ(j)
z

(a, 0, t)

a

≤

t

τ =0

Z

ea(τ −t)(k(j)

0 e−c(j)t + k(j)

b )dτ

By direct computation, the inequality in (a) holds.

9

(b) Based on (a) and using similar analysis, the proof
can be completed.

t

(c) Let h∗(t) := arg suph(t)∈∆δ(j)
i.e., ¯Ψ(j)
∆δ(j)
z
¯Ω/c(j)
1 .

∆δ(j)
z
is a compact set, h∗(t) satisﬁes

a
τ =0 ea(τ −t)
R

(a, t0, t) = a

τ =0 ea(τ −t)
h∗(τ )
R
k
h∗(τ )
k

k
∞
τ =0 k

t

z

R

dτ ,

h(τ )
k

k
dτ . Since

2dτ

≤

To show (c), we construct the auxiliary dynamics

˙χ(t) =

−

aχ(t) + a

h∗(t)
k

k

, χ(0) = 0

(35)

By integrating the dynamics we can ﬁnd χ(t) =
¯Ψ(j)
(a, t0, t). On the other hand, considering the Lya-
punov function V = χ2/2, its derivative along with (35)
satisﬁes

∆δ(j)
z

˙V =χ(

−
aV +

aχ + a
a
2 k

h∗
k
h∗

)
k
2,

k

≤ −

t=0 χ2(t)dt
integrating two sides of which yields
≤
1 . Using similar procedure to ¯Ψ(j)
¯Ω/c(j)
(a, 0, t), it is
R
∆δ(j)
ez
2 ¯Ω/c(j)
1 . (cid:4)
(a, 0, t)dt

easily obtained that

∞
t=0

¯Ψ(j)2
∆δ(j)
ez

≤

∞

∆δ(j)
ez

∆δ(j)
z

(a, 0, t) =

r (t) and e(j)

R
From Lemma 4-(c), one has limt→∞ ¯Ψ(j)
0 and limt→∞ ¯Ψ(j)
(a, 0, t) = 0 following Barbalat’s
Lemma. It means that only if ℧(j)(t) is satisﬁed, the
bound functions ¯e(j)
r,H(t) and ¯e(j)
v,H (t) will converge to
zero, which in turn implies that e(j)
v (t) con-
verge to zero. Lemma 4-(a) and -(b) give prescribed
performance bounds of ¯Ψ(j)
. By replac-
and ¯Ψ(j)
ing ¯Ψ(j)
bounds, we can obtain low-complexity thresholds. How-
ever, such relaxations will weaken the detectability and
extend the detection time. Also, two modiﬁed thresh-
olds converge to k(j)
and 2k(j)
instead of zero, which
may generate the stealthy attacks. Nevertheless, we can
choose k(j)
to be suﬃciently small such that the eﬀects
of the stealthy attacks resulted from the relaxation are
suﬃciently small.

with the prescribed performance

and ¯Ψ(j)

∆δ(j)
ez

∆δ(j)
ez

∆δ(j)
z

∆δ(j)
z

b

b

b

To examine the sensitivity of attacks that can be de-
tectable by the proposed attack detection scheme, the
following attack detectability is analyzed.

Lemma 5 (Detectable attacks). The cyber attack
a(j) occurring at the CPS (
(j)) is detected us-
ing the ARR ℧(j), if there exists some time instant
d > T (j)
T (j)
is the ﬁrst time instant of attack a(j)

(T (j)
a

(j),

P

C

a

6
occurrence) such that the attack satisﬁes

T (j)
d

η(j)

t=T (j)
a
a −T (j)
d )

(cid:13)
Z
(cid:13)
(cid:13)
2eη(j)(T (j)
(cid:13)
(cid:13)

eη(j)(t−T (j)

d )a(j)(t)dt

>

e(j)
r (T (j)
a )
k

k

(cid:13)
(cid:13)
(cid:13)
+ ¯Ψ(j)
(cid:13)
∆δ(j)
(cid:13)
z

(η(j), T (j)

a , T (j)
d )

T (j)
d

+ η(j)

eη(j)(t−T (j)
d )

t=T (j)
Z
a
g(j)(ˆy(j)

(cid:13)
(cid:13)
r (t)) + η(j)z(j)
1 (t)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

−∇

or

g(j)(y(j)

r (t))

∇

dt

(36)

T (j)
d

wNj

(cid:13)
Z
(cid:13)
(cid:13)
j (T (j)
>2ewN
(cid:13)
(cid:13)

t=T (j)
a
a −T (j)
d )

ewN

j (t−T (j)

d )a(j)(t)dt

e(j)
v (T (j)
a )
k

k

(cid:13)
(cid:13)
(cid:13)
+ ¯Ψ(j)
(cid:13)
∆δ(j)
(cid:13)
ez

(wNj , T (j)

a , T (j)
d )

+ wNj

T (j)
d

t=T (j)
a

Z

j (t−T (j)
d )

ewN

r (t) + z(j)
e(j)
(cid:13)
(cid:13)
(cid:13)

1 (t)
(cid:13)
(cid:13)
(cid:13)

dt (37)

then the attack a(j)(t) is detected at the time t = T (j)
d .

Proof. After the ﬁrst occurrence of the attack a(j), i.e.,
t > T (j)

a , the time derivative of e(j)

r (t) becomes

˙e(j)
r =

−

−

[
∇
η(j)(e(j)

g(j)(y(j)
r )
r + z(j)

g(j)(ˆy(j)
r )]
− ∇
1 ) + η(j)a(j)

Integrating both sides and applying the triangular in-
equality yield

r (T (j)
e(j)
d )

η(j)

k ≥

k

(cid:13)
t=Tf
Z
(cid:13)
(cid:13)
eη(j)(T (j)
(cid:13)
(cid:13)
T (j)
d

η(j)

t=T (j)
Z
a
g(j)(ˆy(j)

−

−

−∇

T (j)
d

eη(j)(t−T (j)

d )a(j)(t)dt

a −T (j)
d )

e(j)
r (T (j)
a )
k

k

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

eη(j)(t−T (j)
d )

g(j)(y(j)

r (t))

∇

(cid:13)
(cid:13)
r (t)) + η(j)z(j)
1 (t)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

substituting (36) into which yields

From the deﬁnition of ℧(j)(t), the attack a(j)(t) satisfy-
ing (36) or (37) provokes the violation of ARR ℧(j)(t)
and resultantly a(j)(t) is detected when t = T (j)
(cid:4)
d .

The inequalities (36)-(37) characterize the class of de-
tectable cyber attacks under the worst-case detectabil-
ity. The computation of detection time T (j)
d may be
somewhat conservative. However, diﬀering from the
fault, the attacker may strategically design the (worst-
case) attack to extend the detection time as much as
possible. Thus, the real-time detection time may suf-
ﬁciently approach to T (j)
but not exceed than it. In
general, from (36)-(37), if the cyber attack on the time
interval [T (j)
d ] is suﬃciently large, then the attack
can be detected. However, a crafty attacker may inge-
niously inject the attack signals which are not detected
by the proposed distributed ADI scheme, yet degrade
the system performance. The following lemma 6 gives
the property of the undetectable attack.

a , T (j)

d

Lemma 6 (Undetectable attacks). Suppose that the
(j),
cyber attack a(j)(t) occurring at the subsystem (

(j)) is undetectable by the ARR ℧(j). Then

C

P

∞

t

t=T (j)

a (cid:18)Z

Z

τ =T (j)

a

ewN

j (τ −t)

a(j)(τ )
k

k

dτ

2

(cid:19)

dt

≤

M (38)

where M = 4
over,

∞
t=T (j)

v (T (j)
e(j)
2/w4
a )
k
k
a(j)(t)
2dt < +
k
a k

.
∞

Nj + 16 ¯Ω/(c(j)

1 w2

Nj ). More-

R

Proof. If the attack a(j)(t) occurring at time T (j)
a
T (j)
a ,
detectable, from Lemma 5, then for any t

is not

≥

t

wNj

τ =T (j)
a
a −t)

(cid:13)
Z
(cid:13)
j (T (j)
2ewN
(cid:13)
(cid:13)

≤

ewN

j (τ −t)a(j)(τ )dτ

v (T (j)
e(j)
a )
k

k

(cid:13)
(cid:13)
+ 2 ¯Ψ(j)
(cid:13)
∆δ(j)
(cid:13)
ez

(wNj , T (j)

a , t)

(39)

dt,

Consider the right-hand side of (39). Taking square and
integral consecutively to each term yields

r (T (j)
e(j)
d )
k

k

>eη(j)(T (j)
+ ¯Ψ(j)

∆δ(j)
z

a −T (j)

d )e(j)
(η(j), T (j)

r (T (j)
a )
a , t).

4

v (T (j)
e(j)
a )
k

k

2

Following the similar analysis, (37) guarantees

∞

4

t=T (j)
a

Z

¯Ψ(j)2
∆δ(j)
ez

∞

e2wN

j (T (j)

a −t)dt

2

k

2

e(j)
v (T (j)
a )
k
wNj

,

≤

t=T (j)
a

Z
(wNj , T (j)

a , t)dt

8 ¯Ω
c(j)
1

.

≤

v (T (j)
e(j)
d )
k

k

>ewN

j (T (j)

a −T (j)

d )e(j)
(wNj , T (j)

v (T (j)
a )
a , t).

+ ¯Ψ(j)

∆δ(j)
ez

where the second inequality follows from Lemma 4-(c).

Then using the Cauchy-Buniakowsky-Schwarz inequal-

10

ity, one has

∞

4

t=T (j)
Z
a
+ ¯Ψ(j)

(ewN

j (T (j)

a −t)

k
a , t))2dt

(wNj , T (j)

v (T (j)
e(j)
a )
k

∆δ(j)
ez
v (T (j)
e(j)
a )
k
w2

k

Nj

4

≤

2

+

¯Ω

16
c(j)
1

(40)

Combining (39) and (40), Eq. (38) follows at once. Fur-
ther, limt→∞

j (τ −t)a(j)(τ )dτ = 0.

ewN

t
τ =T (j)

a

R
Next, to prove
the error dynamics

∞
t=T (j)

a k

R

a(j)(t)
k

2dt < +

, we consider

∞

˙e(j)
v =

wNj (e(j)

v −

e(j)
r −

−

z(j)
1 ) + wNj a(j).

Noting that ℧(j) is always satisﬁed, then e(j)
1 ∈
L2 from Lemma 4-(c). Therefore, there exist a suﬃ-
T (j)
ciently big T
a and a time interval Ξv with ν(Ξv) =
0 such that

v , z(j)

r , e(j)

≥

a(j)
s (t)
e(j)
v,s(t)

< 1,

t
∀

∈

[T,

Ξv

)
\
∞

which means that there exists a function ¯φv(t)
that

≤

0 such

or a(j)(t) = ¯φv(t)sgn(e(j)

v (t)) (41)

a(j)(t)
k

k

<

k

e(j)
v (t)
k
Ξv, where a(j)

∈

)
\
∞

for any t
[T,
sth element of a(j) and e(j)
to ˙e(j)
[
− ∇
∇
η(j)a(j), there exist ¯φr(t)
such that

g(j)(y(j)
r )

r =

−

≤

s and e(j)

v,s represent the
v . Applying similar procedure
η(j)(e(j)
1 )+
0 and Ξr with ν(Ξr) = 0

r + z(j)

g(j)(ˆy(j)

r )]

−

a(j)(t)
k

k

<

e(j)
r (t)
k

k

or a(j)(t) = ¯φr(t)sgn(e(j)

r (t)) (42)

for any t

[T, +

Ξr.

)
\
∞

∈

Compared (41) with (42), and noting that the equality

sgn(e(j)

v (t)) = sgn(e(j)

r (t)),

does not hold, it yields that
e(j)
a(j)(t)
v (t)
k
k
k
∞
which guarantees
t=T (j)

<

k

t
∀

Ξv)

[T, +

(Ξr

)
\
∞

∈

∪
e(j)
a(j)(t)
or
r (t)
k
k
k
k
Ξv),
for any t
(Ξr
)
[T, +
\
∈
∞
(cid:4)
a(j)(t)
2dt < +
.
∞
k

a k

<

∪

R

Lemma 6 implies that any undetectable attack must be-
long to L2. From its proof, we can see the design of dou-
ble coupling residuals plays a key role in removing the
existence of stealthy attacks a(j)(t) = ¯φr(t)sgn(e(j)
r (t))

11

against ℧(j,r) or a(j)(t) = ¯φv(t)sgn(e(j)
℧(j,v). Now, we give the main result of this section.

v (t)) against

(j),

(j)) with (

Theorem 3. Under Assumptions 1-3, the closed-loop
(j))) achieves
(j),
CPS (
output consensus at an optimal solution of problem (2)
and all the closed-loop signals are UUB even in the pres-
ence of the undetectable attacks if η > 2(n

(j)(

(j),

M

1).

O

D

K

P

C

−
a(j)(t)
k

Proof. From Lemma 6, one has
+

2dt <
. Following Theorem 1, the proof can be complete. (cid:4)

a k

∞
t=T (j)

∞

R

(j)),
Theorem 3 implies that all the subsystems (
, N can achieve optimal consensus only if the
j = 1,
ARRs ℧(j) are satisﬁed. In other words, any attacks can-
not bypass the designed ADI methodology to destroy
the system convergence.

(j),

· · ·

P

C

6 Secure countermeasure against cyber attacks

With these results on basic DOC and ADI in hand, we
now provide a secure countermeasure against the cyber
attacks and give the ﬁnal secure DOC algorithm. The
security objective is to steer the physical part
NA to a secure state y(j)
s
y(j)
s , while guaranteeing (
the output consensus at the optimal solution of

∈
Rm, i.e., limt→∞ y(j)(t) =
NH to achieve

∈
(j),
P

(j)), j

(j), j

P

∈

C

min

j∈NH
X

g(j)(s), s

Rm

∈

(43)

(j),

(j))
where NA represents the set of subsystems (
which are aﬀected by detectable attack a(j) subject to
(36) or (37), and NH ,
NA represents the
· · ·
set of the subsystems which are healthy or aﬀected by
undetectable attacks satisfying (38). To guarantee the
output consensus of subsystems
NH, the fol-
lowing assumption is necessary in accordance with As-
sumption 2.

(j), j

, N

} \

1,

P

P

∈

C

{

Assumption 4. The network topology induced by
agents

NH is connected.

(j), j

D

∈

G

Assumption 4 captures the communication redundancy
of graph
. Note that diﬀerent notions of network robust-
ness have been reported to guarantee the convergence of
resilient distributed algorithms, e.g., [20,21,22,23]. For
an undirected graph, Assumption 4 is in fact necessary
for achieving the security objective (43).

Before giving the secure countermeasure, we ﬁrst deﬁne
a notiﬁcation signal ̥(j)(t) such that “̥(j)(t) = 1” rep-
(j)) is attacked at time
resents the jth subsystem (
P
t, and “̥(j)(t) = 0” otherwise. In order to prevent the
transmission data y(j) corrupted by the cyber attack a(j)

(j),

C

from being propagated the neighboring subsystems, we
design

̥(j)(t) =

T (j)
1, if t
d
0, otherwise

≥

(

(44)

where T (j)
as

d

is the attack detection time for

(j), deﬁned

M

T (j)
d = inf
t≥0

t : ℧(j)(t) is volated

.

If ℧(j)(t) is always satisﬁed, then the detection time is
deﬁned as T (j)

d = +

o

n

.
∞

According to the security objective, we modify the out-
put of decision-making dynamics (5), i.e., the control
command

(j), under adversarial environment as

ℑ

(j) =

ℑ

(

(y(j)
r ,
∇
(y(j)
s , 0, 0),

g(j)(y(j)

r ), ˜v

Nj ), if t < T (j)
d
otherwise

(45)

The ﬁnal secure decision-making algorithm for
(j) based on the notiﬁcation signal (44) and the
agent
control command (45) is summarized as:

D

Receive (y(i), v(i), ̥(i)) to its neighbors
Set y(i) = 0 and v(i) = 0 if ̥(i) = 1;
Update state by computing Eq. (5);
Send control command

(j) to control module

(i), i

D

∈

Nj;

(j)

K

ℑ

•
•
•
•

C

P

(j),

(j),

(j)(
O
1,
· · ·
(j)), j

Theorem 4. Consider the closed-loop CPS (
(j),
with (
D
K
tacks a(j), j
∈ {
(j),
systems (
C
sus at the optimal solution y⋆
tem output of physical part
a given state y(j)
and limt→∞ y(j)(t) = y(j)
s
closed-loop signals are UUB.

(j))
(j))) in the presence of cyber at-
M
. Under Assumptions 1-4, sub-
, N
}
NH achieve the output consen-
NH of (43), while the sys-
(j), j
NA converges to
NH
NH for j
NA. Moreover, all the

s , i.e., limt→∞ y(j)(t) = y⋆
for j

P

P

∈

∈

∈

∈

(j),

(j)), j

C

P

∈
(j) sends the control command (y(j)

Proof. Consider the subsystem (
NA.
From Lemma 5, ℧(j) is not satisﬁed and the optimiza-
s , 0, 0)
tion module
(O,j). Then from (12)-(14) the
to the control module
outer-loop control u(j)
O = 0 and the inner-loop control
u(j)
(traditional adaptive backstepping control [36]) can
I
guarantee the closed-loop

(j) converges to y(j)
s .

O

K

P

Consider the subsystem (

P

(j)), j

(j),

C

∈

NH . Given the

12

Fig. 2. Model of Underwater Robotics Vehicle

above secure decision-making, the dynamics (5) becomes

˙y(j)
r =

g(j)(y(j)
r )

− ∇

−

wji(v(j)

v(i))

−

i∈Nj ∩NH
X
wji(y(j)

y(i))

−

(1 + η)

−

˙v(j) =

i∈Nj ∩NH
X

i∈Nj ∩NH
X
wji(y(j)

−

y(i))






Following Theorem 1 and Theorem 3, the output of
j
(43) as t

(j),
NH converges to the optimal solution of problem
(cid:4)
, and all the signals are UUB.

+

P

∈

→

∞

From (44) and (45), the security performance under the
cyber attacks heavily relies on the detection time T (j)
d .
With the increase of (T (j)
T (j)
a ), the attacker will have
more time to damage the system performance.

d −

7 Simulation example

As a practical application of the studied problem frame-
work, we apply our algorithms to the problem of mo-
tion coordination of multiple Remotely Operated Vehi-
cles (ROVs). The motion coordination expects the for-
mation of ROVs to rendezvous at a location which is
optimal for the formation [16,14]. The dynamic behav-
ior of ROVs can be described in two coordinate frames,
the body-ﬁxed frame and the earth-ﬁx frame as shown
in Fig. 2. The dynamics equation of each ROV can be
expressed as [44]:

M ˙ν + C(ν) + D(ν)ν + g(η) =τ + ∆f

˙η =J(η)ν

(46)

where η = [x, y, z, φ, θ, ψ]T is the position and orienta-
tion described in the earth-ﬁxed frame (
< π/2 and
|
< π/2), ν = [u, v, w, p, q, r]T is the linear and angu-
φ
|
|
lar velocity in the body-ﬁxed frame, M = MRB + MA
and M is positive deﬁnite, C(ν) = CRB(ν)+ CA(ν) sat-
CT (ν), MRB is the rigid-body inertia
isfying C(ν) =

θ

|

−

matrix, MA is the added inertia matrix; CRB(ν) is the
rigid-body Coriolis and centripetal matrix, CA(ν) is the
hydrodynamic Coriolis and centripetal matrix in clud-
ing added mass, D(ν) is hydrodynamic damping and lift
matrix, g(η) is a vector of gravitational forces and mo-
ment, τ is the control force and torque vector, ∆f is the
bounded disturbance vector. Note that system (46) can
be transformed into the form of system (1) by choosing
the state variables [xT

2 ]T = [ηT , νT J T (η)]T .

1 , xT

As reported in [44], in the positioning and trajectory
tracking control of ROV, the variables needed to be con-
trolled are x, y, z and ψ. Under some cases, for the pur-
pose of improving the dynamic stability and decreasing
the inﬂuences of φ and θ on other variables, a simple P-
controller can be used to control φ and θ. Therefore the
order of the MIMO backstepping robust controller can
be reduced from 6 degrees of freedom (DOF) to 4 DOF.

TABLE I. Simulation Model Parameters of ROV

Par
mν
Iz
W
B
Xu
Yv
Zw
Nr

Value
2500kg
1250kg·m2
24525N
24525N
-3610kg/s
-4660kg/s
-11772kg/s
-7848kg·m2/(s·rad)

Par
X ˙u
Y ˙v
Z ˙w
N ˙r
Xu|u|
Yv|v|
Zw|w|
Nr|r|

Value
-2140kg
-1636kg
-3000kg
-1524kg·m2
-952 kg/m
-1361kg/m
-3561kg/m
-773kg·m2/(s·rad)

from its initial position to rendezvous at the target posi-
tion which minimizes the square sum of distances from
these initial positions. The coordination control objec-
tive can be formulated as the following problem:

To simplify the controller design, the transformation
matrix J(η) can also be approximately obtained by as-
suming that φ = θ = p = q = 0, then the corre-
sponding matrix parameters of reduced system are M =
, D(ν) =
diag
,

−
−
Xu + Xu|u|, Yv + Yv|v|v, Zw + Zw|w|, Nr + Nr|r|r
B), 0]T and

−
{
g(η) = [0, 0,

X ˙u, mν

Y ˙v, mν

Z ˙w, Iz

{
diag

mν

(W

N ˙r

−

−

}

}

−

−

J(η) =

cos ψ

sin ψ 0 0

−

sin ψ cos ψ 0 0

0

0

0

0

1 0

0 1

0

0





















,

0

0

0

0

(mν

(mν

−

−

−

−
0

Y ˙v)v

X ˙u)u



.

C(ν) =

0

0

(mν














According to [44], the velocity dynamics can be ex-
pressed as linear-parametric form

X ˙u)u 0

Y ˙v)v

(mν

−

−

−

0

0

M ˙νv + C(ν) + D(ν)ν + g(η) = ΦT (ν, ˙νv, η)σ

−

X ˙u, mν
B, Iz

Y ˙v, Xu, X|u|u, Yv, Y|v|v, mν

where σ = [mν
−
−
Z ˙w, Zw, Zw|w|, W
N ˙r, Nr, Nr|r|] is unknown
−
system parameter vector, ν v is the virtual control and
Φ(ν, ˙νv, η) is a known reduced regressor matrix function
whose speciﬁc form can be found in [44] and is omitted
here for saving space.

−

Consider a ROV formation which consists of 4 same
ROVs. The parameters of the ROV are shown in Ta-
is given by a 2-
ble I. The communication topology
regular graph and the edge weight wji = 1. The problem
of multi-agent coordination consisting in ﬁnding a dis-
tributed control strategy that is able to drive each ROV

G

13

4

min
η(j)

j=1
X
where η(j)
0

η(j)

k

η(j)
0 k

−

2, s.t. η(1) =

· · ·

= η(4)

(47)

represents the initial state of the jth ROV.

Next, we apply the proposed secure DOC control strat-
egy to complete the motion coordination task. Consider
the cyber attacks (also including the sensor faults or
some extraneous factors such as ocean currents) occur-
ring in the complex underwater environment. When
the cyber core detects the existence of the cyber at-
tacks, it will drive the attacked ROV to the secure state
ηs = 0. In the simulation, the initial state conditions
of these four ROVs are set as η(1)(0) = [0.3 0.4 1 0]T ,
π/8]T
η(2)(0) = [0.1 0.1 0.5
and η(4)(0) = [0.2 0.5 1 0]T . Assume that the
4th ROV suﬀers the cyber attack at t = 30s, and
cos(t)]T .
φ(4)(t) = e0.5(t−30)−1[sin(t) cos(t)
For simplifying calculation, only the ARR ℧(j,r)(t)
rather than ℧(j)(t) is used in the proposed ADI ap-
proach.

π/6]T , η(3)(0) = [0 0 0

sin(t)

−

−

−

−

· · ·

The simulation results are shown in Figs. 3-5. Fig. 3 de-
scribes the state responses of η(j)(t) and ν(j)(t) of these
four ROVs, j = 1,
, 4. It can be seen that these four
ROVs are arriving at the consensus at the optimal solu-
tion of (47) before the attack occurs. The ADI mecha-
nism based on the ARR ℧(j,r)(t) formulated by e(j)
r and
e(j)
r,H is shown in Fig. 4, which implies that for j = 1, 2, 3,
the ARR ℧(j,r)(t) generated by
(j) is still satisﬁed
even after the cyber attack occurs, while ℧(4,y)(t) is im-
mediately violated (about at t = 31.5s), thus indicating
the cyber attack occurs in the 4th ROV. After detecting
(j) will send the control
the cyber attack, the module
(j) = (ηs, 0, 0) to the 4th ROV based on the
command
secure decision-making (45). Then the ROV stops send-
ing the transmission data η(4), and converges to the se-
cure position ηs = 0, while the remaining three ROVs

M

O

ℑ

)

m
X

(

0.4

0.3

0.2

0.1

0

1

0

)

m
Y

(

0.5

0

1st ROV

2nd ROV

)
s
/
m
(
u

0.6

0.4

0.2

0

3rd ROV

4th ROV

20

40

60

80

−0.2

0

1st ROV

2nd ROV

0.5

20

40

60

80

3th ROV

4th ROV

)
s
/
m
(
v

0

−0.5

−0.5

0

1

20

40

60

80

−1

0

1st ROV

2nd ROV

0.4

20

40

3rd ROV

60
4th ROV

80

)

m
(
Z

0.5

0

1

0

)
d
a
r
(

ψ

0.5

0

−0.5

−1

0

0.2

0

)
s
/
m
w

(

20

40

60

80

−0.2

−0.4

0

20

40

60

80

1st ROV

2nd ROV

1

3rd ROV

4th ROV

20

40
Time(s)

60

)
s
/
m

(
r

0.5

0

80

−0.5

0

20

40
Time(s)

60

80

Fig. 3. Trajectories of η(t) and ν(t) of four ROVs.

Attack detection of the 1st ROV

Attack detection of the 2nd ROV

1.5

1

0.5

l

d
o
h
s
e
r
h
t

d
n
a

l

i

a
u
d
s
e
R

0

0

1.5

1

0.5

l

d
o
h
s
e
r
h
t

d
n
a

l

i

a
u
d
s
e
R

0

0

e(1)
r
¯er,H

20

40

60

80

1.5

1

0.5

l

d
o
h
s
e
r
h
t
d
n
a

l

i

a
u
d
s
e
R

0

0

e(2)
r

¯e(2)
r,H

20

40

60

80

Attack detection of the 3rd ROV

Attack detection of the 4th ROV

e(3)
r

¯e(3)
r,H

2.5

2

1.5

1

0.5

l

d
o
h
s
e
r
h
t
d
n
a

l

i

a
u
d
s
e
R

e(4)
r

¯e(4)
r,H

20

40
Time(s)

60

80

0

0

20

40
Time(s)

60

80

Fig. 4. ADI by the ARR ℧(j,r)(t), j = 1, · · · , 4.

Control input of the 1st ROV

Control input of the 2nd ROV

τu
τv
τw
τr

2000

1000

0

τu
τv
τw
τr

20

40
Control input of the 3rd ROV

60

40
4Control input of the 4st ROV

60

20

80

x 10

−1000

−2000

80

0

τu
τv
τw
τr

1

0.5

0

τu
τv
τw
τr

20

40
Time(s)

60

−0.5

80

−1

0

20

40
Time(s)

60

80

4000

2000

0

−2000

−4000

−6000

0

6000

4000

2000

0

−2000

−4000

−6000

0

Fig. 5. Control inputs of four ROVs (τu:kgf, τv:kgf, τw:kgf,
τr:kgf·m).

achieve the consensus at the optimal solution of

min
η(j)

3

j=1
X

η(j)

k

η(j)
0 k

−

2, s.t. η(1) = η(2) = η(3)

(48)

These have been illustrated in Fig. 3. The control inputs
of the overall procedure are plotted in Fig. 5.

To further visualize the motion coordination of the ROV
formation, also for comparison, the routes of the formu-
lation of ROVs under the following three cases are pre-
sented in Figs. 7-9, respectively, where the Simulink in
MATLAB running time is set as [0s,80s]:

Case 1: Apply the basic/secure version of DOC under
attack-free environment;

Case 2: Apply the basic version of DOC (without the
ADI mechanism and secure countermeasure, i.e., set

)

m
(
z

1

0.8

0.6

0.4

0.2

0
0.5

0.4

0.3

0.63

)

m
(
z

0.625

0.62
0.26

X: 0.15
Y: 0.25
Z: 0.625

0.25

y(m)

0.24

0.15

x(m)

0.16

The 1st ROV
The 2nd ROV
The 3rd ROV
The 4th ROV

0.3

0.4

0.2

0.1

y(m)

0

0

0.1

0.2

x(m)

Fig. 6. 3-dimension routes of four ROVs on [0s,80s] under
Case 1.

)

m
(
z

1.5

1

0.5

0

The 1st ROV
The 2nd ROV
The 3rd ROV
The 4th ROV

1

0.5

y(m)

0

−0.4

0

−0.2

x(m)

0.6

0.4

0.2

Fig. 7. 3-dimension routes of four ROVs on [0s,34.45s] under
Case 2.

)

m
(
z

1

0.8

0.6

0.4

0.2

0
1

0.51

0.505

z(m)

0.5

0.495

0.49
0.14

X: 0.1333
Y: 0.1684
Z: 0.5004

0.13

0.12

x(m)

0.15

)

0.16

m
0.17
(
y

0.5

0

y(m)

−0.5

0

The 1st ROV
The 2nd ROV
The 3rd ROV
The 4th ROV

0.3

0.4

0.1

0.2

x(m)

Fig. 8. 3-dimension routes of four ROVs on [0s,80s] under
Case 3.

(j) = (y(j)
r ,

g(j)(y(j)

r ), ˜vNj ) and F (j) = 0 all the

ℑ
time) under adversarial environment;

∇

Case 3: Apply the secure version of DOC under adver-
sarial environment.

In Fig. 6, clearly all the ROVs rendezvous at the tar-
get position (0.15, 0.25, 0.625) (the optimal solution of
problem (47)) under the healthy condition. Fig. 7 shows
that under the case when the 4th ROV is attacked,
all the ROVs follow the wrong control commands and
move along with wrong (insecure) routes due to the at-
tack propagation through the exchange of information
between neighboring subsystems (The Simulink reports
“ERROR” at t = 34.45s and terminates). However,
by applying the secure DOC scheme, the ROVs 1, 2
and 3 rendezvous at the target position (0.1333, 0.1678,
0.5003) (the optimal solution of problem (48)), and the
4th ROV reach the preset secure position (0, 0, 0), which
has been illustrated in Fig. 8.

14

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
8 Conclusions

This paper presented a secure DOC method for a class
of uncertain nonlinear CPSs. First, a basic DOC under
the healthy conditions was proposed. By interacting and
coordinating between cyber dynamics and physical dy-
namics, the consensus and optimality were guaranteed.
In the presence of multiple cyber attacks, we proposed
a distributed ADI approach to identify the locally oc-
curring attacks from multiple propagating attacks. It
is shown that any attack signal cannot bypass the de-
signed ADI approach to destroy the convergence of the
DOC algorithm. Finally, a secure countermeasure strat-
egy against cyber attacks was described, which guaran-
tees that all healthy physical subsystems complete the
DOC objective, while the attacked physical subsystems
converge to a given secure state.

Appendix I

Proof of Theorem 1. First, we give the convergence
analysis on the cyber dynamics (15) and physical dy-
namics (1) based on the Lyapunov method, respectively.

Cyber dynamics: Let y∗ = 1N
⊗
(4). By Lemma 1-(ii), there exists v∗

y⋆ be a solution of
RN m such that
r = 0 holds, and (y∗, v∗) is
∇
the saddle of G. Consider the Lyapunov function of the
cyber dynamics

r ) + Lv∗ + (1 + η)Ly∗

g(y∗

∈

Vc =

1
2

yr

(
k

−

y∗

k

2 +

v

k

−

v∗

2)

k

Note that z1 = y
(15) becomes

−

yr under the healthy conditions. Then

the convexity of G in the ﬁrst argument; (c) follows from
the fact that (y∗, v∗) is the saddle point of G. Note that
the mismatching terms vT Lz1 and
zT
1 π will be com-
pensated by the following physical dynamics.

−

Physical system: The convergence analysis is dis-
cussed based on backstepping procedure. Rewrite (1)
into a compact form

˙xi = xi+1 + ϕi(¯xi)θ, i = 1,
˙xn = Bu + ϕn(x)θ,
y = x1

:

P




, n

1

−

· · ·

(51)



where ϕi(¯xi) = diag
θ = vec(θ1,

, θN ).

· · ·

ϕ(1)
i

(¯x(1)
i

),

{

· · ·

, ϕ(N )
i

(¯x(N )
i

and

)
}

The error dynamics can be expressed as

˙z1 = α1 + ϕ1(¯x1)θ
˙zi = αi + ϕi(¯xi)θ
˙zn = Bu + ϕn(x)θ

˙yr + z2
˙αi−1 + zi+1
˙αn−1

−
−
−




(52)



which can be spitted into inner-loop and outer-loop sub-
systems:

˙z1,I =α1,I + ψ1(¯x1)λ + z2
˙zi,I =αi,I + ψi(¯xi)λ
˙zn,I =BuI + ψn(x)λ

˙αi−1,I + zi+1 −
˙αn−1,I
−

µzn

−
−






and

˙z1,O = α1,O
˙zi,O = αi,O
˙zn,O = BuO

−

−

−
where zi = zi,I + zi,O for i = 1,


˙yr
˙αi−1,O
˙αn−1,O
, n.

· · ·

µzi

(53)

(54)

˙yr =
g(yr)
− ∇
˙v =Lyr + Lz1

−

Lv

−

(1 + η)Lyr

(1 + η)Lz1

−

(49)

Next, we provide the Lyapunov analysis of the physical
dynamics by considering

(a)
= (y∗

−
yr)T [
−
+ G(yr, v)
+ (v

−
G(y∗, v)
ηyT

−
r Lyr

−

ηyT

r Lyr

(b)

≤

(c)

≤ −

The time derivative of Vc along with (49) is

Vp =

˙Vc =(yr

y∗)T [

−
+ (v

−∇
v∗)T Lyr

−

−

g(yr)

(1 + η)Lyr]

Lv
−
(1 + η)zT
1 Lyr + (v
−
yT
r Lyr
(1 + η)zT
1 Lyr

g(yr) + Lv + Lyr]
G(yr, v∗)

−

∇

−

−
v∗)T Lz1

v∗)T Lz1

(1 + η)zT

G(y∗, v∗) + G(y∗, v∗)
1 Lyr + (v
1 Lyr + vT Lz1 −

(1 + η)zT

−

−

−

−

G(y, v∗)
v∗)T Lz1

zT
1 π (50)

where the equalities: (a) follows from Ly∗ = 0 and the
linearity of G in its second argument; (b) follows from

15

1
2  

n

i=1
X

2 + ˜λT Γ−1˜λ + ˜ρT Γ−1

0 ˜ρ + ˜πT Γ−1
1 ˜π

zi

k

k

!

where ˜λ = λ

ˆλ, ˜ρ = ρ

−

ˆρ, ˜π = π

ˆπ.

−

−

The derivative of Vp can be computed as

n

˙Vp =

zi ˙zi

i=1
X
= ˙VI + ˙VO

˜λT Γ−1 ˙ˆλ

−

˜ρT Γ−1
0

˙ˆρ

−

−

˜πT Γ−1

1

˙ˆπ

where ˙VI =
and ˙VO =
outer-loop Lyapunov derivatives, respectively.

n
˙ˆπ
i=1 zi ˙zi,I
−
n
i=1 zi ˙zi,O represent the inner-loop and

˜ρT Γ−1
0

˜πT Γ−1

−

−

˙ˆρ

1

˜λT Γ−1 ˙ˆλ

P
P

Consider the inner-loop error dynamics (53) with con-
trols (16)-(18) and adaptive laws (22)-(24). Following
the traditional backstepping procedure [36], along with
(53), we can obtain

n

n

V (t)

, there exists
V (0)
Also, on the compact set
}
Π for all
∂αi,O/∂yr
a positive constant such that
k ≤
i = 1,
1. Based on these facts, the Lyapunov
derivative ˙Vi,O = zi ˙zi,O along with (58) can be expressed
as

· · ·

, n

≤

−

{

k

Step 1. In view of (54) and (15), we have

+ µ

˙VI

≤ −

−

i=1
X
ρ

z1k

k

zT
i Cizi

µ

−

2 + zT

1 π

i=2
X
zT
1 S

−

zi

k

2

k
z1
δ

(cid:16)

(55)

.

(cid:17)

Now we consider the outer-loop error dynamics (54) with
controls (19)-(21).

˙z1,O = α1,O +

g(yr) + Lv + (1 + η)Ly

∇

(56)

To stabilize (56), consider the Lyapunov derivative
˙V1,O = z1 ˙z1,O. Then using the virtual control (19), we
have

˙V1,O =zT
=

1 [α1,O +

g(yr) + Lv + (1 + η)Ly]

∇
zT
1 Lv + (1 + η)zT
1 Lv + (1 + η)zT
zT
1 Lv + (1 + η)zT
zT

1 Ly
1 L(yr + z1)
1 Lyr + (1 + η)
k

=

−

−

≤ −

2

L

kk

z1k

(57)

i

n). Note that the arguments of the func-
Step i(2
tion αi−1,O involve yr and v. From (54) and (15), we
have

≤

≤

˙zi,O=αi,O +

∂αi−1,O
∂yr

[

g(yr) + Lv + (1 + η)Ly]

∇

∂αi−2,O
∂yr

−

L2y

=

(1 + η)

(cid:20)

∂αi−1,O
∂yr

L

−

∂αi−2,O
∂yr

L2

(cid:21)

(yr + z1) (58)

By using the triangular inequality, one has

2

2

zi

zi

(1 + η)zT
i

∂αi−1,O
∂yr

Lyr

≤

(1 + η)2

1
4
+ yrLyr

zT
i

L

k

k

∂αi−1,O

∂yr (cid:19)

(cid:18)

(1 + η)zT
i

∂αi−1,O
∂yr

Lz1 ≤

∂αi−2,O
∂yr
∂αi−2,O
∂yr

−

−

L2yr

≤

L2z1 ≤

1
4 k

1
4 k

3zT
i

L

k

3zT
i

L

k

1
4
+

(1 + η)2

L

k

2

k
z1k
kk
∂αi−2,O

L

k

∂αi−1,O

∂yr (cid:19)

(cid:18)

zT
i

2

∂yr (cid:19)

2

∂αi−2,O

∂yr (cid:19)

(cid:18)

(cid:18)

zi + yrLyr

zi +

2

L

z1k

kk

k

˙Vi,O =zT
i

(1 + η)

(cid:20)
zi

k

µ

k

≤

2 + 2

k

∂αi−1,O
∂yr
z1k

kk

L

L

−
2 + 2yT

∂αi−2,O
∂yr
r Lyr

L2

(yr + z1)

(cid:21)

(59)

Combining (57) and (59), the outer-loop Lyapunov
derivative satisﬁes

˙VO

≤ −

zT
1 Lv + (1 + η)zT

1 Lyr + ρ

2 + 2(n

z1k

k

−

1)yT

r Lyr

(60)

n

i=2
X

2

zi

k

k

Finally, construct the Lyapunov function V = Vc+Vp for
the overall CPS. Taking (50), (55) and (60) into account,
its time derivative satisﬁes

˙V

(η

−

2(n

−

≤ −

1))yT

r Lyr

N

−

j=1
X

z(j)T
1

S

z(j)
1
δ(j)

!

(η

−

2(n

−

≤ −

1))yT

r Lyr

n

−

i=1
X

n

−

i=1
X

zT
i Cizi

zT
i Cizi

(61)

where the fact z(j)T

1

S(z(j)

1 /δ(j))

0 is used.

≥

1). Then ˙V

1

{

≤

−

V (t)

0. Thus,

Choose η > 2(n
≤
is an invariant set. It implies that z(t), yr(t), v(t),
V (0)
}
ˆλ(t), ˆρ(t), ˆπ(t) and z(j)T
S(z(j)
1 /δ(j)) are bounded. Then
y(t) = z1(t)+yr(t) is bounded. Along with the backstep-
ping procedure, αi(t), ui(t) and xi(t) are also bounded.
Noting ˙yr(t), ˙v(t)
L2. Ac-
∈
cording to Barbalat’s Lemma, limt→∞ yT
r (t)Lyr(t) = 0
and limt→∞ zi(t) = 0. Finally, following the proof of [[8].
Theorem 4.1], one obtains that limt→∞ yr(t) = y∗. Thus,
we can conclude that limt→∞[y(t)
yr(t) + yr(t)

y∗] = limt→∞[y(t)

r (t)Lyr(t), zi(t)

L∞ and yT

y∗] = 0.

−
(cid:4)

−

∈

−

Appendix II

Proof of Lemma 2. To analyze the stability of (30),
we ﬁrst construct an auxiliary system

˙˜e(j)
r,H =

−

η(j)(˜e(j)

r,H + z(j)

1 ), ˜e(j)

r,H (0) = e(j)

r,H (0)

(62)

By directly computing (62), we obtain that

e−η(j)te(j)

r,H(0) + Ψ(η(j), z(j)

1 (t), 0, t).

˜e(j)
r,H(t)

k ≤

k

16

 
Also, along with (62), the time derivative of the Lya-
punov function U (j)(˜e(j)

2/2 is

r,H ) =

˜e(j)
r,Hk

k

˙U (j)(˜e(j)

r,H ) =

−

η(j)˜e(j)T

r,H (˜e(j)

r,H + z(j)
1 )

(63)

On the other hand, the time derivative of U (j)(e(j)
along with (30) can be expressed as

r,H )

˙U (j)(e(j)

r,H ) =

−

−

≤ −

g(j)(ˆy(j)

r )]

e(j)T
r,H [
∇
r,H (e(j)
η(j)e(j)T
r,H (e(j)
η(j)e(j)T

g(j)(y(j)
r )
− ∇
r,H + z(j)
1 )
r,H + z(j)
1 )

1 /δ(j))

S(z(j)
∞
, a contradiction, which in turn implies

1 /δ(j))

k(j)
b k

S(z(j)

k →

+

≥

1

Then z(j)T
as t
z(j)
1 (t)
k

k

→ ∞

< √mδ(j)(t).

References

[1] P. Antsaklis, “Goals and challenges in cyber-physical systems
research editorial of the editor in chief,” IEEE Trans.
Automat. Control, vol. 59, no. 12, pp. 3117–3119, Dec. 2014.

[2] J. Slay and M.Miller, “Lessons learned from the Maroochy
Water Breach,” in Critical Infrastructure Protection. New
York, NY, USA: Springer, 2007.

(64)

[3] J. P. Farwell and R. Rohozinski, “Stuxnet and the future of

cyber war,” Survival, vol. 53, no. 1, pp. 23–40, 2010.

where the inequality follows from the convexity of g(j).

Using the comparison principle [46], under the same ini-
tial condition ˜e(j)
r,H (0), (63) and (64) imply
U (j)(e(j)
r,H )
˜e(j)
r,H(t)

r,H(0) = e(j)
U (j)(˜e(j)
≤
e−η(j)te(j)

r,H ), or equivalently,
r,H (0) + Ψ(η(j), z(j)

e(j)
r,H(t)
k
1 (t), t0, t).

k ≤

k

k ≤

Directly solving (31) and applying the triangular in-
equality,

can be bounded by (33).

e(j)
v,H(t)
k

k

Appendix III

Proof of Lemma 3. Under the healthy conditions, in-
tegrating both sides of Eq. (61) yields

V (t)

−

V (0)

≤ −

(η

n

−

2n + 2)

t

τ =0

Z

yT
r (τ )Lyr(τ )dτ

zT
i (τ )Cizi(τ )dτ

−

τ =0

i=1 Z
X

which implies that

1
2 k

z(j)
1 (t)
k

2 + c(j)
1

τ =0 k
Z
Given Assumption 3 and deﬁnition of ¯Ω, we have

≤

z(j)
1 (τ )
k

2dτ

V (0).

t

t

1
2c(j)
1

z(j)
1 (t)
k

k

2 +

t

τ =0 k
Z

z(j)
1 (τ )
k

2dτ

≤

¯Ω/c(j)
1

1

S(z(j)
< δ(j)(t) for any t

In addition, from Theorem 1 we know z(j)T
1 /δ(j))
z(j)
is bounded, which yields
0.
1,s(t)
|
To prove the result we suppose, for contradiction, there
δ(j)(t) > k(j)
z(j)
exists s
.
1,s(t)
According to the form of S and the prescribed perfor-
S(z(j)
.
mance technique [39],
∞

|
1 /δ(j))
k

converges to +

such that

∈ {

| ≥

, m

· · ·

1,

≥

}

k

|

b

[4] A. Nedic and A. Ozdaglar, “Distributed subgradient methods
for multiagent optimization,” IEEE Trans. Autom. Control,
vol. 54, no. 1, pp. 48–61, 2009.

[5]

I. Lobel and A. Ozdaglar, “Distributed subgradient methods
for convex optimization over random networks,” IEEE Trans.
Autom. Control, vol. 56, no. 6, pp. 1291–1306, June 2011.

[6] M. Zhu and S. Martlnez, “On distributed convex optimization
under inequality and equality constraints,” IEEE Trans.
Autom. Control, vol. 57, no. 1, pp. 151–164, 2012.

[7] B. Johansson, T. Keviczky, M. Johansson, and K. H.
Johansson, “Subgradient methods and consensus algorithms
for solving convex optimization problems,” in Proc. IEEE
Conf. Decision Control, Cancun, Mexico, Dec. 2008, pp.
4185–4190.

[8] B. Gharesifard and J. Cortes, “Distributed continuous-time
convex optimization on weight-balanced digraphs,” IEEE
Trans. Autom. Control, vol. 59, no. 3, pp. 781–786, Mar.
2014.

[9] C. Y. Kim, D. Z. Song, Y. L. Xu, J. G. Yi, and X. Y.
Wu. “Cooperative search of multiple unknown transient radio
sources using multiple paired mobile robots,” IEEE Trans.
Robotics, vol. 30, no. 5, pp. 1161–1173, 2014.

[10] E. Dall’Anese, H. Zhu, and G. B. Giannakis, “Distributed
optimal power ﬂow for smart microgrids,” IEEE Trans.
Smart Grid, vol. 4, no. 3, pp. 1464–1475, 2013.

[11] S. Bose, S. H. Low, T. Teeraratkul, and B. Hassibi,
“Equivalent relaxations of optimal power ﬂow,” IEEE Trans.
Autom. Control, vol. 60, no. 3, pp. 729–742, 2015.

[12] Y. Zhang, Z. Deng, and Y. Hong, “Distributed optimal
coordination for multiple heterogeneous Euler-Lagrangian
systems,” Automatica, vol. 79, pp. 207–213, 2017.

[13] P. Lin, W. Ren, Y. Song, and J.A. Farrell, “Distributed
optimization with the consideration of adaptivity and ﬁnite-
time convergence,” in Proc. Conf. Amer. Control, 2014, pp.
3177–3182.

[14] Y. Xie and Z. Lin,“Global optimal consensus for higher-order
multi-agent systems with bounded controls,” Automatica,
vol. 99, pp. 301–307, 2019.

[15] Y. Zhang and Y. Hong, “Distributed optimization design
for high-order multi-agent systems,” in Proc. Conf. Chin.
Control, 2015, pp. 7251–7256.

[16] Y. Zhao, Y. Liu, G. Wen, and G. Chen, “Distributed
optimization for linear multiagent systems: edge- and node-
based adaptive designs,” IEEE Trans. Autom. Control, vol.
62, no. 7, pp. 3602-3609, 2017.

17

[17] Z. Li, Z. Wu, Z. Li, and Z. Ding, “Distributed optimal
coordination for heterogeneous linear multi-agent systems
with event-triggered mechanisms,” IEEE Trans. Autom.
Control, 10.1109/TAC.2019.2937500.

[34] Y. Chen, S. Kar, and J.M.F. Moura, “Optimal attack
strategies subject to detection constraints against cyber-
physical systems,”IEEE Trans. Control Netw. Syst., vol. 5,
no. 3, pp. 1157–1168, 2019.

[18] T. Yang, X. Yi, J. Wu, Y. Yuan, D. Wu, Z. Meng, Y. Hong,
H. Wang, Z. Lin, K. H. Johansson, “A survey of distributed
optimization,” Ann. Rev. Control, vol. 47, pp. 278–305, 2019.

[19] O. Yaggan, D. Qian, J. Zhang, and D. Cochran, “Optimal
allocation of interconnecting links in cyber-physical systems:
interdependence, cascading failures, and robustness,” IEEE
Trans. Paral. Distr. Syst., vol. 23, no. 9, pp. 1708–1721, 2015.

[20] L. Su and N. Vaidya, “Byzantine multi-agent optimization,”

arXiv:1506.04681, 2015.

[21] S. Sundaram and B. Gharesifard, “Distributed optimization
under adversarial nodes,” IEEE Trans. Autom. Control, vol.
64, no. 3, pp. 1063–1076, 2019.

[22] C. Zhao, J. He, and Q.-G. Wang, “Resilient distributed
optimization algorithm against adversarial attacks,” IEEE
Trans. Autom. Control, 10.1109/TAC.2019.2954363.

[23] W. Fu, J. Qin, Y. Shi, W. Zheng, and Y. Kang,
“Resilient consensus of discrete-time complex cyber-physical
networks under deception attacks,” IEEE Trans. Ind. Inf.,
10.1109/TII.2019.2933596.

[24] Q. Zhang and X. Zhang, “Distributed sensor fault diagnosis
in a class of interconnected nonlinear uncertain systems,” in
Proc. 8th IFAC SAFEPROCESS, Mexico City, Mexico, 2012,
pp. 1101–1106.

[25] V. Reppa, M. M. Polycarpou, and C. G. Panayiotou,
“Decentralized isolation of multiple sensor faults in large-
scale interconnected nonlinear
systems,” IEEE Trans.
Autom. Control, vol. 60, no. 6, pp. 1582–1596, Mar. 2015.

[26] V. Reppa, M. M. Polycarpou, and C. G. Panayiotou,
for a network of
IEEE Trans.

“Distributed sensor
interconnected
Control Netw. Syst., vol. 2, no. 1, pp. 11–23, Mar. 2015.

fault diagnosis

cyber-physical

systems,”

[35] T.-Y. Zhang and D. Ye, “False data injection attacks with
complete stealthiness in cyber-physical systems: A self-
generated approach,” Automatica, vol. 120, Oct. 2020, Art.
no. 109117.

[36] M. Krstic, P. V. Kokotovic, I. Kanellakopoulos, Nonlinear
and Adaptive Control Design. New York: Wiley, 1995.

[37] H. Ouyang, Y. Lin, “Adaptive fault-tolerant control

for
actuator failures: A switching strategy,” Automatica, vol. 81,
pp. 87–95, 2017.

[38] X. D. Tang, G. Tao, and S. M. Joshi, “Adaptive actuator
failure compensation for parametric strict feedback systems
and an aircraft application,” Automatica, vol. 39, pp. 1975–
1982, 2003.

[39] W. Wang and C. Wen, “Adaptive

failure
compensation control of uncertain nonlinear systems with
guaranteed transient performance,” Automatica, vol. 46, pp.
2082–2091, 2010.

actuator

[40] W. Wang, C. Wen, J. Huang, “Distributed adaptive
asymptotically consensus tracking control of nonlinear multi-
agent systems with unknown parameters and uncertain
disturbances,” Automatica, vol. 77, pp. 133–142, 2017.

[41] W. Liu and J. Huang, “Adaptive leader-following consensus
for a class of higher-order nonlinear multi-agent systems with
directed switching networks,” Automatica, vol. 79, pp. 84–92,
2017.

[42] M. Massoumnia, G. Verghese, and A. Willsky, “Failure
detection and identiﬁcation,” IEEE Trans. Autom. Control,
vol. 34, no. 3, pp. 316–321, 1989.

[43] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and
control for cyber-physical systems under adversarial attacks,”
IEEE Trans. Automat. Control, vol. 59, no. 6, pp. 1454–1467,
Jun. 2014.

[27] L. Zhang and G.-H. Yang, “Observer-based fuzzy adaptive
sensor fault compensation for uncertain nonlinear strict-
feedback systems,” IEEE Trans. Fuzzy Syst., vol. 26, no. 4,
pp. 2301–2310, 2018.

[44] K. Zhu, L. Gu, “A MIMO nonlinear robust controller
for work-class ROVs positioning and trajectory tracking
control,” in Proc. Annu. Conf. Control Decision, Hangzhou,
China, 2011, pp. 2565–2570.

[28] F. Pasqualetti, F. Dorﬂer, and F. Bullo, “Attack detection
and identiﬁcation in cyber-physical systems,” IEEE Trans.
Autom. Control, vol. 58, no. 11, pp. 2715–2729, 2013

[29] L. An and G.-H. Yang,

state
estimation for cyber-physical systems under sensor attacks,”
Automatica, vol. 107, pp. 526–538, 2019.

“Distributed secure

[45] A. Eldosouky, A. Ferdowsi, and W. Saad, “Drones in distress:
a game-theoretic countermeasure for protecting UAVs against
GPS spooﬁng,” IEEE Int. Things Journal, vol. 7, no. 4,
2840–2854, 2020.

[46] H. Khalil, Nonlinear Systems, third ed., Prentice Hall,

Hoboken, New Jersey, 2002.

[30] J. Zhang, R. Blum, X. Lu, and D. Conus, “Asymptotically
optimum distributed estimation in the presence of attacks,”
IEEE Trans. Signal Process., vol. 63, no. 5, pp. 1086–1101,
Mar. 2015.

[31] M. Zhu and S. Martnez, “Attack-resilient distributed
formation control via online adaptation,” in Proc. IEEE
Conf. Dec. Control Eur. Control (CDC-ECC), Orlando,
USA,, 2011, pp. 6624–6629.

[32] L. An and G.-H. Yang, “Data-driven coordinated attack
policy design based on adaptive L2-gain optimal theory,”
IEEE Trans. Autom. Control, vol. 63, no. 6, pp. 1760–1767,
2018.

[33] Y. Liu, M.K. Reiter, and P. Ning, “False data injection
attacks against state estimation in electric power grids,”
in Proc. the 16th ACM conf. Computer communications
security, 2009, pp. 21–32.

18

