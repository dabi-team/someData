1
2
0
2

p
e
S
8

]

R
C
.
s
c
[

2
v
6
2
5
2
0
.
5
0
1
2
:
v
i
X
r
a

Honeyboost: Boosting honeypot performance with
data fusion and anomaly detection

Sevvandi Kandanaarachchi ∗, Hideya Ochiai †, Asha Rao ‡

September 9, 2021

Abstract

With cyber incidents and data breaches becoming increasingly common, being able
to predict a cyberattack has never been more crucial. The ability of Network Anomaly
Detection Systems (NADS) to identify unusual behavior makes them useful in predicting
such attacks. However, NADS often suﬀer from high false positive rates. In this paper,
we introduce a novel framework called Honeyboost that enhances the performance of
honeypot aided NADS. Using data from the LAN Security Monitoring Project, Hon-
eyboost identiﬁes most anomalous nodes before they access the honeypot aiding early
detection and prediction. Furthermore, using extreme value theory, we achieve the highly
desirable low false positive rates.

Honeyboost is an unsupervised method comprising two approaches: horizontal and
vertical. The horizontal approach constructs a time series from the communications of
each node, with node-level features encapsulating their behavior over time. The vertical
approach ﬁnds anomalies in each protocol space. Using a window-based model, which
is typically used in online scenarios, the horizontal and vertical approaches are combined
to identify anomalies and gain useful insights. Experimental results indicate the eﬃcacy
of our framework in identifying suspicious activities of nodes.

Key words— network anomaly detection, honeypots, extreme value theory, false positives,

cyber security, time series

∗

Email:sevvandi.kandanaarachchi@rmit.edu.au, Aﬃliation:School of Science (Mathematical Sciences), RMIT University, Melbourne

VIC 3000, Australia.

†

Email:ochiai@elab.ic.i.u-tokyo.ac.jp, Aﬃliation:Graduate School of Information Science and Technology, The University of Tokyo,

Tokyo, Japan
‡

Email:asha.rao@rmit.edu.au, Aﬃliation:School of Science (Mathematical Sciences), RMIT University, Melbourne VIC 3000, Aus-

tralia.

 
 
 
 
 
 
1 Introduction

Increasing cyber attacks and data breaches require new ways of predicting attacks, especially previously
unseen ones. A very popular tool for prediction, is a honeypot (Barak 2020) that aims to lure attackers and
learn their tactics. While honeypots have known advantages such as ease of installation and low resource usage
(Campbell et al. 2015), there exist drawbacks, such as limited vision, discovery and ﬁngerprinting, that increase
the risk of takeover (Mokube & Adams 2007). Thus, honeypots are often deployed in conjunction with Network
Anomaly Detection Systems (NADS) (Baykara & Das 2018, Kondra et al. 2016).

NADS are capable of detecting new attacks, a key requirement in cyber security. However, they suﬀer
from high false positive rates. Furthermore, honeypot aided NADS are generally deployed in public domain
networks. The use of honeypots in Local Area Networks (LANs) has not been widely explored. In this paper,
we propose a novel framework, Honeyboost, that enhances LAN honeypot performance with Network Anomaly
Detection (NAD), while giving low false positive rates. Honeyboost identiﬁes most anomalous nodes in the
LAN, before they even access the honeypot, enabling better prediction of cyber attacks.

While many researchers have studied honeypots and anomaly detection, most place these detection tools in
the public/global IP domain or in Internet gateway routers. This results in eﬃcient detection of global cyber-
attack behaviors such as global-scans, Distributed Denial of Service (DDoS) attacks, or botnet constructions.
However, such placing is inadequate for detecting local or LAN internal cyber-attack behaviors such as malware
propagation, insider attacks, or data stealing through direct communications in the same network segment
without passing through routers. This may happen when (1) a malware is pre-installed in a mobile device that
connects to a WiFi, or (2) a malware is delivered to a computer through a phishing e-mail or Social Network
Sites (SNS).

This paper focuses on honeypot traﬃc in a local area network, where the behavior of the address resolution
protocol (ARP) can be observed. ARP requests are normally broadcast in the local network segment in order to
ﬁnd the media access control (MAC) address of the target IP address before forwarding an IP packet to the host.
The sequences of ARP requests, along with other protocol data are used as input for anomaly detection. This
allows suspicious behavior, such as multiple attempts to access many IP addresses in the local area network, to
be detected as anomalous. This LAN based honeypot research is unique as it allows us to predict anomalous
nodes, something that cannot happen in a global setting as the nodes wouldn’t be known.

We recognize that not all anomalies – nodes that access the honeypot – are malicious. In general, anomalies
are mainly caused by 1. malware trying to intrude into other hosts or steal data from the network data stor-
age/camera, 2. security software equipped with features of basic vulnerability testing, and 3. network operators
intentionally accessing computers in the LAN to check their status.

Honeyboost treats the output traﬃc of each node/host in a LAN as a time series, and computes node-level
features describing the behavior of nodes over time. To the best of our knowledge, this is the ﬁrst study that
computes node-level features by treating the output traﬃc of each node as a time series, in honeypot aided
NADS. We use an unsupervised anomaly detection (AD) method called Lookout that uses extreme value theory
to detect anomalies and eﬀective in minimizing false positives. Thus, the performance of the honeypot is
enhanced by using a node-level formulation in conjunction with an AD method with low false positives.

Identifying anomalous nodes in a network can be formulated as a time series problem as nodes transmit
network packets using multiple protocols at diﬀerent time points (Figure 1). Thus, identifying anomalous time
series would yield the nodes that behave quite diﬀerently from the rest.

1.1 Challenges

Formulating Network Anomaly Detection (NAD) as a time series problem, whether it is honeypot aided or

not, presents several challenges:

1

Figure 1: An example of the output of a single node, which can be treated as a time
series. As each protocol gives rise to a diﬀerent number of features, this is a varying-
dimensional time series.

1. Varying dimensional time series: Univariate and multivariate time series are widely studied in the
literature from many inter-disciplinary contexts. A univariate time series is a sequence of real valued
numbers indexed in time, denoted by {𝑢1, 𝑢2, . . . , 𝑢𝑡, . . .}, where 𝑢𝑡 ∈ R for all 𝑡. A multivariate time
series is a sequence of vectors indexed in time denoted by {𝒖1, 𝒖2, . . . , 𝒖𝑡, . . .}, where 𝒖𝑡 ∈ R𝑝 for all 𝑡.
However, here we have a diﬀerent situation. As the same node emits packets using diﬀerent protocols, we
, . . . , 𝒖𝑡𝑖 , 𝒗𝑡 𝑗 , 𝒘𝑡𝑘 , . . .}, where 𝒖𝑡𝑖 ∈ R𝑝, 𝒗𝑡 𝑗 ∈ R𝑞 and 𝒘𝑡𝑘 ∈ R𝑚 for diﬀerent
have a time series {𝒖𝑡1
values of 𝑝, 𝑞, 𝑚 and diﬀerent times 𝑡𝑖, 𝑡 𝑗 and 𝑡𝑘 . We call such a time series varying-dimensional (VD).
There has not been much research conducted on VD time series. A literature search has not indicated any
study of anomaly detection using VD time series.

, 𝒘𝑡3

, 𝒗𝑡2

2. Irregularity: Unevenly spaced time series are referred to as irregular time series. The traditional time
series theory is applicable to regular, evenly spaced time series, that is, a series {𝑢1, 𝑢2, . . . , 𝑢𝑡, . . .}, where
the time between successive entries 𝑢𝑖 and 𝑢𝑖+1 is constant. Here we have an irregular varying-dimensional
time series as the nodes communicate with each other at diﬀerent time points. As such, when we consider
the VD time series {𝒖𝑡1

, . . . , 𝒖𝑡𝑛, . . .}, in general 𝑡𝑛+1 − 𝑡𝑛 ≠ 𝑡𝑛 − 𝑡𝑛−1.

, 𝒘𝑡3

, 𝒗𝑡2

3. Sparse literature: The literature on NADS mostly considers a packet based feature approach. We see this
in most publicly available datasets. For example popular datasets such as KDD Cup 99 and Kyoto dataset
contain packet level observations without source details. While we appreciate that source addresses may
compromise privacy, without even a dummy identiﬁer it is not possible to construct a time series at the
node level. As such, we observe that while these datasets have been instrumental for the research growth
in NADS, they have also steered the progress towards a packet based feature approach.

While a node-based VD time series approach to NAD has challenges, it takes a more holistic view on NAD. As
such, we expect to gain deeper insights about network anomalies by using this modeling paradigm.

1.2 Our contribution

In this paper, we investigate the problem of honeypot aided NAD as a time series analysis problem and
present Honeyboost – a hybrid framework to ﬁnd anomalous nodes. As shown in Figure 2, Honeyboost includes
the following approaches:

1. Horizontal approach: We treat the data from each node as a VD time series and ﬁnd anomalous time
series using a feature based approach, where features are computed from the node-based VD time series.

2. Vertical approach: We focus on each protocol and ﬁnd anomalous nodes with respect to each protocol
using features relevant to that protocol. We then amalgamate the results enabling visual interpretation.

2

Our results demonstrate the following beneﬁts:

1. We identify most anomalous nodes before they access the honeypot.

2. We compare Honeyboost results obtained by the AD method Lookout with a One Class Support Vector
Machine (OCSVM) and ﬁnd the false positive rate of Lookout is much lower compared to the OCSVM.

3. We rank anomalies, thus enabling prioritization.

4. We gain deeper insights about the anomalous nodes.

5. We identify anomalous nodes with suspicious behavior that do not access the honeypot.

Figure 2: Honeyboost framework comprising horizontal and vertical approaches. The
horizontal approach considers node-level VD time series and identiﬁes anomalous
nodes. The vertical approach considers each protocol separately and ﬁnds anomalies in
each protocol space.

The remainder of the paper is organized as follows; In Section 2 we give a brief introduction to current
research in honeypots, anomaly detection and extreme value theory. The datasets for this study, discussed in
Section 3 are obtained from the Lan-Security Monitoring Project (Ochiai 2020). The window-based approach,
and the horizontal and vertical methodologies are discussed in Section 4. We present the early detection results,
false positive rates and amalgamation of horizontal and vertical anomalies in Section 5. We glean insights from
these results in Section 6. Finally, we present our conclusions in Section 7.

2 Background

In this section we provide the current research related to Honeyboost, including Honeypots, Anomaly

detection and Extreme Value Theory (EVT). We start with honeypot research.

2.1 Honeypots

Honeypot-based cyber security research can be categorized into two broad areas: 1. honeypot architecture
design (Fan et al. 2019, Sadasivam & Hota 2015) and 2. threat detection and prevention. These two topics
are not mutually exclusive, with some studies encompassing both topics. For example Jasek et al. (2013) use
Honeyfarms, a centralized collection of honeypots and analysis tools, to analyze and detect advanced persistent
threats. In this section we explore some of the work done on threat detection and prevention using honeypots.

3

Zhan et al. (2013) characterize honeypot captured cyber attacks using a statistical framework. They show
the rate of autocorrelation decay is slower than
that these cyber attacks exhibit long-range dependence, i.e.
the number of attacks per
exponential decay. They use statistical techniques to predict the attack rate, i.e.
time unit. Almohannadi et al. (2018) use honeypot log data to evaluate a new threat intelligence technique and
ﬁnd attack patterns. They admit that the large amount of data produced by honeypots is diﬃcult to analyze
using general purpose techniques, and instead, use an open search analytics engine called elastisearch. La
et al. (2016) present a game-theoretic model of deception comprising attackers and defenders, using Bayesian
techniques, and verifying their model using simulated data. As part of the game play, defenders have access
to the honeypots. Moore & Al-Nemrat (2015) review production honeypots and analyze data collected from
honeypots over a period of time. They explore geographical locations of attacks, IP addresses and ports in
this data. Shrivastava et al. (2019) use honeypots to capture attacks on IoT devices and classify them using
supervised machine learning algorithms.

Honeypots are also used to combat targeted attacks. Denial of Service (DoS) attacks can cripple entire
networks without ﬁnding loopholes in security. Anirudh et al. (2017) discuss a honeypot model for mitigating
DoS attacks for an Internet of Things (IoT) network. Tiruvakadu & Pallapa (2018) discuss wormhole attacks
in the context of mobile, ad-hoc networks and propose a honeypot based solution to conﬁrm these attacks. A
wormhole attack consists of two or more attackers strategically placing themselves in a network and creating
a tunnel between them. This reduces the shortest path between certain nodes, inducing legitimate traﬃc to go
through the attacker’s tunnel. They argue the necessity of an attack conﬁrmation system and use a honeypot
to conﬁrm the attacks using a wormhole attack tree. Zhang et al. (2021) use honeypots to validate their
adversary detection model in an IoT network. Cybereason, a cyber security technology company, launched a
network honeypot in early 2020 to learn the tactics, techniques and procedures of cyber criminals. Barak (2020)
discusses the lessons learnt from this experiment and the role of honeypots in critical infrastructure system
security. Handa et al. (2021) discuss the use of honeypots as a tool to obtain standard cyber defense for small
and medium scale businesses. In their book, they describe diﬀerent cyber security solutions accessible to small
enterprises.

Several recent reviews on honeypots are testament to their rising popularity. Razali et al. (2019) discuss the
importance and history of honeypots in information security and review their use in IoT networks. Seungjin
et al. (2020) survey honeypot based botnet detection and Matin & Rahardjo (2020) review malware detection
using honeypots.

2.2 Anomaly detection

As per Hawkins (1980) “an anomaly/outlier is an observation which deviates so much from other obser-
vations as to arouse suspicion it was generated by a diﬀerent mechanism”. Motivated by this well accepted
deﬁnition we consider anomalies to be rare observations diﬀerent from the rest of the points in some feature
space.

Anomaly detection (AD) is an extensively researched topic in many inter-disciplinary research ﬁelds. In
computer networks and security research, AD enables detection of unusual patterns in data that may signify
new attacks. While signature based intrusion detection methods reduce the number of false positives, they are
ineﬀective in capturing new attacks. AD methods are commonly used to ﬁll this gap.

Based on the learning paradigm, anomaly detection methodologies can be broadly categorized into three

groups (Goldstein & Uchida 2016):

1. Supervised anomaly detection: A model is trained on labeled data, which includes anomalies, and then

tested on new data.

2. Semi-supervised anomaly detection: Two diﬀerent deﬁnitions exist for semi-supervised anomaly detec-
tion. (a) A model is trained on data including both labeled and unlabeled instances (Ruﬀ et al. 2020).

4

Usually the number of labeled data points is much less than the unlabeled ones. (b) A model is trained on
data that does not include anomalies (Goldstein & Uchida 2016). In both scenarios, the resulting model
is tested on new data.

3. Unsupervised anomaly detection: These techniques do not use a separate set of labeled data to train the

model.

In this study, we focus on unsupervised anomaly detection, as unsupervised methods are better suited to identify
new attacks.

In addition, anomaly detection methods are also categorized as static or dynamic, depending on whether they
evolve with streaming data. The AD literature encompasses a diverse set of methodologies including density
estimation and probabilistic models, distance-based models, one class classiﬁcation models, reconstruction and
deep learning models, and cluster-based and graph-based models. For a general survey of AD methodology,
see Wang et al. (2019) and for a review of deep learning methodologies refer to Ruﬀ et al. (2020).

2.2.1 Anomaly detection in computer networks

Figure 3 shows the generic architecture of an NADS (Ahmed et al. 2016), which includes pre-processing,
anomaly detection, output and evaluation modules. The preprocessing module performs feature extraction and
feature selection at a packet level (Moustafa et al. 2019). Using either the packet header information alone or
packet header along with payload information, a variety of features are computed, then used by the Anomaly
Detection (AD) module. The output of the AD module can be real-valued anomaly scores or binary labels
signifying whether a data point is an anomaly or not. The evaluation module is the pre-action phase, where
decisions are made based on the anomaly scores/labels. Each module can have several sub-modules feeding
into other modules.

Figure 3: The generic architecture of a NADS as depicted in Ahmed et al. (2016).

Researchers have used anomaly detection methods to identify attacks and intrusions in computer networks
for more than 30 years (Maxion 1990). Furthermore, new anomaly detection methods aimed at speciﬁc threats
and technologies such as IoT networks are continuously being developed (Naveed & Wu 2020). A number of
comprehensive reviews on network anomaly detection are available (Baddar et al. 2014, Ahmed et al. 2016,
Fernandes et al. 2019, Moustafa et al. 2019). We brieﬂy discuss the review by Moustafa et al. (2019) and touch
upon some latest developments in the area.

Moustafa et al. (2019) emphasizes that unlike signature-based methods, anomaly detection is better suited
to capture new attacks. NADS operate by creating a normal proﬁle and identifying deviations from it. In the
pre-processing stage, features are extracted from the raw data, then reduced in number by discarding noisy,
unimportant features, leaving a smaller set of meaningful features. Next, categorical features are converted to
numerical and normalized to enable each feature to contribute equally to anomaly detection. The pre-processing
stage is followed by a decision engine, which may have a training phase and a validation and test phase. There are
many AD methodologies in NAD, including classiﬁcation-based methods such as support vector machines and
neural networks, clustering-based methods, deep-learning methods (Sohn 2021), knowledge-based methods,

5

combination-based and statistical methods such as kernel density estimates and particle ﬁlters. The authors
discuss these approaches and the available datasets.

More recent work includes a variety of methods ranging from ensemble methods to fuzzy logic. Zhou
et al. (2020) propose an ensemble technique using a modiﬁed adaptive boosting method called M-AdaBoost-
A to detect intrusions. They extend AdaBoost-A, which can handle class imbalanced data to multi-class
classiﬁcation, and evaluate two variants of the algorithm. Imrana et al. (2021) propose a deep learning approach
– a bi-directional LSTM (long short-term memory) – for intrusion detection. They evaluate their method using
the NSL-KDD dataset. Hamamoto et al. (2018) propose a method using genetic algorithms and fuzzy logic
for network anomalous event detection. Their approach consists of two phases: the genetic algorithm is used
to create a digital signature of the network segment and fuzzy logic is used to identify anomalies. Khan et al.
(2021) propose a deep learning method for network anomaly detection using network spectrogram images
generated from Fourier transforms. They train a deep convolutional neural network to identify the anomalies.
Liu et al. (2021) introduce a NADS using computer log sequences. They discuss the challenges of vectorizing
unstructured log messages while preserving semantics in an eﬃcient way.

2.3 Extreme Value Theory

Extreme Value Theory (EVT) is a branch of statistics used to model rare, extremal events such as 100-year
ﬂoods and catastrophic ﬁnancial losses (R.D. Reiss & M.Thomas 2001). Intuitively, EVT focuses on maxima
or minima and represents them using probability distributions. EVT is a powerful, yet ﬂexible technique to
model diﬀerent types of extremal behavior. From a statistical point of view, extremes are found in the tail of a
distribution. If the tail exhibits exponential decay, that is, if the tail behavior can be written as 𝜆𝑒−𝑘𝑥 for 𝜆, 𝑘 > 0
where 𝑥 is the random variable, then that is good news because many methods can be used to model the tail
behavior and hence we have a handle on the extremes. For example, the normal distribution has an exponentially
decaying tail. The problem arises when we have heavy or fat tails, that is, when the tail behavior exhibits a
power law relationship or decays polynomially. When this is the case, the tail behavior can be expressed as 𝜆𝑥−𝑘
with 𝜆, 𝑘 > 0. Power law decay is more challenging than exponential decay because it is diﬃcult to control
or predict the extremes, meaning there is high probability of getting extreme values. In particular, network
traﬃc is known to have heavy tails (Hernández-Campos et al. 2004, Ramaswami et al. 2014). Therefore, it is
important to use methodologies such as EVT capable of handling heavy tailed distributions.

Recent years have seen increasing interest in EVT based methods for anomaly detection (Kandanaarachchi &
Hyndman 2021, Talagala et al. 2020). We use Lookout (Kandanaarachchi & Hyndman 2021), an EVT based AD
method to detect anomalies in honeypot aided computer networks. Lookout has two main characteristics that
are advantageous in a computer network security context: 1. low false positives and a guarantee on false positive
probability and 2. ﬂexibility to model data without an assumption on the underlying probability distribution.

A low number of false positives is a fundamental characteristic of EVT based AD methods attributed to
its theoretical framework.
In addition, Lookout gives a guarantee or an upper bound on the false positive
probability, which can be set by the user. Furthermore, Lookout is not limited by any distributional assumptions
on the original data. EVT can handle truncated tails, exponentially decaying tails, polynomially decaying tails or
other types of tail distributions. Depending on the tail of the original distribution, EVT characterizes extremal
distributions into 3 types; Gumbel, Frechet and Weibull. These 3 distributions fully describe the space of
extreme value distributions, i.e. all extremes fall into one of the above three categories. A generalized extreme
value distribution incorporates these 3 distributions into 1 distribution using an additional shape parameter 𝜉.
Lookout estimates this shape parameter using the data, thus choosing the appropriate distribution to model
extremes. Therefore, if the data exhibits polynomial decay written as 𝜆𝑥−𝑘 , then Lookout estimates 𝑘 from the
data, which is then used to model extremes and identify anomalies.

6

3 Datasets

Figure 4: The monitoring device map for the LAN-Security Monitoring Project. The
nodes are overlaid on a map taken from the Microsoft security intelligence report (Kelley
2019) showing average monthly malware encounter rate of regions.

The LAN-Security Monitoring Project (Ochiai 2020) is a research collaboration between 12 ASEAN and
SAARC countries led by Japan. The project was deployed in November 2018, and aims to boost cyber-readiness
and cyber-resilience among partners through research collaboration especially focusing on the security of local-
area networks (LAN). Malware or worms can easily intrude into LANs through phishing-emails or WiFi, even
if the network is protected by a ﬁrewall or operated under a network address translation (NAT) unit. This
project deploys local monitoring devices, honeypots, in LANs because LAN-internal events, such as direct
communications between the devices inside the LAN are not visible by the global Internet observatories.
Monitoring devices are installed in severe malware-infected countries as shown in Figure 4.

The datasets we obtained pertained to a single LAN with a honeypot for the time period starting from January
11 2019 until November 15 2020. The honeypot was quiet and did not make any intentional announcements
(e.g., advertisements or discovery requests) to the network. However, a suspicious node on the same network
segment sometimes directly sends TCP or UDP packets targeting the IP address of the honeypot. Such a node is
considered anomalous as there is no legitimate reason to send a TCP/UDP packet to the honeypot. This activity
is captured by the software as the packets are directly exchanged with the honeypot. In addition, all broadcast or
multicast Ethernet frames including ARP requests, DHCP, NBNS, mDNS, LLMNR packets originating from
individual hosts connected to a LAN are also captured by the software. The raw data is then preprocessed to
generate features by protocol, which are given in Table 1.

As mentioned above, the datasets we received from the LAN-Security Monitoring Project comprised features
by protocol for a speciﬁc LAN. As listed in Table 1, in addition to TCP/UDP data, ARP data was collected at
5s, 60s and 600s time intervals. For each time interval, the node address, count and degree are provided in the
dataset.

7

Table 1: Dataset description – features by protocol

Protocol Feature

Description

ARP

TCP

timestamp
node address
count
degree

timestamp
node address
num_ports

count

avg_len
count_ﬁn
count_syn
count_rst
count_psh
count_ack
count_urg
count_ece
count_cwr

UDP

timestamp
node address
num_ports

count

avg_len

The start of the 𝑛 second time interval for 𝑛 ∈ {5, 60, 600}.
The MAC address of the source node.
The number of (broadcast) ARP requests made by the node
The number of IP addresses the node tried to resolve in the time interval
of the ARP broadcast request.

The start of the 5 second time interval.
The MAC address of the source node.
The number of ports speciﬁed by the TCP packets from this node within
the given time interval.
The number of TCP packets the monitoring unit observed from this
node.
The average length of IP packets that deliver the concerned TCP packets
The number of TCP packets with raised ﬁn_ﬂag.
The number of TCP packets with raised syn_ﬂag.
The number of TCP packets with raised rst_ﬂag.
The number of TCP packets with raised psh_ﬂag.
The number of TCP packets with raised ack_ﬂag.
The number of TCP packets with raised urg_ﬂag.
The number of TCP packets with raised ece_ﬂag.
The number of TCP packets with raised cwr_ﬂag.

The start of the 5 second time interval.
The MAC address of the node.
The number of ports speciﬁed by the UDP packets from this node within
the given time interval.
The number of UDP packets the monitoring unit observed from this
node.
The average length of IP packets that deliver the concerned UDP packets.

4 Methodology

To consider appropriate methodology, we take into account that the datasets span 22 months. Using all the
data in one batch and detecting anomalous nodes would amount to detecting anomalies at the end of the 22
month period. Instead, we use a more continuous approach to detect anomalies using a window-based model.
A window-based approach uses the data in the time window to detect anomalies. That is, it does not see data
outside the window. Both horizontal and vertical approaches use window-based models for anomaly detection.
We combine the anomalies found in the amalgamation stage.

4.1 Sliding and expanding time window models

Figure 5 shows the diﬀerent window models used for horizontal and vertical approaches. For the horizontal
approach, we use a sliding window model for all three protocols. We denote the window width by Δ𝑇 and the
step size by Δ𝑡. Suppose the 𝑖th time window starts at 𝑡𝑠𝑖 and ends at 𝑡𝑒𝑖 . Then 𝑡𝑒𝑖 = 𝑡𝑠𝑖 + Δ𝑇. The (𝑖 + 1)st time
window would start at 𝑡𝑠𝑖+1 = 𝑡𝑠𝑖 + Δ𝑡 and ends at 𝑡𝑒𝑖+1 = 𝑡𝑠𝑖+1 + Δ𝑇 = 𝑡𝑒𝑖 + Δ𝑡. This is illustrated in Figure 5(a).
Thus, the horizontal approach considers data in the time window (cid:2)𝑡𝑠𝑖 , 𝑡𝑒𝑖

(cid:3) for each window 𝑖.

The vertical approach is somewhat diﬀerent because it considers each protocol separately to detect anomalies.
We use two diﬀerent window models for the vertical approach, based on the protocol. For ARP, we use the
same sliding windows as in the horizontal approach. For TCP and UDP we use an expanding window model
shown in Figure 5(b). The honeypot captures all the broadcast ARP requests, but only captures TCP or UDP

8

Window 𝑖

Window (𝑖 + 1)

𝑡𝑠𝑖

Δ𝑡

𝑡𝑠𝑖+1

Δ𝑇

(a)

𝑡𝑒𝑖

Δ𝑡

𝑡𝑒𝑖+1

𝑡𝑒𝑖

Δ𝑡

𝑡𝑒𝑖+1

Window 𝑖

Window (𝑖 + 1)

(b)

Figure 5: Sliding and expanding windows: (a) The sliding window model. This is used
in the horizontal approach and in the vertical approach for ARP. (b) The expanding
window model. This is only used for TCP and UDP in the vertical approach.

packets directed at it. Consequently, the number of TCP and UDP packets, compared to ARP packets, are low.
Thus, a sliding window model is not suitable for TCP and UDP separately, for the vertical approach. Thus, for
each ARP window ending at time 𝑡𝑒𝑖 , we use TCP and UDP data for 𝑡 ≤ 𝑡𝑒𝑖 .

While there is no deﬁnitive guide to choosing the window size Δ𝑇 or the step size Δ𝑡, often application
speciﬁc considerations and trial and error are used in selecting these parameters. For each window 𝑖, that is,
at every 𝑡𝑒𝑖 , Honeyboost outputs a list of anomalous nodes identiﬁed from the data in that window. As such,
the step size Δ𝑡 is the frequency of Honeyboost output, which can selected according to requirement. We have
used Δ𝑡 = 60 × 60 seconds in this experimental study, i.e., we have conﬁgured Honeyboost to output anomalous
nodes every hour.

In contrast, the window size Δ𝑇 determines the amount of data the algorithm looks at to detect outliers.
Smaller window sizes give rise to higher ﬂuctuations. For example, using a window size of 1 hour results in
the volume of data being high at peak activity hours and much lower at 4 am in the morning. This is known
as seasonality of the data. Often with network traﬃc data, there could be multiple seasonal patterns ranging
from hourly patterns to daily patterns. Similar to the hourly ﬂuctuations, there is lower traﬃc on some days
of the week compared to other days. Therefore, it is important to choose a window size not aﬀected by such
seasonal patterns.
In addition, the higher ﬂuctuations in data volume from smaller window sizes give rise
to higher false positives. Here, to mitigate seasonal ﬂuctuations and to keep the false positives low, we use
Δ𝑇 = 1 week = 7 × 24 × 60 × 60 seconds, and conﬁgure Honeyboost to predict anomalous nodes every hour
from one week’s worth of data ending at that hour.

4.2 Horizontal approach

Using the sliding window model, the pre-processed features for all three protocols, by node, are sorted
by time, resulting in, for each time window and each node, a set of varying dimensional (VD) time series as
depicted in Figure 1. Figure 6 illustrates the processes involved in this approach, and the input and the output
data type for each process.

Firstly, the VD time series is reshaped to a multivariate time series using homogenization (see Table 2).
This essential step results in transporting the research problem to a space where we can use existing time series
analysis methodology. However, ﬁnding anomalous time series from a collection of multivariate time series is a
challenging task. Hence, we transform each multivariate time series to a point in high dimensional space using
metamorphosis (Figure 7), a feature-based time series approach popular in time series forecasting. This step
transforms the problem of ﬁnding anomalous multivariate time series to ﬁnding anomalous points in Euclidean
space, an easier problem. However, anomaly detection in high dimensional data is prone to error due to the
curse of dimensionality. Therefore, the dimensions of this data are reduced using Principal Component Analysis
(PCA) and only the ﬁrst 2 PC scores are kept. Anomalies are then detected in this 2-dimensional PC space
using Lookout and a One Class Support Vector Machine (OCSVM). Lookout is an Extreme Value Theory based

9

Figure 6: The input and output data type of each process in the horizontal approach.

anomaly detection method and achieves lower false positives compared to the OCSVM. These processes are
detailed below.

4.2.1 Homogenization: constructing a multivariate time series from a VD time series

A multivariate time series is constructed using the VD time series for each node. This transformation, called
homogenization, is shown in Table 2 via an example. The resulting multivariate time series contains 6 numeric
features characterizing important aspects of each protocol along with the node address, timestamp and protocol
name.

As seen in Table 1 the dataset from each protocol contains the node address, the timestamp and some other
numerical features for each observation. These numerical features are depicted in parenthesis in the example
VD time series given in Table 2. In order to give each protocol the same importance, we represent the numeric
features of each protocol by two key features. The two numeric features of ARP (see Table 1) namely degree
and count are included as part of the 6 features in the multivariate time series.

TCP, on the other hand, has 11 numeric attributes per node at each timestamp (see Table 1). We reduce the
dimension of this 11-dimensional feature space to 2, by using Principal Component Analysis (PCA). The ﬁrst
2 principal component scores PC1 and PC2 for TCP then become part of the 6 features in the multivariate time
series. Similarly UDP has 3 numeric attributes at each timestamp; PCA is performed for the UDP space and
the ﬁrst 2 PC scores used.

Thus, each node is homogenized to have the following 8 features: 1. timestamp; 2. protocol name; 3. ARP
degree; 4. ARP count; 5. TCP PC1; 6. TCP PC2; 7. UDP PC1; and 8. UDP PC2. Thus a VD time series
for a given node with observations at 𝑘 diﬀerent time points is transformed into a 𝑘 × 8 matrix denoting an 8
dimensional time series with 𝑘 time points. The node address is a grouping attribute that does not participate
in the statistical analysis. That is, once the anomalous points are identiﬁed, the node address is only used to
recognize the responsible node.

4.2.2 Metamorphosis: Mapping a time series to a point in high-dimensional space

For each time window 𝑖, where 𝑡 ∈ (cid:0)𝑡𝑠𝑖 , 𝑡𝑒𝑖

(cid:1), and each node, we consider a multivariate time series. This
gives us 𝑚 multivariate time series if there is traﬃc from 𝑚 nodes present in that time window. We then
compute features and transform this time series into a point in a high-dimensional space. As a time series
gets transformed into a point, we call this process metamorphosis. Figure 7 illustrates this process. There is

10

Table 2: Homogenization: An example VD time series (left) reshaped to a multivariate
time series (right)

s
s
e
r
d
d
A
e
d
o
N

p
m
a
t
s
e
m
T

i

l
o
c
o
t
o
r
P

Features
N1 30 ARP (10, 12)
N1 55 TCP
N1 85 UDP (3702, 2, 652)

(80, 2, 6, 0, 2, 0, 0, 0, 0, 1, 1)

Time Series

Time

s
s
e
r
d
d
A
e
d
o

=⇒ N

p
m
a
t
s
e
m
T

i

l
o
c
o
t
o
r
P

t
n
u
o
C
P
R
A

N1
N1
N1

30 ARP 10
0
55 TCP
85 UDP 0

𝑥3

•

M e t a m o r p h o s i s

e
e
r
g
e
D
P
R
A

12
0
0

𝑥2

𝑥1

1
C
P
P
C
T

2
C
P
P
C
T

1
C
P
P
D
U

0
2.1
0

0
0
1.7 0
0

3.6 0.4

2
C
P
P
D
U

0
0

Figure 7: A simpler version of metamorphosis: The ﬁgure on the left shows a univariate
time series, which gets mapped to a point in R3 on the right. In reality, we consider a
multivariate time series for each node, and map it to a point in R17.

a bĳective mapping between the nodes and the points in the high-dimensional space, wherein each node is
uniquely identiﬁed by a point in the high dimensional space and each point in the high-dimensional space
denotes the behavior of a speciﬁc node in that time window.

The features
For any given node 𝑁 𝑗 the following features are computed from the multivariate time series associated with
𝑁 𝑗 :

1. The maximum time diﬀerence for the time series max 𝑡 − min 𝑡 for 𝑡 ∈ (cid:0)𝑡𝑠𝑖 , 𝑡𝑒𝑖

(cid:1) for node 𝑁 𝑗

2. The number of protocols used by 𝑁 𝑗 .

3. The number of TCP calls made by 𝑁 𝑗 .

4. The number of UDP calls made by 𝑁 𝑗 .

5. The total length of the line segments in R6 using the 6 protocol features, ARP count, ARP degree,
TCP PC1, TCP PC2, UDP PC1 and UDP PC2: Suppose {𝒙𝑡𝑘 }ℓ
𝑘=1 denotes the time series for 𝑁 𝑗 in
R6. The standard Euclidean norm gives the length of the line segments, viz., (cid:205)ℓ−1
In
the example given in Table 2 the total length of the line segment in 𝑅6 would be (cid:107)(10, 12, 0, 0, 0, 0) −
(0, 0, 2.1, 1.7, 0, 0)(cid:107) + (cid:107)(0, 0, 2.1, 1.7, 0, 0) − (0, 0, 0, 0, 3.6, 0.4) (cid:107).

𝑘=1(cid:107)𝒙𝑡𝑘+1 − 𝒙𝑡𝑘 (cid:107).

6. The total length of the line segments in the ARP space spanned by ARP count and ARP degree: While
similar to the previous feature this only takes the length of the line segments using the ARP count and
ARP degree. Figure 8(a) illustrates this ARP space for a hypothetical node. At times 𝑡1, 𝑡2, 𝑡3, 𝑡4, 𝑡5, 𝑡6

11

and 𝑡8 this node has made ARP calls. The total length of the line segments is given by (cid:205)𝑡,𝑡 (cid:48)∈𝑆 (cid:107)𝒙𝑡 (cid:48) − 𝒙𝑡 (cid:107),
where 𝑆 = {𝑡1, 𝑡2, 𝑡3, 𝑡4, 𝑡5, 𝑡6, 𝑡8} and 𝑡 and 𝑡(cid:48) denote successive time points in 𝑆.

7. Next we ﬁt a line to the points in the ARP space using linear regression. We denote the points in the ARP
𝑘=1 where 𝒙𝑡𝑘 = (𝑥𝑘𝑐, 𝑥𝑘 𝑑) where 𝑥𝑘𝑐 denotes the count and 𝑥𝑘 𝑑 denotes the degree at time

space by {𝒙𝑡𝑘 }ℓ
𝑡𝑘 . Then the line of best ﬁt is given by the equation

where 𝑚 and 𝑐 denotes the slope and intercept, which are given by

ˆ𝑥𝑘 𝑑 = 𝑚𝑥𝑘𝑐 + 𝑐 ,

ℓ (cid:205)𝑘 𝑥𝑘𝑐𝑥𝑘 𝑑 − (cid:205)𝑘 𝑥𝑘𝑐 (cid:205)𝑘 𝑥𝑘 𝑑

,

𝑚 =

and

𝑐 =

1
ℓ

(cid:32)

∑︁

𝑘

ℓ (cid:205)𝑘 𝑥2

𝑘𝑐 − ((cid:205)𝑘 𝑥𝑘𝑐)2
(cid:33)

𝑥𝑘 𝑑 − 𝑚 ∑︁

𝑥𝑘𝑐

.

𝑘

The quantity ˆ𝑥𝑘 𝑑 is the predicted ARP degree by this linear model. The sum of squares errors is given by

SSE =

∑︁

𝑘

( ˆ𝑥𝑘 𝑑 − 𝑥𝑘 𝑑)2 ,

that is the squared diﬀerence between the actual and the predicted degree values summed over the number
of ARP calls. A low value of SSE indicates that the line is a better ﬁt for the data compared to a high SSE
value. These three features, slope, intercept and SSE, are added to the feature pool. An example line of
best ﬁt is shown in Figure 8(c).

8. The equivalent of features 6 and 7 are computed for TCP. This gives the total length of the line segments
in the TCP PC1, PC2 space along with the slope, intercept and sum of errors squares of the line of best
ﬁt (see Figure8(b)).

9. Similarly, the length of the line segments in the UDP PC1, PC2 space and the slope, intercept and SSE of

the line of best ﬁt are computed.

We now have 17 features describing the multivariate time series for each node, thus transforming each time
series to a point in R17. Therefore, a time window containing data from 𝑚 distinct nodes gives rise to 𝑚 time
series, which get transformed to 𝑚 points in R17, with each point denoting the behavior of a node in that time
window.

4.2.3 Dimension reduction and anomaly detection: Identifying anomalies after dimension reduction

In higher dimensions it is hard to diﬀerentiate anomalies from non-anomalies because points are far away
from each other. Therefore, we reduce dimensions using PCA and use the ﬁrst 2 dimensions in the PC space
for anomaly detection. We use the algorithm Lookout (Kandanaarachchi & Hyndman 2021) and an OCSVM
to identify anomalies in this two dimensional space. Lookout uses Extreme Value Theory (EVT) (Coles 2001)
and leave-one-out kernel density estimates to identify anomalies. We brieﬂy describe the algorithm Lookout
next.

1. To compute kernel density estimates, a bandwidth parameter is required. However, the bandwidth suited
for representing the data in general is not suitable for anomaly detection. Using persistent homology
(Ghrist 2008), a methodology in topological data analysis, Lookout chooses a bandwidth appropriate for
anomaly detection.

12

ARP degree

𝑡4

𝑡2

𝑡8

𝑡6

𝑡1

𝑡3

𝑡5
ARP count

(a)

TCP PC2

𝑡2

𝑡5

𝑡9

(b)

𝑡4

TCP PC1

ARP degree

𝑡4

𝑡2

𝑡6

𝑡5

𝑡1

𝑡3

𝑡8
ARP count
(c)

Figure 8: (a) The ARP degree and count for a hypothetical node at diﬀerent time points,
with successive time points connected by line segments. The total length of these line
segments is a feature. (b) The TCP PC1 and PC2 coordinates for the same node, some of
which occur at diﬀerent time points; the total length of these line segments is calculated.
(c) The line of best ﬁt for points in the ARP space. The slope, intercept and the sum of
squares errors are calculated using this line of best ﬁt.

2. Using this bandwidth, kernel density estimates (kde) and leave-one-out kernel density estimates are

computed for the data.

3. As anomalies are rare, they lie in low density regions in a feature space. The bandwidth selected in step
2 results in anomalies having low kde and leave-one-out kde values. However, we want to identify the
anomalies, not just give an anomaly score for all the data points. A threshold is needed so that anomalies
with kde values lower than this threshold are declared anomalous. We set a threshold by computing the
probabilities of the points using EVT. Speciﬁcally, by using Generalized Pareto Distributions.

4. If the probability of a point is below a predeﬁned threshold 𝛼, it is declared anomalous.

For this work we set the threshold as 𝛼 = 0.1, i.e., if the probability 𝑝 of a point being present using the
Generalized Pareto Distribution is less than 0.1, we identify it as an anomaly. Using this probability 𝑝 the
anomaly score is given by

𝑠 = (0.1 − 𝑝) × 100 ,

resulting in the anomaly scores lying between 0 and 10 with data points with zero probability having an anomaly
score of 10. See Kandanaarachchi & Hyndman (2021) for more details on Lookout.

Detecting a stream of false anomalies decreases conﬁdence in the NAD system making a technique with low
false positives attractive in this domain. EVT related methods only identify extremes as anomalies. As such,
we expect Lookout to have a low false positive rate. One-class SVMs (OCSVM) are often used for anomaly
detection in an unsupervised setting. Given the challenges posed by high false positives in NAD, we compare
the performance of Lookout with an OCSVM.

As the sliding time windows overlap, some nodes are identiﬁed as anomalies in multiple time windows,
while others appear as anomalous only in one time window. If a node is identiﬁed as anomalous in multiple
time windows, it is a persistent anomaly, and provides grounds for investigation.

4.3 Vertical Approach

The horizontal approach investigates the activity of each node as a time series and ﬁnds anomalous time
series. In contrast, the vertical approach focuses on each protocol to ﬁnd anomalous activity. All observations
in a single protocol have the same number of attributes, and thus the same dimension, making the vertical

13

approach much simpler as it does not face the challenge of assembling varying dimensional data into a single
construct. The vertical approach comprises the following steps:

1. The numerical feature space for each protocol has diﬀerent dimensions, with ARP being 2-dimensional
feature space, TCP 11-dimensional and UDP 3-dimensional (see Table 1). Identifying anomalies in high
dimensions is diﬃcult, and we consider a 2-dimensional space for each protocol. For ARP we take the
count and the degree. For TCP and UDP we perform PCA and take the ﬁrst two PC scores.

2. Lookout and an OCSVM are used to ﬁnd anomalies in each protocol’s 2D space.

3. The anomalies are combined by node and time window to gain better insights.

For the vertical approach, each point in a protocol 2D space represents a single communication from a node
using that protocol. Nodes communicating multiple times in a time window are represented by multiple points
in the vertical approach. Thus, if a node 𝑁 communicates using ARP, TCP and UDP 𝑚1, 𝑚2 and 𝑚3 times
respectively, it will result in 𝑚1 points in the ARP space, 𝑚2 points in the TCP space and 𝑚3 points in the UDP
space.

Finally, the anomalies identiﬁed from the horizontal and vertical approaches for each time window are
amalgamated to get a better understanding of the behavior of the nodes. A node identiﬁed as anomalous by
both horizontal and vertical approaches gains higher priority for further inspection than a node identiﬁed by a
single approach.

5 Results

This section details the results found from using Honeyboost to identify anomalous nodes. We start with

comparing the two AD methods used in Honeyboost with regards to early detection of anomalous nodes.

5.1 Early detection

The two AD methods in Honeyboost – Lookout and OCSVM – perform similarly and identify most nodes as
anomalous before they access the honeypot. Table 3 shows the anomalous nodes, the earliest time they access
the honeypot and the results of the 2 AD methods. The Table gives the earliest time each AD method identiﬁes
a node as anomalous. If this detection happens before the node accesses the honeypot, it is labeled as early
detection, denoted by Early under the heading Status. The table also indicates the time each node is identiﬁed
as anomalous under the heading Time Diﬀerence with positive values indicating early detection. As the window
step size is 3600 seconds, any time diﬀerence in the interval [−3600, 0) indicates the anomaly was identiﬁed in
the same time window.

Of the 15 nodes that access the honeypot, Lookout identiﬁes 13 nodes before they access the honeypot and
2 nodes (N220 and N225) in the same time window that they access the honeypot. The OCSVM identiﬁes all
nodes before they access the honeypot.

Given that Honeyboost identiﬁes anomalies before they access the honeypot, it is important to consider the
number of false positives it generates. Note that if a node is tagged as anomalous the ﬁrst time it communicates
with another node, Honeyboost would detect all anomalies early. However, such a strategy would create a
barrage of false positives, greatly reducing the conﬁdence in the system. For example, a home security system
that constantly trips the alarm. Therefore, it is imperative to consider the false positive rate, i.e., early detection
is valuable only if the false positive rate is low.

14

Table 3: Early detection of honeypot anomalies - amalgamated results using the hori-
zontal and vertical approaches (Early = Early Detection, SW = Same Window)

Earliest
Honeypot
Time

1598842055
1553585825
1553751195
1566462345
1554351595
1563528080
1565313000
1555312055
1555313055
1567236235
1565059350
1564535840
1565758430
1565758055
1575507740

Node

N021
N039
N046
N132
N135
N153
N155
N158
N159
N163
N171
N219
N220
N225
N239

Lookout Results

OCSVM Results

Earliest Anomaly
Detection Time

Status

Time Diﬀerence
(Positive = Early)

Earliest Anomaly
Detection Time

Status

Time Diﬀerence
(Positive = Early)

1550034180
1553585820
1549530120
1561276560
1554351540
1555997940
1557801000
1555311960
1555312740
1558260780
1563260880
1564535760
1565758435
1565758080
1572234480

Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
SW
SW
Early

48807875
5
4221075
5185785
55
7530140
7512000
95
315
8975455
1798470
80
-5
-25
3273260

1547269200
1547449140
1547521980
1554347700
1554351540
1554803160
1554952440
1555311900
1555312740
1557228000
1558065360
1564535760
1564552620
1565695320
1568005320

Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early
Early

51572855
6136685
6229215
12114645
55
8724920
10360560
155
315
10008235
6993990
80
1205810
62735
7502420

Figure 9: False positives using Lookout and the OCSVM for all time windows. Figures
(a) and (c) give the number of false positives for the vertical and horizontal approaches.
Figures (b) and (d) give the false positive rates for the two approaches.

15

5.2 False positives

We investigate the number of false positives and the false positive rate, deﬁned as the ratio of the number
of false positives to the total number of negatives for both the horizontal and the vertical approaches. Figure 9
shows the false positives and the false positive rates for both Lookout and OCSVM for both approaches. Figures
9(a) and (c) show boxplots of the number of false positives for each time window. The false positive rate is
given in Figures 9(b) and (d).

Lookout achieves a low false positive rate compared to the OCSVM for both approaches. In the vertical
approach, the OCSVM identiﬁes many nodes as anomalies in each window with a median of 20 false positives.
In some windows the OCSVM outputs 80 false positives. This large number of false positives causes the false
positive rate to have a median of 37% and an upper quartile of 87%. The highest false positive rate for the
OCSVM for the vertical approach is close to 1.

It is interesting to note that the vertical approach produces more false positives for the OCSVM compared to
the horizontal approach. This is due to the number of data points in a time window for each approach. Suppose
a given time window has 𝑁 ARP calls belonging to 𝑛 nodes with 𝑁 >> 𝑛. Generally 𝑁 is orders of magnitude
higher than 𝑛. The horizontal approach constructs a data point for each node in each window giving rise to 𝑛
data points. In contrast, the vertical approach has 𝑁 data points. Thus, it is clear the OCSVM identiﬁes more
nodes as anomalous when there are a large number of data points.

Given that Lookout identiﬁes anomalies early and still has a low false positive rate, we focus on the results

produced by Lookout for the remainder of the paper.

5.3 Amalgamating horizontal and vertical anomalies

For each window, the anomalies detected by the horizontal and vertical approaches are amalgamated.
Table 4 shows the anomalies identiﬁed and amalgamated for the vertical and horizontal approaches for each
of 4 windows, using Lookout. In window 2270, 2 anomalies were identiﬁed: N046 is identiﬁed by both the
horizontal and vertical approaches, while N157 is identiﬁed only by the vertical approach. Window 5080 also
produces 2 anomalies: N220 and N225, both of which are identiﬁed only by the horizontal approach. Windows
7700 and 14240 identify nodes N239 and N021 respectively.

Table 4: Amalgamation of horizontal and vertical anomalies for 4 windows.

Window Node Horizontal

Anomaly

Vertical
Anomaly

Horizontal
Anomaly
Score

Vertical
Anomaly
Score

Anomaly History (previous windows)

2270

5080

7700
14240

N046
N157
N220
N225
N239
N021

(cid:88)
–
(cid:88)
(cid:88)
–
(cid:88)

(cid:88)
(cid:88)
–
–
(cid:88)
(cid:88)

10
–
10
10
–
9.97

19.9
11.8
–
–
10
9.93

2269, 2268, 2267, . . .
2269, 2268, 2267, . . .
5079, 5078, 5077, . . .
5079, 5078, 5077, . . .
7610, 7586, 7585, . . .
14239, 14238, 14237, . . .

From Table 4, given Lookout’s low false positive rates, it is clear that every anomalous node identiﬁed,
even by a single approach, horizontal or vertical, should be further investigated. We do this by comparing the
results of Table 4 with that of Table 3. Of the anomalies identiﬁed in window 2270, for example, N046 is a real
anomalies – we regard it as suspicious because it accesses the honeypot. N157 is a false positive as it does not
access the honeypot. Similarly, in window 5080, both N220 and N225 are real anomalies, as is the case with
N239 and N021.

16

6 Insights and Discussion

Lookout is the preferred anomaly detection method employed in Honeyboost. As shown in Figure 2, Hon-
eyboost encompasses the complete framework, starting from the pre-processing and ending with amalgamating
the anomalies that are found by vertical and horizontal approaches.

6.1 Tracking anomalies as they develop over time

The amalgamation of the horizontal and vertical approaches lets us observe the anomalies as they develop
in diﬀerent spaces. For example, a node may be identiﬁed as anomalous by the horizontal approach and later
identiﬁed as anomalous by both approaches. The vertical approach identiﬁes anomalies in each of the ARP, TCP
and UDP spaces separately and then combines them. In contrast, the horizontal approach identiﬁes anomalies
in the combined feature space.

Figure 10: Anomalies detected by the vertical and horizontal approaches in windows
1921, 1922, 2089, 2090, 2091, 2109, 2110, 4149, 4150, 4371, 4372, 4651, 4652, 4653,
5186 and 5187. As the vertical approach consists of each of the ARP, UDP and TCP
spaces, anomalies identiﬁed separately in these spaces are included. The vertical axis
shows the anomalous nodes and the horizontal axis gives the windows and anomaly
types. For example 1921_H denotes horizontal anomalies identiﬁed in window 1921
and 1921_V_A denotes the vertical anomalies identiﬁed in the ARP space in window
1921. The colors indicate the logarithm of anomaly scores with darker shades denoting
larger scores.

Figure 10 shows the windows 1921, 1922, 2089, 2090, 2091, 2109, 2110, 4149, 4150, 4371, 4372, 4651,
4652, 4653, 5186 and 5187 and all anomalies identiﬁed in these windows by Lookout. The 𝑌 axis shows all
nodes labeled as anomalous in these windows. The 𝑋 axis gives the diﬀerent anomaly types sorted by windows.
The anomalies identiﬁed in the horizontal and vertical approaches are diﬀerentiated with an _H and _V label,
respectively. The vertical approach anomalies are further classiﬁed as ARP, TCP and UDP space anomalies.

17

Thus, if an anomaly is identiﬁed by the vertical approach in the ARP space it is tagged with _V_A. Similarly,
vertical TCP and UDP anomalies are tagged with _V_T and _V_U, respectively. The 𝑋 axis labels start with the
window number followed by the anomaly type. Thus, 1921_H denotes horizontal anomalies in window 1921.
Similarly 1921_V_A, 1921_V_T and 1921_V_U denotes vertical ARP, TCP and UDP anomalies in window
1921. The color of the cells denote the logarithm of the anomaly scores with darker shades denoting larger
scores. The windows are separated by dashed lines.

We look at an example of a developing anomaly. In window 1921, N135 is the only node identiﬁed as
anomalous, and is identiﬁed as such by the horizontal as well as the vertical approach, though only in the ARP
space in the latter case. It is then identiﬁed in the vertical UDP space, in window 1922, with a relatively high
anomaly score as seen from the darker color. It is further identiﬁed in window 2089, in the horizontal, as well
as vertical ARP and UDP spaces. Again, in later time windows (4150, 4371), it is identiﬁed as anomalous in
the horizontal, and vertical ARP and UDP spaces.

Nodes N158 and N159 are two further examples. They are identiﬁed as anomalous in window 2090
by the horizontal approach, as well as in the vertical UDP space. These two nodes continue to increase in
anomalousness in subsequent windows as seen by the darker shades of red. In window 2109, both nodes are
identiﬁed by the vertical approach in the ARP, UDP and TCP spaces, with high anomaly scores.

the
Other examples of developing anomalies in these set of windows are N218 and N219. Thus,
amalgamation of the horizontal and vertical approaches enables us to see the anomalies develop, assisting in
the decision making process. Furthermore, Figure 10 shows all anomalies identiﬁed by the two approaches in
this set of windows. The maximum number of anomalies identiﬁed by Lookout in this set of windows is 4,
occurring in windows 2090 and 4149. In comparison, the OCSVM identiﬁes an average of 32.7 anomalies
per window for this set of windows, with a minimum of 3 and a maximum of 58 nodes. Having a smaller
number of anomalies increases clarity and helps focus on the important aspects. This is another advantage of
identifying anomalies sparingly.

6.2 Tracking a node’s anomalous nature

Next, we focus on individual nodes instead of looking at all anomalies identiﬁed in a given window.
Figures 11 and 12 show the behavior of nodes N046, N132, N153 and N239 over a range of windows along with
their anomaly scores. From Figure 12 we see that these nodes are identiﬁed as anomalous either by a single
approach or by both approaches in sets of consecutive windows. For example, N046 is identiﬁed as anomalous
in windows 628 to 650, 1656 to 1822 and in windows 2090 to 2277. We see a similar behavior by each of the
other nodes.

This observation is further validated in Figure 12, in which we explore the ARP, UDP and TCP anomaly
spaces for the vertical approach in addition to the horizontal approach. We only show a subset of windows in
Figure 12 due to space constraints. Node N046 is ﬁrst identiﬁed by the vertical approach in the ARP space
in window 628. Later, in window 1656 it is identiﬁed as anomalous by the horizontal approach as well. This
behavior continues for a while and in window 2118 it is identiﬁed by the horizontal approach and the vertical
approach in the ARP and TCP spaces. It continues to be identiﬁed in multiple vertical approach spaces until
window 2277.

We see a similar pattern for node N132. Initially it is identiﬁed by the vertical approach in the ARP space
in window 3791. In window 5187 it gets identiﬁed by the horizontal approach, and the vertical approach in
the ARP, UDP and the TCP spaces. This continues for many windows and then it slowly dies down. Nodes
N153 and N239 also display a similar pattern where they are identiﬁed by a single approach and then by both
approaches in multiple spaces with higher anomaly scores.

18

Figure 11: The horizontal and vertical anomaly scores for nodes N046, N132, N153
and N239 over all time windows. The 𝑋 axis of each graph displays the range of time
windows for which these nodes are identiﬁed as anomalous starting from the window
they were ﬁrst found as anomalous, to the last window. For example, N132 does not get
identiﬁed before window 3791. As such, windows before 3791 are not included in the
graph for N132.

6.3

Insights into anomalous behavior

We now combine the results found thus far to gain insights into anomalous behavior. Table 5 lists the total
anomaly score, the number of windows reporting the node as anomalous, and the average anomaly score per
window, of the nodes accessing the honeypot. The total anomaly score for each node is the sum of the horizontal
and vertical anomaly scores for the full time period. Figure 13 shows the vertical and horizontal anomaly scores
for the top 6 anomalous nodes from this table. We investigate these anomalies to gain better understanding.

1. N135: This node suddenly makes a large number of ARP broadcasts (count 757, degree 257) and accesses
the honeypot using UDP and TCP. The total length of the UDP packets per 5s time interval are unusually
high for N135. The median value of the total length of the UDP packets, taking into account all nodes
accessing the honeypot, is 28. For N135 the total UDP packet length ranges from 28 to 1047, with a
median of 927. N135 has the highest total anomaly score because it is identiﬁed in 1351 windows. From
Figure 13 we see that it displays a lot of activity for a long period of time.

2. N159: This node makes innocuous ARP broadcasts for the ﬁrst 9 minutes of its communication. Then,
it suddenly makes a large number of ARP broadcasts (count 6760, degree 3384) and starts accessing the
honeypot immediately after that, using 32 UDP ports in a single 5 second interval. After a time lag of
1 hour, it accesses the honeypot using 999 TCP ports. From Figure 13 we see that the vertical anomaly
scores in certain windows are much higher for N159 compared to other nodes. Furthermore, it is only
found anomalous in 169 windows. Thus, N159 has the highest average anomaly score per window.

3. N153: This node is found anomalous in 848 windows.

It has a long span of activity as seen from

19

Figure 12: Selected windows for nodes N046, N132, N153 and N239. The anomaly
scores for the horizontal approach, and the vertical approach in the ARP, UDP and TCP
spaces, are shown for each node with dashed lines showing window boundaries. We
see the behavior of the nodes over time.

Figure 13. In terms of the ARP broadcasts, it has a higher count to degree ratio compared to most other
nodes.

4. N158: This node has very large ARP counts for a long period of time, with a maximum ARP count of
6536 and degree 3262 for a given time interval. After these ARP broadcasts it accesses the honeypot
using 32 UDP ports and 999 TCP ports.

5. N132: Again, we see extremely large ARP counts for multiple time intervals. The maximum ARP count
for N132 is 22558 with degree 4416. It then accesses the honeypot using TCP and UDP protocols. We
ﬁnd that N132 has set the PSH (push) and the URG (urgent) ﬂags in some TCP packets that access the
honeypot. The PSH ﬂag informs the receiving node that the data should be pushed to the application
layer immediately, and the URG ﬂag informs the receiver that the data should be prioritized.

6. N219: Similar to N132, this node sets the PSH and URG ﬂags for some TCP packets and accesses the

honeypot using a large number of TCP ports.

Certain patterns emerge from this analysis. Some nodes such as N135 and N153 are identiﬁed as anomalous
in a large number of windows. These nodes access the honeypot over a long period of time. In contrast, other

20

Table 5: Nodes accessing the honeypot sorted by the total anomaly score. The number
of windows reporting the node as anomalous as well as the average score per window
are also given.

Node

N135
N159
N153
N158
N132
N219
N021
N155
N046
N039
N163
N239
N225
N220
N171

Horizontal
Anomaly
Score Total

Vertical
Anomaly
Score Total

Total
Anomaly
Score

Number of
Anomalous
Windows

Average
Score Per
Window

6998
1487
959
1517
4119
1793
2615
1420
1965
2092
1060
1333
1070
1240
940

62473
30180
23902
22235
9305
7072
5657
6002
3191
2297
2670
1899
1291
0
18

69471
31666
24862
23752
13424
8865
8272
7421
5157
4389
3730
3232
2361
1240
958

1351
169
848
172
551
194
766
427
360
210
152
334
247
124
98

51.4
187.0
29.3
138.0
24.4
45.7
10.8
17.4
14.3
20.9
24.5
9.68
9.56
10.0
9.78

Figure 13: The horizontal and vertical anomaly scores for the top 6 anomalous nodes
accessing the honeypot, as per Table 5.

nodes such as N219, access the honeypot over a small time interval and are identiﬁed as anomalous with high
anomaly scores.

Furthermore, we see diﬀerent types of suspicious behavior: unusually high number of ARP broadcasts
by a node before accessing the honeypot followed by TCP or UDP packets targeted at the honeypot using a

21

large number of ports; and nodes accessing the honeypot using speciﬁc TCP ﬂags that requests urgent attention
and access to higher layers. Overall, it is clear that by combining the horizontal and vertical approaches,
Honeyboost, via Lookout, prioritizes the nodes that need more inspection.

6.4 False Positives vs identifying anomalies

Honeyboost identiﬁes all nodes accessing the honeypot. In addition, it identiﬁes most nodes before they
access the honeypot. Of the identiﬁed anomalies, all do not access the honeypot, i.e. some are false positives.
Table 6 shows the top 3 anomalous nodes, N001, N135, and N157, identiﬁed by Honeyboost and their anomaly
scores.

Table 6: Top 3 Honeyboost anomalies sorted by the total anomaly score. The number
of anomalous windows and average score per window are also given.

Node

Horizontal
Anomaly
Score Total

Vertical
Anomaly
Score Total

N157
N001
N135

230
72178
6998

585540
5744
62473

Total
Anomaly
Score

585770
77921
69471

Number of
Anomalous
Windows

Average
Score Per
Window

86
7445
1351

6811
10.5
51.4

Of these 3 nodes, we discussed N135 in Section 6.3. The other 2 nodes, N157 and N001 do not access the

honeypot. However, it is worth discussing their behavior.

Figure 14 shows the anomaly scores, ARP count and degree values for N157 over time. From Figure 14(a),
we see that the vertical anomaly scores for N157 are extremely large. Many anomaly scores are greater than
5000, and some scores are over 40,000. In fact, from Figure 14(a) it is misleading to think that the horizontal
score is zero for all windows. For some windows the horizontal score is 10, the maximum score for the
horizontal approach, but this is dwarfed by the high values in the vertical axis. The vertical approach does not
have a maximum score as a node can make multiple calls using ARP, UDP and TCP protocols and if many of
them are identiﬁed anomalous the sum of the anomaly scores is considered for each window.

The reason for high anomaly scores from the vertical approach is the large number of ARP calls with high
count that are not balanced by high degree values as seen in Figures 14(b) and (c). Starting from timestamp
1555482240, for every 60s interval N157 makes over 110 ARP broadcasts over 6381 minutes continuously
as can be seen from the thick, black line in Figure 14(b). It is rather unusual for a node to make such ARP
broadcasts continuously for a long period of time. Especially, as it did not make such ARP broadcasts before
that time. Therefore, this node needs investigation.

Another node of interest is N001. Figure 15(a) shows a histogram of the number of windows each node is
found anomalous. N001 is found anomalous in 7445 windows and is the most frequently identiﬁed anomaly
surpassing the other nodes by a large margin. Figure 15(b) shows the anomaly scores for N001 for the horizontal
and vertical approaches. On investigating the feature space, we ﬁnd that this node has a relatively large total
length of 73.4 in the ARP space (Section 4.2.2, feature 6). It turns out this node has made 4635 ARP broadcasts
at diﬀerent time points in its ﬁrst anomalous time window, all having count and degree values of 1, 2, or 3.
Over the full time period, it makes 445,100 ARP broadcasts. Therefore, N001 is unusual because it makes a
small number of ARP broadcasts extremely frequently over a long period of time. It might be a malfunctioning
node needing investigation. We also note that node N001 would not have been identiﬁed by simply tagging the
nodes making a large number of ARP broadcasts.

22

Figure 14: Behavior of Node N157: (a) Anomaly scores. (b) The ARP count over time.
(c) The ARP degree over time.

Figure 15: Behavior of Node N001: (a) Histogram of the nodes identiﬁed as anomalies
in all time windows with N001 getting identiﬁed 7445 times. N001 is labeled in this
histogram. (b) The horizontal and vertical anomaly scores over all windows for N001.

7 Conclusion

In this paper, we presented Honeyboost, a novel, hybrid framework consisting of two complementary
approaches – horizontal and vertical – to enhance honeypot aided NAD. Both approaches use data fusion
techniques to integrate attributes from diverse protocols. Our methodology does not suﬀer from a high false
positive rate as we use an anomaly detection method called Lookout, which uses extreme value theory to identify

23

anomalies. Furthermore, it operates totally unsupervised, alleviating the need for costly labeling procedures.
Using our framework, we successfully identiﬁed anomalous nodes before they accessed the honeypot.
In
addition, we gained useful insights about the behavior of these nodes. Moreover, we identiﬁed some unusual
behavior by nodes that do not access the honeypot. As future work, we plan to investigate network science and
graph theory approaches to further boost early detection and classiﬁcation of anomalies.

References

Ahmed, M., Naser Mahmood, A. & Hu, J. (2016), ‘A survey of network anomaly detection techniques’, Journal

of Network and Computer Applications 60, 19–31.

Almohannadi, H., Awan, I., Al Hamar, J., Cullen, A., Disso, J. P. & Armitage, L. (2018), Cyber threat
intelligence from honeypot data using elasticsearch, in ‘Proceedings - International Conference on Advanced
Information Networking and Applications, AINA’, Vol. 2018-May, pp. 900–906.

Anirudh, M., Arul Thileeban, S. & Nallathambi, D. J. (2017), Use of honeypots for mitigating DoS attacks
targeted on IoT networks, in ‘International Conference on Computer, Communication, and Signal Processing:
Special Focus on IoT, ICCCSP 2017’.

Baddar, S. H. A. H., Merlo, A. & Migliardi, M. (2014), ‘Anomaly detection in computer networks: A state-of-
the-art review’, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications
5(4), 29–64.

Barak, I. (2020), ‘Critical infrastructure under attack: lessons from a honeypot’, Network Security 2020(9), 16–

17.

Baykara, M. & Das, R. (2018), ‘A novel honeypot based security approach for real-time intrusion detection and

prevention systems’, Journal of Information Security and Applications 41, 103–116.

Campbell, R. M., Padayachee, K. & Masombuka, T. (2015), A survey of honeypot research: Trends and oppor-
tunities, in ‘2015 10th international conference for internet technology and secured transactions (ICITST)’,
IEEE, pp. 208–212.

Coles, S. (2001), An introduction to statistical modeling of extreme values, Vol. 208, Springer.

Fan, W., Du, Z., Smith-Creasey, M. & Fernandez, D. (2019), ‘HoneyDOC: An Eﬃcient Honeypot Architecture

Enabling All-Round Design’, IEEE Journal on Selected Areas in Communications 37(3), 683–697.

Fernandes, G., Rodrigues, J. J., Carvalho, L. F., Al-Muhtadi, J. F. & Proença, M. L. (2019), ‘A comprehensive

survey on network anomaly detection’, Telecommunication Systems 70(3), 447–489.

Ghrist, R. (2008), ‘Barcodes: the persistent topology of data’, Bulletin of the American Mathematical Society

45(1), 61–75.

Goldstein, M. & Uchida, S. (2016), ‘A comparative evaluation of unsupervised anomaly detection algorithms

for multivariate data’, PLoS ONE 11(4).

Hamamoto, A. H., Carvalho, L. F., Sampaio, L. D. H., Abrão, T. & Proença, M. L. (2018), ‘Network Anomaly
Detection System using Genetic Algorithm and Fuzzy Logic’, Expert Systems with Applications 92, 390–402.

Handa, A., Negi, R. & Shukla, S. K. (2021), Part I Deception Technologies amp; Threat Visibility – Honeypots

and Security Operations, pp. 3–3.

24

Hawkins, D. M. (1980), Identiﬁcation of outliers, Vol. 11, Springer.

Hernández-Campos, F., Marron, J. S., Samorodnitsky, G. & Smith, F. D. (2004), ‘Variable heavy tails in Internet

traﬃc’, Performance Evaluation 58(2-3), 261–284.

Imrana, Y., Xiang, Y., Ali, L. & Abdul-Rauf, Z. (2021), ‘A bidirectional LSTM deep learning approach for

intrusion detection’, Expert Systems with Applications 185, 115524.

Jasek, R., Kolarik, M. & T., V. (2013), APT detection system using honeypots, in ‘13th International Conference

on Applied Informatics and Communications (AIC’13)’, pp. 25–29.

Kandanaarachchi, S. & Hyndman, R. J. (2021), Leave-one-out kernel density estimates for outlier detection,

Technical report, RMIT University.
URL: http://bit.ly/lookoutliers

Kelley, D. (2019), Microsoft security intelligence report volume 24, Technical report.

URL: https://www.microsoft.com/sir/

Khan, A. S., Ahmad, Z., Abdullah, J. & Ahmad, F. (2021), ‘A Spectrogram Image-Based Network Anomaly

Detection System Using Deep Convolutional Neural Network’, IEEE Access 9, 87079–87093.

Kondra, J. R., Bharti, S. K., Mishra, S. K. & Babu, K. S. (2016), Honeypot-based intrusion detection sys-
tem: A performance analysis, in ‘2016 3rd International Conference on Computing for Sustainable Global
Development (INDIACom)’, pp. 2347–2351.

La, Q. D., Quek, T. Q., Lee, J., Jin, S. & Zhu, H. (2016), ‘Deceptive Attack and Defense Game in Honeypot-

Enabled Networks for the Internet of Things’, IEEE Internet of Things Journal 3(6), 1025–1035.

Liu, X., Liu, W., Di, X., Li, J., Cai, B., Ren, W. & Yang, H. (2021), ‘LogNADS: Network anomaly detection

scheme based on log semantics representation’, Future Generation Computer Systems 124, 390–405.

Matin, I. M. M. & Rahardjo, B. (2020), The Use of Honeypot in Machine Learning Based on Malware Detection:
A Review, in ‘2020 8th International Conference on Cyber and IT Service Management, CITSM 2020’.

Maxion, R. A. (1990), ‘Anomaly detection for diagnosis’, Digest of Papers - FTCS (Fault-Tolerant Computing

Symposium) pp. 20–27.

Mokube, I. & Adams, M. (2007), Honeypots: Concepts, approaches, and challenges, in ‘Proceedings of the

Annual Southeast Conference’, Vol. 2007, pp. 321–326.

Moore, C. & Al-Nemrat, A. (2015), An analysis of honeypot programs and the attack data collected, in

‘Communications in Computer and Information Science’, Vol. 534, pp. 228–238.

Moustafa, N., Hu, J. & Slay, J. (2019), ‘A holistic review of Network Anomaly Detection Systems: A

comprehensive survey’, Journal of Network and Computer Applications 128, 33–55.

Naveed, K. & Wu, H. (2020), ‘Celosia: An Immune-Inspired Anomaly Detection Framework for IoT Devices’,

Proceedings - Conference on Local Computer Networks, LCN 2020-November, 13–23.

Ochiai, H. (2020), ‘Lan-security monitoring project’, IEICE Technical Report; IEICE Tech. Rep. 120(19), 27–38.

Ramaswami, V., Jain, K., Jana, R. & Aggarwal, V. (2014), ‘Modeling heavy tails in traﬃc sources for network

performance evaluation’, Advances in Intelligent Systems and Computing 246, 23–44.

25

Razali, M. F., Muruti, G., Razali, M. N., Jamil, N. & Mansor, F. Z. (2019), IoT honeypot: A review from
researcher’s perspective, in ‘2018 IEEE Conference on Application, Information and Network Security,
AINS 2018’, pp. 93–98.

R.D. Reiss & M.Thomas (2001), Statistical Analysis of Extreme values with Applications to Insurance, Finance,

Hydrology and Other Fields, Vol. 44.

Ruﬀ, L., Kauﬀmann, J. R., Vandermeulen, R. A., Montavon, G., Samek, W., Kloft, M., Dietterich, T. G. &

Müller, K. R. (2020), ‘A unifying review of deep and shallow anomaly detection’, arXiv .

Sadasivam, G. K. & Hota, C. (2015), ‘Scalable honeypot architecture for identifying malicious network
activities’, Proceedings - 2015 2nd International Conference on Emerging Information Technology and
Engineering Solutions, EITES 2015 pp. 27–31.

Seungjin, L., Abdullah, A. & Jhanjhi, N. Z. (2020), ‘A review on honeypot-based botnet detection models for
smart factory’, International Journal of Advanced Computer Science and Applications 11(6), 418–435.

Shrivastava, R. K., Bashir, B. & Hota, C. (2019), Attack Detection and Forensics Using Honeypot in IoT
Environment, in G. Fahrnberger, S. Gopinathan & L. Parida, eds, ‘Distributed Computing and Internet
Technology’, Springer International Publishing, pp. 402–409.

Sohn, I. (2021), ‘Deep belief network based intrusion detection techniques: A survey’, Expert Systems with

Applications 167, 114170.

Talagala, P. D., Hyndman, R. J., Smith-Miles, K., Kandanaarachchi, S. & Muñoz, M. A. (2020), ‘Anomaly
Detection in Streaming Nonstationary Temporal Data’, Journal of Computational and Graphical Statistics
29(1), 13–27.

Tiruvakadu, D. S. K. & Pallapa, V. (2018), ‘Conﬁrmation of wormhole attack in MANETs using honeypot’,

Computers and Security 76, 32–49.

Wang, H., Bah, M. J. & Hammad, M. (2019), ‘Progress in Outlier Detection Techniques: A Survey’, IEEE

Access 7, 107964–108000.

Zhan, Z., Xu, M. & Xu, S. (2013), ‘Characterizing honeypot-captured cyber attacks: Statistical framework and

case study’, IEEE Transactions on Information Forensics and Security 8(11), 1775–1789.

Zhang, J., Bhuiyan, M. Z. A., Yang, X., Wang, T., Xu, X., Hayajneh, T. & Khan, F. (2021), ‘AntiConcealer:
Reliable Detection of Adversary Concealed Behaviors in EdgeAI Assisted IoT’, IEEE Internet of Things
Journal pp. 1–1.

Zhou, Y., Mazzuchi, T. A. & Sarkani, S. (2020), ‘M-AdaBoost-A based ensemble system for network intrusion

detection’, Expert Systems with Applications 162, 113864.

26

