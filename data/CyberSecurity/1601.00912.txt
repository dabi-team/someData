ARL-TR-7566 ● DEC 2015 

US Army Research Laboratory 

Assessing Mission Impact of Cyberattacks: 
Report of the NATO IST-128 Workshop  

by Alexander Kott, Nikolai Stoianov, Nazife Baykal, Alfred 
Moller, Reginald Sawilla, Pram Jain, Mona Lange, and Cristian 
Vidu 

Approved for public release; distribution unlimited. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
NOTICES 

Disclaimers 

The findings in this report are not to be construed as an official Department of the 
Army position unless so designated by other authorized documents. 

Citation  of  manufacturer’s  or  trade  names  does  not  constitute  an  official 
endorsement or approval of the use thereof. 

Destroy this report when it is no longer needed. Do not return it to the originator. 

 
 
 
 
ARL-TR-7566 ● DEC 2015 

US Army Research Laboratory 

Assessing Mission Impact of Cyberattacks: 
Report of the NATO IST-128 Workshop  

by Alexander Kott, Computational and Information Sciences 
Directorate, ARL 

Nikolai Stoyanov, Defense Institute, Bulgaria 

Nazife Baykal, Middle Eastern Technical University, Turkey 

Alfred Moller, Danish Defence Acquisition and Logistics 
Organization, Denmark 

Reginald Sawilla, NATO Communications and Information Agency, 
Netherlands 

Pram Jain, MITRE, USA 

Mona Lange, University of Lübeck, Germany 

Cristian Vidu, National University for Political Sciences and Public 
Administration, Romania 

Approved for public release; distribution unlimited.

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Contents 

Acknowledgments 

1. 

Introduction 

2. 

Findings of the Workshop 

2.1  The Key Finding: The Primacy of a Model-driven Paradigm 

2.2  Mission Impact Assessment Problem Formulation 

2.3  Model Content 

2.4  Models of Adversary 

2.5  Models of Humans 

2.6  Model Construction 

2.7  Data Requirements 

3. 

Conclusion 

iv 

1 

3 

3 

4 

7 

8 

9 

10 

11 

11 

3.1  Selected Observations on the Current State of R&D in MIA (Outcome 

of Brainstorming Sessions) 

3.2  Selected Suggestions for the Future of R&D in MIA (Outcome of 

Brainstorming Sessions) 
3.2.1  Operations 
Formalisms 
3.2.2 
3.2.3  Automation 
3.2.4  Data 

3.3  Recommendations for a Follow-on Activity 

4.  References 

Appendix A. The Announcement of the Workshop IST-128 

Appendix B. The Final Program of the Workshop IST-128 

List of Symbols, Abbreviations, and Acronyms 

Distribution List 

Approved for public release; distribution unlimited. 

iii 

11 

12 
12 
12 
12 
13 

13 

15 

17 

27 

31 

32 

 
Acknowledgments 

We wish to acknowledge many people and organizations who made this workshop 
a success. The Istanbul Technical University provided facilities for the workshop. 
Mr.  Oğuzhan  Topgül  and  Mr.  Hüseyin  TİRLİ,  researchers  of  the  TÜBİTAK 
BİLGEM  Cyber  Security  Institute,  Turkey,  tirelessly  supported  the  workshop 
before  and  during  its  time  in  session.  Dr.  John  McLean,  the  Chairman  of  the 
Information  Systems  and  Technology  (IST)  panel,  encouraged  creation  of  this 
workshop and personally participated in the proceedings. Mrs. Aysegül Apaydin, 
IST  panel  assistant,  guided,  advised  and  managed  numerous  programmatic  and 
logistical  aspects  of  the  workshop.  Ms.  Ana  Santiesteban,  US  Army  Research 
Laboratory, helped to manage the flow and review of the papers submitted to the 
workshop. The members of the workshop’s technical committee (see Appendix B 
for the list of names) generously provided their time to formulate the workshop’s 
program and to review the papers.   

Approved for public release; distribution unlimited. 

iv 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1. 

Introduction 

This report describes the proceedings and outcomes of the North Atlantic Treaty 
Organization  (NATO)  workshop  IST-128  /  RWS-019,  titled  “Cyber  Attack 
Detection, Forensics and Attribution for Assessment of Mission Impact,” organized 
by the NATO Science and Technology Organizations’ (STO) Information Systems 
and  Technology  (IST)  panel.  The  workshop  was  held  at  the  Istanbul  Technical 
University, in  Istanbul, Turkey, on 15–17 June 2015. The workshop was NATO 
Unclassified and open to the NATO Partnership for Peace (PfP) nations, and to the 
NATO Mediterranean Dialogue (MD) nations.   

The  STO’s  mission  is  to  help  position  the  Nations’  and  NATO’s  science  and 
technology  (S&T)  investments  as  a  strategic  enabler  of  the  knowledge  and 
technology advantage for the defense and security posture of NATO Nations and 
partner Nations. This is accomplished by conducting and promoting S&T activities 
that  augment  and  leverage  the  capabilities  and  programs  of  the  Alliance,  of  the 
NATO  Nations,  and  the  partner  Nations,  in  support  of  NATO’s  objectives.  It  is 
further  accomplished  by  contributing to NATO’s ability to  enable and  influence 
security and defense-related capability development and threat mitigation in NATO 
Nations and partner Nations, in accordance with NATO policies; and by supporting 
decision making in the NATO Nations and NATO. 

The immediate sponsor of this workshop, IST is one of the 7 panels whose role it 
is  to  implement,  on  behalf  of  the  S&T  Board,  the  STO  mission  with  respect  to 
information systems technology. The advancement and exchange of techniques and 
technologies  to  provide  timely,  affordable,  dependable,  secure,  and  relevant 
information  to  warfighters,  planners,  and  strategists,  as  well  as  enabling 
technologies for modelling, simulation, and training are the focus of this panel. The 
IST  covers  the  fields  of  information  warfare  and  assurance,  information  and 
knowledge  management,  communications  and  networks  and  architecture  and 
enabling technologies. 

The  motivation  for  the  workshop  had  to  do  with  the  fact  that  the  success  of  a 
military  mission  is  highly  dependent  on  the  communications  and  information 
systems (CISs) that support the mission and their use in the cyber battlespace. The 
inexorably  growing  dependency  on  computational  information  processing  for 
weapons, intelligence, communication, and logistics systems continues to increase 
the  vulnerability  of  missions  to  various  cyber  threats.  Attacks  on  CISs  or  other 
cyber  incidents  degrade  or  disrupt  the  usage  of  CISs,  and  the  resulting  mission 
capability, performance, and completion. Such incidents are expected to increase 
in frequency and sophistication.  

Approved for public release; distribution unlimited. 

1 

 
Thus, in initiating this workshop, the IST panel felt that there is a need to address 
the technology and procedures to characterize the impact of cyber-attacks on the 
mission. Such an impact analysis must necessarily include a broad range of cyber 
analysis activities: detect attacks in a mission-supporting manner, assess damages 
relevant  to  the  mission,  investigate  impacts  on  mission  elements,  recover  from 
attacks in order to continue missions to the maximum extent possible, and decide 
on how  to  respond to cyberattacks in a manner  that  maximizes mission success. 
Additionally, the IST panel believed, forensics methods and tools are necessary to 
determine key facts relevant to assessing mission impact. Such tools are used for 
evidence  collection,  analysis  of  the  attack,  identification  of  the  attacker, 
understanding  the  attack,  damage  assessment,  and  attribution  of  attackers. 
Dependent on the mission and the type of an attack, there may be different degrees 
of relative importance and resources attached to attack detection, continuity of the 
military  mission,  damage  assessment,  evidence  collection,  attribution,  and  other 
activities. Usage of related methods, procedures, tools, or technology will depend 
on the requirements of the mission.  

This  workshop,  therefore,  was  to  focus  on  identifying  practice  and  research 
challenges, gaps, and approaches – current and future – to assessment of mission 
impact due to a cyberattack. Because it was thoughts that such  an  assessment is 
inseparable  from,  and  impossible  without,  attack  detection,  forensics,  and 
attribution, the workshop also intended to explore how these activities and related 
technologies and methods should support the assessment of mission impact. The 
initial announcement of the workshop is found in Appendix A. The final program 
of the workshop is found in Appendix B.  

The workshop gathered a total of 56 participants from 9 countries. The participants 
included authors and presenters of 12 technical papers and briefs. The workshop 
attracted  2  types  of  papers:  full  papers  and  position  papers.  A  full  paper  is  a 
technical paper (between 2500–5000 words) that presents results of novel research 
and is subject to evaluation criteria of a typical technical conference. A position 
paper  is  short  (between  500–1500  words)  and  reflects  the  views  of  the  author  – 
usually  a  discussion  of  research  challenges,  gaps,  and  approaches  –  without 
necessarily  presenting  a  supporting  research.  The  papers  are  found  in  an 
accompanying volume:  Proceedings of  the NATO IST-128  Workshop: Assessing 
Mission Impact of Cyberattacks.1 

The  introductory  session  of  the  workshop  comprised  3  talks  that  welcomed  the 
participants and offered an overview of the organizations and topics involved. It 
was followed by 4 technical sessions that totaled 12 technical talks.  

Approved for public release; distribution unlimited. 

2 

 
The  first  technical  session  focused  on  the  need  to  gain  insights  into  the  intent, 
motivations, and capabilities of the attackers, in order to understand the intended 
and actual mission impact. The second technical session explored whether, and to 
what  extent,  it  is  possible  to  understand  the  mission  impact  by  analyzing  the 
observable cyber signal and events, through such means as are normally associated 
with cyber intrusion detection, forensics, and malware analysis. The third technical 
session  discussed  the  need  for  models  of  missions  and  systems  that  support 
missions  and  the  approaches  to  constructing  such  models.  The  fourth  technical 
session  investigated  the  means  by  which  mission  impact  could  be  simulated  or 
modeled.  

The  last  day  of  the  workshop  was  limited  to  1  half-day  session.  In  a  structured 
brainstorming process, that session integrated and analyzed the overall results and 
findings of the workshop. The participants divided into 3 brainstorming teams. The 
first team aimed to summarize the state of the art in mission impact assessment, 
including the key gaps. The second team was asked to envision the future state of 
the  mission  impact  assessment  10–20  years  from  now.  The  third  analyzed  the 
discussions of the 4 previous sessions in order to distill the key research directions 
that the community should pursue. The 3 teams then presented and discussed their 
findings in a plenary session. Finally, the workshop formulated key ideas for the 
follow-on activity for consideration by the NATO IST panel. 

A  few  disclaimers  are  in  order  here.  First,  not  every  author  of  the  report  or 
participant  of  the  workshop  agrees  with  every  (or  any)  opinion  presented  in  the 
workshop’s report. Second, all statements of fact or opinion presented in this report 
are those of the workshop participants and do not reflect positions or views of their 
employers or any organizations with which they are affiliated.    

2.  Findings of the Workshop 

2.1  The Key Finding: The Primacy of a Model -driven Paradigm 

The original expectations of the workshop’s organizers, although not particularly 
explicit, were reflected in the title of the workshop: it was assumed that the key to 
addressing the challenges of mission impact assessment had to do with a form of 
integration  of  intrusion  detection,  analysis,  forensics,  attribution,  and  related 
traditional  disciplines  of  cyber  defense.  The  answer  that  emerged  from  the 
workshop, however, was decidedly different. 

The workshop witnessed the emergence of a very strong and clear consensus. The 
key to solving the mission impact assessment problem, the workshop’s participants 

Approved for public release; distribution unlimited. 

3 

 
argued, was in adopting and developing a new model-driven paradigm. It requires 
creation and validation of mechanisms of modeling the organization whose mission 
is subject to assessment, the mission (or missions) itself, and the cyber-vulnerable 
systems that support the mission. The models are then used to simulate or otherwise 
portray the impacts of the cyber-attacks.  

In addition, such model-based analysis could be used to explore multiple alternative 
mitigation and work-around strategies – an essential part of coping with mission 
impact – and select the optimal course of mitigating actions. Only such a paradigm 
can be expected to provide meaningful, actionable information about the mission 
impacts  that  have  not  been  seen  before  or  do  not  match  prior  experiences  and 
patterns. 

To  be  sure,  the  model-driven  paradigm  of  mission  impact  assessment  does  not 
imply that traditional disciplines of cyber defense, such as vulnerability analysis, 
intrusion  prevention,  intrusion  detection,  analysis,  forensics,  attribution,  and 
recovery,  are  irrelevant  to  the  topic  of  impact  assessment.  Rather,  these  tasks 
themselves can benefit from – and be integrated into the overall framework of – the 
model-driven paradigm. For example, intrusion detection, especially for zero-day 
or  polymorphic  attacks,  would  greatly  benefit  from  the  ability  to  model  the 
observable effects of a hypothetic attack.  

Based on these findings, the workshop proposed an exploratory team activity that 
focuses on a study of potential approaches and likely barriers to applying model-
driven  paradigm  to  a  broad  range  of  cyber  defense  activities,  including  but  not 
limited to mission impact assessment. 

2.2  Mission Impact Assessment Problem Formulation 

Appropriate formulation of a problem is the key  to its successful solution. What 
constitutes a successful mission impact assessment (MIA) solution depends, in turn, 
on who are the users of the solution. Therefore, the workshop’s participants argued 
for more involvement of the “stakeholders” – primarily end users – in formulating 
the  MIA  problem.  For  example,  commanders  need  decision  support  at 
“commander” level – they are much less interested in technical details. For these 
reasons, future techniques of MIA may specifically focus – and the very problem 
of MIA may be so formulated – on supporting the cyber security decision-making 
process, and particularly on tools that teach and train decision makers, and support 
them. 

Determining the correct users, however, depends on knowing where MIA belongs 
in  the  broader  scheme  of  things.  One  way  to  position  MIA  in  the  context  of  a 

Approved for public release; distribution unlimited. 

4 

 
broader cyber defense concept is to consider MIA as a part of the big control loop 
that  strives  to  keep  the  controlled  “plant”  –  the  mission  –  within  the  prescribed 
space of secure states. The output of this controller is a set of corrective actions, or 
a course of actions, designed to keep the plant in the secure state. Parenthetically, 
among the actions that could be taken to correct or prevent the mission impact one 
is particularly salient – deterrence. MIA can help formulate the nature and extent 
of the appropriate deterrence action.  

In this formulation, then, MIA is the component of the control system that measures 
how much the plant has deviated or will deviate from the desired state. Once we 
say “how much,” we must consider what exactly we quantify when we measure the 
deviation  from  security  to  lesser  security.  To  put  it  differently,  a  formal 
quantification of  a utility  function is needed.  Some of the  current approaches to 
MIA  are  based  on  heuristic  scoring.  To  oversimplify,  the  assessor  sums  up  the 
“impact points” and declares that the total impact on the mission is, let’s say, 73 
points.  Clearly,  this  leaves  much  to  be  desired  in  terms  of  theoretical  rigor. 
Similarly,  to  say  that  “The  mission  impact  is  70%  failure”  is  very  difficult  to 
interpret. For example, even with a 70% mission failure (whatever that means), the 
operator may still be able to reach a key goal. 

Perhaps  a  more  principled  approach  to  measures  would  be  to  use  traditional 
characteristics  of  security  –  confidentiality,  integrity,  and  availability  (CIA). 
Unfortunately, aspects of CIA for missions are not well defined or understood – in 
is  poorly  understood. 
integrity  and  confidentiality 
particular,  measuring 
Furthermore, one can argue that in cyber-physical systems CIA is not particularly 
meaningful,  and  a  better  triad  is  observability,  controllability,  and  operability 
(OCO). 

Other  ways  to express quantitative  output  of MIA  would be  to  measure mission 
impact  as  a  reduction  in  tangible  attributes  of  the  system,  such  as  the  network 
bandwidth,  delay,  or  power  use.  Yet  another  approach  would  be  to  quantify  the 
distance from the achievable states to desired states, for example, via the cost of the 
corrective actions that would bring the plant to the desired, secure state. All this 
suggests that a formal language, a formal mathematics of mission security, would 
be highly desirable to give MIA a solid quantitative foundation.  

Appropriate  formulation  of  the  MIA  problem  also  requires  a  choice  of  the  right 
level  of  abstraction.  When  formulated  and  solved  at  a  very  abstract  level,  the 
solution may not give adequate insights into what actions – often very specific and 
detailed  – need to be considered.  On the other  hand,  when formulated at a  very 
detailed level, the problem demands a very intricate model that is far too expensive 
to construct. Some workshop participants argued that a shift must occur from the 

Approved for public release; distribution unlimited. 

5 

 
enterprise-scale  problem  –  common  in  today’s  practice  –  to  more  meaningful 
tactical scale. One argument for more detailed formulations is that that seemingly 
small attacks on mission activities can have large effects, as confirmed by  some 
simulation studies. 

Although so far we discussed mainly the control-theoretic style of the MIA problem 
formulation,  we  should  not  overlook  the  game-theoretic  (or  game-playing 
simulation) perspective. This would be natural, considering that the cybersecurity 
problem is highly adversarial in nature. Because it involves intelligent, strategically 
thinking  adversaries,  as  opposed  to  random  deviations  in  the  plant  operation,  a 
game perspective seems more appropriate than a control perspective. A related and 
appropriate style of problem formulation could be a robust control with adversarial 
inputs. One  could also consider a  contest-game theory framework for modelling 
economic  impacts  of  cyberattacks.  Because  full  information  is  not  normally 
available, the problem should be formulated as a partial information game; artificial 
intelligence techniques might help here.  

Yet another style of problem formulation that might be applicable to MIA is the 
risk analysis problem. In fact, risk analysis and MIA are closely related. Arguably, 
instead of saying, “Impact to Mission M from attack A is X,” one could say nearly 
equivalently,  “Risk  to  Mission  M  from  attack  A  is  Y.”  Furthermore,  risk  is 
successfully used in ecological impact studies, and an ecological (and biological) 
analogy may be instructive for complex cyber systems. The risk flow concept used 
in analysis of ecological systems appears to be a promising cybersecurity approach 
that may contribute to a temporal and spatial assessment of risk propagation and 
influence.  In  addition,  many  risk  analysis  techniques  do  not  take  into  account  a 
strategically thinking adversary, as game formulations do.  

While arguing for a model-driven paradigms for MIA, with either a control, game, 
or  risk  perspective,  we  must  not  dismiss  entirely  different  yet  complementary 
approaches.  For  example,  analysis  of  malware  found  on  friendly  systems  or 
otherwise captured in the wild can be an important help in MIA. Malware analysis 
and reverse  engineering  may  reveal the adversary’s intent  regarding the  mission 
impact that the malware was designed to inflict. 

If  all  the  above  sounds  very  complex,  that  is  because  it  is.  Despairing  of  this 
complexity, one might be tempted to ask if a much simpler formulation might be 
adopted.  For  example,  a  pattern-matching  approach  like,  “if  you  see  pattern  of 
evidence E, conclude that impact is X.” However, the workshop’s participants did 
not feel that the MIA problem lends itself to much simplification. Instead, model-
driven approaches were deemed most promising, which brings us to the question 
of what should be included in a good model. 

Approved for public release; distribution unlimited. 

6 

 
2.3  Model Content  

The workshop exhibited a rather strong agreement on the fundamental components 
of a model required for MIA. These were generally understood to be the models of 
the organization (or military unit), its business processes (often decomposed into 
functions and tasks), the missions executed through the business processes, and the 
influences,  and 
technical  systems 
dependencies – quantitatively characterized – between all these entities and their 
sub-entities need to be modeled. Even the physical environment of a mission may 
need to be modeled, as well as the sensors and actuators that sense and affect the 
environment, because they also can be subjects of cyber or deception attacks. 

the  missions.  Relations, 

that  support 

Because the MIA problem is so fundamentally adversarial in nature, it was widely 
recognized that one needs a comprehensive model for adversary characterization, 
and  behavior  understanding  and  prediction.  Models  should  also  include  an 
environment property, attacks property, and target property, including modeling of 
these 3 elements and relations and interactions between them. We discuss adversary 
modeling in more detail in the next section.  

In  addition  to  describing  the  structure  of  the  problem,  models  must  capture  its 
dynamics. There are several very different meanings of dynamics in MIA models. 
First,  the  structure  itself  changes  rapidly.  For  example,  the  servers  supporting  a 
mission might be taken down for maintenance and then brought up on line again or 
reassigned to another mission. The model would need to be updated continually to 
reflect such changes. Second, when a cyber-attack impacts a mission, the defenders 
and operators of the mission and supporting systems often show remarkable ability 
to  work  around  an  established  process,  for  example,  to  redesign  the  business 
process rapidly and radically. Third, even in a very static structure of the business, 
actions are dynamic – they start, proceed, and stop at points in time. This dynamic 
has  to  be  captured  in  a  model.  Fourth,  the  characteristics  of  components  and 
relations within the model may change depending on the context. For example, the 
criticality  of  systems  change  during  different  missions,  various  simultaneous 
missions can each place a different criticality on the same shared systems, and the 
organization  will  have  a  time-dependent  and  dynamically  changing  aggregate 
dependency on its systems and other assets. 

Dynamics associated with the adversary’s behavior are particularly complex, and 
we consider them next. 

Approved for public release; distribution unlimited. 

7 

 
 
 
2.4  Models of Adversary 

Mission impact has to be considered in the context of what impact the adversary 
desires.  If  we  know,  or  are  able  to  estimate,  the  intents,  motivations,  and 
anticipations of the adversary, the impact of the adversary on our missions, or the 
intended impact, would be easier to assess. It should be noted that in this section 
we consider the adversary rather abstractly; in particular, we do not assume that the 
adversary  can  be  modeled  as  an  individual  human  or  a  collection  of  individual 
humans. That perspective is explored in a later section.   

A model for adversary characterization and behavior understanding and prediction 
should  be  sufficiently  comprehensive.  In  particular,  the  model  should  include 
properties of the environment in which the cyber conflict occurs; the properties of 
the  attacks  and  targets  that  area  available  to  the  adversary;  and  relations  and 
interactions between all such elements, all this in addition to the properties of the 
adversary itself.  

Naturally, properties and characteristics of the adversary are often unknown, or can 
be assumed only with a significant degree of uncertainty. Modeling tools should 
allow representation of such uncertainties and even unknowns.  

Modeling of the cyber adversary can be helped by analysis of its testing of cyber 
weapons, of which a number of examples are known. Testing of weapons is critical 
to the adversary and is detectable by us. Tests tell us much about the adversary and 
about potential mission impacts. Therefore, we need a program, framework, and 
sensors to be developed for collection and analysis of such tests. 

We  can  also  learn  from  modeling  experiences  in  earlier  decades  and  against 
different types of weapons. In particular, work done on understanding the adversary 
behaviors for purposes of nuclear exchanges has been seen as fairly successful (for 
example, no nuclear exchange has happened to this date) and is potentially a useful 
analogy for cyber conflicts. On the other hand, how sure are we that we really know 
interests, intentions, and strategies of nuclear adversaries? The Cuban crisis seems 
a counter-example. Is it not a misleading analogy? For example, a cyber conflict is 
much less constrained in its effects than a nuclear conflict.  

A powerful determinant of adversary behavior is the adversary’s expectations of 
our  response.  Thus,  it  is  important  to  understand  the  role  of  deterrence  –  the 
measures  we  can  take  to  prevent  hostile  actions  by  an  adversary  –  in  a  cyber 
conflict.  An  adversary  model  should  help  answer  questions  like,  what  does  the 
adversary wants to do and what do they expect us to do? 

Approved for public release; distribution unlimited. 

8 

 
Currently,  little  is  either  understood  or  practiced  with  respect  to  deterrence. 
Arguably, with a consistent and well-understood practice of deterrence, impacts of 
cyber  actions  by  an  adversary  may  be  more  predictable.  Unlike  in  the  case  of 
nuclear deterrence, cyber deterrence might be possible without a threat of human 
victims; the effects could be strictly limited to impacts on industrial and financial 
infrastructure, for example. 

Yet another difference between cyber and nuclear cases is that the theory of nuclear 
conflict relies on a geopolitical approach. Cyber operations, in the other hand, are 
largely geography-independent, difficult to attribute to a specific state, and often 
perpetrated by non-state actors, or state-sponsored but otherwise non-state actors. 
Economic rather than geopolitical perspectives might work better in the case of a 
cyber conflict. 

Analogies  other  than  nuclear  conflict  might  be  better  for  cyber  conflicts.  The 
workshop  participants  discussed  the  possible  terrorism  and  counter-terrorism 
analogies.  Whether  we  can  claim  much  success  in  understanding  and  modeling 
terrorist adversaries is an open question. 

2.5  Models of Humans 

When the adversary is an individual human, or a group of individuals that we find 
appropriate  to  model  individually,  we  should  consider  techniques  of  cognitive 
modeling  of  individual  human  minds.  Such  models  can  help  predict  how 
adversaries  (cyber-attackers)  formulate  their  goals  and  thereby  tell  us  about  the 
intended or actual mission impact of the adversary’s actions. Tools like Adaptive 
Control  of  Thought—Rational  (ACT-R)  are  popular  for  cognitive  modeling  and 
might be applicable to modeling behaviors of cyber-attackers. Cognitive modeling 
of individuals is proven to be possible, and validated tools for such modeling do 
exist. Still, this area tends to be a rather early research field.  

Although we have focused on modeling the adversary, models of defenders should 
not be overlooked. To assess the likely mission impact, we need to know how a 
human  cyber  defender  reacts  to  cyber-attacks.  Errors  committed  by  defenders 
determine the extent of mission impact. A defender may fail to recognize a threat 
and  to  take  appropriate  actions,  thereby  enabling  a  greater  mission  impact.  A 
defender may fall a victim to deception committed by an attacker. A defender may 
fail to undertake a suitable work-around when a mission is impacted. A defender 
may also misinterpret mission impacts when they occur. All this is highly relevant 
to the MIA problem. 

Approved for public release; distribution unlimited. 

9 

 
Whether one models an attacker or a defender, the model needs to be rich enough 
to reflect “irrational” aspects of human cognition, such as cognitive biases. These 
are particularly important in the high-pressure, high-tempo, non-intuitive world of 
cyber operations. Impact of dynamic learning must be considered to account for 
rapid evolution of knowledge in cyber conflicts. Game-theoretic approaches should 
be included in order to account for the highly adversarial nature of cyber operations. 
Because  both  the  attacker  and  the  defender  operate  often  with  very  limited 
awareness of each other’s actions, situational awareness of both should be modeled. 
One  of  the  workshop’s  presentations  pointed  out  the  importance  of  situational 
awareness in achieving impact on the opponent’s mission. 

In many cases, however, both the defender and the attacker are best modeled not as 
individual  human  cognitive  actors,  but  rather  as  organizations.  Organizational 
modeling is studied by a community of researchers in the political science field that 
is distinct from the community of cognitive modelers. It would be worth exploring 
how that community might help solving the MIA problem. 

2.6  Model Construction 

The current practice of constructing models for MIA is almost entirely manual in 
nature.  As  such,  model  construction  is  very  time  consuming,  expensive,  and 
difficult  to  document,  inspect,  and  validate.  Maintenance  of  such  models  –  also 
manual – is also expensive. Quantitative characterization of dependencies between, 
for example, business functions and supporting technical assets, is largely a matter 
of  asking  the  presumed  subject  matter  experts  (SMEs)  for  a  number,  such  as  a 
conditional probability. The guessing of such numbers of SMEs is expensive and 
the verity of numbers is doubtful.  

Still,  manual  construction  of  models  for  MIA  problems  is  feasible,  even  if 
expensive. For example, Analyzing Mission Impacts of Cyber Actions (AMICA) 
(reported in one of the workshop’s papers) is a comprehensive MIA modeling and 
simulation  tool  with  a  fully  implemented  military  “business”  model.  It  relies  on 
manually crafted models. 

Some tools exist that allow essentially manual yet computer-aided construction of 
business models. The widely available Business Process Management (BPM) tools 
fall  into  this  category.  This  may  be  important  because,  in  general,  systems  (and 
networks/infrastructure)  are  better  understood  than  missions  (business),  and  the 
availability of BPM tools can help close this gap. 

Ideally,  however,  we  would  like  to  see  the  bulk  of  MIA  models  constructed 
automatically,  perhaps  by  observing  a  business  process  and  its  cyber  defense 

Approved for public release; distribution unlimited. 

10 

 
operations, and automatically learning or inferring a model. One of the workshop’s 
presentations  described  an  approach  where  significant  part  of  a  model  was 
automatically derived from the observed network flows.  

Modeling of missions can be assisted by decomposing missions hierarchically into 
sub-missions,  e.g.,  strategic  into  tactical.  Although  this  aids  in  simplifying  and 
better  understanding  of  mission,  it  adds  the  problem  of  modeling  complex 
interactions between elements of the decomposed structure. As in any model, it is 
important  to  balance  granularity  and  determine  the  minimum  necessary  level  of 
fidelity. 

2.7  Data Requirements 

Modelling and simulation techniques depend upon availability of large empirical 
datasets,  and  MIA  problems  are  no  exception.  All  aspects  of  models  we  have 
discussed depend on availability of data that can be used to create model elements. 
Data  are  needed  to  create,  validate,  and  maintain  such  models.  Therefore,  it  is 
necessary to establish a rigorous, comprehensive program of automated collection 
and, in some cases, manual maintenance of the data. 

Examples of the required data include the topology of the information technology 
(IT) and communication systems under consideration; the cyber vulnerabilities of 
the software and hardware involved; the business processes of the organization; the 
complex  interdependencies  between  missions,  services,  and  infrastructure;  and 
behaviors of cyber actors.  

3.  Conclusion 

3.1  Selected Observations on the Current State of R&D in MIA 

(Outcome of Brainstorming Sessions) 

•  A degree of maturity has been achieved in models of dependencies between 

cyber assets and physical assets. 

•  Linking attack graphs and missions has been demonstrated. 

•  Examples exist of models that use game theory and control theory for the 

purposes of MIA. 

•  Attempts have been made to model the cyber adversary. 

•  Comprehensive  examples  exist  where  certain  business  processes  were 

modeled with sufficient fidelity to be used for MIA. 

Approved for public release; distribution unlimited. 

11 

 
•  There is understanding and some examples of how to quantify vulnerability, 

risk and resiliency in order to assess mission impact. 

•  Relevant models for risk assessment do exist. 

•  Generally,  human  inputs  are  manually  collected  to  populate  models  with 

parameters. 

3.2  Selected Suggestions for the Future of R&D in MIA 

(Outcome of Brainstorming Sessions) 

3.2.1  Operations 

•  Methods  and  techniques  to  reduce  the  time  to  detect  the  cyberattacks  or 

compromises so that mission impact can be minimized.  

•  Novel architectures that minimize the mission impact by design 

•  Defense  tactics,  techniques,  and  procedures  (TTPs)  can  be  explicitly 

optimized to control the extent of mission impact. 

• 

Intuitive situational awareness to support commander decision making and 
automated execution of actions 

3.2.2  Formalisms 

•  Formal languages for MIA that capture mission, attacker, defense, security 

architecture, etc. 

•  Formal  models  for  situation  awareness,  such  as  hierarchical  concurrent 

probabilistic finite state machine (FSM) 

•  Formal language for decision making integrated with formal cyber language 

3.2.3  Automation 

•  Automated infrastructure model creation 

•  Extract model parameters automatically from logs 

•  Automated population of situational awareness models 

•  Automated support to model validation, and to training and exercises  

•  Appropriate mix of automated and human response to mission impact 

Approved for public release; distribution unlimited. 

12 

 
 
 
3.2.4  Data  

•  Collect ground-truth data on attacker and defender behaviors 

•  Remote cyber sensing for collecting attacker data 

•  Open source, vendors and users are valuable providers of data 

•  Better characterization and use of synthetic data and sanitized real data 

3.3  Recommendations for a Follow-on Activity 

A suitable follow-on to this workshop would be an exploratory team (ET) activity 
that focuses  on  a  study  of  potential  approaches  and likely  barriers to  applying  a 
model-driven paradigm to a broad range of cyber defense activities, including but 
not limited to, mission impact assessment. 

The ET could be titled, tentatively, “The Model-Driven Paradigms for Integrated 
Approaches to Cyber Security.” The ET would explore the possibility of using a 
multi-purpose,  integrated  system  of  models  for  guiding  a  broad  range  of 
cybersecurity  operations:  vulnerability  analysis,  intrusion  prevention,  intrusion 
detection, analysis, forensics, attribution, mission impact assessment, and recovery. 
The  team  will  investigate  whether  such  a  paradigm  can  be  expected  to  provide 
meaningful, actionable information about cyber activities and the resulting impacts 
that have not been seen before or do not match prior experiences and patterns. 

The  workshop  already  identified  a  number  of  research  and  development  (R&D) 
challenges associated with model-driven approaches to MIA. Therefore, it will be 
the ET’s charter to answer a number of questions, such as the following: 

•  How likely these challenges be overcome in the near- and mid-term? 

•  Are there applications of the model-driven paradigm that are more likely to 

prove fruitful in near-term for the MIA problem? 

•  What can be learned and adopted from the Canadian Automated Computer 
Network  Defence  (ARMOUR)  demonstrator  and  European  Union 
PANOPTESEC prototype, which explore a related model-based approach? 

•  What are ways to populate and validate models in an affordable fashion? 

• 

Is  the  model-driven  paradigm  defeated  by  ever-growing  diversity  and 
diffusion of IT infrastructures, such as Internet of Things (IoT)? 

•  What  commercial  tools  are  emerging  that  can  support  the  model-driven 

paradigm? 

Approved for public release; distribution unlimited. 

13 

 
•  Can  any  standards  can  be  leveraged  to  enable  model-driven  R&D  to  be 
conducted  in  an  interoperable  manner?  If  not,  should  candidates  for 
standards be defined within an STO activity? 

Approved for public release; distribution unlimited. 

14 

 
 
 
4.  References 

1.  Kott A, Stoyanov N, Baykal N,  Moller A, Sawilla R, Jain P, Lange M, Vidu 
C. Proceedings of the NATO IST-128 Workshop Assessing Mission Impact of 
Cyberattacks.  Dec  2015.  Adelphi,  MD:  Army  Research  Laboratory  (US). 
Report No.: ARL-RP-0562. 

Approved for public release; distribution unlimited. 

15 

 
 
 
 
INTENTIONALLY LEFT BLANK. 

Approved for public release; distribution unlimited. 

16 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Appendix A. The Announcement of the Workshop IST-128 

Approved for public release; distribution unlimited. 

17 

 
 
 
 
 
 
 
 
 
 
 
 
Approved for public release; distribution unlimited. 

18 

 
Approved for public release; distribution unlimited. 

19 

 
Approved for public release; distribution unlimited. 

20 

 
Approved for public release; distribution unlimited. 

21 

 
Approved for public release; distribution unlimited. 

22 

 
Approved for public release; distribution unlimited. 

23 

 
Approved for public release; distribution unlimited. 

24 

 
Approved for public release; distribution unlimited. 

25 

 
Approved for public release; distribution unlimited. 

26 

 
 
 
 
 
 
 
 
Appendix B. The Final Program of the Workshop IST-128 

Approved for public release; distribution unlimited. 

27 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
A
p
p
r
o
v
e
d
f
o
r
p
u
b

l
i
c

l

r
e
e
a
s
e
;
d
i
s
t
r
i
b
u
t
i
o
n
u
n

l
i

m

i
t
e
d

.

2
8

 
 
 
 
 
 
 
 
 
 
A
p
p
r
o
v
e
d
f
o
r
p
u
b

l
i
c

l

r
e
e
a
s
e
;
d
i
s
t
r
i
b
u
t
i
o
n
u
n

l
i

m

i
t
e
d

.

2
9

 
 
 
 
 
 
 
 
 
 
A
p
p
r
o
v
e
d
f
o
r
p
u
b

l
i
c

l

r
e
e
a
s
e
;
d
i
s
t
r
i
b
u
t
i
o
n
u
n

l
i

m

i
t
e
d

.

3
0

 
 
 
 
 
 
 
 
 
 
List of Symbols, Abbreviations, and Acronyms 

ACT-R 

AMICA 

Adaptive Control of Thought—Rational 

Analyzing Mission Impacts of Cyber Actions  

ARMOUR 

Automated Computer Network Defence   

BPM 

CIA 

CISs 

ET 

FSM 

IoT 

IST 

IT 

MD 

MIA 

NATO 

OCO 

PtP 

R&D 

S&T 

SME 

STO 

TTPs 

Business Process Management  

confidentiality, integrity, and availability  

communications and information systems 

exploratory team  

finite state machine  

Internet of Things  

Information Systems and Technology  

information technology  

Mediterranean Dialogue  

mission impact assessment  

North Atlantic Treaty Organization  

observability, controllability, and operability  

Partnership for Peace  

research and development  

science and technology  

subject matter expert 

Science and Technology Organization  

tactics, techniques, and procedures  

Approved for public release; distribution unlimited. 

31 

 
 
 
 
 
