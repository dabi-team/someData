1
2
0
2

v
o
N
2
2

]

R
C
.
s
c
[

1
v
0
0
0
1
1
.
1
1
1
2
:
v
i
X
r
a

1

PRISM: A Hierarchical Intrusion Detection
Architecture for Large-Scale Cyber Networks

Yahya Javed, Mosab A. Khayat, Ali A. Elghariani, and Arif Ghafoor

Abstract—The increase in scale of cyber networks and the rise in sophistication of cyber-attacks have introduced several challenges
in intrusion detection. The primary challenge is the requirement to detect complex multi-stage attacks in realtime by processing the
immense amount of trafﬁc produced by present-day networks. In this paper we present PRISM, a hierarchical intrusion detection
architecture that uses a novel attacker behavior model-based sampling technique to minimize the realtime trafﬁc processing overhead.
PRISM has a unique multi-layered architecture that monitors network trafﬁc distributedly to provide efﬁciency in processing and
modularity in design. PRISM employs a Hidden Markov Model-based prediction mechanism to identify multi-stage attacks and
ascertain the attack progression for a proactive response. Furthermore, PRISM introduces a stream management procedure that
rectiﬁes the issue of alert reordering when collected from distributed alert reporting systems. To evaluate the performance of PRISM,
multiple metrics has been proposed, and various experiments have been conducted on a multi-stage attack dataset. The results exhibit
up to 7.5x improvement in processing overhead as compared to a standard centralized IDS without the loss of prediction accuracy
while demonstrating the ability to predict different attack stages promptly.

Index Terms—network security, intrusion detection, threat forecasting, network trafﬁc sampling, machine learning, stream processing.
(cid:70)

1 INTRODUCTION

T HE past couple of years have witnessed a concerning

proliferation of cyber-attack incidents with the targets
ranging from critical government infrastructures to common
internet users. State-sponsored Advanced Persistent Threats
(APTs) have revealed the limitations of current Intrusion
Detection Systems (IDSs) with median dwell time of 30
days and internal detection rate on a continuous decline
for the past couple of years [1]. Today, IDSs face three
major challenges; an ever increasing attack complexity, as-
tronomical increase in data traversing through the networks,
and the need to detect attacks in realtime with in-depth
information. To account for the growing attack complexity,
modern IDSs evolved from simple string matching systems
to sophisticated machine learning-based frameworks, mak-
ing intrusion detection a computation intensive process [2].
To cater for the processing of massive data, there is no sub-
stantial change in the IDS computational process other than
the introduction of more powerful processing hardware.
However, according to Gilder’s law the bandwidth grows
at least three times faster than the compute power. While,
compute power doubles every eighteen months (Moore’s
law), bandwidth doubles every six months [3]. This widen-
ing gap between the computational capacity and network
bandwidth has made it immensely challenging for IDSs
to process every packet in realtime and identify threats in
a cost effective manner. Consequently, as the limited IDS

• Yahya Javed and Arif Ghafoor are with the Elmore Family School of
Electrical and Computer Engineering, Purdue University, West Lafayette,
IN, USA.
E-mail: yjaved@purdue.edu, ghafoor@ecn.purdue.edu

• Mosab A. Khayat is with the Department of Computer Engineering, Umm

Al-Qura University, Makkah, KSA.
Email: maakhayat@uqu.edu.sa

• Ali A. Elghariani is with XCOM-Labs, San Diego, CA, USA.

Email: ali.elghariani@gmail.com

resources are deployed at only few parts of the network, the
chances of attackers penetrating the network without detec-
tion increase. At the same time, it is expected of the IDSs
to identify threats with actionable information that can lead
to a proactive response, contrary to binary classiﬁcation like
alerts that have little use for response operations [4]. These
challenges necessitate an overhaul in the IDS architecture
and the intrusion detection process.

Commercial and opensource IDSs for enterprise net-
works are generally deployed in a centralized orchestration.
Some of these IDSs use multiple parallel processing nodes
to handle large quantity of data [5]. The network trafﬁc
is captured by taping the link connecting the enterprise
network to the internet which is then processed by the IDS
detection module to ﬁnd malicious packets [6], [7]. This
design choice has several disadvantages including high cost
of hardware that can process data in Gbps of data rates,
limitations in scalability as the network grows over time,
and inability to monitor internal network trafﬁc that ignores
attack sources other than the internet. In literature, there is a
signiﬁcant amount of work that proposes a distributed IDS
design. While the proposed distributed IDS architectures
address the problems associated with a centralized archi-
tecture, they introduce new issues in addition to ignoring
some of the aforementioned challenges experienced by the
IDSs. As discussed in the related work section of the paper,
some of the proposed distributed IDS architectures only
focus on enhancing the trafﬁc processing capabilities, but
at the same time have the inability to detect complex multi-
stage attacks, and do not possess intrusion prediction fea-
ture that can provide the response mechanism with enough
information for a proactive response. On the other hand, the
proposed IDSs with intrusion prediction capabilities present
a conceptual distributed architecture that does not address
the practical challenges associated with a distributed design.

 
 
 
 
 
 
Among those challenges is the alert reordering issue that
occurs when alerts are collected from distributed sources
with different network latencies. This can cause prediction
error in time series data-based prediction models that are
generally employed to detect multi-stage attacks. Addition-
ally, the proposed IDSs with intrusion prediction capabil-
ities lack in proper implementation and evaluation in a
distributed alert generation setup. This entails the need to
develop an intrusion detection architecture that can process
network trafﬁc in parallel, predict the attack progression
and detect complex multi-stage attacks, while addressing
the challenges introduced by the distributed design.
Present-day IDSs process every packet

traversing
through their assigned region of observation in the network.
For each packet or ﬂow, a decision is made if they are
malicious or benign. Most of the trafﬁc in the network is
benign, and even during an attack, the malicious trafﬁc is a
fraction of the total network trafﬁc. Moreover, once an attack
is detected, most of the malicious packets that follow are of
the same continuing attack. These observations exhibit that
there is room for optimizations in the way IDSs monitor
trafﬁc and detect threats. Network trafﬁc sampling is a
plausible approach to make intrusion detection much more
efﬁcient by directing only sampled trafﬁc to the IDS. How-
ever, existing network sampling techniques are designed for
network trafﬁc engineering purposes and perform poorly
for intrusion detection applications [8]. This necessitates the
development of a network intrusion detection centric sam-
pling scheme with the objectives of providing acceptable
IDS accuracy, retention of IDS’s ability to identify every
attack and maximize attack detection speed by reducing the
amount of trafﬁc to be processed by the IDS.

In this paper we introduce PRISM: Performance-oriented
Realtime Intrusion-detection and Security Monitoring. The
fundamental design goals of PRISM are to detect complex
multi-stage attacks in high bandwidth cyber networks with
minimum processing overhead, provide intrusion predic-
tion and holistic security assessment of the entire network in
realtime, and should be scalable by comprising of a modular
architectural construct. The distinct contributions of PRISM
are as follows:

1)

Intrusion detection, prediction and security analysis:
PRISM incorporates a multi-layered structure that utilizes
the services of its several internal systems to detect in-
trusions, predict attack progression and present a holistic
security outlook of the system. The network trafﬁc is mon-
itored in a distributed fashion by dividing the network
into different surveillance zones. Each surveillance zone is
supervised by an IDS that reports only its local alerts. The
alerts are correlated in a Hidden Markov Model (HMM)-
based prediction system that ﬁrst determines the type of
multi-stage attack and then predicts its current stage. The
prediction output and alerts from surveillance zones are
then processed to compute and visualize several metrics for
intrusion response facilitation.

2) Threat-aware sampling: PRISM uses a probabilistic sam-
pling scheme to process more trafﬁc from devices that have
more likelihood of being attacked. The sampling scheme
utilizes a novel attacker behavior model-based ranking
mechanism that ranks devices in the network according
to their vulnerability and inter-device reachability informa-

2

tion. Packets are sampled according to a sampling prob-
ability which is calculated using the rank-based score of
the packet’s source and destination device. Instead of pro-
cessing every captured packet, only sampled packets are
forwarded to the detection module of the IDS. Using the at-
tacker behavior model-based sampling, PRISM strategically
focuses on the trafﬁc from those devices that are critical,
and are more prone to be attacked, reducing processing
overhead and the required computing resources.

3) Alert stream management: PRISM manages the alert
streams from multiple surveillance zones by implementing
an efﬁcient alert stream management mechanism. The re-
ceived alerts are sent to different systems of PRISM and are
subjected to distinct treatments based on the requirement of
their destination systems. For attack prediction, the alerts
are reordered according to their IDS generated timestamps
before being sent using a window-based stream processing
implementation. For security analysis, the alerts are for-
warded as soon as they are received without any processing
to enable prompt security situation update.

4) Experimentation and performance evaluation: The per-
formance of PRISM is evaluated through extensive exper-
imentation on ISCX-2012 dataset [9]. The dataset consists of
real trafﬁc capture of several complex multi-stage attacks
launched on a widespread target network for seven days.
Experiments are designed to test the performance of all
internal systems of PRISM in terms of multiple performance
metrics. Results show that PRISM can maintain good pre-
diction accuracy while reducing the processing overhead
signiﬁcantly in addition to being able predict attack progress
notably early when studied under several experimental
conditions. The security analysis capability of PRISM pro-
vides valuable utility by computing and visualizing cyber
situational awareness-centric metrics.

The rest of this paper is structured as follows. Section
2 presents the relevant background. Section 3 explains the
working of PRISM and its constituent systems. The exper-
imental setup is described in Section 4. The performance
evaluation of PRISM is provided in section 5. The related
work is outlined in Section 6. Finally, Section 7 concludes
the paper.

2 BACKGROUND

PRISM is built by utilizing the concepts of attacker behavior
modeling, HMM and stream processing. In this section,
the basics of the underlying methods and models used in
PRISM are discussed.

2.1 Attacker Behavior Modeling

Attacker behavior modeling is a widely used technique to
evaluate the security of enterprise networks [10]. PRISM
models the attacker behavior by extending the Google
PageRank mechanism. PageRank is ﬂexible enough to
model a diverse set of cases and its employment in network
security related graph problems is not uncommon [11],
[12]. The behavior of a random web-surfer is modeled by
PageRank who starts at a web-page and keeps on clicking
links until gets bored and starts at another web-page. A
web-page has higher rank if many pages link to it, and

a page is important if it has a high rank and has few
links to other pages. To model the probability of the web-
surfer breaking the chain of clicking links and starting from
a new random web-page, a damping factor is introduced
which essentially asserts that long chains of page clicking
is unlikely [13]. PageRank iteratively calculates the rank of
each page using Eq. 1.

P R(U ) = 1 − δ + δ

(cid:88)

j∈In(U )

P R(Wj)
Out|Wj|

(1)

Where, P R(U ) is the PageRank value of a page U , δ is
the damping factor with the value commonly set to 0.85,
P R(Wj) is the PageRank value of page Wj that points to
page U , and Out|Wj| is the number of links going out of
page Wj.

2.2 Hidden Markov Model

Markov chains are used to determine the probability of
a sequence of events that are observable. However, there
are many instances in which the events of interest are not
directly observable or hidden. A discrete ﬁrst-order HMM
is a doubly stochastic model that accommodates both ob-
served and hidden events. An HMM is characterized by the
following elements [14].

1) The set of N states represented by S = {s1, s2, .., sN },

where state at time t is qt.

2) A set of M distinct observation symbols per state

denoted as V = {v1, v2, .., vM }.

3) Transition probability matrix AN xN where aij is the

probability of shifting from state si to state sj.

aij = P (qt+1 = sj|qt = si),

i, j ∈ [1, N ]

(2)

4) Emission probability matrix BN xM , where bi(k) is the
probability of an observation vk being generated in a state
si.

bi(k) = P (vk at t|qt = si),

i ∈ [1, N ]
k ∈ [1, M ]

(3)

5) Initial probability vector π = {π1, π2, .., πN }, where
πi is the probability of Markov chain initializing at state si.

πi = P (q1 = si),

i ∈ [1, N ]

(4)

HMM-driven prediction systems use the model λ =
(S, V, A, B, π) and observation sequence O = {o1, o2, .., oT }
to effectuate various tasks. Note that observations are IDS
alerts in our case and we use the terms observation sequence
and alert sequence interchangeably. The use of HMMs in
practical applications is characterized by three fundamental
problems. First, how to determine P (O|λ), the probability
of observation sequence given the model. Second, how to
discover the best state sequence Q = q1, q2, .., qT given the
observation sequence and model. Third, how to learn the
model parameters A and B that maximize P (O|λ) given the
observation sequence and the set of states. The ﬁrst problem
is solved using the forward algorithm, the second problem is
solved using the Viterbi algorithm and for the third problem
the standard solution is unsupervised learning-based Baum-
Welch algorithm, but in our implementation we follow a
supervised learning approach discussed in Section 3 of the
paper.

3

2.3 Stream Processing

In the event of an attack, a continuous stream of alerts is
generated by the IDSs. PRISM employs stream processing
techniques to perform certain data manipulation operations
on this stream of alerts. In the stream processing context,
the terms bounded and unbounded refers to the ﬁnite
and inﬁnite data, respectively. Performing data processing
operations like sort, aggregation etc. on unbounded data
causes semantic problems, therefore, it is important to have
some notion of bounds on the unbounded data. Windowing
is a process of dividing data into ﬁnite blocks that can be
processed as a group. The process of windowing is essential
to analyze unbounded data and it has been proven to be
useful for bounded data as well in certain scenarios. Win-
dowing is generally time-based or count-based, however,
there are several other implementations as well. As the
names suggest, a time-based window deﬁnes a data block
on the data stream with respect to a time period, while
grouping a certain number of data items together forms
a count-based window. The three main window types are
tumbling, sliding and sessions. Tumbling windows are non-
overlapping windows deﬁned by constant window size and
a data item cannot be the member of more than one window.
Sliding windows are deﬁned by a ﬁxed window size and a
slide period which may be less than the window size im-
plying that the windows can overlap. In a sliding-windows-
based implementation, a data item can be part of multiple
windows. Sessions are windows that are deﬁned over a
subset of data using a timeout gap. The events that occur
within a timeout are combined to form a session [15]. PRISM
uses a custom implementation of the windowing process
employing both time-based and count-based windows to
manage the ﬂow of alerts streams.

3 SYSTEM MODEL AND ARCHITECTURE

PRISM is depicted in Fig. 1 along with its ﬁve constituent
systems: Threat-Aware Sampler (TAS), Zonal IDS, Alert
Stream Manager (ASM), Prediction Engine, and Security
Analyzer. TAS and Zonal IDS implement the distributed
security monitoring functionality of PRISM and are repli-
cated among multiple surveillance zones. In Fig. 1 only one
surveillance zone is shown for lucidity. The demarcation
of surveillance zones can be done based on the network
layout, trafﬁc volume distribution and amount of available
zonal IDS resources. The objective is to distribute the trafﬁc
equally among surveillance zones with the consideration of
network administrative constraints. The number of avail-
able zonal IDS resources determine the number of surveil-
lance zones. ASM, Prediction Engine and Security Analyzer
implement the integrated security analysis functionality of
PRISM. The detailed information about the design and
working of each component of PRISM is discussed as fol-
lows.

3.1 Threat-Aware Sampler

TAS is deployed in every surveillance zone along with the
zonal IDS. Mirrored trafﬁc from the router of the surveil-
lance zone is forwarded to the TAS which samples trafﬁc
in realtime and directs it to the zonal IDS. TAS has ofﬂine

4

Fig. 2: A sample 4-device NRG.

network devices according to their likelihood of being com-
promised. NRG< D, E > is a directed mutligraph with
its vertices corresponding to the devices in the network
represented by D = {d1, d2, ..., dn}. The parallel edges
of NRG correspond to the end-to-end communication be-
tween devices on different ports and are represented by
E, a multiset of edges (ordered pairs of vertices). A de-
vice in the network is identiﬁed by its ip address, and
for each device, the vulnerability score vs computed by
the vulnerability assessment module is also maintained.
The communication among network devices is in part de-
termined by ﬁrewall policies, network conﬁguration and
authentication/permissions within devices. A sample NRG
is illustrated in Fig. 2. NRG can be generated using any
network mapping tool like Nmap [19]. Another method
of generating NRG is by mapping the ﬂow information of
monitored network activity over time. We have employed
the latter method that is discussed in Section 4 of the paper.

3.1.3 Vulnerability Ranks and Sampling Probabilities Com-
putation

The core idea behind threat-aware sampling is to intel-
ligently sample trafﬁc by modeling the attacker behavior
that can rank network devices according to their likelihood
of being targeted by the attacker. The proposed attacker
behavior model captures the potential actions of an attacker
who has a speciﬁc target and tries to penetrate the network
through any accessible device. From the compromised de-
vices, the attacker tries to strike every other device until
the attainment of target. Fig. 3 shows an example attack
in which the attacker compromises devices d2, d6, and d8
to attack targetB by exploiting vulnerabilities ϑa
d2 , ϑx
d6 ,
ϑy
d8 and ϑz
targetB, respectively. The attacker behavior can
be modeled by extending the random surfer model with
security-centric semantics. A device has a high vulnerability
rank if it has high vulnerability score and has wide attack
surface i.e. several devices can communicate with it on
multiple ports. A device’s vulnerability rank is also high
if the devices communicating to it have high vulnerability
scores. The damping factor in the attacker behavior model
corresponds to the fact that it is unlikely for an attacker
to take a longer path to reach target if a shorter path
exists. The extended PageRank formalism that captures the
vulnerability transference effect of inter connected devices is
presented in Eq. (5). Where, τi represents the vulnerability
transference effect of a device di, δ is the damping factor,
In(di) is the in-set of device di i.e. it is the set of devices

Fig. 1: PRISM and its constituent systems.

and online modes of operation. In ofﬂine mode, TAS per-
forms three operations: vulnerability assessment, network
reachability graph generation and vulnerability ranks and
sampling probabilities computation. In online mode, TAS
carries out the task of realtime probabilistic sampling. The
functioning of the internal modules of TAS is discussed in
detail.

3.1.1 Vulnerability Assessment

The vulnerability assessment module of TAS performs vul-
nerability scan of each device in the network to determine
their Common Vulnerability Scoring System (CVSS) scores
[16]. CVSS is a popular measure of assessing the severity
of a device’s vulnerabilities by assigning a score out of
10. CVSS scores are computed using the information of
three metric groups: base, temporal and environmental.
For base metric group, information of ﬁve exploitability
metrics and three impact metrics is required to calculate
the score of a vulnerability. The vulnerability score for a
device can be obtained by considering the CVSS scores of
all vulnerabilities identiﬁed in a device. There are many
commercial and opensource tools available that can scan
the network and assess the vulnerabilities of each device
[17], [18]. TAS has the ﬂexibility to operate with any propri-
etary or opensource CVSS compatible network vulnerability
scanner. The vulnerability assessment procedure adapted
for experimentation is discussed in Section 4 of the paper.

3.1.2 Network Reachability Graph Generation

TAS employs the Network Reachability Graph (NRG) to
develop the attacker behavior model that is used to rank

vulnerability rank values are used to calculate the sampling
probabilities by employing the softmax function. Algorithm
1 is not computationally intense and it has been shown that
PageRank for millions of web-pages can be computed in few
hours on a medium size workstation [13].

5

Algorithm 1: Vulnerability Ranks and Sampling Probabili-
ties Computation
Input: N RG < D, E >, δ, epochs, thresh
Output: R = {ρ1, ρ2, ..., ρn}, Ψ = {ψ1, ψ2, ..., ψn}
1: R ←− vulnerability scores of n devices in D
2: Ψ ←− zero vector of length n
3: for i ∈ [1, epochs] do
4: Rlast = R
5:
6:

for di ∈ D do

/*vulnerability transference rank from Eq. 5*/
τi = 1 − δ + δ (cid:80)
j∈In(di) ρj
ρi = ρi + τi

|Out(dj ,di)|
|Out(dj )|

end for
/*calculate change in rank values using L1 norm*/
err = sum(abs(R)) − sum(abs(Rlast))
if err ≤ thresh then

7:
8:
9:
10:
11:
12:
13:
end if
14:
15: end for
16: for j ∈ [1, n] do
17:
18:
19: end for

break

/*softmax function to compute sampling probs.*/
ψj = exp(ρj)/sum(exp(R))

3.1.4 Realtime Probabilistic Sampling

Once the vulnerability ranks and sampling probability com-
putation module produces the vulnerability ranks R and
corresponding sampling probabilities Ψ of all devices in the
network, ﬂows (or packets) are sampled in realtime before
being sent to the zonal IDS. Let Xij be a ﬂow from device
di to dj, then the probability of ﬂow Xij of being sampled
is provided in Eq. 6.

P (Xij) = α ψi + β ψj

(6)

The sampling probabilities of devices di and dj are given
by ψi, ψj ∈ Ψ. The relative inﬂuence of source and destina-
tion device vulnerability ranks on the overall probability of
sampling a ﬂow is speciﬁed by α and β, where α, β ∈ [0, 1]
and α + β = 1. A larger α value will sample more ﬂows that
have high vulnerability rank source devices, while a larger
β value will sample more ﬂows with high vulnerability
rank destination devices. In our experiments, the values of
both α and β are set to 0.5. It is possible to ﬁnd optimal
values of α and β by employing parameter estimation
techniques on historical intrusion detection data. The ﬂows
can be sampled in realtime with negligible overhead as the
sampling probabilities of all devices are computed in the
ofﬂine mode.

3.2 Zonal Intrusion Detection System

Zonal IDS receives sampled trafﬁc from TAS, ﬁnds mali-
cious activities in its surveillance zone and sends alerts to

Fig. 3: Illustration of attacker’s movement in the network.

transmitting to di, ρj is the vulnerability rank of device dj
which is one of the devices in the in-set of di, |Out(dj)| is
cardinality of the set of outgoing edges from device dj, and
|Out(dj, di)| is cardinality of the set of edges from device dj
to di.

τi = 1 − δ + δ

(cid:88)

j∈In(di)

ρj

|Out(dj, di)|
|Out(dj)|

(5)

A device receives its vulnerability transference effect
from the devices that can communicate with it and the
devices that can communicate using multiple connections
(port pairs) contribute more to the vulnerability transfer-
ence. In vulnerability rank computation of a device, the de-
vice’s self vulnerability contributes to its rank in addition to
the contributions from the neighboring transmitting devices.
This conforms to the semantics of the proposed attacker
behavior model that a device is likely to be compromised
by an attacker if it has high vulnerability and is surrounded
by devices that have high likelihood of being targeted. It
can be argued that why not simply use the vulnerability
of a device as a measure to estimate its likelihood of being
compromised. The answer is in the fact that the position
of a device in the NRG affects its likelihood of being
reached by the attacker. If a highly vulnerable device is
surrounded by devices with low vulnerabilities, the chances
of the attacker reaching that device become less. Similarly,
if a device with low vulnerability is surrounded by devices
with high vulnerabilities then the likelihood of that device
getting compromised increases. The rank and sampling
probability computation module of TAS uses Algorithm 1 to
perform its operations. The algorithm produces two vectors
R = {ρ1, ρ2, ..., ρn} and Ψ = {ψ1, ψ2, ..., ψn} corresponding
to the vulnerability ranks and sampling probabilities of n
devices in the network. The values of epochs and thresh
regulate the convergence conditions of the algorithm. For
each device, ﬁrst the vulnerability transference effect is com-
puted and then it is combined with the vulnerability score to
obtain the vulnerability rank value of the device. Finally, the

the ASM. IDSs can be either signature-based or anomaly-
based, depending on the methodology they employ to de-
tect intrusions. Signature-based IDSs maintain signatures or
rules that are used to identify known cyber-attacks. These
rules are generally created by the security analysts, but
they can also be learned using supervised machine learning
techniques. Signature-based IDS are widely used and per-
form well in identifying malicious trafﬁc with considerable
detail, but are unable to detect zero-day attacks. On the
other hand, anomaly-based IDSs model the normal behavior
of the network, and raise alerts when a trafﬁc pattern is
observed that deviates from the normal behavior. Anomaly-
based IDSs can detect zero-day attacks, but they provide
little information about the detected malicious activity.
Anomaly-based IDSs are mostly developed using unsuper-
vised machine learning techniques, and their use as a stand-
alone IDS solution is limited. PRISM can incorporate any
IDS provided that the alerts contain information regarding
the vulnerability exploited, devices impacted and intrusion
type. A signature-based IDS is more compatible with other
systems of PRISM, however, a hybrid signature/anomaly-
based IDS can be used as well. In its current implementation,
PRISM uses the opensource signature-based Snort IDS [6].

3.3 Alert Stream Manager

ASM receives streams of alerts from the Zonal IDSs located
in different surveillance zones, and forwards it to the Secu-
rity Analyzer and Prediction Engine. The alerts are sent to
the Security Analyzer as soon as they received. For security
analysis functions, the order in which the alerts are received
is not critical, but to update security information of the
system promptly, it is essential to forward the alerts as soon
as they are received. Between reception and forwarding of
alerts to the Prediction Engine, ASM performs a set of im-
portant operations that ensures the alerts being forwarded
to the Prediction Engine are in the same order as they are
generated at their respective Zonal IDSs. The alerts can be
reordered due to network latencies, unsynchronized clocks
of Zonal IDSs and data transmission over a non-order-
preserving channel. ASM addresses the alert reordering
issue due to alerts being reported with different network
latencies from different Zonal IDSs. To rectify this problem,
ASM processes the unbounded and unordered streams of
alerts by using a window-based stream management proce-
dure. The essence of this procedure is the fact that we can
estimate certain bounds on the network latencies. Bounds
on the network latencies between Zonal IDSs and ASM can
be computed from network characteristics or historical data
that keeps track of the alert generation and reception time
difference [20].

Consider Z1, Z2, .., Zn Zonal IDSs with alert report-
ing latencies upper-bounded by L1, L2, .., Ln, respectively.
The actual maximum alert reporting latency is denoted by
∆max = max(L1, L2, .., Ln), where the estimate of maxi-
mum alert reporting latency is represented by µmax. Each
Zonal IDS generates a stream of alerts where an alert has
a number of attributes, among which the alert generation
timestamp ts is crucial for ASM operations. The alerts are
received by the alert buffer Y = {o1, o2, .., ot, ..}, where
o1 is ﬁrst alert in the buffer and ot is the alert received

6

at a certain time t. Alerts are processed and then sent
to the Prediction Engine by a mechanism known as the
Alert Order Rectiﬁcation (AOR) procedure. The alert buffer
occupancy is constantly being monitored and the number
of alerts in the buffer at any instance is accounted by the
variable buffer occupancy. The interval between successive
AOR procedure executions is also tracked and time elapsed
since the last alert AOR procedure is tracked by the vari-
able time elapsed. The AOR procedure is triggered when
buffer occupancy surpasses a conﬁgurable parameter called
alert sequence length ω or time elapsed exceeds another conﬁg-
urable parameter termed as timeout η. The AOR procedure
triggered when buffer occupancy exceeds ω follows a three
step protocol. First, a forwarding window F is formed that
includes all alerts in Y and all alerts received after waiting
for µmax period of time. Second, the alerts in F are sorted
with respect to ts. Finally, the ﬁrst ω number of alerts
in F are sent to the Prediction Engine and are removed
from Y . The µmax wait time ensures that all alerts that are
supposed to be part of F according to their alert generation
timestamp, but were not received due to network latencies
are included in F . It is possible that buffer occupancy does
not exceed ω for a long period of time. However, the alerts
cannot remain in Y indeﬁnitely, and must be reported to
the Prediction Engine for timely assessment of the attack. In
that case, the AOR procedure is triggered when time elapsed
caps η, which also follows the three step protocol. The only
difference is that all of the alerts in Y are included in F , are
sorted, and then sent to the Prediction Engine. As a result,
a smaller sequence of alerts is sent to the Prediction Engine.
The AOR procedure is articulated in Algorithm 2 and its
time complexity is O(n log(n)), while n here represents the
number of alerts being sorted.

Algorithm 2: Alert Order Rectiﬁcation

if (buffer occupancy ≥ ω) then

F ←− Y [o1 : ot+µmax ]
F.sort()
F = F [0 : ω]
Y = Y − F
sendT oP redictionEngine(F )
F ← ∅

Input: Y = {o1, o2, ..}, µmax, ω, η
1: buffer occupancy ←− no. of alerts in Y
2: time elapsed ←− time since last AOR proc.
3: while Y (cid:54)= ∅ do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21: end while

F ←− Y
F.sort()
Y = Y − F
sendT oP redictionEngine(F )
F ← ∅

end if
update(buffer occupancy)
update(time elapsed)

end if
if (time elapsed == η) then

It is to be noted that for best results the value of µmax
needs to be as close as possible to ∆max. If we underestimate

TABLE 1: Mapping of ATT&CK Tactics to Prediction States

7

ATT&CK Tactics

Prediction States

i) Reconnaissance
ii) Resource development
iii) Initial access

1) Initial access

iv) Execution

2) Execution

v) Persistence
vi) Privilege escalation
vii) Defense evasion
viii) Credential access
ix) Discovery
x) Lateral movement
xi) Collection
xii) Command and control

xiii) Exﬁltration
xiv) Impact

3) Foothold

4) Impact

Fig. 4: Evolution of buffer (Y) during the AOR procedure.
(a) Creation of forwarding window (F) and sorting of alerts.
(b) Sending alerts to Prediction Engine.

the value of µmax then the rectiﬁcation of alert reordering
yields less precise results, and if the value of µmax is over-
estimated then the original alert order can be restored by
the ASM, but it will cause additional delay in sending alerts
to the Prediction Engine. Also, the value set for ω controls
the number of alerts to be processed by the Prediction
Engine at a time. Generally, longer alert sequences allow
more accurate attack prediction but at the cost of delay
in attack prediction decision. The value of η should be set
considering the alert arrival rate. It should not be too small
to trigger the timeout driven forwarding process frequently
and nor should be too large to introduce unnecessary delays
in attack prediction. Fig 4 shows the state of Y during
the AOR procedure. The AOR procedure is triggered by
buffer occupancy exceeding ω, and correspondingly, F is
constructed by including all alerts that arrive until the µmax
time as shown in Fig 4a. Subsequently, the ﬁrst ω number of
sorted alerts in F are sent to the Prediction Engine and are
discarded from Y as illustrated in Fig. 4b.

3.4 Prediction Engine

Prediction engine performs the function of assessing the
progression of an attack using the alerts forwarded by
the ASM. PRISM has the ﬂexibility to accommodate any
time series data-based machine learning model, and in its
current implementation the prediction engine is driven by
HMM. Similar to TAS, prediction engine has ofﬂine and
online modes of operation. In ofﬂine or training mode,
prediction engine performs the operations of training data
preprocessing and multi-stage attack learning. In online or
prediction mode, attack stage prediction is carried out in
realtime. The working of the internal modules of prediction
engine is described as follows.

3.4.1 Training Data Preprocessing
The training of HMM utilizes IDS alert data that can be from
IDS alerts of real attack instances, alerts from engineered

attacks on a test network or synthetic alerts forged for
training purposes. As the training data can be from multiple
diverse sources, it is essential to formalize the preprocessing
task. The training data preprocessing module accepts data
in a CSV format then performs four step preprocessing
operation. First, all rows with missing values are removed.
Second, the timestamp format of alerts is checked and
is reformatted if it is incompatible with the data parsing
function. Third, duplicate rows are discarded. Fourth, the
alert data is rearranged in the ascending order with respect
to the timestamps. Finally, the reﬁned IDS alert data is stored
in a CSV ﬁle ready to be used by the multi-stage attack
learning module of the prediction engine.

3.4.2 Multi-Stage Attack Learning

The multi-stage attack learning module analyzes the pre-
processed IDS alert data ﬁles to train the HMM. For each
multi-stage attack type in the training data, a separate
is trained forming an HMM attack proﬁle bank
model
that is shared with the attack stage prediction module.
PRISM uses the MITRE ATT&CK [21] adversary tactics and
techniques knowledge base to contrive the state space of
its prediction models that correspond to different attack
progression stages. ATT&CK is a real-world observations-
based threat information framework that describes the ac-
tions of adversaries in executing complex multi-stage at-
tacks. These actions are represented by the techniques in
ATT&CK framework that are organized into fourteen tac-
tics. ATT&CK provides a detailed technical description, real-
world usage examples with associated actors, mitigation
and detection information for each technique. Tactics are
the tactical objectives of the adversary that are achieved
by employing the relevant techniques and tactics are ar-
ranged in the way attacker progresses through a multi-
stage attack. The tactics in ATT&CK framework naturally
become suitable candidates for the states in the multi-stage
attack prediction models. However, having fourteen states
not only adds to computational complexity, but having all
fourteen tactics involved in a single attack is highly unlikely.
This necessitates the mapping of the fourteen tactics into a
smaller and more generic state space. The prediction engine
of PRISM maps the fourteen tactics into four states: initial

8

attack learning process where it receives the alert training
data and produces the HMM attack proﬁle bank Λ. It is to
be noted that the models are designed to always begin from
the ﬁrst state thats why all models in Λ are initialized with
πi = [1 0 0 0].

Algorithm 3: Multi-stage Attack Learning

Input: T raining Data = {attack1, attack2, .., attackk}
Output: Λ = {λ1, λ2, .., λk}
1: Λ ←− vector of k λ objects (init. with πi)
2: for x ∈ [1, k] do
3:
4:
5:

/*Learning Transition Probabilities*/
for i ∈ [1, N ] do

for j ∈ [1, N ] do

λx.A[i][j] = Γij
(cid:80)N
if (j > i + 2 || j < i − 1) then

r=1 Γir

/* from Eq. 7*/

6:

7:
8:
9:
10:
11:
12:
13:
14:

15:

λx.A[i][j] = 0

end if
end for

end for
/*Learning Emission Probabilities*/
for i ∈ [1, N ] do

for l ∈ [1, M ] do
λx.B[i][j] =

Υi(l)
r=1 Υi(r) /* from Eq. 8*/

(cid:80)M

end for

16:
17:
18: end for

end for

3.4.3 Attack Recognition and Stage Prediction

The attack recognition and stage prediction module predicts
the type of the multi-stage attack and its current stage for
every alert sequence forwarded by the ASM in realtime.
The attack stage prediction process has two parts, attack
recognition and decoding. In attack recognition, the attack
proﬁle corresponding to the observed alert sequence is
determined from the HMM attack proﬁle bank. To ﬁnd out
the most likely attack proﬁle, the likelihood of the alert
observation sequence given the model, P (O|λ), is computed
for each HMM attack proﬁle using the forward algorithm.
The HMM attack proﬁle with the highest likelihood score
is selected and is used to track the progress of the attack.
The internal mechanism of forward algorithm is discussed
in Appendix A of the paper. After attack recognition, the
process of decoding takes place that involves ﬁnding out the
optimal state sequence corresponding to the forwarded alert
sequence. To achieve this, the variable χt(i) is introduced
that represents the probability of being in state si at time
t as expressed in Eq. 9. The most likely state qt at time t
can be solved independently using Eq. 10. Viterbi algorithm
ﬁnds qt for a given observation sequence efﬁciently using a
dynamic programming approach explained in Appendix A
of the paper.

χt(i) = P (qt = si|O, λ)

qt(i) = argmax
i=1,..,N

χt(i),

t ∈ [1, T ]

(9)

(10)

Algorithm 4 explains the functioning of attack recogni-
tion and stage prediction module systematically. The time

Fig. 5: The process of attack recognition and decoding.

access, execution, foothold, and impact. The mapping be-
tween ATT&CK tactics and the prediction states is shown in
Table 1. Note that the terms attack stage and prediction state
are used interchangeably in the paper. As discussed earlier, a
supervised learning approach is used to train the HMM. The
preprocessed IDS alert training data does not have labels
indicating the classiﬁcation of alert sequence into ATT&CK
tactics and corresponding prediction states. Most of the
mainstream threat detection frameworks have the feature
to report alerts in compliance to the ATT&CK framework
[22], [23], [24]. Since PRISM relies on the opensource snort
IDS, a mechanism is required to associate snort alerts to
the ATT&CK tactics. For this purpose, we have utilized the
concepts of information retrieval to match the key words
from snort alert messages to the technical description of the
ATT&CK techniques which is discussed in detail in Section
4 of the paper. Using the labelled IDS alert training data, A
and B matrices are learned using Eqs. 7 and 8.

aij =

s.t.

,

(cid:80)N

Γij
r=1 Γir
aij = 0,

bi(l) =

Υi(l)
r=1 Υi(r)

(cid:80)M

,

i, j ∈ [1, N ]

j > i + 2
j < i − 1

i ∈ [1, N ]

l ∈ [1, M ]

(7)

(8)

Where, Γij is the number of transitions from state si
to sj and Υi(l) is the number of times observation vl
appears in state si. The learned HMM can be ergodic or
of any shape based on the state transitions present in the
training data. However, there are certain HMM types that
model some applications more accurately, e.g., the left-right
model is considered to have better performance in speech
recognition [14]. Based on our experimentation, we have
devised a semi-ergodic HMM for PRISM. The transition
probabilities being learned in Eq. 7 are constrained by the
two conditions that no transitions of more than two states
are permitted and transitions from higher states to lower
states are only possible among the adjacent states. These
constraints improve the accuracy in detecting multi-stage
attack progression. Algorithm 3 explains the multi-stage

complexity of Algorithm 4 is O(N 2T ) which is the time
complexity of both forward and Viterbi algorithms. Fig.
5 depicts the use HMM attack proﬁle bank in the attack
recognition and decoding tasks.

Algorithm 4: Attack Recognition and Stage Prediction

max likelihood = likelihood
λactive = λ

likelihood = P (O|λ) /* from Eq. A.3 */
if (likelihood > max likelihood) then

Input: O = {o1, o2, .., oT }, Λ = {λ1, λ2, .., λk}
Output: λactive, P ∗, Q = {q1, q2, .., qT }
1: /* Attack Recognition by Forward Algorithm */
2: max likelihood = 0
3: for λ ∈ Λ do
4:
5:
6:
7:
end if
8:
9: end for
10: /* Decoding using Viterbi Algorithm */
11: νt(i) = max
12: P ∗ = max
i=1,..,N
13: Q(cid:48) = argmax
i=1,..,N
14: for t = T − 1 : 1 do
15: Q(cid:48) = Q(cid:48) ∪ ξt+1(q∗
16: end for
17: Q = Q(cid:48).reverse()

νT (i) /* from Eq. A.10 */
νT (i) /* from Eq. A.11 */

q1,..,qt−1

t+1)

P (q1, .., qt−1, o1, .., ot, qt = i|λactive)

3.5 Security Analyzer

Security Analyzer realizes the cyber situational awareness
capability of PRISM by the computation of important secu-
rity metrics and their visualization in realtime for effective
decision making in response to the attacks. The input to
the Security Analyzer is prediction output of the Prediction
Engine and unmediated alerts from the surveillance zones.
By unmediated it is meant that the alerts are not subjected
to the AOR procedure in the ASM. The alert and prediction
output data is processed in realtime to extract relevant
information for metrics computation. The information of
interest in the alert data is the alert id, alert generation
timestamp and id of the device for which the alert has
been generated. From the prediction output, information
regarding attack type, attack stage and the probability of
being at different attack stages corresponding to an alert
is obtained. The metric computation process is alert-driven
(event-driven), and the metrics are computed with each re-
ported alert at time t. To get a holistic picture of the damage
spread, widely used system availability metric is utilized.
Additionally, we propose two metrics: threat perceptivity
and system degradability that are designed to enhance the
cyber situational awareness capabilities speciﬁcally for the
case of availability attacks. Formally, the three metrics are
deﬁned as follows.

System availability: The percentage of devices working
at their routine operational capacity with respect to the total
number of devices in the system at a certain time t. It is
expressed in Eq. 11.

system availability(t) =

no. of available devices at t
total no. of devices

∗ 100 (11)

9

Threat perceptivity: The measure to quantify attack pro-
gression and associated risk to the system. Mathematically,
it is expressed in Eq. 12, where χt(i) is the probability of
being at state si for an alert received at time t, εi is the
numerical value corresponding to the risk associated with
state si, with higher values to be set for advanced stages.
The value of thereat perceptivity is between 0 and 1 and
higher value means the ongoing attack is in advanced stages
with the system facing elevated risk.

threat perceptivity(t) =

(cid:80)N

i=1 χt(i)εi
max(εi)

(12)

System degradability: The impact of attack risk on the
system operability quantiﬁed through the fraction of com-
promised devices in the system. Eq. 13a speciﬁes the fraction
of compromised devices at time t, and system degradability
at time t is manifested in Eq. 13b. Like threat preceptivity,
the value of system degradability is also between 0 and 1,
with higher values implying increased attack progression
intensity.

θ(t) =

no. of compromised devices at t
total no. of devices
system degradability(t) = θ(t) threat perceptivity(t)

(13a)

(13b)

System availability,

threat perceptivity and system
degradability is computed for each reported alert and the
Security Analyzer plots the metrics in realtime for the con-
venience of the security operations team to gain valuable in-
sights about the ongoing attack. Visualization of the metrics
helps to assess the situation better and consequently a more
informed response can be deployed. Additionally, all of the
metric computations are constantly being stored in a report
ﬁle that can be used by an automated response system.
The visualization functionality of the Security Analyzer is
discussed further in Section 5 of the paper.

4 EXPERIMENTAL SETUP

To evaluate the performance of PRISM, extensive experi-
mentation has been conducted on the ISCX-2012 dataset.
The dataset contains a wide variety of multi-stage attacks
embedded in seven days of network activity. The attacks are
launched on a network of hundreds of workstations and the
captured trafﬁc is stored in the packet capture (pcap) ﬁles.
The network activity data of a day is stored in a separate
ﬁle and includes up to 10 million packets. The dataset also
incorporates labelled ﬂow-data ﬁles providing information
whether a ﬂow is malicious or benign. All constituent
systems of PRISM are implemented in Python 3.7 and are
compatible with the speciﬁcations of the dataset. The ex-
periments are conducted on a workstation with 8 cores and
16 GB of memory. Fig. 6 shows the conceptual deployment
of PRISM on ISCX-2012 network architecture by realizing
each Local Area Network (LAN) as a surveillance zone. The
speciﬁc details of how different modules of the constituent
systems of PRISM implement the distributed security mon-
itoring and integrated security analysis functionality using
the dataset resources is discussed as follows.

4.1 Distributed Security Monitoring

TAS and Zonal IDS implement the distributed security
monitoring functionality of PRISM. As mentioned in Section
3, TAS performs the operations of network reachability
graph generation, vulnerability assessment, vulnerability
ranks and sampling probabilities computation, and realtime
probabilistic sampling. The network reachability graph gen-
eration is carried out by determining the communication be-
tween all network devices on different port numbers using
the normal network activity data in the dataset. For vul-
nerability assessment, the vulnerability score of each device
is estimated as we cannot deploy vulnerability scanners on
the ISCX-2012 network nor vulnerability information of the
network devices is provided in the dataset. To estimate the
vulnerability scores of devices, we use the CVSS base score
computation methodology by treating network devices as
vulnerabilities to be exploited. The CVSS base score is deter-
mined using ﬁve exploitability metrics: attack vector, attack
complexity, privileges required, user interaction and scope,
along with three impact metrics: conﬁdentiality, integrity
and availability. The attack vector is determined using net-
work reachability graph with the assumption that all de-
vices that can communicate to a device can also compromise
it. Therefore, the part of the network from where a device
could potentially be targeted can be determined. Since we
are modeling multi-stage attacks, the attack complexity is
set to high for each device. Privileges required is set as low
for regular hosts and high for servers. User interaction is set
as required and scope is set as changed for each device. For all
three impact metrics, the value set to low for regular hosts
and high for servers. Table 2 summarizes the values adjusted
for CVSS base score metrics. Once the network reachability
graph is generated and the vulnerability assessment process
is complete, the vulnerability ranks and sampling proba-
bilities of all devices in the network are calculated using
Algorithm 1. The network trafﬁc incorporated in pcap ﬁles
is then distributed between the surveillance zones using
the IP addresses of the devices. In each surveillance zone,
the packets in the zonal pcap ﬁle are sampled using Eq.
6. The sampled zonal pcap ﬁle is then forwarded to Snort
IDS that generates an alert ﬁle using Snort v3.0 community
rules. To engineer the distributed alert reporting process,
the alert ﬁle in each surveillance zone is appended with a
transmission delay value between ∆min and ∆max, which
are conﬁgurable parameters in our experiments, and for
each surveillance zone, the transmission delay values are
randomly chosen within the range of these parameters. The
alerts from each surveillance zone are then delivered to the
input buffer of the ASM according to the alert generation
timestamp added with the transmission delay.

4.2 Integrated Security Analysis

The integrated security analysis functionality of PRISM is
implemented by ASM, Prediction Engine and Security An-
alyzer. Initially, the multi-stage attack learning operation of
the Prediction Engine is performed to construct the HMM
attack proﬁle bank. The pcap ﬁles for different attack types
in the dataset are used to generate the alert ﬁles using Snort
IDS. The four-step training data preprocessing is carried
out and then the alert labelling corresponding to ATT&CK

TABLE 2: CVSS Metrics Values for Vulnerability Assessment

10

Metric Name

Attack Vector

Metric Value

Determined by NRG

Attack Complexity

High

Privileges Required

Regular hosts: low, Servers: high

User Interaction

Scope

Required

Changed

Conﬁdentiality

Regular hosts: low, Servers: high

Integrity

Regular hosts: low, Servers: high

Availability

Regular hosts: low, Servers: high

tactics is accomplished. To label an alert, keywords are
extracted from the alert information and are matched to
the technical description of ATT&CK techniques using the
information retrieval method of Term Frequency - Inverse
Document Frequency (TF-IDF). The TF-IDF scores of each
keyword are calculated for all ATT&CK techniques and the
technique that has the highest average TF-IDF score of the
alert message keywords is identiﬁed. The ATT&CK tactic
that pairs to the identiﬁed ATT&CK technique is selected,
and prediction state corresponding to the selected tactic, as
described in Table 1, is chosen as the label of the alert. Some
ATT&CK techniques are part of multiple tactics, therefore,
labelling of alerts requires establishment of context. The
context is established by using the state corresponding to the
last labelled alert. For multiple candidate tactics picked up
for an alert, those tactics are selected that maps to a higher
prediction state, otherwise the alert is labelled with the state
of the last labeled alert. The semantics behind this rule is
that as the attacker is executing a multi-stage attack, it is
counter intuitive for the attacker to move in the backwards
direction. If there are several alerts pointing to the previous
prediction states then that will be considered as a new multi-
stage attack. Such attack scenarios are investigated in [26].
In rare cases, the average TF-IDF score of alert message
keywords is not signiﬁcantly different for different ATT&CK
techniques due to limitation of expressiveness in Snort alert
information. To handle such cases we label the alert with the
label of the previous alert, i.e., we make the assumption that
this alert is not causing any attack stage transition. Once the
alert ﬁles are labelled, Algorithm 3 trains the HMM attack
proﬁles using 30% of the alert data for each attack type in
the ISCX-2012 dataset.

Alerts from different surveillance zones are gathered in
the input buffer of the ASM, from where they are sent
to the Prediction Engine and Security Analyzer. The alerts
being sent to the Prediction Engine are ﬁrst sequenced and
then forwarded using the AOR procedure articulated in
Algorithm 2. The value of the parameter µmax is conﬁgured
to be less than the value set for ∆max in the experiments to
test the robustness of alert stream management process. The
parameter ω is selected according to the maximum length
of alert sequence intended to be processed by the Prediction
Engine. The value of the η parameter is ﬁxed to be 500
ms in all experiments. Prediction Engine upon reception
of an alert sequence ﬁrst ﬁnds out which attack is active
and then predicts the stage of the attack using Algorithm
4. Security Analyzer receives unmediated alerts from the
ASM and attack prediction information from the Prediction

11

Fig. 6: PRISM deployment on the ISCX-2012 network.

Engine to compute and visualize three metrics: system avail-
ability, threat perceptivity and system degradability for each
incoming alert.

5 PERFORMANCE EVALUATION
We have conducted several experiments to evaluate the
performance of PRISM in terms of processing efﬁciency
and prediction efﬁcacy. The experiments are designed to
demonstrate the individual performance of the constituent
systems of PRISM and their inﬂuence on the overall system
operability.

5.1 Effect of Threat-Aware Sampling and Distributed
Trafﬁc Processing

The most computation intensive phase in the intrusion de-
tection exercise is the processing of the network trafﬁc. The
vast magnitude of trafﬁc generated by various devices in the
enterprise networks make it even more challenging espe-
cially when the requirement is to detect malicious trafﬁc in
realtime. To cope up with this challenge, a simple yet expen-
sive solution is commonly employed, that is, adding more
computation power. PRISM on the other hand provides an
effective solution that leverages its threat-aware sampling
and distributed trafﬁc monitoring structure to process trafﬁc
in realtime with limited computation resources. In the ﬁrst
experiment, the performance of threat-aware sampling is
compared to common network trafﬁc sampling schemes of
smart sampling and random sampling. In smart sampling,
the ﬂows are sampled according to their size with large
ﬂows having more probability of being selected [27]. The
comparison between the sampling schemes is made using
a measure that determines how much information is lost in
the sampling process. In intrusion detection applications,
a malicious ﬂow is the information that is desired to be
retained where a normal ﬂow is considered as noise. We
introduce the metric Malicious-ﬂow Loss Rate (MLR) that
determines the amount of malicious ﬂows not retained after
sampling as expressed in Eq. 14. Sampling ratio σ is the
control parameter in the threat-aware sampling process,
which is the number of ﬂows selected over the total num-
ber of ﬂows as manifested in Eq. 15. The MLR of threat-
aware sampling, random sampling and smart sampling
corresponding to different values of σ for inﬁltration and
HTTP DoS attacks in the ISCX-2012 dataset is shown in Fig.

(a)

(b)

Fig. 7: Threat-aware sampling performance in comparison
to common sampling schemes for (a) inﬁltration attack and
(b) HTTP DoS attack.

(a)

(b)

Fig. 8: Processing overhead of centralized intrusion detec-
tion and distributed security monitoring of PRISM corre-
sponding to different sampling ratios for (a) inﬁltration
attack and (b) HTTP DoS attack.

7. It can be seen that the MLR of threat-aware sampling
is much lower than that of random sampling and smart
sampling with the widest difference observed for σ = 0.45
and σ = 0.6 for both attack types. The MLR values of all
sampling schemes for both attack types are close to each
other when σ = 0.15 and σ = 0.90. The cause of this
behavior relies on the fact that when the sampling ratio
is low, only few ﬂows have to be selected out of the total,
that forces the sampling schemes including the threat-aware
sampling to lose malicious ﬂows. On the other hand, when
the sampling ratio is high, only few of the ﬂows are needed
to be dropped that leaves all sampling schemes to retain
most of the malicious ﬂows.

M LR =

number of malicious ﬂows not selected
total number of malicious ﬂows

σ =

number of sampled ﬂows
total number of ﬂows

(14)

(15)

In the second experiment, we have investigated the effect
of threat-aware sampling and distributed architecture on
the trafﬁc processing capabilities of Snort. Fig. 8 shows the
processing overhead of Snort for around 5.8 million packets
of inﬁltration attack data and 9.6 million packets of HTTP
DoS attack data. As expected, the performance of PRISM’s
distributed architecture is signiﬁcantly better than a central-
ized intrusion detection architecture for different sampling
ratios. It has been determined in our other experiments

TABLE 3: Distributed Alert Reporting Parameters

Delay Conﬁguration ∆min − ∆max (ms)

Low

Medium

High

50 - 100

100 - 250

250 - 400

µmax (ms)
70

175

280

discussed ahead that the prediction capabilities of PRISM
are acceptable with even σ = 0.3. Comparing the processing
overhead of PRISM’s distributed architecture setting with
σ = 0.3 to the processing overhead of non-distributed and
no sampling system (σ = 1) as an equivalent to a standard
IDS (like Snort) shows that PRISM makes the intrusion
detection process 7.3x faster in the case of inﬁltration attack
and 7.5x faster in HTTP DoS attack scenario.

5.2 Attack Prediction Performance and Utility of Alert
Stream Management

We have performed several experiments to determine the
prediction efﬁcacy of PRISM by varying the training data
size and sampling ratios of the threat-aware sampling. All
of the results presented here correspond to network trafﬁc
data sampled using threat-aware sampling at σ = 0.3. The
prediction output for inﬁltration and HTTP DoS attacks
is presented in Fig. 9(a),(b), while Fig. 9(c),(d) shows the
classiﬁcation details of prediction output in the form of
confusion matrices. It can be seen that the overall prediction
performance is fairly decent for σ = 0.3 and ω = 10. In
the inﬁltration attack scenario, stages 1 and 4 of the attack
are predicted without any error while stages 2 and 3 are in-
correctly predicted as stage 1 for some instances. For HTTP
DoS attack, most of the incorrect predictions are for attack
stages 3 and 4. The prediction capabilities of PRISM are
primarily dependant on the quality of data used in training
the models. However, given a trained model, the runtime
performance of the Prediction Engine is inﬂuenced by ω,
and generally longer length alert sequences are predicted
by the model with more accuracy. But formation of long
sequences entails increased waiting times to gather alerts,
and in a realtime environment, the requirement is to process
the alerts as quickly as possible for a timely prediction
decision. Experiments are conducted to reveal the effect of
different alert sequence sizes on the prediction correctness
and the results are illustrated in Fig. 10. To measure the
prediction correctness, we have used recall that quantiﬁes
how well the model performs in identifying the actual attack
stage in a given conﬁguration. Fig. 10a shows the prediction
recall values for inﬁltration attack corresponding to different
values of ω. It can be seen that the prediction recall for stages
1 and 4 is ideal for all values of ω, but for stages 2 and 3,
the prediction recall values are less for lower values of ω.
Fig. 10b illustrates the prediction recall for HTTP Dos attack
and it can be seen that the prediction recall improves with
the increase in ω for stages 2, 3 and 4. If 9(c),(d) is observed
together with Fig. 10(a),(b), then it can be realised that lower
values of ω exacerbate the error in prediction, especially for
attack stages that are prone to be predicted incorrectly.

To ascertain the effect of alert stream management on
the prediction performance we have engineered distributed
alert reporting mechanism as discussed in Section 4. The

12

(a)

(b)

(c)

(d)

Fig. 9: Attack stage prediction for (a) inﬁltration attack and
(b) HTTP DoS attack. (c),(d) Confusion matrix represen-
tation of prediction output for inﬁltration and HTTP DoS
attacks, respectively.

(a)

(b)

Fig. 10: Prediction recall for different alert sequence lengths
(ω) for (a) inﬁltration attack and (b) HTTP DoS attack.

experimentation has been carried out with ω = 10 using the
three delay conﬁgurations: low, medium and high where
the value of µmax is set to be 30% lower than the value
of ∆max, as detailed in Table 3. The prediction recall cor-
responding to the three delay conﬁgurations including the
alert sequencing using the AOR procedure on the high delay
conﬁguration impacted alerts is shown in Fig. 11. It can be
seen that as the distributed alert reporting latency becomes
more random, that is, higher alert delay conﬁguration, the
ability of the model to predict attack stages correctly is
signiﬁcantly reduced, especially for those attack stages that
have fewer number of alerts. This phenomenon can be
observed through the prediction recall values for high delay
conﬁguration at stage 4 of the inﬁltration attack in Fig.
11a and stage 2 of the HTTP DoS attack in Fig. 11b. The
effectiveness of alert stream management is also apparent
as the AOR procedure even with µmax estimate 30% less
than ∆max value restores the original order of the alerts
signiﬁcantly well. It is to be noted that there is a cost

13

(a)

(b)

(a)

(b)

Fig. 11: (a),(b) Prediction recall corresponding to different
delay conﬁgurations for inﬁltration and HTTP DoS attacks,
respectively.

Fig. 12: EDI corresponding to different delay conﬁgurations
for (a) inﬁltration attack and (b) HTTP DoS attack.

associated to the application of AOR procedure that every
time an alert forwarding window is formed, there is a wait
of µmax before the alerts are sent to the Prediction Engine.

Prediction recall is one aspect to quantify the prediction
system’s performance. In a realtime environment, it is neces-
sary to measure how soon the prediction operation is able to
detect attack stage transitions during the progression of an
attack. The sooner the prediction apparatus is able to iden-
tify the change in attack stage, the more effective response to
thwart the attack can be formulated. To measure the ability
of the Prediction Engine to detect the correct attack stage
as soon as the attack transitions from one stage to another,
the metric Early Detection Index (EDI) is proposed and is
expressed in Eq. 16.

EDI =

(cid:80)N

i=1

i−of
ol
Ci

i

εi

H

(16)

Where ol

i represents the alert number of the last alert
in attack stage i in original labeled data (ground truth)
and of
is the alert number of the ﬁrst alert that the model
i
predicts to be of attack stage i, that is, the alert that detects
the beginning of attack stage i. Ci is the total number of
alerts corresponding to attack stage i in the original labelled
data and εi, is the numerical weight corresponding to the
risk associated with attack stage i. Any ε value can be
assigned to an attack stage with advanced attack stages
being given higher values and in our experiments the attack
stage number itself is used as the ε value. H is the sum of
attack stage risk values, that is, H = (cid:80)N
i=1 εi. Fig. 12(a),(b)
shows the EDI with respect to different values of ω for the
three delay conﬁgurations and alert order correction using
the AOR procedure. It can be observed that the EDI for both
of the attacks is quite less in the case of high delay conﬁgura-
tion as compared to medium and low delay conﬁgurations.
Whereas, the EDI is near the maximum value of 1 in the case
of alert stream being subjected to the AOR procedure. This
demonstrates that the use of alert stream management not
only beneﬁts the prediction correctness but also signiﬁcantly
improves the ability of the Prediction Engine to detect attack
stage transitions rapidly.

5.3 Security Analysis for Cyber Situational Awareness

We have evaluated the functionality of the Security Ana-
lyzer on the alerts generated from the inﬁltration attack data

of the ISCX-2012 dataset. In the experiments the network
trafﬁc is not sampled and the value of ω is set to be 10.
Also, the alerts from different surveillance zones are not
subjected to any additional delay. The metrics are computed
and visualized by the Security Analyzer as each of the alert
is received in realtime, but here we present the plots of
the complete attack. In Fig 13a, system availability of the
network is shown with respect to the alerts. It can be seen
that there is little effect on the system availability during the
ﬁrst half of the attack, but during the second half the system
availability reduces drastically. Threat perceptivity corre-
sponding to the stream of incoming alerts is illustrated in
Fig. 13b. As expected, the threat perceptivity increases as the
attack progresses into advanced stages. In Fig. 13c, system
degradability for the case of inﬁltration attack is presented,
and it can be observed that as the attack progresses, with
the decreasing system availability, the system degradability
increases. Fig. 14 presents the output of Security Analyzer
corresponding to inﬁltration attack scenario with just using
1% of the network trafﬁc that is sampled using the threat-
aware sampling. In addition to exhibiting the effect of a
very high sampling rate, this experimental setting reﬂects
the impact of a fast moving stealthy attack that achieves the
target by generating a minimal amount of alerts. It can be
observed that the system availability, threat perceptivity and
system degradability changes drastically to the worst levels
within the last 30 reported alerts. This shows the limitation
of Security Analyzer in assisting human-driven response
operations and reafﬁrms the proposition that automated
response mechanisms are better suited to foil such attack
types as discussed in [28].

6 RELATED WORK

Many IDS architectures have been proposed over the years
with a certain IDS architecture being dominant for a par-
ticular network type. For enterprise networks a centralized
IDS deployment is the most common in which the IDS
scrutinises all trafﬁc passing through the external routers
that connect the enterprise network to the internet [29].
Internet of Things (IoT) networks are generally protected
by distributed IDS as there is no central location from
where data of the whole network can be monitored [30].
A distributed IDS architecture for enterprise networks is
proposed in [31] that has IDS components distributed into
different regions of the network. Each regional detector

14

(a) System Availability

(b) Threat Perceptivity

(c) System Degradability

Fig. 13: Security Analyzer output during inﬁltration attack scenario.

(a) System Availability

(b) Threat Perceptivity

(c) System Degradability

Fig. 14: Security Analyzer output corresponding to 1% of sampled trafﬁc.

reports malicious activities of its sphere to a global detector
that uses Sequential Hypothesis Testing (SHT) to determine
whether the whole enterprise network is under attack. In
[32], the authors propose a fully distributed architecture in
which the IDS has several IDS nodes. Each sub-network
is observed by a sentry node that communicates with the
sentry nodes of other sub-networks as well. In addition to
sentry nodes, there are a higher level conﬁguration entities
called the survey nodes that work as a long term memory
to cache rules, sub-network states and representations of
connections. A collaborative anomaly detection framework
has been proposed in [33] that uses network virtualization
techniques to implement a global situation detection and lo-
cal behavior detection model. The framework uses Hidden
Markov Random Field (HMRF) to model network behavior
and spatial Markovianity to model the network behavior’s
spatial context. Recently, the use of blockchain technology
in distributed IDS design has become popular. In [34], a
distributed IDS has been proposed that uses blockchain and
smart contracts to mitigate threats on collaborating IDSs on
different cloud networks. None of the abovementioned dis-
tributed IDSs, unlike PRISM, have the capability to identify
multi-stage attacks with the prediction of attack progression
stage.

Several

intrusion prediction, attack projection, attack
intention recognition and network security situation fore-
casting techniques have been proposed [35]. In this paper

we will only discuss intrusion prediction using machine
learning models, speciﬁcally HMM-based intrusion predic-
tion. The use of HMMs for network intrusion detection
is not new, in [36], [37], [38], [39], [40] anomaly detection
systems using HMMs are presented. Recently, HMMs have
been extensively used for network intrusion prediction. An
intrusion prediction and prevention system has been pre-
sented in [41] that uses HMM to predict the next step of an
attacker. The intrusion prediction information is then used
for intrusion prevention operations according to a set of
predetermined rules. In [42] data mining driven algorithm
is proposed that mines the stream of IDS alerts for attack
scenario extraction. An HMM-based alert correlation system
is then introduced that predicts the next class of attacks to
be launched by the intruder. Frameworks to predict multi-
step network attacks using HMMs are proposed in [43],
[44]. In [26], HMM-based architectures have been proposed
that predict the attack stage when several multi-stage at-
tacks are in action simultaneously. Lately, to address the
issue of limited availability of network intrusion detection
datasets, a transfer learning-based approach is proposed
that trains the HMM model using a labelled dataset and
then adapts the model to a target unlabelled dataset [45].
The aforementioned intrusion prediction techniques only of-
fer a centralized approach to process network trafﬁc. PRISM
on the other hand presents an intrusion prediction architec-
ture with distributed trafﬁc processing. Moreover, PRISM

addresses the challenges associated with the distributed
design by introducing an efﬁcient alert stream management
mechanism.

The impact of sampling techniques designed for net-
work trafﬁc engineering on the performance of network
intrusion detection is well studied. In [8], the suitability
of four commonly used sampling techniques for intrusion
detection applications has been investigated. The intrusion
detection performance of random packet sampling, random
ﬂow sampling, sample-and-hold and smart sampling is
compared. It has been shown that ﬂow-based sampling
performs better than packet-based sampling. Both sample-
and-hold and smart sampling are found to be biased to-
wards large volume ﬂows, and are not suitable to detect
several attack types. In [46], smart sampling and selective
sampling techniques are evaluated for intrusion detection
applications. Results demonstrate that selective sampling
does not exhibit much bias towards large volume ﬂows
unlike smart sampling. In [47], a sampling scheme designed
for network intrusion detection has been proposed. The de-
veloped sampling mechanism is based on late and adaptive
sampling process. The late sampling process extracts ﬂow
features and calculate ﬂow statistics. Adaptive sampling
process then selects outlier ﬂows with more preference as
compared to ﬂows with similar ﬂow statistics. Recently,
machine learning-based sampling techniques have been
employed for network intrusion detection applications. In
[48], a hierarchical clustering-based sampling technique is
proposed that uses structural and temporal features of sus-
picious ﬂows in a two-step hierarchical clustering algorithm.
In [49], the impact of sampling on anomaly detection is
studied by comparing the performance of four sampling
techniques. Weighted Round Sampling (WRS), determinis-
tic sampling, Simple Random Sampling (SRS) and chain-
sampling algorithms are evaluated. It has been shown that
WRS performs better than the other evaluated sampling
techniques. PRISM proposes a novel threat-aware sampling
scheme that distinguishes from the existing sampling tech-
niques by employing an attacker behavior model-based
ranking mechanism that uses the vulnerability and inter-
device reachability information to sample more trafﬁc from
the devices that are more likely to be compromised by the
attacker.

7 CONCLUSION

In this paper, we present PRISM, a hierarchical intrusion
detection architecture that can predict the progression of
complex multi-stage attacks in realtime by processing a
fraction of the total network trafﬁc. To achieve this, PRISM
employs an attacker behavior model-based threat-aware
sampling scheme and a distributed network trafﬁc moni-
toring mechanism. Due to its distributed structure, PRISM
experiences the challenge in alert order preservation that in-
troduces errors in the prediction process. PRISM addresses
this challenge by utilizing an efﬁcient alert stream man-
agement mechanism. Extensive experimentation has been
conducted to evaluate the performance of PRISM under
different conditions. It has been shown that PRISM reduces
the network trafﬁc processing overhead by up to 750% as
compared to a standard IDS while being able to predict

15

the attack progression accurately. PRISM also demonstrates
the ability to predict progression of an attack to advanced
stages as soon as the transitions unfold, providing the re-
sponse infrastructure additional margin to operate in a time
constrained environment. Furthermore, we have proposed
multiple security metrics that showcase a holistic security
outlook of the system to support intrusion response opera-
tions.

APPENDIX A
SEQUENCE RECOGNITION AND DECODING USING
HMMS
A.1 Forward Algorithm
Forward algorithm uses the forward variable ζt(i) =
P (o1, o2, .., oT , qt = si|λ) which is the probability of the
observation sequence O = {o1, o2, .., oT }, and state at time
t being si, given the model λ. Forward algorithm solves
for ζt(i) inductively, using the initialization, induction and
termination steps illustrated in Eqs. A.1, A.2 and A.3, re-
spectively [14], [25].

ζ1(i) = πibi(o1),

i ∈ [1, N ]

(A.1)

ζt+1(j) =

N
(cid:88)

i=1

ζt(i)aijbj(ot+1),

j ∈ [1, N ]

t ∈ [1, T − 1]

P (O|λ) =

N
(cid:88)

i=1

ζT (i)

(A.2)

(A.3)

A.2 Viterbi Algorithm

Viterbi algorithm takes a holistic approach in solving for the
most likely state sequence Q = {q1, q2, .., qT } corresponding
to the alert observation sequence O = {o1, o2, .., oT }. The
variable νt, expressed in Eq. A.4, navigates through the
solution [14], [25].

νt(i) = max

q1,q2,..,qt−1

P (q1, .., qt−1, o1, .., ot, qt = i|λ)

(A.4)

Where, νt(i) is the maximum probability for a single
state sequence accounting for t observations and si being
the last state in the state sequence. Using induction, Eq. A.5
can be derived.

νt+1(j) = max
i=1,..,N

νt(i)aijbj(ot+1)

(A.5)

To record the arguments that maximize Eq. A.5, the array
ξt is introduced. Viterbi algorithm begins by initializing νt
and ξt for t = 1, as shown in Eqs. A.6 and A.7.

ν1(i) = πibi(o1),

i ∈ [1, N ]

ξ1(i) = 0,

i ∈ [1, N ]

(A.6)

(A.7)

The algorithm then recursively solves for each time step
t = 2 to T and each state j = 1 to N , using Eqs. A.8 and
A.9.

νt(j) = max
i=1,..,N

νt−1(i)aijbj(ot),

t ∈ [2, T ], j ∈ [1, N ]

(A.8)

16

[18] OpenVAS - open vulnerability assessment scanner, [online]

https://www.openvas.org/.

[19] Nmap: the network mapper, [online]

https://nmap.org/.

[20] U. Srivastava, and J. Widom, ”Flexible time management in data
stream systems,” in Proc. ACM PODS 2004, Jun. 2004, pp. 263-274.

ξt(j) = argmax
i=1,..,N

νt−1(i)aij,

t ∈ [2, T ], j ∈ [1, N ]

(A.9)

Finally, the probability of the best score sequence is de-
termined using Eq. A.10 and the best path state is discovered
in Eq. A.11.

[21] MITRE ATT&CK, [online]

https://attack.mitre.org/.

[22] Splunk enterprise security, [online]

https://www.splunk.com/.

[23] ExtraHop, [online]

https://www.extrahop.com/.

[24] LogRhythm, [online]

https://logrhythm.com/.

P ∗ = max
i=1,..,N

νT (i)

q∗
T = argmax
i=1,..,N

νT (i)

(A.10)

(A.11)

Eq. A.12 ﬁnds out the best state sequence starting at the

best path state and backtracking in time by following ξt.

t = ξt+1(q∗
q∗

t+1),

t = T − 1, T − 2, .., 1

(A.12)

REFERENCES

[1] FireEye M-Trends 2020 report, [online]

https://content.ﬁreeye.com/m-trends/rpt-m-trends-2020.

[2] T. Lukaseder, ”Security in high-bandwidth networks,” Open Access

Repository of the University of Ulm, Dissertation, 2020.
http://dx.doi.org/10.18725/OPARU-33154

[3] G. Gilder, “TELECOSM: How inﬁnite bandwidth will revolutionize

our world,” Free Press, 2000.

[4] R. Sommer, and V. Paxson, ”Outside the closed world: On using
machine learning for network intrusion detection,” in Proc. IEEE
Symp. Secur. Priv., May 2010, pp. 305-316.

[5] Zeek cluster architecture, [online]

https://docs.zeek.org/en/current/cluster/index.html.

[6] Snort intrusion detection/prevention system, [online]

https://www.snort.org.

[7] Zeek network security monitor, [online]

https://www.zeek.org.

[8] J. Mai, C. Chuah, A. Sridharan, T. Ye, and H. Zang, ”Is sampled
data sufﬁcient for anomaly detection?,” in Proc. IMC’06: 6th ACM
SIGCOMM Conf. Internet Measurement, Oct. 2006, pp. 165-176.
[9] A. Shiravi, H. Shiravi, M. Tavallaee, and A. Ghorbani, ”Toward
developing a systematic approach to generate benchmark datasets
for intrusion detection,” Computers & Security, vol. 31, no. 3, pp.
357-374, 2012.

[10] E. Jonsson, and T. Olovsson, ”A quantitative model of the security
intrusion process on attacker behavior,” in IEEE Trans. Softw. Engg.,
vol. 23, no. 4, pp. 235-245, 1997.

[11] V. Mehta, C. Bartzis, H. Zhu, E. Clarke, and J. Wing, ”Ranking
attack graphs,” in Proc. Recent Adv. Intr. Det., 2006, pp. 127-144.
[12] R. Sawilla, and X. Ou, ”Identifying critical attack assets in depen-
dency attack graphs,” in Proc. Eur. Sym. Res. Comp. Sec., 2008, pp.
18-34.

[13] S. Brin, and L. Page, ”The anatomy of a large-scale hypertextual
Web search engine,” in Compt Net. and ISDN Sys., vol. 30, no. 1-7,
pp. 107-117, 1998.

[14] L. Rabiner, ”A tutorial on hidden markov models and selected
applications in speech recognition,” in Proc. of the IEEE, vol. 77, no.
2, pp. 257-286, 1989.

[15] T. Akidau, R. Bradshaw, C. Chambers, S. Chernyak, R. Fernandez-
Moctezuma, R. Lax, S. McVeety, D. Mills, F. Perry, E. Schmidt, and
S. Whittle, ”The dataﬂow model: a practical approach to balancing
correctness, latency, and cost in massive-scale, unbounded, out-of-
order data processing,” in Proc. VLDB Endowment, vol. 8, no. 12,
2015.

[16] Common vulnerability scoring system, [online]

https://www.ﬁrst.org/cvss/.

[17] Nessus network vulnerability scanner, [online]

https://www.tenable.com/products/nessus/.

[25] D. Jurasky, and J. Martin, ”Speech and language processing”,

Pearson Prentice Hall, 2009.

[26] T. Shawly, A. Elghariani, J. Kobes, and, A. Ghafoor, ”Architectures
for detecting interleaved multi-stage network attacks using hidden
Markov models,” IEEE Trans. Dep. Sec. Comp., 2019.

[27] N. Dufﬁeld, C. Lund, and M. Thorup, ”Properties and prediction
of ﬂow statistics from sampled packet streams,” in Proc. ACM
SIGCOMM IMW, Nov. 2002.

[28] Y. Javed, M. Felemban, T. Shawly, J. Kobes, and, A. Ghafoor, ”A
partition-driven integrated security architecture for cyberphysical
systems,” in IEEE Comp., vol. 53, no. 3, pp. 47-56, 2020.

[29] Z. Ahmad, A. Khan, C. Shiang, J. Abdullah, and F. Ahmad, ”Net-
work intrusion detection system: A systematic study of machine
learning and deep learning approaches,” Trans. Emerg. Tel. Tech.,
vol. 32, no. 1, Art. no. e4150, Oct. 2020.

[30] N. Chaabouni, M. Mosbah, A. Zemmari, C. Sauvignac, and P.
Faruki, ”Network Intrusion Detection for IoT Security Based on
Learning Techniques,” IEEE Comm. Surv. Tutor., vol. 21, no. 3, pp.
2671-2701, 2019.

[31] J. Li, D. Lim, and K. Sollins,”Dependency-based distributed intru-
sion detection,” in Proc. DETER community workshop on cyber secur.
experimentation and test, USENIX Association, 2007.

[32] C. Gruhl, F. Beer, H. Heck, B. Slick, U. Buehler, A. Wacker,
and S. Tomforde, ”A concept for intelligent collaborative network
intrusion detection,” in Proc. 30th Int. Conf. Arch. Comp. Sys., 2017,
pp. 1-8.

[33] Y. Xie, Y. Wang, H. He, Y. Xiang, S. Yu, and X. Liu, ”A general
framework for modeling and perceiving distributed network be-
havior,” IEEE/ACM Trans. on Netw., vol. 24, no. 5, pp. 3162-3176,
Oct. 2016.

[34] O. Alkadi, N. Moustafa, B. Turnbull, and K. Choo, ”A deep
blockchain framework-enabled collaborative intrusion detection for
protecting IoT and cloud networks,” IEEE Internet of Things Journal,
May 2020.

[35] M. Husak, J. Komarkova, E. Bou-Harb, and P. Celeda, ”Survey
of attack projection, prediction and forecasting in cyber security,”
IEEE Comm. Surv. and Tutor., vol. 21, no. 1, pp. 640-660, 2019.

[36] S. Cho, ”Incorporating soft computing techniques into a proba-
bilistic intrusion detection system,” IEEE Trans. Sys. Man. Cyber.,
vol. 32, no. 2, pp. 154-160, 2002.

[37] S. Joshi, and V. Phoha, ”Investigating hidden Markov models
capabilities in anomaly detection,” in Proc. ACM-SE 43: 43rd Annual
Southeast Region. Conf., Mar. 2005, pp. 98-103.

[38] G. Florez-Larrahondo, S. Bridges, and R. Vaughn, ”Efﬁcient mod-
eling of discrete events for anomaly detection using hidden Markov
models,” in Proc. ISC’05: 8th Intl. Conf. Info. Secur., Sept. 2005, pp.
506-514.

[39] D. Ariu, R. Tronci, and G. Giacinto, ”HMMPayl: An intrusion
detection system based on hidden Markov models,” Comp. & Secur.,
vol. 30, no. 4, pp. 221-241, 2011.

[40] N. Gornitz, M. Braun, and M. Kloft, ”Hidden Markov anomaly
detection,” in Proc. 32nd Intl. Conf. Mach. Learn., 2015, pp. 1833-1842.
[41] K. Haslum, M. Moe, and S. Knapskog, ”Real-time intrusion pre-
vention and security analysis of networks using HMMs,” in Proc.
2008 Intl. Conf. Local Comp. Netw., 2008.

[42] H. Farhadi, M. AmirHaeri, and, M. Khansari, ”Alert correlation
and prediction using data mining and HMM,” ISC Intl. J. Info.
Secur., vol. 2, no. 2, pp. 77-101, 2011.

[43] A. Sendi, M. Dagenais, M. Jabbarifar, and M. Couture ”Real time
intrusion prediction based on optimized alerts with hidden Markov
model,” J. Netw., vol. 7, no. 2, pp. 311-321, 2012.

17

[44] P. Halgodo, V. Villagra, and L. Vazquez, ”Real-time multistep attak
predeiction based on hidden Markov models,” IEEE Trans. Dep. Sec.
Comp., vol. 17, no. 1, pp. 134-147, 2017.

[45] T. Chadza, K. Kyriakopoulos, and S. Lambotharan, ”Learning to
learn sequential network attacks using hidden Markov models,”
IEEE Access, vol. 8, pp. 134480-134497, 2020.

[46] G. Androulidakis, V. Chatzigiannakis, and S. Papavassiliou, ”Net-
work anomaly detection and classiﬁcation via opportunistic sam-
pling,” IEEE Network, vol. 23, no. 1, pp. 6-12, 2009.

[47] K. Bartos, and M. Rehak, ”IFS: Intelligent ﬂow sampling for
network security-an adaptive approach,” Intl. J. Netw. Mgmt., vol.
25, pp. 263-282, 2015.

[48] L. Su, Y. Yao, N. Li, J. Liu, Z. Lu, and B. Liu, ”Hierarchical cluster-
ing based network trafﬁc data reduction for improving suspicious
ﬂow detection,” in Proc. 12th IEEE Intl. Conf. Big Data Sci. and Engg.,
Sept. 2018.

[49] R. Sibai, Y. Chabchoub, C. Jaoude, J. Demejian, and M. Togbe,
”Towards efﬁcient data sampling for temporal anomaly detection
in sensor networks,” in Proc. IEEE MENACOMM 2019, Nov. 2019.

Yahya Javed is a Ph.D. candidate at the Elmore Family School of
Electrical and Computer Engineering, Purdue University. His research
interests include security analytics, design of intelligent security informa-
tion and event management systems, and development of resilient en-
terprise systems by leveraging artiﬁcial intelligence-based techniques.

Mosab A. Khayat is an Assistant Professor in the Department of Com-
puter Engineering at Umm Al-Qura University, Makkah, Saudi Arabia.
His research interests include modeling and evaluation of visual an-
alytics systems, visualization, and machine learning. Khayat received
his Ph.D. from the Elmore Family School of Electrical and Computer
Engineering, Purdue University.

Ali A. Elghariani [S’12–M’14] received his B.S. and M.S. degrees in
electrical and electronic engineering from the University of Tripoli, Tripoli,
Libya. He obtained his Ph.D. degree in communications, networking,
and signal processing from the Elmore Family School of Electrical and
Computer Engineering, Purdue University, in 2014. Currently, he is a
research engineer at XCOM-Labs in San Diego, CA. He was a visiting
researcher at Purdue University in 2017-2019. He was a Lecturer at
the Department of Electrical and Electronic Engineering, University
of Tripoli, Tripoli, Libya in 2015-2016. His research interests include
network security modeling, signal detection and channel estimation in
large-scale MIMO systems, millimeter wave communication and opti-
mization techniques in wireless communications.

Arif Ghafoor is currently a professor in the Elmore Family School of
Electrical and Computer Engineering, Purdue University. His research
interests are in the areas of multimedia and database systems, and
cyber security. He has served on the Editorial Boards of several journals.

