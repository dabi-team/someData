A software-deﬁned architecture for control of IoT
Cyberphysical Systems

Ala’ Darabseh1 · Nikolaos M. Freris2

8
1
0
2

t
c
O
9

]
I

N
.
s
c
[

1
v
2
2
8
3
0
.
0
1
8
1
:
v
i
X
r
a

Abstract Based on software-deﬁned principles, we pro-
pose a holistic architecture for Cyberphysical Systems
(CPS) and Internet of Things (IoT) applications, and
highlight the merits pertaining to scalability, ﬂexibility,
robustness, interoperability, and cyber security. Our de-
sign especially capitalizes on the computational units
possessed by smart agents, which may be utilized for
decentralized control and in-network data processing.
We characterize the data ﬂow, communication ﬂow, and
control ﬂow that assimilate a set of components such
as sensors, actuators, controllers, and coordinators in
a systemic programmable fashion. We speciﬁcally aim
for distributed and decentralized decision-making by
spreading the control over several hierarchical layers. In
addition, we propose a middleware layer to encapsulate
units and services for time-critical operations in highly
dynamic environments. We further enlist a multitude of
vulnerabilities to cyberattacks, and integrate software-
deﬁned solutions for enabling resilience, detection and
recovery. In this purview, several controllers cooperate
to identify and respond to security threats and abnor-
mal situations in a self-adjusting manner. Last, we il-
lustrate numerical simulations in support of the virtues
of a software-deﬁned design for CPS and IoT.

Keywords Software Deﬁned Systems (SDSys) ·
Internet of Things (IoT) · Cyberphysical Systems
(CPS) · Distributed Systems · Decentralized Control ·
Cyber Security · Middleware

New York University Abu Dhabi, UAE, P.O Box: 129188 ·
Tel.: +971-262846491,+971-262848232
Fax: +971-26284000
E-mail: afd8@nyu.edu1, E-mail: nf47@nyu.edu2

Acknowledgment

This work was supported in part by the Center for Cy-
ber Security at New York University Abu Dhabi.

1 Introduction

The Internet of Things (IoT) [18] interconnects a huge
number of ‘smart’ devices (such as mobile phones, sen-
sors, routers, microcontrollers) alongside large data cen-
ters, and provides mechanisms for collection and pro-
cessing of big data, communication, as well as cloud ser-
vices. A closely related framework lies in Cyberphysical
Systems (CPS) [31,26], where smart agents that pos-
sess sensing, computation, communication, and control
capabilities are internetworked to control physical enti-
ties and processes. Prominent applications enlist Intel-
ligent Transportation Systems (ITS), smart grids, wire-
less sensor networks [14], smart buildings, and mobile
healthcare (mHealth).

At such large scale, existing control architectures
far exceed their capacity in eﬃciently administering the
conjugation of physical space with the cyberspace. No-
table challenges that have to be accounted for in IoT
and CPS applications feature the urge for adaptability,
scalability, security, safety, and robustness to abrupt
changes in the modus operandi of the network [31,28].
A key pathway is to design hybrid systems [2], in which
the software controls are decoupled from the embedded
components [29].

Software Deﬁned Systems (SDSys) come a system-
atic paradigm to design such systems by abstracting the
controls laws from the hardware devices at the physical
layer, and placing them in a software-deﬁned control
layer. Such decoupling is intended to provide reliable,
cost-eﬀective, and real-time control solutions for CPS

 
 
 
 
 
 
2

Ala’ Darabseh1, Nikolaos M. Freris2

and IoT. This concept extends and expands structured
development of large-scale software, and was ﬁrst intro-
duced within the context of cognitive radios [30]. Sub-
sequently, it has been used to develop Software Deﬁned
Networking (SDN) [22] as well as in several facets and
aspects of IoT [24,1,23].

In this paper, we utilize software deﬁned princi-
ples to propose a comprehensive architectural design
for CPS and IoT systems. The proposed architecture
speciﬁcally intends for decentralized decision-making
within the IoT, by leveraging the computational re-
sources that are ubiquitous within the many entities
it comprises. We specify how the proposed model re-
duces the control complexity and allows for ﬂexible in-
tegration and adaptation in the cyberspace. Our archi-
tecture entails three main domains: the physical space,
the cyberspace, and the structured control space, all
being SDSys-described. The hierarchical and decentral-
ized structure of the control space is carefully designed
in a way that assigns the responsibilities of each agent
within the IoT technology domain. The services of the
middleware layer
[27] of the proposed model are ab-
stracted and enhanced to pledge increased safety, reli-
ability and performance in a highly dynamic environ-
ment, primarily due to changes in the network topol-
ogy (mainly resulting from agent mobility and battery
drainage in portable devices). Moreover, we specify key
requirements and software-deﬁned solutions for achiev-
ing high quality-of-service (QoS) alongside cyber secu-
rity. To this end, we interplay both a bottom-up and
a top-bottom workﬂow for spreading information and
actuation throughout the network. In addition, we iden-
tify several classes of potential cyber attacks and vul-
nerabilities across the multiple levels, and propose eﬀec-
tive detection and recovery solutions. Finally, we have
built an object-oriented simulator in Python using fea-
tures and principles from general purpose SDSys simu-
lators such as Mininet, Maxinet and Mininet-WiFi, and
use it to test and evaluate several performance indica-
tors of our proposed modules.

This paper extends and expands our preliminary
studies in [6] in several directions: a) we provide a more
detailed description of several important attributes of
the architecture and solidify the connections with IoT
technology and ﬂedgling applications; b) we explicitly
discuss a software-deﬁned design for cyber security in
CPS and IoT applications; c) we devise an object-oriented
simulator and verify the merits of our approach via var-
ious simulations studies.

The remainder of the paper is structured as fol-
lows. We discuss the main design challenges pertinent
to CPS in Sec. 1.1, and recap the key concepts of Soft-
ware Deﬁned Systems (SDSys) in Sec. 1.2. Sec. 2 is

designated for the proposed software-deﬁned CPS ar-
chitecture (SDCPS): we expose the model requirements
(Sec. 2.1), the architectural overview (Sec. 2.2), the
main elements (Sec. 2.3), the control architecture (Sec.
2.4), the middleware layer (Sec. 2.5), the work-ﬂow (Sec.
2.6) and other important features (Sec. 2.7). We test as-
pects of our proposed solution in Sec. 3. Sec. 4 concludes
the paper.

1.1 Design challenges in CPS

In order for CPS to truly emerge as the fourth indus-
trial revolution they envisioned [31], various attributes
in modeling, communication, sensing, control, and cy-
ber security have to be attended to. We expose a brief
overview of the main challenges and design require-
ments in this fascinating domain [19]:

Large volumes of data: Sensors constitute an eﬀec-
tive bridge between the cyberspace and the physical
space. In large-scale CPS, such as transportation and
sensor networks [14], real-time sensing produces really
big data. It is indispensable to provide algorithms for
eﬃciently ﬁltering and mining big data [35,38] in the
real-time [15,33].

Scalability: The large number of devices in CPS that
come equipped with heterogeneous hardware and soft-
ware is a prior aspect to tackle in CPS [31]. It is integral
to administer the right APIs for oﬀ-the-shelf integra-
tion, and autonomous conﬁguration, accompanied with
new theories for scalable inference and control [39].

Real-Time Decisions: CPS operate subject to strin-
gent real-time constraints in communication, compu-
tation and control. It is therefore crucial to account
for deadlines in allocating resources and making de-
cisions [21], to develop algorithms for online comput-
ing [15,33], as well as software that can facilitate a
smooth operation in the real-time [27].

Security and Fault-Tolerance: The coupling between
the cyber and the physical spaces open the door for
many vulnerabilities to attacks and components fail-
ures. In the regime of CPS, there is a need for new
algorithms that relax the implicit assumption of be-
nign agents and fault-free operation, which can further
provide theoretical guarantees in the presence of malev-
olent or Byzantine users [3, 9, 16].

New Theories: In the light of overwhelming techno-
logical advances, arises the need for new theories [20,
13,14,26] that approach CPS from a fundamental theo-
retical viewpoint and outcome eﬃcient, low-complexity
algorithms with provable performance guarantees [35,
39].

A software-deﬁned architecture for control of IoT Cyberphysical Systems

3

To summarize, modeling and algorithmic tools from
system theory and software engineering associated with
abstraction, wireless networking, system veriﬁcation, con-
trol, and fault tolerance have to be invoked, but at the
same time revisited. To this end, distributed, decentral-
ized, and software-deﬁned solutions can set the stage for
building the engineering systems of the (not so remote)
future.

1.2 Software Deﬁned Systems (SDSys)

Software Deﬁned Systems (SDSys) aim to decouple the
physical space from the cyberspace by retracting con-
trols from the embedded hardware and abstracting them
into a software layer. There has been extensive work in
several contexts: Radios (SDR) [30], Networking (SDN)
[22], Security [4], Storage [5,7] and Cloud [23]. Software-
Deﬁned Networking (SDN) deﬁnes a new way to con-
trol the process of forwarding packets in a network.
In this context, open-source Python-based simulators
are available to evaluate the performance of SDN-based
protocols, such as Mininet [8], Mininet-WiFi [11], Max-
inet [36]. A software-deﬁned model for cloud manage-
ment which may eﬀectively mitigate several cyber-threats
was proposed in [23].

2 SDCPS : The proposed architecture for CPS

In this section, we illustrate our proposed architecture
for cyberphysical systems and IoT applications that
which builds upon software-deﬁned principles. The abun-
dant and ubiquitous communication and computation
power of smart devices is exploited to introduce a light-
weight, secure and reliable systemic control solution for
real-time management of IoT systems.

2.1 Model Requirements

We deﬁne a set of requirements and classify them in two
main categories: 1) quality-of-service (QoS) requirements,
and 2) security requirements.

QoS Requirements:

1. Resource Exploitation: Resources are plentiful in a
CPS. An eﬀective management mechanism is one
that maximizes the beneﬁts from exploiting as much
as possible the available computational, communi-
cation, sensing, and actuation amenities in a coher-
ent and concurrent manner.

2. Load Balancing: It is important to leverage resources
in a fair manner. Service requests should be handled
timely, while maintaining load balancing among the
various system controllers. A key objective of the
schedulers is to distribute the workload as evenly as
possible so as to alleviate network congestion, min-
imize delays, and avoid bottlenecks (in the sense
of communication or computation over-use) which
may drain the batteries of remote smart devices and
consequently drastically compromise system opera-
tion.

3. Real-time: Controlling physical entities such as cars,
sensors, smart grids and medicare operations im-
poses rigid real-time constraints. It is therefore im-
portant to deﬁne deadlines for the completion of
time-critical tasks and devise real-time schedulers [21,
27] that provably honor them.

Security Requirements:

Cyber security constitutes a chief concern in mod-
ern networked-control systems, where it is of vital im-
portance to design and implement eﬀective mechanisms
to prevent, detect and recover from a range of cyber-
attacks. This objective can be accommodated in multi-
ple complementary ways such as: a) encryption, which
yields both data privacy as well as security in packet-
based communication [16], b) control-based approaches
[10,9,32] that seek to identify attacks as well as to han-
dle ‘stealthy’ attacks (by assuring that undetectable at-
tacks may not harm the system operation), c) software-
based solutions, where diﬀerent tasks and entities are
dynamically assigned privileges by a dedicated security
unit in the system.

In CPS, attack strategies are constantly evolving.
Accordingly, the various tools for scanning, isolating,
and resolving threats have to be constantly updated to
meet their crucial mission. Several attack models apply
in the regime of CPS and IoT systems (see also [37]):

– Trojans: Trojans are executable program ﬁles in-
jected by malicious users into the Internet. The ef-
fects of a trojan are triggered when downloaded and
executed by a user. There are several types: Send-
ing Trojans, Remote-access Trojans, Proxy Trojans,
Denial-of-Service (DoS) Trojans and many others.
– DoS/DDoS attack: Denial-of-Service (DoS) refers to
the action of preventing a user from accessing sys-
tem resources. Distributed Denial-of-Service (DDoS)
is a type of DoS attack where multiple compromised
systems are used to target a single system by ren-
dering a subset of resources inaccessible to it.

– Packet Forging attack: This is also known as “packet

injection” and entails creating seemingly normal pack-
ets to interrupt direct communication between users.

4

Ala’ Darabseh1, Nikolaos M. Freris2

Consequently, “man-in-the-middle” attacks can be
launched, where an attacker secretly relays and pos-
sibly alters the messages between two parties under
the perception of directly communicating with each
other. There are several tools that an attacker can
use to generate such attacks, e.g., TCPinject and
packETH.

– Fingerprinting attack: An attacker eavesdrops the
conversation (even when encrypted) between two
users and obtains possession of some critical fea-
tures of the sender/receiver in order to identify the
network status and analyze traﬃc patterns with the
intention of deploying harmful actions.

– Application Layer attack: This genre is classiﬁed
into four types: the ﬁrst one uses the HTTP proto-
col requests to overwhelm a site, the second one re-
ﬂects threats to the SMTP protocol, the third one to
the FTP protocol and the last one concerns SNMP
attacks intending to monitoring and reconﬁguring
the system. Detecting such attacks is typically much
harder than the detection of attacks on the network
layer.

– User attacks: In this type of attack, a malicious user
seeks to trick the supervisor into obtaining the same
privileges as a legitimate user, e.g., by exploiting
vulnerabilities in a local machine to create an ac-
count inside it. There are diﬀerent forms of this at-
tack, such as U2R and R2L attacks.

Malevolent users exploit the heterogeneity of CPS
to launch attacks to all system components; this leads
to the additional taxonomy of attacks into:

1. Sensor-related attacks: An attacker tries to eaves-
drop or alter sensed data in order to compromise
the system operation.

2. Actuator-related attacks: An attacker seeks to change

the control commands of an actuator.

3. Controller-related attacks: Attacks to high-level decision-
making processes such as schedulers, dispatchers,
and middleware services.

4. Communication-related attacks: Communication chan-
nels are principal targets of attackers. There are
many ways to defend the channels, primarily based
on cryptography and coding.

Fig. 1 A ‘high-level’ overview of the proposed solution.

A. Physical space:

Physical entities that need to be managed and con-
trolled by IoT systems are enclosed in this space.
Take as an example a smart home that comprises
several devices like TVs, heating and AC, ovens,
wash machines, doors, and many more entities that
need to be controlled locally or remotely in an inter-
connected fashion. Another example is in Intelligent
Transportation Systems (ITS), where the physical
space comprises cars, traﬃc lights, sensors, etc. The
physical space is organized in domains and subdo-
mains which can interact with the cyberspace via
sensors, actuators, and dispatchers.

B. Cyber space: This space encapsulates hardware
and software designated for communication, sens-
ing and information gathering and processing. It in-
cludes heterogeneous sensors, actuators and access-
points. The quantity and quality of these devices
depend on the IoT application under consideration.
For instance, smart transportation systems may re-
quire more powerful processing units compared to
smart homes. A formidable attribute of the abstrac-
tion in SDCPS is that no matter the type or number
of devices or the application in place, the same con-
trol space can be installed and structured over the
cyberspace to manage the physical space.

2.2 SDCPS:“A High Level View”

In this section, we present our SDCPS system archi-
tecture and illustrate how its spaces and elements are
structured within IoT systems. A general, ‘high-level’
overview of the proposed software-deﬁned model for
CPS (SDCPS) is shown in Fig. 1. The main aspects
of the proposed architecture span three layers.

C. Control space: This is the heart of the proposed
architecture, where all decision-making processes are
initialized and taken. This space involves dispatch-
ers, schedulers, security controllers and coordina-
tors.

The distributed control layer is the key point be-
hind our proposed model, as illustrated in Fig. 2. The
physical space is structured into several zones and sub-

A software-deﬁned architecture for control of IoT Cyberphysical Systems

5

domains, where each one is controlled and managed by
a corresponding local controller. Local controllers com-
municate with one another to exchange information so
as to carry out collaborative decisions. In transporta-
tion systems, for example, a given city can be divided
into diﬀerent areas, each one controlled by a local traf-
ﬁc control center, where the local controllers of diﬀerent
areas communicate information and control actions so
as to improve experienced traﬃc conditions throughout
the metropolitan area.

Fig. 3 presents the building block for a multi-layer
composition in which diﬀerent sub-domains may be in-
tegrated into a vertical (i.e., hierarchical) or horizontal
(i.e., decentralized) fashion.

Fig. 2 Distributed software-deﬁned control layer.

Fig. 3 A partial sub-domain and its main components. The
bottom ﬁgure is borrowed by the WiSE Laboratory at JAIST.

2.3 Architectural Elements

We present the main architectural components and ele-
ments of SDCPS along with their roles, responsibilities
and interaction within IoT applications. To make an
analogy with control systems, we use the language of
linear1 dynamical systems:

x(i)(k + 1) = Aix(i)(k) + Biui(k)
y(i)(k) = Cix(i)(k) + Diui(k),

(1a)

(1b)

where x(i)(k), u(i)(k), y(i)(k) denote the state, measure-
ment, and control input for plant i at time k. We de-
note state-estimates (e.g., as obtained by Kalman ﬁl-
tering) by ˆx(i)(k). We further capture the communica-
tion network topology by an undirected1 graph G(k) :=
(V (k), E(k)) where two sub-systems i, j may communi-
cate at time k if and only if (i, j) ∈ E(k); the graph is
time-varying, in general, due to agent mobility as well
as the features of the wireless medium. For a node i, we
deﬁne its neighborhood Ni(k) := {j : (i, j) ∈ E(k)}.

Physical nodes

1. Mobile node: An entity with time-varying loca-
tion due to mobility (take for example vehicles in a
transportation network).

2. Cluster: The system can be partitioned into several
clusters consisting of multiple atoms (mobile nodes).
The set inclusion relation of each node to a cluster
varies over time, as mobile nodes may partake in
diﬀerent clusters, primarily based on their location.

Cyber nodes

1. Sensor: A sensor gathers information from its sur-
roundings as prescribed by its sensing range. The re-
sulting data is locally ﬁltered and forwarded to the
corresponding aggregate sensor. Each mobile node
may possess several sensors. This corresponds to an
entry (or subset of entries) of vector y.

2. Aggregate sensor: Each mobile node has one ag-
gregate sensor that summarizes the sensing infor-
mation gathered from on-board sensors. This is pre-
cisely what we have denoted as measurement vector
y.

3. Actuator: The information gathered is used by the
system (through external upper control layers) and
local controller to synthesize the control input of
the actuator, i.e., u. Decentralized actions amount
to determining individual entries of u(i) while dis-
tributed control laws describe strategies for synthe-
sizing u(i) from {ˆx(j)(k), u(j)(k)}j∈Ni.

1 We use deterministic linear time-invariant systems with
no loss in generality for simplicity of exposition. For the same
reason, we assume an undirected communication graph.

6

Ala’ Darabseh1, Nikolaos M. Freris2

4. Access point: Several sensors are linked to the sys-
tem via wireless communication access points.

Coordinators

1. Local coordinator: This controller is responsible
to take actions for a subset of neighboring nodes
by collecting data from the corresponding agents.
In the smart home example, we may organize the
home into several local areas, i.e., rooms, each one
managed by a local coordinator. In such case, sev-
eral decisions like turning on/oﬀ the light in a room
do not require any information from sensors in an-
other room.

2. Cluster Coordinator: Each cluster is assigned to
a coordinator that applies roles and actions to the
associated nodes within its sphere of inﬂuence. The
main roles are shaped to manage and control nodes,
transfer information from/to other cluster coordina-
tors, update the middleware (cf. Sec. 2.5) about the
state of its associated nodes, and obtain and execute
rules and instructions from upper layers through the
middleware. As an example in the smart home ap-
plication, several rooms are managed and controlled
by a cluster controller to maintain balanced power
supply among all of them.

3. Area coordinator: In the smart home application
this can be the ﬂoor coordinator, where several clus-
ters are managed and controlled by this coordinator.
This entity is a meta-controller which sets the rules
for distributed and decentralized strategies, e.g., se-
lecting from a subset of rules and privileges at each
decision instant (i.e., how to design the feedback
matrices {Ki} in our canonical example).
The coordinators can take actions based on acquired
information from several resources as shown in Fig. 4.

Fig. 4 Communication Flow (Information and Actuation)
through a coordinator; AP: access point.

Controllers

1. Self-Controller: Each mobile nod, such as a vehi-
cle in the transportation system, has an autonomous
controller which is called self-controller. It takes in-
formation from the aggregate sensors as input or,
in some cases, may take higher commands from the
local coordinator and controllers to launch a self-
control decision.
In our running example, self-controller may be an
autonomous feedback control law, i.e.,

u(i)(k) = Ki(k)ˆx(i)(k),

such as in maintaining a constant velocity of a given
vehicle, as determined by other coordinators and
controllers.

Fig. 5 Communication Flow (Information and Actuation)
through self-controller; AP: access point.

2. Local Controller: Local decisions that do not re-
quire permissions from upper-layer controllers are
taken by the local controller. Information that is
needed to take these decisions is acquired from ag-
gregate sensors in the mobile node itself or from the
ones in neighboring agents.
The distinction between the local coordinator and
local controller lies in that the coordinator may make
a decision related to more than one nodes (the co-
ordinator deﬁnes control policies that a controller is
responsible for enforcing).
In control terminology, the local controller is a local
feedback control of the form:

u(i)(k) =

(cid:88)

Kj(k)ˆx(j)(k).

j∈Ni∪i

3. Super-controller: It is to the local controller like
the local controller is to the self-controller. It en-
ables and supports the hierarchical decision-making
process from top to bottom, while information ﬂows
from bottom to top.

A software-deﬁned architecture for control of IoT Cyberphysical Systems

7

In our example, the super-controller designs the feed-
back gains in a tree-like dependence.

4. Global Controller: This constitutes the engine in
the proposed model, set in the root of the hierarchi-
cal model. All critical and high-level decisions are
established at this controller. It has a holistic view
of all remote nodes.

In the transportation system example, we may say
that diﬀerent parts of the car have their own controller
like steering, engine and lights, where all such parts are
controlled and managed by a local controller. The local
controllers of all cars within a speciﬁc zone are con-
trolled and managed by a super controller when there
is a need to enforce a decision on that area, e.g., for
collision avoidance purposes.

A set of design choices may be inferred to decide
the number of layers and the depth of controller lev-
els based on the speciﬁcs of the application under con-
sideration. In this aspect, trade-oﬀs are omnipresent:
responsiveness vs. load balancing vs. security vs. com-
plexity and so on. As an example, dividing the network
into several clusters implies that the upper controller is
responsible to control fewer lower level nodes. This may
speed up the transfer of decisions and load balancing,
but on the other hand it may increase the complexity of
control synthesis and the vulnerability to a number of
cyberattacks. Diﬀerent scenarios may exist, no choices
are absolute or clear in CPS, and everything has to be
studied as part of a common whole.

Interface: The Middleware

Higher and lower coordinators and controllers are
connected by a bridge, which is called the Middleware.
It is the software residence for schedulers, services, dis-
patchers and several software-deﬁned controllers.

The main challenge in designing the middleware lies
in maximizing scalability, adaptability and reliability.
Our proposed architecture borrows principles from the
Etherware [25], destined for network control due to its
real-time capabilities [27].

The Middleware is composed of two types of com-
ponents: controllers and services. The former is a set
of SD-controllers developed for control and coordina-
tion between the cyber and the physical, while the lat-
ter is responsible for managing the communication be-
tween the controllers and simplifying installation, de-
velopment and execution. For real-time services, a real-
time scheduler is a key component of the middleware:
packets and commands are assigned diﬀerent priorities
and execution deadlines that have to be accommodated
by means of scheduling with QoS guarantees [21]. A
more detailed description of the middleware layer will
be provided in Sec. 2.5.

Fig. 6 The components of software-deﬁned control and the
communication/actuation ﬂow among them; H: host.

Fig. 6 abbreviates the interactions and interconnec-

tions between system components.

2.4 Control architecture

In this section, we zoom in to discuss in further the units
and components of the proposed model; see Fig. 7.

Physical structure

The physical structure of each controller consists
of several processors, and each possessor is mapped to
multiple processing units. The controller can run sev-
eral processes simultaneously in a multi-threading fash-
ion. Moreover, CPUs and GPUs can be leveraged, and
one-pass controller is used, as it is typically faster and
simpler than its multi-pass counterpart, and it helps
improve reliability, security and system performance.
Pipes between producer/consumer threads are used as
safeguard communication channels for security purposes.

Fig. 7 The control architecture and its main units.

8

Logical structure

A set of dedicated software-deﬁned (sub-)controllers
are installed in each controller, which communicate and
collaborate with one other to maintain a smooth work-
ﬂow. Fig. 8 illustrates the logical view.

Each one comes equipped with several units which
we present and deﬁne in the following. Precisely, we
show how these units alongside their main responsibil-
ities work together to control and manage IoT applica-
tions in a software-deﬁned manner.

Fig. 8 The main controllers inside the SDCPS Controller.

SDN Controller: This controller is responsible to con-
trol and manage the networking part of the system. It
maintains network information for all nodes within its
range, which is used for forwarding-table generation.
These tables are forwarded to the switches that are con-
nected to this controller, for multi-hop communication
purposes. Diﬀerent algorithms can be followed to gener-
ate these tables like minimum spanning tree, shortest-
path, etc.), depending on the target of each IoT applica-
tion. For instance, in transportation systems, real-time
decisions have to be taken and for such situation, algo-
rithms that speciﬁcally target real-time scheduling will
be advantageous.

The main units inside SDN Controller are:

1. Path calculation unit: Calculating the path from
source to destination is the responsibility of this
unit. Such a path is taken based on several crite-
ria.

2. Forwarding table generation unit: All forward-
ing tables are generated inside this unit based on
the path calculation unit outcome. These tables are
generated and stored by this unit. It also gets feed-
back from the network status tracking unit to adjust
the calculated path when needed, as explained next.
3. Network status tracking unit: Any change (bot-
tlenecks, channel degradation or broken links) in the

Ala’ Darabseh1, Nikolaos M. Freris2

status of the network is tracked by this unit. For
instance, in a transportation network, when a new
road is built in a speciﬁc region this unit receives
a notiﬁcation about this update to take further ac-
tions.

Other units for enabling the joining and extraction

of nodes are also available.
SDIoT Controller:

All information about IoT application smart de-
vices is kept here. Information such as logical status
and physical location is used in the coordination and
management process.

1. Smart device information tracking unit: The
role of this unit is to scan and track the smart de-
vices for requests that have to be communicated to
the various controllers.

2. Smart device status tracking unit: This is re-
sponsible to track the status of a smart device as rel-
evant to communication and actuation (for example,
busy, sending, receiving, ‘asleep’ in duty-cycling, low
battery, etc.).

3. Smart device location tracking unit: As the
mobile nodes are moving, the physical location of
smart devices also varies. It is crucial to track the lo-
cation continually and accurately to enable location-
aware services and controls (such as set inclusion in
area coordinators, and distributed communication,
computation and control).

Smart device joining and extracting processes are also
the responsibility of this controller.

SDSecurity Controller:

The responsibility of keeping a secure system is as-
signed to this controller. It has a set of units with spe-
ciﬁc mechanisms and tools that are interconnected to
each other to detect, prevent and resolve several types
of cyberattacks.

1. Auditing and Mapping unit: It is important to
keep information about the switches, routers, ac-
cess points and other network nodes for security and
safety purposes. This unit takes the responsibility
for auditing all relevant information about the net-
work infrastructure nodes like its vendor, location,
and type, in order to discover all abnormal behav-
iors.

2. Knowledge-based unit: This unit is responsible
to store and keep all discovered attacks in the sys-
tem. In case a new attack is discovered, the inline
mechanisms and tools are used to determine the re-
quired solution, while this attack is stored in the
unit.

A software-deﬁned architecture for control of IoT Cyberphysical Systems

9

3. Scanning and Screening unit: It uses several
mechanisms and tools to scan traﬃc and detect if
there is a threat to trigger the resolution unit. Many
scanning tools are available, each one responsible to
scan a speciﬁc type of information.

4. Monitoring unit: The tools in this unit help net-
work defenders discover and analyze anomaly ac-
tivities in the network. For this purpose, there are
many visualization tools, and an unceasing need to
develop real-time monitoring methods.

5. Detection unit: This unit works with other con-
troller units to detect any type of cyberattacks. There
are a lot of existing tools for this purpose: MINDS,
ADAM, NIDS being notable examples.

6. Prevention unit: This tool is responsible to pre-
vent the attacks from inducing any anomalous ac-
tions and spreading them over other CPS domains.
7. Handling unit: The tools of this unit are respon-
sible to resolve and handle the attacks in case that
they cannot be prevented, or when the detection was
too late. It tries to eliminate and resolve its eﬀects
and then notify the knowledge-based unit for this
type of attack.

8. Policy unit: A set of security policies correlated to
CPS are sustained inside this unit. Dedicated poli-
cies for each IoT application are deﬁned and applied.
For example, in a smart home, the user can set poli-
cies to keep the room temperature no more than a
given threshold and increase it only in speciﬁc situ-
ations.

9. Security status tracking unit: This unit recaps
the status of the system as related to security.
10. Encryption/Decryption unit: Encrypting traf-
ﬁc is considered an eﬃcient way to protect packet-
based communication from intruders. This unit is
responsible for ascertaining data privacy by means
of applying encryption/decryption methods on the
data. Nonetheless, we note that encryption intro-
duces storage and time overheads (transmission and
processing) and cannot be used as a passepartout,
in particular for time-critical applications.

11. Backup unit: Keeping backup versions of the sys-
tem status facilitates its eﬀective protection. This
unit keeps frequent back-ups to restore the system
when the eﬀects of an attack cannot be resolved
otherwise.

12. Up-To-Date unit: It has a set of procedures to
update the existing software to tackle new attacks
with new solutions.

SDCompute Controller:

Network computation resources like CPUs, GPUs,
and RAMs are controlled and managed by this con-

troller. Dedicated tools for GPU, CPU and memory
managements are installed.

SDS Controller: This controller manages storage de-
vices and processes.

1. Data storing unit: This unit takes the responsi-
bility of controlling the data storing process in the
storage arrays.

2. Data caching unit: In large-scale CPS where the
hosts are distributed over a large area, it is im-
portant to cache parts of the most frequently re-
quested/used information locally [7].

3. Data de-duplication unit: In distributed database
systems, it is important to maintain concurrency of
information; this unit accounts for eliminating du-
plicate values so that any user gets access to the
most up-to-date available information.

Shared units by all types: Some commonplace units
that are available by almost any type of controller in-
clude:

1. I/O Unit: The input/output unit sends, receives
and forwards packets from and to other units.
2. Organizer Unit : This unit assigns priorities to
packets based upon predetermined QoS criteria.
3. Scheduling Unit: This unit schedules packet trans-
mission taking into account the assigned priority;
there is a great number of scheduling algorithms
that can be used for this purpose, see for exam-
ple [21].

4. Aggregate Unit: This unit is responsible for ag-
gregating packets of a given ﬂow before forwarding
them to the next processing unit.

SDCPS Controller: This controller comprises the main
engine of the system. It is responsible to eﬀectuate all
of the functionality described in the prequel and or-
ganize the interplay of the phyical and cyber space by
overlooking and coordinating all other controllers in the
system, either directly or indirectly.

2.5 Middleware Layer Architecture

The middleware layer is conﬁgured to accelerate real-
time decision making and facilitate the communication
and interactions between system control layers. All ser-
vices and entities are software-deﬁned, which empowers
the modiﬁcations and component migration processes
on-the-ﬂy. Fig. 9 shows the structure of the middleware
layer and its three spaces: controller space, kernel space,
and services space.

10

Ala’ Darabseh1, Nikolaos M. Freris2

3. Speed Stamp Service: Estimating and computing
mobile nodes’ speed is useful to predict its position
over time (e.g., by using tracking tools such Kalman
ﬁltering), for example to predict when a can car will
reach a speciﬁc route to avoid collision or deadlock.
4. Fault-Tolerance Service: For large-scale IoT sys-
tems fault-tolerance is crucial. A set of solutions and
policies are implemented inside this service to re-
cover from hardware/software failures (i.e., how to
switch to a nearby controller in case the local con-
troller fails).

5. Controller Registration Service: This service is
responsible to insert a new controller along with its
relevant information so as to keep the system up-
dated.

6. Time-stamping service: A dedicated unit is im-
plemented inside the middleware layer to record the
times of past, present and future events such as
sensed information and control actions.

7. Time-translation service: In a large-scale CPS,
clocks don’t agree [13] and it is fundamental to con-
vert packet’ time to controller’s time, and vice versa.
8. Time synchronization service: Accurate clock
synchronization is a instrumental for distributed co-
ordination in CPS. It aﬀects both performance as
well as safety [13], with examples enumerating wire-
less protocols such as MAC, duty-cycling, forma-
tion control, concurrency in databases, and more.
To this end, algorithms with high scalability, and
low communication and computation overhead are
especially important to implement in the middle-
ware [17,40,12].

9. Resource Tracking Service: This service targets
tracking the resources in the entire system with the
intention of providing load balancing and fairness
among users.

10. Emergency services: This set of services tracks
components and takes actions when they become
unavailable or fail.

2.6 Communication & Control Planes

The proposed architecture features an interplay between
two planes of communication and actuation, namely
horizontal and vertical. Fig. 10 illustrates a global view
of these planes, further elaborated in the sequel (note
that we use the transportation application for demon-
stration purposes, which explains the cars in Fig. 10).

1. Vertical Plane (Control Flow): As explicated
above, control ﬂows in the network in a hierarchical
fashion. At the very top level resides the root con-
troller, while all mobile nodes (such as vehicles in a

Fig. 9 The Middleware layer and its main components.

Controller Space: Each controller is implemented as
a component itself, and all components interact with
each other as explicated before.

Kernel Space: This space is responsible to schedule
packets based on their priority and time-criticality, as
assigned by the tools of the real-time controller. For in-
stance, a signal coming from an ambulance or ﬁretruck
should be served ﬁrst. A wealth of scheduling algo-
rithms [21] can be implemented. Each IoT application
has diﬀerent QoS requirements, and based on these re-
quirements the appropriate scheduling algorithm will
be selected.

Post scheduling decisions, a packet is assigned to a
speciﬁc queue based on its priority, but also the physi-
cal positions of the mobile sender/receiver. It is there-
fore essential to provide position tracking service for
location-aware real-time scheduling. Scheduling queues
in a network is well-studied [34], and extensions are pos-
sible for optimal scheduling subject to deadlines and
priorities [21].

Service Space: Various services are encapsulated in-
side this space to enable real-time decision making and
improve network communication:

1. Messenger Service: This service keeps a smooth
communication between all controllers at the same
layer through the west/east APIs in Fig. 3; take
for example controllers within the same ﬂoor in a
smart building. Additionally, it handles the commu-
nication between control layers located at diﬀerent
ﬂoors through SDN.

2. Position Tracking Service: The positions of mo-
bile nodes over time are tracked by this service. Note
that node position may be changed as a result of a
control decision (e.g., in a transportation system a
local controller routes a car at an intersection).

A software-deﬁned architecture for control of IoT Cyberphysical Systems

11

transportation system) reside at the low level. The
upper layer has coordination power over its imme-
diate lower layer, and higher privileges in resolving
conﬂicts. A middleware layer is responsible for com-
bining and coordinating the controllers at the same
layer and managing the communication across dif-
ferent layers. The number of layers at the vertical
plane is closely related to the size of the network at
the horizontal plane (e.g., it depends on the sizes of
the area clusters such as area dispatchers in urban
transportation).

2. Horizontal Plane (Data Flow): This plane re-
ﬂects the communication between mobile agents and
controllers within the same layer (for example direct
communication among nearby vehicles, and among
dispatchers at the same layer). Recall the trade-oﬀ
between the partition sizes and vertical plane depth:
when nodes are horizontally clustered to smaller
groups (areas), a larger number of cluster coordina-
tors and area coordinators is required; this aﬀects
the accuracy, responsiveness, performance and se-
curity of the entire system, as well as infrastructure
costs, that should all be considered by system de-
signers.

Fig. 10 The Horizontal and the Vertical control planes.

Decision Making Process

Decision making process is performed in a system-
atic way by the proposed system. Such rethinking pro-
motes the real-time decision making process, system re-
liability, security and scalability. A brief discussion on
control packet ﬂow is explained in the following.

2.6.1 Centralized vs. Decentralized / Distributed

An eﬀective control and management plane is a key to
system proliferation. Distributed control is integral for
handling huge network traﬃc volumes via decentralized
autonomy that achieves a scalable, sustainable, robust
and adaptable system operation in a highly dynamic
environment (take for example the failure of a traﬃc
light or closure of a route due to an accident or natural
disaster). However, “to distribute or not to distribute?”
does not always have an easy answer: local communi-
cation and interactions may cause a conﬂict through
several system levels, which require a supervisory con-
trol to solve it, whose complexity increases as the net-
work size is growing. The proposed architecture aims to
leverage the beneﬁts of both worlds (centralized and de-
centralized / distributed) in a coherent methodological
fashion.

2.6.2 Flow of control packets

The proposed methodological way of the decision mak-
ing process fundamentally inﬂuences the control packet
ﬂow. Information is harvested from underlying control
layers and is communicated to controllers in higher lay-
ers that take higher-level control decisions and actions.
Simultaneously, controllers in the underlying layers need
to collaborate and communicate with each other and
they are responsible to control all system entities as-
signed to them by taking the proper actions and for-
ward the information to super controllers at a higher
layer. All and all, this is treated diversely in diﬀerent
contexts: for instance, the auditing and screening secu-
rity unit within the SDSecurity controller, previously
described, is installed and implemented on all software-
deﬁned controllers, but does not perform the exact same
operations in each component. To conclude, decision-
making can be categorized ( among others ) to:

– Self decisions: A given node can take a decision by
itself without consolidating with other controllers or
coordinators at the same or higher levels.

– Coordinated decisions: Nodes are not fully autonomous
in taking a certain decision locally, and coordination
with higher layers is needed to take further actions.

This taxonomy applies inductively to all levels of
the decision-making hierarchy; cf. Fig. 11 illustrates the
work-ﬂow in the system.

12

Ala’ Darabseh1, Nikolaos M. Freris2

Fig. 11 The workﬂow diagram of processing control requests in the SDCPS framework.

Packet Structure: To support the proposed architec-
ture, it is also important to deﬁne the packet attributes
required for control, communication and scheduling; for
example agent-speciﬁc positioning and timing informa-
tion, packet priority and many others; cf. Fig. 12.

Fig. 12 The contents of a packet in SDCPS.

The setup of the system is exposed in Algorithm 1.

2.7 The features of the proposed model

The main features of the proposed architecture are brieﬂy
summarized in what follows:

1. Real-time: The proposed system architecture pro-
motes real-time decision making in three ways: (a)
adding a middleware layer to facilitate and scale
the communication and interaction between various
system layers, (b) implementing services and con-
trollers as self-components at the middleware, (c)
applying QoS-based packet scheduling over multi-
ple levels.

2. Reliability and Security: Service availability, in
the presence of malicious users, can be guaranteed
by prescribing ways of taking control actions and
accessing data. This can, in turn, be achieved by
sharing and distributing responsibilities over several
system modules, and employing redundancies that
improve resilience to single points of failure or at-
tack.

A software-deﬁned architecture for control of IoT Cyberphysical Systems

13

Algorithm 1 The setup algorithm for the proposed
model
1: procedure Setup
2:
3:
4:
5:
6:
7:
8:
9:

Start
STEP1: Run and initialize Global Controller.
ControllerLIST[]= None
SuperConLIST[]= None
LocalConLIST[]= None
AreaConLIST[]= None
STEP2: Create controller objects and initialize them.
ControllerLIST[] ← Create & Initialize list of con-

trollers.

Create instants from the SD Controller and

assign an ID for each one

for i = 0, i++,while i < length(instants)
Controller LIST[i] ← instant(i) ID

STEP3: Assign types for each controller and create

subsets.

SuperConLIST[] ⊆ ControllerLIST[]
LocalConLIST[] ⊆ ControllerLIST[]
AreaConLIST[] ⊆ ControllerLIST[]
STEP4: Global Controller partitions the system en-
vironment into sub-domains and assign all the controllers.
PartitionLIST[] ← Create & Initialize list of Parti-

tions.

Assign area controller for each partition
for i = 0, i++,while i < length(ContollerLIST )
PartitionLIST[i] ← AreaConLIST[i].

formation retrieval, and control to guarantee scala-
bility even for millions of mobile nodes.

3 Experimental results

In this section, we describe our emulation testbed and
expose several experimental ﬁndings to underline the
merits of adopting software-deﬁned control procedures
for IoT applications, in terms of eﬃciency and adapt-
ability.

3.1 Emulation Environment

Our testbed environment was implemented by installing
Mininet 2.2.0rc1 VM [8] over the Oracle Virtual Box
and remotely linking it with the Ubuntu OS. We used
Python as the programming language and extended the
POX controller of Mininet (namely User Switch) along
with its host main classes so as to capture several ele-
ments of the proposed architecture.

Assign “Area Controllers” to associated Local

3.2 Test Scenarios and Experiments

controllers

Assign “Local Controllers” to associated Super

controllers

Assign “Super Controllers” to Global controller
STEP5: Conﬁgure all software-deﬁned units inside

each controller.

for i = 0, i++,while i < length(ContollerLIST )

while ContollerLIST [i].units (cid:54)= Established do
SDN Unit ← Forwarding Table
SDIoT Unit ← Sensors Table
SDSecurity Unit ← Policies Table
SDStorage Unit ← Storage Table
SDC Unit ← Compute Table

end while
STEP6: Run the Controllers.
STEP7: Root Controller takes images from all con-

trollers and keep the state for each one.

for i = 0, i++,while i < length(ContollerLIST )

Image ← ContollerLIST[i].captureState
Root.Receive() ← Image

STEP8: Root Controller forwards all controller im-

ages to underlying controllers.

End

We have tested a range of scenarios for variable network
sizes and topologies. The network topology is captured
by a graph G = (V, E) consisting of n vertices (con-
trollers and end users), V = {v1, v2, . . . , vn}, with m
edges that prescribe the feasible communication among
the system entities. We have adopted a tree of depth
3 in our experiments: the global controller vertex v1
resides at the root, local controllers reside at the ﬁrst
level, switches (2 switches per local controller) reside
at the second level and hosts (users) lie at the third;
the number of users is taken variable. In all test cases,
we chose packet ﬂows where the source and destination
nodes are sampled uniformly at random.

We have studied four scenarios via altering a sub-
set of parameters in our model while ﬁxing others, as
illustrated in Table 1: “Requests” represents the total
number of served requests, “Controllers” refers to the
number of local controllers in our topology, “Users” is
the number of users for each switch, and “Time” de-
notes the accumulation of conﬁguration time and test
time.

10:

11:
12:
13:

14:
15:
16:
17:

18:

19:
20:
21:
22:
23:

24:

25:
26:

27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:

38:
39:
40:
41:

42:

3. Flexibility and Scalability: In volatile large-scale
CPS, high-frequency control and management is re-
quired as some nodes may undergo failure or cy-
ber attack. Such considerations can be served by
our proposed solution in a fast, simple and self-
conﬁgured programmable way. Moreover, our de-
sign combines decentralized distributed sensing, in-

Table 1 Experimental scenarios.

NO
Sc.1
Sc.2
Sc.3
Sc.4

Requests
10,000
10,000
Tested
Tested

Controllers
Changed
8
8
Changed

Users
8
Changed
8
Changed

Time
Tested
Tested
Changed
Tested

14

Ala’ Darabseh1, Nikolaos M. Freris2

network conﬁgurations for a ﬁxed total number of users
(which equals the product Number of Local Controllers
* Number of Switches per Local Controller * Number
of Hosts per Switch). Observe that 8 local controllers
with 8 hosts/switch serve a little bit more than 16 con-
trollers and 4 hosts with less amount of time. This re-
veals the beneﬁt of obtaining optimal performance with
minimum conﬁguration cost for balanced topologies.

Figure 13 demonstrates the eﬀect of varying the
number of local controllers and users on the conﬁg-
uration time for the ﬁrst two scenarios. We use blue
bars to show the required time for variable number of
controllers with the hosts per switch being ﬁxed to 8
(scenario 1). We use red bars to illustrate the time
needed for variable number of hosts per switch with a
ﬁxed number of 8 local controllers (scenario 2). It was
observed that increasing the number of controllers re-
quires more conﬁguration time compared to increasing
the number of users in the system for larger numbers,
whereas the opposite was observed for smaller num-
bers. Additionally, a balanced time was reported when
the number of controllers equals the number of hosts
per switch (both equal to 8).

Fig. 15 Number of requests served & test turation time over
variable network conﬁgurations (scenario 4).

4 Conclusions

We have proposed a software-deﬁned architecture for
Cyberphysical Systems and IoT applications. We have
speciﬁed the main requirements for diﬀerent IoT ap-
plications in terms of performance, security, quality-of-
service and real-time operation. We have demonstrated
how the proposed model exploits the computational
power of a great number of system components (co-
ordinators, controllers, sensors, and portable devices)
to control systems in a scalable and ﬂexible way while
prioritizing cyber security. All components are imple-
mented as software deﬁned nodes inside the middle-
ware layer, and control and information ﬂow in both
top-bottom and bottom-up fashions. Finally, we have
built a simulation testbed tool in Python to measure
the performance of the proposed model, and ran exten-
sive experiments that reveal the main beneﬁts of the
proposed model.

References

1. Al-Ayyoub, M., Jararweh, Y., Benkhelifa, E., Vouk, M.,
Rindos, A., et al.: A novel framework for software de-
ﬁned based secure storage systems. Simulation Modelling
Practice and Theory (2016)

2. Alur, R., Courcoubetis, C., Halbwachs, N., Henzinger,
T.A., Ho, P.H., Nicollin, X., Olivero, A., Sifakis, J.,
Yovine, S.: The algorithmic analysis of hybrid systems.
Theoretical Computer Science 138(1), 3–34 (1995)

Fig. 13 Conﬁguration time for variable network size (sce-
narios 1&2).

Figure 14 shows the total number of requests served
by our system for 8 local controllers and 8 hosts-per
switch over several time periods. It is noted that, by
design, the system gives an equally likely execution time
for each packet across several time periods so that the
number of requests served increases linearly with time.

Fig. 14 Number of requests served over simulation time (sce-
nario 3).

Figure 15 illustrates the total number of served re-
quests and simulation test time across three diﬀerent

A software-deﬁned architecture for control of IoT Cyberphysical Systems

15

3. Cardenas, A.A., Amin, S., Sastry, S.: Secure control: To-
wards survivable cyber-physical systems. In: 28th IEEE
International Conference on Distributed Computing Sys-
tems Workshops (ICDCS), pp. 495–500 (2008)

4. Darabseh, A., Al-Ayyoub, M., Jararweh, Y., Benkhelifa,
E., Vouk, M., Rindos, A.: SDSecurity: A software deﬁned
security experimental framework. In: IEEE International
Conference on Communication Workshop (ICCW), pp.
1871–1876 (2015)

5. Darabseh, A., Al-Ayyoub, M., Jararweh, Y., Benkhelifa,
E., Vouk, M., Rindos, A.: SDStorage: A software deﬁned
storage experimental framework. In: IEEE International
Conference on Cloud Engineering (IC2E), pp. 341–346
(2015)

6. Darabseh, A., Freris, N.: A software deﬁned architecture
for cyberphysical systems.
In: 4th IEEE International
Conference on Software Deﬁned Systems (SDS), pp. 54–
60 (2017)

7. Darabseh, A., Freris, N., Jararweh, Y., Al-Ayyoub, M.:
SDCache: Software deﬁned data caching control for cloud
services. In: 4th IEEE International Conference on Fu-
ture Internet of Things and Cloud (FiCloud) (2016)
8. De Oliveira, R., Shinoda, A., Schweitzer, C., Ro-
drigues Prete, L.: Using Mininet for emulation and pro-
totyping software-deﬁned networks. In: IEEE Colombian
Conference on Communications and Computing (COL-
COM), pp. 1–6 (2014)

9. Duan, X., Freris, N., Cheng, P.: Secure clock synchro-
nization under collusion attacks. In: Proceedings of the
54th Allerton Conference on Communication, Control
and Computing, pp. 1142–1148 (2016)

10. Fawzi, H., Tabuada, P., Diggavi, S.: Secure estimation
and control for cyber-physical systems under adversarial
attacks. IEEE Transactions on Automatic Control 59(6),
1454–1467 (2014)

11. Fontes, R.R., Afzal, S., Brito, S.H., Santos, M.A.,
Rothenberg, C.E.: Mininet-WiFi: Emulating software-
deﬁned wireless networks.
In: 11th International Con-
ference on Network and Service Management (CNSM),
pp. 384–389 (2015)

12. Freris, N., Borkar, V., Kumar, P.R.: A model-based ap-
proach to clock synchronization. In: Proceedings of the
48th IEEE Conference on Decision and Control (CDC),
pp. 5744–5749 (2009)

13. Freris, N., Graham, S., Kumar, P.R.: Fundamental limits
IEEE Transac-

on synchronizing clocks over networks.
tions on Automatic Control 56(6), 1352–1364 (2011)
14. Freris, N., Kowshik, H., Kumar, P.R.: Fundamentals of
Large Sensor Networks: Connectivity, Capacity, Clocks,
and Computation. Proceedings of the IEEE 98(11),
1828–1846 (2010)

15. Freris, N., ¨O¸cal, O., Vetterli, M.: Compressed Sensing
of Streaming data. In: Proceedings of the 51st Allerton
Conference on Communication, Control and Computing,
pp. 1242–1249 (2013)

16. Freris, N., Patrinos, P.: Distributed computing over en-
crypted data. In: Proceedings of the 54th Allerton Con-
ference on Communication, Control and Computing, pp.
1116–1122 (2016)

17. Freris, N., Zouzias, A.: Fast distributed smoothing of rela-
tive measurements. In: 51st IEEE Conference on Decision
and Control (CDC), pp. 1411–1416 (2012)

18. Gubbi, J., Buyya, R., Marusic, S., Palaniswami, M.: In-
ternet of Things (IoT): A vision, architectural elements,
and future directions. Future Generation Computer Sys-
tems 29(7), 1645–1660 (2013)

19. Gungor, V.C., Hancke, G.P.: Industrial wireless sensor
networks: Challenges, design principles, and technical ap-
proaches.
IEEE Transactions on Industrial Electronics
56(10), 4258–4265 (2009)

20. Gupta, P., Kumar, P.R.: The capacity of wireless net-
works. IEEE Transactions on information theory 46(2),
388–404 (2000)

21. Hou, I.H., Borkar, V., Kumar, P.R.: A theory of QoS for
wireless. In: IEEE INFOCOM, pp. 486–494 (2009)
22. Jain, R., Paul, S.: Network virtualization and software
deﬁned networking for cloud computing: a survey. IEEE
Communications Magazine 51(11), 24–31 (2013)

23. Jararweh, Y., Al-Ayyoub, M., Darabseh, A., Benkhelifa,
E., Rindos, A.: Software deﬁned cloud: Survey, system
and evaluation. Future Generation Computer Systems
58, 56–74 (2016)

24. Jararweh, Y., Al-Ayyoub, M., Darabseh, A., Benkhelifa,
E., Vouk, M., Rindos, A.: SDIoT: a software deﬁned
based internet of things framework. Journal of Ambi-
ent Intelligence and Humanized Computing 6(4), 453–
461 (2015)

25. Kim, K.D., Kumar, P.R.: Architecture and mechanism
design for real-time and fault-tolerant etherware for net-
worked control. In: Proceeding of the 17th IFAC World
Congress, pp. 9421–9426 (2008)

26. Kim, K.D., Kumar, P.R.: Cyber–physical systems: A per-
spective at the centennial. Proceedings of the IEEE
100(Special Centennial Issue), 1287–1308 (2012)

27. Kim, K.D., Kumar, P.R.: Real-time middleware for net-
worked control systems and application to an unstable
system. IEEE Transactions on Control Systems Technol-
ogy 21(5), 1898–1906 (2013)

28. Lee, E.A.: Cyber physical systems: Design challenges.
In: 11th IEEE International Symposium on Object and
Component-Oriented Real-Time Distributed Computing
(ISORC), pp. 363–369 (2008)

29. Lee, E.A., Seshia, S.A.: Introduction to embedded sys-
tems: A cyber-physical systems approach. MIT Press
(2011)

30. Mitola, J.: Cognitive radio—an integrated agent archi-
tecture for software deﬁned radio. Ph.D. thesis, Royal
Institute of Technology (KTH) (2000)

31. Rajkumar, R.R., Lee, I., Sha, L., Stankovic, J.: Cyber-
physical systems: the next computing revolution. In: Pro-
ceedings of the 47th Design Automation Conference, pp.
731–736 (2010)

32. Satchidanandan, B., Kumar, P.R.: Dynamic watermark-
ing: Active defense of networked cyber–physical systems.
Proceedings of the IEEE 105(2), 219–240 (2017)

33. Sopasakis, P., Freris, N., Patrinos, P.: Accelerated re-
construction of a compressively sampled data stream.
In: 24th European Signal Processing Conference (EU-
SIPCO) (2016)

34. Srikant, R., Ying, L.: Communication networks: an op-
timization, control, and stochastic networks perspective.
Cambridge University Press (2013)

35. Vlachos, M., Freris, N., Kyrillidis, A.: Compressive min-
ing: fast and optimal data mining in the compressed do-
main. The VLDB Journal 24(1), 1–24 (2014)

36. Wette, P., Draxler, M., Schwabe, A., Wallaschek, F.,
Zahraee, M., Karl, H.: Maxinet: Distributed emulation
of software-deﬁned networks. In: IFIP Networking Con-
ference, pp. 1–9 (2014)

37. Yampolskiy, M., Horvath, P., Koutsoukos, X.D., Xue,
Y., Sztipanovits, J.: Taxonomy for description of cross-
domain attacks on CPS. In: Proceedings of the 2nd ACM
International Conference on high conﬁdence networked
systems, pp. 135–142 (2013)

16

Ala’ Darabseh1, Nikolaos M. Freris2

38. Zoumpoulis, S., Vlachos, M., Freris, N., Lucchese, C.:
Right-protected data publishing with provable distance-
based mining.
IEEE Transactions on Knowledge and
Data Engineering 26(8), 2014–2028 (2014)

39. Zouzias, A., Freris, N.: Randomized Extended Kaczmarz
for solving least squares. SIAM Journal on Matrix Anal-
ysis and Applications 34(2), 773–793 (2013)

40. Zouzias, A., Freris, N.: Randomized gossip algorithms
for solving Laplacian systems.
In: Proceedings of the
14th European Control Conference (ECC), pp. 1920–
1925 (2015)

