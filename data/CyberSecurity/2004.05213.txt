Deceptive Labeling: Hypergames on Graphs for Stealthy Deception

Abhishek N. Kulkarni, Huan Luo, Nandi O. Leslie, Charles A. Kamhoua, and Jie Fu

0
2
0
2

n
u
J

9

]
T
G
.
s
c
[

2
v
3
1
2
5
0
.
4
0
0
2
:
v
i
X
r
a

Abstract— With the increasing sophistication of attacks on
cyber-physical systems, deception has emerged as an effective
tool to improve system security and safety by obfuscating the
attacker’s perception. In this paper, we present a solution to the
deceptive game in which a control agent is to satisfy a Boolean
objective speciﬁed by a co-safe temporal logic formula in the
presence of an adversary. The agent intentionally introduces
asymmetric information to create payoff misperception, which
manifests as the misperception of the labeling function in
the game model. Thus, the adversary is unable to accurately
determine which logical formula is satisﬁed by a given outcome
of the game. We introduce a model called hypergame on
graph to capture the asymmetrical information with one-sided
payoff misperception. Based on this model, we present the
solution of such a hypergame and use the solution to synthesize
stealthy deceptive strategies. Speciﬁcally, deceptive sure winning
and deceptive almost-sure winning strategies are developed by
reducing the hypergame to a two-player game and one-player
stochastic game with reachability objectives. A running example
is introduced to demonstrate the game model and the solution
concept used for strategy synthesis.

Index Terms— Formal methods-based control; Linear Tem-

poral logic; games on graphs; hypergame theory.

I. INTRODUCTION

With the increasing sophistication of the attacks on cyber-
physical systems, deception has emerged as a tool to mitigate
the strategic and informational disadvantages of the defender.
In this paper, we consider a class of games where a control
agent (P1, pronoun ‘he’) plays against its adversary (P2,
pronoun ‘she’) to satisfy a temporal logic formula, which
describes high-level constraints such as safety, reachability,
liveness, and reactivity [1]. However, the task cannot be
achieved if the adversary knows the exact game. Thus,
the agent needs to falsify or obfuscate information to the
adversary in order to satisfy its temporal logic speciﬁcation.
The question arises, how to synthesize provably correct and
deceptive strategies that exploits the information advantages?
The class of games where players’ payoffs are Boolean
valued (1 for satisfying the formula and 0 otherwise) is
known as games on graphs (or ω-regular games). The so-
lution concepts of the games on graphs have been studied in
formal synthesis of reactive systems [2]–[4] and supervisory
control [5]. However, existing work [3], [4] assumes both
players have access to the correct model of the game. This is

A. Kulkarni and J. Fu are with the Robotics Engineering Program and
Dept. of Electrical and Computer Engineering, Worcester Polytechnic Insti-
tute, Worcester, MA 01609 USA. {ankulkarni,jfu2}@wpi.edu
H. Luo is a visiting student with Dr. Fu at the WPI from Sept to Nov,

2019. hluo12@126.com
C.

Leslie

and
N.
Research
Laboratory.
charles.a.kamhoua.civ}@mail.mil

Kamhoua

are

Army
{nandi.o.leslie.ctr,

U.S.

with

not the case when one player (deceiver, P1) can provide mis-
leading information or intentionally hide information to the
other for strategic advantages. In this paper, we study a class
of asymmetric information games in which P1 has complete
information about the game, but he intentionally falsiﬁes
or obfuscates P2’s perception of one game component–the
labeling function, which maps an outcome (sequence of
game states) to a Boolean payoff of one if the temporal
logic formula was satisﬁed or zero otherwise. Such deception
techniques are commonly used in decoy-based cybersecurity
(such as honey-X) and defense (such as camouﬂage) [6], [7].
To synthesize deceptive strategies for P1, we model the
interaction between the two players as a hypergame [8].
A hypergame models the situation where the players have
different perceptions of their interaction given their infor-
mation, and higher-order information (information about
other’s information). We extend the normal-form hypergame
model to deﬁne the hypergame on graph model to capture
the perceptual games of the players and their knowledge
about the opponent’s perceptual game. To solve for P1’s
deceptive strategies, we adopt the solution concept of subjec-
tive rationalizability [9] from incomplete information game
theory. A subjective rationalizable player behaves rationally
and assumes the other player to act rationally in his/her
subjective view of the game. Thus, whenever P1 deviates
from his rational strategy in P2’s subjective view, we expect
P2 to become aware of the information asymmetry. Using
this observation, we establish the necessary and sufﬁcient
conditions for the deceptive strategies to be (a) stealthy sure
winning, and (b) stealthy almost-sure winning (i.e., winning
with probability one). A stealthy strategy ensures that P2
does not become aware of the information asymmetry until
P1 can ensure to satisfy the temporal logic speciﬁcation
irrespective of P2’s actions. These solution concepts for
hypergames on graphs not only provide the provably-correct
deceptive strategies for P1 but also provide a way to assess
the effectiveness of deception and its potential limitations.

Related Work: Game theory for deception has been
investigated extensively using the two models of incomplete
information games: hypergames [8], [10], [11] and Bayesian
games [12], [13]. Hypergames were initially proposed and
studied for the normal-form one-shot games [8], [10] and
later studied by Gharesifard and Cort´es [14], [15] for re-
peated games. Gharesifard and Cort´es developed an H-
digraph model to monitor how a player’s perception evolves
during repeated interactions and to design stealthy deceptive
strategy in which the deceiver’s action does not contradict
the perception of the mark. Bayesian games [16] are used
to design deceptive strategies in cybersecurity applications

 
 
 
 
 
 
[12], [13], [17]. Dynamic Bayesian games are used in [13]
for active deception in cybernetwork, where the defender
has incomplete information about the type of the attacker
(legitimate user or adversary) and the attacker also is uncer-
tain about the type of the defender (high-security awareness
or low-security awareness). Ornkar et al. [17] formulate a
security game (Stackelberg game) to allocate limited decoy
resources in a cybernetwork to mask network conﬁgurations
from the attacker. Existing deception in games describes
players’ payoffs using rewards/costs. We choose to adopt
the hypergame model over Bayesian games because the
hypergame model facilitates the analysis of higher-order
information. We also employ the subjective rationalizability
solution concepts in hypergames [18].

II. PRELIMINARIES

We begin with a brief overview of ω-regular games [2].
An ω-regular game, hereafter referred to as a game, is a tuple
G = hG, ϕi which consists of a game arena G, representing
the dynamics of the interaction between P1 and P2, and a
Linear Temporal Logic (LTL) speciﬁcation ϕ for P1. In this
work, we consider turn-based, deterministic game arenas and
syntactically co-safe LTL speciﬁcations. We formalize these
concepts below.

Game Arena: A turn-based, deterministic game arena
is a tuple G = hS, A, T, s0, AP, Li where S = S1 ∪ S2 is a
ﬁnite set of states partitioned into P1’s states, S1, and P2’s
states, S2; A = A1 ∪ A2 is the set of actions where A1
and A2 are the sets of actions for P1 and P2, respectively;
T : (S1 × A1) ∪ (S2 × A2) → S is a deterministic transition
function that maps a state-action pair to a next state. If there
exists a state s′ ∈ S such that T (s, a) = s′, then we say that
action a is enabled at s; s0 ∈ S is called the initial state
of G; AP is the set of atomic propositions; L : S → 2AP
is the labeling function that maps a state s ∈ S to a subset
L(s) ⊆ AP of propositions which evaluate ‘true’ at s.

A path ρ = s0s1 . . . in G is a sequence of states such that
for any i ≥ 0, there exists a ∈ A for which T (si, a) = si+1.
A path ρ can be mapped to a word over 2AP by using a
labeling function w = L(ρ) = L(s0)L(s1) . . ., which can be
evaluated against logical formulas.

Payoffs in Linear Temporal Logic: Given the set of
atomic propositions, AP, an LTL formula is inductively
deﬁned as:

ϕ := ⊤ | ⊥ | p | ϕ | ¬ϕ | ϕ ∧ ϕ | (cid:13)ϕ | ϕ U ϕ,

where ⊤, ⊥ are universally true and false, respectively, p ∈
AP is an atomic proposition, (cid:13) is a temporal operator called
the “next” operator. U is a temporal operator called the
“until” operator. For details about the syntax and semantics
of LTL, readers are referred to [1].

In this work, we restrict the objectives of P1 to a subclass
of LTL called syntactically co-safe LTL (scLTL) [19]. An
scLTL formula ϕ is equivalently expressed as a Deterministic
Finite-State Automaton (DFA), deﬁned by a tuple A =
hQ, Σ, δ, ι, F i which consists of a ﬁnite set Q of states; a
ﬁnite set of symbols Σ = 2AP ; a deterministic transition

function δ : Q × Σ → Q; an unique initial state ι ∈ Q; and a
set F of ﬁnal states. We extend the transition function over
words u ∈ Σω to write δ(q, uw) = δ(δ(q, u), w). A word w
is accepted by A if and only if there exists a ﬁnite preﬁx u
such that w = uv for some v ∈ Σω, and δ(q, u) ∈ F . Given
a path ρ in G, we say ρ satisﬁes ϕ over G, if and only if
L(ρ) is accepted by the DFA A.

Zero-sum Game on a Graph: Given a game arena G
and the scLTL speciﬁcation ϕ of P1, a zero-sum game on a
graph is a tuple, G = (G, ϕ). For a path ρ ∈ Sω in G, if the
labeling L(ρ) satisﬁes ϕ, then the path is winning for P1.
Otherwise, it is winning for P2.

Next, we construct a product game for solving the zero-
sum game G–that is, determining from the initial state s0,
whether a player can enforce a path winning for him,
regardless of the actions of the other player.

Deﬁnition 1 (Product game). Given an arena G =
hS, A, T, s0, AP, Li and a DFA A = hQ, Σ, δ, ι, F i equiva-
lent to the LTL speciﬁcation of P1 ϕ, the product game is a
tuple G ⊗ A = hS × Q, A, ∆, (s0, q0), S × F i, where S × Q
is a set of states partitioned into P1’s states S1 × Q and P2’s
states S2×Q; ∆ : (S1×Q×A1)∪(S2×Q×A2) → S×Q is a
deterministic transition function that maps a game state (s, q)
and an action a to a next state (s′, q′) where s′ = T (s, a) and
q′ = δ(q, L(s′)); (s0, q0) ∈ S × Q where q0 = δ(ι, L(s0))
is the initial state of the product game; S × F ⊆ S × Q is a
set of ﬁnal states.

We slightly abuse the notation to denote the product game
graph as G := G⊗ A. A path ρ = (s0, q0), (s1, q1), . . . in the
product game G is a sequence of states in G. By deﬁnition of
this product game, the project of ρ onto S, s0s1 . . ., is a path
in G and satisﬁes ϕ if and only if there exists (si, qi) ∈ ρ
for some i ≥ 0 such that (si, qi) ∈ S × F .

Thus, P1 can win (or ensure a run to satisfy ϕ) by reaching
the set S × F in the product game. P2 can win by always
avoiding S × F . Thus, the product game is a reachability
game for P1 and a safety game for P2.

is a function πi

In the product game, a randomized, memoryless1 strategy
for player i, for i ∈ {1, 2},
: Si ×
Q → D(Ai), where D(Ai) is the set of discrete probability
distributions over Ai. A deterministic strategy πi : S × Q →
Ai maps a state (s, q) to an action. We say that player i
commits to a strategy πi if and only if for a given state
(s, q), if πi(s, q) is deﬁned, then an action is sampled from
the distribution πi(s, q) (or the action πi(s, q) is taken if
πi is deterministic), otherwise, player i selects an action at
random. Let Πi be the set of strategies of player i. A strategy
π1 ∈ Π1 is said to sure winning at a state (s, q) ∈ S × Q
if, for any π2 ∈ Π2, P1 is guaranteed to satisfy ϕ within
0 ≤ k < ∞ steps for a determined upper bound k on the
number of steps. A strategy π1 ∈ Π1 is said to almost-sure
winning at a state (s, q) ∈ S × Q if, for any π2 ∈ Π2,
P1 is guaranteed to satisfy ϕ with probability one, i.e., P1

1A memoryless strategy in G is a ﬁnite memory strategy in G, where the

memory is represented by states in DFA A.

might require unbounded number of steps to satisfy ϕ. A
pair hπ1, π2i of strategies is a strategy proﬁle.

The games in Def. 1 are determined [20], [21]: From
any state (s, q) ∈ S × Q exactly one of P1 and P2 has a
memoryless sure winning strategy. This result allows us to
partition the game state space as S × Q = Win1 ∪ Win2.
Here, Win1 includes all the states from which P1 has a sure
winning strategy and Win2 includes all the states from which
P2 has a sure winning strategy. Readers are referred to [21]
and Chapter 2 of [2] for the details of the game solution.

III. GAME ON GRAPH WITH LABELING MISPERCEPTION

In security and defense applications, players often have
incomplete asymmetric information about
the game. For
instance, in a decoy-based deceptive defense approach, only
the defender knows which hosts are decoys but the attacker
does not. Such situations can be understood as the attacker
‘misperceives’ the labels of states in the game. We introduce
a hypergame model to analyze the effect of P2 misperceiving
the true labeling function and how P1 can leverage P2’s
misperception to synthesize deceptive strategies.

A. Hypergame Model
Deﬁnition 2 (Hypergame [8]). A level-1 two-player hyper-
game is a pair HG1 = hG1, G2i, where G1, G2 are games
perceived by players P1 and P2, respectively. A level-2 two-
player hypergame is a pair HG2 = hHG1, G2i, where P1
perceives the interaction as a level-1 hypergame and P2
perceives the interaction as game G2. The ﬁrst component
of a hypergame is called perceptual game of P1; and the
second component is called perceptual game of P2.

While it is possible to deﬁne a level-k hypergame (see
[10]), we note that a level-2 hypergame is sufﬁcient to model
the game with asymmetric information, since P1 knows HG1
and P2 is only aware of G2.
Information Structure In this paper, we are interested in
games with asymmetric information of labeling function.
Speciﬁcally, both P1 and P2 know the following components
S, A, s0, T of the arena G, and P1’s objective ϕ. However,
P1 has complete information about the labeling function,
L1(s) = L(s) for all s ∈ S, and P2 has misperception: There
exists at least one state s ∈ S, L2(s) 6= L(s). Moreover, P1
is aware of P2’s perceived labeling function L2.

This information structure captures decoy-based deception
and camouﬂage. For example, the attacker misperceives a
honeypot to be a regular host and the defender is aware of
the attacker’s misperception.

Deﬁnition 3 (Level-2 Hypergame with Labeling Mispercep-
tion). Given the information structure and the perceptual
games, G1 = hG1, ϕi with G1 = hS, A, T, s0, AP, L1i
and G2 = hG2, ϕi with G2 = hS, A, T, s0, AP, L2i, the
interaction between P1 and P2 is a level-2 hypergame HG2 =
hHG1, G2i, where HG1 = hG1, G2i is the level-1 hypergame.

represent the winning region of P1 (resp., P2) in Gk. From the
winning regions, the winning strategies can be extracted by
construction (See Chapter 2 of [2] for details). To illustrate
the solution, we introduce a running example.

Example 1. In the game arena, G, (see Fig. 1), we have two
players: P1 (circle) and P2 (square). P1 chooses an action
at a circle state, and P2 selects an action at a square state.
Given the transitions are deterministic, we omit the action set
and use the edges of the graph to refer to players’ actions.

start

0

1

2

5

6

7

4

3

Fig. 1. A game arena, G. The red (resp. blue) nodes are P1’s winning
region Win2

1 in G2 (resp. Win1

1 in G1).

Let L be deﬁned such that L(5) = {A} and L(s) = ∅
for s 6= 5. And L2 is deﬁned such that L2(2) = {A}
and L2(s) = ∅ for s 6= 2. The objective of P1 is ϕ =
♦ A, i.e., eventually reaching a state labeled A. The DFA
equivalent to ϕ is shown in Fig. 2.

∅

0

start

A

1

∅

Fig. 2. The DFA for ϕ = ♦ A.

1 = {5, 6, 7} and Win1

Due to the simplicity of DFA, we can directly solve G1
and G2 by marking the ﬁnal set F for P1 to reach in the
arena. In G1, the set to reach is {5}. The solution of G1
yields Win1
2 = {0, 1, 2, 3, 4}. Whereas,
In G2, the set to reach is {2}. The solution of G2 yields
Win2
2 = {0, 1, 4, 5, 6, 7}. In the true game
G1, P2 can win the game by choosing the edge (4, 3), but in
her perceptual game G2, P2 considers the action (4, 5) to be
winning or, in other words, rational.

1 = {2, 3} and Win2

We now introduce the solution concept of subjective
rationality to hypergames on graphs. Let S+ be paths of
length ≥ 1. Let u1 : S+ × Π1 × Π2 → [0, 1] be the utility
function of P1 such that u1(ρ, π1, π2) is the probability of
satisfying the speciﬁcation ϕ given that players commit to
the strategy proﬁle hπ1, π2i for a given history ρ ∈ S+. The
utility function for P2 is u2(ρ, π1, π2) = 1 − u1(ρ, π1, π2).
We denote uj
the utility function of player i perceived by
i
player j.

Deﬁnition 4 (Subjective Rationalizability). Given a level-2
hypergame HG2 = hHG1, G2i and the path ρ ∈ S+, strategy
i : S+ → D(Ai) (resp.,π∗
π∗
j ) is subjective rationalizable for
P2 if and only if for all πi ∈ Πi, we have u2
j ) ≥
j ), where (i, j) ∈ {(1, 2), (2, 1)}. The strategy π∗
i (ρ, πi, π∗
u2
1
is subjective rationalizable for P1 if and only for all π1 ∈
1(ρ, π1, π∗
1 , π∗
Π1, u1
2 is subjective
rationalizable for player 2.

2), where π∗

2) ≥ u1

i (ρ, π∗

1(ρ, π∗

i , π∗

Given two games, G1 and G2, we can use their product
games to obtain the solutions, which yield different partitions
of the product state space S × Q. Let Wink
1 (resp,. Wink
2)

In words, a strategy is called subjectively rationalizable for
player i if it is the best response in that player’s perceptual
game to some strategy of player j, which, for player j, is

the best response to player i in player j’s subjective view of
player i’s perceptual game.

We now formally deﬁne the subjective rationalizable ac-

tions in G2.

Deﬁnition 5 (Subjective rationalizable actions in G2). For
a given state (s, q) in G2, an action of player i, for i =
1, 2, is subjective rationalizable for P2 if it has a non-zero
probability to be selected by a subjectively rationalizable
strategy of player i in P2’s perceptual game G2.

Assumption 1. Subjective rationalizability is a common
knowledge between P1 and P2.

Assumption 1 means that both players know that their
opponent is subjectively rational and that the opponent is
aware of this fact. Thus, we can say that P2 would become
aware of her misperception, i.e., G2 6= G1, whenever P1
uses an action which is not subjectively rationalizable in
P2’s perceptual game, G2. Thus, we deﬁne the notion of a
stealthy deceptive winning strategy over a graphical model—
a hypergame transition system—that effectively allows P1 to
track histories in both G1 and G2.

Deﬁnition 6. Given games G1 = hG1, ϕi and G2 = hG2, ϕi,
a hypergame transition system (HTS) is a tuple,
HTS = hS × Q × Q, A, ∆, (s0, q0, p0), Win1

1 × Qi,

where 1) the transition function ∆ is deﬁned as follows:
given (s, q, p), (s′, q′, p′) ∈ S × Q × Q, ∆((s, q, p), a) =
(s′, q′, p′) for some a ∈ A if and only if s′ = T (s, a) and
q′ = δ(q, L1(s′)) and p′ = δ(p, L2(s′)); and 2) the initial
state is (s0, q0, p0) where s0 is the initial state in the game
arena, q0 = δ(ι, L1(s0)), and p0 = δ(ι, L2(s0)). 3) Win1
1 ×
Q = {(s, q, p) | (s, q) ∈ Win1
1}.

Deﬁnition 7 (Stealthy deceptive winning strategy). A strat-
egy π1 : S × Q × Q → D(A1) deﬁned on the HTS is stealthy
deceptive (sure/almost-sure) winning in the hypergame HG2
(in Def. 3) if the following two conditions are satisﬁed:
1) Stealthy: For any (s, q, p) ∈ S1 × Q × Q \ Win1
1 × Q,
then π1((s, q, p), a) > 0 only if action a is subjective
rationalizable for P1 in G2; 2) Winning: By committing to
π1, P1 ensures to visit a state in Win1
1 × Q, no matter which
subjective rationalizable strategy that P2 commits to.

A state (s, q, p) ∈ S × Q × Q is stealthy deceptive
(sure/almost-sure) winning if P1 has a stealthy deceptive
(sure/almost-sure) winning strategy at that state.

We now formally state our problem:

Problem 1. Given a hypergame on graph HG2 in Def. 3
and Assumption 1, how to synthesize a stealthy deceptive
sure/almost-sure winning strategy for P1?

B. Synthesis of a stealthy deceptive sure winning strategy

For P1’s deceptive strategy to be stealthy, he must choose
actions that are subjective rationalizable in P2’s perceptual
game until reaching the winning region Win1
1. At the same
time, a rational P2 takes subjective rationalizable actions in
G2 unless she becomes aware of the misperception.

Lemma 1. In a turn-based deterministic perceptual game
G2, for a state (s, q) ∈ S × Q, an action a is subjective
rationalizable for player i if and only if it satisﬁes either
condition: 1) (s, q) ∈ Win2
i ; 2)
(s, q) /∈ Win2

i and ∆((s, q), a) ∈ Win2

i and a is enabled from s.

The ﬁrst condition means that P2 thinks that a rational
player should stay within his/her winning region; the second
condition means that P2 thinks that it is rational for a player
to take arbitrary actions if he/she has already lost the game
from that state.

We introduce two functions π2

i , for i ∈ {1, 2}, that maps
a state (s, q) ∈ Win2
into a set of subjective rationalizable
i
actions for player i in the game G2. Formally, for each i, the
function π2
2 ∩ (Si × Q) → 2Ai is deﬁned such that,

i : Win2
i (s, q) = {a | ∆2((s, q), a) ∈ Win2
π2

i }.

(1)

=

1×Qi, functions π2

Theorem 1. Given HTS
hS × Q ×
Q, A, ∆, (s0, q0, p0), Win1
2 : S ×Q → 2A2
and π2
1 : S × Q → 2A1 deﬁned by (1), P1 has a stealthy
deceptive sure winning strategy if and only if he has a sure
winning strategy in the following reachability game:
HG = (S × Q × Q, A, ˜∆, (s0, q0, p0), Win1
g

where ˜∆ is obtained from ∆ by restricting both players’
actions as follows: For a given state (s, q, p) ∈ S × Q ×
Q and action a ∈ A, if (s, q) ∈ Win1
1, ˜∆((s, q, p), a) =
∆((s, q, p), a), otherwise,
CaseI: (s, p) ∈ Win2
˜∆((s, q, p), a) =

2 and (s, q) /∈ Win1
1,

1 × Q)




∆((s, q, p), a)
∆((s, q, p), a)
↑

if s ∈ S1,
if s ∈ S2 and a ∈ π2
if s ∈ S2 and a /∈ π2

2(s, p),
2(s, p).



where ↑ means that the transition is undeﬁned.
CaseII: (s, p) ∈ Win2
˜∆((s, q, p), a) =

1 and (s, q) /∈ Win1
1,




∆((s, q, p), a)
↑
∆((s, q, p), a)

if s ∈ S1 and a ∈ π2
if s ∈ S1 and a /∈ π2
if s ∈ S2.

1(s, p) ,
1(s, p),



1 × Q.

1 × Q–that is, P1

The winning condition is deﬁned by Win1
wins if he reaches the set Win1
Proof. Before reaching the set Win1
1 × Q, at any state
(s, q, p) where s ∈ S2, if (s, p) is perceived winning by
P2 (i.e.,, (s, p) ∈ Win2
2), then P2 will select a subjectively
2(s, p). If (s, p) is not in Win2
rationalizable action a ∈ π2
2,
then any action from P2 is subjective rationzalizable. At a
state (s, q, p) where s ∈ S1, if (s, p) ∈ Win2
1 but (s, q) /∈
Win1
1, then P1 will select a subjectively rationalizable action
a ∈ π2
1(s, p) so as not to contradict P2’s perception. If
(s, p) /∈ Win2
1, then any action of P1
is deemed subjectively rationalizable by P2. The solution of
HG, is a policy π∗
1 : S × Q × Q → A1 that
reachability game
ensures starting from a state where π∗
1 is deﬁned, no matter
g
which action P2 selects in ˜HG, P1 can ensure to reach a state
(s, q, p) with (s, q) ∈ Win1
1 , in ﬁnitely many

1 and (s, q) /∈ Win1

1 by following π∗

steps. By construction, P2 will not know that a misperception
exists as P1 takes only subjective rationalizable actions, until
P1 reaches Win1
1. After reaching the set, P1 can follow the
true winning strategy deﬁned for Win1
1.

game, then the game is entirely different as we would have
eliminated that action from the arena. This P2’s random
choice of subjective rationalizable actions can be considered
as opportunities for P1 to exploit.

Example 2. Given the DFA shown in Fig. 2, we construct
HTS and
the red,
HG shown in Fig. 3. In this ﬁgure,
dashed edges correspond to actions that are not subjective
g
rationalizable in P2’s perceptual game and thus removed to
obtain
HG. For example, at state (3, 0, 0), P2 thinks that it
is irrational for P1 to reach (4, 0, 0) instead of (2, 0, 1) given
g
P2 misperceives the labels of states and thinks that P1 needs
to reach state 2.

start

0, 0, 0

1, 0, 0

2, 0, 1

1, 0, 1

0, 0, 1

4, 0, 0

3, 0, 0

3, 0, 1

4, 0, 1

5, 1, 1

6, 1, 1

5, 1, 0

4, 1, 0

3, 1, 0

2, 1, 1

4, 1, 1

7, 1, 1

6, 1, 0

7, 1, 0

3, 1, 1

Fig. 3. A graph representing HTS and gHG. The blue and dash dot edges
are deterministic choices in two-player reachability game gHG. The red and
dashed edges are not subjectively rationalizable for P2 and thus removed in
gHG. Unreachable states in gHG and HGM are drawn dashed.

In the reachability game

HG, we calculate the stealthy
deceptive sure winning region for P1, which includes
g
{(5, 1, 0), (6, 1, 0), (7, 1, 0), (4, 1, 0), (4, 0, 0)}. This means
that P1 can satisfy his objective deceptively from states
{4, 5, 6, 7}–that is, one state more than the game where P2
does not have misperception. Due to P2’s misperception, P2
will not select to go to state 3 from state 4–making the state
4 deceptive sure winning for P1.

C. Synthesis of a deceptive almost-sure winning strategy

In synthesizing the deceptive sure winning strategy for
P1, we assumed that P2 actively selects actions in the zero-
sum game ˜HG to play against P1’s objective. However, P2
cannot construct this hypergame transition system and thus
may make “mistakes”, exploitable by P1. To see this, let us
consider the winning strategy for P2 in the reachability game
HG, ˜π∗
2, P2 should
know the value of q in the tuple (s, q, p), which means that
g
P2 should have a knowledge about L1. This is not the case.
Next, we consider a realistic assumption for P2.

2 : S ×Q×Q → 2A2. For P2 to exercise ˜π∗

Assumption 2. For a P2 state (s, q, p) in the HTS, any
subjective rationalizable action at (s, p) in G2 will be be
selected by P2 with a non-zero probability.

The assumption on P2’s behavior has the following ratio-
nale: At any given state, the set of subjective rationalizable
actions has the same values (either 1 or 0 depending on
whether (s, p) ∈ Win2
2). The assumption allows P2 to
select any action in this set at random,
instead of the
worst-case scenario (considered by solving stealthy deceptive
sure winning strategy, in Sec. III-B). Besides, if P2 never
selects a subjective rationalizable action in her perceptual

Theorem 2. Given HTS
hS × Q ×
Q, A, ∆, (s0, q0, p0), Win1
1 × Qi, P1 has a stealthy deceptive
almost-sure winning strategy if and only if he has an
almost-sure winning strategy in the following one-player
stochastic game:

=

HGM = (V = V1 ∪ VP , A1, P, v0, F = Win1

1 × Q),

where the states are partitioned into two subsets: V1 = S1 ×
Q × Q are a set of P1’s states and VP = S2 × Q × Q are a
set of probabilistic states. The transition function is partially
deﬁned as follows. First, any state in F is a sink or absorbing
state. At a state (s, q, p) ∈ V1 \ F , we distinguish two cases:
Case I-1: (s, p) ∈ Win2
2, for any action a ∈ A1 enabled
from s, P ((s′, q′, p′)|(s, q, p), a) = 1 where (s′, q′, p′) =
∆((s, q, p), a). Case I-2: (s, p) ∈ Win2
1, for any action a ∈
1(s, p), P ((s′, q′, p′)|(s, q, p), a) = 1 where (s′, q′, p′) =
π2
∆((s, q, p), a).

(s, p) ∈ Win2

At a state (s, q, p) ∈ VP , we distinguish two cases:
Case II-1:
then for any action a ∈
2 ,
2(s, p), P ((s′, q′, p′)|(s, q, p), a) > 0 where (s′, q′, p′) =
π2
∆((s, q, p), a). CaseII-2: (s, p) ∈ Win2
1, then for any action
a ∈ A2 enabled from s, P ((s′, q′, p′)|(s, q, p), a) > 0 where
(s′, q′, p′) = ∆((s, q, p), a).

The almost-sure winning condition is deﬁned by Win1

Q–that is, P1 wins if he reaches the set Win1
probability one.

1 ×
1 × Q with

The proof is similar to that of Thm. 1, with small changes
to consider randomized actions of P2. We omitted the proof
due to the lack of space.

It

is noted that only the support of P ((s, q, p), a) is
known but not the exact probability distribution. The partial
knowledge of the transition probability function gives us a
graph of the underlying one-player stochastic game. The
stealthy deceptive almost-sure winning strategy for P1 is to
ensure, with probability one, a state in Win1
1 × Q can be
reached. Next, we describe Algorithm 1 to solve the almost-
sure stealthy and deceptive winning strategy for P1.

The algorithm uses a function Pre deﬁned as follows.

Pre(v, X) = {v′ ∈ V1 | ∃a ∈ A1, P (v|v′, a) = 1}

∪ {v′ ∈ VP | P (v|v′) > 0 =⇒ v ∈ X} (2)

and Pre(Y, X) = ∪v∈Y Pre(v, X).

Intuitively, the set Pre(Y, X) includes any state starting
from which P1 can ensure to reach the set Y with a positive
probability, while staying in X with probability one. The
following result is readily obtained by construction.
Proposition 1. The ﬁx-point X ∗ = Xk = Xk+1 is the
almost-sure winning region for P1 in the one-player stochas-
tic game HGM .

Given the ﬁxed point X ∗, let Y0, Y1, . . . , Yk be a sequence
of states computed using X = X ∗ in the inner loop, we

Algorithm 1 Computation of the almost-sure winning region
and strategy for P1 in the one-player stochastic game.
Inputs: HGM = (S = V1 ∪ VP , A1, P, F ).
Outputs: Xk, {Yi}.

1: X0 = V , Y0 = F , k ← 0,
2: while True do i ← 0,
3:
4:

while True do

Yi+1 = Pre(Yi, Xk) ∪ Yi
if Yi = Yi+1 then

5:

6:

7:

8:

9:

Break.
i ← i + 1.

if Yi = Xk then Break.
Xk+1 = Yi, k ← k + 1,

can extract P1’s deceptive almost-sure winning strategy π1
as follows. For each v ∈ Yi \ Yi−1, i > 0, π1(v, a) =
1 if P (Yi−1 | v, a) = 1. After reaching F , P1 follows his
sure winning strategy in Win1
1.

edges

3. The

(1, 0, 0) → (0, 0, 0)

Example
and
(1, 0, 0) → (4, 0, 0) are in Fig. 3 are now probabilis-
tic choices of P2. We compute 1) Y0 = Win1
1 × Q =
{(5, 1, 0), (6, 1, 0), (7, 1, 0)}. (here we omitted unreachable
states.) 2) Y1 = {(4, 1, 0), (4, 0, 0)} ∪ Y0. 3) Y2 =
{(1, 0, 0)} ∪ Y1, 4) Y3 = {(0, 0, 0)} ∪ Y2. Because Y4 = Y3.
The inner loop of Alg. 1 ends. Because now all reachable
states in X0 are in Y3. We have X0 = Y3 and the outer
loop of Alg. 1 ends. Thus, the deceptive almost-sure winning
region includes all states of the game.

It is noted that the solutions of deceptive strategies are
based on solving multiple games (two-player zero-sum, turn-
based games and one-player stochastic games). The space/-
time complexity is linear in the size of HTS for solving the
deceptive sure winning strategy, and polynomial for solving
the deceptive almost-sure winning strategy.

IV. CONCLUSION AND DISCUSSIONS

This paper presents a theory of hypergame for synthesizing
stealthy deceptive strategies with temporal logic speciﬁca-
tions. We have shown that different from the games with
complete information where the sure winning and almost-
sure winning region overlap, the deceptive sure winning and
almost-sure winning regions are different when one player
has incomplete or incorrect information.

This work lays the foundation for multiple future direc-
tions for both theoretical advances and algorithmic develop-
ment. One extension is to investigate the application of game-
theoretic synthesis to cyber-physical security with decoy-
based deception. This extension requires us to generalize
the Assumption 1 to incorporate other inference mecha-
nisms. For example, if P2 can detect the true labeling after
interacting with the decoy nodes, then P1 could include
safety (prevent P2 from reaching decoys) as part of stealthy
deception objective. In addition, we will extend the theory
of hypergames to concurrent games on graphs [22] and
investigate the solution of this class of hypergames.

REFERENCES

[1] A. Pnueli and R. Rosner, “On the synthesis of a reactive module,”
in Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on
Principles of programming languages - POPL ’89, 1989, pp. 179–
190.

[2] E. Gradel and W. Thomas, Automata, logics, and inﬁnite games: a
guide to current research. Springer Science & Business Media, 2002,
vol. 2500.

[3] R. Bloem, K. Chatterjee, and B. Jobstmann, “Graph games and reactive
synthesis,” in Handbook of Model Checking. Springer, 2018, pp. 921–
962.

[4] K. Chatterjee and T. A. Henzinger, “A survey of stochastic ω-regular
games,” Journal of Computer and System Sciences, vol. 78, no. 2, pp.
394–413, 2012.

[5] S. Lafortune, “Discrete event systems: Modeling, observation, and
control,” Annual Review of Control, Robotics, and Autonomous Sys-
tems, vol. 2, pp. 141–159, 2019.

[6] S. Jajodia, V. Subrahmanian, V. Swarup, and C. Wang, Cyber decep-

tion. Springer, 2016.

[7] M. I. Handel, War, strategy and intelligence. Routledge, 2012.
[8] P. G. Bennett and R. R. Bussel, “Hypergame Theory and Methodology:
The Current “State of the Art”,” in The Management of Uncertainty:
Approaches, Methods and Applications, L. Wilkin, Ed. Dordrecht:
Springer Netherlands, 1986, pp. 158–181.

[9] Y. Sasaki and K. Kijima, “Hierarchical hypergames and Bayesian
games: A generalization of the theoretical comparison of hypergames
and Bayesian games considering hierarchy of perceptions,” Journal of
Systems Science and Complexity, vol. 29, no. 1, pp. 187–201, Feb.
2016.

[10] M. Wang, K. W. Hipel, and N. M. Fraser, “Solution concepts in
hypergames,” Applied Mathematics and Computation, vol. 34, no. 3,
pp. 147–171, Dec. 1989.

[11] N. S. Kovach, A. S. Gibson, and G. B. Lamont, “Hypergame Theory:
A Model for Conﬂict, Misperception, and Deception,” Game Theory,
2015.

[12] T. E. Carroll and D. Grosu, “A Game Theoretic Investigation of Decep-
tion in Network Security,” in 2009 Proceedings of 18th International
Conference on Computer Communications and Networks, Aug. 2009,
pp. 1–6.

[13] E. Al-Shaer, J. Wei, K. W. Hamlen, and C. Wang, “Dynamic bayesian
games for adversarial and defensive cyber deception,” in Autonomous
Cyber Deception. Springer, 2019, pp. 75–97.

[14] B. Gharesifard and J. Cort´es, “Stealthy Deception in Hypergames
Under Informational Asymmetry,” IEEE Transactions on Systems,
Man, and Cybernetics: Systems, vol. 44, no. 6, pp. 785–795, Jun.
2014.

[15] B. Gharesifard and J. Cortes, “Evolution of Players’ Misperceptions
in Hypergames Under Perfect Observations,” IEEE Transactions on
Automatic Control, vol. 57, no. 7, pp. 1627–1640, Jul. 2012.

[16] J. C. Harsanyi, “Games with incomplete information played by
“bayesian” players, i–iii part i. the basic model,” Management science,
vol. 14, no. 3, pp. 159–182, 1967.

[17] O. Thakoor, M. Tambe, P. Vayanos, H. Xu, C. Kiekintveld, and
F. Fang, “Cyber camouﬂage games for strategic deception,” in In-
ternational Conference on Decision and Game Theory for Security.
Springer, 2019, pp. 525–541.

[18] Y. Sasaki, “Subjective rationalizability in hypergames,” Advances in

Decision Sciences, vol. 2014, 2014.

[19] O. Kupferman and M. Y. Vardi, “Model checking of safety properties,”
Formal Methods in System Design, vol. 19, no. 3, pp. 291–314, 2001.
[20] R. McNaughton, “Inﬁnite games played on ﬁnite graphs,” Annals of

Pure and Applied Logic, vol. 65, no. 2, pp. 149–184, 1993.

[21] W. Zielonka, “Inﬁnite games on ﬁnitely coloured graphs with appli-
cations to automata on inﬁnite trees,” Theoretical Computer Science,
vol. 200, no. 1-2, pp. 135–183, 1998.

[22] L. De Alfaro, T. A. Henzinger, and O. Kupferman, “Concurrent
reachability games,” Theoretical Computer Science, vol. 386, no. 3,
pp. 188–217, 2007.

