Veriﬁcation of Approximate Opacity via Barrier Certiﬁcates

Siyuan Liu and Majid Zamani

1
2
0
2

p
e
S
2
2

]

C
O
.
h
t
a
m

[

1
v
3
9
9
0
1
.
9
0
1
2
:
v
i
X
r
a

Abstract— This paper is motivated by the increasing secu-
rity concerns of cyber-physical systems. Here, we develop a
discretization-free veriﬁcation scheme targeting an information-
ﬂow security property, called approximate initial-state opacity,
for the class of discrete-time control systems. We propose
notions of so-called augmented control barrier certiﬁcates in
conjunction with speciﬁed regions of interest capturing the
initial and secret sets of
the system. Sufﬁcient conditions
for (the lack of) approximate initial-state opacity of discrete-
time control systems are proposed based on the existence
of the proposed barrier certiﬁcates. We further present an
efﬁcient computation method by casting the conditions for
barrier certiﬁcates as sum-of-squares programming problems.
The effectiveness of the proposed results is illustrated through
two numerical examples.

I. INTRODUCTION

In recent decades, the world has witnessed a rapid in-
crease in the development and deployment of cyber-physical
systems (CPSs). Complex CPSs are becoming ubiquitous
in safety-critical infrastructure, ranging from power grids,
medical devices to transportation networks. However, the
tight interaction between embedded control software and
physical processes may release secret information and expose
the system to malicious intruders [1]. As a result, the security
and privacy of modern CPSs have received considerable
attentions in the past few years. In this paper, we focus on
an information-ﬂow security property, called opacity, which
captures whether a system has the ability to conceal its secret
information from outside intruders.

Opacity has been widely investigated in the domain of
discrete event systems (DESs), see [2] and the references
therein. Various notions of opacity were proposed depending
on how the “secrets” are deﬁned, e.g., language-based opacity
[3], initial-state opacity [4] and current-state opacity [5].
Despite the rich history of opacity in DESs community,
most of the works can only apply to systems modeled by
ﬁnite state automata with discrete state sets or bounded
Petri nets [6]. Opacity has been studied on continuous state-
space CPSs only very recently [7]–[9]. The results in [7]
introduced a framework for analyzing certain types of initial-
state opacity for the class of discrete-time linear systems,
wherein the notion of opacity is formulated as an output
reachability property. The opacity veriﬁcation procedure is

This work was supported in part by the H2020 ERC Starting Grant
AutoCPS (grant agreement No. 804639), China Scholarship Council, and
the NSF under Grant ECCS-2015403.

S. Liu is with the Department of Electrical and Computer Engineering,

Technical University of Munich, Germany; email: sy.liu@tum.de.

M. Zamani

is with the Computer Science Department, University
of Colorado Boulder, CO 80309, USA. M. Zamani
is also with
the Computer Science Department, LMU Munich, Germany; email:
majid.zamani@colorado.edu.

established by approximating the set of reachable states. In
[8], a new notion of approximate opacity was proposed that
is more applicable to metric systems with continuous state
domain. The (possibly) imperfect measurement precision
of intruders is characterized by a parameter δ, which on
the other hand indicates the security-guarantee level of the
system. The work was later extended in [9] to the class of
discrete-time stochastic systems based on a notion of opacity-
preserving simulation functions and their ﬁnite abstractions
(ﬁnite Markov decision processes).

In this paper, we aim at verifying approximate initial-state
opacity property of discrete-time control systems. In this
context, the intruder is assumed to be an outside observer
that has full knowledge of the system dynamics. The intruder
intends to infer if the initial state of the system is one of the
secret ones by observing the output trajectories of the system.
Approximate initial-state opacity requires that the intruder
with measurement precision δ can never determine that the
initial state of the system was a secret one [8]. Veriﬁcation
of initial-state opacity has been widely studied in several
literature. Results in DESs literature mostly translate this
issue to an initial-state estimation problem and address it
by the construction of initial-state estimators [4]. However,
this methodology is limited to discrete state-space systems.
Note that in [8], [9], a ﬁnite-abstraction based technique
was presented for verifying approximate opacity of control
systems, where the original control systems are approximated
by discrete ones. Unfortunately, this methodology generally
suffers from scalability issues since it requires discretization
of the state and input sets of the original system.

Motivated by this limitation, we develop a discretization-
free approach for the formal verification of approximate initial-
state opacity based on notions of barrier certificates. Barrier
certificates have shown to be a promising tool for the analysis of
safety problems [10]–[12]. A recent attempt to analyze privacy
of CPSs using barrier certificates is made in [13]. A new notion
of current-state opacity was considered there based on the
belief space of the intruder. The privacy verification problem
is cast into checking a safety property of the intruder’s belief
dynamics using barrier certificates. However, this framework
is again limited to systems modeled by partially-observable
Markov decision processes (POMDPs) with finite state sets.

In this work, we ﬁrst introduce two types of so-called
augmented control barrier certiﬁcates (ACBCs), which are
deﬁned for an augmented system constructed by augmenting a
control system with itself. The ﬁrst type of ACBC guarantees
a safety property of the augmented system in the sense
that there is no trajectory originating from a given initial
region reaching a given unsafe set. Along with this, the

 
 
 
 
 
 
initial and unsafe regions are designed in a speciﬁc form
capturing the secret and initial set of the original system. In
this way, the existence of an ACBC provides us a sufﬁcient
condition ensuring that the original system is approximate
initial-state opaque. In general, the failure in ﬁnding such an
ACBC does not mean the system is not opaque. Therefore,
we further present another type of ACBC which proves a
reachability property of the augmented system. This type of
ACBC can be utilized for showing that the original system
starting from the initial set will eventually reach the unsafe
region. This type of ACBC, on the other hand, provides
a sufﬁcient condition showing that the original system is
lacking approximate initial-state opacity. Additionally, we
present a way to compute polynomial ACBCs by means of
sum-of-squares (SOS) programming, where the conditions
required for the ACBCs are reformulated as SOS constraints.
The remainder of the paper is organized as follows. In
Section II, we introduce discrete-time control systems and
the notion of approximate initial-state opacity. In Section III,
we present two types of augmented control barrier certificates
and their role in verifying approximate initial-state opacity.
Section IV presents a methodology for the construction of
the augmented control barrier certificates using SOS program-
ming. Section V illustrates the theoretical results through two
examples, and conclusion remarks are given in Section VI.

II. PRELIMINARIES

Notations: We denote by R and N the set of real numbers and
non-negative integers, respectively. These symbols are annotated
with subscripts to restrict them in the obvious way, e.g. R>0
denotes the positive real numbers. We denote the closed intervals
in R by [a, b]. For a,b ∈ N and a ≤ b, we use [a; b] to denote
the corresponding intervals in N. Given N∈N≥1 vectors xi ∈
Rni, with i ∈ [1; N ], ni ∈ N≥1, and n = (cid:80)
i ni, we denote
the concatenated vector in Rn by x = [x1;. . .; xN ] and the
Euclidean norm of x by (cid:107)x(cid:107). The individual elements in a
matrix A ∈ Rm×n, are denoted by {A}i,j, where i ∈ [1; m]
and j ∈ [1; n]. We denote by ∅ the empty set. Given sets X
and Y with X ⊂ Y , the complement of X with respect to Y is
defined as Y\X = {x ∈ Y | x /∈ X}. The Cartesian product of
two sets X and Y is defined by X ×Y ={(x, y) | x ∈ X, y ∈ Y }.
Given a function f : X → Y and a function g : A → B, we
define f ×g : X ×A → Y ×B. For any set Z ⊆ Rn, ∂Z and Z,
respectively, denotes the boundary and topological closure of Z.

A. Approximate Initial-State Opacity for Discrete-Time Con-
trol Systems

In this subsection, we introduce the notion of approximate
initial-state opacity for the class of discrete-time control
systems deﬁned below.

Deﬁnition 1: A discrete-time control system (dt-CS) Σ is
deﬁned by the tuple Σ = (X, X0, Xs, U, f, Y, h) where X, U,
and Y are the state set, input set, and output set, respectively.
We denote by X0 ⊆ X and Xs ⊆ X the sets of initial states
and secret states, respectively. The function f : X × U → X
is the state transition function, and h : X → Y is the output

function. The dt-CS Σ is described by difference equations:
(cid:26) x(t + 1) = f (x(t), ν(t)),
y(t) = h(x(t)),

Σ :

(1)

where x : N → X, ν : N → U and y : N → Y are the state,
input and output signals, respectively. We use xx0,ν to denote
a state run of Σ starting from initial state x0 under input run
ν : N → U.

Throughout this paper, we focus on analyzing approximate
initial-state opacity for the class of control systems as in
Deﬁnition 1. Let us recall the notion of approximate initial-
state opacity, originally introduced in [8], deﬁned below.

Deﬁnition 2: Consider a control system Σ = (X, X0, Xs,
U, f, Y, h) and a constant δ ∈ R≥0. System Σ is said to be δ-
approximate initial-state opaque if for any x0 ∈ X0∩Xs and any
finite state run xx0,ν = {x0, . . . , xn}, there exists ˆx0 ∈ X0 \Xs
and a finite state run xˆx0,ˆν = {ˆx0, . . . , ˆxn} such that

max
i∈[0;n]

(cid:107)h(xi) − h(ˆxi)(cid:107) ≤ δ.

Intuitively, the system Σ is δ-approximate initial-state opaque
if for every state run initiated from a secret state, there
exists another state run originated from a non-secret state
with similar output trajectories (captured by δ). Hence, the
intruder is never certain that the system is initiated from a
secret state no matter which output run is generated. Hereafter,
we assume without loss of generality that ∀x0 ∈ X0 ∩Xs,

{x ∈ X0 | (cid:107)h(x) − h(x0)(cid:107) ≤ δ} (cid:42) Xs.

(2)

This assumption requires that the secret of the system is not
revealed initially; otherwise approximate initial-state opacity
is trivially violated.

Remark 3: We remark that our notion of initial-state
opacity is different from that of observability. An observability
notion states that every initial state can be determined by
observing a ﬁnite output sequence under a given input run
[14]. However, in our context, initial-state opacity is deﬁned
as the plausible deniability of a system for every secret initial
information under any input sequence. In DESs literature, it
was shown that observability can be reformulated as language-
based opacity by properly specifying the languages and the
observation mapping [3]. However, the relationship between
opacity and observability is more challenging in the domain
of CPSs and is left to future investigation.
III. VERIFYING APPROXIMATE INITIAL-STATE OPACITY

Although the veriﬁcation of opacity has been widely
investigated for ﬁnite systems with discrete states (e.g., in the
domain of DES), there is no systematic way in the literature
to check opacity of systems with continuous state spaces. In
the sequel, we propose a technique that is sound in verifying
approximate initial-state opacity for discrete-time control
systems. Our approach is based on ﬁnding a certain type of
barrier certiﬁcates as deﬁned in the next subsection.
A. Verifying Approximate Initial-State Opacity via Barrier
Certiﬁcates

Consider a dt-CS Σ = (X, X0, Xs, U, f, Y, h) as in Deﬁni-

tion 1. We deﬁne the associated augmented system by
Σ×Σ = (X×X, X0 ×X0, Xs ×Xs, U×U, f ×f, Y×Y, h×h),

which can be seen as the product of a dt-CS Σ and itself. For
later use, we denote by (x, ˆx) ∈ X×X a pair of states in Σ×Σ
and by (xx0,ν, xˆx0,ˆν) the state trajectory of Σ × Σ starting
from (x0, ˆx0) under input run (ν, ˆν). We use R = X× X to
denote the augmented state space.

Now, we deﬁne a notion of barrier certiﬁcates that is
constructed over the augmented system Σ×Σ and ensures a
safety property for Σ×Σ.

Proposition 4: Consider a dt-CS Σ as in Deﬁnition 1, the
associated augmented system Σ×Σ, and sets R0, Ru ⊆ R.
Suppose there exists a function B : X × X → R and constants
(cid:15), (cid:15) ∈ R with (cid:15) > (cid:15) such that

∀(x, ˆx) ∈ R0,
∀(x, ˆx) ∈ Ru,
∀(x, ˆx) ∈ R, ∀u ∈ U, ∃ˆu ∈ U,

B(x, ˆx) ≤ (cid:15),

B(x, ˆx) ≥ (cid:15),

(3)

(4)

B(f (x, u), f (ˆx, ˆu)) − B(x, ˆx) ≤ 0.

(5)

Then, for any initial condition (x0, ˆx0) ∈ R0 and for
any input run ν, there exists an input run ˆν such that
(xx0,ν(t), xˆx0,ˆν(t)) ∩ Ru = ∅, ∀t ∈ N.

Proof: This proposition is proved by contradiction.
Consider a state trajectory (xx0,ν,xˆx0,ˆν) of Σ×Σ that starts
from an initial condition (x0, ˆx0) ∈ R0, under input sequences
ν and ˆν. Suppose ˆν is computed such that the inequality in
(5) holds. Assume the state run reaches a state in Ru, i.e.,
(xx0,ν(t), xˆx0,ˆν(t)) ∈ Ru for some t ∈ N. From (3) and
(4), we have B(x0, ˆx0) ≤ (cid:15) and B(xx0,ν(t), xˆx0,ˆν(t)) ≥ (cid:15). By
using (5), one has (cid:15) ≤ B(xx0,ν(t), xˆx0,ˆν(t)) ≤ B(x0, ˆx0) ≤ (cid:15),
which contradicts (cid:15) > (cid:15). Therefore, for any state trajectory of
Σ×Σ starting from any initial condition in R0 under any input
run ν, (xx0,ν(t), xˆx0,ˆν(t)) ∩ Ru = ∅ always holds under the
extracted control policy ˆν, which completes the proof.

If B(x, ˆx) satisﬁes the conditions in Proposition 4, then
it is called an augmented control barrier certiﬁcate (ACBC)
for Σ×Σ. Next, we show how one can leverage the ACBC
to verify approximate initial-state opacity for a dt-CS Σ. To
this purpose, we deﬁne the sets of initial conditions R0 and
unsafe states Ru as:
R0 ={(x, ˆx) ∈ (X0 ∩Xs)×(X0 \Xs) | (cid:107)h(x)−h(ˆx)(cid:107) ≤ δ}, (6)
Ru ={(x, ˆx) ∈ X × X | (cid:107)h(x) − h(ˆx)(cid:107) > δ},
(7)

where δ ∈ R≥0 captures the measurement precision of the
intruder as introduced in Deﬁnition 2. The following theorem
provides us a sufﬁcient condition in verifying approximate
initial-state opacity of discrete-time control systems.

Theorem 5: Consider a dt-CS Σ as in Deﬁnition 1. Sup-
pose there exists a function B : X × X → R satisfying (3)-(5)
in Proposition 4 with sets R0, Ru given in (6)-(7). Then,
system Σ is δ-approximate initial-state opaque.

Proof: Consider an arbitrary secret initial state x0 ∈ X0∩
Xs, any input run ν, and the corresponding state run xx0,ν in
Σ. First note that by (2), {x ∈ X0 | (cid:107)h(x)−h(x0)(cid:107) ≤ δ} (cid:42) Xs.
It follows that there exists an initial state ˆx0 ∈ X0\Xs such that
(cid:107)h(ˆx0)−h(x0)(cid:107) ≤ δ. Consider the pair of initial states (x0, ˆx0).
It can be readily seen that (x0, ˆx0) ∈ R0 as in (6). Now,
given the existence of an ACBC as in Proposition 4, there

exists a control policy ˆν such that (5) is satisﬁed. By using
Proposition 4, under ˆν, we have the guarantee that any state
run of Σ×Σ starting from R0 never reaches the unsafe region
Ru, i.e. (xx0,ν(t), xˆx0,ˆν(t))∩Ru = ∅, ∀t ∈ N. This simply
implies the satisfaction of (cid:107)h(xx0,ν(t)) − h(xˆx0,ˆν(t))(cid:107) ≤ δ,
∀t ∈ N. Since x0 ∈ X0 ∩Xs and xx0,ν are arbitrarily chosen,
we conclude that Σ is δ-approximate initial-state opaque.
B. Verifying Lack of Approximate Initial-State Opacity via
Barrier Certiﬁcates

We presented in the previous subsection a sufﬁcient condi-
tion for verifying approximate initial-state opacity. However,
failing to ﬁnd such an ACBC does not necessarily imply that
the system is not opaque. Motivated by this, in this subsection,
we aim at presenting a sufﬁcient condition to verify the lack
of approximate initial-state opacity of a dt-CS Σ. This method
is based on constructing another type of ACBC ensuring a
reachability property for Σ×Σ.

Proposition 6: Consider a dt-CS Σ as in Deﬁnition 1, the
associated augmented system Σ × Σ, and sets R0, Ru ⊆
R. Suppose X ⊂ Rn is a bounded set and there exists a
continuous function V : X × X → R such that

∀(x, ˆx) ∈ R0,
∀(x, ˆx) ∈ ∂R \ ∂Ru,
∀(x, ˆx) ∈ (R \ Ru), ∃u ∈ U, ∀ˆu ∈ U,

V (x, ˆx) ≤ 0,

V (x, ˆx) > 0,

(8)

(9)

V (f (x, u), f (ˆx, ˆu)) − V (x, ˆx) < 0.

(10)

Then, for any initial condition (x0, ˆx0) ∈ R0, there exists an
input run ν such that (xx0,ν(T ), xˆx0,ˆν(T )) ∈ Ru for any ˆν,
for some T ≥ 0, and (xx0,ν(t), xˆx0,ˆν(t)) ∈ R, ∀t ∈ [0, T ].
Proof: Consider an initial state (x0, ˆx0)∈R0. One has
V (x0, ˆx0) ≤ 0 by (8). Consider an input run ν such that (10)
is satisfied for the state runs xx0,ν(t), xˆx0,ˆν(t) of Σ, where
ˆν is an arbitrary input run. First note that the continuous
function V (x, ˆx) is bounded below on the compact set (R\Ru).
From (10), V (x, ˆx) is strictly decreasing along the trajectory
(xx0,ν,xˆx0,ˆν) in region (R\Ru). It follows that (xx0,ν,xˆx0,ˆν)
must leave (R\Ru) in finite time. Now, assume (xx0,ν, xˆx0,ˆν)
leaves (R\Ru) without entering region Ru first. Consider the
first time instant t = T when (xx0,ν(t), xˆx0,ˆν(t)) is leaving
(R\Ru), i.e. (xx0,ν(t), xˆx0,ˆν(t)) ∈ (R\Ru) for all t ∈ [0, T ],
and (xx0,ν(T + (cid:15)), xˆx0,ˆν(T + (cid:15))) /∈ R for any (cid:15) > 0. By
(10) and V (x0, ˆx0) ≤ 0, we have V (xx0,ν(T ), xˆx0,ˆν(T )) ≤
0 which contradicts (9). Therefore, we conclude that for
any run starting from R0 under ν, there must exist T ≥
0 such that (xx0,ν(T ), xˆx0,ˆν(T )) ∈ Ru for any ˆν, and
(xx0,ν(t), xˆx0,ˆν(t)) ∈ R, ∀t ∈ [0, T ], which completes the proof.

Remark 7: We remark that the universal quantiﬁer in (8)
is not necessary to show the lack of approximate initial-state
opacity. One can relax the universal quantiﬁer to an existential
one by modifying the deﬁnition of barrier certiﬁcates, together
with the corresponding initial and unsafe regions, at the cost
of having a much more complex structure. However, it is
difﬁcult to formulate such a function and the corresponding
set constraints to sum-of-squares programs (c.f. Section IV),
and thus, is out of the scope of this paper.

A function V (x, ˆx) satisfying the conditions in Proposition
6 is also called an ACBC for Σ×Σ. The idea of using barrier
functions to prove reachability was first described in [15].
Next, we show that the above-defined ACBC can be used for
verifying the lack of approximate initial-state opacity of dt-CSs.
Theorem 8: Consider a dt-CS Σ as in Definition 1. Suppose
there exists a continuous function V : X×X → R satisfying (8)-
(10) in Proposition 6 with sets R0, Ru given in (6)-(7). Then,
system Σ is not δ-approximate initial-state opaque.

Proof: First note that from Definition 2, system Σ is not
δ-approximate initial-state opaque if there exists a state run
xx0,ν with x0 ∈ X0 ∩ Xs, such that for any other state runs
xˆx0,ˆν starting from a non-secret initial condition ˆx0 ∈ X0 \Xs,
maxi∈[0;n] (cid:107)h(xi)−h(ˆxi)(cid:107) > δ holds. Now consider a function
V : X × X → R and an input run ν satisfying (10). Then,
by Proposition 6 and from (6)-(7), it follows that there must
exist a secret state x0 ∈ X0 ∩ Xs and a state run xx0,ν under
input run ν, such that for any trajectory xˆx0,ˆν originated from
any non-secret initial condition ˆx0 ∈ X0 \Xs, the trajectories
(xx0,ν(t),xˆx0,ˆν(t)) will eventually reach Ru in finite time,
where (cid:107)h(xx0,ν(t))−h(xˆx0,ˆν(t))(cid:107) > δ. Therefore, for the state
run xx0,ν(t), there does not exist a state run starting from a
non-secret initial state that generates similar output trajectories.
Thus, δ-approximate initial-state opacity is violated.

In the next section, we discuss how to leverage existing
computational methods and software tools to compute B(x, ˆx)
and V (x, ˆx) in Propositions 4 and 6, respectively.

IV. COMPUTATION OF BARRIER CERTIFICATES USING
SUM-OF-SQUARES TECHNIQUE

In the previous section, we presented sufﬁcient conditions
for verifying (resp. the lack of) approximate initial-state
opacity of discrete-time control systems by searching for
barrier certiﬁcates satisfying inequalities (resp. (8)-(10)) (3)-
(5). For systems with polynomial transition functions and
semi-algebraic sets (i.e., described by polynomial equalities
and inequalities) X0, Xs, and X, an efﬁcient computational
method based on sum-of-squares (SOS) programming can be
utilized to search for polynomial barrier certiﬁcates.

Assumption 9: System Σ has continuous state set X ⊆ Rn
and continuous input set U ⊆ Rm. Its transition function
f : X × U → X is polynomial in variables x and u, and
output map h is polynomial in variable x.

In the next lemma, we translate the conditions in Proposi-

tion 4 to SOS constraints.

Lemma 10: Suppose Assumption 9 holds and sets R0, Ru,
R, and U can be defined as R0 = {(x, ˆx) ∈ Rn×Rn | g0(x, ˆx) ≥
0}, Ru = {(x, ˆx) ∈ Rn ×Rn | gu(x, ˆx) ≥ 0}, R = {(x, ˆx) ∈
Rn × Rn | g(x, ˆx) ≥ 0}, U = {u ∈ Rm | gc(u) ≥ 0}, where
the inequalities are defined element-wise, and g0, gu, g, gc are
vectors of some polynomial functions. Suppose there exists a
polynomial function B(x, ˆx), polynomials pˆui(x, ˆx, u) corre-
sponding to the ith component of ˆu = [ˆu1; . . . ; ˆum] ∈ U ⊆ Rm,
and vectors of SOS polynomials λ0, λu, λ, λc of appropriate
size such that the following expressions are SOS polynomials:
(11)

−B(x, ˆx) − λ(cid:62)
B(x, ˆx) − λ(cid:62)

0 (x, ˆx)g0(x, ˆx) + (cid:15),
u (x, ˆx)gu(x, ˆx) − (cid:15),

(12)

−B(f (x, u), f (ˆx, ˆu)) + B(x, ˆx) − λ(cid:62)(x, ˆx)g(x, ˆx)

m
(cid:88)

−

(ˆui − pˆui (x, ˆx, u)) − λ(cid:62)

c (u)gc(u),

(13)

i=1

where (cid:15), (cid:15) ∈ R≥0 are some constants with (cid:15) > (cid:15). Then, B(x, ˆx)
satisfies conditions (3)-(5) and ˆu = [ˆu1; ˆu2; . . . ; ˆum], where
ˆui = pˆui (x, ˆx, u), ∀i ∈ [1; m], is a control policy satisfying (5).
We omit the proof of Lemma 10, since it follows the
general methods for converting set constraints conditions to
SOS programs with Positivstellensatz conditions, see [16] for
details. Similarly, we convert the conditions of Proposition 6
to SOS constraints as well.

Lemma 11: Suppose Assumption 9 holds and X ⊂ Rn is a
bounded set. Suppose the regions of interest in Proposition 6
can be defined as R0 = {(x, ˆx) ∈ Rn×Rn | g0(x, ˆx) ≥ 0}, ∂R\
∂Ru = {(x, ˆx) ∈ Rn×Rn | gu(x, ˆx) ≥ 0}, (R\Ru) = {(x, ˆx) ∈
Rn × Rn | g(x, ˆx) ≥ 0}, U = {ˆu ∈ Rm | gc(ˆu) ≥ 0}, where
the inequalities are defined element-wise, and g0, gu, g, gc are
vectors of some polynomial functions. Suppose there exists a
polynomial function V (x, ˆx), polynomials pui(x, ˆx, ˆu) corre-
sponding to the ith component of u = [u1; . . . ; um] ∈ U ⊆ Rm,
and vectors of SOS polynomials λ0, λu, λ, λc of appropriate
size such that the following expressions are SOS polynomials:
(14)

−V (x, ˆx) − λ(cid:62)
V (x, ˆx) − λ(cid:62)

0 (x, ˆx)g0(x, ˆx),
u (x, ˆx)gu(x, ˆx) − ε,
−V (f (x, u), f (ˆx, ˆu)) + V (x, ˆx) − λ(cid:62)(x, ˆx)g(x, ˆx)

m
(cid:88)

(ui − pui(x, ˆx, ˆu)) − λ(cid:62)

c (ˆu)gc(ˆu) − ε,

−

i=1

where ε is a small positive number. Then, V (x, ˆx) satisﬁes
conditions (8)-(10) and u = [u1; u2; . . . ; um], where ui =
pui(x, ˆx, ˆu), ∀i ∈ [1; m], is a control policy satisfying (10).
Note that a small tolerance ε in (15) and (16) is needed to
ensure positivity of polynomials as required in (9) and (10).
Remark 12: As seen in Lemmas 10 and 11, in order to
search for polynomial barrier certiﬁcates by means of SOS
programming, it is required that regions R0, Ru, ∂R \ ∂Ru,
(R\Ru) are semi-algebraic sets. We highlight that having a
system Σ with semi-algebraic sets X0, Xs, and X is enough to
ensure that all these regions are semi-algebraic. In particular,
as a consequence of Tarski-Seidenberg principle [17], the
class of all semi-algebraic sets is closed under ﬁnite unions,
intersections, taking complement, and Cartesian product. The
boundary, the interior, and the closure of a semi-algebraic set
are also semi-algebraic. Additionally, given the polynomial
output map h, the set of states satisfying (cid:107)h(x)−h(ˆx)(cid:107) ≤ δ is
equivalent to the one satisfying (h(x)−h(ˆx))(cid:62)(h(x)−h(ˆx)) ≤
δ2, which is again a semi-algebraic set. See [18] for details.
One can leverage existing computational toolboxes such
as SOSTOOLS [16] together with semideﬁnite programming
solvers such as SeDuMi [19] to compute polynomial barrier
certiﬁcates satisfying (11)-(13) or (14)-(16).

Remark 13: By formulating conditions (3)-(5) (resp. (8)-
(10)) as a satisfiability problem, one can alternatively search
for parametric control barrier certificates using an iterative
program synthesis framework, called Counter-Example-Guided
Inductive Synthesis (CEGIS), with the help of Satisfiability

(15)

(16)

Fig. 1: Plausible deniability of a vehicle in terms of its initial
conditions. The blue lines roughly indicate the intruder’s
insufﬁcient observation precision.

Modulo Theories (SMT) solvers such as Z3 [20] and dReal [21];
see, e.g., [12] for more details. We also refer interested readers
to the recent work [22], where machine learning techniques
were exploited for the construction of barrier certificates.

V. EXAMPLES

In this section, we provide two examples to illustrate how
one can utilize the theoretical results obtained in Sections
III and IV for the veriﬁcation of (the lack of) approximate
initial-state opacity.
A. Verifying Approximate Initial-State Opacity on a Vehicle
Model

In this example, we consider an autonomous vehicle
moving on a single lane road, whose state variable is deﬁned
as x = [x1; x2], with x1 being its absolute position (in the road
frame) and x2 being its absolute velocity. The discrete-time
dynamics of the vehicle is modeled as:

(cid:21)

(cid:20)x1(t + 1)
x2(t + 1)

(cid:20)1 ∆τ
1
0

=

(cid:21) (cid:20)x1(t)
x2(t)
(cid:21)

(cid:21)

+

(cid:21)
(cid:20)∆τ 2/2
∆τ

u(t),

,

(17)

y(t) = (cid:2)1 0(cid:3)

(cid:20)x1(t)
x2(t)
where u is the control input (acceleration) and ∆τ is the
sampling time. The output is assumed to be the position of the
vehicle on the road. Let us first briefly explain the motivation
behind this example; see Fig. 1. Suppose the initial locations
of the vehicle contain critical information which is needed to
be kept secret, e.g., the vehicle might be a cash transit van
that aims at transferring money initially from a bank to an
ATM machine, or a patient who initially visited a hospital
but unwilling to reveal personal information to others. It is
implicitly assumed that there is a malicious intruder who is
observing the behavior of the vehicle remotely intending to
carry out an attack. Therefore, it is in the interest of the system to
verify whether it maintains plausible deniability for secret initial
conditions where some confidential assignment is executed.
This problem can be formulated as a δ-approximate initial-state
opacity problem, where δ ≥ 0 captures the security-guarantee
level in terms of the measurement precision of the intruder.
Now consider system (17) with state space X = [0, 10]×[0, 0.1],
initial set X0 = [0, 10]×{0}, secret set Xs = [0, 1]×[0, 0.1], input
set U = [−0.05, 0.05] and sampling time ∆τ = 1. Consider the
augmented system Σ × Σ. Accordingly, the regions of interest
in (6) and (7) are R0 = {[x1; x2] ∈ [0, 1] × {0}, [ˆx1; ˆx2] ∈
[1, 10]×{0} | (x1 − ˆx1)2 ≤ δ2}, and Ru = {(x, ˆx) ∈ X×X |
(x1 − ˆx1)2 ≥ δ2 + (cid:15)}. Note that a small positive number (cid:15) is
needed to certify positivity of the obtained polynomials using
SOS programming. Now, we set the threshold parameter to

R0

Ru

Ru

Fig. 2: Trajectories of Σ × Σ projected on the position plane
starting from initial region R0 (represented by the black
triangle). The regions in red are the unsafe set Ru.

be δ = 1 and search for barrier certificates by solving sum-of-
squares programs with the help of SOSTOOLS and SeDuMi
tools as described in Section IV. Using Lemma 10, we obtained
a polynomial ACBC of degree 2 satisfying (11)-(13) with (cid:15) = 1,
(cid:15) = 1.001 and a tolerance (cid:15) = 0.01 as follows
2 + 0.9227ˆx2

B(x, ˆx) = 0.9227x2
+ 0.006x1x2 − 0.006ˆx1x2 − 0.006x1 ˆx2 − 0.006ˆx1 ˆx2
− 0.4696x2 ˆx2 − 1.845x1 ˆx1 − 0.0002ˆx1 + 0.0728,

1 + 0.2348ˆx2
2

1 + 0.2348x2

and the corresponding control policy is ˆu(x, ˆx, u) = 0.8x1 −
0.8x2 + 1.5ˆx1 − 1.5ˆx2 + u. Therefore, we conclude that Σ
is 1-approximate initial-state opaque. Particularly, for every
trajectory starting from a secret state, there always exists at
least one alternative trajectory originated from a non-secret state
which are indistinguishable for an intruder with measurement
precision δ. Fig. 2 shows the projection of a few state trajectories
on the position plane of the augmented system Σ × Σ, starting
from randomly generated initial conditions in R0 under control
policy ˆu with u taking values in U. It is seen that any trajectory
starting from R0 does not reach the unsafe region Ru as
time increases. We further notice that δ = 1 is the smallest
threshold for which we are able to find a barrier certificate
ensuring approximate initial-state opacity. For a smaller value
of δ, approximate initial-state opacity is immediately violated
at the initial condition since the assumption in (2) is not valid
anymore.
B. Verifying Lack of Approximate Initial-State Opacity on a
Room Temperature Model

In this example, we showcase the use of an ACBC in
verifying the lack of opacity in a two-room temperature
is borrowed from
model by Proposition 6. The model
[23]. The evolution of the temperature T(·) of 2 rooms is
described by the discrete-time model:

(cid:26) T(k) = AT(k) + αhThν(k) + αeTe,

Σ :

y(k) = h(T(k)),

(18)

where A ∈ R2×2 is a matrix with elements {A}ii = (1−2α−
αe − αhνi), {A}12 = {A}21 = α, T(k) = [T1(k); T2(k)],
Te = [Te1; Te2], ν(k) = [ν1(k); ν2(k)], where νi(k) ∈ [0, 1],
∀i ∈ [1; 2], represents the ratio of the heater valve being
open in room i. The output of the network is assumed to
be the temperature of the second room: h(T(k)) = T2(k).
Parameters α = 0.05, αe = 0.008, and αh = 0.0036 are heat
exchange coefficients, Te = −1 ◦C is the external temperature,

0246810024681001212Ru

R0

Ru

Fig. 3: Trajectories of Σ × Σ projected on the ﬁrst-room
plane starting from initial region R0 (represented by the
black rectangle). The regions in red are the unsafe set Ru.
and Th = 50 ◦C is the heater temperature. The regions of
interest in this example are X = [0, 50]2, X0 = [21, 22]2, and
Xs = [21.5, 50]×[0, 50]. Specifically, the secret of the network
is whether the first room has a temperature initially higher than
21.5 ◦C (which may indicate activities with people gathering
in that room). The intruder wants to infer the initial temperature
of the first room by monitoring the temperature variation of
the last room and using the knowledge of the system model.
Now the objective is to verify if the system is able to keep this
secret in the presence of a malicious intruder with measurement
precision δ = 1. In this example, a degree bound of 8 is imposed
on B and V . First, by means of SOSTOOLS, we failed to find
a function B(x, ˆx) satisfying (11)-(13) in Lemma 10. Then,
we compute a function V (x, ˆx) as in Lemma 11 to see if the
system is lacking the approximate initial-state opacity. In this
case, the regions considered in Lemma 11 are
R0 = {T ∈ [21.5,22]×[21,22], ˆT ∈ [21,21.5]×[21,22]},
∂R\∂Ru = {(T, ˆT) ∈ R | (T1, ˆT1) ∈ R1 ∪ R2 ∪R3 ∪R4},
(R \ Ru) = {(T, ˆT) ∈ R | (T1 − ˆT1)2 ≤ δ2},
where R = X × X, R1 = [0, δ] × {0}, R2 = {0} × [0, δ],
R3 = {50}×[50−δ, 50], R4 = [50−δ, 50]×{50}. With the aid
of SOSTOOLS and SeDuMi, we obtained a polynomial barrier
certificate of degree 6 satisfying (14)-(16) with a tolerance
ε = 0.01 and control policy ν(k) = [0; 0], ∀k ∈ N≥0. The
system is thus lacking 1-approximate initial-state opacity. This
means that for each state run starting from a secret initial
state in Σ under ν, all trajectories from non-secret states
will eventually deviate from the former ones in the sense of
generating different outputs (captured by δ). Once the intruder
sees these trajectories, it is certain that the system was initiated
from a secret state. Fig. 3 shows trajectories of Σ × Σ from
R0 under control sequence ν with ˆν taking values in U. The
trajectories eventually reach Ru in finite time.

VI. CONCLUSIONS

We proposed a discretization-free framework for opacity
verification of discrete-time control systems. A pair of aug-
mented control barrier certificates were defined for the analysis
of approximate initial-state opacity, which are constructed over
an augmented system that is the product of a control system and
itself. While both barrier certificates only serve as sufficient
conditions, they can be utilized in reverse directions in the
sense that one ensures approximate initial-state opacity, and the

other one shows the lack of approximate initial-state opacity
of the control system. We showed that the computation of the
barrier certificates can be carried out by some SOS program-
ming. Numerical case studies were conducted to illustrate the
effectiveness of the proposed results. Future research will look
into the formal synthesis of controllers enforcing approximate
opacity properties for control systems using barrier certificates.
REFERENCES

[1] Y. Ashibani and Q. H. Mahmoud, “Cyber physical systems security:
Analysis, challenges and solutions,” Comput. Security, vol. 68, pp.
81–97, 2017.

[2] S. Lafortune, F. Lin, and C. N. Hadjicostis, “On the history of
diagnosability and opacity in discrete event systems,” Annu. Rev.
Control, vol. 45, pp. 257–266, 2018.

[3] F. Lin, “Opacity of discrete event systems and its applications,”

Automatica, vol. 47, no. 3, pp. 496–503, 2011.

[4] A. Saboori and C. N. Hadjicostis, “Veriﬁcation of initial-state opacity
in security applications of discrete event systems,” Inf. Sci., vol. 246,
pp. 115–132, 2013.

[5] ——, “Notions of security and opacity in discrete event systems,” in

Proc. of the 46th IEEE Conf. Decis. Control, 2007, pp. 5056–5061.

[6] Y. Tong, Z. Li, C. Seatzu, and A. Giua, “Veriﬁcation of state-based
opacity using Petri nets,” IEEE Trans. Autom. Control, vol. 62, no. 6,
pp. 2823–2837, 2016.

[7] B. Ramasubramanian, R. Cleaveland, and S. I. Marcus, “Notions of
centralized and decentralized opacity in linear systems,” IEEE Trans.
Autom. Control, vol. 65, no. 4, pp. 1442–1455, 2019.

[8] X. Yin, M. Zamani, and S. Liu, “On approximate opacity of cyber-
physical systems,” IEEE Trans. Autom. Control, pp. 1–1, 2020.
[9] S. Liu, X. Yin, and M. Zamani, “On a notion of approximate opacity
for discrete-time stochastic control systems,” in Proc. Amer. Control
Conf., 2020, pp. 5413–5418.

[10] S. Prajna, A. Jadbabaie, and G. J. Pappas, “A framework for worst-case
and stochastic safety veriﬁcation using barrier certiﬁcates,” IEEE Trans.
Autom. Control, vol. 52, no. 8, pp. 1415–1428, 2007.

[11] A. D. Ames, S. Coogan, M. Egerstedt, G. Notomista, K. Sreenath, and
P. Tabuada, “Control barrier functions: Theory and applications,” in
Proc. 18th Eur. Control Conf., 2019, pp. 3420–3431.

[12] P. Jagtap, S. Soudjani, and M. Zamani, “Formal synthesis of stochastic
systems via control barrier certiﬁcates,” IEEE Trans. Autom. Control,
2020.

[13] M. Ahmadi, B. Wu, H. Lin, and U. Topcu, “Privacy veriﬁcation in
POMDPs via barrier certiﬁcates,” in Proc. IEEE Conf. Decis. Control,
2018, pp. 5610–5615.

[14] R. Hermann and A. Krener, “Nonlinear controllability and observability,”
IEEE Trans. Autom. Control, vol. 22, no. 5, pp. 728–740, 1977.
[15] S. Prajna and A. Rantzer, “Primal–dual tests for safety and reachability,”
in Proc. Int. Workshop Hybrid Syst. Comput. Control. Springer, 2005,
pp. 542–556.

[16] A. Papachristodoulou, J. Anderson, G. Valmorbida, S. Prajna, P. Seiler,
and P. Parrilo, “SOSTOOLS version 3.00 sum of squares optimization
toolbox for MATLAB,” arXiv preprint arXiv:1310.4716, 2013.
[17] A. Tarski, “A decision method for elementary algebra and geometry,”
in Quantiﬁer elimination and cylindrical algebraic decomposition.
Springer, 1998, pp. 24–84.

[18] M. Coste, “An introduction to semialgebraic geometry,” Dottorato de

Ricerca in Matematica, Dept. di Mat., Univ. Pisa, 2000.

[19] J. F. Sturm, “Using SeDuMi 1.02, a MATLAB toolbox for optimization
over symmetric cones,” Optim. Methods Softw., vol. 11, no. 1-4, pp.
625–653, 1999.

[20] L. De Moura and N. Bjørner, “Z3: An efﬁcient SMT solver,” in Proc.

Int. Conf. Tools Algorithms Constr. Anal. Syst., 2008, pp. 337–340.

[21] S. Gao, S. Kong, and E. M. Clarke, “dReal: An SMT solver for
nonlinear theories over the reals,” in Proc. Int. Conf. Autom. Deduction.
Springer, 2013, pp. 208–214.

[22] A. Peruffo, D. Ahmed, and A. Abate, “Automated formal synthesis
of neural barrier certiﬁcates for dynamical models,” arXiv preprint
arXiv:2007.03251, 2020.

[23] P.-J. Meyer, A. Girard, and E. Witrant, “Compositional abstraction
and safety synthesis using overlapping symbolic models,” IEEE Trans.
Autom. Control, vol. 63, no. 6, pp. 1835–1841, 2017.

0102030405001020304050212220.52121.52223453456