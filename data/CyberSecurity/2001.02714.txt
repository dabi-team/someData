On the conﬁdentiality of controller states
under sensor attacks

⋆

1
2
0
2

v
o
N
5

]

Y
S
.
s
s
e
e
[

4
v
4
1
7
2
0
.
1
0
0
2
:
v
i
X
r
a

David Umsonst a, Henrik Sandberg a,

aDivision of Decision and Control Systems, School of Electrical Engineering and Computer Science, KTH Royal Institute of
Technology, Stockholm, Sweden

Abstract

With the emergence of cyber-attacks on control systems it has become clear that improving the security of control systems is
an important task in today’s society. We investigate how an attacker that has access to the measurements transmitted from
the plant to the controller can perfectly estimate the internal state of the controller. This attack on sensitive information of
the control loop is, on the one hand, a violation of the privacy, and, on the other hand, a violation of the security of the closed-
loop system if the obtained estimate is used in a larger attack scheme. Current literature on sensor attacks often assumes
that the attacker has already access to the controller’s state. However, this is not always possible. We derive conditions for
when the attacker is able to perfectly estimate the controller’s state. These conditions show that if the controller has unstable
poles a perfect estimate of the controller state is not possible. Moreover, we propose a defence mechanism to render the attack
infeasible. This defence is based on adding uncertainty to the controller dynamics. We also discuss why an unstable controller
is only a good defence for certain plants. Finally, simulations with a three-tank system verify our results.

Key words: Cyber-physical security; Privacy; Linear control systems; Kalman ﬁlters; Algebraic Riccati equations;
Discrete-time systems.

1 Introduction

The smart grid and intelligent transportation systems
are two prime examples of cyber-physical systems,
where physical processes are controlled over communi-
cation networks and with digital computers. The inter-
connection of the physical and cyber domain promises
great advantages in the performance and capabilities
of cyber-physical systems. However, with the introduc-
tion of communication networks and computational
devices, the controlled processes become vulnerable to
cyber-attacks. Documented cyber-attacks such as the
Stuxnet attack on an Iranian uranium enrichment facil-
ity (Kushner, 2013), the cyber attack on a German steel
mill (Lee et al., 2014), and the BlackEnergy attack on
the Ukrainian power grid (Lee et al., 2016) show that
these attacks are not a futuristic concept but already
happening.

⋆

This work is supported in part by the Swedish Re-
search Council (grant 2016-00861), the Swedish Energy
Agency (project LarGo!), and the Swedish Civil Contingen-
cies Agency (project CERCES).

Email addresses: umsonst@kth.se (David Umsonst),

hsan@kth.se (Henrik Sandberg).

Teixeira et al. (2015) deﬁne a cyber-physical attack
space that is spanned by the attacker’s disclosure and
disruptive resources as well as its model knowledge.
Disclosure resources enable the attacker to gather infor-
mation about the system and, therefore, break its conﬁ-
dentiality. These disclosure attacks can, for example, be
used to increase the attacker’s model knowledge. Disrup-
tive resources, on the other hand, let the attacker launch
both deception and denial of service attacks, which af-
fect the integrity and the availability of measurement
and actuator signals, respectively. Several attacks can
be mapped into this attack space, for example replay
attacks, where well-behaved sensor measurements are
replayed, while the actuator signals are changed.

Although many attack strategies have been investi-
gated, the analysis of sensor attacks has gained popu-
larity in the last decade. A goal of the sensor attacks is
to remain undetected by the anomaly detector of the
operator, while changing the measurements. Figure 1
shows the block diagram of the cyber-physical system
under a sensor attack. Here, the dashed line going to
the attacker corresponds to the disclosure resources of
the attacker. The disclosure resources can be used to
gather more information about the closed-loop system,

Preprint submitted to Automatica

8 November 2021

 
 
 
 
 
 
tacker needs to perform to execute the attacks proposed
by the papers mentioned above.

1.1 Contributions

The contribution of our work is three-fold. Firstly, we
provide a rigorous analysis of whether or not an attacker
with full-model knowledge and access to all sensors is
able to perfectly estimate the internal state of the output-
feedback controller. Although it may seem obvious that
such a powerful attacker is able to estimate the state
perfectly, we show that if the operator uses an unstable
controller the attacker is not able to do so. We further
classify all gains for a linear time-invariant observer the
attacker could use to achieve a perfect estimate in case
of a stable output-feedback controller. The second con-
tribution provides a defence mechanism against this dis-
closure attack. This mechanism proposes to add some
uncertainty to the controller’s input, which can be in-
terpreted as a watermarking scheme. Furthermore, we
discuss when an unstable controller is an appropriate
defence mechanism. The third contribution is the veri-
ﬁcation of our theoretical results with simulations of a
three-tank system under attack.

1.2 Related work

Most of the research on the security of cyber-physical
systems has focused on the integrity and availability of
data, according to Lun et al. (2019). For example, all
the previously mentioned papers on sensor attacks ex-
cept Umsonst and Sandberg (2019) consider integrity
attacks.

Other work on the conﬁdentiality of control sys-
tems can be found in, for example, Xue et al. (2014),
Yuan and Mo (2015), and Dibaji et al. (2018). What
distinguishes this paper from these results is that
we focus on a general linear system structure, while
Xue et al. (2014) investigate the conﬁdentiality of a
special structured linear system. Further, we focus on
the conﬁdentiality of the controller’s internal state.
However, Xue et al. (2014) consider the conﬁdentiality
of the whole system state, while Dibaji et al. (2018)
look into the conﬁdentiality of controller gains and in
Yuan and Mo (2015) the attacker wants to identify the
controller structure. In Yuan and Mo (2015), it is shown
that an appropriate controller design can lead to conﬁ-
dentiality. We also show that a certain type of controller,
in our case an unstable controller, leads to conﬁdential-
ity regarding sensitive information of the controller. It
is interesting that an appropriate controller design can
preserve the controller’s conﬁdentiality.

Another recent research direction is to use homomor-
phic encryption to ensure the security and privacy of
control systems (Kogiso and Fujita, 2015; Farokhi et al.,

Fig. 1. Block diagram of the closed-loop system equipped
with an anomaly detector under a sensor attack

for example, about the internal states of the plant x(k),
the controller xc(k), or the anomaly detector xD(k).
The disruptive resources are denoted by ya(k) and are
used to change the values of the measurements from
y(k) to ˜y(k) = y(k) + ya(k). Mo and Sinopoli (2010)
look into integrity attacks on sensors and deﬁne a notion
of perfectly attackable systems, while C´ardenas et al.
(2011) analyse two diﬀerent detectors and three sen-
sor attack strategies. Another approach is to maximize
the error covariance matrix of a state estimator with
a sensor attack as it is done in Guo et al. (2018). In
Murguia and Ruths (2016), a sensor attack strategy is
proposed which replaces the residual signal r(k), which
is the input to the anomaly detector (Fig. 1), with a
signal designed by the attacker. This attack strategy is
then used to look at the impact under the two anomaly
detectors investigated in C´ardenas et al. (2011). In
Umsonst and Sandberg (2019), it was shown how an
attacker using this attack strategy is able to break the
conﬁdentiality of the internal anomaly detector state
xD(k).

What connects all these papers on sensor attacks is that
the attacker needs to have exact knowledge about the
internal state xc(k) of the controller, when the attack
starts. Mo and Sinopoli (2010) assume that the initial
system state is zero in order to determine the unde-
tectable attack, while the other papers assume that the
controller state is known to the attacker. Therefore, this
paper investigates a missing piece that is often taken for
granted in sensor attacks, namely the broken conﬁden-
tiality of the controller’s internal state. More precisely,
we examine if an attacker with full model knowledge lis-
tening to the sensor measurements is able to break the
conﬁdentiality of the controller. This conﬁdentiality at-
tack can have two purposes. One purpose might be that
the attacker is curious and wants to follow the activity
of the control centre. The other purpose might be that
it is one step in a more complex attack scheme. This
step represents gathering information of the plant and
its controller, which is then used in later steps to attack
the system. We can interpret this as a ﬁrst step the at-

2017). Based on encrypted sensor measurements the con-
troller determines an encrypted control signal, which is
decrypted at the actuator, i.e., the feedback loop oper-
ates on encrypted signals. The use of encrypted signals
guarantees that, even if the attacker estimates the con-
troller state, the estimate is not useful to the attacker,
due to the encryption. In our approach, we use an ar-
tiﬁcial uncertainty instead of encryption techniques to
preserve the conﬁdentiality of the controller.

Defending the cyber-physical system against attacks
by introducing an artiﬁcial uncertainty is also done in
the work using watermarking. Watermarking of the
actuator signal has been considered as a defence mech-
anism, for example, against replay attacks (Mo et al.,
2015) or sensors attacks in networked control systems
(Hespanhol et al., 2018). However, in this paper, the
uncertainty is added to the input of the controller, while
watermarking techniques usually add it to the output
of the controller, i.e., the actuator signal.

of the respective noise terms and have appropriate di-
mensions. The noise processes w(k) and v(k) are each
independent and mutually uncorrelated. The operator
uses an output-feedback controller of the form

xc(k + 1) = Acxc(k) + Bcy(k),
u(k) = Ccxc(k) + Dcy(k),

(2)

where xc(k) is the controller’s state in Rnc , Ac ∈ Rnc×nc
is the system matrix of the controller, Bc ∈ Rnc×ny is
the input matrix of the controller, Cc ∈ Rnu×nc is the
output matrix of the controller, and Dc ∈ Rnu×ny is the
feedthrough matrix from the measurements to the actua-
tor signal. This structure can represent many commonly
used controllers. For example, with Ac = A − BK − LC,
Bc = L, Cc = −K, and Dc = 0, we obtain an observer-
based controller, where xc(k) is an estimate of x(k), and
K and L represent the feedback and observer gain, re-
spectively. The observer-based controller is, for example,
used in Murguia and Ruths (2016).

1.3 Notation

The closed-loop system dynamics can be written as

Let x be a column vector in Rn and A a matrix in Rn×m.
The spectral radius of a square matrix A is ρ(A). Further,
we say A is (Schur) stable, if ρ(A) < 1. The trace of
A is denoted as tr(A). By B > 0 (B ≥ 0), we mean
a matrix is symmetric positive deﬁnite (semi-deﬁnite).
The identity matrix of dimension n is denoted as In,
while 0 denotes either a scalar, a vector, or a matrix
with all elements equal to zero. The dimension of 0 is
clear from the context. A Gaussian random variable x
with mean µ and covariance matrix Σ is denoted as x ∼
N (µ, Σ).

2 Problem formulation

In this section, we present the models of the plant and
controller. Further, we describe the assumptions on and
the goals of the attacker, which set the stage for the
formulation of the problem.

2.1 Plant and controller model

The plant is modelled as a linear discrete-time system,

x(k + 1) = Ax(k) + Bu(k) + w(k),

y(k) = Cx(k) + v(k),

(1)

where x(k) is the state of the plant in Rnx, u(k) is
the plant input in Rnu , and y(k) is the measured out-
put in Rny . Further, A ∈ Rnx×nx is the system matrix,
B ∈ Rnx×nu is the input matrix, and C ∈ Rny×nx is the
output matrix. Here, w(k) ∼ N (0, Σw) is the process
noise and v(k) ∼ N (0, Σv) is the measurement noise,
where Σw ≥ 0 and Σv > 0 are the covariance matrices

x(k + 1)

"

xc(k + 1)#

=

A + BDcC BCc

x(k)

"

BcC

Ac # "

xc(k)#

w(k) + BDcv(k)

Bcv(k)

.

#

+

"

Introducing

z(k) =

x(k)

"

xc(k)#

and η′

(k) =

w(k) + BDcv(k)

"

Bcv(k)

#

we write the closed-loop system as

z(k + 1) = A′

zz(k) + η′

(k)

y(k) = Czz(k) + v(k) =

C 0

z(k) + v(k),

(3)

h

i

where η′(k) ∼ N (0, Q′) is the zero mean process
noise of the closed-loop system with covariance matrix
Q′ ∈ R(nx+nc)×(nx+nc) and v(k) is the measurement
noise.

Assumption 1 The system is such that

(1) (A, B) is stabilizable,
(2) (C, A) is detectable,
(3) (A, Σ

1
2

w) has no uncontrollable modes on the unit

circle, and

(4) the controller (Ac, Bc, Cc, Dc) is minimal.

The stability of A′
z depends on the controller matri-
ces Ac, Bc, Cc, and Dc. Therefore, we need the ﬁrst two

points of Assumption 1 such that the operator is able to
observe and control all unstable modes in the system.
The third point is needed later for the existence of the
solution of a Riccati equation. To avoid unnecessary dy-
namics, the implementation of the controller should be
its minimal realization.

and

η(k)

E

(cid:26) "

v(k)#

η(k)T v(k)T
h

i (cid:27)

=

,

Q 0
0 R 






Assumption 2 The operator has designed Ac, Bc, Cc,
and Dc, such that the closed-loop system is stable, i.e.,
ρ(A′

z) < 1.

Assuming a stable closed-loop system is in line with nor-
mal operator requirements.

Assumption 3 The closed-loop system has reached
steady state before k = 0 and z(0) ∼ N (0, Σ0), where
Σ0 ≥ 0 is the solution to

Σ0 = A′

zΣ0(A′

z)T + Q′.

This assumption is not restrictive, since industrial plants
usually run for long periods of time, and we know that
the covariance of z(k) will reach its unique steady state,
since ρ(A′

z) < 1 by Assumption 2.

Note that the closed-loop process noise variable η′(k) is
correlated with the measurement noise v(k),

η′(k)
v(k) #

E

(cid:26) "

η′(k)T v(k)T
h

i (cid:27)

Σw + BDcΣvDT
c BT
BcΣvDT
ΣvBT DT
c

c BT BDcΣvBT
BcΣvBT
c
v BT
ΣT
c

c BDcΣv
BcΣv

Σv

Q′ S
ST R 

,



= 

=















where S ∈ R(nx+nc)×ny , and R ∈ Rny×ny .

Since the η′(k) and v(k) are correlated, we will apply a
transformation proposed in Chan et al. (1984) to obtain
a system representation with uncorrelated noises.

z(k + 1) = A′

zz(k) + η′(k) − SR−1(y(k) − y(k))

= Azz(k) + η(k) + SR−1y(k),

where Az = A′

z − SR−1Cz,

η(k) = η′

(k) − SR−1v(k) =

w(k)

"

0 #

,

Q = Q′ − SR−1ST =

Σw 0

"

0 0#

.

The zero elements in Q show us that there is no process
noise acting on the controller in the transformed system.

Therefore, the closed-loop dynamics we consider from
now on are

z(k + 1) = Azz(k) + η(k) + SR−1y(k),

y(k) = Czz(k) + v(k).

(4)

Note that even though ρ(A′
case that ρ(Az) < 1.

z) < 1, it is not always the

2.2 Attack model and goals

Now that we introduced the plant and controller model,
we look into the attack model and the attacker’s goal.
We begin by introducing the assumptions made about
the attacker.

Assumption 4 The attacker has gained access to
the model (A, B, C, Ac, Bc, Cc, Dc), the noise statistics
(Σw, Σv), the measurements y(k) for k ≥ 0 but not the
control signals u(k) and the initial state of the system
z(0).

Since the manipulation of control signals can lead to
an immediate physical impact, we assume u(k) is bet-
ter protected and therefore the attacker does not have
access to it. Moreover, we set the start of the attack ar-
bitrarily to k = 0. This can be interpreted as the point
in time, from which the attacker has access to the mea-
surements. From Assumption 3 we know that the plant
and controller have been running for a long time. There-
fore, the attacker does not know the state z(0) when it
gains access to the sensor measurements.

Assumption 5 The attacker uses measurements up to
time step k to estimate the controller’s internal state at
time step k + 1.

It is possible to use measurements up to time step
k∗ ≥ k + 1 to estimate the controller’s state at time step
k + 1. However, if the attacker wants to launch a false-
data injection attack at time step k + 1, this estimate
needs to be available already.

The goal of the attacker is to obtain an estimate ˆxc(k),
such that this estimate perfectly tracks the controller

state xc(k) as k grows large. This can be either a ﬁrst
step in a larger attack scheme or a way to gain some
insight in the controller’s internal state. The goal can be
formulated as the following problem.

Problem 1 Estimate xc(k) such that the estimation er-
ror is unbiased, i.e., E{xc(k) − ˆxc(k)} = 0, and its co-
variance matrix Σc(k) approaches zero, i.e.,

lim
k→∞

Σc(k) = 0

for a given Σc(0) ≥ 0.

An estimation error covariance matrix Σc(k) that ap-
proaches zero as k grows large means the estimate con-
verges to the true value in mean square (and thus also
in probability).

Note that the controller has a minimal realization (see
Assumption 1), and having access to both actuator and
measurement signals would mean we can always per-
fectly estimate its state using a standard observer in-
volving only the controller model.

In Section 3 we characterize for which systems the con-
troller’s conﬁdentially can be broken (Problem 1), and
in Section 4 we discuss possible defence mechanisms.

3 Estimating the controller’s state xc(k)

In this section, we investigate when a solution to Prob-
lem 1 exists. It may seem obvious that an attacker ac-
cording to Assumption 4 is without any doubt able to
estimate the controller’s state xc(k) perfectly. However,
we show in the following that this is not always the case.
First, we present the optimal attack strategy to estimate
xc(k) and then state conditions for the convergence of
Σc(k) to zero. Following this, we look into non-optimal
strategies to solve Problem 1.

3.1 Optimal attack strategy

To obtain the optimal attack strategy, we start by in-
vestigating the conditional probability of the closed-loop
system state z(k + 1) given all measurements up to time
step k. Due to the presence of the process noise, η(k),
and measurement noise, v(k), we know that z(k + 1)
is a random variable. Since (4) is a linear system with
Gaussian noise, we know that z(k + 1) given the mea-
surements up to time step k is also a Gaussian random
variable (Anderson and Moore, 1979). Let {y(i)}l
i=0 be
the sequence {y(0), · · · , y(l)}, then the conditional prob-
ability distribution of z(k + 1) given {y(i)}k

i=0 is

where

ˆz(k + 1) = Az ˆz(k) + SR−1y(k) + Lz(k)

(cid:0)

y(k) − Cz ˆz(k)
(5)
(cid:1)

z + Q
CzΣz(k)CT

is the conditional mean of z(k + 1) with Lz(k) =
, ˆz(0) = E{z(0)} = 0,
AzΣz(k)CT
z +R
z
and
(cid:0)

CzΣz(k)CT

−1

(cid:1)

(cid:1)(cid:0)
Σz(k + 1) = AzΣz(k)AT

−

AzΣz(k)CT
z

z + R

−1

AzΣz(k)CT
z

T

(cid:0)

(6)
(cid:1)
is the conditional covariance matrix. Its initial condition
is Σz(0) = Σ0, which is given in Assumption 3.

(cid:1)(cid:0)

(cid:0)

(cid:1)

The optimal estimator for z(k) given {y(i)}k
i=0 is the
Kalman ﬁlter (Anderson and Moore, 1979). It is optimal
in the sense that it minimizes the mean square error.
Therefore, the optimal attack strategy to estimate xc(k)
is a time-varying Kalman ﬁlter, which uses ˆz(k) in (5) as
the estimate of z(k). The goal of the attacker is to have
an estimate ˆz(k) of the closed-loop system’s state such
that

ˆz(k) → xc(k) as k → ∞.

0 Inc
h

i

Instead of directly analysing ˆz(k), we introduce the esti-
mation error ez(k) = z(k) − ˆz(k) that has the dynamics

ez(k + 1) =

Az − Lz(k)Cz

ez(k) + η(k) + Lz(k)v(k).

and covariance matrix

(cid:0)

(cid:1)

E

ez(k + 1)ez(k + 1)T

= Σz(k + 1).

(cid:8)

(cid:9)

A Kalman ﬁlter is an unbiased estimator, which
means that E{z(k)} = ˆz(k), or, diﬀerently formu-
lated, E{ez(k)} = 0. Hence, Problem 1 is solved if, for
Σz(0) = Σ0, the attacker’s Kalman ﬁlter fulﬁls

lim
k→∞

Σz(k) =

P 0

"

0 0#

,

(7)

where P ≥ 0. Note that Σ0 can be calculated by the at-
tacker because of its model knowledge by Assumption 4.

3.2 Asymptotic convergence to Σc(k) = 0

Let us now investigate when the optimal attack strat-
egy solves Problem 1. Here, we present necessary and
suﬃcient conditions for the covariance matrix Σc(k) to
converge to zero. Recall this is equivalent to saying that
(7) is fulﬁlled.

z(k + 1|{y(i)}k

i=0) ∼ N

ˆz(k + 1), Σz(k + 1)

,

Before we present our convergence results, note that a
steady state solution to (6) satisﬁes the algebraic Riccati

(cid:0)

(cid:1)

equation (ARE)

After algebraic computations we obtain

Σ∞ = AzΣ∞AT
AzΣ∞CT
z

−

z + Q
CzΣ∞CT

z + R

−1

AzΣ∞CT
z

T

,

(8)

AzΣ∞AT

z +Q =

AP AT + Σw 0

"

0

0#

, AzΣ∞CT

z =

AP CT

"

0

,

#

(cid:0)
where L∞ =
state Kalman gain.

(cid:1)(cid:0)
AzΣ∞CT
z

(cid:0)

(cid:1)
CzΣ∞CT

(cid:0)
z +R

−1

(cid:1)

is the steady

(cid:1)(cid:0)

(cid:1)

Deﬁnition 1 (Deﬁnition 3.1 (Chan et al., 1984))
A real symmetric nonnegative deﬁnite solution Σ∞ to
(8) is called a strong solution if ρ(Az − L∞Cz) ≤ 1.
The strong solution is called a stabilizing solution if
ρ(Az − L∞Cz) < 1.

The following lemma from de Souza et al. (1986) will be
useful in the following discussion.

Lemma 1 (Theorem 3.2 (de Souza et al., 1986))
Let GT G = Q,

(1) the strong solution of the ARE exists and is unique

if and only if (Cz, Az) is detectable;

(2) the strong solution is the only nonnegative deﬁnite
solution of the ARE if and only if (Cz, Az) is de-
tectable and (Az, G) has no uncontrollable modes
outside the unit circle;

(3) the strong solution coincides with the stabilizing
solution if and only if (Cz, Az) is detectable and
(Az, G) has no uncontrollable modes on the unit
circle;

(4) the stabilizing solution is positive deﬁnite if and only
if (Cz, Az) is detectable and (Az, G) has no uncon-
trollable modes inside, or on the unit circle.

Let us begin by showing that a solution to (8) of the
form in (7) exists.

and CzΣ∞CT

z + R = CP CT + Σv such that

z + R

AzΣ∞CT
CzΣ∞CT
z
AP CT (CP CT + Σv)−1CP AT 0
0#
0

(cid:1)(cid:0)

(cid:1)

(cid:0)

"

(cid:0)

(cid:1)

.

−1

AzΣ∞CT
z

T

=

This leads to

Σ∞ =

AP AT + Σw − AP CT (CP CT + Σv)−1CP AT 0
0#
0

.

"

For Σ∞ to be a solution of (8) we require

P = AP AT + Σw − AP CT (CP CT + Σv)

−1CP AT .

(9)

Note that (9) by itself is an algebraic Riccati equation.
It is actually the algebraic Riccati equation an opera-
tor would obtain when it is designing a time-invariant
Kalman ﬁlter. Due to detectability of (C, A) (Assump-
tion 1), there exists a unique strong solution P ≥ 0 for
(9) (Lemma 1). Hence, Σ∞ is a solution of (8).

Now that we proved that Σ∞ is indeed a solution to
the algebraic Riccati equation, we need to show under
which conditions Σz(k) converges to Σ∞ for the initial
condition Σ0.

Proposition 1 A solution of the algebraic Riccati equa-
tion (8) is given by

Lemma 2 The unique strong solution of the ARE (8)
is Σ∞ if and only if ρ(Ac) ≤ 1.

Σ∞ =

P 0

"

0 0#

,

where P ≥ 0 is the unique solution of the ARE

P = AP AT + Σw − AP CT (CP CT + Σv)−1CP AT .

PROOF. Let us ﬁrst determine

Az = A′

z − SR−1Cz =

A BCc

"

0 Ac #

.

PROOF. Due to the ﬁrst statement in Lemma 1, the
strong solution is unique and exists if and only if (Cz, Az)
is detectable. From the stability of A′
z = Az + SR−1Cz,
it follows that (Cz, Az) is detectable. Hence, the strong
solution will be unique. Further, if ρ(Az −L∞Cz) ≤ 1 for

L∞ =

=

−1

z + R

CzΣ∞CT

AzΣ∞CT
z
AP CT (CP CT + Σv)−1
(cid:1)(cid:0)
0

(cid:0)

"

(cid:1)
=

#

¯L

"

0#

,

then Σ∞ is a strong solution. Let us now look at the
eigenvalues of Az − L∞Cz, which are determined by the

eigenvalues of A − ¯LC and Ac, because

Az − L∞Cz =

A − ¯LC BCc

"

0

Ac #

.

Due to the detectability of (C, A) (Assumption 1), the
ﬁrst statement of Lemma 1 shows us that P is a strong
solution of (9), such that ρ(A − ¯LC) ≤ 1. Therefore,
ρ(Az −L∞Cz) ≤ 1, i.e., Σ∞ is the unique strong solution,
if and only if ρ(Ac) ≤ 1.

Theorem 1 The covariance matrix Σz(k) converges to
the attacker’s desired covariance matrix Σ∞ for the ini-
tial condition Σ0 if and only if ρ(Ac) ≤ 1.

PROOF. By Lemma 2, Σ∞ is the unique strong so-
lution of (8) if and only if ρ(Ac) ≤ 1. Theorem 4.2 in
de Souza et al. (1986) states that subject to Σ0−Σ∞ ≥ 0
the covariance matrix Σz(k) will converge to the strong
solution Σ∞ if and only if (Cz, Az) is detectable. That
(Cz, Az) is detectable is shown in the proof of Lemma 2.
Let us now show that Σ0 − Σ∞ ≥ 0. If we use the system
representation with correlated noise processes (3), the
ARE for Σ∞, according to Anderson and Moore (1979),
is

Σ∞ = A′
zΣ∞CT

zΣ∞(A′
z)T + Q′
z + S)(CzΣ∞CT

− (A′

z + R)

−1(A′

zΣ∞CT

z + S)T .

(10)

Subtracting (10) from the Lyapunov equation for Σ0 in
Assumption 3 leads to

Σ0 − Σ∞ = A′
zΣ∞CT

z)T
Σ0 − Σ∞
z + R)−1(A′
z + S)(CzΣ∞CT
(cid:1)

(A′

(cid:0)

z

+ (A′

zΣ∞CT

z + S)T .

This is also a Lyapunov equation with a unique solution
since ρ(A′
z) < 1 (Assumption 2). Further, we observe
that

(A′

zΣ∞CT

z + S)(CzΣ∞CT

z + R)−1(A′

zΣ∞CT

z + S)T ≥ 0,

because Σ∞ ≥ 0. Therefore, we know that Σ0 − Σ∞ ≥ 0.
Hence, with initial condition Σ0

lim
k→∞

Σz(k) = Σ∞

if and only if ρ(Ac) ≤ 1.

Theorem 1 shows that the covariance matrix converges
to the attacker’s desired strong solution, but not how fast
the convergence is. Therefore, we will now investigate
the conditions for an exponential convergence rate.

Proposition 2 Subject to Σ0 > 0, the covariance ma-
trix Σz(k) converges exponentially fast to Σ∞ if and only
if ρ(Ac) < 1.

PROOF. Theorem 4.1 in de Souza et al. (1986) shows
us that subject to Σ0 > 0 the covariance matrix Σz(k)
converges exponentially fast to the stabilizing solution if
and only if (Cz, Az) is detectable and (Az, G) has no un-
controllable modes on the unit circle. We already showed
that (Cz, Az) is detectable, therefore we look at the con-
trollable modes of (Az, G) now. Recall that GGT = Q
such that

G =

1
2

w 0

Σ

"

0 0#

.

For (Az, G) to have no uncontrollable modes on the unit
circle we need Ac to have no eigenvalues on the unit cir-
cle, because we cannot control the eigenvalues of Ac with
G, and due to Assumption 1 (A, Σ
w) has no uncontrol-
lable modes on the unit circle. We showed in Lemma 2
that Σ∞ is a strong solution to the ARE if and only
if ρ(Ac) ≤ 1. Hence, subject to Σ0 > 0 the covariance
matrix Σz(k) converges exponentially fast to Σ∞ if and
only if ρ(Ac) < 1.

1
2

This shows us that if Σ0 > 0 and the operator uses a
stable controller, i.e., ρ(Ac) < 1, the covariance matrix
of the attacker’s time-varying Kalman ﬁlter will converge
exponentially fast to Σ∞. Hence, the attacker is able to
obtain a perfect estimate of xc(k) exponentially fast.

3.3 Breaking conﬁdentiality of xc(k) using non-optimal

observers

Previously, we have shown under which conditions the
attacker is able to get a perfect estimate of the con-
troller state xc(k) when a time-varying Kalman ﬁlter
is used. The time-varying Kalman ﬁlter is the optimal
ﬁlter for linear systems with Gaussian noise. One may
wonder whether or not the attacker is able to perfectly
estimate xc(k), when the attacker uses a non-optimal
observer. Here, we investigate a time-invariant observer
of the form

Corollary 1 Problem 1 is solvable if and only if
ρ(Ac) ≤ 1.

ˆz(k + 1) = Az ˆz(k) + SR−1y(k) + Lz

y(k) − Cz ˆz(k)

Note that since the attacker uses a Kalman ﬁlter, it does
not only obtain a perfect estimate of xc(k) but also an
optimal estimate of x(k).

with ˆz(0) = 0, where Lz is the attacker’s constant ob-
server gain. As before, instead of looking at ˆz(k), we

(cid:0)

,
(11)
(cid:1)

analyse the error dynamics given by

ez(k + 1) =

Az − LzCz

ez(k) + η(k) + Lzv(k).

(cid:1)
with E{ez(k)} = 0 for all k ≥ 0, covariance matrix
E
= Σz(k) and Σz(0) ≥ 0.

ez(k)ez(k)T

(cid:0)

(cid:8)

(cid:9)

The following theorem classiﬁes all gains Lz of a non-
optimal observer such that Problem 1 is solved.

Theorem 2 For any Σz(0) ≥ 0,

Σz(k) = ˜Σ∞ =

lim
k→∞

˜P 0

"

0 0#

,

1 0T ]T and L1 ∈ Rnx×ny
if and only if ρ(Ac) < 1, Lz = [LT
is chosen such that ρ(A−L1C) < 1. Here, ˜P is the unique
solution to

˜P = (A − L1C) ˜P (A − L1C)T + Σw + L1ΣvLT
1 ,

and ˜P − P ≥ 0, where P is the unique solution to (9).

PROOF. With Lz = [LT

1 LT

2 ]T the error dynamics are

ez(k + 1) =

A − L1C BCc

"

−L2C Ac #

ez(k) +

w(k) − L1v(k)
L2v(k)

"

#

.

The error covariance matrix evolves as

Σz(k + 1) = (Az − LzCz)Σz(k)(Az − LzCz)T
1 L1ΣvLT
2
L2ΣvLT

Σw + L1ΣvLT
L2ΣvLT
1

+

"

2 #

Lyapunov equation for ˜P . Therefore, if ˜Σ∞ is a steady
state solution of (12) then L2 = 0. Hence, (12) has ˜Σ∞
as a steady state solution if and only if L2 = 0. Let
us now look at the convergence of (12) to ˜Σ∞. For any
Σz(0) ≥ 0, the error covariance matrix converges to ˜Σ∞
if and only if ρ(Az − LzCz) < 1. With L2 = 0, the sta-
bility of Az − LzCz is guaranteed when both ρ(Ac) < 1
and ρ(A − L1C) < 1. Due to detectability of (C, A) in
Assumption 1 such a stabilizing L1 exists. Therefore,
(12) converges to ˜Σ∞ for any Σz(0) ≥ 0, if and only
if L2 = 0, ρ(A − L1C) < 1, and ρ(Ac) < 1. Further,
ρ(Az − LzCz) < 1 also makes ˜Σ∞ the unique steady
state solution of (12). Since the Kalman ﬁlter is the best
linear estimator, we know that ˜P − P ≥ 0 and ˜P = P
if L1 = AP CT (CP CT + Σv)−1 (Anderson and Moore,
1979). This choice of L1 turns the Lyapunov equation of
˜P into (9).

Theorem 2 shows us that the attacker is able to use the
non-optimal observer (11) to solve Problem 1, if and only
if the controller is stable.

Corollary 2 Problem 1 is solvable with a non-optimal
observer of the form (11) if and only if ρ(Ac) < 1.

According to Theorem 2, the attacker does not need to
know the noise statistics Σw and Σv for the design of
L1 to estimate xc(k) perfectly, as long as L1 is stabiliz-
ing. Hence, the attacker’s required knowledge to solve
Problem 1 is reduced when the operator uses a stable
controller. Further, the attacker has a smaller computa-
tional burden when a time-invariant observer is used.

.

(12)

4 Defence mechanisms

Now we show that ˜Σ∞ is the steady state solution of (12)
if and only if L2 = 0. First, we observe that if L2 = 0
then ˜Σ∞ is a steady state solution of (12), where ˜P is
the solution to the Lyapunov equation

˜P = (A − L1C) ˜P (A − L1C)T + Σw + L1ΣvLT
1 .

Note that ˜P ≥ 0 exists and is unique if ρ(A − L1C) < 1.
Second, if ˜Σ∞ is a steady state solution of (12) the equa-
tions

˜P = (A − L1C) ˜P (A − L1C)T + Σw + L1ΣvLT
1 ,
0 = L2(ΣvLT
0 = L2(C ˜P CT + Σv)LT
2

1 − C ˜P (A − L1C)T ), and

are fulﬁlled. The last equation is only fulﬁlled if L2 = 0,
since Σv is positive deﬁnite. This simultaneously ful-
ﬁls the second equation. The ﬁrst equation recovers the

We presented under which conditions Problem 1 is
solvable both with optimal and non-optimal strategies.
Therefore, we investigate now how to prevent the at-
tacker from estimating xc(k) perfectly, i.e., make Prob-
lem 1 unsolvable. We present a defence mechanism and
discuss why an unstable controller is only in certain
cases a good defence mechanism.

4.1

Injecting noise on the controller side

As previously shown, an attacker under Assumption 4
will be able to predict the controller state perfectly for
ρ(Ac) ≤ 1. We observe that the controller dynamics in
(2) contain no uncertainty for the attacker when y(k) is
known. Therefore, an approach for defence is to intro-
duce uncertainty in the form of an additional noise term
on the controller side.

The additional noise term ν(k) has a zero mean Gaus-
sian distribution with a positive semi-deﬁnite covariance

matrix Σν ∈ Rnc×nc. Further, ν(k) is independent and
identically distributed over time and also independent
of w(k), v(k), and z(0). The controller state with the
additional noise term follows the dynamics

xc(k + 1) = Acxc(k) + Bcy(k) + ν(k).

Here, ν(k) can be interpreted as process noise of the
controller.

Assumption 6 The attacker knows the covariance ma-
trix Σν of the additional noise in the controller.

This assumption is in the spirit of Assumption 4, since
the attacker has full model knowledge and knows the
noise statistics of both w(k) and v(k).

This changes the process noise of the closed-loop sys-
tem (4) from η(k) to ˜η(k) = [w(k)T ν(k)T ]T such that

˜η(k)

E

(cid:26) "

v(k)#

h

Σw 0

0

˜η(k)T v(k)T

= 

0 Σν 0



=

i (cid:27)





0

0 Σv





.

˜Q 0
0 R 






The following proposition shows that with ν(k), the at-
tacker’s desired covariance matrix Σ∞ is not a steady
state solution of (8) any more.

Proposition 3 The algebraic Riccati equation (8) with
Q = ˜Q does not have Σ∞ as a steady state solution.

PROOF. With Σz(k) = Σ∞ and Q = ˜Q we obtain

s.t.

AzΣ∞AT

z + ˜Q =

AP AT + Σw 0

"

0

Σν#

,

and using this in the Riccati equation (8) leads to

Σ∞ =

AP AT + Σw − AP CT (CP CT + Σv)−1CP AT 0
0

Σν #

"

For Σ∞ to be a solution of (8) we need both

P = AP AT + Σw − AP CT (CP CT + Σv)−1CP AT ,

which, as shown previously, exists, and Σν = 0.

Since we assume Σν 6= 0, Σ∞ is not a solution of (8) any
more.

Here, we see that the attacker will not be able to perfectly
estimate the controller’s state if we use this additional

noise on the controller side even if the attacker knows
the noise properties.

Injecting ν(k) does not only lead to limk→∞ Σz(k) =
˜Σ∞ 6= Σ∞ as shown in Proposition 3 but also changes
the steady state covariance matrix of the closed-loop
system from Σ0 (see Assumption 3) to ˜Σ0. The change
in the covariance matrix, ∆Σ0 = ˜Σ0 − Σ0, is given by

∆Σ0 = A′

z∆Σ0(A′

z)T +

.

(13)

0 0

"

0 Σν#

=∆Q

Furthermore, we will quantify the performance degra-
dation in the closed-loop system (3) as tr(∆Σ0), which
represents the increase in total variation for the closed-
loop system state.

| {z }

Therefore, we formulate the following convex optimiza-
tion problem to determine Σν subject to an upper bound
γp > 0 on the performance degradation.

Proposition 4 The noise injection covariance Σν that
maximizes the controller conﬁdentiality while keeping the
performance degradation below a threshold, γp > 0, is an
optimal solution to the convex program,

tr( ˜Σ∞)

max
Σν , ˜Σ∞

T



Cz ˜Σ∞CT

Az ˜Σ∞AT

z + Q + ∆Q − ˜Σ∞ Az ˜Σ∞CT
z
Az ˜Σ∞CT
z + R#
"
z
z∆Σ0(A′
∆Σ0 = A′
z)T + ∆Q

(cid:1)
(cid:0)
tr(∆Σ0) ≤ γp,
Σν ≥ 0,


˜Σ∞ ≥ 0,

≥ 0,

(14)

where ∆Q is given in (13).

.

PROOF. First note that both the objective and the
constraints are convex in Σν and ˜Σ∞, which makes the
optimization problem a convex semi-deﬁnite program
and that problem (14) is feasible, since Σν = 0 and
˜Σ∞ = Σ∞ fulﬁl the constraints.

Next, the objective together with the ﬁrst constraint
guarantee that ˜Σ∞ is the solution to the algebraic
Riccati equation (8), since the solution to (8) is the
maximal solution to the algebraic Riccati inequality
(Ran and Vreugdenhil, 1988).

Last, the second and third constraint impose the limita-
tion on the allowed performance degradation, while the
last two constraints enforce that the covariance matrices
are positive semi-deﬁnite.

Remark 1 If a certain noise level in the controller
is desired, the constraint Σν ≥ 0 can be replaced by
Σν ≥ γcInc, where γc > 0. However, this tighter con-
straint can return an optimal ˜Σ∞ with a smaller trace
than in the case with γc = 0. Furthermore, this constraint
can make the problem infeasible, since a large γc can
interfere with the constraint on the performance bound.

Remark 2 The approach of adding some additional
noise to the system is quite similar to the watermarking
approach used, for example, in Mo et al. (2015). The
diﬀerence is that here the noise is added to the con-
troller input, while in watermarking the noise is typically
added to the output of the controller. Therefore, these
results show that if we position the watermarking noise
at a diﬀerent position we get the additional beneﬁt of
the attacker not being able to estimate the state of the
controller perfectly.

4.2 An unstable controller as defence

As shown before, Problem 1 is not solvable if and
only if ρ(Ac) > 1. Hence, designing the controller
(Ac, Bc, Cc, Dc) such that ρ(A′
z) < 1 and ρ(Ac) > 1
leads to a successful defence against the discussed dis-
closure attack.

This implies that there are plants which have an in-
herent protection against the sensor attack. For exam-
ple, all plants that are not strongly stabilizable, i.e.,
plants that cannot be stabilized with a stable controller
(Doyle et al., 2013), have an inherent protection against
the estimation of the controller’s state by the attacker.
Further, there are also control strategies that give an in-
herent protection to the closed-loop system. Disturbance
accommodation control (Johnson, 1971), where the con-
troller tries to estimate a persistent disturbance, is one
example of these control strategies.

If a plant can be stabilized by using a stable controller,
i.e., a strongly stabilizing plant, using an unstable con-
troller instead comes with several issues. A fundamental
limitation is that the integral of the log sensitivity func-
tion is zero for a stable open-loop system. If the open-
loop system has unstable poles the integral is equal to
a constant positive value that depends on the unstable
poles of the open-loop system and their directions for
a multivariable discrete-time system (Chen and Nett,
1995). As Stein (2003) shows with real world examples,
it can have dire consequences if this fundamental limi-
tation is not taken into account properly. Hence, due to
these fundamental limitation the introduction of unsta-
ble poles in the controller is not desirable. Another is-
sue of unstable controllers is that an unstable controller
leads to an unstable open-loop system, if the feedback
loop is interrupted.

Therefore, using an unstable controller for a strongly sta-
bilizing plant is not recommended, but is an appropriate

defence mechanism if an unstable controller is needed to
stabilize the plant.

5 Simulations

In this section, we verify our results with simulations
for a three-tank system. After stating the model of the
three-tank system, we ﬁrst show the eﬀect of stable and
unstable controllers on the attacker’s estimate of the con-
troller’s state. Later, we verify that the additional noise
prevents the attacker from estimating the controller’s
state perfectly.

5.1 The three-tank system

For the simulation of the closed-loop system estimation
by the attacker we look at the following continuous-time
three-tank system

−2 2

0

0.5 0

˙x(t) = 

2 −4 2



x(t) + 

0

0



u(t) + w(t),

0

2 −3





0 1 0

"

0 0 1#




x(t) + v(t).

y(t) =





0 0.5





By discretizing the continuous-time system with a sam-
pling period of Ts = 0.5 s we obtain A, B, and C. We
assume that w(k) ∼ N (0, I3) and v(k) ∼ N (0, 0.1I2).

5.2 Stable and unstable controllers

Now that the system matrices are deﬁned we are going
to verify that the controller’s stability inﬂuences the es-
timates of the controller’s state by the attacker. We con-
sider an observer-based feedback controller

xc(k + 1) = (A − BKi − LC)xc(k) + Ly(k)

u(k) = −Kixc(k)

where L is the observer gain and Ki is the controller
gain. The closed-loop system matrix is then

A′

z,i =

A

−BKi

"

LC A − BKi − LC#

.

According to Assumption 2, ρ(A′
z,i) < 1, which means
that Ki and L are designed such that ρ(A − BKi) < 1
and ρ(A − LC) < 1. The matrix L is designed via pole
placement to place the eigenvalues of A − LC at 0.1, 0.2,
and 0.3. Therefore, the error dynamics of the observer
used in the controller are stable. In the following, we
design three diﬀerent Ki such that ρ(A − BKi) < 1.

The ﬁrst controller KS places the poles of A − BKS at
0.4, 0.5, and 0.6. This ﬁrst controller results in stable
controller dynamics A − BKS − LC with ρ(A − BKS −
LC) = 0.4167.

The second controller, KU , is unstable, i.e., ρ(A−BKU −
LC) > 1, but has no modes on the unit circle. We deter-
mine KU , such that ρ(A−BKU ) < 1 and A−BKU −LC
has an eigenvalue at 1.5. The controller we obtain is

KU =

0.5530 1.9589

1.2225

"

1.8414 27.0785 −12.9349#

and it places the eigenvalues of A − BKU − LC at 1.5,
−0.5175, and −0.1066 and the eigenvalues of A − BKU
at 0.6275, 0.4272 + j0.6456, and 0.4272 − j0.6456.

For the design of the third controller, KI , we place two
eigenvalues inside the unit circle and one at 1, such that
ρ(A − BKI − LC) = 1, while guaranteeing that ρ(A −
BKI ) < 1. We obtain

KI =

3.0988 −6.0472 2.3966

"

4.0471 10.8175 −4.4516#

,

which places the eigenvalues of A − BKI − LC at 1,
−0.2227, and −0.3693 and the eigenvalues of A − BKI
at −0.2669, 0.6405 + j0.5942, and 0.6405 − j0.5942.

For the ﬁrst two controllers, the attacker designs a time-
invariant Kalman ﬁlter with gain Li
z and steady state
∞ = limk→∞ Σi(k), where
error covariance matrix Σi
i ∈ {S, U }. The attacker’s time-invariant Kalman ﬁlter
design leads to an observer gain LS
z for the closed-loop
system, which matches our results in Theorem 2. Since
KU leads to an unstable controller, we know according
to Corollary 2 that no time-invariant observer exists that
solves Problem 1. Further, Corollary 1 shows that even
if the attacker would use a time-varying Kalman ﬁlter,
Problem 1 is not solvable.

For the closed-loop system with KI , the attacker needs
to use a time-varying Kalman ﬁlter to obtain a perfect
estimate of xc(k). The error covariance matrix in this
case will converge to the same as in the case with KS.

Now that we designed the Kalman ﬁlters for each of the
three closed-loop systems, let us look at the estimation
error ez(k) = z(k) − ˆz(k) ∈ R6. Here, we are only inter-
ested in the last three elements of ez(k), because they
represent the estimation error of the controller state.
The jth element of ez(k) is denoted by ez,j(k), where
j ∈ {1, · · · , 6}. Figure 2 shows that in case of a stable
controller KS the estimation error converges quickly to
zero and the attacker obtains a perfect estimate of the
controller’s state. However, if we use an unstable con-
troller KU the estimation error remains noisy and the

1

0

)
k
(

4
,
z

e

-1

0

2

0

-2

0

5

0

-5

0

)
k
(

5
,
z

e

)
k
(

6
,
z

e

10

20

30

40

50

60

70

80

90

100

Closed-loop system with stable controller
Closed-loop system with unstable controller

10

20

30

40

50

60

70

80

90

100

10

20

30

40

50
Time step k

60

70

80

90

100

Fig. 2. Comparison of the estimation error trajectories for
the stable and unstable controller, KS and KU respectively

10-3

10-4

10-3

)
k
(

4
,
z

e

)
k
(

5
,
z

e

)
k
(

6
,
z

e

2

0

-2

0

2

0

-2

0

2

0

-2

0

1

2

3

4

5

6

7

8

9

1

2

3

4

5

6

7

8

9

1

2

3

4

5
Time step k

6

7

8

9

10
105

10
105

10
105

Fig. 3. Estimation error of the controller’s state when the
controller has a pole on the unit circle and the attacker uses
a time-varying Kalman ﬁlter

attacker is not able to obtain a perfect estimate of the
controller’s state. Furthermore, when KI is used, we
observe that the estimation error converges to zero, but
is still not zero after a million time steps (see Figure 3).
Theorem 1 only tells us that the error will converge, but
we know it does not converge exponentially by Proposi-
tion 2. Although the attacker can obtain an almost per-
fect estimate with the time-varying Kalman ﬁlter after
a million time steps, it is still not a perfect estimate.
This shows us that a controller with modes on the unit
circle can prevent the attacker from quickly obtaining a
perfect estimate.

5.3

Injecting process noise for the controller

Now that we showed how the controller design aﬀects
the attacker’s estimate of the controller’s state, we ver-
ify that injecting noise to the input of the controller pre-
vents the attacker from estimating xc(k) perfectly. Fur-
ther, we demonstrate how the choice of γp aﬀects both
the attacker’s estimate ˆxc(k), the plant’s state x(k), and
the controller state xc(k). We investigate two cases for

5

0

)
k
(

4
,
z

e

-5

0

4

2

0

-2

0

5

0

-5

0

)
k
(

1

x

)
k
(

1
,
c

x

10

20

30

40

50

60

70

80

90

100

10

20

30

40

50

60

70

80

90

100

=0.1

p

=10

p

10

20

30

40

50
Time step k

60

70

80

90

100

Fig. 4. The eﬀect of the additional noise on the ﬁrst ele-
ments of the estimation error of the controller’s state (up-
per plot), the plant’s state (centre plot), and the controller’s
state (lower plot) when a stable controller is used

the performance degradation, one with a small allowed
performance degradation, i.e., γp = 0.1, and one with
a large allowed performance degradation, i.e., γp = 10.
The operator uses the stable controller KS and the at-
tacker uses again a time-invariant Kalman ﬁlter.

The upper plot of Figure 4 shows the trajectory of the
attacker’s estimation error of the ﬁrst controller state.
Compared to Figure 2, the estimation error exhibits
noisy behaviour and the attacker is not able to obtain a
perfect estimate even though the operator uses the sta-
ble controller KS. Further, the noise around the estima-
tion error increases the larger the allowed performance
degradation is.

To see the eﬀect of the additional noise on the closed-
loop system state, we show the trajectory of the ﬁrst
element of the plant’s state, x1(k), in the centre plot
and the trajectory of the ﬁrst element of the controller’s
state, xc,1(k), in the lower plot of Figure 4. We see that
the state trajectory of the plant is not much more af-
fected by the additional noise when we allow a hundred-
fold larger performance degradation, while the controller
state becomes noisier.

The trajectories for the other elements of x(k), xc(k),
and the attacker’s estimation error of the controller state
behave similarly. Since the operator’s objective is to con-
trol the plant optimally, this defence mechanism has the
additional beneﬁt of mostly increasing the noise in xc(k)
but not considerably in the plant’s state.

Hence, the additional noise prevents the attacker from
estimating the controller’s state perfectly and addition-
ally does not considerably aﬀect the trajectory of the
plant’s state.

6 Conclusion and future work

We have shown exactly when an attacker with full model
knowledge is able to perfectly estimate the internal state
of an output-feedback controller by observing all mea-
surements.

Although it seems obvious that an attacker according
to our attack model can always estimate the controller’s
state, we gave necessary and suﬃcient conditions when
an attacker is not able to obtain a perfect estimate.
These conditions state that unstable controller dynam-
ics prevent the attacker from obtaining a perfect esti-
mate. Further, the attacker can use a non-optimal time-
invariant observer to perfectly estimate the controller
state if and only if the controller has stable dynamics.
A defence mechanisms has been proposed to make the
controller states conﬁdential. This mechanism prevents
the attacker from obtaining a perfect estimate by adding
uncertainty to the controller dynamics. This is similar
to watermarking approaches proposed by other authors
with the twist that the noise signal is applied to the
controller input and not to its output. An unstable con-
troller gives an inherent protection to plants that are
not strongly stabilizable. However, designing such a con-
troller introduces fundamental limitations on the sensi-
tivity function of the closed-loop system and should only
be used when an unstable controller is needed to stabi-
lize the plant.

There are several directions of future work. It seems ob-
vious that if the attacker has only access to a few sensors
measurements, it will not be able to estimate the con-
troller’s state. However, it is interesting to investigate
what happens if the attacker has access to some sensor
and some actuator signals, and how many of each the at-
tacker needs to get a perfect estimate of the controller’s
state. Another research direction is to investigate the ro-
bustness of the controller state estimation for cases when
the attacker has less model knowledge.

References

B. D. O. Anderson and J. B. Moore. Optimal Filtering.

Prentice-Hall, Englewood Cliﬀs, NJ, 1979.

A. A. C´ardenas, S. Amin, Z. Lin, Y. Huang, C. Huang,
and S. Sastry. Attacks against process control sys-
tems: Risk assessment, detection, and response.
In
Proceedings of the 6th ACM Symposium on Informa-
tion, Computer and Communications Security, ASI-
ACCS ’11, pages 355–366, New York, NY, USA, 2011.
ACM.

S. W. Chan, G. Goodwin, and K. S. Sin. Convergence
properties of the Riccati diﬀerence equation in opti-
mal ﬁltering of nonstabilizable systems. IEEE Trans-
actions on Automatic Control, 29(2):110–118, Febru-
ary 1984.

bra and its Applications, 99:63 – 83, 1988. ISSN 0024-
3795.

G. Stein. Respect the unstable. IEEE Control Systems

Magazine, 23(4):12–25, Aug 2003.

A. Teixeira, I. Shames, H. Sandberg, and K. H. Johans-
son. A secure control framework for resource-limited
adversaries. Automatica, 51:135 – 148, 2015.

D. Umsonst and H. Sandberg. On the conﬁdentiality
of linear anomaly detector states. In 2019 American
Control Conference (ACC), July 2019.

M. Xue, W. Wang, and S. Roy. Security concepts for the
dynamics of autonomous vehicle networks. Automat-
ica, 50(3):852 – 857, 2014.

Y. Yuan and Y. Mo. Security in cyber-physical systems:
Controller design against known-plaintext attack. In
2015 54th IEEE Conference on Decision and Control
(CDC), pages 5814–5819, Dec 2015.

J. Chen and C. N. Nett. Sensitivity integrals for mul-
tivariable discrete-time systems. Automatica, 31(8):
1113 – 1124, 1995.

C. de Souza, M. Gevers, and G. Goodwin. Riccati
equations in optimal ﬁltering of nonstabilizable sys-
tems having singular state transition matrices. IEEE
Transactions on Automatic Control, 31(9):831–838,
Sep. 1986.

S. M. Dibaji, M. Pirani, A. M. Annaswamy, K. H.
Secure control
Johansson, and A. Chakrabortty.
of wide-area power systems: Conﬁdentiality and in-
tegrity threats. In 2018 IEEE Conference on Decision
and Control (CDC), pages 7269–7274, Dec 2018.
J. C. Doyle, B. A. Francis, and A. R. Tannenbaum. Feed-

back control theory. Courier Corporation, 2013.

F. Farokhi, I. Shames, and N. Batterham. Secure and
private control using semi-homomorphic encryption.
Control Engineering Practice, 67:13 – 20, 2017. ISSN
0967-0661.

Z. Guo, D. Shi, K. H. Johansson, and L. Shi. Worst-
case stealthy innovation-based linear attack on remote
state estimation. Automatica, 89:117 – 124, 2018.
P. Hespanhol, M. Porter, R. Vasudevan, and A. Aswani.
Statistical watermarking for networked control sys-
tems. In 2018 Annual American Control Conference
(ACC), pages 5467–5472, June 2018.

C. Johnson. Accomodation of external disturbances in
linear regulator and servomechanism problems. IEEE
Transactions on Automatic Control, 16(6):635–644,
December 1971.

K. Kogiso and T. Fujita. Cyber-security enhancement
of networked control systems using homomorphic en-
cryption. In 2015 54th IEEE Conference on Decision
and Control (CDC), pages 6836–6843, Dec 2015.
D. Kushner. The real story of stuxnet. IEEE Spectrum,

50(3):48–53, March 2013.

R. M. Lee, M. J. Assante, and T. Conway. German steel

mill cyber attack. E-ISAC, 2014.

R. M. Lee, M. J. Assante, and T. Conway. Analysis of
the cyber attack on the Ukrainian power grid. defense
use case. E-ISAC, 2016.

Y. Z. Lun, A. D’Innocenzo, F. Smarra, I. Malavolta, and
M. D. Di Benedetto. State of the art of cyber-physical
systems security: An automatic control perspective.
Journal of Systems and Software, 149:174 – 216, 2019.
Y. Mo and B. Sinopoli. False data injection attacks in
control systems. In First Workshop on Secure Control
Systems, April 2010.

Y. Mo, S. Weerakkody, and B. Sinopoli. Physical authen-
tication of control systems: Designing watermarked
control inputs to detect counterfeit sensor outputs.
IEEE Control Systems, 35(1):93–109, Feb 2015.

C. Murguia and J. Ruths. CUSUM and chi-squared at-
tack detection of compromised sensors. In 2016 IEEE
Conference on Control Applications (CCA), pages
474–480, Sept 2016.

A.C.M. Ran and R. Vreugdenhil. Existence and com-
parison theorems for algebraic Riccati equations for
continuous- and discrete-time systems. Linear Alge-

