Hindawi Template version: Apr19

Security and Communication Networks

LogKernel: A Threat Hunting Approach Based on Behaviour

Provenance Graph and Graph Kernel Clustering

Jiawei Li,1 Ru Zhang,1 Jianyi Liu,1 and Gongshen Liu,2

1 Beijing University of Posts and Telecommunications, Beijing 100876, China.
2 Shanghai Jiao Tong University, Shanghai 200240, China.

Correspondence should be addressed to Ru Zhang; zhangru@bupt.edu.cn

Abstract

Cyber threat hunting is a proactive search process for hidden threats in the organization's
information system. It is a crucial component of active defense against advanced persistent
threats (APTs). However, most of the current threat hunting methods rely on Cyber Threat
Intelligence(CTI), which can find known attacks but cannot find unknown attacks that have
not been disclosed by CTI. In this paper, we propose LogKernel, a threat hunting method
based on graph kernel clustering which can effectively separates attack behaviour from
benign activities. LogKernel first abstracts system audit logs into Behaviour Provenance
Graphs (BPGs), and then clusters graphs by embedding them into a continuous space using a
graph kernel. In particular, we design a new graph kernel clustering method based on the
characteristics of BPGs, which can capture structure information and rich label information
of the BPGs. To reduce false positives, LogKernel further quantifies the threat of abnormal
behaviour. We evaluate LogKernel on the malicious dataset which includes seven simulated
attack scenarios and the DAPRA CADETS dataset which includes four attack scenarios. The
result shows that LogKernel can hunt all attack scenarios among them, and compared to the
state-of-the-art methods, it can find unknown attacks.

1. Introduction

Advanced Persistent Threats (APTs) have the characteristics of persistence and concealment.
These threats can bypass the Threat Detection Software (TDS) and lurk, so the enterprises
information system may contain attacks that have already occurred but have not been
detected. To better prevent and respond to such attacks, Endpoint Detection and Response
are widely deployed for enterprise security. However, these tools rely on
(EDR) tools
matching low-level Indicators of Compromises (IOCs), which leads to ‘alarm fatigue’
problem and failure to reveal the complete attack scenario. To overcome this challenge,
recent research solutions hunt for cyber threats by perform a causality analysis on audit logs
logs imply high-level
[1,2,3,4]. In fact, causality and contextual
behaviours and goals of attackers that are difficult to hide.

information in audit

Threat hunting is a proactive search process for latent attacks, which has become a key
component of mitigating APT attacks. Existing work extracts attack behaviors from threat
intelligence and designs matching algorithms to search for these known attacks from audit
logs. To achieve this, some work [1,5] constructed audit logs as provenance graphs that

1

Hindawi Template version: Apr19

contain rich contextual information and model threat hunting as a graph matching problem.
Besides, THREATRAPTOR [4] designs Threat Behavior Query Language (TBQL) to query
audit logs stored in the database. However, both graph matching and querying with TBQL
need to extract attack behaviors from threat intelligence. These extracted attack behaviors are
structured as attack graphs, in which nodes represent IOCs and edges represent IOC relations.
These methods rely heavily on threat intelligence, which leads to some limitations. On the
one hand, when there are deviations between threat intelligence and facts, attack activities
may be missed. On the other hand, the description of the same APT attack event may come
from different reports, so the information in these reports may be different or contradictory.
Furthermore, attacks in threat intelligence are not comprehensive. Many APT attacks have
not been disclosed by threat intelligence, and APT groups will upgrade cyber weapons or
change intrusion strategies when attacking new targets. We refer to the above two cases as
unknown attacks, and existing methods cannot detect these attacks.

Some solutions of investigating attack, such as matching rule knowledge base [2,6] or
employing tag strategy [7,8], require manual participation of domain experts. And the
completeness and accuracy of the expert knowledge will affect the analysis result. To
overcome the above problem, Nodoze[9] builds an Event Frequency Database to replace the
rule knowledge base, which considers that audit events related to attacks occur infrequently.
However, to avoid detection, attackers will disguise themselves as normal behaviors or use
some normal processes, such as svchost.exe, which affect the accuracy of methods for
calculating threat scores based on matching or single event frequency.

To solve these problems in threat hunting, this paper proposes LogKernel, a threat hunting
approach based on graph kernel clustering. It does not require additional expert knowledge to
evaluate the threat in provenance graphs, nor does it require knowledge in threat intelligence
to search for threat behaviors. Our first key insight is that there is a considerable discrepancy
between the behavior of attackers and normal users, which is intuitively reflected by the
disparity between the topological structure in provenance graphs. Therefore, LogKernel first
log into Behavior Provenance Graphs (BPGs) which can represent
abstracts the audit
different behaviors. Then, it uses a graph kernel method to calculate the similarity between
BPGs. However, the off-the-shelf graph kernel methods cannot be used directly, since the
BPG is a kind of labelled directed graph with multiple types of directed edges. Therefore, we
propose the BPG kernel, which is improved by the Weisfeiler-Lehman kernel and can capture
the graph topology and the rich label information. Based on the calculated kernel values
which indicates the degree of similarity, we cluster the BPGs by a clustering algorithm. Our
second key insight is that the frequency of benign behaviors is much higher than that of threat
behaviors, providing a basis for determining which clusters represent threats. Therefore,
LogKernel determines which clusters represent threats based on the number of similar
behaviors. Finally, considering false positives caused by low-frequency normal behaviors, a
threat quantification method is proposed to estimate the degree of BPGs.

We evaluate the effectiveness and accuracy of LogKernel using three different datasets.
In
the first malicious dataset, we simulate seven attack scenarios, three from open APT reports
and two complex attacks based on current attack techniques and strategies. In addition, we
also execute two cyber weapons. Then we use the DAPRA CADETS dataset released by the
Transparent Computing program to evaluate the applicability of LogKernel. Finally, we
evaluate the false positives of our method on benign dataset that do not contain attacks and
verify that the threat quantification method has a good performance in reducing false
positives. The results show that LogKernel can hunt the attack scenarios effectively, and

2

Hindawi Template version: Apr19

compared to the state-of-the-art methods relaying on Cyber Threat Intelligence (CTI), it can
find unknown attacks.

In summary, this paper makes the following contributions:

is proposed in this paper, which is a system that hunts for threats in
1. LogKernel
organization’s information systems.
require additional expert
knowledge and manual participation of domain experts. Meanwhile, it finds threats by
comparing differences between behaviors, rather than matching similar attacks in logs with
attack behaviors extracted from threat intelligence. Compared to most threat-hunting methods,
LogKernel can hunt unknown attacks .

The system does not

2. A novel Behavior Provenance Graph abstract algorithm is designed to construct BPGs
from audit logs. In order to better represent the behavior characteristics, nodes and directed
edges in BPGs are assigned labels based on the attributes of logs. Additionally, a novel
density-based partitioning method is proposed to mitigate the impact of dependency
explosion.

3. This is the first time that a graph kernel clustering method is proposed for threat hunting.
In this paper, a novel graph kernel clustering approach are presented to measure the similarity
between BPGs and cluster similar BPGs into one group. The graph kernel method is designed
based on the WL kernel and message passing ideas, which can capture the topological
structure of BPGs and quantify the similarity between BPGs efficiently and accurately.

4. We design a process to evaluate the effectiveness and accuracy of LogKernel. The
performance of each stage is analyzed on several datasets and compared with other methods.
The results show that Logkernel can hunt threats like other work. Furthermore, it can hunt
unknown threats as well.

2. Related Work

2.1. Threat Hunting

Provenance analysis. Our work relays some ideas in provenance analysis, so we introduce
prior work in this area. The idea of constructing a provenance graph from kernel audit logs
was introduced by King et al[10]. Then, the provenance graph is widely used for threat
hunting, attack detection [11,12], attack investigation [13,14,15] and scenario reconstruction
[16,17]. All these researches encountered a variety of challenges.

For attack detection, the main challenge is that the graph size grows continuously as APTs
slowly penetrate a system. UNICORN [12] uses a graph sketching technique to summarize
long-running system execution to combat slow-acting attacks. Attack investigation mainly
traces the root causes and ramifications of an attack through causal analysis. OmegaLog[14]
bridges the semantic gap between system and application logging contexts, and merges
application event
the universal provenance
graph(UPG).The challenges of attack scenario reconstruction is the semantic gap between the
low-level logs and the attack behavior. Holmes [2] maps low-level audit logs to TTPs and
APT stages by matching the rules in knowledge base. WATSON [3] infers log semantics
through contextual information and com-bines event semantics as the representation of
behaviors. It also can reduce analysis workload by two orders of magnitude for attack

logs with system logs

to generate

3

Hindawi Template version: Apr19

investigation. Nevertheless, the amount of audit logs generated by a typical system is
nontrivial, limiting the efficiency of log analysis and resulting in dependency explosion [19].
To solve this problem, resent researches have proposed execution unit partition [20,21], taint
propagation [22,21], grammatical
inference [23,18], and universal provenance [14]
techniques. These researches can perform more accurate provenance tracking and reduce
storage and time overhead. The scope of LogKernel differs from these researches, since we
intend to hunt unknown threats via the comparison between the BPGs.

Threat hunting. Threat hunting is becoming an essential element of active defence against
advanced persistent threats. POIROT [1] constructs query graph by extracting IOCs together
with the relationships among them from CTI reports. Then, the query graph is used to match
Its core contribution is the
the most similar subgraph in the provenance graph.
implementation of the above process via an in-exact graph matching algorithm. However, the
query graph of POIROT requires time-consuming manual construction by cyber analysts.
THREATRAPTOR [4] provides an unsupervised, light-weight, and accurate NLP pipeline
that can extract structured threat behaviors from unstructured OS-CTI texts. It designs Threat
Behavior Query Language (TBQL) to facilitate threat hunting in system audit log data.

Extracting threat knowledge from CTI reports and matching them in audit logs can facilitate
threat hunting. However, the above researches can only hunt known attacks disclosed by CTI
reports. In fact, there are still some APT attacks that have not been discovered or disclosed.
To hunt these unknown threats, a threat hunting method based on graph kernel clustering is
proposed, which can hunt for unknown threats without knowledge of CTI reports.

2.2. Graph kernel

Graph kernels are kernel functions that compute the inner product of a graph [24], which can
be intuitively understood as functions measuring the similarity of pairs of graphs. The graph
kernel [25] approach was proposed by Thomas Gaertner for graph comparison. There is a
huge amount of work in this area due to the prevalence of graph-structured data and the
empirical success of kernel-based classification algorithms [26].

Compared with traditional machine learning methods, graph kernels allows kernelized
learning algorithms such as support vector machines to work directly on graphs without
extraction to transform them into fixed-length, real-valued feature vectors, which loses a lot
of structured information. In this paper, a new graph kernel method is proposed, which can
capture structure information and rich label information of labeled directed graphs.

Figure 1: Illustration of the kernel-based graph mapping

4

Hindawi Template version: Apr19

: G×G→

Let G be a graph set and
exists a map
denotes the inner product of H and
shows a graph kernel implicitly mapping graphs to a Hilbert space H.

be a function associated with a Hilbert space H, so there
for all
is said to be a positive definite kernel function. Figure 1

 1, 2 =  1 ,  2

G → H with

1, 2 ∈

G. Then

· , ·

∅:

ℝ





Given a graph
L denotes the set of labels of nodes. For a node

, where V denotes the set of nodes, E denotes the set of edges and

, we define neighbourhood N

'

is the degree of node

|(, ') ∈ 
()| = ()

 = (, , )
} to denote the set of nodes to which v is connected by an edge, and then
() =


N
{ 
|
The most important and well-known of these strategies is the Weisfeiler-Lehman (WL)
algorithm and kernel [27]. In this paper, WL subtree graph kernel is selected and improved to
calculate the kernel values between the nodes of the graphs. The basic idea of kernel
calculation is as follows:



.

First, we assign an initial label
is

and in unlabeled graph it is a degree, i.e.

0



()

1

.

2

0

to each node of

and

. In labeled graph this label

 ∈ 

Next, we iteratively assign a new label to each node base on the current labels within the
node’s neighborhood:



() = ()

(1)



−1
 = ((
Where the double-braces are used to denote a multi-set.
in multiple-set in ascending order, and then
maps S to a new label which has not been used in previous iterations.

 | ∈ ()}})))
is added to the front of the set.

 , ({{



−1



(S) realizes sorting the elements

()
After running K iterations of re-labeling, we now have a label
for each node that
summarizes the structure of its K-hop neighborhood. Then we can summary statistics over
these labels and calculate the kernel values.








−1


Message Passing Graph Kernels [28] is a graph kernel framework which consists of two
components. The first component is a kernel between vertices and the second component is a
kernel between graphs [16]. Let
be a kernel between
neighborhoods. Then, compute the kernel
between each pair of vertices iteratively and the

recurrence is shown below:

be a kernel between nodes and






(2)

Where
vertices for T iterations, we can compute a kernel between graphs as follows:

are nonnegative constants. After computing the kernel between each pair of

and

1, 2 +  (1 , (2))

+1



1, 2 = α

α



 12 =  12
In this paper, we propose a BPG kernel on the framework to calculate the similarity between
BPGs. Specifically, we improve the WL kernel based on the characteristics of BPGs for
and get a
calculating the kernel values between nodes. Then, we compute the
positive definite kernel matrix
, which can be considered as a similarity matrix in a
Hilbert space.

 12

×

(3)

5

Hindawi Template version: Apr19

Figure 2: The provenance graph for the macro viruses attack scenario. Rectangles represent processes,
diamonds represent IPs, and rounded rectangles represent files

3. Motivation

In this section, we introduce the motivation of the approach. We first use an attack example
to illustrate the challenges and limitations of the threat hunting based on provenance analysis,
and then analyse the feasibility of our approach.

3.1. Limitations and Challenges

An Attack Scenario. Ever since macros were introduced, they have been maliciously
exploited by hackers. More recently, macros have also been widely used as attack vectors by
advanced Persistent Threat (APT) organizations [29]. To avoid detection, macro viruses use
process hollowing [30]. Next, we will introduce an attack scenario using macro viruses.

Consider a scenario where a worker in an organization read emails and download attachments
(such as Office files or zip packages) every morning. One of the emails is a phishing email
with a zip file attached. The worker unzips the package and opens the document containing
the macro instructions. At the same time, the macro virus begins to work. First, the virus
releases a PE file named t2.tmp and executes it. Then the tmp file uses process hollowing
techniques to inject malicious code into explorer.exe and svchost.exe, which tests the
connection to the C&C servers. After that, svchost.exe queries the registry and collects host
information. Finally, the process encrypts the information and sends it to the C&C server in
POST mode.

System audit logs record the OS-level operation such as writing file, executing process and
connecting IP address. Specifically, we can abstract a triple (Subject, Object, Relation) from
audit logs, where Relation is an operation, Subject is the entity executing operation and
Object is the entity being operated. These triples are used to build a provenance graph [9] for
tracking information flows in audit logs. Figure 2 demonstrates the complete scenario
represented by a provenance graph, with the red dotted boxes representing the execution of
the macro virus and the black dotted boxes representing the normal behavior of the worker.

6

Hindawi Template version: Apr19

Figure 3: Two different Behavior Provenance Graphs. Check mail is A normal behavior and Word Macro
Virus is a threat behavior

Based on the above attack scenario, We illustrate the limitations and challenges of existing
threat hunting and attack investigation approach:

Dependency Explosion. Most existing approaches or systems based on provenance graph
face the dependency explosion problem. The main reason for this is that some processes have
a long lifetime and iterative input/output processes. For example, mailbox client process
receives and sends a large number of emails during its lifetime [19]. The process is
considered as a single node in the provenance graph, which results in threat behavior and
normal behavior appearing in the same graph. As shown in Figure 2, the attack behavior in
the red dotted box is constructed in one graph with normal behavior due to mailmaster.exe.

Relay on Knowledge. In essence, both the rule knowledge base and threat intelligence rely
on knowledge to match the threat behavior in the provenance graphs. Unfortunately, some
situations in practice can cause the threat path to break. For example, the rule matching
methods miss the hollowed svchost.exe and explorer.exe, resulting in the threat path
interruption. In addition, many audit behaviors of attackers are common in the audit logs of
normal users, such as writing office files or connecting to the external network, and attackers
use some techniques to disguise themselves to avoid detection. This condition leads to a low
threat score calculated based on the frequency of a single event. Another obvious problem is
that they can only hunt threats described by existing knowledge.

3.2. Feasibility Analysis

Two different behaviors described in Figure 3 intuitively reflect our first key insight.
Checking email is a normal behavior that happens frequently. The topology of the BPG
describing macro virus behavior varies substantially from normal behavior such as the label
of nodes and the relationships between nodes. In fact, the topology implies high-level
behaviors and goals. Because the purpose of the attacker is different from that of the normal
user, the actions taken by the attacker and the causal relationship between the actions are also
different. For example, the topology of sending a macro virus is similar to checking email,
but the causal relationship between subsequent operations implicitly includes the attacker's
purpose of disguising himself and stealing information. Thus, we can compare the similarity
between the provenance graphs of different behaviors to separate advanced threats from
benign activities, and model threat hunting as a clustering problem of labeled directed graphs.

7

Hindawi Template version: Apr19

Figure 4: Overview of LogKernel

We design an algorithm in Section 4.1 to extract BPGs from audit logs to describe different
behaviors. Then we choose the graph kernel to implement our graph clustering task, which is
a popular method for measuring the similarity between graphs. However, the existing graph
kernel cannot be directly used to perform the similarity measurement due to two reasons.
First, the BPGs nodes not only have distinct types, but also contain attributes that are
significant for determining similarity. Besides the type of edges is also a critical feature.
Second, the graph kernel method is typically used for classification tasks and the data are
balanced samples, while the number of graphs in each cluster of BPG clustering tasks vary
greatly. An unsupervised graph kernel clustering approach is proposed in Section 4.2.

4.Approach

The overall approach of LogKernel is shown in Figure 4, which consists of three phases:
BPGs construction, Graph Kernel Clustering and Threat assessment. First of all, LogKernel
analyses audit logs for information on entity types, attributes and relationships between
entities. According to the information, logs are constructed as BPGs, which describes various
behaviors. Next, the similarity between the BPGs is calculated through an improved graph
kernel, and the BPGs are clustered using a clustering algorithm. Finally, abnormal behavior is
identified based on the frequency of similarity behavior. In order to reduce false positives, a
threat quantification method is introduced to assess risk.

4.1 Behavior Provenance Graph Construction

The construction process of the Behavior Provenance Graph (BPG) is described in detail in
this section. The BPG is proposed to represent different behaviors in this paper. Compared to
the existing work [1-4], nodes and edges of BPG are assigned appropriate labels to represent
the characteristics of behaviors. As discussed in Section 3.1, long-running processes cause
false dependencies in the provenance graph, which causes different behaviors to appear in the
same graph. So, a density-based partitioning method is proposed to remove false
dependencies to generate more concise BPGs.

Definitions 1. Behavior Provenance Graph (BPG):

the labeled directed graph

represents the Behavior Provenance Graph, where
indicates the label set of nodes.

represents the node set of
 =
is the directed

system entities,
(, , , )


 = {

  }

 = {| ∈ }

8

Hindawi Template version: Apr19

Figure 5: Subgraphs of BPGs to illustrate the importance of Node Label

is a label set, where

edge set, and
denotes operation
between entities. The entity types and relationships between entities in this work are shown in
Table 1. In fact, a BPG describes the information flow of a certain behavior at the system
level. For example, a BPG can represent the complete process of downloading an attachment
in an email, modifying it, and forwarding it.

 = {: ℎ}

 = {}

Table 1: Entity types and relationships

Start Node

End Node

Relationships

Process

IP
User

File
IP
Process

User
Process

Read; Write; Execute
Connect
Create

Logon
Execute

Definitions 2. Node Label: Node labels are used to indicate the characteristics of behaviors.
Relationships can be used directly as the label of the edge, such as
.
However, the entity type cannot be directly used as the node label, which will ignore the rich
 = {: }
attribute information of the entity. Rich attribute information and relationships imply the
purpose of behavior, but some information is not useful for similarity calculation. For
example, the same malware executed in different hosts may have different paths and names
of the generated files.

To measure the similarity between BPGs, the attribute information of the entity is mapped to
labels and assigned to nodes. Function GETNODE in algorithm 1 abstracts attribute information as
labels. For process, the label is process name, such as mailmaster.exe and svchost.exe. The
label of the file only considers the file type and not the path information. For example,
report.doc and data.xls in D:\download\ are assigned the same label of office file. The label
of IP is address and port, while the label of User is the user’s name. Function GETEDGE
abstracts the relation as edge and operation as the label of edge.

An example is presented below to illustrate the importance of Node Label. As shown in
Figure 5, there are three subgraphs of BPGs. (a) and (b) denote behaviors that normal users
download and unzip the zip files from the emails, and (c) denotes the behavior of macro virus
releasing PE file. (a) and (c) are isomorphic when only node types with distinct forms are
considered. Consider another scenario where the entity attributes are directly used as the label

9

of the node, such as %name%.docx. In this case (a) and (b) will be considered as different
behaviors due to the labels.

Hindawi Template version: Apr19

Figure 6: Density-based partitioning method. The dependencies are expressed as points on the time axis.

In order to extract BPGs that describe different behaviors, a forward depth-first search (DFS)
is performed on the provenance graph. File type nodes are the starting point of DFS, because
they only appear at the end of the directed edges, as illustrated in Table 1. In the process of
traversing the graph, two operations are performed to prevent false dependencies. First, we
compare the time of directed edges to prevent information flowing from a future event to a
past event. Second, the long-running processes are partitioned to remove false dependencies
and achieve the segmentation of the provenance graph.

To partition the long running process, density-based partitioning method is proposed. In other
words, the long-running process is partitioned by the density of dependencies during its life
cycle. A common phenomenon at the system level is that when a process has dependencies
on multiple entities in a short period of time, these dependencies belong to the same behavior
instance. The dependencies are expressed as points on the time axis for calculating their
density, as shown in Figure 6. Note that the edges from and to node are separately calculated.
is the time when the
indicate the timestamp of the occurrence of the i-th

is the time when the first dependency appears, and

last dependency appears. Let

dependency, and calculate a time interval sequence



, where

denotes the time interval between adjacent dependencies. The formula for calculating the
 = +1 −

 = {1, 2, . . . , }



density of the i-th node is as follows:


 =

−
−1+

When the density of the node is high, it suggests that there exist dependencies in a short
period of time before and after this node. We traverse all the nodes and consider continuous
dependencies with the density higher than the average density as belonging to the same
behavior instance. In this process, the long running process is divided into several partition
units.

(4)

The edges to node are also divided into different execution partitions through the above
process. Ultimately, we judge which edges belong to the same behavior instance. To prevent
information flowing from a future event to a past event, the time of edges to node should be
denotes the time when the
before the edges from node, which is shown by

last dependency occurred in the execution partition, and
denotes the time when the first

dependency occurred in the execution partition.








.

< 


10

Hindawi Template version: Apr19

In order to construct BPGs, a graph abstraction algorithm is proposed. First, the algorithm
obtains entity information from audit logs, as shown in Lines 3 through 7. The function
GETNODETYPE determines the type of entity in the log, and then GETTYPENODE extracts
attributes based on the entity type

. NodeList stores the attributes of all entities for the construction of BPGs.
 = {, , _ ∗
Next, function GENERATEGRAPH generates provenance graph and assigns labels to nodes and
,  ∗ }
edges. Finally, function SPLITGRAPH performs forward depth-first search (DFS) on the
provenance graph and partitions the long-running processes which is described in the above
section.

4.2 Graph Kernel Clustering

BPG kernel is proposed in this paper to calculate the similarity between behavior provenance
graphs. It consists of two components. The first component is an improved WL kernel to
calculate kernel values between nodes, and the second component is to calculate the kernel
values between graphs.

The traditional WL graph kernel is only suitable for the undirected graph. An improved WL
kernel is proposed to calculate kernel values between nodes in directed label graphs. The
improved kernel only compares each node's multi-label set without label compression.
Considering the type of directed edges, a kernel function for comparing directed edges is
proposed. The kernel value is calculated by multiple iterations, which is more helpful to
distinguish nodes in different BPGs. The improved WL kernel is described in the following.

and

First, according to definition 1,

is a labeled directed graph. The elements in
are strings, which are not suitable for the process of multiset-label sorting and label
compression in WL method. Therefore, we convert the string label sets into numeric label

sets, in which each string element corresponds to a unique value. By this means, each node in
.
G is assigned an initial numerical label

 = (, , , )



0

Next, we iteratively assign a new label to each node. The traditional WL graph kernel gets
the multiset from the label set of neighborhoods, which does not consider the relationship
between nodes. BPG kernel improves WL kernel by introducing multiset of edges. Given a



()

11

Hindawi Template version: Apr19

and N
node
,
and the multiset is
is the numerical
 ∈ 

label of edge. Like the WL kernel, the elements of multiset are sorted in ascending order, and
then

−1
is added to the front of the set.

() = { |(, ) ∈ 
() = {((, ), 

denotes the neighbour node set of

}, where N

(, )

 )| ∈

N
()

, where

()}

0



()

Then, we calculate the kernel values between nodes. It is necessary to take full account of the
particularity of BPGs, that similar behavior graphs are not completely isomorphic. Therefore,
, The
set
calculation formula is as follows:

is calculated by comparing the label in

and

,

1 ∈ 1

2 ∈ 2

1


1, 2

()

(5)

denotes the similarity of subgraphs with

1, 2 = (1) ∩ (2)

1


as the root. Finally, we compute the kernel

Where
the nodes
1

vertices iteratively, and formula is as follows:

and
1, 2
1

2

ℎℎ = 1



, which are generated by
between each pair of

+1



1, 2 = α 

is defined as the kernel value of the edge, which means that if the label
Where
of two edges is the same, the kernel value is assigned 1, otherwise it is 0. The formula is as
follows:

 1, 2

1, 2 +  1, 2 ⋅

 

1, 2

1 1


2 2 

 

(6)

 1, 2 =  
In essence, the kernel value
in which the shortest step from


achieved when T=5.

1,
0,

1, 2


 (1, 1) =  (2, 2),

(7)

ℎ.

is a quantification of the similarity of the subgraphs,
to any node is less than T. In our method, the best effect is

The second component of the BPG kernel is to calculate the kernel values between the graphs
based on the kernel value between nodes. First, we build a mapping set B
between
nodes based on the idea of optimal assignment kernel, which can provide a more valid notion
of similarity [1].
, and the mapping is only operated between nodes of
same
the

(1, 2)
, where

is the node set of

type. Then B





. Note that the mapping is
has the same type as

 =
(1, 2) = {1: 2|
from a set with fewer nodes to a set with more nodes. The formula for calculating kernel
,


max{
, 
2
values between BPGs is as follows:

1, 2 = }

,
1, 2

, 2 }

∈ 2

,
1

and

1

(8)


 12 = (1,2) 
 
Finally, a positive definite kernel matrix
and
the kernel value between
which represents pair-wise similarities (inner products) between

is
. Kernel matrix can be considered as a similarity matrix
in a Hilbert space.

is calculated by the BPG kernel, where

1, 2

×

,

and





Since the number of types of behavior abstracted from the logs is unknown, supervised
learning methods (SVM, etc.) are not suitable for our task. In this paper, a typical clustering
method called HDBSCAN [31] is employed. Compared with other clustering methods,
HDBSAN is more advisable for our data. The main reasons are as follows:1) it does not need





12

Hindawi Template version: Apr19

to declare the number of clusters in advance, 2) It has good robustness to outliers, and 3) it
supports input custom similarity(distance) matrix. In our approach, HDBSCAN code
published by McInnes L et al. [32] is adopted to implement clustering task, which takes the
kernel matrix generated by BPG kernel as input.

4.3 Threat Assessment

After clustering, the graphs representing attack behavior and normal behavior are divided into
separate clusters. According to the second key insight above, LogKernel determines which
clusters of graphs are abnormal. In order to reduce false positives, threat quantification
method is performed on abnormal BPGs to find the threat behaviors.

Determines abnormal behaviors. When the number of graphs in a cluster is less than the
, the behaviors represented by BPGs in the cluster are determined to be
abnormal behaviors. However, an obvious issue is that some of these abnormal behaviors are
ℎℎℎ
performed by normal users in low frequency, which leads to high false positives.

Threat quantification method. To overcome the above problem, Threat quantification
level of abnormal BPGs. There are several
method is proposed to evaluate the threat
characteristics of advanced cyber threats. For APT attacks, executing malicious files,
collecting sensitive information and connecting to the C&C server are necessary operations
[10]. Based on these characteristics, we design a quantification method. The execution of
malware has been implicitly expressed by BPGs, so our method uses malicious domain name
access, sensitive information acquisition and privilege escalation as the criteria for threat
quantification.

First, the threat values of IP and URL are quantified through public databases and the
frequency of appearances in audit logs. An online database of malicious IP [43] and Alexa
Traffic Rank [44] are employed to identify unsafe web resources, and then some IP that
cannot be determined are assigned scores by frequency. Secondly, different threat values are
assigned to different types of sensitive information, such as account information, sensitive
databases, and sensitive files. These are generally labeled within enterprises or automatically
identified by tools [33]. Finally, it is a critical step for the attacker to elevate the user's
privileges or login as a higher-privileged user such as root, which provides a prerequisite for
the attacker's subsequent operations. The final threat quantification formula is as follows:

(9)



denotes the threat values of IP and URL,

ℎ_ = =1

 




+ 


+ 

represents the quantification of user
Where

represent
denotes the quantification of sensitive information.
permissions and

the weight of three criteria, which can be adjusted according to actual requirements.
Ultimately, we rank the threat score of the abnormal BPGs. If the threat score exceeds a
threshold value, Logkernel determines that the BPGs represent threat behavior and raises an
alarm.

, and 







13

Hindawi Template version: Apr19

5. EVALUATION

5.1 Experimental Datasets

We evaluate LogKernel’s efficacy and accuracy on three datasets.1) A malicious dataset,
which comes from the real work environment and contains 7 attack scenarios. 2) The
DAPRA CADETS dataset, which is a public dataset. 3) A benign dataset, which comes from
the real work environment without cyber-attacks.

Attack Scenario

Description

Key nodes and operation

Table 2: Attack scenarios in the malicious dataset.

OceanLotus [34]

APT28[35]

Kimsuky[36]

Unknown attack 1

Unknown attack 2

cyber weapons

system,

detection

Using phishing mails to deliver a
malicious payload and a malicious
sample, and decrypt the sample to load
additional data. Then releasing the
white application file of the adobe
reader. after loading it connects to
C&C sever.
Using the macro file to release the
Trojan file and modify the registry to
realize self-starting after booting. Then
encrypting the collected files and
sending them back.
Using process injection to evade the
intrusion
then
escalating privileges to obtain host
information, and finally sending it to
C&C sever.
Using phishing emails
to deliver
macro virus samples, which release PE
files and perform process hollowing.
collected
Finally
encrypting
to C&C
information and sending it
sever (Attack Scenario)
Using weak passwords for
remote
login. Then getting higher privileges
user
information in the host and
accessing the registry information.
Finally,
collected
exfiltrating
information over FTP to remote
servers
Using two homologous cyber weapons
with no initial intrusion and delivery
phases, and seeing what happens when
logs are incomplete

the

Node:{hat file, %random%.exe, %deceive %.docx，dll files, C2 sever}
Operation {execute hat file, release Malicious files and deceive document,
connect C2}

Node {%macro%.xls, %Trojan%.exe, %malicious%.dll, C2 sever}
Operation {execute macro, decrypt Trojan, release malicious dll, connect
C2}

{%malicious%.scr,

Node
privileges, C&C sever }
Operation {execute malicious scr, write registry, inject code to process,
connect C2}

explorer.exe(Process Hollowing),

registry,

Node {%macro%.doc, %PE%.tmp, explorer.exe&snchost.exe (Process
Hollowing), C2 sever}
Operation {download&execute macro, process hollowing, encrypted
information, connect C2}

Node {remote user, root, C2 sever}
Operation {remote login, login root, encrypted information, connect C2}

Malicious dataset. In order to obtain the dataset containing attacks, we added some hosts and
virtual machines to the existing work environment and collected audit logs from all hosts in
the work environment. Like in previous work [1-5], we simulated seven attack scenarios on
these hosts and virtual machines, as shown in Table 2. Among them, three real attack
scenarios come from the public APT report, two synthetic APT scenarios are designed based
on the attack methods and strategies in the public report, and also two homologous cyber
weapons from third-party releases are used [34]. To simulate real attack scenarios, we set the
attack time span to 7 days and continuously executed extensive ordinary user behaviors and
underlying system activities in parallel to the attacks on the added hosts and virtual machines.
We used ETW to collect logs in Windows system, and use camflow [42] to collect logs in
Linux system.

In the malicious dataset, in addition to attack behaviors, the normal behaviors mainly include
remote login, mail checking, code modification and execution, and software installation, etc.

14

Hindawi Template version: Apr19

DAPRA CADETS. DAPRA CADETS dataset [38] is released by the DARPA Transparent
Computing program, which contains APT attacks. The dataset was collected from hosts
during DARPA's two-week red team vs. blue team Engagement 3 in April 2018 [39]. In this
engagement, some normal operations such as SSH login, Web browsing and email checking
will be executed on the hosts. At the same time, attackers will use various APT attack method
to penetrate the system and steal privacy information. The attacks on CADETS were
executed four times, resulting in 44,404,339 system level audit entries.

Table 3: Attribute information of the above three datasets

Datasets

Size

logs

graphs

Attack

Benign

Malicious dataset
CADETS
Benign dataset

10.3GB 8,796,458
35.7GB 44,404,339
15.6GB 13,446,341

7
4
0

1867
1683
2453

Table 4: Clustering result of some scenarios

Scenario

Min
Distance

number of
graphs

accuracy

OceanLotus[35]
APT28[36]
Kimsuky[37]
Unknown attack 1
Unknown attack 2
Cyber weapons
Check mails

11.468
10.734
9.278
3.136
5.121
4.257
0.594

1
1
1
1
1
2
483

100%
100%
100%
100%
100%
100%
72.3%

Benign dataset. Benign dataset comes from the real work environment. We collect system
audit logs of common user behaviors and low-level service activities during two weeks. The
main behaviors performed by these users include connecting SSH, executing code, browsing
web sites, and downloading files. To better verify the applicability of the method, we
collected audit logs from two GPU servers at the same time, including the behavior of
ordinary users and administrators. The attributes of the above three datasets are shown in
Table 3.

are set to 3 and
In all the experiments, the values of
3600 respectively. This choice is described in detail in section 5.3. The performance is
ℎℎℎ
evaluated on the malicious dataset and CADETS dataset. The threshold values are validated
on benign dataset.

ℎℎ

and

5.2 Experimental Result

In this section, the performance of LogKernel is evaluated by a large number of experiments
on the malicious dataset and CADETS dataset. First, the accuracy of graph kernel clustering
is analyzed and visualized. Next, we evaluate the threat quantification method to demonstrate
its effectiveness in eliminating false positives. Then, the accuracy of hunting threats was
analyzed. And we conduct several sets of comparative experiments to illustrate the
effectiveness of the BPG and BPG kernel proposed in this paper in threat hunting. Finally, we
analyse and discuss the advantages of LogKernel compared with other methods.

5.2.1 accuracy of graph kernel clustering

15

Hindawi Template version: Apr19

Figure 7: 2D visualization of mutual reachability distance and outliers indicate threat BPGs.

Figure 8: The influence of different thresholds on the results.

The accuracy of the graph kernel clustering indicates whether the attack behaviors are
successfully separated from the normal behaviors. After the BPGs are abstracted, the threat
BPGs are marked, which is used to track intermediate results. At the same time, the normal
BPGs of checking mails are also marked. Figure 7 shows the 2D visualization of mutual
reachability distance and outliers indicate threat BPGs. Table 4 shows the clustering result,
where Min Distance represents the minimum distance from other clusters, and Number of
Graphs indicates the number of BPGs that denote the attack scenarios and behaviors. For
example, the closest dot to Kimsuky is Unknown Attack 1, as shown in Figure 7. The reason
is that they both use process hollowing techniques for explorer.exe and the collected host
information is encrypted and sent back to the C2 server. In the Behavior Provenance Graphs
of the two scenarios, the subgraphs describing the above behaviors are similar, so the
distance between the two graphs is relatively close. However, there are also many dissimilar
parts in these two graphs, so they are not clustering in the same cluster.

Checking mails behaviors are further analyzed. Due to the differences in subsequent
operations caused by different attachment types, the BPGs containing mail-related processes
are divided into multiple clusters. However, some BPGs that do not contain mail processes
appear in these clusters, along with checking mail BPGs in other clusters. The reason is that
the behavior for some attachments is more similar to the behavior in other class clusters.

16

Hindawi Template version: Apr19

Finally, the accuracy of the check mails is 72.3%. The above situation does not affect our
final results. This paper focuses on clustering the threat BPGs into the correct clusters, and
the results show that the clustering for the threat BPGs is 100%.

5.2.2 Evaluate Threat Quantification Method

To evaluate the performance of threat quantification methods in reducing false positives, we
conduct experimental evaluations on the malicious dataset and CADETS dataset. In the
scenarios of using and not using the threat quantification approach, we count the number of
false negatives, true negatives and false positives in the result. Furthermore,
is also critical to avoid false signals. We select six values (1-6) to evaluate the impact on the
ℎℎℎ
result.

The result is depicted in Figure 8. When the number of graphs in the cluster does not exceed
the threshold of graph, these graphs are determined to be abnormal behaviors. As the
threshold increases,
the number of false alarms also increases. When using the threat
quantification method, the number of false alarms is significantly reduced. The number of
false alarms can be reduced to 0 by selecting an appropriate threat score threshold. This
demonstrates that the use of the threat quantification method in LogKernel can effectively
reduce false alarms caused by low-frequency abnormal behaviors.

5.2.3 Accuracy of Hunting Threat

Then the accuracy of the LogKernel is analyzed, and Table 5 shows the hunting results on
two datasets. It can be seen that LogKernel can hunt all attack scenarios without false
positives. In the malicious dataset, five complete attack scenarios appeared in five different
clusters, and two homologous cyber weapons were clustered in the same cluster. Among
these clusters, the maximum number of graphs is 2 which is lower than the
value
of 3. However, there are multiple clusters where the number of graphs is not greater than 3.
The graphs in these class clusters represent behaviors that users rarely perform. For example,
in order to install a program on the mobile phone, a worker accesses the relevant file from
social software to the mobile phone. The above behavior appears only twice in the malicious
dataset. We perform threat quantification on these anomalous behaviors and find that the
threat values of non-threatening behaviors are all below the threshold.

ℎℎ

The threat quantification of the above graphs shows that the threat scores of all threat BPGs
exceed the threshold, while those of normal low-frequency behaviors had threat values well
below the threshold. Finally, LogKernel successfully hunts all threats without false positives
on malicious dataset and CADETS dataset.

The effectiveness of LogKernel is evaluated by several comparative experiments that mainly
contain the following two parts. First, the existing graph kernel methods is compared with
BPG kernel proposed in this paper. Note that
these graph kernel algorithms are not
specifically designed for BPGs, and we use the public codes [40,27,28] to calculate the
similarity between BPGs. Second, we consider two other cases of abstracting graphs and
compare them with BPGs to illustrate the importance of abstracting attribute information as
Node Label which is introduced in section 4.1. The first is no label graphs which hide the
node labels of BPGs and only considering the type of nodes. The second is attribute label
graphs. Instead of mapping the attribute information to Node Label, we use the attribute

17

Hindawi Template version: Apr19

information directly as the label of the nodes to get the attribute label graphs. For example,
C:\Windows\System32\%name%.dll represents the attribute information of a file object.

The results of comparative experiments are shown in Table 5. When only the node type is
considered, false negatives are generated. When the logs are constructed as attribute label
graphs, it results in a lot of false positives in our approach. Besides, the traditional WL kernel
and MPGK AA are compared with BPG kernel. The number of iterations of the two kernel is
set 5 which can put the best results. MPGK AA employs the theory of valid optimal
assignment kernels for developing kernel based on Message Passing Graph Kernels, and its
code is published on GitHub [41]. As shown in Table 5, the performance of LogKernel
outperforms MPGK AA and WL kernel.

Table 5: Hunting results on Malicious dataset and CADETS dataset

Dataset

Graph Kernel

Graph type

Malicious
dataset

CADETS
dataset

BPG Kernel

BPGs
No label graphs
Attribute label graphs

WL Kernel[39,26]

BPGs

BPGs
No label graphs
Attribute label graphs

BPGs

MPGK AA[27]
BPG Kernel

WL Kernel

MPGK AA

Recall

100%
57.1%
100%
85.7%
42.9%

100%
25%
100%
75%
50%

Precision

F-score

100%
57.1%
43.8%
50%
30%

100%
20%
50%
42.9%
33.3%

100%
72.7%
60.9%
63.2%
35.3%

100%
22.2%
66%
54.6%
40%

Figure 9: Determine the optimal threshold values.

5.2.4 Approach Comparisons

Compared with the state-of-the-art approaches (e.g. Poirot [1] and THREATRAPTOR[3]),
LogKernel can hunt known attacks, such as three attack scenarios simulated from the APT
reports and four attacks in CADETS. Additionally, LogKernel can also hunt for unknown
attacks that have not been disclosed by threat intelligence. For example, unknown attack 1 is
designed by us in combination with the attack characteristics of multiple APT organizations.
Since this attack scenario does not appear in threat intelligence, current methods based on
threat intelligence cannot hunt this attack. We used the attack scenario to represent the
upgrading of attack technology by APT organizations and the attacks that have not been
discovered or disclosed.

18

Hindawi Template version: Apr19

Compared with WATSON[3], which can abstract high-level behaviors from audit logs and
reduce the analytical workload of attack investigations, LogKernel focuses on comparing and
clustering behaviors to realize threat detection. WATSON’s purpose is to abstract high-level
behavioral and semantic information from contextual information in audit logs. The method
applies heuristics to specify system entities as termination conditions for DFS during the
extraction subgraph phase, which causes the complete behavior to be split into multiple
subgraphs.

5.3 False positive analysis

Determine the Optimal Threshold Value. The selection of the threshold value is critical to
reducing false alarms. For example, too low the threat score threshold could cause some
normal behaviors to be misclassified as attack behaviors, while too high the threshold could
result in false negatives.

Thus, there is a trade-off in choosing an optimal threshold value. To determine the optimal
threshold value, we measured recall, precision and F1-score using varying threshold values,
as shown in Figure 9. When the

and the

ℎℎℎ = 3

, the F1-score, the harmonic mean of precision and recall, is at its peak. In fact,
ℎℎℎ ∈
3387 is the maximum score of the normal Behavior Provenance Graph, and 3743 is the
[3387,3743]
the
minimum score of the threat Behavior Provenance Graph. Another reason we set
to 3 is to consider the homology of malware, although this is not the scope
of our work. When executing homologous malwares, attack Behavior Provenance Graphs
ℎℎℎ
with similar topological structures will be generated, which means when homologous
malware is discovered in the information system, it will be classified into the same cluster.
as the optimal
Therefore, we set the
threshold values.

and

ℎℎℎ = 3

ℎℎ = 3600

Evaluation on Benign Dataset. We use the benign dataset to validate the threshold values
and LogKernel. The benign dataset comes from the real work environment. Despite the fact
that cyber-attacks are not included in the dataset, there are some normal behaviors that do not
occur frequently. Besides, workers are inquisitive to open some domains that are not
frequently accessed, or use higher-privileged users to access secret information or execute
processes during work. As a result, we execute LogKernel on the benign dataset. Inevitably,
LogKernel recognizes some abnormal behaviors that occur infrequently. However, when we
quantify the threat of these abnormal BPGs, the highest threat score is 2980, well below the
threshold. Compared to real attacks, these abnormal behaviors have a shorter path and only
involve several types of untrusted IPs, user privilege escalation, and sensitive information,
but not all of them. Therefore, their threat score cannot reach the threshold.

5.4 SYSTEM PERFORMANCE

To measure the performance of LogKernel, we record the running overhead of the system on
malicious datasets and DAPRA CADETS. The scale and magnitude of these two datasets are
similar to user data within an organization or enterprise. The runtime overhead of the system
is divided into two parts: the first part is the overhead of reading all the audit logs from disk
and generating the BPGs, and the second part is the overhead of finding the threat behavior
from the BPGs. We perform the experiments on a server with an Intel(R) Xeon(R) Silver
4215R CPU (with 8 cores and 3.20 GHz of speed each) and 256 GB of memory running on
Ubuntu 18.04.5 LTS.

19

Hindawi Template version: Apr19

Table 6 LogKernel performance overhead

Attack
cases

cadets_1
cadets_2
cadets_3

Size on
Disk

11.1 GB
17.7 GB
6.77 GB

BPGs construction
time

25min28s
40min53s
19min47s

Graphs Size

Search Time

Nodes

133.1K
171.1K
94.9K

Edges

295.6K
408.3K
171.9K

Size

57.6MB
78.5MB
35.2 MB

134.24s

10.3GB

22min19s

106.2K

183.6K

42.9MB

94.62s

Datasets

DAPRA
CADETS

Malicious
dataset

BPGs construction. In DAPRA CADETS, attacks are carried out in three different time
periods, so the BPGs were constructed from three segments that are divided according to the
attack cases, as shown in Table 6. Attacks simulated in the malicious dataset overlap in time,
so they are not segmented by attack cases. Table 6 shows LogKernel performance overhead.
The third column shows the initial size of the logs on disk, and the fourth column represents
the time it takes to read the audit logs from disk into memory and construct the BPGs. The
runtime overhead of BPGs construction depends on the number of audit logs and the
operating system. In addition, the current experiment uses a single host, and the efficiency of
the system can be further improved by parallel processing of multiple hosts. The fifth column
represents the size of the constructed graph, including the number of nodes and edges and the
size on the hard disk.
Threat searching. The sixth column represents the time spent hunting threats on both
datasets. This time includes graph kernel clustering and threat quantification. In the hunting
stage, we combined all the graphs of the three cases in the CADETS dataset for search. The
results in the table show that analysing the BPGs constructed by 34.5GB large-scale log data
and finding all the attacks in it can be completed in a relatively short time (134.24s).
Comparing LogKernel with POIROT and THREATRAPTOR’s fuzzy search mode, the total
running time of these three systems is of the same order of magnitude. And LogKernel is
faster than POIROT when processing the same size of data.

5.4 CASE STUDY

In order to understand the hunting process of LogKernel more intuitively, we consider
Kimsuky[36] as a case study from Table 5. For the attack scenario, we manually analyze the
accuracy of BPGs and evaluate the performance of LogKernel.

In this case, the infection starts with a classic executable filewith scr extension, which is used
by Windows to identify Screensaver artifacts. A worker intends to implement a function in
the project, so he downloads similar code from the public website for reference, but this zip
file contains malware scr file. It writes a dll file and sets the registry key to gain persistence.
Then the explorer.exe injection performs by the dll file to avoid Anti-Virus detection. Finally,
the malware contacts the C&C sever and sends back the encrypted information about the
compromised machine. At the same time, the worker also downloads documentation, data
samples, and installs Python.

As shown in the black dashed box in Figure 10, the complete provenance graph is generated
and chrome.exe is a long running process causing false dependencies between multiple
behavior instances. LogKernel's graph abstraction algorithm successfully separates these
behavioral instances according to the density and occurrence time of the related dependencies.
A normal exe file appears in the Kimsuky BPG because it occurs close to the download of the
zip file, but its impact is almost negligible. The PDF and CSV files come from the same
website, and the worker downloads both files at about the same time, so they are considered

20

Hindawi Template version: Apr19

Figure 10: Case study to analyze the accuracy of BPGs and evaluate the performance of LogKernel

to belong to the same BPG. After a long time, the worker downloaded and installed Python
from the official website, which is a new behavior instance.

Then LogKernel computes the kernel values between these BPGs and clusters them. As
shown in Figure 10, the topological structure of Kimsuky BPG is quite different from that of
normal BPGs, which leads to the low kernel value between them. After clustering, there are
many behaviors of downloading pdf and csv files in a certain cluster. However, since Python
was installed only twice during the experiment, it was judged to be abnormal behavior.

Finally, LogKernel quantifies Kimsuky and Installing Python BPGs to achieve threat hunting.
Because installing Python does not involve these three operations, the threat score is well
below the threshold. In Kimsuky BPG, the attacker host information contains some labeled
sensitive information, which makes the threat score higher than the threshold. Even if we
design new methods of leaking data, such as using a network disk which does not appear in
the threat report, LogKernel can still find the unknown threat.

6. DISCUSSION & LIMITATIONS

In this section, some limitations and possible extensions of LogKernel will be discussed.

The basic assumption of our method is that audit logs are trusted and cannot be tampered or
destroyed. In fact, this is an important assumption for almost the entirety of recent work in
provenance-based forensic analysis. Ensuring the integrity of audit logs is beyond the scope
of this work. In addition, LogKernel cannot detect attacks that do not use system call
interfaces because these cannot be captured by the underlying provenance tracker. But such
behaviors appear to be rare, and the harm they can bring to the rest of the system is limited.
Finally, LogKernel cannot hunt the attacks exploiting OS kernel vulnerabilities.

For LogKernel, the definition of labels requires some manual involvement. For common file
types, we can use the extension to automatically assign the file's label, such as *.zip, *.rar are
marked as zipped file. For some uncommon file types, manual participation of experts is
required to assign appropriate label to such files. In fact, after manually labeling this type of
file, automatic labeling can be performed later.

The density-based partitioning method in this paper is less accurate than the existing
execution partitioning system [19,20,21]. These systems require complex binary program

21

Hindawi Template version: Apr19

analysis to instrument a target application for execution partitioning at runtime [15]. During
the experiment, there will be some normal behavior instances that are not separated from the
threat behavior, such as the exe file in the case study. However, the errors produced by our
method do not have a decisive impact on the results.

LogKernel is an offline system that analyses audit logs of Windows and Linux systems. It
still scales well for other formats of logging. Extra work is simply to extract entities and
relationships.

7. CONCLUSION

In order to reduce the dependence on additional expert knowledge and hunt unknown attacks,
this paper proposes a threat hunting approach based on graph kernel clustering, which
consists of three parts: BPGs construction, Graph Kernel Clustering and Threat Assessment.
First, a graph abstraction algorithm is proposed to construct Behavior Provenance Graphs
(BPGs), in which a density-based partitioning method is proposed to alleviate the dependency
explosion problem. Second, based on the characteristics of the BPGs, a BPG kernel is
proposed which can capture structure information and rich label information, and then
HDBSCAN is used to perform the clustering task. Finally, LogKernel determines which
clusters are abnormal, and the threat quantification method is performed on abnormal BPGs
to hunt
the threat behaviors. Experiments are carried out on three datasets containing
simulated APT attacks, unknown attacks, public attack datasets and a large number of normal
behaviors. Experimental results show that our method can hunt all threats in the dataset, and
can detect unknown attacks compared with the method based on threat intelligence.

Data Availability

The data DAPRA CADETS supporting this paper are from previously reported studies and
datasets, which have been cited. These prior studies (and datasets) are cited at relevant places
within the text as references [38, 39]. The processed data are available from the
corresponding author upon request.

The other data used to support the findings of this study are available from the corresponding
author upon request.

Conflicts of Interest

The authors declare that they have no conflicts of interest.

Acknowledgments

This work is supported by National Natural Science Foundation of China U1936216,
U21B2020, and Fundamental Research Funds for the Central Universities (Beijing university
of posts and telecommunications) for Action Plan under Grant 2021XD-A11-1.

References

[1] Milajerdi S M, Eshete B, Gjomemo R, et al. Poirot: Aligning attack behavior with kernel audit records for

cyber threat hunting[C]//Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security. London, UK, 2019: 1795-1812.

22

Hindawi Template version: Apr19

[2] Milajerdi S M, Gjomemo R, Eshete B, et al. Holmes: real-time apt detection through correlation of

suspicious information flows[C]//Proceedings of the 2019 IEEE Symposium on Security and Privacy (SP).
SAN FRANCISCO, USA,2019: 1137-1152.

[3] Zeng J, Chua Z L, Chen Y, et al. Watson: Abstracting behaviors from audit logs via aggregation of
contextual semantics[C]//Proceedings of the 28th Annual Network and Distributed System Security
Symposium, NDSS. 2021.

[4] Gao P, Shao F, Liu X, et al. Enabling efficient cyber threat hunting with cyber threat intelligence[C]//2021

IEEE 37th International Conference on Data Engineering (ICDE). IEEE, 2021: 193-204.

[5] Wei R, Cai L, Zhao L, et al. DeepHunter: A Graph Neural Network Based Approach for Robust Cyber
Threat Hunting[C]//International Conference on Security and Privacy in Communication Systems.
Springer, Cham, 2021: 3-24.

[6] Wajih Ul Hassan, Adam Bates, and Daniel Marino. Tactical provenance analysis for endpoint detection

and response systems. In IEEE Security and Privacy, 2020.

[7] Md Nahid Hossain, Sadegh M Milajerdi, Junao Wang et al. Sleuth: Real-time attack scenario

reconstruction from cots audit data. In USENIX Security Symposium, 2017.

[8] Md Nahid Hossain, Sanaz Sheikhi, and R Sekar. Combating dependence explosion in forensic analysis

using alternative tag propagation semantics. In IEEE Security and Privacy, 2020.

[9] W. U. Hassan, S. Guo, D. Li, Z. Chen, K. Jee, Z. Li, and A. Bates, “Nodoze: Combatting threat alert

fatigue with automated provenance triage.” in NDSS, 2019.

[10] King S T, Chen P M. Backtracking intrusions[C]//Proceedings of the nineteenth ACM symposium on

Operating systems principles. NY, USA, 2003: 223-236.

[11] Xiong C, Zhu T, Dong W, et al. CONAN: A Practical Real-time APT Detection System with High
Accuracy and Efficiency[J]. IEEE Transactions on Dependable and Secure Computing, 2020.

[12] Han X, Pasquier T, Bates A, et al. Unicorn: Runtime provenance-based detector for advanced persistent

threats[J]. arXiv preprint arXiv:2001.01525, 2020.

[13] Alsaheel A, Nan Y, Ma S, et al. {ATLAS}: A Sequence-based Learning Approach for Attack
Investigation[C]//30th {USENIX} Security Symposium ({USENIX} Security 21). 2021.
[14] Hassan W U, Noureddine M A, Datta P, et al. OmegaLog: High-fidelity attack investigation via

transparent multi-layer log analysis[C]//Network and Distributed System Security Symposium. 2020.
[15] Kwon Y, Wang F, Wang W, et al. MCI: Modeling-based Causality Inference in Audit Logging for Attack

Investigation[C]//NDSS. 2018

[16] Hossain M N, Milajerdi S M, Wang J, et al. {SLEUTH}: Real-time attack scenario reconstruction from
{COTS} audit data[C]// Proceedings of the 26th {USENIX} Security Symposium ({USENIX} Security
17). Vancouver, Canada, 2017: 487-504.

[17] Milajerdi S M, Gjomemo R, Eshete B, et al. Holmes: real-time apt detection through correlation of

suspicious information flows[C]//Proceedings of the 2019 IEEE Symposium on Security and Privacy (SP).
SAN FRANCISCO, USA,2019: 1137-1152.

[18] Hassan W U, Aguse L, Aguse N, et al. Towards scalable cluster auditing through grammatical inference

over provenance graphs[C]//Proceedings of the Network and Distributed Systems Security
Symposium(NDSS). San Diego, United States, 2018.

[19] Lee K H, Zhang X, Xu D. High Accuracy Attack Provenance via Binary-based Execution

Partition[C]//NDSS. 2013: 16.

[20] Ma S, Zhai J, Wang F, et al. {MPI}: Multiple perspective attack investigation with semantic aware

execution partitioning[C]//26th {USENIX} Security Symposium ({USENIX} Security 17). 2017: 1111-
1128.

[21] Ma S, Zhang X, Xu D. Protracer: Towards Practical Provenance Tracing by Alternating Between Logging

and Tainting[C]//NDSS. 2016.

[22] Yin H, Song D, Egele M, et al. Panorama: capturing system-wide information flow for malware detection
and analysis[C]//Proceedings of the 14th ACM conference on Computer and communications security.
2007: 116-127.

[23] Gao P, Xiao X, Li Z, et al. {AIQL}: Enabling Efficient Attack Investigation from System Monitoring

Data// Proceedings of the 2018 {USENIX} Annual Technical Conference ({USENIX}{ATC} 18). Boston,
USA, 2018: 113-126.

[24] S.V. N. Vishwanathan; Nicol N. Schraudolph; Risi Kondor; Karsten M. Borgwardt (2010). "Graph

kernels". Journal of Machine Learning Research. 11: 1201–1242.

[25] Gärtner T, Flach P, Wrobel S. On graph kernels: Hardness results and efficient alternatives[M]//Learning

theory and kernel machines. Springer, Berlin, Heidelberg, 2003: 129-143.

[26] Kriege N M, Johansson F D, Morris C. A survey on graph kernels[J]. Applied Network Science, 2020, 5(1):

1-42.

23

Hindawi Template version: Apr19

[27] Shervashidze N, Schweitzer P, Van Leeuwen E J, et al. Weisfeiler-Lehman graph kernels[J]. Journal of

Machine Learning Research, 2011, 12(9).

[28] Nikolentzos G, Vazirgiannis M. Message passing graph kernels[J]. arXiv preprint arXiv:1808.02510, 2018.
[29] TOK M S, CELİKTAS B. MuddyWater APT Group and A Methodology Proposal for Macro Malware

Analysis[J]. Bilişim Teknolojileri Dergisi, 2019, 12(3): 253-263.

[30] https://attack.mitre.org/techniques/T1055/012/
[31] McInnes L, Healy J. Accelerated Hierarchical Density Based Clustering In: 2017 IEEE International

Conference on Data Mining Workshops (ICDMW), IEEE, pp 33-42. 2017

[32] https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html
[33] https://support.huaweicloud.com/function-dsc/index.html
[34] https://github.com/sbousseaden/EVTX-ATTACK-SAMPLES/
[35] https://ti.qianxin.com/alpha-api/v2/apt-dossier/apt-report?name=5d0c89c897868c0020c593a2
[36] https://cloud.tencent.com/developer/article/1042927
[37] https://blog.yoroi.company/research/the-north-korean-kimsuky-apt-keeps-threatening-south-korea-

evolving-its-ttps/

[38] Transparent Computing Engagement 3 Data Release. https://github.com/darpa-i2o/Transparent-

Computing/blob/master/README-E3.md.

[39] DARPA Transparent Computing. https://www.darpa.mil/program/transparent-computing.
[40] Siglidis G, Nikolentzos G, Limnios S, et al. GraKeL: A Graph Kernel Library in Python[J]. J. Mach. Learn.

Res., 2020, 21: 54:1-54:5.

[41] https://github.com/giannisnik/message_passing_graph_kernels
[42] Thomas Pasquier, Xueyuan Han, Mark Goldstein, Thomas Moyer, David Eyers, Margo Seltzer, and Jean
Bacon. 2017. Practical whole-system provenance capture. In Proceedings of the 2017 Symposium on
Cloud Computing (SoCC '17). Association for Computing Machinery, New York, NY, USA, 405–418.

[43] “Google Safe Browsing,” https://developers.google.com/safe-browsing/v4/, 2018

[44] https://www.alexa.com/topsites

24

