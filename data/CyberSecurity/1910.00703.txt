9
1
0
2

p
e
S
0
3

]

R
C
.
s
c
[

1
v
3
0
7
0
0
.
0
1
9
1
:
v
i
X
r
a

Exploring how Component Factors and their
Uncertainty Aﬀect Judgements of Risk in
Cyber-Security(cid:63)

Zack Ellerby, Josie McCulloch, Melanie Wilson, and Christian Wagner

Computer Science, University of Nottingham, UK,
{zack.ellerby,josie.mcculloch,
melanie.wilson,christian.wagner}@nottingham.ac.uk

Abstract. Subjective judgements from experts provide essential infor-
mation when assessing and modelling threats in respect to cyber-physical
systems. For example, the vulnerability of individual system components
can be described using multiple factors, such as complexity, technolog-
ical maturity, and the availability of tools to aid an attack. Such in-
formation is useful for determining attack risk, but much of it is chal-
lenging to acquire automatically and instead must be collected through
expert assessments. However, most experts inherently carry some degree
of uncertainty in their assessments. For example, it is impossible to be
certain precisely how many tools are available to aid an attack. Tradi-
tional methods of capturing subjective judgements through choices such
as high, medium or low do not enable experts to quantify their uncer-
tainty. However, it is important to measure the range of uncertainty sur-
rounding responses in order to appropriately inform system vulnerability
analysis. We use a recently introduced interval-valued response-format to
capture uncertainty in experts’ judgements and employ inferential sta-
tistical approaches to analyse the data. We identify key attributes that
contribute to hop vulnerability in cyber-systems and demonstrate the
value of capturing the uncertainty around these attributes. We ﬁnd that
this uncertainty is not only predictive of uncertainty in the overall vul-
nerability of a given system component, but also signiﬁcantly informs
ratings of overall component vulnerability itself. We propose that these
methods and associated insights can be employed in real world situations,
including vulnerability assessments of cyber-physical systems, which are
becoming increasingly complex and integrated into society, making them
particularly susceptible to uncertainty in assessment.

Keywords: cyber-security · uncertainty · interval-values · intervals

1

Introduction

Cyber-security professionals play a vital role in assessing and predicting vulner-
abilities within cyber-physical systems, which often form part of an organisa-

(cid:63) Supported by EPSRCs EP/P011918/1 grant and by the UK National Cyber Security

Centre (NCSC).

 
 
 
 
 
 
2

Z. Ellerby et al.

tion’s or state’s critical digital infrastructure. As outsider threats become more
prevalent and sophisticated, there is increasing pressure on experts to provide
timely and comprehensive assessments within the context of the rapidly chang-
ing cyber-physical ecosystem. As cyber-systems increase in both ubiquity and
complexity, methods to quantify and handle error in subjective measurements
from experts need to be developed [13]. It has been demonstrated across many
industry sectors that as complexity increases accurate risk assessment decreases
[10]. Enabling the eﬀective reconstruction of overall assessments from component
and attribute ratings would streamline the process of updating overall system
vulnerability assessments, in line with shifts in this ecosystem.

Both objective and subjective measures of risk provide useful information to
aid decision making in vulnerability assessment [4,5]. Several diﬀerent methods
can be used to assess vulnerability and risk in a cyber-security system, such as
vulnerability scanning tools [18] or the Common Vulnerability Scoring System
(CVSS) [15], which gives qualitative severity ratings of low, medium, and high,
and CVSS Version 3, which extends the ratings to include none and critical [8].
However, when using CVSS, the necessary information to complete the calcu-
lation may be missing. Hubbard and Seiersen [11] argue that assessing risk in
terms of low, medium, and high ratings is highly subjective and open to error.
It is therefore suggested that cyber-security risk should be described quantita-
tively. This would help quantify what areas of risk are perceived as important to
cyber-security professionals and, from that, move towards how those risks might
correspond to the actually enacted attacks and their success or failure.

Assessment of risk or the likelihood of an attack are inherently uncertain [1,2].
Objective measures may carry uncertainty because the measures themselves are
imprecisely deﬁned [2]. Subjective assessments (collected from experts) carry
uncertainty because, for example, the experts are not familiar with the particu-
lar technology, there is inherent uncertainty caused by insuﬃcient detail in the
scenario, or due to individual personality [12,16,20].

Between-expert uncertainty is often modelled implicitly, for example, through
probability distributions [7] or uncertainty measures [5]. These methods model
the between-expert uncertainty, but they do not capture within-expert uncer-
tainty. Choi et al. [4] capture within-expert uncertainty by enabling experts to
express knowledge and uncertainty through terms such as very small, small and
large and using fuzzy sets to represent the uncertainty of these words. However,
this assumes that the experts share the same degree of uncertainty regarding
the meanings of these terms. After capturing uncertainty, it may be modelled
and handled through methods such as Dempster-Shafer evidence theory [6,9] or
fuzzy logic [4,14,19].

We propose explicitly capturing uncertainty in experts’ individual judge-
ments using an interval-valued response format, as previously introduced in [17].
Experts provide ratings along a continuous scale to quantify, for example, the
perceived diﬃculty of an attack on a component. Using an interval captures both
the experts’ rating (position on the axis) and the degree of uncertainty associated
with the response (width of the interval). Fig. 1 shows an example of a narrow

Exploring how Factors and Uncertainty Aﬀect Judgements of Risk

3

(a)

(b)

Fig. 1. Illustration of narrow (a) and wide (b) interval-valued responses capturing
diﬀerent degrees of uncertainty.

rating (slightly uncertain) and a wide rating (highly uncertain). In this manner,
uncertainty is captured as an integral aspect of the judgement itself, through
a coherent and intuitive response-format. The novel output of this paper is to
show that an interval-valued response scale can be used to eﬀectively capture
uncertainty in expert judgements, and that this can be used to better predict
both the magnitude and the uncertainty of risk in vulnerability assessments.

In this paper, we assess the importance of a variety of attributes in deter-
mining the overall vulnerability of components being attacked or evaded within
a cyber-system; these include maturity of the technology and the frequency that
a given attack is reported (the full set of attributes are listed in Tables 1 and 2).
We also capture the overall diﬃculty of attacking or evading each component.
Our core aim is to understand how the component attributes contribute to the
overall diﬃculty of an attack and, equally importantly, how uncertainty in com-
ponent attributes aﬀects not only the uncertainty in the overall vulnerability of
a component, but also the overall diﬃculty itself. For example, experts might
perceive an attack as more diﬃcult if there are fewer tools available to aid in
this eﬀort. However, experts might also perceive an attack as more diﬃcult if
they are uncertain about the availability of tools. From this, we can learn what
additional insight is gained by capturing uncertainty through interval-valued
responses. Speciﬁcally, we wish to answer

– how is overall vulnerability of a component aﬀected

• by attribute ratings?
• by uncertainty around attribute ratings?

– how is uncertainty around overall vulnerability of a component aﬀected

• by attribute ratings?
• by uncertainty around attribute ratings?

We ﬁnd that although cyber-security experts only assessed attributes that were
previously deemed likely to be important to component vulnerability, only some

020406080100veryeasyveryhardOverall,howdiﬃcultwoulditbeforanattackertodothis?020406080100veryeasyveryhardOverall,howdiﬃcultwoulditbeforanattackertodothis?4

Z. Ellerby et al.

of these attributes have a signiﬁcant eﬀect. Similarly, we discover that although
uncertainty around some attributes aﬀects the uncertainty around the compo-
nent as a whole, this is not consistent for all attributes. We also ﬁnd that the
uncertainty around some attribute ratings makes a signiﬁcant contribution to
overall vulnerability ratings themselves.

2 Methods

2.1 Data Collection

The data was collected from experts in CESG (Communications-Electronics Se-
curity Group), which was the information security arm of GCHQ (Government
Communication Head Quarters) in the United Kingdom1. A total of 38 cyber-
security experts at CESG assessed a range of components that are commonly
encountered during a cyber-attack. They rated these on both overall diﬃculty
to either attack or evade, as appropriate, and on several attributes that might
aﬀect this diﬃculty. Two types of components (also referred to as hops) were
assessed, those that require an attacker to attack the component (referred to as
attack ) and those that require the attacker to bypass the component (referred to
as evade). Examples of the hops assessed include bypass gateway content checker
and overcome client lockdown, but any hop may be assessed using this method.
Tables 1 and 2 list the attack and evade attributes, respectively (variable
notations are also provided, which are used in the next section). Attack hops are
deﬁned by seven attributes and evade hops by three attributes. In addition, both
are described by their overall diﬃculty. Our aim is to understand how the hop
attributes and the uncertainty around these attributes relate to the perceived
overall diﬃculty of attacking/evading the hop, and to the uncertainty around
this diﬃculty. Experts were asked to provide interval-valued ratings to enable
them to coherently express the uncertainty associated with their responses; these
ratings were provided on a scale from 0 to 100.

The cyber-security components chosen for this study are designed to be rep-
resentative of a mainstream government system, which would include assets at
Business Impact Level 3 (BIL3) – an intermediate category of impact [3]. CESG
describes such a system as typically including remote site and mobile working,
backed by core services and back-end oﬃce integrated systems, such as telemetry
devices and associated systems used by the emergency services. Compromising
assets at BIL3 might have large-scale negative eﬀects, including but not limited
to: disruption to regional power supply, key local transport systems, emergency
or other important local services for up to 24 hours, local loss of telecoms, risk to
an individual’s safety, damage to intelligence operations, hindrance to low level
crime detection and prosecution, or ﬁnancial loss to the UK government or a
leading ﬁnancial company in the order of millions (GBP) [3].

1 CESG has since been replaced by the NCSC (National Cyber Security Centre).

Exploring how Factors and Uncertainty Aﬀect Judgements of Risk

5

Table 1. Attributes used to describe attack hops, the question used in the study, and
the variable name used in the analysis.

var attribute

description

c

t

f

a

d

r

g

o

complexity

interaction

frequency

How complex is the target component (e.g. in terms
of size of code, number of sub-components)?

How much does the target component process/interact
with any data input?

How often would you say this type of attack is reported
in the public domain?

availability of tool

How likely is it that there will be a publicly available
tool that could help with this attack?

inherent diﬃculty

How inherently diﬃcult is this type of attack? (i.e. how
technically demanding would it be to do from scratch,
with no tools to help.)

maturity

How mature is this type of technology?

going unnoticed

How easy is it to carry this attack out without being
noticed?

overall diﬃculty

Overall, how diﬃcult would it be for an attacker to do
this?

2.2 Analysis

We use linear mixed eﬀects modelling (an extension of linear regression) to deter-
mine the contribution of each of the hop attributes, as rated by experts, to overall
hop diﬃculty. We also assess the contribution of the associated uncertainty in
these ratings, captured through the interval-valued response-format. The mid-
point (m) of the interval-valued response is used as a single-valued numeric
rating of the attribute, and the width (w) of the response is used to represent
the uncertainty around this rating. Note, of course, that higher widths are only
possible towards the centre of the scale. That is, as the midpoint approaches
the edge of the scale, a wide interval cannot exist. Also, note that while experts
provided ratings in the range [0, 100], these data were standardised, through
z-transformation, before entry into the model.

This approach estimates the contribution of each attribute’s midpoint and
width together upon the same outcome variable, in the form of β weights. These
variables are entered as ﬁxed eﬀects. The inclusion of random intercepts also
allows the model to account for potential between expert and between hop dif-
ferences in baseline ratings. In addition, this technique allows us to examine the
combined eﬀects of attribute rating and uncertainty (e.g. high certainty may have
an opposite eﬀect on overall diﬃculty when relating to a high or low attribute

6

Z. Ellerby et al.

Table 2. Attributes used to describe evade hops, the question used in the study, and
the variable name used in the analysis.

var attribute

description

c

a

r

o

complexity

How complex is the job of providing this kind of de-
fence?

availability of infor-
mation

How likely is that there will be publicly available in-
formation that could help with evading defence?

maturity

How mature is this type of technology?

overall diﬃculty

Overall, how diﬃcult would it be for an attacker to do
this?

rating). We model this through the inclusion of two-way interaction terms (m·w)
pertaining to the midpoint and width of each attribute.

Four separate analyses are reported. These were conducted for the dependent

variables of

– attack hop overall diﬃculty rating (interval midpoint)
– attack hop overall uncertainty (interval width)
– evade hop overall diﬃculty rating (interval midpoint)
– evade hop overall uncertainty (interval width)

For each of these analyses, an initial model was created. These included ﬁxed
eﬀects of all hop attribute ratings, all hop attribute widths and all two-way
interactions, along with random intercepts for both expert and hop. Following
this, a stepwise variable reduction process was applied to each model, in order to
remove variables that were found not to signiﬁcantly contribute to the respective
outcome variable. β weights of the variables retained into the ﬁnal models were
then interpreted as estimates of the (signiﬁcant) contribution of each of these
factors to the respective outcome variable.

Table 1 lists the variables used to denote the attributes of attack hops. The

sum of all simple eﬀects for the attack hop attribute midpoints (ratings) is

Az

m = βz

1 xcm

i,j + βz

2 xtm

i,j + βz

3 xf m

i,j + βz

4 xam

i,j + βz

5 xdm

i,j + βz

6 xrm

i,j + βz

7 xgm

i,j

(1)

where β is the coeﬃcient, xcm
is the value m (midpoint) of attribute c (com-
i,j
plexity) for i (a given expert) and j (a given hop), and z reﬂects the model’s
outcome variable, which may be either m (midpoints) or w (widths) of the overall
diﬃculty.

The sum of all simple eﬀects for the attack hop attribute widths (uncertainty)

is

Az

w = βz

8 xcw

i,j + βz

9 xtw

i,j + βz

10xf w

i,j + βz

11xaw

i,j + βz

12xdw

i,j + βz

13xrw

i,j + βz

14xgw

i,j

(2)

Exploring how Factors and Uncertainty Aﬀect Judgements of Risk

7

where xcw
j (a given hop).

i,j is the width w of attribute c (complexity) for i (a given expert) and

The sum of the interactions between the midpoints and widths of the attack

hop attributes is

Az

15(xcm
mw =βz
19(xdm
βz

i,j · xcw
i,j · xdw

i,j ) + βz
i,j ) + βz

16(xtm
20(xrm

i,j · xtw
i,j · xrw

i,j) + βz
i,j ) + βz

17(xf m
21(xgm

i,j · xf w
i,j ) + βz
i,j · xgw
i,j )

18(xam

i,j · xaw

i,j )+

(3)

Our initial model formula to explain the overall diﬃculty rating midpoints
(γAom
i,j

) of attack hops is then

) and widths (γAow

i,j

i,j = βz
γAoz

0 + Az

m + Az

w + Az

mw + µz

i + µz

j + (cid:15)z
i,j

(4)

where z reﬂects the model’s outcome variable, which may be either m (mid-
points) or w (widths), for expert i on hop j; β0 denotes the ﬁxed intercept; µi
and µj denote respective random intercepts for expert and hop; and (cid:15) repre-
sents the error. The remaining β terms (within Am, Aw and Amw) denote the
coeﬃcients of the ﬁxed eﬀects of the hop attributes.

We perform likewise calculations for the evade hops (variables listed in Table

2). The sum of eﬀects for the midpoints of the evade hops is

Ez

m = βz

1 xcm

i,j + βz

2 xam

i,j + βz

3 xrm
i,j ,

for the widths is

Ez

w = βz

4 xcw

i,j + βz

5 xaw

i,j + βz

6 xrw
i,j ,

and for the interactions is

Ez

mw = βz

7 (xcm

i,j · xcw

i,j ) + βz

8 (xam

i,j · xaw

i,j ) + βz

9 (xrm

i,j · xrw
i,j )

(5)

(6)

(7)

Our initial model formula to explain the overall diﬃculty ratings for midpoints
(γEom
i,j

) of evade hops is then

) and widths (γEow

i,j

i,j = βz
γEoz

0 + Ez

m + Ez

w + Ez

mw + µz

i + µz

j + (cid:15)z

i,j.

(8)

Each of the initial models, as presented above, was then subjected to a back-
wards stepwise variable elimination procedure. During this, ﬁxed eﬀects were
iteratively assessed and those that did not signiﬁcantly contribute to the overall
model were removed. Speciﬁcally, this process began by selection, from the pool
of all non-signiﬁcant ﬁxed eﬀects, of the eﬀect with the t-statistic closest to zero.
This variable was then removed, and the resulting model directly compared with
the preceding one, using the Theoretical Likelihood Ratio test. This was imple-
mented through the MATLAB f itlme and compare functions. If the beneﬁt of
retaining the variable in question was calculated to be non-signiﬁcant, then the
model with the lower Bayesian Information Criterion (BIC) was retained into
the next iteration. This procedure continued until a ﬁnal model was determined,
within which all ﬁxed eﬀects were statistically signiﬁcant.

8

Z. Ellerby et al.

3 Results

3.1 Attack Hops

Table 3 shows all eﬀects retained in the ﬁnal model with the outcome variable of
overall attack hop diﬃculty (midpoints), following the stepwise variable reduc-
tion process. These results indicate that a number of factors make a substantial
contribution. Attacks were rated less diﬃcult if they are frequently reported or
have a large availability of tools. By contrast, attacks were rated as more diﬃcult
if they have a greater inherent diﬃculty or relate to more mature technologies.
Attacks were also rated as more diﬃcult when technological maturity was un-
certain and, perhaps surprisingly, when easier to go unnoticed. The latter might
relate to some underlying factor - for instance, some attacks may be diﬃcult
to conduct, but also diﬃcult to detect. The signiﬁcant interaction term (m · w)
indicates a combined eﬀect of reported tool availability and uncertainty around
this. This likely reﬂects that a hop is rated as being more diﬃcult to attack when
experts are certain about availability being low, but less diﬃcult when experts
are certain about availability being high. Unsurprisingly, the inherent diﬃculty
rating was found to have the most robust eﬀect.

Table 3. Results showing signiﬁcant eﬀects of hop attribute midpoints (m), widths (w)
and two-way interactions (m · w) on midpoints of overall attack hop diﬃculty ratings.

Fixed Eﬀects Estimates

β

SE

t

p

Intercept : (0)
Frequency m : (xf m
i,j )
Availability Tool m : (xam
i,j )
Inherent Diﬃculty m : (xdm
i,j )
Maturity m : (xrm
i,j )
Going Unnoticed. m : (xgm
i,j )
Maturity w : (xrw
i,j )
Availability Tool m · w : (xam

i,j · xaw
i,j )

.175

.012 .066
.861
-.223 .044
-5.065 < .001
-4.574 < .001
-.201 .044
.357 .030 11.890 < .001
4.159 < .001
.126 .030
5.194 < .001
.142 .027
.009
2.612
.071 .027
.031
2.168
.077 .036

Random Eﬀects Estimates

Expert intercept (i)
Hop intercept (j)

Residual (cid:15)i,j

µ

.183
.204

.502

N = 532, DF = 524, AIC = 896.7, BIC=943.6

Table 4 shows all eﬀects retained in the ﬁnal model with the outcome variable
of uncertainty surrounding overall attack hop diﬃculty (widths). Even more fac-
tors were retained in this ﬁnal model. Results indicated that experts were more
certain about the vulnerability of hops on which attacks were reported more fre-
quently - likely due to familiarity. They were also more certain regarding hops
that relate to mature technologies or when tool availability is low. By contrast,

Exploring how Factors and Uncertainty Aﬀect Judgements of Risk

9

Table 4. Results showing signiﬁcant eﬀects of hop attribute midpoints (m), widths
(w) and two-way interactions (m · w) on widths of overall attack hop diﬃculty ratings.

Fixed Eﬀects Estimates

β

SE

t

p

Intercept : (0)
Frequency m : (xf m
i,j )
Availability Tool m : (xam
i,j )
Maturity m : (xrm
i,j )
Frequency w : (xf w
i,j )
Availability Tool w : (xaw
i,j )
Inherent Diﬃculty w : (xdw
i,j )
Going Unnoticed w : (xgw
i,j )
Maturity m · w : (xrm
i,j · xrw
i,j )
Going Unnoticed m · w : (xgm

i,j · xgw
i,j )

.392
-.857
-.031 .036
.009
-2.614
-.116 .045
.003
2.934
.131 .045
-3.013
.003
-.093 .031
4.034 < .001
.141 .035
.016
2.420
.095 .039
.406 .037 10.959 < .001
7.399 < .001
.268 .036
-3.484 < .001
-.122 .035
.024
-2.270
-.080 .035

Random Eﬀects Estimates

Expert intercept (i)
Hop intercept (j)

Residual (cid:15)i,j

µ

.127
.000

.609

N = 532, DF = 522, AIC = 1066.3, BIC=1121.7

overall uncertainty signiﬁcantly increased in line with attribute uncertainty for
reported attack frequency, tool availability, inherent diﬃculty, and ease of going
unnoticed. Two interaction terms were also retained, indicating that the eﬀects
of uncertainty around these attributes on overall uncertainty were signiﬁcantly
modulated by attribute rating, or vice versa. These can be interpreted together
with main eﬀects, depending upon direction. For example, in the case of ease of
going unnoticed, there is a relatively large positive main eﬀect of attribute un-
certainty and a smaller, but signiﬁcant, negative interaction term. This indicates
that overall ratings were most uncertain when going unnoticed was considered
diﬃcult but uncertain. However, overall ratings were most certain when going
unnoticed was considered diﬃcult with certainty. The eﬀect of attribute un-
certainty was reduced, though still substantial, around hops rated as easier to
go unnoticed when attacking. For maturity, however, there is a negative main
eﬀect of attribute rating and a negative interaction term, of comparable size.
This indicates that overall uncertainty was greatest when maturity was rated
low but uncertain. Also, while an increase in maturity rating tended to increase
the certainty of overall ratings, this eﬀect was driven by cases in which maturity
was itself uncertain. Of all eﬀects in this analysis, uncertainty surrounding the
inherent diﬃculty rating was found to be the most robust.

3.2 Evade Hops

Table 5 shows all eﬀects retained in the ﬁnal model with the outcome variable of
overall evade hop diﬃculty (midpoints). Four ﬁxed eﬀects were retained. Experts

10

Z. Ellerby et al.

Table 5. Results showing signiﬁcant eﬀects of hop attribute midpoints (m), widths (w)
and two-way interactions (m · w) on midpoints of overall evade hop diﬃculty ratings.

Fixed Eﬀects Estimates

β

SE

t

p

Intercept : (0)
Availability Information m : (xam
i,j )
Maturity m : (xrm
i,j )
Availability Information w : (xaw
i,j )
Complexity m · w : (xcm

i,j · xcw
i,j )

-.173

-.023 .133
.863
-.240 .049 -4.895 < .001
3.459 < .001
.177 .051
.004
.142 .049
2.878
.047
-.105 .053 -1.993

Random Eﬀects Estimates

Expert intercept (i)
Hop intercept (j)

Residual (cid:15)i,j

µ

.457
.340

.772

N = 418, DF = 413, AIC = 1081.8, BIC=1114.0

Table 6. Results showing signiﬁcant eﬀects of hop attribute midpoints (m), widths
(w) and two-way interactions (m · w) on widths of overall evade hop diﬃculty ratings.

Fixed Eﬀects Estimates

β

SE

t

p

Intercept : (0)
Complexity w : (xcw
i,j )
Availability Information w : (xaw
i,j )
Maturity w : (xrw
i,j )

-.000 .058
-.000 > .999
.241 .046 5.200 < .001
.440 .045 9.683 < .001
.003
.134 .045 2.982

Random Eﬀects Estimates

Expert intercept (i)
Hop intercept (j)

Residual (cid:15)i,j

µ

.070
.159

.643

N = 418, DF = 414, AIC = 863.0, BIC=891.2

rated a hop as less diﬃcult to evade when more information is available to
aid with this, but more diﬃcult to evade when they were uncertain about the
availability of such information. Overall evasion diﬃculty was also higher for hops
relating to more mature technologies. A negative interaction term was evident
for ratings of hop complexity, with certainty around a more complex hop being
associated with it being more diﬃcult to evade, but certainty around a hop
being less complex associated with it being easier to evade. The availability of
information was found to be have the most robust eﬀect.

Table 6 shows all eﬀects retained in the ﬁnal model with the outcome variable
of uncertainty surrounding overall evade hop diﬃculty (widths). These results
show that experts were more uncertain in their overall hop rating when they
were more uncertain about each of the three attributes of a given hop: complex-
ity, information availability, or maturity. However, no signiﬁcant main eﬀects

Exploring how Factors and Uncertainty Aﬀect Judgements of Risk

11

of attribute rating position, nor any interaction terms were found. Uncertainty
surrounding information availability was found to have the most robust eﬀect.

4 Conclusions

We analyse ratings provided by cyber-security experts that pertain to a range
of potentially important component (hop) attributes, previously identiﬁed as
commonly occurring within attack vectors of mainstream government cyber-
systems. Importantly, these ratings were obtained through interval-valued re-
sponses, which enable experts to indicate both their rating and the uncertainty
associated with this rating in a single, integrated response.

Our analyses provide a ‘proof of concept’ for interval-valued data capture
applied to the ﬁeld of cyber-security. We identify key factors that contribute
to both component vulnerability and uncertainty, depending on whether a hop
requires compromising or only bypassing. For example, the availability of infor-
mation has the largest impact on the overall diﬃculty of evading a component,
while uncertainty around the inherent diﬃculty of an attack has the largest
impact on its overall uncertainty.

Uncertainty in experts’ attribute ratings is found to be valuable in determin-
ing not only overall uncertainty, but also overall hop vulnerability. In a number
of speciﬁc cases, this information explained variance over and above the discrete
midpoints of attribute ratings. For instance, when predicting the overall diﬃ-
culty of attack hops, uncertainty around the maturity of technology of a given
hop was associated with a signiﬁcant increase in diﬃculty rating for that hop.
In other cases, we found that in order to best explain overall diﬃculty ratings it
was necessary to consider an interaction eﬀect, between the position and width
of responses. Sometimes, the combination of both factors provided a better pre-
dictor than either did alone. It was the novel use of an interval-valued response
format that made it possible to coherently capture this uncertainty, alongside
traditional ratings.

This study provides initial empirical evidence for the potential added-value
oﬀered by capturing interval-valued responses to model expert uncertainty. This
is demonstrated in the case of modelling vulnerabilities within cyber-systems
comprising multiple components, each with varying attributes, as is characteris-
tic of cyber-physical systems. The beneﬁt of using interval-valued responses was
found using a comparatively low-complexity linear modelling approach. While
such an approach is unsuited to capturing varying eﬀects of responses along the
response scale (for instance, it cannot account for a tendency for responses to
saturate towards the extremities), its simplicity facilitates interpretation of the
results. In future work, we will investigate the use of generalised additive mod-
els, within which the relationships between independent and dependent variables
may be non-linear. Additionally, we are pursuing an ongoing programme of re-
search to demonstrate the eﬃcacy of interval-valued responses, both in terms of
capturing uncertainty and improving predictive power, with reference to real-
world ground-truth.

12

Z. Ellerby et al.

References

1. Aven, T., Renn, O.: On risk deﬁned as an event where the outcome is uncertain.

Journal of risk research 12(1), 1–11 (2009)

2. Black, P.E., Scarfone, K., Souppaya, M.: Cyber security metrics and measures.
Wiley Handbook of Science and Technology for Homeland Security pp. 1–15 (2008)
3. CESG: Extract from HMG IA Standard No.1 Business Impact Level Tables. CESG

(2009)

4. Choi, H.H., Cho, H.N., Seo, J.W.: Risk assessment methodology for under-
ground construction projects. Journal of Construction Engineering and Manage-
ment 130(2), 258–272 (2004)

5. Duan, Y., Cai, Y., Wang, Z., Deng, X.: A novel network security risk assess-
ment approach by combining subjective and objective weights under uncertainty.
Applied Sciences 8(3) (2018). https://doi.org/10.3390/app8030428, http://www.
mdpi.com/2076-3417/8/3/428

6. Feng, N., Li, M.: An information systems security risk assessment model under

uncertain environment. Applied Soft Computing 11(7), 4332–4340 (2011)

7. Fielder, A., Konig, S., Panaousis, E., Schauer, S., Rass, S.: Uncertainty in cyber

security investments. arXiv preprint arXiv:1712.05893 (2017)

8. FIRST: Cvss v3.0 speciﬁcation document, https://www.first.org/cvss/

specification-document

9. Gao, H., Zhu, J., Li, C.: The analysis of uncertainty of network security risk as-
sessment using dempster-shafer theory. In: 2008 12th International Conference on
Computer Supported Cooperative Work in Design. pp. 754–759. IEEE (2008)

10. Gardner, D.: Risk: The science and politics of fear. Random House (2009)
11. Hubbard, D.W., Seiersen, R.: How to measure anything in cybersecurity risk. John

Wiley & Sons (2016)

12. Kahneman, D., Slovic, S.P., Slovic, P., Tversky, A.: Judgment under uncertainty:

Heuristics and biases. Cambridge university press (1982)

13. Koubatis, A., Schonberger, J.Y.: Risk management of complex critical systems.

International journal of critical infrastructures 1(2-3), 195–215 (2005)

14. Linda, O., Manic, M., Vollmer, T., Wright, J.: Fuzzy logic based anomaly detec-
tion for embedded network security cyber sensor. In: 2011 IEEE Symposium on
Computational Intelligence in Cyber Security (CICS). pp. 202–209. IEEE (2011)
15. Mell, P., Scarfone, K., Romanosky, S.: A complete guide to the common vulnerabil-
ity scoring system version 2.0. In: Published by FIRST-Forum of Incident Response
and Security Teams. vol. 1, p. 23 (2007)

16. Miller, S., Appleby, S., Garibaldi, J.M., Aickelin, U.: Towards a more systematic
approach to secure systems design and analysis. International Journal of Secure
Software Engineering (IJSSE) 4(1), 11–30 (2013)

17. Miller, S., Wagner, C., Aickelin, U., Garibaldi, J.M.: Modelling cyber-security ex-
perts’ decision making processes using aggregation operators. computers & security
62, 229–245 (2016)

18. Munir, R., Disso, J.P., Awan, I., Mufti, M.R.: A quantitative measure of the se-
curity risk level of enterprise networks. In: 2013 Eighth International Conference
on Broadband and Wireless Computing, Communication and Applications. pp.
437–442. IEEE (2013)

19. Sikos, L.F.: Handling uncertainty and vagueness in network knowledge representa-
tion for cyberthreat intelligence. In: 2018 IEEE International Conference on Fuzzy
Systems (FUZZ-IEEE). pp. 1–6. IEEE (2018)
20. Slovic, P.: The perception of risk. Routledge (2016)

