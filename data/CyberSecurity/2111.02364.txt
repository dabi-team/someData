HoneyCar: A Framework to Conﬁgure Honeypot
Vulnerabilities on the Internet of Vehicles

Sakshyam Panda, Stefan Rass, Member, IEEE, Sotiris Moschoyiannis, Member, IEEE,
Kaitai Liang, Member, IEEE, George Loukas, Member, IEEE, and Emmanouil Panaousis, Senior Member, IEEE

1

1
2
0
2

v
o
N
3

]

R
C
.
s
c
[

1
v
4
6
3
2
0
.
1
1
1
2
:
v
i
X
r
a

Abstract—The Internet of Vehicles (IoV), whereby intercon-
nected vehicles communicate with each other and with road
infrastructure on a common network, has promising socio-
economic beneﬁts but also poses new cyber-physical threats. Data
on vehicular attackers can be realistically gathered through cyber
threat intelligence using systems like honeypots. Admittedly,
conﬁguring honeypots introduces a trade-off between the level of
honeypot-attacker interactions and any incurred overheads and
costs for implementing and monitoring these honeypots. We argue
that effective deception can be achieved through strategically
conﬁguring the honeypots to represent components of the IoV
and engage attackers to collect cyber threat intelligence. In
this paper, we present HoneyCar, a novel decision support
framework for honeypot deception in IoV. HoneyCar builds
upon a repository of known vulnerabilities of the autonomous
and connected vehicles found in the Common Vulnerabilities
and Exposure (CVE) data within the National Vulnerability
Database (NVD) to compute optimal honeypot conﬁguration
strategies. By taking a game-theoretic approach, we model the
adversarial interaction as a repeated imperfect-information zero-
sum game in which the IoV network administrator chooses a set
of vulnerabilities to offer in a honeypot and a strategic attacker
chooses a vulnerability of the IoV to exploit under uncertainty.
Our investigation is substantiated by examining two different
versions of the game, with and without the re-conﬁguration cost
to empower the network administrator to determine optimal
honeypot conﬁgurations. We evaluate HoneyCar in a realistic
use case to support decision makers with determining optimal
honeypot conﬁguration strategies for strategic deployment in IoV.

Index Terms—Honeypots, Cyber Deception, Internet of Vehi-

cles, Cybersecurity investment, Game theory, Optimisation.

I. INTRODUCTION

The Internet of Vehicles (IoV) is revolutionising the trans-
portation industry with increasing number of connected vehi-
cles. The aim is to achieve an integrated intelligent transporta-
tion system with advanced trafﬁc management to ensure road
safety, avoid road accidents and improve driving experiences.
IoV is a distributed network that utilises the data gathered
by vehicles to improve safety on roads and allow interaction

S. Panda, G. Loukas, and E. Panaousis are with the School of Computing
and Mathematical Sciences, University of Greenwich, London SE10 9LS, UK,
e-mail: {s.panda, g.loukas, e.panaousis}@greenwich.ac.uk.

S. Rass is with the LIT Secure and Correct Systems Lab, Johannes Kepler

University Linz, Linz, Austria, e-mail: stefan.rass@jku.at.

S. Moschoyiannis is with the Department of Computer Science, University
of Surrey, Guildford GU2 7XH, UK, e-mail: s.moschoyiannis@surrey.ac.uk.
K. Liang is with the Cyber Security Group, Delft University of Technology,

Delft, Netherlands, e-mail: Kaitai.Liang@tudelft.nl.

“This work has been submitted to the IEEE for possible publication.
Copyright may be transferred without notice, after which this version may
no longer be accessible.”

of vehicles with other heterogeneous networks through smart
Vehicle to Everything (V2X) communication [1]. IoV has
evolved from Vehicular ad hoc networks (VANETs) and is
expected to eventually evolve into the Internet of Autonomous
Vehicles [2].

Although connected vehicles bring beneﬁts for the passen-
ger experience and road safety, they have also introduced more
opportunities for cyber attackers to compromise the vehicles
endangering passengers and pedestrians lives. Additionally,
the growing prevalence of cyber incidents has resulted in a
strong demand for security in IoV solutions to ensure cost-
effective, scalable and robust services that conform to legal
requirements and adequately confront cyber-physical threats,
where a cyber security breach may lead to a privacy breach
or adverse physical impact [3]. Steady functioning of IoV
requires integration of many different technologies, services
and standards [4]. As vehicles become more connected to their
vulnerable and unprotected external environment, the number
of attack possibilities and the risk of a vulnerability being
exploited greatly increases. IoV thus needs to address numer-
ous security issues including threats concerning the Internet
of Things (IoT) but also new threats speciﬁc to connected
vehicular networks. Cyber deception and more speciﬁcally
honeypots have been studied within the ﬁeld of vehicular
networks, e.g., [5], [6], [7], [8].

In this paper we propose a game-theoretic framework to
address the strategic interaction between an agent that chooses
a set of vulnerabilities to implement in a honeypot and a
competing agent that selects a vulnerability for exploitation
of the targeted IoV. Numerous papers have used game theory
to model deception [9], [10], [11] and other security challenges
[12], [13]. In particular, using zero-sum games, according to
which the loss of an agent is the gain of the other agent is the
most acceptable approach in the literature, e.g., [14], [15].

Based on the target location of the attacker, attacks on IoV
are classiﬁed into two groups [16]: (i) Inter-vehicle attacks
where compromised vehicles could misbehave or falsify data
sent to other vehicles leading to drastic impact on human
lives, energy and money; and (ii) Intra-vehicle attacks that
involve deceiving a sensor or a system resulting in damage
to the vehicle and the environment. The cyber threats that
affect IoV can range from the application layer all the way
down to the physical layer. Akin to the signiﬁcant growth
and value of the autonomous and connected vehicles, there
is a growing concern about the cyber security and privacy
preservation within these systems. Smart vehicles are not
only exposed to speciﬁc risk in this context, but some of

 
 
 
 
 
 
the risks may involve risk to human life [17]. One of the
current cyber security efforts with respect to vehicles can be
found in the regulations developed within the United Nations
Economic Commission for Europe (UNECE). In particular, the
new UNECE regulations1 highlight theimportance of detection
and mitigation of cyber incidents. Threat detection, in turn,
relies on cyber threat intelligence and defensive deception as
effective means to collect information on adversaries intents
and actions [10].

Identifying risk mitigation actions is one of the main
challenges of security decision-makers in all sectors. As IoV
inherit many of the characteristics of regular computer net-
works, most of the countermeasures for computer networks
are also applicable to IoV. Some of the proposed counter-
measures include threat modelling of security risks in IoV
[18], intrusion detection systems for protection against internal
and external attacks [19], secure routing protocols [20], [21]
and privacy mechanisms [4], encryption key management [22]
and honeypots to collect adversarial information in IoV [23].
Additionally, security frameworks and standards such as the
Cybersecurity Framework for Critical Infrastructure [24] pro-
posed by the National Institute of Standards and Technology
(NIST) could be incorporated to strengthen the security of IoV.
In IoV, the authorisation and the communication modules
which handle the most critical security features are often
targeted by attackers leading to serious security, privacy, and
physical impacts. Honeypots can signiﬁcantly contribute in
protecting these systems by absorbing damage and collecting
information about attackers’ intents and actions. The knowl-
edge from honeypots can be leveraged to identify and close
security gaps, implement measures to avoid attacks on vehicles
and infrastructure, support intrusion detection and prevention
systems, and to realise a wide range of attacks and threats
to IoV. Even so, it is important to know how attackers gain
access and proceed in the network and how the vehicles and
its connected environment behave in case of such attacks.
Honeypots in general have advantages over standard intrusion
detection systems as any connection to the honeypot can
be considered suspicious thus being useful to the network
administrator in identifying threats and malicious activities.

However, a key challenge in designing honeypots is con-
vincing attackers that these are real systems [25]. As hon-
eypots do not involve regular users and usage patterns, it is
a challenge to design convincing honeypots. As highlighted
in existing literature [23], the problem can be addressed by
strategically conﬁguring honeypots such that they resemble
components of the IoV network. Further, as there is always
a limitation to the amount of resources to be invested in
cybersecurity controls, there is a need to strategically deploy
them to improve security as well as have a positive Return On
Security Investment (ROSI). To assist with security decisions,
existing literature proposes several cost-beneﬁt approaches for
selecting optimal set of countermeasures against cyber attacks
[26], [27] leading to optimal cybersecurity investment plans
[28], [29].

1UN Regulation No. 155 - Cyber
system,

security
https://unece.org/transport/documents/2021/03/

management
standards/unregulation-no-155-cyber-security-and-cyber-security

security and cyber

2

This paper proposes a novel decision support framework,
called HoneyCar, that addresses the challenges in designing
convincing honeypots. Our research is motivated by the fact
that an effective cybersecurity strategy must consider the
advancing threat landscape, which can only be achieved by un-
derstanding attackers’ actions. HoneyCar allows the decision
maker to compute optimal strategies for active re-conﬁguration
of honeypots based on a set of available vulnerabilities,
an available budget and the expected beneﬁt, in terms of
attacker engagement time, acquired through each available
conﬁguration action. Note that, we only consider long-distance
communication mode in IoV which includes most of the
critical connections concerning security [23]; in particular,
V2X which supports all the communication between a vehicle
and its environment whether it is another vehicle, roadside
infrastructure, or the cloud.

HoneyCar consists of two models: (i) a formal model of
investing in honeypot deception; and (ii) a game-theoretic
model where the decision maker (called the Defender) con-
ﬁgures a honeypot in IoV while the adversary (called the
Attacker) attempts to exploit vulnerabilities of the observed
systems in the network. The game-theoretic model presents
the strategic use of honeypots by modelling the interaction
between the Defender and the Attacker using a repeated
imperfect-information zero-sum game.

To sum up, this work makes the following contributions:
• It presents a novel decision support framework called
HoneyCar to examine practical (cost effective) honeypot
investment decisions.

• It presents a novel game-theoretic model demonstrating
the strategic use of honeypot through cost effective se-
lection and conﬁguration of honeypot based on a given
budget.

• Through a case study using vulnerabilities related to
autonomous and connected cars in the Common Vul-
nerabilities and Exposure (CVE) list of records2 with
the associated Common Vulnerability Scoring System
(CVSS) metrics3, it demonstrates how HoneyCar can as-
sist with honeypot conﬁguration and investment decisions
satisfying various objectives of using honeypots in IoV.
• It highlights the signiﬁcance of re-conﬁguration cost in
making well-informed cybersecurity investment plans.
The rest of this paper is structured as follows. Section
II presents the related work on the use of honeypots in
connected vehicular networks. It also presents an overview
on the application of game theory to honeypot deception
to secure networks and highlights how this work extends
literature. Section III introduces the honeypot
the current
deception model together with the decisions of the Defender
and the game-theoretic model for optimal conﬁguration of
honeypots. Section IV presents the mathematical analysis for
the
computing optimal honeypot conﬁgurations to support
investment decisions. Section V presents a case study using the
known vulnerabilities related to the autonomous and connected
vehicles to evaluate HoneyCar. Finally, Section VI concludes

2https://cve.mitre.org/
3https://www.ﬁrst.org/cvss/

this paper by discussing the limitations of the proposed method
and potential future work.

II. RELATED WORK

IoV have many open security problems [30] from identiﬁca-
tion and communication to standardisation [31]. These threats
challenge the privacy and security in IoV [32]. However,
research has preliminary focused on identifying vulnerabilities
in connected and autonomous vehicles and analysing the
potential impact of successful exploitation while proposing
some mitigation measures [30], [33]. Successful cyber attacks
on IoV networks have been documented including those on
security keys used in electronic control units, wireless key
fobs,
inertial measuring
tyre-pressure monitoring systems,
units, braking system, and more [34], [35], [36].

Deception is used for both defensive and offensive inter-
actions. Researchers have developed various defences against
offensive deception in connected vehicular networks such
as sybil attacks [37], false positioning attacks [38], illusion
attacks [39] and topology poisoning attacks [40]. Honey-
pots have been widely implemented in network security for
defensive deception [41], [42], moving target defence [43]
and against advanced persistent threats [44]. A broad range
of attacks on connected and autonomous vehicles could be
detected by using honeypots. These attacks could include
random attacks on the vehicles and connected infrastructure
as well as targeted attacks on IoV.

A. Honeypots for Vehicles

Honeypots have been used to identify vehicles behaving
selﬁshly to preserve their resources [5], collect adversarial
information [6], and support intrusion detection systems for
VANETs [23]. [7] highlighted the application of honeypots in
VANETs by presenting how in-vehicle honeypots and road
side unit honeypots could be used to support the security
and enhance the performance of VANETs. Verendel et al. [6]
proposed three in-vehicle honeypot models demonstrating the
use of honeypots in IoV to gather adversarial information.
Besides, [8] proposed the use of a low-interaction honeypot
together with a high-interaction honeypot to collect threat and
vulnerabilities data in connected cars. [45] proposed a physical
honeypot with cross-network access, one-to-many mechanisms
and high interaction capabilities replicating a programmable
logic controller to gather large-scale attack data.

To detect blackhole attacks in wireless mesh networks
such as VANETs and IoV, [46] and [47] used honeypots to
generate dummy route request packets to lure and isolate
blackhole attackers. Patel and Jhaveri [5], on the other hand,
used honeypot-based detection technique to identify vehicles
in VANETs behaving selﬁshly to save their resources. Our
research extends the frontier of the application of honeypots
to secure autonomous and connected vehicles. It focuses on
the strategic re-orientation of honeypots to deceive attackers
and collect threat data in IoV.

3

B. Deception

In the context of deceiving attackers by implementing
honeypots, Garg and Grosu [48] investigated the allocation
of honeypots in a network as a signalling game in which
the Defender implements k honeypots out of n possible
host systems. The goal was to deceive attackers by placing
several honeypots in the network. When attackers cannot
determine the type of systems due to deployed deception, they
either postpone the attack or spend additional resources to
determine the identity of a system. Carroll and Grosu [41]
studied a similar signalling game in which the Defender can
disguise a real system as a honeypot and a honeypot as a
real system. The authors analysed both pooling and hybrid
Perfect Bayesian Nash Equilibria while demonstrating the in-
feasibility of separating equilibria. Ceker et al. [49] build on
[41] to design a honeypot-based deception method to mitigate
distributed denial-of-service attacks. The Defender can either
choose a system to be a real system or a honeypot and the
Attacker can either observe, attack or retreat.

On the other hand, P´ıbil et al. [15] and Kiekintveld et
al. [50] investigated ways of designing honeypot systems to
optimise the probability of the Attacker choosing to attack the
honeypot rather than the real system. The authors modelled the
Defender-Attacker interaction using a zero-sum game. Their
model classiﬁed systems into different levels of importance
with assigned utilities for the Attacker where the Defender
played to minimise the Attacker’s expected value. La et al.
[9] analysed an IoT network along with a honeypot to defend
systems from attacks and extended the analysis from a single-
shot game to a repetitive game considering the deceptive
aspects of the players. While most of the aforementioned
works investigated the deceptive use of honeypots to minimise
the probabilities of attacks on the real system,
the ways
of engaging the attackers remained understudied. HoneyCar
closes this gap by looking into the use of honeypot to deceive
adversaries with the explicit goal of optimal re-conﬁguration of
the honeypot to increase Attackers’ engagement, and thereby
enhancing the information gathered on adversarial behaviour.
There are relatively fewer papers that use game theory
to optimise the information learned about attackers through
multi-round games. Zhuang et al. [51] proposed a multi-round
signalling game to investigate strategies of deception and re-
source allocation. In each round of the game, Defender decides
on investing in either short term expense or long term capital
investments in defence. To deceive the Attacker, Defender then
chooses how much of the investment information to reveal as
a signal. The Attacker on observing the signal decides whether
to attack or not. Durkota et al. [52] investigated a similar
multi-round interactions as a Stackelberg game. The Defender
plays ﬁrst by placing honeypots to harden the network. The
Attacker with knowledge on the number of honeypots but
not their identities follows the Defender. Attack graphs are
used to represent Attacker’s multi-round strategies and develop
network hardening techniques to enhance security. Unlike
most game-theoretic models of deception which are either
static games or single-shot games, we study the interaction
between the Defender and the Attacker as a multi-round

game. Also, concerning the structure of the game, the work
closest
to ours is that of Durkota et al. [52] for regular
computer networks. HoneyCar improves on this by introducing
re-conﬁguration (similar to hardening operation) of honeypot
in each round of the game to engage attackers, rather than just
placing honeypots to harden IoV network. Finally, HoneyCar
uses known vulnerabilities from the CVE records along with
the Common Vulnerability Scoring System (CVSS) metrics
to provide actionable recommendations providing decision
support to the IoV network administrator as will be shown
in Section V.

III. SYSTEM MODEL

We assume that a service provider (e.g., management ser-
vice or network provider), henceforth called the Defender,
decides to invest in honeypots to dissuade adversaries from
critical infrastructure and to capture adversarial activities. An
adversarial entity is referred to as the Attacker. To achieve
the Defender must design their honeypots such that
this,
they can successfully deceive attackers into considering these
honeypots as systems of importance while the investment
in honeypots being economical. Successful deception may
lead to identiﬁcation of potential attributes of intrusion and
techniques of the Attacker. This cyber threat information can
enable the Defender to strengthen their defences to prevent
attacks on real systems by identifying countermeasures against
the observed security gaps, augmenting intrusion detection
signatures or anomaly-based rules based on the observed
behavioural patterns of the Attacker. The information can
also be used to support forensic investigations [53] of cyber
security breaches.

A. System Model

The Defender is often confronted with the challenging task
of making security investment decisions with a limited security
budget and a strict reaction time frame. Key questions the
Defender faces are: (i) whether to invest in cyber deception
and (ii) how this deception must be implemented and delivered.
To support these decisions, we investigate a scenario where the
Defender has an allocated investment budget and this budget
can be determined by another cyber investment decision-
making methodology such as [26], [54], [55]. The computation
of this amount as well as its size is out of the scope of
this paper and the initial question is whether to implement
a honeypot or not given this budget.

Let B be the required budget, i.e., cost, for covering the
implementation and maintenance of a honeypot. We denote
by L the expected loss caused by a successful breach on a
system in the IoV network. Adding a honeypot in the network
would be beneﬁcial when L is greater than B as investing in
deception is affordable and less expensive than the expected
loss caused from cyber incidents. Further, the information
gathered from the honeypot could be used to reduce this
expected loss. Likewise, the Defender would prefer not to
implement a honeypot when L < B as the implementation
cost would exceed its reward leading to a negative Return on
Security Investment (ROSI).

4

Symbol

Interpretation

B
Ch
Cl
V
I
L
S(I)

Bres
s+
j
s−
j
c(I)
g(I)
pj
tj
Uh
Ul
ν(I)
α
β
λ

Constants and Functions

budget to invest in honeypot
implementation cost of HIH
implementation cost of LIH
set of available vulnerabilities
set of offered vulnerabilities (I ⊆ V)
expected loss without honeypot
re-conﬁguration cost for I
Game Variables

residual budget after implementing honeypot
cost of adding vulnerability vj ∈ I
cost of patching vulnerability vj ∈ I
honeypot monitoring cost when offering I
gained cyber threat intelligence when offering I
probability of offering vulnerability vj ∈ I
time to exploit vulnerability vj ∈ I
expected game utility of the Defender with HIH
expected game utility of the Defender with LIH
optimum value obtained from optimisation
average monitoring cost factor
optimisation smoothing factor
honeypot learning rate

TABLE I: List of Symbols

When investing is a preferable choice, the next step is to
identify what type of honeypot to implement i.e., either a
low-interaction honeypot (LIH) or a high-interaction honey-
pot (HIH). Each honeypot type has an implementation cost,
expressed as Cl and Ch for LIH and HIH, respectively, and a
learning rate (λ). The implementation cost is exogenous and
depends on the resources required to implement and maintain
it. For example, LIHs are easy to deploy and maintain,
usually hosted on a virtual machine, and offer limited services
such as Internet protocols and network services without any
interactions with the operating system. The limited interaction
enables them to minimise the risk of exploitation by containing
the activities of the Attacker within the deception environment.
These low-level interactions only capture limited information
on the Attacker’s activities, thus leading to a lower learning
rate. On the other hand, HIHs provide greater levels of
interaction such as interactions with a real/virtual operating
system. These additional functionalities introduce complexities
in implementing and maintaining them [56], besides the higher
risk of breaching the real systems through them. The learning
rate for HIH is higher as they can capture more activities of
the Attacker contributing to better cyber threat intelligence.
Table I presents the list of symbols used in this paper.

We also assume that each honeypot type can only support
vulnerabilities of certain complexities. Let
denote
the set of vulnerabilities to be offered in a honeypot. The
complexity to exploit a vulnerability, i.e., low, medium, or
high, is extracted from Common Vulnerability Scoring System
(CVSS) and is used to differentiate vulnerabilities that can
be offered through LIH and HIH. We assume vulnerabilities
with “high” complexity can only be offered through HIH.

I ⊆ V

Budget B available

No honeypot
(L < B)

L

Honeypot
(L ≥ B )

Bres

LIH

HIH

Gl

Gh

B − Cl + Ul

B − Ch + Uh

Fig. 1: Defender’s decision tree with sub-games

l and

G

h
G

The Defender has to strategically offer the vulnerabilities to
engage the Attacker, which could involve re-conﬁguring the
honeypot multiple times. The re-conﬁguration activities can
be achieved using honey-patches [57], also known as ghost-
patches [58]. A honey-patch can function similar to a regular
patch and has two components: (i) a traditional patch for the
known software vulnerability, and (ii) additional code to to
create fake vulnerabilities to mislead the Attacker [57]. Honey-
patches can lead the Attacker to the decoy providing a false
sense of success. However, the Defender has to bear costs to
perform the re-conﬁguration and maintenance of the honeypot.
We refer to these costs as the re-conﬁguration cost S(
).
The re-conﬁguration action is analysed using a game-theoretic
framework based on a repeated game, as discussed in the
following section. Besides, respecting the available budget B,
the Defender’s security investment decisions are determined
by:

I

;

∈ {

, vn

v1, v2,
{
times

• the expected loss L, without a honeypot, due to a breach;
l, h
• the choice of honeypot type to implement
}
• the set of vulnerabilities to offer in a honeypot,

=
, and their associated exploitation
} ⊆ V
, tn
.
· · ·
}
• the cost of re-conﬁguration S(
, where s+

) =
2 ),
j and s−
j are costs (in time) for
· · ·
deliberately opening (indicated by “+” superscript) or
knowingly patching (‘-” superscript) vulnerability vj
,
respectively.

· · ·
t1, t2,
{
n , s−
, (s+
n )
}

1 ), (s+

(s+
{

1 , s−

2 , s−

∈ I

I

I

B. Game Model

The available choice for the Defender is to either implement
LIH or HIH. Each honeypot type leads to a distinct strategic
game, played between the Defender and the Attacker, as
illustrated in Figure 1. We refer to these games as Honeypot
h (related
Conﬁguration Games (HCG) represented as
to LIH and HIH, respectively). We utilise game theory [59]
which studies optimal decisions involving multiple decision
makers (also referred to as agents or players),
including
adversarial settings where two or more players have opposing
goals, to support the optimal decision.

l and

G

G

We model the HCGs as a repeated imperfect-information
zero-sum two-player game. Security games involve interaction
between players with exactly opposite goals making zero-sum
games the best ﬁt to model them [13]. Zero-sum games, in

5

particular, capture the worst-case scenarios for the Defender,
which is to face the Attacker who is after the most valuable
assets. The key motivation behind using zero-sum games is
that they can provide desirable solutions against any opponent
and not just against rational opponents [15]. On some occa-
sions, this may mean that the Defender spends more resources
in particular when the Attacker is non-strategic or naive.
However, in the absence of complete knowledge about the
Attacker’s incentives, it is reasonable to model the proposed
investment and honeypot conﬁguration decisions as a zero-
sum game to achieve robustness against strategic adversaries,
which most often are mentioned in the literature as Advanced
Persistent Threats (APTs) [60].

i

i and s−

Repeated games refer to games that have multiple indepen-
dent rounds. In each round of HCG, the Defender re-conﬁgures
the honeypot. Re-conﬁguring is a hardening operation which
involves replacing an observed exploited vulnerability with
. The replacement choice aims to convince
another from the
I
is a valuable system. The
the honeypot
the Attacker that
important aspect of this modelling decision is that HoneyCar
considers not only the costs for implementing and maintaining
the honeypots but also the cost for re-conﬁguring the honeypot.
This comes into the model via the cost variables s+
to
offer or revoke some vulnerability vi in a new conﬁguration.
In each HCG, the Defender chooses a set of vulnerabilities
to offer. The offered vulnerabilities can be observed by
I ⊆ V
the Attacker during system reconnaissance, who in response
chooses a vulnerability from the offered ones to exploit.
Having a honeypot in the network makes it difﬁcult for the
Attacker to gain the exact conﬁguration of the network as he
cannot distinguish a real system and a honeypot with certainty.
The Attacker also has no information regarding the kind of
the system he is targeting and the value of the asset he will
have access to by exploiting the vulnerability. Furthermore,
we make the following assumptions about the Attacker: (i)
he needs to compromise at least one vulnerability to mount
an attack on the IoV network; and (ii) he is aware of the
possibility of a honeypot (decoy system) and plays the best
strategy, that is, targets a vulnerability that maximises the
chances of successfully breaching the targeted system.

LIH is a cheaper option than HIH, but it is more likely
to be recognised by the Attacker leaving the Defender with
a lower reward. The Defender, therefore, has to undertake
some cost-beneﬁt analysis to identify the best type of honeypot
for defending the IoV network. The choices of the players
determine the game utility which is the outcome of the cost-
beneﬁt analysis performed when these strategies are played.
As illustrated in Figure 1, the choice of a honeypot type to
implement depends on the residual security budget deﬁned as

Bres = max

(cid:110)

B

−

Cl + Ul , B

−

(cid:111)

Ch + Uh

(1)

G

G

l and

where Ul and Uh are the Defender’s expected game utilities
from
h, respectively. These utilities correspond to the
payoffs of the Defender for implementing a honeypot type with
) to be exploited by the Attacker. In
a set of vulnerabilities (
, which is
each of these games, the Defender selects
different for LIH and HIH. It is evident from Figure 1 that the

I ∈ V

I

selection of a honeypot type and the vulnerabilities to offer
would alter Bres.

Remark 1. The expected game utility is a function of the
gained cyber threat intelligence and the cost of monitoring
the offered vulnerabilities.

Defender

v1

v2

vt

vm

C. Game iterations and utilities

Defender’s
expected
payoff

U1

U2

Ut

Um

. . .

. . .

6

I

=

} ⊆ V

In HCG,

v1, . . . , vm
{

the Defender conﬁgures the honeypot with a
selection of m out of n =
possible vulnerabilities to let
|V|
the Attacker mount any available exploit on the offered m
weaknesses denoted by
. The Attacker
would anticipate that the Defender will eventually discover
the vulnerability expecting the weakness to be patched as in
a real system. But other vulnerabilities will remain, and new
vulnerabilities are opened up with an attempt to retain the
attractiveness of the honeypot for the Attacker. This is exactly
the dynamics that HCG implements. The games proceed with
an assumption that in each iteration the Attacker exploits only
one vulnerability from the offered ones and the Defender re-
conﬁgures the honeypot by patching the exploited vulnerability
to demonstrate activity as she would on a real system. The
Defender further offers a new vulnerability vt from the set of
remaining vulnerabilities as an attempt to keep the Attacker
interested in the honeypot.

Each vulnerability has its own cost and beneﬁts based on
the time required to exploit it and the observed activities
of the Attacker during the interaction with the vulnerability.
For reference, Figure 2a and Figure 2b illustrate the players’
interaction in HCG. The strategic choices of the players are
the following:

• the Defender chooses an m-element subset

• the Attacker chooses a vulnerability vj

making the strategy space having cardinality (cid:0) n

I ⊆ V
(cid:1).
m
to exploit.
This choice can be motivated based on several criteria
such as time, resources and skills.

∈ I

,

the Attacker prefers the “easiest” of all vt

Remark 2. Investigating adversarial proﬁles is beyond the
scope of this paper and for simplicity, yet realistic, we consider
to
that
break into a targeted system. Likewise, we do not further
study sequential combinations of several exploits, and focus
our analysis on a single exploitation trial, corresponding to
a single round of our game. Repeated attempts as occur in
practice then manifest as rounds of our repeated game.

∈ I

The Attacker aims at minimising the time spent to exploit
vt to decrease the engagement time with a targeted system.
Furthermore, intelligent attackers always aim to compromise
a targeted system while remaining undetected. The execution
of such a stealthy attack allows the attacker to compromise the
targeted system without raising any alerts. While the Defender
has a contrary objective of maximising the Attacker’s time
spent interacting with the honeypot rather than the real system
to gather as much intelligence on the Attacker’s activities as
possible. The Defender’s expected utility in HCG is deﬁned
by the amount of cyber threat
),
which depends on the overall time spent by the Attacker

intelligence gained g(

I

(a) A round of HCG.
Defender

v1

vt

vj

vm

U1

. . .

Uj

Um

(b) A later round with changed vulnerabilities.

Fig. 2: The dynamic of HCG: (i) In a round of HCG, the
Defender offers a set of vulnerabilities to be exploited by the
Attacker; (ii) In the next round of HCG, the Defender patches
a vulnerability vt and offers a new one vj from

.

V

exploiting vulnerabilities and the cost of monitoring the offered
vulnerabilities c(

) i.e.,

I

)

UD = g(
I
Note that, for ease of presentation, UD is used to express the
expected game utility of the Defender regardless of the chosen
type of honeypot.

(2)

c(

−

I

)

Remark 3. The Defender aims at maximising the overall time
spent by the Attacker interacting with the honeypot with the
goal to increase cyber threat intelligence. On contrary, the
Attacker aims at minimising the time required to exploit a
targeted vulnerability.

IV. OPTIMALITY ANALYSIS

This section discusses how HoneyCar determines optimal
Defender strategies in the presence of an Attacker that can
cause maximum damage as expressed by the zero-sum nature
of the Honeypot Conﬁguration Game (HCG).

A. Decision complexity

(cid:1)

(cid:0) n
m

·

∈

We represent HCG in a matrix form with m

O(m
·
nm) elements which is computationally intractable even for a
moderately small n, m. To avoid the combinatorial explosion,
we restrict the Defender’s choices to only the set
of all
vulnerabilities from which she can select n vulnerabilities and
assign her randomised choices as a probability distribution
. We represent this in the form of a matrix game with
over
instead of a family of all n-element
the action space being
transforming the action space to a tractable size
subsets of
n =
. The equilibrium strategy of the Defender in the mixed

V

V

V

V

|V|

extension of this revised game is represented by a vector x =
[p1, . . . , pn]T

[0, 1]n, constrained to satisfy

∆(

)

∈

V

⊆
i : pj

|{

= 0

}| ≤

m,

(3)

so that HoneyCar offers the freedom to implement m or less
vulnerabilities in the honeypot.

B. Payoffs maximisation

The zero-sum payoff is derived using the equation (2)
and depends on the time required to exploit a vulnerability.
Considering that we do not offer a single vulnerability from
I
as a pure strategy of the Defender but a set of vulnerabilities
to choose from, the game does not satisfy the usual form
V
of a matrix game. Considering tj as the time to exploit
vulnerability vj, the expected payoff of the Defender equals

uj :=

(cid:26) pj

∞

tj,

·
,

if pj > 0;
otherwise.

(4)

This equals either the expected time to exploit a vulnerability
times the probability that the vulnerability was offered by
the Defender (pj > 0) or inﬁnite if the Attacker invests
time on creating an exploit for a vulnerability that was not
offered by the Defender. Since the Attacker aims at minimising
the exploitation time tj, any choice leading to
would be
a dominated strategy hence would never be chosen to be
exploited by the Attacker.

∞

In standard game theory with real-valued utility functions,
the existence of a Nash equilibrium is assured when the
strategy spaces are non-empty compact subsets of a metric
space and the utility functions are continuous with respect to
the metric [59]. It can be observed in (4) that the expected
payoff is an unbounded, even discontinuous function and thus
needs to be revised to obtain the equilibrium. We address
the unbounded-discontinuous nature of the utility function by
deﬁning the nature of the Attacker to be a maximiser of the
expected residual time obtained for using an exploit. This as-
sumption is in line with the rational characteristics of attackers
seen in the wild who aim to maximise their payoff from an
attack [41]. We choose any constant T > max
tj : vj
,
∈ V}
the Attacker maximise the expected residual
and let
time
tj, which is by construction equivalent to minimising tj.
T
Substituting tj by T
tj in (4), we let the Attacker maximise
the expected payoff without altering her objective and just
changing the optimisation goal. The revised expected payoff
function of the Attacker is

−

−

{

7

payoff of the Attacker and equivalently multiplied by
the expected payoff of the Defender.

1 as

−

To highlight the applicability of HoneyCar, we describe
and analyse two distinct versions of HCG: (i) without the
cost of re-conﬁguration (HCG-a); and (ii) with the cost of re-
conﬁguration (HCG-b). HCG-a presents the baseline model of
interaction between the Defender and the Attacker with no cost
for re-conﬁguring the honeypot in each round of the game. In
HCG-b, we increase the complexity of the model to account
for the cost of patching and opening a new vulnerability
(re-conﬁguring the honeypot), in each iteration of the game,
which affects the overall budget available to the Defender.
The re-conﬁguration cost moderates the number of rounds the
game could be played thus affecting the Defender’s expected
utility. Through these games, we investigate the importance of
re-conﬁguration cost in the Defender’s investment decisions,
which was identiﬁed by Rass et al. [61] as a key component
for an acute game-theoretic model. A comparative analysis of
these games based on the developed use case is discussed in
Section V.

C. Decision analysis for HCG-a

This version of HCG presents a baseline model capturing
the interaction between the Defender and the Attacker. It
presents the optimal honeypot conﬁguration when the re-
conﬁguration cost is ignored providing insights into the base-
line conﬁguration strategies. These baseline strategies are then
used to assess the impact of the re-conﬁguration cost to the
Defender’s decisions which are studied by the HCG-b version,
presented in the following section. We let x = [p1, . . . , pn]
[0, 1]n and y = [q1, . . . , qn]T
∈
0, qk
distributions, i.e., constrained to satisfy: (i) pk
≥
, n, and (ii) (cid:80)
k pk = 1 and (cid:80)
0, k = 1, 2,
k qk = 1. The
payoff of the game depends on the Attacker’s probability of
choosing a vulnerability to exploit (represented as qj) and the
Defender’s probability of choosing the targeted vulnerability
to offer (represented as pi). Since both make their choices at
random, the expected utility is expressed as

∈
[0, 1]n both being probability

· · ·

≥

U (x, y) =

(cid:88)

i,j

pi

qj

·

·

(cid:88)

(5)=

¯uj

i,j

pi

qj

·

·

(pj

·

[T

−

tj])

(6)

uj := pj

(T

·

−

tj),

(5)

whenever the vj-th vulnerability in
is chosen. Depend-
ing on whether vulnerability vj was offered by the Defender
in ﬁrst place, uj is either

I ⊆ V

• uj > 0, if pj > 0, when the vulnerability was offered, or
• uj = 0, if pj = 0, which is a strategically dominated

choice for a maximising Attacker.

It can be asserted that
the revised payoff function (5) is
bounded and no longer has the troublesome discontinuities
as observed in (4). Hereafter, we consider (5) as the expected

=

To be noted from (6) that
depends on i. The variable i iterates over all choices i

the expected utility implicitly

v1, . . . , vn
{

∈
of the Defender, but the payoff to the
V
Attacker occurs if the vulnerability vi was actually chosen for
exploitation. The expected utility depends on the sum running
over i in (6).

}

Since the expected payoff continuously depends on the
mixed strategies x, y of both players, using Glicksberg’s
theorem [59], we have an equilibrium when minx maxy U =
maxy minx U . Towards solving this minimax optimisation, let

(cid:54)
us rewrite U in matrix notation. To this end, observe that

xT x =








p1p1
p2p1
...
pnp1

p1p2
p2p2
...
pnp2

q1(T












t1)

−
0
...
0
0

0
. . .
...
. . .

· · ·

0

0

tj)

qj(T

−
. . .

· · ·
· · ·
. . .

· · ·

· · ·

· · ·

· · ·
. . .
0

= diag[T

(cid:124)

−

t1, . . . , T

(cid:123)(cid:122)
=:Γ

tn]
(cid:125)

·

−








p1pn
p2pn
...
pnpn
0

0

0
...

and












qn(T

tn)

−
(cid:33)

(cid:32) q1

.
.
.
qn

= Γ

·

y (7)

·

and multiplying xT x by the diagonal matrix Γ
y, we techni-
cally multiply the j-th row in (7) by the value qj(T
tj) for all
j = 1, 2, . . . , n. Now, to reproduce (6), we are left with adding
1 vector, which is doable by a
up the rows in the resulting n
R1×n.
multiplication with the row-vector e = [1, 1, . . . , 1]
xT
Γ
The matrix representation being U (x, y) = e
y =
·
·
(cid:124)
(cid:123)(cid:122)
(cid:125)
=:A(x)

∈
·

×

−

x

·

·

A(x)

y, in which A(x) is a (1

n)-matrix for all x.

Let the Defender choose x. The Attacker’s problem, fol-

lowing the Defender, is choosing y towards

max
y

A(x)

y = max
1≤i≤n

·

A(x)e T
i

,

(8)

since the inner maximisation is the selection of the largest
Rn, achievable by a discrete
element from the vector A(x)
∈
optimisation over all unit vectors ei with a 1-entry only at
the i-th coordinate and being zero elsewhere. Introducing the
scalar ν to represent the value of the inner optimisation (8),
we arrive at the Defender’s problem

×

min ν

s.t.


ν

(cid:80)n



pi

i=1 pi = 1,
0.

≥

≥

A(x)e T
i

for all i = 1, 2, . . . , n,

(9)

I

This is a nonlinear problem with smooth objective and con-
straints. The value obtained from this optimisation is used to
compute g(
)
I
) to be logistic functions [62], and are represented as
and c(

), used in equation (2). We deﬁne g(

) and c(

I

I

) = e

1
1+λ·νI

and

g(

I

) = e

1
α·|I|·νI

c(

I

(10)

where νI denotes the optimum ν obtained by solving (9) (or
(0, 1) denotes the
(12) for HCG-b in next section); and λ
learning rate for a honeypot type as detailed in Section III.

∈

The λ value can also be expressed as the degree of
effectiveness of a honeypot which can be represented as
[63]: (i) the time required by the Attacker to realise that
he is attacking a decoy system; (ii) the type of honeypot
implemented to deceive the Attacker; or (iii) the amount
of collected attack data. As any of the above factors are
higher for HIH, we consider λ for HIH is larger than LIH.
(0, 1) value denotes the average monitoring cost
The α

∈

8

factor of a honeypot
type. HIH must be supported with
adequate data collection and control mechanisms to ensure
reliable adversarial information gathering, and to prevent the
honeypot from being used as a foothold to attack connecting
devices and networks. HIH requires signiﬁcant resources for
continuous monitoring and logging all
the interactions to
determine the Attacker’s motives and methods. Thus, high-
interaction honeypots generally exhibit greater monitoring
costs than low-interaction honeypots leading to a higher α.

Example with HCG-a: Let the Defender be the minimis-
ing player with HIH. We consider the exploitation time as
categorical values similar to the complexity metric of the
vulnerabilities in CVSS scores. We let the exploitation time
for low, medium, and high complexity vulnerabilities be 1, 2
= 3, the
and 3, respectively. For example, let m = 3, n =
|I|
associated exploitation time diag(Ψ) =
, and T = 4.
}
The payoff matrix Γ is constructed as

2, 1, 3
{

T





Γ =

t1

−
0
0

T

0

−
0

t2





 =







2
0
0

0 0
3 0
0 1

0
0

−

t3

T

)∗
Analysing the game by solving (9), yields v(
≈
0.545 and the result at an equilibrium strategy x∗
0 ≈
(0.273, 0.182, 0.545). To compute the expected game utility
UD using (2), we let the re-conﬁguration cost
= 0, as we
demonstrate this example with HCG-a, λ = 0.6 and α = 0.7.
Then, using (10), we compute g(
0.418
leading to UD

2.124 and c(

1.706.

≈

≈

S

I

I

I

)

)

≈

D. Decision analysis for HCG-b

In the following, we extend our analysis to include the re-
conﬁguration cost of the Defender in HCG and refer to it as
HCG-b. Since the Defender aims at making the honeypot at-
tractive to the Attacker, they are required to demonstrate some
activities in the honeypot by patching some vulnerabilities and
opening up new ones. However, such re-conﬁguration incur
costs. For each vulnerability vj
j as the
cost (in time) for “offering” vulnerability vi in the honeypot,
and s−
j as the cost (in time) for patching vulnerability vi, i.e.,
removing it from the honeypot. We further consider that if a
vulnerability vj in the current round remains in the honeypot
for the next round, no re-conﬁguration cost occurs and c+
is
i
zero. Likewise, if the vulnerability vj is not offered in this
round of the repeated game nor included in the next round,
then c−
is zero. Assuming stochastic independence of the
j
rounds in the game, we investigate the cases where:

, we denote s+

∈ I

Case 1. vulnerability vj was offered in the current
round with probability pj and is patched in the next
round, with probability 1
the expected
re-conﬁguration cost is pj

pj. Thus,
s−
j .

pj)

−
(1

·

−

·

Case 2. vulnerability vj was not offered in the current
round with probability 1
pj and the honeypot will be
conﬁgured to have vj in the next round leading to the
expected re-conﬁguration cost of (1

−

pj)

pi

s+
j .

−

·

·

9

utility UD using (2), we let λ = 0.6, α = 0.7 and β =
0.5 leading to g(
0.429. The re-
I
conﬁguration cost for offering these vulnerabilities can be
obtained using (x∗
0)T
1.35. Then, taking
(1
·
the re-conﬁguration cost into account gives UD

2.112 and c(

0.33.

x∗
0)

Ψ

−

≈

≈

≈

I

)

)

·

≈

Since the coefﬁcients of the expected re-conﬁguration cost
in both cases above are the same, we end up with the re-
conﬁguration penalty term to be the sum of all pj
pj)
conﬁguration cost

−
. The matrix notation of the re-

) can be expressed as

j ) over vj

j + s−

(s+

∈ I

(1

·

·

xT

·

where Ψ =

(
I

S
x),
(1
Ψ
−
·

1 + s−
s+
1
0
...
0






0
2 + s−
s+
2
...
0

. . .
. . .
. . .
. . .








0
0
...
n + s−
s+
n

Remark 4. When compared to the example in Section IV-C,
it is evident that the re-conﬁguration cost is important in
determining the number of playable rounds of the HCG and
eliminating the unattainable equilibrium.

(11)

in which 1 is the vector of all ones, and Ψ is a diagonal matrix
with the re-conﬁguration cost.

The re-conﬁguration cost matrix Ψ can be included in the

optimisation, as detailed in [61], as a penalty term xT
−
x) to the expected payoff function. To express the trade-off
between the payoff matrix A(x) and the re-conﬁguration cost
matrix Ψ, we introduce a smoothing factor 0 < β < 1. The
so-enhanced optimisation problem can be expressed as:

(1

Ψ

·

·

min ν

such that

ν

β

≥

A(x)ei + (1

·
i = 1, 2,

−
, n,

· · ·

xT

β)

·

(1

Ψ

·

·

−

x)

(12)

∀
1T x = 1,
0.
x

≥

HoneyCar can also incorporate a more complex HCG
where all m-out-of-n subsets are included as
separate
let
strategies to re-conﬁgure the honeypot. For example,
i and
the set of vulnerabilities in the current round be
I
the set of vulnerabilities for the next round be
j. Then
the cost to switch from i to j, i.e., re-conﬁguration cost, is
sij = (cid:80)
s−
k , with i, j ranging over all
strategies, forming a matrix Ψ = (sij). According to [61],
the penalty term to go into the optimisation is then the plain
quadratic form xT
x).

k + (cid:80)
s+

k∈Ij \Ii

k∈Ii\Ij

(1

Ψ

I

·

·

−

Example with HCB-b: We extend the example in Section
IV-C by considering the re-conﬁguration cost. We adopt the
concept of time that uses categorical values similar to the
complexity metric of the vulnerabilities in the CVSS score.
We let the re-conﬁguration cost for low, medium and high
complexities to 1, 2 and 3, respectively. Let the Defender be
= 3,
the minimising player with HIH and let m = 3, n =
|I|
the associated exploitation time diag(Ψ) =
2, 1, 3
, and
}
{
T = 4. Then, the payoff and the re-conﬁguration cost matrices
are given by








Γ =



 ,

and Ψ =



2 0 0
0 3 0
0 0 1

2
0
0

0 0
1 0
0 3



)∗

Analysing the game in the described way and solving (12),
yields v(
0 ≈
(0.332, 0.304, 0.364). Naturally, the Defender’s expected loss
fv here is higher than the conventional game without re-
conﬁguration cost (see IV-C). To compute the expected game

0.562 at an equilibrium strategy x∗

≈

I

E. Scalability analysis

.

{

V

To evaluate the scalability of HoneyCar, we ran simulations
on a 2.8GHz Intel core i7 with 16GB RAM using Python 3.7.0
with the scipy.optimize package4. Our experiments showed
that HoneyCar can solve well up to and at least n = 1000
vulnerabilities, but has the issue with the optimum assigning
of positive probabilities pj > 0 for all 1000 vulnerabilities
with the time of exploits (tj) being represented by a random
sampled set of values from

1, 2, 3
}
In a real-world situation, conﬁguring the honeypot with all
will be overly laborious with signiﬁcant
vulnerabilities in
maintenance and monitoring costs. This was evident from the
fact that even choosing vulnerabilities with pj < 0.001, we
ended up with 319 vulnerabilities in one of the experiments.
Offering such a large set of vulnerabilities in a honeypot might
be infeasible, let alone economic. Our goal was to keep a
small subset of vulnerabilities open, to avoid exposing the
honeypot and to unnecessary suspicion from the Attacker.
Acknowledging the possibility of the honeypot to be identiﬁed
by the Attacker, we introduced the constraint (3) to enforce
an m-out-of-n selection from
. This reduces the problem
into one with cardinality constraints,
to which specialised
approximation methods are applicable [64]. Our experiments
with simple methods to replace (3), such as entropy constraints
or smooth approximation for the indicator function, has failed
when a large vulnerability set (around n = 100) is considered
unless m is as large as n. However, if the honeypot is used
exclusively to monitor unauthorised access, the constrain on
the number of conﬁgured vulnerabilities could be exempted.
The expected game utility is achieved by the following

V

steps:

1) Solve the optimisation problem as stated above (with
or without the cardinality constraint depending on com-
putational feasibility), and call the output value x =
(p1, . . . , pn).
2) Iterate over all vj

, and with probability pj,
as determined from the optimisation problem, choose to
include a vulnerability in the honeypot.

∈ I ⊆ V

3) Evaluate A(x) and determine the Attacker’s optimal
(Defender’s worst-case) strategy as the maximum over
Rn.
the elements of A(x)

4) Compute ν and the re-conﬁguration cost x∗T
at the optimum x∗ to calculate UD in (2).

(1

Ψ

·

·

−

x∗)

∈

4https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html

#
CVE ID
Score
Access
Complexity

v1
CVE-2018-9311
10
Remote
Low

v2
CVE-2018-9318
10
Remote
Low

v3
CVE-2019-9977
6.8
Remote
Medium

v4
CVE-2018-9313
5.7
Remote
Medium

v5
CVE-2012-6510
4.3
Remote
Medium

v6
CVE-2018-6508
6
Remote
Medium

v7
CVE-2016-9337
4
Remote
High

TABLE II: Sample set of vehicular security vulnerabilities with CVSS metrics.

10

V. CASE STUDY

This section presents a case study where HoneyCar is
assessed using known vulnerabilities related to autonomous
and connected vehicles. For the purpose of this case study, we
consider the vulnerabilities from the Common Vulnerabilities
and Exposure (CVE) list found within the National Institute
of Standards and Technology (NIST) National Vulnerability
Database (NVD)5. The CVE data includes a description,
Common Vulnerability Scoring System (CVSS) base scores,
vulnerable product conﬁguration, and weaknesses’ categorisa-
tion information on each identiﬁed vulnerability. We primarily
utilise the CVSS metrics to acquire parametric values required
for HoneyCar. CVSS is a publicly available industry standard
that details the characteristics and severity of software vul-
nerabilities and is built upon three core metric groups: Base,
Temporal, and Environment. The Base metric represents the
intrinsic qualities of a vulnerability that remain unchanged
over time and across user environments. The Temporal metric
reﬂects the characteristics of a vulnerability that can change
over time, while the Environmental metric reﬂects qualities of
a vulnerability that are unique to a user’s environment. This
case study uses the Base metrics to extract the parameters to
be used in HoneyCar.

First, we consider a small sample of vulnerabilities to assess
HoneyCar. Nevertheless, HoneyCar can be implemented with
any number of vulnerabilities to offer decision support to the
Defender. Next, the NVD is checked for available patches for a
vulnerability. Identifying vulnerabilities with available patches
is critical to HoneyCar as without patches it is infeasible to
re-conﬁgure the honeypot. Once a vulnerability with patch has
been identiﬁed, we obtain its CVSS metrics. Finally, HoneyCar
is applied to obtain the optimal honeypot conﬁguration for
the versions of the Honeypot Conﬁguration Game (HCG)
presented in Section IV.

A. Data and use case composition

Taking advantage of the complexity metric of the CVSS, we
derive the exploitation time tj and the re-conﬁguration cost
(vj) for a vulnerability vj. The complexity metric expresses
S
the anticipated efforts needed to exploit a vulnerability. We
associate a low complexity to “short” time, a medium com-
plexity to “medium” time and a high complexity to “long”
time. With such association, we set tj, s+
for
a vulnerability vj within the ranks of the categorical values of
the complexity metric. We further use the complexity metric
to distinguish vulnerabilities that can be supported by LIH
and HIH. Vulnerabilities requiring higher effort
to exploit
require higher access privileges which can only be supported

1, 2, 3
}

j , s−

j ∈ {

5https://nvd.nist.gov/vuln/data-feeds

through high-interaction honeypots. We, thus, consider that a
low-interaction honeypot can only support vulnerabilities with
low and medium complexities. Table II presents the list of
security vulnerabilities used from the Common Vulnerabilities
and Exposures (CVE) database and relevant CVSS metrics.
The CVSS score ranges from 0 to 10 and speciﬁes the
potential impact of a vulnerability. For example, a vulnerability
providing access to the breaking system of a vehicle will
have higher impact compared to the one that compromises
the windscreen wipers.
We assume that

the Defender can offer at most m =
= 6 vulnerabilities through a honeypot. The Honeypot
|I|
Conﬁguration Game (HCG) is played for a ﬁnite number of
rounds equivalent to the maximum number of vulnerabilities
to be offered by a honeypot. Naturally, honeypot monitoring
cost
increases with the offered number of vulnerabilities.
Deploying HoneyCar assists the Defender in determining the
right type of honeypot to implement and the optimum number
of vulnerabilities to offer optimising the expected utility. To
compute the expected game utility (UD), we ﬁrst set values for
the time constant T , exploitation times tj and re-conﬁguration
cost

(vj) for all vulnerabilities vj

.

S
vj
tj
T − tj
S(vj )

v1
1
3
1

v2
1
3
1

v3
2
2
2

∈ V
v4
2
2
2

v5
2
2
2

v6
2
2
2

v7
3
1
3

TABLE III: Exploitation time and re-conﬁguration cost for
sample vulnerabilities.

{

S

1, 2, 3
}

As detailed earlier, we heuristically consider the “complex-
ity” metric to derive these values. We let T := 4 as any
choice for T > max
is admissible. Table III presents
the tj and
(vj) for the vulnerabilities listed in Table II. We
further consider that the re-conﬁguration cost of a vulnerability
equals its exploitation time. From the vulnerabilities sample
in Table II, vulnerability v7 being of high complexity cannot
for LIH.
be offered through LIH implying that
=
For proportionality, we consider
for HIH. Using
these vulnerability sets, we then construct the respective Γ
and Ψ required to complete the optimisation as introduced in
Section IV.

V \ {
}

I
V \ {

=
v1

v7

I

}

B. Results

The ν value, obtained from the optimisation,

is a key
parameter in determining the honeypot conﬁguration strategy.
It expresses the maximum of the minimum residual
time
(T
the Defender can achieve regardless of the
vulnerability chosen by the Attacker to exploit. The ν value is
inﬂuenced by (i) the total number of available vulnerabilities;

tj) that

−

(ii) the number of vulnerabilities selected to offer; and (iii) the
type of the offered vulnerabilities. The ν values decrease with
the increase in the number of offered vulnerabilities as with
increased number of offered vulnerabilities the Defender has
greater chances to deceive the Attacker.

I

≤

≤

Figure 3a presents the ν value over the range 0 < m

n
with LIH and HIH without the re-conﬁguration cost i.e., for
HCG-a. The minimal value for ν is attained at m = n = 6.
Further, Figure 3b shows the expected game utility UD and
the honeypot monitoring cost c(
) for HCG-a with LIH over
n. As expected, the cost of monitoring the
the range 0 < m
honeypot and the gather adversarial activities increases with
ν. In particular, ν increases with an increase in the number of
rounds of the game which enforces the cost of monitoring the
honeypot over the duration of the game. On the contrary to
the escalating monitoring cost, a higher ν is preferred as the
cyber cyber threat intelligence of the Defender grows with the
number of rounds of the game. Thus, an optimal choice would
be to select m such that UD is positive and possibly the largest.
The only positive UD is at m = 6 suggesting that the expected
game utility is the best when offering all six vulnerabilities at
once with LIH. With this strategy, the minimum improvement
in UD is approximately 100% compared to any others selection
of m. Similarly, it can be inferred from Figure 3c, which
presents UD and c(
) with HIH, that implementing HIH will
I
be expensive as UD is always negative regardless of the size
of m.

Result 1. In HoneyCar, when trying to maximise the duration
of engagement with the attacker, an ideal choice for the
Defender would be to offer all available vulnerabilities in
one round of the game. This strategy particularly supports the
objective of wasting attackers’ time before throwing them out
of the network and conﬁrming the reasoning behind the use
of honeypots to dissuade attackers from critical infrastructure
and vehicles in IoV.

The results of the case study with HCG-b are presented
in Figure 4. With regards to re-conﬁguration cost, the De-
fender has to endure additional cost for every selection of
m vulnerabilities. Figure 4a shows that ν is negative when
m > 2 implying that the Defender should not offer more than
two vulnerabilities in a round. The reason for this stems from
the fact that HCG is a zero-sum game and ν < 0 implies a
better payoff for the Attacker. Figures 4b and 4c illustrate the
UD and c(
) with LIH and HIH, respectively. According to
I
the results, the Defender gains a better UD with HIH when
m = 2. The Defender, while spending approximately 62%
less on monitoring cost, can achieve an improved UD of
approximately 134% compared to the best strategy with LIH
which also happens to be with m = 2.

Result 2. When trying to maximise the cyber threat intel-
ligence, the honeypot conﬁguration should be such that it
engages the Attacker longer leading to a positive expected
game utility. HoneyCar assists in determining the optimal
number of vulnerabilities to be offered to gain the largest
positive expected utility. The positive expected utility reﬂects
that the collected amount of cyber threat intelligence is higher

11

than the cost of monitoring the honeypot leading to a positive
Return on Security Investment (ROSI).

Result 3. The re-conﬁguration cost can be seen as a cost
for switching from one Nash Equilibrium of
the game to
another. It reﬁnes the duration of the game by eliminating
unplayable choices regarding the number of vulnerabilities
to be offered in a round. HoneyCar, through such strategies,
recommends optimal honeypot deception investment plans to
engage attackers and achieve cyber threat intelligence.

VI. CONCLUSIONS

The application of honeypots is a promising approach for
protecting IoV networks. If an attacker is successfully lured by
the honeypot, the adversarial activities captured by the honey-
pot can be used to learn about the attacker’s motives and tech-
niques. Successively, this knowledge, also referred to as cyber
threat intelligence, can contribute to protecting existing system
components by improving intrusion detection with new attack
signatures or anomalous behaviour deviating from norms of
protocols and systems’ behaviours. Besides the inevitable cost
of maintaining IoV honeypots, it is a challenge to design
convincing honeypots to successfully deceive attacks This
paper proposed a novel framework called HoneyCar which
aims to assist IoV network administrators with the optimal
conﬁgurations and investments in honeypots. HoneyCar is built
upon two models: (i) a formal model of assessing the option
of the Defender to invest in cyber deception using honeypots;
and (ii) a game-theoretic model to strategically determine the
conﬁguration and selection of honeypot to be deployed in IoV
network. HoneyCar empowers the network administrator to
derive optimal decisions regarding honeypot deception based
on an available budget. We take into consideration the number
and type of vulnerabilities to be offered by the honeypot,
the beneﬁt and cost of implementing a vulnerability, the cost
for re-conﬁguring a honeypot and the available budget for
investment in deception.

We demonstrate and evaluate HoneyCar using autonomous
and connected vehicular security vulnerabilities collected from
the Common Vulnerabilities and Exposure (CVE) data found
within the National Vulnerability Database (NVD) and the
respective Common Vulnerability Scoring System (CVSS)
metrics. Our evaluation suggests that HoneyCar is capable of
supporting IoV network administrators to determine the opti-
mal conﬁguration of honeypots for (i) wasting attacker’s time
and (ii) maximising the collection of cyber threat intelligence.
HoneyCar also highlighted the importance of re-conﬁguration
cost in determining the duration of the game by eliminating
unplayable choices leading to a realistic investment plan.

A key question future work could investigate is when to
re-conﬁgure the honeypot. An option would be to consider
ﬁnite horizon games where the vulnerability set becomes
exhausted at some point leading to reopening a vulnerability
that has been closed in the past. However, such an action could
rise suspicion and the deception might fail. The Defender’s
option could be to invest more to introduce entirely new
set of vulnerabilities or refresh the honeypot. Formally, the
game can be expressed in extensive form, with a number

12

(a) ν(I) with LIH and HIH

(b) c(I) and UD with LIH

(c) c(I) and UD with HIH

Fig. 3: Comparison of HCG-a game utility UD and c(
I
α being 0.5 and 0.7 for LIH and HIH, respectively.

) for a total of six vulnerabilities with β = 0.5, λ being 0.4 and 0.6,

(a) ν(I) with LIH and HIH

(b) c(I) and UD with LIH

(c) c(I) and UD with HIH

Fig. 4: Comparison of the HCG-b game utility UD and c(
0.6, α being 0.5 and 0.7 for LIH and HIH, respectively.

I

) for a total of six vulnerabilities with β = 0.5, λ being 0.4 and

of stages that correspond to the number of re-conﬁgurations
allowed given the vulnerability set. This will introduce more
solution concepts like Subgame Perfect Nash equilibria or even
Stackelberg Nash equilibria. Last, future work can include
approaches that combine both game theory and machine
learning to develop defensive deception techniques. In such
a hybrid approach, reinforcement learning with game theory
could be used to formulate players’ utility functions, estimate
opponent’s beliefs and update the optimal strategy and predict
opponent’s actions by analysing data from host vehicles,
network and threat actor behaviours.

REFERENCES

[1] O. Kaiwartya, A. H. Abdullah, Y. Cao, A. Altameem, M. Prasad, C.-T.
Lin, and X. Liu, “Internet of vehicles: Motivation, layered architecture,
network model, challenges, and future aspects,” IEEE Access, vol. 4,
pp. 5356–5373, 2016.

[2] M. Gerla, E.-K. Lee, G. Pau, and U. Lee, “Internet of vehicles: From
intelligent grid to autonomous cars and vehicular clouds,” in 2014 IEEE
world forum on internet of things (WF-IoT).
IEEE, 2014, pp. 241–246.
[3] G. Loukas, Cyber-physical attacks: A growing invisible threat.

Butterworth-Heinemann, 2015.

[4] J. Cheng, J. Cheng, M. Zhou, F. Liu, S. Gao, and C. Liu, “Routing
in internet of vehicles: A review,” IEEE Transactions on Intelligent
Transportation Systems, vol. 16, no. 5, pp. 2339–2352, 2015.

[5] P. Patel and R. Jhaveri, “A honeypot scheme to detect selﬁsh vehicles
in vehicular ad-hoc network,” in Computing and Network Sustainability.
Springer, 2017, pp. 389–401.

[6] V. Verendel, D. K. Nilsson, U. E. Larson, and E. Jonsson, “An approach
to using honeypots in in-vehicle networks,” in 2008 IEEE 68th Vehicular
Technology Conference.
IEEE, 2008, pp. 1–5.

[7] D. Gantsou and P. Sondi, “Toward a honeypot solution for proactive se-
curity in vehicular ad hoc networks,” in Future Information Technology.
Springer, 2014, pp. 145–150.

[8] Y. M. Schmitz, “A strategy for vehicular honeypots.”
[9] Q. D. La, T. Q. Quek, J. Lee, S. Jin, and H. Zhu, “Deceptive attack and
defense game in honeypot-enabled networks for the internet of things,”
IEEE Internet of Things, vol. 3, no. 6, pp. 1025–1035, 2016.

[10] M. Zhu, A. H. Anwar, Z. Wan, J.-H. Cho, C. Kamhoua, and M. P. Singh,
“A survey of defensive deception: Approaches using game theory and
machine learning,” IEEE Communications Surveys & Tutorials, 2021.

[11] Q. D. La, T. Q. Quek, and J. Lee, “A game theoretic model for enabling
honeypots in iot networks,” in 2016 IEEE International Conference on
Communications (ICC).
IEEE, 2016, pp. 1–6.

[12] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bacs¸ar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Computing Surveys
(CSUR), vol. 45, no. 3, pp. 1–39, 2013.

[13] C. T. Do, N. H. Tran, C. Hong, C. A. Kamhoua, K. A. Kwiat, E. Blasch,
S. Ren, N. Pissinou, and S. S. Iyengar, “Game theory for cyber security
and privacy,” ACM Computing Surveys, vol. 50, no. 2, pp. 1–37, 2017.
[14] E. Panaousis, E. Karapistoli, H. Elsemary, T. Alpcan, M. Khuzani, and
A. A. Economides, “Game theoretic path selection to support security
in device-to-device communications,” Ad Hoc Networks, vol. 56, pp.
28–42, 2017.

[15] R. P´ıbil, V. Lis`y, C. Kiekintveld, B. Boˇsansk`y, and M. Pˇechouˇcek,

246Vulnerabilitiesoﬀered(m)0.00.51.01.52.0ν(I)[time]LPHP246Vulnerabilitiesoﬀered(m)−0.250.000.250.500.75timec(I)UD246Vulnerabilitiesoﬀered(m)−0.250.000.250.500.75timec(I)UD246Vulnerabilitiesoﬀered(m)−1.0−0.50.00.5ν(I)[time]LPHP246Vulnerabilitiesoﬀered(m)0.00.20.40.6timec(I)UD246Vulnerabilitiesoﬀered(m)0.00.20.40.6timec(I)UD13

“Game theoretic model of strategic honeypot selection in computer
networks,” in International Conference on Decision and Game Theory
for Security. Springer, 2012, pp. 201–220.

[39] N.-W. Lo and H.-C. Tsai, “Illusion attack on VANET applications-
a message plausibility problem,” in 2007 IEEE globecom workshops.
IEEE, 2007, pp. 1–8.

[16] F. Sakiz and S. Sen, “A survey of attacks and detection mechanisms on
intelligent transportation systems: VANETs and iov,” Ad Hoc Networks,
vol. 61, pp. 33–50, 2017.

[17] T. Ring, “Connected cars–the next target for hackers,” Network Security,

vol. 2015, no. 11, pp. 11–16, 2015.

[18] K.-Y. Lam, S. Mitra, F. Gondesen, and X. Yi, “Ant-centric iot secu-
rity reference architecture–security-by-design for satellite-enabled smart
cities,” IEEE Internet of Things Journal, 2021.

[19] M. Aloqaily, S. Otoum, I. Al Ridhawi, and Y. Jararweh, “An intrusion
detection system for connected vehicles in smart cities,” Ad Hoc
Networks, vol. 90, p. 101842, 2019.

[20] D. A. Rivas, J. M. Barcel´o-Ordinas, M. G. Zapata, and J. D. Morillo-
Pozo, “Security on VANETs: Privacy, misbehaving nodes, false infor-
mation and secure data aggregation,” Journal of Network and Computer
Applications, vol. 34, no. 6, pp. 1942–1955, 2011.

[21] K. Emara, W. Woerndl, and J. Schlichter, “On evaluation of location
privacy preserving schemes for VANET safety applications,” Computer
Communications, vol. 63, pp. 11–23, 2015.

[22] M. Wazid, P. Bagga, A. K. Das, S. Shetty, J. J. Rodrigues, and Y. Park,
“Akm-iov: Authenticated key management protocol in fog computing-
based internet of vehicles deployment,” IEEE Internet of Things Journal,
vol. 6, no. 5, pp. 8804–8817, 2019.

[23] S. Sharma and A. Kaul, “A survey on intrusion detection systems and
honeypot based proactive security mechanisms in VANETs and VANET
cloud,” Vehicular communications, vol. 12, pp. 138–164, 2018.
[24] M. Barrett, “Framework for improving critical infrastructure cybersecu-

rity version 1.1,” 2018-04-16 2018.

[25] N. C. Rowe, “Measuring the effectiveness of honeypot counter-
counterdeception,” in Proceedings of the 39th Annual Hawaii Interna-
tional Conference on System Sciences, vol. 6.
IEEE, 2006, pp. 129c–
129c.

[26] A. Fielder, E. Panaousis, P. Malacaria, C. Hankin, and F. Smeraldi,
“Decision support approaches for cyber security investment,” Decision
Support Systems, vol. 86, pp. 13–23, 2016.

[27] P. Nespoli, D. Papamartzivanos, F. G. M´armol, and G. Kambourakis,
“Optimal countermeasures selection against cyber attacks: A compre-
hensive survey on reaction frameworks,” IEEE Communications Surveys
& Tutorials, vol. 20, no. 2, pp. 1361–1396, 2017.

[28] L. A. Gordon and M. P. Loeb, “The economics of information security
investment,” ACM Transactions on Information and System Security,
vol. 5, no. 4, pp. 438–457, 2002.

[29] M. Chronopoulos, E. Panaousis, and J. Grossklags, “An options approach
to cybersecurity investment,” IEEE Access, vol. 6, pp. 12 175–12 186,
2017.

[30] H. Hasrouny, A. E. Samhat, C. Bassil, and A. Laouiti, “VANET security
challenges and solutions: A survey,” Vehicular Communications, vol. 7,
pp. 7–20, 2017.

[31] O. Vermesan, P. Friess, P. Guillemin, S. Gusmeroli, H. Sundmaeker,
A. Bassi, I. S. Jubert, M. Mazura, M. Harrison, M. Eisenhauer et al.,
“Internet of things strategic research roadmap,” Internet of things-global
technological and societal trends, vol. 1, no. 2011, pp. 9–52, 2011.
[32] F. Qu, Z. Wu, F.-Y. Wang, and W. Cho, “A security and privacy review
of VANETs,” IEEE Transactions on Intelligent Transportation Systems,
vol. 16, no. 6, pp. 2985–2996, 2015.

[33] J. Petit and S. E. Shladover, “Potential cyberattacks on automated vehi-
cles,” IEEE Transactions on Intelligent transportation systems, vol. 16,
no. 2, pp. 546–556, 2014.

[34] S. Parkinson, P. Ward, K. Wilson, and J. Miller, “Cyber threats facing
autonomous and connected vehicles: Future challenges,” IEEE transac-
tions on intelligent transportation systems, vol. 18, no. 11, pp. 2898–
2915, 2017.

[35] T. Zhang, H. Antunes, and S. Aggarwal, “Defending connected vehicles
against malware: Challenges and a solution framework,” IEEE Internet
of Things journal, vol. 1, no. 1, pp. 10–21, 2014.

[36] C. Miller and C. Valasek, “Remote exploitation of an unaltered passenger

vehicle,” Black Hat USA, vol. 2015, p. 91, 2015.

[37] J. Li, Z. Xue, C. Li, and M. Liu, “Rted-sd: A real-time edge detection
scheme for sybil ddos in the internet of vehicles,” IEEE Access, vol. 9,
pp. 11 296–11 305, 2021.

[38] P. K. Singh, S. Gupta, R. Vashistha, S. K. Nandi, and S. Nandi, “Ma-
chine learning based approach to detect position falsiﬁcation attack in
VANETs,” in International Conference on Security & Privacy. Springer,
2019, pp. 166–178.

[40] J. Wang, Y. Tan, J. Liu, and Y. Zhang, “Topology poisoning attack in
sdn-enabled vehicular edge network,” IEEE Internet of Things Journal,
vol. 7, no. 10, pp. 9563–9574, 2020.

[41] T. E. Carroll and D. Grosu, “A game theoretic investigation of deception
in network security,” Security and Communication Networks, vol. 4,
no. 10, pp. 1162–1172, 2011.

[42] N. Boumkheld, S. Panda, S. Rass, and E. Panaousis, “Honeypot type
selection games for smart grid networks,” in International Conference
on Decision and Game Theory for Security. Springer, 2019, pp. 85–96.
[43] Q. Zhu and T. Bas¸ar, “Game-theoretic approach to feedback-driven
multi-stage moving target defense,” in International Conference on
Decision and Game Theory for Security. Springer, 2013, pp. 246–263.
[44] W. Tian, M. Du, X. Ji, G. Liu, Y. Dai, and Z. Han, “Honeypot detection
strategy against advanced persistent
internet of
things: A prospect theoretic game,” IEEE Internet of Things Journal,
2021.

threats in industrial

[45] J. You, S. Lv, L. Zhao, M. Niu, Z. Shi, and L. Sun, “A scal-
able high-interaction physical honeypot framework for programmable
logic controller,” in 2020 IEEE 92nd Vehicular Technology Conference
(VTC2020-Fall).

IEEE, 2020, pp. 1–5.

[46] A. Prathapani, L. Santhanam, and D. P. Agrawal, “Intelligent honeypot
agent for blackhole attack detection in wireless mesh networks,” in
2009 IEEE 6th International Conference on Mobile Adhoc and Sensor
Systems.

IEEE, 2009, pp. 753–758.

[47] M. R. Babu and G. Usha, “A novel honeypot based detection and
isolation approach (nhbadi) to detect and isolate black hole attacks in
MANET,” Wireless Personal Communications, vol. 90, no. 2, pp. 831–
845, 2016.

[48] N. Garg and D. Grosu, “Deception in honeynets: A game-theoretic
analysis,” in 2007 IEEE SMC Information Assurance and Security
Workshop.

IEEE, 2007, pp. 107–113.

[49] H. C¸ eker, J. Zhuang, S. Upadhyaya, Q. D. La, and B.-H. Soong,
“Deception-based game theoretical approach to mitigate dos attacks,”
in International Conference on Decision and Game Theory for Security.
Springer, 2016, pp. 18–38.

[50] C. Kiekintveld, V. Lis`y, and R. P´ıbil, “Game-theoretic foundations for
the strategic use of honeypots in network security,” in Cyber warfare.
Springer, 2015, pp. 81–101.

[51] J. Zhuang, V. M. Bier, and O. Alagoz, “Modeling secrecy and decep-
tion in a multiple-period attacker–defender signaling game,” European
Journal of Operational Research, vol. 203, no. 2, pp. 409–418, 2010.

[52] K. Durkota, V. Lis`y, B. Boˇsansk`y, and C. Kiekintveld, “Optimal
network security hardening using attack graph games,” in Twenty-Fourth
International Joint Conference on Artiﬁcial Intelligence, 2015.

[53] A. Nisioti, G. Loukas, A. Laszka, and E. Panaousis, “Data-driven
decision support for optimizing cyber forensic investigations,” IEEE
Transactions on Information Forensics and Security, vol. 16, pp. 2397–
2412, 2021.

[54] S. Panda, E. Panaousis, G. Loukas, and C. Laoudias, “Optimizing
investments in cyber hygiene for protecting healthcare users,” From
Lambda Calculus to Cybersecurity Through Program Analysis, 2020.

[55] A. Fielder, S. K¨onig, E. Panaousis, S. Schauer, and S. Rass, “Risk
assessment uncertainties in cybersecurity investments,” Games, vol. 9,
no. 2, p. 34, 2018.

[56] W. Fan, Z. Du, D. Fern´andez, and V. A. Villagra, “Enabling an anatomic
view to investigate honeypot systems: A survey,” IEEE Systems Journal,
vol. 12, no. 4, pp. 3906–3919, 2017.

[57] F. Araujo, K. W. Hamlen, S. Biedermann, and S. Katzenbeisser, “From
patches to honey-patches: Lightweight attacker misdirection, deception,
and disinformation,” in Proceedings of the 2014 ACM SIGSAC confer-
ence on computer and communications security, 2014, pp. 942–953.

[58] J. Avery and E. H. Spafford, “Ghost patches: Fake patches for fake vul-
nerabilities,” in IFIP International Conference on ICT Systems Security
and Privacy Protection. Springer, 2017, pp. 399–412.

[59] D. Fudenberg and J. Tirole, Game Theory. London: MIT Press, 1991.
[60] N. Pitropakis, E. Panaousis, A. Giannakoulias, G. Kalpakis, R. D.
Rodriguez, and P. Sarigiannidis, “An enhanced cyber attack attribution
framework,” in International Conference on Trust and Privacy in Digital
Business. Springer, 2018, pp. 213–228.

[61] S. Rass, S. K¨onig, and S. Schauer, “On the cost of game playing: How to
control the expenses in mixed strategies,” in International Conference on
Decision and Game Theory for Security. Springer, 2017, pp. 494–505.

[62] K. Hausken, “Returns to information security investment: The effect of
alternative information security breach functions on optimal investment
and sensitivity to vulnerability,” Information Systems Frontiers, vol. 8,
no. 5, pp. 338–349, 2006.

[63] M. T. Qassrawi and Z. Hongli, “Deception methodology in virtual
honeypots,” in 2010 Second International Conference on Networks
Security, Wireless Communications and Trusted Computing, vol. 2.
IEEE, 2010, pp. 462–467.

[64] R. Ruiz-Torrubiano, S. Garc´ıa-Moratilla, and A. Su´arez, “Optimization
problems with cardinality constraints,” in Computational Intelligence in
Optimization. Springer, 2010, pp. 105–130.

14

