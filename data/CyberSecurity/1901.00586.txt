Draining the Water Hole:
Mitigating Social Engineering Attacks with CyberTWEAK

Zheyuan Ryan Shi,1 Aaron Schlenker,2 Brian Hay3
Daniel Bittleston,1 Siyu Gao,1 Emily Peterson,1 John Trezza,1 Fei Fang1
1Carnegie Mellon University, 2Facebook, Inc., 3Security Works
ryanshi@cmu.edu, aschlenker@fb.com, bhay@securityworks.com
{dbittles, siyug, emilypet, jtrezza}@andrew.cmu.edu, feif@cs.cmu.edu

9
1
0
2

v
o
N
9
1

]

R
C
.
s
c
[

3
v
6
8
5
0
0
.
1
0
9
1
:
v
i
X
r
a

Abstract

Cyber adversaries have increasingly leveraged social engi-
neering attacks to breach large organizations and threaten the
well-being of today’s online users. One clever technique, the
“watering hole” attack, compromises a legitimate website to
execute drive-by download attacks by redirecting users to an-
other malicious domain. We introduce a game-theoretic model
that captures the salient aspects for an organization protecting
itself from a watering hole attack by altering the environment
information in web trafﬁc so as to deceive the attackers. Our
main contributions are (1) a novel Social Engineering Decep-
tion (SED) game model that features a continuous action set
for the attacker, (2) an in-depth analysis of the SED model to
identify computationally feasible real-world cases, and (3) the
CYBERTWEAK algorithm which solves for the optimal pro-
tection policy. To illustrate the potential use of our framework,
we built a browser extension based on our algorithms which is
now publicly available online. The CYBERTWEAK extension
will be vital to the continued development and deployment of
countermeasures for social engineering.

1

Introduction

Social engineering attacks are a scourge for the well-being
of today’s online user and the current threat landscape only
continues to become more dangerous (Mitnick and Simon
2001). Social engineering attacks manipulate people to give
up conﬁdential information through the use of phishing cam-
paigns, spear phishing whaling or watering hole attacks. For
example, in watering hole attacks, the attacker compromises
a legitimate website and redirects visitors to a malicious do-
main where the attacker can intrude the user’s network. The
number of social engineering attacks is growing at a catas-
trophic rate. In a recent survey, 60% organizations were or
may have been victim of at least one attack (Agari 2016).
Such cybercrime poses an enormous threat to the security at
all levels – national, business, and individual.

To mitigate these attacks, organizations take countermea-
sures from employee awareness training to technology-based
defenses. Unfortunately, existing defenses are inadequate.
Watering hole attackers typically use zero-day exploits, ren-
dering patching and updating almost useless (Sutton 2014).

Copyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Sand-boxing potential attacks by VM requires high-end
hardware, which hinders its wide adoption (Farquhar 2017).
White/blacklisting websites is of limited use, since the adver-
sary is strategically infecting trustworthy websites.

We propose a game-theoretic deception framework to mit-
igate social engineering attacks, and, in particular, the wa-
tering hole attacks. Deception is to delay and misdirect an
adversary by incorporating ambiguity. Watering hole attack-
ers rely on the identiﬁcation of a visitor’s system environment
to deliver the correct malware to compromise a victim. To-
wards this end, the defender can manipulate the identifying
information in the network packets, such as the user-agent
string, IP address, and time-to-live. Consequently, the at-
tacker might receive false or confusing information about the
environment and send incompatible exploits. Thus, decep-
tively manipulating employees’ network packets provides a
promising countermeasure to social engineering attacks.

Our Contributions We provide the ﬁrst game-theoretic
framework for autonomous countermeasures to social en-
gineering attacks. We propose the Social Engineering De-
ception (SED) game, in which an organization (defender)
strategically alters its network packets. The attacker selects
websites to compromise, and captures the organization’s traf-
ﬁc to launch an attack. We model it as a zero-sum game and
consider the minimax strategy for the defender.

Second, we analyze the structure and properties of the
SED game, based on which we identify real-world scenarios
where the optimal protection policy can be found efﬁciently.
Third, we propose the CYBERTWEAK (Thwart WatEring
hole AttacK) algorithm to solve the SED game. CYBER-
TWEAK exploits theoretical properties of SED, linear pro-
gram relaxation of the attacker’s best response problem, and
the column generation method, and is enhanced with domi-
nated website elimination. We show that our algorithm can
handle corporate-scale instances involving over 105 websites.
Finally, we have developed a browser extension based on
our algorithm. The software is now publicly available on the
Chrome Web Store.1 The extension is able to manipulate the
user-agent string in the network packets. We take additional
steps to improve the its usability and explain the output of
CYBERTWEAK intuitively. We believe it will be vital to the

1http://bit.ly/CyberTWEAK

 
 
 
 
 
 
mises a set of legitimate websites. Not only do these websites
need to be lucrative, but the attacker also has to be strategic
in this choice. For example, compromising Google.com is
nearly impossible while the Polish Financial Authority, vic-
tim of the 2017 Ratankba malware attacks (Symantec 2017),
cannot invest the same security resources. Indeed, in previ-
ous attacks the attacker was not observed to compromise all
websites (Parliament 2018). In step 3, employees visit the
compromised website and are redirected to a malicious web-
site which scans their system environment and the present
vulnerabilities. To gather this information, attackers use tech-
niques such as analyzing the user-agent string, operating
system ﬁngerprinting, etc. In Step 4, the attacker delivers
an exploit for an identiﬁed vulnerability. After these steps,
the attacker can navigate the target network and access the
sensitive information.

Our algorithm and browser extension introduce uncertainty
in step 3 of a watering hole attack. Identifying the vulnera-
bilities in a visitor relies on the information gathered from
reconnaissance. The extension modiﬁes the network packets
so that the attacker gets false information about the visitor.
Deception is not free, though. Altering the network packet
can degrade the webpage rendered, e.g., displaying for An-
droid on a Windows desktop. Thus, the defender needs to
carefully trade-off security and the quality of service.

In reality, sophisticated attackers typically do not send all
exploits without tailoring to the packet information, as de-
fense would become easier after seeing more such unknown
exploits. Also, sending all exploits would be ﬂagged as suspi-
cious and get blocked. The attacker would need to get a new
zero-day – a costly proposition. Thus, the attacker prefers
scanning the system environment of the incoming trafﬁc.

3 Social Engineering Deception Game

We model the strategic interaction between the organization
(defender) and an adversary as a two-player zero-sum game,
where the defender chooses an alteration policy and the ad-
versary chooses which websites to compromise and decides
the effort spent on scanning trafﬁc. In everyday activities em-
ployees of a target organization O visit a set of websites W
which includes legitimate sites and potential watering holes
set up by an adversary. Let tall
w denote the total amount of
trafﬁc to w ∈ W from all visitors and tw the total trafﬁc to
w from O. The defender’s alteration policy is represented
by x ∈ [0, 1]|W | where xw is the proportion of O’s trafﬁc to
website w ∈ W for which the network packet will be altered.
We assume a drive-by download attack will be unsuccessful
if, and only if an employee’s packet is altered. However, it is
easy to account for different levels of adversary and defender
sophistication by adding an additional factor in Eq. (1) below.
We consider a cost cw to alter a single unit of trafﬁc to w.
The defender is limited to a budget Bd on the allowable cost.
The adversary ﬁrst chooses which websites to compromise,
represented by a binary vector y ∈ {0, 1}|W |. If yw = 1, i.e.,
they turn website w into a watering hole, they must pay a cost
πw. The attacker has a budget Ba for compromising websites
(w.l.o.g. we assume πw ≤ Ba ∀w ∈ W ). The adversary
then decides the scanning effort for each compromised web-

Figure 1: Anatomy of a watering hole attack.

continued development of social engineering defenses.

Related Work Deception is one of the most effective
ways to thwart cyberattacks. Recent papers have considered
deception techniques for protecting an enterprise network
from an attack by sending altered system environment in-
formation in response to scans performed during the recon-
naissance phase of an attack (Albanese, Battista, and Jajodia
2016; Jajodia et al. 2017). There is a rising interest in building
game-theoretic models for deception (Schlenker et al. 2018),
in particular in the use of honeypots (Durkota et al. 2015;
Pıbil et al. 2012) in the enterprise network.

However, there is a fundamental difference between enter-
prise network defense and social engineering defense. In the
former, an adversary targets an organization by compromis-
ing computers in the network while in watering hole attacks
the attacker targets the user and compromises external web-
sites. A website in SED cannot be properly modeled as a
honeypot target, because the defender has no control over
it. Neither can the user, because the attack depends on an
external task – compromising a website. Instead of actively
querying the network, watering hole attackers passively mon-
itor the users’ trafﬁc. This necessitates the continuous action
space for the attacker in SED, which is also different from
most previous works on enterprise network defense.

Laszka, Vorobeychik, and Koutsoukos (2015) study spear
phishing, another form of social engineering attacks. The
nature of watering hole attacks leads to additional complica-
tions. For example, watering hole attackers need to compro-
mise a website and then scan the trafﬁc. Thus, in SED the
attacker has two layers of decision making: one continuous
and one discrete. This leads to a different problem formula-
tion and solution techniques than those in spear phishing.

2 Watering Hole Attacks
Watering hole attacks are a prominent type of social engineer-
ing used by sophisticated attackers. Before we describe our
modeling decisions, it is useful to highlight the primary steps
in executing a watering hole attack, as illustrated in Fig. 1. In
step 1, the attacker identiﬁes a target organization. They use
surveys and external information like specialized technical
sites to understand the browsing habits of its employees. This
allows the adversary to determine the most lucrative websites
to compromise for maximum exposure to employees from
the targeted organization. In step 2, the adversary compro-

1.Adversary targetsorganization2.Compromiselegitimatewebsite3(a). Users visitwebsite3(b). Redirectsuser and identifiesvulnerabilities4.Sends the exploitto compromisesystemsite which can enable them to send exploits tailored to the
packet information. We use ew to denote how much trafﬁc
the attacker decides to scan per week for w, and refer to e as
the effort vector. The discreet attacker has a budget Be for
scanning the incoming trafﬁc. In the special case where the
scanning effort is negligible (Be = ∞), all our complexity
and algorithmic results to be introduced still hold.

We consider an attacker who aims to maximize the ex-
pected amount of unaltered ﬂow from target organization O
that is scanned by them, as each unit of scanned unaltered
ﬂow can lead to a potential success in the social engineering
attack, i.e., compromise an employee and discover critical
information about O. We model it as a zero-sum game, and
therefore the defender’s goal is to minimize this amount.

Social engineering is a complex domain which we cannot
fully model. However, we build our model and assumptions
so that we can formally reason about deception, and even
when our assumptions are not met, our work provides a sensi-
ble solution. For example, cyber attackers may have tools to
circumvent existing deception techniques. Nonetheless, our
solution increases the attacker’s uncertainty about the envi-
ronment as they cannot easily obtain or trust the information
in the network packets. In Appendix E, we provide a detailed
discussion of the generality and limitations of our work.

4 Computing Optimal Defender Strategy
In this section, we present complexity analysis and algorithms
for ﬁnding the optimal defender strategy x∗ in this game,
which is essentially the minimax strategy, i.e., a strategy that
minmizes the attacker’s maximum possible expected amount
of scanned unaltered ﬂow. x∗ should be the solution of the
following bi-level optimization problem P1.

P1 : minx maxy,e
(cid:88)

s.t.

(cid:88)

w∈W

κw(1 − xw)ew

ew ≤ Be

w∈W

(cid:88)

πwyw ≤ Ba

w · yw, ∀w ∈ W

w∈W
ew ≤ tall
yw ∈ {0, 1}, ∀w ∈ W
ew ∈ [0, ∞), ∀w ∈ W
(cid:88)

cwtwxw ≤ Bd

w∈W

xw ∈ [0, 1], ∀w ∈ W

(1)

(2)

(3)

(4)
(5)
(6)

(7)

(8)

In objective function 1, κw = tw/tall
w . Since tw(1−xw) is the
total amount of unaltered ﬂow from the defender organization
O and ew/tall
w is the percentage of incoming trafﬁc that will
be scanned, κw(1 − xw)ew is the total scanned unaltered
trafﬁc to w. Constraint 2-3 describes the budget constraint for
the attacker, and Constraint 4 requires that the attacker can
only scan trafﬁc for the compromised websites. Constraint 7
is the budget constraint for the defender.

Unfortunately, solving P1 is challenging. It cannot be
solved using any of the existing solvers directly due to the
bi-level optimization structure, the mix of real-valued and bi-
nary variables and the bilinear terms in the objective function
(xwew). In fact, even the adversary’s best response problem

P2(x), represented as a mixed integer linear program (MILP)
below, is NP-hard as stated in Thm 1. Due to space limit, we
defer all the proofs to appendix.2

(cid:88)

P2(x) : max
y,e
s.t. Constraints (2) ∼ (6)

κw(1 − xw)ew

w∈W

(9)

(10)

Theorem 1. Finding adversary’s best response is NP-hard.
Therefore, we exploit the structure and properties of SED
and P1 and design several novel algorithms to solve it. We
ﬁrst identify two tractable special classes of SED games
which can be solved in polynomial time and discuss their real
world implications. Then we present CYBERTWEAK, our
algorithm for general SED games.

4.1 Tractable Classes
The ﬁrst tractable class is identiﬁed based on the key obser-
vation stated in Thm 2: the optimal solutions of SED games
exhibit a greedy allocation of the attacker’s effort budget.
That is, for at most one website w will the attacker spend
scanning effort neither zero nor tall
w .
Theorem 2. Let (x∗, y∗, e∗) be an optimal solution to P1,
WF = {w : e∗
w }, WZ = {w : e∗
w = 0}, WB = {w :
w ∈ (0, tall
e∗
w )}. There is an optimal solution with |WB| ≤ 1.
As a result, if the attacker’s scanning budget is so limited
that he cannot even scan through the trafﬁc of any website, he
will use all the scanning effort on one website in the optimal
solution. Thus, the optimal defender strategy can be found
by enumerating the websites.
Corollary 1. (Small Effort Budget) If 0 < Be ≤ tall
the optimal solution can be found in polynomial time.

w = tall

w , ∀w,

The second tractable class roots in the fact that if the scan-
ning effort is negligible (or equivalently, Be = ∞) the at-
tacker only needs to reason about which websites to compro-
mise. Further, if the attacker has a systematic way of compro-
mising a website which makes the cost πw uniform across
websites, then the attacker only needs to greedily choose the
websites with the highest unaltered incoming trafﬁc and the
defender can greedily alter trafﬁc in the top websites. We
provide details about these algorithms in the appendix.
Theorem 3. (Uniform Cost + Unlimited Effort) If πw =
1, ∀w ∈ W and Be = ∞, the defender’s optimal strategy
can be found in polynomial time.

4.2 CyberTWEAK
For the general SED games, we propose a novel algorithm
CYBERTWEAK (Alg 1). It ﬁrst computes an upper bound
for P1 leveraging the dual problem of the linear program
(LP) relaxation of P2(x). As a byproduct, the computation
provides a heuristic defender strategy ˆx∗ (Line 2). It then
runs an optimality check (Line 3) to see if ˆx∗ is optimal
for P1. When optimality cannot be veriﬁed, it solves the
original problem P1 by converting P1 to an equivalent LP
and applying column generation (Gilmore and Gomory 1961),
an iterative approach to compute the optimal strategy (Line

2https://arxiv.org/abs/1901.00586

Algorithm 1: CYBERTWEAK
1 Remove D ←FIND-DOMINATED-WEBSITES() from W .
2 Get heuristic defender strategy ˆx∗ by solving ˆP1.
3 if OP T (P2(ˆx∗)) ≤ OP T ( ˜P3(ˆx∗)) then return ˆx∗
4 Initialize max effort vector set eA = eP2(ˆx∗).
5 while new max effort vector was added to eA do
6

x ← solution of P LP
e ← solution of P2(x).
Add e to eA.

1 (eA).

7

8

5-8). We further improve the scalability by identifying and
eliminating dominated website as pre-processing (Line 1).
Next we provide details about these steps.

Upper Bound for P1

Let ˆP2(x) be the LP relaxation
of P2(x) and denote the dual variables of the (relaxed) con-
straints (2) ∼ (5) as λ1, λ2, ν, η. We then include the variable
x for the defender strategy along with the dual problem, and
obtain the minimization problem ˆP1.

ˆP1 : min
x,λ,ν,η

ηw

(cid:88)

Beλ1 + Baλ2 +

w∈W
s.t. κw(1 − xw) ≤ λ1 + νw,
w νw + ηw ≥ 0,
cwtwxw ≤ Bd

πwλ2 − tall
(cid:88)

w∈W

(11)

(12)

∀w ∈ W

∀w ∈ W (13)

(14)

xw ∈ [0, 1], λ1, λ2, νw, ηw ≥ 0, ∀w ∈ W (15)
ˆP1 is an LP which can be solved efﬁciently. In addition, ˆx∗
in the optimal solution for ˆP1 is a feasible defender strategy
in the original problem P1. Therefore, solving ˆP1 leads to a
heuristic defender strategy as well as bounds for the optimal
value of P1. Denote the optimal value of a problem P as
OPT(P). We formalize the bounds below.
Theorem 4. If Be ≥ maxw tall
Theorem 5. Let x∗, ˆx∗ be an optimal solution to P1, ˆP1.
OPT(P1) ≤ OPT(P2(ˆx∗)) ≤ OPT( ˆP1) ≤ OPT( ˆP2(x∗)).
Optimality Conditions for ˆx∗ We present a sufﬁcient
condition for optimality, which leverages the solution of the
following LP ˜P3(ˆx∗).
˜P3(ˆx∗) : min
x,v

w , OP T ( ˆP1) ≤ 3OP T (P1).

(16)

v

s.t.

v ≥

(cid:88)

(cid:88)

w∈W

w∈W
|xw − ˆx∗| ≤ (cid:15)

κw(1 − xw)ew, ∀e ∈ eP2(ˆx∗)

(17)

(18)

Constraints (7) ∼ (8)

(cid:15) is an arbitrary positive number and eP2(ˆx∗) denotes the
set of optimal effort vectors in P2(ˆx∗). The following claim
shows the optimality condition.
Claim 1. Given ˆx∗, an optimal solution to ˆP1, ˆx∗ is optimal
for P1 if OP T (P2(ˆx∗)) ≤ OP T ( ˜P3(ˆx∗)).

Clearly, when (cid:15) is large, OP T ( ˜P3(ˆx∗)) is lower and it is
harder to satisfy the condition, so in CYBERTWEAK, we
use a small enough (cid:15) in ˜P3(ˆx∗).

Column Generation

Deﬁne ˆeA as the set of all max
effort vectors which satisfy (cid:80)
w ew = Be and |WB| ≤ 1.
According to Thm 2, restricting the attacker to only choose
strategies from ˆeA will not impact the optimal solution for
the defender. As a result, P1 is equivalent to the following
1 (eA), when eA = ˆeA.
LP, denoted as P LP

P LP

1 (eA) : min
x,v
(cid:88)

s.t.

v ≥

v

w∈W
Constraints (7) ∼ (8)

κw(1 − xw)ew

(19)

(20)

∀e ∈ eA

1 (ˆeA), the order
Although existing LP solvers can solve P LP
of ˆeA is prohibitively high, leading to poor scalability. There-
fore, CYBERTWEAK instead uses an iterative algorithm
based on the column generation framework to incrementally
generate constraints of the LP. Instead of enumerating all of
ˆeA, we keep a running subset eA ⊆ ˆeA of max effort vectors
1 (eA) (referred to as the
and alternate between solving P LP
master problem) and ﬁnding a new max effort vector to be
added to eA (slave problem). In the slave problem, we solve
the adversary’s best response problem P2(x) where x is the
latest defender strategy found. This process repeats until no
new effort vectors are found for the adversary. Recall that
we get ˆx∗ and eP2(ˆx∗) when ﬁnding upper bound and veri-
fying optimality of ˆx∗, which can serve as the initial set of
strategies for column generation.

Dominated Websites

Not all websites are equally valu-
able for an organization as some are especially lucrative for
an adversary to target. In a Polish bank, many employees
may visit the Polish Financial Authority website daily, while
perhaps a CS conference website is rarely visited by a banker.
Intuitively, attackers will not compromise the conference
website and thus, the bank may not need to alter trafﬁc to
it. Identifying such websites in pre-processing could greatly
reduce the size of our problem. A website w is dominated by
another website u if the attacker would not attack w unless
they have used the maximum effort on u, i.e. eu = tall
u , re-
gardless of the defender’s strategy. Thm 6 presents sufﬁcient
conditions for a website to be dominated and leads to an al-
gorithm (Alg. 6) to ﬁnd dominated website to be eliminated.
Theorem 6. Consider websites u, w ∈ W . If the following
conditions hold, the website w is dominated by u:

xmax
u

:= Bd/(cutu) ≤ 1,

πw ≥ πu,

κw ≤ κu(1 − xmax
w ≤ tall
tall
u .

u

),

We conclude the section with the following claim.

Claim 2. CYBERTWEAK terminates with optimal solution.
In light of the hardness of the attacker’s best response prob-
lem (Thm 1), we also design a variant of CYBERTWEAK,
which uses a greedy heuristic to ﬁnd a new max effort
vector to be added in each iteration of column generation
(denoted as GREEDYTWEAK). The algorithm allocates
the adversary’s budget to websites in decreasing order of

Algorithm 2: FIND-DOMINATED-WEBSITES
1 Deﬁne U = {w ∈ W : cwtw ≥ Bd}. Let D = ∅.
2 Calculate xmax
u = Bd/cutu, ∀u ∈ U
3 foreach website w ∈ W do
4

Set Uw = {u ∈ U : κw ≤ κu(1 − xmax
if exists U ∗
w ⊆ Uw such that
πu ≤ πw, (2) (cid:80)
(1) (cid:80)
u ≥ tall
tall
(3) (cid:80)
tall
u ≥ Be then D = D ∪ {w}

u∈U ∗
w

u∈U ∗
w

)}

5

6

u

u∈U ∗
w

w , and

7 return set of dominated websites D

rw = κw(1 − xw)αw, where αw is a tuning parameter. An-
other variant uses an exact dynamic programming algorithm
for the slave problem. Details about these variants can be
found in Appendix A. Also, we note that the SED problem is
related to the recent work on bi-level knapsack with interdic-
tion (Caprara et al. 2016). However, our outer problem of P1
is continuous rather than discrete, and the added dimension
of adversary’s effort makes the inner problem P2(x) more
complicated than that being studied in this work.

5 Experiments
We developed and tested CYBERTWEAK to match the scal-
ability required of large-scale deployment. Unless otherwise
noted, problem parameters are described in details in Ap-
pendix D. All results are averaged over 20 instances; error
bars represent standard deviations of the mean.

First, we run experiments on the polynomial time tractable
cases (Corollary 1 and Theorem 3). Fig. 2a shows that in both
cases, our solution can easily handle 105 websites, applicable
to real-world corporate-scale problems.

Moving on to the general SED games, we test 3 algorithms
(CYBERTWEAK, GREEDYTWEAK, and RELAXEDLP)
with two other baselines, MAXEFFORT and ALLACTIONS.
RELAXEDLP refers to solving ˆP1. MAXEFFORT solves
1 (ˆeA) directly without column generation. ALLACTIONS
P LP
decomposes SED into subproblems, each assuming some
adversary’s effort vector is a best response. Its details can be
found in Appendix A. We test the algorithms with different
problem scales. In small and medium sized instances, we skip
dominated website eliminateion (DWE) step (Line 6) and
optimality check (OC) step (Line 3) in Alg. 1 as the problem
size is small enough, making these steps unnecessary. We use
solid lines to represent methods with optimality guarantee
and dotted lines for others (RELAXEDLP based methods).

For small instances (Fig. 2b), both baselines become im-
practical even on problems with less than 12 websites. How-
ever, CYBERTWEAK is able to ﬁnd the optimal solutions
rather efﬁciently. GREEDYTWEAK slightly improves over
CYBERTWEAK. RELAXEDLP yields the fastest running
time, despite a solution gap above 6% as shown in Table 1.

For medium-sized instances (Fig. 2c), baseline algo-
rithms cannot run and GREEDYTWEAK stops being help-
ful, mainly because the “better” effort vectors generated in
GREEDYTWEAK far outnumbers the “best” effort vectors
in CYBERTWEAK (Fig. 2d) despite the saved time in each

(a) Tractable cases

(b) Small instances

(c) Medium instances running time (d) Medium instances #strategies

(e) Large instances

(f) Trade-off

Figure 2: Experiment results

iteration. RELAXED LP has negligible running time and often
solves the problem optimally (Table 1).

For large instances (Fig. 2e), CYBERTWEAK with both
DWE and OC steps is able to handles 105 websites in 10
seconds. When we remove (denoted as “w\o”) DWE and/or
OC step, runtime increases signiﬁcantly, showing the efﬁcacy
of these steps3 Compared to RELAXEDLP or RELAXEDLP
enhanced with DWE step, which can also efﬁciently handles
105 websites, CYBERTWEAK has optimality guarantee.

Finally, we consider the trade-off between the risk expo-
sure and degradation in rendering websites, represented by
the objective OP T (P1) and defender’s budget Bd, respec-
tively. With budget ¯Bd = (cid:80)
w∈W cwtw, the attacker would
have zero utility. With zero defender budget, the attacker
would get maximum utility ¯U . Fig. 2f shows how the utility
ratio OP T (P1)/ ¯U changes with the budget ratio Bd/ ¯Bd. As
the organization increases the tolerance for service degrada-
tion, its risk exposure drops at a decreasing rate.

3The impact of DWE varies signiﬁcantly across instances and
relies heavily on the distribution of trafﬁc. In less than 4 of the 20
instances DWE did not reduce the problem size by much. We report
in Fig. 2e the majority group where DWE eliminated a signiﬁcant
number of websites. We provide further discussion in Appendix D.

246810Number of Websites (×104)024681012Running Time (s)Small Effort BudgetUniform Cost + Unlimited Effort456789101112Number of Websites103102101100101102Running Time (s)CyberTWEAKGreedyTWEAKAll ActionsMax EffortRelaxed LP50100150200250300350Number of Websites102101100101102Running Time (s)CyberTWEAKGreedyTWEAKRelaxed LP50100150200250300350Number of Websites0100020003000400050006000Strategies GeneratedCyberTWEAKGreedyTWEAK2345678910Number of Websites (×104)100101102103Running Time (s)CyberTWEAKw/o OCw/o DWE or OCRelaxed LPRelaxed LP w/ DWE0.00.20.40.60.81.0Budget Ratio0.00.20.40.60.81.0Utility Ratio|W|=10|W|=30|W|=100|W |
4
8
12
50
100

Gap
13.19%
8.11%
6.63%
2e-6
8e-9

# Exact
2/20
5/20
8/20
18/20
19/20

|W |
150
200
250
300
350

Gap
7e-8
8e-10
0
2e-3
2e-8

# Exact
16/20
19/20
20/20
17/20
18/20

Table 1: Solution quality of RELAXEDLP, with the number
of instances where RELAXEDLP solves the problem exactly.

6 Deployment
Based on CYBERTWEAK, we developed a browser exten-
sion (available on the Google Chrome Web Store1). It can
modify the user-agent string sent to websites automatically
during browsing which contains information such as the op-
erating system, browser, and services running on the user’s
machine. The extension receives from the user the websites
visited W , number of visits per week tw, the cost to alter the
user-agent string cw and budget Bd. The total trafﬁc tall
w and
attack cost πw are estimated from the Cisco Umbrella 1 Mil-
lion list (Cisco 2019). The attacker’s budgets are set in scale
with the previously mentioned parameters. The extension
runs CYBERTWEAK to set the probability of altering the
user-agent string for each website. Note that it is the relative
magnitudes, rather than the exact values, that matter.

The extension takes additional steps to make our algorithm
more usable and interpretable. First, some users may ﬁnd it
hard to specify the cost of altering user-agent string cw and
budget Bd. Our extension will adjust the values based on
the qualitative feedback provided by users about whether the
degradation of the website’s rendering is acceptable when
they visit a website using the modiﬁed user-agent, as shown
in Fig. 3. Second, in addition to showing the computed alter-
ing probabilities, the extension also displays a personalized
“risk level” for each website, to help the user understand the
algorithm’s output. Less popular websites frequented more
often by the user have higher risk, as shown in Fig. 3.

As mentioned in Section 3, advanced cyber attackers might
sometimes circumvent the existing deception methods. Fu-
ture versions of the extension will leverage the latest advances
in anti-ﬁngerprinting techniques, which entail manipulating
more than the user-agent string.

We believe this CYBERTWEAK extension is vital to the
continued study and development of the countermeasure we
develop for this domain and large scale deployments.

Acknowledgments
Co-authors Z. R. Shi and F. Fang are supported in part by
the U.S. Army Combat Capabilities Development Command
Army Research Laboratory under Cooperative Agreement
Number W911NF-13-2-0045 (ARL Cyber Security CRA).

References
[Agari 2016] Agari. 2016. Email Security: Social Engineering

Report.

[Albanese, Battista, and Jajodia 2016] Albanese, M.; Battista, E.;
and Jajodia, S. 2016. Deceiving attackers by creating a virtual
attack surface. In Cyber Deception.

Figure 3: Screenshots of the browser extension

[Caprara et al. 2016] Caprara, A.; Carvalho, M.; Lodi, A.; and Woeg-
inger, G. J. 2016. Bilevel knapsack with interdiction constraints.
INFORMS Journal on Computing.

[Cisco 2019] Cisco. 2019. Cisco Umbrella Popularity List.

[Durkota et al. 2015] Durkota, K.; Lis`y, V.; Bosansk`y, B.; and Kiek-
intveld, C. 2015. Optimal network security hardening using attack
graph games. In IJCAI.

[Farquhar 2017] Farquhar, D. 2017. Watering hole attack preven-

tion.

[Gilmore and Gomory 1961] Gilmore, P. C., and Gomory, R. E.
1961. A linear programming approach to the cutting-stock problem.
Operations research 9(6):849–859.

[Jajodia et al. 2017] Jajodia, S.; Park, N.; Pierazzi, F.; Pugliese, A.;
Serra, E.; Simari, G. I.; and Subrahmanian, V. 2017. A probabilistic
logic of cyber deception.

[Laszka, Vorobeychik, and Koutsoukos 2015] Laszka, A.; Vorobey-
chik, Y.; and Koutsoukos, X. D. 2015. Optimal personalized ﬁltering
against spear-phishing attacks.

[Mitnick and Simon 2001] Mitnick, K. D., and Simon, W. L. 2001.
The art of deception: Controlling the human element of security.

[Parliament 2018] Parliament. 2018. Watering Hole Attacks.

[Pıbil et al. 2012] Pıbil, R.; Lis`y, V.; Kiekintveld, C.; Boˇsansk`y, B.;
and Pechoucek, M. 2012. Game theoretic model of strategic honey-
pot selection in computer networks.

[Schlenker et al. 2018] Schlenker, A.; Thakoor, O.; Xu, H.; Tambe,
M.; Vayanos, P.; Fang, F.; Tran-Thanh, L.; and Vorobeychik, Y.
2018. Deceiving cyber adversaries: A game theoretic approach. In
AAMAS.
[Sutton 2014] Sutton, M. 2014. How to protect against watering

hole attacks.

[Symantec 2017] Symantec. 2017. Attackers target dozens of global

banks with new malware.

[Whittaker 2013] Whittaker, Z. 2013. Facebook, Apple hacks could

affect anyone: Here’s what you can do.

Draining the Water Hole:
Mitigating Social Engineering Attacks
with CyberTWEAK

Appendix

A Deferred Algorithms

A.1 Attacker’s Better Response Heuristic

w

αw

In light of the hardness of ﬁnding the adversary’s best re-
sponse, we consider a greedy heuristic. Leveraging Theo-
rem 2, GREEDY (Alg. 3) allocates the adversary’s budget to
websites in decreasing order of the ratio rw = tw(1−xw)/tall
,
where αw is a tuning parameter. We replace the MILP for
P2(x) in CYBERTWEAK with Alg. 3 to ﬁnd an adversary’s
better response. If it does not yield a new effort vector, the
MILP is called. The column generation process terminates
if the MILP again does not ﬁnd a new effort vector. We re-
fer to this entire procedure as GREEDYTWEAK. Note that
GREEDYTWEAK also terminates with the optimal solution.
Although GREEDY (Alg. 3) does not provide an approxima-
tion guarantee, it performs well in practice. As we show in
the experiment section, in practice the accuracy of its so-
lution improves as the size of the problem grows. We also
considered a dynamic programming algorithm which is exact
and runs in pseudo-polynomial time. However, its practical
performance is unsatisfactory.

Algorithm 3: GREEDY
1 Sort the websites in decreasing order of

rw = tw(1−xw)/tall

w

.

αw

2 foreach website w in the sorted order do
3

if remaining attack budget ≥ attack cost πw then
Attack this website w with maximum effort
allowed

if running out of budget then break

4

5

A.2 Baseline Algorithm for P1

We show the details of one of our baseline algorithms, All
Actions, in Alg. 4. Let A denote the set of actions available
to the adversary such that the budget constraint is satisﬁed.
Each action a∗ ∈ A is a set of websites being compromised.
According to Theorem 2, among all the websites w compro-
mised in a∗, the adversary puts “partial” effort ew ∈ (0, tall
w
on at most one website w∗. Therefore, the action-website
pairs (a∗, w∗) fully characterize the adversary’s strategies.
Alg. 4 works by ﬁnding the optimal defender strategy, assum-
ing each action-website pair is the optimal strategy for the
adversary.

Algorithm 4: ALL ACTIONS
1 foreach (a∗, w∗) ∈ A × W where w∗ ∈ a∗ do
2

foreach website w ∈ W do

3

4

5

6

7

8

9

10

11

12

w∈a∗,w(cid:54)=w∗ tall

w , tall
w∗ }

if w = w∗ then
Deﬁne
zw = min{Be − (cid:80)

else if w ∈ a∗ then
Deﬁne zw = tall
w

else

Deﬁne zw = 0
zw

Deﬁne kw = tw
tall
w
foreach (ˆa, ˆw) ∈ A × W where ˆw ∈ ˆa do
Deﬁne ˆkw similarly as above, for each
w ∈ W .
Add to BR(a∗, w∗) the following linear
constraint
(cid:80)

w∈a∗ kw(1 − xw) ≥ (cid:80)

w∈ˆa

ˆkw(1 − xw)

13

Solve the following LP

min
x,v

v

s.t.

v ≥

(cid:88)

w∈W

kw(1 − xw)

linear constraints in BR(a∗, w∗)
(cid:88)

cwtwxw ≤ Bd

w∈W
xw ∈ [0, 1],

∀w ∈ W

(21)

(22)

(23)

(24)

(25)

14 Select the best solution out of all the LPs.

B Deferred Proofs

B.1 Proof of Theorem 1

We reduce from the knapsack problem. In the knapsack prob-
lem, we have a set W of items each with a weight ωw and
value pw ∀w ∈ N , and aim to pick items of maximum possi-
ble value subject to a capacity B. We now create an instance
of the SED problem. Create a website for each item w ∈ W
with organization trafﬁc and total trafﬁc tw = tall
w = pw and
attack cost ωw. Assume that x = 0T . Next, set Ba = B
and Be = ∞. Notice that the objective function becomes
(cid:80)
w∈W ew ≤ ∞ and ew ≤ pwyw. Hence,
ew = pw whenever yw = 1. Then, the adversary’s best
response problem is given by:

w∈W ew where (cid:80)

(cid:88)

w∈W
(cid:88)

max
y

s.t.

pwyw

ωwyw ≤ B

w∈W
yw ∈ {0, 1}

(26)

(27)

∀w ∈ W

(28)

This is exactly the knapsack problem described above.

w)/tall

B.2 Proof of Theorem 2
For each w ∈ W , let kw = tw(1 − x∗
w . Suppose there
exist some w1, w2 ∈ WB, and w.l.o.g assume kw1 ≥ kw2.
Let ∆e = min{e∗
− e∗
, tall
}. Consider the solution
w1
w1
w2
(x∗, y∗, ˆe) where ˆew1 = e∗
− ∆e, and
w1
ˆew = e∗
w for all other websites w ∈ W . This is a feasible
solution, and the objective increases by (kw1 − kw2 )∆e ≥ 0
compared to (x∗, y∗, e∗). Furthermore, at least one of w1
and w2 is removed from WB. We can apply this argument
repeatedly until |WB| ≤ 1.

+ ∆e, ˆew2 = e∗
w2

B.3 Proof of Corollary 1
Since Be ≤ tall
w ∀w ∈ W , we know |WF | ≤ 1 for any fea-
sible solution. If |WF | = 1, then we have |WZ| = n − 1
and |WB| = 0. If |WF | = 0, by Theorem 2, we have
|WB| = 1 and |WZ| = n − 1. In either case, there is
only website w∗ such that ew∗ > 0. It follows that w∗ ∈
arg maxw∈W
given a defender strategy x. The
optimal defender strategy can be found by solving the follow-
ing LP.

tw(1−xw)Be
tall
w

(29)

∀w ∈ W

(30)

min
x,v

v

s.t.

v ≥

(cid:88)

tw(1 − xw)Be
tall
w
cwtwxw ≤ Bd

w∈W
xw ∈ [0, 1]

∀w ∈ W

B.4 Proof of Theorem 3

Under these assumptions, the problem P1 becomes

min
x

max
y,e

s.t.

(cid:88)

w∈W
(cid:88)

w∈W
(cid:88)

tw(1 − xw)yw

yw ≤ Ba

cwtwxw ≤ Bd

w∈W
xw ∈ [0, 1], yw ∈ {0, 1}

∀w ∈ W (36)

The constraint (cid:80)

w∈W yw ≤ Ba must be satisﬁed with
equality because tw(1 − xw) ≥ 0 for all w ∈ W . The de-
fender’s problem is to minimize the sum of Ba largest linear
functions tw − twxw among the n = |W | of them, subject to
the polyhedral constraints on xw. This problem can be solved
as a single LP (Ogryczak and Tamir 2003) as follows.

min
d+,x,z

Baz +

(cid:88)

d+
w

w∈W

s.t. d+

w ≥ tw − twxw − z
(cid:88)
cwtwxw ≤ Bd

w∈W
xw ∈ [0, 1], d+

w ≥ 0

∀w ∈ W

(37)

∀w ∈ W (38)

(39)

(40)

(31)

(32)

(33)

(34)

(35)

B.5 Proof of Theorem 4
Let x∗ be the optimal solution to P1. Consider the problem
ˆP2(x∗). At optimal solution, the inequality ew ≤ tall
w · yw in
ˆP2(x∗) is satisﬁed with equality, as if ew < tall
w · yw, then we
can decrease yw without changing the objective value and vi-
olating any constraints. Then, we can eliminate the variables
ew and ˆP2(x∗) becomes a standard two-dimensional frac-
tional knapsack problem ˆP4(x∗). It is well-known that there
exists an optimal solution to ˆP4(x∗) which has at most 2 frac-
tional values yw1 and yw2 (Kellerer, Pferschy, and Pisinger
2004). We have

OP T ( ˆP1) ≤ OP T ( ˆP2(x∗)) = OP T ( ˆP4(x∗))
≤ OP T (P2(x∗)) + tw1(1 − x∗
w1
≤ 3OP T (P2(x∗)) = 3OP T (P1)

) + tw2 (1 − x∗
w2

)

Note that if Be = ∞, ˆP1 is a 2-approximation.

B.6 Proof of Theorem 5
Since ˆx∗ and its best response calculated by P2(ˆx∗) form a
feasible solution to P1, the ﬁrst inequality holds. For any de-
fender strategy x, OPT(P2(x)) ≤ OPT( ˆP2(x)) as adversary
can choose fractional yw’s in ˆP2(x). For ˆx∗ speciﬁcally, we
have OPT( ˆP2(ˆx∗)) = OPT( ˆP1), since ˆP1 is, by strong dual-
ity, equivalent to P1 except that the adversary is allowed to
choose fractional yw’s. This establishes the second inequality.
The last inequality holds because x∗ and its fractional best
response calculated by ˆP2(x∗) form a feasible solution to
ˆP1.

B.7 Proof of Theorem 6
From conditions (1) and (2), we know that for the same
amount of effort, the attacker will be better off attacking
website u than w, regardless of the defender’s strategy.

Suppose ew > 0 and eu = 0 (consequently yw = 1, yu =
w = 0 and e(cid:48)
u = ew. This is possible
u so we have
u . Doing this does not increase the attack cost be-
u = 1 and πw ≥ πu from condition

0). Then we could let e(cid:48)
because from condition (4), ew ≤ tall
e(cid:48)
u ≤ tall
cause now y(cid:48)
(3).

w = 0 and y(cid:48)

w ≤ tall

Suppose ew > 0 and eu > 0 (consequently yw =
u =
w > 0, then
u . Of course, the attack cost does not increase as

w = ew − min{ew, tall
u − eu}. We know that if e(cid:48)

u − eu} and e(cid:48)

yu = 1). Let e(cid:48)
eu + min{ew, tall
e(cid:48)
u = tall
well.

B.8 Proof of Claim 1
Suppose (ˆx∗, OP T (P2(ˆx∗))) is not an optimal solution for
1 (ˆeA) which is equivalent to P1. Thus, equiva-
the LP P LP
lently ˆx∗ not optimal for P1. Any of its neighborhood with
radius (cid:15) contains some (ˆx(cid:48), v(cid:48)) as a better solution, mean-
ing v(cid:48) < OP T (P2(ˆx∗)). This solution (ˆx(cid:48), v(cid:48)) satisﬁes con-
straint (20), which is strictly stronger than constraint (17).
Therefore (ˆx(cid:48), v(cid:48)) is feasible for ˜P3(ˆx∗); this contradicts
OP T ( ˜P3(ˆx∗)) ≥ OP T (P2(ˆx∗)).

αw
πw
πw/Ba + 1/Be
1

OPT−OPTGreedy
OPT
0.0079
0.0285
0.0082

Table 2: Solution gaps of different greedy heuristics for the
adversary best response problem. Results are averaged over
5 runs on different problem sizes |W | = 100, 200, . . . , 500.

(a) GREEDY running time

(b) GREEDY solution gap

B.9 Proof of Claim 2
Claim 1 has covered the case where CYBERTWEAK ter-
minates after the optimality check on Line 3, Alg. 1. In the
other case, CYBERTWEAK terminates when no new effort
vectors are found for the adversary. Suppose x is the opti-
mal solution to the defender’s optimization problem (Line 6,
Alg. 1), and suppose now P2(x) does not ﬁnd a new effort
vector (Line 7, Alg. 1). This implies x would still be feasible
1 (eA) even if eA is replaced by the set of all
for the LP P LP
max effort vectors ˆeA. Thus, x is an optimal solution. Indeed,
1 (eA) and P2(x) are
at this point the optimal values of P LP
equal.

w

αw

C Deferred Experiments
We present additional experiments on the adversary’s best
response problem. In the GREEDY algorithm (Alg. 3), the
adversary selects websites based on a decreasing order of
rw = tw(1−xw)/tall
. Here, αw is the tuning parameter.
With different choices of αw, we compare the output value
OPTGreedy of GREEDY with the optimal value OPT obtained
by solving the MILP P2(x). Table 2 shows the solution gap
OPT−OPTGreedy
. We observe that αw = πw yields the small-
OPT
est solution gap. We also tested other choices for αw such
as (πw/Ba)p + (1/Be)q for different powers p and q, yet
they do not yield better optimization gaps. Hence we ﬁx
rw = tw(1−xw)/tall

in subsequent experiments.

w

Fig. 4b shows GREEDY’s solution gap decreases to near
zero as the problem size grows. In addition, GREEDY typi-
cally runs within 1% of the time of the MILP.

πw

D Experiment Parameters
Table 3 shows the distribution from which the parameters are
generated in most of our experiments. In Table 4, we detail
the parameters used in the experiment in Fig. 2e.

In addition, in the case of small effort budget, Be is gener-

ated uniformly between 1 and minw∈W tw

all.

Variable Distribution
tall
U (350, 750)
w
U (50, 100)
tw
U (1, 4)
cw
U (30, 54)
πw
U (0.11 (cid:80)
Bd
U (0.1 (cid:80)
Ba
U (0.2 (cid:80)
Be

w∈W cwtw, 0.71 (cid:80)
w∈W πw, 0.8 (cid:80)
w , 0.8 (cid:80)
w∈W tall

w∈W πw)
w∈W tall
w )

w∈W cwtw)

Table 3: Parameter distribution

For w ∈ W1

For w ∈ W2

Variable Distribution Variable Distribution
U (20, 70)
U (3, 8)
U (1, 3)
3
w∈W cwtw/|W |)

U (60, 110)
U (45, 55)
U (2, 6)
3
U (0, 10 (cid:80)

tall
w
tw
cw
πw
w∈W πw, 0.8 (cid:80)
w∈W tall

tall
w
tw
cw
πw
Bd
Ba
Be

U (0, 3 (cid:80)

U (0.1 (cid:80)

w∈W πw)

w /|W |)

Table 4: Parameter distributions for the experiment on large
instances.

For large scale instances, we set different websites to have
different importance, motivated by the fact that people do
not visit all websites with equal frequency. We split W into
W1, W2 with |W1| : |W2| = 1 : 9. Websites in W1 have a
large portion of trafﬁc from the organization and those in
W2 have a smaller portion. Thus, W1 and W2 follow differ-
ent distributions (Table 4). The attacker has a uniform cost
of attack. In less than 4 of the 20 instances DWE did not
reduce the problem size by much. We report in Fig. 2e the
majority group where DWE eliminated a signiﬁcant number
of websites. |W1|/|W | could be a lot smaller in reality, and
our algorithms with DWE would run even faster.

E Discussion
Assumptions and generality We assumed that the attack
will succeed if and only if the network packet is unaltered.
If the attacker can obtain the true system information with
probability pw even if the packet is altered, we may modify
the objective in Eq. (1) to (cid:80)
w tw(1 − xw(1 − pw))ew/tall
w .
If the organization has other countermeasures (e.g. Bromium
browser VMs), the attack may fail with probability qw
even if the packet is unaltered, the objective then becomes
(cid:80)
w . Thus, our algorithm can
account for different levels of adversary and defender sophis-
tication.

w tw(1 − xw)(1 − qw)ew/tall

We do not attempt to claim that altering the network pack-
ets is a panacea to all watering hole attacks. Cyber attackers
have many tools to circumvent existing deception techniques.
Nonetheless, the proposed deception technique increases
their uncertainty about the true nature of the environment,
which leads to more cost on them, e.g. technical complexity
and increased exposure. This uncertainty ties into our consid-
eration of the attacker’s scanning effort ew and budget Be, as

the attacker cannot easily obtain or trust the basic information
in the network packets.

Limitations The generality notwithstanding, We ac-
knowledge a few limitations of our work and potential prob-
lems in large-scale deployment. First, if an organization is
the sole user of our method and if the attacker has (possi-
bly imperfect) clue about the source of trafﬁc from the start,
randomizing network packet information might serve as an
unintended signal to the attacker, reducing the effort needed
ew to identify trafﬁc from the targeted organization. Second,
by manipulating the web trafﬁc, the organization is effec-
tively monitoring its employees’ internet activities. Although
in many jurisdictions this is allowed when doing properly,
the potential ethical issues must be carefully addressed.

References
[Ogryczak and Tamir 2003] Ogryczak, W. and Tamir, A.,
2003. Minimizing the sum of the k largest functions in linear
time. Information Processing Letters, 85(3), pp.117-122.
[Kellerer, Pferschy, and Pisinger 2004] Kellerer, H., Pfer-
schy, U. and Pisinger, D., 2004. Knapsack problems. Springer,
Berlin, Heidelberg.

