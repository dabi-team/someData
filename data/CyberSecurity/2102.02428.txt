A Game-Theoretic Approach to Secure Estimation and Control for
Cyber-Physical Systems with a Digital Twin

1st Zhiheng Xu
School of Electrical and Electronic Engineering
Nanyang Technological University, Singapore
Email: zhiheng.xu688@gmail.com

2nd Arvind Easwaran
School of Computer Science and Engineering
Nanyang Technological University, Singapore
Email: arvinde@ntu.edu.sg

1
2
0
2

b
e
F
4

]

Y
S
.
s
s
e
e
[

1
v
8
2
4
2
0
.
2
0
1
2
:
v
i
X
r
a

Abstract—Cyber-Physical Systems (CPSs) play an increasingly
signiﬁcant role in many critical applications. These valuable
applications attract various sophisticated attacks. This paper
considers a stealthy estimation attack, which aims to modify the
state estimation of the CPSs. The intelligent attackers can learn
defense strategies and use clandestine attack strategies to avoid
detection. To address the issue, we design a Chi-square detector
in a Digital Twin (DT), which is an online digital model of the
physical system. We use a Signaling Game with Evidence (SGE)
to ﬁnd the optimal attack and defense strategies. Our analytical
results show that the proposed defense strategies can mitigate the
impact of the attack on the physical estimation and guarantee the
stability of the CPSs. Finally, we use an illustrative application
to evaluate the performance of the proposed framework.

Index Terms—Cyber-Physical Systems, Data-Integrity Attack,

Signaling Game with Evidence, Digital Twin.

I. INTRODUCTION

Cyber-Physical Systems (CPS) integrate physical compo-
nents (e.g., sensors, actuators, and controllers), computational
resources, and networked communications [1]. The integration
with networked communications highly enhances the ﬂexi-
bility and scalability of CPSs in various applications, such
as large-scale manufacturing systems [2], intelligent trans-
port systems [3], and smart grid infrastructure [4]. However,
the valuable applications of CPSs attract many sophisticated
attacks. A well-known example is the Stuxnet, a computer
virus compromises Supervisory control and data acquisition
(SCADA) of industrial systems [5]. Besides, we have wit-
nessed many other control-system-related attacks, such as
Maroochy Water attack [6], Unmanned Aerial Vehicle’s (UAV)
GPS spooﬁng attack [7], and German Steel Mill cyber attack
[8].

Due to the increasing number of security-related incidents
in CPSs, many researchers have studied the features of these
attacks and developed relevant defense strategies. Among
many attack models, we focus on data-integrity attacks, where
the attackers modify the original data used by the system or
inject unauthorized data to the system [9]. The data-integrity
attacks can cause catastrophic consequences in CPSs. For
instance, the fake data may deviate the system to a dangerous
trajectory or make the system oscillate with a signiﬁcant

This work was supported by Delta-NTU Corporate Lab for Cyber-Physical
Systems with funding support from Delta Electronics Inc. and the National
Research Foundation (NRF) Singapore under the Corp Lab@University
Scheme.

amplitude, destabilizing the system. Therefore, how to mitigate
the impact of data-integrity attacks becomes a critical issue in
the security design of CPSs.

One typical data-integrity attack for CPSs is the Sensor-and-
Estimation (SE) attack, where the attackers tamper the sensing
or estimated information of the CPSs [10]. Given the SE
attack, Fawzi et al. [11] have studied a SE attack and proposed
algorithms to reconstruct the system state when the attackers
corrupt less than half of the sensors or actuators. Miroslav
Pajic et al. [12] have extended the attack-resilient state esti-
mation for noisy dynamical systems. Based on Kalman ﬁlter,
Chang et al. [13] have extended the secure estimation of
CPSs to a scenario in which the set of attacked nodes can
change over time. However, to recover the estimation, the
above work requires a certain number of uncorrupted sensors
or a sufﬁciently long time. Those approach might introduce a
non-negligible computational overhead, which is not suitable
for time-critical CPSs, e.g., real-time systems. Besides, since
all the senors do not have any protection, the attacker might
easily compromise the a large number of sensors, violating the
assumptions of the above work.

Instead of recovering the estimation from SE attacks, re-
searchers and operators also focus on attack detection [14].
However, detecting a SE attack could be challenging since
the attackers’ strategies become increasingly sophisticated.
Pasqualetti et al. [15] have identiﬁed the conditions of unde-
tectable SE attacks for CPSs. Using the conventional statistic
detection theory, e.g., Chi-square detection, may fail to dis-
cover an estimation attack if the attackers launch a stealthy
attack [16]. Yuan Chen et al. [17] have developed optimal
attack strategies, which can deviate the CPSs subject
to
detection constraints. Hence, the traditional detection theory
may not sufﬁciently address the stealthy attacks in which
the attackers can acquire the defense information. Besides,
using classical cryptography to protect CPSs will introduce
signiﬁcant overhead, degrading the control performance of
delay-sensitive CPSs [18].

The development of Digital Twin (DT) provides essential
resources and environments for detecting sophisticated attacks.
A DT could be a virtual prototype of a CPS, reﬂecting partial
or entire physical processes [19]. Based on the concept of DT,
researchers have developed numerous applications for CPSs
[20]. The most relevant application to this paper is using a
DT to achieve fault detection [21]. Similarly, we use the DT

 
 
 
 
 
 
designing security algorithms since we can use it to search
for the optimal defense strategies against intelligent attackers
[22]. One related game model that can capture the detection
issue is the Signaling Game (SG) [23]. However, instead of
using the SG, we use a Signaling Game with Evidence (SGE),
presented in [24], to protect the system from the attack. In
an SGE, the DT’s detector will provide critical evidence to
explore the stealthy attack. After integrating DT’s detector
with CPSs, we use an SGE to study the stealthy attack and
develop optimal defense strategies based on the equilibria of
the SGE. Our analytical results show that the stealthy attackers
have to sacriﬁce the impact on the physical system to avoid
detection.

We organize the rest of the paper as follows. Section
II presents the problem formulation in which we identify
the control problem, attack model, and a signaling game
framework. Section III analyzes the equilibrium of the game
framework and the stability of the CPSs. Section IV uses
the experimental results to evaluate the performance of the
proposed defense mechanism. Finally, Section V concludes
the entire paper.

II. SYSTEM MODELLING AND CHARACTERIZATION

In this section, we ﬁrst introduce the dynamic model of a
CPS. Secondly, we deﬁne a stealthy estimation attack model.
Based on a Digital Twin (DT), we design a Chi-square
detector to monitor the estimation process. Finally, we deﬁne
a Signaling Game with Evidence (SGE) to characterize the
features of the stealthy attack.

A. System Model and Control Problem of a CPS

Suppose that the physical layer of a CPS is a control system.
We assume that the control system can be linearized as a linear
discrete-time system, given by

xk+1 = Axk + Buk + wk,

yk = Cxk + vk,

(1)

(2)

where k ∈ Z+ is the discrete-time instant; xk ∈ Rnx is the
system state with an initial condition x0 ∼ N (0nx , Σx), and
Σx ∈ Rnx×nx is the covariance matrix; uk ∈ Rnu is the
control input; yk ∈ Rny is the sensor output; wk ∈ Rnx
and vk ∈ Rny are additive zero-mean Gaussian noises with
covariance matrices Σw and Σv with proper dimensions; A,
B, and C are constant matrices with proper dimensions.

Given system model (1), we design a control policy µ :
Rnx → Rnu by minimizing the following expected linear
quadratic cost function, i.e.,

JLQG = lim
N→∞

sup E

(cid:26) 1
N

N −1
(cid:88)

(cid:18)

k Qxk + uT
xT

k Ruk

(cid:19)(cid:27)

,

(3)

k=0
where Q ∈ Rnx×nx and R ∈ Rnu×nu are positive-deﬁnite
matrices.

Fig. 1. The Stealthy Estimation Attack and the Defense Mechanism based on
a Digital Twin: the attacker aims to modify the estimation results in a CPS,
while the Digital Twin protects the system by monitoring the results.

to monitor the estimation process, mitigating the inﬂuence of
the SE attack.

In this paper, we focus on a stealthy estimation attack, where
the attackers know the defense strategies and aim to tamper
the estimation results without being detected. Fig. 1 illustrates
the underlying architecture of the proposed framework. To
withstand the attack, we design a Chi-square detector, running
in a DT. The DT connects to a group of protected sensing
devices, collecting relevant evidence. We use cryptography
(e.g., digital signature or message authentication code) to
preserve the evidence from the attack. Hence, the DT can
use the evidence to monitor the estimation of the physical
systems. The cryptographic overhead will not affect physical
performance since the execution of the real plant does not
depend on the DT.

Different from the work [11]–[13], we have designed two
independent channels, i.e., one is protected by standard cryp-
tography, and the other one is the general sensing channel.
Fig. 2 illustrates the structure of the framework. The main
advantage of this structure is the cryptographical overhead will
affect the control performance of the physical system due to
the independency between these two channels.

the Digital Twin has two
Fig. 2. The Architecture of the Framework:
channels to obtain the sensing information of the plant: one is secure, and
the other is not secure. The secure channel provides less accurate data with
a heavy computational overhead. DT only uses the secure channel to run
the veriﬁcation, and the computational overhead has negligible impact on the
physical performance since these two channels are independent.

To analyze whether a stealthy attack can bypass DT’s
detector, we use game theory to ﬁnd the optimal attack and
defense strategies. Game theory has been an essential tool in

Note that the controller cannot use state xk directly, i.e., we
need to design an observer to estimate xk. Hence, minimizing
function (3) is a Linear Regulator Gaussian (LQG) problem.

According to the separation principle, we can design the
controller and state estimator separately. The optimal control
policy µ : Rnx → Rnu is given by

µk(xk) := Kkxk, with Kk := −(R + BT VkB)BT Vk, (4)

where Vk ∈ Rnx×nx is the solution to the linear discrete-time
algebraic Riccati equation

Vk+1 = Q + AT Vk(A − BKk), with V0 = Inx ,

(5)

and Inx ∈ Rnx×nx is an identity matrix.

We assume that (A, B) is stabilizable. Then, Vk will con-

verge to a constant matrix V when k goes to inﬁnity, i.e.,

lim
k→∞

Vk = V, and lim
k→∞

µk(x) = µ(x) = Kx.

In the next subsection, we will use a Kalman ﬁlter to
estimate xk such that controller (4) uses this estimated value
to control the physical system.

B. Kalman Filter Problem

To use controller (4), we need to design an estimator. Let
ˆxk ∈ Rnx be the estimation of xk and ˆek := ˆxk − xk be
the error of the estimation. Given the observation Yk−1 :=
{y0, y1, . . . , yk−1}, we aim to solve the following Kalman
ﬁltering problem, i.e.,

min
ˆxk∈Rnx×nx

E[(ˆxk − xk)T (ˆxk − xk)|Yk−1].

(6)

To solve (6), we need the following lemma, which charac-

terizes a conditioned Gaussian distribution.

Lemma 1: [25] If a ∈ Rna , b ∈ Rnb are jointly Gaussian
ba, then

with means ¯a, ¯b and covariances Σa, Σb, and Σab = ΣT
given b, distribution a is a Gaussian with

E[a|b] = ¯a + ΣabΣ−1
Cov[a|b] = Σa − ΣabΣ−1

b (b − ¯b),
b Σba.

To use Lemma 1, we deﬁne the covariance matrix of ˆek as

ˆPk := E[ˆek ˆeT

k |yk−1] = E[(ˆxk − xk)(ˆxk − xk)T |yk−1],

with ˆP0 = Σx. Using the results of Lemma 1, we compute
the optimal estimation iteratively, i.e.,

ˆxk = AK ˆxk−1 + ˆLk(yk−1 − C ˆxk−1),

(7)

where AK := (A + BK). Gain matrix ˆLk ∈ Rnx×ny and
covariance ˆPk ∈ Rnx×nx are updated using

ˆLk := AK ˆPkC T (Σv + C ˆPkC T )−1,

ˆPk+1 := Σw + (AK − ˆLkC) ˆPkAT
K.

Assuming that (A, C) is detectable, we can obtain that

ˆPk = ˆP ∗,

lim
k→∞

(8)

where ˆP ∗ ∈ Rnx×nx is a constant positive-deﬁnite matrix.

C. Stealthy Estimation Attack

CPSs face an increasing threat in recent years. Numerous
attack models for CPSs or networked control systems (NCSs)
have been introduced in [26]. Among those attacks, one major
attack is the data-integrity attack, where the attacker can
modify or forge data used in the CPSs. For example, Liu et al.
[27] have studied a false-data-injection attack that can tamper
the state estimation in electrical power grids.

Fig. 3. The Stealthy Estimation Attack: intelligent attacker aims to deviate
the state by modifying the estimation results.

To mitigate the impact of a data-integrity attack on the state
estimation, researchers have designed a Chi-square detector
to monitor the estimation process. However, Yilin Mo et
al. [16] have analyzed stealthy integrity attack, which can
pass the Chi-square detector by manipulating the perturbation
of the injected data. Therefore, the main challenge is that
the conventional fault detectors fail
the system
from a stealthy attack. One real attack that can achieve the
objective is the Advanced Persistent Threat (APT) [28], which
can compromise a cyber system by executing a zero-day
exploration to discover the vulnerabilities.

to protect

In our work, we consider an intelligent attacker who can
launch a stealthy estimation attack to tamper the estimation
results. Fig. 3 illustrates how the attacker achieves its objec-
tive. The attacker can either modify the data in the sensors
or the data in the estimator. Besides tampering the estimation
results, the attacker is also aware of the intrusion detector.
The attacker can know the defense strategy and play a stealthy
attack to remaind unknown.

In the next subsection, based on the Digital Twin (DT), we
design a cyber defender to withstand the stealthy estimation
attack and discuss the beneﬁts introduced by the DT. After
presenting the game model, we will discuss the optimal
defense strategies explicitly in Section III.

D. Digital Twin for the CPS

As mentioned above, an intelligent attacker can learn the
defense strategy and launch a stealthy estimation attack, which
can modify the estimation results without being detected by the
conventional detector, e.g., a Chi-square detector. To resolve
the issue, we aim to design an advanced detector based on
a Digital Twin (DT). After that, we use a game-theoretical
approach to develop an optimal defense strategy.

Fig. 4. The CPS with a DT: the DT uses a secure observation zk to obtain
an estimation ˜xk; given ˜xk, we use a Chi-square detector monitor estimation
result ˆxk.

Fig. 5. The DT’s Monitoring Process: we can view the DT’s monitoring
process as a message-sending process, i.e., the estimator sends a message to
the DT for veriﬁcation.

Given the system information, we design a DT with the

following dynamics

˜xk = AK ˜xk−1 + ˜Lk(zk−1 − D˜xk−1),
zk = Dxk + dk,

(9)

where ˜xk ∈ Rnx is the DT’s estimation of state xk; zk ∈ Rnz
is the DT’s observation; D ∈ Rnz×nx is a constant matrix, dk
is a Gaussian noise with a covariance matrix Σd ∈ Rnz .

Similar to problem (6), we compute ˜Lk using the following

iterations:

˜Lk = AK ˜PkDT (Σd + D ˜PkDT )−1,

˜Pk+1 = Σw + (AK − ˜LkD) ˜PkAT
F ,

where ˜P0 = Σx and ˜Pk is deﬁned by

ˆPk := E[(˜xk − xk)(˜xk − xk)T |zk−1] = E[˜ek ˜eT

k |zk−1].

where ˜ek := ˜xk − xk is the DT’s estimation error. We also
assume that (AK, D) is detectable, i.e., we have

˜Pk = ˜P ∗.

lim
k→∞

(10)

Fig. 4 illustrates the architecture of a CPS with a DT. We
summarize the main differences between Kalman ﬁlter (7) and
the DT’s estimator (9) as follows. Firstly, the Kalman ﬁlter will
use all available sensing information yk to obtain estimation
ˆxk. While the DT’s estimator just uses a minimum sensing
information zk ∈ Rnz to predict xk as long as (A, D) is
detectable, i.e., ny ≥ nz. This feature reduces the dimension
of zk, making it easier to protect zk. Secondly, we do not
require a high accuracy for zk, since we only use zk for attack
detection. Hence, in general, ˆP ∗ and ˜P ∗ satisfy the condition
that tr( ˆP ∗) ≤ tr( ˜P ∗), where tr(P ) is the trace of matrix P .

Thirdly, we do not use any cryptography to protect yk since
the overhead introduced by the encryption scheme will degrade
the performance of the physical system. However, we can use
cryptography, such as Message Authentication Code (MAC)
[29] or Digital Signature (DS) [30], to protect the integrity of
zk. The overhead caused by the cryptography will not affect

the physical system, because it does depend on zk. Besides,
we can put the DT into a supercomputer or a cloud to resolve
the overhead issue.

To sum up, zk is an observation that is less accurate but
more secure than yk. Given the distinct features of yk and zk,
we use yk to estimate xk for the physical control and use zk
for the detection in the DT.

Given DT’s estimator, we construct a Chi-square detector
to monitor estimation result ˆxk at each time k. As illustrated
in Fig. 4, we build the detector in the DT by comparing ˜xk
and ˆxk. The Chi-square detector generates a detection result
qk ∈ Q := {0, 1, 2} at time k, where qk = 0 means the result
is qualiﬁed, qk = 1 means the result is unqualiﬁed, qk = 2
means the result is detrimental. When qk = 2, the DT should
always reject the estimation and send an alarm to the operators.
To design the detector, we deﬁne φk := ˜xk − ˆxk. Since
˜xk and ˆxk are Gaussian distributions, φk is a also Gaussian
distribution with a zero-mean vector and a covariance matrix,
i.e., φ ∼ N (0nx , Σφ). Furthermore, we deﬁne that

k := (˜xk − ˆxk)T Σ−1
χ2

φ (˜xk − ˆxk).

(11)

Then, χ2
square detector as the following:

k follows a Chi-square distribution. We deﬁne a Chi-

qk = fq(mk) :=






0,
1,
2,

if χ2
if χ2
if χ2

k ≤ ρ1;
k ∈ (ρ1, ρ2];
k > ρ2;

(12)

where ρ1, ρ2 are two given thresholds, and they satisfy that
ρ2 > ρ1 > 0; fq : Rnx → Q is the detection function.

Using the above Chi-square detector, we can achieve fault
detection. However, the work [16] has shown that intelligent
attackers can constrain the ability of the Chi-square detector
by manipulating the amount of injected data. In the following
subsection, we will introduce a stealthy sensor attack that aims
to remain stealthy while modifying the estimation.

E. General Setup of Signaling Game with Evidence

Given mixed strategies σs and σr, we deﬁne players’

Due to the existence of attacks, the DT’s might not be able
to monitor the actual value estimation directly. Instead, the
DT’s can read a message provided by the estimator. According
to our attack model, the attacker can compromise the estimator.
Hence, the estimator can have two identities, i.e., a benign
estimator or a malicious estimator. The DT aims to verify
the estimator’s identity by monitoring the estimation results.
As shown in Fig. 5, we can view DT’s monitoring process
as a message-sending process, i.e., the estimator sends an
estimation result to the DT for veriﬁcation. To capture the
interactions between the estimator and DT, we will formally
deﬁne a Signaling Game with Evidence (SGE) as follows.

In an SGE, we have two players: one is the sender, and the
other one is the receiver. The sender has a private identity,
denoted by θ ∈ Θ := {θ0, θ1}, where θ0 means the sender is
benign, and θ1 means the sender is malicious. According to its
identity, the sender will choose a message m ∈ M and send it
to the receiver. After observing the message, the receiver can
choose an action a ∈ A. Action a = 1 means that the receiver
accepts the message, while a = 0 means the receiver rejects
the message. The sender and receiver have their own utility
functions Ui : Θ×M×A → R, for i ∈ {s, r}. Fig. 6 illustrates
how the data and information transmit in the proposed cyber-
physical SGE.

Fig. 6. The Architecture of the Proposed SGE for a CPS: the physical
estimator sends the estimation to the DT, which uses its secure evidence to
verify the identity of the estimator.

In this paper, given a message m ∈ M, we assume that
both players are aware of the corresponding detection results,
i.e., q = fq(m). Hence, both players’ can select the optimal
strategies based on detection result q. To this end, we let
σs(fq(m)|θ) ∈ Γs and σr(a|fq(m)) ∈ Γr be the mixed
strategies of the sender and receiver, respectively. The spaces
Γs and Γr are deﬁned by
(cid:12)
(cid:12)
(cid:12)
(cid:12)
m∈M
(cid:12)
(cid:88)
(cid:12)
(cid:12)
(cid:12)

σr(a|fq(m)) = 1, ∀a, σr(a|fq(m)) ≥ 0

σs(fq(m)|θ) = 1, ∀m, σs(fq(m)|θ) ≥ 0

Γr :=

Γs :=

(cid:88)

σs

σr

(cid:26)

(cid:27)

(cid:26)

(cid:27)

.

,

a∈A

expected utility functions as

¯Us(θ, σs, a) :=

¯Ur(θ, m, σr) :=

(cid:88)

q∈Q
(cid:88)

a∈A

σs(fq(m)|θ)Us(θ, m, a),

σr(a|fq(m))Ur(θ, m, a).

To ﬁnd the optimal mixed strategies of both players, we
identify a Perfect Bayesian Nash Equilibrium (PBNE) of the
SGE in the following deﬁnition.

Deﬁnition 1: A PBNE of a SGE is a strategy proﬁle (σ∗

s , σ∗
r )

and a posterior belief π(θ) such that

σs(fq(m)|θ) ∈ arg max

σs∈Γs

σr(a|fq(m)) ∈ arg max

σr∈Γr

(cid:88)

a∈A
(cid:88)

θ∈Θ

σr(a|fq(m)) ¯Us(θ, σs, a),

π(θ) ¯Ur(θ, m, σr),

and the receiver updates the posterior belief using the Bayes’
rule, i.e.,

π(θ) = fb(π(cid:48)(θ), fq(m))

:=

σs(fq(m)|θ(cid:48))π(cid:48)(θ)
θ(cid:48)∈Θ σs(fq(m)|θ(cid:48))π(cid:48)(θ(cid:48))

(cid:80)

.

(13)

where fb : (0, 1) × Q → (0, 1) is the belief-update function,
and π(cid:48)(θ) is a prior belief of θ.

Remark 1: Deﬁnition 1 identiﬁes the optimal mixed strate-
gies of the sender and receiver. One important thing is that
at any PBNE, the belief π(θ) should be consistent with the
optimal strategies, i.e., at the PBNE, belief π(θ) is independent
of time k. Instead, π(θ) should only depend on detection
results q ∈ Q. Besides, we implement Bays’s rule to deduce
belief-update function (13).

In a SGE, there are different types of PBNE. We present

three types of PBNE in the following deﬁnition.

Deﬁnition 2: (Types of PBNE) An SGE, deﬁned by Deﬁni-

tion 1, has three types of PBNE:

1) Pooling PBNE: The senders with different identities use
identical strategies. Hence, the receiver cannot distin-
guish the identities of the sender based on the available
evidence and message, i.e., the receiver will use the same
strategies with the different senders.

2) Separated PBNE: Different senders will use different
strategies based on their identities, and the receiver can
distinguish the senders and use different strategies for
different senders.

3) Partially-Separated PBNE: different senders will choose
different, but not completely opposite strategies, i.e.,

σs(fq(m)|θ0) (cid:54)= 1 − σs(fq(m)|θ1).

Note that formation of strategy σs(fq(m)|θ) does not mean
the sender can choose detection results directly. Instead, the
sender can only choose message m ∈ M, which leads to a
detection result q based on function fq, given by (12).

Remark 2: In the separated PBNE, the receiver can obtain
the identity of the senders by observing a ﬁnite sequence of
evidence and messages. However, in the other two PBNE, the
receiver may not be able to distinguish the senders’ identity.

Note that in real applications, the CPS will run the SGE
repeatedly, and generate a sequence of detection results Hk :=
{q0, q1, . . . , qk}. At time k, we deﬁne the posterior belief as

πk(θ) := Pr(θ|Hk−1).

Whenever there is a new detection result qk, we can update
the belief using πk+1(θ) = fb(πk(θ), qk), where function fb
is deﬁned by (13). Belief πk+1(θ) will become a prior belief
at time k + 1.

To this end, we will use the SGE framework to capture
the interactions between the physical layer and the DT. We
will ﬁnd the optimal defense strategy of the DT by ﬁnding
the PBNE. In the next section, we deﬁne the utility functions
explicitly and ﬁnd the PBNE of the proposed SGE. Given the
PBNE, we can identify the optimal defense strategies.

III. EQUILIBRIUM RESULTS OF THE CYBER SGE

In this section, we aim to ﬁnd the optimal defense strategy
against a stealthy sensor attack. To this end, we ﬁrst deﬁne
the utility functions, which capture the proﬁt earned by the
players. Secondly, we identify the best response of the players
when they observe or anticipate the other player’s strategy.
Finally, we present a PBNE under the players’ best response
and obtain an optimal defense strategy for the DT. We analyze
the stability of the system under the stealthy attack.

A. SGE Setup for the CPSs

In this work, we use an SGE to capture the interactions
between the physical estimator and the DT. In our scenario,
the message set is just the estimation set, i.e., M := Rnx .
The DT monitors the estimation mk and chooses an action
a ∈ A := {0, 1}. Action a = 1 means the estimation passes
the veriﬁcation, while action a = 0 means the veriﬁcation
fails, and the DT will send an alarm to the operators.

In the next step, we deﬁne the utility functions of both
players, explicitly. Firstly, we deﬁne sender’s utility functions
Us(θ, m, a). Since the sender has two identiﬁes, we need to
deﬁne two types of utility functions for the sender. The utility
function with θ = 0 is deﬁned by

Us(θ0, mk, ak) := −E[(mk − xk)T (mk − xk)],

(14)

In (14), we can see that Us(θ0, mk, ak) is independent of
action ak, and maximizing Us(θ0, mk, ak) is equivalent to the
estimation problem (6). Hence, given (14), the benign sender
always sends the true estimation result ˆxk, deﬁned by (7),
regardless of action ak.

For the malicious estimator, we deﬁne its utility function as
Us(θ1, mk, ak) := E[(mk − xk)T (mk − xk)] · 1{ak=1},(15)
where 1{s} = 1 if statement s is true. In (15), we see that
the motivation of the attacker is to deviate the system state as
much as possible while remaining undiscovered. However, the
attacker’s utility will be zero if the DT detects the attack.

Secondly, we deﬁne the DT’s utility function. Note that the
DT’s utility function should depend on the identity of the
sender. When the estimator is benign, i.e., θ = 0, the DT

should choose ak = 1 to accept the estimation. When the
estimator is malicious, i.e., (θ = 1), the DT should choose
ak = 0 to reject the estimation and send an alarm to the
operators. Given the motivations, we deﬁne Ur(θ, ˆx, a)
Ur(θ0, mk, ak) := −(˜xk − mk)T ˜Q0(˜xk − mk) · 1{ak=0},
Ur(θ1, mk, ak) := −(˜xk − mk)T ˜Q1(˜xk − mk) · 1{ak=1}.
where ˜Q0, ˜Q1 ∈ Rnx×nx are positive-deﬁnite matrices. The
weighting matrices will affect the receiver’s defense strategy.
A large value of tr( ˜Q1) will lead to a conservative strategy,
while a large value of tr( ˜Q0) will lead a radical one. Readers
can receive more details in Proposition 1.

In the next subsection, we analyze the behaviors of the
players and obtain the best-response strategies. Note that
function Ur(θ, mk, ak) is deterministic. The reason is that the
DT can observe ˆxk and ˜xk at time k, explicitly. However, the
physical estimator cannot observe xk at time k.

B. Best Response of the Players and a PBNE of the SGE

We ﬁrst analyze the best response of the DT. Given belief
πk(θ), message mk, and detection result qk, we present the
following theorem to identify DT’s best response.

Proposition 1: (DT’s Best Response) Given qk = fq(mk),

the DT will choose ak according to the following policy,
1,
0,
0,

if qk (cid:54)= 2, πk(θ0) ≥ β;
if qk (cid:54)= 2, πk(θ0) < β;
if qk = 2;
r (ak = 1|qk),

σ∗
r (ak = 0|qk) = 1 − σ∗

σ∗
r (ak = 1|qk) =






where β is deﬁned by

β :=

(˜xk − mk)T ˜Q1(˜xk − mk)
(˜xk − mk)T ( ˜Q0 + ˜Q1)(˜xk − mk)

.

Proof: Note that
E[Ur(θ, mk, ak = 1)|qk] ≥ E[Ur(θ, mk, ak = 0)|qk]

⇔ ak = 1 if πk(θ0) ≥ β,

(16)

(17)

(18)

where β is deﬁned by (18). This completes the proof.

Remark 3: Given Proposition 1, we note that the DT uses
a pure strategy since it can make its decision after observing
detection result qk and message mk.

In the next step, we consider the best response of the
estimator. If the estimator is benign, i.e., θ = θ0, the optimal
estimation should be (7). Therefore, the optimal utility of the
benign estimator is given by

Us(θ0, ˆxk, ak) = E[(ˆxk − xk)T (ˆxk − xk)] = tr( ˆPk),
where tr(P ) is the trace of matrix P . The following theorem
shows the optimal mixed strategy of the benign estimator.

Proposition 2: (Best Response of the Benign Estimator)
Given the DT’s best response (16), the optimal mixed strategy
of the benign estimator, i.e., θ = θ0, is given by

σ∗
s (fq(mk) = 0|θ0) = Fχ(ρ1, nx),
σ∗
s (fq(mk) = 1|θ0) = Fχ(ρ2, nx) − Fχ(ρ1, nx),
σ∗
s (fq(mk) = 2|θ0) = 1 − Fχ(ρ2, nx),

(19)

(20)

(21)

where ˆxk is deﬁned by (7), Fχ(ρ, n) : R+ → [0, 1] is the
Cumulative Distribution Function (CDF) of the Chi-square
distribution with n ∈ Z+ degrees.

Proof: Note that the benign estimator will choose mk =
ˆxk, deﬁned by (7). According to deﬁnition (11), we know that
(˜xk − ˆxk) follows a Chi-square distribution with nx degrees.
Hence, we have

Pr(χ2
Pr(χ2
Pr(χ2

k ≤ ρ1) = Fχ(ρ1, nx),
k > ρ2]) = 1 − Fχ(ρ2, nx),
k ∈ (ρ1, ρ2]) = Fχ(ρ2, nx) − Fχ(ρ1, nx).

Combining the above equations with Chi-square detector (12)
yields mixed strategies (19)-(21).

Remark 4: Note that the benign estimator always choose
the optimal estimation 7. However, from DT’s perspective in
this game, the real mixed strategies of the benign estimator
are (19)-(21) because of uncertainty introduced by the noises.
From the perspective of the malicious estimator, it needs
to select σs(fq(mk)|θ1) such that πk(θ0) ≥ β. Given the
attackers’ incentive, we obtain the following theorem.

Proposition 3: (Best Response of the Malicious Estimator)

σ∗
s (fq(ξk,1) = 0|θ1) = Fχ(ρ1, nx),
σ∗
s (fq(ξk,2) = 1|θ1) = 1 − Fχ(ρ1, nx),

(22)

(23)

where ξk,1, ξk,2 are the solutions to the following problems:

Us(θ1, m, ak = 1),

ξk,1 ∈ arg max
m∈Mρ1 (˜xk)
ξk,2 ∈ arg max
m∈Mρ2 (˜xk)
with spaces Mρ1(˜xk) and Mρ2 (˜xk) deﬁned by

Us(θ1, m, ak = 1),

(24)

(25)

Mρ1 (˜xk) :=

Mρ2 (˜xk) :=

(cid:26)

(cid:26)

m ∈ Rnx

m ∈ Rnx

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:107)˜xk − m(cid:107)2

Σ−1
φ

(cid:107)˜xk − m(cid:107)2

Σ−1
φ

(cid:27)

≤ ρ1

,

(cid:27)

∈ (ρ1, ρ2]

.

Proof: Firstly, the attacker has no incentive to choose
mk /∈ Mρ1(˜xk) ∪ Mρ2 (˜xk) because its utility will be zero.
Secondly,
the attacker aims to choose the mixed strategy
σ∗
s (qk = 1|θ1) as large as possible since it can make a higher
damage to the system. Then, we show that the optimal mixed
strategy of the attacker is given by (22) and (23). To do this,
based on (13), we consider the following belief update:

πk+1(θ0)

=

=

σ∗
s (qk (cid:54)= 0|θ0)πk(θ0)
σ∗
s (qk (cid:54)= 0|θ0)πk(θ0) + σs(qk (cid:54)= 0|θ1)(1 − πk(θ0))

σ∗
s (qk (cid:54)= 0|θ0)πk(θ0)
∆σs(qk (cid:54)= 0)πk(θ0) + σs(qk (cid:54)= 1|θ1)

,

(26)

where ∆σs(qk (cid:54)= 0) is deﬁned by

∆σs(qk (cid:54)= 0) := σ∗

s (qk (cid:54)= 0|θ0) − σs(qk (cid:54)= 0|θ1).

Rearranging (26) yields that

πk+1(θ0)
πk(θ0)

=

σ∗
s (qk (cid:54)= 0|θ0)πk(θ0)
∆σs(qk (cid:54)= 0)πk(θ0) + σs(qk (cid:54)= 0|θ1)

.

Given that πk(θ0) ∈ (0, 1], we have
πk+1(θ0)
πk(θ0) > 1,
πk+1(θ0)
πk(θ0) = 1,
πk+1(θ0)
πk(θ0) < 1,





if ∆σs(qk (cid:54)= 0) > 0;

if ∆σs(qk (cid:54)= 0) = 0;

if ∆σs(qk (cid:54)= 0) < 0.

When πk(θ0) ∈ [β, 1), the attacker has to choose ∆σs(qk (cid:54)=
0) = 0 to maintain the belief at a constant. Otherwise, the
belief will decrease continuously. When the belief πk(θ0) stays
lower than β, the DT will send an alert to the operators. Hence,
the optimal mixed strategies of the malicious estimator are
given by (22) and (23).

Given the results of Propositions 1, 2, and 3, we present the

following theorem to characterize a unique pooling PBNE.

Theorem 1: (The PBNE of the Proposed SGE) The proposed
cyber SGE has a unique pooling PBNE. At the PBNE, the
optimal mixed strategies of the benign and malicious sender
are presented by (19)-(21) and (22)-(23). The DT has a pure
strategy deﬁned by (16). At the PBNE, belief π∗
k(θ0) ∈ [β, 1)
is a ﬁxed point of function fb, i.e.,

k(θ0) = fb(π∗
π∗

k(θ0), qk), for qk ∈ Q.

Proof: We ﬁrst show the existence of the pooling PBNE.
Suppose that both estimators use strategies (19)-(21), (22)-
(23), respectively, and the DT uses (16). Then, no player
has incentive to move since these are already the optimal
strategies. Besides, for any θ ∈ Θ, qk ∈ Q, we note that

k(θ),

k(θ), qk) = π∗

πk+1(θ) = fb(π∗
where fb is deﬁned by (13). Hence, π∗
k(θ) is a ﬁxed point
of function fb, and the belief remain at π∗
k(θ), which means
the belief stays consistently with the optimal strategies of
the sender and receiver. Hence, the proposed strategies pair
(σ∗

s , σ∗
Secondly, we show that pooling PBNE is unique. We note
that the DT and benign estimator have no incentive to move
since they already choose their best strategies. In Proposi-
tion 3, we already show that the attacker cannot change its
mixed strategies. Otherwise, the belief cannot remain constant.
Hence, pooling PBNE is unique.

r ) is a PBNE.

Remark 5: Theorem 1 shows that the SGE admits a unique
pooling PBNE, which means that an intelligent attacker can
use its stealthy strategies to avoid being detected by the DT.
In the next subsection, we will analyze the stability of the
system under the stealthy attack. Besides, we will also evaluate
the loss caused by the attack.

C. Estimated Loss Under the Stealthy Attack

In the previous subsection, we have shown the PBNE in
which the attacker can use a stealthy strategy to pass the
veriﬁcation of the DT. In this subsection, we will quantify
the loss under the attack. Before presenting the results, we
need the following lemma.

Lemma 2: Given ρi and ξk,i, for i ∈ {1, 2}, we have the

following relationship:

ρiλmax(Σφ) ≥ (˜xk − ξk,i)T (˜xk − ξk,i), for i = 1, 2,

where λmax(Σ) is the greatest eigenvalue of matrix Σ.

Proof: Firstly, we note that Us is strictly convex in
mk. The solution to problem (24) and (25) must stay at the
boundary. Hence, we have

ρi = (˜xk − ξk,i)T Σ−1

φ (˜xk − ξk,i)

≥

(˜xk − ξk,i)T (˜xk − ξk,i)
λmax(Σφ)

(27)

Rearranging (27) yields that

ρiλmax(Σφ) ≥ (˜xk − ξk,i)T (˜xk − ξk,i).

This completes the proof.

Considering different estimators, we deﬁne two physical

cost functions J0 and J1, i.e.,

J0 := lim
N→∞

J1 := lim
N→∞

E

(cid:26) 1
N

E

(cid:26) 1
N

k=0
N −1
(cid:88)

k=0

N −1
(cid:88)

(cid:20)
k Qxk + µT (mk)Rµ(mk)
xT

(cid:20)
k Qxk + µT (mk)Rµ(mk)
xT

(cid:27)

θ0

(cid:27)

θ1

,

.

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

We deﬁne a loss function ∆J := J1 − J0 to quantify the loss
caused by the stealthy sensor attack. Given pooling PBNE
deﬁned by Theorem 1, we provide an upper-bound of ∆J in
the following theorem.

Theorem 2: (Bounded Loss) The proposed framework can
guarantee stability of the CPSs, and the value of function ∆J
is bounded by a constant, i.e.,

∆J = J1 − J0

≤ α1tr( ˜P ∗) − α0tr( ˆP ∗) + α1ρ1λmax(Σφ)Fχ(ρ1, nx)
+ α1ρ2λmax(Σφ)(1 − Fχ(ρ1, nx)),

(28)

where α0 and α1 are deﬁned by

α0 :=

α1 :=

λmin(RK)(λmin(G) − λmin(RK))
λmin(G)
λmax(RK)(λmax(RK) + 2λmax(G))
λmax(G)

,

,

and RK := K T RK, G := Q + RK; λmax(W ) and λmin(W )
are the greatest and smallest eigenvalues of matrix W .

Proof: Firstly, we note that

(cid:21)

Q + (cid:107)K ˆxk(cid:107)2
R

(cid:20)

E

(cid:107)xk(cid:107)2
(cid:20)
= E
(cid:107)xk(cid:107)2

G + 2xT

k RK ˆek + (cid:107)ˆek(cid:107)2

RK

(cid:21)

≥ E

(cid:20)(cid:13)
(cid:112)λmin(G)xk +
(cid:13)
(cid:13)
(cid:13)

λmin(RK)
(cid:112)λmin(G)

ˆek

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

+

λmin(RK)(λmin(G) − λmin(RK))
λmin(G)
Using the above inequality, we observe that

(cid:107)ˆek(cid:107)2

(cid:21)
≥ α0tr( ˆPk),

where ˆP ∗ is deﬁned by (8). Secondly, we also note that

(cid:21)
(cid:20)
k Qxk + µT (ξk,i)Rµ(ξk,i)
xT

E

(cid:20)
= E
(cid:107)xk(cid:107)2
(cid:20)
≤ E
(cid:107)xk(cid:107)2

(cid:18)

Q + (cid:107)xk + ˜ek + ξk,i − ˜xk(cid:107)2

RK

G +

2xT

k RK ˜ek + 2xT

k RK(ξk,i − ˜xk)

(cid:21)

(cid:19)

+ 2˜eT

k RK(ξk,i − ˜xk) + (cid:107)ξk,i − ˜xk(cid:107)2
(cid:20)
≤ E
3(cid:107)xk(cid:107)2

λ2
max(RK)
λmax(G)

G +

(cid:18)

(cid:21)

+ (cid:107)˜ek(cid:107)2

RK

RK

(cid:107)˜ek(cid:107)2 + (cid:107)ξk,i − ˜xk(cid:107)2

(cid:19)

(cid:21)

+ 2λmax(RK)(cid:107)˜ek(cid:107)2 + 2λmax(Rk)(cid:107)ξk,i − ˜xk(cid:107)2

≤ 3(cid:107)xk(cid:107)2

G + α1tr( ˜Pk) + α1ρiλmax(Σφ),

(30)

We complete the squares to deduce the second inequality of
(30) Similarly, we have

1
N

N −1
(cid:88)

(cid:26)

k=0

J1 = lim
N→∞
(cid:18)

+

1 − Fχ(ρ1, nx)

(cid:20)
Fχ(ρ1, nx)E
(cid:107)xk(cid:107)2

Q + (cid:107)ξk,1(cid:107)2

RK

(cid:21)

(cid:19)

(cid:20)
(cid:107)xk(cid:107)2

E

Q + (cid:107)ξk,1(cid:107)2

RK

(cid:21)(cid:27)

≤ lim
N→∞

3
N

N −1
(cid:88)

(cid:107)xk(cid:107)2
G

+α1ρ1λmax(Σφ)Fχ(ρ1, nx)

k=0
(cid:123)(cid:122)
=0

(cid:124)

(cid:125)
+ α1ρ2λmax(Σφ)(1 − Fχ(ρ1, nx)) + α1tr( ˜P ∗),

(31)

where ˜P ∗ is deﬁned by (10). Combining inequalities (29) and
(31) yields inequality (28). Hence, the system is stable, and
the impact of the attack is bounded by a constant.

Remark 6: Theorem 2 shows that the difference between J0
and J1 is bounded, i.e., the stealthy estimation attack cannot
deviate the system to an arbitrary point even if the attacker
has an inﬁnite amount of time.

In the next subsection, we will use an application to evaluate

the performance of the proposed defense strategies.

IV. SIMULATION RESULTS

In this section, we use a two-link Robotic Manipulator
(RM) to investigate the impact of the estimation attacks. In
the experiments, we use different case studies to analyze the
performance of the proposed defense framework.

J0 = lim
N→∞

≥ lim
N→∞

1
N

1
N

N −1
(cid:88)

k=0
N −1
(cid:88)

k=0

(cid:20)
(cid:107)xk(cid:107)2

E

Q + (cid:107)K ˆxk(cid:107)2
R

(cid:21)

α0tr( ˆPk) = α0tr( ˆP ∗),

(29)

Fig. 7. The Dynamic Model of a Two-Link Robotic Manipulator (RM): the
RM has two links and moves in a two-dimensional space.

Fig. 8. No-Attack Case: (a) the system trajectory,
physical estimation and DT’s estimation; (b) the
Chi-square value; (c) DT’s belief π(θ0).

Fig. 9. Normal-Attack Case: (a) the system tra-
jectory, physical estimation and DT’s estimation;
(b) the Chi-square value; (c) DT’s belief π(θ0).

Fig. 10. Stealthy-Attack Case: (a) the system tra-
jectory, physical estimation and DT’s estimation;
(b) the Chi-square value; (c) DT’s belief π(θ0).

A. Experimental Setup

Fig. 7 illustrates the physical structure of the two-link RM.
Variables g1 and g2 are the angular positions of Links 1 and
2. We summarize the parameters of the RM in Table II.

TABLE I
PARAMETERS OF THE ROBOTIC MANIPULATOR

Parameter
l1
l2
r1
r2
η1
η2
I1
I2

Description
Length of Link 1
Length of Link 2
Half Length of Link 1
Half Length of Link 2
Mass of Link 1
Mass of Link 2
Inertia of Link 1 on z-axis
Inertia of Link 2 on z-axis
Let g = [g1, g2]T be the angular vector and τ = [τ1, τ2]T be
the torque input. According to the Euler-Lagrange Equation,
we obtain the dynamics of the two-link RM as

Value
0.6 m
0.4 m
0.3 m
0.2 m
6.0 kg
4.0 kg
1 kg·m2
1 kg·m2

M (g)¨g + S(g, ˙g) ˙g = τ,

(32)

where matrices M (g) and S(g, ˙g) are deﬁned by

M (g) :=

S(g, ˙g) :=

(cid:20) a + b cos(g2) δ + b cos(g2)

(cid:21)

δ + cos(g2)

δ

,

(cid:20) −b sin(g2) ˙g2 −b sin(g2)( ˙g1 + ˙g2)

(cid:21)

,

b sin(g2) ˙g1
a := I1 + I2 + η1r2
b := η2l1r2,

0
1 + r2
1 + η2(l2
2),
δ := I2 + η2r2
2.

To control the two-link RM, we let τ be τ := M (g)ag +
S(g, ˙g) ˙g, where aq ∈ R2 is the acceleration that we need
to design. Note that M (g) is positive-deﬁnite, i.e., M (g) is
invertible. Hence, substituting τ into (32) yields that

M (g)¨g = M (g)ag ⇒ ¨g = ag.

Let p ∈ R2 be the position of RM’s end-effector. We have

¨p = H(g)¨g + ˙H(g) ˙g = H(g)ag + ˙H(g) ˙g,

(33)

where H(g) is the Jacobian matrix. Then, we substitute
ag := H −1(g)(u − ˙H(g)) into (33), arriving at ¨p = u. Let
x = [pT , ˙pT ]T be the continuous-time state. Then, we obtain
a continuous-time linear system ˙x = Acx + Bcu. Given a
sampling time ∆T > 0, we discretize the continuous-time
system to obtain system model (1). We let yk and zk be

yk = xk + vk,

zk = p(k∆T ) + dk

(34)

We assume that the DT uses security-protected cameras to
identify the position of the end-effector.

In the experiments, we let the RM to draw a half circle on
a two-dimensional space. The critical parameters are given by

β = 0.65, nx = 4, ρ1 = 9.49, ρ2 = 18.47,
Fχ(ρ1, nx) = 0.95, Fχ(ρ2, nx) = 0.999.

We have three case studies: a no-attack case, a normal-attack
case, and a stealthy-attack case. In the normal-attack case,
the attacker is not aware of the defense strategies and deviate
the system from the trajectory, directly. In the last case, the
attacker aims to tamper the estimation without being detected.
Figures 8, 9, and 10 illustrate the simulation results of the
case studies. In Fig. 8 (a), we can see that the RM can track
the trajectory smoothly when there is no attack. However, we
note that DT’s estimation is worse than the physical estimation,
which coincides with our expectation. Figures 8 (b) and (c)
show the value of the Chi-square and the belief of the DT. In
the no-attack case, the Chi-square detector will remain silent
with a low false alarm rate, and the belief stays at a high
level.In Fig. 9 (a), the attackers deviate the system without
considering the detection. Even though DT’s estimation is
not accurate, the attacker cannot tamper that. Therefore, the
detector will rapidly locate the attack and send alarms to the
operators. The belief of θ0 will remain at the bottom line. In
Fig. 10, differently, the stealthy attackers know the defense
strategies and try to maintain the Chi-square value below
threshold ρ1. However, the behavior mitigates the impact of
the attack, which also coincides with the result of Theorem 2.

Figure 11 illustrates the Mean Square Errors (MSE) of
different cases. Figure 11 (a) presents that the MSE of the
physical estimator is much smaller than the DT’s estimator,
i.e., the physical estimator can provide more accurate sensing
information. However, in Figure 11 (b), we can see that the
attacker can deviate the physical estimation to a signiﬁcant
MSE. Besides, under the DT’s supervision, the stealthy at-
tacker fails to generate a large MSE. The above results show
that the proposed defense mechanism succeeds in mitigating
the stealthy attacker’s impact.

Fig. 11. The Comparison of the Mean Square Error (MSE): (a) the comparison
between the MSE of physical estimation and DT’s estimation; (b) the MSE
of different case studies.

V. CONCLUSIONS

In this paper, we have considered a stealthy estimation
attack, where an attack can modify the estimation results
to deviate the system without being detected. To mitigate
the impact of the attack on physical performance, we have
developed a Chi-square detector, running in a Digital Twin
(DT). The Chi-square detector can collect DT’s observations
and the physical estimation to verify the identity of the
estimator. We have used a Signaling Game with Evidence
(SGE) to study the optimal attack and defense strategies. Our
analytical results have shown that the proposed framework can
constrain the attackers’ ability and guarantee the stability.

REFERENCES

[1] K.-D. Kim and P. R. Kumar, “Cyber–physical systems: A perspective
the IEEE, vol. 100, no. Special

the centennial,” Proceedings of
at
Centennial Issue, pp. 1287–1308, 2012.

[2] L. Wang, M. T¨orngren, and M. Onori, “Current status and advancement
of cyber-physical systems in manufacturing,” Journal of Manufacturing
Systems, vol. 37, pp. 517–527, 2015.

[3] G. Xiong, F. Zhu, X. Liu, X. Dong, W. Huang, S. Chen, and K. Zhao,
“Cyber-physical-social system in intelligent transportation,” IEEE/CAA
Journal of Automatica Sinica, vol. 2, no. 3, pp. 320–333, 2015.

[4] Y. Mo, T. H.-J. Kim, K. Brancik, D. Dickinson, H. Lee, A. Perrig, and
B. Sinopoli, “Cyber–physical security of a smart grid infrastructure,”
Proceedings of the IEEE, vol. 100, no. 1, pp. 195–209, 2011.

[5] R. Langner, “Stuxnet: Dissecting a cyberwarfare weapon,” IEEE Security

& Privacy, vol. 9, no. 3, pp. 49–51, 2011.

[6] J. Slay and M. Miller, “Lessons learned from the maroochy water
breach,” in International Conference on Critical Infrastructure Protec-
tion. Springer, 2007, pp. 73–82.

[7] D. P. Shepard, J. A. Bhatti, and T. E. Humphreys, “Drone hack: Spooﬁng
attack demonstration on a civilian unmanned aerial vehicle,” 2012.
[8] R. M. Lee, M. J. Assante, and T. Conway, “German steel mill cyber

attack,” Industrial Control Systems, vol. 30, p. 62, 2014.

[9] Y. Mo and B. Sinopoli, “Integrity attacks on cyber-physical systems,”
in Proceedings of the 1st international conference on High Conﬁdence
Networked Systems. ACM, 2012, pp. 47–54.

[10] F. Pasqualetti, F. Dorﬂer, and F. Bullo, “Control-theoretic methods for
cyberphysical security: Geometric principles for optimal cross-layer
resilient control systems,” IEEE Control Systems Magazine, vol. 35,
no. 1, pp. 110–127, 2015.

[11] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and control for
cyber-physical systems under adversarial attacks,” IEEE Transactions on
Automatic control, vol. 59, no. 6, pp. 1454–1467, 2014.

[12] M. Pajic, I. Lee, and G. J. Pappas, “Attack-resilient state estimation for
noisy dynamical systems,” IEEE Transactions on Control of Network
Systems, vol. 4, no. 1, pp. 82–92, 2016.

[13] Y. H. Chang, Q. Hu, and C. J. Tomlin, “Secure estimation based kalman
ﬁlter for cyber–physical systems against sensor attacks,” Automatica,
vol. 95, pp. 399–412, 2018.

[14] D. Ding, Q.-L. Han, Y. Xiang, X. Ge, and X.-M. Zhang, “A survey
on security control and attack detection for industrial cyber-physical
systems,” Neurocomputing, vol. 275, pp. 1674–1683, 2018.

[15] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Attack detection and identiﬁca-
tion in cyber-physical systems,” IEEE transactions on automatic control,
vol. 58, no. 11, pp. 2715–2729, 2013.

[16] Y. Mo and B. Sinopoli, “On the performance degradation of cyber-
physical systems under stealthy integrity attacks,” IEEE Transactions
on Automatic Control, vol. 61, no. 9, pp. 2618–2624, 2015.

[17] Y. Chen, S. Kar, and J. M. Moura, “Optimal attack strategies subject to
detection constraints against cyber-physical systems,” IEEE Transactions
on Control of Network Systems, vol. 5, no. 3, pp. 1157–1168, 2017.

[18] Z. Xu and Q. Zhu, “Cross-layer secure and resilient control of delay-
sensitive networked robot operating systems,” in 2018 IEEE Conference
on Control Technology and Applications (CCTA).
IEEE, 2018, pp.
1712–1717.

[19] W. Luo, T. Hu, C. Zhang, and Y. Wei, “Digital twin for cnc machine
tool: modeling and using strategy,” Journal of Ambient Intelligence and
Humanized Computing, vol. 10, no. 3, pp. 1129–1140, 2019.

[20] F. Tao, J. Cheng, Q. Qi, M. Zhang, H. Zhang, and F. Sui, “Digital twin-
driven product design, manufacturing and service with big data,” The
International Journal of Advanced Manufacturing Technology, vol. 94,
no. 9-12, pp. 3563–3576, 2018.

[21] B. Bielefeldt, J. Hochhalter, and D. Hartl, “Computationally efﬁcient
analysis of sma sensory particles embedded in complex aerostructures
using a substructure approach,” in ASME 2015 Conference on Smart
Materials, Adaptive Structures and Intelligent Systems.
American
Society of Mechanical Engineers Digital Collection, 2016.

[22] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bacs¸ar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Computing Surveys
(CSUR), vol. 45, no. 3, p. 25, 2013.

[23] S. Shen, Y. Li, H. Xu, and Q. Cao, “Signaling game based strategy
of intrusion detection in wireless sensor networks,” Computers &
Mathematics with Applications, vol. 62, no. 6, pp. 2404–2416, 2011.

[24] J. Pawlick, E. Colbert, and Q. Zhu, “Modeling and analysis of leaky
deception using signaling games with evidence,” IEEE Transactions on
Information Forensics and Security, vol. 14, no. 7, pp. 1871–1886, 2018.
[25] A. Papoulis and S. U. Pillai, Probability, random variables, and stochas-

tic processes. Tata McGraw-Hill Education, 2002.

[26] A. Teixeira, D. P´erez, H. Sandberg, and K. H. Johansson, “Attack models
and scenarios for networked control systems,” in Proceedings of the
1st international conference on High Conﬁdence Networked Systems.
ACM, 2012, pp. 55–64.

[27] Y. Liu, P. Ning, and M. K. Reiter, “False data injection attacks against
state estimation in electric power grids,” ACM Transactions on Informa-
tion and System Security (TISSEC), vol. 14, no. 1, p. 13, 2011.
[28] C. Tankard, “Advanced persistent threats and how to monitor and deter

them,” Network security, vol. 2011, no. 8, pp. 16–19, 2011.

[29] M. Bellare, J. Kilian, and P. Rogaway, “The security of the cipher block
chaining message authentication code,” Journal of Computer and System
Sciences, vol. 61, no. 3, pp. 362–399, 2000.

[30] R. C. Merkle, “A certiﬁed digital signature,” in Conference on the Theory

and Application of Cryptology. Springer, 1989, pp. 218–238.

