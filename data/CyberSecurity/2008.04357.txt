1
2
0
2

r
a

M
3
2

]
I
S
.
s
c
[

2
v
7
5
3
4
0
.
8
0
0
2
:
v
i
X
r
a

Directional Laplacian Centrality for Cyber Situational Awareness

SINAN G. AKSOY, EMILIE PURVINE, and STEPHEN J. YOUNG, Pacific Northwest National Laboratory

Cyber operations is drowning in diverse, high-volume, multi-source data. In order to get a full picture of current operations and
identify malicious events and actors analysts must see through data generated by a mix of human activity and benign automated
processes. Although many monitoring and alert systems exist, they typically use signature-based detection methods. We introduce
a general method rooted in spectral graph theory to discover patterns and anomalies without a priori knowledge of signatures. We
derive and propose a new graph-theoretic centrality measure based on the derivative of the graph Laplacian matrix in the direction
of a vertex. To build intuition about our measure we show how it identifies the most central vertices in standard network data
sets and compare to other graph centrality measures. Finally, we focus our attention on studying its effectiveness in identifying
important IP addresses in network flow data. Using both real and synthetic network flow data, we conduct several experiments
to test our measure’s sensitivity to two types of injected attack profiles, and show that vertices participating in injected attack
profiles exhibit noticeable changes in our centrality measures, even when the injected anomalies are relatively small, and in the
presence of simulated network dynamics.

CCS Concepts: • Security and privacy → Intrusion/anomaly detection and malware mitigation; • Mathematics of com-
puting → Spectra of graphs.

ACM Reference Format:
Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young. 2021. Directional Laplacian Centrality for Cyber Situational Awareness. 1,
1 (March 2021), 25 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

INTRODUCTION

1
Cyber situational awareness comprises many tasks from understanding the threat landscape and network vulnerabili-
ties to real-time network monitoring [27]. Endsley describes general situational awareness of dynamic systems in
terms of three levels of awareness: perception, comprehension, and projection (or prediction) [22]. In order to achieve
any of perception, comprehension or prediction analysts must navigate a variety of data sources and a deluge of data
within each source in order to get an understanding of current operational posture. Fusing information derived from
these data sources in a way that is interpretable to a human analyst provides a holistic situational awareness. In this
paper we focus on a specific aspect of perception: network anomaly attribution.

One of the difficult problems of perception in cyber systems is the ability to see through real-time network traffic
data produced by benign automated processes and normal human activity to pick out abnormal, potentially malicious,
events and actors. Network traffic data is often messy and massive, requiring assistance from algorithms or analytics
in order to provide the human analyst with tips and cues for further investigation. Many of the existing monitoring
and alert systems use signature-based detection techniques, and are highly tailored to specific data types. In order to
detect zero-day attacks and other previously unseen tactics, techniques, and procedures a signature-agnostic anomaly
detection strategy must be utilized. Broadly speaking, two driving challenges are: (1) identifying the presence of
anomalous or adversarial behavior within the normal background variation of network data; and (2) identifying which
actors or agents within a system are participating in the anomalous behavior. In this regard, a mathematically grounded
approach is helpful to explore data and discover patterns and anomalies without prior knowledge of behaviors of
interest. While there are approaches that attempt to simultaneously address both challenges [39, 41], in this work
we focus on developing a framework for addressing anomaly attribution using a method based on the spectrum of
the network’s graph structure. In addition to these two driving challenges there is also the question of determining
maliciousness of an anomaly. The work we propose here is not meant to answer this question but rather to identify

Authors’ address: Sinan G. Aksoy, sinan.aksoy@pnnl.gov; Emilie Purvine, emilie.purvine@pnnl.gov; Stephen J. Young, stephen.young@pnnl.
gov Pacific Northwest National Laboratory.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to
post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2021 Association for Computing Machinery.
XXXX-XXXX/2021/3-ART $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

, Vol. 1, No. 1, Article . Publication date: March 2021.

 
 
 
 
 
 
2

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

Fig. 1. Example spectral timeline with scan-like anomaly around minute 30.

the actors or agents participating in anomalous behavior. Subsequent packet inspection and other investigation
activities would be necessary to determine the maliciousness of the anomaly.

As a proxy for network structure, and to provide grounding for this work in commonly available network data, we
will focus on network flow, a summary of computer to computer communications across the network. The method
we propose is applicable to any data with records of the form (source, destination, time, metadata), not just within the
cyber domain, although interpretation of the method’s output will vary by data type. Our approach uses a graph
to model a set of network flow records, typically from a small time window. In a spectral approach the structural
properties of network communication, as reflected in a graph derived from flow, are analyzed using eigenvalues of
associated matrices; these eigenvalues are known as the graph spectrum. The temporal sequence of flow data is then
analyzed using a sequence of small time windows, each on the order of a few minutes. The spectrum of each small
time window is computed separately providing a numerical graph spectrum vector for each window. When stitched
together over time this creates a timeline or heartbeat of the network flow data that can be inspected by an analyst to
look for patterns and deviations from those patterns. See Figure 1 for an example visualization of synthetic network
flow with a scan-like anomaly around minute 30. While this tool has shown promise in helping to identify “low and
slow” scans (that is, scans that are not high volume all at once, but rather distributed across a period of time) as well
as frequent recurrent behavior in operational data, the process requires a human in the loop to inspect the timeline
and identify the actor responsible for the spectral anomaly, which can be error-prone.

This paper proposes a tool that we call the Directional Laplacian Centrality to identify “important” Internet Protocol
(IP) addresses within each time window and focus analyst attention from the broad temporal awareness that the
spectrum itself may provide to more specific attribution of anomalies. The underlying philosophy is that an IP is
important if it has a significant (measurable) contribution to the spectrum of the associated graph. Anomalies can
then be characterized as times in which a previously unimportant IP becomes significantly more important. After
defining the Directional Laplacian Centrality we will test the method within real and synthetic data, analyzing how
the importance of IP addresses change in response to planted attack profiles.

We organize our work as follows. In Section 2, we provide the necessary preliminaries to introduce network flow
data and spectral graph theory, justify the advantages of taking a spectral approach, and provide a literature review of
other relevant importance measures. In Section 3, we derive and define our proposed importance measure, Directional
Laplacian Centrality. In Section 4, we provide some intuition through examples of Directional Laplacian Centrality
applied to well-known graph data sets. In Section 5, we describe our specific test data, experimental setup, and report
our findings.

2 PRELIMINARIES
A graph 𝐺 = (𝑉 , 𝐸) is a set 𝑉 of elements, called vertices, and a set 𝐸 of unordered pairs of vertices, called edges.
If {𝑢, 𝑣 } ∈ 𝐸, we say 𝑢 and 𝑣 are adjacent and write 𝑢 ∼ 𝑣. We call {𝑣 ∈ 𝑉 : 𝑢 ∼ 𝑣 } the neighborhood of 𝑢, and
𝑑𝑢 = |{𝑣 ∈ 𝑉 : 𝑢 ∼ 𝑣 }| the degree of 𝑢. A set of vertices 𝑆 ⊆ 𝑉 is connected if for any 𝑢, 𝑣 ∈ 𝑆, there exists a sequence
of adjacent vertices 𝑢, . . . , 𝑣. A maximal connected subset (one which is not strictly contained within a larger subset)

, Vol. 1, No. 1, Article . Publication date: March 2021.

3
is called a connected component and its size is the number of vertices in the component, |𝑆 |. For other basic graph
theory terminology, readers are referred to [6].

Directional Laplacian Centrality for Cyber Situational Awareness

•

In this work, for ease of exposition and simplicity, we focus on unweighted, undirected graphs. In most applications,
however, the edges of the graph may have natural weight or directionality information. The generalizations of the
techniques developed in Section 3 to weighted and directed cases (as appropriate) is a straightforward exercise.

2.1 Network Flow Data
Network flow summarizes data exchanged between pairs of IP addresses in a network. A single network flow is an
aggregation of multiple packets that occur within a small time window and have the same source IP, destination IP,
source port, destination port, and protocol. There is significant subtlety and engineering that goes into packet capture
and flow aggregation (for example, even identifying which IP is source and which is destination is not trivial), as
seen in one of the seminal papers [19] and the more recent [26]. However, for this paper it is enough to think of a
single flow as a record that contains a source and destination IP, and a time stamp. Other metadata are present in a
record (e.g., bytes, packets, ports, and protocol) which one could use to weight or filter the data. Initially created for
accounting and usage profiling, network flow is a prevalent source of data for cyber situational awareness. Advances
in flow monitoring are continuing to enable this usage [28]. A recent paper of Moustafa, Hu, and Slay provides a
thorough survey of network anomaly detection approaches using the paradigm of feature identification followed by
classification, clustering, machine learning, rule-based, or statistical methods [38]. Our approach fits this paradigm
with features derived from a graph interpretation of the network flow data followed by a statistical anomaly detection
based on those derived numerical features.

A set of network flow can be modeled as a graph in which vertices represent IP addresses and an edge {𝑢, 𝑣 }
indicates that a flow between IPs 𝑢 and 𝑣 is contained in the set. Although one could restrict to network flows with
specific ports or protocols for a more targeted analysis, in our experiments we will not filter or label vertices and
edges by ports or protocols but will consider all flows. To construct each graph we restrict to a specific time interval
in order to capture the structure of communications within a given time period. However, network flow gathered
from even a few hours typically creates a graph much too large to yield helpful insights, so in order to represent
time and capture structural evolution we consider a dynamic graph model. A dynamic graph is a sequence of graphs
{𝐺𝑡 }𝑁
𝑡 =1 where 𝑡 denotes a specific time, either instantaneous or a short time window, and 𝐺𝑡 = (𝑉𝑡, 𝐸𝑡 ). Dynamic
graphs in which 𝑡 represents an instantaneous time can be difficult to analyze since at any given instance the graph
may be quite sparse and fragmented; and in the case of network flow, they can evolve very rapidly as some flows
have duration on the order of milliseconds. Instead we consider small time windows, on the order of 30 seconds to
10 minutes, and gather all flow records that overlap the time window into a single graph, 𝐺𝑡 . For a dynamic graph
created from network flow an edge exists in 𝐺𝑡 between two IPs when a flow occurs with one as source and the other
as destination within the time window indicated by 𝑡. The vertices of 𝐺𝑡 are IP addresses present in at least one flow
within the time window. Many of the examples in this paper will be on a fixed snapshot of network flow data, a single
𝐺𝑡 , see Section 5 for details of that graph.

2.2 Spectral Graph Theory
Our methods for identifying potential anomalous actors within networks are rooted in spectral graph theory. This
area of mathematics studies properties of a graph through the eigenvalues and eigenvectors of matrices associated
with the graph, as illustrated in Figure 2. There are a variety of different matrices one could associate with a graph.
Perhaps the most basic and well-known, the adjacency matrix 𝐴 of an 𝑛-vertex graph 𝐺 = (𝑉 , 𝐸) is an 𝑛 × 𝑛 matrix

Fig. 2. From left to right: a graph, its normalized Laplacian matrix, and normalized Laplacian eigenvalues. Spectral graph theory
establishes relationships between eigenvalues and the graph they are derived from, represented in the diagram by the dashed line.

, Vol. 1, No. 1, Article . Publication date: March 2021.

1234AgraphG26641 100 13 1 10 12 10 1 123775Amatrix0,1,3,4Amatrixtime,asthenetworkevolves.Accordingly,analystscanmeasureanomalousnessnotonlyonanabsolutescale,butonarelativescale,takingintoaccountpriornetworkbehavior.Moregenerally,structuralmetricso↵erﬂexibilityina↵ordinganalyststheoptiontoviewtherawmetricdataitself,oranyvarietyofstatisticsderivedfromthisdata.However,forthesebeneﬁtstoberealized,themetricutilizedmustcapturestructuralpropertiesinameaningfulandnuancedway.Onesuchclassofnumericalmeasuresofgraphstructureiseigenvaluesofgraphs.Thestudyofgrapheigenvalueshasarichandextensivehistory.Thisareaofmathematics,knownasspectralgraphtheory,hasestablishedthatamyriadofgraphspropertiesareencodedinlinear-algebraicquantitiescalledeigenvalues,whicharederivedfrommatricesassociatedwithagraph.Foramorecomprehensivesurveyofsuchresults,thereaderisreferredto[2,3,4,7].However,forreadersunfamiliarwithlinearalgebraandspectralgraphtheory,abriefdescriptionofthefundamentalsnecessarytofollowthisworkisincludedbelow.GivenamatrixA,thevectorxiscalledaneigenvectorandthenumber aneigenvalueifAx= x.AgraphG=(V,E)isasetofelementsVcalledvertices,andasetofpairsofverticesEcallededges.Thereareavarietyofdi↵erentmatricesonecouldassociatewithagraph.Perhapsthemostwell-knownistheadjacencymatrixA,whichisdeﬁnedelement-wisebyA(i,j)=(1if{i,j}2E0otherwise.Twootherimportantmatrices,whichwillbethefocusofthiswork,aretheLaplacianmatrixLandnormalizedLaplacianmatricesL,L=D A,L=D 1/2LD 1/2,whereAandDdenotetheadjacencyanddiagonalvertexdegreematrices,respectively.TheeigenvaluesofA,LandLarelabeledinincreasingorder, 1 2··· n,andthesetofeigenvaluesiscalledthespectrum.Thisworkfocusesonhoweigenvaluesandeigenvectorsofgraphscanbeusedtoderiveimportancemeasuresforverticesandedgesinthenetwork.ThisallowsOneofthemostbasicandwell-knownmatricescommonlyassociatedwithgraphsistheadjacencymatrix...tobecontinued!•GraphLaplacian(combinatorialandnormalized)andspectrum[[Emilietodo:]]–Laplaciancentrality:[9]–Bounds:[6]–Interpretation•Laplacianimportancemethodology-[[Stephentodo:]][[Sinantodo:]]–Edgeandnodederivatives–Synthesizethedatatogether(mean,norm,geometricmean,sum,...)–Choiceofwhicheigenvalues(elbow,toponly,bottomonly,both)31234AgraphG266641 1p300 1p31 1p6 1p60 1p61 120 1p6 12137775Amatrix0,1,3,4Amatrixtime,asthenetworkevolves.Accordingly,analystscanmeasureanomalousnessnotonlyonanabsolutescale,butonarelativescale,takingintoaccountpriornetworkbehavior.Moregenerally,structuralmetricso↵erﬂexibilityina↵ordinganalyststheoptiontoviewtherawmetricdataitself,oranyvarietyofstatisticsderivedfromthisdata.However,forthesebeneﬁtstoberealized,themetricutilizedmustcapturestructuralpropertiesinameaningfulandnuancedway.Onesuchclassofnumericalmeasuresofgraphstructureiseigenvaluesofgraphs.Thestudyofgrapheigenvalueshasarichandextensivehistory.Thisareaofmathematics,knownasspectralgraphtheory,hasestablishedthatamyriadofgraphspropertiesareencodedinlinear-algebraicquantitiescalledeigenvalues,whicharederivedfrommatricesassociatedwithagraph.Foramorecomprehensivesurveyofsuchresults,thereaderisreferredto[2,3,4,7].However,forreadersunfamiliarwithlinearalgebraandspectralgraphtheory,abriefdescriptionofthefundamentalsnecessarytofollowthisworkisincludedbelow.GivenamatrixA,thevectorxiscalledaneigenvectorandthenumber aneigenvalueifAx= x.AgraphG=(V,E)isasetofelementsVcalledvertices,andasetofpairsofverticesEcallededges.Thereareavarietyofdi↵erentmatricesonecouldassociatewithagraph.Perhapsthemostwell-knownistheadjacencymatrixA,whichisdeﬁnedelement-wisebyA(i,j)=(1if{i,j}2E0otherwise.Twootherimportantmatrices,whichwillbethefocusofthiswork,aretheLaplacianmatrixLandnormalizedLaplacianmatricesL,L=D A,L=D 1/2LD 1/2,whereAandDdenotetheadjacencyanddiagonalvertexdegreematrices,respectively.TheeigenvaluesofA,LandLarelabeledinincreasingorder, 1 2··· n,andthesetofeigenvaluesiscalledthespectrum.Thisworkfocusesonhoweigenvaluesandeigenvectorsofgraphscanbeusedtoderiveimportancemeasuresforverticesandedgesinthenetwork.Thisallows266641 1p300 1p31 1p6 1p60 1p61 120 1p6 12137775Oneofthemostbasicandwell-knownmatricescommonlyassociatedwithgraphsistheadjacencymatrix...tobecontinued!•GraphLaplacian(combinatorialandnormalized)andspectrum[[Emilietodo:]]–Laplaciancentrality:[9]–Bounds:[6]–Interpretation31234AgraphG266641 1p300 1p31 1p6 1p60 1p61 120 1p6 12137775|{z}MatrixAmatrix 1=0 2=0.77 3=1.5 4=1.73Amatrixtime,asthenetworkevolves.Accordingly,analystscanmeasureanomalousnessnotonlyonanabsolutescale,butonarelativescale,takingintoaccountpriornetworkbehavior.Moregenerally,structuralmetricso↵erﬂexibilityina↵ordinganalyststheoptiontoviewtherawmetricdataitself,oranyvarietyofstatisticsderivedfromthisdata.However,forthesebeneﬁtstoberealized,themetricutilizedmustcapturestructuralpropertiesinameaningfulandnuancedway.Onesuchclassofnumericalmeasuresofgraphstructureiseigenvaluesofgraphs.Thestudyofgrapheigenvalueshasarichandextensivehistory.Thisareaofmathematics,knownasspectralgraphtheory,hasestablishedthatamyriadofgraphspropertiesareencodedinlinear-algebraicquantitiescalledeigenvalues,whicharederivedfrommatricesassociatedwithagraph.Foramorecomprehensivesurveyofsuchresults,thereaderisreferredto[2,3,4,7].However,forreadersunfamiliarwithlinearalgebraandspectralgraphtheory,abriefdescriptionofthefundamentalsnecessarytofollowthisworkisincludedbelow.GivenamatrixA,thevectorxiscalledaneigenvectorandthenumber aneigenvalueifAx= x.AgraphG=(V,E)isasetofelementsVcalledvertices,andasetofpairsofverticesEcallededges.Thereareavarietyofdi↵erentmatricesonecouldassociatewithagraph.Perhapsthemostwell-knownistheadjacencymatrixA,whichisdeﬁnedelement-wisebyA(i,j)=(1if{i,j}2E0otherwise.Twootherimportantmatrices,whichwillbethefocusofthiswork,aretheLaplacianmatrixLandnormalizedLaplacianmatricesL,L=D A,L=D 1/2LD 1/2,whereAandDdenotetheadjacencyanddiagonalvertexdegreematrices,respectively.TheeigenvaluesofA,LandLarelabeledinincreasingorder, 1 2··· n,andthesetofeigenvaluesiscalledthespectrum.Thisworkfocusesonhoweigenvaluesandeigenvectorsofgraphscanbeusedtoderiveimportancemeasuresforverticesandedgesinthenetwork.Thisallows0,0.77,1.5,1.73266641 1p300 1p31 1p6 1p60 1p61 120 1p6 12137775Oneofthemostbasicandwell-knownmatricescommonlyassociatedwithgraphsistheadjacencymatrix...tobecontinued!•GraphLaplacian(combinatorialandnormalized)andspectrum[[Emilietodo:]]–Laplaciancentrality:[9]3• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

4
where

𝐴𝑖 𝑗 =

(cid:40)1
0

if {𝑖, 𝑗 } ∈ 𝐸
otherwise

.

Two other important matrices, which will be the focus of this work, are the combinatorial Laplacian matrix, 𝐿 and
normalized Laplacian matrix L,

𝐿 = 𝐷 − 𝐴,
L = 𝐷 −1/2𝐿𝐷 −1/2,

where 𝐴 is the adjacency matrix defined above and 𝐷 is the diagonal matrix with vertex degrees on the diagonal, i.e.,
𝐷 = diag(𝐴1), where 1 is the appropriately sized all-ones vector. The matrices 𝐴, 𝐿, and L are all symmetric, and
hence have real eigenvalues which we label in increasing order:

𝜆1 ≤ 𝜆2 ≤ · · · ≤ 𝜆𝑛.

When unclear from context, we specify the matrix underlying a particular eigenvalue by writing, for example, 𝜆𝑖 (𝐿)
denotes that 𝜆𝑖 is the 𝑖th eigenvalue of the combinatorial Laplacian.

Unlike 𝐴, both 𝐿 and L are positive semi-definite, and therefore have non-negative eigenvalues. The eigenvalues,
or spectrum, of 𝐿 and L characterize a number of important properties not captured by the adjacency eigenvalues.
Particularly pertinent to our analyses, Laplacian spectra capture various graph connectivity and neighborhood
expansion properties. Loosely speaking, such properties quantify the extent to which a graph (or subsets of vertices
within a graph) are well-connected. For instance, an elementary fact is that the multiplicity of the eigenvalue 0 of
both 𝐿 and L equals the number of connected components of the graph. Furthermore, the second eigenvalue 𝜆2 of a
connected graph quantifies the extent to which that graph is well-connected, in several different regards.

In the case of the combinatorial Laplacian 𝐿, this second eigenvalue is referred to as algebraic connectivity. This
quantity is related to the graph’s vertex connectivity, the minimum number of vertices that must be deleted to
disconnect a graph. Furthermore, the corresponding eigenvector, called Fiedler’s vector, is frequently used to partition
a graph into well-connected groups; see [23] for more. In the case of the normalized Laplacian, the second eigenvalue
captures neighborhood expansion properties, which measure how many edges leave a set of vertices, relative to the
“volume" of that set. One way of quantifying such expansion is via Cheeger’s constant. More precisely, for a vertex
subset 𝑋 ⊆ 𝑉 , letting 𝑒 (𝑋, 𝑋 ) denote the number of edges between 𝑋 and its complement 𝑋 and defining the volume
of a set as vol(𝑋 ) = (cid:205)𝑖 ∈𝑋 𝑑𝑖 , the Cheeger ratio of 𝑋 is

Φ(𝑋 ) =

𝑒 (𝑋, 𝑋 )
min{vol(𝑋 ), vol(𝑋 )}

.

The Cheeger constant of the graph Φ(𝐺) is the minimum Cheeger ratio over all vertex subsets. Via Cheeger’s inequality
[8], 𝜆2(L) serves as an approximation of the Cheeger’s constant,

2Φ(𝐺) ≥ 𝜆2(L) ≥

Φ(𝐺)2
2

.

In this sense, the second eigenvalue controls graph neighborhood expansion properties. Further, just as the aforemen-
tioned Fiedler vector may be used to partition a graph, the normalized Laplacian eigenvector corresponding to 𝜆2(L)
can be used to partition the graph as well.

While the aforementioned connectivity properties were key to the early development of spectral graph theory,
researchers have shown a wide variety of graph structural properties are encoded in eigenvalues. For example,
vertex degrees [20], average shortest path length [37], diameter [17], chromatic number [52], independence number
[24], number of spanning trees [5], network flows1 and routing [3], and random walk mixing time and associated
parameters [2], can all be bounded, controlled, or characterized in terms of eigenvalues. This body of research attests
to eigenvalues of the aforementioned matrices serving as a far-ranging tool for capturing graph properties.

1The term “network flow” here is different than network flow data used in this paper. Here it refers to quantities flowing through a weighted and
directed graph.

, Vol. 1, No. 1, Article . Publication date: March 2021.

Directional Laplacian Centrality for Cyber Situational Awareness

•

5

Importance Measures

2.3
One approach towards identifying agents participating in anomalous behavior within a graph is to understand
their role within the graph structure relative to other agents and how that role changes over time. In this context,
graph-theoretic importance measures provide different ways of quantifying an element’s role in the system. Tracking
the importance over time, through a dynamic graph sequence, can identify anomalous changes in behavior or role.
Here, we briefly review examples of importance measures to elucidate the breadth of properties they can capture, and
to place our proposed importance measure within the literature.

Broadly speaking, one class of graph importance measures are based on the shortest-path structure in the graph.
For example closeness centrality ranks vertices based on their average shortest path length to other vertices in the
graph: vertices in close proximity to the rest of the graph via shorter paths are ranked more highly than vertices on
the periphery. Betweeness centrality measures the importance of a vertex based on the frequency of its occurrence
en route between other pairs of vertices. Accordingly, vertices that belong to many short paths linking other pairs
of vertices are ranked highly. Rather than restrict attention to shortest paths, another related class of importance
measures are based more generally on walks, which may be non-minimal in length. Since a pair of vertices may be
linked by infinitely many walks of arbitrary length, such measures tend to rely on asymptotic expressions, such as the
limiting distribution of a random walk. For instance, the well-known PageRank algorithm assigns scores to vertices
based on the stationary distribution of a modified random walk. Katz centrality considers the total number of walks
from a given vertex to the rest of the graph, penalizing longer walks with an attenuation factor.

Fig. 3. Different centrality scores on the same graph. Vertex size is proportional to a normalized centrality score, and color is
proportional to score percentile, with yellow for higher percentiles and red for lower percentiles.

Figure 3 illustrates these different centrality scores on a single 𝐺𝑡 from a dynamic graph of network flow. The
specific source and snapshot of the data is given in Section 5 where we describe our experiments in detail but the
structure is as outlined in Section 2.1. In Figure 3 vertices are sized proportionally2 to their centrality score, and
colored according to that score’s percentile in the graph. Comparing them, we see how seemingly subtle differences
in centrality definitions can yield drastically different scores. For betweeness centrality, we observe a heavily skewed
score distribution. This is partly due to the prevalence of pendant (i.e. degree 1 vertices), which cannot be on a shortest
path between two other vertices, and hence receive a betweeness score of 0. In contrast, the closeness centrality scores
are much more uniform across the graph. The high-degree or “hub” vertices are not well-distinguished from the
pendant vertices because their distances, on average, to the rest of the graph are comparable. Turning our attention to
the two walk-based measures, PageRank and Katz centrality3, we see that both better distinguish hub from pendant
vertices. PageRank assigns relatively larger scores to hubs than Katz centrality. Taking a broader view, this example
illustrates the importance of understanding the foundations of any proposed centrality metric in order to interpret its
behavior.

In Section 3, we will propose and justify our own centrality score based in spectral graph theory. While the
aforementioned centrality measures are implicitly related to eigenvalues, via the relationship of eigenvalues to

2To make the vertex sizes comparable across centrality measures, the scores within each centrality measure are divided by the sum of all the scores
for that centrality measure.
3Here, PageRank is computed with damping parameter 𝛼 = 0.85, and Katz centrality is computed with attenuation parameter 𝛼 =
𝜆max is the adjacency matrix spectral radius of 𝐺.

1
2𝜆max

where

, Vol. 1, No. 1, Article . Publication date: March 2021.

ClosenessBetweennessPageRankKatz• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

6
random walks and walk-counting noted above, the measures we will consider are explicitly derived from eigenvalues
and eigenvectors. In this vein, our work will build off prior research by Qi [43], who defined a spectral importance
measure they call Laplacian centrality. There, Qi defines vertex importance based on its contribution to the entire
spectrum, as measured by the Laplacian energy:

E (𝐺) =

𝑛
∑︁

𝑖=1

𝜆2
𝑖 .

More precisely, the Laplacian centrality of a vertex 𝑣 is the percent change in Laplacian energy from deleting 𝑣, i.e.
E (𝐺) − E (𝐺 \ 𝑣)
E (𝐺)
where 𝐺 \ 𝑣 denotes the graph formed by deleting 𝑣 and all of its edges from 𝐺. We note Laplacian centrality is always
non-negative [43]. We will return to and visualize Laplacian centrality alongside our proposed notion of centrality at
the end of Section 3.

,

3 DIRECTIONAL CENTRALITY MEASURES
As we have noted in Section 2.2 functions of the various spectra of the graph can encode a variety combinatorial
properties of the underlying graph. This motivates using spectral information to measure the importance of particular
vertices within that structure. Perhaps the most natural way to evaluate the importance of a particular vertex to a
spectral function is the aforementioned approach taken by Qi et al: remove the vertex from the graph, recalculate the
spectrum and the associated function and record the change.

However, in some cases deleting a vertex from a graph may induce dramatic changes to the graph structure that
disproportionately affect the spectrum. For example, recall from Section 2.2 that the Cheeger constant, a measure of
neighborhood expansion, is closely tied to the second eigenvalue of the normalized Laplacian. Consequently, the
deletion of any vertex that disconnects a graph – including, for example, vertices whose removal only isolates a
single vertex from the rest of the graph – converts the Cheeger constant and second eigenvalue to 0. Other graph
parameters we surveyed in Section 2.2 may also be changed significantly by the deletion of a vertex that, in turn,
induces jump-shifts in the spectrum. For this reason, assessing importance based on outright vertex deletion outcomes
may be an insufficiently nuanced approach. Instead, we propose measuring importance using a function of the
spectrum based on an infinitesimal change in the graph structure. More formally, we consider the derivative of an
eigenvalue in the direction of a vertex. In the remainder of this section, we develop this notion and use it to define a
more targeted notion of Laplacian centrality that we call Directional Laplacian Centrality. Following this technical
derivation we will build overall intuition for the behavior of Directed Laplacian Centrality by applying it to a variety
of well-studied networks in Section 4. We will then perform experiments using real and synthetic network flow
data in Section 5 to show how the Directional Laplacian Centrality changes in the presence of two types of planted
anomalies and indicate how it could be used by an analyst to facilitate situational awareness.

3.1 Eigenvalue Directional Derivative
Before we develop the notion of derivative of an eigenvalue in the direction of a vertex, we first recall some basic
facts about the dependence of an eigenpair on the entries of a matrix, (see for instance [35]).

Theorem 1. Let 𝑋0 be an real-symmetric matrix in R𝑛×𝑛 and let (𝜆0, 𝑣0) be an associated eigenpair such that ∥𝑣0∥ = 1.
If 𝜆0 is a simple eigenvalue then there is a neighborhood 𝑁 (𝑋0) and functions 𝜆 : 𝑁 (𝑋0) → R and 𝑣 : 𝑁 (𝑋0) → R𝑛 such
that for all 𝑋 ∈ 𝑁 (𝑋0)
(1) 𝜆(𝑋0) = 𝜆0,
(2) 𝑣 (𝑋0) = 𝑣0,
(3) ∥𝑣 (𝑋 ) ∥ = 1, and
(4) 𝑋 𝑣 (𝑋 ) = 𝜆(𝑋 )𝑣 (𝑋 ).

Furthermore, 𝜆 and 𝑣 are infinitely differentiable on 𝑁 (𝑋0).

In particular, this implies that if (𝜆, 𝑣) is a simple eigenpair associated with a real-symmetric matrix 𝐴 ∈ R𝑛×𝑛, then
for any other matrix 𝐵 ∈ R𝑛×𝑛, the matrix function 𝑀 (𝑡) = 𝐴 + 𝑡𝐵 defines, via the implicit function theorem, a pair
of functions (𝜆(𝑡), 𝑣 (𝑡)) which are infinitely differentiable in a neighborhood, 𝑁 , of 0 and such that ∥𝑣 (𝑡) ∥ = 1 and

, Vol. 1, No. 1, Article . Publication date: March 2021.

7
𝑀 (𝑡)𝑣 (𝑡) = 𝜆(𝑡)𝑣 (𝑡) for all 𝑡 ∈ 𝑁 . If we think of 𝐴 as the adjacency matrix of a graph and 𝐵 as the collection of edges
incident to a vertex 𝑥, this allows us to naturally define a notion of a directional derivative in the direction of the
vertex 𝑥 for any simple eigenpair. Specifically, recalling that given a parameterized matrix 𝑀 (𝑡) and the associated
eigenpair functions (𝜆(𝑡), 𝑣 (𝑡)), we have that

Directional Laplacian Centrality for Cyber Situational Awareness

•

𝑑𝜆
𝑑𝑡

(𝑡0) = 𝑣 (𝑡0)𝑇 𝑑𝑀
𝑑𝑡

(𝑡0)𝑣 (𝑡0),

and thus, the directional derivative in the direction of 𝑥 of (𝜆, 𝑣) for the adjacency matrix is given by 𝑣𝑥 (cid:205)𝑦∼𝑥 𝑣𝑦 .
Using this framework, we will define the directional derivative for eigenpairs of the both the combinatorial and
normalized Laplacian.

Lemma 2. Let 𝐺 = (𝑉 , 𝐸) be a simple graph and let 𝑥 be an arbitrary vertex. If (𝜆, 𝑣) is an eigenpair of the combinatorial
Laplacian 𝐿 of 𝐺, then the derivative of 𝜆 in the direction 𝑥 is given by

(cid:0)𝑣𝑥 − 𝑣𝑦 (cid:1) 2 .

∑︁

𝑦∼𝑥

If instead, (𝜆, 𝑣) is an eigenpair of the normalized Laplacian of 𝐺, then the derivative of 𝜆 in the direction 𝑥 is given by

(1 − 𝜆)

(cid:33) 2

(cid:32) 𝑣𝑥
√
𝑑𝑥

∑︁

𝑦∼𝑥

−

𝑣𝑦
√︁𝑑𝑦

− 𝜆 ∑︁
𝑦∼𝑥

2𝑣𝑥𝑣𝑦
√︁𝑑𝑥𝑑𝑦

.

Proof. Similarly as above, we define the adjacency matrix in the direction of 𝑥 to be

𝐴𝑖 𝑗 (𝑡) =

1 + 𝑡
1
0





{𝑖, 𝑗 } ∈ 𝐸, 𝑥 ∈ {𝑖, 𝑗 }
{𝑖, 𝑗 } ∈ 𝐸, 𝑥 ∉ {𝑖, 𝑗 }
otherwise

.

The matrix 𝐷 (𝑡) is then the diagonal matrix of 𝑡-dependent degrees, i.e. the matrix which has 𝐴(𝑡)1 on the diagonal.
In particular, 𝐷𝑥𝑥 (𝑡) = (1 + 𝑡)𝑑𝑥 , 𝐷𝑦𝑦 (𝑡) = 𝑑𝑦 + 𝑡 for 𝑦 ∼ 𝑥, and 𝐷𝑧𝑧 (𝑡) = 𝑑𝑧 for 𝑧 ≁ 𝑥. Thus we have that

𝑖 𝑗 (𝑡) = (𝐷 ′(𝑡) − 𝐴′(𝑡))𝑖 𝑗 =
𝐿′

𝑑𝑥
1
−1
0






𝑖 = 𝑗 = 𝑥
𝑖 = 𝑗, {𝑖, 𝑥 } ∈ 𝐸
{𝑖, 𝑗 } ∈ 𝐸, 𝑥 ∈ {𝑖, 𝑗 }
otherwise

,

and we see that the derivative of 𝜆 in the direction 𝑥 is given by

𝑣 (0)𝑇 𝐿′(0)𝑣 (0) = 𝑑𝑥𝑣 2

𝑥 +

𝑣 2
𝑦 − 2𝑣𝑥𝑣𝑦 =

∑︁

𝑦∼𝑥

(cid:0)𝑣𝑥 − 𝑣𝑦 (cid:1) 2 ,

∑︁

𝑦∼𝑥

as desired.

For the normalized Laplacian the situation is slightly more complicated by the need to use the non-commutative

product rule, however recalling that L (𝑡) = 𝐼 − 𝐷 (𝑡)−1/2𝐴(𝑡)𝐷 (𝑡)−1/2, we have that

𝑑
𝑑𝑡

L (𝑡) = 1/2𝐷 (𝑡)−3/2𝐷 ′(𝑡)𝐴(𝑡)𝐷 (𝑡)−1/2 − 𝐷 (𝑡)−1/2𝐴′(𝑡)𝐷 (𝑡)−1/2 + 1/2𝐷 (𝑡)−1/2𝐴(𝑡)𝐷 (𝑡)−3/2𝐷 ′(𝑡).

, Vol. 1, No. 1, Article . Publication date: March 2021.

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

8
Hence, using that 𝐷 (𝑡)−3/2𝐷 ′(𝑡) = 𝐷 ′(𝑡)𝐷 (𝑡)−1𝐷 (𝑡)−1/2 and that 𝐷 (0)−1/2𝐴(0)𝐷 (0)−1/2𝑣 = (1 − 𝜆)𝑣,

𝑣𝑇 L ′(0)𝑣 = 1/2𝑣𝑇 𝐷 ′(0)𝐷 −1(0)(1 − 𝜆)𝑣 − 𝑣𝑇 𝐷 (0)−1/2𝐴′(0)𝐷 (0)−1/2 + (1 − 𝜆)𝑣𝑇 𝐷 (0)−1𝐷 ′(0)𝑣

= (1 − 𝜆)𝑣𝑇 𝐷 ′(0)𝐷 −1(0)𝑣 − 𝑣𝑇 𝐷 (0)−1/2𝐴′(0)𝐷 (0)−1/2

= (1 − 𝜆)

= (1 − 𝜆)

(cid:32)
𝑣 2
𝑥 +

(cid:33)

𝑣 2
𝑦
𝑑𝑦

∑︁

𝑦∼𝑥

∑︁

2

−

𝑦∼𝑥

(cid:32)
𝑥 − 2 ∑︁
𝑣 2

𝑦∼𝑥

+

𝑣𝑥𝑣𝑦
√︁𝑑𝑥𝑑𝑦
(cid:33) 2

𝑣𝑥𝑣𝑦
√︁𝑑𝑥𝑑𝑦
(cid:33)
𝑣 2
𝑦
𝑑𝑦

∑︁

𝑦∼𝑥

= (1 − 𝜆)

(cid:32) 𝑣𝑥
√
𝑑𝑥

∑︁

𝑦∼𝑥

−

𝑣𝑦
√︁𝑑𝑦

− 𝜆 ∑︁
𝑦∼𝑥

2𝑣𝑥𝑣𝑦
√︁𝑑𝑥𝑑𝑦

,

− 𝜆 ∑︁
𝑦∼𝑥

2

𝑣𝑥𝑣𝑦
√︁𝑑𝑥𝑑𝑦

as desired.

□

It is easy to see that for both the combinatorial and normalized Laplacian the derivative with respect to the
eigenspace corresponding to eigenvalue 0 (1 for the combinatorial Laplacian and (cid:10)√
for the normalized Laplacian)
in the direction of any vertex is zero, as expected. Unfortunately, it is clear that if 𝜆 is a non-simple eigenvalue (and
hence corresponds to a eigenspace of dimension at least 2), then the definition of the derivative depends on the choice
of eigenvector associated with 𝜆. However, the following result shows that if we instead define the derivative in terms
of the entire eigenspace associated with 𝜆, then the derivative is indpendent of the particular decomposition of the
eigenspace.

𝑑𝑖 (cid:11)

𝑖

Lemma 3. Let 𝑆 be a 𝑘-dimensional subspace of R𝑛 and let 𝑥, 𝑦 ∈ R𝑛. There is some constant 𝐶 such that (cid:205)𝑖 𝑥𝑇 𝑣𝑖𝑦𝑇 𝑣𝑖 = 𝐶
for any choice of orthonormal basis of 𝑆.

Proof. Fix an arbitrary orthonormal basis of 𝑆, {𝑣1, . . . , 𝑣𝑘 } and let 𝑃 be an orthonormal matrix in R𝑘×𝑘 . Define

𝑤𝑖 = 𝑉 𝑃𝑒𝑖 𝑉 = [𝑣1 · · · 𝑣𝑘 ]. Now consider
∑︁

𝑖

𝑥𝑇 𝑤𝑖𝑦𝑇 𝑤𝑖 =

=

𝑥𝑇 (𝑉 𝑃𝑒𝑖 )𝑦𝑇 (𝑉 𝑃𝑒𝑖 )

𝑥𝑇𝑉 𝑃𝑒𝑖𝑒𝑇

𝑖 𝑃𝑇𝑉 𝑇𝑦

∑︁

𝑖
∑︁

𝑖

= 𝑥𝑇𝑉 𝑃

(cid:32)

∑︁

(cid:33)

𝑒𝑖𝑒𝑇
𝑖

𝑖

𝑃𝑇𝑉 𝑇𝑦

= 𝑥𝑇𝑉 𝑃𝑃𝑇𝑉 𝑇𝑦
= 𝑥𝑇𝑉𝑉 𝑇𝑦.
As this value is independent of the choice of 𝑃, and in particular 𝑃 can be chosen to be the identity, we have the
□
existence of the desired constant.

Thus, combining the observations of Lemma 2 and 3, we have the following well-founded definition.

Definition (Eigenspace Directional Derivative). Let 𝐺 = (𝑉 , 𝐸) be a graph and let 𝜆 be an eigenvalue of the combina-
torial Laplacian with (cid:8)𝑣 (1), . . . , 𝑣 (𝑘) (cid:9) an orthonormal basis of the associated eigenspace. The derivative of 𝜆 in the
direction 𝑥 ∈ 𝑉 is given by

1
𝑘

𝑘
∑︁

∑︁

𝑖=1

𝑦∼𝑥

(cid:16)
𝑥 − 𝑣 (𝑖)
𝑣 (𝑖)
𝑦

(cid:17) 2

.

If instead 𝜆 and (cid:8)𝑣 (1), . . . , 𝑣 (𝑘) (cid:9) parameterize an eigenspace of the normalized Laplacian, the derivative of 𝜆 in the
direction of 𝑥 ∈ 𝑉 is

1
𝑘

𝑘
∑︁

𝑖=1

(cid:169)
(cid:173)
(cid:171)

(1 − 𝜆)

∑︁

𝑦∼𝑥

, Vol. 1, No. 1, Article . Publication date: March 2021.

(cid:33) 2

(cid:32) 𝑣 (𝑖)
𝑥
√
𝑑𝑥

−

𝑣 (𝑖)
𝑦
√︁𝑑𝑦

− 𝜆 ∑︁
𝑦∼𝑥

𝑥 𝑣 (𝑖)
2𝑣 (𝑖)
𝑦
√︁𝑑𝑥𝑑𝑦

.

(cid:170)
(cid:174)
(cid:172)

9
We note that it is a straightforward exercise to generalize this definition to the case of weighted graphs or to the

Directional Laplacian Centrality for Cyber Situational Awareness

•

derivative in the direction of any subset of edges of the graph.

3.2 Directional Laplacian Centrality
We also note that, while the formalism and precise definition may be new, the essential idea of the eigenspace
directional derivative is solidly rooted in prior work. For example, the aforementioned work of Qi, et al. [43], where
they define Laplacian Centrality as E (𝐺)−E (𝐺\𝑣)
, where E (𝐺) is the sum of squares of eigenvalues of the combinatorial
Laplacian, can be understood as an attempt to capture the idea of a directional derivative. Specifically, letting 𝐴 be
the adjacency matrix of 𝐺 and letting 𝐵𝑥 be the adjacency matrix of the edges incident to 𝑥, define 𝐴(𝑡) = 𝐴 + 𝑡𝐵𝑥 .
Similarly as above, 𝐷 (𝑡) = 𝐴(𝑡)1 and 𝐿(𝑡) = 𝐷 (𝑡) − 𝐴(𝑡). With this notation it is easy to see that the Laplacian
Centrality of 𝑥 can be viewed as a re-scaling of the approximation

E (𝐺)

𝑑
𝑑𝑡

trace(𝐿2(𝑡))

(cid:12)
(cid:12)
(cid:12)
(cid:12)𝑡 =0

≈

trace(𝐿2(0)) − trace(𝐿2(−1))
0 − (−1)

.

Now, given a complete orthonormal decomposition (cid:8)(𝜆𝑖, 𝑣 (𝑖) )(cid:9) for the combinatorial Laplacian, we can evaluate this
derivative exactly as

𝑑
𝑑𝑡

trace(𝐿2(𝑡))

(cid:12)
(cid:12)
(cid:12)
(cid:12)𝑡 =0

=

=

=

𝑑
𝑑𝑡

∑︁

𝑖
∑︁

𝑖

(cid:32)

∑︁

𝑖

𝜆𝑖 (𝑡)2

(cid:33)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)𝑡 =0

2𝜆𝑖 (0)𝜆′

𝑖 (0)

(cid:16)
𝑥 − 𝑣 (𝑖)
𝑣 (𝑖)
𝑦

(cid:17) 2

.

2𝜆𝑖

∑︁

𝑦∼𝑥

It is interesting to note that, by standard rearrangements of the quadratic form, 𝜆𝑖 = (cid:205)

(cid:205)𝑦∼𝑥

(cid:16)
𝑥 − 𝑣 (𝑖)
𝑣 (𝑖)
𝑦

(cid:17) 2

can be thought of as the portion of 𝜆𝑖 "incident" with 𝑥.

(cid:16)
𝑥 − 𝑣 (𝑖)
𝑣 (𝑖)
𝑦

(cid:17) 2

and thus

{𝑥,𝑦 } ∈𝐸

These ideas can be further expanded to understand the relative importance of any combinatorial substructure
to functions of the spectrum. Namely, if 𝑓 is a function of 𝝀 = (𝜆1, . . . , 𝜆𝑘 ), the eigenspaces of a matrix associated
with a graph 𝐺 = (𝑉 , 𝐸), and 𝐸 ′ is the set of edges associated with a combinatorial substructure of 𝐺, then relative
importance of 𝐸 ′ to 𝑓 can be described by

𝑑
𝑑𝐸 ′

𝑓 (𝝀) = ∇𝑓 (𝝀)𝑇 𝑑𝝀
𝑑𝐸 ′

.

Returning to the Laplacian Centrality definition of Qi, et al. [43], it easy to see that it can be phrased within this
framework by defining 𝑓 as the sum over all eigenspaces {(𝜆𝑖, 𝑉𝑖 )} of dim(𝑉𝑖 )𝜆2
𝑖 .

Having established this context, we introduce our proposed importance measure Directional Laplacian Centrality.

Definition (𝑆-Directional (Normalized) Laplacian Centrality). Let 𝐺 = (𝑉 , 𝐸) be a graph on 𝑛 vertices with combi-
natorial and normalized Laplacians 𝐿 and L, respectively. Let (cid:8)(𝜆𝑖, 𝑣 (𝑖) )(cid:9) be an orthonormal decomposition of the
eigenstructure of 𝐿 (resp. L) such that 𝜆𝑖 ≤ 𝜆𝑖+1. For any set 𝑆 ⊆ {1, . . . , 𝑛}, the 𝑆-Directional Laplacian Centrality
(resp. 𝑆-Directional Normalized Laplacian Centrality) of a vertex 𝑥 ∈ 𝑉 is

𝑆- DLC(𝑥) =

(cid:16)
𝑥 − 𝑣 (𝑠)
𝑣 (𝑠)
𝑦

(cid:17) 2

,

∑︁

∑︁

𝑠 ∈𝑆

𝑦∼𝑥

𝑆- nDLC(𝑥) =

(1 − 𝜆𝑠 )

∑︁

𝑠 ∈𝑆

(cid:169)
(cid:173)
(cid:171)

(cid:32) 𝑣 (𝑠)
𝑥
√
𝑑𝑥

∑︁

𝑦∼𝑥

−

𝑣 (𝑠)
𝑦
√︁𝑑𝑦

(cid:33) 2

− 𝜆𝑠

2𝑣 (𝑠)
𝑥 𝑣 (𝑠)
𝑦
√︁𝑑𝑥𝑑𝑦

∑︁

𝑦∼𝑥

,

(cid:170)
(cid:174)
(cid:172)

respectively.

, Vol. 1, No. 1, Article . Publication date: March 2021.

10

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young
As oftentimes we are interested in the extremal eigenvalues4, we use the notation 𝑘-DLC and 𝑘-DLC to denote
the sets {𝑡 + 1, . . . , 𝑡 + 𝑘 } and {𝑛 − 𝑘 + 1, . . . , 𝑛} where 𝑡 is the dimension of the nontrivial null space of 𝐿. In this way,
eigenvectors in the null space are excluded because the directional derivative for such eigenvectors is always trivially
zero. As an example, we compute the Directional Laplacian Centrality and Normalized Laplacian Centrality for the
first 5 and last 5 nontrivial eigenvalues of the same graph considered in Figure 3. We present a visualization of the
centrality values in Figure 4, alongside Qi’s Laplacian Centrality, and Normalized Laplacian Centrality.5

(a) Directional Laplacian Centrality

(b) Laplacian Centrality

Fig. 4. (a): Directional Laplacian (top row) and Normalized Laplacian Centrality (bottom row) on the same graph, for the 5 largest
(right side) and 5 smallest (left side) nontrivial eigenvalues. (b): Laplacian Centrality (LC) and Normalized Laplacian Centrality
(nLC). Vertex size is proportional to score, and color is proportional to score percentile, with yellow for higher percentiles and red
for lower percentiles.

Comparing the visualizations within this figure, the differences underscore the impact the choice of eigenvalues and
matrix may have on the scores. These differences in centrality score align with our understanding that the maximal
and minimal eigenvalues of a graph capture very different properties. Comparing Figure 4a to the previously depicted
PageRank, Katz, Betweeness and Closeness centrality visualizations in Figure 3, there are clear qualitative differences.
Like those measures, DLC may ascribe importance to “hub" vertices with high degree, particularly as seen in the
5-DLC. But in certain cases, such as the 5-nDLC, low-degree vertices on long radial paths leading to hub vertices are
also highlighted. This may be helpful when looking for lateral movement anomalies in a network as long paths can
indicate such behavior. In contrast, the distance and walk-based measures give minimal scores to these vertices, as do
Qi’s Laplacian Centrality and normalized Laplacian Centrality scores visualized in Figure 4b. The ability to measure
structural importance beyond hubs is particularly valuable and intriguing, as this suggests DLC may reflect structural
nuances otherwise lost in popular measures. In the next section, we conduct experiments aimed at illustrating the
behavior of DLC and nDLC on a vareity of standard network science data sets.

4This preference is motivated by theoretical observations such as the Wigner Semi-circle Law [48–51] and the related extensions [45], as well as
the spectral analysis of the random 𝑑-regular graph [36, 46] and the Chung-Lu random graph [13–15] which show that behavior of the "bulk" of
the spectrum of many random matrices (including those associated with random graphs) has a limiting behavior. This indicates that if a we can
think of the process that generates a graph in a "low-rank" manner, then the "bulk" of the spectrum is is attributable to stochasticity rather than
intrinsic properties of the generative process.
5Although only defined for the combinatorial Laplacian by Qi in [43], the Normalized Laplacian Centrality can be defined in the same way, as the
percent change in the normalized Laplacian energy.

, Vol. 1, No. 1, Article . Publication date: March 2021.

k-DLCk=5k=5k-nDLCLCnLCDirectional Laplacian Centrality for Cyber Situational Awareness

•

11

Fig. 5. The Directional Laplacian Centrality scores for the 5 largest eigenvalues of the Karate Club, Les Mis and Network Science
datasets. In the visualisation (top), vertex size is proportional to score, and color is proportional to score percentile, with yellow for
higher percentiles and red for lower percentiles. Beneath each visualization, the plots present the top 15 scores.

4 APPLICATIONS OF DIRECTIONAL LAPLACIAN CENTRALITY
Before addressing the applicability of Directional Laplacian Centrality to cyber-situational awareness in Section 5, we
develop an intuition for the behavior of the DLC and nDLC by applying it to several well-understood graph data sets.
Below, we consider the Karate Club, Les Misérables, and Network Science collaboration data sets. Then in Section 4.2
we apply DLC and nDLC to the dynamic graph from the Enron email data set.

4.1 Social Interaction Data
We consider several prominent data sets frequently utilized to test graph centrality methods. Each of these datasets
features one or more vertices that, in their respective context, can be naturally interpreted as the most important or
central to that graph. Figure 5 presents the 5-DLC results for these data sets, which we describe below:

• Zachary’s Karate Club. A graph of social interactions amongst members of a karate club [53]. Due to a conflict
between an instructor Mr. Hi, and an administrator, John, the club fractured into two groups. The two highest
scoring 5-DLC values are achieved by the leaders of these groups, Mr. Hi and John.

• Les Misérables. A co-occurrence graph from [33] derived from Victor Hugo’s novel. Vertices represent
characters which are linked if they co-occur in a scene. The 5-DLC assigns the highest centrality value to the
protagonist, Jean Valjean, while other major characters such as Javert and Gavroche are similarly ranked highly.
• Network Science. A collaboration graph from 2006 [40] containing 379 researchers in network science. Two
authors are linked if they co-authored a paper together. As noted in [40], the top 5 authors with the highest
5-DLC scores are group leaders or senior researchers of groups working in network science.

These observations affirm that DLC may serve as a reasonable centrality measure identifying known important
entities in graphs derived from different contexts. While encouraging, such results are not surprising; indeed other
centrality measures, such as closeness, betweenness, PageRank, and Katz, would also likely rank some of the same
vertices highly.

In order to more comprehensively compare our method to existing centrality methods, next we compare not only
the top scoring vertices, but how the entire rankings compare to those given by these other well-known methods.
Furthermore, we apply our measures under a variety of different parameter settings, considering both DLC and nDLC,
and using the top 𝑘 smallest or largest eigenvalues, for all 𝑘. For each such case, we quantify the similarity in ranking

, Vol. 1, No. 1, Article . Publication date: March 2021.

Mr. HiJohnKarate ClubJohnMr. Hi3332914432318202824290.02.55.07.510.012.515.017.520.05-DLCValjeanGavrocheMariusLes MisValjeanGavrocheMariusJavertThenardierFantineEnjolrasCosetteGueulemerBabetMontparnasseBossuetMme.ThenardierClaquesousBamatabois05101520253035405-DLCJeong, HBarabasi, ANewman, MNetwork ScienceBarabasi, AJeong, HNewman, MOltvai, ZBoccaletti, SKurths, JVicsek, TAlbert, RYook, SRavasz, EPodani, JSzathmary, EMason, STombor, BNeda, Z051015202530355-DLC12

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

Fig. 6. Correlations between rankings of authors in the Network Science data set derived from our Directional Laplacian and
Normalized Laplacian centrality under different parameter settings, compared with rankings derived from four other well-known
centrality measures.

using a well-known nonparametric statistical measure, Spearman’s rank correlation coefficient. Spearman’s 𝜌 ranges
from -1 (if the ordinal rankings are reverses of each other) to 1 (if the ordinal rankings are identical). Figure 6 presents
the results for the Network Science collaboration graph, the largest of the 3 data sets.

Examining the correlation coefficients for closeness and betweenness centrality, neither DLC nor nDLC exhibit
strong rank correlations with these measures, regardless of whether the top or bottom 𝑘 eigenvalues are utilized. On
the other hand, PageRank and Katz centrality show very strong correlations with 𝑘-DLC, which tend to increase
as more of the top eigenvalues are considered. In contrast, the 𝑘-nDLC rankings consistently show moderate anti-
correlations across all four centrality measures. Across all 4 centrality measures, we observe a rapid convergence
between the 𝑘 and ¯𝑘 versions of DLC and nDLC as 𝑘 approaches the number of vertices. While the agreement of
these measures is inevitable (as the set of eigenvalues are eventually the same) it is notable this convergence happens
over an abbreviated range of choices for 𝑘 (especially for nDLC).6 We suspect this is a general phenomenon reflective
of the tight correlation of small eigenvalues of 𝐿 and L with the structure of 𝐺. However, as we will see in the next
section, there is still significant information that can be recovered by considering both 𝑘 and 𝑘 variants. Overall,
the range of differences observed here underscores the flexibility afforded by the parameter settings and choice of
matrix in applying our measures, and confirms DLC and nDLC rankings may be distinct from those given by other
prominent centrality measures.

4.2 Enron E-mail Data
The Enron email data set is a well studied data set [4, 7, 21, 32, 34, 42, 44] resulting from the public release of emails of
approximately 150 Enron employees gathered by a Federal Energy Regulation Commission (FERC) investigation into
the manipulation of energy market prices in the western region (in particular, California) by Enron. Subsequently,
these emails were deemed a public record and were made available to the public in various cleaned formats7. We

6Although it is clear that when the entire spectrum is being consider the exact same ordering will be recovered, we note that equal values of the
Spearman’s 𝜌 (such as between 𝑘-DLC and 𝑘-DLC for PageRank) does not imply that the orderings induced by those measures are the same.
7The analysis in this work is based on the version available at https://s3.amazonaws.com/enron-shetty-adibi/enron-mysqldump.tar.gz

, Vol. 1, No. 1, Article . Publication date: March 2021.

,

V
o
l
.

1

,

N
o

.

1

,

A
r
t
i
c
l
e

.

P
u
b
l
i
c
a
t
i
o
n
d
a
t
e
:

M
a
r
c
h
2
0
2
1

.

Fig. 7. Percentiles of 5-DLC, 5-nDLC, 5-DLC, and 5-nDLC of the Enron email day from September 12th to December 2th (the day before significant layoffs). Each email
graph is formed from the emails for the previous seven days. Each plot is sorted in order of increasing sum the percentiles over all graphs. Important/interesting employees
in the data set are identified by job title, Chief Executive Officer (CEO), Chief Operating Officer (COO), President and Executive Officer (P/EO), Vice President of Trading –
Gas West (VPT-GW). The employees labelled with “*” are associated with legal oversight of Enron’s activities (i.e., those with job titles such as General Council, Employment
Lawyer, Legal Specialist, etc.). The employee identified as Trader is one of several traders in the data set.

D
i
r
e
c
t
i
o
n
a
l

L
a
p
l
a
c
i
a
n
C
e
n
t
r
a
l
i
t
y
f
o
r
C
y
b
e
r
S
i
t
u
a
t
i
o
n
a
l

A
w
a
r
e
n
e
s
s

•

1
3

2001-10-012001-10-152001-11-012001-11-152001-12-01VPT-GW P/EO COO CEO Trader ********5-DLC2001-10-012001-10-152001-11-012001-11-152001-12-01VPT-GW P/EO COO CEO Trader ********5-nDLC2001-10-012001-10-152001-11-012001-11-152001-12-01VPT-GW P/EO COO CEO Trader ********5-DLC2001-10-012001-10-152001-11-012001-11-152001-12-01VPT-GW P/EO COO CEO Trader ********5-nDLC0.00.20.40.60.81.0• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

14
restrict our attention to the approximately 13,000 emails in the data set with a time stamp between September 12th,
2001 and December 2nd, 2001 (the day before Enron laid-off approximately 4,000 employees). For each 7 day window
within this time frame, we build the contact graph where two employees are connected by an edge if there is any
email communication between them in that window. From the graph associated with the window, we calculate the
percentile rank according to 5- DLC, 5- nDLC, 5- DLC, and 5- nDLC for each employee in the giant component. The
results of these calculations (sorted by the sum of all percentile scores over the entire time frame) are displayed in
Figure 7. While an in-depth investigation of these results is beyond the scope of this work, we wish to point out three
high level observations resulting from this analysis.

First, we note that for 5-DLC, 5-nDLC, and 5-DLC, the most important individual over the period of interest is the
Vice President of Trading in charge of the market segment corresponding to gas in the western region (VPT-GW).
As FERC’s investigation was focused on the manipulation of energy prices in California it is unsurprising that the
VPT-GW would be a key person of interest and this is reflected in the structure of the email communications gathered
by FERC. It is worth noting that we are aware of no other method applied to the Enron data set that identifies VPT-GW
as the most important individual.

The second observation is that the employees associated with legal issues (denoted by a “*” in Figure 7 and including
roles such as general council, employment lawyer, legal specialist, etc.) have visually higher overall importance
in 5-DLC and 5-nDLC than in 5-DLC and 5-nDLC with an average ranking of the summed percentile importance
increasing from 42 to 32 for DLC and from 34 to 25 for nDLC. While the precise reason for this shift is not clear, it
seems likely that the nature of legal advising within Enron results in a structurally different communication pattern
than that associated with trading, to which the bulk of the other employees can be affiliated.

Finally, we note the interesting patterns associated with a single trader in 5-DLC (denoted “Trader” in Figure 7).
While there are several other employees who have a similar pattern of only occasionally communicating with other
employees in the data set, this trader is unique in the level of importance during those time periods. In particular,
this trader’s average 5-DLC percentile is over 86.1% for the week-long periods when they are present in the giant
component. While the reason for this behavior is unclear, this trader appears in evidence brought by Snohomish
County Public Utility District (SPUD) in their lawsuit against Enron. According to contemporaneous reporting on
the lawsuit, in the transcripts provided by SPUD this trader arranged for the shut-down of power plants in order to
manipulate the California energy market through widespread blackouts/brownouts.

5 CYBER-SITUATIONAL AWARENESS EXPERIMENTAL SETUP AND RESULTS
To evaluate the effectiveness of our proposed DLC and nDLC, we analyze their sensitivity to planted anomalies in
a graph of network flow. Test data sets with real network data and ground truth labeled anomalies can be hard to
come by. There are many causes for this difficulty, for instance, network owners may not want to share technical
data regarding their network for fear that this information will allow adversaries to identify critical resources in a
network. Additionally, even if network owners are willing to release technical information regarding their network,
in many cases even labelling the ground truth is difficult. However, recently Los Alamos National Laboratory (LANL)
has shared three large de-identified data sets8 from their internal network capture [29–31, 47]. One set in particular,
Comprehensive, Multi-Source Cyber-Security Events (CMCE), contains authentication logs, process logs, network flow,
domain name server lookups, and labeled red team authentication events over the course of 58 consecutive days.
Figure 8 depicts the number of flow records in trailing 1-minute windows from the LANL CMCE dataset [30] as well
as timing of the successful red team authentications. It is worth mentioning that the red team events do not represent
all of the actions of the red team, but rather contain only the successful authentications from the red team. This data
set will be the source of our baseline graph for two of three experiments. While we recognize that no two networks
are alike, we note that in our experience with diverse operational data sets there are many similarities within network
traffic data across networks. The resulting graphs tend to have roughly power law degree distribution with few hubs
(high degree nodes) and many leaves or short paths. The “dandelion”, a high degree node connected to many degree 1
nodes, is a common motif found in these graphs. We believe that the LANL data is a good surrogate for a generic
network as we find these structures to be prevalent in this data set. But we also recognize the need for future work to
consider data from additional networks to feed our baseline.

8https://csr.lanl.gov/data/

, Vol. 1, No. 1, Article . Publication date: March 2021.

•

Directional Laplacian Centrality for Cyber Situational Awareness

15
In order to have a baseline graph that is not likely to be influenced by red team activities we chose an arbitrary
1-minute time window (timestamps 1065740 to 1065800) from the CMCE network flow that corresponds to a typically
sized graph and is well-separated from red team events (nearly 3 days after the last successful red team authentications
and 10 minutes before the next red team authentication). To avoid minor technical issues with the spectra of
disconnected graphs the experiments will only use the giant component of this flow graph, which contains 94% of
the vertices. This largest component has 2,005 vertices, 2,450 edges, and has a maximum degree of 605. Figure 9a
shows our chosen graph, which was also used in Figures 3 and 4 to illustrate differences in centrality scores. The
degree distribution of this graph is roughly power-law with exponent approximately equal to 2.18, see Figure 9b. Into
this specific snapshot from the LANL data we will inject two types of anomalies, represented as extremal subgraphs
depicted in Figure 10, the star and clique. The specific method of injection varies by experiment and so those details
are provided in Sections 5.1, 5.2, and 5.3. These two subgraphs represent building blocks of adversarial behavior:
network reconnaissance or data gathering (clique) and lateral movement (star). By studying the injection of these two
patterns separately we can better understand how their presence will perturb importance values.

Star anomaly: In the context of network flow, the injection of a star represents the scenario in which a particular
IP address (represented by the central, or root, vertex 𝑟 ) exchanges data with some additional vertices (the leaves)
while the rest of the graph remains exactly the same. Such a scenario might be malicious or benign, depending on the
number of additional IPs contacted and the nature of the data exchange. Regardless, this structural change should be
reflected as an increase in the importance of 𝑟 since the increase in number of IPs with which 𝑣 exchanges data is the
sole change in the graph.

Fig. 8. Flow record density of trailing 1 minute window for the LANL data set. Successful red-team authentications are denoted
by vertical gray lines.

(a) Graph visualization

(b) Degree distribution

Fig. 9. Graph visualization of network flow over 1 minute from CMCE data (left) and the degree distribution of that graph (right)

, Vol. 1, No. 1, Article . Publication date: March 2021.

16

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young
Clique anomaly: The injection of a clique represents the scenario in which a particular set of IP addresses all
exchange data with each other while the rest of the graph remains exactly the same. Such a scenario could be benign,
representing a broadcasting operation in a distributed computing scenario, or could represent malicious behaviour
such as a prelude to data exfiltration or command-and-control. In either case, the importance of the involved vertices
should increase as the inter-set communication represents the sole change in the graph.

Using these anomalies we conduct three injection experiments, described in the next three subsections, with
increasing levels of complexity and stringency. The first two experiments will be performed on our chosen snapshot
of LANL network flow while the third uses a synthetic time-evolving graph. In Section 5.1 we consider injection of
both patterns among low importance vertices in the baseline graph mentioned above, and in Section 5.2 we randomly
inject the star anomaly. This simulates what could happen if the only temporal change in a graph is the addition
of one of these subgraphs. In Section 5.3 we inject the star anomaly within normal temporal evolution. It is worth
mentioning that conceptually simpler measures (such as degree change or local density) may also be able to detect
the root of the star-anomaly or the vertices of clique-anomaly when compared to a sufficiently stable background.
However, in the dynamic environment, such as that discussed in Section 5.3, these measures will have significant
difficulty in distinguishing the injection of anomalous behavior amid the natural variation of the underlying graph.

5.1 Anomaly Injection Among Low-Importance Vertices
In this first experiment we deterministically choose vertices with low importance scores to be involved in the anomaly.
This simple experiment tests whether, all else equal, the change to lower-importance vertices is registered by the
centrality metrics. The procedure for injecting both anomalies into 𝐺 starts by ordering the vertices of 𝐺 according to
importance in 𝐺, lowest to highest. Then, to inject a star anomaly of size 𝑠 into 𝐺:
(i) Select a root vertex 𝑟 to be one of the vertices of minimum importance.
(ii) Select the next smallest 𝑠 − 1 vertices in the list of importance to be leaves.
(iii) Add, if necessary, an edge between the root vertex and any leaf.
Similarly, the procedure for injecting a clique anomaly of size 𝑠 into 𝐺 is:

(i) Select a set 𝑆 of 𝑠 smallest importance vertices.
(ii) For every pair of vertices, 𝑢, 𝑣 ∈ 𝑆, add, if necessary, an edge between 𝑢 and 𝑣.
Figure 11 displays the percentile of the importance values of the vertices involved in the injection as more vertices
are added to the anomaly (indicated on the 𝑥 axis). For example, in Figure 11a at 𝑥 = 100 the corresponding 𝑦 value
for the solid line is the percentile of the 5-DLC for the root vertex after 100 leaf vertices have been attached to it. The
𝑦 value for the dashed line is the percentile of the average 5-DLC over all of the 100 leaf vertices. For both the leaf
vertices and the vertices involved in the clique, the centrality scores are averaged before evaluating the centrality
percentile. We use the percentile rather than the raw centrality score in order to put centralities of all graphs on
the same scale. Each 𝑥 value corresponds to a different graph (the baseline graph with a differently-sized anomaly
injected) and thus the importance values may not be comparable across all 𝑥 values. For this reason we will continue
to use the percentile in the remaining two experiments.

The most striking result of this experiment is that when the injection size is larger than approximately 7.5% of the
graph for 5-DLC (Figures 11a and 11c) the average importance of the participating vertices is at or above the 99th
percentile, representing an increase in importance percentile of more than 3 orders of magnitude. A similar increase

Fig. 10. A star graph (left) and a clique (right).

, Vol. 1, No. 1, Article . Publication date: March 2021.

Directional Laplacian Centrality for Cyber Situational Awareness

•

17

(a) Star Injection for 5-DLC

(b) Star Injection for 5-nDLC

(c) Clique Injection for 5-DLC

(d) Clique Injection for 5-nDLC

Fig. 11. Importance percentile for vertices in injected anomalies as a function of anomaly size.

occurs for the 5-nDLC under clique injection when the anomaly size is approximately 12.5% of the graph. Further,
the results of these experiments also clearly indicate that both importance measures can be sensitive to even fairly
small injections. For instance, when the injection size is approximately 1% of the size of the graph, both importance
measures register an order of magnitude increase for the star injection and an approximately 2 orders of magnitude
increase for the clique injection.

In the negative direction, it is clear by examining Figure 11b that beyond an initial increase in relative importance,
the nDLC measure is relatively insensitive to the size of the injected star graph. However, this is consistent with the
known behavior of the normalized Laplacian. Specifically, by applying the theory of quasi-randomness, it can be
shown that the spectrum of the normalized Laplacian is sensitive to presence of small cycles in the graph [9, 10, 16, 18].
As a star graph contains no cycles, any small cycles that emerge necessarily have a significant contribution from the
underlying graph. Further, as the example graph has relatively few edges, it is natural to expect that, even for quite
large injections of a star, there will be relatively few short cycles formed in the graph.

5.2 Anomaly Injection Among Random Vertices
In this next experiment we randomly choose vertices to be involved in the anomaly and consider the results over
many trials. In this sense, this experiment reflects average case behavior in a static graph, and accounts for the effects
of vertex choice in the prior experiment. A priori, there is no reason to believe that the importance measures are
independent of the precise set of vertices involved in anomalous behavior. In particular, it is possible that the choice of
vertex order in the experiments depicted in Figure 11 is a nontrivial factor in the results. Thus, to test the sensitivity of
these results an additional series of experiments injecting a star anomaly is performed. Namely, as before, the LANL
flow graph depicted in Figure 9a is utilized as a test case in which structural changes are planted, and the subsequent
changes in importance scores are measured over many trials. The methodology for a single trial is as follows:

(i) Randomly select a vertex 𝑣.
(ii) Randomly choose a vertex subset 𝑆 with 𝑘% of the graph’s vertices.
(iii) For any 𝑠 ∈ 𝑆 that is not already connected to 𝑣, connect 𝑣 to 𝑠.
(iv) Compute importance score and score percentile of 𝑣 before and after these additional edge insertions.

By measuring the change in importance score of 𝑣 for different levels of 𝑘, this experiment tests the importance
measure in two regards: (1) whether the importance measure can detect the aforementioned structural change (as
indicated by a increase in the importance score); and (2) whether the importance measure is sensitive to the intensity

, Vol. 1, No. 1, Article . Publication date: March 2021.

0100200300400500Size1021011001011025-DLCRootLeaves0100200300400500Size1021011001011025-nDLCRootLeaves0100200300400500Size1021011001011025-DLCClique0100200300400500Size1021011001011025-nDLCClique• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

18
of these changes (as indicated by larger increases in the importance score for larger values of 𝑘). In order to reduce the
overall computational load and limit the effects of averaging over a large set of vertices, this experiment is restricted
to studying the importance of the root vertices when a star is injected.

0.1%
(2 edges)

0.5%
(10 edges)

1.0%
(20 edges)

5.0%
(100 edges)

10.0%
(201 edges)

C
L
D
-
5

(cid:123)
(cid:124)
(cid:125)
(cid:122)

Before
After
Change

(cid:123) Before
After
Change

(cid:124)
(cid:125)

(cid:122)

C
L
D
n
-
5

Score

2.30
2.31
0.01

PCTL
Score
44% 1.08
55% 1.11
11% 0.03
50% -7e-5
1%
-2e-3

PCTL
Score
PCTL
Score
43% 2.04
45% 1.11
74% 205.68
64% 1.19
31% 203.63
20% 0.08
49% -9e-6
52% -9e-7
-4e-5
1%
1%
-3e-2
-4e-3
-8e-4
-7e-4 -49% -2e-3 -51% -4e-3 -49% -2e-2 -48% -3e-2

PCTL
Score
45% 0.83
67% 1.47
22% 0.64
50% 5e-5
1%
-2e-2

PCTL

46%
99%
53%

51%
1%
-50%

Table 1. Importance scores for a vertex before and after star injection according to the proportion of other vertices to which the
chosen root vertex connects. The results are averaged over 500 trials.

The results of the experiment are presented in Table 1. The experiment was run for 𝑘 =0.1, 0.5, 1, 5, and 10%, which
corresponds to star anomalies with 2, 10, 20, 100, and 201 edges incident to the root 𝑣. The table presents the mean
scores and mean percentile before and after the star is inserted, along with the mean change, over 500 trials. Turning
attention first to the 5-DLC scores, we observe a positive net change. Even for the smallest value of 𝑘 in which only
two additional edges are added, the 5-DLC scores are responsive, registering an average score percentile increase of
11%. Additionally, we note this change in percentile increases monotonically for each value of 𝑘, with the largest
value of 𝑘 registering an increase of 53% placing the root vertex in the 99th percentile. These results suggest 5-DLC
scores can both detect the star anomaly at minuscule levels of intensity, and reflect the relative magnitude of the star
anomaly.

In contrast, the nDLC scores decrease in response to the star anomaly. Furthermore, these scores decrease more as
the star anomaly intensity parameter 𝑘 increases. This suggests nDLC scores can detect, and are sensitive to, the star
anomaly, but in the opposite direction of the DLC score values. To explain why this apparent “inverted scale" occurs
for nDLC, the aforementioned theory of quasi-random graphs [9, 10, 16, 18] is again relevant. By this theory, the
prevalence of short cycles greatly impacts the spectrum, and the star injection is likely to increase the number of such
cycles incident to the root vertex 𝑣. The net effect of this change on the nDLC score is ultimately negative because
the normalized Laplacian matrix shifts and inverts the sign of the spectrum of the matrix 𝐷 −1/2𝐴𝐷 −1/2. It is worth
noting these observations are in agreement with the results presented in Figure 11b, in which root vertices exhibited
smaller nDLC values than leaf vertices. However, more research is necessary to better interpret nDLC scores, and
to reconcile these observations with the clique experiment of Figure 11d in which the nDLC scores increase. This
dichotomy suggests that nDLC scores can have seemingly counterintuitive interpretations, while DLC scores afford
simpler interpretations in the contexts considered here.

5.3 Anomaly Injection with Time-Evolution
The prior two experiments show that on a static graph the inclusion of an anomaly is reflected in a change in DLC
or nDLC. However, for situational awareness one must compare a current snapshot with an anomaly to a prior
snapshot without an anomaly. In this way we wish to see that the DLC or nDLC are also perturbed significantly in
the presence of an anomaly injected at a specific time step, aiding an analyst in discovering the anomalous vertex
when comparing importance scores across time steps. To that end, in our final experiment we assume a star anomaly
occurs concurrently with the natural time-evolution of a network. This tests the robustness of the measures in the
presence of natural noise. In order to simulate the natural time-evolution of a cyber network, we require a temporal
graph model. For this purpose, we utilize an extension of a model developed by Hagberg, Lemons, abd Misra that was
designed to capture temporal dynamics observed in cyber data.

5.3.1 Hagberg-Lemons-Misra Model. Temporal variations in network traffic comprise a mix of fairly steady computer-
generated traffic and more variable human-generated traffic. Overall, in the data we have observed, beyond some

, Vol. 1, No. 1, Article . Publication date: March 2021.

•

Directional Laplacian Centrality for Cyber Situational Awareness

19
temporal variability (e.g., more traffic during the day than overnight) the structure of communications, as reflected by
the degree distribution of graphs for small time windows, is fairly stable. The temporal graph model developed by
Hagberg, Lemons, and Misra [25], which we refer to as the HLM model, allows the user to specify a degree sequence
and builds on the Chung-Lu model [11, 12] which generates graphs consistent with a given expected degree sequence.
HLM accounts for temporal variability by “masking” some vertex pairs at each time step. Those edges in the current
time step that correspond to vertex pairs not in the masking set are carried to the next time step, while vertex pairs that
are in the masking set are included in the next time step based on independent Bernoulli trials, regardless of whether
they correspond to edges in the prior time step. All time steps of the HLM evolution are equal in distribution, and
equal to a Chung-Lu model with the initial degree sequence. Recent work by the authors of the present paper, together
with Jenne [1], has extended this model to include a temporally varying degree distribution, now the Temporal
HLM or THeLMa model, and shown how to rapidly generate THeLMa instances. In order to test our DLC and nDLC
measures in realistic time-varying data we will use a THeLMa instance with parameters measured from the LANL
data set.

While the THeLMa model can be based on a variety of random graph models, for these experiments we will
consider the variant based on the Chung-Lu random graph model. Formally, this begins with a degree sequence
𝑤 = ⟨𝑤𝑣⟩𝑣 ∈𝑉 as an 𝑛-dimensional vector, where 𝑛 = |𝑉 | is the total number of vertices present across all graphs.
The value 𝑤𝑣 is the expected degree of vertex 𝑣 across all time instances. The THeLMa model additionally requires
a vector that captures temporal variation in graph density, 𝜏 = ⟨𝜏𝑡 ⟩𝑇
𝑡 =1. This corresponds to the expected degree of
vertex 𝑣 at time step 𝑡 being 𝜏𝑡 · 𝑤𝑣 when there is no temporal correlation. A final necessary parameter, 𝛼 ∈ [0, 1]
controls the aforementioned masking set and represents the amount of temporal correlation. That is, if 𝛼 = 1 there is
no correlation between successive graphs and if 𝛼 = 0, successive graphs are identical. One could consider 𝛼 to be a
vector in [0, 1] (𝑛
2) , with one 𝛼 value for each edge, but for simplicity in this experiment we use a single value for
all edges. Given these parameters, the THeLMa model generates a sequence of graphs 𝐺1, 𝐺2, . . . , 𝐺𝑇 . The graph at
time 𝑡, 𝐺𝑡 +1, is formed from 𝐺𝑡 using the 𝛼 parameter to control for how much of 𝐺𝑡 is carried forwards. Specifically,
a masking set 𝑀𝑡 is generated where each pair of vertices, {𝑢, 𝑣 }, is in 𝑀𝑡 independently with probability 𝛼. Any
pair {𝑢, 𝑣 } ∉ 𝑀𝑡 which is an edge in 𝐺𝑡 is carried forward to be an edge in 𝐺𝑡 +1, and any unmasked pair of vertices
which is not an edge in 𝐺𝑡 will not be in 𝐺𝑡 +1. Then, any pair of vertices {𝑢, 𝑣 } ∈ 𝑀𝑡 is present as an edge in 𝐺𝑡 +1
independently with probability9 𝜏𝑡 +1𝑤𝑢 𝑤𝑣
, regardless of whether {𝑢, 𝑣 } was an edge in 𝐺𝑡 , where 𝜌 = (cid:205)𝑣 ∈𝑉 𝑤𝑣. Putting
𝜌
this all together we see that the probability of an edge in 𝐺𝑡 +1 is given by

𝑃 ({𝑢, 𝑣 } ∈ 𝐺𝑡 +1) =

(cid:40) 1 − 𝛼 + 𝛼 · 𝜏𝑡 +1𝑤𝑢 𝑤𝑣

𝜌

𝛼 · 𝜏𝑡 +1𝑤𝑢 𝑤𝑣

𝜌

{𝑢, 𝑣 } ∈ 𝐺𝑡
{𝑢, 𝑣 } ∉ 𝐺𝑡

.

Unlike in the HLM model, which does not allow the degree sequence to be time varying, 𝐺𝑡 is not quite equal in
distribution to G(𝜏𝑡 · 𝑤), the Chung-Lu model with expected degree sequence given by 𝜏𝑡 · 𝑤. Rather, the edge {𝑢, 𝑣 }
is present in 𝐺𝑡 with probability (1 − 𝛼)𝑡 𝜏1𝑤𝑢 𝑤𝑣

+ (cid:205)𝑡

𝑖=1 𝛼 (1 − 𝛼)𝑡 −𝑖 𝜏𝑖 𝑤𝑢 𝑤𝑣

𝜌

𝜌

.

5.3.2 Experimental Results. To determine the parameters of the THeLMa model into which we will inject the anomaly,
we take a series of 15 snapshots of one-minute traffic intervals in a 5-minute window surrounding our example LANL
graph (each of these snapshots is shifted 20 seconds in time). The 𝑤 vector of THeLMa is determined by the average
degree sequence (rounded up) of the vertices across these snapshots (with vertices which do not appear in a snapshot
counting as having degree 0). The resulting weighting vector has 3,987 entries, with a maximum value of 617, and a
average value of 1.74.10 To mimic the natural circadian rhythms expected in a cyber-security system, the temporal
weighting sequence, 𝜏, is given by 500 equally spaced evaluations of (3−cos(𝑥))/2 over the range [0, 4𝜋]. The resulting
degree distribution and temporal sequence are illustrated in Figure 12.

To simulate a relatively slowly changing environment we set the evolution parameter at 𝛼 = 0.05 which means that
every edge has the potential to change state approximately 25 times during the course of the evolution. The result of

9In order to avoid probabilities greater than 1 we actually use min (cid:110)1, 𝜏𝑡 +1𝑤𝑢 𝑤𝑣
10It is worth noting that, because of the extreme sparsity and highly skewed nature of the degree sequence, a standard Chung-Lu model with
this parameter has maximum expected degree significantly smaller than 617. In fact the expected maximum degree is approximately 446 and the
expected average degree is 1.62. To be reflective of this difference we will refer to the value of a vertex in the 𝑤 as its weight, instead of the more
typical usage of expected degree.

(cid:111) as the probability here.

𝜌

, Vol. 1, No. 1, Article . Publication date: March 2021.

20

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

(a) log-log Complimentary Cumulative Weight Se-
quence

(b) Temporal Sequence

Fig. 12. Parameters for THeLMa model

Giant Component Size
Giant Component Edges
Maximum Degree
Total Edges

Minimum Maximum Mean
2949.3
4669.7
660.9
4795.1

2169
2863
452
3123

3473
6282
896
6327

Table 2. Statistics for graphs in THeLMa sequence.

(a) Giant Component Size

(b) Number of Edges

(c) Top 5 Degrees

Fig. 13. Summary Statistics for Generated THeLMa Model

the THeLMa model with these parameters is a sequence of 500 graphs with significant variation of parameters as
shown in Table 2. The evolution of these parameters is shown in Figure 13.

For each time step in the sequence of graphs we will compare the generated graph at time 𝑡 with the same graph
after injecting a single star anomaly with 30 leaves. For consistencies sake we will be injecting the anomaly to the same
vertices across all time steps. Before selecting the vertices that will participate in the injected anomaly, we observe
that almost all vertices have some time step in the THeLMa model where they are in a small component (i.e., not in
the giant component). As the block structure of the combinatorial and normalized Laplacians respects the component
structure of the underlying graph, typical eigenspaces are associated with a single component and are identically
zero on all other components. The sole exception to this is the case where multiple components have a common
eigenvalue, in which case there does exist a basis for the associated eigenspace where all basis vectors are non-zero on
all the components with the common eigenvalue. Even for these eigenspaces it is typical, for computational reasons,
to choose a basis that respects the underlying component structure. We will respect this convention in our eigenbasis

, Vol. 1, No. 1, Article . Publication date: March 2021.

Directional Laplacian Centrality for Cyber Situational Awareness

21
decomposition. As a consequence, when considering ¯5- DLC and 5- nDLC, at any particular time step there are at
most 5 components whose vertices have non-zero importance. In practice, there is typically only a single component
whose vertices have non-zero importance, the giant component. As a consequence, the injection of any anomaly may
trivially change the importance of the vertices involved by adding them to the giant component. To avoid this issue,
we will choose the anomaly from the set of 66 vertices which are in the giant component for every time step. This set
is naturally biased to those vertices of higher weight, with an average weight of 36.1 and so we further refine this set
by remove the top 20% of vertices in terms of weight resulting in a set 𝑋 of candidate vertices for the anomaly with
an average weight of 7.1. The root and thirty leaves forming the anomaly, A, are then selected randomly from the
remaining 53 vertices.

•

Now, given the observed graph 𝐺𝑡 at some time step 𝑡, we wish to understand how the behavior of ¯5- DLC and
5- nDLC differs between 𝐺𝑡 +1 and 𝐺𝑡 +1 + A. To this end, for each vertex 𝑣 in A and for each time step 𝑡, we identify a
set of vertices 𝑆 (𝑡 )
such that for all 𝑠 ∈ 𝑆𝑣 the percentile ranking of the (normalized) DLC in 𝐺𝑡 differs from 𝑣 by at
𝑣
most 2.5% and 𝑠 has a non-zero importance in 𝐺𝑡 +1.11 We refer to this set as the cohort associated with 𝑣. The former
condition allows us to aggregate all vertices sufficiently similar to 𝑣, while the second condition accounts for the
fact that the vertices of A were chosen in such a way that they have non-zero importance for all time steps. By
considering the percentiles of the (normalized) DLC for vertices in 𝑆𝑣, we can recover a "typical" evolution of the
importance of a vertex like 𝑣 after one time step.

In Figure 14 we compare the behavior of the percentile DLC score for the anomaly vertices versus the vertices in
the associated cohort. Specifically, in Figures 14a and 14b, we show the distribution and the cumulative distribution,
respectively, of the gap between the percentile DLC score with an anomaly present and the percentile score without
the anomaly. In Figures 14c and 14d, we instead compare the percentile DLC score with an anomaly with the score in
the prior time step. As Figure 14b emphasizes, there is relatively little difference between the percentile scores for
the cohort vertices with or without the anomaly present. In contrast, from Figure 14a the percentile scores for the
vertices participating in the anomaly are typically about 2.5% (for the leaves) to 5% (for the root) higher than they
would be without the anomaly. In contrast, in Figures 14c and 14d we see that for both the anomaly vertices and
the associated cohorts, the little typical change in percentile between the previous time step and the anomaly time
step. However, from Figure 14c we can see that the vertices in the cohort of the anomaly have a significantly larger
probability of having a sharp decrease in the percentile ranking. Taken together, this indicates that there is likely a
tendency to of the scores of vertices to naturally revert to the median behavior under the natural evolution, however
an injected anomaly somewhat moderates this tendency in a localized way (i.e., while the vertices participating in the
anomaly resist reverting towards the median, this effect does not carry over to similarly situated vertices).

The figures provided in Figure 15 are analogous to those in Figure 14 except for being applied to the normalized
DLC percentiles. We see that qualitatively, the results for the normalized DLC percentile are similar to those for the
DLC percentile. Quantitatively, Figure 15 indicates that the variability of for the normalized DLC percentiles is larger
than that of the DLC, but the injection of the anomaly provides are larger boost to the percentile scores, particularly
for the root of the anomaly.

6 DISCUSSION
This paper introduced two new spectral-based vertex centrality measures, DLC and nDLC, and used the setting
of network flow data to illustrate their sensitivity and ability to identify anomalies planted in graphs. Our new
centralities are related to existing vertex centralities, most closely to the work of Qi, et al. [43], but use a more nuanced
approach by measuring changes to eigenvalues in the face of infinitesimal changes to a given vertex. This allows for
more subtle structural features in a graph to have measurable centrality.

Our experiments in Section 5 show how the DLC and nDLC measures can be used to provide attribution of certain
kinds of anomalies to cyber analysts. In the first experiment we see that the percentiles of both DLC and nDLC,
calculated using the top 5 eigenvalues, show significant increases when a star or clique anomaly is injected onto low
importance vertices. This is true even when the injected anomaly is a rather small percentage of the graph. In the
second experiment, rather than considering only low importance vertices, we inject a star anomaly of varying size
randomly into the graph. Again, we see that even for small anomalies there is a measurable change in both DLC
and nDLC percentiles for the root vertex of the star. These two experiments taken together show that on average,

11The sets 𝑆𝑣 have an average size of 182.4 and 190.4, for ¯5- DLC and 5- nDLC, respectively.

, Vol. 1, No. 1, Article . Publication date: March 2021.

22

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

(a) Kernel Density Estimate for the distribution of the gap
between the scores with and without the injected anomaly.

(b) Kernel Density Estimate for the cumulative density
function for the gap between the scores with and without
the injected anomaly.

(c) Kernel Density Estimate for the distribution of the gap
in between the scores with the injected anomaly and the
score in previous time step.

(d) Kernel Density Estimate for the cumulative density
function for the gap in between the scores with the injected
anomaly and the score in previous time step.

Fig. 14. ¯5- DLC

even small star anomalies manifest measurable changes in both centrality measures. This indicates that looking for
vertices that have a large increase in centrality from one time step to the next may narrow the set of IP addresses to
investigate for malicious behavior.

Those first two experiments did not take into account temporal variation in the network. Rather, we compared a
static, typical network flow graph 𝐺 to that same graph with an anomaly added. In the third experiment we added
the additional complexity of temporal variation. Using the THeLMa model to create a dynamic graph with properties
similar to daily rhythm of network flow data, we injected a small star anomaly onto a set of vertices that are in what
one could consider the core of the graph, i.e., vertices that are in the giant component for all time steps. We showed
that when comparing the DLC and nDLC of vertices in 𝐺𝑡 +1 + A to both 𝐺𝑡 +1 and 𝐺𝑡 those vertices participating in
the anomaly were more perturbed than their “cohort” vertices (those vertices having roughly the same centrality
score in 𝐺𝑡 ). This difference was more pronounced for nDLC than DLC, but still visually evident in both. Given this
observation we hypothesize that DLC and nDLC could be used to detect an anomaly of this type by tracking cohorts
over time and identifying when vertices change cohorts.

Situational awareness comprises understanding the current posture of the network and predicting the security
states of future time points. This paper provides a tool for identifying anomalies in a network in order to assess the
current network state. While our measure does not provide a high level overview of the network’s security posture,

, Vol. 1, No. 1, Article . Publication date: March 2021.

−0.2−0.10.00.10.20.30.40.5(Gt+1+A)−Gt+1024681012ProbabilityDensityLeavesLeavesCohortRootRootCohort−1.00−0.75−0.50−0.250.000.250.500.751.00(Gt+1+A)−Gt+10.00.20.40.60.81.0CummulativeDensityLeavesLeavesCohortRootRootCohort−1.00−0.75−0.50−0.250.000.250.500.751.00(Gt+1+A)−Gt01234567ProbabilityDensityLeavesLeavesCohortRootRootCohort−1.00−0.75−0.50−0.250.000.250.500.751.00(Gt+1+A)−Gt0.00.20.40.60.81.0CummulativeDensityLeavesLeavesCohortRootRootCohortDirectional Laplacian Centrality for Cyber Situational Awareness

•

23

(a) Kernel Density Estimate for the distribution of the gap
between the scores with and without the injected anomaly.

(b) Kernel Density Estimate for cumulative density func-
tion for the gap between the scores with and without the
injected anomaly.

(c) Kernel Density Estimate for the distribution of the gap
between the scores with the injected anomaly and the
score in previous time step.

(d) Kernel Density Estimate for the cumulative density
function of the gap between the scores with the injected
anomaly and the score in previous time step.

Fig. 15. ¯5- nDLC

the ability of these measures to point to even small anomalies may aid operators in preventing those from becoming
large anomalies.

Acknowledgements. The authors would like to thank Helen Jenne for helpful discussions. PNNL Information

Release PNNL-SA-155008.

REFERENCES
[1] Sinan G. Aksoy, Helen Jenne, Emilie Purvine, and Stephen J. Young. Rapid generation and parameter recovery of correlated temporal graphs,

in preparation.

[2] David Aldous and James Fill. Reversible markov chains and random walks on graphs, 1995.
[3] Noga Alon, Fan RK Chung, and Ronald L Graham. Routing permutations on graphs via matchings. SIAM journal on discrete mathematics,

7(3):513–530, 1994.

[4] Brett W. Bader, Michael W. Berry, and Murray Browne. Discussion Tracking in Enron Email Using PARAFAC, pages 147–163. Springer London,

2008.

[5] Francis T Boesch and Helmut Prodinger. Spanning tree formulas and chebyshev polynomials. Graphs and Combinatorics, 2(1):191–200, 1986.
[6] John Adrian Bondy, Uppaluri Siva Ramachandra Murty, et al. Graph theory with applications, volume 290. Macmillan London, 1976.
[7] Anurat Chapanond, Mukkai S. Krishnamoorthy, and Bülent Yener. Graph theoretic and spectral analysis of enron email data. Computational

& Mathematical Organization Theory, 11(3):265–281, 2005.

[8] Fan Chung. Spectral graph theory. Number 92. American Mathematical Soc., 1997.

, Vol. 1, No. 1, Article . Publication date: March 2021.

−0.2−0.10.00.10.20.30.40.5(Gt+1+A)−Gt+1024681012ProbabilityDensityLeavesLeavesCohortRootRootCohort−1.00−0.75−0.50−0.250.000.250.500.751.00(Gt+1+A)−Gt+10.00.20.40.60.81.0CummulativeDensityLeavesLeavesCohortRootRootCohort−1.00−0.75−0.50−0.250.000.250.500.751.00(Gt+1+A)−Gt0.00.51.01.52.02.53.0ProbabilityDensityLeavesLeavesCohortRootRootCohort−1.00−0.75−0.50−0.250.000.250.500.751.00(Gt+1+A)−Gt0.00.20.40.60.81.0CummulativeDensityLeavesLeavesCohortRootRootCohort24

• Sinan G. Aksoy, Emilie Purvine, and Stephen J. Young

[9] Fan Chung and Ron Graham. Quasi-random graphs with given degree sequences. Random Structures & Algorithms, 32(1):1–19, 2008.
[10] Fan Chung and Ronald Graham. Sparse quasi-random graphs. Combinatorica, 22(2):217–244, 2002.
[11] Fan Chung and Linyuan Lu. The average distances in random graphs with given expected degrees. Proceedings of the National Academy of

Sciences, 99(25):15879–15882, 2002.

[12] Fan Chung and Linyuan Lu. The average distances in random graphs with given expected degrees. In Internet Mathematics, volume 1, pages

91–113, 2004.

[13] Fan Chung, Linyuan Lu, and Van Vu. Eigenvalues of random power law graphs. Ann. Comb., 7(1):21–33, 2003.
[14] Fan Chung, Linyuan Lu, and Van Vu. Spectra of random graphs with given expected degrees. Proceedings of the National Academy of Sciences,

100(11):6313–6318, 2003.

[15] Fan Chung, Linyuan Lu, and Van Vu. The spectra of random graphs with given expected degrees. Internet Math., 1(3):257–275, 2004.
[16] Fan R. K. Chung, Ronald L. Graham, and Richard M. Wilson. Quasi-random graphs. Combinatorica, 9(4):345–362, 1989.
[17] Fan RK Chung. Diameters and eigenvalues. Journal of the American Mathematical Society, 2(2):187–196, 1989.
[18] FRK Chung, RL Graham, and RM Wilson. Quasi-random graphs. Proceedings of the National Academy of Sciences, 85(4):969–970, 1988.
[19] Kimberly C. Claffy, H-W Braun, and George C. Polyzos. A parameterizable methodology for internet traffic flow profiling. IEEE Journal on

selected areas in communications, 13(8):1481–1494, 1995.

[20] Kinkar Ch Das and RB Bapat. A sharp upper bound on the largest laplacian eigenvalue of weighted graphs. Linear algebra and its applications,

409:153–165, 2005.

[21] J. Diesner and K. M. Carley. Exploration of Communication Networks from the Enron Email Corpus. Proceedings of Workshop on Link Analysis,

Counterterrorism and Security, SIAM International Conference on Data Mining 2005, pages 3–14, 2005.

[22] Mica R Endsley. Toward a theory of situation awareness in dynamic systems. Human factors, 37(1):32–64, 1995.
[23] Miroslav Fiedler. A property of eigenvectors of nonnegative symmetric matrices and its application to graph theory. Czechoslovak Mathematical

Journal, 25(4):619–633, 1975.

[24] Chris D Godsil and Mike W Newman. Eigenvalue bounds for independent sets. Journal of Combinatorial Theory, Series B, 98(4):721–734, 2008.
[25] Aric Hagberg, Nathan Lemons, and Sidhant Misra. Temporal reachability in dynamic networks. In Dynamic Networks and Cyber-Security,

pages 181–208. World Scientific, 2016.

[26] Rick Hofstede, Pavel Čeleda, Brian Trammell, Idilio Drago, Ramin Sadre, Anna Sperotto, and Aiko Pras. Flow monitoring explained: From

packet capture to data analysis with netflow and ipfix. IEEE Communications Surveys & Tutorials, 16(4):2037–2064, 2014.

[27] Sushil Jajodia, Peng Liu, Vipin Swarup, and Cliff Wang. Cyber situational awareness. Springer, 2009.
[28] T. Jirsik and P. Celeda. Cyber Situation Awareness via IP Flow Monitoring. In NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management

Symposium, pages 1–6, April 2020. ISSN: 2374-9709.

[29] Alexander D. Kent. User-computer authentication associations in time. Los Alamos National Laboratory, 2014.
[30] Alexander D. Kent. Comprehensive, Multi-Source Cyber-Security Events. Los Alamos National Laboratory, 2015.
[31] Alexander D. Kent. Cybersecurity Data Sources for Dynamic Network Research. In Dynamic Networks in Cybersecurity. Imperial College

Press, June 2015.

[32] Bryan Klimt and Yiming Yang. The Enron corpus: A new dataset for email classification research. In Jean-François Boulicaut, Floriana

Esposito, Fosca Giannotti, and Dino Pedreschi, editors, Machine Learning: ECML, pages 217–226, 2004.

[33] Donald Ervin Knuth. The Stanford GraphBase: a platform for combinatorial computing. AcM Press New York, New York, 1993.
[34] Jure Leskovec, Kevin J. Lang, Anirban Dasgupta, and Michael W. Mahoney. Community structure in large networks: Natural cluster sizes and

the absence of large well-defined clusters. Internet Mathematics, 6(1):20–123, 2010.

[35] Jan R. Magnus. On differentiating eigenvalues and eigenvectors. Econometric Theory, 1:179–191, 1985.
[36] Brendan D. McKay. The expected eigenvalue distribution of a large regular graph. Linear Algebra Appl., 40:203–216, 1981.
[37] Bojan Mohar. Eigenvalues, diameter, and mean distance in graphs. Graphs and combinatorics, 7(1):53–64, 1991.
[38] Nour Moustafa, Jiankun Hu, and Jill Slay. A holistic review of network anomaly detection systems: A comprehensive survey. Journal of

Network and Computer Applications, 128:33–55, 2019.

[39] Ido Nevat, Dinil Mon Divakaran, Sai Ganesh Nagarajan, Pengfei Zhang, Le Su, Li Ling Ko, and Vrizlynn LL Thing. Anomaly detection and

attribution in networks with temporally correlated traffic. IEEE/ACM Transactions on Networking, 26(1):131–144, 2017.

[40] Mark EJ Newman. Finding community structure in networks using the eigenvectors of matrices. Physical review E, 74(3):036104, 2006.
[41] Nikolaos Pitropakis, Emmanouil Panaousis, Alkiviadis Giannakoulias, George Kalpakis, Rodrigo Diaz Rodriguez, and Panayiotis Sarigiannidis.
An enhanced cyber attack attribution framework. In International Conference on Trust and Privacy in Digital Business, pages 213–228. Springer,
2018.

[42] Carey E. Priebe, John M. Conroy, David J. Marchette, and Youngser Park. Scan statistics on enron graphs. Computational & Mathematical

Organization Theory, 11(3):229–247, 2005.

[43] Xingqin Qi, Eddie Fuller, Qin Wu, Yezhou Wu, and Cun-Quan Zhang. Laplacian centrality: A new centrality measure for weighted networks.

Information Sciences, 194:240–253, 2012.

[44] Jitesh Shetty and Jafar Adibi. Discovering important nodes through graph entropy the case of enron email database. In Proceedings of the 3rd

international workshop on Link discovery, pages 74–81, 2005.

[45] Terence Tao and Van Vu. Random matrices: the circular law. Communications in Contemporary Mathematics, 10(02):261–307, 2008.
[46] Linh V. Tran, Van H. Vu, and Ke Wang. Sparse random graphs: eigenvalues and eigenvectors. Random Structures Algorithms, 42(1):110–134,

2013.

[47] Melissa J. M. Turcotte, Alexander D. Kent, and Curtis Hash. Unified Host and Network Data Set, chapter Chapter 1, pages 1–22. World Scientific,

nov 2018.

[48] Eugene P. Wigner. Characteristic vectors of bordered matrices with infinite dimensions. Annals of Mathematics, 62(3):548–564, 1955.

, Vol. 1, No. 1, Article . Publication date: March 2021.

Directional Laplacian Centrality for Cyber Situational Awareness

•

25

[49] Eugene P. Wigner. On the distribution of the roots of certain symmetric matrices. Annals of Mathematics, 67(2):325–327, 1958.
[50] Eugene P Wigner. Characteristic vectors of bordered matrices with infinite dimensions i. In The Collected Works of Eugene Paul Wigner, pages

524–540. Springer, 1993.

[51] Eugene P Wigner. Characteristic vectors of bordered matrices with infinite dimensions ii. In The Collected Works of Eugene Paul Wigner,

pages 541–545. Springer, 1993.

[52] Herbert S Wilf. The eigenvalues of a graph and its chromatic number. J. London Math. Soc, 42(1967):330, 1967.
[53] Wayne W Zachary. An information flow model for conflict and fission in small groups. Journal of anthropological research, 33(4):452–473,

1977.

, Vol. 1, No. 1, Article . Publication date: March 2021.

