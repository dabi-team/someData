DRAFT

1

Blockchain-based Collaborated Federated Learning
for Improved Security, Privacy and Reliability

Amir Afaq1, Zeeshan Ahmed1 ID ,Noman Haider2 ID , Muhammad Imran1 ID
1 School of Engineering, Information Technology and Physical Sciences, Federation University, Brisbane, Australia.
2 College of Engineering and Science, Victoria University, Sydney, NSW, 2000, Australia.
Email: {zeeshanahmed, noman90, dr.m.imran}@ieee.org

2
2
0
2

n
a
J

1
2

]

R
C
.
s
c
[

1
v
1
5
5
8
0
.
1
0
2
2
:
v
i
X
r
a

Abstract—Federated Learning (FL) provides privacy
preservation by allowing the model training at edge devices
without the need of sending the data from edge to central-
ized server. FL has distributed the implementation of ML.
Another variant of FL which is well suited for the Internet
of Things (IoT) is known as Collaborated Federated Learn-
ing (CFL), which does not require an edge device to have a
direct link to the model aggregator. Instead, the devices can
connect to the central model aggregator via other devices
using them as relays. Although, FL and CFL protect
the privacy of edge devices but raises security challenges
for a centralized server that performs model aggregation.
The centralized server is prone to malfunction, backdoor
attacks, model corruption, adversarial attacks and external
attacks. Moreover, edge device to centralized server data
exchange is not required in FL and CFL, but model
parameters are sent from the model aggregator (global
model) to edge devices (local model), which is still prone
to cyber-attacks. These security and privacy concerns can
be potentially addressed by Blockchain technology. The
blockchain is a decentralized and consensus-based chain
where devices can share consensus ledgers with increased
reliability and security, thus signiﬁcantly reducing the
cyberattacks on an exchange of information. In this work,
we will investigate the efﬁcacy of blockchain-based de-
centralized exchange of model parameters and relevant
information among edge devices and from a centralized
server to edge devices. Moreover, we will be conducting the
feasibility analysis for blockchain-based CFL models for
different application scenarios like the internet of vehicles,
and the internet of things. The proposed study aims to
improve the security, reliability and privacy preservation
by the use of blockchain-powered CFL.

Index Terms—Blockchain, federated learning, decen-
tralized learning, collaborated federated learning, pri-
vacy, security, model poisoning, backdoor attacks, privacy-
preservation, model corruption.

I. INTRODUCTION

The recent technological advancements in informa-
tion and communication technologies have completely
transformed every human life, however, this growth has
also raised some serious security and privacy challenges.

Machine Learning (ML) is envisioned to be a promising
solution to address the security and privacy challenges
and vulnerabilities in the existing and future digital
infrastructure. Moreover, the changing landscape of in-
formation and communication systems (ICS) has brought
forth unique security, privacy and reliability challenges
[1]. For instance, because of COVID-19, there has been
600 % increase in cybercrime where complex phishing
attacks have been used and many have fallen victim to it
[2]. The malware attacks have seen tremendous growth in
last ten years along with 812.67 million malware attacks
in 2018 alone. Same is the case with the malware attacks
which rose 350% in 2018 worldwide [2]. Hence, our ICS
are more prone to cyber attacks than ever. Malicious
actors also are using machine-powered sophisticated
attacks to beat
the defense mechanism in place and
any such breaches have proven to be catastrophic for
the victim network. Moreover, the privacy concerns are
also ever-high because of data breaches, theft and data
leaks at top-tier digital media companies. Many of such
breaches resulted into sever consequences and proven to
be fatal as well in some cases like Ashley Madison data
breach and cyber attacks on hospitals [3].

A. Machine learning for Security

The recent advancement in artiﬁcial intelligence (AI)
and Machine Learning (ML) has the capability protect
the digital infrastructure against sophisticated and ever-
evolving cyber attacks [4]. Because of robust, dynamic
and real-time adaptive nature of ML models, they are
well-suited as counter-measures for machine-powered
attacks from threat actors. The AI and ML has open
gateways in the domains of security, privacy,
threat
detection for ICS and helped in developing effective
methods for the protection of ICS. The concept of using
ML and AI in security and privacy is not new but the
importance of these ML and AI methods have been
highlighted by the evolution of deep learning algorithms.
Most of the methods before the development of deep

 
 
 
 
 
 
DRAFT

2

of implementation, the central controller than sends the
model to the edge devices for implementation. There are
multiple security and privacy issues with centralized ML
implementation,

1) The private data of edge devices can be very sen-
sitive and prone to theft during the transmission.
Especially, data-sensitive applications and use cases
like IoHTs and IoTs may have serious privacy
concerns.

2) The trained ML model can be intercepted and mod-
iﬁed during the transmission from central server
to the edge devices. Such malicious attack may
cause severe consequences as the edge devices
may not even detect that the ML model has been
compromised.

3) The ML model in itself is pron adversarial type
attacks and the compromised data can be fed when
intercepted during transmission from edge devices
to corrupt the ML model.

4) The central model could also also be a single point
of failure and attacking, risking the entire system.
5) Another concern for resource-constrained edge de-
vices in IoT, and IoHTs setups is that it will be
challenging to transmit
their data while having
limited battery powers.

Although centralized ML has privacy issues, but it is
well-suit for private environments where entire end-to-
end communication link is protected. The centralized
ML model implementation scenario and exchange of
data and model parameters along with their privacy

learning were dedicated to model the attack patterns with
certain characteristic which are not robust in nature, but
with AI and ML, it is expected that systems will become
more resilient towards new sophisticated attacks with
changing characteristics [5].

The ML is showing the positive impact in information
security ﬁeld by adopting ML algorithms to address the
security and privacy issues. The information security
industry is generating more and more data which open
them to advance threats and AI could be a powerful an-
tidote for these threats. The ﬁrst generation of ML solu-
tions are focused on scrutinizing data, detect threats and
assist human in remediation plan. The second generation
of ML solution will make the systems more autonomous
and leave the critical support issues to humans. There
have been different types of ML model implementations
based on where the model will be trained and deployed.
This seggregation is evolved because of the privacy
issues when transferring ML model or its parameters
and training data between the central ML model and
edge devices. The edge devices can be of different types.
For instance, the most resource constrained yet high in
number are Internet of Things (IoTs). Similarly, the ML
models may also need to communicate with other use
cases like Internet of Health Things (IoHTs), Internet of
Vehicles (IoVs), Industrial Internet of Things (IIoTs) and
Unmanned Air Vehicles (UAVs). Based on how the ML
model is implemented and information is communicated
between ML controllers and edge devices, different
ML implementation types are explained in next section
along with privacy and security issues raising from these
implementations.

II. MACHINE LEARNING IMPLEMENTATION TYPES

The ML models can be implemented in different
ways. Among these include centralized implementation
of global ML models, and distributed implementation of
ML known as Federated Learning (FL). There is also
Collaborated FL which does not require a direction link
between the edge devices and central model aggregator.
In this section, we will explain these three types of
implementation, security and privacy concerns in these
implementations.

A. Centralized ML

the model

In this type of ML implementation,

is
selected at centralizer ML server and all the edge de-
vices need to transmit their private data to the central
server for ML model training. The central server and
controller trains the ML model from the data sent by
the edge devices. Once the model is trained and ready

Fig. 1. Centralized machine learning model implementation from
central controller to edge devices and the possible vulnerabilities.

Central ControllerModel selection and initial trainingCentralized ML ServerPrivate data from edgeto central controller1. Centralized controller has mainML model for all edge devices.2. Edge devices transmit their data tocentral controller for model training.3. Central controller trains the modeland finds global optimal solution.4. Sends the trained model to edgedevices.Trained global MLmodel to edge devicesPrivacy issues, malicious data, datacorruption, MiTM attacks, data theftCentral controllervulnerabilities,attacks andcompromises.Model theft,modification andcompromiseDRAFT

3

issues is highlighted in Fig. 1. More detailed insights
on threat surface and attack scope in different parts of
ML architecture can be found in [6]. Because of the
privacy issues in centralized ML implementation, Google
proposed an idea of distributed implementations of ML
model known as Federated Learning (FL) [7].

B. Federated Learning

The FL is a distributed implementation of central-
ized ML. The primary advantage of FL is privacy-
preservation for edge devices because edge devices does
not have to transmit their private data to central con-
troller. The edge devices have their own local ML model
while global ML model resides in central controller.
Edge devices use their private data and train their local
model and then send their model parameters to the
central controller which then develops aggregated ML
model (shared optimal solution) from all of the received
models from the edge. The aggregated model is ﬁnalized
at the central controller and model updates along with
the model parameters are sent to the edge devices. Edge
devices can also request for the updates from the central
controller. Hence, this type of distributed ML model
implementation preserves the privacy of private data of
edge devices as they don’t need to transmit it to the
central controller [8]. Moreover, this also signiﬁcantly
reduces the network bandwidth which is consumed for
the transmission of private data from edge to ML server.
This reduces the data theft and associated risks for edge
devices. The FL architecture along with its advantages
and security issues is presented in Fig. 2.

C. Collaborated Federated Learning

In FL, all the edge devices need to have a link or
connection with the central controller. This may not
be possible for some devices in remote locations or
for the devices relying on the sink or relays for their
data transmission. Authors in [9] proposed concept of
collaborated FL (CFL) in wireless networks where edge
devices can collaborate with one-another and use them
as relays to forward their model updates, trained models
and communication with the model aggregate. This CFL
extends the distributed ML for remote devices which do
not have a direct connection with the model aggregator.
The CFL has more practical applications and extends the
privacy-related beneﬁts of ML by making it scalable. The
working mechanism of CFL is presented in Fig. 3.

D. Security and privacy issues in FL and CFL

The FL and CFL improves the privacy related issues
and extends the advantages of ML modelling to the edge.

Fig. 2. The distributed implementation of ML model using FL along
with its privacy advantages and risks.

Fig. 3. The collaborated federated learning model.

The private data is protected for the edge device as
they don’t need to transmit it, however the ML model
parameters are still being exchanged between model
aggregator and edge devices. If this exchange is not
secure, consensus-based, and fully secure, then this could
still be a major security and privacy risk. The man-in-
the-middle could still modify the model exchange pa-
rameters, hence making the FL and CFL implementation
prone to an external attacks. Hence, there should be a
secure, decentralized and consensus-based ML model

Central ControllerAggregated/Global ML modelFederated ML ServerTrained local MLmodels to aggregator1. Edge devices use local data totrain local ML models at edge.2. Edge devices transmit their trainedlocal models to central controller.3. Central controller aggregates thereceived local ML models andgenerated a new aggregated model.4. Aggregated model is sent to edgedevices.Aggregated ML modelto edge devicesLocal ML modelsVulnerabilities- Attacks during local andaggregated modeltransmission- Server malfunction  &attacks- Supply chain attacks- External attacks- Information modificationattacksAdvantages- Privacy-preservation- Private data protection- Reduced risk of datacompromiseCentral ControllerAggregated/Global ML modelCollaborated Federated LearningTrained local MLmodels to aggregator1. Edge devices use local data totrain local ML models at edge.2. Edge devices transmit their trainedlocal models to central controller.3. Central controller aggregates thereceived local ML models andgenerated a new aggregated model.4. Aggregated model is sent to edgedevices.Aggregated ML modelto edge devicesLocal ML models5. Edge devices collaborate to relay their local ML models and receiveaggregated model. No direct link to aggregated server needed.DRAFT

4

Fig. 4. Decentralized and distributed blockchain mechanism which uses chain of blocks shared among all the participating devices.

sharing mechanism which should be trusted by all the
devices is needed.

III. BLOCKCHAIN

Blockchain is a decentralized, secure and consensus
based information sharing technology which comes with
its inherent security and privacy beneﬁts. Devices in
blockchain use blocks to add new transactions and share
it with other peers using blocks or ledgers, hence all
known as distributed ledger technologies (DLT). All the
devices in peer-to-peer (P2P) distributed networks are
able to verify the integrity of blocks and transactions.
Each and every block is securely connected with it’s
previous and next blocks with strong cryptographic chain
the devices using the
which can be veriﬁed by all
blockchain. Hence, making it very secure and hard to
tamper with as multiple devices have accurate records
of block and tampered blocks can easily be identiﬁed
and removed by consensus mechanism. The realization
of blockchain mechanism is shown in Fig. 4.

Blockchain technology has proven to be potential
candidate in privacy-sensitive applications [10]. Based
on access to certain blockchain network, applications of
block chain can mainly be categorized in to public, and
private blockchains. Some of the important performance
and security advantages of using blockchain are shown
in Fig. 5.

IV. BLOCKCHAIN POWERED FL

CFL can potentially be addressed by using blockchain
consensus based mechanism. Devices in private network
implementing their local ML models with model updates
from global ML model can use blockchain DLT to
strengthen the privacy against external attacks. Block
chain for FL has been considered a reliable, safe and
secure mechanism for devices to share the ML model up-
dates and parameters [11]. On-device blockchain based
federated learning model (BlockFL) has been studied in
the literature [12]. Blockchain powered FL (BlockFL)
can also be used for secure information sharing among
IoVs [13], [14].

V. RESEARCH CHALLENGES

Most of the existing works in the literature have con-
sidered BlockFL for privacy-preservation in consensus
based data sharing applications. To the best of our knowl-
edge, none of the existing works are using BlockFL for
detection, investigation, and analysis of model-poisoning
attacks, and backdoor attacks. In this proposed research
study, we want to investigate the feasibility of BlockFl
for,

1) Detection, investigation and analysis of malicious

ML model updates.

2) Design and modelling of cyber risk assessment
based on different types of adversarial, backdoor
and model poisoning attacks.

3) Reliability and latency analysis of using blockchain.
4) Customized and on-demand data aggregation and

The security and privacy challenges related to ML
model updates, request and data sharing in FL and

protection strategy.

5) Different use-cases and applications.

Node 1Node 2Node 5Node 4Node 3Node 6Node 7Node 8New register#Previous hash#Block n+1New register#Previous hash#Block n+2New register#Previous hash#Block n+3New register#Previous hash#Block n+4New register#Previous hash#Block n+5New register#Previous hash#Block n+6New register#Previous hash#Block n+7New register#Previous hash#Block n+4Decentralized, secure, encrypted, consensus blockchainDecentralized, secure, encrypted, consensus blockchainDRAFT

5

Fig. 5. Advantages of using blockchain.

A. Blockchain powered CFL

Based on the research gap we have identiﬁed, we will
be investigating the use of blockchain for collaborated
FL. To the best of our knowledge, none of the existing
works use BlockCFL mechanism for model updates
among the edge devices. Considering the scalability of
CFL and more wider range of possible application, using
blockchain for model updates is expected to open some
more future research directions.

VI. CONCLUSION AND FUTURE WORK

In this work, we have studied the blockchain and
federated machine learning for safe, secure and reliable
data transfer. Based on our research, we have identiﬁed
that blockchain can complement the performance advan-
tages of collaborated federated learning and could open
new research directions for the future. In the proposed
research work, we intend to use block chain for CFL
(BlockCFL) and study it’s performance advantages in
the context of security, reliability and privacy. Moreover,
in future work, we are also working on developing the
taxanomy of the existing works and their performance
advantages and shortcomings.

REFERENCES

[1] R. Tourani, S. Misra, T. Mick, and G. Panwar, “Security,
privacy, and access control in information-centric networking:
A survey,” IEEE communications surveys & tutorials, vol. 20,
no. 1, pp. 566–600, 2017.

[2] “2021 cyber security statistics.” https://purplesec.us/resources/

cyber-security-statistics/. Accessed: 2021-05-07.

[3] J. A. Lewis, Assessing the risks of cyber terrorism, cyber war
and other cyber threats. Center for Strategic & International
Studies Washington, DC, 2002.

[4] T. C. Truong, I. Zelinka, J. Plucar, M. ˇCand´ık, and V. ˇSulc,
“Artiﬁcial intelligence and cybersecurity: Past, presence, and fu-
ture,” in Artiﬁcial Intelligence and Evolutionary Computations
in Engineering Systems, pp. 351–363, Springer, 2020.

[5] R. Calderon, “The beneﬁts of artiﬁcial intelligence in cyberse-

curity,” Economic Crime Forensics Capstones, vol. 36, 2019.

[6] N. Papernot, P. McDaniel, A. Sinha, and M. Wellman, “Towards
the science of security and privacy in machine learning,” arXiv
preprint arXiv:1611.03814, 2016.

[7] K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Inger-
man, V. Ivanov, C. Kiddon, J. Koneˇcn`y, S. Mazzocchi, H. B.
McMahan, et al., “Towards federated learning at scale: System
design,” arXiv preprint arXiv:1902.01046, 2019.

[8] Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine
learning: Concept and applications,” ACM Transactions on
Intelligent Systems and Technology (TIST), vol. 10, no. 2, pp. 1–
19, 2019.

[9] M. Chen, H. V. Poor, W. Saad, and S. Cui, “Wireless commu-
nications for collaborative federated learning,” IEEE Communi-
cations Magazine, vol. 58, no. 12, pp. 48–54, 2020.

[10] A. Dorri, S. S. Kanhere, R. Jurdak, and P. Gauravaram,
“Blockchain for iot security and privacy: The case study of
a smart home,” in 2017 IEEE international conference on
pervasive computing and communications workshops (PerCom
workshops), pp. 618–623, IEEE, 2017.

[11] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang,
“Blockchain and federated learning for privacy-preserved data
iot,” IEEE Transactions on Industrial
sharing in industrial
Informatics, vol. 16, no. 6, pp. 4177–4186, 2019.

[12] H. Kim, J. Park, M. Bennis, and S.-L. Kim, “Blockchained
on-device federated learning,” IEEE Communications Letters,
vol. 24, no. 6, pp. 1279–1283, 2019.

[13] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang,
“Blockchain empowered asynchronous federated learning for
secure data sharing in internet of vehicles,” IEEE Transactions
on Vehicular Technology, vol. 69, no. 4, pp. 4298–4311, 2020.
[14] S. R. Pokhrel and J. Choi, “Federated learning with blockchain
for autonomous vehicles: Analysis and design challenges,”
IEEE Transactions on Communications, vol. 68, no. 8,
pp. 4734–4746, 2020.

 •More secure then traditional methodsImproved level of Security•Low risk of hacking•Hard to tamper blocksData Integrity•Consensus based transaction verificationTrusted Transaction•Decentralised approach•No single point of attackNO SINGLE POINT FAILURE•No server maintainance•Distributed resource usageReduced Cost•Inheretance structure•History of transactionsTraceability