Interdependent Strategic Security Risk Management
with Bounded Rationality in the Internet of Things

Juntao Chen Student Member, IEEE, and Quanyan Zhu Member, IEEE

9
1
0
2

y
a
M
2
2

]
T
G
.
s
c
[

1
v
1
4
3
9
0
.
5
0
9
1
:
v
i
X
r
a

Abstract—With the increasing connectivity enabled by the
Internet of Things (IoT), security becomes a critical concern,
and the users should invest to secure their IoT applications.
Due to the massive devices in the IoT network, users cannot
be aware of the security policies taken by all
its connected
neighbors. Instead, a user makes security decisions based on
the cyber risks he perceives by observing a selected number
of nodes. To this end, we propose a model which incorporates
the limited attention or bounded rationality nature of players
in the IoT. Speciﬁcally, each individual builds a sparse cognitive
network of nodes to respond to. Based on this simpliﬁed cognitive
network representation, each user then determines his security
management policy by minimizing his own real-world security
cost. The bounded rational decision-makings of players and their
cognitive network formations are interdependent and thus should
be addressed in a holistic manner. We establish a games-in-
games framework and propose a Gestalt Nash equilibrium (GNE)
solution concept to characterize the decisions of agents, and
quantify their risk of bounded perception due to the limited
attention. In addition, we design a proximal-based iterative
algorithm to compute the GNE. With case studies of smart
communities, the designed algorithm can successfully identify
the critical users whose decisions need to be taken into account
by the other users during the security management.

Index Terms—Risk management, bounded rationality, cogni-

tive networks, Internet of Things, smart community

I. INTRODUCTION

Recent years have witnessed a signiﬁcant growth of urban
population. As the growth continues, cities need to become
more efﬁcient to serve the surging population. To achieve this
objective, cities need to become smarter with the integration of
information and communication techniques (ICTs) and urban
infrastructures. Driven by the advances in sensing, computing,
storage and cloud technologies, the Internet of Things (IoT)
plays a central role in supporting the development of smart
city. Though IoT enables a highly connected world, the secu-
rity of IoT becomes a critical concern. There are 5.5 million
new things connected every day in 2016, as we head toward
more than 20 billion by 2020 [1]. These IoT devices come
from different manufacturers, and they have heterogeneous
functionalities and security conﬁgurations and policies. No
uniform security standards are used for IoT devices as they
are developed using different system platforms for various
functionalities. Moreover, due to the connections between
IoT devices, the security of one device is also dependent on

This work was supported in part by the National Science Foundation awards
SES-1541164, ECCS-1847056, ARO grant W911NF1910041, and a grant
through the Critical Infrastructure Resilience Institute (CIRI).

The authors are with the Department of Electrical and Computer Engi-
neering, Tandon School of Engineering, New York University, Brooklyn, NY
11201 USA (E-mail:{jc6412,qz494}@nyu.edu).

Fig. 1.
IoT-enabled interconnected smart community. The connectivity, on
one hand, enhances the situational awareness of smart homes. However, it
increses the cyber risks of the community. Hence, the cyber security of each
household not only dependents on its own risk management strategy but also
the ones of connected neighbors.

the security of other devices to which it connects. There-
fore, the heterogeneity and the interconnectivity of massive
heterogeneous IoT have created signiﬁcant challenges for
security management. Fig. 1 depicts a highly connected smart
community enabled by IoT devices. Each household needs to
take into account the cyber risks coming from their connected
neighbors when securing their devices.

In cyber networks, security management and practices of
users are often viewed as the weakest link [2]. The lack of
security awareness and expertise at the user’s end creates
human-induced vulnerabilities that can be easily exploited
by an adversary, exacerbating the insecurity of IoT. To this
end, it is critical to enhance the security by strengthening
security management in a decentralized way. Hence, in the
IoT, each device owner or system manager needs to allocate
resources (e.g. human resources, computing resources, invest-
ments or cognition) to secure his applications. For example,
the smart building operator can spend resources on upgrading
the hardware, hiring staff members for network monitoring
and forensics, and developing tailored security solutions to
the smart building. A smart home user, on the other hand, can
safely conﬁgure its network and regularly updates its software
and password of the IoT devices as illustrated in Fig. 1.

The devices in the IoT networks and their interconnections
can be modeled as nodes and links, respectively. The security
policy of one device can have an impact on the security
risk of nodes that are connected to it. Since various users
in IoT is
own different devices,

the security management

Smart and connected community 
 
 
 
 
 
decentralized in nature. Therefore, the process of decentralized
security decision-making can be modeled as a game problem
in which each user strategically allocates his resources to
secure the devices [3]. In this game,
the users’ risks are
reduced when their connected neighbors are of high-level
security. Due to the complex and massive connections, users
its
cannot be aware of the security policies taken by all
connected neighbors. Instead, a user can only make security
decisions based on the cyber risk he perceives by observing
a selected number of nodes. This fact indicates that the game
model needs to take into account the bounded rationality of
players [4]. Therefore, in the game framework, we use a
cognition vector representing the observation structure of each
IoT user. Speciﬁcally, a sparser cognition vector represents a
user with weaker cognition ability, and he observes a smaller
number of other users’ behaviors when deciding his strategy.
Thus, the limited attention nature of users creates a bounded
perception of cyber risks.

In the established bounded rational game model, the users
need to make security management decisions as well as design
their cognition networks in a holistic manner. In order to
achieve this goal, we deﬁne a new solution concept called
Gestalt Nash equilibrium (GNE) to capture the cognitive
network formation and the security management under the
bounded rationality simultaneously. The analysis of the GNE
provides a quantitative method to understand the risk of mas-
sive IoTs and gives tractable security management policies.
We further design a proximal-based iterative algorithm to
compute the GNE of the game. The GNE resulting from
the algorithm reveals several typical phenomena that match
well with the real-world observations. For example, when the
network contains two groups of users, then under the limited
attention, all users will allocate their cognition resources to
the same group which demonstrates the law of partisanship.
Further,
the equilibrium
successfully identiﬁes the set of agents that are invariably paid
attention to by other users, demonstrating the phenomenon
of attraction of the mighty. Since the framework predicts the
high-level systemic risk of the IoT network, it also can be
used to inform the design of security standards and incentive
mechanisms, e.g., through contracts and cyber insurance.

in a heterogeneous massive IoT,

The developed security management model provides an
essential framework to assess IoT security risks when applied
to various applications. For example, in smart home commu-
nities, the households are connected together to share hetero-
geneous information, e.g., electricity prices and temperature
readings through smart meters, and real-time information of
items in local stores and shops by wireless sensors. The con-
nections of IoT devices thus create security interdependencies
between households. Another broader application lies in the
different components in smart cities. Due to the interconnec-
tivity between large-scale infrastructures including the trans-
portation, power grids, and communications, the manager of
each sector needs to take into account the cyber risks coming
from other components when adopting security solutions.

The contributions of this paper are summarized as follows:
1) We propose a holistic framework to investigate the
security management of users with bounded rationality

in the IoT networks.

2) We model the cognition of users with a sparse vector
and quantify users’ risk of bounded perception resulting
from the underperceived cyber threats in the network.
3) We design a proximal-based algorithm to compute the
GNE which contains security management strategy and
cognitive network of agents. The algorithm discovers
several phenomena including emergence of partisanship,
ﬁlling the inattention, and attraction of the mighty.
4) We apply the proposed model to a smart community, and
demonstrate that the designed algorithm can identify the
most critical households in the network.

A. Related Work

Security management has been investigated in various re-
search ﬁelds including computer networks [5], communica-
tions [6], cloud computing [7] and infrastructures [8]. With the
advances in ICTs, a growing number of works have focused
on the emerging critical issue of IoT security [9], [10]. Due
to the interconnectivity between different agents, the security
of one agent is also dependent on its connected ones which
gives rise to the notion of “interdependent security” [11].
The authors in [12]–[15] have further investigated the security
interdependencies in multilayer cyber-physical systems. The
authors in [16]–[18] have developed optimal contracts to
address the cyber-physical security issues in IoT. In [19]–[21],
the authors proposed optimal schemes for designing secure and
resilient multi-layer IoT networks through graph-theoretical
approaches.

Games over networks have caught a lot of attention recently
especially from the economics perspective [22]–[24]. The
couplings between players in the network can be either in
a strategic exclusive or strategic complement manner. Based
on the features of security management in IoT, our problem
falls into the latter class. For the engineering applications, the
authors in [8], [25] have studied the resource allocation game
over interdependent critical infrastructures where both players
aim to increase the connectivity of the network. Huang et.al
[26]–[29] have adopted a stochastic Markov game model to
design resilient operating strategies for multilayer networks.
Zhu et.al [30] have proposed a game-theoretic framework
for collaborative intrusion detection systems through resource
to mitigate network cyber threats. Our work
management
differs from [30] in that we take into account the cognitive
factors of human behaviors during decision making.

Humans with limited knowledge or cognitive resources are
bounded rational, since they cannot pay attention to all the
information [31], [32]. Gabaix has proposed a “sparse max”
operator to model the limited attention of players in which
each agent builds a simpliﬁed model of the network based
on an l1 norm [4]. Built upon [33] which includes some
preliminary results, our work leverages on the established
“sparse max” operator and formulates a constrained game
program to capture the bounded cognition ability of players in
the IoT. In addition, we further consider the risk management
of each user based on their underperceived cyber risks over
the network.

TABLE I
NOMENCLATURE

N := {1, 2, ..., N}, set of players/users
security investment cost coefﬁcient of player i

security investment inﬂuence coefﬁcient of player j on player i

unit return of security investment of player i
r := [r1, r2, ..., rN ]
security investment decision of player i
u := [u1, u2, ..., uN ]
set of decisions of all players except i-th one

set of decisions of all players
j] j(cid:54)=i, j∈N , mi
mi := [mi
uci
j = mi
ju j, decision of player j perceived by player i
cost function of player i

j ∈ [0, 1], the attention network of player i

cost function of player i under bounded rationality

best response of player i
Λi := [Λi

jk] j(cid:54)=i,k(cid:54)=i, j∈N ,k∈N , Λi

jk := 1
Ri
ii

i jRi
Ri

iku juk

an N − 1-dimensional column vector with all one entries

weighting factor quantifying the unit cost of player i’s cognition

total number of links in the cognitive network of player i

standard L-1 norm

standard L-2 norm

indicator function on set C

proximal operator

N

Ri
ii
Ri
i j
ri
r

ui
u

u−i
U

mi
uci
j
Ji
˜Ji
BRi
Λi

eN−1
αi
βi
|| · ||1
|| · ||

ιC
prox·

B. Organization of the Paper

The rest of the paper is organized as follows. Section II
formulates a security management game over IoT networks
with bounded rational players. Section III analyzes the prob-
lem. Section IV designs a proximal-based iterative algorithm
to compute the GNE. Case studies are given in Section V, and
Section VI concludes the paper.

C. Summary of Notations

For convenience, we summarize the notations used in the
paper in Table I. Note that notations associated with ∗ refer
to the value at equilibrium. Furthermore, notations with index
k stands for its value at step k during the iterative updates.

II. PROBLEM FORMULATION

In this section, we formulate a problem involving strategic
security decision making and cognitive network formation of
players in the IoT networks.

A. Security Management Game over Networks

In an IoT user network including a set N of nodes1, where
N := {1, 2, ..., N}, each node can be seen as a player that
makes strategic decisions on the security management to se-
cure their IoT devices. For instance, in Fig. 1, each smart home
is a player securing their smart things to mitigate the cyber
threats. We deﬁne U := {u1, ..., uN} by the decision proﬁle of

1The terms of node, agent and player refer to the user in the IoT, and they

are used interchangeably.

all the players. Speciﬁcally, ui is a one-dimensional decision
variable representing player i’s security management effort.
For convenience, we denote u−i := U \ {ui}. The objective of
player i, i ∈ N , is to minimize his security risk strategically
1 : R+ → R+
by taking the costly action ui. We deﬁne by F i
the cost of security management effort of player i which is
an increasing function of ui. The corresponding beneﬁt of
2 : R+ → R+.
security management is captured by a function F i
Intuitively, a larger ui yields a higher return, and hence F i
2 is
monotonically increasing. Due to the interconnections in the
IoT, the risk of player i is also dependent on his connected
+ → R+ to
users. Then, we use a function F i
represent the inﬂuence of player i’s connected users on his
security. The coupling between players in the IoT is in a
to the security
strategic complement fashion with respect
decisions. More speciﬁcally, a larger security investment u j
of player j, a connected node of player i, decreases the cyber
risks of player i as well. Therefore, the cost function of player
i can be expressed as the following form:

3 : R+ × RN−1

Ji(ui, u−i) = F i

1(ui) − F i

2(ui) − F i

3(ui, u−i),

(1)

where Ji : R+ × RN−1
+ → R. To facilitate the analysis and de-
sign of security risk management strategies, we specify some
appropriate forms of functions in (1). In the following, we
1(ui) = 1
focus on player i taking the quadratic form: F i
iiu2
i ,
F i
2(ui) = riui, and F i
i juiu j. Thus, (1) can
be detailed as

3(ui, u−i) = ∑ j(cid:54)=i, j∈N Ri

2 Ri

Ji(ui, u−i) =

1
2

Ri
iiu2

i − riui − ∑

j(cid:54)=i, j∈N

Ri

i juiu j,

(2)

iiu2
i

2 Ri

ii > 0, ri > 0, ∀i, and Ri

i j ≥ 0, ∀ j (cid:54)= i, i ∈ N . Note
where Ri
i j, i, j ∈ N , represent the risk dependence
that parameters Ri
network of player i in the IoT, and the value of Ri
i j indicates
the strength of risk inﬂuence of player j on player i which
is given as a prior. The ﬁrst term 1
in (2) is the cost
of security management with an increasing marginal price.
The second term riui denotes the corresponding payoff of
cyber risk reduction. Then, the ﬁrst two terms capture the
fact that increasing a certain level of cyber security becomes
more difﬁcult in a secure network than a less secure one. The
last term ∑N
i juiu j is the aggregated security risk effect
from connected users of player i. Speciﬁcally, the structure of
F i
3 in ui and u j indicates that the risk measure Ji of player
i decreases linearly with respect to user j’s action. Hence,
in the established model, larger investment from a user helps
reduce cyber risk inﬂuence in a linear way. We have following
assumption on the security inﬂuence parameters.
ii > ∑ j(cid:54)=i, j∈N Ri

Assumption 1. Ri

i j, ∀i ∈ N .

j=1, j(cid:54)=i Ri

Assumption 1 has a natural interpretation which indicates
that the security of a user is mainly determined by his own
strategy rather than other users’ decisions in the IoT network.
Moreover, based on the heterogeneous inﬂuence networks
characterized by Assumption 1, each node designs its own
security investment strategy which enables the decentralized
decision-making. The strategies of nodes are interdependent
due to the coupling between their cost functions shown in (2).

Through the ﬁrst order optimality condition (FOC), we

obtain

Ri
iiui − ∑

j(cid:54)=i, j∈N

Ri
i ju j − ri = 0, ∀i ∈ N .

(3)

Putting (3) in a matrix form yields








R1
11
−R2
21
...
−RN

−R1
12
R2
22
...
N1 −RN
N2








· · · −R1
1N
· · · −R2
2N
...
. . .
RN
· · ·
NN








u1
u2
...
uN








=








r1
r2
...
rN








⇔ Ru = r,

The FOC of (5) gives Ri
N , which is equivalent to

iiui − ∑ j(cid:54)=i, j∈N Ri

i juci

j − ri = 0, ∀i ∈








R1
11
−m2
1R2
21
...
1 RN
−mN

−m1
2R1
12
R2
22
...
2 RN
N1 −mN
N2

· · · −m1
NR1
1N
· · · −m2
NR2
2N
...
. . .
RN
· · ·
NN









=
















u1
u2
...
uN
⇔ Rsu = r.






r1
r2
...
rN








(6)

The bounded rational best-response of player i, i ∈ N , then

(4)

becomes

where r := [ri]i∈N , u := [ui]i∈N .

For convenience, we denote this security management game
by G . One solution concept of game G is Nash equilibrium
(NE) which is deﬁned as follows.

ui = BRi(uci

−i) =

(cid:32)

1
Ri
ii

∑
j(cid:54)=i, j∈N

(cid:33)

i juci
Ri

j + ri

,

(7)

Deﬁnition 1 (Nash Equilibrium of Game G [3]). The strategy
proﬁle u∗ = [u∗
i ]i∈N constitutes a Nash equilibrium of game
−i), ∀i ∈ N , ∀ui ∈ Ui.
G if Ji(ui, u∗

−i) ≥ Ji(u∗

i , u∗

The NE of game G yields strategic security management
policies of players under the condition that they can perceive
all the cyber risks in the IoT network.

B. Bounded Rational Security Management Game

In reality, the users in IoT are connected with numerous
other agents. For example, a single household can be con-
nected with a number of other houses in terms of various
types of IoT products in the smart communities. Therefore,
when making security management strategies, each user may
not be capable to observe all its connected neighbors. Instead,
a user can only respond to a selected number of other players’
decisions. Then, this bounded rational response mechanism
creates a cognitive network formation process for the players
in the network. Speciﬁcally, player i’s irrationality is captured
by a vector mi := [mi
j ∈ [0, 1], which stands for
the attention network that player i builds. When mi
j = 0, user
i pays no attention to user j’s behavior; when mi
j = 1, user i
observes the true value of security management u j of user j.
The value that mi
j admits between 0 and 1 can be interpreted
as the trustfulness of user i on the perceived u j. Another
interpretation of mi
j can be the probability that user i observes
the behavior of user j at each time instance on the security
investment over a long period. Hence, the decision of player
j perceived by player i becomes uci
ju j. Then, player i
minimizes the modiﬁed cost function with bounded rationality
deﬁned as:

j] j(cid:54)=i, j∈N , mi

j = mi

where uci

j = mi

ju j.

We denote the security management game of players with
limited attention by ˜G . Comparing with the solution concept
NE of game G , the one of game ˜G is generalized to bounded
rational Nash equilibrium (BRNE). The formal deﬁnition of
BRNE is as follows.

Deﬁnition 2 (Bounded Rational Nash Equilibrium of Game
˜G ). With given cognition vectors mi, ∀i ∈ N ,
the strat-
˜G if
egy proﬁle u∗ = [u∗
−i, mi) ≥ ˜Ji(u∗
˜Ji(ui, u∗

i ]i∈N constitutes a BRNE of game
−i, mi), ∀i ∈ N , ∀ui ∈ Ui.
i , u∗

Note that the cognitive network each user built has an
˜G . Hence, how the users
impact on the BRNE of game
determine the cognition vector mi, i ∈ N , becomes a critical
issue. In the ensuing section, we introduce the cognitive
network formation of players in the IoT.

C. Cognitive Network Formation

Due to the massive connections in IoT, each user builds
a sparse cognitive network containing the agents to observe.
To this end, the real cost of user i by taking the bounded
rationality into account becomes

(cid:32)

1
2Ri
ii
(cid:32)

(cid:33)2

∑
j(cid:54)=i, j∈N

i juci
Ri

j + ri

(cid:33)(cid:35)

i juci
Ri

j + ri

Ji(BRi(uci

−i), u−i) =

(cid:34)

1
Ri
ii

Ri

ikuk

∑
j(cid:54)=i, j∈N
(cid:33)

∑
j(cid:54)=i, j∈N

i juci
Ri

j + ri

− ∑
k(cid:54)=i,k∈N
(cid:32)

ri
Ri
ii

˜Ji(ui, uci

−i, mi) =

=

1
2

1
2

Ri
iiu2

i − riui − ∑

j(cid:54)=i, j∈N

Ri
iiu2

i − riui − ∑

j(cid:54)=i, j∈N

mi

jRi

i juiu j

−

i juiuci
Ri
j ,

(5)

=

1
2 ∑

j(cid:54)=i, j∈N

∑
k(cid:54)=i,k∈N
(cid:32)

1
Ri
ii

Ri
i jRi

ikuci

j uci

k −

1
2Ri
ii

(ri)2

where ˜Ji : R+ × RN−1

+ × [0, 1]N−1 → R.

− ∑

k(cid:54)=i,k∈N

∑
j(cid:54)=i, j∈N

(cid:33)

uci
j Ri
i j

1
Ri
ii

Ri
ikuk − ∑

k(cid:54)=i,k∈N

1
Ri
ii

riRi

ikuk.

Incorporating the cognition vector mi into the real cost of

player i further yields

Ji(BRi(uci

−i), u−i) =
∑
k(cid:54)=i,k∈N

1
2 ∑

j(cid:54)=i, j∈N

mi
j

− ∑

k(cid:54)=i,k∈N

∑
j(cid:54)=i, j∈N

mi
j

1
Ri
ii
1
Ri
ii

i jRi
Ri

ikmi

ku juk −

1
2Ri
ii

(ri)2

i jRi
Ri

iku juk − ∑

k(cid:54)=i,k∈N

1
Ri
ii

riRi

ikuk.

(8)

Recall that each user aims to minimize the security risk
based on the risks he perceives. Thus, by considering the
real cost induced by the bounded rationality constraint, the
strategic cognitive network formation problem of player i can
be formulated as

Fig. 2.
IoT user and cognitive network-of-networks. Users make strategic
security management decisions in the IoT network as well as determine
their cognitive networks. The security management game in layer G2 and
the cognitive network formation game in layer G1 are interdependent which
create a games-of-games framework.

mi∗ = arg min

mi

j, j(cid:54)=i, j∈N

Ji(BRi(uci

−i), u−i) + αi(cid:107)mi(cid:107)1

= arg min
mi

j, j(cid:54)=i, j∈N

− ∑

j(cid:54)=i, j∈N

= arg min
mi

j, j(cid:54)=i, j∈N

1
2 ∑
j(cid:54)=i, j∈N
1
Ri
ii

∑
k(cid:54)=i,k∈N
1
2

miT

∑
k(cid:54)=i,k∈N

1
Ri
ii

i jRi
Ri

iku jukmi

jmi
k

i jRi
Ri

ikuku jmi

j + αi(cid:107)mi(cid:107)1

Λimi − eT

N−1Λimi + αi(cid:107)mi(cid:107)1,

i jRi
Ri

jk = 1
Ri
ii

jk] j(cid:54)=i,k(cid:54)=i, j∈N ,k∈N , Λi

where Λi := [Λi
iku juk, eN−1 is
an N − 1-dimensional column vector with all one entries, and
αi is a weighting factor capturing the unit cost of cognition
of player i and it can be tuned to match with experimental
data. The term (cid:107)mi(cid:107)1 is a convex relaxed version of (cid:107)mi(cid:107)0
which approximately maintains the sparse property of player
i’s cognitive network [34], [35]. The integrated term αi(cid:107)mi(cid:107)1
can be interpreted as the cognitive cost of user i.

Therefore, for player i, we need to solve the following

constrained optimization problem:

that we still solve (9) by selecting a proper αi which yields
equivalent (9) and (10).

D. Gestalt Nash Equilibrium

The formulated security management under bounded ra-
tionality problem boasts a games-of-games structure. The
users make decisions strategically in the IoT network as
well as form their cognitive networks selﬁshly. The security
management game and cognitive network formation game are
interdependent. Therefore, the cognitive and IoT user layers
shown in Fig. 2 constitute a network-of-networks framework.
In this paper, we aim to design an integrated algorithm to
design the cognitive networks and determine the security risk
management decisions of users in a holistic manner.

To this end, we present the solution concept, Gestalt Nash
equilibrium, of the bounded rational security risk management
game as follows.

mi

min
j, j(cid:54)=i, j∈N

miT

1
2
s.t. 0 ≤ mi

Λimi − eT

N−1Λimi + αi(cid:107)mi(cid:107)1

j ≤ 1, j (cid:54)= i, j ∈ N , (Risk perception),

(9)

Deﬁnition 3 (Gestalt Nash Equilibrium). The Gestalt Nash
the security risk management game
equilibrium (GNE) of
i ), ∀i ∈ N , that
under bounded rationality is a proﬁle (mi∗, u∗
satisﬁes

where the constraints mi
perception behavior of user i.

j ∈ [0, 1], ∀ j (cid:54)= i, indicate the risk

The number of cognitive links that player i can form is
generally a positive integer, i.e., (cid:107)mi(cid:107)1 = βi ∈ N+. Note that
βi here and αi in (9) have the same interpretation which both
quantify the cognition ability of player i. Then, by choosing αi
strategically, the problem in (9) is equivalent to the following
problem:

mi

min
j, j(cid:54)=i, j∈N

miT

1
2
s.t. 0 ≤ mi

Λimi − eT

N−1Λimi

˜Ji(u∗

i , u∗

−i, mi∗) ≤ ˜Ji(ui, u∗

−i, mi), ∀ui ∈ Ui, ∀mi ∈ [0, 1]N−1.

At the GNE, all the players in the network do not change their
action ui and cognition vector mi, ∀i ∈ N , simultaneously.

[u∗

Remark: The strategic security management proﬁle u∗ =
i ]i∈N at GNE is also a BRNE.
In the following, we aim to analyze the GNE of the game

and compute it by designing algorithms.

j ≤ 1, j (cid:54)= i, j ∈ N , (Risk perception),

(10)

III. PROBLEM ANALYSIS

(cid:107)mi(cid:107)1 = βi, (Limited attention),

where βi ∈ N+ ≤ N − 1 is the total number of links that
player i can form in his cognitive network, quantifying his
limited attention. Simulation studies in Section V reﬂect that
considering (cid:107)mi(cid:107)1 = βi yields sparser cognitive networks. Note

We ﬁrst analyze the convergence of the bounded rational
best-response dynamics of players in Section II-B. Then, we
quantify the risk of bounded perception due to limited attention
of players. We further reformulate the cognitive network
formation problem presented in Section II-C.

G223451Cognitive networksIoT user networksG123451A. Bounded Rational Best Response Dynamics

Based on Section II-B, the bounded rational best-response
dynamics of player i under cognitive network mi, i ∈ N , can
be written as

ui,k+1 = BRi(uci

−i,k) =

(cid:32)

1
Ri
ii

∑
j(cid:54)=i, j∈N

(cid:33)

i juci
Ri

j,k + ri

,

(11)

j,k = mi

where uci
ju j,k and k denotes the iteration index. Then, we
obtain the following convergence result of security manage-
ment strategy updates of users under given cognition networks.

Lemma 1. Under Assumption 1, the sparse best-response
dynamics (11) for all players converge to a unique BRNE.

networks,

cognition
since mi

the
sparse
i j, ∀i ∈ N ,
jRi

Ri
Proof. In
ii >
∑ j(cid:54)=i, j∈N mi
j ∈ [0, 1]. Then, Rs
deﬁned in (6) is strictly diagonal dominant by rows, and
u admits a unique solution. In addition, both Gauss-Seidel
and Jacobi types of best-response dynamics (11) converges
(cid:4)
[36].

Note that Assumption 1 is a sufﬁcient condition. In some
cases, the best-response dynamics (11) may still converge
when Assumption 1 does not hold. We focus on the scenarios
under Assumption 1 in this paper which exhibit a natural
security dependence interpretation.

B. Risk of Bounded Perception

When making security strategies in the IoT, the risk of
bounded perception (RBP) of users due to irrationality/limited
attention is deﬁned as follows.

Deﬁnition 4 (RBP). With the cognition vector mi, the RBP of
player i, i ∈ N , is deﬁned as
Li(mi, u−i) = Ji(BRi(uci
where Li : Mi × U−i → R.

−i), u−i) − Ji(BRi(u−i), u−i),

(12)

Note that RBP is deﬁned over the real-world cost functions
(2), quantifying the security loss of the users due to limited
attention. We further present the following lemma.

Lemma 2. Under the bounded rational model, each user in
the network has a degraded security level comparing with the
one obtained from the model containing fully rational users.
The RBP of player i, i ∈ N , with bounded rationality is

Li(mi, u−i) =

1
2 ∑

j(cid:54)=i, j∈N

∑
k(cid:54)=i,k∈N

(1 − mi

j)(1 − mi
k)

1
Ri
ii

Ri

jiRi

iku juk.

Proof. See Appendix A.

(cid:4)

Remark: Note that the RBP of each player is nonnegative
from Lemma 2, since the coefﬁcients and security investments
are nonnegative and the cognition variable admits a value
between 0 and 1. Intuitively, if player i is able to perceive
j ∈ N ,
all the cyber risks in the network, i.e., mi
then the RBP is Li(mi, u−i) = 0. In this scenario, the bounded
rational model degenerates to the fully rational one. This
the IoT users can
indicates that, with more observations,
design security management strategies better to lower their

j = 1, ∀ j (cid:54)= i,

security risks. This fact also leads to the conclusion that more
information (better cognitive ability) is beneﬁcial for the users
in our security management game. The result in Lemma 2
is further illustrated and corroborated through case studies in
Section V.

C. Problem Reformulation

We can rewrite the constrained optimization program (9) as

min
j, j(cid:54)=i, j∈N

mi

Qi(mi) :=

miT

1
2

Λimi −eT

N−1Λimi +αi(cid:107)mi(cid:107)1 +ιC(mi),

where Qi : [0, 1]N−1 → R ∪ {+∞}, C := {mi|0 ≤ mi
i, j ∈ N }, and ιC is an indicator function, i.e.,

(13)
j ≤ 1, j (cid:54)=

ιC(x) =

(cid:40)

if x ∈ C,

0,
+∞, otherwise.

(14)

For convenience, we decompose the function Qi into three
parts and deﬁne

miT

1
2

N−1Λimi, (Security loss),

Λimi − eT
f i
1(mi) =
2(mi) = αi(cid:107)mi(cid:107)1, (Cognition cost),
f i
3(mi) = ιC(mi), (Feasible risk perception),
f i

(15)

2 : RN−1 → [0, +∞) and f i

1 : RN−1 → R, f i

where f i
{0, +∞}. Speciﬁcally, for user i ∈ N , f i
security loss; f i
feasible risk perception over the IoT.

2 captures the cognition cost; and f i

3 : RN−1 →
1 quantiﬁes a modiﬁed
3 ensures a

The optimization problem (13) is quite challenging to solve.
First, note that the convexity of f i
1 depends on the character-
istics of matrix Λi. Specially, when Λi is positive deﬁnite,
then f i
1 is convex in mi. When Λi is not deﬁnite, then solving
the quadratic program is an NP hard problem. Second, the
l1 norm-based function f i
3 are
nonsmooth and not differentiable, though they are convex. The
traditional gradient-based optimization tools are not sufﬁcient
to deal with this type of optimization problem in (13) [37].
To this end, we aim to design a proximal algorithm to solve
this problem.

2 and the indicator function f i

IV. COMPUTING GNE VIA ALGORITHM DESIGN

In this section, our goal

is to design an algorithm to
solve problem (13). We further characterize the closed form
solutions for a special case with homogeneous agents for
comparison during case studies in Section V. In addition, we
present an integrated algorithm that computes the GNE of the
bounded rational security management game.

A. Basics of Proximal Operator

To address (13), we leverage the tools from proximal
operator theory. We ﬁrst present the deﬁnition of proximal
operator as follows.

Deﬁnition 5 (Proximal Operator [38]). Let g ∈ Γ0, where
Γ0 denotes the set of proper lower semicontinuous convex

functions. The proximal mapping associated to g is deﬁned
as

1) The domain of f is denoted by dom f := {x ∈ Rn : f (x) <

+∞}.

proxλ g(x) = arg min

l

g(l) +

1
2λ

(cid:107)l − x(cid:107)2.

(16)

2) For x ∈ dom f , the Fr´echet subdifferential of f at x is
the set of vectors p ∈ Rn, denoted by ˆ∂ f (x), that satisfy

Note that the proximal mapping is unique, since the opti-
mization problem in (16) is convex. Speciﬁcally, for function
f i
2 in (15), we have

(cid:104)
proxλ f i

2

(cid:105)
(x)

=

j






x j − λ αi,
0,
x j + λ αi,

x j ≥ λ αi,
|x j| < λ αi,
x j ≤ −λ αi,

for j (cid:54)= i,

j ∈ N , which can be put in a compact form as [39]

lim inf
y(cid:54)=x,y→x

1
(cid:107)y − x(cid:107)

[ f (y) − f (x) − (cid:104)p, y − x(cid:105)] ≥ 0.

3) The limiting-subdifferential (or subdifferential) of

f at

x ∈ dom f , denoted by ∂ f (x), is deﬁned by

(cid:110)

∂ f (x) :=

p ∈ Rn : ∃xn → x, f (xn) → f (x),
(cid:111)
pk ∈ ˆ∂ f (xn) → p
.

proxλ f i

2

(x) = (x − λ αieN−1)+ − (−x − λ αieN−1)+.

(17)

Remark: Based on the subifferential, a necessary condition

for x ∈ Rn being a minimizer of f is

In addition, proxλ f i
equivalent to

3

(x) = projC(x), C = [0, 1]N−1, which is

∂ f (x) (cid:51) 0.

(18)

(cid:104)
proxλ f i

3

(cid:105)
(x)

j

= [projC(x)] j =






1,
x j,
0,

if x j > 1,
if 0 ≤ x j ≤ 1,
if x j < 0,

where “proj” denotes the projection operator.

The following lemma characterizes the aggregated proximal
3 which is useful in designing

2 and f i

operator of functions f i
the proximal algorithm.

3 deﬁned in (15), ∀i ∈ N ,

Lemma 3. Functions f i
satisfy the property: proxλ ( f i

2 and f i
2+ f i
Proof. We proof for single dimensional case, i.e., C = [0, 1],
and the analysis can be generalized for higher dimensional
cases. By deﬁnition, we obtain

3) = projC ◦ proxλ f i

.

2

proxλ ( f i

2+ f i

3)(x) = arg min

l

= arg min
l∈C

(cid:107)l − x(cid:107)2

2(l) + f i
f i
3(l) +
1
2λ

f i
2(l) +

1
2λ
(cid:107)l − x(cid:107)2.

(cid:19)

(cid:18) ∂( f i

2

= 0

(cid:107)l−x(cid:107)2)

2(l)+ 1
Let l∗ = argl
(x). In addi-
= proxλ f i
2λ
∂ x
2(l) + 1
tion, function f i
2λ (cid:107)l − x(cid:107)2 is decreasing in l < l∗ and
increasing in l ≥ l∗. Remind that C = [0, 1] is a closed set.
3)(x) = l∗; when l < l∗,
Hence, when 0 ≤ l∗ ≤ 1, proxλ ( f i
3)(x) = 1.
proxλ ( f i
2+ f i
3)(x) = projC(l∗) =
In all three cases, we obtain proxλ ( f i
(cid:4)
projC(proxλ f i

3)(x) = 0; and when l > l∗, proxλ ( f i

(x)).

2+ f i

2+ f i

2+ f i

2

Lemma 3 indicates that we can deal with the convex terms
of cognitive cost and feasible risk perception jointly. The
security loss term f i

1 is addressed in the ensuing section.

B. Design of Proximal Algorithm
2 and f i
f i

Recall that

3, ∀i ∈ N , are nonsmooth and not
differentiable. To characterize the optimal cognition vector in
2 and f i
f i
3, we ﬁrst present the deﬁnition of subdifferential of a
function which can be nonconvex and nonsmooth as follows.
Deﬁnition 6 (Subdifferential [40]). Let f : Rn → R be a proper
and lower semicontinuous function.

Note that the points satisfying (18) are called critical points
of f . Our goal is to ﬁnd a critical point ¯mi ∈ dom Qi that can
be characterized by the necessary FOC: 0 ∈ ∂ Qi( ¯mi).

Note that

f i
1 is continuously differentialble with Lipschitz

continuous gradient, i.e.,

(cid:107)∇ f i

1(y)(cid:107) ≤ Li(cid:107)x − y(cid:107), ∀x, y ∈ RN−1,

1(x) − ∇ f i
is the Lipschitz constant of

where Li
∇ f i

f i
1. Speciﬁcally,
1(mi) = Λimi − ΛieN−1, which further yields

(cid:107)∇ f i

1(x) − ∇ f i

1(y)(cid:107) = (cid:107)Λi(x − y)(cid:107) ≤ Li(cid:107)x − y(cid:107), ∀x, y ∈ RN−1.
(19)
The main steps in solving (13) for a general Λi of user i

are designed as follows:

k = xi
yi

k +

k − xi

k) +

k−1),

ti
k−1 − 1
ti
k
y∇ f i
x∇ f i

1(yi
1(xi

(xi

k − xi
(cid:17)
k))

,

(cid:17)
k))

,

(zi

ti
k−1
ti
k
(cid:16)
proxλ i
(cid:16)
proxλ i
(cid:113)

y f i
2

x f i
2

(yi

(xi

k − λ i
k − λ i
(cid:19)

4(ti

k)2 + 1

/2,

zi
k+1 = projC

vi
k+1 = projC
(cid:18)

ti
k+1 =

1 +

(cid:40)

xi
k+1 =

if Qi(zi
zi
k+1,
vi
k+1, Otherwise,

k+1) ≤ Qi(vi

k+1),

(20)

(21)

(22)

(23)

(24)

x < 1/Li and
y < 1/Li, respectively. If the algorithm converges, the
k are the same which give the optimal

where the step constants λ i
0 < λ i
values of xi
cognition vector mi.

y satisfy 0 < λ i

x and λ i

k and vi

k, yi

k, zi

Remark: Note that (22) serves as a monitor of the update in
(21). Together with the condition in (24), each player updates
their cognitive network when there is a sufﬁcient decrease of
the security management cost.

Before presenting the convergence results of the algorithm
(20)-(24), we ﬁrst characterize a critical property of function
Qi(mi) deﬁned in (13).

Deﬁnition 7 (Kurdyka-Łojasiewicz (KL) Property [41]). A
function f : Rn → (−∞, +∞] has the KL property at x∗ ∈
dom ∂ f := {x ∈ Rn : ∂ f (x) (cid:54)= /0} if there exists η ∈ (0, +∞], a
neighborhood U of x∗, and a desingularising function φ ∈ Φη ,

such that ∀x ∈ U ∩ {x ∈ Rn : f (x∗) < f (x) < f (x∗) + η}, the
following KL inequality holds,

φ (cid:48)( f (x) − f (x∗))dist(0, ∂ f (x)) ≥ 1,

(25)

where Φη includes a class of function φ : [0, η) → R+ satisfy-
ing: (1) φ is concave and φ ∈ C1((0, η)); (2) φ is continuous
at 0 with φ (0) = 0; and (3) φ (cid:48)(x) > 0, ∀x ∈ (0, η). In addition,
dist(0, ∂ f (x)) := inf {(cid:107)z(cid:107) : z ∈ ∂ f (x)} .

Note that a proper lower semicontinuous function f having
the KL property at each point of dom ∂ f
is called a KL
function. KL inequality (25) ensures that, by choosing a proper
desingularising function φ , we can reparameterize the values
of function f near its critical points to avoid ﬂatness. Thus,
φ has an impact on the convergence rate of the designed
algorithm which will be presented in Theorem 1. KL property
is general in functions. Notably, the semi-algebraic functions
satisfy the KL property [41]. Some examples include real poly-
nomial functions, indicator functions of semi-algebraic sets
and (cid:107)·(cid:107)p with p ≥ 0. Furthermore, the semi-algebraic property
preserves under composition, ﬁnite sums and products of semi-
algebraic functions [42].

2 and f i
f i

Lemma 4. Functions f i
3 in (15) satisfy the KL
1,
property, and thus Qi in (13) is a KL function. In addition, the
desingularising function φ (u) can be chosen as φ (u) = κ
θ uθ
for some θ ∈ (0, 1

2 ] and κ > 0.
Proof. We know that f i
2 and f i
f i
1,
3 are semi-algebraic func-
tions, and thus Qi satisﬁes the KL property [41]. Remind that
j ≤ 1, j (cid:54)= i, j ∈ N }, Qi(mi) → +∞.
when mi /∈ C := {mi|0 ≤ mi
Based on Deﬁnition 6, we obtain dom ∂ Qi = C. Therefore,
Qi(mi) is analytic over dom ∂ Qi. In addition, the desingular-
ising function of real-analytical functions satisfying inequality
2 , 1) [42]. (cid:4)
(25) can be chosen as φ (u) = u1−δ , where δ ∈ [ 1

Based on Lemma 4, we present the convergence result of

the designed algorithm (20)-(24) in Theorem 1.

Theorem 1. The algorithm given by (20)-(24) converges to a
critical point with rates related to the parameters κ and θ ,
where κ and θ are deﬁned in Lemma 4. Speciﬁcally, there
exists a k0 such that ∀k > k0,

Qi(xk) − Q∗

i ≤

(cid:18)

κ
(k − k0)(1 − 2θ )d2

(cid:19) 1
1−2θ

,

is the function value achieved at critical points
+

where Q∗
i
of {xk}, d2 = min
L)2/(1 − 2α), and σ = κ

(cid:110) 1
2d1κ , σ (Qi(v0) − Q∗
(cid:16)
2θ −1
2θ −2 − 1
2

i )2θ −1(cid:111)
(cid:17)
.

, d1 = 2α( 1
λx

1−2θ

Proof. See Appendix B.

(cid:4)

For a special case where f i

the following
simpliﬁed steps (26)-(29) can be adopted to accelerate the
computation. The monitoring update step vk+1 is omited due to
the convexity of f i
1. This algorithm is slightly different with
the one in [43] in terms of the projection step. Since Qi is

1 is convex,

Algorithm 1 Cognitive Network Formation for Player i

2 and C = [0, 1]N−1
0, xi

0, xi

1) Input f i
1, f i
2) Initialize parameters zi
3) for k = 1, 2, ... do
1 is convex
4)
k, zi
Update yi
5)

if f i

k+1, vi

k+1, ti

(29)

1, ti

0, ti

1, λ i

x and λ i
y

k+1 and xi

k+1 through (26)-

6)
7)

else

Update yi

k, zi

k+1, vi

k+1, ti

k+1 and xi

k+1 through (20)-

(24)

end

8)
9) end for
10) Return mi = xi
k

convex, then algorithm (26)-(29) converges to a unique optimal
solution.

(zi

ti
k−1
ti
k
(cid:16)
proxλ i
(cid:113)

k = xi
yi

k +

k − xi

k) +

zi
k+1 = projC
(cid:18)

ti
k+1 =

1 +

y f i
2

(yi

k − λ i
(cid:19)

4(ti

k)2 + 1

/2,

ti
k−1 − 1
ti
k
y∇ f i

1(yi

(xi

k − xi
(cid:17)
k))

,

k−1),

xi
k+1 =

(cid:40)

zi
k+1,
xi
k,

k+1) ≤ Qi(xi

k),

if Qi(zi
Otherwise.

(26)

(27)

(28)

(29)

Similar to (20)-(24), when the algorithm (26)-(29) converges,
the values of xi
k, yi
k are the same which give the optimal
cognition vector mi.

k and zi

Homogeneous Users Case: When the agents in the IoT
network are homogeneous, i.e., Ri
ji, ri = r j = r,
βi = β j = β ≤ N −1, ∀i, j ∈ N , we can characterize the closed
form solutions of decisions ui and mi, ∀i ∈ N . Speciﬁcally,
we obtain, ∀i ∈ N ,

i j = R j

ii = R j

j j, Ri

mi∗

j =

u∗
i =

β
N − 1
r
R1 − β R2

, ∀ j (cid:54)= i, j ∈ N ,

,

(30)

ii and R2 = Ri

where R1 = Ri
jk for j (cid:54)= i and k (cid:54)= i. The results
indicate that, at GNE, the cognitive network that each user
i forms, i ∈ N , is symmetric, i.e., the allocated attention to
other users j (cid:54)= i by user i is the same. In addition, with a larger
β , the users spend more effort on the security management
at GNE. This can be interpreted as follows: with a better
perception of cyber risks in the IoT, the users becomes better
informed of the risks and make best effort to reduce the
security loss.

C. Integrated Algorithm and Discussions

For clarity, we summarize the combined algorithm in-
cluding the strategic security decision-makings of players in
the IoT networks and their corresponding cognitive network
formations together in Algorithm 2. The integrated algorithm
exhibits an alternating pattern between the best-response of
security management and the strategic cognitive network for-
mation of IoT users.

Algorithm 2 Strategic Risk Management with Bounded Ra-
tionality

1) Initialize parameters in the game G , cognition cost αi,

cognitive networks mi, ∀i ∈ N

2) Do

identiﬁes the most inﬂuential agents in the network. Moreover,
the critical agents to pay attention to for each user almost
overlap, resulting the phenomenon of attraction of the mighty
during the cognitive network formation.

We illustrate the discovered phenomena in Section V.

Best response dynamics:

3) Based on mi, i ∈ N , player i determines their best-
response strategy through (11) iteratively until reaching
a BRNE
Cognitive network formation:

4) Each player i, i ∈ N , forms their cognitive network mi

through Algorithm 1

5) Until [mi]i∈N and [ui]i∈N converge
6) Return mi and ui, ∀i ∈ N , which form a GNE

k+1 and vi

We next discuss some observations obtained from the algo-
rithm. The steps zi
k+1 in (21) and (22) of the algorithm
can be simpliﬁed further. Here, we only analyze zi
k+1, and the
k+1. First, we have ∇ f i
procedure follows for vi
1(yi
k) = Λi(yi
k −
eN−1). Then, [yi
y∇ f i
yΛi(yi
1(yi
k − eN−1)] j ≥ 0,
∀ j (cid:54)= i, j ∈ N . Thus, based on (17), we obtain
k − eN−1) − λ i
k − λ i
k + λ i

(cid:1)
yαieN−1
k) − αieN−1)(cid:1) .

yΛi(yi
y(Λi(eN−1 − yi

zi
k+1 = projC
= projC

k)] j = [yi

(cid:0)yi
(cid:0)yi

k − λ i

k − λ i

The update of player i’s attention on player j at step k + 1,
j (cid:54)= i, can be expressed as

[zi

k+1] j =
(cid:32)

proj[0,1]

[yi

k] j + λ i
y

(cid:32) Ri
i j
Ri
ii

u j ∑

p(cid:54)=i,p∈N

Ri

ipup

(cid:0)1 − [yi

k]p

(cid:1) − αi

(cid:33)(cid:33)

.

k]p

When

(cid:0)1 − [yi

k+1] j ≥ [zi

ipup − Ri
ii
Ri
i ju j

(cid:1) ≥ αi which is equiv-

u j ∑p(cid:54)=i,p∈N Ri
ipup[yi

ipup
k]p ≤ ∑p(cid:54)=i,p∈N Ri

Ri
i j
Ri
ii
alent to ∑p(cid:54)=i,p∈N Ri
αi, we
know that [zi
k] j. The player i’s attention on player
j increases at step k + 1, since there remains extra cognition
resources to be allocated which corresponds to a phenomenon
called ﬁlling the inattention. In addition, a smaller cognition
cost αi yields a larger upper bound for ∑p(cid:54)=i,p∈N Ri
k]p,
and hence player i can pay more attention to other players
which again leads to the observation of ﬁlling the inattention.
In the IoT network, user j’s decision has an impact on
the strategy of user i. To illustrate the discovery, we consider
two groups of IoT users, and one group of users have more
incentive to secure the devices, i.e., their security investment
is larger. Then, from user i’s perspective, his attention on user
j is inﬂuenced by the term Ri
i ju j). When user j lies in
the group of a higher investment u j, then the upper bound
∑p(cid:54)=i,p∈N Ri
αi is larger. Therefore, each IoT user
will allocate more cognition resources to the users in the group
with a higher security standard which exposes the phenomenon
of emergence of partisanship.

ipup − Ri
ii
Ri
i ju j

ipup[yi

ii/(Ri

In a heterogeneous IoT network, the system parameters
i j, Ri
Ri
ii, and decisions ui are generally different. Then, for
player i ∈ N , the term
j ∈ N ,
u j ∑p(cid:54)=i,p∈N Ri

ipup, j (cid:54)= i,

Ri
i j
Ri
ii

V. CASE STUDIES

We use case studies of IoT-enabled smart communities
shown in Fig. 1 to corroborate the designed algorithms and
illustrate the security management of bounded rational agents
in this section.

A. Effectiveness of Algorithm 1

First, we verify the effectiveness of Algorithm 1. Speciﬁ-
cally, we choose N = 10, α = 100 and generate a 9×9 random
matrix which is not deﬁnite for Λi. Thus,
f i
2 in (15) is not
convex. The iterative updates through the designed proximal
algorithm are presented in Fig. 3 which reveal fast conver-
gence to the steady state. In addition, the algorithm yields
a sparse cognition vector m = [1, 0, 0, 0, 0.41, 1, 0, 0.30, 0.26].
To investigate the robustness of the algorithm, we study the
same network as in Fig. 3(a) with different initial conditions.
The results are shown in Figs. 3(b) and 3(c). We can verify
that the steady states in Figs. 3(b) and 3(c) are the same
as the ones in Fig. 3(a) which corroborate the robustness
of the algorithm to initial conditions. To further verify the
algorithm, we also investigate the network containing different
numbers of agents. The results with 7 and 15 agents are
presented in Figs. 3(d) and 3(e). Both results indicate that the
designed algorithm is reliable in computing the sparse steady
strategy. After conducting sufﬁcient number of case studies,
we conclude that the algorithm is effective with probability 1
under arbitrary number of agents.

B. Homogeneous Smart Homes

In this case study, we consider N = 10 homogeneous
households in the smart community, i.e., all the parameters
are the same for each agent. Speciﬁcally, the parameters are
chosen as follows: Ri
jk = 20 unit/k$2 if j = k = i, otherwise
jk = 1 unit/k$2, ∀i; ri = 25 unit/k$, ∀i ∈ N and α i = α, ∀i,
Ri
is chosen to satisfy β = (cid:107)mi(cid:107)1 = 3. The selected parameters
the security level of a household is mainly
indicate that
determined by its own security management policy rather
than the ones of connected households. Recall that we have
obtained the analytical solutions for homogeneous case in (30)
which yield mi
17 = 1.47k$.
Thus, each agent allocates attention resource equally to their
connected neighbors. Fig. 4 presents the results by using Algo-
rithm 2, where the step index represents an iteration between
two components of cognitive network formation and security
investment. We can conclude that the rational decision yields
less cost for players compared with their irrational decision
counterparts due to the bounded rationality. Furthermore, the
algorithm gives the same cognitive network structure as the
one obtained from the analytical results which corroborates
the proposed integrated algorithm.

3 , ∀ j (cid:54)= i, j ∈ N and ui = 25

j = 1

(a) rational strategy

(b) cost under rational strategy

(c) bounded rational strategy

(d) cost under bounded rational strat-
egy

(a) N = 10, case 1

(b) N = 10, case 2

(c) N = 10, case 3

(d) N = 7

(e) N = 15

(e) cognitive network

Fig. 3. Performance of Algorithm 1 on a nonconvex f i
2 in (15). (a), (d), and
(e) show the results with 10, 7 and 15 agents in the network, respectively.
The network conﬁgurations in (a), (b), and (c) are the same, but their initial
conditions are different. The algorithm yields the same result for cases in (a),
(b), and (c) which shows the robustness of the algorithm.

Fig. 4. (a) and (b) are the rational decision of players and the corresponding
cost, respectively. (c) and (d) are the counterparts of (a) and (b) with bounded
rationality. (e) illustrates the formed cognitive networks which is symmetric
in this homogeneous case.

C. Emergence of Partisanship

We next

investigate a smart community including two
groups of agents denoted by G1 and G2, respectively. Specif-
ically, G1 includes 5 agents, G1 = {1, ..., 5}, and G2 con-
tains 10 agents, G2 = {6, ..., 15}. The parameters are the
same as those in Section V-B except that for agents in G1,
ri = 40 unit/k$, ∀i ∈ G1, to distinguish two groups of users.
Thus, the agents in G1 have more incentives to secure their
IoT products than those in G2. Fig. 5 shows the results.
For agents in G1, the cognitive network is characterized by
mi = [0.75, ..., 0.75, 0, ..., 0], i ∈ G1, and for agents in G2,
m j = [0.6, ..., 0.6, 0, ..., 0], j ∈ G2. Therefore, with limited cog-
nition, all agents only pay attention to the security decisions
made by smart homes in G1 which yields the phenomenon of
partisanship. We also verify that the RBP increases due to the
bounded rationality.

D. Filling the Inattention

Under the setting of Section V-C, we further assume that
the agents have better cognitive ability and can perceive
more cyber risks in the smart community in a way that β =
(cid:107)mi(cid:107)1 = 8. Other parameters are the same as those in Section
V-C. Fig. 6 presents the results. Speciﬁcally, we obtain mi =
[1, ..., 1, 0.4, ..., 0.4] for i ∈ G1 and m j = [1, ..., 1, 0.33, ..., 0.33]
for j ∈ G2, which show that the agents in G1 play a critical
role in the security risk management of smart community.
Furthermore, with more cognition resource, the agents in G2
that are not paid attention to previously in Section V-C are
considered by other households. This phenomenon is termed
as ﬁlling the inattention.

E. Attraction of the Mighty

The critical agents in the IoT-enabled smart community
are those households whose security management policies
will be taken into account by the other agents during their
decision makings. Speciﬁcally, the nodes who often appear

0100200300400500Step00.20.40.60.81mm1m2m3m4m5m6m7m8m90100200300400500Step00.20.40.60.81mm1m2m3m4m5m6m7m8m90100200300400500Step00.20.40.60.81mm1m2m3m4m5m6m7m8m90100200300400500Step00.20.40.60.81mm1m2m3m4m5m60100200300400500Step00.20.40.60.81mm1m2m3m4m5m6m7m8m9m10m11m12m13m1405101520Step00.511.522.53Security management policy u (k$)Rational decisions of playersu1u2u3u4u5u6u7u8u9u1005101520Step-55-50-45-40-35-30-25-20-15-10-5Cost JCost of players under rational behaviorsJ1J2J3J4J5J6J7J8J9J1005101520Step00.511.522.53Security management policy us (k$)Bounded rational decisions of playersus1us2us3us4us5us6us7us8us9us1005101520Step-40-35-30-25-20-15-10-50Cost JsCost of players under bounded rational behaviorsJs1Js2Js3Js4Js5Js6Js7Js8Js9Js10(a) bounded rational strategy

(b) RBP

(a) rational strategy

(b) cost under rational strategy

(c) cognition vector m

(d) cognitive network

(c) bounded rational strategy

(d) RBP

Fig. 5.
(a) shows the bounded rational strategy of players, indicating that
players in G1 have a lower cost. (b) depicts the RBP which corroborates
that the security risk of users increases under the bounded rational model
comparing with the fully rational one. (c) and (d) illustrate the formed sparse
cognitive networks. In (d), blue and green dots are agents in G1 and G2,
respectively, and the red ones are representatives in each group. In the network,
all agents only allocate cognition resource to smart homes in G1 at GNE,
leading to the emergence of partisanship.

(a) bounded rational strategy

(b) RBP

(c) cognition vector m

(d) cognitive network

Fig. 6.
(a) shows the bounded rational decisions, and (b) presents the RBP
which is positive. (c) and (d) illustrate the formed cognitive networks. This
case study indicates that players in G1 are more critical that those in G2 in
the cognitive networks. In addition, cognition resource is further allocated to
the users in G2 which reveals the phenomenon of ﬁlling the inattention.

in the cognitive networks of other nodes can be regarded
as critical agents. In the following case study, we aim to
identify the critical agents in a smart community with N = 10
households using Algorithm 2. To model the heterogeneity
of smart homes, we choose Ri
jk = 3 sin(i) + 20 unit/k$2 for

(e) cognitive network

Fig. 7. In this heterogeneous case with 10 users, the formed cognitive network
shown in (e) is sparse for each smart home. Note that the red rectangular in
each subplot of (e) denotes the user that forms his cognitive network with
the lines standing for links. Under the bounded rational model, the algorithm
can successfully detect the critical agents (attraction of the mighty) in the IoT
network which are 5th, 9th and 10th users in this case.

j = k = i. Otherwise, Ri
jk = 1 unit/k$2, ∀i; ri = 15 + 2i unit/k$
for i ∈ N ; and other parameters are the same as those in
Section V-B. The results are shown in Fig. 7. Speciﬁcally,
Fig. 7(e) shows the established cognitive network of each
player. For example, during the cognitive network formation,
player 1 chooses to observe the strategies of players 5, 9, and
10 in the network, and player 5’s cognitive network includes
players 6, 9, and 10. Furthermore, agents 5, 9 and 10 present
in all agents’ cognitive networks, and hence they constitute a
critical community in this smart home network. In addition,
agent 6 also plays a critical role in agents 5, 9 and 10’s
cognitive networks. Therefore, the behavior of agents paying
attention to a speciﬁc set of households can be described by
the attraction of mighty. This case study demonstrates that
Algorithm 2 is able to identify the critical components in the
smart communities.

VI. CONCLUSION

In this paper, we have investigated the security management
of users with limited attention over IoT networks through a
two-layer framework. The proposed Gestalt Nash equilibrium

051015Step11.522.533.54Security management policy us (k$)Bounded rational decisions of playersus1us2us3us4us5us6us7us8us9us10us11us12us13us14us15051015Step80100120140160180200220Cost Difference Js-JJs1-J1Js2-J2Js3-J3Js4-J4Js5-J5Js6-J6Js7-J7Js8-J8Js9-J9Js10-J10Js11-J11Js12-J12Js13-J13Js14-J14Js15-J15051015Step00.51m (group 1)051015Step00.51m (group 2) Cognitive network of each group-6-4-20246Group 1123-6-4-20246Group 2123 Cognitive network of users in each group051015Step11.522.533.54Security management policy us (k$)Bounded rational decisions of playersus1us2us3us4us5us6us7us8us9us10us11us12us13us14us15051015Step60708090100110120130140150160Cost Difference Js-JJs1-J1Js2-J2Js3-J3Js4-J4Js5-J5Js6-J6Js7-J7Js8-J8Js9-J9Js10-J10Js11-J11Js12-J12Js13-J13Js14-J14Js15-J15051015Step00.51m (group 1)051015Step00.51m (group 2) Cognitive network of each group05101520Step123456789Security management policy u (k$)Rational decisions of playersu1u2u3u4u5u6u7u8u9u1005101520Step-150-100-50050100150Cost JCost of players under rational behaviorsJ1J2J3J4J5J6J7J8J9J1002468101214161820Step123456789Security management policy us (k$)Bounded rational decisions of playersus1us2us3us4us5us6us7us8us9us1002468101214161820Step-30-20-1001020304050Cost Difference Js-JJs1-J1Js2-J2Js3-J3Js4-J4Js5-J5Js6-J6Js7-J7Js8-J8Js9-J9Js10-J10-202player 1-20246-202player 2-20246-202player 3-20246-202player 4-20246-202player 5-20246-202player 6-20246-202player 7-20246-202player 8-20246-202player 9-20246-202player 10-20246 Cognitive network of each player(GNE) has successfully characterized the bilevel decision mak-
ings, including the security management policies and the cog-
nitive network formations of users. Under the security inter-
dependencies, users with a better cognition ability can reduce
their cyber risks by making mature decisions. Furthermore,
the designed proximal-based algorithm for the computation of
GNE has revealed some phenomena that match well with the
real-life observations, including the emergence of partisanship
and attraction of the mighty. The future work would be
extending the framework to incorporate hidden information of
unperceived cyber risks of IoT users and design mechanisms to
mitigate security loss. Another interesting research direction is
to extend the current model to scenarios when a set of users are
not fully strategic in minimizing their own risks and analyze
the impact of this class of users’ misbehavior on the network
security risk.

APPENDIX A
PROOF OF LEMMA 2
Proof. Based on (8), we can compute the RBP of node i as

Li(mi, u−i) = Ji(BRi(uci

−i), u−i) − Ji(BRi(u−i), u−i)

=

1
2 ∑

j(cid:54)=i
j∈N

∑
k(cid:54)=i
k∈N

mi
j
Ri
ii

+

1
2 ∑

j(cid:54)=i
j∈N

∑
k(cid:54)=i
k∈N

1
Ri
ii

Ri

jiRi

ikmi

ku juk −

1
2 ∑

k(cid:54)=i
k∈N

Ri

jiRi

iku juk −

1
2 ∑

k(cid:54)=i
k∈N

∑
j(cid:54)=i
j∈N

mi
j
Ri
ii

∑
j(cid:54)=i
j∈N
mi
j
Ri
ii

Ri

jiRi

iku juk

Ri

jiRi

iku juk.

Further, we can rewrite ∑ j(cid:54)=i, j∈N ∑k(cid:54)=i,k∈N
1
∑ j(cid:54)=i, j∈N ∑k(cid:54)=i,k∈N mi
j
Ri
ii
j) ∑k(cid:54)=i,k∈N (1 − mi
mi
jiRi
j) ∑k(cid:54)=i,k∈N mi
mi
k

Ri
k) 1
Ri
ii
iku juk. Therefore, we obtain

iku juk =
+ ∑ j(cid:54)=i, j∈N (1 −
iku juk + ∑ j(cid:54)=i, j∈N (1 −

jiRi
iku juk
jiRi
Ri

Ri

Ri

jiRi

1
Ri
ii

1
Ri
ii
1
2 ∑

j(cid:54)=i, j∈N

∑
k(cid:54)=i,k∈N

mi
j

1
Ri
ii

Ri

jiRi

ikmi

ku juk

(1 − mi

j) ∑

k(cid:54)=i,k∈N
1
Ri
ii

mi
j

Ri

∑
j(cid:54)=i, j∈N

mi
k

1
Ri
ii

Ri

jiRi

iku juk

jiRi

iku juk

(1 − mi

j) ∑

k(cid:54)=i,k∈N

(1 − mi
k)

j(cid:54)=i, j∈N

∑
k(cid:54)=i,k∈N

j(cid:54)=i, j∈N

(1 − mi

j)(1 − mi
k)

1
Ri
ii
1
Ri
ii

Ri

jiRi

iku juk

Ri

jiRi

iku juk.

Li(mi, u−i) =

k(cid:54)=i,k∈N

j(cid:54)=i, j∈N

+

−

+

=

1
2 ∑
1
2 ∑
1
2 ∑
1
2 ∑

(cid:107)x − xk(cid:107)2 + f i

xk(cid:105) + 1
2λx
1
(cid:107)vk+1 − xk(cid:107)2 + f i
2λx
continuous condition of f i

2(vk+1) ≤ f i

2(x). Then,

(cid:104)∇ f i

1(xk), vk+1 − xk(cid:105) +
2(xk). Based on the Lipschitz

1, we obtain
1(xk) + f i

3(xk) + (cid:104)∇ f i

1(xk), vk+1 − xk(cid:105)

2(vk+1) + f i

Qi(vk+1) ≤ f i
Li
2
2(xk) − (cid:104)∇ f i
≤ f i

(cid:107)vk+1 − xk(cid:107)2

+

1(xk), vk+1 − xk(cid:105) −

1
2λx

(cid:107)vk+1 − xk(cid:107)2

+ f i

1(xk) + f i

= Q(xk) −

3(xk) + (cid:104)∇ f i
1(xk), vk+1 − xk(cid:105) +
(cid:18) 1
(cid:19)
2λx

(cid:107)vk+1 − xk(cid:107)2.

Li
2

−

Li
2

(cid:107)vk+1 − xk(cid:107)2

(31)

When Qi(zk+1) ≤ Qi(vk+1),
xk+1 = zk+1, Qi(xk+1) =
Qi(zk+1) ≤ Qi(vk+1), and when Qi(zk+1) > Qi(vk+1), xk+1 =
vk+1, Qi(xk+1) = Qi(zk+1). Hence,

Qi(xk+1) ≤ Qi(vk+1) ≤ Qi(xk).

(32)

Based on (31) and (32),

Qi(vk+1) ≤ Qi(vk) −

(cid:19)

(cid:18) 1
2λx

−

Li
2

(cid:107)vk+1 − xk(cid:107)2.

(33)

In addition,

dist(0, ∂ Qi(vk+1)) ≤

(cid:18) 1
λx

(cid:19)

+ Li

(cid:107)vk+1 − xk(cid:107).

(34)

Furthermore, {xk} and {vk} have the same accumulation
the accumulation
points. Let Ψ be the set containing all
points of {xk}. Note that Qi admits the same value Q∗
i at all
accumulation points in Ψ due to the non-increasing Qi(vk).
i and Qi(vk) → Q∗
Then, Qi(vk) ≥ Q∗
i . If there exists an n such
i , the algorithm converges. If Qi(vk) ≥ Q∗
that Qi(vn) = Q∗
i ,
∀k,
i + η for
k > ˜k1. Since dist(vk, Ψ) → 0, there exists a ˜k2 such that
dist(vk, Ψ) < ε for k > ˜k2. Thus, when k > k0 = max{˜k1, ˜k2},
vk ∈ {v, dist(vk, Ψ) < ε} ∩ {Q∗
i + η}. Based on
the KL property in Deﬁnition 7, there exists a concave function
φ such that

then there exists a ˜k1 such that Qi(vk) < Q∗

i < Qi(v) < Q∗

φ (cid:48)(Qi(vk) − Q∗

i )dist(0, ∂ Qi(vk)) ≥ 1.

(35)

Deﬁne rk := Qi(vk) − Q∗
i , and we further assume that rk >
0, ∀k. Otherwise, the algorithm converges in ﬁnite steps by
deﬁnition. Then, ∀k > k0,

1 ≤ φ (cid:48)(Qi(vk) − Q∗

i )dist(0, ∂ Qi(vk))

(cid:4)

(cid:18)

φ (cid:48)(rk)

≤

(cid:19)

(cid:19)2

(cid:107)vk − xk−1(cid:107)

+ Li

(cid:18) 1
λx
(cid:18) 1
λx

APPENDIX B
PROOF OF THEOREM 1
Proof. The main idea of the proof follows [44] with sev-
eral differences. Especially the imposed conditions for show-
ing convergence in [44] are different. In addition, our al-
gorithm contains projections and an auxiliary parameter
vk+1 during updates. First, based on Deﬁnition 5, vk+1 =
1(xk), x −
projC

= arg minx∈C (cid:104)∇ f i

(xk − λx∇ f i

(cid:17)
1(xk))

(cid:16)
proxλx f i

2

≤ (φ (cid:48)(rk))2

+ Li

(cid:19)2 Qi(vk−1) − Qi(vk)
1
2λx

− Li
2

(36)

= d1(φ (cid:48)(rk))2(rk−1 − rk),

+ L)2/(1 − 2α). Besides, φ admits the form

where d1 = 2α( 1
λx
φ (u) = κ

θ uθ . Then, (36) can be rewritten as
1 ≤ d1κ 2r2(θ −1)

(rk−1 − rk).

k

(37)

2 , then, we have −1 ≤ θ −
2 and −1 < 2θ − 1 < 0. When rk−1 > rk, we obtain
. In addition,
1−2θ u2θ −1, and then ζ (cid:48)(u) = −κu2θ −2. When

Lemma 4 indicates that 0 < θ ≤ 1
1 < − 1
r2(θ −1)
k−1 < r2(θ −1)
deﬁne ζ (u) = κ
r2(θ −1)
≤ 2r2(θ −1)
k−1
k

< ... < r2θ −1

and r2θ −1
0

< r2θ −1
1

k

k

ζ (rk) − ζ (rk−1) = κ

u2(θ −1)du ≥ κr2(θ −1)

k−1

(rk−1 − rk)

, then ∀k > k0,
(cid:90) rk

rk
κr2(θ −1)
k−1

≥

1
2

(rk−1 − rk) ≥

1
2κd1

.

> 2r2(θ −1)
k−1
κ
1 − 2θ

When r2(θ −1)
k

, then r2θ −1

k

> 2

2θ −1
2(θ −1) r2θ −1

k−1 , and

ζ (rk) − ζ (rk−1) =

(r2θ −1
k

− r2θ −1
k−1 )

>

κ
1 − 2θ

(2

2θ −1
2(θ −1) − 1)r2θ −1

k−1 >

κ
1 − 2θ

(2

2θ −1
2(θ −1) − 1)r2θ −1

0

.

2θ −1

1−2θ (2

2(θ −1) − 1) and d2 = min{ 1
Let σ = κ
}, then
2κd1
∀k > k0, ζ (rk) − ζ (rk−1) ≥ d2, and ζ (rk) ≥ ζ (rk) − ζ (rk0) ≥
t=k0+1 ζ (rt ) − ζ (rt−1) ≥ (k − k0)d2. Hence, r2θ −1
∑k
κ (k −
k0)(1 − 2θ ), leading to rk ≤
1−2θ . Therefore, we

, σ r2θ −1
0

≥ d2

k

1

κ
d2(k−k0)(1−2θ )
(cid:16)

obtain Qi(xk)−Q∗

i ≤ Qi(vk)−Q∗

i = rk =

κ
d2(k−k0)(1−2θ )

(cid:17) 1

1−2θ .
(cid:4)

REFERENCES

[1] Gartner, http://www.gartner.com/newsroom/id/3165317, 2015, [Online;

accessed 19-June-2017].

[2] R. West, “The psychology of security,” Communications of the ACM,

vol. 51, no. 4, pp. 34–40, 2008.

[3] T. Basar and G. J. Olsder, Dynamic noncooperative game theory. SIAM,

1999, vol. 23.

[4] X. Gabaix, “A sparsity-based model of bounded rationality,” The Quar-
terly Journal of Economics, vol. 129, no. 4, pp. 1661–1710, 2014.
[5] R. Zhang, Q. Zhu, and Y. Hayel, “A bi-level game approach to attack-
aware cyber insurance of computer networks,” IEEE Journal on Selected
Areas in Communications, vol. 35, no. 3, pp. 779–794, 2017.

[6] Q. Zhu, Z. Yuan, J. B. Song, Z. Han, and T. Basar, “Interference aware
routing game for cognitive radio multi-hop networks,” IEEE Journal
on Selected Areas in Communications, vol. 30, no. 10, pp. 2006–2015,
2012.

[7] H. Takabi, J. B. Joshi, and G.-J. Ahn, “Security and privacy challenges
in cloud computing environments,” IEEE Security & Privacy, vol. 8,
no. 6, pp. 24–31, 2010.

[8] J. Chen and Q. Zhu, “Resilient and decentralized control of multi-level
cooperative mobile networks to maintain connectivity under adversarial
environment,” in IEEE Conference on Decision and Control (CDC),
2016, pp. 5183–5188.

[9] H. Wu and W. Wang, “A game theory based collaborative security
detection method for internet of things systems,” IEEE Transactions
on Information Forensics and Security, vol. 13, no. 6, pp. 1432–1445,
2018.

[10] H. Abie and I. Balasingham, “Risk-based adaptive security for smart iot
in ehealth,” in Proceedings of the 7th International Conference on Body
Area Networks, 2012, pp. 269–275.

[11] H. Kunreuther and G. Heal, “Interdependent security,” Journal of risk

and uncertainty, vol. 26, no. 2, pp. 231–249, 2003.

[12] Z. Xu and Q. Zhu, “A cyber-physical game framework for secure
and resilient multi-agent autonomous systems,” in IEEE Conference on
Decision and Control (CDC), 2015, pp. 5156–5161.

[13] J. Pawlick, S. Farhang, and Q. Zhu, “Flip the cloud: Cyber-physical
signaling games in the presence of advanced persistent
threats,” in
International Conference on Decision and Game Theory for Security.
Springer, 2015, pp. 289–308.

[14] J. Chen and Q. Zhu, “Interdependent strategic cyber defense and robust
switching control design for wind energy systems,” in IEEE Power &
Energy Society General Meeting, 2017, pp. 1–5.

[15] J. Pawlick, J. Chen, and Q. Zhu, “iSTRICT: An interdependent strategic
trust mechanism for the cloud-enabled internet of controlled things,”
IEEE Transactions on Information Forensics and Security, vol. 14, no. 6,
pp. 1654–1669, 2019.

[16] J. Chen and Q. Zhu, “Optimal contract design under asymmetric infor-
mation for cloud-enabled internet of controlled things,” in International
Conference on Decision and Game Theory for Security. Springer, 2016,
pp. 329–348.

[17] J. Chen and Q. Zhu, “Security as a service for cloud-enabled internet
of controlled things under advanced persistent threats: a contract design
approach,” IEEE Transactions on Information Forensics and Security,
vol. 12, no. 11, pp. 2736–2750, 2017.

[18] J. Chen and Q. Zhu, “A linear quadratic differential game approach
to dynamic contract design for systemic cyber risk management under
asymmetric information,” in 2018 56th Annual Allerton Conference on
Communication, Control, and Computing (Allerton).
IEEE, 2018, pp.
575–582.

[19] J. Chen, C. Touati, and Q. Zhu, “Heterogeneous multi-layer adversarial
network design for the iot-enabled infrastructures,” in IEEE Global
Communications Conference, 2017, pp. 1–6.

[20] J. Chen, T. Corinne, and Q. Zhu, “A dynamic game analysis and design
of infrastructure network protection and recovery,” ACM SIGMETRICS
Performance Evaluation Review, vol. 45, no. 2, pp. 125–128, 2017.
[21] J. Chen, C. Touati, and Q. Zhu, “Optimal secure two-layer IoT network
design,” IEEE Transactions on Control of Network Systems, 2019.
[22] M. O. Jackson and Y. Zenou, “Games on networks,” Handbook of game

theory, vol. 4, 2014.

[23] M. D. K¨onig, C. J. Tessone, and Y. Zenou, “Nestedness in networks: A
theoretical model and some applications,” Theoretical Economics, vol. 9,
no. 3, pp. 695–752, 2014.

[24] O. Baetz, “Social activity and network formation,” Theoretical Eco-

nomics, vol. 10, no. 2, pp. 315–340, 2015.

[25] J. Chen and Q. Zhu, “Interdependent network formation games with an
application to critical infrastructures,” in American Control Conference
(ACC), 2016, pp. 2870–2875.

[26] L. Huang, J. Chen, and Q. Zhu, “A large-scale markov game approach
to dynamic protection of interdependent infrastructure networks,” in
International Conference on Decision and Game Theory for Security.
Springer, 2017, pp. 357–376.

[27] L. Huang, J. Chen, and Q. Zhu, “A factored mdp approach to optimal
mechanism design for resilient large-scale interdependent critical infras-
tructures,” in Workshop on Modeling and Simulation of Cyber-Physical
Energy Systems (MSCPES), CPS Week, 2017, pp. 1–6.

[28] L. Huang, J. Chen, and Q. Zhu, “Distributed and optimal resilient
planning of large-scale interdependent critical infrastructures,” in Winter
Simulation Conference (WSC), 2018, pp. 1096–1107.

[29] L. Huang, J. Chen, and Q. Zhu, “Factored markov game theory for secure
interdependent infrastructure networks,” in Game Theory for Security
and Risk Management. Springer, 2018, pp. 99–126.

[30] Q. Zhu, C. Fung, R. Boutaba, and T. Basar, “Guidex: A game-theoretic
incentive-based mechanism for intrusion detection networks,” IEEE
Journal on Selected Areas in Communications, vol. 30, no. 11, pp. 2220–
2230, 2012.

[31] G. Gigerenzer and R. Selten, Bounded rationality: The adaptive toolbox.

MIT press, 2002.

[32] A. Ellis, “Foundations for optimal inattention,” Journal of Economic

Theory, vol. 173, pp. 56–94, 2018.

[33] J. Chen and Q. Zhu, “Security investment under cognitive constraints:
A gestalt nash equilibrium approach,” in 52nd Annual Conference on
Information Sciences and Systems (CISS), 2018, pp. 1–6.

[34] E. J. Candes and T. Tao, “Near-optimal signal recovery from random
projections: Universal encoding strategies?” IEEE transactions on infor-
mation theory, vol. 52, no. 12, pp. 5406–5425, 2006.

[35] R. G. Baraniuk, “Compressive sensing,” IEEE signal processing maga-

zine, vol. 24, no. 4, 2007.

[36] Y. Saad, Iterative methods for sparse linear systems. SIAM, 2003.
[37] J. Nocedal and S. Wright, Numerical optimization. Springer, 2006.
[38] H. H. Bauschke and P. L. Combettes, Convex analysis and monotone

operator theory in Hilbert spaces. Springer, 2011.

[39] N. Parikh, S. P. Boyd et al., “Proximal algorithms.” Foundations and

Trends in optimization, vol. 1, no. 3, pp. 127–239, 2014.

[40] R. T. Rockafellar and R. J.-B. Wets, Variational analysis.

Springer,

2009, vol. 317.

[41] H. Attouch, J. Bolte, P. Redont, and A. Soubeyran, “Proximal alternating
minimization and projection methods for nonconvex problems: An
approach based on the kurdyka-lojasiewicz inequality,” Mathematics of
Operations Research, vol. 35, no. 2, pp. 438–457, 2010.

[42] J. Bolte, S. Sabach, and M. Teboulle, “Proximal alternating linearized
minimization for nonconvex and nonsmooth problems,” Mathematical
Programming, vol. 146, no. 1-2, pp. 459–494, 2014.

[43] A. Beck and M. Teboulle, “Fast gradient-based algorithms for con-
strained total variation image denoising and deblurring problems,” IEEE
Transactions on Image Processing, vol. 18, no. 11, pp. 2419–2434, 2009.
[44] P. Frankel, G. Garrigos, and J. Peypouquet, “Splitting methods with vari-
able metric for Kurdyka–łojasiewicz functions and general convergence
rates,” Journal of Optimization Theory and Applications, vol. 165, no. 3,
pp. 874–900, 2015.

