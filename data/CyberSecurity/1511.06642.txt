5
1
0
2

v
o
N
0
2

]

C
O
.
h
t
a
m

[

1
v
2
4
6
6
0
.
1
1
5
1
:
v
i
X
r
a

Mean-ﬁeld-game model for Botnet defense in
Cyber-security

V. N. Kolokoltsov∗and A. Bensoussan†

September 1, 2018

Abstract

We initiate the analysis of the response of computer owners to various oﬀers of
defence systems against a cyber-hacker (for instance, a botnet attack), as a stochas-
tic game of a large number of interacting agents. We introduce a simple mean-ﬁeld
game that models their behavior. It takes into account both the random process of
the propagation of the infection (controlled by the botner herder) and the decision
making process of customers. Its stationary version turns out to be exactly solvable
(but not at all trivial) under an additional natural assumption that the execution
time of the decisions of the customers (say, switch on or out the defence system) is
much faster that the infection rates.

Mathematics Subject Classiﬁcation (2010):

Key words: botnet defence, mean-ﬁeld game, stable equilibrium, phase transitions

1

Introduction

A botnet, or zombie network, is a network of computers infected with a malicious program
that allows cybercriminals to control the infected machine remotely without the user’s
knowledge. Botnets have become a source of income for entire groups of cybercriminals
since the cost of running botnets is cheap and the risk of getting caught is relatively small
due to the fact that other people’s assets are used to launch attacks. The interactive
process of the attackers and defenders can be modeled as a Game. The use of game theory
in modeling attacker-defender has been extensively adopted in the computer security
domain recently; see [5], [22] and [24] and bibliography there for more details. Two
aspects are important. The ﬁrst one is the contamination eﬀect. The second one is the
large number of computers. So, in fact, one deals with a stochastic game of a large
number of interacting agents. This is amenable to Mean Field theory. To investigate
this approach represents the main objective of this paper. Our model takes into account

∗Department

of

Statistics, University

of Warwick, Coventry CV4

v.kolokoltsov@warwick.ac.uk and associate member of
CSC RAS

Institute of

7AL UK, Email:
Informatics Problems, FRC

†School of Management, The University of Texas at Dallas, P.O. Box 830688, SM 30 Richardson US,
Graduate School of Business, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong,
and Ajou University, Korea

1

 
 
 
 
 
 
both the random process of the propagation of the infection (controlled by the botnet
herder) and the decision making process of customers. We develop a stationary version
which turns out to be exactly solvable (but not at all trivial) under an additional natural
assumption that the execution time of the decisions of the customers (say, switch on or
out the defense system) is much faster that the infection rates.

Similar models can be applied to the analysis of defense against a biological weapon,
for instance by adding the active agent (principal interested in spreading the disease),
into the general mean-ﬁeld epidemic model of [23] that extends the well established SIS
(susceptible-infectious-susceptible) and SIR (susceptible-infectious-recovered) models.

Mean-ﬁeld games present a quickly developing area of the game theory. It was initiated
by Lasry-Lions [21] and Huang-Malhame-Caines [14], [15], see [1], [4], [13], [12], [6] for
recent surveys, as well as [8], [7], [9], [2], [20], [25], [3] and references therein. The papers
[10] and [11] initiated the study of ﬁnite-state space mean-ﬁeld games that are the objects
of our analysis here.

The paper is organized as follows. In the next section we introduce our model, formu-
late the basic mean-ﬁeld game (MFG) consistency problem in its dynamic and stationary
versions leading to precise formulation of our main problem of characterizing the stable
solutions (equilibria) of the stationary problem. This problem is a consistency problem
between an HJB equation for a stochastic control of individual players and a ﬁxed point
problem for an evolutionary dynamics. These two preliminary problems are fully ana-
lyzed in Sections 3 and 4 respectively. Section 5 is devoted to the ﬁnal synthesis of the
stationary MFG problem from the solutions to these two preliminary problems. In par-
ticular, the phase transitions and the bifurcation points changing the number of solutions
are explicitly found. In the last section further perspectives are discussed.

2 The model

Assume that any computer can be in 4 states: DI, DS, UI, US, where the ﬁrst letter, D
or U, refers to the state of a defended (by some system, which eﬀectiveness we are trying
to analyze) or an unprotected computer, and the second letter, S and I, to susceptible
or infected state. The change between D and U is subject to the decisions of computer
owners (though the precise time of the execution of her intent is noisy) and the changes
between S and I are random with distributions depending on the level of eﬀorts vH of
the Herder and the state D or U of the computer.

Let nDI, nDS, nU I, nU S denote the numbers of computers in the corresponding states
with N = nDS + nDI + nU I + nU S the total number of computers. By a state of the
system we shall mean either the 4-vector n = (nDI, nDS, nU I, nU S) or its normalized
version x = (xDI, xDS, xU I, xU S) = n/N. The fraction of defended computers xDI + xDS
represents the analogue of the control parameter vD from [5], the level of defense of the
system, though here it results as a compound eﬀect of individual decisions of all players.
The control parameter u of each player may have two values, 0 and 1, meaning that
the player is happy with the level of defense (D or I) or she prefers to switch one to
another. When the updating decision 1 is made, the updating eﬀectively occurs after
some exponential time with the parameter λ (measuring the speed of the response of the
defense system). The limit λ → ∞ corresponds to the immediate execution.

The recovery rates (the rates of change from I to S) are given constants qD

rec and qU
rec

2

inf and vHqU

inf respectively with constants qD

for defended and unprotected computers respectively, and the rates of infection from the
direct attacks are vH qD
inf . The rates of
infection spreading from infected to susceptible computers are βU U /N, βU D/N, βDU /N, βDD/N,
with numbers βU U , βU D, βDU , βDD, where the ﬁrst (resp second) letter in the index refers
to the state of the infected (resp. susceptible) computer (the scaling 1/N is necessary to
make the rates of unilateral changes and binary interactions comparable in the N → ∞
limit).

inf and qU

Thus if all computers use the strategy uDS, uDI, uU S, uU I, u ∈ {0, 1} and the level of
attack is vH, the evolution of the frequencies x in the limit N → ∞ can be described by
the following system of ODE:



˙xDI = xDSqD
˙xDS = −xDSqD
˙xU I = xU SqU
˙xU S = −xU SqU

inf vH − xDIqD

rec + xDIxDSβDD + xU IxDSβU D + λ(xU IuU I − xDIuDI),

inf vH + xDIqD

rec − xDI xDSβDD − xU I xDSβU D + λ(xU SuU S − xDSuDS),

inf vH − xU IqU

inf vH + xU IqU

rec + xDIxU SβDU + xU IxU SβU U − λ(xU IuU I − xDIuDI),



Remark 1. If all βU D, βU U , βDU , βU U are equal to some β, qD
rec =
qD
rec = vD, where vD is interpreted as the defender group’s combined defense eﬀort, then
summing up the ﬁrst and the third equations in (1) leads to the equation

rec − xDI xU SβDU − xU IxU SβU U − λ(xU SuU S − xDSuDS).

inf = qinf and qD

inf = qU

(1)

˙x = qinf vH(1 − x) + βx(1 − x) − vDx,

(2)

for the total fraction of infected computers x = xDI + xU I . This equation coincides (up to
some constants) with equation (2) from [5], which is the starting point of the analysis of
paper [5].

It is instructive to see, how evolution (1) can be deduced rigorously as the limit of the
Markov processes specifying the random dynamics of N players. The generator of this
Markov evolution on the states n is (where the unchanged values in the arguments of F
on the r.h.s are omitted)

LN F (nDI, nDS, nU I, nU S) = nDSqD

inf vH F (nDS −1, nDI + 1) + nU SqU

inf vHF (nU S −1, nU I + 1)

+nDIqD

recF (nDI − 1, nDS + 1) + nU IqU

recF (nU I − 1, nU S + 1)

+nDInDSβDDF (nDS − 1, nDI + 1)/N + nDInU SβDU F (nU S − 1, nU I + 1)/N

+nU InDSβU DF (nDS − 1, nDI + 1)/N + nU InU SβU U F (nU S − 1, nU I + 1)/N

+λnDSuDSF (nDS − 1, nU S + 1) + λnU SuU SF (nU S − 1, nDS + 1)

+λnDIuDIF (nDI − 1, nU I + 1) + λnU IuU IF (nU I − 1, nDI + 1),

or in terms of x as

LN F (xDI, xDS, xU I, xU S) = NxDSqD

inf vHF (x−eDS/N+eDI/N)+NxU SqU

inf vH F ((x−eU S/N+eU I/N)

+NxDI qD

recF (x − eDI/N + eDS/N) + NxU I qU

recF (x − eU I/N + eU S/N)

+NxDI xDSβDDF (x − eDS/N + eDI/N) + NxDIxU SβDU F (x − eU S/N + eU I/N)

3

+NxU I xDSβU DF (x − eDS/N + eDI/N) + NxU IxU SβU U F (x − eU S/N + eU I/N)

+NλxDSuDSF (x − eDS/N + eU S/N) + NλxU SuU SF (x − eU S/N + eDS/N)

+ NλxDI uDIF (x − eDI/N + eU I/N) + NλxU I uU IF (x − eU I/N + eDI/N),

(3)

where {ej} is the standard basis in R4.

If F is a diﬀerentiable function, the generator LN turns to the generator

LF (xDI, xDS, xU I, xU S) = xDSqD

inf vH

∂F
∂xDI

−

∂F
∂xDS (cid:19)

(cid:18)

+ xU SqU

inf vH

∂F
∂xU I

−

∂F
∂xU S (cid:19)

(cid:18)

+xDIqD
rec

+xDIxDSβDD

+xU I xDSβU D

+λxDSuDS

∂F
∂xDS

∂F
∂xDI

∂F
∂xDI

(cid:18)

(cid:18)

(cid:18)

∂F
∂xU S

(cid:18)

+ λxDIuDI

∂F
∂xU I

(cid:18)

−

−

−

∂F
∂xDI (cid:19)
∂F
∂xDS (cid:19)
∂F
∂xDS (cid:19)
∂F
∂xDS (cid:19)
∂F
−
∂xDI (cid:19)

−

+ xU IqU
rec

∂F
∂xU S

−

(cid:18)

+ xDIxU SβDU

(cid:18)

+ xU IxU SβU U

∂F
∂xU I

∂F
∂xU I

+ λxU SuU S

(cid:18)

+ λxU IuU I

(cid:18)
∂F
∂xDS

∂F
∂xDI

(cid:18)

−

∂F
∂xU I (cid:19)
∂F
−
∂xU S (cid:19)
∂F
∂xU S (cid:19)
∂F
∂xU S (cid:19)
∂F
∂xU I (cid:19)

−

−

(4)

in the limit N → ∞. This is a ﬁrst order partial diﬀerential operator. Its characteristics
are given precisely by the ODE (1). A rigorous derivation showing the solutions to (1)
describe the limit of the Markov chain generated by (3) can be found e.g. in [17].

We shall now use the Markov model above to assess the actions of individual players.
If x(t) and vH (t) are given, the dynamics of each individual player is the Markov chain

on 4 states with the generator

Lindg(DI) = λuind(DI)(g(UI) − g(DI)) + qD
Lindg(DS) = λuind(DS)(g(US) − g(DS)) + qD

rec(g(DS) − g(DI)),

inf vH (g(DI) − g(DS))

+ xDIβDD(g(DI) − g(DS)) + xU IβU D(g(DI) − g(DS)),
rec(g(US) − g(UI)),

Lindg(UI) = λuind(UI)(g(DI) − g(UI)) + qU
Lindg(US) = λuind(US)(g(DS) − g(US)) + qU

inf vH (g(UI) − g(US))

(5)

+ xDIβDU (g(UI) − g(US)) + xU IβU U (g(UI) − g(US))

depending on the individual control uind.

Assuming that an individual pays a fee kD per unit of time for the defense system and
kI per unit time for losses resulting from being infected, her cost during a period of time
T , that she tries to minimize, is

T

0
Z

(kD1D + kI1I) ds,

(6)

where 1D (resp. 1I) is the indicator function of the states DI, DS (resp. of the states DI,
UI). Assuming that the Herder has to pay kHvH per unit of time using eﬀorts vH and

4

receive the income f (x) depending on the distribution x of the states of the computers,
her payoﬀ, that she tries to maximize, is

T

0
Z

(fH(x) − kHvH) ds.

(7)

Therefore, starting with some control

ucom = (ucom

t

(DI), ucom

t

(DS), ucom

t

(UI), ucom

t

(US))

the Herder can ﬁnd his optimal strategy vH(t) solving the deterministic optimal control
problem with dynamics (1) and payoﬀ (7) ﬁnding both optimal vH and the trajectory
x(t). Once x(t) and vH(t) are known, each individual should solve the Markov control
problem (5) with costs (6) thus ﬁnding the individual optimal strategy

t = (uind
uind

t

(DI), uind

t

(DS), uind

t

(UI), uind

t

(US)).

The basic MFG consistency equation can now be explicitly written as

t = ucom
uind

t

.

Instead of analyzing this rather complicated dynamic problem, we shall look for a

simpler problem of consistent stationary strategies.

There are two standard stationary problems naturally linked with a dynamic one, one

being the search for the average payoﬀ

g = lim
T →∞

T

1
T

0
Z

(kD1D + kI1I) dt

for long period game, and another the search for discounted optimal payoﬀ. The ﬁrst is
governed by the solutions of HJB of the form (T − t)µ + g, linear in t (then µ describing
the optimal average payoﬀ), so that g satisﬁes the stationary HJB equation:

λ min
u
λ min
u

λ min
u
λ min
u

u(g(UI) − g(DI)) + qD

rec(g(DS) − g(DI)) + kI + kD = µ,

u(g(US) − g(DS)) + qD

inf vH(g(DI) − g(DS))

+ xDIβDD(g(DI) − g(DS)) + xU IβU D(g(DI) − g(DS)) + kD = µ,

u(g(DI) − g(UI)) + qU

rec(g(US) − g(UI)) + kI = µ,

u(g(DS) − g(US)) + qU

inf vH(g(UI) − g(US))

+ xDIβDU (g(UI) − g(US)) + xU IβU U (g(UI) − g(US)) = µ

(8)






where min is over two values {0, 1}. We shall denote u = (uDI, uU I, uDS, uU S) the argmax
in this solution.

The discounted optimal payoﬀ (with the discounting coeﬃcient δ) satisﬁes the sta-

tionary HJB

5






λ min
u
λ min
u

λ min
u
λ min
u

u(g(UI) − g(DI) + qD

rec(g(DS) − g(DI)) + kI + kD = δg(DI),

u(g(US) − g(DS)) + qD

inf vH (g(DI) − g(DS))

+ xDI βDD(g(DI) − g(DS)) + xU IβU D(g(DI) − g(DS)) + kD = δg(DS),

u(g(DI) − g(UI)) + qU

rec(g(US) − g(UI)) + kI = δg(UI),

(9)

u(g(DS) − g(US)) + qU

inf vH (g(UI) − g(US))

+ xDI βDU (g(UI) − g(US)) + xU IβU U (g(UI) − g(US)) = δg(US)

The analysis of these two settings is mostly analogous. We shall concentrate on the

ﬁrst one. Introducing the coeﬃcients

α = qD
β = qU

inf vH + xDIβDD + xU I βU D,
inf vH + xDIβDU + xU IβU U ,

(10)

the stationary HJB equation (8) rewrites as

rec(g(DS) − g(DI)) + kI + kD = µ,

λ min(g(UI) − g(DI), 0) + qD
λ min(g(US) − g(DS), 0) + α(g(DI) − g(DS)) + kD = µ,
λ min(g(DI) − g(UI), 0) + qU
rec(g(US) − g(UI)) + kI = µ,
λ min(g(DS) − g(US), 0) + β(g(UI) − g(US)) = µ,




where the choice of the ﬁrst term as the inﬁmum in these equations corresponds to the
choice of control u = 1.

(11)

The stationary MFG consistency problem is in ﬁnding x = (xDI, xDS, xU I, xU S) and

u = (uDI, uDS, uU I, uU S), where x is the stationary point of evolution (1), that is

xDSα − xDIqD
− xDSα + xDIqD
xU Sβ − xU IqU
− xU Sβ + xU IqU

rec + λ(xU IuU I − xDIuDI) = 0

rec + λ(xU SuU S − xDSuDS) = 0

rec − λ(xU IuU I − xDI uDI) = 0

rec − λ(xU SuU S − xDSuDS) = 0,

(12)






with u = (uDI, uDS, uU I, uU S) giving minimum in the solution to (8) or (11). Thus x is a
ﬁxed point of the limiting dynamics of the distribution of large number of agents such that
the corresponding stationary control is individually optimal subject to this distribution.
Yet in other words, x = (xDI, xDS, xU I, xU S) and u = (uDI, uDS, uU I, uU S) solve (8), (12)
simultaneously.

Fixed points can practically model a stationary behavior only if they are stable. Thus
we are interested in stable solutions (x, u) to the stationary MFG consistency problem
(12),(8), where a solution is stable if the corresponding stationary distribution x is a
stable equilibrium to (1) (with u ﬁxed by this solution).

Apart from stability, the ﬁxed points can be classiﬁed via its eﬃciency. Namely, let
us say that a solution to the stationary MFG is eﬃcient (or globally optimal) if the
corresponding average cost µ is minimal among all other solutions.

Talking about strategies, let us reduce the discussion to non-degenerate situations,
where the minima in (11) are achieved on a single value of u only. In principle, there are

6

16 possible pure stationary strategies (functions from the state space to {0, 1}). But not
all of them can be realized as solutions to (11). In fact if uDI = 1, then g(UI) < g(DI)
(can be equal in degenerate case) and thus uU I = 0. This argument forbids all but four
strategies as possible solutions to (11), namely

(i)
(ii)
(iii)
(iv)

g(UI) ≤ g(DI),
g(UI) ≥ g(DI),
g(UI) ≤ g(DI),
g(UI) ≥ g(DI),

g(US) ≤ g(DS) ⇐⇒ uU I = uU S = 0,
g(US) ≥ g(DS) ⇐⇒ uDI = uDS = 0,
g(US) ≥ g(DS) ⇐⇒ uU I = uDS = 0,
g(US) ≤ g(DS) ⇐⇒ uDI = uU S = 0,




(13)
The ﬁrst two strategies, either always choose U or always choose D, are acyclic, that
is the corresponding Markov processes are acyclic in the sense that there does not exist a
cycle in a motion subject to these strategies. Other two strategies choose between U and
D diﬀerently if infected or not.

uDI = uDS = 1,
uU I = uU S = 1,
uDI = uU S = 1,
uU I = uDS = 1.

Of course, allowing degenerate strategies, more possibilities arise.
To complete the model, let us observe that the natural assumptions on the parameters

of the model arising directly from their interpretation are as follows:

rec ≥ qU
qD
rec,
βU D ≤ βU U ,
kD ≤ kI.




inf ,

inf < qU
qD
βDD ≤ βDU ,

(14)

We shall always assume (14) hold. Two additional natural simplifying assumptions
that we shall use sometimes are the following: the infection rate does not depend on the
level of defense of the computer transferring the infection, but only on the level of defence
of the susceptible computer, that is, instead of four coeﬃcients β one has only 2 of them



βU = βDU = βU U ,

βD = βU D = βDD,

(15)

and the recovery rate do not depend on whether a computer is protected against the
infection or not:

rec = qU
As we shall see, a convenient assumption, which is weaker than (16), turns out to be

qrec = qD

rec.

(16)

rec − qU
qD

rec < (qU

inf − qD

inf )vH.

(17)

Finally, it is reasonable to assume that customers can switch rather quickly their
regime of defence (once they are willing to) meaning that we are eﬀectively interested in
the asymptotic regime of large λ. As we shall show, in this regime the stationary MFG
problem above can be completely solved analytically. In this sense the present model is
more complicated than a related mean-ﬁeld game model of corruption with three basic
states developed in [19], where a transparent analytic classiﬁcation of stable solutions is
available already for arbitrary ﬁnite λ.

3 Analysis of the stationary HJB equation

Let us start by solving HJB equation (11).

7

Consider strategy (i) of (13), so that being unprotected is always optimal. Then (11)

becomes

rec(g(DS) − g(DI)) + kI + kD = µ,

λ(g(UI) − g(DI)) + qD
λ(g(US) − g(DS)) + α(g(DI) − g(DS)) + kD = µ,
qU
rec(g(US) − g(UI)) + kI = µ,
β(g(UI) − g(US)) = µ.

(18)

As the solution g is deﬁned up to an additive constant we can set g(US) = 0. Then (18)
becomes

rec(g(DS) − g(DI)) + kI + kD = µ,

λ(g(UI) − g(DI)) + qD
− λg(DS) + α(g(DI) − g(DS)) + kD = µ,
− qU
βg(UI) = µ.

recg(UI) + kI = µ,









From the third and fourth equations we ﬁnd

g(UI) =

kI
β + qU
rec

, µ = βg(UI) =

βkI
β + qU
rec

.

Substituting these values in the ﬁrst and second equations we obtain

g(DS) =




g(DI) =

kD − µ
λ
kD − µ
λ

+ kI

+ kI

α(β + λ + qU

rec)

,

λ(β + qU

(α + λ)(β + λ + qU

rec)(α + λ + qD
rec)
rec)(α + λ + qD

λ(β + qU

rec)

rec)

,

and the conditions g(UI) ≤ g(DI), g(US) = 0 ≤ g(DS) become



kD(β + qU
kD(β + qU

rec)(α + λ + qD
rec)(α + λ + qD

rec) ≥ kI[(β + λ)qD
rec) ≥ kI[β(λ + qD

rec − (α + λ)qU
rec) − α(λ + qU

rec],
rec)]

respectively.

Consider strategy (ii) of (13), so that being defended is optimal. Then (11) becomes

Setting g(DS) = 0 yields

qD
rec(g(DS) − g(DI)) + kI + kD = µ,
α(g(DI) − g(DS)) + kD = µ,
λ(g(DI) − g(UI)) + qU
λ(g(DS) − g(US)) + β(g(UI) − g(US)) = µ.

rec(g(US) − g(UI)) + kI = µ,

recg(DI)) + kI + kD = µ,

− qD
αg(DI) + kD = µ,
λ(g(DI) − g(UI)) + qU
− λg(US)) + β(g(UI) − g(US)) = µ.

rec(g(US) − g(UI)) + kI = µ,









From the ﬁrst and second equations we ﬁnd

g(DI) =

kI
α + qD
rec

, µ = kD + αg(DI) =

α(kD + kI) + kDqD
rec
α + qD
rec

.

8

(19)

(20)

(21)

(22)

(23)

(24)

(25)

Substituting these values in the third and fourth equations we obtain

g(US) = −

g(UI) = −





kD
λ
kD
λ

+ kI

+ kI

β(λ + qD
λ(α + qD
(β + λ)(λ + qD
λ(α + qD

rec) − α(λ + qU
rec)(β + λ + qU
rec) − αqU
rec
rec)(β + λ + qU
rec)

rec)
rec)

.

,

g(US) ≥ g(DS) = 0 turn to

and the conditions g(UI) ≥ g(DI),

kD(α + qD
kD(α + qD

rec)(β + λ + qU
rec)(β + λ + qU

rec) ≤ kI[(β + λ)qD
rec) ≤ kI[β(λ + qD

rec − (α + λ)qU
rec) − α(λ + qU

rec],
rec)]

respectively.

Consider strategy (iii) of (13). Then (11) becomes

rec(g(DS) − g(DI)) + kI + kD = µ,

λ(g(UI) − g(DI)) + qD
α(g(DI) − g(DS)) + kD = µ,
qU
rec(g(US) − g(UI)) + kI = µ,
λ(g(DS) − g(US)) + β(g(UI) − g(US)) = µ.





Setting g(DS) = 0 yields

from the second equation, then

µ = αg(DI) + kD

λg(UI) = g(DI)(α + λ + qD

rec) − kI

from the ﬁrst equation and

g(US) =

g(DI)
λqU
rec

[αλ + qU

rec(α + λ + qD

rec)] +

λkD − (λ + qU

rec)kI

λqU
rec

from the third one. Plugging these expressions in the fourth equation of (28) we ﬁnd
(after many cancelations) g(DI) and then the other values of g:

(β + λ + qU

rec)(kI − kD)

,

α(β + λ + qU
kI[β(λ + qD
1
λ
1
λ

rec) + qU
rec) − α(λ + qU
α(β + λ + qU
rec)(λ + β) − αqU
α(β + λ + qU

kI[(λ + qD

rec(α + λ + qD

rec)
rec)] − kD(β + qU
rec) + qU

rec(α + λ + qD
rec)
rec)(α + λ + qD
rec] − kD(β + λ + qU
rec(α + λ + qD
rec) + qU
rec)

rec)

rec)(α + λ + qD

rec)

,

g(DI) =

g(US) =

g(UI) =






Hence

The conditions g(UI) ≤ g(DI),

µ =

kIα(β + λ + qU
α(β + λ + qU

rec) + kDqU
rec) + qU

rec(α + λ + qD
rec)

rec(α + λ + qD
g(US) ≥ g(DS) rewrite as

rec)

.

kD(α + qD
kD(α + λ + qD

rec)(β + λ + qU
rec)(β + qU

rec) ≥ kI[(β + λ)qD
rec) ≤ kI[β(λ + qD

rec − (α + λ)qU
rec) − α(λ + qU

rec],
rec)].

(

9

(26)

(27)

(28)

(29)

(30)

Consider strategy (iv) of (13). Then (11) becomes

qD
rec(g(DS) − g(DI)) + kI + kD = µ,
λ(g(US) − g(DS)) + α(g(DI) − g(DS)) + kD = µ,
λ(g(DI) − g(UI)) + qU
rec(g(US) − g(UI)) + kI = µ,
β(g(UI) − g(US)) = µ.

(31)





Setting g(US) = 0 yields µ = βg(UI) from the fourth equation, then

λg(DI) = g(UI)(β + λ + qU

rec) − kI

from the third equation and

λqD

recg(DS) = g(UI)[βλ + qD

rec(β + λ + qU

rec)] − kDλ − kI(λ + qD

rec)

from the ﬁrst one. Plugging these expressions in the second equation of (31) we ﬁnd
g(UI) and then the other values of g:

g(UI) =

g(DS) =

g(DI) =

(kD + kI)(α + λ + qD
rec) + qD

rec(β + λ + qU

rec)

,

kD(β + λ + qU

β(α + λ + qD
1
λ
1
λ

kD(β + λ + qU

rec)(α + qD
β(α + λ + qD

rec)
rec) + kI[α(λ + qU
rec) + qD

rec)(α + λ + qD
β(α + λ + qD

rec)

rec(β + λ + qU
rec) + kI[(α + λ)(λ + qU
rec(β + λ + qU

rec)

rec) + qD

rec) − β(λ + qD

rec)]

,

(32)

rec) − βqD

rec]






Hence the conditions g(UI) ≥ g(DI),

g(DS) ≥ g(US) = 0 rewrite as

kD(α + λ + qD
kD(α + qD

rec)(β + qU
rec)(β + λ + qU

rec) ≤ kI[(β + λ)qD
rec) ≥ kI[β(λ + qD

rec − (α + λ)qU
rec) − α(λ + qU

rec],
rec)].

(

.

(33)

We are now interested in ﬁnding out how many solutions equation (11) may have for
a given x. The ﬁrst observation in this direction is that the interior of the domain deﬁned
by (22) (that is, with a solution of case (i)) and the interior of the domain deﬁned by
(30) (that is, with a solution of case (iii)) do not intersect, because the ﬁrst inequality in
(22) contradicts the second inequality in (30) (apart from the boundary). Similarly, the
interior of the domain deﬁned by (22) (that is with a solution of case (i)) and the interior
of the domain deﬁned by (33) (that is, with a solution of case (iv)) do not intersect, and
the interior of the domain deﬁned by (27) (that is, with a solution of case (ii)) does not
intersect with the domains having solutions in cases (iii) or (iv).

Next we ﬁnd that one can distinguish two natural domains of x classifying the solutions

to HJB equation (11):

D1 = {x : β + qU

rec > α + qD

rec}, D2 = {x : β + qU

rec < α + qD

rec}.

More explicitly,

D1 = {x : xDI(βDU − βDD) + xU I(βU U − βU D) > (qD

inf − qU

inf )vH + qD

rec − qU

rec}.

10

By (14) it is seen that under a natural additional simplifying assumptions (16) or even

(17), all positive x belong to D1 (or its boundary), so that D2 is empty.

Under additional assumption (15) the condition x ∈ D1 gets a simpler form

x > ¯x =

(qD

inf − qU

inf )vH + qD
βU − βD

rec − qU
rec

.

(34)

To link with the conditions for cases (i)-(iv) one observes the following equivalent

forms of the main condition of being in D1:

β + qU

rec > α + qD

rec ⇐⇒ (β + qU

rec)(α + qD

rec + λ) > (α + qD

rec)(β + qU

rec + λ)

⇐⇒ β(λ + qD

rec) − α(λ + qU

rec) > (β + λ)qD

rec − (α + λ)qU

rec.

(35)

From here it is seen that if x belongs simultaneously to the interiors of the domains
speciﬁed by (22) and (27) (that is, with solutions in cases (i) and (ii) simultaneously),
then necessarily x ∈ D1 (that is, for x ∈ D2 the conditions specifying cases (i) and (ii)
are incompatible). On the other hand, if x belongs simultaneously to the interiors of
the domains speciﬁed by (30) and (33) (that is, with solutions in cases (iii) and (iv)
simultaneously), then necessarily x ∈ D2 (that is, for x ∈ D1 the conditions specifying
cases (iii) and (iv) are incompatible).

Denoting κ = kD/ki, we can summarize the properties of HJB equation (11) as follows

(uniqueness is always understood up to the shifts in g).

Proposition 3.1. Suppose x ∈ D1.

(1) If

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)(α + qD
rec)

< κ <

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec)(α + qD
rec + λ)

,

(36)

then there exists a unique solution to (11) belonging to case (iii) and there are no other
solutions to (11).

(2) If

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec + λ)(α + qD
rec)

< κ <

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)

rec)(α + qD

,

(37)

then there exists a unique solution to (11) belonging to case (iv) and there are no other
solutions to (11).

(3) A solution belonging to case (i) exists if and only if

κ ≥

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec)(α + qD
rec + λ)

,

and is unique if this holds. A solution belonging to case (ii) exists if and only if

κ ≤

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)(α + qD
rec)

,

(38)

(39)

and is unique if this holds. Either of conditions (38) or (39) is incompatible with either
(36) or (37). In particular, equation (11) may have at most two solutions (if both (38)
and (39) hold).

11

(4) Under (16), one has always

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec + λ)(α + qD
rec)

≥

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)

rec)(α + qD

,

and

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)(α + qD
rec)

≤

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec)(α + qD
rec + λ)

.

(40)

(41)

Hence (37) becomes impossible and conditions (38) and (39) become incompatible implying
the uniqueness of the solution to (11) for any x ∈ D1. This unique solution belongs to
cases (ii), (iii) and (i) respectively for κ satisfying (39), (36), (38) (when equality holds
in (38) or (39), two solutions from diﬀerent cases become coinciding).

Proof. Statements (1)-(3) follow from the arguments given above. (iv) Under (16), con-
ditions (41) and (40) rewrite as

qrec(β − α)2 − (β − α)(β + λ + qrec)(α + qrec) ≤ 0

and

qrec(β − α)2 + (β − α)(β + qrec)(α + λ + qrec) ≥ 0,

which obviously hold.

Remark 2. (1) When (16) does not hold one can ﬁnd situations when solutions from
cases (i) and (ii) exist simultaneously. To get simple examples one can assume κ = 1.
(2) When two solutions exist simultaneously one can discriminate them by the values of
the average payoﬀ µ. One sees from (20) and (25), that µ arising from cases (i) and (ii)
are diﬀerent (apart from a single value of κ). (3) The uniqueness result under (16) is
quite remarkable, as it does not seem to follow a priori from any intuitive arguments.

Again directly from the argument above one can conclude the following.

Proposition 3.2. Suppose x ∈ D2.

(1) If

κ >

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)

rec)(α + qD

,

(42)

then there exists a unique solution to (11) belonging to case (i) and there are no other
solutions to (11).

(2) If

κ <

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec + λ)(α + qD
rec)

,

(43)

then there exists a unique solution to (11) belonging to case (ii) and there are no other
solutions to (11).

(3) A solution belonging to case (iii) exists if and only if

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)(α + qD
rec)

≤ κ ≤

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec)(α + qD
rec + λ)

,

(44)

and is unique if this holds. A solution belonging to case (iv) exists if and only if

β(λ + qD
(β + qU

rec) − α(λ + qU
rec)
rec + λ)(α + qD
rec)

≤ κ ≤

12

(β + λ)qD
(β + qU

rec − (α + λ)qU
rec
rec + λ)

rec)(α + qD

,

(45)

and is unique if this holds. Either of conditions (44) or (45) is incompatible with either
(42) or (43). In particular, equation (11) may have at most two solutions (if (44) and
(45) hold simultaneously).

Essential simpliﬁcations that allow eventually for a full classiﬁcation of the stationary
MFG consistency problem occur in the limit of large λ. For a precise formulation in case

δ = qD

rec − qU

rec > 0

(46)

one needs further decomposition of the domains D1, D2. Namely, for j = 1, 2, let

Dj1 = {x ∈ Dj :

δ
α + qD
rec

<

β − α
β + qU
rec

}.

Proposition 3.3. The following hold for large λ outside an interval of κ of size of order
λ−1:

(1) Under (16) conditions (39), (36), (38) classifying the solutions to the HJB equation

rewrite as

κ ≤ 0,

0 < κ <

(β − α)
β + q

, κ ≥

(β − α)
β + q

,

(47)

respectively. In particular, solutions of case (ii) become impossible.

(2) Suppose x ∈ D1 and (46) holds. If x ∈ D11, there exists a unique solution to (11),

which belongs to cases (ii), (iii), (i) for

κ <

δ
α + qD
rec

,

δ
α + qD
rec

< κ <

β − α
β + qU
rec

, κ >

β − α
β + qU
rec

,

(48)

respectively. If x ∈ D12, solutions from case (iii) do not exist and there exist two solutions
to (11) for

β − α
β + qU
rec

< κ <

δ
α + qD
rec

,

(49)

belonging to cases (i) and (ii), and only one solution otherwise.

(3) Suppose x ∈ D2. If x ∈ D22, solutions from case (iii) do not exist and there is

always a unique solution to (11) belonging to case (ii), (iv) or (i), for

κ <

β − α
α + qD
rec

,

β − α
α + qD
rec

< κ <

δ
β + qU
rec

, κ >

δ
β + qU
rec

,

respectively. If x ∈ D21, then there are two solutions to (11) for

δ
α + qD
rec

< κ <

β − α
β + qU
rec

,

(50)

(51)

which belong to cases (iii) and (iv), and one solution otherwise. This unique solution
belongs to case (ii) or (i) for

κ <

β − α
α + qD
rec

, κ >

δ
β + qU
rec

respectively and to case (iv) otherwise.

13

Proof. Statement (ii) follows from the observation that, for δ > 0 and large λ, conditions
(36) - (37) turn to

δ
α + qD
rec

< κ <

β − α
β + qU
rec

,

β − α
α + qD
rec

< κ <

δ
β + qU
rec

respectively, and conditions (38) - (39) turn to

κ ≥

β − α
β + qU
rec

, κ ≤

δ
α + qD
rec

(52)

(53)

respectively. Other statements are similar.

4 Analysis of the ﬁxed points

Next we are solving the ﬁxed point system (12).

In case (i), that is with uU I = uU S = 0, uDI = uDS = 1, equation (12) takes the form

xDSα − xDIqD
− xDSα + xDIqD
xU Sβ − xU IqU
− xU Sβ + xU IqU

rec − λxDI = 0

rec − λxDS = 0

rec + λxDI = 0

rec + λxDS = 0.

(54)






Adding the ﬁrst two equations we get xDI = xDS = 0, and the system reduces to the
single equation

Substituting the value of β yields

xU Sβ − xU I qU

rec = 0.

xU S(qU

inf vH + xU IβU U ) − xU IqU

rec = 0.

Denoting y = xU I it follows that xU S = 1 − y and thus

QU (y) = βU U y2 + y(qU

rec − βU U + qU

inf vH) − qU

inf vH = 0.

This equation has a unique solution on the interval (0, 1):

1
2βU U

x∗ = x∗

U I =

inf vH )
(55)
The stability of the ﬁxed point x = (0, 0, x∗, 1 − x∗) means its stability as a ﬁxed point

βU U − qU
h

inf vH )2 + (qU

rec(βU U − qU

rec)2 − 2qU

(βU U + qU

rec − qU

inf vH +

q

.

i

of the dynamics






˙xDI = xDSα − xDIqD
˙xDS = −xDSα + xDIqD
˙xU I = xU Sβ − xU IqU
˙xU S = −xU Sβ + xU IqU

rec − λxDI

rec − λxDS

rec + λxDI

rec + λxDS.

14

(56)

We rewrite it by shifting the variables by the value of the stationary point, that is, in
terms of xDI, xDS, y = xU I − x∗, z = xU S − (1 − x∗). Since the sum of these variables is
one, we have eﬀectively the system of three equations on the variables xDI, xDS, y:

inf vH + xDIβDD + (x∗ + y)βU D]xDS − (λ + qD
inf vH + xDIβDD + (x∗ + y)βU D]xDS + qD

˙xDI = [qD
˙xDS = −[qD
˙y = (1 − x∗ − y − xDI − xDS)[qU

rec)xDI
recxDI − λxDS

inf vH + βDU xDI + βU U (y + x∗)] − (y + x∗)qU

rec + λxDS.





Its linear approximation around the ﬁxed point (0, 0, 0) is

rec)xDI + (qD

˙xDI = −(λ + qD
˙xDS = qD
˙y = (1 − x∗)[βDU xDI + βU U y] − (y + xDI + xDS)(qU

inf vH + x∗βU D + λ)xDS

inf vH + x∗βU D)xDS

recxDI − (qD

inf vH + x∗βU U ) − qU

recy + λxDS,






and the corresponding characteristic equation for the eigenvalues ξ is

[(1 − x∗)βU U − (qU

inf vH + x∗βU U ) − qU

rec − ξ]

×[(ξ + λ + qU

inf vH + x∗βU U )(ξ + λ + qD
The free term cancels in the second multiplier and we get the eigenvalues

inf vH + x∗βU U )] = 0.

rec) − qD

rec(qU

ξ1 = (1 − x∗)βU U − qU
ξ2 = −λ − (qD
ξ3 = −λ.

rec + qU




inf vH − x∗βU U − qU

rec

inf vH + x∗βU U )

(57)

The second and the third eigenvalues being negative, the condition of stability is reduced
to the negativity of the ﬁrst eigenvalue, that is, to the condition



2x∗ > 1 −

inf vH

rec + qU
qU
βU U

.

(58)

But it always holds for x∗ of form (55).

Thus we proved the ﬁrst part of the following statement and the second is analogous.

Proposition 4.1. (1) There exists a unique solution to system (12) with the strategy U
being individually optimal (that is, with the ﬁrst acyclic stationary strategy uU I = uU S =
0, uDI = uDS = 1) and it is stable. It equals x = (0, 0, x∗
U I given by
(55).

U I) with x∗

U I, 1 − x∗

(2) There exists a unique solution to system (12) with the strategy D being individually
optimal (that is, with the second acyclic stationary strategy) and it is stable. It equals
x = (x∗

DI being the unique solution of equation

DI, 0, 0) with x∗

DI , 1 − x∗

QD(y) = βDDy2 + y(qD

rec − βDD + qD

inf vH) − qD

inf vH = 0

(59)

on the interval (0, 1), that is

x∗
DI =

1
2βDD

rec − qD

inf vH +

βDD − qD
h

(βDD + qD

inf vH)2 + (qD

rec)2 − 2qD

rec(βDD − qD

inf vH)

q

15

.

i

Let us consider case (iii): uU I = uDS = 0, uDI = uU S = 1. Then (12) takes the form

xDSα − xDI qD
− xDSα + xDIqD
xU Sβ − xU I qU
− xU Sβ + xU I qU

rec − λxDI = 0

rec + λxU S = 0

rec + λxDI = 0

rec − λxU S = 0.

(60)






By adding the ﬁrst two equations we get xDI = xU S with two independent equations

left:

xDSα − (qD
xDI(β + λ) − xU IqU

rec + λ)xDI = 0
rec = 0.

(

This rewrites as two equations on the two independent variables xDI, xU I as

(1 − xU I − 2xDI)(qD
xDI(qU

inf vH + βDU xDI + βU U xU I + λ) − xU IqU

inf vH + βDDxDI + βU DxU I) − (qD
rec = 0.

rec + λ)xDI = 0

(

Solving the second equation with respect to xU I ,

xU I =

xDI(qU

inf vH + xDIβDU + λ)
qU
rec − βU U xDI

,

(61)

(62)

(63)

and substituting in the ﬁrst one, leads to a fourth order equation on y = xDI. This
equation does not seem to be much revealing in general. Of course it can be fully analyzed
by numeric methods, but we shall turn now to the large λ asymptotics that yields more
manageable results.

For large λ we get directly from (63) that

xU I =

xDIλ
qU
rec − βU U xDI

(1 + O(λ−1)).

But this implies that xDI is small of order O(λ−1), so that

xU I =

xDI λ
qU
rec

(1 + O(λ−1)),

xDI =

xU IqU
rec
λ

(1 + O(λ−1)).

Substituting this in the ﬁrst equation of (62) yields

βU Dx2

U I + xU I (qU

rec − βU D + qD

inf vH ) − qD

inf vH = O(λ−1),

(64)

(65)

which is of the same type as equations (59) up to terms of order λ−1 (and coincides with
it under (15), (16)). Therefore, for large λ, there exists a unique solution to (65) from the
interval (0, 1):

U I = O(λ−1)
¯x∗

+

1
2βU D

rec − qD

inf vH +

βU D − qU
h

(βU D + qD

inf vH)2 + (qU

rec)2 − 2qU

rec(βU D − qD

inf vH)

q

16

.

i
(66)

The stability of the ﬁxed point x = (x∗

DI, x∗

DS = 1 − ¯x∗

U I − 2x∗

DI, ¯x∗

U I, x∗

U S = x∗

DI)

means its stability as a ﬁxed point of the dynamics



˙xDI = xDSα − xDIqD
˙xDS = −xDSα + xDIqD
˙xU I = xU Sβ − xU IqU
˙xU S = −xU Sβ + xU I qU

rec − λxDI

rec + λxU S

rec + λxDI

rec − λxU S.



˜xDI = xDI − x∗
DI ,

In terms of independent variables

˜xU S = xU S − x∗

U S,

y = ˜xU I = xU I − ¯x∗

U I

this rewrites as

d
˜xDI = (1 − y − ¯x∗
dt
˙y = ˜xU Sβ − (y + ¯x∗
d
dt






with

U I − ˜xDI − ˜xU S)α − ˜xDIqD
U I)qU

rec + λ(˜xDI + x∗

DI) + O(λ−1)

rec − λ(˜xDI + x∗

DI) + O(λ−1)

˜xU S = −˜xU Sβ + (y + ¯x∗

U I)qU

rec − λ(˜xU S + x∗

U S) + O(λ−1).

α = qD

inf vH + ˜xDIβDD + (y + ¯x∗
inf vH + ˜xDIβDU + (y + ¯x∗
Linearized around the ﬁxed point (0, 0, 0) system (68) takes the form

U I )βU D + O(λ−1),
U I )βU U + O(λ−1).

β = qU

(67)

(68)

inf vH + ¯x∗

U IβU D) + (1 − ¯x∗

U I)(˜xDIβDD + ˜xU IβU D) − ˜xDI(qD

rec + λ)

˜xDI = −(y + ˜xDI + ˜xU S)(qD
inf vH + ¯x∗

U IβU U ) − ˜xU IqU

rec + λ˜xDI



d
dt
˙y = ˜xU S(qU
d
dt

˜xU S = −˜xU S(qU



up to terms of order O(λ−1). Thus the matrix of the linear approximation divided by λ
is

U IβU U ) + ˜xU IqU

inf vH + ¯x∗

rec − λ˜xU S

O(λ−1) − 1 [−qD
O(λ−1) + 1
O(λ−1)

recvH + βU D(1 − 2¯x∗
rec/λ + O(λ−2)
− qU
O(λ−1)

U I)]/λ + O(λ−2)

O(λ−1)
O(λ−1)
O(λ−1) − 1

.






M(λ) = 




The ﬁrst order approximation of this matrix in λ−1 is

− 1 0
0
0
1 0
0 0 − 1

.






M0 = 




and has eigenvalue −1 of double multiplicity and a zero eigenvalue. Hence all eigenvalues
of M(λ) are negative if and only if its determinant det(M(λ)) is negative. As seen directly

det(M(λ)) = [−qU

rec − qD

recvH + βU D(1 − 2¯x∗

U I)]/λ + O(λ−2),

17

and is negative for large λ if and only if

βU D(2¯x∗

U I − 1) > qU

rec + qD

recvH,

which always holds by (66). Thus we proved the ﬁrst part of the following statement and
the second part is analogous.

Proposition 4.2. (1) For large λ there exists a unique solution to system (12) in case
(iii), that is with uU I = uDS = 0, uDI = uU S = 1, and it is stable.
It has the form
x = (0, 1 − ¯x∗
U I being the unique solution
of equation (65) on (0, 1) given by (66).

U I, 0) up to corrections of order λ−1, with ¯x∗

U I , ¯x∗

(2) For large λ there exists a unique solution to system (12) in case (iv), that is with
U I)

uU I = uDS = 1, uDI = uU S = 0, and it is stable. It has the form x = (¯x∗
up to corrections of order λ−1, with ¯x∗

DI being the unique solution of equation

DI, 0, 0, 1 − ¯x∗

βDU x2

DI + xDI (qU

rec − βDU + qU

inf vH ) − qU

inf vH = O(λ−1),

(69)

on (0, 1).

5 Solutions to the stationary MFG problem

Combining Propositions 4.1, 4.2 and 3.3 allows one to fully characterize the solutions to
our stationary MFG consistency problem for large λ.

The most straightforward general conclusion is the following.

Theorem 5.1. For large λ there may exist up to 4 solutions to the stationary MFG
problem, with only one in each of the cases (i) -(iv). All these solutions are stable.

Remark 3. Notice that already this statement is not at all obvious a priori, and may not
be true for ﬁnite λ, where solutions to case (iii) or (iv) are found from an equation of
fourth order.

As an example of more precise classiﬁcation, let us present it under assumption (17)

that ensures that all solutions lie in the domain D1.

Let us introduce the function

κ(z) =

(qU

inf − qD
inf )vH + z(βU U − βU D)
qU
inf vH + zβU U + q

.

First let (16) hold. It is seen from Propositions 4.1 and 4.2 that for large λ, (and apart
from κ from negligible intervals of size of order λ−1 that we shall ignore), a solution of
the stationary MFG problem exists in case (i) if

κ > κ∗ = κ(x∗

U I ),

and a solution of the stationary MFG problem exists in case (iii) if

κ < ¯κ∗ = κ(¯x∗

U I ),

U I and ¯x∗

where x∗
U I are given by (55) and (66) respectively. Thus one can have up to
two (automatically stable) solutions to the stationary MFG problem. Let us make this
number precise.

18

Diﬀerentiating κ(z) we ﬁnd directly that it is increasing if

βU U (qD

inf vH + q) > βU D(qU

inf vH + q),

(70)

and decreasing otherwise. Hence the relation κ∗ > ¯κ∗ is equivalent to the same or the
opposite relation for x∗

U I. Thus we are led to the following conclusion.

U I and ¯x∗

Theorem 5.2. Let (16) hold.
(1) If (70) holds and x∗

U I > ¯x∗

U I, or the opposite to (70) holds and x∗

U I , then
κ∗ > ¯κ∗. Consequently, for κ < ¯κ∗ there exists a unique solution to the stationary MFG
problem, which is stable and belongs to case (iii); for κ ∈ ( ¯κ∗, κ∗) there are no solutions
to the stationary MFG problem; for κ > κ∗ there exists a unique solution to the stationary
MFG problem, which is stable and belongs to case (i).

U I < ¯x∗

U I < ¯x∗

(2) If (70) holds and x∗

U I, or the opposite to (70) holds and x∗

U I , then
κ∗ < ¯κ∗. Consequently, for κ < κ∗ there exists a unique solution to the stationary MFG
problem, which is stable and belongs to case (iii); for κ ∈ (κ∗, ¯κ∗) there exist two (stable)
solutions to the stationary MFG problem; for κ > ¯κ∗ there exists a unique solution to the
stationary MFG problem, which is stable and belongs to case (i).

U I > ¯x∗

Thus if one considers the system for all parameters ﬁxed except for κ (essentially
specifying the price of the defence service), points κ∗ and ¯κ∗ are the bifurcation points,
where the phase transitions occur.

To deal with case when (16) does not hold let us introduce the numbers

κ1 =

β − α
β + qU
rec
U I , x∗

(x∗

U I), κ2 =

δ
α + qD
rec

(x∗

DI), κ3 =

δ
α + qD
rec

(¯x∗

U I ), κ4 =

β − α
β + qU
rec

(¯x∗

U I),

DI, ¯x∗

where x∗
U I in brackets mean that α, β deﬁned in (10) are evaluated at the corre-
sponding solutions given by Propositions 4.1 and 4.2. Since x∗
U I are expressed in
terms of diﬀerent parameters, any order relation between them are to be expected in gen-
eral. Of course, restrictions appear under additional assumptions, for instance x∗
DI = ¯x∗
under (15). From Proposition 3.3 we deduce the following.

DI, ¯x∗

U I, x∗

U I

Theorem 5.3. Let (17) and (46) hold.

Depending on the order relation between x∗

U I, one can have up to 3 solutions
to the stationary MFG problem for large λ, the characterization in each case being fully
explicit, since for κ > κ1, there exists a unique solution in case (i), for κ < κ2, there
exists a unique solution in case (ii), for κ3 < κ < κ4, there exists a unique solution in
case (iii).

DI, ¯x∗

U I, x∗

Thus in this case the points κ1, κ2, κ3, κ4 are the bifurcation points, where the phase

transitions occur.

The situation when (17) does not hold is analogous, though there appears an additional
bifurcation relating to x crossing the border between D1 and D2, and the possibility of
having four solutions arises.

6 Discussion

Our model of four basic states is of course the simplest one that takes eﬀective account
It suggests extensions in
of both interaction (infection) and rational decision making.

19

various directions. For instance, it is practically important to allow for the choice of
various competing protection systems, leading to a model with 2d basic states: iI and iS,
where i ∈ {1, · · · , d} denotes the ith defense system available (which can be alternatively
interpreted as the levels of protection provided by a single or diﬀerent ﬁrms), while S
and I denote again susceptible or infected state, with all other parameters depending
on i. On the other hand, in the spirit of papers [18], [17] that concentrate on modeling
myopic behavior (rather than rational optimization) of players one can consider the set of
computer owners consisting of two groups, rational optimizers and those changing their
strategies by copying their neighbors.

The main theoretical question arising from our results concerns the rigorous relation
between stationary and dynamic MFG solutions, which in general is in front of research
in the mean-ﬁeld game literature. We hope that working with our simple model with fully
solved stationary version can help to get new insights in this direction. In the present
context the question can be formulated as follows. Suppose that, if at some moment of
time N players are distributed according certain frequency vector x among the four basic
state, each player chooses the optimal strategy u arising from the solution of the stationary
problem for ﬁxed x (fully described in Section 3), and the Markov evolution continues
according to the generator L. When two solutions are available, players may be supposed
to choose the one with the lowest µ (see see Remark 2 (2)). The resulting changes in x
induce the corresponding changes of u specifying a well-deﬁned Markov process on the
states of N agents. Intuitively, we would expect this evolution stay near our stationary
MFG solutions for large N and t. Can one prove something like that?

References

[1] M. Bardi, P. Caines and I. Capuzzo Dolcetta. Preface: DGAA special issue on mean

ﬁeld games. Dyn. Games Appl. 3:4 (2013), 443 – 445.

[2] R. Basna, A. Hilbert and V. Kolokoltsov. An epsilon-Nash equilibrium for non-linear
Markov games of mean-ﬁeld-type on ﬁnite spaces. Commun. Stoch. Anal. 8:4 (2014),
449 - 468.

[3] D. Bauso, H. Tembine, and T. Basar. Robust mean-ﬁeld games. Dynamic Games and

Applications, online, 6 June 2015, 10.1007/s13235-015-0160-4

[4] A. Bensoussan, J. Frehse, P. Yam. Mean Field Games and Mean Field Type Control

Theory. Springer, 2013.

[5] A Bensoussan, S. Hoe and M. Kantarcioglu. A Game-Theoretical Approach for Find-
ing Optimal Strategies in a Botnet Defense Model. Decision and Game Theory for
Security First International Conference, GameSec 2010, Berlin, Germany, November
22-23, 2010. Proceeding, T. Alpcan, L. Buttyan, and J. Baras (Eds.), Vol. 6442 pp.
135-148.

[6] P. E. Caines, “Mean Field Games”, Encyclopedia of Systems and Control, Eds. T.
Samad and J. Ballieul. Springer Reference 364780; DOI 10.1007/978-1-4471-5102-9
30-1, Springer-Verlag, London, 2014.

20

[7] P. Cardaliaguet, J-M. Lasry, P-L. Lions and A. Porretta. Long time average of mean
ﬁeld games with a nonlocal coupling. SIAM J. Control Optim. 51:5 (2013), 3558 –
3591.

[8] R. Carmona and D. Lacker. A probabilistic weak formulation of mean ﬁeld games

and applications. Ann. Appl. Probab. 25:3 (2015), 1189 – 1231.

[9] R. Carmona and F. Delarue. Probabilistic analysis of mean-ﬁeld games. SIAM J.

Control Optim. 514 (2013), 2705 – 2734.

[10] D. A. Gomes, J. Mohr and R. R. Souza. Discrete time, ﬁnite state space mean feld

games. J. Math. Pures Appl. 93:3 (2010), 308-328.

[11] D. A. Gomes, J. Mohr and R. R. Souza. Continuous time ﬁnite state space mean feld

games. Appl. Math. Optim. 68:1 (2013), 99-143.

[12] D. A. Gomes and J. Saude. Mean ﬁeld games models – a brief survey. Dyn. Games

Appl. 4:2 (2014), 110 – 154.

[13] O. Gu´eant O, J-M. Lasry and P-L. Lions. Mean Field Games and Applications.
Paris-Princeton Lectures on Mathematical Finance 2010. Lecture Notes in Math.
2003, Springer, Berlin, p. 205-266.

[14] M. Huang, R. Malham´e, P. Caines. Large population stochastic dynamic games:
closed-loop Mckean-Vlasov systems and the Nash certainty equivalence principle.
Communications in information and systems 6 (2006), 221 – 252.

[15] M. Huang, P. Caines and R. Malham´e. Large-Population Cost-Coupled LQG Prob-
lems With Nonuniform Agents: Individual-Mass Behavior and Decentralized ǫ-Nash
Equilibria. IEEE Trans Automat Control 52:9 (2007), 1560 – 1571.

[16] V. N. Kolokoltsov. Nonlinear Markov processes and kinetic equations. Cambridge
Tracks in Mathematics 182, Cambridge Univ. Press, 2010. See the review of Prof. D.
Applebaum in Bull. London Math. Soc. (2011) 43(6): 1245-1247.

[17] V. N. Kolokoltsov. Nonlinear Markov games on a ﬁnite state space (mean-ﬁeld and
binary interactions). International Journal of Statistics and Probability 1:1 (2012),
77-91. http://www.ccsenet.org/journal/index.php/ijsp/article/view/16682

[18] V. N. Kolokoltsov. The evolutionary game of pressure (or interference), resistance

and collaboration (2014). http://arxiv.org/abs/1412.1269

[19] V. N. Kolokoltsov and O. A. Malafeyev. Mean ﬁeld game model of corruption (2015).

http://arxiv.org/abs/1507.03240

[20] V. Kolokoltsov, M. Troeva and W. Yang. On the rate of convergence for the mean-
ﬁeld approximation of controlled diﬀusions with large number of players. Dyn. Games
Appl. 4:2 (2014), 208 – 230.

[21] J-M. Lasry and P-L. Lions. Jeux `a champ moyen. I. Le cas stationnaire (French).

C.R. Math. Acad. Sci. Paris 343:9 (2006) 619-625.

21

[22] Zh. Li, Q. Liao and A. Striegel. Botnet Economics: Uncertainty Matters.

http://weis2008.econinfosec.org/papers/Liao.pdf

[23] J. Liu, Y. Tang and Z. R. Yang. The spread of disease with birth and death on net-
works. arXiv:q-bio/0402042v3. Published in Journal of Statistical Mechanics: Theory
and Experiment, 2004.

[24] K-W. Lye, J. M. Wing. Game strategies in network security. Int J Inf Secur 4 (2005),

71 - 86.

[25] H. Tembine, Q. Zhu and T. Basar. Risk-sensitive mean-ﬁeld games. IEEE Trans.

Automat. Control 59:4 (2014), 835 – 850.

22

