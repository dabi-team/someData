7
1
0
2

g
u
A
4
2

]

R
C
.
s
c
[

1
v
8
1
5
7
0
.
8
0
7
1
:
v
i
X
r
a

Uniﬁed Host and Network Data Set

Melissa J. M. Turcotte∗, Alexander D. Kent∗ and Curtis Hash†
∗Los Alamos National Laboratory, Los Alamos, NM, 87545, U.S.A.
mturcotte@lanl.gov
†Ernst & Young

Abstract

The lack of data sets derived from operational enterprise networks continues to be a critical deﬁciency
in the cyber security research community. Unfortunately, releasing viable data sets to the larger com-
munity is challenging for a number of reasons, primarily the diﬃculty of balancing security and privacy
concerns against the ﬁdelity and utility of the data. This chapter discusses the importance of cyber secu-
rity research data sets and introduces a large data set derived from the operational network environment
at Los Alamos National Laboratory. The hope is that this data set and associated discussion will act as
a catalyst for both new research in cyber security as well as motivation for other organizations to release
similar data sets to the community.

1 Introduction

The lack of diverse and useful data sets for cyber security research continues to play a profound and limiting
role within the relevant research communities and their resulting published research. Organizations are
reticent to release data for security and privacy reasons. In addition, the data sets that are released are
encumbered in a variety of ways, from being stripped of so much information that they no longer provide
rich research and analytical opportunities, to being so constrained by access restrictions that key details are
lacking and independent validation is diﬃcult. In many cases, organizations do not collect relevant data
in suﬃcient volumes or with high enough ﬁdelity to provide cyber research value. Unfortunately, there is
generally little motivation for organizations to overcome these obstacles.

In an attempt to help stimulate a larger research eﬀort focused on operational cyber data as well as
to motivate other organizations to release useful data sets, Los Alamos National Laboratory (LANL) has
released two data sets for public use (Kent, 2016, 2014). A third, entitled the “Uniﬁed Host and Network
Data Set,” is introduced in this chapter.

The Uniﬁed Host and Network Data Set is a subset of network ﬂow and computer events collected from
the LANL enterprise network over the course of approximately 90 days.1 The host (computer) event logs
originated from the majority of LANL’s computers that run the Microsoft Windows operating system. The
network ﬂow data originated from many of the internal core routers within the LANL enterprise network
and are derived from router netﬂow records. The two data sets include many of the same computers but are
not fully inclusive; the network data set includes many non-Windows computers and other network devices.
Identifying values within the data sets have been de-identiﬁed (anonymized) to protect the security of
LANL’s operational IT environment and the privacy of individual users. The de-identiﬁed values match
across both the host and network data allowing the two data elements to be used together for analysis and
research. In some cases, the values were not de-identiﬁed, including well-known network ports, system-level
usernames (not associated to people) and core enterprise hosts. In addition, a small set of hosts, users and
processes were combined where they represented well-known, redundant entities. This consolidation was
done for both normalization and security purposes.

1The network ﬂow data are only 89 days due to missing data on the ﬁrst day.

1

 
 
 
 
 
 
In order to transform the data into a format that is useful for researchers who are not domain experts,
a signiﬁcant eﬀort was made to normalize the data while minimizing the artifacts that such normalization
might introduce.

1.1 Related public data sets

A number of public, cyber security relevant data sets currently exist Glasser and Lindauer (2013); Cyber
Systems and Technology Group (1998); imp; mal; Ma et al. (2009); Canadian Institute for Cybersecurity.
Some of these represent data collected from operational environments, while others capture speciﬁc, pseudo
real-world events (for example, cyber security training exercises). Many data sets are synthetic and created
using models intended to represent speciﬁc phenomenon of relevance; for example, the Carnegie Melon
Software Engineering Institute provides several insider threat data sets that are entirely synthetic Glasser
and Lindauer (2013). In addition, many of the data sets commonly seen within the research community
are egregiously dated. The DARPA cyber security data sets Cyber Systems and Technology Group (1998)
published in the 1990s are still regularly used, even though the systems, networks and attacks they represent
have almost no relevance to modern computing environments.

Another issue is that many of the available data sets have restrictive access and constraints on how they
may be used. For example, the U.S. Department of Homeland Security provides the Information Marketplace
for Policy and Analysis of Cyber-risk and Trust (IMPACT) imp, which is intended to facilitate information
sharing. However, the use of any of the data hosted by IMPACT requires registration and vetting prior to
access. In addition, data owners may (and often do) place limitations on how and where the data may be
used.

Finally, many of the existing data sets are not adequately characterized for potential researchers. It is
important that researchers have a thorough understanding of the context, normalization processes, idiosyn-
cracies and other aspects of the data. Ideally, researchers should have suﬃciently detailed information to
avoid making false assumptions and to reproduce similar data. The need for such detailed discussion around
published data sets is a primary purpose of this chapter.

The remainder of this chapter is organized as follows: a description of the Network Flow Data is given
in Section 2 followed by the Windows Host Log Data in Section 3. Finally, a discussion of potential research
directions is given in Section 4.

2 Network Flow Data

The network ﬂow data set included in this release is comprised of records describing communication events
between devices connected to the LANL enterprise network. Each ﬂow is an aggregate summary of a
(possibly) bi-directional network communication between two network devices. The data are derived from
Cisco NetFlow Version 9 Claise (2004) ﬂow records exported by the core routers. As such, the records
lack the payload-level data upon which most commercial intrusion detection systems are based. However,
research has shown that ﬂow-based techniques have a number of advantages and are successful at detecting a
variety of malicious network behaviors Sperotto et al. (2010). Furthermore, these techniques tend to be more
robust against the vagaries of attackers, because they are not searching for speciﬁc signatures (e.g., byte
patterns) and they are encryption-agnostic. Finally, in comparison to full-packet data, collection, analysis
and archival storage of ﬂow data at enterprise scales is straightforward and requires minimal infrastructure.

2.1 Collection & Transformation

As mentioned previously, the raw data consisted of NetFlow V9 records that were exported from the core
network routers to a centralized collection server. While V9 records can contain many diﬀerent ﬁelds, only
the following are considered: StartTime, EndTime, SrcIP, DstIP, Protocol, SrcPort, DstPort, Packets and
Bytes. The speciﬁcs of the hardware and ﬂow export protocol are largely irrelevant, as these ﬁelds are
common to all network ﬂow formats of which the authors are aware.

2

Field Name

Description

Time
Duration
SrcDevice
DstDevice
Protocol
SrcPort
DstPort
SrcPackets
DstPackets
SrcBytes
DstBytes

The start time of the event in epoch time format.
The duration of the event in seconds.
The device that likely initiated the event.
The receiving device.
The protocol number.
The port used by the SrcDevice.
The port used by the DstDevice.
The number of packets the SrcDevice sent during the event.
The number of packets the DstDevice sent during the event.
The number of bytes the SrcDevice sent during the event.
The number of bytes the DstDevice sent during the event.

Table 1: Bi-directional ﬂow data

This data can be quite challenging to model without a thorough understanding of its various idiosyn-
crasies. The following paragraphs discuss two of the most relevant issues with respect to modelling. For a
comprehensive overview of these issues, among others, readers can refer to Hofstede et al. (2014).

Firstly, note that these ﬂow records are uni-directional (uniﬂows): each record describes a stream of
packets sent from one network device (SrcIP ) to another (DstIP ). Hence, an established TCP connection
— bi-directional by deﬁnition — between two network devices, A and B, results in two ﬂow records: one
from A to B and another from B to A. It follows that there is no relationship between the direction of a
ﬂow and the initiator of a bi-directional connection (i.e., it is not known whether A or B connected ﬁrst).
This is the case for most netﬂow implementations as bi-directional ﬂow (biﬂow ) protocols such as Trammell
and Boschi (2008) have yet to gain widespread adoption. Clearly, this presents a challenge for detection of
attack behaviors, such as lateral movement, where directionality is of primary concern.

Secondly, signiﬁcant duplication can occur due to ﬂows encountering multiple netﬂow sensors in transit
to their destination. Routers can be conﬁgured to track ﬂows on ingress and egress, and, in more complex
network topologies, a single ﬂow can traverse multiple routers. More recently, the introduction of netﬂow-
enabled switches and dedicated netﬂow appliances has exacerbated the issue. Ultimately, a single ﬂow can
result in many distinct ﬂow records. To add further complexity, the ﬂow records are not necessarily exact
duplicates and their arrival times can vary considerably; these inconsistencies occur for many reasons, the
particulars of which are too complex to discuss in this context.

In order to simplify the data for modelling, a transformation process known as biﬂowing or stitching
was employed. This is a process intended to aggregate duplicates and marry the opposing uniﬂows of bi-
directional connections into a single, directed biﬂow record (Table 1). Many approaches to this problem can
be found in the literature Minarik et al. (2009); Nguyen et al. (2017); Barbosa (2014); Berthier et al. (2010),
all of them imperfect. A straightforward approach was used that relies on simple port heuristics to decide
direction. These heuristics are based on the assumption that SrcPorts are generally ephemeral (i.e., they are
selected from a pre-deﬁned, high range by the operating system), while DstPorts tend to have lower numbers
that correspond to established, shared network services and will therefore be observed more frequently than
ephemeral ports. The heuristics are given below in order of precedence.

• Destination ports are less than 1024 and source ports are not.

• The top 90 most frequently observed ports are destination ports.

• The smaller of the two ports is the destination port.

Each uniﬂow was transformed into a biﬂow by renaming the Packets and Bytes ﬁelds to SrcPackets and
SrcBytes respectively. DstPackets and DstBytes ﬁelds were added with initial values of zero. Next, the port
heuristics were considered and, if any were violated or ambiguous, the Src and Dst attributes were swapped,

3

eﬀectively reversing the direction. Finally, the 5-tuple was extracted from each record and used as the key
in a lookup table.

SrcIP, DstIP, SrcPort, DstPort, Protocol

If a match was found, the ﬂows were aggregated by keeping the minimum StartTime, maximum EndTime
and summing the other attributes. If no match was found, the ﬂow was simply added to the table. This
process was performed in a streaming fashion on all of the records in the order in which they were received
by the collector. Flows were periodically evicted from the lookup table after 30 minutes of inactivity (i.e.,
failing to match with any incoming ﬂows). Flows that remained active for long periods of time were reported
approximately every 3 hours, but were not evicted from the table until inactive.

While biﬂowing the data mitigates the problems posed by duplicates and ambiguous directionality, it
does not address another signiﬁcant obstacle: the lack of stable identiﬁers upon which to build models.
In some cases, IP addresses are transient (e.g., DHCP, VPN). In other cases, devices have multiple IP
addresses (e.g., multihoming) or one IP address is shared by multiple devices (e.g., load-balancing, NAT).
Whatever the case may be, modelling the behavior of IP addresses on a typical network is clearly error
prone. Instead, one should endeavor to map IP addresses to more stable identiﬁers such as Media Access
Control (MAC) addresses or fully-qualiﬁed domain names (FQDN), interchangeably referred to as hostnames
throughout the rest of the chapter. As with directionality, there is no perfect solution to this problem. The
most appropriate identiﬁer will depend greatly on the conﬁguration of the target network, as well as the
availability of auxiliary data sources from which a mapping can be constructed. An ideal solution will likely
involve some combination of supplementary network data (e.g., DNS logs, DNS zone transfers, DHCP logs,
VPN logs, NAC logs), business rules and considerable trial and error.

For this data release, a combination of Domain Name Service (DNS) and Dynamic Host Conﬁguration
Protocol (DHCP) logs was used to construct a mapping of IP addresses to FQDNs over time. The IP
addresses in each biﬂow were then replaced with their corresponding FQDNs at the time of the ﬂow. Where
a given IP address and timestamp mapped to multiple FQDNs, business rules were incorporated to give
preference to the least-ephemeral name. IP addresses that failed to map to any FQDN were left as-is. The
resulting mix of names and IP addresses correspond to the SrcDevice and DstDevice ﬁelds in the ﬁnal data.
Finally, the data were de-identiﬁed by mapping SrcDevice, DstDevice, SrcPort and DstPort to random
identiﬁers. In the event that the IP-to-FQDN mapping failed, the random identiﬁer was prepended with
“IP.” Well-known ports were not de-identiﬁed. Records with protocol numbers other than 6 (TCP), 17
(UDP) and (1) ICMP were removed entirely. The output from this process is provided in CSV format, one
record per line, with ﬁelds in the order shown in Table 1.

2.2 Data Quality

Several ﬁgures have been provided in order to assess the quality of the network ﬂow data set. The top plot in
Figure 1, which shows the number of biﬂows over time, demonstrates the periodicity that one would expect
for data whose volume is driven by the comings and goings of employees during a typical 5-day workweek.
The bottom plot of Figure 1 is intended to measure the success rate of the biﬂowing and IP-to-FQDN
mapping processes. TCP biﬂows where either SrcPackets or DstPackets is zero suggests a failure to ﬁnd
matching uniﬂows for both directions of the exchange. 57% of TCP and approximately 70% of all biﬂows fall
within this category. This can largely be attributed to LANL’s netﬂow sensor infrastructure, which has been
speciﬁcally conﬁgured to export only one direction on many routes. In addition, some devices — namely
vulnerability scanners and the like — attempt to connect to all possible IP addresses within a range; this
results in a signiﬁcant number of uniﬂows for which no response is possible. Likely for the same reason,
IP-to-FQDN mapping failed for signiﬁcantly more DstDevices than SrcDevices.

Figure 2 shows the daily proportion of biﬂows corresponding to each Protocol. Figure 3 contains two
histograms of the top SrcPorts and DstPorts respectively. Note the non-uniformity in the SrcPort histogram;
this illustrates either a consistent failure of the biﬂowing process to choose the appropriate direction or the
presence of protocols that use non-ephemeral source ports. For example, the Network Time Protocol (NTP)
uses port 123 for both the source and destination ports per the speciﬁcation.

4

Figure 1: Top: Daily count of biﬂows by end time. Bottom: Fraction of biﬂows where SrcPackets = 0,
DstPackets = 0, SrcDevice FQDN-mapping failed and DstDevice FQDN-mapping failed.

Figure 2: Daily proportions of each Protocol.

Figure 4 shows the distribution of Duration, SrcBytes and DstBytes per Protocol. Of particular interest
is the presence of many long-lived UDP and ICMP biﬂows in the data. This indicates frequent, persistent
UDP and ICMP traﬃc sharing the same 5-tuple and is an unfortunate side-eﬀect of not limiting the biﬂow
transformation to TCP uniﬂows. Finally, Figure 5 shows exemplar in-degree and out-degree distributions
for two randomly-selected days.

5

1.5e+082.0e+082.5e+080.00.10.20.30.40.50510152025303540455055606570758085DayNumber of biflowsFraction of biflowsSrcPackets = 0DstPackets = 0missing SrcDevice namemissing DstDevice name0.00.20.40.60.80510152025303540455055606570758085DayFraction of biflowsProtocol1617Figure 3: Histogram of the top 50 SrcPorts and DstPorts.

Figure 4: Distribution of Duration, SrcBytes and DstBytes.
6

0e+001e+072e+073e+070e+001e+092e+093e+09Port15379Port95765137Port59844Port20995Port844742049Port36836123Port87103Port00588Port12772Port24820Port797985060427Port38818Port68911Port60378Port62256Port46272Port375927001Port82174Port97238Port38713Port072127003Port137777006Port5572370047005Port21874Port21982Port400157007Port24326Port78500Port39034Port15921Port66659Port55240Port20503Port78720Port92355Port32067Port14127Port325107008534438051438942788161445Port95765Port231188080135Port28904Port18995Port844747002Port64788Port92667Port3683614335061Port20990Port30640Port12772Port99055Port859262554325060Port79798700122Port38818Port24820Port224254447003Port153797006Port95695Port37592Port68911Port14127Port32067Port3251070047005Top source portsTop dest portsCountCountProtocol1617Protocol1617lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0e+001e+021e+051e+080e+001e+021e+051e+080e+001e+021e+051e+080e+005e+041e+050500000100000015000000e+002e+054e+056e+05Duration (minutes)Source MbsDest MbsCountCountCountProtocoll1617Protocoll1617Protocoll1617Figure 5: In-degree and out-degree distribution for two randomly-selected days.

3 Windows Host Log Data

As remote attackers and malicious insiders increasingly use encryption, network-only detection mechanisms
are becoming less eﬀective, particularly those that require the inspection of payload data within the network
traﬃc. As a result, cyber defenders now rely heavily on endpoint agents and host event logs to detect and
investigate incidents. Host event logs capture nuanced details for a wide range of activities; however, given
the vast number of logged events and their speciﬁcity to an individual host, human analysts struggle to
discover the few useful log entries amid the huge number of innocuous entries. Statistical analytics for host
event data are in their infancy. Advanced analytical capabilities on this host data, including computer and
user proﬁling, which move beyond signature-based methods, will increase network awareness and detection
of advanced cyber threats.

The host event data set is a subset of host event logs collected from all computers running the Microsoft
Windows operating system on LANL’s enterprise network. The host logs were collected with Windows
Logging Service (WLS), which is a Windows service that forwards event logs, along with administrator-
deﬁned contextual data to a set of collection servers Honeywell - NSC. The released data are in JSON
format in order to preserve the structure of the original events, unlike the two previously released data sets
based on this log source Kent (2016, 2014). The events from the host logs included in the data set are all
related to authentication and process activity on each machine.

Table 2 contains the subset of EventIDs included from the event logs in the released data set and a
brief description of each; see R. F. Smith for a more detailed description. Figure 6 shows the percentage of
EventIDs contained in the logs, as well as the LogonTypes for EventIDs 4624, 4625 and 4634.

Each record in the data set will have some of the event attributes listed in Appendix A and the table in

7

Day14Day260e+005e+041e+052e+050250050007500IndegreeCount0e+005e+041e+052e+05025005000750010000IndegreeCount010000300000200004000060000OutdegreeCount010000200000200004000060000OutdegreeCountEvent ID

Description

Authentication events

4768
4769
4770
4774
4776
4624
4625
4634
4647
4648
4672
4800
4801
4802
4803

4688
4689

4608
4609
1100

Kerberos authentication ticket was requested (TGT)
Kerberos service ticket was requested (TGS)
Kerberos service ticket was renewed
An account was mapped for logon
The domain controller attempted to validate credentials
An account was successfully logged on, see Logon Types
An account failed to logon, see Logon Types
An account was logged oﬀ, see Logon types
User initiated logoﬀ
A logon was attempted using explicit credentials
Special privileges assigned to a new logon
The workstation was locked
The workstation was unlocked
The screensaver was invoked
The screensaver was dismissed

Process events

Process start
Process end

System events

Windows is starting up
Windows is shutting down
Event logging service has shut down
(often recorded instead of EventID 4609)

Logon Types (EventIDs: 4624, 4625 and 4634)

2 - Interactive
3 - Network
4 - Batch
12 - CachedRemoteInteractive

5 - Service
7 - Unlock
8 - NetworkClearText
0 - Used only by the system account

9 - NewCredentials
10 - RemoteInteractive
11 - CachedInteractive

Table 2: Host log Event IDs

Appendix B speciﬁes which Event IDs have each attribute. Note that not all events with a given EventID
share the same set of attributes. If an expected attribute was missing from the original host log record, then
the attribute was not included in the corresponding record in the de-identiﬁed data set.

All records will contain the attributes EventID, LogHost and Time. LogHost indicates the network host
where the record was logged. For directed authentication events, this attribute will always correspond to
the computer to which the user is authenticating, and the source computer will be given by Source. For
the user associated with the record, if the UserName ends in $ then it will correspond to the computer
account for the speciﬁed computer. These computer accounts are host-speciﬁc accounts within the Microsoft
Active Directory domain that allow the computer to authenticate as a unique entity within the network.
Figure 7 shows the count of unique processes, log hosts (LogHost), source hosts (Source), computer accounts
(UserName ending in $) and users (UserName not ending in $) for the 90 day period. Figure 8 shows the
count for the same attributes on a per-day basis. Note that the set of source hosts includes devices running
non-Windows operating systems, hence there are more source hosts than log hosts.

Requests to the Kerberos Ticket Granting Service (TGS) (EventID 4769) correspond to a user requesting

8

Figure 6: Histogram of the Event IDs and Logon Types.

Figure 7: Histogram of unique processes, usernames, log hosts (LogHost), source hosts (Source) and computer
accounts for the whole time period.

Kerberos authentication credentials from the Active Directory domain to a service or account name on a
network computer. Hence, the LogHost attribute should always be an Active Directory machine and the
service or account name the user is requesting access to will be given by ServiceName. The ServiceName
often corresponds to a computer account on the target computer. Because this event only grants a credential,
a subsequent network logon event (EventID 4624 - LogonType 3) to the computer indicated by ServiceName
is common. This diﬀers from the previous data release Kent (2016), in which TGS events were assumed
to be directed authentication events from the user’s machine to the computer indicated by ServiceName,

9

46884624463446724776476946484768462548004801477448024803464746890.00.10.2DensityEvent ID325879410011120.000.250.500.751.00DensityLogon Typeprocessessource_hostsuserscomp_accountslog_hosts0500010000150002000025000CountFigure 8: Daily count of the ﬁelds in Figure 7.

ignoring the Kerberos intermediary.

When de-identifying the process events, only the base process name was de-identiﬁed and the extension
was left as is. Further, the parent process names (ParentProcessName) do not have ﬁle extensions unlike the
child process names (ProcessName); this is a direct artifact of how the process information is logged within
WLS. The missing extension can be obtained by using the ParentProcessID to identify the parent process
start event.

Finally, many events include the DomainName attribute that indicates what Active Directory domain
the event is associated with. The domain, combined with the UserName, should be considered a unique
account identity. For example, user u1 with domain d1 is not necessarily user u1 in domain d2. In addition,
the domain may actually be a hostname, indicating the event does not involve a user or account associated
with an Active Directory domain, but is instead a local account. Again, these accounts should be considered
unique to the host indicated within the DomainName attribute. For example, the Administrator account
on host c1 likely does not have a relationship to the Administrator account on c2 or the Administrator
account in domain d1. The LANL data sets have a single primary domain, with a number of much smaller,
secondary domains and most computers have a small set of local accounts.

3.1 Data parsing considerations

While host logs can be an extremely valuable data resource for cyber security research, the formatting and
content of the logs can vary drastically between enterprises depending upon the audit policy and technologies
used to collect and forward the logs to a centralized server. Hence, parsing the data and extracting the
relevant attributes is an important ﬁrst step in analyzing these data; see also Kent (2016).

Even though WLS provides more content and normalization around the raw Windows logs, some chal-

10

300060009000120000255075DayCountuserscomp_accountsprocesseslog_hostssource_hostslenges were still faced to provide the de-identiﬁed data.

Firstly, the semantics of attribute names are not necessarily the same for diﬀerent EventIDs and the
attribute names themselves may diﬀer according to what tool is being used to collect and forward the logs.
For example, with WLS the UserName for EventID 4774 is MappedName, for EventID 4778 and 4779 it is
AccountName and for most other events it is TargetUserName. When parsing the data, these names were
all standardized to UserName.

As with the network ﬂow data, an extremely important task is mapping IP addresses to FQDNs. Further,
unlike netﬂow, each record may contain both IP addresses and hostnames. The machine where the event is
recorded (LogHost for the de-identiﬁed data) is provided as a hostname, whereas the Source computer for
network logons is often given as an IP address.

Finally, both usernames and process names were standardized. In some records, usernames appear with
the domain name or additional characters. These discrepancies were removed from the released data in
order to ensure all usernames were in canonical form. In addition, some usernames, such as “Anonymous”,
“Local Service” and “Network Service”, do not map to a computer or user account. For some analyses,
one may want to remove these events. In the de-identiﬁed data these commonly-seen usernames were not
anonymized. For the process names, dates, version numbers, operating systems and hexadecimal strings
were removed where possible so that processes run on diﬀerent operating systems or with diﬀerent versions
would map to the same process name. For example, ﬂashplayerplugin 20 0 0 286.exe would be mapped to
ﬂashplayerplugin VERSION.exe.

4 Research directions

Anomaly detection for the defensive cyber domain is a major yet evolving research area, with much work still
to be done in characterizing and ﬁnding anomalies within complex cyber data sets. Finding viable attack
indicators and per computer, user and computer-to-computer models that enable anomaly detection and
ﬁngerprinting are all interesting and important research opportunities.

Although research on anomaly detection for cyber defense spans more than two decades, operational
tools are still almost exclusively rule- or signature-based. Two reasons that statistical methods have not
been more widely adopted in practice are a high false positive rate and un-interpretable alerts. Analysts are
inundated with a large number of alerts and triaging them takes signiﬁcant time and resources; this results
in low tolerance for false alarms and alerts that provide no contextual information to guide investigation.
Signature-based systems can be ﬁnely tuned to reduce false positives as they rely on very speciﬁc peculiarities
that have been previously identiﬁed and documented as indicative of a cyber attack. Further, they are
interpretable as they refer to speciﬁc patterns within the data, such as weird domains, network protocols or
process names.

However, despite their inherent challenges, anomaly detection methods have the advantage of being able
to detect new variants of cyber attacks and are able to keep pace with the rapidly changing cyber attack
landscape by dynamically learning patterns for normal behavior and detecting deviations. Further, with the
increasing level of encrypted network traﬃc, the importance of this research and the use of these methods can
not be understated. Research into ways to reduce false positives and providing interpretable anomalies will
have signiﬁcant impact in furthering the use of anomaly detection systems. In fact, providing interpretable
anomalies can help overcome the false positive issue as interpretability leads to quickly identifying alerts
that are false positives in the same way it would enable understanding true positives. Research approaches
to tackle these problems could include combining diﬀerent data sets and signals, borrowing strength across
entities that are similar by incorporating peer-based behavior, community detection approaches and ways to
provide meaningful context surrounding alerts to human analysts.

When using the host log data set for research, some notable characteristics of these data that need to
be considered, especially if looking at the events as a time series, is periodicity and signiﬁcant correlations
between arrivals of diﬀerent event types. This can be seen clearly in Figure 9, which shows the event
times for various EventIDs for User205265. Periodicity in the data is often an artifact of the computer
regularly renewing credentials. This explains why EventID 4624 - LogonType 3 (network logon) constitutes

11

Figure 9: Event times for User205265. 4624l2 corresponds to EventID 4624 - LogonType 2.

such a signiﬁcant portion of the events as seen in Figure 6. For a given entity, extrapolating higher-level,
interpretable actions from the sequence of low-level events would improve modelling eﬀorts, understanding
of these data and would itself be very useful for security analysts. See Heard et al. (2014) and Price-Williams
et al. (2017) for relevant research in this area.

Another area for research with the host logs is exploring the records related to process starts and stops
in detail, in particular looking at process trees. To date, little has been done in this area. Computer
systems operate hierarchically; an initial root process starts many other processes, which in turn start and
run descendants. A process tree is the dynamic structure that results. In theory, any process can be traced,
through its ancestors, to the root process. Unusual or atypical events in process trees could indicate potential
cyber security anomalies.

Moving beyond anomaly detection, there are other important research directions for which these data
could prove useful. For example, preliminary work has been done using similar data to model network
segmentation and associated risk Pope et al. (2017). Using the data to build new, potential network topologies
in order to reduce risk and improve security posture are viable directions. Another potential research problem
is to quantify and understand data loss within cyber data sets. The collection and normalization processes
in place for these data can result in information loss and understanding this data loss is an open problem
both in general and speciﬁc to each element of the data. As most of the data elements represent people and
their actions on computers, research on organizational and social behavior is also viable using these data.

5 Conclusion

Operational cyber security data sets are paramount to ensuring valuable and productive research continues
to improve the state of cyber defense. The network ﬂow and host log event data discussed in this chapter are

12

llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll78910111207:0008:0009:0010:0011:0012:0013:0014:0015:0016:00TimeDayeventidl4624l24624l34624l7476847694776intended to enable such research as well as to provide an example for other potential data set providers. In
particular, while there is a considerable amount of relevant work on network data, relatively little attention
has been given to host log data in the literature. Host log data are becoming increasingly relevant as endpoint
security tools gain popularity within the cyber security ecosystem. It is important that researchers embrace
both the opportunity and challenge that they present. Finally, even less consideration has been given to
meaningful analyses that combine these and other data sets. This paradigm shift towards a holistic approach
to cyber security defense is critical to advancing the state of the art.

6 Acknowledgment

This work has been authored by an employee of Los Alamos National Security, LLC, operator of the Los
Alamos National Laboratory under Contract No. DE-AC52-06NA25396 with the U.S. Department of En-
ergy. The United States Government retains and the publisher, by accepting this work for publication,
acknowledges that the United States Government retains a nonexclusive, paid-up, irrevocable, world-wide
license to publish or reproduce this work, or allow others to do so for United States Government purposes.

A Host log ﬁelds

• Time: The epoch time of the event in seconds.

• EventID: Four digit integer corresponding to the event id of the record.

• LogHost: The hostname of the computer that the event was recorded on. In the case of directed authen-
tication events, the LogHost will correspond to the computer that the authentication event is terminating
at (destination computer).

• LogonType: Integer corresponding to the type of logon, see Table 2.

• LogonTypeDescription: Description of the LogonType, see Table 2.

• UserName: The user account initiating the event. If the user ends in $, then it corresponds to a computer

account for the speciﬁed computer.

• DomainName: Domain name of UserName.

• LogonID: A semi-unique (unique between current sessions and LogHost) number that identiﬁes the logon
session just initiated. Any events logged subsequently during this logon session should report the same
Logon ID through to the logoﬀ event.

• SubjectUserName: For authentication mapping events, the user account speciﬁed by this ﬁeld is mapping

to the user account in UserName.

• SubjectDomainName: Domain name of SubjectUserName.

• SubjectLogonID: See LogonID.

• Status: Status of the authentication request. “0x0” means success otherwise failure, see R. F. Smith for

failure codes for the appropriate Event ID.

• Source: For authentication events, this will correspond to the the computer where the authentication

originated (source computer), if it is a local logon event then this will be the same as the LogHost.

• ServiceName: The account name of the computer or service the user is requesting the ticket for.

• Destination: This is the server the mapped credential is accessing. This may indicate the local computer

when starting another process with new account credentials on a local computer.

13

• AuthenticationPackage: The type of authentication occurring including Negotiate, Kerberos, NTLM plus

a few more.

• FailureReason: The reason for a failed logon.

• ProcessName: The process executable name, for authentication events this is the process that processed

the authentication event. ProcessNames may include the ﬁle type extensions (i.e exe).

• ProcessID: A semi-unique (unique between currently running processes AND LogHost) value that identiﬁes
the process. Process ID allows you to correlate other events logged in association with the same process
through to the process end.

• ParentProcessName: The process executable that started the new process. ParentProcessNames often do
not have ﬁle extensions like ProcessName but can be compared by removing ﬁle extensions from the name.

• ParentProcessID: Identiﬁes the exact process that started the new process. Look for a preceding event

4688 with a ProcessID that matches this ParentProcessID.

B Event Attributes

Event Ids

All
All
All
4624, 4625, 4634
4624, 4625, 4634
All except System Events
All except System Events
All except 4768, 4769, 4770, 4774, 4776
4624 (LogonType 9), 4648, 4774
4624 (LogonType 9), 4648, 4774
4624 (LogonType 9), 4648
4768, 4769, 4776
4624, 4625, 4648, 4768, 4769, 4770, 4776
4769, 4770
4648
4624, 4625, 4776
4625
4624, 4625, 4648, 4688, 4689
4624, 4625, 4648, 4688, 4689
4688
4688

Attribute

Time
EventID
LogHost
LogonType
LogonTypeDescription
UserName
DomainName
LogonID
SubjectUserName
SubjectDomainName
SubjectLogonID
Status
Source
ServiceName
Destination
AuthenticationPackage
FailureReason
ProcessName
ProcessID
ParentProcessName
ParentProcessID

Table 3: Event Attributes

References

Information marketplace for policy and analysis of cyber-risk and trust (IMPACT). URL https://www.

dhs.gov/csd-impact.

14

Malware and exploit kit traﬃc. URL http://malware-traffic-analysis.net/.

Rafael Ramos Regis Barbosa. Anomaly Detection in SCADA Systems-A Network Based Approach. PhD

thesis, Centre for Telematics and Information Technology, University of Twente, 2014.

Robin Berthier, Michel Cukier, Matti Hiltunen, Dave Kormann, Gregg Vesonder, and Dan Sheleheda. Nf-
sight: netﬂow-based network awareness tool. In Proceedings of LISA10: 24th Large Installation System
Administration Conference, page 119, 2010.

Canadian Institute for Cybersecurity. Cybersecurity datasets. URL http://www.unb.ca/cic/research/

datasets/index.html.

B. Claise. Cisco systems NetFlow services export version 9. RFC 3954, Internet Engineering Task Force,

October 2004. URL https://www.ietf.org/rfc/rfc3954.txt.

Cyber Systems and Technology Group. DARPA intrusion detection data sets, 1998. URL https://www.

ll.mit.edu/ideval/data/.

Joshua Glasser and Brian Lindauer. Bridging the gap: A pragmatic approach to generating insider threat
data. 2012 IEEE Symposium on Security and Privacy Workshops, 00:98–104, 2013. URL https://www.
cert.org/insider-threat/tools/index.cfm.

N. Heard, P. Rubin-Delanchy, and D. J. Lawson. Filtering automated polling traﬃc in computer network
In 2014 IEEE Joint Intelligence and Security Informatics Conference, pages 268–271, Sept

ﬂow data.
2014.

Rick Hofstede, Pavel ˇCeleda, Brian Trammell, Idilio Drago, Ramin Sadre, Anna Sperotto, and Aiko Pras.
Flow monitoring explained: From packet capture to data analysis with NetFlow and IPFIX. IEEE Com-
munications Surveys & Tutorials, 16(4):2037–2064, 2014.

Honeywell

- NSC.

URL http://honeywell.com/sites/aero-kcp/SiteCollectionDocuments/

WindowsLoggingServiceSummary.pdf.

Alexander D. Kent. User-computer authentication associations in time. Los Alamos National Laboratory,

2014.

Alexander D Kent. Cyber security data sources for dynamic network research. Dynamic Networks and

Cyber-Security, 1:37, 2016.

Justin Ma, Lawrence K Saul, Stefan Savage, and Geoﬀrey M Voelker.

Identifying suspicious URLs: an
application of large-scale online learning. In Proceedings of the 26th annual international conference on
machine learning, pages 681–688. ACM, 2009. URL http://sysnet.ucsd.edu/projects/url/.

Pavel Minarik, Jan Vykopal, and Vojtech Krmicek. Improving host proﬁling with bidirectional ﬂows. In
Computational Science and Engineering, 2009. CSE’09. International Conference on, volume 3, pages
231–237. IEEE, 2009.

Khanh V Nguyen, Naveen Kumar Tyagi, and Ray M Lau. Flow de-duplication for network monitoring,

January 2017. US Patent 9,548,908.

A. Pope, D. Tauritz, and A. Kent. Evolving bipartite authentication graph partitions. IEEE Transactions

on Dependable and Secure Computing, PP(99):1–1, 2017. ISSN 1545-5971.

M. Price-Williams, N. Heard, and M. Turcotte. Detecting periodic subsequences in cyber security data.

ArXiv e-prints, June 2017.

R. F. Smith. URL https://www.ultimatewindowssecurity.com/securitylog/encyclopedia/default.

aspx.

15

Anna Sperotto, Gregor Schaﬀrath, Ramin Sadre, Cristian Morariu, Aiko Pras, and Burkhard Stiller. An
overview of IP ﬂow-based intrusion detection. IEEE Communications Surveys and Tutorials, 12(3):343–
356, 2010.

B. Trammell and E. Boschi. Bidirectional ﬂow export using IP Flow Information Export (IPFIX). RFC
5103, Internet Engineering Task Force, January 2008. URL https://www.ietf.org/rfc/rfc5103.txt.

16

