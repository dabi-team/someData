Network Information Theoretic Security

Hongchao Zhou and Abbas El Gamal

1

0
2
0
2

y
a
M
7
2

]
T
I
.
s
c
[

2
v
9
6
1
5
0
.
1
0
0
2
:
v
i
X
r
a

Abstract—Shannon showed that to achieve perfect secrecy in
point-to-point communication, the message rate cannot exceed
the shared secret key rate giving rise to the simple one-time
pad encryption scheme. In this paper, we extend this work from
point-to-point to networks. We consider a connected network
with pairwise communication between the nodes. We assume
that each node is provided with a certain amount of secret
bits before communication commences. An eavesdropper with
unlimited computing power has access to all communication and
can hack a subset of the nodes not known to the rest of the
nodes. We investigate the limits on information-theoretic secure
communication for this network. We establish a tradeoff between
the secure channel rate (for a node pair) and the secure network
rate (sum over all node pair rates) and show that perfect secrecy
can be achieved if and only if the sum rate of any subset of
unhacked channels does not exceed the shared unhacked-secret-
bit rate of these channels. We also propose two practical and
efﬁcient schemes that achieve a good balance of network and
channel rates with perfect secrecy guarantee. This work has a
wide range of potential applications for which perfect secrecy
is desired, such as cyber-physical systems, distributed-control
systems, and ad-hoc networks.

Index Terms—Network information theoretic security, all com-

munication eavesdropped, network capacity.

I. INTRODUCTION

The information-theoretic security introduced by Shan-
non [1] and widely accepted as the strictest notation of
security, is becoming increasingly attractive for many cyber-
physical systems, distributed-control systems, wireless ad-hoc
networks, among other applications. Secure network cod-
ing [2] has been well studied to guarantee the information-
theoretic security when a subset of channels are wire-
tapped [3], [4] or in the presence of Byzantine adversaries [5],
[6]. In this paper, we make a stronger assumption: all the
channels are eavesdropped and some nodes are hacked without
knowledge of the rest of the nodes. This assumption is realistic
for example in wireless networks in which an eavesdropper can
sense the transmitted signals, or the network nodes communi-
cate via an insecure public network as another example. Under
this assumption, pure network-coding approaches cannot work
without the help of common randomness shared among the
network nodes. Physical layer security [7]–[11] can be used
to distribute secret keys among network nodes, however,
the channel advantage required by the receivers over any
eavesdropper is not easy to guarantee in a wireless network.
In many scenarios, it is feasible and much cheaper to pre-
distribute a very large number of secret bits to network nodes
to support future secure communication. In this paper, we
are interested in a fundamental problem: if every node in the

H. Zhou is with the School of Information Science and Engineering,

Shandong University, Qingdao, Shandong, 266237 China.

A. El Gamal is with the Department of Electrical Engineering, Stanford

University, Stanford, CA, 94305 USA.

network is allowed to carry a certain large number of secret
bits, how much information can be securely transmitted over
the network under the information-theoretic security criterion?
We consider a connected network of n nodes, with at most
t ≤ n − 2 nodes hacked without knowledge of the other
nodes. We assume pairwise communication with end-to-end
encryption, that is each sender node encrypts its message using
a secret key generated from the common randomness shared
with the intended receiver node and the receiver decrypts
it using the same key. Through the process of key pre-
distribution, each node has a sequence of l secret bits, and the
secret bits from different nodes may be correlated according
to a symmetric joint probability distribution which does not
depend on future communications. If a node is hacked, all
its secret bits are disclosed to the eavesdropper. Before two
nodes communicate, they generate a secret key by purifying
their common randomness with privacy ampliﬁcation [12]–
[15] then use the one-time pad scheme to communicate the
message. As the total length of the messages to be transmitted
over a channel (i.e., from a source to a destination) cannot
exceed the secret-bit length l of each node, we deﬁne their
ratio as the channel rate, and the sum rate of all the channels
as the network rate.

The secure-communication limit of a network depends on
the secret bits distributed and the method of utilizing them to
deliver information. As an example, consider a network with
n = 4 nodes and t = 1 nodes being hacked. A straightforward
way to pre-distribute the secret bits is to assign each pair
of nodes l/3 common secret bits as the secret key which
they can use with the one-time pad scheme. In this case, the
messages are secure if and only if the rate of each channel
does not exceed 1/3. As the network size n increases, this
approach can only reach channel rate of at most 1/(n − 1),
limiting its applications for large networks. An alternative way
to redistribute the secret bits in the 4-node example is to assign
every three nodes l/3 common secret bits, and hence there are
four sequences of secret bits denoted by u123, u124, . . ., where
u123 is the secret bits distributed to nodes 1, 2, 3. When two
nodes say nodes 1 and 2 communicate to each other, they use
u123 + u124 as the secret key. In this case, no matter whether
node 3 or node 4 is hacked, the messages are secure as long
as the channel rate between node 1 and 2 does not exceed
1/3. Compared to the previous way, it can be proved that for
a larger network of size n, by allowing each secret bit to be
distributed to multiple nodes instead of only two nodes, the
maximum channel rate (channel capacity) can be improved to
more than 1/4 from 1/(n − 1). Our scheme can be viewed as
another application of linear network coding. It allows higher
secure communication rates by utilizing the secret bits shared
by multiple channels perfect secrecy can be achieved.

We address several basic questions about our network

 
 
 
 
 
 
2

setting: (i) what is the limit on the network rate and the
channel rate for secure communication considering all the
symmetric ways of pre-distributing secret bits? (ii) given an
arbitrary distribution on the secret bits, how do we determine
the security of a network with given channel rates? and (iii)
how to design efﬁcient and practical network-communication
schemes that have both high network rate and high channel
rate?

The rest of this paper is organized as follows. Section II
provides the formulation and deﬁnitions of the problem for
network communication with information theoretic security.
Section III summaries some main results. Two practical and
efﬁcient communication schemes with perfect secrecy guar-
antee are proposed and investigated in Section IV. Section V
further discusses the network security beyond the information
theoretic limit, the application of network coding, and some
open questions. The proofs of the main results are given in
Section VI.

The network communication is information-theoretically
secure if and only if for any possible set of hacked nodes
Nh and for any channel (i, j) ∈ Ps, it has

I[xij ; y, uh] < ǫ

(1)

for small ǫ ≥ 0, with ǫ = 0 for perfect secrecy. Note that
the security of the network depends on the message lengths
{mij} (i.e. the channel rates {rij} for a given l) but not on
their exact values or which of the two terminals is the source.
We say that a set of channel rates {rij} is achievable using
a scheme ψ if any messages with these channel rates can be
securely communicated with high probability (arbitrarily close
to 1) for l sufﬁciently large. We denote the set of achievable
rates using a scheme ψ by R(ψ).

We deﬁne the maximum channel rate and the maximum
network rate of a scheme ψ as the supremum of all the
achievable channel rates and network rates of the scheme, and
denote them by

II. DEFINITIONS

We consider a network consisting of a set of nodes N =
{1, 2, . . . , n}, where every two nodes can ﬁnd a path (channel)
connecting them, and use P = {(i, j)} to denote the set of all
the channels. It is assumed that all the channels are insecure,
namely, every ciphertext transmitted over the network is possi-
ble to be known by an eavesdropper. Each node in the network
is able to store a large number l of secret bits. To guarantee the
network security, the total message length mij of a channel
(i, j) ∈ P cannot exceed l. We call the number of message
bits transmitted through a channel (i, j) per a node’s secret
bit as the channel rate rij , and the sum of the channel rates
as the network rate r. Mathematically,

rij =

mij
l

,

r =

rij .

X(i,j)∈P

We assume that up to t nodes could be hacked by an
eavesdropper, and in this case, all the secret bits stored in
these nodes are revealed to the eavesdropper. We use Nh ⊂ N
with |Nh| ≤ t to denote the set of hacked nodes, and use
Ns = N/Nh to denote the set of unhacked secure nodes. As a
channel is insecure if one of its terminals is hacked, our goal
is to protect those channels between secure nodes, denoted by
Ps. Note that if t ≥ n − 1, it has |Ps| = 0, and in this case
no message bits can be securely transmitted between any two
nodes. In this paper, we assume that t ≤ n − 2 by default.

A secure network-communication scheme ψ consists of two
phases. In the key pre-distribution phase, the scheme provides
a sequence of secret bits u ∈ {0, 1}∗ to the network nodes,
with each bit possibly distributed to multiple nodes. We use
ui to denote the sequence of secret bits distributed to node i.
In the communication phase, we let xij ∈ {0, 1}mij be the
message transmitted in channel (i, j) (we assume there is a
single message transmitted in each channel for simplicity), and
the corresponding ciphertext is yij . Both all the transmitted
ciphertexts y = {yij|(i, j) ∈ P} and the hacked secret bits
uh = ∪j∈Nh uj are known to the eavesdropper.

Rchannel(ψ) =

sup
{rij }∈R(ψ)

max
(i,j)∈P

rij ,

Rnet(ψ) =

sup

{rij }∈R(ψ) X(i,j)∈P

rij .

The communication demand is typically unknown during
the key pre-distribution phase. To ensure that the designed
schemes have enough ﬂexibility,
the secret bits are pre-
distributed to network nodes in a symmetric fashion (thus
permuting the indices of the nodes does not change the joint
probability distribution of the secret bits). In this case, the
maximum network rate can be achieved by the equal channel
rates with rij = 1
n−1 for all the channels, following the
symmetry assumption of the network as well as the distributed
randomness. On the other hand, the maximum channel rate can
be achieved when there is only one channel having message
transmissions, i.e., rij > 0 for a speciﬁc single channel and
rij = 0 for all the other channels.

To investigate the communication limit, we deﬁne the
channel capacity and the network capacity of a network as the
maximum over all the maximum channel rates and maximum
network rates of any scheme with symmetric key distribution,
and denote them by

Cchannel = max

ψ

Rchannel(ψ), Cnet = max

ψ

Rnet(ψ).

III. SUMMARY OF MAIN RESULTS

From its deﬁnition, the maximum channel rate of a scheme
is at most 1. But this upper bound cannot be reached when
t > 0. The following result provides the capacities of a general
network, as the theoretical limit for all the schemes with
symmetric key distribution. From this result, a network with
n = 4 and t = 1 has channel capacity of 1/3. Interestingly, if
we further increase the size of the network to 5, the channel
capacity is still 1/3.

Theorem 1. Given a network of n nodes with at most t ≤ n−2
nodes being hacked, its network capacity and channel capacity

are

(cid:1)

n
2

Cnet =

with a = ⌈

, Cchannel = (cid:0)
(cid:0)

n−t−2
a−2
n−1
a−1
There is a certain tradeoff between the maximum network
rate and the maximum channel rate of a scheme. In particular,
they have the following relationship for t = 0, implying that
one may sacriﬁce the maximum network rate to obtain a better
maximum channel rate, and vice versa.

n
t + 1

⌉.

(cid:1)

Theorem 2. Given a network of n nodes without any nodes
being hacked, for any scheme ψ with symmetric key distribu-
tion, it satisﬁes

Rnet(ψ)

2
n + 1

+ Rchannel(ψ)

n − 1
n + 1

≤ 1.

(2)

The equality is achievable for any 1 ≤ Rnet(ψ) ≤ n
2 .

Given a scheme, it is crucial to determine whether a network
with channel rates {rij} is perfectly secure or not, as the
communication phase has to be terminated for guaranteeing
perfect secrecy when the channel rates get very close to the
limit. The difﬁculty arises from the fact that different channels
may share some common secret bits, hence “interfere” with
each other. Given an arbitrary (symmetric or not) distribution
of secret bits, we prove that perfect secrecy is achievable if
and only if the sum rate of any subset of unhacked channels
does not exceed the shared unhacked-secret-bit rate of these
channels. Here, given the set of hacked nodes Nh, the shared
unhacked-secret-bit rate of a set of channels P ⊆ Ps is deﬁned
by

rsecrecy(P, Nh) =

| ∪(i,j)∈P uij /uh|
l

.

Theorem 3. Given a network of n nodes with at most t ≤ n−2
nodes being hacked, the channel rates {rij } are achievable if
and only if for any possible set of hacked nodes Nh and for any
subset of channels P ⊆ Ps, it satisﬁes 1 either
(i,j)∈P rij =
0 or

P

rij < rsecrecy(P, Nh).

(3)

is secure for sufﬁciently large l if and only if

r12 + r13 + r23 < 1/3

holds for any node permutation.

3

(4)

Note that if the size of the network is large, the number of
constrains in the above criteria becomes prohibitively large.
One can reduce the computational complexity by relaxing the
conditions to hold only for any set of channels of some size
w,

max
|P |=w X(i,j)∈P

rij < min

|P |=w,Nh

rsecrecy(P, Nh),

where the left term is easy to calculate and the right term can
be computed explicitly (see subsection IV-D) for symmetric
key distribution.

The following result provides an alternative approach to
check the security of a network, in which we let uG be the set
of secret bits distributed only to all the nodes in set G. The
shared unhacked-secret-bit rate of G is deﬁned by

rsecrecy(G, Nh) =

|uG/uh|
l

.

Theorem 4. Given a network of n nodes with at most t ≤ n−2
nodes being hacked, the channel rates {rij } are achievable if
for any possible set of hacked nodes Nh, there exists a non-
negative feasible solution for {xij

G} such that

rij <

XG|i,j∈G⊆Ns
rsecrecy(G, Nh) =

xG
ij ,

∀(i, j) ∈ Ps with rij > 0,

xG
ij ,

∀G ⊆ Ns.

Xi,j∈G

We continue using the network of 4 nodes as an example. If
node 4 is hacked, then only u123 is not hacked. The network is
secure for sufﬁciently large l if there exists a feasible solution
for {x12, x13, x23} such that

r12 < x12, r13 < x13, r23 < x23,

1/3 = x12 + x13 + x23,

X(i,j)∈P

reaching the same condition as (4).

Achievability uses a simple method for privacy ampliﬁca-
tion that generates each secret-key bit by computing the XOR
of d randomly sampled common secret bits shared by two
terminals with d = O(log l). For a network with 4 nodes,
assume that the secret bits are distributed as follows: each
secret bit is distributed to 3 different nodes, and every 3 nodes
share l/3 common secret bits. If no nodes are hacked, then
the network is secure for sufﬁciently large l if and only if

r12 < 2/3

r12 + r13 + r14 < 1

rij < 4/3

Xij

holds for any node permutation. None of the inequalities can
be dismissed. If one of the nodes is hacked, then the network

1It

is assumed that privacy ampliﬁcation is applied to every channel.
Otherwise, the equality holds if the common secret bits shared by two nodes
are unknown by the rest of nodes and are used as the secret key directly.

IV. NETWORK SCHEMES

We wish to develop schemes that can securely communicate
as many message bits as possible not only over the entire
network but also through a single channel.

As deﬁned earlier, a secure network-communication scheme
consists of a key pre-distribution phase and a communication
phase in which a secret key between two nodes is estab-
lished from their common secret bits via privacy ampliﬁcation
and the one-time pad scheme is used to achieve secure
communication. There are a variety of methods for privacy
ampliﬁcation, such as universal hashing [16], random linear
transformations [17] and polar codes [18]. Given a large
number of common secret bits uij between two nodes, one
straightforward idea is to divide the shared secret bits into
blocks, and then apply privacy ampliﬁcation to each block.
However, this approach is not appropriate for our applications
as it requires knowledge of the message length (channel rate)

before communication as well as sophisticated coordination
among the nodes. We adopt a simple method for privacy
ampliﬁcation: each secret-key bit is generated by computing
the XOR of d randomly sampled common secret bits from
uij with d a large integer, for example, 128. We can repeat
this process whenever more secret-key bits are needed. The
performance of this method is very close to optimal. To further
improve the computational efﬁciency, one can generate q ≫ 1
secret-key bits simultaneously by packing q secret bits together
at the same location and performing the same operations on
them.

A. Key Pre-Distribution

We study two different key pre-distribution schemes. The
ﬁrst is the combinational key scheme, which distributes each
secret bit to exactly a ≥ 2 nodes. The second scheme is the
random key scheme, which distributes each secret bit to every
node with some probability p ≤ 1.

(cid:1)

(cid:0)

(cid:0)

(cid:1)

n
a

n−1
a−1

The combinational key scheme distributes the same number
of distinct secret bits to each combination of a nodes with
a ≥ 2. Hence, we divide all the secret bits into
groups
each of size l/
, and assign the secret bits of each group
to a unique combination of a nodes. For every two nodes,
their shared common secret bits consist of the secret bits from
n−2
groups. There is a problem with this scheme: when n
a−2
and a are large, the scheme becomes less practical as there
(cid:0)
are too many groups of secret bits. To address this problem,
we suggest to use only m random groups. This subset of
m groups can be found based on an m × n random matrix
with each row containing a ones (corresponding to a group)
and each column containing am/n ones (corresponding to a
node), whose construction has been studied for the parity-
check matrix of regular LDPC codes [19].

(cid:1)

The random key scheme generates a random-bit sequence
u of length u and assigns each of its bits to every network
node with a predetermined probability p ≤ 1. Similar ideas
were explored for key management in sensor networks with
the computational security [20], [21]. In contrast, we study the
key distribution for the information theoretic security, which
directly affect the communication rates. With the random key
scheme, each node i obtains a sequence of secret bits ui with
length around pu ≃ l. A difﬁculty with this scheme is to help
every two nodes to identify their shared common secret bits
for generating a secret key. It would be too storage-inefﬁcient
if each node stores not only the values of its secret bits but
also their locations in u. Our observation is that the secret
bits need to be truly random, but not the ways of distributing
them. One can use a pseudo-random permutation for key pre-
distribution, and it helps to identify those common secret bits
between nodes. Speciﬁcally, given the network size n and the
total number of secret bits u, we construct a pseudo-random
permutation [22]

F : {1, 2, . . . , u} × {1, 2, . . . , n} → {1, 2, . . . , u}.

We distribute the kth secret bit in u to node i at the location
F (k, i) if F (k, i) ≤ l. This pseudo-random permutation is
publicly known by all the network nodes.

4

B. Maximum Rates

Table I lists the maximum rates of the combinational key
scheme and the random key scheme. For both the schemes,
the maximum network rates can be achieved by the equal
channel rates with rij = 1
n and the maximum channel rates
can be achieved when there is only one channel with message
transmissions. Let us take the combinational key scheme as
an example.

Example 1. For the combinational key scheme with a ≥ 2,
n−1
each node is distributed
groups of secret bits, and every
a−1
n−2
two nodes share
groups of secret bits. When t nodes
(cid:0)
(cid:1)
a−2
are hacked, then for every pair of unhacked nodes, they share
n−t−2
groups of secret bits that are not hacked. As a result,
a−2
the maximum channel rate of the combinational key scheme is
(cid:0)

(cid:0)

(cid:1)

(cid:1)

Rchannel(ψcomb) =

n − t − 2

/
a − 2 (cid:19)

(cid:18)

n − 1
a − 1(cid:19)

(cid:18)

=

a − 1
n − 1 (cid:0)

n−t−2
a−2
n−2
a−2

.

(cid:1)

(cid:1)

(cid:0)
n−2
a−2

(cid:0)

(cid:0)

(cid:1)

/
(cid:1)

n−t−2
a−2

For the maximum rates of the combinational key scheme,
they have a common term γ(t, a) =
which
is a decreasing function of t with γ(0, a) = 1. This term
captures the effect of the number of hacked nodes t on the
maximum rates of the scheme. From this term, we can estimate
the number of hacked nodes that the scheme can tolerate. For
instance, when a = 3, γ(t, a) = n−t−2
n−2 , and one can tolerate
relatively large t. When a is large, the scheme can only tolerate
a very small number of nodes to be hacked. We observe
similar behaviors for the maximum rates of the random key
scheme, which have a common term approximately (1 − p)t
that captures the effect of t.

Further comparing the maximum rates of the two schemes,
there is a rough mapping between the parameter a in the
combinational key scheme and the np in the random key
scheme, which is about the expected number of nodes that each
secret bit is distributed to. The intuition behind this mapping
is that: compared to the scheme that distributes each secret
bit to 2 nodes, the proposed schemes distribute each secret bit
to around a ≥ 2 nodes. As a result, the maximum channel
rates of the schemes increase by a factor of a − 1. Meanwhile,
the usage efﬁciency of each secret bit (corresponding to the
maximum network rates) is reduced by a factor of roughly 2
a ,
as each secret bit can only be used for once by two nodes
among the a nodes.

C. Hybrid Schemes

For any combinational/random key scheme, the multiplica-
tion of its maximum network rate and its maximum channel
rate does not exceed 1. It implies that with a pure combina-
tional/random key scheme, high network rate and high channel
rate cannot be achieved at the same time.

We denote the combinational key scheme with a = 2 as the
pairwise key scheme, which reaches the network capacity. To
better balance the maximum network rate and the maximum
channel rate, we consider a hybrid scheme, in which each
node uses a fraction λ ∈ [0, 1] of its storage space to run the
pairwise key scheme and the rest to run the combinational
key scheme with a > 2 (or a random key scheme with

Combinational Key Scheme

Random Key Scheme

1
p

(n
2)
(n−t
2 )

Maximum Network Rate
(n−t−2
a−2 )
(n−2
a−2)

n
a

((1 − p)t − (1 − p)n − (n − t)p(1 − p)n−1)

Maximum Channel Rate
(n−t−2
a−2 )
(n−2
a−2)
p(1 − p)t

a−1
n−1

TABLE I
THE MAXIMUM RATE OF THE COMBINATIONAL KEY SCHEME AND THE RANDOM KEY SCHEME.

5

np > 2). The maximum network rate of this hybrid scheme
is the weighted sum of their respective component schemes’
maximum network rates, and so is its maximum channel rate.
For λ = 1
2 , for example, the maximum rates of the hybrid
scheme are

Rnet(ψhybrid) =

n
4

+

Rchannel(ψhybrid) =

1
2(n − 1)

,

(cid:1)

n−t−2
a−2
n−2
a−2

n
2a (cid:0)
(cid:0)
(cid:1)
a − 1
2(n − 1) (cid:0)
(cid:0)

+

n−t−2
a−2
n−2
a−2

.

(cid:1)

(cid:1)

The maximum network rate is strictly larger than n/4, and
the maximum channel rate can be adjusted by selecting
appropriate a. For example, for a network with n = 100
nodes and t = 1, the maximum network and channel rates
of the pairwise key scheme are 50.0 and 0.0101, respectively,
and those of the hybrid scheme with a = 25 are 26.53 and
0.0978, respectively, which improves on the maximum channel
rate by sacriﬁcing on the maximum network rate.

D. Security Criteria

When the network size is large, it is computationally too
complex to check the security of a network directly based
on Theorem 3 and Theorem 4, as the number of constrains
in the criteria becomes prohibitively large. We discuss some
techniques to reduce the number of constrains by relaxing the
criteria, and their applications to the proposed schemes.

We can relax the conditions in the criteria of Theorem 3 to

hold only for any set of channels of some size w,

max
|P |=w X(i,j)∈P

rij < min

|P |=w,Nh

rsecrecy(P, Nh).

The left term is easy to calculate, and we would like ﬁnd a
simple way to compute the right term

rsecrecy(w) = min

|P |=w,Nh

| ∪(i,j)∈P uij /uh|
l

.

Due to the symmetry of key distribution, we can assume
without loss of generality that the last t nodes are hacked,
and the minimum of | ∪(i,j)∈P uij /uh| with |P | = w can be
reached by the ﬁrst w elements in

u12, u13, . . . , u1(n−t), u21, . . . , u(n−t−1)(n−t),

whose indices are in lexicographical order. As a consequence,
rsecrecy(w) can be computed in an explicit way

rsecrecy(w) =

|(u12

u13 . . .
l

S

S

uxy)/uh|

(5)

for some x, y with 1 ≤ x < y ≤ n − t and

w =

n − t

(cid:18)

2 (cid:19)

−

n − t − x
2

(cid:18)

(cid:19)

− (n − t − y).

n−t
2

.
(cid:1)

The number of constrains is therefore reduced to

If we apply the relaxed criteria to the combinational key

(cid:0)

scheme with a > 2, it can be shown that

rsecrecy(w) = (cid:0)

n−t
a

−

n−t−x
a
(cid:1)
n−1
a−1

(cid:0)

−

n−t−y
a−1

(cid:0)

.

(cid:1)

(cid:1)

If we apply the relaxed criteria to the random key scheme

(cid:0)

(cid:1)

with probability p, it can shown that

rsecrecy(w) =(1 − p)t[α(n − t)/p − (1 − p)xα(n − t − x)/p
− (1 − p)y−1(1 − (1 − p)n−t−y)],

where α(n) = 1 − (1 − p)n − np(1 − p)n−1 is the probability
that a secret bit is distributed to at least two nodes among n
nodes.

For the criteria of Theorem 4,

instead of determining
whether there exists a feasible solution of {xij
G} for all
possibilities of hacked nodes Nh, it is much easier to check
whether a concrete solution is feasible. Speciﬁcally, given a
set of hacked nodes Nh, we can construct {xij

G} such that

xij
G =

|uG/uh|
|G|

G′:i,j∈G′⊆Ns

|uG′ /uh|
|G′|

(1 + ǫ)rij ,

(6)

P

where |G| is the number of nodes in G and ǫ > 0 is small.
This {xij

G} satisﬁes

rij <

XG|i,j∈G⊆Ns

xij
G = (1 + ǫ)rij

for all (i, j) ∈ Ps with rij > 0. If

xij
G ≤ rsecrecy(G, Nh)

Xi,j∈G

holds for all G ⊆ Ns, then there must be a feasible solu-
tion such that the equalities hold, and the channel rates are
achievable. This can be used to check the security of the
combinational key scheme.

V. DISCUSSIONS

In this section we provide some further discussions, in-
cluding the security strength with channel rates near their
theoretical limit, the application of network coding, and several
open questions.

6

A. Security Beyond Limit

Can a network continue to communicate when its channel
rates reach or even exceed the theoretical limit? We demon-
strate that the network communication near the theoretical
limit is still more secure than cryptographic approaches that
are based on some unproven assumptions about computational
hardness.

Let us study a simpliﬁed model: let u ∈ {0, 1}u be a
sequence of random bits with u very large, and a secret key
s ∈ {0, 1}m with u < m < 2u is generated with a random
linear transformation on u, i.e., s = M u, where M is a
random matrix. Let x ∈ {0, 1}m be the transmitted message,
then the ciphertext generated using the one-time pad scheme
is

over node-disjoint paths (only the channels whose rates are
below the limit are used) to the destination. Two nodes can
communicate to each other with perfect secrecy if and only if
there exits at least t + 1 node-disjoint paths connecting them.
It is worth mentioning that this network-coding approach
based on multiple paths is very expensive: it costs at least
2(t + 1) times of secret-bit resources (more precisely propor-
tional to the number of channels in the selected t + 1 node-
disjoint paths), and introduces much more communication
latency. Furthermore, it may bring in additional adversaries,
as some hacked nodes may interrupt the communication by
modifying relayed packets or injecting corrupted packets,
know as Byzantine adversaries [5], [6].

y = s + x = M u + x.

C. Further Questions

Attacking the system is to derive some information about x
from y and M . Although perfect secrecy is not guaranteed,
it
is extremely difﬁcult to derive some information about
x when the dimension u is very large for the following
reasons. Firstly, the attacking process is analog to the decoding
of a linear random code, with u being the message, s as
the codeword, and x as the noise. It has been proven that
ﬁnding the x with the minimum Hamming weight is NP-
complete [23]. Secondly, there are some uncertainties in the
message x especially when the message is compressed. Even
an eavesdropper is possible to search all the 2u possibilities
of u with unlimited computing power, given y and M ,
there are about 2O(H(x)+|u|−|y|) feasible choices for x. It is
almost impossible for an eavesdropper to choose the right
one. Thirdly, as in our proposed schemes,
the secret key
is generated by jointly utilizing all the common secret bits
between the two terminals (not block by block). Attacking the
system needs to solve the values of the common secret bits
together, which is very difﬁcult in a typical application with
each node storing more than gigabytes of secret bits.

B. Network Coding

According to Theorem 3, a channel rate rij reaches its limit
if there exists a set of hacked nodes Nh and a set of channels
P ⊆ Ps that includes the channel (i, j) such that

ri′j′ ≥ rsecrecy(P, Nh).

X(i′,j′)∈P

In this case, the channel (i, j) cannot support more communi-
cations with end-to-end encryption. But it is still possible for
node i to communicate to node j via network coding.

A solution of network coding that can be used here is called
“secret sharing” [24]. In order to tolerate t nodes to be hacked,
the source node encodes the message into t + 1 packets such
that no eavesdropper can obtain any information about the
message unless getting all the t + 1 packets. For example,
let x ∈ {0, 1}m be the message to communicate, then it is
encoded into

r1,

r2,

. . . ,

rt,

r1 + . . . + rt + x

with the random-bit sequence ri ∈ {0, 1}m as the ith packet
for 1 ≤ i ≤ t. Then the source node sends the t + 1 packets

In this paper, we work on a framework that studies the
problem of network communication with the information-
theoretic security when each node is allowed to carry some
pre-distributed randomness. This work is an extension of the
well-known one-time pad scheme from ‘links’ to ‘networks’.
There are several questions that are not completely solved in
this paper, which deserve further studies.

1) The tradeoff between the maximum network rate and the
maximum channel rate for a network without any nodes
being hacked is given in Theorem 2. A natural question
is how to extend it to a network with t > 1.

2) The criteria in Theorem 3 are both necessary and sufﬁ-
cient for guaranteeing the information theoretic security.
It is also proved that the criteria in Theorem 4 are
sufﬁcient, but it is unclear whether they are necessary
or not.

This paper mainly focuses on networks with symmetric key
distribution, where every network node can carry the same
number of secret bits. The models, methods and analysis
developed can be naturally extended to some other occasions,
such as a clustered network or a centralized network. For
example, if a network has a trustable central node with a
larger storage space, one may distribute all the secret bits to
this central node and meanwhile each secret bit is also shared
by some of the other nodes. This allows the central node to
easily communicate with the other nodes and monitor all the
messages transmitted over the network.

VI. PROOFS OF MAIN RESULTS

In this section we provide proofs of our main results.

A. Proof of Theorem 1

The network capacity is easy to derive: The total message

length communicated with a node cannot exceed l, hence

(
Xj>i

Xi

mij +

mji) ≤ nl.

Xj<i

2 on
This leads to
the network capacity. This upper bound is achievable using
the simple pairwise key scheme when t ≤ n − 2. We continue

2 , yielding the upper bound n

mij ≤ nl

P

(n−t−2
a−2 )
(n−1
a−1)

with

The total amount of memory needed to store the distributed

secret bits is

7

to prove that the channel capacity is at most
a = ⌈ n

t+1 ⌉, and it’s achievable.

Given the sequence of secret bits stored in node i, ui, for
all i ∈ N, the entropy of ui is at most l. Due to the symmetry
of the network, without loss of generality, we assume that
the ﬁrst t nodes are hacked, then the hacked secret bits are
uh = ut
1 = u1u2 . . . ut, and the maximal number of message
bits that can be securely communicated between node t + 1
and node t + 2 is the mutual information between ut+1 and
ut+2 conditioning on ut
1. As a result,

Cchannel ≤

I[ut+1; ut+2|ut
1]
l

.

Since I[ut+1; ut+2|ut

1] is invariant under any permutation

of node indices, for simplicity, we can rewrite it as I(2|t).

We can generalize this concept of conditional mutual infor-

mation to a higher order as

I(a|b) = I[ub+1; . . . ; ub+a|ub
1]
1] − I[ub+2; . . . ; ub+a|ub+1
= I[ub+2; . . . ; ub+a|ub

1

],

with the short notations,

I(a|b) = I(a − 1|b) − I(a − 1|b + 1).

(7)

This quantity I(a|b) is the amount of mutual information
among all the a nodes given the secret bits of any other b
nodes.

From (7), it can be shown that

n

I(1|0) =

Xa=1
where I(1|0) = H(ui) ≤ l.

On the other hand,

n − 1
a − 1(cid:19)

(cid:18)

I(a|n − a),

I(2|t) =

n−t

n − t − 2

(cid:18)

Xa=2

a − 2 (cid:19)

I(a|n − a).

From (8) and (9), we get

I(2|t)
I(1|0)

≤

n−t
max
a=2 (cid:0)
(cid:0)

n−t−2
a−2
n−1
a−1

(cid:1)

(cid:1)

n

n

(pau)a = (

paa)u ≤ nl.

(10)

Xa=0

Here, we write E(f (a)) =

Xa=0
n
a=0 paf (a) for a function f (a).
Firstly, the total number of secure message bits is upper
bounded by the total number of secret bits u, hence the
maximum network rate

P

Rnet(ψ) ≤

u
l

≤

nl
E(a)l

=

n
E(a)

.

(11)

Secondly, the number of message bits that can be securely
communicated over a channel is upper bounded by the number
of common secret bits shared by the two terminals. If the key
distribution is symmetric, then
u12
l

Rchannel(ψ) ≤

n−2
a−2
n
a

(cid:1)

(cid:1)

=

=

≤

≤

(upa) (cid:0)

1
l Xa≥2
(cid:0)
uE(a(a − 1))
l · n(n − 1)
E(a(a − 1))
E(a)(n − 1)
n + 1
n − 1

−

2n
E(a)(n − 1)

.

(12)

(8)

The last step follows since a(a − 1) ≤ (n + 1)a − 2n for
2 ≤ a ≤ n.

From(11) and (12), we obtain

Rnet(ψ)

2
n + 1

+ Rchannel(ψ)

n − 1
n + 1

≤ 1.

(9)

Let us prove the achievablity, starting from two simple
schemes. In the ﬁrst scheme (called the same key scheme), all
the nodes share the same set of secret bits, and its maximum
rates are

,

Rnet(ψsame) = 1, Rchannel(ψsame) = 1.

(13)

where the maximum is achieved with a = ⌈ n

t+1 ⌉. As a result,

I(2|t) ≤ (cid:0)

n−t−2
a−2
n−1
a−1

l with a = ⌈

n
t + 1

⌉.

(cid:1)

(cid:0)

(cid:1)

This leads to the upper bound on the channel capacity. This
upper bound can be achieved with the combinational key
scheme with a = ⌈ n
t+1 ⌉ if the underlying privacy ampliﬁcation
is asymptotically optimal.

B. Proof of Theorem 2

Given a scheme ψ, let u ∈ {0, 1}u be the independent
sequence of random bits from which the distributed secret bits
are chosen. Denote the fraction of bits that are distributed to
exactly a nodes by pa with 0 ≤ pa ≤ 1 and

n

Xa=0

pa = 1.

The second scheme is the pairwise key scheme, whose

maximum rates are

Rnet(ψpair) =

n
2

, Rchannel(ψpair) =

1
n − 1

.

(14)

The equality in the theorem holds both for the same key
scheme and the pairwise key scheme. Here we construct a
scheme as the hybrid of the two simple schemes. For each
node, it uses a fraction 0 ≤ λ ≤ 1 of its storage space for the
same key scheme and the rest for the pairwise key scheme.
The maximum rates for the hybrid scheme ψhybrid are

Rnet(ψhybrid) = λ +

Rchannel(ψhybrid) = λ +

(1 − λ),

n
2

1
n − 1

(1 − λ).

By adjusting the fraction λ, we can obtain all the maximum
network rates and the maximum channel rates meeting the
equality in the theorem.

C. Proof of Theorem 3

The necessity is easy to prove: if there exists a subset of
channels violating (3), then their total message length must be
larger than the number of their used unhacked secret bits. As
a result, at least one of these messages must be information-
theoretically insecure.

To prove achievability, we consider a simple method for
privacy ampliﬁcation: for every channel (i, j), given the com-
mon secret bits uij , the secret key sij = Mijuij with a sparse
random matrix Mij of density O(log l/l). The reason of using
this method is not only due to its asymptotic optimality, but
also to its practicality. It is the basis of our proposed network
schemes.

Let ss = {sij|(i, j) ∈ Ps} be the secret keys between
unhacked nodes, and let uh be the distinct secret bits stored
in hacked nodes, which are disclosed to the eavesdropper. The
network communication is information-theoretically secure if
and only if for any possible set of hacked nodes Nh, the secret
keys ss and the hacked secret bits uh are truly random bits,
and ss, uh are independent. Note that both ss and uh can be
written as linear transformations of the source sequence u.

Let z be the concatenation of ss and uh, then

z = ssuh = M u

(15)

for some matrix M . The network is information-theoretically
secure if and only if all the rows in matrix M are linearly
independent.

We can write the secret key sij as

′

sij = A

ij (uij /uh) + B
= Aij (u/uh) + Bij uh

′

ij(uij ∩ uh)

for some matrices Aij and Bij , where Aij is an (lrij)×|u/uh|
matrix consisting of |uij /uh| random columns of density
O(log l/l) and |u/uh| − |uij /uh| zero columns.

Then z = ssuh is represented by

z = M u =

A B
0

I (cid:19) (cid:18)

u/uh
uh (cid:19)

,

(cid:18)

(16)

where I is an identity matrix and A consists of all the matrices
Aij with (i, j) ∈ Ps. The network is perfectly secure if the
rows in M are linearly independent. This is equivalent to
showing that the rows in A are linearly independent, i.e., all
the rows in {Aij|(i, j) ∈ Ps} are linearly independent. This
can be proved based on the following results.
Lemma 5. All the rows in {Aij |(i, j) ∈ Ps} are linearly
independent if and only if for any subset of channels P ⊆ Ps,
there does not exist any subset of rows from {Aij|(i, j) ∈ P }
that includes at least one row from each matrix such that their
sum is a zero-vector.
Lemma 6. Given any subset of channels P ⊆ Ps, if sij =
Mijuij with a random matrix Mij of density O(log l/l) and
(i,j)∈P |sij|
| ∪(i,j)∈P uij/uh|

< 1

P

with | ∪(i,j)∈P uij/uh| = O(l), when l → ∞, with proba-
bility almost 1 there does not exist any subset of rows from

8

{Aij|(i, j) ∈ P } that includes at least one row from each
matrix such that their sum is a zero-vector.

The proof of Lemma 6 is provided in subsection VI-E.
Finally, we can conclude that the rows of the security matrix
M are linearly independent with high probability, and the
criteria in Theorem 3 are sufﬁcient.

D. Proof of Theorem 4

Using the same proof as Theorem 3, the network is perfectly
secure if and only if the rows of the matrix A in (16) are
linearly independent. In Theorem 4, for this matrix A, it has
the following properties: there are |uG/uh| columns in A
corresponding to the bits in uG/uh, in which each column has
(i,j)∈G mij random entries with mij = l · rij corresponding

to the bits in {sij} with i, j ∈ G.
P

The rank of the matrix A remains unchanged if we do
elementary row or column operations on A. The rows of a
matrix are linearly independent if and only if the the matrix can
be reduced to the simplest form [I, 0] by elementary operations
such that it consists of an identity matrix and a zero matrix.
ij }, we can divide the
columns corresponding to the bits in uG/uh into some groups
of sizes {uG
ij = |uG/uh|.
ij and
On the other hand, we can divide the rows corresponding
ij =

to the bits in sij into some groups of sizes {mG
l · yG

If there exists a feasible solution for {xG

ij} with mG

ij} with uG

ij = l · xG

i,j∈G uG

P

ij and

yG
ij =

rij
G xG
ij

xG
ij ,

mG

ij = |sij|.

XG|i,j∈G

P

ij <

ij = 0.

According to the inequalities in the theorem, it has either yG
ij or yG
xG
Based on the row groups and the column groups,

the
ij}|×|{uG
matrix A is divided into |{mG
ij}| sub-matrices, whose
dimensions are {mG
ij} × {uG
ij}. By switching the rows and
columns of the matrix A, the matrix A can be transformed into
ij × uG
a form such that the sub-matrices of dimensions {mG
ij}
are on the diagonal of the sub-matrices. We denote the sub-
matrices on the diagonal by [A1, A2, . . .] = {AG
ij}, and the
matrix A is transformed to

A1
. . .
... A2
...
. . .

. . .
...
. . .

.







A ⇔







The sub-matrices [A1, A2, . . .] are random matrices of density
O(log l/l). The dimension of the sub-matrix Ai is mi × ui for
some mi, ui such that mi
ui

< 1 for ui = O(l) or mi = 0.

For the sub-matrix A1, according to Lemma 7 in subsection
the rows of A1 are linearly independent with high
VI-E,
probability when l is sufﬁciently large. The sub-matrix A1
can be reduced to its simplest form [I1, 0] consisting of an
identity matrix and a zero matrix by elementary operations on
A. Furthermore, all the other entries on the right of A1 (in
the same rows with A1) can be reduced to 0 by elementary

column operations. Right now, each sub-matrix Ai with i > 1
is transformed to A′

i with
A′

i = Ai + Ai

0



A′
2

A ⇔

for some Ai independent of Ai, and the matrix A is reduced
to

0
...
. . .

I10
...
...
We continue repeating the above process
3, ..., iteratively. For the sub-matrix A′
2, A′

to handle
A′
i = Ai +Ai, it can
be proved that the conclusion of Lemma 7 still holds, and all
the rows of A′
i are linearly independent with high probability
when l is sufﬁciently large.









. . .



.

Finally, all the sub-matrices [A1, A2, ...] are reduced to their
simplest forms with high probability, and all the other entries
on their right are 0s. In this case, the matrix A is reduced to
the reversed row echelon form, and it has full rank. Hence
all the rows of the matrix A are linearly independent with
high probability if l is sufﬁciently large. This leads to the
achievability of the channel rates.

E. Proof of Lemma 6

We ﬁrst prove the following result.

Lemma 7. Let M ∈ {0, 1}k×r be a random matrix such that
the probability of each entry being 1 is p = O(log r/r). The
rows in M are linearly independent with high probability for
sufﬁciently large r if and only if k/r < 1.

Each row in M is an independent random vector. The sum
of any j rows in M is still an independent vector. Denote the
probability of its entry being 1 by pj.

It is easy to show that

pj = pj−1(1 − p) + (1 − pj−1)p,

from which and by induction, we obtain

pj =

1
2

−

1
2

(1 −

2d
r

)j.

Furthermore, since the sum of any j rows is an independent

vector, the probability for it being a zero-vector is

Pj(0) = (1 − pj)r.

The rows of M are linearly independent if and only if for
any subset of the rows, their sum is not a zero-vector. Hence,
the probability of the rows of M being linearly independent

Pindep(M ) ≥ 1 −

k

Xj=1

k
j(cid:19)

(cid:18)

Pj(0),

where

k
j
This leads to
(cid:1)

(cid:0)

is the number of subsets consisting of j rows.

When j < r

2d with r sufﬁciently large, it has

9

k
(
j(cid:19)

(cid:18)

1
2

+

1
2

(1 −

2d
r

)j)r

kj(1 −

dj
r

+

j(j − 1)d2
r2

)r

kj(1 −

dj
2r

)r

rj e−dj/2

r
2d

Xj=1
r
2d

Xj=1
r
2d

Xj=1
r
2d

Xj=1
r
2d

≤

≤

≤

≤

(elog r−d/2)j → 0.

Xj=1

When r

2d ≤ j < r

3 log r with r sufﬁciently large, it has

r
3 log r

Xj= r
2d
r
3 log r

Xj= r
2d

≤

k
j(cid:19)

(

1
2

(cid:18)

+

1
2

(1 −

2d
r

)j)r

k
j(cid:19)

(

1
2

(cid:18)

+

e−1
2

)r

≤r

r

3 log r +1(

≤r(e

1
3 (

1
2

+

+

1
2
e−1
2

e−1
2

)r

))r → 0.

When j ≥ r

3 log r with r sufﬁciently large, it has

k

Xj= r

3 log r

k

Xj= r

3 log r

≤

k
(
j (cid:19)

(cid:18)

k
(
j (cid:19)

(cid:18)

1
2

1
2

+

1
2

(1 −

2d
r

)j)r

+

3 log r

e− 2d
2

)r

)r

+

3 log r

e− 2d
2

1
2
r −1(1 + e− 2d
r −1)r → 0.

k

k

≤2k(

=(2

→(2

3 log r ))r

Summing the above results up, we obtain

Pindep(M ) ≥ 1 − ǫ

for any ǫ > 0 when r is sufﬁciently large.

Lemma 8. Given Si ⊆ {1, 2, . . . , r} with 1 ≤ i ≤ k, let
Mi ∈ {0, 1}mi×r with 1 ≤ i ≤ k be a binary matrix such
that each entry in columns Si is 1 with probability O(log r/r)
and each entry not in columns Si is 0. If Pi mi
|∪iSi| < 1 and
| ∪i Si| = O(r), as r → ∞, with high probability there does
not exist any subset of rows from {Mi} that includes at least
one row from each matrix such that their sum is a zero-vector.

Pindep(M ) ≥ 1 −

k

Xj=1

k
(
j(cid:19)

(cid:18)

1
2

+

1
2

(1 −

2d
r

)j)r.

(17)

We say that a set of matrices {Mi} are linearly cross-
independent if and only if there does not exist a subset of

rows from {Mi} that includes at least one row from each
matrix such that their sum is a zero-vector. If the rows of
M1, M2, . . . , Mk are linearly cross-independent, it does not
necessarily imply that these rows are linearly independent. For
example, consider the matrices

M1 =

1 1
1 1

(cid:18)

0
0 (cid:19)

, M2 =

0 1

1

(cid:0)

(cid:1)

The rows in M1, M2 are linearly cross-independent, but not
linearly independent, as the rows in M1 are not
linearly
independent.

One observation is that

if {Mi} are linearly cross-
independent on a subset of columns, then {Mi} are linearly
cross-independent on all the columns.

We divide the columns into at most 2k groups depending
on which Si the column belongs to. Two columns are in the
same group if and only if they belong to the same subset of
{S1, S2, . . . , Sk}. Now, we are only interested in the groups
of size O(r) (sufﬁciently large groups), and the union of their
columns are denoted by S. Then

|S| > | ∪i Si|(1 − ǫ)

for sufﬁciently small ǫ, which leads to Pi mi
|S| < 1 for
sufﬁciently large r. We will prove that the matrices {Mi} are
linearly cross-independent on the columns in S.

Given ℓ = {l1, . . . , lk} with 1 ≤ li ≤ mi, we choose li
rows from Mi with 1 ≤ i ≤ k, and we use P (ℓ) to denote
i li chosen rows is a
the probability that the sum of all the
zero-vector on S. Then the probability of the matrices {Mi}
being not linearly cross-independent on S is

P

Pdep. =

k

Xl1,l2,...

Yi=1

mi
li (cid:19)

(cid:18)

P (ℓ).

There are two possibilities considering the chosen

i rows:
r
(1) every column in S has more than
log r random entries in
the chosen rows; and (2) there exists a group (among the up
to 2k groups) of columns in S, whose size is at least b = O(r)
r
log r random entries in
and in which each column has at most
the chosen rows. We use P1(ℓ) to denote the probability that
the sum of chosen rows is a zero-vector on S in the ﬁrst case,
and P2(ℓ) to denote that in the second case. It can be shown
that

P

P1(ℓ) ≤ (

for sufﬁcient small ǫ and

1
2

+ ǫ)|S|

P2(ℓ) ≤ 2k

r
log r

Xj=1

i li
(
j (cid:19)

(cid:18)P

1
2

+

1
2

(1 −

2d
r

)j)b.

Consider all possible choices of ℓ, as r → ∞, the sum

probability of the ﬁrst case is

P1 =

Xl1,l2,...

k

Yi=1
k

≤

Xl1,l2,...

Yi=1

mi
li (cid:19)

(cid:18)

P1(ℓ)

mi
(
li (cid:19)

(cid:18)

1
2

+ ǫ)|S|

10

≤ 2Pi mi(

1
2

+ ǫ)|S|

≤ ǫ

for sufﬁciently small ǫ.

Consider all possible choices of ℓ, as r → ∞, the sum

probability of the second case is

k

Yi=1

mi
li (cid:19)

(cid:18)

P2(ℓ)

i mi
(
j (cid:19)

1
2

+

1
2

(1 −

2d
r

)j)b

P2 =

Xl1,l2,...
r
log r

≤

(cid:18)P

Xj=1

≤ ǫ

for sufﬁciently small ǫ. The last step follows the same proof
as Lemma 7.
Finally,

the matrices {Mi} are not

linearly cross-

independent with probability

Pdep. ≤ P1 + P2 ≤ 2ǫ

as r → ∞. This leads to the conclusion in Lemma 8.

It is straightforward to obtain Lemma 6 from Lemma 8.

REFERENCES

[1] C. E. Shannon, “Communication theory of secrecy systems,” Bell System

Technical Journal, vol. 28, pp. 656-715, 1949.

[2] N. Cai and T. Chan, “Theory of secure network coding,” Proceedings of

the IEEE, 99(3), pp. 421-437, 2011.

[3] T. Cui, T. Ho, and J. Kliewer, “On secure network coding with nonuniform
or restricted wiretap sets,” IEEE Transactions on Information Theory,
59(1), pp. 166-176, 2012.

[4] N. Cai and R. W. Yeung, “Secure network coding on a wiretap network,”
IEEE Transactions on Information Theory, vol. 57, no. 1, pp. 424-435,
Jan. 2011.

[5] T. Ho, B. Leong, R. Koetter, M. M´edard, M. Effros, and D. R. Karger,
“Byzantine modiﬁcation detection in multicast networks using random-
ized network coding.” In Proc. of IEEE International Symposium on
Information Theory (ISIT), Chicago, USA, June 2004.

[6] S. Jaggi, M. Langberg, S. Katti, T. Ho, D. Katabi, and M. M´edard, “Re-
silient network coding in the presence of byzantine adversaries,” in Proc.
of 26th IEEE International Conference on Computer Communications
(INFOCOM), pp. 616-624, May 2007.

[7] Y. Shiu, S. Y. Chang, H. Wu, S. C. Huang and H. Chen, “Physical layer
security in wireless networks: a tutorial,” IEEE Wireless Communications,
vol. 18, no. 2, pp. 66-74, April 2011.

[8] M. Bloch, J. Barros, M. R. Rodrigues, and S. W. McLaughlin, “Wire-
less information-theoretic security,” IEEE Transactions on Information
Theory, 54(6), pp. 2515-2534, 2008.

[9] Y. Liang, H. V. Poor, and S. Shamai, “Information theoretic security,”
Foundations and Trends in Communications and Information Theory, 5(4-
5), pp. 355-580, 2009.

[10] L. Dong, Z. Han, A. P. Petropulu, and H. V. Poor, “Improving wireless
physical layer security via cooperating relays,” IEEE Transactions on
Signal Processing, 58(3), pp. 1875-1888, 2010.

[11] Y. Liu, Z. Qin, M. Elkashlan, Y. Gao, and L. Hanzo. “Enhancing the
physical layer security of non-orthogonal multiple access in large-scale
networks,” IEEE Transactions on Wireless Communications, 16(3), pp.
1656-1672, 2017.

[12] U. M. Maurer and S. Wolf, “Information-theoretic key agreement: From
weak to strong secrecy for free,” in Proc. of International Conference
on the Theory and Applications of Cryptographic Techniques, Berlin,
Heidelberg, pp. 356-373, May 2000.

[13] C. H. Bennett, G. Brassard, and J. M. Robert, “Privacy ampliﬁcation
by public discussion,” SIAM Journal on Computing, vol. 17, no. 2, pp.
210-229, 1988.

[14] U. Maurer, “Secret key agreement by public discussion from common
information,” IEEE Transactions on Information Theory, vol. 39, no. 3,
pp. 733-742, May 1993.

11

[15] C. H. Bennett, G. Brassard, C. Crepeau, and U. M. Maurer, “Generalized
privacy ampliﬁcation,” IEEE Transactions on Information Theory, vol. 41,
no. 6, pp. 1915-1923, 1995.

[16] J. L. Carter and M. N.Wegman, “Universal classes of hash functions,”
Journal of computer and system sciences, vol. 18, no. 2, pp. 143-154,
1979.

[17] H. Zhou, V. Chandar, and G. Wornell, “Low-density random matrices
for secret key extraction,” in Proc. of IEEE International Symposium on
Information Theory (ISIT), 2013.

[18] R. A. Chou, M. R. Bloch, and E. Abbe, “Polar coding for secret-key
generation,” IEEE Transactions on Information Theory vol. 61, no. 11,
pp. 6213-6237, 2015.

[19] R. Gallager. “Low-density parity-check codes,” IRE Transactions on

information theory, vol. 8, no. 1, pp. 21-28, 1962.

[20] L. Eschenauer and V. D. Gligor, “A keymanagement scheme for dis-
tributed sensor networks,” in Proc. of 9th ACM Conference on Computer
and Communication Security, pp. 41-47, Nov. 2002.

[21] H. Chan, A. Perrig, and D. Song, “Random key predistribution schemes
for sensor networks,” in Proc. of IEEE Symposium on Research in Security
and Privacy, 2003.

[22] J. Katz and Y. Lindell, “Introduction to modern cryptography: principles
and protocols,” Chapman and Hall/CRC, ISBN 978-1584885511, 2007.
[23] E. Berlekamp, R. McEliece, and H. van Tilborg, “On the inherent
intractability of certain coding problems,” IEEE Transactions on Infor-
mation Theory, vol. 24, no. 3, pp. 384-386, 1978.

[24] A. Shamir, “How to share a secret,” Commun. ACM, vol. 22, pp. 612-

613, November 1979.

