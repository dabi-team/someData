GENERATING CYBER THREAT INTELLIGENCE TO DISCOVER
POTENTIAL SECURITY THREATS USING CLASSIFICATION AND
TOPIC MODELING

Md Imran Hossen∗
School of Computing and Informatics
University of Louisiana at Lafayette
Louisiana, USA
md-imran.hossen1@louisiana.edu

Ashraful Islam∗
School of Computing and Informatics
University of Louisiana at Lafayette
Louisiana, USA
ashraful.islam1@louisiana.edu

Farzana Anowar†
Department of Computer Science
University of Regina
Regina, Canada
anowar@uregina.ca

Eshtiak Ahmed†
Faculty of Information Technology and Communication Sciences
Tampere University
Tampere, Finland
eshtiak.ahmed@tuni.fi

Mohammed Masudur Rahman†
Department of Computer Science and Engineering
Bangladesh University of Engineering and Technology
Dhaka, Bangladesh
masudurism@gmail.com

ABSTRACT

Due to the variety of cyber-attacks or threats, the cybersecurity community enhances the traditional
security control mechanisms to an advanced level so that automated tools can encounter potential
security threats. Very recently, Cyber Threat Intelligence (CTI) has been presented as one of the
proactive and robust mechanisms because of its automated cybersecurity threat prediction. Generally,
CTI collects and analyses data from various sources e.g., online security forums, social media where
cyber enthusiasts, analysts, even cybercriminals discuss cyber or computer security-related topics and
discovers potential threats based on the analysis. As the manual analysis of every such discussion
(posts on online platforms) is time-consuming, inefﬁcient, and susceptible to errors, CTI as an
automated tool can perform uniquely to detect cyber threats. In this paper, we identify and explore
relevant CTI from hacker forums utilizing different supervised (classiﬁcation) and unsupervised
learning (topic modeling) techniques. To this end, we collect data from a real hacker forum and
constructed two datasets: a binary dataset and a multi-class dataset. We then apply several classiﬁers
along with deep neural network-based classiﬁers and use them on the datasets to compare their
performances. We also employ the classiﬁers on a labeled leaked dataset as our ground truth. We
further explore the datasets using unsupervised techniques. For this purpose, we leverage two
topic modeling algorithms namely Latent Dirichlet Allocation (LDA) and Non-negative Matrix
Factorization (NMF).

Keywords Cyber threat intelligence · CTI · Hacker forum · Cyber-attack · Machine learning · Topic modeling

∗Authors contributed equally and share co-ﬁrst authorship
†Authors contributed equally and share co-second authorship

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

1

Introduction

1.1 Background and Motivation

Cybersecurity is one of the most key concerns among users [1, 2, 3]. Cybercriminals are delivering more strong and
advanced security threats constantly to gain security control over the networks i.e. Internet [1, 3, 4]. During the previous
decades, computer security was bound in only preventing computer viruses and another most common security issue
was email spamming [5, 6]. But, in recent years, cybercriminals are making targeted attacks so that they can obtain the
whole control from the users. Over the online community, topics related to computer security are the most popular and
community members discuss prior and possible security threats in social media, hacker forums [1, 2, 7, 8]. Hacker
forums are the most valuable source for computer security related posts, blogs and these posts usually contain vital
information about possible computer and cybersecurity threats or holes [1, 2].

Cyber Threat Intelligence, abbreviated as CTI, can be deﬁned as a knowledge and intelligence which assists in collecting,
analyzing, understanding, preventing possible cyber-attacks based on gathered data from various security related sources
e.g. hacker forums and by transferring analyzed data to possible cyber threats in meaningful representations [2, 3, 8].
According to Gartner [9]:

“Threat intelligence is evidence-based knowledge, including context, mechanisms, indicators, im-
plications, and action-oriented advice about an existing or emerging menace or hazard to assets.
This intelligence can be used to inform decisions regarding the subject’s response to that menace or
hazard.”

In general, CTI usually compiles data from diverse sources (usually of unstructured nature) such as the National
Vulnerability Database (NVD), social media platforms, e.g., Facebook, Twitter, and computer security forums, and uses
scientiﬁc methods to convert it to the meaningful representation of threats [2, 3, 10, 11]. In this way, CTI can provide
insights into emerging security threats and may help prevent possible and potential cyber-attacks [1, 12].

1.2 Problem Statement and Goal

The hackers are constantly posting and sharing information about diverse cybersecurity-related topics on online forums
[1, 8]. The posts on these forums can hold data that may help assist in the discovery of cyber threat intelligence.
However, manual analysis of this highly unstructured data could be tedious and ineffective [4, 11, 13]. The goal of
this work, therefore, is to design and develop a set of procedures to collect, process, and analyze hacker forums data to
discover emerging threats. Once we have constructed datasets, classiﬁcation tasks could be apply to the posts so that
classiﬁers can distinguish security-relevant posts from irrelevant ones. Furthermore, we can categorize security-relevant
posts in more speciﬁc cyber threat categories e.g. credential leaks, keyloggers, DDoS attacks, etc.

Moreover, we utilize topic modeling algorithms to the whole datasets as well as on each security-relevant class so that
we can explore latent topics available in the datasets. For example, if we discover a category that holds a discussion
about ransomware, and if our topic modeling algorithm ﬁnds keywords like WannaCry, and Petya for this topic, we
would know that these are the current trends in ransomware-based attacks.

The contributions of this research are two-folded.

• Designing and developing a set of procedures to collect, process and analyze data from open source hacker

forums.

• Generating CTI from processed data to discover emerging threats by utilizing the knowledge of Information

Retrieval (IR). This stage can be done in three phases as following:

– Identify security-relevant posts from non-relevant/irrelevant ones (Classiﬁcation problem).
– Categorize security-relevant posts according to different threat categories (Classiﬁcation problem).
– Explore key topics in the dataset using topic modeling algorithms (Unsupervised learning).

2 Methodology

This research work is implemented by performing several sequential stages. The following stages are involved in
developing our intended goal i.e. mining and classifying hacker forums’ data for fathering CTI. Figure 1 demonstrates
the steps of the methodology for extracting CTI from the hacker forums.

2

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

Figure 1: Steps that were followed for extracting CTI.

2.1 Data Collection

We ﬁrst collect data from the posts shared in hacker forums that are posted by computer and network security loving
persons, analysts, and experts. Collecting data from hacker forums is a challenging task for several reasons: a) the
forums usually restrict the access to their content only to registered users making it difﬁcult to build a web crawler to
collect data automatically, b) some forums use CAPTCHAs to prevent automated programs that are used to collect data.
To make things worse, forums often employ invitation-only registration; one can register only when someone who is
already registered on the forum sends him/her an invitation. Alternatively, we may use some publicly available datasets
on the internet.

However, we ﬁnd some decent forums that do not have such restrictions, e.g., [14, 15]. Also, it is noted that we only
use the data from the second forum since the ﬁrst one does not seem to contain a good amount of posts. We build two
separate crawlers (using Python) to collect posts from these forums, which in turn will be used to make the corpus.
Moreover, we utilized a leaked dataset which is labeled by the experts and it is used as the ground truth dataset for this
work from https://nulled.io.

2.2 Pre-processing and Dataset Construction

Generally, data collected from the web are highly unstructured. Some preprocessing is necessary before we create the
ﬁnal dataset. Hence, ﬁrst, we clean up the HTML tags and extract the title and content of each post found in the forums,
second, we remove stop words, special characters, punctuation after transforming all the text into lower-case. Further,
lemmatization is also used so that we can obtain more clean and optimized text collection to build the datasets. Once
the data is reasonably cleaned up, we represent each post as a single line document to build a corpus.

Our target is to build two datasets for both binary classiﬁcation and multi-class classiﬁcation. We build separate datasets
for each security forums we crawled and preprocessed. Both datasets are constructed using the keyword search method
where we label each sample based on keyword relevancy.

A list of very common cybersecurity keywords are used for labeling the relevant class are- adware, antivirus, botnet,
backdoor, crack, crimeware, crypter, ddos, downloader, dropper, exploit, ﬁrewall, hijack, infect, keylogger, malware,
password, ransomware, reverse, shell, rootkit, scanner, shell, code, security, spam, spoof, spyware, trojan virus,
vulnerability, worm, zero-day, stealware.

3

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

We attempt the following approaches for building both the datasets.

2.2.1 Binary Dataset Construction

Binary dataset has two labels or classes i.e. relevant, irrelevant. The samples bearing the posts containing keywords
relevant to computer security are labeled as relevant. Some common relevant keywords that we approach are ‘exploit’,
‘keylogger’, ‘reverse shell’, ‘antivirus’, ‘ransomware’, etc. Other samples are labeled as irrelevant as they contain
irrelevant keywords such as ‘song’, ‘tv show’, ‘browsing’, ‘football’, etc. Since the number of security keywords are
not comprehensive we label a post as irrelevant if it satisﬁes these two properties –

• None of the keywords from the relevant class is present, and
• Any computer security related keywords are absent.

Table 1 shows two samples from the binary dataset for better understanding where relevant keywords are underlined.
Figure 2 presents the distribution of sampler for each class i.e. relevant, irrelevant. Table 1 contains examples of posts
labeled in the binary dataset.

Table 1: Two samples collected from binary dataset (Posts collected from various sources found in Internet for dataset
construction).

Post
“... Here is a .php ﬁle from an exploit, downloaded from
... Apache APR is prone to a vulnerability that may
allow attackers to cause a denial-of-service condition
...”
“... Good work, its good to learn how to do things
yourself. Its a very rewarding experience ...”

Class Label
Relevant

Irrelevant

Figure 2: Samples (posts) distribution per class i.e. relevant, irrelevant

2.2.2 Multi-class Dataset Construction

At this phase, we build another dataset from the samples labeled as relevant in the binary dataset. This dataset contains
samples labeled in six categories and the categories are-

• Credential Leaks (Keywords: username, password, pass list, etc.)
• Keylogger (Keyword: keylogger )
• DDoS Attack (Keywords: ddos, denial of service, server, etc.)
• Remote Access Trojans (Keywords: rat, trojan, remote access, etc.)
• Cyrpters (Keywords: crypter, fud, etc.)

4

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

• SQL Injection (Keywords: sql, injection, id=, etc.)

Table 2 contains examples of posts labeled in the multi-class dataset.

Table 2: Few samples collected from the multi-class dataset constructed from the relevant class (Posts collected from
various sources found in Internet for dataset construction).

Post
“Leaked data for ***
USERNAME / PASSWORD
hope0507 : ***
jimsam100234:***”
“The Best Keylogger logs all keystrokes, mouse clicks, applications ... sent to you via mail so
you can monitor your computer without being there”
“If you’re not interested in creating a botnet, with a RAT for example ... Which use servers to
DDoS targets ... Written on mobile-phone, sorry for the formatting”
“Initial checker
$newHost = $host.’/interface/ipsconnect.php’;
$sql = ’SELECT COUNT(*) FROM members’;
... $response = SendPost($newHost, $data)”;
“Plasma HTTP BotNet allows you to remotely control computers, known as Clients ... Persistent
(Miner is re-injected if terminated) (...truncated)”
“Application name: Imminent Monitor Application description: Advanced RAT (The others
cracked/leaked here ... Vendor’s URL: http://www.hackforums.net/showthread.php? /”

Class Label

Credential Leaks
Keylogger

DDoS attack

SQL Injection
Crypter

Remote Access
Trojans

2.3 Feature Engineering

Machine learning algorithms cannot directly work with textual data [1, 12, 16, 17]. We need to vectorize the documents
before feeding them as inputs to any learning algorithms, either supervised or unsupervised [13, 18]. To this end,
we explore the best of both worlds for this purpose. First, we use standard feature engineering techniques such as
bag-of-words (BOW) and term frequency-inverse document frequency (TF-IDF)-based weights. Further, both binary
term weights and term-frequency weights measurements are used for the BOW model. Moreover, for TF-IDF based
weighting we use two varieties- word-level unigram and word-level bigram features.

Second, we conduct the experiment with two contemporary and more advanced feature engineering techniques based on
deep learning namely, Word2Vec and Doc2Vec models. Word2Vec is a word-embedding model that learns the semantic
between words in the corpus [19]. There are several pre-trained Word2Vec models available on the internet. Doc2Vec
model performs very well while using with sentiment analysis data [20, 21, 22]. However, none of them are trained on
the cybersecurity-relevant corpus. For this reason, we do not use any trained models and train a Word2Vec model (with
feature_size=100) on our own dataset. Since the Word2Vec model by default does not provide document-level vectors,
we obtain a 100-dimensional vector for each word in a document and summed them up and calculate the ﬁnal averaged
document vector. We do the same for all the documents in the dataset. We also train a Doc2Vec model on our dataset
which directly learns and provides the document-level vectors [23].

2.4 Supervised Method: Classiﬁcation

We ﬁrst carry out classiﬁcation tasks to see how accurately cybersecurity-relevant posts can be separated and identiﬁed
from the non-security posts. This is an important step since the majority of the posts in the hacker forum has nothing to
do with security and serve as noises. Filtering out the noises, provides us the chance to focus more on what we actually
care about and that is security-relevant posts. It also allows us to further inspect and investigate the security-relevant
posts for potential cyber threats. We also evaluate the performance of classiﬁcation for our multiclass dataset.

In our experiment, we use ﬁve different classiﬁcation algorithms along with two neural network learning classiﬁers.
The classiﬁers that we use are: Naive Bayes (NB), Logistic regression (LR), Random Forest (RF), Decision Tree (DT)
and k-nearest neighbors (kNN). We also use one shallow neural network and one deep neural network-based classiﬁers.

2.5 Unsupervised Method: Topic Modeling

Topic modeling is the process of identifying and determining topics in a set of documents. It is an unsupervised learning
approach and can be a powerful tool to ﬁnd possible latent topics (in the form of keywords) in a large unlabeled dataset

5

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

[24, 25]. For instance, say we have a dataset that contains newspaper articles from some major online news agencies.
We provide the number of topics to the algorithm, it will provide top k (number of topics) per topic. By looking at
the keywords for each topic we may be able to tag topics like politics, technology, culture, and so on. It can also be
useful for a labeled dataset to further explore key topics in each class. We use two popular commonly used topic
modeling algorithms in this work. The algorithms are: 1) Latent Dirichlet allocation (LDA), and 2) Non-negative Matrix
Factorization (NMF). We consider ‘frequency weights’ as a feature to LDA as we ﬁnd TF-IDF weights do not seem to
make any difference for this algorithm. In contrast, TF-IDF weights based features are used for the NMF algorithm.

3 Experimental Setup

Data that is used for this work, is collected on a server with 12 Intel R Xeon R E5-2667 CPUs, and 64 GB of RAM
running Debian Linux operating system with Linux kernel version 4.18. We develop and test our code for classiﬁcation
on a server with 6 Intel R Xeon R E5-2667 CPUs, an NVIDIA GeForce RTX 2070 GPU, and 96GB of RAM running
the Arch Linux operating system.

We process the data using standard regular expressions. However, for lemmatization, we use the spaCy library. We also
utilize several open-source Python libraries throughout this research work. We use the scikit-learn libraries to develop
the classiﬁers. The neural network-based classiﬁers are coded in Keras. We use both gensim and scikit-learn libraries
for topic modeling. The gensim library is also used for training Word2Vec and Doc2Vec models.

4 Experimental Results

In the ﬁrst phase of our experiment, we utilize ﬁve regular and two neural network-based classiﬁers. In all of our
experiments, we split the whole data for organizing datasets for both training (67%) and testing (33%). We validate our
code on two datasets, IMDB movie review dataset (binary) [26] and twenty newsgroups dataset (multiclass) [27]. We
ﬁnd that our results are comparable with the given benchmark results. Speciﬁcally, the accuracies vary from 76% to
88% for different classiﬁers with different feature sets on IMDB movie review datasets. For the twenty newsgroups
dataset (only 8 classes have been considered) the accuracies vary from 79% to 89%.

Table 3 lists the performance metrics based on accuracy for different classiﬁers for forums.hak5.org data sets. Table 4
presents the performance metrics in accuracy for different classiﬁers for the nulled.io data sets or our ground truth data
sets.

For topic modeling we utilize two popular algorithms: a) Latent Dirichlet Allocation (LDA) and b) Non-negative
Matrix Factorization (NMF). These algorithms require some k (number of topics) to be passed as an input. Finding
the optimal value of k requires some experimentation. But our goal is about determining the best value of k, rather
we want to explore the datasets and get some more insights of the datasets. We use k as 10 for binary datasets and
apply the algorithm as a dataset as a whole. For multinomial datasets we run LDA and NMF separately on individual
categories. In any cases, we show only the top 05 keywords per category. The topic modeling results are listed in Tables
5-8 (showing only 05 topics in each table and ‘Credentials’ category for the simplicity of the paper).

Table 3: Classiﬁcation accuracy (%) obtained by classiﬁers on the forums.hak5.org dataset

Dataset

Classiﬁer

Binary

Multiclass

Naive Bayes
Logistic Regression
Random Forest
Decision Tree
kNN
Naive Bayes
Logistic Regression
Random Forest
Decision Tree
kNN
Simple Neural Net
Deep Neural Net

Feature Extraction Method

BOW
(Binary term weights)
79.96
93.67
89.88
93.4
47.42
85.67
97.39
89.25
97.39
88.27
86.97
77.85

BOW
(TF weights)
78.96
92.75
89.89
92.8
57.08
83.06
96.09
94.14
97.07
85.99
85.34
87.3

TF-IDF
(Unigram)
75.36
90.69
88.3
92.18
60.01
70.68
83.06
91.86
97.07
77.2
83.81
79.48

TF-IDF
(Bigram)
64.65
68.87
68.55
67.03
53.29
68.4
75.24
70.03
64.5
28.66
78.83
77.85

Word2Vec Doc2Vec

-
64.64
58.4
56.5
59.96
-
48.86
48.53
38.76
49.19
-
-

-
73.85
62.88
58.49
62.61
-
94.46
63.19
54.72
73.62
-
-

6

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

Table 4: Classiﬁcation accuracy (%) obtained by classiﬁers on the nulled.io dataset

Dataset

Classiﬁer

Binary

Multiclass

Naive Bayes
Logistic Regression
Random Forest
Decision Tree
kNN
Naive Bayes
Logistic Regression
Random Forest
Decision Tree
kNN
Simple Neural Net
Deep Neural Net

Feature Extraction Method

BOW
(Binary term weights)
91.65
93.26
92.96
94.62
47.56
74.94
87.06
84.21
86.96
67.84
86.53
87.11

BOW
(TF weights)
90.75
93.06
93.16
94.77
61.44
75.66
86.29
85.27
86.96
69.34
86.05
86.53

TF-IDF
(Unigram)
91.61
92.01
91.76
92.75
78.95
70.01
87.59
85.9
87.01
74.17
85.22
85.66

TF-IDF
(Bigram)
90.71
93.71
9067
88.73
90.42
72.53
57.95
76.2
72.86
46.45
77.84
77.64

Word2Vec Doc2Vec

-
93.1
9.18
87.41
92.95
-
42.49
41.04
34.67
38.88
-
-

-
92.85
92.5
85.26
92.8
-
88.31
64.8
52.34
77.98
-
-

Table 5: Result after applying topic modeling on forums.hak5.org Binary dataset.

Dataset: forums.hak5.org BINARY

Topic Modeling Method: LDA

Topic Keywords
0
1
2
3
4

[‘password’ ‘see’ ‘google’ ‘know’ ‘site’ ‘android’ ‘github’ ‘user’ ‘use’ ‘windows’]
[‘script’ ‘windows’ ‘ﬁle’ ‘usb’ ‘payload’ ‘ﬁles’ ‘work’ ‘ducky’ ‘run’ ‘drive’]
[‘pineapple’ ‘connect’ ‘wiﬁ’ ‘internet’ ‘get’ ‘connection’ ‘network’ ‘port’ ‘router’ ‘connected’]
[‘email’ ‘antenna’ ‘mail’ ‘darren’ ‘signal’ ‘spam’ ‘cp‘ ‘speed’ ‘wait’ ‘antennas’]
[‘http’ ‘www’ ‘php’ ‘hak5’ ‘https’ ‘forums’ ‘code’ ‘like’ ‘index’ ‘page’]

Topic Modeling Method: NMF

Topic Keywords
0
1
2
3
4

[‘like’ ‘get’ ‘know’ ‘use’ ‘something’ ‘work’ ‘time’ ‘want’ ‘see’ ‘really’]
[‘pineapple’ ‘wiﬁ’ ‘internet’ ‘172’ ‘mark’ ‘connect’ ‘ﬁrmware’ ‘via’ ‘connected’ ‘connection’]
[‘php’ ‘hak5’ ‘index’ ‘forums’ ‘topic’ ‘https’ ‘showtopic’ ‘http’ ‘forum’ ‘thread’]
[‘usb’ ‘power’ ‘drive’ ‘ducky’ ‘hub’ ‘rubber’ ‘battery’ ‘adapter’ ‘port’ ‘device’]
[‘ﬁle’ ‘script’ ‘payload’ ‘ducky’ ‘payloads’ ‘bunny’ ‘run’ ‘exe’ ‘ﬁles’ ‘command’]

5 Discussion on Results

In almost all cases the kNN algorithm yields the worst performance comparing to other classiﬁers. It is interesting to
note that the simple term-frequency weights as feature provide better (or similar) results than TF-IDF. We also found
that word-level unigram and bigram for TF-IDF weighting have a minor impact on ﬁnal performance metrics. Further,
using Word2Vec-based feature engineering techniques do not provide any signiﬁcant performance boost. In some
instances, speciﬁcally for multiclass datasets, they actually seem to generate much less accurate results comparing to TF
and TF-IDF weights. One reason can be the fact that we only use 100-dimensional vectors to represent the documents
for both Word2Vec and Doc2Vec. Besides, the multiclass dataset has more categories and a small number of samples per
class when comparing to the binary-class datasets. Increasing the size of the feature vector may result in enhanced
performance. However, it will consume signiﬁcant computing resources to train such a model. For this reason, we
refrain from doing so. We can also see that Doc2Vec-based models perform remarkably better than Word2Vec models.
The Doc2Vec model learns word-level and document level embedding simultaneously. Consequently, it outperforms
Word2Vec where we use simple word vector averaging technique to derive document-level vectors.

It is also noticeable that none of the neural network-based classiﬁers (shallow neural network and deep neural network),
is unable to beat traditional classiﬁers we use in this experiment. While neural networks algorithms, especially deep
neural networks, have made a breakthrough in several computer vision applications and outperform all machine
learning-based approaches, their performance for text classiﬁcation is about the same as the regular classiﬁers. Using
neural network algorithms specialized in Natural Language Processing (NLP) such as Recurrent Neural Network

7

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

Table 6: Result after applying topic modeling on forums.hak5.org Multiclass dataset.

Dataset: forums.hak5.org MULTI-CLASS

Category: ‘Credentials’

Topic Modeling Method: LDA

Topic Keywords
0
1
2
3
4

[‘password’ ‘username’ ‘get’ ‘login’ ‘use’ ‘like’ ‘user’ ‘know’ ‘account’ ‘need’]
[‘password’ ‘username’ ‘ﬁle’ ‘pineapple’ ‘root’ ‘http’ ‘use’ ‘using’ ‘get’ ‘ssh’]
[‘hashcat’ ‘use’ ‘john’ ‘using’ ‘txt’ ‘net’ ‘post’ ‘username’ ‘mimikatz’ ‘gmail’]
[‘barcode’ ‘assets’ ‘date’ ‘ass_tag’ ‘echo’ ‘strlen’ ‘mysql_query’ ‘die’ ‘simpleassets’ ‘update’]
[‘network’ ‘wan2’ ‘option’ ‘uci’ ‘set’ ‘172’ ‘etc’ ‘interface’ ‘conﬁg’ ‘device’]

Topic Modeling Method: NMF

Topic Keywords
0
1
2
3
4

[‘password’ ‘root’ ‘username’ ‘user’ ‘login’ ‘ﬁle’ ‘use’ ‘get’ ‘account’ ‘server’]
[‘wan2’ ‘uci’ ‘network’ ‘set’ ‘12d1’ ‘iptables’ ‘ﬁrewall’ ‘sleep’ ‘172’ ‘init’]
[‘wiﬁ’ ‘pineapple’ ‘connect’ ‘network’ ‘wpa2’ ‘enterprise’ ‘connected’ ‘internet’ ‘client’ ‘using’]
[‘php’ ‘splash’ ‘nodogsplash’ ‘portal’ ‘auth’ ‘page’ ‘html’ ‘evil’ ‘call’ ‘www’]
[‘option’ ‘conﬁg’ ‘255’ ‘ifname’ ‘proto’ ‘interface’ ‘device’ ‘ht_capab’ ‘netmask’ ‘ipaddr’]

Table 7: Result after applying topic modeling on nulled.io binary dataset.

Dataset: nulled.io BINARY

Topic Modeling Method: LDA

Topic Keywords
0
1
2
3
4

[‘http’ ‘www’ ‘color’ ‘https’ ‘application’ ‘php’ ‘url’ ‘topic’ ‘hack’ ‘nulled’]
[‘bol’ ‘bot’ ‘scripts’ ‘legends’ ‘nulled’ ‘download’ ‘work’ ‘login’ ‘use’ ‘auth’]
[‘php’ ‘gmail’ ‘hotmail’ ‘net’ ‘yahoo’ ‘hide’ ‘http’ ‘index’ ‘html’ ‘server’]
[‘hide’ ‘https’ ‘ﬁle’ ‘www’ ‘http’ ‘download’ ‘spoiler’ ‘virus’ ‘link’ ‘virustotal’]
[‘local’ ‘255’ ‘end’ ‘function’ ‘class’ ‘user’ ‘bot’ ‘serverversion’ ‘autoupdatermsg’ ‘true’]

Topic Modeling Method: NMF

Topic Keywords
0
1
2
3
4

[‘like’ ‘script’ ‘get’ ‘use’ ‘know’ ‘thanks’ ‘bot’ ‘crack’ ‘working’ ‘help’]
[‘legends’ ‘bot’ ‘dominate’ ‘login’ ‘download’ ‘available’ ‘enemies’ ‘occur’ ‘monitoring’ ‘freeze’]
[‘hide’ ‘http’ ‘mega’ ‘password’ ‘https’ ‘enjoy’ ‘download’ ‘upvote’ ‘html’ ‘mediaﬁre’]
[‘bol’ ‘scripts’ ‘vip’ ‘studio’ ‘script’ ‘exe’ ‘bolvip’ ‘hijacker’ ‘cracked’ ‘use’]
[‘nulled’ ‘www’ ‘https’ ‘auth’ ‘topic’ ‘php’ ‘http’ ‘access’ ‘need’ ‘cracked’]

(RNN), and long short-term memory (LSTM), perform better in this case [20]. However, we did not use them. There
are two reasons for this decision. First, training RNN based models requires a good amount of computing resources and
they are very slow. Second, our basic classiﬁers have already provided with promising results.

Our experimental results show that running topic modeling algorithms on binary dataset does not uncover security-
relevant keywords. However, when we apply these algorithms ((LDA and NMF) on multi-class datasets as a whole and
separately on each security-relevant category, they provide us with topics and keywords that make much sense in the
context of their security relevance. Further, we ﬁnd that the quality of generated keywords for the given topics depends
signiﬁcantly on preprocessing. If we do not preprocess the data properly, the algorithm may get lost in clutter of words
such as stop words and other commonly used words, and the ﬁnal outcome may not represent the latent topics in the
dataset.

8

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

Table 8: Result after applying topic modeling on nulled.io Multiclass dataset.

Dataset: nulled.io MULTI-CLASS

Category: ‘Credentials’

Topic Modeling Method: LDA

Topic Keywords
0
1
2
3
4

[‘username’ ‘password’ ‘ﬁle’ ‘download’ ‘email’ ‘level’ ‘hide’ ‘region’ ‘pages’ ‘summoner’]
[‘user’ ‘password’ ‘username’ ‘php’ ‘http’ ‘admin’ ‘login’ ‘hide’ ‘www’ ‘script’]
[‘var’ ‘steam’ ‘system’ ‘string’ ‘using’ ‘function’ ‘require’ ‘new’ ‘windows’ ‘data’]
[‘user’ ‘action’ ‘password’ ‘email’ ‘login’ ‘https’ ‘host’ ‘username’ ‘agent’ ‘form’]
[‘password’ ‘username’ ‘account’ ‘accounts’ ‘get’ ‘email’ ‘use’ ‘like’ ‘need’ ‘login’]

Topic Modeling Method: NMF

Topic Keywords
0
1
2
3
4

[‘action’ ‘user’ ‘email’ ‘agent’ ‘login’ ‘host’ ‘form’ ‘https’ ‘referer’ ‘http’]
[‘account’ ‘password’ ‘username’ ‘hide’ ‘bol’ ‘accounts’ ‘get’ ‘login’ ‘nulled’ ‘use’]
[‘checker’ ‘check’ ‘delay’ ‘accounts’ ‘killerabgg’ ‘owned’ ‘pvpnetconnect’ ‘library’ ‘last’ ‘current’]
[‘rune’ ‘pages’ ‘rank’ ‘validated’ ‘skins’ ‘champions’ ‘level’ ‘unranked’ ‘summoner’ ‘region’]
[‘user’ ‘export’ ‘scrape’ ‘press’ ‘select’ ‘pick’ ‘number’ ‘page’ ‘list’ ‘check’]

6 Challenges and Future Scopes

We face several issues throughout this research work, for example, the ﬁrst major challenge is the scarcity of open
source threat intelligence (OSTI) datasets for either analysis or benchmarking. We ﬁnally manage to get a leaked dataset
for nulled.io forum from the internet archive website, https://archive.org that we use as a ground truth. The second
challenge is to collect data from hacker forums for actual experimentation. We observe that most hacker forums employ
some kind of anti-crawling technology, such as CAPTCHA, making it difﬁcult to collect data using an automated
program like web crawler. Further, some forums only allow invite-only registrations. It means we cannot get access to
the forum unless we have an account in it and to get an account we need to get an invitation from a registered member
of that forum ﬁrst. We, however, managed to collect data from a popular forum name forums.hak5.org since it does not
have such restrictions.

One limitation of our work is that we construct the dataset using a simple keyword searching technique. This process
may result in biased measurements. A possible future extension of this work would be using more advanced dataset
construction purposes. Alternatively, it is possible to reﬁne and clean the relevant and non-relevant classes using the
relevance feedback provided by some human experts in the cybersecurity domain.

7 Conclusion

Our study collected and analyzed data from a popular hacker forum, forums.hak5.org, for the purpose of identifying
and classifying possible cyber threat intelligence. We used both standard and state-of-art deep-learning techniques for
feature extraction and document vectorization purposes. We then developed and utilized several machine learning and
neural network models for classiﬁcations. Our results showed that it is possible to classify security-relevant posts and
irrelevant one with high accuracy. We further evaluate the performance of these algorithms on the multiclass dataset.
Moreover, we utilized two topic modeling algorithms as an unsupervised learning approach. We were able to extract the
top words for a different number of topics on these datasets using LDA and NMF topic modeling algorithms. Further,
we applied all these approaches to a labeled dataset named nulled.io.

References

[1] Apurv Singh Gautam, Yamini Gahlot, and Pooja Kamat. Hacker forum exploit and classiﬁcation for proactive
cyber threat intelligence. In International Conference on Inventive Computation Technologies, pages 279–285.
Springer, 2019.

9

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

[2] Liang Guo, Senhao Wen, Dewei Wang, Shanbiao Wang, Qianxun Wang, and Hualin Liu. Overview of cyber
threat intelligence description. In International Conference on Applications and Techniques in Cyber Security and
Intelligence, pages 343–350. Springer, 2021.

[3] Mauro Conti, Tooska Dargahi, and Ali Dehghantanha. Cyber threat intelligence: challenges and opportunities. In

Cyber Threat Intelligence, pages 1–6. Springer, 2018.

[4] Ajay Modi, Zhibo Sun, Anupam Panwar, Tejas Khairnar, Ziming Zhao, Adam Doupé, Gail-Joon Ahn, and
Paul Black. Towards automated threat intelligence fusion. In 2016 IEEE 2nd International Conference on
Collaboration and Internet Computing (CIC), pages 408–416. IEEE, 2016.

[5] Asif Karim, Sami Azam, Bharanidharan Shanmugam, Krishnan Kannoorpatti, and Mamoun Alazab. A compre-

hensive survey for intelligent spam email detection. IEEE Access, 7:168261–168295, 2019.

[6] Asif Karim, Sami Azam, Bharanidharan Shanmugam, and Krishnan Kannoorpatti. Efﬁcient clustering of
emails into spam and ham: The foundational study of a comprehensive unsupervised framework. IEEE Access,
8:154759–154788, 2020.

[7] Char Sample, Jennifer Cowley, Tim Watson, and Carsten Maple. Re-thinking threat intelligence.

In 2016

International Conference on Cyber Conﬂict (CyCon US), pages 1–9. IEEE, 2016.

[8] Vasileios Mavroeidis and Siri Bromander. Cyber threat intelligence model: an evaluation of taxonomies, sharing
standards, and ontologies within cyber threat intelligence. In 2017 European Intelligence and Security Informatics
Conference (EISIC), pages 91–98. IEEE, 2017.

[9] Gartner Inc. Deﬁnition: Threat intelligence, May 2013. https://www.gartner.com/en/documents/2487216/deﬁnition-

threat-intelligence.

[10] Thomas J Holt, Deborah Strumsky, Olga Smirnova, and Max Kilger. Examining the social networks of malware

writers and hackers. International Journal of Cyber Criminology, 6(1), 2012.

[11] Tianyi Wang and Kam Pui Chow. Automatic tagging of cyber threat intelligence unstructured data using semantics
extraction. In 2019 IEEE International Conference on Intelligence and Security Informatics (ISI), pages 197–199.
IEEE, 2019.

[12] Brett van Niekerk, Trishana Ramluckan, and Petrus Duvenage. An analysis of selected cyber intelligence texts. In

Proceedings of the 18th European Conference on Cyber Warfare and Security, pages 554–559, 2019.

[13] Masashi Kadoguchi, Shota Hayashi, Masaki Hashimoto, and Akira Otsuka. Exploring the dark web for cyber
threat intelligence using machine leaning. In 2019 IEEE International Conference on Intelligence and Security
Informatics (ISI), pages 200–202. IEEE, 2019.

[14] Forums - hak5 forums. https://forums.hak5.org/. (Accessed on 08/15/2021).

[15] 0x00sec - the home of the hacker. https://0x00sec.org/. (Accessed on 08/15/2021).

[16] Victoria Bobicev. Text classiﬁcation: the case of multiple labels. In 2016 International Conference on Communi-

cations (COMM), pages 39–42. IEEE, 2016.

[17] Ke Li, Hui Wen, Hong Li, Hongsong Zhu, and Limin Sun. Security osif: Toward automatic discovery and
analysis of event based cyber threat intelligence. In 2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing,
Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet
of People and Smart City Innovation, pages 741–747. IEEE, 2018.

[18] Fabrizio Sebastiani. Machine learning in automated text categorization. ACM computing surveys (CSUR),

34(1):1–47, 2002.

[19] Bofang Li, Aleksandr Drozd, Yuhe Guo, Tao Liu, Satoshi Matsuoka, and Xiaoyong Du. Scaling word2vec on big

corpus. Data Science and Engineering, 4(2):157–175, 2019.

[20] Md Tazimul Hoque, Ashraful Islam, Eshtiak Ahmed, Khondaker A Mamun, and Mohammad Nurul Huda.
Analyzing performance of different machine learning approaches with doc2vec for classifying sentiment of
In 2019 International Conference on Electrical, Computer and Communication
bengali natural language.
Engineering (ECCE), pages 1–5. IEEE, 2019.

[21] Qufei Chen and Marina Sokolova. Word2vec and doc2vec in unsupervised sentiment analysis of clinical discharge

summaries. arXiv preprint arXiv:1805.00352, 2018.

[22] Metin Bilgin and ˙Izzet Fatih ¸Sentürk. Sentiment analysis on twitter data with semi-supervised doc2vec. In 2017

international conference on computer science and engineering (UBMK), pages 661–666. Ieee, 2017.

10

Generating Cyber Threat Intelligence to Discover Potential Security Threats Using Classiﬁcation
and Topic Modeling

[23] Otgonpurev Mendsaikhan, Hirokazu Hasegawa, Yukiko Yamaguchi, and Hajime Shimada. Identiﬁcation of
cybersecurity speciﬁc content using the doc2vec language model. In 2019 IEEE 43rd annual computer software
and applications conference (COMPSAC), volume 1, pages 396–401. IEEE, 2019.

[24] Jipeng Qiang, Zhenyu Qian, Yun Li, Yunhao Yuan, and Xindong Wu. Short text topic modeling techniques,
applications, and performance: a survey. IEEE Transactions on Knowledge and Data Engineering, 2020.
[25] Tian Shi, Kyeongpil Kang, Jaegul Choo, and Chandan K Reddy. Short-text topic modeling via non-negative
matrix factorization enriched with local word-context correlations. In Proceedings of the 2018 World Wide Web
Conference, pages 1105–1114, 2018.

[26] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learning
word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technologies, pages 142–150, Portland, Oregon, USA, June 2011.
Association for Computational Linguistics.

[27] Uci machine learning repository: Twenty newsgroups data set.
datasets/Twenty%20Newsgroups. (Accessed on 08/15/2021).

https://archive.ics.uci.edu/ml/

11

