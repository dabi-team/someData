On Decidability of Existence of Nonblocking Supervisors
Resilient to Smart Sensor Attacks

aSchool of Electrical & Electronic Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore 639798.

Rong Su a

2
2
0
2

r
p
A
1

]

R
C
.
s
c
[

2
v
6
2
6
2
0
.
9
0
0
2
:
v
i
X
r
a

Abstract

Cybersecurity of discrete event systems (DES) has been gaining more and more attention recently, due to its high relevance to
the so-called 4th industrial revolution that heavily relies on data communication among networked systems. One key challenge
is how to ensure system resilience to sensor and/or actuator attacks, which may tamper data integrity and service availability.
In this paper we focus on some key decidability issues related to smart sensor attacks. We ﬁrst present a suﬃcient and necessary
condition that ensures the existence of a smart sensor attack, which reveals a novel demand-supply relationship between an
attacker and a controlled plant, represented as a set of risky pairs. Each risky pair consists of a damage string desired by the
attacker and an observable sequence feasible in the supervisor such that the latter induces a sequence of control patterns,
which allows the damage string to happen. It turns out that each risky pair can induce a smart weak sensor attack. Next,
we show that, when the plant, supervisor and damage language are regular, it is possible to remove all such risky pairs from
the plant behaviour, via a genuine encoding scheme, upon which we are able to establish our key result that the existence of
a nonblocking supervisor resilient to smart sensor attacks is decidable. To the best of our knowledge, this is the ﬁrst result
of its kind in the DES literature on cyber attacks. The proposed decision process renders a speciﬁc synthesis procedure that
guarantees to compute a resilient supervisor whenever it exists, which so far has not been achieved in the literature.

Key words: discrete-event systems, smart sensor attacks, decidability of existence of resilient supervisory control

1 Introduction

Cyber-attack resilience refers to properties of service
availability and data integrity. With the continuous ad-
vancement of information and communications technol-
ogy (ICT), in particular, the recent 5G-based IoT tech-
nologies, we are enjoying unprecedented connectivity
around the world. Nevertheless, the threat of cyber at-
tacks that may potentially cause signiﬁcant damage to
human lives and properties has more frequently become
the center of attention, and has been attracting lots of re-
search from diﬀerent communities. Basically, an attacker
aims to inﬂict damage on a target system by disrupting
its control loop. This could be achieved either by inter-
cepting and changing the controller’s input signals (in
terms of sensor attacks), or by intercepting and chang-
ing the controller’s output signals (in terms of actuator
attacks), or by completely blocking the data transmis-
sion between the controller and the plant (in terms of
denial-of-service attacks). An attack can be either brute-
force, e.g., via hardware destruction or signal jamming,
or covert (or stealthy), i.e., to inﬂict damage without
being detected by relevant monitoring mechanisms.

A good survey of cyber attacks and cyber defence
with a systems-and-control perspective can be found in
[1]. Typically, linear systems are considered in existing

(cid:63) Corresponding author: Rong Su. Tel. +65 6790-6042. Fax:
+65 6793-3318. The support from Singapore Ministry of Ed-
ucation Tier 1 Academic Research Grant 2018-T1-001-245
(RG 91/18) and from Singapore National Research Foun-
dation Delta-NTU Corporate Lab Program (SMA-RP2) are
gratefully acknowledged.

Email address: rsu@ntu.edu.sg (Rong Su).

works that rely on system identiﬁcation and control tech-
niques. Within the DES community, most works rely on
the control system setup introduced in the Ramadge-
Wonham supervisory control paradigm [23], where the
plant generates observable outputs, received by the su-
pervisor via an observation channel, and each control
command speciﬁed as a set of allowed (or disallowed)
events is generated by the supervisor and fed to the plant
via a command channel. The plant nondeterministically
picks one event from a received control command and
executes it. The event execution process is assumed to
be asynchronous, i.e., up to one event execution at each
time instant, and instantaneous. Unlike attacks in time-
driven systems described in [1], attacks under consider-
ation in a DES aim to change the sequence of events in
speciﬁc system runs.

There are two diﬀerent streams of research on cyber
attacks and resilient control. The ﬁrst stream refers to a
set of black-box methods that treat attacks as undesir-
able (either intentional or unintentional) uncontrollable
and mostly unobservable disturbances to a given closed-
loop system. Existing works include, e.g., a game theo-
retical approach [29], fault-tolerance based approaches
such as [5] and [19] on sensor attacks, [2] on actuator
attacks, and [3] [6] [4] on sensor+actuator attacks, and
transducer-based modelling and synthesis approaches
such as [7] [8]. In the black-box methods, system vulner-
ability is typically modelled by concepts similar to diag-
nosability described in, e.g., [34], and system resilience
bears similarity to fault tolerant control described in,
e.g., [28] [32], that concerns whether there is a supervi-
sor that can perform satisfactorily under the worst case
attack scenarios. The second stream refers to a set of

Preprint submitted to Automatica

4 April 2022

 
 
 
 
 
 
white-box methods, aiming to develop a speciﬁc “smart”
attack model that ensures certain intuitive properties
such as covertness and guaranteed (strong or weak) dam-
age inﬂiction. Existing works include, e.g., [9] [10] [11]
[13] [12] [12] [20] on smart sensor attacks, [14] [18] and
[17] on smart actuator attacks, and [16] [21] and [15] on
smart sensor+actuator attacks. With such smart attack
models, existing research works address the impact of
a speciﬁc attack on the closed-loop behaviour, the vul-
nerability of a system to such an attack, and ﬁnally the
resilience of a supervisor to a concerned attack.

After examining those existing works on smart cy-
ber attacks, it is clear that most works focus on how to
derive a proper smart attack model. Various synthesis
algorithms have been proposed under relevant assump-
tions. Nevertheless, the existence of a supervisor that is
resilient to all possible smart cyber attacks is still open
for research. In [35] [36] the authors present synthesis
methods for resilient control against a speciﬁc sensor
attack model described by a ﬁnite-state automaton in
diﬀerent scenarios. Thus, the synthesized supervisor is
not designed to be resilient to all possible smart sensor
attacks. In case of a worst-case sensor attack scenario,
no smartness in terms of, e.g., covertness, is considered
by the authors. There are a few heuristic synthesis ap-
proaches proposed in the literature, e.g., [10] proposes
one algorithm against smart sensor attacks, [16] pro-
poses one algorithm that generates a resilient supervisor
whose state set is bounded by a known value, and [18]
presents an algorithm to synthesize a supervisor, which is
control equivalent to an original supervisor and resilient
to smart actuator attacks. But none of those existing al-
gorithms can guarantee to ﬁnd one resilient supervisor,
if it exists. That is, when those algorithms terminate and
return an empty solution, it does not necessarily mean
that there is no solution.

Before any attempt of overcoming a complexity chal-
lenge in order to derive a resilient solution, it is critical
to answer a computability question ﬁrst, that is, how to
decide whether a solution exists. To address this impor-
tant decidability issue, in this paper we focus only on
sensor attacks, but hoping that our derived result may
shed light on research of other types of attacks. We fol-
low a sensor attack model proposed in [10], which asso-
ciates each observed sequence from the plant G with an
altered observable sequence that becomes the input of
a given supervisor. After slightly improving the concept
of attackability originally introduced in [10] and the cor-
responding deﬁnition of smart sensor attacks, our ﬁrst
contribution is to identify conditions that ensure the ex-
istence of a smart sensor attack. It turns out that the
existence of a smart weak sensor attack, which is not
necessarily regular (i.e., representable by a ﬁnite-state
automaton), is solely determined by the existence of at
least one risky pair that consists of a damage string de-
sired by the attacker and an observable sequence feasi-
ble in the supervisor such that the latter induces a se-
quence of control patterns, which allows the concerned
damage string to happen. Because any strong sensor at-
tack is also a weak attack, the existence of such a risky
pair becomes the suﬃcient and necessary condition for
the existence of a smart sensor attack. In [9] and its
journal version [10], by imposing language normality to
the closed-loop behaviour, it is shown that the supremal
smart sensor attack language can be synthesized, when-
ever it exists, upon which a speciﬁc smart sensor attack
model can be derived. In [11] and its journal version

[12], the language normality is dropped, and it is shown
that a smart sensor attack model (not necessarily supre-
mal) can be synthesized via a special insertion-deletion
attack structure, whenever it exists. However, none of
these works reveals the aforementioned demand-supply
relationship reﬂected in risky pairs that capture the na-
ture of sensor attacks. Due to this insightful concept of
risky pairs, our second contribution is to show that the
existence of a nonblocking controllable and observable
supervisor that is resilient to all regular smart sensor at-
tacks is decidable. To this end, we develop a genuine en-
coding mechanism that reveals all possible sequences of
control patterns required by a regular sensor attack and
all sequences of control patterns feasible in the plant, al-
lowing us to remove the set of all risky pairs from the
plant behaviour. After that, we introduce a language-
based concept of nonblocking resilient supervisor candi-
date and its automaton-counterpart control feasible sub-
automaton that does not contain any risky pair, upon
which we are able to decide the existence of a resilient
supervisor. As our third contribution, the proposed deci-
sion process renders a concrete synthesis procedure that
guarantees to compute a nonblocking supervisor resilient
to smart sensor attacks, whenever it exists.

The remainder of the paper is organized as follows.
In Section 2 we present a motivation example. Then in
Section 3 we review the basic concepts and operations of
discrete event systems introduced in [26], followed by a
speciﬁc smart sensor attack model, where the concept of
attackability is introduced. Then we present a suﬃcient
and necessary condition to ensure a smart sensor attack
in Section 4, where the key concept of risky pairs is in-
troduced. After that, we present a suﬃcient and neces-
sary condition for the existence of a nonblocking super-
visor that is resilient to smart sensor attacks in Section
5, and show that this suﬃcient and necessary condition
is veriﬁable in Section 6, which ﬁnally establishes the
decidability result for the existence of a resilient super-
visor. Conclusions are drawn in Section 7. Long proofs
for Theorems 1-4 are shown in the Appendix.

2 A motivation example - attack of navigator

Image that Bob would like to ride his autonomous car
from his home to his oﬃce. There is a GPS navigator
installed inside his car. The navigator ﬁrst generates a
shortest path based on traﬃc conditions, then guides
the vehicle to make required turns at planned junctions.
However, Bob’s friend Peter plans to play a prank on
Bob by tricking the navigator to lead Bob’s car to an-
other location via GPS spooﬁng, shown in Figure 1. Pe-

Fig. 1. Example 0: An example of attack of navigator

ter has the city road map and also knows Bob’s home
address and oﬃce address. In addition, he has a naviga-
tor of the same model as the one installed in Bob’s car.

2

Thus, by running his own navigator over the same origin-
destination pair, Peter will know Bob’s route plan. Fig-
ure 2 depicts the system setup, where Bob’s home is at

Fig. 2. Example 0: Road network setup

“start 0” node, his oﬃce is at “Destination 8” node, and
the prank location is at “Trap 9” node. Each symbol “lij”
denotes the length of the road segment between node i
and node j. In addition, the position of each node in the
map is publicly known. By simply running the naviga-
tor of the same model, Peter knows that Bob’s car will
choose the shortest path “0 → 1 → 2 → 3 → 4 → 8”,
which leads to the following navigation commands: (1)
right turn (at node 2), followed by (2) left turn (at node
3), followed by (3) left turn (at node 4). To trick the nav-
igator to issue the same sequence of commands but at
incorrect junctions, say, right turn at node 1, followed
by left turn at node 5, and followed by left turn at node
6, Peter only needs to buy a GPS spooﬁng device avail-
able in the market that can send fake GPS position sig-
nals to Bob’s navigator. Peter can easily determine the
spoofed GPS position signal as follows. Assume that p0
denotes the position of “start 0” node, and p(t) ∈ R2
and pa(t) ∈ R2 denote the actual and spoofed GPS po-
sitions in a 2D map. The travel distance made by Bob’s
car between time t0 and time t (t ≥ t0) can be calculated
by a simple line integral shown below:

(cid:90) t

t0

p(τ )
||p(τ )||

· dp(τ ),

where p(t) is the parametric function of the path from
node “start 0” to node 1, p(t0) = p0, ||p(t)|| denotes the
magnitude of p(t) and ‘·’ is the dot product of vectors.
For each p(t), Peter uniquely determines the value of
pa(t), which is the parametric function of the path from
node “start 0” to node 2 with pa(t0) = p0, such that

(cid:82) t
t0
(cid:82) t
t0

pa(τ )
||pa(τ )|| · dpa(τ )
p(τ )
||p(τ )|| · dp(τ )

=

l01 + l12
l01

,

which ensures that, when the navigator receives the
spoofed signal, indicating that node 2 is reached, the
actual node reached is node 1. With a similar GPS po-
sition spooﬁng scheme, Peter can misguide Bob’s car to
reach node 9, instead of node 8, without being detected.
Such GPS spooﬁng is one speciﬁc example of a smart
sensor attack, whose formal deﬁnition will be given in
the next section. Intuitively, it contains the following
basic characteristics: by knowing suﬃcient information
in advance, an attacker can trick a victim to issue the
correct order of commands but at incorrect states (or
locations), which leads to an unwanted consequence.

If Bob somehow knows that Peter will use GPS spoof-
ing to play a trick on his car, he can simply choose the

3

path “0 → 1 → 7 → 8”. In this case, even Peter knows
this new path, he cannot spoof the GPS signals to trick
Bob’s car to node 9 without being detected, as the new
path generates a new sequence of navigation commands:
(1) left turn (at node 1), then (2) right turn (at node 7),
which, no matter how Peter changes GPS position sig-
nals, cannot bring Bob to node 9. Such a path plan is a
speciﬁc example of a resilient supervisor against smart
sensor attacks, whose deﬁnition will be given later in this
paper. Intuitively, a resilient supervisor will ensure that,
for any sensor attack, either it can be detected before
inﬂicting damage, or it will not lead to any damage.

One big question is, for an arbitrary network, see, e.g.,
a road map of a small region in Singapore shown in Fig-
ure 3, how to decide whether a resilient path plan (or

Fig. 3. Example 0: A more realistic road network

navigation supervisor) exists. In this paper, we will in-
vestigate this decidability problem against smart sensor
attacks. The computational eﬃciency, i.e., the complex-
ity issue, however, will not be addressed here.

3 A smart sensor attack model

In this section we ﬁrst recall basic concepts used in the
Ramadge-Wonham supervisory control paradigm [23].
Then we recall a smart sensor attack model introduced
in [10]. Most notations in this paper follow [26].

3.1 Preliminaries on supervisory control

Given a ﬁnite alphabet Σ, let Σ∗ be the free monoid
over Σ with the empty string (cid:15) being the unit element
and the string concatenation being the monoid binary
operation. We use Σ+ to denote non-empty strings in
Σ∗, i.e., Σ+ = Σ∗ − {(cid:15)}. Given two strings s, t ∈ Σ∗, we
say s is a preﬁx substring of t, written as s ≤ t, if there
exists u ∈ Σ∗ such that su = t, where su denotes the
concatenation of s and u. For any string s(cid:48) ∈ Σ∗ with
s(cid:48) ≤ s, we use s/s(cid:48) to denote the post substring u ∈ Σ∗
such that s = s(cid:48)u. We use |s| to denote the length of
s, and by convention, |(cid:15)| = 0. Any subset L ⊆ Σ∗ is
called a language. The preﬁx closure of L is deﬁned as
L = {s ∈ Σ∗|(∃t ∈ L) s ≤ t} ⊆ Σ∗. For each string
s ∈ L, let EnL(s) := {σ ∈ Σ|sσ ∈ L} be the set of events
that can extend s in L. Given two languages L, L(cid:48) ⊆ Σ∗,
:= {ss(cid:48) ∈ Σ∗|s ∈ L ∧ s(cid:48) ∈ L(cid:48)} denote the
let LL(cid:48)
concatenation of two sets. Let Σ(cid:48) ⊆ Σ. A mapping P :
Σ∗ → Σ(cid:48)∗ is called the natural projection with respect
to (Σ, Σ(cid:48)), if

(1) P ((cid:15)) = (cid:15),

(2) (∀σ ∈ Σ) P (σ) :=

(cid:40)

σ if σ ∈ Σ(cid:48),

(cid:15) otherwise,

(3) (∀sσ ∈ Σ∗) P (sσ) = P (s)P (σ).
Given a language L ⊆ Σ∗, P (L) := {P (s) ∈ Σ(cid:48)∗|s ∈ L}.
The inverse image mapping of P is

P −1 : 2Σ(cid:48)∗

→ 2Σ∗

: L (cid:55)→ P −1(L) := {s ∈ Σ∗|P (s) ∈ L}.

A given target plant is modelled as a deterministic
ﬁnite-state automaton, G = (X, Σ, ξ, x0, Xm), where X
stands for the state set, Σ for the alphabet, ξ : X × Σ →
X for the (partial) transition function, x0 for the ini-
tial state and Xm ⊆ X for the marker state set. We
follow the notation in [26], and use ξ(x, σ)! to denote
that the transition ξ(x, σ) is deﬁned. For each state
x ∈ X, let EnG(x) := {σ ∈ Σ|ξ(x, σ)!} be the set of
events enabled at x in G. The domain of ξ can be ex-
tended to X × Σ∗, where ξ(x, (cid:15)) = x for all x ∈ X, and
ξ(x, sσ) := ξ(ξ(x, s), σ). The closed behaviour of G is
deﬁned as L(G) := {s ∈ Σ∗|ξ(x0, s)!}, and the marked
behaviour of G is Lm(G) := {s ∈ L(G)|ξ(x0, s) ∈ Xm}.
G is nonblocking if Lm(G) = L(G). We will use N to
denote natural numbers, |X| (or |G|) for the size of the
state set X, and |Σ| for the size of Σ. Given two ﬁnite-
state automata Gi = (Xi, Σ, ξi, xi,0, Xi,m) (i = 1, 2),
the meet of G1 and G2, denoted as G1 ∧ G2, is a (reach-
able) ﬁnite-state automaton whose alphabet is Σ such
that L(G1 ∧ G2) = L(G1) ∩ L(G2) and Lm(G1 ∧ G2) =
Lm(G1) ∩ Lm(G2). A sub-automaton of G is an automa-
ton Gsub = (X, Σ, ξsub, x0, Xm) such that

(∀x, x(cid:48) ∈ X)(∀σ ∈ Σ) ξsub(x, σ) = x(cid:48) ⇒ ξ(x, σ) = x(cid:48),

that is, each transition of Gsub must be a transition in
G, but the opposite may not be true. When the tran-
sition map is ξ : X × Σ → 2X , where 2X denotes the
power set of X, we call G a nondeterministic ﬁnite-state
automaton. If for each x ∈ X, there exists s ∈ Σ∗ such
that ξ(x, s) ∩ Xm (cid:54)= ∅, then G is co-reachable. For the
remainder of this paper, unless explicitly mentioned, all
automata are assumed to be deterministic.

We now recall the concept of supervisors. Let Σ =
Σc ˙∪Σuc = Σo ˙∪Σuo, where Σc (Σo) and Σuc (Σuo) are
disjoint, denoting respectively the sets of controllable
(observable) and uncontrollable (unobservable) events.
For notational simplicity, let Σ(cid:15)
o := Σo ∪ {(cid:15)}. Let Γ =
{γ ⊆ Σ|Σuc ⊆ γ}, where each γ ∈ Γ is one control pat-
tern (or control command). A supervisory control map
of G under partial observation Po : Σ∗ → Σ∗
o is deﬁned
as V : Po(L(G)) → Γ. Clearly,

(∀s ∈ L(G))(∀σ ∈ Σuc) sσ ∈ L(G) ⇒ σ ∈ V (Po(s)),

namely the supervisory control map V never tries to
disable an uncontrollable transition. In addition,

(∀s, s(cid:48) ∈ L(G)) Po(s) = Po(s(cid:48)) ⇒ V (Po(s)) = V (Po(s(cid:48))),

namely any two strings in L(G) that are observably iden-
tical, their induced control patterns are equal.

Let V /G denote the closed-loop system of G under the

supervision of V , i.e.,

• (cid:15) ∈ L(V /G),
• For all s ∈ L(V /G) and σ ∈ Σ

sσ ∈ L(V /G) ⇐⇒ sσ ∈ L(G) ∧ σ ∈ V (Po(s)),

• Lm(V /G) := Lm(G) ∩ L(V /G).
The control map V is ﬁnitely representable if V
can be described by a ﬁnite-state automaton, say
S = (Z, Σ, δ, zo, Zm = Z), such that
• L(S ∧ G) = L(V /G) and Lm(S ∧ G) = Lm(V /G),
• (∀s ∈ L(S)) EnS(s) := {σ ∈ Σ|sσ ∈ L(S)} = V (s),

4

• (∀s, s(cid:48) ∈ L(S)) Po(s) = Po(s(cid:48)) ⇒ δ(z0, s) = δ(z0, s(cid:48)).
The last condition indicates that V (s) = EnS(s) =
EnS(s(cid:48)) = V (s(cid:48)) if Po(s) = Po(s(cid:48)). Such a supervisor S
can be computed by existing synthesis tools such as TCT
[30] or SuSyNA [31]. It has been shown that, as long as
a closed-loop language K ⊆ Lm(G) is controllable [23],
observable [22] and Lm(G)-closed, i.e., K = K ∩ Lm(G),
there always exists a ﬁnitely-representable supervisory
control map V such that Lm(V /G) = K and L(V /G) =
K. From now on we make the following assumption.

Assumption 1 V is nonblocking,
Lm(V /G), and ﬁnitely representable by S.
We will use V or S interchangeably, depending on the
context. They will be called a (nonblocking) supervisor.

i.e., L(V /G) =
(cid:50)

3.2 A smart sensor attack model

We assume that an attacker can observe each observ-
able event generated by the plant G, and replace the
observable event with a sequence of observable events
from Σ∗
o, including the empty string (cid:15), in order to “fool”
the given supervisor V , known to the attacker. Con-
sidering that in practice any event occurrence takes a
non-negligible amount of time, it is impossible for an at-
tacker to insert an arbitrarily long observable sequence
to replace a received observable event. Thus, we as-
sume that there exists a known number n ∈ N such
that the length of any “reasonable” observable sequence
that the attacker can insert is no more than n. Let
∆n⊆{s ∈ Σ∗
o||s| ≤ n} be the set of all n-bounded ob-
servable sequences possibly inserted by an attacker. A
sensor attack is a total map A : Po(L(G)) → ∆∗
n, where
• A((cid:15)) = (cid:15),
• (∀σ ∈ Σ0) A(σ) ∈ ∆n,
• (∀s ∈ Po(L(G)))(∀σ ∈ Σo) A(sσ) = A(s)A(σ).
The ﬁrst condition states that, before any observation
is obtained, the attack cannot generate any non-empty
output, because, otherwise, such a fake observation se-
quence may reveal the existence of an attack, if the plant
has not started yet, whose starting time is unknown to
the attacker. The second and third conditions state that
each received observation σ ∈ Σo will trigger a fake
string in ∆n. This model captures moves of insertion,
deletion and replacement introduced in, e.g., [11] [6] [12].

o and O : (Σ(cid:15)

o × ∆n)∗ → ∆∗

An attack model A is regular if there exists a ﬁnite-
state transducer A = (Y, Σ(cid:15)
o ×∆n, η, I, O, y0, Ym), where
Ym = Y , η : Y × Σ(cid:15)
o × ∆n → Y is the (partial) tran-
sition mapping such that if η(y, σ, u)! and σ = (cid:15) then
u = (cid:15), i.e., if there is no observation input, then there
should be no observation output. The functions I : (Σ(cid:15)
o×
∆n)∗ → Σ∗
n are the input
and output mappings, respectively, such that for each
µ = (a1, b1)(a2, b2) · · · (al, bl) ∈ (Σ(cid:15)
o × ∆n)∗, I(µ) =
a1a2 · · · al and O(µ) = b1b2 · · · bl. We require that, for
each µ ∈ L(A), we have A(I(µ)) = O(µ) and I(L(A)) =
Po(L(G)). Since A is a function, we know that for all
µ, µ(cid:48) ∈ L(A), if I(µ) = I(µ(cid:48)), then O(µ) = A(I(µ)) =
A(I(µ(cid:48))) = O(µ(cid:48)), that is, the same input should result
in the same output. Notice that, in [9] [10], an attack
model is directly introduced as a ﬁnite-state transducer,
which may not necessarily be representable by an attack
map A, because a ﬁnite-transducer model allows nonde-
terminism, i.e., for the same observation input, an at-
tacker may choose diﬀerent attack moves, as long as they
are allowed by the transducer model. In this sense, the

attack model concerned in this paper is a special case
of the one introduced in [9] [10], and bears more resem-
blance to the model introduced in [12], as both treat an
attack as a function. But since there exists a nondeter-
ministic attack model if and only if there exists a deter-
ministic one, the decidability results derived in this pa-
per shall be applicable to nondeterministic attack mod-
els introduced in [9] [10]. To see this fact, it is clear that
each deterministic model is a nondeterministic model.
Thus, we only need to show that from each nondeter-
ministic model we can derive at least one deterministic
model. We will use a simple example to illustrate the
construction procedure. Assume that the nondetermin-
istic attack model adopted from [10] is shown in Fig-
ure 4, which is a transducer. We ﬁrst start from damage
states (i.e., marker states), and perform co-reachability
search to ﬁnd all states in the nondeterministic model
that satisfy the following two conditions: (1) each state
is reachable from the initial state, (2) at each state, each
observable event is associated with only one transition
(denoting an attack move). After that, we perform reach-
ability search upon those states derived from the ﬁrst
step and add new necessary states in so that the follow-
ing condition holds: at each state, each observable event
is associated with only one transition (denoting an at-
tack move) if and only if it is associated with at least one
transition in the original nondeterministic model. This
construction will result in a deterministic smart sensor
attack model, shown in Figure 4. In this example, we

Fig. 4. Transforming a nondeterministic attack to a deter-
ministic attack

can see that there can be several deterministic attack
models derivable from the nondeterministic model.

Assumption 2 Only regular attacks are considered.

The combination of the attack A and the supervisor
V forms a new supervisor V ◦ A : Po(L(G)) → Γ, where

(∀s ∈ Po(L(G))) V ◦ A(s) := V (A(s)).

We call V ◦ A an attacked supervisor under A. This deﬁ-
nition consumes the standard style of one command per
each received (fake) observation used in, e.g., [6] [35], as
a special case, when n is set to 1. The closed and marked
behaviours, L(V ◦A/G) and Lm(V ◦A/G), of the closed-
loop system V ◦ A/G are deﬁned accordingly. We call
L(V ◦ A/G) the attacked language of V /G under A. The
closed-loop system is depicted in Figure 5.

Deﬁnition 1 Given a plant G and a supervisor V real-

5

Fig. 5. The block diagram of a plant under attack

ized by S, let Ldam ⊆ L(G) − L(V /G) be a damage lan-
guage. The closed-loop system V /G is attackable with re-
spect to Ldam, if there exists an attack A, called a smart
sensor attack of V /G, such that the following hold:

(1) Covertness: Event changes made by A are covert

to the supervisor V , i.e.,

A(Po(L(V ◦ A/G))) ⊆ L(S).

(1)

(2) Damage inﬂiction: A causes “damage” to G, i.e.,
• strong attack: Any string may lead to damage:

L(V ◦ A/G) = L(V ◦ A/G) ∩ Ldam;

(2)

• weak attack: Some string may lead to damage:

L(V ◦ A/G) ∩ Ldam (cid:54)= ∅.

(3)

If V /G is not attackable with respect to Ldam, then V is
(cid:50)
resilient to smart attacks with respect to Ldam.

The concept of attackability introduced in Def. 1 sim-
pliﬁes the concept of attackability introduced in [10] by,
ﬁrstly, dropping the requirement of control existence, as
V ◦A automatically allows all uncontrollable transitions,
thus, ensuring controllability, and secondly, dropping the
normality requirement, as we directly model an attack
as a function over the plant’s observable behaviours, in-
stead of a language used in [10] (which is equivalent to
a nondeterministic attack), making the closed-loop lan-
guage L(V ◦ A/G) observable automatically.

Remark: In [10], a special subset of observable events
called protected events is introduced, which is denoted by
Σo,p ⊆ Σo, representing observable events in the plant
that cannot be changed by any sensor attack. This fea-
ture makes the modeling framework more general. How-
ever, it diminishes the chance of having a smart sensor
attack, due to the challenge of ensuring the covertness
property, when the system trajectory s ∈ L(V ◦ A/G)
is outside the legal language L(V /G) and there are a
few protected system output events that will inevitably
reveal the attack. Due to this complication, we lack a
simple suﬃcient and necessary condition to characterize
the existence of a smart sensor attack, making the sub-
sequent study of the existence of a supervisor resilient to
such smart sensor attacks infeasible. To overcome this
challenge, we could restrict the damage language Ldam
to be L(G) − L(V /G), i.e., any string outside L(V /G) is
a damage string. This will allow us to relax the covert-
ness property to be

A(Po(L(V ◦ A/G) ∩ L(V /G))) ⊆ L(S),

that is, an attacker does not need to make any event
change, after the system trajectory is outside L(V /G), as
damage has been inﬂicted. Then all results presented in

this paper will still be valid. So a user of this theory has
two options for the system setup, that is, either Σo,p = ∅
and Ldam ⊆ L(G) − L(V /G), as adopted in Def. 1 of this
paper, or Σo,p (cid:54)= ∅ and Ldam = L(G) − L(V /G).

Let F(G, V, Ldam) be the collection of all attacked
languages caused by smart sensor attacks. Clearly,
(F(G, V, Ldam), ⊆) is a partially ordered set. When
L(V ◦ A/G) is required to be normal [22], i.e., only ob-
servable events may be disabled, and the attack model A
is nondeterministic, i.e., for the same observable input,
A may have more than one output choice, it has been
shown in [10] that (F(G, V, Ldam), ⊆) over all smart
strong attacks becomes an upper semilattice, and the
supremal strong attacked language L(V ◦ A∗/G) exists
such that for any smart strong sensor attack A, we have
L(V ◦ A/G) ⊆ L(V ◦ A∗/G). In this case, the supremal
strong attacked language is computable, as shown in
[10]. With a similar spirit, the supremal weak attacked
language exists and is also computable, as brieﬂy men-
tioned in the conclusion of [10]. When only deterministic
attack models are adopted, it turns out that the supre-
mal deterministic attack model may not always exist.
However, by computing the supremal nondeterministic
smart weak attacked language ﬁrst, which induces a
ﬁnite-state transducer, as shown in [10], we can show
that a deterministic attack model derivable from the
ﬁnite-state transducer by applying the transformation
procedure shown in Figure 4 results in a maximal at-
tacked language in F(G, V, Ldam). Detailed arguments
are omitted here, due to limited space and the focus
of this paper that is not about supremality or maxi-
mality of attacked languages. In the example depicted
in Figure 4, the illustrated deterministic smart attack
model results in a maximal attacked language. However,
there is no supremal attacked language induced by a
deterministic smart weak attack.

4 A suﬃcient and necessary condition for the

existence of a smart sensor attack

Let us start with a small example, which is depicted in
Figure 6. Assume that the attacker A wants to achieve

Fig. 6. Example 1: A smart sensor attack

a string abc ∈ Ldam, which leads to a damage state. As-
sume that event a is contained in control pattern γ1,
event b is in control pattern γ2, and event c in control
pattern γ3. After event a ﬁres, the attacker wants the
control pattern γ2 to be issued. Since event a does not
lead to control pattern γ2, but event d does, the attacker
A will replace event a with d to trick the supervisor S
to generate γ2. Assume that b is ﬁred afterwards. The
attacker wants γ3 to be issued. Since event b does not
lead to γ3, instead, event e does, the attacker A replaces
event b with event e to trick the supervisor S to issue
γ3, if event c happens afterwards, the attacker achieves
his/her goal without being detected by the supervisor.
The attacker could continue this trick as long as it is pos-
sible. So essentially, by faking some observable string,

6

the attacker hopes to trick the supervisor to issue a se-
quence of control patterns, which contain some damag-
ing strings, without being detected by the supervisor.
We now generalize this idea. For notational simplicity,
given a string t = ν1 · · · νn ∈ Σ∗ with n ∈ N, for each
i ∈ {1, · · · , n}, we use ti to denote the preﬁx substring
ν1 · · · νi. By convention, t0 := (cid:15).
Theorem 1 Given a plant G, a supervisor V and a dam-
age language Ldam ⊆ L(G) − L(V /G), there is a smart
weak sensor attack A, if and only if the following condi-
tion holds: there exists s = u1σ1 · · · urσrur+1 ∈ Ldam,
with r ∈ N, u1, · · · , ur+1 ∈ Σ∗
uo and σ1, · · · , σr ∈ Σo,
and t = ν1 · · · νr ∈ Po(L(V /G)) with ν1, · · · , νr ∈ ∆n
such that (1) u1, σ1 ∈ V (t0)∗; (2) for each i ∈ {2, · · · , r},
(cid:50)
ui, σi ∈ V (ti−1)∗; (3) ur+1 ∈ V (t)∗.

As an illustration, in Example 1 depicted in Figure 6,
we can see that r = 3, σ1 = a, σ2 = b, σ3 = c, ν1 = d,
ν2 = e, u1 = u2 = u3 = u4 = (cid:15).

The strings s and t in Theorem 1 form a risky pair
(s, t) ∈ Ldam × ∆∗
n such that, by mapping Po(s) to t, the
attacker can rely on the existing supervisor V to inﬂict
a weak attack on the plant G, without being detected by
the supervisor. Since the existence of a risky pair is suf-
ﬁcient and necessary for the existence of a smart weak
sensor attack, we will use this fact to determine the exis-
tence of a resilient supervisor. But before that, we would
like to state the following result about the decidability
of the existence of a regular smart weak sensor attack.

Theorem 2 Given a plant G, a regular supervisor V ,
and a regular damage language Ldam ⊆ L(G)−L(V /G),
the existence of a regular smart weak sensor attack is
(cid:50)
decidable.

By the proof of Theorem 2 shown in the Ap-
pendix, the computational complexity of deciding the
existence of a regular smart weak sensor attack is
O(|Σ|2|∆n|2|G||S||D|), where S is an automaton realiza-
tion of V and D is an automaton recognizing Ldam.

In [12] the authors have shown that a deterministic
attack function that ensures the covertness and weak
damage inﬂiction can always be synthesized, when it ex-
ists. But since the attack model adopted in this paper is
diﬀerent from the one used in [12], e.g., the latter does
not requires A((cid:15)) = (cid:15) (thus, non-existence of an attack
model in our deﬁnition does not necessarily means the
non-existence of an attack model in [12]), and encodes
attack moves diﬀerently, Theorem 2 has its own value by
providing another way of synthesizing a regular deter-
ministic smart weak sensor attack, whenever it exists.

5 Supervisor resilient to smart sensor attacks

In this section we explore whether there exists a suf-
ﬁcient and necessary condition to ensure the existence
of a supervisor that is resilient to all regular smart sen-
sor attacks, i.e., the closed-loop system is not attack-
able by any regular smart sensor attack. In Section 3
we have shown that there is a suﬃcient and necessary
condition for the existence of a smart weak sensor at-
tack shown in Theorem 1. Since each strong attack is
also a weak attack, if we can eﬀectively eliminate those
risky pairs described in Theorem 1, we shall be able to
prevent the existence of any smart sensor attack. Since,
given a plant G and a requirement Spec, we can always
synthesize a controllable and observable sublanguage of
Lm(G) ∩ Lm(Spec), without loss of generality, we as-

sume that the plant G satisﬁes all given requirements.
Thus, we will only focus on the following problem.

Problem 1 Given a plant G and a damage language
Ldam ⊆ L(G), synthesize a supervisor V such that V /G
is not attackable by any regular smart sensor attack with
(cid:50)
respect to Ldam.

To solve this problem, we ﬁrst intend to ﬁnd a proper
way of encoding all risky pairs. Given a string s ∈ Σ∗,
we use s↑ to denote the last event of s. If s = (cid:15), by con-
vention, s↑ := (cid:15). In addition, we use so to denote the
longest preﬁx substring of s, whose last event is observ-
able, i.e., so ∈ {s} ∩ (Σ∗
(Po({s})). Thus, if
s ∈ Σ∗

uo, then we can derive that so = (cid:15).

uoΣo)∗ ∩ P −1

o

• For each µ ∈ (Σ × Γ)∗ and (σ, γ) ∈ Σ × Γ, we have

(cid:40)

ψ(µ(σ, γ)) :=

ψ(µ){(σ, γ)}

if σ ∈ Σuo,

ψ(µ)(∆n × {γ}) otherwise.

We extend the domain of ψ to languages in the usual
way, i.e., for all L ⊆ (Σ × Γ)∗, ψ(L) := ∪s∈Lψ(s).

To explicitly describe how a smart attack may utilize
possible sequences of control patterns, we introduce one
more mapping

ν : ((Σ ∪ ∆n) × Γ)∗ → 2(Σ(cid:15)

o×Γ)∗

,

Let ι : Σ∗ → 2(Σ×Γ)∗

be a partial mapping, where

where

• ι((cid:15)) := {(cid:15)};
• (∀s ∈ Σ∗)(∀σ ∈ Σ) ι(sσ) := ι(s){(σ, γ)|σ ∈ γ}.

In Example 1, we have (a, γ1)(b, γ2)(c, γ3) ∈ ι(abc).
What the map ι does is to map each string s ∈ Σ∗ to
a set of sequences of control patterns such that each
derived control pattern sequence, say γ1 · · · γr ∈ Γ∗,
contains the string s in the sense that s ∈ γ1 · · · γr ⊆ Σ∗.
By applying the map ι to the damage language Ldam,
the result ι(Ldam) := ∪s∈Ldam ι(s) presents all possible
sequences of control patterns, each of which contains at
least one string in Ldam - in other words, each string in
ι(Ldam) may potentially result in damage.

To further illustrate how this function works, we intro-
duce another simple example depicted in Figure 7, where

• ν((cid:15)) := {(cid:15)};
• For all (σ, γ) ∈ (Σ ∪ {(cid:15)}) × Γ,

ν(σ, γ) =






(σ, γ) if σ ∈ Σo ∧ σ ∈ γ;

((cid:15), γ) if σ ∈ Σuo ∧ σ ∈ γ;
∅

otherwise.

• For all s = σ1 · · · σr ∈ ∆n, |Po(s)| = r ≥ 2, and γ ∈ Γ,
ν(s, γ) := {(σ1, γ1) · · · (σr, γ)|σr ∈ γ∧
(∀i ∈ {1, · · · , r − 1})σi ∈ γr−1 ∈ Γ}.
• (∀µ(s, γ) ∈ ((Σ ∪ ∆n) × Γ)+) ν(µ(s, γ)) = ν(µ)ν(s, γ).
As an illustration, we apply the map ψ to the dam-
age language ι(Ldam) in Figure 8, where n = 1. To sim-
plify illustration, we assume that an attacker can, but
prefers not to, change events c and d. The outcome is
depicted in Figure 9. Notice that when event a is inter-
cepted by the attacker, it can be replaced by any other
strings in ∆n. Because n = 1, we have ∆1 = Σo ∪ {(cid:15)} =
{a, b, c, d, (cid:15)} - in this case, the outcome of ν(ψ(ι(L(G))))
equals ψ(ι(L(G))).

Fig. 7. Example 2: A small plant G

Σ = {a, b, c, d, v}, Σc = {a, b, d} and Σo = {a, b, c, d}.
To simplify our illustration, in this example we assume
that ∆n = Σ(cid:15)
o, i.e., n = 1. The damage language Ldam =
{ad}, which is shown by a dashed line leading to state
3. Figure 8 depicts the outcome of ι(Ldam).

Fig. 9. Example 2: The model of ψ(ι(L(G)))

Next, we determine all control pattern sequences in
the plant G that may be used by a smart attack. Let
ΥG : L(G) × Σ∗ × Γ → {0, 1} be a Boolean map, where
for each (s, t, γ) ∈ L(G) × Σ∗ × Γ,

ΥG(s, t, γ) = 1 ⇐⇒ st ∈ L(G) ∧ t ∈ γ∗.

Fig. 8. Example 2: The model of ι(Ldam)

For each γ ∈ Γ, let

A smart sensor attack replaces each intercepted ob-
servable event σ ∈ Σo with a string in ∆n, unless σ is
silent, i.e., σ = (cid:15). To capture the impact of such changes
on the control pattern sequences, we introduce a map-
ping ψ : (Σ × Γ)∗ → 2((Σ∪∆n)×Γ)∗
• ψ((cid:15)) := {(cid:15)};

, where

(cid:40)

B(γ) :=

{((cid:15), γ)}∗ if γ ∩ Σuo (cid:54)= ∅,
{(cid:15)}

otherwise.

Let p : (Σ(cid:15)

o × Γ)∗ → Γ∗ be a projection map, where

• p((cid:15)) := (cid:15);
• (∀s(σ, γ) ∈ (Σ(cid:15)

o × Γ)+) p(s(σ, γ)) := p(s)γ.

7

And let g : (Σ(cid:15)

o × Γ)∗ → Σ∗

o be a projection map, where

o × Γ)+) g(µ(σ, γ)) := g(µ)Po(σ).

• g((cid:15)) := (cid:15);
• (∀µ(σ, γ) ∈ (Σ(cid:15)
Let ζ : L(G) → 2(Σ(cid:15)
• ζ((cid:15)) := (∪γ∈Γ:γ∩Σuo(cid:54)=∅{((cid:15), γ)}+) (cid:83)(∪γ∈Γ:γ⊆Σo{((cid:15), γ)});
• For all s ∈ (Σ∗

be a total mapping, where

uoΣo)∗ and t ∈ Σ∗

o with st ∈ L(G),

uoΣ(cid:15)

o×Γ)∗

(cid:40)

ζ(st) :=

ζ(s) if Po(t) = (cid:15),

M otherwise,

where

M :=

(cid:91)

(cid:91)

{w(Po(t), γ(cid:48))}B(γ(cid:48)).

w∈ζ(s):ΥG(s,t,p(w)↑)=1

γ(cid:48)∈Γ

We call ζ(L(G)) the augmented closed behaviour of G.
The augmented marked behaviour of G induced by ζ is
deﬁned as ζ(L(G)) ∩ g−1(Po(Lm(G))).

This deﬁnition of ζ indicates that, except for control
patterns generated initially, i.e., when s = (cid:15), each control
pattern will be changed only after an observable event
is received, i.e., when st ∈ Σ∗Σo ∩ L(G). This matches
the deﬁnition of a supervisor V that changes its output
only when a new observation is received. In addition, if
a control pattern γ contains unobservable events, it will
be contained in a self-loop of the augmented event ((cid:15), γ),
i.e., {((cid:15), γ)}∗, denoting that the control pattern γ may
be used more than once by the plant, as long as no new
observable event has been received. Again, this matches
the Ramadge-Wonham supervisory control paradigm,
where execution of any unobservable transition allowed
by the current control pattern will not change the cur-
rent control pattern - recall that in a ﬁnite-state automa-
ton realization of V , unobservable events are self-looped
at relevant states.

As an illustration, we apply ζ to the plant model L(G)
depicted in Figure 7. Part of the outcome is depicted in
Figure 10. Because the total state set is X ×Σ(cid:15)
o×Γ, which

Fig. 10. Example 2: The model of ζ(L(G))

is too big to be shown entirely in the picture, we only
include states that have at least one future extension,
unless they are marker states (i.e., states (3, d, {v, c}),
(5, c, {v, c}) and (7, d, {v, c})), except for one blocking
state (2, b, {v, c}), which is left there for an illustration
purpose that will be explained shortly. The marker states
in Figure 10 denote the augmented marked behaviour of
G in Example 2.

8

Till now, we have provide suﬃcient means to describe
all risky pairs, which are captured by ν(ψ(ι(Ldam)))
at the attacker’s demand side, and ζ(L(G)) at the
plant’s supply side. To avoid such risky pairs, we only
o × Γ)∗ from
need to remove p−1(p(ν(ψ(ι(Ldam))))(Σ(cid:15)
ζ(L(G)). The reason why we concatenate (Σ(cid:15)
o × Γ)∗ at
the end of p−1(p(ν(ψ(ι(Ldam)))) is to denote all possi-
ble augmented strings that may contain some strings in
p−1(p(ν(ψ(ι(Ldam)))) as preﬁx substrings. Thus, all safe
supervisory control pattern sequences shall be contained
in ˆH := ζ(L(G)) − p−1(p(ν(ψ(ι(Ldam))))(Σ(cid:15)
o × Γ)∗ in
order to prevent any sequence of control patterns from
being used by an attacker.

Figure 11 depicts the outcome of subtracting risky

Fig. 11. Example 2: The model of ˆH

control pattern sequences p−1(p(ν(ψ(ι(Ldam))))(Σ(cid:15)
o ×
Γ)∗ from (part of) ζ(L(G)) shown in Figure 10. It is clear
that there cannot be any sequence of control patterns
γ1γ2 · · · γl such that a ∈ γ1 and d ∈ γ2.

To extract a proper supervisor from ˆH, we need a few
more technical preparations. Let H := ˆH ⊆ (Σ(cid:15)
o × Γ)∗
be the preﬁx closure of ˆH. All tuples (σ, γ) ∈ Σo × Γ are
considered to be controllable, except for tuples {(cid:15)} × Γ.
We introduce the concept of conditional controllability
inspired by the standard notion of controllability in [27].

Deﬁnition 2 A sublanguage L ⊆ H is conditionally
controllable with respect to ζ(L(G)) and {(cid:15)} × Γ, if

(L − {(cid:15)})({(cid:15)} × Γ) ∩ ζ(L(G)) ⊆ L.

(cid:50)

In other words, as long as ((cid:15), γ) is not deﬁned at the be-
ginning, i.e., ((cid:15), γ) /∈ ζ(L(G)), it should not be disabled,
if it follows a non-empty string s ∈ L. We can brieﬂy
explain the motivation as follows. If an event ((cid:15), γ) does
not appear at the beginning, by the deﬁnition of ζ(L(G))
and subsequently that of H, it must be incurred by an-
other string s(σ, γ) such that γ ∩ Σuo (cid:54)= ∅ – clearly, we
can stop (σ, γ), if σ (cid:54)= (cid:15), by not choosing γ; but after
γ is chosen and some unobservable event allowed by γ
occurs, the same control pattern γ will continuously re-
main active, i.e., ((cid:15), γ) will still be allowed, until a new
observation is generated, leading to a new control pat-
tern. But the situation is diﬀerent initially, as we can di-
rectly disable the control pattern γ, thus stop the event
((cid:15), γ). It is clear that conditional controllability is also
closed under set union.

Let C(ζ(L(G)), H) be the set of all preﬁx-closed
sublanguages of H, which is conditionally controllable
with respect to ζ(L(G)) and {(cid:15)} × Γ. It is clear that
the supremal conditionally controllable sublanguage

in C(ζ(L(G)), H) under the partial order of set in-
clusion exists. We denote this unique sublanguage as
S∗ := supC(ζ(L(G)), H). Notice that S∗ contains no
sequence of control patterns that may be used by a
smart attack to inﬂict damage. Later, we will show that
S∗ contains all feasible supervisors that are resilient to
smart sensor attacks, as long as such a supervisor ex-
ists. We now introduce techniques to extract a feasible
resilient supervisor out of S∗, if it exists. To this end,
we introduce a few more concepts.

Let f : S∗ → 2X be a mapping, where

• For all ((cid:15), γ) ∈ S∗,

f ((cid:15), γ) := {x ∈ X|(∃t ∈ γ∗ ∩ Σ∗

uoΣo)ξ(x0, t) = x};

• For all s ∈ S∗ and (σ, γ) ∈ Σ(cid:15)

o × Γ with s(σ, γ) ∈ S∗,

if σ = (cid:15), then f (s(σ, γ)) := f (s); otherwise,

{x ∈ X|(∃t ∈ γ∗ ∩ Σ∗

f (s(σ, γ)) :=
uoΣo)(∃x(cid:48) ∈ f (s))ξ(x(cid:48), σt) = x}.
The map f essentially associates each string s ∈ S∗
with the corresponding state estimate of G. Let
h : S∗ → 2X be the marking coreachability map
associated with the plant G, where for each s =
((cid:15), γ0)(σ1, γ1) · · · (σn, γn) ∈ S∗ with n ∈ N,
• f (s) ∩ Xm = ∅ ⇒ h(s) = ∅;
• If f (s) ∩ Xm (cid:54)= ∅, then let (cid:37) : 2X × Γ → 2X , where

for all U ∈ 2X and γ ∈ Γ,

(cid:37)(U, γ) :=
uoΣo)(∃x(cid:48) ∈ U )ξ(x, t) = x(cid:48)},

{x ∈ X|(∃t ∈ γ∗ ∩ Σ∗

and h(s) := ∪n
i=0Ui, where
· Un := (cid:37)(f (s) ∩ Xm, γn);
· (∀i ∈ {0, · · · , n − 1}) Ui := (cid:37)(Ui+1, γi).

Deﬁnition 3 A resilient supervisor candidate L ⊆ S∗
is nonblocking with respect to G, if for all s ∈ L,

f (s) ⊆

(cid:91)

h(t).

t∈L:s≤t

(cid:50)

(cid:50)

Deﬁnition 4 A sublanguage L ∈ C(ζ(L(G)), H) is a
nonblocking resilient supervisor candidate if for all s ∈ L,
(1) (∀t ∈ g−1(g(s)) ∩ L)p(t)↑ = p(s)↑;
(2) g(EnL(s)) = Po(p(s↑)) ∩ g(Enζ(L(G))(s));
(3) L is nonblocking with respect to G.
Notice that t ∈ g−1(g(s))∩L means that g(s) = g(t), and
p(t)↑ = p(s)↑ means that the incurred control patterns
by g(t) and g(s) are the same. Thus, the ﬁrst condition
in Def. 4 essentially states that, all observably identical
strings must lead to the same control pattern – conse-
quently, any silent transition (cid:15) cannot generate any new
control pattern other than the current one. The second
condition states that an “observable” event σ ∈ Σ(cid:15)
o is al-
lowed by L, i.e., σ ∈ g(EnL(s)), if and only if it is allowed
by the control pattern incurred by s, i.e., σ ∈ Po(p(s↑)),
and also allowed by L(G), i.e., σ ∈ g(Enζ(L(G))(s))).
The last condition refers to nonblockingness of L.

As an illustration, we calculate supC(ζ(L(G)), H) and
remove all states that violate either one of the condi-
tions of Def. 4. Figure 12 depicts the outcome. We can
see that the state (2, b, {v, c}) in Figure 11 needs to
be removed because it is blocking, violating the third
condition in Def. 4. In addition, states (0, (cid:15), {a, b, v, c})
and (0, (cid:15), {a, b, d, v, c}) and (0, (cid:15), {a, d, v, c}) in Figure

9

Fig. 12. Example 2: The set of all nonblocking resilient su-
pervisor candidates of S∗

11 also need to be removed because they clearly vio-
late the second condition of Def. 4, as the event b is
deﬁned in control patterns {a, b, v, c} and {a, b, d, v, c}
of states (0, (cid:15), {a, b, v, c}) and (0, (cid:15), {a, b, d, v, c}), respec-
tively, but no outgoing transitions containing b are al-
lowed at these two states in H, even though these tran-
sitions are allowed in ζ(L(G)), and event d is deﬁned in
the control pattern {a, d, v, c} of state (0, (cid:15), {a, d, v, c}),
but no outgoing transition containing d is allowed in H,
even though such a transition is allowed in ζ(L(G)).

We now state the following theorem, which is the ﬁrst
step towards solving the decidability problem of the ex-
istence of a supervisor resilient to smart sensor attacks.

Theorem 3 Given a plant G and a damage language
Ldam ⊆ L(G), let S∗ be deﬁned above. Then there ex-
ists a supervisor V : Po(L(G)) → Γ such that V /G is
not attackable w.r.t. Ldam, iﬀ there exists a nonblocking
(cid:50)
resilient supervisor candidate L ⊆ S∗.

As an illustration, we can check that any marked se-
quence in Figure 12 is a nonblocking resilient super-
visor candidate. For example, take a look at the sub-
language L := {((cid:15), {a, v, c})}+{(a, {v, c})}{((cid:15), {v, c})}∗
{(c, {v, c})}{((cid:15), {v, c})}∗. We can check that L is condi-
tional controllable with respect to ζ(L(G)) and {(cid:15)} × Γ.
Thus, L ∈ C(ζ(L(G)), H). In addition, L is nonblock-
ing and satisﬁes conditions in Def. 4. Thus, L is a non-
blocking resilient supervisor candidate of S∗. By Theo-
rem 3, we know that there must exist a resilient super-
visor V that does not allow any smart sensor attack.
Based on the construction shown in the proof of Theo-
rem 3, the corresponding supervisor is V ((cid:15)) := {a, v, c},
V (a) := {v, c} and V (ac) := {v, c}. For any other ob-
servable string s ∈ Po(L(G)), we simply set V (s) := Σuc.
Theorem 3 indicates that, to decide whether there ex-
ists a nonblocking supervisor that disallows smart sen-
sor attacks, we only need to decide whether there ex-
ists a nonblocking resilient supervisor candidate L ⊆ S∗.
Next, we shall discuss how to determine the existence of
such a language L.

6 Decidability of the existence of a supervisor

resilient to smart sensor attacks

In the previous section we present a suﬃcient and nec-
essary condition for the existence of a resilient supervi-
sor. However, the computability issue is not addressed.
In this section, we discuss how to compute all those sets
and languages introduced in the previous section, and
eventually show how to decide the existence of a resilient
supervisor, i.e., to decide when that suﬃcient and neces-
sary condition mentioned in Theorem 3 holds for a given
plant G and a regular damage language Ldam.

We ﬁrst discuss how to compute ι(Ldam). As shown

in Section 4, let D = (W, Σ, κ, w0, Wm) recognize Ldam,
i.e., Lm(D) = Ldam. We construct another ﬁnite-state
automaton Dι := (W, Σ × Γ, κι, w0, Wm), where κι :
W × Σ × Γ → W is the (partial) transition map such
that for each (w, σ, γ) ∈ W × Σ × Γ and w(cid:48) ∈ W ,

κι(w, σ, γ) = w(cid:48) ⇐⇒ σ ∈ γ ∧ κ(w, σ) = w(cid:48).

Proposition 1 ι(Ldam) = Lm(Dι).
Proof: It is clear from the construction of Dι.

(cid:50)

(cid:4)

Next, we describe how to calculate ψ(ι(Ldam)). Let
Dψ = (W, (Σ ∪ ∆n) × Γ, κψ, w0, Wm), where κψ : W ×
(Σ ∪ ∆n) × Γ → W is the (partial) transition map such
that for each (w, u, γ) ∈ W × (Σ ∪ ∆n) × Γ and w(cid:48) ∈ W ,
we have κψ(w, u, γ) = w(cid:48) if one of the following holds:
• u ∈ Σuo ∧ κι(w, u, γ) = w(cid:48);
• u ∈ ∆n ∧ (∃σ ∈ Σo) κι(w, σ, γ) = w(cid:48).
Proposition 2 ψ(ι(Ldam)) = Lm(Dψ).
Proof: By the construction of Dψ and the deﬁnition of
(cid:4),
ψ, the proposition follows.

(cid:50)

Next, we describe how to calculate ν(ψ(ι(L(G)))) by
modifying Dψ. For each transition κψ(w, u, γ) = w(cid:48), if
u ∈ ∆n and |u| ≥ 2, we make the following changes
to Dψ. Assume that u = σ1 · · · σr with r ∈ N and
σi ∈ Σo (i ∈ {1, · · · , r}). We create r − 1 new states
˜w1, · · · , ˜wr−1 such that for each sequence γ1 · · · γr−1 ∈
Γ∗ with σi ∈ γi (i = 1, · · · , r), we deﬁne κψ(w, σ1, γ1) =
˜w1, κψ( ˜wi, σi+1, γi+1) = ˜wi+1 (i = 1, · · · , r − 2) and
κψ( ˜wr−1, σr, γ) = w(cid:48). Add newly created states to the
state set W of Dψ and new transitions to κψ. Continue
this process until all transitions are processed. Let the
ﬁnal ﬁnite-state automaton be Dν.
Proposition 3 ν(ψ(ι(Ldam))) = Lm(Dν).
Proof: By the construction of Dν and the deﬁnition of
(cid:4)
ν, the proposition follows.

(cid:50)

Next, we will show how to compute ζ(L(G)). We con-
struct a nondeterministic ﬁnite-state automaton Gζ :=
(X × Σ(cid:15)

o × Γ, ξζ, (x0, (cid:15), Σ), Xm × Σ(cid:15)

o × Γ, Σ(cid:15)

o), where

ξζ : X × Σ(cid:15)

o × Γ × Σ(cid:15)

o × Γ → 2X×Σ(cid:15)

o×Γ

is the nondeterministic transition map such that

• For all γ ∈ Γ, ξζ(x0, (cid:15), Σ, (cid:15), γ) := {(x0, (cid:15), γ)};
• For all (x, σ, γ) ∈ X × Σ(cid:15)

o × Γ − {(x0, (cid:15), Σ)}, and

(σ(cid:48), γ(cid:48)) ∈ Σ(cid:15)
o × Γ, we have that
· if σ(cid:48) = (cid:15) and γ(cid:48) = γ and γ ∩ Σuo (cid:54)= ∅, then

ξζ(x, σ, γ, (cid:15), γ) = {(x, σ, γ)};

· if σ(cid:48) ∈ Σo, then

ξζ(x, σ, γ, σ(cid:48), γ(cid:48)) := {(x(cid:48), σ(cid:48), γ(cid:48)) ∈ X × Σ(cid:15)
(∃u ∈ P −1

o × Γ|
uoΣo)∗)ξ(x, u) = x(cid:48)}.

(σ(cid:48)) ∩ γ∗ ∩ (Σ∗

o

To illustrate the construction procedure for Gζ,
a small example is depicted in Figure 13, where
Σ = {a, b, c, v}, Σc = {a} and Σo = {a, b, c}. Thus,
there are only two control patterns γ1 = {a, b, v, c} and
γ2 = Σuc = {b, v, c}. The outcome of Gζ is shown in Fig-
ure 13, where nondeterministic transitions occur at both
(augmented) states (1, a, {b, v, c}) and (1, a, {a, b, v, c}).
(cid:50)

Proposition 4 ζ(L(G)) = L(Gζ).
Proof: By the deﬁnition of ζ and the construction of Gζ,
it is clear that ζ(L(G)) ⊆ L(Gζ). So we only need to show

10

Fig. 13. Example 3: A plant G and the corresponding Gζ

that L(Gζ) ⊆ ζ(L(G)). We use induction. At the initial
state (x0, (cid:15), Σ), for each γ ∈ Γ, if γ ∩ Σuo (cid:54)= ∅, we have
κζ(x0, (cid:15), Σ, (cid:15), γ) = {(x0, (cid:15), γ)} and κζ(x0, (cid:15), γ, (cid:15), γ) =
{(x0, (cid:15), γ)}), namely {((cid:15), γ)}+ ⊆ L(Gζ). By the deﬁni-
tion of ζ(L(G)), we know that {((cid:15), γ)}+ ⊆ ζ(L(G)). If γ∩
Σuo = ∅, then we have κζ(x0, (cid:15), Σ, (cid:15), γ) = {(x0, (cid:15), γ)},
namely ((cid:15), γ) ∈ L(Gζ). By the deﬁnition of ζ(L(G)), we
know that ((cid:15), γ) ∈ ζ(L(G)). Thus, the base case holds.
Assume that s ∈ ζ(L(G)) ∩ L(Gζ), and s(σ, γ) ∈ L(Gζ),
we need to show that s(σ, γ) ∈ ζ(L(G)). If σ = (cid:15),
then since s(σ, γ) ∈ L(Gζ), we know that γ = p(s)↑
and γ ∩ Σuo (cid:54)= ∅. Since s ∈ ζ(L(G)) and p(s)↑ = γ
and γ ∩ Σuo (cid:54)= ∅, we know that s((cid:15), γ) ∈ ζ(L(G)). If
σ ∈ Σo, then clearly there exists tu ∈ L(G) such that
uoΣo)∗. Clearly,
g(s) = Po(t) and u ∈ P −1
s ∈ ζ(t) and Po(u) = σ (cid:54)= (cid:15). Thus, by the deﬁnition of
ζ(L(G)), we know that s(Po(u), γ) = s(σ, γ) ∈ ζ(L(G)).
Thus, the induction holds, which completes the proof. (cid:4)

(σ)∩p(s)∗ ∩(Σ∗

o

Notice that in Gζ, except for being at the initial state
(x0, (cid:15), Σ), no transition between two diﬀerent states can
be unobservable.

Since the map p introduced before is a projec-
tion, it is not diﬃcult to check that ˆH = ζ(L(G)) −
o × Γ)∗ is regular, as both
p−1(p(ν(ψ(ι(Ldam)))))(Σ(cid:15)
ζ(L(G)) and ν(ψ(ι(Ldam))) are shown to be regular.
Thus, its preﬁx closure H := ˆH is also regular. Let
the alphabet be Σ(cid:15)
o × Γ and the uncontrollable al-
phabet be {(cid:15)} × Γ. Since Gζ is nondeterministic, H
can be recognized by a nondeterministic automaton,
without masking out necessary marking information
inherited from G, which will be used later. By us-
ing a synthesis algorithm similar to the one proposed
in [24]
[25], which is realized in [31], we can show
that S∗ = supC(ζ(L(G)), H) is also regular, and gen-
erated by a nondeterministic ﬁnite-state automaton
H := (Q, Σ(cid:15)
o × Γ, Ξ, q0, Qm), where Q = X × Σ(cid:15)
o × Γ × R
and Qm = Xm × Σ(cid:15)
o × Γ × R with R being the state set
of the recognizer of p−1(p(ν(ψ(ι(Ldam)))))(Σ(cid:15)
o × Γ)∗.
That is S∗ = L(H). Next, we will develop a compu-
tational method to determine whether a nonblocking
resilient supervisor candidate in S∗ exists.

To handle partial observation induced by g, we under-
take the following subset-construction style operation on
H. Let P(H) = (QP , Σ(cid:15)
• QP := Σ(cid:15)
• q0,P := ((cid:15), {q ∈ Q|(∃t ∈ g−1((cid:15)))q ∈ Ξ(q0, t)}, q0);
• The transition map ΞP : QP ×Σ(cid:15)

o × Γ, ΞP , q0,P , Qm,P ), where

o × 2Q × Q, Qm,P := Σ(cid:15)

o×Γ → 2QP is deﬁned

o × 2Q × Qm;

as follows: for each (σ, U, q) ∈ QP and (σ(cid:48), γ) ∈ Σ(cid:15)
if σ(cid:48) = (cid:15), then

o×Γ,

ΞP (σ, U, q, (cid:15), γ) := {σ} × {U } × Ξ(q, (cid:15), γ);

otherwise, we have

ΞP (σ, U, q, σ(cid:48), γ) := {σ(cid:48)} × Ξ(U, σ(cid:48), γ) × Ξ(q, σ(cid:48), γ),

where

Ξ(U, σ(cid:48), γ) :=
{ˆq ∈ QP |(∃˜q ∈ U )(∃t ∈ g−1(Po(σ(cid:48))))ˆq ∈ Ξ(˜q, t)}.
Remarks: It is clear that L(P(H)) = L(H) = S∗.
In addition, since all unobservable transitions in Gζ are
selﬂooped at relevant states, by the construction of S∗,
we can check that the recognizer H also selﬂoops all
unobservable transitions. Due to this property, we have
ΞP (σ, U, q, (cid:15), γ) := {σ}×{U }×Ξ(q, (cid:15), γ) in the deﬁnition
of P(H), where Ξ(q, (cid:15), γ) either equals {q} or ∅ in H.

To illustrate the construction procedure for P(H), as-
sume that in Example 3 depicted in Figure 13, H = Gζ.
After applying the construction procedure for P(H), the

(5) Ω is co-reachable.

(cid:50)

The ﬁrst condition in Def. 5 essentially states that in
Ω no uncontrollable transitions allowed by Gζ shall be
disabled, which is similar to the concept of state con-
trollability in [24] that handles nondeterministic transi-
tions. Based on the construction of P(H), if ((cid:15), γ(cid:48)) is al-
lowed at state q = (σ, U, x, σ, γ, r) in Ω, then γ(cid:48) = γ and
ΞΩ(q, (cid:15), γ) = {q}. The second condition states that all
strings observably identical in L(Ω) must result in the
same control pattern. The third condition states that,
for any state in Ω, an observable event is allowed at state
q if and only if it is allowed both by the plant Gζ and the
corresponding control pattern γ associated with q. The
fourth condition is similar to the concept of state observ-
ability in [24] to handle nondeterminism, which requires
that all states in P(H) reachable by strings observably
identical to some string in L(Ω), must be included in Ω.
The last condition is self-explained.

As an illustration, Figure 15 depicts one choice of Ω
derived from P(H) in Example 3. We can see that clearly

Fig. 14. Example 3: The model of P(H)

outcome is depicted in Figure 14, where

U0 = {q0,P , (0, (cid:15), {a, b, v, c}), (0, (cid:15), {b, v, c})};
U1 = {(1, a, {a, b, v, c}), (1, a, {b, v, c})};
U2 = {(2, b, {a, b, v, c}), (2, b, {b, v, c})};
U3 = {(3, c, {a, b, v, c}), (3, c, {b, v, c}), (5, c, {a, b, v, c}),

(5, c, {b, v, c})};

U4 = {(7, c, {a, b, v, c}), (7, c, {b, v, c})}.

Deﬁnition 5 Given P(H), a reachable sub-automaton
Ω = (QΩ ⊆ QP , Σ(cid:15)
o × Γ, ΞΩ, q0,P , Qm,Ω ⊆ Qm,P ) of
P(H) is control feasible if the following conditions hold:

(1) For all q = (σ, U, x, σ, γ, r) ∈ QΩ with q (cid:54)= q0,P ,

(∀γ(cid:48) ∈ Γ) ξζ(x, σ, γ, (cid:15), γ(cid:48)) (cid:54)= ∅ ⇒ ΞΩ(q, (cid:15), γ(cid:48)) (cid:54)= ∅;

(2) For all (σ, U, x1, σ, γ1, r1), (σ, U, x2, σ, γ2, r2) ∈ QΩ,

we have γ1 = γ2;

(3) For each q = (σ, U, x, σ, γ, r) ∈ QΩ,

g(EnΩ(q)) = Po(γ) ∩ g(EnGζ (x, σ, γ));

(4) For all (σ, U, q) ∈ QΩ and µ ∈ Σ(cid:15)

o × Γ,
ΞΩ(σ, U, q, µ) (cid:54)= ∅, then for all (σ, U, q(cid:48)) ∈ QP ,

if

ΞΩ(σ, U, q(cid:48), µ) = ΞP (σ, U, q(cid:48), µ) ⊆ QΩ;

Fig. 15. Example 3: A model containing one Ω

no self-looped uncontrollable events are disabled. So the
ﬁrst condition in Def. 5 holds. Due to the second condi-
tion in Def. 5, in U0 we choose to keep γ = {a, b, v, c},
and thus, only states q0,P and ((cid:15), U0, 0, (cid:15), {a, b, v, c})
will be kept in Ω. Similarly, in U1 the control pat-
tern γ = {b, v, c} is chosen; in U2 the control pattern
γ = {a, b, v, c} is chosen; in U3 the pattern γ = {a, b, v, c}
is chosen; and in U4 the pattern γ = {b, v, c} is cho-
sen. Due to the third condition in Def. 5, we can see
that in U0 both outgoing transitions (a, {b, v, c} and
(b, {a, b, v, c}) of state ((cid:15), U0, 0, (cid:15), {a, b, v, c}) must be
chosen in Ω, as both events a and b are allowed by
the control pattern {a, b, v, c} and the augmented plant
Gζ. In U1, due to the fourth condition in Def. 5, both
nondeterministic outgoing transitions (c, {a, b, v, c}) to-
wards (c, U3, 3, c, {a, b, v, c}) and (c, U3, 5, c, {a, b, v, c})
must be allowed in Ω. Clearly, all reachable states
in Ω is co-reachable. Thus, after removing all un-
reachable states in Figure 15, the remaining struc-
ture Ω is a control feasible sub-automaton of P(H)
in Example 3. The corresponding supervisory control
map V : Po(L(G)) → Γ can be derived as follows:
V ((cid:15)) := {a, b, v, c}, V (a) := {b, v, c}, V (b) := {a, b, v, c},
V (ac) := {a, b, v, c, } and V (bc) := {b, v, c}. Similarly,
we can check that in Example 2, each marked trajectory
in Figure 12 leads to one control feasible sub-automaton
Ω, which satisﬁes all conditions in Def. 5.

Theorem 4 Let P(H) be constructed as shown above.
Then there exists a nonblocking resilient supervisor can-

11

didate of S∗ if and only if there exists a control feasible
(cid:50)
reachable sub-automaton of P(H).

|X||Σ(cid:15)

o|2|X||Σ(cid:15)

o ||Γ|2|W |+n|∆n|

o||Γ|2|W |+n|∆n|

The complexity of computing P(H) is O(|QP |2|Σ(cid:15)
o||Γ|).
To determine the existence of a control feasible sub-
automaton of P(H), in the worst case we need to check
each sub-automaton. There are 2|QP | sub-automata.
For each sub-automaton Ω, whose state set is QΩ ⊆ QP ,
we need to check all four conditions deﬁned in Def. 5,
whose complexity is O(|QΩ|2 + |QΩ||Σ(cid:15)
o||Γ|). Typically,
we have |QP | (cid:29) |Σ(cid:15)
o||Γ| and 2|QP | (cid:29) |QP |3. The ﬁnal
complexity of ﬁnding a control feasible sub-automaton
is O(2|QP |). Notice that |QP | = |Σ(cid:15)
o|2|Q||Q|, where |Q| =
o||Γ||R| with |R| = 2|W |+n|∆n|. The ﬁnal complex-
|X||Σ(cid:15)
ity is O(2|Σ(cid:15)
Theorem 5 Given a plant G and a damage language
Ldam ⊆ L(G), it is decidable whether there exists a non-
blocking supervisor V such that the closed-loop system
(cid:50)
V /G is not attackable with respect to Ldam.
Proof: By Theorem 3, there exists a nonblocking super-
visor which disallows any regular smart sensor attack
with respect to Ldam if and only if there exists a non-
blocking resilient supervisor candidate L ⊆ S∗. By The-
orem 4, we know that there exists a nonblocking resilient
supervisor candidate if and only if there exists a con-
trol feasible sub-automaton of P(H), which recognizes
S∗. Since there exists a ﬁnite number of sub-automata in
P(H), the existence of a control feasible sub-automaton
of P(H) is decidable. Thus, the existence of a nonblock-
ing supervisor which disallows any regular smart sensor
(cid:4)
attack with respect to Ldam is decidable.

).

It is interesting to point out that, in general, there
are typically many choices of a control feasible sub-
automaton Ω, leading to possibly many resilient super-
visors. It is unfortunate that the most permissive re-
silient supervisor in terms of set inclusion of closed-loop
behaviours typically does not exist. For example, in Ex-
ample 2 there are up to three diﬀerent supervisory con-
trol maps depicted in Figure 12, leading to two non-
compatible maximally permissive supervisors: one gen-
erates the closed-loop behaviour of L(V1/G) = {avc}
and the other one generates L(V2/G) = {bvd}. It is an
interesting question whether the structure P(H) could
be used to directly synthesize a maximally permissive
nonblocking resilient supervisor, as it conceptually con-
tains all resilient supervisors.

7 Conclusions

Although in our early work [9] [10], the concept of
smart sensor attacks was introduced, and syntheses of a
smart sensor attack and a supervisor resilient to smart
sensor attacks were presented, it has not been shown
whether the existence of a nonblocking supervisor re-
silient to all smart sensor attacks is decidable, as the
synthesis algorithm presented in [10] does not guarantee
to ﬁnd a resilient supervisor, even though it may exist.
In this paper we have ﬁrst shown that the existence of
a regular smart weak sensor attack is decidable, and in
case it exists, it can be synthesized. Our ﬁrst contribu-
tion is to identify risky pairs that describe how a legal
sequence of control patterns may be used by a sensor at-
tack to inﬂict weak damage, which is stated in Theorem
1 that there exists a smart weak sensor attack if and only
if there exists at least one risky pair. Notice that this
result is valid, regardless of whether the attack model is

12

regular, i.e., representable by a ﬁnite-state automaton.
With this key idea, to ensure the existence of a super-
visor resilient to smart sensor attacks, we only need to
make sure that there should be no risky pairs. Our sec-
ond contribution is to show that all risky pairs can be
identiﬁed and removed from the plant behaviours, via a
genuine encoding scheme, upon which a veriﬁable suﬃ-
cient and necessary condition is presented to ensure the
existence of a nonblocking supervisor resilient to smart
sensor attacks. This establishes the result that the exis-
tence of a supervisor resilient to all smart sensor attacks
is decidable. Finally, as our third contribution, the deci-
sion process renders a synthesis algorithm for a resilient
supervisor, whenever it exists, which has never been ad-
dressed in any existing works.

The decidability result established in this paper may
shed light on future research on cyber attack related
resilient synthesis, e.g., to decide existence of a resilient
supervisor for smart actuator attacks or smart attacks
with observations diﬀerent from those of the supervisor,
which are gaining more and more attention recently.
This decidability result allows us to focus more on com-
putational eﬃciency related to smart sensor attacks.

Appendix

1. Proof of Theorem 1: (1) We ﬁrst show the IF part.
Assume that there exist s = u1σ1 · · · urσrur+1 ∈ Ldam,
with r ∈ N, u1, · · · , ur+1 ∈ Σ∗
uo and σ1, · · · , σr ∈ Σo,
and t = ν1 · · · νr ∈ Po(L(V /G)) with ν1, · · · , νr ∈ ∆n
such that (1) u1, σ1 ∈ V (t0)∗; (2) for each i ∈ {2, · · · , r},
ui, σi ∈ V (ti−1)∗; (3) ur+1 ∈ V (t)∗. We now explicitly
design an attack model A as follows.

(1) A((cid:15)) := (cid:15);
(2) for each s ∈ Po(L(G)), where A(s) has been deﬁned,

for each σ ∈ Σo with sσ ∈ Po(L(G)),

A(sσ) :=






A(s)νi if sσ = σ1 · · · σi, i ∈ {1, · · · , r};

A(s)σ if sσ ∈ L(V /G) − {σ1 · · · σr};

A(s)

otherwise.

Clearly, A is well deﬁned. We now show that A(Po(L(V ◦
A/G))) ⊆ L(S), i.e., A is covert, by using induction on
the length of strings in Po(L(G)). Clearly, (cid:15) ∈ Po(L(V ◦
A/G)), and A((cid:15)) = (cid:15) ∈ L(S). Assume that for all strings
s ∈ Po(L(V ◦ A/G)) with |s| ≤ n, where n ∈ N, we have
A(s) ∈ L(S). We need to show that for each σ ∈ Σo
with sσ ∈ Po(L(V ◦ A/G)), we have A(sσ) ∈ L(S).
If sσ = σ1 · · · σn+1, where n + 1 ≤ r, then we have
A(sσ) = ν1 · · · νn+1 ∈ {t} ⊆ Po(L(V /G)) ⊆ L(S).
If sσ ∈ L(V /G) − {σ1 · · · σr}, then we have two cases
to consider. Case 1: A(s)σ ∈ L(V /G) ⊆ L(S). Then
A(sσ) = A(s)σ ∈ L(S). Case 2: A(s)σ /∈ L(S). We will
show that, sσ /∈ Po(L(V ◦A/G)). Since sσ ∈ L(V ◦A/G),
we have A(s) ⊆ L(S). Because s ∈ Po(L(G)), there
must exist ˜s ∈ L(V ◦ A/G) such that s = Po(˜s). For
all ˜u ∈ Σ∗
uo, if ˜s˜uσ ∈ L(V ◦ A/G), we know that ˜uσ ∈
V (A(Po(˜s)))∗ = V (A(s))∗. By the deﬁnition of V , we
know that σ must also be in V (A(s)). Thus, A(s)σ ∈
L(S). But this contradicts our assumption that A(s)σ /∈
L(S). Thus, the only possibility is that sσ /∈ L(V /G).
Since sσ ∈ Po(L(V ◦ A/G)), we know that A(s) ∈ L(S)
and σ ∈ V (A(s)) ∈ Γ(V ). If s ∈ L(V /G), then clearly
sσ ∈ L(G) − (L(V /G) ∪ {σ1 · · · σr}). Thus, by Deﬁnition

of A, we have A(sσ) = A(s) ∈ L(S). With a similar ar-
gument, we know that for all s(cid:48) ∈ Σ∗, ss(cid:48) ∈ L(V ◦ A/G)
implies that s(cid:48) ∈ V (A(s))∗, and A(ss(cid:48)) = A(s) ∈ L(S).
If s /∈ L(V /G), then we can always ﬁnd ˆs ≤ s and
ˆσ ∈ Σo with ˆsˆσ ≤ s such that ˆs ∈ L(V /G) but ˆsˆσ /∈
L(V /G). Then with the same argument, we know that
(s/ˆs)σ ∈ L(G)−(L(V /G)∪{σ1 · · · σr}), namely A(sσ) =
A(ˆs(s/ˆs)σ) = A(ˆs) ∈ L(S). Thus, the induction part
holds, which means A is covert.

Since A results in weak damage due to the existence

of ˆs, by Def. 1, A is a smart weak sensor attack.
(2) Next, we show the ONLY IF part. Assume
that there exists a smart weak sensor attack A. By
Def. 1, we know that A(Po(L(V ◦ A/G))) ⊆ L(S)
and L(V ◦ A/G) ∩ Ldam (cid:54)= ∅. Thus, there exists
s = u1σ1 · · · urσrur+1 ∈ L(V ◦ A/G) ∩ Ldam with
r ∈ N, u1, · · · , ur+1 ∈ Σ∗
uo and σ1, · · · , σr ∈ Σo,
such that A(Po(u1)) = (cid:15), A(Po(u1)σ1) = ν1 ∈ ∆n;
A(Po(u1)σ1 · · · Po(uj)) = A(Po(u1)σ1 · · · Po(uj−1)σj−1)
and A(Po(u1)σ1 · · · Po(uj)σj) = ν1 · · · νj with νj ∈ ∆n
for all j ∈ {2, · · · , r}; and ﬁnally,

A(Po(s)) = A(Po(u1)σ1 · · · Po(ur)σr).

Let t = ν1 · · · νr. Since s ∈ L(V ◦A/G), by the deﬁnition
of L(V ◦ A/G), we know that (1) u1, σ1 ∈ V (t0)∗; (2) for
each i ∈ {2, · · · , r}, ui, σi ∈ V (ti−1)∗; (3) ur+1 ∈ V (t)∗.
(cid:4)
Thus, the theorem follows.

2. Proof of theorem 2: Since V is regular, there is
a ﬁnite-state automaton S = (Z, Σ, δ, z0, Zm = Z)
that realizes V . We follow an idea adopted from
[10], and start with a single-state transducer A =
(Y, Σ(cid:15)
o × ∆n, η, I, O, y0, Ym = Y ), where Y = {y0} and
for all (σ, u) ∈ Σo × ∆n, we have η(y0, σ, u) = y0.
A contains all possible attack moves. Since Ldam
is
exists a ﬁnite-state automaton
D = (W, Σ, κ, w0, Wm) such that L(D) = Σ∗ and
Lm(D) = Ldam. We now form a combination of all
relevant ﬁnite-state transition structures. Let

regular,

there

Similarly, let (cid:36) : Σ∗

N → ∆∗

n be a projection, where

• (cid:36)((cid:15)) = (cid:15);
• (∀(σ, σ(cid:48), u) ∈ ΣN ) (cid:36)(σ, σ(cid:48), u) := u;
• (∀sς ∈ Σ∗

N ) (cid:36)(sς) = (cid:36)(s)(cid:36)(ς).

We calculate a controllable [23] preﬁx-closed sublan-
guage U ⊆ L(Ψ) w.r.t. Ψ and ΣN,uc := ΣN − ΣN,c, i.e.,

U ΣN,uc ∩ L(Ψ) ⊆ U,

which satisﬁes the following properties:
• π(U ) ∩ Lm(D) (cid:54)= ∅;
• (∀s ∈ U )π({ς ∈ ΣN |sς ∈ U }) = EnL(G)(π(s)) ∩

EnS((cid:36)(s));

o

• (∀s ∈ U )(∀t ∈ π−1(P −1

(Po(π(s)))) ∩ U )(cid:36)(s) = (cid:36)(t).
We can check that Condition 1 of U states a weak
nonblocking property. Condition 2 is an “extended”
controllability property, which states that, after a string
s ∈ U , each outgoing transition ς ∈ ΣN is allowed, as
long as the plant G allows it, i.e., π(ς) ∈ EnL(G)(π(s)),
and the supervisor also allows it, i.e., π(ς) ∈ EnS((cid:36)(s)).
Because the supervisor allows all uncontrollable tran-
sitions, thus, no uncontrollable events in Σuc shall be
disabled here, which is the reason why we call it a spe-
cial controllability property. Condition 3 states that
any two strings s and t, “observably” identical in the
sense that Po(π(s)) = Po(π(t)), must lead to the same
(fake) observable strings in ∆∗
n, i.e., (cid:36)(s) = (cid:36)(t), which
means Po(π(s)) = Po(π(t)) implies the same attack
move - thus, may result in a deterministic attack func-
tion. Based on this interpretation, by adopting either a
power set construction over Ψ via the projection Po ◦ π
and a state pruning algorithm similar to the one pro-
posed in [24] that originally aims to compute a supremal
nonblocking supervisor with respect to Lm(D), that is
state-controllable and state-normal, or one algorithm
proposed in [33] that computes a maximally control-
lable and observable nonblocking supervisor, we can
show that the existence of such a U is decidable.

Ψ = (N, ΣN , λ, n0, Nm),

where

• N = X × Z × Y × W , Nm = Xm × Zm × Ym × Wm;
• n0 = (x0, z0, y0, w0);
• ΣN := {(σ, σ(cid:48), u) ∈ Σ × Σ(cid:15)

o × ∆n|σ(cid:48) = Po(σ) ∧ [σ(cid:48) =

(cid:15) ⇒ u = (cid:15)]};

To complete the proof, we only need to show that there
exists a regular smart weak sensor attack if and only if
there exists such a language U .

To show the IF part, we deﬁne an attack model A :

n, where

Po(L(G)) → ∆∗
• (∀s ∈ U )A(Po(π(s))) := (cid:36)(s);
• for all s ∈ U and µ ∈ ΣN ,

• λ : N ×ΣN → N is the partial transition map: for each
(x, z, y, w), (x(cid:48), z(cid:48), y(cid:48), w(cid:48)) ∈ N and (σ, σ(cid:48), u) ∈ ΣN ,

λ(x, z, y, w, σ, σ(cid:48), u) = (x(cid:48), z(cid:48), y(cid:48), w(cid:48))

if and only if the following conditions hold:

(1) σ ∈ EnS(z);
(2) δ(z, u)!;
(3) ξ(x, σ) = x(cid:48), δ(z, u) = z(cid:48), η(y, σ(cid:48), u) = y(cid:48), and

κ(w, σ) = w(cid:48).

Let the controllable alphabet of Ψ be

ΣN,c := ΣN ∩ (Σo × Σo × ∆n).

Let π : Σ∗

N → Σ∗ be a projection, where

• π((cid:15)) = (cid:15);
• (∀(σ, σ(cid:48), u) ∈ ΣN ) π(σ, σ(cid:48), u) := σ;
• (∀sς ∈ Σ∗

N ) π(sς) = π(s)π(ς).

sµ /∈ U ⇒ (∀t ∈ Σ∗

N )A(Po(π(sµt))) := A(Po(π(s))).

Since for all s, t ∈ U , if Po(π(s)) = Po(π(t)), then (cid:36)(s) =
(cid:36)(t), we know that A is well deﬁned.

Next, we show that conditions (1) and (3) stated in
Def. 1 hold for A, meaning that A is a smart weak sensor
attack.

We ﬁrst show that Condition (1) in Def. 1 holds,
i.e., A(Po(L(V ◦ A/G))) ⊆ L(S). We ﬁrst consider all
s ∈ U . Since U ⊆ L(Ψ), by the deﬁnition of Ψ and
Condition 2 of U , we write string s as s = s1 · · · sr ∈ U ,
where si = (τi,1, (cid:15), (cid:15)) · · · (τi,li, (cid:15), (cid:15))(σi, σi, ui) with
r, l1, · · · , lr ∈ N, 1 ≤ i ≤ r, σ1, · · · , σr ∈ Σo and
{τi,1, · · · , τi,li } ⊆ Σuo such that τj,p ∈ V (u1 · · · uj−1) =
EnS(δ(z0, u1 · · · uj−1)) (j = 2, · · · , r, 1 ≤ p ≤ lj)
and τ1,q ∈ V ((cid:15)) = EnS(z0) with 1 ≤ q ≤ l1. Thus,
(cid:36)(s) = u1 · · · ur ∈ L(S), as all unobservable tran-
sitions are self-looped in S. Thus, A(Po(π(s))) =

13

(cid:36)(s) ∈ L(S). For each string t ∈ L(V ◦ A/G), there
exists s(cid:48) ∈ π−1(t) ∈ Σ∗
N and, by the deﬁnition of A,
A(Po(π(s(cid:48)))) = A(Po(t)) ⊆ L(S).

Next, we show that Condition (3) in Def. 1 holds, that
is, L(V ◦ A/G) ∩ Ldam (cid:54)= ∅. To see this, notice that
L(V ◦ A/G) = π(U ) and since π(U ) ∩ Ldam (cid:54)= ∅, we
have L(V ◦ A/G) ∩ Ldam (cid:54)= ∅. Thus, by Def. 1, A is a
smart weak sensor attack.

To show the ONLY IF part, assume that there exists
a regular smart weak sensor attack A represented by
a ﬁnite-transducer A = (Y, Σ(cid:15)
o × ∆n, η, I, O, y0, Y ). We
construct Ψ as shown above and let U = L(Ψ). Since A
is a smart weak sensor attack, conditions (1) and (3) in
Def. 1 hold. Clearly, U is controllable and preﬁx closed.
We know that π(U ) ∩ Ldam = L(V ◦ A/G) ∩ Ldam (cid:54)= ∅,
due to Condition (3) in Def. 1. Due to the covertness
condition in Def. 1, we know that, for all s ∈ U , we have
(cid:36)(s) ∈ L(S). By the deﬁnition of U , we know that

iii) For all s ∈ L, and σ(cid:48) ∈ Po(p(s)↑) and γ ∈ Γ,

(σ(cid:48), γ) ∈ Enζ(L(G))(s) ⇒ s(σ(cid:48), V (g(s)σ(cid:48))) ∈ L;

iv) All strings in L are generated in Steps (1)-(3).

Clearly, L ⊆ ζ(L(G)). Because V is a resilient super-
visor, by Theorem 1 we know that L ⊆ H - other-
wise, there must exist a smart weak attack. By the con-
struction of L, we know that L is conditionally con-
trollable with respect to ζ(L(G)) and {(cid:15)} × Γ. Thus,
L ∈ C(ζ(L(G)), H), namely, L ⊆ S∗. Since V is a non-
blocking supervisor, we can check that the ﬁrst and
last conditions in Def. 4 hold. Since L ⊆ ζ(L(G)), we
know that g(EnL(s)) ⊆ g(Enζ(L(G))(s)). By Steps (iii)-
(iv), we know that g(EnL(s)) ⊆ Po(p(s↑)). Thus, we
have g(EnL(s)) ⊆ Po(p(s↑)) ∩ g(Enζ(L(G))(s)). On the
other hand, by Step (iii), we know that g(EnL(s)) ⊇
Po(p(s↑)) ∩ g(Enζ(L(G))(s)). Thus, we ﬁnally have

π({ς ∈ ΣN |sς ∈ U }) = EnL(G)(π(s)) ∩ EnS((cid:36)(s)).

g(EnL(s)) = Po(p(s↑)) ∩ g(Enζ(L(G))(s)),

Finally, because the attack model A : Po(L(G)) → ∆∗
n
is a map, which maps all strings observably identical
to the same observable string acceptable by S, by the
deﬁnition of U , we have

(∀s ∈ U )(∀t ∈ π−1(P −1

o

(Po(π(s)))) ∩ U )(cid:36)(s) = (cid:36)(t).

Thus, all required conditions for U hold. This completes
(cid:4)
the proof.

3. Proof of Theorem 3: (1) We ﬁrst show the IF part. As-
sume that there exists a nonblocking resilient supervisor
candidate L ⊆ S∗. For each s ∈ Po(L(G)), if s /∈ g(L)
then let V (s) := Σuc; otherwise, for any u ∈ g−1(s) ∩ L,
let V (s) := [p(u)]↑. For the latter case, we ﬁrst show
that V (s) is well deﬁned. Assume that it is not true,
then there exist u1, u2 ∈ g−1(s) ∩ L such that u1 (cid:54)= u2
and [p(u1)]↑ (cid:54)= [p(u2)]↑. But this violates Condition 1
of Def. 4, thus, contradicts our assumption that L is a
nonblocking resilient supervisor candidate. So V must
be well deﬁned, that is, for each s ∈ Po(L(G)), V (s) is
uniquely deﬁned.

Secondly, since [p(u)]↑ is a control pattern for u ∈
g−1(s) ∩ L, it is clear that V (s) ∈ Γ. Since V maps all
strings observably identical to a same control pattern,
we know that L(V /G) is observable. Finally, by the third
condition of Def. 4, it is clear that L is nonblocking. By
the construction of L, and the second condition of Def.
4, where for all ˆs ∈ L,

g(EnL(ˆs)) = Po(p(ˆs↑)) ∩ g(Enζ(L(G))(ˆs)),

we can show that g(L) = Po(L(V /G)). Thus, by the
third condition of Def. 4, we have that V is a nonblocking
supervisory control map. Clearly, V does not allow any
weak sensor attack damage. Thus, it is resilient to any
smart sensor attack, regardless of whether the attack is
a strong or weak one.

(2) We now show the ONLY IF part. Assume that there
exists a supervisor V , which does not allow any smart
sensor attack. Since each strong attack is also a weak
attack, we will only need to consider weak sensor attacks.
We deﬁne the following language L induced from V :

i) (cid:15) ∈ L;
ii) ((cid:15), V ((cid:15))) ∈ L;

which means the second condition of Def. 4 holds. Thus,
L is a nonblocking resilient supervisor candidate, which
(cid:4)
completes the proof.

4. Proof of Theorem 4: (1) To show the IF part,
feasible reachable sub-
assume that Ω is a control
automaton of P(H). Let L := L(Ω). By condition
(1) of Def. 5, we know that L is conditionally con-
trollable with respect to ζ(L(G)) and {(cid:15)} × Γ. Thus,
L ∈ C(ζ(L(G)), H). For all s ∈ L and t ∈ g−1(g(s)) ∩ L,
let (σ, U, x1, σ, γ1, r1), (σ, U, x2, σ, γ2, r2) ∈ QΩ be in-
duced by s and t with σ = g(s)↑ = g(t)↑. Then by
condition (2) of Def. 5, we have γ1 = γ2. Thus, the ﬁrst
condition in Def. 4 holds. In addition, we have

EnL(s) :=

(cid:91)

EnΩ(q).

q=(g(s)↑,U,x,g(s)↑,γ,r)∈ΞΩ(q0,P ,s)

By condition (3) of Def. 5, we have g(EnΩ(q)) = Po(γ)∩
g(EnGζ (x, g(s)↑, γ)), by condition (4) of Def. 5, we have

(cid:91)

EnGζ (x, σ, γ) = Enζ(L(G))(s),

(σ,U,x,σ,γ,r)∈ΞΩ(q0,P ,s)

where σ = g(s)↑. Thus, we conclude that g(EnL(s)) =
Po(p(s↑)) ∩ g(Enζ(L(G))(s)), namely the second condi-
tion of Def. 4 holds. Finally, since Ω is co-reachable, and
together with condition (4) of Def. 5, we know that L
is nonblocking. Thus, by Def. 4, L is a nonblocking re-
silient supervisor candidate of S∗.
(2) To show the ONLY IF part, assume that there exists
a nonblocking resilient supervisor candidate L ⊆ S∗. We
need to show that there exists a control feasible sub-
automaton Ω of P(H). We construct a sub-automaton
P(H)L := (QL, Σ(cid:15)

o × Γ, ΞL, q0,P , Qm,L), where

QL := {q ∈ QP |(∃s ∈ L)q ∈ ΞP (q0,P , s)},

and Qm,L := QL ∩ Qm,P . The transition map ΞL is the
restriction of ΞP over QL.

Let Ω be the sub-automaton P(H)L. Since L is a su-
pervisor candidate, by the ﬁrst condition of Def. 4, we
have the following property:

(∀s ∈ L){[p(t)]↑|t ∈ g−1(g(s)) ∩ L} = {p(s)↑}.

(∗)

14

By the construction of P(H), we know that for each
state reachable by s, say (g(s)↑, Us, qs), and each state
reachable by t ∈ g−1(g(s)) ∩ L, say (g(t)↑, Ut, qt), we
have Us = Ut. Thus, if qs = (xs, g(s)↑, γs, rs) and qt =
(xt, g(t)↑, γt, rt), by the property (∗), we have γs = γt,
which means the second condition of Def. 5 holds. Based
on the construction of Ω, it is also clear that the condi-
tion (1) of Def. 5 holds because P(L)L is conditionally
controllable due to the conditional controllability of L.
Because P(H)L is derived from a language L, the fourth
condition of Def. 5 holds for P(H)L. In addition, since L
is a resilient supervisor candidate, by the second condi-
tion of Def. 4, we know that the third condition of Def.
5 holds. Finally, since L is nonblocking, based on Def. 3,
we know that each state in Ω must be co-reachable. This
completes the proof that Ω is indeed control feasible. (cid:4)

References

[15] Lin, L., & Su, R. (2021). Synthesis of covert actuator and
sensor attackers. Automatica , 130:109714 (early access).

[16] Lin, L., Zhu, Y., & Su, R. (2019b). Towards bounded
synthesis of resilient supervisors. In Proceedings of the 58th
IEEE Conference on Decision and Control (CDC), pp.
7659–7664.

[17] Lin, L., Zhu, Y., & Su, R. (2020). Synthesis of covert actuator
attackers for free. Journal of Discrete Event Dynamic
Systems, 30:561-577.

[18] Zhu, Y., Lin, L., & Su, R. (2019). Supervisor obfuscation
against actuator enablement attack. In Proceedings of 2019
European Control Conference (ECC), pp. 1760–1765.

[19] Wakaiki, M., Tabuada, P., & Hespanha, J. P. (2019).
Supervisory control of discrete-event systems under attacks.
Dynamic Games and Applications, 9(4):965-983.

[20] Fritz, R., & Zhang, P. (2018). Modeling and detection of
cyber attacks on discrete event systems. In Proceedings of
the 14th International Workshop on Discrete Event Systems
(WODES), pp. 285-290.

[1] Dibaji, S. M., Pirani, M., Flamholz, D. B., Annaswamy, A.
M., Johansson, K. H., & Chakrabortty, A. (2019). A systems
and control perspective of CPS security. Annual Reviews in
Control, 47: 394–411.

[21] Khoumsi, A. (2019). Sensor and actuator attacks of cyber-
physical systems: a study based on supervisory control of
discrete event systems. In Proceedings of the 8th International
Conference on Systems and Control (ICSC), pp. 176-182.

[2] Carvalho, L. K., Wu, Y.-C., Kwong, R., & Lafortune, S.
(2016). Detection and prevention of actuator enablement
attacks in supervisory control systems. In Proceedings of
the 13th International Workshop on Discrete Event Systems
(WODES), pp. 298–305.

[3] Lima, P., Alves, M. V., Carvalho, L., & Moreira, M. (2017).
Security against network attacks in supervisory control
systems. IFACPapersOnLine, 50(1):12333–12338.

[4] Lima, P., Carvalho, L., & Moreira, M. (2018). Detectable
and undetectable network attack security of cyber-physical
systems. IFACPapersOnLine, 51(7):179–185.

[5] Gao, C., Seatzu, C., Li, Z., & Giua, A. (2019). Multiple
attacks detection on discrete event systems. In Proceedings of
2019 IEEE International Conference on Systems, Man and
Cybernetics (SMC), pp. 2352–2357.

[6] Carvalho, L., Wu, Y., Kwong, R., & Lafortune, S. (2018).
Detection and mitigation of classes of attacks in supervisory
control systems. Automatica, 97:121–133.

[7] Wang, Y., & Pajic, M. (2019a). Attack-resilient supervisory
control with intermittently secure
In
Proceedings of the 58th IEEE Conference on Decision and
Control (CDC), pp. 2015–2022.

communication.

[8] Wang, Y., & Pajic, M. (2019b). Supervisory control of
discrete event systems in the presence of sensor and actuator
attacks. In Proceedings of the 58th IEEE Conference on
Decision and Control (CDC), pp. 5350–5355.

[9] Su, R. (2017). A cyber attack model with bounded sensor
reading alterations. In Proceedings of 2017 American Control
Conference (ACC), pp. 3200–3205.

[10] Su, R.

(2018). Supervisor

to thwart cyber
attack with bounded sensor reading alterations. Automatica,
94:35–44.

synthesis

[11] Meira-G´oes, R., Kang, E., Kwong, R., & Lafortune, S. (2017).
Stealthy deception attacks for cyber-physical systems. In
Proceedings of the 56th IEEE Conference on Decision and
Control (CDC), pp. 4224–4230.

[12] Meira-G´oes, R., Kang, E., Kwong, R., & Lafortune, S. (2020).
Synthesis of sensor deception attacks at the supervisory layer
of cyber-physical systems. Automatica, 121:109172 (online
access).

[22] Lin, F., & Wonham, W. M. (1988). On observability of
discrete-event systems.Information Sciences, 44(3), 173-198.

[23] Ramadge, P. J., & Wonham, W. M. (1987). Supervisory
control of a class of discrete event systems. SIAM J. Control
and Optimization, 25(1), 206–230.

[24] Su, R., Van Schuppen, J. H., & Rooda, J. E. (2010).
Aggregative synthesis of distributed supervisors based on
automaton abstraction.
IEEE Trans. Automatic Control,
55(7), 1627-1640.

[25] Su, R., Van Schuppen,

J. E.
(2012). Maximally permissive coordinated distributed
supervisory
of nondeterministic discrete-event
systems. Automatica, 48(7), 1237-1247.

J. H., & Rooda,

control

[26] Wonham, W. M. (2014). Supervisory Control of Discrete-
Event Systems. Systems Control Group, Dept. of ECE,
University of Toronto. URL: www.control.utoronto.ca/DES.

[27] Wonham, W. M., & Ramadge, P. J. (1987). On the supremal
controllable sublanguage of a given language. SIAM J.
Control and Optimization, 25(3), 637-659.

[28] Paoli, A., Sartini, M., & Lafortune, S. (2011). Active
fault tolerant control of discrete event systems using online
diagnostics. Automatica, 47(4), 639-649.

[29] Rasouli, M., Miehling, E., & Teneketzis, D. (2014). A
supervisory control approach to dynamic cyber-security.
Proceedings of 2014 International Conference on Decision
and Game Theory for Security, (pp. 99-117).

[30] TCT:

A Computation Tool
http://www.control.utoronto.ca/DES/Research.html.

for Supervisory Control Synthesis.

[31] SuSyNA:

Supervisor Synthesis
http://www.ntu.edu.sg/home/rsu/Downloads.htm.

for Nondeterministic Automata.

[32] Alves, M., Basilio, J. C., da Cunha, A., Carvalho, L. K., &
Moreira, M. V. (2014). Robust supervisory control against
intermittent loss of observations. Proceedings of the 12th Int.
Workshop on Discrete Event Syst., (pp. 294-299).

[33] Yin, X., & Lafortune, S. (2016). Synthesis of maximally
permissive supervisors for partially observed discrete event
systems. IEEE Trans. Automatic Control, 61(5), 1239-1254.

[13] Meira-G´oes, R., Kwong, R., & Lafortune, S.

(2019).
Synthesis of sensor deception attacks for systems modeled
as probabilistic automata. In Proceedings of 2019 American
Control Conference (ACC), pp. 5620–5626.

[34] Sampath, M., Sengupta, R., Lafortune, S., Sinnamohideen,
K., & Teneketzis, D. (1995). Diagnosability of discrete-event
systems. IEEE Trans. on Automatic Control, 40(9), 1555-
1575.

[14] Lin, L., Thuijsman, S., Zhu, Y., Ware, S., Su, R., & Reniers,
M. (2019a). Synthesis of supremal successful normal actuator
attackers on normal supervisors. In Proceedings of 2019
American Control Conference (ACC), pp. 5614–5619.

[35] Meira-Goes, R., Marchand, H., & Lafortune, S. (2019).
Towards
sensor deception
supervisors against
attacks. Proceedings of the IEEE 58th Conference on Decision
and Control, (pp. 5144-5149).

resilient

15

[36] Meira-Goes, R., Lafortune, S., & Marchand, H. (2021).
Synthesis of supervisors robust against sensor deception
attacks. IEEE Transactions on Automatic Control, 66(10),
4990-4997.

[37] Meira-G´oes, R., Kwong, R., & Lafortune, S. (2021). Synthesis
of
multi-
optimal
objective attack strategies for controlled systems modeled
by probabilistic automata. IEEE Transactions on Automatic
Control, 10.1109/TAC.2021.3094737 (early access).

16

