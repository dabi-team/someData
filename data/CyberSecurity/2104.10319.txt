Evidential Cyber Threat Hunting

Frederico Araujo Dhilung Kirat Xiaokui Shu Teryl Taylor

Jiyong Jang

IBM Research, Yorktown Heights, NY, USA

1
2
0
2

r
p
A
1
2

]

R
C
.
s
c
[

1
v
9
1
3
0
1
.
4
0
1
2
:
v
i
X
r
a

Abstract
A formal cyber reasoning framework for automating the
threat hunting process is described. The new cyber reasoning
methodology introduces an operational semantics that operates
over three subspaces—knowledge, hypothesis, and action—
to enable human-machine co-creation of threat hypotheses
and protective recommendations. An implementation of this
framework shows that the approach is practical and can be used
to generalize evidence-based multi-criteria threat investigations.

Introduction

1
Traditional attack detection and defense mechanisms often
operate as separate, loosely-connected activities in threat
hunting and mitigation contexts. When a suspicious event
is detected in the monitoring data, the conventional course
of action is to generate an intrusion alert in order to
notify a security analyst about a potential threat. In
response to the incident, the analyst correlates the alert
to diﬀerent sources of intelligence (both internal and
external to the organization) to determine an appropriate
mitigation strategy to counter the threat. The outcome is
the execution of one or more defensive actions, such as
blacklisting a remote DNS domain, patching a software
vulnerability, or isolating potentially aﬀected assets for
further investigation.

This semi-manual process is onerous and requires
that cyber combatants connect spatially and temporally
scattered security alerts in order to comprehend threat
scenarios, assess the impact of an attack, and defend against
it. Figure 1a illustrates this concept. In this model, threat
detectors are partial functions mapping collected data (e.g.,
network packets, system traces, logs) to security alerts, and
detection responses are denoted by the hyperplane relating
alerts to defenses—the protective measures available to
the defendant. Such a reactive approach is insuﬃcient for
eﬀective threat hunting because (a) it fails to capture the
high-dimensional features of advanced attacks (local, global,
and oﬀense contexts), yielding too many false positives,
(b) it imposes a cognitive overload [14] on security analysts,
and (c) it misses the larger attack campaign, because
defensive actions respond to single, out-of-context events,
therefore promoting a “whack-a-mole” threat detection
methodology.

Recent automated approaches employ provenance
tracking to discover causality between alerts [8], prune
search trees [9, 7] and link low-level data to domain
knowledge [16, 10]. However, while useful in combating
threat alert fatigue, these approaches lack support for
iterative reasoning, and do not oﬀer a framework for
integrating data from various telemetry and intelligence
sources, and making explainable decisions from such data.

(a)

(b)

Figure 1: Illustration of (a) traditional ﬁrst-order functions
in threat detection and response, and (b) high-dimensional
decision manifolds in cyber threat hunting.

To better characterize the dynamics of advanced cyber
threats, this paper formalizes a cyber reasoning framework
based on multi-functors that deﬁne structure-preserving
mappings (a.k.a. morphisms) on threat knowledge,
hypothesis, and action subspaces. Unlike the ﬁrst-order
threat detection and response capabilities of traditional
cyber security models, such decision manifolds, depicted in
Figure 1b, connect cyber-hunting operations in a high-
dimensional space—where each subspace comprises many
dimensions—thus coping with the cognitive overload
problem (by enriching sensor data with threat information
that can be used to automatically reject or accept threat
hypotheses) and adversarial targeting (by embedding
attack models into the decision space).

Our framework introduces three high-dimensional
subspaces, which shape decision boundaries and augment
the threat hunting process with contextual information,
evidence-based reasoning, and a defense capability model.

Knowledge Subspace deﬁnes the scope of what is known
about the internal and external environments. Internal
knowledge includes monitoring events (e.g., ﬁrewall and
system logs, network packets and ﬂows, system traces),
network and assets information (e.g., sensors, services,
version, conﬁguration), and internal threat information
(e.g., vulnerability assessment reports, veriﬁed threats).
External knowledge includes threat intelligence [15] (e.g.,
security feeds, threat reports, malicious domains) and
security analytics information (e.g., security knowledge
graphs, ﬁle reputation and analysis services).

Hypothesis Subspace deﬁnes the domains of detection
hypotheses and threat hypotheses. A detection hypothesis
deﬁnes an attack proposition (e.g., “hostA is vulnerable to
reﬂected server XSS”, “hostB and clientX beacon every
two hours”), which can be substantiated by the type

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

detection functionsdatadefensesdetection responsesalertsaction subspace (A)knowledge subspace (K)hypothesis subspace (H)detection functionsaction manifoldscase manifoldsverifiersH⇥K*A<latexit sha1_base64="JX1BqiGEqlDI3oGV6n/+4RX78N0=">AAACGHicbVDLSgMxFM3UV62vqks3wSK4qjNS0GXFTcFNBfuAzlAyadqGZpIhuSOUoZ/hxl9x40IRt935N6btINp6IHA451xy7wljwQ247peTW1vf2NzKbxd2dvf2D4qHR02jEk1ZgyqhdDskhgkuWQM4CNaONSNRKFgrHN3O/NYj04Yr+QDjmAURGUje55SAlbrFCz8iMKREpLWJDzxiBt9hX/PBEIZEx0rJJMY/mZtJt1hyy+4ceJV4GSmhDPVucer3FE0iJoEKYkzHc2MIUqKBU8EmBT8xLCZ0RAasY6kkdoUgnR82wWdW6eG+0vZJwHP190RKImPGUWiTsxXNsjcT//M6CfSvg5TLOAEm6eKjfiIwKDxrCfe4ZhTE2BJCNbe7Ymr7IBRslwVbgrd88ippXpY9t+zdV0rVSlZHHp2gU3SOPHSFqqiG6qiBKHpCL+gNvTvPzqvz4XwuojknmzlGf+BMvwHX8aDX</latexit><latexit sha1_base64="JX1BqiGEqlDI3oGV6n/+4RX78N0=">AAACGHicbVDLSgMxFM3UV62vqks3wSK4qjNS0GXFTcFNBfuAzlAyadqGZpIhuSOUoZ/hxl9x40IRt935N6btINp6IHA451xy7wljwQ247peTW1vf2NzKbxd2dvf2D4qHR02jEk1ZgyqhdDskhgkuWQM4CNaONSNRKFgrHN3O/NYj04Yr+QDjmAURGUje55SAlbrFCz8iMKREpLWJDzxiBt9hX/PBEIZEx0rJJMY/mZtJt1hyy+4ceJV4GSmhDPVucer3FE0iJoEKYkzHc2MIUqKBU8EmBT8xLCZ0RAasY6kkdoUgnR82wWdW6eG+0vZJwHP190RKImPGUWiTsxXNsjcT//M6CfSvg5TLOAEm6eKjfiIwKDxrCfe4ZhTE2BJCNbe7Ymr7IBRslwVbgrd88ippXpY9t+zdV0rVSlZHHp2gU3SOPHSFqqiG6qiBKHpCL+gNvTvPzqvz4XwuojknmzlGf+BMvwHX8aDX</latexit><latexit sha1_base64="JX1BqiGEqlDI3oGV6n/+4RX78N0=">AAACGHicbVDLSgMxFM3UV62vqks3wSK4qjNS0GXFTcFNBfuAzlAyadqGZpIhuSOUoZ/hxl9x40IRt935N6btINp6IHA451xy7wljwQ247peTW1vf2NzKbxd2dvf2D4qHR02jEk1ZgyqhdDskhgkuWQM4CNaONSNRKFgrHN3O/NYj04Yr+QDjmAURGUje55SAlbrFCz8iMKREpLWJDzxiBt9hX/PBEIZEx0rJJMY/mZtJt1hyy+4ceJV4GSmhDPVucer3FE0iJoEKYkzHc2MIUqKBU8EmBT8xLCZ0RAasY6kkdoUgnR82wWdW6eG+0vZJwHP190RKImPGUWiTsxXNsjcT//M6CfSvg5TLOAEm6eKjfiIwKDxrCfe4ZhTE2BJCNbe7Ymr7IBRslwVbgrd88ippXpY9t+zdV0rVSlZHHp2gU3SOPHSFqqiG6qiBKHpCL+gNvTvPzqvz4XwuojknmzlGf+BMvwHX8aDX</latexit><latexit sha1_base64="JX1BqiGEqlDI3oGV6n/+4RX78N0=">AAACGHicbVDLSgMxFM3UV62vqks3wSK4qjNS0GXFTcFNBfuAzlAyadqGZpIhuSOUoZ/hxl9x40IRt935N6btINp6IHA451xy7wljwQ247peTW1vf2NzKbxd2dvf2D4qHR02jEk1ZgyqhdDskhgkuWQM4CNaONSNRKFgrHN3O/NYj04Yr+QDjmAURGUje55SAlbrFCz8iMKREpLWJDzxiBt9hX/PBEIZEx0rJJMY/mZtJt1hyy+4ceJV4GSmhDPVucer3FE0iJoEKYkzHc2MIUqKBU8EmBT8xLCZ0RAasY6kkdoUgnR82wWdW6eG+0vZJwHP190RKImPGUWiTsxXNsjcT//M6CfSvg5TLOAEm6eKjfiIwKDxrCfe4ZhTE2BJCNbe7Ymr7IBRslwVbgrd88ippXpY9t+zdV0rVSlZHHp2gU3SOPHSFqqiG6qiBKHpCL+gNvTvPzqvz4XwuojknmzlGf+BMvwHX8aDX</latexit>HD⇥K*HT<latexit sha1_base64="MxWXVpnky2NaQ9xampmL8IAHiVw=">AAACInicbVDLSgMxFM3UV62vqks3wSK4KjMiqLuCLgpuKvQFnVIyadqGZpIhuSOUYb7Fjb/ixoWirgQ/xkzbRW09EDiccy659wSR4AZc99vJra1vbG7ltws7u3v7B8XDo6ZRsaasQZVQuh0QwwSXrAEcBGtHmpEwEKwVjG8zv/XItOFK1mESsW5IhpIPOCVgpV7xxg8JjCgRSbWX3KWpDzxkBt9jX/PhCEZER0rJOMKLuXqaFgq9Ysktu1PgVeLNSQnNUesVP/2+onHIJFBBjOl4bgTdhGjgVLC04MeGRYSOyZB1LJXELtJNpiem+MwqfTxQ2j4JeKouTiQkNGYSBjaZLWqWvUz8z+vEMLjuJlxGMTBJZx8NYoFB4awv3OeaURATSwjV3O6KqW2FULCtZiV4yyevkuZF2XPL3sNlqXI5ryOPTtApOkceukIVVEU11EAUPaEX9IbenWfn1flwvmbRnDOfOUZ/4Pz8AjjIpJw=</latexit><latexit sha1_base64="MxWXVpnky2NaQ9xampmL8IAHiVw=">AAACInicbVDLSgMxFM3UV62vqks3wSK4KjMiqLuCLgpuKvQFnVIyadqGZpIhuSOUYb7Fjb/ixoWirgQ/xkzbRW09EDiccy659wSR4AZc99vJra1vbG7ltws7u3v7B8XDo6ZRsaasQZVQuh0QwwSXrAEcBGtHmpEwEKwVjG8zv/XItOFK1mESsW5IhpIPOCVgpV7xxg8JjCgRSbWX3KWpDzxkBt9jX/PhCEZER0rJOMKLuXqaFgq9Ysktu1PgVeLNSQnNUesVP/2+onHIJFBBjOl4bgTdhGjgVLC04MeGRYSOyZB1LJXELtJNpiem+MwqfTxQ2j4JeKouTiQkNGYSBjaZLWqWvUz8z+vEMLjuJlxGMTBJZx8NYoFB4awv3OeaURATSwjV3O6KqW2FULCtZiV4yyevkuZF2XPL3sNlqXI5ryOPTtApOkceukIVVEU11EAUPaEX9IbenWfn1flwvmbRnDOfOUZ/4Pz8AjjIpJw=</latexit><latexit sha1_base64="MxWXVpnky2NaQ9xampmL8IAHiVw=">AAACInicbVDLSgMxFM3UV62vqks3wSK4KjMiqLuCLgpuKvQFnVIyadqGZpIhuSOUYb7Fjb/ixoWirgQ/xkzbRW09EDiccy659wSR4AZc99vJra1vbG7ltws7u3v7B8XDo6ZRsaasQZVQuh0QwwSXrAEcBGtHmpEwEKwVjG8zv/XItOFK1mESsW5IhpIPOCVgpV7xxg8JjCgRSbWX3KWpDzxkBt9jX/PhCEZER0rJOMKLuXqaFgq9Ysktu1PgVeLNSQnNUesVP/2+onHIJFBBjOl4bgTdhGjgVLC04MeGRYSOyZB1LJXELtJNpiem+MwqfTxQ2j4JeKouTiQkNGYSBjaZLWqWvUz8z+vEMLjuJlxGMTBJZx8NYoFB4awv3OeaURATSwjV3O6KqW2FULCtZiV4yyevkuZF2XPL3sNlqXI5ryOPTtApOkceukIVVEU11EAUPaEX9IbenWfn1flwvmbRnDOfOUZ/4Pz8AjjIpJw=</latexit><latexit sha1_base64="MxWXVpnky2NaQ9xampmL8IAHiVw=">AAACInicbVDLSgMxFM3UV62vqks3wSK4KjMiqLuCLgpuKvQFnVIyadqGZpIhuSOUYb7Fjb/ixoWirgQ/xkzbRW09EDiccy659wSR4AZc99vJra1vbG7ltws7u3v7B8XDo6ZRsaasQZVQuh0QwwSXrAEcBGtHmpEwEKwVjG8zv/XItOFK1mESsW5IhpIPOCVgpV7xxg8JjCgRSbWX3KWpDzxkBt9jX/PhCEZER0rJOMKLuXqaFgq9Ysktu1PgVeLNSQnNUesVP/2+onHIJFBBjOl4bgTdhGjgVLC04MeGRYSOyZB1LJXELtJNpiem+MwqfTxQ2j4JeKouTiQkNGYSBjaZLWqWvUz8z+vEMLjuJlxGMTBJZx8NYoFB4awv3OeaURATSwjV3O6KqW2FULCtZiV4yyevkuZF2XPL3sNlqXI5ryOPTtApOkceukIVVEU11EAUPaEX9IbenWfn1flwvmbRnDOfOUZ/4Pz8AjjIpJw=</latexit>H⇥K*I<latexit sha1_base64="PmQtcefgS4FXTpt5ACim+B8UBhM=">AAACF3icbVDLSgMxFM3UV62vqks3wSK4KjMi6LLgpuKmgn1AZyiZNG1DM8mQ3BHK0L9w46+4caGIW935N2baQbT1QOBwzrnk3hPGghtw3S+nsLK6tr5R3Cxtbe/s7pX3D1pGJZqyJlVC6U5IDBNcsiZwEKwTa0aiULB2OL7K/PY904YreQeTmAURGUo+4JSAlXrlqh8RGFEi0vrUBx4xg298zYcjGBEdKyWT+CdxPS31yhW36s6Al4mXkwrK0eiVP/2+oknEJFBBjOl6bgxBSjRwKti05CeGxYSOyZB1LZXEbhCks7um+MQqfTxQ2j4JeKb+nkhJZMwkCm0y29Esepn4n9dNYHAZpFzGCTBJ5x8NEoFB4awk3OeaURATSwjV3O6Kqe2DULBVZiV4iycvk9ZZ1XOr3u15pXae11FER+gYnSIPXaAaqqMGaiKKHtATekGvzqPz7Lw57/NowclnDtEfOB/fZTygnw==</latexit><latexit sha1_base64="PmQtcefgS4FXTpt5ACim+B8UBhM=">AAACF3icbVDLSgMxFM3UV62vqks3wSK4KjMi6LLgpuKmgn1AZyiZNG1DM8mQ3BHK0L9w46+4caGIW935N2baQbT1QOBwzrnk3hPGghtw3S+nsLK6tr5R3Cxtbe/s7pX3D1pGJZqyJlVC6U5IDBNcsiZwEKwTa0aiULB2OL7K/PY904YreQeTmAURGUo+4JSAlXrlqh8RGFEi0vrUBx4xg298zYcjGBEdKyWT+CdxPS31yhW36s6Al4mXkwrK0eiVP/2+oknEJFBBjOl6bgxBSjRwKti05CeGxYSOyZB1LZXEbhCks7um+MQqfTxQ2j4JeKb+nkhJZMwkCm0y29Esepn4n9dNYHAZpFzGCTBJ5x8NEoFB4awk3OeaURATSwjV3O6Kqe2DULBVZiV4iycvk9ZZ1XOr3u15pXae11FER+gYnSIPXaAaqqMGaiKKHtATekGvzqPz7Lw57/NowclnDtEfOB/fZTygnw==</latexit><latexit sha1_base64="PmQtcefgS4FXTpt5ACim+B8UBhM=">AAACF3icbVDLSgMxFM3UV62vqks3wSK4KjMi6LLgpuKmgn1AZyiZNG1DM8mQ3BHK0L9w46+4caGIW935N2baQbT1QOBwzrnk3hPGghtw3S+nsLK6tr5R3Cxtbe/s7pX3D1pGJZqyJlVC6U5IDBNcsiZwEKwTa0aiULB2OL7K/PY904YreQeTmAURGUo+4JSAlXrlqh8RGFEi0vrUBx4xg298zYcjGBEdKyWT+CdxPS31yhW36s6Al4mXkwrK0eiVP/2+oknEJFBBjOl6bgxBSjRwKti05CeGxYSOyZB1LZXEbhCks7um+MQqfTxQ2j4JeKb+nkhJZMwkCm0y29Esepn4n9dNYHAZpFzGCTBJ5x8NEoFB4awk3OeaURATSwjV3O6Kqe2DULBVZiV4iycvk9ZZ1XOr3u15pXae11FER+gYnSIPXaAaqqMGaiKKHtATekGvzqPz7Lw57/NowclnDtEfOB/fZTygnw==</latexit><latexit sha1_base64="PmQtcefgS4FXTpt5ACim+B8UBhM=">AAACF3icbVDLSgMxFM3UV62vqks3wSK4KjMi6LLgpuKmgn1AZyiZNG1DM8mQ3BHK0L9w46+4caGIW935N2baQbT1QOBwzrnk3hPGghtw3S+nsLK6tr5R3Cxtbe/s7pX3D1pGJZqyJlVC6U5IDBNcsiZwEKwTa0aiULB2OL7K/PY904YreQeTmAURGUo+4JSAlXrlqh8RGFEi0vrUBx4xg298zYcjGBEdKyWT+CdxPS31yhW36s6Al4mXkwrK0eiVP/2+oknEJFBBjOl6bgxBSjRwKti05CeGxYSOyZB1LZXEbhCks7um+MQqfTxQ2j4JeKb+nkhJZMwkCm0y29Esepn4n9dNYHAZpFzGCTBJ5x8NEoFB4awk3OeaURATSwjV3O6Kqe2DULBVZiV4iycvk9ZZ1XOr3u15pXae11FER+gYnSIPXaAaqqMGaiKKHtATekGvzqPz7Lw57/NowclnDtEfOB/fZTygnw==</latexit>K*HD<latexit sha1_base64="Igkvbr39/FkJO3aIGtRzcoz2KtE=">AAACCXicbVDLSsNAFJ3UV62vqEs3g0VwVRIp6LKgi4KbCvYBTQiT6aQdOpkJMxOhhGzd+CtuXCji1j9w5984abPQ1gMXDufcy733hAmjSjvOt1VZW9/Y3Kpu13Z29/YP7MOjnhKpxKSLBRNyECJFGOWkq6lmZJBIguKQkX44vS78/gORigp+r2cJ8WM05jSiGGkjBTa89SQdT/QEyUQIniZejPQEI5a1g+wmz2uBXXcazhxwlbglqYMSncD+8kYCpzHhGjOk1NB1Eu1nSGqKGclrXqpIgvAUjcnQUI5iovxs/kkOz4wygpGQpriGc/X3RIZipWZxaDqLO9WyV4j/ecNUR1d+RnmSasLxYlGUMqgFLGKBIyoJ1mxmCMKSmlshNpkgrE14RQju8surpHfRcJ2Ge9est5plHFVwAk7BOXDBJWiBNuiALsDgETyDV/BmPVkv1rv1sWitWOXMMfgD6/MHOVqamQ==</latexit><latexit sha1_base64="Igkvbr39/FkJO3aIGtRzcoz2KtE=">AAACCXicbVDLSsNAFJ3UV62vqEs3g0VwVRIp6LKgi4KbCvYBTQiT6aQdOpkJMxOhhGzd+CtuXCji1j9w5984abPQ1gMXDufcy733hAmjSjvOt1VZW9/Y3Kpu13Z29/YP7MOjnhKpxKSLBRNyECJFGOWkq6lmZJBIguKQkX44vS78/gORigp+r2cJ8WM05jSiGGkjBTa89SQdT/QEyUQIniZejPQEI5a1g+wmz2uBXXcazhxwlbglqYMSncD+8kYCpzHhGjOk1NB1Eu1nSGqKGclrXqpIgvAUjcnQUI5iovxs/kkOz4wygpGQpriGc/X3RIZipWZxaDqLO9WyV4j/ecNUR1d+RnmSasLxYlGUMqgFLGKBIyoJ1mxmCMKSmlshNpkgrE14RQju8surpHfRcJ2Ge9est5plHFVwAk7BOXDBJWiBNuiALsDgETyDV/BmPVkv1rv1sWitWOXMMfgD6/MHOVqamQ==</latexit><latexit sha1_base64="Igkvbr39/FkJO3aIGtRzcoz2KtE=">AAACCXicbVDLSsNAFJ3UV62vqEs3g0VwVRIp6LKgi4KbCvYBTQiT6aQdOpkJMxOhhGzd+CtuXCji1j9w5984abPQ1gMXDufcy733hAmjSjvOt1VZW9/Y3Kpu13Z29/YP7MOjnhKpxKSLBRNyECJFGOWkq6lmZJBIguKQkX44vS78/gORigp+r2cJ8WM05jSiGGkjBTa89SQdT/QEyUQIniZejPQEI5a1g+wmz2uBXXcazhxwlbglqYMSncD+8kYCpzHhGjOk1NB1Eu1nSGqKGclrXqpIgvAUjcnQUI5iovxs/kkOz4wygpGQpriGc/X3RIZipWZxaDqLO9WyV4j/ecNUR1d+RnmSasLxYlGUMqgFLGKBIyoJ1mxmCMKSmlshNpkgrE14RQju8surpHfRcJ2Ge9est5plHFVwAk7BOXDBJWiBNuiALsDgETyDV/BmPVkv1rv1sWitWOXMMfgD6/MHOVqamQ==</latexit><latexit sha1_base64="Igkvbr39/FkJO3aIGtRzcoz2KtE=">AAACCXicbVDLSsNAFJ3UV62vqEs3g0VwVRIp6LKgi4KbCvYBTQiT6aQdOpkJMxOhhGzd+CtuXCji1j9w5984abPQ1gMXDufcy733hAmjSjvOt1VZW9/Y3Kpu13Z29/YP7MOjnhKpxKSLBRNyECJFGOWkq6lmZJBIguKQkX44vS78/gORigp+r2cJ8WM05jSiGGkjBTa89SQdT/QEyUQIniZejPQEI5a1g+wmz2uBXXcazhxwlbglqYMSncD+8kYCpzHhGjOk1NB1Eu1nSGqKGclrXqpIgvAUjcnQUI5iovxs/kkOz4wygpGQpriGc/X3RIZipWZxaDqLO9WyV4j/ecNUR1d+RnmSasLxYlGUMqgFLGKBIyoJ1mxmCMKSmlshNpkgrE14RQju8surpHfRcJ2Ge9est5plHFVwAk7BOXDBJWiBNuiALsDgETyDV/BmPVkv1rv1sWitWOXMMfgD6/MHOVqamQ==</latexit> 
 
 
 
 
 
of detection analysis employed—encoding a notion of
detection precision, or conﬁdence level in the hypothesis.
A threat hypothesis embeds the higher-level reasoning
performed by threat hunters, serving as cognitive glue and
trigger for the next step of the hunting process. Examples
of threat hypotheses include propositions about threat
type (e.g., “downloaded binary in clientY is trojanZ”,
“beaconing behavior between hostB and clientX is part of
a C&C protocol”) and impact assessment (e.g., “clients
who accessed hostB’s web server have been infected with
trojanZ”, “trojanZ has spread laterally in the network”).

Action Subspace encodes the space of defense mechanisms
and protective measures available to cyber defendants.
Examples of defense mechanisms include proactive mon-
itoring (e.g., update a sensor’s policy), blocking (e.g.,
updating ﬁrewall rules), statically analysing deployed
software for malware and vulnerabilities [11], sandbox-
ing [13, 12], and deploying deceptive responses across the
software stack [3, 19, 21]. Protective measures include dis-
seminating detection models and policies across endpoints,
and sharing hunting outcomes with partner organizations.

To reduce the impact of false positives, our framework
enriches this decision model with threat intelligence
and domain-speciﬁc information to weed out legitimate
behaviors and identify new attack patterns. Upon
veriﬁcation, each malicious hypothesis elicits a protective
measure harnessed from the action subspace. Our
implementation shows that this model is practical and can
automate hypothesis generation for threat hunting tasks.

2 Cyber Threat Hunting Model
Our cyber threat hunting model (CTHM) conceptualizes
threat detection, analysis, and response as ﬁrst-class
components of the threat hunting process. In this model, a
hunt is the tuple (K,

, ∆, Φ, Ψ, Γ,

), where:

• K = Σ

H

∪ I

A
is a set comprising internal data Σ,
sourced from monitoring and asset management
infrastructures, and intelligence data
, sourced from
external threat intelligence, domain knowledge, or
derived from hypotheses veriﬁed during the threat
hunting process.

I

•

=

HD ∪ HT

is a set comprising detection (
) hypotheses. A hypothesis h

H
HD
and threat (
∈ H
can optionally deﬁne a conﬁdence level, which can be
derived from a detection event or predeﬁned by the
the threat analysis.

HT

)

• ∆ is a set of detectors, comprising threat detection

analyses, δ

∆, δ : K (cid:42)

∈

HD

• Φ is a set of case manifolds, or hypothesis generators,

φ

Φ, φ :

∈

HD ×

K (cid:42)

HT

• Ψ is a set of decision manifolds, ψ

Ψ, ψ :

K (cid:42)

H ×
denotes the action subspace of ψ.

∈

• Γ is a set of hypothesis veriﬁers accepting or rejecting

, where

A

A

hypotheses, γ

Γ, γ :

K (cid:42)

I

H ×

∈

Figure 2: Attack scenario

,

G

· · ·

1(a),
(a) = (
C
, where k

stores the state of a hunt, including
A case graph
the history of executed hunting steps and the outcomes
produced during the execution of a hunt. Hunts and
case graphs are two central concepts in our threat
hunting model, analogous to programs and computation in
traditional programming languages. Similarly, knowledge
and hypotheses compare to abstract data types.
A vector-valued objective cost function

Rk,
k(a)) maintains the cost values
C
associated with the execution of each protective action
1 is the number of cost estimators, which
a
can be derived from context-speciﬁc proxies (e.g., ﬁnancial
losses, liability risks) or computed as intrinsic functions of
the action (e.g., employed resources, analysis time). Since
depends on the environment and can change during
C
]] to denote the cost
the course of a hunt, we write
C
function associated with a given hunt state. This choice of
design for
explicitly models cost as a situation-speciﬁc
and user-speciﬁc concept, and enables the application of
normative (i.e., prescriptive) theories to drive hypothesis
generation in threat hunting scenarios.

A →

∈ A

≥

G

C

C

C

[[

:

Manifold Selection. CTHM enforces that its diﬀerent analy-
sis components (detectors, manifolds, and veriﬁers) operate
on well-deﬁned abstractions (knowledge, hypotheses, ac-
tions) and interfaces. This ensures that hunts are always
consistent by construction—the model doesn’t allow type
mismatches. The choice of candidate manifolds and ac-
tions to be executed therefore reduces to the predeﬁned
semantics of each component, which may involve weighting
uncertainty, costs estimations, and context associated with
the state of the hunt.

Attack Scenario. Figure 2 depicts an attack campaign, which
comprises malware distribution servers and C&C endpoints ( 0 ).
The targeted attack starts with delivering a malicious web link
via a spear phishing tactic ( 1 ). When the victim is tricked to
follow the web link ( 2 ), the attacker’s malicious web server
exploits the browser’s vulnerability to install malware ( 3 ).
Once the malware infects the user’s device, it establishes a
communication channel with a C&C server using DGAs and/or
fast-ﬂuxing techniques ( 4 ). The malware moves laterally
to other devices to locate critical assets in the company
( 5 ). The
network (e.g., by leveraging a zero-day exploit
malware also beacons to a C&C server to report its presence
and receive further instructions ( 6 ), and conducts internal

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

1© 2017 IBM CorporationIBM Confidential | DO NOT DISTRIBUTE2/26/21C&C1Maliciousweb serverC&C20. Setup exploit0. Setup C&C2. Visit3. Exploit5. Lateralmove4. C&C comm6. BeaconingCode repoDatabase7. Access8. ExfiltrateClient1Client21. Spear phisingInternal Σ =

{

endpoints :

clients1−10

{

,

}

Intelligence

I

Hypotheses

=

H

Detectors ∆ =

Cases Φ =

Decisions Ψ =

Veriﬁers Γ =

HTTP/S records, syslogs

}}

monitoring :
c&c :
{
malware :

=

{

{
1.2.3.4

,

}

{

(zeus, 014e7...7bbb)

}}

beacon

D

H
K (cid:42)

}

c&c,malware,

T

H

c&c,malware

}

K (cid:42)

K (cid:42)

A}

malware
accepted ,

T

malware
rejected }

,

T

H

⊥
δbeacon : HTTP/S (cid:42)

beacon

×
K (cid:42)

T

H

×

K (cid:42)

,
A
malware

{

{

{

{

φKGE :

D

H

φimpact :

ψc&c :

T

H

×

c&c

ψmalware :

γf orensics :

γanalytics :

T

H

T

H

T

H

×

malware

×

K (cid:42)

{H

c&c

×

{H

Actions

=

{

A

quarantine, contain, misdirect, fortify, share

c&c
accepted,

T

c&c
rejected}

T

H

}

Figure 3: An initial hunt state for a threat hunting scenario

reconnaissance to identify and gain access to critical assets
(e.g., code repositories) using stolen credentials ( 7 ). Finally,
the malware exﬁltrates sensitive information to an attacker-
controlled remote server ( 8 ).

3 Evidential Threat Hunting Semantics
To illustrate these concepts, let (K, H, ∆, Φ, Ψ, Γ, A)(0) be the
initial hunt state of the threat hunting scenario depicted in
Figure 3. This example describes an attack campaign where
an adversary has successfully compromised a small network
of 10 client endpoints with a customized variant of Zeus [1].
Both network and endpoints are monitored for HTTP/S ﬂows
and system logs. Protective actions available to defenders
include quarantining compromised endpoints to impede threat
propagation across the network, containing and monitoring
suspicious processes into a transparent sandbox, misdirecting
attackers to decoys, actively seeking and hardening vulnerable
targets in the network, and sharing threat information with
partner organizations.

Case Fragment 1: From beaconing to malware detection

The hunt begins when δbeacon observes beaconing behavior
between remote host 1.2.3.4 and client1, resulting in a new
detection hypothesis (step 0 – 1 ).

(K, H, ∆, Φ, Ψ, Γ, A)(0) δbeacon

−−−−−→1

(K, Hi (cid:55)→ H :: beacon(1.2.3.4, client1), ∆, Φ, Ψ, Γ, A)(1)

k = 1 · · · 6, and

A case manifold φKGE explores a cognitive knowledge graph to
generate two threat hypotheses, which predicate that (a) host
1.2.3.4 is a C&C server (step 1 – 2 ), and that (2) client1 is
infected with Zeus (step 2 – 3 ).

(K, Hi, ∆, Φ, Ψ, Γ, A)(1) φKGE−−−−−→1
(K, Hii (cid:55)→ Hi :: c&c(1.2.3.4), ∆, Φ, Ψ, Γ, A)(2)

(K, Hiii (cid:55)→ Hii :: inf ected(client1, zeus), ∆, Φ, Ψ, Γ, A)(3)

φKGE−−−−−→1

To verify these hypotheses, the threat hunter leverages an
automated security analytics tool γanalytics (e.g., a Security
Knowledge Graph) to assert that 1.2.3.4 indeed belongs to
a known C&C server (step 3 – 4 ). Meanwhile, an endpoint
forensics analysis γf orensics reveals that client1 has been
infected by a speciﬁc self-propagating variant of Zeus (step 4 –
5 ). The analyst accepts these threat hypotheses, which become
new knowledge.

(· · · )(3)

γanalytics
−−−−−−−→1(K i (cid:55)→ K :: c&c(1.2.3.4),

Hiv (cid:55)→ Hiii/c&c(1.2.3.4), · · · )(4)

γf orensics
−−−−−−−−→1(K ii (cid:55)→ K i :: inf ected(client1, zeus),

Hv (cid:55)→ Hiv/inf ected(client1, zeus), · · · )(5)

Case Fragment 2: Lateral movement assessment

To assess the scope and impact of this attack campaign, a case
manifold φimpact hypothesizes whether the trojan spreads itself
laterally to other clients in the network (step 5 – 6 ). Using
information acquired in prior hunts about this speciﬁc variant
of Zeus, φimpact gathers a list of all the clients whose system
logs reveal network ﬁle system access from client1 (e.g., SMB),
and performs a forensics analysis on each client to conﬁrm the
propagation of the trojan. The outcome of this analysis reveals
that while client2 has been compromised, no evidence of this
particular variant of Zeus was found in client7 (step 6 – 7 ).

(· · · )(5)

φimpact
−−−−−−→1(K ii, Hvi (cid:55)→ Hv ∪ {inf ected(client2, zeus),

inf ected(client7, zeus)}, · · · )(6)

γf orensics
−−−−−−−−→1(K iii (cid:55)→ K ii :: inf ected(client2, zeus),

Hvii (cid:55)→ Hvi/inf ected(client7, zeus), · · · )(7)

Case Fragment 3: Deployment of protective measures

Following this initial assessment, action manifolds subscribing to
the new facts generated in prior hunt steps start a deliberation
process to decide on the next hunt step. In this case, the
optimality criteria for the decision combine threat hunting
goals set beforehand by the threat hunter, constraints imposed
by the current hunt state G(7), and cost and risk estimations
derived from a simple, yet relevant cost model. For explanatory
precision, let G(7)[[C]] = (C1 · · · C6) denote the cost function
associated with the hunt, where:

Ck : A → {low, moderate, high},






C1 : system downtime
C2 : allocated resources
C3 : analysis time
C4 : defender risk
C5 : threat intel acquisition
C6 : attacker risk






cost estimators.

Risk is encoded as cost estimations, and attack cost estimations
output negative costs. For simplicity, cost valuation results fall
into one of three categorical values: low, moderate, or high.
Table 1 summarizes G(7)[[C]]’s cost valuations and the
manifold deliberation process. Leveraging this analysis, action
manifold ψmalware performs its deliberation over infected
endpoints client1 (a critical asset) and client2 (a crown jewel),

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

Table 1: Cost valuations for

(7)[[

C

G

]] and action deliberation considerations

Type

Action

C1

C2

C3

C4

C5

C6 Deliberation

threat
mitigation

proactive
hunting

quarantine
contain

misdirect
fortify

intelligence

share

(cid:32)
(cid:35)

(cid:35)
(cid:35)

(cid:35)
(cid:35)

(cid:35)
(cid:32)

(cid:35)
(cid:71)(cid:35)

(cid:35)
(cid:35)

(cid:71)(cid:35)
(cid:71)(cid:35)

(cid:32)
(cid:35)

(cid:35)
(cid:71)(cid:35)

(cid:35)
(cid:71)(cid:35)

(cid:35)
(cid:71)(cid:35)

(cid:32)
(cid:71)(cid:35)

key:

(cid:35)
=low

(cid:35)

(cid:35)
=moderate

(cid:35)

(cid:71)(cid:35)
(cid:71)(cid:35)

(cid:71)(cid:35)
(cid:35)
=high
(cid:32)

if target is a crown jewel
if target can’t tolerate downtime

if defender is resource-constrained
if defender is averse to risk

to inform partners

(values in red represent attacker cost)

resulting in the three prescriptive actions to the risk-averse
threat hunter (step 7 – 8 ). Finally, ψc&c shares the newly
uncovered attack campaign information {c&c hunt} with its
organization’s partners (step 8 – 9 ).

(· · · )(7) ψmalware

−−−−−−−→1(K iii, Hvii, · · · , {contain[client1],

quarantine[client2], fortify[decoy1–25]})(8)

ψc&c−−−→1(K iii, Hvii, · · · , {share[ {c&c hunt} ]})(9)

Implementation

4
Threat Hunting Description Language. We imple-
mented a domain-speciﬁc language [17] and data model [20] to
facilitate the creation and execution of complex threat hunting
ﬂows. This Threat Hunting Description Language (THDL)
allows security analysts to uniformly i) express domain knowl-
edge, ii) retrieve observations for further threat hypothesis
development, iii) verify hypotheses against the data, and iv) ex-
ecute decision manifolds (§2). To support sharing and reuse of
hunt ﬂows, the language satisﬁes the following design goals:

• Composability:

larger, more complex hunts with a
compounded eﬀects of decision manifolds can be created
by composition of smaller, simpler hunting steps and
decision manifolds.

• Explainability: each hunt step as well as a collection (code
block) of steps are human-understandable and support
rich visual representations to facilitate quick assimilation
of hunt workﬂows by novice threat hunters.

• Partial updatability: the system minimizes re-execution
and caches partial results when parts of the composed
hunt ﬂows is changed and needs to be re-evaluated.

Automated Reasoning. Our framework also implements a
language runtime and hunt execution pipeline that enables
eﬃcient and scalable hunt execution through automated
reasoning and case prioritization (§2). Hunts and case graphs
form the basis of a threat hunting computation model
that deﬁnes hunt programs orchestrated by the framework.
For each case initiated by detection hypotheses HD ⊆
H, a corresponding hunt program (K, H, ∆, Φ, Ψ, Γ, A) is
instantiated. The framework embodies three main components:
• Semantic steps: The execution of the hunt program emits a
sequence of operational steps called semantic steps (§3). A
semantic step represents a unit of reasoning task in a hunt

analysis. These steps may involve simple case manifold
executions, such as retrieving additional data from diﬀerent
data sources, or performing complex analytics or running
other existing hunt programs.

• Semantic reasoning: To reason about the current case
graph and properly prioritize the execution of the
next semantic step out of many potential steps, our
implementation performs a signal propagation analysis
called signal ﬂow. Signal ﬂow propagates multiple signals
in the case graph representing diﬀerent semantic meanings,
such as relevance and toxicity (badness). The ﬂow of a
signal is inﬂuenced by various factors, such as behavioral,
temporal, and veracity aspects, resulting an annotated
case graph with semantically-relevant hunt paths. By
combining signal ﬂow with a cost and reward strategy, our
framework produces a dynamic and adaptive sequence of
steps guided by the reasoning semantics.

• Hypothesis generation: The framework distills competing
hypotheses, chains hypotheses from multiple case manifolds,
and ranks and summarizes them before reporting to a
human analyst.

Protective Responses. Automated threat responses gen-
erated by our workﬂows (§3) must not allow any proactive
measure to unwittingly be used to attack the network it is
trying to protect. Moreover, such measures must try to identify
all network hosts involved in an attack campaign and quaran-
tine them at once so that no backdoors remain open for the
attacker. To satisfy these constraints, our framework augments
traditional threat responses with deceptive capabilities to antic-
ipate and foil attempted attacks. These deceptive responses
include dynamically sandboxing or terminating attacker ses-
sions [5], implementing ﬁlesystem separation [6, 19], altering
the network topology [18], and embedding decoys into software
applications [3, 2, 4]. Overall, our proactive measures fall into
ﬁve categories: containment (e.g., sandboxing), misdirection
(e.g., deception), quarantine (e.g., isolation), fortiﬁcation (e.g.,
vulnerability scanning), and sharing (e.g., threat reports).

5 Conclusion
This paper conceptualized and outlined the implementation
of an evidential multi-criteria cyber reasoning framework for
threat hunting. We are currently evaluating this framework
with diverse attack scenarios and data to optimize threat
hunting workﬂows in a large security operations center.

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

Acknowledgments
The research reported herein was developed with funding from
the Defense Advanced Research Projects Agency (DARPA)
under the U.S. ACC-APG/DARPA award W912CG-19-C-
0003. The views, opinions and/or ﬁndings expressed are those
of the author and should not be interpreted as representing
the oﬃcial views or policies of the Department of Defense or
the U.S. Government. The U.S. Government is authorized to
reproduce and distribute reprints for Government purposes
notwithstanding any copyright notation hereon. Approved for
Public Release, Distribution Unlimited.

References

[1] Zeus Trojan. https://www.avast.com/c-zeus/, 2017.

Acces. March 1, 2021.

[2] F. Araujo, G. Ayoade, K. Al-Naami, Y. Gao, K. W. Hamlen,
and L. Khan. Improving intrusion detectors by crook-
sourcing. In Procceedings of the 35th Annual Computer
Security Applications Conference (ACSAC), pages 245–256,
2019.

[3] F. Araujo, K. W. Hamlen, S. Biedermann, and S. Katzen-
beisser. From patches to honey-patches: Lightweight
attacker misdirection, deception, and disinformation. In
Proceedings of the ACM SIGSAC Conference on Computer
and Communications Security (CCS), 2014.

[4] F. Araujo, S. Sengupta, J. Jang, A. Doup´e, K. Hamlen, and
S. Kambhampati. Software deception steering through
version emulation. In Proceedings of the 54th Hawaii
International Conference on System Sciences, 2021.
[5] F. Araujo and T. Taylor. Improving cybersecurity hygiene
through JIT patching. In ACM Joint Meeting on European
Software Engineering Conference and Symposium on the
Foundations of Software Engineering, 2020.

[6] F. Araujo, T. Taylor, J. Zhang, and M. Stoecklin. Cross-
stack threat sensing for cyber security and resilience. In
Proceedings of the IEEE/IFIP International Conference on
Dependable Systems and Networks Workshops (DSN-W),
2018.

[7] X. Han, T. Pasquier, A. Bates, J. Mickens, and M. Seltzer.
Unicorn: Runtime provenance-based detector for advanced
persistent threats. In Network and Distributed Systems
Security Symposium (NDSS), 2020.

[8] W. U. Hassan, A. Bates, and D. Marino. Tactical provenance
analysis for endpoint detection and response systems. In
IEEE Symposium on Security and Privacy (SP). IEEE,
2020.

[9] W. U. Hassan, S. Guo, D. Li, Z. Chen, K. Jee, Z. Li, and
A. Bates. Nodoze: Combatting threat alert fatigue with

automated provenance triage. In Network and Distributed
Systems Security Symposium, 2019.

[10] M. N. Hossain, S. M. Milajerdi, J. Wang, B. Eshete,
R. Gjomemo, R. Sekar, S. Stoller, and V. Venkatakrishnan.
SLEUTH: Real-time attack scenario reconstruction from
COTS audit data. In USENIX Security Symposium, 2017.
[11] J. Jang, A. Agrawal, and D. Brumley. ReDeBug: Finding
Unpatched Code Clones in Entire OS Distributions. In
IEEE Symposium on Security and Privacy (SP), 2012.
[12] D. Kirat and G. Vigna. MalGene: Automatic Extraction of
Malware Analysis Evasion Signature. In Proceedings
of the ACM SIGSAC Conference on Computer and
Communications Security (CCS), 2015.

[13] D. Kirat, G. Vigna, and C. Kruegel. BareCloud: Bare-
metal Analysis-based Evasive Malware Detection. In
USENIX Security Symposium, 2014.

[14] D. Kirsh. A few thoughts on cognitive overload. Intellectica,

1(30):19–51, 2000.

[15] V. G. Li, M. Dunn, P. Pearce, D. McCoy, G. M. Voelker, and
S. Savage. Reading the tea leaves: A comparative analysis
of threat intelligence. In USENIX Security Symposium,
2019.

[16] S. M. Milajerdi, R. Gjomemo, B. Eshete, R. Sekar, and
V. Venkatakrishnan. Holmes: real-time apt detection
through correlation of suspicious information ﬂows. In
IEEE Symposium on Security and Privacy (SP), 2019.
[17] X. Shu, F. Araujo, D. L. Schales, M. P. Stoecklin,
J. Jang, H. Huang, and J. R. Rao. Threat intelligence
computing. In ACM SIGSAC Conference on Computer
and Communications Security (CCS), 2018.

[18] M. P. Stoecklin, J. Zhang, F. Araujo, and T. Taylor.
Dressed up: Baiting attackers through endpoint service
projection. In Proceedings of the ACM International
Workshop on Security in Software Deﬁned Networks &
Network Function Virtualization (SDN-NFV), 2018.

[19] T. Taylor, F. Araujo, A. Kohlbrenner, and M. P. Stoecklin.
Hidden in plain sight: Filesystem view separation for data
integrity and deception. In Proceedings of the Conference
on Detection of Intrusions and Malware, and Vulnerability
Assessment (DIMVA), 2018.

[20] T. Taylor, F. Araujo, and X. Shu. Towards an open format
for scalable system telemetry. In Proceedings of the IEEE
International Conference on Big Data, 2020.

[21] J. Zhang, Z. Gu, J. Jang, D. Kirat, M. P. Stoecklin, X. Shu,
and H. Huang. Scarecrow: Deactivating evasive malware
via its own evasive logic. In Proceedings of the IEEE/IFIP
International Conference on Dependable Systems and
Networks (DSN), 2020.

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

