4
1
0
2

g
u
A
1
1

]
S
D
.
s
c
[

1
v
0
5
3
2
.
8
0
4
1
:
v
i
X
r
a

Dictionary Matching with One Gap(cid:63)

Amihood Amir1,2,(cid:63)(cid:63), Avivit Levy3, Ely Porat1, and B. Riva Shalom3

1 Department of Computer Science, Bar-Ilan University, Ramat-Gan 52900, Israel.
E-mail: {amir, porately}@cs.biu.ac.il
2 Department of Computer Science, Johns Hopkins University, Baltimore, MD 21218.
3 Department of Software Engineering, Shenkar College, Ramat-Gan 52526, Israel.
Email: {avivitlevy, rivash}@shenkar.ac.il

Abstract. The dictionary matching with gaps problem is to prepro-
cess a dictionary D of d gapped patterns P1, . . . , Pd over alphabet Σ,
where each gapped pattern Pi is a sequence of subpatterns separated by
bounded sequences of don’t cares. Then, given a query text T of length n
over alphabet Σ, the goal is to output all locations in T in which a pat-
tern Pi ∈ D, 1 ≤ i ≤ d, ends. There is a renewed current interest in the
gapped matching problem stemming from cyber security. In this paper we
solve the problem where all patterns in the dictionary have one gap with
at least α and at most β don’t cares, where α and β are given parameters.
Speciﬁcally, we show that the dictionary matching with a single gap prob-
lem can be solved in either O(d log d + |D|) time and O(d logε d + |D|)
space, and query time O(n(β − α) log log d log2 min{d, log |D|} + occ),
where occ is the number of patterns found, or preprocessing time and
space: O(d2 + |D|), and query time O(n(β − α) + occ), where occ is the
number of patterns found. As far as we know, this is the best solution
for this setting of the problem, where many overlaps may exist in the
dictionary.

1

Introduction

Pattern matching has been historically one of the key areas of computer science.
It contributed many important algorithms and data structures that made their
way to textbooks, but its strength is that it has been contributing to applied
areas, from text searching and web searching, through computational biology
and to cyber security. One of the important variants of pattern matching is
pattern matching with variable length gaps. The problem is formally deﬁned
below.

Deﬁnition 1. Gapped Pattern
A Gapped Pattern is a pattern P of the form p1 {α1, β1} p2 {α2, β2} . . . {αk−1, βk−1} pk,
where each subpattern pj, 1 ≤ j ≤ k is a string over alphabet Σ, and

(cid:63) This research was supported by the Kabarnit Cyber consortium funded by the Chief

Scientist in the Israeli Ministry of Economy under the Magnet Program.

(cid:63)(cid:63) Partly supported by NSF grant CCR-09-04581, ISF grant 347/09, and BSF grant

2008217.

 
 
 
 
 
 
{αj, βj} refers to a sequence of at least αj and at most βj don’t cares
between the subpatterns Pj and Pj+1.

Deﬁnition 2. The Gapped Pattern Matching Problem:
Input: A text T of length n, and a gapped pattern P over alphabet Σ
Output: All locations in T , where the pattern P ends.

The problem arose a few decades ago by real needs in computational biology
applications [20,12,22,14]. For example, the PROSITE database [14] supports
queries for proteins speciﬁed by gaps.

The problem has been well researched and many solutions proposed. The
ﬁrst type of solutions [7,19,23] consider the problem as a special case of regular
expression. The best time achieved using this method is O(n(B|Σ| + m)), where
n is the text length, B = (cid:80)k
i=1 βi (the sum of the upper bounds of the gaps),
and m = (cid:80)k

i=1 pi (the length of the non-gapped part of the pattern).
Naturally, a direct solution of the gapped pattern matching problem should
have a better time complexity. Indeed, such a solution exists [8] whose time is
essentially O(nk).

A further improvement [18,24,6] analyses the time as a function of socc, which
is the number of times all segments pi of the gapped pattern appear in the text.
Clearly socc ≤ nk.

Rahman et al. [24] suggest two algorithms for this problem. In the ﬁrst, they
build an Aho-Corasick [1] pattern matching machine from all the subpatterns
and use it to go over the text. Validation of subpatterns appearances with re-
spect to the limits of the gaps is performed using binary search over previous
subpatterns locations. Their second algorithm uses a suﬃx array built over the
text to locate occurrences of all subpatterns. For the validation of occurrences
of subpattern, they use Van Emde Boas data structure [26] containing ending
positions of previous occurrences. In order to report occurrences of the gapped
pattern in both algorithms, they build a graph representing legal appearances
of consecutive subpatterns. Traversing the graph yields all possible appearances
of the pattern.

Their ﬁrst algorithm works in time O(n + m + socc log(maxj gapj)) where m
is the length of the pattern (not including the gaps), socc is the total number
of occurrences of the subpatterns in the text and gapj = βj − αj. The time
requirements of their second algorithm is O(n + m + socc log log n) where n is
the length of the text, m is the length of the pattern (not including the gaps) and
socc is the total number of occurrences of the subpatterns in the text. The DFS
traversal on the subpatterns occurrences graph, reporting all the occurrences is
done in O(k ·occ) where occ is the number of occurrences of the complete pattern
P in the text.

Bille et al. [6] also consider string matching with variable length gaps. They
present an algorithm using sorted lists of disjoint intervals, after traversing the
text with Aho-Corasick automaton. Their time complexity is O(n log k+m+socc)
and space O(m + A), where A is the sum of the lower bounds of the lengths of

the gaps in the pattern P and socc is the total number of occurrences of the
substrings in P within T .

Kucherov and Rusinowitch [16] and Zhang et al. [29] solved the problem of
matching a set of patterns with variable length of don’t cares. They considered
the question of determining whether one of the patterns of the set matches
the text and report a leftmost occurrence of a pattern if there exists one. The
algorithm of [16] has run time of O((|t|+|D|) log |P |), where |D| is the total length
of keywords in every pattern of the dictionary D. The algorithm of [29] takes
O((|t| + dk) log dis/ log log dis) time, where dk is the total number of keywords
in every pattern of P , and dis is the number of distinct keywords in D.

There is a renewed current interest in the gapped matching problem stem-
ming from a crucial modern concern - cyber security. Network intrusion detection
systems perform protocol analysis, content searching and content matching, in
order to detect harmful software. Such malware may appear on several packets,
and thus the need for gapped matching [15]. However, the problem becomes
more complex since there is a large list of such gapped patterns that all need to
be detected. This list is called a dictionary. Dictionary matching has been amply
researched in computer science (see e.g. [1,4,3,9,5,2,10]). We are concerned with
a new dictionary matching paradigm - dictionary matching with gaps. Formally:

Deﬁnition 3. The Dictionary Matching with gaps (DM G) Problem:
Input: A text T of length n over alphabet Σ and a dictionary D over
alphabet Σ consisting of d gapped patterns P1, . . . , Pd.

Output: All locations in T , where a pattern Pi, for 1 ≤ i ≤ d ends.

The DM G problem has not been suﬃciently studied yet. Haapasalo et al. [13]
give an on-line algorithm for the general problem. Their algorithm is based on
locating “keywords” of the patterns in the input text, that is, maximal sub-
strings of the patterns that contain only input characters. Matches of preﬁxes of
patterns are collected from the keyword matches, and when a preﬁx constitut-
ing a complete pattern is found, a match is reported. In collecting these partial
matches they avoid locating those keyword occurrences that cannot participate
in any preﬁx of a pattern found thus far. Their experiments show that this al-
gorithm scales up well, when the number of patterns increases. They report at
most one occurrence for each pattern at each text position. The time required
for their algorithm is O(n · SU F + occ · P REF ), where n is the size of the text,
SU F is the maximal number of suﬃxes of a keyword that are also keywords,
and P REF denotes the number of occurrences in the text of pattern preﬁxes
ending with a keyword.

Nevertheless, more research on this problem is needed. First, in many appli-
cations it is necessary to report all patterns appearances. Moreover, as far as we
know [27], these Aho-Corasick automaton based methods fail when applied to
real data security, which contain many overlaps in the dictionary patterns, due
to overhead in the computation when run on several ports in parallel. Therefore,
other methods should be developed and combined with the existing ones in order
to design eﬃcient practical solutions.

Results. In this paper, we indeed suggest other directions for solving the prob-
lem. We focus on the DM G problem where the gapped patterns in the dictionary
D have only a single gap, i.e., we consider the case of k = 1 implying each pat-
tern Pi consists of two subpatterns Pi,1, Pi,2. In addition, we consider the same
gaps limits, α and β, apply to all patterns in Pi ∈ D, 1 ≤ i ≤ d. We prove:

Theorem 1. The dictionary matching with a single gap problem can be solved
in:

1. Preprocessing time: O(d log d + |D|).

Space: O(d logε d + |D|), for arbitrary small ε.
Query time: O(n(β − α) log log d log2 min{d, log |D|} + occ), where occ is the
number of patterns found.

2. Preprocessing time: O(d2 + |D|).

Space: O(d2 + |D|).
Query time: O(n(β − α) + occ), where occ is the number of patterns found.

Note that, |D| is the sum of lengths of all patterns in the dictionary, not including
the gaps sizes.

The paper is organized as follows. In Sect. 2 we describe our basic method
based on suﬃx trees and prove the ﬁrst part of Theorem 1. In Sect. 3 we describe
how this algorithm query time can be improved while doing more work in the
preprocessing time and prove the second part of Theorem 1. We also discuss
eﬃcient implementations of both algorithms using text splitting in Subsect. 3.1.
Section 4 concludes the paper and poses some open problems.

2 Bidirectional Suﬃx Trees Algorithm

The basic observation used by our algorithm is that if a gapped pattern Pi
appears in T , then searching to the left from the start position of the gap we
should ﬁnd the reverse of the preﬁx Pi,1, and searching to the right from the
end position of the gap we should ﬁnd the suﬃx Pi,2. A similar observation
was used by Amir et al. [5] to solve the dictionary matching with one mismatch
problem. Their problem is diﬀerent from the DM G problem, since they consider
a single mismatch while in our problem a gap may consist of several symbols.
Moreover, a mismatch symbol appears both in the dictionary pattern and in the
text, while in the DM G problem the gap implies skipping symbols only in the
text. Nevertheless, we show that their idea can also be adopted to the solve the
DM G problem.

Amir et al. [5] use two suﬃx trees: one for the concatenation of the dictionary
and the other for the reverse of the concatenation of the dictionary. Combining
this with set intersection on tree paths, they solved the dictionary matching
with one mismatch problem in time O(n log2.5 |D| + occ) where n is the length
of the text, |D| is the sum of the lengths of the dictionary patterns, and occ is
the number of occurrences of patterns in the text. Their preprocessing requires
O(|D|log|D|). We use the idea to design an algorithm to the DM G problem.

A naive method is to consider matching the preﬁxes Pi,1 for all 1 ≤ i ≤ d,
and then look for the suﬃxes subpatterns Pi,2, 1 ≤ i ≤ d, after the appropriate
gap and intersect the occurrences to report the dictionary patterns matchings.
However, as some of the patterns may share subpatterns and some subpatterns
may include other subpatterns, there may be several distinct subpatterns occur-
ring at the same text location, each of diﬀerent length. Therefore, we need to
search for the suﬃxes Pi,2, 1 ≤ i ≤ d, after several gaps, each beginning at the
end of a matched preﬁx Pi,1, 1 ≤ i ≤ d. To avoid multiple searches we search all
subpatterns Pi,1, 1 ≤ i ≤ d that end at a certain location. Note that in order to
ﬁnd all subpatterns ending at a certain location of the text we need to look for
them backwards and ﬁnd their reverse P R
i,1.
In the preprocessing stage we concatenate the subpatterns Pi,2, 1 ≤ i ≤ d
of the dictionary separated by the symbol $ /∈ Σ to form a single string S. We
repeat the procedure for the subpatterns Pi,1, 1 ≤ i ≤ d, to form a single string
F . We construct a suﬃx tree TS of the string S, and another suﬃx tree TF R of
the string F R, which is the reverse of the string F .

We then traverse the text by inserting suﬃxes of the text to the TS suﬃx tree.
When we pass the node of TS for which the path from the root is labeled Pi,2,
it implies that this subpattern occurs in the text starting from the beginning of
the text suﬃx. We then should ﬁnd whether Pi,1 also appears in the text within
the appropriate gap from the occurrences of the Pi,2 subpatterns. To this end,
we go backward in the text skipping as many locations as the gap requires and
inserting the reversed preﬁx of the text to TF R . If a node representing Pi,1 is
encountered, we can output that Pi appears in the text.

Note that several dictionary subpatterns representative nodes may be en-
countered while traversing the trees. Therefore, we should report the intersec-
tion between the subpatterns found from each traversal. We do that by eﬃcient
intersection of labels on tree paths, as done in Amir et al. [5], using range queries
on a grid. However, since some patterns may share subpatterns, we do not la-
bel the tree nodes by the original subpatterns they represent, as done in [5].
Instead, we mark the nodes representing subpatterns numerically in a certain
order, hereafter discussed, regardless to the origin of the subpatterns ending at
those nodes.

In order to be able to trace the identity of the patterns from the nodes
marking, we keep two arrays AF and AS, both of size d. The arrays contain
linked lists that identify when subpatterns are shared among several dictionary
patterns. These arrays are ﬁlled as follows: AF [g] = i if P R
i,1 is represented by
node labelled g in TF R and AS[h] = i if Pi,2 is represented by the node labelled
by h in TS. In addition, AF [g] is linked to h and vice versa, if g, h represent two
subpatterns of the same pattern of the dictionary.

Every pattern Pi is represented as a point i on a grid of size d×d, denoted by
< g, AF [g].link >, that is, the x-coordinate is the mark of the node representing
P R
i,1 in TF R , and the y-coordinate is the mark of the node representing Pi,2 in TS.
Now, if we mark the nodes representing the end of subpatterns so that the marks
on a path are consecutive numbers, then the problem of intersection of labels

on tree paths can be reduced to range queries on a grid in the following way.
Let the ﬁrst and last mark on the relevant path in TF R be g, g(cid:48) and, similarly,
on the path in TS let the ﬁrst and last mark be h, h(cid:48). Thus, points < x, y > on
the grid where g ≤ x ≤ g(cid:48) and h ≤ y ≤ h(cid:48), represent patterns in the dictionary
for which both subpatterns appear at the current check. A range query can be
solved using the algorithm of [11].

We use the decomposition of a tree into vertical path for the nodes marking,
suggested by [5], though we use it diﬀerently. A vertical path is deﬁned as follows.

Deﬁnition 4. [5] A vertical path of a tree is a tree path (possibly consisting of
a single node) where no two nodes on the path are of the same height.

After performing the decomposition, we can traverse the vertical paths and mark
by consecutive order all tree nodes representing the end of a certain subpattern
appearing in TS or its reverse appearing in TF R . Since some subpatterns may
be shared by several dictionary patterns, there are at most d marked nodes at
each of the suﬃxes trees.

Note that due to the deﬁnition of vertical path there may be several vertical
paths that have a non empty intersection with the unique path from the root
to a speciﬁc node. Hence, when considering the intersection of marked nodes on
the path from the root till a certain node marked by g in TF R and the marked
nodes on the path from the root till a node marked by h in TS, we actually need
to check the intersection of all vertical paths that are included in the path from
the root to g with all vertical paths that are included in the path from the root
to h.

The algorithm appears in Figure 1.

Lemma 1. The intersection between the subpatterns appearing at location t(cid:96) and
the reversed subpatterns ending at t(cid:96)−gap−1 can be computed in time O(occ +
log log d log2 min{d, log |D|}), where occ is the number of patterns found. The
preprocessing requires O(|D| + d log d) time and O(|D| + d logε d) space, for ar-
bitrary small ε.

At each of the O(n) relevant locations of the text, the algorithm inserts the
current suﬃx of the text to TS using Weiner’s algorithm [28]. For each of the
preﬁxes deﬁned by all β − α + 1 possible speciﬁc gaps we insert its reverse to
TF R . As explained in [5], the navigation on the suﬃx tree and reverse suﬃx
tree can be done in amortized O(1) time per character insertion. Note that each
character is inserted to TS once and to TF R O(β − α) times. This concludes the
proof of the ﬁrst part of Theorem 1.

3

Intersection by Lookup Table

If a very fast query time is crucial and we are willing to pay in preprocessing time,
we can solve the problem of intersection between the appearances of subpatterns
on the paths of TF R , TS using a lookup table.

Single Gap Dictionary (T, D )
Preprocessing:

F = P1,1$P2,1$ · · · Pd,1.
S = P1,2$P2,2$ · · · Pd,2.
TS ← a suﬃx tree of S.
TF R ← a suﬃx tree of the F R.

1
2
3
4
5 For every edge (u, v) ∈ {TS, TF R } with label y$z, where y, z ∈ Σ∗
6
7 Decompose TF R into vertical paths.
8 Mark the nodes representing Pi,1 on the vertical paths of TF R .
9 Decompose TS into vertical paths.
10 Mark the nodes representing Pi,2 on the vertical paths of TS.
11 Preprocess the points according to the patterns for range queries.

Break (u, v) into (u, w) and (w, v) labelling (u, w) with y and (w, v) with $z.

Query:

Insert t(cid:96)t(cid:96)+1 . . . tn to TS.
h ← node in TS representing suﬃx t(cid:96)t(cid:96)+1 . . . tn.
For f = (cid:96) − α − 1 to (cid:96) − β − 1
Insert tf tf −1 . . . t1 to TF R .
g ← node in TF R representing tf tf −1 . . . t1.
For every vertical path on the the path p from the root to h
For every vertical path p(cid:48) on the path from the root to g

12 For (cid:96) = mini{|Pi,1|} + α to n
13
14
15
16
17
18
19
20
21

Perform a range query on a grid with the ﬁrst and last marks of p and p(cid:48)
Report appearance for every Pi where point i appears in the speciﬁed range.

Fig. 1. Dictionary matching with a single gap algorithm, intersection is computed by
range queries on a grid.

The inter table is of size d × d, where inter[g, h] refers to the set of all indices
i of patterns Pi such that P R
i,1 appears on the path from the root of TF R till the
node marked by g and Pi,2 appears on the path from the root of TS till the
node marked by h. We ﬁll the table using dynamic programming procedure.
Consequentially, labelling the nodes representing subpatterns, can be done by
any numbering system, guaranteeing that nodes closer to the root are labelled
by smaller numbers than nodes farther from the root, such as the BFS order.

Saving at every entry all the relevant pattern indices causes redundancy in
case subpatterns include others as their preﬁx or suﬃx. In order to save every
possible occurrence only once, we save pattern index i only at entry inter[g, h]
where g, h are the nodes respectively representing both subpatterns of Pi in the
suﬃx trees. Note that at most one index can be saved at inter[g, h].index as
two patterns are bound to diﬀer by at least one subpattern. The ﬁlling of these
d ﬁelds is done in the preprocessing.

We hereafter prove that besides the index ﬁeld, merely 3 links are required

for every inter[g, h] :

1. A link to inter[g(cid:48), h] in case node h represents subpattern Pi,2 and g(cid:48) is the
maximal labelled ancestor of node g, representing Pi,1. We call this link an
up link.

2. A link to cell inter[g, h(cid:48)] in case node g represents the subpattern Pi,1 and
h(cid:48) is the maximal labelled ancestor of node h representing Pi,2. We call this
link a lef t link.

3. A link to cell [prev∗(g), prev∗(h)], where prev∗(g) and prev∗(h) are the clos-
est marked ancestors of the nodes marked by g and h where inter[prev∗(g),
prev∗(h)] has a pattern index or non null up or lef t link.

The recursive rule for constructing the lookup table is described in the fol-

lowing lemma.

Lemma 2. The Recursive Rule
Let prev(x) be the maximal labelled ancestor of the node labelled by x.

inter[g, h].up =

(cid:26) [prev(g), h]

inter[prev(g), h].up

if inter[prev(g), h].index (cid:54)= null
otherwise

inter[g, h].lef t =

(cid:26) [g, prev(h)]

if inter[g, prev(h)].index (cid:54)= null

inter[g, prev(h)].lef t

otherwise

inter[g, h].prev =






[prev(g), prev(g)]

if inter[prev(g), prev(h)].index (cid:54)= null
or inter[prev(g), prev(h)].up (cid:54)= null
or inter[prev(g), prev(h)].lef t (cid:54)= null

inter[prev(g), prev(g)].prev otherwise

Proof. Every inter[g, h] entry for 1 ≤ g, h ≤ d, has to contain links to all entries
containing indices of patterns whose ﬁrst subpattern is represented by node g or
its ancestors in TF R and its second subpattern is represented by node h or its
ancestors in TS. Assume, without loss of generality, that the marks on the path
from the root of TF R till the node marked by g are g(cid:48)
a, g and the marks
on the path from the root of TS till the node marked by h are h(cid:48)
1, h(cid:48)
b, h.
There are four cases of relevant entries, for each we prove the correctness of the
recursive rule.

2, ...h(cid:48)

2, ...g(cid:48)

1, g(cid:48)

1. Case 1: In case the pair of labels < g, h > represent pattern Pi, then assygn

inter[g, h].index by i in the preprocess. No recursion is required.

2. Case 2: Some {g(cid:48)

x} represent the reverse of ﬁrst subpattern of some dictionary
patterns (as theses subpatterns include others as their suﬃxes), and these
patterns share the second subpattern where h represent this second subpat-
tern. In such a case inter[g, h] should be linked to all entries {inter[g(cid:48)
x, h]}.
Nevertheless, saving a link to the ancestor node with maximal label, is suf-
ﬁcient, since all other relevant patterns can be reached by recursively fol-
lowing up links starting from inter[g(cid:48)
x, h]. Therefore, we consider prev(g)
as the maximal labeled ancestor and if inter[prev(g), h] includes an index,
we assign up with [prev(g), h]. Otherwise we are seeking the same ances-
tor inter[prev(g), h] looked for, for its up link, hence we assign up with
inter[prev(g), h].up.

3. Case 3: Some {h(cid:48)

y} represent the second subpattern of some dictionary pat-
terns (as theses subpatterns include others as their preﬁxes), and these pat-
terns share the ﬁrst subpattern where g represent the reverse of this ﬁrst
subpattern. Due to similar arguments we assign the lef t link either with
[g, prev(h)] or with inter[g, prev(h)].lef t.

4. Case 4: Some ancestors of nodes g and h represent both subpatterns of dictio-
nary patterns. Note that it must be ancestors to both nodes as the previous
cases dealt with representations of patterns using the nodes g or h them-
selves. We need to enable inter[g, h] to follow all such entries, to this end we
look for the closest such ancestors. We check whether inter[prev(g), prev(h)]
includes an index or an up or lef t link. If it does, link the prev link to
[prev(g), prev(h)]. If it does not, it means that no pattern is represented
either by node prev(g) and a node on the path from the root of TS till
node prev(h) or by a node on the path from the root of TSR till node
prev(g) and the node prev(h). Therefore we can step back in both pathes
of the trees to prev(prev(g)) and prev(prev(h)). Such a scenario can re-
peat, yet inter[prev(g), prev(h)].prev which is [prev∗(g), prev∗(h)], was al-
ready computed, due to the numbering system, and the relevant informa-
tion is bound to appear at that entry, so we can follow it by assigning
prev = inter[prev(g), prev(h)].prev.

Example. An example of using the recursive rule, ﬁlling the inter table can be
seen in Figure 3 for the trees depicted in Figure 2 and the following dictionary.
P1 =< 3, 9 >, P2 =< 3, 5 >, P3 =< 2, 9 >, P4 =< 2, 7 >, P5 =< 1, 2 >,
P6 =< 1, 5 >, P7 =< 4, 1 >, P8 =< 3, 4 >, P9 =< 2, 3 >, P10 =< 4, 8 >.
Note the dashed prev arrow from inter[3, 8] to inter[1, 5], due to the lack of
information in inter[2, 6], which is the entry of the immediate ancestors of [3, 8].

Lemma 3 gives the preprocessing time and space guarantee.

Lemma 3. Preprocessing to build the inter table r equires O(|D| + d2) time.

Proof. The preprocess requires labelling both suﬃx trees in BFS order all in
O(|D|). Filling d inter[g, h] entries with the index of the pattern the nodes g, h
represent can be done in at most O(d2).

Filling each of the d2 entries of the table inter[g, h] can be performed in O(1)

due to Lemma 2.

Answering LookUp Queries. A query of a node g from TF R and node h
from TS is answered by consulting entry inter[g, h]. We output inter[g, h].index
if exists which means there is a pattern whose ﬁrst subpattern is represented by
node g and its second aubpattern is represented by node h. In order to report
all relevant patterns, that their subpatterns are represented by g or its ancestors
and by h or its ancestors in the suﬃx trees, we follow the links saved at the
current entry, as detailed in the procedure appearing at Figure 4.

Lemma 4 gives the query time guarantee.

Fig. 2. Two suﬃx trees are shown, where the nodes representing subpatterns are
marked by numerical labels.

Fig. 3. The lookup table built according to the trees depicted in Figure 2. The arrows
represent the prev links.

7 1 2 5 9 3 4 6 8 1 2 3 4 TS TFR 9 8 7 6 5 4 3 2 1 g \ h up = --  l  =[1,5]  up = --  l  =[1,5]  up = --  l  =[1,5]  up = --  l  =[1,5]  up = --  l  = [1,2] Indx = 6 up = --  l = [1,2]  up = --  l  = [1,2]  up =  -- l     =  -- indx = 5 up =  -- l     =  -- 1  up = --  l  = [2,7] Indx = 3  up = -- l  = --    up = --  l     = -- Indx = 4  up = -- l     = --   up =[1,5] l  = --  up = --  l     = --   up =  -- l     =  -- indx = 9  up =[1,2] l     =  --   up =  -- l     =  --  2  up=[2,9] l   = [3,5] Indx = 1  up = -- l  = [3,5]    up =[2,7] l   = [3,5]    up = -- l  =[3,5]    up =[1,5] l     = -- indx = 2  up = -- l     = -- indx = 8  up =[2,3] l  = --  up =[1,2] l     =  --   up =  -- l     =  --  3  up=[3,9] l  =  [4,1]  up = -- l  = [4,1] indx =10  up=[2,7] l  =  [4,1]    up = -- l  = [4,1]   up =[3,5] l   = [4,1]   up=[3,4] l  = [4,1]   up =[2,3] l   = [4,1]   up =[1,2] l    = [4,1]   up =  -- l     =  -- indx =7 4 LookupQuery( g, h )

1
2

3
4
5

6
7
8
9
10

11
12
13
14

If inter[g, h].index (cid:54)= null

Output inter[g, h].index

If inter[g, h].prev (cid:54)= null

Let [g(cid:48), h(cid:48)] ← inter[g, h].prev.
LookupQuery( g’, h’ )

Let G ← g.
While (inter[g, h].up (cid:54)= null ).
Let [g(cid:48), h] ← inter[g, h].up.
Output inter[g(cid:48), h].index
g ← g(cid:48).

While (inter[G, h].lef t (cid:54)= null).
Let [G, h(cid:48)] ← inter[G, h].lef t.
Output inter[G, h(cid:48)].index
h ← h(cid:48).

Fig. 4. The Lookup Query Procedure

Lemma 4. Using the inter table, the intersection between the subpatterns ap-
pearing at location t(cid:96) and the reversed subpatterns ending at t(cid:96)−gap−1 can be
computed in time O(occ), where occ is the number of patterns found.

Proof. The query procedure is based on following links and reporting indices
found. Every step of following an up or lef t link implies that another pattern is
reported, as those links connect two subpatterns including one another, where
both should be reported. The prev link either directs us to an entry including
a pattern index, needs to be reported or it directs us to an entry with an up or
lef t links hence, by following at most two links we encounter an index needed
to be reported. Consequently, the time of following links is attributed to the size
of the output.

As the Lookup Query procedure can replace the intersection by range queries,
which is executed n(β −α) times, Lemma 4 proves the second part of Theorem 1.

3.1 Splitting the Text

Usually, the input text is very long and arrives on-line. This makes the query
algorithm requirement to insert all suﬃxes of the text unreasonable. Transform-
ing this algorithm into an online algorithm seems a diﬃcult problem. The main
diﬃculty is working with on-line suﬃx trees construction in a sliding window.
While useful constructions based on Ukkonen’s [25] and McCgright’s [17] suﬃx

trees constructions exist (see [21]), no such results are known for Weiner’s suﬃx
tree construction, which our reversed preﬁxes tree construction depends on.

(cid:80)

Nevertheless, we do not need to know the whole text in advance and we
can process only separate chunks of it each time. To do this we take m =
β − α + maxi
j |Pi,j| and split the text twice to pieces of size 2m: ﬁrst starting
form the beginning of the text and the second starting after m symbols. We then
apply the algorithms for a single gap or k-gaps for each of the pieces separately
for both text splits. Note that any appearance of a dictionary pattern can still
be found by the algorithms on the splitted text.

4 Conclusions and Open Problems

We showed that combinatorial string methods other than Aho-Corasick automa-
ton can be applied to the DM G problem to yield eﬃcient algorithms. In this
paper we focused on solving DM G, where a single gap exists in all patterns in
the dictionary. We also relaxed the problem so that all patterns in the dictionary
have the same gap bounds. It is an interesting open problem to study the general
problem without these relaxations.

References

1. A.V. Aho and M.J. Corasick. Eﬃcient string matching: an aid to bibliographic

search. Comm. ACM, 18(6):333–340, 1975.

2. A. Amir and G. Calinescu. Alphabet independent and dictionary scaled matching.

J. of Algorithms, 36:34–62, 2000.

3. A. Amir, M. Farach, R. Giancarlo, Z. Galil, and K. Park. Dynamic dictionary

matching. Journal of Computer and System Sciences, 49(2):208–222, 1994.

4. A. Amir, M. Farach, R.M. Idury, J.A. La Poutr´e, and A.A Sch¨aﬀer. Improved dy-
namic dictionary matching. Information and Computation, 119(2):258–282, 1995.
5. A. Amir, D. Keselman, G. Landau, M. Lewenstein, N. Lewenstein, and M. Rodeh.
Indexing and dictionary matching with one error. Journal of Algorithms, 37:309–
325, 2000. (Preliminary version appeared in WADS 99.).

6. P. Bille, I.L. Gørtz, H. W. Vildhøj, and D. K. Wind. String matching with variable

length gaps. Theoretical Computer Science, (443):25–34, 2012.

7. P. Bille and M. Thorup. Faster regular expression matching. In Proc. 36th Inter-
national Colloquium on Automata, Languages and Programming (ICALP), volume
5555 of LNCS, pages 171–182. Springer, 2009.

8. P. Bille and M. Thorup. Regular expression matching with multi-strings and in-
In Proc. 21st Annual ACM-SIAM Symposium on Discrete Algorithms

tervals.
(SODA), pages 1297–1308, 2010.

9. G. S. Brodal and L. Gasieniec. Approximate dictionary queries.

In Proc. 7th
Annual Symposium on Combinatorial Pattern Matching (CPM 96), pages 65–74.
LNCS 1075, Springer, 1996.

10. R. Cole, L. Gottlieb, and M. Lewenstein. Dictionary matching and indexing with
errors and don’t cares. In Proc. 36th annual ACM Symposium on the Theory of
Computing (STOC), pages 91–100. ACM Press, 2004.

11. T. M. Chan, K. G. Larsen, and M. Pˇatra¸scu, Orthogonal range searching on the
ram, revisited, Proc. 27th ACM Symposium on Computational Geometry (SoCG),
2011, pp. 1–10.

12. K. Fredriksson and S. Grabowski. Eﬃcient algorithms for pattern matching with
general gaps, character classes and transposition invariance. Inf. Retr., 11(4):338–
349, 2008.

13. T. Haapasalo, P. Silvasti, S. sippu, and E. S. Soininen. Online dictionary matching
with variable-length gaps. In Proc. 10th Intl. Symp. on Experimental Algorithms
(SEA), number 6630 in LNCS, pages 76–87. Springer, 2011.

14. K. Hofmann, P. Bucher, L. Falquet, and A. Bairoch. The PROSITE database.

Nucleic Acids Res., (27):215–219, 1999.

15. M. Krishnamurthy, E. S. Seagren, R. Alder, A. W. Bayles, J. Burke, S. Carter,
Syngress Publishing,
How to Cheat at Securing Linux.
e-edition:

and E. Faskha.
Inc., Elsevier, Inc., 30 Corporate Dr., Burlington, MA 01803, 2008.
http://www.sciencedirect.com/science/book/9781597492072.

16. G. Kucherov, and M. Rusinowitch. Matching a set of strings with variable length

dont cares. Theoret. Comput. Sci., 178(12):129–154, 1997.

17. E. M. McCreight. A Space-Economical Suﬃx Tree Construction Algorithm. Jour-

nal of the ACM, 23(2):262–272, 1976.

18. M. Morgante, A. Policriti, N. Vitacolonna, and A. Zuccolo. Structured motifs

search. J. Comput. Bio., 12(8):1065–1082, 2005.

19. G. Myers. A four-russian algorithm for regular expression pattern matching. J.

ACM, 39(2):430–448, 1992.

20. G. Myers and G. Mehldau. A system for pattern matching applications on biose-

quences. CABIOS, 9(3):299–314, 1993.

21. J.C. Naa, A. Apostolico, C. S. Iliopoulos, and K. Park. Truncated suﬃx trees and
their application to data compression. Theoretical Computer Science, 304(3):87–
101, 2003.

22. G. Navarro and M. Raﬃnot. Fast and simple character classes and bounded
gaps pattern matching, with applications to protein searching. J. Comput. Bio.,
10(6):903–923, 2003.

23. G. Navarro and M. Raﬃnot. New techniques for regular expression searching.

Algorithmica, 41(2):89–116, 2004.

24. S. Rahman, C. S. Iliopoulos, I. Lee, M. Mohamed, and W. F. Smyth. Finding
patterns with variable length gaps or don’t cares. In Proc. 12th Annual Conference
on Computing and Combinatorics (COCOON), pages 146–155, 2006.

25. E. Ukkonen. On-line construction of suﬃx trees. Algorithmica, 14(3):249–260,

1995.

26. P. van Emde Boas. Preserving order in a forest in less than logarithmic time.
Proceedings of the 16th Annual Symposium on Foundations of Computer Science,
pages 75–84, 1975.

27. Verint. Packet intrusion detection. Personal communication, 2013.
28. P. Weiner. Linear pattern matching algorithm. Proc. 14 IEEE Symposium on

Switching and Automata Theory, pages 1–11, 1973.

29. M. Zhang, Y. Zhang, and L. Hu. A faster algorithm for matching a set of patterns
with variable length don’t cares. Inform. Process. Letters, 110:216–220, 2010.

