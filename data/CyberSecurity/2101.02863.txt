Foureye: Defensive Deception based on
Hypergame Theory Against Advanced
Persistent Threats

Zelin Wan, Jin-Hee Cho, Senior Member, IEEE, Mu Zhu, Ahmed H. Anwar, Charles Kamhoua, Senior
Member, IEEE, and Munindar P. Singh, IEEE Fellow

1
2
0
2

n
a
J

1
3

]
T
G
.
s
c
[

2
v
3
6
8
2
0
.
1
0
1
2
:
v
i
X
r
a

Abstract—Defensive deception techniques have emerged as a promis-
ing proactive defense mechanism to mislead an attacker and thereby
achieve attack failure. However, most game-theoretic defensive decep-
tion approaches have assumed that players maintain consistent views
under uncertainty. They do not consider players’ possible, subjective
beliefs formed due to asymmetric information given to them. In this
work, we formulate a hypergame between an attacker and a defender
where they can interpret the same game differently and accordingly
choose their best strategy based on their respective beliefs. This gives
a chance for defensive deception strategies to manipulate an attacker’s
belief, which is the key to the attacker’s decision making. We consider
advanced persistent threat (APT) attacks, which perform multiple attacks
in the stages of the cyber kill chain where both the attacker and the
defender aim to select optimal strategies based on their beliefs. Through
extensive simulation experiments, we demonstrated how effectively the
defender can leverage defensive deception techniques while dealing
with multi-staged APT attacks in a hypergame in which the imperfect
information is reﬂected based on perceived uncertainty, cost, and ex-
pected utilities of both attacker and defender, the system lifetime (i.e.,
mean time to security failure), and improved false positive rates in
detecting attackers.

Index Terms—Defensive deception, hypergame theory, uncertainty, at-
tacker, defender, advanced persistent threat

1 INTRODUCTION

The key purpose of a defensive deception technique is to
mislead an attacker’s view and make it choose a suboptimal
or poor action for the attack failure [33]. When both the
attacker and defender are constrained in their resources,
strategic interactions can be the key to beat an opponent.
In this sense, non-game-theoretic defense approaches have
inherent limitations due to lack of efﬁcient and effective
strategic tactics. Forms of deception techniques have been
discussed based on certain classiﬁcations, such as hiding the

• Zelin Wan and Jin-Hee Cho are with the Department of Computer
Science, Virginia Tech, Falls Church, VA 22043, USA. Email: {zelin,
jicho}@vt.edu. Mu Zhu and Munindar P. Singh are with the Depart-
ment of Computer Science, North Carolina State University, Raleigh,
NC 27695, USA. Email: {mzhu5, mpsingh}@ncsu.edu. Ahmed H. An-
war and Charles A. Kamhoua are with the US Army Research Lab-
oratory, Adelphi, MD 20783, USA. Email: a.h.anwar@knights.ucf.edu;
charles.a.kamhoua.civ@mail.mil.

(cid:70)

1

truth vs. providing false information or passive vs. active for
increasing attackers’ ambiguity or confusion [3, 9].

Game theory has been substantially used for dynamic
decision making under uncertainty, assuming that players
have consistent views. However, this assumption fails as
players may often subjectively process asymmetric infor-
mation available to them [22]. Hypergame theory [5] is a
variant of game theory that provides a form of analysis
considering each player’s subjective belief, misbelief, and
perceived uncertainty and accordingly their effect on deci-
sion making in choosing a best strategy [22].

This paper leverages hypergame theory to resolve con-
ﬂicts of views of multiple players as a robust decision-
making mechanism under uncertainty where the players
may have different beliefs towards the same game. Hyper-
game theory models players, such as attackers and defend-
ers in cybersecurity to deal with advanced persistent threat
(APT) attacks. We dub this effort Foureye after the Foureye
butterﬂyﬁsh, demonstrating deceptive defense in nature [40].
To be speciﬁc, we identify the following nontrivial chal-
lenges in obtaining a solution. First of all, it is not trivial
to derive realistic game scenarios and develop defensive
deception techniques to deal with APT attacks beyond the
reconnaissance stage. This aspect has not been explored in
the state-of-the-art. Second, quantifying the degree of uncer-
tainty in the views of attackers and defenders is challenging,
although they are critical because how each player frames a
game signiﬁcantly affects its strategies to take. Third, given
a number of possible choices under dynamic situations,
dealing with a large number of solution spaces is not triv-
ial whereas the deployment and maintenance of defensive
deception techniques is costly in contested environments.
We partly addressed these challenges in our prior work
in [12]; however, its contribution is very limited in con-
sidering a small-scale network and a small set of strategies
with a highly simpliﬁed probability model developed using
Stochastic Petri Network.

To be speciﬁc, this paper has the following new key

contributions:

• We modeled an attack-defense game under uncertainty
based on hypergame theory where an attacker and a

 
 
 
 
 
 
defender have different views of the situation and are
uncertain about strategies taken by their opponents.

• We reduced a player’s action space by using a subgame
determined based on a set of strategies available where
each subgame is formulated based on each stage of the
cyber kill chain (CKC) based on a player’s belief under
uncertainty.

• We considered multiple defense strategies, including de-
fensive deception techniques whose performance can be
signiﬁcantly affected by an attacker’s belief and perceived
uncertainty, which impacts its choice of a strategy.

• We modeled an attacker’s and a defender’s uncertainty
towards its opponent (i.e., the defender and the attacker,
respectively) based on how long each player has moni-
tored the opponent and its chosen strategy. To the best of
our knowledge, prior research on hypergame theory uses
a predeﬁned constant probability to represent a player’s
uncertainty. In this work, we estimated the player’s un-
certainty based on the dynamic, strategic interactions
between an attacker and a defender.

• We conducted comparative performance analysis with or
without a defender using defensive deception (DD) strate-
gies and with or without perfect knowledge available
towards actions taken by the opponent. We measured the
effectiveness and efﬁciency of DD techniques in terms of
a system’s security and performance, such as perceived
uncertainty, hypergame expected utility, action cost, mean
time to security failure (MTTSF or system lifetime), and
improved false positive rate (FPR) of an intrusion detec-
tion by the DD strategies taken by the defender.

2 RELATED WORK

Garg and Grosu [15] proposed a game-theoretic decep-
tion framework in honeynets with imperfect information
to ﬁnd optimal actions of an attacker and a defender and
investigated the mixed strategy equilibrium. Carroll and
Grosu [10] used deception in attacker-defender interactions
in a signaling game based on perfect Bayesian equilibria
and hybrid equilibria. They considered defensive deception
techniques, such as honeypots, camouﬂaged systems, or
normal systems. Yin et al. [41] considered a Stackelberg
attack-defense game where both players make decisions
based on their perceived observations and identiﬁed an
optimal level of deceptive protection using fake resources.
Casey et al. [11] examined how to discover Sybil attacks
based on an evolutionary signaling game where a defender
can use a fake identity to lure the attacker to facilitate
cooperation. Schlenker et al. [32] studied a sophisticated and
na¨ıve APT attacker in the reconnaissance stage to identify an
optimal defensive deception strategy in a zero-sum Stackel-
berg game by solving a mixed integer linear program.

Unlike the above works cited [10, 11, 15, 32, 41], our
work used hypergame theory which offers the powerful ca-
pability to model uncertainty, different views, and bounded
rationality by different players. This way reﬂects more real-
istic scenarios between the attacker and defender.

Hypergame theory has emerged to better reﬂect real-
world scenarios by capturing players’ subjective and im-
perfect belief, aiming to mislead them to adopt uncertain
or non-optimized strategies. Although other game theories
deal with uncertainty by considering probabilities that a

certain event may happen, they assume that all players play
the same game [34]. Hypergame theory has been used to
solve decision-making problems in military and adversarial
environments House and Cybenko [20], Vane [37], Vane
and Lehner [39]. Several studies [16, 17] investigated how
players’ beliefs evolve based on hypergame theory by de-
veloping a misbelief function measuring the differences
between a player’s belief and the ground truth payoff of
other players’ strategies. Kanazawa et al. [21] studied an
individual’s belief in an evolutionary hypergame and how
this belief can be modelled by interpreter functions. Sasaki
[31] discussed the concept of subjective rationalizability where
an agent believes that its action is a best response to the
other agent’s choices based on its perceived game.

Putro et al. [30] proposed an adaptive, genetic learning
algorithm to derive optimal strategies by players in a hy-
pergame. Ferguson-Walter et al. [13] studied the placement
of decoys based on a hypergame. This work developed a
game tree and investigated an optimal move for both an
attacker and defender in an adaptive game. Aljefri et al.
[2] studied a ﬁrst level hypergame involving misbeliefs to
resolve conﬂicts for two and then more decision makers.
Bakker et al. [4] modeled a repeated hypergame in dynamic
stochastic setting against APT attacks primarily in cyber-
physical systems.

Unlike the works using hypergame theory above [2,
4, 13, 16, 17, 20, 21, 30, 31, 37, 39], our work considered
an APT attacker performing multi-staged attacks where
attack-defense interactions are modeled based on repeated
hypergames. In addition, we show the effectiveness of de-
fensive deception techniques by increasing the attacker’s
uncertainty leading to choosing non-optimal actions and
increasing the quality of the intrusion detection (i.e., a
network-based intrusion detection system, NIDS) through
the collection of attack intelligence using defensive decep-
tion strategies.

3 SYSTEM MODEL
3.1 Network Model

This work concerns a software-deﬁned network (SDN)-
based Internet-of-Things (IoT) environment characterized
by servers and/or IoT devices, such as an SDN-based
smart environment [7]. The key beneﬁt of using the SDN
technology is decoupling the network control plane from
the data plane (e.g., packet forwarding) for higher ﬂexi-
bility, robust security/performance, and programmability
for a networked system in which an SDN controller can
efﬁciently and effectively manage security and performance
mechanisms. We use the SDN controller to involve packet
forwarding decisions and to deploy defense mechanisms,
such as ﬁrewalls or NIDSs. SDN-enabled switches handle
forwarding packets, where they encapsulate packets with-
out exact matching ﬂow rules in ﬂow tables in which the
encapsulated packets, ‘OFPT PACKET IN’ packets in Open-
Flow (OF) protocol (i.e., a standard communication protocol
between SDN-enabled switches and the SDN controller), are
provided to the SDN controller handling the ﬂow.

The nodes in this environment collect data and perform
a periodic delivery of those collected data to the servers via
multi-hop communications, in which the servers may need
to process further to provide queried services. The nodes

2

may be highly heterogeneous in their types and functional-
ities and spread over different Virtual Local Area Networks
(VLANs) of the IoT environment. Each VLAN may have one
or more servers and is assigned with a set of nodes based
on the common characteristics of their functionalities. We
leverage the advanced SDN technology [27] for the effective
and efﬁcient management of IoT nodes with the help of an
SDN controller.

3.2 Node Model

A node, including web servers, databases, honeypots, and
IoT devices, is characterized by the following set of features:
• Criticality: This metric, ci, indicates how critical node i is
in terms of its given role for security and reachability (i.e.,
inﬂuence) in a network to maintain network connectivity,
and given by:

ci = importancei × reachabilityi,

(1)

where importancei is given as an integer ranged in [0, 10]
during the network deployment phrase. reachabilityi is
computed based on the faster betweenness centrality met-
ric [8] by the SDN controller. Note that the algorithmic
complexity of the faster betweenness in this work is
O(|V |2) as a given network follows Erd ¨os–R´enyi (ER)
network model [28]. reachabilityi is estimated in the range
of [0, 1] as a real number.

• Security vulnerability: A node’s vulnerabilities to various
types of attacks are considered based on three types of
vulnerabilities: (1) vulnerabilities associated with software
installed in each node, denoted by svi; (2) vulnerabilities
associated with encryption keys (e.g., secret or private
keys), denoted by evi. As a longer-term key exposes
higher security vulnerability, the attacker can exploit en-
cryption vulnerability over time with ˆevi = evi · e−1/Trekey
and Trekey is the time elapsed since the attacker has
investigated a given key; and (3) an unknown vulnera-
bility, denoted by uvi, representing the average unknown
vulnerability. We assume that all the vulnerabilities are
computed based on the Common Vulnerability Scoring
System (CVSS) [1] with the severity value in [0, 10] as an
integer. We measure the average vulnerability associated
with node i being vulnerable by:

vulnerabilityi =

(cid:80)

vj ∈Vi
|Vi|

vj

,

(2)

where Vi is a set of vulnerabilities associated with node
i (e.g., {sv0, sv1, sv2, ev0, ev1, ev2, uv0}), vj refers to one
of vulnerabilities, associated with node i where vj
is
measured based on [0, 10] following the CVSS. We de-
note P v
i = vulnerabilityi/10 as a normalized vulnerability
probability. P v
is used as the probability to exploit (i.e.,
i
compromise) node i by an attacker.

• Mobility: We model the mobility rate of node i by con-
sidering a rewiring probability P r
i only for IoT devices
where node i can be connected with a new IoT node
with P r
i . For rewiring connections, node i will select one
of its neighbors with P r
to disconnect and then select a
i
new node to be connected to maintain a same number of
neighbors (nodes being directly connected).

TABLE 1
EXAMPLE NODE CHARACTERISTICS.

Importance

Software Vul.

Web servers
Datbases
Honeypots
IoT devices

[8, 10]
[8, 10]
0
[1, 5]

[3, 7]
[3, 7]
[7, 10]
[1, 5]

Encryption
Vul.

[1, 3]
[1, 3]
[9, 10]
[5, 10]

Table 1 shows an example set of node characteristics show-
ing the ranges of each node type’s attributes and the
shown values used as default settings for our experiments
in Section 6. We select each attribute value at random
based on uniform distribution in a given range. Notice
that we consider zero importance for honeypots, implying
no performance degradation and security damage upon its
compromise. In addition, we put a fairly high range of the
number of vulnerabilities in the honeypots in order to lure
attackers with high attack utility. Since a legitimate user
can be compromised by the attacker, cp refers to the status
of a node’s compromise (i.e., cpi = 1 for compromise; 0
otherwise). We summarize node i’s proﬁle as:

ni = [ci, cpi, evi, Vi, P v
i , and P r

i , P r
i ].

Recall that ci, cpi, evi, Vi, P v
i are node i’s criticality
in [0, 1], the status of being compromised (=1) or not(=0),
evicted (=1) or not (=0), vulnerability vector in software,
encryption, and unknowns, the probability of the overall
vulnerability, and rewiring probability for mobility in [0, 1].

(3)

3.3 Assumptions

We assume that the SDN controller and control channel
are trusted and considering their security vulnerabilities is
beyond the scope of this work. Since each SDN controller
should be well informed of basic network information un-
der its control and other SDN controllers’ control, each SDN
controller periodically updates the network topology and
software vulnerabilities of nodes under its control to other
SDN controllers. Via this process, each SDN controller can
periodically check an overall system security state and take
actions accordingly.

We also assume that a network-based IDS (NIDS) is
deployed in the SDN controller and is characterized by
the probabilities of false positives (Pf p) and false negatives
(Pf n). The NIDS runs throughout the system lifetime. The
NIDS’s Pf p and Pf n will be dynamically updated as it
receives more attack intelligence from the defensive de-
ception techniques used in this work. We assume that the
collected signatures from the deception-based monitoring
mechanisms can decrease Pf n due to an increased volume
of additional signatures. We simply use Beta distribution to
derive Beta(Pf n; α, β) where α refers to false negatives (FN)
and β is true positives (TP) with Pf n = F N/(T P +F N ). Sim-
ilarly, as more attack intelligence is forwarded to NIDS via
defensive deception-based monitoring, β (TP) increments by
1 per monitoring interval. Similarly, false positives will be
reduced as defensive deception techniques are used where
Pf p = F P/(T N + F P ) and TN increases by 1.

We assume that legitimate users use a secret key for
secure group communications among internal, legitimate
users while prohibiting outsiders from accessing secured
network resources. If an outsider wants to access a target

3

network and become an inside attacker with legitimate
credentials, it needs to be authenticated and given the secret
key to access the target network. In addition, network re-
sources are accessed according to the privilege of each user.
Therefore, to compromise a legitimate node, the attacker
should obtain appropriate privileges to access them.
3.4 Attack Model

We consider APT attackers performing multi-staged attacks
following the cyber kill chain (CKC) for compromising
a target node and exﬁltrating conﬁdential information to
outside [29]. We consider the APT attacks as follows.

APT Attack Procedure to Achieve Data Exﬁltration:
We deﬁne an APT attacker’s goal in that the attacker has
reached and compromised a target node and successfully
exﬁltrated its conﬁdential data. We assume that nodes with
a higher importance (i.e., having more important, credential
information) are more likely to be targeted.

To reach a target node, the attacker needs to compromise
other intermediate nodes along the way. We often call the
path to the target node ‘an attack path.’ In reality, the
attacker may not have an exact, complete view on network
topology. We assume that the attacker only knows its adja-
cent nodes (i.e., nodes being directly connected) and needs
to choose which node to compromise next. The attacker will
consider how easily given adjacent node i can be exploited
according to an attack cost metric, ack, for attack strategy
k. Moreover, if the attacker ﬁnds already compromised,
adjacent nodes, it can leverage it and has no need to put
additional effort to compromise it. We call this ‘the value
of an intermediate node i in an attack path,’ denoted by
AP V (i, k), where k refers to attack strategy ID. Highest
AP V (i, k) will be added to the attacker’s attack path to the
target node. AP V (i, k) is given by:

AP V (i, k) =

(cid:40)

(1 − ˆack) · P v
i
1 otherwise.

if cpi == 0,

(4)

Here ˆack = e−(1/ack) ∈ [0, 1] that represents a normalized at-
tack cost where ack is a predeﬁned attack cost ranged in [0, 3]
(see ‘Attack Strategy Attributes’ later in this section), and
vulnerabilityi is the overall vulnerability in Eq. (2). Given a
node to be compromised next, its vulnerability degree can
be computed as P v
(= vulnerabilityi/10). If cpi = 1 (i.e.,
i
node i is compromised), the attacker may add it to the attack
path at no cost, which gives AP V (i, k) = 1. The attacker
may need to compromise more than one intermediate nodes
before reaching a target node.

Attack Strategy Attributes: An APT attacker can per-
form multiple attacks through the stages of the CKC. Each
attack strategy k can be characterized by: (1) attack cost, ack,
indicating how much time/effort is needed to launch the
attack; and (2) the expected impact (i.e., attack effectiveness)
upon attack success, aik. ack is a predeﬁned constant as
an integer in [0, 3] reﬂecting no, low, medium, and high
cost, respectively. aik is obtained by victim j’s criticality,
cj (see Eq. (1)). This implies the attack beneﬁt through
compromising a set of exploitable nodes. If there have been
multiple nodes being compromised by taking given attack
k, aik captures the criticalities of the compromised nodes by:
(cid:80)

aik =

cj

j∈Ck
N

,

(5)

4

TABLE 2
CHARACTERISTICS OF APT ATTACK STRATEGIES

AS

AS1
AS2
AS3
AS4
AS5
AS6
AS7
AS8

CKC
stage

R – DE
D – DE
E – DE
E – DE
E – DE
C2 – DE
E – DE
DE

Attack
cost (ac)

Node com-
promise

Exploited
vulnerability

1
3
3
3
1
3
2
3

No
Yes (SN)
Yes (MN)
Yes (SN)
Yes (SN)
Yes (SN)
Yes (SN)
Yes (SN)

UV
SV + EV
SV
SV + UV
UV
EV
EV
S + EV

Note: Each CKC stage is indicated by Reconnaissance (R), Delivery
(D), Exploitation (E), Command and Control (C2), Lateral Movement
(M), and Data Exﬁltration (DE). Attack cost is ranged in [1, 3] as an
integer, representing low, medium, and high, respectively. Node
compromise may involve a single node compromise (SN) or multiple
nodes compromise (MN). Exploited vulnerability is indicted by
Overall (O: Average vulnerability across all three types of
vulnerabilities), Software (SV: software vulnerability), Encryption (EV:
vulnerability by compromising encryption key(s)); and Unknown (UV:
unknown vulnerability).

where Ck is a set of compromised nodes by given attack k
and N is the the total number of nodes. If node j is already
compromised, then there is no additional attack impact,
aik = 0, introduced by attack strategy k. Compromising
more important nodes with highly conﬁdential information
leads to early system failure (see Eq. (8)).

Attack Strategies: Attackers in IoT environments have
their own characteristics. We consider several types of at-
tacks at the different stages of the CKC by an APT attacker.
The CKC consists of six stages denoted by (R, D, E, C2, M,
and DE) (see Table 2). Each attack strategy is characterized
by (1) in which CKC stage the attacker is in; (2) whether the
attacker will compromise other nodes in an attack path to
reach a target; (3) what attack cost ack and attack impact
aik) are associated with each attack strategy k; and (4)
what vulnerability an attacker can exploit to perform a
given attack strategy (ASk). For simplicity, when an attacker
exploits more than one vulnerability, the average security
vulnerability is used to compute the normalized vulnerabil-
ity, P v
i . In addition, each attack strategy k’s attack impact,
aik, is obtained based on Eq. (5). Note that an attacker can
select a non-compromised adjacent victim with the highest
AP V value (see Eq. (4)) to maximize the attack success
probability while minimizing the attack cost. We describe
each attack strategy as follows:

• AS1 – Monitoring attack: This attack is to collect useful
system information and identify a vulnerable node to
compromise as a target. It can be performed inside or
outside the network from R to DE stages. In this attack,
no node compromise process is involved and accordingly
its attack cost is low, ac1 = 1.

• AS2 – Social engineering: The typical examples of this
attack include email phishing, pretexting, baiting, or tail-
gating [23]. We assume that an inside attacker can suc-
cessfully compromise an adjacent node if the attack is
successful. If the attacker is an outside attacker, it can
identify a node as vulnerable during its reconnaissance
stage. This attack can be performed from D to DE stages as
an outside or inside attacker. Since it is highly challenging
to deceive a human user who can easily detect a social

engineering attack, the associated attack cost for AS2 is
high, ac2 = 3.

• AS3 – Botnet-based attack: A botnet consists of compro-
mised machines (or bots) running malware using C2 of
a botmaster. When this attack is chosen, all compromised
nodes (including original attackers) will launch epidemic
attacks (e.g., spreading malware to compromise) to their
adjacent, legitimate nodes [6]. This attack can be used
from E to DE stages. This attack incurs high attack cost,
ac3 = 3.

• AS4 – Distributed Denial-of-Service (DDoS): A set of com-
promised nodes can form a botnet and perform DDoS by
sending multiple requests [6]. When an attacker tries to
compromise one of its adjacent nodes as a potential victim
node, if all compromised nodes send service requests
to the potential victim node, the potential victim node’s
vulnerability may increase because it could not properly
handle all operations due to the large volume of requests
received (e.g., not properly executing underlying security
operations). This will allow the attacker to easily compro-
mise the potential victim node or exﬁltrate conﬁdential
data from it. To model this, unknown vulnerability, uvi,
for a given victim node i will increase for the attacker
to more easily compromise a node with unknown vul-
nerability (e.g., increasing (cid:15)1% for UV). This attack can
be performed from E to DE stages, with high attack cost,
ac4 = 3.

• AS5 – Zero-day attacks: This attack can be performed to
exploit unknown vulnerabilities of software, which are
not patched yet. The attacker can compromise chosen
adjacent node i based on normalized uvj. This attack can
be performed from E to DE stages at low cost, ac5 = 1.
• AS6 – Breaking encryption: Examples include a legitimate
node’s private or secret key compromise. The attacker
with the encryption key is considered an inside attacker
with a privilege to exploit system resources. This attack
can be launched from C2 to DE stages to collect system
conﬁgurations or conﬁdential information. Upon the at-
tack success, the attacker can intercept all the informa-
tion to be sent to a victim node whose private key is
compromised. This attack may exploit vulnerabilities ˆevi
associated with encryption keys and involve high attack
cost, ac6 = 3. We assume that if a legitimate node’s private
key is compromised, the node is compromised. Hence, the
attacker can escalate its attack by reauthenticating itself
with a new password and steal conﬁdential information
or implant malware into ﬁle downloads.

• AS7 – Fake identity: This attack can be performed when
packets are transmitted without authentication or inter-
nal nodes spooﬁng the ID of a source node, such as
MAC/IP/Virtual LAN tag spooﬁng in an SDN-based IoT
by an SDN switch [26]. This attack involves compromising
a node with a fake ID. This attack can be performed from
E to DE stages with cost, ac7 = 2. This attack increases
the encryption vulnerabilities of its adjacent nodes (e.g.,
increasing (cid:15)1% for EV).

• AS8 – Data exﬁltration: This attack will also allow the
attacker to compromise one of the adjacent nodes. The
attacker will check all data compromised by itself until
DE stage. Then, if the accumulated importance of compro-
mised data exceeds a certain threshold (i.e., (cid:80)
cj >

j∈CA

Thc), the attacker can decide whether to exﬁltrate the
collected intelligence to the outside. This attack costs high
with ac8 = 3.

We summarize the characteristics of all attack strategies
considered in terms of the CKC stages involved, attack cost,
node compromise, and exploited vulnerability in Table 2.
Except AS1, the attack success from AS2 to AS8 is deter-
mined based on whether all nodes on the attack path to
reach a target node have been successfully compromised.
For AS1, the attack success is determined based on how
long the attacker has monitored a target system. This is
computed by the probability vulnerabilityi ·e−1/TA where TA
is the time elapsed the attacker has monitored a given target
system. This implies that the attack is likely successful when
the attacker has more scanned the targeted system longer
and ﬁnd more vulnerabilities. After the attacker exﬁltrates
data successfully and leaves the system, a new attacker will
arrive. Otherwise, the attacker may be evicted by the NIDS
or need to try other attack strategies to escalate its attack to
a next level.

An Attacker’s Deception Detectability: Depending on
an attacker’s capability, the attacker may have a different
level of intelligence to detect defensive deception tech-
niques. We denote it by ad to represent an attacker’s prob-
ability (omitted an attacker’s ID for simplicity) to detect
deception used by the defender. An attacker can use this
probability, ad, to detect honeypots or honey information,
as described in DS5 in the next section below.

3.5 Defense Model

Attack Intelligence Collection: Different types of defense
strategies can be deployed by the defender to counter APT
attackers. At the same time, the NIDS will be run periodi-
cally (see Section 3.1). Note that we don’t count triggering
an NIDS as one of defense strategies in order to meet a high
standard of the system integrity. When an attacker arrives
at the system as an inside attacker (i.e., after the E stage),
it can be detected by the NIDS. However, the system aims
to collect more attack intelligence (e.g., attack signatures),
which can improve the NIDS as a long-term goal. Thus,
depending on the perceived risk level from the attacker, the
system will determine whether to keep the detected attacker
in the system or evict it. We estimate the perceived system
risk level based on the criticality level of the compromised
node, ci, and determine if the system will allow the attacker
to reside in the system or be evicted according to predeﬁned
risk threshold, Thrisk ∈ [0, 1]. The decision to evict node i,
which is detected as compromised, can be given by:

Evicti =

(cid:40)

1 if ci > Thrisk
0 otherwise.

(6)

Here Evicti = 1 means evicting node i while Evicti = 0
means allowing node i to reside in the system. Note that this
rule is applied when node i is detected as compromised by
the NIDS regardless of its correctness. Hence, false positive
nodes can be also assessed by this rule while false negative
nodes can safely reside in the system without being assessed
by Thrisk.

When nodes detected as compromised (i.e., true and
false positives) are evicted, all associated edges will be

5

disconnected, which may generate some non-compromised
nodes being isolated from the network. To maintain connec-
tivity of non-compromised but isolated nodes, we connect
them to the network based on P r
to maintain node i’s
i
mean degree based on the ER network model [28]. To deal
with the attackers (or compromised nodes) residing in the
system, which are either false negatives or attackers kept
to collect further attack intelligence, the defender system
can take the several defense strategies. Each strategy k will
be represented by: (i) defense cost (dck) in time/complexity
and expense, where dck ∈ [0, 3] as an integer for no, low,
medium, and high cost, respectively; (ii) defense impact
(dik) for its defense effectiveness; (iii) the stage of the CKC
(i.e., R, D, E, C2, LM, or DE) for strategy k being used; and
(iv) system change on what actual changes are made in the
system (e.g., what vulnerabilities are reduced or network
topology or cryptographic keys being changed). The defense
impact, dik, is computed by:

dik = 1 − aik,

(7)

where aik is the attack impact introduced by strategy k in
Eq. (5). We measure the effectiveness of a defense strategy
as the opposite impact of attack success (i.e., successfully
compromising a node). That is, attack failure will increase
the impact of the defense strategy.

Defense Strategies: This work considers the following

defense strategies:
• DS1 – Firewalls: We assume that ﬁrewalls are implemented
in the SDN controller to monitor and control the incom-
ing and outgoing packet ﬂows according to predeﬁned
rules. We model the effectiveness of ﬁrewalls by lowering
down unknown vulnerabilities (uvi) all over the network.
Speciﬁcally, ﬁrewall is assumed to reduce vulnerabilities
to outside attackers by a certain percent (i.e., (cid:15)2%).

• DS2 – Patch Management: Known vulnerabilities can be
patched by a given defense system [25]. A patch is used
to temporarily ﬁx software vulnerabilities or provide up-
dates in a full software package. A patch refers to a
software update such as code to be installed in a software
program. This will decrease software vulnerabilities (svi)
of all nodes, such as decreasing a certain percent of the
vulnerability (i.e., (cid:15)2%).

• DS3 – Rekeying Cryptographic Keys: Cryptographic keys
used for all nodes in the network are rekeyed, which
lowers the encryption vulnerability by setting Trekey = 1
which reduces ˆevi = evi · e−1/Trekey .

• DS4 – Eviction: Recall that an attacker with low risk (see
Eq. (6)) is allowed to stay in the system for collecting
attack intelligence. However, as the system is at risk due
to high security vulnerability in terms of the amount of
compromised conﬁdential information (i.e., importance;
see Eq. (8)), all inside attackers (or compromised nodes)
will be evicted from the system. However, the false nega-
tives will remain in the system while a substantial number
of compromised nodes is evicted using DS4.

• DS5 – Low/high-interaction honeypots (LHs/HHs) [24]: LHs
and HHs can be activated as a defense strategy. LHs and
HHs differ in their deception detectability and cost. In a
given network, we deploy a set of LHs and HHs which are
deactivated in the deployment phase. When this strategy
is selected, they will be activated, which will change the

TABLE 3
CHARACTERISTICS OF DEFENSE STRATEGIES

DS

DS1
DS2
DS3
DS4

DS5

CKC
stage

R – D
D – DE
E – DE
E – DE

E – DE

DS6

C2 – DE

DS7
DS8

E – DE
R – DE

Defense
cost (dc)

System change (dsc)

1
2
3
3

3

1

2
2

Lowering UV
Lowering SV
Lowering EV
Evict all compromised
nodes
Lure attackers to with LHs
and HHs
Disseminate fake system
vulnerability information
Plant a fake key
Hide critical network edges

Note: Each CKC stage is indicated by Reconnaissance (R), Delivery
(D), Exploitation (E), Command and Control (C2), Lateral Movement
(M), and Data Exﬁltration (DE). Defense cost is ranged in [1, 3] as an
integer, representing low, medium, and high, respectively. System
change may involve lowering unknown vulnerabilities (UV), software
vulnerabilities (SV), or encryption vulnerabilities (EV).

network topology as LHs and HHs are to be connected
with a number of nodes in the network. Hence, DS5 will
change attack paths and lure attackers to the honeypots.
To be speciﬁc, when DS5 is selected, LHs and HHs will
be activated. This will enable them to be connected to
highly vulnerable nodes based on vulnerabilityi where
HHs will be connected to nodes of higher vulnerability
than nodes connected to LHs. In order for the attacker not
to reach legitimate nodes, we will only allow incoming
connections (i.e., in-degree) from legitimate nodes to the
honeypots. Once the attacker is caught by one of the
implemented honeypots, it will be diverted to a fake
network for monitoring purposes. Recall that an attacker
can detect the deception with ad for a LH and ad/2 for a
HH.

• DS6 – Honey information: This defense strategy can lure
attackers by disseminating false information, such as
honey token, fake patch, honey ﬁles, or bait ﬁles. This
strategy will involve the dissemination of false system
vulnerability information, such as providing high (low)
vulnerabilities for less (more) vulnerable nodes. The at-
tacker will need to detect whether a known vulnerability
of a potential victim node is true or fake according to its
deception detectability, ad. If the attacker is successfully
deceived, it will make an attack strategy decision based
on incorrect vulnerability information.

• DS7 – Fake keys [3]: Fake keys can be planted for potential,
inside attackers which may use a fake key obtained by
compromising another legitimate, inside node to commu-
nicate with other nodes to obtain more conﬁdential infor-
mation. This will be realized that even if the attacker com-
promises a cryptographic key (e.g., AS2, AS6, AS7, AS8),
a potential victim targeted by the attacker may not be
compromised. We model this using the probability the
attacker obtains a fake key implanted in nodes, Pf ake.
When the attacker obtains the fake key of a node, the node
will not be compromised.

• DS8 – Hiding network topology edges: This strategy hides
cN T % of network edges in order to hide an actual network
topology to an attacker. We use a simple rule for each node
to hide the edge with the most critical adjacent node based
on its criticality value, ci.

All defense strategies will have corresponding defense

6

costs (dck’s) and are believed useful when the attacker are
in certain CKC stages based on the defender’s belief. This is
used for the defender to choose each subgame based on
hypergame theory. We summarized the characteristics of
each defense strategy considered in Table 3.

System Failure Conditions: We deﬁne that a system

failure (SF) occurs when the following condition is met:

SF =

(cid:40)

1 if ρ1 ≤

(cid:80)

i∈G cpi·Importancei
(cid:80)
i∈G Importancei

|| ρ2 ≥ |Gt|
|G|

0 otherwise.

(8)

Here Gt refers to a network at time t which does not include
nodes being evicted while G is an original network. Hence
|G| and |Gt| are the number of the original nodes and the
number of the current nodes in the system at time t, respec-
tively. ρ1 is a threshold as a fraction to determine whether a
system fails or not based on the sum of compromised nodes’
importance values over the sum of all nodes’ importance
values. SF mainly captures the system failure caused by the
loss of three security goals, such as conﬁdentiality, integrity,
and availability. ρ2 is a threshold to determine whether
a system can functionally operate based on a sufﬁcient
number of active nodes at time t.

4 ATTACK-DEFENSE HYPERGAME
First, the attacker will select strategy AS1 to monitor a target
system in the reconnaissance (R) stage, aiming to penetrate
into it as a legitimate user. If the attack is successful based
on the success probability vulnerabilityi ·e−1/TA , the attacker
can proceed to the delivery (D) stage of the CKC. In the
D stage, the attacker can choose one of the two strategies
AS1 and AS2. If the attacker can successfully compromise a
targeted victim node, which is one of its adjacent nodes, it
can successfully penetrate the system and become an inside
attacker with legitimate credentials. Now the attacker is in
the Exploitation (E) stage. From E to data exﬁltration (DE)
stages, any inside attacker detected can be assessed by the
defender on whether it can stay in the system based on
the risk assessment in Eq. (6). Hence, depending on the
criticality of the attacked node, the attacker can be detected
by the NIDS or be kept in the system if the defense system
intends to collect attack intelligence from it. To assess such
risk, the attacker should be detected as an attacker (i.e., true
and false positives) by the NIDS. If not (i.e., false negatives),
the attacker can safely stay even without being detected.
From E to DE, the attack is determined as successful if
aii > 0 (see Eq. (5)). If the original attacker (i.e., a node
the attacker is on) is evicted, then a new attacker will arrive.
If an attacker is successful by taking AS8 (data exﬁltrated),
it will leave the system and a new attacker will arrive. This
process will continue until the system fails based on Eq. (8).
Next we formulate the hypergame between the attacker
and defender, and deﬁne the game components. We pro-
vided the detailed explanation of hypergame theory formu-
lations and its related equations in Appendix A, which are
used in the sections below.

4.1 Utilities
An attacker’s utility (uA
pq) corresponding to attack strategy
p (ASp) can be expressed as the difference between attack

TABLE 4
POSSIBLE STRATEGIES UNDER EACH STAGE OF THE CKC

Subgame CKC stage

Attack strategies

Defense strategies

0
1
2
3
4
5
6

Full game
R
D
E
C2
M
DE

AS1 − AS8
AS1
AS1, AS2
AS1 − AS5, AS7
AS1–AS7
AS1–AS7
AS1–AS8

DS1 − DS8
DS1, DS8
DS1, DS2
DS3 − DS5, DS7
DS3–DS8
DS3–DS8
DS3–DS8

gain and attack loss. The attacker’s utility (uA
pq) when the
attacker takes ASp and the defender takes DSq is calculated
by:

pq = GA
uA

pq − LA

pq, GA

pq = aip + dcq, LA

pq = acp + diq,

(9)

where the attack and defense cost (i.e., acp and dcq) and the
attack and defense impact (i.e., aip and diq) are discussed in
Sections 3.4 and 3.5, respectively.
A defender’s utility (uD

qp) by selecting DSq when the
attacker takes ASp can be computed based on the difference
between the gain and loss by:
qp − LD

qp = GD
uD
Similar to uA
pq, the attack and defense cost (i.e., dcq and
acp) and the attack and defense impact (i.e., diq and aip)
are computed. We consider a zero-sum game between the
attacker and defender (i.e., uA

qp = diq + acp, LD

qp = dcq + aip.

qp, GD

(10)

pq + uD

qp = 0).

4.2 Estimation of Uncertainty

As in Eq. (22) in Appendix A, an attacker’s and defender’s
hypergame expected utilities (HEUs) are estimated based
on the level of uncertainty, g, perceived by each player. In
this section, we show how the level of g is estimated by the
attacker (i.e., gA) and the defender (i.e., gD). Note that we
omit an ID of the attacker and defender for simplicity.

We model an attacker’s perceived uncertainty based
whether a defensive deception is used and how long the
attacker has monitored a target system. That is, given the
time period the attacker has monitored in a target system
(TA) and a defense strategy taken (df), the attacker’s uncer-
tainty (gA) is estimated by:

gA = 1 − exp(−λ · df/TA).

(11)

Here λ is a parameter of representing an amount of initial
knowledge towards a given system conﬁguration (higher
λ increases uncertainty, and vice versa) and df = 1 + (1 −
ad) · dec. df returns 1 when no defensive deception is used
(i.e., dec = 0); it returns 1 + (1 − ad) where ad refers to
an attacker’s deception detectability in [0, 1] when defensive
deception is used (i.e., dec = dc where dc is defense cost
implying that higher defense cost allows higher quality of
deception). The formulation of gA above implies that the
attacker has lower uncertainty as it has monitored the target
system longer. On the other hand, the attacker has higher
uncertainty when it has lower deception detectability and
the defender uses a defensive deception strategy. Hence,
we set dec = dc (defense cost) when defensive deception
strategies, DS5–DS8, are taken while setting dec = 0 when
non-deception defense strategies, DS1 − DS4, are taken.

A defender’s uncertainty towards an attacker increases
as it has monitored the attacker for a longer period where

7

the defender’s monitoring time towards the attacker is
denoted by TD. In addition, if the attacker has not been
deceived by defense strategies, it is assumed to be intelligent
not to expose its information to the defender. Considering
these two, we model gD by:

rA
κp =

rD
κq =

γA
κp

(cid:80)

p∈ASκ
γD
κq

(cid:80)

q∈DSκ

, cA

κq =

γA
p

, cD

κp =

γD
q

(cid:80)

γD
κq

q∈DSκ
γA
κp

,

γD
q

(cid:80)

p∈ASκ

.

γA
p

(13)

(14)

gD = 1 − exp(−µ · ad/TD),

(12)

where µ is a parameter of representing an amount of initial
knowledge towards an attacker (higher λ increases uncer-
tainty, and vice versa), ad is an attacker’s deception de-
tectability, and TD is a defender’s accumulated monitoring
time towards the attacker. In gD, the defender perceives
lower uncertainty at longer TD while perceiving higher
uncertainty at higher ad.

4.3 Estimation of HEUs

In order to calculate the HEU for each player (see Eq. (22)
in Appendix A), we need to obtain Pκ (i.e., the probability
a row player chooses subgame κ), rκp (i.e., the probability
that a row player takes strategy k in subgame κ), and cκj
(i.e., the probability that a column player takes strategy h
in subgame κ based on a row player’s belief) because Sq is
estimated based on Pκ and cκh while rκp is needed when a
row player considers strategy k.

κ and P D

Computation of Pκ: Recall that Pκ refers to the probabil-
ity that subgame κ is played by a row player. We notate this
for an attacker and a defender by P A
κ , respectively.
We deﬁne a subgame based on where an attacker is located
in the stages of the CKC which will determine a set of
available strategies for both parties. We assume that the
attacker clearly knows where it is located in the CKC while
the defender is not certain about the stage of the attacker
in the CKC. We model the defender’s P D
κ based on its
uncertainty gD. Thus, the defender can know the CKC
stage of the attacker with 1 − gD (certainty) and correctly
choose a subgame based on the attacker’s actual stage in
the CKC. With gD, the defender will choose subgame 0 (i.e.,
a full game with all available strategies). The set of available
strategies may be different depending on what subgame to
play, as shown in Table 4.

Computation of rκh and cκh: rκh is the probability that
a row player will play strategy h. We denote this for the at-
κp and rD
tacker and defender by rA
κq for attack strategy p and
defense strategy q, respectively. cκh is the probability that a
column player will take strategy h based on a row player’s
belief. We also denote this for the attacker and defender by
κp and cD
cA
κq attack strategy p and defense strategy q, respec-
tively. In the very beginning, since no historical information
is available, each player will use a uniform probability by
choosing one of available strategies in a chosen subgame
with an equal probability, meaning choosing a strategy at
random. As players participate in repeated games, their
recorded history regarding what strategies have been taken
is available. Then, we will use Dirichlet distribution [35]
to model multinomial probabilities based on the strategies
taken for past repeated games. If either an attacker or
defender is certain about the opponent’s strategy, it will
κp, rD
estimate its corresponding rA

κp, and cD

κq, cA

κq as:

(γA

Note that ASκ and DSκ are a set of attack strategies and
defense strategies, respectively. γD
p ) is the number of
q
times the defender (attacker) will take strategy q (or p)
based on the attacker’s (defender’s) belief up to time (t − 1)
where the current state is at time t. Since the probability of a
column player playing a particular strategy is estimated by
a row player’s belief, ground truth cA
κp (as shown
in the equations above) will be only detected with the
probability (1 − gA) and (1 − gD) when the row player is
an attacker or a defender, respectively. Otherwise, the row
player will select one among the available strategies in a
given subgame κ at random due to the uncertainty.

κq and cD

An attacker’s HEU (AHEU) is computed with: (1) attack
utilities (i.e., uA
kh’s in Eq. (9)); (2) the attacker’s belief about
defense strategy h (i.e., SA
q in Eq. (21) in Appendix A); and
(3) the attacker’s perceived uncertainty (i.e., gA in Eq. (11)).
Similarly, a defender’s HEU (DHEU) is estimated using:
(1) defense utilities (i.e., uD
qp’s in Eq. (10)); (2) the defender’s
belief about attack strategy p (i.e., SD
p in Eq. (21) in Appendix
A); and (3) the defender’s perceived uncertainty (i.e., gD in
Eq. (12)). Both AHEU and DHEU can be obtained based on
Eq. (22) in Appendix A. Since the row player selects each
strategy h based on rκh for given subgame κ, we calculate
AHEU and DHEU as follows:

AHEU(rsA
DHEU(rsD

p , gA) = HEU(rsA
q , gD) = HEU(rsD

p , gA),
q , gD).

(15)

A player will play a strategy according to the probability
distribution of strategies available in a given subgame κ.

5 EXPERIMENTAL SETTING

In this work, we use the following metrics:
• Perceived Uncertainty Level (gA or gD): An attacker’s or a
defender’s mean uncertainty level which is measured as
shown in Eqs. (11) and (12), respectively.

• Hypergame Expected Utility (HEU): This metric measures
the HEU of played strategies proﬁle, according to Eq. (22)
in Appendix A in the supplement document.

• Cost for Taking a Chosen Strategy (CA or CD): This metric
measures the average attack (or defense) cost paid by an
attacker (or a defender) to play a speciﬁc strategy. Attack
cost (CA) and defense cost (CD) of all available strategies
are summarized in Tables 2 and 3, respectively. For a given
scenario consisting of a series of games until the system
fails based on Eq. (8), the average attack or defense cost
per game is demonstrated.

• Mean Time to Security Failure (MTTSF): This metric mea-
sures a system lifetime based on the system states that do
not fall in the system failure states based on Eq. (8).

• TPR of an NIDS: This metric measures the true positive
rate of the NIDS in order to observe how much defensive
deception can improve the quality of the NIDS based on
the attack intelligence collected during the time of using
defensive deception.

8

Our work compares the performance following schemes:
• Game with defensive deception and perfect information (DD-
PI): This scheme plays a game where each player has
perfect information regarding which strategy is played by
its opponent, which means there is no uncertainty, g = 0
(i.e., gA = gD = 0), when a defender uses all defensive
deception (DD) strategies.

• Game without defensive deception and perfect information (No-
DD-PI): This scheme plays a game where each player has
perfect information regarding what strategy its opponent
plays (i.e., g = 0) when the defender does not use DD
strategies.

• Hypergame with defensive deception and imperfect information
(DD-IPI): This scheme plays a game where each player
does not have perfect information regarding the strategy
of its opponent (i.e., g > 0 with gA > 0, gD > 0) when the
defender uses DD strategies. This is our proposed scheme
that considers uncertainty g (i.e., imperfect information,
IPI) and DD.

• Hypergame without defensive deception and imperfect informa-
tion (No-DD-IPI): This scheme plays a game where each
player does not have perfect information towards what
strategy its opponent takes (i.e., g > 0) when the defender
does not use DD strategies.

We consider 500 nodes in a given network where a
network topology is generated by the ER random graph
model with G(N, P r) where N is the total number of nodes
and P r(= P r
i ) is the connection probability between any
pair of nodes [28]. To consider honeypots with low or high
interactions, we also assign 75 nodes as honeypots with 50
LHs and 25 HHs. For honeypots, we maintain a directed net-
work where the outgoing edges (i.e., out-degree) are from
each honeypot to all other honeypots to ensure an attacker
not to be connected with other legitimate nodes. When a
honeypot is activated (i.e., DS5), highly vulnerable nodes
are connected to the honeypot as an incoming edge (i.e., in-
degree). However, outgoing edges from the honeypot are
always forwarded to other honeypots, not real legitimate
nodes, which are protected from the attacker. In our ex-
periment, when the honeypots are activated, the top 225
vulnerable nodes are connected to honeypots where top 75
vulnerable nodes are connected to 25 HHs and next top 150
vulnerable nodes are connected to 50 LHs. We assume that
the defender has inherently higher uncertainty regarding an
attacker while the attacker has a certain level of knowledge
regarding a system due to its reconnaissance effort before
becoming an inside attacker. This was reﬂected by setting
λ = 0.8 and µ = 8 in Eqs. (11) and (12), respectively. We
summarized the notations of key design parameters, their
meaning, and default values used in Table 5 in Appendix B
of the submitted supplement document.

6 RESULTS & ANALYSES
In Fig. 1a, the attacker’s perceived uncertainty is plotted for
the four defense schemes. When imperfect information (IPI)
is considered, the attacker has fairly high uncertainty at the
beginning regardless of whether defensive deception (DD)
is used or not (i.e., DD-IPI starting from over 0.7 and No-
DD-IPI starting from over 0.55). The reason is that using
DD strategies can provide a high chance to increase the

attacker’s uncertainty by misleading the attacker. On the
other hand, under perfect information (PI), the attacker’s
uncertainty is zero. However, without DD (i.e., No-DD-PI
and No-DD-IPI), the system lifetime (i.e., MTTSF) is short,
so the curve with respect to the number of games stops at
around 80 rounds. Under DD-IPI, the system lifetime much
more prolongs compared to No-DD schemes. However, the
attacker’s uncertainty under DD-IPI decreases with more
rounds of games played, because playing more games will
result in more compromised nodes. A new attacker can
leverage this situation to get into the system quicker. This
makes the inside attacker stay longer in the system, result-
ing in lowering uncertainty as more rounds of games are
played. Some more ﬂuctuations in later games are due to
the small number of runs in simulation show long system
lifetimes. Notice that using DD makes the system prolong
even if it allows some compromised nodes to reside in the
system. This is because the system does not evict detected
intrusions immediately after detecting them but does re-
assess them to reduce false positives while collecting more
attack intelligence. This process can give a chance for the
NIDS to improve its detection rate. In addition, the attacker
perceives lower uncertainty as more games are played as
it can perceive less uncertainty about the system since it
has been in the system for a while. This was intentionally
allowed by the defender to collect attack intelligence.

In Figs. 1b and 1c, under varying the vulnerability of
nodes in the network, we plotted AHEU and attack cost
for each defense scheme. We didn’t observe any noticeable
sensitivity with respect to varying the extent of node vulner-
ability. This is because all three metrics, uncertainty, AHEU,
and attack cost do not depend on network conditions but
rather depend on the choices of strategies by the attacker
and corresponding impact and cost in HEU. In terms of
AHEU in Fig. 1b, overall, the attacker performs better
under DD-based schemes than No-DD-based schemes. The
reason is that under DD-based schemes, attackers can use
more strategies by being an insider of the system while
performing only monitoring attacks as an outside attacker
under No-DD-based schemes. In addition, this leads the
attacker naturally to perform better under PI than IPI. This
explains why the attacker obtains the highest AHEU under
DD-PI while having the lowest AHEU under No-DD-IPI.
In terms of attack cost, the attacker used more cost under
IPI while using less cost under PI as shown in Fig. 1c.
Under uncertainty, the attacker cannot choose its optimal,
cost-effective strategy. Moreover, the attacker paid higher
cost under DD while incurring a lower cost under No-DD.
This implies that DD strategies are effective to mislead the
attacker to choose less cost-effective strategies by increasing
its uncertainty. We also discussed how the attack cost and
AHEU with respect to the number of games in Fig. 4 (a)-
(b) in Appendix B of the supplement document with the
detailed explanations of the observed trends.

In Fig. 2a, the defender’s uncertainty is shown with re-
spect to the number of attack-defense hypergames. Overall
under IPI, the defender’s uncertainty is much lower than
the attacker’s uncertainty. This is because the defender can
collect more attack intelligence while the attacker can be
interrupted by DD strategies which increase the attacker’s
uncertainty. In addition, there are more ﬂuctuations under

9

(a) Attacker’s uncertainty

(b) Attacker’s HEU

(c) Attack cost

Fig. 1. An attacker’s uncertainty, hyergame expected utility (AHEU), and attack cost. The ‘vulnerability upper bound’ (Uv) refers to the CVSS-based
software vulnerability score of IoT devices, Web servers and Databases, which is scaled in [1, Uv].

(a) Defender’s uncertainty

(b) Defender’s HEU

(c) Defense cost

Fig. 2. A defender’s uncertainty, hyergame expected utility (DHEU), and defense cost. The ‘vulnerability upper bound’ (Uv) refers to the CVSS-based
software vulnerability score of IoT devices, Web servers and Databases, which is scaled in [1, Uv].

terms of MTTSF. Regardless of whether PI or IPI is con-
sidered, DD-based schemes outperformed non-DD-based
schemes. Again this is because DD-based schemes allow for
the reassessment of detected intrusions, leading to reduc-
tion in false positives while improving TPR of the NIDS.
However, DD-IPI outperformed all other schemes in terms
of MTTSF. This is because IPI can allow the defender to
effectively leverage the nature of DD strategies for mis-
leading the attacker effectively and making it choose non-
optimal strategies. Moreover, we notice that the behavior
of DD schemes is sensitive to node vulnerability, showing
the reduced MTTSF under high vulnerability because the
attacker can better exploit vulnerable nodes and more efﬁ-
ciently compromise them. Except insensitivity under high
vulnerability nodes, the performance trends in TPR of the
NIDS are well aligned with those in MTTSF under the four
schemes, as shown in Fig 3c. TPR can be improved under
DD-IPI due to the high effectiveness of DD under IPI.

We also discussed the probability of each strategy taken
by an attacker and a defender in Figs. 5 and 6 and TPR of
the NIDS in Fig. 7 of Appendix B with respect to the number
of attack-defense games played under each scheme in the
submitted supplement document.

7 CONCLUSION & FUTURE WORK
From this study, we obtained the following key ﬁndings:
• An attacker’s and defender’s perceived uncertainty can
be reduced when defensive deception (DD) is used. This
is because the attacker perceives more knowledge about
the system as it performs attacks as an inside attacker. On
the other hand, the defender’s uncertainty can be reduced
by collecting more attack intelligence by using DD while
allowing the attacker to be in the system.

• Attack cost and defense cost are two critical factors in
determining HEUs (hypergame expected utilities). There-
fore, high DHEU (defender’s HEU) is not necessarily
related to high system performance in MTTSF (mean time

(b) MTTSF

(c) TPR of an NIDS

Fig. 3. System lifetime (i.e., MTTSF) and true positive rate (TPR) of an
NIDS under varying the level of system vulnerability.

No-DD-IPI is because attackers are not allowed to stay in
a system if they are detected as compromised. This keeps
resetting the time the attacker has stayed in the system,
which makes the defender observe the same attacker for
a longer time.

In Figs. 2b and 2c, we further show DHEU and defense
cost for varying the vulnerability upper bound of nodes (Uv)
in the network. In Fig. 2b, compared to AHEU (i.e., 2.5 to 6),
we can observe much higher DHEU (i.e., 6 to 8.5). Since
HEU is estimated based on the impact and cost of taking a
chosen strategy, using DD costs more, leading to lowering
DHEU. Besides, under IPI, the defender may not choose its
optimal strategy all the time, lowering down DHEU due to
less beneﬁt of taking a chosen strategy. Hence, it is reason-
able to observe that the highest DHEU is obtained with No-
DD-PI while the lowest DHEU is observed with DD-IPI. In
Fig. 2c, as expected, the highest defense cost incurs under
DD-IPI while the lowest defense cost is observed under
No-DD-PI. This also reﬂects the role of the defense cost in
DHEU. DHEU and defense cost with respect to the number
of games are also discussed in Fig. 4 (c)-(d) in Appendix B
of the submitted supplement document.

In Fig. 3b, we showed how the four different schemes
perform under varying the extent of node vulnerability in

10

to security failure) or TPR (true positive rate) which can
also be a key indicator of system security. Therefore, using
DD under imperfect information (IPI) yields the best
performance in MTTSF (i.e., the longest system lifetime)
while it gives the minimum DHEU among all schemes.
• DD can effectively increase TPR of the NIDS in the system
based on the attack intelligence collected through the DD
strategies.

This work bring up some important directions for future
research by: (1) considering multiple attackers arriving in
a system simultaneously in order to consider more real-
istic scenarios; (2) estimating each player’s belief based
on machine learning in order to more correctly predict a
next move of its opponent; (3) dynamically adjusting a risk
threshold, i.e., Eq. (6), depending on a system’s security
state; (4) introducing a recovery mechanism to restore a
compromised node to a healthy node allowing the recovery
delay; (5) developing an intrusion response system that can
reassess a detected intrusion in order to minimize false
positives while identifying an optimal response strategy to
deal with intrusions with high urgency; and (6) considering
another intrusion prevention mechanism, such as moving
target defense, as one of the defense strategies.

ACKNOWLEDGEMENT
This research was partly sponsored by the Army Re-
search Laboratory and was accomplished under Cooper-
ative Agreement Number W911NF-19-2-0150. In addition,
this research is also partly supported by the Army Research
Ofﬁce under Grant Contract Number W91NF-20-2-0140. The
views and conclusions contained in this document are those
of the authors and should not be interpreted as representing
the ofﬁcial policies, either expressed or implied, of the Army
Research Laboratory or the U.S. Government. The U.S. Gov-
ernment is authorized to reproduce and distribute reprints
for Government purposes notwithstanding any copyright
notation herein.

REFERENCES
[1]

“Common vulnerability scoring system (CVSS).”
[Online]. Available: https://www.ﬁrst.org/cvss/
[2] Y. M. Aljefri, M. A. Bashar, L. Fang, and k. W. Hipel,
“First-level hypergame for investigating misperception
in conﬂicts,” IEEE Trans. Systems, Man, and Cybernetics:
Systems, vol. 48, no. 12, pp. 2158–2175, 2017.

[3] H. Almeshekah and H. Spafford, “Cyber security de-
ception,” in Cyber Deception. Springer, 2016, pp. 25–52.
[4] C. Bakker, A. Bhattacharya, S. Chatterjee, and D. L.
Vrabie, “Learning and information manipulation: Re-
peated hypergames for cyber-physical security,” IEEE
Control Systems Letters, vol. 4, no. 2, pp. 295–300, 2019.
[5] P. G. Bennett, “Toward a theory of hypergames,”

Omega, vol. 5, no. 6, pp. 749–751, 1977.

[6] E. Bertino and N. Islam, “Botnets and Internet of Things
security,” Computer, vol. 50, no. 2, pp. 76–79, Feb. 2017.
[7] M. Boussard, D. T. Bui, L. Ciavaglia, R. Douville, M. L.
Pallec, N. L. Sauze, L. Noirie, S. Papillon, P. Peloso,
and F. Santoro, “Software-deﬁned LANs for intercon-
nected smart environment,” in 2015 27th Int’l Teletrafﬁc
Congress, Sep. 2015, pp. 219–227.

[8] U. Brandes, “A faster algorithm for betweenness cen-
trality,” Jour. mathematical sociology, vol. 25, no. 2, pp.
163–177, 2001.
J. W. Caddell, “Deception 101-primer on deception,”
DTIC Document, Tech. Rep., 2004.

[9]

[10] T. E. Carroll and D. Grosu, “A game theoretic investi-
gation of deception in network security,” Security and
Communication Networks, vol. 4, no. 10, pp. 1162–1172,
2011.

[11] W. Casey, A. Kellner, P. Memarmoshreﬁ, J. A. Morales,
and B. Mishra, “Deception, identity, and security: The
game theory of Sybil attacks,” Comms. of the ACM,
vol. 62, no. 1, pp. 85–93, 2018.

[12] J.-H. Cho, M. Zhu, and M. P. Singh, Modeling and
Analysis of Deception Games based on Hypergame Theory.
Cham, Switzerland: Springer Nature, 2019, ch. 4, pp.
49–74.

[13] K. Ferguson-Walter, S. Fugate, J. Mauger, and M. Major,
“Game theory for adaptive defensive cyber deception,”
in Proc. 6th Annual Symp. on Hot Topics in the Science of
Security. ACM, 2019, p. 4.

[14] N. M. Fraser and K. W. Hipel, Conﬂict Analysis: Models

and Resolutions. North-Holland, 1984.

[15] N. Garg and D. Grosu, “Deception in honeynets: A
game-theoretic analysis,” in Proc. IEEE Information As-
surance and Security Workshop (IAW).
IEEE, 2007, pp.
107–113.

[16] B. Gharesifard and J. Cort´es, “Evolution of the percep-
tion about the opponent in hypergames,” in Proc. 49th
IEEE Conf. Decision and Control (CDC), Dec. 2010, pp.
1076–1081.

[17] ——, “Evolution of players’ misperceptions in hyper-
games under perfect observations,” IEEE Trans. Auto-
matic Control, vol. 57, no. 7, pp. 1627–1640, Jul. 2012.

[18] I. GmbH. MindNode.
//mindnode.com/

[Online]. Available: https:

[19] J. Han, J. Pei, and M. Kamber, Data Mining: Concepts

and Techniques. Elsevier, 2011.

[20] J. T. House and G. Cybenko, “Hypergame theory ap-
plied to cyber attack and defense,” in Proc. SPIE Conf.
Sensors, and Command, Control, Comms., and Intelligence
(C3I) Technologies for Homeland Security and Homeland
Defense IX, vol. 766604, May. 2010.

[21] T. Kanazawa, T. Ushio, and T. Yamasaki, “Replicator
dynamics of evolutionary hypergames,” IEEE Trans.
Systems, Man, and Cybernetics - Part A: Systems and
Humans, vol. 37, no. 1, pp. 132–138, Jan. 2007.

[22] N. S. Kovach, A. S. Gibson, and G. B. Lamont, “Hy-
pergame theory: A model for conﬂict, misperception,
and deception,” Game Theory, 2015, article ID 570639,
20 pages.

[23] K. Krombholz, H. Hobel, M. Huber, and E. Weippl,
“Advanced social engineering attacks,” Jour. Informa-
tion Security and Applications, vol. 22, pp. 113–122, 2015.
[24] S. Kyung, W. Han, N. Tiwari, V. H. Dixit, L. Srinivas,
Z. Zhao, A. Doup´e, and G. Ahn, “Honeyproxy: Design
and implementation of next-generation honeynet via
SDN,” in 2017 IEEE Conf. Comms. and Network Security
(CNS), Oct. 2017, pp. 1–9.

[25] O. Leiba, Y. Yitzchak, R. Bitton, A. Nadler, and A. Shab-
tai, “Incentivized delivery network of IoT software up-

11

dates based on trustless proof-of-distribution,” in 2018
IEEE European Symp. on Security and Privacy Workshops
(EuroS PW), Apr. 2018, pp. 29–39.

[26] Y. Liu, Y. Kuang, Y. Xiao, and G. Xu, “SDN-based data
transfer security for Internet of Things,” IEEE Internet
of Things Journal, vol. 5, no. 1, pp. 257–268, Feb. 2018.

[27] D. F. Macedo, D. Guedes, L. F. M. Vieira,
M. A. M. Vieira, and M. Nogueira, “Programmable
networks—from software-deﬁned radio to software-
deﬁned networking,” IEEE Comms. Surveys Tutorials,
vol. 17, no. 2, pp. 1102–1125, Second Quarter 2015.
[28] M. E. J. Newman, Networks: An introduction, 1st ed.

Oxford University Press, 2010.

[29] H. Okhravi, M. A. Rabe, W. G. Leonard, T. R. Hobson,
D. Bigelow, and W. W. Streilein, “Survey of cyber
moving targets,” Lexington Lincoln Lab, MIT, TR 1166,
2013.

[30] U. S. Putro, K. Kijima, and S. Takahashi, “Adaptive
learning of hypergame situations using a genetic algo-
rithm,” IEEE Trans. Systems, Man, and Cybernetics-Part
A: Systems and Humans, vol. 30, no. 5, pp. 562–572, Sep.
2000.

[31] Y. Sasaki, “Subjective rationalizability in hypergames,”
Advances in Decision Sciences, vol. 2014, no. Article ID
263615, p. 7 pages, 2014.

[32] A. Schlenker, O. Thakoor, h. Xu, F. Fang, M. Tambe,
L. Tran-Thanh, P. Vayanos, and Y. Vorobeychik, “De-
ceiving cyber adversaries: A game theoretic approach,”
in Proc. 17th Int’l Conf. Autonomous Agents and MultiA-
gent Systems, 2018, pp. 892–900.

[33] W. L. Sharp, “Military deception,” Joint War-Fighting
Center, Doctrine and Education Group, Norfolk, VA,
Pub. 3-13.4, 2006.
[34] S. Tadelis, Game Theory.

Princeton University Press,

2013.

[35] Y. W. Teh, Dirichlet Process. Boston, MA: Springer US,

2010, pp. 280–287.

[36] R. Vane, Hypergame theory for DTGT agents. AAAI,

2000.

[37] ——, “Planning for terrorist-caused emergencies,” in

Proc. Winter Simulation Conf., Dec. 2005.

[38] ——, “Advances in hypergame theory,” in Proc. AA-
MAS Workshop on Game-Theoretic and Decision Theoretic
Agents, 2006.

[39] R. Vane and P. E. Lehner, “Using hypergames to select
plans in adversarial environments,” in Proc. 1st Work-
shop on Game Theoretic and Decision Theoretic Agents,
1999, pp. 103–111.

[40] Wikipedia. (2018) Foureye butterﬂyﬁsh. Available at
https://en.wikipedia.org/wiki/Foureye butterﬂyﬁsh.
[41] Y. Yin, B. An, Y. Vorobeychik, and J. Zhuang, “Optimal
deceptive strategies in security games: A preliminary
study,” in Proc. AAAI Conf. Artiﬁcial Intelligence, 2013.

12

APPENDIX

APPENDIX A
HYPERGAME THEORY

In this section, we brieﬂy discuss hypergame theory which
is mainly leveraged to propose the hypergame theoretic
defensive deception framework that deals with APT attacks
in this work. This section was mainly used in Section 4 of
the main paper.

Hypergame theory offers two levels of hypergames that
can be used to analyze games differently perceived by
multiple players [14]. We adopt ﬁrst-level hypergames for
simplicity. Although hypergame theory applies to multiple
players, we consider a game of two players, an attacker and
a defender.

A.1 First-Level Hypergame

Given two players, p and q, vectors of their preferences,
denoted by Vp and Vq, deﬁne game G that can be repre-
sented by G = {Vp, Vq} [14]. Note that Vp and Vq are player
p’s and player q’s actual preferences (i.e., ground truth),
respectively. If all players exactly know all other players’
preferences, all players are playing the same game because
their view of the game is the same. However, in reality,
that assumption may fail. Player p can perceive player q’s
preferences differently from what they are, leading to dif-
ferences between p’s view and q’s view. A game perceived
by player p based on its perceived preferences about q’s
preferences, Vqp, and the game perceived by player q based
on its perceived preferences about p’s preferences, Vpq, can
be given by

Gp = {Vqp}, Gq = {Vpq}

(16)

Hence, the ﬁrst-level hypergame H perceived by each player
is written by H1 = {Gp, Gq}. In a ﬁrst-level hypergame,
analysis is performed at the level of each player’s perceived
game because each player plays the game based on its belief.
Even if the player does not know all outcomes of the game,
the outcome can be stable for the player because the player
may not unilaterally change its belief. If a game includes
an unknown outcome, the unknown outcome is caused by
the uncertainty. The stability of an outcome about a game
is determined by each player’s reaction to the action by the
opponent. An outcome is stable for p’s game if the outcome
is stable in each of p’s perceived preference vectors, i.e., in
each Vqp. The equilibrium of p’s game is determined by the
outcome that p believes to resolve the conﬂict [14].

A.2 Hypergame Normal Form (HNF)

Vane [38] provides a hypergame normal form (HNF) that
can succinctly model hypergames based on players’ beliefs
and possible strategies of their opponents. HNF is formu-
lated, similar to the normal strategic form in game theory.
HNF consists of the following four key aspects: (1) full
game; (2) row-mixed strategies (RMSs); (3) column-mixed
strategies (CMSs); and (4) belief contexts.

The full game is the grid form consisting of row and
column strategies, which are associated with the utilities,
ru11, · · · , rumn and cu11, · · · , cumn where m is the number
of the row player’s strategies and n is the number of the

column player’s strategies. The full game’s grid form U can
be represented by an m×n matrix with an element ruij, cuij
for i = 1, · · · , m and j = 1, · · · , n.





U =

(ru11, cu11)
· · ·
(rum1, cum1)

· · ·
· · ·
· · ·

(ru1n, cu1n)
· · ·
(rumn, cumn)



 ,

(17)

where R0 and C0 denote the full-game strategies by the row
and column players, respectively.
Row-mixed strategies (RMSs) are m strategies the row
player considers based on its belief of the column player’s
strategies. A player’s subgame is deﬁned as a subset of the
full game (i.e., a set of all possible strategies by all players)
because the player may limit a number of strategies it wants
to consider based on its belief. Therefore, depending on a
situation, the player can choose a subgame to play. RMSs
for the κ-th subgame a player perceives are given by:

RMSκ = [rκ1, · · · , rκm], where

m
(cid:88)

i=1

rκi = 1,

(18)

where each probability that a particular strategy i is chosen
is estimated by player p’s belief based on learning from past
experience. Since a subgame consists of a subset of strategies
in a full game, if a particular strategy i is not in the subgame
κ, the probability for the row player to take strategy i at
subgame κ is zero, i.e., rκi = 0.
Column-mixed strategies (CMSs) are a column player’s n
strategies, believed by a row player for a κ-th subgame,
which are denoted by:

CMSκ = [cκ1, · · · , cκn], where

n
(cid:88)

j=1

cκj = 1,

(19)

where each probability that particular strategy j is chosen
is obtained by player p’s observations (or learning) towards
q’s strategies. Similar to the row-mixed strategies, if strategy
j is not in subgame κ, we set cκj = 0.

Belief contexts are the row player’s belief probabilities that
each subgame κ will be played and are represented by:

P = [P0, · · · , PK ], where

K
(cid:88)

κ=0

Pκ = 1.

(20)

P0 is the probability that the full game is played where
the full game considers all possible strategies of a player
based on the ground truth view of a situation. If the row
player is not sure of what subgame κ to played due to
perceived uncertainty, the unknown belief probability is
treated simply for the probability that a full game is played,
denoted by P0 = 1 − (cid:80)K

κ=1 Pκ.

The row player’s belief towards the column player’s

strategy j, denoted by Sh, is computed by:

Sj =

K
(cid:88)

κ=0

Pκcκj where

n
(cid:88)

j=1

Sj = 1.

(21)

The summary of
the row player’s belief on the col-
umn player’s n strategies is represented by C(cid:80) =
[S1, S2, · · · , Sn].

13

A.3 Hypergame Expected Utility

The hypergame expected utility (HEU) can be calculated
based on EU(·), and the uncertainty probability perceived
by the row player, denoted by g, representing the level of
uncertainty about what is guessed about a given game. g
affects the degree of the EU(·) of a given hyperstrategy by
the row player. HEU for the given row player’s strategy rsi
with uncertainty g is given by [36]:

HEU(rsi, g) = (1 − g) · EU (rsi, C(cid:80)) + g · EU (rsi, CMSw),
(22)
where rsi
is a given strategy i by the row player.
EU(rsi, C(cid:80)) refers to the row player’s expected utility in
choosing strategy i when the column player can take a
strategy among all available strategies n. EU(rsi, CMSw)
indicates the row player’s expected utility when choosing
strategy i when the column player chooses strategy w which
gives the minimum utility to the row player. EU(rsi, C(cid:80))
and EU(rsi, CMSw) are computed by:

EU(rsi, C(cid:80)) =

n
(cid:88)

j=1

Sj · uij,

EU(rsi, CMSw) = n · Sw · uiw

(23)

(24)

where g = 0 means complete conﬁdence (i.e., complete
certainty) in a given strategy while g = 1 implies that the
row player is completely occupied with the fear of being
outguessed (i.e., complete uncertainty) [38].

The calculation of EU(rsi, CMSw) is based on a pes-
simistic perspective in that when a player is uncertain,
it estimates utility based on the worst scenario. In our
work, we consider a realistic scenario in that the player
will simply choose a random strategy among strategies in
a given subgame. For the defender, when it is uncertain, it
will simply play a full game because it does not know what
subgame the attacker plays. Note that the utility values will
be normalized using min-max normalization method [19].

APPENDIX B
ADDITIONAL EXPERIMENTAL RESULTS
B.1 Strategy Cost and Hypergame Expected Utility of
the Attacker and Defender

Fig. 4 shows the attack cost, defense cost, and the HEUs of
the attacker and defender, respectively, with respect to the
number of games played between the attacker and defender
when the default setting is used based on Table 5. Note
that we only showed the number of games from the 2nd
game for meaningful analysis. The main reason of high
ﬂuctuations in later games is because only a small number
of simulation runs have long system lifetimes, resulting
in high variances. We can clearly see the similar trends
observed in Fig. 2 of the main paper in that No-DD-based
schemes have shorter lifetimes while DD-based schemes
show much higher system lifetime, which was measured
based on MTTSF in Fig. 4 of this document. Aligned with
the trends observed in Fig. 2 of the main paper, in Fig. 4a,
we can observe that when DD-IPI is used, the attacker
incurs higher cost than other schemes as it is less likely
to choose an optimal strategy, which is cost-effective, due
to the confusion or uncertainty introduced by DD-IPI. But

TABLE 5
TABLE OF NOTATIONS

Meaning

Cost of attack strategy k (main paper)
Cost of defense strategy k (main paper)
Thresholds for SF in Eq. (8) in the main paper
Number of low-interaction honeypots deployed
but not activated in a network
Number of high-interaction honeypots deployed
but not activated in a network
Number of Web servers deployed in a network
Number of databases deployed in a network
Number of IoT nodes deployed in a network
Total number of nodes
Total number of security vulnerabilities of node
i, including encryption (5), software (5), and un-
known (1)
Probability of two nodes being connected in an
Erd ¨os-R´enyi random network
An attacker’s deception detectability
A constant for normalization for the attacker’s un-
certainty and defender’s uncertainty, respectively
Probabilities of false positives and false negatives
in the NIDS
Risk threshold used in Eq. (6) in the main paper
The threshold used in AS8 (Data exﬁltration)
Increased or decreased percent of a given vulner-
ability probability by taking attack strategies (i.e.,
AS5, AS7) or defense strategies (i.e., DS1 −DS3)
Probability the attacker obtains a fake key
Percentage (%) of edges that are hidden by defense
strategy DS8

Symbol
ack
dck
ρ1, ρ2
NLH

NHH

NWS
NDB
NIoT
N
nvi

P r

ad
λ, µ

Pf p,
Pf n
Thrisk
Thc
(cid:15)1, (cid:15)2

Pf ake
cN T

Default

Table 2
Table 3
1/3, 1/2
50

25

25
25
450
500
11

0.05

[0, 0.5]
0.8, 8

0.01, 0.1

0.2
150
0.1, 0.01

1 − ad
20

under DD-PI, by taking the beneﬁt of perfect information
(PI) available, the attacker can take a better action incurring
less cost. When No-DD is used, the attacker does not have to
use various attack strategies that can be useful as an insider
attack because it is less likely to be the inside attacker due to
the immediate eviction by the NIDS. In addition, there is no
chance for the system to intentionally allow them to be in
the system for collecting further attack intelligence. Hence,
the attacker can use a limited set of attack strategies that do
not incur high cost.

In Fig. 4b, we demonstrated the attacker’s hypergame
expected utility (AHEU) with respect to the number of
games played between the attacker and the defender in the
default setting. Under DD-based schemes, when PI is used,
higher AHEU is obtained. On the other hand, imperfect
information (IPI) hinders the attacker to choose optimal
strategies, leading to less AHEU. This was indirectly exhib-
ited that the proposed DD strategies under uncertainty were
effective to confuse the attacker. When No-DD is used, PI
helps the attacker to make better attack decisions than IPI.

Similarly we demonstrated the defense cost in Fig. 4c
and the defender’s HEU (DHEU) in Fig. 4d. Under DD-
based schemes, in terms of the data availability with respect
to the number of games, the system lifetime is observed
longer than under No-DD-based schemes with the same
reasons explained in the attack cost and AHEU as above. As
expected, PI helps the defender to choose better strategies
due to no uncertainty perceived than IPI. However, using
DD strategies introduces additional cost to achieve better
security than using No-DD-based strategies. Hence, DD-IPI
incurs minimum DHEU overall. However, note that this
doesn’t mean DD-IPI has less beneﬁt in system security;
rather it implies that there is cost to achieve enhanced
security.

14

(a) Attack cost

(b) Attacker’s HEU

(c) Defense cost

(d) Defense HEU

Fig. 4. Attack cost and defense cost along with the attacker’s hypergame expected utility (AHEU) and the defender’s HEU (DHEU). The performance
is shown from the second game.

B.2 Probabilities of Attack Strategies

Fig. 5 shows the probabilities of each attack strategy taken,
denoted by P A
S , with respect to the number of games played
between the attacker and defender under the four schemes.
Under all the four schemes, attack strategy 1, AS1 (scanning
attack), is dominantly taken. This is because every attacker
starts from scanning a target system in the stage of recon-
naissance (R) in the cyber kill chain (CKC), which is the
ﬁrst step of the advanced persistent threat (APT) attacks.
In addition, due to the presence of the NIDS, when the
attacker successfully penetrated into the system, it is highly
likely for the attacker to be detected by the NIDS with fairly
high detection rate (i.e., Ppf = 0.01 and Ppn = 0.1). In
addition, only a compromised node or an attacker, which
are not detected by the NIDS or passed the risk threshold
(Thrisk; see Eq. (6) in the main paper), can only remain in
the system. Hence, there won’t be many insider attackers
compared to outsider attackers. Hence, observing the high-
est probability using scanning attack (AS1) is natural. In
addition, as the attacker tries to get into the system by using
social engineering attacks (AS2) exploiting both software
and encryption vulnerabilities, it is reasonable to observe
the attacker taking AS2 as the second most attack strategy.
In Figs. 5a and 5b, when DD strategies are used, AS5 and
AS7 are commonly taken. This is because these two attack
strategies, AS5 and AS7, relatively incur less cost (1 and 2
for attack costs, respectively). When No-DD strategies are
used, it is reasonable to observe that the attacker mainly
uses AS1 and AS2 as it does not have many chances to use
other strategies due to being detected by the NIDS. When

PI is used, the defender also knows more about the attacker
due to no uncertainty. This makes the attacker being evicted
quicker and more new attackers are likely to attempt to
access the defense system. Hence, the attacker uses social
engineering attacks (AS2) more frequently in the later games
when PI is used than when IPI is used.

B.3 Probabilities of Defense Strategies

Fig. 6 shows the probabilities of the eight defense strategies
(P D
S ) used under the four schemes with respect to the
number of games played between the attacker and defender.
Under all the four schemes, defense strategy 1, DS1 (ﬁre-
wall), is dominantly used as it deals with outside attackers.
However, when DD-IPI is used, DS2 (patch management)
and DS6 (honey information) were used more commonly
compared to other defense strategies. This is because these
two defense strategies cost less, which makes the corre-
sponding DHEU higher, ultimately leading the defender to
choose DS2 and DS6 more often than other strategies. When
No-DD strategies are used, DS1 and DS2 are mainly used
while DS3 and DS4 are marginally used.

B.4 TPR of the NIDS With Respect To the Number of
Games

Fig. 7 shows the TPR of the NIDS with respect to the number
of games played between the attacker and defender. As
expected, since DD-based schemes allow the defender to
learn additional attack intelligence which is considered in
the NIDS, this naturally leads to the improvement of the
TPR in the NIDS.

15

(a) Under DD-IPI

(b) Under DD-PI

Fig. 5. The probabilities of attack strategies under the four schemes. The performance is shown from the second game.

(c) Under No-DD-IPI

(d) Under No-DD-PI

APPENDIX C
REPRESENTATIONS OF MODELED ATTACK AND DE-
FENSE STRATEGIES, HEUS, AND NIDS USING THE
MIND MAP
For Figs. 8-11, we demonstrated the Mind Maps on how
attack and defense strategies are designed, how AHEU and
DHEU are estimated, and how the NIDS operates in the
given system. These Mind Maps are based on Eqs. (19)-
(24) in this supplement document and Eqs. (9) and (10)
in the main paper. For Fig. 11, we described the workﬂow
on how the NIDS operates in the considered system where
each number refers to an execution step. We demonstrated
these Mind Maps in order for readers to clearly follow the
algorithms used in this work for easy reproducibility. For
the demonstrated Mind Maps, we used the Mind Maps tool
called the MindNode [18].

16

(a) Under DD-IPI

(b) Under DD-PI

Fig. 6. Probabilities of defense strategies under the four schemes. The performance is shown from the second game.

(c) Under No-DD-IPI

(d) Under No-DD-PI

Fig. 7. True positive rate (TPR) of the NIDS.

17

Fig. 8. Modeling Attack Strategies.

Fig. 9. Modeling Defense Strategies.

Fig. 10. Modeling HEU.

18

Fig. 11. Modeling NIDS.

19

