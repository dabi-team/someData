6
1
0
2

l
u
J

5
2

]

C
O
.
h
t
a
m

[

1
v
0
5
3
7
0
.
7
0
6
1
:
v
i
X
r
a

Corruption and botnet defense: a mean ﬁeld game
approach ∗

V. N. Kolokoltsov†and O. A. Malafeyev‡

September 1, 2021

Abstract

Recently developed toy models for the mean-ﬁeld games of corruption and bot-
net defence in cyber-security with three or four states of agents are extended to
a more general mean-ﬁeld-game model with 2d states, d ∈ N. In order to tackle
new technical diﬃculties arising from a larger state-space we introduce new asymp-
totic regimes, namely small discount and small interaction asymptotics. Moreover,
the link between stationary and time-dependent solutions is established rigorously
leading to a performance of the turnpike theory in a mean-ﬁeld-game setting.

Key words: mean-ﬁeld game, stable equilibrium, turnpike, botnet defense, cyber-

security, corruption, inspection, social norms, disease spreading

Mathematics Subject Classiﬁcation (2010): 91A06, 91A15, 91A40, 91F99

1

Introduction

Toy models for the mean-ﬁeld games of corruption and botnet defense in cyber-security
were developed in [18] and [17]. These were games with three and four states of the
agents respectively. Here we develop a more general mean-ﬁeld-game model with 2d
states, d ∈ N, that extend the models of [18] and [17]. In order to tackle new technical
diﬃculties arising from a larger state-space we introduce new asymptotic regimes, small
discount and small interaction asymptotics. Hence the properties that we obtain for the
new model do not cover more precise results of [18] and [17] (with the full classiﬁcation of
the bifurcation points), but capture their main qualitative and quantitative features and
provide regular solutions away from the points of bifurcations. Apart from new modeling,
this paper contributes to one of the key questions in the modern study of mean-ﬁeld games,
namely, what is the precise link between stationary and time -dependent solutions. This
problem is sorted out here for a concrete model, but the method can be deﬁnitely used
in more general situations.

∗Supported by RFFI grant No 14-06-00326
†Department
Statistics, University

of

v.kolokoltsov@warwick.ac.uk and associate member of
CSC RAS

Institute of

‡Fac. of Appl. Math. and Control Processes, St.-Petersburg State Univ., Russia

1

of Warwick, Coventry CV4

7AL UK, Email:
Informatics Problems, FRC

 
 
 
 
 
 
On the one hand, our model is a performance of the general pressure-and-resistance-
game framework of [16] and the nonlinear Markov battles of [15], and on the other hand, it
represents a simple example of mean-ﬁeld- and evolutionary-game modeling of networks.
Initiating the development of the latter, we stress already here that two-dimensional arrays
of states arise naturally in many situations, one of the dimensions being controlled mostly
by the decision of agents (say, the level of tax evasion in the context of inspection games)
and the other one by a principal (major player) or evolutionary interactions (say, the level
of agents in bureaucratic staircase, the type of a computer virus used by botnet herder,
etc).

We shall dwell upon two basic interpretations of our model: corrupted bureaucrats
playing against the principal (say, governmental representative, also referred in literature
as benevolent dictator) or computer owners playing against a botnet herder (which then
takes the role of the principal), which tries to infect the computers with viruses. Other
interpretations can be done, for instance, in the framework of the inspection games (in-
spector and tax payers) or of the disease spreading in epidemiology (among animals or
humans), or the defense against a biological weapon. Here we shall keep the principal in
the background concentrating on the behavior of small players (corrupted bureaucrats or
computer owners), which we shall refer to as agents or players.

The paper is organized as follows. In the next section we introduce our model specify-
ing in this context the basic notions of the mean-ﬁeld-game (MFG) consistency problem in
its dynamic and stationary versions. In section 3 we calculate explicitly all non-degenerate
solutions of the stationary MFG problem. In section 4 we show how from a stationary
solution one can construct a class of full time-dependent solutions satisfying the so-called
turnpike property around the stationary one.

We complete this introductory section with short bibliographical notes.
Analysis of the spread of corruption in bureaucracy is a well recognized area of the
application of game theory, which attracted attention of many researchers. General sur-
veys can be found in [1], [14], [23]. More recent literature is reviewed in [18], see also [26],
[2] for electric and engineering interpretations of corruption games.

The use of game theory in modeling attacker-defender has been extensively adopted
in the computer security domain recently, see [7], [24] and [25] and bibliography there for
more details.

Mean-ﬁeld games present a quickly developing area of the game theory. Their study
was initiated by Lasry-Lions [22] and Huang-Malhame-Caines [13] and has been quickly
developing since then, see [3], [6], [12], [11], [8] for recent surveys, as well as [9], [10], [4],
[21] [28], [5] and references therein for some further developments.

2 The model

We assume that any agent has 2d states: iI and iS, where i ∈ {1, · · · , d} and is referred
to as a strategy. In the ﬁrst interpretation the letters S or I designate the senior or initial
position of a bureaucrat in the hierarchical staircase and i designates the level or type of
corruptive behavior (say, the level of bribes one asks from customers or, more generally,
the level of illegal proﬁt he/she aims at). In the literature on corruption the state I is
often denoted by R and is referred to as the reserved state. It is interpreted as a job of
the lowest salary given to the not trust-worthy bureaucrats. In the second interpretation

2

the letters S or I designate susceptible or infected states of computers and i denotes the
level or the type of defense system available on the market.

We assume that the choice of a strategy depends exclusively on the decision of an
agent. The control parameter u of each player may have d values denoting the strategy
the agent prefers at a moment. As long as this coincides with the current strategy, the
updating of a strategy does not occur. Once the decision to change i to j is made, the
actual updating is supposed to occur with a certain rate λ. Following [17], we shall be
mostly interested in the asymptotic regime of fast execution of individual decisions, that
is, λ → ∞.

The change between S and I may have two causes: the action of the principal (pressure
game component) and of the peers (evolutionary component). In the ﬁrst interpretation
the principal can promote the bureaucrats from the initial to the senior position or de-
grade them to the reserved initial position, whenever their illegal behavior is discovered.
The peers can also take part in this process contributing to the degrading of corrupted
bureaucrats, for instance, when they trespass certain social norms.
In the second in-
terpretation the principal, the botnet herder, infects computers with the virus by direct
attacks turning S to I, and the virus then spreads through the network of computers by
a pairwise interaction. The recovery change from I to S is due to some system of repairs
which can be diﬀerent in diﬀerent protection levels i.

Let qi

+ denote the recovery rates of upgrading from iR to iS and qi

− the rates of
degrading (punishment or infection) from state iR to iS, which are independent of the
state of other agents (pressure component), and let βij denote the rates at which an agent
in state iI can stimulate the degrading (punishment or infection) of another agent from jS
to jI (evolutionary component). For simplicity we ignore here the possibility of upgrading
changes from jS to jI due to the interaction with peers.

A state of the system is a vector n = (n1S, n1I, · · · , ndS, ndI) with coordinates pre-
senting the number of agents in the corresponding states, or its normalized version
x = (x1S, x1I, · · · , xdS, xdI) = n/N with N = n1S + n1I + · · · + ndS + ndI the total
number of agents.

Therefore, assuming that all players have the same strategy ucom

t = {ucom(iS), ucom(iI)},
the evolution of states in the limit of large number of players N → ∞ is given by the
equations

˙xiI = λ

xjI1(ucom(jI) = i) − λ

xiI 1(ucom(iI) = j) + xiSqi

− − xiIqi

+ +

˙xiS = λ

j6=i
X

j6=i
X

xjS1(ucom(jS) = i) − λ

j6=i
X

j6=i
X

xiS1(ucom(iS) = j) − xiSqi

− + xiIqi

+ −

xiSxjIβji,

j
X

xiSxjIβji,

j
X

(1)

for all i = 1, · · · , d. Here and below 1(M) denotes the indicator function of a set M.

Remark 1. It is well known that evolutions of this type can be derived rigorously as the
dynamic law of large numbers for the corresponding Markov models of a ﬁnite number of
players, see detail e.g. in [15] or [16].

To specify the optimal behavior of agents we have to introduce payoﬀs in diﬀerent
states and possibly costs for transitions. For simplicity we shall ignore here the latter.
Talking about corrupted agents it is natural to talk about maximizing proﬁt, while talking

3

about infected computers it is natural to talk about minimizing costs. To unify the exposi-
tion we shall deal with the minimization of costs, which is equivalent to the maximization
of their negations.
I and wi

S denote the costs per time-unit of staying in iI and iS respectively.

Let wi

According to our interpretation of S as a better state, wi

S < wi

I for all i.

Given the evolution of the states x = x(s) of the whole system on a time interval [t, T ],
s (iI)

the individually optimal costs g(iI) and g(iS) and individually optimal control uind
and uind

s (iS) can be found from the HJB equation

˙g(iI) + λ min

u

d

j=1
X
d

˙g(iS) + λ min

u

d

+

j=1
X

1(u(iI) = j)(g(jI) − g(iI)) + qi

+(g(iS) − g(iI)) + wi

I = 0,

1(u(iS) = j)(g(jS) − g(iS)) + qi

−(g(iI) − g(iS))

(2)

j=1
X
βjixjI(s)(g(iI) − g(iS)) + wi

S = 0.

The basic MFG consistency equation for a time interval [t, T ] can now be written as

ucom
s = uind

s

.

Remark 2. The reasonability of this condition in the setting of the large number of
players is more or less obvious. And in fact in many situations it was proved rigorously
that its solutions represent the ǫ-Nash equilibrium for the corresponding Markov model of
N players, with ǫ → 0 as N → ∞, see e.g. [4] for ﬁnite state models considered here.

In this paper we shall mostly work with discounted payoﬀ with the discounting coef-
ﬁcient δ > 0, in which case the HJB equation for the discounted optimal payoﬀ e−sδg of
an individual player with any time horizon T writes down as

˙g(iI) + λ min

u

d

j=1
X
d

˙g(iS) + λ min

u

d

+

j=1
X

1(u(iI) = j)(g(jI) − g(iI)) + qi

+(g(iS) − g(iI)) + wi

I = δg(iI),

1(u(iS) = j)(g(jS) − g(iS)) + qi

−(g(iI) − g(iS))

(3)

j=1
X
βjixjI(s)(g(iI) − g(iS)) + wi

S = δg(iS).

Notice that since this is an equation in a Euclidean space with Lipschitz coeﬃcients,
it has a unique solution for s ≤ T and any given boundary condition g at time T and any
measurable functions xiI (s).

For the discounted payoﬀ the basic MFG consistency equation ucom

for a time in-
terval [t, T ] can be reformulated by saying that x, u, g solve the coupled forward-backward
system (1), (3), so that ucom
used in (1) coincide with the minimizers in (3). The main
objective of the paper is to provide a general class of solutions of the discounted MFG
consistency equation with stationary (time-independent) controls ucom

s = uind

.

s

s

s

4

As a ﬁrst step to this objective we shall analyse the fully stationary solutions, when

the evolution (1) is replaced by the corresponding ﬁxed point condition:

λ

λ

j6=i
X

xjI1(ucom(jI) = i) − λ

xjS1(ucom(jS) = i) − λ

j6=i
X

xiI1(ucom(iI) = j) + xiSqi

− − xiI qi

+ +

xiS1(ucom(iS) = j) − xiSqi

− + xiIqi

+ −

j
X

xiSxjIβji = 0,

xiSxjIβji = 0.

j6=i
X

j6=i
X

(4)
There are two standard stationary optimization problems naturally linked with a dy-
namic one, one being the search for the average payoﬀ for long period game, and another
the search for discounted optimal payoﬀ. The ﬁrst is governed by the solutions of HJB of
the form (T − s)µ + g, linear in s (then µ describing the optimal average payoﬀ), so that
g satisﬁes the stationary HJB equation:

j
X

λ min
u

λ min
u

d

j=1
X
d

j=1
X

+

1(u(iI) = j)(g(jI) − g(iI) + cij) + qi

+(g(iS) − g(iI)) + wi

I = µ,

1(u(iS) = j)(g(jS) − g(iS) + cij) + qi

−(g(iI) − g(iS))

(5)

βjixjI(g(iI) − g(iS)) + wi

S = µ.

d

j=1
X

In the second problem, if the discounting coeﬃcient is δ, the stationary discounted

optimal payoﬀ g satisﬁes the stationary version of (3):

λ min
u

λ min
u

d

j=1
X
d

j=1
X

+

1(u(iI) = j)(g(jI) − g(iI) + cij) + qi

+(g(iS) − g(iI)) + wi

I = δg(iI),

1(u(iS) = j)(g(jS) − g(iS) + cij) + qi

−(g(iI) − g(iS))

(6)

βjixjI(g(iI) − g(iS)) + wi

S = δg(iS).

d

j=1
X

In [18] and [17] we concentrated on the ﬁrst approach, and here we shall concentrate
on the second one, with a discounted payoﬀ. The stationary MFG consistency condition
is the coupled system of equations (4) and (6), so that the individually optimal stationary
control uind found from (6) coincides with the common stationary control ucom from (4).
For simplicity we shall be interested in non-degenerate controls uind characterized by

the condition that the minimum in (6) is always attained on a single value of u.

A new technical novelty as compared with [17] and [18] will be systematic working
in the asymptotic regimes of small discount δ and small interaction coeﬃcients βij. This
approach leads to more or less explicit calculations of stationary MFG solutions and their
further justiﬁcation.

5

3 Stationary MFG problem

The following result identiﬁes all possible stationary non-degenerate controls that can
occur as solutions of (6).

Proposition 3.1. Non-degenerate controls solving (6) could be only of the type [i(I), k(S)]:
switch to strategy i when in I and to k when in S.

Proof. If moving from the strategy k to the strategy i is optimal, then g(i) < g(l) for all
l and hence moving from m to i is optimal for any m.

Let us consider ﬁrst the control [i(I), i(S)] denoting it by ˆui:

ˆui(jS) = ˆui(jI) = i,

j = 1, · · · , d.

We shall refer to the control ˆui as the one with the strategy i individually optimal.

The control ˆui and the corresponding distribution x solve the stationary MFG problem

if they solve the corresponding HJB (6), that is

qi
+(g(iS) − g(iI)) + wi
qi
−(g(iI) − g(iS)) +

I = δg(iI),

βkixkI(g(iI) − g(iS)) + wi

S = δg(iS),

λ(g(iI) − g(jI)) + qj
λ(g(iS) − g(jS)) + qj

k
X
+(g(jS) − g(jI)) + wj
−(g(jI) − g(jS))

I = δg(jI),

j 6= i,

(7)

+

βkjxkI(g(jI) − g(jS)) + wj

S = δg(jS),

j 6= i,

k
X






where for all j 6= i

and x is a ﬁxed point of the evolution (4) with ucom = ˆui, that is

g(iI) ≤ g(jI),

g(iS) ≤ g(jS),

xiSqi

− − xiI qi

+ +

− xiSqi

− + xiI qi

j
X
+ −

xiSxjIβji + λ

xjI = 0,

j6=i
X
xiSxjIβji + λ

xjS = 0,

xjSqj

− − xjIqj

+ +

j
X

j6=i
X

xjSxkIβkj − λxjI = 0,

j 6= i,

− xjSqj

− + xjIqj

k
X
+ −

xjSxkIβji − λxjS = 0,

j 6= i.






This solution (ˆui, x) is stable if x is a stable ﬁxed point of the evolution (1) with

ucom = ˆui, that is, of the evolution

(8)

(9)

k
X

6

˙xiI = xiSqi

− − xiIqi

+ +

xiSxjIβji + λ

xjI,

j
X

j6=i
X

˙xiS = −xiSqi

− + xiIqi

+ −

˙xjI = xjSqj

− − xjIqj

+ +

xiSxjIβji + λ

xjS,

j
X

j6=i
X
xjSxkIβkj − λxjI,

j 6= i,

(10)

˙xjS = −xjSqj

− + xjIqj

+ −

k
X

xjSxkIβji − λxjS,

j 6= i.






k
X
Adding together the last two equations of (9) we ﬁnd that xjI = xjS = 0 for j 6= i, as

one could expect. Consequently, the whole system (9) reduces to the single equation

which, for y = xiI , 1 − y = xiS, yields the quadratic equation

xiSqi

− + xiI βiixiS − xiIqi

+ = 0,

Q(y) = βiiy2 + y(qi

+ − βii + qi

−) − qi

− = 0,

with the unique solution on the interval (0, 1):

x∗ =

1
2βii (cid:20)

βii − qi

+ − qi

− +

q

(βii + qi

−)2 + (qi

+)2 − 2qi

+(βii − qi

−)

.

(cid:21)

(11)

To analyze stability of the ﬁxed point xiI = x∗, xiS = 1 − x∗ and xjI = xjS = 0 for
j 6= i, we introduce the variables y = xiI − x∗. In terms of y and xjI, xjS with j 6= i,
system (10) rewrites as

˙y = [1 − x∗ − y −

(xjI + xjS)][q− +

xkIβki + (y + x∗)βii] − (y + x∗)qi

+ + λ

xjI,






˙xjI = xjS[qj

− +

j6=i
X
xkIβkj + (y + x∗)βij] − xjIqj

k6=i
X

+ − λxjI,

j 6= i,

k6=i
X

˙xjS = −xjS[qj

− +

xkIβkj + (y + x∗)βij] + xjIqj

+ − λxjS,

j 6= i.

k6=i
X

Its linearized version around the ﬁxed point zero is

˙y = (1 − x∗)(

xkIβki + yβii) − [y +

(xkI + xkS)](qi

− + x∗βii) − yqi

+ +

j6=i
X

(12)

λxkI,

k6=i
X

k6=i
X

− + x∗βij) − xjIqj

˙xjI = xjS(qj
˙xjS = −xjS(qj




Since the equations for xjI, xjS contain neither y nor other variables, the eigenvalues
of this linear system are

− + x∗βij) + xjIqj

+ − λxjS,

+ − λxjI,

j 6= i.

j 6= i,

k6=i
X

and (d − 1) pairs of eigenvalues arising from (d − 1) systems

ξi = (1 − 2x∗)βii − qi

− − qi
+,

˙xjI = xjS(qj
˙xjS = −xjS(qj

(

− + x∗βij) − xjIqj

+ − λxjI,

− + x∗βij) + xjIqj

+ − λxjS,

j 6= i,

j 6= i,

7

that is

(

1 = −λ − (qj
ξj
ξj
2 = −λ.

+ + qj

− + x∗βii)

These eigenvalues being always negative, the condition of stability is reduced to the

negativity of the ﬁrst eigenvalue ξi:

2x∗ > 1 −

+ + qi
qi
−
βii

.

But this is true due to (11) implying that this ﬁxed point is always stable (by the Grobman-
Hartman theorem).

Next, the HJB equation (7) takes the form

I = δg(iI),

qi
+(g(iS) − g(iI)) + wi
qi
−(g(iI) − g(iS)) + βiix∗(g(iI) − g(iS)) + wi
λ(g(iI) − g(jI)) + qj
λ(g(iS) − g(jS)) + qj

+(g(jS) − g(jI)) + wj
−(g(jI) − g(jS))

S = δg(iS),

I = δg(jI),

j 6= i,

(13)

+ βijx∗(g(jI) − g(jS)) + wj

S = δg(jS),

j 6= i,






Subtracting the ﬁrst equation from the second one yields

g(iI) − g(iS) =

wi
I − wi
S
− + qi
qi
+ + βiix∗ + δ

.

In particular, g(iI) > g(iS) always, as expected. Next, by the ﬁrst equation of (13),

δg(iI) = wi

I −

+(wi
qi
qi
− + qi

I − wi
S)
+ + βiix∗ + δ

.

Consequently,

δg(iS) = wi

I −

(qi
+ + δ)(wi
− + qi
qi

I − wi
S)
+ + βiix∗ + δ

= wi

S +

− + βiix∗)(wi
(qi
− + qi
qi

I − wi
S)
+ + βiix∗ + δ

.

Subtracting the third equation of (13) from the fourth one yields

(14)

(15)

(16)

(λ + qj

+ + qj

− + βiix∗ + δ)(g(jI) − g(jS)) − λ(g(iI) − g(iS)) = wi

I − wi
S,

implying

g(jI) − g(jS) =

wj
I − wj
λ + qj

S + λ(g(iI) − g(iS))
+ + qj
S) − (g(iI) − g(iS))(qj

− + βijx∗ + δ
+ + qj

= g(iI) − g(iS) + [(wj

I − wj

− + βijx∗ + δ)]λ−1 + O(λ−2). (17)

From the fourth equation of (13) it now follows that

(δ + λ)g(jI) = wj

I − qj

+(g(jI) − g(jS)) + λg(iI),

8

so that

g(jI) = g(iI) + [wj

I − qj

+(g(iI) − g(iS)) − δg(iI)]λ−1 + O(λ−2).

Consequently,

= g(iS) + [wj

S + (qj

g(jS) = g(jI) − (g(jI) − g(jS))
− + βiix∗)(g(iI) − g(iS)) − δg(iS)]λ−1 + O(λ−2).

Thus the consistency conditions (8) in the main order in λ → ∞ become

(18)

(19)

wj
I − qj

+(g(iI) − g(iS)) − δg(iI) ≥ 0, wj

S + (qj

− + βiix∗)(g(iI) − g(iS)) − δg(iS) ≥ 0,

or equivalently

wj

I − wi

I ≥

(qj
+ − qi
− + qi
qi

+)(wi
I − wi
S)
+ + βiix∗ + δ

, wj

S − wi

S ≥

[qi

− − qj
− + (βii − βij)x∗](wi
− + qi
qi
+ + βiix∗ + δ

I − wi
S)

In the ﬁrst order in small βii this gets the simpler form, independent of x∗:

wj
wi

I − wi
I
I − wi
S

≥

qj
+ − qi
+
− + qi
qi
+ + δ

,

wj
S − wi
S
I − wi
wi
S

≥

− − qj
qi
− + qi
qi

−
+ + δ

.

Summarizing, we proved the following.

.

(20)

(21)

Proposition 3.2. If (21) holds for all j 6= i with the strict inequality, then for suﬃciently
large λ and suﬃciently small βij there exists a unique solution to the stationary MFG
consistency problem (4) and (6) with the optimal control ˆui, the stationary distribution is
i = x∗, xS
xI
i = 1 − x∗ with x∗ given by (11) and it is stable; the optimal payoﬀs are given
by (15), (16), (18), (19). Conversely, if for all suﬃciently large λ there exists a solution
to the stationary MFG consistency problem (4) and (6) with the optimal control ˆui, then
(20) holds.

Let us turn to control [i(I), k(S)] with k 6= i denoting it by ˆui,k:

ˆui,k(jS) = k,

ˆui,k(jI) = i,

j = 1, · · · , d.

The ﬁxed point condition under ucom = ˆui,k takes the form

xiSqi

− − xiI qi

+ +

− xiSqi

− + xiIqi

j
X
+ −

xiSxjIβji + λ

xjI = 0

j6=i
X

xiSxjIβji − λxiS = 0

xkSqk

− − xkIqk

+ +

j
X

xkSxjIβjk − λxkI = 0

− xkSqi

− + xkIqk

j
X
+ −

xkSxjIβjk + λ

xjS = 0

(22)

xlSql

− − xlIql

+ +

− xlSql

− + xlI ql

j
X
+ −

j6=k
j
X
X
xlSxjIβjl − λxlS = 0

xlSxjIβjl − λxlI = 0,

j
X

9






where l 6= i, k.

Adding the last two equations yields xlI + xlS = 0 and hence xlI = xlS = 0 for all

l 6= i, k, as one could expect. Consequently, for indices i, k the system gets the form

− − xiI qi

+ + xiSxiI βii + xiSxkIβki + λxkI = 0

− + xiIqi

− − xkIqk

+ − xiSxiI βii − xiSxkIβki − λxiS = 0
+ + xkSxkIβkk + xkSxiIβik − λxkI = 0

− + xkIqk

+ − xkSxkIβkk − xkSxiI βik + λxiS = 0

xiSqi
− xiSqi
xkSqk
− xkSqi






(23)

Adding the ﬁrst two equation (or the last two equations) yields xkI = xiS. Since by

normalization

xkS = 1 − xiS − xkI − xiI = 1 − xiI − 2xkI,

we are left with two equations only:

xkIqi
− − xiI qi
(1 − xiI − 2xkI)(qk

(

+ + xkIxiIβii + x2

kIβki + λxkI = 0

− + xkIβkk + xiI βik) − (λ + qk

+)xkI = 0.

(24)

From the ﬁrst equation we obtain

xiI =

λxkI + βkix2
qi
+ − xkIβii

kI + qi

−xkI

=

λxkI
qi
+ − xkIβii

(1 + O(λ−1)).

Hence xkI is of order 1/λ, and therefore

xiI =

λxkI
qi
+

(1 + O(λ−1)) ⇐⇒ xkI =

xiI qi
+
λ

(1 + O(λ−1)).

(25)

In the major order in large λ asymptotics, the second equation of (24) yields

(1 − xiI)(qk

− + βikxiI ) − qi

+xiI = 0

or for y = xiI

Q(y) = βiky2 + y(qi

+ − βik + qk

−) − qk

− = 0,

which is eﬀectively the same equation as the one that appeared in the analysis of the
control [i(I), i(S)]. It has the unique solution on the interval (0, 1):

x∗
iI =

1
2βik (cid:20)

βik − qi

+ − qk

− +

(βik + qk

−)2 + (qi

+)2 − 2qi

+(βik − qk
−)

q

Let us note that for small βik it expands as

x∗
iI =

qk
−
− + qi
qk
+

+ O(β) =

qk
−
− + qi
qk
+

+

qk
−qi
+
− + qi

(qk

+)3 β + O(β2).

.

(cid:21)

(26)

(27)

Similar (a bit more lengthy) calculations, as for the control [i(I), i(S)] show that the
obtained ﬁxed point of evolution (1) is always stable. We omit the detail, as they are the
same as given in [17] for the case d = 2.

10

Let us turn to the HJB equation (7), which under control [i(I), k(S)] takes the form

qi
+(g(iS) − g(iI)) + wi
λ(g(kS) − g(iS)) + ˜qi
λ(g(iI) − g(kI)) + qk
−(g(kI) − g(kS)) + wk
˜qk
λ(g(iI) − g(jI)) + qj
λ(g(kS) − g(jS)) + ˜qj

I = δg(iI),
−(g(iI) − g(iS)) + wi
+(g(kS) − g(kI)) + wk

S = δg(iS),
I = δg(kI),

S = δg(kS)

+(g(jS) − g(jI)) + wj
−(g(jI) − g(jS)) + wj

I = δg(jI),
S = δg(jS),






supplemented by the consistency condition

g(iI) ≤ g(jI),

g(kS) ≤ g(jS),

for all j, where we introduced the notation

˜qj
− = ˜qj

−(i, k) = qj

− + βijxiI + βkjxkI.

j 6= i, k,

j 6= i, k,

(28)

(29)

(30)

The ﬁrst four equations do not depend on the rest of the system and can be solved

independently. To begin with, we use the ﬁrst and the fourth equation to ﬁnd

g(iS) = g(iI) +

δg(iI) − wi
I
qi
+

,

g(kI) = g(kS) +

δg(kS) − wk
S
˜qk
−

.

(31)

Then the second and the third equations can be written as the system for the variables
g(kS) and g(iI):

λg(kS) − (λ + δ)g(iI) − (λ + δ + ˜qi

−)

λg(iI) − (λ + δ)g(kS) − (λ + δ + qk
+)




or simpler as

δg(iI) − wi
I
qi
+
δg(kS) − wk
S
˜qk
−

+ wi

S = 0

+ wk

I = 0,

λqi
[λ(˜qk

+g(kS) − [λ(qi
− + δ) + δ(˜qk

+ + δ) + δ(qi
− + qk

+ + ˜qi
+ + δ)]g(kS) − λ˜qk

− + δ)]g(iI) = −wi
−g(iI) = wk
I ˜qk

I (λ + δ + ˜qi
− + wk

−) − wi
S(λ + δ + qk

Sqi
+
+).

(

(32)

Let us ﬁnd the asymptotic behavior of the solution for large λ. To this end let us write

g(iS) = g0(iS) +

g1(iS)
λ

+ O(λ−2)

with similar notations for other values of g. Dividing (32) by λ and preserving only the
leading terms in λ we get the system

+g0(kS) − (qi
qi
− + δ)g0(kS) − ˜qk
(˜qk

+ + δ)g0(iI) = −wi
I,
−g0(iI) = wk
S.

(

(33)

Solving this system and using (31) to ﬁnd the corresponding leading terms g0(iS), g0(kI)
yields

11

g0(iS) = g0(kS) =

g0(kI) = g0(iI) =

S + δwk
S

+wk

I + qi
−wi
˜qk
1
˜qk
− + qi
δ
I + qi
−wi
+wk
˜qk
1
− + qi
˜qk
δ
+ + δ

+ + δ
S + δwi
I

.

,

(34)

The remarkable equations g0(iS) = g0(kS) and g0(kI) = g0(iI) arising from the
calculations have natural interpretation: for instantaneous execution of personal decisions
the discrimination between strategies i and j is not possible. Thus to get the conditions
ensuring (29) we have to look for the next order of expansion in λ.
Keeping in (32) the terms of zero-order in 1/λ yields the system

+g1(kS) − (qi
qi
− + δ)g1(kS) − ˜qk
(˜qk

(

+ + δ)g1(iI) = δ(qi

+ + ˜qi

− + δ)g0(iI) − wi

−g1(iI) = −δ(˜qk

− + qk

+ + δ)g0(kS) + wk

I(δ + ˜qi
I ˜qk

−) − wi

Sqi
+
S(δ + qk

− + wk

+).

Taking into account (34), conditions g(iI) ≤ g(kI) and g(kS) ≤ g(iS) turn to

−g1(iI) ≤ g1(kS)(˜qk
˜qk

− + δ),

+g1(kS) ≤ g1(iI)(qi
qi

+ + δ).

Solving (35) we obtain

g1(kS)δ(˜qk
− + qi
+ [qi
+(qk
− + qi
−(˜qi
+ [˜qk

g1(iI)δ(˜qk

+ + δ) = ˜qk
+ − ˜qk
− − qi
+ + δ) = qi
+ − ˜qk
− − qi

+wi
−[qi
+) + δ(qk
−wk
+[˜qk
−) + δ(˜qi

S + (qi
+ − qi

I + (˜qi

+ + δ)wk
+)]wk
S,
S + (qk
− + δ)wi
−)]wi
I,

I + (˜qk

− − ˜qk

− − ˜qk

− − qi

+ − δ)wi
I]

+ − qi

+ − ˜qk

− − δ)wk
S]

(35)

(36)

(37)

We can now check the conditions (36). Remarkably enough the r.h.s and l.h.s. of both
inequalities always coincide for δ = 0, so that the actual condition arises from comparing
higher terms in δ. In the ﬁrst order with respect to the expansion in small δ conditions
(36) turn out to take the following simple form

−(wk
˜qk

I − wi

I) + wk

S(qk

+ − qi

+) ≥ 0,

+(wi
qi

S − wk

S) + wi

I(˜qi

− − ˜qk

−) ≥ 0.

(38)

From the last two equations of (28) we can ﬁnd g(jS) and g(jI) for j 6= i, k yielding

g(jI) = g(iI) +

[wj

I − δg(iI) + qj

+(g(iI) − g(kS))] + O(λ−2),

g(jS) = g(kS) +

[wj

S − δg(kS) + ˜qj

−(g(iI) − g(kS))] + O(λ−2).

1
λ
1
λ

(39)

From these equations we can derive the rest of the conditions (29), namely that g(iI) ≤
g(jI) for j 6= k and g(kS) ≤ g(jS) for j 6= i. In the ﬁrst order in the small δ expansion
they become

qj
+(wi

I − wk

S) + wj

I(˜qk

− + qi

+) ≥ 0,

˜qj
−(wi

I − wk

S) + wj

S(˜qk

− + qi

+) ≥ 0.

(40)

Since for small βij, the diﬀerence ˜qj

− − qj

− is small, we proved the following result.

12

Proposition 3.3. Assume

qj
+(wi
qj
−(wi
−(wk
qk

I − wk
I − wk
I − wi

S) + wj
S) + wj
I) + wk

I(qk
S(qk
S(qk

− + qi
− + qi
+ − qi

+) > 0,

+) > 0,
+) > 0,

j 6= k,

j 6= i,
+(wi
qi

S − wk

S) + wi

I(qi

− − qk

−) > 0.

(41)

Then for suﬃciently large λ, small δ and small βij there exists a unique solution to
the stationary MFG consistency problem (4) and (6) with the optimal control ˆui,k, the
stationary distribution is concentrated on strategies i and k with x∗
iI being given by (26)
or (27) up to terms of order O(λ−1), and it is stable; the optimal payoﬀs are given by
(34), (37), (39).

Conversely, if for all suﬃciently large λ and small δ there exists a solution to the
stationary MFG consistency problem (4) and (6) with the optimal control ˆui,k, then (38)
and (40) hold.

4 Main result

By the general result already mentioned above, see [4], a solution of MFG consistency
problem constructed above and considered on a ﬁnite time horizon will deﬁne an ǫ-Nash
equilibrium for the corresponding game of ﬁnite number of players. However, solutions
given by Propositions 3.2 and 3.3 work only when the initial distribution and terminal
payoﬀ are exactly those given by the stationary solution. Of course, it is natural to ask
what happens for other initial conditions. Stability results of Propositions 3.2 and 3.3
represent only a step in the right direction here, as they ensure stability only under the
assumption that all (or almost all) players use from the very beginning the corresponding
stationary control, which might not be the case. To analyse the stability properly, we
have to consider the full time-dependent problem. For possibly time varying evolution
x(t) of the distribution, the time-dependent HJB equation for the discounted optimal
payoﬀ e−tδg of an individual player with any time horizon T has form (3).

In order to have a solution with a stationary u we have to show that solving the linear
equation obtained from (3) by ﬁxing this control will be consistent in the sense that this
control will actually give minimum in (3) in all times.

For deﬁniteness, let us concentrate on the stationary control ˆui, the corresponding

linear equation getting the form

+(g(iS) − g(iI)) + wi

I = δg(iI),

˙g(iI) + qi
˙g(iS) + qi

−(g(iI) − g(iS)) +

βkixkI(t)(g(iI) − g(iS)) + wi

S = δg(iS),

˙g(jI) + λ(g(iI) − g(jI)) + qj
˙g(jS) + λ(g(iS) − g(jS)) + qj

k
X
+(g(jS) − g(jI)) + wj
−(g(jI) − g(jS))

I = δg(jI),

j 6= i,

(42)

+

βkjxkI(t)(g(jI) − g(jS)) + wj

S = δg(jS),

j 6= i,

k
X






with the consistency requirement (8), but which has to hold now for time-dependent
solution g.

13

Theorem 4.1. Assume the strengthened form of (21) holds, that is

wj
wi

I − wi
I
I − wi
S

>

qj
+ − qi
+
− + qi
qi
+ + δ

,

wj
wi

S − wi
S
I − wi
S

>

− − qj
qi
− + qi
qi

−
+ + δ

for all j 6= i. Assume moreover that

qj
+ > qi
+,

− > qj
qi

−

(43)

(44)

for all j 6= i. Then for any λ > 0 and all suﬃciently small βij the following holds. For any
T > t, any initial distribution x(t) and any terminal values gT such that gT (jI)−gT (jS) ≥
0 for all j, gT (iI) − gT (iS) is suﬃciently small and

gT (iI) ≤ gT (jI) and gT (iS) ≤ gT (jS),

j 6= i,

(45)

there exists a unique solution to the discounted MFG consistency equation such that u is
stationary and equals ˆui everywhere. Moreover, this solution is such that, for large T − t,
x(s) tends to the ﬁxed point of Proposition 3.2 for s → T and gs stays near the stationary
solution of Proposition 3.2 almost all time apart from a small initial period around t and
some ﬁnal period around T .

Remark 3. (i) The last property of our solution can be expressed by saying that the
stationary solution provides the so-called turnpike for the time-dependent solution, see
e.g. [19] and [29] for for reviews in stochastic and deterministic settings. (ii) Condition
(44) is strong and can possibly be dispensed with by a more detailed analysis. (iii) Similar
time-dependent class of turnpike solutions can be constructed from the stationary control
of Proposition 3.3.

Proof. To show that starting with the terminal condition belonging to the cone speciﬁed
by (45) we shall stay in this cone for all t ≤ T , it is suﬃcient to prove that on a boundary
point of this cone that can be achieved by the evolution the inverted tangent vector of
system (42) is not directed outside of the cone. This (more or less obvious) observation
is a performance of the general result of Bony, see e. g. [27]. From (42) we ﬁnd that

˙g(jI) − ˙g(iI) = (λ + δ)(g(jI) − g(iI)) + qj

+(g(jI) − g(jS)) − qi

+(g(iI) − g(iS)) − (wj

I − wi

I).

Therefore, the condition for staying inside the cone (45) for a boundary point with g(jI) =
g(iI) reads out as

(wj

I − wi

I) ≥ qj

+(g(jI) − g(jS)) − qi

+(g(iI) − g(iS)).

Since

a simpler suﬃcient condition for (46) is

0 ≤ g(jI) − g(jS) ≤ g(iI) − g(iS),

(wj

I − wi

I) ≥ (qj

+ − qi

+)(g(iI) − g(iS)).

Subtracting the ﬁrst two equations of (42) we ﬁnd that

˙g(iI) − ˙g(iS) = a(s)(g(iI) − g(iS)) − (wi

I − wi
S)

14

(46)

(47)

with

Consequently,

gt(iI)−gt(iS) = exp{−

T

t
Z

a(t) = qi

+ + qi

− + δ +

βkixkI(t).

k
X

a(s) ds}(gT (iI)−gT (iS))+(wi

I −wi
S)

T

s

exp{−

a(τ ) dτ }ds.

t
Z

t

Z

(48)
Therefore, as we assumed (44), condition (47) will be fulﬁlled for all suﬃciently small
gT (iI) − gT (iS) whenever

(wj

I − wi

I) > (qj

+ − qi

+)(wi

I − wi
S)

T

s

exp{−

a(τ ) dτ }ds.

(49)

t
Z

t
Z

But since a(t) ≥ qi

+ + qi

− + δ, we have

exp{−

s

t
Z

so that (47) holds if

a(τ ) dτ } ≤ exp{−(s − t)(qi

+ + qi

− + δ)},

wj
I − wi
I
I − wi
wi
S

≥

qj
+ − qi
+
+ + qi
qi
− + δ

1 − exp{−(T − t)(qi

+ + qi

− + δ)}

which is true under the ﬁrst assumptions of (43) and (44).

(cid:0)

(50)

,

(cid:1)

Similarly, to study a boundary point with g(jS) = g(iS) we ﬁnd that

˙g(jS) − ˙g(iS) = (λ + δ)(g(jS) − g(iS)) − (qj

− +

βkjxkI)(g(jI) − g(jS))

k
X

+(qi

− +

βkixkI)(g(iI) − g(iS)) − (wj

S − wi

S).

Therefore, the condition for staying inside the cone (45) for a boundary point with g(jS) =
g(iS) reads out as

k
X

(wj

S − wi

S) ≥ (qi

− +

βkixkI)(g(iI) − g(iS)) − (qj

− +

βkjxkI)(g(jI) − g(jS)).

(51)

Now 0 ≤ g(iI) − g(iS) ≤ g(jI) − g(jS), so that (51) is fulﬁlled if

k
X

k
X

(wj

S − wi

S) ≥ (qi

− +

βkixkI − qj

− −

βkjxkI)(g(iI) − g(iS))

(52)

k
X

k
X

for all times. Taking into account the requirement that all βij are suﬃciently small, we
ﬁnd as above that it holds under the second assumptions of (43) and (44).

The last statement of the theorem concerning x(s) follows from the observation that
the eigenvalues of the linearized evolution x(s) are negative and well separated from zero
implying the global stability of the ﬁxed point of the evolution for suﬃciently small β.
The last statement of the theorem concerning g(s) follows by similar stability argument
for the linear evolution (42) taking into account that away from the initial point t, the
trajectory x(t) stays arbitrary close to its ﬁxed point.

15

References

[1] T. S. Aidt. Economic Analysis of corruption: a survey. The Economic Journal 113:

491 (2009), F632-F652.

[2] G.V.Alferov, O.A. Malafeyev and A.S. Maltseva. Programming the robot in
International Conference on Mechan-
(2015), 1 - 3,

tasks of
ics - Seventh Polyakhovs Reading. Conference Proceedings
http://dx.doi.org/10.1109/Polyakhov.2015.7106713.

inspection and interception,

[3] M. Bardi, P. Caines and I. Capuzzo Dolcetta. Preface: DGAA special issue on mean

ﬁeld games. Dyn. Games Appl. 3:4 (2013), 443 – 445.

[4] R. Basna, A. Hilbert and V. Kolokoltsov. An epsilon-Nash equilibrium for non-
linear Markov games of mean-ﬁeld-type on ﬁnite spaces. Commun. Stoch. Anal. 8:4
(2014), 449 - 468.

[5] D. Bauso, H. Tembine, and T. Basar. Robust mean-ﬁeld games. Dynamic Games

and Applications, online, 6 June 2015, 10.1007/s13235-015-0160-4

[6] A. Bensoussan, J. Frehse, P. Yam. Mean Field Games and Mean Field Type Control

Theory. Springer, 2013.

[7] A Bensoussan, S. Hoe and M. Kantarcioglu. A Game-Theoretical Approach for
Finding Optimal Strategies in a Botnet Defense Model. Decision and Game The-
ory for Security First International Conference, GameSec 2010, Berlin, Germany,
November 22-23, 2010. Proceeding, T. Alpcan, L. Buttyan, and J. Baras (Eds.),
Vol. 6442 pp. 135-148.

[8] P. E. Caines, “Mean Field Games”, Encyclopedia of Systems and Control, Eds. T.
Samad and J. Ballieul. Springer Reference 364780; DOI 10.1007/978-1-4471-5102-9
30-1, Springer-Verlag, London, 2014.

[9] P. Cardaliaguet, J-M. Lasry, P-L. Lions and A. Porretta. Long time average of mean
ﬁeld games with a nonlocal coupling. SIAM J. Control Optim. 51:5 (2013), 3558 –
3591.

[10] R. Carmona and F. Delarue. Probabilistic analysis of mean-ﬁeld games. SIAM J.

Control Optim. 514 (2013), 2705 – 2734.

[11] D. A. Gomes and J. Saude. Mean ﬁeld games models – a brief survey. Dyn. Games

Appl. 4:2 (2014), 110 – 154.

[12] O. Gu´eant O, J-M. Lasry and P-L. Lions. Mean Field Games and Applications.
Paris-Princeton Lectures on Mathematical Finance 2010. Lecture Notes in Math.
2003, Springer, Berlin, p. 205-266.

[13] M. Huang, R. Malham´e, P. Caines. Large population stochastic dynamic games:
closed-loop Mckean-Vlasov systems and the Nash certainty equivalence principle.
Communications in information and systems 6 (2006), 221 – 252.

16

[14] A. K. Jain. Corruption: a review. Journal of Economic Surveys 15: 1 (2001), 71-

121.

[15] V. N. Kolokoltsov. Nonlinear Markov games on a ﬁnite state space (mean-ﬁeld and
binary interactions). International Journal of Statistics and Probability 1:1 (2012),
77-91. http://www.ccsenet.org/journal/index.php/ijsp/article/view/16682

[16] V. N. Kolokoltsov. The evolutionary game of pressure (or interference), resistance

and collaboration (2014). http://arxiv.org/abs/1412.1269

[17] V. N. Kolokoltsov and A. Bensoussan. Mean-ﬁeld-game model of botnet defense in

cyber-security (2015). http://arxiv.org/abs/1511.06642

[18] V. N. Kolokoltsov and O. A. Malafeyev. Mean ﬁeld game model of corruption
(2015). http://arxiv.org/abs/1507.03240. Dynamics Games and Applications (pub-
lished with Open Access). Online ﬁrst DOI: 10.1007/s13235-015-0175-x

[19] V. Kolokoltsov and W. Yang. The turnpike theorems for Markov games. Dynamic

Games and Applications 2: 3 (2012), 294-312.

[20] V. Kolokoltsov, H. Passi and W. Yang. Inspection and crime prevention: an evolu-

tionary perspective (2013). http://arxiv.org/abs/1306.4219

[21] V. Kolokoltsov, M. Troeva and W. Yang. On the rate of convergence for the mean-
ﬁeld approximation of controlled diﬀusions with large number of players. Dyn.
Games Appl. 4:2 (2014), 208230.

[22] J-M. Lasry and P-L. Lions. Jeux `a champ moyen. I. Le cas stationnaire (French).

C.R. Math. Acad. Sci. Paris 343:9 (2006) 619-625.

[23] M. I. Levin and M. L. Tsirik. Mathematical modeling of corruption (in Russian) .

Ekon. i Matem. Metody 34:4 (1998), 34-55.

[24] Zh. Li, Q. Liao and A. Striegel. Botnet Economics: Uncertainty Matters.

http://weis2008.econinfosec.org/papers/Liao.pdf

[25] K-W. Lye and J. M. Wing. Game strategies in network security. Int J Inf Secur 4

(2005), 71 - 86.

[26] O.A. Malafeyev, N.D. Redinskikh and G.V. Alferov. Electric

in economics modeling:

analogies
national Conference
http://dx.doi.org/10.1109/Emission.2014.6893965

on Emission Electronics Proceeding

circuits
Corruption networks. Second Inter-
28-32,

(2014),

[27] R. M. Redheﬀer. The Theorems of Bony and Brezis on Flow-Invariant Sets. The

Americal Mathematical Monthly 79:7 (1972), 740-747.

[28] H. Tembine, Q. Zhu and T. Basar. Risk-sensitive mean-ﬁeld games. IEEE Trans.

Automat. Control 59:4 (2014), 835 – 850.

[29] A. J. Zaslavski. Turnpike properties in the calculus of variations and optimal control.

Springer, New York, 2006.

17

