Mining actionable information from security forums:
the case of malicious IP addresses

8
1
0
2

r
p
A
3
1

]
I
S
.
s
c
[

1
v
0
0
8
4
0
.
4
0
8
1
:
v
i
X
r
a

Joobin Gharibshah∗, Tai Ching Li∗, Andre Castro∗,
Konstantinos Pelechrinis†, Evangelos E. Papalexakis∗ and Michalis Faloutsos∗
∗ University of California - Riverside, CA
Email: {jghar002,tli010,acast050,epapalex,michalis}@cs.ucr.edu
† School of Information Sciences, University of Pittsburgh, Pittsburgh, PA
Email: kpele@pitt.edu

Abstract—The goal of this work is to systematically extract
information from hacker forums, whose information would be
in general described as unstructured: the text of a post is
not necessarily following any writing rules. By contrast, many
security initiatives and commercial entities are harnessing the
readily public information, but they seem to focus on structured
sources of
information. Here, we focus on the problem of
identifying malicious IP addresses, among the IP addresses which
are reported in the forums. We develop a method to automate
the identiﬁcation of malicious IP addresses with the design goal
of being independent of external sources. A key novelty is that we
use a matrix decomposition method to extract latent features of
the behavioral information of the users, which we combine with
textual information from the related posts. A key design feature
of our technique is that it can be readily applied to different
language forums, since it does not require a sophisticated Natural
Language Processing approach. In particular, our solution only
needs a small number of keywords in the new language plus the
user’s behavior captured by speciﬁc features. We also develop a
tool to automate the data collection from security forums. Using
our tool, we collect approximately 600K posts from 3 different
forums. Our method exhibits high classiﬁcation accuracy, while
the precision of
is greater
than 88% in all three forums. We argue that our method
can provide singiﬁcantly more information: we ﬁnd up to 3
times more potentially malicious IP address compared to the
reference blacklist VirusTotal. As the cyber-wars are becoming
more intense, having early accesses to useful information becomes
more imperative to remove the hackers ﬁrst-move advantage, and
our work is a solid step towards this direction.

identifying malicious IP in post

forums, like Offensive Community, where we ﬁnd users with
names like satan911. Some of these forums have been known
to have hackers boast of attacks they have mounted, or sell
tools for malicious purposes (think rent-a-botnet). For example,
in our dataset there is a post that mentions “I give you a
second server to have your fun with. Multiple websites on
this server. So let’s see if anyone can actually bring down the
server”. Right after that the hacker posted the IP, username
and password for anyone to access the server. In fact, there
is a show-off section in these forums for people to broadcast
their hacking “skills”.

The overarching goal of this work is to mine the unstruc-
tured, user-generated content in security forums. Speciﬁcally,
we focus here on collecting malicious IP addresses, which
are often reported at such forums. We use the term security
forum to refer to discussion forum with a focus on security,
system administration, and or more generally, systems-related
discussions. The users in these forums include: security pro-
fessionals, hobbyists, and hackers, who go on these forums
to identify issues, discuss solutions, and in general exchange
information.

Let us provide a few examples of how users report IP
addresses, which may or may not be malicious. Posts could
talk about a benign IP address, say in conﬁguration ﬁles, as
in the post:

"[T]his thing in my hosts ﬁle: 64.91.255.87 ... [is] it

Keywords: Security, Online communities mining, Fo-

correct?".

rums

I.

INTRODUCTION

How can we take the ﬁrst-mover advantage away from
hackers? We argue that hacker forums provide information
earlier than other sources, and we should leverage these forums
in our security intelligence. Here, we focus on a speciﬁc
question. In particular, we want to extract as much useful
information from hacker/security forums as possible in order
to perform (possibly early) detection of malicious IP addresses,
e.g., prior to their appearance on blacklists. The latter can
exhibit large delays in their update and hence, new ways
for labeling malicious IP addresses are needed [15]. In this
study we will use the term “hacker forums” to describe online
forums with a focus on security and system administration.
Interestingly, we can classify these forums into categories: (a)
main stream forums, like Wilders Security, and (b) “fringe”

At the same time, posts could also report compromised or

malicious IP addresses, as in the post:

"My

browser

homepage

has

been

hijacked

to

http://69.50.191.51/2484/".

The challenge is to automatically distinguish between the
two. By doing so, we can provide a new source of information
of malicious IP addresses directly from the affected individu-
als. Formally, we can state the problem as follows:

Key Question: Malicious IP Detection. Given a set of
posts PF that may contain IP addresses and users UF of a
security forum F , as well as, the features Φp, ∀p ∈ PF and
Φu, ∀u ∈ UF for the posts and the users respectively, can we
determine if a given IP address i is malicious or not?

The set of features PF includes attributes such as the text

 
 
 
 
 
 
of the post, the posting user, the time of post, etc., while UF
includes information such as the date of a user joining the
forum, the number of posts the user has made etc. The above
problem has two associated questions:

a. Exclusivity: How many IP Addresses can we ﬁnd that

are never reported by other reference sources?

b. Early warning: How much earlier are malicious IP
Addresses reported in a forum compared to reference sources,
for the IP Addresses reported by both?

Most previous studies in this area have focused on struc-
tured information sources, such as security reports, or malware
databases. In fact, many efforts focus on addressing security
problems using knowledge obtained from the web, as well
as social and information networks. These efforts are mainly
focused on analyzing structured sources (e.g., [16]). However,
studies assessing the usefulness of (unstructured) information
in online forums have only recently emerged (e.g., [23]). These
studies are rather exploratory and provide evidence of the
usefulness of the data in the forums, but do not provide a
systematic methodology or ready-to-use tools, which is the
goal of our work. We discuss existing literature in more detail
later in section V.

The motivation of our work is to provide more information
to security analysts and systems. We want to enhance and
complement, but not replace, existing efforts for detecting
malicious IP Addresses. For instance, many IP blacklists enlist
an IP as malicious after a number of reports above a pre-
deﬁned threshold have been made for the speciﬁc address.
Depending on the threshold and the reactivity of the affected
users/systems, this might take several days, weeks or months.
Therefore, a system, like the one proposed here, can identify
and point to malicious IP address to blacklist services and
ﬁrewalls.

We propose InferIP, a systematic approach for identifying
malicious IP Addresses among the IP addresses, which are
mentioned in security forums. A key novelty is that we use the
behavioral information of the users, in addition to the textual
information from the related posts. Speciﬁcally, we customize
and use a Sparse Matrix Regression method on this expanded
set of features.

This paper presents an extension of our previous work [14].
Here, we add some spatiotempral and behavioral analysis to
extract the characteristics of the identiﬁed IP addresses and the
users who used these IP address in their posts. Moreover, we
investigate the ability of the proposed method to provide early
warning regarding malicious IP addresses.

By design, our framework is applicable to forums in
different languages as it relies only on the behavioral patterns
of users and simple word counts, and not a complex language-
speciﬁc Natural Language Processing technique. From a tech-
nical point of view the challenge in designing a solution
to our Key Question is most IP Addresses mentioned in
these forums are not malicious. We show that our system
can add a signiﬁcant number of previously unreported IP
address to existing blacklist services. Finally, as an engineering
contribution, we develop a customizable tool to facilitate the
crawling of forums, which we discuss in the next section.

Our results can be summarized into the following points:

a. Our method exhibits precision and recall greater
than 88% and 85% respectively, and an accuracy over
malicious class above 86% in the 10-fold cross validation
tests we conducted for the three different forums. In partially
answering our Key Question, if our method labels a currently
non-blacklisted IP as malicious, there is a high chance that it
is malicious, given our high precision.

b. Our method identiﬁes three times more malicious IP
Addresses compared to VirusTotal [5] a widely used aggrega-
tor of 60 blacklists of IP addresses. Across our three forums,
we ﬁnd more than 2000 potential malicious IP Addresses that
were never reported by VirusTotal.

c. Our method identiﬁes more than half of the IP
addresses at least 3 month earlier than VirusTotal. We
study the malicious IP addresses that are identiﬁed by both
VirusTotal and InferIP. We ﬁnd 53%, 71% and 62% of these
IP addreses in Wilders Security, Offensive Community and
Ashiyane respectively at least 3 months earlier than they were
reported in VirusTotal.

d. The number of reported malicious IP addresses has
increased by a factor 8 in 4 years. We ﬁnd that the number of
malicious IP addresses has increased from roughly 100 in 2011
and 2012 to more than 800 in 2016. This could be attributed to
either an increase in the user base, an increase in the number
of attacks, or a combination of the two.

II. DATA COLLECTION AND BASIC PROPERTIES

We have collected data from three different forums relevant
to our study; (i) Wilders Security [6], (ii) Offensive Commu-
nity [4], (iii) Ashiyane [1]. The ﬁrst two forums are mainly
written in English, while the last forum is an Iranian forum,
in Farsi1.

Our data collection tool. We develop a customizable uni-
versal tool to make the crawling forums easier. The challenge
here is that each forum has its own format and layout. Our
tool requires only a custom conﬁguration ﬁle, before crawling
a new forum. In conﬁguration ﬁle, we specify entities in the
forum which are needed such as user ID, post’s date, post’s
content and etc by XML Path Language known as Xpath.
Leveraging our current conﬁguration ﬁles, the task of crawling
a new forum is simpliﬁed signiﬁcantly. Using our crawler, we
collect data from three forums, two English and one in Farsi
for a total number of more than 30K users and 600K posts.

We use VirusTotal [5] as our reference blacklist IP ad-
dresses, since it is an aggregator, and combines the information
from over 70 other blacklists and resources. VirusTotal is
free to end users for non-commercial use and is a private
API to query the services in the rate of more than 4000
IP addresses per minutes. It is provided upon requests for
academic purposes.

We provide some basic statistics for our three forums in
Table II. Offensive Community and Ashiyane are two fringe
forums in different languages. In these forums there is a section
where people openly boast about their achievement in hacking.
They share their ideas and tutorials on how to break into

1Our

software
https://github.com/hackerchater/

and

datasets

will

be made

available

at:

TABLE I: Extracting useful information; Number of malicious IP Addresses found by InferIP and not by VirusTotal.

IP found by

Dataset
Wilders Security
Offensive Community
Ashiyane

Total IP Virus Total

4338
7850
8121

216
339
133

InferIP only
670
617
806

vulnerable networks. On the other hand, Wilders Security as a
mainstream forum is mostly used to protect non-experts against
attacks such as browser hijacking, and provide solutions for
their security problems.

an equal number of IP addresses that have not been reported as
malicious and via manual inspection further assess their status.
Finally, for every security forum we have a different dataset
and hence, we build a different model.

For completeness, we present some of the terms we use
here. A user is deﬁned by a login name registered with the
site. The term post refers to a single unit of content generated
by a user. A thread refers to a collection of posts that are
replies to a given initiating post.

In Figures 1 and 2, we present the cumulative complemen-
tary distribution function of the number of posts per user and
the number of threads per users respectively. As we can see in
all the cases the distributions are skewed, that is, most of the
users contribute few posts in the forums and engage with few
threads. In Wilders Security, 85% of users post less than 10
posts each, while 5.2% of the users post more than 50 posts.
We ﬁnd that 70% of the users post in only one thread and
only 8% of the users are active in more than 10 threads. This
skewed behavior is typical for online users and communities
[12]. We will use features to capture aspects of both these user
properties, as we will see in the next section.

In Figure 3, we present the cumulative complementary
distribution function of the number of IP addresses that appear
in each post. The skewed distribution shows that most of
the posts contain a few number of IP address. We ﬁnd that
84.2% of the posts with IP addresses in Wilders Security and
84.1% in Offensive Community have two or less IP addresses.
In Ashiyane, 87.2% of these posts contain less than two
IP addresses. Interestingly, in Ashiyane, we ﬁnd 1% of the
IP containing posts with more than 100 IP addresses. We
investigated and we found that typically, these posts provide
benign IP addresses of proxies servers to fellow administrators.

Groundtruth for training and testing. In order to build
and evaluate, our model we need to obtain a reasonably labeled
dataset from IP addresses that appear in the posts of the
security forums. For that, we use the VirusTotal service and
assign malicious labels to an IP that has been reported by this
service. The number of malicious IP Addresses that we have
used with the corresponding posts are shown in table I as the
IP found by VirusTotal. Note that the absence of a report on
VirusTotal does not necessarily mean that the IP is benign.
However, a listed IP address is most likely malicious, since
VirusTotal as most blacklist sites require a high threshold of
conﬁdence for blacklisting an address. This way, we ﬁnd in
total 688 malicious IP addresses for our forums as shown in
Table I.

Using this labeling process we have collected all the IP
addresses that have appeared on our forums prior to their report
on VirusTotal. For building our model, we also randomly select

III.

INFERIP: MALICIOUS IP DETECTION

We propose a method to identify whether an IP address
within a post is malicious. For example, although many users
report a malicious IP address, such as one that is attacking the
user’s network, there are also users that will mention a benign
IP address when people discuss about network tutorials like
setting up Putty or initiating a SSH connection.

While this task is simple for a human, it is non-trivial to
automate. Adding to the challenge, different communities use
different terminology and even different languages altogether
(english and farsi in our case). In order to overcome these
challenges, we use a diverse set of features and build a model
to identify IP addresses that are potentially malicious.

Our approach consists of four steps that each hide non-

trivial novelties:

Step 1: We consider the user behavior and extract features

that proﬁle users that post IP-reporting posts.

Step 2: We extract keywords from the posts and use
information gain to identify the 100 most informative features.

Step 3: We identify meaningful latent feature sets using

an unsupervised co-clustering approach [19].

Step 4: We train a classiﬁer using these latent feature sets

using 10-fold cross validation.

We describe each step in more detail.

Step 1: Behavioral Features. We associate each user of
the forum with a set of 11 features that capture their behavior.
In particular:

•

•

•

•

•

Number of posts; the total number of posts made by
the user

Number of threads; the total number of threads the
user has contributed to

Number of threads initiated;
threads initiated by the user

the total number of

Average thread entropy; the average entropy of the
user distribution of the threads in which the user has
contributed to

Number of active days; the number of days that the
user generates at least one post

TABLE II: The collected forums.

Forum
Wilders Security
Offensive Comm.
Ashiyane

Threads
28661
3542
67004

Posts
302710
25538
279309

Users Active days
14836
5549
22698

5227
1508
4978

2
10

1
10

0
10

−1

10

−2

10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

2
10

1
10

0
10

−1

10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

2
10

1
10

0
10

−1

10

−2

10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

−3

10

0
10

1
10

2
10
Number of posts

3
10

4
10

−2

10

0
10

1
10

2
10

Number of posts

3
10

−3

10

0
10

(a) Wilders Security.

(b) Offensive Community.

Fig. 1: CCDF of the number of posts per user (log-log scale).

2
10

1
10

0
10

−1

10

−2

10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

2
10

1
10

0
10

−1

10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

2
10

1
10

0
10

−1

10

−2

10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

−3

10

0
10

1
10

2
10
Number of threads

3
10

4
10

−2

10

0
10

1
10

2
10

Number of threads

3
10

−3

10

0
10

(a) Wilders Security

Fig. 2: CCDF of the number of thread per user (log-log scale).

(b) Offensive Community

2
10

1
10

0
10

−1

10

s
t
s
o
p
f
o
e
g
a
t
n
e
c
r
e
p

2
10

1
10

s
t
s
o
p
f
o
e
g
a
t
n
e
c
r
e
p

2
10

1
10

0
10

−1

10

s
t
s
o
p
f
o
e
g
a
t
n
e
c
r
e
p

1
10

2
10
Number of posts
(c) Ashiyane

3
10

4
10

1
10

2
10
Number of threads
(c) Ashiyane

3
10

4
10

−2

10

0
10

1
10
Number of IPs

(a) Wilders Security

2
10

0
10

0
10

1
10
Number of IPs

2
10

(b) Offensive Community

−2

10

0
10

1
10

2
10

Number of IPs
(c) Ashiyane

3
10

Fig. 3: CCDF of the number of IP addresses per post (log-log scale).

• Average day entropy; the average entropy of the user
distribution of the posts made on the days that the user
is active

• Wait time; the number of days passed between the
day the user joined the forum and the day the user
contributed their ﬁrst post

• Active lifetime; the number of days between the ﬁrst

•

and the last post of the user

Average post length; the average number of characters
in the user’s posts

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
• Median post length; the median number of characters

in the user’s posts

• Maximum post length; the number of character’s in

the user’s longest post

Step 2: Contextual Features. Apart from the aforemen-
tioned behavioral features we also include features related with
the context in which an IP address appears within a post. In
particular, we consider the frequency of the words (except
stop-words) in the posts. Words that are frequent only in few
documents (posts in our case) are more informative than those
that appear frequently on a larger corpus [21]. To this end, we
use TF-IDF to weight the various words/terms that appear in
our data. After calculating the frequency and the corresponding
weights of each word in the dataset we end up with more
than 10,000 features/terms. Hence, in the next step we select
discriminative features by extracting latent features.

We begin by performing feature selection in order to iden-
tify the most informative features by applying the information
gain framework [25]. Furthermore, in order to avoid overﬁtting
we pick a random subset of posts from the whole dataset and
select the highest ranked features based on Information Gain
score. In this way, a subset of discriminative keywords, 100 in
our model, are selected. It turns out that each user uses only
a small number of those words, resulting in a sparse dataset
which we wish to exploit in our model.

Step 3: Identifying latent feature sets. We also like to
leverage latent similarities of different posts in some of the di-
mensions spanned by post features and behavioral features for
the writer of the post. Essentially, we seek to identify groups of
highly similar posts under a small number of features, which
does not necessarily span the full set of features. The reason
why we wish to pinpoint a subset of the features instead of
the entire set is because this way we are able to detect subtle
patterns that may go undetected if we require post similarity
across all the features. We call those sets of feastures latent
feature sets . To this end, we apply a soft co-clustering method,
Sparse Matrix Regression (SMR) [19], to exploit the sparsity
and extract latent features of the post containing IP addresses.
Given a matrix X of posts × features, its soft co-clustering
via SMR can be posed as the following optimization problem:

classiﬁer. Our 10-fold cross validation indicates that the Lo-
gistic regression classiﬁer outperforms kNN and Naive Bayse,
achieving high accuracy, precision and recall (see Table III).

Determining feature sets. We investigate the effect of
selecting different feature sets in classifying IP addresses in
forums. To this end, we investigate three subsets of the features
discussed earlier.

a. Words-Frequency is the normalized frequency of the
most informative words that appear in a post as discussed in
Step 2.

b. Combined is the set of features which consists of the
combination of the words frequency features, deﬁned above,
and user behaviour features, which are extracted in Step 1. In
other words, it is the union of the features in Step 1 and Step
2.

c. Co-Clustered is the latent set of features extracted
in Step 3 by applying the co-clustering approach on the
Combined features set.

We evaluate these three sets of features on their ability to
enable the classiﬁcation. In more detail, we use these features
with a classiﬁer to assess their effectiveness by computing the
accuracy of the classiﬁer to identify malicious IP addresses.
According to the results which are shown in Figure 4, the
Co-Clustered features set exhibits higher accuracy by 4.1%
compared to Words-Frequency. On the other hand, although
the Combined features do not increase the accuracy compared
to the Words-Frequency, the co-clustering method does. It
extracts the latent features from the Combined features set and
outperforms Words-Frequency and Combined in identifying
malicious IP addresses.

105

100

95

90

85

e
g
a
t
n
e
c
r
e
P
y
c
a
r
u
c
c
A

minar≥0,br≥0 kX − PR
r

λ Pj,r |br(j)|

arbT

r k2

F + λ Pi,r |ar(i)| +

where ar and br are vectors that “describe” co-cluster r,
which we explain below. Each ar is a vector with as many
dimensions as posts. Each value ar(i) expresses whether post
i is afﬁliated with co-cluster r. Similarly, br is a vector with
as many dimensions as features, and br(j) expresses whether
feature j is afﬁliated with with co-cluster r. Parameter λ
controls how sparse the co-cluster assignments are, effectively
controlling the co-cluster size. As we increase λ we get sparser
results, hence cleaner co-clustering assignments. We tune λ
via trial-and-error so that we obtain clean but non-empty co-
clusters, and we select λ = 0.01 in our case.

Step 4: Training the model. We subsequently train a
number of classiﬁers using the selected features based on a
matrix. In particular, we examine (a) a Naive Bayes classiﬁer,
(b) a K-Nearest Neighbor classiﬁer and (c) a logistic regression

80

Combined

Words−Frequecny
Datasets
Fig. 4: Accuracy of different feature sets in Wilders Security forum
to detect malicious IP

Co−Clustered

A. Applying InferIP on the forums

Having established the statistical conﬁdence of our classi-
ﬁer, we apply it on the posts of the forums except the ones
that we used in our groundtruth. We use the logistic regression
classiﬁer as it exhibits the best performance.

Applying InferIP on the forums shows that there is a wealth
of information that we can extract from security forums in
two aspects of the quantity and time of detecting malicious IP
against VirusTotal.

a. Detecting more IP addresses. With InferIP, we ﬁnd an
additional 670 malicious IP addresses in Wilders Security, and

 
TABLE III: Selecting a classiﬁer: overall accuracy.

Forum
Wilders Security
Offensive Comm.
Ashiyane

Naive Bayes
91.9%
84.1%
85.1%

3NN
87.1 %
83.2%
82.3%

Logistic regression
94.8%
86.5%
94%

TABLE IV: InferIP evaluation: 10-fold cross validation evaluation (using Logistic Regression).

Forum
Wilders Security
Offensive Comm.
Ashiyane

Instances
362
342
446

Precision Recall ROC Area
0.94
0.85
0.92

0.96
0.91
0.92

0.9
0.88
0.9

is interesting to observe that

617 in Offensive Community 806 in Ashiyane (see Table I). In
other words, InferIP enables us to ﬁnd three times additional
malicious IP addresses in total compared to the IP addresses
this
found on VirusTotal. It
factor varies among our three sites. For Ashiyane, our method
ﬁnds roughly 6 times additional malicious IP addresses. With
a precision of roughly around 90% and considering small
amount of False Positive rate, our method can add a signiﬁcant
number of malicious IP addresses to a blacklist. Using the
limited manual inspection, we conﬁrm that the precision of
the method on out of sample data is in the order of 88%.

b. Detecting malicious IP addresses earlier: more than
half IPs, at least 3 months earlier Here we focus on the
malicious IP addresses that are jointly identiﬁed by our method
and VirusTotal and compare the time that they were reported
in each source, and show the results in Table V for 3, 6 and
12 months difference in time. We compare jointly detected IP
addresses with InferIP and VirusTotal in terms of time that the
IP addresses were mentioned in posts and the time they were
reported on VirusTotal. We see that on average 62% of the
malicious IP addresses with InferIP could be identiﬁed at least
3 months earlier than VirusTotal. We can see that with InferIP,
we ﬁnd 53%, 71% and 62% of these IP addresses in Wilders
Security, Offensive Community and Ashiyane respectively at
least 3 months earlier than in VirusTotal. We also identify 39%
and 24% of the malicious IP addresses respectively at least 6
and 12 months earlier with InferIP.

Additional stress-testing of our accuracy: In order to
assess the performance of our approach, we randomly picked
10 percent of the labeled data with InferIP method and
annotated them manually by human annotators. The calculated
accuracy on the sampled data shows more than 85% accuracy
on average over all datasets which is close but somewhat lower
than the reported accuracy in the Table III.

Contributing Users. Who are the users that report ma-
licious IP addresses? We want
to understand and ideally,
develop a proﬁle for these users, which we will refer to as
Contributing users. We start by considering the number of
post these users post on the forums.

TABLE V: Timely comparison between jointly detected malicious IP
addresses in InferIP and VirusTotal. Reported percentage of malicious
IP Addresses which InferIP detected earlier than VirusTotal

At least X months earlier

Dataset
Wilders Security
Offensive Community
Ashiyane
Average (across forums)

3

6

53% 23%
71% 46%
62% 49%
62% 39%

12
14%
21%
37%
24%

More than 72% of the Contributing users post more than 10
posts overall, which we consider as high engagement given
the distribution of posting that we saw in the previous section.
Therefore, in Ashiyane, Contributing users are contributing
signiﬁcantly in reporting malicious IP addresses. Intrigued, we
examined further and found that, among them, there are two
users who have more than 1000 posts, 1058 and 2780 to be
exact, and whose user-names are "Classic" and "Crisis". On
the other side of the spectrum, 2.4% of Contributing users have
posted a single post in the forum, and in that post they reported
a malicious IP address.

The majority of IP reporting is done by less active users
(less than 10 posts overall) in Offensive Community. In
Figure 5, we show the cumulative complementary distribution
function for the number of posts per Contributing user for
Offensive Community. Unlike Ashiyane, here 65% of the
Contributing users have less than 10 posts overall. Going into
more detail, roughly 12% of the Contributing users have a
single post overall, while 26% of them have only two overall
posts. The same behavior is observed in Wilders Security
which is shown in Figure 5.

Overall, there does not seem to be an obvious pattern
between number of total posts and number of malicious IPs
reported among Contributing users.

B. Case-study: from reported malicious IPs to a DDoS attack

The majority of IP reporting is done by highly active
(more than 10 posts overall) in Ashiyane. In Figure 5,
we show the cumulative complementary distribution function
for the number of posts per Contributing user for Ashiyane.

We show that mining the forums could actually provide
information about real events. We identify a link between a
malicious IP address that our method detected with an actual
DDoS attack.

2
10

1
10

0
10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

2
10

1
10

0
10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

2
10

1
10

0
10

s
r
e
s
u
f
o
e
g
a
t
n
e
c
r
e
P

−1

10

0
10

1
10

2
10
Number of posts

3
10

4
10

−1

10

0
10

1
10

2
10

Number of posts

3
10

−1

10

0
10

(a) Wilders Security

(b) Offensive Community

Fig. 5: CCDF of the number of overall posts per Contributing users (who report malicious IPs) in log-log scale.

1
10

2
10
Number of posts
(c) Ashiyane

3
10

4
10

We conducted the following analysis. We plot the time-
series of the number of posts containing malicious IP addresses
in Wilders Security from 2012 to 2013 found by InferIP. We
show the time-series in Figure 6. We observe some spikes on
these time-series, which we further analyze. One of the spikes
was in September 2012, and it reports a set of malicious IP
addresses that were involved in an DDoS attack that month.
That same thread continued being active, and in December of
2012, it was reported in that thread that attack was caused by
Nitol Botnet due to a Microsoft’s vulnerability [3].

We argue that this case-study points to additional layers
of functionality that can be built upon our method, that can
provide a semi-automated way to extract richer information
beyond just reporting malicious IP addresses.

25

20

P

I

f
o
r
e
b
m
u
N

15

10

5

0

02/2012

03/2012

04/2012

05/2012

06/2012

07/2012

08/2012

09/2012

11/2012

01/2013

02/2013

03/2013

04/2013

05/2013

06/2013

07/2013

08/2013

09/2013

Fig. 6: Time-series of the number of posts containing malicious IP
reported in each month for Wilders Security.

Dates

C. Discussion and limitations

Although our method exhibits pretty good accuracy overall,
we attempt to understand its limitations and detect the source
of misclassiﬁcations.

Limited text in the post: The words in the post provide
signiﬁcant evidence for the classiﬁcation. In some cases, some
posts are very sparse in their text, which makes the classiﬁ-
cation of the included IP address harder. We consider these
kinds of posts a signiﬁcant contributor to misclassiﬁcations.

Characterization at the post level: In our method, we
classify an IP address by using features at the level of a post.
Recall that roughly 86% of all posts across all forums has
a single IP per post as shown in Figure 3. In other words,

having more than one IP address per post is already not very
common. Furthermore, even more rarely, we have seen a few
cases, where a post contains both a benign and a malicious
IP address. As our method is currently set-up, this will lead
to errors in the classiﬁcation. A straightforward solution is to
consider examining the text surrounding each IP address within
the post.

IV.

SPATIOTEMPORAL ANALYSIS

In this section, we discuss the spatiotemporal features of
the malicious IP addresses identiﬁed in security forums in
Section III.

A. Temporal analysis

The key question from a temporal point of view is if
the number of reported malicious IP addresses increases or
decreases over time.

s
e
s
s
e
r
d
d
A
P

I

f
o
r
e
b
m
u
N

900

800

700

600

500

400

300

200

100

0

2011

2012

2013

2014

2015

2016

Years

Fig. 7: Increasing trend: Malicious IP addresses reported on the
forums each year.

The number of reported malicious IP addresses has
increased by a factor 8 in 4 four years. In Figure 7, we plot
the number of reported malicious IPs found by our method
across all three forums between 2011-2016. We ﬁnd that the
number increased by a factor of 8: from roughly 100 to roughly
800. In spite of some decreases in years 2011, 2012 and 2015,
it has a clear increasing trend.

 
 
 
 
 
 
 
 
 
 
 
B. Spatial analysis

We study the geo-location of the identiﬁed IP addresses
from Section III. We utilize GeoLite database [2], which can
show us the country and continent of an IP address. Here we
focus on continents of the IP addresses location.

A natural question to ask is whether the geographical dis-
tribution of the malicious addresses differs between VirusTotal
and InferIP. We investigate this in detail below.

VirusTotal: North America hosts the majority of the
reported malicious IP addresses. We plot the percentage
of the distribution of the IP addresses extracted from Virus-
Total across continents in Figure 8 (a) between 2011-2016.
We observe that the majority of the malicious IP addresses
are located in the North America continent. There are two
exception in 2013 and 2016 when Asia and Europe respectively
contain most of the malicious IP addresses. Overall, Table VI
shows the geo-graphical distribution over all the years: North
America, Asia and Europe are the three most active continents
in that order.

InferIP: North America dominates again, but South
America and Africa have non-trivial contributions. We plot
the percentage of the distribution of the IP addresses extracted
form InferIP across continents in Figure 8 (b) between 2011-
2016. We observe that North America hosts the majority of
the reported malicious IP addresses again, but we ﬁnd a
more diverse global activity compared to what we observed
in VirusTotal. For example, we can see that in years 2013,
2014, and 2016: (a) Asia has the majority of the malicious IP
addresses, and (b) South America and Africa have a consid-
erable percentage of malicious IP addresses. However, when
seen across all years, the geographical distributions of the IPs
in InferIP and VirusTotal quite similar: North America, Asia
and Europe have the majority of the malicious IPs detected by
InferIP similarly to those of VirusTotal. In Figure 9, we plot
the geographical distribution of malicious IPs per continent
across all years and all forums for InferIP and VirusTotal,
while the exact numbers are shown in Table VI. Qualitatively
the distributions look relatively similar, especially in the order
of signiﬁcance of the continents, but at the same, we can see
that South America and Africa have a larger percentage of IP
addresses in InferIP compared to those in VirusTotal.

V. RELATED WORK

We brieﬂy discuss three categories of relevant research.

a. Analyzing structured security sources. There is a long
line of research studying the ontology of cyber security and the
automatic extraction of information from structured security
documents. Iannacone et al.[16] developed a schema for ex-
tracting relevant concepts from various types of structured data
sources. In another work, Blanco et al. [9] proposed methods
to detect anomalies on the extracted ontology and network
ﬂow graph. Moreover, Bridges et al.[10] proposed a method
to do entity labeling on structured data by utilizing neural
networks. These work are complementary to ours as we focus
on unstructured data, which poses different challenges.

b. Analyzing online security forums. Recently security
forums have been the focus of various studies that showcase
the usefulness of the information present in security forums.

For example, Motoyama et al. [18] present a comprehensive
statistical analysis in underground forums. Others studies focus
on the users’ classiﬁcation or the discovery of the relationships
between the forum’s members [26], [7]. Extracting different
discussion topic in the forums and classifying the language of
the codes posted in the forum has been done in [23]. Contrary
to these studies, our work emphasizes on the development of
automated systems that actually exploit the wealth of infor-
mation in these security forums in order to enhance security.
Similar to detecting malicious users on commenting platforms
has been done on [17]. A recent work analyzes security forums
to identify and geo-locate Canadian IP addresses focusing on
spam and phishing [13] and in another work, Portnoff et al.
[20] studies the exchange of malicious services and tools and
studies their prices on the security forums.

c. Analyzing blogs and social networks. There has been
a plethora of studies on blogs and social media, but their goals
are typical not related to extracting security information. [11],
[8], [24]. The studies range from modeling user behavior [12],
[22] to inferring information about the user (demographics,
preferences, mental state), and to modeling the information
propagation on online forums. Although interesting, the focus
of these studies are signiﬁcantly different from our goal here.

VI. CONCLUSION

The take away message from our work is that there seems
to be a wealth of useful information in security forums. The
challenge is that the information is unstructured and we need
novel methods to extract it. In this direction, a key insight of
our work is that using behavioral and text-based features can
provide promising results.

In support of this assertion, we develop a systematic
method to extract malicious IP addresses reported in security
forums. We utilize both behavioral, as well as textual features
and show that we can detect malicious IP addresses with
high accuracy, precision and recall. Our results in Table I are
promising.

We then apply InferIP to all the posts we have collected.
Although are classiﬁcation is not perfect, our relatively high
precision (hovering around 90% in Table IV) provides sufﬁ-
cient conﬁdence in our results. We ﬁnd three times as many
additional malicious IP addresses as the original malicious
IP addresses identiﬁed by VirusTotal. Furthermore, even for
the jointly discovered IP addresses, at least 53% of the IP
addresses detected at least 3 months earlier than VirusTotal.
The key message from our spatiotemporal analysis is that the
number of reported malicious IP addresses is increasing over
time.

In the future, we plan to extend our work by extracting
other types of security information. Our ﬁrst goal is to detect
malicious URLs mentioned in the forums. Our second and
more ambitious goal is to identify the emergence of new
malware, threats, and possibly attacks, which we expect to
see associated with large numbers of panic-ﬁlled or help-
requesting posts. Our ﬁnal goal is to identify malicious users,
since interestingly, some users seem to be promoting and
selling hacking tools in these forums.

e
g
a
t
n
e
c
r
e
P
n
o
i
s
i
c
e
r
P

1.2

1

0.8

0.6

0.4

0.2

0

s
e
s
s
e
r
d
d
a
P

I

f
o
%

60

50

40

30

20

10

0

Asia Europe North America South America Africa Oceania

2011

2012

2013

2014

Datasets

2015

2016

e
g
a
t
n
e
c
r
e
P
n
o
i
s
i
c
e
r
P

1.2

1

0.8

0.6

0.4

0.2

0

Asia Europe North America South America Africa Oceania

2011

2012

2013

2014
Datasets

2015

2016

2011

(a) VirusTotal

(b)InferIP

Fig. 8: SpatioTemporal distribution of malicious IP addresses detected by InferIP and VT .

TABLE VI: Percentage of distribution of IP addresses across continents over all the years.
Europe
South America Africa Oceania
13.5
20.4

North America Asia
32.5
26.5

InferIP
VirusTotal

0.5
0.17

46.7
50

5.2
2.4

1.6
0.6

North America Asia Europe South America Africa Oceania

Search and Data Mining, WSDM ’17, pages 537–546, New York, NY,
USA, 2017. ACM.

[9] C. Blanco, J. Lasheras, R. Valencia-García, E. Fernández-Medina,
A. Toval, and M. Piattini. A systematic review and comparison
In 2008 Third International Conference on
of security ontologies.
Availability, Reliability and Security, pages 813–820, March 2008.

[10] R. A. Bridges, C. L. Jones, M. D. Iannacone, and J. R. Goodall.
Automatic labeling for entity extraction in cyber security. CoRR,
abs/1308.4941, 2013.
J. Cheng, M. Bernstein, C. Danescu-Niculescu-Mizil, and J. Leskovec.
Anyone Can Become a Troll: Causes of Trolling Behavior in Online
Discussions. ArXiv e-prints, Feb. 2017.

[11]

[12] P. Devineni, D. Koutra, M. Faloutsos, and C. Faloutsos. If walls could
talk: Patterns and anomalies in facebook wallposts. In Proceedings of
the 2015 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining 2015, ASONAM ’15, pages 367–374,
New York, NY, USA, 2015. ACM.

[14]

[13] R. Frank, M. Macdonald, and B. Monk. Location, location, location:
Mapping potential canadian targets in online hacker discussion forums.
EISIC ’16, 2016.
J. Gharibshah, T. C. Li, M. S. Vanrell, A. Castro, K. Pelechrinis, E. E.
Inferip: Extracting actionable infor-
Papalexakis, and M. Faloutsos.
In Proceedings of the 2017
mation from security discussion forums.
IEEE/ACM International Conference on Advances in Social Networks
Analysis and Mining 2017, ASONAM ’17, pages 301–304, New York,
NY, USA, 2017. ACM.

[15] H. Hang, A. Bashir, M. Faloutsos, C. Faloutsos, and T. Dumitras.
“Infect-me-not": A user-centric and site-centric study of web-based
malware. In IFIP Networking, pages 234–242, May 2016.

[16] M. Iannacone, S. Bohn, G. Nakamura, J. Gerth, K. Huffer, R. Bridges,
E. Ferragut, and J. Goodall. Developing an ontology for cyber security
In Proceedings of the 10th Annual Cyber and
knowledge graphs.
Information Security Research Conference, CISR ’15, pages 12:1–12:4,
New York, NY, USA, 2015. ACM.

[17] T. C. Li, J. Gharibshah, E. E. Papalexakis, and M. Faloutsos. Trollspot:
In Proceedings of
Detecting misbehavior in commenting platforms.
the 2017 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining 2017, ASONAM ’17, 2017.

[18] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. Voelker.
An analysis of underground forums. In Proceedings of the 2011 ACM
SIGCOMM Conference on Internet Measurement Conference, IMC ’11,
pages 71–80, New York, NY, USA, 2011. ACM.

InferIP

VirusTotal

Areas
Fig. 9: The percentage distribution of malicious IP Addresses in each
continent across all three forums for InferIP and VirusTotal.

VII. ACKNOWLEDGMENTS

This material is based upon work supported by an Adobe
Data Science Research Faculty Award, and DHS ST Cyber
Security (DDoSD) HSHQDC-14-R-B00017 grant. Any opin-
ions, ﬁndings, and conclusions or recommendations expressed
in this material are those of the author(s) and do not necessarily
reﬂect the views of the funding institutions.

REFERENCES

[1] Ashiyane. http://www.ashiyane.org/forums/.
[2] Geolite. http://dev.maxmind.com/geoip/legacy/geolite/.
[3] Nitol-botnet. https://threatpost.com/tag/nitol-botnet/.
[4] Offensive community. http://www.offensivecommunity.net.
[5] Virustotal. http://www.virustotal.com.
[6] Wilders security. http://www.wilderssecurity.com.
[7] A. Abbasi, W. Li, V. Benjamin, S. Hu, and H. Chen. Descriptive
In 2014 IEEE
analytics: Examining expert hackers in web forums.
Joint Intelligence and Security Informatics Conference, pages 56–63,
Sept 2014.

[8] T. Althoff, P. Jindal, and J. Leskovec. Online actions with ofﬂine impact:
How online social networks inﬂuence online and ofﬂine user behavior.
In Proceedings of the Tenth ACM International Conference on Web

[19] E. E. Papalexakis, N. D. Sidiropoulos, and R. Bro. From k-means to
higher-way co-clustering: Multilinear decomposition with sparse latent
factors. IEEE transactions on signal processing, 61(2):493–506, 2013.

 
 
 
 
 
 
 
 
 
 
 
[21]

[20] R. S. Portnoff, S. Afroz, G. Durrett, J. K. Kummerfeld, T. Berg-
Kirkpatrick, D. McCoy, K. Levchenko, and V. Paxson. Tools for
automated analysis of cybercriminal markets. WWW ’17, 2017.
J. Ramos. Using TF-IDF to determine word relevance in document
queries. In Instructional Conference on Machine Learning, 2003.
[22] R. Rawassizadeh, E. Momeni, C. Dobbins, J. Gharibshah, and M. Paz-
zani. Scalable daily human behavioral pattern mining from multivariate
temporal data. IEEE Transactions on Knowledge and Data Engineering,
28(11):3098–3112, Nov 2016.

[23] S. Samtani, R. Chinn, and H. Chen.

Exploring hacker assets in
underground forums. In IEEE International Conference on Intelligence
and Security Informatics (ISI), pages 31–36, May 2015.
J. Ugander, B. Karrer, L. Backstrom, and C. Marlow. The anatomy of
the facebook social graph. CoRR, abs/1111.4503, 2011.

[24]

[25] Y. Yang and J. O. Pedersen. A comparative study on feature selection
In Proceedings of the Fourteenth International
in text categorization.
Conference on Machine Learning, ICML ’97, pages 412–420, San
Francisco, CA, USA, 1997. Morgan Kaufmann Publishers Inc.
[26] X. Zhang, A. Tsang, W. T. Yue, and M. Chau. The classiﬁcation
Information Systems

of hackers by knowledge exchange behaviors.
Frontiers, 17(6):1239–1251, Dec. 2015.

