9
1
0
2

t
c
O
0
3

]

R
C
.
s
c
[

2
v
4
6
7
9
0
.
7
0
8
1
:
v
i
X
r
a

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

1

Architectures for Detecting Interleaved
Multi-stage Network Attacks Using
Hidden Markov Models

Tawfeeq Shawly, Member, IEEE, Ali Elghariani, Member, IEEE,
Jason Kobes, Member, IEEE, and Arif Ghafoor, Fellow, IEEE

Abstract—With the growing amount of cyber threats, the need for development of high-assurance cyber systems is becoming
increasingly important. The objective of this paper is to address the challenges of modeling and detecting sophisticated network
attacks, such as multiple interleaved attacks. We present the interleaving concept and investigate how interleaving multiple attacks can
deceive intrusion detection systems. Using one of the important statistical machine learning (ML) techniques, Hidden Markov Models
(HMM), we develop two architectures that take into account the stealth nature of the interleaving attacks, and that can detect and
track the progress of these attacks. These architectures deploy a database of HMM templates of known attacks and exhibit varying
performance and complexity. For performance evaluation, in the presence of multiple multi-stage attack scenarios, various metrics are
proposed which include (1) attack risk probability, (2) detection error rate, and (3) the number of correctly detected stages. Extensive
simulation experiments are used to demonstrate the efﬁcacy of the proposed architectures.

Index Terms—cyber systems, network security, intrusion detection, Hidden Markov Model, interleaved attacks.

(cid:70)

1 INTRODUCTION

L Arge organizations face a daunting challenge in the

provision of security for their cyber-based systems.
Modern cyber-based infrastructures typically consist of
a large number of interdependent systems and exhibit
increasing reliance on the security of such systems. In the
present threat landscape, network attacks have become
more advanced, sophisticated and diversiﬁed, and the
rapid pace of coordinated cyber security crimes has
witnessed a massive growth over the past several years.
For instance, in May 2017, the “WannaCry” ransomware
attack was detected after it locked up over 200,000
servers in more than 150 countries [1]. A month later,
another version of the same attack caused outages of
most of the government websites and several companies
in Ukraine, and eventually, this attack spread worldwide
[2]. With the explosive growth of cyber threats, a dire
need exists for the development of high-assurance and
resilient cyber-based systems. One of the most important
requirements for high-assurance systems is the need
for advanced and sophisticated attack detection and
prediction systems [3].

Security reports reveal that, over time, the type of
network intrusions have transformed from the original
Trojan horses and viruses into more complex attacks
comprised of a myriad of individual attacks. These
attacks follow a series of long-term steps and actions
referred to as multi-stage attacks, and therefore are hard
to predict [4], [5]. During these attacks, an intruder
launches several actions, which may not be performed
simultaneously, but are correlated in the sense that each
action is part of the execution of previous ones and

each multi-stage attack is aimed at a speciﬁc target.
The detection of multi-stage attacks poses a daunting
challenge to the existing threat detection techniques [3].
This challenge is exacerbated when multiple attacks such
as these are launched simultaneously in the network,
originated by a single or multiple attackers trying to
stealth certain attacks among others [5], [6].

1.1 Related Work

In the past, various approaches have been proposed to
address intrusion detection challenges related to multi-
stage attacks. These approaches can, in general, be cat-
egorized as correlation-based techniques [7]–[9] or ma-
chine learning (ML) based techniques. Examples of ML
techniques include Hidden Markov Models, Bayesian
Networks, Clustering and Neural Networks [10]–[13].
Correlation-based techniques, based on cause and effect
relationships, mainly utilize attack-graphs when search-
ing the possible stages of the attack [14]–[19]. For exam-
ple, the work in [15] focuses on the causal relationships
between attack phases on the basis of security infor-
mation. Onwubiko et al. [16] assesses network security
through mining and restoring the attack paths within an
attack graph. A causal relations graph presented in [17],
contains the low-level attack patterns in the form of their
prerequisites and consequences. In this approach, during
the correlation phase, a new search is performed upon
the arrival of a new alert. Several other techniques use
similar ideas for analyzing attack scenarios from security
alerts [18], [19]. However, most of these approaches de-
pend on correlation rules in conjunction with the domain
knowledge. Due to increased computational complexity

 
 
 
 
 
 
IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

2

in detecting real time attacks, these techniques pose a
limitation.

In the category of ML techniques, HMM is a leading
approach for the prediction of multi-stages attacks, [20]–
[28]. In this approach, stages of an attack are modeled
as states of the HMM. The HMM is considered the
most suitable detection techniques for such attacks for
several reasons [20]. First, it has a tractable mathemat-
ical formalism in terms of the analysis of input-output
relationships, and the generation of transition probability
matrices based on a training dataset. Second, because
of its specialized capacity to deal with sequential data
by exploiting transition probability between states, it
can track the progress of a multi-stage attack. Despite
the existing research in the use of HMM for intrusion
detection in general and multi-stage attacks in particular,
none of these approaches considers the problem of in-
terleaving multi-stage attacks and analyzing the impact
on the detection performance of such attacks. Moreover,
existing approaches address only a single multi-stage
attack.

1.2 Contribution

This research addresses several challenges to the de-
tection of interleaved attacks which include: (1) how
to model each multi-stage attack in terms of HMM
states in the presence of mixed observations, (2) how to
detect a multi-stage attack when an attacker(s) performs
interleaved attacks with the intention to hide an attack
(i.e. stealthy attacks), (3) since no standard public dataset
is available that can provide interleaved trafﬁc from si-
multaneous multiple attacks, the generation of this type
of datasets poses a challenge to the research community,
(4) the design of an efﬁcient architecture that can detect
and track the progress of multiple simultaneous attacks,
and (5) the development of an approach to accurately
quantify and measure the detection performance of such
an architecture.

To address the above challenges, we propose in this
paper two architectures based on HMM formalism. The
proposed architectures exhibit varying detection perfor-
mance and processing complexities. The architectures
can detect the occurrence of multiple organized attacks
and provide insights into the dynamics of these attacks
such as identifying which attack is progressing and
which one is idle at any point of time, how fast or
slow each attack is progressing, and in which security
state each attack is occurring at any given point in time.
Knowledge of this information can assist in designing
effective response mechanisms that can mitigate security
risks to the network [3], [29]. The design of the ﬁrst
proposed architecture relies on modifying HMM model
parameters to detect multiple multi-stage attacks in the
presence of mixed alerts. The design of the second
proposed architecture relies on de-interleaving mixed
alerts from different attacks prior to the HMM processing
subsystem. We compare the two architectures in terms
of their detection performance and design complexity.

The remainder of this paper is organized as follows. In
Section 2, we discuss how HMM is used to detect multi-
stage attacks. We introduce the system model in Section
3. We present the proposed architectures in Section 4 and
evaluation and performance measures in Section 5. We
conclude the paper in Section 6.

2 THE HIDDEN MARKOV MODEL (HMM) FOR
DETECTING MULTI-STAGE ATTACKS

An HMM is a double-stochastic process [30] in that it has
an underlying stochastic process that is hidden, and can
only be observed through another set of stochastic pro-
cesses that produce the sequence of observed symbols.
The observation process corresponds to alerts generated
by the IDS. Mathematical preliminaries for the discrete
HMM in the context of multiple multi-stage attacks are
given in Appendix A.

2.1 Using HMM to Detect Multi-stage Attacks

In a multi-stage attack, an intruder launches a series of
long-term steps and actions that are sequentially corre-
lated in the sense that each action follows the successful
execution of the previous one. In other words, the output
of one stage serves as the input to a subsequent stage.
One example of multi-stage attacks is the DDoS attack
in which the attacker starts by scanning the targeted
network in order to identify potential vulnerabilities.
Subsequently, the attacker tries to break into vulnerable
hosts which have been compromised by the attacker.
After exploiting these hosts, the attacker installs a soft-
ware such as a Trojan horse. Eventually, the attacker
initiates access to the ﬁnal target, which could be a server
accessible from all the exploited hosts, and subsequently,
the DDoS attack is launched [31].

Most detection systems have the capability to detect
a single-stage attack or each of the stages of a multi-
stage attack independently. However, the detection of
multi-stage attacks poses a daunting challenge to the
existing intrusion detection techniques due to the lack
of an ability to analyze the entire attack activity chain as
a whole. This challenge is exacerbated if several of these
attacks are launched simultaneously in the network, each
attack originated by a single or multiple attackers trying
to stealth certain attacks within others. The difﬁculty in
detecting interleaved attacks comes from the unrelated
observations made of unrelated attacks, observations
that conceal the details of the activity chains of multi-
stage attacks.

Fig. 1 illustrates this challenge by exhibiting three
possible scenarios involving the interleaving of three
multi-stage attacks that can target a speciﬁc or multiple
servers. For example, Attack 1, shown in yellow, is an
SQL injection attack, wherein Attack 2, in orange, is a
Brute force SSH, and Attack 3, in red, is a DDoS attack
[31]. The table in the lower-left corner of the ﬁgure shows
the correspondence between the type of attack, Alert

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

3

Note, the selection of the optimum number of states
for each HMM template is a challenge, and no simple
in general, this
theoretical answer exists as to how,
parameter can be selected; this selection depends on the
application [30]. In this paper, we model the number
of HMM states so that they are similar to the number
of stages of the multi-stage attack. The justiﬁcation for
this approach is that the closer the number of states is
to the number of stages in the multi-stage attack, the
better the details can be provided regarding the progress
of the attack; therefore this approach can lead to the
development of a more effective response mechanism.

Also note, for each attack type, multiple instances
of the same type of attack can be launched by the
attacker(s) and consequently, each instance constitutes
a distinct attack. The distinction among instances is
maintained by a set of observations features such as the
source and destination IP addresses and ports. The full
description of the attributes and features associated with
observations is given in Section 4.

The parameters of the HMM template (i.e. the HMM
model λk)
for the multi-stage attack k include the
number of states of its Markov chain, the number of
related IDS observations and aforementioned probability
matrices A and B. These parameters are derived ofﬂine
from a training dataset that contains alerts of a similar
multi-stage attack scenario and which can be reestimated
and improved online [32]. Speciﬁcally, each state is
trained based on the observations that belong to the
corresponding stage. Subsequently, in the presence of
observations related to Attack k, HMM estimates the
probability of being in each state of the model using
Viterbi Algorithm [30]. However, as mentioned earlier,
in the presence of multiple interleaved multi-stage at-
tacks, the performance of the state estimation degrades
signiﬁcantly, especially in a scenario that contains a high
degree of interleaving among the observations of multi-
stage attacks. In the next section, we discuss interleaved
multi-stage attacks in detail and present an HMM-based
architecture.

3 SYSTEM MODEL AND ARCHITECTURE

In order to detect multiple multi-stage attacks, say K
attacks, one can generalize the existing single attack
architecture by building a database of K HMM tem-
plates. In Fig. 2, we present a generic architecture for
the threat detection process that uses such a database.
Here, each HMM-based template is designed to detect
a speciﬁc type of multi-stage attack. The goal of this
generic architecture is to detect K multi-stage attacks
originated from a single or multiple attackers. Note,
each of the K HMM templates is trained to detect an
individual multi-stage attack. As mentioned earlier, each
template encompasses the HMM structure including all
its parameters.

The second major component of this architecture is the
Intrusion Detection System (IDS), (e.g., Snort software

Fig. 1: State Estimation of Multi-stage Attacks with Var-
ious Degrees of Interleaving at Time t

ID, Alert type, and stages for some observations of the
aforementioned attacks. In addition, on the right side
of the ﬁgure, an HMM heatmap shows the estimation
of the belief about the current state assuming there are
ﬁve stages for each multi-stage attack. A darker color
indicates a higher probability and a higher degree of
certainty about the current state.

In this example, ICMP PING is a common observation
between Attack 1 and Attack 2. Also, assume that the
system is in State 4 of Attack 1 and the next alert(s)
generated by the IDS is ICMP PING, which is an ob-
servation for State 1 in this attack. The ICMP PING
observation could be originally generated from Attack
2, thus, in this case, the state estimation can be affected
due to the uncertainty regarding the exact current state
of the system caused by the unexpected ICMP PING
observation(s).

Fig. 1 also exhibits an example of how the degree
of interleaving among the observations of three multi-
stage attacks can hypothetically affect the performance
of the state estimation over time. For instance, Scenario
C in Fig. 1 has a higher degree of interleaving compared
to Scenario B and, consequently, the uncertainty about
the current state for each multi-stage attack at time t in
Scenario C can be higher than in Scenario B. A detailed
performance analysis regarding the interleaving is given
in Section 5.

In this paper, we use HMM to model and detect
possible multi-stage attack scenarios on a targeted cyber-
based system. In particular, in order to detect a single
multi-stage attack, (say Attack k), stages of the attack are
modeled as states of the HMM and the observation pro-
cess corresponds to related alerts generated by the IDS
and processed later by a preprocessing component. Note,
the aforementioned three multi-stage attacks can consist
of different types in terms of the order of sequences and
the number of stages and corresponding observations.
Each attack type (k) is modeled using a distinct HMM
template λk. In the case of M possible attacks, we have
a set of M templates.

......HMMs States EstimationDegree of InterleavingOnline Observations( Length T = 10)......Alerts ( O8) of Attack 1Alerts ( O5) of Attack3Alerts ( O1) of Attack 2Alerts ( O9) of Attack 1ScenarioBScenarioCCyber-based System123IDSScenarioAObservations( Length T = 1000)Attack 2S1S2S3S4S5Attack 1Attack 3Attack2Attack 1Attack 1S2S1S3S4S5Attack 2S2S1S4S5S3Attack 3S2S1S3S4S5Scenario C –StagesAttack 1HMMs States EstimationO5O5O5O5O5O1O1O8O1O9O1O9O8O8O1O9Time tAttack 1S2S1S3S4S5Attack 2S2S1S4S3Attack 3S2S3S4S5Scenario B –StagesS1S5HMMs Heat map shows the belief of the current state (stage)A darker state indicatesa higher probabilityAttack TypeAlert IDAlert TypeStageSQL Injection 1O8Stack overflow AttemptS4SQL Injection 1O9Policy_Other PHP Injection AttemptS5Brute force SSH O1ICMP PINGS1DDoS 1O5RPC Sadming PINGS2IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

4

domly by different attackers. Note, for each observation
length (T ), we assume T alerts are processed by the
HMM templates sub-system. In particular, at any time, it
is possible that these T alerts can result from one attack
or a mix of at most K attacks. Some possible interleaved
attack scenarios that can be orchestrated by an attacker
include:

•

•

•

•

An attacker starts and ﬁnishes an attack (Attack
2) in the middle of another ongoing attack
(Attack 1) as shown in Scenario A in Fig. 1.
Multiple attacks start and ﬁnish at different
times in the presence of one or multiple ongo-
ing attacks.
Stages of attack(s) can be embedded at different
times of an ongoing attack(s).
Systematic interleaving among multiple multi-
stage attacks can be launched based on in-
terleaving groups of alerts (see; for example,
Scenario C in Fig. 1).

The existing datasets which feature multi-stage attacks
and are publicly available, do not consider these com-
plex attack scenarios. The DARPA2000 alerts dataset,
for instance, contains two distributed denial-of-service
(DDoS) multi-stage attacks that happened at different
times in which the attacker used multiple distributed
compromised hosts to launch DoS attacks on a speciﬁc
target [31]. To address the challenge of generating the
aforementioned interleaved attack scenarios, we gen-
erate interleaved alerts by altering timestamps and IP
addresses of the DARPA2000 dataset.

In order to detect the aforementioned attack scenar-
ios, we propose two architectures based on the generic
architecture shown in Fig. 2. The design of the ﬁrst
architecture, Architecture I, is based on modifying the
HMM model parameters so that they can deal with the
interleaved alerts. The design of Architecture II improves
attack detection capability by separating alerts from the
various attacks prior to routing the alerts to HMM
templates sub-system.

4 PROPOSED ARCHITECTURES
4.1 Proposed Architecture I

As mentioned earlier, in order to deal with interleaved
trafﬁc alerts from different attacks, we modify the HMM
of the generic architecture to accommodate observa-
tions from different attacks. The modiﬁed architecture
is shown in Fig. 3. The stream of alerts generated by the
IDS contains alerts that belong to one or more concurrent
attacks. That is, for each observation length T , there are
T observations (o1, o2, . . . , ot, . . . , oT ) processed by the
HMM detection system, as shown in Fig. 3. Arrival of
these alerts represents the interleaved attacks mentioned
in Section 3.2. The HMMk template is trained for Attack
k. Therefore, out of T observations, HMMk is expected
to distinguish and process only those observations that
belong to its attack, for which this HMM has been
designed. Note, among T observations, there are Lk

Fig. 2: A Generic Architecture for Multiple Multi-stage
Attack Detection using an HMM Database

[33], [34]), which generates the attack related alerts in
real time from the network trafﬁc according to a prede-
ﬁned set of rules. Typically, an IDS generates a stream of
alerts which are temporally ordered based on their times-
tamps. The online processing of this stream of alerts can
potentially require a large amount of memory [35]. Such
memory requirements can be improved by implement-
ing Snort rules using deterministic or nondeterministic
forms of ﬁnite automata [36]–[39]. The selection of IDS
rules can help to reduce the large volume of alerts and
false positives by tuning these rules [40]. The interleaved
alerts generated by Snort can belong to one or multiple
attacks. These alerts can be preprocessed to generate
observations in a suitable format that can be forwarded
to the HMM database. Based on the information from
Snort, the preprocessing module can assign different
severity levels for the incoming alerts. The higher the
level is, the more severe the alert which indicates an
ongoing multi-stage attack is progressing towards an
advanced stage. In this paper, we assume a window-
based technique which is needed in order to buffer
a ﬁnite number of observations so that these can be
processed by the HMM templates. For this purpose, the
incoming alerts to the system are grouped together to
form an observation sequence of window size (observa-
tion length) (T ). We assume no overlap occurs between
two consecutive windows. Note, the risk of progressing
multi-stage attacks can be assessed in real time by the
risk assessment component. Prioritized response actions
can be taken based on detected states and the risk of the
active attacks [3].

3.1 Modeling Interleaved Attacks
Note, in general, K distinct multi-stage attacks can be
launched simultaneously in a network, and their related
alerts, generated by the IDS (Snort), are forwarded to
the HMM database in the form of a single stream of
interleaved alerts. These alerts can be the result of a
systematic interleaving of multiple multi-stage attacks
initiated by a single attacker or can be generated ran-

Intrusion DetectionSystem(SNORT)Threat ResponseMechanismR1Rm……Detection ModuleRisk AssessmentHMM1HMM Database(Parameterization)HMM2HMM3HMMK...λ1λ2λ3λKObservations( Length = T)Alerts Pre-ProcessingHMM templates characterized by λk  = {πk, Ak, Bk}Offline / TrainingSecurity Database......Cyber-based SystemNetwork Data GatheringIEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

5

from unrelated attacks occur. An important advantage of
modeling unrelated alerts in this way is that the training
of each HMM is simpliﬁed. Subsequently, by introducing
(cid:15)2, the matrix Ak becomes:

Fig. 3: Architecture I

observations (i.e., {o1k , o2k , . . . , oLk }) belonging to Attack
k, and the HMMk consider the remaining T − Lk obser-
vations to be unrelated (interfering) alerts. We introduce
a common state that encompasses all of the unrelated
alerts in HMMk.

Regarding HMM structure, we focus on the alerts
generated by the IDS which may consist of True Positive
(TP) and False Positive (FP) observations. For each tem-
plate, we consider State 1 as the most likely state that can
be inferred by observing T − Lk unrelated observations
using HMMk. In other words, the occurrence of these
interfering (unrelated) observations leads to the lowest
security state (State 1) in the HMMk. To deal with these
unrelated observations in parameterizing HMMk, we
introduce a new symbol, {ot /∈ Vk}, that represents
all unrelated observations for Attack k. This requires
modifying the HMM parameters, (i.e., matrices Ak and
Bk). This modiﬁcation can be obtained by considering an
observation ot, such that {ot /∈ Vk}. Therefore, we add
an extra column in the emission probability matrix, Bk,
to account for this new symbol, as follows:

Bk =








b11
b21
...
bNk1

b12
b22
...
bNk2

· · ·
· · ·
. . .
· · ·

b1Mk
b2Mk
...
bNkMk








(cid:15)1
0

0

Note, transition to State 1, in the presence of unrelated
observation ot, occurs with probability (cid:15)1 which has a
very small value (such as < 1 × 10−6) chosen such that
(cid:80)M
j=1 b1j = 1. Accordingly, almost no change is made
to the other observation probabilities in the ﬁrst row of
the emission probability matrix. In addition, setting the
probability to zero in the rest of the last column increases
the probability that observing {ot /∈ Vk} leads to State
1. A second modiﬁcation is needed for the transition
probability matrix (Ak) to ensure that whenever HMMk
observes the T −Lk alerts from attacks other than Attack
k, transition to State 1 occurs. This transition can be
achieved by introducing transition probability ((cid:15)2) in
the ﬁrst column of the Ak matrix. Although our initial
assumption is based on a left-right model, in this archi-
tecture, instead of adding a new state to the model we
let all other states return only to State 1 whenever alerts

Ak =








a11 a12
a22
(cid:15)2
...
...
0
(cid:15)2

· · ·
· · ·
. . .
· · ·








a1Nk
a2Nk
...
aNkNk

Based on this modiﬁcation and training of

the
HMM template (λk), the evaluation module determines
whether Attack k is active or not, as shown in Fig. 3,
according to the criteria P r(O|λk) ≥ thr. Note, thr is a
threshold used to avoid unnecessary computations of the
Viterbi algorithm module in case the attack is not active.
The thr value can be chosen within a range of 0 to 0.5.
However, with the larger the value of thr, the HMM
template (λk) estimates only the states of the high prob-
ability sequences. In this paper, we take a conservative
approach in choosing thr = 0. The evaluation probability
can be computed using the forward algorithm [30]. In
case the Attack k is active, then HMMk (λk) runs the
Viterbi algorithm to decode the most probable hidden
states that correspond to the given observation sequence
O = {o1, o2, . . . , ot, . . . , oT }, as follows:

xt = max
1≤i≤Nk

γt(i)

γt(i) = P r(xt = si|O, λk)
t = 1, . . . , T

(1)

where γt(i) represents the probability of being in state
si at time t based on the observation sequence. In
Architecture I, each HMM template in Fig. 3 uses the
Viterbi algorithm to ﬁnd the best state sequence, X =
{x1, . . . , xt, . . . , xT }. For a given observation sequence,
the Viterbi algorithm ﬁnds the highest probability along
a single path for every ot (t ≤ T ) such that:

δt(i) = argmax
s1,...,st−1

P r(s1, . . . , st, o1, . . . , ot|λk)

(2)

Using induction, the algorithm determines the rest of the
state sequence, as follows:

δt+1(j) = argmax
1≤i≤Nk

{δt(i)aij(k)}.bi(ot+1(k))

(3)

This computation for a given sequence is repeated by
all HMM templates in the Architecture I (Fig. 3). Table
1 shows the overall processing of alerts based on Archi-
tecture I.

Architecture I has the limitation of a high probability
of high false negatives in states detection, especially
when the attacks are highly interleaved as shown in
Section 5. The reason for this limitation in such scenarios
is that each HMM template processes an observation
sequence that contains interfering observations belong-
ing to other attacks. However, the low performance of
Architecture I is observed only in special attack scenar-
ios. Nevertheless, Architecture I has a low computation

Stream of Interleaved Alertsmaxip(Si |O, λ1)i= 1,2,…NEvaluationP(O|λ1) > thrmaxip(Si |O, λ2)i= 1,2,..NEvaluationP(O|λ2) > thrmaxip(Si |O, λK)i= 1,2,..NEvaluationP(O|λK) > thrAttack1performanceAttack2performanceAttackKperformanceO=O1, O2, O3,….., OTAlertPre-ProcessingHMM1HMMKIEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

6

complexity in terms of observations preprocessing (as
discussed later). More details about the detection per-
formance of Architecture I is given in Section 5.

To achieve better performance, we propose another
variation of the generic architecture of Fig. 2. Termed
as Architecture II, this new architecture, is depicted in
Fig. 4 and is discussed below.

TABLE 1: Detection process for Architecture I

Input: interleaved alerts: O = {o1, o2, . . . , ot, . . . , oT },
πk: λk, k = 1, 2, . . . , K,
Output: X = {x1, x2, . . . , xT }

1 While (O is not empty)
for k = 1 : K
2
if (P r(O|λk ≥ thr))
3
for t = 1 : T
4
Compute γt(i),
5
xt = max
6

γt(i)

1≤i≤Nk

i = 1, 2, . . . , Nk from equation (1)

7
8
9
10

endfor
endif
endfor
endWhile

4.2 Proposed Architecture II
Again, we consider K interleaved multi-stage attacks
that can be simultaneously launched in the network. The
IDS system, based on Snort, generates alerts from these
attacks. Every alert is generated with a set of features,
which includes alert ID, source/destination IP address,
source/destination port number, and timestamp. In Ar-
chitecture II, we use these features to improve detection
efﬁciency of the HMM templates. In particular, unrelated
observations that do not belong to the kth attack are
separated and passed to their respective HMMs. Note,
the major design philosophy behind Architecture II is
to use aforementioned features to preprocess the online
network trafﬁc stream and demultiplex it into multiple
substreams, as shown in Fig. 4. Note, each substream
is routed to individual instances (planes) where each
instance plane contains templates of all attack types. We
refer to this preprocessing step as a demultiplexing step.
It is an important step as it helps in eliminating the
number of interfering observations from other attacks
that are not detectable by a particular HMM.

Note, alerts triggered by the same attack scenario are
correlated based on some features, (e.g., the source and
destination IP addresses). We deﬁne alert (oi) as a 7-tuple
features (timestamp, ID, srcIP, srcPort, desIP, desPort,
priority) according to the IDMEF [41]. We refer to this
tuple as a feature set F = {f1, f2, f3, f4, f5, f6, f7}. The
timestamp represents date and time of an alert generated
by the IDS. ID is the identiﬁcation of the alert, srcIP and
srcPort indicate the source IP address and source port
number, respectively. Also, desIP and desPort represent
the destination IP address and port number, respectively,
and priority indicates the alert’s rank [7]. Note, these
features are used to distinguish between attacks as to

Fig. 4: Architecture II exhibiting L Instance Planes with Sub-
stream Routing

whether their instances are from the same or different
types of attacks.

A subset, S, from the feature set F (S ⊂ F ) can
be used for the demultiplexing operation. The simplest
way in which we can demultiplex interleaved alerts is
by grouping the alerts that are triggered by the same
multi-stage attack into one subsequence based on their
IP addresses relationships, i.e., S = {f3, f5}. Note, the IP
addresses of the alerts, which are triggered by the same
attack scenario, are generally related in form a single
substream. Consider there are two alerts, oi and oj. The
demultiplexer searches for their addresses to check if
they have the same srcIP, or the same desIP. Moreover,
it also checks whether destIP of the previous alert is
the same as the srcIP of the next one, as in a multi-
stage attack scenario, as when the destination node of an
earlier alert is the source node of the next alert. Based on
the IP address search, the demultiplexer either inserts oi
and oj in the same subsequence or in different ones.

In essence, the demultiplexer module demultiplexes
the alert streams into L subsreams (1 ≤ L ≤
K). The demultiplexing process is based on one or
more of the aforementioned distinguishing feature(s)
the incoming alerts and/or based on the corre-
of
lation of IP addresses. Therefore, from the incoming
stream of alerts, O = {o1, o2, . . . , ot, . . . , oT }, the de-
multiplexer generates L substreams each of which be-
longs to a distinct multi-stage attack. These substreams
are a subset of O, which are represented as, O1 =
{o11, o21 , . . . , oT1}, Ok = {o1k , o2k , . . . , oTk }, and so on till
OL = {o1L , o2L, . . . , oTL}, where L ≤ K and Tk ≤ T .
Note, the larger the feature subset we consider in stream
demultiplexing, the more distinct substreams we obtain
and,
in turn, the more processing is entailed. Note,
within one observation sequence, alerts can belong to
L attacks where 1 ≤ L ≤ K. We assume that the
demultiplexer does not cause any error in generating
substreams.

The demultiplexer module does not distinguish
among types of attacks, therefore, it cannot route a sub-
stream to its corresponding HMM template. To address
this issue in Architecture II, each HMM can have L in-

Attack1performanceAttack2performanceAttackKperformanceO=O1, O2, O3,….., OTStream of interleaved AlertsStreamDE-MUXmaxip(Si |O1, λ1)i= 1,2,…Nmaxip(Si |OK, λK)i= 1,2,…Nmaxip(Si |O2, λ2)i= 1,2,…NSub-sequence 1Sub-sequence 2Sub-sequence LmaxlP(Ol| λ1) l= 1,….,LmaxlP(Ol| λ2) l= 1,….,LmaxlP(Ol| λK) l= 1,….,LHMM1HMMKAlertPre-ProcessingInstance Plane......IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

7

TABLE 2: Detection process for Architecture II

Input: interleaved alerts: O = {o1, o2, . . . , ot, . . . , oT },
πk: λk, k = 1, 2, . . . , K,
Output: X = {x1, x2, . . . , xT }

1 While (O is not empty)
2

Demultiplex sequence O into L subsequences, O1, O2, . . . , OL,

using features and address correlation

3
4
5
6
7

8
9
10

11
12
13

for k = 1 : K
for l = 1 : L
Compute (P r(Ol|λk))
endfor(l)
Find O∗
P r(Ol|λk)
for t = 1 : Tk, Tk is the length of sequence O∗
k

k = max
1≤l≤L

Compute γt(i) = P r(xt = si|O∗
γt(i)
xt = max

k, λk),

1≤i≤Nk

from equation (5)

endfor(t)

endfor(k)

endWhile

stances, each of which can process one single substream.
Thus, all the L generated substreams pass through each
HMM to ﬁnd which subsequence matches a certain
HMM. The computation by each instance is performed
based on the posterior probability given in (4).

O∗

k = max
1≤l≤L

P r(Ol|λl), L ≤ K

(4)

Note, this probability computation is performed L × K
times. The next stage of the HMM process is to estimate
the state probabilities for its corresponding subsequence,
O∗
k, found from (4) using the Viterbi decoding algorithm,
as follows:

xt = max
1≤i≤Nk

γt(i)

γt(i) = P r(xt = si|Ok, λk)
t = 1, . . . , Tk

(5)

Unlike Architecture I, the ﬁrst stage of every HMM
in Architecture II has a maximum of K instances of
the forward algorithm and one instance of the Viterbi
algorithm. In addition, the HMM in Architecture II
deals with subsequences of length Tk, where Tk ≤ T .
Table 2 shows the overall processing of alerts based on
Architecture II.

4.3 Complexity Comparison of the Proposed Archi-
tectures

Note, in Architectures I and II in Figs. 3 and 4, the main
modules that contribute to their computational com-
plexity are the alert preprocessing module for assigning
alert severity, the stream demultiplexing module, and the
HMM parallel branch modules. The ﬁrst preprocessing
module is the same for both architectures. However,
the demultiplexing module exists only in Architecture
II, which demultiplexes all T alerts based on a subset
(S) of alert features considered in the demultiplexing
operation. The larger the T and S sets are, the more
complex computation is performed by this module. In
other words, as a result of the demultiplexing operation,

Architecture II has T ×|S| additional computational steps
as compared with Architecture I.

Next, we consider the HMM database component of
the architectures. Note, two algorithms need to be exe-
cuted in each branch of the HMM database, the forward
algorithm (FW) to compute posterior probability for the
evaluation purpose and the Viterbi algorithm (VA) to
estimate the best state sequence. In Architecture I, each
incoming sequence of T alerts is processed by all of the
K branches. In other words, K computations of the FW
algorithm plus K computations of the Viterbi algorithm
are performed. On the other hand, in Architecture II,
each HMM template processes, on the average, with
a shorter sequence length compared to the sequence
lengths in Architecture I. In the ﬁrst module of each
branch, the FW algorithm is executed L times, and in
the second module of the branch, the Viterbi algorithm
is executed only once. Therefore, in Architecture II, L×K
computations of the FW algorithm plus L computations
of the Viterbi algorithm are performed. It is important
to note that although Architecture II seems to perform a
greater number of computations in the HMM database,
the length of sequences processed by both the FW and
the Viterbi algorithms is, on the average, shorter than the
sequences in Architecture I. The primary shortcoming of
Architecture II is the computation overhead needed for
the demultiplexing operation. This overhead can be high
especially in cases where T has a very large value and
a large number of features.

5 PERFORMANCE EVALUATION
In this section, we discuss the experimental results
based on the DARPA2000 dataset [31], since limited
datasets are available for this particular evaluation. The
DARPA2000 dataset contains two DDoS multi-stage at-
tacks labeled as LLDDOS 1.0 and LLDDOS 2.0.2. Each
of these attacks has ﬁve stages: 1) IP sweeping, 2)
Sadmind probing, 3) Sadmind exploitation, 4) DDoS
software installation, and 5) Launching the DDoS attack.
In our experiment, DARPA2000 raw network packets
were processed by Snort IDS [33] to generate alerts. The
total number of alerts resulting from this process is 3500
and 2000, for LLDDOS 1.0 and LLDDOS 2.0.2 attacks,
respectively. These alerts are clustered into 12 distinct
symbols, therefore, Mk = 12, k = 1, 2. The preprocessing
module assigns a severity level to these alerts based on
their relation to the stages of the multi-stage attacks.
In the case of more than one alert which leads to a
state, the higher severity level is given to the alert which
indicates that the attack is progressing. The training of
the two HMMs is conducted based on a ﬁve-state model
(Nk = 5, k = 1, 2), which corresponds to the ﬁve stages
in each attack. A discussion on the training and the
parameterization of each HMM is given in Appendix A.
For the completeness of our evaluation, several sce-
narios of the two simultaneous attacks are generated
with a varying degree of interleaving to test the per-
formance of the proposed architectures. For some cases,

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

8

(a) Scenario 1

(b) Scenario 2

(c) Scenario 3

(d) Scenario 4

Fig. 5: Interleaved Alerts Scenarios from LLDDOS 1.0 and LLDDOS 2.0.2 Attacks

we compare the three architectures of Figs. 2, 3, and 4.
The reason for using the generic architecture of Fig. 2
for the comparison is that no evaluation has been done
in the literature for multiple multistage attacks. For all
the results, the x-axis shows the running count of alerts
as they are generated by Snort. For evaluation purposes,
we propose three performance metrics, in addition to the
widely used state probability metric [24]. The proposed
metrics are: (1) the attack risk probability which provides
insight to the speed of the attacks, (2) the detection error
rate performance, which measures how much error is
generated by an architecture in estimating states, and (3)
the number of correctly detected stages. The justiﬁcation
of these metrics is given in the following subsections.

5.1 Generating Alert Interleaving Scenarios

Based on the two multi-stage attacks in the DARPA2000
dataset, we alter the timestamp of some of these alerts in
both attacks so that we can generate a single sequence
of alerts that is composed of a mix of the two attacks
without altering the temporal order of the original alerts.
In addition, the IP addresses of the hosts attacked by
Attack 2 (LLDDOS 2.0.2) are also changed. The reason
for this modiﬁcation is to simulate two simultaneous
attacks intruding into a network. Fig. 5 shows several
scenarios of interleaved alerts for two simultaneous
DDoS attacks. Note, the degree of interleaving increases
from Scenario 1 to Scenario 4 indicating an increase in
the sophistication of actions and complexity of attacks.
Since Attack 2 takes a shorter time to compromise the
target and launch DDoS, we manipulate the timestamps
of Attack 2 so that it spreads across different times
of Attack 1. Note also, in this experiment Case Study
1, we only implement systematic interleaving scenarios
and no random interleaving scenario is used. The y-
axis in Fig. 5 represents the alert severity based on
the preprocessing module. Based on these scenarios the
performance results of the proposed architectures are
given in the following subsections.

5.2 Probability of State Estimation and the Effect of
Interleaving

In this subsection, we present the state probability, γt(i),
from (1) and (5) for i = 1, . . . , 5 with two observation
lengths, T = 10 and T = 500. Regarding T = 500,
it can be seen from Figs. 6a and 6b that Architecture
I can estimate1 the states of both attacks with a high
probability, especially for States 1, 2, 4, and 5. However,
as the degree of interleaving increases from Scenario
1 to Scenario 4, Architecture I fails to detect many
states. For example, for Scenario 3, States 3 and 4 of
Attack 2 are not detected, as depicted in Fig. 6c. For
Scenario 4, Architecture I performs very poorly as it
fails to detect all the states of both attacks, as depicted
in Fig. 6d. For T = 10, Architecture I shows a small
improvement in detecting States 3 and 4 for Scenarios 1
and 3, respectively, as can be seen from Fig. 6 and Fig. 8.
The reason for the poor performance of Architecture I is
that the increasing degree of interleaving between alerts
allows for more interfering alerts to exist within a given
sequence. These conditions cause the Viterbi algorithm
to incorrectly determine the state probability of the non-
interfering alerts.

Architecture II, on the other hand, performs better as
compared to Architecture I in terms of estimating correct
states of all incoming alerts for both T = 10 and T = 500.
This performance improvement, even for higher degrees
of interleaving, can be observed from Figs. 6c, 6d, 7c, 7d,
8c, 8d, 9c, and 9d. The reason behind this performance
improvement for Architecture II is the presence of the
demultiplexing module that helps each HMM to process
only relevant attack alerts. Note, for both architectures
the state probability for State 3 of Attack 1 is very low for
both values of T because Snort does not produce enough
alerts for this stage.

We observe discontinuity in the state probability plot
of Architecture I in Figs. 6 and 8, a condition that results
when both of the HMMs return to State 1 whenever
interfering alerts exist from other attacks. However, in

1. Note: The terms detecting a state and estimating a state are used

interchangeably in this paper

050100150200250300350400450500024681012Alerts Severity of each Alert  Attack 1Attack 2050100150200250300350400450500024681012Alerts Severity of each Alert  Attack 1Attack 2050100150200250300350400450500024681012Alerts Severity of each Alert  Attack 1Attack 2050100150200250300350400450500024681012Alerts Severity of each Alert  Attack 1Attack 2IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

9

(a)

(b)

(c)

(d)

Fig. 6: State Probability of Attacks 1 and 2 Detected by HMM1 and HMM2 Based on Architecture I, T=500

(a)

(b)

(c)

(d)

Fig. 7: State Probability of Attacks 1 and 2 Detected by HMM1 and HMM2 Based on Architecture II, T=500

(a)

(b)

(c)

(d)

Fig. 8: State Probability of Attacks 1 and 2 Detected by HMM1 and HMM2 Based on Architecture I, T=10

(a)

(b)

(c)

(d)

Fig. 9: State Probability of Attacks 1 and 2 Detected by HMM1 and HMM2 Based on Architecture II, T=10

0100200300400500012Alerts State 1Observation length, T=500  0100200300400500012Alerts State 2  0100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 1Observation length, T=500  0100200300400500012Alerts State 2  0100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 1Observation length, T=500  0100200300400500012Alerts State 2  0100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 1Observation length, T=500  0100200300400500012Alerts State 2  0100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5Attack 1 by HMM1Attack 2 by HMM 2050100150200250300350400450500012Alerts state 1Observation length, T=500  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5050100150200250300350400450500012Alerts state 1Observation length, T=500  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5050100150200250300350400450500012Alerts state 1Observation length, T=500  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5050100150200250300350400450500012Alerts state 1Observation length, T=500  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 50100200300400500012Alerts State 1Observation length, T=10  Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 20100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 50100200300400500012Alerts State 1Observation length, T=10  Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 20100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 50100200300400500012Alerts State 1Observation length, T=10  Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 20100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 50100200300400500012Alerts State 1Observation length, T=10  Attack 1 by HMM1Attack 2 by HMM 20100200300400500012Alerts State 20100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5050100150200250300350400450500012Alerts state 1Observation length, T=10  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5050100150200250300350400450500012Alerts state 1Observation length, T=10  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5050100150200250300350400450500012Alerts state 1Observation length, T=10  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5050100150200250300350400450500012Alerts state 1Observation length, T=10  Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500012Alerts state 2050100150200250300350400450500012Alerts state 3050100150200250300350400450500012Alerts state 4050100150200250300350400450500012Alerts state 5IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

10

(a) SC2, (cid:15)2 = 0

(b) SC2, (cid:15)2 = 0.001

(c) SC3, (cid:15)2 = 0

(d) SC3, (cid:15)2 = 0.001

Fig. 10: Effect of (cid:15)2 on State Probability Based on Architecture I

Architecture II, as the alerts from different attacks are
demultiplexed prior to their processing by the HMMs,
the states of the HMMs are not interrupted. Fig. 10
shows the importance of considering (cid:15)2 in designing
the HMM used by Architecture I. In this experiment,
we choose (cid:15)2 = 0.001, which is a small value that
does not signiﬁcantly affect the transition probability
matrices, A1 and A2, obtained from training. Note, (cid:15)2 = 0
represents the case of generic architecture, for which
returning to State 1 is not allowed when HMM1 receives
alerts belonging to Attack 2 or when HMM2 receives
alerts belonging to Attack 1. Setting (cid:15)2 = 0 reduces the
accuracy of state detection for the two attacks, as can be
seen in Fig. 10. For example, for interleaving Scenario
2, Fig. 10a provides no estimate for state probability
of States 2 and 4 for the ﬁrst 200 alerts when (cid:15)2 = 0,
as compared to Fig. 10b when (cid:15)2 = 0.001. A similar
observation can be made by comparing Figs. 10c and
10d for the ﬁrst 350 alerts of State 2.

In summary, Figs. 6, 7, 8, and 9 show that no signiﬁ-
cant change occurs in the state detection performance of
each architecture as the observation length changes from
10 to 500 alerts. Moreover, Architecture II is more robust
in terms of having a better state probability estimation
metric at a higher degree of interleaving as compared to
Architecture I.

5.3 Attack Risk Probability

We deﬁne the ﬁrst proposed performance metric as
the attack risk probability, which is the probability of
how far an attack is from compromising the target, i.e.,
reaching the ﬁnal state. The calculation of this attack
probability depends on the estimated state probability
(γt(i)) averaged over the total number of states. Its
value gets updated at every observation length in a non-
decreasing manner, as shown below in (6):

(cid:80)Nk

P rattackk (t) =

i=1 γt(i)si
Nk
t = 1, . . . , T i = 1, . . . , Nk, k = 1, . . . , 2

(6)

This performance measure can help in tracking the
progress of each attack, especially when there are mul-
tiple organized attacks. It can be noted that, the rate at

which the attack risk probability changes with respect to
alerts gives an indication of how fast or slow an attack
is progressing. Consequently, this measure can help in
prioritizing response actions for each ongoing attack.

Figs. 11 and 12 show the attack risk probability for
both DARPA multi-stage attacks using Architecture I
and II for different interleaving scenarios and for the two
observation lengths, T = 10 and T = 500. The results
shown are for Scenarios 3 and 4, as they are relatively
more complex to detect. Fig. 12 shows that Architecture
II can track the progress of Attacks 1 and 2 for both
interleaving scenarios accurately based on the knowl-
edge of the generated input alerts shown in Figs. 5c
and 5d. Note, there is no signiﬁcant difference is shown
between the case of T = 10, and T = 500. Also note,
after 100 alerts, Attack 2 progresses relatively quickly,
and reaches the compromised state well before Attack 1.
In contrast, however, Architecture I underestimates the
progress of Attacks 1 and 2, as shown in Figs. 11c and
11d, because Architecture I fails to detect some of the
states for Scenarios 3 and 4, as illustrated in the previous
subsection. Fig. 11c shows that both attacks progress at
a slow pace. However, this discrepancy is not true as
depicted in Fig. 12c where Architecture II shows both
attacks progress quickly at different rates. For instance,
Attack 2 reaches 80% after 100 alerts, while Attack 1
reaches 80% after 300 alerts. Moreover, Fig. 11d shows
that Attack 1 progresses faster than Attack 2, which is
also not true, as depicted in Fig. 12d which indicates
Attack 2 is faster than Attack 1. This inaccurate detection
of attacks can adversely affect response decisions, espe-
cially, when a priority-based mechanism is employed [3].

5.4 Error Rate Performance

The next performance measure we propose is the error
rate (ER), which is the ratio of the number of errors
resulting from the inconsistency between the type of an
alert and the corresponding estimated state relative to
the total number of incoming alerts. Formally, ER is
given by the following equation:

ER =

Number of incorrect detected states of the incoming Alerts
Total number of Alerts

× 100 (7)

050100150200250300350400450500012Alerts State 1Observation length, T=500  Attack 1 by HMM1Attack 2 by HMM 2050100150200250300350400450500012Alerts State 2050100150200250300350400450500012Alerts State 3050100150200250300350400450500012Alerts State 4050100150200250300350400450500012Alerts State 50100200300400500012Alerts State 1Observation length, T=500  0100200300400500012Alerts State 2  0100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5Attack 1 by HMM1Attack 2 by HMM 2050100150200250300350400450500012Alerts State 1Observation length, T=500  Attack 1 by HMM1Attack 2 by HMM 2050100150200250300350400450500012Alerts State 2050100150200250300350400450500012Alerts State 3050100150200250300350400450500012Alerts State 4050100150200250300350400450500012Alerts State 50100200300400500012Alerts State 1Observation length, T=500  0100200300400500012Alerts State 2  0100200300400500012Alerts State 30100200300400500012Alerts State 40100200300400500012Alerts State 5Attack 1 by HMM1Attack 2 by HMM 2IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

11

(a) Scenario 3

(b) Scenario 3

(c) Scenario 4

(d) Scenario 4

Fig. 11: Attack Risk Probability Based on Architecture I

(a) Scenario 3

(b) Scenario 3

(c) Scenario 4

(d) Scenario 4

Fig. 12: Attack Risk Probability Based on Architecture II

Note, the exact state corresponding to every incoming
alert is considered based on the knowledge of the input
alerts and their corresponding states. The reasons for in-
consistency between the type of alerts and their detected
states are: (1) the presence of interfering alerts, and (2)
the state estimation error resulting from the enforcement
of the left-right HMM model along with some of the
observations which may be out of sequence due to the
packets generated by the attacker. In Subsection 5.6,
we analyze the effect of False Positives (FPs) and False
Negatives (FNs) introduced by the Snort alert generation
system on the state estimation error.

Fig. 13 shows the plot of ER for different interleaving
scenarios and for several values of T . Note, the error
for Architecture I is due to the aforementioned reasons
(1) and (2), while the error for Architecture 2, is due
to only reason (2). It can be seen from the ﬁgure that
the proposed architectures outperform generic archi-
tecture (Fig. (2)) for interleaving Scenarios 1,2, and 3.
However, for Scenario 4, both Architecture I and the
generic architecture have similar ER, which is higher
than Architecture II. It can also be noted that the ER
for Architecture II remains almost constant with respect
to T and is also the same for all scenarios. Similarly,
Architecture I has an almost constant ER with respect to
T ; however, its ER performance gets worse as the degree
of interleaving increases as compared to Architecture II.
For instance, for Scenario 4, the ER for Architecture I
is as high as 77% as compared to Architecture II which

has a value of 22%. Note, for the generic architecture,
the ER generally increases with T and saturates to a
value. The main reason for this trend is the same as
aforementioned reason (1) and the lack of capability of
this architecture to distinguish between alerts from two
different attacks. In addition, due to the same reason,
the ER of the generic architecture also increases from
Scenario 1 through Scenario 4.

5.5 Number of Correctly Detected Stages per Attack

The third performance measure we propose is the num-
ber of correctly detected stages per attack, which allows
us to analyze the security impact due to missing or
incorrectly detecting stages in a multi-stage attack, espe-
cially in consideration of response actions. We compare
between architectures in terms of the number of detected
stages per attack.

This measure is computed as follows. As we know the
correspondence between alerts and stages (or states) of
the attacks based on the knowledge of the DARPA2000
dataset, we compare the estimated states from each
HMM with the exact states. Table 3 provides the results
for three different values of T . It can be observed that
Architecture II outperforms Architecture I in correctly
detecting more stages for both attacks. The performance
of the two architectures is the same for the interleaving
Scenario 2, as both of them can detect stages 1, 2, 4, and
5 but not 3. This can be seen in Figs. 6b, 7b, 8b, and 9b.
For Scenarios 3 and 4, Architecture II detects more

010020030040050000.050.10.150.20.250.30.350.40.450.5alerts Attack Risk Probability  Observation length, T=500  Attack 1Attack 2010020030040050000.050.10.150.20.250.30.350.40.450.5alerts Attack Risk Probability  Observation length, T=10  Attack 1Attack 2010020030040050000.050.10.150.20.250.30.350.40.450.5alerts Attack Risk Probability  Observation length, T=500  Attack 1Attack 2010020030040050000.050.10.150.20.250.30.350.40.450.5alerts Attack Risk Probability  Observation length, T=10  Attack 1Attack 2010020030040050000.10.20.30.40.50.60.70.80.9alerts Attack Probability  Observation length, T=500  Attack 1Attack 2010020030040050000.10.20.30.40.50.60.70.80.9alerts Attack Probability  Observation length, T=10  Attack 1Attack 2010020030040050000.10.20.30.40.50.60.70.80.9alerts Attack Probability  Observation length, T=500  Attack 1Attack 2010020030040050000.10.20.30.40.50.60.70.80.9alerts Attack Probability  Observation length, T=10  Attack 1Attack 2IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

12

(a) Scenario 1

(b) Scenario 2

(c) Scenario 3

(d) Scenario 4

Fig. 13: State Detection Error Rate at Various interleaving Scenarios

(a) Exact States

(b) Architecture I

(c) Architecture II

Fig. 14: Comparison between Architectures I and II in detecting stages of Attack 2 for Scenario 3

(a) Scenario 1

(b) Scenario 2

(c) Scenario 3

(d) Scenario 4

Fig. 15: The Impact of False Positives on the State Detection Error Rate of Architectures I & II in Scenarios 1-4 Using Various
False Discovery Rates (F DR = 0% − 50%) - The Observation Window Size = 500 and the Number of Experiments = 100

(a) Scenario 1

(b) Scenario 2

(c) Scenario 3

(d) Scenario 4

Fig. 16: The Impact of False Negatives on the State Detection Error Rate of Architectures I & II in Scenarios 1-4 Using Various
False Negative Rates (F N R = 0% − 50%) - The Observation Window Size = 500 and the Number of Experiments = 100

01002003004005000102030405060708090100Observation Length (T) Detection Error Rate   Generic ArchitectureArchitecture IArchitecture II01002003004005000102030405060708090100Observation Length (T) Detection Error Rate  Generic ArchitectureArchitecture IArchitecture II01002003004005000102030405060708090100Observation Length (T) Detection Error Rate  Generic ArchitectureArchitecture IArchitecture II01002003004005000102030405060708090100Observation Length (T) Detection Error Rate  Generic ArchitectureArchitecture IArchitecture II050100150200250300350400450500012345Alerts Exact states of Attack 2050100150200250300350400450500012345Alerts Estimated States of Attack 2 by Architecture I  Interleaved Scenario 3, T=500050100150200250300350400450500012345Alerts Estimated States of Attack 2, by Architecture II  Interleaved scenario 3, T=500IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

13

TABLE 3: Number of Correctly Detected Stages per Attack at Various Interleaving Scenarios

I

II

Scenario 2

Interleaving Scenario Architecture Attack
Attack 1
Attack 2
Attack 1
Attack 2
Attack 1
Attack 2
Attack 1
Attack 2
Attack 1
Attack 2
Attack 1
Attack 2

Scenario 4

Scenario 3

II

II

I

I

T = 10
4
5
4
5
4
4
4
5
1
1
4
5

T = 100
4
5
4
5
4
4
5
5
1
1
5
5

T = 500
4
5
4
5
5
3
5
5
1
1
5
5

stages than Architecture I. For example, all ﬁve stages
of Attack 2 are detected in Scenario 3 using Architecture
II for T = 500, while Architecture I only detects Stages
1 and 5. Fig. 14 shows the estimated states by HMM2
for Attack 2 using Scenario 3. It can be observed that
with Architecture I, Stages 3 and 4 are not detected. The
advantage of Architecture II is more apparent in Table 3
when the interleaving Scenario 4 is used.

Fig. 14 and Table 3 show the importance of this
performance metric in terms of how much lead time is
available to respond to ongoing attacks. For instance,
Fig. 14b shows that Architecture I detects State 2 then
immediately detects State 5 of Attack 2, which implies
that not enough lead time is available to respond to a
progressing attack. While Fig. 14c shows, on the other
hand, that Architecture II detects all states of Attack 2
in a correct sequence similar to the synthesized input
states of Attack 2 shown in Fig. 14a. This performance
metric establishes the importance of considering a large
number of states in modeling the HMM in essence that
the effect of missing a few number of states does not
drastically impact lead time while making real time
response decisions to an ongoing multi-stage attack.

5.6 Impact of False Positives (FPs) and False Nega-
tives (FNs)

The security alerts generated by an IDS are, in general,
noisy and suffer from both FPs and FNs. In the former
case, the IDS (e.g. Snort) generates false alerts when no
attack attempts are happening in the network, and in the
latter case, the IDS fails to detect exploit attempts and
does not generate alerts [40]. In our evaluation of the
proposed architectures, similar effects are observed, as
discussed below.

We have conducted several experiments to study the
impact of FPs and FNs for the proposed HMM archi-
tectures. In our experiments, we synthesize the dataset
by eliminating some of the True Positive alerts (TPs),
in order to mimic FNs, and inject some FPs into the
observation sequence in a randomized fashion. In our
experiments, we vary the False Discovery Rate (FDR)
and the False Negative Rate (FNR) from 0% to 50% for
the alert generation system (Snort). In addition, due to
randomized injection and elimination, we conduct 100
experiments for each interleaving scenario and for each

value of FDR and FNR to identify any potential outliers.
Note, in our experiments, we assume that the FP error
is uniformly induced by all of the alert generation rules
employed by Snort. In other words, the effect of the FPs
is uniformly distributed over generated alerts by Snort.
The results for the impact of FDR for both architectures
are shown in Fig. 15. It can be noticed that the perfor-
mance of Architecture II degrades with the increase of
FDR. This lowered performance is expected as some of
FPs are also ”demultiplexed” and affect the TPs in their
respective substreams when each of these substreams is
processed by the associated HMM template.

However, for Architecture I, the general trend ob-
served is an improvement in the detection error rate
performance which is more noticeable for Scenario 4
(Fig. 15d). A plausible explanation for this trend is that
the FPs in the whole stream either maintain the current
state or allow for a transition to a subsequent state in the
HMM. The DARPA2000 dataset contains a high number
of observations related to State 1 as compared to other
states. Therefore, under the assumption of a uniform
injection of FPs in the alert stream, the likelihood of the
HMM staying in State 1 increases with the increase in
FDR. Note, an HMM template for Architecture I always
leads to State 1 for unrelated observations. Therefore,
as the percentage of FDR increases, this tendency of
staying in State 1 also increases with the high degree
of interleaving due to the increase in the number of
unrelated observations.

The effect of FNs of the IDS system (Snort) on both
architectures is shown in Fig. 16. The effect of the FNR
on the performance of Architecture II is shown in Fig.
16. Note, some of the TPs which are eliminated by
FNs may belong to the erratic behavior of the attacker
(which is reason (2) mentioned in Subsection 5.4), while
some other TPs eliminated by FNs are legitimate (i.e.
correctly sequenced) alerts. A positive effect is shown
on performance in the case of erratic behavior results in
improved performance of detection error rate, while for
the case of legitimate alerts, the performance degrades.
We can notice such improvement and degradation in
the performance for different values of FDR and FNR
as shown in Figs. 15 and 16.

For Architecture I, in addition to reason (2), the reason
(1) (mentioned in Subsection 5.4) also comes into play,
whereby FNs can eliminate some unrelated alerts and

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

14

(a) Exact States

(b) Architecture I

(c) Architecture II

Fig. 17: State Probability of Synthesized Attacks 1 and 2 for the Interleaving Scenario 3 Detected by HMM1 and HMM2 Based
on both Architectures, T=500

thereby reduce the possibility of transition to State 1 and
increasing the possibility of transition from a given state
to the next state. This improvement in the performance
is more noticeable for Scenario 4 where the prospects of
making such forward transitions are higher.

5.7 Performance Evaluation Using Synthesized
Datasets - Case Study 2

The evaluation experiments in the previous case study
(Subsections 5.1-5.6) have been implemented with
DARPA2000 simultaneously interleaved attacks. Due to
the limitation of this dataset in terms of number of
scenarios and due to the lack of availability of datasets
with a large number of attacks,
in this case study,
we generate synthesized datasets that contain different
instances of the DARPA2000 multi-stage attacks. Note,
it is important to point out that our objective is not to
evaluate a speciﬁc dataset, but rather to evaluate the
proposed architectures for detecting complex multi-stage
attacks that are orchestrated by an adversary through
interleaving. The design of the architectures is generic
in the sense they can process any dataset with multiple
attacks. Speciﬁcally, the goal of this case study is to
study the effectiveness of the proposed architectures
when tested on various datasets that have multi-stage
attack instances which vary from from the trained HMM
templates. The importance of this evaluation is that, in
reality, the attacker(s) may not follow the exact same
steps for the same multi-stage attack type, for example,
in terms of the targeted nodes or the number of attempts.
In particular, an HMM generator [42], which gener-
ates sequences for HMM, is used to orchestrate several
instances of a multi-stage attack type. In this case study,
the original DARPA2000 dataset is used for training, and
the generated synthesized datasets is used for testing.

5.7.1 Performance Evaluation - Two Synthesized Multi-
stage Attacks

Fig. 17 shows the state probability of synthesized Attacks
1 and 2 for the interleaving Scenario 3 detected by
HMM1 and HMM2 for Architecture I, Fig. 17b, and for
Architecture II, (Fig. 17c). It can be observed in Fig. 17

that the results of the case study of synthesized multi-
stage attacks are consistent with the previous results for
Scenario 3 from Case study 1, discussed in Subsection
5.2 (Figs. 5c, 6c , 7c), in terms of detection performance
and state estimation. In particular, Architecture II detects
all stages of the interleaved multi-stage attack scenario.
In contrast, Architecture I fails to detect State 5 of Attack
2 as it estimated the state as State 2 and State 3 due to
the noisy observations resulting from unrelated alerts.

5.7.2 Performance Evaluation - Four Synthesized Multi-
stage Attacks

The proposed architectures can be applied to more than
two simultaneous attacks, as well as attacks with differ-
ent instances. We have conducted several experiments,
using synthetic datasets, to study the effect of having
more than two simultaneous multi-stage attacks on the
performance of the proposed architectures. In particular,
Architecture II performs better than Architecture I since
it depends essentially on the demultiplexing operation.
However, with more than two multi-stage attacks, more
computations are involved, especially in the demulti-
plexing module and also in the HMM database com-
ponent. Consequently, the mean time to demultiplex the
stream and to estimate the state for a window size of
100 increases from 0.46 milliseconds to 1.9 milliseconds.
Architecture I works well with more than two attacks,
but its detection performance deteriorates signiﬁcantly
with a large number of attacks and a higher degree
of interleaving. Fig. 18 shows the results for a sce-
nario of four multi-stage attacks. In this scenario, the
attacker(s) in Attack 3 and Attack 4 attempt to hide
an attack with some of their previous attempts that
he/she exploited successfully, which represent two quite
different instances from the trained HMM templates for
these attacks. Although the sequence of observations has
unrelated observations from four different multi-stage
attacks, especially in the window between 300 and 400,
Fig. 18b shows that the proposed architecture estimates
the progress of the attack correctly. Due to page limit,
we show the results for only one scenario of interleaving
from the four multi-stage attacks.

024681012Severity of each Alert0100200300400500Alerts Attack 1Attack 2050100150200250300350400450500Alerts 012State 1Observation length, T=500Attack 1 by HMM1Attack 2 by HMM 2050100150200250300350400450500Alerts 012State 2050100150200250300350400450500Alerts 012State 3050100150200250300350400450500Alerts 012State 4050100150200250300350400450500Alerts 012State 5050100150200250300350400450500Alerts 012state 1Observation length, T=500Attack 1 by HMM1, T=500Attack 2 by HMM2, T=500050100150200250300350400450500Alerts 012state 2050100150200250300350400450500Alerts 012state 3050100150200250300350400450500Alerts 012state 4050100150200250300350400450500Alerts 012state 5IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

15

(a) Exact States

(b) Attack Probability

(c) State Probability

Fig. 18: State Probability of Synthesized Attacks 1 - 4 the Detected by HMM1 and HMM2 Based on Architecture I, T=10

6 CONCLUSION
This paper addresses the detection problem of inter-
leaved multiple multi-stage attacks intruding into a
computer network. We emphasize the importance of
this problem by showing how interleaving and stealthy
attacks can deceive the detection system. Therefore,
we propose two architectures based on a well-known
machine learning technique, i.e., the Hidden Markov
Model, and provide their performance results and com-
putational complexity. Both architectures can track in-
terleaved attacks by detecting the correct states of the
system for each incoming alert. However, as the degree
of interleaving among attacks increases, Architecture II,
which employs a demultiplexing mechanism, exhibits
more robustness and better performance as compared to
Architecture I. For the performance assessment of these
architectures, we propose three performance metrics
which include (1) attack risk probability, (2) detection er-
ror rate, and (3) the number of correctly detected stages.
The DARPA2000 dataset is chosen to synthesize inter-
leaved multi-stage attack scenarios and to demonstrate
the efﬁcacy of the proposed architectures. The proposed
architectures are generic in terms of their capability to
process any dataset that contains multiple interleaved
multi-stage attacks.

7 ACKNOWLEDGMENT
This research was supported by the grants from
Northrop Grumman Corporation and US National Sci-
ence Foundation (NSF) Grant IIS-0964639 and was sup-
ported by King Abdulaziz University. Distribution State-
ment A: Approved for Public Release; Distribution is
Unlimited #18-1658, Dated 10/30/18.

REFERENCES

[1] CNET, “Wannacry ransomware: Everything you need to know,”

2017, accessed: 2017-10-22.

[2] Washingtonpost,

“Massive

cyberattack

hits

europe with

[3]

widespread ransom demands,” 2017, accessed: 2017-10-22.
S. Jajodia and M. Albanese, “An Integrated Framework for Cyber
Situation Awareness”. Springer International Publishing, 2017.

[4] N. Luktarhan, X. Jia, L. Hu, and N. Xie, “Multi-stage attack detec-
tion algorithm based on hidden markov model,” in International
Conference on Web Information Systems and Mining. Springer, 2012.

[5]

J. Navarro, A. Deruyver, and P. Parrend, “A systematic survey on
multi-step attack detection,” Computers & Security, 2018.

[6] X. Qin and W. Lee, “Attack plan recognition and prediction using
causal networks,” in 20th Annual Computer Security Applications
Conference, 2004, pp. 370–379.
F. Valeur, G. Vigna, C. Kruegel, and R. A. Kemmerer, “Compre-
hensive approach to intrusion detection alert correlation,” IEEE
Transactions on Dependable and Secure Computing, 2004.

[7]

[8] B. C. Cheng, G. T. Liao, C. C. Huang, and M. T. Yu, “A novel
probabilistic matching algorithm for multi-stage attack forecasts,”
IEEE Journal on Selected Areas in Communications, 2011.

[9] L. Wang, A. Liu, and S. Jajodia, “Using attack graphs for corre-
lating, hypothesizing, and predicting intrusion alerts,” Computer
Communications, vol. 29, no. 15, pp. 2917 – 2933, 2006.

[10] D. S. Fava, S. R. Byers, and S. J. Yang, “Projecting cyberattacks
through variable-length Markov models,” IEEE Transactions on
Information Forensics and Security, vol. 3, no. 3, pp. 359–369, 2008.
[11] H. Du, D. F. Liu, J. Holsopple, and S. J. Yang, “Toward ensemble
characterization and projection of multistage cyber attacks,” Pro-
ceedings - International Conference on Computer Communications and
Networks, ICCCN, 2010.

[12] A. A. Ramaki, M. Amini, and R. Ebrahimi Atani, “RTECA: Real
time episode correlation algorithm for multi-step attack scenarios
detection,” Computers and Security, vol. 49, pp. 206–219, 2015.
[Online]. Available: http://dx.doi.org/10.1016/j.cose.2014.10.006
[13] F. Manganiello, M. Marchetti, and M. Colajanni, “Multistep attack
detection and alert correlation in intrusion detection systems,” in
Information Security and Assurance, T.-h. Kim, H. Adeli, R. J. Robles,
and M. Balitanas, Eds., 2011.

[14] P. Ning and D. Xu, “Learning attack strategies from intrusion
alerts,” in Proceedings of the 10th ACM Conference on Computer
and Communications Security, ser. CCS ’03. New York, NY,
USA: ACM, 2003, pp. 200–209.
[Online]. Available: http:
//doi.acm.org/10.1145/948109.948137

[15] L. Huiying, P. Wu, W. Ruimei et al., “A real-time network threat
recognition and assessment method based on association analysis
of time and space,” Journal of Computer Research and Development,
vol. 51, no. 5, pp. 1039–1049, 2014.

[16] C. Onwubiko, “Situational Awareness in Computer Network Defense:
Principles, Methods and Applications: Principles, Methods and Appli-
cations”.

IGI Global, 2012.

[17] Z. Zali, M. R. Hashemi, and H. Saidi, “Real-time attack scenario
detection via intrusion detection alert correlation,” in Information
Security and Cryptology (ISCISC), 2012 9th International ISC Confer-
ence on.

IEEE, 2012, pp. 95–102.

[18] F. Alserhani, M. Akhlaq, I. U. Awan, A. J. Cullen, and P. Mirchan-
dani, “Mars: multi-stage attack recognition system,” in Advanced
Information Networking and Applications (AINA), 2010 24th IEEE
International Conference on.

IEEE, 2010, pp. 753–759.

[19] W. J. Zhang Hengwei, Yang Haopu and L. Tao, “Multi-step attack-
oriented assessment of network security situation,” International
Journal of Security and Its Application, 2017.

[20] D. Ourston, S. Matzner, W. Stump, and B. Hopkins, “Applications
of Hidden Markov Models to Detecting Multi-Stage Network
Attacks,” Proceedings of the 36th Annual Hawaiian International
Conference on System Sciences, p. 334, 2003.

[21] A. ˚Arnes, K. Sallhammar, K. Haslum, T. Brekne, M. E. G. Moe, and

0123456Severity of each Alert01002003004005006007008009001000Alerts Attack 1Attack 2Attack 3Attack 401002003004005006007008009001000Alerts 00.10.20.30.40.50.60.70.80.9Attack Risk Probability  Observation length, T=10Attack 1Attack 2Attack 3Attack 401002003004005006007008009001000Alerts 012State 1Observation length, T=10Attack 1 by HMM 1Attack 2 by HMM 2Attack 3 by HMM 3Attack 4 by HMM 401002003004005006007008009001000Alerts 012State 201002003004005006007008009001000Alerts 012State 301002003004005006007008009001000Alerts 012State 401002003004005006007008009001000Alerts 012State 5IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. XX, NO. X, MONTH 20XX, DOI: 10.1109/TDSC.2019.2948623

16

S. J. Knapskog, “Real-time risk assessment with network sensors
and intrusion detection systems,” in International Conference on
Computational and Information Science. Springer, 2005.

[22] K. Haslum, A. Abraham, and S. Knapskog, “Fuzzy online risk
assessment for distributed intrusion prediction and prevention
systems,” Proceedings - UKSim 10th International Conference on
Computer Modelling and Simulation, EUROSIM/UKSim2008, pp.
216–223, 2008.

[23] H. Farhadi, M. Amirhaeri, and M. Khansari, “Alert Correlation
and Prediction Using Data Mining and HMM,” The ISC Int’l
Journal of Information Security, vol. 3, pp. 77–101, 2011.

[24] A. S. Sendi, M. Dagenais, M. Jabbarifar, and M. Couture, “Real
time intrusion prediction based on optimized alerts with hidden
markov model.” JNW, vol. 7, no. 2, pp. 311–321, 2012.

[25] S. Zonouz, K. M. Rogers, R. Berthier, R. B. Bobba, W. H. Sanders,
and T. J. Overbye, “Scpse: Security-oriented cyber-physical state
estimation for power grid critical infrastructures,” IEEE Transac-
tions on Smart Grid, vol. 3, no. 4, pp. 1790–1799, 2012.

[26] H. A. Kholidy, A. Erradi, S. Abdelwahed, and A. Azab, “A ﬁnite
state hidden markov model for predicting multistage attacks in
cloud systems,” in Dependable, Autonomic and Secure Computing
(DASC), 2014 IEEE 12th International Conference on, 2014.

[27] P. Holgado, V. A. Villagra, and L. Vazquez, “Real-time multistep
attack prediction based on hidden markov models,” IEEE Trans-
actions on Dependable and Secure Computing, 2017.

[28] A. R. Ali, R. Abbas, and J. J. Abbas, “A systematic review
on intrusion detection based on the hidden markov model,”
Statistical Analysis and Data Mining: The ASA Data Science
Journal, vol. 11, no. 3, pp. 111–134, 2018. [Online]. Available:
https://onlinelibrary.wiley.com/doi/abs/10.1002/sam.11377
[29] M. Albanese, S. Jajodia, A. Pugliese, and V. S. Subrahmanian,
“Scalable analysis of attack scenarios,” Lecture Notes in Computer
Science (including subseries Lecture Notes in Artiﬁcial Intelligence and
Lecture Notes in Bioinformatics), vol. 6879 LNCS, pp. 416–433, 2011.
[30] L. R. Rabiner, “A tutorial on hidden markov models and se-
lected applications in speech recognition,” Proceedings of the IEEE,
vol. 77, no. 2, pp. 257–286, 1989.

[31] L. L. M. I. of Technology, “Defense advanced research projects

agency dataset (darpa),” 2015.

[32] J. Yin and Y. Meng, “Abnormal behavior recognition using self-
adaptive hidden markov models,” in Image Analysis and Recogni-
tion, M. Kamel and A. Campilho, Eds.
Springer Berlin Heidel-
berg, 2009.

[33] Snort, “The snort intrusion detection system,” 2015.
[34] Barnyard2, “Barnyard2: an open source interpreter for snort out-

put ﬁles,” 2016.

[35] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom, “Mod-
els and issues in data stream systems,” in Proceedings of the Twenty-
ﬁrst ACM SIGMOD-SIGACT-SIGART Symposium on Principles of
Database Systems, ser. PODS ’02, 2002.

[36] M. Becchi and P. Crowley, “A hybrid ﬁnite automaton for practical
deep packet inspection,” in Proceedings of the 2007 ACM CoNEXT
Conference, ser. CoNEXT ’07, 2007.

[37] C. R. Meiners, J. Patel, E. Norige, E. Torng, and A. X. Liu,
“Fast regular expression matching using small tcams for network
intrusion detection and prevention systems,” in Proceedings of the
19th USENIX Conference on Security, ser. USENIX Security’10, 2010.
[38] X. Yu, B. Lin, and M. Becchi, “Revisiting state blow-up: Au-
tomatically building augmented-fa while preserving functional
equivalence,” IEEE Journal on Selected Areas in Communications,
2014.

[39] X. Yu, W.-c. Feng, D. D. Yao, and M. Becchi, “O3FA: A scalable
ﬁnite automata-based pattern-matching engine for out-of-order
deep packet inspection,” in Proceedings of the 2016 Symposium
on Architectures for Networking and Communications Systems, ser.
ANCS ’16, 2016.

[40] G. C. Tjhai, M. Papadaki, S. M. Furnell, and N. L. Clarke,
“Investigating the problem of ids false alarms: An experimental
study using snort,” in SEC, 2008.

[41] D. Curry, “Intrusion detection message exchange format data
model and extensible mark-up language (xml) document type
deﬁnition,” draft-ietf-idwg-idmef-xml-09. txt, 2002.

[42] MATLAB and Statistics Toolbox Release 2017a, The MathWorks,

Inc., Natick, Massachusetts, United States.

Tawfeeq Shawly received the M.S. and Ph.D.
degrees in communications, networking, and
signal processing from the School of Electrical
and Computer Engineering, Purdue University,
West Lafayette, IN, USA, in 2016 and 2019,
respectively. He is an Assistant Professor in the
Electrical Engineering Department at the King
Abdulaziz University in Rabigh, Saudi Arabia.
His research interests include security of net-
worked cyber-physical systems, artiﬁcial intelli-
gence and machine learning.

Ali Elghariani (S’12-M’14) received the B.S.
and M.S. degrees in electrical and electronic
engineering from the University of Tripoli, Tripoli,
Libya. He obtained his Ph.D. degree in communi-
cations, networking, and signal processing from
the School of Electrical and Computer Engineer-
ing, Purdue University, West Lafayette, IN, USA,
in 2014. Currently, he is a research engineer at
XCOM-Labs in San Diego CA. When this paper
was submitted, he was a visiting researcher at
Purdue University, West Lafayette IN. In 2015-
2016, he was a Lecturer at the Department of Electrical and Electronic
Engineering, University of Tripoli, Tripoli, Libya. His research interests
include signal detection and channel estimation in large-scale MIMO
systems, mmwave communication, optimization techniques in wireless
communications, and network security.

PLACE
PHOTO
HERE

Jason Kobes works as a principal cyber archi-
tect and research scientist in Washington, DC for
Northrop Grumman Corporation. He has over 20
years of experience concentrated in information
systems design analytics, business/mission se-
curity architecture, enterprise risk management,
information assurance research, and business
consulting. He has an M.S. in information as-
surance (MSIA) and a B.S. in computer science
from Iowa State University.

Arif Ghafoor is a professor in the School of
Electrical and Computer Engineering at Purdue
University. His research interests include multi-
media information systems, database security,
and distributed computing. He is a Fellow of the
IEEE.

