0
2
0
2

n
u
J

0
1

]

R
C
.
s
c
[

1
v
5
4
0
6
0
.
6
0
0
2
:
v
i
X
r
a

Evaluating the Exploitability of Implicit Interactions
in Distributed Systems

Jason Jaskolka

Systems and Computer Engineering
Carleton University
Ottawa, ON Canada
jason.jaskolka@carleton.ca

Abstract—Implicit

interactions refer to those interactions
among the components of a system that may be unintended
and/or unforeseen by the system designers. As such, they repre-
sent cybersecurity vulnerabilities that can be exploited to mount
cyber-attacks causing serious and destabilizing system effects. In
this paper, we study implicit interactions in distributed systems
speciﬁed using the algebraic modeling framework known as
Communicating Concurrent Kleene Algebra (C2KA). To identify
and defend against a range of possible attack scenarios, we
develop a new measure of exploitability for implicit interactions
to aid in evaluating the threat posed by the existence of such
vulnerabilities in system designs for launching cyber-attacks.
The presented approach is based on the modeling and analysis
of the inﬂuence and response of the system agents and their
C2KA speciﬁcations. We also demonstrate the applicability of
the proposed approach using a prototype tool that supports the
automated analysis. The rigorous, practical techniques presented
here enable cybersecurity vulnerabilities in the designs of dis-
tributed systems to be more easily identiﬁed, assessed, and then
mitigated, offering signiﬁcant improvements to overall system
resilience, dependability, and security.

Index Terms—Implicit interactions, Communicating Concur-
rent Kleene Algebra (C2KA), exploitability, attack scenarios,
cybersecurity.

I. INTRODUCTION AND MOTIVATION

Implicit interactions refer to component interactions within
a distributed system that may be unfamiliar, unplanned, or
unexpected, and either not visible or not immediately com-
prehensible by the system designers [1]. These kinds of
interactions have also been referred to as hidden interactions
in the literature, although it is not necessary that they are
intentionally hidden from the view of the system designers.
Implicit interactions represent previously unknown linkages
among system components. Because system designers are gen-
erally unaware of such linkages, they indicate the presence of
cybersecurity vulnerabilities that can be exploited by attackers.
This can have severe consequences in terms of the system’s
safety, security, and reliability.

In previous work [1], [2], we developed a rigorous and
systematic approach for identifying the existence of implicit
interactions in distributed systems. The approach involves the
speciﬁcation and analysis of the communication among system
components using the Communicating Concurrent Kleene Al-
gebra (C2KA) modeling framework [3], [4]. More speciﬁcally,

the approach veriﬁes whether each possible interaction in
a given system exists as part of a characterization of the
intended system interactions resulting from the system design.
In any system engineering process, the articulation of the
expected behaviour and operation of the system results in a
set of intended sequences of communication and interaction
among the components of the system. This set of intended
interactions is typically derived from the system description
and requirements explicitly provided by the system designer.
Therefore, any interaction that is found to deviate from this
expected or intended behaviour is an implicit interaction.

However, while identifying the existence of these vulnera-
bilities is a critically important initial step, it is also necessary
to examine whether they are likely to manifest in real-world
systems [1]. A natural next step is to determine the ways in
which such vulnerabilities can be exploited to mount a cyber-
attack in the system. This information is critical in assessing
the severity of the vulnerabilities, as well as in determining
measures to mitigate the potential that they could be exploited
in an attack.

In this paper, we present an approach for evaluating the
exploitability of implicit
interactions in distributed system
designs. The approach is based on attack scenario deter-
mination, which looks to ﬁnd the set of possible ways in
which a compromised system agent can exploit a particular
implicit interaction to mount a cyber-attack that inﬂuences the
behaviour of other agents in the system. The attack scenario
determination involves an analysis of the set of implicit
interactions identiﬁed using the technique proposed in [2] and
the C2KA speciﬁcation of the system. Using the results of
the attack scenario determination for an identiﬁed implicit
interaction, we compute a measure of its exploitability to more
accurately assess the threat that it poses to the overall safety,
security, and reliability of the system. Thus, the key objective
of this paper is to provide a systematic approach for evaluating
the ways in which implicit interactions can be used to mount
cyber-attacks in a given system, as well as speciﬁc guidance
on ways to modify system designs to reduce the potential
exposure to such attacks. Note that while critically important,
in this paper, we are not assessing the potential impact that
a cyber-attack resulting from the exploitation of an implicit
interaction may have on a given system, but rather the ways in

 
 
 
 
 
 
which an attacker may use an implicit interaction to affect the
behaviour of the system in order to support the development
of methodologies and mechanisms for achieving systems with
improved dependability and security.

The rest of this paper is organized as follows. Section II
compares and contrasts our proposed approach with related
work. Section III provides the required background for the
approach and associated mathematical framework, and Sec-
tion IV outlines an illustrative example that will be used
to demonstrate the proposed approach throughout this paper.
Section V provides a high-level overview of the proposed
approach for readers that wish to forgo the technical details
provided in Sections VI–VIII. Section VI develops the theo-
retical background required for analyzing the inﬂuence and
response of agents in a distributed system speciﬁed using
C2KA. Section VII articulates the proposed approach for
determining the possible attack scenarios that can exploit
implicit interactions. Section VIII presents a measure of the
exploitability of an implicit interaction. Section IX presents
a summary of our experimental results in evaluating the
exploitability of implicit interactions and provides a discussion
of the proposed approach. Lastly, Section X concludes and
discusses future work.

II. RELATED WORK

In this section, we compare and contrast our contributions
with the existing literature related to assessing the exploitabil-
ity of cybersecurity vulnerabilities, and studying information
ﬂows, dependence, and causality in distributed systems.

A. Threat Modeling and Risk Management Frameworks

The Common Vulnerability Scoring System (CVSS) [5] is
largely considered the de facto standard for quantifying and
assessing the severity and risk of security vulnerabilities in
computing systems. CVSS metrics are designed to measure the
fundamental characteristics of vulnerabilities that can be used
to compute measures of exploitability. In CVSS, exploitability
is a function of metrics called access vector, access complex-
ity, and authentication. The access vector metric provides a
measure of how a vulnerability is exploited (e.g., locally or
remotely). The access complexity metric provides a measure
of the amount of effort that is needed to exploit a vulnerability
once a malicious agent has gained access to the system. Lastly,
the authentication metric provides a measure of the number of
times that a malicious agent needs to authenticate itself to
successfully exploit the vulnerability. A number of additional
frameworks for measuring cybersecurity-related vulnerabilities
and risks, such as the OCTAVE risk management frame-
work [6] and the Microsoft Exploitability Index [7], have also
been proposed. More recently, extensions to CVSS that use
stochastic modeling to aid in improving decision making and
reducing risk have been proposed (e.g., [8]).

However, CVSS and its associated exploitability analysis, as
well as other similar frameworks, have received much criticism
due to their perceived subjectivity and lack of speciﬁcity in
the ways in which values are measured and assigned (e.g., [9],

[10]). By developing a rigorous technique for determining
the ways in which a vulnerability can be exploited based on
the system speciﬁcation and design, the approach proposed in
this paper, as well as the developed measure of exploitability,
avoids this kind of subjectivity and lack of speciﬁcity.

B. Attack Surfaces

Generally speaking, attack surfaces are related to expo-
sures enabling a malicious agent to mount a cyber-attack on
a system. Attack surfaces are typically considered along a
number of different dimensions including interfaces, channels,
protocols, and access rights, among others. The intuition
behind analyzing and measuring a system’s attack surface is
based on the idea that the more extensive and exposed the
system’s attack surface is, the more opportunity for a malicious
agent to conduct an attack [11]. Therefore, many approaches
aim to improve security by reducing the attack surface of the
system in question. An important element of this process is
understanding the system’s attack surface. For example, [11]
proposed a metric called the Relative Attack Surface Quotient.
This was expanded upon in [12] which additionally proposed
considering the damage potential-effort ratios associated with
possible attacks. A similar approach was proposed in [13].
More recently researchers have looked to assess the likelihood
of an attack by considering the possibility for individual, co-
ordinated, and concurrent attacks [14]. New approaches have
also developed more objective metrics derived from attack
surface, vulnerability, and exploitation analyses by studying
software properties [10].

However, attack surface metrics are often designed to
measure the exploitability of an entire system, rather than
the exploitability of individual vulnerabilities. By comparison,
the proposed approach studies the exploitability of each in-
dividually identiﬁed vulnerability (i.e., each implicit interac-
tion). Consequently, this allows us to obtain information that
can help in determining where and how to spend valuable
resources to mitigate the most severe, or most exploitable,
vulnerabilities.

C. Formal Veriﬁcation and Test-Based Approaches

Many existing approaches for conducting vulnerability and
exploitability analyses involve the development high-level
models of system components for which security-relevant
properties can be formalized and analyzed to verify their
satisfaction in the composite system. For example, [15] pro-
posed formal approaches for specifying desired security prop-
erties and conducting vulnerability and exploitability analyses.
Also, [16] proposed the Correlated Attack Modeling Language
(CAML) to help in automatically identifying cyber-attack sce-
narios.

Other approaches look to perform formal veriﬁcation and
analyses on program code. The use of such techniques for
specifying and analyzing systems is often highly desirable
when developing systems with high standards of safety, secu-
rity, and reliability [17]. In [18], a symbolic analysis approach

that operates on disassembled binary code to identify condi-
tions by which a malicious agent can exploit a “dangerous
path” was proposed. In [19], an approach for verifying pro-
grams represented in a specialized modeling language using
a formal security domain model was presented. The approach
aimed to detect execution paths that violated the security prop-
erties speciﬁed in the domain model. However, the ability to
identify and analyze exploitable vulnerabilities at earlier stages
of system development was desired. As such, [20] provided an
approach that studied system architectures to identify possible
scenarios and metrics, similar to those derived for attack
surfaces, that can be used to determine which system vulnera-
bilities may be exploitable. The possible scenarios and security
metric signatures were formalized using the Object Constraint
Language. This allowed for the development of an approach
supporting both metric-based and scenario-based architecture
security analysis. Similarly, [21] provided a constraint-based
approach for identifying and mitigating cascading network
paths that compromise security.

Test-based approaches aim to provide a proof-of-concept
that a given system vulnerability can be exploited by a
malicious system agent. Black-box fuzz testing is a common
technique used for this purpose (e.g., [22]). Other test-based
approaches look to use static analysis to ﬁnd potential vulner-
abilities in program code, and then combinations of static and
dynamic analyses to uncover execution paths within the code
for which an exploit can be automatically generated. This is the
idea behind Automatic Exploit Generation (AEG) [23], which
generates evidence that identiﬁed security vulnerabilities are
exploitable. However, testing-based techniques such as AEG
and fuzz testing are not easily scalable and are typically only
suited for particular types of systems.

By comparison, the approach proposed in this paper is
targeted at analyzing systems at much earlier stages of de-
velopment. Rather than analyzing program code, we aim to
analyze the speciﬁcation and design of distributed cyber-
physical systems at a high-level of abstraction. This can allow
for substantial savings in terms of the costs associated with
minimizing cybersecurity vulnerabilities, and recovering from
the effects of a cyber-attack.

D. Models of Information Flow, Dependence, and Causality

Among the most well-known approaches for studying the
interactions of components in complex distributed systems
and networks has been information ﬂow analysis [24]. Many
approaches targeted at modeling and analyzing information
ﬂow with respect to cybersecurity requirements have been
proposed using a variety of formalisms such as state machines
(e.g., [25]), Petri nets (e.g., [26]), process algebras (e.g., [24],
[27]), typing systems (e.g., [28], [29]), and axiomatic ap-
proaches (e.g., [30], [31]). Furthermore, models and notions
of causality, such as those proposed in [32] and [33] have also
provided foundational approaches for studying the dependence
of actions in distributed systems.

Numerous other approaches aimed at formally analyzing
and verifying of concurrent systems (e.g., [34]–[36]), as well

as the formal veriﬁcation of dynamic and parametrized sys-
tems and networks (e.g., [37], [38]) have also been prosed.
These publications have laid important groundwork for ap-
proaches aimed at providing assurances that systems operate
as expected as they continue to grow in size and complexity.
Although many formalisms and approaches exist for mod-
eling and studying interactions, information ﬂows, and depen-
dencies among components in distributed systems, we propose
an alternative approach meant to aid designers, at early stages
of system development, in systematically evaluating the ways
in which security vulnerabilities in their designs can be ex-
ploited to cause unexpected, and potentially unsafe and inse-
cure, system behaviours. Our approach, based on the C2KA
modeling framework, provides a different and complementary
perspective for studying the interactions of system components
and evaluating the exploitability of security vulnerabilities in
system designs, than what is offered by existing formalisms
and approaches.

III. BACKGROUND AND PRELIMINARIES

In this section, we brieﬂy introduce Communicating Con-
current Kleene Algebra and the required preliminaries related
to specifying agents and interactions.

A. Communicating Concurrent Kleene Algebra

(cid:1)

(cid:1)

SK, ⊕
(cid:0)

(cid:0)SK, +

and a right K-semimodule

Communicating Concurrent Kleene Algebra (C2KA) [3], [4]
is an algebraic framework for specifying the concurrent and
communicating behaviour of agents in a distributed system.
A C2KA is a mathematical system consisting of a left S-
semimodule
SK, ⊕
(cid:1)
(cid:0)
which characterize how a stimulus structure S and a CKA K
mutually act upon one another to describe the response in-
voked by a stimulus on an agent behaviour as a next behaviour
and a next stimulus.
describes how the stimulus
(cid:0)SK, +
(cid:1)
structure S acts upon the CKA K via the next behaviour
mapping ◦ and
describes how the CKA K acts upon
the stimulus structure S via the next stimulus mapping λ. The
formal deﬁnition of a C2KA is given in Deﬁnition 1.
Deﬁnition 1 (C2KA — e.g., [4]). A C2KA is a system
,
S, K
(cid:0)
(cid:1)
where S =
is a stimulus structure and K =
K, +, ∗, ; , *(cid:13), ;(cid:13), 0, 1
(cid:0)S K, +
(cid:1)
(cid:0)
is a unitary and zero-preserving left S-semimodule with next
behaviour mapping ◦ : S × K → K and
is a unitary
and zero-preserving right K-semimodule with next stimulus
mapping λ : S × K → S, where the following axioms are
satisﬁed for all a, b, c ∈ K and s, t ∈ S:
(a) s ◦ (a ; b) = (s ◦ a) ;
(b) a ≤K c ∨ b = 1 ∨ (s ◦ a) ;
(c) λ(s ⊙ t, a) = λ
s, (t ◦ a)
(cid:1)
(cid:0)
(d) s = d ∨ s ◦ 1 = 1
(e) a = 0 ∨ λ(n, a) = n

λ(s, c) ◦ b
(cid:0)
⊙ λ(t, a)

is an atomic CKA such that

S, ⊕, ⊙, d, n
(cid:0)

λ(s, a) ◦ b
(cid:0)

SK, ⊕
(cid:0)

= 0

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

The reader is referred to the Appendix A for a summary
of the algebraic structures mentioned in this discussion, and
to [3], [4], [39] for a full description of C2KA.

Many complex distributed systems involve intensive com-
munication and exchange with their environment, which often
includes other systems. Consequently, when modeling such
systems, the interactions between the system and its envi-
ronment need to be carefully taken into account [40]. C2KA
allows for the separation of communicating and concurrent
behaviour in a system and its environment and for the expres-
sion of the inﬂuence of stimuli on agent behaviours, thereby
providing the capability to model and capture the dynamic
behaviour of complex distributed systems by considering these
important interactions.

(cid:1)

S, ·, 1
(cid:0)

1) Atomic Behaviours and Stimuli: For a commutative
with a, b ∈ S, the divisibility relation div is
monoid
deﬁned on S via a div b ⇐⇒ ∃(c | c ∈ S : b = a · c ). An
element a is called a unit if a div 1, and a non-unit otherwise.
A non-unit a is called an atom if a = b · c implies that either b
is atomic if every non-unit
or c is a unit. We say that
S, ·, 1
(cid:0)
may be factored into atoms in at least one way. Throughout the
remainder of this paper, the set of atomic behaviours will be
denoted by Ka, and the set of atomic stimuli will be denoted
by Sa.

(cid:1)

(cid:1)

S, +, ·, 0, 1
(cid:0)

2) Sub-Behaviours and Sub-Stimuli:

K, +, ∗, ; , *(cid:13), ;(cid:13), 0, 1
(cid:0)

In general, every
idempotent semiring
has a natural partial or-
der ≤ on S deﬁned by a ≤ b ⇐⇒ a + b = b. This means
that associated with a CKA K =
,
(cid:1)
there is an ordering relation ≤K related to the semirings
upon which K is built representing the sub-behaviour relation.
For behaviours a, b ∈ K, a ≤K b indicates that a is a
sub-behaviour of b if and only if a + b = b. Similarly,
associated with a stimulus structure S =
is
an ordering relation ≤S representing the sub-stimulus relation.
For stimuli s, t ∈ S, s ≤S t indicates that s is sub-stimulus of t
if and only if s ⊕ t = t. These notions will play an important
role in the attack scenario determination in Section VII-B.

S, ⊕, ⊙, d, n
(cid:0)

(cid:1)

(cid:10)

(cid:11)

b
(cid:10)

a
(cid:10)

3) Agents:

In this paper,

the term agent refers to any
system, component, or process whose behaviour consists of
where A is the name
discrete actions [41]. We write A 7→
given to an agent and a ∈ K is its behaviour. For A 7→
a
(cid:11)
(cid:10)
and B 7→
.
a + b
(cid:11)
In a similar way, we can extend the remaining operators on
behaviours of K to their corresponding agents. Thus, agents
are deﬁned by simply describing their behaviour, and for
this reason, we may use the terms agents and behaviours
interchangeably.

, we write A + B to denote the agent
(cid:11)

4) Specifying Agents using C2KA: C2KA provides three
levels of speciﬁcation for the behaviour of agents in dis-
tributed systems. The stimulus-response speciﬁcation of agents
speciﬁes the next behaviour mapping ◦ and next stimulus
mapping λ for each agent. This involves specifying how each
atomic stimulus that can be issued acts upon the atomic
behaviours that each agent can have in the given system. The
abstract behaviour speciﬁcation speciﬁes each agent behaviour
as a CKA term. This enables the speciﬁcation of complex
agent behaviours without the need to explicitly articulate the
dependencies between agent behaviours, or to further reﬁne
agent behaviours into state-based speciﬁcations. Lastly, the

concrete behaviour speciﬁcation provides the state-level spec-
iﬁcation of each agent behaviour. At this level, the concrete
programs for each of the CKA terms which specify each
agent behaviour are given using any suitable programming or
speciﬁcation language. In this paper, we use Dijkstra’s guarded
command language [42] for this purpose.

To determine the possible ways that agents in a distributed
system can interact and inﬂuence each other’s behaviour,
we need to consider multiple levels of abstraction in the
speciﬁcation and analysis of the system. These multiple levels
of abstraction correspond to the possibility for agents to com-
municate via stimuli (i.e., message-passing communication)
by considering the stimulus-response and abstract behaviour
speciﬁcations, or via shared environments (i.e., via shared vari-
able communication) by considering the concrete behaviour
speciﬁcations. For this reason, all three levels of speciﬁcation
are required for the analysis approach presented in Section VII.

B. Agent Interactions

A distributed system may consist of numerous agents, and
may feature complex agent interactions for synchronizing and
sequencing behaviour, or coordinating access to shared re-
sources, for example. In a distributed system formed by a set A
of agents, agent interactions are represented as sequences of
def
agents in the following form: pTn
= An →Tn An−1 →Tn−1
n
. . . →T2 A1 →T1 A0 where each Ai ∈ A for all 0 ≤ i ≤ n,
and each Tj ∈ {S, E} for all 1 ≤ j ≤ n. In an agent interac-
tion, →S denotes direct communication via stimuli and →E
denotes direct communication via shared environments. These
notions are discussed in more detail in Sections VI-A and
VI-B. In this way, an interaction pTn
n can be written recursively
def
= An →Tn pTn−1
such that pT1
n−1 .
1
The length of an interaction pTn
n |) is counted by
the number of direct communications of which it is comprised
(i.e., |pTn

def
= A1 →T1 A0 and pTn
n
n (denoted |pTn

n | = n − 1).

Additionally, for an interaction pTn

n , we call An the source
agent of the interaction, A0 the sink agent of the interaction,
and each Ai−1 the neighbouring agent of Ai for all 1 ≤ i ≤ n.
Moreover, when we refer to a compromised agent, we mean
any agent A ∈ A that can behave in a way that is not consistent
with its original or intended speciﬁcation, meaning that it has
the ability to issue any stimulus s ∈ S and/or alter its concrete
behaviour (e.g., by deﬁning a program variable v in the set of
all program variables in the state space of the system).

IV. AN ILLUSTRATIVE EXAMPLE

Distributed systems, where each agent is responsible for
providing some information, or controlling some element of
the system, play a vital role in many critical industries, such
as critical infrastructures, aerospace, automotive, and indus-
trial manufacturing. In this paper, we consider an illustrative
maritime port container terminal coordination system adapted
from [43].

A. Port Terminal Coordination System Description

The port terminal coordination system consists of six classes
of agents, which consist of both cyber components (e.g.,
control software) and physical components. The Port Cap-
tain (PC) decides how the ship will be managed once it
arrives at the port, and initializes the arriving ship’s infor-
mation. The Ship Managers (SMi) are assigned to manage
the loading/unloading of an arriving ship, and for determining
its desired service time. For each Ship Manager, there is an
associated Stevedore (SVi) that is responsible for requesting
cranes and planning the loading/unloading operations for an
arriving ship. The Terminal Manager (TM) allocates the berth
points (i.e., the docking position) for an arriving ship, and
allocates cranes to service a ship based on requests from the
Stevedores. The Crane Manager (CM) is responsible for coor-
dinating the cranes to carry out the loading/unloading sequence
as efﬁciently as possible. The Carrier Coordinator (CC) is
responsible for managing the straddle carrier positions to aid
in loading/unloading the ship, and moving containers on the
ground of the shipping yard.

When a ship approaches the port, it transmits an arrive
message to begin the port-side operations. The Port Cap-
tain PC responds to the arrive message by determining
how to manage the ship upon its arrival at the port, and
initializing its record of the ship’s information. For the purpose
of illustration in this paper, assume that there are two Ship
Managers SM1 and SM2. This means that there are also two
Stevedores SV1 and SV2 assigned to their corresponding Ship
Managers. Assume that PC non-deterministically chooses to
use SM1 and SV1, or SM2 and SV2 to manage arriving ships.
Based on its choice, PC sends either a mnge1 message or
a mnge2 message to notify the appropriate Ship Manager
that is has been assigned to manage the arriving vessel. In
what follows, we describe the operation of the system in the
case where a mnge1 message is sent. An analogous operation
involving SM2 and SV2 occurs in the event that PC sends
a mnge2 message.

Upon receiving a mnge1 message, Ship Manager SM1
responds by reading the ship information from PC and com-
puting the desired service time according to the following
formula: tservice = tdepart − tarrive − twait. After computing the
desired service time, SM1 issues a ship1 request. Upon receiv-
ing a ship1 request, Stevedore SV1 tries to satisfy the request
by calculating the number of cranes n needed to service the
ship. This calculation is based on the number of containers c,
the desired service time tservice, the average efﬁciency of the
cranes x (moves per hour), and according to the following
formula: n = c/(x ∗ tservice). Once completed, SV1 sends
a crane1 request.

The Terminal Manager TM responds to the crane1 request
by allocating the berth points for the ship and then allocat-
ing cranes to service the ship. After completing the alloca-
tions, TM issues an allocd message. The waiting SV1 responds
to the allocd message by determining a ship bay allocation
plan based on the crane allocation and berth position. Upon

completion of the plan, SV1 conveys the berth position to SM1
via a berth message. SM1 responds to the berth message
by updating the ship docking position, and issuing a dock
command to notify the ship that it may proceed to dock at the
given berth position. SV1 also responds to the dock command
by recording that the ship is docked and issuing a oper1
command.

The Crane Manager CM responds to the oper1 command
by reading the ship bay plan, determining the containers
that should be loaded/unloaded to each bay, and issuing
a carrier request. The Carrier Coordinator CC responds to
the carrier request by determining the availability of the
straddle carriers, assigning a set of them to service the crane,
and issuing an assgnd message when completed. CM responds
to the assgnd message by determining the loading/unloading
sequence and the position to which a straddle carrier should
be moved. Once completed, CM issues a serve request. CC
responds to the serve request by determining the closest as-
signed straddle carrier and moving it to the requested position.
Once completed, CC issues a served message. CM re-
sponds to the served message by updating the ship bay plan
and carrying out
its operations (load/unload). After doing
so, CM issues a done message. The waiting SV1 responds to
the done message by reseting its record of the ship information
and issuing a compl1 message. Upon receiving a compl1
message, TM frees the berth and crane allocations. Also in
response to the compl1 message, SM1 resets its record of the
ship information and sends a deprt1 message. PC responds
to the deprt1 message by freeing the ship manager allocation
and its record of the ship information.

The operation of the port container terminal when us-
ing Ship Manager SM1 can be visualized as shown in the
sequence diagram given in Fig. 1, where the solid arrows
denote message-passing communication (i.e., communication
via stimuli) and the dashed arrows denote shared variable com-
munication (i.e., communication via shared environments).

B. C2KA Speciﬁcation of the System

To specify the given port terminal coordination system de-
scribed in Section IV-A using C2KA, we ﬁrst identify the set of
system agents, namely the set A consisting of the agents: {PC,
SM1, SM2, SV1, SV2, TM, CM, CC}. Next, we identify the
set of atomic stimuli that can be issued by the system agents
and the set of atomic behaviours that the agents can exhibit.
These sets are derived from the system description, and are
used to generate the support sets of the stimulus structure S
and the CKA K that comprise the C2KA to be used for the
speciﬁcation. For the port terminal coordination system, the
set S is generated using the operations of stimulus structures
and the set of atomic stimuli {arrive, mnge1 , mnge2 , ship1 ,
ship2 , crane1 , crane2 , allocd , berth, dock , oper1 , oper2 ,
carrier , assgnd , serve, served , done, compl1 , compl2 ,
deprt1 , deprt2 }. Similarly, the set K is generated using the
operations of CKA and the set of atomic behaviours {DEPART,
CLEAR1, CLEAR2, INIT, MAN1, MAN2, SRVT, POSN, LEAVE,
CRANES, PLAN, DOCK, RLSE, ALLO, FREE, READ, CARGO,

Port Captain
(PC)

Ship Manager
(SM1)

Stevedore
(SV1)

Ship Manager
(SM2)

Stevedore
(SV2)

Terminal Manager
(TM)

Crane Manager
(CM)

Carrier Coordinator
(CC)

arrive

dock

mnge1

shipInfo

shipInfo

shipInfo

ship1

berth

berthPos

dock

crane1

cranes

berth

allocd

berth

dock

allocd

oper1

bayPlan

carrier

containers

assgnd

carrierAssign

serve

position

served

carrierState

deprt1

deprt1

compl1

compl1

done

done

Fig. 1: Intended interactions for the port terminal coordination system when using Ship Manager SM1.

SEQ, SERVE, UPDT, OPER, AVAIL, ASSGN, NEAR, MOVE}.
Lastly, using the constructed C2KA, we develop the three
levels of speciﬁcation (see Section III-A4) for each agent in
the system.

Using the C2KA constructed above, the stimulus-response
speciﬁcations of the port terminal coordination system agents
are compactly speciﬁed. The speciﬁcation shown below de-
picts the stimulus-response speciﬁcation of the Ship Man-
ager SM1:

λ(berth, SRVT) = dock
λ(compl1 , POSN) = deprt1
λ(mnge1 , LEAVE) = ship1

berth ◦ SRVT = POSN
compl1 ◦ POSN = LEAVE
mnge1 ◦ LEAVE = SRVT
where s ◦ a = a and λ(s, a) = n for all other a ∈ K
and s ∈ S in the C2KA constructed above. Analogous
speciﬁcations can be derived for the remaining system agents
and can be found in Appendix C.

Based on the description of the system from Section IV-A,
the abstract behaviour speciﬁcation of each agent is derived
and shown in Fig. 2.

Finally, we use a fragment of Dijkstra’s guarded command
language [42] to provide the concrete behaviour speciﬁcation
of each system agent. This involves specifying the concrete
programs corresponding to the abstract behaviour speciﬁcation
of each agent. Fig. 3 depicts the concrete behaviour spec-
iﬁcation of the Ship Manager SM1. Once again, analogous
speciﬁcations can be derived for the remaining system agents
and can be found in Appendix C.

PC 7→
SMi
7→
SVi
7→
TM 7→
CM 7→
CC 7→

(MAN1 + MAN2) ; INIT + (CLEAR1 + CLEAR2) ; DEPART
(cid:10)
SRVT + POSN + LEAVE
(cid:10)
CRANES + PLAN + DOCK + RLSE
ALLO + FREE
READ ; CARGO + SEQ ; SERVE + UPDT ; OPER
AVAIL ; ASSGN + NEAR ; MOVE

(cid:10)
(cid:10)

(cid:11)

(cid:11)

(cid:11)

(cid:11)

(cid:11)

(cid:10)
(cid:10)

(cid:11)

Fig. 2: Abstract behaviour speciﬁcation of the port terminal
coordination system agents.

SRVT

POSN

LEAVE

def
= serviceT[1] := departT[1] − arriveT[1] − waitT[1]
def
= dockPos[1] := berthPos[1]
def
= dockPos[1] := null; serviceT[1] := 0

Fig. 3: Concrete behaviour speciﬁcation of the Ship Man-
ager SM1 behaviours.

C. Implicit Interactions Present in the System

Given the speciﬁcation of the port terminal coordination
interactions that are
system, we can identify the implicit
present in the system using the approaches presented in [1],
[2]. After performing a full system analysis, it can be shown
that there are 3902 implicit interactions out of the 4596 total
possible system interactions. In particular, the results of the
analysis show that there are 19 implicit interactions from the
Stevedore SV1 to the Stevedore SV2, which are shown in
Fig. 4.

p1

p2

p3

p4

p5

p6

p7

p8

p9

p10

p11

p12

p13

p14

p15

p16

p17

p18

p19

def
= SV1 →E CM →S SV2
def
= SV1 →S CM →S SV2
def
= SV1 →S SM2 →S PC →E SM1 →S SV2
def
= SV1 →S SM2 →S PC →S SM1 →S SV2
def
= SV1 →E SM1 →S PC →E SV2
def
= SV1 →S SM1 →S PC →E SV2
def
= SV1 →S SM2 →S PC →E SV2
def
= SV1 →S SM2 →E SV2
def
= SV1 →E SM1 →S PC →E SM2 →E SV2
def
= SV1 →S SM1 →S PC →E SM2 →E SV2
def
= SV1 →E SM1 →S PC →S SM2 →E SV2
def
= SV1 →S SM1 →S PC →S SM2 →E SV2
def
= SV1 →E TM →E SV2
def
= SV1 →S TM →E SV2
def
= SV1 →S SM2 →S SV2
def
= SV1 →E SM1 →S PC →E SM2 →S SV2
def
= SV1 →S SM1 →S PC →E SM2 →S SV2
def
= SV1 →E SM1 →S PC →S SM2 →S SV2
def
= SV1 →S SM1 →S PC →S SM2 →S SV2

Fig. 4: Identiﬁed implicit interactions from SV1 to SV2 in the
port terminal coordination system.

Implicit interactions in a system are possible due to the po-
tential for out-of-sequence reads from and/or writes to shared
variables, and/or the potential for out-of-sequence stimuli to
be issued by system agents. This kind of unexpected behaviour
could be the result of agents experiencing some kind of
compromise or failure. As an example, consider the implicit
def
= SV1 →S SM2 →S PC →E
interaction represented as p7
SV2. The existence of this implicit interaction indicates that it
is possible for a compromised SV1 to inﬂuence the behaviour
of SV2 indirectly via SM2 and PC.

This port

terminal coordination system will serve as a
running example throughout the remainder of this paper to
demonstrate the approach for determining the possible attack
scenarios, and for evaluating the exploitability of the subset
of implicit interactions shown in Fig. 4 that are present in
the system. While we present this example within the context
of maritime port operations,
the proposed approaches are
applicable in nearly all distributed systems.

V. OVERVIEW OF THE PROPOSED APPROACH

This section provides a high-level overview of the proposed
approach for determining the possible attack scenarios and
assessing the exploitability of implicit interactions. It presents
the main ideas of the proposed approach for readers that wish
to skip the technical details presented in Sections VI–VIII.

A. Highlights of the Proposed Approach

Determining how system agents are capable of inﬂuencing
each other’s behaviour is an important part of uncovering
how an implicit
interaction can be exploited to mount a
cyber-attack. To make this determination, we ﬁrst need to

study the potential for communication via stimuli and via
shared environments in a system speciﬁed using C2KA. As an
example, consider the Ship Manager SM1 from the port con-
tainer terminal example described in Section IV. To determine
how SM1 can be inﬂuenced from the perspective of message-
passing communication, we need to study the potential for
direct communication via stimuli among system agents to
determine the set of stimuli that will cause an observable
change in the behaviour of SM1. Similarly,
to determine
how SM1 can be inﬂuenced from the perspective of shared
variable communication, we need to study the potential for
direct communication via shared environments to determine
the set of program variables that are referenced in the concrete
behaviour of SM1. In each of these cases, we are looking to
capture the ways in which a compromised agent within the
system can directly inﬂuence the behaviour of the agent under
consideration. The formulation of these notions are provided
in Section VI.

Once we have determined how a system agent can be
directly inﬂuenced by other agents in a given system, we
need to extend these ideas to determine how an agent can be
indirectly inﬂuenced by studying the pattern of communication
dictated by a particular system interaction. Generally speaking,
we are looking to ﬁnd the stimuli or program variables that a
source agent can use to inﬂuence its neighbouring agent in the
interaction so that the neighbouring agent issues a stimulus
or deﬁnes a program variable that inﬂuences the behaviour
of its neighbouring agent, and so on until the behaviour of
the sink agent is inﬂuenced in some way. The idea is to
identify the set of possible scenarios that will cause a kind
of “chain-reaction” through the given implicit interaction. As
an example, consider the implicit interaction represented as
def
= SV1 →S SM2 →S PC →E SV2 that was identiﬁed in
p7
the port terminal coordination system in Section IV. Since the
interaction dictates that SV1 interacts with SM2 via stimuli
(i.e., SV1 →S SM2), we need to determine the set of stimuli
that can be issued by a compromised SV1 to inﬂuence the
behaviour of SM2. However, we must ensure that the resulting
behaviour of SM2, when inﬂuenced by SV1, will lead to
the issuance of a stimulus that can inﬂuence the behaviour
of PC, since, according to the given interaction, SM2 interacts
with PC via stimuli (i.e., SM2 →S PC). Again, since the
interaction shows that PC interacts with SV2 via shared
environments (i.e., PC →E SV2), it must be ensured that the
resulting behaviour of PC deﬁnes a program variable that is
referenced by SV2. Only in this way, will the actions of the
compromised SV1 ultimately inﬂuence the behaviour of SV2,
and will the implicit interaction be exploitable. The technical
details and formulation of this approach, which we call attack
scenario determination, can be found in Section VII.

After having determined the set of possible attack scenarios
which allow for an implicit interaction to be exploited in a
given system, we would like to have a measure of the overall
exploitability of the given implicit interaction so that we can
better assess the threat that it may pose to the system. Using

the results of the attack scenario determination, we devise
a new measure of severity for an implicit interaction called
exploitability. The derivation of the exploitability measure
can be found in Section VIII. This new measure of severity
provides a way to compare implicit
interactions, as well
as actionable information for system designers to determine
where and how to spend valuable resources in mitigating the
most severe vulnerabilities that exist in their designs. This
insight can offer signiﬁcant improvements to the overall the
safety, security, and reliability of the system.

As mentioned above, the complete technical details of what
has been presented in this section can be found in Sections VI–
VIII. Readers that wish to forgo those details may skip ahead
to Section IX for a summary of our experimental results and
a discussion of the proposed approach.

B. Tool Support

We use a prototype software tool to support the automated
analysis of the exploitability of implicit interactions present
in distributed systems speciﬁed using C2KA. It allows for
the speciﬁcation of systems using C2KA and automatically
identiﬁes the implicit
interactions in a given system. For
this paper, the tool has been extended to also automatically
determine the potential attack scenarios and compute the
exploitability measure for identiﬁed implicit interactions. The
tool is implemented in Haskell and uses the Maude term
rewriting system [44].

VI. ANALYZING THE INFLUENCE AND RESPONSE OF
SYSTEM AGENTS

In this section, we formulate and capture the ways in which
an agent can be inﬂuenced by another agent by studying the
communication via stimuli and via shared environments in
a system speciﬁed using C2KA. Given an implicit interac-
tion identiﬁed to exist in a given system, we are interested
in determining the exact stimuli or program variables that
a compromised source agent of the interaction can use to
ultimately inﬂuence the behaviour of the sink agent of the in-
teraction thereby causing the system to experience unintended
or unanticipated behaviours. The formulations developed in
this section will be applied in Section VII to determine the
possible attack scenarios for a given implicit interaction. In the
following discussion, we consider a distributed system formed
by a set A of agents with agents A, B ∈ A such that A 6= B.

A. Inﬂuencing Stimuli

In a distributed system, stimuli are required to initiate agent
behaviours. As such, we assume that an agent needs to be
inﬂuenced by a stimulus before it can issue a stimulus that
might inﬂuence the behaviour of another agent. Formally, this
assumption is articulated as (s ◦ a = a) =⇒ (λ(s, a) = n)
for all s ∈ S\{d} and a ∈ K\{0}.

This assumption is motivated by the fact that, in order for
an agent to generate and issue a stimulus (i.e., to send a
message or signal), a concrete program needs to be executed.
As an analogy, consider a system to be an arrangement of

dominoes where each domino represents a system agent. For
a domino to fall over, and potentially cause other dominoes
to fall over, some kind of stimulus (e.g., a push) is required;
a domino cannot simply fall over by itself. This means that
an agent needs some kind of external inﬂuence to initiate its
behaviour and execute its programs before it can inﬂuence
any other agent(s) in the system. Such external inﬂuences may
result from systems outside the boundaries of the system being
considered.

Throughout this paper, when we consider a distributed sys-
tem and its constituent agents, each agent is subjected to each
stimulus that is presented to the system, and every stimulus
invokes a response from an agent. When the behaviour of an
agent changes as a result of the response, we say that the
stimulus inﬂuences the behaviour of the agent.

b

(cid:11)

(cid:11)

(cid:10)

a
(cid:10)

We say that A 7→

has the potential for direct commu-
nication via stimuli with B 7→
(denoted by A →S B) if
and only if ∃
s, t | s, t ∈ Sa ∧ t ≤S λ(s, a) : t ◦ b 6= b
(cid:1)
(cid:0)
where Sa is the set of all atomic stimuli [45]. This means that
if there exists an atomic sub-stimulus that is generated by A
that causes an observable change in the behaviour of B, then
there is a potential for direct communication via stimuli from A
to B. In this way, we can alternatively say that if A →S B,
then there is at least one way in which A can inﬂuence the
behaviour of B by communication via stimuli, and that is by
issuing the atomic stimulus t.

However, we are interested in determining all of the possible
ways in which the behaviour of an agent can be inﬂuenced
by another agent in the system. By relating the notion of
inﬂuence to the formal deﬁnition of the potential for direct
communication via stimuli, we determine the set of stimuli
that can inﬂuence the behaviour of a given agent.

Deﬁnition 2 (Inﬂuencing Stimuli). Let
S, K
(cid:0)
The inﬂuencing stimuli of an agent A 7→
a
(cid:10)
the set given by: Inﬂ(A) = {s ∈ Sa | s ◦ a 6= a}.

(cid:11)

be a C2KA.
(cid:1)
with a ∈ K is

The inﬂuencing stimuli of A is the set of all atomic stimuli
that cause an observable change in the behaviour of A. The
inﬂuencing stimuli of an agent can be used to determine how
other agents in the system can directly inﬂuence the given
agent’s behaviour. For instance, to directly inﬂuence the be-
haviour of A, an agent must issue some stimulus s ∈ Inﬂ(A).

(cid:1)

(cid:0)SK, +

Given a C2KA, it should be noted that since

is
zero-preserving, every agent behaviour becomes inactive when
subjected to the deactivation stimulus d (i.e., d ◦ a = 0 for
all a ∈ K). This means that every agent, other than the inactive
agent 0, can be inﬂuenced by the deactivation stimulus d.
Similarly, since
is unitary, every agent behaviour
remains unchanged by the neutral stimulus n (i.e., n ◦ a = a
for all a ∈ K). This means that the neutral stimulus n does not
inﬂuence the behaviour of any agent. For these reasons, we
exclude these trivial cases when discussing inﬂuencing stimuli
in the remainder of this paper.

(cid:0)SK, +

(cid:1)

Example VI.1 (Computing the Inﬂuencing Stimuli of an
Agent). Consider the port
terminal coordination system
inﬂuencing stimuli
described in Section IV. The set of
for the Ship Manager SM1 is given by Inﬂ(SM1) =
{berth, compl1 , mnge1 }. This means any agent that issues
any of the stimuli berth, compl1 , or mnge1 will inﬂuence the
behaviour of SM1. When given the system speciﬁcation, the
computation of the set of inﬂuencing stimuli for a given system
agent can be computed automatically using our prototype
software tool.

(cid:11)

a
(cid:10)

An agent A 7→

is said to have a ﬁxed point behaviour
if ∀(s | s ∈ S\{d} : s◦ a = a ) [4]. This means that a ﬁxed
point behaviour is one that remains unchanged in response to
all stimuli other than the deactivation stimulus d. Proposition 1
shows how an agent with a ﬁxed point behaviour does not have
any non-trivial inﬂuencing stimuli.

Proposition 1. If an agent A 7→
behaviour then Inﬂ(A) = ∅.

a
(cid:10)

(cid:11)

has a ﬁxed point

Proof. The proof is straightforward from the deﬁnition of a
ﬁxed point behaviour. The detailed proof can be found in
Appendix B.

As a direct result of Proposition 1, we have Inﬂ(1) = ∅
and Inﬂ(0) = ∅. This means that the idle agent 1 and inactive
agent 0 cannot be inﬂuenced by any non-trivial stimuli.

B. Inﬂuencing Variables
We say that A 7→

(cid:11)

(cid:11)

b
(cid:10)

has the potential for direct com-
a
(cid:10)
munication via shared environments with B 7→
(denoted
by A →E B) if and only if a R b where R is a dependence
relation [45]. In this paper, due to the use of Dijkstra’s guarded
command language for the concrete behaviour speciﬁcations
of agents, such a dependence relation is considered to be a
deﬁnition-reference relation between program variables. Thus
if there exists a program variable that is deﬁned in the concrete
behaviour speciﬁcation of A, and referenced in the concrete
behaviour speciﬁcation of B, then there is a potential for direct
communication via shared environments from A to B.

In what follows,

let Def(A) and Ref(A) represent

the
sets of program variables that are deﬁned and referenced in
the concrete behaviour speciﬁcation of agent A, respectively.
These sets can be deﬁned by structural induction on programs
speciﬁed with Dijkstra’s guarded command language. We are
interested in determining all of the possible ways in which
the behaviour of an agent can be inﬂuenced by another agent
in the system. By relating the notion of inﬂuence to the
formal deﬁnition of the potential for direct communication
via shared environments, we determine the set of program
variables that can be used to inﬂuence the behaviour of an
agent A. We call this set of variables the inﬂuencing variables
of A, which is quite simply the set of all program variables
that are referenced in the concrete behaviour speciﬁcation of A
(i.e., Ref(A)). Therefore, to directly inﬂuence the behaviour
of an agent A via shared environments, an agent must deﬁne
some variable v ∈ Ref(A).

Example VI.2 (Computing the Inﬂuencing Variables of
an Agent). Consider the port
terminal coordination sys-
inﬂuencing vari-
tem described in Section IV. The set of
ables for the Ship Manager SM1 is given by Ref(SM1) =
{arriveT[1], berthPos[1], departT[1], waitT[1]}.
This means any agent
the variables
arriveT[1], berthPos[1], departT[1], or waitT[1]
will inﬂuence the behaviour of SM1. The computation of the
set of inﬂuencing variables for a given system agent can also
be computed automatically using our prototype software tool
when given the system speciﬁcation.

that deﬁnes any of

VII. DETERMINING POSSIBLE ATTACK SCENARIOS FOR
IMPLICIT INTERACTIONS

To this point, we have formulated the possible ways in
which an agent can directly inﬂuence the behaviour of another
agent in a given system, either via stimuli or via shared
environments. However, implicit interactions are rarely direct
interactions, and therefore, we need to generalize the notions
of inﬂuence that have been established in Sections VI-A
and VI-B.

A. Attack Stimuli and Attack Variables

Given an implicit interaction in a system speciﬁed using
C2KA, we want to determine the potential ways in which
the interaction can be exploited to mount a cyber-attack. To
achieve this, we consider how a compromised source agent
can exploit the given implicit interaction via stimuli or via
shared environments by examining the pattern of communica-
tion (i.e., the sequence of direct communications via stimuli
and/or shared environments) of the interaction within the given
system. As such, we identify the sets of attack stimuli and
attack variables for a given implicit interaction, which are
deﬁned by mutual recursion in Deﬁnitions 3 and 4.

Deﬁnition 3 (Attack Stimuli). Given an implicit interaction of
def
the form pTn
= An →Tn An−1 →Tn−1 . . . →T2 A1 →T1 A0,
n
the set of stimuli that a compromised source agent An can
issue to exploit
interaction and inﬂuence the
the sink agent A0 is given by Equation 1
behaviour of
pTn−1
denotes the set of attack variables for pTn−1
where AV
n−1
n−1
(cid:0)
as deﬁned in Deﬁnition 4.

the implicit

(cid:1)

Deﬁnition 3 describes the set of stimuli that a compromised
source agent can issue to inﬂuence the behaviour of the
sink agent of a given implicit interaction. To exploit a direct
def
interaction via stimuli (pS
= A1 →S A0), a compromised
1
source agent A1 needs to issue any stimulus that inﬂuences
the sink agent A0. Similarly, to exploit an implicit interaction
of the form (pS
n−1 ), a compromised source
n
agent An needs to issue any atomic stimulus s for which
there exists an atomic sub-behaviour a of its neighbouring
agent An−1 that is inﬂuenced by s and either:
(a) the atomic sub-behaviour a under s generates a stimulus
that exploits the rest of the given interaction denoted
by pTn−1

= An →S pTn−1

def

n−1 ; or

AS
(cid:0)

pTn
n (cid:1)

=

AV

pTn
n (cid:1)

(cid:0)

=









∅

∅

Inﬂ(A0)
a | a ∈ Ka ∧ a ≤K An−1 ∧ s ∈ Inﬂ(a) :
s | ∃
(cid:0)
∃(v |: v ∈ Def(s ◦ a) ∩ AV

(cid:8)

pTn−1
n−1
(cid:0)

(cid:1)

pTn−1
) ∨ λ(s, a) ∈ AS
n−1
(cid:0)

(cid:1) (cid:1)(cid:9)

Ref(A0)
a | a ∈ Ka ∧ a ≤K An−1 ∧ v ∈ Ref(a) :
v | ∃
(cid:0)

(cid:8)

∃(w |: w ∈ Def(a) ∩ AV

pTn−1
n−1
(cid:0)

(cid:1)

pTn−1
) ∨ ∃(s | s ∈ Sa : λ(s, a) ∈ AS
n−1
(cid:0)

if Tn = S ∧ n = 1

if Tn = S ∧ n > 1
otherwise

if Tn = E ∧ n = 1

)

(cid:1)

(cid:1)(cid:9)

if Tn = E ∧ n > 1
otherwise

(1)

(2)

(b) there is a program variable v that

is deﬁned by the
resulting behaviour of a under s that can exploit the rest
of the given interaction denoted by pTn−1
n−1 .

Deﬁnition 3 also shows that for any implicit interaction of
the form An →E pTn−1
= ∅. This follows
then AS
n−1
from intuition since direct interactions via shared environments
(i.e., An →E An−1) are exploited only by deﬁning program
variables.

pTn
n (cid:1)
(cid:0)

Deﬁnition 4 (Attack Variables). Given an implicit interaction
def
of the form pTn
= An →Tn An−1 →Tn−1 . . . →T2 A1 →T1
n
A0, the set of variables that a compromised source agent An
can deﬁne to exploit the implicit interaction and inﬂuence
the behaviour of the sink agent A0 is given by Equation 2
denotes the set of attack stimuli for pTn−1
pTn−1
where AS
n−1
n−1
(cid:0)
as deﬁned in Deﬁnition 3.

(cid:1)

Deﬁnition 4 describes the set of program variables that
a compromised source agent can deﬁne to inﬂuence the
behaviour of the sink agent of a given implicit interaction. To
def
exploit a direct interaction via shared environments (pE
=
1
A1 →E A0), a compromised source agent A1 needs to deﬁne
any variable referenced by the sink agent A0. Likewise, to
def
exploit an implicit interaction of the form (pE
= An →E
n
pTn−1
n−1 ), a compromised source agent An needs to deﬁne any
program variable referenced by an atomic sub-behaviour a of
its neighbouring agent An−1 and for which either:
(a) there is a program variable w that is deﬁned by the atomic
sub-behaviour a that can exploit the rest of the given
interaction denoted by pTn−1
n−1 ; or

(b) there is an atomic stimulus s for which the atomic sub-
behaviour a under s generates a stimulus that exploits the
rest of the given interaction denoted by pTn−1
n−1 .

Similar to Deﬁnition 3, Deﬁnition 4 also shows that for any im-
plicit interaction of the form An →S pTn−1
=
∅. Once again, this follows from intuition since direct inter-
actions via stimuli (i.e., An →S An−1) are exploited only by
issuing stimuli.

n−1 then AV

pTn
n (cid:1)
(cid:0)

When determining the attack stimuli and attack variables
for the purpose of determining the possible attack scenarios
for implicit interactions in Deﬁnitions 3 and 4, we need to
consider the existence of an atomic sub-behaviour of the
neighbouring agent of An (i.e., a ≤K An−1) to ensure that
it is indeed possible for An−1 to subsequently inﬂuence the
behaviour of its neighbouring agent.

(cid:11)

As one example of this situation, consider an implicit
the form A3 →E A2 →E A1 →E A0
interaction of
with A2
such that a1, a2 ∈ Ka and
7→
a1 + a2
(cid:10)
def
the concrete behaviour speciﬁcations are given by a1
=
def
= y := x + 1; w := z. There-
u := v + 1 and a2
fore, Def(A2) = {u, y, w} and Ref(A2) = {v, x, z}. Now
= {y, w}. By applying Deﬁnition 4,
suppose that AV
(cid:1)
= {v, x, z}. However, while deﬁning v
we compute AV
(cid:1)
will inﬂuence the behaviour of A2 (namely a1), it will not sub-
sequently inﬂuence the behaviour of its neighbouring agent A1
. This means that A2 will only be able to
since v /∈ AV
(cid:1)
inﬂuence the behaviour of A1 if it behaves as the atomic sub-
behaviour a2. Similar cases can be constructed for implicit
interactions of different forms.

pT1
1
(cid:0)
pT2
2
(cid:0)

pT1
1
(cid:0)

B. Attack Scenario Determination

By combining the deﬁnitions of the sets of attack stimuli and
attack variables, we obtain a generalized formulation of the set
of possible attack scenarios for a given implicit interaction in
a distributed system speciﬁed using C2KA.

= AS

∪ AV

pTn
.
n (cid:1)
(cid:0)

Deﬁnition 5 (Attack Scenario Determination). Given an im-
def
plicit interaction of the form pTn
= An →Tn An−1 →Tn−1
n
. . . →T2 A1 →T1 A0, the set of possible attack scenarios by
which a compromised source agent An can exploit the implicit
interaction and inﬂuence the behaviour of the sink agent A0
pTn
is given by: attack
n (cid:1)
(cid:0)

pTn
n (cid:1)
(cid:0)
By Deﬁnition 5, the set of possible attack scenarios for a
given implicit interactions is either the set of attack stimuli
or the set of attack variables for the interaction. This is
due to the fact that the pattern of communication needs to
be respected when exploiting the implicit interaction. This
means that the source agent can only inﬂuence its immediate
neighbour according the type of communication (either via
stimuli or shared environments) dictated by the interaction.
Consequently, for any given interaction pTn
is
either a subset of atomic stimuli or a subset of program
variables, depending on the way in which the source agent
communicates with its neighbouring agent. This is a direct
result from Deﬁnitions 3 and 4, and the fact that for any
implicit interaction pTn
= ∅, and
n : if Tn = S then AV
pTn
if Tn = E then AS
n (cid:1)
(cid:0)

pTn
n , attack
n (cid:1)
(cid:0)

pTn
n (cid:1)
(cid:0)

= ∅.

Example VII.1 (Computing the Possible Attack Scenarios of
Implicit Interactions). Consider the port terminal coordination
system described in Section IV and the implicit interaction
def
= SV1 →S SM2 →S PC →E SV2.
represented as p7
By direct application of Deﬁnitions 3–5, the set of possi-
= {compl2 }.
ble attack scenarios is given by attack
p7
(cid:0)
This shows that to exploit the given implicit interaction, a
compromised SV1 can send a compl2 message, which can
cause SM2 to enter its leaving behaviour (LEAVE) and send
a deprt2 message. In turn, this can cause PC to clear the
ship information which is needed by SV2, and can therefore
disrupt the port operations.

(cid:1)

(cid:1)

As another example, consider the implicit

def
= SV1 →E TM →E SV2.

interaction
In
represented as p13
this case,
the set of possible attack scenarios is given
by attack
= {berth[1], berth[2], numCranes[1],
p13
(cid:0)
numCranes[2]}. This shows that a compromised SV1 can
exploit the given implicit interaction by modifying any, or
all, of the variables berth[1], berth[2], numCranes[1],
and/or numCranes[2], which are used by TM to determine
the crane allocations. This means that when TM references
these variables, it can determine incorrect crane allocations.
Therefore, once SV2 enters its planning behaviour (PLAN),
it may use the incorrect crane allocations, which can also
disrupt the port operations.

Using our prototype software tool, we can automatically
compute the set of possible attack scenarios for an implicit
interaction when given the system speciﬁcation. A selection
of the results of the tool output are summarized in Table I in
Section IX.

pS
It should be noted that if attack
n(cid:1)
(cid:0)

= ∅ for any implicit
interaction of the form pS
n, then the implicit interaction can
only be exploited trivially. As mentioned in Section VI-A,
every agent other than the inactive agent 0 can be inﬂuenced
by the deactivation stimulus d. Therefore, if attack
pS
= ∅,
n(cid:1)
(cid:0)
then pS
n can only be exploited by issuing the deactivation
stimulus d, which will ultimately cause the sink agent to
pE
behave as the inactive agent 0. Furthermore, if attack
= ∅
n(cid:1)
(cid:0)
for any implicit interaction of the form pE
n, then the implicit
interaction cannot be exploited. While it is the case that there is
a potential for direct communication via shared environments
from An to An−1 which allows for the identiﬁcation of pE
n as
an implicit interaction, the attack scenario determination shows
that there is no way in which a compromised agent An can
create a chain of inﬂuence to ultimately affect the behaviour of
sink agent A0. As an example, consider the implicit interaction
def
= SV1 →E SM1 →S PC →S SM2 →E
represented as p11
SV2 for which attack
= ∅. By carefully examining the
p11
(cid:0)
attack scenarios, we ﬁnd that in order to exploit this implicit
interaction, SV1 must deﬁne any program variable that is
referenced by an atomic sub-behaviour of SM1 for which there
is an atomic stimulus that will generate a stimulus that can
exploit the rest of the given interaction (i.e., SM1 →S PC →S
SM2 →E SV2), which in this case is the arrive stimulus.
However, because there does not exist any behaviour in the

(cid:1)

port terminal coordination system that can generate the arrive
stimulus (it is an external stimulus), there does not exist any
variable that SV1 can deﬁne to cause the chain of inﬂuence to
ultimately affect the behaviour of SV2 via the given implicit
interaction.

Proposition 2 shows that if there are no attack scenarios for
n , then there is no way
n apart from the trivial cases as described above.

any sufﬁx of an implicit interaction pTn
to exploit pTn

Proposition 2. Let pTn
n
pTn−1
attack
n−1
(cid:0)
{S, E} for 1 < i ≤ n.

= ∅ =⇒ attack
(cid:0)

be an implicit
pTn
n (cid:1)

(cid:1)

interaction. Then,
= ∅ where Ti ∈

Proof. The proof follows straightforwardly from Deﬁnition 3,
Deﬁnition 4, and Deﬁnition 5. The detailed proof can be found
in Appendix B.

The result of Proposition 2 enables us to determine the
attack scenarios for the given implicit interaction without the
need to analyze the entire interaction. In cases where a given
implicit interaction is long, which is possible in systems with
a large numbers of interacting agents, this result allows for
savings in terms of the time required to perform the attack
scenario determination.

VIII. EVALUATING THE EXPLOITABILITY OF IMPLICIT
INTERACTIONS

After performing the attack scenario determination for each
of the identiﬁed implicit interactions in a given system design,
we use the set of possible attack scenarios to develop a new
measure of the severity of each interaction. The severity of
an implicit interaction gives an indication of the interactions
that have the potential to most negatively impact the safety,
security, and/or reliability of the system in which they exist.
We call this new measure of severity, the exploitability of the
implicit interaction and compute it as prescribed by Deﬁni-
tion 6.

Deﬁnition 6 (Exploitability). The exploitability of an implicit
interaction pTn
pTn
) is computed recursively by:
n (cid:1)
(cid:0)
pTn
|Inﬂ(An−1) ∩ attack
|
n (cid:1)
(cid:0)

n (denoted ξ

if Tn = S ∧ n > 1

ξ

pTn−1
n−1
(cid:0)

(cid:1)

|Inﬂ(An−1)|

ξ

pTn
n (cid:1)
(cid:0)

=

ξ

pTn−1
n−1
(cid:0)

(cid:1)

pTn
|Ref(An−1) ∩ attack
|
n (cid:1)
(cid:0)

|Ref(An−1)|

1

if Tn = E ∧ n > 1

otherwise






Deﬁnition 6 computes the fraction of ways that a source
agent can inﬂuence the behaviour of its neighbouring agent in
a way that the inﬂuence is propagated along the implicit inter-
action to eventually inﬂuence the behaviour of the sink agent.
The exploitability of an implicit interaction interaction pTn
n
is a numeric value ξ
≤ 1. In
each fractional component of the exploitability measure, the
denominator represents the total number of ways in which
the behaviour of the next agent in the interaction can be
inﬂuenced, and the numerator represents the number of those

such that 0 ≤ ξ

pTn
n (cid:1)
(cid:0)

pTn
n (cid:1)
(cid:0)

ways that will maintain the chain of inﬂuence for the given
the implicit interaction, thereby allowing for its exploitation.
Deﬁnition 6 shows that the exploitability of direct inter-
actions is always equal to 1. This follows from intuition,
and directly from Deﬁnition 5, since any attack scenario for
a direct interaction will inﬂuence the behaviour of the sink
agent. In the recursive cases, we compute the product of the
exploitability of each proper subpath of the given implicit
interaction. This allows us to account for the fact that an
indirect implicit interaction requires that each intermediate
agent propagate the inﬂuence to its neighbouring agent. This
means that for an implicit interaction that contains a large
number of intermediate agents, a compromised source agent
needs to rely on a number of additional agents to inﬂuence
the sink agent’s behaviour. Intuitively, the fewer possibilities
that each agent in an implicit interaction has to cause a “chain
reaction” of inﬂuence in its neighbouring agents, the lower
the exploitability of interaction. In this way, the lower the
exploitability measure for an implicit interaction, the more
narrow the possibilities for exploiting the interaction.

Note that for an implicit interaction pTn

n , the exploitability
measure is always deﬁned because it is the case that Inﬂ(Ai) 6=
∅ if Ti = S and Ref(Ai) 6= ∅ if Ti = E for all Ai in pTn
n
and 1 ≤ i ≤ n. This follows from the deﬁnition of an
implicit interaction as a sequence of direct communications
either via stimuli or shared environments (see Sections VI-A
and VI-B). For an implicit interaction to exist, there must be
at least one stimulus or program variable that can inﬂuence
each neighbouring agent in the interaction (i.e., a potential for
direct communication). For instance, an implicit interaction of
the form A2 →S A1 →E A0 is only possible if there exists
some stimulus issued by A2 that inﬂuences A1 (i.e., ∃(s |:
s ∈ Inﬂ(A1) )), and some program variable deﬁned by A1 that
is referenced by A0 (i.e., ∃(v |: v ∈ Ref(A0) )).

Consider the port terminal coordination system described in
def
Section IV and the implicit interaction represented as p7
=
SV1 →S SM2 →S PC →E SV2. By applying Deﬁnition 6,
the exploitability of p7 is computed to be 0.222. This is due
to the fact that, of the three stimuli that will inﬂuence the
behaviour of SM2, only one (namely compl2 ) will allow SM2
to, in turn, inﬂuence the behaviour of PC, and ultimately the
rest of the agents in the given interaction. Similarly, of the
three stimuli that will inﬂuence the behaviour of PC, only
two (namely deprt1 and deprt2 ) will allow PC to inﬂuence
the behaviour of SV2.

The exploitability of an implicit interaction can be computed
automatically using our prototype software tool when given
the system speciﬁcation. We refer the reader to Table I in
Section IX for a selection of results from the tool output.

ξ
= ξ

= ξ

(cid:0)
(cid:0)

(cid:0)

SV1 →S SM2 →S PC →E SV2
SM2 →S PC →E SV2

(cid:1)

∗
(cid:1)
SV1 →S SM2 →S PC →E SV2
|Inﬂ(SM2) ∩ attack
(cid:0)
|Inﬂ(SM2)|

|
(cid:1)

PC →E SV2

∗

(cid:1)
SM2 →S PC →E SV2
|Inﬂ(PC) ∩ attack
(cid:0)

|
(cid:1)

∗

|Inﬂ(PC)|

SV1 →S SM2 →S PC →E SV2
|Inﬂ(SM2) ∩ attack
(cid:0)
|Inﬂ(SM2)|

|
(cid:1)

= 1 ∗

|{arrive, deprt1 , deprt2 } ∩ {deprt1 , deprt2 , mnge1 , mnge2 }|
|{arrive, deprt1 , deprt2 }|

∗

|{berth, compl2 , mnge2 } ∩ {compl2 }|
|{berth, compl2 , mnge2 }|

= 1 ∗

|{deprt1 , deprt2 }|
|{arrive, deprt1 , deprt2 }|
|{compl2 }|
|{berth, compl2 , mnge2 }|

∗

= 1 ∗

2
3

∗

1
3

= 0.222

This shows that, of the three stimuli that will inﬂuence the
behaviour of SM2, only one (namely compl2 ) will allow SM2
to, in turn, inﬂuence the behaviour of PC, and ultimately the
rest of the agents in the given interaction. Similarly, of the
three stimuli that will inﬂuence the behaviour of PC, only two
(namely deprt1 and deprt2 ) will allow PC to inﬂuence the
behaviour of SV2. The exploitability of an implicit interaction
can be computed automatically with the help of our prototype
software tool when given the system speciﬁcation. We refer the
reader to Table I in Section IX for a selection of results from
the tool output.

It is important to note that we are determining and measur-
ing the possible ways in which an attacker can use an implicit
interaction to inﬂuence the behaviour of an agent in a given
system, regardless of the impact that such an inﬂuence can
have on the overall system behaviour. Not all of the ways
in which an attacker may exploit an implicit interaction are
“created equal,” and we do not rule out the fact that some
ways may be more likely to be used by an attacker than others,
for a number of reasons. Because of this, we acknowledge
that the study of the potential impact that particular exploits
of existing implicit interactions in system designs can have
on the overall system behaviour and operation is critically
important, however it is a signiﬁcant effort in its own right and
is out of the scope of this paper. Rather, we conjecture that
the information generated from the proposed attack scenario
determination and exploitability analysis can provide vital
information for studying the potential impact of cyber-attacks
launched through implicit interactions and is the subject of our
future work.

IX. EXPERIMENTAL RESULTS AND DISCUSSION

Example VIII.1 (Computing the Exploitability of an Implicit
Interaction). Consider the port terminal coordination system
described in Section IV and the implicit interaction represented
def
= SV1 →S SM2 →S PC →E SV2. By applying
as p7
Deﬁnition 6, the exploitability of p7 is computed to be 0.222.

In this section, we summarize our experimental results
for determining the possible attack scenarios and evaluating
the exploitability of implicit
interactions identiﬁed in our
illustrative port terminal coordination system. We also provide
a discussion of the results and the proposed approach.

A. Experimental Results

Using our developed prototype software tool, we compute
the attack scenario determination and the exploitability of
each of the identiﬁed implicit interactions from SV1 to SV2
(see Section IV-C and Fig. 4). The experimental results are
summarized in Table I. A similar analysis can be performed
for the remaining implicit interactions identiﬁed in the system.
Due to space limitations, we do not present the analysis of the
entire system here.

When comparing the exploitability of the given implicit
in the port
interactions that have been identiﬁed to exist
terminal coordination system with a source agent SV1 and
a sink agent SV2, we ﬁnd a variation in the results for each
of the interactions. An interaction with a higher exploitability
shows that there are more ways in which a compromised
source agent can inﬂuence the behaviour of the sink agent.
This means that such interactions present a higher probability
that the source agent can mount a cyber-attack on the given
interaction and ultimately inﬂuence the behaviour of the sink
agent. This analysis aids in validating the existence of the
implicit interactions within the system, and provides system
designers with plenty of insight into identifying, assessing, and
mitigating deﬁciencies in their designs.

Table I shows that the exploitability measure for some im-
plicit interactions (e.g., p13 and p14) is 1.0. This indicates that
these implicit interactions are maximally exploitable, meaning
that as long as a compromised source agent inﬂuences the
behaviour of its neighbouring agent, then it will ultimately
inﬂuence the behaviour of the sink agent. As such, this makes
the compromised source agent very powerful in being able to
conduct a cyber-attack within the system. Consequently, these
particular implicit interactions present the most serious threat
to the safety, security, and reliability of the system and ought
to be assigned the highest priority for mitigation.

Conversely, some implicit interactions (e.g., p4, p11, p12,
p18 and p19) have an exploitability measure of 0.0. In the
case of p4, p12, and p19, the results show that these implicit
interactions can only be exploited trivially, as discussed in
Section VII-B, by having the compromised source agent issue
a deactivation stimulus d. In this way, these interactions pose
little threat to the system since this very speciﬁc and trivial
way to exploit the interaction is straightforward to monitor
and mitigate. Similarly, in the case of p11 and p18, the results
show that these implicit interactions cannot be exploited in the
given system. Therefore, these interactions can be considered
benign, which is very useful for the system designers when
they need to determine where and how to focus their efforts in
mitigating the existence of implicit interactions in their system
designs.

In addition to the special cases discussed above, Table I
also shows that there are a number of implicit interactions
in between the two
with exploitability measures that fall
pE
= 0.0), or trivially
extremes of not exploitable (i.e., ξ
n(cid:1)
(cid:0)
= 0.0), and maximally exploitable
exploitable (i.e., ξ
pTn
= 1.0 for Tn ∈ {S, E}). For example, the
(i.e., ξ
n (cid:1)
(cid:0)

pS
n(cid:1)
(cid:0)

def
= SV1 →S SM2 →E SV2 has an
implicit interaction p8
exploitability of 0.667. This indicates there is a 66.7% chance
that a compromised SV1 can inﬂuence the behaviour of SM2
in such a way that it will ultimately result in an inﬂuence of the
behaviour of the sink agent SV2. Furthermore, when compared
def
= SV1 →E CM →S SV2
with the implicit interaction p1
which has an exploitability of 0.333 (half of that of p8), we
can say that p8 is twice as exploitable as p1. The ability
to compare the relative exploitability between two or more
implicit interactions can help system designers in determining
which implicit interactions found to exist in their designs
should be mitigated with the highest priority.

More broadly, the illustrative example of the port terminal
coordination system and our experimental results show that
despite having two seemingly unconnected components (e.g.,
the Stevedores SV1 and SV2), there is a possibility for one to
inﬂuence the behaviour of the other. The proposed approach
allows us to determine the precise ways in which this is
possible with respect to a given system speciﬁcation. As our
in some cases, a compromised
experimental results show,
source agent requires a very speciﬁc scenario to exploit an
implicit interaction to inﬂuence the behaviour of the sink
agent, and in other cases, there is much more freedom and
possibility for exploitation.

B. Discussion of the Proposed Approach

The proposed approach for determining the ways in which
implicit interactions can be exploited to mount a cyber-attack
provides a step towards validating the existence of implicit
interactions in the designs of distributed systems. This infor-
mation is critical in assessing the severity of the vulnerabilities,
as well as in determining where and how to spend valuable
resources in mitigating the potential for such attacks. In turn,
this enables system designers, early in the system development
life-cycle, to more accurately assess the threat that such vul-
nerabilities pose to the overall safety, security, and reliability
of the system if left unmitigated. Furthermore, the proposed
approach can aid in developing guidelines for designing and
implementing resilient distributed systems. For example, it can
help designers to rework their system designs to eliminate or
mitigate the identiﬁed vulnerability and/or to aid in selecting
appropriate security and reliability controls (such as strict input
validations) to be implemented to prevent any exploits or
attacks of vulnerabilities that cannot be completely eliminated.
Although any sufﬁciently general model would allow study-
ing interactions between components and their relationship to
certain classes of properties, our approach using the C2KA
modeling framework takes advantage of the capability of
C2KA to separate the behaviour of a system and its en-
vironment, and to deterministically ascertain the potential
attack scenarios for both communication via stimuli (message-
passing communication) and communication via shared en-
vironments (shared variable communication); something that
cannot be done directly using other approaches. The moderate
effort required to model a given system using C2KA (i.e., to
develop the formal speciﬁcation of the system) is outweighed

TABLE I: Experimental results of the attack scenario determination and exploitability analysis for the identiﬁed implicit
interactions from SV1 to SV2; a higher exploitability measure indicates a higher threat in the system.

ID

p1
p2
p3
p4
p5
p6
p7
p8
p9
p10
p11
p12
p13
p14
p15
p16
p17
p18
p19

Implicit Interaction
SV1 →E CM →S SV2
SV1 →S CM →S SV2
SV1 →S SM2 →S PC →E SM1 →S SV2
SV1 →S SM2 →S PC →S SM1 →S SV2
SV1 →E SM1 →S PC →E SV2
SV1 →S SM1 →S PC →E SV2
SV1 →S SM2 →S PC →E SV2
SV1 →S SM2 →E SV2
SV1 →E SM1 →S PC →E SM2 →E SV2
SV1 →S SM1 →S PC →E SM2 →E SV2
SV1 →E SM1 →S PC →S SM2 →E SV2
SV1 →S SM1 →S PC →S SM2 →E SV2
SV1 →E TM →E SV2
SV1 →S TM →E SV2
SV1 →S SM2 →S SV2
SV1 →E SM1 →S PC →E SM2 →S SV2
SV1 →S SM1 →S PC →E SM2 →S SV2
SV1 →E SM1 →S PC →S SM2 →S SV2
SV1 →S SM1 →S PC →S SM2 →S SV2

Attack Scenarios: attack(cid:0)pi(cid:1)
{plan, sequence}
{served }
{compl2 }
∅
{berthPos[1]}
{compl1 }
{compl2 }
{compl2 , mnge2 }
{berthPos[1]}
{compl1 }
∅
∅
{berth[1], berth[2], numCranes[1], numCranes[2]}
{compl1 , compl2 , crane1 , crane2 }
{berth, mnge2 }
{berthPos[1]}
{compl1 }
∅
∅

Exploitability: 0 ≤ ξ(cid:0)pi(cid:1) ≤ 1
0.333
0.250
0.167
0.000
0.167
0.222
0.222
0.667
0.125
0.167
0.000
0.000
1.000
1.000
0.667
0.125
0.167
0.000
0.000

by the natural formalization of the notions of the attack
scenario determination and exploitability as presented in this
paper. Furthermore, it provides the ability to perform other
kinds of analyses (e.g., model-checking, simulations, etc.) on
the C2KA speciﬁcations, including those outside of the realm
of implicit interactions.

X. CONCLUDING REMARKS AND FUTURE WORK

Implicit

interactions are previously unknown linkages
among system components indicating the presence of cyber-
security vulnerabilities that,
if exploited, can have serious
consequences with respect to the safety, security, and relia-
bility of a system. In this paper, we presented a systematic
approach for evaluating the exploitability of implicit interac-
tions in distributed systems. The approach is based on attack
scenario determination, which ﬁnds the set of possible ways
in which a compromised system agent can exploit a particular
implicit interaction to mount a cyber-attack that inﬂuences
the behaviour of other agents in the system. This is done
by studying the inﬂuence and response of the system agents
and their C2KA speciﬁcations. We have also developed a
new measure of exploitability for implicit interactions, which
provides critical information that can offer useful insights to
system designers when determining measures to mitigate the
potential for implicit interactions to be exploited in a cyber-
attack. In addition, we reported on a prototype tool that aids
in the automated analysis, and demonstrates the feasibility and
practicality of the proposed approach for analyzing systems of
reasonable size and complexity. Broadly speaking, the rigorous
and practical techniques presented in this paper enable better
identiﬁcation and assessment of cybersecurity vulnerabilities
in system designs which can improve overall system resilience,
dependability, and security.

While we have shown that

there are speciﬁc scenarios
by which an implicit implicit interaction can be exploited,
and that there are varying degrees of exploitability, a further
examination and assessment of the impact that a potential

cyber-attack can have on a system is needed. For example,
while it may be the case that an implicit interaction is highly
exploitable, it is possible that the resulting system behaviour
from an attack may not lead to a critical system state that
is cause for serious concern. As such, in future work, we
plan to develop analysis methods based on simulations of
cyber-attacks launched upon implicit interactions using the
attack scenarios determined by the proposed approach, to study
their potential effects and impacts on the given systems and
their operations. The results of these simulations and impact
analyses will provide actionable information on where to focus
efforts and resources on reducing the risk and impact of such
attacks.

ACKNOWLEDGMENT

This work is supported by the U.S. Department of Home-

land Security under Grant Number 2015-ST-061-CIRC01.
Disclaimer: The views and conclusions contained in this doc-
ument are those of the authors and should not be interpreted as
necessarily representing the ofﬁcial policies, either expressed
or implied, of the U.S. Department of Homeland Security.

REFERENCES

[1] J. Jaskolka and J. Villasenor, “Identifying implicit component inter-
actions in distributed cyber-physical systems,” in Proceedings of the
50th Hawaii International Conference on System Sciences, HICSS-50,
pp. 5988–5997, January 2017.

[2] J. Jaskolka and J. Villasenor, “An approach for identifying and analyzing
interactions in distributed systems,” IEEE Transactions on

implicit
Reliability, vol. 66, pp. 529–546, June 2017.

[3] J. Jaskolka, R. Khedri, and Q. Zhang, “Endowing concurrent Kleene
algebra with communication actions,” in Proceedings of the 14th Inter-
national Conference on Relational and Algebraic Methods in Computer
Science (P. Höfner, P. Jipsen, W. Kahl, and M. Müller, eds.), vol. 8428
of Lecture Notes in Computer Science, pp. 19–36, Springer International
Publishing Switzerland, 2014.

[4] J. Jaskolka, On the Modelling, Analysis, and Mitigation of Distributed
Covert Channels. PhD thesis, McMaster University, Hamilton, ON,
Canada, March 2015. Available: http://hdl.handle.net/11375/16872.
[5] P. Mell, K. Scarfone, and S. Romanosky, “The common vulnerability
scoring system (CVSS) and its applicability to federal agency systems,”
NIST Interagency Report 7435, National Institute of Standards and
Technology, August 2007.

[6] R. Caralli, J. Stevens, L. Young, and W. Wilson, “Introducing octave
allegro: Improving the information security risk assessment process,”
Tech. Rep. CMU/SEI-2007-TR-012, Software Engineering Institute,
Carnegie Mellon University, Pittsburgh, PA, 2007.

[7] Microsoft,

“Microsoft

Available:
https://technet.microsoft.com/en-us/security/cc998259.aspx (Accessed:
October 24, 2016), August 2014.

exploitability

index.”

[8] S. Abraham and S. Nair, “Exploitability analysis using predictive cy-
bersecurity framework,” in Proceedings of the IEEE 2nd International
Conference on Cybernetics, pp. 317–323, June 2015.

[9] A. J. A. Wang, M. Xia, and F. Zhang, “Metrics for information security
vulnerabilities,” Journal of Applied Global Research, vol. 1, no. 1,
pp. 48–58, 2008.

[10] A. Younis, Y. K. Malaiya, and I. Ray, “Assessing vulnerability ex-
ploitability risk using software properties,” Software Quality Journal,
vol. 24, no. 1, pp. 159–202, 2016.

[11] M. Howard, J. Pincus, and J. M. Wing, Computer Security in the
21st Century, ch. 8: Measuring Relative Attack Surfaces, pp. 109–137.
Boston, MA: Springer US, 2005.

[12] P. K. Manadhata and J. M. Wing, “An attack surface metric,” IEEE
Transactions on Software Engineering, vol. 37, pp. 371–386, May 2011.
[13] A. A. Younis, Y. K. Malaiya, and I. Ray, “Using attack surface entry
points and reachability analysis to assess the risk of software vulner-
ability exploitability,” in Proceedings of the IEEE 15th International
Symposium on High-Assurance Systems Engineering, pp. 1–8, January
2014.

[14] L. Samarji, N. Cuppens-Boulahia, F. Cuppens, S. Papillon, W. Ka-
noun, and S. Dubus, “Coordination and concurrency aware likelihood
assessment of simultaneous attacks,” in Proceedings of the 10th In-
ternational Conference on Security and Privacy in Communication
Networks (J. Tian, J. Jing, and M. Srivatsa, eds.), vol. 152 of Lecture
Notes of the Institute for Computer Sciences, Social Informatics and
Telecommunications Engineering, pp. 524–529, Springer International
Publishing, 2015.

[15] C. Ramakrishnan and R. Sekar, “Model-based analysis of conﬁguration
vulnerabilities,” Journal of Computer Security, vol. 10, no. 1–2, pp. 189–
209, 2002.

[16] S. Cheung, U. Lindqvist, and M. W. Fong, “Modeling multistep cyber
attacks for scenario recognition,” in Proceedings of the 3rd DARPA
Information Survivability Conference and Exposition, DISCEX III,
(Washington, D.C.), pp. 284–292, 2003.

[17] A. Nhlabatsi, R. Laney, and B. Nuseibeh, “Feature interaction: The
security threat from within software systems,” Progress in Informatics,
no. 5, pp. 75–89, 2008.

[18] G. Grieco, L. Mounier, M.-L. Potet, and S. Rawat, “A stack model for
symbolic buffer overﬂow exploitability analysis,” in Proceedings of the
IEEE 6th International Conference on Software Testing, Veriﬁcation and
Validation Workshops, pp. 216–217, March 2013.

[19] A. Shaffer, M. Auguston, C. Irvine, and T. Levin, “Toward a secu-
rity domain model for static analysis and veriﬁcation of information
systems,” in Proceedings of the 7th OOPSLA Workshop on Domain-
Speciﬁc Modeling, DSM ’07, (Montreal, QC, Canada), pp. 160–171,
October 2007.

[20] M. Almorsy, J. Grundy, and A. S. Ibrahim, “Automated software
architecture security risk analysis using formalized signatures,” in Pro-
ceedings of the 2013 International Conference on Software Engineering,
pp. 662–671, 2013.

[21] S. Bistarelli, S. N. Foley, and B. O’Sullivan, “A soft constraint-based
approach to the cascade vulnerability problem,” Journal of Computer
Security, vol. 13, no. 5, pp. 699–720, 2005.

[22] S. Sparks, S. Embleton, R. Cunningham, and C. Zou, “Automated
vulnerability analysis: Leveraging control ﬂow for evolutionary input
crafting,” in Proceedings of the 23rd Annual Computer Security Appli-
cations Conference, pp. 477–486, December 2007.

[23] T. Avgerinos, S. K. Cha, A. Rebert, E. J. Schwartz, M. Woo, and
D. Brumley, “Automatic exploit generation,” Communications of the
ACM, vol. 57, pp. 74–84, February 2014.

[24] R. Focardi, R. Gorrieri, and F. Martinelli, “Real-time information ﬂow
analysis,” IEEE Journal on Selected Areas in Communications, vol. 21,
no. 1, pp. 20–35, 2003.

[25] J. Shen and S. Qing, “A dynamic information ﬂow model of secure
systems,” in Proceedings of the 2nd ACM Symposium on Information,
Computer and Communications Security, ASIACCS ’07, (Singapore),
pp. 341–343, ACM, 2007.

[26] V. Varadharajan, “Petri net based modelling of information ﬂow security
requirements,” in In Proceedings of the Computer Security Foundations
Workshop III, pp. 51–61, June 1990.

[27] R. Focardi and R. Gorrieri, “A classiﬁcation of security properties for
process algebras,” Journal of Computer Security, vol. 3, pp. 5–33,
November 1994.

[28] K. Hristova, T. Rothamel, Y. A. Liu, and S. D. Stoller, “Efﬁcient type
inference for secure information ﬂow,” in Proceedings of
the 2006
Workshop on Programming Languages and Analysis for Security, PLAS
’06, (New York, NY, U.S.A.), pp. 85–94, October 2006.

[29] D. Volpano, G. Smith, and C. Irvine, “A sound type system for secure
ﬂow analysis,” Journal of Computer Security, vol. 4, no. 2-3, pp. 167–
187, 1996.

[30] G. R. Andrews and R. P. Reitman, “An axiomatic approach to informa-
tion ﬂow in programs,” ACM Transactions on Programming Languages
and Systems, vol. 2, pp. 56–76, January 1980.

[31] K. E. Sabri, R. Khedri, and J. Jaskolka, “Veriﬁcation of information
ﬂow in agent-based systems,” in Proceedings of the 4th International
MCETECH Conference on e-Technologies (G. Babin, P. Kropf, and
M. Weiss, eds.), vol. 26 of Lecture Notes in Business Information
Processing, pp. 252–266, Springer Berlin/Heidelberg, May 2009.
[32] L. Lamport, “Time, clocks, and the ordering of events in a distributed
system,” Communications of the ACM, vol. 21, pp. 558–565, July 1978.
[33] N. Ay and D. Polani, “Information ﬂow in causal networks,” Advances

in Complex Systems, vol. 11, no. 01, pp. 17–41, 2008.

[34] L. Lamport, “Proving the correctness of multiprocess programs,” IEEE
Transactions on Software Engineering, vol. SE-3, pp. 125–143, March
1977.

[35] S. M. German and A. P. Sistla, “Reasoning about systems with many
processes,” Journal of the ACM, vol. 39, pp. 675–735, July 1992.
[36] S. F. Siegel and G. Gopalakrishnan, “Formal analysis of message pass-
ing,” in Proceedings of the 12th International Conference on Veriﬁcation,
Model Checking, and Abstract Interpretation (R. Jhala and D. Schmidt,
eds.), vol. 6538 of Lecture Notes in Computer Science, pp. 2–18,
Springer Berlin Heidelberg, 2011.

[37] P. A. Abdulla, F. Haziza, and L. Holík, “All for the price of few
(parameterized veriﬁcation through view abstraction),” in Proceedings
fo the 14th International Conference on Veriﬁcation, Model Checking,
and Abstract Interpretation (R. Giacobazzi, J. Berdine, and I. Mastroeni,
eds.), vol. 7737 of Lecture Notes in Computer Science, pp. 476–495,
Springer Berlin Heidelberg, 2013.

[38] K. S. Namjoshi and R. J. Treﬂer, “Analysis of dynamic process net-
works,” in Proceedings of the 21st International Conference on Tools
and Algorithms for the Construction and Analysis of Systems (C. Baier
and C. Tinelli, eds.), vol. 9035 of Lecture Notes in Computer Science,
pp. 164–178, Springer Berlin Heidelberg, 2015.

[39] J. Jaskolka and R. Khedri, “Mitigating covert channels based on analysis
of the potential for communication,” Theoretical Computer Science,
vol. 643, pp. 1–37, August 2016.

[40] W. Kröger and E. Zio, Vulnerable Systems, ch. 3: Challenges to Methods
for the Vulnerability Analysis of Critical Infrastructures, pp. 33–39.
London: Springer London, 2011.

[41] R. Milner, Communication and Concurrency. Prentice-Hall International

Series in Computer Science, Prentice Hall, 1989.

[42] E. W. Dijkstra, “Guarded commands, nondeterminacy and formal deriva-
tion of programs,” Communications of the ACM, vol. 18, pp. 453–457,
August 1975.

[43] L. Henesey, P. Davidsson, and J. A. Persson, “Agent based simulation
architecture for evaluating operational policies in transshipping contain-
ers,” in Proceedings of the 4th German Conference on Multiagent System
Technologies (K. Fischer, I. J. Timm, E. André, and N. Zhong, eds.),
pp. 73–85, Springer Berlin Heidelberg, September 2006.

[44] M. Clavel, F. Durán, S. Eker, P. Lincoln, N. Martí-Oliet, J. Meseguer,
and C. Talcott, “The Maude 2.0 System,” in Rewriting Techniques
and Applications (R. Nieuwenhuis, ed.), vol. 2706 of Lecture Notes in
Computer Science, pp. 76–87, Springer Berlin/Heidelberg, 2003.
[45] J. Jaskolka and R. Khedri, “A formulation of the potential for com-
munication condition using C2KA,” in Proceedings of the 5th Interna-
tional Symposium on Games, Automata, Logics and Formal Veriﬁcation
(A. Peron and C. Piazza, eds.), vol. 161 of Electronic Proceedings
in Theoretical Computer Science, pp. 161–174, Verona, Italy: Open
Publishing Association, September 2014.

EVALUATING THE EXPLOITABILITY OF IMPLICIT INTERACTIONS IN DISTRIBUTED SYSTEMS

APPENDIX A
ALGEBRAIC STRUCTURES

This appendix summarizes the relevant algebraic structures discussed in the paper.
1) A monoid is a mathematical structure

S, ·, 1

the identity with respect to · (i.e., a · 1 = 1 · a = a for all a ∈ S).

(cid:0)

(cid:1)

where S is a nonempty set, · is an associative binary operation and 1 is

• A monoid is called commutative if · is commutative (i.e., a · b = b · a for all a, b ∈ S).
• A monoid is called idempotent if · is idempotent (i.e., a · a = a for all a ∈ S).

2) A semiring is a mathematical structure

(cid:1)
such that · distributes over + (i.e., a · (b + c) = a · b + a · c and (a + b) · c = a · c + b · c for all a, b, c ∈ S).

(cid:1)

(cid:1)

S, +, ·, 0, 1
(cid:0)

where

S, +, 0
(cid:0)

is a commutative monoid and

is a monoid

S, ·, 1
(cid:0)

• Element 0 is called multiplicatively absorbing if it annihilates S with respect to · (i.e., a · 0 = 0 · a = 0 for all a ∈ S).
• A semiring is called idempotent if + is idempotent.
• Every idempotent semiring has a partial order ≤ on S deﬁned by a ≤ b ⇐⇒ a + b = b.

3) A Kleene algebra is a mathematical structure

multiplicatively absorbing 0 and identity 1, and where the following axioms are satisﬁed for all a, b, c ∈ K:

K, +, ·, ∗, 0, 1
(cid:0)

(cid:1)

where

K, +, ·, 0, 1
(cid:0)

(cid:1)

is an idempotent semiring with a

a) 1 + a · a∗ = a∗
b) 1 + a∗ · a = a∗

c) b + a · c ≤ c =⇒ a∗ · b ≤ c
d) b + c · a ≤ c =⇒ b · a∗ ≤ c

4) Let S =

S, ⊕, ⊙, 0S, 1S
(cid:0)

(cid:1)

semimodule if there exists a mapping ◦ : S × K → K such that for all s, t ∈ S and a, b ∈ K:

be a semiring and K =

be a commutative monoid. We call

K, +, 0K
(cid:0)

(cid:1)

(cid:0)SK, +

(cid:1)

a left S-

a) s ◦ (a + b) = s ◦ a + s ◦ b
b) (s ⊕ t) ◦ a = s ◦ a + t ◦ a
c) (s ⊙ t) ◦ a = s ◦ (t ◦ a)

d)
e)

(cid:0)SK, ⊕
(cid:0)SK, ⊕

(cid:1)
(cid:1)

is unitary if also 1S ◦ a = a
is zero-preserving if also 0S ◦ a = 0K

• An analogous right K-semimodule corresponding is denoted by

denote the semimodule mapping for

SK, ⊕
(cid:0)

.
(cid:1)

5) A concurrent Kleene algebra (CKA) is a mathematical structure

. In this paper, we use λ : S × K → S to
(cid:1)

SK, ⊕
(cid:0)
K, +, ∗, ; , *(cid:13), ;(cid:13), 0, 1
(cid:0)

(cid:1)

such that

K, +, ∗, *(cid:13), 0, 1
(cid:0)

(cid:1)

are Kleene algebras linked by the exchange axiom (a ∗ b) ; (c ∗ d) ≤ (b ; c) ∗ (a ; d).

and

K, +, ; , ;(cid:13), 0, 1
(cid:0)

(cid:1)

• K represents a set of possible behaviours.
• + is a choice of two behaviours.
; is a sequential composition of two behaviours.
•
• ∗ is a concurrent composition of two behaviours.

•

;(cid:13) is a ﬁnite sequential iteration of a behaviour.
*(cid:13) is a ﬁnite concurrent iteration of a behaviour.
•
• 0 represents the behaviour of the inactive agent.
• 1 represents the behaviour of the idle agent.

def
=

6) A stimulus structure S

S, ⊕, ⊙, d, n
(cid:0)
• S is the set of stimuli which may be introduced in a system.
• ⊕ is a choice of two stimuli.
• ⊙ is a sequential composition of two stimuli.
• d represents the deactivation stimulus which inﬂuences all agents to become inactive.
• n represents the neutral stimulus which has no inﬂuence on the behaviour of all agents.

(cid:1)

is an idempotent semiring with a multiplicatively absorbing d and identity n.

7) A dependence relation on a set K with operator + is a bilinear relation R ⊆ K × K (i.e.,

b R c)
(cid:3)

and

a R (b + c) ⇐⇒ (a R b ∨ a R c)
(cid:3)

(cid:2)

• If a R b, we say that b depends on a.

for all a, b, c ∈ S).

(a + b) R c ⇐⇒ (a R c ∨
(cid:2)

A. Detailed Proof of Proposition 1

APPENDIX B
DETAILED PROOFS OF PROPOSITIONS

be an agent such that a is a ﬁxed point behaviour (i.e., ∀(s | s ∈ S\{d} : s ◦ a = a )). Then, Inﬂ(A) = ∅.

Let A 7→

a
(cid:10)
Inﬂ(A) = ∅

(cid:11)

⇐⇒ h Deﬁnition 2 i

{s ∈ Sa | s ◦ a 6= a} = ∅

⇐= h Hypothesis: a is a ﬁxed point & Sa ⊆ S i

{s ∈ Sa | false} = ∅

⇐⇒ h Empty Set Axiom & Reﬂexivity of = i

true

B. Detailed Proof of Proposition 2

Let pTn

pTn−1
n be an implicit interaction. Then, attack
n−1
(cid:0)

pTn
= ∅ =⇒ attack
n (cid:1)
(cid:0)

(cid:1)

= ∅ where Ti ∈ {S, E} for 1 < i ≤ n.

= ∅

pTn
attack
n (cid:1)
(cid:0)
⇐⇒ h Deﬁnition 5 i
pTn
n (cid:1)
(cid:0)
⇐⇒ h Deﬁnition 3 & Deﬁnition 4 i

pTn
n (cid:1)
(cid:0)

∪ AV

= ∅

AS

∪

s |

a | a ∈ Ka ∧ a ≤K Xn−1 ∧ s ∈ Inﬂ(a)
∃
(cid:0)
pTn−1
)
n−1
(cid:0)
(cid:1)

(cid:8)
a | a ∈ Ka ∧ a ≤K Xn−1 ∧ v ∈ Ref(a) : ∃(w |: w ∈ Def(a) ∩ AV
AV
v | ∃
(cid:0)
(cid:1)(cid:9)
pTn−1
∃(s | s ∈ Sa : λ(s, a) ∈ AS
n−1
(cid:0)
pTn−1
⇐= h Hypothesis: attack
n−1
(cid:0)

(cid:1)
a | a ∈ Ka ∧ a ≤K Xn−1 ∧ s ∈ Inﬂ(a) : λ(s, a) ∈ ∅ ∨ ∃(v |: v ∈ Def(a) ∩ ∅ )
s | ∃
(cid:0)

(cid:8)
(cid:1)(cid:9)
a ∈ Ka ∧ a ≤K Xn−1 ∧ v ∈ Ref(a) : ∃(w |: w ∈ Def(a) ∩ ∅ ) ∨ ∃(s | s ∈ Sa : λ(s, a) ∈ ∅ )

= ∅
(cid:1)(cid:9)
= ∅ =⇒ AS

: λ(s, a) ∈ AS

pTn−1
n−1
(cid:0)

= ∅ ∧ AV

pTn−1
n−1

= ∅ i

∪

(cid:8)

(cid:1)

(cid:0)

(cid:1)

(cid:1)

(cid:1)

)

∨ ∃(v |: v ∈ Def(a) ∩
) ∨

pTn−1
n−1
(cid:0)

(cid:1)

a |
v | ∃
(cid:8)
(cid:0)
= ∅

pTn−1
n−1
(cid:0)

(cid:1)(cid:9)

⇐⇒ h Zero of ∩

& Empty Set Membership i

a | a ∈ Ka ∧ a ≤K Xn−1 ∧ s ∈ Inﬂ(a) :
s | ∃
(cid:0)

(cid:8)
Xn−1 ∧ v ∈ Ref(a) : ∃(w |:

false ) ∨ ∃(s | s ∈ Sa : false )

false ∨ ∃(v |:

false )

∪

a | a ∈ Ka ∧ a ≤K
v | ∃
(cid:0)

(cid:8)

(cid:1)(cid:9)

= ∅

(cid:1)(cid:9)

⇐⇒ h ∃-False Body & Identity of ∨ i

s | false
(cid:9)

v | false
(cid:9)
⇐⇒ h Empty Set Axiom & Reﬂexivity of = i

= ∅

∪

(cid:8)

(cid:8)

true

APPENDIX C
C2KA SPECIFICATION OF THE PORT TERMINAL COORDINATION SYSTEM

This appendix contains the complete speciﬁcation of the port terminal coordination system described in Section IV.

A. System Agents

The port terminal coordination system consists of the following eight agents:

PC
Port Captain
TM Terminal Manager
CM Crane Manager

SM1
SV1
CC

Ship Manager 1
Stevedore 1
Carrier Coordinator

SM2
SV2

Ship Manager 2
Stevedore 2

B. Stimulus Structure

The set of stimuli S is generated using the operations of stimulus structures and the following set of 21 atomic
stimuli: {arrive, mnge1 , mnge2 , ship1 , ship2 , crane1 , crane2 , allocd , berth, dock , oper1 , oper2 , carrier , assgnd , serve,
served , done, compl1 , compl2 , deprt1 , deprt2 }.

C. Behavior (CKA) Structure

The set of agent behaviours K is generated using the operations of CKA and the following set of 25 atomic be-
haviours: {DEPART, CLEAR1, CLEAR2, INIT, MAN1, MAN2, SRVT, POSN, LEAVE, CRANES, PLAN, DOCK, RLSE, ALLO,
FREE, READ, CARGO, SEQ, SERVE, UPDT, OPER, AVAIL, ASSGN, NEAR, MOVE}.

D. Stimulus-Response Speciﬁcations of Agents

The stimulus-response speciﬁcations for the system agents are provided in a tabular format as shown in Tables I–VIII.
While the stimulus-response speciﬁcations of the system agents speciﬁes a single next behaviour mapping ◦ and next stimulus
mapping λ, they are presented as separate tables for each agent to improve the readability and reviewability of the speciﬁcations.
For each table, the row header shows the atomic behaviours that the given agent can exhibit as dictated by the abstract behaviour
speciﬁcation of the agent and the C2KA. The column header shows the atomic stimuli to which the agent may be subjected.
The table grid provides the resulting next behaviour or next stimulus (with respect to the operator given in the top left cell)
when the stimulus shown in the column header is applied to the behaviour shown in the row header.

E. Abstract Behaviour Speciﬁcations

The abstract behaviour speciﬁcations for the system agents are given in Fig. 1. The behaviour of the port terminal coordination

system (PCT) can be represented by the concurrent composition of the behaviours of each of the system agents, i.e.,

PCT 7→

PC ∗ SM1 ∗ SM2 ∗ SV1 ∗ SV2 ∗ TM ∗ CM ∗ CC
(cid:11)
(cid:10)

PC 7→
SMi
7→
SVi
7→
TM 7→
CM 7→
CC 7→

(MAN1 + MAN2) ; INIT + (CLEAR1 + CLEAR2) ; DEPART
(cid:10)
SRVT + POSN + LEAVE
(cid:10)
CRANES + PLAN + DOCK + RLSE
ALLO + FREE
READ ; CARGO + SEQ ; SERVE + UPDT ; OPER
AVAIL ; ASSGN + NEAR ; MOVE

(cid:10)
(cid:10)

(cid:11)

(cid:11)

(cid:11)

(cid:11)

(cid:11)

(cid:10)
(cid:10)

(cid:11)

Fig. 1: Abstract behaviour speciﬁcation of the port terminal coordination system agents.

◦
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

λ
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

◦
SRVT
POSN
LEAVE

λ
SRVT
POSN
LEAVE

◦
SRVT
POSN
LEAVE

λ
SRVT
POSN
LEAVE

arrive
MAN1
MAN2
INIT
MAN1
MAN2
DEPART

arrive
n
n
n
mnge1
mnge2
n

arrive
SRVT
POSN
LEAVE

arrive
n
n
n

arrive
SRVT
POSN
LEAVE

arrive
n
n
n

mnge1
MAN1
MAN2
INIT
CLEAR1
CLEAR2
INIT

mnge1
n
n
n
n
n
mnge1

mnge1
SRVT
POSN
SRVT

mnge1
n
n
ship1

mnge1
SRVT
POSN
LEAVE

mnge1
n
n
n

mnge2
MAN1
MAN2
INIT
CLEAR1
CLEAR2
INIT

mnge2
n
n
n
n
n
mnge2

mnge2
SRVT
POSN
LEAVE

mnge2
n
n
n

mnge2
SRVT
POSN
SRVT

mnge2
n
n
ship2

TABLE I: Stimulus-response speciﬁcation of the Port Captain PC.

ship1
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

ship1
n
n
n
n
n
n

ship2
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

ship2
n
n
n
n
n
n

crane1
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

crane1
n
n
n
n
n
n

crane2
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

crane2
n
n
n
n
n
n

allocd
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

allocd
n
n
n
n
n
n

berth
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

berth
n
n
n
n
n
n

dock
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

dock
n
n
n
n
n
n

oper1
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

oper1
n
n
n
n
n
n

oper2
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

oper2
n
n
n
n
n
n

carrier
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

carrier
n
n
n
n
n
n

assgnd
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

assgnd
n
n
n
n
n
n

serve
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

serve
n
n
n
n
n
n

served
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

served
n
n
n
n
n
n

done
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

done
n
n
n
n
n
n

ship1
SRVT
POSN
LEAVE

ship1
n
n
n

ship1
SRVT
POSN
LEAVE

ship1
n
n
n

ship2
SRVT
POSN
LEAVE

ship2
n
n
n

ship2
SRVT
POSN
LEAVE

ship2
n
n
n

TABLE II: Stimulus-response speciﬁcation of the Ship Manager SM1.

crane1
SRVT
POSN
LEAVE

crane1
n
n
n

crane2
SRVT
POSN
LEAVE

crane2
n
n
n

allocd
SRVT
POSN
LEAVE

allocd
n
n
n

berth

POSN
POSN
LEAVE

berth
dock
n
n

dock
SRVT
POSN
LEAVE

dock
n
n
n

oper1
SRVT
POSN
LEAVE

oper1
n
n
n

oper2
SRVT
POSN
LEAVE

oper2
n
n
n

carrier
SRVT
POSN
LEAVE

carrier
n
n
n

assgnd
SRVT
POSN
LEAVE

assgnd
n
n
n

TABLE III: Stimulus-response speciﬁcation of the Ship Manager SM2.

crane1
SRVT
POSN
LEAVE

crane1
n
n
n

crane2
SRVT
POSN
LEAVE

crane2
n
n
n

allocd
SRVT
POSN
LEAVE

allocd
n
n
n

berth

POSN
POSN
LEAVE

berth
dock
n
n

dock
SRVT
POSN
LEAVE

dock
n
n
n

oper1
SRVT
POSN
LEAVE

oper1
n
n
n

oper2
SRVT
POSN
LEAVE

oper2
n
n
n

carrier
SRVT
POSN
LEAVE

carrier
n
n
n

assgnd
SRVT
POSN
LEAVE

assgnd
n
n
n

TABLE IV: Stimulus-response speciﬁcation of the Stevedore SV1.

serve
SRVT
POSN
LEAVE

serve
n
n
n

serve
SRVT
POSN
LEAVE

serve
n
n
n

served
SRVT
POSN
LEAVE

served
n
n
n

served
SRVT
POSN
LEAVE

served
n
n
n

done
SRVT
POSN
LEAVE

done
n
n
n

done
SRVT
POSN
LEAVE

done
n
n
n

compl1
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

compl1
n
n
n
n
n
n

compl1
SRVT
LEAVE
LEAVE

compl1
n
deprt1
n

compl1
SRVT
POSN
LEAVE

compl1
n
n
n

compl2
MAN1
MAN2
INIT
CLEAR1
CLEAR2
DEPART

compl2
n
n
n
n
n
n

compl2
SRVT
POSN
LEAVE

compl2
n
n
n

compl2
SRVT
LEAVE
LEAVE

compl2
n
deprt2
n

deprt1
CLEAR1
MAN2
DEPART
CLEAR1
CLEAR2
DEPART

deprt1
deprt1
n
n
n
n
n

deprt1
SRVT
POSN
LEAVE

deprt1
n
n
n

deprt1
SRVT
POSN
LEAVE

deprt1
n
n
n

deprt2
MAN1
CLEAR2
DEPART
CLEAR1
CLEAR2
DEPART

deprt2
n
deprt2
n
n
n
n

deprt2
SRVT
POSN
LEAVE

deprt2
n
n
n

deprt2
SRVT
POSN
LEAVE

deprt2
n
n
n

◦

CRANES
PLAN
DOCK
RLSE

λ

CRANES
PLAN
DOCK
RLSE

arrive

mnge1

mnge2

ship1

ship2

crane1

crane2

CRANES
PLAN
DOCK
RLSE

arrive
n
n
n
n

CRANES
PLAN
DOCK
RLSE

mnge1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

mnge2
n
n
n
n

CRANES
CRANES
CRANES
CRANES

ship1
n
crane1
crane1
crane1

CRANES
PLAN
DOCK
RLSE

ship2
n
n
n
n

CRANES
PLAN
DOCK
RLSE

crane1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

crane2
n
n
n
n

allocd

PLAN
PLAN
DOCK
RLSE

allocd
berth
n
n
n

berth

dock

oper1

oper2

carrier

assgnd

serve

served

done

compl1

compl2

deprt1

deprt2

CRANES
PLAN
DOCK
RLSE

CRANES
DOCK
DOCK
RLSE

CRANES
PLAN
DOCK
RLSE

CRANES
PLAN
DOCK
RLSE

berth
n
n
n
n

dock
n
oper1
n
n

oper1
n
n
n
n

oper2
n
n
n
n

CRANES
PLAN
DOCK
RLSE

carrier
n
n
n
n

CRANES
PLAN
DOCK
RLSE

assgnd
n
n
n
n

CRANES
PLAN
DOCK
RLSE

serve
n
n
n
n

CRANES
PLAN
DOCK
RLSE

served
n
n
n
n

CRANES
PLAN
RLSE
RLSE

done
n
n
compl1
n

CRANES
PLAN
DOCK
RLSE

compl1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

compl2
n
n
n
n

CRANES
PLAN
DOCK
RLSE

deprt1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

deprt2
n
n
n
n

TABLE V: Stimulus-response speciﬁcation of the Stevedore SV2.

◦

CRANES
PLAN
DOCK
RLSE

λ

CRANES
PLAN
DOCK
RLSE

arrive

mnge1

mnge2

ship1

ship2

crane1

crane2

CRANES
PLAN
DOCK
RLSE

arrive
n
n
n
n

CRANES
PLAN
DOCK
RLSE

mnge1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

mnge2
n
n
n
n

CRANES
PLAN
DOCK
RLSE

ship1
n
n
n
n

CRANES
CRANES
CRANES
CRANES

ship2
n
crane2
crane2
crane2

CRANES
PLAN
DOCK
RLSE

crane1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

crane2
n
n
n
n

allocd

PLAN
PLAN
DOCK
RLSE

allocd
berth
n
n
n

berth

dock

oper1

oper2

carrier

assgnd

serve

served

done

compl1

compl2

deprt1

deprt2

CRANES
PLAN
DOCK
RLSE

CRANES
DOCK
DOCK
RLSE

CRANES
PLAN
DOCK
RLSE

CRANES
PLAN
DOCK
RLSE

berth
n
n
n
n

dock
n
oper2
n
n

oper1
n
n
n
n

oper2
n
n
n
n

CRANES
PLAN
DOCK
RLSE

carrier
n
n
n
n

CRANES
PLAN
DOCK
RLSE

assgnd
n
n
n
n

CRANES
PLAN
DOCK
RLSE

serve
n
n
n
n

CRANES
PLAN
DOCK
RLSE

served
n
n
n
n

CRANES
PLAN
RLSE
RLSE

done
n
n
compl2
n

CRANES
PLAN
DOCK
RLSE

compl1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

compl2
n
n
n
n

CRANES
PLAN
DOCK
RLSE

deprt1
n
n
n
n

CRANES
PLAN
DOCK
RLSE

deprt2
n
n
n
n

TABLE VI: Stimulus-response speciﬁcation of the Terminal Manager TM.

◦

ALLO
FREE

λ

ALLO
FREE

arrive

ALLO
FREE

arrive
n
n

mnge1

mnge2

ALLO
FREE

mnge1
n
n

ALLO
FREE

mnge2
n
n

ship1

ALLO
FREE

ship1
n
n

ship2

ALLO
FREE

ship2
n
n

crane1

crane2

ALLO
ALLO

crane1
n
allocd

ALLO
ALLO

crane2
n
allocd

allocd

ALLO
FREE

allocd
n
n

berth

ALLO
FREE

berth
n
n

dock

ALLO
FREE

dock
n
n

oper1

ALLO
FREE

oper1
n
n

oper2

ALLO
FREE

oper2
n
n

carrier

assgnd

ALLO
FREE

carrier
n
n

ALLO
FREE

assgnd
n
n

serve

ALLO
FREE

serve
n
n

served

ALLO
FREE

served
n
n

done

ALLO
FREE

done
n
n

compl1

compl2

deprt1

deprt2

FREE
FREE

compl1
n
n

FREE
FREE

compl2
n
n

ALLO
FREE

deprt1
n
n

ALLO
FREE

deprt2
n
n

TABLE VII: Stimulus-response speciﬁcation of the Crane Manager CM.

carrier

assgnd

serve

served

done

compl1

compl2

◦

READ
CARGO
SEQ
SERVE
UPDT
OPER

λ

READ
CARGO
SEQ
SERVE
UPDT
OPER

◦

AVAIL
ASSGN
NEAR
MOVE

λ

AVAIL
ASSGN
NEAR
MOVE

arrive

READ
CARGO
SEQ
SERVE
UPDT
OPER

arrive
n
n
n
n
n
n

arrive

AVAIL
ASSGN
NEAR
MOVE

arrive
n
n
n
n

mnge1

READ
CARGO
SEQ
SERVE
UPDT
OPER

mnge1
n
n
n
n
n
n

mnge1

AVAIL
ASSGN
NEAR
MOVE

mnge1
n
n
n
n

mnge2

READ
CARGO
SEQ
SERVE
UPDT
OPER

mnge2
n
n
n
n
n
n

mnge2

AVAIL
ASSGN
NEAR
MOVE

mnge2
n
n
n
n

ship1

READ
CARGO
SEQ
SERVE
UPDT
OPER

ship1
n
n
n
n
n
n

ship1

AVAIL
ASSGN
NEAR
MOVE

ship1
n
n
n
n

ship2

READ
CARGO
SEQ
SERVE
UPDT
OPER

ship2
n
n
n
n
n
n

crane1

READ
CARGO
SEQ
SERVE
UPDT
OPER

crane1
n
n
n
n
n
n

crane2

READ
CARGO
SEQ
SERVE
UPDT
OPER

crane2
n
n
n
n
n
n

allocd

READ
CARGO
SEQ
SERVE
UPDT
OPER

allocd
n
n
n
n
n
n

berth

READ
CARGO
SEQ
SERVE
UPDT
OPER

berth
n
n
n
n
n
n

dock

READ
CARGO
SEQ
SERVE
UPDT
OPER

dock
n
n
n
n
n
n

oper1

READ
CARGO
READ
CARGO
READ
CARGO

oper1
n
n
oper1
carrier
oper1
carrier

oper2

READ
CARGO
READ
CARGO
READ
CARGO

oper2
n
n
oper2
carrier
oper2
carrier

READ
CARGO
SEQ
SERVE
UPDT
OPER

carrier
n
n
n
n
n
n

SEQ
SERVE
SEQ
SERVE
SEQ
SERVE

assgnd
assgnd
serve
n
n
assgnd
serve

READ
CARGO
SEQ
SERVE
UPDT
OPER

serve
n
n
n
n
n
n

TABLE VIII: Stimulus-response speciﬁcation of the Carrier Coordinator CC.

ship2

AVAIL
ASSGN
NEAR
MOVE

ship2
n
n
n
n

crane1

crane2

AVAIL
ASSGN
NEAR
MOVE

crane1
n
n
n
n

AVAIL
ASSGN
NEAR
MOVE

crane2
n
n
n
n

allocd

AVAIL
ASSGN
NEAR
MOVE

allocd
n
n
n
n

berth

AVAIL
ASSGN
NEAR
MOVE

berth
n
n
n
n

dock

AVAIL
ASSGN
NEAR
MOVE

dock
n
n
n
n

oper1

AVAIL
ASSGN
NEAR
MOVE

oper1
n
n
n
n

oper2

AVAIL
ASSGN
NEAR
MOVE

oper2
n
n
n
n

carrier

assgnd

AVAIL
ASSGN
AVAIL
ASSGN

carrier
n
n
carrier
assgnd

AVAIL
ASSGN
NEAR
MOVE

assgnd
n
n
n
n

serve

NEAR
MOVE
NEAR
MOVE

serve
serve
served
n
n

UPDT
OPER
UPDT
OPER
UPDT
OPER

served
served
done
served
done
n
n

served

AVAIL
ASSGN
NEAR
MOVE

served
n
n
n
n

READ
CARGO
SEQ
SERVE
UPDT
OPER

done
n
n
n
n
n
n

done

AVAIL
ASSGN
NEAR
MOVE

done
n
n
n
n

READ
CARGO
SEQ
SERVE
UPDT
OPER

compl1
n
n
n
n
n
n

READ
CARGO
SEQ
SERVE
UPDT
OPER

compl2
n
n
n
n
n
n

deprt1

READ
CARGO
SEQ
SERVE
UPDT
OPER

deprt1
n
n
n
n
n
n

compl1

compl2

AVAIL
ASSGN
NEAR
MOVE

compl1
n
n
n
n

AVAIL
ASSGN
NEAR
MOVE

compl2
n
n
n
n

deprt1

AVAIL
ASSGN
NEAR
MOVE

deprt1
n
n
n
n

deprt2

READ
CARGO
SEQ
SERVE
UPDT
OPER

deprt2
n
n
n
n
n
n

deprt2

AVAIL
ASSGN
NEAR
MOVE

deprt2
n
n
n
n

F. Concrete Behaviour Speciﬁcations

The concrete behaviour speciﬁcations for the system agents are given in Figs. 2–7. Note that in the concrete behaviour
speciﬁcations, we use functions as a simpliﬁcation of the speciﬁcation in places where we are not concerned with how the
system performs the operation. In these cases, we assume that the function arguments are passed by value, meaning that they
can only be referenced, and not deﬁned, in the function. For example, in the concrete behaviour speciﬁcation of the Carrier
Coordinator CC, there is a function call denoted by ASSIGN(carriers, containers). In this case, the concrete behaviour
references the variables carriers and containers when determining the straddle carrier assignment. Additionally, note that
program variables appearing in all capitals (e.g., SHIP_MANIFEST, SHIP_LENGTH, CRANE_EFF, etc.) denote deﬁned constants.

MAN1

MAN2

INIT

CLEAR1

CLEAR2

DEPART

def
= m1 := true; i := 1
def
= m2 := true; i := 2
def
= if

(i = 1) −→ manifest[1] := SHIP_MANIFEST; length[1] := SHIP_LENGTH;
numBays[1] := SHIP_BAYS; numContainers[1] := SHIP_CONTAINERS;
arriveT[1] := ARRIVE_TIME; departT[1] := DEPART_TIME; waitT[1] := WAIT_TIME

(i = 2) −→ manifest[2] := SHIP_MANIFEST; length[2] := SHIP_LENGTH;
numBays[2] := SHIP_BAYS; numContainers[2] := SHIP_CONTAINERS;
arriveT[2] := ARRIVE_TIME; departT[2] := DEPART_TIME; waitT[2] := WAIT_TIME

⌈⌋

ﬁ

def
= m1 := false; i := 1
def
= m2 := false; i := 2
def
= if

(i = 1) −→ manifest[1] := null; length[1] := 0; numBays[1] := 0;

numContainers[1] := 0; arriveT[1] := 0; departT[1] := 0; waitT[1] := 0

(i = 2) −→ manifest[2] := null; length[2] := 0; numBays[2] := 0;

numContainers[2] := 0; arriveT[2] := 0; departT[2] := 0; waitT[2] := 0

⌈⌋

ﬁ

Fig. 2: Concrete behaviour speciﬁcation of the Port Captain PC behaviours.

SRVT

POSN

LEAVE

def
= serviceT[i] := departT[i] − arriveT[i] − waitT[i]
def
= dockPos[i] := berthPos[i]
def
= dockPos[i] := null; serviceT[i] := 0

Fig. 3: Concrete behaviour speciﬁcation of the Ship Manager behaviours where i = 1 for SM1 and i = 2 for SM2.

CRANES

PLAN

def
= numCranes[i] := numContainers[i]/(CRANE_EFF ∗ serviceT[i])
def
= berthPos[i] := berth[i];

bayPlan[i] := PLAN(berthPos[i], alloCranes[i], manifest[i], numBays[i])

DOCK

RLSE

def
= docked[i] := true
def
= docked[i] := false; berthPos[i] := null; bayPlan[i] := null; numCranes[i] := 0

Fig. 4: Concrete behaviour speciﬁcation of the Stevedore behaviours where i = 1 for SV1 and i = 2 for SV2.

ALLO

def
= receive y;

(y ≥ crane1 ) −→ berth[1] := POSITION(numCranes[1]);

alloCranes[1] := ALLOCATE(berth[1])

(y ≥ crane2 ) −→ berth[2] := POSITION(numCranes[2]);

alloCranes[2] := ALLOCATE(berth[2])

if

⌈⌋

ﬁ

FREE

def
= receive y;

(y ≥ compl1 ) −→ berth[1] := null; alloCranes[1] := null
(y ≥ compl2 ) −→ berth[2] := null; alloCranes[2] := null

if

⌈⌋
ﬁ

Fig. 5: Concrete behaviour speciﬁcation of the Terminal Manager TM behaviours.

READ

def
= receive y;

(y ≥ oper1 ) −→ plan := bayPlan[1]
(y ≥ oper2 ) −→ plan := bayPlan[2]

if

⌈⌋
ﬁ

CARGO

SEQ

SERVE

UPDT

OPER

def
= containers := CONTAINERS(plan)
def
= sequence := SEQUENCE(carrierAssign)
def
= position := SERVICE(sequence)
def
= plan := UPDATE(carrierState)
def
= operation := OPERATE(plan)

Fig. 6: Concrete behaviour speciﬁcation of the Crane Manager CM behaviours.

AVAIL

ASSGN

NEAR

MOVE

def
= carriers := AVAIL(carrierState)
def
= carrierAssign := ASSIGN(carriers, containers)
def
= nearest := NEAREST(carriers, position)
def
= carrierState := MOVE(carrierState, nearest, position)

Fig. 7: Concrete behaviour speciﬁcation of the Carrier Coordinator CC behaviours.

