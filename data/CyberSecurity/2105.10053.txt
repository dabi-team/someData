1
2
0
2

y
a
M
0
2

]

R
C
.
s
c
[

1
v
3
5
0
0
1
.
5
0
1
2
:
v
i
X
r
a

A Rule Mining-Based Advanced Persistent Threats Detection System

Sidahmed Benabderrahmane1,2∗ , Ghita Berrada3,4 , James Cheney1,5 and Petko Valtchev6
1The University of Edinburgh, School of Informatics, Edinburgh, UK.
2New York University, Computer Science Department.
3King’s College London, School of Population Health and Environmental Sciences, UK.
4University of Manchester, School of Health Sciences, UK.
5The Alan Turing Institute, UK.
6Universit´e du Qu´ebec `a Montr´eal, CRIA, Montr´eal (QC), Canada.
sidahmed.benabderrahmane@gmail.com, ghita.berrada@kcl.ac.uk, jcheney@inf.ed.ac.uk,
valtchev.petko@uqam.ca

Abstract

Advanced persistent
threats (APT) are stealthy
cyber-attacks that are aimed at stealing valuable
information from target organizations and tend to
extend in time. Blocking all APTs is impossi-
ble, security experts caution, hence the importance
of research on early detection and damage lim-
itation. Whole-system provenance-tracking and
provenance trace mining are considered promising
as they can help ﬁnd causal relationships between
activities and ﬂag suspicious event sequences as
they occur. We introduce an unsupervised method
that exploits OS-independent features reﬂecting
process activity to detect realistic APT-like attacks
from provenance traces. Anomalous processes are
ranked using both frequent and rare event associ-
ations learned from traces. Results are then pre-
sented as implications which, since interpretable,
help leverage causality in explaining the detected
anomalies. When evaluated on Transparent Com-
puting program datasets (DARPA), our method out-
performed competing approaches.

1 Introduction

“[I]n this world nothing can be said to be certain, except
death and taxes.”, wrote Benjamin Franklin in 1789. To this
list, one could add the increasingly common and headline-
grabbing cyberattacks/security breaches [Sebenius, 2021;
Ping and Johnson, 2018; Huang and Majidi, 2018], most of
which are so-called advanced persistent threats (APT).

APTs are long-running and stealthy cyberattacks where ad-
versaries gain access to speciﬁc targets’ systems, staying un-
detected in the system for as long as necessary to reach their
goal (mostly stealing or corrupting sensitive data or damaging
the target’s critical systems). Such attacks are now “part and
parcel of doing business” [Auty, 2015], say experts and when
not stopped early enough, inﬂict signiﬁcant damage, partic-
ularly ﬁnancial or reputational, to the victim. Preventing all

∗Contact Author

such attacks is impossible [Auty, 2015], experts warn, so sys-
tems should be monitored continuously so as to detect APTs
early and keep their damage to a minimum.

With APTs mimicking normal user activity, such attacks
cannot be detected with traditional means (e.g antivirus soft-
ware, signature or system-policy-based techniques). Meth-
ods relying on system/event logs or audit trails typically
fail as they generally only analyze short event/system call
sequences, which not only makes them unable to properly
model and capture long-term behavior patterns but also sus-
ceptible to evasion techniques. Recent work [Park et al.,
2012; Manzoor et al., 2016; Han et al., 2018; Berrada et
al., 2020; Han et al., 2020] has suggested whole-system
provenance-tracking and provenance trace mining as solu-
tions better suited for APT detection: the richer contextual
information of provenance would help identify causal rela-
tionships between system activities, allowing the detection
of attack patterns (e.g data exﬁltration) that usually go un-
noticed with the usual perimeter defence-based or policy-
driven tools [Brian and Beaver, 2011; Zhang et al., 2012;
Abir et al., 2016; Jenkinson et al., 2017].

There are, however, challenges to be overcome before
mining provenance data that can fulﬁll its system security
strengthening promises. There are also issues directly linked
to the recording of provenance itself (e.g. level of provenance
granularity, fault tolerance, trustworthiness and consistency
of the recorded trace [Jenkinson et al., 2017]). The more wor-
risome issue though is the “needle in a haystack” problem:
the volume of recorded provenance traces is massive (each
day of system activity results in one or more gigabytes of
provenance traces, containing hundreds or thousands of pro-
cesses) and anomalous system activity (if at all present) only
constitutes a tiny fraction of the recorded traces. Added to
this, the diversity of possible APT patterns and the unavail-
ability of fully annotated data make it even more complex to
uncover anomalous activity indicative of an ongoing APT.

In such a context, typical supervised learning techniques
would be of limited use to detect APT patterns and only un-
supervised learning techniques would pass muster (see sec-
tion 5.1 on data imbalance). In operational security settings,
the ready availability of actionable information is critical. Se-

 
 
 
 
 
 
curity analysts can easily recognize and forensically investi-
gate suspicious system behavior (e.g. processes created or
subverted by an attacker) when brought to their attention.
However, having the analysts sift through the traces in their
entirety, when as little as 0.004% of the activity, if any at
all, is suspicious, is hardly an efﬁcient use of their time.
In this paper, we investigate the key subproblem of quickly
ﬂagging unusual process activity that calls for further man-
ual inspection. To tackle this problem, we summarize pro-
cess activity through binary or categorical features (e.g kinds
of events performed by a process, process executable name,
IP addresses and ports accessed) and propose an anomaly
detection method that scores individual processes based on
whether they satisfy or violate association rules (both fre-
quent and rare) extracted from process activity summaries.

Central to our method and a key advantage of it is the use of
association rules. Not only do the rules let us score processes
and ﬂag anomalies in a principled manner, but they also al-
low us to present results in a way that could be more easily
understood and interpreted by experts/security analysts seek-
ing to thoroughly investigate and gain a deeper understanding
of attack patterns. We evaluated our approach using prove-
nance traces produced by the DARPA Transparent Comput-
ing (TC) program1. We set our association-based anomaly
detector against an array of existing batch anomaly detectors
and show it outperformed all of them.

The remainder of the paper is as follows: Section 2 sum-
marizes related work, while section 3 provides background
on association rule mining. Next, section 4 introduces our
approach and section 5 discusses the experimental study and
its outcome. We conclude with section 6.

2 Related Work

Intrusion and malware detection methods follow two main
approaches: misuse detection (e.g. [Kumar and Spafford,
1994]) and anomaly detection (e.g. [Ji et al., 2016]). Mis-
use detection searches for events matching predeﬁned signa-
tures and patterns. Related methods can only detect attacks
with known signature/patterns, hence are unsuitable for APT
detection. By contrast, anomaly detection makes no assump-
tion about the attack nature and just looks for activity that
deviates from normal behavior i.e. usually recorded on a spe-
ciﬁc host or network. Ahmed et al. [Mohiuddin et al., 2016]
is a survey of the main network anomaly detection tech-
niques, which it divides into four categories: classiﬁcation-
based, clustering-based, information theory-based and sta-
tistical. Anomaly detection surveys [Chandola et al., 2009;
Akoglu et al., 2015] typically distinguish approaches w.r.t.
the type of data (categorical, continuous, semi-structured,
etc.) they admit. Among those, graph methods are the most
relevant for our study, yet they typically work on graph for-
mats of reduced expressiveness (e.g. undirected or unla-
beled), whereas provenance graphs have rich structure (labels
and properties on both nodes and edges). Existing anomaly
detection approaches for provenance graphs rely on train-
ing with benign traces [Manzoor et al., 2016], require user-
provided annotations [Hossain et al., 2017], or assume highly

1https://www.darpa.mil/program/transparent-computing

regular background activity [Hassan et al., 2018].

In parallel, a number of anomaly detection approaches
have been designed for categorical data [He et al., 2005;
Narita and Kitagawa, 2008; Koufakou et al., 2007; Koen
and Vreeken, 2011; Akoglu et al., 2013; Bertens et al.,
2017]. Some of them, e.g. OC3 [Koen and Vreeken, 2011;
Vreeken et al., 2011] and CompreX [Akoglu et al., 2013],
are based on the Minimum Description Length (MDL) prin-
ciple [Gr¨unwald, 2007]:
the idea here is to preprocess the
dataset by compressing it and then take the compressed
record size as its anomaly score, the underlying assumption
being that infrequent/anomalous patterns are less efﬁciently
compressed and result in higher sizes. UPC [Bertens et al.,
2017] also relies on MDL (in combination with pattern min-
ing) and is a two-pass approach that looks for a different kind
of anomalies (class-2) than CompreX. FPOF (Frequent Pat-
tern Outlier Factor) [He et al., 2005] is an itemset-mining
method exploiting transaction outlierness: outliers (lower
FPOF values) are transactions with fewer frequent patterns.
Outlier-degree (OD) [Narita and Kitagawa, 2008], uses both
categorical and continuous variables whereby infrequent val-
ues would indicate outlier status. AVF (Attribute Value Fre-
quency) [Koufakou et al., 2007] computes anomaly scores by
summing attribute frequencies. Data points having features
with low occurrence probability (estimated from frequencies)
are likely to be outliers. Other existing methods mixing cat-
egorical and numerical, e.g. SmartSifter [Yamanishi et al.,
2004] and ODMAD [Koufakou and Georgiopoulos, 2010],
could be applied to pure categorical data. ODMAD performs
an initial off-line pattern mining stage, while SmartSifter is,
to the best of our knowledge, the only previous unsupervised
online algorithm for categorical data. However, it is unclear
whether it can scale to a large number of attributes.

Itemset and Association Rule Mining

3
In association rule mining (ARM) [Agrawal et al., 1993], data
comes as a transaction database D (as in Table 1) involving
a universe of items, or attributes, A = {a1, a2, . . . , an} (here
named a to e). A set of items X ⊆ A is called an item-
set. Below, for compactness reasons, itemsets are given in
separator-less form. Then, a transaction, aka object, is a pair
(tid, itemset) where tid is a transaction identiﬁer taken from
the set O = {o1, o2, ..., om} (aka set of objects). Next, a set
of tids is called a tidset. For historical reasons, we call D a
context and introduce it as ×-table (see Table 1).

The image of a tidset Y from O, ι(Y ) = (cid:84){Z|(j, Z) ∈
D, j ∈ Y } is made of the items shared by all the correspond-
ing objects. Conversely, the image of an itemset X, aka its
support set, comprises the tids of all objects for which X is a
subset of the respective itemset, τ (X) = {j|(j, Z) ∈ D, X ⊆
Z}. For instance, in Table 1, τ (e) = {o1}. An itemset qual-
ity reﬂects its support: (absolute) support is its supporting set
size, suppa(X) = |τ (X)| while relative support is the frac-
tion supp(X) = |τ (X)|/|D|. A support threshold, min supp,
splits itemsets into frequent and infrequent itemsets, whereas
with a max supp, infrequent ones, a.k.a. rare [Szathmary et
al., 2007], are the target. For instance, with min supp=3,
ac is frequent while abcd is rare. Here, we exploit border-
line cases, i.e. maximal frequent itemsets (MFI, no frequent

e
x

b
x

x

x

a

x
x
x
x
x

c
x
x
x

x
x

d

x
x
x
x
x

o1
o2
o3
o4
o5
o6

Table 1: A sample transaction database (context).

superset) and minimal rare itemsets (MRI, no rare subsets),
which are closed itemsets and generators, respectively.
In
fact, τ induces an equivalence relations on ℘(A): X ≡ Z
iff τ (X) = τ (Z) whereby each class has a unique maximum,
called the closed itemset, and one or more minima, its gen-
erators. Both categories admit straightforward support-wise
deﬁnitions: an itemset X is closed (generator) if it admits
no superset (subset) with identical support. For instance, in
Table 1, bc is closed while b is a (non closed) generator.

An association rule has the form X→Y , where X, Y ⊆
A and X ∩ Y = ∅. Among the most popular rule qual-
ity measures are the support, supp(X→Y )=supp(X∪Y ),
the conﬁdence, conf (X→Y )=supp(X→Y )/supp(X), and the
lift,
lift(X→Y )= supp(X∪Y )/supp(X)×supp(Y ). Again,
support-wise, a rule qualiﬁes as frequent or rare [Szathmary
et al., 2007] whereas it is said to be conﬁdent if it reaches a
conﬁdence threshold min conf . Frequent (rare) and conﬁ-
dent rules are valid. For example, with min conf = 3/5, and
min supp=max supp=3, a→c is valid frequent (supp= 4 and
conf =4/5) while ab→d is valid rare (supp=2 and conf =1).

4 Rule Mining-Based Anomaly Detection

Frequent and rare patterns [Szathmary et al., 2007] clearly
convey different types of regularities in the data. The former
tend to capture generally valid rules, e.g. the typical behavior
of customers on an online retail portal. The latter, in con-
trast, focus on local regularities that, without being totally
exceptional, i.e. unique, have a very limited extent. In fact,
such regularities will likely be missed by an exhaustive search
with a low min supp threshold since they will be missed in
the immensely voluminous result. Rare patterns have the ca-
pacity to capture the features of a highly under-represented —
and unknown — class in an imbalanced sample, which makes
them valuable for our study.

Following the above guidelines, we hypothesize that APT-
related processes constitute a separate class following a event
chaining schema that distinguishes them from normal ones.
The schema should manifest as atypical associations of events
which, taken separately, might be totally legitimate. Conse-
quently, such atypical behavior may be captured either as a
mismatch to common behavioral patterns or as a consistent,
yet rare, pattern of itself. Thus, a forensic APT detection ap-
proach should focus on candidate processes satisfying these
conditions. Technically speaking, an anomaly score needs to
quantify the above (mis)matches of key patterns while also
reﬂecting those patterns’ quality (see section 3).

As a ﬁrst approach, we propose to organize system traces
as a transaction database and to mine itemset associations
from them (rather than, say, sequential patterns). Such an
approach has the added beneﬁt of being explainable as the
event implication format is easy to interpret. This, in turn, fa-

vors better understanding of mechanisms behind an APT and
therefore should facilitate threat prevention.

4.1 Anomaly Detection Method

We designed two separate anomaly detection methods: VR-
ARM for Valid Rare ARM and VF-ARM for Valid Frequent
ARM. The underlying association rules have been derived
from MRIs and MFIs, respectively. The advantage behind us-
ing both here is to speed up the ARM task w.r.t. other direct
approaches [Szathmary et al., 2012] due to a substantial re-
duction in the underlying search space. Algorithm 1 presents
the pseudo-code of VR-ARM. It takes as input a context C
(i.e. a m × n ×-table) plus the support and conﬁdence thresh-
olds. Its outputs are (i) Rules: the association rules extracted
from C; (ii) Attacks: the list of anomalous objects; and (iii)
Scores: the list of scores associated to objects in Attacks.
The algorithm starts by calling GetRareRules to generate
the rare rules through the MRIs. It implements the BtB (Break
the Barrier) method [Szathmary et al., 2012]. Next, each
object from C is matched against the rare associations: an
object is said to satisfy a rare rule if the rule’s itemsets are
included in the object’s itemsets. A score is assigned based
on the set of matching outcomes, which represents the de-
gree of anomalousness of the matched object (the higher the
score, the more anomalous the object). VF-ARM follows the
same principles as VR-ARM so will be skipped here: main
differences include the parameter min supp and a call to the
MFI-based rule miner GetF reqRules. Moreover, an object
violates a frequent rule if its itemsets are included in the left-
hand side of the rule and not in its right-hand side. Objects
matching rare rules or violating frequent ones are deemed po-
tentially anomalous, hence put in Attacks. Their anomalous-
ness scores are computed as the average of a function combin-
ing the interestingness (e.g. lift) and length of the respective
rules, log2(1 − Interest(R[j])) ∗ Length(R[j]). High qual-
ity rules, with many items on both sides, would have large
scores.

At a ﬁnal stage, the list of the potential attack objects are
ranked w.r.t. their anomaly scores so that the top-ranked el-
ements could be subsequently checked by a security expert.

5 Results and Discussion

5.1 Datasets

For our evaluation, we use two data collections described
in [Berrada et al., 2020], publicly available2. These collec-
tions (or scenarios) consist of sets of feature views or con-
texts from raw whole-system provenance graphs produced
during two DARPA Transparent Computing (TC) program
“engagements” (exercises aimed at evaluating provenance
recorders and techniques to detect APT activity from prove-
nance data). During the engagements, several days (5 for
scenario 1 and 8 for scenario 2) of system activity (pro-
cess, netﬂow, etc.) were recorded on various platforms (Win-
dows, BSD, Linux and Android) subjected to APT-like at-
tacks. [Han et al., 2020] explains engagements in more detail

2https://gitlab.com/adaptdata

Algorithm 1: VR-ARM: Rare Rule mining anomaly
detection.

inputs : A context C[m, n], max supp, min conf
outputs: Rules[0 : r]; // A list of association rules

Attacks[0 : a]a≤m; //A list of anomalous objects
Scores[0 : a]a≤m; // A list of attack scores

1 begin
2
3
4
5
6
7
8
9

Rules = GetRareRules(C,max supp, min conf );
foreach Object O[i]1≤i≤m in C do

Score[i] = 0.0;
IsAttack = F alse;
foreach Rule R[j] in Rules do
if O[i] satisﬁes R[j] then

IsAttack = T rue;
Score[i] = Score[i] + |log2(1 −

Interest(R[j])) ∗ Length(R[j])|

end

end
if IsAttack==True then

Append(Attacks, Oi);
Append(Scores, Score[i]);

end

end
Rank(Attacks using Scores);
return (Rules, Attacks, Scores);

10
11
12
13
14

15
16
17
18
19 end

and provides more information on provenance data for Sce-
nario 2 (referred to as Engagement 3). All contexts in the data
collections relate unique process identiﬁers (rows) to vary-
ing features/attributes of process activity: types of events per-
formed by process (P rocessEvent (PE)), name of process
executable (P rocessExec (PX)), name of parent process ex-
ecutable (P rocessP arent (PP)), IP addresses and ports ac-
cessed by process (P rocessN etf low (PN)), joining all the
previous features (renamed, if needed, to avoid ambiguity) to-
gether (P rocessAll (PA)). Table 2 summarizes the properties
of all contexts per collection/scenario. For a more detailed de-
scription, see [Berrada et al., 2020]. We might observe that
(a): The number of processes varies widely: Linux has 3 to
10-times more that Windows/BSD and up to 2400 times more
than Android. (b): The number of processes/attributes is un-
related to the original dataset size. Thus, albeit the largest,
the Android dataset has the fewest processes and attributes
(due to the provenance recorder mostly logging low-level app
activity and performing dynamic information ﬂow tracking,
which are pieces of information we do not analyze).

5.2 Evaluation Metrics

Rather than classifying processes as anomalous or not, our
method ranks them w.r.t. their degree of suspiciousness. Due
to the high data imbalance (attacks amount to 0.004% to 8.8%
of data), using classiﬁcation with accuracy would lead to the
accuracy paradox [Thomas and Balakrishnan, 2008].

Instead, a better suited metric would be normalized dis-
introduced in [Kalervo and
counted gain (nDCG), ﬁrst
Kek¨al¨ainen, 2002] as a means to assess ranking quality in
information retrieval. It is intended to reﬂect the value the
end user assigns to a ranked document, i.e. relevant docu-
ments are more valuable than marginally relevant ones and
even more so than irrelevant ones. Also, intuitively, since
a user will only scan a small portion of a ranking, relevant
documents close to its top have more value than comparably
relevant ones further down the list (those too far down would
be skipped). Consequently, nDCG favors rankings with all

relevant documents near the top. The same principle applies
to anomalous process: low ranked attack processes are all but
useless to analysts whose monitoring burden increases with
the amount of events to inspect (up to a point where suspi-
cious processes escape their attention). Also, a large number
of top-ranked normal processes (false alarms) may degrade
analyst conﬁdence in the automated monitoring system. The
discounted cumulative gain (DCG) of a ranking sums element
relevance scores penalized by the logarithm of their rank:

DCGN = (cid:80)N

log2(i+1) , where N is the ranking size,
reli the i-th element relevance score. As DCG scores are
not comparable for lists of varying size, a normalization
is performed with the ideal score iDCG, i.e. one corre-
sponding to the best case (all relevant entities at the top).
Thus, for a ranking with p relevant entities iDCGN =
(cid:80)p
log2(i+1) . nDCG is the normalized version of DCG:
. We use binary scale for relevance reli:

reli

reli

i=1

i=1

nDCGN = DCGN
iDCGN
1 for attack processes, 0 for normal ones.
5.3 Evaluation Results

APT Ranking Visualisation with Band Diagrams

To ease the inspection of generated rankings, we designed a
visualization technique, called band diagram charts (see ﬁg-
ure 1). Each ranked list is drawn as a horizontal band, where
the position of a true positive (APT) is marked by red lines.
Top ranked entities will be put on the left, thus multiple red
lines in that area reveal highly efﬁcient anomaly detection.

Figure 1: Band diagrams representing the positions of the attacks
(true positives) in some contexts of the BSD dataset (scenario 1).
The x-axis represents the attack positions in ranked lists.

Ranking Evaluation With nDCG

We compared VF-ARM and VR-ARM to existing tools
such as FPOutlier (FPOF) [He et al., 2005], Outlier-degree
(OD) [Narita and Kitagawa, 2008], CompreX [Akoglu et al.,
2013], AVF (Attribute Value Frequency) [Koufakou et al.,
2007] and OC3 (Krimp) [Vreeken et al., 2011]: We ran them
on the contexts from Table 2 and assessed the resulting rank-
ings by means of nDCG. To that end, we ﬁrst reimplemented
FPOF, AVF, OC3 and OD in Python following their original
descriptions3. We reused publicly-available implementations

3Code available at https://gitlab.com/anomalyDetection/baseline

Scenario

Size

P E

P X

P P

P N

P A

nb attacks

% nb attacks
nb processes

BSD

Windows

Linux

Android

1
2
1
2
1
2
1
2

288 MB
1.27 GB
743 MB
9.53 GB
2858 MB
25.9 GB
2688 MB
10.9 GB

76903 / 29
224624 / 31
17569 / 22
11151 / 30
247160 / 24
282087 / 25
102 / 21
12106 / 27

76698 / 107
224246 / 135
17552 / 215
11077 / 388
186726 / 154
271088 / 140
102 / 42
12106 / 44

76455 / 24
223780 / 37
14007 / 77
10922 / 84
173211 / 40
263730 / 45
0 / 0
24 / 11

31 / 136
42888 / 62
92 / 13963
329 / 125
3125 / 81
6589 / 6225
8 / 17
4550 / 213

76903 / 296
224624 / 265
17569 / 14431
11151 / 606
247160 / 299
282104 / 6435
102 / 80
12106 / 295

13
11
8
8
25
46
9
13

0.02
0.004
0.04
0.07
0.01
0.01
8.8
0.10

Table 2: Experimental dataset metrics. A context entry (columns 4 to 8) is number of rows (processes) / number of columns (attributes).

of OC3 [Koen and Vreeken, 2011] and CompreX [Akoglu et
al., 2013], in C++ and Matlab respectively. Finally, experi-
ments were run on an Intel Core i7-6700 CPU (3.4 GHz), 32
GB RAM PC with Ubuntu OS.

The global set of nDCG scores is split context-wise into ta-
bles 3, 4, 5, 6, and 7. An entry here corresponds to a combina-
tion (method, scenario, OS). Noteworthily, some algorithms
did not ﬁnish within a reasonable time (4 to 48 hours). Such
cases are indicated by DN F . For each OS (row) vs scenario
combination, the maximum nDCG score is marked in bold.
For visibility, high scores of our approach, VR-ARM or VF-
ARM, are colored: green for values in ]0.25,50], orange for
]0.50, 0.75] and red for top scores in ]0.75, 1].

on

competitive

VR-ARM and OC3 were

the
P rocessEvent context with considerably better scores
obtained with VR-ARM between 0.50 (Android, scenario 2)
and up to 0.87 (Android, scenario 1). FPOF and OD yielded
similar scores to each other. AVF and VF-ARM produced
good scores with scenario 1. Concerning P rocessExec
and P rocessP arent, AVF and OC3 generated moderately
acceptable scores with all four OS. The highest scores in
these contexts were obtained by OC3 (0.51 and 0.42) in
BSD w.r.t. scenario 2. VF-ARM got good ranking scores
for BSD (scenario 1) for both contexts, yet due to the low
conﬁdence values,
they were deemed irrelevant and non
competitive with the other methods on this task. Concerning
attacks in P rocessN etf low, VR-ARM reached good
results on both attack scenarios, with nDCG scores varying
between 0.30 (Windows, scenario 2) and 0.71 (Android,
scenario 2). Like-wise, top-ranked anomalous entities in
the super-context P rocessAll have been detected with
VR-ARM on both attack scenarios. AVF and OC3 have
also generated good scores with attack scenario 1. Note that
CompreX produced good results whenever it was able to
ﬁnish within a reasonable time (P rocessEvent, scenario 1);
for wider contexts such as P rocessExec or P rocessP arent
or P rocessAll, it usually did not terminate within a few
minutes (while [Akoglu et al., 2013] claims CompreX can be
run in anytime-mode, the available Matlab implementation
does not support it). Runtime-wise, FPOF, CompreX and OD
were signiﬁcantly more expensive than VR-ARM and AVF.

Table 8 summarizes attack detection and ranking for each
combination (OS, scenario): The winner method for each
OS is given with the best input context. Results comprise
the top nDCG scores, the running time and the Area Under
Curve (AUC). As per the ﬁgures, VR-ARM is likely to be the
method that has led to the best nDCG scores with interesting
AUC values on the four OS w.r.t. both scenarios (see also

Figure 2). Its time efﬁciency is arguably due to MRI-based
associations being only a tiny fraction of all the rules.

Intuitively, the results seem to conﬁrm that most of the at-
tacks can be detected by tracking their uncommon (rare) be-
havior in the provenance data. Indeed, in our experiments,
we ran VR-ARM with max supp values ranging between 0.05
and 30 %. More interestingly, the rare rules found have con-
ﬁdence of 100%. Note that we kept the best conﬁguration for
every method that needs parameter tuning. Here again, VR-
ARM stood out as very competitive even when compared to
the best conﬁgurations of its competitors.

Note that our tool provides an explainable output, e.g.
when tracing back a process with anomalousness score of
79.0 (highest), one of the rules it satisﬁed comprised rare
itemsets of Events (OPEN, READ, CHANGEPRINCIPAL,
SENDMSG), of Network activities (216.66.26.25:1025’,
’216.66.26.25:0’, ’128.55.12.10:53’), and of File activities
(’/etc/host.conf’,’/lib/x86 64 linux gnu/libnss dns.so’). Af-
ter interpretation, the rule expressed the fact that matching
processes alter the library ﬁles and try to communicate with
the listed ip addresses and subsequently send or receive data.

6 Conclusion

We proposed a novel OS-agnostic APT detection method
which detects anomalous entities using an association rule-
based scoring and ranking, and dedicated techniques visual-
izing potential anomalies within the rankings. It was evalu-
ated on large datasets containing realistic APT on a variety
of OS. The rare rule version VR-ARM was shown to consis-
tently rank attack processes as highly anomalous entities. A
key advantage thereof is the easy interpretation of its results.
We are studying a stream version of the method to main-
tain MFI/MRI over a stream window (e.g. as in [Martin et
al., 2020]). We’ll next examine the integration of analysts’
feedback in the scoring loop as an active learning task.

Acknowledgements

Reported work was partially supported by DARPA under con-
tract FA8650-15-C-7557, by ERC grant Skye (grant 682315),
and by an ISCF Metrology Fellowship grant provided by the
UK Department for Business, Energy and Industrial Strategy.
We thank H. Mookherjee for reimplementing FPOF and OD.

References

[Abir et al., 2016] A. Abir, S. Kadry, et al. Data leakage de-
tection using system call provenance. In INCoS, 2016.

Detection method
Attack scenario

e Windows

c
r
u
o
S

BSD
Linux

Android

FPOF

OD

1

0.20

0.20
0.18

0.29

2

DNF

0.13
0.22

0.36

1

0.20

0.19
0.18

0.33

2

DNF

0.17
0.21

0.22

Comprex
2
1

0.60

0.54
0.30

0.82

DNF

DNF
DNF

DNF

OC3

AVF

1

0.30

0.43
0.38

0.74

2

0.23

0.24
0.38

0.32

1

0.60

0.51
0.27

0.84

2

0.21

0.19
0.29

0.30

VR-ARM (sup x conf)
2
1

VF-ARM (sup x conf)

1

2

0.82 (5x100)

0.19 (5x100)

0.33 (60x70)

0.13 (30x30)

0.64 (0.05x100)
0.13 (0.05x100)

0.87 (30x100)

0.12 (5x100)
0.14 (5x100)

0.50 (5x100)

0.33 (40x97)
0.22 (20x97)

0.12 (40x40)
0.10 (40x40)

0.77 (5x70)

0.12 (5x70)

Table 3: Evaluation of anomaly scoring: ProcessEvent (PE)

Detection method
Attack scenario

c
r
u
o
S

e Windows
BSD
Linux
Android

FPOF

OD

1

0.15

0.15
0.18
0.22

2

DNF

0.18
0.20
0.29

1

0.15

0.15
0.18
0.22

2

DNF

0.17
0.20
0.29

Comprex
2
1

DNF

DNF
DNF
0.22

DNF

DNF
DNF
DNF

OC3

AVF

1

0.28

0.49
0.30
0.39

2

0.24

0.51

0.42
0.39

1

0.28

0.34
0.43
0.39

2

0.22

0.17
0.42
0.38

VR-ARM (sup x conf)
2
1

0

0

VF-ARM (sup x conf)
1

0

2

0

0.08 (0.05x100)
0.12 (0.05x100)
0

0.05 (0.05x100)
0
0

0.53 (0.001x10)
0.10 (0.001x0.1)
0

0.06 (1x40)
0.004 (0.001x0.1)
0

Table 4: Evaluation of anomaly scoring: ProcessExec (PX)

Detection method
Attack scenario

e Windows
c
r
u
o
S

BSD
Linux

FPOF

OD

1

0.10

0.13
0.17

2

DNF

0.10
0.20

1

0.10

0.13
0.17

2

DNF

0.09
0.20

Comprex
2
1

DNF

DNF
DNF

DNF

DNF
DNF

OC3

AVF

1

0.21

0.43
0.24

2

0.22

0.29
0.42

1

0.21

0.30
0.20

2

0.22

0.17
0.25

VR-ARM (sup x conf)
2
1

0

0

VF-ARM (sup x conf)
1

0

2

0

0.29 (0.05x100)
0

0.24 (0.05x100)
0

0.67 (0.001x10)
0.12 (0.001x1)

0.06 (0.001x10)
0.03 (10x40)

Table 5: Evaluation of anomaly scoring: ProcessParent (PP)
OD

OC3

AVF

Detection method
Attack scenario

e Windows

c
r
u
o
S

BSD

Linux

Android

FPOF

1

0.36

0.13

0.23

0.42

2

DNF

0.20

0.31

0.36

1

0.36

0.14

0.23

0.36

2

DNF

0.20

0.23

0.34

Comprex
2
1

DNF

DNF

DNF

DNF

DNF

DNF

DNF

DNF

1

0.65

0.11

0.38

0.64

2

0.24

0.50

0.35

0.30

1

0.58

0.58

0.31

0.47

2

0.18

0.18

0.42

0.32

VR-ARM (sup x conf)
2
1

0.62 (10x100)

0.30 (5x100)

VF-ARM (sup x conf)

1

0

2

0

0.34 (10x100)

0.60 (5x100)

0.11 (5x60)

0.18 (5x60)

0.58 (20x100)

0.39 (5x100)

0.42 (5x50)

0.11 (10x40)

0.46 (50x100)

0.71 (30x100)

0

0.10 (20x50)

Table 6: Evaluation of anomaly scoring: ProcessNetﬂow (PN)
OD

OC3

AVF

Detection method
Attack scenario

e Windows

c
r
u
o
S

BSD

Linux

Android

FPOF

1

DNF

0.21

0.18

0.31

2

DNF

0.15

DNF

0.37

1

DNF

0.19

0.18

0.34

2

DNF

0.15

DNF

0.20

Comprex
2
1

DNF

DNF

DNF

DNF

DNF

DNF

DNF

DNF

1

0.49

0.38

0.41

0.82

2

DNF

DNF

DNF

0.40

1

0.52

0.52

0.29

0.83

2

DNF

DNF

DNF

0.35

VR-ARM (sup x conf)
2
1

VF-ARM (sup x conf)

1

2

0.61 (5x100)

0.35 (5x100)

0.50 (80x70)

0.07 (40x40)

0.36 (0.05x100)

0.52 (5x100)

0.18 (97x97)

0.14 (40x40)

0.54 (0.05x100)

0.45 (5x100)

0.13 (40x70)

0.09 (40x40)

0

0.51 (0.05x100)

0

0.43 (40x40)

Table 7: Evaluation of anomaly scoring: ProcessAll (PA)

Winner AD method

Winner context

Running time (sec.)

nDCG

AUC

Source

Attack scenario
Windows
BSD
Linux
Android

2

1

1
ProcessEvent
VR-ARM VR-ARM
VR-ARM VR-ARM
ProcessEvent
VR-ARM VR-ARM ProcessNetﬂow
ProcessEvent
VR-ARM VR-ARM

2
ProcessAll
ProcessNetﬂow
ProcessAll
ProcessNetﬂow

1
4.60
12.18
3.53
0.78

2
23.86
12.30
2.74
3.35

1
0.82
0.64
0.58
0.87

2
0.35
0.60
0.45
0.71

1
0.75
0.75
0.83
0.92

2
0.50
0.50
0.50
0.50

Table 8: Highest AUC and nDCG scores of the rule-mining anomaly detection (AD) methods for each database.

Figure 2: ROC curves of the best anomaly scores obtained with the winner contexts (cf Table 8). Top: scenario 1, bottom: scenario 2. Left to
right: Windows, BSD, Linux, Android (the ROC curves use different scales in both axes due to space limits).

Imieli´nski,

[Agrawal et al., 1993] R. Agrawal, T.

and
A. Swami. Mining association rules between sets of items
in large databases. SIGMOD Rec., 22(2):207–216, 1993.
[Akoglu et al., 2013] L. Akoglu, H. Tong, et al. CompreX:
Fast and reliable anomaly detection in categorical data. In
CIKM, pages 415–424, 2013.

[Akoglu et al., 2015] L. Akoglu, H. Tong, et al. Graph based
anomaly detection and description: a survey. DMKD,
29(3):626–688, 2015.

[Auty, 2015] M. Auty. Anatomy of an advanced persistent

threat. Network Security, 15(4):13–16, 2015.

[Berrada et al., 2020] G. Berrada, J. Cheney, et al. A base-
line for unsupervised advanced persistent threat detection
in system-level provenance. FGCS, 108:401–413, 2020.
[Bertens et al., 2017] R. Bertens, J. Vreeken, et al. Efﬁ-
ciently discovering unexpected pattern-co-occurrences. In
SDM, pages 126–134, 2017.

[Brian and Beaver, 2011] J. Brian and M. Beaver. Host-
based data exﬁltration detection via system call sequences.
In ICIW, pages 134–142, 2011.

[Chandola et al., 2009] V. Chandola, A. Banerjee, et al.
Anomaly detection: A survey. ACM computing surveys
(CSUR), 41(3):15:1–15:58, July 2009.

[Gr¨unwald, 2007] P. Gr¨unwald. The Minimum description

length principle. MIT Press, 2007.

[Han et al., 2018] X. Han, T. Pasquier, et al. Provenance-
based intrusion detection: Opportunities and challenges.
In TaPP, 2018.

[Han et al., 2020] X. Han, T. Pasquier, et al. Unicorn: Run-
time provenance-based detector for advanced persistent
threats. In NDSS, 2020.

[Hassan et al., 2018] W. Hassan, M. Lemay, et al. Towards
scalable cluster auditing through grammatical inference
over provenance graphs. In NDSS, 2018.

[He et al., 2005] Z. He, X. Xu, et al. FP-outlier: Frequent
pattern based outlier detection. CSIS, 2(1):103–118, 2005.

[Hossain et al., 2017] N. Hossain, S. Milajerdi,

et al.
SLEUTH: real-time attack scenario reconstruction from
COTS audit data. In USENIX, pages 487–504, 2017.
[Huang and Majidi, 2018] B. Huang and M. Majidi. Case
study of power system cyber attack using cascading outage
analysis model. In 2018 IEEE PESGM, pages 1–5, 2018.
[Jenkinson et al., 2017] G. Jenkinson, L. Carata, et al. Ap-
plying provenance in APT monitoring and analysis: Prac-
tical challenges for scalable, efﬁcient and trustworthy dis-
tributed provenance. In TaPP, pages 16–21, 2017.

[Ji et al., 2016] S.Y. Ji, B.K. Jeong, et al. A multi-level in-
trusion detection method for abnormal network behaviors.
NCA, 62:9–17, 2016.

[Kalervo and Kek¨al¨ainen, 2002] J.

J. Kek¨al¨ainen.
IR techniques. TOIS, 20(4), 2002.

and
Cumulated gain-based evaluation of

Kalervo

[Koen and Vreeken, 2011] S. Koen and J. Vreeken. The odd
In

Identifying and characterising anomalies.

one out:
SDM, 2011.

[Koufakou and Georgiopoulos, 2010] A. Koufakou

and
M. Georgiopoulos. A fast outlier detection strategy
for distributed high-dimensional data sets with mixed
attributes. DMKD, 20(2):259–289, 2010.

[Koufakou et al., 2007] A. Koufakou, E. Ortiz, et al. A scal-
able and efﬁcient outlier detection strategy for categorical
data. In 19th IEEE ICTAI, pages 210–217, 2007.

[Kumar and Spafford, 1994] S. Kumar and E. Spafford. A
pattern matching model for misuse intrusion detection. In
NCSC, page 11, 1994.

[Manzoor et al., 2016] E. Manzoor, S. Milajerdi, et al. Fast
memory-efﬁcient anomaly detection in streaming hetero-
geneous graphs. In SIGKDD, pages 1035–1044, 2016.
[Martin et al., 2020] T. Martin, G. Francoeur, et al. CI-
CLAD: A fast and memory-efﬁcient closed itemset miner
for streams. In ACM SIGKDD, pages 1810–1818, 2020.
[Mohiuddin et al., 2016] A. Mohiuddin, A. Mahmood, et al.
A survey of network anomaly detection techniques. JNCA,
60:19–31, 2016.

[Narita and Kitagawa, 2008] K. Narita and H. Kitagawa.
Outlier detection for transaction databases using associa-
tion rules. In WAIM, pages 373–380, 2008.

[Park et al., 2012] J. Park, D. Nguyen, et al. A provenance-
based access control model. In PST, pages 137–144, 2012.
[Ping and Johnson, 2018] W. Ping and W. Johnson. Cyberse-
curity incident handling: A case study of the equifax data
breach. Issues in Information Systems, 19(3), 2018.

[Sebenius, 2021] A. Sebenius. SolarWinds hack followed
years of warnings of weak c-security. Bloomberg, 2021.
[Szathmary et al., 2007] L. Szathmary, P. Valtchev, et al. To-
ward rare itemset mining. In ICTAI, pages 305–312, 2007.
[Szathmary et al., 2012] L. Szathmary, P. Valtchev, et al. Ef-
ﬁcient vertical mining of minimal rare itemsets. In CLA,
pages 269–280, 2012.

[Thomas and Balakrishnan, 2008] C. Thomas and N. Bal-
akrishnan. Improvement in minority attack detection with
skewness in network trafﬁc. In Data Mining, Intrusion De-
tection, Inform. Assurance, and Data Networks Security,
page 69730N, 2008.

[Vreeken et al., 2011] J. Vreeken, M. van Leeuwen, et al.
DMKD,

KRIMP: Mining itemsets that compress.
23(1):169–214, 2011.

[Yamanishi et al., 2004] K. Yamanishi, J.I. Takeuchi, et al.
On-line unsupervised outlier detection using ﬁnite mix-
DMKD,
tures with discounting learning algorithms.
8(3):275–300, 2004.

[Zhang et al., 2012] O. Zhang, R. Ko, et al. How to track
your data: Rule-based data provenance tracing algorithms.
In TrustCom, pages 1429–1437. IEEE, 2012.

