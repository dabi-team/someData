2
2
0
2

l
u
J

6
1

]
T
I
.
s
c
[

1
v
3
0
9
7
0
.
7
0
2
2
:
v
i
X
r
a

UNSUPERVISED ENSEMBLE BASED DEEP LEARNING
APPROACH FOR ATTACK DETECTION IN IOT NETWORK

Mir Shahnawaz Ahmed, Shahid M Shah
Communication Control Learning Lab,
Department of Electronics & Communication Engineering,
National Institute of Technology Srinagar
{mirshahnawaz888@gmail.com, shahidshah@nitsri.net}

ABSTRACT

The Internet of Things (IoT) has altered living by controlling devices/things over the Internet. IoT has
speciﬁed many smart solutions for daily problems, transforming cyber-physical systems (CPS) and
other classical ﬁelds into smart regions. Most of the edge devices that make up the Internet of Things
have very minimal processing power. To bring down the IoT network, attackers can utilise these
devices to conduct a variety of network attacks. In addition, as more and more IoT devices are added,
the potential for new and unknown threats grows exponentially. For this reason, an intelligent security
framework for IoT networks must be developed that can identify such threats. In this paper, we have
developed an unsupervised ensemble learning model that is able to detect new or unknown attacks in
an IoT network from an unlabelled dataset. The system-generated labelled dataset is used to train
a deep learning model to detect IoT network attacks. Additionally, the research presents a feature
selection mechanism for identifying the most relevant aspects in the dataset for detecting attacks.
The study shows that the suggested model is able to identify the unlabelled IoT network datasets and
DBN (Deep Belief Network) outperform the other models with a detection accuracy of 97.5% and a
false alarm rate of 2.3% when trained using labelled dataset supplied by the proposed approach.

Keywords IoT, malicious attacks, feature selection, unsupervised ensemble learning, deep learning

1

Introduction

The Internet of Things (IoT) expands the Internet’s edge by integrating new terminal devices and resources at the
network’s edge. It is one of the fastest-growing and most extensively utilised technologies on the internet. IoT constitutes
integration of millions of devices that can communicate with one another to solve a wide range of real-world challenges
by providing innovative and cost-effective solutions. Smart metering, smart transportation systems, smart homes, smart
medical care, smart agriculture etc. are growing as a result of IoT technology [1]. Apart from these applications, IoT
devices are widely used for the purpose of surveillance [2].

The sensors used in IoT networks/CPS continuously monitor their surroundings, thereby generating huge volumes of
data. These massive volumes of data are saved in data-centers, some of which may contain sensitive information about
systems/individuals, thus making IoT networks/CPS vulnerable to various cyber attacks. More apparent and unseen
attacks are developing like Denial of Service (DoS), Remote to Local (R2L), Brute Force, Probing (Probe), User to Root
(U2R), Man-in-the-middle, Scanning, Ransomware, Password attack, etc., wreaking havoc and creating irreversible
damage [3]. Also, the use of large numbers of heterogeneous IoT devices in a network increases the attack surface.
Attackers generally target the data-centers because they have large volumes of diverse information. In addition, IoT
network devices have limited storage and computational capabilities which prohibit them from detecting and ﬁghting
against possible online cyber threats. Also, due to the increase in the attack surfaces for IoT networks, the detection of
new/unknown attacks increases the challenge of attack detection [4]. IoT networks might be severely harmed by even a
moderate security attack, thereby hindering the applicability of IoT networks in different ﬁelds. IoT networks generate
enormous volumes of network trafﬁc and have more number of edge devices of varying types than the traditional
computer networks, making IoT network security concerns more complicated and difﬁcult. Thus, it is evident that a

 
 
 
 
 
 
Running Title for Header

Acronyms
IoT

Description
Internet of Things

Table 1: List of Acronyms

Acronyms
RPL

CPS
DDoS
Probe
LSTM
DBN
IDS
OPTICS

AMI
MCC
RBM
PR

DoS
Cyber-Physical Systems
Distributed Denial of Service attack R2L
U2R
Probing attack
MLP
Long Short Term Memory
PCA
Deep Belief Networks
CNN
Intrusion Detection System
ARI
Ordering Points to Identify the Clus-
tering Structure
Adjusted Mutual Information
Matthews Correlation Coefﬁcient
Restricted Boltzmann Machine
Precision-Recall

FAR
SGD
ROC
DODAG

Description
Routing Protocol for Low-Power
and Lossy Networks
Denial of Service attack
Remote to Local attack
User to Root attack
Multilayer Perceptron
Principal Component Analysis
Convolution Neural Network
Adjusted Rand Index

False Alarm Rate
Stochastic Gradient Descent
Receiver Operating Characteristic
Destination Oriented Directed
Acyclic Graph

smart and intelligent attack detection mechanism has to be developed which is able to detect even new/unknown attacks
in IoT networks. The characteristics of machine learning techniques and their recent advancements make them suitable
for the purpose of attack detection in IoT networks. The list of acronyms used in the paper are described in table 1.

The contributions of this paper are summarized as:

• We propose an amalgamation of correlation coefﬁcient and LASSO regression for the purpose of feature
selection to detect attacks in an IoT network. The amalgamation is done after a thorough analysis of the
performance metrics and identiﬁcation of critical parameters for correlation based and LASSO regression
based feature selection techniques separately. The fusion of both the techniques is done in such a way that the
overall performance of the system is increased by selecting most relevant features from the available network
datasets.

• To identify new/unknown attacks, the model should be able to identify hidden patterns in the network dataset
and cluster the network trafﬁc into malicious and non-malicious. To achieve this, we have used a group of
clustering algorithms. The output of each clustering algorithm, for a particular IoT network trafﬁc, is combined
using a weighted voting technique to predict the class label (malicious/non-malicious) with increased accuracy.
The weights associated with the output of each clustering technique have been calculated after a detailed
performance analysis. The combination of clustering techniques with the weighted voting gives rise to an
ensemble machine learning approach which converts an unlabelled dataset (representing IoT network trafﬁc
with malicious attacks) into labelled dataset, thereby proposing an unsupervised mechanism which is able to
identify new/unknown attacks in the IoT network trafﬁc.

• The labelled dataset generated by the proposed model is utilized to train a deep learning model for attack
detection in an IoT network. To identify which deep learning model is best suited for the purpose, a performance
analysis of different deep learning models (LSTM, MLP and DBN) has been done, and an efﬁcient one is
proposed to be deployed for detecting attacks in an IoT network.

The rest of the paper is organised as: Section 2 describes the recent literature in the direction of attack detection in IoT
networks. Section 3 gives the detailed view of the proposed unsupervised ensemble learning model. The implementation
of the proposed model along with the deep learning models used are discussed in section 4. Finally, section 5 concludes
the paper and presents future directions.

2 Related Work

With the advancement in the ﬁeld of IoT, many researchers have proposed various techniques for detecting malicious
behaviour in IoT and hence creating a secure environment for implementing IoT network.

Xiao et al. in [5] discuss various security mechanisms which use machine learning algorithms to achieve the security
requirements of an IoT network, but most of them require the accurate knowledge of network and attack state, which
is difﬁcult in IoT networks. Furthermore various machine learning based security solutions have high computational
complexities and require huge training data. Lianbing et al. [6] explains various types of Artiﬁcial Intelligence based

2

Running Title for Header

Intrusion Detection techniques to detect malicious behaviours in IoT network and, ﬁnally proposed cloud architecture
based intrusion detection system, which uses a combination of Fuzzy C-Means algorithm and Principal Component
Analysis (PCA) approach. The proposed system has used PCA for dimensionality reduction of used dataset, in order
to decrease the attack detection time, and Fuzzy C-Means algorithm is used for clustering purposes. Shailendra et
al. [7] proposed a distributed attack detection framework for fog-based IoT which uses Semi-supervised learning
approach. They also have used the Fuzzy C-Means algorithm to enhance the efﬁciency of the clustering mechanism and
used Extreme Learning Machine (a feed-forward neural network with a single hidden layer). The performance of the
system has been tested on NSL KDD dataset with an attack detection accuracy of 86.53% and attack detection time of
11ms, but the attack detection accuracy of the system needs to be enhanced. Sahay et al. [8] proposes a Multilayer
Perceptron (MLP) based Misappropriation attack detection mechanism for IoT network. The authors describe the
Misappropriation attack as decreased rank attack, where an attacker decreases the rank of a malicious network path in
a DODAG, thereby deviating the trafﬁc to the network path containing attacker nodes.DODAG is used by RPL for
IoT network organization. The proposed approach has been implemented in Cooja simulator. It only detects one type
of network attack, and the attack detection accuracy needs to be increased. Also, Sahay et al. [9] also presented a
similar approach for detecting version number attack in RPL. Mirsky et al. [10] proposes an ANN based unsupervised
online IDS, which uses Autoencoders to reconstruct the network trafﬁc for anomaly detection. Even though the authors
claim that the proposed model is lightweight, but the resources requirement makes them computational infeasible for
IoT networks. Insider threats are one of the most difﬁcult cyber-security concerns today, and they aren’t effectively
addressed by most security solutions [11]. An insider threat is caused by a legitimate user to jeopardise a network’s data,
policies, or devices in an unwanted or disruptive manner. These attacks are more common in the IoT environment and
hard to detect, but intelligent machine learning techniques can be used to detect such attacks effectively [12]. A hybrid
intrusion detection mechanism was proposed by Ansam et al. in [13] which combines the advantages of signature
and anomaly based intrusion detection systems (IDS). The proposed mechanism ﬁrst creates a decision tree using C5
Decision Tree Classiﬁer to identify various known attacks based on predeﬁned attack signatures. The unknown attacks
are then detected using anomaly based IDS, which is trained using One-class Support Vector Machine. The combination
of these two techniques result in a hybrid system which is able to detect DDOS, DOS, Reconnaissance and Key-logging
attacks in BoT-IoT intrusion detection dataset. The proposed approach relies on predeﬁned attack signatures for the
purpose of training a machine learning model, thus making it an ineffective approach for detecting unknown attacks.
Venkatraman et al. in [14] have also proposed a hybrid of signature based and anomaly based intrusion detection
system, which uses Crowd-sourcing to gather various attack signatures and then use Automata based event processor
to automatically detect malicious behaviours. The proposed attack detection system has been tested for smaller IoT
networks. Bovenzi et al. [15] proposes a MultiModal Deep AutoEncoder for detecting attacks in Bot-IoT dataset. The
model has considerable performance but the use of AutoEncoders increase the complexity of the proposed model. A
blockchain based security framework has also been proposed by Sahay et al. [16], in which the vulnerabilities of RPL
are explored to propose a secure attack detection module for an IoT network using blockchain. The proposed system is
computationally complex because of blockchain and hence the complexity needs to be reduced. Another blockchain
based secure data sharing mechanism was proposed by veeramakali et al. [17], but here again the overall computational
complexity of the system has to be reduced. A Speciﬁcation based Intrusion Detection was proposed by Jagadeesh
Babu et al. [18], which relies on a supervised learning approach to discover various transaction speciﬁcations for
normal and abnormal behaviour. The discovered speciﬁcations are then further optimized using the proposed heuristics
approach, which results in a system capable of identifying normal and abnormal (malicious) behaviour depending
on the speciﬁcations of the network transactions performed by various IoT devices. Aaisha et al. have mentioned in
[19] that various devices in IoT networks prefer to search/access data using search engines available on the internet,
but this way of accessing the data faces Web Spam as its biggest hindrance. To overcome this challenge they have
proposed a deep learning based mechanism, which uses LSTM Network, that when incorporated in the search engine
detects spam while calculating the page rank score for a particular web-page. Eskandari et al. in [20] propose an
Intrusion Detection System, which identiﬁes new attacks (anomalies) by using one-class classiﬁcation i.e., it analysis
the characteristics of normal IoT network trafﬁc and then detects anomalies if the characteristics of network trafﬁc
deviate. It uses Isolation Forest for isolating the malicious from non-malicious data, and Local Outlier Factor method
for detecting the attacks. However, the false positive rate of the IDS is high. Also, the efﬁciency of the system has been
calculated on a real testbed and the system needs new training sessions each time the underlying network changes.
Verma et al. [21] discusses the performance analysis of various supervised machine learning classiﬁers (Random Forest,
Adaboost, Gradient Boosting, Extreme Gradient Boosting and Extremely Randomized Trees) for detecting DoS attack,
among which Extreme Gradient Boosting outperforms the other, and also uses Raspberry Pi to ﬁnd the response time
for each classiﬁer. The performance analysis is done using CIDDS-001, UNSW-NB15, and NSL-KDD datasets, by
using all the available features. It is not able to detect new/unknown attacks.
Sahu et al. in [22] presents a combination of Convolution Neural Network (CNN) and LSTM Model for attack detection
in IoT. The proposed model uses CNN for the purposes of feature selection and trains a LSTM model with the selected
features to detect attacks in the IoT network. Although the model achieves 92% accuracy, it is computationally complex

3

Running Title for Header

and requires more energy resources. Also the model is tested on real testbed with a smaller size of IoT network. Also,
Fotohi et al. in [23] proposes a lightweight clustering mechanism for detecting ﬂooding attacks in IoT environment
using ant colony optimization algorithm. The model efﬁcacy has been tested using the NS-3 network simulator.

4

Running Title for Header

Table 2: Comparison of some of the related work with the proposed model

References Description

Ambusaidi
et
al.
[24]

Shone et
al. [25]

The paper proposes a mutual in-
formation based feature selection
mechanism and uses Least Square
SVM to detect network attacks.
It uses stacked encoder phase of a
deep auto-encoder, together with a
random forest classiﬁer to create a
network intrusion detection system.

Dataset
Used

No. of fea-
tures used

NSL-KDD

18

NSL-KDD

All

Meidan
et
[26]

al.

Shailendra
et al. [7]

Ansam et
al.
in
[13]

The paper proposes a deep auto-
encoder based detection system for
IoT networks. It uses normal net-
work trafﬁc to train the model, and
an anomaly is detected if the auto-
encoder fails to reconstruct the data.
The paper proposes a combination
of Fuzzy C-means algorithm with
Extreme Learning Machine to de-
tect attacks.
It proposes a hybrid IDS, which
uses C5 decision tree to detect
known attacks and One-class SVM
to detect anomalies.

NA

NA (model
on
tested
real
IoT
network)

NSL-KDD

All

Bot-IoT

All

Limitations

Learning
Approach
used
Supervised The mechanism only detects
known attacks, and is unable to
detect new/unknown network at-
tacks.
It uses all the features available in
the dataset and has an attack de-
tection rate of 85.42% and false
alarm rate of 14.58%, and is not
able to detect new/unknown at-
tacks.

Supervised

Supervised The proposed model was trained
to detect botnet attacks only,
and it
is unable to detect
new/unknown attacks.

Semi-
supervised

Semi-
supervised

Even-though the model is able to
detect new/unknown attacks, but
the model has attack detection ac-
curacy of 86.53% only.
The proposed approach relies on
predeﬁned attack signatures for
the purpose of training a machine
learning model, thus making it an
ineffective approach for detecting
unknown attacks.

Jan et al.
[27]

It evaluates SVM with different ker-
nel functions to detect network at-
tacks using variation in the trafﬁc
intensity.

Zhou et
al. [28]

Srinivas
and
Patnaik
[29]

Sahay et
al. [30]

The paper proposes an ensemble ap-
proach that uses voting mechanism
to combine the results of C4.5, Ran-
dom Forest, and Forest by Penaliz-
ing Attributes techniques, to create
an ensemble mechanism for detect-
ing attacks. It also uses Bat algo-
rithms with correlation based fea-
ture selection technique to retrieve
relevant features from the dataset.
They have used a metaheuristic
quantum worm swarm optimization-
based clustering technique to pro-
pose a secure routing protocol for
mobile ad hoc networks, by select-
ing an optimal cluster head and se-
cure routing path.
The paper proposes a holistic ap-
proach that uses smart contract-
fortiﬁed blockchain technology to-
gether with LSTM and CNN to de-
tect routing attacks in an IoT net-
work

NA

Supervised The proposed model

is only
tested to detect
those attacks
which vary in network trafﬁc in-
tensities.

10, 8, 13
(resp.)

Supervised Unable to detect new/unknown
attacks, and is computationally
complex.

All

Unsupervised It only detects routing attacks in

mobile ad hoc networks.

Dataset
generated
from CI-
CIDS2017
using
Poisson
dist.
NSL-KDD,
AWID,
and
CIDS2017

CI-

hoc

Mobile
ad
network
created in
MATLAB

All

IoT trafﬁc
from Cooja
simulator

Unsupervised It only detects known routing at-
tacks in an IoT network using net-
work speciﬁcations.

Proposed
Work

The paper proposes an unsupervised ensemble approach for clustering network trafﬁc into malicious and non-malicious
(thereby identifying new/unknown attacks) and uses system identiﬁed network trafﬁc to train deep learning model to
detect attacks in an IoT network. The proposed mechanism was tested on NSL-KDD and TON-IoT network datasets
and has overall attack detection accuracy of 97.6% and false alarm rate of 2.3%. The paper also proposes feature
selection mechanism (which selects 11 and 9 relevant features from respective datasets).

5

Running Title for Header

Most of the above cited papers mainly use supervised machine learning approaches, which are efﬁcient in detecting
known attacks in an IoT network, but they rely on labelled datasets and are ineffective in detecting new/unknown
attacks. Also, due to the increasing use of the IoT network, various new and heterogeneous devices get added in the
network, which can be used by an attacker to launch new attacks. Thus, it is necessary to propose an intelligent attack
detection system for IoT networks which uses an unsupervised machine learning approach to detect new/unknown
attacks in an IoT network. Also, the performance of such systems can be improved by combining ensemble machine
learning approaches with deep learning models. The comparison of some of the related work with the proposed model
is shown in table 2.

3 Proposed Method

In this section we introduce the proposed model for the detection of attacks in an IoT network. The proposed model is
shown in ﬁgure 1, which takes an unlabelled IoT network dataset (containing IoT network trafﬁc: malicious as well as
non-malicious) as input. The input unlabelled dataset is ﬁrst pre-processed for any missing/redundant data. After data
pre-processing, the value of each feature is being scaled using a standard scaler. The pre-processed and scaled dataset
is then given to the proposed feature selection module to select relevant features for detecting network attacks. After
feature selection, each data entry of the dataset (for selected features) is given to three clustering mechanisms (Mini
batch K-means, Fuzzy C-means and OPTICS) simultaneously which cluster the data into malicious (represented by 1)
or non-malicious (represented by 0). The output of each clustering algorithm is combined using a weighted voting,
thereby predicting the most appropriate/accurate class label for the data entry. The combination of clustering algorithms
and voting mechanism formulates the proposed ensemble learning model. So, after processing the entire unlabelled
dataset by the ensemble learning model, a labelled dataset is generated. This process of converting the unlabelled IoT
network dataset into a labelled dataset sufﬁces that any new/unknown IoT network attacks can be also detected by the
system. Due to the limited availability of computational resources in IoT devices, the proposed ensemble learning
model can be deployed at a cloud layer and the labelled dataset generated by the system can be used to train a deep
learning model for detecting new/unknown attacks in an IoT network. Hence at step-7 in ﬁgure 1 we propose to use a
deep learning model, which is to be trained using the system generated labelled network dataset. Finally, the trained
deep learning model can be deployed in any IoT device at fog or edge layer of fog computing architecture. The deep
learning model can be then updated timely at cloud layer using the proposed ensemble learning model for detecting
new/unknown attacks that may be encountered in future.

Figure 1: Proposed Model

3.1 Feature Selection

The performance of any machine learning algorithm depends on the selection of appropriate features from the given
dataset. Selecting relevant features from a dataset helps to overcome overﬁtting or under-ﬁtting of machine learning
models. In the proposed model, we have used a combination of Correlation-based feature selection with LASSO
regression to identify relevant features. In Correlation-based feature selection we select those features which are highly

6

 TestingDataUnlabelledDataPre-processingFeature ScalingFeature SelectionMini Batch K-MeansClusteringFuzzy C-MeansClusteringOPTICSClusteringWeighted VotingTraining aNeural NetworkClassifierPredictedClass LabelTesting ofNeural NetworkClassifierClassLabelTrainedModelModel Accuracy123456789PredictedClass Label10Ensemble Learning ModelRunning Title for Header

correlated with the class label. We have used Pearson’s correlation coefﬁcient [31] to ﬁnd the correlation between
feature vectors and the class label. The Pearson’s correlation coefﬁcient for each feature vector i with the class label (L)
is calculated using:

cof (i) =

cov(Xi, L)
(cid:112)(var(Xi) ∗ var(L))

(1)

where Xi is the value of ith feature vector, L is the class labels, cov() and var() are the covariance and the variance
respectively. For selecting the relevant features, we calculate the absolute value of cof (i) for each feature vector, and
then select those features which have cof (i) greater than threshold (δ). In our study, after various iteration of proposed
model for varying values of δ, we got the optimal value of δ = 0.4. The nomenclature for the symbols used in the paper
are shown in table 3.

In LASSO (Least Absolute Shrinkage and Selection Operator) regression some model coefﬁcients are narrowed, while
others are set to zero [32]. It is this feature which makes it possible to select relevant features from a dataset. So, if
xi = (xi1, xi2, . . . , xip)T represents the features selected from correlation method and yi represent the corresponding
class label, then the LASSO regression coefﬁcients are calculated as:

ˆβ(i) =






N
(cid:88)

i=1



yi −

(cid:88)

j

2



βjxij




 + α

(cid:88)

|βj|

j

(2)

where α is the constant that determines how much regularisation is applied. For large values of α, the penalty term
(cid:80)
j |βj| has the effect of forcing some of the coefﬁcients to absolutely zero, thus assisting in relevant variable selection.
The optimal value of α was calculated using 10-fold cross validation with varying value of α from 0.1 to 8 with step-size
of 0.01. The complete feature selection mechanism is described in algorithm 1.

calculate cof (i) using equation 1
if abs(cof (i)) > δ then
insert Vi in SF1

Algorithm 1 Feature Selection Mechanism
1: Input: D(F1, F2, . . . , FN , L)
2: Begin
3: Create empty lists SF1 and SF2
4: for each feature-vector Vi in D do
5:
6:
7:
8:
9: end for
10: for each feature-vector Vi in D do
11:
12:
13:
14:
15: end for
16: return (SF1 ∪ SF2)

ﬁnd ˆβ(i) using equation 2
if ˆβ(i) (cid:54)= 0 then

insert Vi in SF2

end if

end if

Proposition 1. Time complexity of algorithm 1 is O(n), where n is the number of observations in each feature of the
dataset.

Proof. Step-3 of the algorithm takes O(1) time.

Step-4 to step-9 computes the Pearson’s correlation coefﬁcient for each pair of feature vector Vi (with n number of
observations) and class label L. If V is the number of features in a given dataset, then the total computations performed
in Step-4 to step-9 are (n ∗ V ).

Step-10 to step-15 computes the LASSO regression coefﬁcient for each feature vector Vi. Number of computations
performed in Step-10 to step-15 are (n ∗ V 2) [32].
Finally, step-16 calculates union of two sets which takes O(V (cid:48) + V (cid:48)(cid:48)), where V (cid:48) is the number of features in set SF1
and V (cid:48)(cid:48) is the number of features in set SF2.

7

Running Title for Header

So, the overall time complexity of the algorithm is:
O(1 + (n ∗ V ) + (n ∗ V 2) + V (cid:48) + V (cid:48)(cid:48)) = O(n ∗ V 2)

Since, the number of features in a dataset are limited and small, hence V can be neglected. So, the overall time
complexity of algorithm 1 is: O(n).

3.2 Unsupervised Ensemble Learning Model with deep learning

Ensemble learning is based on the principle that the combination of outputs from various learning models can produce
more accurate results. The ensemble learning model can be implemented in two ways to produce multiple predicted
results: Independent ensemble construction and Coordinated ensemble construction [33]. In independent ensemble
construction approach, a learning algorithm can be executed independently multiple times on various training data-
subsets or different learning models can be executed independently on same dataset, to produce multiple results which
can then be combined using ensemble technique. Whereas, in coordinated ensemble construction the output of one
learning algorithm can be used as an input to another learning algorithm, thus making all the base learning algorithms
dependent on each other.

In the proposed model, we have used an independent ensemble construction approach and used weighted voting for
combining the output from different base learning models. The main purpose of the proposed ensemble learning
model is to predict a class label for each data vector in the given unlabelled dataset. It is because of this we have used
clustering techniques for predicting the class labels for data vectors. In the proposed model, we have used Mini Batch
K-Means [34], Fuzzy C-Means [35] and OPTICS (Ordering Points to Identify the Clustering Structure) clustering
[36] as the base learning models. The predicted output of each clustering technique will be either 0 or 1, where 0
represents non-malicious trafﬁc (cluster-1) and 1 represents malicious trafﬁc (cluster-2). The predicted output from each
clustering algorithm, for each data entry, is combined using weighted voting using equation 3 to create two clusters –
one containing benign data and another containing malicious data.

An independent ensemble construction approach has been used because it helps to enhance the overall accuracy, reduce
variance and produces a more stable prediction for the data by combining the results of different clustering algorithm
used through weighted voting technique [37].

Where, Wi represent the weights associated with the prediction Pi from each base clustering technique. Then the ﬁnal
predicted class label ˆV is calculated as:

3
(cid:88)

(Pi ∗ Wi)

V =

i=1

(3)

ˆV =

(cid:26) 1
0

if V > 0.5
otherwise

(4)

After thorough performance analysis of the clustering technique used in our proposed model, the weights associated
with the predicted value from Mini Batch K-Means and OPTICS clustering were set to 0.25 each and for Fuzzy C-Means
it was set to 0.5. The entire process of converting an unlabelled dataset into a labelled dataset using the ensemble
learning model is shown in algorithm 2.
Proposition 2. Time complexity of algorithm 2 is O(n2), where n is the number of observations in the dataset.

Proof. For each step-5 and step-6, it takes O(1) time for execution.

Step-7 to step-18 computes P1, P2, P3 for each data entry of the dataset with VF S number of features (selected by
algorithm 1), n number of observations in the dataset and i number of iterations.

So, to compute P1, it takes O(n ∗ i ∗ k ∗ VF S) [34], where k is the number of clusters. Since, k = 2 and VF S is small,
so we can neglect them while calculating complexity. Hence, the time complexity of computing P1 for entire dataset
will be O(n ∗ i).
Also, to compute P2, it takes O(n2) [36], and
To compute P3, it takes O(n ∗ i ∗ VF S ∗ c2) [35], where c is the number of clusters. Here again, c = 2 and VF S is small,
so we can neglect them while calculating complexity. Hence, the time complexity of computing P3 for entire dataset
will be O(n ∗ i).

8

Running Title for Header

Algorithm 2 Working of Ensemble Learning Model

1: Input:
2: DU L: Unlabelled Dataset
3: F S: Feature set from algorithm 1
4: Begin
5: Create an empty list DL
6: Set W1 = W2 = 0.25 & W3 = 0.50
7: for each data-entry dU L in DU L do
P1 = M BKmeans(F S(dU L))
8:
P2 = OP T ICS(F S(dU L))
9:
P3 = F Cmeans(F S(dU L))
10:
Cal. V using eq. 3
11:
if V > 0.5 then
12:
Set ˆV = 1
13:
14:
15:
16:
17:
18: end for
19: return DL: Labelled Dataset

end if
Append (dU L, ˆV ) in DL

Set ˆV = 0

else

Step-12 to 16 takes O(n), and step-17 also takes O(n) time for execution.

Step-19 has O(1) time complexity.

Hence, the overall time complexity of algorithm 2 is:
O(1 + (n ∗ i) + n2 + (n ∗ i) + (2 ∗ n) + 1) = O(n2)

The proposition 1 and 2 suggest that both the proposed feature selection mechanism and ensemble learning model have
polynomial time complexities, thus making them computationally feasible.

The proposed ensemble model generates a labelled dataset. The generated labelled dataset is then used to train different
deep learning models. In our study, we have used LSTM network [38], MLP [39] and DBN [40], and using performance
analysis an efﬁcient model is selected for detecting the malicious attacks in the IoT network. The detailed architectures
used for building each deep neural network model is shown in ﬁgure 2. The efﬁcient trained deep learning model can
be then deployed at fog layer (in a fog computing architecture for IoT [41]), and periodically updated on cloud layer, to
detect new/unknown network attacks in IoT devices at edge layer.

Figure 2: Neural network architecture (a) LSTM NN (b) Multilayer Perceptron NN (c) DBN

9

 1211....126....1231InputLayerHiddenLayerHiddenLayerOutputLayer(a)SigmoidSigmoidTanhTanh1211....126....123HiddenLayerHiddenLayerHiddenLayerOutputLayer(b)ReluSigmoidReluRelu1211....InputLayerSigmoid2MaliciousNon-malicious12MaliciousNon-MaliciousActivation FunctionsActivation Functions1211....126.....1231RBM1RBM2RBM3Back Propagation LayerWith Relu Activation function(c)2MaliciousNon-maliciousRunning Title for Header

4 Results and Discussion

To evaluate the performance of proposed model for detecting attacks in IoT network, we used NSL-KDD [42] &
TON-IoT [43] Network dataset and implemented the model using Python programming language (ver. 3.7.3) with
Scikit-learn and numpy packages. For implementing the deep learning model, we used Keras open-source software
library. The literature suggests that NSL-KDD dataset has been used by many researcher to access the performance of
attack detection models for IoT network [44, 45, 46]. Also, TON-IoT network dataset represents true network trafﬁc of
an IoT network and contains more IoT network speciﬁc network attacks, as the dataset was generated by real world
heterogeneous IoT devices.

4.1 Dataset Pre-processing

NSL-KDD is an enhanced version of KDD CUP 99 dataset (initially generated in 1998). The enhancement took place
in 2009 by Tavallaee et al. [47] by performing partitioning and removing the redundant records from the original
dataset. The dataset is publicly available on the internet. In our study, we have used the NSL-KDD training data ﬁle,
which consists of 125,973 network trafﬁc samples with 41 features and classiﬁes each trafﬁc detail by the class label
into malicious (represented by 1) or non-malicious (represented by 0). The malicious entries represent the network
trafﬁc generated by attackers. In the dataset the malicious entries represent DoS, Probe, R2L and U2R attacks. Before
implementing the proposed model on the dataset, we have converted the data-type of some of the features, which
include: Protocol type, Service and Flag. Mainly there are 3 types of protocols used in the dataset and we have assigned
a numeric value to each: 1 for Internet Control Message Protocol, 2 for Transmission Control Protocol and 3 for User
Datagram Protocol. Similarly, the 70 services in the service feature are also represented by numeric values from 1 to 70.
The Flag attribute has 11 different values and each is represented by a numeric value as: OTH (1), REJ (2), RSTO (3),
RSTOS0 (4), RSTR (5), S0 (6), S1 (7), S2 (8), S3 (9), SF (10) and SH (11).

TON-IoT dataset represents a combination of Telemetry, Operating and Network datasets, created at the IoT lab of
UNSW Canberra in Australian Defence Force Academy (ADFA). In our study, we have used TON-IoT network dataset,
which consists of 461,043 observations regarding network trafﬁc generated by different IoT devices (malicious as
well as non-malicious). It contains IoT network speciﬁc attacks like, DDoS, Ransomware attack, Injection attack,
Man-in-the-middle attack etc. As described for NSL-KDD dataset, similar data pre-processing was carried out in
TON-IoT network dataset for the features having string type data. Also, for feature scaling we have used standard scalar
for both the datasets.

Once the dataset is ready to be used for implementing the proposed model, we ﬁrst implement the proposed feature
selection mechanism on the dataset. The proposed feature selection mechanism selects 11 & 9 relevant features out of
41 & 43 available features of NSL-KDD & TON-IoT network datasets respectively. This results in the feature reduction
rate (FRR) of 73.17% & 79.07% for respective datasets, which can be calculated using equation 5.

F RR = 1 −

n(SF )
n(F )

(5)

Where, n(SF ) represents the number of selected features and n(F ) represent the total number of features in the dataset.
Also, the complete dataset features and selected features are shown in ﬁgure 3a & 3b. Network attacks in both the
datasets are shown in ﬁgure 4.

4.2 Evaluation metrics

In the proposed model we have used clustering as well as classiﬁcation techniques and each produces binary output (0
or 1) representing non-malicious or malicious trafﬁc. So, to measure the performance of various techniques used in the
model, we have used confusion matrix (as shown in table 4) and following evaluation metrics:

• Homogeneity (h) refers to how identical the samples in a cluster are.

h = 1 −

H(Ypred.|Ytrue)
H(Ytrue)

• The clustering algorithm’s completeness (c) determines how many related samples are grouped together.

Where, H() represents the entropy.

c = 1 −

H(Ypred.|Ytrue)
H(Ypred.)

10

(6)

(7)

Running Title for Header

(a) NSL-KDD dataset

(b) TON-IoT network dataset

Figure 3: Dataset Features

Figure 4: Network attacks in NSL-KDD and TON-IoT network Datasets

• V-measure (V ) is the harmonic means between h and c.

• A Rand Index RI evaluates all pairs of samples from true and predicted clusterings and ﬁnds the similarity

V =

2 ∗ h ∗ c
h + c

(8)

between the two.

RI =

T P + T N
T P + F N + F P + T N

The Adjusted Rand Index (ARI) is then calculated as:

ARI =

(RI − ExpectedRI)
(max(RI) − ExpectedRI)

(9)

(10)

• If X and Y are two clusterings, then Adjusted Mutual Information (AM I) between two clusterings is

calculated as:

AM I(X, Y ) =

M I(X, Y ) − E(M I(X, Y ))
avg(H(X), H(Y )) − E(M I(X, Y ))

(11)

• Out of all the samples analysed, the accuracy Acc indicates the percentage of samples that are correctly

identiﬁed.

Acc =

T P + T N
T P + F N + F P + T N

• The capacity of the classiﬁer to detect only relevant data is referred to as precision.

P recision =

T P
T P + F P

11

(12)

(13)

duration (0–to–54451)protocol type(1, 2, 3)service (1–to–70)src_bytes(0–to– 1379963888)dst_bytes(0–to– 309937401)Flag(1–to–11)Land(0, 1)wrong_fragment (0, 1, 3)Urgent(0–to–3)Hot(0–to–101)num_failed_logins(0–to–4)logged_in (0,1)num_compromised(0–to–7479)root_shell (0, 1)su_attempted(0, 1)num_root(0–to–7468)num_file_creations(0–to–100)num_shells(0–2)num_access_files(0–9)is_guest_login(0, 1)is_hot_logins(0, 1)num_outbound_cmds(0)Count(0–511)srv_count(0–511)serror_rate(0–to–1)srv_serror_rate(0–to–1)rerror_rate(0–to–1)srv_rerror_rate(0–to–1)same_srv_rate(0–to–1)diff_srv_rate(0–to–1)srv_diff_host_rate(0–to–1)dst_host_count(0–to–255)dst_host_srv_count(0–to–255)dst_host_same_srv_rate(0–to–1)dst_host_diff_srv_rate(0–to–1)dst_host_same_src_port_rate(0–to–1)dst_host_srv_diff_host_rate(0–to–1)dst_host_serror_rate(0–to–1)dst_host_srv_serror_rate(0–to–1)dst_host_rerror_rate(0–to–1)dst_host_srv_rerror_rate(0–to–1)class_label(0–to–1)Class LabelLeft-out FeaturesSelected FeaturesTs (ConnectionTimestamp)src_ip (Source IP)src_port (SourceTCP/UDP port)dst_ip (Destination IP)dst_port (DestinationTCP/UDP port)Proto (Transport layerprotocol)Activities related toconnection betweensource & destinationdevicesService (other protocolsfor providingservices)durationsrc_bytes (No. of bytessent by source)dst_bytes(No. of bytesresponded bydestination)conn_state(status ofconnection)missed_bytessrc_pkts(packets originatedfrom source)src_ip_bytes(length of IPheader fromsource)dst_pkts(packets originated fromdestination)dst_ip_bytes(length of IP header fromdestination)Connection statisticsdns_querydns_qclassdns_qtypedns_rcodeDNS activitiesdns_RAdns_rejecteddns_AAdns_RDssl_versionssl_cipherssl_resumedssl_establishedssl_subjectssl_issuerSSL activitieshttp_trans_depthhttp_methodhttp_urihttp_versionhttp_request_body_lenhttp_response_body_lenHTTP activitieshttp_status_codehttp_user_agenthttp_resp_mime_typeshttp_orig_mime_typesweird_nameweird_addlweird_noticeViolation activitiesLabel(0 – non-malicious,  1 – malicious)Class Label Feature TypeLeft-out FeaturesSelected FeaturesDoS Attack- Apache2                              - Arppoison- Back- Crashiis- Dosnuke- Land- Mailbomb- Neptune- PoD (Ping   Of   Death)- Smurf- Teardrop- UdpstormUser-to-Root Attack- Loadmodule- Perl- PS- XtermRemote-to-local Attack- password-guessing- HTTP-tunnel- FTP-write- IMAP- Named- PHF- Xlock - Xsnoop    Probes  - Ipsweep- Mscan- Nmap  - SAINT- SatanNetwork Attacks In NSL-KDD datasetNetwork Attacks In TON-IoT datasetScanning AttackDenial of Service (DoS) attackDistributed Denial of Service (DDoS) attackRansomware attackBackdoor attackInjection attackCross-site Scripting (XSS) attackPassword attackMan-In-The-Middle attackRunning Title for Header

• The ratio of total positives recognised by the system to real positives across the entire system is given by

Recall.

Recall =

T P
T P + F N

• F1-score represents the harmonic mean between precision and recall.

F 1 − score =

2 ∗ T P
2 ∗ T P + F P + F N

(14)

(15)

• The False Alarm Rate (F AR) is the percentage of non-malicious samples in the given dataset that were

incorrectly categorised as an attack.

F AR =

F P
T N + F P

(16)

• The rate of accurately predicted non-malicious samples for all possible non-malicious samples in the given

dataset is represented by speciﬁcity.

Specif icity =

T N
T N + F P

(17)

• Matthews Correlation Coefﬁcient (M CC) ﬁnds the correlation between actual class label and the predicted

class value.

4.3 Performance Analysis

M CC =

(T P ∗ T N ) − (F P ∗ F N )
(cid:112)(T P + F N ) ∗ (T P + F P ) ∗ (T N + F P ) ∗ (T N + F N )

(18)

In the initial phase, we have implemented the clustering techniques (as discussed in the proposed model) on NSL-KDD
and TON-IoT network datasets for selected features, to evaluate the clustering performance of each model. The entries
of confusion matrices and other performance parameters for clustering the network trafﬁc, in both the dataset, into
malicious and non-malicious are shown in table 5. Figure 5a & 5b shows the comparative analysis of the performance
of each clustering technique used for both the datasets. It is evident from the results that Fuzzy C Means clustering
outperforms the other, that is why we have set more weight on its predicted class label.

(a) For NSL-KDD dataset

(b) For TON-IoT network dataset

Figure 5: Comparative results of various clustering techniques used for predicting class label (malicious and non-
malicious)

After ﬁnalising the weights for performing weighted voting in the ensemble learning model, the proposed ensemble
model is now executed where the entire unlabelled NSL-KDD and TON-IoT network datasets separately are given to
the clustering algorithms to predict the class label for each trafﬁc observation. The predicted class labels are used as an
input to the weighted voting process to predict the ﬁnal class label for each observation. After, the entire unlabelled
datasets are converted into labelled datasets, then these generated dataset are used to train various deep neural network
models. The architectures used for building each deep neural network model is shown in ﬁgure 2.

The optimal values of hyperparameters of various deep learning models were selected after iterative simulation of the
models with varying values. For implementing LSTM deep neural networks, the value of various hyperparameters is
given as: Learning rate: 0.2, decay: 0.01, Number of epochs: 40, Batch size: 250, Optimizer: Adam, and Dropout rate at
each LSTM layer: 0.2. Similarly, for Multilayer perceptron, the value of various hyperparameters is given as: Learning
rate: 0.001, Number of epochs: 40, Batch size: 200, Optimizer: stochastic gradient descent (SGD). All the layers of

12

Running Title for Header

DBN are created using Restricted Boltzmann Machine (RBM), except the output layer (which uses back-propagation
layer to generate the ﬁnal output). The value of various hyperparameters in DBN are: Learning rate: 0.08, Decay:
0.006, Optimizer: Adamax, Number of epochs: 30, Batch size: 300. Figure 6 shows the loss curve for various models
during the training phase.

Figure 6: Loss curve during training process for various deep learning models

Once, the deep learning models are trained using the labelled datasets generated by the proposed model, they are then
tested on actual NSL-KDD and TON-IoT network datasets separately to detect malicious and non-malicious trafﬁc.
The performance of deep learning models are shown in table 6 and ﬁgure 7a & 7b.

(a) For NSL-KDD dataset

(b) For TON-IoT network dataset

Figure 7: Comparative results of models for detecting malicious network trafﬁc, after being trained on labelled dataset
generated by proposed model

(a) For NSL-KDD dataset

(b) For TON-IoT network dataset

Figure 8: ROC curves of models for detecting malicious network trafﬁc, after being trained on labelled dataset generated
by proposed model

Figure 7a & 7b describe the comparison of results of various deep learning models, which were trained using NSL-KDD
and TON-IoT network datasets (labelled by the proposed ensemble learning model). The results in the ﬁgure show that

13

Running Title for Header

Symbol
β
ˆβ
α
cof (i)
cov(X, y)

var(X)
Pi
Wi
V
ˆV

DU L
DL
F S
δ

Table 3: Nomenclature

Deﬁnition
Regression coefﬁcient
LASSO regression coefﬁcient
Regularization parameter
Correlation coefﬁcient for each feature vector i
Covariance between feature vector X and class
label y
Variance of feature vector X
Predicted output from clustering algorithm i
Weights associated with the prediction Pi
Combined predicted class label
Final predicted class label (after weighted vot-
ing)
Unlabelled Dataset
Labelled Dataset
Selected relevant features from the dataset
Threshold for correlation coefﬁcient

Table 4: Confusion Matrix

Actual Value

Malicious
Non-malicious

Predicted Value

Malicious
True Positive (TP)
False Positive (FP)

Non-malicious
False Negative (FN)
True Negative (TN)

Table 5: Results of clustering techniques for predicting class label (malicious or non-malicious)

For NSL-KDD Dataset
OPTICS

Fuzzy C-
Means

For TON-IoT Dataset
OPTICS

Fuzzy C-
Means

Performance
Parameters

TP
FN
FP
TN
Precision
Recall
Homogeneity
Completeness

Mini
Batch
K-Means
40951
17679
1803
65540
0.957
0.698
0.426
0.427

56711
1919
20187
47156
0.737
0.967
0.398
0.411

43906
14724
176
67167
0.996
0.748
0.543
0.58

Mini
Batch
K-Means
112483
48560
8032
291968
0.933
0.698
0.482
0.463

155772
5271
89929
210071
0.633
0.967
0.398
0.411

120600
40443
784
299216
0.993
0.748
0.543
0.58

Table 6: Results of various deep learning models for detecting malicious network trafﬁc, after being trained on labelled
dataset generated by proposed model

Parameters
TP
FN
FP
TN
Precision
Recall
FAR
Training Time (in
Sec)
Testing Time (in Sec)

For NSL-KDD Dataset

For TON-IoT Dataset

LSTM
54505
4125
2442
64901
0.957
0.929
0.036
11.84

MLP
55469
3161
1293
66050
0.977
0.946
0.019
18.31

DBN
57253
1377
1596
65747
0.972
0.976
0.023
15.63

LSTM
149713
11330
10879
289121
0.932
0.929
0.036
19.44

MLP
152360
8683
5760
294240
0.963
0.946
0.019
28.64

DBN
157261
3782
7110
292890
0.956
0.976
0.0237
24.25

0.023

0.036

0.029

0.056

0.074

0.068

14

Running Title for Header

(a) For NSL-KDD dataset

(b) For TON-IoT network dataset

Figure 9: PR curve of models for detecting malicious network trafﬁc, after being trained on labelled dataset generated
by proposed model

all the studied models produce acceptable results for detecting malicious attacks in IoT networks, this proves that the
labelled dataset generated by the proposed ensemble learning model has effectively predicted the class label for each
data entry in the unlabelled dataset. Also, it is evident from the testing results that DBN model outperforms the other
with an attack detection accuracy of 97.6% and has least false alarm rate of 2.3% on both the datasets.

Figure 8a & 8b show the Receiver Operating Characteristic (ROC) and ﬁgure 9a & 9b show the Precision-Recall (PR)
curves for NSL-KDD & TON-IoT network datasets respectively, with Area Under the Curve (AUC) values. The AUC
value lies in the range of [0, 1] and a classiﬁer whose AUC value is closer to 1 is considered efﬁcient. Again, these
ﬁgures also depict that DBN has better results with ROC-AUC = 0.98 (for both the datasets) & PR-AUC = 0.98 (for
NSL-KDD) and 0.97 (for TON-IoT network Dataset).

Figure 10: Attack detection accuracy of DBN model, after being trained on labelled dataset generated by proposed
model for the features selected by Correlation based, LASSO Reg. based and proposed feature selection mechanisms
resp.

To show the signiﬁcance of the proposed feature selection mechanism, which is an amalgamation of correlation based
and LASSO reg. based feature selection mechanism, we have implemented three cases. In case-I, we have selected the
features using correlation based feature selection mechanism (for NSL-KDD & TON-IoT network datasets resp.), used
proposed ensemble learning model to predict the class labels for malicious and non-malicious records, then train DBN
model for detecting malicious attacks and note the detection accuracy. In case-II and III, again the same procedure is
followed for LASSO regression based and proposed feature selection mechanisms respectively. The attack detection
accuracies for case-I, II & III are shown in ﬁgure 10. The study clearly indicates that the proposed feature selection
helps to extract most relevant features from the datasets and thus helps to enhance attack detection accuracy.

15

Running Title for Header

5 Conclusion & Future Work

In this paper, we proposed an unsupervised ensemble based learning model which is able to transform an unlabelled
network dataset into labelled dataset, thereby predicting new/unknown attacks. The paper also proposed a feature
selection mechanism which is able to discover relevant features in NSL-KDD & TON-IoT network datasets for detecting
malicious attacks, resulting in FRR of 73.17% & 79.07% respectively. The proposed ensemble learning model ﬁrst
converts each unlabelled dataset into labelled dataset, then use it to train a deep learning model (separately for each
dataset). In the study, we used LSTM, MLP & DBN deep learning models and results show that DBN is more efﬁcient
than the other two studied deep learning models for detecting malicious attacks in an IoT network, with attack detection
accuracy of 97.6% and FAR of 2.3% on both the studied datasets.

The proposed unsupervised ensemble based learning model can be implemented with fog computing architecture,
where the model can be deployed at cloud layer to identify new/unknown attacks by analysing the unlabelled IoT
network trafﬁc. The network trafﬁc labelled by the proposed model can then be used to train DBN deep learning model
to detect network attack. The trained DBN can then be deployed at the fog layer to analyse the network trafﬁc of
edge devices and detect attacks, with periodic updates at the cloud layer for identifying new attacks. The use of fog
computing architecture will decrease the load on fog as well as energy constrained IoT edge devices. In future, we will
implement the model on a real world IoT network with fog computing architecture to further investigate the efﬁciency
and complexity of the proposed model.

Acknowledgement

We would like to thank TEQIP-III project and MITS, Gwalior for supporting this research.

References

[1] Javed F, Afzal MK, Sharif M, Kim BS. Internet of Things (IoT) operating systems support, networking technolo-
gies, applications, and challenges: A comparative review. IEEE Communications Surveys & Tutorials 2018; 20(3):
2062–2100.

[2] Ciuonzo D, Rossi PS, Varshney PK. Distributed detection in wireless sensor networks under multiplicative fading

via generalized score tests. IEEE Internet of Things Journal 2021; 8(11): 9059–9071.

[3] Meneghello F, Calore M, Zucchetto D, Polese M, Zanella A. IoT: Internet of threats? A survey of practical security

vulnerabilities in real IoT devices. IEEE Internet of Things Journal 2019; 6(5): 8182–8201.

[4] Hassan WH, others . Current research on Internet of Things (IoT) security: A survey. Computer networks 2019;

148: 283–294.

[5] Xiao L, Wan X, Lu X, Zhang Y, Wu D. IoT security techniques based on machine learning: How do IoT devices

use AI to enhance security?. IEEE Signal Processing Magazine 2018; 35(5): 41–49.

[6] Deng L, Li D, Yao X, Cox D, Wang H. Mobile network intrusion detection for IoT system based on transfer

learning algorithm. Cluster Computing 2018; 22(4): 9889–9904.

[7] Rathore S, Park JH. Semi-supervised learning based distributed attack detection framework for IoT. Applied Soft

Computing 2018; 72: 79–89.

[8] Sahay R, Geethakumari G, Modugu K, Mitra B. Trafﬁc convergence detection in IoT LLNs: a multilayer

perceptron based mechanism. In: IEEE. ; 2018: 1715–1722.

[9] Sahay R, Geethakumari G, Mitra B, Sahoo I. Efﬁcient framework for detection of version number attack in internet

of things. In: Springer. ; 2018: 480–492.

[10] Mirsky Y, Doitshman T, Elovici Y, Shabtai A. Kitsune: an ensemble of autoencoders for online network intrusion

detection. arXiv preprint arXiv:1802.09089 2018.

[11] Homoliak I, Toffalini F, Guarnizo J, Elovici Y, Ochoa M. Insight into insiders and it: A survey of insider threat
taxonomies, analysis, modeling, and countermeasures. ACM Computing Surveys (CSUR) 2019; 52(2): 1–40.

[12] Ahmad MS, Shah SM. Mitigating Malicious Insider Attacks in the Internet of Things using Supervised Machine

Learning Techniques. Scalable Computing: Practice and Experience 2021; 22(1): 13–28.

[13] Khraisat A, Gondal I, Vamplew P, Kamruzzaman J, Alazab A. A Novel Ensemble of Hybrid Intrusion Detection

System for Detecting Internet of Things Attacks. Electronics 2019; 8(11): 1210.

16

Running Title for Header

[14] Venkatraman S, Surendiran B. Adaptive hybrid intrusion detection system for crowd sourced multimedia internet

of things systems. Multimedia Tools and Applications 2020; 79(5): 3993–4010.

[15] Bovenzi G, Aceto G, Ciuonzo D, Persico V, Pescapé A. A hierarchical hybrid intrusion detection approach in IoT

scenarios. In: IEEE. ; 2020: 1–7.

[16] Sahay R, Geethakumari G, Mitra B. A novel blockchain based framework to secure IoT-LLNs against routing

attacks. Computing 2020; 102(11): 2445–2470.

[17] Veeramakali T, Siva R, Sivakumar B, Senthil Mahesh P, Krishnaraj N. An intelligent internet of things-based
secure healthcare framework using blockchain technology with an optimal deep learning model. The Journal of
Supercomputing 2021; 77(9): 9576–9596.

[18] Babu MJ, Reddy AR. SH-IDS: Speciﬁcation Heuristics Based Intrusion Detection System for IoT Networks.

Wireless Personal Communications 2020: 1–23.

[19] Makkar A, Kumar N. An efﬁcient deep learning-based scheme for web spam detection in IoT environment. Future

Generation Computer Systems 2020: 467–487.

[20] Eskandari M, Janjua ZH, Vecchio M, Antonelli F. Passban IDS: an intelligent anomaly-based intrusion detection

system for IoT edge devices. IEEE Internet of Things Journal 2020; 7(8): 6882–6897.

[21] Verma A, Ranga V. Machine learning based intrusion detection systems for IoT applications. Wireless Personal

Communications 2020; 111(4): 2287–2310.

[22] Sahu AK, Sharma S, Tanveer M, Raja R. Internet of Things attack detection using hybrid Deep Learning Model.

Computer Communications 2021.

[23] Fotohi R, Pakdel H. A Lightweight and Scalable Physical Layer Attack Detection Mechanism for the Internet of

Things (IoT) Using Hybrid Security Schema. Wireless Personal Communications 2021: 1–18.

[24] Ambusaidi MA, He X, Nanda P, Tan Z. Building an intrusion detection system using a ﬁlter-based feature selection

algorithm. IEEE transactions on computers 2016; 65(10): 2986–2998.

[25] Shone N, Ngoc TN, Phai VD, Shi Q. A deep learning approach to network intrusion detection. IEEE transactions

on emerging topics in computational intelligence 2018; 2(1): 41–50.

[26] Meidan Y, Bohadana M, Mathov Y, et al. N-baiot—network-based detection of iot botnet attacks using deep

autoencoders. IEEE Pervasive Computing 2018; 17(3): 12–22.

[27] Jan SU, Ahmed S, Shakhov V, Koo I. Toward a lightweight intrusion detection system for the internet of things.

IEEE Access 2019; 7: 42450–42471.

[28] Zhou Y, Cheng G, Jiang S, Dai M. Building an efﬁcient intrusion detection system based on feature selection and

ensemble classiﬁer. Computer networks 2020; 174: 107247.

[29] Srinivas M, Patnaik MR. Clustering with a high-performance secure routing protocol for mobile ad hoc networks.

The Journal of Supercomputing 2022: 1–22.

[30] Sahay R, Geethakumari G, Mitra B. A holistic framework for prediction of routing attacks in IoT-LLNs. The

Journal of Supercomputing 2022; 78(1): 1409–1433.

[31] Benesty J, Chen J, Huang Y, Cohen I. Pearson correlation coefﬁcient. In: Springer. 2009 (pp. 1–4).
[32] Tibshirani R. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B

(Methodological) 1996; 58(1): 267–288.

[33] Dietterich TG, others . Ensemble learning. The handbook of brain theory and neural networks 2002; 2(1):

110–125.

[34] Bottou L, Bengio Y. Convergence properties of the k-means algorithms. In: ; 1995: 585–592.
[35] Bezdek JC, Ehrlich R, Full W. FCM: The fuzzy c-means clustering algorithm. Computers & geosciences 1984;

10(2-3): 191–203.

[36] Ankerst M, Breunig MM, Kriegel HP, Sander J. OPTICS: Ordering points to identify the clustering structure.

ACM Sigmod record 1999; 28(2): 49–60.

[37] Kim HC, Pang S, Je HM, Kim D, Bang SY. Constructing support vector machine ensemble. Pattern recognition

2003; 36(12): 2757–2767.

[38] Kim J, Kim J, Thu HLT, Kim H. Long short term memory recurrent neural network classiﬁer for intrusion

detection. In: IEEE. ; 2016: 1–5.

[39] Friedman JH. The elements of statistical learning: Data mining, inference, and prediction. springer open . 2017.

17

Running Title for Header

[40] Hinton GE, Osindero S, Teh YW. A fast learning algorithm for deep belief nets. Neural computation 2006; 18(7):

1527–1554.

[41] Hu P, Dhelim S, Ning H, Qiu T. Survey on fog computing: architecture, key technologies, applications and open

issues. Journal of network and computer applications 2017; 98: 27–42.

[42] NSL-KDD dataset. https://www.unb.ca/cic/datasets/nsl.html (accessed: 02.08.2020).
[43] N. Moustafa, ToN_IoT Datasets, 2019 (online). http://dx.doi.org/10.21227/fesz-dm97 (accessed: 02.08.2020).
[44] Gunupudi RK, Nimmala M, Gugulothu N, Gali SR. CLAPP: A self constructing feature clustering approach for

anomaly detection. Future Generation Computer Systems 2017; 74: 417–429.

[45] Su T, Sun H, Zhu J, Wang S, Li Y. BAT: Deep learning methods on network intrusion detection using NSL-KDD

dataset. IEEE Access 2020; 8: 29575–29585.

[46] Souza dCA, Westphall CB, Machado RB, Sobral JBM, Santos Vieira dG. Hybrid approach to intrusion detection

in fog-based IoT environments. Computer Networks 2020; 180: 107417.

[47] Tavallaee M, Bagheri E, Lu W, Ghorbani AA. A detailed analysis of the KDD CUP 99 data set. In: IEEE. ; 2009:

1–6.

18

