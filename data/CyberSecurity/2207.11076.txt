Specialized Cyber Threat Intelligence

Multi-Level Fine-Tuning, Data Augmentation, and Few-Shot
Learning for Specialized Cyber Threat Intelligence

Markus Bayer · Tobias Frey · Christian Reuter

2
2
0
2

l
u
J

2
2

]

R
C
.
s
c
[

1
v
6
7
0
1
1
.
7
0
2
2
:
v
i
X
r
a

bayer@peasec.tu-darmstadt.de, tobiasjonathan.frey@stud.tu-darmstadt.de, reuter@peasec.tu-darmstadt.de
PEASEC - Science and Technology for Peace and Security
Technical University of Darmstadt
Pankratiusstraße 2, 64289 Darmstadt
Germany

Abstract Gathering cyber threat intelligence from open sources is becoming increasingly important for main-
taining and achieving a high level of security as systems become larger and more complex. However, these open
sources are often subject to information overload. It is therefore useful to apply machine learning models that
condense the amount of information to what is necessary. Yet, previous studies and applications have shown that
existing classiﬁers are not able to extract speciﬁc information about emerging cybersecurity events due to their
low generalization ability. Therefore, we propose a system to overcome this problem by training a new classiﬁer
for each new incident. Since this requires a lot of labelled data using standard training methods, we combine three
diﬀerent low-data regime techniques – transfer learning, data augmentation, and few-shot learning – to train a
high-quality classiﬁer from very few labelled instances. We evaluated our approach using a novel dataset derived
from the Microsoft Exchange Server data breach of 2021 which was labelled by three experts. Our ﬁndings reveal
an increase in F1 score of more than 21 points compared to standard training methods and more than 18 points
compared to a state-of-the-art method in few-shot learning. Furthermore, the classiﬁer trained with this method
and 32 instances is only less than 5 F1 score points worse than a classiﬁer trained with 1800 instances.

Keywords Cyber Threat Intelligence · Few-Shot Learning · Transfer Learning · Data Augmentation · Information
Overload

1 Introduction

Social media is where cutting-edge and critical cyber
threat information is disseminated, which is highly rel-
evant to researchers, security providers, security oper-
ation centers, urban infrastructures, and cyber emer-
gency response teams (CERTs), among others (Mit-
tal et al., 2016; Rodriguez and Okamura, 2019). While
there have been several research works on general cy-
ber threat detection (Dion´ısio et al., 2020; Fang et al.,
2020), the goal of this work is to enable a ﬁne-grained
information collection.

One major challenge in collecting speciﬁc informa-
tion in this domain is that cyber information is highly
dynamic and diﬀers greatly from past events (in terms
of speciﬁc names, diﬀerent attack vectors, speciﬁc at-

tack paths, aﬀected functions, etc.) (Chatterjee and
Thekdi, 2020). As a result, supervised machine learn-
ing yields poor results because these dynamics cannot
be captured in the learning process. Alternatively, new
classiﬁers could be trained for each cyber threat so that
the new features are taken into account. However, since
machine learning usually requires a large amount of
data for normal training, this would result in having to
label a dataset for each cyber threat, which is unrealis-
tic considering the eﬀort involved and the need for fast
and up-to-date information. Against this background,
the concept of active learning systems take a ﬁrst step
towards label reduction for supervised machine learning
for cyber threats (Riebe et al., 2021b). Active learning
supports the labeling process, so that only the instances
with the highest learning value need to be labeled for

 
 
 
 
 
 
2

machine learning. However, despite this method, too
much data is still needed to train a useful classiﬁer.
The endeavor sought in this work takes an even stronger
stance on labeling reduction by proposing a system with
few-shot learning, transfer learning, and data augmen-
tation. With few-shot learning, it is suﬃcient if the
model is already trained with very few instances, as
opposed to hundreds or thousands in the case of active
or normal learning (Brown et al., 2020). This includes
special learning techniques as well as transfer learning,
where knowledge from a previous task is transferred
to the new one. Data augmentation is used to create
artiﬁcial instances from the training data using label-
preserving transformations (Bayer et al., 2022).

The concept of few-shot learning is extended in this
work through the use of multi-level transfer learning.
The diﬀerent levels start with a model that has been
trained on a large general dataset and thus has a ba-
sic prior knowledge. During the next steps, this model
is approximated more and more to the actual task do-
main. In this way, it can be ensured that the model is
given a basic cybersecurity reference in order to be able
to counter the dynamics in the task, in addition to be-
ing familiar with the task. This is particularly relevant
for urban infrastructures, which require high resilience
against cyberattacks, as well as for CERTs, as they need
to collect and communicate information in the most re-
liable and targeted way possible (Riebe et al., 2021a).
The data augmentation strategy is inspired by the work
of Bayer et al. (2021) and follows the example of Yoo
et al. (2021) by utilizing the large generation model
GPT-3 to generate new instances based on the few ex-
isting labeled ones.

Our paper includes several contributions relevant for

the cybersecurity and machine learning community:

– A novel pipeline combining transfer learning, data
augmentation, and few-shot learning for develop-
ing an eﬀective specialized cyber threat intelligence
(CTI) classiﬁer.

– Novel techniques of data augmentation and few-shot
learning to deal with a small number of training
instances.

– A new specialized CTI dataset annotated by three
experts and based on the 2021 Microsoft Exchange
Server data breach.

The code and dataset of this study are freely avail-
able. The remainder of the paper is structured as fol-
lows: After introducing related work on transfer learn-
ing, data augmentation, few-shot learning, and cyber
threat detection and intelligence (Section 2), we explain
the concept of our method (Section 3). It is subdivided
in three components which are described in detail. In
Section 4 the evaluation is presented and ﬁndings are

given in detail. The last section (Section 5) contains a
discussion of the implications, limitations, and poten-
tials for future research.

2 Related Work

2.1 Transfer Learning

Transfer learning describes the process of transferring
knowledge gained from training a neural network from
one task to another related task (Torrey and Shav-
lik, 2010; Pan, 2020). This technique is now one of
the standard learning methods for machine learning,
especially in the ﬁeld of natural language processing
(NLP). It is particularly powerful for tasks where there
is not enough training data or it is diﬃcult to man-
ually adjust the data for training. In this case, it is
possible to use a pre-trained neural network that was
trained to solve a related task or with more easily ac-
cessible data. Afterwards the neural network is ﬁne-
tuned with the task-speciﬁc data to ﬁt the wanted task.
One of the most frequently used pre-trained models is
BERT by Devlin et al. (2018). BERT (short for Bidirec-
tional Encoder Representations from Transformers) is a
pre-trained deep bidirectional transformer for language
understanding. In essence, it is trained by predicting
words in a sentence given the other words, also called
masked language modeling. It has a lot of widely used
descendants trained for many diﬀerent tasks, such as
BioBERT (Lee et al., 2019), SciBERT (Beltagy et al.,
2019), and CamemBERT (Martin et al., 2020). While
BERT is already a considerably large model, nowadays
far larger models, like GPT-3 from Brown et al. (2020),
are trained. Compared to BERT’s base model with 110
million parameters, GPT-3 has 175 billion parameters,
however, GPT-3 is not publicly available and cannot be
easily ﬁne-tuned due to its size.

2.2 Data Augmentation

Data augmentation is the concept for artiﬁcially en-
larging the training datasets for machine learning by
transforming the existing ones. Originated and heav-
ily used in computer vision, it is now also increasingly
being explored on textual data (Bayer et al., 2022).
NLP data augmentation techniques can be applied to
the raw text or also on the numerical representations.
Ranging from small transformations, i.e. ﬂipping char-
acters (Belinkov and Bisk, 2018) or inducing adver-
sarial noise (Jiang et al., 2020), to interpolated (Sun
et al., 2020) or even newly created instances (Anaby-
Tavor et al., 2020), data augmentation can have great

eﬀects. Nevertheless, as Longpre et al. (2020) point out,
the success of data augmentation in NLP is often not
perceivable when ﬁne-tuning large pre-trained models.
A data augmentation technique needs to incorporate
new linguistic patterns as otherwise the changes are too
small and already captured by the pre-training phase of
the model. For example, simple synonym replacement
methods have not been shown to be beneﬁcial with pre-
trained models, as these synonyms are already mapped
to nearly the same vector for their numerical represen-
tation (Mosolova et al., 2018). On the other hand, there
are generation models that can integrate new linguis-
tic patterns, for example, through their own training
data during pre-training, as for example shown by Yoo
et al. (2021) with the GPT-3 model. The challenge with
using these models is to make the generations truly la-
bel preserving. This is, for example, done by Anaby-
Tavor et al. (2020), Queiroz Abonizio and Barbon Ju-
nior (2020) and Bayer et al. (2021). The models are
conditioned by ﬁne-tuning on the label-induced train-
ing data (or just the class data) and are then tasked
to complete a text given the label conditioned begin-
ning (prompt). As this is oftentimes not suﬃcient to
achieve a high label preservation, a ﬁlter mechanism is
used that removes artiﬁcial instances that are unlikely
to ﬁt the class. For example, Anaby-Tavor et al. (2020)
use a classiﬁer trained on the data to predict whether
the new instance can be assigned to the expected label.
For an overview of the data augmentation methods
that could be used in this study, we advise the reader
to have a look at the survey from Bayer et al. (2022).

2.3 Few-Shot Learning

Few-shot learning describes the training of eﬀective
classiﬁers on the basis of a small number of examples.
While there are several strands of research on few-shot
learning (Bragg et al., 2021), in this study we focus
on the use of pre-trained language models. At the lat-
est, the large language model GPT-3 by Brown et al.
(2020) paved the way for using these kinds of models, as
it reaches astounding performance even without task-
speciﬁc training data. However, as GPT-3 is too large
for most companies and research institutes, the research
ﬁeld adapted smaller language models to reach similar
or even better few-shot performances (Tam et al., 2021).
Pre-trained language models can be especially bene-
ﬁcial for few-shot settings when the instances are refor-
mulated in a cloze-style way. Cloze tests (Taylor, 1953)
are tests where some words in the text are missing and
have to be completed. For few-shot learning, instances
are rephrased, often into questions, so that the text con-
tains the label (or a word that can be mapped to the

3

label), generally within the answer to the question. The
label, known (training) or not known (testing and in-
ference), is masked out, so that the language model can
ﬁll it with the right word and a label can be inferred.
Using the language model directly is more eﬀective for
few-shot learning than the classical way of training a
classiﬁer head on top of it, as there are no more ran-
domly initialized parameters that have to be learned
(Gao et al., 2021).

A pattern describes the transformation of the input
instance to the cloze-like text. The verbalizer maps the
predicted words for the mask to the label. An example
for a pattern and a verbalizer can be seen in Figure 1.
Gao et al. (2021) show that the choice of template
and verbalizer has a major impact on the resulting per-
formance. Since domain knowledge is often necessary
for these, the authors propose a method to automati-
cally ﬁnd meaningful templates and verbalizer. For this
purpose, they use a language model and the existing
training instances to predict the words for the verbal-
izer and template. Zhang et al. (2022) take a diﬀer-
ent perspective on automatic template generation with
the DART method by making the template diﬀeren-
tiable. They use special tokens in the template that
are mapped into trainable parameters. These template
parameters are then optimized together with the tar-
get label. PERFECT by Mahabadi et al. (2022) lever-
ages task-speciﬁc adapters to replace template tokens.
Adapters make it possible to train only the newly added
parameters, which are able to transform the hidden
states, while freezing all other parameters.

Schick and Sch¨utze

(2021) propose a semi-
supervised few-shot learning technique, called PET.
They take several manually designed templates and use
the training data to train on each one a pre-trained
language model. They take these models to generate
pseudo-labels for unlabeled data. A classiﬁer is then
trained on the resulting dataset. Tam et al. (2021)
adapt the PET method to not be dependent on ad-
ditional training data and can even improve the per-
formances. Contrary to the preceding PET technique,
the word probabilities are computed not only for the
verbalizer words, like “yes” and “no”, but also for all
other words. In the training, incorrect class tokens are
explicitly penalized and correct tokens are encouraged.
Furthermore, ADAPET (Tam et al., 2021) introduces
a label conditioning step in which the model is tasked
to predict other tokens in the sentence given the label.

2.4 Cyber Threat Detection and Intelligence

Cyber threat detection is generally known as the pro-
cess of automatic scraping of the webspace and Open

4

Fig. 1 Example of a template and a verbalizer and how they are applied on an instance.

Source Intelligence (OSINT) to detect possible cyberse-
curity vulnerabilities (Sabottke et al., 2015; Riebe et al.,
2021b; Le Sceller et al., 2017). Social Media platforms,
like Twitter, are part of OSINT and propose a great
space to share and discuss possible cybersecurity vul-
nerabilities. There are some automated systems and re-
search that already scrape Twitter and other OSINT
sources to detect cyber threats. Some examples are the
CySecAlert system from Riebe et al. (2021b) or SONAR
from Le Sceller et al. (2017), which collect cyber threat
relevant tweets from Twitter, ﬁlter them, and present
them in a manageable dashboard.

CTI on the other hand describes the process of col-
lecting additional information after the ﬁrst detection
of a cyber threat. The process helps deliver the context
of the vulnerabilities found to assist CERTs and cyber-
security organizations make sound decisions and ﬁnd
quick solutions (Abu et al., 2018; Tounsi and Rais, 2018;
Wagner et al., 2019). CTI is currently mostly accom-
plished by manually sharing information on diﬀerent
platforms (Abu et al., 2018). They depend heavily on
manual input and are therefore labor intensive (Wagner
et al., 2019). However, there are already some threat in-
telligence platforms, such as Facebook ThreatExchange
or CrowdStrike, that are able to automatically detect,
monitor, and analyze cyber threat occurrences (Tounsi
and Rais, 2018). A manageable dashboard is also pro-
vided by the Cyber Threat Observatory of Kaufhold
et al. (2022), which aggregates cybersecurity informa-
tion from various sources, including social media, se-
curity advisories, indicators of compromise and CVEs.
However, these systems need too much time to adapt
to a newly discovered threat that is, for example, prop-
agated on Twitter.

2.5 Research Gap

Our study addresses several research gaps which are
highly relevant for researchers as well as practition-
ers. Most importantly, our research paves the way for
ﬁne-grained CTI. Current research addresses CTI from
a very coarse perspective, by building classiﬁers, like
Riebe et al. (2021b), that are able to ﬁnd general cyber
threat information. As a result, only a small amount
of data reduction can be achieved in these information-
overloaded situations. On the other hand, specialized
classiﬁers are not designed to generalize well to new
situations. Our work ﬁlls this gap by introducing a
pipeline for specialized CTI, where new cyber threat
events are encountered with the very fast creation of
new classiﬁers. By addressing this ﬁne-grained infor-
mation gathering challenge, we create a novel dataset
combined with a sophisticated labeling guideline for
CTI. Furthermore, with our pipeline we address re-
search gaps of machine learning low-data regimes. Our
data augmentation strategy is the ﬁrst to explore the
generation capabilities of large language models with
constraining them through ﬁltering mechanisms. We
combine the works of Yoo et al. (2021) and Bayer et al.
(2021) by using GPT-3 with a human-in-the-loop ﬁl-
tering mechanism. We extend the few-shot learning re-
search by proposing a multi-level ﬁne-tuning approach.
In the process, the model learns a very broad knowl-
edge in the ﬁrst levels, which in the later stages becomes
more and more directed to the speciﬁc CTI task.

3 Concept

3.1 Dataset Creation

The goal of dataset creation is to extract speciﬁc CTI
information during a signiﬁcant cyber threat event.
This dataset is subsequently binary-labeled according
to the relevance of the information for CTI and for cy-
bersecurity experts. We focused on the Microsoft Ex-
change Server data breach of 2021, where four zero-day
exploits were discovered. While the ﬁrst report of a vul-
nerability was already made in January of that year, in
March various attackers were found to be exploiting the
vulnerabilities and a Proof of Concept was released.

We used the Twitter APIv2 to gather Tweets in
March that fulﬁll the query “Microsoft Exchange” OR
“MS Exchange” OR “CVE-2021-26855” OR “CVE-
2021-26857” OR “CVE-2021-26858” OR “CVE-2021-
27065”. For these Tweets we resolved the links that
were shortened by Twitter, as the full URLs might be
an important indicator in the context of CTI.

The labeling process of the data was performed by
three cybersecurity experts guided by a codebook. The
guidelines, which provide clear guidance on when to
mark a contribution as relevant or irrelevant, were up-
dated iteratively by the annotation leader. A ﬁrst draft
was developed using the CTI concept (McMillan, 2013):

“Threat intelligence is referred to as the task
of gathering evidence-based knowledge, includ-
ing context, mechanisms,
implica-
tions, and actionable advice, about an existing
or emerging menace or hazard to assets that can
be used to inform decisions regarding the sub-
ject’s response to that menace or hazard.”

indicators,

After an initial sifting of the tweets and again after the
ﬁrst labeling of 750 tweets, the process was reﬁned by
the annotation leader.

The ﬁrst round of annotation of 750 tweets was
conducted by the annotation leader, who updated the
guidelines after gathering several insights. He and the
other two cybersecurity experts then annotated the 750
tweets again. After this round, all three experts dis-
cussed the cases they were not sure about and corrected
them if necessary. Regarding the intercoder reliability
the Kappa Scores were calculated (see 1). Subsequently,
each annotator tagged 750 diﬀerent examples, resulting
in a total of 3001 commented Twitter posts for the com-
plete dataset (the labels of the 750 instances of the ﬁrst
round were determined by majority vote).

The dataset was then split into a full and few-shot
training set and development set. The splits (train, dev)
consist of 1800 and 600 instances for the full set and 32
and 32 instances for the few-shot set, respectively. The

5

Coder
C1 and C2
C2 and C3
C1 and C3

Score
0.8763
0.7446
0.8709

Table 1 Intercoder reliability calculated with the Kappa
Score.

Fig. 2 Multi-level ﬁne-tuning process that shows the model
becoming more specialized as it is guided to the actual task
with less data.

test set is the same in both cases and consists of 601
instances.

3.2 Approach

Our system for dynamic, specialized cyber threat de-
tection consists of three components, all of which help
to boost performance with little data. We explain the
three components in detail in the following:

Multi-Level Fine-Tuning: In light of the success of large
pre-trained models such as BERT, we propose to fur-
ther tune such models on several
levels of domain-
dependent data (see Figure 2). The levels begin from
a broader view and are narrowed down to the actual
task. In our case, we ﬁrst take a pre-trained BERT
model (which can be seen as the 0th level of ﬁne-
tuning), train it with masked language modeling on cy-
bersecurity data. We then tune the resulting model for
classiﬁcation on the CySecAlert dataset (Riebe et al.,
2021b) in which Twitter posts are generally assigned
to the cybersecurity domain. Finally, we train it on the
few training examples of the specialized cyber threat
dataset. The rationale behind this is that the model
gains more and more knowledge as it is tuned to more
and more ﬁtting tasks. The 0th level is about gaining
general knowledge of text. In the ﬁrst level, the dataset
consists of papers, blogs, web pages, and also Twit-
ter data, from which the model gains knowledge about

6

cybersecurity language and also how Twitter data is
written in this domain. In the second level, the model
should gain a general understanding of the relevance
of cybersecurity information. Finally, in the third level,
the model is tuned to the actual task data to which it
can transfer the knowledge of the previous levels.

GPT-3 Data Augmentation: With data augmentation
we can create new instances from existing ones, which
can be particularly advantageous when the amount of
data is small. We propose a data augmentation strat-
egy based on text generation with GPT-3 (Brown et al.,
2020), which is inspired by the method from Yoo et al.
(2021) and Bayer et al. (2021). GPT-3 can be tasked to
complete a given text, also called a prompt. We utilize
this mechanism so that the generation model creates
new instances based on the training data of one class.
Speciﬁcally, this means that we are concatenating all in-
stances of one class with a class speciﬁc priming token.
For the class of cyber threat information we prepend ev-
ery positive instance with “cybersecurity ->”. For the
irrelevant class we chose “other ->” as priming token.
In both cases the priming token is also appended at
the end so that the model generates the instance(s) af-
ter it. Dependent on how many remaining generation
tokens the model has after the prompt, it may gener-
ate more than one instance by picking up the priming
token. After the creation of the instances we perform
the human-in-the-loop ﬁltering step proposed by Bayer
et al. (2021). The training examples and generated in-
stances are mapped into an embedding space. There,
the generated instances that deviate the most from the
training data are discarded. The distance from which
this happens is determined by an expert.

Few-Shot Learning: We make use of the existing
ADAPET (Tam et al., 2021) few-shot learning tech-
nique and adapt it to our case. With ADAPET, in con-
trast to normal use, no classiﬁcation head is trained on
the language models. The instances are transformed to
cloze-style phrases and then the language model itself
is used to predict the blank word in the phrases. The
predicted word is subsequently transformed with a ver-
balizer to one of the labels. The cloze-style phrases are
automatically formed with templates. For our task we
use the following template:

“[POST] Question : Is this text helpful for cy-
bersecurity experts? Answer : <MASK>. [SEP]”

The verbalizer maps the two possible words “yes”
and “no” to the labels representing relevant and not
relevant. As explained in Section 2.3 there also exist
methods for automatically determining the pattern and

verbalizer. We believe that these techniques are not nec-
essary in our case, as we can integrate the expert knowl-
edge regarding the task, which facilitates the learning
process.

4 Evaluation

4.1 Dataset, Models and Evaluation Settings

Following the research goal of specialized CTI for se-
curity professionals, we constructed a setting, consist-
ing of models and datasets, representing the real con-
ditions. For the dataset, we labeled data from the 2021
Microsoft Exchange Server data breach. The speciﬁcs
of the dataset can be found in Section 3.1. The labeled
dataset, including few-shot and normal-shot splits, is
freely available.

In our main evaluation we have diﬀerent settings re-
garding the dataset and models. The baseline and initial
model of our evaluation is the bert-base-uncased model
by Devlin et al. (2018). For the baseline, this model
is ﬁne-tuned on the few-shot dataset representing the
standard training strategy without any few-shot or data
augmentation methods. For the best case, on the other
hand, we train the bert-base-uncased model with the
full dataset of 1800 instances. This is called the best
case because we consider this amount of data to be the
best case in the event of a new cybersecurity attack.
In addition, we also train a model with ADAPET, as
we consider this to be the current state of the art in
few-shot research. In preliminary tests, we found that
ADAPET performed best on the few-shot split with
ALBERT (Lan et al., 2020) compared to DART and
a PERFECT variant. To be consistent with our evalu-
ation settings as opposed to the evaluation settings of
ADAPET, we use the bert-base-uncased model, instead
of the albert-xxlarge-v2 model by Tam et al. (2021).
The evaluation settings of our procedure are divided
into the three components mentioned. For the data aug-
mentation technique we use GPT-3 (DaVinci) as text
generation model, which is prompted with the speciﬁcs
explained in section 3.2. The multi-stage ﬁne-tuning
process starts with the bert-base-uncased model, which
is further pre-trained on a cybersecurity dataset, which
is then ﬁne-tuned with the ADAPET few-shot method
on the CySecAlert dataset. This resulting model is ﬁ-
nally trained on the few-shot split and evaluated on
the test set of the Microsoft Exchange dataset. Further-
more, in addition to the CySecAlert ﬁne-tuning process,
we also use the ADAPET few-shot method for the ﬁne-
tuning of the Microsoft Exchange Server dataset. The
mentioned components are also inspected within an ab-

lation study, showing their individual contribution to
the overall pipeline.

The evaluation performance is measured in accuracy
and with the F1-score. For every evaluation setting, we
perform ﬁve runs to rule out random factors. The re-
sults are given with the minimum, maximum, mean,
and standard deviation.

4.2 Hyperparameters

As already mentioned, we are using bert-base-uncased
as base model for our experiments. The evaluations
are performed on a NVIDIA A100 with 40 GB GPU
memory. The training runs on the CySecAlert and Mi-
crosoft Exchange dataset are performed with 5 epochs
each. Furthermore, we used a batch size of 48, 100
warmup steps with a warmup ratio of 0.06, a learning
rate of 0.00001, and weight decay of 0.001. As opti-
mization algorithm, we used the Adam algorithm. For
the data augmentation technique we used the GPT-
3 text-davinci-002, which has 175 billion parameters.
The ﬁltering was performed with SBERT with the all-
mpnet-base-v2 model.

4.3 Evaluation

The ﬁrst section of our evaluation is about the data
augmentation process, as we manually inspected the
instances generated by GPT-3. After this, the main
evaluation follows where we compare our methods to
a baseline, state-of-the-art and best case experiment.
Finally, we inspect our method by doing ablation stud-
ies, testing how each component evaluates.

4.3.1 Data Augmentation

Due to our human-in-the-loop approach, we already saw
that the generated instances are of very high quality.
An excerpt of the generated data is given in Table 4.
For research purposes, we were also interested in the
most likely original instances that the model used for
generating speciﬁc instances. This is why we tried to
ﬁnd the training instance with the closest resemblance
to the generated one. We measured the resemblance by
generating sentence embeddings with SBERT (Reimers
and Gurevych, 2019) and comparing them with the co-
sine distance. These counterparts are also given in Ta-
ble 4. These examples show that the data augmenta-
tion method is capable of many diﬀerent transforma-
tions. The ﬁrst example demonstrates that the model
sometimes replaces one or few words with synonyms

7

Fig. 3 Violin plots of the main experimentation setting.

(hosting -> running) or adds context words (#cyber-
security). While in the second example, one can see
that the model is able to paraphrase parts of the orig-
inal instance (Another #ransomware operation known
as ‘Black Kingdom’ is exploiting the [...] -> Black King-
dom ransomware is exploiting the [...] ), in the third ex-
ample the entire instance is paraphrased (Just as pre-
dicted, the Microsoft Exchange exploit chain #Proxy-
Logon now conﬁrmed being used to install ransomware
-> The ProxyLogon vulnerability in Microsoft Exchange
Server is being actively exploited in the wild to install
ransomware). The fourth shown instance is an example
of the method stripping away parts, while still preserv-
ing the label (Thousands of US companies have been
hacked by Chinese hackers using This RCE. Microsoft
Exchange Server Remote Code Execution CVE-2021-
26855 Exploit.). For some generated instances, like the
ﬁfth example, we were not able to ﬁnd similar instances.
The instances might be entirely new based on the in-
terpolation of the given instances and the knowledge of
the underlying model.

Regarding the irrelevant class, we see that many
generated instances are duplicates of the training in-
stances, diﬀering at most by very small changes, such
as removing the hashtag in the ﬁrst example (#Mi-
crosoftExchange Server Attack -> Microsoft Exchange
Server Attack ) or swapping the position of words in the
second example (#Technology #TechNews Microsoft
[...] Authority #Cybersecurity #AiUpNow #techy ->
#Technology #Cybersecurity Microsoft [...] Authority
#AiUp-Now #tech). While the third example, again,
shows an instance where the content is paraphrased,
the last two generated texts have no clear counterpart.

4.3.2 Main Experiments

In our main experiments, we test the whole pipeline
proposed in Section 3. As a quick reminder, our method
includes the multi-level ﬁne-tuning with bert-base-
uncased on cybersecurity data, the CySecAlert dataset
and the actual few-shot learning task with 32 instances,

8

Name

Model

Accuracy

F1

84.69/ 85.36(0.07) /86.02
Best Case
46.26/ 49.65(1.90) /50.58
Baseline
64.89/ 65.89(1.35) /68.05
ADAPET
Our Approach CyBERT 78.54/ 79.13(0.56) /80.03

BERT
BERT
BERT

84.87/ 85.35(0.47) /85.81
25.06/ 58.70(18.81) /67.18
59.30/ 62.54(4.32) /69.81
80.42/ 80.63(0.27) /81.07

Table 2 Detailed evaluation results of the main experiments. The values on the left show the minimum, in the middle the
mean, in brackets the standard deviation, and on the right the maximum value.

as well as the GPT-3-based data augmentation tech-
nique and ADAPET for few-shot training. For a sen-
sible comparison, we ﬁrst follow the standard train-
ing procedure by ﬁne-tuning a bert-base-uncased model
with a classiﬁer head on the few-shot training instances
(baseline). Furthermore, we test a bert-base-uncased
model with the ADAPET method, as it can be re-
garded as the state-of-the-art method for performing
few-shot learning. We also perform a best case evalua-
tion in which we train the bert-base-uncased model on
the full training dataset (1800 instances) to see how a
classiﬁer would perform with enough data. A more de-
tailed analysis of the approach itself can be found in
the ablation studies in Section 4.3.3.

The results of the pipeline experiments are shown
in Table 2. It is observable that the baseline is not able
to learn any meaningful classiﬁcation strategy with the
low dataset, reaching an accuracy of about 50% and
F1 score of 58.70%. ADAPET reaches a signiﬁcantly
higher accuracy with an additive improvement of about
15 points in accuracy and a F1 score of 62.57%. This
is, nevertheless, far from a good classiﬁcation quality
as the best case classiﬁer reaches a F1 score of 85.35%.
With an F1 score of 80.63%, our approach proposed in
this paper could even almost keep up with the best case
classiﬁer. Particularly noteworthy at this point is that
the best case classiﬁer is trained with 1800 instances,
while our approach only has access to 32 instances. Fur-
thermore, our approach improves the current state of
the art with 18.09 points in F1. A look at the violin
plots in Figure 3 shows that both the best case and our
approach have a very good standard deviation, which
means that both are robust to random changes.

The evaluation results show that our approach is
able to identify cyber threat information from which
we can deduce that a new classiﬁer can be trained for
upcoming cybersecurity incidents with limited data.

4.3.3 Ablation Studies

Finally, we want to give a more detailed insight into our
method by showing how each component contributes
to the resulting score. For this purpose, we conducted
three further experiments in which we omitted one com-

Name

F1

Our Approach
→ w/o Augmentation
→ w/o Multi-Level Fine-Tuning
→ w/o ADAPET

80.42/ 80.63(0.27) /81.07
78.48/ 80.33(1.27) /81.49
63.95/ 66.16(1.67) /67.43
65.33/ 71.33(3.62) /75.08

Table 3 Detailed evaluation results of the ablation exper-
iments. The values on the left show the minimum, in the
middle the mean, in brackets the standard deviation, and on
the right the maximum value.

ponent in each case and evaluated the other two compo-
nents. When multi-level ﬁne-tuning is not used, we eval-
uate the BERT base model with the auxiliary data of
the augmentation method and ADAPET for the learn-
ing objective. Without ADAPET, we train the cyberse-
curity pre-trained model on the CySecAlert dataset and
the ﬁnal task (with augmented data) with a classiﬁer
head. In the last experiment, the augmented data are
simply omitted, while training the model in the multi-
level ﬁne-tuning process with ADAPET.

Upon examination of the results, presented in Table
3, it becomes clear that leaving out a component wors-
ens the overall results. The highest loss is reached when
the multi-level ﬁne-tuning component is left out, show-
ing how important it is. This behavior could be due to
the many speciﬁc cybersecurity words trained by the
general language modelling of cybersecurity data (Cy-
BERT) and to ﬁne-tuning by a very related task that al-
ready gives the model an idea of how to distinguish be-
tween relevant and irrelevant content. Furthermore, we
can clearly observe that leaving out ADAPET greatly
worsens the results. When compared with the results
of the main evaluation presented in Table 2, ADAPET
even improves the values signiﬁcantly more than com-
pared to the baseline. This shows that ADAPET needs
a strong base model to be highly beneﬁcial. The small-
est improvement is made with the augmented data. Al-
though the data appeared to be of high quality (see
Section 4.3.1), it did not signiﬁcantly improve the clas-
siﬁer. Nevertheless, a small increase can be reached and
the classiﬁer training got more robust through the ad-
ditional training data (smallest standard deviation).

Table 4 Generated data instances and their most similar original counterparts. The instances created are displayed ﬁrst and
the most similar ones second. URLs are removed from the text.

RT If you’re running Microsoft Exchange Server on premises, you need to take these urgent security steps now.
The zero-day exploits may have already caused a breach of your data. #infosec #cybersecurity #HAFNIUM
http://..

Positive

If you are hosting #MicrosoftExchange on premises you need to take these urgent security steps right now. The
zero-day exploits may have already caused a breach of your data. #infosec #HAFNIUM http://..

RT Black Kingdom ransomware is exploiting the Microsoft Exchange Server ProxyLogon vulnerabilities to
encrypt servers. http://..

9

Please take Information Security seriously. #CyberAttack can bring your reputation down. Another #ran-
somware operation known as ’Black Kingdom’ is exploiting the Microsoft Exchange Server ProxyLogon vulner-
abilities to #encrypt servers. http://..

RT @SecureList: The ProxyLogon vulnerability in Microsoft Exchange Server is being actively exploited in the
wild to install ransomware. http://..

RT Just as predicted, the Microsoft Exchange exploit chain #ProxyLogon now conﬁrmed being used to install
ransomware #DEARCRY http://..

RT RT @hackerfantastic: Microsoft Exchange Server Remote Code Execution CVE-2021-26855 Exploit.
#BugBounty #RCE #infosec http://..

RT Thousands of US companies have been hacked by Chinese hackers using This RCE.
Microsoft Exchange Server Remote Code Execution CVE-2021-26855 Exploit.
#BugBounty #RCE #infosec http://..

RT @ryan a h: Microsoft just released their quarterly updates which include a patch for the Exchange zero-day.
You can ﬁnd more information here: http://..

If you are hosting #MicrosoftExchange on premises you need to take these urgent security steps right now. The
zero-day exploits may have already caused a breach of your data. #infosec #HAFNIUM http://..

Microsoft Exchange Server Attack Escalation Prompts #Patching Panic
#cybersecurity #vulnerabilities http://..

#MicrosoftExchange Server Attack Escalation Prompts #Patching Panic
#cybersecurity #vulnerabilities http://..

Negative

#Technology #Cybersecurity Microsoft Exchange Hackers Also Breached European Banking Authority #AiUp-
Now #techy http://..

#Technology #TechNews Microsoft Exchange Hackers Also Breached European Banking Authority #Cyber-
security #AiUpNow #techy via http://..

RT Microsoft Exchange Server has been hacked – here’s what you need to know http://..

RT Here’s what we know so far about the massive Microsoft Exchange hack http://..

Microsoft Exchange Server Flaws Expose Millions of Emails to Attack http://..

RT Here’s what we know so far about the massive Microsoft Exchange hack http://..

Protected: Microsoft Exchange Server Attacks Escalate to Government, Healthcare and Financial Institutions
http://..

The Microsoft Exchange hacks: How they started and where we are http://..

5 Conclusion and Discussion

CTI, the collection of evidence-based knowledge of cy-
bersecurity threats, is highly relevant for identifying
and remediating security incidents. Professionals, se-
curity providers, CERTs, as well as many others in
the cybersecurity realm can gain important informa-

tion about the incidents, such as how severe they may
be, which software and systems are aﬀected, how to be
protected, and if exploits exist. The challenges lie in
the information overload and the high dynamics asso-
ciated with every new threat event. To our knowledge,
this is the ﬁrst work to address this issue by propos-
ing a framework for specialized CTI. It consists of sev-

10

eral components that allow the end user to label only
a few data instances (tested here with 32 instances)
to obtain a classiﬁer that is comparable to one trained
with 1800 instances. We also constructed a dataset la-
beled by three cybersecurity experts showing that this
method indeed overcomes the problem of information
overload and addresses high dynamics by being easily
adaptable to new incidents.

5.1 Practical, Theoretical, and Empirical
Contributions

Considering our ﬁndings, the study revealed (P) prac-
tical, (T) theoretical, and (E) empirical contributions:
(P) A novel pipeline for detecting special-
ized cyber threat information. Our work provides
an approach to the detection of speciﬁc cyber threat
information that is aligned with the circumstances of
such events. These circumstances include that infor-
mation has to be gathered fast in the early stages of
the events and that security institutions and experts
do not have the time and capacity to label many in-
stances. Therefore, we combine few-shot learning with
multi-level ﬁne-tuning and data augmentation to pro-
duce classiﬁers that only need few instances to per-
form with high quality. For few-shot learning we uti-
lize ADAPET by Tam et al. (2021) combined with the
multi-level ﬁne-tuning process. For data augmentation
we use GPT-3 to create instances with novel linguis-
tic patterns. Our pipeline reaches a F1-score of 80.63
on a specialized cyber threat dataset, which is 21.93
points above the score of a classical learning scheme.
Other work, such as the cyber threat detection systems
of Riebe et al. (2021b) or Le Sceller et al. (2017), allow
for coarse-grained information gathering. To the best of
our knowledge, our system is the ﬁrst to provide rapid
detection of specialized cyber threat information.

(T) New few-shot learning technique based
on multi-level ﬁne-tuning. We propose a novel few-
shot learning approach for creating classiﬁers of high
quality with a smaller amount of training data. The
idea behind this approach is to ﬁne-tune a machine
learning model in several levels where enough data is
available (see Figure 2). In our study we ﬁrst further
trained a BERT model on a general cybersecurity cor-
pus. This model was then trained on a general Twitter
cybersecurity relevance dataset. From this point, the
model has a fundamental understanding of cybersecu-
rity texts and is also able to distinguish cybersecurity-
related content from irrelevant content. With this pre-
trained knowledge, the model only needs few data in-
stances to be able to diﬀerentiate speciﬁc cybersecurity
content. As shown in this study, this new technique can

also be combined with other techniques like ADAPET
or data augmentation to further reduce the amount of
needed training data. However, we show that this multi-
stage ﬁne-tuning approach has the greatest impact on
classiﬁcation quality of all techniques (+14.47 F1, see
Table 3). The multi-level ﬁne-tuning approach signiﬁ-
cantly advances research in few-shot learning, as it al-
lows for a much higher model quality and at the same
time can be combined with previous few-shot studies,
such as ADAPET (Tam et al., 2021), DART (Zhang
et al., 2022), or PERFECT (Mahabadi et al., 2022).

(T) New insights on data augmentation with
large pre-trained language models. In our study,
we also implemented a data augmentation technique
that combines the works of Yoo et al. (2021) and Bayer
et al. (2021). As in the former, we used the large lan-
guage model GPT-3 with a prompting strategy and ﬁl-
tered the generated instances with a human-in-the-loop
technique, as in the latter. The idea is that GPT-3 can
create instances with a very high degree of novelty, re-
sulting in some very valuable instances. However, this
novelty comes with the problem of poor label preser-
vation, as the instances may be too far away from the
class. For this reason, we also introduced this ﬁlter-
ing strategy where the original labeled data of a class
is compared with the generated data and those that
are too far away from the original data are discarded.
The boundary is determined by an expert who exam-
ines those instances close to a predeﬁned boundary. As
shown in section 4.3.1 and table 4, this procedure gen-
erates instances with very diﬀerent transformation pat-
terns, including word substitution, paraphrasing, and
partial removal. It even leads to instances that are en-
tirely novel. However, in section 4.3.3, we showed that
omitting this method from the overall pipeline only
slightly reduces the resulting score. This means that the
model learns very little from the augmented data when
multi-level ﬁne-tuning and ADAPET are already used.
Nevertheless, the evaluation results show a reduction
in the standard deviation, which shows that the model
has become more robust with the artiﬁcial data.

(E) A specialized CTI dataset for further re-
search purposes. In this study we created a CTI
dataset based on the 2021 Microsoft Exchange Server
data breach. The dataset was constructed by three ex-
perts. The guidelines have been revised several times
in an attempt to ﬂesh out the concept of cyber threat
analysis as much as possible. Along with the code and
the dataset, the guidelines are available in the reposi-
tory. All annotators reached a good intercoder reliabil-
ity showing that the guidelines and the general annota-
tion process was successful. Further research can beneﬁt
from this dataset as it is, to our knowledge, the ﬁrst to

contain a relevance coding regarding CTI in Twitter in
relation to a speciﬁc cybersecurity event.

5.2 Limitations and Outlook

In terms of the overall concept, we look forward to re-
search studies testing the performance of this approach
in other domains. For example, it would be interesting
to see if the same improvements can be achieved in med-
ical or crisis domains, where data is also scarce. More-
over, our experiments are limited to the BERT base
model. It would be interesting to see if the improve-
ments are as high when a larger model like RoBERTa
(Liu et al., 2019) is used. Likewise, one could also test
other language models for the data augmentation tech-
nique. Especially interesting would be to test if open
source models, like GPT-NeoX-20B (Black et al., 2022),
reach a good augmentation performance.

A part of our experiments was to ﬁne-tune the
model on the CySecAlert dataset of Riebe et al.
(2021b). The authors of this work propose an active
learning component to achieve high classiﬁcation scores
with less data. With a view to future research, it might
be sensible to also include active learning into the con-
cept of our approach to further increase the classiﬁ-
cation quality. In practice, our approach would in the
worst case lead to users labelling very similar examples,
resulting in poor execution of data augmentation and
poor classiﬁcation quality, which can happen quickly
when labelling such a small amount of data. Therefore,
an active learning system could help to collect very dif-
ferent examples. Otherwise, experts can also be trained
to label diverse examples.

Acknowledgements This work has been co-funded by
the German Federal Ministry of Education and Research
(BMBF) in the project CYWARN (13N15407) and funded
by the Deutsche Forschungsgemeinschaft (DFG, German Re-
search Foundation) – SFB 1119 (CROSSING) – 236615297,
as well as the German Federal Ministry of Education and
Research and the Hessian Ministry of Higher Education,
Research, Science and the Arts within their joint support
of the National Research Center for Applied Cybersecurity
ATHENE. Calculations for this research were conducted on
the Lichtenberg high performance computer of the TU Darm-
stadt.

References

Abu MS, Selamat SR, Ariﬃn A, Yusof R (2018) Cyber
threat intelligence–issue and challenges. Indonesian
Journal of Electrical Engineering and Computer Sci-
ence 10(1):371–379

11

Anaby-Tavor A, Carmeli B, Goldbraich E, Kantor A,
Kour G, Shlomov S, Tepper N, Zwerdling N (2020)
Do not have enough data? Deep learning to the res-
cue! Proceedings of the AAAI URL http://arxiv.org/
abs/1911.03118

Bayer M, Kaufhold MA, Buchhold B, Keller M,
Dallmeyer J, Reuter C (2021) Data Augmentation in
Natural Language Processing: A Novel Text Gener-
ation Approach for Long and Short Text Classiﬁers.
International Journal of Machine Learning and Cy-
bernetics (IJMLC) DOI 10.1007/s13042-022-01553-
3, URL http://arxiv.org/abs/2103.14453

Bayer M, Kaufhold MA, Reuter C (2022) A Sur-
vey on Data Augmentation for Text Classiﬁca-
tion. ACM Computing Surveys p 3544558, DOI
10.1145/3544558, URL https://dl.acm.org/doi/10.
1145/3544558

Belinkov Y, Bisk Y (2018) Synthetic and natural noise
both break neural machine translation. In: Proceed-
ings of ICLR

Beltagy I, Lo K, Cohan A (2019) SciBERT: A Pre-
trained Language Model for Scientiﬁc Text. URL
http://arxiv.org/abs/1903.10676, arXiv:1903.10676
[cs]

Black S, Biderman S, Hallahan E, Anthony Q, Gao L,
Golding L, He H, Leahy C, McDonell K, Phang J,
Pieler M, Prashanth US, Purohit S, Reynolds L, Tow
J, Wang B, Weinbach S (2022) GPT-NeoX-20B: An
Open-Source Autoregressive Language Model. URL
http://arxiv.org/abs/2204.06745

Bragg J, Cohan A, Lo K, Beltagy I (2021) FLEX: Uni-

fying Evaluation for Few-Shot NLP. arXiv p 14

Brown TB, Mann B, Ryder N, Subbiah M, Kaplan
J, Dhariwal P, Neelakantan A, Shyam P, Sastry G,
Askell A, Agarwal S, Herbert-Voss A, Krueger G,
Henighan T, Child R, Ramesh A, Ziegler DM, Wu
J, Winter C, Hesse C, Chen M, Sigler E, Litwin
M, Gray S, Chess B, Clark J, Berner C, McCan-
dlish S, Radford A, Sutskever I, Amodei D (2020)
Language models are few-shot learners. In: NeurIPS,
URL http://arxiv.org/abs/2005.14165

Chatterjee S, Thekdi S (2020) An iterative learning
and inference approach to managing dynamic cy-
ber vulnerabilities of complex systems. Reliability
Engineering & System Safety 193:106664, DOI
https://doi.org/10.1016/j.ress.2019.106664,
https://www.sciencedirect.com/science/article/pii/
S0951832018314558

URL

Devlin J, Chang MW, Lee K, Toutanova K (2018)
BERT: Pre-training of deep bidirectional transform-
ers for language understanding (Mlm), URL http:
//arxiv.org/abs/1810.04805

12

Dion´ısio N, Alves F, Ferreira PM, Bessani A (2020) To-
wards end-to-end Cyberthreat Detection from Twit-
ter using Multi-Task Learning. In: 2020 International
Joint Conference on Neural Networks (IJCNN), pp
1–8, DOI 10.1109/IJCNN48605.2020.9207159, iSSN:
2161-4407

Fang Y, Gao J, Liu Z, Huang C (2020) Detect-
ing Cyber Threat Event from Twitter Using ID-
CNN and BiLSTM. Applied Sciences 10(17):5922,
DOI 10.3390/app10175922, URL https://www.mdpi.
com/2076-3417/10/17/5922

Gao T, Fisch A, Chen D (2021) Making Pre-trained
Language Models Better Few-shot Learners. URL
http://arxiv.org/abs/2012.15723

Jiang H, He P, Chen W, Liu X, Gao J, Zhao T
(2020) SMART: Robust and Eﬃcient Fine-Tuning
for Pre-trained Natural Language Models through
Principled Regularized Optimization. In: Proceed-
ings of the 58th Annual Meeting of the Association
for Computational Linguistics, Association for Com-
putational Linguistics, Online, pp 2177–2190, DOI
10.18653/v1/2020.acl-main.197, URL https://www.
aclweb.org/anthology/2020.acl-main.197

Kaufhold MA, Basyurt AS, Eyilmez K, Ag V,
St¨ottinger M, Reuter C, Sercan A (2022) Cyber
Threat Observatory: Design and Evaluation of an
Interactive Dashboard for Computer Emergency Re-
sponse Teams. ECIS 2022 p 18

Lan Z, Chen M, Goodman S, Gimpel K, Sharma
P, Soricut R (2020) ALBERT: A Lite BERT
for Self-supervised Learning of Language Repre-
sentations. URL http://arxiv.org/abs/1909.11942,
arXiv:1909.11942 [cs]

Le Sceller Q, Karbab EB, Debbabi M, Iqbal F (2017)
Sonar: Automatic detection of cyber security events
over the twitter stream. In: Proceedings of the 12th
International Conference on Availability, Reliabil-
ity and Security, Association for Computing Ma-
chinery, New York, NY, USA, ARES ’17, DOI
10.1145/3098954.3098992, URL https://doi.org/10.
1145/3098954.3098992

language

Lee J, Yoon W, Kim S, Kim D, Kim S, So
CH, Kang J (2019) BioBERT: a pre-trained
model
biomedical
representation
for biomedical
text mining. Bioinformatics p
btz682, DOI 10.1093/bioinformatics/btz682, URL
https://academic.oup.com/bioinformatics/advance-
article/doi/10.1093/bioinformatics/btz682/5566506
Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy
O, Lewis M, Zettlemoyer L, Stoyanov V, Allen PG
(2019) RoBERTa: A Robustly Optimized BERT Pre-
training Approach. Tech. rep., URL https://github.
com/pytorch/fairseq

Longpre S, Wang Y, DuBois C (2020) How eﬀective
is task-agnostic data augmentation for pretrained
transformers? In: Findings of EMNLP

Mahabadi RK, Zettlemoyer L, Henderson J, Saeidi M,
Mathias L, Stoyanov V, Yazdani M (2022) PER-
FECT: Prompt-free and Eﬃcient Few-shot Learning
with Language Models. URL http://arxiv.org/abs/
2204.01172, arXiv:2204.01172 [cs]

Martin L, Muller B, Ortiz Su´arez PJ, Dupont Y,
Romary L, de la Clergerie ´E, Seddah D, Sagot
B (2020) CamemBERT: a tasty French language
model. In: Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguis-
tics, Association for Computational Linguistics, On-
line, pp 7203–7219, URL https://www.aclweb.org/
anthology/2020.acl-main.645

McMillan R (2013) Deﬁnition: Threat Intelligence.
https://www.gartner.com/en/documents/

URL
2487216

Mittal S, Das PK, Mulwad V, Joshi A, Finin T (2016)
Cybertwitter: Using twitter to generate alerts for
cybersecurity threats and vulnerabilities. In: 2016
IEEE/ACM International Conference on Advances
in Social Networks Analysis and Mining (ASONAM),
IEEE, pp 860–867

Mosolova AV, Fomin VV, Bondarenko IY (2018) Text
augmentation for neural networks. CEUR Workshop
Proceedings 2268:104–109

Pan SJ (2020) Transfer learning. Learning 21:1–2
Queiroz Abonizio H, Barbon Junior S (2020) Pre-
trained Data Augmentation for Text Classiﬁcation.
In: Lecture Notes in Computer Science (including
subseries Lecture Notes in Artiﬁcial Intelligence and
Lecture Notes in Bioinformatics), Springer Science
and Business Media Deutschland GmbH, vol 12319
LNAI, pp 551–565, DOI 10.1007/978-3-030-61377-
8 38, iSSN: 16113349

Reimers N, Gurevych I (2019) Sentence-BERT: Sen-
tence Embeddings using Siamese BERT-Networks.
DOI 10.18653/v1/d19-1410

Riebe T, Kaufhold MA, Reuter C (2021a) The Im-
pact of Organizational Structure and Technology
Use on Collaborative Practices in Computer Emer-
gency Response Teams: An Empirical Study. Pro-
ceedings of the ACM on Human-Computer Inter-
action 5(CSCW2):1–30, DOI 10.1145/3479865, URL
https://dl.acm.org/doi/10.1145/3479865

Riebe T, Wirth T, Bayer M, K¨uhn P, Kaufhold MA,
Knauthe V, Guthe S, Reuter C (2021b) CySecAlert:
An Alert Generation System for Cyber Security
Events Using Open Source Intelligence Data. In: Gao
D, Li Q, Guan X, Liao X (eds) Information and Com-
munications Security, Springer International Publish-

13

Association for Computational Linguistics, Punta
Cana, Dominican Republic, pp 2225–2239, DOI
10.18653/v1/2021.ﬁndings-emnlp.192, URL https://
aclanthology.org/2021.ﬁndings-emnlp.192

Zhang N, Li L, Chen X, Deng S, Bi Z, Tan C,
Huang F, Chen H (2022) Diﬀerentiable Prompt
Makes Pre-trained Language Models Better Few-
shot Learners. URL http://arxiv.org/abs/2108.
13161, arXiv:2108.13161 [cs]

ing, Cham, Lecture Notes in Computer Science, pp
429–446, DOI 10.1007/978-3-030-86890-1 24

Rodriguez A, Okamura K (2019) Generating real time
cyber situational awareness information through so-
cial media data mining. In: 2019 IEEE 43rd an-
nual computer software and applications conference
(COMPSAC), IEEE, vol 2, pp 502–507

Sabottke C, Suciu O, Dumitras T (2015) Vulner-
ability disclosure in the age of
social media:
Exploiting twitter for predicting Real-World ex-
ploits.
In: 24th USENIX Security Symposium
(USENIX Security 15), USENIX Association, Wash-
ington, D.C., pp 1041–1056, URL https://www.
usenix.org/conference/usenixsecurity15/technical-
sessions/presentation/sabottke

Schick T, Sch¨utze H (2021) Exploiting Cloze Ques-
tions for Few Shot Text Classiﬁcation and Natu-
ral Language Inference. URL http://arxiv.org/abs/
2001.07676, arXiv:2001.07676 [cs]

Sun L, Xia C, Yin W, Liang T, Yu PS, He L (2020)
Mixup-transfomer: Dynamic data augmentation for
NLP tasks. DOI 10.18653/v1/2020.coling-main.305,
iSSN: 23318422 Publication Title: arXiv eprint:
2010.02394

Tam D, Menon RR, Bansal M, Srivastava S, Raﬀel C
(2021) Improving and Simplifying Pattern Exploit-
ing Training. URL http://arxiv.org/abs/2103.11955,
number: arXiv:2103.11955 arXiv:2103.11955 [cs]
Taylor WL (1953) “Cloze Procedure”: A New Tool
for Measuring Readability. Journalism Quarterly
30(4):415–433, DOI 10.1177/107769905303000401,
http://journals.sagepub.com/doi/10.1177/
URL
107769905303000401

Torrey L, Shavlik J (2010) Transfer learning. In: Hand-
book of research on machine learning applications
and trends: algorithms, methods, and techniques, IGI
global, pp 242–264

Tounsi W, Rais H (2018) A survey on technical
threat intelligence in the age of sophisticated cyber
attacks. Computers & Security 72:212–233, DOI
https://doi.org/10.1016/j.cose.2017.09.001,
https://www.sciencedirect.com/science/article/pii/
S0167404817301839

URL

Wagner TD, Mahbub K, Palomar E, Abdallah
AE (2019) Cyber threat intelligence sharing: Sur-
vey and research directions. Computers & Secu-
rity 87:101589, DOI https://doi.org/10.1016/j.cose.
2019.101589, URL https://www.sciencedirect.com/
science/article/pii/S016740481830467X

Yoo KM, Park D, Kang J, Lee SW, Park W (2021)
GPT3Mix: Leveraging Large-scale Language Models
for Text Augmentation. In: Findings of the Associ-
ation for Computational Linguistics: EMNLP 2021,

