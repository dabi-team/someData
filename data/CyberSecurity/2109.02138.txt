A Transformer-based Model to Detect Phishing
URLs

Pingfan Xu
School of Computer Science
University of Guelph
Guelph, Canada
pingfan@uoguelph.ca

1
2
0
2

p
e
S
5

]

R
C
.
s
c
[

1
v
8
3
1
2
0
.
9
0
1
2
:
v
i
X
r
a

Abstract—Phishing attacks are among emerging security issues
that recently draws signiﬁcant attention in the cyber security
community. There are numerous existing approaches for phishing
URL detection. However, malicious URL detection is still a
research hotspot because attackers can bypass newly introduced
detection mechanisms by changing their tactics. This paper will
introduce a transformer-based malicious URL detection model,
which has signiﬁcant accuracy and outperforms current detection
methods. We conduct experiments and compare them with six
existing classical detection models. Experiments demonstrate that
our transformer-based model is the best performing model from
all perspectives among the seven models and achieves 97.3% of
detection accuracy.

Index Terms—Transformer, Phishing URL Detection, Machine

Learning, Deep Learning

I. INTRODUCTION

Phishing is a type of attack leveraged by cyber criminals
which impersonate some legitimate organizations’ websites
or URL to deceive the victims [1]. The attackers will use
somebody or some company’s identity that the people trust
to send them spam emails or messages embedded with those
phishing links [2]. The count of phishing-related cyber crimes
incidents proliferation in the last several decade. It was men-
tioned in Verizon Data Breach Investigation Report (DBIR)
that phishing attacks caused more than 22% of the breaches
in 2020 [3]. The consequent ransomware was estimated to cost
over 8 billion USD all over the world [4]. Among the 22% of
the breaches in 2020 caused by phishing attack, 99% of them
were delivered through emails or websites. In December 2013,
42890 unique phishing websites were recorded and reported
worldwide [5]. Since phishing emails and website both may
involve malicious URLs, the exploration of malicious URL
detection has double beneﬁts for both anti-email-phishing and
anti-website-phishing.

In order to mitigate phishing attacks,

there are already
numerous anti-phishing solutions in practice. As for modern
web browsers, there are indicators as built-in countermeasures
for a phishing website. For instance, browsers would validate
the website’s SSL certiﬁcate and provide the result by dis-
playing a special indicator icon on the address bar for users’
references. Unfortunately,
this validation process could be
easily bypassed if the attacker used an URL visually similar to
the original site’s address. Studies showed that these indicators

might be ineffective and even put the users into a higher-
risk situation [6]–[8]. Another commonly employed method
against phishing is two-factor authentication. It introduces an
extra security layer. One of the widely used techniques for
two-factor authentication (2FA) is sending real-time generated
veriﬁcation code via SMS [9]. Even though 2FA may protect
against phishing attacks, it typically requires a different device.
Additionally,
there are researches found possible ways to
bypass 2FA as well [10]. Therefore, it would be critical to
discover reliable and lightweight malicious URLs detection
solutions to identify malicious URLs on time to prevent severe
consequences and potential losses.

This paper’s contributions are as following:

•

•

•

We reviewed and categorized the typical existing ap-
proaches for phishing URL detection.
We proposed an innovative transformer-based model as a
light-weight but high performance solution for malicious
URL prediction.
We evaluated our proposed model by comparing its
performance with six other existing classical models’. We
proved that our model has better performance competing
with these other models.

In this paper, Section II provides a background introduction
and literature reviews of the existing anti-phishing solutions
in practice. Then, our proposed solution and its design details
will be illustrated at Section III. Afterwards Section IV will
explain how we train our Transformer model. The experiment
section will be followed by the model evaluation section
where we mainly compare the performance of six machine
learning models (Decision Tree, Random Forest, Multi-layer
Perceptrons, XGBoost, Support Vector Machine, Auto En-
coder) implemented by Sundari and her team [11] to our
transformer model. Finally, we will provide some suggestions
to improve our proposed solution further at Section VI.

II. LITERATURE REVIEW AND BACKGROUND

In recent years, researchers have explored a massive amount
of possible solutions for phishing website detection. We
roughly categorized the existing detection techniques into
content-based, property-based, and URL-based approaches tar-
geting different websites. Each approach has its advantages
and disadvantages. Several typical pieces of research under

 
 
 
 
 
 
each approach category will be reviewed in this section.
Additionally, as one innovative solution under URL-based
approaches, the transformer model will be demonstrated with
its background.

A. Literature Review

Content-based phishing website detection may be one of the
most intuitive techniques among the three. It might also be the
method closest to how the average person gets to determine
phishing sites. Firstly, people would visually identify the iden-
tity that the images and texts on the website suggested. With
the identiﬁed site identity, they could query the corresponding
URL of the identity through a trusted source. The website
would be considered a benign one only when the queried
URL matches the URL shown on the address bar. The logic
behind content-based phishing website detection techniques
was the same. For example, Chiew et al. utilized the website
logo for phishing site detection [12]. The researchers employed
Google image search on extracted logos from the website to
get the portrayed site identity. The phishing detection result
was determined through the consistency check of the portrayed
site identity and the actual domain of the testing website.
Their proposed solution provided an outstanding performance
with 99.8% true positive rate and 87.0% true negative rate.
Additionally, the texts shown on a site could also be used for
phishing detection. Yang et al. proposed a multidimensional
included vectorizing
feature-based detection technique that
texts on the page for determine the possibility that the vec-
torized text was from a phishing site [13]. Their approach
achieved 98.99% in its accuracy. Similarly, there was another
approach using the same methodology and the website favicon
for phishing detection [14] where its true positive rate reached
96.93%.

In addition to visual and literal contents on a web page,
other properties or meta-data information hidden to every-
day users could also be employed for phishing detection.
The property-based approach generally pays attention to the
abnormal behaviors of a website. For example, Pan and
Ding used six abnormal properties, including Abnormal URL,
Abnormal DNS record, Abnormal Anchors, Server-Form-
Handler, Abnormal cookie, and Abnormal Secure Sockets
Layer(SSL)-certiﬁcate,
to conduct phishing checking [15].
Their proposed model gives an average false positive rate as
low as 4%. Since studies suggested the number of redirect
pages contained in malicious sites is between 2 to 4 [16],
the count of redirecting times was proposed as one possible
detecting approach. To avoid being easily identiﬁed by end-
users inspecting source code, attackers may use JavaScript to
disable the mouse right-click function [17]. Hence, uncommon
disabling of browser functionalities could be another standard
for detection. Furthermore, other website properties related
to its domain information can be utilized. Properties like the
domain age, domain name, and IP address were also proven
to have positive contributions to phishing detection in recent
researches [18], [19].

Besides content-based and property-based approaches, the
URL-based method is also a hot research topic in the ﬁeld
of phishing detection. URL-based approaches take advantage
of URL analysis to conduct phishing predictions. Researchers
have tried different URL-based techniques to detect malicious
URLs. Most of them utilize hand-crafted features extracted
from the URLs. Ma et al. proposed a detection method from
the lexical and host-based features in 2011, which detects ma-
licious Web sites from a balanced dataset with 99% accuracy
[20]. Choi et al. identiﬁed malicious URLs with six manually
extracted class features from URLs: lexical, link popularity,
webpage content, DNS, DNS ﬂuxiness, and Network [21].
Their solution was capable of malicious URL detection with
over 98% of accuracy. In 2012, Zhang and Wang developed an
accurate, real-time, and language-independent malicious URL
classiﬁer with hosted and lexical features of target URLs [22].
A model based on word n-gram and Markov Chains that could
generate proactive blacklists of malicious URLs was designed
by Marchal et al. in 2012 [23]. Their approach to preventing
phishing scams could be considered the opposite of traditional
detections. Pao et al. proposed a detection method that uti-
lizes the estimation of conditional Kolmogorov complexity of
URLs [24]. Their approach could independently handle large
amounts of input URLs very efﬁciently with high accuracy.
Additionally, their model could be used in conjunction with
other URL-feature-based detection techniques to improve the
prediction accuracy further.

Since URLs are essentially pieces of texts, researchers
started exploring the possibilities of utilizing Natural Lan-
guage Processing (NLP) techniques for URL-based phishing
detection. As one of the most
innovative NLP models in
recent years, the transformer model has also been applied to
phishing site detection. Researches applied transformer model
on malicious URL detection turn out to have outstanding ac-
curacy. It was proven that the novel transformer model would
have comparably good performance to the more traditional
approaches [25].

B. Background

In recent years, Transformer is a hot research topic in
handling tasks closely related to characters. One of the most
crucial concepts in the transformer model is called attention.
In 2017, the Google machine translation team published a
research paper, “Attention Is All You Need.” [26] It completely
subverted some traditional network structures such as RNN
and CNN and only applied the attention mechanism to perform
machine translation tasks. The transformer model had a better
performance than other machine learning models, and this
let the attention technique became a research hotspot. Later,
Devlin et al.
introduced an improved language processing
model, Bidirectional Encoder Representations from Trans-
formers (BERT) [27], based on the Transformer. It is different
from the standard language representative models because
BERT is used to pre-train deep bidirectional representations
to produce an encoder with hidden states that can be used for
various NLP ﬁne-tuning tasks. In 2018, Radford et al. from

OpenAI came up with the Generative Pre-trained Transformer
(GPT) series models [28]. Their approach is similar to BERT
but utilizes L - R masked modeling. The decoder stack per-
forms a prediction on the following elements of the sequence
from the previous token.

where query (Q), key (K), value(V) and output are all matrices
and dk is the dimension of input queries and keys.

Fig. 2. Self-attention mechanism.

The multi-head attention (as depicted in Fig. 3) can then be

described as:

M ultiHead(Q, K, V ) = Concat(head1, ..., headh)W O

(2)

where

Q, KWi

K, V Wi

V ),

Q

K

headi = Attention(QWi
Rdmodel×
Wi
Rdmodel×
Wi
Rdmodel×
Wi
Rhdv×
W O

dk ,
dk ,
dv ,
dmodel .

V

∈
∈
∈
∈

Fig. 1. Standard structure of Transformer.

A typical transformer model contains two stacks: the en-
coder and the decoder. Each stack of it includes an embedding
layer, positional encoding, multi-headed attention layers, feed-
forward layers, residual connections, and masks (as depicted
text and makes
in Fig. 1). The encoder takes the input
it model-readable through input embedding and positional
encoding. The encoder then applied several tensors to the
processed input. The tensors are made of multi-head attention
layers connected to feed-forward layers, which provides the
self-attention feature to the model as a combination. The
multi-head attention layers are the collection of identical
self-attention mechanisms. Each self-attention mechanism (as
depicted in Fig. 2) can be described as a mapping:

Attention(Q, K, V ) = sof tmax(

QK T
√dk

)

(1)

Fig. 3. Multi-head attention.

Then, the result from multi-head attention is passed to a
fully connected feed-forward network (FFN) containing two
linear transformations with a Rectiﬁed Linear Unit (ReLU) as
activation function in between:

F F N (x) = ReLU (W1x + b1)W2 + b2

(3)

Figure1:TheTransformer-modelarchitecture.3.1EncoderandDecoderStacksEncoder:TheencoderiscomposedofastackofN=6identicallayers.Eachlayerhastwosub-layers.Theﬁrstisamulti-headself-attentionmechanism,andthesecondisasimple,position-wisefullyconnectedfeed-forwardnetwork.Weemployaresidualconnection[11]aroundeachofthetwosub-layers,followedbylayernormalization[1].Thatis,theoutputofeachsub-layerisLayerNorm(x+Sublayer(x)),whereSublayer(x)isthefunctionimplementedbythesub-layeritself.Tofacilitatetheseresidualconnections,allsub-layersinthemodel,aswellastheembeddinglayers,produceoutputsofdimensiondmodel=512.Decoder:ThedecoderisalsocomposedofastackofN=6identicallayers.Inadditiontothetwosub-layersineachencoderlayer,thedecoderinsertsathirdsub-layer,whichperformsmulti-headattentionovertheoutputoftheencoderstack.Similartotheencoder,weemployresidualconnectionsaroundeachofthesub-layers,followedbylayernormalization.Wealsomodifytheself-attentionsub-layerinthedecoderstacktopreventpositionsfromattendingtosubsequentpositions.Thismasking,combinedwithfactthattheoutputembeddingsareoffsetbyoneposition,ensuresthatthepredictionsforpositionicandependonlyontheknownoutputsatpositionslessthani.3.2AttentionAnattentionfunctioncanbedescribedasmappingaqueryandasetofkey-valuepairstoanoutput,wherethequery,keys,values,andoutputareallvectors.Theoutputiscomputedasaweightedsumofthevalues,wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionofthequerywiththecorrespondingkey.3ScaledDot-ProductAttentionMulti-HeadAttentionFigure2:(left)ScaledDot-ProductAttention.(right)Multi-HeadAttentionconsistsofseveralattentionlayersrunninginparallel.3.2.1ScaledDot-ProductAttentionWecallourparticularattention"ScaledDot-ProductAttention"(Figure2).Theinputconsistsofqueriesandkeysofdimensiondk,andvaluesofdimensiondv.Wecomputethedotproductsofthequerywithallkeys,divideeachbypdk,andapplyasoftmaxfunctiontoobtaintheweightsonthevalues.Inpractice,wecomputetheattentionfunctiononasetofqueriessimultaneously,packedtogetherintoamatrixQ.ThekeysandvaluesarealsopackedtogetherintomatricesKandV.Wecomputethematrixofoutputsas:Attention(Q,K,V)=softmax(QKTpdk)V(1)Thetwomostcommonlyusedattentionfunctionsareadditiveattention[2],anddot-product(multi-plicative)attention.Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactorof1pdk.Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwithasinglehiddenlayer.Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionismuchfasterandmorespace-efﬁcientinpractice,sinceitcanbeimplementedusinghighlyoptimizedmatrixmultiplicationcode.Whileforsmallvaluesofdkthetwomechanismsperformsimilarly,additiveattentionoutperformsdotproductattentionwithoutscalingforlargervaluesofdk[3].Wesuspectthatforlargevaluesofdk,thedotproductsgrowlargeinmagnitude,pushingthesoftmaxfunctionintoregionswhereithasextremelysmallgradients4.Tocounteractthiseffect,wescalethedotproductsby1pdk.3.2.2Multi-HeadAttentionInsteadofperformingasingleattentionfunctionwithdmodel-dimensionalkeys,valuesandqueries,wefounditbeneﬁcialtolinearlyprojectthequeries,keysandvalueshtimeswithdifferent,learnedlinearprojectionstodk,dkanddvdimensions,respectively.Oneachoftheseprojectedversionsofqueries,keysandvalueswethenperformtheattentionfunctioninparallel,yieldingdv-dimensionaloutputvalues.Theseareconcatenatedandonceagainprojected,resultingintheﬁnalvalues,asdepictedinFigure2.4Toillustratewhythedotproductsgetlarge,assumethatthecomponentsofqandkareindependentrandomvariableswithmean0andvariance1.Thentheirdotproduct,q·k=Pdki=1qiki,hasmean0andvariancedk.4ScaledDot-ProductAttentionMulti-HeadAttentionFigure2:(left)ScaledDot-ProductAttention.(right)Multi-HeadAttentionconsistsofseveralattentionlayersrunninginparallel.3.2.1ScaledDot-ProductAttentionWecallourparticularattention"ScaledDot-ProductAttention"(Figure2).Theinputconsistsofqueriesandkeysofdimensiondk,andvaluesofdimensiondv.Wecomputethedotproductsofthequerywithallkeys,divideeachbypdk,andapplyasoftmaxfunctiontoobtaintheweightsonthevalues.Inpractice,wecomputetheattentionfunctiononasetofqueriessimultaneously,packedtogetherintoamatrixQ.ThekeysandvaluesarealsopackedtogetherintomatricesKandV.Wecomputethematrixofoutputsas:Attention(Q,K,V)=softmax(QKTpdk)V(1)Thetwomostcommonlyusedattentionfunctionsareadditiveattention[2],anddot-product(multi-plicative)attention.Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactorof1pdk.Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwithasinglehiddenlayer.Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionismuchfasterandmorespace-efﬁcientinpractice,sinceitcanbeimplementedusinghighlyoptimizedmatrixmultiplicationcode.Whileforsmallvaluesofdkthetwomechanismsperformsimilarly,additiveattentionoutperformsdotproductattentionwithoutscalingforlargervaluesofdk[3].Wesuspectthatforlargevaluesofdk,thedotproductsgrowlargeinmagnitude,pushingthesoftmaxfunctionintoregionswhereithasextremelysmallgradients4.Tocounteractthiseffect,wescalethedotproductsby1pdk.3.2.2Multi-HeadAttentionInsteadofperformingasingleattentionfunctionwithdmodel-dimensionalkeys,valuesandqueries,wefounditbeneﬁcialtolinearlyprojectthequeries,keysandvalueshtimeswithdifferent,learnedlinearprojectionstodk,dkanddvdimensions,respectively.Oneachoftheseprojectedversionsofqueries,keysandvalueswethenperformtheattentionfunctioninparallel,yieldingdv-dimensionaloutputvalues.Theseareconcatenatedandonceagainprojected,resultingintheﬁnalvalues,asdepictedinFigure2.4Toillustratewhythedotproductsgetlarge,assumethatthecomponentsofqandkareindependentrandomvariableswithmean0andvariance1.Thentheirdotproduct,q·k=Pdki=1qiki,hasmean0andvariancedk.4The output of FFN is considered the encoder’s output and is
passed to the decoder for an intermediate tensor operation. The
decoder has a similar structure as the encoder. The primary
differences are the masking operation and an additional multi-
head attention layer on each tensor. The masking operation is
applied on the ﬁrst multi-head attention layer, which takes
the processed input of the decoder. The additional multi-
head attention layer is the one next to the masked multi-head
attention layer. Also, the extra layer is where the output of the
encoder is taken into the decoding operation.

The above usage based on the network architecture of the
transformer is most frequently applied to NLP problems. It
can be seen that the transformer model has certain advantages
compared with other models in processing language semantics.
However, using the transformer in the information security
area, especially the prediction and classiﬁcation of URLs, is
a relatively new attempt. Rudd and Abdallah from FireEye
Inc. came up with the idea of using a transformer model
for malicious URL prediction [25]. They split each URL
into single-character tokens and append a classiﬁcation token
“CLS” at the end. To solve the different lengths of each
URL, padding tokens “PAD” will be added to normalize the
input to a ﬁxed length for training. The preprocessed URLs
will be projected into an embedding area with a stack of
attention layers and feed-forward neural network layers. Like
the transformer’s basic idea, each input token has an essential
relation with other tokens no matter how long the distance
the feed-forward layers allow learning the
is. Meanwhile,
combination of the input tokens’ relationship and their context.
The training process utilized over a million labeled malicious
and benign URLs. For the evaluation, they compared their
transformer model with four other models: Random Forest,
CNN, and LSTM. Finally, they concluded that the transformer
model had the highest accuracy score. Our model that will be
later introduced in this paper is inspired by their design.

III. PROPOSED MODEL

Based on the existing solutions and approaches of phishing
or malicious URL detection, our group has proposed and
implemented an innovative solution mainly based on the
transformer model. The design and implementation details of
our approach will be introduced in this section.

Our approach to the transformer model design is not iden-
tical to the standard structure. The model design of Rudd and
Abdallah from FireEye Inc. inspires the transformer model
design of our approach [25]. In our solution, the transformer
model is very similar to the design of OpenAI’s GPT model,
one of the famous variants of the Transformer model. Our
Transformer model applied left to right (L-R) modeling and
only contained the encoder part from the standard transformer
model. There are mainly two parts included in our solution:
the input text pre-processing part and the classiﬁer model part.
text pre-processing part, we
tokenize the input URL ﬁrst by splitting it into single-character
tokens. The most frequently appeared single-character tokens
in the URLs of the training dataset are used to form the

Speciﬁcally for

the input

token repository, which is also known as the vocabulary of
the tokenizer. The maximum vocabulary size is designed to
be 256 is corresponding to a 256-character embedding space
from index 0 to 255. Any characters contained in the input
URL out of the most frequently appeared 256 characters
will be replaced by a unique character < OOV >. For the
relatively shorter input URLs, they will be padded to the max
length of 256. On the other hand, the input URLs that are
longer than 256 characters will be truncated to the length of
256. Therefore, after the input text pre-processing operations,
each input URL will be tokenized to an array of length 256.
For example, given an input URL

https : //www.google.com/

the tokenized array will be1:

[15, 2, 2, 13, 9, 31, 4, 4, 33, 33, 33, 18, 26, 5, 5, 26, 17,
3, 18, 12, 5, 16, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0]

For the classiﬁer model part of our Transformer model,
there are eight main layers connected sequentially. The ﬁrst
layer is the input layer that takes the pre-processed input
URL as an array 256. The input layer passes the tokenized
input URL to a token and position embedding layer. The
dimension of this layer is equal to the vocabulary size of the
dataset gotten after the input text pre-processing operations.
Thus, the dimension of this layer is up to 256. This token
and position embedding layer consists of two sub-layers
which are both embedding layers. One of these two separate
embedding layers is for tokens, while the other is for token
index (positions). The layer next to the token and position
embedding layer is a transformer block. The transformer block
is the same as the encoder layer of the standard transformer
model, which consists of sublayers: multi-head attention and
point-wise feed-forward networks. The transformer block has
the same embedding dimension as the token and position
embedding layer. There are four attention heads included in
the Transformer block. The relationship of model dimension
(dmodel), key dimension (dk), and value dimension (dv) is:

dk = dv = dmodel/4 = 64.

1Note: A character’s corresponding sequence number representation may
differ depending on the character’s appearance frequency in the given
dataset. Furthermore, 0 is the padding’s corresponding sequence number
representation.

Thus, the multi-head attention sublayer can be described very
similar to (2) as:

M ultiHead(Q, K, V ) = Concat(head1, head2, head3, head4)W O
(4)

where

Q, KWi

K, V Wi

V ),

Q

K

headi = Attention(QWi
Wi
×
Wi
Wi
W O

R256
R256
R256
×
R4
64

64,
64,
×
64,
256.
×

×

V

∈
∈
∈
∈

Inside the transformer block, the hidden layer size in the
feed-forward network is 128. The transformer layer outputs
one vector for each time step of our tokenized input URL. We
take the mean across all time steps and use a feed-forward
network on top of it to classify text. Also, the dropout rate
of 0.1 is employed to help with preventing overﬁtting. At the
end of our classiﬁer model, a softmax function is employed to
generate the ﬁnal prediction result of whether the input URL
is malicious or benign.

IV. EXPERIMENT

A. Dataset

Our dataset is a combination of two resources: PhishTank
[29], and the University of New Brunswick (UNB) [30].
PhishTank provides hourly updated phishing URLs sets in
various formats including .json, .csv etc. The phishing URLs
on PhishTank are veriﬁed as valid by the community, which
gives better quality on the original dataset. PhishTank is a
widely used source of phishing URLs for researches related
to phishing detection [31]–[33]. The other dataset from UNB
has a collection of benign URLs, spam URLs, phishing URLs,
malware URLs, and defacement URLs. Researches like [34]
used this dataset as part of its input URL feeding source. Since
we only focus on phishing and legitimate URLs, we pulled
malicious URLs from PhishTank and benign URLs from UNB.
We randomly selected 20000 URLs with 10000 benign URLs
from UNB’s dataset and 10000 malicious from PhishTank’s
dataset for training and testing purposes. All selected URLs are
labeled with 0 or 1 for benign or malicious correspondingly.
We separate 80% (16000 URLs) for training and 20% of the
data (4000 URLs) for testing. Before the training process,
we also shufﬂed our labeled dataset to improve our model’s
robustness.

B. Training Process

Initially, we used a batch size of 512 and 20 epochs for
test training to get the appropriate epoch number to avoid
overﬁtting. After each training epoch, a checkpoint would be
saved for referring back at the model ﬁnalization stage. Based
on the initial training experiment, we found that both the
training and testing accuracy were kept on a high (over 95%)
and steady level between the 3rd and 13th (as depicted in Fig.

4). Additionally, the validation accuracy of our transformer
model started dropping dramatically after the 13th epoch
of training (as depicted in Fig. 4). At the same time, the
transformer model’s loss began increasing signiﬁcantly (as
depicted in Fig. 5). According to this ﬁnding, it suggested
that the checkpoint saved immediately after the 13th epoch
of training could be considered as a good balance between
pursuing high accuracy and avoiding model overﬁtting. Thus,
the checkpoint saved after the 13th epoch of training were
taken as the ﬁnalized training result of our model.

Fig. 4. Transformer model accuracy during training & validation.

Fig. 5. Transformer model loss during training & validation.

V. EVALUATION
As mentioned in the previous section, the checkpoint after
the 13th epoch of training was chosen as the ﬁnalized model
based on the 20-epoch experimental training results of model
accuracy and model loss. Thus, the evaluation analysis in this
section would be conducted on top of the transformer model’s
checkpoint after the 13th epoch of training.
A. Model Evaluation

We ran the prediction on the validation dataset that includes
4000 records combined with benign and malicious URLs to

1234567891011121314151617181920Epoch0.750.800.850.900.95AccuracyModel Accuracytraintest1234567891011121314151617181920Epoch0.10.20.30.40.5LossModel Losstraintestevaluate our model. Then, we used the prediction results and
the original labels to generate the confusion matrix. In our
experiment, True Negative (TN) is the number of benign URLs
classiﬁed as benign, False Positive (FP) is the number of
benign URLs misclassiﬁed as malicious, False Negative (FN)
is the number of malicious URLs misclassiﬁed as benign, and
True Positive (TP) is the number of malicious URLs classiﬁed
as malicious. Fig. 6 shows the confusion matrix.

In terms of confusion matrix results, the ideal situation
is that
it contains a large number of TP and TN and a
small number of FP and FN. From Fig. 6, we have a large
number of TP (1896). And we also have a high value for
TN (2028). These two numbers indicates our model is capa-
ble of accurately predict both malicious and benign URLs.
Additionally, we can also ﬁnd that neither FP (36) nor FN
(40) is a large number. These two numbers suggest there is
higher chance that the input URL is actually benign when our
transformer model made predictions incorrectly. Even though
our transformer model may make mistakes while predicting,
its overall performance is outstanding based on the results that
its confusion matrix shows.

To further evaluate our Transformer model, we utilized the
following indicators: accuracy (5), precision (6), recall (7),
and F1-score (8). Accuracy is the most intuitive metric that
calculates correct predicted results over all the predictions.
Precision measures the ratio of precise positive prediction
overall positive prediction. Recall shows the correct positive
prediction over the value of a speciﬁc class. Furthermore, F1-
score calculates the weighted average of the precision and
recall. According to the confusion matrix, the accuracy is
0.981, the precision is 0.981, the recall is 0.979, and the F1-
score is 0.980. These values all together indicate the high-
quality performance of our model.

Accuracy =

T P + T N
T P + F N + T N + F P

P recision =

T P
T P + F P

Recall =

T P
T P + F N

F 1

−

score = 2

P recision
Recall
P recision + Recall

∗

∗

B. Model Comparison

(5)

(6)

(7)

(8)

In addition, to evaluate our Transformer model by its valida-
tion performance, we also compared our model’s performance
with other typical classiﬁer models. We employed six extra
trained models from Sundari, and her team [11]’s work. Their
proposed approach could be considered as a hybrid solution
of property-based and URL-based approaches. They mainly
extracted 17 features from each URL that belongs to three
main categories: Address-Bar-based Features, Domain-based
Features, and HTML-&-Javascript-based Features. Our Trans-
former model is comparable with their six models because

Fig. 6. Confusion matrix of Transformer model.

their models were also trained on the datasets from PhishTank
and UNB.

To compare the performance of all seven models (Deci-
sion Tree, Random Forest, Multi-layer Perceptrons, XGBoost,
Support Vector Machine, Auto Encoder, Transformer), we
randomly select 1000 new URLs other than the training and
validation dataset. Half of these 1000 URLs are malicious
URLs, and the other half are benign ones. All of these
1000 URLs are labeled. We used the 1000 URLs to conduct
predictions with each one of the seven models. After the
experimental prediction process, we compared the predicted
results and the actual labels concerning each model. Each
model’s performance in the experiment was reﬂected by its
corresponding test accuracy, precision, recall, and F1-score
values. The result is in Table I. According to the performance
result table, we can ﬁnd that our Transformer models got
the highest values across all the four calculated metrics. For
all these four metrics, the higher value suggests the better
performance of the model from a speciﬁc aspect. We also
sorted the models by the F1-score in descending order to
reﬂect a model’s all-around performance. The F1-score (8)
is the harmonic mean of precision (6) and recall (7). It takes
the contribution of both, so the higher the F1 score, the better.
A model does well in the F1 score if the positive predicted
are positives (precision), does not miss out on positives,
and predicts them negative (recall). Therefore, in terms of
overall performance or performance from a speciﬁc aspect,
our Transformer model presents the best performance among
all seven models involved in the performance comparison
experiment.

01Predicted Label01True Label2028.036.040.01896.0Confusion Matrix25050075010001250150017502000TABLE I
MODEL PERFORMANCE COMPARISON

ML Model
Transformer
Random Forest
Autoencoder
XGBoost
Support Vector Machines
Decision Tree
Multilayer Perceptrons

Test Accuracy
0.973
0.849
0.843
0.825
0.845
0.841
0.778

Test Precision
0.984
0.973
0.934
0.831
0.978
0.975
0.747

Test Recall
0.962
0.718
0.738
0.816
0.706
0.700
0.840

Test F1-Score
0.973
0.826
0.825
0.823
0.820
0.815
0.791

[8] S. Egelman, “Trust me: Design patterns for constructing trustworthy trust
indicators,” CARNEGIE-MELLON UNIV PITTSBURGH PA SCHOOL
OF COMPUTER SCIENCE, Tech. Rep., 2009.

[9] S. H. Apandi,

J. Sallim, and R. M. Sidek, “Types of anti-
for phishing attack,” IOP conference series.
phishing solutions
Materials Science and Engineering, vol. 769, no. 1, p. 12072, Feb
1, 2020. [Online]. Available: https://iopscience.iop.org/article/10.1088/
1757-899X/769/1/012072

[10] A. Dmitrienko, C. Liebchen, C. Rossow, and A.-R. Sadeghi, On
the (In)Security of Mobile Two-Factor Authentication, ser. Financial
Cryptography and Data Security.
Berlin, Heidelberg: Springer
Berlin Heidelberg, Nov 9, 2014, pp. 365–383. [Online]. Available:
http://link.springer.com/10.1007/978-3-662-45472-5 24

VI. CONCLUSION AND FUTURE WORK

In this paper, we reviewed literature about different ap-
proaching trends on malicious URL prediction. Based on the
existing researches in this ﬁeld, we introduced our construction
of a Transformer classiﬁer model for predicting the malicious
URL. Additionally, we demonstrated our training dataset and
the corresponding training processes. Also, we evaluated our
ﬁnalized model by its performance upon the validation dataset
and its quality compared to the other six machine learning or
deep learning-based models. Comparing to the performance of
the other six models (Decision Tree, Random Forest, Multi-
layer Perceptrons, XGBoost, Support Vector Machine, and
Auto Encoder), we concluded that our transformer model is
the best performing model from all perspectives among the
total seven models when conducting predictions using our
model comparison dataset. Future training based on the current
ﬁnalized model with a large dataset may improve our robust-
ness. The performance and robustness could be pushed onto a
higher level, especially when using a huge dataset, including a
large portion of short URLs. Even with the ﬁnalized version,
our transformer model still provides an innovative idea of
a low-cost but good-performing solution for malicious URL
prediction. Also, our current ﬁndings and implementations of
our transformer model veriﬁed that transformer technology
is useful in malicious URL prediction and is worth future
research and even productizations.

REFERENCES

[1] E. Rzeszut and D. Bachrach, 10 Don’ts on Your Digital Devices.
Berkeley, CA: Apress L. P, 2014.
[Online]. Available: https://
ebookcentral.proquest.com/lib/[SITE ID]/detail.action?docID=1964915
[2] M. Jakobsson and S. Myers, Phishing and countermeasures. Newy
York: WILEY, 2006. [Online]. Available: http://portal.igpublish.com/
iglibrary/search/WILEYB0009517.html

[3] “Verizon: Data breach investigations report 2020,” Computer fraud &

security, vol. 2020, no. 6, pp. 4–4, 2020.

[4] H. Shahbaznezhad, F. Kolini, and M. Rashidirad, “Employees’ behavior
in phishing attacks: What individual, organizational, and technological
factors matter?” The Journal of computer information systems, vol.
ahead-of-print, no. ahead-of-print, pp. 1–12, October 29, 2020. [Online].
Available: http://www.tandfonline.com/doi/abs/10.1080/08874417.2020.
1812134

[5] A. APWG, “Phishing activity trends report: 4th quarter 2016,” Anti-
Phishing Working Group. Retrieved December, vol. 12, p. 2017, 2017.
[6] T. Whalen and K. M. Inkpen, “Gathering evidence: use of visual security
cues in web browsers,” in Proceedings of Graphics Interface 2005.
Citeseer, 2005, pp. 137–144.

[7] E. Lin, S. Greenberg, E. Trotter, D. Ma, and J. Aycock, “Does domain
highlighting help people identify phishing sites?” in Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems, 2011,
pp. 2075–2084.

[11] S.

G.
by

Sundari,

machine

tion
2020.
Phishing-Website-Detection-by-Machine-Learning-Techniques/

Available:

[Online].

learning

website

detec-
10,
https://github.com/shreyagopal/

techniques,”

May

“Phishing

[12] K. L. Chiew, E. H. Chang, S. N. Sze, and W. K. Tiong,
“Utilisation of website logo for phishing detection,” Computers
& security, vol. 54, pp. 16–26, Oct 2015.
[Online]. Available:
http://dx.doi.org/10.1016/j.cose.2015.07.006

[13] P. Yang, G. Zhao, and P. Zeng, “Phishing website detection
based on multidimensional
features driven by deep learning,”
IEEE access, vol. 7, pp. 15 196–15 209, 2019. [Online]. Available:
https://ieeexplore.ieee.org/document/8610190

[14] K. L. Chiew, J. S.-F. Choo, S. N. Sze, and K. S. C. Yong,
“Leverage website favicon to detect phishing websites,” Security and
communication networks, vol. 2018, pp. 1–11, Mar 6, 2018. [Online].
Available: https://dx.doi.org/10.1155/2018/7251750

[15] Y. Pan and X. Ding, “Anomaly based web phishing page detection.”
IEEE, Dec 2006, pp. 381–392. [Online]. Available: https://ieeexplore.
ieee.org/document/4041183

[16] R. M. Mohammad, F. Thabtah, and L. McCluskey, “An assessment
related to phishing websites using an automated
[Online]. Available:
IEEE, Dec 2012, pp. 492–497.

of
features
technique.”
https://ieeexplore.ieee.org/document/6470857

[17] G. H. Lokesh and G. BoreGowda, “Phishing website detection
based on effective machine learning approach,” Journal of cyber
security, vol. 5, no. 1, pp. 1–14, Jan 2, 2021. [Online]. Available:
http://www.tandfonline.com/doi/abs/10.1080/23742917.2020.1813396

[18] I. Fette, N. Sadeh, and A. Tomasic, “Learning to detect phishing
emails,” ser. WWW ’07. ACM, May 8, 2007, pp. 649–656. [Online].
Available: http://dl.acm.org/citation.cfm?id=1242660

[19] A. Zamir, H. U. Khan, T. Iqbal, N. Yousaf, F. Aslam, A. Anjum,
and M. Hamdani, “Phishing web site detection using diverse machine
learning algorithms,” Electronic library, vol. 38, no. 1, pp. 65–80,
2020. [Online]. Available: https://www.emerald.com/insight/content/doi/
10.1108/EL-05-2019-0118/full/html

[20] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker, “Learning to
detect malicious urls,” ACM Transactions on Intelligent Systems and
Technology (TIST), vol. 2, no. 3, pp. 1–24, 2011.

[21] H. Choi, B. B. Zhu, and H. Lee, “Detecting malicious web links and
identifying their attack types.” WebApps, vol. 11, no. 11, p. 218, 2011.
[22] J. Zhang and Y. Wang, “A real-time automatic detection of phishing
urls,” in Proceedings of 2012 2nd International Conference on Computer
Science and Network Technology.

IEEE, 2012, pp. 1212–1216.

[23] S. Marchal, J. Franc¸ois, T. Engel et al., “Proactive discovery of phishing
related domain names,” in International Workshop on Recent Advances
in Intrusion Detection. Springer, 2012, pp. 190–209.

[24] H.-K. Pao, Y.-L. Chou, and Y.-J. Lee, “Malicious url detection based
on kolmogorov complexity estimation,” ser. WI-IAT ’12, vol. 1.
IEEE
Computer Society, Dec 4, 2012, pp. 380–387. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2457619

[25] E. M. Rudd and A. Abdallah, “Training transformers for information
security tasks: A case study on malicious url prediction,” Nov 5, 2020.
[Online]. Available: https://arxiv.org/abs/2011.03040

[26] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” Jun
12, 2017. [Online]. Available: https://arxiv.org/abs/1706.03762

[27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” 2019,
1810.04805.

[28] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving

language understanding by generative pre-training,” 2018.

[29] “Phishtank,” August 2021. [Online]. Available: http://data.phishtank.

com/data/online-valid.csv

[30] “Url dataset (iscx-url2016),” 2016. [Online]. Available: https://www.

unb.ca/cic/datasets/url-2016.html

[31] S. W. Liew, N. F. M. Sani, M. T. Abdullah, R. Yaakob, and M. Y.
Sharum, “An effective security alert mechanism for real-time phishing
tweet detection on twitter,” Computers & security, vol. 83, pp. 201–207,
Jun 2019. [Online]. Available: https://dx.doi.org/10.1016/j.cose.2019.
02.004

[32] P. A. Barraclough, M. A. Hossain, M. A. Tahir, G. Sexton, and
N. Aslam, “Intelligent phishing detection and protection scheme
for online transactions,” Expert systems with applications, vol. 40,
no. 11, pp. 4697–4706, Sep 1, 2013.
[Online]. Available: https:
//dx.doi.org/10.1016/j.eswa.2013.02.009

[33] G. Varshney, M. Misra, and P. K. Atrey, “A phish detector using
lightweight search features,” Computers & security, vol. 62, pp.
213–228, Sep 2016. [Online]. Available: https://dx.doi.org/10.1016/j.
cose.2016.08.003

[34] M. S. I. Mamun, M. A. Rathore, A. H. Lashkari, N. Stakhanova,
and A. A. Ghorbani, Detecting Malicious URLs Using Lexical
Analysis,
Cham: Springer
ser. Network and System Security.
International Publishing, Sep 21, 2016, pp. 467–482.
[Online].
Available: http://link.springer.com/10.1007/978-3-319-46298-1 30

