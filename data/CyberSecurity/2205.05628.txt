Extensible Machine Learning for Encrypted
Network Trafﬁc Application Labeling via
Uncertainty Quantiﬁcation

Steven Jorgensen, John Holodnak, Jensen Dempsey, Karla de Souza, Ananditha Raghunath,
Vernon Rivet, Noah DeMoes, Andr´es Alejos, and Allan Wollaber∗
MIT Lincoln Laboratory, Lexington, Massachusetts
Email: allan.wollaber@ll.mit.edu∗

2
2
0
2

y
a
M
1
1

]

R
C
.
s
c
[

1
v
8
2
6
5
0
.
5
0
2
2
:
v
i
X
r
a

Abstract—With the increasing prevalence of encrypted net-
work trafﬁc, cyber security analysts have been turning to
machine learning (ML) techniques to elucidate the trafﬁc on their
networks. However, ML models can become stale as known trafﬁc
features can shift between networks and as new trafﬁc emerges
that is outside of the distribution of the training set. In order
to reliably adapt in this dynamic environment, ML models must
additionally provide contextualized uncertainty quantiﬁcation to
their predictions, which has received little attention in the cyber
security domain. Uncertainty quantiﬁcation is necessary both to
signal when the model is uncertain about which class to choose
in its label assignment and when the trafﬁc is not likely to belong
to any pre-trained classes.

We present a new, public dataset of network trafﬁc that
includes labeled, Virtual Private Network (VPN)-encrypted net-
work trafﬁc generated by 10 applications and corresponding
to 5 application categories. We also present an ML framework
that is designed to rapidly train with modest data requirements
and provide both calibrated, predictive probabilities as well
as an interpretable “out-of-distribution” (OOD) score to ﬂag
novel trafﬁc samples. We describe how to compute a calibrated
OOD score from p-values of the so-called relative Mahalanobis
distance.

We demonstrate that our framework achieves an F1 score of
0.98 on our dataset and that it can extend to an enterprise net-
work by testing the model: (1) on data from similar applications,
(2) on dissimilar application trafﬁc from an existing category,
and (3) on application trafﬁc from a new category. The model
correctly ﬂags uncertain trafﬁc and, upon retraining, accurately
incorporates the new data. We additionally demonstrate good
performance (F1 score of 0.97) when packet sizes are made to
be uniform, as occurs for certain encryption protocols.

Index Terms—network trafﬁc classiﬁcation, virtual private net-
works, machine learning, discrete wavelet transform, encrypted
trafﬁc, cybersecurity

I. INTRODUCTION

The proportion and popularity of encrypted network trafﬁc
has quickly risen over the last several years, with over 95% of
trafﬁc across Google and 97 of the top 100 websites defaulting
to encryption [1]. This is a boon for online privacy; however,
there is a corresponding increase in encryption for malware
delivery [2], [3]. Beyond that, MITRE ATT&CK enumerates
several
techniques in which encryption has been used to
obfuscate command and control or to masquerade one appli-
cation as another. Although signature-based techniques such

as website ﬁngerprinting [4], [5] and (e.g.) Palo Alto’s App-
ID can ﬂag particular packet sequences that indicate a known
website request or protocol handshake, the general problem
of inferring an application when signatures and heuristics fail
remains a challenging problem. In particular, Virtual Private
Network (VPN) providers have also lowered the barriers for
users not only to encrypt the ports, protocols, and IP addresses
of their connections, but also to obfuscate the IP address of
the VPN server itself [6] and/or pad all packets to be the
same size before encryption [7], which can defeat signature
detection capabilities. In light of these difﬁculties, network
security analysts have begun turning to machine learning (ML)
approaches that leverage latent signals in the packet timings,
sizes, and their encrypted payloads in order to predict the
applications that generated the encrypted trafﬁc.

Existing work in machine learning for encrypted trafﬁc
classiﬁcation has focused primarily on feature construction and
model development to optimize raw performance metrics such
as overall accuracy. For example, traditional machine learning
models (like na¨ıve Bayes and decision trees) have been applied
to simple statistical features [8], [9] and neural networks based
on one or two-dimensional convolutions have been applied to
sequences of raw byte values, interarrival times, and wavelet
coefﬁcients [10]–[16]. Many of these techniques yield very
good performance on publicly available data, the most popular
being the ISCXVPN2016 dataset [9].

In this work, we build upon some previously developed fea-
tures (interarrival statistics and wavelet signal processing) with
an eye towards enabling rapid learning with limited data. In
addition, we focus on developing an ML model with accurate
uncertainty quantiﬁcation that is able to (1) produce accurate
probabilistic predictions for the classes on which the model
is trained, and (2) detect examples dissimilar to application
categories that the model was trained to predict. While there
has been some limited mention of uncertainty quantiﬁcation
in cyber security applications of machine learning in general
[17]–[20], the problem has not received the same attention in
cyber security as it has in other domains, such as computer
vision and healthcare. We consider this unfortunate and believe
that in a dynamic environment such as a computer network, it
is critically important to quantify model uncertainty. A recent

1

 
 
 
 
 
 
review highlighted the need to reduce errors (false positives)
when moving from a closed training set to real-world data for
encrypted network trafﬁc analysis [21].

In our work, we develop a classiﬁer for encrypted network
trafﬁc based on prototypical networks, which leverage dis-
tances to class prototypes (means) in a learned embedding
space to compute class probabilities and thus predictions [22].
We use the recently developed relative Mahalanobis distance
between test examples and class prototypes to detect out of
distribution (OOD) examples [23]. Our model uses as input a
mixture of simple features derived from ﬂow statistics as well
as wavelet transform coefﬁcients to produce class predictions
for segments of bi-directional network ﬂows. To enable regular
predictions in VPN settings in which (1) the embedded 5-
tuples for connections are encrypted and (2) the beginnings
and endings of connections are obfuscated, we split all network
ﬂows into discretely sampled time segments and make one
prediction for each time segment in each ﬂow.

We apply our model to a new dataset (which we have made
publicly available) of encrypted network trafﬁc collected on
a testbed from ten applications that cover ﬁve broad, but not
comprehensive categories of trafﬁc. This dataset supplements
those already available in the literature, which either cover
only very speciﬁc types of network trafﬁc such as the UC
Davis dataset of QUIC trafﬁc [14] or the Orange dataset of
HTTPS trafﬁc [16], or contain artifacts such as unencrypted
packets that could affect the validity of models trained on
them1. When trained with an 80/20 train/test split, our model
has a micro F1-score of 0.98. Further, we investigate our
model’s performance when training with only small fractions
of the dataset, achieving (for instance) 95% accuracy on VoIP
trafﬁc in a 5-class problem using just under 7 minutes of data
capture.

We stress-test the model by attempting to transfer its learn-
ing from the testbed to an enterprise network over several
categories. We found that in some instances (a streaming and
VoIP application), the model cleanly transfers onto another
network with high accuracy and low uncertainty, and in others
(two ﬁle transfer applications), the model successfully reports
low in-distribution conﬁdence and can be quickly retrained
to incorporate the new applications for identiﬁcation in the
known category.

To test our model’s ability to identify OOD examples,
we perform inference on PCAP containing an unseen trafﬁc
category (Zoom) from an enterprise network and demonstrate
that
the model reliably assigns the new category a high
OOD score, with over 77% predicted as signiﬁcantly out of
distribution. Upon retraining with about two hours of labeled
examples of Zoom, which takes under 5 minutes, the fraction
of signiﬁcantly OOD test examples drops to 26%.

Finally, we test our model’s robustness by investigating the
case where all packets are padded to have identical sizes, as
occurs in the Noise Protocol or in certain implementations of

1See Section II-E for speciﬁc examples of artifacts we identiﬁed in the
introduced in [9], which we hope to

often-used ISCXVPN2016 dataset,
supplement.

Trafﬁc Flow Conﬁdentiality [7], [24]. We see that the model
(which utilizes both packet timing and size information) is
still able to obtain very good performance (micro F1-score of
0.97) indicating that packet size information is not necessary
for accurate classiﬁcation. In addition, this observation calls
into question the degree of privacy offered by such obfuscation
strategies.

To summarize, the primary contributions of this paper are:
• a new public dataset of application-labeled, VPN-

encrypted and non-VPN-encrypted network trafﬁc,

• an ML architecture for encrypted trafﬁc designed to
quickly train with limited labeled data and provide cal-
ibrated, uncertainty-contextualized predictions for two
tasks: (1) predictive uncertainty, when the model is in-
decisive about which known label a sample belongs to
and (2) model uncertainty, when the model encounters
OOD data potentially from an unknown label, enabling
the model to be systematically extended to new data, and
• a demonstration of high accuracy and F1 score for appli-
cation data that is grouped into discrete time windows,
instead of by collecting statistics or data for an entire
connection or relying upon ﬁngerprints or signatures,
enabling sequential application predictions under a VPN.

II. RELATED WORK

In this section, we describe existing work in the literature
related to trafﬁc classiﬁcation in general, encrypted trafﬁc
classiﬁcation, and website ﬁngerprinting. Due to our focus
on uncertainty in encrypted trafﬁc classiﬁcation, we brieﬂy
review relevant work on uncertainty in deep learning from
the machine learning community. Finally, we discuss existing
encrypted trafﬁc datasets and our motivation for collecting our
own.

A. Early Trafﬁc Classiﬁcation

In the early days of the Internet, censors used port-based
trafﬁc classiﬁcation to restrict Internet content [25]. Port-
based classiﬁcation models could classify network trafﬁc using
the port numbers encoded in the packet headers because
the Internet Assigned Numbers Authority maps services to
unique port numbers [26]. In response, clever Internet users
and application developers adapted to port-based censorship
by dynamically changing port numbers, hiding behind port
numbers already assigned to well-known, trusted applications,
or using unregistered port numbers [27]–[29]. Deep packet
inspection (DPI) then emerged as a technique that inspects
the payloads of packets and classiﬁes them accordingly [25],
[30]–[33]. DPI is often used to check for malicious code,
obtain situational awareness on a network, and eavesdrop on
connections. For example, the operators of the Great Firewall
of China have used DPI to inform active probing to identify
and censor Tor [25]. However, with the rise of easy-to-use
encryption schemes such as HTTPS and VPNs, DPI has lost
its effectiveness. Although possible, trafﬁc decryption is not a
viable countermeasure, because decryption not only compro-
mises user privacy but is also computationally expensive and

2

difﬁcult to implement [34]. VPNs in particular can effectively
obscure payloads, ports, and IP addresses, through encryption,
leaving only packet timing and size information as potential
signal sources.

ﬁngerprinting identiﬁes a handshake to a malicious website.
Our approach could then also be applied to the connection to
determine if any ﬁle transfer or new command and control
channels occurred after the signature was detected.

B. Encrypted Trafﬁc Classiﬁcation

D. Uncertainty in Deep Learning

To overcome the limitations of port- and payload-based
classiﬁcation models, researchers have focused on trafﬁc clas-
siﬁcation models that use features from observable encrypted
trafﬁc metadata [21], [34].

Some examples of features constructed from observable
metadata include features based on simple statistics derived
from ﬂows [9], [28], [31], [34]–[43] and wavelet-based fea-
tures [10], [44]. While trafﬁc classiﬁcation methods that use
ﬂow statistic-based features yield respectable results for iso-
lated application classiﬁcation in contained environments, it is
uncertain whether they are robust enough to be utilized in real-
world settings. Flow statistic-based features can vary widely
between network topologies and are not able to characterize
the highly variable and bursty nature of Internet trafﬁc [45]–
[48]. On the other hand, wavelet-based features can capture
the inherent nonlinearities of Internet trafﬁc, such as jumps
and edges, by providing representations of the observable
metadata from the bidirectional connection that are localized
in both time and frequency [49]. Shi et al. [44] are the ﬁrst
to use wavelet-based features for trafﬁc classiﬁcation and
show that SVMs trained with wavelet features outperform
those trained with ﬂow statistic-based features. Later [10] used
Convolutional Neural Networks (CNNs) trained on wavelet-
based features for trafﬁc classiﬁcation. We build on this
approach by dividing the connections into chunks of time
rather than classifying the aggregate connection all at once and
combining ﬂow statistic-based features and wavelet features in
each time window.

C. Website Fingerprinting

Website ﬁngerprinting is a process of recognizing speciﬁc
web trafﬁc (e.g.,
to particular websites) based on unique
patterns in the trafﬁc [50]. This approach leverages the fact
that websites tend to have unique packet sequence patterns
(handshakes) that allow for identiﬁcation. Trafﬁc features can
include information such as unique packet lengths, sequence
lengths, packet ordering, and packet interarrival timings [51].
These features are then fed to ML algorithms that classify
trafﬁc based on the observed patterns. However, the identify-
ing handshake must be learned beforehand and observed in
a trafﬁc sample to enable detection. Website ﬁngerprinting
techniques also tend to be sensitive to changes in network
patterns such as packet padding and ﬂuctuations in packet
round trip time, and it is challenging to know when the models
must be updated [52].

We envision our approach would work in tandem with web-
site ﬁngerprinting and signature-based approaches, allowing
for contextual, uncertainty-quantiﬁed predictions to be made
before or after a handshake has been identiﬁed. An example
of this is the case where, within some packet capture, website

Quantifying the uncertainty of model predictions is an
active area of research in the machine learning community.
Considerable research has been focused on improving the abil-
ity of classiﬁcation models to output calibrated probabilistic
predictions and to detect OOD examples at test time.

To be clear, a model’s predictive probabilities are calibrated
if their conﬁdence (highest predicted probability) matches
their accuracy. In other words, a model should correctly label
90% of the examples that it categorizes with 90% conﬁdence.
Guo et al. [53] showed that while shallow neural networks
tend to be reasonably well calibrated, deep neural networks
are not. Various procedures for improving calibration have
been proposed including temperature calibration [53], deep
ensembles [54], and Bayesian Model Averaging [55].

We now brieﬂy review some of the major approaches to
OOD detection in the machine learning literature. The degree
to which examples are out of distribution is usually quan-
tiﬁed either using the distribution of predicted probabilities
for examples or some notion of distance to the distribution
of training data. For example, the magnitude of the largest
predicted probability was used in [56] as a score, encoding
the assumption that if a data example is out of distribution,
no class will be assigned a high probability. Other work [57],
improved this approach by applying input preprocessing and
softmax temperature scaling to improve separation between
the largest predicted probabilities of in and out of distribution
examples. In another approach [58], the authors model the
output probabilities as a distribution and place a Dirichlet
prior over them. During training, they attempt to enforce the
assumption that uncertain examples produce a ﬂat distribution
of predictive probabilities by training on OOD examples. This
idea is improved in [59], which removes the necessity for using
OOD examples in training.

On the other hand, the authors in [60] ﬁt class-conditional
Gaussian distributions in the embedding space of a model
with softmax output probabilities and compute Mahalanobis
distances to the Gaussian distributions at test time. A very
similar approach is taken in [61], but in the context of meta-
learning and prototypical networks. In this case, the authors
use the distance to the closest class prototype as an OOD score.
Our approach is similar to that in [61], but instead makes use
of the relative Mahalanobis distance from [23] and converts
the OOD score to a p-value for greater interpretability.

E. Publicly Available Encrypted Trafﬁc Datasets

The development of reproducible research in encrypted
trafﬁc classiﬁcation is hindered by the shortage of publicly
available encrypted trafﬁc data. In 2016, the Canadian Institute
for Cybersecurity published the ISCXVPN2016 dataset of
VPN and non-VPN trafﬁc from 20 applications and seven

3

that they post-process the packet headers to ensure that all
packets appear under the same 5-tuple, as they would inside
a VPN connection. Alternatively, one could also replay the
VPN-labeled ﬁles through a VPN.

Finally, there is also a challenge with respect to consistent
assignment of the trafﬁc categories to the collected PCAP ﬁles.
As an example, the ﬁle skype_video1a.pcap could rea-
sonably be categorized as VoIP or Web Browsing, but probably
would have ﬁt better with other video-teleconferencing PCAPs
in its own VTC category.

In response to the limitations of the ISCXVPN2016 dataset,
we introduce a supplemental, labeled dataset of VPN and non-
VPN network trafﬁc for public use and to test our extensible
machine learning framework.

III. ENCRYPTED TRAFFIC DATASET

In this section, we describe the characteristics of our
dataset2 and outline the process used to produce the dataset.
Our dataset is a collection of 37.5 GB of labeled network
trafﬁc that contains both VPN-encrypted and unencrypted
ﬂows from the ﬁve trafﬁc categories shown in Table I, which
is inspired by the categories in [9] with a few omissions
(e.g., P2P, Web Browsing) and a new category (Command
& Control). See Table V in Appendix A for the ﬁle mappings
used to assign class labels.

TABLE I
THE APPLICATIONS AND TRAFFIC CATEGORIES USED TO GENERATE THE
DATASET.

Trafﬁc Category

Applications

Streaming
VoIP
Chat
Command & Control
File Transfer

Vimeo, Netﬂix, YouTube
Zoiper
Skype
SSH, RDP
SFTP, RSYNC, SCP

A. Dataset Characteristics

Our dataset consists of 37.5 GB, 44,981 connections, and
approximately 272 hours of packet capture from ﬁve trafﬁc
categories as listed in Table II. The relative breakdown of sizes,
connections, and times per trafﬁc category is visualized in
Figure 2. Although the File Transfer category constitutes 87%
of the total size of the dataset, it only contributes to roughly
36% and 5% of the total connections and time, respectively.
In contrast, the Command & Control category only makes
up about 2% of the dataset in size while comprising 30%
of the connections and almost 47% of the total time. The
Streaming category contributes approximately 11%, 29%, and
1% of the total size, connections, and time. The Chat category
contributes less than 1% of the total size, 3% of the total
connections, and 45% of the total time. Finally, the smallest
trafﬁc category, VoIP, makes up less than 1% of the total size
and time, and less than 5% of the total connections.

2The dataset

is available for download at: https://www.ll.mit.edu/r-

d/datasets/vpnnonvpn-network-application-trafﬁc-dataset-vnat.

Fig. 1. The unencrypted payload of the 17th packet in the ICQ chat VPN
capture of the ISCXVPN2016 dataset. The IP address of this capture also
matches a known ICQ server, and other connections can be distinguished in
the capture.

trafﬁc categories [9]. As the ﬁrst publicly available dataset
of VPN trafﬁc, the ISCXVPN2016 dataset has been used by
many researchers to train and test ML models. Other datasets
have since been released as well, such as the UC Davis
dataset of QUIC trafﬁc [14] or the Orange dataset of HTTPS
trafﬁc [16], but lack the diversity of applications and trafﬁc
categories.

Despite its widespread use, we found that

the IS-
CXVPN2016 dataset contains discrepancies in the VPN cap-
tures that compromise the integrity of encrypted network traf-
ﬁc classiﬁcation methods evaluated on it. Upon closer inspec-
tion of the PCAP ﬁles from the VPN captures, we ﬁnd packets
with unencrypted payloads. For example, Figure 1 shows the
unencrypted payload of the 17th packet in the PCAP ﬁle for
the ICQ Chat VPN capture in vpn_icq_chart1b.pcap.
We also ﬁnd PCAP ﬁles for VPN-labeled captures to con-
tain multiple connections, although we expect
the PCAP
ﬁles for a VPN session to contain a single connection be-
tween the VPN client and the VPN server. For example,
the vast majority of packets in the vpn_netflix_A.pcap
ﬁle are over port 80 to a Netﬂix IP address,
the major-
ity of packets in vpn_hangouts_audio1.pcap resolve
to a Google IP address, and the majority of packets in
vpn_facebook_audio2.pcap resolve to a Facebook IP
address (with a minority fraction also going to Google). These
ﬁndings imply that either the network was tapped before the
packets went through the VPN client or the packets were not
encrypted.

Unencrypted packet payloads will unfairly strengthen trafﬁc
classiﬁcation methods that leverage packet payloads, such as
DPI or the deep packet approach in [15]. Additionally, the
presence of multiple connections per VPN capture will un-
fairly strengthen methods that leverage connection information
aggregated at the ﬂow-level.

In light of these concerns, we recommend that researchers
seeking to utilize the ISCXVPN2016 dataset ensure that their
trafﬁc classiﬁcation methods do not presume that VPN-labeled
packet payloads are VPN-encrypted. Additionally,
if their
methods for analyzing VPN-encrypted trafﬁc rely on connec-
tion information aggregated at the ﬂow-level, we recommend

4

TABLE II
TOTAL PACKET SIZES, CONNECTIONS, AND TIME PER TRAFFIC CATEGORY
IN THE DATASET.

Trafﬁc Category

Size (MB)

Connections

Time (h)

File Transfer
Streaming
VoIP
Command & Control
Chat

Total

32,600
4,034
103
622
185

37,546

16,430
13,034
617
13,599
1,301

44,981

14.8
4.3
2.7
127.4
123.0

272.3

Breakdown of the total packet sizes, connections, and time per
Fig. 2.
trafﬁc category. The totals are normalized to one to demonstrate the relative
contribution of each trafﬁc category.

B. Network Setup

To produce the dataset, we begin by creating virtual sub-
networks for each trafﬁc category as shown in Figure 3. Each
subnetwork contains a client, a client DNS server, a VPN
client, and a VPN server. The Skype subnetwork contains
an additional client to allow for bidirectional chat. The video
streaming and web browsing subnetworks are connected to
the Internet to enable access to Firefox, Chrome, YouTube,
Netﬂix, and Vimeo. As shown in Figure 3, VPN trafﬁc
is captured between the VPN client and the VPN server.
Separately, non-VPN trafﬁc is captured between the VPN
client and the application layer.

C. Data Generation

Once the network setup is complete, we generate the dataset
for each trafﬁc category individually to ensure data purity.
All trafﬁc is captured using tcpdump and stored in the PCAP
format. Filename-to-category mappings are provided in Table
V in the Appendix.

Fig. 3. Diagram of the virtual subnetworks used to capture network trafﬁc.
The yellow stars denote where the data captures occur. The non-VPN trafﬁc
is captured between the client and the client VPN while the VPN trafﬁc is
captured between the client VPN and the VPN server.

5

The Streaming category includes Vimeo, Netﬂix, and
YouTube trafﬁc generated by team members watching videos
on each platform. The VoIP category is composed of VoIP
audio generated by team members having conversations with
one another using Zoiper. The Chat category consists of Skype
Chat trafﬁc generated with bots that replay actual chats from
publicly available logs from Gitter.im chat rooms [62].

The Command & Control category includes SSH and RDP
trafﬁc. RDP trafﬁc is generated by team members actively
performing tasks, such as editing Word documents, over an
RDP connection. To emulate SSH trafﬁc, we created a script
to randomly sample 2 to 20 commands with replacement from
a predetermined list of 17 commands. For each command, it
samples a random wait time between 1 and 60 seconds. Once it
is ﬁnished executing each command and wait time, it waits 60
seconds before repeating the entire process from the beginning.
The File Transfer category contains SFTP, RSYNC, and
SCP trafﬁc. To emulate users performing ﬁle transfers, we
created scripts that randomly choose a ﬁle out of a list of
15 ﬁles of sizes ranging from 1 KB to 1 GB. Then, they
randomly decide whether to send the chosen ﬁle to or from
a remote server. After executing the ﬁle transfer, the scripts
wait 60 seconds before selecting a new ﬁle.

IV. METHODS

In this section, we discuss the features that we used as model
input, the speciﬁcs of our model architecture, and how we
deﬁne out of distribution scores.

A. Data Pre-processing

We group packets into connections based on the ﬁve-tuple
consisting of the source IP address, destination IP address,
source port, destination port, and protocol using the dpkt3
Python module. We split the connections into 40.96-second
intervals4 and discard any intervals containing fewer than 20
packets. For each 40.96-second interval, we obtain the packet
timestamps, payload sizes, and directions discretized into 0.01-
second bins. After this preprocessing,
the data collection
contains 1675 Command & Control examples, 10498 Chat,
851 File Transfer, 1827 Streaming, and 243 VoIP examples.

B. Feature Construction

For each 40.96-second interval, we compute aggregate
statistics (such as total, average, maximum, etc.) for ﬂow
features such as interarrival times and time spent as active
or idle. We compute statistics both for the ﬂow’s forward and
backward direction. We note here that in our current imple-
mentation, “forward” and “backward” are arbitrary; the ﬁrst
observed packet in the connection is designated as “forward”
for the remainder of the connection. The full set of aggregate
statistics features are listed in Table III and are very similar
to those in [9].

3https://github.com/kbandla/dpkt
4A discussion of our selection of 40.96-second intervals and 0.01-second

bins is provided in Appendix A.

TABLE III
FLOW STATISTIC FEATURES CALCULATED OVER EACH TIME WINDOW.

Feature

Description

total forward
total backward
bytes per sec
total bytes forward
total bytes backward
FIAT (mean, min, max, std)
BIAT (mean, min, max, std)
FlowIAT (mean, min, max, std)
Active (mean, min, max, std)
Idle (mean, min, max, std)

Number of forward packets
Number of backward packets
Total bytes per second
Total forward bytes
Total backward bytes
Forward inter-arrival time
Backward inter-arrival time
Flow inter-arrival time
Total seconds ﬂow is active
Total seconds ﬂow is idle

We also generate wavelet-based features from the 40.96-
second intervals using the discrete wavelet transform as done
by [44]. We select
the Haar basis as the mother wavelet
because it produces the maximum energy to Shannon entropy
ratio. Before calculating the wavelet-based features, we ex-
tract the detail coefﬁcients from frequency bands 0 to 12 of
the wavelet-transformed connection sizes in the forward and
backward directions using the PyWavelets Python package
[63]. Then, we use the detail coefﬁcients of each band to
calculate the wavelet-based features from the connection sizes
in the forward and backward directions. The wavelet-based
features include the relative wavelet energy, Shannon entropy,
and absolute means and standard deviations of the detail coef-
ﬁcients as shown in Table IV. The absolute means and standard
deviations of the detail coefﬁcients are log-transformed to
induce symmetry because the original distributions of these
features are heavily right-skewed. See Appendix A for details
on how to calculate the wavelet-based features.

In total, this data pipeline collapses the (up to) gigabytes of
network trafﬁc that could ﬂow across 40.96 seconds into two
vectors of length 4096 that are then reduced to 129 features
per time-window. Some of these features are also correlated
and could be winnowed (data not shown) to further sparsen
the signal.

C. Classiﬁcation Model

Prototypical Networks are neural networks that compute
class probabilities using the distances to a set of so-called
prototypical examples [22], rather than by applying a softmax
activation function to the output layer. The neural network
that forms the base of the prototypical network is usually

TABLE IV
WAVELET-BASED FEATURES CALCULATED OVER EACH TIME WINDOW.

Feature

Description

RelEng Forward
RelEng Backward
Entropy Forward
Entropy Backward
MeanDetail Forward
MeanDetail Backward
StdDetail Forward
StdDetail Backward

Forward relative wavelet energy
Backward relative wavelet energy
Forward Shannon entropy
Backward Shannon entropy
Absolute mean of forward detail coefﬁcients
Absolute mean of backward detail coefﬁcients
Std. deviation of forward detail coefﬁcients
Std. deviation of backward detail coefﬁcients

referred to as an embedding function. We denote the em-
: RD → RE, where D is the
bedding function as fθ
dimension of the feature space, E is the dimension of the
embedding space, and θ are weights to be learned. We assume
access to a set X = {xi} of examples with corresponding
labels yi ∈ {1, 2, . . . , K}. We will use the notation Xtrain,
Xcal, and Xtest to refer to partitions of the dataset. The
prototype for each class k, 1 ≤ k ≤ K, which we denote
as ck is simply the mean of the embedding of a few (S)
examples of the class (known as the support examples); that
is, ck = 1
s ). Here, the superscript k indicates the
S
examples come from class k.

s=1 fθ(xk

(cid:80)S

For a given observation, the class probabilities are calculated
by applying the softmax activation function to the distances
between the class prototypes and the embedding of the ob-
servation. Speciﬁcally, the probability of class k for input
example xi is

P (yi = k|xi) =

exp(−dk(fθ(xi), ck))
k(cid:48) exp(−dk(cid:48)(fθ(xi), ck(cid:48)))

(cid:80)

,

(1)

where each dk is a distance function on the embedding space.
In our application, we use an embedding model with four
fully connected hidden layers each containing 64 neurons with
Relu activations. We perform 25% dropout on the weights
connecting the second and third and the third and fourth layers.
We learn our model’s parameters using the episodic training
paradigm [22]. In episodic training, for each of Nepisode
episodes, we sample Nquery query examples and Strain sup-
port examples. The prototypes are computed from the support
examples and we compute the cross-entropy loss over the
query examples. We summarize our training procedure in
Algorithm 1.

Throughout the paper, we set Nepisode to 20000, Nquery
to 512, and Strain to 5. As in [22], the choice of squared
Euclidean distance during training roughly corresponds to
spherical Gaussian densities in RE; this motivates our use of
the Mahalanobis distance for OOD scoring.

D. Out of Distribution Scores

We now describe how we obtain OOD uncertainty measures
from the prototypical network. Our OOD score is based

Algorithm 1 Train
Require: Xtrain, ytrain, Nepisodes, Nquery, Strain, fθ

for 1 ≤ b ≤ Nepisodes do
Sample support {xk

examples {xi}Nquery

i=1

s }Strain
s=1
from Xtrain

for each class k and query

Compute embeddings fθ(xi) and fθ(xk
s )
(cid:80)Strain
Compute prototypes ck = 1
i=s
Calculate class probabilities as in Equation (1) where

fθ(xk

Strain

s ).

each dk is the Euclidean distance

Compute the gradient of the loss over the query exam-

ples; update parameters θ
end for
Ensure: fθ

6

on Mahalanobis distance. Mahalanobis distance is used to
measure the distance between a point and a distribution. Given
a point x and a distribution with mean µ and covariance matrix
Σ, the Mahalanobis distance between x and the distribution is

M (x; µ, Σ) =

(cid:113)

(x − µ)T Σ−1(x − µ).

For a dataset consisting of K classes, the relative Mahalanobis
distance to class k is deﬁned to be the Mahalanobis distance
to class k minus the Mahalanobis distance to the overall data
distribution [23]. That is,

M k

rel(x; µk, µ0, Σ, Σ0) = M (x; µk, Σ) − M (x; µ0, Σ0),

where µk is the mean of class k, µ0 is the mean of the dataset
as a whole, Σ is the covariance matrix of each class k, and Σ0
is the covariance matrix of the dataset as a whole. To be clear,
s ) and µ0 = 1
µk = 1
s ),
KS
K
while

s=1 fθ(xk

s=1 fθ(xk

(cid:80)K

(cid:80)S

(cid:80)S

k=1

Σ =

1
KS

K
(cid:88)

S
(cid:88)

k=1

s=1

(fθ(xk

s ) − µk)(fθ(xk

s ) − µk)T ,

and

Σ0 =

1
KS

K
(cid:88)

S
(cid:88)

k=1

s=1

(fθ(xk

s ) − µ0)(fθ(xk

s ) − µ0)T .

The authors in [23] argue that subtracting out M (x; µ0, Σ0)
removes the outlier score contribution along dimensions that
are not discriminative between in and out of distribution
examples. This is especially important for scenarios in which
a large number of dimensions are not discriminative.

While the relative Mahalanobis distance is effective at
discriminating between in and out of distribution examples, it
is not particularly interpretable. To ease its use, after training
is complete, we ﬁt a kernel density estimate to the relative
Mahalanobis distances computed on a set of held-out
in
distribution examples Xcal. We use a support set of size
Scal = 100 sampled from the training data to ﬁt the means
and full covariance matrices used in the relative Mahalanobis
distance. We refer to this process as calibration and summarize
our procedure in Algorithm 2.

At test time, to compute a p-value for a particular test point,
we calculate the area under the density corresponding to the
predicted class for distances larger than the relative Maha-
lanobis distance of the test point. To maintain the convention
that large scores indicate OOD examples, we take one minus
the p-value as our OOD score. We summarize this procedure
in Algorithm 3.

V. EXPERIMENTS AND RESULTS

Algorithm 2 Calibrate
Require: Xtrain, ytrain, Xcal, ycal, Scal, fθ

s }Scal

s=1 from the training data for each

Sample support {xk
class k
Compute µk, for each class k, µ0, Σ and Σ0 as deﬁned in
Section IV-D with S = Scal
for 1 ≤ k ≤ K do

Compute Σk = 1
Scal
(used only in testing phase)

(cid:80)Scal

s=1 (fθ(xk

s ) − µk)(fθ(xk

s ) − µk)T

Compute relative Mahalanobis distance for calibration

examples M k

rel(fθ(xk

i ))

Fit Gaussian kernel density estimate Gk to the set of

relative Mahalanobis distances M k
end for

rel(fθ(xk

i ))

Ensure: Gk, µk, µ0, Σ, Σ0, Σk

Algorithm 3 Test
Require: Gk, µk, µ0, Σ, Σ0, Σk xtest, fθ

Compute predicted class k∗ as in Equation 1 where dk =
M (x; µk, diag(Σk))
Compute r = M k∗
Compute p-value p = (cid:82) ∞

rel(fθ(xtest))

r Gk∗ (r(cid:48))dr(cid:48)

Ensure: 1 − p

A. Model Performance on the Dataset

First, we train the model on the provided dataset using
an increasing, stratiﬁed fraction of the dataset and compute
the F1-scores (harmonic average of precision and recall) on
a held-out test set (20% of the data). We also compute the
model’s Expected Calibration Error (ECE) as a way to measure
the quality of its probabilistic forecasts. ECE measures the
discrepancy between a model’s predicted probability and the
observed accuracy of those predictions. For more details, see
[53]. For each training dataset size considered, we repeat the
experiment ten times. The results for F1-score and ECE are
shown in Figs. 4 and 5. Clearly, the model’s performance
improves as we increase the fraction of data provided, both
for F1-score and ECE. It is interesting to note that we achieve
quite good performance with only a limited number of training
examples. To call out a speciﬁc example, using 10%5 of the
training data corresponds to 59 examples of Command &
Control, 422 examples of Chat, 33 examples of File Transfer,
71 examples of Streaming, and just 10 examples of VoIP. Even
with only this very small training set, we are able to obtain
a micro F1-score of nearly 0.96. Additionally, the calibration
error using 10% of the data for training is about 0.04, which
indicates the model’s conﬁdence is fairly consistent with its
accuracy. Marginal gains in calibration (lower ECE values)
can be achieved via neural network ensembles as in [18] (data
not shown); we speculate that the relatively shallow network,
dropout, and Prototypical Network architecture helped to en-

In order to validate our framework, we perform a series
of increasingly challenging tests for our machine learning
framework.

5Technically, only 8% of the data is used for training, as 20% of the
10% is reserved internally by our implementation for generating the p-value
distributions.

7

C2

0.97

0.00

0.00

0.00

0.02

CHAT

0.00

0.99

0.00

0.00

0.00

l
a
u
t
c
A

FT

0.01

0.01

0.94

0.01

0.03

STREAM

0.00

0.01

0.01

0.95

0.03

VOIP

0.00

0.00

0.00

0.00

1.00

C 2

C H A T

F T
Predicted

M

S T R E A

V OIP

Fig. 6. Average confusion matrix for 10 runs using a randomized 80/20
train/test split (FT indicates File Transfer).

times. The results were quite good. For the YouTube trafﬁc, the
model predicted the correct class 40 out of 40 times in nine
of the trials and 39 out of 40 times in the other trial, only
predicting one of the examples to have an OOD score above
0.95 on average6. Thus, even though the YouTube trafﬁc was
collected on a different network than the one that the training
data came from, the model was still able to recognize its class
(Streaming). This is an encouraging result, although we do not
rely on this transferability holding true for all applications in
the training set, as will be demonstrated next.

To answer the second question, we collected data from
three applications that do not appear in the training data
(Avaya, Samba (SMB), and the Code42 automated ﬁle backup
program). In our labeling schema, we consider Avaya to be
a VoIP application and SMB and Code42 to be File Transfer.
We collected 123 examples of Avaya, 141 examples of SMB,
and 202 examples of Code42. As before, we trained on 80%
of our training dataset (for ten trials) and tested on the new
applications. Avaya was easily recognized by the model as
VoIP trafﬁc, correctly labeling all 123 examples in each trial,
although the model was less certain about them, assigning
about half of them OOD scores above 0.95. SMB and Code42,
however, were not initially recognized as File Transfer. En-
couragingly, the model tended to give these examples a high
OOD score. Speciﬁcally, across the ten trials, an average of
78% of the SMB trafﬁc received an OOD score above 0.95,
and an average of about 63% of the ﬁle backup program
received an OOD score above 0.95.

To see whether the model could learn to classify SMB and
Code42 as File Transfer, given a few training examples, we
investigate retraining the model. For the case of SMB, we
add 91 examples to our training set and test on the remaining

6We have selected OOD scores above 0.95 as a threshold of interest, as
it corresponds to a p-value of 0.05 or lower for rejecting the null hypothesis
that the test samples are in-distribution.

Fig. 4. Micro F1-score of the model against the fraction of data used to
train the model. We plot the average F1-score over ten trials. The error bars
indicate one standard deviation.

ECE of the model against the fraction of data used to train the
Fig. 5.
model. We plot the average F1-score over ten trials. The error bars indicate
one standard deviation.

able the low ECE values. Fig. 6 depicts the average confusion
matrix for each of the ten training runs using an 80/20 train/test
split, indicating that the model performs well in every category,
the worst confusion being 3% of File Transfer examples being
incorrectly predicted as VoIP.

B. Model Performance in a New Environment

Having established the “usual” ML metrics, we then turn
to a more challenging problem of validation outside of the
training dataset. To do these experiments, we used Wire-
shark to capture network trafﬁc on a live, enterprise network,
and then tested our model on this new trafﬁc. We consider
three increasingly challenging scenarios. First, can the model
recognize trafﬁc from an existing application in an existing
category? Second, can the model recognize new applications
in an existing category? Finally, can the model detect data that
is out of distribution (comes from a new category)?

To answer the ﬁrst question, we collected 40 additional in-
stances of YouTube (an application in the Streaming category).
We trained the model on 80% of our training dataset and then
tested on the YouTube data. We repeated the experiment ten

8

50. After retraining, the model is able to correctly classify
an average of 92% of the test samples. In addition, the OOD
scores are much lower. After retraining, only an average of
10% of examples had OOD scores above 0.95 (left side of
Figure 7). Figure 7 also provides the predictive conﬁdences
before and after retraining with examples of SMB, which
refers to the probability associated with the class prediction
(the highest probability class among known classes). The
distributions exhibit high conﬁdences both before and after
retraining. This indicates that it is important to not rely solely
on the predictive conﬁdences for uncertainty quantiﬁcation, as
they are essentially meaningless when applied to OOD test
examples.

In the case of Code42, we add 42 examples to our training
set and test on the remaining 160. The model now correctly
classiﬁes an average of 98% of the test samples. As with SMB,
the OOD scores are now much lower as well, with only an
average of 5% with scores above 0.95. In Figure 8, we show
OOD score and predictive conﬁdence before and after training
with examples of Code42.

Fig. 7. Model uncertainties for SMB from an enterprise network before
(using a pretrained model from our dataset) and after retraining (adding 91
labeled examples).

Fig. 8. Model uncertainties for Code42 from an enterprise network before
(using a pretrained model from our dataset) and after retraining (adding 42
labeled examples).

9

Fig. 9. Distribution of Zoom OOD scores on a held-out validation set of
128 examples (sum of 10 runs) using the pretrained model from our dataset
(“Before Training”) and after retraining with 195 labeled examples (“After
Training”).

To answer the ﬁnal question, we collected 323 examples
of Zoom, which is a new application of a new category one
could label as Video TeleConferencing (VTC). Since VTC is
a new class, we expect that the model will give high OOD
scores to the Zoom examples. This ended up being the case,
as an average of 78% of examples had an OOD score above
0.95. We then retrained our model with 195 Zoom examples
added to the training set (with the new VTC label). After
retraining, the fraction of OOD scores above 0.95 is reduced
to 26%. Figure 9 depicts the distribution of OOD scores
before and after training on a held-out validation set of 128
Zoom examples; the post-training results are more uniform,
as expected. Across 10 trials, the model correctly labeled an
average of 73% of the validation examples as Zoom, generally
confusing the errors as VoIP. We note that this accuracy is
lower than the previous examples, however, about 97% of the
incorrectly labeled examples still have OOD scores above 0.95,
indicating that these errors can easily be screened out due to
their model uncertainty. It perhaps indicates that Zoom trafﬁc
behaves differently depending upon its mode of usage (screen
sharing, video, or audio-only); it may be possible to cluster
self-similar OOD examples in the embedding space to assist
analysts with new labeling.

C. Model Performance on Padded Packets

Finally, in order to address any concerns about the model’s
resilience to encryption protocols that pad packets to be of
uniform size, we repeated the initial testing on the collected
dataset but masked the sizes of all packets to be 1500 bytes
before feature generation. Upon retraining ten times with 80/20
train/test splits, the model retained an average F1-score of
0.971 ± 0.008 on the dataset. This is a marginal drop from the
raw, unpadded data, at 0.982 ± 0.004. These results indicate
that our model is not much affected by the effective removal of
packet size information. In addition, this result presents initial
evidence that packet padding alone may not offer substantial
privacy beneﬁts, at least at the level of granularity of trafﬁc

categories.

VI. DISCUSSION

The results of the previous section appear very encouraging,
particularly since (1) the framework performs effectively,
achieving high accuracy without requiring rigorous feature
optimizations and on only timing and size information, (2)
the dataset and model extended in part to another network for
YouTube and VoIP, and (3) the model “degraded gracefully”
when confronted with novel application data and was quick
to retrain on limited data. We envision this framework to be
used in a tool that would allow network analysts to systemat-
ically build insight for applications of interest in conjunction
with other analysis techniques (malware signatures, website
ﬁngerprinting, etc.) to supplement where they fail.

Shorter window-lengths could hypothetically provide more
label opportunities over the entire observation period, but arbi-
trarily short window lengths would reduce accuracy (additional
analysis is provided in Figure 10). Longer window-lengths
within a VPN would also be more likely to merge multiple
application types into the same sample, and our approach
only predicts one application per time window; future work
needs to address concurrent applications. We also note that
this framework does not leverage continuity between time-
windows as of yet, and certain connections can tend to be
shorter (loading a web page) or longer (streaming movies).

Our approach can also be attacked and degraded by ma-
nipulating the trafﬁc, e.g., by adding “cover packets” to
ﬂood connections or mask timings, re-encoding trafﬁc through
another protocol [64] or by leveraging adversarial ML [65],
[66]. However, our approach still retains an advantage in that
it forces an adversary to work harder to obfuscate the nature
of their connections. We also note that our approach could
be used to “red-team” censorship evasion development by
incorporating uncertainty in addition to the standard accuracy
metrics.

We ﬁnally comment that although our dataset does not
comprehensively capture the diversity of Internet applications,
it was enough to “generate intuition” for a generic ML
framework to predict time-windowed, encrypted application
trafﬁc on a different network, and we have demonstrated
the importance of treating uncertainty as a ﬁrst-class feature
to enable a systematic extension of the dataset onto other
networks or application categories of interest.

VII. CONCLUSIONS

We presented a labeled dataset of VPN-encrypted and un-
encrypted network trafﬁc to facilitate machine learning appli-
cations seeking to leverage packet size and timing information
to predict the trafﬁc’s most likely application categories. We
discussed potential
issues and possible workarounds for a
popular alternative dataset, which motivated the organization
of our dataset. We showed a machine learning framework
leveraging wavelet-based and statistical features on discrete,
sampled time windows in a Prototypical Network architecture

that achieved high F1 scores (0.98) on the labeled dataset. Fur-
ther, we showed the architecture could be trained on a small,
random fraction of the dataset, achieving an accuracy of 0.96
on VOIP using fewer than 7 minutes of data. Additionally, we
demonstrated low calibration errors for predictive conﬁdence
(3%). We also tested the model on application trafﬁc (YouTube
and a new VoIP application) from an enterprise network and
found it extended accurately.

We used a technique for constructing an out-of-distribution
(OOD) score based on p-values of the relative Mahalanobis
distance on in-distribution data to reliably indicate model
degradation in a series of increasingly challenging experi-
ments. In all cases, the model retrained quickly with relatively
few examples to learn to incorporate the new applications
into a known category or assign them to a new one. We
additionally demonstrated that the framework retains very high
performance (F1-score of 0.97) even when all packet sizes are
uniform, such as occurs in encryption protocols that ensure
all packets are padded to the same size before encryption. We
ﬁnally discussed limitations of the current approach.

ACKNOWLEDGMENT

DISTRIBUTION STATEMENT A. Approved for public
release. Distribution is unlimited. This material is based upon
work supported by USCYBERCOM under Air Force Contract
No. FA8702-15-D-0001. Any opinions, ﬁndings, conclusions
or recommendations expressed in this material are those of
the author(s) and do not necessarily reﬂect
the views of
USCYBERCOM.

APPENDIX

FILENAME-TO-CATEGORY MAPPINGS

We use the mappings shown in Table V to assign class labels
to each PCAP ﬁle. If any of the words in the “File Keyword”
column occurs in the column name, then we assign the label
in the left column.

TABLE V
FILENAME-TO-CATEGORY LABELING SCHEME.

Trafﬁc Category

File Keyword

STREAMING
CHAT
C2
FILE TRANSFER
VOIP

vimeo, netﬂix, youtube
chat
ssh, rdp
sftp, rsync, scp
voip

WAVELET-BASED FEATURES

This section provides details on how to calculate the
wavelet-based features extracted from the wavelet-transformed
connection sizes in the forward and backward directions for
frequency bands 0 to 12. The wavelet-based features include
the relative wavelet energy, Shannon entropy, and absolute
means and standard deviations of the detail coefﬁcients.

10

The continuous wavelet transform coefﬁcients are deﬁned

by the equation:

d(a, b) =

1
(cid:112)|a|

(cid:90) T

0

x(t)ψ

(cid:19)

(cid:18) t − b
a

dt ,

(2)

a

where x(t) is the time-dependent signal over the observation
period [0, T ] (for instance, bytes transferred in a ﬂow during
a sample interval), ψ (cid:0) t−b
(cid:1) is the wavelet function, a is the
scale factor, and b is the translation factor. This work employs
the discrete wavelet transformation, which restricts a and b to
discrete values that balance temporal and frequency resolution
while reducing computational burden. We employ the shift-
invariant (stationary) wavelet transformation to ensure that
the resulting features are insensitive to signal translations,
otherwise known as the “algorithm a-trous” [67], [68].

The time-dependent signal, x(t), required for the wavelet
transform, is represented by a discrete vector over an obser-
vation period from [0, T ] that is discretized into N smaller
time bins of width ∆t. Within each ∆t time interval, all of
the packet statistics are aggregated. For instance, let tj, yj be
the packet timestamp and size for packet j in a series of J
ﬂow-aggregated packets with t0 = 0. Then a vector version
of x(t), appropriate for the wavelet transform, is deﬁned by
xn(t), where T = N ∆t, n ∈ [0, N − 1], and

Fig. 10. A study in the sensitivity of the overall machine learning accuracy
with respect to different choices of window-length T and three time-bin sizes
∆t, 0.1, 0.01, and 0.001 seconds. Note the semi-log x-scale.

where pn is the fraction of energy of the n-th detail coefﬁcient,
d2
n,k
Ek

pn =

(7)

.

Detail Coefﬁcient Statistics

For each frequency band k, the absolute mean of the detail

coefﬁcients µk is given by

µk =

1
N

(cid:88)

n

|dn,k|

for n = 1, 2, . . . , N ,

(8)

and the standard deviation of the detail coefﬁcients σn is given
by

xn(t) =

J
(cid:88)

j=0

yjχj(t) ; χj(t) =

(cid:40)

1 n∆t ≤ tj < (n + 1)∆t
0

else

.

σk =

(cid:115)

1
N

(cid:88)

(µk − dn,k)2

n

for n = 1, 2, . . . , N .

(9)

We enforce that the length of the vector xn be an integer power
of 2 (N = 2K for some K) by judiciously selecting ∆t and
T , or by reﬂecting the signal in our pipeline. Applying Eq. 2
for ﬁxed values of a ∈ 2k and b ∈ xn gives a rectangular
coefﬁcient matrix of the form dn,k, where n ∈ [0, N − 1]
indexes the coefﬁcients in time and k ∈ [0, K] indexes the
coefﬁcients in frequency-band.

Relative Wavelet Energy

For each frequency band k, the relative wavelet energy ρk

is given by

Ek
Etotal
where Ek is the energy of frequency band k

for k = 0, 1, . . . , K ,

ρk =

Ek =

|dn,k|2

(cid:88)

n

for n = 1, 2, . . . , N ,

(4)

and Etotal
decomposition

is the total energy of the signal after wavelet

Etotal =

(cid:88)

k

Ek

for k = 0, 1, . . . , K .

(5)

Wavelet Shannon Entropy

For each frequency band k, the wavelet Shannon entropy

Sk is given by

Sk = −

(cid:88)

n

pn log(pn)

for n = 1, 2, . . . , N ,

(6)

Figure 10 depicts the results of a range of experiments
using three time bins (∆t of 1, 10, and 100 milliseconds)
and variable time-windows, T . The general
trend is that,
the longer the sample window, T ,
the more accurate the
model. However, this has the tradeoff that longer windows
require longer vectors, particularly for small time bins (note
that we capped the number of wavelet bands at 13 to limit
feature-computation requirements). The second-to-rightmost
blue datapoint represents (∆t, T )=(0.01, 40.96), the selected
value for the analysis in this paper, as this neared the maximum
accuracy and used an acceptable vector length for computing
the wavelet features.

(3)

REFERENCES

[1] Nov. 2021, accessed 15-November-2021. [Online]. Available: https:

[2] L. O. A. H. Eric Ahlm,

//transparencyreport.google.com/https/overview?hl=en
Jeremy D’Hoinne,

“Predicts 2017:
Network and gateway security,” Gartner Research, Tech. Rep., 2016.
[Online]. Available: https://www.gartner.com/en/documents/3542117/
predicts-2017-network-and-gateway-security

Hall,

[3] C.

Warﬁeld

J.
and
accessed
15-November-2021.
https://www.watchguard.com/wgrd-news/press-releases/
watchguard-threat-lab-reports-915-malware-arrived-over-encrypted
[4] V. Rimmer, D. Preuveneers, M. Juarez, T. Van Goethem, and W. Joosen,
“Automated website ﬁngerprinting through deep learning,” in Network
and Distributed Systems Security Symposium 2018, 2017.

2021,
Available:

[Online].

Sep.

[5] N. P. Hoang, A. A. Niaki, P. Gill, and M. Polychronakis, “Domain
Name Encryption Is Not Enough: Privacy Leakage via IP-based Website
Fingerprinting,” arXiv:2102.08332 [cs], Jun. 2021, arXiv: 2102.08332.
[Online]. Available: http://arxiv.org/abs/2102.08332

[6] Nov. 2021, accessed 15-November-2021. [Online]. Available: https:

//nordvpn.com/features/obfuscated-servers/

11

[7] T. Perrin, “The noise protocol

framework,” Jul. 2018, accessed
15-November-2021. [Online]. Available: http://www.noiseprotocol.org/
noise.html

[8] R. Alshammari and A. N. Zincir-Heywood, “Machine learning based
encrypted trafﬁc classiﬁcation: Identifying ssh and skype,” in 2009 IEEE
Symposium on Computational Intelligence for Security and Defense
Applications.

IEEE, 2009, pp. 1–8.

[9] G. Draper-Gil, A. H. Lashkari, M. S. I. Mamun, and A. A. Ghorbani,
“Characterization of encrypted and VPN trafﬁc using time-related fea-
tures,” in Proceedings of the 2nd international conference on information
systems security and privacy (ICISSP), 2016, pp. 407–414.

[10] Y. Liang, Y. Xie, X. Fei, X. Tan, and H. Ma, “Content recognition
of network trafﬁc using wavelet transform and cnn,” in International
Conference on Machine Learning for Cyber Security. Springer, 2019,
pp. 224–238.

[11] M. Abbasi, A. Shahraki, and A. Taherkordi, “Deep learning for
network trafﬁc monitoring and analysis (ntma): A survey,” Computer
Communications, vol. 170, pp. 19–41, 2021.
[Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0140366421000426

[12] W. Wang, M. Zhu, J. Wang, X. Zeng, and Z. Yang, “End-to-end
encrypted trafﬁc classiﬁcation with one-dimensional convolution neural
networks,” in 2017 IEEE International Conference on Intelligence and
Security Informatics (ISI), 2017, pp. 43–48.

[13] W. Wang, M. Zhu, X. Zeng, X. Ye, and Y. Sheng, “Malware trafﬁc
classiﬁcation using convolutional neural network for representation
learning,” in 2017 International Conference on Information Networking
(ICOIN), 2017, pp. 712–717.

[14] S. Rezaei and X. Liu, “How to achieve high classiﬁcation accuracy with
just a few labels: A semisupervised approach using sampled packets,” in
Advances in Data Mining - Applications and Theoretical Aspects, 19th
Industrial Conference, ICDM 2019, New York, USA, July 17 - July 21,
2019, P. Perner, Ed.

ibai Publishing, 2019, pp. 28–42.

[15] M. Lotfollahi, M. Jafari Siavoshani, R. Shirali Hossein Zade, and
M. Saberian, “Deep packet: a novel approach for encrypted trafﬁc
classiﬁcation using deep learning,” Soft Computing, vol. 24, no. 3, 2020.
[16] I. Akbari, M. A. Salahuddin, L. Ven, N. Limam, R. Boutaba,
B. Mathieu, S. Moteau, and S. Tufﬁn, “A look behind the curtain:
Trafﬁc classiﬁcation in an increasingly encrypted web,” Proc. ACM
Meas. Anal. Comput. Syst., vol. 5, no. 1, Feb. 2021. [Online]. Available:
https://doi.org/10.1145/3447382

[17] K. Highnam, K. Arulkumaran, Z. Hanif, and N. R. Jennings, “Beth
dataset: Real cybersecurity data for anomaly detection research,” in
ICML 2021 Workshop on Uncertainty & Robustness in Deep Learning,
2021.

[18] K. E. Brown, F. A. Bhuiyan, and D. A. Talbert, “Uncertainty quantiﬁca-
tion in multimodal ensembles of deep learners,” in FLAIRS Conference,
2020.

[19] D. Engel, K. Jarman, Z. Xu, B. Zheng, A. Tartakovsky, X. Yang,
R. Tipireddy, H. Lei, and J. Yin, “Q Methods for HPDA and Cy-
bersecurity Models, Data, and Use Cases,” Paciﬁc Northwest National
Laboratory, Tech. Rep., 2015.

[20] M. C. Darling and D. J. Stracuzzi, “Toward uncertainty quantiﬁcation
classiﬁcation,” Sandia National Lab.(SNL-NM),
[Online].

for
Albuquerque, NM (United States), Tech. Rep., 1 2018.
Available: https://www.osti.gov/biblio/1527311

supervised

[21] E. Papadogiannaki and S. Ioannidis, “A survey on encrypted network
trafﬁc analysis applications, techniques, and countermeasures,” ACM
Comput. Surv., vol. 54, no. 6,
[Online]. Available:
https://doi.org/10.1145/3457904

jul 2021.

[22] J. Snell, K. Swersky, and R. Zemel, “Prototypical networks for few-shot
learning,” in Advances in neural information processing systems, 2017,
pp. 4077–4087.

[23] J. Ren, S. Fort, J. Liu, A. Guha Roy, S. Padhy, and B. Lakshminarayanan,
“A simple ﬁx to mahalanobis distance for improving near-ood detection,”
in Uncertainty in Deep Learning Workshop, International Conference on
Machine Learning, 2021.

[24] S. Kent, “IP Encapsulating Security Payload (ESP),” Internet Requests
for Comments, RFC Editor, Tech. Rep. 4303, 2005. [Online]. Available:
https://www.rfc-editor.org/info/rfc4303

[25] M. C. Tschantz, S. Afroz, V. Paxson et al., “Sok: Towards grounding
censorship circumvention in empiricism,” in 2016 IEEE Symposium on
Security and Privacy (SP).

IEEE, 2016, pp. 914–933.

and challenges,” in 2015 Tenth International Conference on Digital
Information Management (ICDIM).

IEEE, 2015, pp. 43–48.

[27] A. C. Callado, C. A. Kamienski, G. Szab´o, B. P. Gero, J. Kelner,
S. F. Fernandes, and D. F. H. Sadok, “A survey on internet trafﬁc
identiﬁcation,” IEEE Communications Surveys and Tutorials, vol. 11,
no. 3, pp. 37–52, 2009.

[28] M. Roughan, S. Sen, O. Spatscheck, and N. Dufﬁeld, “Class-of-service
mapping for QoS: a statistical signature-based approach to IP trafﬁc
classiﬁcation,” in Proceedings of the 4th ACM SIGCOMM conference
on Internet measurement. ACM, 2004, pp. 135–148.

[29] A. W. Moore and K. Papagiannaki, “Toward the accurate identiﬁcation
of network applications,” in Passive and Active Network Measurement,
C. Dovrolis, Ed. Berlin, Heidelberg: Springer Berlin Heidelberg, 2005,
pp. 41–54.

[30] L. Deri, M. Martinelli, T. Bujlow, and A. Cardigliano, “nDPI: Open-
source high-speed deep packet inspection,” in 2014 International Wire-
less Communications and Mobile Computing Conference (IWCMC),
Aug 2014, pp. 617–622.

[31] A. W. Moore and K. Papagiannaki, “Toward the accurate identiﬁcation of
network applications,” in International Workshop on Passive and Active
Network Measurement. Springer, 2005, pp. 41–54.

[32] S. Sen, O. Spatscheck, and D. Wang, “Accurate, scalable in-network
identiﬁcation of p2p trafﬁc using application signatures,” in Proceedings
of the 13th International Conference on World Wide Web, ser. WWW
’04. New York, NY, USA: ACM, 2004, pp. 512–521. [Online].
Available: http://doi.acm.org/10.1145/988672.988742

[33] T. Choi, C. Kim, S. Yoon, J. Park, B. Lee, H. Kim, H. Chung,
and T. Jeong, “Content-aware internet application trafﬁc measurement
and analysis,” in IEEE/IFIP Network Operations and Management
Symposium.

IEEE, 2004.

[34] B. Anderson and D. McGrew, “Identifying encrypted malware trafﬁc
with contextual ﬂow data,” in Proceedings of the 2016 ACM workshop
on artiﬁcial intelligence and security, 2016, pp. 35–46.

[35] A. McGregor, M. Hall, P. Lorier, and J. Brunskill, “Flow clustering using
machine learning techniques,” in International workshop on passive and
active network measurement. Springer, 2004, pp. 205–214.

[36] S. Zander, T. Nguyen, and G. Armitage, “Automated trafﬁc classiﬁcation
and application identiﬁcation using machine learning,” in The IEEE
Conference on Local Computer Networks 30th Anniversary (LCN’05)
l.

IEEE, 2005, pp. 250–257.

[37] W. Li, M. Canini, A. W. Moore, and R. Bolla, “Efﬁcient application
identiﬁcation and the temporal and spatial stability of classiﬁcation
schema,” Computer Networks, vol. 53, no. 6, pp. 790–809, 2009.
[38] R. Yuan, Z. Li, X. Guan, and L. Xu, “An SVM-based machine learning
method for accurate internet trafﬁc classiﬁcation,” Information Systems
Frontiers, vol. 12, no. 2, pp. 149–156, 2010.

[39] M. Soysal and E. G. Schmidt, “Machine learning algorithms for accurate
ﬂow-based network trafﬁc classiﬁcation: Evaluation and comparison,”
Performance Evaluation, vol. 67, no. 6, pp. 451–467, 2010.

[40] H. Zhang, G. Lu, M. T. Qassrawi, Y. Zhang, and X. Yu, “Feature se-
lection for optimizing trafﬁc classiﬁcation,” Computer Communications,
vol. 35, no. 12, pp. 1457–1471, 2012.

[41] A. Fahad, Z. Tari, I. Khalil, A. Almalawi, and A. Y. Zomaya, “An
optimal and stable feature selection approach for trafﬁc classiﬁcation
based on multi-criterion fusion,” Future Generation Computer Systems,
vol. 36, pp. 156–169, 2014.

[42] B. Yamansavascilar, M. A. Guvensan, A. G. Yavuz, and M. E. Karsligil,
“Application identiﬁcation via network trafﬁc classiﬁcation,” in 2017 In-
ternational Conference on Computing, Networking and Communications
(ICNC).

IEEE, 2017, pp. 843–848.

[43] A. H. Lashkari, G. Draper-Gil, M. S. I. Mamun, and A. A. Ghorbani,
“Characterization of Tor trafﬁc using time based features.” in ICISSP,
2017, pp. 253–262.

[44] H. Shi, H. Li, D. Zhang, C. Cheng, and W. Wu, “Efﬁcient and robust
feature extraction and selection for trafﬁc classiﬁcation,” in Computer
Networks, 2017, pp. 1–16.

[45] A. C. Gilbert, W. Willinger, and A. Feldmann, “Scaling analysis of
conservative cascades, with applications to network trafﬁc,” IEEE Trans-
actions on Information Theory, vol. 45, no. 3, pp. 971–991, 1999.
[46] S. Moln´ar, I. Maricza, I. Maricza, T. Daniels, J. F¨arber, M. Frater et al.,
“Source characterization in broadband networks,” Interim report, COST,
vol. 257, 1999.

[26] N. Al Khater and R. E. Overill, “Network trafﬁc classiﬁcation techniques

[47] R. H. Riedi, M. S. Crouse, V. J. Ribeiro, and R. G. Baraniuk, “A

12

USA: Association for Computing Machinery, May 2021, pp. 147–161.
[Online]. Available: https://doi.org/10.1145/3433210.3453080

[65] M. Nasr, A. Bahramali, and A. Houmansadr, “Defeating dnn-based
trafﬁc analysis systems in real-time with blind adversarial perturbations,”
in 30th {USENIX} Security Symposium ({USENIX} Security 21), 2021.
[66] K. Bock, G. Hughey, X. Qiang, and D. Levin, “Geneva: Evolving
censorship evasion strategies,” in Proceedings of the 2019 ACM SIGSAC
Conference on Computer and Communications Security, ser. CCS ’19.
New York, NY, USA: Association for Computing Machinery, 2019,
p. 2199–2214.
[Online]. Available: https://doi.org/10.1145/3319535.
3363189

[67] M. Holschneider, R. Kronland-Martinet, J. Morlet, and P. Tchamitchian,
“A real-time algorithm for signal analysis with the help of the wavelet
transform,” in Wavelets. Springer, 1990, pp. 286–297.

[68] D. Percival and A. Waldern, Wavelet Methods for Time Series Analysis.

Cambridge University Press, 2000.

multifractal wavelet model with application to network trafﬁc,” IEEE
transactions on Information Theory, vol. 45, no. 3, pp. 992–1018, 1999.
[48] R. H. Riedi and W. Willinger, “Toward an improved understanding of
network trafﬁc dynamics,” Self-Similar Network Trafﬁc and Performance
Evaluation, pp. 507–530, 2000.

[49] T. Hastie, R. Tibshirani, and J. Friedman, The elements of statistical
learning: data mining, inference, and prediction. Springer Science &
Business Media, 2009.

[50] S. Bhat, D. Lu, A. Kwon, and S. Devadas, “Var-CNN: A Data-Efﬁcient
Website Fingerprinting Attack Based on Deep Learning,” Proceedings
on Privacy Enhancing Technologies, vol. 2019, no. 4, pp. 292–310, Oct.
2019.

[51] M. S. Rahman, P. Sirinam, N. Mathews, K. G. Gangadhara,
“Tik-Tok: The Utility of Packet Timing in
and M. Wright,
Website Fingerprinting Attacks,” Proceedings on Privacy Enhancing
Technologies, vol. 2020, no. 3, pp. 5–24, Jul. 2020, arXiv: 1902.06421.
[Online]. Available: http://arxiv.org/abs/1902.06421

[52] M. Juarez, S. Afroz, G. Acar, C. Diaz, and R. Greenstadt, “A critical
evaluation of website ﬁngerprinting attacks,” in Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Security,
2014, pp. 263–274.

[53] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, “On calibration
of modern neural networks,” in Proceedings of the 34th International
Conference on Machine Learning,
ser. Proceedings of Machine
Learning Research, D. Precup and Y. W. Teh, Eds., vol. 70.
PMLR, 06–11 Aug 2017, pp. 1321–1330.
[Online]. Available:
https://proceedings.mlr.press/v70/guo17a.html

[54] B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and
scalable predictive uncertainty estimation using deep ensembles,” in
Advances in Neural Information Processing Systems, I. Guyon, U. V.
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan,
and R. Garnett, Eds.,
Inc.,
2017.
[Online]. Available: https://proceedings.neurips.cc/paper/2017/
ﬁle/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf

Curran Associates,

vol.

30.

[55] A. G. Wilson and P.

Izmailov, “Bayesian deep learning and a
probabilistic perspective of generalization,” in Advances in Neural
Information Processing Systems 33: Annual Conference on Neural
Information Processing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and
H. Lin, Eds., 2020. [Online]. Available: https://proceedings.neurips.cc/
paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html

[56] D. Hendrycks and K. Gimpel, “A baseline for detecting misclassiﬁed and
out-of-distribution examples in neural networks,” in 5th International
Conference on Learning Representations, ICLR 2017, Toulon, France,
April 24-26, 2017, Conference Track Proceedings. OpenReview.net,
2017. [Online]. Available: https://openreview.net/forum?id=Hkg4TI9xl
[57] S. Liang, Y. Li, and R. Srikant, “Enhancing the reliability of
out-of-distribution image detection in neural networks,” in 6th
International Conference on Learning Representations, ICLR 2018,
Vancouver, BC, Canada, April 30 - May 3, 2018, Conference
Track Proceedings.
[Online]. Available:
OpenReview.net, 2018.
https://openreview.net/forum?id=H1VGkIxRZ

[58] A. Malinin and M. Gales, “Predictive uncertainty estimation via prior
networks,” in Proceedings of the 32nd International Conference on Neu-
ral Information Processing Systems, ser. NIPS’18, 2018, p. 7047–7058.
[59] T. Tsiligkaridis, “Information aware max-norm dirichlet networks for
predictive uncertainty estimation,” Neural Networks, vol. 135, pp.
105–114, 2021. [Online]. Available: https://doi.org/10.1016/j.neunet.
2020.12.011

[60] K. Lee, K. Lee, H. Lee, and J. Shin, “A simple uniﬁed framework for
detecting out-of-distribution samples and adversarial attacks,” Advances
in neural information processing systems, vol. 31, 2018.

[61] K.-C. Wang, P. Vicol, E. Triantaﬁllou, C.-C. Liu, and R. Zemel, “Out-
of-distribution detection in few-shot classiﬁcation,” 2020. [Online].
Available: https://openreview.net/forum?id=BygNAa4YPH

[62] freeCodeCamp.org.

(2016)

freeCodeCamp/gitter-history.

[Online].

Available: https://github.com/freeCodeCamp/gitter-history

[63] G. R. Lee, R. Gommers, F. Waselewski, K. Wohlfahrt, and A. O’Leary,
“Pywavelets: A python package for wavelet analysis,” Journal of Open
Source Software, vol. 4, no. 36, p. 1237, 2019.

[64] P. K. Sharma, D. Gosain, and S. Chakravarty, “Camouﬂer: Accessing
The Censored Web By Utilizing Instant Messaging Channels,” in
Proceedings of
the 2021 ACM Asia Conference on Computer and
Communications Security, ser. ASIA CCS ’21. New York, NY,

13

