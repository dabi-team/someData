Eﬃcient Collective Action for Tackling
Time-Critical Cybersecurity Threats

Sébastien Gillard1,2 [0000-0002-3237-8599], Dimitri Percia David1,3,4 [0000-0002-9393-1490]
Alain Mermoud3 [0000-0001-6471-772X] and Thomas Maillart1,5 [0000-0002-5747-9927]

1 Information Science Institute, Geneva School of Economics and Management, University of Geneva
2 Department of Defense Economics, Military Academy at ETH Zurich
3 Cyber-Defence Campus, armasuisse Science and Technology
4 Institute of Entrepreneurship & Management, School of Management, University of Applied Sciences of Western

Switzerland (HES-SO Valais-Wallis)

5 Citizen Cyber Lab, University of Geneva

Presented at the 21st Workshop on the Economics of Information Security (WEIS),
2022, Tulsa, USA
https://weis2022.econinfosec.org/

Abstract

The latency reduction between the discovery of vulnerabilities, the build-up
and dissemination of cyber-attacks has put signiﬁcant pressure on cybersecurity
professionals. For that, security researchers have increasingly resorted to
collective action in order to reduce the time needed to characterize and tame
outstanding threats. Here, we investigate how joining and contributions
dynamics on MISP, an open source threat intelligence sharing platform,
inﬂuence the time needed to collectively complete threat descriptions. We ﬁnd
that performance, deﬁned as the capacity to characterize quickly a threat event,
is inﬂuenced by (i) its own complexity (negatively), by (ii) collective action
(positively), and by (iii) learning, information integration and modularity
(positively). Our results inform on how collective action can be organized at
scale and in a modular way to overcome a large number of time-critical tasks,
such as cybersecurity threats.

Keywords— cybersecurity, information sharing, collective action, information
integration, economies of scales, Malware Information Sharing Platform (MISP)

2
2
0
2

t
c
O
9

]

R
C
.
s
c
[

2
v
5
5
0
5
1
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
1

Introduction

From Computer Emergency Readiness Teams (CERT) established in the nineties [1], to
information-sharing analysis centers (ISACs) [2], to bug bounty programs [3, 4], collec-
tive action has long been used and recognized as key for the gathering, the integration
and the sharing of critical cybersecurity information [5, 6]. The reason for resorting to
information-sharing as a form of collective action stems from the complexity associated
with the continuous and somewhat decentralized (e.g., open source software) adaptation
of hardware and software in information systems [7, 8]. Although the Internet has largely
developed through an open source spirit [9–11] with signiﬁcant positive externalities [12,
13], information-sharing has remained diﬃcult when it comes to cybersecurity [6]. The
expansion of threats in volume, severity and span has further challenged information in-
frastructures. Hence, it has forced further cooperation through information-sharing [14].
While their utility has been somewhat conﬁrmed by their wide adoption, there is a dearth
of knowledge regarding how these collective action platforms concretely bring performance
when addressing cybersecurity threats. For instance, cybersecurity has become increasingly
time-critical and demands ever faster reaction time. Determining the chances that a threat
will be fully characterized on time for security oﬃcers to act upon before attacks actually
start has become crucial [15].

Here, we investigate 39, 639 threat events contributed by 485 organizations to a MISP
information-sharing platform [14] operated by the Computer Incident Response Center
Luxembourg (CIRCL). We speciﬁcally study how collective action unravels through infor-
mation integration and how it brings signiﬁcant economies of scale in terms of time needed
to fully characterize cybersecurity threats (i.e., performance). We resort to a multivariate
cross-sectional regression with ordinary least squares method, and we ﬁnd that (i) the
number of organizations engaged in information-sharing, (ii) their acquired experience in
the events completion, (iii) the proportion of information integration and (iv) modularity
increase performance.

The remainder of this article is organized as follows. Section 2 covers background from
the perspectives of social dilemma, productivity and information integration in collective
action in general and for cybersecurity. Section 3 introduces MISP and presents the data.
In Section 4, we introduce the theoretical framework followed by research hypotheses in
Section 5. Section 6 describes the methodological approach. Results are presented in
Section 7 and discussed in Section 8 before concluding in Section 9.

2 Background

Knowledge sharing in cybersecurity has been considered as a crucial way to overcome
number of vulnerabilities [16] and threats [1]. It is however bound to limiting factors on the
one hand, such as social dilemma, as well as enhancing return-on-scale eﬀects on the other
hand. Here, we review the literature on (i) social dilemma and productivity of collective
action, and on (ii) challenges associated with information integration. We then review the
state-of-the-art research in (iii) information sharing for cybersecurity.

2.1 Social Dilemma and Productivity in Collective Action

According to Olson’s logic of collective action, small communities are more able to provide
collective goods [17]. The central argument is that minor interests will be over-represented
and diﬀuse majority interests trumped, due to a free-rider problem [18]. This free-riding
eﬀect is stronger for larger groups [19]. For instance, while Dejean et al. [20] found a positive
relation between the size of a community and the amount of collective good provided, they
paradoxically also found a decreased propensity by individuals to cooperate as the size

1

of the community increases. Yet, there is overwhelming evidence that large crowds can
be organized in order to establish successful online collective action. Examples include
peer-to-peer networks [20, 21], Wikipedia [22], Stack Overﬂow [23], communities of open
source software developers [24, 25]. The Dejean et al. paradox may at least partially resolved
by considering that (i) the distribution of eﬀort is highly skewed, with few contributors
providing most eﬀort, and (ii) the dynamics of contribution are highly non-linear [25–27].
Taken together, these phenomena are associated with positive return-on-scale of production
[25], which may be hindered by coordination costs [28]. Super-linear productivity has
been debated at length in organization and management sciences. Investigations of how
the number of members, temporal dynamics of events generated can inﬂuence positively
outputs in way that is greater than the sum of the outputs related to each element of the
system (i.e., exhibiting super-linear growth patterns). Research has successfully delivered
hints to improve the performance of organization [29–32] by ﬁne-tuning complementary
mechanisms within the organization [33], which also foster innovation [34].

2.2

Information Integration and Modularity

One key aspect of generating return-on-scale in knowledge production is information
integration. The management of information resources has become central to organizations
[35], so that knowledge appears as an utmost strategic resource [36]. For instance, there
is growing evidence in science that greater teams create more impacting knowledge [37].
If knowledge is so important, the fundamental capability of an organization has to be
considered as the specialized knowledge of each organization member. Its integration shall
provide a competitive advantage [36, 38]. With the emergence of virtual exchanges, ﬁrms
are increasingly seen as distributed knowledge systems [39]. Yet, new interaction methods
present various new constraints in term of mutual understanding, contextual knowledge
or techniques (e.g., memory, connectivity), which lead to asymmetries in information
integration.

In this respect, the tremendous development of online collaboration platforms, as
tools for governance strategy and knowledge management, highlights the importance
of information-sharing [40]. These platforms promote knowledge transfer by generating
modular collaborative units [41]. One may consider that individuals, or groups of individuals,
composing a subsystem (i) bring added value in their own speciﬁc ﬁeld (diﬀerentiation), in
order to (ii) produce a complex good by pooling together this added value (integration).
Following Arrow & Debreu [42], diﬀerentiation and integration have been a focal point in
optimizing the structure of organizations [43, 44]. In fact, diﬀerentiation considers segments
of a system into subsystems. Each subsystem develops a part of a task, while the integration
focuses on the interactions between these subsystems in order to accomplish the entire
task [38, 45]. Recently, Engel and Malone used the theory of consciousness as information
integration [46] to measure information integration computer systems and on collaborative
platforms [45].

2.3 Collective Action and Information Integration for Cybersecurity

As early as twenty years ago, the ﬁrst Computer Emergency Readiness Teams (CERT)
and Information Sharing and Analysis Centers (ISACs) have been established as a central
resource for sharing information on cybersecurity threats to critical infrastructures [47].
Nowadays, threat intelligence platforms help organizations aggregate, correlate, and analyze
threat data from multiple sources in (almost) real-time to support defensive actions [48].
Further, open source solutions have been proposed as a counterweight to cyber-criminals
successfully working together [5]. The swift evolution of cyber-threats has forced orga-
nizations and governments to develop new strategies [49] in order to reduce the risks of

2

security breaches [40]. Although information sharing is an interesting way to enhance
cybersecurity, it is believed to be thwarted by social dilemma. Without trust, commitment
and shared vision between stakeholders, organizations are reluctant to share information
due to the fear of disclosure, reputation risk or loss of competitive power [50]. As such,
information-sharing can be considered as a marketplace on which transactions occur and
knowledge is transferred [51]. However, human beings have a tendency to not optimize
organizational goals [52] and – in the case of collective action – might adopt behaviors
that are not conducive to the overall goal of sharing information [6]. As a consequence,
cybersecurity professionals share probably less information than desirable, leading to a
knowledge asymmetry to the advantage of the attackers [6]. In particular, stakeholders
strategically select their contributions to share (i.e., quantity and quality), leading to
truncated and imperfect information sharing. Yet, specially crafted forms of cybersecurity
information-sharing platforms have developed, such as bug bounty marketplaces. These
platforms act as a trusted third-party between security researchers and software editors
[3]. Further, in cybersecurity, resource belief, usefulness belief, and reciprocity belief are all
positively associated with knowledge absorption, whereas reward belief is not [51]. These
empirical results show that functional cybersecurity information-sharing indeed requires
to overcome social dilemma and goes beyond simple reward expectations, but foremost
requires that information-sharing is eﬃcient in a context that increasingly requires to
address time-critical threats.

3 Data

To understand the nuts and bolts of cybersecurity information-sharing, we resort to MISP
Project,1 a popular open source platform, which is used e.g., by the North Atlantic Treaty
Organization (NATO).2 MISP stands for Malware Information Sharing Platform and Threat
Sharing. Although it carries the word malware in its name, MISP is a threat intelligence
platform on which people can share, store and collaborate on all sorts of incidents (e.g.,
COVID-19 MISP community,3 but primarily cybersecurity threats. These threats (i.e.,
events) are characterized by indicators of compromise (i.e., attributes), which are contributed
by a multitude of organizations.

There are advantages in using MISP as an object of research. First, it is an open
source software. This allows to understand in much detail how the platform is designed and
works. Second, a number of threat information sharing communities use MISP to share
relatively openly their threat intelligence. Here, we use the whole history of a MISP instance
maintained by the Computer Incident Response Center Luxembourg (MISP CIRCL), i.e.,
the Luxembourg CERT.

As of February 8, 2022, the MISP CIRCL instance is a community of 1, 908 organizations
(respectively 4, 013 users), which have contributed 39, 639 events, 9, 099, 685 attributes and
3, 786 tags since November 10, 2008. Table 1 shows the ten most involved organizations.
One can see that the number of events contributed by organizations is highly skewed.
Indeed, Figure 1A shows that the complementary cumulative distribution function exhibits
a power law P (XE > xE) ∼ 1/xµE
E with µe = 0.54(4) (c.f., Appendix B for details on the
ﬁtting method). One may additionally note that 1, 423, i.e., around 75%, of organizations
do not participate in sharing threat information as a collective good with the broad MISP
CIRCL community. These organizations may however consume information or share threat
information privately within informal sub-groups, which cannot be observed. Similarly
to P (XE > xE), the distributions of attributes P (XA > xA) and tags P (XT > xT ) per

1https://www.misp-project.org/
2https://misp.ncirc.nato.int
3https://covid-19.iglocska.eu

3

event, depicted in Figure 2, follow power laws with exponents respectively µA = 0.64(1)
(with an upper cut-oﬀ around Aupper = 105) and µT = 2.26(6). It is additionally important
to consider that only 22, 423 (i.e., around 57%) events have been marked as completed,
suggesting that either threat analysis is complicated or that users tend to forget to formally
close a large number of events. The cumulative number of tags NT,cum = 116, 407 used is
bigger than the unique tags amount NTU = 3, 786. Thus, there is a massive reuse of already
existing tags.

rank
1
2
3
4
5
6
7
8
9
10

org ID # users # events contributed
7,682
1092
5,637
1395
3,214
1960
2,939
2
1,411
1857
1,247
201
1,141
1713
1,077
698
1,060
204
998
643
26,406

8
2
3
31
3
8
1
2
56
12
Total

percentage of total events
19.38%
14.22%
8.11%
7.41%
3.56%
3.15%
2.88%
2.72%
2.67%
2.52%
66.62%

Table 1: 10 of 1, 908 organizations have contributed 66.62% of the 39, 639 events, bringing further evidence
of the heavy-tailed nature of the distribution of contributions by organizations in MISP CIRCL.

We further observe that organizations have joined MISP CIRCL following an almost
perfect linear relation NO(t) ∼ αO · t with αO = 0.79(1) (R2 = 0.99 and p < 10−2) with 161
organizations initially joining MISP CIRCL instance on September 14, 2015, the presumed
date of oﬃcial start. Figure 1B, not only shows the almost linear organization joining rate,
but also how many events each organization has contributed over time. One see that the
contribution eﬀort is highly heterogeneous. It is also worth noting that event contributions
started on November 10, 2008, long before the ﬁrst organizations joined MISP CIRCL
instance. This can be explained in the following way: organizations run ﬁrst their MISP
instance locally. At some point, they join the MISP CIRCL community and share at once
all their non-private threat intelligence, yet with the nominal event timestamp, which may
well be in the past. Also, it is likely that the linear organization joining function may be
the result of a highly vetted joining process, controlled by CIRCL.

3.1 Reduction of the Completion Time of Events ∆tC

Following the method described in the Appendix B, we can treat the data and, from them,
generate the Figure 3B. As explained in the appendix, by playing with the axis, we remark
that when the axes are in linear-logarithmic scale, the data depict two straight lines. From
this observation, we can deduce that ∆tC(t) follows an exponential decrease in phase. By
applying a binning by month and computing the mean value ∆tC for each bin, we see a ﬁrst
phase that extends from 2011 to 2020 which decrease slower than the second phase from
2020 to today. By applying the linear regression on the data, according to the equation (9),
we conﬁrm that ∆tC exhibits an exponential decrease:

∆tC(t) =

where

(cid:40)

∼ 10β1
∼ 10β2

∆·t, for t ∈ [2011, 2020[,
∆·t, for t ∈ [2020, 2022],

(1)

4

Figure 1: A. Complementary cumulative distribution function (CCDF) of events per contributing organiza-
µE with µE = 0.54(4). The ﬁt
tion, which is best described by a power law distribution P (XE > xE) ∼ 1/xE
and the goodness-of-ﬁt, provided by the Kolmogorov-Smirnov statistics test, are obtained with the Python
library plfit. B. Curve of the joining organizations (in blue) has followed, after the September 14, 2015,
the presumed date of oﬃcial start, a linear growth with slope αO = 0.79(1), (R2 = 0.99, p-value < 10−2).
The events contributed by the organizations have been added (in dark gray), the distribution shows the
heterogeneity of organizations eﬀorts.

– β1

∆ = (−6.32 ± 0.91) × 10−3 is the exponential decrease of the ﬁrst part
regression and
∆ = (−7.12 ± 0.59) × 102 is the exponential decrease of the second part
regression.

– β2

The ﬁt from the linear is of high quality since its Pearson’s determination coeﬃcient
R2 = 0.86 and its p-value < 10−2. Hence, the time ∆tC to complete an event decreases
over time, indicating an improvement of performances of the MISP CIRCL instance.

4 Theoretical Framework

Collective action is thought to be a fundamental tool to overcome sprawling and increasing
time-critical cybersecurity threats [53–55]. Yet, despite numerous studies of online platforms
fostering collective action [56, 57], very little evidence has been uncovered linking the
organisation of collective action with group performance as an output. By investigating
the MISP threat management platform run by the Computer Incident Response Center
Luxembourg (CIRCL), we have a unique chance to better understand how collective action
is organized to tackle time-critical cybersecurity threats.

We posit that the performance of collective platforms devoted to the resolution of
time-critical tasks at scale, such as MISP, pull from progressively building a knowledge and
action environment, made of organizations, which contribute to the resolution of events
and, at the same time, bring returns of scale through (i) gaining own experience and (ii)
sharing and integrating knowledge, which is associated with increased performance. We
further posit that, in order to oﬀset decreasing return-of-scale due to increased groups size
and coordination costs [28], the organization of collective action must adapt in a modular
way [58], as it has already been witnessed in several open source projects [59, 60].

5

Figure 2: A. Complementary cumulative distribution function (CCDF) of attributes encapsulated in an
µA with µA = 0.64(1). B.
event, which is best described by a power law distribution P (XA > xA) ∼ 1/xA
CCDF of tags attached to an event which is best described by a power law distribution P (XT > xT ) ∼ 1/xµT
T
with µT = 2.26(6). The ﬁts and the goodness-of-ﬁts, provided by the Kolmogorov-Smirnov statistics test,
of panels A and B are obtained with the Python library plfit.

We test our theory of collective action for tackling time-critical tasks, through a set of
three hypotheses and six sub-hypotheses to understand how time completion performance
is achieved for events, given (i) the nature of event, (ii) the collective action environment
and (iii) the knowledge integration environment at the time of event arrival (c.f., section 5).
We proceed with an exploratory approach to test our theory by resorting to a multivariate
cross-sectional regression with ordinary least squares method (c.f., sections 6 and 7).

5 Hypotheses

To explain how event completion time has evolved, we consider their intrinsic nature, i.e.,
number of attributes and tags required to characterize events, the overall collective action
environment and how knowledge is integrated. We hypthesize that these three overall factors
signiﬁcantly inﬂuence collective action performance, in terms of improved completion time
in characterizing threat events.

5.1 Event Complexity Hinders Performance (H1)

First, events are not all equal: while some are fairly simple and require limited input
in terms of attributes and of categorization with tags, others are more complex and
require more eﬀort. As shown on Figures 2A and 2B, the distribution of respectively
attributes and tags is heavy-tailed: while a majority of events have a limited number of
attributes (resp. tags), some carry a large numbers of attributes (resp. tags), presumably
aﬀecting the time required to complete the characterization of an event. Hypothesis 1 states:

H1: The number of attributes and tags per event negatively inﬂuences performance.

6

Figure 3: A. Complementary cumulative distribution function (CCDF) of the completion time ∆tC , which
is best described by a decreasing exponential distribution P (X∆ < x∆) ∼ 10β∆ with β∆ = −0.93(1). B.
Completion time ∆tC of events over the time. The data (blue dots) represents the mean value of ∆tC
binned monthly. The data depict an exponential decrease in two phases, ﬁtted by linear regression (dashed
red line), ∆tC (t) ∼ (−6.32 ± 0.91) × 10−2 for t ∈ [2011, 2020[ and ∆tC (t) ∼ (−7.12 ± 0.59) × 10−2 for
t ∈ [2020, 2022] (R2 = 0.86, p-value < 10−2). The ﬁts and their goodness-of-ﬁts, provided by the Pearson’s
coeﬃcient of determination R2 and the p-value for the Wald test, of panels A and B are obtained with the
Python library scipy.stats.linregress.

5.2 Collective Action Improves Performance (H2)

We consider how collective action at scale aﬀects positively or negatively performance.
Namely, there are conﬂicting views on whether having more stakeholders (e.g., contributors,
organizations) joining collective action is likely to enhance or hinder performance [17,
25–28]. Yet, to exist and be sustainable, collective action necessarily needs to bring
economies of scale of some form, which in turn would attract more contributors. Conversely,
having more participants should bring marginally increasing performance. Therefore, we
aim to test the following hypothesis:

H2a: The overall performance increases with the number of organizations participating

in collective action.

Yet, as already shown in [61], the ongoing collective action workload is likely to aﬀect neg-
atively performance, by increasing completion time. Therefore, our second hypothesis states:

H2b: Given a focal event, the number of simultaneously open events decreases

performance.

5.3 Knowledge Integration Increases Performance (H3)

Having more contributors does not necessarily imply economies of scale [28]. Economies of
scale may rather be generated by “the whole is more than the sum of its parts” mechanisms
[25], which may stem from productive integration of information [45, 62, 63] as a single
entity [25] or through the eﬃcient communication of several modular sub-systems [64,

7

65], which in turn may even mitigate free-riding [58]. Here, we recognize that the ﬁrst
form on knowledge integration occurs through experience as learning within organizations
[66], and one may expect that an organization having accumulated experience in char-
acterizing a large number of threat events is likely to perform better on new events, therefore :

H3a: More experienced organizations solve events faster.

On MISP instances, collective action goes beyond coordinating time-critical tasks. As
people and organizations contribute, a large corpus of knowledge is built as a library of
events, attributes, and tags. In turn, by design of MISP software, this information can be
easily reused to quickly characterize new events, proposing matching possibilities according
to the preliminary entries.

Hence, the reuse of knowledge simpliﬁes the emission of attributes and the knowledge
is integrated by the creator of the new events. These new events are thus composed of
a certain percentage of inherited attributes which are likely to impact positively performance:

H3b: The reuse of tags and attributes from existing events contributes positively to

performance in the completion of new events.

The capacity of an entity to integrate knowledge is tightly related to its modular
organization [46, 58, 59]. As MISP clusters of events or attributes, called “Galaxies”, were
progressively introduced and developed on MISP CIRCL, we have an opportunity to test
for modularity. We therefore formulate the following hypothesis:

H3c: Modularity in collective action positively inﬂuences performance.

By testing these three hypotheses (and six sub-hypotheses), we expect to gain robust
insights on how collective action on MISP brings performance in terms of characterizing
time-critical cybersecurity threats.

6 Method

We proceed to validate our theory through the testing of three hypotheses, divided in six
sub-hypotheses (c.f., Section 5). For this, we specify an econometric model with completion
time as the main dependent variable representing the key performance indicator in our
posited theory of collective action for tackling time-critical threats (c.f., Section 4).

We deﬁne the following set of events,

Ωe = {e|e ≤ Ne, e ∈ N∗},

(2)

where Ne corresponds to 22, 423 events, which have explicitly been marked as completed
(i.e., with ﬁeld Analysis = 2, see section 3). For each event, we deﬁne ∆tC,e the completion
time of events as

∆tC,e = tf,e − tc,e,

(3)

with tc,e the event creation date and tf,e the last event modiﬁcation.

To determine the relation between the dependent variable, i.e. the completion time
∆tC,e for the events, we proceed to a multivariate cross-sectional regression [67]. Speciﬁcally,
we investigate if completion time ∆tC,e for the events can be explained by the selected
explanatory variables. The corresponding Python variable is CompletionT. For each event
e, the multivariate cross-sectional regression writes:

8

log(∆tC,e) = ζ +

Nk(cid:88)

Ne(cid:88)

·

k=1

e=1

κk · log(Zk,e) + εe,

(4)

with:

– ∆tCe : time completion for event e,
– ζ : constant,

– Nk : number of explanatory variables,

– κk : autoregressor parameter corresponding to Zk,e,

– Zk,e : k-th explanatory variable for event e,
– εe : error term (i.e., log(∆tC,e) − log((cid:92)∆tC,e)).

This multivariate cross-sectional regression is performed with the ordinary least squares
(OLS) method. The choice of this model is adapted to deal with data without time series,
which is the case here. Then, the explicated and explanatory variables are linked with a set
of points in time. This set of points in time is given by the creation tc,e of the diﬀerent e and
contains 22, 423 elements, corresponding to the number of completed elements Ne considered.
Thanks to this model, it is easy to consider all chosen independent variables. However,
due to the heavy-tailed behaviour of the variables and their diﬀerence of magnitude (see
Section 3), we transform the variables in logarithm in base of 10 [68]. However, the results
are indicated as a percentage change of ∆tC,e when Zk,e varies by a certain percentage [68].
We specify the following explanatory variables in relation with the formulated hypotheses
(c.f., Section 5). To test hypothesis H1 (i.e., event complexity hinders performance), we
resort to two explanatory variables:

– NA,e: the number of attributes per event e. The corresponding Python vari-
able is AttrCount, which is expected to positively inﬂuence CompletionT
(i.e., reduce performance).

– NT,e: the number of tags per event e, The corresponding Python variable is
NTags, which is expected to positively inﬂuence CompletionT (i.e., reduce
performance).

To test hypothesis H2 (i.e., collective action improves performance), we resort to two

explanatory variables:

– NO,e stands for the number of organizations listed on MISP CIRCL at
the creation tc,e of event e. The corresponding Python variable is CumOrgs.
CumOrgs is expected to negatively inﬂuence CompletionT (i.e., increase
performance) and to demonstrate the overall beneﬁts of collective action
for tackling time criticial threats (H2a).

– Esim,e is the number of simultaneously open events on MISP CIRCL
at the creation tc,e of event e. The corresponding Python variable is
SimEvents, which is expected to positively inﬂuence CompletionT (i.e.,
reduce performance) and to show that collective action performance is
bound to circumstantial operational constraints associated with time as a
scarce resource (H2b) [61, 69].

To test hypothesis H3 (i.e., knowledge integration increases performance), we resort to

three explanatory variables:

9

– EC,e takes into account the number of already completed events by the
organizations at the creation tc,e of a new event e on their behalf. The
corresponding Python variable is CumCompE, which is expected to negatively
inﬂuence CompletionT (i.e., increase performance) (H3a).

– I%A,e is the inherited percentage of attributes per event e. The correspond-
ing Python variable is InhPer, which is expected to negatively inﬂuence
CompletionT (i.e., increase performance) (H3b).

– NG,e counts the number of galaxies created on MISP CIRCL instance at the
creation tc,e of the e. The corresponding Python variable is NbGalaxies,
which is expected to negatively inﬂuence CompletionT (i.e., increase per-
formance) (H3c).

– NEG,e considers the number of events in its corresponding aforementioned
galaxy at the creation tc,e of a new event e in this galaxy. The correspond-
ing Python variable is NbEventsinhisG, which is expected to negatively
inﬂuence CompletionT (i.e., increase performance) (H3c).

The pairwise correlations of the dependent variable and the independent ones provide

the correlation matrix (see Table 2).

)
C
t
∆
(
g
o
l

1.00
0.11
-0.07
0.07
0.74
-0.23
-0.60
-0.16
-0.12

)
e
,
A
N

(
g
o
l

1.00
-0.27
0.08
0.06
-0.03
0.023
0.01
0.00

)
e
,
A
%
I
(
g
o
l

1.00
-0.59
0.01
0.05
-0.02
-0.07
-0.07

log(∆tC)
log(NA,e)
log(I%A,e)
log(NT,e)
log(Esim,e)
log(NO,e)
log(EC,e)
log(NG,e)
log(NEG,e)

)
e
,

T
N

(
g
o
l

)
e
,
m

i
s

E
(
g
o
l

)
e
,
O
N

(
g
o
l

)
e
,
C
E
(
g
o
l

)
e
,
G
N

(
g
o
l

)
e
,

G
E
N

(
g
o
l

1.00
0.04
0.01
0.01
-0.02
0.07

1.00
0.02
-0.53
-0.42
-0.11

1.00
0.33
0.19
0.42

1.00
0.23
0.43

1.00
0.14

1.00

Table 2: Correlation matrix of dependent and explanatory variables.

With the explanatory variables of our model being deﬁned, we are in position to

formulate the econometric model by developing the equation (4):

log(∆tC,e) = ζ + κNA · log(NA,e) + κI%A · log(I%A,e) + κNT · log(NT,e)
+ κEsim · log(Esim,e) + κNO · log(NO,e) + κEC · log(EC,e)
+ κNG · log(NG,e) + κNEG
+ εe

· log(NEG,e)

(5)

Model validation is performed as follows. When handling a multivariate regression,
one must pay particular attention to multi-collinearity between the Zk’s, which may
distort the model. For that, the variance inﬂation factor (VIF) resulting from the re-
gression of the explanatory variable Zk on the other explanatory variables which provide
2) and must be
R2
< 10 [67]. The stability of the variance has to be examined, namely by studying het-
eroskedasticity, which is ruled out if the p-value obtained from a White test is lower than a

k, must be computed. The VIFk is then given as VIFk = 1/(1 − Rk

10

threshold α = 0.05 [67]. The computation steps are performed with the Python libraries
statsmodels.api.OLS for the regression, statsmodels.stats.outliers_influence for
the VIF and statsmodels.stats.diagnostic for the White test.

7 Results

In order to establish evidence of collective action as an eﬃcient way for tackling time-critical
cybersecurity threats, we have resorted to data the MISP instance, which is run by the
computer Incident Response Center Luxembourg (CIRCL). We used a multivariate cross-
sectional regression analysis of completion time (i.e., performance) required to characterize
a threat event with both event related and collective action explanatory variables.

Dep. Variable
Method
No. Observations
R-squared

Const
CountAttr
InhPer
NTags
CumOrgs
CumCompE
NbGalaxies
NbEventsinhisG
Skew
Kurtosis

Completion Time
OLS
F-Stat
22423 Prob (F-Stat)
0.413
Log-likelihood
coeﬀ
16.505(∗∗∗)
0.230(∗∗∗)
−0.089(∗∗∗)
0.951(∗∗∗)
−0.346(∗∗∗)
−0.629(∗∗∗)
−0.083(∗∗∗)
0.160(∗∗∗)

2.251 × 103
0.00

−5.030 × 104
std err

0.135
0.011
0.014
0.090
0.024
0.006
0.019
0.005

-0.011 Durbin-Watson 1.302
76.4
2.833 Cond No.

Table 3: Results of the ordinary least squares (OLS) regression with the explained variable CompletionT
CountAttr, InhPer, NTags, CumOrgs, CumCompE, NbGalaxies and
and the explanatory variables:
NbEventsinhisG, namely the number of attributes per event, the inherited percentage of attributes per
event, the number of tags per event, the cumulative number of organizations at the creation of the event e,
the number of already completed events by the organization at the creation of his new event e, the number
of galaxies at the creation of the event e and the number of events populating these galaxies at the creation
of the event e. For each explanatory variable, the autoregressor coeﬃcient (in the column coeff), as well as
its standard deviation (in the column std err) are provided. The signiﬁcance of the explanatory variables
is given by the p-value and its threshold, i.e. p − value < 0.1 : (∗), < 0.05 : (∗∗) or < 0.01 : (∗ ∗ ∗) and the
goodness-of-ﬁt by the R-squared. The other added information are not necessary for the evaluation of the
model.

The regression results are shown in Table 3. Overall, the regression model is robust and
explains 41.3% of the variance (R2 = 0.413). Testing for hypothesis 1, the model shows that
indeed event complexity measured by the number of attributes CountAttr and tags NTags
inﬂuences performance negatively, i.e., event characterization completion time is increased.
Hypothesis H1 is supported. Regarding how collective action improves performance (H2),
the model shows that overall performance (i.e., completion time reduced) is positively
associated with the number of organizations participating in MISP: Hypothesis H2a is
supported. Hypothesis H2b could not be tested as a result of unexplained strong multi-
collinearity between CumOrgs and SimEvents. Turning to Hypothesis 3 (i.e., knowledge
integration increases performance), we ﬁnd that more experienced organizations perform
better in reducing event completion time. Hypothesis H3a is supported. We also ﬁnd that
the proportion of attributes that an event e inherits from previous events, i.e., from the
MISP CIRCL knowledge base, also positively inﬂuences performance. Hypothesis H3b is

11

supported. Finally, testing for hypothesis H3c, i.e., modularity, we ﬁnd mixed results. While
the number of MISP Galaxies, measuring the number of modular sub-systems, inﬂuences
positively performance, the number of events recorded in MISP Galxies, measuring to some
extent the intensity of modularity, inﬂuences performance negatively. Hypothesis H3b is
only partially supported.

We have checked for multi-collinearity of the explanatory variables. We computed the
variance inﬂation factor (VIF) for each explanatory variables, which happens to be all
smaller than 10. This implies that there is no evidence of multi-collinearity between the
selected explanatory variables (c.f., Table 4). We also controlled for heteroskedasticity, i.e.,
a possible instability of the variance by performing a White statistics tests. We obtained
p-value < 10−2, which implies that there is no heteroskedasticity in our model. The
post-analysis for the VIFs and the White statistics test completely validate the used model
and its results.

Explanatory variables
Number of attributes per event
Inherited percentage of attributes per event e
Number of tags per event e
Cumulated number of organizations at the creation of e
Cumulated number of completed events at the creation of e EC,cum,e
NG,cum,e
Cumulated number of galaxies at the creation of e
NEG,cum,e
Cumulated number of events in galaxies at creation of e

Notation VIF
5.15
NA,e
1.67
I%A,e
1.03
NT,e
6.73
Fcum,e
3.28
1.12
2.02

Table 4: Computation of the variance inﬂation factor (VIF) for the explanatory variables of the econometric
model. The values of the VIF allows to detect the presence of multi-collinearity between the considered
variables. As all values VIF < 10, there is no evidence of multi-collinearity between the explanatory
variables. These results validate the econometric model.

8 Discussion

Organizations are increasingly encouraged to cooperate and share information to overcome
cybersecurity threats. Investigating how collective action unfolds and brings performance
on information-sharing platforms is necessary as cybersecurity threats have become
In other words, not only collective action shall be used to
increasingly time-critical.
characterize threat events, it also must be used to characterize threat events before attacks
unravel [55]. Here, we have investigated collective action on MISP, a popular open source
threat intelligence platform, from the perspective of the time required to fully characterize
an event as an objective function to be optimized (i.e., completion time or performance).
We found that performance is negatively associated with event complexity (Hypothesis 1)
and positively associated with collective action (Hypothesis 2). Indeed, as the number of
organizations taking part to information-sharing on the MISP instance studied increased,
the time required to complete the characterization of events decreased. This result informs
on positive returns on scale, which necessarily exist given the increased adoption of MISP
as well as other information-sharing platforms. Nevertheless, the mechanisms at work
generating these economies of scale have remained unclear. We considered the perspective
of knowledge integration [46] as the collective action process at work to generate the “the
whole is more than the sum of its parts” [25]. With hypothesis 3, we tested and veriﬁed
organizational learning, knowledge integration and modularity as positively associated with
performance.

edWhile event completion time is associated with explanatory variables pertaining
to event complexity, collective action, and knowledge integration, we could not establish

12

causality. Although this is a signiﬁcant limitation to our model, we have organized our
multivariate cross-sectional regression in a way that minimizes the risks of uncovering
spurious dependencies between the explained variable on the one hand and the explanatory
variables on the other hand. And the fact that all our explanatory variables are signiﬁcant
(at the exception of SimEvents, the number of simultaneously open events on MISP CIRCL
at the creation, which had to be excluded from the model), shows that our proposed theory
on collective action for tackling time-critical tasks is comprehensive and altogether robust.
Yet, the regression analysis approach remains exploratory. Indeed, it does not provide
reliable information on which precise collective action mechanisms generate positive returns
on scale. Building and testing ﬁne-grained causal models of critical cascades in collective
action, inspired from e.g. [25–27], may surely help better understand the activity, learning,
knowledge integration and modularization paths of contributing organizations, as well as
how they handle time as a particularly scarce resource [69]. Indeed, when tackling large
amounts of time-critical tasks, such as cybersecurity threats or incidents, contingencies
necessarily appear [61], which may aﬀect coordination between contributors, and as a
result performance, either in a transient way or by triggering long-term instability through
cascades of disorganization. At the meso-scale, our model does not account for aﬃnities
between events, organizations and the combined commonalities of events and organizations.
Indeed, as for number of collective action online platforms, modular Galaxies on MISP show
that some sub-communities of organizations have speciﬁc goals when tackling cybersecurity
threats. These speciﬁc interests deserve further scrutiny. For instance, are the organizations
contributing to a given MISP galaxy active in the same industry? If not, why do they share
interest in similar threats? Considering MISP (or other information-sharing platforms)
from the perspective of threats, we may investigate kinship between threats, as they most
often share attributes. Questioning and perhaps predicting how attributes are “transmitted”
from one event to others is likely to be key to anticipate threats and guide organizations in
their search of (respectively contributions to) threat information. It may even help decide
what information should be shared and with whom.

Finally, our results show that completion time as an objective function in collective
action concerned with time-critical tasks can be optimized. This opens further perspectives
for computational social science research. One may envision to use machine learning in order
to recommend personalized precision strategies that optimize the organization of collective
action and knowledge integration. This may help make best use of time as an increasingly
critically scarce resource, especially in face of a looming tsunami of cybersecurity threats.

9 Conclusion

Information-sharing in cyber-security has become an increasingly common collective action
practice. Yet, its beneﬁts have so far remained unclear. We have investigated MISP, a
commonly used open source threat sharing platform, and we found how building a critical
mass of contributing organizations and of knowledge to be integrated from past threats brings
signiﬁcant economies of scale. Through collective action, security researchers overcome
the challenge of characterizing cybersecurity threats, which appear to be increasingly time-
critical. We ﬁnd that performance, deﬁned as the time needed to fully characterize a threat
event, is (i) negatively inﬂuenced its own complexity, (ii) positively inﬂuenced by collective
action, and (iii) positively by learning, knowledge integration and modularity. Our results
also inform more generally on how collective action can be organized online at scale and in
a modular way to overcome a large number of time-critical tasks.

13

Acknowledgements

The authors thank the WEIS’2021 and WEIS’2022 anonymous reviewers for their useful
comments. The authors acknowledge support from the members of the Computer Incident
Response Center Luxembourg (CIRCL) for making their data available and for their
technical support. One of the authors (S. Gillard) acknowledges ﬁnancial support from
the Military Academy at ETH Zurich. Another author (D. Percia David) acknowledges
ﬁnancial support from the Cyber-Defence Campus (armasuisse Science and Technology).

References

1. Sridhar, K., Householder, A., Spring, J. & Woods, D. W. Cybersecurity Information
Sharing: Analysing an Email Corpus of Coordinated Vulnerability Disclosure en. in
(2021), 39.

2. Gal-Or, E. & Ghose, A. The Economic Incentives for Sharing Security Information. en.
Information Systems Research 16, 186–208. issn: 1047-7047, 1526-5536 (June 2005).
3. Maillart, T., Zhao, M., Grossklags, J. & Chuang, J. Given enough eyeballs, all bugs are
shallow? Revisiting Eric Raymond with bug bounty programs. Journal of Cybersecurity
3, 81–90 (June 2017).

4. Sridhar, K. & Ng, M. Hacking for good: Leveraging HackerOne data to develop an

economic model of Bug Bounties. Journal of Cybersecurity 7 (Jan. 2021).

5. Böhme, R. Back to the Roots: Information Sharing Economics and What We Can
Learn for Security in Proceedings of the 2016 ACM on Workshop on Information
Sharing and Collaborative Security (ACM, Vienna Austria, Oct. 2016), 1–2.

6. Laube, S. & Böhme, R. Strategic Aspects of Cyber Risk Information Sharing. ACM

Computing Surveys 50, 77:1–77:36 (Nov. 2017).

7. Brady, R. M., Anderson, R. J. & Ball, R. C. Murphy’s law, the ﬁtness of evolving
species, and the limits of software reliability en. Tech. rep. UCAM-CL-TR-471 (Uni-
versity of Cambridge, Computer Laboratory, 1999). https://www.cl.cam.ac.uk/
techreports/UCAM-CL-TR-471.html (2022).

8. Stojkovski, B., Lenzini, G., Koenig, V. & Rivas, S. What’s in a Cyber Threat Intelligence
sharing platform?: A mixed-methods user experience investigation of MISP en. in
Annual Computer Security Applications Conference (ACM, Virtual Event USA, Dec.
2021), 385–398. isbn: 978-1-4503-8579-4. https : / / dl . acm . org / doi / 10 . 1145 /
3485832.3488030 (2022).

9. Levy, S. hackers: heroes of the computer revolution. en. 35, 4 (2010).

10. Benkler, Y. The Penguin and the Leviathan: How Cooperation Triumphs over Self-

Interest en. isbn: 978-0-307-59019-0 (Crown, Aug. 2011).

11. Benkler, Y. The wealth of networks: how social production transforms markets and
freedom en. OCLC: ocm61881089. isbn: 978-0-300-11056-2 (Yale University Press,
New Haven [Conn.], 2006).

12. Katz, M. L. & Shapiro, C. Network Externalities, Competition, and Compatibility.

en, 18 (2021).

13. Shapiro, C. & Varian, H. R. Information rules: a strategic guide to the network economy

en. isbn: 978-0-87584-863-1 (Harvard Business School Press, Boston, Mass, 1999).
14. Wagner, C., Dulaunoy, A., Wagener, G. & Iklody, A. MISP: The Design and Im-
plementation of a Collaborative Threat Intelligence Sharing Platform in Proceedings
of the 2016 ACM on Workshop on Information Sharing and Collaborative Security
(Association for Computing Machinery, New York, NY, USA, Oct. 2016), 49–56.

14

15. Zibak, A. & Simpson, A. Cyber Threat Information Sharing: Perceived Beneﬁts and
Barriers en. in Proceedings of the 14th International Conference on Availability,
Reliability and Security (ACM, Canterbury CA United Kingdom, Aug. 2019), 1–9.

16. Mell, P., Scarfone, K. & Romanosky, S. Common Vulnerability Scoring System. IEEE
Security Privacy 4. Conference Name: IEEE Security Privacy, 85–89. issn: 1558-4046
(Nov. 2006).

17. Olson, M. The Logic of Collective Action: Public Goods and the Theory of Groups,
With a New Preface and Appendix Revised edition. English. isbn: 978-0-674-53751-4
(Harvard University Press, Cambridge, Mass., Jan. 1971).

18. Anesi, V. Moral hazard and free riding in collective action. Social Choice and Welfare

32, 197 (June 2008).

19. Esteban, J. & Ray, D. Collective Action and the Group Size Paradox. The Ameri-
can Political Science Review 95. Publisher: [American Political Science Association,
Cambridge University Press], 663–672 (2001).

20. Dejean, S., Pénard, T. & Suire, R. Olson’s Paradox Revisited: An Empirical Analysis
of incentives to contribute in P2P File-Sharing Communities SSRN Scholarly Paper
ID 1299190 (Social Science Research Network, Rochester, NY, July 2010).

21. Asvanund, A., Clay, K., Krishnan, R. & Smith, M. D. An Empirical Analysis of
Network Externalities in Peer-to-Peer Music-Sharing Networks. Information Systems
Research 15. Publisher: INFORMS, 155–174 (June 2004).

22. Klein, M., Maillart, T. & Chuang, J. The Virtuous Circle of Wikipedia: Recursive
Measures of Collaboration Structures in Proceedings of the 18th ACM Conference on
Computer Supported Cooperative Work & Social Computing (Association for Computing
Machinery, New York, NY, USA, Feb. 2015), 1106–1115.

23. Wang, S., Lo, D. & Jiang, L. An empirical study on developer interactions in Stack-
Overﬂow in Proceedings of the 28th Annual ACM Symposium on Applied Computing
(Association for Computing Machinery, New York, NY, USA, Mar. 2013), 1019–1024.
isbn: 978-1-4503-1656-9. https://doi.org/10.1145/2480362.2480557 (2022).
24. Hippel, E. v. & Krogh, G. v. Open Source Software and the “Private-Collective”
Innovation Model: Issues for Organization Science. Organization Science 14. Publisher:
INFORMS, 209–223. issn: 1047-7039. https://pubsonline.informs.org/doi/abs/
10.1287/orsc.14.2.209.14992 (2022) (Apr. 2003).

25. Sornette, D., Maillart, T. & Ghezzi, G. How much is the whole really more than the
sum of its parts? 1 (cid:1) 1 = 2.5: Superlinear productivity in collective group actions. Plos
one 9, e103023 (2014).

26. Maillart, T. & Sornette, D. Aristotle vs. Ringelmann: On superlinear production in
open source software. en. Physica A: Statistical Mechanics and its Applications 523,
964–972 (June 2019).

27. Murić, G., Abeliuk, A., Lerman, K. & Ferrara, E. Collaboration Drives Individual
Productivity. en. Proceedings of the ACM on Human-Computer Interaction 3, 1–24.
issn: 2573-0142 (Nov. 2019).

28. Scholtes, I., Mavrodiev, P. & Schweitzer, F. From aristotle to ringelmann: A large-scale
analysis of team productivity and coordination in open source software projects in
(Gesellschaft für Informatik e.V., 2016).

29. Tziner, A. & Eden, D. Eﬀects of crew composition on crew performance: Does the
whole equal the sum of its parts? Journal of Applied Psychology 70. Place: US Pub-
lisher: American Psychological Association, 85–93. issn: 1939-1854(Electronic),0021-
9010(Print) (1985).

15

30. Sundstrom, E., De Meuse, K. P. & Futrell, D. Work teams: Applications and eﬀec-
tiveness. American Psychologist 45. Place: US Publisher: American Psychological
Association, 120–133 (1990).

31. Cohen, S. G. & Bailey, D. E. What Makes Teams Work: Group Eﬀectiveness Research
from the Shop Floor to the Executive Suite. en. Journal of Management 23. Publisher:
SAGE Publications Inc, 239–290. issn: 0149-2063 (June 1997).

32. Neuman, G. A. & Wright, J. Team eﬀectiveness: Beyond skills and cognitive ability.

en. Journal of Applied Psychology. issn: 0021-9010 (Jan. 1999).

33. Ennen, E. & Richter, A. The Whole Is More Than the Sum of Its Parts— Or Is It?
A Review of the Empirical Literature on Complementarities in Organizations. en.
Journal of Management. issn: 0149-2063 (Jan. 2010).

34. Sacramento, C. A., Chang, M.-W. S. & West, M. A. in Innovation through collaboration

(Emerald Group Publishing Limited, 2006).

35. Nonaka, I. A Dynamic Theory of Organizational Knowledge Creation. en. ORGANI-

ZATION SCIENCE 5, 25 (1994).

36. Grant, R. M. Prospering in Dynamically-Competitive Environments: Organizational
Capability as Knowledge Integration. Organization Science 7, 375–387 (1996).

37. Wuchty, S., Jones, B. F. & Uzzi, B. The Increasing Dominance of Teams in Production
of Knowledge. en. Science 316, 1036–1039. issn: 0036-8075, 1095-9203 (May 2007).

38. Lawrence, P. R. & Lorsch, J. W. Diﬀerentiation and Integration in Complex Organi-
zations. en. Administrative Science Quarterly 12, 1. issn: 00018392 (June 1967).

39. Majchrzak, A., Griﬃth, T. L., Reetz, D. K. & Alexy, O. Catalyst Organizations as
a New Organization Design for Innovation: The Case of Hyperloop Transportation
Technologies. en. Academy of Management Discoveries 4, 472–496. issn: 2168-1007.
http://journals.aom.org/doi/10.5465/amd.2017.0041 (2022) (Dec. 2018).

40. Safa, N. S. & Von Solms, R. An information security knowledge sharing model
in organizations. en. Computers in Human Behavior 57, 442–451. issn: 07475632.
https : / / linkinghub . elsevier . com / retrieve / pii / S0747563215303083 (2022)
(Apr. 2016).

41. Mockus, A., Fielding, R. T. & Herbsleb, J. A case study of open source software
development: the Apache server. Software Engineering, 2000. Proceedings of the 2000
International Conference on, 263–272 (2000).

42. Debreu, K. J. A. a. G. Existence of an Equilibrium for a Competitive Economy. The

Econometric Society 22, pp. 265–290 (1954).

43. Ravasi, D. & Verona, G. Organising the process of knowledge integration: the bene"ts

of structural ambiguity. en, 26 (2001).

44. Huang, J. C. & Newell, S. Knowledge integration processes and dynamics within the
context of cross-functional projects. en. International Journal of Project Management,
10 (2003).

45. Engel, D. & Malone, T. W. Integrated information as a metric for group interaction.

PLOS ONE 13 (ed Dovrolis, C.) e0205335 (Oct. 2018).

46. Tononi, G. Consciousness and Complexity. en. Science 282, 1846–1851 (Dec. 1998).

47. Zheng, D. E. Cyber Threat Information Sharing: Recommendations for Congress and

the Administration. en, 18 (2015).

16

48. He, M., Devine, L. & Zhuang, J. Perspectives on Cybersecurity Information Sharing
among Multiple Stakeholders Using a Decision-Theoretic Approach: Cybersecurity
Information Sharing. en. Risk Analysis 38, 215–225. issn: 02724332. https : / /
onlinelibrary.wiley.com/doi/10.1111/risa.12878 (2022) (Feb. 2018).

49. Meier, R., Scherrer, C., Gugelmann, D., Lenders, V. & Vanbever, L. FeedRank: A
tamper- resistant method for the ranking of cyber threat intelligence feeds in 2018 10th
International Conference on Cyber Conﬂict (CyCon) ISSN: 2325-5374 (May 2018),
321–344.

50. Mermoud, A., Keupp, M. M., Huguenin, K., Palmié, M. & Percia David, D. To
share or not to share: a behavioral perspective on human participation in security
information sharing. Journal of Cybersecurity 5, tyz006. issn: 2057-2085. https :
//doi.org/10.1093/cybsec/tyz006 (2022) (Jan. 2019).

51. Percia David, D., Keupp, M. M. & Mermoud, A. Knowledge absorption for cyber-
security: The role of human beliefs. Computers in Human Behavior 106, 106255 (May
2020).

52. Mermoud, A., Keupp, M. M. & Percia David, D. Governance Models Preferences for
Security Information Sharing: An Institutional Economics Perspective for Critical
Infrastructure Protection in Critical Information Infrastructures Security (eds Luiijf,
E., Žutautait˙e, I. & Hämmerli, B. M.) (2019).

53. Mermoud, A. Three articles on the behavioral economics of security information
sharing: A theoretical framework, an empirical test, and policy recommendations PhD
Thesis (Université de Lausanne, Faculté des hautes études commerciales, 2019).

54. Bouwman, X. Governance of cybersecurity communities: Understanding threat intelli-
gence sharing as a collective action problem through incentivization of the National
Detection Network. en. https : / / repository . tudelft . nl / islandora / object /
uuid%3A3134a935-1156-409d-a58c-47cf06a88dad (2022) (2018).

55. Wagner, T. D., Mahbub, K., Palomar, E. & Abdallah, A. E. Cyber threat in-
telligence sharing: Survey and research directions. en. Computers & Security 87,
101589. issn: 0167-4048. https://www.sciencedirect.com/science/article/pii/
S016740481830467X (2022) (Nov. 2019).

56. Bouwman, X. et al. Helping hands: Measuring the impact of a large threat intelligence

sharing community. en, 17 (2022).

57. McColl, R. C., Ediger, D., Poovey, J., Campbell, D. & Bader, D. A. A performance
evaluation of open source graph databases in Proceedings of the ﬁrst workshop on
Parallel programming for analytics applications (Association for Computing Machinery,
New York, NY, USA, 2014), 11–18. isbn: 978-1-4503-2654-4. https://doi.org/10.
1145/2567634.2567638 (2022).

58. Baldwin, C. Y. & Clark, K. B. The Architecture of Participation: Does Code Archi-
tecture Mitigate Free Riding in the Open Source Development Model? Management
Science 52. Publisher: INFORMS, 1116–1127. issn: 0025-1909. https://pubsonline.
informs.org/doi/abs/10.1287/mnsc.1060.0546 (2022) (July 2006).

59. Narduzzo, A. & Rossi, A. The Role of Modularity in Free/Open Source Software
Development en. Chap. ISBN: 9781591403692 Pages: 84-102 Publisher: IGI Global.
2005. https : / / www . igi - global . com / chapter / role - modularity - free - open -
source/www.igi- global.com/chapter/role- modularity- free- open- source/
18721 (2022).

17

60. Langlois, R. N. & Garzarelli, G. Of Hackers and Hairdressers: Modularity and the
Organizational Economics of Open-source Collaboration. en. Industry and Innovation
15, 125–143. issn: 1366-2716, 1469-8390. https://www.tandfonline.com/doi/full/
10.1080/13662710801954559 (2022) (Apr. 2008).

61. Kuypers, M. & Maillart, T. Designing Organizations for Cyber Security Resilience
in Proceedings of the 2018 The Workshop on the Economics of Information Security
(WEIS), Innsbruck, Austria (2018), 18–19.

62. Oizumi, M., Albantakis, L. & Tononi, G. From the Phenomenology to the Mechanisms
of Consciousness: Integrated Information Theory 3.0. PLoS Computational Biology 10
(ed Sporns, O.) e1003588 (May 2014).

63. Malone, T. W. Superminds: how hyperconnectivity is changing the way we solve
problems English. OCLC: 1130848208. isbn: 978-1-78607-568-0 (Oneworld Publicatins,
London, 2019).

64. Barrett, A. B. & Seth, A. K. Practical Measures of Integrated Information for Time-
Series Data. en. PLoS Computational Biology 7 (ed Sporns, O.) e1001052. issn:
1553-7358. https://dx.plos.org/10.1371/journal.pcbi.1001052 (2021) (Jan.
2011).

65. Baldwin, C. & Clark, K. Design Rules: The Power of Modularity (MIT Press, Cam-

bridge, 2000).

66. Argote, L. & Miron-Spektor, E. Organizational Learning: From Experience to Knowl-
edge. Organization Science 22. Publisher: INFORMS, 1123–1137. issn: 1047-7039.
https://pubsonline.informs.org/doi/abs/10.1287/orsc.1100.0621 (2022)
(Oct. 2011).

67. Asteriou, D. & Hall, S. G. Applied Econometrics en. Google-Books-ID: eOEd-
CwAAQBAJ. isbn: 978-1-137-41547-9 (Macmillan International Higher Education,
Oct. 2015).

68. Benoit, K. Linear Regression Models with Logarithmic Transformations. en, 8 (2011).

69. Maillart, T., Sornette, D., Frei, S., Duebendorfer, T. & Saichev, A. Quantiﬁcation of
deviations from rationality with heavy tails in human dynamics. Physical Review E
83, 056101 (May 2011).

70. Clauset, A., Shalizi, C. R. & Newman, M. E. J. Power-law distributions in empirical

data. SIAM Review 51, 661–703 (Feb. 2009).

Appendices

A MISP: Description and Data Retrieval

A.1 Detailed Description of MISP

MISP is a partially de-centralized system of communities (e.g., NATO MISP, CIRCL
MISP). interacting more or less together across MISP instances. A MISP instance consists
in the installation of the MISP software and the community database in which community
members share and collect data. Similarly to GIT,4 organizations work on their own
instance and synchronize with remote instances. According to their sharing setting (i.e.,
your organization only, community only, connected communities, all communities or deﬁned
sharing group), community members have access to a certain amount of data.

4https://git-scm.com/

18

Based on investigation needs or reports found in the newspapers or on specialized
websites, the user creates an event to contextualize and encapsulate the related attributes
(i.e., IoCs) and their properties (e.g., an IP address). All events have some general properties
of the event, such creation date, aforementioned sharing level, threat level (i.e., 1: High, 2:
Medium, 3: Low, 4: Undeﬁned), analysis level (i.e., 0: Initial, 1: Ongoing, 2: Complete)
and a general description. The creator of an event can choose if this event is published
on the remote instance or remains internal to the organization. Then, when the event is
created, some attributes are added to populate this event. The event attributes refer to
intrusion artifacts or methods used by attackers. These attributes provide details and they
are characterized by their type (e.g., ﬁlename|md5, sha256, etc.) and their belonging to a
category (e.g., Antivirus detection, Targeting data, etc.), putting them in the context and
justify then its attribution to its corresponding event. To add an attribute related to an
event, global information such as its category, its type and its distribution, either the same
as for the event or its own rule, is required, as well as two important text ﬁelds: value
and contextual comment. The "value" ﬁeld stores the data we want to add, e.g. an url
leading to a report, while the “comment” ﬁeld allows complementary information about
the attribute. Moreover, it is possible to allocate one tag or more to an event in order to
simplify the read and the classiﬁcation of this event. These tags can follow the MISP taxon-
omy, i.e. a ﬁxed machine-tag vocabulary, or be created by the users according to their needs.

On the platform, events, attributes, organizations and tags are associated to their own
identiﬁcation (ID) number and their creation are timestamped, as well as the publication
and the last update of an event.

As an open-source platform, MISP relies on voluntary action. On the one hand, its
members can create or exchange content. On the other hand, these same actors can obtain
new insights or possible response elements from the community regarding cyber-threats
of interest. To organize interactions and to create information-sharing incentives for the
participants, MISP oﬀers several aforementioned sharing levels through a comprehensive
sharing model. Users can select to whom they want to share information among the
following levels from the most restrictive to the most open. Regardless of access and to
guarantee the quality of the shared data, only organizations that created an event have the
permission to modify this event. However, each user has the possibility to submit his own
suggestions to change an event created by others, who can then accept or reject the proposal.

Moreover, the experience of older MISP versions has shown that the time to ﬁll the
ﬁelds and a complicated web interface introduce some frictions. For this purpose, a free
text importer has been deployed, so that data can be copied and pasted into the intended
ﬁeld. Further, MISP implements a heuristics-based algorithm, which helps users to match
events or event attributes with events or attributes from events already in the data base.
However, let us added that the matching is never performed automatically, and goes
through human supervision.

A.2 Data Retrieval

To investigate our hypotheses, we have to curate the main dataset by considering only the
closed events, i.e. the events with an analysis level equal to 2, meaning “complete”.

To retrieve the data, we have followed the user guide5 provided by the MISP CIRCL
instance. We used the PyMISP module to download data in .json format ﬁle. The main

5https://www.circl.lu/doc/misp/book.pdf

19

dataset contains one ﬁle per event. These event ﬁles contain the attributes (see MISP
core format6), as well as the name and the ID of the concerned organizations. However,
due to the policy of the MISP CIRCL instance, we cannot disclose the names of these
organizations and present no interest and have no inﬂuence on the obtained results.

B Exploratory Analysis of the Data Set

B.1 Probabilistic Distributions

In order to understand the mechanisms handling on the MISP platform, we want to
investigate the distribution of our data, we have to present the selected variables and
explore the distribution associated with these. In some cases, we are able to investigate the
probabilities distribution. Hence, if we consider a random variable X with a probability
density function (PDF) fX (x), the cumulative distribution function (CDF), FX (x) is given
by:

FX (x) = P (X ≤ x) =

(cid:90) x

−∞

fX (t)dt.

(6)

Then, thanks to the formula (6), the complementary cumulative distribution function

(CCDF) FX (x) can be written as follow:

This CCDF provides a rank ordering of the selected variables.

FX (x) = 1 − FX (x) = P (X > x).

(7)

B.2 Fit of the Data

Before we start ﬁtting our data, a visual analysis can be performed. Then, in any case,
by varying the scale of axis – double linear, linear-logarithmic or double logarithmic
– depicting our data, we are able, if our data follow approximately a straight line in
one of cases presented below, to ﬁt the data. The logarithmic scales are considered in base 10.

B.2.1 Double Linear Scales
By considering two vectors of data −→x and −→y and plotting the data contained in −→y (y-axis)
in function of the data in −→x (x-axis) in linear scale for the axes x and y. If the displayed
data shows an approximate straight line, that means that each element yi of the vector −→y
is given by the relation:

yi = a · xi + b,

(8)

where a is the slope of the straight line and b, its intercept. Thanks to the relation
(8), we are able to compute the estimated ˆyi, a and b by applying a least-square linear
regression. To validate the parameter obtained from the linear regression, we need to
establish the goodness-of-ﬁt with these parameters. For this type of simple linear regression,
we use the Pearson’s coeﬃcient of determination R2 and, to reinforce the results of R2,
we perform a Wald test with a chosen level α = 0.05 to deﬁne if these two samples are
signiﬁcantly identical or not. Then a value |R2| ≈ 1 implies a strong correlation between
−→x and −→y , while a p-value < α for the Wald test allows us to aﬃrm that the parameters of

6https://www.misp-standard.org/rfc/misp-standard-core.html

20

the ﬁt are good and the estimated ˆ−→y are signiﬁcant according to −→y . With these indicators,
we can thus say that our data have a linear behaviour which follow a straight line with
slope a. a is the most important parameter for our analysis, then b can be neglected To
produce the linear regression on our data and to compute R2 and the p-value < 0.05 for
the Wald test, we use the Python library scipy.stats.linregress.

B.2.2 Linear-Logarithmic Scales

Following the same process as above, excepted that we put the y-axis in logarithmic scale.
If data −→y in function of −→x depict a straight line, we can write the relation as:

log(yi) = a · xi + b, derived from

yi = 10(a·x) · 10b,

(9)

(10)

where, a is the slope or the increasing factor and b the intercept or an additive constant
depending on the relations (9) and (10). In this case, the data describe an exponential
shape. As this process is not used in this article, we don’t develop completely this, it
remains nevertheless important to pursue with the last case.

B.2.3 Double Logarithmic Scales

Considering the same method than the two aforementioned cases, we plot the data contained
in −→y versus −→x on logarithmic x- and y-axis. In the case where the data behave itselves
like a straight line we are then able to deduce the relation:

log(y) = a · log(x) + b, derived from

y = xa · 10b,

(11)

(12)

where a is the slope or the exponent and b is the intercept or a multiplicative constant
according to the equations (11) and (12). From the relation (11), we can determine the
estimated values for elements ˆyi, a and b.

From here, we have to distinguish the two following cases:

(cid:40)

a ≥ 0 or
a < 0

(13)

In the case of a ≥ 0, we treat a power function given by the equation (12). The
ﬁt can be, as for the double linear case, obtained by performing the least-square linear
regression. Then, the goodness-of-ﬁt is given by the Pearson’s coeﬃcient of determination
R2 and the p-value < 0.05 for the Wald test. The results are computed the Python library
scipy.stats.linregress.

In the case of a < 0, we are in presence of a power law. Due to the presence of the
logarithm on both sides of (11), we cannot apply a least-square linear regression, because
this method and the similar ones return systematic errors for common conditions. For this
reason, it is impossible to trust the results [70]. Instead of this method, we estimate the
parameters a with the method of maximum likelihood after a quadratic approximation to
the log-likelihood to deal with our discrete values. In our analysis, the parameter b is not
relevant and we don’t need to estimate this. To determine if it really handles of a power law,
we proceed to a Kolmogorov-Smirnov test, attempting to minimize the distance between
the estimated parameters and our data. If the p-value from the Kolgomorov-Smirnov is

21

smaller than the chosen threshold α = 0.05 , we can aﬃrm that our data follow a power law
[70]. Sometimes, the ﬁts don’t ﬁt very well with a power law distribution that is why we
have to investigate other heavy-tailed distributions like the log-normal (L) or the Weibull
(W) (i.e., stretched-exponential) distributions, for which we can deﬁne the goodness-of-ﬁt
with the previous Kolmogorov-Smirnov test and its p-value. However, with approximately
same results, the power law is privileged because it is determined by one parameter instead
of two parameters for the two aforementioned distributions.
The computations in this part have been widely inspired from the works of A. Clauset &
al. and done with Python libraries such that plfit for the powerlaw and implemented
according to the works of A. Clauset & al. for the other distributions [70].

B.2.4 Goodness-of-ﬁts Summary

The results for the ﬁts presented in this article (i.e., Figure 1, 2 and 3), as well as their
goodness of are detailed in the below Table 5.

Fig Model Estimated Parameter(s)
1A PL a

µatt = 0.64(1)

Goodness-of-ﬁt
6.43 × 10−2

p-value Quality
< 10−2

(***)

1B PL a

2A PL a

2B LR b

3A LR b

3B LR b

µtags = 2.26(6)

µevents = 0.54(4)

βorgs = 0.79(1)

β∆ = −0.93(1)
β1
∆ = (−6.32 ± 0.91) × 10−2
∆ = (−7.12 ± 0.59) × 10−2
β2

1.52 × 10−1

1.51 × 10−1

0.99

0.97

0.86

< 10−2

(***)

< 10−2

(***)

< 10−2

(***)

< 10−2

(***)

< 10−3

(***)

Table 5: Goodness-of-ﬁts summary. The ﬁts are generated by the Power Law a and ordinary least squares
(OLS) Linear Regression b models. The goodness-of-ﬁt are obtained with the Pearson’s coeﬃcient R2 a and
the p-value of a Wald test for the Linear Regression a model and with the Kolmogorov-Smirnov statistic
test, also providing the p-value, for the Power Law b model. The results are computed with the Python
libraries scipy.stats.linregressa and plfit b.

22

