DeepTaskAPT: Insider APT detection using
Task-tree based Deep Learning

Mohammad Mamun
Digital Technology
National Research Council Canada
Fredericton, Canada
mohamad.mamun@nrc-cnrc.gc.ca

Kevin Shi
Digital Technology
National Research Council Canada
Fredericton, Canada
kevin.shi@nrc-cnrc.gc.ca

1
2
0
2

g
u
A
1
3

]

R
C
.
s
c
[

1
v
9
8
9
3
1
.
8
0
1
2
:
v
i
X
r
a

Abstract—APT, known as Advanced Persistent Threat, is a
difﬁcult challenge for cyber defence. These threats make many
traditional defences ineffective as the vulnerabilities exploited by
these threats are insiders who have access to and are within the
network. This paper proposes DeepTaskAPT, a heterogeneous
task-tree based deep learning method to construct a baseline
model based on sequences of tasks using a Long Short-Term
Memory (LSTM) neural network that can be applied across
different users to identify anomalous behaviour. Rather than
applying the model to sequential log entries directly, as most
current approaches do, DeepTaskAPT applies a process tree
based task generation method to generate sequential log entries
for the deep learning model.

To assess the performance of DeepTaskAPT, we use a recently
released synthetic dataset, DARPA Operationally Transparent
Computing (OpTC) dataset and a real-world dataset, Los Alamos
National Laboratory (LANL) dataset. Both of them are composed
of host-based data collected from sensors. Our results show
that DeepTaskAPT outperforms similar approaches e.g. DeepLog
and the DeepTaskAPT baseline model demonstrate its capability
to detect malicious traces in various attack scenarios while
having high accuracy and low false-positive rates. To the best
of knowledge this is the very ﬁrst attempt of using recently
introduced OpTC dataset for cyber threat detection.

I. INTRODUCTION

Cyber defense is a fundamental problem for the digital
economy, and it is, at the root, a data synthesis problem.
Organizations set up multiple sensors to feed their cyber
defenders with concurrent data streams reporting a large and
eclectic set of observations regarding resource usage, network
communications, application logs, user and host behavior,
threat intelligence, and so on. Defenders maintain awareness
of ongoing activities, and of malicious activities in particular,
by making sense of this complicated dataset. One of these
data synthesis tasks is to detect anomalies in the data stream,
e.g. extraordinary sequences of events, under the assumption
that incipient incidents would involve behaviors or actions
observed most rarely.

Current log-based methods of anomaly detection can be
narrowly grouped into two groups: Approaches based on log
event indices and approaches based on log template-semantics
[1]. Log event indices anomaly detection methods i.e. [1],
[3], [5], [17] extracts log events from log messages and
converts them into indexes. This approach doesn’t attempt
in log messages to use semantic knowledge. Thus, unseen

log models cannot be handled and can be unreliable. On the
other hand, log template semantic based methods [2], [6], [7]
treat the log stream model as a natural language sequence and
transform log templates to word vectors to train the model.
Both of these techniques can be used successfully to detect
advanced persistent threat (APT) to the modern enterprise [8].
We focus on understanding advanced persistent threat (APT)
attacks against host-based sensor telemetry and develop new
tools to combat them. Host-based sensors are headless soft-
ware with features similar to antivirus or EDR agents. They
capture low-level events regarding process life cycles, network
transactions, ﬁle operations, and other services of the operating
system; and relay all these events to a central repository. Host-
based telemetry is a heterogeneous dataset. It is composed
of event records of varying schema, whose semantics differ
signiﬁcantly between event types. These events enable analysts
to reconstruct the various threads of activity occurring on
the host, particularly that of an APT actor as it deploys
and runs persistently on the host to compromise other hosts
via intranet and steal sensitive information [12]. Many other
similar works restrict themselves to a subset of event types,
but we hypothesize that the collective semantics of events
of various types enables a better modeling of normal event
ﬂows [4]. In addition, concurrent activity threads, such as web
browsing, text redaction, system housekeeping are superposed
in a single stream. In the same vein, certain host activities
generate long sequences of events of a single type. As normal
activity can mix such data phenomena in a combinatorially
large number of ways, the development of recurrent neural
models is complicated.
Recently, recurrent

language
processing [15] have been applied to log data analysis, for
purposes of system failure diagnosis and root cause analysis.
In [14], a clustering technique is used to detect and forecast
device failure through several log entries that are input to
the LSTM network. DeepLog in [17] has used a generalised
method of identiﬁcation and diagnosis, with tasks isolated
from a log ﬁle. For each task a working ﬂow model has been
created before feeding to the LSTM model. OCAN in [18],
a semi-supervised anomaly detection model, uses LSTM for
fraud detection learning the representations of users from their
web activity. DeepAPT in [16] demonstrates how deep neural

techniques used in natural

 
 
 
 
 
 
network can be used to attribute nation-state APTs using
sandbox reports as input. That said, advances based on deep
learning can play a role in addressing issues with the afore-
mentioned work, in terms of detection performance, typically
due to the novelty of anomalies raised from malicious activity.
Learning rich normality representations with a limited amount
of data (with labeled anomalies) that generalize to new types
of anomalies remains a major challenge in unsupervised/semi-
supervised anomaly detection [10]. Deep learning methods
such as LSTM allow the whole anomaly detection pipeline to
be optimised and facilitate learning representation designed for
the detection of unknown anomalies [11], [13]. The methodol-
ogy embraced in these papers inspires the methods we present
here.

In general, a typical APT detection method transforms user
operations into sequences that can store information, such
as the sequential relationship between log entries, and then
uses sequence modelling techniques, such as N-gram to learn
from past events and predict the next one. In essence, these
methods model user behaviour at the training stage and trigger
exceptions as anomalies. However, concurrency is another big
challenge in this domain. It is certain that the order of events
in a log contains valuable insights and analytical detail, but
events log in the host can be generated by many different users,
threads or concurrent tasks. Prediction approaches based on
continuous logs can suffer a reliability loss to APT detection
if this relationship in the log is ignored.

A. Our contribution

We propose DeepTaskAPT, a deep learning method based
on tasks performed by the user, keeping in mind task-based
relationships in the log to detect APT attacks. DeepTaskAPT
comprises three components: 1) task tree construction. Deep-
TaskAPT constructs a task tree based on hierarchical relation-
ships between the system processes to integrate relationships
between log entries to determine users concurrent tasks in
the process trees within a host. 2) a baseline model. A
Long Short-Term Memory (LSTM) based neural network
model that includes all types of host-based events in a users’
tasks to vectorize the user’s normal activities to allow for a
plausible evaluation of their similarity to identify anomalies.
This powerful approach is a classiﬁer trained solely on normal
usage data without any assumption on the deployed malicious
tactics or common malware categories. 3) an anomaly detector,
against the baseline model to identify malicious actions effec-
tively. We assess the performance of DeepTaskAPT against
the DARPA OpTC [19] and LANL [22] synthetic and real-life
datasets respectively. They are highly representative of host-
based data streams captured through enterprise-grade sensors.
Furthermore, DeepTaskAPT can be updated incrementally
from new data, new users, as well as the identiﬁcation of
false positives by a human analyst. This adaptive aspect of
the model makes it appealing as its training cost can be spread
over time, enabling higher mission availability.

II. OVERVIEW

A. Anomaly detection in host-based telemetry

Semantics-aware anomaly detection methods

such as
DeepLog in [17] transform user operations into sequences that
store information, such as the sequential relationship between
log entries. They use sequence modeling techniques, such as
N -gram decomposition, to predict the next event from history.
In essence, these methods model user behaviour at the training
stage and trigger exceptions as anomalies.

However, these methods may overlook other relationships.
For example, a large number of operations at any given time
may imply a data breach and can be detected by the trained
LSTM model based on the user’s regular behavior [8]. This
surge of operations (sequences ordered by time) may not be
related to each other. Clearly, sequential relationship among
the operations may not be a logical relationship. In fact, they
might be generated from concurrent tasks. Existing sequence
based deep learning methods ignore these relationships. It
seems to be a strong assumption that a user’s everyday
behaviour must be fairly consistent and comparable over time.
Recently Log2vec in [8] proposes a complex graph embedding
based approach to address this problem and shows that existing
approaches’ performance incompetency to detect APT attacks.
DeepTaskAPT addresses the same issue with a solution
based on a task-tree based deep learning model (see Figure.
1b). More clearly, instead of using a deep learning model
directly, we demonstrate a task-based tree indicating process-
oriented user behavior. We can ﬁnd out anomalous user’s tasks
based on the relationship between operations. We rely on the
process-oriented nature of operating systems and assume that
prediction approaches can suffer a reliability loss if task-based
relationships in the log are ignored. DeepTaskAPT can detect
anomalous tasks based on a complete or partial sequence
of operations in the task from host-based telemetry records
captured on a single host or across an enterprise-size network.
From this detector, our second goal is to train such models
from telemetry data under weaker assumptions than previous
work.

DeepTaskAPT,

like other models, can be trained using
only normal/benign data. Rather than using a multi-source
LSTM model whose training requires telemetry describing
both benign and malicious activity, it leverages an LSTM
network to encode users’ log templates and to predict the next
action in the sequence.

B. System architecture

DeepTaskAPT architecture, as shown in Figure. 1, consists
of three components: Task-tree construction, building a base-
line model, and anomaly detection.

1) Task tree construction : General-purpose operating
systems start new processes in the context of another one
that’s already running: the former is deemed the child process,
and the latter, the parent process. This ﬁliation relationship
establishes a hierarchy across all running computations on a
system. Host-based sensors described in Section I report the

id
a390127d
d4f73408
4288ccff
...

object
FILE
PROCESS
FILE
...

action
CREATE
START
READ
...

pid
4
1804
344
...

ppid
0
554
556
...

actorid
1f8b17b2
6600a6eb
a0731a85
...

objectid
82ecf099
d2bb8111
7fe74abd
...

principal
NT AUTHORITY\textbackslash{}\textbackslash{}SYSTEM
NT AUTHORITY\textbackslash{}\textbackslash{}SYSTEM
NT AUTHORITY\textbackslash{}\textbackslash{}LOCAL SERVICE

ﬁle path
nan
winlogbeat.yml.new
Security.evtx
...

image path
System
lwabeat.exe
svchost.exe
...

parent image path
nan
nan
nan
...

timestamp
2019-09-25 12:32:14.303000
2019-09-25 15:38:13.715000
2019-09-25 15:38:14.552000
...

malicious
0
1
0
...

TABLE I: Log Entries From OpTC Datset

(a)

Fig. 1: DeepTaskAPT cyber threat detection: (a) system architecture (b) sequence creation approach from a task tree

(b)

start of any new process, and annotate it with an identiﬁer of
the parent process. Such process identiﬁers also tag any other
event reported by the sensor (such as network transactions
and ﬁle operations), augmenting the process tree with a set
of leaf objects. We call this augmented tree the task tree. We
call a task the union of a process and the events performed
in its context, which correspond to its child nodes in the task
tree and a trace is a sequence of events in a task ordered
chronologically.

To create tasks for a user from a host-based telemetry
stream, we rely on process identiﬁers associated with each
record, and assume that process-start events are also tagged
with the parent process identiﬁer. The goal of task tree genera-
tion is to map the relationships between log events representing
normal user behaviour and reveal malicious operations.

DeepTaskAPT tree construction algorithm tackles all the use
cases possible to generate a complete or partial task tree and
splits the events into tasks that we store in a tree to ﬁnd out the
relationship between events. We use CreateTaskTree function
in Algorithm. 1 to construct the task tree. It begins with the
events in sorted order and each event is then added to the tree
based on its ﬁliation relationship such as child (process id,
object id) and parent (parent process id, actor id) in OpTC
data. A detailed description of our tree construction process is
given in Algorithm. 1 and a sample tree in Figure. 1b. Each
child of the default root R is treated as a task and all events
that are part of the task are treated as traces under the task.

2) Encoding Task sequence: To obtain a logical repre-
sentation of a user’s operations, we develop a log sequence
encoder that handles contextual knowledge such as repetition
of action in a log sequence. The purpose of the encoding
algorithm is to ensure a meaningful sequence of actions
when the repetitive occurrence of certain actions may ﬁll
the File-Creation action occurs
the window. For instance,

(cid:46) D: List of actions from Dataset
(cid:46) tree= tree of all actions from D

nodeid ← (action.pid, action.objectid)
parentid ← (action.ppid, action.actorid)
if nodeid not in tree then

tree.addnode(id = parentid, parent = R)
tree.addnode(id = nodeid, parent = parentid)

if parentid not in tree then

tree ← new T ree
tree.addnode(R)
count ← 0
for action in D do

Algorithm 1 Task Tree Construction
1: procedure CREATETASKTREE(D)
2: Output: tree
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:

if tree.nodeid.parent = R then

else

else

else

return tree

if parentid not in tree then

tree.addnode(id = parentid, parent = R)

tree.move(nodeid, parentid)

if tree.nodeid.parent (cid:54)= parentid then

count ← F lagN odes(tree, nodeid, count)
if parentid not in tree then

tree.addnode(id = parentid, parent = R)
tree.addnode(id = nodeid, parent = parentid)

tree.nodeid.adddata(action)

1000 times consecutively. Instead of removing these action
sequences completely, we encode them as a new key.

We use Encode function as described in the Algorithm. 3
to generate encoded keys in a task. Encode gives a new label
to the events that occurred more than two times consecutively.
c}. We relabelled
b
Let a sequence be {a b
b(cid:48)
the sequence as {a b
c}
b
would remain as is. The encoding process occurs before the
task sequence is passed to the anomaly detection models.

b
c}. However, {a b

b

b

b

The encoding algorithm takes in a sequence of operations to
encode and the total number of unique operations in a dataset

Algorithm 2 Flag Nodes

1: procedure FLAGNODES(tree, id, count) (cid:46) tree:task tree, id: node to be

ﬂagged, count: #ﬂagged nodes

(cid:46) count= new #ﬂagged nodes

returnid, count ← F lagN odes(T ree, child.id, count)
tree.movenode(returnid, newid)

node ← tree.node(id)
newid ← id + count
tree.addnode(id = newid)
count ← count + 1
for child in node do

2: Output: count
3:
4:
5:
6:
7:
8:
9:
10:

tree.removenode(id)
return count

r.add(action)

if action = K.last then

Algorithm 3 Encoding keys in a Task
1: procedure ENCODE(K, n)
2: Output: r
r ← ∅
3:
f lag ← False
4:
for action in K do
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:

r.add(action + n)
f lag ← True

r.add(action)
f lag ← False

if action.last (cid:54)= action then

if not f lag then

r.add(action)

else

else

else

return r

(cid:46) K= actions in task n: #unique actions
(cid:46) r= encoded actions

if action.last (cid:54)= action and not f lag then

if action.last (cid:54)= action.next and not f lag then

(e.g. 32 in OpTC data). This ensures that the output sequence
has a maximum of two duplicate items consecutively. We
observed 61 encoded keys after the applying encoding function
on 32 unique actions in OpTC data, and 8 encoded keys from
4 unique keys in LANL data.

3) Building baseline model: We interpret log entries from
a user into trees or chronological sequences. They are all
connected to form a heterogeneous forest. Each tree in the
forest, corresponding to a task, is derived from a process based
relationship (see Section. II-B1). DeepTaskAPT’s baseline
model includes all types of normal host-based events in a joint
model. For baseline construction, we randomly choose users
in the dataset with a good number of log entries involved
in daily activities comprising all operations (log keys). The
object-action pairs (OpTC) or eventIDs (LANL), as referred
to log keys, parsed from the task trees, are used to train the
LSTM based anomaly detection model. The LSTM network is
a classiﬁer that is trained entirely on normal usage data, with
no assumptions about malicious tactics or common malware
categories.

4) Detection and validation: DeepTaskAPT adopts the
baseline anomaly detection model to analyze a task to be
benign or malicious. Assuming that the newly arrived user
events are parsed into a task (or subtask) and then the sequence
of task actions, DeepTaskAPT determines if the incoming task
is malicious. A task is labelled as malicious if one or more

input,

entries in the task are predicted to be malicious. However,
given the expert
the observed anomaly could be a
false positive. The model can be updated to integrate and
conform to the new trend. In order to validate DeepTaskAPT
performance, we use two types of public datasets: synthetic
(DARPA OpTC), real-life (LANL); and compare with similar
existing models such as Linear Regression, DeepLog, Random
Forest. We evaluate the results with testing data from the same
or different users against the baseline model.

C. Threat model

In general, host based system logs collected from network
sensors are considered secure and private in a large enterprise
setting. However, APT attacks, typically triggered by insider
employees, may perform malicious activities such as installing
malicious software, data leaks, scanning the system for vul-
nerability, compromising other hosts for escalating privileges
using the APT actor’s valid credentials. APT can be mod-
eled through three main approaches: asset-centric approach
focuses on individual assets that have value to the attacker, a
system-centric approach ﬁnds out vulnerability in the overall
system software, and a data-centric approach prevents data
leakage [23]. DeepTaskAPT concentrates on identifying the
approaches and a model that can detect malicious activities
and hence reduce APT risk.

D. Dataset for Cyber threat detection

We validate our anomaly detector using DARPA’s Opera-
tionally Transparent Computing Cyber (OpTC) dataset [19].
This dataset is the most detailed public dataset that includes
host-based telemetry records. Indeed, this sort of dataset is typ-
ically gathered privately, either as part of an enterprise’s own
cybersecurity operations, or by running professional security
services. While free sensor and data centralization software
has been available for a few years [20], building such a dataset
from scratch is a difﬁcult endeavor, notably involving privacy
issues if real users are involved in the data collection. Thus, the
public ﬁrst dataset recognizable as host-based telemetry was
heavily crippled for anonymization, discarding even process
ﬁliation information [21]. Its authors followed it up with an
improved dataset [22], whose host-based component adopted
a richer variable schema, much closer to comparable private
datasets. However, this stream only described normal activ-
ity on an IT network: unlike its predecessor, no red team
operation went on during its collection, which precludes the
validation of anomaly detectors as proxies to malicious activity
detectors. The OpTC dataset provides three types of red team
engagements that mirror such modern tactics, and its baseline
activity, while still generated through simulators, echoes the
structure and complexity of the private datasets the authors
have used in their own cyber defense research work. As
mentioned early, the LANL Uniﬁed Host and Network dataset
[22] is the only available public dataset that is somewhat
close to the OpTC dataset. It captures LANL’s network and
host operations over the span of 90 days. Similar to the
OpTC dataset, this dataset reports detailed process information

required for DeepTaskAPT’s task-tree generation. It is worth
noting that we couldn’t use the LANL 2015 dataset [21] due
to the missing ﬁliation relationship in the system process.

contrast to 32 (out of 32 in the dataset) in the OpTC dataset.
We use this dataset only to validate the performance of our
baseline model with the accuracy metric.

TABLE II: Experiment datasets

Log Dataset

#Training Data

OpTC
(same user)

25000 (task)
1015441 (trace)

OpTC
(different user)

42898 (task)
2975266(trace)

LANL
(different user)

5 (task)
41828 (trace)

#Test Data
#labeled 1 (task)
#unlabeled 17898 (task)
#labeled 14142 (traces)
#unlabeled 1355221 (trace)
#labeled 36 (task)
#unlabeled 8296 (task)
#labeled 53461 (trace)
#unlabeled 471596 (trace)
#unlabeled 14 (task)
#unlabeled 31138 (trace)

#encoded keys

61

61

8

III. EXPERIMENT

We conduct our experiment on a workstation with an Intel
Core i7-10750H running at 2.6 GHz, 128G RAM and 6 cores.
We use spark 3.0.2, python libraries for data extraction, tree
generation, training and tuning deep learning model.

A. Experimental Dataset and methods

OpTC/ecar logs were produced by several different threads
or concurrently running tasks. As part of pre-processing, Deep-
TaskAPT applied a Task-based tree construction algorithm (see
Section II-B1) followed by an encoding function (see Section
II-B2) to identify individual tasks of users to train and test
the model. As mentioned earlier, the OpTC dataset is highly
imbalanced in the number of labelled or malicious events. For
example, we identiﬁed 6 malicious tasks out of 27099 tasks
for user ID user0352, 1 malicious task out of 42899 tasks
for user0201. We assume a task is malicious if at least one
of its traces is labelled as malicious. Class imbalance is a
well-known issue in the area of machine learning or deep
learning.This is obvious in the OpTC dataset, with labelled
items being approximately 0.0016% of the whole dataset from
27 users. The disparity in the amount of benign and malicious
events makes it difﬁcult to train and test models as the model
performance degrades, especially for the minority classes.
DeepTaskAPT presents two solutions to tackle this problem:
1) training the model with only benign or unlabelled data, 2)
translate the events in the task to window-size traces for the
experiment. For instance, we created 14142 malicious traces
from 1 malicious task for OpTC user0201, 41131 benign traces
from 1 task for LANL user024735.

We collect 6 days (90 days) of users’ tasks from OpTC data
(LANL data) and transformed them to sequences of events to
learn the representations of ordinary users. The model that
emerges will then be used to identify labelled/malicious tasks
or actions performed by the same or other users. For the OpTC
dataset, we present test results from the model trained by one
user’s benign data and validated by the benign and malicious
data from 13 users. In contrast, the LANL dataset does not
have any labelled malicious events. Moreover, it lacks the
richness of contextual facts that hinder ﬁne-grained feature
engineering. For instance, only 4 operations (out of 20 in the
dataset) have ﬁliation information in the LANL dataset, in

’pid-ppid’,

to parse to a ’object-action’,

Events Log for the user has been extracted from (OpTC
data)
’actorid-
objectid’ values vector to generate a task tree. The LANL
dataset has 4 types of events with ﬁliation information (lo-
gin and process events only). Tasks trees for each user in
the LANL dataset
is created with ’EventID’, ’ProcessID-
ParentProcessID’, ’ProcessName-ParentProcessName’ values
vector. A detail description of task tree generation is given
in the section. II-B1. Due to resource constraints, for the
OpTC dataset DeepTaskAPT considers only the ﬁrst few
occurrences (e.g. 300, 1000, 1500) rather than training all of
the traces/sequences in the task.

Experimental data from LANL only includes trace based
evaluation. Due to a data shortage, we train the model with
41828 traces from ﬁve random users and test
the model
on 31138 traces from 14 users. A detailed description of
experiment data is given in Table. II.

B. Anomaly detection

DeepTaskAPT trains the model as a multi-classiﬁer over
recent user task operations where input is a history of recent
task based actions/traces (keys), and the output is a probability
distribution over the number of classes so that it can predict the
probability of the next operation in a sequence of operations.
Suppose we have a task resulting from benign execution parsed
into a sequence of actions {ai, ai+1, ai+2. . . , an}. Given a
window size (w = 15 in our case), we create an input sequence
and output level {aj, aj+1. . . a15 → ak}. In the detection
phase, we send a window from a task to the model as its
input. The output will be the probability distribution of each
candidate to be the next action. If an action is among the
top t candidates, DeepTaskAPT treats it as normal, otherwise
malicious. This is similar to a traditional N -gram model where
N is the window size. Fig: 1a embodied our design.

In the training phase, the model decides on proper weight
allotments to produce the desired output in the ﬁnal output
the LSTM sequence. Each input-output pair updates
of
these weights incrementally throughout
the training phase
by minimising losses (categorical cross-entropy loss) thru
is a window w with t
gradient descent where an input
is the action key value
operation keys, and an output
that follows w. In the detection phase, the input layer is
the encoded one hot vector of the t potential
log keys
from G. An output kt is predicted from the input window
w = (k0, k1, . . . , k(t−1)) using a layer of LSTM blocks.
The output layer actually converts the hidden state into a
distributed probability function P r(kt = pi|w) s.t. pi ∈ G.

Metrics: For evaluation, we performed both task based and
trace based prediction.
the
anomaly detection system determines True Positive (TP) and
False Positive (FP) based on the ﬁrst occurrence of miss-

In the task-based prediction,

classiﬁcation. While trace-based prediction evaluates all the
traces in the test dataset.

• TP: if malicious labelled is not predicted correctly
• FP: if benign labelled is not predicted correctly

Metric
Sensitivity/Recall
False Positive Rate (FPR)
Speciﬁcity
Accuracy
Precision
GMean

Computation detail
TP / (TP + FN)
FP / (FP + TN)
TN / (FP + TN)
(TP + TN)/ (TP + TN + FP + FN)
TP / (TP + FP)
Sensitivity ∗ Speciﬁcity

√

C. Model Parameters

DeepTaskAPT’s baseline model construction includes gen-
erating a complete task tree for the target user followed by
training the LSTM model. We use the gradient descent with
decaying learning rate for the error calculation, categorical
cross-entropy as a loss function. DeepTaskAPT uses window
size w = 15, number of layers L = 2, the number of memory
units per block α = 64, batch size B = 2048, number of
epochs (cid:15) =153 to 250. #candidate is the number of options
DeepTaskAPT is able to compare to for each trace/task, the
higher numbers allow for lower FPR but also lower recall. The
number of predicted #candidates (3 to 19) has been adjusted
based on the performance requirement. The random forest
model used in the experiment employs 50 estimators with no
maximum depth. All other settings are left at default.

IV. RESULTS AND DISCUSSION

We evaluate the performance of DeepTaskAPT based on
DeepLog [17] and typical machine learning algorithms such
as Random Forest, Linear Regression etc. In order to com-
pare our approach with other similar approaches, we build a
comprehensive train/test dataset (see Table. II) from the OpTC
and LANL datasets. According to our ﬁndings, DeepTaskAPT
outperforms existing related approaches in log based anomaly
detection. Besides, the efﬁcacy of task based tree and the
feature set’s diversity in the OpTC dataset aids in the analysis
of activity sequences by detection models. The metrics that we
employ to compare different approaches are accuracy, FPR,
recall and G-Mean.

The performance of DeepTaskAPT on the OpTC (same
user) dataset can be seen in Figure. 2 and Table. III. When
the model is tested only with malicious traces from the same
user, the model achieves better classiﬁcation performance than
when tested against malicious traces from all users. Evaluating
the performance of using traces and tasks from the same user,
the model shows that traces have a higher accuracy score and
a lower FPR than using tasks. However, the model with tasks
is able to achieve a recall score of 1.

Table.

III shows anomaly detection results for Deep-
TaskAPT when using tasks. When only testing with anomalous
tasks from the same user (user0201), the model is able to
detect all of the anomalous tasks 13 out of 13. With anomalous
tasks from all users in the dataset, 34 out of 36 anomalous
tasks are detected.

TABLE III: Anomaly Detection results for DeepTaskAPT with
Tasks on OpTC Dataset with malicious Tasks from Same User
and All Users

Test User
# of detected log
entries/ # total

Same User

All User

13/13

34/36

The results for user0321 and user0205 using a Deep-
TaskAPT model trained on user0201 data can be seen in
Figure. 3 for user0321. The results for both users show that
the model’s
with an increased number of training traces,
accuracy improves and has a lower FPR, but this also results
in reduced recall performance. For user0321, comparing the
model’s performance when using traces versus tasks shows
that the performance for traces is better for all metrics except
for accuracy at 15 candidates or greater. While for user0205,
the relative performance is dependent on the number of
candidates as tasks have higher recall below 11 candidates
and higher accuracy above 17 candidates.

The performance of a DeepTaskAPT model

trained on
user0201 applied to two different users, user0321 and
user0205, shows that a single model can be applied to dif-
ferent users within a dataset without signiﬁcant changes to
performance. The model’s anomaly detection performance for
both users is similar, with user0205 achieving a higher accu-
racy but having a near-identical FPR and recall performance.
This result implies that it would be possible to generalize a
DeepTaskAPT model trained on one user in a dataset and
apply that model to different users within the same dataset as
the individual user tested does not heavily impact the model’s
performance.

Comparing the performance of DeepTaskAPT to DeepLog
on the OpTC (same user) dataset (see Table. IV), Deep-
TaskAPT results in better performance in all metrics regardless
of the number of candidates chosen. When both models are
applied to the OpTC (different user) dataset, DeepTaskAPT
achieves a lower FPR (0.0529 vs. 0.1488) and higher accuracy
(0.9363 vs 0.8204) as well as having a much higher recall
score (0.882 vs. 0.5834).

TABLE IV: Anomaly Detection Performance for Different
Models on OpTC Dataset using traces with Models Trained on
user0201 and tested on user0201 and user0205. #candidate=5
for RF, DeepLog and DeepTaskAPT.

Method

DeepTaskAPT
DeepLog
RF (tree-processed)
RF (raw)
LR (tree-processed)
LR (raw)

user0201

user0205

Accuracy
0.9854
0.8354
0.9052
0.8088
0.1139
0.0858

FP Rate
0.011
0.161
0.0833
0.1831
0.9145
0.9370

Accuracy
0.9363
0.8204
0.8739
0.7967
0.1635
0.1128

FP Rate
0.0529
0.1488
0.0921
0.1800
0.9239
0.9566

DeepTaskAPT’s task tree construction is able to process data
for different prediction models such as random forests (RF)
and linear regression (LR) models. Task-tree processed and
raw data are tested with RF and LR models to evaluate the

Fig. 2: Performance evaluation on OpTC Dataset user0201 (same user)

Fig. 3: Performance evaluation on OpTC Dataset training: user0201 testing: user0321 window size: 15

TABLE V: Anomaly Detection Performance for Differ-
ent Models on OpTC Dataset using traces with Mod-
els Trained on user0201 and tested on user0201 and
user0205. #candidate=2 for DeepLog (user0201) and Deep-
TaskAPT(user0201) #candidate=3 for RF, DeepLog(user0205)
and DeepTaskAPT(user0205).

Method

DeepTaskAPT
DeepLog
RF (tree-processed)
RF (raw)
LR (tree-processed)
LR (raw)

user0201
Recall
0.7587
0.7202
0.6784
0.6132
0.9339
0.9057

user0205
Recall
0.882
0.5834
0.6784
0.6132
0.9344
0.9466

performance impact of using the processed data. Table. IV
and Table. V show the performance of the different methods
on the OpTC dataset. DeepTaskAPT achieves the highest
performance out of all of the approaches tested, with the
highest accuracy (0.9854) and the lowest false positive rate
(0.011), as well as one of the highest recall scores (0.882). The
models that use tree processed data from DeepTaskAPT’s task
tree generation deliver better performance than the same type
of model using raw data. This behaviour is seen in both the
random forest and linear regression models. This performance
improvement results in the random forest model with tree
processed data outperforming DeepLog in all metrics except
for user0201 recall performance. In comparison, the random
forest model with raw data performs worse than DeepLog in
all metrics except for recall performance for user0205. The
linear regression model with tree processed data outperforms
in all metrics for both users except for recall preference on
user0205. Although the recall appears to be incredibly good,
LR is not the winner of the experiment due to its high FPR

and the low accuracy.

TABLE VI: Number of FPs and FNs on OpTC Dataset
using traces with Models Trained on user0201 and Tested on
user0205 #candidate=5 for RF, DeepLog and DeepTaskAPT.

Method
false positive (FP)
/#Unlabeled
false negative (FN)
/#Labeled

DeepTaskAPT-Trace
24971
/471596
8493
/53461

DeepTaskAPT-Task

3274/8296

6/36

DeepLog
68622
/461201
21573
/41048

RF (tree-processed)
43426
/471545
22761
/53461

RF (raw)
90004
/500000
20129
/41661

LR (tree-processed)
435640
/471545
3505
/53461

LR (raw)
478314/
500000
2225
/41661

Table. VI shows the number of false-positive and false-
negative results for each method. The linear regression (raw)
method achieves the lowest number of false-positive results
but also generates the highest number of false-negative re-
sults showing the unbalanced performance of this method.
DeepTaskAPT has the best overall performance generating the
smallest percentage of false results.

TABLE VII: Anomaly Detection results for Different Mod-
els on OpTC Dataset using traces with Models Trained
on user0201 and Tested on user0205 #candidate=3 for RF,
DeepLog and DeepTaskAPT.

Method
# of detected log
entries/ #total

DeepTaskAPT

DeepLog

RF (tree-processed)

RF (raw)

LR (tree-processed)

LR (raw)

47150/53461

23946/41048

45367/53461

34078/41661

49956/53461

39436/41661

Table. VII shows the anomaly detection results for each
method using traces. Out of all of the methods, linear re-
gression (raw) followed by linear regression (tree-processed)
achieves the highest percentage of anomalous events detected,
but these methods also had the highest FPR out of all methods.
For methods with an acceptable FPR, DeepTaskAPT results in
the highest percentage of anomalous events detected, followed
by the random forest models, and lastly, DeepLog. DeepLog
exhibits better performance when tested and trained on the
same user.

TABLE VIII: Classiﬁcation Accuracy on LANL Dataset with
DeepTaskAPT and DeepLog Models. Both models trained on
5 users, models tested on 14 users. #candidate=3 for DeepLog
and DeepTaskAPT

Method
DeepTaskAPT
DeepLog

Accuracy
0.983
0.883

Using the LANL dataset, accuracy is measured based on
if the predicted value from the model matches the following
value in the sequence as LANL is an unlabeled dataset. Table.
VIII shows that DeepTaskAPT achieves a higher prediction
accuracy than DeepLog (0.983 vs 0.883) when tested on the
same users. DeepTaskAPT can outperform DeepLog on both
the OpTC dataset and the LANL dataset.

V. CONCLUSION

Task trees package sequential details of log operations
that are chronologically distant yet semantically close. This
enables DeepTaskAPT a useful model to detect APT attacks
as APT also reﬂects this characteristic. Task tree based se-
quence crea tion is thus an important step in creating efﬁcient
event representations for LSTM-based sequence classiﬁcation.
While DeepTaskAPT effectively detects anomalous behaviour
in the OpTC dataset with high accuracy and a low FPR, we
demonstrate that the task tree generation method can improve
the performance of other prediction methods.

Training deep learning models is a big challenge given
computations and memory limitations. We observed that train-
ing the model with more data and the number of epochs
(model parameter) improves the results. For example, training
the model with the ﬁrst 1500 traces from the tasks yields
better results than the trained model with the ﬁrst 300 traces.
It is worth noting that due to resource (RAM) limitations,
we were unable to train the model with full user data or
epoch values greater than 157 in certain instances. In an
enterprise setting, distinct baseline models for various types
of users may be developed. Alternatively, a baseline model
may be constructed using data from various groups of users.
Furthermore, a hierarchical architecture for anomaly detection
can be developed. For example, after initial detection, a second
level vector with additional parameters such as frequency
values can be produced. If any actions or parameters are
predicted to be malicious, the new task will be labelled as
malicious. Since the model can be retrained/updated with new
users’ data, these plans will be carried out in the future.

ACKNOWLEDGEMENT

We thank Dr. Benoit Hamelin from Communications Secu-
rity Establishment Canada for his valuable and constructive
suggestions. His willingness to share malicious labelled data
with technical details so generously has been very much
appreciated.

REFERENCES

[1] Huang, Shaohan, et al. ”HitAnomaly: Hierarchical Transformers for
Anomaly Detection in System Log.” IEEE Transactions on Network and
Service Management 17.4 (2020): 2064-2076.

[2] Mamun, Mohammad, et al. Detecting malicious urls using lexical analy-
sis. International Conference on Network and System Security. Springer,
Cham, 2016.

[3] J.-G. Lou, Q. Fu, S. Yang, Y. Xu, and J. Li, Mining invariants from
console logs for system problem detection, in Proc. USENIX Annu. Tech.
Conf., 2010, pp. 1–14.

[4] Mamun, Mohammad, Rongxing Lu, and Manon Gaudet. Tell

them
from me: An encrypted application proﬁler. International Conference on
Network and System Security. Springer, Cham, 2019.

[5] P. He, J. Zhu, S. He, J. Li, and M. R. Lyu, Towards automated log
parsing for large-scale log data analysis, IEEE Trans. Dependable Secure
Comput., vol. 15, no. 6, pp. 931–944, Nov./Dec. 2018.

[6] W. Meng et al., LogAnomaly: Unsupervised detection of sequential and
quantitative anomalies in unstructured logs, in Proc. 28th Int. Joint Conf.
Artif. Intell. (IJCAI), vol. 7, 2019, pp. 4739–4745.

[7] X. Zhang et al., Robust log-based anomaly detection on unstable log
data, in Proc. 27th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp.
Foundations Softw. Eng., 2019, pp. 807–817.

[8] Liu, F., Wen, Y., Zhang, D., Jiang, X., Xing, X., & Meng, D. (2019,
November). Log2vec: a heterogeneous graph embedding based approach
for detecting cyber threats within enterprise. In Proceedings of the 2019
ACM SIGSAC Conference on Computer and Communications Security
(pp. 1777-1794).

[9] Ferri, C´esar, Jos´e Hern´andez-Orallo, and R. Modroiu. ”An experimental
comparison of performance measures for classiﬁcation.” Pattern Recog-
nition Letters 30.1 (2009): 27-38.

[10] Aggarwal, C. C. (2017). An introduction to outlier analysis. In Outlier

analysis (pp. 1-34). Springer, Cham.

[11] Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark
Depristo, Joshua Dillon, and Balaji Lakshminarayanan. 2019. Likelihood
ratios for out-of-distribution detection. In NeurIPS. 14680–14691.
[12] A. Bohara, M. A. Noureddine, A. Fawaz, andW. H. Sanders. 2017. An
Unsupervised Multi-Detector Approach for Identifying Malicious Lateral
Movement. In 2017 IEEE 36th Symposium on Reliable Distributed
Systems (SRDS). 224–233.

[13] Dan Hendrycks and Kevin Gimpel. 2017. A baseline for detecting
misclassiﬁed and out-of-distribution examples in neural networks. In
ICLR.

[14] T. Young et al., Natural language processing: speaker, language, and
gender identiﬁcation with LSTM, Advanced Computing and Systems for
Security, pp. 143–156, Springer, Berlin, Germany, 2019.

[15] K. Zhang, J. Xu, M. R. Min et al., Automated ITsystem failure
prediction: a deep learning approach, in Proceedings of the Big Data
IEEE International Conference IEEE, pp. 1291–1300, Washington, DC,
USA, December 2016.

[16] Rosenberg, Ishai, Guillaume Sicard, and Eli Omid David. ”DeepAPT:
nation-state APT attribution using end-to-end deep neural networks.”
International Conference on Artiﬁcial Neural Networks. Springer, Cham,
2017.

[17] M. Du, F. Li, G. Zheng et al., DeepLog: anomaly detection and diagnosis
from system logs through deep learning, in Proceedings of the ACM
SIGSAC Conference on Computer and Communications Security, pp.
1285–1298, Dallas, TX, USA, October 2017.

[18] Panpan Zheng, Shuhan Yuan, Xintao Wu, Jun Li, and Aidong Lu. 2019.
One-class adversarial nets for fraud detection. In AAAI. 1286–1293.
[19] DARPA. 2020. Operationally Transparent Cyber Data Release 5. https:

//github.com/FiveDirections/OpTC-data Accessed 2021-04-13.

[20] Roberto Rodriguez.

2020.

SimuLand.

https://github.com/OTRF/

SimuLand Accessed 2021-04-14.

[21] Alexander D. Kent. 2015. Comprehensive, Multi-Source Cyber-Security
Events. Los Alamos National Laboratory. DOI 10.17021/1179829
[22] Melissa J. M. Turcotte, Alexander D. Kent and Curtis Hash.
In Data Science
2018. Uniﬁed Host
for Cyber-Security, chapter 1, pages 1-22. World Scientiﬁc. DOI
10.1142/9781786345646 001

and Network Data Set.

[23] Matt Tatam, Bharanidharan Shanmugam, Sami Azam, Krishnan Kan-
noorpatti. A review of threat modelling approaches for APT-style attacks.
Heliyon, Volume 7, Issue 1, 2021.

