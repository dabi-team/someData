6
1
0
2

r
a

M
0
1

]
I
S
.
s
c
[

2
v
2
7
3
7
0
.
2
1
5
1
:
v
i
X
r
a

MULTI-CENTRALITY GRAPH SPECTRAL DECOMPOSITIONS AND THEIR
APPLICATION TO CYBER INTRUSION DETECTION

Pin-Yu Chen⋆

Sutanay Choudhury†

Alfred O. Hero III⋆, Fellow, IEEE

⋆Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA
{pinyu, hero}@umich.edu
†Paciﬁc Northwest National Laboratory
Sutanay.Choudhury@pnnl.gov

ABSTRACT

Many modern datasets can be represented as graphs and hence spec-
tral decompositions such as graph principal component analysis
(PCA) can be useful. Distinct from previous graph decomposition
approaches based on subspace projection of a single topological
feature, e.g., the Fiedler vector of centered graph adjacency matrix
(graph Laplacian), we propose spectral decomposition approaches to
graph PCA and graph dictionary learning that integrate multiple fea-
tures, including graph walk statistics, centrality measures and graph
distances to reference nodes. In this paper we propose a new PCA
method for single graph analysis, called multi-centrality graph PCA
(MC-GPCA), and a new dictionary learning method for ensembles
of graphs, called multi-centrality graph dictionary learning (MC-
GDL), both based on spectral decomposition of multi-centrality
matrices. As an application to cyber intrusion detection, MC-GPCA
can be an effective indicator of anomalous connectivity pattern and
MC-GDL can provide discriminative basis for attack classiﬁcation.

1. INTRODUCTION

Many real-world data ranging from physical systems, social inter-
actions, network ﬂows, knowledge graphs to biological and chemi-
cal reactions are often represented as graphs, especially for anomaly
or community detection [1–9] and graph signal processing [10–14].
Dimensionality reduction methods on graphs allow one to decom-
pose a graph into principal components using a spectral decompo-
In this
sition of the graph adjacency or graph Laplacian matrix.
paper we propose a general framework to dimensionality reduction
based on spectral decomposition of a matrix composed of many dif-
ferent graph centrality statistics. This general framework leads to
a single-graph decomposition method that extends graph principal
components analysis (PCA) and a graph-ensemble decomposition
method that extends dictionary learning. These methods are appli-
cable to both directed and undirected graphs with edge weights and
are based on a spectral decomposition, speciﬁcally the singular value
decomposition (SVD), of a matrix composed of multiple graph cen-
trality statistics. The proposed methods are denoted multi-centrality
graph PCA (MC-GPCA) and multi-centrality graph dictionary learn-
ing (MC-GDL), respectively. By integrating multiple descriptions
of graph centrality, the proposed methods provide graph community

This work was partially supported by the Consortium for Veriﬁcation
Technology under Department of Energy National Nuclear Security Admin-
istration award number de-na0002534 and by the Asymmetric Resilient Cy-
ber Security initiative at Paciﬁc Northwest National Laboratory, which is op-
erated by Battelle Memorial Institute.

detection and graph structure learning that are signiﬁcantly more ro-
bust to noise and variation affecting graph connectivity structures.

In [15], a kind of graph PCA is performed on the distance ma-
trix of average commute time between nodes. In [16], PCA can also
be performed on the graph Laplacian matrix of nodal similarities.
In [17], the graph Laplacian matrix is used as a smooth regularization
function for robust PCA on graphs. In [18, 19], PCA is performed
on the matrix of origin-destination trafﬁcs. In [20–22], dictionary
learning methods for graph signals are proposed based on the graph
Laplacian matrix. Dictionary learning, also known as sparse cod-
ing, linear unmixing and matrix factorization, has been applied to
collections of images, audio, and graph signals to learn low dimen-
sional representations that give a sparse approximation to the en-
tire collection. Dictionary learning ﬁnds a low rank factored-matrix
approximation to the observation matrix, whose columns span this
collection. Many different methods for this approximation problem
have been proposed [23, 24]. Among the simplest methods is the
K-SVD approach [25] which uses a spectral decomposition to deter-
mine the best low rank approximation to the observed matrix. For
the purposes of illustration, in this paper we adopt this latter spectral
approach for learning a dictionary spanning an ensemble of graphs.
More often graph PCA and graph dictionary learning approaches
start with a set of raw multivariate data samples, create a similar-
ity (or dissimilarity) graph of the data samples, and aim to learn a
low-dimensional or sparse representation of the original multivariate
dataset. When applied to graph data, these methods are often limited
to graphs that are weighted, undirected and connected, which may
not be feasible for applications such as cyber network data analysis.
Furthermore, these methods often accomplish graph decomposition
based on a single measure of centrality, e.g., betweeness central-
ity [26], closeness centrality [27], ego centrality [28], or eigenvector
centrality [1]. In this paper we introduce graph spectral decompo-
sition methods that combine multiple centrality measures such as
graph walk statistics and graph distances as structural features and
apply them to different graph types including weighted, directed and
disconnected graphs. The proposed MC-GPCA method decomposes
a single graph utilizing multiple centrality features, achieving di-
mensionality reduction and feature decorrelation of the graph. The
proposed MC-GDL performs dictionary learning across a popula-
tion of graphs using multiple centrality features to learn the atoms of
the dictionary and the corresponding coefﬁcients to represent each
individual graph in terms of its projection onto the dictionary. Ap-
plying our approach to cyber intrusion detection, we use MC-GPCA
to deﬁne a structural difference score (SDS) that reﬂects structural
variations within a graph and we use MC-GDL to learn discrimina-
tive structural atoms for classifying the presence of cyber attacks.

 
 
 
 
 
 
2. STRUCTURAL FEATURE EXTRACTION ON GRAPHS

Table 1: Utility of the introduced structural features.

Here we describe three categories of generic structural features that
can be extracted from a graph, namely graph walk statistics, central-
ity measures and internode distances. The utility of the introduced
features with respect to different graph types, including weighted, di-
rected and disconnected graphs, is summarized in Table 1. While not
investigated in this paper, application-speciﬁc features such as web-
site hit rates, social interaction frequency, source-destination trafﬁcs
can also be leveraged as structural features. Without loss of general-
ity a graph G = (V, E ) can be characterized by two n×n matrices A
and W representing the adjacency and weight matrix, respectively,
where V (E ) is the set of nodes (edges), and n is the total number
of nodes (i.e., graph size). A is a binary matrix such that its entry
[A]ij = 1 if there is an edge connecting from node i to node j, and
[A]ij = 0 otherwise. Throughout this paper we consider graphs
with nonnegative edge weights such that W is a nonnegative matrix,
where its entry [W]ij ≥ 0 if [A]ij = 1, and [W]ij = 0 otherwise.

2.1. Graph walk statistics

Graph walk statistics include commute time and cover time [29],
graph diffusion [30], hitting times [31], and hop walks. In this paper
we focus on hop walk statistics. An h-hop walk of a node on a graph
is a path starting from the node and traversing through (possibly re-
peated) h edges. An h-hop walk weight is deﬁned as the sum of edge
weights of the corresponding path. We consider the number and to-
tal weight of h-hop walks of each node as features since they entail
the structural information of nodal reachability relative to its h-hop
vicinity. In principle one should extract graph walk statistics from
h = 1 to at least h = graph diameter hops as structural features,
where graph diameter is the largest shortest path hop count between
any node pairs in all connected components of a graph. We propose
an efﬁcient iterative computation method to incrementally computes
these two structural features with respect to the hop count number h:
• Iterative computation of number of h-hop walks
Let Ah denote the matrix product of h copies of A. Observe that
the entry of A2, [A2]ij =
Pk[A]ik[A]kj , is the number of 2-hop
walks from i to j. Extending this result to Ah we have [Ah]ij be-
ing the number of h-hop walks from i to j. Let a(h) = Ah1n be a
column vector where its entry [a(h)]i is the number of h-hop walks
starting from i and 1n denotes the n×1 column vector of ones. Then
a(h+1) can be computed by the matrix-vector product iteration

a(h+1) = Ah+11n = A · Ah1n = Aa(h).

(1)

• Iterative computation of total h-hop walk weight
Let W(h) be an n × n matrix such that its entry [W(h)]ij is the sum
of all h-hop walk weights from node i to node j. Then we have

[W(h+1)]ij =

=

X
k∈V

X
k∈V

(cid:16)[W]ik · [Ah]kj + [W(h)]kj (cid:17) · Aik

[W]ik · [Ah]kj +

[W(h)]kj · Aik

X
k∈V

= [WAh + AW(h)]ij ,

(2)

where we use [W]ik · [A]ik = [W]ik. Let w(h) = W(h)1n denote
a column vector such that its entry [w(h)]i is the total h-hop walk
weight starting from node i. Then w(h+1) can be computed by

w(h+1) = hWAh + AW(k)

i 1n = Wa(h) + Aw(h).

(3)

Feature / Graph Type
# of h-hop graph walks
total h-hop walk weight
degree
betweenness
closeness
eigenvector centrality
ego
LFVC
graph distance

Weighted Directed Disconnected

X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X

X

X
X
X

X
X
X

2.2. Centrality measures

A centrality measure is a quantity that evaluates the level of impor-
tance or inﬂuence of a node in a graph and it reﬂects certain topolog-
ical characteristics. Here we introduce several centrality measures,
which will be used in the sequel to deﬁne feature sets associated with
a graph or a set of graphs.
• Degree. Degree is deﬁned as the number of edges associated with a
node. It can be extended to directed graphs by considering the num-
ber of edges connecting to (from) a node as in-degree (out-degree).
• Betweenness [26]. Betweenness is the fraction of shortest paths
passing through a node relative to the total number of shortest paths
in the graph. It is infeasible for disconnected graphs since it is based
on shortest path distance. The betweenness of node i is deﬁned as

betweenness(i) =

X
k∈V,k6=i

X
j∈V,j6=i,j>k

σkj(i)
σkj

,

(4)

where σkj is the total number of shortest paths from k to j and
σkj(i) is the number of such shortest paths passing through i.
• Closeness [27]. Closeness is associated with the shortest path dis-
tances of a node to all other nodes. Let ρ(i, j) denote the shortest
path distance between node i and node j in a connected graph. Then

closeness(i) =

1
Pj∈V,j6=i ρ(i, j)

.

(5)

• Eigenvector centrality [1]. Eigenvector centrality of node i is the
i-th entry of the eigenvector associated with the largest eigenvalue
of the weight matrix W. It is deﬁned as

eigenvector centrality(i) = λ−1

max X
j∈V

[W]ji[ξ]j ,

(6)

where (λmax, ξ) is the largest right eigenpair of WT .
• Ego centrality [28]. Ego centrality can be viewed as a local ver-
sion of betweenness that computes the shortest paths between its
neighboring nodes. Let di denote the degree of node i, W(i) de-
note the (di + 1) × (di + 1) local weight matrix of node i, I be
the identity matrix, and let ◦ denote entrywise matrix product. Ego
centrality is deﬁned as

ego(i) =

X
k∈V

X
j∈V,j>k

1
[W2(i) ◦ (I − W(i))]kj

.

(7)

• Local Fiedler Vector Centrality (LFVC) [32]. LFVC is a cen-
trality measure that evaluates the structural importance of a node re-
garding graph connectivity. Let y denote the eigenvector associated

with the smallest nonzero eigenvalue of the graph Laplacian matrix.
LFVC is deﬁned as

LFVC(i) =

X
j∈Ni

([y]i − [y]j )2,

(8)

where Ni is the set of nodes connecting to or from i (i.e., neighbors).

2.3. Graph distances to a set of reference nodes

We propose to use graph distances of each node to a set of refer-
ence nodes as structural features that compensate the insufﬁciency
of graph walk statistics and centrality measures when one performs
MC-GPCA on graphs with high structural symmetry. For exam-
ple, consider a star-like graph where the central node is a singleton
and each leaf node is an identical clique (i.e., a complete graph).
All edges in the graph are undirected and have identical weight.
Therefore this graph has high structural symmetry and apparently
the nodes of identical structural property (e.g., connected to the cen-
tral node or not) have the same graph walk statistics and centrality
measures. To resolve the ambiguity of graph walk statistics and cen-
trality measures due to high structural symmetry in graphs we use
the shortest path distance of each node to the selected r reference
nodes as the r additional structural features. In the example of the
star-like graph with high structural symmetry, if r = 1 then selecting
any but the central node as a reference node can yield distinguish-
able structural features due to difference in shortest path distance to
the reference node. The reference nodes are selected according to a
user speciﬁed criterion, e.g. the nodes of maximal degrees.

3. METHODOLOGY

The extracted centrality features introduced in Sec. 2 can be rep-
resented as an n × p matrix X, where n is the graph size, p is the
number of extracted features and each column of X corresponds to
a particular centrality feature that is normalized to have unit norm.
The multi-centrality feature matrix X is then centered by subtracting
the row-wise empirical average from each row.

3.1. Multi-centrality graph PCA (MC-GPCA)

In analogy to standard graph PCA, which is applied to the graph
Laplacian matrix, MC-GPCA is PCA applied to X. PCA can be
formulated as ﬁnding an orthonormal transformation Q on X such
that after transformation the multi-centrality feature matrix X is rep-
resented by an n × q (q ≤ p) matrix Y = XQ that maximally
preserves the total data variance trace(YT Y)/n, where trace(·) de-
notes the sum of diagonal entries of a matrix and Q is a p × q matrix
such that QT Q = I. Such a matrix Q can be obtained by solving
the q right singular vectors associated with the q largest singular val-
ues of X, which is denoted by a p×q matrix Vq. Moreover, the total
variance of Y is equivalent to the sum of the q squared largest sin-
gular values of X divided by n. Therefore using MC-GPCA we ob-
tain n q-dimensional coordinates representing structural scores with
respect to the q principal components (i.e., columns of Vq). The
algorithm for MC-GPCA is summarized in Algorithm 1.

3.2. Structural difference score (SDS)

We use these structural coordinates (i.e., each row of Y = XVq) to
deﬁne a structural difference score (SDS) for each node in a graph.
The SDS of node i is associated with the total squared Euclidean

Algorithm 1 Multi-centrality graph PCA (MC-GPCA)

Input: A graph G = (V, E ), desired dimension q
Output: n structural coordinates Y for each node in G
1. Extract p structural vectors X from G
2. Normalize each column of X to have unit norm
3. Subtract row-wise empirical average from X
4. Solve the right singular vectors Vq of X
5. Y = XVq

Algorithm 2 Multi-centrality graph dictionary learning (MC-GDL)

ℓ=1, number of atoms K, sparsity

Input: A set of graphs {Gℓ}g
constraint S, number of highest SDS feature z
Output: graph structure dictionary D, coefﬁcient matrix C
1. Obtain z highest SDS from (9) for each graph as columns of Z
2. Subtract column-wise empirical average from Z
3. Perform K-SVD on Z to obtain D and C

distance to its neighboring nodes Ni and its number of edges (i.e.,
degree di), which is deﬁned as

SDS(i) = Pj∈Ni krowi(Y) − rowj(Y)k2

di + 1

,

(9)

where rowi(Y) denotes the i-th row of Y, k · k denotes Euclidean
distance, and the denominator di + 1 is such that the SDS of a sin-
gleton node is well-deﬁned.

3.3. Multi-centrality graph dictionary learning (MC-GDL)

Consider the case where a set of graphs {Gℓ}g
ℓ=1 is available, each
possibly being of different graph size and connectivity pattern, e.g.,
data from a cyber network at different time instances. Multiple-
centrality graph dictionary learning (MC-GDL) is proposed to learn
a sparse structure representation of {Gℓ}g
ℓ=1 by ﬁnding a dictio-
nary D consisting of K atoms (columns of D) and an associated
sparse coefﬁcient matrix C ∈ RK×g such that the representation
error kZ − DCkF is minimized while satisfying the column-wise
sparsity constraints on C that the number of nonzero entries of each
column can not exceed a speciﬁed value S, where the columns in
Z are structural features of {Gℓ}g
ℓ=1 and k · kF denotes the Frobe-
nious norm. Many different methods exist for solving the dictionary
learning problem of estimating D and C, often called the sparse cod-
ing problem [23, 24]. In this paper, we focus on a spectral method
(K-SVD) of dictionary learning introduced in [25]. The proposed
MC-GDL selects the z highest SDS from each graph as one column
of Z and applies K-SVD to ﬁnd the dictionary and the corresponding
coefﬁcient matrix. The algorithm is summarized in Algorithm 2.

4. EXPERIMENTS AND CYBER INTRUSION DETECTION

4.1. Illustration of sensitivity to structural changes on graphs

Here we consider four similar graphs with different structural char-
acteristics as displayed in Fig. 1 (a). From top to bottom, these four
graphs represent high structural symmetry, reduced structural sym-
metry due to edge removal, increase of the weight of edge (3,4), and
change in edge direction. The extracted multi-centrality features are
1) graph walk statistics from 1 to 4 hops, and 2) the graph distance
to node 1 (the reference node). It can be observed from Fig. 1 (b)

2

1
2

1
2

1
2

1

3

4
3

4
3

4
3

4

unweighted with
 high structural 
symmetry

5

unweighted with
 low structural 
symmetry

5
weighted

5
directed

5

7

6
7

6
7

6
7

6

8

9
8

9
8

9
8

9

total variance=100%

principal component variance

total variance=99.73%

pricipal component variance

2

4

6

8

0.5

0

−0.5

−0.4

4
1 2 3

6

7
8
9

5

−0.2

0
total variance=99.65%

0.2

0.05

0

−0.05

−0.4

789
1 23

4

6

5

−0.2

0
total variance=99.82%

0.2

0.4

e
r
o
c
s

l

i

a
p
c
n
i
r
p

d
n
2

0.1

0

3

−0.1

−0.4

0.1

0

−0.1

−0.4

4

2
1

6

9
7 8

5
−0.2

0
total variance=97.95%

0.2

78
9

6

5

12 3
0
total variance=90.03%

−0.2

0.2

4

100

50

0

0

100

)

%

(

e
c
n
a
i
r
a
v

100

1

0

−1

−1

789

6
5
23 4

0

1

1

1st principal score

50

0

0

2

4

6

8

50

0

0

2

4

6

8

100

50

0

0

2

4
pricipal component

6

8

0.4

0.4

2

7
8
9

6

0.4

0.4

0.4

)

%

(

e
c
n
a
i
r
a
v

0.2

0

3

5

2
4

1
−0.2

e
r
o
c
s

l

i

a
p
c
n
i
r
p

d
n
2

−0.2

−0.4

0.5

0

−0.5

−0.4

1

0

−1

−2

0
total variance=98.20%

0.2

4
1

23

6
5

7
9

8

−0.2

0
total variance=84.58%

0.2

1

6
5
2 34

789

−1

0

1

1st principal score

100

50

0

0

100

50

0

0

100

50

0

0

100

50

0

0

5

5

5

10

10

10

5
pricipal component

10

(a) Four example graphs

(b) MC-GPCA without reference nodes

(c) MC-GPCA with one reference node

Fig. 1: Illustration of sensitivity of proposed MC-GPCA algorithm to structural perturbations. Each node on a graph is represented by a
2-dimensional structural coordinate. Nodes marked by a gray box have identical MC-GPCA score.

Table 2: Description of the University of New Brunswick (UNB)
Intrusion Detection Evaluation Dataset [33]

Dataset
Day 1
Day 2

# nodes
5357
2631

# edges
12887
5614

Day 3

3052

5406

Day 4

8221

12594

Day 5

24062

32848

Day 6

Day 7

5638

4738

13958

11492

Description
Normal activity
Normal activity
Inﬁltrating attack and
normal activity
HTTP denial of service
attack and normal activity
Distributed denial of
service attack using Botnet
Normal activity
Brute force SSH attack
and normal activity

that MC-GPCA can reﬂect structural perturbations, and total data
variance is explained by one or two principal components. More-
over, the ﬁrst principal component is shown to completer describe
the network ﬂow pattern for the directed example graph. Fig. 1 (c)
shows that the graph distance feature adds discrimination power as
the MC-GPCA scores are better differentiated.

4.2. Cyber intrusion detection

The UNB intrusion detection evaluation dataset [33] described in
Table 2 is a collection of directed cyber network graphs where each
node is a host (machine) in a cyber system and an edge indicates the
existence of communication between hosts. No information beyond
graph topology is used for analysis. The extracted multi-centrality
features are 1) graph walk statistics from 1 to 20 hops, 2) all central-
ity measures introduced in Sec. 2.2 (edge directions are omitted for
computing LFVC), and 3) graph distances to 10 reference nodes of
highest degree, resulting in p = 56 features (columns of X). Fig. 2
(a) shows that the proposed SDS statistic (Eqn. (9)) with q = 2 prin-
cipal components from MC-GPCA. The SDS statistics are similar
over days without attacks, whereas they are signiﬁcantly higher in
days under attacks that induce anomalous connectivity patterns (i.e.
Days 3, 4 and 5). On the other hand degree statistic (Fig. 2 (b)) fails
to be a valid indicator of cyber attacks. The SDS statistic fails to
detect the SSH attack (Day 7) since it is a password attack that takes
place only between a single host and a single server.

10

e
g
a
r
e
v
a

n
o
i
t
a
v
e
d

i

d
r
a
d
n
a
t
s

5

0

6

4

2

0

Normal
Under Attack

1

2

3

5

6

7

4
Day

Normal
Under Attack

1

2

3

5

6

7

4
Day

e
g
a
r
e
v
a

6

4

2

0

n
o
i
t
a
v
e
d

i

d
r
a
d
n
a
t
s

150

100

50

0

Normal
Under Attack

1

2

3

5

6

7

4
Day

Normal
Under Attack

1

2

3

5

6

7

4
Day

(a) Graph-wise SDS statistic

(b) Graph-wise degree statistic

l

e
u
a
v
e
r
u
t
a
e
f

0.13

0.12

0.11

0.1

0.09

0.08

0.07

0.06

0.05

0.04

0.03

0

normal activity atom
attack activity atom

main router for external 
and internal traffics

higher variantion 
in SDS feature

50

100

150
SDS feature

200

250

300

m
o
t
a

y
t
i
v
i
t
c
a

k
c
a
t
t
a

f
o

i

t
n
e
c
i
f
f
e
o
c

30

20

10

0

−10

−20

−30

−40

−50

−60

−80

45

3

1
6 7

2

−60

−40

0
coefficient of normal activity atom

−20

20

40

60

80

(c) Dictionary from MC-GDL

(d) Coefﬁcients from MC-GDL

Fig. 2: Cyber intrusion detection on the UNB dataset. MC-GPCA
and MC-GDL are shown to be effective indicators of cyber attacks.

We applied MC-GDL to the entire UNB database of graphs to
learn a dictionary that spans the dataset. For this implementation
of MC-GDL we select K = 2 atoms, z = 300 SDS features and
S = 2 sparsity level. The two learned structural atoms in Fig. 2 (c)
can be interpreted as a normal activity atom consisting of identical
SDS features except for one spike accounting for the main router
and an attack activity atom of higher variance in SDS features. The
corresponding coefﬁcients in Fig. 2 (d) reﬂect the mixture portion
of these atoms and they can be used for attack classiﬁcation. For
instance, K-means clustering with 2 clusters identiﬁes Days 3, 4
and 5 as being anomalous and thus under attack.

5. CONCLUSION

This paper proposes PCA and dictionary learning graph decomposi-
tion methods that are based on multi-centrality features of the graph.
The proposed methods can reﬂect structural perturbations in graph
symmetry, edge weight and edge direction. When applied to cyber
intrusion detection, our experiments show that MC-GPCA and MC-
GDL can effectively detect attacks on the network.

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
6. REFERENCES

[1] M. E. J. Newman, Networks: An Introduction. Oxford Uni-

versity Press, Inc., 2010.

[17] N. Shahid, V. Kalofolias, X. Bresson, M. M. Bronstein,
and P. Vandergheynst, “Robust principal component analysis
on graphs,” CoRR, vol. abs/1504.06151, 2015. [Online].
Available: http://arxiv.org/abs/1504.06151

[2] C. C. Noble and D. J. Cook, “Graph-based anomaly detection,”
in ACM SIGKDD international conference on Knowledge dis-
covery and data mining, 2003, pp. 631–636.

[18] A. Lakhina, M. Crovella, and C. Diot, “Diagnosing network-
wide trafﬁc anomalies,” in ACM SIGCOMM Computer Com-
munication Review, vol. 34, no. 4, 2004, pp. 219–230.

[3] E. Hogan, P. Hui, S. Choudhury, M. Halappanavar, K. Oler,
and C. Joslyn, “Towards a multiscale approach to cybersecurity
modeling,” in IEEE International Conference on Technologies
for Homeland Security (HST), 2013, pp. 80–85.

[19] J. Terrell, K. Jeffay, F. D. Smith, L. Zhang, H. Shen,
Z. Zhu, and A. Nobel, “Multivariate SVD analyses for network
anomaly detection,” in ACM SIGCOMM Conference Poster
Session, 2005.

[4] P.-Y. Chen and A. O. Hero, “Assessing and safeguarding
network resilience to nodal attacks,” IEEE Commun. Mag.,
vol. 52, no. 11, pp. 138–143, Nov. 2014.

[20] D. Thanou, D. Shuman, and P. Frossard, “Learning parametric
dictionaries for signals on graphs,” IEEE Trans. Signal Pro-
cess., vol. 62, no. 15, pp. 3849–3862, Aug. 2014.

[5] C. Joslyn, S. Choudhury, D. Haglin, B. Howe, B. Nickless, and
B. Olsen, “Massive scale cyber trafﬁc analysis: A driver for
graph database research,” in International Workshop on Graph
Data Management Experiences and Systems (GRADES), 2013,
pp. 3:1–3:6.

[6] P.-Y. Chen and A. Hero, “Phase transitions in spectral commu-
nity detection,” IEEE Trans. Signal Process., vol. 63, no. 16,
pp. 4339–4347, Aug 2015.

[21] X. Zhang, X. Dong, and P. Frossard, “Learning of struc-
tured graph dictionaries,” in IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), Mar. 2012,
pp. 3373–3376.

[22] D. Thanou and P. Frossard, “Multi-graph learning of spec-
tral graph dictionaries,” in IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), Apr. 2015,
pp. 3397–3401.

[7] L. Akoglu, H. Tong, and D. Koutra, “Graph based anomaly
detection and description: a survey,” Data Mining and Knowl-
edge Discovery, vol. 29, no. 3, pp. 626–688, 2015.

[23] H. Lee, A. Battle, R. Raina, and A. Y. Ng, “Efﬁcient sparse
coding algorithms,” in Advances in neural information pro-
cessing systems (NIPS), 2006, pp. 801–808.

[8] B. Miller, M. Beard, P. Wolfe, and N. Bliss, “A spectral frame-
work for anomalous subgraph detection,” IEEE Trans. Signal
Process., vol. 63, no. 16, pp. 4191–4206, Aug. 2015.

[9] K. Oler and S. Choudhury, “Graph based role mining tech-

niques for cyber security,” in FloCon, 2015.

[10] D. Shuman, S. Narang, P. Frossard, A. Ortega, and P. Van-
dergheynst, “The emerging ﬁeld of signal processing on
graphs: Extending high-dimensional data analysis to networks
and other irregular domains,” IEEE Signal Process. Mag.,
vol. 30, no. 3, pp. 83–98, 2013.

[11] A. Bertrand and M. Moonen, “Seeing the bigger picture: How
nodes can learn their place within a complex ad hoc network
topology,” IEEE Signal Process. Mag., vol. 30, no. 3, pp. 71–
82, 2013.

[12] A. Anis, A. Gadde, and A. Ortega, “Towards a sampling
theorem for signals on arbitrary graphs,” in IEEE Interna-
tional Conference on Acoustics, Speech and Signal Processing
(ICASSP), 2014, pp. 3864–3868.

[13] X. Wang, P. Liu, and Y. Gu, “Local-set-based graph signal re-
construction,” IEEE Trans. Signal Process., vol. 63, no. 9, pp.
2432–2444, May 2015.

[14] S. Chen, A. Sandryhaila, J. Moura, and J. Kovacevic, “Signal
recovery on graphs: Variation minimization,” IEEE Trans. Sig-
nal Process., vol. 63, no. 17, pp. 4609–4624, Sept. 2015.

[15] M. Saerens, F. Fouss, L. Yen, and P. Dupont, “The principal
components analysis of a graph, and its relationships to spec-
tral clustering,” in Machine Learning: ECML. Springer, 2004,
pp. 371–383.

[16] B. Jiang, C. Ding, B. Luo, and J. Tang, “Graph-laplacian PCA:
Closed-form solution and robustness,” in IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), 2013, pp.
3492–3498.

[24] R. Jenatton, J. Mairal, F. R. Bach, and G. R. Obozinski, “Prox-
imal methods for sparse hierarchical dictionar learning,” in In-
ternational Conference on Machine Learning (ICML), 2010,
pp. 487–494.

[25] M. Aharon, M. Elad, and A. Bruckstein, “K-SVD: An algo-
rithm for designing overcomplete dictionaries for sparse rep-
resentation,” IEEE Trans. Signal Process., vol. 54, no. 11, pp.
4311–4322, 2006.

[26] L. Freeman, “A set of measures of centrality based on between-

ness,” Sociometry, vol. 40, pp. 35–41, 1977.

[27] G. Sabidussi, “The centrality index of a graph,” Psychometrika,

vol. 31, no. 4, pp. 581–603, 1966.

[28] M. Everett and S. P. Borgatti, “Ego network betweenness,” So-

cial Networks, vol. 27, no. 1, pp. 31–38, 2005.

[29] L. Lov´asz, “Random walks on graphs: A survey,” Combina-
torics, Paul erdos is eighty, vol. 2, no. 1, pp. 1–46, 1993.

[30] M. Gomez Rodriguez, J. Leskovec, and A. Krause, “Inferring
networks of diffusion and inﬂuence,” in ACM SIGKDD inter-
national conference on Knowledge discovery and data mining,
2010, pp. 1019–1028.

[31] L. Galluccio, O. Michel, P. Comon, M. Kliger, and A. O. Hero,
“Clustering with a new distance measure based on a dual-
rooted tree,” Information Sciences, vol. 251, pp. 96–113, 2013.

[32] P.-Y. Chen and A. O. Hero, “Local Fiedler vector centrality for
detection of deep and overlapping communities in networks,”
in IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), 2014, pp. 1120–1124.

[33] A. Shiravi, H. Shiravi, M. Tavallaee, and A. A. Ghorbani,
“Toward developing a systematic approach to generate bench-
mark datasets for intrusion detection,” Computers & Security,
vol. 31, no. 3, pp. 357–374, 2012.

