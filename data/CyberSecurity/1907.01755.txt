Gathering Cyber Threat Intelligence from Twitter
Using Novelty Classiﬁcation

Ba-Dung Le
School of Computer Science
University of Adelaide
Adelaide, Australia
badung.le@adelaide.edu.au

Guanhua Wang
School of Computer Science
University of Adelaide
Adelaide, Australia
guanhua.wang@adelaide.edu.au

Mehwish Nasim
School of Mathematical Sciences
University of Adelaide
Adelaide, Australia
mehwish.nasim@adelaide.edu.au

M. Ali Babar
School of Computer Science
University of Adelaide
Adelaide, Australia
ali.babar@adelaide.edu.au

9
1
0
2

p
e
S
5

]

R
C
.
s
c
[

2
v
5
5
7
1
0
.
7
0
9
1
:
v
i
X
r
a

Abstract—Preventing organizations from Cyber exploits needs
timely intelligence about Cyber vulnerabilities and attacks, re-
ferred to as threats. Cyber threat intelligence can be extracted
from various sources including social media platforms where
users publish the threat information in real-time. Gathering
Cyber threat intelligence from social media sites is a time-
consuming task for security analysts that can delay timely
response to emerging Cyber threats. We propose a framework for
automatically gathering Cyber threat intelligence from Twitter
by using a novelty detection model. Our model
learns the
features of Cyber threat intelligence from the threat descriptions
published in public repositories such as Common Vulnerabilities
and Exposures (CVE) and classiﬁes a new unseen tweet as either
normal or anomalous to Cyber threat intelligence. We evaluate
our framework using a purpose-built data set of tweets from 50
inﬂuential Cyber security-related accounts over twelve months (in
2018). Our classiﬁer achieves the F1-score of 0.643 for classifying
Cyber threat tweets and outperforms several baselines including
binary classiﬁcation models. Analysis of the classiﬁcation results
suggests that Cyber threat-relevant tweets on Twitter do not often
include the CVE identiﬁer of the related threats. Hence, it would
be valuable to collect these tweets and associate them with the
related CVE identiﬁer for Cyber security applications.

Keywords-Cybersecurity, Cyber threat, open source intelli-

gence, OSINT, Twitter

I. INTRODUCTION

Recently,

there has been an increasing reliance on the
Internet for business, government, and social interactions as
a result of a trend of hyper-connectivity and hyper-mobility.
While the Internet has become an indispensable infrastructure
for businesses, governments, and societies, there is also an
increased risk of Cyber attacks with different motivations and
intentions. For examples, a U.S. government report [1] shows
that there was an average of more than 4000 ransomware
attacks per day in 2016 - a four fold increase compared to
2015. According to Cybersecurity Ventures [2], Cyber crime
to businesses
will continue to rise with a combined cost
globally more than $6 trillion annually by 2021. Therefore,
Cyber security has become a critically important area of
research and practice over the last few years.

Preventing organizations from Cyber exploits needs timely
intelligence about Cyber vulnerabilities and attacks, referred
to as threats. Threat intelligence is deﬁned as “evidence-based
knowledge, including context, mechanisms, indicators, impli-

cations and actionable advice, about an existing or emerging
menace or hazard to assets that can be used to inform decisions
regarding the subject’s response to that menace or hazard” [3].
Threat intelligence in Cyber security domain, or Cyber threat
intelligence, provides timely and relevant information, such as
signatures of the attacks, that can help reduce the uncertainty
in identifying potential security vulnerabilities and attacks.

Cyber threat intelligence can generally be extracted from
overt or formal sources, which ofﬁcially release threat infor-
mation in structured data format. Structured threat intelligence
adhere to a well-deﬁned data model, with common format and
structure, such as an XML schema. Structured Cyber threat
intelligence, therefore, can be easily parsed by security tools to
analyze and respond to security threats accordingly. Examples
of formal sources of Cyber threat intelligence include the
Common Vulnerabilities and Exposures (CVE) database [4]
and the National Vulnerability Database (NVD) [5]. Fig. 1
shows an example of the entries in the CVE database relating
to a threat. Each CVE entry has an identiﬁer (ID) that includes
the preﬁx ‘CVE’, the year that the CVE entry was created
or published and a sequence number of four or more digits.
A CVE entry also has a brief description of the threat that
generally includes the information about the affected product,
versions and vendor, the threat type and the impact, method
and inputs of an attack. However, some of these details may
not be included in a CVE description if the information is not
available at the publishing time.

Cyber threat

intelligence is also available on covert or
informal sources, such as public blogs, dark webs, forums
and social media platforms. Informal sources allow any person
or entity on the Internet to publish, in real-time, the threat
information in natural language, or unstructured data format.
The unstructured and publicly available threat
intelligence
are also called Open Source Intelligence (OSINT) [6]. Cyber
security related OSINT are early warning sources for Cyber
security events such as security vulnerability exploits [7].
For examples, in June 2017, the global ransomware outbreak
of ‘Petya/NotPetya’ was discussed widely via Twitter before
being reported by mainstream media [8]. To prioritize response
to Cyber threats, Cyber security analysts must quickly de-
termine the emerging threats that are currently discussed on
public sources. However, gathering Cyber OSINT is a time-

 
 
 
 
 
 
Fig. 1. An example of the entries in the CVE database

consuming task as natural language is ambiguous and difﬁcult
for security tools to parse. Any delay in taking suitable actions
against a security vulnerability, threat, or attack can lead to
more loss.

The work reported in this paper has focused on collecting
and analyzing data from Twitter, which allows its users to
post 280 character long messages, called tweets. Twitter is a
main source for Cyber OSINT as many Cyber security experts
are using this open platform to disseminate information about
Cyber threats [9]. Fig. 2 shows a few examples of Cyber threat-
relevant tweets on Twitter. The ﬁrst tweet summarizes the CVE
entry with the identiﬁer ‘CVE-2018-0101’. The second and
third tweets discuss two different threats but do not include
any CVE identiﬁer. However, using our knowledge about
Cyber security, we can associate these two tweets with the
CVE identiﬁers ‘CVE-2018-20714’ 1 and ‘CVE-2017-11882’
2 respectively. Collecting these tweets with the associated CVE
identiﬁers is useful for Cyber threat-related applications such
as exploit prediction [7] and Indicators of Compromise (IoCs)
generation [10].

We have developed a framework for automatically gathering
Cyber threat intelligence from Twitter. Our framework utilizes
a novelty detection model to classify the tweets as relevant or
irrelevant to Cyber threat intelligence. The novelty classiﬁer
learns the features of Cyber threat intelligence from the threat
descriptions in the CVE database and classiﬁes a new unseen
in relation to Cyber threat
tweet as normal or abnormal
intelligence. The normal tweets are considered as Cyber threat-
relevant while the abnormal tweets are considered as Cyber
threat-irrelevant. We evaluate our framework on a purpose-
built data set created from the tweets collected over a period of
twelve months in 2018 from 50 inﬂuential Cyber security re-
lated accounts. During the evaluation, our framework achieved
the highest performance of 0.643 measured by the F1-score

1https://thehackernews.com/2018/06/wordpress-hacking.html
2https://www.trendmicro.com/vinfo/au/security/news/vulnerabilities-and-
exploits/17-year-old-ms-ofﬁce-ﬂaw-cve-2017-11882-actively-exploited-in-
the-wild

metric for classifying Cyber threat tweets. To our knowledge,
our approach outperformed several baselines including binary
classiﬁcation models. We have analyzed the correctly classiﬁed
Cyber threat tweets and discovered that 81 of them do not
contain a CVE identiﬁer. We have also found that 34 out of
the 81 tweets can be associated with a CVE identiﬁer included
in the top 10 most similar CVE descriptions of each tweet.

The highlights of this work are:
• An automated framework for detecting Cyber threat

tweets on Twitter using novelty classiﬁcation

• An evaluation of our framework on a challenging data
set created from the tweets collected over a period of
twelve months from 50 inﬂuential Cyber security related
accounts

• A detailed description of an analysis and the results of the
relationship between the correctly classiﬁed Cyber threat
tweets and threat descriptions in the CVE database

The rest of the paper is organized as follows. In section
2, we summarize the existing work related to automatically
gathering Cyber OSINT from Twiter. In section 3, we present
our framework for the automated collection task. We evaluate
our framework and discuss our ﬁndings in section 4. In section
5, we presents our conclusions from the results of our work
and suggests directions for future work.

II. RELATED WORK

In the last few years, research on using Cyber threat-relevant
information available on Twitter for security purposes has
gained signiﬁcant attention. To automatically collect Cyber
threat intelligence from Twitter, several methods have been
used [7], [8], [10]–[14].

The most traditional method for collecting Cyber threat-
relevant tweets is searching for the tweets containing the CVE
identiﬁer [7]. Sabottke at. al. [7] use this collection method
for predicting Cyber exploits in the real world. Their exploit
detector uses the collected Cyber threat tweets to improve the
precision of the prediction model and to generate early exploit
warnings. However, because the tweets that do not contain the

Fig. 2. Examples of the tweets about Cyber threats

CVE identiﬁer are ignored, their exploit detector might not
appropriately take into account the potential exploits relating
to the ignored Cyber threat tweets.

Le Sceller at. al. [11] collect Cyber threat information,
referred to as Cyber security events, on Twitter based on a
set of related keywords. Cyber threat irrelevant information,
that might have been collected, are discarded using backlist
keywords. Over time, new related keywords are added into
the set of the initially related keywords using a self-learned
mechanism. Sapienza et al. [8] identify Cyber threat tweets
as the tweets containing a number of terms in a set of Cyber
security related terms. Trabelsi et. al. [12] collect Cyber threat
tweets based on both the CVE identiﬁer and a set of Cyber
security related keywords. Mittal et al. [13] combine the key-
words based collection method and Name Entity Recognition
(NER) to collect Cyber threat information. The drawback of
the keywords based collection method for Cyber threat infor-
mation is that this method requires expert knowledge about
Cyber threats to choose the relevant keywords. The keywords
based collection method, therefore, can easily ignore Cyber
threat-related information and collects Cyber threat irrelevant
information if the keywords are not carefully selected [11].

Alves at. al. [14] focus on designing a completed online
monitoring system for Cyber threat tweets on Twitter. Their
monitoring system includes a Cyber threat tweet classiﬁcation
module that uses supervised machine learning approach to
classify Cyber threat tweets. This module transforms tweets
to vector representations and classiﬁes the tweets as Cyber
threat relevant or irrelevant using binary classiﬁcation models,
particularly Support Vector Machines (SVM) and Multi-Layer
Perceptron (MLP) neural networks. Dionsio et. al. [10] use
word embeddings such as GloVE [15] and Word2Vec [16]
for feature extraction and use the binary classiﬁcation model
Convolutional Neural Network (CNN) [17] for classifying
Cyber threat tweets. The collection method for Cyber threat
tweets based on binary classiﬁcation requires the classiﬁers
to be trained with both positive and negative samples, or
Cyber threat-relevant and Cyber threat-irrelevant tweets. This
potentially introduces the problem of sampling bias which

occurs when the positive or negative samples are not the rep-
resentative of Cyber threat-relevant or Cyber threat-irrelevant
tweets respectively.

III. GATHERING CYBER THREAT TWEETS USING
NOVELTY CLASSIFICATION
As previously reported, our work focuses only on the
collection method of Cyber threat tweets instead of a complete
system with functional requirements such as scalability, real-
time processing and security alert generation as in some
previous work [10], [13], [14]. The key idea of our method is
that we formulate the task of detecting Cyber threat tweets
as a novelty classiﬁcation task [18]. A novelty classiﬁer
needs to be trained only with positive samples without using
negative samples. After being trained, the novelty classiﬁer
subsequently applies its knowledge to decide whether a new
unseen tweet is normal or abnormal to the class of the positive
samples. By using novelty classiﬁcation, we avoid the issue
of sampling bias toward the negative training data set.

Fig. 3 shows the architecture of our framework for clas-
sifying Cyber threat tweets. Our framework consists of three
phases including pre-processing, feature extraction and novelty
classiﬁcation. The input of our framework includes the tweets
collected from Twitter and the threat descriptions from the
CVE database [4]. The CVE descriptions are used as the
positive samples for training our novelty classiﬁer. The output
of our framework consists of the tweets that are classiﬁed
as normal, or Cyber threat-relevant, and the tweets that are
classiﬁed as abnormal, or Cyber threat-irrelevant.

A. Preprocessing

The preprocessing phase is to eliminate the terms in the
input documents that are unnecessary for identifying Cyber
threat information. This phase converts the input documents
into lowercase with punctuation, numbers, hyperlinks, men-
tions and hashtags stripped out. Stopwords in the input doc-
uments are also removed using the default stopword list in
the Natural Language Toolkit (NLTK) package 3. We do not

3The NLTK package can be downloaded at https://www.nltk.org/

Fig. 3. Architecture of our framework for classifying Cyber threat tweets

apply stemming and lemmatizing onto the input documents as
it may change the meaning of them.

which is deﬁned as

cos(vi, vj) =

vi.vj
||vi|| ∗ ||vj||

.

B. Feature extraction

The feature extraction phase is to transform the pre-
processed documents into numerical vector representations for
classiﬁcation. To represent each document as a vector, we
use the Term Frequency-Invert Document Frequency (TF-IDF)
method [19], [20] which assigns weights to the document
terms as follows. Let d is a document in a corpus and t is
a term in the document. The weight of term t in document d
is deﬁned as

T F − IDF (t, d) = f (t, d) ∗ log(N/nt),

where f (t, d) is the number of the occurrences of term t in
document d, N is the total number of documents in the corpus
and nt is the number of the documents containing term t.

It is noted that our training corpus consists of only positive
samples. Therefore, the total number of documents in our
training corpus is the total number of the positive samples.

C. Novelty classiﬁcation

After transforming the collected tweets and the CVE de-
scriptions into numerical vectors, we use a novelty classiﬁer
to classify each of the input tweets as normal or abnormal to
the class of Cyber threat intelligence. To choose a suitable clas-
siﬁcation model, we explore two different novelty classiﬁers
including Centroid [21], [22] and One-class Support Vector
Machine [18], [23].

The Centroid classiﬁer [21], [22] decides whether an input
document is normal or abnormal to the positive class based on
the distance between the input document and the centroid of
the positive class. The centroid C of a class S of documents
is deﬁned as

C =

1
|S|

(cid:88)

d∈S

vd,

where d is a document in S, vd is the vector representation of
document d and |S| is the total number of document in S.

Given a threshold value, an input document is classiﬁed
abnormal to the positive class if the distance between the
document and the centroid is larger than the threshold value.
Otherwise, the input document is classiﬁer as normal to the
positive class. The distance between two vectors vi and vj is
computed as the cosine similarity between the two vectors,

The One-class Support Vector Machine (One-class SVM)
classiﬁer [18], [23] aims at ﬁnding a function that returns a
positive value for a normal data point of the positive class
and a negative value for an abnormal data point. As ﬁnding
the function is difﬁcult in the original feature space, the One-
class SVM classiﬁer maps the input data points into a high
dimensional feature space via a kernel. The mapping kernel
transforms the abnormal or novel data point closer to the origin
than the members. The One-class SVM classiﬁer then ﬁnds the
hyperplane that separates the training class from the origin
with maximum margin. For an input data point, the function
returns a value deciding the side of the hyperplane that the
input data point falls on. We use the implementation of One-
class SVM classiﬁer in the scikit-learn Python package 4.

IV. PERFORMANCE EVALUATION

A. Experiment setting

a) Training and testing data sets: To evaluate the perfor-
mance of our framework for classifying Cyber threat tweets,
we trained our classiﬁer with all the CVE descriptions released
in 2017. We tested our classiﬁer on the tweets posted in
2018 from 50 inﬂuential Cyber security related accounts on
Twitter. All of these Twitter accounts are known as experts or
organizations working in the Cyber security domain and each
of them has more than 5000 followers. Table I lists the 50
Twitter accounts for collecting Cyber threat tweets.

Since the total number of the tweets posted in 2018 from
the 50 Twitter accounts is very large (76205 tweets), it is
not practical to manually label all these tweets for verifying
the classiﬁcation performance. Therefore, we selected only a
subset of the posted tweets to create the testing data set. To
cover all the posted tweets that were potentially relevant to
Cyber threats, we weighted the relevance of each tweet to
Cyber threats and selected only the tweets with high relevance
score.

Because the training data consisted of only Cyber threat
descriptions, we assumed that the more frequently a term
appears in the training data set, the more relevant is the term
to Cyber threats. The more relevant to Cyber threats a term
is, the larger the relevance weight of the term is. Therefore,

4The scikit-learn Python package can be downloaded at https://scikit-

learn.org/

TweetsCVE Listis abnormal?Novelty Threat-Threat-irrelevantNoYesFeaturetweetPreprocessingtweetclassi(cid:1)cationrelevantextractionTABLE I
LIST OF THE 50 TWITTER ACCOUNTS FOR COLLECTING CYBER THREAT TWEETS

avast antivirus, cyber, CyberSec News, MalwareTechBlog, lennyzeltser, securityaffairs, CSOonline, DarkReading,
helpnetsecurity, USCERT gov, Peerlyst, e kaspersky, troyhunt, jeremiahg, schneierblog, mikko, IBMSecurity, k8em0,
briankrebs, OracleSecurity, TenableSecurity, Cybersec EU, Hacker Combat, securityonion, AdobeSecurity, circl lu,
USCyberMag, Secureworks, WDSecurity, CiscoSecurity, CarbonBlack Inc, MISPProject, Binary Defense, FireEye,
EmergingThreats, InfosecurityMag, EHackerNews, TheHackersNews, TrendMicro, SecurityWeek, Sophos, threatintel,
NortonOnline, McAfee, symantec, kaspersky, RecordedFuture, alienvault, Unit42 Intel, CyberGovAU

we deﬁned the relevance weight of a term t to Cyber threats
as:

rw(t) = log(1 +

nt
N − nt + 1

)

(1)

where N is the total number of documents in the training data
set and nt is the total number of the documents that contain
term t in the training data set.

Fig. 4 illustrates the word cloud of the top 100 popular
terms in the training data set. It can be inferred from the ﬁgure
that the terms such as ’CVE’ and ’vulnerability’ have larger
relevance weights to Cyber threats than the other terms such
as ’service’ and ’versions’.

The relevance weight of a tweet to Cyber threats can be
calculated as the sum of the relevance scores of all the terms,
weighted by their occurrences, in the tweet [24]. Therefore,
we deﬁned the relevance weight of a tweet d to Cyber threats
as

Fig. 4. Word cloud of the top 100 popular terms in our training data set

as follows.

RW (d) =

(cid:88)

t∈d

f (t, d) ∗ rw(t)

(2)

P recision =

True positives
True positives + False positives

where t is a term in tweet d, f (t, d) is the number of the
occurrences of term t in tweet d and rw(t) is the relevance
weight of term t to Cyber threats.

Combining (1) and (2), the relevance weight of a tweet d

to Cyber threats can be rewritten as

and

Recall =

True positives
True positives + False negatives

where True positives are the correctly classiﬁed Cyber threat-
relevant tweets, False positives are the Cyber threat irrelevant
tweets that are classiﬁed as relevant and False negatives are the
Cyber threat-relevant tweets that are classiﬁed as irrelevant.

RW (d) =

(cid:88)

t∈d

f (t, d) ∗ log(1 +

nt
N − nt + 1

)

(3)

F1-score is a combination of Precision and Recall given by

their harmonic mean.

We calculated the relevance weights for all the tweets posted
in 2018 from the 50 Twitter users and selected only the
top 3000 tweets with the highest relevance weight to create
the testing data set. The selected tweets were then manually
labeled as Cyber threat-relevant or irrelevant by two of the
authors (one is a postdoctoral researcher and the other is a PhD
student in the ﬁeld relating to Cyber security). After labeling
the selected tweets, we created a challenging testing data set
with 232 tweets labeled as positive and 2768 tweets labeled
as negative.

b) Evaluation metrics: To measure the classiﬁcation per-
formance, we used three common metrics including Precision,
Recall and F1-score. The deﬁnitions of these metrics are given

F 1 − score =

2 * Precision * Recall
Precision + Recall

B. Results and discussions

Fig. 5 plots Precision as a function of Recall achieved by
the Centroid and the One-class SVM classiﬁers. Precision
and Recall are computed by varying the threshold parameter
of these classiﬁers for deciding whether a tweet is normal
or anomalous to Cyber threats. Normal tweets are labeled
as Cyber threat-relevant while anomalous tweets are labeled
as Cyber threat-irrelevant. As can be seen from the ﬁgure,
the Centroid classiﬁer achieves a higher Precision rate than
the One-class SVM classiﬁer at the same Recall rate. This
means that the Centroid classiﬁer detects less number of false

cvevulnerabilityallowsremoteattackercraftedattackerscodeservicearbitrarycausedenialaccessfiledataidsiteuiavacprexecuteallowreadwebcrossxssphpcvssuseexistsversionsuseraffectedissuememoryserverversionfunctioninformationapplicationcomponentsuccessfulexecutiondiscoveredproductsusersbufferexploitableattackscrashandroidvulnerableresultlocalnetworkearlierunauthenticatedwindowskernelexploitscriptingoverflowimpacthttpcompromisemaliciousauthenticatedbaseunauthorizedpriorparameterunspecifiedoracleimpactsscoresupportedusingrelatedcorruptionsubcomponentsensitiveproductcontextleadcertainprivilegedinjectiondisclosureprivilegeseasilyaccessiblerequestvectorprocesslinuxattackbasedusedconfidentialityTABLE II
PERFORMANCE OF OUR NOVELTY CLASSIFIER AND THE BINARY
CLASSIFIERS SVM, MLP AND CNN

Classiﬁer
SVM
MLP
CNN
Our novelty classiﬁer

Precision Recall F1-score
0.608
0.578
0.625
0.517

0.653
0.638
0.474
0.851

0.629
0.606
0.539
0.643

Fig. 5. Precision as a function of Recall when varying the decision threshold
of the Centroid and One-class SVM classiﬁers

positives than the One-class SVM classiﬁer providing that both
the classiﬁers give the same number of true positives. The best
overall performance, in term of F1-score, is 0.643 given by
the Centroid classiﬁer corresponding to the Precision value of
0.851 and the Recall value of 0.517. In further analysis, we
used the Centroid classiﬁer with the threshold parameter value
that resulted in these Precision and Recall rates.

a) Comparison with baselines: To show the effectiveness
of our classiﬁcation framework, we further compared our
classiﬁer with several baselines. The ﬁrst baseline is the
collection method of Cyber threat tweets based on the CVE
identiﬁer [7]. This collection method simply collects only the
tweets that contain the CVE identiﬁer and ignores the tweets
that do not have a CVE identiﬁer. Applying to our testing
data set, 61 tweets with CVE identiﬁer were collected but
only 53 of them were relevant to Cyber threats. Recalled that
the total number of Cyber threat-relevant tweets in our testing
data set was 232. Therefore, collecting the Cyber threat tweets
based on the CVE identiﬁer gave the Precision rate of 53/61
(≈0.869) and the Recall rate of 53/232 (≈0.228). The F1-score
given from these Precision and Recall values is 0.361, which
is signiﬁcantly below the F1-score of 0.643 achieved by our
classiﬁer.

We also compared our classiﬁer with other baselines includ-
ing Support Vector Machine (SVM), Multilayer Perceptron
(MLP) and Convolutional Neural Network (CNN) [10], [14].
These baselines are binary classiﬁcation models which require
to be trained with both positive and negative samples. To
obtain the negative samples, we randomly collected 3000
tweets that were irrelevant to Cyber threats from the 50 Twitter
accounts (the tweets were veriﬁed by the two authors who
labeled the testing data set). The implementation of SVM and
MLP are provided in the scikit-learn Python package. The
implementation of CNN is provided in the TensorFlow Python
package 5. All the binary classiﬁcation models were trained

and executed with default parameter values.

Table II compares the performance of our novelty classiﬁer
and the binary classiﬁers SVM, MLP and CNN. It can be seen
from Table II that the binary classiﬁers give a higher Recall
rate than our classiﬁer but have a notably lower Precision rate.
In term of overall performance, our classiﬁer achieves a higher
F1-score than SVM, MLP and CNN.

C. Analysis of classiﬁed tweets

To demonstrate the usefulness of our classiﬁcation method,
we examined the relationship between the correctly classiﬁed
Cyber threat-relevant tweets and threat descriptions in the CVE
database. Our classiﬁer correctly labeled 120 Cyber threat-
relevant tweets out of the 232 Cyber threat-relevant tweets in
the training data set. Out of the 120 correctly labeled Cyber
threat-relevant tweets, 39 tweets contained the CVE identiﬁer
and 81 tweets did not. Since the recent research has well
analyzed Cyber threat-relevant tweets with CVE identiﬁer [7],
[10], [14], we focus our analysis on only Cyber threat-relevant
tweets without CVE identiﬁer.

For each of the 81 Cyber threat-relevant tweets without
CVE identiﬁer, we collected the top 10 CVE descriptions
which were most similar to the tweet 6 7. Our annotators were
then asked to identify that if each of the Cyber threat-relevant
tweets refers to the same threat with at least one of the top
10 CVE descriptions. We ﬁnd that 34 of the 81 Cyber threat-
relevant tweets without CVE identiﬁer refer to the same threat
with at least a CVE description. Table III lists some examples
of these tweets and the corresponding CVE description. The
other 47 Cyber threat-relevant tweets without CVE identiﬁer
refer to a threat that is not described by the top 10 CVE
descriptions. Table IV lists some examples of these tweets.

Our analysis of the classiﬁcation results suggests that Cyber
threat-relevant
tweets on Twitter do not often include the
CVE identiﬁer of the related threats. However, the related
CVE identiﬁer of a Cyber threat-relevant tweet can be iden-
tiﬁed by matching the tweet with the top 10 most similar
CVE descriptions. The matched CVE description, therefore,
provides additional information that are valuable for Cyber
threat-related applications such as exploit prediction [7] and
Indicators of Compromise (IoCs) generation [10].

6The similarity between a tweet and a CVE description was calculated by

the cosine similarity measure

5The

TensorFlow Python

package

can

be

downloaded

at

7The tweets were compared with only the CVE descriptions publicly

https://www.tensorﬂow.org

disclosed between 01/01/2015 and 30/04/2019

406080100Recall(%)20406080100Precision(%)CentroidOne-class SVMTABLE III
EXAMPLES OF THE TWEETS WITHOUT CVE IDENTIFIER THAT REFER TO A THREAT DESCRIBED BY AT LEAST ONE OF THE TOP 10 MOST SIMILAR CVE
DESCRIPTIONS.

Tweet
Newly Disclosed Cross-Site Scripting (XSS)
Vulnerability Resides in the Popular # CKEdi-
tor Rich-Text Editor Library That Comes Pre-
Integrated in Drupal Core. [Rated Moderately
Critical] Affected Versions x0014 CKEditor
4.5.11 and later versions (Drupal 8 & 7)
DHCP client application that allows systems to
automatically receive network parameters like
IP addresses contains # security vulnerability
that allows # hackers to run arbitrary com-
mands

CVE ID
CVE-2018-9861

CVE-2018-1111

CVE description
Cross-site scripting (XSS) vulnerability in the Enhanced Image
(aka image2) plugin for CKEditor (in versions 4.5.10 through
4.9.1; ﬁxed in 4.9.2), as used in Drupal 8 before 8.4.7 and
8.5.x before 8.5.2 and other products, allows remote attackers
to inject arbitrary web script through a crafted IMG element.

DHCP packages in Red Hat Enterprise Linux 6 and 7, Fedora
28, and earlier are vulnerable to a command injection ﬂaw
in the NetworkManager integration script
included in the
DHCP client. A malicious DHCP server, or an attacker on
the local network able to spoof DHCP responses, could use
this ﬂaw to execute arbitrary commands with root privileges
on systems using NetworkManager and conﬁgured to obtain
network conﬁguration using the DHCP protocol.

TABLE IV
EXAMPLES OF THE TWEETS WITHOUT CVE IDENTIFIER THAT REFER TO A THREAT NOT DESCRIBED BY ANY OF THE TOP 10 MOST SIMILAR CVE
DESCRIPTIONS

Tweet
Cb TAU recently detected a # Squiblydoo attack attempting to leverage regsvr32.exe & scrobj.dll to download and execute scriptlet
code via an # XML ﬁle. This attack also attempts to use taskeng.exe and the schedule service as persistence mechanisms via
The Sharpshooter technique can allow attackers to use a script to run a .NET binary directly from memory not ever needing to reside
on disk. Using durable AMSI-aided detection Windows Defender ATP disrupts campaigns and a steady hum of daily activity.

V. CONCLUSION

related entities to the current framework.

In this paper, we proposed an automated framework for
intelligence from Twitter. Our col-
gathering Cyber threat
that
lection framework utilizes a novelty detection model
learns the features of Cyber threat
intelligence from the
CVE descriptions and classiﬁes each input tweet as either
normal or anomalous to the class of Cyber threat intelligence.
We evaluated our framework on a challenging data set of
the tweets collected over the twelve months of 2018 from
50 inﬂuential Cyber security related accounts. Our classiﬁer
achieved a performance of 0.643 measured by F1-score for
classifying Cyber threat-relevant tweets, which is higher than
the performance of several baselines including SVM, MLP
and CNN. Our analysis on the correctly classiﬁed Cyber
threat-relevant tweets suggests that these tweets do not often
mention the CVE identiﬁer of the related threats. Collecting
these tweets and ﬁnding the related CVE identiﬁer, therefore,
provide further information that are valuable for Cyber threat-
related applications.

For the future work, our classiﬁcation framework for Cyber
threat-relevant tweets can be potentially enhanced by combin-
ing it with word embeddings [15], [16] for feature extraction.
The classiﬁcation performance can also be improved by adding
a phase of Named Entity Recognition (NER) for vulnerability-

ACKNOWLEDGMENT
The work has been supported by the Cyber Security Re-
search Centre Limited whose activities are partially funded
by the Australian Governments Cooperative Research Centres
Programme.

REFERENCES

[1] U. government, “How to protect your networks from ransomware.”
[2] C. Ventures, “Cybersecurity market report,” 2018.
[3] Gartner, “Deﬁnition: Threat intelligence.”
[4] MITRE, “Common vulnerabilities and exposures (cve).”
[5] U. government, “National vulnerability database (nvd).”
[6] R. D. Steele, “Open source intelligence: What is it? why is it important
to the military?,” American Intelligence Journal, pp. 35–41, 1996.
[7] C. Sabottke, O. Suciu, and T. Dumitras, “Vulnerability disclosure in
the age of social media: Exploiting twitter for predicting real-world
exploits.,” in USENIX Security Symposium, pp. 1041–1056, 2015.
[8] A. Sapienza, S. K. Ernala, A. Bessi, K. Lerman, and E. Ferrara, “Dis-
cover: Mining online chatter for emerging cyber threats,” in Companion
of the The Web Conference 2018 on The Web Conference 2018, pp. 983–
990, International World Wide Web Conferences Steering Committee,
2018.

[9] A. Queiroz, B. Keegan, and F. Mtenzi, “Predicting software vulnerability
using security discussion in social media,” in European Conference
on Cyber Warfare and Security, pp. 628–634, Academic Conferences
International Limited, 2017.

[10] N. Dion´ısio, F. Alves, P. M. Ferreira, and A. Bessani, “Cyberthreat
detection from twitter using deep neural networks,” arXiv preprint
arXiv:1904.01127, 2019.

[11] Q. Le Sceller, E. B. Karbab, M. Debbabi, and F. Iqbal, “Sonar:
Automatic detection of cyber security events over the twitter stream,”
in Proceedings of the 12th International Conference on Availability,
Reliability and Security, p. 23, ACM, 2017.

[12] S. Trabelsi, H. Plate, A. Abida, M. M. B. Aoun, A. Zouaoui, C. Mis-
saoui, S. Gharbi, and A. Ayari, “Mining social networks for software
vulnerabilities monitoring,” in New Technologies, Mobility and Security
(NTMS), 2015 7th International Conference on, pp. 1–7, IEEE, 2015.

[13] S. Mittal, P. K. Das, V. Mulwad, A. Joshi, and T. Finin, “Cybertwitter:
Using twitter to generate alerts for cybersecurity threats and vulnerabil-
ities,” in Proceedings of the 2016 IEEE/ACM International Conference
on Advances in Social Networks Analysis and Mining, pp. 860–867,
IEEE Press, 2016.

[14] F. Alves, A. Bettini, P. M. Ferreira, and A. Bessani, “Processing tweets
for cybersecurity threat awareness,” arXiv preprint arXiv:1904.02072,
2019.

[15] J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors
for word representation,” in Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP), pp. 1532–
1543, 2014.

[16] Q. Le and T. Mikolov, “Distributed representations of sentences and doc-
uments,” in International Conference on Machine Learning, pp. 1188–
1196, 2014.

[17] Y. Kim, “Convolutional neural networks for sentence classiﬁcation,”

arXiv preprint arXiv:1408.5882, 2014.

[18] B. Sch¨olkopf, R. C. Williamson, A. J. Smola, J. Shawe-Taylor, and
J. C. Platt, “Support vector method for novelty detection,” in Advances
in neural information processing systems, pp. 582–588, 2000.

[19] T. Joachims, “A probabilistic analysis of the rocchio algorithm with tﬁdf
for text categorization.,” tech. rep., Carnegie-mellon univ pittsburgh pa
dept of computer science, 1996.

[20] G. Salton and C. Buckley, “Term-weighting approaches in automatic
text retrieval,” Information processing & management, vol. 24, no. 5,
pp. 513–523, 1988.

[21] F. E. Grubbs, “Procedures for detecting outlying observations in sam-

ples,” Technometrics, vol. 11, no. 1, pp. 1–21, 1969.

[22] H. Guan, J. Zhou, and M. Guo, “A class-feature-centroid classiﬁer for
text categorization,” in Proceedings of the 18th international conference
on World wide web, pp. 201–210, ACM, 2009.

[23] L. M. Manevitz and M. Yousef, “One-class svms for document classiﬁ-
cation,” Journal of machine Learning research, vol. 2, no. Dec, pp. 139–
154, 2001.

[24] G. Domeniconi, G. Moro, R. Pasolini, and C. Sartori, “A comparison
of term weighting schemes for text classiﬁcation and sentiment analysis
with a supervised variant of tf. idf,” in International Conference on Data
Management Technologies and Applications, pp. 39–58, Springer, 2015.

