7
1
0
2

c
e
D
8
2

]

R
C
.
s
c
[

2
v
1
9
8
2
0
.
9
0
7
1
:
v
i
X
r
a

Defending against the advanced persistent threat: An optimal control approach

Pengdeng Lia,b, Xiaofan Yanga,b,∗, Qingyu Xionga,b, Junhao Wena,b, Yuan Yan Tangc

aKey Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044,
China
bSchool of Software Engineering, Chongqing University, Chongqing, 400044, China
cDepartment of Computer and Information Science, The University of Macau, Macau

Abstract

The new cyber attack pattern of advanced persistent threat (APT) has posed a serious threat to modern society. This

paper addresses the APT defense problem, i.e., the problem of how to eﬀectively defend against an APT campaign.

Based on a novel APT attack-defense model, the eﬀectiveness of an APT defense strategy is quantiﬁed. Thereby,

the APT defense problem is modeled as an optimal control problem, in which an optimal control stands for a most

eﬀective APT defense strategy. The existence of an optimal control is proved, and an optimality system is derived.

Consequently, an optimal control can be ﬁgured out by solving the optimality system. Some examples of the optimal

control are given. Finally, the inﬂuence of some factors on the eﬀectiveness of an optimal control is examined through

computer experiments. These ﬁndings help organizations to work out policies of defending against APTs.

Keywords: cybersecurity, advanced persistent threat, cyber attack-defense model, optimal control problem,

optimality system

1. Introduction

Nowadays, the daily operation of most organizations, ranging from large enterprises and ﬁnancial institutions to

government sectors and military branches, depends largely on computers and networks. However, this dependency

renders the organizations vulnerable to a wide range of cyber attacks. Traditional cyber attacks include computer

viruses, worms and spyware. Conventional cyber defense measures including ﬁrewall and intrusion detection turn out

to be eﬀective in withstanding these cyber attacks [1, 2].

The cyber security landscape has changed drastically over the past few years. A new type of cyber attack —

advanced persistent threat (APT) — has posed an unprecedentedly serious threat to modern society. According to

report, many high-proﬁle organizations have experienced APTs [3], and the number of APTs has been increasing

rapidly [4]. Compared with traditional cyber attacks, APTs exhibit two distinctive characteristics: (a) The attacker

∗Corresponding author
Email addresses: 1414797521@qq.com (Pengdeng Li), xfyang1964@gmail.com (Xiaofan Yang), Xiong03@equ.edu.cn (Qingyu Xiong),

jhwen@cqu.edu.cn (Junhao Wen), yytang@umac.mo (Yuan Yan Tang)

Preprint submitted to Security and Communication Networks

December 29, 2017

 
 
 
 
 
 
of an APT is a well-resourced and well-organized group, with the goal of stealing as many sensitive data as possible

from a speciﬁc organization. (b) Based on meticulous reconnaissance, the attacker is going to launch a preliminary

advanced social engineering attack on a few target users to gain footholds in the organization and then to gain access

to critical information stealthily and slowly [5–7]. Due to these characteristics, APTs can evade traditional detection,

causing tremendous damage to organizations. To date, the detection of APTs is far from mature [8, 9]. Consequently,

the APT defense problem, i.e., the problem of how to eﬀectively defend against APTs, has become a major concern

in the ﬁeld of cybersecurity.

As a branch of applied mathematics, optimal control theory aims to solve a class of optimization problems in

which, subject to a set of dynamic constraints, we seek to ﬁnd a function (control) so that an objective functional

is optimized [10, 11]. In real world applications, the set of dynamic constraints represents a dynamic environment,

a control represents a time-varying strategy, and the objective functional represents an index to be maximized or

minimized. Optimal control theory has been successfully applied to some aspects of cybersecurity [12–19]. To our

knowledge, the APT defense problem has yet to be addressed in the framework of optimal control theory. To model

the problem as an optimal control problem, we have to formulate an APT defense strategy as a control, characterize

the state evolution of an organization as a set of dynamic constraints, and quantify the eﬀectiveness of an APT defense

strategy as an objective functional. The key to the modeling process is to accurately characterize the state evolution

of an organization by employing the epidemic modeling technique [20].

Individual-level epidemic models refer to epidemic models in which the state evolution of each individual in

a population is characterized by one or a few separate diﬀerential equations. As compared with the coarse-ﬁned

state-level epidemic models [21–26] and the intermediate degree-level epidemic models [27–33], the ﬁne-coarsed

individual-level epidemic models can characterize spreading processes more accurately, because they can perfectly

accommodate the network topology. The individual-level epidemic modeling technique has been successfully applied

to areas such as the epidemic spreading [34–37], the malware spreading [38–43], and the rumor spreading [44]. In

particular, a number of APT attack-defense models have recently been proposed by employing this technique [45–48].

This paper focuses on the APT defense problem. Based on a novel individual-level APT attack-defense model,

the eﬀectiveness of an APT defense strategy is quantiﬁed. On this basis, the APT defense problem is modeled as

an optimal control problem, in which an optimal control represents a most eﬀective APT defense strategy. The

existence of an optimal control to the optimal control problem is proved, and an optimality system for the optimal

control problem is derived. Therefore, an optimal control can be ﬁgured out by solving the optimality system. Some

examples of the optimal control are presented. Finally, the inﬂuence of some factors on the eﬀectiveness of an optimal

control is examined through computer simulations. To our knowledge, this is the ﬁrst time the APT defense problem

is dealt with in this way. These ﬁndings help organizations to work out policies of defending against APTs.

2

The remaining materials are organized in this fashion. Section 2 models the APT defense problem as an optimal

control problem. Section 3 studies the optimal control problem. Some most eﬀective APT defense strategies are given

in Section 4. Section 5 discusses the inﬂuence of diﬀerent factors on the optimal eﬀectiveness. This work is closed

by Section 6.

2. The modeling of the APT defense problem

The goal of this paper is to solve the following problem:

The APT defense problem: Defend an organization against APTs in an eﬀective way.

To achieve the goal, we have to model the problem. The modeling process consists of the following four steps:

Step 1: Introduce preliminary terminologies and notations.

Step 2: Establish an APT attack-defense model.

Step 3: Quantify the eﬀectiveness of an APT defense strategy.

Step 4: Model the APT defense problem as an optimal control problem.

Now, let us proceed by following this four-step procedure.

2.1. Preliminary terminologies and notations

Consider an organization with a set of N computer systems labeled 1, 2, · · · , N. Let G = (V, E) denote the access

network of the organization, where (a) each node stands for a system, i.e., V = {1, 2, · · · , N}, and (b) (i, j) ∈ E if and

only if system i has access to system j. Let A =

0 according as (i, j) ∈ E or not.

ai j
h

iN×N

denote the adjacency matrix for the network, i.e., ai j = 1 or

Suppose an APT campaign to the organization starts at time t = 0 and terminates at time t = T . Suppose at any

time t ∈ [0, T ] every node in the organization is either secure, i.e. under the defender’s control, or compromised, i.e.,

under the attacker’s control. Let Xi(t) = 0 and 1 denote the event that node i is secure and compromised at time t,

respectively. The vector

X(t) = [X1(t), X2(t), · · · , XN(t)]

(1)

stands for the state of the organization at time t. Let S i(t) and Ci(t) denote the probability of the event that node i is

secure and compromised at time t, respectively. That is,

S i(t) = Pr {Xi(t) = 0} , Ci(t) = Pr {Xi(t) = 1} .

As S i(t) + Ci(t) ≡ 1, the vector

C(t) = [C1(t), · · · , CN(t)]T

stands for the expected state of the organization at time t.

3

(2)

(3)

From the attacker’s perspective, each secure node in the organization is subject to the external attack. Let ai denote

the cost per unit time for attacking a secure node i. The vector

a = [a1, · · · , aN]

(4)

stands for an attack strategy. Additionally, each secure node is vulnerable to all the neighboring compromised nodes.

From the defender’s perspective, each secure node in the organization is protected from being compromised. Let

xi(t) denote the cost per unit time for protecting the secure node i at time t. The vector-valued function

x(t) = [x1(t), · · · , xN(t)] ,

0 ≤ t ≤ T

(5)

stands for a prevention strategy. Additionally, each compromised node in the organization is revovered. Let yi(t)

denote the cost per unit time for recovering the compromised node i at time t. The vector-valued function

stands for a recovery strategy. We refer to the vector-valued function

y(t) =

y1(t), · · · , yN(t)

,

0 ≤ t ≤ T

(cid:2)

(cid:3)

u(t) =

x(t), y(t)

=

x1(t), · · · , xN(t), y1(t), · · · , yN(t)

,

0 ≤ t ≤ T

(cid:2)

(cid:3)

(cid:2)

(cid:3)

(6)

(7)

as an APT defense strategy.

2.2. An APT attack-defense model

For fundamental knowledge on diﬀerential dynamical systems, see Ref. [49]. For our purpose, let us impose a set

of hypotheses as follows.

(H1) Due to the external attack and prevention, a secure node i gets compromised at time t at the average rate ai

xi(t) .
The rationality of this hypothesis lies in that the average rate is proportional to the attack cost per unit time and

is inversely proportional to the prevention cost per unit time.

(H2) Due to the internal infection and prevention, a secure node i gets compromised at time t at the average rate

β

N
j=1 a jiC j(t)
xi(t)

P

, where β > 0 is a constant, which we refer to as the infection force. The rationality of this assumption

lies in that the average rate is proportional to the probability of each neighboring node being compromised and

is inversely proportional to the prevention cost per unit time.

(H3) Due to the recovery, a compromised node i becomes secure at time t at the average rate yi(t). The rationality of

this assumption lies in that the average rate is proportional to the recovery cost per unit time.

According to these hypotheses, the state transitions of a node are shown in Fig. 1. Hence, the time evolution of

the expected state of the organization obeys the following dynamical system:

dCi(t)
dt

=

ai + β

1
xi(t) 


N

Xj=1

a jiC j(t)


[1 − Ci(t)] − yi(t)Ci(t),

0 ≤ t ≤ T, i = 1, · · · , N.

(8)

4

We refer to the model as the APT attack-defense model.

(cid:4)
(cid:8) (cid:3)
(cid:1) (cid:2)
(cid:1)

(cid:3)
(cid:5)(cid:6)
(cid:6)
(cid:1)
(cid:8)

(cid:2)

(cid:4)

(cid:10)

(cid:5)

(cid:1)
(cid:4)

(cid:6) (cid:7) (cid:3)
(cid:1) (cid:2)

(cid:5)(cid:1)

(cid:5)

(cid:4)
(cid:7)
(cid:9)

(cid:1)(cid:2) (cid:3) (cid:1)
(cid:1) (cid:2)

(cid:3)

(cid:1)(cid:2) (cid:3) (cid:1)

(cid:1) (cid:2) (cid:4)

(cid:1)(cid:9) (cid:3)
(cid:1) (cid:2)
Figure 1. The diagram of state transitions of a node under the hypotheses (H1)-(H3).

The APT attack-defense model can be written in matrix-vector notation as

dC(t)
dt

= F(C(t), u(t)),

0 ≤ t ≤ T.

(9)

2.3. The eﬀectiveness of an APT defense strategy

The defender’s goal is to ﬁnd the most eﬀective APT defense strategy. To achieve the goal, we have to quantify the

eﬀectiveness of an APT defense strategy. For this purpose, let us introduce an additional set of hypotheses as follows.

(H4) The prevention cost per unit time is bounded from above by x and from below by x > 0, and the recovery cost

per unit time is bounded from above by y and from below by y > 0. That is, the admissible set of APT defense

strategies is given by

U =

u ∈
(cid:26)

(cid:16)

L2[0, T ]

2N

(cid:17)

| 0 < x ≤ xi(t) ≤ x, 0 < y ≤ yi(t) ≤ y, 0 ≤ t ≤ T, 1 ≤ i ≤ N

,

(cid:27)

(10)

where L2[0, T ] denote the set of all the Lebesgue square integrable functions deﬁned on the interval [0, T ] [50].

(H5) The amount of losses caused by a compromised node i in the inﬁnitesimal time interval [t, t + dt] is widt, where

wi =

N
j=1 ai j stands for the out-degree of node i in the network. The rationality of this hypothesis lies in that

P

the more nodes a node has access to, the more serious the consequence when it is compromised [51, 52].

According to the hypotheses, the expected loss of the organization in the time horizon [0, T ] when implementing

an APT defense strategy u =

x, y

is

(cid:2)

(cid:3)

Loss(u) =

N

T

Z
0

Xi=1

wiCi(t)dt,

and the overall cost for implementing the APT defense strategy is

Cost(u) =

N

T

Z

0

Xi=1

(cid:2)

xi(t) + yi(t)

dt.

(cid:3)

Hence, the eﬀectiveness of the APT defense strategy u can be measured by the quantity

J(u) = Loss(u) + Cost(u) =

wiCi(t)dt +

N

T

Z
0

Xi=1

(cid:2)

xi(t) + yi(t)

dt.

(cid:3)

N

T

Z
0

Xi=1

5

(11)

(12)

(13)

Obviously, the smaller this quantity, the more eﬀective the APT defense strategy. Let

Then

N

L(C(t), u(t)) =

[wiCi(t) + xi(t) + yi(t)].

Xi=1

J(u) =

T

Z
0

L(C(t), u(t))dt.

(14)

(15)

2.4. The modeling of the APT defense strategy

Based on the previous discussions, the APT defense problem boils down to the following optimal control problem:

T

J(u) =

min
u∈U

L(C(t), u(t))dt,

Z
0
dC(t)
dt

subject to

= F(C(t), u(t)),

0 ≤ t ≤ T,

(16)

C(0) = C0.

Here, each control stands for an APT defense strategy, the objective functional stands for the eﬀectiveness of an

APT defense strategy, the set of constraints stands for the time evolution of the expected state of the organization, an

optimal control stands for a most eﬀective APT defense strategy, and the optimal value stands for the eﬀectiveness of

a most eﬀective APT defense strategy.

3. A theoretical analysis of the optimal control problem

For fundamental knowledge on optimal control theory, see Refs. [10, 11]. This section is devoted to studying the

optimal control problem (16).

3.1. The existence of an optimal control

As an optimal control to the problem (16) represents a most eﬀective APT defense strategy, it is critical to show

that the problem does have an optimal control. For this purpose, we need the following lemma [11].

Lemma 1. Problem (16) has an optimal control if the following ﬁve conditions hold simultaneously.

(C1) U is closed and covex.

(C2) There is u ∈ U such that the adjunctive dynamical system is solvable.

(C3) F(C, u) is bounded by a linear function in C.

(C4) L(C, u) is convex on U .

(C5) L(C, u) ≥ c1||u||ρ + c2 for some vector norm || · ||, ρ > 1, c1 > 0 and c2.

Next, let us show that the ﬁve conditions in Lemma 1 indeed hold.

6

Lemma 2. The admissible set U is closed.

Proof: Let u = (x1, · · · , xN, y1, · · · , yN) be a limit point of U , u(n) =
sequence of points in U that approaches u. As

N , y(n)
is complete, we have u ∈

x(n)
1 , · · · , x(n)

L2[0, T ]

1 , · · · , y(n)
N
L2(0, T )

2N

(cid:16)

(cid:17)
2N

, n = 1, 2, · · · , be a

. Hence, the claim

follows from the observation that

(cid:16)

(cid:17)

(cid:16)

(cid:17)

x ≤ xi(t) = lim
n→∞

x(n)
i

(t) ≤ x,

y ≤ yi(t) = lim
n→∞

y(n)
i

(t) ≤ y,

0 ≤ t ≤ T, 1 ≤ i ≤ N.

(17)

Lemma 3. The admissible set U is convex.

Proof: Let u(1) =

x(1)
1 , · · · , x(1)
a real vector space, we get (1 − η)u(1)(t) + ηu(2)(t) ∈

1 , · · · , y(1)

N , y(1)

, u(2) =

(cid:17)

(cid:16)

N

x(2)
1 , · · · , x(2)

(cid:16)
L2[0, T ]

2N

1 , · · · , y(2)

N , y(2)
(cid:17)
. So, the claim follows from the observation that

∈ U , 0 < η < 1. As

L2[0, T ]

(cid:17)

(cid:16)

N

2N

is

x ≤ (1 − η)x(1)
i

(t) + ηx(2)
i

(t) ≤ x,

(cid:16)

(cid:17)
y ≤ (1 − η)y(1)
i

(t) + ηy(2)
i

(t) ≤ y,

0 ≤ t ≤ T, 1 ≤ i ≤ N.

(18)

Lemma 4. There is u ∈ U such that the associated adjunctive dynamical system is solvable.

Proof: Consider the adjunctive dynamical system

where u(t) ≡ u = (x, · · · , x, y, · · · , y). As F(C, u) is continuously diﬀerentiable, the claim follows from the Continua-

dC(t)
dt

= F(C(t), u),

0 ≤ t ≤ T,

(19)

tion Theorem for Diﬀerential Dynamical Systems [49].

Lemma 5. F(C, u) is bounded by a linear function in C.

Proof: The claim follows from the observation that for 0 ≤ t ≤ T , i = 1, 2, · · · , N,

ai + β

1
xi(t) 


N

Xj=1

a jiC j(t)


[1 − Ci(t)] − yi(t)Ci(t) ≤

ai + β

1
x 


N

Xj=1

a jiC j(t)


− yCi(t).

(20)

Lemma 6. L(C, u) is convex on U .

Proof: Let u(1), u(2) ∈ U , 0 < η < 1. Then

L

C, (1 − η)u(1) + ηu(2)

= (1 − η)L

C, u(1)

+ ηL

C, u(2)

.

(cid:16)

(cid:17)

(cid:16)

(cid:17)

(cid:16)

(cid:17)

Lemma 7. L(C, u) ≥

1

max{x,y} ||u||2
2.

Proof: We have

L(C, u) =

N

Xi=1

(wiCi + xi + yi) ≥

N

Xi=1

(xi + yi) ≥

Based on Lemmas 1-7, we get the following result.

Theorem 1. The problem (16) has an optimal control.

x2
i
x

+

N

Xi=1




y2
i
y 


≥

1
max{x, y}

||u||2
2.

This theorem guarantees that there is a most eﬀective APT defense strategy.

7

(21)

(22)

3.2. The optimality system

It is known that the optimality system for an optimal control problem oﬀers a method for numerically solving the

problem. This subsection is intended to present the optimality system for the problem (16). For this purpose, consider

the corresponding Hamiltonian

N

H(C(t), u(t), λ(t)) =

wiCi(t) + xi(t) + yi(t)

+

Xi=1

where λ = (λ1, · · · , λN)T is the adjoint.

Xi=1 (cid:2)
N

(cid:3)
N

Xj=1

ai + β

1
xi(t) 


λi(t) 



a jiC j(t)


[1 − Ci(t)] − yi(t)Ci(t)



.

Theorem 2. Suppose u∗ is an optimal control to the problem (16), C∗ is the solution to the adjunctive dynamical

system with u = u∗. Then, there exists λ∗ with λ∗(T ) = 0 such that for 0 ≤ t ≤ T , 1 ≤ i ≤ N,

dλ∗
i (t)
dt

= −wi + y∗

i (t)λ∗

i (t) +

ai + β

N

Xj=1

λ∗
i (t)
i (t) 
x∗


N

x∗
i (t) = max 



y,

ai + β

λ∗
i (t) 
min 





i (t)C∗
λ∗
i (t) < 1,

Xj=1

a jiC∗

j (t)


− β

a jiC∗

j(t)

1 − C∗
i (t)
(cid:2)

(cid:3)





,

, x



, x



ai j[1 − C∗
j (t)]λ∗
x∗
j(t)

j(t)

,

N

Xj=1

1
2

y∗
i (t) = 



y,

i (t)C∗
λ∗

i (t) > 1,






Proof: According to the Pontryagin Minimum Principle [10], there exists λ∗ such that

dλ∗
i (t)
dt

= −

∂H(C∗(t), u∗(t), λ∗(t))
∂Ci

,

0 ≤ t ≤ T, 1 ≤ i ≤ N

Thus, the ﬁrst N equations in the claim follow by direct calculations. As the terminal cost is unspeciﬁed and the ﬁnal

state is free, the transversality condition λ∗(T ) = 0 holds. By using the optimality condition

u∗(t) = arg min
u∈U

H(C∗(t), u(t), λ∗(t)),

0 ≤ t ≤ T.

we get (a) either

∂H(C∗(t), u∗(t), λ∗(t))
∂xi

= 1 −

or x∗

i (t) = x or x∗

i (t) = x, and (b)

λ∗
i (t)

x∗
i (t)

(cid:16)

(cid:17)

2 

ai + β


N

Xi=1

a jiC∗

j (t)


[1 − C∗

i (t)] = 0

y∗
i (t) = arg min
y≤yi(t)≤y

(cid:0)

1 − λ∗

i (t)C∗

i (t)

y,

y,

λ∗
i (t)C∗

i (t) < 1,

i (t)C∗
λ∗

i (t) > 1.

(cid:1)

yi(t) = 



8

Combining the above discussions, we get the optimality system for the problem (16) as follows.

ai + β

1
xi(t) 


N

Xj=1

dCi(t)
dt

=

dλi(t)
dt

= −wi + yi(t)λi(t) +

ai + β

a jiC j(t)


λi(t)
xi(t) 


N

ai + β

xi(t) = max 
λi(t) 
min 








y,

λi(t)Ci(t) < 1,

y,

λi(t)Ci(t) > 1,

yi(t) = 








[1 − Ci(t)] − yi(t)Ci(t),

N

Xj=1

− β

a jiC j(t)

[1 − Ci(t)]


ai j[1 − C j(t)]λ j(t)
x j(t)

,

N

Xj=1

1
2

,

, x



, x



(23)

Xj=1

a jiC j(t)


where C(0) = C0, λ(T ) = 0, 0 ≤ t ≤ T, 1 ≤ i ≤ N.

Applying the forward-backward Euler scheme to the optimality system, we can obtain an optimal control to the

problem (16), i.e, a most eﬀective APT defense strategy.

4. Some most eﬀective APT defense strategies

In this section, we give some most eﬀective APT defense strategies by solving the optimality system (23). For

ease in observation, let us introduce two functions as follows. For an admissible control u to the problem (16), deﬁne

the cumulative eﬀectiveness (CE) as

CE(t; u) =

N

t

Z
0

Xi=1

wiCi(s)ds +

N

t

Xi=1

Z

0 (cid:2)

xi(s) + yi(s)

ds,

0 ≤ t ≤ T,

(cid:3)

and deﬁne the superposed control (SC) as

S C(t; u) =

N

Xi=1 (cid:2)

xi(t) + yi(t)

,

0 ≤ t ≤ T,

(cid:3)

(24)

(25)

Obviously, we have CE(T ; u) = J(u).

For some optimal control problems, let us give the cumulative eﬀectiveness and superposed control for an optimal

control.

Example 1. Consider the problem (16) in which G is a scale-free network with N = 100 nodes that is generated by

executing the algorithm given in Ref. [53], T = 20, β = 0.001, x = y = 0.1, x = y = 0.7, ai = 0.1, 0 ≤ i ≤ N,

and Ci(0) = 0.1, 0 ≤ i ≤ N. An optimal control to the problem is obtained by solving the optimality system (23).

Fig. 2 plots the cumulative eﬀectiveness and superposed control for the optimal control. For comparison purpose, the

cumulative eﬀectiveness and superposed control for three admissible static controls are also shown in Fig. 2.

9

5000

4000

3000

2000

1000

0

s
s
e
n
e
v
i
t
c
e
f
f
e

e
v
i
t
a
l
u
m
u
C

(a)

 Optimal control
 xi(t)=0.3, yi(t)=0.2
 xi(t)=0.4, yi(t)=0.3
 xi(t)=0.5, yi(t)=0.4

5

10
Time

15

20

160

140

120

100

80

60

40

20

0

l
o
r
t
n
o
c

d
e
s
o
p
r
e
p
u
S

(b)

 Optimal control
 xi(t)=0.3, yi(t)=0.2
 xi(t)=0.4, yi(t)=0.3
 xi(t)=0.5, yi(t)=0.4

5

10
Time

15

20

Figure 2. The cumulative eﬀectiveness and superposed control for the optimal control and a few static controls in Example 1.

Example 2. Consider the problem (16) in which G is a small-world network with N = 100 nodes that is generated

by executing the algorithm given in Ref. [54], T = 20, β = 0.001, x = y = 0.1, x = y = 0.7, ai = 0.1, 0 ≤ i ≤ N,

and Ci(0) = 0.1, 0 ≤ i ≤ N. An optimal control to the problem is obtained by solving the optimality system (23). Fig.

3 depicts the cumulative eﬀectiveness and superposed control for the optimal control. For comparison purpose, the

cumulative eﬀectiveness and superposed control for three admissible static controls are also shown in Fig. 3.

6000

5000

4000

3000

2000

1000

0

s
s
e
n
e
v
i
t
c
e
f
f
e

e
v
i
t
a
l
u
m
u
C

(a)

 Optimal control
 xi(t)=0.3, yi(t)=0.2
 xi(t)=0.4, yi(t)=0.3
 xi(t)=0.5, yi(t)=0.4

5

10
Time

15

20

160

140

120

100

80

60

40

20

0

l
o
r
t
n
o
c
d
e
s
o
p
r
e
p
u
S

(b)

 Optimal control
 xi(t)=0.3, yi(t)=0.2
 xi(t)=0.4, yi(t)=0.3
 xi(t)=0.5, yi(t)=0.4

5

10
Time

15

20

Figure 3. The cumulative eﬀectiveness and superposed control for the optimal control and a few static controls in Example 2.

Example 3. Consider the problem (16) in which G is a realistic network given in Ref. [55], T = 20, β = 0.001,

x = y = 0.1, x = y = 0.7, ai = 0.1, 0 ≤ i ≤ N, and Ci(0) = 0.1, 0 ≤ i ≤ N. An optimal control to the problem is

obtained by solving the optimality system (23). Fig. 4 exhibits the cumulative eﬀectiveness and superposed control for

the optimal control. For comparison purpose, the cumulative eﬀectiveness and superposed control for three admissible

static controls are also shown in Fig. 4.

10

 
 
 
 
3
12x10

10

s
s
e
n
e
v
i
t
c
e
f
f
e

e
v
i
t
a
l
u
m
u
C

8

6

4

2

0

(a)

 Optimal control
 xi(t)=0.3, yi(t)=0.2
 xi(t)=0.4, yi(t)=0.3
 xi(t)=0.5, yi(t)=0.4

5

10
Time

15

20

160

140

120

100

80

60

40

20

0

l
o
r
t
n
o
c

d
e
s
o
p
r
e
p
u
S

(b)

 Optimal control
 xi(t)=0.3, yi(t)=0.2
 xi(t)=0.4, yi(t)=0.3
 xi(t)=0.5, yi(t)=0.4

5

10
Time

15

20

Figure 4. The cumulative eﬀectiveness and superposed control for the optimal control and a few static controls in Example 3.

It is seen from the above three examples that a most eﬀective APT defense strategy is signiﬁcantly superior to

any static APT defense strategy in terms of the eﬀectiveness. This observation justiﬁes our method. Additionally, the

superposed control drops rapidly to a lower value.

5. Further discussions

This section is devoted to examining the inﬂuence of diﬀerent factors on the optimal eﬀectiveness of an admissible

APT defense strategy. For ease in understanding these inﬂuences, let us introduce three quantities as follows. For an

optimal control u∗ to the problem (16), let OL∗, OC∗, and OJ∗ denote the corresponding expected loss, overall cost,

and eﬀectiveness, respectively. That is,

OL∗ = Loss(u∗), OC∗ = Cost(u∗), OJ∗ = OL∗ + OC∗ = J(u∗).

(26)

5.1. The bounds on the admissible controls

Deﬁnitely, the four bounds on the admissible controls aﬀect the optimal eﬀectiveness of an admissible APT de-

fense strategy. Now, let us examine these inﬂuences.

Example 4. Consider a set of problems (16) in which G is the scale-free network generated in Example 1, T = 20,

β = 0.001, ai = 0.1, 0 ≤ i ≤ N, and Ci(0) = 0.1, 0 ≤ i ≤ N.

(a) Let y = 0.1, y = 0.7. Fig. 5(a)-(c) exhibits the inﬂuence of x and x on OL∗, OC∗, and OJ∗, respectively.

(b) Let x = 0.1, x = 0.7. Fig. 5(d)-(f) displays the inﬂuence of y and y on OL∗, OC∗, and OJ∗, respectively.

11

 
 
Figure 5. The inﬂuence of the four bounds on OL∗, OC∗, and OJ∗ in Example 4.

Figure 6. The inﬂuence of the four bounds on OL∗, OC∗, and OJ∗ in Example 5.

Example 5. Consider a set of problems (16) in which G is the small-world network generated in Example 2, T = 20,

β = 0.001, ai = 0.1, 0 ≤ i ≤ N, and Ci(0) = 0.1, 0 ≤ i ≤ N.

(a) Let y = 0.1, y = 0.7. Fig. 6(a)-(c) exhibits the inﬂuence of x and x on OL∗, OC∗, and OJ∗, respectively.

(b) Let x = 0.1, x = 0.7. Fig. 6(d)-(f) displays the inﬂuence of y and y on OL∗, OC∗, and OJ∗, respectively.

12

Example 6. Consider a set of problem (16) in which G is the realistic network given in Example 3, T = 20, β = 0.001,

ai = 0.1, 0 ≤ i ≤ N, and Ci(0) = 0.1, 0 ≤ i ≤ N.

(a) Let y = 0.1, y = 0.7. Fig. 7(a)-(c) exhibits the inﬂuence of x and x on OL∗, OC∗, and OJ∗, respectively.

(b) Let x = 0.1, x = 0.7. Fig. 7(d)-(f) displays the inﬂuence of y and y on OL∗, OC∗, and OJ∗, respectively.

Figure 7. The inﬂuence of the four bounds on OL∗, OC∗, and OJ∗ in Example 6.

The following conclusions are drawn from the above three examples.

(a) With the increase of the two lower bounds, OL∗ goes down, but OC∗ and OJ∗ go up. In practice, the two lower

bounds should be chosen carefully so that a balance between the expected loss and the overall cost is achieved.

(b) The inﬂuence of the two upper bounds on OL∗, OC∗, and OJ∗ is almost negligible.

5.2. The network topology

Obviously, the topology of the network in an organization aﬀects the optimal eﬀectiveness of an admissible APT

defense strategy. Now, let us inspect this inﬂuence.

Example 7. Consider a set of problems (16) in which G ∈ {Gi : 1 ≤ i ≤ 7}, where Gi is a scale-free network with

N = 100 nodes and a power-law exponent of γi = 2.7 + 0.1 × i, T = 20, β = 0.001, x = y = 0.1, x = y = 0.7, ai = 0.1,

0 ≤ i ≤ N, and Ci(0) = 0.1, 0 ≤ i ≤ N. Figure 8 displays the inﬂuence of the power-law exponent on OL∗, OC∗, and

OJ∗, respectively.

13

449.0

448.0

*
L
O

447.0

446.0

2.8

(a)

523.4

(b)

*
C
O

523.2

523.0

(c)

971.6

971.2

970.8

970.4

970.0

*
J
O

3.0

3.2

3.4

2.8

3.0

3.2

3.4

2.8

3.0

3.2

3.4

Figure 8. The inﬂuence of the power-law exponent of a scale-free network on OL∗, OC∗, and OJ∗ in Example 7.

It is seen from this example that, with the increase of the power-law exponent of a scale-free network, OL∗ and OJ∗

decline, but OC∗ inclines. It is well known that the heterogeneity of a scale-free network increases with its power-law

exponent. Therefore, a homogeneously mixed access network is better in terms of the optimal defense eﬀectiveness.

Example 8. Consider a set of problems (P) in which G ∈ {Gi : 1 ≤ i ≤ 5}, where Gi is a small-world network with

N = 100 nodes and an edge-rewiring probability of pi = 0.1 × i, T = 20, β = 0.001, x = y = 0.1, x = y = 0.7, ai = 0.1,

0 ≤ i ≤ N, and Ci(0) = 0.1, 0 ≤ i ≤ N. Figure 9 exhibits the inﬂuence of the edge-rewiring probability on OL∗, OC∗,

and OJ∗, respectively.

1800

1600

(a)

*
L
O

1400

1200

(b)

560

540

520

500

*
C
O

(c)

2200

2000

*
J
O

1800

1600

1000

0.1

0.2

0.4

0.5

0.3
p

480

0.1

0.2

0.3
p

0.4

0.5

0.1

0.2

0.4

0.5

0.3
p

Figure 9. The inﬂuence of the edge-rewiring probability of a small-world network on OL∗, OC∗, and OJ∗ in Example 8.

It is seen from this example that, with the increase of the randomness of a small-world network, OL∗, OC∗, and

OJ∗ rise rapidly. Hence, a randomly connected access network is better from the perspective of the optimal defense

eﬀectiveness.

14

 
 
 
6. Concluding remarks

This paper has addressed the APT defense problem, i.e., the problem how to eﬀectively defend against APTs.

By introducing an APT attack-defense model and quantifying the eﬀectiveness of an APT defense strategy, we have

modeled the APT defense problem as an optimal control problem in which an optimal control represents a most

eﬀective APT defense strategy. Through theoretical study, we have presented the optimality system for the optimal

control problem. This implies that an optimal control can be derived by solving the optimality system. The inﬂuence

of some factors on the optimal eﬀectiveness of an APT defense strategy has been examined.

There are many relevant problems to be resolved. The expected loss and overall cost of an APT defense strategy

should be appropriately balanced to adapt to speciﬁc application scenarios.

In practice, the implementation of a

recommended defense strategy needs a great eﬀort; the security level of all the systems in an organization must be

labelled accurately [6], the defense budget must be made, and the robustness of the defense strategy must be evaluated.

As the topology of the access network in an organization may well vary with time, the approach proposed in this work

should be adapted to time-varying networks [56–59]. It is of practical importance to deal with the APT defense

problem in the game-theoretical framework, where the attacker is strategic [60–63].

Acknowledgments

The authors are grateful to the anonymous reviewers and the editor for their valuable comments and suggestions.

This work is supported by National Natural Science Foundation of China (Grant No. 61572006), National Sci-Tech

Support Program of China (Grant No. 2015BAF05B03), and Fundamental Research Funds for the Central Universities

(Grant No. 106112014CDJZR008823).

References

[1] G.K. Kostopoulos, Cyberspace and Cybersecurity, Taylor & Francis, 2012.

[2] P.W. Singer, A. Friedman, Cybersecurity and Cyberwar: What Everyone Needs to Know, Oxford University Press, 2014.

[3] N. Virvilis, D. Gritzalis, T. Apostolopoulos, Trusted computing vs. advanced persistent threat: Can a defender win this game? in: Proceedings

of UIC/ATC, 2013, pp. 396-403.

[4] S. Rass, S. Konig, S. Schauer, Defending against advanced persistent threats using game-theory, PLoS ONE 12(1) (2017) e0168675.

[5] C. Tankard, Advanced persistent threats and how to monitor and deter them, Network Security 2011(8) (2011) 16-19.

[6] E. Cole, Advanced Persistent Threat: Understanding the Danger and How to Protect Your Organization, Elsevier, 2013.

[7] T. Wrightson, Advanced Persistent Threat Hacking: The Art and Science of Hacking Any Organization, McGraw-Hill Education, 2015.

[8] I. Friedberg, F. Skopik, G. Settanni, R. Fiedler, Combating advanced persistent threats: From network event correlation to incident detection,

Computers & Security 48 (2015) 35-57.

[9] M. Marchetti, F. Pierazzi, M. Colajanni, A. Guido, Analysis of high volumes of network traﬃc for advanced persistent threat detection,

Computer Networks 109 (2016) 127-141.

15

[10] D.E. Kirk, Optimal Control Theory: An Introduction, Dover Publications, 2004.

[11] D. Liberzon, Calculus of Variations and Optimal Control Theory: A Concise Introduction, Princeton University Press, 2012.

[12] M.H.R. Khouzani, S. Sarkar, E. Altman, Maximum damage malware attack in mobile wireless networks, in: Proceedings of INFOCOM,

2010, pp. 1-9.

[13] M.H.R. Khouzani, S. Sarkar, Maximum damage battery depletion attack in mobile sensor networks, IEEE Transactions on Automatic Control

56(10) (2011) 2358-2368.

[14] J. Ren, Y. Xu, C. Zhang, Optimal control of a delay-varying computer virus propagation model, Discrete Dynamics in Nature and Society

2013 (2013) 210291.

[15] L. Chen, K. Hattaf, J. Sun, Optimal control of a delayed SLBS computer virus model, Physica A: Statistical Mechanics and its Applications

427 (2015) 244-250.

[16] L.X. Yang, M. Draief, X. Yang, The optimal dynamic immunization under a controlled heterogeneous node-based SIRS model, Physica A:

Statistical Mechanics and its Applications 450 (2016) 403-415.

[17] C. Nowzari, V.M. Preciado, G.J. Pappas, Analysis and control of epidemics: A survey of spreading processes on complex networks, IEEE

Control Systems 36(1) (2016) 26-46.

[18] T. Zhang, L.X. Yang, X. Yang, Y. Wu, Y.Y. Tang, Dynamic malware containment under an epidemic model with alert, Physica A: Statistical

Mechanics and its Applications 470 (2017) 249-260.

[19] W. Liu, S. Zhong, Web malware spread modelling and optimal control strategies, Scientiﬁc Reports 7 (2017) 42308.

[20] N.F. Britton, Essential Mathematical Biology, Springer-Verlag, 2003.

[21] J.R.C. Piqueira, V.O. Araujo, A modiﬁed epidemiological model for computer viruses, Applied Mathematics and Computation 213(2) (2009)

355-360.

[22] L. Feng, X. Liao, H. Li, Q. Han, Hopf bifurcation analysis of a delayed viral infection model in computer networks, Mathematical and

Computer Modelling 56(7-8) (2012) 167-179.

[23] B.K. Mishra, N. Keshri, Mathematical model on the transmission of worms in wireless sensor network, Applied Mathematical Modelling

37(6) (2013) 4103-4111.

[24] Y. Yao, N. Zhang, W. Xiang, G. Yu, F. Gao, Modeling and analysis of bifurcation in a delayed worm propagation model, Journal of Applied

Mathematics 2013 (2013) 927369.

[25] L. Feng, L. Song, Q. Zhao, H. Wang, Modeling and stability analysis of worm propagation in wireless sensor network, Mathematical Problems

in Engineering 2015 (2015) 129598.

[26] J. Ren, Y. Xu, A compartmental model for computer virus propagation with kill signals, Physica A: Statistical Mechanics and its Applications

485 (2017) 446-454.

[27] R. Pastor-Satorras, A. Vespignani, Epidemic spreading in scale-free networks, Physical Review Letters 86(14) (2001) 3200.

[28] R. Pastor-Satorras, A. Vespignani, Epidemic dynamics in ﬁnite size scale-free networks, Physical Review E 65(3) (2002) 035108.

[29] C. Castellano, R. Pastor-Satorras, Thresholds for epidemic spreading in networks, Physical Review Letters 105(21) (2010) 218701.

[30] L.X. Yang, X. Yang, J. Liu, Q. Zhu, C. Gan, Epidemics of computer viruses: A complex-network approach, Applied Mathematics and

Computation 219(16) (2013) 8705-8717.

[31] J. Ren, J. Liu, Y. Xu, Modeling the dynamics of a network-based model of virus attacks on targeted resources, Communications in Nonlinear

Science and Numerical Simulation 31(1-3) (2016) 1-10.

[32] W. Liu, C. Liu, Z. Yang, X. Liu, Y. Zhang, Z. Wei, Modeling the propagation of mobile malware on complex networks, Communications in

Nonlinear Science and Numerical Simulation 37 (2016) 249-264.

[33] L.X. Yang, X. Yang, The eﬀect of network topology on the spread of computer viruses: a modeling study, International Journal of Computer

Mathematics 94(8) (2017) 1591-1608.

16

[34] P. Van Mieghem, J.S. Omic, R.E. Kooij, Virus spread in networks, IEEE/ACM Transactions on Networking 17(1) (2009) 1-14.

[35] P. Van Mieghem, The N-Intertwined SIS epidemic network model, Computing 93(2) (2011) 147-169.

[36] F.D. Sahneh, F.N. Chowdhury, C.M. Scoglio, On the existence of a threshold for preventive behavioral responses to suppress epidemic

spreading, Scientiﬁc Reports 2 (2012) 623.

[37] F.D. Sahneh, C. Scoglio, P. Van Mieghem, Generalized epidemic mean-ﬁeld model for spreading processes over multilayer complex networks,

IEEE/ACM Transactions on Networking 21(5) (2013) 1609-1620.

[38] S. Xu, W. Lu, Z. Zhan, A stochastic model of multivirus dynamics, IEEE Transactions on Dependable and Secure Computing 9(1) (2012)

30-45.

[39] S. Xu, W. Lu, L. Xu, Push-and pull-based epidemic spreading in networks: Thresholds and deeper insights, ACM Transactions on Au-

tonomous and Adaptive Systems 7(3) (2012) 32.

[40] S. Xu, W. Lu, L. Xu, Z. Zhan, Adaptive epidemic dynamics in networks: Thresholds and control, ACM Transactions on Autonomous and

Adaptive Systems 8(4) (2014) 19.

[41] L.X. Yang, M. Draief, X. Yang, Heterogeneous virus propagation in networks: A theoretical study, Mathematical Methods in the Applied

Sciences 40(5) (2017) 1396-1413.

[42] L.X. Yang, X. Yang, Y. Wu, The impact of patch forwarding on the prevalence of computer virus, Applied Mathematical Modelling 43 (2017)

110-125.

[43] L.X. Yang, X. Yang, Y.Y. Tang, A bi-virus competing spreading model with generic infection rates, IEEE Transactions on Network Science

and Engineering, doi: 10.1109/TNSE.2017.2734075.

[44] L.X. Yang, P. Li, X. Yang, Y. Wu, Y.Y. Tang, On the competition of two conﬂicting messages, Nonlinear Dynamics, doi: 10.1107/s11071-

017-3986-z.

[45] S. Xu, W. Lu, H. Li, A stochastic model of active cyber defense dynamics, Internet Mathematics 11 (2015) 28-75.

[46] R. Zheng, W. Lu, S. Xu, Active cyber defense dynamics exhibiting rich phenomena, in: Proceedings of HotSoS, 2015, Article No. 2.

[47] L.X. Yang, P. Li, X. Yang, Y.Y. Tang, Security evaluation of the cyber networks under advanced persistent threats, IEEE Access 5 (2017)

20111-20123.

[48] R. Zheng, W. Lu, S. Xu, Preventive and reactive cyber defense dynamics is globally stable, IEEE Transactions on Network Science and

Engineering, doi: 10.1109/TNSE.2017.2734904.

[49] R.C. Robinson, An Introduction to Dynamical Systems: Continuous and Discrete, Pearson Education, Inc., 2004.

[50] E.M. Stein, R. Shakarchi, Real Analysis: Measure Theory, Integration, and Hilbert spaces, Princeton University Press, 2005.

[51] D. Kempe, J. Kleinberg, E, Tardos, Inﬂuential nodes in a diﬀusion model for social networks, in: Proceedings of ICALP, 2005, pp. 1127-1138.

[52] W. Chen, Y. Wang, S. Yang, Eﬃcient inﬂuence maximization in social networks, in: Proceedings of KDD, 2009, pp. 199-208.

[53] A.L. Barabasi, R. Albert, Emergence of scaling in random networks, Science 286 (1999) 509-512.

[54] D.J. Watts, S.H. Strogatz, Collective dynamics of ’small-world’ networks, Nature 393 (1998) 440-442.

[55] http://konect.uni-koblenz.de/networks/arenas-email

[56] Y. Schwarzkopf, A. Rakos, D. Mukamel, Epidemic spreading in evolving networks, Physical Review E 82 (2010) 036112.

[57] P. Holme, J. Saramaki, Temporal networks, Physics Reports 519(3) (2012) 97-125.

[58] M. Karsai, N. Perra, A. Vespignani, Time varying networks and the weakness of strong ties, Scientiﬁc Reports 4 (2014) 4001.

[59] E. Valdano, L. Ferreri, C. Poletto, V. Colizza, Analytical computation of the epidemic threshold on temporal networks, Physical Review X 5

(2015) 021005.

[60] T. Alpcan, T. Basar, Network Security: A Decision and Game-Theoretic Approach, Cambridge University Press, 2010.

[61] M.H. Manshaei, Q. Zhu, T. Alpcan, T. Basar, J.P. Hubaux, Game theory meets network security and privacy, ACM Computing Surveys 45(3)

(2013) 25.

17

[62] X. Liang, Y. Xiao, Game theory for network security, IEEE Communications Surveys and Tutorials 15(1) (2013) 472-486.

[63] P. Hu, H. Li, H. Fu, D. Cansever, P. Mohapatra, Dynamic defense strategy against advanced persistent threat with insiders, in: Proceedings of

INFOCOM, 2015, pp. 747-756.

18

The authors declare that there is no conﬂict of interest regarding the publication of this paper.

19

