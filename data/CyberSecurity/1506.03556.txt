Breaking Dense Structures – Proving Stability of Densely
Structured Hybrid Systems∗

Eike M¨ohlmann and Oliver Theel
Carl von Ossietzky University of Oldenburg
Department of Computer Science
D-26111 Oldenburg, Germany

{eike.moehlmann, theel}@informatik.uni-oldenburg.de

Abstraction and reﬁnement is widely used in software development. Such techniques are valuable
since they allow to handle even more complex systems. One key point is the ability to decompose a
large system into subsystems, analyze those subsystems and deduce properties of the larger system.
As cyber-physical systems tend to become more and more complex, such techniques become more
appealing.
In 2009, Oehlerking and Theel presented a (de-)composition technique for hybrid systems. This
technique is graph-based and constructs a Lyapunov function for hybrid systems having a complex
discrete state space. The technique consists of (1) decomposing the underlying graph of the hybrid
system into subgraphs, (2) computing multiple local Lyapunov functions for the subgraphs, and ﬁ-
nally (3) composing the local Lyapunov functions into a piecewise Lyapunov function. A Lyapunov
function can serve multiple purposes, e.g., it certiﬁes stability or termination of a system or allows to
construct invariant sets, which in turn may be used to certify safety and security.
In this paper, we propose an improvement to the decomposing technique, which relaxes the graph
structure before applying the decomposition technique. Our relaxation signiﬁcantly reduces the con-
nectivity of the graph by exploiting super-dense switching. The relaxation makes the decomposition
technique more efﬁcient on one hand and on the other allows to decompose a wider range of graph
structures.

Keywords: Hybrid Systems, Automatic Veriﬁcation, Stability, Lyapunov Theory, Graphs, Relaxation

1

Introduction

In this paper, we present a relaxation technique for hybrid systems exhibiting dense graph structures.
It improves the (de-)compositional technique proposed by Oehlerking and Theel in [10]. The relax-
ation results in hybrid systems that are well suited for (de-)composition. This increases the likeliness of
successfully identifying Lyapunov functions.

Throughout the paper, in order to ease readability we will simply write “decomposition” or “decompo-

sitional technique” instead of “(de-)composition” or “(de-)compositional technique”.

Stability, in general and for hybrid systems in particular, is a very desirable property, since stable sys-
tems are inherently fault-tolerant: after the occurrence of faults leading to, for example, a changed en-
vironment, the system will automatically “drive back” to the set of desired (i.e., stable) states. Stable
systems are therefore particularly suited for contexts where autonomy is important such as for depend-
able assistance systems or in contexts where security has to be assured in an adverse environment.

Modeling such real world systems often involves the interaction of embedded systems (e.g., a con-
troller) and its surrounding environment (e.g., a plant). Examples of such systems are automatic cruise

∗This work has been partly supported by the German Research Foundation (DFG) as part of the Transregional Collaborative

Research Center “Automatic Veriﬁcation and Analysis of Complex Systems” (SFB/TR 14 AVACS).

J. Pang, Y. Liu, and S. Mauw (Eds.): 4th International Workshop
on Engineering Safety and Security Systems 2015 (ESSS’15)
EPTCS 184, 2015, pp. 49–63, doi:10.4204/EPTCS.184.4

c(cid:13) E. M¨ohlmann & O. Theel
This work is licensed under the Creative Commons
Attribution-Noncommercial-No Derivative Works License.

50

Breaking DenseStructures

controllers, engine control units, or unmanned powerhouses. In all these examples, an optimal operating
range should be maintained. Although it is sometimes possible to discretize physical relations (using
sampling) or to ﬂuidize discrete steps (having a real-valued count of objects) it is more natural and less
error-prone to use hybrid systems for modeling and veriﬁcation. This is due to the fact that hybrid
systems allow both: the representation of discrete and continuous behavior.

For hybrid systems with a complex discrete behavior, the technique proposed in [10] decomposes the
monolithic problem of proving stability into multiple subproblems. But if a hybrid system exhibiting a
complex control structure – in the sense of a dense graph structure – is decomposed, then the blow-up
can be enormous. The result is a high number of subproblems that must be solved – this is not bad per
se. But since the decompositional technique requires to underapproximate the feasible sets of each sub-
problem – when applied to often – results in the feasible set becoming empty. The relaxation technique
presented in this paper reduces the number of steps required by the decomposition and, therefore, the
number of underapproximations. This has two beneﬁts: the runtime is reduced as well as the effect of
underapproximations is minimized.

This paper is organized as follows. Section 2 gives a brief overview on related work. In Section 3,
we deﬁne the hybrid system model, the stability property, an adaptation of the Lyapunov Theorem, and
brieﬂy sketch the idea of the decompositional proof technique. Section 4 describes our improvement
to that proof scheme. In Section 5, we apply the relaxation to prove stability of three examples. The
ﬁrst example is the automatic cruise controller which is the motivating example for the decompositional
technique. The second example is abstract and shows what happens if decomposition is applied to
complete graph structures. The last example is a spidercam that exhibits a dense graph structure for which
proving stability using decomposition is not possible. Finally, in Section 6, we give a short summary.

2 Related Work

In contrast to safety properties, stability has not yet received that much attention wrt. automatic proving
and therefore, only a few tools are available. Indeed only the following automatic tools – each special-
ized for speciﬁc system classes – are known to the authors. Podelski and Wagner presented a tool in
[12] which computes a sequence of snapshots and then tries to relate the snapshots in decreasing se-
quence. If successful, then this certiﬁes region stability, i.e., stability with respect to a region instead
of a single equilibrium point. Oehlerking et al. [9] implemented a powerful state space partitioning
scheme to ﬁnd Lyapunov functions for linear hybrid systems. The RSOLVER by Ratschan and She [18]
computes Lyapunov-like functions for continuous system. Duggirala and Mitra [3] combined Lyapunov
functions with searching for a well-foundedness relation for symmetric linear hybrid systems. Prabhakar
and Garc´ıa [16] presented a technique for proving stability of hybrid systems with constant derivatives.
Finally, some MATLAB toolboxes (YALMIP [5], SOSTOOLS [11]) that require a by-hand generation of
constraint systems for the search of Lyapunov functions are available. These toolboxes do not automati-
cally prove stability but assist in handling solvers.

Related theoretical works are the decompositional technique by Oehlerking and Theel [10], which
we aim to improve, and the work on pre-orders for reasoning about stability in a series of papers by
Prabhakar et al. [14, 13, 15] whose aim is a precise characterization of soundness of abstractions for
stability properties. In contrast, our vision is an automatic computational engine for obtaining Lyapunov
functions. The technique and tool presented in [16] is also based on abstractions. Unfortunately, their
technique is restricted to hybrid systems whose differential equations have constant right hand sides

E.M¨ohlmann &O.Theel

51

while our technique is more general. However, the techniques are not even mutually exclusive and have
the potential to be combined.

3 Preliminaries

In this section, we give the deﬁnitions of the hybrid system model, global asymptotic stability, and
discontinuous Lyapunov functions. Furthermore, we sketch the decomposition technique of [10].
Deﬁnition 1. A Hybrid Automaton H is a tuple (V,M, T , Flow, Inv) where

• V is a ﬁnite set of variables and S = R|V| is the corresponding continuous state space,
• M is a ﬁnite set of modes,
• T is a ﬁnite set of transitions (m1, G, U, m2) where

– m1, m2 ∈ M are the source and target mode of the transition, respectively,
– G ⊆ S is a guard which restricts the valuations of the variables for which this transition can

be taken,

– U : S → S is the update function which might update some valuations of the variables,
• Flow : M → [S → P(S)] is the ﬂow function which assigns a ﬂow to every mode. A ﬂow f ⊆
S → P(S) in turn assigns a closed subset of S to each x ∈ S, which can be seen as the right hand
side of a differential inclusion ˙x ∈ f (x),

• Inv : M → P(S) is the invariant function which assigns a closed subset of the continuous state
space to each mode m ∈ M, and therefore restricts valuations of the variables for which this mode
can be active.

A trajectory of H is an inﬁnite solution in form of a function t (t) = (x(t), m(t)) over time t where x(·)
describes the evolution of the continuous variables and m(·) the corresponding evolution of the modes.1
Roughly speaking, stability is a property basically expressing that all trajectories of the system eventu-
ally reach an equilibrium point of the sub-state space and stay in that point forever given the absence of
errors. For technical reasons the equilibrium point is usually assumed to be the origin of the continuous
state space, i. e. 0. This is not a restriction, since a system can always be shifted such that the equilibrium
is 0 via a coordinate transformation. In the sequel, we focus on asymptotic stability which does not re-
quire the equilibrium point to be reached in ﬁnite time but only requires every trajectory to “continuously
approach” it (in contrast to exponential stability where additionally the existence of an exponential rate
of convergence is required).
In the following, we refer to x↓V ′ ∈ R|V ′| as the sub-vector of a vector x ∈ RV containing only values of
variables in V ′ ⊆ V.
Deﬁnition 2 (Global Asymptotic Stability with Respect to a Subset of Variables [8]). Let H = (V,M, T ,
Flow, Inv) be a hybrid automaton, and let V ′ ⊆ V be the set of variables that are required to converge
to the equilibrium point 0. A continuous-time dynamic system H is called Lyapunov stable (LS) with
respect to V ′ if for all functions x↓V ′(·),

∀e > 0 : ∃d > 0 : ∀t ≥ 0 : ||x(0)|| < d ⇒

x↓V ′(t)

< e .

H is called globally attractive (GA) with respect to V ′ if for all functions x↓V ′(·),
< e ,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
x↓V ′(t) = 0, i. e.,∀e > 0 : ∃t0 ≥ 0 : ∀t >t0 :

(cid:12)
(cid:12)
(cid:12)
(cid:12)
x↓V ′(t)

lim
t→¥

1 Note, that deﬁnition of trajectories given here is for real time, i. e., t ∈ R≥0 while solutions of the relaxed hybrid automaton
in Section 4 require a corresponding deﬁnition of trajectories for dense time, i. e., t ∈ N × R≥0. However, as there is only little
difference in our setting and we do not directly reason about the solutions of the relaxation, we omit corresponding deﬁnitions.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

52

Breaking DenseStructures

where 0 is the origin of R|V ′|. If a system is both globally stable with respect to V ′ and globally attractive
with respect to V ′, then it is called globally asymptotically stable (GAS) with respect to V ′.
Intuitively, LS is a boundedness condition, i. e., each trajectory starting d -close to the origin will remain
e -close to the origin. GA ensures progress, i. e., for each e -distance to the origin, there exists a point
in time t0 such that afterwards a trajectory always remains within this distance. It follows, that each
trajectory is eventually always approaching the origin. This property can be proven using Lyapunov
Theory [6]. Lyapunov Theory was originally restricted to continuous systems but has been lifted to
hybrid systems.

Theorem 1 (Discontinuous Lyapunov Functions for a subset of variables [8]). Let H = (V,M, T , Flow,
Inv) be a hybrid automaton and let V ′ ⊆ V be the set of variables that are required to converge. If for
each m ∈ M, there exists a set of variables Vm with V ′ ⊆ Vm ⊆ V and a continuously differentiable
function Vm : S → R such that

1. for each m ∈ M, there exist two class K¥

functions a and b such that

∀x ∈ Inv(m) : a

x↓Vm

≤ Vm(x) ≤ b

x↓Vm

,

2. for each m ∈ M, there exists a class K¥

(cid:0)(cid:12)
(cid:12)
function g such that
(cid:12)
(cid:12)

(cid:12)
(cid:1)
(cid:12)

(cid:12)
(cid:12)

(cid:0)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:1)
(cid:12)
(cid:12)

for each ˙Vm(x) ∈

dVm(x)
dx

3. for each (m1, G, U, m2) ∈ T ,
(cid:12)
(cid:12)
(cid:12)

nD

∀x ∈ Inv(m) : ˙Vm(x) ≤ −g

x↓Vm

f (x)

f (x) ∈ Flow(m)

,

(cid:0)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

E (cid:12)
(cid:12)
∀x ∈ G : Vm2 (U(x)) ≤ Vm1 (x),
(cid:12)

o

then H is globally asymptotically stable with respect to V ′ and Vm is called a local Lyapunov function
(LLF) of m.

dV(x)
dx

denotes the inner product between the gradient of a Lyapunov function V
In Theorem 1,
and a ﬂow function f (x). Throughout the paper we denote by mode constraints the constraints of Type 1
and Type 2 and by transition constraints the constraints of Type 3.

f (x)

D

E

(cid:12)
(cid:12)
(cid:12)

Decompositional Construction of Lyapunov Functions

In this section we brieﬂy introduce the decompositional construction of Lyapunov functions for self-
containment and refer to [10] for the details.

The decomposition technique introduces a so-called constraint graph. In the constraint graph, vertices
are labeled with mode constraints and transition constraints for self-loops, i. e., m1 = m2 while edges
are labeled with transition constraints for non-self-loops, i. e., m1 6= m2. Obviously, any solution to the
constraint graph is a solution to Theorem 1. The graph structure is exploited in two ways:

1) The constraint graph is partitioned into ﬁnitely many strongly connected components (SCCs). A
trajectory entering an SCC of the corresponding hybrid automaton may either converge to 0 within
the SCC or leave the SCC in ﬁnite time. In any case, once entered, an SCC might not be entered
again. This allows us to compute LLFs for each SCC separately.

2) Each SCC is further partitioned into (overlapping) cycles. LLFs for modes in a cycle can also be
computed separately but compatibility – wrt. constraints on the edges – has to be assured somehow.
Compatibility can be guaranteed if the cycles are examined successively in the following way: A cycle

E.M¨ohlmann &O.Theel

53

a

b*

c

e

d

a

b*

c

e

e

d

d

a

b

c

(a) Selection of a Cycle

(b) After a Reduction Step

(c) Selection of a Mode to Split

a

a

a

a

a

a

d

b*

c

e

d

b*

c

e

d

b,c,a,e

b*

e

(d) After a Mode-splitting step

(e) Selection of a Cycle

(f) After a Reduction Step

c

Figure 1: A Sketch of the Decomposition

is selected and replaced by an underapproximation of the feasible set of its constraints, i. e., ﬁnitely
many solutions (candidate LLFs) to the constraints of that cycle. Since the constraints describe a
convex problem, conical combinations of the candidate LLFs satisfy the constraints, too. This step is
called a reduction step. The reduction step collapses all vertices that lie only on that cycle and replaces
references to LLFs in the constraints of adjacent edges by conical combinations of the candidate
LLFs. This allows us to prove stability of each cycle separately while, cycle-by-cycle, ensuring
compatibility of the feasible sets of the (overlapping) cycles.
The reduction step is visualized in Figure 1a and Figure 1b: In the former, a cycle is selected and in
the latter, the cycle is replaced by a ﬁnite set of solutions of the corresponding optimization problem
– visualized by collapsing the cycle into a single vertex.

The reduction step is more efﬁcient if the cycle is connected to the rest of the graph by at most one
vertex. We call such a cycle an outer cycle and the vertex a border vertex. On one hand, if the graph
contains an outer cycle, then the cycle can be collapsed into a single vertex which replaces the border
vertex. Thus, the feasible set of the cycle’s constraints is replaced by a set of candidate LLFs. On the
other hand, if the graph does not contain an outer cycle, then another step, called a mode-splitting step,
is performed. In the mode-splitting step, a single vertex is replaced by a copy per pair of incoming and
outgoing edges. This is visualized Figure 2. In Figure 2a, vertex 1 is connected to four other vertices by

2

c

3

d

2

c

c

d

3

d

1

1

1

1

1

a

b

4
5
(a) Before splitting

a

a

4

b

b

5

(b) After splitting

Figure 2: The Mode-Splitting Step

54

Breaking DenseStructures

two incoming and two outgoing edges. In Figure 2b, vertex 1 is replaced by four copies, where each one
is connected to exactly one incoming and one outgoing edge. Depending on the order in which vertices
are chosen for mode-splitting, one can make a cycle connected to the rest of the graph by exactly one
vertex and then perform a reduction step. Clearly, the order of mode-splitting and reduction steps does
not only affect the termination of the procedure, but also the size of the graph and, therefore, the number
of cycles that have to be reduced. With a good order of reduction and mode-splitting steps, one ends up
with a single cycle for which the following holds: The successful computation of candidate LLFs implies
the existence of a piecewise Lyapunov function for the whole SCC.

Continuing on the example given in Figure 1: In Figure 1c, there are no outer cycles, thus, a mode-
splitting step is performed: the vertex a is selected, copied twice, and each path is routed through one
copy. The result is shown in Figure 1d. Since the result contains outer cycles, we can select an outer
cycle as in Figure 1e and perform another reduction step resulting a single cycle being left. Figure 1f
shows the result.

Automatically Computing Lyapunov Functions

To compute Lyapunov functions needed for decomposition as well as for the monolithic approaches each
Lyapunov function is instantiated by a template involving free parameters. Using this Lyapunov function
templates a constraint system corresponding to Theorem 1 is generated. Such a constraint system is
then relaxed by a series of relaxations involving 1. the so-called S-Procedure [2] which restricts the
constraints to certain regions and 2. the sums-of-squares (SOS) decomposition [17] which allows us
to rewrite the polynomials as linear matrix inequalities (LMI). These LMIs in turn can be solved by
Semideﬁnite Programming (SDP) [2]. Instances of solvers are CSDP [1] and SDPA [4]. These solvers
typically use some kind of interior point methods and numerically approximate a solution. While this is
very fast, such numerical solvers sometimes suffer from numerical inaccuracies. Therefore, constraints
may be strengthened by adding additional “gaps”. These gaps make the constraints more robust against
numerical issues but sometimes result in the feasible set becoming empty.

These the gaps further limit the use of the decomposition as each reduction now “doubly” shrinks the

feasible set: via gaps and via computing ﬁnitely many candidate LLFs.

4 Relaxation of the Graph Structure

In this section, we show how the decomposition can be improved by our graph structure-based relaxation.
Consider the underlying digraph G = (V, E) of a hybrid automaton with the set of vertices V = M and the
set of edges E = {(m1, m2) | ∃(m1, G, U, m2) ∈ T }. Note that the underlying graph has at most a single
edge between any two vertices while the hybrid automaton might have multiple transitions between two
modes. The density of the graph G is the fraction of the number of edges in the graph and the maximum
possible number of edges in a graph of the same size, i. e.,

|E|
|V|(|V|−1) .2

The idea is to identify a set of modes of a hybrid automaton whose graph structure is dense. This can,
for example, be done by a clique-ﬁnding or dense-subgraph-ﬁnding algorithm. A clique is a complete
subgraph, i. e., having a density of 1.3 Our relaxation then rewires the transitions such that the resulting

2We are referring to the deﬁnition of density for directed graphs.
3Finding the maximum clique is NP-hard. However, a maximum clique is not required, any maximal clique (with more than
two vertices) is sufﬁcient. Even better as we are interested in dense structures only, we can use quasi cliques. A quasi clique is
a subgraph where the density is not less than a certain threshold. Thus, any greedy algorithm can be used.

E.M¨ohlmann &O.Theel

55

automaton immediately exhibits a structure well-suited for decomposition. By “well-suited,” we mean
that the graph structure contains mainly outer cycles.

The reason, that our relaxation technique plays so well with the decomposition technique, is as follows:
if a hybrid system exhibits a dense graph structure, then the decomposition results in a huge blow-up.
This blow-up is a result of the splitting step. The splitting step separates vertices shared between cycles,
i. e., if there is more than one vertex shared between two or more cycles, then multiple copies are created.
Thus, the higher the density of the graph structure is, the higher the blow-up gets. Further, if many cycles
share many vertices – as in dense graphs – then whole cycles get copied and each copy requires solving
an optimization problem and underapproximating the problem’s feasible set. In contrast, our relaxation
overapproximates the discrete behavior by putting each vertex in its own cycle and connecting this vertex
by a new “fake” vertex. This reduces the number of optimization problems to be solved and the number
of feasible sets to be underapproximated.

In the following, we deﬁne the relaxation operator. Then we give an algorithm which applies the
relaxation integrated with decomposition. Finally, we prove termination and implication of stability of
the hybrid automaton which has been relaxed.
Deﬁnition 3. The graph structure relaxed hybrid automaton Rlx(H,Md) = (V ♯,M♯, T ♯, Flow♯, Inv♯) =
H♯ of a hybrid automaton H = (V,M, T , Flow, Inv) wrt. the sub-component Md ⊆ M is deﬁned as
follows

V ♯ = V,
M♯ = M ·∪ {mc},

T ♯ =

(m1, G, U, m2)

(cid:26)

(m1, G, U, m2) ∈ T ,
{m1, m2} ∩ Md = /0

(m1, G, id, mc),
(mc, G, U, m2)

(m1, G, U, m2) ∈ T ,
{m1, m2} ∩ Md 6= /0

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:27)

,
(cid:27)

Flow♯(m) =

[(cid:26)

zero
Flow(m)

(

(cid:12)
(cid:12)
(cid:12)
(cid:12)

if m = mc
otherwise,

Inv♯(m) =

/0
Inv(m)

(

if m = mc
otherwise,

where zero : S → P(S) is a function assigning 0 to each x ∈ S, i. e., ˙x ∈ {0}.
In T ♯ in Deﬁnition 3, we replace each transition (m1, G, U, m2) ∈ T connected to at least one mode in
Md with two transitions: one connecting the old source mode m1 with the new mode mc and the other
connecting mc with the old target mode m2. We call this step a transition-splitting step where the result
is a pair of transitions which is called split transition and the set of all split transitions is denoted by ST.
Intuitively, the introduced mode mc is a dummy mode whose invariant always evaluates to false and the
ﬂow function does not change the valuations of the continuous variables. Indeed, the mode cannot be
entered and thus, a trajectory taking an ingoing transition must, immediately, take an outgoing transition.
The sole reason to add the mode is changing the structure of the hybrid system’s underlying graph: the
new structure contains mainly cycles that are connected via mc.
Next, we show how to integrate decomposition and relaxation. Pseudo-code of the relaxation function
and a reconstruction function – which step-by-step reverts the relaxation – can be found in Algorithm 1
and Algorithm 2, respectively. Algorithm 3 gives pseudo-code of the main algorithm. The main al-

56

Breaking DenseStructures

Algorithm 1: The Relaxation Function

input : A hybrid automaton H, a dense sub-component Md of H.
output: The relaxed version of H, a set of split transitions ST, the central mode mc.

1 mc ← newMode();
2 H.M ← H.M ∪ {mc};
3 H.Flow(mc) ← zero;
4 H.Inv(mc) ← /0;
5 T ← H.T ;
6 foreach t = (m1, G, U, m2) ∈ T do
if {m1, m2} ∩ Md 6= /0 then
7

8

9

10

11

// split the transitions into two parts
t1 ← (m1, G, id, mc);
t2 ← (mc, G, U, m2);
// replace the transition by the two parts
H.T ← (H.T \ {t}) ∪ {t1,t2};
// keep account of split transitions
ST ← ST ∪ {(t1,t2)}

gorithm works as follows: Step 1) The function relax relaxes the graph structure of the hybrid au-
tomaton H and generates the set of split transitions ST. Step 2) If the set ST is empty, then call
applyDecomposition with the original automaton and return the result – this function applies the origi-
nal decompositition technique as described in Section 3. Step 3) Otherwise, apply applyDecomposition
on the current relaxed form of the automaton. If the result is stable, then return the result. Otherwise,
if the original decompositional technique has failed, then it returns a failed subgraph that is a subgraph
for which it was unable to ﬁnd Lyapunov functions. Step 4) Choose a split transition from the set ST
which also belongs to the failed subgraph. It is then used to reconstruct a transition from the original
hybrid automaton. Then execution is continued with step 2. Step 5) If no such split transition exists,
then the algorithm fails and returns the failed subgraph since this failing subgraph will persist in the
automaton. Further reverting the relaxation cannot help because no split transition is contained in the
failed subgraph.

Next, we prove termination and soundness of the algorithm. Here, soundness indicates that a Lyapunov
function-based stability certiﬁcate for a relaxed automaton implies stability of the original, unmodiﬁed
automaton. In particular, the local Lyapunov functions of the relaxed hybrid automaton are valid local
Lyapunov functions for the original automaton.

Termination of the Integrated Algorithm

Theorem 2. The proposed algorithm presented in Algorithm 3 terminates.

Proof. The function relax terminates since the copy of the set of transitions of H is ﬁnite and is not
modiﬁed in the course of the algorithm. The while-loop terminates if either an applyDecomposition
is successful, no pair for reconstruction can be identiﬁed, or the set ST is empty. In the ﬁrst two cases,
the algorithm terminates directly. For the last case, we assume that no call to applyDecomposition is
successful and a spilt transition is always found. Then, in each iteration of the loop, one edge is removed

E.M¨ohlmann &O.Theel

57

Algorithm 2: The Reconstruction Function

input : A relaxed hybrid automaton H, a set of split transitions ST, a pair of split transitions

(t1,t2), where t1 = (m1, G, id, mc), t2 = (mc, G, U, m2) and mc is the central mode.

output: A relaxed hybrid automaton H with one split transition being reconstructed, the set of

split transitions ST

// reconstruct the original transition

1 t ← (m1, G, U, m2);

// replace the split transition (t1,t2) by t

2 H.T ← (H.T \ {t1,t2}) ∪ {t};

// update the set of split transitions

3 ST ← ST \ {(t1,t2)};

// remove mc iff unconnected

4 if ST = /0 then
5

H.M ← H.M \ {mc};

from ST. The set ST is ﬁnite because the relaxation function relax splits only ﬁnitely many edges.
Thus, the set ST becomes eventually empty. Therefore, the loop terminates.

Preservation of Stability

Theorem 3. For any hybrid automaton H and a sub-component Md, it holds: If a family of local Lya-
punov functions (Vm) proving Rlx(H,Md) to be GAS exists, then there exists a family of local Lyapunov
functions for H proving H to be GAS.

Proof. Given a hybrid automaton H = (V,M, T , Flow, Inv). Let Rlx(H,Md) = (V ♯,M♯, T ♯, Flow♯, Inv♯)
= H♯, be a graph structure-relaxed version of H where Md ⊆ M is the sub-component of H that has
been relaxed. Further, let (Vm) be the family of local Lyapunov functions that prove stability of H♯ and
let ST be the set of split transitions – some transition may have been reconstructed. Now, it must be
shown that Vm are valid Lyapunov functions for H.
The mode constraints of Theorem 1 trivially hold, since Rlx alters neither the ﬂow functions nor the in-
variants, i. e., ∀m ∈ M : Flow♯(m) = Flow(m) ∧ Inv♯(m) = Inv(m). The transition constraint also holds
for all transitions that are not altered by Rlx or have been reconstructed, i. e., T ∩ T ♯. Now assume that
t ∈ T \ T ♯ is an arbitrary transition for which the transition constraint does not hold. We show that this
leads to a contradiction. Due to the deﬁnition of Rlx all transition in T \ T ♯ are split transitions and there
is a corresponding pair in ST. Let (t1,t2) ∈ ST be the pair corresponding to t = (m1, G, U, m2). Since
(Vm) is a valid family of local Lyapunov function for H♯, the transition constraint holds for all transitions
in T ♯. In particular, the transition constraint holds for t1 = (m1, G, id, mc) and t2 = (mc, G, U, m2). Thus,

∀x ∈ G : Vmc(id(x)) ≤ Vm1(x) ∧ ∀x ∈ G : Vm2 (U(x)) ≤ Vmc(x).

It follows, that

Therefore, the transition constraint holds for t. But this contradicts the assumption.  

∀x ∈ G : Vm2 (U(x)) ≤ Vmc(x) ≤ Vm1(x).

While Theorem 3 shows that stability of the relaxed automaton yields stability of the original automaton,
the contrary is not true. Figure 3 shows a hybrid system where the relaxation renders the system unstable.

58

Breaking DenseStructures

Algorithm 3: The Integrated Relaxation and Decomposition Algorithm

input : A hybrid automaton H, a set of modes Md corresponding to a dense subgraph.
output: stable if the H is stable and failed otherwise.
// relax the graph structure

1 H, ST, mc ← relax(H,Md);
2 while ST 6= /0 do

// apply decomposition
result ← applyDecomposition(H);
if result is stable then
return stable;

// apply reconstruction
if ∃(t1,t2) ∈ ST : {t1,t2} ∩ failedSubgraph(result) 6= /0 then

H, ST ← reconstruct(H, ST, (t1,t2), mc);

else

return result;

3

4

5

6

7

8

9

// apply decomposition on the original automaton

10 result ← applyDecomposition(H);
11 return result;

This example exploits that the relaxation may introduce spurious trajectories. This happens if there are
transitions with overlapping guard sets connected to the central mode mc. A trajectory of the relaxed
automaton might then take the ﬁrst part of a split transition to the central mode mc and continues with
the second part of a different split transition. A transition corresponding to this behavior might not exist
in the unmodiﬁed hybrid automaton. While this does not render our approach being incorrect, it may
lead to difﬁculties since these extra trajectories have to be GAS, too. In case of the system in Figure 3,
new trajectories are introduced which allow a trajectory to jump back from the mode L to H by taking the
transitions t1,t2. This behavior corresponds to leaving L by the right self-loop and entering H by the left
self-loop, which is obviously impossible. However, due to the update the value of x might increase as
1 + 0.01(x − 1)(x − 10) > 1 for x < 1.

In general our relaxation introduces conservatism which is again reduced step-by-step by the recon-
struction. The degree of conservatism highly depends on the guards of the transitions since the central
mode relates all LLFs of modes in Md. Therefore, if more guards are overlapping, more LLFs have to
be compatible even if not needed in the original automaton.

One possibility to counter-act this issue is to introduce a new continuous variable in the relaxed au-
tomaton which is set to a unique value per split transition: the update function of the ﬁrst part of a split
transition sets the value used to guard the second part of the transition. Indeed, this trick discards any
spurious trajectories for the price of an additional continuous variable. However, since the values of that
variable are somewhat artiﬁcial, a Lyapunov function may not make use of that variable. Thus, this trick
will not ease satisfying the conditions of the Lyapunov theorem in general.

E.M¨ohlmann &O.Theel

59

true/x := 0.9x

true/x := 0.9x

H

˙x = −0.2x

1 ≤ x ≤ 10

x ≤ 1

x ≥ 1

L

˙x = −0.1x

0 ≤ x ≤ 1

true/x := 1 + 0.01(x − 1)(x − 10)

(a) The unmodiﬁed (stable) version.

H

true

˙x = −0.2x

1 ≤ x ≤ 10

x ≥ 1
t2

C

˙x = 0

false

x ≤ 1

t1
true

L

˙x = −0.1x

0 ≤ x ≤ 1

true/x := 1 + 0.01(x − 1)(x − 10)

(b) The relaxed (unstable) version.

Figure 3: A Hybrid System; Unstable after Relaxation

Graph Structure

Nodes (n)

Edges

Reductions

directed K1
directed K2
directed K3
directed K4
directed K5
Spidercam
Cruise Controller

1
2
3
4
5
9
6

0
2
6
12
20
32
11

0
1
6
47
1852
753
7

Decomposition
Mode-
Splittings
0
0
4
25
352
287
6

With Relaxation

Time

Reductions

0.04s
0.04s
0.21s
1.15s
13h22m
1h46m
0.060s

0
2
3
4
5
9
6

Time

0.04s
0.04s
0.05s
0.05s
0.05s
0.06s
0.06s

Table 1: Comparison of the Decomposition with and without Relaxation

5 Application of the Relaxation

In this section we present three examples where the graph structure-based relaxation suggested in this
paper improves the application of the decomposition technique. The ﬁrst example deals with the auto-
matic cruise controller (ACC) of [8]. The second example is the fully connected digraph K3. The K3 does
not represent a concrete hybrid automaton but a potential graph structure of a hybrid automaton. The last
example is a spidercam. Here, the graph is not as fully connected as the K3 example, but its density is
already too high to apply decomposition directly.

We have implemented the decomposition and relaxation in python. Table 1 gives the graph properties
and a comparison of the number of reduction steps required by the decomposition with and without re-
laxation (in the best case). The given data was obtained without actually computing Lyapunov functions
focusing on the graph related part of the decomposition. In fact, computing Lyapunov functions for the
spidercam via decomposition without our relaxation fails after 18 steps.

Example 1: The Automatic Cruise Controller (ACC)

The automatic cruise controller (ACC) regulates the velocity of a vehicle. Figure 5 shows the controller
as an automaton. The task of the controller is to approach a user-chosen velocity – indeed the variable v
represents the velocity relative to the desired velocity.

The ACC is globally asymptotically stable. It can be proven stable using the original decomposition
technique (cf. [8, 7]). Indeed, the graph structure is sparse and thus, already well-suited for applying
the decomposition technique directly. In fact, only one more cycle needs to be reduced compared to
decomposition after relaxation (cf. Table 1). Even though the relaxation is not needed here, it also does
not harm, though, it may be used for sparse graphs structures, too.

60

Breaking DenseStructures

1

3

2

(a) original

1

3

2

(b) relaxed

Figure 4: The K3.

Emergency Brake Act
˙v = −t − 2.5
˙x = 0
˙t = 1
15 ≤ v ≤ 40
0 ≤ t ≤ 2.5

t = 2.5∧
15 ≤ v ≤ 40

15 ≤ v ≤ 16∧
0 ≤ t ≤ 2.5∧
t := 0

Emergency Brake Full
˙v = −5
˙x = 0
˙t = 0
15 ≤ v ≤ 40
t = 2.5

18 ≤ v ≤ 20∧
0 ≤ t ≤ 1.3∧
t := 0

15 ≤ v ≤ 16∧
0 ≤ t ≤ 2.5∧
t := 0

18 ≤ v ≤ 20∧
t = 1.3∧
t := 0

Brake Act
˙v = −t − 1.2
˙x = 0
˙t = 0.5
5 ≤ v ≤ 20
0 ≤ t ≤ 1.3

13 ≤ v ≤ 15∧
−500 ≤ x ≤ 500∧
t := 0

5 ≤ v ≤ 11∧
0 ≤ t ≤ 1.3∧
x := 0

Normal
˙v = −0.001x − 0.052v
˙x = v
˙t = 0
−15 ≤ v ≤ 15
−500 ≤ x ≤ 500

t = 1.3∧
5 ≤ v ≤ 20

5 ≤ v ≤ 11∧
t = 1.3∧
x := 0

Brake Full
˙v = −2.5
˙x = 0
˙t = 0
5 ≤ v ≤ 20
t = 1.3

−15 ≤ v ≤ −14∧
−500 ≤ x ≤ 500

−6 ≤ v ≤ −5∧
−500 ≤ x ≤ 500∧
x := 0

Accelerate
˙v = 1.5
˙x = 0
˙t = 0
−20 ≤ v ≤ −5

Figure 5: The Automatic Cruise Controller [8]

Example 2: The directed K3

The directed Kn is a fully connected digraph with n nodes. The K3 as well as a relaxed version of it is
shown in Figure 4. In a fully connected digraph, there is a single edge from each node to each other
node, resulting in a total number of n(n − 1) edges. The number of cycles, the decomposition technique
has to reduce, grows very fast with n which can be seen in Table 1. In comparison, the number of cycles
in the relaxed version of the graph grows linearly with n, assuming that the edges can be concentrated4.
Otherwise, after the relaxation, each original node has n − 1 incoming and n − 1 outgoing edges where
each edge connects the node with the central node mc. Each such combination forms a cycle between mc
and an original mode, giving a total of n(n − 1)(n − 1) cycles in the worst case. This cubic growth is still
much less than the number of reductions without relaxation.

Such a graph might not be the result of a by-hand designed system but might be the outcome of a
synthesis or an automatic translation. However, the fast growth of the cycles also indicates the high
number of reduction and therefore underapproximations.

Example 3: The Spidercam

A spidercam is a movable robot equipped with a camera. It is used at sport events such as a football
matches. The robot is connected to four cables. Each cable is attached to a motor that is placed high
above the playing ﬁeld in a corner of a stadium. By winding and unwinding the cables – and thereby
controlling the length of the cables, – the spidercam is able to reach nearly any position in the three-
dimensional space above the playing ﬁeld. Figure 6 shows a very simple model of such a spidercam in
the plane. The target is to stabilize the camera at a certain position. The continuous variables x and y
denote the distance relative to the desired position on the axis induced by the cables.

4With “concentrating edges,” we mean that edges with the same source and target node are handled as a single edge for the

cycle ﬁnding algorithm.

E.M¨ohlmann &O.Theel

61

Fourth Quadrant

Positive Y

First Quadrant

x ≤ −0.5

˙x = −0.1 · x

0.5 ≤ x

˙x = 0.6

˙y = −0.6

−100 ≤ x ≤ −0.4

−0.4 ≤ x

0.4 ≤ y ≤ 100

x

≤

−

0
.
5

˙y = −0.6

−0.5 ≤ x ≤ 0.5
0.4 ≤ y ≤ 100

4
.
0
≤
y

y
≤
5
.
0

−

0
.
4

≤

x

∧

y

∧

0
.
5

≤

y

4
.
0
≤
y

y
≤
5
.
0

x

≤

0.5

≤

0
.
4

Center

˙x = −0.6

˙y = −0.6

0.4 ≤ x ≤ 100
0.4 ≤ y ≤ 100

0.4

≤

4
.
0
≤
y

y
≤
5
.
0

Positive X

x ≤ 0.4

y

≤

∧ 0.5

0.4 ∧ y

≤

x

x ≤ −0.5

˙x = −0.1 · x

0.5 ≤ x

˙x = −0.6

Fourth Quadrant

x ≤ −0.5

∨0.5 ≤ y

− 0.4 ≤ x

∨y ≤ 0.4

−0.4 ≤ x∨y ≤ −0.5

∨0.5 ≤ y

Negative X

˙x = 0.6

˙y = −0.1 · y

−100 ≤ x ≤ −0.4
−0.5 ≤ y ≤ 0.5

y
≤
4
.
0
−

5
.
0
−
≤
y

≤

x

Third Quadrant

˙x = 0.6

˙y = 0.6

−0.4 ≤ x

− 0.5

≤

∧

x

≤

− 0.5 ∧ y
− 0.4

˙y = −0.1 · y

−0.6 ≤ x ≤ 0.6
−0.6 ≤ y ≤ 0.6

x ≤ 0.4

0
.
5

≤

x

y

≤

− 0.4

y
≤
4
.
0
−

5
.
0
−
≤
y

Negative Y

x

≤

0
.
4

∧

y

≤

∧

−

0
.
5

−

0
.
4

≤

y

x ≤ −0.5

˙x = −0.1 · x

0.5 ≤ x

˙y = −0.1 · y

Negative X

0.4 ≤ x ≤ 100
−0.5 ≤ y ≤ 0.5

x ≤ −0.5∨y ≤ 0.4

∨ − 0.4 ≤ y

y
≤
4
.
0
−

5
.
0
−
≤
y

− 0.4 ≤ x

∨ − 0.4 ≤ y

Second Quadrant

Third Quadrant

˙x = −0.6

˙y = 0.6

−100 ≤ x ≤ −0.4
−100 ≤ y ≤ −0.4

−0.4 ≤ x

˙y = 0.6

−0.5 ≤ x ≤ 0.5
−100 ≤ y ≤ −0.4

x ≤ 0.4

0.4 ≤ x ≤ 100

−100 ≤ y ≤ −0.4

(a) unmodiﬁed

Positive Y

First Quadrant

− 0.4 ≤ x

∨x ≤ 0.4

∨0.5 ≤ y

0.5 ≤ x
∨x ≤ −0.5

∨y ≤ 0.4

0.5 ≤ x

∨0.5 ≤ y

x ≤ 0.4

∨y ≤ 0.4

C

˙x = 0
˙y = 0

false

−0.4 ≤ x∨x ≤ 0.4

∨y ≤ 0.4∨ − 0.4 ≤ y

Center

0.5 ≤ x∨x ≤ −0.5

∨y ≤ −0.5∨0.5 ≤ y

0.5 ≤ x∨y ≤ 0.4

∨ − 0.4 ≤ y

Positive X

x ≤ 0.4

∨y ≤ −0.5 ∨ 0.5 ≤ y

x ≤ −0.5

∨y ≤ −0.5

0.5 ≤ x
∨x ≤ −0.5

− 0.4 ≤ x

∨x ≤ 0.4

∨ − 0.4 ≤ y

∨y ≤ −0.5

x ≤ 0.4

∨ − 0.4 ≤ y

0.5 ≤ x

∨y ≤ −0.5

Negative Y

Second Quadrant

(b) relaxed

Figure 6: The Simple Planar Spidercam

In the model, we assume a high-level control of the motor engines, i. e., the movement is on axis ˙x
and ˙y instead of a low-level control of each individual motor. The model has nine modes: one mode
that controls the behavior while being close to the desired position, four modes corresponding to nearly
straight movements along one of the axes and four modes cover the quadrants between the axes. The
maximal velocity in the direction of each axis is limited from above by 0.6 m
s . Thus, in the four modes
corresponding to the quadrants, the movement in each direction is at full speed.
In the four modes
corresponding to the axes, the movement on the particular axis is at full speed while the movement
orthogonal to the axis is proportional to the distance. In the last mode, the speed in both directions is
proportional to the distance.

The spidercam is globally asymptotically stable which can be proven fully automatically. However,
it is not possible to obtain a piecewise Lyapunov function via decomposition without relaxation due
to accumulating underapproximations of the partial solutions and the high number of cycles that have
to be reduced.5 The reason is that each time a cycle is reduced, the feasible set of a subproblem is
underapproximated by a ﬁnite set of solutions which ﬁnally results in a feasible set becoming empty and
no LLFs can be found.

In contrast, relaxing the graph structure followed by applying the decomposition is successful immedi-

ately. In particular, no reconstruction step is required.

6 Summary

We have presented a relaxation technique based on the graph structure of a hybrid automaton. The re-
laxation exploits super-dense switching or cascaded transitions to modify the transitions of the hybrid
automaton in a way that improves the decompositional proof technique of [10]. The idea is to re-route

5We used the implementation in STABHYLI [7] which currently does not contain strategies to handle the situation where no
reduction is possible. The current implementation would then simply fail. Even though, it is theoretically possible to perform
some form of backtracking, it is hard to decide which underapproximation must be reﬁned.

62

Breaking DenseStructures

every transition through a new “fake” node. Thus, if in the original automaton a single transition is
taken, then the relaxed automaton has to take the cascade of two transitions to achieve the same result.
However, the relaxed automaton’s graph structure is better suited towards decomposition. Furthermore,
the procedure can be automated which is very much desired as our focus is the automation of Lyapunov
function-based stability proofs. Furthermore, in Section 5, we successfully employed the proposed tech-
nique in some examples.

The decompositional proof technique is particularly well-suited to prove stability of large-scale hybrid
systems because it allows: 1. to decompose a monolithic proof into several smaller subproofs, 2. to reuse
subproofs after modifying the hybrid system, and 3. to identify critical parts of the hybrid automaton.
All these beneﬁts are not available when the hybrid system exhibits a very dense graph structure of
the automaton because that would lead to an enormous number of computational steps required in the
decomposition. The proposed relaxation overcomes these matters in the best case. If the relaxation is
too loose, then our technique falls back to step-by-step reconstruct the original automaton. Each step
increases the effort needed for the decomposition until a proof succeeds or ultimately – in the worst
case – the original automaton gets decomposed. Future research will include a tighter coupling of the
decomposition and our relaxation approach. A ﬁrst step will be to not discard the progress made by the
decomposition but reuse the “gained knowledge”. Doing so will greatly reduce the computational effort.

References

[1] Brian Borchers (1999): CSDP, a C Library for Semideﬁnite Programming. Optim. Met. Softw. 10, pp.

613–623, doi:10.1080/10556789908805765.

[2] Stephen Boyd & Lieven Vandenberghe (2004): Convex Optimization. Cambridge University Press,

doi:10.1017/CBO9780511804441.

[3] Parasara Sridhar Duggirala & Sayan Mitra (2012): Lyapunov abstractions for inevitability of hybrid sys-
tems. In: Proceedings of the 15th International Conference on Hybrid Systems: Computation and Control
(HSCC’12), pp. 115–124, doi:10.1145/2185632.2185652.

[4] Katsuki Fujisawa, Kazuhide Nakata, Makoto Yamashita & Mituhiro Fukuda (2007): SDPA Project
Available at

JORSP 50(4), pp. 278–298.

Solving Large-Scale Semideﬁnite Programs.
:
http://ci.nii.ac.jp/naid/110006532053/en/.

[5] J. L¨ofberg (2004): YALMIP : A Toolbox for Modeling and Optimization in MATLAB.

In: Proceed-
ings of the 13th Conference on Computer-Aided Control System Design (CACSD’04), Taipei, Taiwan,
doi:10.1109/CACSD.2004.1393890.

[6] M.A. Lyapunov (1907): Probl`eme g´en´eral de la stabilit´e du movement.

In: Ann. Fac. Sci. Toulouse, 9,
Universit´e Paul Sabatier, pp. 203–474, doi:10.5802/afst.246. (Translation of a paper published in Comm.
Soc. Math. Kharkow, 1893, reprinted Ann. Math. Studies No. 17, Princeton Univ. Press, 1949).

[7] Eike M¨ohlmann & Oliver E. Theel (2013): Stabhyli: A Tool for Automatic Stability Veriﬁcation of Non-
Linear Hybrid Systems. In: Proceedingsofthe16thInternationalConferenceonHybridSystems: Computa-
tionandControl(HSCC’13), pp. 107–112, doi:10.1145/2461328.2461347.

[8] Jens Oehlerking (2011): Decomposition of Stability Proofs for Hybrid Systems. Ph.D. thesis, Carl von Ossi-

etzky University of Oldenburg, Department of Computer Science, Oldenburg, Germany.

[9] Jens Oehlerking, Henning Burchardt & Oliver E. Theel (2007): Fully Automated Stability Veriﬁcation for
Piecewise Afﬁne Systems. In: Proceedingsof the 10th internationalconferenceon Hybridsystems: compu-
tationandcontrol(HSCC’07), pp. 741–745, doi:10.1007/978-3-540-71493-4 74.

E.M¨ohlmann &O.Theel

63

[10] Jens Oehlerking & Oliver E. Theel (2009): Decompositional Construction of Lyapunov Functions for Hybrid
Systems. In: Proceedingsofthe12thInternationalConferenceonHybridSystems: ComputationandControl
(HSCC’09), pp. 276–290, doi:10.1007/978-3-642-00602-9 20.

[11] A. Papachristodoulou, J. Anderson, G. Valmorbida, S. Prajna, P. Seiler & P. A. Parrilo (2013): SOSTOOLS:
Sum of squares optimization toolbox for MATLAB. Available at http://arxiv.org/abs/1310.4716.
[12] Andreas Podelski & Silke Wagner (2007): Region Stability Proofs for Hybrid Systems. In: FormalModelling

andAnalysisofTimedSystems(FORMATS’07), pp. 320–335, doi:10.1007/978-3-540-75454-1 23.

[13] Pavithra Prabhakar (2012): Foundations for approximation based analysis of stability properties of hybrid
systems. In: Proceedingsofthe50thAnnualAllertonConferenceonCommunication,Control,andComput-
ing, pp. 1602–1609, doi:10.1109/Allerton.2012.6483412.

[14] Pavithra Prabhakar, Geir E. Dullerud & Mahesh Viswanathan (2012): Pre-orders for reasoning about sta-
bility. In: Proceedingsof the 15th InternationalConferenceon Hybrid Systems: Computation and Control
(HSCC’12), pp. 197–206, doi:10.1145/2185632.2185662.

[15] Pavithra Prabhakar, Jun Liu & Richard M. Murray (2013): Pre-orders for reasoning about stability properties
In: Proceedings of the International Conference on Embedded

with respect to input of hybrid systems.
Software(EMSOFT’13), pp. 1–10, doi:10.1109/EMSOFT.2013.6658602.

[16] Pavithra Prabhakar & Miriam Garcia Soto (2013): Abstraction Based Model-Checking of Stability of Hybrid
Systems. In: Proceedings of the 25th InternationalConference on Computer Aided Veriﬁcation (CAV’13),
pp. 280–295, doi:10.1007/978-3-642-39799-8 20.

[17] S. Prajna & A. Papachristodoulou (2003): Analysis of Switched and Hybrid Systems - Beyond Piecewise
Quadratic Methods. In: American Control Conference, 2003. Proceedings of the 2003, 4, pp. 2779–2784
vol.4, doi:10.1109/ACC.2003.1243743.

[18] Stefan Ratschan & Zhikun She (2010): Providing a Basin of Attraction to a Target Region of Polynomial
Systems by Computation of Lyapunov-Like Functions. SIAM J. Control and Optimization 48(7), pp. 4377–
4394, doi:10.1137/090749955.

