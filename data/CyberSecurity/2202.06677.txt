2
2
0
2

b
e
F
4
1

]

R
C
.
s
c
[

1
v
7
7
6
6
0
.
2
0
2
2
:
v
i
X
r
a

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Abstract. Correct-by-construction synthesis is a cornerstone of the conﬂuence of formal methods and con-
trol theory towards designing safety-critical systems. Instead of following the time-tested, albeit laborious
(re)design-verify-validate loop, correct-by-construction methodology advocates the use of continual reﬁne-
ments of formal requirements—connected by chains of formal proofs—to build a system that assures the
correctness by design. A remarkable progress has been made in scaling the scope of applicability of correct-by-
construction synthesis—with a focus on cyber-physical systems that tie discrete-event control with continuous
environment—to enlarge control systems by combining symbolic approaches with principled state-space reduc-
tion techniques. Unfortunately, in the security-critical control systems, the security properties are veriﬁed ex
post facto the design process in a way that undermines the correct-by-construction paradigm. We posit that,
to truly realize the dream of correct-by-construction synthesis for security-critical systems, security considera-
tions must take center-stage with the safety considerations. Moreover, catalyzed by the recent progress on the
opacity sub-classes of security properties and the notion of hyperproperties capable of combining security with
safety properties, we believe that the time is ripe for the research community to holistically target the challenge
of secure-by-construction synthesis. This paper details our vision by highlighting the recent progress and open
challenges that may serve as bricks for providing a solid foundation for secure-by-construction synthesis of
cyber-physical systems.

The revolution in miniaturized communication devices in the beginning of this millennium contributed towards
a revolution in the internet-of-things (IoT) and the networked systems woven around them: the cyber-physical
systems (CPS). CPS are marked by a close-knit interaction of discrete computation and continuous control
over a network and are playing critical roles in virtually every aspect of our modern experience ranging from
consumer electronics to implantable medical devices, from smart cars to smart hospitals, and from controlling
our power systems to safeguarding our nuclear rectors. These systems are clearly safety-critical as a bug in
their design could be life threatening, but given their societal implications, they are also security-critical where
a bug in their design may have the potential to jeopardize the privacy, trust, and economic interests of society
built around them.

“ We believe that the security considerations should be elevated as primary design drivers along with

safety ones to tackle the design challenge of modern CPS and call for a need to expand the correct-by-
construction paradigm of designing safety-critical systems to encompass security: we call this paradigm
secure-by-construction.

This paper synthesizes ideas from three research communities: discrete event systems (DES), control sys-
tems (CS), and formal methods (FM) to pose and study central problems supporting secure-by-construction
synthesis.

1. Introduction

Security considerations in the traditional computer science literature are often classiﬁed along the CIA
mnemonic: conﬁdentiality, integrity, and availability. The conﬁdentiality properties concern the protection
of sensitive information leakage either directly or, more importantly, via side-channels (seemingly harmless
observations of the system by malintent eavesdroppers). The umbrella-term integrity targets the establish-
ment of the trust in the authenticity of the source of the information. Finally, availability properties concern
1

 
 
 
 
 
 
2

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Services provided by average consultation, examination, and wait times

Service

Minor
assessment
(std.)
Intermediate
assessment
(std.)
General
assessment
(std.)
Psycho-
therapy
(std.)
Annual exam
(after 16th
birthday) (std.)

Other service
No service
code given

Avg.
Total
Time
(min)

Avg.
Total
Wait
(min)

Avg. Time
with
Nurse
(min)

Avg. Time
with
Physician
(min)

No.
Cases
(n)

Incom-
plete
Cases
(n)

50 (30)

33 (22)

1 (3)

16 (13)

67

55 (24)

37 (21)

2 (3)

16 (12)

400

77 (27)

31 (17)

10 (5)

36 (19)

71 (22)

35 (16)

2 (3)

34 (14)

51 (30)

26 (12)

7 (4)

18 (8)

43

11

5

13

74

11

29

1

0

2

N/A

N/A

Figure 1. Consider the dataset studied by Bestvater et al. [26], where the authors focused on the
impact of waiting times on patient’s perception of service satisfaction. This survey collected the
average time patients spend with the nurse and the physician for various services ranging from major
and minor assessments to psychotherapy. We emphasize that the dataset was carefully curated to
minimize leaking any diﬀerentially private information about the patients taking part in the survey.
On the other hand, using a simple decision-tree classiﬁer over this data, we found out that the timing
data collected is leaking private information about patients in timing side-channels. For instance, if a
patient spends less than 6 minutes with the nurse and spends close to 32 minutes with the physician
with a low waiting time, the patient is visiting the hospital for a psychotherapy session!

with the protection of the system operations from cyberattacks aimed at disrupting or interrupting the core
functionality of the system. While ensuring integrity deals with similar issues as for classical computer systems
and can beneﬁt from current best practices on encryption, the conﬁdentiality and availability concerns in CPS
get ampliﬁed due to a plethora of attack surfaces available in the form of physical system observations and
constraints ranging from the usual time and memory to temperature, acoustics, pressure, and electro-magnetic
radiation.

On the positive side, since principled approaches to CPS modeling and analysis already embrace the integration
of the encoding of physical variables and discrete control, the conﬁdentiality and availability properties can
be explicated during the design time to ensure a system that is not only functional, but also guarantees
freedom from known vulnerabilities. This is primary tenet of our stance on CPS-security: the design of
security-critical CPS must tackle both functionality and security challenges simultaneously by leveraging
correct-by-construction synthesis to include conﬁdentiality and availability.

Security-related attacks are increasingly becoming pervasive in safety-critical CPS. While most of the well-
known attacks—such as drone hacking [202], Jeep hacking [58], pacemaker and Implantable Cardioverter De-
ﬁbrillator (ICD) attacks [66, 153]—exploit unencrypted wireless communication, such attacks can be readily
guarded against by following recommended cryptographic measures without requiring any signiﬁcant mod-
iﬁcation to the control logic. On the other hand, security vulnerabilities related to information leaks via
side-channels may be impossible to mitigate without requiring a non-trivial modiﬁcation to control software,
as the side-channels are products of the interaction of the embedded control software with its physical envi-
ronment.

To provide a simple scenario of unintended information leak via timing side-channels, let us consider an
example in the setting of smart hospitals shown in Figure 1. An increasing prevalence of smart-devices and

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

3

(a)

(b)

(c)

(d)

Figure 2. The AWS DeepRacer car and its dynamics (a); The plausible deniability of the car for
secret initial region (b); The grid-world observations (c) where the red regions depict sensitive starting
locations (e.g., hospital or bank) and the green regions represent the target; Our actual platform in
the lab (d) corresponding to this grid-world.

sensors in modern hospitals makes such an attack scenario on smart hospitals viable. While at a ﬁrst glance,
this example may seem contrived, it emphasizes how seemingly innocuous observations can provide a strong
side-channel to leak private information. Furthermore, the presence of wide variety of observations (time
delays between various responses [104], temperature [76], electro-magnetic emissions [122], optical [122] and
acoustic [53], physiological [135]) in CPS expose corresponding attack surfaces to the intruder and render CPS
even more vulnerable than traditional software.

Formal-methods based approach to system design [189, 22] recommends rigorous requirement speciﬁcation
in every stage of the system development. Formal veriﬁcation [17] and controller synthesis [189, 22] are
two leading approaches to provide correctness guarantees with respect to such requirements. While formal
veriﬁcation aims at providing a proof of correctness with respect to the given speciﬁcations, the goal of the
controller synthesis approach is more ambitious: it takes a control system together with the speciﬁcation, and
produces a controller such that the resulting closed-loop satisﬁes the speciﬁcation. The automated controller
synthesis approach from formal requirements is referred to as correct-by-construction controller synthesis
scheme [189, 22, 101]. While the controller synthesis approach has been well understood for safety, the secrecy
requirements in CPS are often veriﬁed after the design of controllers. Hence, if the system leaks information,
the controller needs to be redesigned incurring high veriﬁcation and validation costs.

We envisage a paradigm shift in the development of simultaneously safe and secure CPS that advocates a
secure-by-construction controller synthesis scheme which generalizes existing correct-by-construction syn-
thesis methods by considering privacy properties simultaneously to safety ones during the design phase.

Overview . We give a brief overview of the secure-by-construction approach using a concrete synthesis problem
for our experimental setup. Consider a physical platform developed as shown in Figure. 2(d). Here we
are interested in synthesizing a controller for the movement of a robotic vehicle (AWS DeepRacer Car in
Figure. 2(a)) with safety and security requirements. The intuition behind the security property of interest is
as follows. Suppose the initial locations of the vehicle contain critical information which is needed to be kept
secret, e.g., the vehicle might be a cash transit van that aims at transferring money initially from a bank to an
ATM machine, or a patient who initially visited a hospital but unwilling to reveal this information to others.
It is implicitly assumed that there is a malicious intruder who is observing the behavior of the vehicle remotely
intending to carry out an attack. Therefore, it is in the interest of the system to verify whether it maintains
plausible deniability for secret initial location where some conﬁdential assignment is executed. In the physical
platform, we assume that the vehicle can start from any of the four corner cell (Cells 0, 5, 12, and 17). We
also assume that Cell 5 and Cell 12 marked in red are sensitive starting locations. We also assume that the
time it takes for the robot to travel to any neighboring cell on east (E), west (W), north (N), and south (S)
is the same and it is known to the intruder. Now assume that the intruder can only observe when the robotic
vehicle is in the regions marked by P (parking area) and Q (checkout queue) and gets the common observation
G for the rest of the cells. A secure-by-construction controller synthesis task is to design a feedback controller

4

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

satisfying the following requirements: 1) a mission requirement: the robotic vehicle visits regions P and Q
inﬁnitely often and 2) a privacy requirement: the intruder is unable to infer whether the vehicle got initiated
from a sensitive location.

Suppose we design a controller providing control strategies from all initial cells such that the robot ﬁrst
follows a shortest path to reach Cell 8 or Cell 15, and then cycles between them forever.
It is easy to
verify that these control strategies satisfy the mission requirement of visiting regions P and Q inﬁnitely often.
However, unfortunately such controller does not satisfy the privacy requirement as it is clear from the following
system executions adhering to the aforementioned control strategies: here on the left side we show the system
executions, while on the right hand side we show the observations made by the intruder. The notation ω over
parentheses shows the inﬁnite repetition of the ﬁnite execution inside them.

– 0 E−→1 E−→2 S−→8( S−→14 E−→15 N−→9 W−→8)ω
– 12 E−→13 E−→14 N−→8( S−→14 E−→15 N−→9 W−→8)ω
– 5 W−→4 W−→3 W−→2 S−→8( S−→14 E−→15 N−→9 W−→8)ω
– 17 W−→16 W−→15( N−→9 W−→8 S−→14 E−→15)ω

(cid:55)→ G−→G−→G−→P (−→G−→Q−→G−→P )ω

(cid:55)→ G−→G−→G−→P (−→G−→Q−→G−→P )ω

(cid:55)→ G−→G−→G−→G−→P (−→G−→Q−→G−→P )ω

(cid:55)→ G−→G−→Q(−→G−→P −→G−→Q)ω

For this controller, if the system starts in the secret state 12, the corresponding observation is also matched
by the non-secret state 0. On the other hand, when the system starts in secret state 5, there is no other
non-secret initial state giving the same observation. Hence, whenever the system starts from the secret state
5, the observation uniquely identiﬁes the initial state to be a secret one. For this controller, we say that the
system is not opaque. On the other hand, by modifying the controller to change the strategy from Cell 17 to
the one below makes the system opaque since it matches the observation sequence starting from Cell 5.

– 17 N−→11 W−→10 W−→9 W−→8( S−→14 E−→15 N−→9 W−→8)ω

(cid:55)→ G−→G−→G−→G−→P (−→G−→Q−→G−→P )ω

We detail the secure-by-construction synthesis framework to automatically design such controllers for large-
scale CPS satisfying both the complex logic missions as well as the security requirements.

Scope. The goal of this paper is to provide the reader with a bird-eye view of the recent research and future
challenges in this promising and active ﬁeld. We will provide a general deﬁnition of the system and provide
various deﬁnitions from the discrete-event systems (DES), cyber-physical systems (CPS), formal methods
(FM) communities. In our selection, the focus of the DES community is on the ﬁnite state models, the CS
community primarily on the continuous space models, while the results from FM community will primarily
focus on logical and automata-theoretic results. We will provide a unifying view of various models and problems
studied in this context, and then survey key complexity and (un-) decidability results while providing practical
sub-classes and theoretical tools studied to recover eﬃcient solutions. A particularly fruitful avenue to provide
scalability is compositional reasoning and we will present a separate treatment on compositional veriﬁcation
and synthesis. The organization of the paper is graphically depicted in Figure 3.

2. Preliminaries

Notation. We denote by R and N the set of real numbers and non-negative integers, respectively. These symbols
are annotated with subscripts to restrict them in the usual way. We use notations K and K∞ to denote the dif-
ferent classes of comparison functions, as follows: K = {γ : R≥0 → R≥0 : γ is continuous, strictly increasing and
γ(0) = 0}; K∞ = {γ ∈ K : limr→∞ γ(r) = ∞}. Given N ∈ N≥1 vectors νi ∈ Rni , ni ∈ N≥1, and i ∈ [1; N ],
we write ν = (ν1, . . . , νN ) to denote the corresponding concatenated vector in Rn with n = (cid:80)
i ni. Given a
vector x ∈ Rn, we denote the inﬁnity norm of x by (cid:107)x(cid:107). We denote by id the identity function over R, i.e.,
id(r) = r for all r ∈ R. The complement of set X w.r.t. Y is deﬁned as Y \X = {x : x ∈ Y, x /∈ X}. For any set
S ⊆ Rn of the form of ﬁnite union of boxes, e.g., S = (cid:83)M
i , dj
i ] ⊆ Rn
with cj
n|}. Moreover, for a

i , we deﬁne span(S) = minj=1,...,M ηSj and ηSj = min{|dj

j=1 Sj for some M ∈ N, where Sj = (cid:81)n

1|, . . . , |dj

i < dj

1 − cj

i=1[cj

n − cj

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

5

Figure 3. Organization of the paper.

set in the form of X = (cid:81)N
(component-wise) vector η = (η1, . . . , ηN ) with ηi ≤ span(Xi), ∀i ∈ [1; N ], we deﬁne [X]η = (cid:81)N
[Xi]ηi = [Rni]ηi ∩ Xi and [Rni]ηi = {a ∈ Rni : aj = kjηi, kj ∈ Z, j = 1, . . . , ni}.
For a set A, we write A∗ for the set of ﬁnite sequences from A and Aω for the set of (inﬁnite) ω-sequences.
We write A∞ = A∗ ∪ Aω.

i=1 Xi, where Xi ⊆ Rni are of the form of ﬁnite union of boxes, and any positive
i=1[Xi]ηi, where

Deﬁnition 1. (System Model) A system Σ in this paper is described by a quadruple

Σ = (X, X0, U, (cid:45) ),
where X is a (possibly inﬁnite) set of states, X0 ⊆ X is a (possibly inﬁnite) set of initial states, U is
a (possibly inﬁnite) set of inputs, and (cid:45) ⊆ X × U × X is a transition relation. We call a system
ﬁnite (or symbolic), if X and U are ﬁnite sets.

(1)

A transition (x, u, x(cid:48)) ∈ (cid:45) is also denoted by x
u(cid:45) x(cid:48), state x(cid:48) is called a
u-successor, or simply a successor, of state x; state x is called a u-predecessor, or simply a predecessor, of state
x(cid:48). We denote by Postu(x) the set of all u-successors of state x and by Preu(x) the set of all u-predecessors
of state x. For a set of states q ∈ 2X , we write

u(cid:45) x(cid:48). For a transition x

Postu(q) = ∪x∈qPostu(x) and Preu(q) = ∪x∈qPreu(x).
We call a system deterministic, if for any state x ∈ X and any input u ∈ U , Postu(x) is singleton; otherwise
we call it non-deterministic.

A system Σ from an initial state x0 ∈ X0 and input sequence u1u2 · · · un ∈ U ∗, induces a ﬁnite state run

un−1(cid:45) xn−1
(2)
ui+1(cid:45) xi+1 for all 0 ≤ i < n. Note that the run induced by an input sequence may not be unique

un(cid:45) xn,

u2(cid:45) · · ·

u1(cid:45) x1

x0

such that xi
because the system may be non-deterministic.

We call a ﬁnite sequence of states x0x1 · · · xn ∈ X ∗ a ﬁnite path of the system Σ and denote by Path(Σ, x0)
the set of all ﬁnite paths generated by Σ starting from x0 with Path(Σ) = ∪x0∈X0Path(Σ, x0). Similarly, an
inﬁnite path x0x1 · · · ∈ X ω is an ω-sequence deﬁned analogously and we denote by Pathω(Σ, x0) the set of all
inﬁnite paths of Σ from x0 with Pathω(Σ) = ∪x0∈X0Pathω(Σ, x0).
Behaviors. A primary concern is whether the behaviors of system Σ satisfy some desired speciﬁcation. For-
mally, let AP be a ﬁnite set of features, or (atomic) propositions, of the state space. We view the states with
the lenses of atomic propositions, and to do so, we deﬁne a labeling function L : X → 2AP that assigns to each
state x ∈ X in Σ a set of propositions L(x) true at the state x. The labeling function can naturally be extended

6

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

from states to path: we call such labeling of a path a trace. For any ﬁnite or inﬁnite path x = x0x1 · · · ∈ X∞,
its trace is L(x) = L(x0)L(x1) · · · ∈ (2AP )∞. The set of all ﬁnite traces and the set of all inﬁnite traces are
denoted by Trace(Σ) and Traceω(Σ), respectively.

Observations. The system releases information to the external world during its execution. The external world
often may not observe the internal states X or their atomic propositions directly but rather their properties over
some observation symbols. Let Y be such set of observations. Let the output function H : X → Y determine
the external observation of each internal state x ∈ X. It can naturally be extended to ﬁnite or inﬁnite paths,
i.e., for a path x = x0x1 · · · ∈ X∞, its output corresponds to a sequence H(x) = H(x0)H(x1) · · · ∈ Y ∞.
The system Σ is said to be metric if the observation set Y is equipped with a metric d : Y × Y → R≥0.
1 · · · , we say the outputs of x and x(cid:48) are (exactly) output
For any two paths x = x0x1 · · · and x(cid:48) = x(cid:48)
equivalent, denoted by H(x) = H(x(cid:48)), if H(xi) = H(x(cid:48)
i) for all i ≥ 0; on the other hand, we say that they are
δ-approximately output equivalent, and write H(x)≈δH(x(cid:48)), if supi≥0 d(H(xi), H(x(cid:48)
To emphasize the labeling L : X → 2AP and output functions H : X → Y of a system Σ, we rewrite the tuple
describing the system as

Σ = (X, X0, U, (cid:45) , AP, L, Y, H).
When it is clear from the context, we may drop some of the elements in the tuple for the sake of simple
presentation.

i)) ≤ δ.

0x(cid:48)

Remark 2.1. In the DES literature, it is customary to model a system as a ﬁnite state machine G =
(X, E, δ, X0), where X is a set of states, E is a set of events, δ : X × E → 2X is a transition function and
X0 ⊆ X is a set of initial states [35]. In such treatments, both inputs and properties are captured by events
E. Furthermore, it is also assumed that the observation mapping is also event-based captured by a natural
projection P : E → Eo.

Our modeling framework is general enough to capture treatment in DES literature and capable of expressing
more general scenarios posed in the reactive control systems settings.

3. Security of CPS

Security requirements, in the DES [106, 206, 219, 97] and control theory communities, are often expressed
using the notion of opacity, while in the realm of computer science security requirements are expressed using
closely related, but subtly diﬀerent, concepts of non-interference [127, 136, 205], K-safety [183, 141], language-
based secrecy [4], and their generalizations using HyperLTL properties [41, 40]. We review these notions in
this section.

3.1. Security Notions for Finite Systems: Opacity.

Attack Model. In the setting discussed here, we assume that there exists a secret predicate on runs
that models the conﬁdential behavior of the system. The system does not want the intruder to infer
the status of the secret predicate, i.e., whether it has executed a secret run. We consider that the
intruder knows the dynamics of the system; and can observe the output sequences of the system. The
intruder wants to use the output sequences observed online and the knowledge of the system model
to infer certain information about the secret predicates of the corresponding run. For simplicity, we
assume that the input sequences are internal information and unknown to the intruder. This setting
can be easily relaxed to handle the case where both input and output information are available to the
intruder.

Opacity is a well-studied conﬁdentiality property that captures whether or not the “secret” of the system can
be revealed to an intruder that can infer the system’s actual behavior based on the information ﬂow. A system
is said to be opaque if it always has the plausible deniability for any of its secret behavior.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

7

Figure 4. Initial-state opacity.

Deﬁnition 2 (Language-Based Opacity). For a system Σ = (X, X0, U, (cid:45) , Y, H), let PS ⊆
Path(Σ) be the set of secret (ﬁnite) paths and PP ⊆ Path(Σ) be a set of non-secret (ﬁnite) paths. We
say system Σ is opaque w.r.t. PS and PP if for any secret path x ∈ PS, there exists a non-secret path
x(cid:48) ∈ PP such that H(x) = H(x(cid:48)).

The above deﬁnition of opacity is referred to as language-based opacity in the DES literature [106] as it uses
languages PS and PP to represent secret and non-secret behaviors, respectively. The condition in the deﬁnition
can also be equivalently written in terms of language inclusion as follows:

H(PS) ⊆ H(PP ).

(3)

In speciﬁc applications, secret paths PS usually have concrete meanings, e.g., currently at a secret location
or initiated from a secret location. Therefore, a commonly used approach is to consider a set of secret states
XS ⊆ X. Depending on what information the system wants to hide, the following state-based notions of
opacity have been introduced in the literature.

Deﬁnition 3 (State-Based Opacity). Let Σ = (X, X0, U, (cid:45) , Y, H) be a system, XS ⊆ X be a
set of secret states and K ∈ N be a non-negative integer. We say system Σ is
– Initial-State Opaque [165] if for any path x = x0x1 · · · xn ∈ Path(Σ), where x0 ∈ XS, there exists a

path x(cid:48) = x(cid:48)

0x(cid:48)

1 · · · x(cid:48)

n ∈ Path(Σ), where x(cid:48)

0 /∈ XS, such that H(x) = H(x(cid:48));

– Current-State Opaque [167] if for any path x = x0x1 · · · xn ∈ Path(Σ), where xn ∈ XS, there exists

a path x(cid:48) = x(cid:48)

0x(cid:48)

1 · · · x(cid:48)

n ∈ Path(Σ), where x(cid:48)

n /∈ XS, such that H(x) = H(x(cid:48));

– Inﬁnite-Step Opaque [164] if for any path x = x0x1 · · · xn . . . xn+k ∈ Path(Σ), where xn∈XS, there

is a path x(cid:48) = x(cid:48)

0x(cid:48)

1 · · · x(cid:48)

n . . . x(cid:48)

n+k ∈ Path(Σ), where x(cid:48)

n /∈ XS, such that H(x)=H(x(cid:48));

– K-Step Opaque [163] if for any path x = x0x1 · · · xn . . . xn+k ∈ Path(Σ), where xn ∈ XS and k ≤ K,

there exists a path x(cid:48) = x(cid:48)

0x(cid:48)

1 · · · x(cid:48)

n · · · x(cid:48)

n+k ∈ Path(Σ), where x(cid:48)

n /∈ XS, such that H(x) = H(x(cid:48));

– Pre-Opaque [215] if for any path x = x0x1 · · · xn and any k ∈ N, there exists a path x(cid:48) =

0x(cid:48)
x(cid:48)

1 · · · x(cid:48)

n · · · x(cid:48)

n+k ∈ Path(Σ), where x(cid:48)

n+k /∈ XS, such that H(x0x1 . . . xn) = H(x(cid:48)

0x(cid:48)

1 · · · x(cid:48)

n).

The above state-based notions of opacity are closely related to the three fundamental state estimation problems
in the systems theory: ﬁltering, smoothing and prediction [62]. Speciﬁcally, current-state opacity is related
to the ﬁltering problem because it requires that the intruder can never determine for sure that the system
is currently at a secret state. Initial-state opacity and inﬁnite/K-step opacity are related to the smoothing
problem because they both consider the scenario where the intruder can use latter observations to infer whether
or not a system was at a secret state for some previous or the initial instant. In particular, initial-state opacity
says that the intruder can never know that the system was initiated from a secret state, and K-step opacity says

2022/02/018

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

that the intruder can never know that the system was at a secret state within the past K-steps. Clearly, when
K takes values 0 and ∞, K-step opacity becomes current-state opacity and inﬁnite-step opacity, respectively.
Finally, the notion of pre-opacity is related to the predication problem by requiring that the intruder can never
know for sure that the system will reach a secret state for some speciﬁc future instant. This type of opacity
essentially captures the intention security of the system. An illustration of the concept of initial-state opacity
is depicted in Figure. 4.

3.2. Security Notions for CPS: Approximate Opacity. The formulation of opacity in the last subsection
requires that for any secret behavior, there exists a non-secret behavior such that they generate exactly the
same output. Therefore, we will also refer to these deﬁnitions as exact opacity. Exact opacity essentially
assumes that the intruder or the observer can always measure each output or distinguish between two diﬀerent
outputs precisely. This setting is reasonable for non-metric systems where outputs are symbols or events.
However, for metric systems, e.g., when the outputs are physical signals, this setting is too restrictive. In
particular, due to the imperfect measurement precision, which is almost the case for all physical systems, it is
very diﬃcult to distinguish two observations if their diﬀerence is very small. Therefore, exact opacity may be
too strong for metric systems and it is meaningful to deﬁne a weak and “robust” version of opacity.

In [225], a concept called approximate opacity is proposed that is more applicable to metric systems. The new
concept can be seen as a “robust” version of opacity by characterizing under what measurement precision the
system is opaque. In particular, we treat two outputs as “indistinguishable” outputs if their distance is smaller
than a given threshold parameter δ ≥ 0, i.e., condition H(x) = H(x(cid:48)) is replaced by H(x) ≈δ H(x(cid:48)). All exact
notions of opacity deﬁned in Deﬁnition 3 can be generalized to the approximate versions by replacing the output
equivalence condition as δ-closeness. In the remainder part of this paper, for the sake of simple presentation, we
mainly focus on initial-state opacity to present the main results. Moreover, when discussing state-based opacity,
we incorporate the secrete state set XS in the system deﬁnition and use Σ = (X, X0, XS, U, (cid:45) , Y, H) to
denote a metric system.

Deﬁnition 4 (Approximate Opacity). Let Σ = (X, X0, XS, U, (cid:45) , Y, H) be a metric system,
with the metric d deﬁned over the output set, and a constant δ ≥ 0. System Σ is said to be δ-
approximate initial-state opaque if for any path x = x0x1 · · · xn ∈ Path(Σ), where x0 ∈ XS, there
exists path x(cid:48) = x(cid:48)

0 /∈ XS, such that H(x) ≈δ H(x(cid:48)).

n ∈ Path(Σ), where x(cid:48)

1 · · · x(cid:48)

0x(cid:48)

Clearly, when δ = 0, δ-approximate initial-state opacity reduces to its exact version in Deﬁnition 3. The main
diﬀerence is how we treat two outputs as indistinguishable outputs. Speciﬁcally, same as in the exact case,
we still assume that the intruder know the system model and the output trajectory generated. However, we
further assume that the intruder may not be able to distinguish an output trajectory from other δ-closed
ones. Intuitively, the approximate version of opacity can be interpreted as “the secret of the system cannot
be revealed to an intruder that does not have an enough measurement precision related to parameter δ”. In
other words, instead of providing an exact security guarantee, approximate opacity provides a relaxed and
quantitative security guarantee with respect to the measurement precision of the intruder. Therefore, the
value δ can be interpreted as either the measurement imprecision of the intruder or the security level the
system can guarantee, i.e., under how powerful intruder the system is still secure.

3.3. Safety & Security in Formal Methods: Temporal Logic. In the DES literature, opacity is deﬁned
over (possibly arbitrarily long) ﬁnite paths. In the context of formal veriﬁcation and synthesis in the computer
science literature, formal properties are usually deﬁned over inﬁnite traces. Speciﬁcally, a property P ⊆ (2AP )ω
is a subset of inﬁnite traces. Since languages over inﬁnite sequences are more expressive than languages over
ﬁnite ones, it is more general to consider ω-languages than ﬁnite-languages. Formal logics such as LTL [17]
and their generalizations (hyperLTL [40, 41]) are convenient ways to express subsets of ω-regular languages.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

9

Safety and Mission Requirements. Linear Temporal Logic (LTL) [17] is a convenient and expressive formalism
to express properties of inﬁnite runs (or traces) of the system. A restricted form of LTL [44] has been proposed
to express properties of ﬁnite runs or traces. The set of LTL properties over the atomic proposition AP can
be deﬁned by the following grammar:

φ ::= a ∈ AP | ¬φ | φ ∨ φ | X φ | φ U φ.

Here, ¬ and ∨ stand for logical negation and disjunction, while X and U are temporal modalities expressing
next (in the next discrete step) and until (left property continues to hold until the property on the right
holds) modalities, respectively. For convenience, additional operators can be derived from these basic ones:
true def= a ∨ ¬a; false def= ¬true; ϕ ∧ ψ def= ¬(¬ϕ ∨ ¬ψ); ϕ → ψ def= ¬ϕ ∨ ψ; F ϕ def= false U ϕ; and G ϕ def= ¬ F ¬ϕ.
Here ∧ and → stand for conjunction and implication, while F and G stand for temporal operators finally
(some time in the future) and globally (at each step). The semantics of the LTL can be deﬁned inductively
in a straightforward fashion (see, [17]). This logic allows the designers to unambiguously characterize system
properties. For instance, a safety property can be expressed as “G ¬φ” which states that some bad property
φ never holds. Similarly, a reachability property “F φ” can be used to express that some good property φ
eventually holds.

For an inﬁnite trace r ∈ Traceω(Σ) of a system Σ, we say that r satisﬁes the LTL property ϕ and denoted by
r |= ϕ, if it satisﬁes the LTL formula ϕ. It is known that the set of all inﬁnite traces satisfying an LTL formula
can be accepted by either a non-deterministic B¨uchi automaton or a deterministic Rabin automaton [17].
Given a system Σ and an LTL requirement ϕ, we denote by Σ |= ϕ if for every inﬁnite trace r ∈ Traceω(Σ)
we have that r |= ϕ.

LTL formulae capture the safety and functional correctness requirements of the system. Essentially, it evaluates
whether or not each single inﬁnite trace satisﬁes the property. However, formal reasoning about security
properties requires reasoning with multiple traces of the system. For example, Alur et al. [4] show that modal
µ-calculus is insuﬃcient to express all opacity policies.

Clarkson and Schneider [41] introduced the concept of hyperproperties to express security policies using second-
order logic. Hyperproperties generalize the concept of linear-time properties [17] from being sets of runs to
sets of sets of runs. HyperLTL, unlike LTL which implicitly considers only a single trace at a time, can
relate diﬀerent trace executions simultaneously through the use of existential and universal quantiﬁers. The
HyperLTL formulae can be given using the following grammar:

ψ ::= ∃π.ψ | ∀π.ψ | φ
φ ::= aπ | ¬φ | φ ∨ φ | X φ | φ U φ.

The key distinction over LTL formulae is the introduction of trace quantiﬁers ∃ and ∀. The quantiﬁer ∃π
stands for “for some trace π” while the quantiﬁer ∀π stands for “for all traces π”, respectively. The variable
φ generates standard LTL formulae (complete with Boolean connectives and temporal operators X and U)
with the exception that atomic propositions can refer to distinct trace variables. Hence, for every proposition
a ∈ AP and trace variable π, we use aπ to express that proposition a is referring to the trace π. We say that
a trace variable occurs free in a HyperLTL formula, if it is not bounded by any trace quantiﬁer. A HyperLTL
formula with no free variable is called a closed formula.

HyperLTL can express certain opacity properties. For instance, the following HyperLTL formula expresses
language-based opacity introduced in Deﬁnition 2 when PS and PP are given as LTL properties ς and ϕ

∀π∃π(cid:48) · L(π) |= ς → (H(π) = H(π(cid:48)) ∧ L(π(cid:48)) |= ϕ)

where π is deﬁned over Pathω(Σ).

Unfortunately, since HyperLTL requires quantiﬁcation over paths in the beginning of the formula, it is not
expressive enough to deﬁne inﬁnite-step, current-state, and K-step opacity requirements.

10

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

We propose the following generalized language-based opacity notion which extends language-based opacity in
Deﬁnition 2 from ﬁnite paths to inﬁnite paths.

Deﬁnition 5 (Generalized Language-Based Opacity). Let Σ = (X, X0, U, (cid:45) , AP, L, Y, H) be
a metric system, with the metric d deﬁned over the output set, and a constant δ ≥ 0, PS ⊆ Traceω(Σ)
be a secret property and PP ⊆ Traceω(Σ) be a public property. For computational representation,
the secret and public properties can be expressed either logically (e.g., via LTL) or using automatic
structures (e.g., ω-automata or ﬁnite state machines).
We say system Σ is opaque with respect to PS and PP if for any secret path x ∈ Pathω(Σ), where
L(x) ∈ PS, there exists a non-secret path x(cid:48) ∈ Pathω(Σ), where L(x(cid:48)) ∈ PP , such that

H(x) ≈δ H(x(cid:48)).

The above deﬁnition of language-based opacity generalizes Deﬁnition 2 in threefold. First, secret behaviors
are deﬁned in terms of traces rather than the internal paths. This setting clearly subsumes Deﬁnition 2
because we can set the labeling function as an identity mapping L : X → X. Second, secret behaviors are
evaluated in terms of inﬁnite sequences rather than ﬁnite sequences. Note that, state-based notions of opacity
in Deﬁnition 3 are instances of Deﬁnition 2. Therefore, the notions of state-based opacity, such as initial-state
opacity or inﬁnite-step opacity, can all be formulated in terms of Deﬁnition 5 with a syntactic modiﬁcation
to the system (by adding a dummy sink state to the system) to enable the treatment of ﬁnite sequences as
inﬁnite sequences. Finally, Deﬁnition 5 considers approximate output equivalence rather than the exact one.
Language-based opacity in Deﬁnition 5 also generalizes the notions of noninterference [127, 136, 205] and
2-safety [183, 141].

Our Settings. In our later problem formulations, for mission/safety requirements we focus on those given as
LTL formulae, while for security ones we focus on generalized language-based opacity in Deﬁnition 5 where
secret and public properties αS ⊆ (2AP )ω and αP ⊆ (2AP )ω. We denote such a generalized opacity property
as a tuple α = (αS, αP ). A system Σ is called α-opaque if it is opaque w.r.t. secret and public properties
expressed, respectively, using αS and αP . Therefore, we use tuple (ϕ, α) to model both the mission and
security requirements. Our ﬁrst objective is to verify whether or not system Σ satisﬁes (ϕ, α). If not, the
second objective is to synthesize a controller such that the system under control satisﬁes (ϕ, α). We will
elaborate in details on the veriﬁcation and the synthesis problems in Sections 4 and 5, respectively.

4. Security-Aware Verification

In the previous section, we have introduced various security formulations that are commonly used from the
literature. A natural question to answer is: how to determine whether a given system preserves certain security
property? Furthermore, if the system does not preserve the desired security property, how can one design
proper controllers to enforce security properties on it? We proceed with the following sections to address these
questions.

In this section, we investigate the veriﬁcation problem.

Problem 1 (Security-Aware Veriﬁcation). Given a mission requirement (as an LTL formula) ϕ
and a security property α, the security-aware veriﬁcation problem is to decide whether Σ |= (ϕ, α), i.e.,
Σ satisﬁes the property ϕ and is α-opaque.

Note that the above problem is formulated in a very general setting by considering an arbitrary mission
requirement ϕ and an arbitrary security requirement α. Throughout the paper, we will mainly consider
approximated initial-state opacity as a speciﬁed α to present our result. To this end, we ﬁrst overview the
standard model checking approaches for verifying LTL formulae. Then, for the veriﬁcation of security, we will

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

11

ﬁrst discuss the typical schemes on verifying opacity for ﬁnite systems, and then present some recent results
which are potential to deal with complex continuous-space CPS.

Given a mission requirement (as an LTL formula) ϕ and a generalized opacity property (as a pair of two
LTL formulae) α, the veriﬁcation problem, Σ |= (ϕ, α), can be decomposed into verifying mission and opacity
properties separately. The veriﬁcation problem against the mission requirements given as LTL formula reduces
to a repeated reachability problem on the composition of Σ with a monitor automaton corresponding to the
negation of the LTL formula [17]. The problem is known to be PSPACE-complete and there are eﬃcient
symbolic tools (e.g., NuSMV [39] and SPIN [72]) to verify ﬁnite labelled transition systems (LTS) representations
of Σ against LTL requirements. On the other hand, veriﬁcation of the generalized language-based opacity has
only been explored in its restricted forms of opacity. We will review them next.

4.1. Finite Systems. In the last section, we reviewed a security notion called approximate opacity that is
suitable to reason both discrete and continuous dynamics. Here, we show how to verify approximate opacity
for ﬁnite systems, which will be later used for the veriﬁcation of opacity for general CPS equipped with
continuous state space. Here we present an approach based on the construction of the δ-approximate observer.

Deﬁnition 6 (Approximate Observer). Let Σ = (X, X0, XS, U, (cid:45) , Y, H) be a metric system,
with the metric d deﬁned over the output set, and a constant δ ≥ 0. The δ-approximate observer is a
system without outputs

where

Obs(Σ) = (Q, Q0, U,

(cid:45) ),

obs

– Q ⊆ X × 2X×X is the set of states;
– Q0 = {(x, z) ∈ X0 × 2X0×X0 : (xI , xC) ∈ z ⇔ xI = xC ∧ d(H(x), H(xC)) ≤ δ} is the set of initial

states;

– U is the set of inputs, which is the same as the one in Σ;
–

(cid:45) ⊆ Q × U × Q is the transition function deﬁned by: for any (x, z), (x(cid:48), z(cid:48)) ∈ X × 2X×X

obs

u

(cid:45) (x(cid:48), z(cid:48)) if

and u ∈ U , (x, z)
1 (x, u, x(cid:48)) ∈ (cid:45) ; and
(cid:83)
2 z(cid:48) = (cid:83)

obs

u(cid:48)∈U

(xI ,xC )∈z{(xI , x(cid:48)

C) : d(H(x(cid:48)), H(x(cid:48)

C)) ≤ δ ∧ xC

u(cid:48)(cid:45) x(cid:48)

C}.

For the sake of simplicity, we only consider the part of Obs(Σ) that is reachable from initial states.

Intuitively, the δ-approximate observer works as follows. Each initial state of Σ is a pair consisting of a system
state x ∈ X0 and its δ-closed state pairs z ∈ 2X0×X0 . Note that each state pair in z is of form (xI , xC),
where xI denotes the initial-state the system came from and xC denotes the current-state of the system. Note
that, since we cannot observe the actual state x precisely, we need to consider all such initial-current state
pairs whose second (current-state) component is δ-close to the actual state x. Then from each state, we track
states that are consistent with the output information recursively. Essentially, the ﬁrst component can be
understood as the “reference trajectory” that is used to determine what is “δ-close” at each instant and the
second component is the set of “initial-current-state-pairs” that are δ-close to the reference trajectory. This
structure is motivated by the well-known “subset construction” and combines both the initial-state estimator
and the current-state estimator in a single structure.

For each state q = (x, z) ∈ Q, we denote by int(q) = {xI : (xI , xC) ∈ z} and cur(q) = {xC : (xI , xC) ∈ z}
the set of all possible initial-states and current-states, respectively. Employing the above-deﬁned observer, the
next theorem is proposed in [225] for the veriﬁcation of δ-approximate initial-state or current-state opacity of
ﬁnite metric systems.

12

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Figure 5. Pipeline of standard discretization-based or abstraction-based veriﬁcation tech-
nique.

Theorem 4.1 (Veriﬁcation of Opacity). Let Σ = (X, X0, XS, U, (cid:45) , Y, H) be a ﬁnite met-
ric system, with the metric d deﬁned over the output set, and a constant δ ≥ 0. Let Obs(Σ) =
(cid:45) ) be its δ-approximate observer. Then, Σ is δ-approximate initial-state opaque (re-
(Q, Q0, U,
spectively, current-state opaque) if and only if for any q ∈ Q, we have int(q) (cid:54)⊆ XS (respectively,
cur(q) (cid:54)⊆ XS).

obs

It is worth noting that the complexity of verifying exact opacity is already known to be PSPACE-complete
[36]. Therefore, the complexity of verifying approximate opacity is also PSPACE-complete. Essentially, the
exponential complexity comes from the subset construction to handle information uncertainty. Note that the
observer structure presented in Deﬁnition 6 is a uniﬁed structure that can handle both initial-state opacity
and current-state opacity. If one just needs to verify initial-state or current-state opacity, the state space of
the observer structure can further be reduced to X × 2X ; see, [225] for more detailed discussion. Regarding the
veriﬁcation of inﬁnite-step or K-step opacity, eﬀective algorithms have also been proposed in [163, 164, 219]
for the exact notions and [225] for the approximate ones.

4.2. CPS: Abstraction-Based Approach. In the previous subsections, we discussed frameworks on verify-
ing opacity properties for ﬁnite systems. In this subsection, we present some recent results for the veriﬁcation
of opacity for continuous-space CPS based on their ﬁnite abstractions (a.k.a. symbolic models).

Models of CPS are inherently heterogeneous: from discrete systems modeling computational parts to diﬀeren-
tial or diﬀerence equations modeling continuous physical processes. The ability to handle this heterogeneity
is a prerequisite of a rigorous formal framework for both design and analysis framework for CPS. In order to
address the heterogeneity of CPS models, formal veriﬁcation and synthesis are often addressed by methods
of abstraction in which continuous-space models are approximated by discrete ones. When a suitable ﬁnite
abstraction is constructed, by leveraging computational tools developed for DES and games on automata, one
can verify or synthesize controllers in an automated fashion against complex logic requirements.

The pipeline of traditional abstraction-based veriﬁcation technique is depicted in Figure.5, which consists of
three key phases. The ﬁrst phase is on the construction of a ﬁnite abstraction of the CPS with the property
that the set of behaviours of the CPS is included in that of the constructed ﬁnite abstraction. The second
phase in the architecture requires symbolic analysis to eﬃciently reason about formal speciﬁcations. The ﬁnal
phase is to bring the reasoning back to the original concrete systems with formal guarantee.

The key to the construction of such ﬁnite/symbolic systems is the establishment of formal relations between
the concrete and abstract systems. A system relation formalizes the ability to extrapolate properties from
an abstraction to the concrete system. Diﬀerent system relations enable extrapolation of diﬀerent kinds
of properties. Such relations include (alternating) (bi)simulation relations, their approximate versions, and
strongest or asynchronous (cid:96)-complete approximations. Finite abstraction together with the notions of so-called
simulation relations have been widely and successfully used in the past decade for formal veriﬁcation, synthesis,
and approximation of hybrid systems [5, 55, 54, 56, 232, 228, 147, 189, 22, 230, 158]. Nevertheless, none of the

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

13

constructed ﬁnite abstractions in the aforementioned literature is guaranteed to preserve opacity. As reported
in [237], existing notions of standard (bi)simulation relations and their approximate versions which are often
used in ﬁnite abstraction synthesis schemes fail to preserve opacity.

In the following, we discuss some recent results proposed in [225], which develop for the ﬁrst time an
abstraction-based opacity veriﬁcation approach by adapting notions of simulation relations to the context
of opacity.

For the sake of an easier presentation, the main results presented in the sequel will be based on the class of
discrete-time control systems as follows. A discrete-time control system (dt-CS) Σ is a metric system and
denoted by the tuple Σ = (X, X0, XS, U, f, Y, H). Notice that here, instead of (cid:45) , we use f : X × U → X
to denote the state transition function. The dynamics of Σ is described by diﬀerence equations of the form

Σ :

(cid:26) x(k + 1) = f (x(k), ν(k)),
y(k) = H(x(k)),

(4)

where x : N → X, y : N → Y , and ν : N → U are the state, output, and input signals, respectively. We write
xx0,ν(k) to denote the point reached at time k under the input signal ν from initial condition x0. Similarly,
we denote by yx0,ν(k) the output corresponding to state xx0,ν(k), i.e., yx0,ν(k) = H(xx0,ν(k)).

Deﬁnition 7 (Approximate Initial-State Opacity Preserving Simulation Relation). Consider
two metric systems Σ = (X, X0, XS, U, f, Y, H) and ˆΣ = ( ˆX, ˆX0, ˆXS, ˆU , ˆf , ˆY , ˆH) with the same output
sets Y = ˆY and metric d. For ε ∈ R≥0, a relation R ⊆ X × ˆX is called an ε-approximate initial-state
opacity preserving simulation relation (ε-InitSOP simulation relation) from Σ to ˆΣ if
1 a) ∀x0 ∈ X0 ∩ XS, ∃ˆx0 ∈ ˆX0 ∩ ˆXS : (x0, ˆx0) ∈ R;
b) ∀ˆx0 ∈ ˆX0 \ ˆXS, ∃x0 ∈ X0 \ XS : (x0, ˆx0) ∈ R;

2 ∀(x, ˆx) ∈ R : d(H(x), ˆH(ˆx)) ≤ ε;
3 For any (x, ˆx) ∈ R, we have
u(cid:45) x(cid:48), ∃ˆx
ˆu(cid:45) ˆx(cid:48), ∃x

ˆu(cid:45) ˆx(cid:48) : (x(cid:48), ˆx(cid:48)) ∈ R;
u(cid:45) x(cid:48) : (x(cid:48), ˆx(cid:48)) ∈ R.

b) ∀ˆx

a) ∀x

We say that Σ is ε-InitSOP simulated by ˆΣ, denoted by Σ (cid:22)ε
I
relation R from Σ to ˆΣ.

ˆΣ, if there exists an ε-InitSOP simulation

Note that a system ˆΣ that simulates Σ through the InitSOP simulation relation is often called an opacity-
preserving abstraction of Σ. We should mention that, although the above relation appears to be similar to
the approximate bisimulation relation proposed in [55], it is still a one-sided relation here because Condition
1 is not symmetric. We refer the interested readers to [237] to see why one needs the strong Condition 3
in Deﬁnition 7 to show preservation of initial-state opacity in one direction when ε = 0. Similar notions of
approximate simulation relations for preserving current-state and inﬁnite-step opacity are introduced in [225]
and omitted here due to lack of space.

The following theorem provides a suﬃcient condition for verifying δ-approximate initial-state opacity based
on related systems as in Deﬁnition 7.

Theorem 4.2 (Abstraction-based Opacity Veriﬁcation). Consider two metric systems Σ =
(X, X0, XS, U, f, Y, H) and ˆΣ = ( ˆX, ˆX0, ˆXS, ˆU , ˆf , ˆY , ˆH) with the same output sets Y = ˆY and metric
d and let ε, δ ∈ R+

ˆΣ and ε ≤ δ

0 . If Σ (cid:22)ε
I
ˆΣ is (δ − 2ε)-approximate opaque ⇒ Σ is δ-approximate opaque.

2 , then we have:

14

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Figure 6. Example of ε-approximate initial-state opacity preserving simulation relation.

Note that the above implication across two related systems holds for all of the three types of approximate
opacity. This result provides us a suﬃcient condition for verifying approximate opacity using abstraction-
based techniques. It is worth remarking that δ and ε are parameters specifying two diﬀerent types of precision.
Parameter δ is used to specify the measurement precision under which we can guarantee opacity for a single
system, while parameter ε is used to characterize the “distance” between two systems in terms of preservation
of approximate opacity.

We illustrate the usefulness of ε-approximate initial-state opacity preserving simulation relation by the follow-
ing example.

Example 4.3. Consider two systems Σ and ˆΣ as shown in Figure 6, where the outputs are speciﬁed by
the values inside the brackets associated to each state, and secret states are marked in red. First note that
one can easily verify that the smaller system ˆΣ is δ-approximate initial-state opaque with δ = 0.1. Next,
we show that Σ is ε-approximate InitSOP simulated by ˆΣ, as in Deﬁnition 7, through the relation R =
{(A, J), (B, K), (C, K), (D, K), (E, N ), (F, M ), (G, M ), (I, M )}, where ε = 0.1. Condition 1 in Deﬁnition 7
can be easily checked since : a) for E ∈ X0 ∩ XS, there exists N ∈ ˆX0 ∩ ˆXS such that (E, N ) ∈ R; b) for
J ∈ ˆX0 \ ˆXS, there exists A ∈ X0 \ XS such that (A, J) ∈ R. Condition 2 is satisﬁed readily by seeing
d(H(x), ˆH(ˆx)) ≤ 0.1 holds for any (x, ˆx) ∈ R. One can also verify that Condition 3 holds as well by checking
Conditions 3a) and 3b) for each pair of states in the relation R. For instance, consider the state pair (C, K) ∈
R, we have for C (cid:45) D, there exists K (cid:45) K, such that (D, K) ∈ R, and vice versa. Hence, R is an ε-
InitSOP simulation relation from Σ to ˆΣ as in Deﬁnition 7. Now, without applying any veriﬁcation algorithm
to Σ, by leveraging the results in Theorem 4.2, we can readily conclude that Σ is 0.3-approximate initial-state
opaque, where 0.3 = δ + 2ε.

Till here, we have introduced notions of approximate opacity-preserving simulation relations and discussed
their properties as in Theorem 4.2. As mentioned before, this allows us to verify approximate opacity for
inﬁnite systems, e.g., continuous-space control systems, based on their ﬁnite abstractions. In the following,
we present how to construct ﬁnite abstractions for a class of dt-CS for the purpose of verifying approximate
opacity under the assumption of incremental input-to-state stability (δ-ISS) [13]. Formally, a dt-CS Σ is called
incrementally input-to-state stable (δ-ISS) if there exist a KL function β and K∞ function γ such that for all
x, x(cid:48) ∈ X and for all ν, ν(cid:48) : N → U , the following inequality holds for any k ∈ N:

(cid:107)xx,ν(k)−xx(cid:48),ν(cid:48)(k)(cid:107) ≤ β((cid:107)x − x(cid:48)(cid:107), k)+γ((cid:107)ν − ν(cid:48)(cid:107)∞).

(5)

Now, consider a concrete control system Σ = (X, X0, XS, U, f, Y, H). Assume that the output map H satisﬁes
the following general Lipschitz assumption: (cid:107)H(x) − H(x(cid:48))(cid:107) ≤ α((cid:107)x − x(cid:48)(cid:107)), for all x, x(cid:48) ∈ X, where α ∈ K∞.
Consider a tuple q = (η, µ) of parameters, where 0 < η ≤ min {span(XS), span(X \ XS)} is the state set
quantization, and 0 < µ ≤ span(U ) is the input set quantization parameter. A ﬁnite abstraction of Σ is
deﬁned as

ˆΣ = ( ˆX, ˆX0, ˆXS, ˆU , ˆf , ˆY , ˆH),

(6)

where ˆX = ˆX0 = [X]η, ˆXS = [XS]η, ˆU = [U ]µ, ˆY = {H(ˆx) | ˆx ∈ ˆX}, where ˆH(ˆx) = H(ˆx), ∀ˆx ∈ ˆX, and

– ˆx(cid:48) ∈ ˆf (ˆx, ˆu) if and only if (cid:107)ˆx(cid:48) − f (ˆx, ˆu)(cid:107) ≤ η.

Page .29Xiang YinCDC 2021December 11Approximate Opacity-Preserving (Bi-)simulationsABCD[2.8][1.5][1.4][1.3]IGFE[1.6][1.5][1.4][3.1]JK[2.9][1.4]MN[1.5][3.0]𝛴≈𝐼0.1෠𝛴System 𝛴System ෠𝛴•System 𝑇1is 0.1-approximately IntSOP simulated by system 𝑇2•It is easy to check that system 𝑇2is 0.1-ISO because the intruder has to have enough precision to distinguish between states 𝐽and 𝑁Theorem: Suppose that 𝑇1≼𝐼𝜀𝑇2. Then we have𝑇2is 𝛿-approximate ISO⇒𝑇1is (𝛿+2𝜀)-approximate ISOSECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

15

The following result shows that, under some condition over the quantization parameters η and µ, ˆΣ and Σ are
related under the approximate InitSOP simulation relation as in Deﬁnition 7.

Theorem 4.4 (Opacity Preserving Finite Abstractions). Consider a δ-ISS control system Σ =
(X, X0, XS, U, f, Y, H). For any desired precision ε > 0, let ˆΣ be a ﬁnite abstraction of Σ with a tuple
q = (η, µ) of parameters satisfying

β (cid:0)α−1(ε), 1(cid:1) + γ(µ) + η ≤ α−1(ε),

(7)

then, we have Σ (cid:22)ε
I

ˆΣ (cid:22)ε

I Σ.

We would like to refer interested readers to [225, Example. VI.9] for an example that illustrates how to use
Theorem 4.4 to verify approximate opacity for an inﬁnite system based on its ﬁnite abstraction.

Here, we presented the results mainly tailored to initial-state opacity to illustrate the rough idea of abstraction-
based approaches for verifying opacity of continuous-space CPS. Note that similar results on the preservation
of approximate current-state and inﬁnite-step opacity through related systems can be found in [225]. We
would like to refer interested readers to some extensions of the results illustrated above to larger classes of
systems including stochastic systems [112] and switched systems [111, 110].

4.3. CPS: Deductive Approach via Barrier Certiﬁcates. The results discussed in the previous sub-
section provides a systematic framework to deal with opacity properties for complex CPS. However, this
methodology may suﬀer from scalability issues since it requires discretization of the state and input sets of the
original system. As an alternative, there is a growing interest in developing discretization-free approaches for
the formal veriﬁcation of privacy properties based on notions of barrier certiﬁcates. In the past decade, barrier
certiﬁcates have shown to be a promising tool for the analysis of safety problems [151, 8, 9, 203] and recently
extended to deal with more general temporal logic speciﬁcations [78, 108, 12]. A recent attempt to analyze
privacy of CPS using barrier certiﬁcates is made in [2]. A new notion of current-state opacity was considered
there based on the belief space of the intruder. The privacy veriﬁcation problem is cast into checking a safety
property of the intruder’s belief dynamics using barrier certiﬁcates. However, this framework is again limited
to systems modeled by partially-observable Markov decision processes (POMDPs) with ﬁnite state sets. In this
subsection, we revisit a discretization-free approach proposed in [113] that is sound in verifying approximate
initial-state opacity for discrete-time control systems.

Consider a dt-CS Σ = (X, X0, XS, U, f, Y, H). We deﬁne the associated augmented system by

Σ×Σ = (X ×X,X0 ×X0,XS ×XS, U ×U,f ×f, Y ×Y,H ×H),

which can be seen as the product of a dt-CS Σ and itself. For later use, we denote by (x, ˆx) ∈ X ×X a pair
of states in Σ×Σ and by (xx0,ν, xˆx0,ˆν) the state trajectory of Σ × Σ starting from (x0, ˆx0) under input run
(ν, ˆν). We use R = X × X to denote the augmented state space. In order to leverage barrier certiﬁcates to
verify approximate initial-state opacity for a dt-CS Σ, we further deﬁne two sets of interests, i.e., the sets of
initial conditions R0 and unsafe states Ru, as:

R0 ={(x, ˆx) ∈ (X0 ∩XS)×(X0 \XS) : (cid:107)H(x)−H(ˆx)(cid:107) ≤ δ},
Ru ={(x, ˆx) ∈ X ×X : (cid:107)H(x)−H(ˆx)(cid:107) > δ},

(8)

(9)

where δ ∈ R≥0 captures the measurement precision of the intruder as introduced in Deﬁnition 4.

The following theorem provides a suﬃcient condition in verifying approximate initial-state opacity of discrete-
time control systems via a notion of barrier certiﬁcates.

16

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Figure 7. Barrier certiﬁcate ensuring safety of the augmented system, which implies opacity
of the original system.

Theorem 4.5 (Barrier Certiﬁcates for Verifying Opacity). Consider a dt-CS Σ, the associated
augmented system Σ×Σ, and sets R0, Ru in (8)-(9). Suppose there exists a function B : X × X → R
such that

∀(x, ˆx) ∈ R0,
∀(x, ˆx) ∈ Ru,
∀(x, ˆx) ∈ R, ∀u ∈ U, ∃ˆu ∈ U,

B(x, ˆx) ≤ 0,

B(x, ˆx) > 0,

for any (x0, ˆx0) ∈ R0 and for any input run ν, there exists an input run ˆν such that

Then,
(xx0,ν(t), xˆx0,ˆν(t)) ∩ Ru = ∅, ∀t ∈ N. This implies that Σ is δ-approximate initial-state opaque.

B(f (x, u), f (ˆx, ˆu)) − B(x, ˆx) ≤ 0.

A function B(x, ˆx) that satisﬁes the conditions in Theorem 4.5 is called an augmented control barrier certiﬁcate
for Σ×Σ. This result shows that the existence of such barrier certiﬁcates ensures a safety property for Σ×Σ,
which further implies opacity property of Σ. The interpretation of Theorem 4.5 is depicted in Figure. 7. It is
worth noting that, failing to ﬁnd such a barrier certiﬁcate does not necessarily imply that the system is not
opaque. In this situation, a natural question is whether or not we can use similar barrier-certiﬁcates based
approaches to show the lack of opacity. This problem is addressed in [113] and brieﬂy presented next.

Theorem 4.6 (Barrier Certiﬁcates for Verifying Lack of Opacity). Consider a dt-CS Σ, the
associated augmented system Σ × Σ, and sets R0, Ru given in (8)-(9). Suppose X ⊂ Rn is a bounded
set and there exists a continuous function V : X × X → R such that

∀(x, ˆx) ∈ R0,
∀(x, ˆx) ∈ ∂R \ ∂Ru,

V (x, ˆx) ≤ 0,

V (x, ˆx) > 0,

∀(x, ˆx) ∈ (R \ Ru), ∃u ∈ U, ∀ˆu ∈ U,

V (f (x, u), f (ˆx, ˆu)) − V (x, ˆx) < 0.

Then, for any (x0, ˆx0) ∈ R0, there exists an input run ν such that (xx0,ν(T ), xˆx0,ˆν(T )) ∈ Ru for any
ˆν, for some T ≥ 0, and (xx0,ν(t), xˆx0,ˆν(t)) ∈ R, for all t ∈ [0, T ]. This implies that system Σ is not
δ-approximate initial-state opaque.

In particular, the previous theorem provides a suﬃcient condition to verify the lack of approximate initial-state
opacity by constructing another type of augmented control barrier certiﬁcates ensuring a reachability property
for Σ×Σ. The interpretation is illustrated in Figure. 8.

2022/02/04SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

17

Figure 8. Barrier certiﬁcate ensuring reachability of the augmented system, which implies
lack of opacity of the original system.

We should mention that, by deﬁning proper regions of interest, i.e., the sets of initial conditions R0 and
unsafe states Ru for the barrier certiﬁcates, similar results can be derived for the veriﬁcation of other types
of approximate opacity; see, e.g., [83].

For systems with polynomial transition functions and semi-algebraic sets (i.e., described by polynomial equal-
ities and inequalities) X0, XS, and X, an eﬃcient computational method based on sum-of-squares (SOS)
programming can be utilized to search for polynomial barrier certiﬁcates. In this way, one can leverage ex-
isting computational toolboxes such as SOSTOOLS [139] together with semideﬁnite programming solvers such
as SeDuMi [184] to compute polynomial barrier certiﬁcates. We refer interested readers to [113, Sec. IV] for
more details on how to translate barrier conditions to SOS constraints. Note that by formulating the barrier
conditions as a satisﬁability problem, one can alternatively search for parametric control barrier certiﬁcates
using an iterative program synthesis framework, called Counter-Example-Guided Inductive Synthesis (CEGIS),
with the help of Satisﬁability Modulo Theories (SMT) solvers such as Z3 [45] and dReal [52]; see, e.g., [78] for
more details. We also refer interested readers to the recent work [142], where machine learning techniques
were exploited for the construction of barrier certiﬁcates.

4.4. Ongoing & Open Problems. So far, we discussed the basic security veriﬁcation procedures for general
CPS using abstractions and barrier certiﬁcates. In the followings, we further discuss some ongoing research
topics and open problems.

Veriﬁcation of General Notion of Opacity for CPS . Existing works for opacity veriﬁcation of general CPS
mainly focus on particular types of opacity such as initial-state opacity or inﬁnite-step one. For ﬁnite systems,
the general notion of α-opacity as deﬁned in Deﬁnition 5 can be veriﬁed using the observer-like structures
when the security properties can be realized by ω-automata. However, for general CPS with inﬁnite states,
how to verify the general notion of α-opacity still needs developments. In particular, for the abstraction-based
approach, one needs to identify suitable relation that preserves α-opacity. For the barrier-based approach,
appropriate conditions for barrier certiﬁcates of α-opacity also need to be identiﬁed.

Quantitative Veriﬁcation of Opacity. The opacity veriﬁcation problem discussed in this section is binary in
the sense that the system is either opaque or not. In some cases, when the veriﬁcation result is negative, one
may be further interested in how insecure the system is. This motivates the research of quantifying the level of
information leakage. For ﬁnite systems, one popular approach is to consider systems modeled by probabilistic
ﬁnite-state automata, Markov chains or Markov decision processes. Then one can quantify opacity in terms
of probability [166, 23, 25, 87, 224, 102]. For example, one may require that the intruder can never know that
the system is currently at a secret-state with more than (cid:15) probability, or the system has less than (cid:15) probability
to reveal its secret. However, all existing works on quantifying opacity consider ﬁnite systems, although their
belief spaces may be inﬁnite. How to leverage opacity quantiﬁcation techniques for general CPS, using either

2022/02/0418

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

abstraction-based approaches or barrier certiﬁcates, still need to be developed. The recent result in [112] has
made some initial steps towards this objective using the abstraction-based technique.

Opacity Veriﬁcation for Larger Classes of CPS . The aforementioned abstraction-based approaches for opacity
veriﬁcation of general CPS crucially depends on incremental ISS assumption. However, this assumption is
rather restrictive for many practical systems. How to relax the stability assumption so that the veriﬁcation
techniques can be applied to more general classes of CPS is an interesting and important future direction.

Also, in the problem formulation of opacity, the attacker is assumed to be able to access partial information-
ﬂow of the plant. However, for networked control systems, the information transmission between controllers
and plants in the feedback loops may also be released to the intruder. There are some very recent works on the
veriﬁcation of opacity for networked control systems using ﬁnite-state models; see, e.g., [222, 214, 238, 107, 213].
However, existing works on formal veriﬁcation of networked control system mainly focus on the mission
requirements [231, 69, 146, 28] and to the best of our knowledge, there is no result on formal veriﬁcation of
opacity for general networked CPS.

5. Secure-by-Construction Controller Synthesis

In the previous section, we investigated the security veriﬁcation problem for open-loop systems. However,
the original system Σ may not be opaque. Therefore, it is desired to enforce opacity for the system via the
feedback control mechanism. In the realm of control theory, one of the most popular approaches for enforcing
certain property of the system is through a feedback controller.

A supervisor or a controller for Σ is a function C : Path(Σ) → 2U that determines a set of possible control inputs
based on the executed state sequences. We denote by ΣC the closed-loop system under control. Speciﬁcally,
un(cid:45) xn is feasible in the closed-loop system if it is a run in
a state run x0
the open-loop system Σ and ui ∈ C(x0x1 · · · xi−1) for any i ≥ 1. Similarly, we denote by Path(ω)(ΣC) and
Trace(ω)(ΣC) the set of paths and the set of traces of the controlled system ΣC, respectively.

un−1(cid:45) xn−1

u2(cid:45) · · ·

u1(cid:45) x1

The goal of the control synthesis problem is to synthesize a feedback controller C such that the closed-loop
system ΣC satisﬁes both the mission requirement, e.g., an LTL formula ϕ, and/or, the security requirement,
e.g., opacity. Speciﬁcally, we investigate the following control synthesis problem.

Problem 2 (Secure-by-construction Controller Synthesis). Given a mission requirement (as an
LTL formula) ϕ and a security property α, the secure-by-construction controller synthesis problem is
to design a supervisor C such that ΣC |= (ϕ, α).

The foundations for the correct-by-construction approach were laid by Church in [38] where he stated his
famous synthesis problem: given a requirement which a circuit is to satisfy, ﬁnd a circuit that satisﬁes the
given requirement (or alternatively, to determine that there is no such circuit). The landmark paper by B¨uchi
and Landweber [31] gave the ﬁrst solution of Church’s synthesis problem for speciﬁcation given in Monadic
second-order logic. Pnueli and Rosner [145] studied the synthesis problem for speciﬁcations given as LTL [17]
and showed the problem to be complete with 2Exptime complexity. Ramadge and Wonham [154] studied
the synthesis problem—as a mechanism for supervisory controller synthesis of discrete event systems—for
simple safety speciﬁcations and gave an eﬃcient linear-time algorithm for computing maximally permissive
controller for this fragment. The relation between reactive synthesis and supervisory control has been thor-
oughly discussed in a serious of recent works; see, e.g., [48, 155, 140, 179, 124, 171]. The goal of this thrust
is to study decidability and complexity of the synthesis problems for LTL speciﬁcation (and their eﬃciently
solvable sub-classes) with security requirements and propose eﬃcient algorithms to solve synthesis problems.

5.1. Finite Systems. In opacity enforcement using supervisory control, the objective is to synthesize a
supervisor C that avoids executing those “secret-revealing” paths and at the same time, satisﬁes the desired

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

19

mission requirement described as an LTL formula. Note that in Problem 2, the meaning of mission satisfaction,
i.e., ΣC |= ϕ, is relatively clear. However, there may have diﬀerent interpretations for security for the closed-
loop system, i.e., ΣC |= α. In particular, the synthesis problem can be categorized as policy-aware synthesis
and policy-unaware synthesis. Here, we still use initial-state opacity as the concrete security property to
illustrate the diﬀerences.

Basic Opacity-Enforcing Controller Synthesis Problem. The most basic setting for opacity enforcing control is
to assume that the intruder is not aware of the presence of the controller C. In this setting, we say controller
C enforces initial-state opacity for system Σ if for any path x = x0x1 · · · xn ∈ Path(ΣC), where x0 ∈ XS,
there exists a path x(cid:48) = x(cid:48)
0 /∈ XS, such that H(x) = H(x(cid:48)). Note that, here, the
ﬁrst secret path x belongs to the closed-loop system ΣC since we consider those secret paths that can actually
happen. However, the second non-secret path x(cid:48) belongs to the open-loop system Σ as we assume that the
intruder is unaware of control C.

n ∈ Path(Σ), where x(cid:48)

1 · · · x(cid:48)

0x(cid:48)

The basic idea for solving the basic synthesis problem is to construct the corresponding (initial, current or
delayed) state-estimator Obs(Σ) based on the open-loop system Σ. Then we compose the system Σ, the state-
estimator Obs(Σ) and the deterministic Rabin automata for ϕ to obtain a new system Σ(cid:48). Then controller C
can be synthesized by solving a Rabin game over Σ(cid:48) for the Rabin acceptance condition [57] and at the same
time avoiding reaching those secret-revealing estimator states in Obs(Σ). Complete solution for this problem
can be found in [190, 199, 211, 121]; some of them do not consider the LTL mission requirement, which can
be addressed easily by combining with the standard LTL synthesis procedures.

Policy-Awareness and Imperfect Information. The above basic synthesis problem is based on the assumptions
that (i) the controller has full state information; and (ii) the intruder is unaware of the implementation of the
controller. In particular, the latter assumption is reﬂected by the fact that we choose non-secret path x(cid:48) from
the original open-loop system Path(Σ) rather than the closed-loop one Path(ΣC). However, in practice, the
control policy may become a public information, which is also available to the intruder. Then the intruder may
further use the knowledge of the controller to improve its state estimator, e.g., it can exclude some paths that
have already been disabled by the controller during the state estimation process. In order to ensure opacity
for this general case, one needs to further investigate how control aﬀects estimation in the synthesis phase.
That is, the state estimate of the intruder cannot be constructed solely based on the original open-loop system
but should also based on the synthesized control policy. Interested readers are referred to [47, 169, 218, 210]
for the complete solution to this general case for ﬁnite systems.

Another practical design consideration is the imperfect information of the controller. In practice, the controller
also may not be able to access the full state information of the system. Instead, the controller may have its own
observation speciﬁed by a new output mapping HC : X → O and a controller with imperfect information is a
function of the form C : O∗ → 2U , which determines the control input based on its own observation. Systematic
procedures for synthesizing controllers under imperfect information can be found in [14, 156, 192, 217]. In the
context of opacity-enforcing synthesis, the main diﬃculty here is that the information of the intruder and the
information of the controller may be incomparable, i.e., the equivalent classes induced by mappings H and HC
are incomparable. Interested readers are referred to [46, 47] for more discussions on this issue.

Opacity-Preserving Path Planning. The complexity of the basic opacity-enforcing controller synthesis problem
is exponential in the size of Σ due to the subset construction used in the state estimators and double-exponential
in the length of the LTL formula ϕ due to the construction of the deterministic Rabin automaton. Note that
one has to use deterministic ω-automata to realize the LTL formulae because the plant under control is non-
deterministic in general. However, when system Σ is deterministic, the basic synthesis problem becomes a
planning problem for which the computational complexity can be signiﬁcantly improved. In particular, when
system Σ is deterministic, a deterministic controller is also referred to as a plan because the trajectory of the
system can be completely determined without any uncertainty. Therefore, for planning problem, one just needs
to ﬁnd an inﬁnite path satisfying both the mission and the security requirements. The results in [61] investigate
the problem of planning a trajectory towards a target state under current-state opacity constraints. The results

20

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Figure 9. Pipeline of standard discretization-based synthesis technique.

in [216] consider the security-aware path planning problem together with LTL mission requirements. The idea
is to construct the so-called twin-system, whose size is polynomial with respect to the size of Σ, to capture the
security requirements without building the exponentially large state estimator. Furthermore, since system Σ is
already deterministic, one can further use non-deterministic B¨uchi automata, whose size is single-exponential
in the length of formula ϕ, to capture the LTL speciﬁcation.
In this case, the complexity of the opacity
synthesis can be reduced to polynomial in the size of the system and to single-exponential in the length of ϕ.

Other Opacity Enforcement Mechanisms. In the above paragraphs, we discussed the enforcement of opacity
using feedback controllers. In some applications, however, one cannot change the actual behavior of the system
directly. Therefore, many diﬀerent alternative enforcement mechanisms have also been developed by changing
the information-ﬂow available to the intruder to ensure security of the systems. For example, in [207, 79, 204],
insertion functions were used to “confuse” the intruder by adding factitious symbols to the output sequences.
Insertion functions have been further generalized to edit functions that allow not only event insertions, but
also event erasures and replacements [208, 80]. Another widely used approach is to synthesize dynamic masks
[36, 234, 21, 221, 223] that determine which information to be released to the outside world under the security
constraints. Other approaches for enforcing opacity include using run-time techniques [49] and event shuﬄes
[19].

5.2. Secure-by-Construction Controller Synthesis for CPS. The above discussed controller synthesis
techniques are developed for ﬁnite systems. Those techniques, in general, are not appropriate for CPS with
continuous-space dynamics such as systems in the form of equation (4). Unfortunately, there are only very
few recent works on the enforcement of opacity for CPS, which are discussed as follows.

Abstraction-Based Synthesis. The basic pipeline of abstraction-based or discretization-based controller synthe-
sis is shown in Figure 9. Similar to the abstraction-based veriﬁcation, in abstraction-based synthesis, one needs
to ﬁrst build the ﬁnite abstraction of the concrete CPS, and then synthesize a controller based on the ﬁnite
abstraction, and ﬁnally, reﬁne the synthesized discrete controller back as a hybrid controller to the original
CPS. Then the key question is still to ﬁnd appropriate relations between concrete systems and their ﬁnite
abstractions such that properties of interest can be preserved under controller reﬁnement.

It is well-known that the (bi)simulation relation is not suitable for the purpose of controller synthesis because
it does not take the eﬀect of control non-determinism into account [150]. To address this issue, one needs to
extend the (approximate) (bi)simulation relations to the (approximate) alternating (bi)simulation relations [6,
189]. However, although the standard alternating simulation relations preserve the LTL mission requirements,
they do not preserve security requirements. In [73], two notions of opacity-preserving alternating simulation
relations are proposed, one for initial-state opacity and one for inﬁnite-step opacity. Based on these notions,
one can synthesize opacity-enforcing controllers directly by applying existing synthesis algorithms to the ﬁnite
abstractions that opacity-preserving alternatively simulate the concrete systems. In [129], the authors propose
a two-stage approach for enforcing opacity for CPS. First, a controller ensuring the LTL mission requirement
is synthesized based on the standard alternating simulation relations without considering opacity. Then those

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

21

actions violating opacity are eliminated by a symbolic control barrier function such that security requirement
is fulﬁlled.

Abstraction-Free Synthesis. In the context of discretization-free approaches, to the best our knowledge, only the
results in [10] investigated the opacity enforcement problem for restricted classes of CPS and security notions.
Speciﬁcally, they considered CPS modeled by linear time-invariant (LTI) systems and the security requirement
is to make sure that the interference attenuation capacity of the system is opaque. Then the opacity enforce-
ment problem is formulated as an L2-gain optimization problem for LTI systems. An approximated-based
adaptive dynamic-programming (ADP) algorithm was proposed to design an opacity-enforcing controller.

5.3. Ongoing & Open Problems. In the following, we mention some ongoing research directions and open
problems regarding secure-by-construction controller synthesis. Compared with security-aware veriﬁcation,
secure-by-construction synthesis is less tackled in the literature.

Synthesis for Finite Systems. The opacity-enforcing control problem for ﬁnite systems has already been studied
for about ﬁfteen years. However, all existing solutions are either based on the assumption that the knowledge
of the supervisor and the intruder are comparable [47, 169, 218], or based on the assumption that the intruder
is unaware of the presence of the supervisor [190, 199]. The general opacity-enforcing control problem without
any assumption, to the best of our knowledge, is still open even for ﬁnite systems. Also, for networked control
systems with both control and observation channel information leakages, how to synthesize opacity-enforcing
controllers is still an open problem; so far, only the veriﬁcation problem is solved for ﬁnite systems [222, 214].
Furthermore, existing works on opacity-enforcing control mainly consider centralized control architectures. In
general, the plant may be controlled by a set of local controllers with or without communications, which leads
to the distributed [20, 84] or the decentralized control architectures [226, 149]. How to synthesize opacity-
enforcing controllers under those general information structures is still an open problem.

The high complexity or even undecidability are the major obstacles towards automated controller synthesis
of opacity. To overcome this challenge, a potential future direction is to develop bounded-synthesis [176] that
reduces the search for a bounded size implementation satisfying the synthesis objective to a SAT problem. The
key advantage of the bounded synthesis over traditional synthesis is that it constructs minimal size supervisors.
Therefore, it is a promising direction to extend the bounded synthesis approach to solve controller synthesis
problem for generalized language-based opacity by implicitly encoding the self-composition of the abstract
model. Another premising direction is to investigate security-aware synthesis for well-behaved sub-classes of
LTL such as Generalized reactivity(1) (GR(1)) [143, 27]. These are sub-classes of the form

(G F p1 ∧ . . . ∧ G F pm) =⇒ (F G q1 ∧ . . . ∧ F G qn),

where pi, qj, i ∈ {1, . . . , m}, j ∈ {1, . . . , n}, are some predicates. For GR(1) formulae, Piterman et al. [143]
showed that synthesis can be performed in (singly) exponential time. Moreover, authors argued that GR(1)
formulas are suﬃciently expressive to provide complete speciﬁcations of many designs.
It is promising to
develop an analogous result for security-aware controller-synthesis w.r.t generalized language-based opacity
properties.

Abstraction-Based Synthesis for CPS . The notions of opacity-preserving alternating simulation relations (ASR)
proposed in [73] made the ﬁrst step towards abstraction-based opacity synthesis for CPS. However, it has many
limitations that need to be addressed in the future. First, the results in [73] are developed for particular types
of state-based opacity. Similar to the veriﬁcation problem, we also need to extend the results, particularly
the underlying simulation relations, to the general case of α-opacity. Second, the opacity-preserving ASR
belongs to the category of exact simulation. This condition, in general, is too strong for general CPS with
continuous state-space. It is likely that there does not exist a ﬁnite symbolic model simulating the concrete
system exactly. One possible direction to address this issue is to enforce approximate opacity rather than the
exact version. To this end, one needs to consider the approximate ASR [150, 232] rather than the exact ASR.
Third, existing results only support state-feedback controllers, i.e., the controller knows the current-state of the
system precisely. As we discussed, an opacity-enforcing controller is observation-based in general. To address

22

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

this issue, a possible solution is to use the output-feedback reﬁnement relation (OFRR) [158, 90] instead of
the ASR. How to suitably generalize the OFRR to preserve opacity is still an open problem. Finally, although
opacity-preserving relations have been identiﬁed, there is no abstraction algorithm available so far for building
ﬁnite abstractions based on the concrete systems with continuous-space dynamics that satisfy those relations.
When the concrete system is δ-ISS, the abstraction can be done analogous to the case of veriﬁcation. The
major open problem is how to build opacity-preserving ﬁnite abstractions for the purpose of control without
the stability assumption.

Abstraction-Free Synthesis for CPS . As we have already mentioned, there are very few results for abstraction-
free opacity synthesis. One important direction is to extend the barrier-certiﬁcates techniques for opacity
veriﬁcation to opacity synthesis. To this end, one may borrow the idea of control barrier functions [9, 172]
that generalize the idea of barrier certiﬁcates to control systems by explicitly taking the eﬀect of control
choices into account. Another widely used abstraction-free technique for formal synthesis is the sampling-
based approaches [201, 86, 118].
In this approach, one can use the concrete models of CPS to randomly
generate sample paths until a satisﬁable path is found. This avoids discretizing the state-space explicitly
and under certain conditions, can provide probabilistic complete solutions. However, existing sampling-based
planning techniques can only handle LTL mission requirements. How to incorporate the security requirements
into the sampling-based process needs further developments.

6. Compositional Reasoning for Scalability

In the previous sections, we presented various discretization-based and discretization-free approaches in verify-
ing or enforcing opacity and mission requirements for CPS. Though promising, when confronted with large-scale
interconnected systems, the aforementioned results in general suﬀer from the so-called the curse of dimen-
sionality. This prevents current techniques from providing automated veriﬁcation or synthesis for large-scale
interconnected CPS. This is not just a theoretical concern, many safety-critical applications, such as traﬃc
network, automated highway driving, building management systems, power networks, air traﬃc management,
uninhabited aerial vehicles, and so on, consist of many subsystems interacting with each other. One way to
address the inherent diﬃculty in analyzing or controlling complex, large-scale, interconnected systems, is to
apply a “divide and conquer” strategy, namely, compositional approaches.

In the past decades, many potential compositionality results have been proposed to tackle the acute computa-
tional bottlenecks in the analysis of safety properties for large-scale continuous-space systems [191, 148, 91, 93,
29, 160, 187, 188, 99, 109]. However, in the context of analyzing security properties, compositional approaches
have been explored only recently for modular veriﬁcation and synthesis of DES in [168, 137, 132, 196, 212, 239]
and for continuous-space systems in [114, 111, 83].

6.1. Modular Approaches for Finite Systems. Formally, an interconnected large-scale system Σ consists
of a set of subsystems or local modules {Σ1, . . . , Σn} whose connectivities are speciﬁed by an interconnection
mapping I. In the context of ﬁnite systems or discrete-event systems, the interconnection mapping is usually
simpliﬁed as the synchronization product ⊗ over shared events. That is, the monolithic system is Σ =
Σ1 ⊗ · · · ⊗ Σn.

General Complexity Results. In the context of opacity veriﬁcation, it was ﬁrst shown by [220] that verifying
opacity for modular systems in the form of ⊗n
i=1Σi is PSPACE-hard. This complexity result was then fur-
ther improved by [125] to EXPSPACE-complete, which says that the time-complexity for verifying opacity
for modular systems grows double-exponentially fast when the number of subsystems increases. Therefore,
verifying opacity directly by computing the entire monolithic model is computationally intractable in general.
Since the opacity synthesis problem is even more diﬃcult than the veriﬁcation one, its complexity is at least
EXPSPACE-hard.

Modular Veriﬁcation. The ﬁrst modular approach for opacity veriﬁcation was provided in [168]. Speciﬁcally,
it identiﬁed a structural suﬃcient condition such that events shared by each pair of subsystems are pairwise

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

23

Figure 10. Feedback composition of two subsystems.

observable. With this structural condition, the veriﬁcation of opacity for system ⊗n
i=1Σi can be divided
as n local veriﬁcation problems for subsystems Σi, which reduces the double-exponential complexity 2|X|n
to single-exponential complexity n2|X|, where |X| = maxi=1,...,n |Xi|. More recently, the results in [196, 212]
follow the similar line of reasoning by identifying suﬃcient conditions under which current-state opacity can be
veriﬁed eﬃciently using modular approach without building the monolithic system. In [137], a compositional
abstraction technique was developed based on a notion of visible bisimulation relation. This approach was
applied to opacity veriﬁcation of modular systems by incrementally building the monolithic system while
avoiding irrelevant components for the purpose of veriﬁcation. Finally, the results in [132] investigated how
to transform the opacity veriﬁcation problem for modular systems to a non-blockingness veriﬁcation problem,
for which mature modular veriﬁcation algorithms have been developed already [134].

Modular Synthesis. Similar to the veriﬁcation problem, the existing opacity enforcing synthesis algorithms also
need the monolithic model of the system. The results in [239] investigated the opacity enforcing controller
synthesis for modular systems under the assumption that the attacker can observe the interface between each
local module. Under this assumption, opacity-enforcing controllers Ci can be synthesized for subsystems Σi
individually and the overall control system ⊗n
i=1Σi,Ci is guaranteed to be opaque. In [131], a compositional
and abstraction-based approach is proposed for synthesis of edit functions for opacity enforcement. The idea is
similar to [132] and is based on transforming the opacity synthesis problem to an existing supervisor synthesis
problem for modular system without security considerations [133]. Note that, diﬀerent from a supervisory
controller, an edit function can only change the observation of the system and not the actual behavior of the
system.

6.2. Modular Veriﬁcation for Large-scale CPS: An Abstraction-based Approach. As we have dis-
cussed in Section 4.2, opacity-preserving ﬁnite abstractions and simulation relations serve as a bridge between
continuous-space CPS and existing veriﬁcation or synthesis algorithms for opacity developed in DES commu-
nity. Although they are shown to be a useful tool in some recent results [225], a non-negligible challenge lies
in scaling the approach for large-scale systems. Typically, existing techniques reported in Section 4.2 take a
monolithic view of systems where abstraction, veriﬁcation, and synthesis are performed for the entire system.
This monolithic view interacts poorly with the construction of ﬁnite abstractions where the complexity of
the construction grows exponentially in the number of state variables in the model. Diﬀerent compositional
approaches have been proposed in the literature to overcome this challenge in dealing with large-scale CPS.
The two most commonly used schemes are based on: 1) assume-guarantee contracts [92, 173, 181] which are
originally introduced in the computer science literature and 2) the input-output properties of the system,
including those expressed as small-gain [160, 92, 148] or dissipativity properties [229, 187] which are originally
introduced in the control theory literature. Here, the overall large-scale systems are usually seen as intercon-
nections of smaller (reasonably sized) components, i.e., subsystems. Subsequently, the analysis and the design
of the overall system is reduced to those of the subsystems.

In the following, we denote a discrete-time control subsystem by a tuple Σi = (Xi, X0i, XSi, Ui, Wi, fi, Yi, Hi).
The formal deﬁnition of a control subsystem is similar to the one in (4) but with two sets of inputs. In partic-
ular, w ∈ W are termed as “internal” inputs which are used to describe the interaction between subsystems,
and u ∈ U are called “external” inputs served as interfaces for controllers. An interconnected control system

24

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Figure 11. Compositional framework for the construction of opacity-preserving ﬁnite ab-
stractions for interconnected systems.

composed of N ∈ N≥1 subsystems is iteself a discrete-time control system as in (4), denoted by I(Σ1, . . . , ΣN ),
subject to certain interconnection constraints. An example of an interconnected system composed of two
subsystems is depicted in Figure 10. Now, we brieﬂy discuss a recent result developed in [114] on the com-
positional construction of opacity-preserving ﬁnite abstractions for large-scale CPS. In order to illustrate the
main idea, let us consider the interconnected system depicted in Figure 10, which is a feedback composition of
two subsystems Σ1 and Σ2. Suppose each subsystem is denoted by Σi = (Xi, X0i , XSi, ∅, Wi, fi, Xi, id) and
for simplicity described as a discrete-time linear system:

Σi :

(cid:26) x+

i = aixi + bixj,
yi = xi,

(10)

where |ai| < 1. Let us deﬁne so-called gain functions γi = |bi/(1 − ai)| for each Σi. The main compositionality
result of [114] for this particular setting is summarized as follows.

Theorem 6.1 (Compositional Construction of Opacity Preserving Finite Abstractions).
Consider the interconnected system Σ = I(Σ1, Σ2) depicted in Figure 10, consisting of two sub-
systems Σ1 and Σ2 each described in (10). For each Σi, we construct a local ﬁnite abstraction
ˆΣi = ( ˆXi, ˆX0i , ˆXSi, ∅, ˆWi, ˆfi, ˆXi, id) as in (6) via so-called local approximate initial-state opacity-
preserving simulation functions Vi : Xi × ˆXi → R≥0 satisfying the following conditions:
1 a) ∀x0 ∈ X0i ∩XSi, ∃ˆx0i ∈ ˆX0i ∩ ˆXSi, s.t. Vi(x0i,ˆx0i) ≤ (cid:15)i;
b) ∀ˆx0 ∈ ˆX0i \ ˆXSi, ∃x0i ∈ X0i \XSi, s.t. Vi(x0i, ˆx0i) ≤ (cid:15)i;

2 ∀xi ∈ Xi, ∀ˆxi ∈ ˆXi, (cid:107)xi − ˆxi(cid:107) ≤ Vi(xi, ˆxi);
3 ∀xi ∈ Xi, ∀ˆxi ∈ ˆXi s.t. Vi(xi, ˆxi) ≤ (cid:15)i, ∀wi ∈ Wi, ∀ ˆwi ∈ ˆWi s.t. (cid:107)wi − ˆwi(cid:107) ≤ ϑi, the following hold:

a) ∀x+
b) ∀ˆx+

i , s.t. Vi(x+
i , s.t. Vi(x+

i , ˆx+
i , ∃ˆx+
i , ˆx+
i , ∃x+
where (cid:15)i, ϑi ∈ R≥0.
If γ1γ2 < 1 (similar to the small gain criterion in [233]), then V (x, ˆx) =
maxi=1,2{Vi(xi, ˆxi)} is an approximate initial-state opacity-preserving simulation function from
I(Σ1, Σ2) to I( ˆΣ1, ˆΣ2).

i ) ≤ (cid:15)i;
i ) ≤ (cid:15)i,

Note that similar results can be obtained for interconnections of N subsystems with general dynamics as
shown in [114]. More details can be found there on the compositionality results tailored to diﬀerent types of
opacity as well.

As can be observed from the theorem, the compositional framework is based on a small-gain type condition.
Small-gain theorems have a long-known history in control design dating back to the 1960’s [233]. They

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

25

have been extensively leveraged to establish stability properties of interconnected systems [81, 43]. In our
work, the small-gain type condition is imposed on the concrete network of subsystems for the existence of
proper compositional ﬁnite abstractions. More speciﬁcally, it facilitates the compositional construction of
ﬁnite abstractions by certifying a small (weak) interaction of the subsystems which prevents an ampliﬁcation
of the signals across the possible interconnections.

The intuition behind the proposed compositionality result is as follows. Instead of tackling the overall system
in a monolithic manner, the compositional scheme provided here allows us to build an abstraction for the
overall system by dealing with subsystems only. In particular, new notions of approximate opacity-preserving
simulation functions are ﬁrst introduced for both subsystems and the interconnected system, which provide
the basis for using abstraction-based techniques in verifying approximate opacity for large-scale interconnected
systems. Based on the local simulation functions, one can construct local ﬁnite abstractions for subsystems
individually. Then, under a small-gain type condition, a compositionality result is derived which ensures that
the interconnection of local abstractions mimics the behavior of the concrete interconnected system in terms
of preserving opacity. An algorithm ([114, Algorithm 1]) is provided as a guideline to design quantization
parameters of local ﬁnite abstractions. The compositionality scheme proposed in this paper is schematically
illustrated in Figure. 11.

6.3. Modular Veriﬁcation for Large-scale CPS: A Barrier Certiﬁcate Approach. As presented in
Section. 4.3, barrier certiﬁcates can be leveraged as an useful alternative approach for the veriﬁcation of opacity
for CPS. Though promising, the computation of such types of barrier certiﬁcates is still an expensive problem,
which may become intractable while dealing with large-scale interconnected systems. In this subsection, we
brieﬂy describe the recent results developed in [83] for a compositional approach for verifying approximate
opacity via the construction of barrier certiﬁcates. This result shows that by employing a small-gain type
condition, a barrier certiﬁcate for an interconnected system as in Theorem 4.5 can be constructed by composing
so-called local barrier certiﬁcates of subsystems.

Let us again consider the feedback interconnection of two subsystems Σ1 and Σ2 each described as in (10)
and associated with gain functions γi = |bi/(1 − ai)|. The main compositionality result proposed in [83] is
summarized as follows.

Theorem 6.2 (Compositional Construction of Barrier Certiﬁcates for Verifying Opacity).
Consider the interconnected system Σ = I(Σ1, Σ2) depicted in Figure 10, consisting of two subsystems
Σ1 and Σ2 each described in (10). For each Σi, we construct a so-called local barrier certiﬁcate
Bi : Xi × Xi → R for the augmented subsystem Σi × Σi satisfying the following conditions

∀(xi, ˆxi) ∈ Ri,
∀(xi, ˆxi) ∈ R0i,
∀(xi, ˆxi) ∈ Rui,
∀(xi, ˆxi) ∈ Ri, ∀(xj, ˆxj) ∈ Rj,
i , ˆx+

Bi(x+

Bi(xi, ˆxi) ≥ (cid:107)(xi, ˆxi)(cid:107),
Bi(xi, ˆxi) ≤ 0,
Bi(xi, ˆxi) > 0,

i ) ≤ (1 − ai)Bi(xi, ˆxi) + bi(cid:107)(xj, ˆxj)(cid:107),

where sets R0i and Rui are the projections of sets R0 and Ru as in (8)-(9) over the augmented
subsystem Σi × Σi.
If γ1γ2 < 1 holds, then B(x, ˆx) = maxi=1,2{Bi(xi, ˆxi)} is a barrier certiﬁcate
for the augmented interconnected system Σ × Σ, which implies that the interconnected system Σ is
δ-approximate initial-state opaque.

Note that local barrier certiﬁcates of subsystems are mainly used for constructing overall barrier certiﬁcates
for the interconnected systems, and they are not useful on their own to verify opacity properties. The above
results show that, under a small-gain type condition, a barrier certiﬁcate B for the augmented interconnected
system can be obtained by composing local barrier certiﬁcates computed for subsystems. As presented in

26

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

Sec. 4.3, if we can ﬁnd a barrier certiﬁcate for the interconnection of augmented subsystems, one obtains
that the original large-scale interconnected system is approximately initial-state opaque. Note that similar
results can be obtained for interconnections of N subsystems with general dynamics as shown in [83]. The
compositional construction of barrier certiﬁcates which implies the lack of opacity (as in Theorem.4.6) of large
CPS can be achieved by a similar framework as well.

6.4. Ongoing & Open Problems. Here, we mention some potential future directions on compositional
approaches for opacity veriﬁcation and synthesis.

Eﬃcient Models for Concurrent Systems. Interconnected systems are inherently concurrent, for which the
major computational challenge comes from the issue of state-space explosion. For discrete systems, instead of
using labeled transition systems, many alternative models have been proposed to eﬃciently represent large-
scale concurrent systems without enumerating the composed state space; one of the most widely used models
is Petri nets [35]. Using Petri nets as the underlying model for opacity veriﬁcation goes back to the seminal
work of Bryans et al. [30]. Unfortunately, it has been proved that opacity veriﬁcation is generally undecidable
for unbounded Petri nets [197, 24, 126]. On the other hand, for bounded Petri nets, many computationally
eﬃcient approaches have been developed recently by utilizing structural properties and modularity of Petri
nets to overcome the issue of state-space explosion; see, e.g., [120, 198, 42, 162, 103, 195]. However, all these
results can only be applied to ﬁnite systems. How to abstract concurrent interconnected CPS using Petri nets
while preserving opacity properties is an interesting future direction.

Leverage Existing Modular Algorithms. In the past decades, despite those opacity-related modular techniques
already mentioned in Section 6.1, there are already numerous diﬀerent modular veriﬁcation and synthesis
methods developed for other non-security properties in DES and formal methods literature. For example,
in the context of supervisory control of DES, researchers have proposed many eﬀective modular controller
synthesis approaches using, for example, state tree structures [119, 37], hierarchical interfaces [100, 71], multi-
level coordinators [94], and equivalence-based abstractions [51, 185]. There are also numerous recent works
exploring the philosophy of compositional reasoning in the context of reactive synthesis; see, e.g., [7, 123, 18].
We believe that many of the aforementioned modular/compositional approaches for non-security properties
can be generalized to incorporate the security constraints, which deserve deeper and detailed investigations.

Distributed Secure-by-Construction Synthesis. For large-scale interconnected systems, the abstract intercon-
nection constitutes several relatively smaller local ﬁnite abstractions, as investigated in Section 6.2, that run
synchronously. Since the controller synthesis problem for LTL speciﬁcations has severe worst-time complexity
(doubly exponential), computing the monolithic product of all of the ﬁnite components makes the synthesis
highly impractical. Moreover, often it may be impractical to assume that subsystems have complete knowledge
of the states of other subsystems. To model these scenarios, one can represent the system as a network of
ﬁnite abstractions where each subsystem has a separate mission and opacity requirement. Some of the states
of neighbouring local ﬁnite abstractions may be shared with other local abstractions. This gives rise to the
distributed reactive synthesis problem [174] where the system consists of several independent processes that
cooperate based on local information to accomplish a global speciﬁcation. Such a setting changes the synthesis
problem from a two-player complete-information game to two-player games of incomplete information [157].
However, even for safety and reachability objective (sub-classes of LTL), it is well known [144, 175] that the
distributed synthesis problem is undecidable for general interconnected systems. There are two directions to
achieve decidability: the ﬁrst is to restrict the network architecture [144] and the second is the approach of
bounded synthesis [176] as we have already discussed for the case of monolithic sysnthesis.

7. Future Directions

Next, we touch upon some potential directions related to the overall secure-by-construction theme that diﬀer
from the parameters of study in this technical introduction. We believe that these directions may provide
impetus to research in security-critical system design.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

27

7.1. Information-Theoretic Foundations. The concept of privacy discussed so-far in this paper is binary:
either a system leaks information or it does not leak any information. However, in practice such binary
mitigation may not be feasible and may require an information-theoretic prospective on quantifying and
minimizing the amount of information leak. Shannon, in his seminal paper [180], coined and popularized the
notion of entropy in measuring information:
for a random variable X with values in some domain X , the
entropy of (or the uncertainty about) X, denoted by H(X), is deﬁned as

H(X) =

(cid:88)

x∈X

P [X = x] log2

1
P [X = x]

.

Shannon proved that H(X) is the only function (modulo scaling) that satisﬁes the natural continuity, mono-
tonicity, and choice decomposition (See [180], for more details). Similarly, for jointly distributed random
variables X and Y , the conditional entropy H(X | Y ), i.e. uncertainty about X given Y , can be deﬁned as

H(X | Y ) =

(cid:88)

y∈Y

P [Y = y]H(X | Y = y),

where Y is the domain of Y . These deﬁnitions provide us a way to measure the information loss: if H(X)
is the uncertainty about X and if H(X | Y ) is the uncertainty about X after Y is revealed, the information
loss in this process is I(X; Y ) = H(X) − H(X | Y ). Smith [182] introduced an alternative notion of entropy
called the guessing entropy G(X) that corresponds to the number of guesses required to infer the value of X:
of course a rational strategy in guessing these values will be to guess them in a non-increasing sequence of
probability, hence G(X) = (cid:80)n
i=1 ipi where (cid:104)p1, p2, . . . , pn(cid:105) is the sequence of probabilities of elements of X
arranged in an non-increasing fashion.

The notion of opacity discussed in this paper requires that the attacker should deduce nothing about all opacity
properties of the system from observing the outputs of the system. However, achieving full opacity may not
be possible in general, because oftentimes systems reveal information depending on the secret properties. To
extend the notion of opacity to quantitative opacity, we can use the quantitative notion of information leakage.
We say that two opacity properties α, α(cid:48) are indistinguishable in Σ, and we write α ≡Σ α(cid:48), if for any trace r
satisfying α, there exists another trace r(cid:48) satisfying α(cid:48) such that both r and r(cid:48) have analogous observations,
i.e. h(r) = h(r(cid:48)). Let us generalize the original set of opacity properties from {α, ¬α} to α = {α1, . . . , αn}. In
this case, the system Σ is called opaque, if every pair of opacity properties in α are mutually indistinguishable.
Let Q = {Q1, Q2, . . . , Qk} be the quotient space of O characterized by the indistinguishability relation. Let
BQ = (cid:104)B1, B2, . . . , Bk(cid:105) be the sizes of observational equivalence classes from Q; let B = (cid:80)k
i=1 Bi. Assuming
uniform distributions on Q, K¨opf and Basin [95] characterize expressions for various information-theoretic
measures on information leaks which are given below:

1 Shannon Entropy: SE(Σ, α) = ( 1

2 Guessing Entropy: GE(Σ, α) = ( 1

B ) (cid:80)
2B ) (cid:80)

1≤i≤k

1≤i≤k

Bi log2(Bi),

B2

i + 1
2 ,

3 Min-Guess Entropy: M G(Σ, α)= min
1≤i≤k

{(Bi + 1)/2}.

This allows us to generalize our opacity requirements in a quantitative fashion. Given a property ϕ as a mission
requirement, and opacity property tuple α = {α1, . . . , αk}, an entropy bound K and the corresponding entropy
criterion κ ∈ {SE, GE, M G}, the quantitative security-aware veriﬁcation Σ |= (ϕ, α) is to decide whether Σ |=
ϕ and κ(Σ, α) ≤ K. Similarly, the quantitative security-aware synthesis is to design a supervisor/controller C
such that ΣC |= (ϕ, α).

Quantitative theory of information have been widely used for the veriﬁcation of security properties [182, 95, 16,
70] in the context of ﬁnite state and software systems. Moreover, for such systems several restricted classes of
synthesis approaches [96, 15, 235, 236, 82, 178, 194] have been proposed that focus on side-channel mitigation
techniques by increasing the remaining entropy of secret sets leaked while maintaining the performance.

28

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

7.2. Data-Driven Approaches for CPS Security. This paper assumed the access to a model of the system
and proposed security-aware veriﬁcation and synthesis approaches. Oftentimes, a true explicit model of the
system is not available or is too large to reason with formally. Reinforcement learning [186] (RL) is a sampling-
based optimization algorithm that computes optimal policies driven by scalar reward signals. Recently, RL has
been extended to work with formal logic [32, 33, 138, 68, 98], and automatic structures (ω-automata [64, 65]
and reward machines [77]) instead of scalar reward signals. A promising future direction is to extend RL-based
synthesis to reason with security properties of the system.

The controller learned via deep RL will have deep neural networks as the controllers. Additionally, deep
neural networks are often employed in place of cumbersome tabular controllers to minimize the size of the
program logic.
In such systems, security veriﬁcation need to reason with neural networks along with the
system dynamics. There is a large body of work [74, 1, 64, 152, 115, 209, 98] in verifying control systems with
neural networks using SMT solvers, and will provide a promising avenue of research in developing security
veriﬁcation and synthesis approaches for CPS with neural networks based controllers.

Radical advances in inexpensive sensors, wireless technology, and the Internet of Things (IoT) oﬀer unprece-
dented opportunities by ubiquitously collecting data at high detail and at large scale. Utilization of data
at these scales, however, poses a major challenge for verifying or designing CPS, particularly in view of the
additional inherent uncertainty that data-driven signals introduce to systems behavior and their correctness.
In fact, this eﬀect has not been rigorously understood to this date, primarily due to the missing link between
data analytics techniques in machine learning/optimization and the underlying physics of CPS. A future re-
search direction is to develop scalable data-driven approaches for formal veriﬁcation and synthesis of CPS with
unknown closed form models (a.k.a. black-box systems) with respect to both mission and security properties.
The main novelty is to bypass the model identiﬁcation phase and directly verify or synthesize controller for
CPS using system behaviors. The main reasons behind the quest to directly work on system behaviors and
bypass the identiﬁcation phase are:
i) Identiﬁcation can introduce approximation errors and have a large
computational complexity; ii) Even when the model is known, formal veriﬁcation and synthesis of CPS are
computationally challenging.

7.3. Security for Network Multi-Agent CPS. This paper mostly discussed a centralized setting for CPS
security, i.e., a single CPS plant with global secrets against a single attacker, although the CPS itself may
consist of several smaller subsystems. However, in many modern engineering systems such as connected au-
tonomous vehicles [116], smart micro-grids [227] and smart cities [34], there may exist no centralized decision-
maker.
Instead, each CPS agent interacts and collaborates/competes with each other via information ex-
changes over networks to make decisions, which leads to the network multi-agent CPS. There is a large body
of works [59, 200, 60, 85, 177, 170] in synthesizing coordination strategies for network multi-agent CPS for
high-level mission requirements using formal methods. However, the security issue, which is more severe in
multi-agent CPS due to large communications and information exchanges, is rarely considered. In particular,
in multi-agent CPS, each agent may have its own security considerations that depend on the time-varying
conﬁgurations of the entire network. Therefore, how to deﬁne formal security notions that are suitable for
multi-agent systems is an important but challenging future direction.

Recently, security and privacy considerations over networks have attracted signiﬁcant attentions in the context
of distributed state estimations [128, 11], distributed averaging/consensus [130, 63], distributed optimizations
[67, 117], and distributed machine learning [75, 105]. However, those results are mostly developed for dis-
tributed computing systems and are not directly applicable for multi-agent CPS with heterogeneous dynamics.
Furthermore, most of the existing security-aware protocols for distributed systems are designed for speciﬁc
tasks and there is still a lack of formal methodologies for security-aware veriﬁcation and secure-by-construction
synthesis of communication protocols and coordination strategies for network multi-agent CPS. Finally, rather
than a single passive attacker, network CPS may suﬀer from multiple active malicious attackers. Therefore,

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

29

one needs to develop eﬀective approaches for characterizing and controlling the evolution of security proper-
ties over dynamic networks of multiple players. A promising future direction is to develop a comprehensive
framework for multi-agent CPS security by extending formal reasoning with multi-player game-theory.

8. Conclusion

This paper may serve as an excursion into some prominent ideas and formalism from three distinct ﬁelds of for-
mal methods, discrete-event systems, and control theory to study secure-by-construction synthesis paradigm.
We intentionally kept the technical discussion at a higher-level to expand the readership and aimed to provide
necessary background and references, where appropriate. We synthesized a general setting of security-aware
veriﬁcation and secure-by-construction synthesis integrating various notions of privacy and correctness in a
common framework. While this article is primarily informed by the research interests of the authors, we hope
that it provides the basic foundations on which the related questions can be posed and answered.

We shall draw the readers’ and potential researchers’ attention that, security has been a moving goalpost
and more damaging vulnerabilities are yet unknown. The proposed approaches in this paper need to be com-
bined with classical fuzzing-based security research to uncover previously undiscovered security vulnerabilities.
Moreover, most of the existing results on security analysis for CPS remain mainly theoretical. Over the past
few years, several software tools (e.g., DESUMA [159], SUPREMICA [3], and TCT [50]) have been developed for
the analysis of DES modeled as ﬁnite automata, which are shown to be useful in the veriﬁcation or synthe-
sis of opacity properties for ﬁnite systems. Our prior research has produced software tools including SCOTS
[161], pFaces [88], OmegaThreads [89], DPDebugger [193] and Schmit [194], which provides formal, automated
abstractions of complex CPS and of reactive synthesis. There is a great need to develop eﬃcient toolboxs
and proof-of-concept benchmarks to evaluate the practical feasibility of the foundations and algorithms devel-
oped for abstracting, analyzing, or enforcing security properties over complex CPS. In addition to academic
benchmarks, it is important to improve the applicability of theoretical methods to industrial case studies and
real-life applications. Designing open access courses that provide an “end-to-end view”, starting from the
foundations of control and discrete systems theory and going into security issues for CPS is also needed to
train students, particularly those deciding to pursue research or work professionally on autonomous systems.

References

[1] A. Abate, D. Ahmed, M. Giacobbe, and A. Peruﬀo. Formal synthesis of Lyapunov neural networks. IEEE Control Systems

Letters, 5(3):773–778, 2021.

[2] M. Ahmadi, B. Wu, H. Lin, and U. Topcu. Privacy veriﬁcation in POMDPs via barrier certiﬁcates. In 57th IEEE Conference

on Decision and Control (CDC), pages 5610–5615, 2018.

[3] K. Akesson, M. Fabian, H. Flordal, and R. Malik. Supremica-an integrated environment for veriﬁcation, synthesis and
simulation of discrete event systems. In 8th International Workshop on Discrete Event Systems (WODES), pages 384–385.
IEEE, 2006.

[4] R. Alur, P. ˇCern´y, and S. Zdancewic. Preserving secrecy under reﬁnement. In Automata, Languages and Programming,

pages 107–118. Springer Berlin Heidelberg, 2006.

[5] R. Alur, T. Henzinger, G. Laﬀerriere, and G. J. Pappas. Discrete abstractions of hybrid systems. Proceedings of the IEEE,

88(7):971–984, 2000.

[6] R. Alur, T. A. Henzinger, O. Kupferman, and M. Y. Vardi. Alternating reﬁnement relations. In International Conference

on Concurrency Theory, pages 163–178. Springer, 1998.

[7] R. Alur, S. Moarref, and U. Topcu. Compositional and symbolic synthesis of reactive controllers for multi-agent systems.

Information and Computation, 261:616–633, 2018.

[8] A. D. Ames, S. Coogan, M. Egerstedt, G. Notomista, K. Sreenath, and P. Tabuada. Control barrier functions: Theory and

applications. In 18th European Control Conference (ECC), pages 3420–3431, 2019.

[9] A. D. Ames, X. Xu, J. W. Grizzle, and P. Tabuada. Control barrier function based quadratic programs for safety critical

systems. IEEE Transactions on Automatic Control, 62(8):3861–3876, 2017.

[10] L. An and G.-H. Yang. Opacity enforcement for conﬁdential robust control in linear cyber-physical systems. IEEE Trans-

actions on Automatic Control, 65(3):1234–1241, 2019.

[11] L. An and G.-H. Yang. Enhancement of opacity for distributed state estimation in cyber–physical systems. Automatica,

136:110087, 2022.

30

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

[12] M. Anand, V. Murali, A. Trivedi, and M. Zamani. Formal veriﬁcation of control systems against hyperproperties via barrier

certiﬁcates. arXiv preprint arXiv:2105.05493, 2021.

[13] D. Angeli. A Lyapunov approach to incremental stability properties. IEEE Transactions on Automatic Control, 47(3):410–

21, 2002.

[14] A. Arnold, A. Vincent, and I. Walukiewicz. Games for synthesis of controllers with partial observation. Theoretical Computer

Science, 303(1):7–34, 2003.

[15] A. Askarov, D. Zhang, and A. C. Myers. Predictive black-box mitigation of timing channels. In Proceedings of the 17th

ACM conference on Computer and communications security, pages 297–307, 2010.

[16] M. Backes, B. K¨opf, and A. Rybalchenko. Automatic discovery and quantiﬁcation of information leaks. In 30th IEEE

Symposium on Security and Privacy, pages 141–153, 2009.

[17] C. Baier and J. P. Katoen. Principles of model checking. The MIT Press, 2008.
[18] G. Bakirtzis, E. Subrahmanian, and C. H. Fleming. Compositional thinking in cyberphysical systems theory. Computer,

54(12):50–59, 2021.

[19] R. J. Barcelos and J. C. Basilio. Enforcing current-state opacity through shuﬄe and deletions of event observations. Auto-

matica, 133:109836, 2021.

[20] G. Barrett and S. Lafortune. Decentralized supervisory control with communicating controllers. IEEE Transactions on

Automatic Control, 45(9):1620–1638, 2000.

[21] B. Behinaein, F. Lin, and K. Rudie. Optimal information release for mixed opacity in discrete-event systems. IEEE Trans-

actions on Automation Science and Engineering, 16(4):1960–1970, 2019.

[22] C. Belta, B. Yordanov, and E. G¨ol. Formal Methods for Discrete-Time Dynamical Systems, volume 89. Springer Interna-

tional Publishing, 2017.

[23] B. B´erard, K. Chatterjee, and N. Sznajder. Probabilistic opacity for Markov decision processes. Information Processing

Letters, 115(1):52–59, 2015.

[24] B. B´erard, S. Haar, S. Schmitz, and S. Schwoon. The complexity of diagnosability and opacity veriﬁcation for petri nets.

Fundamenta Informaticae, 161(4):317–349, 2018.

[25] B. B´erard, J. Mullins, and M. Sassolas. Quantifying opacity. Mathematical Structures in Computer Science, 25(2):361–403,

2015.

[26] D. Bestvater, E. V. Dunn, C. Townsend, and W. Nelson. Satisfaction and wait time of patients visiting a family practice

clinic. Canadian family physician (Medecin de famille canadien), 34:67–70, 1988.

[27] R. Bloem, B. Jobstmann, N. Piterman, A. Pnueli, and Y. Sa’ar. Synthesis of reactive (1) designs. Journal of Computer and

System Sciences, 78(3):911–938, 2012.

[28] A. Borri, G. Pola, and M. D. Di Benedetto. Design of symbolic controllers for networked control systems. IEEE Transactions

on Automatic Control, 64(3):1034–1046, 2019.

[29] D. Boskos and D. V. Dimarogonas. Decentralized abstractions for feedback interconnected multi-agent systems. In 54th

IEEE Conference on Decision and Control (CDC), pages 282–287, 2015.

[30] J. W. Bryans, M. Koutny, L. Mazar´e, and P. Y. Ryan. Opacity generalised to transition systems. International Journal of

Information Security, 7(6):421–435, 2008.

[31] J. R. Buchi and L. H. Landweber. Solving sequential conditions by ﬁnite-state strategies. Transactions of the American

Mathematical Society, 138:295–311, 1969.

[32] A. Camacho, O. Chen, S. Sanner, and S. A. McIlraith. Non-Markovian rewards expressed in LTL: guiding search via reward

shaping. In Tenth Annual Symposium on Combinatorial Search, 2017.

[33] A. Camacho, R. T. Icarte, T. Q. Klassen, R. A. Valenzano, and S. A. McIlraith. LTL and beyond: Formal languages
for reward function speciﬁcation in reinforcement learning. In International Joint Conferences on Artiﬁcial Intelligence
Organization (IJCAI), volume 19, pages 6065–6073, 2019.

[34] C. G. Cassandras. Smart cities as cyber-physical social systems. Engineering, 2(2):156–158, 2016.
[35] C. G. Cassandras and S. Lafortune. Introduction to discrete event systems, volume 3. Springer, 2021.
[36] F. Cassez, J. Dubreil, and H. Marchand. Synthesis of opaque systems with static and dynamic masks. Formal Methods in

System Design, 40(1):88–115, 2012.

[37] W. Chao, Y. Gan, Z. Wang, and W. M. Wonham. Modular supervisory control and coordination of state tree structures.

International Journal of Control, 86(1):9–21, 2013.

[38] A. Church. Application of recursive arithmetic to the problem of circuit synthesis. Journal of Symbolic Logic, 28(4):289–290,

1963.

[39] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri, R. Sebastiani, and A. Tacchella. NuSMV
Version 2: An OpenSource Tool for Symbolic Model Checking. In International Conference on Computer-Aided Veriﬁcation
(CAV), volume 2404. Springer, 2002.

[40] M. R. Clarkson, B. Finkbeiner, M. Koleini, K. K. Micinski, M. N. Rabe, and C. S´anchez. Temporal logics for hyperproperties.

In Principles of Security and Trust, pages 265–284, Berlin, Heidelberg, 2014. Springer Berlin Heidelberg.
[41] M. R. Clarkson and F. B. Schneider. Hyperproperties. Journal of Computer Security, 18(6):1157–1210, 2010.
[42] X. Cong, M. P. Fanti, A. M. Mangini, and Z. Li. On-line veriﬁcation of current-state opacity by petri nets and integer linear

programming. Automatica, 94:205–213, 2018.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

31

[43] S. Dashkovskiy, B. S. R¨uﬀer, and F. R. Wirth. An ISS small gain theorem for general networks. Mathematics of Control,

Signals, and Systems, 19(2):93–122, 2007.

[44] G. De Giacomo and M. Y. Vardi. Linear temporal logic and linear dynamic logic on ﬁnite traces. In 23rd International

Joint Conference on Artiﬁcial Intelligence (IJCAI), pages 854–860. AAAI Press, 2013.

[45] L. De Moura and N. Bjørner. Z3: An eﬃcient SMT solver. In International conference on Tools and Algorithms for the

Construction and Analysis of Systems, pages 337–340. Springer, 2008.

[46] J. Dubreil, P. Darondeau, and H. Marchand. Opacity enforcing control synthesis. In 9th International Workshop on Discrete

Event Systems (WODES), pages 28–35. IEEE, 2008.

[47] J. Dubreil, P. Darondeau, and H. Marchand. Supervisory control for opacity. IEEE Transactions on Automatic Control,

55(5):1089–1100, 2010.

[48] R. Ehlers, S. Lafortune, S. Tripakis, and M. Y. Vardi. Supervisory control and reactive synthesis: a comparative introduction.

Discrete Event Dynamic Systems, 27(2):209–260, 2017.

[49] Y. Falcone and H. Marchand. Enforcement and validation (at runtime) of various notions of opacity. Discrete Event Dynamic

Systems, 25(4):531–570, 2015.

[50] L. Feng and W. M. Wonham. TCT: A computation tool for supervisory control synthesis. In 8th International Workshop

on Discrete Event Systems (WODES), pages 388–389. IEEE, 2006.

[51] L. Feng and W. M. Wonham. Supervisory control architecture for discrete-event systems. IEEE Transactions on Automatic

Control, 53(6):1449–1461, 2008.

[52] S. Gao, S. Kong, and E. M. Clarke. dReal: An SMT solver for nonlinear theories over the reals. In International conference

on automated deduction, pages 208–214. Springer, 2013.

[53] D. Genkin, A. Shamir, and E. Tromer. Rsa key extraction via low-bandwidth acoustic cryptanalysis. In Advances in

Cryptology – CRYPTO, pages 444–461. Springer Berlin Heidelberg, 2014.

[54] A. Girard, A. A. Julius, and G. J. Pappas. Approximate simulation relations for hybrid systems. Discrete event dynamic

systems, 18(2):163–179, 2008.

[55] A. Girard and G. J. Pappas. Approximation metrics for discrete and continuous systems. IEEE Transactions on Automatic

Control, 52(5):782–798, 2007.

[56] A. Girard, G. Pola, and P. Tabuada. Approximately bisimilar symbolic models for incrementally stable switched systems.

IEEE Transactions on Automatic Control, 55(1):116–126, 2010.

[57] E. Gradel and W. Thomas. Automata, logics, and inﬁnite games: a guide to current research. Springer Science & Business

Media, 2002.

[58] A. Greenberg. Hackers remotely kill a jeep on the highway—with me in in. https://www.wired.com/2015/07/hackers-re

motely-kill-jeep-highway/, 2015. Online published 21-July-2015.

[59] M. Guo and D. V. Dimarogonas. Multi-agent plan reconﬁguration under local LTL speciﬁcations. The International Journal

of Robotics Research, 34(2):218–235, 2015.

[60] M. Guo, J. Tumova, and D. V. Dimarogonas. Communication-free multi-agent control under local temporal tasks and

relative-distance constraints. IEEE Transactions on Automatic Control, 61(12):3948–3962, 2016.

[61] C. N. Hadjicostis. Trajectory planning under current-state opacity constraints. IFAC-PapersOnLine, 51(7):337–342, 2018.
[62] C. N. Hadjicostis. Estimation and Inference in Discrete Event Systems. Springer, 2020.
[63] C. N. Hadjicostis and A. D. Dom´ınguez-Garc´ıa. Privacy-preserving distributed averaging via homomorphically encrypted

ratio consensus. IEEE Transactions on Automatic Control, 65(9):3887–3894, 2020.

[64] E. M. Hahn, M. Perez, S. Schewe, F. Somenzi, A. Trivedi, and D. Wojtczak. Omega-regular objectives in model-free
reinforcement learning. In International Conference on Tools and Algorithms for the Construction and Analysis of Systems,
pages 395–412. Springer, 2019.

[65] E. M. Hahn, M. Perez, S. Schewe, F. Somenzi, A. Trivedi, and D. Wojtczak. Model-free reinforcement learning for lexico-

graphic ω-regular objectives. International Symposium on Formal Methods, 2021.

[66] D. Halperin, T. S. Heydt-Benjamin, B. Ransford, S. S. Clark, B. Defend, W. Morgan, K. Fu, T. Kohno, and W. H. Maisel.
Pacemakers and implantable cardiac deﬁbrillators: Software radio attacks and zero-power defenses. In IEEE Symposium
on Security and Privacy, pages 129–142, 2008.

[67] S. Han, U. Topcu, and G. J. Pappas. Diﬀerentially private distributed constrained optimization. IEEE Transactions on

Automatic Control, 62(1):50–64, 2017.

[68] M. Hasanbeig, A. Abate, and D. Kroening. Certiﬁed reinforcement learning with logic guidance. arXiv preprint

arXiv:1902.00778, 2019.

[69] K. Hashimoto, A. Saoud, M. Kishida, T. Ushio, and D. V. Dimarogonas. A symbolic approach to the self-triggered design

for networked control systems. IEEE Control Systems Letters, 3(4):1050–1055, 2019.

[70] J. Heusser and P. Malacaria. Quantifying information leaks in software. In Proceedings of the 26th Annual Computer

Security Applications Conference, pages 261–269. ACM, 2010.

[71] R. C. Hill, J. E. R. Cury, M. H. de Queiroz, D. M. Tilbury, and S. Lafortune. Multi-level hierarchical interface-based

supervisory control. Automatica, 46(7):1152–1164, 2010.

[72] G. Holzmann. The SPIN Model Checker: Primer and Reference Manual. Addison-Wesley Professional, 2011.
[73] J. Hou, X. Yin, S. Li, and M. Zamani. Abstraction-based synthesis of opacity-enforcing controllers using alternating simu-

lation relations. In 58th IEEE Conference on Decision and Control (CDC), pages 7653–7658, 2019.

32

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

[74] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu. Safety veriﬁcation of deep neural networks. In International conference

on computer aided veriﬁcation (CAV), pages 3–29. Springer, 2017.

[75] Y. Huang, Z. Song, K. Li, and S. Arora. Instahide: Instance-hiding schemes for private distributed learning. In International

Conference on Machine Learning, pages 4507–4518, 2020.

[76] M. Hutter and J.-M. Schmidt. The temperature side-channel and heating fault attacks. In International Conference on

Smart Card Research and Advanced Applications, volume 8419, pages 219–235. Springer, 2013.

[77] R. T. Icarte, T. Klassen, R. Valenzano, and S. McIlraith. Using reward machines for high-level task speciﬁcation and
decomposition in reinforcement learning. In International Conference on Machine Learning, pages 2107–2116, 2018.
[78] P. Jagtap, S. Soudjani, and M. Zamani. Formal synthesis of stochastic systems via control barrier certiﬁcates. IEEE

Transactions on Automatic Control, 66(7):3097–3110, 2020.

[79] Y. Ji, X. Yin, and S. Lafortune. Enforcing opacity by insertion functions under multiple energy constraints. Automatica,

108:108476, 2019.

[80] Y. Ji, X. Yin, and S. Lafortune. Opacity enforcement using nondeterministic publicly known edit functions. IEEE Trans-

actions on Automatic Control, 64(10):4369–4376, 2019.

[81] Z.-P. Jiang, A. R. Teel, and L. Praly. Small-gain theorem for ISS systems and applications. Mathematics of Control, Signals

and Systems, 7(2):95–120, 1994.

[82] S. Kadloor, N. Kiyavash, and P. Venkitasubramaniam. Mitigating timing based information leakage in shared schedulers.

In Proceedings IEEE INFOCOM, pages 1044–1052, 2012.

[83] S. T. Kalat, S. Liu, and M. Zamani. Modular veriﬁcation of opacity for interconnected control systems via barrier certiﬁcates.

IEEE Control Systems Letters, 6:890–895, 2021.

[84] G. Kalyon, T. Le Gall, H. Marchand, and T. Massart. Symbolic supervisory control of distributed systems with communi-

cations. IEEE Transactions on Automatic Control, 59(2):396–408, 2014.

[85] Y. Kantaros and M. M. Zavlanos. Distributed intermittent connectivity control of mobile robot networks. IEEE Transactions

on Automatic Control, 62(7):3109–3121, 2016.

[86] Y. Kantaros and M. M. Zavlanos. Sampling-based optimal control synthesis for multirobot systems under global temporal

tasks. IEEE Transactions on Automatic Control, 64(5):1916–1931, 2019.

[87] C. Keroglou and C. N. Hadjicostis. Probabilistic system opacity in discrete event systems. Discrete Event Dynamic Systems,

28(2):289–314, 2018.

[88] M. Khaled and M. Zamani. pFaces: An acceleration ecosystem for symbolic control. In International Conference on Hybrid

Systems: Computation and Control (HSCC), pages 252–257. ACM, 2019.

[89] M. Khaled and M. Zamani. OmegaThreads: Symbolic controller design for ω-regular objectives. In International Conference

on Hybrid Systems: Computation and Control (HSCC). ACM, 2021.

[90] M. Khaled, K. Zhang, and M. Zamani. Output-feedback symbolic control. arXiv preprint arXiv:2011.14848, 2020.
[91] E. S. Kim, M. Arcak, and S. A. Seshia. Compositional controller synthesis for vehicular traﬃc networks. In 54th IEEE

Conference on Decision and Control (CDC), pages 6165–6171, 2015.

[92] E. S. Kim, M. Arcak, and S. A. Seshia. A small gain theorem for parametric assume-guarantee contracts. In International

Conference on Hybrid Systems: Computation and Control (HSCC), pages 207–216. ACM, 2017.

[93] E. S. Kim, M. Arcak, and M. Zamani. Constructing control system abstractions from modular components. In 21st Inter-

national Conference on Hybrid Systems: Computation and Control (HSCC), pages 137–146. ACM, 2018.

[94] J. Komenda, T. Masopust, and J. H. van Schuppen. Coordination control of discrete-event systems revisited. Discrete Event

Dynamic Systems, 25(1):65–94, 2015.

[95] B. K¨opf and D. Basin. An information-theoretic model for adaptive side-channel attacks. In 14th ACM Conference on

Computer and Communications Security, pages 286–296, New York, NY, USA, 2007.

[96] B. K¨opf and M. D¨urmuth. A provably secure and eﬃcient countermeasure against timing attacks. In 22nd IEEE Symposium

on Computer Security Foundations, pages 324–335, 2009.

[97] S. Lafortune, F. Lin, and C. N. Hadjicostis. On the history of diagnosability and opacity in discrete event systems. Annual

Reviews in Control, 45:257–266, 2018.

[98] A. Lavaei, F. Somenzi, S. Soudjani, A. Trivedi, and M. Zamani. Formal controller synthesis for continuous-space MDPs via
model-free reinforcement learning. In 11th International Conference on Cyber-Physical Systems (ICCPS), pages 98–107.
IEEE, 2020.

[99] A. Lavaei, S. Soudjani, and M. Zamani. Compositional (in) ﬁnite abstractions for large-scale interconnected stochastic

systems. IEEE Transactions on Automatic Control, 65(12):5280–5295, 2020.

[100] R. J. Leduc, B. A. Brandin, M. Lawford, and W. M. Wonham. Hierarchical interface-based supervisory control-part i: serial

case. IEEE Transactions on Automatic Control, 50(9):1322–1335, 2005.

[101] E. A. Lee and S. A. Seshia. Introduction to embedded systems, a cyber-physical systems approach. MIT Press, second edition,

2017.

[102] D. Lefebvre and C. N. Hadjicostis. Exposure and revelation times as a measure of opacity in timed stochastic discrete event

systems. IEEE Transactions on Automatic Control, 66(12):5802–5815, 2020.

[103] D. Lefebvre and C. N. Hadjicostis. Privacy and safety analysis of timed stochastic discrete event systems using markovian

trajectory-observers. Discrete Event Dynamic Systems, 30(3):413–440, 2020.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

33

[104] P. Leu, I. Puddu, A. Ranganathan, and S. ˇCapkun. I send, therefore I leak: Information leakage in low-power wide area

networks. In 11th ACM Conference on Security & Privacy in Wireless and Mobile Networks, pages 23–33, 2018.

[105] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith. Federated learning: Challenges, methods, and future directions. IEEE

Signal Processing Magazine, 37(3):50–60, 2020.

[106] F. Lin. Opacity of discrete event systems and its applications. Automatica, 47(3):496–503, 2011.
[107] F. Lin, L. Y. Wang, W. Chen, W. Wang, and F. Wang. Information control in networked discrete event systems and its

application to battery management systems. Discrete Event Dynamic Systems, 30(2):243–268, 2020.

[108] L. Lindemann and D. V. Dimarogonas. Control barrier functions for signal temporal logic tasks. IEEE control systems

letters, 3(1):96–101, 2018.

[109] S. Liu, N. Noroozi, and M. Zamani. Symbolic models for inﬁnite networks of control systems: A compositional approach.

Nonlinear Analysis: Hybrid Systems, 43:101097, 2021.

[110] S. Liu, A. Swikir, and M. Zamani. Compositional veriﬁcation of initial-state opacity for switched systems. In 59th IEEE

Conference on Decision and Control (CDC), pages 2146–2151, 2020.

[111] S. Liu, A. Swikir, and M. Zamani. Veriﬁcation of approximate opacity for switched systems: A compositional approach.

Nonlinear Analysis: Hybrid Systems, 42:101084, 2021.

[112] S. Liu, X. Yin, and M. Zamani. On a notion of approximate opacity for discrete-time stochastic control systems. In American

Control Conference (ACC), pages 5413–5418. IEEE, 2020.

[113] S. Liu and M. Zamani. Veriﬁcation of approximate opacity via barrier certiﬁcates. IEEE Control Systems Letters, 5(4):1369–

1374, 2020.

[114] S. Liu and M. Zamani. Compositional synthesis of opacity-preserving ﬁnite abstractions for interconnected systems. Auto-

matica, 131:109745, 2021.

[115] A. Lomuscio and L. Maganti. An approach to reachability analysis for feed-forward relu neural networks. arXiv preprint

arXiv:1706.07351, 2017.

[116] N. Lu, N. Cheng, N. Zhang, X. Shen, and J. W. Mark. Connected vehicles: Solutions and challenges. IEEE Internet of

Things Journal, 1(4):289–299, 2014.

[117] Y. Lu and M. Zhu. Privacy preserving distributed optimization using homomorphic encryption. Automatica, 96:314–325,

2018.

[118] X. Luo, Y. Kantaros, and M. M. Zavlanos. An abstraction-free method for multirobot temporal logic optimal control

synthesis. IEEE Transactions on Robotics, 2021.

[119] C. Ma and W. Wonham. Nonblocking supervisory control of state tree structures. IEEE Transactions on Automatic Control,

51(5):782–793, 2006.

[120] Z. Ma, Y. Tong, Z. Li, and A. Giua. Basis marking representation of petri net reachability spaces and its application to the

reachability problem. IEEE Transactions on Automatic Control, 62(3):1078–1093, 2017.

[121] Z. Ma, X. Yin, and Z. Li. Veriﬁcation and enforcement of strong inﬁnite-and k-step opacity using state recognizers. Auto-

matica, 133:109838, 2021.

[122] K. Mai. Side Channel Attacks and Countermeasures, pages 175–194. Springer, New York, NY, 2012.
[123] R. Majumdar, K. Mallik, A.-K. Schmuck, and D. Zuﬀerey. Assume–guarantee distributed synthesis. IEEE Transactions on

Computer-Aided Design of Integrated Circuits and Systems, 39(11):3215–3226, 2020.

[124] R. Majumdar and A.-K. Schmuck. Supervisory controller synthesis for non-terminating processes is an obliging game. IEEE

Transactions on Automatic Control, 2022.

[125] T. Masopust and X. Yin. Complexity of detectability, opacity and a-diagnosability for modular discrete event systems.

Automatica, 101:290–295, 2019.

[126] T. Masopust and X. Yin. Deciding detectability for labeled petri nets. Automatica, 104:238–241, 2019.
[127] D. Milushev, W. Beck, and D. Clarke. Noninterference via symbolic execution. In Formal Techniques for Distributed

Systems, pages 152–168. Springer, 2012.

[128] A. Mitra and S. Sundaram. Byzantine-resilient distributed observers for LTI systems. Automatica, 108:108487, 2019.
[129] M. Mizoguchi and T. Ushio. Abstraction-based control under quantized observation with approximate opacity using symbolic

control barrier functions. IEEE Control Systems Letters, 6:2222–2227, 2022.

[130] Y. Mo and R. M. Murray. Privacy preserving average consensus. IEEE Transactions on Automatic Control, 62(2):753–765,

2017.

[131] S. Mohajerani, Y. Ji, and S. Lafortune. Compositional and abstraction-based approach for synthesis of edit functions for

opacity enforcement. IEEE Transactions on Automatic Control, 65(8):3349–3364, 2020.

[132] S. Mohajerani and S. Lafortune. Transforming opacity veriﬁcation to nonblocking veriﬁcation in modular systems. IEEE

Transactions on Automatic Control, 65(4):1739–1746, 2019.

[133] S. Mohajerani, R. Malik, and M. Fabian. A framework for compositional synthesis of modular nonblocking supervisors.

IEEE Transactions on Automatic Control, 59(1):150–162, 2014.

[134] S. Mohajerani, R. Malik, and M. Fabian. A framework for compositional nonblocking veriﬁcation of extended ﬁnite-state

machines. Discrete Event Dynamic Systems, 26(1):33–84, 2016.

[135] A. Mohsen Nia, S. Sur-Kolay, A. Raghunathan, and N. K. Jha. Physiological information leakage: A new frontier in health

information security. IEEE Transactions on Emerging Topics in Computing, 4(3):321–334, 2016.

34

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

[136] S. Nilizadeh, Y. Noller, and C. S. P˘as˘areanu. Diﬀuzz: diﬀerential fuzzing for side-channel analysis. In 41st International

Conference on Software Engineering (ICSE), pages 176–187. IEEE, 2019.

[137] M. Noori-Hosseini, B. Lennartson, and C. Hadjicostis. Compositional visible bisimulation abstraction applied to opacity

veriﬁcation. IFAC-PapersOnLine, 51(7):434–441, 2018.

[138] R. Oura, A. Sakakibara, and T. Ushio. Reinforcement learning of control policy for linear temporal logic speciﬁcations using

limit-deterministic B¨uchi automata. IEEE Control Systems Letters, 4(3):761–766, 2020.

[139] A. Papachristodoulou, J. Anderson, G. Valmorbida, S. Prajna, P. Seiler, and P. Parrilo. SOSTOOLS version 3.00 sum of

squares optimization toolbox for MATLAB. arXiv preprint arXiv:1310.4716, 2013.

[140] A. Partovi and H. Lin. Reactive supervisory control of open discrete event systems. In 58th Conference on Decision and

Control (CDC), pages 1056–1061. IEEE, 2019.

[141] C. S. Pasareanu, Q.-S. Phan, and P. Malacaria. Multi-run side-channel analysis using symbolic execution and max-smt. In

29th Computer Security Foundations Symposium (CSF), pages 387–400. IEEE, 2016.

[142] A. Peruﬀo, D. Ahmed, and A. Abate. Automated formal synthesis of neural barrier certiﬁcates for dynamical models. arXiv

preprint arXiv:2007.03251, 2020.

[143] N. Piterman, A. Pnueli, and Y. Sa’ar. Synthesis of reactive(1) designs. In Veriﬁcation, Model Checking, and Abstract

Interpretation, pages 364–380. Springer Berlin Heidelberg, 2006.

[144] A. Pneuli and R. Rosner. Distributed reactive systems are hard to synthesize. In 31st Annual Symposium on Foundations

of Computer Science, volume 2, pages 746–757, 1990.

[145] A. Pnueli and R. Rosner. On the synthesis of a reactive module. In 16th ACM SIGPLAN-SIGACT Symposium on Principles

of Programming Languages, pages 179–190. ACM, 1989.

[146] G. Pola and M. D. Di Benedetto. Control of cyber-physical-systems with logic speciﬁcations: A formal methods approach.

Annual Reviews in Control, 47:178–192, 2019.

[147] G. Pola, A. Girard, and P. Tabuada. Approximately bisimilar symbolic models for nonlinear control systems. Automatica,

44(10):2508–2516, 2008.

[148] G. Pola, P. Pepe, and M. Di Benedetto. Symbolic models for networks of control systems. IEEE Transactions on Automatic

Control, 61(11):3663–3668, 2016.

[149] G. Pola, P. Pepe, and M. D. Di Benedetto. Decentralized supervisory control of networks of nonlinear control systems.

IEEE Transactions on Automatic Control, 63(9):2803–2817, 2018.

[150] G. Pola and P. Tabuada. Symbolic models for nonlinear control systems: Alternating approximate bisimulations. SIAM

Journal on Control and Optimization, 48(2):719–733, 2009.

[151] S. Prajna, A. Jadbabaie, and G. J. Pappas. A framework for worst-case and stochastic safety veriﬁcation using barrier

certiﬁcates. IEEE Transactions on Automatic Control, 52(8):1415–1428, 2007.

[152] L. Pulina and A. Tacchella. Challenging smt solvers to verify neural networks. Ai Communications, 25(2):117–135, 2012.
[153] A. Raghunathan and N. K. Jha. Hijacking an insulin pump: Security attacks and defenses for a diabetes therapy system.

In 13th International Conference on e-Health Networking, Applications and Services, pages 150–156, 2011.

[154] P. J. Ramadge and W. M. Wonham. Supervisory control of a class of discrete event systems. SIAM Journal on Control and

Optimization, 25(1):206–230, 1987.

[155] Z. Ramezani, J. Krook, Z. Fei, M. Fabian, and K. Akesson. Comparative case studies of reactive synthesis and supervisory

control. In 18th European Control Conference (ECC), pages 1752–1759, 2019.

[156] J.-F. Raskin, T. A. Henzinger, L. Doyen, and K. Chatterjee. Algorithms for omega-regular games with imperfect information.

Logical Methods in Computer Science, 3, 2007.

[157] J. H. Reif. The complexity of two-player games of incomplete information. Journal of Computer and System Sciences,

29(2):274 – 301, 1984.

[158] G. Reissig, A. Weber, and M. Rungger. Feedback reﬁnement relations for the synthesis of symbolic controllers. IEEE

Transactions on Automatic Control, 62(4):1781–1796, 2017.

[159] L. Ricker, S. Lafortune, and S. Genc. DESUMA: A tool integrating GIDDES and UMDES. In 8th International Workshop

on Discrete Event Systems (WODES), pages 392–393. IEEE, 2006.

[160] M. Rungger and M. Zamani. Compositional construction of approximate abstractions of interconnected control systems.

IEEE Transactions on Control of Network Systems, 5(1):116–127, 2016.

[161] M. Rungger and M. Zamani. SCOTS: A tool for the synthesis of symbolic controllers. In International Conference on Hybrid

Systems: Computation and Control (HSCC), pages 99–104. ACM, 2016.

[162] I. Saadaoui, Z. Li, and N. Wu. Current-state opacity modelling and veriﬁcation in partially observed petri nets. Automatica,

116:108907, 2020.

[163] A. Saboori and C. Hadjicostis. Veriﬁcation of k-step opacity and analysis of its complexity. IEEE Transactions on Automa-

tion Science and Engineering, 8(3):549–559, 2011.

[164] A. Saboori and C. Hadjicostis. Veriﬁcation of inﬁnite-step opacity and complexity considerations. IEEE Transactions on

Automatic Control, 57(5):1265–1269, 2012.

[165] A. Saboori and C. Hadjicostis. Veriﬁcation of initial-state opacity in security applications of discrete event systems. Infor-

mation Sciences, 246:115–132, 2013.

[166] A. Saboori and C. Hadjicostis. Current-state opacity formulations in probabilistic ﬁnite automata. IEEE Transactions on

Automatic Control, 59(1):120–133, 2014.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

35

[167] A. Saboori and C. N. Hadjicostis. Notions of security and opacity in discrete event systems. In 46th IEEE Conference on

Decision and Control (CDC), pages 5056–5061, 2007.

[168] A. Saboori and C. N. Hadjicostis. Reduced-complexity veriﬁcation for initial-state opacity in modular discrete event systems.

IFAC Proceedings Volumes, 43(12):78–83, 2010.

[169] A. Saboori and C. N. Hadjicostis. Opacity-enforcing supervisory strategies via state estimator constructions. IEEE Trans-

actions on Automatic Control, 57(5):1155–1165, 2011.

[170] Y. E. Sahin, N. Ozay, and S. Tripakis. Multi-agent coordination subject to counting constraints: A hierarchical approach.

In Distributed Autonomous Robotic Systems, pages 265–281. Springer, 2019.

[171] A. Sakakibara, N. Urabe, and T. Ushio. Finite-memory supervisory control of discrete event systems for LTL [f] speciﬁca-

tions. IEEE Transactions on Automatic Control, 2022.

[172] C. Santoyo, M. Dutreix, and S. Coogan. A barrier function approach to ﬁnite-time stochastic system veriﬁcation and control.

Automatica, 125:109439, 2021.

[173] A. Saoud, A. Girard, and L. Fribourg. Assume-guarantee contracts for continuous-time systems. Automatica, 134:109910,

2021.

[174] S. Schewe. Synthesis of distributed systems. PhD thesis, Saarland University, Saarbr¨ucken, Germany, 2008.
[175] S. Schewe. Distributed synthesis is simply undecidable. Information Processing Letters, 114(4):203 – 207, 2014.
[176] S. Schewe and B. Finkbeiner. Bounded synthesis. In International Symposium on Automated Technology for Veriﬁcation

and Analysis, pages 474–488, 2007.

[177] P. Schillinger, M. B¨urger, and D. V. Dimarogonas. Simultaneous task allocation and planning for temporal logic goals in

heterogeneous multi-robot systems. The international journal of robotics research, 37(7):818–838, 2018.

[178] S. Schinzel. An eﬃcient mitigation method for timing side channels on the web. In 2nd International Workshop on Con-

structive Side-Channel Analysis and Secure Design (COSADE), 2011.

[179] A.-K. Schmuck, T. Moor, and R. Majumdar. On the relation between reactive synthesis and supervisory control of non-

terminating processes. Discrete Event Dynamic Systems, 30(1):81–124, 2020.

[180] C. E. Shannon. A mathematical theory of communication. The Bell system technical journal, 27(3):379–423, 1948.
[181] M. Sharf, B. Besselink, A. Molin, Q. Zhao, and K. H. Johansson. Assume/guarantee contracts for dynamical systems:

Theory and computational tools. IFAC-PapersOnLine, 54(5):25–30, 2021.

[182] G. Smith. On the foundations of quantitative information ﬂow. In International Conference on Foundations of Software

Science and Computational Structures, pages 288–302. Springer, 2009.

[183] M. Sousa and I. Dillig. Cartesian hoare logic for verifying k-safety properties. In 37th ACM SIGPLAN Conference on

Programming Language Design and Implementation, volume 51, pages 57–69, 2016.

[184] J. F. Sturm. Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones. Optimization methods and

software, 11(1-4):625–653, 1999.

[185] R. Su, J. H. van Schuppen, and J. E. Rooda. Model abstraction of nondeterministic ﬁnite-state automata in supervisor

synthesis. IEEE Transactions on automatic control, 55(11):2527–2541, 2010.

[186] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018.
[187] A. Swikir, A. Girard, and M. Zamani. From dissipativity theory to compositional synthesis of symbolic models. In Indian

Control Conference (ICC), pages 30–35. IEEE, 2018.

[188] A. Swikir and M. Zamani. Compositional synthesis of ﬁnite abstractions for networks of systems: A small-gain approach.

Automatica, 107:551–561, 2019.

[189] P. Tabuada. Veriﬁcation and Control of Hybrid Systems: A Symbolic Approach. Springer Science & Business Media, 2009.
[190] S. Takai and Y. Oka. A formula for the supremal controllable and opaque sublanguage arising in supervisory control. SICE

Journal of Control, Measurement, and System Integration, 1(4):307–311, 2008.

[191] Y. Tazaki and J. Imura. Bisimilar ﬁnite abstractions of interconnected systems. In M. Egerstedt and B. Mishra, editors,
International Conference on Hybrid Systems: Computation and Control (HSCC), volume 4981, pages 514–527. Springer
Verlag, Berlin Heidelberg, 2008.

[192] J. G. Thistle and H. Lamouchi. Eﬀective control synthesis for partially observed discrete-event systems. SIAM Journal on

Control and Optimization, 48(3):1858–1887, 2009.

[193] S. Tizpaz-Niari, P. Cerny, B.-Y. E. Chang, and A. Trivedi. Diﬀerential performance debugging with discriminant regression

trees. In AAAI Conference on Artiﬁcial Intelligence, pages 2468–2475, 2018.

[194] S. Tizpaz-Niari, P. Cern´y, and A. Trivedi. Quantitative mitigation of timing side channels. In International Conference on

Computer Aided Veriﬁcation (CAV), volume 11561, pages 140–160. Springer, 2019.

[195] G. D. Tommasi, C. Motta, A. Petrillo, and S. Santini. Optimization-based assessment of initial-state opacity in petri nets.

In Optimization and Data Science: Trends and Applications, pages 127–138. Springer, 2021.

[196] Y. Tong and H. Lan. Current-state opacity veriﬁcation in modular discrete event systems. In 58th IEEE Conference on

Decision and Control (CDC), pages 7665–7670, 2019.

[197] Y. Tong, Z. Li, C. Seatzu, and A. Giua. Decidability of opacity veriﬁcation problems in labeled petri net systems. Automatica,

80:48–53, 2017.

[198] Y. Tong, Z. Li, C. Seatzu, and A. Giua. Veriﬁcation of state-based opacity using petri nets. IEEE Transactions on Automatic

Control, 62(6):2823–2837, 2017.

36

SIYUAN LIU1,2, ASHUTOSH TRIVEDI3, XIANG YIN4, AND MAJID ZAMANI3,2

[199] Y. Tong, Z. Li, C. Seatzu, and A. Giua. Current-state opacity enforcement in discrete event systems under incomparable

observations. Discrete Event Dynamic Systems, 28(2):161–182, 2018.

[200] J. Tumova and D. V. Dimarogonas. Multi-agent planning under local LTL speciﬁcations and event-based synchronization.

Automatica, 70:239–248, 2016.

[201] C. I. Vasile and C. Belta. Sampling-based temporal logic path planning. In International Conference on Intelligent Robots

and Systems, pages 4817–4822. IEEE, 2013.

[202] S. Walters. How can drones be hacked? https://medium.com/@swalters/how-can-drones-be-hacked-the-updated-list-

of-vulnerable-drones-attack-tools-dd2e006d6809, 2016. Online published 19-Oct-2016.

[203] L. Wang, A. D. Ames, and M. Egerstedt. Safety barrier certiﬁcates for collisions-free multirobot systems. IEEE Transactions

on Robotics, 33(3):661–674, 2017.

[204] B. Wu, J. Dai, and H. Lin. Synthesis of insertion functions to enforce decentralized and joint opacity properties of discrete-

event systems. In American Control Conference (ACC), pages 3026–3031. IEEE, 2018.

[205] M. Wu, S. Guo, P. Schaumont, and C. Wang. Eliminating timing side-channel leaks using program repair. In 27th ACM

SIGSOFT International Symposium on Software Testing and Analysis, pages 15–26, 2018.

[206] Y.-C. Wu and S. Lafortune. Comparative analysis of related notions of opacity in centralized and coordinated architectures.

Discrete Event Dynamic Systems, 23(3):307–339, 2013.

[207] Y.-C. Wu and S. Lafortune. Synthesis of insertion functions for enforcement of opacity security properties. Automatica,

50(5):1336–1348, 2014.

[208] Y.-C. Wu, V. Raman, B. C. Rawlings, S. Lafortune, and S. A. Seshia. Synthesis of obfuscation policies to ensure privacy

and utility. Journal of Automated Reasoning, 60(1):107–131, 2018.

[209] W. Xiang and T. T. Johnson. Reachability analysis and safety veriﬁcation for neural network control systems. arXiv preprint

arXiv:1805.09944, 2018.

[210] Y. Xie, X. Yin, and S. Li. Opacity enforcing supervisory control using non-deterministic supervisors. IEEE Transactions

on Automatic Control, 2021.

[211] Y. Xie, X. Yin, S. Li, and M. Zamani. Secure-by-construction controller synthesis for stochastic systems under linear

temporal logic speciﬁcations. In 60th IEEE Conference on Decision and Control (CDC), pages 7015–7021, 2021.

[212] J. Yang, W. Deng, and D. Qiu. Current-state opacity and initial-state opacity of modular discrete event systems. Interna-

tional Journal of Control, pages 1–24, 2021.

[213] J. Yang, W. Deng, D. Qiu, and C. Jiang. Opacity of networked discrete event systems. Information Sciences, 543:328–344,

2021.

[214] S. Yang, J. Hou, X. Yin, and S. Li. Opacity of networked supervisory control systems over insecure communication channels.

IEEE Transactions on Control of Network Systems, 8(2):884–896, 2021.

[215] S. Yang and X. Yin. Secure your intention: On notions of pre-opacity in discrete-event systems. arXiv preprint

arXiv:2010.14120, 2020.

[216] S. Yang, X. Yin, S. Li, and M. Zamani. Secure-by-construction optimal path planning for linear temporal logic tasks. In

59th IEEE Conference on Decision and Control (CDC), pages 4460–4466, 2020.

[217] X. Yin and S. Lafortune. Synthesis of maximally permissive supervisors for partially observed discrete event systems. IEEE

Transactions on Automatic Control, 61(5):1239–1254, 2016.

[218] X. Yin and S. Lafortune. A uniform approach for synthesizing property-enforcing supervisors for partially-observed discrete-

event systems. IEEE Transactions on Automatic Control, 61(8):2140–2154, 2016.

[219] X. Yin and S. Lafortune. A new approach for the veriﬁcation of inﬁnite-step and K-step opacity using two-way observers.

Automatica, 80:162–171, 2017.

[220] X. Yin and S. Lafortune. Veriﬁcation complexity of a class of observational properties for modular discrete events systems.

Automatica, 83:199–205, 2017.

[221] X. Yin and S. Lafortune. A general approach for optimizing dynamic sensor activation for discrete event systems. Automatica,

105:376–383, 2019.

[222] X. Yin and S. Li. Veriﬁcation of opacity in networked supervisory control systems with insecure control channels. In 57th

IEEE Conference on Decision and Control (CDC), pages 4851–4856, 2018.

[223] X. Yin and S. Li. Synthesis of dynamic masks for inﬁnite-step opacity. IEEE Transactions on Automatic Control, 65(4):1429–

1441, 2020.

[224] X. Yin, Z. Li, W. Wang, and S. Li. Inﬁnite-step opacity and k-step opacity of stochastic discrete-event systems. Automatica,

99:266–274, 2019.

[225] X. Yin, M. Zamani, and S. Liu. On approximate opacity of cyber-physical systems. IEEE Transactions on Automatic

Control, 66(4):1630–1645, 2021.

[226] T.-S. Yoo and S. Lafortune. A general architecture for decentralized supervisory control of discrete-event systems. Discrete

Event Dynamic Systems, 12(3):335–377, 2002.

[227] X. Yu and Y. Xue. Smart grids: A cyber–physical systems perspective. Proceedings of the IEEE, 104(5):1058–1070, 2016.
[228] M. Zamani, A. Abate, and A. Girard. Symbolic models for stochastic switched systems: A discretization and a discretization-

free approach. Automatica, 55:183–196, 2015.

[229] M. Zamani and M. Arcak. Compositional abstraction for networks of control systems: A dissipativity approach. IEEE

Transactions on Control of Network Systems, 5(3):1003–1015, 2018.

SECURE-BY-CONSTRUCTION SYNTHESIS OF CYBER-PHYSICAL SYSTEMS

37

[230] M. Zamani, P. M. Esfahani, R. Majumdar, A. Abate, and J. Lygeros. Symbolic control of stochastic systems via approxi-

mately bisimilar ﬁnite abstractions. IEEE Transactions on Automatic Control, 59(12):3135–3150, 2014.

[231] M. Zamani, M. Mazo, M. Khaled, and A. Abate. Symbolic abstractions of networked control systems. IEEE Transactions

on Control of Network Systems, 5(4):1622–1634, 2018.

[232] M. Zamani, G. Pola, M. Mazo, and P. Tabuada. Symbolic models for nonlinear control systems without stability assumptions.

IEEE Transactions on Automatic Control, 57(7):1804–1809, 2012.

[233] G. Zames. On the input-output stability of time-varying nonlinear feedback systems part one: Conditions derived using

concepts of loop gain, conicity, and positivity. IEEE transactions on automatic control, 11(2):228–238, 1966.

[234] B. Zhang, S. Shu, and F. Lin. Maximum information release while ensuring opacity in discrete event systems. IEEE

Transactions on Automation Science and Engineering, 12(3):1067–1079, 2015.

[235] D. Zhang, A. Askarov, and A. C. Myers. Predictive mitigation of timing channels in interactive systems. In Proceedings of

the 18th ACM conference on Computer and communications security, pages 563–574. ACM, 2011.

[236] D. Zhang, A. Askarov, and A. C. Myers. Language-based control and mitigation of timing channels. SIGPLAN Notices,

47(6):99–110, 2012.

[237] K. Zhang, X. Yin, and M. Zamani. Opacity of nondeterministic transition systems: A (bi)simulation relation approach.

IEEE Transactions on Automatic Control, 64(12):5116–5123, 2019.

[238] Z. Zhang, S. Shu, and C. Xia. Networked opacity for ﬁnite state machine with bounded communication delays. Information

Sciences, 572:57–66, 2021.

[239] G. Zinck, L. Ricker, H. Marchand, and L. H´elou¨et. Enforcing opacity in modular systems. IFAC-PapersOnLine, 53(2):2157–

2164, 2020.

1Department of Electrical and Computer Engineering, Technical University of Munich, 80333 Munich, Germany

Email address: sy.liu@tum.de

2Department of Computer Science, LMU Munich, 80538 Munich, Germany

3Department of Computer Science, University of Colorado Boulder, CO 80309, USA

Email address: ashutosh.trivedi@colorado.edu,majid.zamani@colorado.edu

4Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China

Email address: yinxiang@sjtu.edu.cn

