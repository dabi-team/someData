1

0
2
0
2

b
e
F
7

]
T
G
.
s
c
[

2
v
6
0
5
3
0
.
2
0
9
1
:
v
i
X
r
a

A Game of Drones: Cyber-Physical Security of Time-Critical UAV

Applications with Cumulative Prospect Theory Perceptions and Valuations
Anibal Sanjab1,2, Walid Saad1, and Tamer Bas¸ar3
1 Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA,

2 Flemish Institute for Technological Research, VITO/EnergyVille, Genk, Belgium, Email: anibal.sanjab@vito.be

3 Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, IL, USA, Email: basar1@illinois.edu

Emails: {anibals,walids}@vt.edu

Abstract

In this paper, a novel mathematical framework is introduced for modeling and analyzing the cyber-physical security

of time-critical UAV applications. A general UAV security network interdiction game is formulated to model interactions

between a UAV operator and an interdictor, each of which can be benign or malicious. In this game, the interdictor

chooses the optimal location(s) from which to target the drone system by interdicting the potential paths of the UAVs.

Meanwhile, the UAV operator responds by ﬁnding an optimal path selection policy that enables its UAVs to evade attacks

and minimize their mission completion time. New notions from cumulative prospect theory (PT) are incorporated into

the game to capture the operator’s and interdictor’s subjective valuations of mission completion times and perceptions

of the risk levels facing the UAVs. The equilibrium of the game, with and without PT, is then analytically characterized

and studied. Novel algorithms are then proposed to reach the game’s equilibria under both PT and classical game theory.

Simulation results show the properties of the equilibrium for both the rational and PT cases. The results show that the

operator’s and interdictor’s bounded rationality is more likely to be disadvantageous to the UAV operator.

Unmanned Aerial Vehicles, Cyber-Physical Systems, Security, Network Interdiction Games, Game Theory, Cumu-

Index Terms

lative Prospect Theory.

I. INTRODUCTION

Recent developments in unmanned aerial vehicle (UAV) technology have led to its adoption in various

applications such as telecommunications, surveillance, delivery systems, rescue operations, and intelligence

missions [1]–[6]. Due to their ability to reach relatively inaccessible locations (such as natural disaster sites,

remote mountains, valleys, and forests) and their capacity to travel without being restricted to predeﬁned

pathways, UAVs can effectively carry out time-critical missions [1], [7]–[9].

A. Time Critical UAV Applications and Security Challenges

One prominent time-critical UAV application is drone delivery systems [6]–[15] which can be used to

deliver consumer parcels [6], [10]–[12] (with Amazon Prime Air [10] and Google’s Project Wing [6] being

key examples) as well as emergency medical products [7]–[9]. However, the practical deployment of drone

delivery systems can be hindered by their vulnerability to a myriad of cyber and physical attacks [16]–[22]. On

 
 
 
 
 
 
2

the physical side, to avoid conﬂict with manned and commercial aviations, the altitude of UAVs is typically

limited to around 400 ft [23], putting them in the range of hunting riﬂes and ﬁrearms. Moreover, UAVs are

vulnerable to a variety of cyber threats as demonstrated in [16]–[22]. For example, the work in [16] provided

a general overview of cyber attacks which can target the conﬁdentiality, integrity, and availability of UAV

systems. The authors in [17] focused on the security of the communication links between ground control and

unmanned aircrafts. Moreover, the authors in [18] successfully launched a man-in-the-middle attack against

a typical UAV used by law enforcement agencies for critical applications. Meanwhile, the authors in [19]

and [20] investigated GPS spooﬁng attacks to manipulate the trajectory of an autonomous UAV while the

work in [21] considered jamming, spooﬁng, and eavesdropping attacks which can target UAV systems. In

addition, the authors in [22] surveyed various detection and localization techniques as well as cyber-physical

attacks which can be used against UAVs.

On the other hand, the ability of drones to reach secure or private locations has raised concerns regarding

their possible usage for executing malicious missions, with recent real-world incidents at Gatwick airport in

the UK [23]. For instance, a number of recent works, such as [22] and [24], studied the risks of potentially

using UAVs to execute nefarious missions such as targeting a public, political, or military ﬁgure in a secure

perimeter, intruding into a military secure perimeter, smuggling illicit products, or gaining unauthorized access

to personal property. This has led to the development of what is known as anti-drone systems whose goal is

to defend against intruding drones as discussed in [22] and [24]. The interactions between intruding drones

and anti-drone systems is clearly another highly time-critical application of UAVs, beyond delivery systems.

Security analyses of these two time-critical UAV applications involve: a) a UAV aiming to achieve a mission

(benign or malicious) in the shortest possible time and b) an interdictor (malicious, e.g., in drone delivery

systems, or benign, e.g., in anti-drone systems) whose goal is to interdict and delay the UAV and compromise

its mission. The highly intertwined decision making processes of these two scenarios motivate the need for

a holistic strategic analysis which can capture this underlying interdependent decision making processes and

identify optimal interdiction and security strategies. However, beyond our preliminary work in [25] on the

security of drone delivery systems, which was limited to a static analysis1, prior art [16]–[22], [24], and

references therein, have somewhat remarkably ignored such interactive time-critical situations and, instead,

have either provided qualitative analyses or focused on speciﬁc and isolated security experiments, rather than

on a comprehensive study.

1Our current work advances and generalizes our preliminary results presented in [25]. Our preliminary work [25] considered a static environment

while the current work treats a general setting in which the UAV performs a repeated path selection decision making aiming at minimizing a

cumulative mission completion time. In addition, the results in [25] mainly relied on numerical simulations while the current work presents

rigorous analytical derivation and results.

3

B. Summary of Contributions

The main contribution of this paper is to develop the ﬁrst comprehensive framework for the modeling and

analysis of the cyber-physical security of time-critical UAV applications. We pose the general problem as a

network interdiction game with a leader-follower structure between an interdictor (malicious or benign) and a

UAV operator (benign or malicious). In this game, the interdictor (i.e. the leader) chooses the optimal attack

locations along the area which can be traversed by the UAV to interdict the UAV, via a cyber or physical

attack, with the goal of delaying the UAV and compromising its mission. On the other hand, the UAV (i.e.

the follower) acts as an evader that chooses the best path selection policy from its origin to its destination,

while evading attacks and minimizing its total expected travel time (hereinafter called the expected delivery

time) needed to complete the mission. We consider both deterministic and probabilistic interdiction strategies.

First, with deterministic interdiction strategies, we derive and analyze the Stackelberg equilibrium (SE) of

the game. We then show that a probabilistic interdiction strategy gives rise to a game structure in which

the UAV’s problem corresponds to ﬁnding an optimal policy in a Markov Decision Process (MDP) and the

interdictor’s problem corresponds to setting the parameters of this MDP. In this regard, we characterize the

SE of the game with mixed interdiction strategies, and propose practical algorithms to solve the underlying

UAV operator’s and interdictor’s problems.

The aforementioned analysis captures the decision making processes of the agents considering that they

are fully rational, i.e., they assess delivery times and perceive risk levels objectively. In order to capture

wider practical application settings, our work also considers the interdictor’s and UAV operator’s potential

subjectivity, i.e. bounded rationality. For instance, time-critical UAV applications aim at strictly accomplishing

a mission within a target delivery time as delays in such applications can have tragic consequences. Given

this time criticality, the merit of an achieved delivery time can be valued relatively to the target delivery

time, rather than as an absolute quantity, and this valuation can be performed subjectively and differently

by the UAV operator and the interdictor. In addition, the choices of interdiction and path selection strategies

are inﬂuenced by various underlying uncertainties which stem, for example, from the probabilistic risk levels

of a certain path and the likelihood with which a carried out cyber-physical attack is successful. Hence,

due to these uncertainties, the likelihood of achieving a certain delivery time can be perceived and assessed

differently by the interdictor and the UAV operator2. Classical game theory does not capture such subjective

valuations and perceptions as it assumes full rationality of the players, which for our game implies that both

players assess delivery times and their probability of occurrence objectively and similarly. Thus, to capture

these bounded rationality factors in our game, we extend our analysis by using tools from cumulative prospect

2The subjective valuation of outcomes and distorted perception of probabilities in decision making under risk have been repeatedly observed

and quantiﬁed in various empirical analyses such as in [26] and [27].

4

G(N , E)

O, D ∈ N

H

t(i, j): E → R

pn

ta

f h(n)

Z = {I, U }

x ∈ X

Ed(n, h)

TABLE I

SUMMARY OF MAIN NOTATIONS.

Directed security graph

O: Origin node, D: Destination node

Set of O-to-D paths over G

Travel time from node i to j over ek = (i, j) ∈ E

Attack success probability at n ∈ N

Re-handling time

Travel time from O to n ∈ N following h ∈ H

Set of players: I (interdcitor), U (UAV operator)

Generic mixed-strategy interdiction

Expected deliver time for pure-strategy interdiction at n and UAV path h

M (i, j; (x, k)) MDP transition probability from state i to j for a mixed-strategy interdiction x and U ’s action k

r (i, j; (x, k))

MDP i to j state transition instantaneous cost/reward

πx ∈ P

hπx

Eπx (O; x)

Vi(n, h)

Ξi(x, h)

Path selection policy for MDP deﬁned by x ∈ X

O-to-D path resulting from policy πx

Expected delivery time under policy πx

PT valuation by i ∈ Z of strategy pair (n ∈ N , h ∈ H)

PT valuation by i ∈ Z of strategy pair (x ∈ X , h ∈ H)

theory3 (PT) [26]. In this respect, we consider both deterministic and probabilistic strategies in the PT game

analysis. We derive closed-from analytical expressions of the PT valuations of the interdictor and the UAV

operator, and prove their convergence. Then, we analytically derive the SE of the deterministic PT game, and

propose solution algorithms that deliver numerically the SE of the PT game with mixed interdiction strategies.

We complement our theoretical analysis with extensive simulations, where our results provide key insights

into the effects of PT on the equilibrium strategies and achieved delivery times. For example, the numerical

results show that the PT bounded rationality of the players is in general disadvantageous to the UAV operator,

leading to expected delivery times that exceed the pre-set target delivery times and highlighting the need for

proper PT game modeling when specifying such target times.

The rest of this paper is organized as follows. Section II presents the system model and formulates the

proposed network interdiction game with fully rational players. Section III and Section IV study the game

under deterministic and probabilistic interdiction strategies, respectively. Section V studies the PT game.

Numerical results are presented in Section VI; while conclusions and future directions are discussed in

Section VII. A summary of our main notations is given in Table I.

3Cumulative prospect theory [26] provides a reﬁnement and generalization of traditional prospect theory [27]–[30] allowing it to accommodate

a large number of outcomes as needed in this work.

5

II. SYSTEM MODEL AND PROBLEM FORMULATION

A. System Model

Consider a drone system in which a UAV, controlled by an operator, executes a time-critical mission

requiring it to travel from a source location O to a destination location D in minimum time, referred to as

the delivery time. Meanwhile, an interdictor seeks to interdict the UAV’s ﬂight by choosing a certain area or

location, among a number of “danger points” along its path from O to D, to launch a cyber-physical attack.

The interdictor’s attacks [16]–[19], [22] include physical attacks against the UAV (such as using riﬂes or a

military defense system) as well as cyber attacks (such as de-authentication or GPS spooﬁng attacks) which

cause the UAV operator to lose control of the drone. Our model readily captures two time-critical UAV use

cases: a) The drone delivery system case in which the UAV is a benign player and the interdictor is malicious,

and b) the anti-drone scenario in which the interdictor is an anti-drone system seeking to stop a rogue (or

malicious) drone from reaching its destination.

A danger point represents a location (or area) along the possible paths between O and D, from which the

UAV is exposed to possible cyber-physical attacks. Such points can represent locations of high altitude, which

allow line-of-sight and spatial proximity (e.g., high hills, high-rise buildings, etc.) between a potential attacker

and the UAV. As a result, the set of danger points between O and D correspond to inevitable locations along

the drone’s ﬂight paths that are susceptible to attacks by a malicious interdictor or an anti-drone system. The

set of danger points between O and D deﬁne a security network represented by a directed graph G(N , E),

as shown in Fig. 1, in which the set of vertices, N , is the set of N danger points between O and D, and

the set of edges, E, such that |E| = E, is the set of connections between these danger points. Given that, in

practice, the UAV’s travel from origin to destination may not be restricted to predeﬁned airways, there can

be an inﬁnite number of paths which connect O to D. However, each one of these paths will go through

a number of danger points that may be shared among different paths. This inﬁnite set of possible O to D

paths can, from a security viewpoint, be represented by the set of danger points that each path traverses.

Given the time-critical nature of the considered UAV applications, the deﬁned set of edges E in the security

graph G will comprise the shortest paths between each two danger points. For two neighboring points i and
j connected by edge ek ∈ E, we let t(i, j), t(.) : E → R, be the time that the UAV needs to travel from i

to j over ek. We let pn be the probability with which an attack launched from point n ∈ N is successful.
Without loss of generality, we consider that for any n ∈ N \ {O, D}, pn (cid:54)= 0; and for n(cid:48) ∈ {O, D}, pn(cid:48) = 0.
We deﬁne H to be the set of H paths (containing no repeated vertices4) from the origin, O, to destination,

4Cycles are naturally dismissed by a UAV operator aiming to minimize delivery time.

6

Fig. 1.

Illustration of a security graph with 10 danger points.

D, over the security graph G. For each path5 h ∈ H, we deﬁne a distance function f h(.): h → R, which

takes an input node n ∈ h and returns the time needed by the UAV to reach n ∈ h from O following path
h ∈ H. For example, in Fig. 1, f h(cid:48)(5) = t2 + t6 where h(cid:48) (cid:44) (1, 3, 5, 8, 10).

On this security graph G, the interdictor aims at ﬁnding the best interdiction strategy (a choice of danger

points from which to launch an attack) to intercept/delay the travel of the UAV while the UAV acts as an

evader who aims at ﬁnding the best travel policy, and as a result a path selection strategy, to reach D from

O in a minimum delivery time.

B. Game-Theoretic Problem Formulation

The UAV operator, denoted by player U , must ﬁnd the best possible path for the UAV to take over graph G

to reach D from O in minimum time while accounting for the presence of the interdictor (player I). In case

the UAV is successfully compromised by the interdictor from a node n ∈ N , U will have to resend a new UAV

with the same mission from node O, which leads to both ﬁnancial losses and delayed delivery time. Hence,

a successful attack by I at node n can be mathematically modeled as if the UAV had returned to the point

of origin from which it needs to travel again to its destination. Hence, with the goal of minimizing delivery

time, U may not always choose the shortest O-to-D path if this path is suspected to be risky. Hence, the

path selection strategy must account for possible interdiction strategies so as to successfully accomplish the

O-to-D mission in a minimum delivery time. Similarly, the interdiction strategy must anticipate the possible

paths that may be taken by the UAV to maximize this delivery time. To model and analyze these intertwined

decision making processes of the interdictor and the UAV operator, we next introduce a novel time-critical

network interdiction game.

In this game, the set of players is Z (cid:44) {U, I}. I chooses ﬁrst an interdiction strategy x ∈ X which is a

probability distribution over the set of danger points, N , where xn (i.e. element n of vector x) speciﬁes the
probability with which to launch an attack from node n ∈ N while satisfying (cid:80)

n∈N xn = 1. We refer to this
probabilistic choice of x as a mixed interdiction strategy. A special case of x consists of restricting x to pure

5An O-to-D path h ∈ H is represented by its sequence of nodes connecting O to D. Hence, we use the notation n ∈ h to represent a node n

that is in h.

OD1t1t2t4t5t6t7t8t9t10t11t12t13t14t15t16t17t182345678910t37

interdiction strategies in which case xn = 1 for some n = m ∈ N and xn = 0 for n ∈ N \ m. On the other
hand, U chooses a travel policy (i.e. a path selection strategy), which speciﬁes the node n(cid:48) ∈ Ng(n) to go to

from each possible node n ∈ N , where Ng(n) is the set of outgoing neighbor nodes of n in graph G. Such a

policy will result in a certain O-to-D path. Hence, the goal of I is to choose the best interdiction strategy x,

while anticipating the path selection policy that could be taken by U , to maximize the expected delivery time

while the goal of U is to respond to x by choosing the best possible path h ∈ H to minimize the expected

delivery time. This gives rise to a leader-follower (with I as the leader and U as the follower) hierarchical

time-critical network interdiction game. We next separately study the games under pure interdiction and mixed

interdiction strategies.

III. GAME UNDER PURE INTERDICTION STRATEGIES

A. Game Formulation under Pure Strategies

Under pure strategies, I chooses to be located at node n (the action space of I is, hence, N ) while the

UAV seeks to choose an O-to-D path h ∈ H. If h ∈ H contains node n, when traveling from O-to-D along

path h, it will traverse all danger points n(cid:48) ∈ h, n(cid:48) (cid:54)= n without any risk of being attacked. However, when

the UAV reaches danger point n, it may continue its path with probability 1 − pn, i.e., the probability with

which the attack launched from n is not successful, or it may be sent back to O with probability pn, i.e., the

probability with which the attack launched from n is successful. Let ta be the re-handling time, which is the

time needed by the operator to send a new UAV, if the original one was compromised, captured, or destroyed.

In other words, ta is the time span between the instant at which the drone is compromised or destroyed and

the instant at which a new replacement drone is sent from O. This time span would include the time delay

for the operator to detect6 that an attack has taken place and the time the operator needs to prepare a new

replacement drone. Then, the possible delivery times which can occur when n ∈ h and their probability of

occurrence will be:

Tk = f h(D) + k[f h(n) + ta],

τk = (1 − qn)kqn = pk

nqn,

(1)

(2)

for k ∈ N0; where qn = 1 − pn, Tk is the kth possible delivery time, and τk is the probability of occurrence

of Tk. Hence, based on the possible delivery times and their likelihood, deﬁned respectively in (1) and (2),
6We consider that when the UAV is attacked, U can eventually detect (with a possible delay accounted for as part of ta) that the UAV has been

destroyed/compromised. Hence, the inclusion of ta allows our model to accommodate attack types which might not be promptly detected by U .

8

the expected delivery time, Ed(n, h),7 when the interdictor is located at n and the UAV takes path h is given

in Proposition 1.

Proposition 1: The expected delivery time for an interdiction and path selection strategy pair, (n, h), is

given by:

Ed(n, h) =






f h(D), if n /∈ h,

pn
1 − pn

(f h(n) + ta) + f h(D), if n ∈ h.

(3)

(4)

Proof: First, we consider the case in which n /∈ h. If the chosen path h does not contain n, then the

UAV cannot be successfully attacked, which yields Ed(n /∈ h) = f h(D). Second, we consider the case in
which h contains node n, i.e. n ∈ h. From (1), one can see that f h(D) appears in every possible delivery time

outcome, while (f h(n) + ta) is multiplied by the number of times the UAV had been successfully attacked

at n before it was successfully able to traverse n. This latter component of (1) corresponds to the number of

failures that the UAV experiences before the ﬁrst success in traversing n. Consider being successfully attacked

at n to be a failure of the UAV in traversing n, which can occur with probability pn, and consider traversing

n to be a success for the UAV, which can occur with probability qn = 1 − pn; then, the expected delivery
time will be: Ed(n ∈ h)=(expected # failures before 1st success)(f h(n)+ta)+f h(D). The number of failures
before the ﬁrst success follows a geometric distribution whose mean is given by µ = 1−qn
qn
result, Ed(n ∈ h)= pn
1−pn

(f h(n) + ta) + f h(D).

= pn
1−pn

. As a

Hence, the pn
1−pn

(f h(n) + ta) term in (4) can be viewed as a delay penalty, which the UAV would endure for

taking the risk of traversing a risky danger point at which the interdictor is located. The goal of the interdictor

is to maximize this expected delivery time, Ed(n, h), while the goal of the UAV operator is to minimize it,

leading to a zero-sum game.

B. Equilibrium in Pure Strategies

For each choice n ∈ N by the interdictor, U can identify the optimal reaction strategy h = ρ(n) specifying

the best path to take when I chooses n. The equilibrium concept of this hierarchical game structure is known

as the Stackelberg equilibrium [31] and is deﬁned as follows:

Deﬁnition 1: A strategy pair (n∗, h∗) constitutes a Stackelberg equilibrium (SE) of the network interdiciton

game if

Ed(n∗, h∗ = ρ(n∗)) ≥ Ed(n, ρ(n)) ∀n ∈ N , and

ρ(n) = argmin

Ed(n, h),

h∈H

(5)

(6)

7We also use the notations Ed(n ∈ h) and Ed(n /∈ h) to highlight whether or not path h contains node n in the computed expected delivery

time.

where Ed(n, h) is as given in (3) and (4).

Denoting a shortest O-to-D path by hs and a shortest O-to-D path not containing a node n by hn, the SE

of our network interdiction game can be analytically characterized.

Theorem 1: The interdictor’s SE strategy, n∗, is given by:

9

where

(cid:40) n1, if Ed(n1, ρ(n1)) > Ed(n2, ρ(n2)),

n∗=

n2,

otherwise,

n1 = argmax

n∈Nhs

pn
1 − pn

(f hs(n) + ta) + f hs(D),

Nhs = {n ∈ hs|

f hn(D), and

n2 = argmax
n∈hs\Nhs
(f hs(n) + ta) + f hs(D) ≤ f hn(D)}.

pn
1 − pn

The UAV operator’s SE strategy is given by

h∗=ρ(n∗)=

(cid:40) hs, if n∗ = n1;

hn2, if n∗ = n2.

In addition, the resulting SE expected delivery time is

Ed(n∗, h∗)=






(f hs(n∗) + ta) + f hs(D),

pn∗
1 − pn∗
f hn2 (D),

if n∗ = n1;

if n∗ = n2.

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

Proof: The proof is presented in Appendix A.

The SE8 highlights that, from a delivery time perspective, selecting the shortest path may still be optimal

since it may result in an expected delivery time that is lower than all other alternative paths. This, in particular,

occurs when n∗ = n1. However, in general, as shown in Theorem 1, the optimal path selection strategy goes
beyond simply considering the shortest O-to-D path, as is, for example, the case when n∗ = n2.

IV. GAME UNDER MIXED INTERDICTION STRATEGIES

A. Game Formulation with Mixed-Strategy Interdiction

We now analyze the time-critical network interdiction game under a more general probabilistic choice of

interdiction9. Here, the interdictor may prefer to choose a probabilistic (i.e. mixed) interdiction strategy to

possibly prevent U from predicting their exact actions and, hence, potentially achieving a better outcome. In

this case, I’s mixed-strategy vector, x = [x1, x2, ..., xN ] ∈ X speciﬁes the probability with which I plans to
8The SE of the game is not necessarily unique. However, given the hierarchical structure of the game [31], all possible SEs will lead to an

equal expected delivery time. This equally applies to the equilibria which we will derive for the games that ensue.

9Given the hierarchical structure of our game, considering mixed path selection policies by U would not yield any advantage regarding

the achieved expected delivery time as compared to the optimal deterministic path selection policy [31], [32]. Thus, we limit our analysis to

deterministic path selection.

10

launch an attack on the UAV from the nodes in N . Hence, under mixed-strategy interdiction, the UAV can be

subject to successive probabilistic attacks from multiple nodes. Next, we show that when I chooses a mixed

interdiction strategy x, U ’s choice of optimal path becomes an MDP problem whose transition probabilities

result from the choice x by I.

Consider the case in which I had chosen strategy x ∈ X and the UAV was at node n, at time t0, and then

decides to go to a neighboring node j ∈ Ng(n). By reaching node j (i.e. the proximity of danger point j) at

time t0 + t(i, j), the UAV could be subject to an attack. The probability with which the UAV is successfully

attacked at node j is equal to xjpj. Hence, if the UAV has reached node i at time t0 and then decided to

go to node j next, it can either reach node j at time t0 + t(i, j) and not be successfully attacked at j (with

probability 1 − xjpj), or it can be brought back to the origin when reaching node j (if subject to a successful

attack) with probability xjpj. This latter case implies that the UAV would reach node O at time t0 +t(i, j)+ta

with probability xjpj. This security problem can be modeled as an MDP [32] whose transition probabilities

depend on the security graph, G, and on the choice x of I. We deﬁne the set of states of this MDP to be

the set of nodes N of G. U can then decide to go from a node n to any of its neighboring nodes (i.e. next

potential states). However, its transition to this state is stochastic because, if the attack is successful, instead

of transitioning to a neighboring node, the UAV transitions to state O.

The state transition probabilities, M (cid:0)i, j; (x, k)(cid:1), specify the probability of transitioning from state i to

state j when I chooses strategy x and U chooses action k when at i (choosing action k refers to choosing
to move from node i to node k ∈ Ng(i))10. M (cid:0)i, j; (x, k)(cid:1) is deﬁned as:

M (cid:0)i, j; (x, k)(cid:1)=





(1 − xkpk), for j = k,

xkpk, for j = O,

0, for j ∈ N \ {O, k}.

(15)

(16)

(17)

Here, we note the fundamental difference between the attempted action, k, by U and the MDP state j to

which the UAV transitions from state i. In fact, in both (15) and (16), the attempted action is to move the

UAV from node i to node k. However, the MDP state to which the UAV transitions is either j = O or j = k

depending on whether or not the UAV is successfully attacked. The instantaneous cost to U (reward to I)

from a state transition from i to j, when I chooses x and U chooses to move to node k, can be expressed

as follows:

(cid:16)

i, j; (cid:0)x, k ∈ Ng(i)(cid:1)(cid:17)

=

r

(cid:40) t(i, k), for j = k,

(18)

(19)
10M (cid:0)i, j; (x, k)(cid:1) can be alternatively represented as M (cid:0)i, j; (x, i → k)(cid:1) to explicitly indicate that the action of U is to move the UAV from

t(i, k) + ta, for j = O.

node i to node k. However, for ease of notation, and since it is given that the UAV is initially at state i, rather than using i → k, we use only

the end node k to indicate the operator’s action.

11

For every transition between two states, the UAV accumulates additional delivery time as expressed in (18)

and (19), until the UAV reaches D and the game ends. The goal of U is hence to minimize this expected

cumulative delivery time. Therefore, the choice of a mixed strategy by the interdictor, x, deﬁnes an MDP11

whose set of states is N with transition probabilities as deﬁned in (15)-(17) and instantaneous reward/cost

structure as shown in (18) and (19). The goal of U is to choose the best MDP policy to minimize its expected

accumulated delivery time, where a policy πx speciﬁes, for each node n ∈ N \{D}, the next node n(cid:48) ∈ Ng(n)

to which to go. We let P be the set of all policies. We note that, given the state transitions in (15)-(17), a

policy πx practically results in one realizable O-to-D path denoted by hπx. This is due to the fact that under

the MDP policy πx, only the nodes of a certain path will ever be reached. Hence, a policy reduces to a path

selection strategy. Given the equivalence between a policy πx and its resulting O-to-D path hπx, we next use

the two notations interchangeably depending on whether the emphasis is on a general policy πx or on its

resulting path hπx. We deﬁne Eπx(s; x) to be the value of the state s ∈ N when U follows policy πx for the

MDP induced by the mixed strategy, x, of player I. In other words, Eπx(s; x) is the expected time that the

UAV needs to reach D from s when policy πx is followed. Based on (15)-(19), we can express the values of

the states, for a given policy πx, recursively; as follows:
s, s(cid:48); (cid:0)x, πx(s)(cid:1)(cid:17)(cid:104)
(cid:16)

Eπx(s; x)=

(cid:88)

M

(cid:105)
r(cid:0)s, s(cid:48); (x, πx(s))(cid:1)+Eπx(s(cid:48); x)

.

(20)

As such, the values of each two consecutive nodes, ni and nj (nj being reached from ni based on πx), are

s(cid:48)∈{πx(s),O}

such that:

Eπx(ni; x) = (1 − xnj pnj )(cid:0)t(ni, nj) + Eπx(nj; x)(cid:1) + xnj pnj

(cid:0)t(ni, nj) + ta + Eπx(O; x)(cid:1).

(21)

Of particular interest to our analysis is the value at the origin, Eπx(O; x), which constitutes the expected

delivery time when following policy πx. For a given choice x by I, the goal of U is to ﬁnd a policy π∗

x which
x(s; x), at each state s – i.e. the minimum expected time for
the UAV to reach D from s – are interdependent in a recursive manner following from the Bellman equation:

minimizes Eπx(O; x). The optimal values, Eπ∗

Eπ∗

x(s; x)= min
k∈Ng(s)

s(cid:48)∈{k,O}

(cid:88)

M (cid:0)s, s(cid:48); (x, k)(cid:1)[r(cid:0)s, s(cid:48); (x, k)(cid:1)+Eπ∗

x(s(cid:48); x)].

(22)

Based on the recursive deﬁnition in (21), the value at the origin for an interdiction strategy x and an MDP

policy πx, inducing a path hπx=( O, n1, n2, n3, ..., nr, nl, nk, nm, D) containing m + 2 nodes with ordered

indices, is given in Proposition 2.

11Hence, hereinafter, we refer to this MDP as the MDP induced by x.

12

Proposition 2: The expected delivery time, Eπx(O; x), for a mixed interdiction strategy x and MDP policy

πx, inducing path hπx = (O, n1, n2, n3, ..., nr, nl, nk, nm, D), is given by:

Eπx(O; x)=t(nm, D)+

(cid:34)

1
1−xDpD

g(nk, nm, nD)+

(cid:18)

1
1−xnmpnm

g(nl, nk, nm)+...+

(cid:16)

1
1−xn3pn3

g(n1, n2, n3)

+

1
1−xn2pn2

(cid:0)g(O, n1, n2)+

1
1−xn1pn1

g(O, n1)(cid:1)(cid:17)

(cid:19)(cid:35)
...

,

(23)

where g(.) is a function which takes either 2 or 3 inputs (2 or 3 consecutive nodes of a path hπx, respectively)

(cid:124) (cid:123)(cid:122) (cid:125)
m brackets

and which we deﬁne as g(k, m, n)= xnpn(t(m, n)+ta)+t(k, m), and g(m, n)= xnpn(t(m, n)+ta), considering

k, m, and n to be three consecutive nodes of a path hπx

Proof: The proof follows directly from (21) and from the fact that Eπx(D; x) = 0 for any possible policy,

since the expected delivery time starting from D is equal to 0. Details are omitted due to space limitations.

To solve the game, we deﬁne the SE with mixed-strategy interdiction12:

Deﬁnition 2: A strategy pair (x∗, π∗

x∗) constitutes a mixed interdiction Stackelberg equilibrium (MSE) of

the network interdiction game if

x∗ = argmax

x∈X

Eπ∗

x(O; x), where

π∗
x = argmin

πx∈P

Eπx(O; x).

(24)

(25)

This MSE can be also equivalently deﬁned in terms of x∗ and the optimal path induced by π∗

x∗, i.e.,

(x∗, h∗ = hπ∗

x∗ ).

B. Game Equilibrium under Mixed-Strategy Interdiction

U ’s problem consists of computing the optimal policy (or optimal path) for the MDP induced by x. This

can be achieved using known methods such as value iteration and policy iteration methods [32]. Indeed,

for obtaining the values at each state (i.e. node) resulting from a policy πx (known as policy evaluation),

Eπx(O; x) can be computed as shown in (23) and then used to ﬁnd Eπx(s; x) for each s ∈ S by starting

from D (whose value is Eπx(D; x) = 0) and moving backwards while applying (21). As such, using policy

iteration [32], starting from a certain MDP policy, policy evaluation and policy improvement steps can be

sequentially taken to converge to the optimal policy.

12The MSE in Deﬁnition 2 is a saddle point of our underlying zero-sum game. An alternative approach for studying the equilibrium of the

zero-sum game is to identify its corresponding saddle point in mixed strategies (i.e. considering mixed strategies for both players), where these

saddle-point mixed strategies can be computed by solving a linear program [31]. However, the MSE in Deﬁnition 2 is tailored to the structure of

our game, introduced in Section II, and does not follow a brute-force approach.

13

Fig. 2. Phases-connected security graph with A = 5 phases.

In their traditional form, value and policy iteration methods seek to ﬁnd an optimal policy specifying the

best action to take from every state in the state space. However, as stated in our game formulation, a certain

policy leads to a unique resulting O-to-D path resulting in a certain value at the origin as shown in (23).

Next, we propose an alternative method for identifying U ’s problem solution which does not seek to ﬁnd

the optimal action to be taken from each possible state, but rather an optimal O-to-D path. This method is

dubbed the all-paths method and can be carried out by the following steps:

1) Find all possible paths, H, from O to D,

2) Evaluate Eh(O; x) for each path h ∈ H using (23),

3) Find the optimal path h∗ which solves:

h∗ = argmin

Eh(O; x).

h∈H

(26)

Note that after computing Eh(O; x), and given that Eh(D; x) = 0, the resulting optimal values at the nodes

of h∗ can be computed following (21).

Remark 1: The all-paths method is guaranteed to ﬁnd a solution to U ’s problem, given in (25), in |H| =

H iterations. By its deﬁnition, the all-paths method searches over all possible O-to-D paths. Due to the

equivalence between a certain policy and its resulting path in terms of the achieved value at the origin,

searching over all possible paths H, requiring H iterations, will guarantee obtaining the solution to (25).

The all-paths method can be considered an informed exhaustive search method. In fact, rather than searching

over all possible policies, P, whose size can be computed as |P| = (cid:81)

n∈N \{D} |Ng(n)| ≥ H, the all-paths
method leverages the policy-path equivalence to search only over the set of possible O-to-D paths, H. If

the security graph, G, can be split into phases where each two consecutive phases form a complete bipartite

graph13 (as is the case in Fig. 1 and Fig. 2), H grows linearly in the number of nodes, Ni, in a given phase.
Indeed, in a phase-connected graph with A phases, the total number of O-to-D paths is given by H = (cid:81)A

i=1 Ni.
For example, in Fig. 2, A = 5 and H = 18 while |P| = 216; the latter is the number of iterations needed for

13We refer to such graphs as phase-connected graphs, which reﬂect the practical case in which the UAV goes from one set of danger points to

the other (e.g. between sets of hills and sets of high-rise buildings) with relatively safe conditions in between.

OD12345678910Phase 1N1=1Phase 2N2=3Phase 3N3=2Phase 4N4=3Phase 5N5=114

a standard exhaustive search. Hence, the all-paths method requires fewer iterations than the exhaustive search

method, and in contrast to policy and value iterations, each iteration of the all-paths method is search-free

(that is, it does not require a minimization step) and is only limited to arithmetic operations which can be

efﬁciently performed.

From the interdictor’s side, after predicting the reaction π∗

x for a chosen interdiction strategy x ∈ X , I aims
at solving the optimization problem deﬁned in (24). The main challenge with solving this problem resides

in the discontinuous changes in the objective function which can be induced by a slight modiﬁcation to the

chosen strategy x. This is due to the fact that a minimal change to the chosen x can lead to a complete

modiﬁcation of the resulting optimal reaction MDP policy of U . Hence, due to the discontinuity of the

objective function in (24), ﬁnding an exact globally optimal solution to the interdictor’s problem may not

be guaranteed. The search for such a global optimum can be done using heuristic methods such as pattern

search based methods [33]. By using pattern search based methods, an achievable solution to the interdictor’s

problem can be obtained which leads to what we consider an achievable MSE. As such, the proposed all-paths

method and pattern search are two complimentary methods, which when combined, allow computing an MSE

of the network interdiction game.

V. GAME ANALYSIS UNDER PT

As established in Section III and Section IV, the choices of interdiction and path selection strategies are

carried out under uncertainty. Indeed, every chosen interdiction strategy and path selection strategy give rise

to a prospect: A set of possible achievable delivery times each of which can occur with a certain probability.
In fact, when I chooses x and U chooses path h = (O, n1, n2, n3, ..., nr, nl, nk, nm, D), and if we let kni ∈ N0
be the number of times the UAV is successfully attacked at node ni ∈ h \ {O, D}, then the possible achieved
delivery times T (cid:48)(kn1, kn2, ..., knm) and their associated probabilities of occurrence, τ (cid:48)(kn1, kn2, ..., knm), will
be given by14

T (cid:48)(kn1, kn2, ..., knm)=f h(D)+

kni[f h(ni)+ta],

m
(cid:88)

i=1

(cid:3)kn1(cid:2)

m
(cid:89)

(ξnj )knj(cid:3),

j=2

τ (cid:48)(kn1, kn2,..., knm)=(cid:2)

(1−xnipni)(cid:3)(cid:2)xn1pn1

m
(cid:89)

i=1
j−1
(cid:89)

(27)

(28)

(29)

where

ξnj = (cid:2)

(1 − xnrpnr)(cid:3)xnj pnj .

r=1

The previous analyses in Section III and Section IV had considered the situation where the uncertainty is

managed by I and U in a fully rational and objective manner. In other words, the possible delivery times,

in (27), and the probabilities of their occurrence, in (28), are similarly and objectively perceived by I and

14The expressions in (27) and (28) reduce, respectively, to (1) and (2) when considering pure-strategy interdiction.

15

U , leading the players to assess a pair of strategies based on an expected value of their resulting prospect.

However, given the time criticality of the studied drone applications (which must execute certain missions

within a target time period), a certain achieved delivery time can be assessed subjectively and differently

by U and I with respect to their chosen target delivery times. In addition, the perception of probabilities

by U and I can be distorted, which makes them deviate from the rational objective perception, leading

each player to assess the risk level of a certain path differently. Indeed, as has been shown in a number

of psychological empirical studies, as in [26] and [27], when faced with risk and uncertainty (similarly to

our time-critical network interdiction game), the decision making processes of individuals can signiﬁcantly

deviate from full rationality. Essentially, individuals have been found to subjectively evaluate outcomes and

perceive probabilities [26], [27], hence assessing a certain prospect not based on its expected value but based

on a subjective valuation assigned to this prospect.

To capture the interdictor’s and UAV operator’s potential subjective perceptions (i.e. bounded rationality)15,

we incorporate the principles of cumulative prospect theory [26] in our game formulation. PT is a Nobel prize-

winning theory which has been shown to successfully model and predict decision makers’ subjective behaviors,

preferences, and valuations. Indeed, using PT, the subjective perception of the likelihood of occurrence of

a probabilistic delivery time and the subjective evaluation of this delivery time with respect to a reference

point becomes central to the decision making processes of I and U . Consider a prospect g(φi, ηi), listing
each possible outcome φi and its probability of occurrence ηi. Each φi is a possible delivery time T (cid:48) in (27)
and ηi is its corresponding probability, τ (cid:48)

i , in (28). Under PT, for a maximizer, the value of an outcome φi,

denoted by v(φi), with respect to a reference point R is given by [26]:

v(φi) =




(φi − R)β+, if φi ≥ R,



−λ(−(φi − R))β−, if φi < R,

(30)

(31)

where λ is known as the loss multiplier and β+ and β− are constant parameters which shape the value

function. Based on the sign of v(φi), g can be split into a negative prospect g− and positive prospect g+.
The values in g− correspond to losses and the values in g+ correspond to gains. Consider that g− contains

m terms, indexed from −m to −1, and g+ contains κ terms, indexed from 1 to κ. In addition, consider that

each of the two prospects are ranked in ascending order based on the values, v(φi). Under PT, the valuations

of the positive and negative prospects, V (g+) and V (g−), are given by [26]:

V (g+) =

κ
(cid:88)

i=1

π+
i v(φi), and V (g−) =

−1
(cid:88)

i=−m

π−
i v(φi),

(32)

15Although the proposed game policy will be implemented autonomously by the drone, the design of the game-theoretic policies are performed

by a human operator whose perceptions are subjective and rationality is bounded.

resulting in the valuation, V (g) = V (g+) + V (g−), of prospect g. π+

i and π−

i are decision weights deﬁned

16

based on the cumulative probability of occurrence of outcome φi:
i
(cid:88)

κ
(cid:88)

κ
(cid:88)

i = ω+(cid:0)
π+

(cid:1)−ω+(cid:0)

ηi

(cid:1), π−

i = ω−(cid:0)

j=i

ηi
j=i+1

(cid:1) − ω−(cid:0)

i−1
(cid:88)

ηi
j=−m

(cid:1),

(33)

ηi
j=−m

where ω+ and ω− are the weighting functions associated with the positive and negative prospects, respectively,

and are deﬁned as follows (for a certain objective probability η) [26]:

ω+(η)=

ηγ+

(ηγ++(1−η)γ+)1/γ+ , ω−(η)=

ηγ−
(ηγ−+(1−η)γ−)1/γ− ,

(34)

where γ+ ∈ (0, 1] and γ− ∈ (0, 1] are known as the rationality parameters. The higher the value of the

rationality parameter, the closer are ω+(η) and ω−(η) to the rational probability η.

The expressions in (33) showcase the way decision weights are formed from cumulative probabilities of

outcomes in a prospect. In fact, (cid:80)κ
as φi while (cid:80)κ
(cid:80)i

j=i ηi corresponds to the probability that the outcome is at least as good
j=i+1 ηi corresponds to the probability that the outcome is strictly better than φi. Equivalently,
j=−m corresponds

j=−m ηi corresponds to the probability that the outcome is at least as bad as φi while (cid:80)i−1

to the probability that the outcome is strictly worse than φi.

Next, we formulate our network interdiction game under PT, which we call the PT game. We also split

our analysis of the PT game into pure and mixed interdiction cases. Here, we note that the notations of the

constants used in (30), (31), and (34), i.e. λ, R, β+, β−, γ+, and γ−, will be consistently used in the analyses

that ensues but will be indexed by I and U depending on the player to which they refer.

A. PT Game under Pure Interdiction Strategies

As discussed in Section III-A, when U chooses path h and I is located on node n ∈ h, the possible
outcomes, Tk, and their associated probability of occurrence, τk, for k ∈ N0, are as described, respectively,

in (1) and (2). Hence, the (n, h) strategy pair gives rise to a prospect, g(n ∈ h), in which the outcomes are

ordered from lowest to highest, and is expressed as:

g(n ∈ h) = (cid:0)f h(D), qn; f h(D) + (f h(n) + ta), pnqn; . . . ; f h(D) + k(f h(n) + ta), (pn)kqn; . . . (cid:1).

(35)

As PT predicts, the interdictor and the UAV operator evaluate each possible outcome of this prospect

subjectively, as shown in (30) and (31). In this regard, the valuation, vI

k, that the interdictor gives to the kth

possible outcome, Tk = f h(D) + k(f h(n) + ta), is as follows:

where






vI
k=

(∆Ik)β+

I , if ∆Ik≥0,

−λI(−(∆Ik))β−

I , if ∆Ik<0,

∆Ik = f h(D) + k(f h(n) + ta) − RI.

(36)

(37)

(38)

17

Given that the interdictor aims at maximizing the expected delivery time, ∆Ik ≥ 0 is seen as a gain while
∆Ik < 0 is seen as a loss. Equivalently, the valuation, vU
k , that the UAV operator gives to the kth possible

outcome, Tk, is as follows:

where

vU
k =






λU (∆Uk)β−

U , if ∆Uk>0,

−(−(∆Uk))β+

U , if ∆Uk≤0,

∆Uk = f h(D) + k(f h(n) + ta) − RU .

(39)

(40)

(41)

Since U aims at minimizing the expected delivery time, ∆Uk > 0 is evaluated as a loss while ∆Uk ≤ 0 is

viewed as a gain.

Using PT principles, we derive the valuations that I and U assign to each possible choice of the pair of

pure interdiction and path selection strategies (n, h). We denote these valuations by VI(n, h) and VU (n, h)

for, respectively, I and U .

Theorem 2: The PT valuation that I assigns to a strategy pair (n, h) is given by

VI(n, h) =

(cid:40) VI(gI(n /∈ h)), if n /∈ h,

VI(gI(n ∈ h)), if n ∈ h,

where

VI(gI(n ∈ h))=

VI(gI(n /∈ h))=




(f h(D)−RI)β+

I , if f h(D) ≥ RI,



−λI(−(f h(D)−RI))β−

k−
I(cid:88)

(cid:16)
−λI(−∆Ii)β−

i

i=0

ω−
I

(cid:0)1−pi+1

n

(cid:1)−ω−

I

(cid:0)1−pi

n

(cid:1)(cid:17)

+

I, if f h(D)<RI,
∞
(cid:88)

(cid:104)
(∆Ii)β+

ω+
I

I

i=k+
I

(cid:0)(pn)i(cid:1)−ω+

I

(cid:0)(pn)i+1(cid:1)(cid:105)

where k−

I and k+

I are such that: ∆Ik < 0 for k ≤ k−

I , ∆Ik > 0, for k > k+

I , and k+

I = k−

I + 1.

Proof: The proof is presented in Appendix B.

Theorem 3: The PT valuation that U assigns to a strategy pair (n, h) is given by

VU (n, h) =

(cid:40) VU (gU (n /∈ h)), if n /∈ h,

VU (gU (n ∈ h)), if n ∈ h,

where

VU (gU (n ∈ h))=

k−
U(cid:88)

i=0

VU (gU (n /∈ h))=




−(−(f h(D)−RU ))β+

U , if f h(D)≤RU ,



λU (f h(D)−RU )β−

U , if f h(D) > RU ,

−(−∆Ui)β+

U (cid:0)ω+

U (1−pi+1

n )−ω+

U (1−pi

n)(cid:1)+

∞
(cid:88)

λU (∆Ui)β−

U

i=k+
U

(cid:16)

ω−
U

(cid:0)(pn)i(cid:1)−ω−

U

(cid:0)p(i+1)

n

(cid:1)(cid:17)
,

(49)

where k−

U and k+

U are such that: ∆Uk < 0 for k ≤ k−

U , ∆Uk > 0 for k ≥ k+

U , and k+

U = k−

U + 1.

(42)

(43)

(44)

,

(45)

(46)

(47)

(48)

18

Proof: This proof follows steps similar to those in the proof of Theorem 2 while accounting for the

valuations that U assigns to each possible outcome given in (39)-(41).

As shown in (45) and (49), VI(gI(n ∈ h)) and VU (gU (n ∈ h)) correspond to inﬁnite summations, i.e. inﬁnite

series. Hence, to be able to compare between possible pairs of strategies (n, h), based on their valuations

VI(n, h) and VU (n, h), and to identify the equilibrium strategy pair, it is necessary for these sums to converge.

We next show in Proposition 3 and Proposition 4 that VI(gI(n ∈ h)) and VU (gU (n ∈ h)) are convergent series.

Proposition 3: VI(gI(n ∈ h)) is a convergent series.

Proof: Toward proving the convergence of VI(gI(n ∈ h)), we ﬁrst prove that VI(g+

I (n ∈ h)), deﬁned
in (68) and composed of positive terms, converges using what is known as the ratio test. Following the
ratio test, for a series (cid:80)∞
(cid:80)∞

n=1 an with positive terms an, L is deﬁned as L = lim
n→∞
, which is given by V I +

n=1 an converges. As such, we refer to the kth term of VI(g+

I (n ∈ h)) by V I +

|. If L < 1, then

| an+1
an

k =

k

(cid:104)

(∆Ik)β+

I

ω+
I

(cid:0)(pn)k(cid:1)−ω+

I

(cid:0)(pn)k+1(cid:1)(cid:105)
V I +
k+1
V I +
k

, while ω+

I (pk
−p(k+2)γ+
p(k+1)γ+
n −p(k+1)γ+
pkγ+

=

n

n

n

I

I

I

I

L= lim
k→∞

=

I

I

n

pγ+
n −p2γ+
1−pγ+

I
n

=pγ+

I

n < 1

n) follows from (34). In this respect,

⇒ VI(g+

I (n ∈ h)) converges ⇒ VI(gI(n ∈ h)) converges.

Proposition 4: VU (gU (n ∈ h)) is a convergent series.

Proof: The proof follows steps similar to those in the proof of Proposition 3.

Under PT, the pure-strategy equilibrium of the game is based on the subjective valuations, VI(n, h) and

VU (n, h), that I and U respectively assign to the prospect resulting from the choice of strategy pair (n, h).

As such, under PT, the game becomes a nonzero-sum game whose SE is analyzed next.

As in the analysis in Section III-B, U can optimally react to a decision n that had been taken by I. However,

for the PT game, this optimal reaction is based on the valuation VU (n, h) rather than the expected delivery

time Ed(n, h). In this PT game, we denote the choice of a path h ∈ H by U , as an optimal reaction to a

node n ∈ N that had been chosen by I, by ρPT(n), which is formally deﬁned as:

ρPT(n) = argmin

VU (n, h),

h∈H

(50)

where VU (n, h) is as given in Theorem 3.

Paralleling the SE for the fully rational game in Deﬁnition 1, an SE for the PT game (SE-PT) is deﬁned

as follows.

Deﬁnition 3: A strategy pair (˜n∗, ˜h∗) constitutes a Stackelberg equilibrium of the PT game if

VI(˜n∗, ˜h∗ = ρPT(˜n∗)) ≥ VI(n, ρPT(n)) ∀n ∈ N ,

(51)

where VI(n, h) is as deﬁned in Theorem 2, and ρPT(n) is as deﬁned in (50).

I’s problem corresponds, then, to choosing ˜n∗ which solves

˜n∗ = argmax

n∈N

VI(n, ρPT(n)).

19

(52)

Following a similar logic as in the derivation of the SE in Theorem 1, the SE-PT can be analytically

characterized.

Theorem 4: The interdictor’s SE-PT strategy, ˜n∗, is given by:

(cid:40) m1, if VI(m1, ρPT(m1)) > VI(m2, ρPT(m2)),

˜n∗=

where

m2,

otherwise,

m1 = argmax
n∈Mhs
m2 = argmax
n∈hs\Mhs

VI(gI(n ∈ hs)),

VI(gI(n /∈ hn)),

Mhs = {n ∈ hs|VU (gU (n ∈ hs)) ≤ VU (gU (n /∈ hn))},

and hn is the shortest O-to-D path not containing node n.

The resulting UAV operator’s SE-PT strategy is given by

(cid:40) hs, if ˜n∗ = m1,

˜h∗=ρPT(˜n∗)=

(53)

(54)

(55)

(56)

(57)

(58)
Proof: Due to space limitations, only a sketch of the proof is provided. U ’s response to a choice n ∈ hs
by I will either be hs or hn. I always has an incentive to choose n ∈ hs, since otherwise, ρPT(n) = hs, which

hm2, if ˜n∗ = m2.

results in the worst possible VI(n, h) for I. However, choosing an n ∈ hs might also lead U to deviate from

hs to the best alternative hn. Hence, I can split the nodes in hs into two sets, Mhs and N \ Mhs, where the

former set consists of nodes of hs which when attacked would not lead U to deviate from hs, while the latter

set consists of nodes which when attacked will lead to deviations to the best alternative. Hence, m1 and m2

in (54) and (55) represent the best two alternatives for I. As such, ˜n∗ in (53) corresponds to choosing the
best of these two alternatives, and ˜h∗ in (57) and (58) correspond to choosing the best reaction ρPT by U to

the choice made by I.

Theorem 4 analytically characterizes the SE of the PT game, which can be compared to the SE of the

game with full rationality derived in Theorem 1. This comparison enables us to analyze the effect of the

players’ subjective PT valuations and perceptions on their chosen equilibrium strategies. A main component

of the choice of the SE and SE-PT strategies is the characterization of sets Nhs, in (10), and Mhs, in (56). By
comparing (10) and (56), we can see that Ns relies on the comparison between pn
(f hs(n)+ta)+f hs(D) and
1−pn
f hn(D) for each n ∈ hs; while Mhs relies on comparing VU (gU (n ∈ hs)), which can be obtained from (49),
with VU (gU (n /∈ hn)), which can be obtained from (48). This difference in Nhs and Mhs enables possible

deviation of the SE-PT strategies from the SE strategies.

20

B. PT Game under Mixed-Strategy Interdiction

Consider the case where I chooses x and U chooses a policy that induces path h = (O, n1, n2, n3, ...,
nr, nl, nk, nm, D). Then, the resulting possible delivery times, T (cid:48)(kn1, kn2, ..., knm), and their associated
probabilities of occurrence, τ (cid:48)(kn1, kn2, ..., knm), are given by (27) and (28), where kni ∈ N0 is the number
of times the UAV is successfully attacked at a node ni ∈ h \ {O, D}. Hence, the interdiction strategy x,
by I, and response path h, by U , result in a prospect Γ(x, h) in which each outcome T (cid:48)(kn1, kn2..., knm)
occurs with probability τ (cid:48)(kn1, kn2..., knm). Under PT, to compare strategy pairs (x, h) ∈ X × H, each of I
and U generates a personal valuation of this prospect. As a result, their choices of optimal mixed interdiction

and path selection strategies are based on these PT valuations. Given (27)-(29) and the value and weighting

functions introduced in (30)-(34), we can generate the valuations assigned by I and U , ΞI(x, h) and ΞU (x, h),

to prospect Γ(x, h) by following steps similar to those in Section V-A. Based on ΞI(x, h) and ΞU (x, h), the

equilibrium of the PT game with mixed interdiction strategies can be characterized.

In this regard, the deﬁnition of the SE-PT equilibrium introduced in Deﬁnition 3 can be extended to the

mixed-strategy interdiction case as follows:
Deﬁnition 4: A strategy pair (˜x∗, ˜h∗

˜x∗) constitutes a PT mixed-strategy interdiction Stackelberg equilibrium

(MSE-PT) of the network interdiction game if

ΞI(˜x∗, ˜h∗

˜x∗ = ˜ρPT(˜x∗)) ≥ ΞI(x, ˜ρPT(x)) for all n ∈ N ,

where ˜ρPT(x) is the optimal reaction of U to x and is given by:

˜ρPT(x) = argmin

ΞU (x, h).

h∈H

(59)

(60)

Our solution approach presented in Section IV-B, which delivered the MSE of the game (under full

rationality), also applies here to derive the MSE-PT of the PT game. Indeed, characterizing the MSE-PT

requires solving U ’s problem in (60) as well as I’s problem given in (59). The all-paths method proposed in

Section IV-B can guarantee solving U ’s problem.

Remark 2: The all-paths method is guaranteed to ﬁnd ˜ρ(x) for each interdiction strategy x ∈ X . Finding

˜ρ(x) corresponds to identifying the path h obtained as h = argmin

ΞU (x, h). As such, by following steps 1

to 3 of the all-paths method, and considering ΞU (x, h) instead of Eh(O; x), the all-paths method performs a

h∈H

complete search over all possible O-to-D paths and returns path h which results in the minimum ΞU (x, h),

hence, determining ˜ρ(x).

The interdictor’s problem corresponds to solving the following optimization problem:

˜x∗ = argmax

x∈X

ΞI(x, ˜ρPT(x)).

(61)

As in I’s problem in Section IV, obtaining an exact global solution to (61) cannot be guaranteed due to the

non-convexity and discontinuity of the objective function stemming from the sudden changes to ˜ρPT(x) which

21

Fig. 3. Paths lengths, f h(D), and node risk probabilities, pn.

can be triggered by minimal changes to x. Hence, for obtaining a solution to (61), we propose using a pattern

search based method, as discussed in Section IV-B.

VI. NUMERICAL RESULTS

For our numerical analysis, we provide a tractable set of examples which showcase the different contribu-

tions of the derived analytical results and highlight the effects that the various PT parameters can have on the

equilibrium strategies and achieved expected delivery times. For these simulation-based numerical analyses,

we consider the graph shown in Fig. 1 composed of N = 10 nodes and E = 18 edges. We label the 18 paths,
from 1 to 18, as follows: [1, 2, ..., 18] (cid:44) [(2, 5, 7), (2, 5, 8), (2, 5, 9), (2, 6, 7), (2, 6, 8), (2, 6, 9), (3, 5, 7),

(3, 5, 8), (3, 5, 9), (3, 6, 7), (3, 6, 8), (3, 6, 9), (4, 5, 7), (4, 5, 8), (4, 5, 9), (4, 6, 7), (4, 6, 8), (4, 6, 9)]. Given

that node 1 (O) and node 10 (D) are part of each path, a path (1, i, j, k, 10) is, for convenience, referred to

by (i, j, k). In addition, the travel times ti, for i ∈ {1, ..., 18}, in Fig. 1 are drawn from a uniform distribution
in the interval [2, 8] yielding [t1, t2, ..., t18] (cid:44) [6.89, 3.46, 7.58, 4.1, 3.18, 3.51, 5.7, 4.84, 4.11, 6.99, 5.51, 5.3,

7.5, 3.72, 6.54, 6.52, 4.28, 5.41]. We then choose the attack success probabilities as p= [0, 0.3, 0.5, 0.4, 0.6,

0.3, 0.4, 0.8, 0.4, 0]. The length of each path h, f h(D), and the risk probability at each node, pn, are shown

in Fig. 3. Fig. 3 shows that path 8, i.e. (3, 5, 8), is the shortest path followed by paths 11, i.e. (3, 6, 8), and

path 9, (3, 5, 9); while node 8 is the most risky node followed by nodes 5 and 3, respectively. The re-handling

and processing time is considered to be ta = 5. For the PT parameters of I and U , unless stated otherwise,
we consider RI = RU = 20, λI = λU = 2.5, β−

I = β−
We will ﬁrst take the reference points (which represent, for example, a target delivery time) of both players

U = 0.6, and γ−

I = β+

U = β+

U = 0.5.

I = γ−

I = γ+

U = γ+

to be equal, RI = RU = R, and ranging from 10 to 35. The resulting equilibrium interdiction strategies (i.e.

I’s equilibrium strategies) are shown in Fig. 4, and U ’s equilibrium strategies are shown in Fig. 5. Fig. 4

shows that the MSE interdiction strategy, x∗, focuses solely on nodes 5, 8, and 9, (x∗

8 = 0.31, and
x∗
9 = 0.21) each of which is at least part of one of the three shortest paths (paths 8, 11, and 9). In addition,
U ’s MSE strategy, h∗, corresponds to choosing path 12, which is composed of nodes 3, 6, and 9. Given that

5 = 0.48, x∗

24681012141618Path (h)152025Path length, f h(D)12345678910Node (n)00.20.40.60.81pn22

Fig. 4. Equilibrium interdiction strategy for different R = RI = RU .

nodes 3 and 6 are not attacked by I at the MSE and that p9 = 0.4 and x∗

9 = 0.2, path 12 is a relatively
safe path. The players’ MSE strategies lead to an MSE expected delivery time that is equal to around 23, as

shown in Fig. 6.

Fig. 4 shows the difference between I’s MSE-PT interdiction strategies, ˜x∗, and the MSE interdiction
strategies for different values of R. Fig. 4 shows the shift in the PT interdiction strategy, ˜x∗, from mainly

targeting the incoming neighbor nodes of D (i.e. nodes 7, 8, and 9), at R = 10, to a more spread out

interdiction strategy targeting a larger number of nodes, at R = 35. At small values of R, such as R = 10,

all possible delivery times fall above R. Hence, all possible outcomes are valued by I as gains. Since the

PT value function, vI(.) in (30) and (31), leads I to be risk averse in gains, choosing nodes 7, 8, and 9 is
appealing since any O-to-D path is guaranteed to pass by at least one of these nodes. Clearly, this choice of ˜x∗

is a risk averse choice that guarantees a sure gain. However, when R increases, some of the possible delivery

times will fall below R. Hence, for a choice x by I, and h by U , some of the outcomes will correspond to

gains and some to losses leading I to drift away from a mere risk averse strategy. In Fig. 5, we show the

different MSE-PT strategies of U as R varies. Fig. 5 shows that at R = 10, U chooses the shortest path 8 at

the MSE-PT. This is due to the fact that, for this small reference point R, all possible delivery times are seen

as losses by U . The concavity of the value function for outcomes greater than RU renders U risk seeking in

losses. Hence, taking the shortest path (even if it is risky up to a certain extent) becomes more appealing to

U . When R increases, U ’s MSE-PT strategy will drift away from the shortest path, particularly at values of

R that are high enough to enable certain possible delivery times to fall below the reference delivery time, R,

leading to outcomes that are valued as gains.

Fig. 6a shows the resulting expected delivery times, at the MSE and MSE-PT, for the different values

of R. Clearly, for low values of R, the MSE-PT results in a lower expected delivery time than the MSE.

However, for relatively high values of R, the MSE-PT results in an expected delivery time that is higher than

the expected delivery time at the MSE. As shown in Fig. 6a, the percentage difference in expected delivery

time at the MSE-PT compared to the MSE is −7.5% at R = 15 and +14.4% at R = 30. Indeed, since at

1234567891000.10.20.30.40.50.6NodeEquilibrium interdiction strategy  Rational (MSE)RU=RI=10 (MSE−PT)RU=RI=15 (MSE−PT)RU=RI=20 (MSE−PT)RU=RI=25 (MSE−PT)RU=RI=30 (MSE−PT)RU=RI=35 (MSE−PT)23

Fig. 5. U ’s equilibrium path selection strategy for different R = RI = RU .

low values of R, I takes a risk averse non-aggressive attack strategy, as shown in Fig. 4, and U chooses

a risk-seeking shortest path, as shown in Fig. 5, this leads to achieving a relatively short expected delivery

time since this shortest path (i.e. path 8) is not heavily targeted by I at the MSE-PT. However, for higher

values of R, I considers more aggressive interdiction strategies and U considers safer paths which results in

expected delivery times that are higher at the MSE-PT than at the MSE. In addition, the results in Fig. 6a

show that at the MSE-PT, except for R = 30 and R = 35, U was not able to achieve an expected delivery

time that is below its target reference delivery time. However, at the MSE, U ’s expected delivery time is lower

than its target delivery time for R ≥ 25. Hence, selecting strategies based on PT valuations is, based on this

comparison, disadvantageous to U . In addition, Fig. 6a shows the expected delivery time achieved when U

chooses the shortest path (i.e. path 8) and I chooses either its fully rational MSE interdiction strategy or its

prospect-theoretic MSE-PT interdiction strategy (these strategies are shown in Fig. 3) – labeled, respectively,

“Shortest path vs. Interdiction MSE” and “Shortest path vs. Interdiction MSE-PT” – for different values of

R. Fig. 6a shows that under full rationality, unilaterally deviating from the MSE path (i.e. path 12 as shown

in Fig. 5) to the shortest path (i.e. path 8) results in an increase in the expected delivery time, which is

not advantageous to U . Under PT, deviating from the MSE-PT path to the shortest path results in a worse

(i.e. higher) expected delivery time for R ≤ 20, while it results in a better (i.e. lower) expected delivery

time for R ≥ 25. Indeed, under PT, U aims at minimizing its PT valuation of the expected delivery time,

ΞU (x, h), as shown in (60), rather than the objective expected delivery time. However, minimizing ΞU (x, h)
may not lead to achieving the minimum possible expected delivery time. In fact, Fig. 6b shows ΞU (˜x∗, ˜h∗
˜x∗)
and ΞU (˜x∗, 8), i.e., the PT valuation achieved by U when choosing its MSE-PT strategy vs. I’s MSE-PT
strategy (˜x∗) as compared to choosing the shortest path 8 vs. ˜x∗. As shown in Fig. 6b, U ’s valuation of

choosing its equilibrium MSE-PT strategy is lower than the valuation achieved when choosing the shortest

path. However, Fig. 6a shows that the deviation to the shortest path would have been advantageous to U for

R ≥ 25. This, hence, highlights the effect of the subjective PT perceptions of U , which may lead to a worse

expected delivery time as compared to the expected delivery time which could have been achieved by a mere

101520253035R=RU=RI024681012141618Equilibrium pathRational (MSE)PT (MSE-PT)24

Fig. 6. a) Expected delivery time for different R = RI = RU , b) U ’s PT valuation of the MSE-PT strategies and when unilaterally deviating to

the shortest path.

choice of a non-strategic shortest path.

Hereinafter, to characterize the effect of the various PT parameters on the resulting equilibrium strategies

and outcomes, we consider the interdictor to be fully rational (i.e. RI = 0, λI = 1, β−
I = 1, and
γ−
I = γ+
I = 1), while U values outcomes and performs probability weighting following PT, with PT parameters
similar to the ones used in the previous simulations, unless stated otherwise. We ﬁrst study the effect of varying
the rationality parameters of U , i.e. γ−
U and γ+
loss parameter λU . First, we consider γU = γ−

U , on the MSE-PT and then study the effects of varying U ’s
U = γ+
U , and we let γU take the following values: 0.25, 0.3,

I = β+

0.35, 0.5, 0.75, and 0.9.

Fig. 7 shows that the MSE-PT interdiction strategy approaches its MSE strategy at higher values of γU .

However, one can see that I’s MSE-PT strategy does not completely coincide with its MSE even for high

values of γU . This is due to the fact that even when U ’s probability weighting is closer to full rationality, the

way U values the possible game outcomes (i.e. the possible delivery times) is based on its reference point RU

and value function. Hence, even with a closely rational probability weighting, U ’s MSE-PT may not equal

its MSE strategy. This can, indeed, be seen from Fig. 8, which shows that even for γU = 0.9, U ’s MSE-PT

strategy is different from its MSE strategy. Fig. 8 shows how U ’s MSE-PT strategy changes with an increase

in γU . At lower values of γU , U ’s MSE-PT strategy consists of path 9, i.e. (3, 5, 9), while at higher values

of γU , U ’s MSE-PT strategy shifts to choosing path 11, i.e (3, 6, 8). As shown in Fig. 7, at lower values of

γU , I’s optimal strategy is focused on nodes 5 and 8 making path 9, chosen by U at the MSE-PT, highly

risky. However, U still chooses this path, at the MSE-PT, since at such low values of γU , U ’s valuation of
probabilities is highly distorted. In fact, the weighting functions ω+

U (.) ﬂatten for lower values of
γU . Hence, U would assess different paths as almost equally risky leading U to choose path 9. However,

U (.) and ω−

when γU increases, U ’s perception of probabilities becomes more rational. Hence, for these values of γU , U

101520253035R = RU = RI192021222324252627Expected delivery timeRational (MSE)Shortest path vs. Interdiction MSEPT (MSE-PT)Shortest path vs. Interdiction MSE-PT101520253035R = RU = RI0510Operator's  PT valuationPT (MSE-PT)Shortest path vs. Interdiction MSE-PTa)b)25

Fig. 7. I’s equilibrium interdiction strategy for different values of γU =γ−

U =γ+
U .

Fig. 8. U ’s equilibrium path selection strategy for different γU =γ−

U =γ+
U .

can observe that path 9 is highly risky and chooses instead the safer path 11, composed of nodes (3, 6, 8)

which are not attacked with a high probability by I at the MSE-PT.

Fig. 9a shows the resulting expected delivery times at the MSE and at the MSE-PT for various values of

γU . From Fig. 9a, we can see that the MSE-PT strategies result in expected delivery times that are longer than

the expected delivery time achieved at the MSE. Indeed, for γU = 0.25, the percentage difference between

the expected delivery time at the MSE-PT and that at the MSE goes up to +21.5%. The reason is that, as

shown in Fig. 8, for low values of γU , U admits a risky MSE-PT strategy leading to high expected delivery

times. However, as γU increases, the shift in U ’s MSE-PT strategy allows achieving better expected delivery

times; which are, however, still longer than the MSE expected delivery time. Fig. 9a also shows an expected

delivery time labeled “Rational response”. This corresponds to U choosing a rational strategy in response to

I’s MSE-PT strategy. In other words, rational response corresponds to choosing the path strategy h∗ which
solves (26) for x = ˜x∗. In this scenario, I assumes that U admits PT valuations and would, hence, choose
its MSE-PT strategy, ˜x∗. However, if U is rather rational, it can take advantage of its knowledge of ˜x∗ to

achieve a better expected delivery time. Indeed, the rational response of U consists of choosing path 11,

for γU = 0.25 and γU = 0.3, and path 12, for the higher values of γU , which result in achieving expected

12345678910Node00.10.20.30.40.50.60.70.80.9Equilibrium interdiction strategyRational (MSE)U=0.25 (MSE-PT)U=0.3 (MSE-PT)U=0.35 (MSE-PT)U=0.5 (MSE-PT)U=0.75 (MSE-PT)U=0.9 (MSE-PT)0.30.40.50.60.70.80.9U024681012141618Equilibrium pathRational (MSE)PT (MSE-PT)26

Fig. 9. a) Expected delivery time when U plays a rational response to I’s MSE-PT strategy, at the MSE, at the MSE-PT, and when U chooses
the shortest path in response to I’s MSE-PT strategy, for different γU = γ−

U , b) U ’s PT valuation at the MSE-PT and when unilaterally

U = γ+

deviating to the shortest path.

delivery times that are shorter than the expected delivery times at the MSE-PT and the MSE, as shown in

Fig. 9a. In fact, as can be seen from Fig. 9a, at γU = 0.25, choosing the rational response strategy (which

corresponds to choosing path 11) allows U to achieve an expected delivery time that is 30.3% lower than the

expected delivery time achieved at the MSE-PT. Fig. 9a also shows the resulting expected delivery time when

U chooses the shortest O-to-D path and I chooses its MSE-PT interdiction strategy, labeled “Shortest Path

vs. Interdictor MSE-PT”, for different values of γU . As can be seen in Fig. 9a, a deviation from the MSE-PT

path to the shortest path would have been advantageous to U as it would lead to a lower expected delivery

time for the entire investigated range of γU . However, as U subjectively assesses expected delivery times

under PT, the choice of the MSE-PT path is valued to be better than choosing the shortest path, as shown

in Fig. 9b, as the MSE-PT path leads to a lower PT valuation. Hence, this further highlights the negative

effect that the subjective PT perception of U can have on its achieved expected delivery time. The rational

response as well as the MSE strategies both lead to a better expected delivery time than the shortest path and

the MSE-PT strategies, as shown in Fig. 9a.

Fig. 10a shows the resulting expected delivery times at the MSE and at the MSE-PT, for the various values

of λU ∈ {1, 2.5, 5}. Fig. 10a also shows the expected delivery time achieved when U plays the rational

response strategy, or the shortest path, as a reaction to I choosing its MSE-PT strategy. Fig. 10a shows

that the MSE-PT strategies chosen at different values of λU result in an expected delivery time that is only

slightly higher than the one achieved at the MSE. At higher values of λU , this difference in expected delivery

times decreases. Indeed, at λU = 1, the percentage difference between the MSE-PT and the MSE expected

delivery times is +4.14% while this difference drops to only 1.3% at λU = 5. However, when U plays a

rational response strategy, in response to I’s MSE-PT strategy (which consists of choosing path 12 for all

0.30.40.50.60.70.80.9U202224262830Expected delivery timeRational responseMSE-PTMSEShortest path vs. Interdictor MSE-PT0.20.30.40.50.60.70.80.9U246Operator's    PT valuation  MSE-PTShortest path vs. Interdictor MSE-PTa)b)27

Fig. 10. a) Expected delivery time when U plays a rational response to I’s MSE-PT strategy, at the MSE, at the MSE-PT, and when U chooses

the shortest path in response to I’s MSE-PT strategy, for different λU , b) U ’s PT valuation at the MSE-PT and when unilaterally deviating to

the shortest path.

the three values of λU , i.e. 1, 2.5 and 5), U can achieve an expected delivery time that is up to 11% lower

than the expected delivery time achieved at the MSE. Choosing the shortest path by U would lead to a better

expected delivery time only for λU = 1. Fig. 10b shows U ’s valuation of the MSE-PT strategies as compared

to choosing the shortest path, which highlights the reason for which a deviation from the MSE-PT path to the

shortest path is not valued to be advantageous by U as it leads to an increase in the valuation. In all cases,

choosing the rational response is the most advantageous to U , as shown in Fig. 10a.

VII. CONCLUSION AND FUTURE OUTLOOK

In this paper, we have introduced a novel mathematical framework for studying the cyber-physical security

of time-critical UAV applications, such as drone delivery systems and anti-drone systems. We have provided

a formulation of the problem using the framework of a network interdiction game between the UAV operator

and the interdictor, while viewing either of them as malicious and the other one as benign. In addition, we

have incorporated principles from cumulative prospect theory in the game formulation to account for the

players’ potential bounded rationality. We have characterized Stackelberg (leader-follower) equilibria of the

various types of games and studied their properties. Simulation results have shown that the subjectivity of the

players can lead to delays in the expected delivery time.

This work paves the way for various future research steps. Indeed, the introduced time-critical network

interdiction game can be studied in the presence of multiple UAVs and multiple adversaries as well as

considering dynamically changing security graphs. In addition, the introduced time-critical model can be

leveraged beyond the analysis of UAVs, by focusing on any autonomous system performing a time-critical

mission. Each studied application yields different types of security graphs over which the game can be

formulated and analyzed.

11.522.533.544.55U2121.52222.52323.524Expected delivery timeRational responseMSE-PTMSEShortest path vs. Interdictor MSE-PT11.522.533.544.55U0510Operator's  PT valuationMSE-PTShortest path vs. Interdictor MSE-PTa)b)28

APPENDIX A

PROOF OF THEOREM 1

Proof: We ﬁrst prove that choosing a node n /∈ hs is a dominated strategy for the interdictor. In fact,
If n /∈ hs ⇒ ρ(n) = hs ⇒ Ed(n /∈ hs, ρ(n))=f hs(D) ≤ Ed(n, ρ(n)) ∀n ∈ N , since f hs(D) is the shortest

possible expected delivery time. Hence, the interdictor should always choose a node n that is part of a shortest

O-to-D path, hs. Now, based on (3) and (4), for n ∈ hs,

ρ(n)=






hs, if

pn
1−pn

(f hs(n)+ta)+f hs(D)≤f hn(D),

hn, otherwise,

(62)

(63)

where condition (62) reﬂects that, even when the interdictor is located at n ∈ hs, the shortest path, hs, results

in a shorter expected delivery time than the best alternative, i.e., hn. When this condition is not met, a deviation

from hs to the best alternative, hn, leads to a shorter expected delivery time as captured in (63). In this respect,
(f hs(n)+ta)+f hs(D)≤f hn(D).

we let Nhs denote the set of nodes that are part of hs but are such that

pn
1−pn

Nhs is formally deﬁned in (10). Hence, the two possible alternatives for the optimal choice of I are n1 and

n2 deﬁned as:

n1 = argmax

n∈Nhs

(cid:104) pn

(cid:105)
(f hs(n) + ta) + f hs(D)

,

1 − pn
n2 = argmax
n∈hs\Nhs

f hn(D),

which result, respectively, in expected delivery times:
pn1
1 − pn1
Ed(n2, ρ(n2) = hn2) = f hn2 (D).

Ed(n1, ρ(n1) = hs) =

(f hs(n1) + ta) + f hs(D),

The interdictor’s SE strategy consists, hence, of choosing the best of the two alternatives, n1 and n2:

(cid:40) n1, if Ed(n1, ρ(n1)) > Ed(n2, ρ(n2)),

n∗=

n2,

otherwise,

which will result in SE strategies for U and expected delivery times as stated in (11)-(14).

Proof: We start by considering the case in which n ∈ h. In this case, incorporating I’s valuation of each

APPENDIX B

PROOF OF THEOREM 2

possible outcome, based on (36)-(38), in prospect g(n ∈ h), leads to the following prospect, gI(n ∈ h):

gI(n ∈ h)=

(cid:16)
−λI(−∆I0)β−

I , qn; −λI(−∆I1)β−

I , (pn)qn; ...; −λI(−∆Ik−

)β−

I , (pn)k−

I qn; (∆Ik+

I

I

)β+

I , (pn)k+

I qn; ...

(cid:17)

,

I , k+

I , and ∆Ik > 0, for k > k+
I , ..., ∞}. gI(n ∈ h) can be further split into a negative prospect, g−

such that ∆Ik < 0, for k ≤ k−
{0, 1, ..., k−
the elements of gI(n ∈ h) with ∆Ik < 0 (i.e. for k ∈ {0, ..., k−
includes the elements of gI(n ∈ h) with ∆Ik > 0 (i.e. for k ≥ k+

I ; while ∆Ik is as deﬁned in (38) for k ∈
I (n ∈ h), which includes
I (n ∈ h), which
I ). The negative and positive prospects

I }), and a positive prospect, g+

include, respectively, the outcomes that I values as losses and outcomes that I values as gains. g−
and g+

I (n ∈ h) are expressed as:

I (n ∈ h)

(cid:16)
−λI(−∆I0)β−
g−
I (n ∈ h)=
(cid:16)
g+
I (n ∈ h)=

(∆Ik+

)β+

I

I , qn; . . . ; −λI(−∆Ik−

I

)β−

I , (pn)k−

I , (pn)k+

I qn; . . . ; (∆IkI )β+

I , (pn)kI qn; . . .

(cid:17)

,

I qn
(cid:17)
.

29

(64)

(65)

We next consider the way I values this prospect by incorporating not only its subjective valuation of

outcomes but also its cumulative weighting of the probability of occurrence of each of these outcomes. We

let VI(gI(n ∈ h)) denote the PT value that I gives to prospect gI(n ∈ h), which results from the PT valuation

of the negative and positive components of gI(n ∈ h),

VI(gI(n ∈ h)) = VI(g−

I (n ∈ h)) + VI(g+

I (n ∈ h)).

Here,

VI (g−

I (n ∈ h))=−

(cid:105)(cid:104)
(cid:104)
λI (−∆I0)β−

I

(cid:104)
(cid:105)
−
I (qn)

ω−

(cid:105)(cid:104)
λI (−∆I1)β−

I

ω−
I

(cid:0)qn+pnqn

(cid:1)−ω−

(cid:105)
I (qn)

−...−

(cid:104)
λI (−∆Ik−

)β−

I

(cid:105)(cid:104)

I

(cid:0)

ω−
I

k−
I(cid:88)

i=0

qn(pn)i(cid:1)−ω−

I

(cid:0)

k−
I −1
(cid:88)

i=0

qn(pn)i(cid:1)(cid:105)
,

where ∆Ii is as deﬁned in (38) for i ∈ {0, 1, ..., k−

I }. Hence,

VI (g−

I (n ∈ h))=

(cid:20)
−λI

k−
I(cid:88)

i=0

(cid:16)
(−∆Ii)β−

i

(cid:17)(cid:16)

(cid:0)
ω−
I

i
(cid:88)

j=0

(cid:0)
qn(pn)j(cid:1)−ω−

I

i−1
(cid:88)

qn(pn)j(cid:1)(cid:17)(cid:21)

.

j=0

However, based on geometric series, (cid:80)i
j=0 qn(pn)j = 1 − pi+1
k−
I(cid:88)

n . Then,

VI(g−

I (n ∈ h))=

(cid:16)
−λI(−∆Ii)β−
ω−
I

i

(cid:0)1−pi+1

(cid:1)−ω−

(cid:0)1−pi

n

I

(cid:1)(cid:17)

.

n

A similar analysis can be carried out to obtain the expression of VI(g+
I (n ∈ h)). In this regard,
∞
(cid:105)(cid:104)
(cid:88)

∞
(cid:88)

∞
(cid:88)

∞
(cid:88)

(cid:105)(cid:104)

VI (g+

(cid:104)
I (n ∈ h))=

(∆Ik+

I

)β+

I

(cid:0)

ω+
I

(pn)iqn

(cid:1)−ω+

(cid:0)

I

(pn)iqn

+...+

(cid:1)(cid:105)

(cid:104)
(∆IkI )β+

I

(cid:0)

ω+
I

(pn)iqn

(cid:1)−ω+

(cid:0)

I

(pn)iqn

i=k+
I

i=k+

I +1

i=kI

i=kI +1

i=0

∞
(cid:88)

=

i=k+
I

(∆Ii)β+

I

(cid:104)

(cid:0)

ω+
I

∞
(cid:88)

j=i

(pn)jqn

(cid:1) − ω+

I

(cid:0)

∞
(cid:88)

(pn)jqn

(cid:1)(cid:105)
.

j=i+1

(66)

(67)

(cid:1)(cid:105)

+...

In addition, based on geometric series, (cid:80)∞

j=i(pn)jqn =qn
∞
(cid:88)

(cid:104)
(∆Ii)β+

ω+
I

I

(cid:16) (cid:80)∞

j=0(pn)j− (cid:80)i−1
(cid:0)(pn)i+1(cid:1)(cid:105)

(cid:0)(pn)i(cid:1)−ω+

I

j=0(pn)j(cid:17)

= pi

n which results in

.

(68)

VI(g+

I (n ∈ h))=

Hence, based on (66), (67), and (68),

i=k+
I

VI(gI(n ∈ h))=

k−
I(cid:88)

(cid:16)
−λI(−∆Ii)β−
ω−
I

i

where k+

I = k−

I + 1.

i=0

(cid:0)1−pi+1

n

(cid:1)−ω−

I

(cid:0)1−pi

n

∞
(cid:88)

(cid:1)(cid:17)

+

i=k+
I

(∆Ii)β+

I

(cid:104)
ω+
I

(cid:0)(pn)i(cid:1)−ω+

I

(cid:0)(pn)i+1(cid:1)(cid:105)

,

Next, we consider the case of n /∈ h. When the chosen path h does not include the interdiction node n,
the resulting delivery time does not result in a probabilistic prospect but is rather deterministic and equal to
f h(D) with a probability equal to 1, i.e., g(n /∈ h) = (f h(D), 1). As such, g(n /∈ h) is valued by I depending

on whether f h(D) is higher or lower than RI (i.e. a gain or a loss scenario). Hence, the value, VI(gI(n /∈ h)),
that I associates to prospect gI(n /∈ h), is:

30

VI (gI (n /∈ h))=






(f h(D)−RI )β+

I , if f h(D) ≥ RI ;

−λI (−(f h(D)−RI ))β−
REFERENCES

I , if f h(D)<RI .

[1] K. P. Valavanis and G. J. Vachtsevanos, Handbook of Unmanned Aerial Vehicles. Springer, Dordrecht, 2015.
[2] M. Mozaffari, W. Saad, M. Bennis, and M. Debbah, “Unmanned aerial vehicle with underlaid device-to-device communications: Performance

and tradeoffs,” IEEE Transactions on Wireless Communications, vol. 15, no. 6, pp. 3949–3963, June 2016.

[3] Y. A. Nijsure, G. Kaddoum, N. K. Mallat, G. Gagnon, and F. Gagnon, “Cognitive chaotic UWB-MIMO detect-avoid radar for autonomous

UAV navigation,” IEEE Transactions on Intelligent Transportation Systems, vol. 17, no. 11, pp. 3121–3131, Nov. 2016.

[4] M. Mozaffari, A. T. Z. Kasgari, W. Saad, M. Bennis, and M. Debbah, “Beyond 5G with UAVs: Foundations of a 3D wireless cellular

network,” IEEE Transactions on Wireless Communications, vol. 18, no. 1, pp. 357–372, Jan. 2019.

[5] Y. Nijsure, M. F. A. Ahmed, G. Kaddoum, G. Gagnon, and F. Gagnon, “WSN-UAV monitoring system with collaborative beamforming and

ADS-B based multilateration,” in Proc. IEEE Vehicular Technology Conference, Nanjing, China, May 2016, pp. 1–5.

[6] M. McFarland, “Google drones will deliver chipotle burritos at Virginia Tech,” CNN Money, Sept. 2016.
[7] R. Pahonie, R. Mihai, and C. Barbu, “Biomechanics of ﬂexible wing drones usable for emergency medical transport operations,” in Proc.

E-Health and Bioengineering Conference (EHB), Iasi, Romania, Nov. 2015, pp. 1–4.

[8] G. Xiang, A. Hardy, M. Rajeh, and L. Venuthurupalli, “Design of the life-ring drone delivery system for rip current rescue,” in Proc. IEEE

Systems and Information Engineering Design Symposium (SIEDS), Charlottesville, VA, Apr. 2016, pp. 181–186.

[9] V. Gatteschi, F. Lamberti, G. Paravati, A. Sanna, C. Demartini, A. Lisanti, and G. Venezia, “New frontiers of delivery services using
drones: A prototype system exploiting a quadcopter for autonomous drug shipments,” in Proc. 39th IEEE Annual Computer Software and
Applications Conference (COMPSAC), vol. 2, Taichung, Taiwan, July 2015, pp. 920–927.

[10] Amazon, “Amazon prime air,” 2016. [Online]. Available: https://www.amazon.com/b?node=8037720011
[11] P. M. Kornatowski, A. Bhaskaran, G. M. Heitz, S. Mintchev, and D. Floreano, “Last-centimeter personal drone delivery: Field deployment

and user interaction,” IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 3813–3820, Oct. 2018.

[12] N. Peinecke and A. Kuenz, “Deconﬂicting the urban drone airspace,” in Proc. 36th IEEE/AIAA Digital Avionics Systems Conference (DASC),

St. Petersburg, FL, Sept. 2017, pp. 1–6.

[13] J. Lee, “Optimization of a modular drone delivery system,” in Proc. Annual IEEE International Systems Conference (SysCon), Montreal,

QC, Apr. 2017, pp. 1–8.

[14] A. Troudi, S. Addouche, S. Dellagi, and A. E. Mhamedi, “Post-production analysis approach for drone delivery ﬂeet,” in Proc. IEEE

International Conference on Service Operations and Logistics, and Informatics (SOLI), Bari, Italy, Sept. 2017, pp. 150–155.

[15] K. Dorling, J. Heinrichs, G. G. Messier, and S. Magierowski, “Vehicle routing problems for drone delivery,” IEEE Transactions on Systems,

Man, and Cybernetics: Systems, vol. 47, no. 1, pp. 70–85, Jan 2017.

[16] A. Y. Javaid, W. Sun, V. K. Devabhaktuni, and M. Alam, “Cyber security threat analysis and modeling of an unmanned aerial vehicle

system,” in Proc. IEEE Conference on Technologies for Homeland Security (HST), Waltham, MA, Nov. 2012, pp. 585–590.

[17] K. Mansﬁeld, T. Eveleigh, T. H. Holzer, and S. Sarkani, “Unmanned aerial vehicle smart device ground control station cyber security threat

model,” in Proc. IEEE International Conference on Technologies for Homeland Security (HST), Waltham, MA, Nov. 2013, pp. 722–728.

[18] N. M. Rodday, R. d. O. Schmidt, and A. Pras, “Exploring security vulnerabilities of unmanned aerial vehicles,” in Proc. IEEE/IFIP Network

Operations and Management Symposium (NOMS), Istanbul, Turkey, Apr. 2016, pp. 993–994.

[19] J. Su, J. He, P. Cheng, and J. Chen, “A stealthy GPS spooﬁng strategy for manipulating the trajectory of an unmanned aerial vehicle,”

IFAC-PapersOnLine, vol. 49, no. 22, pp. 291 – 296, Tokyo, Japan, Sept. 2016.

[20] A. J. Kerns, D. P. Shepard, J. A. Bhatti, and T. E. Humphreys, “Unmanned aircraft capture and control via GPS spooﬁng,” Journal of Field

Robotics, vol. 31, no. 4, pp. 617–636, Apr. 2014.

[21] L. Xiao, C. Xie, M. Min, and W. Zhuang, “User-centric view of unmanned aerial vehicle transmission against smart attacks,” IEEE

Transactions on Vehicular Technology, vol. 67, no. 4, pp. 3420–3430, Apr. 2018.

[22] X. Shi, C. Yang, W. Xie, C. Liang, Z. Shi, and J. Chen, “Anti-drone system with multiple surveillance technologies: Architecture,

implementation, and challenges,” IEEE Communications Magazine, vol. 56, no. 4, pp. 68–74, Apr. 2018.
ground

ﬂights,” BBC, Dec.

airport: Drones

“Gatwick

[23] BBC News,

2018.

[Online]. Available: www.bbc.com/news/

[24]

uk-england-sussex-46623754
I. Guvenc, F. Koohifar, S. Singh, M. L. Sichitiu, and D. Matolak, “Detection, tracking, and interdiction for amateur drones,” IEEE
Communications Magazine, vol. 56, no. 4, pp. 75–81, Apr. 2018.

[25] A. Sanjab, W. Saad, and T. Bas¸ar, “Prospect theory for enhanced cyber-physical security of drone delivery systems: A network interdiction

game,” in Proc. IEEE International Conference on Communications (ICC), Paris, France, May 2017, pp. 1–6.

[26] A. Tversky and D. Kahneman, “Advances in prospect theory: Cumulative representation of uncertainty,” Journal of Risk and Uncertainty,

vol. 5, no. 4, pp. 297–323, 1992.

[27] D. Kahneman and A. Tversky, “Prospect theory: An analysis of decision under risk,” Econometrica, vol. 47, no. 2, pp. 263–291, Mar. 1979.
[28] A. R. Hota and S. Sundaram, “Interdependent security games on networks under behavioral probability weighting,” IEEE Transactions on

Control of Network Systems, vol. 5, no. 1, pp. 262–273, Mar. 2018.

[29] G. E. Rahi, A. Sanjab, W. Saad, N. B. Mandayam, and H. V. Poor, “Prospect theory for enhanced smart grid resilience using distributed
energy storage,” in Proc. 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton), Monticello, IL, Sept.
2016, pp. 248–255.

[30] L. Xiao, D. Xu, C. Xie, N. B. Mandayam, and H. V. Poor, “Cloud storage defense against advanced persistent threats: A prospect theoretic

study,” IEEE Journal on Selected Areas in Communications, vol. 35, no. 3, pp. 534–544, March 2017.

[31] T. Bas¸ar and G. J. Olsder, Dynamic Noncooperative Game Theory. Philadelphia, PA, USA: SIAM Series in Classics in Applied Mathematics,

Jan. 1999.

[32] M. L. Puterman, Markov Decision Processes: Discrete Stochastic Dynamic Programming.
[33] C. Audet and J. E. Dennis Jr., “Analysis of generalized pattern searches.” SIAM Journal on Optimization, vol. 13, no. 3, p. 889, Feb. 2003.

John Wiley & Sons, 2008.

