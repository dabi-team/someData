Sneak into Devil’s Colony-Study of Fake Profiles in Online Social 
Networks and the Cyber Law 

  Mudasir Ahmad Wani a                Suraiya Jabin b         Ghulam Yazdani c                        Nehaluddin Ahmad d                     
mudasirwanijmi@gmail.com              sjabin@jmi.ac.in           gyazdani@jmi.ac.in             profnehaluddin.ahmad@unissa.edu.bn               

a, b Department of Computer Science                             c Faculty of Law                                                                d Faculty of Law and Sharia                              
Jamia Millia Islamia (Central University),      Jamia Millia Islamia (Central University),           Sultan Sharif Ali Islamic University,                
           New Delhi, India                                                New Delhi, India                                              (UNISSA) Brunei Darussalam                        
    Abstract  

Massive content about user’s social, personal and professional life stored on Online Social Networks (OSNs) has 
attracted  not  only  the  attention  of  researchers  and  social  analysts  but  also  the  cyber  criminals.  These  cyber 
criminals  penetrate  illegally  into  an  OSN  by  establishing  fake  profiles  or  by  designing  bots  and  exploit  the 
vulnerabilities of an OSN to carry out illegal activities. With the growth of technology cyber crimes have been 
increasing  manifold.  Daily  reports  of  the  security  and  privacy  threats  in  the  OSNs  demand  not  only  the 
intelligent  automated  detection  systems  that  can  identify  and  alleviate  fake  profiles  in  real  time  but  also  the 
reinforcement of the security and privacy laws to curtail the cyber crime.  

In  this  paper,  we  have  studied  various  categories  of  fake  profiles  like  compromised  profiles,  cloned 
profiles and online bots (spam-bots, social-bots, like-bots and influential-bots) on different OSN sites along with 
existing  cyber  laws  to  mitigate  their  threats.  In  order  to  design  fake  profile  detection  systems,  we  have 
highlighted  different  category  of  fake  profile  features  which  are  capable  to  distinguish  different  kinds  of  fake 
entities from real ones.  Another major challenges faced by researchers while building the fake profile detection 
systems  is  the  unavailability  of  data  specific  to  fake  users.  The  paper  addresses  this  challenge  by  providing 
extremely obliging data collection techniques along with some existing data sources. Furthermore, an attempt is 
made to present several machine learning techniques employed to design different fake profile detection systems.  

Keywords  –  Online  Social  Network  Analysis  (OSNA),  Privacy,  Security  &  Trust,  Fake  profiles,  Bots, 
Machine Learning, Cyber Security, Cyber Law, Classification. 

1.  INTRODUCTION 

Online Social Network Analysis (OSNA) is considered as one of the most emerging research fields. An Online 
Social Network (OSN) is the grouping of nodes (individuals, actors, organizations, nations, states or web pages 
etc.)  around  the  world  connected  by  a  set  of  links  (relationships,  interactions,  distances,  hyperlinks,  etc). 
Basically, OSNs refer to the web applications which are primarily designed to facilitate interaction, collaboration 
and share content among users. OSNs have changed the way people think, express, and socialize with outside 
world. Nowadays there are a huge number of social networking sites like Facebook, Twitter, Flicker, LinkedIn, 
Researchgate,  etc.  which  are  used  by  people  to  carry  out  their  social  and  professional  activities.  Since  the 
structure  of  OSNs  bears  a  resemblance  to  the  real-life  communities  and  they  hold  a  massive  amount  of  user 
content, therefore, they are highly important to the researchers and several other disciplines including marketing, 
sociology,  politics,  etc.  Marketing  companies  study  OSNs  to  design  viral  marketing  strategies  and  attain their 
potential customers, sociologists use them to analyze the human behavior and politicians use them to empower 
their political campaigns. [95,100,101]. 
Apart  from  researchers  and  business  organizations,  the  universal  popularity  of  OSNs  has  also  attracted  the 
attention  of  social  criminals.  These  social  criminals  (or  simply  cyber  criminals)  exploit  the  exposure  and 
weakness of an OSN to perform unlawful, misleading, malicious, or discriminatory operations. They penetrate 
into the  social  network  either  by  creating  fake  profiles  or  by  executing  a  number  of  identity  theft attacks  like 
cloning  attacks,  spoofing  attacks  [24],  etc.  on  existing  users  to  steal  their  credentials.  These  cybercriminals 

 
 
 
 
 
 
 
 
 
                                                                                              
especially  the  professional  attackers  also  design  different  types  of  bots  to  control  their  fake  profiles  without 
much human effort [78].  There are various kinds of fake profiles, and their functions generally vary with the 
type  of  network  on  which  they  have  been  established.  A  growing  number  of  hackers  are  creating  forged 
identities on networks like Facebook and Twitter in order to access the social as well as personal information of 
users, to promote a particular brand or a person, to defame a user, etc. Adversaries may target professional sites 
like LinkedIn and Researchgate with the aim to track the activity of the members or to gain the trust of business 
professionals, lure users to give up personal details1. They also target dating websites with the intend to develop 
personal, romantic, or sexual relationships or gain financial benefits, gifts, or personal information, etc. A study 
[114] presented a review of the different security and privacy risks to OSN users, and endow with a simple set of 
recommendations to safeguard user virtual as well as real world.  
      Although,  fake  profiles  are  not  always  harmful;  users  sometimes  create  additional  profiles  for  fun  and 
entertainment, or for connecting with specific friend group only, etc. But as they violate the rules and regulations 
of the  service, they  are considered  as  illegal.  Here  rules  and  regulations  in  the  context  of  OSN  may  mean  the 
owner should not have more than one personal account, it should not spread any unlawful or malicious content, it 
should not collect the user’s information or access network by automated means such as bots and spiders [10, 
76], etc. According to Facebook an account maintaining by a person other than his principal account is fake2. 
Millions of fake profiles exist on popular social networks like Facebook and Twitter especially in the markets of 
China  and  India3.  Social  networking  service  providers  are  employing  a  number  of  ways  to  ensure  the  user 
security.  For  example,  Facebook  has  provided  several  options  to  enhance  the  privacy  of  user  accounts  like 
protecting the password and sending location-specific login alerts and location alerts. Users can also use the extra 
security features of the network like how to log- out from remote devices, how to keep Facebook password safe 
using  app  passwords,  etc. [87].  Besides  that,  Facebook  also  has  its  own  inbuilt  immune  system  [27]  to  detect 
objectionable profiles on the network. Similarly, Twitter [82] and LinkedIn [83] also allow their users to report a 
recognized  spam  or  a  fugitive  content.  Recently  Facebook  introduced  an  Artificial  Intelligence-based  system 
called Deep Text Tool [84] which is able to understand the text like humans. Besides helping the users with what 
they want to say, the tool would also be able to help in filtering the spam content in near future. Furthermore, 
Instagram  is  developing  an  anti-harassment  tool  [86]  to  filter  comments  or  even  help  users  to  turn  off  the 
comment option on a particular post. This way the users can block a particular comment to avoid harassment. A 
study proposed a framework called “Safebook”[85] to protect user’s personal data from both the malicious users 
as well as service providers who violate privacy rules. 
Apart from an enormous number of methods for the detection of malicious users, there are plenty of cyber laws 
for cybercriminals. The cyber laws are usually framed by government IT and cyber experts in every country. As 
per ministry of electronics and information technology, government of India, destroying or altering the computer 
network, computer program or computer source code is punishable with imprisonment up to three years, or with 
fine which may extend up to two lakh rupees, or with both [106]. Also, as per the section 66F of the Information 
Technology  Act  20004,  whoever  commits  or  conspires  to  commit  cyber  terrorism  shall  be  punishable  with 
imprisonment  which  may  extend  to  imprisonment  for  life.  Similarly,  we  have  a  cyber  law  for  identity  theft, 
under section 66C of IT Act, 20005, which states that the person shall be punished with imprisonment of either 
description  for  a  term  which  may  extend  to  three  years  and  shall  also  be  liable  to  fine  which  may  extend  to 
rupees one lakh (INR), whoever, fraudulently or dishonestly make use of the electronic signature, password or 
any  other  unique  identification  feature  of  any  other  person.  Since  there  are  very  strict  regulations  and 
punishments for different category of cyber criminals but still this cyber crime especially cyber terrorism exists 

1 http://www.bbc.com/news/technology-34994858 
2 https://www.facebook.com/legal/terms 
3 http://www.gadgetsnow.com/tech-news/Facebook-may-have-over-100-million-fake-accounts-
globally/articleshow/34672084.cms 
4 http://www.itlaw.in/section-66f-punishment-for-cyber-terrorism/ 
5 https://cybercrimelawyer.wordpress.com/category/66c-punishment-for-identity-theft/ 

                                                           
in every nation. The Information Technology Act in India has proved to be inadequate to a certain extent during 
its  application.  Adversaries  are  easily  hacking  into  banking  systems,  social  networking  websites,  e-commerce 
websites, etc. [107]. The tools and instruments needed to investigate  cybercrime are quite different from those 
used to investigate ordinary crimes.  

In order to control the cyber terrorism, more advanced automated methods for fake profile detection are 
needed. Also, the cyber laws need to be strengthened to handle cybercrimes across the boundaries. Cyber crime 
is a global phenomenon and therefore it should be tackled on the same level.  Collectively it has been observed 
that the need of the hour is to identify a unique set of features to design effective  model for detection of fake 
profiles on social networks and a worldwide uniform cyber laws in order to combat cyber crimes. In this paper, 
we  aim  to  put  everything  about  online  malicious  accounts  at  one  place  along  with  different  cyber  laws  and 
commandments especially in Indian jurisdiction to curtail the fake profiles and their cybercrime.  

OSNs are playing a vital role in contemporary life, people relying on them from different dimensions 
including social interactions, information sharing, and other daily activities. The negative impact on these OSNs 
by Fake profiles not only damages the user experience, but also the marketability and advertising potential of the 
given  OSN.  In  respect  to  above  circumstances,  following  are  some  key  aspects  which  motivate  this  work  to 
survey different kinds of suspicious identities on OSNS.  

  Online Fake profiles exist on every social networking platform with diverse aims. The different nature of 
fake  profiles  and  the  way  they  achieve  their  goals  is  still  at  its  infancy.  Furthermore,  the  cyber  laws 
against  cyber  criminals  are  still  generalised,  inadequate  with  several  shortcomings  such  as,  there  is 
ambiguity  in  terms,  clear  definitions  for  the  important  terms  in  law  are  not  mentioned  which  can  be 
dangerous and may have several degrees of interpretation.   

  As online fake users carry out their illicit operations based on their aim and architecture of the platform 
(online social networking websites), therefore, they may cuddle an exclusive set of attributes. Study of 
unique characteristics about every category of fake profiles can better aid in building efficient detection 
systems. 

  One of the major hurdles faced by researchers while building the fake profile detection systems is the 
unavailability of data specific to fake users on OSNs. Although very few, but there exist obliging data 
collection  techniques  which  should  be  available  to  researchers  in  order  to  obtain  the  data  to  learn  the 
fake profile detection models.    

  A  number  of  studies  towards  detection  of  suspicious  identities  have  been  carried  out  so  far  using 
different machine learning based techniques on different platforms. The evolving research in this domain 
demands the appropriate techniques to deal with all kinds of bogus users. Therefore, all the techniques 
along with types of fake profiles should be available at a single place which assists to solve a particular 
problem with appropriate set of techniques. 

Based on the above aspects the aim of this paper is to collect everything allied to online phony users at a single 
place. The rest of the paper is structured as follows: Section 2 describes the various categories of  fake profiles 
found on different social networking sites along with existing cyber laws to alleviate the threats caused by them. 
Section 3 presents different types of features employed by researchers so far for the detection of fake profiles on 
OSNs.    Several  data  collection  methods  specific  to  fake  profiles  have  been  discussed  in  section  4.  Section  5 
explains different fake profile detection techniques. Finally, section 6 concludes the paper.  

Online Social Network (OSN) Fake Profiles 
To avail the service, most of the OSNs require a user to establish a profile on the network containing his/her 
basic (sometimes personal) information such as name, gender, location, e-mail address, etc.  The openness of 

 
      
 
 
 
these social networking sites enables adversaries to exploit the service by creating different kinds of fake profiles 
to carry out illegitimate, adversarial, unlawful, misleading or malicious activities such as spamming, promotion 
and advertising, stalking, bullying, defaming, etc. However, specific reasons behind establishing the fake profiles 
generally depend on the type of the social network being targeted.  Adversary creates forged identities on 
networks like Facebook and Twitter to access the personal information of users, endorse a particular brand or a 
person or to defame a user, etc. For professional sites like LinkedIn and Researchgate, they aim to track the 
activity of the members or to gain the trust of business professionals. Attackers often target dating websites to 
take the advantage of people who are seeking for ideal matches and work collaborators to extract money from 
these users by playing with their emotions or stealing personal information. One of the most dangerous fake 
profiles on dating OSNs is called Catfisher [108], a person who uses the online dating websites to tempt people 
into a scam romance.  
      The Indian cyber law stated specific provisions for different unlawful operations executed by means of fake 
profiles. According to the section 449 and 500, Indian Panel Code (IPC)6, whoever, by words either spoken or 
intended to be read, or by signs or by visible representations, makes or publishes any imputation concerning any 
person intending to harm, or knowing or having reason to believe that such imputation will harm, the reputation 
of such person, is said, except in the cases hereinafter excepted to defame that person will be punishable with 
imprisonment of two years or fine or both. Similarly, the section 469, Indian Panel Code (IPC)7 deals with the 
forgery  accounts  and  states  that  if  anyone  creates  a  false  document  or  fake  account  by  which  it  harms  the 
reputation of a person. The punishment of this offense can extend up to 3 years and fine. Furthermore, making a 
random fake account is not punishable unless it is fraudulent under the cyber laws of the country.  Under section 
66A (b) of Information Technology act 2000, a person is considered as guilty of sending information which he 
knows  to  be  bogus  and  is  aimed  to  cause  annoyance,  inconvenience,  danger  etc.  The  punishment  for  such 
activities is imprisonment up to three years and a fine could also be levied. 
This  section  provides  an  exhaustive  classification  of  a  different  variety  of  fake  profiles  with  an  emphasis  on 
online social networks, along with cyber laws to curb their consequence.  

OSN Fake Profiles 

Compromised Profiles 

Cloned Profiles 

Sybil Accounts 

Sockpuppets 

Bots as Fake Profiles 

Inter-site Cloning 

Intra-site Cloning 

Social Bots 

Spam Bots 

Like Bots 

Influential Bots 

Bot Nets 

         Figure 1: Types of fake profiles in online social networks  

As shown in Figure 1, the fake profiles have been divided into five categories viz compromised profiles, cloned 
profiles, sybil accounts, sockpuppets, and fake bot profiles which are briefly described in following subsections. 

6 http://bombayhighcourt.nic.in/libweb/oldlegislation/ipc1860/Chapter%2021.pdf 
7 http://www.indianlawcases.com/Act-Indian.Penal.Code,1860-1929 

 
 
 
 
 
 
 
 
 
 
 
 
                                                           
 
 
 
 
 
These  categories  can  be  considered  as  the  different  ways  by  which  the  adversaries  achieve  their  ill  aims  on 
different online social networking platforms.   

2.1 Compromised Profiles 

Compromised accounts are basically the real accounts but their owners don’t have complete control over them 
and they have lost the control to a phisher or any malware agent [7]. As per the Facebook terms and conditions, 
any  legitimate  account  that  is  accessed  by  the  person  who  is  not  the  authorized  owner  of  the  account  is 
considered as compromised. According to authors in [58], compromised accounts are the most difficult type of 
accounts to be detected as the real owner has already maintained a level of trust on the networks. Another recent 
study  [23]  states  that  more  than  97%  profiles  are  compromised  rather  than  fake  which  are  generally  used  to 
spread spam. The fake profiles are generally created to steal the credentials from the real users, and then  these 
fake profiles are abandoned or deactivated and compromised ones are used by adversaries. 
      Compromised  profiles have  much  value  because they  have  already  established  a level  of trust  within their 
network  and  therefore,  they  cannot  be  easily  detected  and  alleviated  from  the  social  network  by  the  service 
providers. The study [23] reveals that the compromised real profiles spread more malicious content than other 
types  of  fake  profiles.  Facebook  assists  its  users  to  recover  hacked  and  compromised  accounts  once  reported. 
There are options such as my-account-was-hacked8 or My-Account-is-Compromised9 on the Facebook help page, 
using which the users can report their compromised accounts.   
      Usually, the cyber criminals launch various phishing attacks to obtain credentials of a real account in order to 
perform several unlawful activities, and this is considered as a serious cybercrime. According to the section 66D 
of  the  Information  Technology  Act,  2000  whoever,  by  means  of  any  communication  device  or  computer 
resource cheats  by  impersonating,  shall  be  punished  with  imprisonment  which  may  extend  to three  years  and 
shall also be liable to fine which may extend to one lakh rupees in Indian currency. Furthermore, section 66C of 
Information Technology Act 2000, (amendment 2008) states that if any person, fraudulently or dishonestly uses 
password  or  any  other  unique  identification  feature  belonging  to  any  other  person,  shall  be  punished  with 
imprisonment of either description for a term which may extend to three years and shall also be liable to fine 
which may extend to amount rupees one million in Indian currency. 
      There are several reasons for a profile to get compromised such as weak passwords, virus infections, sharing 
passwords, etc. Users should take proper care while using the social media accounts to secure their personal and 
social data from cybercriminals.  

2.2 Cloned Profiles  

Profile cloning is a technique in which the adversary establishes  another profile using the information such as 
name, age, gender, profile picture, etc. of any existing real profile.  In other words, we can say profile cloning is 
the process of stealing the victim’s information in order to create one more profile to spread spam, obtain private 
information  about  the  victim  and  victim’s  friends  or  carry  out  other  scams  including,  stalking,  defaming,  etc. 
Once the clone profile is created, the cloner can send friend requests to people in the victim’s friends list and 
start  sending  scam  messages  on  the  name  of  the  victim.  A  clever  cloner  may  even  perform  identity  theft  by 
tricking  the  victim’s  friends  into  revealing  a  large  amount  of  their  personal  and  financial  information.  This  is 
called as Identity Clone Attacks (ICAs) [24].  There are two types of profile cloning attacks namely single site 
profile  cloning  and  cross-site  profile  cloning.  The  attackers  are  usually  well  funded,  skilled  persons  and  have 
almost everything available at their disposal and have control over compromised and infected accounts [27]. The 
adversary can be a strange person, but statistics show that adversary has the knowledge of victim and can be one 
of  the  victim’s  relatives,  friend  or  colleague  [24].  The  two  types  of  cloning  attacks  (intra  site  and  inter-site 

8 https://www.facebook.com/help/131719720300233 
9 https://www.facebook.com/hacked 

 
                                                           
profile  cloning)  are  shown  in  Figure  2  and  Figure  3,  respectively,  and  are  briefly  explained  in  the  following 
subsections. 

2.2.1 Intra site profile cloning: 

 In case of intra site cloning, the adversary creates one more profile of the victim on the same network and sends 
the  friend  requests  or  follows  the  victim’s  friends.  The  victim’s  friends  easily  accept  the  friend  request  by 
treating it as a request from a legitimate user. It is possible to have different online accounts with the same name 
because in real life multiple persons can have the same name with different contact details, mobile number, and 
email address. Adversaries are taking the advantage by creating one more account of an already existing person 
and pretending to be some real person with the same name.  

Profile 
A 

Adversary 

Netwo
rk 

Clone of Profile 
A 

Figure 2: Intra site or same site profile cloning 

2.2.2 Inter site profile cloning: 

The  inter-site  cloning  (also  called  cross-site  cloning)  is  the  process  in  which  the  adversary  creates  one  more 
profile of victim on the new network where the user is not yet registered and sends the request to the victim’s 
friends  who  are  on  both  the  networks.    Inter  site  profile  cloning  can  also  be  viewed  as  the  reconstruction  of 
victim’s friend list in another social network where he/she is yet not registered. The main goal of the adversary in 
creating these cloned profiles is to steal people’s personal information, deceive or defame others or sometimes 
simply for entertainment. These ICAs are a matter of concern for both users as well as service providers as it 
becomes  very  difficult  to  detect  these  kinds  of  attacks.  The  users  simply  treat  it  as  a  friend  request  from  a 
legitimate  user  and  the  service  providers  take  it  as  a  new  user  registering  in  these  online  social  networks  [6]. 
Detection of cloned profiles with more accuracy can enhance the level of security in OSNs which in turn will 
keep users safe from any kind of unauthorized access.  
      A recent study [28] has suggested different ways to cope with cloning attacks and recommended measures 
for OSN sites to improve the security and how the users can protect themselves.  Bilge et al.[6] presented  two 
automated ICAs namely ‘profile cloning’ and ‘cross-site profile cloning’ and proposed prototype attack system 
(iCLONER) to attack the five most popular OSNs including XING, StudVZ, MeinVZ, Facebook and LinkedIn. 
This study showed that ICA schemes are much effective and enemies do not raise much suspicion in users. 
Profile cloning is a serious issue in online social networks. Normal users are not aware that their identities are 
being copied and used as a weapon to destroy their own kingdom by dodgy characters. 
 These  criminals  actually  copy  all  the  content  from  victim’s  profile  including  profile  name,  profile  picture, 
education, work even status updates to give it exactly the same look as the real account and exploits it to perform 
other cyber crimes.  

 
 
 
 
 
 
 
 
 
 
Network 1 

Profile A 

Adversary 

Network 2 

Clone of profile A from network 1 

u1 

u3 

u4
43 

   u1      u2      u3     u4     .   un         

u2 

Figure 3: Inter site or Cross site Profile Cloning  

As  per  section  66C  of  Information  Technology  Act  2000,  (amendment 2008),  if  any  person,  fraudulently  or 
dishonestly uses electronic signature, password or any other unique identification feature belonging to any other 
person, shall be punished with imprisonment of either description for a term which may extend to three years and 
shall also be liable to fine which may extend to amount rupees one million in Indian currency. 
      There are various approaches and techniques [6][28][109] for the detection of cloned profiles in online social 
networks but still, the profiles are cloned and misused at very higher rates. The behavior of these accounts needs 
to be studied more rigorously to spot and stop profile cloning.   

2.3 Sockpuppets: 

A sockpuppet is an account developed with an aim to deceive others or to promote someone or something on 
discussion  forums,  blogs,  social  networking  sites  etc.  In  other  words,  sockpuppets  are  those  online  accounts 
which  are  created  to  cheat  the  netizens  in  different  ways,  for  example,    to  make  the  people  believe  that  a 
particular product is good to buy, there is low risk in an investment plan with high return[40] etc.  Usually, in 
case of OSN sites, the blocked users create new accounts which are referred as sockpuppetry [2]. According to 
the  authors  in  [40],  if  there  exist  two  different  accounts  on  any  news  blog,  social  network  or  any  discussion 
forum that belong to the same person, it is called sockpuppet pair. Sockpuppets are created for several reasons 
including  business  promotions,  fake  reviews  on  books  and  movies,  false  campaigning,  defend  or  support  a 
person or an organization, etc. In case of discussion forums, sockpuppets are used to engage people by deceiving 
others or manipulating discussions. The authors in [104] studied the sockpuppetry and showed that sockpuppets 
have different posting behavior than normal users in various discussion forums.  In OSNs like Facebook, Twitter, 
etc., Sockpuppets are created for the purpose of making more followers, false likes and also for the purpose of 
conducting mass propaganda through retweets and comments. Establishing Sockpuppets is considered as one of 
the main ways of online deception [105].  Nowadays, sockpuppets are used for false marketing- an example of 
astroturfing10,  in  which  the  people  artificially  stimulate  online  conversation  and  positive  reviews  about  a 
particular  product,  brand  or  service. Because  sock  puppets  can  be  created  quickly  and  do  not  need  manual 
maintenance, they are often used on social media sites to attract public interest or defame a competitor’s product, 
brand or service. 
Astroturfing and sockpuppetry, in general, are unethical and illegal. If detected, sockpuppet marketing can have a 
negative  impact,  causing  potential  customers  to  lose  trust  and  doubt  if  the  product  or  service  is  so  lacking  in 
value that it cannot be effectively promoted honestly. In the United States, the Federal Trade Commission (FTC) 
under  Section  5[102]  has  the  legal  authority  to  charge  fines  if  a  company  found  involved  in  sockpuppet 
marketing.  

2.4 Sybil Accounts 

10 https://www.merriam-webster.com/dictionary/astroturfing 

 
 
 
 
 
 
 
 
                                                           
 
In case of sybil accounts, the malicious users create multiple accounts and handle them manually to attack the 
trusted  network.  When  a  node  in  online  social  network  claims  multiple  roles  and  threatens  the  security,  it  is 
referred  as  Sybil  attack.  In  a  Sybil  attack,  the  attacker  weakens  the  reputation  of  a  network by  manually 
establishing and maintaining a large number of pseudonymous identities, using them to spread the malware and 
spam on social networks and to gain a disproportionately large influence. Sybil attackers have many goals like 
bad mouthing an opinion, illegal voting, accessing resources, compromising the security and privacy, etc [36].  
According  to  [37],  social  networks  with  well-defined  community  structure  are  more  exposed  to  these  Sybil 
attacks because their links can be used by the Sybil attackers more effectively. Several studies [36, 37, 38 42, 
68,77] have been carried out so far for the defense of these attacks, but still, the detection of Sybil attacks is in its 
early stage.  
      Disrupting or deceiving the reputation or key functions of a system, network or an individual is considered as 
offense according to the section 41511, Indian panel Code (IPC). According to this section whoever, by deceiving 
any person, fraudulently or dishonestly induces the person so deceived  to the extent to deliver any property to 
any  person,  or  to  consent  that  any  person  shall  retain  any  property,  or  intentionally  induces  the  person  so 
deceived  to  do  or  omit  to  do  anything  which  he  would  not  do  or  omit  if  he  were  not  so,  and  which  act  or 
omission causes or is likely to cause damage or harm to that person in body, mind, reputation or property, is said 
to  "cheat"  and  under  the  section  41712  Indian  panel  Code  (IPC),  whoever  cheats  shall  be  punished  with 
imprisonment of either description for a term which may extend to one year, or with fine, or with both.  

2.5 Bots as Fake Profiles 

A bot is a computer program that runs different scripts to perform human activities over the internet. According 
to the authors in [46], a bot is a computer program that produces some data to interact with humans especially the 
persons using the internet (netizens) in order to alter their behavior. The main use of bots is web data crawling 
where  a  simple  online  computer  program  identifies  and  extracts  the  information  from  web  servers  at  a  much 
higher speed which was not possible by a human alone. More than 60% of the total web data is generated by bots 
[78]. But nowadays the bots have been exploited by spammers on different social networks to execute various 
malicious activities and turned to be a serious threat to the internet. According to a study [10], more than 8% 
bots exist in the Twitter network and most of them have been developed for commercial purposes. The 
cyber  criminals  establish  fake  profiles  on  OSNS  and  control  them  by  an  automated  program  for  performing 
several malicious activities. Bot profiles are used to retweet a post without verifying its source in order to make it 
viral.  In  online  multiplayer  games,  bots  are used  to  gain the  unfair  advantage  [44,  46].  Sometimes  bots  act  as 
automated avatars to interact with humans and create social networks, which are even more difficult to identify 
[45].  Bots  can  also  be  used  to  influence  users,  post  messages  and  send  friend  requests  [47]  in  online  social 
networks.  From the working point of view,  bots are similar as Sybil accounts but the main difference is  Sybil 
accounts are handled by users manually whereas bots are automated computer programs [46]. Many researchers 
are working on the detection of bots in order to mitigate their bad effect. The authors in [99] have deeply studied 
the  behavior  of  bot-controlled Twitter  accounts  and  highlighted  how  bots  use  different retweet  and  mentioned 
strategies while interacting with humans or other bots on the network and presented a framework to detect such 
accounts. 
Various OSN service providers employed a number of ways to fight the spam bots. Facebook has its Facebook 
Immune  System  (FIS)  [27]  to  deal  with  bots.  However,  the  users  in  various  OSNs  claim  that  their  legitimate 
accounts are being caught by the detection techniques.  
      It  is  not  true that  a  bot  is  always  designed  for  malicious  activities. They  can  be  used to  assist the  internet 
users as well. For example, chatbots [103] can be used to help students to answer their day-to-day queries and the 
bots  which  are  developed for  daily  activities like  weather  update  (e.g.  Twitter bots)  are the examples  of good 
bots. But unfortunately, cyber criminals exploit the functionalities of these bots to use them as fake profiles  in 

11 http://thepracticeoflawjalan.blogspot.in/2012/04/offences-cheating.html 
12 http://devgan.in/ipc/section/417/ 

 
 
                                                           
order to perform various unlawful, misleading, malicious operations. Based on the functionality we present five 
categories of fake bot profiles as shown in Figure 4. Each category is discussed in the following subsections.  

2.5.1 Spam Bots  
Spam bot is a computer program specially designed to spread malicious content such as links to personal blogs, 
paid  contents,  pornographic  websites,  and  advertisements,  or  to  shill  for  any  person  or  organization,  etc.  by 
creating a large number of unwanted relationships on the network [50]. 

Spam Bots 

Social Bots 

    Bots 

Like Bots 

Influential Bots 

Bot Nets 

            Figure 4: Categories of Bots in OSNs 

In the [44] the authors studied the behavior of spam bots in the Twitter network and applied several classification 
techniques  to  differentiate  them  from  normal  bots.  One  more  study  in  [46]  has  presented  a  method  known  as 
BotOrNot  to  differentiate  between  a  human  and  a  bot  controlled  Twitter  account  based  on  six  categories  of 
features viz Network, User, Friends, Temporal, Content and Sentiment features. Although the spam bots are new 
to the OSNs, the detection of spams has been previously focused on the emails, web sites, etc.  
      Initially,  spam-bots  were  designed  to  gather  or  harvest,  e-mail  addresses  from  the  Internet  for  sending 
unsolicited  e-mail,  also  known  as spam.  According  to  the  CAN-SPAM  Act  of  2003[98],  the  Federal  Trade 
Commission  (FTC)  has  the  authority  to  levy  fines  up  to  $11,000  against  business  owners  engaging  in 
commercial emails. Also according to Information Technology Act, section 43(b), section 66 read with section 
43(d), (e), (f)13, sending of spam dishonestly or fraudulently is punishable with “imprisonment up to three years 
or fine up to five lakh rupees or both”   

2.5.2 Social Bots 

Social bots are the computer programs used by humans for their several online activities. According to a study 
[49], social bots are highly complex computer programs which behave like humans and usually keep users busy. 
Social bots are the programs which publicize themselves like viruses to reach and infect a maximum number of 
users  [47].  One  more  study  [50]  refers  to  them  as  bots  which  control  accounts  on  online  social  networks  and 
imitate the behavior of legitimate users. 
      Social bots are not always problematic. They are same as other bots in their working but their focus is more 
on building social relations with the online people e.g. politicians can use social bots to get connected with the  
public of interests, companies can use them as their customer care agents, an individual can use them to highly 
influence  a  user  or  a  group  etc.  Social  bots  imitate  the  human  behavior  to  gain  the  attention  (for  example 
followers, friend  requests, replies, likes  etc.)  from  their targets  and  use  this  trust  network  to  spread  content  or 

13 http://vle.du.ac.in/mod/book/print.php?id=9205&chapterid=13341 

 
 
 
 
 
 
 
 
 
 
                                                           
 
 
 
 
 
promote  an  agenda  or  a  product  [49].  Also,  social  bots  play  an  important  role  in  multiplayer  online  games  to 
make  the  game  more  entertaining  and  interesting  for  the  game  lovers  [44].  Bots  can  also  be  used  to  gain  the 
unfair  advantages  in  the  online  games.  Establishing  and  creating  social  bots  is  not  illegal  until  and  unless  it 
causes any disturbance to the normal functionalities of the system. For example, once a social bot found involved 
in diffusing of malicious content over the network, it becomes spam bot, and the owner will be punished with 
“imprisonment up to three years or fine up to five lakh Indian rupees or both” under the IT Act, section 43(b), 
section 66 read with section 43(d), (e), (f).  

2.5.3 Like Bots 

A "Like" is a support of a post, product, business, etc. registered by clicking the button associated with that item. 
Like-bots are just computer programs controlled mostly by advertising companies, politician or a normal user to 
like their products, promote some agenda or to like their activities. One of the main jobs of like-bots is used to 
increase the ‘likes’ on ads or pages, but sometimes they can be used to send messages as well. In several OSNs, 
one  can  buy  fake  likes  for  their  content  [51]  from  different  online  vendors14  and  the  sellers  (usually  cyber 
professionals) make use of multiple numbers of like-bots to like the customer content. The number of likes for a 
product  or  a  page  signifies  its  success  and  reputation.  People  use  like-bots  for  their  own  benefit  which  can 
misdirect the normal users. Obtaining fake likes for a product can lead a customer to believe in the quality of that 
product and prudently setting pseudo followers to your profile can make you influential. Selling and buying of 
fake like and followers is nowadays a million dollar business. Online sites like socialbuzzstore15  provide 1000 
Facebook page likes for 25 (USD) and five hundred Facebook followers cost 19 USD.  
      Very few studies have been carried out for the detection of like bots (or fake likes) so far. In [51] the authors 
have conducted a comparative study of ‘likes’ of Facebook pages produced by Facebook ads and several like-
farms.  The  authors  created  more  than  a  dozen  honeypot  pages  on  Facebook  and  analyzed  the  produced  likes 
based  on  users’  demography,  temporal  and  social  behavior,  etc.  Like-farms  can  make  the  use  of  like-bots  for 
their  businesses,  but  naive  users  need  to  be  aware  of  these  fake  likes,  otherwise,  they  are  likely  to  get 
unacceptable results.  One more study [10] analyzed a number of Facebook accounts used by some Like-farms 
and  compared  their  contents  (posted  on  their  timeline)  with  normal  user  content  and  found  that  Facebook 
accounts  owned  by  like-farms  mostly  produce  likes  and  comments  and  often  post  the  same  content.  Creating 
like-bots for gaining fake likes and bogus followers deceive the customers and can cause potential customers to 
lose trust on the organization. Nowadays, it is very hard to find that how many ‘likes’ for a product or a post are 
from real users and how many of them are fake which results in misdirection and poses a false impact on the 
normal  users.  Therefore,  a  strict  mechanism  should  be  employed  to  identify  the  like-bots  and  shut  them  off. 
Deceiving  the  people  by  means  of  fake-likes  falls  under  the  crime  of  online  deception  and  Federal  Trade 
Commission (FTC) [102] has the legal authority to charge fines if a company found involved in such kinds of 
crime.   

2.5.4 Influential Bots 

     Influential  bots  are  automated  identities  that  illegitimately  perform  discussions  on  some  trending  topics  on 
OSNs like Facebook and Twitter in order to influence opinion or to popularize the topic [52]. Influential bots 
usually generate messages (tweets or posts) either by reposting (or retweeting) the content posted by other users 
on the same network or create their own synthetic message by an already defined set of rules. Nodes (users) who 
are connected to the maximum number of nodes in the network are called core nodes and these core nodes play 
an important role in influencing a topic or an individual. Since the influential nodes have one of their  goals to 

14https://boostlikes.com 
  http://kingdomlikes.com 
15 socialbuzzstore.com 

 
    
                                                           
spread  the  content  to  the  maximum  number  of  people,  therefore,  they  try  to  send  a  maximum  number  of 
friend/connection requests before spreading the content. Influence of a particular node (user) depends upon its 
popularity  and  level  of  trust  in  the  network  and  the  popularity  of  a  node  is  determined  by  the  number  of 
incoming requests or received messages [54].  
      Influential  nodes  play  an  important  role  in  viral  marketing,  but  for  marketing  companies  to  identify 
influential nodes on a network often seems to be challenging. Therefore nowadays the organizations first design 
their  OSN  bots  and  start  getting  into  online  communities  to  reach  the  maximum  number  of  customers.  Once 
these bots obtain trust level within the real users in the network, they start promoting products or brands. 
      The main job of influential nodes in the network is to change the opinion of users about a particular topic or 
product. Influential bots, in the same way, try to change the way the people think about an article or any brand on 
an OSN. Since the normal (real) influential users and the influential bots have almost the same job, therefore it is 
possible that they have some set of features in common. One possible way to identify the influential bots is to 
make  use  of  tools  and  technologies  like  Klout16  and  Twitalyzer17  which  are  used  for  normal  influential 
identification.  Various  studies  have  been  carried  out  for  the  identification  of  influential  users  in  online  social 
media  like  [55],  [56],  [57].  The  more  dangerous  fact  about  "influence  bots"  is  that  they  are  being  used 
systematically to influence any online debate by making something appear popular when it is not. 

2.5.5 Botnet 

The  network  of  automated  computer  programs  in  an  OSN  is  referred  as  Botnet.  Each  program  (bot)  in  this 
network is assigned either a similar or different set of tasks to be performed in an automated manner. A botnet is 
a collection of computer programs handled by a  'control-channel' which gives commands to perform unlawful 
activities [47].  
Since the botnet consists of multiple bots, therefore the botnet controller can perform different kind of tasks like 
spreading malicious content (spam bot), liking a post or a product (like-bot), sending friend request to unknowns 
(interaction/social bot) and popularizing a topic (influence bot) at the same time.       
      Botnets  are  mostly  controlled  by  malevolent  users  called  'botmasters'  by  issuing  commands  to  perform 
malicious activities. Basically, the main purpose of botnets was to assist the users in Internet Relay Chat (IRC) 
chat  rooms  [47]  by  controlling  the  interactions,  providing  help  to  administrators,  offering  games,  extracting 
information about the platform (operating system), and other details of the user such as email addresses, logins, 
aliases etc. In [66] the authors have studied the growth of social botnet in the Twitter network and observed how 
the tweets of a normal user differ from the content generated by a social botnet and how these social botnets help 
in popularization. 
Historically,  botnets  were  primarily  used  to  spread  misinformation,  propaganda  and  for  many  other  malicious 
activities. Several kinds of bots get infiltrated into the target OSN to start a Botnet campaign.  The botnet units 
(bots) help each other by liking the post without verifying it, influencing (retweet or share) the content of each 
other,  writing  the  positive  comment  or  review  etc.  in  order  to  gain  the  trust  in  the  targeted  OSN.  Botnets  are 
mostly designed for different kinds of benefits varying from individual to individual  e.g. shopping companies 
design them to get likes and increase the ratings of their products, researchers, academicians and data scientists 
use  botnets  to  crawl  data  from  the  web,  hackers  and  other  cyber  criminals  use  them  as  tools  for  social 
engineering. A study [53] designed the botnet with three components namely socialbots, botmaster and control-
and-command-channel which handles the targeted OSN profiles, providing commands (like posting a message, 
sending friend/connection request, etc.) and carrying the commands respectively. The botnet has been designed 
to extract the data from the internet.  
     A pictorial representation of a botnet is shown in Figure 5. There are three types of users in the diagram viz. 
normal  users,  infected  users,  and  bots.  Botmaster  is  simply  the  user  (adversary)  who  owns  and  controls  the 

16 https://klout.com  
17 http://www.twitalyzer.com 

                                                           
botnet and provides the commands via command and control channel. The commands are followed by each bot 
in the botnet.  

Botmaster 
(Adversary) 

C
h
a
n
n
e

l

C
o
m
m
a
n
d

a
n
d

C
o
n
t
r
o

l

Online Social Network 

Figure 5: Pictorial representation of an OSN Botnet 

Botnet 

Bots exploit OSNs as an attractive medium to spread the abusive content, bias public opinions, influence user 
perception and perform fraudulent activities, etc. and are very complex and highly evolving threats to users’ trust 
and security on the internet. Therefore, serious strategies and steps should be taken to mitigate their effect and 
risk associated with them. Since OSNs are for real humans, handling profiles by automated programs is against 
the rules  and  regulations  of  OSNs.  Bots,  either  used for commercial  activities, entertainment or research must 
obey the cyber rules and regulations. Table  1 summarizes different kinds of bots and the group of people who 
mainly use them along with the type of network where they are mostly found. 

Purpose 

  Social Bots 
To create 
social, 
personal and 
professional 
relations 

Spam Bots 

To spread 
malicious 
content 

Like-Bots 
To increase the 
ranking/ratings 
To gain false 
followers 

Influential Bots 
To alter the 
behavior of 
people 
To perform viral 
marketing  

     Botnets 

To perform 
various unlawful 
operations by bot 
network  

Used by 

Politicians,  

Cyber criminals,  

Politician 

Researchers, 

Researchers  

Academicians 

Marketing and 
advertising 
agencies. 

Marketing  and 
advertising 
agencies  

Networks 

OSNs,  
Discussion 
forums. 

OSNs. 

e-commerce 
sites,  
OSNs. 

Marketing  and 
advertising 
agencies, 

Celebrities 
OSNs,  
Discussion- 
forums,  e-
commerce.   

Hackers,  

Marketing and 
advertising 
agencies, etc.  

Discussion forums, 
OSNs. 

 
 
 
 
 
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
References 

[19, 27, 44-47, 
49, 50, 52] 

[50,48] 

[51,52] 

[50, 36, 34, 52] 

[10, 47,50, 52, 53, 
66] 

Table 1: Fake Bots and their characteristics 

Fake profiles have been seen very risky for both the OSN service providers as well as their users [33], [34] and 
can be more dangerous in future if not detected at early stage. As soon as one creates an OSN account, he/she 
becomes susceptible for targets of an adversary. The fake profiles can catch one’s behavior and convince the user 
to perform unlawful activities. From above discussion, it can be concluded that fake profiles are basically of two 
types;  one  created  manually  and  the  others  using  automated  methods.  And  automatic  fake  profiles  pose  more 
threats  than  other  kinds  of  fake  profiles.  A  botmaster  can  handle  several  fake  profiles  simultaneously  (botnet) 
which  damages  the  reputation  of  the  network  to  great  extent.  Therefore,  in  order  to  assure  the  privacy  and 
security of user data and reputation of the network, it is suggested to focus on characterization and identification 
of automated fake profiles.  
So  far  we  have  seen  five  different  types  of  fake  profiles  and  their  different  characteristics  exploited  by 
adversaries  in  order  to  perform  illegitimate  activities.  Table  2  summarizes  these  malignant  profiles  and  their 
main goals on the network along with the group of people/organization that are affected by them. 

Cloned Profiles 

Sock Puppets 

Sybil Accounts 

Fake Bot Profiles 

Compromised 
Profiles 

Definition   Existing legitimate 

profile taken over by 
an adversary.  

Duplicate profile of 
existing, legitimate 
profile created by 
cloner. 

Fake account 
developed with 
an intention to 
deceive others  

Purpose 

To defame or steal 
personal information 
of a person.  

To defame or steal 
personal information 
of a person.  

 To spread malicious    
 content by exploiting     
 the trusted network. 

 Fun and  
 Entertainment  

Types 

References  

 Partial-
Compromised(PC),  
Complete- 
Compromised(CC)  

Intra-site cloning, 
Inter-site cloning  

To honor,  
 defend or   
support a   
person or an    
organization 

Manipulate  
 a Public   
 opinion. 

To avoid a  
suspension  
or ban from  
a website.  

Strawman-
sockpuppet, 
Meatpuppet 

Multiple forged 
accounts manually 
established  and 
controlled by a 
malicious user  
Bad  mouthing 
Opinion 

Casting fake votes  

an 

To  spread  malicious 
content. 

Software program desig
ned to control the fake 
profile to perform 
malicious activities 
automatically.    
To perform viral 
marketing (influential-
bots). 

To increase the number 
of fake likes. 

               -- 

Spam-bots, Social-bots, 
Like-bots and 
Influential-bots 

[7] [58] 

[22][24][25][28][29] 

[2] [39][40] 
[41][67] 

[36][37][38][42][68][7
7] 

[10, 44-53, 99 ] 

Table2:  Summarization of various fake  OSN accounts 

 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                
 
 
 
 
 
 
In the cyber world, it has been seen very challenging to recognize any activity as a pure crime. Although 
it  is  not  possible  to  completely  eliminate  cybercrime,  with  the  evolution  of  cyber  space,  new  laws  should  be 
incorporated  and  embedded  into  existing  ones  to  make  them  stronger.  Besides,  the  existing  cyber  laws  are 
associated  with  several  shortcomings  such  as,  there  is  ambiguity  in  terms,  clear  definitions  for  the  important 
terms  in  law  are  not  mentioned  which  can  be  dangerous  and  may  have  several  degrees  of  interpretation.  For 
example, online libel does not define which situations are considered as libelous. Also, the law by creating fear, 
that any negative commentary and criticism may be seen as an “attack,” and inhibits those persons who want to 
speak out.  Sometimes, depending upon the way it is treated, the exposition of the truth may be seen as libelous.  

Table 3: Fake profiles and Cyber Crimes along with Cyber Laws 

Fake Profiles/ Bots 
Compromised Accounts 

Cyber Crime 
Phishing, Defamation, 
Spamming. 

Cloned Profiles 

Identity theft,  Spamming, 
Defamation, Stalking 

Astroturfing, Cheating, Fake 
followers, fake reviews, 
Deception. 
Spamming, pornography,  
Astroturfing, malware 

Sybil Accounts 

Spam Bots 

Like-Bots 

Sockpuppets 

Cyber Law(s) 
Section 66D of the Information 
Technology Act, 2000 
Section 449 and 500, Indian 
Panel Code (IPC)18 
Section 66 C, Section 455, 
information Technology Act, 
2000, 
section 449 and 500, Indian 
Panel Code (IPC), 
section 41519, section 41720 
Indian panel Code (IPC) 

Section  449  and  500,  Indian 
Panel Code (IPC),  
CAN-SPAM Act of 2003 [98],  
Section  43(b),  section  66  read 
with section 43(d), (e), (f).  

Deception, Fake promotion, 
Astroturfing 
Astroturfing, Deception, etc. 

Section 415, Section 449  
Indian Panel Code 1860 
Section 5, Federal Trade 
Commission (FTC) [102] 

As  we  already  discussed  in  the  paper, the  punishment  for  a  crime  depends  upon  its  intensity,  level  of 
damage to the system or the society. Various laws have been outlined for different cyber crimes. The  Table 3 
summarizes different kinds of cyber crime performed with the help of different kinds of fake profiles along with 
the cyber laws to curb them.  

3. Fake Profile Attributes 

For detecting fake profiles on social networking websites, the prime requirement is to analyze the characteristics 
which will distinguish these profiles from the real ones. In order to design an efficient fake profile detector, one 
must  prepare  an  appropriate  and  effective  feature  set.  The  features  can  be  either  observed  manually  from  the 
social  network  sites  or  explored  using  literature  survey.  However,  it is  also  possible  that  some  of  the  features 
existing in literature may not prove to be fruitful at present as the adversaries are keep on changing their behavior 
to  fool  and  bypass  detection  systems.  Different  features  of  online  profiles  have  been  identified  by  several 

18 http://bombayhighcourt.nic.in/libweb/oldlegislation/ipc1860/Chapter%2021.pdf 
19 http://thepracticeoflawjalan.blogspot.in/2012/04/offences-cheating.html 
20 http://devgan.in/ipc/section/417/ 

 
 
                                                           
researchers from time to time to train their fake profile detection models [2, 8, 31, 32, 35, 39, 40, 41, 44] and 
based on their nature, we have categorized them into 5 classes as discussed in following subsections.  

A) Network Based Attributes 

As in real life, people interact with friends, make new friends, discuss issues, etc., the OSN users also perform 
their daily social activities like interacting with online friends, making new friends, and joining new communities 
(groups, pages, etc.) and creating a network of trust within friends. The features which represent the structural 
aspects of a social network are called network attributes, for example, groups joined by users, number of friend 
requests accepted (in degree), number of friend requests sent [8] (out-degree), the extent to which a node acts as 
a bridge between other nodes (betweenness centrality), nearest node to all other nodes in the network (closeness 
centrality), etc. Based on these network attributes various researchers designed models for the detection of fake 
profiles  on  OSNs.  Network  features  are  recommended  for  the  identification  of  fake  profiles  in  Twitter 
network. A  study  [5]  towards  the  characterization  of  real  profiles  have  identified  three  features  including  the 
growth of OSN friends with time, authentic social interactions and change in the structure of OSN graph over 
time.  Under  the  third  feature,  the  average  degree  of  nodes  and  number  of  singleton  friends  are  taken  into 
consideration to detect the fake profiles. Different users have a different set of features, depending upon the type 
of social network they belong to. Therefore, to spot out the malicious users in a specific social network, a study 
of the environment and the culture of that particular network would be more helpful.  

B) Content Based attributes 

What  user  posts  or  shares  on  the  profile  such  as  text,  photos,  videos,  etc.  is  referred  as  content,  for  example, 
numbers of tags in the post, the number of words in the post, etc. The content tells a lot about the behavior of the 
user. Not only  the  behavior but also the  way of thinking, even overall personality of a user on the network is 
reflected  by  his/her  content.    In  the  literature,  researchers  have  employed  several  content-based  attributes  to 
identify  various  kinds  of  spammers  on  different social  networks.  In  [41],  the  authors  have  used content-based 
features like use of capital or lowercase,  quotation-count and punctuation mark for the detection of sockpuppet 
accounts  in  Wikipedia.  Another  study  [8]  on  a  Chinese  social  network  Sina  Weibo  used  attributes  like  the 
number of hash tags and URLs in the post in order to detect the spammers on the network. Similarly, the content-
based attributes like a number of photos of a person tagged in, the number of tags in the uploaded photos by the 
person have been used in [21] for the detection of fake profiles in the Facebook social network. As per the study 
of  authors  in  [59],  if  any  account  posted  a  duplicate  content,  it  can  be  considered  as  spam  account  because 
genuine accounts do not usually update same content multiple times. Another feature can be the message title. 
Twitter has the “hash tag” mechanism by which we can say what a particular post is about.  Usually, the users 
discuss about a particular set of topics of their interests such as favorite sports, favorite movies or some political 
party, etc.  Since the users typically post about their favorite topics and thus are mostly related to each other but 
on the other hand, fake user-generated posts are usually unrelated. This unusual behavior can also help to spot an 
anomalous user. The authors in [3] have used content-based attributes such as the ratio of messages containing 
URL to the total number of messages and similarity among the messages sent by the user to identify spammers 
on Facebook, MySpace and Twitter networks. 
     Initially,  researchers  were  more  focused  towards  the  URL  centric  features  to  detect  human  controlled  fake 
profiles. But with the increasing number of automated spam accounts, other forms of unlawful content such as 
malicious  text,  pornographic  pictures,  etc.  have  also  been  seen  frequent  on  the  network.  Therefore,  several 
opinion  oriented  (content-based)  features  have  been  leveraged  by  various  researchers  for  the  identification  of 
spammers on the social networks. For example, POS (Part Of Speech)-tags feature is a content-based attribute 
which assists in identifying adjectives, adverbs, verbs or nouns used as opinion phrases in the text content. The 
authors in [35] have used a feature like pages liked by the user and other features for the detection of anomalous 

 
user behavior on the Facebook network and stated that if all the pages liked by a user strictly belong to a single 
category only, the user may be considered as suspicious. 

C) Temporal Features 

Temporal features as the name implies are the characteristics related to time, for instance, account creation time, 
last login time, the time between the two status updates, active account time, etc. According to authors in [58], 
the users who post their updates or showing any other activity on their profile in  odd periods (regular sleeping 
hours) can be considered as suspicious. Also, in case of social bots,  it has been seen that a group of accounts 
(botnet) is getting active at the same time, perform activities (usually malicious activities), and logout at the same 
time because social bots are controlled by a single adversary. This time-based behavior can help researchers to 
identify a social botnet. 

D)  Profile Based features 

Profile features refer to the basic information about the user identity on an OSN such as gender, location, age, 
phone number, email address, nationality, profile name, profile picture, number of friends, work and education, 
etc. Several studies [12, 21, 44] have used user profile attributes to distinguish between normal and anomalous 
users  on  different  social  networks.  In  [96],  the  authors  have  applied  several  machine  learning  techniques  on 
profile-based features, friend information (such as the number of friends, number of followers, etc.) as one of the 
predictor  variables  to  expose  spammers  on  MySpace  and  Twitter  network.  In  [44], a  machine  learning  based 
approach has been used for the detection of social bots in the Twitter network where the author has used profile 
feature  like  the  ratio  of  followers  to  the  followee  of  a  user  profile.  Furthermore  according  to  Twitter  spam 
policy, if the number of people following you is less than the number of people followed by you, or you trying to 
follow the people beyond the limit [3], your identity can be considered as suspicious.  Similarly, in a study [12], 
the  authors  used  profile  features  such  as  following/follower  ratio  and  account  age  along  with  other  types  of 
attributes to analyze distinguishing characters of spammers on two Chinese microblogging networks, Sina Weibo 
(weibo.com), and Tencent Weibo (t.QQ.com).  Apart from above list of features, literature is replete with other 
profile characteristics which can be used to identify anomalies in several OSNs, for example, languages known 
by the user as in certain scenarios, some users mention multiple languages in their “languages-known” column, 
later they write posts in some other language, which is not considered as the normal behavior.  

E) Action Based Features 

Action-based attributes refer to the activities performed by the user on a social network, for example, posting, 
uploading  or  sharing,  etc.  Reacting  or  commenting  on  friend’s  posts  also  reflects  the  actions  of  a  user  on  the 
network.  Action-based  features  also  called  activity  features  [30]  play  a  fundamental  role  in  identifying  spam 
accounts as they perform unlawful and discriminatory activities publicly. Another study [8] on a Chinese social 
network Sina Weibo uses attributes like number of messages per day, the number of comments, number of likes 
in the post, etc. to detect the spammers on the network. It has been observed by the authors of the study that the 
spammers post messages three times more than the non spammers. In [35], the authors have used the behavioral 
feature  like  how  frequently  the  user  likes  the  pages  (rate  of  like  activity)  for  the  detection  of  anomalous  user 
behavior on the Facebook network. If the frequency of page likes within a specific time interval is very high, the 
user may be considered as suspicious.  
     All  the  5  categories  of  attributes  discussed  above  have  been  summarised  in  Table  4  below  along  with  the 
category  of  fake  profile  that  has  been  detected  by  using  those  features  on  different  social  networks.  This 
exhaustive  list  of  identified  features  would  certainly  be  helpful  for  researchers  to  build  different  fake  identity 
detection models for social networks.  

   
 
 
 
 
 
Table 4: Different categories of features and type of fake profile identified by them 

Features/Attributes 

Author(s) 

Network 

Targeted fake profile 
Category 

- Profile layout colors (P) 
- First names, user names  (P) 
- Spatiotemporal Information (T) 

- Pages liked by the user (C) 
- Rate of like activity (A) 

-Writing style  (C) 

- Number of Replies (A) 
- Registration Dates (P) 

- Ratio of friend requests sent to the number of 
  Friends (N) 
- Ratio of messages containing URL to the total 
  number of messages (C) 
- Similarity among the messages sent by the user (C) 
- Number of messages sent (A) 
- Friend Count (P) 

- Number of total revisions (A) 
- Article discussion (C) 
- User page (P ) 
-  User discussion page (C) 
- Punctuation count (C) 
- Quotation count (C) 
- Use of capital or lowercase (C) 

- Number of friends (P) 
- Number of followers (P) 
- Follower ratio (P) 

- Number of reposts (C) 
- Number of Comments (A) 
- Number of Likes (A) 
- Number of Mentions (C) 
- Number of URLs in the post (C) 
- Number of Hashtags (C) 
- Education and work (P) 
- Relationship status (P) 
- Gender (P) 
- Number of wall posts by the person (A) 
- Number of photos of person tagged in (C) 
- Number of photos the person has uploaded (A) 
- Number of tags in the uploaded photos by the 
- Person (C) 

[31] 

Twitter 

Spam bots 

[35] 

Facebook 

Sybil Accounts 

[39] 

[40] 

[3] 

Tianya 
(China forum) 

Uwants 
(Hong Kong 
discussion forum) 

Facebook 
Twitter 
MySpace 

Sockpuppets 

Sockpuppets 

Spam bots 

[2] 

Wikipedia 

Sockpuppets 

[41] 

Wikipedia 

Sockpuppets 

[44] 

Twitter 

Spam bots 

[8] 

Sina Weibo 

Sockpuppets 

[21] 

Facebook 

Sybil Accounts 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
- Number of Followers (P) 
- Number of  Followees (P) 
- Number of Friends (P) 
- Number of microblogs to get a fan (A) 

[12] 

Sina Weibo 
and Tencent 
Weibo 

Sockpuppets 

A: Action-based Attribute, C: Content-based Attribute, N: Network-based Attribute, P: Profile-based Attribute, T: Temporal  Attribute 

 4. Data Collection Approaches 

So for we have seen different types of features used in research particularly for the detection of fake suspicious 
identities in OSNs Collecting a required (for example, specific to fake profiles) dataset is considered as a prime 
challenge  while  analyzing  Online  Social  Networking  sites.    Different  techniques  have  been  employed  by 
researchers  to  extract  the  data  from  ONS  sites.    A  study  [113]  has  presented  a  detailed  discussion  on  web  data 
extraction techniques along with the application domains in which they are applied. 
In  this  section  we  discuss different  approaches  to  collect  the required  data  of  both fake  as  well  as  real  profiles 
from a social network. The most popular methods to collect the required data includes data extraction using APIs 
(Application Programming Interfaces) provided by the service providers, designing standalone crawler program, 
generating  artificial  data  using  available  tools,  or  using  existing  datasets  as  shown  in  Figure  7.  All  the  four 
methods are briefly explained as under:  

4.1 Data Collection using APIs  

Collecting  data  using  APIs  is  mostly  used  nowadays  for  social  network  analysis  and  is  highly  recommended. 
Generally, the OSN service providers assist developers and normal users with the several libraries (packages) for 
various data extracting operations. In order to collect the problem specific data from a social network, most of the 
researchers  write  their  own  code  to  interact  with  the  targeted  social  network  via  API.  Almost  every  social 
networking site has its own API, for example, there is GRAPH API21 for the Facebook network which allows its 
users to interact with their application and collect user information. Similarly, for Twitter, there is Twitter REST-
API22.  The  working  of  an  API  is  like  a  web  site,  we  can  pass  the  requests  to  it  and  get  back  a  response  over 
the HyperText Transfer Protocol (HTTP). 
In [60], the authors have used Twitter API  methods to crawl and collect several activities of users such as 100 
most recent tweets, following, followers, etc.  A similar approach was used in [5] in which authors developed a 
Facebook  sensing  application  to  collect  the  required  statistical  information  from  user’s  Facebook  wall  via 
Facebook  Graph  API.  The  researcher  in  [61]  has  designed  and  implemented  an  application  called  “NetVizz” 
based on the Graph API for the collection of information about Facebook users. 

API-Based 
Approach 

Artificial Data 
Generation (ADG) 

 Extracted   
   Dataset 

        Bot-Based 
(Crawler) Approach 

Existing Dataset 
Study (EDS) 

Figure 7: Data Collection Techniques  

21https://developers.facebook.com/docs/graph-api 
22 https://dev.twitter.com/rest/public 

 
 
 
 
 
 
 
 
 
 
 
                                                           
 
 
 
 
 
 
 
 
     
       
   
No  doubt  APIs  are  fast  and  easy  to  use  but  unfortunately,  these  APIs  are  associated  with  several unavoidable 
constraints such as data request rate restrictions, selective data access, etc. The limit on request rate may inhibit 
the user to obtain dataset timely. Also, every piece of information on the network may not be retrieved via these 
APIs.    Therefore,  it  is  not  always  necessary  that  one  will  get  the  required  dataset  by  using  APIs  provided  by 
OSNs. In that case, there are other alternative approaches which are discussed in the following sections. Figure 8 
(a) gives a conceptual view of API-Based data collection approach for social networks.  

Social Network 

Social Network 

Extraction 
Program 

  API 

User Crawler 

User Crawler 
Program 

User Crawler 

  Figure 8 
 (a)   Data extraction using API                                                     (b)   A typical OSN data crawler 

4.2 Bot-Based (Crawler) Approach 

The  bot-based  approach  involves  designing  of  a  standalone  data  crawler  to  extract  the  information  from  the 
social  network.  Like  API-based  approach,  it  also  extracts  the  information  about  users  but  here  the  crawler 
program does not use any API to interact with the social network, rather the direct communication takes place 
between crawler program and the social network as shown in Figure 8 (b).  
Different programming languages may be used to design the data extraction programs such as javascript, python, 
PHP, etc. However, every extraction program requires a set of seed profiles which are usually selected based on 
some criteria such as a large number of friends, location-based profiles, etc. The  seed profiles are used by the 
program in order to traverse the network and extract the information. The network can be explored by several 
graph  traversing  techniques  including  Breadth  First  Search  (BFS)  [19,  61],  Depth  First  Search  (DFS)  [109], 
Forest  Fire  (FF)  [97],  etc.  BFS  technique  is  one  of  the  most  popular  techniques  employed  by  researchers  for 
crawling social networks. It starts at the target profile (seed node) and explores its  neighbor nodes first, before 
moving to the next level of neighbors. In case of DFS crawler, instead of extracting all the neighbors of the target 
profile, the attributes of neighbor’s of the neighbor profile up to a specific level are collected first. 

The  extraction  program  or  generally,  we  can  say  a  data  crawler  needs  three  things. 
First, a source file that contains the URL of target profiles (seed profiles). Second, it requires data fields to be 
extracted from a user profiles. And third, a file to store the extracted data. The conceptual view of data extraction 
program is shown in the figure as under. The crawler program generally makes use of Document Object Model 
(DOM) for determining the information to be scrapped from a user profile. 

     (Seed profile 
file) 

            (Data fields) 

   Data        
   Extraction     
   Program 

(Extracted data file) 

Figure 9: Pictorial representation of Data extraction program 

DOM represents a web page in the form of a tree where HTML tags are denoted by nodes and tree hierarchy 
represents  the  alignment  of  the  data  elements.  In  [3],  the  authors  have  written  a  script  to  get  connected  with 
already  created  honey  profiles  and  extracted  all  the  information  needed  to  detect  the  malicious  activities.  The 
authors in [14] have used java API “HTML Parser” to collect the users’ public information from the Facebook 

 
 
 
 
 
 
 
 
 
 
 
                       
 
                                                                
 
                              
 
 
 
network.  The  authors  in  [115]  have  designed  an  iMacros–based  data  crawler  called  IMcrawler  to  extract  the 
information of users on the Facebook website in order to perform the user behavioural analysis on the network. 

Although,  the  Bot-based  approach  overcomes  the  limitations  of  API-based  approach  there  are  several 
inherent shortcomings with this approach as well. First, writing a complete stand-alone crawler program is a very 
complicated  task  as  one  need  to  start  it  from  scratch.  Second,  most  of  the  social  networks  have  imposed  a 
restriction on automatic data retrieval, for  instance, Facebook has implemented a Facebook immune system to 
notice  any  automated  activity  on  the  network.  Third,  the  data  collected  by  a  bot-based  approach  is  generally 
unstructured in nature which demands strict data pre-processing.     

4.3 Artificial Data Generation 

API-based and bot-based approaches are time-consuming methods for data collection and are highly subject to 
privacy and security settings of users. As in many cases, we need data instantly to solve a particular problem, but 
the  data  cannot  be  at  hand  all  the  time.  Also,  one  may  not  have  access  to  the  data  of  interest  because  of  the 
privacy  concerns.  Therefore,  in  such  cases,  we  generate  the  synthetic  data  sample  based  on  the  structure  of  a 
network or the characteristics of existing datasets with the help of existing data generator packages [64,110, 111] 
or by designing synthetic data generators [93]. 
The  data  can  be  generated  using  various  available  tools  based  on  the  known  statistics  or  parameters  of  any 
existing  social  network.  For  example,  if  we  know  the  degree  distribution,  clustering  coefficient,  average 
betweeness centrality and other statistical parameters, a dummy data set can be generated for analysis purposes. 
The various online data generators like GEDIS Studio [110], Databene Benerator [111], etc. are available for the 
generation  of  artificial  data23.  However,  the  artificially  generated  will  not  be  useful  till  its  resemblance  is  not 
verified with the original data. 

4.4 Existing Dataset Study (EDS)  

The researchers can also  conduct different studies  using the  data that have been collected by  others and made 
available to the public for the further use. The process is called secondary analysis, where the study is conducted 
on  the  dataset  generated  by  others.  Authors  in  [90]  used  the  public  dataset  to  conduct  analysis  on  social 
bookmarking  website-BibSonomy  for  predicting  the  spam  users.  The  use  of  existing  datasets  saves  a 
considerable  amount  of  time  and  effort  of  researchers.  Moreover,  since  the  available  dataset  has  already  been 
used for analysis, it contains less noise, outliers, and missing values, etc. and therefore, does not demand rigorous 
pre-processing.  Several  researchers  have  generated  the  data  for  their  analysis  and  made  it  available  for  others 
[89,  91].  Also,  there  are  a  number  of  resources  on  the  web  that  serve  as  the  repository  of various  publicly 
available datasets [70], [72], [74], verified and authenticated by research communities for solving various social 
network analysis problems. Some need a registration process or a request via email [71], [73], [75]. However, the 
main  disadvantage  of  the  existing  datasets  is  that  it  may  not  include  all  the  features  what  an  investigator  is 
interested in. Since we are more focused towards fake profiles and the data in existing datasets hardly contain all 
the features that better serve the purpose, therefore, the existing datasets are least used for fake profile detection 
in OSNs.  
      The selection of data collection technique mainly depends upon the data of interest. After the identification of 
features for the detection of fake profiles, we need to make sure if the data related to these features is existing in 
any  of  the  available  datasets  or  can  be  generated  artificially.  In  that  case,  we  directly  get  our  sample  data.  If 
neither of the two techniques (artificial data generation and existing datasets)  solves the problem, there are two 
alternative techniques, API-based and bot-based, to deal with the problem. The API-based approach may restrict 
the researchers to extract every piece of information of their interest while as the bot-based approach enables a 

23 http://www.freedatagenerator.com, http://www.generatedata.com,.https://www.mockaroo.com 

     
 
                                                           
user  to  extract  every  piece  of  information  visible  on  a  browser  but  at  the  expense  of  technical  complexities. 
However,  in  both  the  two  approaches  data  is  explicitly  scrapped  from  user  profiles  by  writing  an  extraction 
program. Therefore, a set of fake and real profiles need to be selected for the extraction of information. Real user 
profiles  can  be  easily  obtained  from  our  friend  list,  follower  list,  trusted  people,  etc.,  on  the  other  hand  for 
selecting a set of fake profiles, we have suggested three methods which are discussed in the following subsection. 
It should be noted that data collection process may involve more than one data collection technique to harvest the 
data based on the problem under consideration.  

4.5 Profile Selection Approaches 

It is now clear from above subsections that, existing datasets and artificial data generation methods do not need 
any kind of profiles to extract the data while as the rest of the two approaches (API-based approach and crawler-
based approach) require a list of profiles (seed nodes) to extract data. In order to extract data via API or through 
a  crawler,  we  need  both  real  and  fake  profiles.  The  real  profiles  are  available  in  the  abundant  amount  on  the 
social network, so can be easily located. One can use the account of trusted users and their network of friends to 
collect the real profiles. Trusted users can be friends, verified accounts or profiles of personally known users on 
the network. However, in comparison to real profiles, the fake accounts exist in much lesser amount than the real 
ones  which  make  it  very  difficult  for the researchers to  locate them  on  a  huge network  with  billions of  users. 
According to a study on Facebook, out of 955  million monthly active users, 8.7% of the users are reported as 
fake24.  In  order  to  obtain  the  list  of  fake  profiles  for  data  extraction,  we  describe  three  approaches  namely, 
manual-approach, honey profile-based approach  and botnet-based approach. Honey profile-based approach [3] 
involves the creation of fake attractive profiles (honeytraps) to attract the people (especially fake) towards them. 
In case of Botnet approach, a network of interrelated bots (computer programs) is created to interact with other 
bots and normal users to obtain the fake profile list for data extraction. All the three approaches to obtain fake 
profiles to be extracted by one of the above-mentioned data extraction approaches are discussed as under.  

A)   Manual Approach 

In  case  of  manual  approach,  we  need  to  explore  the  suspicious  accounts  manually  and  keep  a  record  of  the 
profiles found involved in malicious activities [14].  Generally, in manual selection approach, there are several 
ways to investigate and select fake profile set. One way is to manually collect a list of random profiles from a 
network and label every profile in the list based on a set of characteristics which distinguish real profiles from 
forged ones. For instance, if any user found to be involved in spreading malicious or unlawful content on his/her 
profile  or  friends  profile,  it  may  be  fake  and  later  the  information  is  crawled  from  it  using  any  of  the  data 
collection methods.  In another way, the researchers extract the user attributes from the network and can create 
fake  profile  set  with  the  help  of  domain  experts  by  carefully  inspecting  each  attribute  of  the  collected  dataset 
[94]. The manual fake profiles selection approach also includes those accounts which had already been detected 
and labelled as fake by OSN service providers or the research organizations25.  

B)  Honey Profile Based Approach 

Honey  profiles  as  the  name  indicates  are  the  OSN  profiles  used  to  attract  other  (most  likely  similar)  users 
towards  them.  Different  types  of  honey  profiles  or  simply  honey-traps  are  established  to  attract  both  real  and 
fake users as per the requirement. For example, some people create honey profiles to attract specific group such 
as  teenagers  and  young  people  on  the  targeted  network  while some  people  create  honey  profiles to  attract  the 
general public.  However, in case of fake profile selection, the researchers  create honey  profiles such as porn-

24 https://www.digitaltrends.com/mobile/8-7-percent-of-facebook-users-are-fake/ 
25 https://www.barracuda.com/ 

 
 
                                                           
based  profile  which  specifically  entice  the  fake  ones  of  the  same  category  [30].  To  make  the  honey  profiles 
active all the time the owners constantly keep on updating these profiles with latest and interesting stories and 
images.    The  authors  in  [3]  have  created  around  900  honey  profiles  on  three  different  social  networks  viz 
Facebook, MySpace and Twitter and then analyzed the collected profiles to identify the anomalous behavior of 
users  who  contacted  their  honey  profiles.  Similarly,  in  [9],  the  authors  created  eight  very  interactive  and 
attractive  profiles  on  Facebook  with  different  age  groups  to  collect  the  user  profiles  and  observed  these  eight 
profiles for a period of three months. Another study [51] has used honey profiles to collect and uncover social 
spammers  in  social  networks.  As  the  honey  pots  attract  users’  attention  on  the  large  scale,  therefore,  they  are 
mostly expolited by spammers to spread malicious activities as well. 

C)  Botnet Based Approach 

As already discussed, a botnet is a network of automated programs (bots) controlled and supervised by a human 
controller called 'botherder', designed to perform a number of tasks such as interacting and attracting other users 
on the network, promoting products and brands, election campaigning, etc. [53]. Unlike above two approaches, 
where we select already existing fake profiles on the network, the botnet-based approach involves the injection 
of  a  series  of  automated  interacting  fake  profiles  into  the  network  and  increasing  the  trust  level  among  other 
users on the network to obtain the fake profile list. Unlike honey profiles which most of the time wait passively 
for the specific connection requests, the profiles in botnet are mostly active and are constantly involved in tasks 
like  sending  connection  requests,  generating  content  [47],  etc.  in  order  to  gain  large  user  base.  Moreover,  the 
honey  profile-based  approach  is  effective  to  attract  a  specific  domain  of  profiles  such  as  pornographic  fake 
profiles  or  other  adult  content  spreading  profiles,  etc.,  but  would  not  give  satisfactory  results  in  attracting 
domains like astroturfing accounts. On the other hand, botnet approach can be used to simulate the behavior of 
broader domains of fake profiles. Later on, the botnet profiles as well as the fake profiles attracted by botnet are 
used  to  construct  a  fake  profile  dataset.    In  [53],  the  authors  have  designed  a  botnet  with  three  components, 
socialbots, botmaster and control-and-command-channel to show the vulnerability of OSNs to an infiltration by 
socialbots. The pictorial representation of a botnet is shown in Figure 5.  

5. Fake Profile Detection Techniques 

In section 2, several types of OSN profiles and their properties have been described. Here, in this  section, we 
highlight category wise, the different machine learning techniques, employed by researchers for the identification 
of different categories of fake profiles on online social networks.   
It has been observed that compromised accounts play a vital role in spamming as these users exploit the level of 
trust maintained by the real users on the network. In the paper [58] authors proposed a tool, COMPA to detect 
compromised  accounts  on  Twitter  and  Facebook.  The  authors  have  used  statistical  modelling  to  build  the 
behavioral profile of users on the basis of characteristics of their sent messages and use several similarity metrics 
like  n-gram  analysis  to  compute  the  anomaly  score.  The  authors  have  used Sequential  Minimal  Optimization 
(SMO)  to  determine  the  weights  of  the  features  in  the  dataset.  In  paper  [23]  the  authors  have  detected  spam 
campaigns  on  Facebook  by  applying  clustering  techniques  on  the  wall  posts.  They  further  analyzed  each 
malicious  account  for  the  presence  of  compromised  accounts  based  on  the  content  (photos,  videos,  etc.) 
generated on their walls.   
     A  number  of  researchers  have  focused  towards  to  detection  of  cloned  accounts  on  the  social  networks.  In 
[25],  authors  have  used  Markov  Clustering  algorithm  (MCL)  to  divide  the  Facebook  network  into  smaller 
communities based on their similarities, all the profiles similar to the real profiles are gathered to calculate the 
strength of the relationship in order to check whether it is a clone or not. In another study [29], authors propose a 
method  for  detecting  social  network  profile  cloning  by  designing  a  system  with  three  components  namely 
information distiller, profile hunter, and profile verifier. Information distiller extracts the information from real 

 
 
 
user profiles and selects attributes which can be used to uniquely identify the profile. Profile hunter processes the 
information and locates the profiles of the user on different OSNs. Profile verifier calculates the similarity score 
between all the profiles and presents the result to the user.  
     Several studies have also been conducted to identify sockpuppet accounts on social networks. A study in [39] 
has  created  a  network  of  users  based  on  their  topics  of  interest  on  Tianya  forum  and  Taobao  online  auction 
website.  Based  on  the  writing  style  of  the  users,  the  author  pruned  the  graph  to  obtain  sockpuppet  network 
(SPN). Finally, the different community detection techniques have been applied on SPN to identify sockpuppet 
communities.  Another  method  to  detect  sockpuppets  on  a  Hong  Kong-based  discussion  forum  is  presented  in 
[40]. The method is based on the total number of topics posted by one account and the number of replies from 
the other accounts. A detection score is calculated to spot a sockpuppet pair. The larger the score, the more will 
be  the  chances  of  two  accounts  being  the  sockpuppet  pair.  Based  on  the  verbal  features  like  of  the  user's 
Punctuation  count,  Quotation  count,  Use  of  capital  or  lowercase,  the  authors  in  [41]  presented  a  sockpuppet 
detection method for Wikipedia network using natural language processing techniques. 
     Researchers  also  paid  a  vital  attention  towards  the  detection  and  mitigation  of  Sybil  accounts  from  social 
networks  [36,  42,  68,  77],  but  the  detection  of  Sybil  attacks  is  still  in  its  infancy.  Most  of  the  Sybil  defense 
techniques work on the ranking of nodes based on how well a node (an account) is connected to trusted nodes 
(legitimate  accounts),  the  node  has  a  higher  rank  if  it  is  within  the  local  community  of  a  trusted  node.  In 
SybilGuard  [38]  the  authors  present  a  novel  approach  to  protect  a  social  network  from  Sybil  attacks.  They 
consider the link between two nodes as a trust relationship. Sybil nodes are differentiated from trust nodes using 
the calculated trust-relationship. Basically, the SybilGuard depends upon two characteristics of underlying social 
networks,  first,  the  trusted  accounts  always  have  a  huge  number  of  links,  second,  the  fake  users  create  many 
nodes  (accounts)  but  with  few  trusted  connections.  The  authors  in  [30]  have  used  Markov  Clustering  (MCL) 
technique  on  real  data  of  Facebook  network  for  the  identification  of  fake  profiles  using  the  features  such  as  
Facebook fan pages, links shared and active friends, etc. MCL technique groups the users into three clusters, one 
contains all the fake identities, second contains all the normal profiles and the third cluster contains the mixture 
of both. This study suggested that techniques like a decision tree, Support Vector Machine (SVM), Naïve Bayes 
(NB) etc. can be a choice to classify profiles as fake or real, but do not work efficiently for the social network 
profile dataset with multiple classes. Also, there is a scarcity of such well-defined profile data sets and most of 
the data set neither have any predefined class label nor a well-defined feature set, therefore unsupervised learning 
techniques are preferable over supervised techniques. Similarly, a novel approach has been proposed by authors 
in [31] for deception detection in a Twitter using gender and location attributes by applying Bayesian classifier 
and k-means clustering. Authors in [3] have designed a classifier based on Random Forest (RF) algorithms to 
identify the spammers among users who got connected with their honey profiles. Based on the spam strategy, 
four categories of spam profiles were distinguished namely Displayer, Bragger, Poster, and Whisperer.  
     Spam bot detection is also taken into consideration by several researchers. The  authors in [44] have shown 
that out of four (decision tree, support vector machine, K-nearest  neighbor and neural networks) classification 
techniques,  the  Bayesian  classifier  is  the  best  in  predicting  spam  bots  in  Twitter  network.  In  [10]  the  authors 
have studied the growth of social botnet in the Twitter network and observed how the tweets of a normal user 
differ  from  the  content  generated  by  a  social  botnet  and  how  these  social  botnets  help  in  popularization.  The 
authors of a  study  [52]  proposed  a framework  that  comprises  of three steps for  detecting  influential  bots on  a 
social network.  In  the  first  step,  the  bots are  identified  by  basic  techniques  like manual  inspection,  behavioral 
analysis or linguistic knowledge. In the second steps, more bots are identified on the basis of clustering, outliers 
and network analysis. In the third step, remaining bots are identified by building the classifier using the bots and 
humans identified in the earlier steps as training data. 

Network 

Fake Profile Category 

Technique(s) 

Author(s) 

 
 
 
 
Twitter 

Spam bots 

Facebook 

Compromised 
Accounts 
Sybil Accounts 

Tianya 
(China forum) 

Sockpuppets 

Twitter 

Spam Accounts 

Bayesian classification 
K-means clustering 
k-Nearest Neighbor (kNN) 
Principal Component Analysis (PCA) 

Authorship-identification techniques 
Link Analysis 

Random Forest 
Sequential Minimal Optimization 
(SMO) 
Naïve Bayesian 
K-NN neighbor 

Facebook 
Twitter 
MySpace 

Spam bots 

Random Forest algorithm 

Twitter 

Spam bots 

Wikipedia 

Sockpuppets 

Wikipedia 

Sockpuppets 

Twitter 

Spam bots 

Sina Weibo 

Sockpuppets 

Twitter 

Sybil Accounts 

Facebook 

Sybil Accounts 

Sina Weibo 
Tencent Weibo 

Sockpuppets 

Random Forests 
AdaBoost, 
Logistic Regression 
Decision Tree 

Support Vector Machine (SVM) 
Random Forest (RF) 
Adaptive Boosting (ADA) 

Support Vector Machine (SVM) 
Bayesian classification 

Support Vector Machine (SVM) 

Support Vector Machine (SVM) 

K-means Clustering 
Naïve Bayesian Classifier 
Support Vector Machine (SVM) 
Decision Tree-C4.5 (J48) 
IBk, 
Naive-Bayes 
Bagging 
AdaBoostM1 
Rotation Forest 
OneR 

Twitter 

Twitter  
Facebook 

Spam Accounts 

Compromised 
accounts 

Bayesian classification  Algorithm  
N-gram Analysis 
Sequential Minimal Optimization 
(SMO) 

[31] 

[35] 

[39] 

[60] 

[3] 

[99] 

[2] 

[41] 

[44] 

[8] 

[36] 

[21] 

[13] 

[59] 

[58] 

Table 5: Commonly used machine learning techniques for detection of suspicious accounts on OSNs 

Apart  from  above  discussed  approaches,  we  have  presented  few  most  popular  and  commonly  used  machine 
learning techniques in Table 5, employed in research to detect the fake profiles on social networking websites.    

It can be clearly seen from the above table that SVM, Decision tree and Bayesian classification algorithms have 
been mostly used in the fake profile detection  studies. Furthermore, most of the researchers have used Twitter 

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
social network to conduct their study. The reason can be the availability of data as the Twitter allows access to 
the user data for research purpose [48]. Keeping that in mind, this paper also provides different approaches to 
obtain data from social networking websites and assist researchers to carry out their studies on different OSNs in 
different dimensions.        
Different  machine  learning  based  techniques  have  been  applied  for  the  prediction  and  identification  of  forged 
accounts on social networks, but most of the researchers concentrate only on a specific type of fake profile which 
lefts the other fake profile categories undetected and enables the attacker to contaminate the network. Therefore, 
a generalized method which can spot maximum types of fake identities on a social network is highly required. 
Here in this paper, put everything about several kinds of fake profiles at a single place which assists researchers 
in designing a generalized and an efficient fake profile detection model. Furthermore, with the passage of time, 
the  number  of  users  and  the  content  generated  by  them  on  these  social  networks  is  growing  rapidly  and  the 
prediction becomes more challenging. Therefore, identifying the anomalous behavior or conducting any kind of 
analysis  on  social  networks,  highly  scalable  machine  learning  techniques  for large-scale  graph  analysis,  graph 
partitioning, and clustering algorithms are needed.    

6. Conclusions  

With thousands of fake profiles on different OSNs having multifaceted aims to deceive, one need to adapt more 
advanced methods to secure one’s online presence as least can be done when the security gets compromised. In 
this paper, we have described various types of OSN threat generators (fake profiles) like compromised profiles, 
cloned profiles and online bots (spam-bots, social-bots, like-bots and influential-bots). An exhaustive effort has 
been taken to put all kinds of  malicious entities on OSNs at one place along with existing cyber laws to curb 
imposters. Since there are very strict regulations and punishments for different categories of cyber criminals but 
still cybercrime and cyber terrorism dictates across the world. The most important reason for failure in nabbing 
the  cyber  criminals  is,  the  investigators  are  not  able  to  get  a  trace  of  the  criminals  as  the  crime  is  mostly 
conducted across the boundaries of the nation. Therefore, the need of the hour is a worldwide uniform cyber law 
to combat cyber crimes.  This paper also provides a brief outlining of pro and cons of several existing cyber laws 
which are framed to curb the online fake profiles. Also, to alleviate the data crunch faced by OSN researchers, 
the paper also highlights different data crawling approaches along with some existing data sources. Furthermore 
a rigorous survey of techniques used in studies for fake profile detection, has been presented. 
              Many researchers have tried to mitigate fake profiles to some extent but more concrete steps are still to 
be taken. It can be concluded that the need for more advanced automated methods still remains unfulfilled for 
secure  social  networks.  The  appropriate  and  timely  steps  are  needed  to  develop  automated  mechanisms  to 
identify suspicious users.  

References 

1.  Wang,  G.  A.,  Chen,  H.,  Xu,  J.  J.,  &  Atabakhsh,  H.  (2006).  Automatically  detecting  criminal  identity 
deception:  an  adaptive  detection  algorithm. IEEE  Transactions  on  Systems,  Man,  and  Cybernetics-Part  A: 
Systems and Humans, 36(5), 988-999 

2.  Tsikerdekis, M., &Zeadally, S. (2014). Multiple account identity deception detection in social media using 

nonverbal behavior. Information Forensics and Security, IEEE Transactions on, 9(8), 1311-1321. 

3.  Stringhini,  G.,  Kruegel,  C.,  &Vigna,  G.  (2010,  December).  Detecting  spammers  on  social  networks. 

In Proceedings of the 26th Annual Computer Security Applications Conference (pp. 1-9). ACM. 

4.  Shen,  H.,  &  Li,  Z.  (2014).  Leveraging  social  networks  for  effective  spam  filtering. Computers,  IEEE 

Transactions on, 63(11), 2743-2759. 

5.  Conti, M., Poovendran, R., &Secchiero, M. (2012, August). Fakebook: Detecting fake  

 
 
 
 
 
 profiles  in  on-line  social  networks.  In Proceedings  of  the  2012  International  Conference  on  Advances  in 
Social Networks Analysis and Mining (ASONAM 2012) (pp. 1071-1078). IEEE Computer Society. 

6.  Bilge, L., Strufe, T., Balzarotti, D., & Kirda, E. (2009, April). All your contacts are belong to us: automated 
identity theft attacks on social networks. In Proceedings of the 18th international conference on World wide 
web (pp. 551-560). ACM. 

7.  Savage,  D.,  Zhang,  X.,  Yu,  X.,  Chou,  P.,  &  Wang,  Q.  (2014).  Anomaly  detection  in  online  social 

networks. Social Networks, 39, 62-70. 

8.  Zheng,  X.,  Zeng,  Z.,  Chen,  Z.,  Yu,  Y.,  &Rong,  C.  (2015).  Detecting  spammers  on  social 

networks. Neurocomputing, 159, 27-34. 

9.  Krombholz,  K.,  Merkl,  D.,  &Weippl,  E.  (2012).  Fake  identities  in  social  media:  A  case  study  on  the 

sustainability of the facebook business model. Journal of Service Science Research, 4(2), 175-212. 

10.  Facebook: Statement of rights and responsibilities https://www.facebook.com/terms, January 30, 2015, doa: 

June 12, 2016 

11.  Ahmed, F., &Abulaish, M. (2012, June). An mcl-based approach for spam profile detection in online social 
networks. In Trust, Security and Privacy in Computing and Communications (TrustCom), 2012 IEEE 11th 
International Conference on (pp. 602-608). IEEE. 

12.  Zhou,  Y.,  Chen,  K.,  Song,  L.,  Yang,  X.,  &  He, J. (2012,  August).  Feature  analysis  of spammers  in  social 
networks  with  active  honeypots:  A  case  study  of  Chinese  microblogging  networks.  In Proceedings  of  the 
2012 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2012) (pp. 
728-729). IEEE Computer Society. 

13.  Fire, M., Kagan, D., Elyashar, A., &Elovici, Y. (2014). Friend or foe? Fake profile identification in online 

social networks. Social Network Analysis and Mining, 4(1), 1-23. 

14.  Ahmed,  F.,  &Abulaish,  M.  (2013).  A  generic  statistical  approach  for  spam  detection  in  Online  Social 

Networks. Computer Communications, 36(10), 1120-1129. 

15.  Mislove,  A.,  Viswanath,  B.,  Gummadi,  K.  P.,  &  Druschel,  P.  (2010,  February).  You  are  who  you  know: 
inferring user profiles in online social networks. In Proceedings of the third ACM international conference 
on Web search and data mining (pp. 251-260). ACM. 

16.  Raad,  E.,  Chbeir,  R.,  &  Dipanda,  A.  (2010,  September).  User  profile  matching  in  social  networks. 
In Network-Based Information Systems (NBiS), 2010 13th International Conference on (pp. 297-304). IEEE. 
17.  Backstrom,  L.,  Dwork,  C.,  &  Kleinberg,  J.  (2007,  May).  Wherefore  art  thou  r3579x?:  anonymized  social 
networks, hidden patterns, and structural steganography. In Proceedings of the 16th international conference 
on World Wide Web (pp. 181-190). ACM. 

18.  Bhagat, S., Cormode, G., Krishnamurthy, B., & Srivastava, D. (2009). Class-based graph anonymization for 

social network data. Proceedings of the VLDB Endowment, 2(1), 766-777. 

19.  Catanese,  S.  A.,  De  Meo, P.,  Ferrara,  E.,  Fiumara,  G.,  &Provetti,  A.  (2011,  May).  Crawling  facebook  for 
social network analysis purposes. InProceedings of the international conference on web intelligence, mining 
and semantics (p. 52). ACM. 

20.  Wu,  W.,  Xiao,  Y.,  Wang,  W.,  He,  Z.,  &  Wang,  Z.  (2010,  March).  K-symmetry  model  for  identity 
anonymization  in  social  networks.  In Proceedings  of  the  13th  international  conference  on  extending 
database technology (pp. 111-122). ACM. 

21.  Sarode, A. J., & Mishra, A. (2015, September). Audit and Analysis of Impostors: An experimental approach 
to  detect  fake  profile  in  online  social  network.  In Proceedings  of  the  Sixth  International  Conference  on 
Computer and Communication Technology 2015 (pp. 1-8). ACM. 

22.  Jin,  L.,  Takabi,  H.,  &  Joshi, J.  B.  (2011,  February). Towards  active  detection  of  identity  clone  attacks  on 
online  social  networks.  In Proceedings  of  the first  ACM  conference  on  Data  and  application  security  and 
privacy (pp. 27-38). ACM. 

23.  Gao, H., Hu, J., Wilson, C., Li, Z., Chen, Y., & Zhao, B. Y. (2010, November). Detecting and characterizing 
the  10th  ACM  SIGCOMM  conference  on  Internet 

social  spam  campaigns.  In Proceedings  of 
measurement (pp. 35-47). ACM. 

24.  Kharaji, M. Y., Rizi, F. S., &Khayyambashi, M. R. (2014). A new approach for finding cloned profiles in 

online social networks. arXiv preprint arXiv:1406.7377. 

25.  Kharaji,  M.  Y.,  &Rizi,  F.  S.  (2014).  An  IAC  Approach  for  Detecting  Profile  Cloning  in  Online  Social 

Networks. arXiv preprint arXiv:1403.2006. 

26.  Adikari, S., & Dutta, K. (2014). Identifying Fake Profiles in LinkedIn. In PACIS (p. 278). 
27.  Stein,  T.,  Chen,  E.,  &Mangla,  K.  (2011,  April).  Facebook  immune  system.  InProceedings  of  the  4th 

Workshop on Social Network Systems (p. 8). ACM 

28.  Bhumiratana,  B.  (2011,  November).  A  model  for  automating  persistent  identity  clone  in  online  social 
network.  In Trust,  Security  and  Privacy  in  Computing  and  Communications  (TrustCom),  2011  IEEE  10th 
International Conference on (pp. 681-686). IEEE. 

29.  Kontaxis,  G.,  Polakis,  I.,  Ioannidis,  S.,  &Markatos,  E.  P.  (2011,  March).  Detecting  social  network  profile 
cloning.  In Pervasive  Computing  and  Communications  Workshops  (PERCOM  Workshops),  2011  IEEE 
International Conference on (pp. 295-300). IEEE. 

30.  Lee,  K.,  Caverlee,  J.,  &  Webb,  S.  (2010,  July).  Uncovering  social  spammers:  social  honeypots+  machine 
learning. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in 
information retrieval (pp. 435-442). ACM. 

31.  Alowibdi,  J.  S.,  Buy,  U.  A.,  Philip,  S.  Y.,  Ghani,  S.,  &Mokbel,  M.  (2015).  Deception  detection  in 

Twitter. Social Network Analysis and Mining, 5(1), 1-16. 

32.  Wondracek, G., Holz, T., Kirda, E., &Kruegel, C. (2010, May). A practical attack to de-anonymize social 

network users. In Security and Privacy (SP), 2010 IEEE Symposium on (pp. 223-238). IEEE. 

33.  Dickerson,  J.  P.,  Kagan,  V.,  &  Subrahmanian,  V.  S.  (2014,  August).  Using  sentiment  to  detect  bots  on 
twitter:  Are  humans  more  opinionated  than  bots?.  In Advances  in  Social  Networks  Analysis  and  Mining 
(ASONAM), 2014 IEEE/ACM International Conference on (pp. 620-627). IEEE. 

34.  The  Washington 

comes 
hoaxer 
http://www.washingtonpost.com/blogs/blogpost/post/twitter-hoaxertommaso-de-benedetti-comes-
clean/2012/03/30/gIQARjYwlS blog.html,2012. 

Tommaso  De 

Benedetti 

“Twitter 

Post, 

clean”, 

35.  Viswanath, B., Bashir, M. A., Crovella, M., Guha, S., Gummadi, K. P., Krishnamurthy, B., &Mislove, A. 
(2014).  Towards  detecting  anomalous  user  behavior  in  online  social  networks.  In 23rd  USENIX  Security 
Symposium (USENIX Security 14) (pp. 223-238). 

36.  Gao,  P.,  Gong,  N.  Z.,  Kulkarni,  S.,  Thomas,  K.,  &  Mittal,  P.  (2015).  Sybilframe:  A  defense-in-depth 

framework for structure-based sybildetection.arXiv preprint arXiv:1503.02985. 

37.  Viswanath,  B.,  Post,  A.,  Gummadi,  K.  P.,  &Mislove,  A.  (2011).  An  analysis  of  social  network-based 

sybildefenses. ACM SIGCOMM Computer Communication Review, 41(4), 363-374. 

38.  Yu, H., Kaminsky, M., Gibbons, P. B., & Flaxman, A. D. (2008). Sybilguard: defending against sybil attacks 

via social networks. Networking, IEEE/ACM Transactions on, 16(3), 576-589. 

39.  Bu, Z., Xia, Z., & Wang, J. (2013). A sock puppet detection algorithm on virtual spaces. Knowledge-Based 

Systems, 37, 366-377. 

40.  Zheng, X., Lai, Y. M., Chow, K. P., Hui, L. C., &Yiu, S. M. (2011, October). Sockpuppet detection in online 
discussion  forums.  In Intelligent  Information  Hiding  and  Multimedia  Signal  Processing  (IIH-MSP),  2011 
Seventh International Conference on (pp. 374-377). IEEE. 

41.  Solorio,  T.,  Hasan,  R.,  &Mizan,  M.  (2013,  June).  A  case  study  of  sockpuppet  detection  in  wikipedia. 

In Workshop on Language Analysis in Social Media (LASM) at NAACL HLT (pp. 59-68). 

42.  Douceur, J. R. (2002). The sybil attack. In Peer-to-peer Systems (pp. 251-260). Springer Berlin Heidelberg. 
43.  Benevenuto,  F.,  Magno,  G.,  Rodrigues,  T.,  &  Almeida,  V.  (2010,  July).  Detecting  spammers  on  twitter. 
In Collaboration, electronic messaging, anti-abuse and spam conference (CEAS) (Vol. 6, No. 2010, p. 12). 

44.  Wang,  A.  H.  (2010).  Detecting  spam  bots  in  online social networking  sites:  a machine  learning  approach. 

In Data and Applications Security and Privacy XXIV (pp. 335-342). Springer Berlin Heidelberg. 

45.  Varvello,  M.,  &Voelker,  G.  M.  (2010,  June).  Second  life:  a  social  network  of  humans  and  bots. 
In Proceedings  of  the  20th  international  workshop  on  Network  and  operating  systems  support  for  digital 
audio and video (pp. 9-14). ACM. 

46.  Ferrara, E., Varol, O., Davis, C., Menczer, F., &Flammini, A. (2014). The rise of social bots. arXiv preprint 

arXiv:1407.5225. 

47.  Silva, S. S., Silva, R. M., Pinto, R. C., &Salles, R. M. (2013). Botnets: A survey. Computer Networks, 57(2), 

378-403. 

48.  Puschmann, C., & Burgess, J. (2013). The politics of Twitter data. 
49.  Wald,  R., Khoshgoftaar, T.  M.,  Napolitano,  A.,  &  Sumner,  C.  (2013,  August).  Predicting  susceptibility  to 
social bots on twitter. In Information Reuse and Integration (IRI), 2013 IEEE 14th International Conference 
on (pp. 6-13). IEEE. 

50.  Boshmaf,  Y.,  Muslukhov,  I.,  Beznosov,  K.,  &Ripeanu,  M.  (2013).  Design  and  analysis  of  a  social 

botnet. Computer Networks, 57(2), 556-578. 

51.  De Cristofaro, E., Friedman, A., Jourjon, G., Kaafar, M. A., &Shafiq, M. Z. (2014, November). Paying for 
likes?:  Understanding  Facebook  like  fraud  using  honeypots.  In Proceedings  of  the  2014  Conference  on 
Internet Measurement Conference (pp. 129-136). ACM. 

52.  Subrahmanian, V. S., Azaria, A., Durst, S., Kagan, V., Galstyan, A., Lerman, K., ...&Waltzman, R. (2016). 

The DARPA Twitter Bot Challenge. arXiv preprint arXiv:1601.05140. 

53.  Boshmaf, Y., Muslukhov, I., Beznosov, K., &Ripeanu, M. (2011, December). The socialbot network: when 
bots  socialize  for  fame  and  money.  InProceedings  of  the  27th  Annual  Computer  Security  Applications 
Conference (pp. 93-102). ACM. 

54.  Aiello, L. M., Deplano, M., Schifanella, R., &Ruffo, G. (2014). People are Strange when you're a Stranger: 

Impact and Influence of Bots on Social Networks. arXiv preprint arXiv:1407.8134. 

55.  Chen, D., Lü, L., Shang, M. S., Zhang, Y. C., & Zhou, T. (2012). Identifying influential nodes in complex 

networks. Physica a: Statistical mechanics and its applications, 391(4), 1777-1787. 

56.  Ilyas, M. U., &Radha, H. (2011, June). Identifying influential nodes in online social networks using principal 
component centrality. In Communications (ICC), 2011 IEEE International Conference on (pp. 1-5). IEEE. 
57.  Probst, F., Grosswiele, D. K. L., &Pfleger, D. K. R. (2013). Who will lead and who will follow: Identifying 
Influential Users in Online Social Networks.Business& Information Systems Engineering, 5(3), 179-193. 
58.  Egele,  M.,  Stringhini,  G.,  Kruegel,  C.,  &Vigna,  G.  (2013,  February).  COMPA:  Detecting  Compromised 

Accounts on Social Networks. In NDSS. 

59.  Wang,  A.  H.  (2010,  July).  Don't  follow  me:  Spam  detection  in  twitter.  InSecurity  and  Cryptography 

(SECRYPT), Proceedings of the 2010 International Conference on (pp. 1-10). IEEE.  

60.  Mccord, M., &Chuah, M. (2011). Spam detection on twitter using traditional classifiers. In Autonomic and 

trusted computing (pp. 175-186). Springer Berlin Heidelberg. 

61.  Rieder, B. (2013, May). Studying Facebook via data extraction: the Netvizz application. In Proceedings of 

the 5th annual ACM web science conference(pp. 346-355). ACM. 

62.  Markines,  B.,  Cattuto,  C.,  &  Menczer,  F.  (2009,  April).  Social  spam  detection.  In Proceedings  of  the  5th 

International Workshop on Adversarial Information Retrieval on the Web (pp. 41-48). ACM. 

63.  Guyon,  I.,  &  Elisseeff,  A.  (2003).  An  introduction  to  variable  and  feature  selection. Journal  of  machine 

learning research, 3(Mar), 1157-1182. 

64.  Barse,  E.  L.,  Kvarnstrom,  H.,  &Jonsson,  E.  (2003,  December).  Synthesizing  test  data  for  fraud  detection 
systems.  In Computer  Security  Applications  Conference,  2003.  Proceedings.  19th  Annual (pp.  384-394). 
IEEE. 

65.  Xiao, Z., Liu, B., Hu, H., & Zhang, T. (2012, June). Design and Implementation of Facebook Crawler Based 
on  Interaction  Simulation.  InTrust,  Security  and  Privacy  in  Computing  and  Communications  (TrustCom), 
2012 IEEE 11th International Conference on (pp. 1109-1112). IEEE. 

66.  Abokhodair, N., Yoo, D., & McDonald, D. W. (2015, February). Dissecting a social botnet: Growth, content 
and influence in Twitter. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative 
Work & Social Computing (pp. 839-851). ACM. 

67.  Liu, D., Wu, Q., Han, W., & Zhou, B. (2016). Sockpuppet gang detection on social media sites. Frontiers of 

Computer Science, 10(1), 124-05 

68.  Yang, Z., Wilson, C., Wang, X., Gao, T., Zhao, B. Y., & Dai, Y. (2014). Uncovering social network sybils in 

the wild. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(1), 2. 

69.  Xiao, C., Freeman, D. M., & Hwa, T. (2015, October). Detecting clusters of fake accounts in online social 
networks.  In Proceedings  of  the  8th  ACM  Workshop  on  Artificial  Intelligence  and  Security(pp.  91-101). 
ACM. 

70.  Jure  Leskovec 

and  Andrej  Krevl. 

SNAP  Datasets: 

Stanford 

large 

network 

dataset 

collection. http://snap.stanford.edu/data, June 2014. 

71.  AlanMislove .Flickr,  LiveJournal,  Orkut,  YouTube,  and  Facebook  datahttps://socialnetworks.mpi-

sws.org/datasets.html , doa: 19.6.2016 

72.   Centre for Computational Analysis of Social and Organizational Systems (CASOS). 

Network Analysis Data http://www.casos.cs.cmu.edu/tools/data2.php, [Accessed: 19.6.2016] 

73.  Opsahl,  T.,  Panzarasa,  P.,  2009.  Clustering  in  weighted  networks.  Social  Networks  31  (2),  155-163,  doi: 

10.1016/j.socnet.2009.02.002 

74.  R. Zafarani and H. Liu, (2009). Social Computing Data Repository at ASU [http://socialcomputing.asu.edu]. 
Tempe, AZ: Arizona State University, School of Computing, Informatics and Decision Systems Engineering. 
75.  Kosinski, M., Matz, S., Gosling, S., Popov, V. & Stillwell, D. (2015) Facebook as a Social Science Research 
Tool: Opportunities, Challenges, Ethical Considerations and Practical Guidelines. American Psychologist. 

76.  Twitter: The Twitter Rules https://twitter.com/rules , doa: June 12, 2016 
77.  Yu, H., Gibbons, P. B., Kaminsky, M., & Xiao, F. (2008, May). Sybillimit: A near-optimal social network 
defense against sybil attacks. In 2008 IEEE Symposium on Security and Privacy (sp 2008) (pp. 3-17). IEEE. 
,  doa:  July  24,  2016 
to  61.5%  of  all  website 

78.  Lgal  Z 

,  “Bot 

traffic” 

is  up 

traffic 

https://www.incapsula.com/blog/bot-traffic-report-2013.html 
lemmanization. 

79.  Stemming 

and 

https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-

lemmatization-1.html, July 4 , 2009,  [Accessed June 20, 2016] 

80.  Haddi,  E.,  Liu,  X.,  &  Shi,  Y.  (2013).  The  role  of  text  pre-processing  in  sentiment  analysis. Procedia 

Computer Science, 17, 26-32. 

81.  Hu, X., Tang, J., & Liu, H. (2014, July). Online Social Spammer Detection. In AAAI (pp. 59-65). 
82.  Twitter “Reporting a spam on Twitter” https://support.twitter.com/articles/64986 

[Accessed: 26-July-2016]. 
“Recognizing 

83.  Linkedin 

and  Reporting 

Spam, 

Inappropriate, 

and  Offensive  Content” 

https://www.linkedin.com/help/linkedin/answer/37822/recognizing-and-reporting-spam-inappropriate-and-
offensive-content?lang=en   [Accessed: 26-July-2016]. 

84.  Facebook 

“Facebook's  new  AI 

tool 

can 

read 

and  understand  messages 

like  humans”  

http://timesofindia.indiatimes.com/tech/social/Facebooks-new-AI-tool-can-read-and-understand-messages-
like-humans/articleshow/52600437.cms   [Accessed: 08-August-2016]. 

85.  Strufe, T. (2009). Safebook: A privacy-preserving online social network leveraging on real-life trust. IEEE 

Communications Magazine, 95. 

86.  Times 

of 

trolling” 
http://epaperbeta.timesofindia.com/Article.aspx?eid=31808&articlexml=New-Instagram-tool-to-help-tackle-
trolling-03082016021023   [Accessed; 08-August-2016]. 

Instagram 

tackle 

“New 

India 

help 

tool 

to 

87.  Facebook “Security Tips”  https://www.facebook.com/help/379220725465972   [Accessed:10-August-2016]. 
88.  Tang, J., & Liu, H. (2012, April). Feature selection with linked data in social media. In Proceedings of the 
2012  SIAM  International  Conference  on  Data  Mining (pp.  118-128).  Society  for  Industrial  and  Applied 
Mathematics.  

89.  Lewis, K., Kaufman, J., Gonzalez, M., Wimmer, A., & Christakis, N. (2008). Tastes, ties, and time: A new 

social network dataset using Facebook. com. Social networks, 30(4), 330-342. 

90.  Zheleva, E., & Getoor, L. (2009, April). To join or not to join: the illusion of privacy in social networks with 
mixed public and private user profiles. In Proceedings of the 18th international conference on World wide 
web (pp. 531-540). ACM. 

91.  Kwak, H., Lee, C., Park, H., & Moon, S. (2010, April). What is Twitter, a social network or a news media?. 

In Proceedings of the 19th international conference on World wide web (pp. 591-600). ACM. 

92.  Wong, C. I., Wong, K. Y., Ng, K. W., Fan, W., & Yeung, K. H. (2014). Design of a crawler for online social 

networks analysis. WSEAS Transactions on Communications, 3, 264-274. 

93.  Ali,  A.  M.,  Alvari,  H.,  Hajibagheri,  A.,  Lakkaraju,  K.,  &  Sukthankar,  G.  (2014).  Synthetic  generators  for 

cloning social network data. Proceedings of SocInfo 

94.   Fire, M., Katz, G., & Elovici, Y. (2012). Strangers intrusion detection-detecting spammers and fake profiles 

in social networks based on topology anomalies. Human Journal, 1(1), 26-39 

95.  Vergeer, M., Hermans, L., & Sams, S. (2013). Online social networks and micro-blogging in political  

 campaigning: The exploration of a new campaign tool and a new campaign style. Party Politics, 19(3), 477-  
501. 

96.   Lee, K.,  Caverlee, J.,  & Webb,  S. (2010, July).  Uncovering  social  spammers:  social honeypots+  machine 
learning. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in 
information retrieval (pp. 435-442). ACM 

97.   Cao, Q., Sirivianos, M., Yang, X., & Pregueiro, T. (2012, April). Aiding the detection of fake accounts in 
large  scale  social  online  services.  In Proceedings  of  the  9th  USENIX  conference  on  Networked  Systems 
Design and Implementation (pp. 15-15). USENIX Association 

98.  Federal Trade Commission,  CAN-SPAM Act: A Compliance Guide for Business https://www.ftc.gov/tips-

advice/business-center/guidance/can-spam-act-compliance-guide-business , last accessed 07.08.2017 

99.   Varol, O., Ferrara, E., Davis, C. A., Menczer, F., & Flammini, A. (2017). Online human-bot interactions: 

Detection, estimation, and characterization. arXiv preprint arXiv:1703.03107 

100.  Staab,  S.,  Domingos,  P.,  Mike,  P.,  Golbeck,  J.,  Ding,  L.,  Finin,  T.,    &  Vallacher,  R.  R.  (2005).  Social  

networks applied. IEEE Intelligent systems, 20(1), 80-93. 

101. Christakis, N. A., & Fowler, J. H. (2013). Social contagion theory: examining dynamic social networks and  

human behavior. Statistics in medicine, 32(4), 556-577. 

102. Search Compliance, Margaret Rouse    

 http://searchcompliance.techtarget.com/definition/FTC-Federal-Trade-Commission,                    
 last accessed : 06.08.2017. 

103.  Kerly,  A.,  Hall,  P.,  &  Bull,  S.  (2007).  Bringing  chatbots  into  education:  Towards  natural  language 

negotiation of open learner models. Knowledge-Based Systems, 20(2), 177-185  

104. Kumar, S., Cheng, J., Leskovec, J., & Subrahmanian, V. S. (2017, April). An army of me: Sockpuppets in 
online  discussion  communities.  In Proceedings  of  the  26th  International  Conference  on  World  Wide 
Web (pp. 857-866). International World Wide Web Conferences Steering Committee 

105.  Maity, S. K., Chakraborty, A., Goyal, P., & Mukherjee, A. (2017, February). Detection of Sockpuppets in 
Social Media. In Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and 
Social Computing (pp. 243-246). ACM. 

106. Ministry 

of 

Electronics 

Information 

& 

Technology, 

Government 

of 

India 

http://meity.gov.in/content/offences;   accessed on 9th January 2017. 

107. Times of India; 7,000 Indian sites hacked, claim Pak rookies http://timesofindia.indiatimes.com/india/7000-

Indian-sites-hacked-claim-Pak-rookies/articleshow/54686941.cms; accessed on 9th January 2017. 

108. Making Technology easier,  bobology- What is a Catfisher?  https://www.bobology.com/public/What- is-a-

Catfisher.cfm last accessed 05-08-2017 

109. Khayyambashi, M. R., & Rizi, F. S. (2013, April). An approach for detecting profile cloning in online social 
networks.  In E-Commerce  in  Developing  Countries:  With  Focus  on  E-Security  (ECDC),  2013  7th 
Intenational Conference on (pp. 1-12). IEEE 

110. GEDIS Studio: the online test data generator: http://www.gedis-studio.com accessed on 26th April 2017 
111. Databene, Databene Benerator:  http://databene.org/databene-benerator , last accessed on 26th April 2017 
112.  Tang, J., Musolesi, M., Mascolo, C., & Latora, V. (2010). Characterising temporal distance and reachability 
in mobile and online social networks. ACM SIGCOMM Computer Communication Review, 40(1), 118-124 
113.  Ferrara,  E.,  De  Meo,  P.,  Fiumara,  G.,  &  Baumgartner,  R.  (2014).  Web  data  extraction,  applications  and 

techniques: A survey. Knowledge-based systems, 70, 301-323 

114.  Fire,  M.,  Goldschmidt,  R.,  &  Elovici,  Y.  (2014).  Online  social  networks:  threats  and  solutions. IEEE 

Communications Surveys & Tutorials, 16(4), 2019-2036. 

115.  Wani, M. A., Agarwal, N., Jabin, S., & Hussai, S. Z. (2018). Design and Implementation of iMacros-based 

Data Crawler for Behavioral Analysis of Facebook Users. arXiv preprint arXiv:1802.09566. 

 
 
 
 
