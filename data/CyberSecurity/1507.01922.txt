Cyber-Deception and Attribution
in Capture-the-Flag Exercises

Eric Nunes, Nimish Kulkarni, Paulo Shakarian
School of Computing, Informatics and
Decision Systems Engineering
Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, nimish.kulkarni, shak} @asu.edu

Andrew Ruef, Jay Little
Trail of Bits, Inc.
New York, NY 10003, USA
Email: {andrew, jay} @trailofbits.com

5
1
0
2

l
u
J

7

]

R
C
.
s
c
[

1
v
2
2
9
1
0
.
7
0
5
1
:
v
i
X
r
a

Abstract—Attributing the culprit of a cyber-attack is widely
considered one of the major technical and policy challenges
of cyber-security. The lack of ground truth for an individual
responsible for a given attack has limited previous studies. Here,
we overcome this limitation by leveraging DEFCON capture-the-
ﬂag (CTF) exercise data where the actual ground-truth is known.
In this work, we use various classiﬁcation techniques to identify
the culprit in a cyberattack and ﬁnd that deceptive activities
account for the majority of misclassiﬁed samples. We also explore
several heuristics to alleviate some of the misclassiﬁcation caused
by deception.

I.

INTRODUCTION

Attributing the culprit of a cyber-attack is widely con-
sidered one of the major technical and policy challenges of
cyber-security. The lack of ground truth for an individual
responsible for a given attack has limited previous studies. In
this study, we take an important ﬁrst step toward developing
computational techniques toward attributing the actual culprit
(here hacking group) responsible for a given cyber-attack. We
leverage DEFCON capture-the-ﬂag (CTF) exercise data which
we have processed to be amenable to various machine learning
approaches. Here, we use various classiﬁcation techniques to
identify the culprit in a cyber-attack and ﬁnd that deceptive
activities account for the majority of misclassiﬁed samples. We
also explore several heuristics to alleviate some of the misclas-
siﬁcation caused by deception. Our speciﬁc contributions are
as follows:

• We assemble a dataset of cyber-attacks with ground
truth derived from the trafﬁc of the CTF held at
DEFCON 21 in 2013.

• We analyze this dataset to identify cyber-attacks where

deception occurred.

• We frame cyber-attribution as a multi-label classiﬁca-
tion problem and leverage several machine learning
approaches. We ﬁnd that deceptive incidents account
for the vast majority of misclassiﬁed samples.

• We introduce several pruning techniques and show
that they can reduce the effect of deception as well as
provide insight into the conditions in which deception
was employed by the participants of the CTF.

explore the deception hypothesis in a cyber-warfare scenario.
When compared to other domains of warfare, there is a much
greater potential for evidence found in the aftermath of cyber-
attack to be planted by the adversary for purposes of deception.
The policy implications of cyber-attribution have also been
discussed in [9] where the authors point out that anonymity,
ability to launch multi-stage attacks, and attack speed pose
signiﬁcant challenges to cyber attribution.

In an early survey on cyber-attribution [1], the authors point
out that technical attribution will generally identify machines,
as opposed to a given hacker and his/her afﬁliations. While
we will use technical information in our approach, we have
ground truth data on the group involved by the nature of
the capture-the-ﬂag data. This will allow our approach to
proﬁle the tactics, techniques, and procedures of a given group
as we have ground-truth information on a hacking group as
opposed to machines. An example of such an approach is the
WOMBAT attribution method [3] which attributes behavior
to IP sources that are potentially linked to some root cause
determined through a clustering technique. Similarly, other
work [8] combines cluster analysis with a component for multi-
criteria decision analysis and studied an implementation of this
approach using honeypot data – again, this approach lacks any
ground truth of the actual hacker or hacking group.

Concurrently, we have devised a formal logical framework
for reasoning about cyber-attribution [5], [7]. However, we
have not studied how this framework can be instantiated on
a real world dataset and, to date, we have not reported on an
implementation or experiments in the literature. We note that
none of the previous work on cyber-attribution leverages a
data set with ground truth information of actual hacker groups
– which is the main novelty of this paper.

II. DATASET

Our dataset consists of events recorded from a Capture-
the-ﬂag (CTF) tournament held at DEFCON 21 in 2013.
Brieﬂy, CTF competitions act as educational exercise that
exposes real world attack scenarios to participants. Network
snifﬁng, analysis of protocols, programming and system level
knowledge, cryptanalysis are some of the instrumental skills
acquired by contestants.

In our text on cyber-warfare [6], we discuss the difﬁculties
of cyber-attribution and how an intelligence analyst must also

Our data represents attack/defense style, where each team
owns a small network of machines to defend. Teams are judged

 
 
 
 
 
 
based on scores given to attack machines of other teams as well
as defending their own network. Initially, all virtual machines
are conﬁgured with speciﬁc set of services. These services
are vulnerable to state-of-art hacking techniques. Files can be
considered as form of ﬂag to be captured from other teams or
to be planted to other teams by exploiting those vulnerabilities.

DEFCON CTF organizers recorded network trafﬁc that
includes network packets generating to and from all partici-
pating teams and is available on Internet [4]. Recordings are
stored as archive ﬁles of PCAP (packet capture) for each team
(destination as that team) separately. PCAP ﬁle contains packet
headers (TCP, SSL, UDP etc.) and respective data as source,
destination, sequence numbers etc. with timestamp having
millisecond precision. Using open source tool tcpﬂow1, we
interpreted collection of PCAPs as cumulative data streams.
Tcpﬂow reconstructs actual data streams from the packets
that proved helpful in protocol analysis and debugging. This
tool produces a ﬁle containing the contents of each stream,
representing the data sent between two points in the CTF
system.

For each ﬁle, we computed an md5 checksum, a byte
histogram, and an ARM instruction histogram. This data was
recorded as a list of tuples (time-stamp, hash, byte-histogram,
instruction-histogram) in a JSON document. These individual
ﬁelds of the tuple are listed in Table 1.

TABLE 1: Fields in an instance of network attack

Field

byte hist

inst hist

from team

to team

svc

Intuition

histogram of byte sequences in the payload

histogram of instructions used in the payload

the team where the payload originates (attacking team)

the team being attacked by the payload

the service that the payload is running

payload hash

indicates the payload used in the attack (md5)

time

indicates the date and time of the attack

From this pre-processing of the network data (packets) we
have around 10 million network attacks. There are 20 teams
in the CTF competition. In order to attribute an attack to a
particular team, apart from analyzing the payloads used by the
team, we also need to analyze the behavior of the attacking
team towards his adversary. For this purpose we separate the
network attacks according to the team being targeted. Thus
we have 20 such subsets. We represent the 20 subsets (teams)
as T-i, where i = 1, 2, 3...20. An example of an event in the
dataset is shown in Table 2.

TABLE 2: Example event from the dataset

Field

byte hist

inst hist

from team

to team

svc

Value

0×43:245, 0×69:8, 0×3a:9, 0×5d:1, .....

cmp:12 , svcmi:2, subs:8, movtmi:60 ......

men in black hats

Robot Maﬁa

02345

payload hash

2cc03b4e0053cde24400bbd80890446c

time

2013-08-03T23:45:17

attack to a team difﬁcult.
Deception: In the context of this paper we deﬁne an attack to
be deceptive when multiple adversaries get mapped to a single
attack pattern. In the current setting we deﬁne deception as the
scenario when the same payload is used by multiple teams to
target the same team. Fig. 1 shows the distribution of unique
deception attacks with respect to the total unique attacks in
the dataset based on the target team. These unique deceptive
attacks amount to just under 35% of the total unique attacks.

Fig. 1: Unique deceptive attacks directed towards each team.

Duplicate attacks: A duplicate attack occurs when the same
team uses the same payload to attack a team at different time
instances. Duplicate attacks can be attributed to two reasons.
First when a team is trying to compromise other systems, it
just does not launch a single attack but a wave of attacks with
very little time difference between consecutive attacks. Second,
once a successful payload is created which can penetrate the
defense of other systems, it is used more by the original
attacker as well as the deceptive one as compared to other
payloads. We group duplicates as being non-deceptive and
deceptive. Non-deceptive duplicate are the duplicates of the
team that ﬁrst initiated the use of a particular payload. On the
other hand deceptive duplicates are all the attacks from the
teams that are being deceptive. Deceptive duplicates form a
large portion of the dataset as seen in Fig. 2.

Fig. 2: Total attacks and duplicate attacks(Deceptive and
Non-deceptive) directed towards each team

A. Dataset Analysis

We now discuss two important observations from the
dataset, that makes the task of attributing an observed network

1https://github.com/simsong/tcpﬂow

III. BASELINE APPROACHES

From the dataset, we have the ground truth available for
all the samples. Hence we use supervised machine learning

0100000200000300000400000T-1T-2T-3T-4T-5T-6T-7T-8T-9T-10T-11T-12T-13T-14T-15T-16T-17T-18T-19T-20Unique AttacksTeamsUnique AttacksDeceptive Attacks0200000400000600000800000T-1T-2T-3T-4T-5T-6T-7T-8T-9T-10T-11T-12T-13T-14T-15T-16T-17T-18T-19T-20Total AttacksTeamsNon-DeceptiveDeceptiveTotal Attacksapproaches to predict the attacking team. The ground truth
corresponds to a team competing in the competition.

Decision Tree (DT). For baseline comparisons we ﬁrst im-
plemented a decision tree classiﬁer. We built the decision tree
by ﬁnding the attribute that maximizes the information gain at
each split. In order to avoid over-ﬁtting, the terminating criteria
is set to less than 0.1% of total samples.
Random Forest (RF). We use a random forest which com-
bines bagging for each tree with random feature selection at
each node to split the data thus generating multiple decision
tree classiﬁers.
Support Vector Machine (SVM). Support vector machines
is a popular supervised classiﬁcation technique that works
by ﬁnding a separating margin that maximizes the geometric
distance between classes. We use the popular LibSVM imple-
mentation [2] which is publicly available.
Logistic Regression (LOG-REG). Logistic regression clas-
siﬁes samples by computing the odds ratio. The odds ratio
gives the strength of association between the features and the
class. We implement the multinomial logistic regression which
handles multi-class classiﬁcation.

A. Experimental Results

For our baseline experiments, we separate the attacks based
on the team being targeted. Thus we have 20 subsets. We then
sort the attack according to time. We reserve the ﬁrst 90% of
the attacks for training and the rest 10% for testing. Attacker
prediction accuracy is used as the performance measure for
the experiment. Accuracy is deﬁned as the fraction of correctly
classiﬁed test samples. Fig. 3 shows the accuracy for predicting
the attacker for each target team. Machine learning techniques
signiﬁcantly outperform random guessing which would have
an average accuracy of choosing 1 out of 19 teams attacking
yielding an accuracy of 0.053. For this experiment random
forest classiﬁer performs better than logistic regression, sup-
port vector machine and decision tree for all the target teams.
Table 3 below summarizes the average performance for each
method.

Fig. 3: Team prediction accuracy for LOG-REG, RF, SVM
and DT.

B. Misclassiﬁed Samples

Misclassiﬁcation can be attributed to the following sources,

TABLE 3: Summary of Prediction results averaged across all
Teams

Method

Decision tree (DT)

Logistic regression (LOG-REG)

Support vector machine (SVM)

Random Forest (RF)

Average Performance

0.26

0.31

0.30

0.37

•

•

•

Non-deceptive duplicate attacks attributed to one of
the deceptive teams.

Deceptive duplicates attributed to some other decep-
tive team.

Payloads that were not encountered during the training
phase.

The ﬁrst
two sources of error make up the majority of
misclassiﬁcations, since a given attack can be attributed to any
of the 19 teams.

Fig. 4: Sources of error in the misclassiﬁed samples.

Fig. 4 shows the distribution of the above mentioned
sources of misclassiﬁcation for each team. Deceptive du-
plicates form the majority of misclassiﬁcations. This is not
surprising given the fact that deceptive duplicates make up
almost 90% of the total attacks (see Fig. 2).

IV. PRUNING

We explore different pruning techniques

to address
misclassiﬁcation issues with respect to deceptive and non-
deceptive duplicates. The pruning techniques are only applied
to the training data, while the test data is maintained at 10%
as mentioned in Section III-A. We use the random forest
classiﬁer for all the pruning techniques.

All-but-majority (P-1): In this pruning technique, for each
payload, we only retain duplicates of the most frequent at-
tacking team and prune the duplicates of all other teams. This
pruned set is then used to train the random forest classiﬁer.
Table 4 shows the classiﬁer performance in comparison with
the baseline method. All-but-majority pruning technique has
better performance on the test set than the baseline approach
for 11 out of 20 teams. Using this pruning technique does
beneﬁt majority of the teams as the prediction accuracy im-
proves for them, but for some teams the performance drops.

00.10.20.30.40.50.6T-1T-2T-3T-4T-5T-6T-7T-8T-9T-10T-11T-12T-13T-14T-15T-16T-17T-18T-19T-20AccuracyTeamsLOG-REGRFSVMDT0.00.20.40.60.81.0T-1T-2T-3T-4T-5T-6T-7T-8T-9T-10T-11T-12T-13T-14T-15T-16T-17T-18T-19T-20Fraction of Misclassified SamplesTeamsNon-Deceptive DuplicatesDeceptive DuplicatesUnseen payloadsThe reason for the drop in performance for some teams is
due to the fact that training set gets dominated by a single
team which does not have majority in testing set. Since the
majority team gets represented in most of the leaves of the
random forest classiﬁer, it gets predicted more often leading
to high misclassiﬁcations.

All-but-K-majority (P-2): In order to address the issue of
one team dominating in the training set, we use the all-but-K-
majority where we consider the K most frequent teams for a
payload under consideration. After trying out different values
of K we select K = 3, which gives the best performance.
For higher values of K, the pruning behaves like the baseline
approach and for lower values it behaves like All-but-majority.
On average each team gains about 40K samples in the training
set as compared to all-but-majority pruning. Table 4 shows
the classiﬁer performance. In this case also pruning performs
better than baseline in 11 out of 20 teams, but as compared to
all-but-majority the performance for most teams is better.

All-but-earliest (P-3): For this pruning we only retain the
duplicates of the team that initiated the attack using a particular
payload. This pruning technique retains all the non-deceptive
duplicates while getting rid of the deceptive ones. Table 4
shows the classiﬁer performance. This pruning technique per-
forms better than the baseline approach for 8 out of 20 teams.
Comparing this result to all-but-majority (including all-but-
K-majority) pruning indicates that deceptive duplicates are
informative in attributing an attack to a team and should not
be ignored completely.

All-but-most-recent (P-4): In this pruning we repeat a similar
procedure like All-but-earliest but
instead of retaining the
duplicates of the team that initiated an attack, we retain the
duplicates of the team that used the payload last in the training
set. Since the data is sorted according to time, the last attacker
becomes the most recent attacker for the test set. Table 4 shows
the classiﬁer performance.

TABLE 4: Pruning technique performance comparison.

Teams

T-1

T-2

T-3

T-4

T-5

T-6

T-7

T-8

T-9

T-10

T-11

T-12

T-13

T-14

T-15

T-16

T-17

T-18

T-19

T-20

RF

0.45

0.22

0.30

0.26

0.26

0.50

0.45

0.42

0.41

0.30

0.37

0.24

0.35

0.42

0.30

0.42

0.43

0.48

0.41

0.48

P-1(RF)

P-2(RF)

P-3(RF)

P-4(RF)

0.16

0.28

0.53

0.33

0.38

0.27

0.59

0.52

0.65

0.54

0.27

0.37

0.27

0.27

0.20

0.28

0.45

0.39

0.65

0.16

0.46

0.30

0.29

0.27

0.45

0.24

0.58

0.52

0.68

0.34

0.35

0.37

0.37

0.40

0.27

0.22

0.35

0.43

0.58

0.16

0.15

0.15

0.57

0.31

0.40

0.31

0.19

0.51

0.52

0.55

0.27

0.25

0.29

0.30

0.21

0.32

0.43

0.41

0.54

0.16

0.15

0.14

0.57

0.32

0.42

0.26

0.49

0.55

0.53

0.57

0.29

0.22

0.27

0.30

0.20

0.31

0.40

0.40

0.60

0.17

Table 5 gives the summary of the prediction results for
all the pruning techniques in comparison with the random
forest baseline approach. In the pruning techniques All-but-
K-majority works best with an average accuracy of 0.42.

TABLE 5: Summary of Prediction results averaged across all
Teams

Method

Average Performance

Baseline Approach (RF)

All-but-majority Pruning (RF)

All-but-K-majority Pruning (RF)

All-but-earliest Pruning (RF)

All-but-most-recent Pruning (RF)

0.37

0.40

0.42

0.34

0.36

V. CONCLUSION

In this paper, we study cyber-attribution by examining
DEFCON CTF data - which provides us with ground-truth
on the culprit responsible for each attack. We frame cyber-
attribution as a classiﬁcation problem and examine it using
several machine learning approaches. We ﬁnd that deceptive
incidents account for the vast majority of misclassiﬁed samples
and introduce heuristic pruning techniques that alleviate this
problem somewhat. Moving forward, we look to employ a
more principled approach to counter deception based on our
previously established theoretical framework for reasoning
about cyber-attribution [5], [7]. In particular we wish to employ
temporal reasoning to tackle the problem of deceptive attacks.
This opens up interesting research questions in particular iden-
tifying hacking group from a series of attacks over a period of
time, differentiating between deceptive hacking groups in time
series data. This is a knowledge engineering challenge which
calls for development of efﬁcient and scalable algorithms.

VI. ACKNOWLEDGMENT

Some of this work was supported by the U.S. Ofﬁce of

Naval Research and ASU Global Security Initiative (GSI).

REFERENCES

[1] W. E. Boebert. A survey of challenges in attribution. In Proceedings of

a workshop on Deterring CyberAttacks, pages 41–54, 2010.

[2] C.-C. Chang and C.-J. Lin. Libsvm: A library for support vector
machines. ACM Transactions on Intelligent Systems and Technology
(TIST), 2(3):27, 2011.

[3] M. Dacier, V.-H. Pham, and O. Thonnard. The wombat attack attribution
In Information Systems Security, pages 19–37.

method: some results.
Springer, 2009.

[4] DEFCON. Defcon: Capture the ﬂag. 2013.
[5] S. Jajodia, P. Shakarian, V. S. Subrahmanian, V. Swarup, and C. Wang.
Cyber Warfare: Building the Scientiﬁc Foundation. Springer Publishing
Company, Incorporated, 2015.

[6] P. Shakarian, J. Shakarian, and A. Ruef. Introduction to cyber-warfare:

A multidisciplinary approach. Newnes, 2013.

[7] P. Shakarian, G. I. Simari, and M. A. Falappa. Belief revision in
In Foundations of Information

structured probabilistic argumentation.
and Knowledge Systems, pages 324–343. Springer, 2014.

[8] O. Thonnard, W. Mees, and M. Dacier. On a multicriteria clustering
approach for attack attribution. ACM SIGKDD Explorations Newsletter,
12(1):11–20, 2010.

[9] N. Tsagourias. Nicolas politis initiatives to outlaw war and deﬁne
aggression, and the narrative of progress in international law. European
Journal of International Law, 23(1):255–266, 2012.

