8
1
0
2

b
e
F
9

]

G
L
.
s
c
[

1
v
8
5
3
3
0
.
2
0
8
1
:
v
i
X
r
a

Deep Learning for Malicious Flow Detection

Yun-Chun Chen∗, Yu-Jhe Li†, Aragorn Tseng†, and Tsungnan Lin∗†‡
∗ Department of Electrical Engineering, National Taiwan University
† Graduate Institute of Communication Engineering, National Taiwan University
‡ Cybersecurity Technology Institute, Institute for Information Industry

Abstract—Cyber security has grown up to be a hot
issue in recent years. How to identify potential malware
becomes a challenging task. To tackle this challenge, we
adopt deep learning approaches and perform ﬂow detection
on real data. However, real data often encounters an
issue of imbalanced data distribution which will lead to
a gradient dilution issue. When training a neural network,
this problem will not only result in a bias toward the
majority class but show the inability to learn from the
minority classes.

In this paper, we propose an end-to-end trainable Tree-
Shaped Deep Neural Network (TSDNN) which classiﬁes
the data in a layer-wise manner. To better learn from
the minority classes, we propose a Quantity Dependent
Backpropagation (QDBP) algorithm which incorporates the
knowledge of the disparity between classes. We evaluate
our method on an imbalanced data set. Experimental result
demonstrates that our approach outperforms the state-of-
the-art methods and justiﬁes that the proposed method is
able to overcome the difﬁculty of imbalanced learning. We
also conduct a partial ﬂow experiment which shows the
feasibility of real-time detection and a zero-shot learning
experiment which justiﬁes the generalization capability of
deep learning in cyber security.

I. INTRODUCTION
Cyber security has become an important issue that
cannot be overlooked. Recently, a notorious type of
Ransomware, WannaCry, has posed a threat to the entire
cyber society. This Ransomware has appeared numerous
kinds of variants so far and the third version whose
targeted vulnerability differs from others has come into
existence as well.

Traditional methods to defend these threats are sig-
nature oriented, which means that anti-virus software
will not be able to detect them if malware changes its
behavior. On the other hand, real-time detection is also
a concern when applying anti-virus software.

Recently, many literature [1], [2] proposed different
methods to detect malware. Even though the methods
mentioned in these literature can achieve a high ac-
curacy, we discover that the precision, which is also
an important index in machine learning tasks, of the
proposed methods aren’t high. To seek for a substantial
improvement on the precision of malware detection
and perform a detailed classiﬁcation, we construct a
neural network-based model based on our understanding
regarding neural network’s potential and generalization
capability.

978-1-5386-3531-5/17/$31.00 c(cid:13) 2017 IEEE

Deep learning has an excellent performance in many
aspects such as computer vision task [3] and speech
recognition task [4] to name a few. With the emergence
of various types of neural network architectures and dif-
ferent training mechanisms, deep learning has become a
feasible and powerful approach when handling problems
with complexity.

Data is an important issue in building a robust model.
Unlike computer vision tasks that data are available on
the Internet with ease since there are numerous open data
sets, on the contrary, to the authors’ best knowledge, the
task we are conducting does not have any malware open
data set and therefore the malware data samples used in
this task are collected by authors. Under this situation,
the collected data will often result in an imbalanced data
distribution.

Imbalanced data distribution occurs quite frequently
in many machine learning related tasks [5], [6] and this
issue will become a major challenge in training neural
networks due to the gradient dilution issue. Besides, the
number of malware we obtained is even less than we
expected. How to construct a robust and unbiased model
becomes a challenging problem in our task.

To tackle the above-mentioned challenge, we propose
an end-to-end trainable Tree-Shaped Deep Neural Net-
work (TSDNN) along with a Quantity Dependent Back-
propagation (QDBP) algorithm which incorporates the
knowledge of the disparity between classes and classiﬁes
the data layer by layer. We evaluate the effectiveness of
our method on a considerably imbalanced data set. The
main contributions of this paper are summarized as the
following:

• We propose an end-to-end trainable TSDNN model
which classiﬁes the data in a layer-wise manner.
It is shown experimentally to perform far beyond
the multi-layer perceptron architecture on an imbal-
anced data set.

• We propose a QDBP algorithm which incorporates
the knowledge of the disparity between classes
and overcome the difﬁculty of imbalanced learning.
Experimental result shows that our method outper-
forms the state-of-the-art approaches on an imbal-
anced data set whether in accuracy or precision.
• We further show the feasibility of real-time detec-
tion by executing a partial ﬂow experiment and

 
 
 
 
 
 
we also conduct a zero-shot learning experiment
which demonstrates the generalization performance
of deep learning on cyber security.

The rest of the paper is organized as follows. The
next section presents the state-of-the-art methods to
tackle imbalanced data issue. Section III introduces the
terminologies used in this paper and describes the phe-
nomenon of gradient dilution. The proposed algorithm
and the architecture of neural network are elaborated in
section IV. Section V presents the experimental frame-
work and provides comprehensive experimental results.
Eventually, we conclude this paper in section VI.

II. RELATED WORK

Imbalanced data distribution is an inevitable issue
when performing classiﬁcation tasks. There are many
literature [5], [6] aimed at tackling the challenge, and
the proposed methods can be categorized into two main
strategies, data manipulating techniques and training
mechanism adjustment.

A. Data Manipulating Technique

There are two types of data manipulating techniques,
the oversampling method [7] and the undersampling
method [8]. Oversampling is a method that constantly
re-samples the minority class into the training data set.
Undersampling, on the other hand, is a method that
randomly eliminates the data of the majority class. Even
though these two methods are opposed to each other,
both of them are aimed to adjust the data distribution
and mitigate the imbalanced data issue.

B. Training Mechanism Adjustment

Incremental learning is a feasible method to mitigate
imbalanced data issue [9]. The objective of incremental
learning is intended to learning from the newly intro-
duced data without forgetting past memories. The model
usually trains on a small data set initially and increases
the size of training data set gradually.

III. GRADIENT DILUTION

Training neural networks is a gradient-based method
which updates the parameters according to the partial
derivatives computed with respect to the cost function.
When computing gradient in each epoch, the number
of the gradient contributed by each class equals to the
vector summation over the training data of each class.
If the number of the data of the majority class is much
greater than that of the minority class, the model will
tend to update the parameter toward the majority class.
To understand the phenomenon, we have to analyze the
computation of gradient when training a neural network.
For each epoch, every training sample will be trained
by the model once. Namely,
the model will update
its parameters with respect to each data once in every
epoch. The total gradient of each epoch will be the sum

of all gradients contributed by each individual training
data and the mathematical formula is given by:

∂Loss
∂θ

=

N
(cid:88)

i=1

∂Lossi
∂θ

(1)

∂θ

where ∂Loss

refers to the total gradient of each
epoch with respect to θ, ∂Lossi
refers to the gradient
contributed by the ith training data with respect to θ,
and N represents the number of training data samples
in each epoch.

∂θ

If we reorder equation (1), and group the gradient

contributed by the same class together, we will have

∂Loss
∂θ

=

(cid:88)

(cid:88)

Mi∈M

Aik∈Mi

∂LossAik
∂θ

(2)

where M represents the training data set, Mi refers
to the ith class of M , Aik is the kth data of Mi, and
LossAik is the loss contributed by data Aik.

From equation (2), we can observe that the number
of updates of parameter θ with respect to each class
depends on the size of each class. Once the number of
the data disparate between classes severely, the model
will tend to bias toward the majority class since the
total gradient will be dominated by the gradients con-
tributed by the majority class in terms of frequency.
This phenomenon will result in the insensitivity of the
model toward the minority classes because the model
seldom updates the parameter with respect to the minor-
ity classes. Metaphorically, the gradients contributed by
the minority classes fade as if it were diluted by that
contributed by the majority class. This phenomenon is
called the gradient dilution.

For instance, considering a binary classiﬁcation on
an imbalanced data set where positive class contains
10,000 pieces of data whereas only 10 pieces of data
belongs to the negative class. For every epoch, the model
will update the parameters toward the direction of the
positive class 10,000 times while only updates 10 times
toward the direction of the negative class. Under this
scenario, the model will tend to bias toward the positive
class since the model updates more frequently toward
the direction of the positive class.

The effect of the gradient dilution depends on the
number ratio of the data between classes. If the ratio
is large to some extent, 216,015
in our task, the model
45
will be more likely to update toward the majority class
and result in an inability of the model to learn from the
minority classes. To mitigate the impact of the gradient
dilution without adjusting the distribution of the data,
we propose a QDBP algorithm which takes the disparity
between classes into consideration, adjust the sensitivity
of the model with respect to each class, and is able to
overcome this difﬁculty.

Fig. 1. This model performs a 12-class classiﬁcation in three stages. Firstly, the model performs a coarse classiﬁcation which preliminarily
classiﬁes the data into the class of benign ﬂows and malicious ﬂows. Secondly, the model conducts a multi-class classiﬁcation on the malicious
ﬂows, which classiﬁes them into 5 different categories according to the attack behavior. Lastly, the model executes a ﬁne-grained classiﬁcation
on Ransomware family.

IV. METHODOLOGY

A. Quantity Dependent Backpropagation (QDBP)

Backpropagation is a gradient-based method to train
neural networks. The mathematical formula is given by:

i − η ×

where θl

θl+
i = θl

∂Loss
∂θl
i
represent the ith parameter in layer l
and the updated parameter respectively, η is the learning
rate, ∂Loss
refers to the partial derivative of Loss with
∂θl
i
respect to θl
i.

i and θi

(3)

l+

However, neither backpropagation nor adaptive learn-
ing rate approaches can’t reﬂect the sensitivity toward
minority classes whether applying online learning or
batch learning mechanism since both methods treat each
class evenly and are only sensitive to gradient. When
imbalanced data distribution occurs, these methods will
result in the inability of the model to learn from the
minority classes due to gradient dilution issue.

To mitigate this issue, we introduce a vector F into
backpropagation (equation (3)) and propose a QDBP
algorithm which takes the disparity between classes into
consideration and shows different sensitivities toward
different classes. The mathematical formula is given by:

θl+
i = θl

F =

i − η · F · ∇Loss
(cid:20) c1
(cid:21)
n1

cN
nN

c2
n2

, ...,

,

∇Loss =

(cid:20) ∂Loss1
∂θi

,

∂Loss2
∂θi

, ...,

∂LossN
∂θi

(cid:21)T

(4)

(5)

(6)

where F is a row vector, N represents the cardinality
of the training data set, ni represents the cardinality
of the class where the ith data belongs to, and ci is
the pre-selected coefﬁcient for the class where the ith
data belongs to. The adjustment of ci depends on the
sensitivity of the model to the gradients contributed by
the data belonging to class Mi. ∇Loss is a column
vector composed of the partial derivatives of loss with
respect to θ contributed by each data. For example, if
the ith data belongs to class Mk, and the pre-selected
coefﬁcient for class Mk is c, then ni = |Mk| and ci = c.

From equation (4), we can show that:

θl+
i = θl

i − η

(cid:88)

Mt∈M

cMt
nMt

(cid:88)

Atk∈Mt

∂LossAtk
∂θi

M =

|M |
(cid:91)

t=1

Mt , Mt =

|Mt|
(cid:91)

k=1

Atk

(7)

(8)

where M represents the training data set, Mt refers

to the tth class in M , and Atk is the kth data of Mt.

(cid:80)

By selecting cMt to 1, ∀Mt ∈ M ,
∂LossAtk
1
can be viewed as the normal-
nMt
∂θi
ized equivalent gradient computed by each data Atk,
∀Atk ∈ Mt since nMt = |Mt|.

Atk∈Mt

Under this mechanism, gradient dilution issue will
be mitigated since the total gradient contributed by
each class accounts for the same proportion in terms of
contribution. In our experiment, to reﬂect the sensitivity
of the minority class, the pre-selected coefﬁcient for the
minority class is set to 1.2 while others remain 1.

B. Tree-Shaped Deep Neural Network (TSDNN)

To mitigate the imbalanced data issue, we propose an
end-to-end trainable TSDNN model (Fig. 1) which clas-
siﬁes the data layer by layer. We deﬁne each model in
TSDNN as a nodal network and the links between nodal
networks are called bridges. We adopt cross entropy as
the loss function and apply QDBP to each nodal network
to optimize the performance.

Unlike the architecture of a multi-layer perceptron
model which is a static structure, the model we proposed
grows and expands dynamically as the classiﬁcation goes
more detailed.

As shown in Fig. 1 (a), we ﬁrstly combine all the
malware data into a group labeled ”Malicious” and
perform a coarse classiﬁcation separating the malicious
ﬂows from the benign ones. Under this scenario, the
number of the two classes does not exist a large disparity
compared to the distribution of the entire data set and
therefore the gradient dilution issue will hardly alter the
classiﬁcation. After the preliminary classiﬁcation, the
data labeled ”Malicious” will ﬁrstly be transferred into
a concatenation stage then fed into a subsequent nodal

DataVi1BenignMaliciousVo1BotExploitRansomwareVo2MalspamTrojanLocky(a)CoarseClassification(b)Multi-classClassification(c)Fine-grainedClassificationConcatenationConcatenationCryptomixTeslacryptCrypMicCryptowallCryptXXXCerber[Vi1,Vo1][Vi1,Vo1,Vo2](a) Coarse Classification(b) Multi-class Classification(c)Fine-grained Classificationnetwork, which is the child of the current nodal network,
to further perform a detailed classiﬁcation.

In the second layer of TSDNN (Fig. 1 (b)), we would
like to classify the malicious ﬂows according to their
attack behavior. As far as the authors’ understanding,
the attack behavior of the malware can be categorized
into 5 categories as listed at the output end in Fig. 1
(b). Thus, the output dimension of the second nodal
network is set
to 5. Instead of directly feeding the
output vector V o1 of the malicious ﬂow calculated in
the ﬁrst layer into current nodal network, the output
vector V o1 will ﬁrstly undergo a concatenation process
where we concatenate the input vector V i1 of the
malicious ﬂow in the ﬁrst layer with the output vector
V o1 computed by the ﬁrst nodal network and regard
the resulting vector V i2 = [V i1, V o1] as the input
vector of the second nodal network. Namely, the input
vector V i2 of the second nodal network will consist
of two parts, the original vector V i1 of the malicious
ﬂow and the learned feature V o1 computed by the ﬁrst
nodal network. For example, if the input vector V i1 of
the ﬁrst nodal network is V i1 = [ui1, ui2, ui3] and the
corresponding output vector V o1 is V o1 = [uo1, uo2],
the input vector of the second nodal network will be
given by V i2 = [ui1, ui2, ui3, uo1, uo2]. However, as the
classiﬁcation goes ﬁner, the imbalanced data distribution
will become more conspicuous meaning that the gradient
dilution issue will inﬂuence the performance. By suitably
selecting the coefﬁcients ci for each class, QDBP can
still improve the performance. Afterwards, the data la-
beled ”Ransomware” will be fed into a succeeding nodal
network which is the child of the current nodal network
to further conduct a ﬁne-grained classiﬁcation.

Lastly, we conduct a ﬁne-grained classiﬁcation
demonstrated in Fig. 1 (c). In this layer, we classify
the data of the Ramsomware family in particular. As
described, the input vector V i3 of this nodal network
will incorporate the knowledge learned from the previ-
ous nodal networks. In other words, we concatenate the
output vectors V o1 and V o2 computed by the ﬁrst and
second nodal networks respectively with the input vector
V i1 of the ﬁrst nodal network and consider the resulting
vector V i3 = [V i1, V o1, V o2] as the input vector of
the current nodal network. Likewise, imbalanced data
distribution arises in this layer. By selecting suitable
coefﬁcients ci for each class, we can still conquer the
difﬁculty caused by the gradient dilution issue.

Apart from the multi-layer perceptron which classi-
ﬁes data altogether, we classify the data in a layer-
wise manner which can diminish the disparity between
classes when analyzing the data distribution in each
layer. Furthermore, the input vectors V i2 and V i3 of
the second and the third nodal networks are not directly
fed by the output vectors V o1 and V o2 of the preced-
ing nodal networks. Instead, the advantage of such a

hierarchical classiﬁcation is that we can generate new
features V o1 and V o2 in each layer and incorporate
the learned features into the next level’s input vector
to further provide more information. Moreover, since
TSDNN is end-to-end trainable meaning that all the
nodal networks are trained simultaneously, TSDNN can
tune the output vector of each nodal network through
QDBP to improve the erroneous classiﬁcation in the
learning phase. Another advantage is that TSDNN can
grow and expand dynamically, which differs from other
neural networks structurally. Namely, the more detailed
the classiﬁcation is desired, the more layers and nodal
networks will be involved in TSDNN.

V. EXPERIMENTS

A. Data Collection

The malware trafﬁc used in the experiments was
collected from September 2016 to May 2017 so as the
benign trafﬁc. We record the ﬁrst 6-minute network
behavior of the malicious samples obtained from Virus-
Total(https://www.virustotal.com) under sandbox.

The malicious data we collected are categorized into
5 different classes where each class represents differ-
ent attack behaviors. We further label the data of the
Ransomware family:Cryptomix, Locky, CrypMic, Tel-
slacrypt, CryptXXX, Cryptowall, Cerber, according to
the ofﬁcial name listed in VirusTotal. Therefore, our data
set is now composed of 12 different classes as illustrated
in Table I.

TABLE I
DATA STATISTICS

Class

Number of Flows

Size

Benign
Bot
Exploit
Trojan
Malspam
Cryptomix
Locky
CrypMic
Telslacrypt
CryptXXX
Cryptowall
Cerber

Total

246,015
99
349
3,085
3,612
90
229
390
755
1,259
2,864
23,260

560.2 MB
6.5 MB
32.5 MB
18.1 MB
142.1 MB
2.0 MB
9.3 MB
14.3 MB
26.5 MB
44.7 MB
34.7 MB
23.5 MB

282,007

914.4 MB

B. Feature Extraction

1) Connection Records: Referring to Williams et al.
[10], Internet protocols and connection statistics are
signiﬁcant to the identiﬁcation of trafﬁc and ﬂow. Thus,
we extract
the connection records like port, IP, and
protocol information in trafﬁc ﬂows from the transport
layer. In addition, according to Anderson et al. [11] and
Tseng et al. [12], the information of the HTTP requests
and TLS handshake will play a crucial role in trafﬁc
identiﬁcation. These information can be obtained in TCP
payloads.

TABLE II
ACCURACY AND PRECISION OF DIFFERENT APPROACHES

Method

Accuracy

Precision

DNN + Backpropagation
DNN + Oversampling (10000 samples/class) [7]
DNN + Undersampling (45 samples/class) [8]
DNN + Incremental Learning [9]
DNN + QDBP
SVM (RBF)
Random Forest
TSDNN + QDBP

59.08%
85.18%
68.89%
78.84%
84.56%
83.87%
98.9%
99.63%

8.33%
65.9%
49.45%
71.23%
62.3%
38.8%
68.25%
85.4%

2) Network Packet Payload: TCP and UDP payloads
always contain the transmitted data, and the former are
sometimes sent encrypted under TLS or SSL protocols.
In order to trace the malicious ﬂows and the accompa-
nied malware, the transmitted data of all payloads in a
ﬂow is important and should be taken into consideration.
Hence, we extract all the payloads from each packet
where the length of each packet ranges from 0 to 1,500
bytes.

3) Flow Behavior: Flow behavior is described as a
way to monitor the sending process of packets whereas
each malware family possesses different ﬂow behaviors.
According to Moore et al. [13], they proposed nearly
250 discriminators to classify the ﬂow record. Among
these discriminators, inter-arrival time of each packet
in a ﬂow plays the most important role in terms of
classiﬁcation. Besides, from McGrew et al. [14], they
used Markov matrix to store the relationship between
sequential packets. Inspired by their methods, we apply
Markov transition matrix to represent the ﬂow behavior
and document the before-and-after relationship.

C. Malicious Flow Detection and Layer-wise Analysis

1) Analysis on the Malicious Flow Detection: Firstly,
we would like to test if our model is able to distinguish
malicious ﬂows from the benign ones. Referring to
Tseng et al. [12],
their result could achieve a 93%
accuracy in malicious ﬂow detection using only HTTP
headers and TCP payloads. However, after including the
new features mentioned in the previous section, we can
achieve an accuracy of 99% under vanilla backpropa-
gation. If we further apply QDBP, the recognition rate
can even improve to 99.7%. This evidence shows the
improvement from the past work [12] to current and
justiﬁes that it is the feature that results in the improve-
ment under same training mechanism. On the other hand,
the subtle improvement contributed by QDBP indicates
that when the number of data in the minority class is
large to some extent, 35,992 in our task, the imbalanced
data distribution won’t be signiﬁcant since the quantity
is large enough to construct a robust model.

2) Comparison of Different Approaches on Flow
Classiﬁcation: In addition to detecting malicious ﬂows,
we would like to further classify the malicious ﬂows

more detailed into 11 different classes. In our task, there
are 246,015 ﬂows belong to the ”Benign” class while
”Cryptomix” class only contains 90 ﬂows. Such disparity
will result in an insensitive model which will misclassify
the data into the majority class if classifying the data
altogether through vanilla backpropagation. The result
is illustrated in Fig. 2. Fig. 2 is the confusion matrix
result of a 12-class classiﬁcation, confusion matrix is
a concrete way to present the result of a multi-class
classiﬁcation where true label represents the the ground
true label while the predicted label is the result that
given by the model. For example, if a data labeled ”Bot”
but predicted ”Exploit”, then the block corresponding
to that classiﬁcation will be increased by 1. An ideal
confusion matrix will have a dark color in the diagonal
while others bright. From the confusion matrix shown in
Fig. 2, we can observe that all testing data is classiﬁed
into the ”Benign” class, where the shade of the color of
each block indicates the probability of the corresponding
classiﬁcation.

Fig. 2. Confusion matrix of a traditional DNN with 3 hidden layers.
The DNN is trained with the vanilla backpropagation algorithm.

However, from Table II, the accuracy of vanilla back-
propagation can still achieve 59% even if the model
bias toward the majority class since the testing data set
contains roughly 30 thousand benign samples and 20
thousand malicious samples. This shows that the accu-
racy is not a comprehensive evaluation index because it
can easily be manipulated by adjusting the distribution
of the testing data set.

BenignBotExploitMalspamTrojanCrypMicLockyTeslacryptCerberCryptomixPredictedLabelCryptowallCryptXXXTrue LabelPredicted LabelTesting Confusion MatrixTo evaluate the model

in a more precise manner,
we adopt another performance metrics called average
precision and the mathematical formula is given by:

N
(cid:88)

i=1

(9)

P recisionavg =

T Pi
T Pi + F Pi

1
N
where N represents the number of classes, N = 2
in the coarse classiﬁcation and N = 12 in the 12-
class classiﬁcation. T Pi and F Pi stand for True Positive
and False Positive of class i respectively. Precision is
one of the performance metrics which represents the
ratio between the correctly classiﬁed samples and the
total data in each class. This performance metrics won’t
be seriously affected by the existence of the majority
class since it calculates the average precision of each
class. Though the cardinality of the ”Benign” class is
extremely large, this performance metrics won’t bias
toward the majority class completely since it treats each
class evenly. From Table II, the precision of vanilla
backpropagation is 8.33% which can reasonably support
the phenomenon shown in Fig. 2.

To mitigate the inﬂuence of the imbalanced data
distribution, we structure our neural network to be
hierarchical and classify the data layer by layer. Under
this setting, the data distribution in each layer will be
more balanced compared to prior methods. We can
reduce the quantity ratio between the majority class and
the minority class from 216,015
50 which nearly
45
shrinks the ratio by 17 times. Besides, we apply QDBP
in each layer to further improve the gradient dilution
issue.

to 14,423

imbalanced data set has to ascribe to two factors, the
TSDNN model which diminishes the disparity in each
layer and the proposed QDBP algorithm which mitigates
the gradient dilution issue.

We also compare the result with the state-of-the-art
methods [7], [8], [9] mentioned in the related work
section. As illustrated in Table II, the performance of
the vanilla backpropagation is seriously affected by the
gradient dilution issue because the cardinality of ”Bot”
and ”Cryptomix” classes is much smaller than that of
”Benign” class. Even though the state-of-the-art methods
can improve the performance of classiﬁcation,
these
methods still can’t resolve the gradient dilution issue.
If incorporating QDBP into TSDNN, the recognition
rate can even achieve 99.63% in accuracy and 85.4% in
precision which outperforms other approaches whether
in accuracy or in precision.

D. Partial Flow Detection

For the sake of real-time detection, we devise an
experiment by dividing each attack into fractions and
only consider a portion of the data to test the potentiality
of being a malware.

As illustrated in Fig. 4, the recognition rate of mali-
cious ﬂow detection ascends as the portion of the data
increases. Besides, from the result shown in Fig. 4, we
can conclude that our model is able to distinguish the
malicious ﬂow by only considering the ﬁrst 5 percent
of the entire ﬂow which shows the possibility of a real-
time detection since the model can perceive the potential
threats in the very beginning of the process without
analyzing the entire ﬂow.

Fig. 3. Confusion matrix of TSDNN. TSDNN is trained with QDBP
in each nodal network.

From the confusion matrix shown in Fig. 3, our
method enhances the performance of classifying the
entire imbalanced data set not only in the classiﬁcation
accuracy where the accuracy is improved from 59.08%
to 99.63% but in the sensitivity of the model where the
precision is improved from 8.33% to 85.4%. We further
conclude that the superior performance in training an

Fig. 4.
In the 6 minutes of each attack, our model can achieve
95% accuracy perceiving malicious ﬂows in the ﬁrst 5 percent of the
duration, namely 18 seconds. The ﬁrst part of ﬂows in the connection
gives enough clues for alerting malicious attacks.

E. Zero-shot Learning

There are various kinds of malware existing in the
cyber society. However, it is impossible to collect data
samples of each family since there are many new

BenignBotExploitMalspamTrojanCrypMicLockyTeslacryptCerberCryptomixPredictedLabelCryptowallCryptXXXPredicted LabelTrue LabelTesting Confusion MatrixPartial Flow ExperimentFlow Percentage (%)Accuracy (%)variants coming into existence every day. To evaluate
the generalization performance of the proposed model,
we would like to examine the ability of TSDNN to
identify some malware that has never been trained by
our model. This kind of scenario is coined as a ”zero-
shot learning” in machine learning term. Therefore, we
collect 14 different kinds of malware (Fig. 5) to evaluate
the ability of our model to perceive potential threats and
the experimental result is illustrated in Fig. 5.

From the experimental results, we can observe that
our model performs reasonably well on recognizing
these malware. In real world, each attack usually has
several network ﬂows. Once any part of these ﬂows is
recognized as a malicious connection, the attack will be
blocked and the process will be terminated immediately.
This result not only shows the ability to predict potential
threats but further justiﬁes that a behavior-oriented ap-
proach to detect malware is a better way compared to the
traditional signature-based methods, which also accounts
for the generalization capability of deep learning.

Fig. 5. The new malware data set contains 14 different families which
are different from that used in training TSDNN.

VI. CONCLUSION
We propose an end-to-end trainable TSDNN model
along with a QDBP algorithm, which enables the model
to
to memorize and learn from the minority class,
perform malicious ﬂow detection. Unlike the multi-layer
perceptron architecture which classiﬁes the data alto-
gether, we classify the data in a layer-wise manner. We
further conduct a partial ﬂow detection which is meant
to seek for the possibility of real-time detection by only
considering a portion rather than the entire ﬂow. From
the experimental result, real-time detection can truly

be fulﬁlled. To evaluate our model’s ability to detect
potential malware, we execute an experiment on testing
the malware that has never been trained by our model.
The experimental results show that our model is able
to accurately detect the potential malware at a superior
performance which also justiﬁes that behavior-oriented
approach is better than signature-oriented methods when
detecting malware.

VII. ACKNOWLEDGEMENT

This work is supported by the Ministry of Science
and Technology, Taiwan, under Grant MOST 106-3114-
E-002-005 and MOST 106-2627-M-002-023.

REFERENCES

[1] Saja Alqurashi, Omar Batarﬁ, et al., “A comparison of malware
detection techniques based on hidden markov model,” in Journal
of Information Security, vol. 7, no. 03, pp. 215, 2016.

[2] John Demme, Matthew Maycock, Jared Schmitz, Adrian Tang,
Adam Waksman, Simha Sethumadhavan, and Salvatore Stolfo,
“On the feasibility of online malware detection with performance
counters,” in ACM SIGARCH Computer Architecture News, vol.
41, no. 3, pp. 559-570, 2013.

[3] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton, “Im-
agenet classiﬁcation with deep convolutional neural networks,”
in Advances in Neural Information Processing Systems 25, pp.
1097-1105, 2012.

[4] Tomas Mikolov, Martin Karaﬁ´at, Lukas Burget, Jan Cernock`y,
“Recurrent neural network based

and Sanjeev Khudanpur,
language model,” in Interspeech, vol. 2, pp. 3, 2010.

[5] Ioan Sorin Coms¸a, Sijing Zhang, Mehmet Aydin, Jianping Chen,
Pierre Kuonen, and Jean-Frederic Wagen, “Adaptive proportional
fair parameterization based lte scheduling using continuous actor-
critic reinforcement learning,” in IEEE Global Communications
Conference(GLOBECOM), pp. 4387-4393, Dec. 2014.

[6] Ioan Sorin Coms¸a, Mehmet Aydin, Sijing Zhang, Pierre Kuonen,
Jean-Frederic Wagen, and Yao Lu, “Scheduling policies based
on dynamic throughput and fairness tradeoff control in lte-a
networks,” in 39th Annual IEEE Conference on Local Computer
Networks (LCN), pp. 418-421,Sept. 2014.

[7] Russel Pears, Jacqui Finlay, and Andy M Connor, “Synthetic
minority over-sampling technique (smote) for predicting software
build outcomes,” in arXiv preprint arXiv:1407.2330, 2014.
[8] Xu-Ying Liu, Jianxin Wu, and Zhi-Hua Zhou, “Exploratory un-
dersampling for class-imbalance learning,” in IEEE Transactions
on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 39,
no. 2, pp. 539-550, 2009.

[9] Pallavi Kulkarni and Roshani Ade, “Incremental learning from
unbalanced data with concept class, concept drift and missing
features: a review,” in International Journal of Data Mining &
Knowledge Management Process, vol. 4, no. 6, pp. 15, 2014.

[10] Nigel Williams, Sebastian Zander, and Grenville Armitage, “A
preliminary performance comparison of ﬁve machine learning
algorithms for practical ip trafﬁc ﬂow classiﬁcation,” in ACM
SIGCOMM Computer Communication Review, vol. 36, no. 5,
pp. 5-16, 2006.

[11] Blake Anderson, Subharthi Paul, and David McGrew, “Decipher-
ing malware’s use of tls (without decryption),” in arXiv preprint
arXiv:1607.01639, 2016.

[12] Aragorn Tseng YunChun Chen YiHsiang Kao, TsungNan Lin,
“Deep learning for ransomware detection,” in IEICE Tech. Rep.,
vol. 116, no. 282, IA2016-46, pp. 87-92, Nov. 2016.

[13] Andrew Moore, Denis Zuev, and Michael Crogan, “Discrimina-
tors for use in ﬂow-based classiﬁcation,” Technical Report, Intel
Research, Cambridge, 2013.

[14] David McGrew and Blake Anderson,
for encrypted threat analytics,”
Conference on Network Protocols (ICNP), pp. 1-6, 2016.

“Enhanced telemetry
in IEEE 24th International

7580859095100Bergat (447 flows)      Crowti (2476 flows)    Dynamer (310 flows)  M_bagsu (221 flows)  Virlock (464 flows)     Virut (212 flows)         Upatre (5506 flows)    Sality (386 flows)        Partie.B (107 flows)    Skeeyah (184 flows)    Symmi (231 flows)      Toga (241 flows)          WannaCry (709 flows) Adylkuzz (5683 flows)Recognition rate(%)