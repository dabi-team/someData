1
2
0
2

b
e
F
0
2

]
E
S
.
s
c
[

1
v
0
3
4
0
1
.
2
0
1
2
:
v
i
X
r
a

Cybersecurity Awareness Platform with Virtual
Coach and Automated Challenge Assessment

Tiago Gasiba1,2[0000−0003−1462−6701], Ulrike Lechner2[0000−0002−4286−3184],
Maria Pinto-Albuquerque3[0000−0002−2725−7629], and Anmoal
Porwal1[0000−0002−2926−9797]

1 Siemens AG, Munich, Germany
{tiago.gasiba,anmoal.porwal}@siemens.com
2 Universit¨at der Bundeswehr M¨unchen, Munich, Germany
{ulrike.lechner,tiago.gasiba}@unibw.de
3 Instituto Universit´ario de Lisboa (ISCTE-IUL), ISTAR-IUL, Lisboa, Portugal
maria.albuquerque@iscte-iul.pt

Abstract. Over the last years, the number of cyber-attacks on indus-
trial control systems has been steadily increasing. Among several factors,
proper software development plays a vital role in keeping these systems
secure. To achieve secure software, developers need to be aware of secure
coding guidelines and secure coding best practices. This work presents a
platform geared towards software developers in the industry that aims
to increase awareness of secure software development. The authors also
introduce an interactive game component, a virtual coach, which im-
plements a simple artiﬁcial intelligence engine based on the laddering
technique for interviews. Through a survey, a preliminary evaluation of
the implemented artifact with real-world players (from academia and
industry) shows a positive acceptance of the developed platform. Fur-
thermore, the players agree that the platform is adequate for training
their secure coding skills. The impact of our work is to introduce a new
automatic challenge evaluation method together with a virtual coach
to improve existing cybersecurity awareness training programs. These
training workshops can be easily held remotely or oﬀ-line.

Keywords: Cybersecurity · Awareness · Training · Artiﬁcial Intelligence
· Serious Games · Secure Coding · Static Application Security Testing ·
Capture-the-Flag

1

Introduction

Errors and vulnerabilities in software development, if not solved early, can end
up in a ﬁnal product. These problems can result in serious consequences for
the customer and the company that produced the software. This work aims to
improve the situation through a serious game to raise awareness on secure coding
and software development best practices of software developer – thus addressing
the issues at early stages in software development, i.e., when it is being written.

 
 
 
 
 
 
2

T. Gasiba et al.

In the next sub-sections, we present the problem at hand in more detail. We
give a brief overview of standardization bodies, industry-led eﬀorts, and academic
eﬀorts that were started to address the current situation. Finally, we describe
our proposed methodology and our contributions to scientiﬁc knowledge.

1.1 The Need for Secure Coding Awareness

The number of security advisories issued per year by the Industrial Control
System - Computer Emergency Response Team (ICS-CERT) has been steadily
increasing. While before 2014 the number of advisories per year was less than
100, from 2017 to 2019 more than 200 advisories have been issued per year. These
facts correlate well with the observed increase in the number and sophistication
of cyber-attacks to industrial control systems (ICS).

The ransomware WannyCry, released by the ”The Shadow Brocker” hacker
group in 2017, which exploits a vulnerability in the Server Message Block (SMB)
protocol, dubbed EternalBlue, has aﬀected numerous industrial control systems.
It has caused a ﬁnancial impact exceeding 4 billion USD in more than 140
countries. The vulnerability exploited by EternalBlue is a buﬀer overﬂow caused
by an integer overﬂow; exploitation of buﬀer overﬂows is not new - this is known
since the late ’70s.

While not everything (e.g., attacks and vulnerabilities) can be traced back
directly to a speciﬁc software vulnerability, an increasing number of such vul-
nerabilities (i.e., related with secure coding) have also been observed. Software
security and secure software development play a fundamental role in industrial
cybersecurity, particularly in critical infrastructures. According to a recent sur-
vey with more than 4000 software developers [14], ”less than half of developers
can spot security holes” [18]. This lack of awareness causes a severe issue in
terms of cybersecurity of industrial control systems and critical infrastructures.
The present work focuses on C and C++ programming languages. This is mo-
tivated by a recent study by Whitehat [23], which has shown that C and C++
are among the most used programming languages for industrial environments,
but they are also among the most vulnerable in terms of cybersecurity vulnera-
bilities. This study also implies that the majority of vulnerabilities are created
in these programming languages.

1.2 Standards, Industry, and Academic Eﬀorts

In recognition of the importance of secure products and a consequence of the cur-
rent move towards digitalization and higher connectivity, several large industrial
players have joined together and committed to a document called the charter of
trust [19]. The charter of trust outlines ten fundamental principles that the part-
ners vow to obey to address the issues inherent with cybersecurity. ICS relevant
standards such as IEC 62443-4-1 [12] or ISO 27001 [13] mandate the implementa-
tion of secure software development life-cycle processes and awareness training.
These standards address security from a high-level perspective and are not spe-
ciﬁc enough about recommendations, policies, and best practices to be followed

Cybersecurity Awareness with Virtual Coach and Automated Assessment

3

in software development. Towards this goal, an industry-led eﬀort was created,
the Software Assurance Forum for Excellence in Code (SAFECode), with the
aim of identifying and promoting best practices for developing and delivering
more secure and reliable software, hardware and services.

Serious Games designed to train developers and raise their awareness for
cybersecurity and secure coding is our approach to ameliorate the situation, and
other approaches are [5, 6, 15, 16]. We designed a game to raise awareness for
cybersecurity among programmers and for secure coding guidelines and secure
coding best practices. Our approach is an adoption of the popular format of
Capture-the-Flag. CTF is a serious game genre in the domain of cybersecurity
popular in the penetration-test community as a means to practice oﬀensive skills.
In this kind of game, the game participants aim to gather the highest amount of
awarded by solving cybersecurity challenges, e.g., breaking into systems. In [6],
Gasiba et al. study the requirements that a game designer should follow to
target the game to software developers in the industry. In a further work [8],
the authors provide six concrete and diﬀerent challenge types to be used in this
kind of CTF event. One of these is the ”code entry” challenge type, where the
proposed idea is that player interacts through a web interface with a backend
by modifying vulnerable code until all the coding guidelines are fulﬁlled, thus
solving the challenge.

1.3 Automatic Challenge Evaluation

This paper extends the previous work, particularly the ”code entry” challenge
type, by describing the architecture of a platform, which the authors call Sifu,
that was constructed to implement the game backend. The goal of this platform
is to: 1) automatically analyze the solution submitted by the participant to the
backend, 2) determine if this solution contains vulnerabilities and fulﬁlls the
required functionality, 3) generate hints to the player if the solution does not
achieve a pre-determined goal and ﬁnally 4) provide a ﬂag (i.e., a unique code)
which the player can use to gather points in the game. The correctness of the
solution depends on it following established secure coding guidelines and secure
programming best practices.

The generated hints are provided by a virtual coach, which assists the player
in solving the challenge. These hints are created using a simple artiﬁcial intel-
ligence (AI) engine that provides automatic pre-programmed interactions with
the player when the submitted solution fails to meet the secure coding criteria.
These hints generated by the AI Engine (i.e., the virtual coach) assist the player
in solving the challenge in a playful way and help lower the frustration, increase
the fun, and improve the learning eﬀect during gameplay.

The core of the present work is to describe the virtual coach platform. Nev-
ertheless, to validate its suitability as a means to raise secure coding awareness,
a small survey was performed with real players. Our preliminary results show
that the participants have fun using the platform and also ﬁnd it adequate for
learning secure coding guidelines and secure software development best practices.

4

T. Gasiba et al.

1.4 Contributions of this work

This work seeks to provide the following impact in the research community:

– introduce a novel method to automatically analyze player code submission in
terms of secure coding guidelines and software development best practices,
– introduce a virtual coach based on the laddering interview AI technique, and
– provide a preliminary analysis of the suitability of the proposed architecture
in terms of adequacy to raise secure coding awareness of software developers.

Although we intend to use the Sifu platform in a CTF environment, it can
also be used stand-alone in remote and oﬄine training scenarios. This can be
especially important if the players are spread over a large geographic area or
have inherent restrictions on a face-to-face workshop.

1.5 Paper Outline

This work is organized as follows. In section 2 we present previous related sci-
entiﬁc work. Section 3 presents details on the architecture and implementation
of the Sifu platform. This section also introduces the virtual coach and gives
details on the implemented artiﬁcial intelligence algorithm. In section 4, pre-
liminary results from a short survey to 15 participants in a pilot are presented.
Finally, section 5 presents the conclusions and further work.

2 Related Work

Playing cybersecurity games is gaining more and more attention in the research
community. In [5], Frey et al. show both the potential impact that playing cy-
bersecurity games can have on the participants and also show the importance
of playing games as means of cybersecurity awareness. They conclude that cy-
bersecurity games can be useful to build a common understanding of security
issues.

A serious game [4] is a game that is designed with a primary goal and purpose
other than entertainment. Typically these games are developed to address a
speciﬁc need such as learning or improving a skill. A Capture-the-Flag (CTF)
game is one possible instance of a serious game. Votipka et al. [22] argue in
their work that CTF events can be used as a means to improve security software
development. In particular, their work shows that the participants of such events
experience positive eﬀects on improving their security mindset. Davis et al., in [2],
discuss the beneﬁts of CTF for software developers. In their work, they argue
that CTFs can be used to teach computer security and conclude that playing
CTFs is a fun and engaging activity.

In their work, Graziotin et al. [9] argue that happy developers are better
coders. They show that developers that are happy at work tend to be more fo-
cused, adhering to software development processes, and following best practices.
This improvement in software development leads to the conclusion that happy

Cybersecurity Awareness with Virtual Coach and Automated Assessment

5

developers can produce higher quality and more secure code than unhappy de-
velopers. The authors believe that CTF events since they are experienced as
fun events, can foster higher code quality and adherence to secure development
principles.

However, CTF events need to be properly designed to achieve this goal.
Gasiba et al., in [6], perform requirements elicitation employing systematic lit-
erature review, interview of security experts, and also CTF participants from
industry. Their work details the requirements for CTF events to raise secure
coding awareness of software developers in the industry. In particular, they con-
clude that CTF challenges for software developers should focus on the defensive
perspective instead of oﬀensive.

In their work, Sim˜oes et. al [20] present several programming exercises for
teaching software programming in academia. Their design includes nine exercises
that can be presented to students to foster student motivation and engagement
in academic classes and increase learning outcomes. Their approach uses gamiﬁ-
cation and automatic assessment tools. However, their work focus on the correct
solution (implementation) of the programming exercise and not on the secure
programming and security best practices aspects.

Gasiba et. al [8] propose, in a similar work, six diﬀerent challenge types. These
challenges, which are also a form of programming exercises, are executed in the
context of a serious game of the type CTF and target software developers in the
industry. One of the challenge types is a so-called code-entry challenge, where
the CTF participant is given a project (e.g., in C or C++) that contains software
vulnerabilities. The challenge aims to have the participants ﬁx the security vul-
nerabilities by applying secure coding guidelines and software development best
practices. In this previous work, the challenge type was only derived conceptually
and lacked implementation and practical evaluation aspects.

Vasconcelos et. al [21] have recently shown a method to evaluate program-
ming challenges automatically. In their work, the authors use Haskell and the
QuickCheck library to perform automated functional unit tests of challenges
submitted by students. Their goal is to evaluate if the solutions presented by
the students comply with the programming challenge in terms of desired func-
tionality. One of the main limitations of this work is that the code to be tested
should be free from side eﬀects. The authors also focus on functional testing of
single functions and do not address the topic of cybersecurity.

In [1, 3], Dobrovsky et al. describe an interactive reinforcement learning
framework for serious games with complex environments where a non-player
character is modeled using human guidance. They argue that interactive rein-
forcement learning can be used to improve learning and the quality of learning.
However, their work aims to train an algorithm better to recreate human behav-
ior by means of machine learning techniques. In our work, we aim at training
humans to write better and more secure code. Due to this fact, machine learn-
ing techniques are not applicable. Nonetheless, we draw inspiration from the
conceptual framework, which we adapt to our scenario.

6

T. Gasiba et al.

Rietz et al. [17], show how to apply the principles of the laddering interview
technique for requirements elicitation. The laddering technique consists of issu-
ing a series of questions that are based on previous system states (i.e., previous
answers and previous questions). The questions generated are reﬁned versions
of previously issued questions as if the participant is climbing up a ladder con-
taining more speciﬁc questions. Although this previous work applies in the ﬁeld
of requirements elicitation and does not focus on cybersecurity, the laddering
technique principle can be adapted to a step-wise hint system.

In the present work, we also make use of the concept of awareness or IT-
security awareness as deﬁned by Haensch et al. in [11], in order to evaluate our
artifact. In their work, they deﬁne awareness as having the following three dimen-
sions: perception, protection, and behavior. The perception dimension is related
to the knowledge of existing software vulnerabilities. The protection dimension
is related to knowing the existing mechanisms (best practices) that avoid soft-
ware vulnerabilities. Finally, the behavior dimension relates to the knowledge
and intention to write secure code. We collect data from participants based on
the three dimensions of awareness through a small survey. We use best practices
in the design, collection, and processing of survey information given by Grooves
et al. [10].

3 Sifu Platform

In following sub-sections we present the research problem in terms of research
questions and present a possible solution. Additionally, we describe the setup of
a small survey that was performed to evaluate our result.

3.1 Problem Statement

In [8], the authors present a type of challenge for CTFs in the industry, which is
called code-entry challenge (CEC). The main idea of this type of challenge is for
the Player to be given a software development project that contains code that
does not follow secure coding guidelines (SCG) and secure software development
best practices (BP) and contains security vulnerabilities. In this work, we target
speciﬁcally ICS by using SCG and BP, which are speciﬁc for this ﬁeld. The task
of the Player is to ﬁx the vulnerabilities and to follow SCG and BP. The Player
should do this so that the original intended functionality is still fulﬁlled in the
new version of the code. The present work aims to solve these requirements by
means of a platform that performs an automatic evaluation of the code sub-
mitted by the participant and guides the participant towards the ﬁnal solution.
Considering these requirements, the following research questions are then raised:

RQ1: how to automatically assess the challenges in terms of SCG and BP?
RQ2: how to aid the software developer when solving the challenges?

This work proposes to address RQ1 through a specialized architecture to au-
tomatically assess the level of compliance to SCG and BP by combining several

Cybersecurity Awareness with Virtual Coach and Automated Assessment

7

state-of-the-art security testing frameworks, namely Static Application Security
Testing (SAST), Dynamic Application Security Testing (DAST), and Runtime
Application Security Protection (RASP). The functional correctness of the pro-
vided solution by the Player is evaluated using state-of-the-art Unit Testing
(UT). To address RQ2, the authors propose to combine the output of the secu-
rity testing tools with an AI algorithm to generate hints based on the laddering
technique, thus implementing a virtual coach. The task of the virtual coach is
to lower the frustration of the participant during gameplay and to aid in the
participant to improve the code.

The proposed solution herein described makes a contribution towards an-
swering these research questions. To validate the assumption of the suitability
of our proposal as a means to address the research questions, a small survey was
conducted.

3.2 Code-entry challenge platform architecture

Figure 1 shows the top-level view of the Sifu architecture. In this ﬁgure, the
”Player” represents the game participant (a human) and the ”Project” repre-
sents a software project that contains vulnerabilities to be ﬁxed by the Player.
The ”Analysis & Hints” (AH) component performs the core functionality: 1)
evaluates the submitted code (Project) in terms SCG and BP, 2) indicates if the
challenge is solved or not and, if not solved, 3) generates hints to send back to the
participant. The ”State” component stores previous interactions and generated
hints. During gameplay, the Player reads the Project and modiﬁes the code by
interacting with a web editor interface. When the changes in the code are done,
the Player submits the code to the AH component for analysis.

Fig. 1. Conceptual game overview: interaction and components

A possible realization of the conceptual architecture is shown in ﬁgure 2.
Interaction takes place between the Player and a web interface, which connects
to a web backend. The web backend is responsible for triggering the automated
security assessment, collecting the answer from the AI engine, and sending the
answer back to the participant. To realize this, the Project submitted by the

(cid:51)(cid:85)(cid:82)(cid:77)(cid:72)(cid:70)(cid:87)(cid:36)(cid:81)(cid:68)(cid:79)(cid:92)(cid:86)(cid:76)(cid:86)(cid:3)(cid:9)(cid:3)(cid:43)(cid:76)(cid:81)(cid:87)(cid:86)(cid:51)(cid:79)(cid:68)(cid:92)(cid:72)(cid:85)(cid:54)(cid:87)(cid:68)(cid:87)(cid:72)(cid:51)(cid:79)(cid:68)(cid:92)(cid:72)(cid:85)(cid:3)(cid:76)(cid:81)(cid:87)(cid:72)(cid:85)(cid:68)(cid:70)(cid:87)(cid:86)(cid:54)(cid:81)(cid:54)(cid:81)(cid:14)(cid:20)(cid:51)(cid:81)(cid:43)(cid:81)(cid:14)(cid:20)8

T. Gasiba et al.

participant is ﬁrst saved into a temporary folder after a pre-processing step (e.g.
to inject code necessary for unit tests). After the addition of auxiliary ﬁles (e.g.
C/C++ include ﬁles) to the temporary project directory, the Project is compiled,
and a functional test and security assessment is performed. All these results are
then made available to an AI engine, which determines if the challenge is solved
and generates hints. This feedback is collected by the web backend and stored
in an internal database and forwarded as the answer back to the participant’s
web browser.

Fig. 2. Detailed architecture: the Sifu Platform

Automatic Security Assessment The security assessment which is per-
formed to the Project is composed of the following steps: 1) Compilation, 2)
Static Application Security Testing, 3) Unit Testing, 4) Dynamic Application
Security Testing, and 5) Runtime Application Security Testing. In step 1, the
Project is compiled; if there are compilation errors, these are reported to the
AI component, and no further analysis takes place. Step 2 performs static code
analysis. Note that in this step, the code does not need to be executed. Since the
steps 3, 4 and 5 involve executing untrusted (and potentially dangerous) code,
these are performed in a time-limited sandbox. The sandbox is very restrictive,
e.g., it only contains the project executable and drops security-relevant capa-
bilities (e.g., debugging and network connections are not allowed). Additionally,
the executable is only allowed to run for a certain amount of time inside the
sandbox. If this time is exceeded, the process will be automatically terminated.
This avoids denial-of-service attacks by means of high CPU usage. Two types
of Unit tests are executed: 1) functional testing - in order to guarantee that the
provided code is working as intended (e.g., in the challenge description), and 2)
security testing - in order to guarantee that typical vulnerabilities are not present
in the code (e.g., buﬀer overﬂow). Security testing is done using self-developed

WebBackendWebFrontendSandboxToolsSASTUnitTestsA.I.CollectorFeedbackBackendProjectPre-ProcessingAI EngineDASTCompiler!"#$Cybersecurity Awareness with Virtual Coach and Automated Assessment

9

tests and also using state-of-the-art fuzzing tools. Steps 4 and 5 perform several
dynamic security tests. Table 1 lists the tools that the authors have used in each
of these components. In this table, the open-source components used in the Sifu
platform are marked with ”OS”.

Table 1. Security Assessment Tools

Component

Tools

Compiler
SAST
DAST
RASP
Unit Test

GCC v10.1 (OS), Clang 9.0.0 (OS)
SonarQube, Pc Lint, cppchecker (OS), fbinfer (OS), semgrep (OS)
Valgrind (OS), Helgrind (OS)
Address Sanitizer (OS), Leak Sanitizer (OS), Thread Sanitizer (OS)
ATF (OS), Kyua (OS), AFL (OS)

Virtual Coach with AI Technique The AI component shown in ﬁgure 2
collects the results of the previous analysis steps, runs an AI engine based on
the laddering technique, and generates the feedback to be sent back to the par-
ticipant. Figure 3 shows the implementation of the AI engine using the laddering
technique.

As previously detailed, the automated assessment tools perform several tests
that are used to determine the existing software vulnerabilities present in the
Project. These are collected in textual form (e.g., JSON and XML) and nor-
malized to be processed by the AI engine. The two most essential test results
from the security assessment components are related to compilation errors (e.g.,
syntax errors) and functional unit testing. The participant’s solution will be re-
jected if the code does not compile or is not working (functioning) as intended.
When both these tests pass, the artiﬁcial engine uses the security tests, SAST,
DAST, and RASP tools to generate hints to send to the participant.

A combination of ﬁndings from these tools forms a vulnerability. These ﬁnd-
ings and vulnerabilities are then mapped to SCG and BP. In ﬁgure 3, each
horizontal path (ith row) corresponds to a ladder and also to a speciﬁc combina-
tion of vulnerabilities or static events found in the source code. Each path is also
assigned a priority p(i) based on the criticality of the SCG and vulnerabilities.
These priorities are assigned according to the ranking of secure coding guidelines,
as presented in Gasiba et al. (see [7]). Higher-ranked secure coding guidelines
are given higher priorities, and lower-ranked secure coding guidelines are given
lower priorities. The AI engine to selects the corresponding path (corresponding
to one ladder) which based on the ﬁnding with the highest rank.

The chosen hint Hn+1 depends on the ladder and on the previous hint level
sent to the participant on the ladder, as given by the system state. If there are
no more hints in the ladder, no additional hint is sent to the Player.

Table 2 shows an example of hints provided by the virtual coach’s AI en-
gine corresponding to an ”undeﬁned behavior” path. The lower level hints are
generic and give background information for the participant. The highest level

10

T. Gasiba et al.

Fig. 3. Laddering technique to generate hints

hint contains exact information on how to solve the problem, thus revealing the
solution.

Table 2. Example of hint ladder with six levels

Level
1
2

3
4
5
6

Hint Text

The following links contain information that might be helpful: <link>, <link>
The compiler is free to optimize the compiled code assuming that there is no
undeﬁned behavior in the code
Look at the variable ’i’
Read carefully the following secure coding guideline: <link>
The code accesses the variable ”Values” - check carefully the bounds
Since undeﬁned behavior is not allowed, and the variable ”Values” must be indexed
within the bounds, the check i<4 is removed by the compiler!

Finally, the Feedback component formats and enriches the selected hint by
the AI Engine with project-speciﬁc information and sends it to the Web Back-
End component to present to the Player. To foster critical thinking, the authors
have also implemented a hint back-oﬀ (i.e., no hint will be given to the Player who
is brute-forcing the hint system). This back-oﬀ system implements the following
rule: 1) no hint is provided to the Player during 4 minutes after the backend
has sent a hint to the Player, and 2) no hint is given until the number of code
submissions since the previous hint sent to the Player by the backend is equal
to 3 submissions.

Note that the feedback component not only fosters critical thinking by the
Player, but can also be used to train the Player with the usage of static code
analysis tools. However, further investigation of this aspect is needed in the
future.

Real-World Artifact Figure 4 shows the web interface of a real-world im-
plementation of the Sifu platform. The machine where the Sifu platform was
deployed was an AWS instance of type T3.Medium (2 CPUs with 4Gb RAM
and network connection up to 5Gb/s). In order to install the required tools, a

H1,1H1,2H1,N(1)H2,1H2,2H2,N(2)Hk,1Hk,2Hk,N(k)Path selectorHint adaptationCybersecurity Awareness with Virtual Coach and Automated Assessment

11

hard-disk of 40Gb was selected. The Sifu platform itself is developed in Python
3.8 using Flask.

Fig. 4. Sifu Web Interface

On the left, the Player can browse the Project and select a ﬁle to edit; the
ﬁle editor is in the center, and on the right are the hints that the Player receives
from the backend. The upper part contains buttons which include the following
functionality: Submit - to submit the Project for analysis, Reload - to reload the
Project from scratch, Report Challenge - to report problems with the challenge
to the developers. Note that, when a player ﬁnishes a challenge successfully, it is
taken to an additional page with discussions on the impact of the vulnerability
and additional closing questions (e.g., on which secure coding guidelines have
not been taken into consideration).

Evaluation of real-world artifact The platform containing ﬁve diﬀerent chal-
lenges was made available for experimentation to 15 participants in Germany in
June 2020. Participants’ ages ranged between 20 and 50 years old, with an av-
erage of 28.3. The participants’ background was: 7 computer science students, 7
professional software developers, and 1 assistant professor. Participants were al-
lowed to try the platform for as long as they liked; this resulted in a range from
15 minutes to 45 minutes. When successfully solving a challenge, the partici-
pants were asked (through the web interface) to rate the challenge based on the
questions presented in table 3. Additionally, upon completing the experiment,
when the participants were asked to ﬁll out a small online survey. The questions
asked in this survey are presented in table 4. Both the challenge rating and the
platform survey questions were based on a 5-point Likert scale.

12

T. Gasiba et al.

Table 3. Challenge rating questions

Question

Please give an overall rating to the challenge
How well could you recognize the vulnerability in the code?
How well can you ﬁx this problem in production code?

Table 4. Platform survey questions

Feedback Question
My overall experience with the platform was positive
The Sifu platform helps me to improve my secure coding skills
Solving challenges in the Sifu platform helps me in recognizing
vulnerable code
Solving challenges in the Sifu platform helps me in under-
standing consequences of exploiting vulnerable code
Solving challenges in the Sifu platform makes me overall
happy
Challenges in the Sifu platform help me to practice secure
coding guidelines
I ﬁnd the Sifu platform adequate as a means to raise awareness
on secure coding
The examples in the Sifu platform are clearly presented
It is fun to solve challenges in the Sifu platform

Number
Q1
Q2
Q3

Number
F1
F2
F3

F4

F5

F6

F7

F8
F9

4 Results

In this section, we present the results of the challenge feedback questions and the
participants’ survey. The results were processed using RStudio version 1.2.5019.
Additionally, we brieﬂy discuss the threats to validity.

4.1 Challenge Feedback

Figure 5 shows the results of the challenge rating questions. The average values
and standard deviation are the following: Q3 3.92 (σ = 1.19), Q1 3.76 (σ = 1.30),
Q2 3.72 (σ = 1.21). In order of agreement: the participants are conﬁdent to be
able to ﬁx the problem in production code, have rated positively the presented
challenges and would be able to recognize the vulnerability in (production) code.

Fig. 5. Evaluation of Challenges in Sifu Platform

213031673751010980%10%20%30%40%50%60%70%80%90%100%Q1Q2Q312345StronglyDisagreeStronglyAgreeCybersecurity Awareness with Virtual Coach and Automated Assessment

13

4.2 Sifu Survey

Figure 4 shows the survey results. The average values and standard deviation
are the following: F6 4.33 (σ = 0.49), F2 4.00 (σ = 0.38), F9 3.93 (σ = 1.03), F7
3.80 (σ = 0.86), F8 3.80 (σ = 0.94), F1 3.73 (σ = 0.70), F3 3.67 (σ = 0.62), F5
3.67 (σ = 1.35), and F4 3.33 (σ = 0.82). In general, the overall positive feedback
gathered through the survey shows that the Sifu platform helps to raise aware-
ness on software developers on the topic of secure coding and secure software
development best practices. In particular, the Sifu platform helps software devel-
opers to practice secure coding guidelines (F6) and helps software developers to
improve their secure coding skills (F2). Furthermore, using the platform is fun
and adequate as a means to raise secure coding awareness (F9 and F7). In terms
of awareness (perception - F3, protection - F2, and behavior - F6), as deﬁned by
H¨ansch et al. [11], the platform is also seen as adequate to improve awareness.
Another important aspect is that the participants ﬁnd that the programming
examples are clearly presented in the platform (F8). Finally, the participants
also tend to agree that using the platform can be fun (F9) and improve happi-
ness (F5) and is an overall positive experience (F1). The results can be split into
three clusters, according to the level of agreement as follows: medium agreement
(3.33-3.67), higher agreement (3.73-3.8) and highest agreement (3.80-4.33). Using
these clusters, the results can be interpreted in the following way (from highest
agreement to medium agreement):

– highest agreement: helps to practice and improve secure coding, is fun and

adequate to raise secure coding awareness

– higher agreement: challenges are clearly presented and the experience is pos-

itive

– medium agreement: helps to recognize vulnerable code and understand con-

sequences and makes happy

Fig. 6. Survey Results

The results hereby presented give an indication towards the suitability of the
herein proposed solution to address RQ1 and RQ2, as stated in the problem
statement of section 3.

201300222013440122131311841010860100552350%20%40%60%80%100%F1F2F3F4F5F6F7F8F912345StronglyDisagreeStronglyAgree14

T. Gasiba et al.

4.3 Threats to Validity

The main aim of this work is to present an architecture of a serious game geared
towards improving the secure coding skills of software developers. To validate the
platform’s usefulness, the authors have gathered feedback from 15 participants
in a trial experiment. Possible sources of threat to the validity of the results and
conclusions presented in the previous section include:

– low number of participants: although the gathered feedback shows a clear
tendency towards positive feedback, the number of participants was low,
making the standard deviations relatively high,

– participants’ background: while the serious game is designed for industrial
environments, a large portion of the participants were computer science stu-
dents. Although the authors do not believe that this causes a signiﬁcant
change in the results, further studies with industry players is required,

– survey design: the survey administered at the end of the experiment was
guided by survey best practices; however, it lacks a formal and thorough
design, e.g., based on existing theories and existing questions database,
– external validity: although the goal of the present work is to propose a new
method to raise secure coding awareness of software developers, our study did
not contain a comparison of the methodology against existing and established
methods.

5 Conclusions

Secure coding guidelines, secure software development best practices, and se-
cure coding policies form an essential aspect of secure software development
for industrial control and cybersystems. Motivated by cybersecurity standards
and industry needs on raising awareness about secure coding guidelines, this
work presents a novel method where software developers learn these secure cod-
ing best practices in an online environment in the context of a serious game -
Capture-the-Flag, while being assisted through a virtual coach. In particular,
this work addresses and details an architecture that can scale (e.g., through
online training) and is based on an interview laddering technique to generate
helpful hints. Another source of inspiration for the current work is reinforcement
learning techniques; however, the trainee is a human being, not a machine.

Our proposed solution uses existing open source components to perform unit-
testing, static, dynamic, and run-time security analyses of the project code,
which the participants need to change to eliminate software vulnerabilities. We
also brieﬂy discuss implemented mechanisms that prevent cheating by the players
and mechanisms that do not allow them to attack the system back-end.

Finally, we obtain feedback on the produced artifact through evaluation ques-
tions upon completing diﬀerent challenges and a small survey at the end of the
experiment. Preliminary results show that the participants have fun using the
platform and ﬁnd it an adequate means to raise awareness on secure coding best

Cybersecurity Awareness with Virtual Coach and Automated Assessment

15

practices. The developed platform will be made available in the future, after the
internal software clearing process.

In future work, the authors would like to investigate additional factors that
lead software developers to understand better the consequences of exploiting
vulnerable code. Furthermore, the authors would like to investigate additional
means to implement a more robust artiﬁcial engine for the virtual coach through
systematic literature research. Furthermore, in a future publication, the authors
will perform a large-scale comparative study with existing and established cy-
bersecurity teaching methods. Finally, the quality of the virtual coach engine
depends heavily on the quality and number of input sources. In this aspect, the
authors intend to investigate further possible sources and the quality (e.g., false
positive, false negative) of the existing and future input sources.

Acknowledgements

The authors would like to thank the participants of the survey for their time
and their valuable answers. This work is ﬁnanced by portuguese national funds
through FCT - Funda¸c˜ao para a Ciˆencia e Tecnologia, I.P., under the project
FCT UIDB/04466/2020. Furthermore, the third author thanks the Instituto
Universit´ario de Lisboa and ISTAR-IUL, for their support.

References

1. Brisson, A., Pereira, G., Prada, R., Paiva, A., Louchart, S., Suttie, N., Lim, T.,
Lopes, R.A., Bidarra, R., Bellotti, F., et al.: Artiﬁcial intelligence and personaliza-
tion opportunities for serious games. In: Eighth Artiﬁcial Intelligence and Interac-
tive Digital Entertainment Conference. pp. 51–57 (Oct 2012)

2. Davis, A., Leek, T., Zhivich, M., Gwinnup, K., Leonard, W.: The Fun and Future
of CTF. 2014 USENIX Summit on Gaming, Games, and Gamiﬁcation in Secu-
rity Education (3GSE 14) pp. 1–9 (2014), https://www.usenix.org/conference/
3gse14/summit-program/presentation/davis

3. Dobrovsky, A., Borghoﬀ, U.M., Hofmann, M.: An approach to interactive deep re-
inforcement learning for serious games. In: 2016 7th IEEE International Conference
on Cognitive Infocommunications (CogInfoCom). pp. 85–90. IEEE (2016)

4. D¨orner, R., G¨obel, S., Eﬀelsberg, W., Wiemeyer, J.: Serious Games: Founda-
tions, Concepts and Practice. Springer International Publishing, 1 edn. (2016).
https://doi.org/10.1007/978-3-319-40612-1

5. Frey, S., Rashid, A., Anthonysamy, P., Pinto-Albuquerque, M., Naqvi, S.A.: The
Good, the Bad and the Ugly: A Study of Security Decisions in a Cyber-Physical
Systems Game. IEEE Transactions on Software Engineering 45(5), 521–536 (2019)
6. Gasiba, T., Beckers, K., Suppan, S., Rezabek, F.: On the Requirements for Seri-
ous Games geared towards Software Developers in the Industry. In: Damian, D.E.,
Perini, A., Lee, S. (eds.) 27th IEEE International Requirements Engineering Con-
ference, RE 2019, Jeju Island, Korea (South), September 23-27, 2019. IEEE (2019),
https://ieeexplore.ieee.org/xpl/conhome/8910334/proceeding

16

T. Gasiba et al.

7. Gasiba, T., Lechner, U., Cuellar, J., Zouitni, A.: Ranking Secure Coding Guidelines
for Software Developer Awareness Training in the Industry (Jun 2020), Accepted
for Publication

8. Gasiba, T., Lechner, U., Pinto-Albuquerque, M., Zouitni, A.: Design of Secure Cod-
ing Challenges for Cybersecurity Education in the Industry (Sep 2020), Accepted
for Publication

9. Graziotin, D., Fagerholm, F., Wang, X., Abrahamsson, P.: What happens when
software developers are (un)happy. Journal of Systems and Software 140, 32–47
(Jun 2018)

10. Groves, R.M., Fowler, F., Couper, M., Lepkowski, J., Singer, E.: Survey Method-

ology. John Wiley & Sons, 2 edn. (2009)

11. H¨ansch, N., Benenson, Z.: Specifying IT security awareness. In: 25th International
Workshop on Database and Expert Systems Applications, Munich, Germany. pp.
326–330 (Sep 2014). https://doi.org/10.1109/DEXA.2014.71

12. IEC 62443-4-1: Security for industrial automation and control systems - part 4-1:
Secure product development lifecycle requirements. Standard, International Elec-
trotechnical Commission (Jan 2018)

13. ISO 27001: Information technology – Security techniques – Information security
management systems – Requirements. Standard, International Standard Organi-
zation, Geneva, CH (Oct 2013)

14. Patel, S.: 2019 Global Developer Report: DevSecOps ﬁnds security road-
blocks divide teams (July 2020), https://about.gitlab.com/blog/2019/07/15/
global-developer-report/, [Online; posted on July 15, 2019]

15. Rieb, A.: IT-Sicherheit: Cyberabwehr mit hohem Spaßfaktor. In: kma - Das

Gesundheitswirtschaftsmagazin. vol. 23, pp. 66–69 (Jul 2018)

16. Rieb, A., Gurschler, T., Lechner, U.: A gamiﬁed approach to explore techniques of
neutralization of threat actors in cybercrime. In: GDPR & ePrivacy: APF 2017 -
Proceedings of the 5th ENISA Annual Privacy Forum. pp. 87–103. Lecture Notes
in Computer Science, Springer Verlag (Jun 2017)

17. Rietz, T., Maedche, A.: LadderBot: A Requirements Self-Elicitation System. In:
2019 IEEE 27th International Requirements Engineering Conference (RE). pp.
357–362. IEEE (2019)

18. Schneier, B.: Software Developers and Security (July 2020), https://www.

schneier.com/blog/archives/2019/07/software_develo.html, Online

19. Siemens AG: Charter of Trust (July 2020), https://www.charteroftrust.com/,

Online

20. Sim˜oes, A., Queir´os, R.: On the Nature of Programming Exercises. In: ICPEC
- First International Computer Programming Education Conference. vol. 81, pp.
251–259. Virtual Conference (Jun 2020)

21. Vasconcelos, P., Ribeiro, R.P.: Using Property-Based Testing to Generate Feedback
for C Programming Exercises. In: ICPEC - First International Computer Program-
ming Education Conference. vol. 81, pp. 285–294. Virtual Conference (Jun 2020)
22. Votipka, D., Mazurek, M.L., Hu, H., Eastes, B.: Toward a Field Study on the
Impact of Hacking Competitions on Secure Development. In: Workshop on Security
Information Workers (WSIW). Marriott Waterfront - Baltimore, MD, USA (Aug
2018)

23. WhiteSource: What

guages?
most-secure-programming-languages/

(Mar

are
2019),

the Most

Lan-
https://www.whitesourcesoftware.com/

Programming

Secure

