Deep Down the Rabbit Hole:
On References in Networks of Decoy Elements

Daniel Reti, Daniel Fraunholz, Janis Zemitis, Daniel Schneider and Hans Dieter Schotten

Intelligent Networks Research Group
German Research Center for Artiﬁcial Intelligence
67655 Kaiserslautern, Germany
Email: {ﬁrstname}.{lastname}@dfki.de

1
2
0
2

r
p
A
8

]

R
C
.
s
c
[

1
v
1
3
6
3
0
.
4
0
1
2
:
v
i
X
r
a

Abstract—Deception technology has proven to be a sound
approach against threats to information systems. Aside from
well-established honeypots, decoy elements, also known as
honeytokens, are an excellent method to address various
types of threats. Decoy elements are causing distraction
and uncertainty to an attacker and help detecting malicious
activity. Deception is meant to be complementing ﬁrewalls
and intrusion detection systems. Particularly insider threats
may be mitigated with deception methods. While current
approaches consider the use of multiple decoy elements as
well as context-sensitivity, they do not sufﬁciently describe a
relationship between individual elements. In this work, inter-
referencing decoy elements are introduced as a plausible
extension to existing deception frameworks, leading attackers
along a path of decoy elements. A theoretical foundation is
introduced, as well as a stochastic model and a reference
implementation. It was found that the proposed system is
suitable to enhance current decoy frameworks by adding
a further dimension of inter-connectivity and therefore im-
prove intrusion detection and prevention.

Index Terms—information security, network security, cy-
berdeception, honeytokens, decoy elements

1. Introduction

The widely adopted perimeter-based and signature-
based defense strategies in network security have a passive
nature of preventing and detecting unauthorized resource
access. While network ﬁrewalls and Intrusion Detection
Systems (IDS) are theoretically quite capable of effec-
tively preventing a compromise, in reality, sophisticated
and persistent attackers often manage to ﬁnd previously
unconsidered attack vectors. These might be, but are not
limited to social engineering, weak credentials or the
misconﬁguration of defense measures. Strongly depending
on the network’s security plan, an attacker who manages
to gain network access is hard to detain and will likely
cause disastrous consequences. A similar risk is posed by
a malicious insider with legitimate network access and
the capabilities seeing and accessing other hosts in the
network.

While many defense-in-depth strategies are capable of
mitigating insider threats, this work applies the strategy
of deception technology, which is most commonly known
for honeypots but also encompasses other types of fake

entities. In contrast to conventional security measures, de-
ception has a more active nature regarding the interaction
with attackers, aiming to distract an attacker away from
real targets towards decoy targets. Decoy elements, also
referred to as honeytokens or honeytraps, proposed in pre-
vious research include leaking fake accounts, credentials,
documents, executables or database entries [1].

The novel approach of this work is to let different
types of decoy elements have references to other de-
coy elements with the goal of forming a well-deﬁned
network of inter-referencing decoy elements, leading the
attacker along a speciﬁc path towards a honeypot or a less
critical network segment, while exhausting the attackers
time and resources. Such a network of referencing decoy
elements is also useful to detect perimeter breaches and
trigger adequate containment measures and thus reduce
the probability of successful privilege escalation or lateral
movement.

In recent research, frameworks for the deployment of
such elements were proposed. These frameworks partic-
ularly cope with the challenge of context-sensitivity for
the deployment of decoy elements [1]. However, to the
best of the authors’ knowledge, no previous research was
conducted on networks that consist of decoy elements
referencing further decoy elements. In this work the au-
thors provide the theoretical foundation for a generation
framework for inter-referencing decoy element networks
as well as a qualitative evaluation of the proposed frame-
work and reference-implementation. This work is struc-
tured as follows: In section 2, the theoretical background
of deception and decoys as well as the state of the art
is introduced. After that, the proposed system of graph
computation and transition probabilities is described in
section 3. Subsequently, the reference implementation is
presented in section 4. In section 5, an evaluation of the
proposed system is given. A conclusion is given in section
6.

2. Background

In this section the fundamentals of deception technol-
ogy are presented and for a proper problem statement and
evaluation the applied attacker model is introduced.

 
 
 
 
 
 
2.1. Deception Technology

Deception offers a diverse set of methods for infor-
mation security. Although deception is typically targeting
human adversaries, software can be deceived as well.
Web application fuzzers as an example rely strongly on
feedback in form of status codes, version information
and banners which can easily be manipulated without
a degradation in usability [1]–[3]. A typical objective
is to increase the interaction between an intruder and a
deception system and thus exhaust resources, such as time
or computational power, and expose tactics, techniques
and procedures (TTPs). The most common taxonomy
for deception, as proposed by [4], distinguishes between
simulation and dissimulation. Simulation-based deception
is deﬁned by presenting something that does not exist, uti-
lizing the strategies of mimicking, inventing and decoying.
A well-known application of simulation-based deception
is the use of honeypots and honeynets. The decoy elements
used in this work are all simulation-based deception meth-
ods. Dissimulation-based methods aim to conceal the truth
by masking, repacking and dazzling. Commonly known
dissimulation-based deception techniques are obfuscation
and moving target defense.

2.2. Attacker Model and Problem Statement

This work is approaching an attacker who has gained
access to the network in which the proposed system is
operating. Typical scenarios are a malicious insider or a
pivoting attacker. Although the system could be conﬁg-
ured to be applicable for a perimeter system, this is not
the focus of this work. The attacker performs reconnais-
sance and enumerates hosts and services on the network
before and attack is chosen, therefore attack vectors of
an attacker in such a position are strongly dependent on
the system’s information. Gathered system information
are typically used to identify user accounts, other hosts
in the network, unprotected services or further potential
attack vectors. Therefore, the proposed system is aware
of common information sources of interest for attackers,
where it presents false information, increasing the com-
plexity for an attacker to identify relevant information
and furthermore guiding an attacker on wrong tracks of
misleading information.

2.3. Decoy Elements

While the concept of decoy elements is nothing new,
the term honeytoken as a reference to honeypots was only
coined in 2003 by DeBarros [5], since then it was imple-
mented in various shapes and environments. The usage
of decoy elements is limited rather by imagination than
by technical restrictions. Any type of information may be
applicable as a decoy element. Previous studies present an
overview of common decoy elements [1], [6]. In this work,
a set Ω of 10 decoy element types is considered for further
analysis. While no novel decoy types are introduced in
this work, a classiﬁcation is proposed in order to describe
properties that are introduced with inter connectivity of
decoy elements. First, decoy elements may be accessed
from different kinds of proximity. A suitable classiﬁcation
was adapted from the Common Vulnerability Scoring

System (CVSS) [7]. The groups are: Physical (A1), local
(A2), adjacent (A3) and network (A4). Second, each type
has a set of features describing essential properties during
deployment and operation.

(a)

Self-referenceable (P1): Property of the decoy ele-
ment to be able to reference to a decoy element of
its own type. This feature is important for the gen-
eration of the reference network. If this property is
not given, the decoy type cannot be subsequent to
a decoy of the same type. An example for non-self-
referenceable is an ARP-cache entry. Such entries
can only reference to IP- and hardware addresses
but not to further cache entries.

(b) Observable (P2): Several decoy types cannot be
directly observed during operation. This property
depends on the given scenario, as a particular
type can be observable in one scenario but not in
another. An example is a DB-entry, which may be
non-observable if a MySQL-client with encrypted
communication is used, but is observable if the
communication is unencrypted, as the queries can
be monitored with tools such as wireshark or
tcpdump.

(c) Runtime revisions (P3): An important property in
dynamic deployment environment is the ability of
a decoy element to be revised during runtime.
For this property, plausibility must be taken into
account, since from a technical perspective most
decoy types may be revised during operation.
However, for types with a dynamic nature, such as
the caches, this property is more likely and thus
more believable.
Post-deployment revisions (P4): This property is
related to the previous one, but has the requirement
of being able to be revised after the deployment
and operation, but not during operation.
Privileged (P5): Several decoy types are only ac-
cessible by privileged users. An example of such a
decoy type is the ARP-cache and the shadow ﬁle
[8].

(e)

(d)

(f) Multi-domain (P6): A decoy element can be con-
ﬁgured to be accessed by either one or multiple
entities, depending on the reading permissions. In
the presented work, a domain is implemented as a
user or group that is able to access a particular
resource. This property describes the ability to
be accessible by more than one particular user
without administrative privileges. Typically user
logs are only readable by the user itself or adminis-
trators and would therefore not fulﬁll this property.
(P7): This property describes
whether a decoy element type might be deployed
more then once on a system. An operating system
usually only has one host ﬁle, thus the host ﬁle
as a decoy element does not have this property,
while one host ﬁle may contain multiple entries
as references to other decoy elements.

(g) Multi-instance

Third, each decoy type has a particular set of decoy
elements it can reference to. For example, a document
may reference to most other decoy types, whereas a host
ﬁle is only able to reference to domains and IP addresses.
This kind of limitation must be taken into account when

generating the decoy networks. An exemplary, incomplete
set of decoy types considered in this work is given in
table 1 and described in the following. The selection of
decoy element types is based on information the authors
expect to be of interest for an attacker.

(a) Comment

(D1): Comments may contain any
kind of information and are commonly found in
source code or conﬁguration ﬁles. In contrast to
documents-type decoys, comment-type decoys are
not part of the ﬁle’s content, but rather a remark
to the content and thus not interfering with regular
usage or functionality. This type of decoy can
reference most other decoy types, since comments
are ﬂexible in their content. When comments are
deployed into existing content, context-sensitivity
is required. This can be achieved by using either
generic comments or content analysis, e.g. with
NLP methods [16].

(b) DB-entry (D2): Entries in a DB are similarly
ﬂexible as comments and require the same consid-
erations regarding their deployment. Furthermore,
it must be taken into account that remote access
to a DB is rather usual. It is also important to
consider the observability. Monitoring access to a
DB ﬁle is less complex than access to a particular
table, which itself is less complex than monitoring
access to a particular decoy entry. The later ones
are not observable based on ﬁle access, instead log
monitoring or network snifﬁng may be applied to
monitor access [11].

(c) ARP cache (D3): In contrast to the former de-
coy types, the ARP cache has a limited set of
information it can provide. The most conclusive
information from an attacker’s perspective may
be the IP and MAC address contained in an en-
try. This decoy type can be used to reference
network addresses, which can be located on the
local or a remote system. As stated in table 1,
administrative privileges are required to directly
access information in the ARP cache. This has
the disadvantage of a decreased probability of
detecting unprivileged attackers, but also provides
the insight that usage of the deployed information
must be the consequence of a full system compro-
mise. However, monitoring the ARP cache based
on ﬁle access is not possible, as the cache ﬁle is
frequently accessed for legitimate reasons.
(d) Account (D4): Accounts can be used as versatile
decoy elements. They can be referenced in various
contexts and often do not require more informa-
tion than a user name. In cases where authenti-
cation software can be manipulated (e.g. PAM in
Unix), authentication attempts into accounts may
be simple to monitor. Furthermore, they frequently
provide complete sets of ﬁles, directories or even
environments to the logged-in entity, thus enabling
a broad range of further deception. As account and
password management is still a ongoing challenge
in information security, references to accounts,
including credentials, may be not susceptible.
(e) History (D5): Several types of software create and
store history information. In this work, history

ﬁles used for optimized user experience (browser
history) and convenience (shell history) are taken
into account. History ﬁles used for traceability and
accountability such as log ﬁles are not considered,
even though they are applicable as decoy elements.
(f) Document contents (D6): Documents are the best–
known types of decoy elements. Document con-
tents can contain any type of information. They
are observable by means of ﬁle-access monitoring,
and more ﬂexible than comments and DB-entries,
but have the downside of interfering with usage
and might be mistakenly found by legitimate users.
Typically, the most effort for this decoy type is
devoted to contextual adaptation [16], which is not
part of this work.
File metadata (D7): Information that is not part
of the content
itself is frequently of sensitive
nature as well. In this work, no aggregation or
inference of sensitive information is considered.
However, ﬁle names often leak information about
ﬁle content or even about further ﬁles or directory
structures. Further metadata, such as time stamps,
ﬁle owner or groups may reveal information, e.g.
the existence of user accounts or working hours
of particular users.

(g)

(h) Uniform Resource Locator (D8): Given the deﬁni-
tion in RFC 3986 section 3, a Uniform Resource
Locator (URL) follows the syntax:

URL = scheme :
[//authority]path[?query][#f
ragment],
where an authority consists of the following
parts:
authority = [userinfo@]host[:port.

This syntax can be exploited to deploy decoy
elements of various types within a URL. Several
components are directly indicating a suitable de-
coy type such as: Path, userinfo, host and port.
However, the query and fragment component can
be used to reference any other decoy type. A
query component typically consists of a parameter
and value that can be chosen arbitrarily, while the
fragment component refers to a section within a
resource, which can also be chosen arbitrarily.
(i) Host ﬁle (D9): Similar to the ARP cache, a host
ﬁle is limited in the kind on information it pro-
vides and the ability to monitor access. The major
difference to the ARP cache is that instead of a
MAC address, a domain is stored. Host ﬁles may
contain comments, but they are not considered in
this work.
Port (D10): Most TCP ports are associated with
information about
particular services. However,
a service may also be obtained by connecting
to an open port, where services may transfer a
protocol speciﬁc message, containing protocol or
service name and version information, followed
by a message. Plausible messages are redirects
to other hosts or ports as well as error messages
referring to a contact which could be an email
address.

(j)

TABLE 1. PROPERTIES OF POTENTIAL DECOY ELEMENTS

Meta information

Name

Abbrev.

Access type

Properties
Outbound connections

P1

P2

P3

P4

P5

P6

P7

D1
Comment [2]
D2
DB-entry [2], [6], [9]–[11]
D3
ARP-cache [8]
D4
Account [2], [12], [13]
D5
History [8]
Document [2], [6], [8], [14] D6
D7
File-Metadata [15]
D8
URL/Link [2], [8]
D9
Host ﬁle
D10
Port [2], [8]

A2, A3, A4 D1-D10
A2, A3, A4 D2-D4, D6, D8-D10
D8, D10
A2
A2, A3, A4 D1-D10
D1-D10
A2
A2, A3, A4 D1-D10
A2, A3, A4 D2, D4, D6, D8
A3, A4
A2
A3, A4

D4, D6, D10
D4, D8, D10
D4, D8, D10

(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:55) (cid:13) (cid:55)
(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:51) (cid:13)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:55) (cid:13)
(cid:55)
(cid:51)
(cid:51) (cid:13) (cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:51) (cid:13)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51) (cid:13) (cid:13)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:51)
(cid:51)
(cid:51)

An extensive overview of further decoy types is given by
[1] and [6]. The terminology is discussed by [17].

Figure 1. Examples of valid graphs, based on the networkx implemen-
tation of the named models, each with 10 nodes, Erd˝os-R´enyi with
p = 0.15, random k-out with k = 1.

3. The Rabbit Hole

In this section, the framework for the generation and
operation of inter-referencing decoy networks is intro-
duced. First, the computation of the network topology
is discussed. Then, the probabilistic model to determine
the network population and the references is deﬁned. The
introduced framework is also able to generate references
at runtime, which is discussed at the end of this section.

3.1. Computation of Directed Graphs

A reference has a directional property. Therefore, the
network generated has to be directional at initialization
as well. The network is represented as a graph, where a
decoy element is a node and a reference is a directed edge.
The directed graph is generated by a graphical model.
As there are several models and assigned properties, the
requirements of the network must be deﬁned in advance,
in order to select a model accordingly.

(a) Directed edges: As previously discussed, a refer-
ence is information at a particular location, point-
ing to another particular location. From this deﬁ-
nition, it can be concluded that edges need to be
directional.

(b) Reciprocal edges: It is not required that the re-
ferred location contains information referring back
to the previous location. Like other references,
reciprocal references increase the probability to
lure a trespasser into the decoy network.

(c) Acyclic property: This property may affect subse-
quent processing steps and needs to be considered,
e.g. when traversing the graph with a depth-ﬁrst
search, there is no restriction from a information
security perspective. In particular, loops with sev-
eral nodes may mislead a trespasser into more
interaction.

(d) Connectivity: It is not required that there is a
particular k-connectivity, neither for nodes nor
for edges. However, the improvement proposed
in this work is the concept of references, which

are supposed to drag a trespasser into the decoy
network and keep the trespasser engaged with
reconnaissance activities. Therefore, in this work,
connectivity is assumed to be required for the
generated graph.

(e) Adjacency: The number of in- and outbound ref-
erences for each decoy is dependent on the decoy
type itself. However, as discussed in detail later on,
a trespasser may not be able to follow a particular
reference for lack of knowledge or permission. It
is therefore considered more effective to ensure a
equal distribution of in- and outbound references.

Given these identiﬁed restrictions, there is still ﬂex-
ibility for the generation of graphs. Figure 1 gives four
examples of valid graphs from four different graphical
models.

As it can be seen, the selection of a graph model re-
mains subject to the implementation. For the reference im-
plementation, the Erd˝os-R´enyi model in the G(n, p) vari-
ant [18] is used to generate random graphs, satisfying the
discussed properties. However, there are further models
such as Barab´asi-Albert and Watts-Strogatz that may be
used instead. Different models can be randomly selected
during initialization or mixed. Further evaluation on the
correlation of network generation models and deception

Erdos-Renyi modelGrowing networkScale-free graphRandom k-out modelsuccess is required. As discussed before, connected graphs
are preferred to unconnected graphs. This can be achieved,
for example, by selecting only the largest subgraph, either
in terms of edges or nodes. Alternatively, the subgraphs
may be connected.

3.2. Probabilistic Model for Decoy Types

A time-homogeneous discrete-time Markov chain
(DTMC) was chosen to represent the model for the gen-
eration of decoy type sequences. This model determines
subsequent decoy types to a given decoy type. The prob-
ability pij of decoy type j to be deployed subsequently
to decoy type i is deﬁned in eq. (1).

pij = P r(Xt−1 = i|Xt = j) for i, j ∈ Ω

(1)

pij represents the forward transition probability within
the model. However, due to the directed characteristic of
the generated graphs, it may be necessary to traverse an
edge backwards, in order to identify precedent referencing
nodes. The probability of a backward transition is given
in eq. (2).

πipij = πjpji

(2)

The necessary and sufﬁcient condition for eq. (2) is

Kolmogorov’s criterion [19] as given in eq. (3).

3.3. Computation Efﬁcient Probability

During the operational phase, the probability for sub-
sequent decoy elements can be adapted to the observed
activity. As attackers are more likely to follow references
that they have knowledge of and that appear useful, the
system can be optimized by increasing the likelihood
for transitions that are observed, while decreasing the
likelihood for transitions that are ignored. This learning
model assumes that the behavior of multiple attackers is
not completely unrelated. Therefore, if it were completely
unrelated, an adaption to the behavior would not be possi-
ble. There are two requirements to be met when designing
the learning functionality:

(a) The sum of each row in P must be 1. Therefore an
increase in a particular transition probability must
result in a decrease of the same magnitude. The
decrease can be split between multiple transition
probabilities.
pij must be ensured to be in the range 0 ≤ pij ≤ 1.

(b)

Optionally, the probability adaption ∆pij can be dy-
namically adjusted to the current transition probability pij.
This property increases the resiliency against overﬁtting.
Following the design decision not to differentiate between
the set of actually available outbound references and the
potential set of outbound references as given in table 1,
a computational efﬁcient learning method is deﬁned in
eq. (7) and eq. (8).

pt+1
F = pt

F + η(1 − pt

F )

(7)

(8)

pi1i2pi2i3 ...pin−1in pini1 = pji∀i1, i2...in ∈ Ω (3)

pt+1
A = pt

A(1 − η)

Kolmogorov’s criterion requires that the product of
probabilities on each closed loop must be equal in both
directions. If the criterion is satisﬁed, P ∗ = P . If it is not
reversible, P ∗ can be computed from P by employing
Bayes law as given in eq. (4).

p∗
ij = P r(Xt−1 = j|Xt = i)

P (Xt = Ej)
P (Xt−1 = Ei)

(4)

P (E) is the stationary distribution ϕT . This distribu-
tion is uniform if P is symmetric. It can be determined
as given in eq. (5) and eq. (6).

lim
N→∞

pN =







ϕ1 ϕ2
ϕ1 ϕ2
...
...
ϕ1 ϕ2







... ϕΩ
... ϕΩ
...
... ϕΩ

ϕT = (ϕ1, ϕ2, ..., ϕΩ)

(5)

(6)

ϕT is also used as probabilities for the decoy type of
the entry node. In doing so, it is ensured to start in the
stationary phase of the DTMC. It additionally provides the
expected distribution of decoy elements of each type, it
can therefore be used to analyze and tweak the distribution
of decoy types while conﬁguring the model.

pt
F is the transition probability of the reference fol-
lowed at the time t and pt
A the transition probability of
references that are not followed at the time t. η is the
learning rate, used to parametrize the impact observations
have on the transition probability. In this learning method,
a uniformly distributed split of the aforementioned de-
crease between the ignored references is implemented.

The fulﬁllment of the ﬁrst requirement can be proven
as shown in eq. (9), stating that positive deltas on the left
side are always the same as the sum of all negative deltas
on the right side for all numbers of ignored references.

η(1 − pt

F ) =

(cid:88)

Ω

ηpt

A∀|Ω| ∈ N

(9)

To prove the second requirement the relevant limits

are determined as shown in eq. (10).

(cid:40)

∆pij =

η(1 − pij)
−ηpij

if followed
if ignored

(10)

There are two identiﬁed limits that can be used to
prove the fulﬁllment of the second requirement as given
in eq. (11) and eq. (12).

lim
pij→1

η(1 − pij) = 0

lim
pij→0

−ηpij = 0

(11)

(12)

In ﬁg. 2, an example is visualized for the learning
mode. For the sake of clarity, a set of only two potential
outbound references is considered. The example shows
the transition probabilities and their deltas in respect to
the observations made.

On the top, the probabilities for the references are 0.85
(orange) and 0.15 (blue) with a learning rate η of 0.3. On
the left side, the probability to observe activity on the blue
reference is set to 1, while it is 0 for the orange reference.
As proven before,
the probabilities asymptotically ap-
proach the limit values derived from the requirements. Ad-
ditionally, the satisfaction of the optional third requirement
is visualized by the dashed lines. If the probabilities are
more close to the limit values, the changes are decreasing
dynamically. On the top right side, the initialization values
for the probabilities are equal to the previous example as
well as the learning rate. However, in this example, the
probability to observe activity on the blue reference is set
to 0.5, while it is also 0.5 for the orange reference. As
it can be seen, the probabilities do not converge. This is
because a learning rate of 0.3 is too high for the number
of observations. The learning rate must be adapted to the
expected number of observations. In the example on the
bottom, a learning rate of 0.01 was chosen, while the
initialization values for the probabilities are equal to the
previous examples. In order to illustrate the effect of low
learning rates, the number of observation was increased
to 200. The probability to observe activity on the blue
reference is set to 0.5, while it is also 0.5 for the orange
reference. As it can be seen, the reference probabilities
are approaching the observation probabilities. However,
learning rates in this magnitude require a large number of
observations, which cannot be expected to occur within
the security perimeter.

4. Implementation

The reference implementation is developed for Unix-
based operating systems. Therefore, some decoy types
may not be applicable for other environments. Even
though the program is written in Python 3.5 which is plat-
form independent, operating in other environments may
require to employ an alternative solution for ﬁle access
monitoring and decoy deployment. Several monitoring so-
lutions for MS-Windows exist, such as FileSystemWatcher,
FindFirstChangeNotiﬁcation or inotify-win, an inotify port
to MS-Windows. fsevents may be applicable for OSX envi-
ronments. SQLlite is used to store and manage information
about the deployed decoys. Figure 3 gives an overview of
the program ﬂow.

4.1. Selection of Decoy Elements

For the reference implementation, the following six

decoy types have been selected:

(a) Comment (D1): In the reference implementation,
the decoy type comment is interpreted as informa-
tion embedded in a source code ﬁle.

(b) DB-entry (D2): In this work, DB-entries are stored
locally in a SQLite. Depending on the applica-
tion, a full database management system (DBMS)

might be more plausible and could be imple-
mented as well.

(c) Account (D4): For this decoy type a OS user
account is created. A reference corresponding to
an account is implemented as a hint for an account
name and the password. If no password is pro-
vided, the password is set to be the account name.
This requires an attacker to try basic password
guessing attacks in order to follow the reference.
Once authenticated successfully, the subsequent
references are implemented implicitly by placing
the referenced ﬁles inside the home directory of
the account. This requires the domain of refer-
enced decoys to be the account. Any transition
to a decoy of type D4 results in the creation of
a new user account, which will be available as a
new domain for subsequently deployed decoys.

(e)

(d) Document (D6): Document decoys consist of text
ﬁle with no content other than the subsequent
reference itself in the reference implementation.
File-metadata (D7): Only the ﬁle name itself is
used as metadata. The name of a ﬁle contains
the reference to the subsequent decoy. This type
is more complex to observe, as the reference
information can be retrieved from the preceding
reference and without ﬁle access. To mitigate this,
the decoy is placed inside a dedicated directory,
to which the preceding reference refers. Access to
this directory is then monitored.

(f) Uniform Resource Locator (D8): This decoy type
differs from document and comment type decoys
by the type of access. It can be accessed via
a web browser and requires to be pointing to
a ﬁle in the directory of an HTTP server. The
provided resource is an HTML document, contain-
ing a redirect to a non-existing resource. How-
ever, the information sources implemented are the
GET-parameters within the redirect. As described
above, these parameters consist of a name and a
value, thus being able to provide various decoy
references.

The transition probabilities set in the reference imple-
mentation are given in table 2. Values are chosen based on
the authors’ knowledge of the system and may be subject
to adaption and optimization.

TABLE 2. TRANSITION MATRIX P FOR A SELECTION OF DECOY
ELEMENTS

Potential outbound decoy type

D1

D2

0.15

0.15

0

0.25

0.2

0

0

0.3

0.25

0.25

0.2

0

D4

0.1

0.1

0

0.05

0.3

0.2

D6

D7

0.25

0.15

0.3

0.25

0.15

0.2

0.8

0

0.25

0.15

0

0

D8

0.2

0.3

0

0.2

0.3

0

e
p
y
t

y
o
c
e
D

D1

D2

D4

D6

D7

D8

As a result, a total of 26 possible transition are imple-

mented.

Figure 2. Example visualization for learning mode, two possible outbound references (orange, blue), reference probability (solid), delta probability
(dashed), same reference (left), uniform reference choice (right, down), learning rate η = 0.3 (up), learning rate η = 0.01 (down)

Figure 3. Overview of the program ﬂow with focus on the supported
operational modes and their differences. Chart is created in compliance
with SDL.

element. The subsequent elements then become decoy
elements, containing references themselves.

For each deployed and monitored element, the DB-
entry contains information if access to the decoy element
has been observed, to prevent more than one creation of
references for the same subsequent decoys.

4.2.2. Operation Modes.

(a) Graphical: (1) In graphical mode, a generator
based on a graphical model is used to create a di-
rected network. Nodes represent decoys and edges
represent references from a decoy to another. (2)
Then, an initial node is chosen randomly, where

.

the probability p for a node n ∈ N is p =

1
|N |
Afterwards, the decoy type and the domain are
determined for the initial node by a similar proce-
dure. (3) The network is traversed by an iterative
deepening depth-ﬁrst search (IDDFS), where for
each transition, the type of the subsequent decoy
is determined based on the transition probability
matrix P. IDDFS is chosen because it provides
a reasonable trade-off between the speed of a
depth-ﬁrst search (DFS) and the completeness of
a breadth-ﬁrst search (BFS). If the networks are
small and memory is not the primary concern, BFS
may also provide reasonable results. DFS is not
suitable, as it does not guarantee to traverse each
node within the network. (4) After the search is
completed the decoy reference network is ready
for deployment. This mode requires the graph to
be connected. If the underlying model does not
guarantee the graph to be connected, this property
can be ensured as proposed earlier. An overview
of the graphical mode is given in ﬁg. 4, where the
decoy type is represented by the node color.
Inﬁnite: (1) In inﬁnite mode, one single decoy
is initially deployed and monitored. This decoy
contains references to a particular number of sub-
sequent decoys. The referenced decoys are not
monitored, and do not contain further references.
(2) If an access to the initially deployed and moni-
tored decoy is observed, the decoys referenced by
it are assigned to a particular number of subse-

4.2. Digging the Hole: Decoy Deployment

The deployment process can be split up into different
phases, which are elaborated on in the following section.
After that, the three implemented operational modes are
introduced and discussed with visual examples.

4.2.1. Generation and management. When new decoy
elements need to be deployed, the proposed system will
execute four steps: First, based on the decoy element
type containing the reference, the subsequent decoy type
is determined. The employed probability distribution is
shown in table 2. Additionally, in this step the number
of outbound references is determined, if necessary. This
is the case in inﬁnite and hybrid mode. Second,
the
referenced decoy elements are created. Those elements
are created as speciﬁed in the implementation discussed
above. However, they are also stored as an entry in the
management database. In this step, these referenced decoy
elements are also indicated as subsequent to the containing
decoy element in the management database. Third, the
actual reference to the previously created decoy elements
are generated and deployed into the containing decoy
element. Last, the containing reference will be added to
the inotify watch list. If access to this decoy element is
observed, this process is repeated for each subsequent

(b)

02468100.00.51.0Reference probability (solid)0.20.00.202468100.250.500.750.20.00.2Delta probability (dashed)0255075100125150175200Number of observations0.250.500.75                ModeStartGenerate graphDeploy decoysMonitor graphGenerate new decoy elementStore decoy informationMode  InfiniteMonitor modeIncident responseDecoy access detectedMode  GraphicalFinishedNoYesYesNoNoYesquent decoys. As in the step before, these refer-
enced decoys do not contain references. However,
the decoys referenced by the initial decoy, now
contain the references to their subsequent decoys.
(3,4) This procedure can be repeated inﬁnite times,
generating a deep tree structure of decoys and
references. An overview of this process is given
in ﬁg. 5, where the decoy type is represented by
the node color.
In contrast to the graphical mode, there is only
one inbound edge per node. From a conceptional
perspective, a new reference can be set to refer
to a previous decoy element. In this case,
the
management database needs to be queried to de-
termine all deployed and monitored decoys. From
this set of active decoys a number of decoys can
be chosen. The inﬁnite mode ensures connectivity
of the iteratively generated graph by design. If
non-observable (¬P 2) decoy types are used in this
mode, they must be considered as accessed and the
subsequent decoys have to be deployed. This must
be repeated until only decoy types satisfying P 2
are the latest deployed type within a branch.
(c) Graphical-inﬁnite (hybrid): Both presented modes
have inherent disadvantages. The graphical mode
has a limited number of decoys and those decoys
have been deployed without knowledge about the
attacker. The inﬁnite mode has only one initial
entry node, while the number of decoys is related
to the probability of an attacker triggering it. To
mitigate these disadvantages, both modes can be
combined into the graphical-inﬁnite mode, where
the initialization phase is based on the graphical
mode and the operational phase (monitor and de-
ploy) is based on the inﬁnite mode. However, only
decoy types satisfying P 4 can be extended by
further references. ¬P 4 types are considered as
in graphical mode.

5. Evaluation and Analysis

To evaluate the proposed system, three different as-
pects are considered. First, the relationship between at-
tacker and system behavior in the context of the intro-
duced learning mechanism is discussed. Then, security
and performance perspectives on the system are elaborated
separately. An empirical evaluation of the effectiveness of
the concept and it’s different aspects is yet to be done.

5.1. Behavioral Model of Attackers

An attacker can be described by establishing a Markov
model, where PA is a matrix containing the probabilities
of an attacker to follow an existing reference. However, in
contrast to the transition matrix P of the decoy network,
the probabilities are not based on the plausibility of the
reference itself but on the:

(a)

knowledge an attacker has about computer systems
of the type the attacker believes to be interacting
with, as this knowledge may limit the capabilities
of an attacker to follow a certain reference and the

(b)

objective an attacker intents to accomplish on the
system as this affects the likelihood an attacker
follows a reference to a particular decoy type.
For example, an attacker looking for network re-
sources is more likely to follow a network-related
reference.

The implemented learning mode will adapt P to PA
. It will eliminate references an attacker will not follow
and enhance frequently followed references. This behavior
points out the need for a moderate learning rate η to
prevent over-ﬁtting. In the conducted experiments 0.3
was found to be sufﬁcient, however, the rate should be
adapted to the use case. In general, a higher number
of expected observations should result in a lower value
of η. A limitation of this approach is that interaction
with a decoy element is not necessarily initiated by an
intruder. Although deception systems are characterized by
having few to none false-positive results, unintentional
interaction cannot be ruled out and therefore an interaction
with a decoy element, while being a strong indicator for
malicious activity, is not deﬁnitive proof for it. However,
the low false-positive rate should prevent alarm fatigue.

5.2. Security Analysis

As the reference implementation is based on software,
it might contain vulnerabilities. In this subsection, the
system concept instead of the reference implementation
is reviewed from a security perspective. There are two
major aspects that are considered in this analysis: Security
boundaries and evasion. A security boundary is trespassed
if an attacker is able to gain access to information that
is supposed to be inaccessible by the attacker. The most
plausible attack vector is the monitoring daemon. This
daemon is required to be executed in privileged mode and
is unable to drop privileges after initialization. Therefore,
compromising the daemon results in a fully compromised
system. The daemon is only required in the inﬁnite mode
or if intrusion detection is necessary. If this is not the case,
program execution is ﬁnished after the initialization, thus
reducing the time frame for a successful attack.

System evasion is possible, as inotify is not polling the
ﬁle system for performance reasons. Thus, accesses and
modiﬁcation invoked by mmap, msync and munmap are
invisible to the system. Additionally, pseudo-ﬁle systems
like /proc are not monitorable. Both restrictions may be
circumvented when using a different monitoring system.
Intentional boundary trespassing and evasion require an at-
tacker to suspect the system to employ a deception frame-
work. There are various types of detection techniques
to identify deception systems [11], [20]–[28]. However,
several countermeasures may be applied to conceal the
operation.

(a) Decoy meta information: Despite being of de-
ceptive nature, ﬁle meta information may provide
information to an attacker. This can be prevented
by determining suitable metadata based on the
environment. Context-sensitivity is the objective
of previous research work [16], [29]–[31], and not
part of this work.
Process information: An attacker with system ac-
cess may identify suspicious processes running on

(b)

Figure 4. Overview of graphical mode, (1) generating network, (2) determining initial node,(3) traversing network, (4) completing network

Figure 5. Overview of inﬁnite mode, (1) generating initial decoy, (2,3,4) monitoring and deploying decoys

(c)

the system. Countermeasures are closely related
to rootkits, trojans and backdooring techniques.
DLL-injection, for example, can be applied to hide
the process inside another process.
System ﬁles: Besides the decoy elements itself,
the deception framework requires a few ﬁles to be
used. In the reference implementation, a Python
script exists on the system as well as a number of
templates for the decoy generation and a SQLite
database to store information about the deployed
decoy elements. Obfuscation techniques may be
adapted to increase the detection complexity. At
the cost of persistence, the required ﬁles may only
be stored within volatile memory. Even if volatile
memory is not resistant against memory forensics,
it is more complex to investigate and less likely
to raise suspicion.

5.3. Performance Implications

From a memory consumption perspective, the frame-
work can be considered light-weight. The source code
consists of a few thousand lines of Python code, with
less than 200,000 bytes in size. The DB used to store
and manage active decoys is based on SQLite, where
the data stored is given in table 3. SQLite does only
support particular data types and is therefore subject to

unnecessarily large memory consumption. Boolean types
are not available and boolean information needs to be
stored in 1 byte integer values. However, SQLite database
ﬁle headers contain only 100 bytes of information, thus
allowing for fast and memory preserving operation.

Storage formats such as ext3, ext4, HFS+, Brts and
ZFS have a maximum size of a ﬁle name of 255 byte.
However, the path size may extend the ﬁle size. POSIX
requires the maximal path size to be more than 255, but
does not give an upper limit. Linux for example uses 4096
bytes as maximal supported path size. Determining the
size of an occurring path in advance is therefore not suit-
able. In the reference implementation, 100 bytes are used
to store path information. In total, 155 bytes are stored
for each deployed decoy. The default page size of data
stored by SQLite is 4096 bytes, which is enough space
for around 26 decoy elements. So the data base will grow
by 4096 bytes for approximately each 26th decoy element
in the default conﬁguration. As a result, the total memory
consumption of the reference implementation in operation
is less than 250,000 byte, thus rendering the proposed
solution suitable for large-scale deployment as well as
deployment in resource restricted environments. Inotify
consumes system resources as well. Most important are
the watch list and the event queue. The watch list contains
the inode and the mask. It is growing as the number of ﬁles
to monitor is increasing. By default, the maximal number

(1)(2)(3)(4)(1)(2)(3)(4)Name

Identiﬁer

Created

Reference set

Decoy type

Path

Children

Domain

Parents

TABLE 3. STRUCTURE OF THE DATA BASE FOR DECOY MANAGEMENT

Data type

Int

Int

Int

Int

Char

Char

Char

Int

Size

1 byte

1 byte

1 byte

1 byte

100 byte

10 byte

40 byte

1 byte

Usage

Primary key

Monitor state

Children set

File prop.

Locate decoy

Child ID

File perm.

Parent ID

Example

1

True

True

D7

/tmp/doc_384.txt

2,3

user1

1

of watches is limited to 8, 192 watches per instance, while
128 instances per user are allowed. The event queue is
populated based on the watch list. Events exceeding the
maximal number of events are dropped. This number is
deﬁned to be 16,384 by default. In experiments conducted
during this work, inotify was able to monitor 100,000
ﬁles on COTS-hardware without a signiﬁcant reduction
of performance.

6. Conclusion

In this work, the concept and deployment of inter-
referencing decoy elements was introduced. The concept
was developed as a fast deployable, environment agnostic
stand-alone system, whereat the reference implementation
was created for UNIX environments. To the best of the
authors’ knowledge, an interreferential decoy network has
not been addressed in previous research. An advantage
of the proposed solutions are an increase in interaction
between an attacker and the deployed decoy elements,
increasing the probability of inducing the attacker uncer-
tainty, while wasting the attacker’s time and resources. A
disadvantage is the decrease in quality of the observations
as interaction and therefore the threat
intelligence are
affected by the references. The proposed system is able to
enhance the intrusion detection process as well as delaying
and interfering ongoing reconnaissance activities. It will
be extended to include honeypots as endpoint nodes in the
interreferential network. For operational usage a SIEM-
conform API will also be provided.

Acknowledgment

This research was supported by the German Federal
Ministry of Education and Research (BMBF) within the
SCRATCh project under grant number 01IS18062E. The
SCRATCh project is part of the ITEA 3 cluster of the
European research program EUREKA. The responsibility
for this publication lies with the authors.

References

[1] D. Fraunholz, S. Duque Anton, C. Lipps, D. Reti, D. Krohmer,
F. Pohl, M. Tammen, and H. D. Schotten, “Demystifying deception
technology: A survey,” arXiv preprint arXiv:1804.06196, 2018.

[2] D. Fraunholz and H. D. Schotten, “Defending web servers with
feints, distraction and obfuscation,” in 2018 International Con-
ference on Computing, Networking and Communications (ICNC),
March 2018, pp. 21–25.

[3] M. Nawrocki, M. W¨ahlisch, T. Schmidt, C. Keil,

and
J. Sch¨onfelder, “A survey on honeypot software and data analysis,”
Computing Research Repository, 2016.

[4]

J. Bell and B. Whaley, Cheating and Deception. New Brunswick:
Transaction Publishers, 1991.

[5] A. P. de Barros, “DLP and honeytokens,” Security Balance, 2007.

[6] N. Virvillis, B. Vanautgaerden, and O. Serrano, “Changing the
game: The art of deceiving sophisticated attackers,” in International
Conference on Cyber Conﬂict, 2014.

[7]

“Common vulnerability scoring system,” Forum of
Response
and Security Teams, 2018.
https://www.ﬁrst.org/cvss/

Incident
[Online]. Available:

[8] O. Zohar, A. Barbalat, and R. Elhara, “Applying deception mecha-
nisms for detecting sophisticated cyber attacks,” TopSpin Security,
Research Report.

[9] M. Bercovitch, M. Renford, L. Hasson, A. Shabtai, L. Rokach,
and Y. Elovici, “Honeygen: An automated honeytokens generator,”
in Proceedings of 2011 IEEE International Conference on Intelli-
gence and Security Informatics.

IEEE, 2011, pp. 131–136.

[10] M. G. Hoglund and S. M. Bracken, “Inoculator and antibody for
computer security,” U.S. Patent US9 311 482B2, 04 12, 2016.

[11] N. Krawetz, “Anti-honeypot technology,” IEEE Security Privacy,

vol. 2, no. 1, pp. 76–79, Jan 2004.

[12] M. H. Almeshekah, “Using deception to enhance security: A taxon-
omy, model, and novel uses,” Ph.D. dissertation, Purdue University,
Department of Computer Science, 2015.

[13] A. Juels and R. L. Rivest, “Honeywords: Making password-
cracking detectable,” in Proceedings of the 2013 ACM SIGSAC
Conference on Computer &#38; Communications Security, ser.
CCS ’13. New York, NY, USA: ACM, 2013, pp. 145–160.

[14] M. Lazarov, J. Onaolapo, and G. Stringhini, “Honey sheets: What
happens to leaked google spreadsheets?” in 9th Workshop on Cyber
Security Experimentation and Test (CSET 16).
Austin, TX:
USENIX Association, aug 2016.

[15] N. C. Rowe, “Deception in defense of computer systems from cy-
ber attack,” in Cyber Warfare and Cyber Terrorism, L. Janczewski
and A. Colarik, Eds.

IGI Global, 2007, pp. 97–104.

[16] B. Whitham, “Automating the generation of enticing text content
for high-interaction honeyﬁles,” in Proceedings of the 50th Hawaii
International Conference on System Sciences, 2017, pp. 6069–
6078.

[17] F. Pouget, M. Dacier, and H. Debar, “White paper: honeypot,
honeynet, honeytoken: terminological issues,” Rapport technique
EURECOM, vol. 1275, 09 2003.

[18] P. Erd˝os and A. R´enyi, “On the evolution of random graphs,” Pub-
lication of the Mathematical Institute of the Hungarian Academy
of Sciences, vol. 5, no. 1, pp. 17–61, 1960.

[19] F. Kelly, “Reversibility and stochastic networks,” SERBIULA (sis-

tema Librum 2.0), vol. 76, 06 1981.

[20] S. Bahram, X. Jiang, Z. Wang, M. Grace, J. Li, D. Srinivasan,
J. Rhee, and D. Xu, “Dksm: Subverting virtual machine introspec-
tion for fun and proﬁt,” in 2010 29th IEEE symposium on reliable
distributed systems.
IEEE, 2010, pp. 82–91.

[21] J. Corey, “Local honeypot identiﬁcation,” Phrack, vol. Volume

0x0b, Issue 0x3e, Phile# 0x07 of 0x0f, 2004.

[22] ——, “Advanced honey pot

identiﬁcation and exploitation,”
Phrack, vol. Volume 0x0b, Issue 0x3f, Phile# 0x09 of 0x0f, 2005.

[23] R. Dahbul, C. Lim, and J. Purnama, “Enhancing honeypot decep-
tion capability through network service ﬁngerprinting,” in Journal
of Physics: Conference Series, vol. 801, no. 1.
IOP Publishing,
2017, p. 012057.

[24] M. Dornseif, T. Holz, and C. N. Klein, “NoSEBrEaK – attacking
honeynets,” in Proceedings from the Fifth Annual IEEE SMC
Information Assurance Workshop, 2004.
IEEE, 2004, pp. 123–
129.

[25] O. Ferrand, “How to detect the cuckoo sandbox and hardening it?”
in 22th EICAR Annual Conference. EICAR, 2013, pp. 131–148.

[26] T. Holz and F. Raynal, “Detecting honeypots and other suspicious
environments,” in Proceedings from the Sixth Annual IEEE SMC
Information Assurance Workshop, June 2005, pp. 29–36.

[27] A. Morris, “Kippo SSH honeypot detector,” MSF Module,
Rapid7 Vulnerability & Exploit Database, 05 2018. [Online].
Available: https://www.rapid7.com/db/modules/auxiliary/scanner/
ssh/detect kippo

[28] D. Sysman, G. Evron, and I. Sher, “Breaking honeypots for fun

and proﬁt,” Black Hat USA, Las Vegas, NV, USA, 2015.

[29] D. Fraunholz, F. Pohl, and H. D. Schotten, “On the detection
and handling of security incidents and perimeter breaches - a
modular and ﬂexible honeytoken based framework,” in 2018 9th
IFIP International Conference on New Technologies, Mobility and
Security (NTMS), Feb 2018, pp. 1–4.

[30] D. Fraunholz, M. Zimmermann, and H. D. Schotten, “An adaptive
honeypot conﬁguration, deployment and maintenance strategy,” in
2017 19th International Conference on Advanced Communication
Technology (ICACT), Feb 2017, pp. 53–57.

[31] ——, “Towards Deployment Strategies for Deception Systems Un-
supervised Machine Learn- ing,” Advances in Science, Technology
and Engineering Systems Journal, vol. 2, no. 3, pp. 1272–1279,
2017.

