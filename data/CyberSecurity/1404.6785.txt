Characterizing the Power of Moving Target Defense via
Cyber Epidemic Dynamics

Yujuan Han† ⋆ Wenlian Lu†‡

Shouhuai Xu⋆

† School of Mathematical Sciences, Fudan University
⋆ Department of Computer Science, University of Texas at San Antonio
‡ Department of Computer Science, University of Warwick

4
1
0
2

r
p
A
7
2

]

Y
S
.
s
c
[

1
v
5
8
7
6
.
4
0
4
1
:
v
i
X
r
a

ABSTRACT
Moving Target Defense (MTD) can enhance the resilience of cy-
ber systems against attacks. Although there have been many MTD
techniques, there is no systematic understanding and quantitative
characterization of the power of MTD. In this paper, we propose to
use a cyber epidemic dynamics approach to characterize the power
of MTD. We deﬁne and investigate two complementary measures
that are applicable when the defender aims to deploy MTD to achieve
a certain security goal. One measure emphasizes the maximum por-
tion of time during which the system can afford to stay in an un-
desired conﬁguration (or posture), without considering the cost of
deploying MTD. The other measure emphasizes the minimum cost
of deploying MTD, while accommodating that the system has to
stay in an undesired conﬁguration (or posture) for a given portion
of time. Our analytic studies lead to algorithms for optimally de-
ploying MTD.

Categories and Subject Descriptors
D.4.6 [Security and Protection]

General Terms
Security, Theory

Keywords
Moving target defense, cyber epidemic dynamics, epidemic thresh-
old, security models, cybersecurity dynamics

1.

INTRODUCTION

Moving Target Defense (MTD) is believed to be a “game changer"
for cyber defense. Although there have been many studies on spe-
ciﬁc MTD techniques, the power of MTD is often demonstrated
via simulation. Rigorously characterizing the power of MTD is an
important problem and is closely related to the well known hard
problem of security metrics. In this paper, we initiate the study of
a novel approach for characterizing the power of MTD.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
HotSoS ’14 Raleigh, NC USA
Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.

1.1 Our Contributions

We propose to use the cyber epidemic dynamics approach to
characterize the power of classes of MTD techniques. We deﬁne
and investigate two novel and complementary security measures
that are applicable when using MTD to achieve a certain defense
goal. The ﬁrst measure is centered on the maximum portion of time
(in the equilibrium) during which the system can afford to stay in an
undesired/insecure conﬁguration (or posture), without considering
the cost of deploying MTD. The second measure is centered on the
minimum cost when the system has to stay in an undesired/insecure
conﬁguration (or posture) for a predetermined portion of time. Our
analytic studies lead to algorithms for deploying MTD in such op-
timal fashions. To our knowledge, this is the ﬁrst systematic study
on characterizing the power of classes of MTD techniques.

1.2 The Science

Rigorously characterizing the power of MTD (or any defense)
would be a core problem in the science of security.
Indeed, the
present study initiates a paradigm for measuring the power of MTD
(or other kinds of defense techniques whose deployment can make
a global difference). The paradigm is centered on measuring the de-
gree of undersired/insecure conﬁgurations that can be tolerated by
deploying advanced defense such as MTD. The speciﬁc criterion
used in the present paper, namely that the attacks are eventually
wiped out in a certain sense, can be substituted by other criteria.
One possible candidate is the containment of malware infections
to a certain tolerable level [50] (e.g., by appropriately choosing
threshold cryptosystems).

1.3 Related Work

The present paper does not introduce any new MTD technique.
Rather, it studies how to systematically characterize the power of
MTD and optimally launch MTD. Existing studies for a similar
purpose are often based on simulation [1, 2, 27, 21]. There is effort
at analytically evaluating the power of some speciﬁc MTD tech-
niques from a localized view [31, 54]; in contrast, we characterize
the power of classes of MTD techniques from a global view.

Cyber epidemic dynamics was rooted in biological epidemic dy-
namics [33, 26]. The ﬁrst cyber epidemic models [24, 25] were lim-
ited by their homogeneity assumption that each computer/node has
the same effect on the others. Recently, models that are more ap-
propriate for studying cyber security problems have been proposed
[37, 45, 10, 15, 44, 51, 52, 50]. As we will elaborate later, the basic
idea underlying these models is to use a graph-theoretic abstraction
to represent the attack-defense structure, and use parameters to rep-
resent attack and defense capabilities. Cyber epidemic dynamics is
a special kind of cybersecurity dynamics [49],

We will use the cyber epidemic dynamics model in [50] as the

 
 
 
 
 
 
starting point of our study. This model [50] describes reactive
adaptive defense (i.e., the defender aims to adjust its defense to
control/contain the global security state). We extend this model to
accommodate MTD, a kind of proactive defense, and the resulting
model is analyzed using different skills [29, 32]. We mention that
the effect of dynamic structures in cyber epidemic models is stud-
ied in [38], where the structure dynamics however follows a de-
terministic and periodic process, rather than adaptively scheduled
by using (for example) MTD. We also mention that the effect of
dynamic semi-heterogeneous structures (i.e., clustered networks),
rather than arbitrary heterogeneous structures, is studied in [39].
These studies [38, 39] consider static parameters only and do not
have any of the measures we propose to use.

The rest of the paper is organized as follows. In Section 2, we
present a classiﬁcation of MTD techniques and describe a cyber
epidemic dynamics model that can accommodate MTD. In Section
3, we characterize the power of MTD that induces dynamic param-
eters. In Section 4, we characterize the power of MTD that induces
dynamic attack-defense structures. We discuss the limitations of
the present study in Section 5. We conclude the paper in Section 6.

2. CYBER EPIDEMIC DYNAMICS MODEL
ACCOMMODATING MOVING TARGET
DEFENSE

2.1 Three Classes of Moving Target Defense

Techniques

As mentioned in Section 1.3 and elaborated later, cyber epidemic
dynamics models use a graph-theoretic abstraction to represent the
attack-defense structure, and use parameters to represent attack and
defense ecapabilities. This suggests us to classify MTD techniques
based on what they will induce changes to the attack-defense struc-
ture and/or parameters.

Networks-based MTD Techniques (Class I)

Example techniques that fall into this class are IP address (and
TCP port) randomization and dynamic access control. The ba-
sic idea underlying IP address and TCP port randomization is to
frequently shufﬂe the IP addresses of computers by using various
methods. One method is to use virtual machine techniques, such as
migrating ensembles of virtual machines [23] and others [48, 53].
Another method is to use networking techniques, such as Network
Address Space Randomization (NASR) whereby IP addresses can
be dynamically assigned (in lieu of DHCP) to render the attacker’s
hitlist useless [1], IP hopping [2] and others [27]. A recent variant
also considers constraints and how to minimize the operation cost
[21].

The basic idea underlying dynamic access control is to dynami-
cally regulate which computers or which network address space can
directly have access to the services in which other network address
space. For example, certain servers on a campus network only ac-
commodate service requests from certain classrooms. By dynami-
cally randomizing IP addresses of authorized computers (e.g., using
aforementioned techniques), some compromised computers cannot
launch direct attacks against some target computers.

Hosts-based MTD Techniques (Class II)

Four kinds of techniques fall into this class: instruction-level, code-
level, memory-level, and application-level. One instruction-level
technique is called Instruction Set Randomization (ISR), which aims
to randomize the instructions of each process so that the attacker

cannot inject executable malicious code [22, 5]. ISR uses a program-
speciﬁc key to encrypt the instructions of a program and the pro-
cessor uses the same key to decrypt and run the instructions, where
encryption is often based on binary transformation tools, and de-
cryption is often based on dynamic binary instrumentation tools [5,
4], emulators [22, 7], or architectural support [35, 41, 47].

One code-level technique is code randomization [11, 14]. Code
randomization offers ﬁne-grained protection against code reuse at-
tacks by substituting/reordering instructions, inserting NOPs, and
re-allocating registers. Code randomization operations can be con-
ducted at the compiler [16, 20] or virtual machine level [18], or via
static binary rewriting [36, 46] and runtime binary rewriting [8, 28,
30, 34]. Dynamically generated code can be randomized as well
[19].

One memory-level technique is called Address Space Layout Ran-
domization (ASLR), which defeats code-injection attacks by ran-
domizing the memory layout of a program (e.g., stack) either at
the compile time or at the runtime [42]. ASLR can protect an ex-
ecutable (including the associated static data, stack, heap and dy-
namic libraries) [6] and the operating system kernel [16], but can-
not defeat code reuse attacks.

One application-level technique is called N -version program-
ming [3], by which the defender can dynamically use different im-
plementations of the same program function. Another technique
is called proactive cryptography. Cryptographic properties proven
in abstract models are undermined by attacks (e.g., malware) that
can compromise cryptographic keys. Threshold cryptography can
avoid this single-point-of-failure because it “split" a key into m
pieces such that compromising fewer than t pieces will not cause
exposure of the key, while the cryptographic function can be com-
puted when any t of the m pieces participate [40, 12]. Proactive
cryptography can render the compromised pieces of a key useless
once the pieces are re-shufﬂed [17].

Instruments-based MTD Techniques (Class III)

The defender can utilize honeypot-like techniques to capture new
attacks. However, the attacker can “tomograph" honeypots and by-
pass the IP addresses monitored by them. Therefore, the defender
can dynamically change the IP addresses monitored by honeypots
[9].

2.2 Cyber Epidemic Dynamics Model Accom-

modating MTD

Cyber Epidemic Dynamics Models

The basic idea underlying cyber epidemic dynamics models (see,
for example, [45, 10, 15, 44, 52, 51, 50]) can be explained as fol-
lows. Cyber attacks are often launched from compromised comput-
ers against vulnerable computers. This means that there exists an
(attacker, victim) relation, which captures that an attacker (e.g.,
compromised computer) can directly attack a victim (e.g., vulnera-
ble) computer. In the extreme case where any computer can attack
any other computer, this relation induces a complete graph struc-
ture. In general, any graph structure can be relevant. The resulting
graph structures are called attack-defense structures, where com-
promised computers/nodes may be detected and cured, but may
later get attacked again. Such models can naturally abstract attack
and defense capabilities as parameters that are associated to the
nodes and edges of attack-defense structures. A core concept in cy-
ber epidemic dynamics models is the so-called epidemic threshold,
namely a sufﬁcient condition under which the epidemic dynamics
converges to the clean state.

Accommodating MTD

We adapt the cyber epidemic dynamics model introduced in [50],
which considers reactive adaptive defense, to accommodate MTD
(i.e., proactive defense). Speciﬁcally, the afore-discussed Class
I MTD techniques can be accommodated with dynamic attack-
defense structures, because they can cause that an infected com-
puter may be able to attack a vulnerable computer at time t1 but
not at time t2 > t1 (e.g., the vulnerable computer’s IP address
has been changed). Class II MTD techniques can be accommo-
dated with dynamic parameters because they can affect capabili-
ties of attacker and defender over time. Class III MTD techniques
can be accommodated with dynamic attack-defense structures (be-
cause an IP address assigned to honeypot at time t1 may be re-
assigned to a production computer at time t2 > t1) and dynamic
parameters (because the defender could learn zero-day attacks from
honeypot-captured data, and identify and disseminate countermea-
sures to prevent/detect such attacks). As such, our characterization
study can accommodate the three classes of MTD techniques.

}

{

∈

1, . . . , n

Speciﬁcally, we consider a cyber epidemic dynamics model with
dynamic attack-defense structure G(t) = (V, E(t)), where V is
the set of nodes (e.g., computers) and E(t) is the set of edges at
E(t) means that node w can attack node
time t such that (w, v)
∈
v at time t. Suppose
as
= n. We may think V =
V
|
|
well. Let A(t) = [Avu(t)] denote the adjacency matrix of G(t),
E(t) and Avu(t) = 0 otherwise.
where Avu(t) = 1 if (u, v)
V (i.e., a computer
Naturally, we have Auu(t) = 0 for all u
V has two possible
does not attack itself). Suppose any node v
states: secure or infected. A node v
V is secure if it is vulnerable
but not successfully attacked yet, and infected if it is successfully
attacked. Let iv(t) and sv(t) respectively be the probabilities that
V is infected and secure at time t, where iv(t) + sv(t) = 1.
v

∈
Let γ(t) be the probability that at time t, an infected node u

V
∈
E(t).
successfully attacks a secure node v
Let β(t) be the probability that an infected node v
V becomes
secure at time t. Suppose the attacks are independently launched.
V becomes infected at time
The probability that a secure node v
t is [50]:

V over (u, v)

∈
∈

∈

∈

∈

∈

∈

ξv(t) = 1

−

G(t)=(V,E(t)):Avu(t)=1
Y

(1

−

iu(t)γ(t)) .

The master dynamics equation is [50]:

div(t)
dt

= ξv(t)(1

(1

−

Avu(t)iu(t)γ(t))

!

−

(1

iv(t))

−

β(t)iv(t) =

iv(t))

−

−

iv(t)β(t).

1

−

u∈V
Y

This is the starting point of our study. Table 1 lists the main nota-
tions used in the paper.

2.3 Measuring the Power of MTD

Let I ∗ = (0, . . . , 0) denote the clean state or equilibrium i∗
v

def
=
limt→∞ iv(t) = 0 for all v
V , namely that there are no in-
fected computers in the equilibrium (i.e., the spreading dies out).
Cyber epidemic threshold is a sufﬁcient condition under which the
dynamics converges to I ∗ = (0, . . . , 0). In the special case that
G = (V, E) and (β, γ) are independent of t, it is known [10, 15,
44, 51] that the dynamics converges to I ∗ = (0, . . . , 0) if

∈

def
= β

µ

−

γλ1(A) > 0,

(1)

where λ1(A) is the largest (in modulus) eigenvalue of the adjacent
matrix A of G. If µ < 0, the dynamics does not converge to I ∗ =
(0, . . . , 0) at least for some initial values.

Table 1: Main notations used throughout the paper
X(t), X X(t) is a function of time t, while X is not

A(t)
sv(t), iv(t)

|

i∗
v

V
|

= n

G(t) G(t) = (V, E(t)) is attack-defense structure at
time t: a graph of node set V and edge set E(t),
where
adjacency matrix of G(t) = (V, E(t))
the probability node v is secure or infected at time
t
the probability node v is infected as t
existing)
I ∗ def
= (i∗
n) where n =
the cure probability that an infected node becomes
secure at time t (reﬂecting defense power)
the infection probability that infected node u suc-
cessfully attacks secure node v over edge (u, v)
E(t)

1, . . . , i∗

I ∗
β(t)

→ ∞

γ(t)

V
|

(if

∈

|

(t)

C

1

C

j

C

λ1(A)
In

k · k
R S
←
exp(a)

s

←

T

(t) = (G(t), β(t), γ(t)) is system conﬁguration

C
or posture at time t

≥

j = (Gj , βj , γj) for j

1 = (G1, β1, γ1) is the undesired/insecure con-
C
ﬁguration that violates the convergence condition
2 are MTD-induced
C
desired conﬁgurations that satisfy the convergence
condition
the largest eigenvalue (in modulus) of matrix A
the n-dimensional identity matrix
the 2-norm of vector or matrix
select s as a random element of set S
assign T a value according to the exponential dis-
tribution with parameter a

C

≥

≥

Suppose the defender is confronted with conﬁguration or posture
1 = (G1 = (V, E1), β1, γ1), under which condition (1) does
C
not hold. Suppose the defender can launch combinations of MTD
techniques to induce conﬁgurations
j = (Gj = (V, Ej), βj, γj)
C
2, each of which satisﬁes condition (1). If the defender
for j
can always assure (G(t), β(t), γ(t)) =
j = (Gj , βj , γj) for any
t > 0 and some j
2, the problem is solved because the defender
can make the dynamics converge to I ∗ = (0, . . . , 0) by launching
j. However, it would be more realistic that the
MTD to induce
defender can maintain such conﬁgurations as
2) for a small
period of time, because the attacker can introduce (for example)
zero-day attacks to force the system to depart from conﬁguration
j
C
1. Moreover, the system may have to stay
and enter conﬁguration
1 at least for some period of time because G1 =
in conﬁguration
(V, E1) is necessary for facilitating some applications. Figure 1
illustrates the idea of using MTD to make the overall dynamics
converge to I ∗ = (0, . . . , 0), while allowing the system to stay
for some portion of time in the undersired conﬁguration
1, which
violates condition (1).

j (j

≥

C

C

C

C

C

The preceding discussion leads us to deﬁne two measures of
power of MTD. The ﬁrst deﬁnition captures the maximum time
the system can afford to stay in the undersired conﬁguration
1
C
while the overall dynamics converges to I ∗ = (0, . . . , 0) because
of MTD, without considering cost.

DEFINITION 1. (power of MTD without considering cost) Con-

C

sider undesired conﬁguration
1 = (G1, β1, γ1) that violates con-
dition (1). Suppose the defender can launch MTD to induce con-
[2, . . . , J], where each
ﬁgurations
γkλ1(Ak) for
C
k = 1, . . . , J, where Ak is the adjacency matrix of Gk. We say
MTD is (µ1, µ2, . . . , µJ , π∗
1 )-powerful if it can make the overall

j = (Gj, βj , γj) for j
j satisﬁes condition (1). Denote by µk = βk

−

∈

C

 
Non-MTD C1

MTD C2

Non-MTD C1

MTD C3

0

t1

t2

t3

t4

Time t

C

Figure 1: Illustration of MTD-induced switching of conﬁgu-
rations: The system is in conﬁguration
1 during time inter-
2 during time interval [t1, t2) because the de-
val [0, t1), in
fender launches MTD, etc. Although
1 violates condition (1),
the overall dynamics can converge to I ∗ = (0, . . . , 0) because
of MTD. Note that
1’s
(i.e., launching two combinations of MTD to induce
3
before returning to

3 may reside in between two

C
2 and

2 and

C

C

C

C

C

C

1).

C

dynamics converge to I ∗ = (0, . . . , 0), while allowing the system
to stay in conﬁguration
1 -portion of time in
the equilibrium.

1 for the maximum π∗

C

The second deﬁnition captures the minimum cost with respect to
a given portion of time, π1, during which the system must stay in
conﬁguration

1.

C

C

C

C

C

j satisﬁes condition (1). Denote by µj = βj

DEFINITION 2. (power of MTD while considering cost) Con-
sider undesired conﬁguration
1 = (G1, β1, γ1) that violates con-
dition (1), and the potion of time π1 that the system must stay in
1. Suppose the defender can launch MTD to in-
conﬁguration
j = (Gj , βj , γj) for j = 2, . . . , J, where
duce conﬁgurations
each
γj λ1(Aj)
for j = 2, . . . , J, where Aj is the adjacency matrix of Gj. Con-
R+ such that h(µj ) is the cost
) : R+
sider cost function h(
·
of launching MTD to induce conﬁguration
j for j = 2, . . . , J,
where h′(µ)
), we say
·
≥
, µJ , π1, Υ)-powerful if the overall dynamics
MTD is (µ1, µ2,
converges to I ∗ = (0, . . . , 0) at the minimum cost Υ(π∗
J ),
2 ,
where π∗
J) is the portion of time the system stays in
j (2
conﬁguration

j
j in the equilibrium.

0 for µ > 0. For give cost function h(

, π∗

· · ·

· · ·

→

≤

−

C

≤
C

2 , . . . , π∗

J because the problem of computing π∗

Remark. Deﬁnitions 1-2 characterize the power of MTD from
two complementary perspectives. Deﬁnition 1 does not explicitly
mention π∗
2 , . . . , π∗
N
is orthogonal to the existence of π∗
1 . Nevertheless, all of our results
allow to explicitly compute π∗
N . Deﬁnition 2 explicitly
2 ,
mentions π∗
2 , . . . , π∗
J because they are essential to the deﬁnition of
minimum cost, where π1 is not a parameter of the cost Υ because
1 for a predetermined portion of time π1.
the system must stay in

, π∗

· · ·

C

3. POWER OF MTD INDUCING DYNAMIC

PARAMETERS

In this section we characterize the power of MTD that induces
dynamic parameters but keeps the attack-defense structure intact
(i.e., G is independent of time t throughout this section). Let A be
the adjacency matrix of G. We ﬁrst recall the following theorem
from [50] and present a corollary of it.

THEOREM 1. ([50]) Consider conﬁgurations (G, β(t), γ(t)),
where the dynamic parameters β(t) and γ(t) are driven by some
ergodic stochastic process. Let E(β(0)) and E(γ(0)) be the re-
spective expectations of the stationary distributions of the process.
Suppose convergences limt→∞

β(τ )dτ = E(β(0)) and

t0+t
t0

γ(τ )dτ = E(γ(0)) are uniform with respect to t0
limt→∞
R
almost surely. If E(β(0))/E(γ(0)) > λ1(A), the dynamics con-
verges to I ∗ = (0, . . . , 0) almost surely; if E(β(0))/E(γ(0)) <
λ1(A), there might exist infected nodes in the equilibrium.

R

t0+t
t0

· · ·
· · ·

· · ·
· · ·

COROLLARY 1. Consider conﬁgurations (G, β(t), γ(t)), where
(β(t), γ(t)) are driven by a homogeneous Markov process ηt with
steady-state distribution [π1,
(β1, γ1), . . . , (βN , γN )
{
and E(γηt ) = π1γ1 +

, πN ] and support
, meaning E(βηt ) = π1β1 +
}
+ πN γN . If
· · ·
π1β1 +
π1γ1 +

+ πN βN
+ πN γN

> λ1(A),

+πN βN

· · ·

· · ·

(2)

the dynamics will converge to I ∗ = (0, . . . , 0); if

π1β1 +
π1γ1 +

+ πN βN
+ πN γN

< λ1(A),

the dynamics will not converge to I ∗ = (0, . . . , 0) at least for some
initial value scenarios.

3.1 Characterizing Power of MTD without Con-

sidering Cost
In this case, despite that

C

C

1 = (G, β1, γ1) violates condition
(1), the system needs to stay as much as possible in conﬁgura-
tion
1. Fortunately, the defender can exploit MTD to make the
overall dynamics converge to I ∗ = (0, . . . , 0). This is possi-
ble because MTD can induce conﬁgurations
j = (G, βj , γj) for
j satisﬁes condition (1). Denote by
j = 2, . . . , N , where each
, N . Without loss of generality,
µj = βj
suppose µ1 < 0 < µ2 <

< µN . According to Corollary 1, if

C
γjλ1(A) for j = 1,

· · ·

−

C

· · ·
π1µ1 +

· · ·

+ πN µN > 0,

(3)

then the dynamics will converge to I ∗ = (0, . . . , 0). Since in-
equality (3) is strict and is a linear function of π1, in order to reach
the maximum π∗
1 we need to introduce a sufﬁciently small constant
0 < δ

1 and replace condition (3) with

≪

π1µ1 +

+ πN µN

δ.

≥

· · ·

(4)

Theorem 2 constructively identiﬁes the maximum π∗
portion of time the system can afford to stay in

1.

1 , the maximal

C

THEOREM 2. Suppose conﬁguration

1 = (G, β1, γ1) violates

condition (1). Suppose MTD-induced conﬁgurations
for j = 2,
< µN .
The maximal potion of time the system can afford to stay in conﬁg-
uration

C
, N satisfy condition (1) as 0 < µ2 <

j = (G, βj , γj)

· · ·

· · ·

1 is

C

C

π∗
1 =

µN
µN

δ
µ1

−
−

,

(5)

while the system will stay in conﬁgurations
with portions of time given by

2, . . . ,

C

C

N respectively

π∗
2 =

· · ·

= π∗

N−1 = 0, π∗

N =

δ
µN

−
−

µ1
µ1

.

, µN , π∗

1 )-powerful.

In other words, MTD is (µ1,

· · ·

PROOF. Eq. (4) implies

π2µ2 +

π1

≤

+ πN µN
µ1

· · ·
−

δ

−

≤

(π2 +

· · ·

+ πN )µN

µ1

−

δ

−

(6)

(1

−

=

δ

,

−

π1)µN
µ1

−

which means

π1

≤

µN
µN

.

δ
µ1

−
−

(7)

Moreover, this maximum π∗
Eqs. (6) and (7) hold, namely

1 can be reached if all the equalities in

π2 =

· · ·

= πN−1 = 0, πN =

δ
µN

−
−

µ1
µ1

.

This means that the defender only needs to launch the MTD that
N = (G, βN , γN ).
induces conﬁguration

C

2, . . . ,

1) conﬁgurations,

induce a set of (N
< µN , only

Theorem 2 says that although the defender can launch MTD to
N with 0 < µ2 <
−
N matters. This means that µk is indicative of the
· · ·
capability of a conﬁguration. Figure 2 plots the dependence of π∗
1
µ1 and µN with δ = 10−5. We observe that for ﬁxed µ1, the
on
maximum portion of time π∗
1 monotonically non-decreases in µN .
For example, by ﬁxing µ1 =
1 is a non-decreasing curve
in µN .

0.4, π∗

−

−

C

C

C

1*
π

1

0.8

0.6

0.4

0.2

0
1

subject to

π1β1 +

π1γ1 +

P

N
j=2 πjβj
N
j=2 πjγj

Since

P

π1β1+PN
π1γ1+PN

j=2 πj βj
j=2 πj γj

0, Eq. (9) is equivalent to:

N

> λ1(A), π1 +

πj = 1, πj

j=2
X

0 (9)

≥

> λ1(A) is equivalent to π1µ1+

N
j=2 µj >

P

0.

(10)

N

πjµj >

N

π1µ1,

πj = 1

−

π1, πj

−

≥

j=2
X

j=2
X
Since the objective is linear and the optimal solution would get on
bound of the non-closed constraint (10), we need to introduce a
sufﬁciently small constant 0 < δ
1 and replace constraint (10)
with

≪

N

j=2
X

πj µj

≥ −

N

π1µ1 + δ,

πj = 1

j=2
X

π1, πj

0.

≥

−

(11)

Theorem 3 shows how to ﬁnd the minimum cost Φ(π∗
N )
2 ,
according to constraints (8) and (11), and therefore gives an algo-
rithm for the optimization problem. Proof of Theorem 3 is deferred
to the Appendix.

, π∗

· · ·

THEOREM 3. Suppose conﬁguration

1 = (G, β1, γ1) violates

condition (1). Suppose MTD-induced conﬁgurations
for j = 2,
π1
≤
Suppose f (

, N satisfy condition (1). Suppose π1, where 0 <
1.
, is the potion of time the system must stay in

) is the cost function as discussed above. Deﬁne
·

· · ·
µN −δ
µN −µ1

C

C

j = (G, βj , γj)

C

0.8

0.6

µ

N

0.4

0.2

1

0.8

0.2

0

0

0.6

0.4

−µ
1

µk∗ = min

µk

and for 2

l < m

≤

(cid:26)

N ,

≤

µk > −
(1
|

π1µ1
π1)

−

, 2

k

≤

≤

N

(cid:27)

(12)

Figure 2: Dependence of π∗

1 on

µ1 and µN .

−

3.2 Characterizing Power of MTD while Con-

sidering Cost
In this case, conﬁguration

C

C

1 = (G, β1, γ1) is given and the time
the system must stay in
1 is predetermined as π1. The defender
wants to deploy MTD to make the overall dynamics converge to
I ∗ = (0, . . . , 0), while minimizing the cost of launching MTD.
j = (G, βj , γj ) for
Denote the MTD-induced conﬁgurations by
N . Note that cost may only be considered for N
2
3
≥
because when N = 2, it is more meaningful to maximize π∗
1 (i.e.,
the preceding case).

≤

≤

C

j

Since we have proved that π1

1 = µN −δ
π∗
µN −µ1

≤

is necessary to

make the dynamics converge to I ∗ = (0, . . . , 0), µN −δ
is the
µN −µ1
natural upper bound on π1 (i.e., if π1 is above the upper bound,
we cannot assure the dynamics will converge to I ∗ = (0, . . . , 0),
R+
regardless of the cost). Consider cost function f (
as in Deﬁnition 2. such that f (µj ) is the cost of launching MTD
0 for
to induce conﬁguration
µ > 0. The objective is to minimize, for given cost function f (
)
·
and any constant f (µ1), the following cost:

) : R+
·
N , where f ′(µ)

j for 2

→

≥

≤

≤

C

j

Φ(π2,

· · ·

, πN ) = π1f (µ1) +

πj f (µj )

(8)

N

j=2
X

F (µl, µm) =π1f (µ1) +

f (µl)
f (µm)
−
µl
µm
−
µlf (µm)
µl

(1

−
−

(δ

−

π1µ1)

π1).

(13)

+

µmf (µl)
µm

−
If k∗ = 2, the minimal cost under constraint (11) is

min
π2,··· ,πN

Φ(π2,

· · ·

, πN ) = π1f (µ1) + (1

π1)f (µ2),

−

which is reached by launching MTD to induce conﬁguration
only. If k∗ > 2, the minimal cost under constraint (11) is

2

C

min
π2,··· ,πN

Φ(π2,

· · ·

, πN ) = min

l<k∗≤m

F (µl, µm).

(14)

Denote by

µl∗ , µm∗

{

}

= arg min

l<k∗≤m

F (µl, µm). The minimal

cost is reached by launching MTD to induce conﬁgurations
respectively with portions of time [πl∗ , πm∗ ]:

l∗,

C

C

m∗

πl∗
πm∗

=

(cid:21)

µm∗

1

−

(cid:20)

µl∗

(cid:20)

(µm∗
(µl∗

−

−
−

δ) + π1(µ1
−
δ) + π1(µl∗

µm∗ )
µ1)

−

,

(cid:21)
(15)

where 0 < δ
(µ1, µ2,

· · ·

1 is some constant. That is, MTD is

≪
, µN , π1, Φ)-powerful.

3.3 Algorithm for Orchestrating Optimal MTD
When not considering cost, Theorem 2 constructively gives a
method for optimally launching MTD. When considering arbitrary
), Theorem 3 constructively shows how to ﬁnd
cost function f (
·
the minimum cost Φ(π∗
N ) according to constraints (8) and
2 ,

, π∗

· · ·

(11), and therefore gives a method for computing the minimum
cost and the corresponding strategy for optimally launching MTD.
Theorems 2-3 suggest many possible ways/algorithms to achieve
the goal, with Algorithm 1 being a concrete example.

C

C

≥

· · ·

, N and N

j = (G, βj , γj ) for j = 2,

Algorithm 1 Launching optimal MTD (dynamic parameters)
INPUT: initial conﬁguration
1 = (G, β1, γ1), MTD-induced con-
2, con-
ﬁgurations
stant a > 0 determining time resolution, optional cost function
), δ (0 < δ << 1), optional π1
f (
·
OUTPUT: Optimal MTD strategy
1: if cost function is not given (i.e., no need to consider cost) then
2:
3:
4:
5:

Compute π∗
while TRUE do

1}
N for time TN

Wait for time T1
←
Launch MTD to make system stay in
exp(a/(1
Stop launching MTD {system returns to

1 according to Eq. (5)

1 ) {system in

exp(a/π∗

π∗
1 ))

←

−

C

C

1}

C

end while

6:
7:
8: else
9:
10:
11:
12:
13:
14:
15:
16: Wait for time T1
17:
R
18:
19:

l∗, m∗
j
}
{
while TRUE do

end if

else

←

Compute k∗ according to Eq. (12)
if k∗ > 2 then

Compute µl∗ , µm∗ according to Eq. (13)
Compute πl∗ , πm∗ according to Eq. (15)

Set l∗ = m∗ = 2 and πl∗ = 1

π1

−

exp(a/π1) {system in
1}
{j = 2 when l∗ = m∗ = 2}

C

←

Launch MTD to make system stay in
exp(a/πj) {system in
Set ∆ =
j
if j = 1 then

j}
C
j
} − {
R ∆ {j = 1 when l∗ = m∗ = 2}

1, l∗, m∗
{

←

C

}

j for time T

Stop launching MTD and wait for time T1
exp(a/π1) {system in
1}
l∗, m∗
j
←
{
end if
end while

C

}

R

20:
21:
22:
23:

24:
25:
26:
27: end if

C

Speciﬁcally, lines 2-7 describe the algorithm corresponding to
Theorem 2 (i.e., not considering cost), where line 4 instructs the
defender not to launch MTD so that the system stays in conﬁg-
1 for a period of time T1, and line 5 instructs the de-
uration
fender to launch MTD to make the system stay in conﬁguration
N for the period of time TN . On the other hand, lines 9-26 de-
C
scribe the algorithm corresponding to Theorem 3 (i.e., considering
If k∗ = 2, the defender needs to make the cyber system
cost).
2. If k∗ > 2, the de-
stay alternatively in conﬁgurations
fender needs to make the cyber system stay alternatively in con-
ﬁgurations
l∗ for
m∗ for a period of
a period of time Tl∗ and/or in conﬁguration
time Tm∗ . Depending on the random coins ﬂipped on lines 21 and
24, possible conﬁguration sequences include:
1, . . .
1, . . .. Another algorithm for achieving the
and
C
same goal it to make the system in
m∗ , . . .
l∗,
C
periodically for periods of time T1, Tl∗ , Tm∗ , respectively.

1 for a period of time T1, in conﬁguration

1 and

m∗ ,

m∗ ,

m∗ ,

l∗ ,

l∗ ,

l∗,

l∗,

1,

1,

1,

1,

C

C

C

C

C

C

C

C

C

C

C

C

C

C

C

C

C

C

The computational complexity of Algorithm 1 is straightforward.
When not considering cost, the algorithm incurs O(1) computa-
tional complexity. When considering cost, line 9 incurs O(N )
complexity for searching k∗ according to (12), line 11 incurs O(N 2)

complexity for searching the optimal l∗ and m∗ according to (13),
and all other steps incur O(1) complexity.

3.4 Simpler Algorithm for Convex and Con-

cave Cost Functions

1 ≤

µN −δ
µN −µ1

and cost function f (

Algorithm 1 applies to arbitrary cost function f (

). We make
·
a further observation on Theorem 3, which says that for any given
0 < π∗
), if k∗ = 2, the min-
·
2; if k∗ > 2,
imum cost is reached by inducing conﬁguration
Eqs. (13) and (14) indicate that the minimum cost is dependent
upon the property of f (
) is con-
·
vex or concave, which may hold for most scenarios, we can obtain
closed-form results on l∗, m∗, and therefore Algorithm 1 is natu-
rally simpliﬁed. Recall that µ2 <
< µN . Deﬁne R(µl, µm) =
f (µm)−f (µl)
µm−µl
F (µl, µm) =π∗

). Now we show that when f (
·

. It can be veriﬁed that

· · ·

C

1 f (µ1) + (1
−
+ R(µl, µm)[(δ
1 f (µ1) + (1
−
+ R(µl, µm)[(δ

=π∗

π∗
1 )f (µl)
π∗
1 µ1)
−
−
π∗
1 )f (µm)
π∗
1 µ1)

−

µl(1

−

π∗
1 )]

µm(1

π∗
1 )].

−

−
) is convex, namely f ′′(
·

If f (
0, then for ﬁxed µl (or
)
·
µm), R(µl, µm) is monotonically non-decreasing in µm (or
µl). Note that µl < δ−π
1. For ﬁxed
µl (or µm), F (µl, µm) is monotonically non-decreasing (or
non-increasing) in µm (or µl). The minimum cost is

∗
1 µ1
1−π∗
1 ≤

µm, where δ

≪

≥

min
l<k∗≤m

F (µl, µm) = F (µk∗−1, µk∗ ).

(16)

Having identiﬁed µk∗−1, µk∗ , one can compute πk∗−1, πk∗
according to (15). Thus, lines 11 and 12 are simpliﬁed by
this analytical result, with the complexity of searching for
the optimal solution (i.e., k∗ in this case) reduced to O(N ).

) is concave, namely f ′′(
·

0, then for ﬁxed µl (or
If f (
µm), R(µl, µm) is monotonically non-increasing (or non-
decreasing) in µm (or µm). The minimum cost is

)
·

≤

min
l<k∗≤m

F (µl, µm) = F (µ2, µN ).

(17)

Similarly, having identiﬁed µ2, µN , one can compute π2, πN
according to (15). Thus, lines 11 and 12 are simpliﬁed by
this analytical result, with the complexity of searching for
the optimal solution reduced to O(1).

C

C

k∗−1,

k∗; if f (

C
MTD to induce conﬁgurations

The above discussion suggests the following: If f (
) is convex,
·
the defender only needs to launch MTD to induce conﬁgurations
) is concave, the defender only needs to launch
·

2,
To illustrate the inﬂuence of f (

N .
C
) on the power of MTD, we set
·
N = 4, (β1, γ1) = (0.2, 0.00422), (β2, γ2) = (0.4, 0.000845),
(β3, γ3) = (0.6, 0.00169), (β4, γ4) = (0.8, 0.00169), δ = 10−5,
0.4,
λ1(A) = 118.4, µ1
0.3, µ2
≈
−
0.6. From Eq. (5), we get π∗
= 2
and µ4
3 .
δ
≈
−
We set π∗
5 , which means k∗ = 4. Figure 3 plots the to-
1 = 3
tal cost Φ with different cost functions f (
−
π3. The shadow area in the π2π3-plane is the con-
π1
strain slope of π2, π3 with respect to condition (11). Note that Φ =
π∗
π3)f (µ4), which
1 f (µ1) + π2f (µ2) + π3f (µ3) + (1
is linear non-increasing in π2 for ﬁxed π3 (also in π3 for ﬁxed π2).
For convex function f (x) = 100(x + 0.1)2, the above analysis
revealed that the minimum cost is reached at [π3, π4] = [πl∗ , πm∗ ]

), where π4 = 1
·

0.3, µ3
1 ≤

δ
−
µ4−δ
µ4−µ1

π∗
1 −

≈ −

π2

π2

−

−

−

−

≈

−

δ

δ

•

•

←

←

C

C

3,

as given by Eq. (15), namely by launching MTD to induce conﬁgu-
rations
4. Figure 3(a) shows that the minimum cost is reached
at [π2, π3, π4] = [0, 0.3, 0.1] and the minimum cost is 14.6, which
matches the analytic result given by Eq. (16). For concave function
f (x) = 10√x + 0.5, Figure 3(b) shows that the minimum cost
is reached at [π1, π2, π3] = [0.2, 0, 0.2] and the minimum cost is
6.5696, which matches the analytic result given by Eq. (17).

* =0.6
π
1

Φ

25

20

15

10

5

0
0

Φ

9

8

7

6

5

4

3

2

1

0
0

,π
,π
(π
)=(0.2,0,0.2)
4
3
2
Φ(π)=15

,π
,π
(π
)=(0,0.3,0.1)
3
4
2
Φ(π)=14.6

0.05

0.1

0.15

π
3

0.2

0.25

0.2

0

0.05

0.1

0.15

π
2

(a) Convex cost function f (x) = 100(x + 0.1)2

* =0.6
π
1

,π
,π
(π
)=(0,0.3,0.1)
3
4
2
Φ(π)=6.5781

,π
,π
(π
)=(0.2,0,0.2)
4
3
2
Φ(π)=6.5696

0.05

0.1

0.15

π
3

0.2

0.25

0.2

0

0.05

0.1

0.15

π
2

(b) Concave cost function f (x) = 10√x + 0.5

Figure 3: Dependence of Φ on π1, π2 under different cost func-
tions f (

)
·

4. POWER OF MTD INDUCING DYNAMIC

STRUCTURES

In this section, we characterize the power of MTD that induces
dynamic attack-defense structures G(t), while the parameters (β, γ)
are kept intact. More speciﬁcally, suppose conﬁguration
1 =
(G1, β, γ) violates condition (1). Suppose MTD-induced conﬁg-
urations
2 satisfy
condition (1). We want to identify a Markov process strategy σt,
CN ′ , to make the dynamics converge to
deﬁned over
equilibrium I ∗ = (0, . . . , 0), while staying in conﬁguration
1
C
as much as possible or minimizing the cost of launching MTD.
Throughout this section, let Al be the adjacency matrix of Gl for

l = (Gl, β, γ) for l = 2,

, N ′ and N ′

2, . . . ,

· · ·

≥

1,

C

C

C

C

l = 2, . . . , N ′.

We start with a general result where one or more conﬁgurations

violating condition (1).

C

C

THEOREM 4. Consider

l = (Gl, β, γ) for l = 1,

ℓ = (Gℓ, β, γ) for some 1
≤
k = (Gk, β, γ) for some j < k

, N ′,
j violate condition (1)
where
≤
N ′ satisfy condition (1).
but
Then, the overall dynamics converges to I ∗ = (0, . . . , 0) almost
surely under Markov process strategy σt with inﬁnitesimal genera-
tor Q = (quv)N ′×N ′ deﬁned as:

· · ·

≤

C

ℓ

(i) for k > j,

qkk

−

≤

(ii) for ℓ

j,

qℓℓ

−

≤

≥

2a[β−γλ1(Ak)−δ]
′−1−j
′−1

jc+N
N

−a

;

2b[γλ1(Aℓ)−β+δ]
′−j
b−
′−1

c(j−1)
′−1
N

− N
N

;

(iii) qrp = −qrr

N ′−1 for all p

= r and p, r

1, . . . , N ′

∈ {

.
}

PROOF. Suppose (if needed, with reordering)

λ1(A1)

≥ · · ·

λ1(Aj) >

β
γ

> λ1(Aj+1)

· · · ≥

λ1(AN ′ ).

(18)

−

For any k > j, [γAk
βIn] is a Hurwitz matrix [43] (i.e., real parts
of all eigenvalues are negative), meaning that there exist positive
deﬁnite matrices Pk < In and a constant 0 < δ
1 such that
≪
2 ]Pk < 0. We can ﬁnd
(Pk[γAk
−
j and positive constants
positive deﬁnite matrices Pℓ with ℓ
a < 1 < b < c such that

βIn])s = [γλ1(Ak)

β + δ

−

≤

aIn < Pk < In < bIn < Pℓ < cIn,

k > j, ℓ

∀

j,

≤

and

Pℓ[γAℓ

{

βIn]

s
}

−

≤

[γλ1(Aℓ)

β +

−

δ
2

]Pℓ,

ℓ

∀

≤

j.

By combining (i)-(iii) in the condition of the theorem, we obtain

Pm[γAm

{

βIn]

s +
}

−

1
2

′

N

r=1
X

qrmPr

δ
2

In.

≤ −

(19)

Since the parameters are static and the structures are driven by
Markov process σt, the dynamics of iv(t) for v

V is:

∈

=

1

(cid:20)

−

u∈V
Y

[1

−

γ(Aσt )vuiu(t)]
(cid:21)

(1

−

iv(t))

−

βiv(t).

(20)

div(t)
dt

Since

1

−

(cid:20)

u∈V
Y

[1

−

γ(Aσt )vuiu(t)]
(cid:21)

(1

−

iv(t))

≤

u∈V
X

γ(Aσt)vuiu(t)

always holds, we deﬁne a new variable yv(t) with dynamics:

dyv(t)
dt

=

u∈V
X

γ(Aσt )vuyu(t)

βyv(t).

−

(21)

Note that any sample point w
σt(w). Let

∈

Ω corresponds to a deterministic

i(t) = [i1(t),

· · ·

, in(t)]⊤, y(t) = [y1(t),

, yn(t)]⊤

· · ·

be the solutions of systems (20) and (21) under the Markov switch-
ing process σt(w) respectively. From the comparison theory of
differential equations, we know i(t)
y(t) holds if i(0) = y(0),
E[
which implies that E[
k
k

2].
k

≤
y(t)

2]
k

i(t)

≤

6
Let V (y(t), t, σt) = 1

process
(y(t), σt) : t > 0
inﬁnitesimal generator of the process is:

{

}

2 y(t)⊤P (σt)y(t) and ζ = δ

2c . The joint
is a strong Markov process and the

, N ′

2,
{
conﬁgurations. Under the deﬁnition of Q in Theorem 4, we have

(which will be determined below) are MTD-induced

· · ·

}

= Q + diag

L

y⊤P ⊤(1)
{

∂
∂y

,

· · ·

, y⊤P ⊤(N ′)

∂
∂y }

Then, we have

V (y, t, j) =

qkj V (y, t, k) + (

N

L

∂V (y, t, j)
∂y

)⊤ ˙y,

k=1
X

From the Dynkin Formula [13] and Eq. (19), we have

EeζtV (y(t), t, σt)

= V (y0, 0, σ0) + E

ζeζτ V (y(τ ), τ, στ )dτ

t

0

Z

t

eζτ

L

+E

0
Z

V (y(τ ), τ, στ )dτ

= V (y0, 0, σ0) + E

t

+E

Z
eζτ y(τ )⊤

0
Z

E

t

+

1
2

0

Z
V (y0, 0, σ0).

eζτ y(τ )⊤

t

0

ζeζτ y(τ )⊤P (στ )y(τ )dτ

P (στ )[γA(στ )

{

βIn]

sy(τ )dτ
}

−

′

N

r=1
X

qr,στ P (r)y(τ )dτ

≤
Hence, we have

E

i(t)

k

(cid:20)

2
k

(cid:21)

≤

which implies that
k
This completes the proof.

k

≤
i(t)

2EV (y(t), t, σt)
a

E

y(t)

2
k

k

(cid:20)

(cid:21)

≤
2V (y0, 0, σ0)
a

e−ζt,

converges to zero almost surely for all v.

4.1 Characterizing Power of MTD without Con-

sidering Cost

THEOREM 5. Suppose conﬁguration

1 = (G1, β, γ) violates
l = (Gl, β, γ)

C

condition (1) and MTD-induced conﬁgurations
for l = 2, . . . , N ′ satisfy condition (1). Denote by µl = β
−
γλ1(Aj) for l = 1, . . . , N ′. Without loss of generality, suppose
< µN ′ . Under the deﬁnition of Q in Theorem
µ1 < 0 < µ2 <
4, the maximum portion of time the system can afford to stay in
conﬁguration

· · ·

C

1 is

C

π∗
1 =

b−1
2b[−µ1+δ]
2b[−µ1+δ] + c−a
2a[µN
which is reached by launching MTD to induce conﬁguration (GN ′ , β, γ).
That is, MTD is (µ1,

1 )-powerful.

, µN ′ , π∗

(22)

′ −δ]

b−1

,

· · ·

PROOF. The inﬁnitesimal generator Q deﬁned in the proof of
Theorem 4 speciﬁes the desired law σt, which can guide the de-
ployment of MTD to force the overall dynamics converge to I ∗ =
(0, . . . , 0). Note that j in Eq. (18) represents the number of conﬁg-
urations that violate condition (1). Hence, j = 1 in the present sce-
nario. For each r
∈ {
is the portion of time in conﬁguration
in the proof of Theorem 4.
Consider conﬁgurations

Pp xp
r. Let a, b, c be as deﬁned

, let xr = 1
}

; then πr = xr

1, . . . , N ′

, where m

N ′,

−qrr

C

{C

1,

k1 ,
C
1,
∈ {

· · ·

· · ·

,
km}
C
and
, m
}

≤
k1, . . . , km
{

} ⊆

and

C

kl = (Gkl , β, γ) for l

x1

≤

2b[

−

b

1
−
µ1 + δ]

, xkl ≥

c+m−1

m −
2a[µkl −

a
δ]

, l = 1,

, m.

· · ·

This means that the dynamics converges to I ∗ = (0, . . . , 0), while
staying in conﬁguration

1 for a portion of time π1, where

π1 =

≤

≤

C
x1
x1 + xk1 +

+ xkm ≤

x1 +

l

· · ·

−δ] ≤

x1
x1 + c+m−1−am

2a[maxl µkl
b−1
2b[−µ1+δ]
2b[−µ1+δ] + c−a
2a[µN

b−1

′ −δ]

x1 +

.

x1

c+m−1

m −a
−δ]

2a[µkl

x1
P
c−a

2a[µk

N

′ −δ]

}

GN ′
{

1 , is reached when

. This completes the proof.

We see that the maximum π1, namely π∗
Gk1 , . . . , Gkm }
=
{
Theorem 5 further conﬁrms that µ is indicative of the capabil-
ity of a conﬁguration in terms of “forcing” the overall dynamics
to converge to I ∗ = (0, . . . , 0). Eq. (22) says that π∗
1 is mono-
tonically increasing in µN ′ for ﬁxed µ1 and decreasing in µ1 for
ﬁxed µN ′ . Figure 4 conﬁrms this property with a = 0.8, b = 1.5,
c = 2.4, δ = 10−5, while Eq. (22) leads to π∗

1 =

′ −δ

µN
′ −6µ1+5δ .

µN

1*
π

1

0.8

0.6

0.4

0.2

0
1

0.8

0.6

µ

N’

0.4

0.2

1

0.8

0.2

0

0

0.4

0.6

−µ
1

Figure 4: Dependence of π∗

1 on

µ1 and µN ′ .

−

Remark. In Theorem 5 we consider a single conﬁguration
1
C
that violates condition (1). We can extend Theorem 5 to accom-
modate multiple conﬁgurations that violate condition (1), because
Theorem 4 can accommodate this scenario. However, if the goal is
to maximize the time that the system can stay in the conﬁgurations
that violate condition (1), the optimal solution is with respect to
j, where j is given by Eq. (18), such that the sys-
conﬁguration
C
tem will stay in
1 given by
Theorem 5.

j for the maximum portion of time π∗

C

4.2 Characterizing Power of MTD while Con-

sidering Cost

The goal is to make the dynamics converge to I ∗ = (0, . . . , 0),
at minimum cost of launching MTD, while the system stays a pre-
1. The preceding case proved
determined π1 portion of time in

C

is necessary to make the dynam-

condition (1). Suppose π1, where 0 < π1

l = 1,

, m′

· · ·

(23)

For given cost function g(
imum cost is

) with arbitrary constant g(µ1), the min-
·

that π1

b−1
2b[−µ1 +δ]
+

≤

b−1
2b[−µ1 +δ]

c−a

′ −δ]

2a[µN
ics converge to I ∗ = (0, . . . , 0). Let µl = β
γλ1(Al) for
R+ be the
): R+
l = 1, . . . , N ′. Let the cost function g(
·
same as discussed in Deﬁnition 2, namely that g(µl) is the cost of
launching MTD to induce
0
for µ > 0.

l for l = 2, . . . , N ′, where g′(µ)

−
→

≥

C

Let σt be the desired “law" for deploying MTD, and denote by

C

Q = [qjk] its inﬁnitesimal generator. Let xl = 1
−qll
is the expectation of sojourn time in conﬁguration
l is πl = xl
portion of time in
PN

1
, where
−qll
l. Then, the
. Our goal is to ﬁnd the “law"

′
l=1 xl
under which the cost is minimum. Theorem 4 speciﬁes the desired
Markov “law" σt via its inﬁnitesimal generator. Now we consider
cost function Ψ(x) with respect to x = [x1,
· · ·
Let Gkl for l = 1, . . . , m′ and m′
1 be the MTD-induced
≥
and
conﬁgurations, namely πk = 0 for k /
1, k1,
∈ {
, N ′
. Under the the deﬁnition of Q in
2,
k1,
}
{
Theorem 4, σt needs to satisfy:

, xN ′ ].

} ⊆ {

, km′

, km′

· · ·

· · ·

· · ·

C

}

0 < x1

xkl ≥

≤
c+m
m
2a[µkl

, ¯x1,

b−1
2b[−µ1+δ]
′−1
′ −a
, ¯xkl (m′),
−δ]
1, a < 1 < b < c.

0 < δ

≪




Note that

x1
x1+Pm
tions of time in conﬁgurations

′
l=1

and

xkl

xkl
′
x1+Pm
l=1
1 and

are respectively the por-

xkl
kl . Deﬁne

C

C

¯π1 ,

¯x1 +

¯x1
m′
l=1 ¯xkl (m′)

,

(24)

the maximum portion of time the system can stay in
1 when MTD
induces the m′ conﬁgurations. For any π1 such that π1 > ¯π1 does
not hold, π1 cannot be realised by a underlying Markov process.
Therefore, we assume that π∗
1 < ¯π1.

P

C

Denote the index set corresponding to Eq. (24) as

=

K

(cid:26)

k1,
{

· · ·

, km′

π∗
1 ≤

}|

¯x1 +

¯x1
m′
l=1 ¯xkl(m′)

, k1 <

· · ·

< km′

.

(cid:27)

k1,
{

For
, km′
· · ·
(23). From π1 =

} ∈ K

, we need to ﬁnd the “law" σt that satisﬁes
x1
x1.
′
x1+Pm
l=1 xkl

l=1 xkl = 1−π1
π1

P
, we have

′
m

The cost of launching MTD according to “law" σt is:

P

Ψ(x1, xk1 ,

, xkm

′ )

· · ·
′
m

= π1g(µ1) +

πkl g(µkl)

l=1
X

= π1g(µ1) + (1

π∗
1 )

−

P

′
m
l=1 xklg(µkl )
m′
l=1 xkl

P

subject to

′−1

xkl ≥

′
m

c+m
−a
ℓ
−δ] ,
2a[µkl
l=1 xkl = 1−π1
π1
0 < δ

l = 1,

, m′

x1

· · ·
1−π1
π1
1, a < 1 < b < c.

¯x1,

≤

P

≪






We want to compute the minimize cost

(25)

(26)

min
x,{k1,··· ,km

′ }∈K

Ψ(x1, xk1 ,

, xkm

′ ).

· · ·

THEOREM 6. Given conﬁguration

and MTD-induced conﬁgurations

C

1 that violates condition (1)
l for l = 2, . . . , N ′ that satisfy

C

b−1
2b[−µ1 +δ]
+

≤

b−1
2b[−µ1 +δ]

c−a

2a[µN

′ −δ]

,

C

is the portion of time that the system must stay in

1. Denote by

G(k1,
ℓ

· · ·

, km′ )

l=1 ¯xkl (m′)g(µkl) + g(µk1 )∆(k1,
m′
l=1 ¯xkl (m′) + ∆(k1,

· · ·
, km′ )

, km′ )

,

=

P

· · ·

where

P

¯xkl(m′) =

∆(k1,

· · ·

, km′ ) =

We want to ﬁnd

k∗
1 ,
{
, µk∗

m }

, k∗

m}

· · ·
= arg

,

µk∗
{
1

· · ·

a
δ]

′
c+m
ℓ

−1

−
2a[µkl −
π1
1

¯x1

−
π1

,

′
m

−

l=1
X

such that

¯xkl(m′).

min
{k1,··· ,km

′ }∈K

G(k1,

· · ·

, km′ )

(27)

min
x,{k1,··· ,km
= Ψ(¯x1, ¯xk∗
1

= π1g(µ1) + (1

−

Ψ(x1, xk1 ,

′ }∈K

(m) + ∆,

, ¯xk∗

· · ·
π1)G(k∗
1 ,

′ )

, xkm

· · ·
m (m))
, k∗
m),

· · ·

which is reached by launching MTD to induce conﬁguration
(Gk∗
{
l

m
l=1 via the following deployment strategy:
}

, β, γ)

πk∗
1

= (1

πk∗
l

= (1

−

−

π1)

¯xk∗
1
m
l=1 ¯xk∗

l

(m) + ∆(k∗
1 ,

· · ·
(m) + ∆(k∗
1 ,

P

π1)

(m)

¯xk∗
l
(m) + ∆(k∗
1 ,

m
l=1 ¯xk∗

l

, k∗

m)
, k∗

m)

· · ·

· · ·

,

(28)

, k∗

m)

, l = 2,

, m.

· · ·

Hence, MTD is (µ1, . . . , µN ′ , π1, Ψ)-powerful.

P

k1,
{
¯xkl(m′) for l = 1,

. We introduce variables
PROOF. Suppose
′
m
ζ 2
kl = xkl −
l=1 xkl
¯x1
· · ·
and translate the minimum problem speciﬁed by (25)-(26) into the
following minimum problem:

} ∈ K
, m′, ζ 2 = 1−π1
π1

, km′

· · ·

P

−

Ψ(x1, xk1 ,

· · ·

, xkm

′ ) = π1g(µ1) + (1

′
m
l=1 xkl g(µkl)
m′
l=1 xkl

π1)

−

P

subject to

xkl = ζ 2
′
m

kl + ¯xkl (m′),
x1,

l=1 xkl = 1−π1
π1
l=1 xkl + ζ 2 = 1−π1
π1

′
m




P

P

l = 1,

· · ·

, m′,

¯x1.

P


Let x = [xk1 ,
α = [α′, α′′, αk1 · · ·

· · ·

, xkm

′ ], ζ = [ζk1 · · ·
, αkm

, ζkm

′ ], and

′ ]. We study the Lagrange function

Λ1(x, ζ, α) = Ψ(x1, xk1 ,

, xkm

′ ) +

· · ·

αkl [xkl −

ζ 2
kl −

¯xkl(m′)] + α′

xkl −

1

π1

−
π1

x1

′
m

l=1
X

′
m




′
m

l=1
X

xkl + ζ 2

1

π1

−
π1

−

α′′





l=1
X

+





¯x1

.





Find all stationary points
}
The x parts of stationary points are

x, ζ, α

{

of Λ1, with gradient

Λ1 = 0.

∇

X1 =

Xl =

′
m

π1

l=1 ¯xkl(m′)
π1
1
"
P
¯x1, ¯xk1 (m′),
l = 1,

· · ·

−

(cid:2)

· · ·

, ¯xk1 (m′),

, ¯xkℓ (m′)

,

#

· · ·

′ (m′)

, ¯xkm
, m′,

+ el+1∆(k1,

, km′ ),

· · ·

(cid:3)

′

Lines 9-21 correspond to the case of considering cost. Speciﬁcally,
line 9 incurs complexity O(2N
), which is not infeasible because
in practice N ′ (i.e., the number of MTD-induced conﬁgurations)
is often small. Possible instances of conﬁgurations the system will
∗
stay include
1 , . . . and
k∗
k∗
2
1

m ,
k∗
C
C
∗
1 , . . ..
m,
k∗

1,
C
C
, Ck∗
1

k∗
1
, . . . ,

, . . . ,

C
5. LIMITATIONS OF THE MODEL

1,

C

C

C

C

,

where el is the vector whose l-th element equals 1 and any other
element equals 0.

By comparing the costs of these stationary points, we ﬁnd the

minimum cost of launching these ℓ conﬁgurations is

First, the present study assumes that the attack-defense struc-
tures and parameters are given. It is sufﬁcient for characterizing
the power of MTD. Nevertheless, it is important to study how to
obtain such structures and parameters.

π1g(µ1) + (1

π1)G(k1,

, km′ ).

· · ·

−

This complete the proof.

C

Remark. Similar to Theorem 5, in Theorem 6 we consider a
single conﬁguration
1 that violates condition (1). We also can
extend Theorem 6 to accommodate multiple conﬁgurations that vi-
olate condition (1), because Theorem 4 can accommodate this sce-
nario. The extension is straightforward because the portions of time
that are allocated to the violating conﬁgurations are ﬁxed and not
involved in the deﬁnition of cost.

4.3 Algorithm for Launching Optimal MTD

Theorems 5 and 6 are constructive and lead to Algorithm 2 that

can guide the deployment of optimal MTD.

C

≥

1, optional cost function g(

C
l for l = 2, . . . , N ′ and N ′

), MTD-
·
2, constant a > 0 (de-

Algorithm 2 Launching optimal MTD (dynamic structures)
INPUT: conﬁguration
induced
termining time resolution), δ (0 < δ << 1), optional π1
OUTPUT: Optimal MTD strategy
1: if cost function is not given (i.e., no need to consider cost) then
2:
3:
4:
5:

Wait for time T1
Launch MTD to force the system to stay in conﬁguration
CN ′ for time TN ′
1 ))
←
Stop launching MTD {system returns to

Compute π∗
while TRUE do

1 according to Eq. (22)

1 ) {system in

exp(a/π∗

exp(a/(1

π∗

←

1}

−

C

1}

C

6:
7:
8: else
9:
10:

end while

Find indices k∗
1 ,
Set πk∗
, . . . , πk∗
1
k

, k∗

m according to Eq. (27)

· · ·
m as deﬁned in Eq. (28) and πk = 0 for

R

C

1}

} − {
←
, k∗

1 , . . . , k∗
k∗
m}
exp(a/π1) {system in
m}

2, . . . , N ′
∈ {
11: Wait for time T1
k∗
k∗
12:
1 ,
j ←
· · ·
{
13:
while TRUE do
Launch MTD to make the system stay in
14:
exp(a/πk∗
Tk∗
j ←
j
1, k∗
Set ∆ =
1 ,
· · ·
{
k∗
k∗
R ∆
j }
j ←
− {
if k∗
j = 1 then
Stop launching MTD to make the system stay in
time T1
k∗
R
j ←
end if
end while

exp(a/π1)
←
k∗
1 ,
m}
{

15:
16:
17:
18:

m} − {

k∗
j }

, k∗

, k∗

· · ·

k∗
j

C

)

19:
20:
21:
22: end if

for time

1 for

C

In Algorithm 2, lines 2-7 correspond to the case of not consid-
ering cost, where each step incurs O(1) computational complexity.

Second, the present study does not allow the attacker to choose
1. It is important to give the attack
when to impose conﬁguration
the freedom in choosing when to impose
1. This incurs technical
difﬁculties. For example, the portion of time in the violating con-
ﬁguration may not be ﬁxed at π1, which breaks the setting of the
optimisation problem.

C

C

Third, it is interesting to extend the model to accommodate het-
erogeneous γv,u and βv. However, this will make the model difﬁ-
cult to analyze mainly because of accommodating βv.

6. CONCLUSION

We have introduced an approach of using cyber epidemic dy-
namics to characterize the power of MTD. The approach offers
algorithms for optimally deploying MTD, where “optimization"
means maximizing the portion of time the system can afford to stay
in an undesired conﬁguration, or minimizing the cost of launching
MTD when the system has to stay in an undesired conﬁguration for
a predetermined portion of time. We have discussed the limitations
of the present study, which should inspire fruitful future research.

Acknowledgement. Wenlian Lu was supported by a Marie Curie
International Incoming Fellowship from European Commission (no.
FP7-PEOPLE-2011-IIF-302421), National Natural Sciences Foun-
dation of China (no. 61273309), and Program for New Century
Excellent Talents in University (no. NCET-13-0139). Shouhuai
Xu was supported in part by ARO Grant #W911NF-12-1-0286 and
AFOSR Grant FA9550-09-1-0165. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this material are those
of the author(s) and do not necessarily reﬂect the views of any of
the funding agencies.

7. REFERENCES
[1] S. Antonatos, P. Akritidis, E. Markatos, and K.

Anagnostakis. Defending against hitlist worms using
network address space randomization. In Proc. (WORM’05),
pages 30–40.

[2] M. Atighetchi, P. Pal, F. Webber, and C. Jones. Adaptive use
of network-centric mechanisms in cyber-defense. In IEEE
Symposium on Object-Oriented Real-Time Distributed
Computing, 2003, pages 183–192, 2003.

[3] A. Avizienis. The n-version approach to fault-tolerant

software. IEEE Transactions on Software Engineering,
(12):1491–1501, 1985.

[4] E. Barrantes, D. Ackley, S. Forrest, and D. Stefanovi´c.
Randomized instruction set emulation. ACM TISSEC,
8(1):3–40, 2005.

[5] E. Barrantes, D. Ackley, T. Palmer, D. Stefanovic, and D.

Zovi. Randomized instruction set emulation to disrupt binary
code injection attacks. In Proc. ACM CCS’03, pages
281–289.

[6] S. Bhatkar, D. DuVarney, and R. Sekar. Address obfuscation:
An efﬁcient approach to combat a board range of memory
error exploits. In USENIX Security Symposium, 2003.

[27] D. Kewley, R. Fink, J. Lowry, and M. Dean. Dynamic

approaches to thwart adversary intelligence gathering. In
Proc. DISCEX’01.

[7] S. Boyd, G. Kc, M. Locasto, A. Keromytis, and V.

[28] V. Kiriansky, D. Bruening, and S. Amarasinghe. Secure

Prevelakis. On the general applicability of instruction-set
randomization. IEEE TDSC, 7(3):255–270, July 2010.

execution via program shepherding. In Proc. USENIX
Security’02.

[8] D. Bruening, T. Garnett, and S. Amarasinghe. An

[29] D. Liberzon. Switching in Systems and Control. Birkhauser,

infrastructure for adaptive dynamic optimization. In Proc.
CGO’03, pages 265–275.

[9] J. Cai, V. Yegneswaran, C. Alfeld, and P. Barford. An

attacker-defender game for honeynets. In COCOON, pages
7–16, 2009.

Boston, MA, 2003.

[30] C. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V. Reddi, and K. Hazelwood. Pin: Building
customized program analysis tools with dynamic
instrumentation. In Proc. PLDI’05.

[10] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and

[31] P. Manadhata. Game theoretic approaches to attack surface

C. Faloutsos. Epidemic thresholds in real networks. ACM
TISSEC, 10(4):1–26, 2008.

shifting. In Moving Target Defense II, pages 1–13. 2013.

[32] M. Mariton. Jump linear systems in automatic control.

[11] Frederick B. Cohen. Operating system protection through

Marcel dekker, New York, 1990.

program evolution. Comput. Secur., 12(6):565–584, October
1993.

[12] Y. Desmedt and Y. Frankel. Threshold cryptosystems. In

Proc. CRYPTO 89, pages 307–315.

[13] E. B. Dynkin. Markov processes. Springer, Berlin, 1965.
[14] S. Forrest, A. Somayaji, and D. Ackley. Building diverse

computer systems. In Proc. HotOS-VI.

[15] A. Ganesh, L. Massoulie, and D. Towsley. The effect of

network topology on the spread of epidemics. In Proc. IEEE
Infocom 2005.

[16] C. Giuffrida, A. Kuijsten, and A. Tanenbaum. Enhanced

operating system security through efﬁcient and ﬁne-grained
address space randomization. In Proc. USENIX Security’12.

[17] A. Herzberg, M. Jakobsson, S. Jarecki, H. Krawczyk, and
M. Yung. Proactive public key and signature schemes. In
Proc. ACM CCS’97.

[18] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J.W.
Davidson. Ilr: Where’d my gadgets go? In Proc. IEEE
Security and Privacy 2012.

[19] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz.

Librando: transparent code randomization for just-in-time
compilers. In Proc. ACM CCS’13.

[20] T. Jackson, B. Salamat, A. Homescu, K. Manivannan, G.

Wagner, A. Gal, S. Brunthaler, C. Wimmer, and M. Franz.
Diversifying the Software Stack Using Randomized NOP
Insertion In S. Jajodia, A. Ghosh, V. Swarup, C. Wang, and
X. Wang, editors, Moving Target Defense, pages 77–98.
[21] J. Jafarian, E. Al-Shaer, and Q. Duan. Openﬂow random host
mutation: Transparent moving target defense using software
deﬁned networking. In Proc. HotSDN’12.

[22] G. Kc, A. Keromytis, and V. Prevelakis. Countering

code-injection attacks with instruction-set randomization. In
Proc. ACM CCS’03.

[23] Eric Keller, Soudeh Ghorbani, Matt Caesar, and Jennifer

Rexford. Live migration of an entire network (and its hosts).
In Proc. HotNets’12.

[24] J. Kephart and S. White. Directed-graph epidemiological

models of computer viruses. In IEEE Symp. on Security and
Privacy’91. 1991.

[25] J. Kephart and S. White. Measuring and modeling computer
virus prevalence. In IEEE Symposium on Security and
Privacy’93.

[26] W. Kermack and A. McKendrick. A contribution to the

mathematical theory of epidemics. Proc. of Roy. Soc. Lond.
A, 115:700–721, 1927.

[33] A. McKendrick. Applications of mathematics to medical
problems. Proc. of Edin. Math. Soceity, 14:98–130, 1926.
[34] N. Nethercote and J. Seward. Valgrind: A framework for

heavyweight dynamic binary instrumentation. In Proc.
PLDI’07.

[35] A. Papadogiannakis, L. Loutsis, V. Papaefstathiou, and S.
Ioannidis. Asist: Architectural support for instruction set
randomization. In ACM CCS’13.

[36] V. Pappas, M. Polychronakis, and A. Keromytis. Smashing
the gadgets: Hindering return-oriented programming using
in-place code randomization. In IEEE Symp. on Security and
Privacy’12.

[37] R. Pastor-Satorras and A. Vespignani. Epidemic dynamics in

ﬁnite size scale-free networks. Physical Review E,
65:035108, 2002.

[38] B. Prakash, H. Tong, N. Valler, M. Faloutsos, and

C. Faloutsos. Virus propagation on time-varying networks:
Theory and immunization algorithms. In ECML/PKDD (3),
pages 99–114, 2010.

[39] M. Rami, V. Bokharaie, O. Mason, and F. Wirth. Stability

criteria for sis epidemiological models under switching
policies, 2013.

[40] A. Shamir. How to share a secret. CACM, 22:612–613, 1979.
[41] A. Sovarel, D. Evans, and N. Paul. Where’s the feeb? the
effectiveness of instruction set randomization. In Pro.
USENIX Security’05.

[42] The PaX Team. http://pax.grsecurity.net/docs/aslr.txt.
[43] G. Teschl. Ordinary Differential Equations and Dynamical

Systems. American Mathematical Society, 2010.

[44] Piet Van Mieghem, Jasmina Omic, and Robert Kooij. Virus

spread in networks. IEEE/ACM Trans. Netw., 17(1):1–14,
February 2009.

[45] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos.
Epidemic spreading in real networks: An eigenvalue
viewpoint. In SRDS’03, pages 25–34.

[46] R. Wartell, V. Mohan, K. Hamlen, and Z. Lin. Binary

stirring: Self-randomizing instruction addresses of legacy
x86 binary code. In CCS’12

[47] Yoav Weiss and Elena Gabriela Barrantes. Known/chosen

key attacks against software instruction set randomization. In
Proc. ACSAC’06.

[48] D. William, Z. Jiang, H. Jamjoom, and H. Weatherspoon.

Virtualwires for live migrating virtual networks across clouds
(IBM TR rc25378, 2013).

[49] S. Xu. Cybersecurity dynamics. In HotSoS’14 (poster).

[50] S. Xu, W. Lu, L. Xu, and Z. Zhan. Adaptive epidemic

dynamics in networks: Thresholds and control. ACM TAAS,
8(4):19, 2014.

[51] S. Xu, W. Lu, and L. Xu. Push- and pull-based epidemic

spreading in networks: Thresholds and deeper insights. ACM
TAAS, 7(3):32, 2012.

[52] S. Xu, W. Lu, and Z. Zhan. A stochastic model of multivirus

dynamics. IEEE Trans. Dependable Sec. Comput.,
9(1):30–45, 2012.

[53] J. Yackoski, H. Bullen, X. Yu, and J. Li. Applying

self-shielding dynamics to the network architecture. In
Moving Target Defense II, pp 97–115. 2013.
[54] Q. Zhu and T. Basar. Game-theoretic approach to

feedback-driven multi-stage moving target defense. In Porc.
GameSec’13, pages 246–263.

APPENDIX
Now we present the proof of Theorem 3.

≥

k∗, we have π1µ1 + (1

PROOF. For any m

π1)µm > 0,
meaning that the dynamics will converge to I ∗ = 0 by launching
MTD to induce conﬁguration
1 . For
C
−
any l < k∗, we have π1µ1 + (1
0, meaning that con-
−
dition (2) for the dynamics to converge to I ∗ = 0 is not satisﬁed
l with
even if the defender launches MTD to induce conﬁguration
portion of time 1

m with portion of time 1

π1)µl

π∗

−

≤

C

If k∗ = 2, the dynamics will converge to I ∗ = 0 by launch-
) is non-
·

ing MTD to induce conﬁguration
decreasing, we have

2. Since f (

l, l

≥

C

π∗
1 .

−

Φ(π2,

· · ·

, πN ) = π1f (µ1) +

πlf (µl)

N

l=2
X
π1f (µ1) + (1
−

≥

π1)f (µ2).

−

It can be seen that the equality above can be guaranteed by taking
π2 = 1

π∗
1 and πj = 0 for j > 2.

If k∗ > 2, we use Lagrange multipliers to calculate the mini-
mum cost Φ(π), subject to constraint (11). Since Lagrange multi-
pliers require equality constraints, we introduce vector of variables
j and variable ζ with
x = [x2,
ζ 2 = π1µ1 +
δ, such that solving the minimiza-
j −
tion problem is equivalent to ﬁnding the minimum of the following
N
function Φ1(x) = π1f (µ1) +

, xN ] with xj satisfying πj = x2

j f (µj ) subject to

j=2 µj x2

· · ·

P

N

j=2 x2

h1(x) =

N

P
µj x2

j =

π1µ1 + δ + ζ 2

−

h2(x) =

j=2
X
N

j=2
X

x2
j = 1

π1,

−

where Φ1,h1, and h2 have continuous ﬁrst partial derivatives. To
solve this variant problem, we introduce Lagrange multipliers α1
and α2 and the Lagrange function as follows

Λ(x, ζ, α1, α2) =Φ1(x) + α1[h1(x) + π1µ1

+ α2[h2(x) + π1

1].

−

δ

−

−

ζ 2]

Denote by Φ1(x0) the minimum of Φ1(x). There exist ¯α1 and
¯α2 such that (x0, ζ0, ¯α1, ¯α2) is a stationary point for the Lagrange
Λ = 0. Then, we are
function Λ(x, ζ, α1, α2), i.e., with gradient

∇

to solve

∇

Λ = 0:
x2 Λ = 2[f (µ2) + α1µ2 + α2]x2 = 0

...

∇

∇
∇
∇
∇






xN Λ = 2[f (µN ) + α1µN + α2]xN = 0
ζΛ =
−
α1 Λ =
α2 Λ =

2α1ζ = 0
j=2 µj x2
j=2 x2

δ
−
1 = 0,

j + π1µ1

j + π1

−

N

N

ζ 2 = 0

(29)

P
−
To solve (29), there are three cases:
P
Case 1: The optimal strategy is that the defender launches MTD
k∗ must hold
to induce only one conﬁguration
π1)f (µm). Hence, the
and the cost is Φ1(x) = π1f (µ1) + (1
minimum cost of launching MTD to induce a single conﬁguration
is

m. Then, m

−

≥

C

π1f (µ1) + (1

π1)f (µk∗ ),

(30)

−

k∗.

C

which is reached when inducing conﬁguration

C

l,

Case 2: The optimal strategy is that the defender launches MTD
m. The minimum cost will be
to induce two conﬁgurations
reached at l < k∗
m because the cost function f (µ) is non-
decreasing in µ > 0. Firstly, we look for the minimal cost when
m.
launching MTD to induce conﬁgurations
This requires to ﬁnd stationary points of Λ(x, ζ, α1, α2) such that
x2
l > 0, x2
= l, m. It can be veriﬁed
that the following points are stationary points for Λ(x, ζ, α1, α2):

m > 0 and x2

m, l < k∗

k = 0 for k

2, k

≤

≤

≥

l,

C

C

C

x2
l
x2
m (cid:21)

(cid:20)

=

µk

1

−

µ1 (cid:20)

δ) + π1(µ1
δ) + π1(µl

(µm
−
(µl
−
ζ = 0, x2
k = 0, k

−

−
−
2, k

µm)
µ1)

(cid:21)
= l, m.

,

≥

and the corresponding cost is F (µl, µm). Hence, the minimum
cost of inducing two conﬁgurations is

min
l<k∗≤m

F (µl, µm),

(31)

which is reached by launching MTD to induce conﬁgurations
according to πl∗ , πm∗ in Eq. (15).

C

l∗,

m∗

C

Case 3: The optimal strategy is that the defender launches MTD
to induce m′
m′. To ﬁnd the
minimum cost, we need to ﬁnd stationary points of Λ(x, ζ, α1, α2)
such that x2
= kj .
That is,

C
m′ and x2

3 conﬁgurations

k = 0 for k

kj > 0, 1

kj , 1

2, k

≤

≤

≤

≥

≤

≥

j

j

(32)

f (µk1 ) + α1µk1 + α2 = 0

...
f (µkm
Thus, the stationary point x should satisfy

′ ) + α1µkm




′ + α2 = 0.


x2
k1 µk1 +
¯x2
k1 +
· · ·
¯x2
kl > 0, 1






+ ¯x2

· · ·
+ ¯x2
km
l

′ µkm

km
′ = 1

−
m′, x2

−

′ = δ
π1
k = 0, k

π1µ1

, ζ = 0.

2, k

= kl

≥
The cost at this stationary points x becomes

≤

≤

Φ =x2

k1 f (µk1 ) +

· · ·
π1µ1)α1

(δ

=
−
=F (µk1 , µk2 ).

−

+ x2

km
(1

′ f (µkm
π1)α2

−

−

′ )

(33)

j

≤

m′ and x2

If (32) does not hold, then there is no stationary point x in the form
x2
= kj , meaning
kj > 0, 1
that there is no minimum cost when inducing these conﬁgurations.
By comparing the costs given by Eqs. (30), (31), and (33), we
conclude that the minimum cost is given by Eq. (31). This com-
pletes the proof.

k = 0 for k

2, k

≥

≤

6
6
6
6
6
