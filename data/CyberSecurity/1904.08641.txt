9
1
0
2

r
p
A
8
1

]

O
L
.
s
c
[

1
v
1
4
6
8
0
.
4
0
9
1
:
v
i
X
r
a

Doping Tests for Cyber-Physical Systems(cid:63)

Sebastian Biewer1, Pedro D’Argenio1,2,3, and Holger Hermanns1

1 Saarland University, Saarland Informatics Campus, Germany
2 Universidad Nacional de C´ordoba, FAMAF, Argentina
3 CONICET, Argentina

Abstract. The software running in embedded or cyber-physical systems
(CPS) is typically of proprietary nature, so users do not know precisely
what the systems they own are (in)capable of doing. Most malfunction-
ings of such systems are not intended by the manufacturer, but some
are, which means these cannot be classiﬁed as bugs or security loopholes.
The most prominent examples have become public in the diesel emissions
scandal, where millions of cars were found to be equipped with software
violating the law, altogether polluting the environment and putting hu-
man health at risk. The behaviour of the software embedded in these
cars was intended by the manufacturer, but it was not in the interest of
society, a phenomenon that has been called software doping. Doped soft-
ware is signiﬁcantly diﬀerent from buggy or insecure software and hence
it is not possible to use classical veriﬁcation and testing techniques to
discover and mitigate software doping.
The work presented in this paper builds on existing deﬁnitions of soft-
ware doping and lays the theoretical foundations for conducting software
doping tests, so as to enable attacking evil manufacturers. The complex
nature of software doping makes it very hard to eﬀectuate doping tests in
practice. We explain the biggest challenges and provide eﬃcient solutions
to realise doping tests despite this complexity.

1

Introduction

Embedded and cyber-physical systems are becoming more and more widespread
as part of our daily life. Printers, mobile phones, smart watches, smart home
equipment, virtual assistants, drones and batteries are just a few examples. Mod-
ern cars are even composed of a multitude of such systems. These systems can
have a huge impact on our lives, especially if they do not work as expected. As
a result, numerous approaches exist to assure quality of a system. The classical
and most common type of malfunctioning is what is widely called “bug”. Usu-
ally, a bug is a very small mistake in the software or hardware that causes a

(cid:63) This work is partly supported by the ERC Grant 695614 (POWVER) by the
Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) grant
389792660 as part of TRR 248, see https://perspicuous-computing.science, by
the Saarbr¨ucken Graduate School of Computer Science, by the Sino-German CDZ
project 1023 (CAP), by ANPCyT PICT-2017-3894 (RAFTSys), and by secyt-unc
33620180100354CB (ARES).

 
 
 
 
 
 
2

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

behaviour that is not intended or expected. Other types of malfunctioning are
caused by incorrect or wrongly interpreted sensor data, physical deﬁciencies of
a component, or are simply radiation-induced.

Another interesting kind of malfunction (also from an ethical perspective [4])
arises if the expectation of how the system should behave is diﬀerent for two (or
more) parties. Examples for such scenarios are widespread in the context of per-
sonal data privacy, where product manufacturers and data protection agencies
have notoriously diﬀerent opinions about how a software is supposed to han-
dle personal data. Another example is the usage of third-party cartridges in
printers. Manufacturers and users do not agree on whether their printer should
work with third-party cartridges (the user’s opinion) or only with those sold by
the manufacturer (the manufacturer’s opinion). Lastly, an example that received
very high media attention are emission cleaning systems in diesel cars. There are
regulations for dangerous particles and gases like CO2 and NO2 deﬁning how
much of these substances are allowed to be emitted during car operation. Part of
these regulations are emissions tests, precisely deﬁned test cycles that a car has
to undergo on a chassis dynamometer [28]. Car manufacturers have to obey to
these regulations in order to get admission to sell a new car model. The central
weakness of these regulations is that the relevant behaviour of the car is only
a trickle of the possible behaviour on the road. Indeed, several manufacturers
equipped their cars with defeat devices that recognise if the car is undergoing
an oﬃcial emissions test. During the test, the car obeys the regulation, but out-
side test conditions, the emissions extruded are often signiﬁcantly higher than
allowed. Generally speaking, the phenomena described above are considered as
incorrect software behaviour by one party, but as intended software behaviour by
the other party (usually the manufacturer). In the literature, such phenomena
are called software doping [3,10].

The diﬀerence between software doping and bugs is threefold: (1) There is a
disagreement of intentions about what the software should do. (2) While a bug
is most often a small coding error, software doping can be present in a consider-
able portion of the implementation. (3) Bugs can potentially be detected during
production by the manufacturer, whereas software doping needs to be uncovered
after production, by the other party facing the ﬁnal product. Embedded software
is typically proprietary, so (unless one ﬁnds a way to breach into the intellectual
property [9]) it is only possible to detect software doping by observation of the
behaviour of the product, i.e., by black-box testing.

This paper develops the foundations for black-box testing approaches geared
towards uncovering doped software in concrete cases. We will start oﬀ from an
established formal notion of robust cleanness (which is the negation of software
doping) [10]. Essentially, the idea of robust cleanness is based on a succinct
speciﬁcation (called a “contract”) capturing the intended behaviour of a system
with respect to all inputs to the system. Inputs are considered to be user inputs
or environmental inputs given by sensors. The contract is deﬁned by input and
output distances on standard system trajectories supplemented by input and
output thresholds. Simply put, the input distance and threshold induce a tube

Doping Tests for Cyber-Physical Systems

3

around the standard inputs, and similar for outputs. For any input in the tube
around some standard input the system must be able to react with an output
that is in the tube around the output possible according to the standard.

Example 1. For a diesel car the standard trajectory is the behaviour exhibited
during the oﬃcial emissions test cycle. The input distance measures the deviation
in car speed from the standard. The input threshold is a small number larger
than the acceptable error tolerance of the cycle limiting the inputs considered of
interest. The output distance then is the diﬀerence between (the total amount
of) NOx extruded by the car facing inputs of interest and that extruded if on
the standard test cycle. For cars with an active defeat device we expect to see a
violation of the contract even for relatively large output thresholds.

A cyber-physical system (CPS) is inﬂuenced by physical or chemical dynam-
ics. Some of this can be observed by the sensors the CPS is equipped with,
but some portion might remain unknown, making proper analysis diﬃcult. Non-
determinsm is a powerful way of representing such uncertainty faithfully, and
indeed the notion of robust cleanness supports non-deterministic reactive sys-
tems [10]. Furthermore, the analysis needs to consider (at least) two trajectories
simultaneously, namely the standard trajectory and another that stays within
the input tube. In the presence of nondeterminism it might even become neces-
sary to consider inﬁnitely many trajectories at the same time. Properties over
multiple traces are called hyperproperties [8]. In this respect, expressing robust
cleanness as a hyperproperty needs both ∀ and ∃ trajectory quantiﬁers. Formu-
las containing only one type of quantiﬁer can be analysed eﬃciently, e.g., using
model-checking techniques, but checking properties with alternating quantiﬁers
is known to be very complex [7,16]. Even more, testing of such problems is
in general not possible. Assume, for example, a property requiring for a (non-
deterministic) system that for every input i, there exists the output o = i, i.e.,
one of the systems possible behaviours computes the identity function. For black-
box systems with inﬁnite input and output domains the property can neither be
veriﬁed nor falsiﬁed through testing. In order to verify the property, it is neces-
sary to iterate over the inﬁnite input set. For falsiﬁcation one must show that for
some i the system can not produce i as output. However, not observing an out-
put in ﬁnitely many steps does not rule out that this output can be generated.
As a result, there is no prior work (we are aware of) that targets the automatic
generation of test cases for hyperproperties, let alone robust cleanness.

The contribution of this paper is three-fold. (1) We observe that standard
behaviour, in particular when derived by common standardisation procedures,
can be represented by ﬁnite models, and we identify under which conditions
the resulting contracts are (un)satisﬁable. (2) For a given satisﬁable contract we
construct the largest non-deterministic model that is robustly clean w.r.t. this
contract. We integrate this model into a model-based testing theory, which can
provide a non-deterministic algorithm to derive sound test suites. (3) We develop
a testing algorithm for bounded-length tests and discretised input/output values.
We present test cases for the diesel emissions scandal and execute these tests
with a real car on a chassis dynamometer.

4

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

2 Software Doping on Reactive Programs

Embedded software is reactive, it reacts to inputs received from sensors by pro-
ducing outputs that are meant to control the device functionality. We consider a
reactive program as a function P : Inω → 2(Outω) on inﬁnite sequences of inputs
so that the program reacts to the k-th input in the input sequence by produc-
ing non-deterministically the k-th output in each respective output sequence.
Thus, the program can be seen, for instance, as a (non-deterministic) Mealy or
Moore machine. Moreover, we consider an equivalence relation ≈ ⊆ Inω × Inω
that equates sequences of inputs. To illustrate this, think of the program em-
bedded in a printer. Here ≈ would for instance equate input sequences that
agree with respect to submitting the same documents regardless of the cartridge
brand, the level of the toner (as long as there is suﬃcient), etc. We furthermore
consider the set StdIn ⊆ Inω of inputs of interest or standard inputs. In the pre-
vious example, StdIn contains all the input sequences with compatible cartridges
and printable documents. The deﬁnitions given below are simple adaptations of
those given in [10] (but where parameters are instead treated as parts of the
inputs).

Deﬁnition 1. A reactive program P is clean if for all inputs i, i(cid:48) ∈ StdIn such
that i ≈ i(cid:48), P (i) = P (i(cid:48)). Otherwise it is doped.

This deﬁnition states that a program is clean if its execution exhibits the same
visible sequence of output when supplied with two equivalent inputs, provided
such inputs comply with the given standard StdIn. Notice that the behaviour
outside StdIn is deemed immediately clean since it is of no interest.

In the context of the printer example, a program that would fail to print a
document when provided with an ink cartridge from a third-party manufacturer,
but would otherwise succeed to print would be considered doped, since this
diﬀerence in output behaviour is captured by the above deﬁnition. For this,
the inputs (being pairs of document and printer cartridge) must be considered
equivalent (not identical), which comes down to ink cartridges being compatible.
However, the above deﬁnition is not very helpful for cases that need to pre-
serve certain intended behaviour outside of the standard inputs StdIn. This is
clearly the case in the diesel emissions scandal where the standard inputs are
given precisely by the emissions test, but the behaviour observed there is assumed
to generalise beyond the singularity of this test setup. It is meant to ensure that
the amount of NO2 and NO (abbreviated as NOx) in the car exhaust gas does
not deviate considerably in general, and comes with a legal prohibition of defeat
mechanisms that simply turn oﬀ the cleaning mechanism. This legal framework
is obviously a bit short sighted, since it can be circumvented by mechanisms that
alter the behaviour gradually in a continuous manner, but in eﬀect drastically.
In a nutshell, one expects that if the input values observed by the electronic
control unit (ECU) of a diesel vehicle deviate within “reasonable distance” from
the standard input values provided during the lab emission test, the amount of
NOx found in the exhaust gas is still within the regulated threshold, or at least
it does not exceed it more than a “reasonable amount”.

Doping Tests for Cyber-Physical Systems

5

This motivates the need to introduce the notion of distances on inputs and
outputs. More precisely, we consider distances on ﬁnite traces: dIn : (In∗ × In∗) →
R≥0 and dOut : (Out∗ × Out∗) → R≥0. Such distances are required to be pseu-
dometrics. (d is a pseudometric if d(x, x) = 0, d(x, y) = d(y, x) and d(x, y) ≤
d(x, z) + d(z, y) for all x, y, and z.) With this, D’Argenio et. al [10] provide a
deﬁnition of robust cleanness that considers two parameters: parameter κi refers
to the acceptable distance an input may deviate from the norm to be still consid-
ered, and parameter κo that tells how far apart outputs are allowed to be in case
their respective inputs are within κi distance (Def. 2 spells out the Hausdorﬀ
distance used in [10]).

Deﬁnition 2. Let σ[..k] denote the k-th preﬁx of the sequence σ. A reactive
program P is robustly clean if for all input sequences i, i(cid:48) ∈ Inω with i ∈ StdIn,
for all k ≥ 0 such that dIn(i[..j], i(cid:48)[..j]) ≤ κi for all j ≤ k, the following holds:
(1) for all o ∈ P (i) there exists o(cid:48) ∈ P (i(cid:48)) such that dOut(o, o(cid:48)) ≤ κo, and
(2) for all o(cid:48) ∈ P (i(cid:48)) there exists o ∈ P (i) such that dOut(o, o(cid:48)) ≤ κo,
where P (i)[..k] = {o[..k] | o ∈ P (i)} and similarly for P (i(cid:48))[..k].

Notice that this is what we actually need for the non-deterministic case: each
output of one of the program instances should be matched within “reasonable
distance” by some output of the other program instance. Also notice that i(cid:48)
does not need to satisfy StdIn, but it will be considered as long as it is within
κi distance of any input satisfying StdIn. In such a case, outputs generated by
P (i(cid:48)) will be requested to be within κo distance of some output generated by the
respective execution induced by a standard input.

We remark that Def. 2 entails the existence of a contract which deﬁnes the
set of standard inputs StdIn, the tolerance parameters κi and κo as well as the
distances dIn and dOut. In the context of diesel engines, one might imagine that
the values to be considered, especially the tolerance parameters κi and κo for a
particular car model are made publicly available (or are even advertised by the
car manufacturer), so as to enable potential customers to discriminate between
diﬀerent car models according to the robustness they reach in being clean. It is
also imaginable that the tolerances and distances are ﬁxed by the legal authori-
ties as part of environmental regulations.

3 Robustly Clean Labelled Transition Systems

This section develops the framework needed for an eﬀective theory of black-box
doping tests based on the above concepts. In this, the standard behaviour (e.g.
as deﬁned by the emission tests) and the robust cleanness deﬁnitions together
will induce a set of reference behaviours that then serve as a model in a model-
based conformance testing approach. To set the stage for this, we recall the
deﬁnitions of labelled transition systems (LTS) and input-output transitions
systems (IOTS) together with Tretmans’ notion on model-based conformance
testing [25]. We then recast the characterisation of robust cleanness (Def. 2) in
terms of LTS.

6

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

Deﬁnition 3. A labelled transition system (LTS) with inputs and outputs is a
tuple (cid:104)Q, In, Out, →, q0(cid:105) where (i) Q is a (possibly uncountable) non-empty set
of states; (ii) L = In (cid:93) Out is a (possibly uncountable) set of labels; (iii) → ⊆
Q × L × Q is the transition relation; (iv) q0 ∈ Q is the initial state. We say that
a LTS is an input-output transition system (IOTS) if it is input-enabled in any
state, i.e., for all s ∈ Q and a ∈ In there is some s(cid:48) ∈ Q such that s a−→ s(cid:48).

For ease of presentation, we do not consider internal transitions. The following
deﬁnitions will be used throughout the paper. A ﬁnite path p in an LTS L is
ai−→ si+1 for all 1 ≤ i < n. Similarly, an
a sequence s1a1s2a2 . . . an−1sn with si
ai−→ si+1 for all i ∈ N. Let
inﬁnite path p in L is a sequence s1a1s2a2 . . . with si
paths∗(L) and pathsω(L) be the sets of all ﬁnite and inﬁnite paths of L beginning
in the initial states, respectively. The sequence a1a2 · · · an is a ﬁnite trace of L if
there is a ﬁnite path s1a1s2a2 . . . ansn+1 ∈ paths∗(L), and a1a2 · · · is an inﬁnite
trace if there is an inﬁnite path s1a1s2a2 . . . ∈ pathsω(L). If p is a path, we let
trace(p) denote the trace deﬁned by p. Let traces∗(L) and tracesω(L) be the sets
of all ﬁnite and inﬁnite traces of L, respectively. We will use L1 ⊆ L2 to denote
that tracesω(L1) ⊆ tracesω(L2).

Model-Based Conformance Tests. In the following we recall the basic notions of
ioco conformance testing [25,26,27], and refer to the mentioned literature for
more details. In this setting, it is assumed that the implemented system under
test (IUT) I can be modelled as an IOTS while the speciﬁcation of the required
behaviour is given in terms of a LTS S. The idea of whether the IUT I conforms
to the speciﬁcation S is formalized by means of the ioco relation which we deﬁne
in the following.

We ﬁrst need to identify the quiescent (or suspended ) states. A state is quies-
cent whenever it cannot proceed autonomously, i.e., it cannot produce an output.
We will make each such state identiﬁable by adding a quiescence transition to
it, in the form of a loop with the distinct label δ.

Deﬁnition 4. Let L = (cid:104)Q, In, Out, →, q0(cid:105) be an LTS. The quiescence closure
(or δ-closure) of L is the LTS Lδ := (cid:104)Q, In, Out ∪ {δ}, →δ, q0(cid:105) with →δ := → ∪
{s δ−→δ s | ∀o ∈ Out, t ∈ Q : s (cid:54)o−→ t}. Using this we deﬁne the suspension traces
of L by traces∗(Lδ).

Let L be an LTS with initial state q0 and σ = a1 a2 . . . an ∈ traces∗(L). We
deﬁne L after σ as the set {qn | q0a1q1a2 . . . anqn ∈ paths∗(L)}. For a state q,
let out(q) = {o ∈ Out ∪ {δ} | ∃q(cid:48) : q o−→ q(cid:48)} and for a set of states Q(cid:48) ⊆ Q, let
out(Q(cid:48)) = (cid:83)

q∈Q(cid:48) out(q).

The idea behind the ioco relation is that any output produced by the IUT
must have been foreseen by its speciﬁcation, and moreover, any input in the
IUT not foreseen in the speciﬁcation may introduce new functionality. ioco
captures this by harvesting concepts from refusal testing. As a result, I ioco
Spec is deﬁned to hold whenever out(Iδ after σ) ⊆ out(Specδ after σ) for all
σ ∈ traces∗(Specδ).

Doping Tests for Cyber-Physical Systems

7

The base principle of conformance testing now is to assess by means of testing
whether the IUT conforms to its speciﬁcation w.r.t. ioco. An algorithm to derive
a corresponding test suite TSpec is available [26,27], so that for any IUT I,
I ioco Spec iﬀ I passes all tests in TSpec.

It is important to remark that the speciﬁcation in the setting considered here
is missing. Instead, we need to construct the speciﬁcation from the standard
inputs and the respective observed outputs, together with the distances and the
tresholds given by the contract. Furthermore, this needs to respect the ∀ − ∃
interaction required by the cleanness property (Def. 2).

Software Doping on LTS. To capture the notion of software doping in the context
of LTS, we provide two projections of a trace, projecting to a sequence of the
appearing inputs, respectively outputs. To do this, we extend the set of labels
by adding the input –i, that indicates that in the respective step some output
(or quiescence) was produced (but masking the precise output), and the output
–o that indicates that in this step some (masked) input was given.

The projection on inputs ↓i : Lω → (In∪{–i})ω and the projection on outputs
↓o : Lω → (Out∪{–o})ω are deﬁned for all traces σ and k ∈ N as follows: σ↓i[k] :=
if σ[k] ∈ In then σ[k] else –i and σ↓o[k] := if σ[k] ∈ Out then σ[k] else –o.
They are lifted to sets of traces in the usual elementwise way.

Deﬁnition 5. A LTS S is standard for a LTS L, if for all σ ∈ tracesω(S) and
σ(cid:48) ∈ tracesω(L), σ↓i = σ(cid:48)↓i implies σ(cid:48) ∈ tracesω(S).

The above deﬁnition provides our LTS-speciﬁc interpretation of the notion of
StdIn for a given program P modelled in terms of LTS L. StdIn is implicitly
determined as the input sequences tracesω(S)↓i occurring in S, which contains
both the standard inputs and the outputs that are produced in L, and altogether
covers exactly the traces of L whose input sequences are in StdIn. If instead L
and StdIn ⊆ (In ∪ –i)ω are given, LTS S can be deﬁned such that σ ∈ tracesω(S)
iﬀ σ↓i ∈ StdIn and σ ∈ tracesω(L). This S is indeed standard for L and contains
exactly all traces of L whose input sequences are in StdIn.

In this new setting, we assume that the distance functions dIn and dOut run
on traces containing labels –i and –o, i.e. they are pseudometrics in (In∪{–i})∗ ×
(In ∪ {–i})∗ → R≥0 and (Out ∪ {–o})∗ × (Out ∪ {–o})∗ → R≥0, respectively.

Now the deﬁnition of robustly clean can be restated in terms of LTS as

follows.

Deﬁnition 6. Let L be an IOTS and S a standard LTS. L is robustly clean if
for all σ, σ(cid:48) ∈ tracesω(Lδ) such that σ ∈ tracesω(Sδ) then for all k ≥ 0 such that
dIn(σ[..j]↓i, σ(cid:48)[..j]↓i) ≤ κi for all j ≤ k, the following holds:
1. there exists σ(cid:48)(cid:48) ∈ tracesω(Lδ) s.t. σ(cid:48)↓i = σ(cid:48)(cid:48)↓i and dOutδ (σ[..k]↓o, σ(cid:48)(cid:48)[..k]↓o) ≤ κo
2. there exists σ(cid:48)(cid:48) ∈ tracesω(Lδ) s.t. σ↓i = σ(cid:48)(cid:48)↓i and dOutδ (σ(cid:48)[..k]↓o, σ(cid:48)(cid:48)[..k]↓o) ≤ κo.

Following the principles of model-based testing, Def. 6 takes speciﬁc care of qui-
escence in a system. In order to properly consider quiescence in the context of ro-
bust cleanness it must be considered as a unique output. As a consequence, in the

8

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

presence of a contract C = (cid:104)In, Out, S, dIn, dOut, κi, κo(cid:105), we use – instead of S, Out
and dOut – the quiescence closure Sδ of S, Outδ = Out∪{δ} and an extended out-
put distance deﬁned as dOutδ (σ1, σ2) := dOut(σ1\δ, σ2\δ) if σ1[i] = δ ⇔ σ2[i] = δ
for all i, and dOutδ (σ1, σ2) := ∞ otherwise, where σ\δ is the same as σ whith all
δ removed.

Def. 6 echoes the semantics of the HyperLTL interpretation appearing in
Proposition 19 of [10] restricted to programs with no parameters. Thus, the
proof showing that Def. 6 is the correct interpretation of Def. 2 in terms of LTS,
can be obtained in a way similar to that of Prop. 19 in [10].

4 Reference Implementation for Contracts

As mentioned before, doping tests need to be based on a contract C, which we
assume given. C speciﬁes the domains In, Out, a standard LTS S, the distances
dIn and dOut and the bounds κi and κo. We intuitively expect the contract to
be satisﬁable in the sense that it never enforces a single input sequence of the
implementation to keep outputs close enough to two diﬀerent executions of the
speciﬁcation while their outputs stretch too far apart. We show such a problem-
atic case in the following example.

i+κi

δ

Sδ

i−κi

Example 2. On the right a quiescence-closed standard LTS Sδ
for an implementation L (shown below) is depicted. For sim-
plicity some input transitions are omitted. Assume Out = {o}
and In = {i, i − κi, i + κi}. Consider the transition labelled x
of L. This must be one of either o or δ, but we will see that ei-
ther choice leads to a contradiction w.r.t. the output distances
induced. The input projection of the middle path in L is i –i
and the input distance to (i − κi) –i and (i + κi) –i is exactly
κi, so both branches (i + κi) o and (i − κi) δ of Sδ must be con-
sidered to determine x. For x = o, the output distance of –o x
to –o o in the right branch of Sδ is 0, i.e. less than κo. However,
dOutδ (–o δ, –o o) = ∞ > κo. Thus the output distance to the left
branch of Sδ is too high if picking o. Instead picking x = δ does not work either,
for the symmetric reasons, the problem switches sides. Thus, neither picking o
nor δ for x satisﬁes robust cleanness here. Indeed, no implementation satisfying
robust cleanness exists for the given contract.

i−κi

L

x

o

o

δ

δ

i

i+κi

We would expect that a correct implementation fully entails the standard be-
haviour. So, to satisfy a contract, the standard behaviour itself must be robustly
clean. This and the need for satisﬁability of particular inputs lead to Def. 7.

Deﬁnition 7 (Satisﬁable Contract). Let In, Out, S, dIn, dOut, κi and κo deﬁne
some contract C. Let input σi ∈ (In∪{–i})ω be the input projection of some trace.
σi is satisﬁable for C if and only if for every standard trace σS ∈ tracesω(Sδ)
and k > 0 such that for all j ≤ k dIn(σi[..j], σS[..j]↓i) ≤ κi there is some imple-
mentation L that satisﬁes Def. 6.2 w.r.t. C and has some trace σ ∈ tracesω(Lδ)
with σ↓i = σi and dOutδ (σ[k]↓o, σS[k]↓o) ≤ κo.

Doping Tests for Cyber-Physical Systems

9

C is satisﬁable if and only if all inputs σi ∈ (In ∪ {–i})ω are satisﬁable for C
and if Sδ is robustly clean w.r.t. contract CS = (cid:104)StdIn, Out, S, dIn, dOut, κi, κo(cid:105). A
contract that is not satisﬁable is called unsatisﬁable.

Given a satisﬁable contract it is always possible to construct an implementa-
tion that is robustly clean w.r.t. to this contract. Furthermore, for every contract
there is exactly one implementation (modulo trace equivalence) that contains all
possible outputs that satisfy robust cleanness. Such an implementation is called
the largest implementation.

Deﬁnition 8 (Largest Implementation). Let C be a contract and L an im-
plementation that is robustly clean w.r.t. C. L is the largest implementation
within C if and only if for every L(cid:48) that is robustly clean w.r.t. C it holds that
tracesω(L(cid:48)

δ) ⊆ tracesω(Lδ).

In the following, we will focus on the fragment of satisﬁable contracts with
standard behaviour deﬁned by ﬁnite LTS. For unsatisﬁable contracts, testing is
not necessary, because every implementation is not robustly clean w.r.t. to C.
Finiteness of S will be necessary to make testing feasible in practice. For sim-
plicity we will further assume past-forgetful output distance functions. That is,
dOut(σ1, σ2) = dOut(σ(cid:48)
1) and last(σ2) = last(σ(cid:48)
2) whenever last(σ1) = last(σ(cid:48)
2)
(where last(a1 a2 . . . an) = an.) Thus, we simply assume that dOut : (Out∪{–o} ×
Out∪{–o}) → R≥0, i.e., the output distances are determined by the last output
only. We remark that dOutδ (δ, o) = ∞ for all o (cid:54)= δ.

1, σ(cid:48)

We will now show how to construct the largest implementation for any con-
tract (of the fragment we consider), which we name reference implementation R.
It is derived from Sδ by adding inputs and outputs in such a way that whenever
the input sequence leading to a particular state is within κi distance of an input
sequence σi of Sδ, then the outputs possible in such a state should be at most κo
distant from those outputs possible in the unique state on Sδ reached through
σi. This ensures that R will satisfy condition 2) in Def. 6.

Reference implementation. To construct the reference implementation R we de-
cide to model the quiescence transitions explicitly instead of using the quiescence
closure. We preserve the property, that in each state of the LTS it is possible
to do an output or a quiescence transition. The construction of R proceeds by
adding all transitions that satisfy the second condition of Def. 6.

Deﬁnition 9. Given a standard LTS Sδ = (cid:104)Q, In, Out, →Sδ , (cid:15)(cid:105), bounds κi and
κo, and distances dIn and dOut, the reference implementation R is the LTS
(cid:104)Q, In, Out, →R, (cid:15)(cid:105) where →R is deﬁned by

∀σi ∈ tracesω(Sδ)↓i :

(∀j ≤ |σ| + 1 : dIn((σ · a)↓i[..j], σi[..j]) ≤ κi)

⇒ ∃σS ∈ tracesω(Sδ) : σS↓i = σi ∧ dOutδ (a↓o, σS[|σ| + 1]↓o) ≤ κo

σ a−→R σ · a

10

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

i+[−κi,0)

(cid:15)

i+[0,2κi]

other i

i+[−κi, 0)

i+[0, 2κi]

any i

o+[−κo,2κo]

any i

i+[−κi, 0) any i

i+[−κi, 0) o+[−κo, 2κo]

i+[0, 2κi] any i

o+[0,2κo]
i+[0, 2κi] o+[0, 2κo]

other i

any o

any i

other i any o

other i any i

Fig. 1: The reference implementation R of S in Example 3.

Notably, R is deterministic, since only transitions of the form σ a−→R σ · a are
added. As a consequence of this determinism, outputs and quiescence may co-
exists as options in a state, i.e. they are not mutually exclusive.

i

S

s0

s1

i
s2

Example 3. Fig. 1 gives a schematic representation of
the reference implementation R for the LTS S on the
right. Input (output) actions are denoted with letter i (o,
respectively), quiescence transitions are omitted. We use
Euclidean distances (cid:107)·(cid:107), so that dIn(i, i(cid:48)) := (cid:107)i − i(cid:48)(cid:107) and
dOut(o, o(cid:48)) := (cid:107)o − o(cid:48)(cid:107). For this example, the quiescence
closure Sδ looks like S but with δ-loops in states s0, s4,
s5, and s6. Label r+[a, b] should be interpreted as any value r(cid:48) ∈ [a + r, b + r]
and similarly r+[a, b) and r+(a, b], appropriately considering closed and open
boundaries; “other i” represents any other input not explicitly considered leaving
the same state; and “any i” and “any o” represent any possible input and output
(including δ), respectively. In any case –i and –o are not considered since they
are not part of the alphabet of the LTS. Also, we note that any possible sequence
of inputs becomes enabled in the last states (omitted in the picture).

i+κi
s3

o
s4

o+κo

o+κo

s6

s5

Robust cleanness of reference implementation. In the following, the aim is to
show that R is robustly clean. By construction, each state in R equals the trace
that leads to that state. In other words, last(p) = trace(p) for any p ∈ paths∗(R)
can be shown by induction. As a consequence, a path in R can be completely
identiﬁed by the trace it deﬁnes. The following lemma states that R preserves
all traces of the standard Sδ it is constructed from. This can be proven by using
that Sδ is robustly clean w.r.t. the (satisﬁable) contract C (see Def. 7).

Lemma 1. Let R be constructed from contract C = (cid:104)In, Out, S, dIn, dOut(cid:105). Then
tracesω(Sδ) ⊆ tracesω(R).

The following theorem states that the reference implementation R is robustly

clean w.r.t. the contract it was constructed from.

Theorem 1. Let R be constructed from C. Then R is robustly clean w.r.t. C.

Furthermore, it is not diﬃcult to show that R is indeed the largest imple-

mentation within the contract it was constructed from.

Theorem 2. Let R be constructed from contract C. Then R is the largest im-
plementation within C.

Doping Tests for Cyber-Physical Systems

11

Algorithm 1 Doping Test (DT)
Input: history h ∈ (In ∪ Out ∪ {δ})∗
Output: pass or fail

1 c ← Ωcase(h)
2 if c = 1 then

/* Pick from one of three cases */

return pass

3
4 else if c = 2 and no output from I is available then
/* Pick next input */

/* Finish test generation */

5

i ← ΩIn(h)
i (cid:16) I
return DT(h · i)

6

/* Forward input to SUT */

7
8 else if c = 3 or output from I is available then

/* Continue with next step */

9

10

11

12

13

o (cid:17) I
if o ∈ acc(h) then

/* Receive output from SUT */

return DT(h · o) /* If o is foreseen by oracle continue with next step */

else

return fail

/* Otherwise, report test failure */

end if

14
15 end if

5 Model-Based Doping Tests

Following the conceptual ideas behind ioco, we need to construct a speciﬁcation
that is compatible with our notion of robust cleanness in such a way that a test
suite can be derived. Intuitively, such a speciﬁcation must be able to foresee
every behaviour of the system that is allowed by the contract. We will take the
reference implementation from the previous section as this speciﬁcation. Indeed
we claim that R is constructed in such a way that whenever an IUT I is robustly
clean, I ioco R holds. The latter translates to

∀σ ∈ traces∗(Rδ) : out(Iδ after σ) ⊆ out(Rδ after σ).

(1)

Theorem 3. Let C be a contract with standard S, let IOTS I be robustly clean
w.r.t. C and with Sδ ⊆ Iδ. If R is constructed from C, then I ioco R.

The key observations to prove this theorem are: (i) the reference implementation
is the largest implementation within the contract, i.e. if the IUT is robustly
clean, then all its traces are covered by R, and (ii) by construction of R and
satisﬁability of C, the suspension traces of R are exactly its ﬁnite traces.

Test Algorithm. An important element of the model-based testing theory is a
non-deterministic algorithm to generate test cases. A set of test cases is called a
test suite. It is shown elsewhere [27], that there is an algorithm that can produce
a (possibly inﬁnitely large) test suite T , for which a system I passes T if I
is correct w.r.t. ioco and, conversely, I is correct w.r.t. ioco if I passes T .
The former property is called soundness and the latter is called exhaustiveness.
Algorithm 1 shows a tail-recursive algorithm to test for robust cleanness. This DT

12

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

algorithm takes as an argument the history h of the test currently running. Every
doping test is inititalized by DT((cid:15)). Several runs of the algorithm constitute a
test suite. Each test can either pass or fail, which is reported by the output of
the algorithm. In each call DT picks one of three choices: (i) it either terminates
the test by returning pass (line 3), (ii) if there is no pending output that has
to be read from the system under test, the algorithm may pick a new input and
pass it to the system (lines 5-6), or (iii) DT reads and checks the next output (or
quiescence) that the system produces (lines 9-10). Quiescence can be recognized
by using a timeout mechanism that returns δ if no output has been received in
a given amount of time. In the original algorithm, the case and the next input
are determined non-deterministically. Our algorithm is parameterized by Ωcase
and ΩIn, which can be instantiated by either non-determinism or some optimized
test-case selection. Until further notice we assume non-deterministic selection.
An output or quiescence that has been produced by the IUT is checked by means
of an oracle acc (line 10). The oracle reﬂects the reference implementation R, that
is used as the speciﬁcation for the ioco relation and is deﬁned in equation (2).

acc(h) := {o ∈ Outδ |

(2)
∀σi ∈ tracesω(Sδ)↓i : (∀j ≤ |h|+1 : dIn(σi[..j]↓i, (h · o)[..j]↓i) ≤ κi})
⇒ ∃σ ∈ tracesω(Sδ) : σ↓i = σi↓i ∧ dOutδ (o, σ[|h| + 1]↓o) ≤ κo}

Given a ﬁnite execution, acc returns the set of acceptable outputs (after such an
execution) which corresponds exactly to the set of outputs in R (after such an
execution). Thus acc(h) is precisely the set of outputs that satisﬁes the premise
in the deﬁnition of R after the trace h, as stipulated in Def. 9.

We refer to acc as an oracle, because it cannot be computed in general due to
the inﬁnite traces of Sδ in the deﬁnition. However, we get the following theorem
stating that the algorithm is sound and exhaustive with respect to ioco (and we
present a computable algorithm in the next section). The theorem follows from
the soundness and exhaustiveness of the original test generation algorithm for
model-based testing and Def. 9.

Theorem 4. Let C be a contract with standard S. Let I be an implementation
with Sδ ⊆ Iδ and let R be the largest implementation within C. Then, I ioco R
if and only if for every test execution t = DT((cid:15)) it holds that I passes t.

Together with Theorem 3 and satisﬁability of C, we derive the following corollary.

Corollary 1. Let C be a contract with standard S. Let I be an implementation
with Sδ ⊆ Iδ.If I is robustly clean, then for every test execution t = DT((cid:15)) it
holds that I passes t.

It is worth noting that in Corollary 1 we do not get that I is robustly clean if
I always passes DT. This is due the intricacies of genuine hyperproperties. By
testing, we will never be able to verify the ﬁrst condition of Def. 6, because this
needs a simultaneous view on all possible execution traces of I. During testing,
however, we always can observe only one trace.

Doping Tests for Cyber-Physical Systems

13

Finite Doping Tests. As mentioned before, the execution of DT is not possible,
because the oracle acc is not computable. There is, however, a computable version
accb of acc for executions up to some test length b for bounded and discretised
In and Out. Even for inﬁnite executions, b can be seen as a limit of interest and
testing is still sound. accb is shown in eq. (3). The only variation w.r.t. acc lies in
the use of the set tracesb(Sδ), instead of tracesω(Sδ), so as to return all traces of
Sδ whose length is exactly b. Since Sδ is ﬁnite, function accb can be implemented.

accb(h) := {o ∈ Outδ |

(3)

∀σi ∈ tracesb(Sδ)↓i : (∀j ≤ |h|+1 : dIn(σi[..j]↓i, (h · o)[..j]↓i) ≤ κi)
⇒ ∃σ ∈ tracesb(Sδ) : σ↓i = σi↓i ∧ dOutδ (o, σ[|h|+1]↓o) ≤ κo}

Now we get a new algorithm DTb by replacing acc by accb in DT and by forcing
case 1 when and only when |h| = b. We get a similar soundness theorem for DTb
as in Corollary 1.

Theorem 5. Let C be a contract with standard S. Let I be an implementation
with Sδ ⊆ Iδ. If I is robustly clean, then for every boundary b and every test
execution t = DTb((cid:15)) it holds that I passes t.

Since I passes DTb((cid:15)) implies I passes DTa((cid:15)) for any a ≤ b, we have in
summary arrived at an on-the-ﬂy algorithm DTb that for suﬃciently large b
(corresponding to the length of the test) will be able to conduct a “convicting”
doping test for any IUT I that is not robustly clean w.r.t. a given contract C.
The bounded-depth algorithm eﬀectively circumvents the fact that, except for
S and Sδ, all other objects we need to deal with are countably or uncountably
inﬁnite and that the property we check is a hyperproperty.

We implemented a prototype of a testing framework using the bounded-depth
algorithm. The speciﬁcation of distances, value domains and test case selection
are parameters of the algorithm that can be set speciﬁc for a concrete test
scenario. This ﬂexibility enables us to use the framework in a two-step approach
for cyber-physical systems not equipped with a digital interface to forward the
inputs to: ﬁrst, the tool can generate test inputs, that are executed by a human
or a robot on the CPS under test. The actual inputs (possibly deviating from
the generated inputs) and outputs from the system are recorded so that in the
second step our tool determines if the (actual) test is passed or failed.

6 Evaluation

The normed emission test NEDC (New European Driving Cycle) (see Fig. 2) is
the legally binding framework in Europe [28] (at the time the scandal surfaced).
It is to be carried out on a chassis dynamometer and all relevant parameters are
ﬁxed by the norm, including for instance the outside temperature at which it is
run.

For a given car model, the normed test induces a standard LTS S as fol-
lows. The input dimensions of S are spanned by the sensors the car model is

14

]

m h
k
[

d
e
e
p
S

120
100
70

32
0

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

0

200

400

600

800

1,000

1,180

Time [s]

Fig. 2: NEDC speed proﬁle.

equipped with (including e.g. temperature of the exhaust, outside temperature,
vertical and lateral acceleration, throttle position, time after engine start, engine
rpm, possibly height above ground level etc.) which are accessible via the stan-
dardized OBD-2 interface [24]. The output is the amount of NOx per kilometre
that has been extruded since engine start. Inputs are sampled at equidistant
times (once per second). The standard LTS S is obtained from the trace rep-
resenting the observations of running NEDC on the chassis dynamometer, say
σS := i1 · · · i1180 oS δ δ δ · · · with inputs i1, · · · i1180 given by the NEDC over its
20 minutes (1180 seconds) duration, and oS is the amount of NOx gases accu-
mulated during the test procedure. This σS is the only standard trace of our
experiments. The trace ends with an inﬁnite suﬃx δω of quiescence steps.

The input space, In is a vector space spanned by all possible input parameter
dimensions. For a ∈ In we distinguish the speed dimension as v(a) ∈ R (mea-
sured in km/h). We can use past-forgetful distances with dIn(a, b) := |v(a)−v(b)|
if a, b ∈ In, dIn(–i, –i) = 0 and dIn(a, b) = ∞ otherwise. The speed is the decisive
quantity deﬁned to vary along the NEDC (cf. Fig. 2). Hence dIn(a, b) = 0 if
v(a) = v(b) regardless of the values of other parameters. We also take Out = R
for the average amount of NOx gases per kilometre since engine start (in mg/km).
We deﬁne dOut(a, b) = |a − b| if a, b ∈ Out, and dOut(a, b) = ∞ otherwise.

Doping tests in practice. For the purpose of practically exercising doping tests,
we picked a Renault 1.5 dci (110hp) (Diesel) engine. This engine runs, among
others, inside a Nissan NV200 Evalia which is classiﬁed as a Euro 6 car. The test
cycle used in the original type approval of the car was NEDC (which corresponds
to Euro 6b). Emissions are cleaned using exhaust gas recirculation (EGR). The
technical core of EGR is a valve between the exhaust and intake pipe, controlled
by a software. EGR is known to possibly cause performance losses, especially at
higher speed. Car manufacturers might be tempted to optimize EGR usage for
engine performance unless facing a known test cycle such as the NEDC.

We ﬁxed a contract with κi = 15 km/h, κo = 180 mg/km. We report here on
two of the tests we executed apart from the NEDC reference: (i) PowerNEDC
is a variation of the NEDC, where acceleration is increased from 0.94 m
s2 to 1.5 m
s2
in phase 6 of the NEDC elementary urban cycle (i.e. after 56s, 251s, 446s and
641s) and (ii) SineNEDC deﬁnes the speed at time t to be the speed of the
NEDC at time t plus 5 · sin(0.5t) (but capped at 0). Both can be generated by
DT1181((cid:15)) for speciﬁc deterministic Ωcase and ΩIn. For instance, SineNEDC is
given below. Fig. 3 shows the initial 200s of SineNEDC (red, dotted).

]

m h
k
[

d
e
e
p
S

50

32

15

0

0

Doping Tests for Cyber-Physical Systems

15

100

Time [s]

200

Fig. 3: Initial 200s of a SineNEDC (red, dotted), its test drive (green) and the
NEDC driven (blue, dashed).

Ωcase(h) =

(cid:40)

2 , if |h| ≤ 1179
3 , if |h| = 1180

ΩIn(h) = max

(cid:26) 0,

(cid:27)

NEDC(|h|) + 5 · sin(0.5|h|))

The car was ﬁxed on a Maha LPS 2000 dynamometer and attached to an
AVL M.O.V.E iS portable emissions measurement system (PEMS, see Fig. 4)
with speed data sampling at a rate of 20 Hz, averaged to match the 1 Hz rate
of the NEDC. The human driver eﬀectuated the NEDC with a deviation of at
most 9 km/h relative to the reference (notably, the result obtained for NEDC
are not consistent with the car data sheet, likely caused by lacking calibration
and absence of any further manufacturer-side optimisations).

Distance [m]
Avg. Speed (cid:2) km
(cid:2) g
CO2
km
(cid:2) mg
NOx
km

(cid:3)
(cid:3)

h

(cid:3)

Sine
NEDC Power
11,029 11,081 11,171
34
182
584

33
189
180

29
186
204

Table 1: Dynamometer measurements
(sample rate: 1Hz )

Fig. 4: Nissan NV200 Evalia on
a dynamometer
The PowerNEDC test drive diﬀered by less than 15 km/h and the SineNEDC
by less than 14 km/h from the NEDC test drive, so both inputs deviate by less
than κi. The green line in Fig. 3 shows SineNEDC driven. The test outcomes are
summarised in Table 1. They show that the amount of CO2 for the two tests is
lower than for the NEDC driven. The NOx emissions of PowerNEDC deviate
by around 24 mg/km, which is clearly below κo. But the SineNEDC produces
about 3.24 times the amount of NOx, that is 404 mg/km more than what we
measured for the NEDC, which is a violation of the contract. This result can
be veriﬁed with our algorithm a posteriori, namely by using ΩIn to replay the
actually executed test inputs (which are diﬀerent from the test inputs generated
upfront due to human driving imprecisions) and by feeding the outputs recorded
by the PEMS into the algorithm. As to be expected, this makes the recording
of the PowerNEDC return pass and the recording of SineNEDC return fail.
Our algorithm is powerful enough to detect other kinds of defeat devices like
those uncovered in investigations of the Volkswagen or the Audi case. Due to
lack of space, we cannot present the concrete Ωcase and ΩIn for these examples.

16

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

7 Discussion

Related Work. The present work complements white-box approaches to software
doping, like model-checking [10] or static code analysis [9] by a black-box testing
approach, for which the speciﬁcation is given implicitly by a contract, and usable
for on-the-ﬂy testing. Existing test frameworks like TGV [18] or TorX [29] pro-
vide support for the last step, however they fall short on scenarios where (i) the
speciﬁcation is not at hand and, among others, (ii) the test input is distorted in
the testing process, e.g., by a human driving a car under test.

Our work is based on the deﬁnition of robust cleanness [10] which has concep-
tual similarities to continuity properties [6,17] of programs. However, continuity
itself does not provide a reasonably good guarantee of cleanness. This is be-
cause physical outputs (e.g. the amount of NOx gas in the exhaust) usually do
change continuously. For instance, a doped car may alter its emission cleaning in
a discrete way, but that induces a (rapid but) continuous change of NOx gas con-
centrations. Established notions of stability and robustness [23,13,19,21] diﬀer
from robust cleanness in that the former assure the outputs (of a white-box sys-
tem model) to stabilize despite transient input disturbances. Robust cleanness
does not consider perturbations but (intentionally) diﬀerent inputs, and needs a
hyperproperty formulation.

Concluding Remarks. This work lays the theoretical foundations for black-box
testing approaches geared towards uncovering doped software. As in the diesel
emissions scandal – where manufacturers were forced to pay excessive ﬁnes [22]
and where executive managers are facing lawsuits or indeed went to prison [14,5]
– doped behaviour is typically strongly related to illegal behaviour.

As we have discussed, software doping analysis comes with several challenges.
It can be performed (i) only after production time on the ﬁnal embedded or
cyber-physical product, (ii) notoriously without support by the manufacturer,
and (iii) the property belongs to the class of hyperproperties with alternating
quantiﬁers. (iv) Non-determinism and imprecision caused by a human in-the-
loop complicate doping analysis of CPS even further.

Conceptually central to the approach is a contract that is assumed to be
explicitly oﬀered by the manufacturer. The contract itself is deﬁned by very
few parameters making it easy to form an opinion about a concrete contract.
And even if a manufacturer is not willing to provide such contractual guarantees,
instead a contract with very generous parameters can provide convicing evidence
of doping if a test uncovers the contract violation. We showed this in a real
automotive example demonstrating how a legally binding reference behaviour
and a contract altogether induce a ﬁnite state LTS enabling to harvest input-
output conformance testing for doping tests. We developed an algorithm that
can be attached directly to a system under test or in a three-step process, ﬁrst
generating a valid test case, afterwards used to guide a human interacting with
the system, possibly adding distortions, followed by an a-posteriori validation
of the recorded trajectory. For more eﬀective test case selection [15,11] we are
exploring diﬀerent guiding techniques [2,12,1] for cyber-physical systems.

Doping Tests for Cyber-Physical Systems

17

References

1. Adimoolam, A.S., Dang, T., Donz´e, A., Kapinski, J., Jin, X.: Classiﬁca-
tion and coverage-based falsiﬁcation for embedded control systems. In: Ma-
jumdar, R., Kuncak, V. (eds.) Computer Aided Veriﬁcation - 29th Interna-
tional Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Pro-
ceedings, Part I. Lecture Notes in Computer Science, vol. 10426, pp. 483–
503. Springer (2017). https://doi.org/10.1007/978-3-319-63387-9 24, https://
doi.org/10.1007/978-3-319-63387-9_24

2. Annpureddy, Y., Liu, C., Fainekos, G.E., Sankaranarayanan, S.: S-taliro: A tool for
temporal logic falsiﬁcation for hybrid systems. In: Abdulla, P.A., Leino, K.R.M.
(eds.) Tools and Algorithms for the Construction and Analysis of Systems - 17th
International Conference, TACAS 2011, Held as Part of the Joint European Con-
ferences on Theory and Practice of Software, ETAPS 2011, Saarbr¨ucken, Ger-
many, March 26-April 3, 2011. Proceedings. Lecture Notes in Computer Science,
vol. 6605, pp. 254–257. Springer (2011). https://doi.org/10.1007/978-3-642-19835-
9 21, https://doi.org/10.1007/978-3-642-19835-9_21

3. Barthe, G., D’Argenio, P.R., Finkbeiner, B., Hermanns, H.: Facets of software
doping. In: Margaria and Steﬀen [20], pp. 601–608. https://doi.org/10.1007/978-
3-319-47169-3 46, http://dx.doi.org/10.1007/978-3-319-47169-3_46

4. Baum, K.: What the hack is wrong with software doping? In: Margaria and
Steﬀen [20], pp. 633–647. https://doi.org/10.1007/978-3-319-47169-3 49, https:
//doi.org/10.1007/978-3-319-47169-3_49

5. BBC: Audi chief Rupert Stadler arrested in diesel emissions probe. BBC,
https://www.bbc.com/news/business-44517753 (2018), https://www.bbc.com/
news/business-44517753, Online; accessed: 2019-01-28

6. Chaudhuri, S., Gulwani, S., Lublinerman, R.: Continuity analysis of pro-
grams. In: Hermenegildo, M.V., Palsberg, J. (eds.) Proceedings of the 37th
ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages, POPL 2010, Madrid, Spain, January 17-23, 2010. pp. 57–70. ACM
(2010). https://doi.org/10.1145/1706299.1706308, http://doi.acm.org/10.1145/
1706299.1706308

7. Clarkson, M.R., Finkbeiner, B., Koleini, M., Micinski, K.K., Rabe, M.N., S´anchez,
C.: Temporal logics for hyperproperties. In: Abadi, M., Kremer, S. (eds.) POST
2014. LNCS, vol. 8414, pp. 265–284. Springer (2014). https://doi.org/10.1007/978-
3-642-54792-8 15, http://dx.doi.org/10.1007/978-3-642-54792-8_15

8. Clarkson, M.R., Schneider, F.B.: Hyperproperties. In: CSF’08. pp. 51–65 (2008).
https://doi.org/10.1109/CSF.2008.7, http://dx.doi.org/10.1109/CSF.2008.7
9. Contag, M., Li, G., Pawlowski, A., Domke, F., Levchenko, K., Holz, T., Sav-
age, S.: How they did it: An analysis of emission defeat devices in modern au-
tomobiles. In: 2017 IEEE Symposium on Security and Privacy, SP 2017, San
Jose, CA, USA, May 22-26, 2017. pp. 231–250. IEEE Computer Society (2017).
https://doi.org/10.1109/SP.2017.66, https://doi.org/10.1109/SP.2017.66
10. D’Argenio, P.R., Barthe, G., Biewer, S., Finkbeiner, B., Hermanns, H.: Is your
software on dope? - Formal analysis of surreptitiously ”enhanced” programs. In:
Yang, H. (ed.) Programming Languages and Systems - 26th European Symposium
on Programming, ESOP 2017, Proceedings. Lecture Notes in Computer Science,
vol. 10201, pp. 83–110. Springer (2017). https://doi.org/10.1007/978-3-662-54434-
1 4, https://doi.org/10.1007/978-3-662-54434-1_4

18

Sebastian Biewer, Pedro D’Argenio, and Holger Hermanns

11. de Vries, R.: Towards formal test purposes. In: Brinksma, H., Tretmans, G.,
Brinksma, H. (eds.) Formal Approaches to Testing of Software 2001 (FATES’01).
pp. 61–76. No. NS-01-4 in BRICS Notes Series, BRICS, University of Aarhus (8
2001)

12. Deshmukh, J.V., Jin, X., Kapinski, J., Maler, O.: Stochastic local search
In: Finkbeiner, B., Pu, G., Zhang, L.
for falsiﬁcation of hybrid systems.
(eds.) Automated Technology for Veriﬁcation and Analysis
- 13th Inter-
national Symposium, ATVA 2015, Shanghai, China, October 12-15, 2015,
Proceedings. Lecture Notes in Computer Science, vol. 9364, pp. 500–517.
Springer
(2015). https://doi.org/10.1007/978-3-319-24953-7 35, https://doi.
org/10.1007/978-3-319-24953-7_35

13. Doyen, L., Henzinger, T.A., Legay, A., Nickovic, D.: Robustness of sequen-
tial circuits. In: Gomes, L., Khomenko, V., Fernandes, J.M. (eds.) 10th Inter-
national Conference on Application of Concurrency to System Design, ACSD
2010, Braga, Portugal, 21-25 June 2010. pp. 77–84. IEEE Computer Soci-
ety (2010). https://doi.org/10.1109/ACSD.2010.26, https://doi.org/10.1109/
ACSD.2010.26

14. Ewing, J.: Ex-Volkswagen C.E.O. Charged With Fraud Over Diesel Emis-
sions. New York Times, https://www.nytimes.com/2018/05/03/business/
volkswagen-ceo-diesel-fraud.html (2018), https://www.nytimes.com/2018/
05/03/business/volkswagen-ceo-diesel-fraud.html, Online; accessed: 2019-
01-28

15. Feijs, L.M.G., Goga, N., Mauw, S., Tretmans, J.: Test selection, trace distance and
heuristics. In: Schieferdecker, I., K¨onig, H., Wolisz, A. (eds.) Testing of Commu-
nicating Systems XIV, Applications to Internet Technologies and Services, Pro-
ceedings of the IFIP 14th International Conference on Testing Communicating
Systems - TestCom 2002, Berlin, Germany, March 19-22, 2002. IFIP Conference
Proceedings, vol. 210, pp. 267–282. Kluwer (2002)

16. Finkbeiner, B., Rabe, M.N., S´anchez, C.: Algorithms for model checking Hyper-
LTL and HyperCTL∗. In: Kroening, D., Pasareanu, C.S. (eds.) CAV 2015. LNCS,
vol. 9206, pp. 30–48. Springer (2015). https://doi.org/10.1007/978-3-319-21690-
4 3, http://dx.doi.org/10.1007/978-3-319-21690-4_3

17. Hamlet, D.: Continuity in sofware systems. In: Frankl, P.G. (ed.) Proceed-
the International Symposium on Software Testing and Analysis,
Italy, July 22-24, 2002. pp. 196–200. ACM (2002).
https://doi.org/10.1145/566172.

ings of
ISSTA 2002, Roma,
https://doi.org/10.1145/566172.566203,
566203

18. Jard, C., J´eron, T.: TGV: theory, principles and algorithms. STTT 7(4), 297–315
(2005). https://doi.org/10.1007/s10009-004-0153-x, https://doi.org/10.1007/
s10009-004-0153-x

19. Majumdar, R., Saha, I.: Symbolic robustness analysis. In: Baker, T.P. (ed.) Pro-
ceedings of the 30th IEEE Real-Time Systems Symposium, RTSS 2009, Wash-
ington, DC, USA, 1-4 December 2009. pp. 355–363. IEEE Computer Society
(2009). https://doi.org/10.1109/RTSS.2009.17, https://doi.org/10.1109/RTSS.
2009.17

20. Margaria, T., Steﬀen, B. (eds.): Leveraging Applications of Formal Meth-
ods, Veriﬁcation and Validation: Discussion, Dissemination, Applications -
7th International Symposium, ISoLA 2016, Part II, LNCS, vol. 9953 (2016).
https://doi.org/10.1007/978-3-319-47169-3, http://dx.doi.org/10.1007/978-3-
319-47169-3

Doping Tests for Cyber-Physical Systems

19

21. Pettersson, S., Lennartson, B.: Stability and robustness for hybrid systems. In:
Proceedings of 35th IEEE Conference on Decision and Control. vol. 2, pp. 1202–
1207 vol.2 (Dec 1996). https://doi.org/10.1109/CDC.1996.572653

22. Riley, C.: Volkswagen’s diesel scandal costs hit $30 billion. CNN Business,
https://money.cnn.com/2017/09/29/investing/volkswagen-diesel-cost-30-
billion/index.html (2018), https://money.cnn.com/2017/09/29/investing/
volkswagen-diesel-cost-30-billion/index.html, Online; accessed: 2019-01-28
23. Tabuada, P., Balkan, A., Caliskan, S.Y., Shoukry, Y., Majumdar, R.: Input-
output robustness for discrete systems. In: Jerraya, A., Carloni, L.P., Maran-
inchi, F., Regehr, J. (eds.) Proceedings of the 12th International Conference
on Embedded Software, EMSOFT 2012, part of the Eighth Embedded Systems
Week, ESWeek 2012, Tampere, Finland, October 7-12, 2012. pp. 217–226. ACM
(2012). https://doi.org/10.1145/2380356.2380396, http://doi.acm.org/10.1145/
2380356.2380396

24. The European Parliament and the Council of the European Union: Direc-
tive 98/69/ec of the european parliament and of the council. Oﬃcial Journal
of the European Communities (1998), http://eur-lex.europa.eu/LexUriServ/
LexUriServ.do?uri=CELEX:31998L0069:EN:HTML

25. Tretmans, J.: A formal approach to conformance testing. Ph.D. thesis, University of
Twente, Enschede, Netherlands (1992), http://purl.utwente.nl/publications/
58114

26. Tretmans, J.: Conformance testing with labelled transition systems: Implementa-
tion relations and test generation. Computer Networks and ISDN Systems 29(1),
49–79 (1996). https://doi.org/10.1016/S0169-7552(96)00017-7, https://doi.org/
10.1016/S0169-7552(96)00017-7

27. Tretmans, J.: Model based testing with labelled transition systems. In: Hierons,
R.M., Bowen, J.P., Harman, M. (eds.) Formal Methods and Testing, An Outcome
of the FORTEST Network, Revised Selected Papers. Lecture Notes in Computer
Science, vol. 4949, pp. 1–38. Springer (2008). https://doi.org/10.1007/978-3-540-
78917-8 1, https://doi.org/10.1007/978-3-540-78917-8_1

28. United Nations: UN Vehicle Regulations - 1958 Agreement, Revision 2, Addendum
100, Regulation No. 101, Revision 3 — E/ECE/324/Rev.2/Add.100/Rev.3 (2013),
http://www.unece.org/trans/main/wp29/wp29regs101-120.html

29. de Vries, R.G., Tretmans, J.: On-the-ﬂy conformance testing using SPIN. STTT
2(4), 382–393 (2000). https://doi.org/10.1007/s100090050044, https://doi.org/
10.1007/s100090050044

