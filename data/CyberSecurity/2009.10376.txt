Noname manuscript No.
(will be inserted by the editor)

Eﬃciently Finding a Maximal Clique Summary via Eﬀective
Sampling

Xiaofan Li · Rui Zhou · Lu Chen · Chengfei Liu · Qiang He · Yun Yang

0
2
0
2

v
o
N
8
2

]

B
D
.
s
c
[

2
v
6
7
3
0
1
.
9
0
0
2
:
v
i
X
r
a

Received: date / Accepted: date

Abstract Maximal clique enumeration (MCE) is a fun-
damental problem in graph theory and is used in many
applications, such as social network analysis, bioinfor-
matics, intelligent agent systems, cyber security, etc.
Most existing MCE algorithms focus on improving the
eﬃciency rather than reducing the output size. The out-
put unfortunately could consist of a large number of
maximal cliques. In this paper, we study how to report
a summary of less overlapping maximal cliques. The
problem was studied before, however, after examining
the pioneer approach, we consider it still not satisfac-
tory. To advance the research along this line, our paper
attempts to make four contributions: (a) we propose
a more eﬀective sampling strategy, which produces a
much smaller summary but still ensures that the sum-
mary can somehow witness all the maximal cliques and
the expectation of each maximal clique witnessed by the
summary is above a predeﬁned threshold; (b) we prove
that the sampling strategy is optimal under certain op-
timality conditions; (c) we apply clique-size bounding
and design new enumeration order to approach the op-
timality conditions; and (d) to verify experimentally, we
test eight real benchmark datasets that have a variety
of graph characteristics. The results show that our new
sampling strategy consistently outperforms the state-
of-the-art approach by producing smaller summaries
and running faster on all the datasets.

Keywords maximal clique · clique summary · bound
estimation · clique enumeration · clique sampling

X. Li, R. Zhou, L. Chen, C. Liu, Q. He and Y. Yang
Swinburne University of Technology, Australia
E-mail: {xiaofanli,rzhou,luchen,cliu,qhe,yyang}@swin.edu.au

1 Introduction

A clique C is a complete subgraph of an undirected
graph G(V, E), which means that each pair of nodes
in C have an edge between them. A maximal clique is
a clique which is not a subgraph of any other clique.
The procedure of enumerating all maximal cliques in a
graph is called Maximal Clique Enumeration (MCE).

MCE has a range of applications in diﬀerent ﬁelds,
such as discovering communities in social networks [18],
identifying co-expressed genes [22], detecting protein-
protein interaction complexes [41], supporting the con-
struction of intelligent agent systems [29] and recogniz-
ing emergent patterns in terrorist networks [4].

There are a suﬃcient number of works [12,14,21,24,
25,32,38] focusing on improving the eﬃciency of MCE,
which is considered as having exponential time. This is
probably because the number of cliques in a graph is
always very large. A graph with less than 106 vertices
and 7 × 106 edges can have more than 107 maximal
cliques [36]. Counting the number of maximal cliques in
a general graph is considered to be #P-complete [34].
This means that the output of any MCE procedure is
hard to be used by some other post applications. For-
tunately, there typically exist a lot of overlaps between
diﬀerent cliques. This motivates us to consider report-
ing a summary set of all maximal cliques which has less
overlap but can somehow represent all the cliques.

Wang et al. [36] introduced the concept of τ -visible
summary, a set of maximal cliques, which promises that
every maximal clique in graph G can be covered by at
least one maximal clique in the summary with a ratio
of at least τ . Here, τ is given by a user and reﬂects the
user’s tolerance of overlap. For example, a summary
with τ = 0.8 ensures that any maximal clique can have
at least 80% nodes covered by some clique in the sum-

 
 
 
 
 
 
2

Xiaofan Li et al.

mary. This summary model is interesting, e.g., in the
marketing domain, if a certain percentage of users in a
clique community has been covered, we expect that the
covered users will spread a message across the commu-
nity. Consequently, ﬁnding fewer communities as tar-
gets due to marketing cost while still ensuring a broad
ﬁnal user coverage is very desirable. The work [36] mod-
iﬁed the depth-ﬁrst MCE [5] by adding a sampling func-
tion that determines whether a new clique enumeration
sub-procedure should be entered. It was proved that the
expected visibility of such a sampled summary is larger
than τ .

in such an order that two consecutive generated max-
imal cliques tend to be contained by the same cohe-
sive k-truss and thus overlap more. When one of the
two cliques is included into the summary ﬁrst, the sec-
ond one has a higher probability to be discarded so the
summary keeps concise. Besides, we utilize k-truss to
estimate the size of a maximal clique contained by a
subgraph, which provides an upper bound tighter than
the k-core based bound (used by [36]), since a k-truss
must be a (k − 1)-core. With these two strategies, we
provide our best eﬀort to improve the practical perfor-
mance of our proposed sampling approach.

However, expected τ -visible summaries are not unique.

Our main contributions are summarized as follows:

Apparently, as long as a summary is τ -visible, the more
concise the summary is, the better the summary is.
Hence three questions arise naturally in sequence:

(1) Is there any sampling strategy that can ﬁnd a better

(smaller) expected τ -visible summary?
(2) What kind of sampling strategy is optimal?
(3) If achieving the optimal is diﬃcult or impossible,

how can we provide the best eﬀort?

We will tackle these three questions in this paper.
For question (1), the answer is yes. The state-of-the-
art work [36] used a sampling function to determine
whether each maximal clique should be included into
the growing summary. However, it could include many
redundant maximal cliques that (a) are visible to the
current summary; (b) are likely to be visible to the fu-
ture summary (explained by Observation 1 for (a) and
by Observation 2 for (b) in Section 3.1). By identifying
and discarding these two types of maximal cliques, we
ﬁnd a novel sampling function that is superior to the
existing work in terms of both output summary size
and running time. For question (2), we naturally deﬁne
the optimality as including each maximal clique with
the lowest probability while still promising τ -visibility
of the summary. We ﬁnd that, when (I) the maximal
cliques are enumerated in a proper order and (II) the
size of a clique can be estimated suﬃciently accurate
at an early stage of the depth-ﬁrst search, our newly
proposed sampling function successfully guarantees op-
timality, while the existing approach [36] does not. The
optimality of our sampling function promises signiﬁcant
improvement vs. [36] in terms both eﬀectiveness and ef-
ﬁciency. Although, the above two optimality conditions
(I) and (II) are hard to hold ideally, they provide us two
important directions to approach the optimal by look-
ing for (i) better vertex orders to enumerate maximal
cliques, and (ii) better maximal clique size estimation
techniques. Thus for question (3), inspired by the co-
hesive structure of k-truss, we design a novel vertex
order based on truss decomposition. Following this ver-
tex order, our algorithm can enumerate maximal cliques

– We introduce a new sampling strategy to help to
identify an expected τ -visible maximal clique sum-
mary. We prove that the new sampling strategy guar-
antees a better performance than the state-of-the-
art method in terms of producing a smaller sum-
mary while still meeting the threshold τ .

– We give a theoretical analysis that the sampling can
be optimal under certain conditions, which substan-
tiates good performance of the proposed sampling
strategy in practice. Future investigations could also
be directed by exploring how to approximate the op-
timal conditions.

– We show that the sampling approach can get close
to optimal with clique size bounding and enumera-
tion ordering strategies. Then we propose truss or-
dering and truss bound respectively to further im-
prove the performance of our sampling strategy.
– We conduct experimental studies to verify the su-
periority of the new sampling method as well as
our newly designed truss order and truss bound in
terms of both eﬀectiveness and eﬃciency on eight
real-world datasets.

The rest of this paper is organized as follows. In
Section 2, we review the deﬁnition of τ -visible sum-
mary and an existing sampling approach. In Section
3, we give our motivation, introduce a novel sampling
function and prove its superiority. The conditions of
optimality are analyzed in Section 4. We propose truss
vertex order and truss bound to practically instantiate
optimality conditions in Section 5. Extensive experi-
ments are conducted in Section 6. Related work and
conclusion are in Section 7 and Section 8.

2 τ -Visible Summary

A clique refers to a complete subgraph of an undirected
graph G(V, E). A clique C is maximal if it is not con-
tained by any other clique. When the context is clear,
we also use C to denote the node set of a maximal

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

3

clique. Given the set of all maximal cliques in graph G,
denoted as M(G), a summary S is a subset of M(G)
which means S ⊆ M(G). To measure to what extent
a summary can witness a clique, visibility is deﬁned
in [36], restated as Deﬁnitions 1 and 2. We then intro-
duce expected visibility in Deﬁnitions 3 and 4.

Deﬁnition 1 (Visibility) Given a summary S, the
visibility VS : M(G) → [0, 1] of a maximal clique C is
deﬁned as:

point out that, such a VS (C) does exist albeit it is hard
to know its value early. We will see under which con-
ditions VS (C) can be calculated without S is known in
Section 4. Currently, we only need a lower bound of it
since we want to make sure the lower bound is suﬃ-
ciently large, so that the expectation of VS (C) is larger
than a user-given threshold, implying that we want to
ﬁnd a summary with good visibility expectation guar-
antee. Deﬁnition 4 deﬁnes this case:

VS (C) = max
C(cid:48)∈S

|C ∩ C (cid:48)|
|C|

Deﬁnition 4 (Expected τ -Visible Summary)
A summary S is expected τ -visible iﬀ ∀C ∈ M(G),

(1)

Note that C (cid:48) is allowed to be the same as C. This means
that if C ∈ S, C’s visibility with respect to S is 1. In
other words, if C ∈ S, the summary S can completely
witness C.

Deﬁnition 2 (τ -Visible Summary) A summary S
is called τ -visible iﬀ ∀C ∈ M(G),

VS (C) ≥ τ

(2)

Rather than the exact τ -visible summary deﬁned above,
our work looks for an expected τ -visible summary. Be-
fore we give the formal deﬁnition of expected τ -visible
summary, we explain what the term expected means in-
tuitively. Since the number of maximal cliques is likely
to be exponential, it is infeasible to ﬁrstly compute all
the cliques and then decide the summary. Instead, it
is more practical to decide on the way while enumerat-
ing, i.e., try to make a decision whether to keep/discard
a new clique or keep/discard with a probability, when
the clique is found. To be more active, a decision can
be made on whether to enter each enumeration branch
with some probability. This means that each maximal
clique has a probability P r[C ∈ S] to be included in
S and a corresponding probability P r[C /∈ S] = 1 −
P r[C ∈ S] to be discarded. For a clique C, if it is se-
lected to be included into S, the visibility of it should
be 1, since it is witnessed by itself; otherwise this value
is VS (C), which stays unknown before S is ﬁnalized.
Given the above discussion of visibility, we can have
the mathematical expectation of VS (C) in Deﬁnition 3:

Deﬁnition 3 (Expected Visibility) The expected
visibility of a clique C with regards to a summary S,
E[VS (C)], is deﬁned as

E[VS (C)] (cid:44) 1 · P r[C ∈ S] + VS (C) · P r[C /∈ S]

(3)

One may question that, before S is ﬁnally known,
VS (C) is unavailable to Formula (3), since this value
relies on a materialization of S. However, we need to

E[VS (C)] ≥ τ

(4)

where τ ∈ [0, 1] is a given threshold.

In this paper, we focus on developing theories
and algorithms for ﬁnding a good expected τ -
visible summary. The key issue that we are go-
ing to address is how to keep/discard the enumeration
branches to ensure the ﬁnal found cliques can form a
summary which is τ -visible and of a small size. Note
that in an expected τ -visible summary, there may exist
a clique which cannot be covered by any other clique
in the summary with a factor more than the extent of
τ . However, we still aim for expected visibility rather
than exact visibility, because (1) visibility itself has al-
ready meant that the summary is an approximation,
hence there may be less gain to enforce exact visibil-
ity; (2) the basic MCE algorithm (BK-MCE) which
we will introduce in Section 2.1 is a depth-ﬁrst search
approach. For expected visibility semantics, the great
pruning power of a sampling approach can terminate
search subtrees as early as possible so that the expo-
nential search space can be reduced signiﬁcantly and
the summary is promised to be concise with a suﬃcient
quality guarantee. An algorithm serving for exact vis-
ibility has to decide whether a search subtree can be
discarded at a relatively late stage, thus slows down
the running time.

Next, we start with introducing an existing depth-
ﬁrst MCE procedure [5] for maximal clique enumeration
in Section 2.1, and then explain how it can be modiﬁed
to ﬁnd an expected τ -visible summary by the state-of-
the-art work [36] in Section 2.2. Important notations
are listed in Table 1.

2.1 Maximal Clique Enumeration

BK-MCE algorithm [5] (Algorithm 1) is a backtracking
approach, which recursively calls procedure P rocM CE
to grow the current partial clique by adding a new
node from the candidate set until a maximal clique is

4

Xiaofan Li et al.

Table 1: Notations

Algorithm 1 BK-Maximal Clique Enumeration

Notation

Meaning

G(V, E)
GT
C
M(G)
S
VS (C)

E[VS (C)]
τ
N (v)
T
D

vp
r
l
r
s(r)
sopt(r)
T

the graph G with vertex set V and edge set E
the induced graph of vertex set T on graph G
a maximal clique
the set of all maximal cliques in graph G
a summary, which is a subset of M(G)
the visibility of maximal clique C w.r.t. sum-
mary S
the expectation of visibility VS (C)
the user-speciﬁed threshold
the neighbor node set of node v
the candidate set in BK-MCE algorithm
the candidate set whose elements should not be
touched in BK-MCE algorithm
the pivot in BK-MCE algorithm
the local visibility, refers to Formula (5)
the upper bound of the size of a maximal clique
the lower bound of local visibility
the sampling function used in [36]
the conditional optimal sampling function
a search subtree

found. Here we denote all the neighbor nodes of node
v by N (v). C is the current partial clique or conﬁgura-
tion, which is still growing. T and D are candidate sets
whose elements are common neighbors of C, while D
only contains nodes which have been contained by some
earlier output maximal cliques grown from the cur-
rent C. Algorithm 1 takes graph G(V, E) as input and
outputs all the maximal cliques in G. Initially it calls
procedure P rocM CE(∅, V, ∅) (line 1). Then P rocM CE
will be called recursively (line 10) until M(G) is gen-
erated. At every recursive stage P rocM CE will ﬁrst
check whether T = ∅ and D = ∅ (line 3). If so, it means
that there is no candidate node left, and therefore the
current C is output as a maximal clique (line 4). If not,
generally speaking, it will remove an arbitrary node v
from T and add it into C. Then it recursively calls pro-
cedure P rocM CE(C ∪ {v}, T ∩ N (v), D ∩ N (v)). Here,
T ∩N (v) is the reﬁned T by deleting all nodes which are
not neighbors of v, and the same for D ∩ N (v). It en-
sures that every node in T or D is a common neighbor
of the current C. Finally, since v is sure to be contained
by some future cliques grown from C, v is added into D
(lines 8-12). Note that a pivot vp is chosen for avoiding
some branches which will generate the same maximal
clique (line 6). This is because, from the current con-
ﬁguration, a maximal clique containing v which is a
neighbor of vp, can be grown either from vp or u. u is
a neighbor of v but not of vp.

Input: Graph G(V, E);
Output: M(G);
1: Call P rocM CE(∅, V, ∅)

Output C as a maximal clique; return

if T = ∅ and D = ∅ then

2: procedure P rocM CE(C, T, D)
3:
4:
5:
6:
7:
8:
9:
10:

Choose a pivot vertex vp from (T ∪ D);
T (cid:48) ← T \N (vp);
for each v ∈ T (cid:48) do

Call P rocM CE(C ∪ {v}, T ∩ N (v), D ∩ N (v));
T ← T \{v};
D ← D ∪ {v};

Algorithm 2 Summarization by Sampling

Input: Graph G(V, E), threshold τ ;
Output: An expected τ -visible summary S;
1: S ← ∅, C (cid:48) ← ∅;
2: Call P rocRM CE(∅, V, ∅).

include C in S; C (cid:48) ← C; return

3: procedure P rocRM CE(C, T, D)
if T = ∅ and D = ∅ then
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:

Calculate l and r;
Keep the branch T with probability l(cid:112)s(r);
if the branch T is kept then

Choose a pivot vertex vp from (T ∪ D);
T (cid:48) ← T \N (vp);
for each v ∈ T (cid:48) do

Call P rocRM CE(C ∪{v}, T ∩N (v), D∩N (v));
T ← T \{v};
D ← D ∪ {v};

2.2 Summarization by Sampling

Let us ﬁrst ignore sampling and consider a determinis-
tic enumeration that can ﬁnd a τ -visible summary: re-
call that BK-MCE is a depth-ﬁrst algorithm, it outputs
M(G) in such an order that two maximal cliques share
a large portion of common nodes if they are produced
next to each other. We denote this property as local-
ity. Let C (cid:48) be the last generated maximal clique which
has been added into summary S, when a new clique C
is generated, we can compare it with C (cid:48), rather than
with every clique in S, to compute a local visibility r
(Formula (5)). If r ≥ τ , discard C; otherwise, keep C.
Such a deterministic strategy will guarantee to produce
a τ -visible summary.

r =

|C ∩ C (cid:48)|
|C|

(5)

However, it will be desirable if we can discard a whole
search branch with good conﬁdence when we ﬁnd that
the branch has signiﬁcant overlap with the last found
clique C (cid:48). This leads to the idea of deliberately pruning
some recursive sub-procedures with some probability -

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

5

let us call it sampling. Meanwhile, we must guarantee
that the summary should have the expected visibility
E[VS (C)] ≥ τ, ∀C ∈ M(G).

Details about invoking a sampling method to give
an expected τ -visible summary are shown in Algorithm
2. The key idea is to execute a sampling operation (line
8) to determine whether this current new branch T
should be grown or not before entering a new proce-
dure P rocM CE(C, T, D) (line 13). In line 7, l denotes
an upper bound of the size of the next maximal clique C
and r denotes a lower bound of the local visibility r. As
we have not found C, i.e., l(= |C|) and r are unknown,
we can only estimate l and r. The sampling probability
function l(cid:112)s(r) is designed to be a function of l and r.
The work in [36] chose the probability function s() to
be:

s(r) =

(1 − r)(2 − τ )
(2 − r − τ )

(6)

and proved that applying s(r) in Algorithm 2 can pro-
duce a summary with the expected visibility E[VS (C)] ≥
τ, ∀C ∈ M(G). Due to the space limit, we brieﬂy intro-
duce the rationale of l(cid:112)s(r). From Formula (6), s(r) is a
decreasing function with range [0,1]. This means when
we ﬁnd the estimated r becoming larger, the probability
of keeping the current search branch becomes smaller.
When l is estimated larger, this implies that we will
call the recursion more times, hence the probability of
keeping the current search branch is made larger. Algo-
rithm 1 and Algorithm 2 follow the clique enumeration
paradigm, so the time complexities of them are both
bounded by O(3|V |/3) because a |V |-vertex graph has
at most 3|V |/3 maximal cliques [19]. Algorithm 2 should
be practically faster due to early prunings, but has the
same complexity in the worst case when τ = 1.

3 A new sampling function

Expected τ -visible summaries are not unique. Appar-
ently, the more concise (smaller) a summary is, the bet-
ter the summary is. Three questions arise naturally:

(1) Are there any better sampling strategies?
(2) What kind of sampling strategy is optimal?
(3) If ﬁnding the optimal is diﬃcult, how can we provide

the best eﬀort?

We will address question (1) in this section and dis-
cuss questions (2) and (3) in Section 4 and Section 5
respectively. In Section 3.1, we give our idea why we
consider there should exist a better sampling function,
then we introduce the new sampling function and prove
its superiority in Section 3.2.

3.1 Intuition

Our new sampling strategy is based on the following
two observations:

Observation 1: In Formula (6), when r ∈ (τ, 1), we
always have s(r) > 0. This means even if we know the
newly generated clique is τ -visible with respect to the
current S, there is still a positive probability to add
it into the summary. Thus S will be more redundant
because of these unnecessary cliques. A better strategy
is to set s(r) = 0 in such cases, which means not to add
these cliques at all.

Observation 2: In Formula (6), when r = 0, we
have s(r) = 1. This means once we ﬁnd a maximal
clique whose nodes are totally new to the current sum-
mary, we add it into S without hesitation. This seems
reasonable, however, there is still some possibility for
this brand new clique to be covered by some future
cliques. Moreover, considering we are looking for an ex-
pected τ -visible summary, which means that we have
the option not to include a brand new clique as long as
the ﬁnal summary is expected τ -visible. In other words,
it is safe to add the brand new clique with certain prob-
abilities. Cases where r is in (0, τ ) are similar.

3.2 Sampling Function sopt(r)

Following the observations in Section 3.1, we give a new
sampling function sopt(r) in Formula (7).

sopt(r) =

(cid:40) τ −r
1−r
0

, if r ∈ [0, τ ).

, if r ∈ [τ, 1].

(7)

The sampling function sopt(r) implies: if r ∈ [τ, 1], dis-
card the current search branch; otherwise, keep the cur-
rent search branch with probability τ −r
1−r . The rationale
of setting τ −r

1−r will be shown in Theorem 2.

Next, we prove that compared with s(r), sopt(r) is a
better function. This means that we need to prove: (1)
sopt(r) samples with a lower probability (in Theorem 1);
and (2) sopt(r) can produce an expected τ -visible sum-
mary (in Theorem 2).

Theorem 1 sopt(r) samples with a low probability than
s(r), i.e.

sopt(r) ≤ s(r), ∀r ∈ [0, 1]

(8)

The equation holds iﬀ r = 1.

Proof We show that this inequality holds when r ∈
[0, τ ) and r ∈ [τ, 1] separately:

6

Xiaofan Li et al.

- if r ∈ [τ, 1], we have sopt(r) = 0 and s(r) ≥ 0,
it is clear that this inequality is satisﬁed, and the
equation holds only when r = 1 (corresponding to
s(r) = 0).

- if r ∈ [0, τ ), since τ ∈ [0, 1] and r (cid:54)= 1, we have

s(r) − sopt(r) =

(1 − r)(2 − τ )
(2 − r − τ )

−

τ − r
1 − r

=

=

(1 − r)2(2 − τ ) − (2 − r − τ )(τ − r)
(2 − r − τ )(1 − r)
(1 − τ )((1 − r)2 + (1 − τ ))
(2 − r − τ )(1 − r)

> 0

(9)

Combining these two cases, we complete this proof.

While Theorem 1 promises us a more concise sum-
mary S, we have to prove that this S is indeed expected
τ -visible:

Theorem 2 Algorithm 2, with sampling function sopt(r),
can produce an expected τ -visible summary .

Proof First, we give the probability for a maximal clique
C being added into S. Then we calculate the expected
visibility E[VS (C)] and show it is no less than τ .

Recall that every time before Algorithm 2 starts a
new search subtree Ti, line 7 will compute a new pair of
l and r. We denote them by li and ri, where 1 ≤ i ≤ k
and k = |C| is the size of this maximal clique to be
grown. Since every li is an upper bound of k and every
ri is a lower bound of r, together with the monotonicity
of sopt(r), we have

P r[C ∈ S] = Π

1≤i≤k

P r[Ti is kept]

(cid:113)
li

sopt(ri)

(cid:113)
k

sopt(r)

= Π

1≤i≤k

≥ Π

1≤i≤k

= sopt(r)

(10)

If C is not included in S, its visibility VS (C) should
be no less than the local visibility r; if C is included in
S, VS (C) = 1. Now we can calculate the expectation of
VS (C):

E[VS (C)] ≥ 1 · P r[C ∈ S] + r · P r[C /∈ S]

≥ sopt(r) + r · (1 − sopt(r))

(11)

We show two cases where r ∈ [0, τ ) and r ∈ [τ, 1]

separately:

- if r ∈ [τ, 1], E[VS (C)] ≥ 0 + r · (1 − 0) = r ≥ τ .
- if r ∈ [0, τ ), E[VS (C)] ≥ τ −r

1−r + r · (1 − τ −r

1−r ) = τ .

Combining these two cases, we complete this proof.

Summary: Theorem 1 and Theorem 2 jointly show
that sopt(r) is a valid sampling function and is better
than s(r).

4 Optimality

In this section, for the purpose of analyzing the opti-
mality of the sampling function, we show what kinds of
conditions should be satisﬁed. We prove the optimal-
ity of sopt(r) under such conditions and further explain
why the performance of sopt(r) is good even without
the conditions being fully satisﬁed.

4.1 Conditions for Optimality Analysis

Since we can ﬁnd a better sampling function sopt(r),
another question comes out naturally: with the restric-
tion of expected τ -visibility, does an optimal sampling
function (even better than sopt(r)) with the smallest
probability exist?

In the proof of Theorem 2, we can only prove the
expectation E[VS (C)] ≥ τ . Intuitively, the smaller the
sampling probability is, the smaller the expectation is.
It is hard to determine whether a sampling function
is optimal because of lacking information on how loose
the inequality is. If we intend to analyze the optimality
of any function, we need to tighten this inequality to be
an equation ﬁrst. Now we show under what conditions
the theoretical analysis of optimality can be feasible.

In the proof of Theorem 2, we amplify E[VS (C)] two

times:

The ﬁrst inequality sign of Formula (11) is de-
rived from Formula (10). Algorithm 2 implements the
sampling operation in each recursive procedure using
the probability li(cid:112)sopt(ri). Since li and ri are upper
bound and lower bound of k and r respectively, we have
li(cid:112)sopt(ri) ≥ k(cid:112)sopt(r), thus P r[C ∈ S] ≥ sopt(r). Now
we have two approaches to eliminate this inequality.
The ﬁrst approach is that if we want to analyze the
property of the sampling function itself, we need to set
the other factors ideal. This means if we do not care
about the details of how to calculate li, we can assume
that this upper bound is ideal, so we have li = l, and
the same for ri. Note this hypothesis is made only for
the purpose of analyzing the function theoretically, not
for implementing Algorithm 2 in practice. With this
assumption, we have P r[C ∈ S] = sopt(r). The second
approach is to modify the sampling procedure. Now let

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

7

us sample using the probability sopt(r) only after a com-
plete maximal clique is generated, rather than sample
each time a new node is grown. If so, it is obvious that
P r[C ∈ S] = sopt(r). One may argue that it is mean-
ingless to do sampling once a maximal clique is found.
It is true that if we add every clique whose r is no more
than τ into summary, this summary is strictly τ -visible.
However, as we explained in Section 3, this would in-
troduce more redundancy to S. In some applications,
we only need this summary to be expected τ -visible, so
this one-step sampling procedure is signiﬁcant to give
such a concise S.

The second inequality sign of Formula (11) is
from the deﬁnition of r. Due to the locality of Algo-
rithm 2, we use r to replace the real visibility which
should be no less than r. Now we need to make the
assumption that such locality is suﬃciently strong (by
which we mean that two similar cliques should be pro-
duced consecutively), so that r is indeed the visibility
deﬁned in Formula (1). In practice, we do not need to
enforce such strong locality to implement Algorithm 2.
We introduce this hypothesis only for the theoretical
consideration, which means, we only need this assump-
tion to construct a framework under which we can an-
alyze the optimality of sampling functions. Once this
hypothesis is made, the second inequality becomes an
equation.

Now we can modify Formula (11) to be an equation:

E[VS (C)] = sopt(r) + r · (1 − sopt(r))

(12)

if the following two conditions are satisﬁed:

- The bounds of l and r are ideal, or we only do sam-
pling each time when a full maximal clique is gen-
erated.

- The property of locality is strong for r to be the real

visibility.

4.2 Optimality of sopt(r)

will also be disturbed thereafter. Since a nondetermin-
istic (sampling) algorithm can hardly know the exact
predecessor C (cid:48) of each maximal clique unless the algo-
rithm is ﬁnalized, it may be impossible to deﬁne ρ(r)
unless the summary is fully determined. Thus ρ(r) not
only is data-dependent, but also relies on the sampling
function s(r). Since s(r) should inversely rely on ρ(r), it
is likely to be hard to properly give ρ(r) an independent
deﬁnition.

For the above reasons, we choose not to seek a dis-
tribution related sampling function with the strong ver-
sion of optimality, but rather deﬁne the optimality as:
given the r value of maximal clique C, sampling
C with the lowest probability while still promis-
ing τ -visibility of the summary. We consider this
deﬁnition being more manipulatable theoretically and
applicable practically. And this optimality successfully
shows its eﬀectiveness in the experimental studies (see
Section 6). Now we can analyze the optimality of sopt(r)
in the framework introduced in Section 4.1.

Theorem 3 If the two conditions in Section 4.1 are
satisﬁed, sopt(r) is optimal for Algorithm 2.

Proof We show that if there exists a sampling function
s(cid:48)(r), such that ∀r ∈ [0, 1], s(cid:48)(r) ≤ sopt(r) and for at
least one point r0 there is s(cid:48)(r0) < sopt(r0), such a func-
tion cannot be used to generate an expected τ -visible
summary.

Note sopt(r) = 0 when r ∈ [τ, 1], r0 cannot be in this
range, since a valid probability should be nonnegative.
So we have r0 ∈ [0, τ ), and

E[VS (C)]|r0 = s(cid:48)(r0) + r0 · (1 − s(cid:48)(r0))

< sopt(r0) + r0 · (1 − sopt(r0))

=

τ − r0
1 − r0

= τ

+ r0 · (1 −

τ − r0
1 − r0

)

(13)

This means that the summary generated by s(cid:48)(r) can-
not be expected τ -visible.

One may expect that the optimality should be deﬁned
as minimizing the expected cardinality of the summary.
However, we notice that such a strong version of opti-
mality requires the sampling function s(r) to be a func-
tion of the distribution of r: ρ(r), rather than simply
a function of r. Accordingly, we have to report that it
is not easy to give a proper deﬁnition for ρ(r). This is
due to such a fact: ρ(r) could not be known until the
summary has been found. This fact holds because the
r value of maximal clique C depends on which maxi-
mal clique C (cid:48) it is compared with: once C (cid:48) changes, the
value of r will change accordingly, and distribution ρ(r)

Theorem 3 is a conditional theoretical guarantee for
the optimality of sopt(r). Note even if in general cases
these two strong conditions are not fully satisﬁed, The-
orem 3 is still useful for the practical implementation
of Algorithm 2. That means if the bounds l and r are
well estimated and the property of locality is strong,
the inequalities in Formula (11) can be very tight. In
such cases, sopt(r) can still show good performance.

One may concern that it is not clear to what ex-
tent we can achieve the good performance of sopt(r) in
practice by (1) tightening bounds; (2) strengthening the
locality. In the next section, we address the ﬁrst concern

8

Xiaofan Li et al.

by reviewing two existing bounds and proposing a new
one which outperforms the other two by large margins.
For the second concern, we show that stronger locality
can be achieved by reordering vertices carefully. We will
review an existing vertex order and design a new better
one.

5 Bounds and Locality

In this section, we show how to approach good per-
formance of the new sampling strategy by tightening
bounds (Section 5.1) and by reordering vertices (Sec-
tion 5.2).

5.1 Bound Analysis

The ﬁrst inequality of (11) is derived from bound esti-
mation. Note that Formula (14) we use to calculate the
lower bound r is the same as that introduced in [36]:

r = min
1≤t≤d

|C ∩ C (cid:48)| + max{t − yt, 0}
|C| + t

(14)

where C (cid:48) is the previous maximal clique added into
S; t is the number of vertices to be used for growing
the partial conﬁguration C into a full maximal clique;
d, which satisﬁes l = |C| + d, is the upper bound of
t; and given yt out of the t vertices are not covered
by C (cid:48), yt is an upper bound of yt. Formula (14) can
be understood in this way: suppose we know that the
current partial conﬁguration C still needs t vertices to
grow into a full maximal clique P , then the dominator
|C| + t is the size of P . Since yt means that at most
yt out of t vertices in P \C are not contained by C (cid:48),
this means that at least t − yt are covered by C (cid:48). Thus
max{t−yt, 0} is a lower bound of the size of (P \C)∩C (cid:48).
(The max operator is inserted here because depending
on the estimation method of yt, t−yt may be negative.)
Now we see that the two parts of the numerator are
|C ∩ C (cid:48)| and a lower bound of |(P \C) ∩ C (cid:48)| respectively,
thus the sum is a lower bound of |P ∩C (cid:48)|. Combining the
discussions above, the whole fraction is the very lower
bound of r ≡ |P ∩ C (cid:48)|/|P |. Since we lack information of
the exact value of t, we have to enumerate all possible
t in [0, d] and choose the minimum as the lower bound.
yt can be estimated as |T \C (cid:48)|, or simply the value of t,
or the number of vertices in T \C (cid:48) whose degrees are at
least t−1 (because these yt vertices should be contained
by a t-clique). We see here the upper bound d ( = l −
|C|, where |C| is known) is used to estimate r, and
the fraction after the min1≤t≤d operator has nothing
related to d (because it is calculated after t is given),

so the quality of r is determined by the tightness of d
(or l). Thus in the following, we focus on estimating d.
One valid and tight bound of d is the size of the
maximum clique in candidate set T , however, ﬁnding
such a maximum clique itself is a clique enumeration
problem which is of exponential time. As a result, we
should consider realistic bounds instead. In the follow-
ing, we review two bounds that were discussed in the
previous work [36], then we propose a new one to fur-
ther improve the eﬀectiveness of sopt(r).

Let GT be the induced graph of the candidate set T
on graph G, then two existing upper bounds of d are:

- H bound, denoted by dh, is the maximum h so that
there exist at least h vertices in GT whose degrees
are no less than h − 1. The maximum clique size
can be bounded by h because if there exists a k-
clique, there should also exist at least k vertices in
GT whose degrees are no less than k − 1. Therefore
h ≥ k holds for all possible k-cliques, including the
maximum clique.

- Core bound, denoted by dcore = Core(GT ) + 1,
where Core(GT ) denotes the maximum core number
in GT . We now review the deﬁnition of k-core [26]
and core number ﬁrst.

Deﬁnition 5 (k-core) The k-core of a graph G is the
largest induced subgraph in which the degree of each
vertex is at least k.

Deﬁnition 6 (Core Number) The core number of
graph G, denoted as Core(G), is the largest k such that
a k-core is contained in G.

The core number can serve as an upper bound because
k-core is weaker than k-clique: a k-clique must be a (k-
1)-core, while a (k-1)-core may not be a k-clique. Thus
Core(GT ) + 1 will be no less than the maximum clique
size in GT . Now we deﬁne our newly proposed bound.

Deﬁnition 7 (Truss bound) Truss bound, denoted
by dtruss, is the maximum truss number T russ(GT ) in
GT .

Now we review the deﬁnition of k-truss and truss num-
ber, and then explain why the maximum truss number
T russ(GT ) is valid to be an upper bound.

Deﬁnition 8 (k-truss) The k-truss of a graph G is
the largest induced subgraph in which each edge must
be part of k − 2 triangles in this subgraph.

Deﬁnition 9 (Truss Number) The truss number of
graph G, denoted as T russ(G), is the largest k such
that a k-truss is contained in G.

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

9

dtruss is a upper bound of the size of maximum clique.
This is because a k-clique with the maximum k is also a
k-truss since each edge in a k-clique is strictly contained
by k −2 triangles. Thus the truss number cannot be less
than the maximum clique size k.

These three bounds satisfy the following inequality:

dh ≥ dcore ≥ dtruss

(15)

The ﬁrst inequality holds because H bound does not
enforce the h vertices to be connected, while core bound
does. The second inequality comes from the fact that
a k-truss must be a (k − 1)-core. This is because the
endpoints of each edge e should be incident to no less
than k−1 edges (including e itself) since e is guaranteed
to be involved in at least k − 2 triangles.

The cost of evaluating these bounds are:

dh : O(VT ); dcore : O(ET ); dtruss : O(E1.5
T )

(16)

where VT and ET are vertex set and edge set of the
induced graph GT respectively. The induced graph GT
can be constructed when selecting the pivot thus its
construction does not incur an extra cost. For dh, when
constructing GT , we can maintain a VT -length array to
record the number of vertices at each degree value. This
can be done in O(VT ). Then the H-value can be found
by scanning this array from tail (where the numbers of
vertices with higher degree values are stored) to head
(where the numbers of vertices with lower degree values
are stored) until h vertices whose degrees are no less
than h − 1 are found. This step is also in O(VT ). For
dcore, an O(ET ) core decomposition [13] is needed after
GT is found. For dtruss, the truss decomposition takes
O(E1.5
T ) to ﬁnd the maximum truss number [35].
We see that the truss bound is the tightest one
among all of the three, and therefore it promises the
best performance in terms of eﬀectiveness. The intrin-
sic is the fact that the structure of truss is more com-
pact (or cohesive) than the other two. (This property of
compactness can also be used to design vertex orders to
enhance the locality. We will give a detailed discussion
soon in Section 5.2.) Users may have their own prefer-
ences to balance the running time and summary size.
Thus which bound to select depends on to what extent
the eﬀectiveness can be improved by sacriﬁcing the eﬃ-
ciency. In Section 6, we conduct experimental studies to
compare the practical performance of diﬀerent bounds
in terms of both eﬀectiveness and eﬃciency.

5.2 Locality Analysis

C, the local visibility computed with the previous out-
put clique C (cid:48) should be close to the global visibility
which is computed with the most similar clique to C
in the summary. However, such a condition is diﬃcult
to meet. Reﬂected in practice, one typical implementa-
tion is the vertex order we should follow to grow the
current partial clique. An eﬀective vertex order with
strong locality should have such a property that each
candidate set T of the current conﬁguration C has a
suﬃciently compact structure. Here, by compact (or co-
hesive) we mean that the nodes of a candidate set are
well-connected with each other such that cliques in this
set have a higher probability to overlap.

One question arises: in the outer recursion level of
BK-MCE, since the neighbor set N (v) of the only ver-
tex v in the current partial clique C={v} is uniquely
determined by the graph G(V, E), why we still expect
a particular structure in the candidate set of {v}? The
answer is that if we implement a ﬁxed vertex order to
grow cliques, when we include v into C, all the neigh-
bors of v which precede it in the order can be safely
moved into set D. The key point is that the diﬀerence
between N (v) and the candidate set of {v} is deter-
mined by the particular order we choose, thus leaves
us the very opportunity to reshape the structure of the
candidate set. The same holds for each level of the re-
cursion.

Now we see that strong locality can be achieved by
reordering vertices. In the following, we explain why
degeneracy order can be employed to achieve this goal
even if the initial purpose of it is to bound time com-
plexity of the BK-MCE [12]. Then we propose a novel
truss order based on truss decomposition to further en-
hance locality. Now we begin with the deﬁnition of de-
generacy.

Deﬁnition 10 (Degeneracy) Given a graph G(V, E),
the degeneracy of G is the smallest value d, such that
every subgraph of G contains a vertex whose degree is
no more than d.

Degeneracy is naturally related to a special vertex order
below.

Deﬁnition 11 (Degeneracy Order) The vertices of
a d-degeneracy graph have a degeneracy order, in which
each vertex v has only d or fewer neighbors after itself.

Degeneracy order can be formed by repeatedly delet-
ing the minimum degree vertex with all its edges on the
current subgraph. Note this actually is the core decom-
position procedure [13], thus this order sorts vertices by
core number from low to high.

Strong locality implies that two similar cliques should
be produced consecutively. This means, for a new clique

The reason why this order can be used to enhance
locality is straightforward. We explain it by focusing

10

Xiaofan Li et al.

Table 2: Statistics of datasets

Name

|V |

|E|

Cliques

τ -RMCE-TU [τ = 0.5/0.9]

τ -R+MCE-TU [τ = 0.5/0.9]

soc-Epinions1
loc-Gowalla
amazon0302
email-EuAll
NotreDame
com-youtube
soc-pokec
cit-Patents

75,879
196,591
262,111
265,214
325,729
1,134,890
1,632,803
3,774,768

508,837
950,327
1,234,877
420,045
1,497,134
2,987,624
30,622,564
16,518,948

1,775,065
960,916
403,360
377,750
495,947
3,265,951
19,376,873
14,787,031

18.1% / 77.9%
33.9% / 85.3%
68.8% / 95.6%
71.3% / 93.6%
69.2% / 93.7%
62.8% / 93.8%
61.1% / 93.3%
86.4% / 96.4%

2.5% / 31.3%
3.9% / 30.3%
15.8% / 37.8%
3.7% / 14.0%
5.1% / 17.0%
6.0% / 23.5%
6.0% / 27.3%
7.6% / 20.2%

on this particular scene during MCE procedure that a
vertex v is being moved from candidate set T to partial
clique C. This v and all vertices of G that are reordered
after v in the degeneracy order induce a subgraph G(cid:48).
By the construction of degeneracy order, we know v
is the minimum degree vertex in G(cid:48), which is denoted
by d(v), thus G(cid:48) is a d(v)-core. Since the candidate set
T is a subset of G(cid:48), we reach the conclusion that T is
contained by a d(v)-core, which is our desirable com-
pact structure with strong locality. Although existing
works [12] [24] studied using degeneracy to speed up
MCE in the aspect of running time, to our best knowl-
edge, our work is the ﬁrst to exploit degeneracy order
to strengthen the locality for the purpose of reducing
overlapping cliques. To further enhance the locality, we
notice that the key of locality is to guarantee the candi-
date set T to be contained by a compact structure, e.g.,
k-core. Hence if we can ﬁnd a novel vertex order that
has a stronger guarantee, e.g., T is covered by a k-truss,
then we can foresee that the performance in terms of
eﬀectiveness will outperform that of degeneracy order.
Following this intuition, we carefully inspect the rela-
tionship between core decomposition and degeneracy
order, and ﬁnd that such a relationship also applies to
the truss decomposition and a new vertex order (truss
order).

Deﬁnition 12 (Truss Order) Vertices sorted by truss
order satisfy such a property: if k is the maximum value
that there exists a k-truss containing vertex v, then all
the vertices reordered after v should also be contained
by the same k-truss.

Truss order can be formed during the procedure of
truss decomposition. We ﬁrstly delete the edge (u, v)
which is contained by the least number of triangles
(this number is denoted by the support of an edge).
After (u, v) is removed, the supports of all edges whose
endpoints contain u or v decrease by 1. The procedure
repeats until all the edges are removed. Then the order
that vertices are peeled oﬀ from G is a valid truss order.
This is because the order sorts each vertex by the max-

imum value of k that there exists a k-truss containing
it. The same analysis why degeneracy order enhances
locality applies to truss order: by Deﬁnition 12, the can-
didate set T is guaranteed to be contained by a k-truss.
Since what we desire is a compact structure of can-
didate set, k-truss is apparently more favorable than
k-core. Note that the concept of locality is more goal-
driven and the extent of locality is output-determined.
Hence, instead of giving a formal theoretical analysis
which we found diﬃcult, we decide to use extensive ex-
periments to illustrate the eﬀect of three types of vertex
orders on output size. We will report experimental re-
sults in Section 6 to compare the performance of these
two vertex orders with random order as a baseline in
terms of both eﬀectiveness and eﬃciency.

6 Experimental Evaluation

In this section, we look into three research questions
by experiments. (1) To what extent the summary size
and running time can be reduced by τ -R+MCE vs.
τ -RMCE? (2) To what extent the eﬀectiveness of τ -
R+MCE can be further improved by our newly pro-
posed truss order and truss bound? (3) To what ex-
tent our newly designed truss order and bound aﬀect
the eﬃciency (both running time and memory require-
ment)? For short, we denote the the τ -visible MCE al-
gorithm [36] by τ -RMCE and ours by τ -R+MCE. All
algorithms are implemented in C++ and tested on a
MacBook Pro with 16GB memory and Intel Core i7
2.6GHz CPU 64. We evaluated both eﬀectiveness (in
terms of summary size) and eﬃciency (in terms of ﬁrst-
result time, total running time and total memory re-

Table 3: Notations

Setting Meaning

T, H, C
U, I, R

Truss bound, H bound, Core bound
Truss order, Degeneracy order, Random order

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

11

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 1: Summary size of τ -R+MCE and τ -RMCE on eight datasets with τ varied from 0.5 to 0.9, T and U as default

quirement) with τ varying from 0.5 to 0.9. τ -R+MCE
and τ -RMCE were implemented with three types of
bounds (truss bound (T), core bound (C), H bound
(H)) as well as three vertex orders (truss order (U),
degeneracy order (I), random order (R)). Details are
shown in Table 3. All results were reported by an aver-
age of ﬁve runs.

Datasets We use eight real-world datasets from dif-
ferent domains with various data properties to show the
robustness of our algorithms. To provide a more com-
prehensive comparison with τ -RMCE, we also test the
algorithms on the dataset cit-Patents that contains the
largest number of vertices used by the work [36]. Details
are shown in Table 2. For each dataset, we denote by
|V | the number of vertices, by |E| the number of edges
and by Cliques the total number of maximal cliques as
reference. The 5th and 6th column denotes the fraction
summary size/total number of maximal cliques for τ -
RMCE-TU and τ -R+MCE-TU with the best conﬁgu-
ration (Truss bound (T) and Truss order (U)) respec-
tively. The percentage before and after / is the value
at τ = 0.5 and τ = 0.9 respectively. For example, for
soc-Epinions1 at the 5th column, 18.1%/77.9% means
that the sizes of summaries produced by τ -RMCE oc-
cupy 18.1% and 77.9% of the total number of maximal
cliques at τ = 0.5 and τ = 0.9. All datasets used in this
paper can be found in Stanford Large Network Dataset
Collection1.

1 Available at http://snap.stanford.edu/data/index.html

6.1 Eﬀectiveness

To evaluate the eﬀectiveness of our algorithm, we com-
pare the size of the summaries generated by τ -RMCE
and τ -R+MCE in Section 6.1.1 (both with T bound
and U order as default). To see to what extent our pro-
posed truss bound and truss order beneﬁt eﬀectiveness,
we implemented τ -RMCE and τ -R+MCE with three
orders (U, I, R, bound T as default) in Section 6.1.2,
and with three bounds (T, C, H, order U as default) in
Section 6.1.3.

6.1.1 Summary size

We implemented τ -RMCE and τ -R+MCE with the best
conﬁgurations using truss bound and truss order, which
are denoted by τ -RMCE-TU and τ -R+MCE-TU re-
spectively. The results are shown in Fig. 1. We see that
τ -R+MCE-TU consistently outperforms τ -RMCE-TU
on all datasets with all the τ values.

When τ = 0.9, τ -R+MCE-TU signiﬁcantly reduces
more than 50% output cliques vs. τ -RMCE-TU on all
datasets, three of which (Fig. 1f, 1g, 1h) achieve 70%,
and two of which (Fig. 1d, 1e) even achieve more than
80%. When τ decreases, the diﬀerence is more dra-
matic, i.e., the percentage of reduction monotonically
increases. At τ = 0.5, the reduction for all datasets is
more than 70%, two of which (Fig. 1a, 1b) reach 85%,
and ﬁve of which (Fig. 1d, 1e, 1f, 1g, 1h) reach 90%
to reduce the summary size by more than one order
of magnitude. This monotonic increasing trend implies
that the performance of τ -R+MCE-TU performs more
signiﬁcantly than τ -RMCE-TU along with τ decreas-

12

Xiaofan Li et al.

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 2: Summary size of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent orders, τ varies from 0.5 to 0.9,
T bound as default

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 3: Average r of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent orders, τ varies from 0.5 to 0.9, T
bound as default

ing. This is because for a small threshold, τ -RMCE in-
cludes more unnecessary cliques whose visibilities are
greater than τ into the summary with high probabil-
ities, which conﬁrms our intuition in Section 3 that
sopt(r) should be set to 0 for r ∈ [τ, 1]. Another rea-
son is that for a clique C whose visibility is close to 0,
s(r) forces τ -RMCE to output C immediately, while τ -
R+MCE considers the potential that C may be covered
by some future cliques, thus more carefully outputs such
a clique with a proper probability. To show the robust-
ness of our proposed method, we tested the algorithms

on eight real-world datasets with diﬀerent scales. The
results show that τ -R+MCE achieves relatively better
performance on large graphs. For the convenience of our
discussion, now we focus on the results at τ = 0.5. We
see that all the ﬁve datasets (Fig. 1d, 1e, 1f, 1g, 1h)
that have more than 90% reductions are the top ﬁve
largest graphs among all eight datasets. This implies
that our proposed method are more capable to handle
contemporary large scale graphs than the state-of-the-
art approach.

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

13

6.1.2 Eﬀect of vertex orders

To see to what extent the performance of τ -R+MCE
can be further improved by employing a vertex order
with strong locality, we implemented τ -R+MCE and τ -
RMCE with three types of orders: random order (R),
degeneracy order (I) and truss order (U). The default
bound was set as truss bound (T). The results are
shown in Fig. 2.

Fig. 2 shows that truss order consistently outper-
forms degeneracy order and random order for both τ -
R+MCE and τ -RMCE, while generally degeneracy or-
der is superior to random order except one exception
(τ -R+MCE on loc-Gowalla at τ = 0.8). Now we focus
our discussion on τ -R+MCE. Generally τ -R+MCE-TI
is superior to τ -R+MCE-TR for all τ values on 7 out
of 8 datasets (except web-NotreDame), while the reduc-
tion percentage (10% ∼ 20%) is not signiﬁcant. How-
ever, the reduction for τ -R+MCE-TU vs. τ -R+MCE-TI
is much dramatic: at τ = 0.5, the reduction percent-
age varies from 33% (soc-pokec) to 83% (com-youtube),
and 5 out of 8 achieve more than 50% (except soc-
Epinions1, amazon0103, soc-pokec).

To further show how diﬀerent orders help our ap-
proach get close to the optimal, we calculate the actual
average r for each dataset w.r.t diﬀerent τ values. We
take every maximal clique generated by MCE into con-
sideration. If a search subtree should be pruned at a
certain stage, we keep searching the subtree to calcu-
late r of the discarded cliques while disallowing these
cliques to be added into summary S. Results are shown
in Fig. 3. This set of experiments show that with τ
decreasing from 0.9 to 0.5, the average visibility r of
τ -RMCE changes very mildly and keeps no less than
0.9 for all the datasets, regardless which vertex order
is implemented. For datasets except loc-Gowalla, the
lines of τ -RMCE overlap with each other, which implies
that diﬀerent types of vertex orders may have limited
impact on the state-of-the-art approach. However, the
three lines of τ -R+MCE drop sharply from around 0.95
to below 0.6 for every dataset. They are thus much
closer to the optimal reference line (represented by the
user-speciﬁed threshold in red). τ -R+MCE-TR shows
the worst performance among the tested three vertex
orders, of which the line drops from around 0.95 to 0.6
for all the datasets. τ -R+MCE-TI shows better eﬀec-
tiveness (which drops from around 0.95 to 0.55) than τ -
R+MCE-TR, and τ -R+MCE-TU shows the best perfor-
mance (which drops from 0.93 to 0.52). We see that the
setting of truss order U successfully helps τ -R+MCE
step forward to the optimal reference line, which leaves
a narrow gap between them.

Fig. 2 and Fig. 3 conﬁrm our assumption that the
eﬀectiveness of τ -R+MCE can be further improved by
properly reordering vertices. The newly designed truss
order signiﬁcantly outperforms the degeneracy order by
a large margin due to strong locality provided by the
cohesiveness of k-truss.

6.1.3 Eﬀect of bounds

To see to what extent the eﬀectiveness of τ -R+MCE
can be further improved by employing a tight bound,
we implemented τ -R+MCE and τ -RMCE with three
diﬀerent bounds: H bound (H), core bound (C) and
truss bound (T). Truss order (U) was set to be the
default. The results are shown in Fig. 4.

We see that for both τ -R+MCE and τ -RMCE, the
performance of eﬀectiveness consistently follows this or-
der: T outperforms C, and C outperforms H. When we
focus on τ -R+MCE, results show that τ -R+MCE-CU
reduces the summary size vs. τ -R+MCE-HU by less
than 10% for all τ values on all datasets. However, the
reduction between τ -R+MCE-TU and τ -R+MCE-CU
ranges from 21% to 43%. At τ = 0.5, the percentage
achieves more than 30% for four out of eight datasets
(except email-EuAll, web-NotreDame, com-youtube, cit-
Patents).

Fig. 5 reports the average of r for τ -RMCE and τ -
R+MCE with diﬀerent bounds. The results are similar
to Fig. 3. We see that the three lines of τ -RMCE stay
much closer with each other for all datasets, and the
line of τ -RMCE-TU keeps slightly lower than the other
two lines. This implies that various bounds can provide
only limited improvements to the existing sampling ap-
proach. Whereas for τ -R+MCE, we see that a better
bound helps the three lines move towards the required
threshold by a signiﬁcant margin. The gap between
τ -R+MCE-TU and τ -R+MCE-CU is much more dra-
matic than that between τ -R+MCE-CU and τ -R+MCE-
HU, which conﬁrms the superiority of the newly applied
truss bound T.

Fig. 4 and Fig. 5 conﬁrm the fact that the eﬀec-
tiveness of τ -R+MCE can be further improved by em-
ploying tight bounds. Although the extent of beneﬁt
brought by good bounds is inferior to that brought by
vertex orders with strong locality, our proposed truss
bound still surpasses the state-of-the-art core bound by
a signiﬁcant margin.

6.2 Eﬃciency

While our main concern in this paper is the output size,
the eﬃciency of τ -RMCE and τ -R+MCE (with three
types of bounds and orders) is also reported. To provide

14

Xiaofan Li et al.

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 4: Summary size of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent bounds, τ varies from 0.5 to
0.9, U order as default

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 5: Average r of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent bounds, τ varies from 0.5 to 0.9, U
order as default

a fuller discussion of the eﬃciency, we plotted both the
total running time and the memory requirement.

6.2.1 Running time

We compare the total running time of τ -R+MCE and
τ -RMCE with default setting of U and T (see Fig. 6).
Results show that τ -R+MCE consistently surpasses τ -
RMCE on eight datasets. When τ = 0.9, the time
reduction is more than 20% for all datasets, among
which four datasets (soc-Epinions1, email-EuAll, com-
youtube, cit-Patents) achieve 30%. When τ = 0.5, this

percentage exceeds 35% for all datasets, and ﬁve of
them (soc-Epinions1, amazon0302, email-EuAll, com-
youtube, cit-Patents) achieve more than 40%.

To get a full understanding of why our proposed
method beneﬁts eﬃciency (although our initial purpose
is to target the eﬀectiveness), we recorded the ﬁrst-
result time, that is, the duration from the beginning
to the ﬁrst maximal clique being included into sum-
mary. We found that the result varies very little for
diﬀerent bounds and vertex orders. Thus we use Ta-
ble 4 to brieﬂy summarize the results (T and U are

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

15

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 6: Running time of τ -R+MCE and τ -RMCE on eight datasets, τ varies from 0.5 to 0.9, T bound and U order as default

set as default, τ = 0.9). The ﬁrst-result time takes up
only a very small proportion (less than 7%) of the total
running time, and this holds for both τ -R+MCE and
τ -RMCE on eight datasets with all the τ values. The
fact is that most of the running time (more than 93%)
is consumed by the enumeration procedure, which im-
plies that the beneﬁted eﬃciency of τ -R+MCE comes
from the early pruning power that speeds up the enu-
meration recursion. The search tree of τ -R+MCE does
not have to explore as deep as τ -RMCE does to ﬁnally
determine whether to discard a candidate clique, thus
less time is wasted on growing cliques that would result
in redundancy.

6.2.2 Eﬃciency of orders

To test the eﬃciency of three types of vertex orders,
we implement τ -RMCE and τ -R+MCE with orders U,
I and R. The default bound is set to T. We recorded
both the total running time and memory requirement
for all experiments. The details are shown in Fig. 7 and
Fig. 8.

Running time: Fig. 7 shows that the results of τ -
R+MCE and τ -RMCE are very similar on each dataset,
hence we focus on curves of τ -R+MCE. We see that τ -
R+MCE-TU shows the best performance on ﬁve out
of eight datasets (soc-Epinions1 (18% ∼ 29%), ama-
zon0302 (5% ∼ 7%), email-EuAll (8% ∼ 23%), com-
yotube (15% ∼ 40%), cit-Patents (3% ∼ 4%), where
the percentages in parentheses are the range of reduc-
tions vs. τ -R+MCE-TI). It shows similar performances
as τ -R+MCE-TI on two datasets (web-NotreDame, soc-
pokec) since the two lines coincide with each other. τ -

Table 4: First-Result Time (s) at τ = 0.9

Name

τ -RMCE-TU

τ -R+MCE-TU

soc-Epinions1
loc-Gowalla
amazon0302
email-EuAll
NotreDame
com-youtube
soc-pokec
cit-Patents

0.62
8.55
0.21
1.22
5.97
12.33
40.11
10.30

0.61
8.55
0.21
1.20
5.97
12.32
39.57
9.27

R+MCE-TU shows the worst performance on a spe-
cial dataset loc-Gowalla because of its small degener-
acy. This result implies that beneﬁted from its summa-
rization eﬀectiveness, τ -R+MCE-TU shows a compara-
ble or even better performance than the state-of-the-art
order on a variety of real-world datasets. However, de-
generacy order is still the best choice for graphs with
small degeneracies that this order is initially designed
for.

Memory requirement: Fig. 8 shows the mem-
ory requirement for diﬀerent orders. We see that the
truss order U consistently outperforms the other two for
both τ -R+MCE and τ -RMCE. The memory reduction
of τ -R+MCE-TU vs. τ -R+MCE-TI varies little when τ
changes. The reduction is more than 10% for all eight
datasets, with two of which (email-EuAll, com-youtube)
even achieving 30%. The results of memory cost are
much similar to the output size. This is because the
memory requirement highly relies on the depth of re-
cursion: more number of deep branches result in higher
memory consumption. The strong locality thus early

16

Xiaofan Li et al.

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 7: Running time of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent orders, τ varies from 0.5 to 0.9, T as default

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 8: Memory requirement of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent orders, τ varies from 0.5
to 0.9, T bound as default

pruning power of τ -R+MCE-TU prevents some of the
redundant branches from growing unnecessarily deep,
hence the memory requirement can be reduced signiﬁ-
cantly, which has the same reason why the output sum-
mary size is reduced.

6.2.3 Eﬃciency of bounds

We test the eﬃciency of diﬀerent bounds (T, C, H)
with default vertex order U. Both the total running
time (Fig. 9) and memory requirement (Fig. 10) are
recorded.

Running time: Fig. 9 shows that for both τ -R+MCE

and τ -RMCE, H bound is the fastest choice on ﬁve
out of eight datasets (except for soc-Epinions1, ama-
zon0302, email-EuAll). U bound runs most slowly on
seven out of eight datasets (except for soc-Epinions1).
However, we still notice that the time diﬀerences be-
tween τ -R+MCE-TU and τ -R+MCE-CU are narrowed
with τ decreasing for all datasets. This is consistent
with Fig. 4: since the summary reduction increases with
τ decreasing, the beneﬁt of early pruning gradually oﬀ-
sets the cost of bound calculation. This explains why τ -
R+MCE-TU shows the best performance when τ ≤ 0.7.

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

17

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 9: Running time of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent bounds, τ varies from 0.5 to
0.9, U order as default

(a) soc-Epinions1

(b) loc-Gowalla

(c) amazon0302

(d) email-EuAll

(e) web-NotreDame

(f) com-youtube

(g) soc-pokec

(h) cit-Patents

Fig. 10: Memory requirement of τ -R+MCE and τ -RMCE on eight datasets with diﬀerent bounds, τ varies from
0.5 to 0.9, U order as default

Memory requirement: As we explained in Sec-
tion 6.2.2, the result of memory requirement is similar
to that of output size. The performance of three bounds
for both τ -R+MCE and τ -RMCE are quite clear: U
is better than C, and C is better than H. When we
focus on τ -R+MCE, we see that the memory reduc-
tion of τ -R+MCE-TU vs. τ -R+MCE-CU is more than
10% on eight datasets for all τ values, among which
four datasets (soc-Epinions1, com-youtube, soc-pokec,
cit-Patents) even achieves 25% at τ = 0.5. This reduc-
tion is mainly caused by the fact that a tight bound thus
early pruning helps to avoid redundant search branches

from growing unnecessarily deep, which shows the su-
periority of the truss bound.

6.3 Algorithm Realization

In this subsection, we discuss one detail of the algo-
rithm realization: during each recursion of Algorithm 2,
to calculate the intersection C ∩ C (cid:48) by merge join, we
have to sort the vertices of C according to a given order.
This is caused by such an undetected fact: even if we
strictly select each vertex in candidate set T (cid:48) by a given
order to grow the current partial clique C, the order of

18

Xiaofan Li et al.

vertices in C is still disorganized due to pivot selection.
The other intersection operations (T ∩ N (v), D ∩ N (v))
in Algorithm 2 have no such requirement of vertex sort-
ing. Ignorance of such a fact can lead to wrong outputs
while the algorithm runs improperly fast. This explains
why our results of τ -RMCE diﬀer from the work [36],
where the results show that the output size of τ -RMCE
changes dramatically when τ decreases. However, with
our appropriate implementation, we indeed ﬁnd that
both output size and running time decrease much more
slowly when τ varies from 0.9 to 0.5. Even if we set the
default parameter as our newly proposed truss bound T
and truss order U, the decreases are much less dramatic
than the results shown in the work [36]. Besides, we test
the algorithms on eight benchmark real-world datasets
from various domains, all of which show very similar re-
sults. Hence we believe that our results are convincing.
Moreover, we did not include two other datasets Skit-
ter and Wiki used by [36] because although the vertex
numbers of them are less than cit-Patents, the running
times of τ -RMCE with our appropriate implementation
on these two datasets are not as fast as anticipated. Be-
cause of the inherent nature of the clique enumeration
problem, once the input graph gets large, the processing
time becomes unbearable. Therefore, we chose datasets
that are relatively manageable (3600s for the running
time limit). For extremely large datasets, we believe
that parallel and distributed computing solutions are
more preferred, which could be very interesting to ex-
plore [10, 25, 38]. Accordingly, we are excited to raise
this problem in the future work section to attract more
attentions from the research community.

6.4 Summary

After a comprehensive discussion of all experiments, we
can now answer the three questions at the beginning of
Section 6:

(1) τ -R+MCE consistently outperforms τ -RMCE
for both eﬀectiveness and eﬃciency on all datasets with
all the τ values. The output reduction can be up to one
order of magnitude, and time reduction is more than
35% at τ = 0.5. τ -R+MCE achieves relatively better
performance on large graphs than τ -RMCE.

(2) When implemented with τ -R+MCE, the truss
order reduces up to 83% output size vs. the state-of-
the-art degeneracy order at τ = 0.5, and this reduction
of truss bound vs. core bound can be up to 43%. The
boost of vertex order is more signiﬁcant than that of
bounds.

(3) The running time of truss order with τ -R+MCE
has comparable or even better performance than the
degeneracy order except when implemented on small

degeneracy graphs. The memory requirement of truss
order consistently shows the best performance, of which
the reduction vs. degeneracy order is more than 10%.
Although the eﬃciency of truss bound is surpassed by
core bound and H bound, the diﬀerence is narrowed
with τ decreasing. The memory requirement of truss
bound still shows the best performance, which achieves
more than 10% reduction vs. core bound.

7 Related Work

The number of maximal cliques in an undirected graph
is proved to be exponential [19]. Bron and Kerbosch [5],
Akkoyunlu et al. [2] introduced backtracking algorithms
to enumerate all maximal cliques in a graph. There are
suﬃcient studies focusing on the eﬃciency of MCE. To
eﬀectively reduce the search space, pruning strategies
were introduced in [6, 14, 32] by selecting good pivots.
The key idea is to avoid searching in some unnecessary
branches which leads to duplicated results. Degeneracy
vertex ordering was introduced by [12] to bound the
time complexity because with the degeneracy order the
size of candidate set T in the ﬁrst recursion level can be
bounded by the degeneracy, thus all the candidate set
at all depths of the search tree can be bounded. Pivot
selection strategies were studied by [21, 24] to optimize
the algorithms. Naud´e [21] relaxed the restriction of
pivot selection while keeping the time complexity un-
changed. Segundo et al. [24] improved the practical per-
formance of the algorithm by avoiding too much time
consumed by selecting the pivot. With distributed com-
puting paradigms, scalable and parallel algorithms were
designed for MCE in [25,38]. Schmidt et al. [25] decom-
posed the search tree to enable parallelization. Xu et
al. [38] proposed a distributed MCE algorithm based
on a share-nothing architecture. The I/O performance
of MCE in massive networks was improved by [8, 9].
The external-memory algorithm for MCE was ﬁrst in-
troduced by [8] to bound the memory consumption. A
partition-based MCE algorithm is designed by [9] to
reduce the memory used for processing large graphs.
The maximal spatial clique enumeration was studied
by [42], in which some geometric properties were used
to enhance the enumeration eﬃciency. Dynamic max-
imal clique enumeration was studied in [11, 27, 28], in
which the graph structure can evolve mildly. All the
three works considered the dynamic cases where edges
can be added or deleted. When considering an uncertain
graph, which is a nondeterministic distribution on a set
of deterministic graphs, the uncertain version of MCE
was designed by [15, 20]. Mukherjee et al. [20] designed
an algorithm to enumerate all α-maximal cliques in an
uncertain graph. The size of an uncertain graph can be

Eﬃciently Finding a Maximal Clique Summary via Eﬀective Sampling

19

reduced by core-based algorithms proposed by [15]. The
top-k maximal clique ﬁnding problem was also studied
by [43] on uncertain graphs. While these eﬃcient ap-
proaches reduced the running time of MCE, the bottle-
neck in applications is the large output size, which is
our main focus.

There exist a large volume of works [7, 17, 30, 31, 33]
studying the maximum clique problem, which aimed to
ﬁnd a maximal clique with the largest size. An approxi-
mate coloring technique was employed by [30] to bound
the maximum clique size, which was further improved
by [31] and [33]. Lu et al. [17] proposed a randomized
algorithm with a binary search technique to ﬁnd the
maximum clique in massive graphs, while the work [7]
studied this problem over sparse graphs by transform-
ing the maximum clique in sparse graphs to the k-clique
over dense subgraphs. Although the concept of max-
imum clique is closely related to the maximal clique,
the MCE and maximum clique ﬁnding are two distin-
guishable problems and there is no need to employ a
summary to summarize the output of this problem since
the number of maximum cliques is typically small.

Summarizing has also been studied for frequent pat-
tern mining [1, 37, 39]. Afrati et al. [1] studied how to
ﬁnd at most k patterns to span a collection of pat-
terns which is an approximation of the original pattern
sets. Yan et al. [39] proposed a proﬁle-based approach
to summarize all frequent patterns by k representives.
The pattern redundancy was introduced by [37], which
studied how to extract redundancy-aware and top-k sig-
niﬁcant patterns. While cliques share great similarity
with frequent patterns, these algorithms cannot be used
to summarize maximal cliques eﬃciently due to their
oﬄine nature. There are some studies focusing on on-
line algorithms to do summarizing. Saha et al. [23] and
Ausiello et al. [3] studied how to ﬁnd diversiﬁed k sets
to represent all sets with a streaming approach, based
on which [40] introduced an online algorithm to give
diversiﬁed top-k maximal cliques. In these works, k is
normally small, and coverage is not the focus.

Our work is close to the work [36] which introduced
the τ -visible summary of maximal cliques. Other than
giving a better sampling function in the earlier ver-
sion [16], we further discuss the optimality conditions
and propose to approach the optimal by introducing
the novel truss vertex order and truss bound.

8 Conclusion and Future Work

In this paper, we have studied how to report a sum-
mary of less overlapping maximal cliques during the
online maximal clique enumeration process. We have
proposed so far the best sampling strategy, which can

guarantee that the summary expectedly represents all
the maximal cliques while keeping the summary suf-
ﬁciently concise, i.e., each maximal clique can be ex-
pectedly covered by at least one maximal clique in the
summary with a ratio of at least τ (τ is given by a
user and reﬂects the user’s tolerance of overlap). We
have proved the optimality of this sampling approach
under two conditions (ideal bound estimation and suf-
ﬁciently strong locality), and proposed the novel truss
order as well as the truss bound to approach the op-
timal. Experimental studies have shown that the new
strategy can outperform the state-of-the-art approach
in both eﬀectiveness and eﬃciency on eight real-world
datasets. Future work could be conducted towards ap-
proaching the optimal conditions further. It would also
be interesting to solve the problem in parallel consid-
ering that maximal clique enumeration is expensive on
large graphs.

Acknowledgments

The work was supported by Australia Research Coun-
cil discovery projects DP170104747, DP180100212. We
would like to thank Yujun Dai for her eﬀort in the ear-
lier version [16].

References

1. Afrati, F., Gionis, A., Mannila, H.: Approximating a col-
lection of frequent sets. In: Proceedings of the 2004 ACM
SIGKDD International Conference on Knowledge Discov-
ery and Data Mining, pp. 12–19. ACM Press, Seattle,
WA, USA (2004)

2. Akkoyunlu, E.: The enumeration of maximal cliques of
large graphs. SIAM Journal on Computing 2(1), 1–6
(1973)

3. Ausiello, G., Boria, N., Giannakos, A., Lucarelli, G.,
Paschos, V.T.: Online maximum k-coverage. In: O. Owe,
M. Steﬀen, J.A. Telle (eds.) Fundamentals of Compu-
tation Theory, vol. 6914, pp. 181–192. Springer Berlin
Heidelberg, Berlin, Heidelberg (2011)

4. Berry, N., Ko, T., Moy, T., Smrcka, J., Turnley, J., Wu,
B.: Emergent clique formation in terrorist recruitment.
In: AAAI-04 Workshop on Agent Organizations: Theory
and Practice (2004)

5. Bron, C., Kerbosch, J.: Algorithm 457: ﬁnding all cliques
of an undirected graph. Communications of the ACM
16(9), 575–577 (1973)

6. Cazals, F., Karande, C.: A note on the problem of re-
porting maximal cliques. Theoretical Computer Science
407(1-3), 564–568 (2008)

7. Chang, L.: Eﬃcient maximum clique computation over
large sparse graphs.
In: Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discov-
ery & Data Mining, pp. 529–538. ACM, New York, USA
(2019)

8. Cheng, J., Ke, Y., Fu, A.W.C., Yu, J.X., Zhu, L.: Find-
ing maximal cliques in massive networks by H*-graph.
In: Proceedings of the 2010 ACM SIGMOD International
Conference on Management of Data, pp. 447–458. ACM,
New York, USA (2010)

20

Xiaofan Li et al.

9. Cheng, J., Zhu, L., Ke, Y., Chu, S.: Fast algorithms for
maximal clique enumeration with limited memory.
In:
Proceedings of the 18th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining,
pp. 1240–1248. ACM, New York, USA (2012)

10. Das, A., Sanei-Mehri, S.V., Tirthapura, S.: Shared-
memory parallel maximal clique enumeration from static
and dynamic graphs. ACM Transactions on Parallel
Computing (TOPC) 7(1), 1–28 (2020)

11. Das, A., Svendsen, M., Tirthapura, S.: Incremental main-
tenance of maximal cliques in a dynamic graph. The
VLDB Journal 28(3), 351–375 (2019)

12. Eppstein, D., L¨oﬄer, M., Strash, D.: Listing all maxi-
mal cliques in large sparse real-world graphs. Journal of
Experimental Algorithmics 18, 3.1–3.21 (2013)

13. Khaouid, W., Barsky, M., Srinivasan, V., Thomo, A.: K-
core decomposition of large networks on a single PC. Pro-
ceedings of the VLDB Endowment 9(1), 13–23 (2015)
14. Koch, I.: Enumerating all connected maximal common
subgraphs in two graphs. Theoretical Computer Science
250(1), 1–30 (2001)

15. Li, R., Dai, Q., Wang, G., Ming, Z., Qin, L., Yu, J.X.: Im-
proved algorithms for maximal clique search in uncertain
networks. In: 2019 IEEE 35th International Conference
on Data Engineering (ICDE), pp. 1178–1189 (2019)
16. Li, X., Zhou, R., Dai, Y., Chen, L., Liu, C., He, Q., Yang,
Y.: Mining maximal clique summary with eﬀective sam-
pling. In: 2019 IEEE International Conference on Data
Mining (ICDM), pp. 1198–1203. IEEE (2019)

17. Lu, C., Yu, J.X., Wei, H., Zhang, Y.: Finding the maxi-
mum clique in massive graphs. Proceedings of the VLDB
Endowment 10(11), 1538–1549 (2017)

18. Lu, Z., Wahlstr¨om, J., Nehorai, A.: Community detection
in complex networks via clique conductance. Scientiﬁc
Reports 8(1), 5982–5997 (2018)

19. Moon, J.W., Moser, L.: On cliques in graphs. Israel Jour-

nal of Mathematics 3(1), 23–28 (1965)

20. Mukherjee, A.P., Xu, P., Tirthapura, S.: Mining maximal
cliques from an uncertain graph.
In: 2015 IEEE 31st
International Conference on Data Engineering (ICDE),
pp. 243–254 (2015)

21. Naud´e, K.A.: Reﬁned pivot selection for maximal clique
enumeration in graphs. Theoretical Computer Science
613, 28–37 (2016)

22. Rokhlenko, O., Wexler, Y., Yakhini, Z.: Similarities and
diﬀerences of gene expression in yeast stress conditions.
Bioinformatics 23(2), 184–190 (2007)

23. Saha, B., Getoor, L.: On maximum coverage in the
streaming model & application to multi-topic Blog-
Watch. In: C. Apte, H. Park, K. Wang, M.J. Zaki (eds.)
Proceedings of the 2009 SIAM International Conference
on Data Mining, pp. 697–708. Society for Industrial and
Applied Mathematics, Philadelphia, PA (2009)

24. San Segundo, P., Artieda, J., Strash, D.: Eﬃciently enu-
merating all maximal cliques with bit-parallelism. Com-
puters & Operations Research 92, 37–46 (2018)

25. Schmidt, M.C., Samatova, N.F., Thomas, K., Park, B.H.:
A scalable, parallel algorithm for maximal clique enumer-
ation. Journal of Parallel and Distributed Computing
69(4), 417–428 (2009)

26. Seidman, S.B.: Network structure and minimum degree.

Social networks 5(3), 269–287 (1983)

27. Stix, V.: Finding all maximal cliques in dynamic graphs.
Computational Optimization and Applications 27(2),
173–186 (2004)

28. Sun, S., Wang, Y., Liao, W., Wang, W.: Mining maximal
cliques on dynamic graphs eﬃciently by local strategies.

In: 2017 IEEE 33rd International Conference on Data
Engineering (ICDE), pp. 115–118 (2017)

29. Tandon, A., Karlapalem, K.: Agent strategies for the
hide-and-seek game. In: Proceedings of the 17th Inter-
national Conference on Autonomous Agents and Multi-
Agent Systems, pp. 2088–2090. International Foundation
for Autonomous Agents and Multiagent Systems, Rich-
land, SC (2018)

30. Tomita, E., Kameda, T.: An eﬃcient branch-and-bound
algorithm for ﬁnding a maximum clique with compu-
tational experiments. Journal of Global Optimization
37(1), 95–111 (2007)

31. Tomita, E., Sutani, Y., Higashi, T., Takahashi, S., Wakat-
suki, M.: A simple and faster branch-and-bound algo-
rithm for ﬁnding a maximum clique. In: M.S. Rahman,
S. Fujita (eds.) WALCOM: Algorithms and Computa-
tion, Lecture Notes in Computer Science, pp. 191–203.
Springer Berlin Heidelberg (2010)

32. Tomita, E., Tanaka, A., Takahashi, H.: The worst-case
time complexity for generating all maximal cliques and
computational experiments. Theoretical Computer Sci-
ence 363(1), 28–42 (2006)

33. Tomita, E., Yoshida, K., Hatta, T., Nagao, A., Ito, H.,
Wakatsuki, M.: A much faster branch-and-bound algo-
rithm for ﬁnding a maximum clique. In: D. Zhu, S. Bereg
(eds.) Frontiers in Algorithmics, Lecture Notes in Com-
puter Science, pp. 215–226. Springer International Pub-
lishing (2016)

34. Valiant, L.G.: The complexity of enumeration and re-
liability problems. SIAM Journal on Computing 8(3),
410–421 (1979)

35. Wang, J., Cheng, J.: Truss decomposition in massive net-

works. arXiv preprint arXiv:1205.6693 (2012)

36. Wang, J., Cheng, J., Fu, A.W.C.: Redundancy-aware
In: Proceedings of the 19th ACM
maximal cliques.
SIGKDD international conference on Knowledge discov-
ery and data mining, pp. 122–130. ACM Press, Chicago,
Illinois, USA (2013)

37. Xin, D., Cheng, H., Yan, X., Han, J.: Extracting
redundancy-aware top-k patterns. In: Proceedings of the
12th ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, pp. 444–453. ACM
Press, Philadelphia, PA, USA (2006)

38. Xu, Y., Cheng, J., Fu, A.W.: Distributed maximal clique
IEEE Transactions on

computation and management.
Services Computing 9(1), 110–122 (2016)

39. Yan, X., Cheng, H., Han, J., Xin, D.: Summarizing item-
set patterns: a proﬁle-based approach.
In: Proceeding
of the 11th ACM SIGKDD International Conference on
Knowledge Discovery in Data Mining, pp. 314–323. ACM
Press, Chicago, Illinois, USA (2005)

40. Yuan, L., Qin, L., Lin, X., Chang, L., Zhang, W.: Di-
versiﬁed top-k clique search. The VLDB Journal 25(2),
171–196 (2016)

41. Zhang, B., Park, B.H., Karpinets, T., Samatova, N.F.:
From pull-down data to protein interaction networks
and complexes with biological relevance. Bioinformatics
24(7), 979–986 (2008)

42. Zhang, C., Zhang, Y., Zhang, W., Qin, L., Yang, J.:
In: 2019
Eﬃcient maximal spatial clique enumeration.
IEEE 35th International Conference on Data Engineer-
ing (ICDE), pp. 878–889 (2019)

43. Zou, Z., Li, J., Gao, H., Zhang, S.: Finding top-k max-
imal cliques in an uncertain graph. In: 2010 IEEE 26th
International Conference on Data Engineering (ICDE),
pp. 649–652 (2010)

