2
2
0
2

b
e
F
5

]

R
C
.
s
c
[

1
v
1
0
5
2
0
.
2
0
2
2
:
v
i
X
r
a

GraphEye: A Novel Solution for Detecting
Vulnerable Functions Based on Graph Attention
Network

1st Li Zhou
School of Information and Communication Engineering
University of Electronic Science and Technology of China
Chengdu, China
2018010801006@std.uestc.edu.cn

2nd Minhuan Huang
National Key Laboratory of Science and Technology
on Information System Security
Beĳing, China
darbean@126.com

3rd Yujun Li
School of Computer Science and Engineering
University of Electronic Science and Technology of China
Chengdu, China
liyujun@uestc.edu.cn

4th Yuanping Nie
National Key Laboratory of Science and Technology
on Information System Security
Beĳing, China
yuanpingnie@nudt.edu.cn

5th Jin Li
National Key Laboratory of Science and Technology
on Information System Security
Chengdu, China
201922081124@std.uestc.edu.cn

6th Yiwei Liu
School of Computer Science and Engineering
University of Electronic Science and Technology of China
Chengdu, China
2017060901015@std.uestc.edu.cn

Abstract—With the continuous extension of the Industrial
Internet, cyber incidents caused by software vulnerabilities have
been increasing in recent years. However, software vulnerabilities
detection is still heavily relying on code review done by experts,
and how to automatedly detect software vulnerabilities is an
open problem so far. In this paper, we propose a novel solution
named GraphEye to identify whether a function of C/C++ code
has vulnerabilities, which can greatly alleviate the burden of
code auditors. GraphEye is originated from the observation that
the code property graph of a non-vulnerable function naturally
diﬀers from the code property graph of a vulnerable function
with the same functionality. Hence, detecting vulnerable functions
is attributed to the graph classiﬁcation problem.GraphEye is
comprised of VecCPG and GcGAT. VecCPG is a vectorization
for the code property graph, which is proposed to characterize
the key syntax and semantic features of the corresponding source
code. GcGAT is a deep learning model based on the graph at-
tention graph, which is proposed to solve the graph classiﬁcation
problem according to VecCPG. Finally, GraphEye is veriﬁed
by the SARD Stack-based Buﬀer Overﬂow, Divide-Zero, Null
Pointer Deference, Buﬀer Error, and Resource Error datasets,
the corresponding F1 scores are 95.6%, 95.6%,96.1%,92.6%,
and 96.1% respectively, which validate the eﬀectiveness of the
proposed solution.

Index Terms—cyber security, vulnerable detection, code prop-

erty graph,graph attention network

I. Introduction

Software vulnerabilities refer to software design or im-
plementation defects, which may be exploited by malicious
users to achieve information leakage, resource utilization, and

facility destruction. In recent years, with the rapid develop-
ment of the Industrial Internet and continuously emerging
applications, functionalities of diﬀerent software have become
more and more complex and larger in scale. In addition to the
complexity of source code quality management, zero-day and
n-day software vulnerabilities have shown an upward trend.
Thus, cyber incidents caused by this kind of vulnerability
have also increased. Hence, software vulnerability detection
based on source code, as an old research topic, has once again
received signiﬁcant attention recently [1]–[6].

The mainstream method of software vulnerability detection
based on source code is to convert ﬁrstly the source code
into an abstract representation and then analyze the abstract
representation to check whether it matches a certain predeﬁned
vulnerability detection rule, to determine ﬁnally whether the
source code contains the corresponding vulnerabilities [3].
According to speciﬁc analysis techniques, the vulnerability
detection methods can be divided into three categories: code
similarity-based vulnerability detection, pattern-based vulner-
ability detection, and machine learning-based vulnerability
detection.

Code similarity-based vulnerability detection originates that
similar codes are likely to contain the same vulnerabilities.
Code segments are abstractly represented based on their char-
acteristics, and then judge the similarity between the code to
be detected and the code containing a known vulnerability ac-
cording to their corresponding representations, and determine

 
 
 
 
 
 
ﬁnally whether the detected code contains the corresponding
vulnerability. Based on the above idea, ReDeBug can quickly
ﬁnd unpatched code clones in OS-distribution scale code bases
[7], VulPecker can automatically detect whether a piece of
software source code contains a given vulnerability or not
[8], VUDDY can fully detect security vulnerabilities in large
software programs eﬃciently and accurately by leveraging
function-level granularity and a length-ﬁltering technique [9],
and so on. The principle of code similarity-based vulnerability
detection is clear and easy to understand, but this approach is
limited to detecting vulnerabilities incurred by code cloning
or approximate code cloning, and the false negatives for non-
code-cloning vulnerabilities are high.

The core of pattern-based vulnerability detection is plenty
of rules formulated by lots of analysts based on domain
knowledge, historical vulnerability data, or vulnerable codes
directly. Each rule can capture the essential characteristics
of a kind of vulnerability from the abstract representation
of the corresponding source code, and hence can be used
to identify whether the detected code contains the speciﬁc
vulnerabilities. This method is widely used in current tools for
automatic code analysis, including open-source software such
as Flawﬁnder, RATS, and ITS4, and commercial software such
as Checkmarx, Fortify, and Coverity. Recently, Yamaguchi
et al. advance this approach by a novel representation of
source code that named the code property graph which merges
concepts of abstract syntax trees, control ﬂow graphs, and
program dependence graphs. Based on this representation,
common vulnerabilities can be modeled as graph traversals
which can identify buﬀer overﬂows, integer overﬂows, format
string vulnerabilities, or memory disclosures [10]. Pattern-
based vulnerability detection methods can accurately locate
the vulnerability but are rather laborious. Furthermore, this
kind of method may lead to both a high false-positive rate
and a high false-negative rate due to imperfect rules and are
entirely incapable of unknown vulnerabilities.

Machine learning-based vulnerability detection is proposed
to reduce the reliance on domain experts, which can be
subdivided into traditional machine learning-based vulnerabil-
ity detection and deep learning-based vulnerability detection
according to whether domain experts are required to deﬁne
features. Traditional machine learning-based vulnerability de-
tection relies on domain experts to manually deﬁne features,
and use machine learning models, such as KNN, SVM, C4.5,
to automatically classify vulnerable code and
and so on,
non-vulnerable code. For example, to detect subtle taint-style
vulnerabilities from C source code, Yamaguchi et al. introduce
unsupervised machine learning to construct patterns that are
usually identiﬁed by manual analysis [11]. Better than tra-
ditional machine learning-based vulnerability detection, deep
learning-based vulnerability detection can automatically gen-
erate vulnerability patterns, which alleviates the requirements
to manually deﬁne features further. Zhen Li et al. propose
the ﬁrst systematic framework for using deep learning to
detect vulnerabilities in C/C++ programs with source code just
recently [6].

Deep learning has been successful in the image and natural
language process and is very promising in vulnerability detec-
tion. However, most of the recent works focus on how to apply
traditional vectorization methods in natural language process-
ing, such as word2vec, glove, and so on, to the program source
code [4], [6], [12]. However, the program source code diﬀers
from the image and natural language in nature. More eﬀorts for
vectorization of program source code are needed to improve
deep learning vulnerability detection. Furthermore, research
is also needed in terms of detection accuracy, vulnerability
location, large-scale labeled datasets, model interpretation, and
so on.

Our contributions. In this paper, we ﬁrstly propose that
detecting vulnerable functions of c/c++ code is attributed
to the graph classiﬁcation problem. Then, a novel solution
named GraphEye for this problem is proposed. GraphEye is
comprised of a vectorization for the code property graph and
a deep learning model based on the graph attention network.
The focus of this paper is centered on answering the following
question: How can we detect vulnerable functions based on
graph neural network model, given the fact that the code
property graphs of these functions have fully captured enough
syntax and semantic information to identify the potential
vulnerabilities?

The remainder of the paper is organized as follows: Sec-
tion 2 brieﬂy introduces the code property graph. Section 3
describes the solution framework in detail. Section 4 analyzes
experiment results in depth. Section 5 concludes our work and
discusses the future directions.

II. Code Property Graph Overview

A graph can be formally deﬁned as G = (V, E) in math
theory, where V is a set of nodes, and E ⊆ (V × V )
is a set of edges. However, this highly abstract deﬁnition
ignores the fact that there may be signiﬁcant diﬀerences both
between entities and the relationships between entities in the
real world. Hence, the concept of property graph comes into
being, which is an extension of traditional graph deﬁnition by
characterizing nodes and edges’ properties. A property graph
is a directed labeled multigraph with the special characteristic
that each node or edge could maintain a set (possibly empty)
of property-value pairs [13]. The deﬁnition of property graph
can be described as following:

Deﬁnition 1: A property graph is a ﬁve-tuple G =
(V, E, λ, Γ, µ) , where V is a set of nodes, E ⊆ (V × V )
is a set of directed edges from source node to destination, λ
is a labeling function for nodes, Γ is a type function for edges
and µ is a property function for both nodes and edges.

In a property graph, each node has at most one label,
and each edge has at most one type, respectively identifying
the classes of nodes and edges. Any node or edge in the
property graph can have zero or more attributes to identify
the characteristics of the node or edge. Figure 1 illustrates a
typical property graph about a movie, and the charactersistics
of v1 and e1 can be described by functions as follows:

Fig. 1: a simple movie property graph

λ(v1) = {Actor}
µ(v1, name) = ”Keanu Reeves”
µ(v1, birthday) = ”Sep. 2, 1964”
Γ(e1) = {Acted_ in }
µ(e1, role) = ”N eo”

With the help of the property graph, Yamaguchi et al. ﬁrstly
merge the concept of the abstract syntax tree, control ﬂow,
and program ﬂow chart to form a novel representation of
program source code that named the code property graph in
their publication [10]. The code property graph can be formally
deﬁned as follows:

GCP G = (VCP G, ECP G, λCP G, ΓCP G, µCP G)

= GAST ∪ GCF G ∪ CP DG

where GAST , GCF G and GP DG are the representation with
property graph for the traditional abstract syntax tree, the
control ﬂow graph, and the program dependence graph of a
program source code respectively.

This combination is prior to a single representation alone
to characterize a vulnerability type in the vast majority of
cases. As mentioned in [14] that the code property graph
is not limited to the abstract syntax tree, the control ﬂow
graph, and the program dependence graph, more additional
representations can be overlaid to extend the capability of
the code property graph. We also note that more traditional
representations, such as data dependence graph and control
dependence graph, have been merged into the code property
graph in Joern [15] which is an open-source tool to generate
the code property graph.

Listing 1 A bad function with divide-zero error

1: static void bad( float Data)
2: {
3: float data = Data;
4: {
5: /* POTENTIAL FLAW: Possibly divide by zero

*/

Fig. 2: The code property graph of bad() function

6: int result = (int) (100.0/ data);
7: printIntLine ( result );
8: }
9: }

For instance, Fig. 2 illustrates the code property graph of
a simple function depicted in Listing 1 from Juliet [16]. In
Fig. 2, the edges of the abstract syntax tree, control ﬂow graph,
program dependence graph, and data dependence graph are in-
dicated by the black solid lines, the red dashed lines, the purple
dotted lines, and the green dashed-dotted lines respectively.
All the syntax structs such as variable, data type, operate,
statement, the function call, and so on are included in the
subgraph consisting of black solid edges and the corresponding
nodes. All the control ﬂow information, i.e., the execution
order of statements, described by the subgraph consisting of
the red dashed edges and the corresponding nodes. All the
control dependencies are depicted in the subgraph consisting
of the purple dotted edges and the corresponding nodes. All the
data dependencies are illustrated by the subgraph comprising
of the green dashed-dotted edges and the corresponding nodes.

III. Solution Framework

A. Motivation and Overview

Our motivation comes from both the capture of vulnerability
characteristics by the code property graph and the development
of graph neural network technology. We ﬁrst observe that
the code property graph of the non-vulnerable source code
diﬀers naturally from the code property graph of the vulner-
able source code with the same functionality. Then, we also
notice that graph neural networks have been used for graph
classiﬁcation [19].

The diﬀerences in the code property graph of the non-
vulnerable source code and the vulnerable can be illustrated
by the following example. The ﬁxed code of bad() function in
Listing 1 is depicted in Listing 2, and its code property graph
is shown in Fig. 3. There is a lack of a subgraph to judge
whether data is equal to zero in Fig. 2, and the judgment
is essential to lead to the error of divided by zero. It must
be pointed out that the diﬀerence is not limited to the above
vulnerability type, and it does exist in all vulnerability types
as long as that the code property graph is enough overlayed.

Listing 2 A good funciotn without divide-zero error

Actorname = “Hugo Weaving”birthday =“Apr.4, 1960”Directorname = “Lilly Wachowski”birthday = “Dec. 29, 1967”Actorname = “Keanu Reeves”birthday = “Sep. 2, 1964”Movietitle = “The Matrix”released = “1994”DirectedbadALIGNfloatOP.=dataDataALIGNintOP.=resultOP.castintOP./100.0dataCALLprintIntLineargresultargDataASTPDGDDGCFGX = R|VCP G|×|F |
where |VCP G| is the cardinalities of the node-set VCP G, and
is the dimension of the selected properties of nodes.
|F |
F represents the features related to vulnerabilities, which is
consisted of ﬁve diﬀerent components illustrated in Table I.

TABLE I: The structure of VecCPG.

label
13 + 2

operator
25 + 2

function
39 + 2

literal
32

type
16 + 2

The structure of VecCPG characterizes the syntax details
of the node label, operator, API function call, constant, and
variable type.

Label: This label indicates which class a node belongs to,
which is similar to the meaning of a label in a traditional
property graph. There are 13 diﬀerent classes are considered
the labels and their corresponding
in this paper, and all
implications are listed in table II. All these labels are encoded
in a one-hot way, one additional bit for the unknown node,
another additional bit for reservation.

TABLE II: Labels and implications.

Label
INDENTIFIER
LITERAL
LOCAL

BLOCK
METHOD_RETURN
METHOD
CONTROL_STRUCTURE

FIELD_IDENTIFIER

UNKNOWN
RETURN
PARAM
JUMP_TARGET
CALL

implications
variables
constants, such as strings, integers
variables in the function body that
has been declared
separator
the return of a method
a method deﬁnition
the control
such as if, while
a reference to a namespace, usually
is ::
unknown types
the return of a function
the parameters of a function
the label used by goto
a call to a function or operator

statement

structure,

Operator: 25 types of operators including arithmetic oper-
ators, rational operators, logical operators, bitwise operators,
pointer operators, and so on are considered in these compo-
nents. The detailed operators and the corresponding meaning
are described in Table III. Operators are also encoded in a
one-hot way, one additional bit for the unknown node, another
additional bit for reservation.

Function: Considering some API function calls, for exam-
ple, memcpy(), may lead to vulnerabilities, hence API function
names are encoded into VcCPG in a one-hot way. The number
of diﬀerent API functions varies in diﬀerent datasets. Thus,
the simplest way to encode all API functions for a certain
language. However, Limited to the dataset used in this paper,
39-bit encodes are enough to represent all API functions,
one additional bit for unknown, another additional bit for

Fig. 3: The code property graph of good() function

1: static void good( float Data)
2: {
3: float data = Data;
4: if(fabs(data) > 0.000001)
5: {
6: int result = (int) (100.0/ data);
7: printIntLine ( result );
8: }
9: else
10: {
11: printLine ("This(cid:32) would (cid:32) result (cid:32)in(cid:32)a(cid:32) divide (cid:32)

by(cid:32)zero");

12: }
13: }

Hence, detecting vulnerable functions of c/c++ code is
modeled as the graph classiﬁcation problem, and the solution
framework is illustrated as Fig.4.The solution framework can
be divided into three components. The ﬁrst component is the
generation of the code property graph for the program source
code, which is the basis of our works and can be done by Joern.
The second component is the vectorization of the property
graph, and which is the foundation for the application of graph
neural network model and can be done by our novel schema
called VecCPG (Vectorization for the Code Property Graph
of a program source code). The third component is the deep
learning model, and we propose a novel model, named GcGAT
(Graph Classiﬁcation based on Graph Attention NeTworks), to
detect vulnerable functions. The combination of VecCPG and
GcGAT is called GraphEye, which is the core of the solution
framework.

B. Vectorization

Although the extension of the code property graph for a pro-
gram source code has captured most vulnerability types so far,
there is still a gap that must be ﬁlled before the model of graph
neural network can be used to detect vulnerable functions. That
is to say, how to vectorize the code property graph? VecCPG
is proposed to ﬁll the gap.VecCPG is comprised of the feature
matrix and the adjacent matrix. The feature matrix represents
nodes’ information, which captures the syntax characteristics
of a program source code. For a given code property graph
GCP G = (VCP G, ECP G, λCP G, ΓCP G, µCP G), the feature
matrix of GCP G is deﬁned as follows:

goodALIGNfloatOP.=dataDataIFOP.>CALLfabsargdata1e-6CONDITIONIfStatementTrueALIGNintOP.=resultintOP./100.0dataCALLprintIntLineargresultOP.castElseStatementCALLprintLinearg“THIS…”argDataASTPDGDDGCFGFig. 4: The solution framework

TABLE III: Operators and implications.

operator
=
[]
sizeof()
*
()
-
.
<
++
&
+
==
**
-
!=
>=
->
|
/
&
delete()
&&
>
%
new

meaning
assignment
indirectIndexAccess
sizeOf
multiplication
cast
subtraction
ﬁeldAccess
lessThan
postIncrement
addressOf
addition
equals
indirection
minus
notEquals
greaterEqualsThan
indirectFieldAccess
logicalOr
division
logicalAnd
delete
and
greaterThan
modulo
new

reservation. Surely, the encoding is easily extended to meet
requirements in real application scenarios.

Literal: Some constants are also factors for the vulnerabil-
ities, such as the divide-by-zero vulnerability. Due to the fact
that the dataset in this paper is limited to 32 bits, all integers
are encoded into 32 bits same to the underlying storage method
of the system, and the ﬂoating-point constants are encoded
according to IEEE 754 standard [17]. Of course, this encoding
is easily extended to 64-bit systems.

Type: For C/C++ languages,10 basic variable types and 6
complex variable types are considered. These basic variable
types are char, int, short, ﬂoat, double, long, string, void,

struct, and union. Those complex variable types are signed,
unsigned, *, array, map, and vector. A basic variable type and
a complex variable type can be combined together, such as
“char *”. Basic variable types and complex variable types are
independently encoded in a one-hot way with an additional
one-bit reservation.

The adjacency matrix is composed of AST, CFG, and
DDG edges in the code property graph of a program source
code, reﬂecting semantic information such as dependence and
control between nodes. The adjacency matrix is deﬁned as
A = R(|VCP G|×|VCP G|) where |VCP G|
is the cardinalities
of the node-set VCP G. Compared to the feature matrix, the
adjacent matrix is easier to construct. As long as there is at
least one edge between two nodes, regardless of the type and
number of edges, the element in the corresponding adjacency
matrix is set to 1; otherwise, it is set to 0.

C. Deep Learning Model

A novel deep learning model, named GcGAT is proposed to
detect vulnerable functions of the program source code. This
model illustrated in Fig.5 includes GAT, SAGpool, MLP, and
softmax.

In traditional graph attention network application scenarios,
the input is a feature matrix and an adjacency matrix. After
the feature extraction of the multi-head attention model, the
feature vectors of all nodes are output to label diﬀerent nodes.
However, what we need is to classify graphs rather than
labeling nodes in a graph. If GAT’s output feature matrix
is directly expanded into a vector and then input into MLP
for classiﬁcation, it may lead to the problem of excessive
MLP parameters and the consequent high-dimensional curse.
Inspired by the convolutional layer and pooling layer of CNN
which is introduced to solve the classiﬁcation problem by
converting the output feature matrix of the graph into a vector.
An improved SAGPool after GAT is introduced as our graph
pooling.

float bad(int data){…float b = 2/data;…}01⋯01⋮⋱⋮10 ⋯1 1Adjacency matrix11⋯00⋮⋱⋮01 ⋯0 1FeaturematrixSource codeJoernVecCPGDeep Learning ModelGcGAToutput[0.9, 0.1]ProbabilityProgram source codeCode property graph generated by JoernAdjacency and feature matrix  generated by VecGPG. Deep learning frameworkProbability indicated whether a function has vulnerabilitiesClassificationFig. 5: GcGAT

Traditional SAGPool is an implementation of hierarchical
pooling. It adaptively learns the importance of nodes from the
graph through graph convolution and discards non-important
nodes based on the TopK mechanism. Instead, we use GCN
to directly reduce the dimensionality of the feature matrix
output by GAT and then convert it into a vector to represent
the whole graph. After obtaining the feature vector of the
graph, we input it into MLP with fewer layers and parameters
for classiﬁcation. The number of nodes in the input layer of
MLP is the dimension of the feature vector of the graph,
and the number of nodes in the output layer of MLP is 2,
which indicates that the results are divided into two categories.
Finally, a common function named softmax is introduced for
normalization to meet requirements of probability for MLP’s
output. The deﬁnition of softmax is as follows:

Si =

ezi
j=1 ezj

(cid:80)K

where zi is the ith element and Si is the corresponding

output of softmax.

IV. Experiments

A. Data Preprocessing

SARD [18] is a dataset of diﬀerent types of vulnerabilities,
which has been widely used for researchers to evaluate their
methods. In terms of model training and testing, we have
selected three classic sub-datasets, namely, CWE 121 Stack-
based Buﬀer Overﬂow, CWE 369 Divide-Zero, CWE 476
NULL Pointer Deference. In comparison with other models,
we have selected two more widely used vulnerability types:
CWE 199 Buﬀer Error and CWE-399 Resource Management
Error.

Remember that this paper discusses whether there are vul-
nerabilities in functions. Hence, for training and testing the
proposed deep learning model, the ﬁrst thing that needs to do
is to label the functions in the dataset classiﬁed by whether a
function has vulnerabilities. At ﬁrst, the concept of root bad
function and root good function is introduced as follows:

Root bad function: The function that its vulnerabilities are
caused by either the statements themselves or API function
calls is a root bad function. That is to say, the vulnerabilities
in this function are not caused by user-deﬁned function calls.

Root good function: The function that has no vulnerabil-
ities or its vulnerabilities are caused by user-deﬁned function
calls is a root good function. That is to say, there are no
vulnerabilities under the exception of user-deﬁned function
calls.

TABLE IV: The distribution of labeled functions

CWE
121
369
476
119
399

Name
Stack-based Buﬀer Overﬂow
Divide-Zero
NULL Pointer Dereference
Buﬀer Error
Resource Error

good
529
845
410
844
1179

bad
3643
593
274
4682
802

Total
4172
1368
684
5330
1915

Then, based on the above deﬁnitions, all

the functions
without user-deﬁned function calls are picked up and labeled
“good” or “bad” respectively in the dataset, as illustrated in
Table IV.

B. Training Process

Since the feature matrix of a code property graph is
relatively sparse,
the gradient update needs more epochs
to obtain better parameters. A module named ray.tune is
applied to perform a grid search on hyperparameters and
pick up the best hyperparameters. Then based on the best
hyperparameters, training by some epochs for the ﬁxed dataset.
Generally, the model is seriously underﬁtting from the 1st to
5th epochs. By the 7th epoch, the model performance has been
greatly improved. After 10 epochs, the model performance
has stabilized, and the training can be considered to be over.
The hyperparameters ﬁnally used in GcGAT are as follows:
learning rate equals 8.6e-4, the number of epochs is 15; the
dropout is 0.3; the dimension of the hidden layer is 64 and the
dimension of the pooling layer is 32.

Due to the imbalance problem of the dataset under the
two classiﬁcations [19], a penalty factor strategy is adopted
in GcGAT. For frequently occurring classes, the penalty is
reduced by multiplying a number less than 1. For losses
in small samples,
the penalty is increased by multiplying
a number greater than 1. In our experiments, the penalty
factor is optimized to 0.6 for frequently occurring classes, and
the penalty factor is optimized to 1.7 for small samples by
hyperparameters searching.

VecCPGGATSAGPoolMLPSoftmaxTABLE V: The comparison with others for CWE 119

TABLE VI: The comparison with others for CWE 399

Flawﬁnder
RATS
Paper [4]
GraphEye

P

FNR

FPR
TPR
56.6% 44.8% 55.2% 39.9% 46.3%
68.7% 31.3% 68.7% 40.5% 51.0%
14.3% 14.6% 85.4% 80.4% 82.8%
12.2% 87.8% 98.0% 92.6%
9.4%

F1

Flawﬁnder
RATS
Paper [4]
GraphEye

P

FNR

FPR
TPR
40.7% 58.4% 41.6% 34.1% 37.4%
33.9% 63.8% 36.2% 35.0% 35.6%
14.1% 18.5% 81.5% 73.7% 77.4%
93.0% 99.3% 96.1%
0.4%

7.0%

F1

For CWE 121 Stack-based Buﬀer Overﬂow,

the large-
sample down-sampling technique is adopted to balance the
positive samples and negative samples. The large-sample
down-sampling technique is not adopted for CWE 369 Divide-
Zero and CWE 476 NULL Pointer due to their balanced
samples. CWE 119 Buﬀer Error and CWE 399 Recourse Error
are used for comparisons with other methods, the large-sample
down-sampling technique is not adopted to ensure fairness. For
all types of vulnerabilities, the dataset is randomly divided into
the training set and test set according to the ratio of 8:2.

We implement our framework in Python using Pytorch.
The computer running experiments has two NVIDIA RTX
TITAN GPUs and an Intel Xeon E5-2678 v3 CPU running
at 3.30GHz.When training the neural networks to ﬁnd vul-
nerabilities,
the framework only consumes 2.46G memory
with 1.16% average load on CPU, and 1.4G GPU memory
with 29% average load on GPU. And when we leverage our
model for inference, the speed reaches 185.69 functions per
second on average, which indicates that our model can detect
vulnerabilities rapidly under the condition of low resource
usage.

C. Experiment Results

FPR (False Positive Rate), FNR (False Negative Rate), TPR
(True Positive Rate), P (Precision) and F1 are common metrics
for evaluting the eﬀectiveness of a deep learning model. In
terms of software vulnerabilities detection,their deﬁnitions can
be described as follows:

F P R =

F N R =

T P R =

F P
F P + T N
F N
T P + F N
T P
T P + F N
T P
T P + F P

P =

F 1 =

2 × P × T P R
P + T P R

where F P denotes the number of samples that are non-
vulnerable but detected as vulnerable, T N denotes the number
of samples that are non-vulnerable and detected as non-
vulnerable, F N denotes the number of samples that are
vulnerable but detected as non-vulnerable, and T P denotes
the number of samples that are vulnerable and detected as
vulnerable. It is clear that the lower FRR and FNR, the higher
TPR, P and F1 implicates the better eﬀectiveness of the model.
For CWE 119 Buﬀer Error and CWE 399 Recourse Error,
the experiment results compared with Flawﬁnder, RATS, and

TABLE VII: The experiment results for CWE121, CWE369
and CWE476

CWE 121
CWE 369
CWE 476

TPR

FNR

FPR
2.9% 6.7% 93.3% 97.9% 95.6%
4.4% 2.7% 97.3% 93.9% 95.6%
1.3% 5.8% 94.2% 98.0% 96.1%

F1

P

Paper [4] are shown in Table V and Table VI. Results
of Flawﬁnder, RATS and Paper [4] come from [4]. Both
FlawFinder and RATS are vulnerability detection tools based
on pattern recognition, while Paper [4] adopts deep learning
models to detect vulnerabilities. It is obvious from Table V
and Table VI that the eﬀectiveness of Flawﬁnder and RATS
is poor. This is because the predeﬁned rules for vulnerabilities
are usually simple and are diﬃcult to handle complex and
ﬂexible implementation. The eﬀectiveness of Paper [4] has
been greatly improved, and far better than Flawﬁnder and
RATS in all F P R,F N R,T P R,P , and F 1 metrics. Unlike
natural language processing adopted in Paper [4], GraphEye
is rooted in graph attention network and can capture more
syntax structure and semantic information characteristics from
the program source code. Hence, the overall eﬀectiveness of
GraphEye is much better than Paper [4].

The experiment results for CWE 121 Stack-based Buﬀer
Overﬂow, CWE 369 Divide-Zero, and CWE 476 NULL
Pointer Deference are shown in Table VII. F1 of these three
types of vulnerabilities are all higher than 95%.For CWE 121
Stack-based Buﬀer Overﬂow, the diﬀerence between a root
good function and a corresponding root bad function mainly
lies in the value of the variable or constant, rather than the
logical structure of the program source code. While GAT
is sensitive to structure but is a little obtuse to constants.
Hence, GraphEye adopts the penalty for bad function samples
in the training process, which leads to the high false alarm
rate. For CWE 369 Divide-Zero and CWE 476 NULL Pointer
Deference, the results are similar. This is because that these
two types of vulnerabilities mainly depend on whether there
are branch statements for diﬀerent values of variables. Some
useless structures such as if(0) can Interference GraphEye, so
the false-negative rate is higher.

V. Conclusion and Future Work

This paper ﬁrstly proposes that detecting vulnerable func-
tions can be attributed to the graph classiﬁcation problem.
Then, a novel solution named GraphEye for this problem is
proposed. GraphEye is comprised of VecCPG and GcGAT.
VecCPG is a vectorization for the code property graph, which

DOI: 10.24963/ĳcai.2020/454.

[13] R. Angles, "The property graph database model," Proceedings of the
12th Alberto Mendelzon International Workshop on Foundations of Data
Management, Cali, Colombia, May 21-25, 2018.

[14] Yamaguchi, Fabian. "Pattern-based methods for vulnerability discovery."
in the PhD Program in Computer Science (PCS) of the Georg-August
University School of Science (GAUSS), 2015.

[15] Joern, "Joern, Open-Source Code Querying Engine for C/C++,"

ShiftLeft, https://joern.io, accessed in Mar. 14. 2021

Technology

[16] Information

Documents,"
and Systems Division PRIVACY/SECURITY ISSUES,

Software
https://samate.nist.gov/SARD/around.php, accessed Mar. 3. 2021.
[17] W. Kahan, "IEEE Standard 754 for Binary Floating-Point Arithmetic,"in

Laboratory,

"Juliet

IEEE Std 754-2008, vol., no., pp.1-70, 29 Aug. 2008.
DOI: 10.1109/IEEESTD.2008.4610935.

[18] Information Technology Laboratory, "NIST Software Assurance Ref-
erence Dataset Project," Software Assurance Reference Dataset,
https://samate.nist.gov/SRD/index.php, accessed Mar. 14. 2021.

[19] He, Haibo Garcia, E.A, "Learning from Imbalanced Data." IEEE Trans-
actions on Knowledge and Data Engineering, vol. 21, no. 9, pp. 1263-
1284, Sept. 2009.
DOI: 10.1109/TKDE.2008.239.

[20] Z. Li et al., "VulDeePecker: A deep learning-based system for vulner-
ability detection," Network and Distributed Systems Security (NDSS)
Symposium 2018, 18-21 February 2018, San Diego, CA, USA
DOI: 10.14722/ndss.2018.23158.

[21] Z. Zhang et al., "Hierarchical graph pooling with structure learning,"

arXiv:1911.05954, 2019.

reﬂects the grammatical structure and semantic information.
GcGAT is a deep learning model, which introduces SAGPool,
MLP, and Softmax based on GAT to classify vulnerable
functions and non-vulnerable functions. Finally, the experi-
ment results validate the correctness and eﬀectiveness of our
solution. However, our current work is limited to detecting
vulnerable functions caused by function internal statements
and system calls. In the future, we will study how to detect
vulnerable functions under the existence of custom function
calls that are more general in actual situations.

Acknowledgments

This work was

supported in part by the Key Re-
search and Development Project of Sichuan Province (no.
2021YFG0160), the National Key Research and Development
Program of China (no. 2019QY1406). The authors would like
to thank the anonymous reviewers for their valuable comments
and suggestions.

References

[1] R. Russell et al., "Automated Vulnerability Detection in Source Code
Using Deep Representation Learning," 2018 17th IEEE International
Conference on Machine Learning and Applications (ICMLA), Orlando,
FL, USA, pp. 757-762, 2018.
DOI: 10.1109/ICMLA.2018.00120.

[2] Young-Su JANG, Jin-Young CHOI., "Automatic Prevention of Buﬀer
Overﬂow Vulnerability Using Candidate Code Generation," IEICE
Trans. Information and Systems, Vol.E101-D, No.12, pp.3005-3018,
2018.

[3] Zhen Li, Deqing Zou, Zeli Wang, Hai Jin. "Survey on static software
vulnerability detection for source code," Chinese Journal of Network
and Information Security, Vol. 5, No. 1, pp.1-14, 2019.

[4] X. Duan, J. Z. Wu, T. Y. Luo, M. T. Yang, and Y. J. Wu, "Vulnerability
Mining Method Based on Code Property Graph and Attention BiLSTM,"
Journal Software, Vol. 31, No. 11, pp. 3404–3420, 2020.

[5] H. Wang et al., "Combining Graph-Based Learning With Automated
Data Collection for Code Vulnerability Detection," IEEE Transactions
on Information Forensics and Security, Vol. 16, pp. 1943-1958, 2021.
DOI: 10.1109/TIFS.2020.3044773.

[6] Z. Li, D. Zou, S. Xu, H. Jin, Y. Zhu, and Z. Chen, "SySeVR: A
Framework for Using Deep Learning to Detect Software Vulnerabilities,"
IEEE Transactions on Dependable and Secure Computing, 2021
DOI: 10.1109/TDSC.2021.3051525.

[7] J. Jang, A. Agrawal and D. Brumley,"ReDeBug: Finding Unpatched
Code Clones in Entire OS Distributions". 2012 IEEE Symposium on
Security and Privacy, San Francisco, CA, USA, 2012, pp. 48-62. 2012.
DOI: 10.1109/SP.2012.13.

[8] Z. Li, D. Zou, S. Xu, H. Jin, H. Qi, and J. Hu, "VulPecker: an automated
vulnerability detection system based on code similarity analysis," In
Proceedings of the 32nd Annual Conference on Computer Security
Applications. Association for Computing Machinery, New York, NY,
USA, 201–213, 2016.
DOI: 10.1145/2991079.2991102.

[9] S. Kim, S. Woo, H. Lee and H. Oh, "VUDDY: A Scalable Approach for
Vulnerable Code Clone Discovery," 2017 IEEE Symposium on Security
and Privacy (SP), San Jose, CA, USA,pp. 595-614, 2017.
DOI: 10.1109/SP.2017.62

[10] F. Yamaguchi, N. Golde, D. Arp, and K. Rieck, "Modeling and discover-
ing vulnerabilities with code property graphs," 2014 IEEE Symposium
on Security and Privacy, San Jose, CA, USA, pp. 590–604, 2014.
DOI: 10.1109/SP.2014.44.

[11] F. Yamaguchi, A. Maier, H. Gascon and K. Rieck, "Automatic Inference
of Search Patterns for Taint-Style Vulnerabilities," 2015 IEEE Sympo-
sium on Security and Privacy, San Jose, CA, USA, pp. 797-812, 2015.
DOI: 10.1109/SP.2015.54.

[12] Y. Zhuang, Z. Liu, P. Qian, Q. Liu, X. Wang, and Q. He, "Smart contract
vulnerability detection using graph neural networks," ĲCAI Int. Jt. Conf.
Artif. Intell., vol. 2021-Janua, pp. 3283–3290, 2020.

