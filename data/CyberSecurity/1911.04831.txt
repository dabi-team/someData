9
1
0
2

v
o
N
2
1

]

R
C
.
s
c
[

1
v
1
3
8
4
0
.
1
1
9
1
:
v
i
X
r
a

Anomaly Detection for Industrial Control
Systems Using Sequence-to-Sequence Neural
Networks

Jonguk Kim, Jeong-Han Yun, and Hyoung Chun Kim

The Aﬃliated Institute of ETRI, Republic of Korea
{jongukim,dolgam,khche}@nsr.re.kr

Abstract. This study proposes an anomaly detection method for oper-
ational data of industrial control systems (ICSs). Sequence-to-sequence
neural networks were applied to train and predict ICS operational data
and interpret their time-series characteristic. The proposed method re-
quires only a normal dataset to understand ICS’s normal state and detect
outliers. This method was evaluated with SWaT (secure water treatment)
dataset, and 29 out of 36 attacks were detected. The reported method
also detects the attack points, and 25 out of 53 points were detected. This
study provides a detailed analysis of false positives and false negatives
of the experimental results.

Keywords: Anomaly detection · Deep learning · Operational data ·
Industrial control system.

1

Introduction

Since Stuxnet struck a nuclear facility in 2010, threats towards industrial con-
trol systems (ICSs) have increased. Unfortunately, as most of ICS attackers
are state-sponsored and use zero-day vulnerabilities, signature-based detection
(maintaining the blacklist and updating it) is inappropriate.

The most common and safe approaches that do not harm the availability of
ICSs monitor the network traﬃc of these systems. ICSs present more periodic
behavior than information technology systems. Several studies [5,13,20] applied
the statistical characteristics of traﬃc for ICS-speciﬁc security mechanisms. Al-
though this approach is suitable for ICS traﬃc characteristics, it presents limi-
tations in detecting attacks at the ICS operation level.

Other researches focused on the detection of anomalies with physical prop-
erties [14]. By using the speciﬁcation or control logic, the monitoring system
rarely emits false alarms [3,15]. However, it is relatively expensive to obtain
and specify the speciﬁcation or control logic. An ICS recognizes the environ-
ment with sensors, makes decisions for its purpose, and delivers the right action
with actuators. To detect anomalies at the ICS operation level, its normal state
must be deﬁned and the control logic that decides actuators’ behaviors must be

 
 
 
 
 
 
2

J. Kim et al.

understood. However, understanding the entire set of the control logic is com-
plicated. In fact, the volume of the control logic is enormous, and acquiring it
from vendors is not allowed in most cases.

Herein, the aim is to monitor the ICS operational data. A feasible alterna-
tive is the data-driven approach. Machine-learning-based approaches have been
highly studied and especially deep-learning-based anomaly detection methods
which have been reported recently using fully-connected networks (FCN) [18],
convolutional neural networks (CNN) [10], recurrent neural networks (RNN) [7],
and generative adversarial networks (GAN) [12].

We propose a deep learning-based anomaly detection method using a sequence-
to-sequence model (seq2seq) [19]. Seq2seq is designed initially for natural lan-
guage translation. It encodes the words of a given sentence with RNN into a
latent vector, then decodes from it to a set of words in the target language.
Seq2seq’s encoding-decoding approach presents a signiﬁcant advantage as it can
understand the context of the entire sentence, while vanilla RNN gives the out-
put immediately for every input. Seq2seq is expected to be an eﬀective method
for learning the context or semantics of time-series operational data, and obtain
a better prediction based on the given data.

To date, no abnormal samples have been reported to train machine learning
models robustly. Therefore, the reported model is trained with the only normal
dataset (training dataset), and it is considered that the training data are clean. In
the detection phase, the developed model investigates unseen data with trained
neural networks. Using the model after the learning phase, the detection method
proceeds in three steps: Step 1, the model predicts the future values of the sensors
and actuators, Step 2, the diﬀerence between the prediction and actual data is
determined, and Step 3, alerts are sent for signiﬁcant diﬀerences.

The rest of this paper is organized as follows. Section 2 introduces the
anomaly detection method using the seq2seq neural network. Section 3 presents
the experimental results after applying the proposed method to the secure water
treatment (SWaT) dataset [6]. Section 4 analyzes the experimental results in
detail and Section 5 concludes this study.

2 Proposed Method

2.1 SWaT Dataset

Several studies have recently been reported on dataset generation for ICS re-
search [4,6,11,17]. The most frequently used dataset is the SWaT dataset [6] by
Singapore University of Technology and Design (SUTD), which has operational
data and attack labels. Herein, the method is developed and evaluated with the
SWaT dataset.

The SWaT dataset was collected from a testbed water treatment system.
Fifty-one tags (25 sensors and 26 actuators) are sampled every second. Some
are digital, and others are analog. Tag names deﬁne their roles. For example,
MV denotes motorized valve, P for pump, FIT for ﬂow meter, and LIT for level
transmitter.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

3

Fig. 1. Proposed learning model using seq2seq with attention

SWaT consists of six processes. Water ﬂows from process 1 to the process 6.
The numbers following the tag names indicate the process ID and the gadget
ID. For example, MV-101 is the ﬁrst motorized valve in process 1.

In the SWaT dataset, normal and attack datasets are separated. The normal
part has 480,800 samples, and the attack part includes 41 attacks during 449,919
samples.

2.2 Data Preprocessing

Multiple machine learning schemes normalize the input into a Gaussian distri-
bution with an average of 0 and a standard deviation of 1. However, to ensure
that the distributions of most tags in the normal part of the SWaT dataset
were not distorted nor had multiple peaks, min-max normalization was chosen.
Long-short term memory (LSTM) [8], which is a RNN cell used in the developed
model, has a sigmoid function inside that gives a (0, 1) output. The minimum
and maximum for normalization were chosen as 0 and 1.

The operational data were time-series. The model used sliding windows of
length 100 seconds to understand the temporal context, and each window slides
1 by 1 second.

2.3 Sequence-to-Sequence Neural Networks

There are various ways to build a neural network for learning time-series data.
We chose the sequence-to-sequence network with attention [2] for training and
evaluation. Since RNN is proper for learning a series of data, we expected that
RNN is able to encode the current window of data and to anticipate the next
values. Figure 1 shows the data ﬂow of the proposed model. The shape of inputs
for the encoder is (# of sequences, batch, # of tags). The encoder obtains the
ﬁrst 90 seconds of the window. The encoder’s output is two-fold: 1) the last
cell state of the last layer and 2) all hidden states of the last layer. The ﬁrst

4

J. Kim et al.

Fig. 2. Prediction errors for processes 1, 2, 3, 4, and 5 of SWaT (red: attack, purple:
prediction error, and blue: anomaly score)

one has the context of the given sequences. The second one helps the decoder
predict future operational data with the attention mechanism. The decoder part
is optional. The reason why we added a decoder with attention is that it gives
us more accurate results. The decoder predicts the last second with a 9-second
hint. The values of 9th second of the hint is almost the same with those of the
last record of the window (we wanted to expect), which helps the model give
almost-zero prediction error. The shape of the decoder’s ﬁnal output is (batch,
# of tags).

An independent model was applied for each process of SWaT. The model
n learns the process n. Figure 2 shows the prediction error of each process. At
the early stage of this study, a holistic model1 was tested for six processes. The
result was not accurate because each process shows a diﬀerent prediction error
pattern, especially the process 2, as observed in Figure 2.

2.4 Measuring Prediction Error

The mean absolute error (MAE) is a typical measuring method. However, p-
norm can also be used, with p > 2. The greater the value of p, the greater the
value of the vector. ∞-norm returns the maximum value of the vector. Herein,
a 4-norm was chosen, while Kaspersky chose a 6-norm [18] for SWaT dataset.

1 [18] used this approach: one model for the whole processes.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

5

The prediction error (distance) D can be extracted as follows:

(cid:118)
(cid:117)
(cid:117)
(cid:116)

n
(cid:88)

D = 4

d4
i where di = Ii − Oi

(1)

i=1

where n is the number of tags, Ii is the i-th tag values in the dataset, and Oi is
the i-th output of the model.

2.5 Anomaly Decision using Prediction Errors

The proposed method considers that the system is under attack if the model
has never seen the current state. The developed model was trained to perform
a precise prediction. When the model detects a never-seen window, it cannot
perform an accurate prediction, which leads to more notable 4-norm value.

Multiple approaches can be used to determine anomalies such as cumula-
tive sum (CUSUM) and anomaly likelihood [1]. The custom rating method was
applied by considering the prediction errors – due to the following factors:

1. A learning model often presents periodic noises, but it is hard to remove

noises because of the limited learning data.

2. From a speciﬁc time, the distances of process 2, especially AIT-201 in SWaT,
are increasing and never recovered (this issue is discussed in Section 4.2).

A similar (but not signiﬁcant) phenomenon occurred in process 5. It is as-
sumed that an insuﬃcient amount of training data and unexpected dynamics
can cause growing prediction errors.

A sliding window for rating was also applied. First, the top-k outliers were
removed. As aforementioned, the developed model presents noise (the impulse of
prediction error). The sum of remains except the outliers represents the distance
of the window. Fortunately, attacks last at least 2 minutes (the shortest attack
is attack 34). For a large summation on a speciﬁc window, a high rate can be
attributed to that particular region.

Second, N summations were collected to compare the current sum with near-
by ones. Two hyper-parameters were deﬁned: H and L. L is the 20th percentile,
and H is the 90th percentile. H is not the 80th because top-k values (outliers)
were already removed to reduce noises. The ratio H
L and divided by R, which is
another hyper-parameter. Here, R = 20.

In short, if the 90th percentile is 20 times greater than the 20th percentile,
it is certain that an attack happens. The rate for suspicious region S is derived
as follows:

S = min(

, 1.0)

(2)

H
LR

Finally, if S is greater than 0.3 (30%), it is regarded as an attack. All numbers
mentioned above (90 for H, 20 for L, 20 for R, and 0.3 for threshold) are hyper-
parameters which are dataset-dependent.

6

J. Kim et al.

Equation 2 determines high rates at the start and end of the attack because
it measures the change. We use both sides: start and end. Depending on the
attack the high rate can be obtained at the start or at the end. Figure 3 shows
D and S of attack 41.

Fig. 3. Asymmetric ratings at the start and end of attack 41 (red: attack, purple:
prediction error, and blue: anomaly score)

As D grows slowly at the start and shrink quickly at the end, S is low at the

start but high at the end.

3 Experiment

All source codes, pre-processed datasets, trained network parameters, and results
are available at https://github.com/jukworks/swat-seq2seq.

3.1 Training

Occasionally, a neural network goes bad local minima during training process. A
general approach to solve this issue is to train the neural network multiple times
independently and choose the best result among the multiple training results.
As a neural network is trained with a stochastic gradient descent and mostly
initialized with random numbers, diﬀerent results are obtained every run. Two
independent training sessions were run for each model (each process) and the
network presenting the lowest training loss was chosen.

The model was optimized with Adam [9], amsgrad [16], and without weight
decay. Each model trained 150 epochs with a 4,096 batch size. Early stopping
was not applied.

The hardware consisted of Intel Xeon CPU E5-2960 v4 2.60GHz, 6 NVIDIA
Tesla V100, and 512 GB RAM. Table 1 shows that the training time was ap-
proximately 2 hours on average. Six models have a diﬀerent size of input and
output, but their internal LSTM architectures were entirely the same. Therefore,
the number of trainable parameters is similar, which leads to similar training
time.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

7

Table 1. Training time for 150 epochs

Process 1 Process 2 Process 3 Process 4 Process 5 Process 6

Trial 1
Trial 2

1h 48m
1h 50m

2h 00m
1h 59m

1h 53m
1h 59m

1h 54m
2h 01m

2h 23m
2h 01m

2h 27m
2h 12m

Fig. 4. LIT-101 was not stable after attack 30 happens (from [10])

3.2 Anomaly Detection

The results are compared with Kaspersky’s research [18] because this is the only
study providing the list of found attack points.

If an alert is received within 15 minutes after the attack range of SWaT, it
is considered as a detection. 15 minute is chosen as attacks attacks on cyber-
physical systems tend to have a long impact. The shortest attack in SWaT,
attack 29, lasts 2 minutes2. Figure 4 shows LIT-101 on attack 30 [10]. The two
black vertical lines represent the start and end of the attack. After the end of the
attack, LIT-101 was unstable. As the reported model learns the normal-labeled
data only, it may perceive the stabilizing region as an anomaly.

Tables 2 and 3 compare the detection results with those of [18]. Attacks 5,
9, 12, 15, and 18 have no physical impact. These attacks were ignored as they
cannot be detected with operational data. The ﬁrst column shows the attack
numbers. The second column presents the answer to attack points labeled in
the SWaT dataset. The third column represents the detection of the attack:
Yes means 100% sure, not sure means 30% - 100% means sure, and No means
less than 30% sure. As mentioned in Section 2.5, 30% represents the heuristic
threshold. The fourth and ﬁfth column represents the attack points determined
by the model and [18], respectively. Bold text indicates correct answers. The

2 The longest attack in SWaT is attack 28, which lasted 9.5 hours.

8

J. Kim et al.

Fig. 5. List of detected attacks and comparison with [18]. Red (4, 14, 29) represents
attacks that are impossible to detect. Yellow (24) represents attacks that are diﬃcult
to detect.

parentheses indicate the second-longest distance. N/A indicates that the model
failed to detect.

[18] reported 25 attacks and 11 attack points (nine with the ﬁrst predictions
and 2 with the second predictions). Herein, the model found 29 attacks and 25
attack points (22 with the ﬁrst predictions and 3 with the second predictions).
21 attacks were detected by both the developed model and that in [18]. Four
attacks were detected only by the model in [18]: attacks 19, 24, 25, and 29. Eight
attacks were detected only by the developed model: attacks 1, 3, 17, 20, 27, 32,
33, and 41, which also detected attacks 21 and 31 with 35% and 50% rates,
respectively. The SWaT dataset indicates that the attack points of attack 35 is
process 1, but it was detected by the developed model for process 3 (20% rate
at the model for process 1). Both methods failed to detect three attacks: attacks
4, 13, and 14.

The model was not used with process 6 as it has only two tags. The SWaT

dataset presents only one attack3 and has an impact on process 6.

4 Analysis of Experimental Results

Three pairs of attacks, (10, 11), (19, 20), and (27, 28) were indistinguishable
for the developed model because they occur almost continuously4 and have the
same attack point.

4.1 Analysis on False Negative (Undetected Attacks)

The model failed to detect attacks 4, 13, 14, 19, 24, 25, and 29.

3 Attack 23 also has an impact on process 3. The developed model for process 3

detected this attack.

4 Their intervals are 0, 42, and 1 second(s) respectively, while the developed model

uses a 100-second sliding windows.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

9

Table 2. Anomaly detection results compared with those of [18] (attacks 1 to 30)

Attack #

1
2

3

4
6

7

8

10

11

13
14
16

17

19

20
21

22

23

24
25

26

27

28

29

30

Answer (by
SWaT)
MV-101
P-102

Detection (our
work)
Yes
Yes

LIT-101

MV-504
AIT-202

LIT-301

DPIT-301

FIT-401

FIT-401

MV-304
MV-303
LIT-301

MV-303

Not sure
(65%)
No
Yes

Yes

Yes

Yes

Yes

No
No
Yes

Yes

AIT-504

No (15%)

Attack point
([18])
N/A
MV-301
(P-102)
N/A

Attack point
(our work)
MV-101
MV-101
(P-102)
MV-101
(LIT-101)
N/A
AIT-202

LIT-301

FIT-401

N/A
AIT-202
(P-203)
LIT-301
(PIT-502)
DPIT-301 DPIT-301
(MV-302)
FIT-401
(PIT-502)
MV-304
(MV-302)
N/A
N/A
MV-301
(MV-303)
N/A

FIT-401
(FIT-504)
MV-304
N/A
LIT-301

MV-301
(MV-303)
AIT-504

Yes
Not sure
(35%)
Yes

AIT-504
LIT-101

FIT-401,
FIT-504

AIT-504
(P-501)
N/A
UV-401
(P-501)
DPIT-301
(MV-302)

Yes

DPIT-301

P-302, P-203

No
No (20%)

Yes
(25% at P3)
Yes

Yes

No

Yes

N/A
LIT-401

P-102,
LIT-301
LIT-401

FIT-401,
AIT-504
N/A

LIT-101

LIT-401
P-602,
MV-303
LIT-401
(AIT-402)
N/A

MV-201,
LIT-101
LIT-401,
AIT-503
LIT-301
(FIT-301)

AIT-504
MV-101,
LIT-101
UV-401,
AIT-502,
P-501
P-602,
DPIT-301,
MV-302
P-203, P-205
LIT-401,
P-401
P-101,
LIT-301
P-302,
LIT-401
P-302

P-201, P-203,
P-205
LIT-101,
P-101,
MV-201

10

J. Kim et al.

Table 3. Anomaly detection results compared with those of [18] (attacks 31 to 41)

Attack #

31

32
33
34

35

36

37

38

39

40

41

Answer (by
SWaT)
LIT-401

LIT-301
LIT-101
P-101

Detection (our
work)
Not sure
(50%)
Yes
Yes
Yes

P-101, P-102

LIT-101

P-501,
FIT-502
AIT-402,
AIT-502

FIT-401,
AIT-502
FIT-401

LIT-301

Not sure
(20% at P1,
45% at P3)
Yes

Yes

Yes
(15% at P5)

Yes

Yes

Yes

Attack point
(our work)
LIT-101

LIT-301
LIT-101
P-101

P-101

LIT-101

FIT-401,
FIT-504
MV-101,
AIT-402,
AIT-502
FIT-401

FIT-401,
FIT-504
LIT-301

Attack point
([18])
P-602,
MV-303
N/A
N/A
MV-201
(P-203)
MV-201,
MV-303

LIT-101,
AIT-503
FIT-504
(FIT-503)
AIT-502,
AIT-402

FIT-401,
P-201
UV-401
(FIT-401)
N/A

Impossible-to-ﬁnd attacks It appears that attacks 4, 14, and 29 were impos-
sible to detect (in red in Figure 5). The developed model, the model in [18], and
the model in [10] all failed to detect attacks 4, 13, and 14.

Attack 4 This attack opens MV-504 that does not exist in the dataset. The
description [6] in SWaT’s list of attacks indicates that this attack has no impact.

Attack 14 According to SUTD, the attack 14 failed because tank 301 was already
full [6].

Attack 29 SUTD said that P-201, P-203, and P-205 did not start because of
mechanical interlocks. In the dataset, nothing was changed around 2015/12/31
at 3:32:00 PM.

Diﬃcult-to-ﬁnd attacks According to [6], attacks 13 and 24 have a small
impact (represented in yellow in Figure 5). The developed model did not detect
these attacks. The model also failed to detect attacks 19 and 25.

Attack 13 This attack attempted to close MV-304 but MV-304 was closed later
than when this attack occurred. In the SWaT dataset, MV-304 did not change.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

11

Attack 19 This attack attempted to set value of AIT-504 to 16 µs/cm. AIT-504
is below 15 µs/cm in the normal state. In Figure 6, the attack appeared to be
detected, but the high rate was derived from attack 20 which set a value of AIT-
504 to 255 µs/cm. the distances provided by the developed model are too short
to detect for attack 19. The rate S was of approximately 20% for attack 19.

Fig. 6. Attack 19 in process 5 (red: attack, purple: prediction error, and blue: anomaly
score)

Attack 24 This attack attempted to turn oﬀ P-203 and P-205 (both are pumps
are used for injecting chemicals). However, there was only a small impact due
to the closure of P-101.

Attack 25 This attack attempted to set the value of LIT-401 to 1,000 and open
P-402 while P-402 was still operating. LIT-401 presented notable distances but
the rate was of approximately 20% (Figure 7). According to [18], attack 25 was
detected but wrong attack points were determined.

Managed-to-ﬁnd attack The developed model managed to detect attack 35
with a rate of 45%.

Attack 35 According to [6], attack 35 occurred at process 1, but herein, the
attack was detected at process 3. Before the attack, P-101 was open, and P-202
was close. The attack opened P-101 and kept P-102 close. Figure 8 shows the
attacks 34 and 35. Processes 1, 2, and 3 presented remarkable distances. The
distance of process 2 appears to be large, but the scale is small. There are two
high peaks of rate in process 1, but they come from the attack 34.

Attack 34 closed P-101 (2 → 1) and opened P-102 (1 → 2). Later, P-101
was opened (1 → 2) at 17:14:59 and P-102 was closed (2 → 1). Attack 35 was
diﬀerent from attack 34 as it kept P-102 closed. In the training (normal) dataset,
P-102 was closed (of value 1) at all time, which is why the developed model
always indicated 1. Because P-102 is a backup pump for P-101, the developed

12

J. Kim et al.

Fig. 7. Attack 25 in process 4 (red: attack, purple: prediction error, and blue: anomaly
score)

Table 4. Number of false positives. OP indicates the number of false positives for
attacks on other processes, LT indicates the long-tailed detection (over 15 minutes),
and TFP indicates the true false positives.

Process

False positives
(all duplicates)

OP

LT

TFP

1
2
3
4
5

7(11)
5(8)
0
1(1)
0

4
0
-
1
-

2
0
-
0
-

1
5
-
0
-

model must understand their connection. However, the model could not learn
the connection as the training dataset did not give enough information.

4.2 Analysis on False Positives (False Alarms)

This subsection analyzes false positives. The evaluation script is also available
at https://github.com/jukworks/swat-seq2seq/tree/master/evaluation.
Sixty seven false positives were obtained from all models, and many of them
were timely overlapped. After removing the duplicates, twenty false positives
were found. The number of false positives is presented in Table 4. Processes 3
and 5 present no false positives.

The decision method described in Section 2.5 reacted twice at the start and
end of the attack. The second column represents the number of false positives
after removing the duplicates. The third column, OP, represents the number
of positives caused by the attacks on the other processes. The fourth column,
LT, represents the number of long-tailed positives. 15 minutes after the end of
the attack as a true-positive, but sometimes the tail was too long and the attack
lasted over 15 minutes. The long-tail positives were not counted as true-positives.
In summary, there was one true false positive (TFP, the ﬁfth column) in process
1 and ﬁve in process 2.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

13

Fig. 8. Attacks 34 and 35 in processes 1, 2, and 3 (red: attack, purple: prediction error,
and blue: anomaly score)

False positives in process 1 There were eleven false positives in process 1.
In Table 5, (2, 3), (4, 5), (7, 8), and (10, 11) are pairs of start-end having the
same related attacks. Therefore there were seven independent false positives.
One of them was true false positive. Four of them were simultaneous detection
for attacks targeting other processes. Two of them were long-tail detection.

False positives in process 2 The developed model for process 2 created eight
false positives. In Table 6, pairs (1, 2), (4, 5), and (6, 7) have the same related
attacks. Therefore, there were ﬁve independent false positives, and four of them
were true.

Most false positives occurred at P-201, P-205, and MV-201. P-201 is the NaCl
injection jump; P-205 is the NaOCl injection pump. In the training dataset, P-
201 never changed. We guess that the model regarded any change of P-201 as
an attack. AIT-201, a sensor for NaCl, caused a false positive (No. 8 in Table 6)
because P-201 had changed the level of NaCl.

After the last false positive, the prediction errors of AIT-201 and AIT-203
went high. AIT-201 and AIT-203 are sensors for NaCl and NaOCl, respectively.
We guess that the unexpected behaviors of P-201 and P-205 led to new but
normal dataset.

False positives in process 4 In Table 7, there was one false positive in process
4, which came from attack 37 hitting process 5.

14

J. Kim et al.

Table 5. The analysis of false positives in process 1. OP means the number of false
positives for attacks on other processes; LT for long-tailed detection (over 15 minutes);
TFP for true false positives.

No.

Time

Related attacks Tags Type of false positive

7

17

17

-

-

26

32

32

33

38

38

P-101

MV-101

MV-101

MV-101

MV-101

-

MV-101

MV-101

-

P-101

P-101

OP

OP

OP

TFP

TFP

LT

OP

OP

LT

OP

OP

1

3

4

2

5

2015-12-28 12:19:05 PM
- 2015-12-28 12:20:46 PM
2015-12-29 02:32:36 PM
- 2015-12-29 02:36:34 PM
2015-12-29 02:39:42 PM
- 2015-12-29 02:43:39 PM
2015-12-30 01:51:41 PM
- 2015-12-30 01:55:36 PM
2015-12-30 02:06:12 PM
- 2015-12-30 02:09:55 PM
2015-12-30 06:20:01 PM
- 2015-12-30 06:21:07 PM
2016-01-01 10:58:18 AM
- 2016-01-01 11:02:11 AM
2016-01-01 11:10:06 AM
- 2016-01-01 11:13:38 AM
2016-01-01 03:02:23 PM
- 2016-01-01 03:04:04 PM
10 2016-01-02 11:32:16 AM

8

9

7

6

- 2016-01-02 11:36:10

11 2016-01-02 11:47:29 AM
- 2016-01-02 11:51:04 AM

5 Conclusion

It is diﬃcult to get internal speciﬁcation and control logic of ICSs. If routine
ICS operational data is the only information available, a data-driven approach
is a proper way to develop security products.

We proposed an anomaly detection method for industrial control systems
using sequence-to-sequence neural networks with attention. Due to the diﬃculty
of deﬁning the abnormal state, the model learns the normal dataset in an un-
supervised way. In the detection phase, the model predicts future values based
on the previously observed ones. The diﬀerence between the model’s prediction
and the measured value is the key criterion to detect anomalies.

The alarm decision depends on the threshold, and heuristic hyper-parameters
were necessary for this experiment. Our proposed method is not dedicated to the
dataset. It can be generalized to train any ICS datasets and extract the decision
grounds because the speciﬁcation of operational data and control logic inside
was not required. It is also able to detect anomalies with only the dataset from
normal operations.

Anomaly Detection for ICSs Using Seq2Seq Neural Networks

15

Table 6. Analysis of false positives of process 2. OP indicates the number of false
positives for attacks on other processes, and TFP indicates true false positives.

No.

Time

Related attacks Tags Type of false positive

1

2

3

4

5

6

7

8

2015-12-29 07:18:41 PM
- 2015-12-29 07:22:14 PM
2015-12-29 07:29:56 PM
- 2015-12-29 07:33:38 PM
2015-12-29 09:23:58 PM
- 2015-12-29 09:26:36 PM
2015-12-29 09:44:08 PM
- 2015-12-29 09:47:43 PM
2015-12-29 09:52:23 PM
- 2015-12-29 09:54:07 PM
2015-12-29 11:12:18 PM
- 2015-12-29 11:12:58 PM
2015-12-29 11:19:43 PM
- 2015-12-29 11:20:37 PM
2015-12-30 01:12:39 AM
- 2015-12-30 01:14:50 AM

-

-

-

-

-

16

16

-

P-201,
P-205
P-201,
P-205
MV-201,
P-201
MV-201,
P-201
MV-201,
P-201
P-201,
P-205
P-201,
P-205
P-201,
AIT-201

TFP

TFP

TFP

TFP

TFP

OP

OP

TFP

Table 7. Analysis of false positives of process 4. OP indicates the number of false
positives for attacks on other processes

No.

1

Time

Related attacks Tags Type of false positive

2016-01-02 11:19:16 AM
- 2016-01-02 11:23:15 AM

37

-

OP

References

1. Ahmad, S., Lavin, A., Purdy, S., Agha, Z.: Unsupervised real-time anomaly detec-

tion for streaming data. Neurocomputing 262, 134 – 147 (2017)

2. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learn-
ing to align and translate. In: 3rd International Conference on Learning Repre-
sentations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track
Proceedings (2015)

3. Chen, Y., Poskitt, C.M., Sun, J.: Learning from mutants: Using code mutation to
learn and monitor invariants of a cyber-physical system. In: 2018 IEEE Symposium
on Security and Privacy (SP). pp. 648–660. IEEE (2018)

4. Choi, S., Yun, J.H., Kim, S.K.: A comparison of ics datasets for security research
based on attack paths. In: The 13th International Conference on Critical Informa-
tion Infrastructures Security (CRITIS) (2018)

5. Formby, D., Srinivasan, P., Leonard, A., Rogers, J., Beyah, R.A.: Who’s in con-
trol of your control system? device ﬁngerprinting for cyber-physical systems. In:
Network and Distributed Systems Security (NDSS) (2016)

16

J. Kim et al.

6. Goh, J., Adepu, S., Junejo, K.N., Mathur, A.: A dataset to support research in the
design of secure water treatment systems. In: The 11th International Conference
on Critical Information Infrastructures Security (CRITIS) (2016)

7. Goh, J., Adepu, S., Tan, M., Lee, Z.S.: Anomaly detection in cyber physical systems
using recurrent neural networks. In: 2017 IEEE 18th International Symposium on
High Assurance Systems Engineering (HASE). pp. 140–145. IEEE (2017)

8. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8),

1735–1780 (Nov 1997)

9. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: 3rd In-
ternational Conference on Learning Representations, ICLR 2015, San Diego, CA,
USA, May 7-9, 2015, Conference Track Proceedings (2015), http://arxiv.org/
abs/1412.6980

10. Kravchik, M., Shabtai, A.: Detecting cyber attacks in industrial control systems
using convolutional neural networks. In: Proceedings of the 2018 Workshop on
Cyber-Physical Systems Security and PrivaCy. pp. 72–83. CPS-SPC ’18 (2018)
11. Lemay, A., Fernandez, J.M.: Providing scada network data sets for intrusion detec-
tion research. In: Proceedings of the 9th USENIX Conference on Cyber Security
Experimentation and Test. pp. 6–6. CSET’16, Berkeley, CA, USA (2016)

12. Li, D., Chen, D., Shi, L., Jin, B., Goh, J., Ng, S.: MAD-GAN: multivariate
anomaly detection for time series data with generative adversarial networks. CoRR
abs/1901.04997 (2019)

13. Lin, C.Y., Nadjm-Tehrani, S., Asplund, M.: Timing-based anomaly detection in
scada networks. In: International Conference on Critical Infrastructures Security
(CRITIS) (2017)

14. Mitchell, R., Chen, I.R.: A survey of intrusion detection techniques for cyber-

physical systems. ACM Computing Surveys (CSUR) 46(4), 55 (2014)

15. Mitchell, R., Chen, R.: Behavior-rule based intrusion detection systems for safety
critical smart grid applications. IEEE Transactions on Smart Grid 4(3), 1254–1263
(2013)

16. Reddi, S.J., Kale, S., Kumar, S.: On the convergence of adam and beyond. In: 6th
International Conference on Learning Representations, ICLR 2018, Vancouver, BC,
Canada, April 30 - May 3, 2018, Conference Track Proceedings (2018)

17. Rodoﬁle, N.R., Schmidt, T., Sherry, S.T., Djamaludin, C., Radke, K., Foo, E.:
Process Control Cyber-Attacks and Labelled Datasets on S7Comm Critical Infras-
tructure. In: Information Security and Privacy. pp. 452–459 (2017)

18. Shalyga, D., Filonov, P., Lavrentyev, A.: Anomaly detection for water treatment
system based on neural network with automatic architecture optimization. DISE1
Workshop, International Conference on Machine Learning (ICML) (2018)

19. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural net-
works. In: Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N.D., Weinberger,
K.Q. (eds.) Advances in Neural Information Processing Systems 27, pp. 3104–3112
(2014)

20. Yun, J., Hwang, Y., Lee, W., Ahn, H., Kim, S.: Statistical similarity of critical
infrastructure network traﬃc based on nearest neighbor distances. In: Research in
Attacks, Intrusions, and Defenses - 21st International Symposium, RAID 2018. pp.
577–599 (2018)

