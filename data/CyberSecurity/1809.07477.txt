9
1
0
2

p
e
S
9
1

]

R
C
.
s
c
[

2
v
7
7
4
7
0
.
9
0
8
1
:
v
i
X
r
a

Taming the War in Memory: A Resilient Mitigation
Strategy Against Memory Safety Attacks in CPS

Eyasu Getahun Chekole1,2, Unnikrishnan Cheramangalath1, Sudipta
Chattopadhyay1, Mart¬¥ƒ±n Ochoa1,3, and Guo Huaqun2

1 Singapore University of Technology and Design, Singapore, Singapore
2 Institute for Infocomm Research (I2R), Singapore, Singapore
3 Department of Applied Mathematics and Computer Science, Universidad del Rosario,
Bogot¬¥a, Colombia

Abstract. Memory-safety attacks have been one of the most critical threats
against computing systems. Although a wide-range of defense techniques have
been developed against these attacks, the existing mitigation strategies have sev-
eral limitations. In particular, most of the existing mitigation approaches are
based on aborting or restarting the victim program when a memory-safety at-
tack is detected, thus making the system unavailable. This might not be accept-
able in systems with stringent timing constraints, such as cyber-physical systems
(CPS), since the system unavailability leaves the control system in an unsafe
state. To address this problem, we propose CIMA ‚Äì a resilient and light-weight
mitigation technique that prevents invalid memory accesses at runtime. CIMA
manipulates the compiler-generated control-Ô¨Çow graph to automatically detect
and bypass unsafe memory accesses at runtime, thereby mitigating memory-
safety attacks along the process. An appealing feature of CIMA is that it also
ensures system availability and resilience of the CPS even under the presence
of memory-safety attacks. To this end, we design our experimental setup based
on a realistic Secure Water Treatment (SWaT) and Secure Urban Transporta-
tion System (SecUTS) testbeds and evaluate the eÔ¨Äectiveness and the eÔ¨Éciency
of our approach. The experimental results reveal that CIMA handles memory-
safety attacks eÔ¨Äectively with low overhead. Moreover, it meets the real-time
constraints and physical-state resiliency of the CPS under test.

1

Introduction

Software systems with stringent real-time constraints are often written in C/C++ since
they aid in generating eÔ¨Écient program binaries. However, since memory management
is handled manually and also the lack of bounds checking in C/C++, programs writ-
ten in such languages often suÔ¨Äer from memory-safety vulnerabilities, such as buÔ¨Äer
over/underÔ¨Çows, dangling pointers, double-free errors and memory leaks. Due to the
diÔ¨Éculty in discovering these vulnerabilities, they might often slip into production run.
This leads to memory corruptions and runtime crashes even in deployed systems. In the
worst case, memory-safety vulnerabilities can be exploited by a class of cyber attacks,
which we refer to as memory-safety attacks [1, 2]. Memory-safety attacks, such as code
injection [3, 4] and code reuse [5, 6, 7], can cause devastating eÔ¨Äects by compromising
vulnerable programs in any computing system. These attacks can hijack or subvert

1

 
 
 
 
 
 
speciÔ¨Åc operations of a system or take over the entire system, in general. A detailed
account of such attacks is provided in existing works [7, 8, 9].

Given a system vulnerable to memory-safety attacks, its runtime behavior will de-
pend on the type of memory accesses being made, among others. For instance, accesses
to an array element beyond the imposed length of the array (buÔ¨Äer overÔ¨Çows) could be
exploited to overwrite the return address of a function. However, a safety check gen-
erated at compile time [10] can be added before any memory access to ensure validity
of the memory going to be accessed. This can be accomplished via compiler-assisted
program analysis. Traditionally, such memory-safe compilers will generate an exception
and abort when such violations are found at run-time.

However, we make the observation that one could also react to such violations
by bypassing the illegal instructions, i.e., instructions that attempt to access memory
illegally, and thus favoring availability of the system. This is the main intuition upon
which our CIMA approach is based upon. In particular, CIMA is a resilient mitigation
strategy that eÔ¨Äectively and eÔ¨Éciently prevents memory-safety attacks and guarantees
system availability with minimal overhead (8.06%).

To realize the aforementioned intuition behind CIMA, we face several technical
challenges. Firstly, it is infeasible (in general) to statically compute the exact set of
illegal memory accesses in a program. Consequently, a fully static approach, which
modiÔ¨Åes the program to eliminate the illegal instructions from the program, is unlikely
to be eÔ¨Äective. Moreover, such an approach will inevitably face scalability bottlenecks
due to its heavy reliance on sophisticated program analysis. Secondly, even if the illegal
instructions are identiÔ¨Åed during execution, it is challenging to bypass the manifestation
of illegal memory access. This is because, such a strategy demands full control to
manipulate the normal Ô¨Çow of program execution. Finally, to bypass the execution of
certain instructions, we need modiÔ¨Åcations to the control Ô¨Çow of the program. From a
technical perspective, such modiÔ¨Åcations involve the manipulation of program control
Ô¨Çow over multitudes of passes in mainstream compilers.

To alleviate the technical challenges, CIMA systematically combines compile-time
instrumentation and runtime monitoring to defend against memory-safety attacks.
SpeciÔ¨Åcally, at compile time, each instrumented memory access is guarded via a con-
ditional check to detect its validity at runtime. In the event where the conditional
check fails, CIMA skips the respective memory access at runtime. To implement such
a twisted Ô¨Çow of control, CIMA automatically transforms the program control Ô¨Çow
logic within mainstream compilers. This makes CIMA a proactive mitigation strategy
against a large class of memory-safety attacks.

It is the novel mitigation strategy that sets our CIMA approach apart from the ex-
isting works [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]. Most of the existing mitigation
schemes against memory-safety attacks are primarily programmed to abort or restart
the victim system when an attack or a memory-safety violation is detected. Other
schemes, such as self-healing [22, 23, 24] or live patching [25], are based on directly
detecting exploitations or attacks and resuming the corrupted system from a previous
safe state. CIMA never aborts the system and avoids the heavy overhead of maintaining
system states for checkpoints. On the contrary, CIMA follows a fundamentally diÔ¨Äerent
approach, i.e., to continue execution by skipping only the illegal instructions.

Although our proposed security solution is applicable to any computing system
that involves C/C++ programs, we mainly focus on the CPS domain. This is because,

2

unlike the mainstream systems, CPS often imposes conÔ¨Çicting design constraints in-
volving real-time guarantees, physical-state resiliency involving its physical dynam-
ics and security. In CPS, the memory-safety vulnerabilities might be found in the
Ô¨Årmware (or sometimes in the control software) of PLCs. Such Ô¨Årmware is commonly
implemented in C/C++ for the sake of eÔ¨Éciency. Consequently, it is not uncom-
mon to have buÔ¨Äer over/underÔ¨Çows and dangling pointers being regularly discovered
even in modern PLCs. In fact, recent trends in Common Vulnerabilities and Expo-
sures (CVEs) show the high volume of interest in exploiting these vulnerabilities in
PLCs [26, 27, 28, 29, 30, 31, 32, 33]. This shows that the mitigation of memory-safety
attacks in CPS should not merely be restricted to academic research. Instead, it is
a domain that requires urgent and practical security solutions to protect a variety of
critical infrastructures at hand. Nonetheless, attacks that manipulate sensor and ac-
tuator values in CPS (either directly on sensor/actuator devices or on communication
channels) are orthogonal issues that are out of our scope.

In summary, our work tackles the problem of ensuring critical systems and services
to remain available and eÔ¨Äective while successfully mitigating a wide-range of memory-
safety attacks. We make the following technical contributions:

1. We eÔ¨Äectively prevent system crashes that could be arisen due to memory-safety

violations.

2. We eÔ¨Äectively and eÔ¨Éciently prevent memory-safety attacks in any computing sys-

tem.

3. We deÔ¨Åne the notion of physical-state resiliency that is crucial for CPS and should

be met alongside strong security guarantees.

4. Our mitigation solution ensures physical-state resiliency and system availability
with reasonable runtime and storage overheads. Thus, it is practically applicable
to systems with stringent timing constraints, such as CPS.

5. We evaluate the eÔ¨Äectiveness and eÔ¨Éciency of our approach on two real-world CPS

testbeds.

2 Background

In this section, we introduce the necessary background in the context of our CIMA
approach.

2.1 CPS

CPS constitutes of complex interactions between entities in the physical space and the
cyber space over communication networks. Unlike traditional IT systems, such complex
interactions are accomplished via communication with the physical world via sensors
and with the digital world via controllers (PLCs) and other embedded devices. CPS
usually impose hard real-time constraints. If such real-time constraints are not met,
then the underlying system might run into an unstable and unsafe state. Moreover,
the devices in a typical CPS are also resource constrained. For example, PLCs and
I/O devices have limited memory and computational power. In general, a typical CPS
consists of the following entities:

3

‚Äì Physical plants: Physical systems where the actual processes take place.
‚Äì Sensors: Devices that are capable of reading or observing information from plants

or physical processes.

‚Äì PLCs: Controller devices that receive sensor inputs, make decisions and issue con-

trol commands to actuators.

‚Äì Actuators: Physical entities that are capable of implementing the control com-

mands issued by the PLCs.

‚Äì Communication networks: The communication medium through which packets
containing sensor inputs, control commands, diagnostic information and alarms
transmit from one CPS entity to another.

‚Äì SCADA: A software entity designed for monitoring and controlling diÔ¨Äerent pro-
cesses in a CPS. It often comprises a human-machine interface (HMI) and a his-
torian server. The HMI is used to display state information of plants and physical
processes in the CPS. The historian server is used to store all operational data and
the history of alarms.

An abstraction of a typical CPS architecture is shown in Figure 2. In Figure 2,
x denotes the physical state of the plant, y captures the sensor measurements and u
denotes the control command computed by the PLC at any given point of time.

2.2 ASan

Despite the presence of several memory error detector tools, their applicability in CPS
is limited due to several reasons. This includes the lack of error coverage, signiÔ¨Åcant
performance overhead and other technical compatibility issues. After researching and
experimenting on various memory-safety tools, we chose ASan [10] as our memory
error detector tool. Our choice is motivated by its broad error coverage, high detec-
tion accuracy and relatively low runtime overhead when compared with other code-
instrumentation based tools [10, 34].

ASan is a compile-time memory-safety tool based on code instrumentation. It in-
struments C/C++ programs at compile time. The instrumented program will then
contain additional ASan libraries, which are checked to detect possible memory-safety
violation at runtime. Such an instrumented code can detect buÔ¨Äer over/underÔ¨Çows, use-
after-free errors (dangling pointers), use-after-return errors, initialization order bugs
and memory leaks.

Since ASan was primarily designed for x86 architectures, it has compatibility issues
with RISC-based ARM or AVR based architectures. Therefore, we adapted ASan for
ARM-based architecture in our system.
Limitations of ASan: Although ASan covers a wide range of memory errors, it
does not cover some memory-safety errors such as uninitialized memory reads and
some use-after-return bugs. In fact, such errors are less critical and rarely exploited
in practice. ASan also has minor limitation in detection accuracy. Although it oÔ¨Äers
high detection accuracy for most memory-safety vulnerabilities, there are rare false
negatives for global buÔ¨Äer overÔ¨Çow and use-after-free vulnerabilities. This might allow
memory-safety attacks to bypass the checks enforced by ASan with low probability. The
other major limitation of ASan is its ineÔ¨Äective mitigation strategy; it simply aborts
the system whenever a memory-safety violation or an attack is detected. This makes
ASan inapplicable in systems with stringent availability constraints.

4

ASan as a debugging and monitoring tool: Because of the limitations, as men-
tioned in the preceding paragraph, ASan is often considered as rather a debugging
tool than a runtime monitoring tool. However, using ASan only as a debugging tool
does not guarantee memory-safety. Because, most memory-safety vulnerabilities (e.g.
buÔ¨Äer overÔ¨Çows) can be probed by systematically crafted inputs by attackers who aim
to exploit it. Since carefully tailored inputs might not be used during debugging, ASan
might miss important memory bugs that can be exploited by an attacker at runtime.
Therefore, only debugging the program does not oÔ¨Äer suÔ¨Écient guarantee in detecting
critical memory-safety vulnerabilities.

In our CIMA approach, we adopt ASan for the dual purpose of debugging and run-
time monitoring, with the speciÔ¨Åc focus on mitigating memory-safety vulnerabilities.
As a runtime monitoring tool, CIMA leverages on ASan to detect attacker injected
memory-safety bugs. Moreover, CIMA enhances the capability of ASan to mitigate
memory-safety bugs on-the-Ô¨Çy. This is to ensure the availability of the underlying sys-
tem and in stark contrast to plain system abort.

3 Attacker and system models

In this section, we Ô¨Årst discuss the attacker model. Then, we discuss the diÔ¨Äerent traits
of formally modeling our system and the related design constraints.

3.1 Attacker model

The main objective of memory-safety attacks, like code injection and code reuse, is to
get privileged access or take control (otherwise to hijack/subvert speciÔ¨Åc operations)
of the vulnerable system. To achieve this, vulnerabilities such as buÔ¨Äer overÔ¨Çows and
dangling pointers of a program are targeted. For example, to exploit a buÔ¨Äer overÔ¨Çow,
the attacker sends carefully crafted input to the buÔ¨Äer. When the buÔ¨Äer overÔ¨Çows, the
attacker can manipulate important memory addresses, like return address of a function,
and divert control Ô¨Çow of the program. A detailed account of such exploitations can be
found in [7, 35]. In general, a typical memory-safety attack follows the following steps
(See Figure 1):

1. Interacting with the victim PLC, e.g., via network connection (for remote attacks).
2. Finding a memory-safety vulnerability (e.g., buÔ¨Äer overÔ¨Çow, dangling pointers) in

the PLC Ô¨Årmware or control software with the objective of exploiting it.
3. Triggering a memory-safety violation on the PLC, e.g., overÔ¨Çowing a buÔ¨Äer.
4. Overwriting critical addresses of the vulnerable program, e.g., overwriting return

address of the PLC program.

5. Using the modiÔ¨Åed address, divert control Ô¨Çow of the program to an injected (ma-
licious) code (i.e. code injection attacks) or to an existing module of the vulnerable
program (i.e. code reuse attacks). In the former case, the attacker can take over the
PLC with the injected malicious code. In the latter case, the attacker still needs to
collect appropriate gadgets from the program (basically by scanning the program‚Äôs
text segment), then she will synthesize a shellcode that will allow her to take over
the PLC.

5

Fig. 1: Overview of memory-safety attack exploitations

3.2 Modeling CPS timing constraints

Most cyber-physical systems are highly time-critical. The communication between its
diÔ¨Äerent components, such as sensors, controllers (PLCs) and actuators, is synchronized
by system time. Therefore, delay in these CPS nodes could result in disruption of
the control system or damage the physical plant. In particular, PLCs form the main
control devices and computing nodes of a typical CPS. As such, PLCs often impose
hard real-time constraints to maintain the stability of the control system in a CPS. In
the following section, we deÔ¨Åne and discuss the notion of real-time constraints imposed
on a typical CPS.

Modeling real-time constraints In general, PLCs undergo a cyclic process called
scan cycle. This involves three major operations: input scan, PLC program (logic)
execution and output update. The time it takes to complete these operations is called
scan time (Ts). A typical CPS deÔ¨Ånes and sets an upper-bound on time taken by PLC
scan cycle, called cycle time (Tc). This means the scan cycle must be completed within
the duration of the cycle time speciÔ¨Åed, i.e., Ts ‚â§ Tc. We refer this constraint as a real-
time constraint of the PLC. By design, PLCs meet this constraint. However, due to
additional overheads, such as memory-safety overheads (MSO), PLCs might not satisfy
its real-time constraint. As discussed above, by hardening the PLC with our memory-
safety protection (detection + mitigation), the scan time increases. This increase in
the scan time is attributed to the MSO. Concretely, the memory-safety overhead is
computed as follows:

MSO = ÀÜTs ‚àí Ts,

(1)

6

where ÀÜTs and Ts are scan time with and without memory-safe compilation, respectively.
A detailed account of modeling Ts is provided in our earlier works [8, 9].

It is crucial to check whether the induced MSO by the memory-safe compilation still
satisÔ¨Åes the real-time constraint imposed by the PLC. To this end, we compute MSO
for ‚Äì 1) average-case and 2) worst-case scenarios. In particular, after enabling memory-
safe compilation, we compute the scan time (i.e. ÀÜTs) for n diÔ¨Äerent measurements and
compute the respective average and worst-case scan time. Formally, we say that the
MSO is acceptable in average-case if the following condition is satisÔ¨Åed:

(cid:80)n

ÀÜTs(i)
i=1
n

‚â§ Tc

(2)

In a similar fashion, MSO is acceptable in the worst-case with the following condition:

n
max
i=1

ÀÜTs(i) ‚â§ Tc

(3)

where ÀÜTs(i) captures the scan time for the i-th measurement after the memory-safe
compilation.

3.3 Physical-state resiliency

The stability of CPS controllers (i.e. PLCs in our case) plays a crucial role in enforcing
the dynamics of a cyber-physical system to be compliant with its requirement. For
example, assume that a PLC issues control commands every Tc cycle and an actuator
receives these commands at the same rate. Therefore, cycle time of the PLC is Tc. If the
PLC is down for an arbitrary amount of time say œÑ , then the actuator will not receive
fresh control commands for the duration œÑ . Consequently, the physical dynamics of the
respective CPS will be aÔ¨Äected for a total of œÑ
Tc

scan cycles.

We note that the duration œÑ might be arbitrarily large. Existing solutions [10],
albeit in a non-CPS environment, typically revert to aborting the underlying process
or restart the entire system when a memory-safety attack is detected. Due to the critical
importance of availability constraints in CPS, our CIMA approach never aborts the
underlying system. Nevertheless, CIMA induces an overhead to the scan time of the
PLC, as discussed in the preceding section. Consequently, the scan time of PLCs, with
CIMA-enabled memory-safety (i.e. ÀÜTs), may increase beyond the cycle time (i.e. Tc).
In general, to accurately formulate œÑ (i.e. the amount of downtime for a PLC), we need
to consider the following three mutually exclusive scenarios:

1. The system is aborted or restarted.
2. The system is neither aborted nor restarted and ÀÜTs ‚â§ Tc. In this case, there will
be no observable impact on the physical dynamics of the system. This is because
the PLCs, despite having increased scan time, still meet the real-time constraint
Tc. Thus, they are not susceptible to downtime.

3. The system is neither aborted nor restarted and ÀÜTs > Tc. In this scenario, the PLCs
will have a downtime of ÀÜTs ‚àí Tc, as the scan time violates the real-time constraint
Tc.

7

Based on the intuitions mentioned in the preceding paragraphs, we now formally

deÔ¨Åne œÑ , i.e., the downtime of a PLC as follows:

œÑ =

Ô£±
Ô£¥Ô£≤

Ô£¥Ô£≥

‚àÜ,
0,
ÀÜTs ‚àí Tc,

system is aborted/restarted
ÀÜTs ‚â§ Tc
ÀÜTs > Tc

(4)

where ‚àÜ captures a non-deterministic threshold on the downtime of PLCs when the
underlying system is aborted or restarted.

Example As an example, let us consider the Ô¨Årst process in SWaT (discussed in
Section 6.1). This process controls the inÔ¨Çow of water from an external water supply
to a raw water tank. PLC1 controls this process by opening (with ‚ÄúON‚Äù command)
and closing (with ‚ÄúOFF‚Äù command) a motorized valve, i.e., the actuator, connected
with the inlet pipe to the tank. If the valve is ‚ÄúON‚Äù for an arbitrarily long duration,
then the raw water tank might overÔ¨Çow, often causing a severe damage to the system.
This might occur due to the PLC1 downtime œÑ , during which, the control command
(i.e. ‚ÄúON‚Äù) computed by PLC1 may not change. Similarly, if the actuator receives the
command ‚ÄúOFF‚Äù from PLC1 for an arbitrarily long duration, then the water tank may
underÔ¨Çow. Such a phenomenon will still aÔ¨Äect the system dynamics. This is because
tanks from other processes may expect raw water from this underÔ¨Çow tank. In the
context of SWaT, the tolerability of PLC1 downtime œÑ (cf. Eq. (4)) depends on the
physical state of the water tank (i.e. water level) and the computed control commands
(i.e. ON or OFF) by PLC1. In the next section, we will formally introduce this notion
of tolerance, as termed physical-state resiliency, for a typical CPS.

Modeling physical-state resiliency To formally model the physical-state resiliency,
we will take a control-theoretic approach. For the sake of simplifying the presentation,
we will assume that the dynamics of a typical CPS, without considering the noise and
disturbance on the controller, is modeled via a linear-time invariant. This is formally
captured as follows (cf. Figure 2):

xt+1 = Axt + But

(5)

(6)
yt = Cxt
where t ‚àà N captures the index of discretized time domain. xt ‚àà Rk is the state vector
of the physical plant at time t, ut ‚àà Rm is the control command vector at time t and
yt ‚àà Rk is the measured output vector from sensors at time t. A ‚àà Rk√ók is the state
matrix, B ‚àà Rk√óm is the control matrix and C ‚àà Rk√ók is the output matrix.

We now consider a duration œÑ ‚àà R for the PLC downtime. To check the tolerance
of œÑ , we need to validate the physical state vector xt at any discretized time index t.
To this end, we Ô¨Årst assume an upper-bound œâ ‚àà Rk on the physical state vector xt
at an arbitrary time t. Therefore, for satisfying physical state resiliency, xt must not
exceed the threshold œâ. In a similar fashion, we deÔ¨Åne a lower-bound Œ∏ ‚àà Rk on the
physical state vector xt.

With the PLC downtime œÑ , we revisit Eq. (5) and the state estimation is reÔ¨Åned as

follows:

x(cid:48)
t+1 = Axt + But‚àí1[[t, t + œÑ ]]

(7)

8

Fig. 2: An abstraction of a CPS model

t+1 ‚àà Rk is the estimated state vector at time t+1 and the PLCs were down for
where x(cid:48)
a maximum duration œÑ . The notation ut‚àí1[[t, t + œÑ ]] captures that the control command
ut‚àí1 was active for a time interval [t, t + œÑ ] due to the PLC downtime. In Eq. (7), we
assume, without loss of generality, that ut‚àí1 is the last control command received from
the PLC before its downtime.

Given the foundation introduced in the preceding paragraphs, we say that a typical
CPS (cf. Figure 2) satisÔ¨Åes physical-state resiliency if and only if the following condition
holds at an arbitrary time index t:

Œ∏ ‚â§ x(cid:48)

t+1 ‚â§ œâ

Œ∏ ‚â§ Axt + But‚àí1[[t, t + œÑ ]] ‚â§ œâ

(8)

Fig. 3: Illustrating the impact of PLC downtime

Figure 3 illustrates three representative scenarios to show the consequence of Eq. (8).
If the downtime œÑ1 = 0, then ut (i.e. control command at time t) is correctly computed
and x(cid:48)
t+1 = xt+1. If the downtime œÑ2 ‚àà (1, 2], then the control command ut will be
the same as ut‚àí1. Consequently, x(cid:48)
t+1 is unlikely to be equal to xt+1. Finally, when

9

t-1tt+1ùõï1 = 0 ut = ut-1 x‚Äôt+1=xt+1PLC down2 ‚â• ùõï2 > 1 ut = ut-1 x‚Äôt+1‚â† xt+1t+2ùõï3 > 2 ut+1 = ut = ut-1 x‚Äôt+1‚â† xt+1, x‚Äôt+2‚â† xt+2Discretized  time012downtime œÑ3 > 2, the control command vector ut+i for i ‚â• 0 will be the same as ut‚àí1.
As a result, the estimated state vectors x(cid:48)
t+j for j ‚â• 1 will unlikely to be identical to
xt+j.

4 CIMA: Countering Illegal Memory Accesses

CIMA is a mitigation technique designed to counter illegal memory accesses at runtime.
We Ô¨Årst outline a high-level overview and the key ingredients of our approach. Later
in this section, we discuss the speciÔ¨Åc implementation traits in more detail.

4.1 Overview of CIMA

Objective CIMA follows a proactive approach to mitigate memory-safety attacks
and thereby ensuring system availability and physical-state resilience in CPS. The key
insight behind CIMA is to prevent any operation that attempts to illegally access
memory. We accomplish this by skipping (i.e. not executing) the illegal instructions
that attempt to access memory illegally. For example, consider the exploitation of a
memory-safety attack shown in Figure 1. With our CIMA approach, the attack will be
ceased at step 3 (i.e. ‚ÄúTrigger a memory-safety violation‚Äù) of the exploitation process.

WorkÔ¨Çow of CIMA CIMA systematically manipulates the compiler-generated con-
trol Ô¨Çow graph (CFG) to accomplish its objective, i.e., to skip illegal memory accesses
at runtime. Control Ô¨Çow graph (CFG) of a program is represented by a set of basic
blocks having incoming and outgoing edges. A basic block [36] is a straight-line se-
quence of code with only one entry point and only one exit, but it can have multiple
predecessors and successors. CIMA works on a common intermediate representation
of the underlying code, thus making our approach applicable for multiple high-level
programming languages and low-level target architectures.

To manipulate the CFG, CIMA needs to instrument the set of memory-access op-
erations in such a fashion that they trigger memory-safety violations at runtime. To
this end, CIMA leverages oÔ¨Ä-the-shelf technologies, namely address sanitizers (ASan).
A high-level workÔ¨Çow of our entire approach appears in Figure 4. The implementation
of CIMA replaces the ineÔ¨Äective mitigation strategy (i.e. system abort) of ASan with
an eÔ¨Äective, yet lightweight scheme. Such a scheme allows the program control Ô¨Çow
to jump to the immediately next instruction that does not exhibit illegal memory ac-
cess. In such a fashion, CIMA not only ensures high accuracy of memory-safety attack
mitigation, but also provides conÔ¨Ådence in system availability and resilience. In the
following section, we describe our CIMA approach in detail.

4.2 Approach of CIMA

An outline of our CIMA approach appears in Algorithm 1. As input, CIMA takes a
function (in the GIMPLE format) instrumented by ASan. As output, CIMA gener-
ates a GIMPLE function with memory-safety mitigation enabled. We note that the
modiÔ¨Åcation is directly injected in the compiler workÔ¨Çow. To this end, CIMA modiÔ¨Åes
the internal data structures of GCC to reÔ¨Çect the changes of control Ô¨Çow. SpeciÔ¨Åcally,

10

Fig. 4: A high-level architecture of CIMA

CIMA manipulates the intermediate representation, which is often derived in the static-
single-assignment (SSA) form. To this end, CIMA also ensures that the SSA form is
maintained during the manipulation, so as not to disrupt the compiler workÔ¨Çow. We
now elaborate the crucial steps of CIMA in detail and discuss the speciÔ¨Åc choices taken
during its implementation.

Capture memory access instructions: CIMA validates memory accesses at run-
time to detect and mitigate illegal memory access instructions. To achieve this, CIMA
combines a compile-time code instrumentation and a runtime validity check technique.
The code instrumentation includes instrumenting memory addresses (via ASan) and
memory access instructions (via CIMA). The memory address instrumentation cre-
ates poisoned (i.e. illegal) memory regions, known as redzones, around stack, heap
and global variables. Since these redzones are inaccessible by the running program,

11

Algorithm 1: CIMA‚Äôs approach to ensure memory safety

Input: Function fun() with ASan Instrumentation
Output: Function funCIMA() with CIMA-enabled memory safety

1 forall the basic block bb in fun() do
2

forall the instruction i instrumented by ASan in bb do

Let check bb holds the memory-safety check condition check i for instruction i in
bb
Let abort bb be the basic block where control reaches to when instruction i is
illegal
Find target instruction Ti for instruction i
if ( i and Ti reside in the same basic block bb ){

tempbb := succ(bb)
/* split basic block */
Split bb into basic blocks ibb and Tbb
ibb holds instructions of bb up to i
Tbb holds instructions from Ti up to the end of bb
/* Modify control Ô¨Çow */
/* succ(bb) captures successor of bb */
succ(ibb) := {Tbb}
succ(checkbb) := {ibb, Tbb}
succ(Tbb) := tempbb

else{

/* Modify control Ô¨Çow */
Let Ti be in basic block Tbb
succ(checkbb) := (succ(checkbb) \ {abortbb}) ‚à™ {Tbb}

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

}
end

22
23 end

any memory instruction, attempting to access them at runtime will be detected as an
illegal instruction.

To mitigate the potential illegal instructions, CIMA instruments memory access
instructions at compile-time. To this end, CIMA captures memory access instructions
from the ASan instrumented code. These instructions serve as the potential candidates
for illegal instructions at runtime.

Compute target instruction: To prevent the execution of an illegal memory access
instruction i, CIMA computes its corresponding target instruction Ti. We note that
the set of potentially illegal instructions are computed via the technique as explained
in the preceding paragraph. The target instruction Ti for an illegal instruction i is the
instruction that will be executed right after i is bypassed. The compile-time analysis of
CIMA generates an instrumented binary in such a fashion that if an illegal instruction
i is detected at runtime, then i is bypassed and control reaches target instruction Ti.
If Ti is detected as illegal too, then the successor of Ti will be executed. This process
continues until an instruction is found without illegal memory access at runtime.

Computing the target instruction is a critical step in our CIMA approach. The
target instruction Ti is computed as the successor of the memory access instruction i
in the CFG. We note that a potentially illegal instruction must access memory, as the

12

objective of CIMA is to mitigate memory-safety attacks. At the GIMPLE IR-level, any
memory access instruction has a single successor. Such a successor can either be the
next instruction in the same basic block (see Figure 5(a)) or the Ô¨Årst instruction of the
successor basic block (see Figure 5(c)). Since CIMA works at the GIMPLE IR-level,
it can identify the target instruction Ti for any instruction i by walking through the
static control Ô¨Çow graph.

We modify the control Ô¨Çow graph in such a fashion that the execution is diverted
to Ti (i.e. the successor of i) at runtime when instruction i is detected to be illegal at
runtime. However, the modiÔ¨Åcation of the CFG depends on the location of the illegal
and target instructions as discussed below.
Compute target basic block: From the discussion in the preceding paragraph, we
note that the execution of memory access instruction i is conditional (depending on
whether it is detected as illegal at runtime). In the case where the instruction exhibits
an illegal memory access, a jump to the respective target instruction Ti is carried out.
However, it is not possible to simply divert the execution Ô¨Çow to the target instruction
Ti. This needs to be accomplished via a systematic modiÔ¨Åcation of the original program
CFG at compile time.

Consider the case when the illegal instruction i and the target instruction Ti reside
in the same basic block (say bb). In this case, since the execution of i is conditional, it
is always the Ô¨Årst instruction of its holding basic block whereas the target instruction
Ti appears as the next instruction in the basic block bb (see Figure 5(a)). However, it
is not possible to make a conditional jump to Ti within the same basic block bb, as this
breaks the structure of the control Ô¨Çow graph. Thus, to be able to make a conditional
jump to Ti, a target basic block (say Tbb), that contains Ti as its head instruction, is
created. In particular, we split the basic block bb into two basic blocks ‚Äì ibb and Tbb (cf.
Algorithm 1, Lines 9 ‚Äì 11). ibb holds the potentially illegal instruction i and Tbb holds
the instructions of bb following i, i.e., starting from the target instruction Ti and up to
the last instruction of bb. As such, control jumps to Tbb if instruction i is detected as
illegal at runtime.

If the illegal instruction i and the respective target instruction Ti are located in
diÔ¨Äerent basic blocks in the original CFG (see Figure 5(c)), then there is no need to
split any basic block. In such a case, the target basic block Tbb will be the basic block
holding Ti as its Ô¨Årst instruction. Therefore, CIMA diverts the control Ô¨Çow to Tbb,
should i exhibits an illegal memory access at runtime.
Modify and maintain CFG: CIMA ensures the diversion of control Ô¨Çow of the
program whenever an illegal memory access is detected. To accomplish such a twisted
control Ô¨Çow, CIMA directly modiÔ¨Åes and maintains the CFG (cf. Algorithm 1, Lines (14
‚Äì 16) and (20)), as explained in the preceding paragraph. Figure 5 illustrates excerpts
of control Ô¨Çow graphs that are relevant to the modiÔ¨Åcation performed by CIMA. In
particular, Figure 5 demonstrates how the control Ô¨Çow is systematically manipulated
to guarantee the system availability, while still mitigating memory-safety attacks.

4.3 Illustrative Example

CIMA detected and mitigated two global buÔ¨Äer overÔ¨Çow vulnerabilities on the Ô¨Årmware
of OpenPLC controller. Due to space limitation, we discuss here only one such vulnera-
bility. A code fragment relevant to the vulnerability is shown in Program 2. In Line 3, a

13

(a)

(b)

(c)

(d)

Fig. 5: DiÔ¨Äerent scenarios encountered in CIMA‚Äôs approach. checki is the inserted con-
ditional check by ASan to identify illegal memory accesses in instruction i. abortbb
is the basic block to which control jumps to if i exhibits illegal memory access. (a):
ASan instrumented CFG where both i and Ti belong to the same basic block; (b):
the modiÔ¨Åcation of control Ô¨Çow by CIMA for the ASan instrumented code in (a); (c):
ASan instrumented CFG where i and Ti belong to diÔ¨Äerent basic blocks; (d): the
modiÔ¨Åcation of control Ô¨Çow by CIMA for the ASan instrumented code in (c).

buÔ¨Äer ‚Äúint memory[]‚Äù (with a buÔ¨Äer size of 1024) is declared in the ‚Äúglue generator.cpp‚Äù
Ô¨Åle. This buÔ¨Äer is also used in the ‚Äúmodbus.cpp‚Äù Ô¨Åle, enclosed within a for loop (Lines 19
‚Äì 30) under the ‚ÄúmapUnusedIO()‚Äù function. In the loop, the memory write operation
‚Äúint memory[i] = &mb holding regs[i]‚Äù (Line 27) writes data to the buÔ¨Äer. However,
due to a coding error, this operation exhibits a memory-safety violation. Such a viola-
tion occurs in the 1024th iteration when the operation attempts to write data beyond
the buÔ¨Äer limit. CIMA successfully mitigates such memory-safety violation. This was
possible as the illegal memory access operation was bypassed in each iteration starting
from the 1024th iteration of the loop.

5 Validating CIMA

In this section, we discuss the impact on using CIMA to mitigate memory-safety at-
tacks.

Breaking program semantics The mitigation strategy of CIMA by itself is based
upon breaking semantics of the program when an invalid memory access is detected.
This is accomplished via skipping the respective memory access. In the presence of
memory-safety attacks, we believe it is extremely time and memory consuming (given
the CPS context) to roll back to a semantics preserving state. Thus, CIMA aims for a
lightweight solution (attributes to only 8% overhead in real-world CPS) that works for
most common cases and we validate CIMA with a real-world CPS. Nevertheless, there
exists semantics-preserving issues that deserve discussion. For example, in Program 3,
Line 7, variable y is dependent on the output of memory access instruction arr[i]. CIMA
always checks the validity of the memory access arr[i] whenever the access occurs. If
the access arr[i] is found to be illegal, CIMA skips it and the variable assignment, i.e.,
y = arr[i], is also skipped as a side-eÔ¨Äect. In this case, y preserves the last ‚Äúlegally‚Äù
assigned value to it. Variable y preserves its initial value if the access arr[i] is detected
as illegal at the beginning (i.e. at index i = 0) otherwise. Concretely, the assignment

14

checkiabort()illegallegaliTi..bbabortbbcheckbbcheckiabort()iTi..Tbbibbillegallegalcheckbbabortbbcheckiabort()i‚Ä¶..TbbillegallegalTi..bbcheckbbabortbbcheckiabort()i‚Ä¶..TbbillegallegalTi..bbcheckbbabortbbProgram 2: The OpenPLC vulnerability

1 //‚Äî‚Äî‚Äî‚Äî//glue generator.cpp‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì
2 #deÔ¨Åne BUFFER SIZE 1024
3 IEC UINT *int memory[BUFFER SIZE];
4 IEC UINT *int output[BUFFER SIZE];
5 .
6 .
7 //‚Äî‚Äî‚Äî‚Äî//modbus.cpp‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
8 #deÔ¨Åne MIN 16B RANGE 1024
9 #deÔ¨Åne MAX 16B RANGE 2047
10 #deÔ¨Åne MAX HOLD REGS 8192
11 IEC UINT mb holding regs[MAX HOLD REGS];
12 .
13 .
14 /* This function sets the internal OpenPLC buÔ¨Äers to */
15 /* point to valid positions on the Modbus buÔ¨Äer */
16 void mapUnusedIO() {
17

.
.
for( int i = 0; i <= MAX 16B RANGE; i++ ){

18

19

20

21

22

23

24

25

26

27

28

29

if ( i <MIN 16B RANGE ){

if ( int output[i] == NULL ){

int output[i] = &mb holding regs[i];

}

}
if ( i >= MIN 16B RANGE && i <= MAX 16B RANGE ){
if ( int memory[i - MIN 16B RANGE] == NULL ){

int memory[i] = &mb holding regs[i];

}

}

}

30
31 }

of y can be recursively deÔ¨Åned as follows:

y =

Ô£±
Ô£¥Ô£≤

Ô£¥Ô£≥

arr[i],
arr[i ‚àí 1],
y0,

if arr[i] is legal instruction
if arr[i] is illegal, i > 0
if arr[0] is illegal

(9)

where y0 is the initial value of y.

At a broader level, CIMA may encounter memory safety attacks either due to an
inherent vulnerability in the program or due to an illegal memory access caused by the
attacker (e.g. via well crafted attack inputs). For inherent program vulnerabilities, we
hypothesize that the underlying program semantics was already Ô¨Çawed and therefore,
skipping the illegal memory accesses (due to such vulnerabilities), despite aÔ¨Äecting the
program semantics, will not further impair the system functionality. For illegal memory
accesses via carefully crafted attack inputs, we hypothesize that in most common cases
the program functionality will be unaÔ¨Äected when CIMA skips such illegal memory

15

accesses. This is due to the reason that such illegal memory accesses were executed
for the sole purpose of launching memory-safety attacks and skipping them should not
aÔ¨Äect the functionality of the system.

Continuity of program execution CIMA might not ensure continuity in program
execution when a loop bound or loop counter is controlled by an attacker. Let us consider
the example shown in Program 3, Line 5, where the loop bound arr[x] is dependent on
the attacker input x. We note that the value of x determines whether the memory read
instruction arr[x] is legal or not. CIMA skips the access to arr[x] should it turns out to
be illegal. This could lead to premature abortion of the loop (e.g. if arr[x] is detected
as illegal before the loop starts).

Consider a diÔ¨Äerent scenario when the the loop counter i is incremented by arr[z]
(cf. Program 3, Line 8). Assuming z can be controlled by the attacker, arr[z] might
manifest illegal memory access. Thus, CIMA bypasses the respective memory access
and the value of i remains unchanged. This leads to an execution that never terminates.

Program 3: Attacker controlled loop bound and counter

int arr[100], i, x, y, z;
printf(‚ÄúEnter the value of x and z:‚Äù);
scanf(‚Äú%d %d‚Äù, &x, &z);
for( i=0; i <arr[x]; ){
// Do something
y = arr[i];
i += arr[z] //incrementing the loop counter

1 main() {
2

3

4

5

6

7

8

9

10
11 }

}
return 0;

The examples discussed in the preceding paragraphs may not happen in practice.
This is because providing loop bound and loop counter values via attacker controlled
memory accesses (e.g. arr[x] in Program 3) is certainly considered as a bad coding
practice. The occurrence of such corner cases could result in an undesirable outcome
(e.g. program crash) even in the absence of CIMA. In essence, avoiding such bad
coding practices will also help CIMA to maintain continuity of program execution in
the presence of memory-safety violations or attacks.

AÔ¨Äecting the system dynamics CIMA may aÔ¨Äect the overall system dynamics (or
the physical-state resiliency in the context of CPS) when it skips too many illegal mem-
ory access instructions. This is because skipping too many illegal instructions creates
a delay in program execution. This, in turn, may result in the following scenarios:

‚Äì Lack of fresh input: Skipping instructions results impeding of fresh input to the
system. For example, actuators in CPS may not receive a new control command

16

while instructions are skipped due to memory-safety violation. This, in turn, may
aÔ¨Äect the system dynamics.

‚Äì Denial-of-service (DoS) attack: When CIMA skips too many illegal instructions,
the program execution may get stuck for a long period. This may result in the
denial-of-service.

As an example, consider the case where CIMA detected the OpenPLC vulnerability
(cf. Program 2, Line 27). CIMA skipped the illegal memory write instruction (i.e.
int memory[i] = &mb holding regs[i]) 1024 times in the for loop. This creates a delay
equivalent to 1024 iterations of the loop. Let us assume Œ¥ captures the total elapsed time
to skip illegal instructions in the loop. During the period of Œ¥, the PLC is busy skipping
invalid memory accesses and does not issue a control command to the actuator. The
number of PLC scan cycles (similarly the number of control commands) missed during
this delay can be computed as Œ¥/Tc. As such, the eÔ¨Äect of Œ¥ in the CPS dynamics (or
the physical-state resiliency) is analogous to the downtime (i.e. œÑ ) of the PLC discussed
on Section 3.3. Therefore, quantifying the level of delay (Œ¥) that is tolerable to satisfy
physical-state resiliency of a typical CPS can be similarly modeled using Eq. (8) as
follows:

Œ∏ ‚â§ Axt + But‚àí1[[t, t + Œ¥]] ‚â§ œâ

(10)

To minimize the eÔ¨Äect of CIMA on system dynamics (i.e. to satisfy Eq. (10)), we

propose the following two approaches:

‚Äì Detect long skips with debugging: As discussed in Section 2.2, we make use of
CIMA both as a debugging and a runtime memory-safety tool. If the illegal mem-
ory access occurs due to an existing vulnerability in a loop, i.e., the vulnerability
is from the existing source-code of the program and not attacker injected, then
CIMA automatically detects this vulnerability while debugging the program. This
is experimentally validated by accurately detecting the vulnerabilities found on the
OpenPLC Ô¨Årmware. We also developed an informative report (supported by an
alarm) for detected and mitigated illegal memory access instructions. Therefore,
the inherent vulnerabilities in the source-code should be manually Ô¨Åxed once they
are discovered by our framework. On the other hand, as discussed on Section 5,
attackers may manipulate memory accesses in the loop bound or loop counter via
untrusted inputs. However, as discussed in the preceding sections, such vulnerabil-
ities are caused by bad coding practices and they can be solved by avoiding bad
coding practices.
For illegal memory accesses that occur outside loops (e.g. a substantial number of
illegal memory access instructions in the source-code), the skipping time is unlikely
to aÔ¨Äect the system dynamics. As evidenced by our experiments, the skipping time
of a single instruction is negligible. As such, skipping thousands of instructions is
still tolerable in the context of real-world CPS. Yet, it is unlikely to have tens of
thousands of illegal memory accesses in the absence of loops.

‚Äì Exiting loop: In certain cases, it might be possible to exit the loop when a suÔ¨É-
cient number of illegal memory accesses are detected inside it. This will reduce the
delay Œ¥. However, more involved analysis are required to identify potential loops
that can be skipped altogether as soon as a certain number of illegal memory ac-
cesses are detected within it. We plan to extend CIMA along this direction in the
future.

17

6

case Studies and Experimental Design

6.1 SWaT

SWaT [37] is a fully operational water puriÔ¨Åcation testbed for research in the design
of secure cyber-physical systems. It produces Ô¨Åve gallons/minute of doubly Ô¨Åltered
water. A detailed account of the water puriÔ¨Åcation process and some salient features
and design considerations of SWaT can be found on our prior work [8]. Concurrently,
SWaT is based on closed-source and proprietary Allen Bradely PLCs. Hence, it is not
possible to directly modify the Ô¨Årmware of these PLCs and to enforce memory-safety
solutions. To alleviate this problem in our experimental evaluation, an open platform,
named Open-SWaT, was designed.

Open-SWaT [8, 9] is a mini CPS based on open source PLCs that mimics the fea-
tures and operational behaviors of SWaT. The PLCs are designed using OpenPLC
[38] ‚Äì an open source PLC that runs on top of Linux on Raspberry PI (RPI). With
Open-SWaT, we reproduce operational proÔ¨Åles and details of SWaT. In particular, we
reproduce the main factors that have substantial eÔ¨Äect on the scan time and MSO of
PLCs such as hardware speciÔ¨Åcations of PLCs (e.g. 200MHz of CPU speed and 2MB
of user memory), a Remote Input/Output (RIO) terminal (containing 32 digital inputs
(DI), 13 analog inputs (AI) and 16 digital outputs (DO)), real-time constraints (i.e.
cycle time of PLCs), a PLC program (containing 129 instructions of several types),
communication frequencies and a full SCADA system. The main purpose of design-
ing Open-SWaT was to employ our CIMA approach on a realistic CPS. A high-level
architecture of Open-SWaT is shown in Figure 6. Due to space limitation, interested
readers are referred to a detailed account of Open-SWaT in our prior papers [8, 9].

Fig. 6: Architecture of Open-SWaT

18

6.2 SecUTS

The Secure Urban Transportation System (SecUTS) is a CPS testbed designed to re-
search on the security of a Metro SCADA system. The Metro SCADA system [39]
comprises an Integrated Supervisory Control System (ISCS) and a train signaling sys-
tem. ISCS integrates localized and centralized control and supervision of mechanical
and electrical subsystems located at remote tunnels, depots, power substations and pas-
senger stations. The entire Metro system can be remotely communicated, monitored,
and controlled from the operation control center via the communication network. On
the other hand, the signaling system facilitates communications between train-borne
and track-side controllers. It also controls track-side equipments and train position
localization. Modbus is used as a communication protocol among the devices in the
ISCS. A detailed account of the Metro SCADA can be found on [39].

The SecUTS testbed provides facilities to examine several types of cyber attacks,
such as message replay, forged message and memory-safety attacks, in the ISCS sys-
tem and enforce proper countermeasures against such attacks. However, the SecUTS
testbed is also based on closed-source proprietary Siemens PLCs, hence we cannot
directly enforce CIMA to these PLCs to detect and mitigate memory-safety attacks.
Consequently, we similarly designed Open-SecUTS testbed (by mimicking SecUTS)
using OpenPLC controller. It consists of 6 DI (emergency and control buttons) and 9
DO (tunnel and station lightings, ventilation and alarms). Subsequently, we enforced
CIMA to Open-SecUTS and evaluated its practical applicability in a Metro SCADA
system (See Section 7).

6.3 Measuring runtime overheads

To measure the scan time and and compute memory-safety overheads of the PLCs
in Open-SWaT and Open-SecUTS, a function is implemented using POSIX clocks (in
nanosecond resolution). The function measures the execution time of each operation in
the PLC scan cycle. Results will be then exported to external Ô¨Åles for further manip-
ulation, e.g., computing MSO and plotting graphs. We run 50,000 scan cycles for each
PLC operation to measure the overall performance of the PLC.

7 Evaluation

This section discusses a detailed evaluation of our CIMA approach on Open-SWaT
and Open-SecUTS. Subsequently, we discuss the experimental results to Ô¨Ågure out
whether our proposed approach is accurate enough to detect and mitigate memory-
safety violations. We also discuss the eÔ¨Éciency of our approach in the context of CPS
environment. In brief, we evaluate the proposed approach along four dimensions: 1)
Security guarantees ‚Äì detection and mitigation accuracy of ASan and CIMA, respec-
tively, 2) Performance ‚Äì tolerability of the runtime overhead of the proposed security
measure in CPS environment, 3) Resilience ‚Äì its capability to ensure system availabil-
ity and maintain physical-state resiliency in CPS even in the presence of memory-safety
attacks, and 4) its Memory usage overheads.

19

7.1 Security guarantees

To stress test the accuracy of our approach, we have evaluated CIMA against a wide-
range of memory-safety vulnerabilities. This is to explore the accuracy of mitigating
memory-safety vulnerabilities by our CIMA approach. As our CIMA approach is built
on top of ASan, it is crucial that ASan detects a wide-range of memory-safety vul-
nerabilities accurately. According to the original results published for ASan [10], it
detects memory-safety violations with high-accuracy ‚Äì without false positives for vul-
nerabilities such as (stack, heap and global) buÔ¨Äer under/overÔ¨Çows, use-after-free errors
(dangling pointers), use-after-return errors, initialization order bugs and memory leaks
. Only rare false negatives may appear for global buÔ¨Äer overÔ¨Çow and use-after-free
vulnerabilities due to some exceptions [10].

CIMA eÔ¨Äectively mitigates memory-safety violations, given that such a violation is
detected by ASan at runtime. Therefore, the mitigation accuracy of our CIMA approach
is exactly the same as the detection accuracy of ASan.

As discussed in detail on Section 4.2, we discovered two global buÔ¨Äer overÔ¨Çow
vulnerabilities in the OpenPLC Ô¨Årmware. Both these vulnerabilities were successfully
mitigated by our CIMA approach. Besides, throughout our evaluation, we did not
discover any false positives or negatives in mitigating all the memory-safety violations
detected by ASan.

Operations

Table 1: Memory-safety overheads for the Open-SWaT Testbed
Number
of cycles

CPU speed
(in MHz)

Network
devices

ASan

ASan + CIMA ( ÀÜTs)

Max
(in ¬µs)

Max
(in ¬µs)

Mean
(in ¬µs)

Original (Ts)
Mean
(in ¬µs)
59.38 788.12 118.44 1132.32 59.09 99.46 122.86 1151.35 63.48 106.9
69.09 611.82 115.88 720.36 46.79 67.72 118.97 802.18 49.88 72.2
145.01 981.09 185.37 1125.45 40.36 27.83 199.89 1213.62 54.88 37.85
273.48 2381.03 419.69 2978.13 146.21 53.46 441.72 3167.15 168.24 61.52

MSO
(in ¬µs)

MSO
(in ¬µs)

Max
(in ¬µs)

Mean
(in ¬µs)

MSO
(in %)

MSO
(in %)

Input scan
50000
Program exec. 50000
Output update 50000
Full scan time 50000

6
6
6
6

200
200
200
200

Operations

Table 2: Memory-safety overheads for the Open-SecUTS Testbed
Number
of cycles

CPU speed
(in MHz)

Network
devices

ASan

ASan + CIMA ( ÀÜTs)

Max
(in ¬µs)

Max
(in ¬µs)

Mean
(in ¬µs)

Original (Ts)
Mean
(in ¬µs)
59.84 739.94 114.88 902.01 55.04 91.98 115.07 906.09 55.23 92.3
48.56 488.38 91.36 443.61 42.8
145.47 850.62 175.59 1045.34 30.12 20.71 178.91 924.11 33.44 22.99
398.39 2506.39 144.52 56.93
253.87 2078.94 381.83 2390.96 127.96 50.4

88.14 104.41 676.19 55.85 115.01

MSO
(in ¬µs)

MSO
(in ¬µs)

Mean
(in ¬µs)

Max
(in ¬µs)

MSO
(in %)

MSO
(in %)

Input scan
50000
Program exec. 50000
Output update 50000
Full scan time 50000

1
1
1
1

200
200
200
200

7.2 Performance

According to the original article published for ASan [10], the average MSO of ASan
is 73%. However, all measurements were taken on benchmarks diÔ¨Äerent from ours and
more importantly, in a non-CPS environment. With our CPS environment integrated in

20

the Open-SWaT and Open-SecUTS, the average overhead induced by ASan is 53.46%
and 50.4%, respectively. Additionally, our proposed CIMA approach induces 8.06%
and 6.53% runtime overheads on Open-SWaT and Open-SecUTS, respectively. Thus,
the overall runtime overhead of our security measure is 61.52% (for Open-SWaT) and
56.93% (for Open-SecUTS). A more detailed performance report, including the perfor-
mance overhead of each PLC operation in both testbeds, is illustrated on Table 1 and
2.

It is crucial to check whether the induced overhead by ASan and CIMA ( ÀÜTs) is
tolerable in a CPS environment. To this end, we evaluate if this overhead respects the
real-time constraints of SWaT and SecUTS. For instance, consider the tolerability in
average-case scenario. We observe that our proposed approach satisÔ¨Åes the condition of
tolerability, as deÔ¨Åned in Eq. (2). In particular, from Table 1, mean( ÀÜTs) = 441.72¬µs, and
Tc = 10ms; and from Table 2, mean( ÀÜTs) = 398.39¬µs, and Tc = 150ms. Consequently,
Eq. (2) is satisÔ¨Åed and the overhead induced by our CIMA approach is both tolerable
in SWaT and SecUTS.

Similarly, considering the worst-case scenario, we evaluate if Eq. (3) is satisÔ¨Åed.
From Table 1, max( ÀÜTs) = 3167.15¬µs, and Tc = 10ms; and from Table 2, max( ÀÜTs) =
2506.39¬µs, and Tc = 150ms. It is still tolerable, thus the proposed security measure
satisÔ¨Åes SWaT‚Äôs and SecUTS‚Äôs real-time constraints in both scenarios. Therefore, de-
spite high security guarantees provided by CIMA, its overhead is still tolerable in a
CPS environment.

CIMA and ASan together induce a runtime overhead of 61.52% in
Open-SWaT and 56.93% in Open-SecUTS, whereas the overhead due
to CIMA is only 8.06% and 6.53%, respectively. Despite this over-
head, our proposed approach meets the hard real-time constraints for
SWaT and SecUTS both in the average- and worst-case scenarios.

Table 3: Memory usage overheads for the Open-SWaT Testbed

Category Original

ASan

ASan+CIMA

Original Overhead Original Overhead

Virtual
Memory 62.97MB 549.38MB 8.72√ó 557.5MB 8.85√ó

Real

Memory 8.17MB 10.31MB 1.26√ó 11.2MB 1.37√ó
Binary
2.25√ó
Shared
library

1.34√ó 4288KB 1.34√ó

3196KB 4288KB

324KB

316KB

144KB

2.19√ó

21

Table 4: Memory usage overheads for the Open-SecUTS Testbed

Category Original

ASan

ASan+CIMA

Original Overhead Original Overhead

Virtual
Memory 56.37MB 489.29MB 8.68√ó 490.6MB 8.70√ó

Real

Memory 8.76MB 9.81MB
Binary
288KB
136KB
Shared
library

3196KB 4288KB

1.12√ó 10.21MB 1.17√ó
2.18√ó
296KB
2.12√ó

1.34√ó 4288KB 1.34√ó

7.3 Resilience

One of the main contributions of our work is to empirically show the resilience of our
CIMA approach against memory-safety attacks. Here, we evaluate how our mitigation
strategy ensures availability and physical-state resiliency of a real-world CPS. As dis-
cussed in the preceding sections, CIMA does not render system unavailability. This is
because it does not abort or restart the PLC when mitigating memory-safety attacks.
In such a fashion, the availability of PLCs is ensured by our approach. As discussed
in Section 3.3, physical-state resiliency of a CPS can be aÔ¨Äected by the memory-safety
overhead (when the overhead is not tolerable due to the real-time constraint of the
PLC) or the downtime of the PLC (when the PLC is unavailable for some reason).

In the preceding section, we show that our CIMA approach ensures the memory-
safety overhead to be tolerable. Hence, the additional overhead induced by CIMA does
not aÔ¨Äect the physical-state resiliency. Added to the fact is that the availability of
SWaT and SecUTS is also ensured by CIMA via its very construction, as CIMA never
aborts the system or leads to PLC downtime. Given that our proposed solution ensures
availability of the PLC and also maintains the physical-state resiliency, we ensure the
resilience of SWaT even in the presence of memory-safety attacks.

CIMA ensures physical-state resiliency of SWaT and SecUTS, as ÀÜTs ‚â§
Tc (cf. Eq. (4) and Eq. (8)) holds in all of our experiments. This makes
CIMA to be a security solution that ensures the SWaT and SecUTS
systems to remain resilient even in the presence of memory-safety
attacks.

7.4 Memory usage overheads

Finally, we evaluated the memory usage overheads of our CIMA approach. Tables 3
and 4 summarize the increased virtual memory usage, real memory usage, binary size
and shared library usage for the Open-SWaT and Open-SecUTS testbeds, respectively.
The reported statistics are collected by reading VmPeak, VmRSS, VmExe and VmLib Ô¨Åelds,
respectively, from /proc/self/status. In general, we observe a signiÔ¨Åcant increase in
virtual memory usages (8.85√ó for Open-SWaT and 8.70√ó for Open-SecUTS). This is

22

primarily because of the allocation of large redzones with malloc (as part of the ASan
approach). However, the real memory usage overhead is only 1.37√ó (for Open-SWaT)
and 1.17√ó for Open-SecUTS. We believe these overheads are still acceptable since
most PLCs nowadays come with at least 1GB memory size. Moreover, the increased
memory size is an acceptable trade-oÔ¨Ä in the light of strong mitigation mechanics
provided by our CIMA approach. Finally, we observe that CIMA introduces negligible
memory usage overhead over ASan, meaning the majority of memory-usage overhead
is attributed to the usage of ASan.

8 Related work

CIMA is built on top of ASan. ASan [10] is a fast memory-safety tool based on code-
instrumentation. It covers a wide range of temporal memory errors, such as use-after-
free, use-after-return and memory leaks, and spatial memory errors such as stack,
heap and global buÔ¨Äer overÔ¨Çows. It is also a standard tool included in the GCC and
LLVM compiler infrastructures as a memory-safety checker. However, its mitigation
approach (in normal mode) is to simply abort the program whenever a memory-safety
violation is detected. This is not acceptable in most critical systems, such as CPS
and ICS, with stringent time constraints. In such systems, availability is of the utmost
importance. This makes ASan to be impractical for critical systems with hard real-time
constraints. ASan does also provide a special mode to continue execution even after
detecting a memory-safety error. However, this mode does not provide any protection
against memory-safety attacks.

Softbound [16] and its extension CETS [17] guarantee a complete memory-safety.
However, such guarantees arrive with the cost of a very high runtime overhead (116%).
Such a high performance overhead is unlikely to be tolerable due to the real-time con-
straints imposed on a typical CPS. Moreover, Softbound and CETS do not implement
a mitigation strategy to consider the physical-state resiliency in a CPS environment.

SafeDispatch [11] is a fast memory-safety tool developed within the LLVM infras-
tructure. SafeDispatch also involves exhaustive performance optimizations to make the
overhead just 2.1%. However, SafeDispatch is not supported by an appropriate miti-
gation strategy that guarantees system availability in the presence of memory-safety
attacks. Thus, its applicability to the CPS environment is limited.

Sting [22, 23] is an end-to-end self-healing architecture developed against memory-
safety attacks. It detects attacks with address space layout randomization (ASLR) and
system-call-based anomaly detection techniques. However, ASLR can be defeated by
code-reuse attacks and system-call-based detections (e.g. control-Ô¨Çow integrity) can be
bypassed by data injection attacks. To diagnosis the root cause of the attack, Sting
leverages a heavy-weight static taint analysis. Furthermore, it performs periodic check-
pointing and continuously records system calls to resume the victim program from an
earlier safe state. These techniques bring signiÔ¨Åcant performance and memory usage
overhead. As reported [22], there are cases where the corrupted program cannot be
recovered and requires to be restarted. Therefore, the performance and memory usage
overheads and the system unavailability problems limit the applicability of Sting to a
CPS environment.

ROPocop [12] is a dynamic binary code instrumentation framework against code
injection and code reuse attacks. It relies on Windows x86 binaries to detect such

23

attacks. Its runtime overhead is 240%, which is signiÔ¨Åcantly high and is unlikely be
tolerable due to the real-time constraints in CPS. Moreover, it is unclear what kind of
mitigation strategies were incorporated with ROPocop.

Over the past decades, a number of control-Ô¨Çow integrity (CFI) based solutions
(e.g., [13, 14, 15, 40]) have been developed to defend against memory-safety attacks.
The main objective behind these solutions is ensuring the control-Ô¨Çow integrity of a
program. Therefore, they aim to prevent attacks from redirecting the Ô¨Çow of program
execution. These solutions also oÔ¨Äer a slight performance advantage over other counter-
measures, such as code-instrumentation based countermeasures. However, CFI-based
solutions generally have the following limitations: (i) determining the required control-
Ô¨Çow graph (often using static analysis) is diÔ¨Écult and requires a substantial amount
of memory; (ii) attacks that are not diverting the control-Ô¨Çow of the program cannot
be detected (e.g. data oriented attacks [41]); (iii) Ô¨Ånally, these solutions are mainly
to detect memory-safety attacks, but do not implement mitigation strategies against
the attacks. Consequently, the applicability of CFI-based solutions is limited in a CPS
environment.

In summary, to the best of our knowledge, there is no prior work that eÔ¨Éciently
detects and mitigates memory-safety attacks without compromising the real-time con-
straints or availability of the underlying system. Moreover, we are not aware of any
work that designs and evaluates memory-safety attack mitigation techniques in the
light of real-time constraints and physical-state resiliency imposed on critical systems.
In this paper, CIMA bridges this gap of research.

9 Threats to validity

The eÔ¨Äectiveness of CIMA critically depends on the following:

1. Uncovered memory-safety errors: ASan does not cover some memory-safety
errors such as uninitialized memory reads and some use-after-return bugs. Thus,
CIMA does not also mitigate these errors. However, these errors are less critical
and unlikely to be exploited in practice. Moreover, the central idea behind CIMA
is unaÔ¨Äected by such limitation. SpeciÔ¨Åcally, CIMA leverages ASan as an oÔ¨Ä-the-
shelf capability to detect the memory-safety errors. Any improvement on memory-
safety attack detection tool will also automatically improve the coverage of attacks
mitigated via CIMA.

2. Experimental limitations: We conducted our experiments only on a water treat-
ment and Metro SCADA systems. Nevertheless, our proposed approach is generic
and it can be applied on diÔ¨Äerent CPSs with various real-time constraints. In the
future, we intend to conduct further experiments on power grid and robotics sys-
tems.

3. Limitations due to proprietary PLC code: SWaT and SecUTS are realistic
CPS testbeds containing a set of real-world vendor-supplied PLCs. However, their
PLCs are proprietary and closed-source. Hence, we were unable to incorporate
our security solution directly to these PLCs. Instead, we designed our testbeds (i.e.
Open-SWaT and Open-SecUTS) by mimicking all operational details of SWaT and
SecUTS, respectively. While designing the testbeds, we have paid careful attention
to all design features and constraints imposed on SWaT and SecUTS, especially

24

timing-related constraints. Hence, we can provide high conÔ¨Ådence on our results
obtained from Open-SWaT and Open-SecUTS to be applicable also to the real
SWaT and SecUTS systems.

10 Conclusion

In this paper, we propose CIMA, a resilient mitigation strategy to ensure protection
against a wide variety of memory-safety attacks. The main advantage of CIMA is
that it mitigates memory-safety attacks in a time-critical environment and ensures
the system availability by skipping only the instructions that exhibit illegal memory
accesses. Such an advantage makes CIMA to be an attractive choice of security measure
for cyber-physical systems and critical infrastructures, which often impose strict timing
constraints. To this end, we evaluate our approach on a real-world CPS testbed. Our
evaluation reveals that CIMA mitigates memory-safety errors with acceptable runtime
and memory-usage overheads. Moreover, it ensures that the resiliency of the physical
states are maintained despite the presence of memory-safety attacks. Although we
evaluated our approach only in the context of CPS, CIMA is also applicable and useful
for any system under the threat of memory-safety attacks.

From conceptual point of view, CIMA provides a fresh outlook over mitigating
memory-safety attacks. In future, we plan to build upon our approach to understand
the value of CIMA across a variety of systems beyond CPS. We also plan to leverage
our CIMA approach for live patching. In particular, at its current state, CIMA does
not automatically Ô¨Åx the memory-safety vulnerabilities of the victim code (although
CIMA does ensure that the vulnerabilities are not exploited at runtime). Instead, it
generates a report for the developer to help produce a patched version of the code. In
future, we will use the report generated by CIMA to automatically identify the pattern
of illegal memory accesses and Ô¨Åx the code accordingly.

References

1. Szekeres, L., Payer, M., Wei, T., Song, D.: Sok: Eternal war in memory. 2013 IEEE

Symposium on Security and Privacy (2013)

2. Saito, T., Watanabe, R., Kondo, S., Sugawara, S., Yokoyama, M.: A survey of preven-
tion/mitigation against memory corruption attacks. 2016 19th International Conference
on Network-Based Information Systems (NBiS) (2016)

3. Younan, Y., Joosen, W., Piessens, F.: Code injection in c and c++ : A survey of vulner-

abilities and countermeasures. Technical report (2004)

4. Francillon, A., Castelluccia, C.: Code injection attacks on harvard-architecture devices.
In: Proceedings of the 15th ACM Conference on Computer and Communications Security
(CCS‚Äô08). (2008)

5. Snow, K.Z., Monrose, F., Davi, L., Dmitrienko, A., Liebchen, C., Sadeghi, A.: Just-in-
time code reuse: On the eÔ¨Äectiveness of Ô¨Åne-grained address space layout randomization.
In: Proceedings of the IEEE Symposium on Security and Privacy (SP‚Äô13), Washington,
USA (2013)

6. Dahse, J., Krein, N., Holz, T.: Code reuse attacks in php: Automated pop chain genera-
tion. In: Proceedings of the ACM SIGSAC Conference on Computer and Communications
Security (CCS‚Äô14). (2014)

25

7. Bittau, A., Belay, A., Mashtizadeh, A., Mazi¬¥eres, D., Boneh, D.: Hacking blind.

In:
Proceedings of the 2014 IEEE Symposium on Security and Privacy. SP‚Äô14 (2014) 227 ‚Äì
242

8. Chekole, E.G., Castellanos, J.H., Ochoa, M., Yau, D.K.Y.: Enforcing memory safety in
cyber-physical systems. In: Katsikas S. et al. (eds) Computer Security. SECPRE 2017,
CyberICPS 2017

9. Chekole, E.G., Chattopadhyay, S., Ochoa, M., Huaqun, G.: Enforcing full-stack memory
safety in cyber-physical systems.
In: Proceedings of the International Symposium on
Engineering Secure Software and Systems (ESSoS‚Äô18), Springer International Publishing
(2018)

10. Serebryany, K., Bruening, D., Potapenko, A., Vyukov, D.: Addresssanitizer: a fast address
sanity checker. In: Proceedings of the USENIX conference on Annual Technical Conference
(USENIX ATC‚Äô12). (2012)

11. Jang, D., Tatlock, Z., Lerner, S.: Safedispatch: Securing c virtual calls from memory cor-
ruption attacks. Proceedings 2014 Network and Distributed System Security Symposium
(2014)

12. Follner, A., Bodden, E.: Ropocop ‚Äî dynamic mitigation of code-reuse attacks. Journal

of Information Security and Applications (2016)

13. Zhang, M., Sekar, R.: Control Ô¨Çow integrity for cots binaries.

In: Proceedings of the

USENIX Security Symposium (USENIX‚Äô13). (2013)

14. Tice, C., Roeder, T., Collingbourne, P., Checkoway, S., Erlingsson, ¬¥U., Lozano, L., Pike,
G.: Enforcing forward-edge control-Ô¨Çow integrity in gcc & llvm. In: Proceedings of the
23rd USENIX Security Symposium. USENIX‚Äô14 (2014) 941‚Äì955

15. Ge, X., Talele, N., Payer, M., Jaeger, T.: Fine-grained control-Ô¨Çow integrity for kernel

software. In: 2016 IEEE European Symposium on Security and Privacy. (2016)

16. Nagarakatte, S., Zhao, J., Martin, M.M., Zdancewic, S.: Softbound: Highly compatible
and complete spatial memory safety for C. In: Proceedings of the 2009 ACM SIGPLAN
conference on Programming language design and implementation. PLDI‚Äô09 (2009)

17. Nagarakatte, S., Zhao, J., Martin, M.M., Zdancewic, S.: Cets: Compiler enforced tem-
In: Proceedings of the 2010 International Symposium on Memory

poral safety for C.
Management (ISMM‚Äô10). (2010)

18. Simpson, M.S., Barua, R.K.: Memsafe: Ensuring the spatial and temporal memory safety

of c at runtime. Software: Practice and Experience 43(1) (2013) 93‚Äì128

19. Bruening, D., Zhao, Q.: Practical memory checking with dr. memory. In: Proceedings
of the 9th Annual IEEE/ACM International Symposium on Code Generation and Opti-
mization. CGO‚Äô11

20. Necula, G.C., Condit, J., Harren, M., McPeak, S., Weimer, W.: Ccured: Type-safe

retroÔ¨Åtting of legacy software. ACM Trans. Program. Lang. Syst. 27(3) (2005)

21. F. Ch. Eigler: MudÔ¨Çap: pointer use checking for C/C++. In: GCC Developer‚Äôs Summit,

Red Hat Inc. (2003)

22. Newsome, J., Brumley, D., Song, D.: Sting: An end-to-end self-healing system for defend-

ing against zero-day worm attacks on commodity software (2005)

23. Newsome, J., Brumley, D., Song, D.: Vulnerability-speciÔ¨Åc execution Ô¨Åltering for exploit
prevention on commodity software. In: Proceedings of the 13th Symposium on Network
and Distributed System Security (NDSS‚Äô05). (2005)

24. Brumley, D., Newsome, J., Song, D., Wang, H., Jha, S.: Towards automatic generation
of vulnerability-based signatures. In: Proceedings of IEEE Symposium on Security and
Privacy (SP‚Äô06), DC, USA (2006)

25. Smirnov, A., Chiueh, T.: Automatic patch generation for buÔ¨Äer overÔ¨Çow attacks. Third

International Symposium on Information Assurance and Security (2007)

26. CVE-2016-5814. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-5814

(2016)

26

27. CVE-2012-6438. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-6438

(2012)

28. CVE-2012-6436. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-6436

(2012)

29. CVE-2013-0674. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-0674

(2013)

30. CVE-2015-1449. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-1449

(2015)

31. CVE-2012-0929. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-0929

(2012)

32. CVE-2015-7937. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-7937

(2015)

33. CVE-2011-5007. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-5007

(2011)
34. github

repository, A.:

tools.
memory
AddressSanitizerComparisonOfMemoryTools (2015)

safety

Comparison

other
addresssanitizer
https://github.com/google/sanitizers/wiki/

with

of

35. Schuster, F., Tendyck, T., Liebchen, C., Davi, L., Sadeghi, A.R., Holz, T.: Counter-
feit object-oriented programming: On the diÔ¨Éculty of preventing code reuse attacks in c
applications. 2015 IEEE Symposium on Security and Privacy (2015)

36. GCC: Gcc basic blocks. https://gcc.gnu.org/onlinedocs/gccint/Basic-Blocks.html

(2018)

37. SWaT: Secure water treatment (swat) testbed (2018)
38. OpenPLC: Openplc. http://www.openplcproject.com/ (2018)
39. Zhou, L., Guo, H., Li, D., Wong, J.W., Zhou, J.: Mind the gap: Security analysis of metro
platform screen door system. In: Proceedings of the Singapore Cyber-Security RandD
Conference (SG-CRC‚Äô17). (2017)

40. Niu, B., Tan, G.: Rockjit: Securing just-in-time compilation using modular control-Ô¨Çow
integrity. In: Proceedings of the ACM SIGSAC Conference on Computer and Communi-
cations Security (CCS‚Äô14). (2014)

41. Hu, H., Shinde, S., Adrian, S., Chua, Z.L., Saxena, P., Liang, Z.: Data-oriented pro-
gramming: On the expressiveness of non-control data attacks. 2016 IEEE Symposium on
Security and Privacy (2016)

27

