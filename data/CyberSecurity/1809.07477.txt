9
1
0
2

p
e
S
9
1

]

R
C
.
s
c
[

2
v
7
7
4
7
0
.
9
0
8
1
:
v
i
X
r
a

Taming the War in Memory: A Resilient Mitigation
Strategy Against Memory Safety Attacks in CPS

Eyasu Getahun Chekole1,2, Unnikrishnan Cheramangalath1, Sudipta
Chattopadhyay1, Mart´ın Ochoa1,3, and Guo Huaqun2

1 Singapore University of Technology and Design, Singapore, Singapore
2 Institute for Infocomm Research (I2R), Singapore, Singapore
3 Department of Applied Mathematics and Computer Science, Universidad del Rosario,
Bogot´a, Colombia

Abstract. Memory-safety attacks have been one of the most critical threats
against computing systems. Although a wide-range of defense techniques have
been developed against these attacks, the existing mitigation strategies have sev-
eral limitations. In particular, most of the existing mitigation approaches are
based on aborting or restarting the victim program when a memory-safety at-
tack is detected, thus making the system unavailable. This might not be accept-
able in systems with stringent timing constraints, such as cyber-physical systems
(CPS), since the system unavailability leaves the control system in an unsafe
state. To address this problem, we propose CIMA – a resilient and light-weight
mitigation technique that prevents invalid memory accesses at runtime. CIMA
manipulates the compiler-generated control-ﬂow graph to automatically detect
and bypass unsafe memory accesses at runtime, thereby mitigating memory-
safety attacks along the process. An appealing feature of CIMA is that it also
ensures system availability and resilience of the CPS even under the presence
of memory-safety attacks. To this end, we design our experimental setup based
on a realistic Secure Water Treatment (SWaT) and Secure Urban Transporta-
tion System (SecUTS) testbeds and evaluate the eﬀectiveness and the eﬃciency
of our approach. The experimental results reveal that CIMA handles memory-
safety attacks eﬀectively with low overhead. Moreover, it meets the real-time
constraints and physical-state resiliency of the CPS under test.

1

Introduction

Software systems with stringent real-time constraints are often written in C/C++ since
they aid in generating eﬃcient program binaries. However, since memory management
is handled manually and also the lack of bounds checking in C/C++, programs writ-
ten in such languages often suﬀer from memory-safety vulnerabilities, such as buﬀer
over/underﬂows, dangling pointers, double-free errors and memory leaks. Due to the
diﬃculty in discovering these vulnerabilities, they might often slip into production run.
This leads to memory corruptions and runtime crashes even in deployed systems. In the
worst case, memory-safety vulnerabilities can be exploited by a class of cyber attacks,
which we refer to as memory-safety attacks [1, 2]. Memory-safety attacks, such as code
injection [3, 4] and code reuse [5, 6, 7], can cause devastating eﬀects by compromising
vulnerable programs in any computing system. These attacks can hijack or subvert

1

 
 
 
 
 
 
speciﬁc operations of a system or take over the entire system, in general. A detailed
account of such attacks is provided in existing works [7, 8, 9].

Given a system vulnerable to memory-safety attacks, its runtime behavior will de-
pend on the type of memory accesses being made, among others. For instance, accesses
to an array element beyond the imposed length of the array (buﬀer overﬂows) could be
exploited to overwrite the return address of a function. However, a safety check gen-
erated at compile time [10] can be added before any memory access to ensure validity
of the memory going to be accessed. This can be accomplished via compiler-assisted
program analysis. Traditionally, such memory-safe compilers will generate an exception
and abort when such violations are found at run-time.

However, we make the observation that one could also react to such violations
by bypassing the illegal instructions, i.e., instructions that attempt to access memory
illegally, and thus favoring availability of the system. This is the main intuition upon
which our CIMA approach is based upon. In particular, CIMA is a resilient mitigation
strategy that eﬀectively and eﬃciently prevents memory-safety attacks and guarantees
system availability with minimal overhead (8.06%).

To realize the aforementioned intuition behind CIMA, we face several technical
challenges. Firstly, it is infeasible (in general) to statically compute the exact set of
illegal memory accesses in a program. Consequently, a fully static approach, which
modiﬁes the program to eliminate the illegal instructions from the program, is unlikely
to be eﬀective. Moreover, such an approach will inevitably face scalability bottlenecks
due to its heavy reliance on sophisticated program analysis. Secondly, even if the illegal
instructions are identiﬁed during execution, it is challenging to bypass the manifestation
of illegal memory access. This is because, such a strategy demands full control to
manipulate the normal ﬂow of program execution. Finally, to bypass the execution of
certain instructions, we need modiﬁcations to the control ﬂow of the program. From a
technical perspective, such modiﬁcations involve the manipulation of program control
ﬂow over multitudes of passes in mainstream compilers.

To alleviate the technical challenges, CIMA systematically combines compile-time
instrumentation and runtime monitoring to defend against memory-safety attacks.
Speciﬁcally, at compile time, each instrumented memory access is guarded via a con-
ditional check to detect its validity at runtime. In the event where the conditional
check fails, CIMA skips the respective memory access at runtime. To implement such
a twisted ﬂow of control, CIMA automatically transforms the program control ﬂow
logic within mainstream compilers. This makes CIMA a proactive mitigation strategy
against a large class of memory-safety attacks.

It is the novel mitigation strategy that sets our CIMA approach apart from the ex-
isting works [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]. Most of the existing mitigation
schemes against memory-safety attacks are primarily programmed to abort or restart
the victim system when an attack or a memory-safety violation is detected. Other
schemes, such as self-healing [22, 23, 24] or live patching [25], are based on directly
detecting exploitations or attacks and resuming the corrupted system from a previous
safe state. CIMA never aborts the system and avoids the heavy overhead of maintaining
system states for checkpoints. On the contrary, CIMA follows a fundamentally diﬀerent
approach, i.e., to continue execution by skipping only the illegal instructions.

Although our proposed security solution is applicable to any computing system
that involves C/C++ programs, we mainly focus on the CPS domain. This is because,

2

unlike the mainstream systems, CPS often imposes conﬂicting design constraints in-
volving real-time guarantees, physical-state resiliency involving its physical dynam-
ics and security. In CPS, the memory-safety vulnerabilities might be found in the
ﬁrmware (or sometimes in the control software) of PLCs. Such ﬁrmware is commonly
implemented in C/C++ for the sake of eﬃciency. Consequently, it is not uncom-
mon to have buﬀer over/underﬂows and dangling pointers being regularly discovered
even in modern PLCs. In fact, recent trends in Common Vulnerabilities and Expo-
sures (CVEs) show the high volume of interest in exploiting these vulnerabilities in
PLCs [26, 27, 28, 29, 30, 31, 32, 33]. This shows that the mitigation of memory-safety
attacks in CPS should not merely be restricted to academic research. Instead, it is
a domain that requires urgent and practical security solutions to protect a variety of
critical infrastructures at hand. Nonetheless, attacks that manipulate sensor and ac-
tuator values in CPS (either directly on sensor/actuator devices or on communication
channels) are orthogonal issues that are out of our scope.

In summary, our work tackles the problem of ensuring critical systems and services
to remain available and eﬀective while successfully mitigating a wide-range of memory-
safety attacks. We make the following technical contributions:

1. We eﬀectively prevent system crashes that could be arisen due to memory-safety

violations.

2. We eﬀectively and eﬃciently prevent memory-safety attacks in any computing sys-

tem.

3. We deﬁne the notion of physical-state resiliency that is crucial for CPS and should

be met alongside strong security guarantees.

4. Our mitigation solution ensures physical-state resiliency and system availability
with reasonable runtime and storage overheads. Thus, it is practically applicable
to systems with stringent timing constraints, such as CPS.

5. We evaluate the eﬀectiveness and eﬃciency of our approach on two real-world CPS

testbeds.

2 Background

In this section, we introduce the necessary background in the context of our CIMA
approach.

2.1 CPS

CPS constitutes of complex interactions between entities in the physical space and the
cyber space over communication networks. Unlike traditional IT systems, such complex
interactions are accomplished via communication with the physical world via sensors
and with the digital world via controllers (PLCs) and other embedded devices. CPS
usually impose hard real-time constraints. If such real-time constraints are not met,
then the underlying system might run into an unstable and unsafe state. Moreover,
the devices in a typical CPS are also resource constrained. For example, PLCs and
I/O devices have limited memory and computational power. In general, a typical CPS
consists of the following entities:

3

– Physical plants: Physical systems where the actual processes take place.
– Sensors: Devices that are capable of reading or observing information from plants

or physical processes.

– PLCs: Controller devices that receive sensor inputs, make decisions and issue con-

trol commands to actuators.

– Actuators: Physical entities that are capable of implementing the control com-

mands issued by the PLCs.

– Communication networks: The communication medium through which packets
containing sensor inputs, control commands, diagnostic information and alarms
transmit from one CPS entity to another.

– SCADA: A software entity designed for monitoring and controlling diﬀerent pro-
cesses in a CPS. It often comprises a human-machine interface (HMI) and a his-
torian server. The HMI is used to display state information of plants and physical
processes in the CPS. The historian server is used to store all operational data and
the history of alarms.

An abstraction of a typical CPS architecture is shown in Figure 2. In Figure 2,
x denotes the physical state of the plant, y captures the sensor measurements and u
denotes the control command computed by the PLC at any given point of time.

2.2 ASan

Despite the presence of several memory error detector tools, their applicability in CPS
is limited due to several reasons. This includes the lack of error coverage, signiﬁcant
performance overhead and other technical compatibility issues. After researching and
experimenting on various memory-safety tools, we chose ASan [10] as our memory
error detector tool. Our choice is motivated by its broad error coverage, high detec-
tion accuracy and relatively low runtime overhead when compared with other code-
instrumentation based tools [10, 34].

ASan is a compile-time memory-safety tool based on code instrumentation. It in-
struments C/C++ programs at compile time. The instrumented program will then
contain additional ASan libraries, which are checked to detect possible memory-safety
violation at runtime. Such an instrumented code can detect buﬀer over/underﬂows, use-
after-free errors (dangling pointers), use-after-return errors, initialization order bugs
and memory leaks.

Since ASan was primarily designed for x86 architectures, it has compatibility issues
with RISC-based ARM or AVR based architectures. Therefore, we adapted ASan for
ARM-based architecture in our system.
Limitations of ASan: Although ASan covers a wide range of memory errors, it
does not cover some memory-safety errors such as uninitialized memory reads and
some use-after-return bugs. In fact, such errors are less critical and rarely exploited
in practice. ASan also has minor limitation in detection accuracy. Although it oﬀers
high detection accuracy for most memory-safety vulnerabilities, there are rare false
negatives for global buﬀer overﬂow and use-after-free vulnerabilities. This might allow
memory-safety attacks to bypass the checks enforced by ASan with low probability. The
other major limitation of ASan is its ineﬀective mitigation strategy; it simply aborts
the system whenever a memory-safety violation or an attack is detected. This makes
ASan inapplicable in systems with stringent availability constraints.

4

ASan as a debugging and monitoring tool: Because of the limitations, as men-
tioned in the preceding paragraph, ASan is often considered as rather a debugging
tool than a runtime monitoring tool. However, using ASan only as a debugging tool
does not guarantee memory-safety. Because, most memory-safety vulnerabilities (e.g.
buﬀer overﬂows) can be probed by systematically crafted inputs by attackers who aim
to exploit it. Since carefully tailored inputs might not be used during debugging, ASan
might miss important memory bugs that can be exploited by an attacker at runtime.
Therefore, only debugging the program does not oﬀer suﬃcient guarantee in detecting
critical memory-safety vulnerabilities.

In our CIMA approach, we adopt ASan for the dual purpose of debugging and run-
time monitoring, with the speciﬁc focus on mitigating memory-safety vulnerabilities.
As a runtime monitoring tool, CIMA leverages on ASan to detect attacker injected
memory-safety bugs. Moreover, CIMA enhances the capability of ASan to mitigate
memory-safety bugs on-the-ﬂy. This is to ensure the availability of the underlying sys-
tem and in stark contrast to plain system abort.

3 Attacker and system models

In this section, we ﬁrst discuss the attacker model. Then, we discuss the diﬀerent traits
of formally modeling our system and the related design constraints.

3.1 Attacker model

The main objective of memory-safety attacks, like code injection and code reuse, is to
get privileged access or take control (otherwise to hijack/subvert speciﬁc operations)
of the vulnerable system. To achieve this, vulnerabilities such as buﬀer overﬂows and
dangling pointers of a program are targeted. For example, to exploit a buﬀer overﬂow,
the attacker sends carefully crafted input to the buﬀer. When the buﬀer overﬂows, the
attacker can manipulate important memory addresses, like return address of a function,
and divert control ﬂow of the program. A detailed account of such exploitations can be
found in [7, 35]. In general, a typical memory-safety attack follows the following steps
(See Figure 1):

1. Interacting with the victim PLC, e.g., via network connection (for remote attacks).
2. Finding a memory-safety vulnerability (e.g., buﬀer overﬂow, dangling pointers) in

the PLC ﬁrmware or control software with the objective of exploiting it.
3. Triggering a memory-safety violation on the PLC, e.g., overﬂowing a buﬀer.
4. Overwriting critical addresses of the vulnerable program, e.g., overwriting return

address of the PLC program.

5. Using the modiﬁed address, divert control ﬂow of the program to an injected (ma-
licious) code (i.e. code injection attacks) or to an existing module of the vulnerable
program (i.e. code reuse attacks). In the former case, the attacker can take over the
PLC with the injected malicious code. In the latter case, the attacker still needs to
collect appropriate gadgets from the program (basically by scanning the program’s
text segment), then she will synthesize a shellcode that will allow her to take over
the PLC.

5

Fig. 1: Overview of memory-safety attack exploitations

3.2 Modeling CPS timing constraints

Most cyber-physical systems are highly time-critical. The communication between its
diﬀerent components, such as sensors, controllers (PLCs) and actuators, is synchronized
by system time. Therefore, delay in these CPS nodes could result in disruption of
the control system or damage the physical plant. In particular, PLCs form the main
control devices and computing nodes of a typical CPS. As such, PLCs often impose
hard real-time constraints to maintain the stability of the control system in a CPS. In
the following section, we deﬁne and discuss the notion of real-time constraints imposed
on a typical CPS.

Modeling real-time constraints In general, PLCs undergo a cyclic process called
scan cycle. This involves three major operations: input scan, PLC program (logic)
execution and output update. The time it takes to complete these operations is called
scan time (Ts). A typical CPS deﬁnes and sets an upper-bound on time taken by PLC
scan cycle, called cycle time (Tc). This means the scan cycle must be completed within
the duration of the cycle time speciﬁed, i.e., Ts ≤ Tc. We refer this constraint as a real-
time constraint of the PLC. By design, PLCs meet this constraint. However, due to
additional overheads, such as memory-safety overheads (MSO), PLCs might not satisfy
its real-time constraint. As discussed above, by hardening the PLC with our memory-
safety protection (detection + mitigation), the scan time increases. This increase in
the scan time is attributed to the MSO. Concretely, the memory-safety overhead is
computed as follows:

MSO = ˆTs − Ts,

(1)

6

where ˆTs and Ts are scan time with and without memory-safe compilation, respectively.
A detailed account of modeling Ts is provided in our earlier works [8, 9].

It is crucial to check whether the induced MSO by the memory-safe compilation still
satisﬁes the real-time constraint imposed by the PLC. To this end, we compute MSO
for – 1) average-case and 2) worst-case scenarios. In particular, after enabling memory-
safe compilation, we compute the scan time (i.e. ˆTs) for n diﬀerent measurements and
compute the respective average and worst-case scan time. Formally, we say that the
MSO is acceptable in average-case if the following condition is satisﬁed:

(cid:80)n

ˆTs(i)
i=1
n

≤ Tc

(2)

In a similar fashion, MSO is acceptable in the worst-case with the following condition:

n
max
i=1

ˆTs(i) ≤ Tc

(3)

where ˆTs(i) captures the scan time for the i-th measurement after the memory-safe
compilation.

3.3 Physical-state resiliency

The stability of CPS controllers (i.e. PLCs in our case) plays a crucial role in enforcing
the dynamics of a cyber-physical system to be compliant with its requirement. For
example, assume that a PLC issues control commands every Tc cycle and an actuator
receives these commands at the same rate. Therefore, cycle time of the PLC is Tc. If the
PLC is down for an arbitrary amount of time say τ , then the actuator will not receive
fresh control commands for the duration τ . Consequently, the physical dynamics of the
respective CPS will be aﬀected for a total of τ
Tc

scan cycles.

We note that the duration τ might be arbitrarily large. Existing solutions [10],
albeit in a non-CPS environment, typically revert to aborting the underlying process
or restart the entire system when a memory-safety attack is detected. Due to the critical
importance of availability constraints in CPS, our CIMA approach never aborts the
underlying system. Nevertheless, CIMA induces an overhead to the scan time of the
PLC, as discussed in the preceding section. Consequently, the scan time of PLCs, with
CIMA-enabled memory-safety (i.e. ˆTs), may increase beyond the cycle time (i.e. Tc).
In general, to accurately formulate τ (i.e. the amount of downtime for a PLC), we need
to consider the following three mutually exclusive scenarios:

1. The system is aborted or restarted.
2. The system is neither aborted nor restarted and ˆTs ≤ Tc. In this case, there will
be no observable impact on the physical dynamics of the system. This is because
the PLCs, despite having increased scan time, still meet the real-time constraint
Tc. Thus, they are not susceptible to downtime.

3. The system is neither aborted nor restarted and ˆTs > Tc. In this scenario, the PLCs
will have a downtime of ˆTs − Tc, as the scan time violates the real-time constraint
Tc.

7

Based on the intuitions mentioned in the preceding paragraphs, we now formally

deﬁne τ , i.e., the downtime of a PLC as follows:

τ =






∆,
0,
ˆTs − Tc,

system is aborted/restarted
ˆTs ≤ Tc
ˆTs > Tc

(4)

where ∆ captures a non-deterministic threshold on the downtime of PLCs when the
underlying system is aborted or restarted.

Example As an example, let us consider the ﬁrst process in SWaT (discussed in
Section 6.1). This process controls the inﬂow of water from an external water supply
to a raw water tank. PLC1 controls this process by opening (with “ON” command)
and closing (with “OFF” command) a motorized valve, i.e., the actuator, connected
with the inlet pipe to the tank. If the valve is “ON” for an arbitrarily long duration,
then the raw water tank might overﬂow, often causing a severe damage to the system.
This might occur due to the PLC1 downtime τ , during which, the control command
(i.e. “ON”) computed by PLC1 may not change. Similarly, if the actuator receives the
command “OFF” from PLC1 for an arbitrarily long duration, then the water tank may
underﬂow. Such a phenomenon will still aﬀect the system dynamics. This is because
tanks from other processes may expect raw water from this underﬂow tank. In the
context of SWaT, the tolerability of PLC1 downtime τ (cf. Eq. (4)) depends on the
physical state of the water tank (i.e. water level) and the computed control commands
(i.e. ON or OFF) by PLC1. In the next section, we will formally introduce this notion
of tolerance, as termed physical-state resiliency, for a typical CPS.

Modeling physical-state resiliency To formally model the physical-state resiliency,
we will take a control-theoretic approach. For the sake of simplifying the presentation,
we will assume that the dynamics of a typical CPS, without considering the noise and
disturbance on the controller, is modeled via a linear-time invariant. This is formally
captured as follows (cf. Figure 2):

xt+1 = Axt + But

(5)

(6)
yt = Cxt
where t ∈ N captures the index of discretized time domain. xt ∈ Rk is the state vector
of the physical plant at time t, ut ∈ Rm is the control command vector at time t and
yt ∈ Rk is the measured output vector from sensors at time t. A ∈ Rk×k is the state
matrix, B ∈ Rk×m is the control matrix and C ∈ Rk×k is the output matrix.

We now consider a duration τ ∈ R for the PLC downtime. To check the tolerance
of τ , we need to validate the physical state vector xt at any discretized time index t.
To this end, we ﬁrst assume an upper-bound ω ∈ Rk on the physical state vector xt
at an arbitrary time t. Therefore, for satisfying physical state resiliency, xt must not
exceed the threshold ω. In a similar fashion, we deﬁne a lower-bound θ ∈ Rk on the
physical state vector xt.

With the PLC downtime τ , we revisit Eq. (5) and the state estimation is reﬁned as

follows:

x(cid:48)
t+1 = Axt + But−1[[t, t + τ ]]

(7)

8

Fig. 2: An abstraction of a CPS model

t+1 ∈ Rk is the estimated state vector at time t+1 and the PLCs were down for
where x(cid:48)
a maximum duration τ . The notation ut−1[[t, t + τ ]] captures that the control command
ut−1 was active for a time interval [t, t + τ ] due to the PLC downtime. In Eq. (7), we
assume, without loss of generality, that ut−1 is the last control command received from
the PLC before its downtime.

Given the foundation introduced in the preceding paragraphs, we say that a typical
CPS (cf. Figure 2) satisﬁes physical-state resiliency if and only if the following condition
holds at an arbitrary time index t:

θ ≤ x(cid:48)

t+1 ≤ ω

θ ≤ Axt + But−1[[t, t + τ ]] ≤ ω

(8)

Fig. 3: Illustrating the impact of PLC downtime

Figure 3 illustrates three representative scenarios to show the consequence of Eq. (8).
If the downtime τ1 = 0, then ut (i.e. control command at time t) is correctly computed
and x(cid:48)
t+1 = xt+1. If the downtime τ2 ∈ (1, 2], then the control command ut will be
the same as ut−1. Consequently, x(cid:48)
t+1 is unlikely to be equal to xt+1. Finally, when

9

t-1tt+1𝛕1 = 0 ut = ut-1 x’t+1=xt+1PLC down2 ≥ 𝛕2 > 1 ut = ut-1 x’t+1≠ xt+1t+2𝛕3 > 2 ut+1 = ut = ut-1 x’t+1≠ xt+1, x’t+2≠ xt+2Discretized  time012downtime τ3 > 2, the control command vector ut+i for i ≥ 0 will be the same as ut−1.
As a result, the estimated state vectors x(cid:48)
t+j for j ≥ 1 will unlikely to be identical to
xt+j.

4 CIMA: Countering Illegal Memory Accesses

CIMA is a mitigation technique designed to counter illegal memory accesses at runtime.
We ﬁrst outline a high-level overview and the key ingredients of our approach. Later
in this section, we discuss the speciﬁc implementation traits in more detail.

4.1 Overview of CIMA

Objective CIMA follows a proactive approach to mitigate memory-safety attacks
and thereby ensuring system availability and physical-state resilience in CPS. The key
insight behind CIMA is to prevent any operation that attempts to illegally access
memory. We accomplish this by skipping (i.e. not executing) the illegal instructions
that attempt to access memory illegally. For example, consider the exploitation of a
memory-safety attack shown in Figure 1. With our CIMA approach, the attack will be
ceased at step 3 (i.e. “Trigger a memory-safety violation”) of the exploitation process.

Workﬂow of CIMA CIMA systematically manipulates the compiler-generated con-
trol ﬂow graph (CFG) to accomplish its objective, i.e., to skip illegal memory accesses
at runtime. Control ﬂow graph (CFG) of a program is represented by a set of basic
blocks having incoming and outgoing edges. A basic block [36] is a straight-line se-
quence of code with only one entry point and only one exit, but it can have multiple
predecessors and successors. CIMA works on a common intermediate representation
of the underlying code, thus making our approach applicable for multiple high-level
programming languages and low-level target architectures.

To manipulate the CFG, CIMA needs to instrument the set of memory-access op-
erations in such a fashion that they trigger memory-safety violations at runtime. To
this end, CIMA leverages oﬀ-the-shelf technologies, namely address sanitizers (ASan).
A high-level workﬂow of our entire approach appears in Figure 4. The implementation
of CIMA replaces the ineﬀective mitigation strategy (i.e. system abort) of ASan with
an eﬀective, yet lightweight scheme. Such a scheme allows the program control ﬂow
to jump to the immediately next instruction that does not exhibit illegal memory ac-
cess. In such a fashion, CIMA not only ensures high accuracy of memory-safety attack
mitigation, but also provides conﬁdence in system availability and resilience. In the
following section, we describe our CIMA approach in detail.

4.2 Approach of CIMA

An outline of our CIMA approach appears in Algorithm 1. As input, CIMA takes a
function (in the GIMPLE format) instrumented by ASan. As output, CIMA gener-
ates a GIMPLE function with memory-safety mitigation enabled. We note that the
modiﬁcation is directly injected in the compiler workﬂow. To this end, CIMA modiﬁes
the internal data structures of GCC to reﬂect the changes of control ﬂow. Speciﬁcally,

10

Fig. 4: A high-level architecture of CIMA

CIMA manipulates the intermediate representation, which is often derived in the static-
single-assignment (SSA) form. To this end, CIMA also ensures that the SSA form is
maintained during the manipulation, so as not to disrupt the compiler workﬂow. We
now elaborate the crucial steps of CIMA in detail and discuss the speciﬁc choices taken
during its implementation.

Capture memory access instructions: CIMA validates memory accesses at run-
time to detect and mitigate illegal memory access instructions. To achieve this, CIMA
combines a compile-time code instrumentation and a runtime validity check technique.
The code instrumentation includes instrumenting memory addresses (via ASan) and
memory access instructions (via CIMA). The memory address instrumentation cre-
ates poisoned (i.e. illegal) memory regions, known as redzones, around stack, heap
and global variables. Since these redzones are inaccessible by the running program,

11

Algorithm 1: CIMA’s approach to ensure memory safety

Input: Function fun() with ASan Instrumentation
Output: Function funCIMA() with CIMA-enabled memory safety

1 forall the basic block bb in fun() do
2

forall the instruction i instrumented by ASan in bb do

Let check bb holds the memory-safety check condition check i for instruction i in
bb
Let abort bb be the basic block where control reaches to when instruction i is
illegal
Find target instruction Ti for instruction i
if ( i and Ti reside in the same basic block bb ){

tempbb := succ(bb)
/* split basic block */
Split bb into basic blocks ibb and Tbb
ibb holds instructions of bb up to i
Tbb holds instructions from Ti up to the end of bb
/* Modify control ﬂow */
/* succ(bb) captures successor of bb */
succ(ibb) := {Tbb}
succ(checkbb) := {ibb, Tbb}
succ(Tbb) := tempbb

else{

/* Modify control ﬂow */
Let Ti be in basic block Tbb
succ(checkbb) := (succ(checkbb) \ {abortbb}) ∪ {Tbb}

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

}
end

22
23 end

any memory instruction, attempting to access them at runtime will be detected as an
illegal instruction.

To mitigate the potential illegal instructions, CIMA instruments memory access
instructions at compile-time. To this end, CIMA captures memory access instructions
from the ASan instrumented code. These instructions serve as the potential candidates
for illegal instructions at runtime.

Compute target instruction: To prevent the execution of an illegal memory access
instruction i, CIMA computes its corresponding target instruction Ti. We note that
the set of potentially illegal instructions are computed via the technique as explained
in the preceding paragraph. The target instruction Ti for an illegal instruction i is the
instruction that will be executed right after i is bypassed. The compile-time analysis of
CIMA generates an instrumented binary in such a fashion that if an illegal instruction
i is detected at runtime, then i is bypassed and control reaches target instruction Ti.
If Ti is detected as illegal too, then the successor of Ti will be executed. This process
continues until an instruction is found without illegal memory access at runtime.

Computing the target instruction is a critical step in our CIMA approach. The
target instruction Ti is computed as the successor of the memory access instruction i
in the CFG. We note that a potentially illegal instruction must access memory, as the

12

objective of CIMA is to mitigate memory-safety attacks. At the GIMPLE IR-level, any
memory access instruction has a single successor. Such a successor can either be the
next instruction in the same basic block (see Figure 5(a)) or the ﬁrst instruction of the
successor basic block (see Figure 5(c)). Since CIMA works at the GIMPLE IR-level,
it can identify the target instruction Ti for any instruction i by walking through the
static control ﬂow graph.

We modify the control ﬂow graph in such a fashion that the execution is diverted
to Ti (i.e. the successor of i) at runtime when instruction i is detected to be illegal at
runtime. However, the modiﬁcation of the CFG depends on the location of the illegal
and target instructions as discussed below.
Compute target basic block: From the discussion in the preceding paragraph, we
note that the execution of memory access instruction i is conditional (depending on
whether it is detected as illegal at runtime). In the case where the instruction exhibits
an illegal memory access, a jump to the respective target instruction Ti is carried out.
However, it is not possible to simply divert the execution ﬂow to the target instruction
Ti. This needs to be accomplished via a systematic modiﬁcation of the original program
CFG at compile time.

Consider the case when the illegal instruction i and the target instruction Ti reside
in the same basic block (say bb). In this case, since the execution of i is conditional, it
is always the ﬁrst instruction of its holding basic block whereas the target instruction
Ti appears as the next instruction in the basic block bb (see Figure 5(a)). However, it
is not possible to make a conditional jump to Ti within the same basic block bb, as this
breaks the structure of the control ﬂow graph. Thus, to be able to make a conditional
jump to Ti, a target basic block (say Tbb), that contains Ti as its head instruction, is
created. In particular, we split the basic block bb into two basic blocks – ibb and Tbb (cf.
Algorithm 1, Lines 9 – 11). ibb holds the potentially illegal instruction i and Tbb holds
the instructions of bb following i, i.e., starting from the target instruction Ti and up to
the last instruction of bb. As such, control jumps to Tbb if instruction i is detected as
illegal at runtime.

If the illegal instruction i and the respective target instruction Ti are located in
diﬀerent basic blocks in the original CFG (see Figure 5(c)), then there is no need to
split any basic block. In such a case, the target basic block Tbb will be the basic block
holding Ti as its ﬁrst instruction. Therefore, CIMA diverts the control ﬂow to Tbb,
should i exhibits an illegal memory access at runtime.
Modify and maintain CFG: CIMA ensures the diversion of control ﬂow of the
program whenever an illegal memory access is detected. To accomplish such a twisted
control ﬂow, CIMA directly modiﬁes and maintains the CFG (cf. Algorithm 1, Lines (14
– 16) and (20)), as explained in the preceding paragraph. Figure 5 illustrates excerpts
of control ﬂow graphs that are relevant to the modiﬁcation performed by CIMA. In
particular, Figure 5 demonstrates how the control ﬂow is systematically manipulated
to guarantee the system availability, while still mitigating memory-safety attacks.

4.3 Illustrative Example

CIMA detected and mitigated two global buﬀer overﬂow vulnerabilities on the ﬁrmware
of OpenPLC controller. Due to space limitation, we discuss here only one such vulnera-
bility. A code fragment relevant to the vulnerability is shown in Program 2. In Line 3, a

13

(a)

(b)

(c)

(d)

Fig. 5: Diﬀerent scenarios encountered in CIMA’s approach. checki is the inserted con-
ditional check by ASan to identify illegal memory accesses in instruction i. abortbb
is the basic block to which control jumps to if i exhibits illegal memory access. (a):
ASan instrumented CFG where both i and Ti belong to the same basic block; (b):
the modiﬁcation of control ﬂow by CIMA for the ASan instrumented code in (a); (c):
ASan instrumented CFG where i and Ti belong to diﬀerent basic blocks; (d): the
modiﬁcation of control ﬂow by CIMA for the ASan instrumented code in (c).

buﬀer “int memory[]” (with a buﬀer size of 1024) is declared in the “glue generator.cpp”
ﬁle. This buﬀer is also used in the “modbus.cpp” ﬁle, enclosed within a for loop (Lines 19
– 30) under the “mapUnusedIO()” function. In the loop, the memory write operation
“int memory[i] = &mb holding regs[i]” (Line 27) writes data to the buﬀer. However,
due to a coding error, this operation exhibits a memory-safety violation. Such a viola-
tion occurs in the 1024th iteration when the operation attempts to write data beyond
the buﬀer limit. CIMA successfully mitigates such memory-safety violation. This was
possible as the illegal memory access operation was bypassed in each iteration starting
from the 1024th iteration of the loop.

5 Validating CIMA

In this section, we discuss the impact on using CIMA to mitigate memory-safety at-
tacks.

Breaking program semantics The mitigation strategy of CIMA by itself is based
upon breaking semantics of the program when an invalid memory access is detected.
This is accomplished via skipping the respective memory access. In the presence of
memory-safety attacks, we believe it is extremely time and memory consuming (given
the CPS context) to roll back to a semantics preserving state. Thus, CIMA aims for a
lightweight solution (attributes to only 8% overhead in real-world CPS) that works for
most common cases and we validate CIMA with a real-world CPS. Nevertheless, there
exists semantics-preserving issues that deserve discussion. For example, in Program 3,
Line 7, variable y is dependent on the output of memory access instruction arr[i]. CIMA
always checks the validity of the memory access arr[i] whenever the access occurs. If
the access arr[i] is found to be illegal, CIMA skips it and the variable assignment, i.e.,
y = arr[i], is also skipped as a side-eﬀect. In this case, y preserves the last “legally”
assigned value to it. Variable y preserves its initial value if the access arr[i] is detected
as illegal at the beginning (i.e. at index i = 0) otherwise. Concretely, the assignment

14

checkiabort()illegallegaliTi..bbabortbbcheckbbcheckiabort()iTi..Tbbibbillegallegalcheckbbabortbbcheckiabort()i…..TbbillegallegalTi..bbcheckbbabortbbcheckiabort()i…..TbbillegallegalTi..bbcheckbbabortbbProgram 2: The OpenPLC vulnerability

1 //————//glue generator.cpp————————–
2 #deﬁne BUFFER SIZE 1024
3 IEC UINT *int memory[BUFFER SIZE];
4 IEC UINT *int output[BUFFER SIZE];
5 .
6 .
7 //————//modbus.cpp————————————
8 #deﬁne MIN 16B RANGE 1024
9 #deﬁne MAX 16B RANGE 2047
10 #deﬁne MAX HOLD REGS 8192
11 IEC UINT mb holding regs[MAX HOLD REGS];
12 .
13 .
14 /* This function sets the internal OpenPLC buﬀers to */
15 /* point to valid positions on the Modbus buﬀer */
16 void mapUnusedIO() {
17

.
.
for( int i = 0; i <= MAX 16B RANGE; i++ ){

18

19

20

21

22

23

24

25

26

27

28

29

if ( i <MIN 16B RANGE ){

if ( int output[i] == NULL ){

int output[i] = &mb holding regs[i];

}

}
if ( i >= MIN 16B RANGE && i <= MAX 16B RANGE ){
if ( int memory[i - MIN 16B RANGE] == NULL ){

int memory[i] = &mb holding regs[i];

}

}

}

30
31 }

of y can be recursively deﬁned as follows:

y =






arr[i],
arr[i − 1],
y0,

if arr[i] is legal instruction
if arr[i] is illegal, i > 0
if arr[0] is illegal

(9)

where y0 is the initial value of y.

At a broader level, CIMA may encounter memory safety attacks either due to an
inherent vulnerability in the program or due to an illegal memory access caused by the
attacker (e.g. via well crafted attack inputs). For inherent program vulnerabilities, we
hypothesize that the underlying program semantics was already ﬂawed and therefore,
skipping the illegal memory accesses (due to such vulnerabilities), despite aﬀecting the
program semantics, will not further impair the system functionality. For illegal memory
accesses via carefully crafted attack inputs, we hypothesize that in most common cases
the program functionality will be unaﬀected when CIMA skips such illegal memory

15

accesses. This is due to the reason that such illegal memory accesses were executed
for the sole purpose of launching memory-safety attacks and skipping them should not
aﬀect the functionality of the system.

Continuity of program execution CIMA might not ensure continuity in program
execution when a loop bound or loop counter is controlled by an attacker. Let us consider
the example shown in Program 3, Line 5, where the loop bound arr[x] is dependent on
the attacker input x. We note that the value of x determines whether the memory read
instruction arr[x] is legal or not. CIMA skips the access to arr[x] should it turns out to
be illegal. This could lead to premature abortion of the loop (e.g. if arr[x] is detected
as illegal before the loop starts).

Consider a diﬀerent scenario when the the loop counter i is incremented by arr[z]
(cf. Program 3, Line 8). Assuming z can be controlled by the attacker, arr[z] might
manifest illegal memory access. Thus, CIMA bypasses the respective memory access
and the value of i remains unchanged. This leads to an execution that never terminates.

Program 3: Attacker controlled loop bound and counter

int arr[100], i, x, y, z;
printf(“Enter the value of x and z:”);
scanf(“%d %d”, &x, &z);
for( i=0; i <arr[x]; ){
// Do something
y = arr[i];
i += arr[z] //incrementing the loop counter

1 main() {
2

3

4

5

6

7

8

9

10
11 }

}
return 0;

The examples discussed in the preceding paragraphs may not happen in practice.
This is because providing loop bound and loop counter values via attacker controlled
memory accesses (e.g. arr[x] in Program 3) is certainly considered as a bad coding
practice. The occurrence of such corner cases could result in an undesirable outcome
(e.g. program crash) even in the absence of CIMA. In essence, avoiding such bad
coding practices will also help CIMA to maintain continuity of program execution in
the presence of memory-safety violations or attacks.

Aﬀecting the system dynamics CIMA may aﬀect the overall system dynamics (or
the physical-state resiliency in the context of CPS) when it skips too many illegal mem-
ory access instructions. This is because skipping too many illegal instructions creates
a delay in program execution. This, in turn, may result in the following scenarios:

– Lack of fresh input: Skipping instructions results impeding of fresh input to the
system. For example, actuators in CPS may not receive a new control command

16

while instructions are skipped due to memory-safety violation. This, in turn, may
aﬀect the system dynamics.

– Denial-of-service (DoS) attack: When CIMA skips too many illegal instructions,
the program execution may get stuck for a long period. This may result in the
denial-of-service.

As an example, consider the case where CIMA detected the OpenPLC vulnerability
(cf. Program 2, Line 27). CIMA skipped the illegal memory write instruction (i.e.
int memory[i] = &mb holding regs[i]) 1024 times in the for loop. This creates a delay
equivalent to 1024 iterations of the loop. Let us assume δ captures the total elapsed time
to skip illegal instructions in the loop. During the period of δ, the PLC is busy skipping
invalid memory accesses and does not issue a control command to the actuator. The
number of PLC scan cycles (similarly the number of control commands) missed during
this delay can be computed as δ/Tc. As such, the eﬀect of δ in the CPS dynamics (or
the physical-state resiliency) is analogous to the downtime (i.e. τ ) of the PLC discussed
on Section 3.3. Therefore, quantifying the level of delay (δ) that is tolerable to satisfy
physical-state resiliency of a typical CPS can be similarly modeled using Eq. (8) as
follows:

θ ≤ Axt + But−1[[t, t + δ]] ≤ ω

(10)

To minimize the eﬀect of CIMA on system dynamics (i.e. to satisfy Eq. (10)), we

propose the following two approaches:

– Detect long skips with debugging: As discussed in Section 2.2, we make use of
CIMA both as a debugging and a runtime memory-safety tool. If the illegal mem-
ory access occurs due to an existing vulnerability in a loop, i.e., the vulnerability
is from the existing source-code of the program and not attacker injected, then
CIMA automatically detects this vulnerability while debugging the program. This
is experimentally validated by accurately detecting the vulnerabilities found on the
OpenPLC ﬁrmware. We also developed an informative report (supported by an
alarm) for detected and mitigated illegal memory access instructions. Therefore,
the inherent vulnerabilities in the source-code should be manually ﬁxed once they
are discovered by our framework. On the other hand, as discussed on Section 5,
attackers may manipulate memory accesses in the loop bound or loop counter via
untrusted inputs. However, as discussed in the preceding sections, such vulnerabil-
ities are caused by bad coding practices and they can be solved by avoiding bad
coding practices.
For illegal memory accesses that occur outside loops (e.g. a substantial number of
illegal memory access instructions in the source-code), the skipping time is unlikely
to aﬀect the system dynamics. As evidenced by our experiments, the skipping time
of a single instruction is negligible. As such, skipping thousands of instructions is
still tolerable in the context of real-world CPS. Yet, it is unlikely to have tens of
thousands of illegal memory accesses in the absence of loops.

– Exiting loop: In certain cases, it might be possible to exit the loop when a suﬃ-
cient number of illegal memory accesses are detected inside it. This will reduce the
delay δ. However, more involved analysis are required to identify potential loops
that can be skipped altogether as soon as a certain number of illegal memory ac-
cesses are detected within it. We plan to extend CIMA along this direction in the
future.

17

6

case Studies and Experimental Design

6.1 SWaT

SWaT [37] is a fully operational water puriﬁcation testbed for research in the design
of secure cyber-physical systems. It produces ﬁve gallons/minute of doubly ﬁltered
water. A detailed account of the water puriﬁcation process and some salient features
and design considerations of SWaT can be found on our prior work [8]. Concurrently,
SWaT is based on closed-source and proprietary Allen Bradely PLCs. Hence, it is not
possible to directly modify the ﬁrmware of these PLCs and to enforce memory-safety
solutions. To alleviate this problem in our experimental evaluation, an open platform,
named Open-SWaT, was designed.

Open-SWaT [8, 9] is a mini CPS based on open source PLCs that mimics the fea-
tures and operational behaviors of SWaT. The PLCs are designed using OpenPLC
[38] – an open source PLC that runs on top of Linux on Raspberry PI (RPI). With
Open-SWaT, we reproduce operational proﬁles and details of SWaT. In particular, we
reproduce the main factors that have substantial eﬀect on the scan time and MSO of
PLCs such as hardware speciﬁcations of PLCs (e.g. 200MHz of CPU speed and 2MB
of user memory), a Remote Input/Output (RIO) terminal (containing 32 digital inputs
(DI), 13 analog inputs (AI) and 16 digital outputs (DO)), real-time constraints (i.e.
cycle time of PLCs), a PLC program (containing 129 instructions of several types),
communication frequencies and a full SCADA system. The main purpose of design-
ing Open-SWaT was to employ our CIMA approach on a realistic CPS. A high-level
architecture of Open-SWaT is shown in Figure 6. Due to space limitation, interested
readers are referred to a detailed account of Open-SWaT in our prior papers [8, 9].

Fig. 6: Architecture of Open-SWaT

18

6.2 SecUTS

The Secure Urban Transportation System (SecUTS) is a CPS testbed designed to re-
search on the security of a Metro SCADA system. The Metro SCADA system [39]
comprises an Integrated Supervisory Control System (ISCS) and a train signaling sys-
tem. ISCS integrates localized and centralized control and supervision of mechanical
and electrical subsystems located at remote tunnels, depots, power substations and pas-
senger stations. The entire Metro system can be remotely communicated, monitored,
and controlled from the operation control center via the communication network. On
the other hand, the signaling system facilitates communications between train-borne
and track-side controllers. It also controls track-side equipments and train position
localization. Modbus is used as a communication protocol among the devices in the
ISCS. A detailed account of the Metro SCADA can be found on [39].

The SecUTS testbed provides facilities to examine several types of cyber attacks,
such as message replay, forged message and memory-safety attacks, in the ISCS sys-
tem and enforce proper countermeasures against such attacks. However, the SecUTS
testbed is also based on closed-source proprietary Siemens PLCs, hence we cannot
directly enforce CIMA to these PLCs to detect and mitigate memory-safety attacks.
Consequently, we similarly designed Open-SecUTS testbed (by mimicking SecUTS)
using OpenPLC controller. It consists of 6 DI (emergency and control buttons) and 9
DO (tunnel and station lightings, ventilation and alarms). Subsequently, we enforced
CIMA to Open-SecUTS and evaluated its practical applicability in a Metro SCADA
system (See Section 7).

6.3 Measuring runtime overheads

To measure the scan time and and compute memory-safety overheads of the PLCs
in Open-SWaT and Open-SecUTS, a function is implemented using POSIX clocks (in
nanosecond resolution). The function measures the execution time of each operation in
the PLC scan cycle. Results will be then exported to external ﬁles for further manip-
ulation, e.g., computing MSO and plotting graphs. We run 50,000 scan cycles for each
PLC operation to measure the overall performance of the PLC.

7 Evaluation

This section discusses a detailed evaluation of our CIMA approach on Open-SWaT
and Open-SecUTS. Subsequently, we discuss the experimental results to ﬁgure out
whether our proposed approach is accurate enough to detect and mitigate memory-
safety violations. We also discuss the eﬃciency of our approach in the context of CPS
environment. In brief, we evaluate the proposed approach along four dimensions: 1)
Security guarantees – detection and mitigation accuracy of ASan and CIMA, respec-
tively, 2) Performance – tolerability of the runtime overhead of the proposed security
measure in CPS environment, 3) Resilience – its capability to ensure system availabil-
ity and maintain physical-state resiliency in CPS even in the presence of memory-safety
attacks, and 4) its Memory usage overheads.

19

7.1 Security guarantees

To stress test the accuracy of our approach, we have evaluated CIMA against a wide-
range of memory-safety vulnerabilities. This is to explore the accuracy of mitigating
memory-safety vulnerabilities by our CIMA approach. As our CIMA approach is built
on top of ASan, it is crucial that ASan detects a wide-range of memory-safety vul-
nerabilities accurately. According to the original results published for ASan [10], it
detects memory-safety violations with high-accuracy – without false positives for vul-
nerabilities such as (stack, heap and global) buﬀer under/overﬂows, use-after-free errors
(dangling pointers), use-after-return errors, initialization order bugs and memory leaks
. Only rare false negatives may appear for global buﬀer overﬂow and use-after-free
vulnerabilities due to some exceptions [10].

CIMA eﬀectively mitigates memory-safety violations, given that such a violation is
detected by ASan at runtime. Therefore, the mitigation accuracy of our CIMA approach
is exactly the same as the detection accuracy of ASan.

As discussed in detail on Section 4.2, we discovered two global buﬀer overﬂow
vulnerabilities in the OpenPLC ﬁrmware. Both these vulnerabilities were successfully
mitigated by our CIMA approach. Besides, throughout our evaluation, we did not
discover any false positives or negatives in mitigating all the memory-safety violations
detected by ASan.

Operations

Table 1: Memory-safety overheads for the Open-SWaT Testbed
Number
of cycles

CPU speed
(in MHz)

Network
devices

ASan

ASan + CIMA ( ˆTs)

Max
(in µs)

Max
(in µs)

Mean
(in µs)

Original (Ts)
Mean
(in µs)
59.38 788.12 118.44 1132.32 59.09 99.46 122.86 1151.35 63.48 106.9
69.09 611.82 115.88 720.36 46.79 67.72 118.97 802.18 49.88 72.2
145.01 981.09 185.37 1125.45 40.36 27.83 199.89 1213.62 54.88 37.85
273.48 2381.03 419.69 2978.13 146.21 53.46 441.72 3167.15 168.24 61.52

MSO
(in µs)

MSO
(in µs)

Max
(in µs)

Mean
(in µs)

MSO
(in %)

MSO
(in %)

Input scan
50000
Program exec. 50000
Output update 50000
Full scan time 50000

6
6
6
6

200
200
200
200

Operations

Table 2: Memory-safety overheads for the Open-SecUTS Testbed
Number
of cycles

CPU speed
(in MHz)

Network
devices

ASan

ASan + CIMA ( ˆTs)

Max
(in µs)

Max
(in µs)

Mean
(in µs)

Original (Ts)
Mean
(in µs)
59.84 739.94 114.88 902.01 55.04 91.98 115.07 906.09 55.23 92.3
48.56 488.38 91.36 443.61 42.8
145.47 850.62 175.59 1045.34 30.12 20.71 178.91 924.11 33.44 22.99
398.39 2506.39 144.52 56.93
253.87 2078.94 381.83 2390.96 127.96 50.4

88.14 104.41 676.19 55.85 115.01

MSO
(in µs)

MSO
(in µs)

Mean
(in µs)

Max
(in µs)

MSO
(in %)

MSO
(in %)

Input scan
50000
Program exec. 50000
Output update 50000
Full scan time 50000

1
1
1
1

200
200
200
200

7.2 Performance

According to the original article published for ASan [10], the average MSO of ASan
is 73%. However, all measurements were taken on benchmarks diﬀerent from ours and
more importantly, in a non-CPS environment. With our CPS environment integrated in

20

the Open-SWaT and Open-SecUTS, the average overhead induced by ASan is 53.46%
and 50.4%, respectively. Additionally, our proposed CIMA approach induces 8.06%
and 6.53% runtime overheads on Open-SWaT and Open-SecUTS, respectively. Thus,
the overall runtime overhead of our security measure is 61.52% (for Open-SWaT) and
56.93% (for Open-SecUTS). A more detailed performance report, including the perfor-
mance overhead of each PLC operation in both testbeds, is illustrated on Table 1 and
2.

It is crucial to check whether the induced overhead by ASan and CIMA ( ˆTs) is
tolerable in a CPS environment. To this end, we evaluate if this overhead respects the
real-time constraints of SWaT and SecUTS. For instance, consider the tolerability in
average-case scenario. We observe that our proposed approach satisﬁes the condition of
tolerability, as deﬁned in Eq. (2). In particular, from Table 1, mean( ˆTs) = 441.72µs, and
Tc = 10ms; and from Table 2, mean( ˆTs) = 398.39µs, and Tc = 150ms. Consequently,
Eq. (2) is satisﬁed and the overhead induced by our CIMA approach is both tolerable
in SWaT and SecUTS.

Similarly, considering the worst-case scenario, we evaluate if Eq. (3) is satisﬁed.
From Table 1, max( ˆTs) = 3167.15µs, and Tc = 10ms; and from Table 2, max( ˆTs) =
2506.39µs, and Tc = 150ms. It is still tolerable, thus the proposed security measure
satisﬁes SWaT’s and SecUTS’s real-time constraints in both scenarios. Therefore, de-
spite high security guarantees provided by CIMA, its overhead is still tolerable in a
CPS environment.

CIMA and ASan together induce a runtime overhead of 61.52% in
Open-SWaT and 56.93% in Open-SecUTS, whereas the overhead due
to CIMA is only 8.06% and 6.53%, respectively. Despite this over-
head, our proposed approach meets the hard real-time constraints for
SWaT and SecUTS both in the average- and worst-case scenarios.

Table 3: Memory usage overheads for the Open-SWaT Testbed

Category Original

ASan

ASan+CIMA

Original Overhead Original Overhead

Virtual
Memory 62.97MB 549.38MB 8.72× 557.5MB 8.85×

Real

Memory 8.17MB 10.31MB 1.26× 11.2MB 1.37×
Binary
2.25×
Shared
library

1.34× 4288KB 1.34×

3196KB 4288KB

324KB

316KB

144KB

2.19×

21

Table 4: Memory usage overheads for the Open-SecUTS Testbed

Category Original

ASan

ASan+CIMA

Original Overhead Original Overhead

Virtual
Memory 56.37MB 489.29MB 8.68× 490.6MB 8.70×

Real

Memory 8.76MB 9.81MB
Binary
288KB
136KB
Shared
library

3196KB 4288KB

1.12× 10.21MB 1.17×
2.18×
296KB
2.12×

1.34× 4288KB 1.34×

7.3 Resilience

One of the main contributions of our work is to empirically show the resilience of our
CIMA approach against memory-safety attacks. Here, we evaluate how our mitigation
strategy ensures availability and physical-state resiliency of a real-world CPS. As dis-
cussed in the preceding sections, CIMA does not render system unavailability. This is
because it does not abort or restart the PLC when mitigating memory-safety attacks.
In such a fashion, the availability of PLCs is ensured by our approach. As discussed
in Section 3.3, physical-state resiliency of a CPS can be aﬀected by the memory-safety
overhead (when the overhead is not tolerable due to the real-time constraint of the
PLC) or the downtime of the PLC (when the PLC is unavailable for some reason).

In the preceding section, we show that our CIMA approach ensures the memory-
safety overhead to be tolerable. Hence, the additional overhead induced by CIMA does
not aﬀect the physical-state resiliency. Added to the fact is that the availability of
SWaT and SecUTS is also ensured by CIMA via its very construction, as CIMA never
aborts the system or leads to PLC downtime. Given that our proposed solution ensures
availability of the PLC and also maintains the physical-state resiliency, we ensure the
resilience of SWaT even in the presence of memory-safety attacks.

CIMA ensures physical-state resiliency of SWaT and SecUTS, as ˆTs ≤
Tc (cf. Eq. (4) and Eq. (8)) holds in all of our experiments. This makes
CIMA to be a security solution that ensures the SWaT and SecUTS
systems to remain resilient even in the presence of memory-safety
attacks.

7.4 Memory usage overheads

Finally, we evaluated the memory usage overheads of our CIMA approach. Tables 3
and 4 summarize the increased virtual memory usage, real memory usage, binary size
and shared library usage for the Open-SWaT and Open-SecUTS testbeds, respectively.
The reported statistics are collected by reading VmPeak, VmRSS, VmExe and VmLib ﬁelds,
respectively, from /proc/self/status. In general, we observe a signiﬁcant increase in
virtual memory usages (8.85× for Open-SWaT and 8.70× for Open-SecUTS). This is

22

primarily because of the allocation of large redzones with malloc (as part of the ASan
approach). However, the real memory usage overhead is only 1.37× (for Open-SWaT)
and 1.17× for Open-SecUTS. We believe these overheads are still acceptable since
most PLCs nowadays come with at least 1GB memory size. Moreover, the increased
memory size is an acceptable trade-oﬀ in the light of strong mitigation mechanics
provided by our CIMA approach. Finally, we observe that CIMA introduces negligible
memory usage overhead over ASan, meaning the majority of memory-usage overhead
is attributed to the usage of ASan.

8 Related work

CIMA is built on top of ASan. ASan [10] is a fast memory-safety tool based on code-
instrumentation. It covers a wide range of temporal memory errors, such as use-after-
free, use-after-return and memory leaks, and spatial memory errors such as stack,
heap and global buﬀer overﬂows. It is also a standard tool included in the GCC and
LLVM compiler infrastructures as a memory-safety checker. However, its mitigation
approach (in normal mode) is to simply abort the program whenever a memory-safety
violation is detected. This is not acceptable in most critical systems, such as CPS
and ICS, with stringent time constraints. In such systems, availability is of the utmost
importance. This makes ASan to be impractical for critical systems with hard real-time
constraints. ASan does also provide a special mode to continue execution even after
detecting a memory-safety error. However, this mode does not provide any protection
against memory-safety attacks.

Softbound [16] and its extension CETS [17] guarantee a complete memory-safety.
However, such guarantees arrive with the cost of a very high runtime overhead (116%).
Such a high performance overhead is unlikely to be tolerable due to the real-time con-
straints imposed on a typical CPS. Moreover, Softbound and CETS do not implement
a mitigation strategy to consider the physical-state resiliency in a CPS environment.

SafeDispatch [11] is a fast memory-safety tool developed within the LLVM infras-
tructure. SafeDispatch also involves exhaustive performance optimizations to make the
overhead just 2.1%. However, SafeDispatch is not supported by an appropriate miti-
gation strategy that guarantees system availability in the presence of memory-safety
attacks. Thus, its applicability to the CPS environment is limited.

Sting [22, 23] is an end-to-end self-healing architecture developed against memory-
safety attacks. It detects attacks with address space layout randomization (ASLR) and
system-call-based anomaly detection techniques. However, ASLR can be defeated by
code-reuse attacks and system-call-based detections (e.g. control-ﬂow integrity) can be
bypassed by data injection attacks. To diagnosis the root cause of the attack, Sting
leverages a heavy-weight static taint analysis. Furthermore, it performs periodic check-
pointing and continuously records system calls to resume the victim program from an
earlier safe state. These techniques bring signiﬁcant performance and memory usage
overhead. As reported [22], there are cases where the corrupted program cannot be
recovered and requires to be restarted. Therefore, the performance and memory usage
overheads and the system unavailability problems limit the applicability of Sting to a
CPS environment.

ROPocop [12] is a dynamic binary code instrumentation framework against code
injection and code reuse attacks. It relies on Windows x86 binaries to detect such

23

attacks. Its runtime overhead is 240%, which is signiﬁcantly high and is unlikely be
tolerable due to the real-time constraints in CPS. Moreover, it is unclear what kind of
mitigation strategies were incorporated with ROPocop.

Over the past decades, a number of control-ﬂow integrity (CFI) based solutions
(e.g., [13, 14, 15, 40]) have been developed to defend against memory-safety attacks.
The main objective behind these solutions is ensuring the control-ﬂow integrity of a
program. Therefore, they aim to prevent attacks from redirecting the ﬂow of program
execution. These solutions also oﬀer a slight performance advantage over other counter-
measures, such as code-instrumentation based countermeasures. However, CFI-based
solutions generally have the following limitations: (i) determining the required control-
ﬂow graph (often using static analysis) is diﬃcult and requires a substantial amount
of memory; (ii) attacks that are not diverting the control-ﬂow of the program cannot
be detected (e.g. data oriented attacks [41]); (iii) ﬁnally, these solutions are mainly
to detect memory-safety attacks, but do not implement mitigation strategies against
the attacks. Consequently, the applicability of CFI-based solutions is limited in a CPS
environment.

In summary, to the best of our knowledge, there is no prior work that eﬃciently
detects and mitigates memory-safety attacks without compromising the real-time con-
straints or availability of the underlying system. Moreover, we are not aware of any
work that designs and evaluates memory-safety attack mitigation techniques in the
light of real-time constraints and physical-state resiliency imposed on critical systems.
In this paper, CIMA bridges this gap of research.

9 Threats to validity

The eﬀectiveness of CIMA critically depends on the following:

1. Uncovered memory-safety errors: ASan does not cover some memory-safety
errors such as uninitialized memory reads and some use-after-return bugs. Thus,
CIMA does not also mitigate these errors. However, these errors are less critical
and unlikely to be exploited in practice. Moreover, the central idea behind CIMA
is unaﬀected by such limitation. Speciﬁcally, CIMA leverages ASan as an oﬀ-the-
shelf capability to detect the memory-safety errors. Any improvement on memory-
safety attack detection tool will also automatically improve the coverage of attacks
mitigated via CIMA.

2. Experimental limitations: We conducted our experiments only on a water treat-
ment and Metro SCADA systems. Nevertheless, our proposed approach is generic
and it can be applied on diﬀerent CPSs with various real-time constraints. In the
future, we intend to conduct further experiments on power grid and robotics sys-
tems.

3. Limitations due to proprietary PLC code: SWaT and SecUTS are realistic
CPS testbeds containing a set of real-world vendor-supplied PLCs. However, their
PLCs are proprietary and closed-source. Hence, we were unable to incorporate
our security solution directly to these PLCs. Instead, we designed our testbeds (i.e.
Open-SWaT and Open-SecUTS) by mimicking all operational details of SWaT and
SecUTS, respectively. While designing the testbeds, we have paid careful attention
to all design features and constraints imposed on SWaT and SecUTS, especially

24

timing-related constraints. Hence, we can provide high conﬁdence on our results
obtained from Open-SWaT and Open-SecUTS to be applicable also to the real
SWaT and SecUTS systems.

10 Conclusion

In this paper, we propose CIMA, a resilient mitigation strategy to ensure protection
against a wide variety of memory-safety attacks. The main advantage of CIMA is
that it mitigates memory-safety attacks in a time-critical environment and ensures
the system availability by skipping only the instructions that exhibit illegal memory
accesses. Such an advantage makes CIMA to be an attractive choice of security measure
for cyber-physical systems and critical infrastructures, which often impose strict timing
constraints. To this end, we evaluate our approach on a real-world CPS testbed. Our
evaluation reveals that CIMA mitigates memory-safety errors with acceptable runtime
and memory-usage overheads. Moreover, it ensures that the resiliency of the physical
states are maintained despite the presence of memory-safety attacks. Although we
evaluated our approach only in the context of CPS, CIMA is also applicable and useful
for any system under the threat of memory-safety attacks.

From conceptual point of view, CIMA provides a fresh outlook over mitigating
memory-safety attacks. In future, we plan to build upon our approach to understand
the value of CIMA across a variety of systems beyond CPS. We also plan to leverage
our CIMA approach for live patching. In particular, at its current state, CIMA does
not automatically ﬁx the memory-safety vulnerabilities of the victim code (although
CIMA does ensure that the vulnerabilities are not exploited at runtime). Instead, it
generates a report for the developer to help produce a patched version of the code. In
future, we will use the report generated by CIMA to automatically identify the pattern
of illegal memory accesses and ﬁx the code accordingly.

References

1. Szekeres, L., Payer, M., Wei, T., Song, D.: Sok: Eternal war in memory. 2013 IEEE

Symposium on Security and Privacy (2013)

2. Saito, T., Watanabe, R., Kondo, S., Sugawara, S., Yokoyama, M.: A survey of preven-
tion/mitigation against memory corruption attacks. 2016 19th International Conference
on Network-Based Information Systems (NBiS) (2016)

3. Younan, Y., Joosen, W., Piessens, F.: Code injection in c and c++ : A survey of vulner-

abilities and countermeasures. Technical report (2004)

4. Francillon, A., Castelluccia, C.: Code injection attacks on harvard-architecture devices.
In: Proceedings of the 15th ACM Conference on Computer and Communications Security
(CCS’08). (2008)

5. Snow, K.Z., Monrose, F., Davi, L., Dmitrienko, A., Liebchen, C., Sadeghi, A.: Just-in-
time code reuse: On the eﬀectiveness of ﬁne-grained address space layout randomization.
In: Proceedings of the IEEE Symposium on Security and Privacy (SP’13), Washington,
USA (2013)

6. Dahse, J., Krein, N., Holz, T.: Code reuse attacks in php: Automated pop chain genera-
tion. In: Proceedings of the ACM SIGSAC Conference on Computer and Communications
Security (CCS’14). (2014)

25

7. Bittau, A., Belay, A., Mashtizadeh, A., Mazi´eres, D., Boneh, D.: Hacking blind.

In:
Proceedings of the 2014 IEEE Symposium on Security and Privacy. SP’14 (2014) 227 –
242

8. Chekole, E.G., Castellanos, J.H., Ochoa, M., Yau, D.K.Y.: Enforcing memory safety in
cyber-physical systems. In: Katsikas S. et al. (eds) Computer Security. SECPRE 2017,
CyberICPS 2017

9. Chekole, E.G., Chattopadhyay, S., Ochoa, M., Huaqun, G.: Enforcing full-stack memory
safety in cyber-physical systems.
In: Proceedings of the International Symposium on
Engineering Secure Software and Systems (ESSoS’18), Springer International Publishing
(2018)

10. Serebryany, K., Bruening, D., Potapenko, A., Vyukov, D.: Addresssanitizer: a fast address
sanity checker. In: Proceedings of the USENIX conference on Annual Technical Conference
(USENIX ATC’12). (2012)

11. Jang, D., Tatlock, Z., Lerner, S.: Safedispatch: Securing c virtual calls from memory cor-
ruption attacks. Proceedings 2014 Network and Distributed System Security Symposium
(2014)

12. Follner, A., Bodden, E.: Ropocop — dynamic mitigation of code-reuse attacks. Journal

of Information Security and Applications (2016)

13. Zhang, M., Sekar, R.: Control ﬂow integrity for cots binaries.

In: Proceedings of the

USENIX Security Symposium (USENIX’13). (2013)

14. Tice, C., Roeder, T., Collingbourne, P., Checkoway, S., Erlingsson, ´U., Lozano, L., Pike,
G.: Enforcing forward-edge control-ﬂow integrity in gcc & llvm. In: Proceedings of the
23rd USENIX Security Symposium. USENIX’14 (2014) 941–955

15. Ge, X., Talele, N., Payer, M., Jaeger, T.: Fine-grained control-ﬂow integrity for kernel

software. In: 2016 IEEE European Symposium on Security and Privacy. (2016)

16. Nagarakatte, S., Zhao, J., Martin, M.M., Zdancewic, S.: Softbound: Highly compatible
and complete spatial memory safety for C. In: Proceedings of the 2009 ACM SIGPLAN
conference on Programming language design and implementation. PLDI’09 (2009)

17. Nagarakatte, S., Zhao, J., Martin, M.M., Zdancewic, S.: Cets: Compiler enforced tem-
In: Proceedings of the 2010 International Symposium on Memory

poral safety for C.
Management (ISMM’10). (2010)

18. Simpson, M.S., Barua, R.K.: Memsafe: Ensuring the spatial and temporal memory safety

of c at runtime. Software: Practice and Experience 43(1) (2013) 93–128

19. Bruening, D., Zhao, Q.: Practical memory checking with dr. memory. In: Proceedings
of the 9th Annual IEEE/ACM International Symposium on Code Generation and Opti-
mization. CGO’11

20. Necula, G.C., Condit, J., Harren, M., McPeak, S., Weimer, W.: Ccured: Type-safe

retroﬁtting of legacy software. ACM Trans. Program. Lang. Syst. 27(3) (2005)

21. F. Ch. Eigler: Mudﬂap: pointer use checking for C/C++. In: GCC Developer’s Summit,

Red Hat Inc. (2003)

22. Newsome, J., Brumley, D., Song, D.: Sting: An end-to-end self-healing system for defend-

ing against zero-day worm attacks on commodity software (2005)

23. Newsome, J., Brumley, D., Song, D.: Vulnerability-speciﬁc execution ﬁltering for exploit
prevention on commodity software. In: Proceedings of the 13th Symposium on Network
and Distributed System Security (NDSS’05). (2005)

24. Brumley, D., Newsome, J., Song, D., Wang, H., Jha, S.: Towards automatic generation
of vulnerability-based signatures. In: Proceedings of IEEE Symposium on Security and
Privacy (SP’06), DC, USA (2006)

25. Smirnov, A., Chiueh, T.: Automatic patch generation for buﬀer overﬂow attacks. Third

International Symposium on Information Assurance and Security (2007)

26. CVE-2016-5814. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-5814

(2016)

26

27. CVE-2012-6438. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-6438

(2012)

28. CVE-2012-6436. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-6436

(2012)

29. CVE-2013-0674. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-0674

(2013)

30. CVE-2015-1449. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-1449

(2015)

31. CVE-2012-0929. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-0929

(2012)

32. CVE-2015-7937. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-7937

(2015)

33. CVE-2011-5007. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-5007

(2011)
34. github

repository, A.:

tools.
memory
AddressSanitizerComparisonOfMemoryTools (2015)

safety

Comparison

other
addresssanitizer
https://github.com/google/sanitizers/wiki/

with

of

35. Schuster, F., Tendyck, T., Liebchen, C., Davi, L., Sadeghi, A.R., Holz, T.: Counter-
feit object-oriented programming: On the diﬃculty of preventing code reuse attacks in c
applications. 2015 IEEE Symposium on Security and Privacy (2015)

36. GCC: Gcc basic blocks. https://gcc.gnu.org/onlinedocs/gccint/Basic-Blocks.html

(2018)

37. SWaT: Secure water treatment (swat) testbed (2018)
38. OpenPLC: Openplc. http://www.openplcproject.com/ (2018)
39. Zhou, L., Guo, H., Li, D., Wong, J.W., Zhou, J.: Mind the gap: Security analysis of metro
platform screen door system. In: Proceedings of the Singapore Cyber-Security RandD
Conference (SG-CRC’17). (2017)

40. Niu, B., Tan, G.: Rockjit: Securing just-in-time compilation using modular control-ﬂow
integrity. In: Proceedings of the ACM SIGSAC Conference on Computer and Communi-
cations Security (CCS’14). (2014)

41. Hu, H., Shinde, S., Adrian, S., Chua, Z.L., Saxena, P., Liang, Z.: Data-oriented pro-
gramming: On the expressiveness of non-control data attacks. 2016 IEEE Symposium on
Security and Privacy (2016)

27

