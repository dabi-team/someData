Attack Analysis and Resilient Control Design for
Discrete-Time Distributed Multi-Agent Systems

Aquib Mustafa, Student Member, IEEE and Hamidreza Modares, Senior Member, IEEE

9
1
0
2

y
a
M
4
1

]

Y
S
.
s
c
[

5
v
0
7
8
0
0
.
1
0
8
1
:
v
i
X
r
a

Abstract—This work presents a rigorous analysis of the adverse
effects of cyber-physical attacks on discrete-time distributed
multi-agent systems, and propose a mitigation approach for
attacks on sensors and actuators. First, we show how an attack
on a compromised agent can propagate and affect intact agents
that are reachable from it. That is, an attack on a single node
snowballs into a network-wide attack and can even destabilize
the entire system. Moreover, we show that the attacker can
bypass the robust H∞ control protocol and make it entirely
ineffective in attenuating the effect of the adversarial
input
on the system performance. Finally, to overcome adversarial
effects of attacks on sensors and actuators, a distributed adap-
tive attack compensator is designed by estimating the normal
expected behavior of agents. The adaptive attack compensator is
augmented with the controller and it is shown that the proposed
controller achieves secure consensus in presence of the attacks on
sensors and actuators. This controller does not require to make
any restrictive assumption on the number of agents or agent’s
neighbors under direct effect of adversarial input. Moreover, it
recovers compromised agents under actuator attacks and avoids
propagation of attacks on sensors without removing compromised
agents. The effectiveness of the proposed controller and analysis
is validated on a network of Sentry autonomous underwater
vehicles subject to attacks under different scenarios.

Index Terms—Resilient control, Distributed multi-agent sys-

tems, Adaptive control, Discrete-time systems.

I. INTRODUCTION

A cyber-physical system (CPS) refers to a class of engineer-
ing systems that integrates the cyber aspect of computation
and communication elements with physical entities. Based
on their control objectives CPSs can be categorized into two
classes, namely distributed multi-agent systems (DMASs) and
centralized networked control systems (CNCSs). The control
objective in DMAS is to achieve a coordinated or synchronized
motion or behavior through the exchange of local information
among agents [1]-[4]. On the other hand, the control objective
in CNCS, for which the feedback loops are closed through a
communication network, is to regulate the system’s output to
a desired value or trajectory [5]-[7]. DMASs and CNCSs are
both prone to cyber-physical attacks and corruption of sensory
data or manipulation of actuators’ inputs which can severely
and adversely affect their performance.

Stealthy attacks in CNCSs are considered as attacks that
signiﬁcantly disrupt the systems’ states while assuring that
the system outputs, observed by the system monitors, remain
within their acceptable bounds. On the other hand, the bulk
of the work on the resilient control of DMASs assumes

Aquib Mustafa and Hamidreza Modares are with the Department of
Mechanical Engineering, Michigan State University, East Lansing, MI, 48863,
USA (e-mails:mustaf15@msu.edu; modaresh@msu.edu).

that agents exchange their states, and not outputs, with each
other over a communication network to achieve consensus
or synchronization. In this class of systems, the effects of
adversaries are analyzed based on the discrepancy between
the state of agents and their neighbors. A stealthy attack
on the communication network can remain unnoticed, but
attacks on sensors and actuators can be detected if the agent’s
states do not follow its system dynamics. However, mitigation
of attacks without removing them and harming the network
connectivity is not straightforward, and, as shown in this paper,
if the mitigation process does not take actions fast, the entire
network can become unstable.

Considerable results have been presented for detection [8]-
[14] and mitigation of attacks in DMAS. There are generally
two approaches in designing mitigation techniques for DMAS.
In the ﬁrst approach, a monitor is designed to detect attacks
on neighbors and then remove compromised agents, once
identiﬁed [15]-[23]. In these approaches, each normal agent
either uses an observer for each of its neighbors to detect
abnormality [17] or discard neighbors information based on
the discrepancy between actual and malicious agents using
an iterative strategy [15]-[16]. The former approach requires
a model for each of its neighbors which makes it not scal-
able. The latter requires meeting the F-total or the F-local
condition. That is, there should be an upper bound on F
either on the total number of adversarial agents, called as F-
total or on the local number of compromised agents in the
neighborhood of each intact agent, called as F-local. Although
these approaches can counteract variety of attacks, including
attacks on sensors, actuators and communication network, they
might harm the network connectivity by rejecting neighbor’s
information even if there is no attack. This is because they
might not be able to distinguish between a change in neighbors
behavior due to attack and a legitimate change in the system.
For example, in a leader-follower synchronization problem,
a legitimate change in leader’s state can be detected as a
change due to adversarial input by neighbors. Moreover, these
approaches treat all types of attacks the same by discarding
compromised agents. However, as shown in this paper, attacks
on sensors and actuators can be recovered and compromised
agents can be brought back to the network without making
any restrictive assumption on the network connectivity. This
avoids any unnecessary harm to the network connectivity.

In the second approach, local resilient control protocols
based attack mitigation are designed to directly mitigate attack
without identifying them. Reputation-based resilient control
is presented in [24] for leader-follower problem
protocol
under certain conditions. Game-theory based resilient control

 
 
 
 
 
 
architectures [25]-[28] are presented to minimize the effects
of adversarial input. With an assumption of having partial
knowledge of attacker, a resilient receding horizon-based con-
trol protocol is discussed in [29]-[31] for mitigation of the
replay attack. Secure state estimation and control under sensor
attack is considered in [32]-[33]. A resilient control protocol
is presented in [34] for single and double integrator system
based on local state emulator. In [35], an adaptive resilient
control protocol is presented for the attack on sensor and
actuator of the system. Most of these results are presented for
continuous-time systems. However, in real-time applications,
the system communicates and broadcasts there information at
discrete instants.

To design a resilient control protocol, one needs to identify
the adverse effects of the attack on the system performance
from the attacker’s perspective. Despite tremendous progress
in identifying the adverse effects of attacks on DMAS, there is
still a need to identify the vast effects of stealthy attacks and
equipt the system with resilient control protocol to mitigate
them. Toward this end, in this paper, ﬁrst, we illustrate how an
attack on a compromised agent spreads across the network and
affects intact agents that are reachable from a compromised
agent. Then, we show that the attacker can design a stealthy
attack that has a common mode with the system dynamics and
launch on a single root node to destabilize the entire system.
We call this as the internal model principle for the attacker in
discrete-time DMAS. The attacker does not need to know the
graph topology or agents dynamics to design its attack signal
and can eavesdrop on some sensory information to identify
one eigenvalue of the consensus dynamics. We also show that
the attacker can entirely disable robust techniques such as H∞,
used for attenuating the effects of adversarial inputs on the
performance of the system.

To mitigate the effect of the adversarial input, this work
presents a distributed adaptive resilient controller. First, the
expected normal behavior of agents are predicted using an
observer-like dynamics. Then, an adaptive attack compensator
is designed using predicted normal behavior of agents. The
designed adaptive attack compensator is augmented with the
controller for the mitigation of the attack. Moreover, we
have shown that the consensus error is uniformly bounded
using the proposed controller in the presence of the attack.
The proposed adaptive resilient control protocol makes no
restriction on graph topology as compared to the existing
approaches [15]-[23]. The proposed controller preserves the
network connectivity and mitigates the effect of adversarial
input on the actuator of the compromised agent. That is, not
only the synchronization is achieved in the presence of actuator
attacks, but also compromised agents are recovered. On other
the hand, attacks on sensor affect only compromised agents
without being propagated in the network. Finally, simulation
results validate the effectiveness of the proposed controller
and theoretical analysis for a network of Sentry autonomous
underwater vehicles under the inﬂuence of attacks for different
scenarios.

II. NOTATIONS AND PRELIMINARIES

In this section,

the preliminaries of graph theory and
standard distributed consensus of multi-agent systems are

provided.

A. Graph Theory

A directed graph G consists of a pair (V , E ) in which set
of nodes and set of edges are represented by V = v1, . . . , vN
and E ⊂ V xV , respectively. The adjacency matrix is deﬁned
as A = [ai j], with ai j > 0 if (v j, vi) ∈ E . The set of nodes vi
with edges incoming to node v j is called as neighbors of node
vi, namely Ni = v j : (v j, vi) ∈ E . The graph Laplacian matrix
is deﬁned as L = H − A , where H = diag(hi) is known as
the in-degree matrix, with ∑ j∈Ni ai j as the weighted in-degree
of node i. A node is called as a root node if it can reach
all other nodes of the graph G through a directed path. A
directed tree is an acyclic digraph with a root node, such that
any other node of the digraph can be reached by one and only
one directed path starting at the root node. A graph is said to
have a spanning tree if a subset of the edges forms a directed
tree.

Throughout the paper, λ (.) represents the eigenvalues of
a matrix. (.)ad j refers to adjoint of a matrix. ker(.) denotes
the null space. Furthermore, λmax(.) and λmin(.) represent
maximum and minimum eigenvalue of matrix, respectively.
diag(.) denotes the diagonal matrix. a ⊗ b represents Kro-
necker product of a and b.
Assumption 1. The directed graph G has a spanning tree.

B. Standard Distributed Consensus in MAS

This subsection presents the standard distributed control

protocol for consensus of discrete-time MAS.

Consider N agents with identical system dynamics repre-

sented by

xi(k + 1) = Axi(k) + Bui(k),

(1)
where xi(k) ∈ Rn and ui(k) ∈ Rm are the state and control input
of agent i, respectively. A and B are the system and input
matrices, respectively. (A, B) is assumed to be stabilizable.

i = 1, . . . , N

Deﬁne the local neighborhood tracking error for the agent

i as

εi(k) = (1 + hi)−1

N
∑
j=1

ai j(x j(k) − xi(k))

(2)

where ai j is the (i, j)-th value of the adjacency matrix.

Consider the distributed control law for each node i as in

[36]

ui(k) = cKεi(k),

i = 1, . . . , N

(3)

where c is a positive coupling gain and K ∈ Rm×n is a control
gain, designed to gaurantee that agents reach consensus, i.e.,
xi(k) → x j(k) ∀i, j. Deﬁne the global state vector as x(k) =
[xT
the global
dynamics of DMAS can be expressed as

N(k)]T ∈ RnN. Using (1)-(3),

2 (k), . . . , xT

1 (k), xT

x(k + 1) = [IN ⊗ A − c(I + H)−1L ⊗ BK]x(k)

(4)

The normalized graph Laplacian matrix ˆL is deﬁned as [36]

ˆL = (I + H)−1L

(5)

Let the eigenvalues of the normalized graph Laplacian matrix
ˆL be λi, ∀ i = 1, . . . , N. Then, λi lies inside unit circle centered
at 1 + j0 for i = 2, . . . , N and λ1 = 0 [37].

Using (4), the state of agent’s global dynamics is given by

A. Effects of Attack on Standard DMAS

x(k) = [IN ⊗ A − c ˆL ⊗ BK]kx(0) (cid:44) Ak
where Ac is the closed-loop matrix deﬁned as

cx(0)

(6)

Ac = (IN ⊗ A − c ˆL ⊗ BK)
(7)
Lemma 1. [37] Let R ⊂ V be the set of root nodes and r =
[p1, . . . , pN]T be the left eigenvector of the normalized graph
Laplacian matrix ˆL for λ1 = 0. Then, pi > 0 if i ∈ R and pi = 0
if i /∈ R.
Theorem 1. [36]-[37] Let feedback gain K be designed such
that A−cλiBK is Schur stable for i = 2, . . . , N. Then, according
to Lemma 1, the ﬁnal consensus value for DMAS can be
written as

x(k) = (rT ⊗ Ak)

i = 1, . . . , N as k → ∞

(8)













x1(0)
.
.
xN(0)

III. ATTACK ANALYSIS FOR DISCRETE-TIME DMAS
This section presents the attack modeling and analyzes its
adverse effects on the standard control protocol. The internal
model principle for the attacker is presented to show how a
single compromised agent can destabilize the entire system.
Then,
the effect of the attack on the local neighborhood
tracking error is analyzed to show the ineffectiveness of the
standard robust H∞ control protocol (which is a well-known
disturbance attenuation technique) in the presence of a stealthy
attack.

Attacks on actuators of agent i can be modeled as

This subsection analyzes the effects of the attack on the
standard discrete-time DMAS (1). Theorem 2 investigates how
an attack can propagate across the network.

Deﬁnition 1. In a graph, agent i is reachable from agent j if
there is a directed path of any length from node j to node i.

Deﬁnition 2. An agent is said to be a compromised agent, if
it is directly affected by the attacker.

Theorem 2. Consider the discrete-time DMAS (11) under the
attack fi(k). Let the control protocol be designed as (3) such
that the closed loop matrix Ac in (7) is Schur. Then,

1) All agents reach consensus if fi(k) = 0, ∀i = 1, . . . , N.
2) The intact agent deviates from the desired consensus
value if it is reachable from a compromised agent.
3) The deviation of the network from the desired behavior
depends on the number of compromised agents, their
attack signal magnitude and the number of agents reach-
able from them.

Proof. It is shown in [37] that if c and K are designed so
that Ac in (7) is Schur, then all agents reach consensus. This
completes the proof of part 1.

prove
part
2(k))T , . . . , (xa
2(k))T , . . . , (ua

xa(k) =
2,
To
[(xa
1(k))T , (xa
ua(k) =
N(k))T ]T
[(ua
1(k))T , (ua
N(k))T ]T
as a vector of signals
injected to the sensors and actuators, respectively. The global
dynamics for DMAS (11) under the effect of attack can be
written as

deﬁne
and

i (k) = ui(k) + γiua
uc

i (k)

(9)

x(k + 1) = Acx(k) + (IN ⊗ B) f (k),

i = 1, . . . , N

(13)

where ui is the control law given in (3), ua
represents the
i
attacker’s signal injected into the actuator of agent i, uc
i is the
distorted control law applied to (1) and the scalar γi is 1 when
there is an attack on actuators of agent i and 0, otherwise.

Attacks on sensors of agent i can be modeled as

i (k) = xi(k) + δixa
xc

i (k)

(10)

where xi represents the state of agent i, xa
is the attacker’s
i
signal injected into the sensor of agent i, xc
is the distorted
i
state and the scalar δi is 1 when there is an attack on sensors
of agent i and 0, otherwise.

Based on the distributed control law (3), and using (9) and
(10) in (1), one can express the DMAS dynamics for an agent
i as

xi(k + 1) = Axi(k) + Bui(k) + B fi(k),

i = 1, . . . , N

(11)

where the injected global attack signal f (k) is

f (k) = −c( ˆL ⊗ K)(δ ⊗ IN)xa + (γ ⊗ IN)ua

(14)

with γ = diag(γ1, . . . , γN) and δ = diag(δ1, . . . , δN). If f (k) (cid:54)= 0,
then the solution of (13) is given by

x(k) = Ak

cx(0) +

k−1
∑
p=0

(Ac)k−p−1(IN ⊗ B) f (p)

(15)

with k ≥ p. Then, one can write (15) as

x(k) = Ak

cx(0) +

k−1
∑
p=0

(IN ⊗ A)k−p−1(IN ⊗ In

−c ˆL ⊗ A−1BK)k−p−1(IN ⊗ B) f (p)

(16)

ai j(δ jxa

j (k) − δixa

fi(k) = c(1 + hi)−1K(

where fi(k) represents the overall attack signal injected into
the agent i, which is given by
N
∑
j=1
+γiua

i (k)
Remark 1. An attacker can manipulate sensors or actuators
without physical tampering. Spooﬁng of global positioning
system (GPS) of an unmanned vehicle or of phasor measure-
ment unit’s (PMU’s) in power system are examples of attacks
without physical tampering.

i (k))

(12)

in which the second part of (16) reﬂects the effect of the
attackers’ input on the system. For a positive integer n, the
binomial theorem for matrices can be expressed as (x + y)n =
n
if x and y is commutative.
∑
k=0
Using this fact and Theorem 1, (16) becomes

k xn−kyk with Cn
Cn

k = n!

(n−k)!k!

x(k) = (rT ⊗ Ak)x(0) +

k−1
∑
p=0

(IN ⊗ A)k−p−1

∗

k−p−1
∑
m=0

Ck−p−1
m

(−c ˆL ⊗ A−1BK)m(IN ⊗ B) f (p)

(17)

Using (17), the state of the agent i at steady state can be
written as

Deﬁnition 3. (IMP-based and non-IMP-based Attacks.) Let
the attack signal fi(k) be generated by

xi(k) → rT AKx(0)+
k−p−1
N
∑
∑
m=0
j=1

k−1
∑
p=0

Ak−p−1Ck−p−1

m

(−1)mcmlm

i j(A−1BK)mB f j(p)

(18)

(cid:44) [(I + H)−1L]m

in which ﬁrst term represents the desired consensus value that
depends on the eigenvalues of the system dynamics matrix
A (i.e., consensus value becomes zero for the stable system
dynamics A or non-zero for the marginally stable system
dynamics A). lm
i j with [ ]i j denotes the element
i j
(i, j) of a matrix. m represents the length of shortest directed
path from j to i [38]. Assume now that the agent j is under
direct attack, but agent i is intact, i.e. fi(k) = 0 and f j(k) (cid:54)= 0.
If the intact agent i is reachable from the compromised agent j,
since lm
i j (cid:54)= 0 for some 0 < m < N − 1, one can infer from (18)
that the agent state xi(k) at steady state in (18) has nonzero
second part which deduces that intact agent i is deviated from
the desired consensus behavior. This completes the proof of
part 2.

For the proof of part 3, taking the norm from both sides of

(15) yields

(cid:107)x(k)(cid:107) (cid:54)

(cid:13)
(cid:13)Ak
(cid:13)

(cid:13)
(cid:13)
cx(0)
(cid:13) +

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k−1
∑
p=0

(cid:13)
(cid:13)
(Ac)k−p−1(IN ⊗ B) f (p)
(cid:13)
(cid:13)
(cid:13)

and using

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k−1
∑
p=0

(cid:13)
(cid:13)
(Ac)k−p−1 f (p)
(cid:13)
(cid:13)
(cid:13)

(cid:54) (cid:107) f (k)(cid:107)
|λmin(Ac)|

one can write (15)

(cid:107)x(k)(cid:107) (cid:54)

(cid:13)
(cid:13)
(cid:13)(rT ⊗ Ak)x(0)
(cid:13)
(cid:13)
(cid:13) + N f

(cid:107)B(cid:107) b f
|λmin(Ac)|

(19)

(20)

(21)

is bound on adversarial input

at steady state, where, N f is the number of agents for which
fi(k). It
fi(k) is non-zero, b f
was shown in part 2 that if agent i is reachable from the
compromised agent
then its deviation from the desired
behavior is nonzero. That is, for the agent i which is reachable
from a compromised agent, the deviation in (cid:107)xi(k)(cid:107) in (21)
depends on the number of compromised agents N f and bound
(cid:3)
on adversarial input b f . This completes the proof.

j,

fi(k + 1) = W fi(k)

(22)

where W ∈ Rm×m denotes the dynamics of the attack signal.
Deﬁne
(cid:26) ΛW = [λW1, . . . , λWm]
ΛA = [λA1, . . . , λAn ]

(23)

as the set of eigenvalues of the attack dynamics W and the
system dynamics matrix A, respectively. Then, if ΛW ⊆ ΛA,
the attack signal is called the IMP-based attack. Otherwise,
if ΛW (cid:54)⊂ ΛA or the attacker has no dynamics (e.g. a random
signal), it is called a non-IMP based attack.

We assume that the system matrix A in (1) is marginally
stable, with eigenvalues on the unit circle centered at origin.
This is a standard assumption in the literature for consensus
and synchronization problems [39]. In fact, if A has stable
eigenvalues, one can ignore them and reduce the dimension of
A. This is because, stable states of the agent have no effect on
the steady-state synchronization trajectory, and only contribute
to the transient response.Deﬁne
S(k) = ∑N

p1 j f j(k)

(24)

j=1

where p1 j represents the element of left eigenvector corre-
sponding to zero eigenvalue of ˆL. Based on Lemma 1, one
can conclude that S(k) (cid:54)= 0 if j ∈ R, i.e., if attack is on a root
node, and S(k) = 0 otherwise.

Theorem 3. Consider the DMAS (11) under the attack fi(k)
fi(k) be designed as (22).
with the control protocol (3). Let
Then,

1) An IMP-based attack destabilizes the complete network,

if S(k) (cid:54)= 0, i.e., if attack is on a root node.

2) Any non-IMP based attack or IMP-based attack with
S(k) = 0 deviates agents from the desired consensus
behavior but does not cause instability, if agents are
reachable from the compromised one.

Proof. The transfer function for the DMAS (1), from xi(z)

to ui(z) in z-domain can be written as

Gi(z) =

xi(z)
ui(z)

= (zI − A)−1B

(25)

Using (3), the global control law under the inﬂuence of the

attack can be expressed as

B. Internal Model Principle Approach for the Attacker

u(z) = −(c ˆL ⊗ K)x(z) + f (z)

(26)

In the control systems, to reject a disturbance or follow
a reference trajectory, one needs to incorporate reference
dynamics in the system. This is called the internal model
principle (IMP). We showed in the following Theorem 3 that
the attacker can also leverage the IMP and incorporate some
eigenvalues of the consensus dynamics in its attack design to
destabilize the entire network.

We now take the role of the attacker and show that how it
can maximize the damage and cause a catastrophe. Conditions
under which the attacker achieves this objective are provided.

with u(z) = [uT
1
[ f T
, . . . , f T
N
1
global form can be written as

, . . . , uT
N

]T and f (z) =
]T . Using (25) and (26), the system state in the

x(z) = [xT
1

, . . . , xT
N

]T ,

x(z) = (IN ⊗ G(z))u(z) = (IN ⊗ G(z))(−(c ˆL ⊗ K)x(z) + f (z))
(27)
where G(z) = diag(Gi(z)) with dimension RNxN. Let M be a
non-singular matrix such that ˆL = MΛM−1, with Λ be the Jor-
dan canonical form of the normalized graph Laplacian matrix
ˆL. The left and the right eigenvectors of ˆL corresponding to

the zero eigenvalue of the normalized graph Laplacian matrix
are r and 1N, respectively [37]. Deﬁne

M = [1 M1], M−1 = [rT M2]T
where M1 ∈ RN×(N−1) and M2 ∈ R(N−1)×N. Using (27) with
ˆL = MΛM−1, one has

[INn + cMΛM−1 ⊗ G(z)K]x(z) = (IN ⊗ G(z)) f (z)

(28)

As MM−1 = IN, one can write (28) as

(M ⊗ In)[InN + cΛ ⊗ G(z)K](M−1 ⊗ In)x(z) = G(z) f (z) (29)

Deﬁning a state transformation as

ˆx(z) = (M−1 ⊗ In)x(z)

(30)

and premultiplying (29) with (M−1 ⊗ In) gives

ˆx(z) = [INn + cΛ ⊗ G(z)K]−1(M−1 ⊗ G(z)) f (z)

(31)

Let assume for simplicity that all the Jordan blocks are simple,
M−1 = [pi j] and M = [mi j], where pi j and mi j represent the
elements of matrices M−1 and M, formed by left eigenvectors
and right eigenvectors of the normalized graph Laplacian
matrix ˆL, respectively. For the agent i, using (30) and (31),
one has

xi(z) =

N
∑
h=1

mih[In + cKGi(z)λi]−1Gi(z)∑N

j=1

pi j f j(z)

(32)

The ﬁrst eigenvalue of the normalized graph Laplacian matrix
ˆL is zero and its corresponding right eigenvector is 1N i.e.
mi1 = 1. Using this fact with (32), one has

xi(z) = Gi(z)

N
∑
j=1

p1 j f j(z)+

N
∑
h=2

mih[In + cλhGi(z)K]−1Gi(z)

(33)

N
∑
j=1

ph j f j(z)

Since (A − cλhBK), ∀h = 2, . . . , N is Schur,

Now, if we show that [In + cKGi(z)λh]−1 is Schur, then the
second term of (33) is bounded, even in the presence of attack.
therefore if
the roots of the characteristic polynomial
we show that
(A − cλhBK) are identical to the poles of [In + cKGi(z)λh]−1,
then one can say [In + cKGi(z)λh]−1 is also Schur. To this end,
using (25), one has

∆|(zIn − (A − cλhBK))| = ∆|(zIn − A + cλhBK)|
= ∆|zIn − A|(In + cλh(zIn − A)−1BK)

=

∆|zIn − A|[(∆|zIn − A| + cλh(zIn − A)ad jBK)]
∆|zIn − A|

(34)

Hence, this proves that the roots of the characteristic poly-
nomial (A − cλhBK) are identical
[In +
cKGi(z)λh]−1 using matrix properties from [40]. Therefore,
[In + cKGi(z)λh]−1 is Schur. Thus, it concludes that the second
term of (33) is bounded and has no contribution in destabiliz-
ing the system.

to the poles of

According to Lemma 1, ∑N

j=1 p1 j f j(k) or S(k) in (24) is
zero for attack on non-root nodes and nonzero, if the attack
is launched on root nodes. Consider an IMP-based attack on

a root node. Then, using the transfer function (25) and the
attack signal deﬁned in (22), one can write (33) as
(zIn − A)ad jB(zIn −W )ad j fi(0)
)(z2 + λ 2
Wi

(z2 + λ 2
Ai

(z2 + λ 2
Al

N
∑
j=1

xi(z) =

)2{

p1 j

)}

+

N
∑
h=2

mih[1 + cKGi(z)λh]−1Gi(z)

n
∏
i=1,i(cid:54)=l
N
∑
j=1

ph j f j(z)

(35)

The ﬁrst term of (35) shows that the pole λAl
lies on the
unit circle centered at the origin and has multiplicity greater
than 1. Thus, the system states tend to inﬁnity in the discrete-
time domain as k → ∞. Therefore, the attack on the root node
destabilizes the entire network. This completes the proof of
part 1.

If the attack is on a non-root node, then ∑N

j=1 p1 j f j(k) = 0.

So, (33) can be expressed as

xi(z) =

N
∑
h=2

mih[1 + cKGi(z)λh]−1Gi(z)

N
∑
j=1

ph j f j(z)

(36)

Then, according to (34), [In + cKGi(z)λh]−1 is Schur stable.
Therefore, the system states are bounded, even in the presence
of the attack. Moreover, the agents that are reachable from
the attacker shows stable behavior, but deviation from the
desired consensus value. If ΛA ∩ΛW (cid:54)= φ which implies that the
multiplicity of poles lie on the unit is one. Therefore according
to (33), the system states remain bounded and shows deviation
from the desired consensus behavior due to the adverse effect
(cid:3)
of the attacker. This completes the proof.

Remark 2. Note that the attacker does not need to know
the system matrix A, and it can identify the eigenvalues of
dynamics through eavesdropping the sensory informations.
Then, the attacker can identify root node and destabilize the
entire system.

The following example presents the adverse effect of attack

on the root node.

Example 1. Consider 4 agents having single-integrator dy-
namics given by

xi(k + 1) = xi(k) + ui(k) i = 1, . . . , 4

(37)

with the control protocol (3) and communicating to each other
according to graph structure in Fig.1.

In the absence of attack signal, agents achieve the desired
consensus value, which is the average of the initial values of
Agents 1 and 2 in this example. If the attacker launches an
attack on the Agent 1, then, the dynamics of the system at the
steady state can be written as

x1(k + 1) = x1(k) + u1(k) + uac(k) = 0
⇒ x1(k) + (1 + h1)−1(x2(k) − x1(k)) + 1 = 0
⇒ (x1(k) + x2(k)) = −2

x2(k + 1) = x2(k) + u2(k) = 0
⇒ x2(k) + (1 + h2)−1(x1(k) − x2(k)) = 0
⇒ (x1(k) + x2(k)) = 0

(38)

(39)

bypass existing H∞ disturbance attenuation approaches and
make them entirely ineffective.
Lemma 2. Consider the normalized graph Laplacian matrix ˆL
deﬁned in (5). Then, [ ˆLT ˆL − 2 ˆL] is negative semideﬁnite.
Proof. Let λk be the eigenvalue of the normalized graph
Laplacian matrix ˆL. So, the eigenvalue of [ ˆLT ˆL − 2 ˆL] can be
written as

eig[ ˆLT ˆL − 2 ˆL] = λ 2

k − 2λk
= (λk − 1)2 − 1

(44)

Since all eigenvalues of matrix ˆL lie inside unit circle
centered at 1 + j0, except λ1 = 0 [37], therefore (λk − 1)2 − 1
is less than or equal to zero for k = 1, . . . , N. This shows that
[ ˆLT ˆL − 2 ˆL] is negative semideﬁnite.

In the following theorem, for the sake of simplicity, we
consider the single integrator dynamics (37) and its global
dynamics is given by

x(k + 1) = x(k) + u(k)

(45)

Under the inﬂuence of attack, one can write the control input
u(k) in (45) as

u(k) = (− ˆLx(k) + f (k))

(46)

Theorem 4. Consider the discrete-time DMAS with single
integrator dynamics (45). Assume that the system is under
f (k). Then, the local neighborhood
a constant attack signal
tracking error for intact agents is zero while agents do not
reach the desired consensus.

Proof. Consider the Lyapunov function for the discrete-time
DMAS as

V (x(k), f (k)) = (− ˆLx(k) + f (k))T (− ˆLx(k) + f (k))

(47)

The difference equation of the Lyapunov function (47) can be
written as

∆V (x(k), f (k)) = V (x(k + 1), f (k + 1)) −V (x(k), f (k))

= (− ˆLx(k + 1) + f (k + 1))T (− ˆLx(k + 1) + f (k + 1))
−(− ˆLx(k) + f (k))T (− ˆLx(k) + f (k))

(48)

For the constant attack signal f (k + 1) = f (k), one can write
(48) as

= (− ˆLx(k + 1) + f (k))T (− ˆLx(k + 1) + f (k))
−(− ˆLx(k) + f (k))T (− ˆLx(k) + f (k))

or equivalently,

= (− ˆLx(k + 1))T (− ˆLx(k + 1)) − (− ˆLx(k))T (− ˆLx(k))
−2 f (k)T ˆL(x(k + 1) − x(k))

(49)

Using the scalar system dynamics (45) in (49), one has

= (− ˆL[x(k) + u(k)])T (− ˆL[x(k) + u(k)])
−(− ˆLx(k))T (− ˆLx(k)) − 2 f (k)T ˆLu(k)

(50)

Fig. 1: Graph topology

x3(k + 1) = x3(k) + u3(k) = 0
⇒ x3(k) + (1 + h3)−1(x2(k) − x3(k)) = 0
⇒ (x2(k) + x3(k)) = 0

x4(k + 1) = x4(k) + u4(k) = 0
⇒ x4(k) + (1 + h4)−1(x1(k) − x4(k)) = 0
⇒ (x1(k) + x4(k)) = 0

(40)

(41)

However, the dynamics in (38) and (39) show that to reach a
steady state, (x1(k) + x2(k)) = −2 and (x1(k) + x2(k)) = 0 at
same time. This is not possible for consensus on a bounded
state, and this can happen only, if they both go to inﬁnity.
Therefore, the system states never achieve the desired consen-
sus behavior and they converge to inﬁnity.

When Agent 1 is attacked with an IMP-based adversarial

input uac = 1, using Z-transform, one has

(z − 1)x1(z) = u1(z) + uac(z) ⇒ x1(z) =

u1(z)
(z − 1)

+

z
(z − 1)2

(42)
It can be seen from (42) that an IMP-based attack can desta-
bilize the entire system. This veriﬁes the results of Theorem
3.

Now, we present the analysis of the effects of the attack on
the local neighborhood tracking error (2). This analysis shows
that although attacks on sensors and actuators can be modeled
as disturbances, existing disturbance attenuation techniques do
not work for attack attenuation.

Disturbance attenuation approaches focus on minimizing the
effects of disturbance on the local neighborhood tracking error
[41]-[42]. More speciﬁcally, the H∞ approach for DMAS (1)
in presence of disturbance wi(k) designs a distributed control
protocol as in (3), such that the desired consensus is achieved
as in (8), if disturbance wi(k) = 0 and the bounded L2-gain
condition is fulﬁlled for any disturbance wi(k) ∈ L2[0, ∞)

∞
∑
k=0

ε T (k) ¯Mε(k) (cid:54) γ 2

∞
∑
k=0

wT (k) ¯Nw(k)

(43)

where γ > 0 is attenuation constant,
deﬁnite weight matrices.

¯M and ¯N are positive

We present the following rigorous analysis for the effects
of the attack on the local neighborhood tracking error in
following Theorem 4 and show that how an attacker can

Using (46), equation (50) can be written as

= (− ˆL[x(k) − ˆLx(k) + f (k))])T (− ˆL[x(k) − ˆLx(k) + f (k))])
−(− ˆLx(k))T (− ˆLx(k)) − 2 f (k)T ˆL(− ˆLx(k) + f (k)))

(51)

assumption. Therefore, this shows that the intact agent i is
deviated from the desired consensus value. Similarly, one can
use the same argument to show that all reachable agents from
the compromised agent will deviate from the desired consensus
(cid:3)
value. This completes the proof.

one can further simplify (51) as

= (− ˆLx(k) + f (k))T [ ˆLT ˆL − 2 ˆL](− ˆLx(k) + f (k))

(52)

Using Lemma 2, one has

∆V (x(k), f (k)) = (− ˆLx(k) + f (k))T [ ˆLT ˆL
−2 ˆL](− ˆLx(k) + f (k)) (cid:54) 0

(53)

Then, using Lasalle’s invariance principle [43], the trajectories
(x(k), f (k)) converge to a set that satisfy ∆V (x(k), f (k)) = 0.
Based on (53), this yields

(− ˆLx(k) + f (k)) ∈ ker( ˆLT ˆL − 2 ˆL)

or

(− ˆLx(k) + f (k)) = 0

(54)

(55)

From (54), one has (− ˆLx(k) + f (k)) = ¯c1N. According to
this, the single integrator system dynamics becomes xi(k +
1) = xi(k) + ¯c, which shows that it destabilizes the system.
Therefore, xi(k) → ∞ as k → ∞ ∀i = 1, . . . , N with the local
neighborhood tracking error goes to zero for all agent. Note
that, based on Theorem 3, (54) is the possible case when the
attack is on a root node. On the other hand, for an attack on a
non-root node agent, from (55), one has (− ˆLx(k) + f (k)) = 0.
Since for the intact agent i,
fi(k) = 0, therefore, the local
neighborhood tracking error for intact agents converge to zero,
even in the presence of the attack.

We now show that intact agents do not reach the desired
consensus, despite the fact the local neighborhood tracking
error is zero. From (55), one has

ˆLx(k) = f (k)

(56)

which can be written for agent i as

(1 + hi)−1

N
∑
j=1

ai j(x j(k) − xi(k)) = fi(k)

(57)

For a compromised agent i, since fi(k) (cid:54)= 0, then, one has
xi(k) (cid:54)= x j(k) for some i, j.

Now let assume that agent i is intact. Then, one has

Consider the intact agent i as an immediate neighbor of the
compromised agent ic. Let assume by contradiction that only
the compromised agent does not reach the desired consensus
but all the intact agents reach the desired consensus. Using
(58), one can write

(1 + hi)−1 ∑
j∈Ni

ai j(x j − xi)+aiic(xic − xi) = 0

(59)

intact agents

reach consensus, xi(k) =
Assuming that
x j(k) ∀ j ∈ Ni. However, (59) cannot be satisﬁed if xi(k) =
x j(k) ∀ j ∈ Ni because xic (k) (cid:54)= xi(k) and this contradict the

Remark 3. If an intact agent i is an immediate neighbor of a
compromised agent ic, then using (2), one can write the local
neighborhood tracking error εi(k) with ai j = 1 as
εi(k) = (1 + hi)−1 ∑
j∈Ni
1
|Ni| ∑
j∈Ni
= |Ni| (1 + hi)−1(xavg − xi)

= |Ni| (1 + hi)−1(

(x j(k) − xi(k))

x j(k) − xi)

(60)

x j(k)

∑
j∈Ni

|Ni|

, which is not equal to xi(k) due to
where xavg =
incoming information from a comprised agent xic(k). From
(60), one can infer that the deviation of the intact agent from
the desired consensus value depends on the number of the in-
neighbors and deviation of the compromised agent ic from the
desired consensus value which depends on the magnitude of
the injected attack signal. Moreover, the closer the agent is to
the source of the attack, the more its value will be deviated
from the desired consensus.

Corollary 1. Let the attacker design its attack signal using
the internal model principle approach described in Theorem
3. Then, it bypasses the H∞ control protocol.
Proof. In the absence of the attack, minimizing the local neigh-
borhood tracking error results in minimizing the consensus
error. Therefore, the H∞ control in (43) is used to attenuate the
effect of adversarial input on the local neighborhood tracking
error. However, according to Theorem 4, in the presence of
IMP attack, by making the local neighborhood tracking error
go to zero, agents do not reach consensus. This completes the
(cid:3)
proof.

Theorem 4 and the following analysis highlight that while
the local neighborhood tracking error is zero, agents might not
reach consensus. Now, deﬁne a global performance function
Γ(k) as

Γ(k) = ∑
i∈N

∑
j∈Ni

(cid:13)
(cid:13)xi(k) − x j(k)(cid:13)
2
(cid:13)

Deﬁne the set of intact agents as

(61)

(62)

where N represents set of all agents and Nc represents set of
compromised agents in the network.

Corollary 2. Consider the global performance function Γ(k)
and the local neighborhood tracking error εi(k) deﬁned in (61)
and (3), respectively. Then,

1) Γ(k) and εi(k) ∀i = 1, . . . , N converge to zero, if there is
no attack. Moreover, agents achieve the desired consen-
sus.

2) If the attacker designs an IMP-based attack on the
non-root node, then εi(k) ∀i ∈ Nint converges to zero,
but Γ(k) does not converges to zero. That is, agents

(1 + hi)−1

N
∑
j=1

ai j(x j(k) − xi(k)) = 0

(58)

Nint = N − Nc

do not reach the desired consensus, while the local
neighborhood tracking error is zero.

3) If the attacker designs an IMP-based attack on the root
node, then εi(k) and Γ(k) ∀i = 1, . . . , N go to zero,
despite agents do not achieve the desired consensus and
the entire system get destabilized.

Proof. According to Theorem 1,
the system achieves the
desired consensus if there is no adversarial input in the system
and this proves part 1 of corollary. If the attacker injects
an IMP-based attack signal into the non-root node of the
DMAS,
then based on Theorem, 3 and 4, one can infer
εi(k) → 0. However, as shown in Theorem 4, xi(k)−x j(k) (cid:54)→ 0,
so Γ(k) (cid:54)→ 0 and this proves part 2. Based on Theorem 3, if the
attacker injects an IMP-based attack signal into the root node
of the DMAS, then xi(k) − x j(k) → 0. However, the system
gets destabilized as xi(k) → ∞ as k → ∞, while εi(k) and Γ(k)
∀i = 1, . . . , N converge to zero. This completes the proof. (cid:3)

Remark 4. The attacker can deceive the existing H∞ con-
troller by using its IMP-based adversarial input. Although the
global performance function Γ(k) reﬂects the adverse effect
of the attacks, the local neighborhood tracking error does not.
Therefore, the local performance measure does not ensure the
global performance of the DMAS under the inﬂuence of the
sophisticated attacks. This analysis reinforces the design of
resilient control protocol to mitigate the adverse effects of the
attack.

IV. RESILIENT DISTRIBUTED CONTROL PROTOCOL FOR
ATTACKS ON SENSOR AND ACTUATOR : AN ADAPTIVE
APPROACH

This section presents the design of a resilient distributed
control protocol for the mitigation of the adverse effect of
attacks on sensors and actuators of an agent in the discrete-
time DMAS. Regardless of the magnitude of attack f (k) on
sensors and actuators of an agent and its reachability from
intact agents, our distributed adaptive compensator is resilient
against attacks and avoids catastrophic effects. To this end,
ﬁrst, the expected normal behavior of each agent is predicted
using an observer-like predictor (called here expected state
predictor), which employs the agent’s dynamics to predict its
expected normal state at each time step. This expected state
predictor does not use any actual state measurement, and,
instead, calculates the expected normal state of the agent based
on the evolution rule of its dynamics, and taking into account
the local information it receives from its neighbors. Then, a
distributed adaptive compensator is designed using predicted
behavior of agents to compensate for any discrepancy between
the actual state and its predicted normal one.
Consider the estimated state for agent

i as ˆxi(k). The

distributed expected state predictor is designed as

ˆxi(k + 1) = A ˆxi(k) + cBK(1 + hi)−1

N
∑
j=1

ai j( ˆx j − ˆxi)

(63)

where the gain K and the coupling coefﬁcient c are to be
designed to ensure Ac in (7) is Schur. The global expected

state predictor state vector for (63) can be written as ˆx(k) =
[ ˆxT

N(k)]T ∈ RnN.

2 (k), . . . , ˆxT

1 (k), ˆxT

Lemma 3. Consider the N expected state predictors given in
(63). Let the feedback gain K and coupling coefﬁcient c are
designed to ensure Ac in (7) is Schur. Then, the expected state
predictor state ˆx(k) converges to the desired consensus value.

Proof. The designed expected state predictor in (63) can be
expressed as

ˆxi(k + 1) = A ˆxi(k) + B ˆui(k)

where

ˆui(k) = cK ˆεi(k)

(64)

(65)

with the local neighborhood tracking error ˆε(k) as

ˆεi(k) = (1 + hi)−1

N
∑
j=1

ai j( ˆx j − ˆxi))

(66)

One can write the global expected state predictor state dynam-
ics as

which yields

ˆx(k + 1) = Ac ˆx(k) ∈ RnN

ˆx(k) = Ak

c ˆx(0) ∈ RnN

(67)

(68)

As A − cλiBK is Schur stable, with λi be the eigenvalues of
the normalized graph Laplacian matrix ˆL for i = 2, . . . , N and
λ1 = 0. Therefore, the expected state predictor states achieve
the desired consensus value and written as




ˆx(k) = (rT ⊗ Ak)

i = 1, . . . , N as k → ∞

(69)

ˆx1(0)
.
.
ˆxN(0)









(cid:3)
Remark 5. Note that a broad class of the DMAS includes
the leader-follower or the containment control problem (i.e.
MAS with multiple-leader) for which even if the ˆxi(0) (cid:54)= xi(0),
Lemma 3 is valid. This is because, the reference trajectory to
be followed by agents is determined by the leaders, which are
assumed to be trusted by using more advanced sensors and
investing more security. The system (63) acts as a reference
model for the agents and if ˆxi(0) (cid:54)= xi(0), even for the intact
DMAS, di in (73) will be nonzero until the difference between
the initial conditions is gone. Agents converge to the desired
behavior irrespective of initial values.

Although the attacks on actuators and/or sensors can ad-
versely affect the agents dynamics, they cannot affect the
dynamics of the distributed expected state predictor (63),
unless they entirely compromise the agent which is extremely
harder to do for the attacker.

The deviation of the agent’s behavior from the normal
behavior is estimated by distributed expected state predictor.
Then, an adaptive attack compensator is developed using an
expected state predictor. The designed adaptive compensator
is augmented with the controller for the mitigation of the
adversarial input.

The update for the distributed adaptive compensator is de-
signed as

di(k + 1) = θ cK(ˆεi(k) − ¯εi(k)) + θ di(k)

(75)

where θ > 0 is a design parameter, and ¯εi(k) and ˆεi(k) are
deﬁned in (74) and (66).

Remark 6. The information exchanged among agents in (74)
is the corrupted state measurement xc
i (k) deﬁned in (10) which
is different from xi(k) deﬁned in (11). However, if the agent
i is intact or only under actuator attack, then xc
i (k) = xi(k). If
attacker corrupt the sensor data, then xc
i (k) (cid:54)= xi(k). In most
of the existing DMAS work, it is assumed the states of the
agents are measurable and also we consider the same in our
work. Therefore, the attack on the sensor corrupts the state
measurements.

According to Lemma 3, the expected state predictor con-
verges to the desired consensus value. Therefore, consensus
of DMAS can be achieved by showing the convergence of
the agent state xi(k) to the predicted state ˆxi(k). Deﬁne the
consensus error ˜x(k) as

˜x(k) = x(k) − ˆx(k)

(76)

In the following theorem, we show that

the consensus
error remains bounded using the proposed resilient adaptive
controller.

Theorem 5. Consider the DMAS (11) under attacks on sensors
and actuators. Let the control protocol be developed as (73)-
(75). Then, the agent’s consensus errors deﬁned in (76) are
bounded, and the bound can be made arbitrarily small, despite
the attack.

Proof. According to Lemma 4, the expected state predictor
converges to the desired consensus value. Therefore, consensus
of discrete-time DMAS can be achieved by showing the
convergence of the agent state xi(k) to the predicted state ˆxi(k).
Then, with (11) and (64), one can write ˜x(k + 1) as

˜x(k + 1) = (IN ⊗ A − c ˆL ⊗ BK) ˜x(k) − (IN ⊗ B) ˜d(k)

(77)

where

˜d(k) = d(k) − f (k)

(78)

rejection

1 (k), dT

attack
2 (k), . . . , dT

d(k) =
denotes
[dT
the global adaptive
compensator vector and the dynamics of the attack f (k) is
deﬁned in (22).

N (k)]T ∈ RnN as

error

with

Using (75), the global dynamics of the adaptive compen-

sator can be written as

d(k + 1) = θ c ˆL ⊗ ¯R−1

1 BT P1A ˜x(k) + θ ˜d(k) + θ ¯f (k)

(79)

where ¯R1 = R1 + BT P1B and ¯f (k) = 2 f (k) − (γ ⊗ IN)ua. Note
that ¯f (k) = f (k) only if the actuator of the agent is compro-
2 > 0 as Q2 = cR2(I + H)−1L = cR2 ˆL
mised. Deﬁne Q2 = QT
with some positive deﬁnite R2. Let
the real part of the
minimum eigenvalue of the normalized graph Laplacian matrix
ˆL be λm.

Deﬁne the Lyapunov candidate function function as

Fig. 2: Architecture of the proposed adaptive resilient controller. Si represents the sensor
of agent i∀i = 1, . . . , N.

In contrast to existing detection-removing approaches [15]-
[23], which require a strong network connectivity, the devel-
oped resilient distributed controller preserves network topol-
ogy and achieves the desired consensus without any restric-
tions on the number of agents under sensor and actuator
attacks. Attacks on communication links i.e. denial of service
(DoS) attack can be mitigated by integrating existing attack
detection/identiﬁcation methodologies [15]-[23] with the pro-
posed approach. Therefore, agents under the inﬂuence of the
adversarial input on sensors and actuators can be recovered
using the proposed resilient controller and be brought back to
the network in intact mode without being isolated.

We now design a distributed resilient control protocol as

ui,r(k) = ui(k) + ui,comp(k)

(70)

where, ui(k) represents standard control protocol deﬁned in (3)
and ui,comp(k) represents the distributed adaptive compensator
protocol responsible for rejection of the adversarial input.

Consider the feedback gain K in the control protocol (3)

given as

K = (R1 + BT P1B)−1BT P1A = ¯R−1

1 BT P1A

(71)

where R1 is a positive deﬁnite design matrix, and P1 is solution
of

AT P1A − P1 − AT P1B(R1 + BT P1B)−1BT P1A = Q1

(72)

with a positive deﬁnite matrix Q1.

The designed distributed control protocol is given by

ui,r(k) = cK ¯εi(k) − di(k)

(73)

where di(k) is the estimated response of the adaptive com-
pensator and K is the gain given by (71) and (72). The local
neighborhood tracking error ¯εi(k) in (73) is given by

¯εi(k) = (1 + hi)−1

N
∑
j=1

ai j(xc

j(k) − xc

i (k))

(74)

V (k) = ˜xT (k)(Q2 ⊗ P1) ˜x(k) + θ −2 ˜dT (k)(R2 ⊗ ¯R1) ˜d(k)

(80)

The difference equation of the Lyapunov candidate function
can be written as

(cid:124)

∆V (k) = V (k + 1) −V (k)
= ˜xT (k + 1)(Q2 ⊗ P1) ˜x(k + 1) − ˜xT (k)(Q2 ⊗ P1) ˜x(k)
(cid:123)(cid:122)
(cid:125)
part 1
+ θ −1 ˜dT (k + 1)(R2 ⊗ R1) ˜d(k + 1) − θ −1 ˜dT (k)(R2 ⊗ R1) ˜d(k)
(cid:123)(cid:122)
(cid:125)
part 2

(cid:124)

(81)

Using (77), part 1 of the difference equation of the Lyapunov
candidate function (81) can be expressed as
= ˜xT (k)(Q2 ⊗ AT P1A − 2cQ2 ˆL ⊗ AT P1BK
+c2 ˆLT Q2 ˆL ⊗ (BK)T P1BK − (Q2 ⊗ P1)) ˜x(k)
−2 ˜xT (k)[Q2 ⊗ AT P1B − c ˆLT Q2 ⊗ (BK)T P1B] ˜d(k)
+ ˜dT (k)(Q2 ⊗ BT P1B) ˜d(k)

(82)

Using the Young’s inequality, one can further simplify and
express (82) as
(cid:54) − ˜xT (k)(Q2 ⊗ Q1) ˜x(k) − ˜xT (k)(−Q2 + 2cQ2 ˆL) ⊗ AT P1BK) ˜x(k)

+2c2λmin(c2 ˆLT ˆLλmin(T Q−1
−2 ˜xT (k)(Q2 ⊗ AT P1B) ˜d(k) + 2 ˜dT (k)(Q2 ⊗ BT P1B) ˜d(k)

1 )) ˜xT (k)(Q2 ⊗ Q1) ˜x(k)

(83)

where T = KT BT P1BK. We now consider the part 2 of the
difference equation of the Lyapunov candidate function in (81)
as

θ −2 ˜dT (k + 1)(R2 ⊗ ¯R1) ˜d(k + 1) − θ −2 ˜dT (k)(R2 ⊗ ¯R1) ˜d(k)

(84)

where ¯R1 = (R1 + BT P1B) is a positive deﬁnite matrix. Using
(78), one can express (84) as

1
θ 2 [dT (k + 1)(R2 ⊗ ¯R1)d(k + 1) − 2dT (k + 1)(R2 ⊗ ¯R1) f (k + 1)
+ f T (k + 1)(R2 ⊗ ¯R1)( f (k + 1) − ˜dT (k)(R2 ⊗ ¯R1) ˜d(k)]

(85)

Using the dynamics of the distributed adaptive compensator
in (79) with (85), one has
= ˜xT (k)(c ˆLT Q2 ⊗ KT BT P1A) ˜x(k) + 2 ˜dT (k)(Q2 ⊗ BT P1A) ˜x(k)
+2[ ¯f (k) − θ −1 f (k + 1)]T (Q2 ⊗ BT P1A) ˜x(k)
+(1 − θ −2) ˜dT (k)(R2 ⊗ ¯R1) ˜d(k)
+[ ¯f (k) − θ −1 f (k + 1)]T (R2 ⊗ ¯R1) ˜d(k)
+[ ¯f (k) − θ −1 f (k + 1)]T (R2 ⊗ ¯R1)[ ¯f (k) − θ −1 f (k + 1)]

(86)

Using the Young’s inequality, one can simplify (86) as

3
2

≤

˜xT (k)(cQ2 ˆL ⊗ AT P1BK) ˜x(k) + 2 ˜dT (k)(Q2 ⊗ BT P1A) ˜x(k)

+(2 − θ −2) ˜dT (k)(R2 ⊗ ¯R1) ˜d(k)
+4[ ¯f (k) − θ −1ψ(k) f (k)]T (R2 ⊗ ¯R1)[ ¯f (k) − θ −1ψ(k) f (k)]

where ψ(k) denotes how the value of attack signal changes at
next time instant. If attack signal is constant, i.e., f (k + 1) =

(87)

f (k), then ψ(k) = 1. Thus, one can infer that ψ(k) is always
bounded, i.e., |ψ(k)| < ζ ∀ k. Integrating equation (83) and
(87) with further simpliﬁcation, one has

∆V (cid:54) − ˜xT (k)(Q2 ⊗ Q1) ˜x(k)

1
2

cQ2 ˆL) ⊗ AT P1BK) ˜x(k)

− ˜xT (k)(−Q2 +
+2c2λmin( ˆLT ˆL)λmin(T Q−1
− (θ −2 − 2 − 2λmin(c ˆLBT P1B ¯R−1
+4[ ¯f (k) − θ −1ζ f (k)]T (R2 ⊗ ¯R1)[ ¯f (k) − θ −1ζ f (k)]

1 )) ˜xT (k)(Q2 ⊗ Q1) ˜x(k)

1 ) ˜dT (k)(R2 ⊗ ¯R1) ˜d(k)

(88)

One can show that ∆V ≤ 0, if the coupling coefﬁcient satisﬁes
2
λm

< c <

and

(cid:113)

1

λm

2λmin(T Q−1
1 )

(cid:13) ˜d(k)(cid:13)
(cid:13)

(cid:13) >

(cid:13)( ¯f (k) − θ −1ζ f (k))(cid:13)
4 (cid:13)
(cid:13)
θ −2 − 2 − 2λmin(c ˆLBT P1B ¯R−1
1 )

(89)

The design parameter θ

chosen such θ <
and then, one can ensure the bound in

can be

(cid:113)

1
2+λmin(c ˆLBT P1B ¯R−1
1 )

(89). This shows that the agent’s consensus error is bounded.
Therefore, the actual agent’s state x(k) achieve the desired
consensus behavior with a bounded error that can be made
arbitrarily small by appropriate selection of design parameter
(cid:3)
θ . This completes the proof.

Remark 7. The coupling coefﬁcient c needs to be in a
certain range which depends on the λm and λmin(T Q−1
1 ). This
condition is standard in the literature of DMAS [36]. On
the other hand, the condition for the bound on ˜d(k) in (89)
depends on the design parameters θ , and one can select this
parameter to satisfy (89) which ensures ∆V ≤ 0. Thus, the
bound on consensus error can be made arbitrarily small based
on selection of design parameter θ . Moreover, this bound
is conservative, and as shown in the simulation results, the
consensus error almost goes to zero.

Remark 8. As presented in Theorem 4 and Corollary 2, exist-
ing H∞ approaches minimize the local neighborhood tracking
error of the system εi(k) and are not capable of attenuating
sophisticated attacks. In contrast,
the designed distributed
resilient control can successfully attenuate the adverse effects
of attacks using the distributed adaptive compensator. The
developed compensator di(k) in (79) minimizes the deviation
of the local neighborhood tracking error of the system εi(k)
from the local neighborhood tracking error of the expected
state predictor ˆεi(k). We can also infer that, although the
proposed controller is designed for leaderless multi-agent
systems, it can be used for the leader-follower systems and
the containment control systems.

Remark 9. Compromised agents under the effect of the sensor
attack might not be recovered completely and result a non-
zero bound in (88). The proposed distributed adaptive law
compensates the difference between the incoming neighboring
sensor measurement (xc
i (k)) and the desired state ˆxi(k) and
xc
i (k) (cid:54)= xi(k) in the case of sensor attack. Under the actuator
attack xc
i (k) = xi(k) and the error bound for (88) can be made
arbitrarily small.

V. SIMULATION RESULTS

This section presents simulation results to validate the ef-
fectiveness of the presented work. We consider both leaderless
as well as leader-follower network for the simulation. First, a
leader-follower network of autonomous underwater vehicle’s
(AUV’s) in Fig. 3 is considered for the evaluation of the
presented results. Then, the leaderless network is considered.

A. Leader-follower Network

The communication network is shown in Fig.3 for a set
of Sentry AUVs. Sentry AUV is manufactured by the Woods
Hole Oceanographic Institution [44]. The linearized model of
the Sentry is of 6 DOF, but it is generally decomposed into
four non-interacting subsystems which are speed subsystem
(u), the roll subsystem (φ ), the steering subsystem (ν, r, ψ),
the diving subsystem (ω, q, z, θ ). Here, we focus on the diving
subsystem of Sentry AUV for the desired depth maneuvering
in the leader-follower network.

sinusoidal trajectory, respectively. Since the leader input is
non-zero, slightly different discrete-time control protocol from
that the one proposed in the paper is used for which the leader
exchanges its input signal u0 with its neighbors and agents
reach consensus by exchanging states and leader’s input. This,
however, does not change our attack analysis and mitigation.
The state feedback gain K0 is given by
(cid:20) - 0.18
1.56

-2.25
5.39

-0.21
1.59

0.13
0.49

K0 =

(cid:21)

In the absence of the attack, agents follow the desired depth
trajectory and illustrate the healthy behavior of the network as
shown in Fig. 5.

Fig. 4: Graph topology

Fig. 3: Distributed network of AUVs under the inﬂuence of attack

The graph topology for Fig. 3 is shown in Fig. 4 for the
team of Sentry AUVs communicating with each other with
the following diving subsystem dynamics

Fig. 5: Agents depth trajectory in healthy mode

where

and

A =





xi(k + 1) = Axi(k) + Bui(k)


0.65
0.21
0.83
0.11


B =





0.54
1.48
0.84
1.21

0.08
- 0.13
0.02
- 0.07







0.0 -0.0019
-0.01
0.0
0.99
1.0
0.99
0.0


0.13
0.20
0.09
0.09





i (k), δ b

xi(k) = [(ωi(k), qi(k), zi(k), θi(k))]T ,
i (k), δ b

and
with
i (k)]T , where (ωi(k), qi(k), zi(k), θi(k))
ui(k) = [δ b
and δ b
i (k) represent the heave speed, pitch rate, depth
and pitch, and bone and stern plane deﬂections, respectively.
In the network communication graph, we assumed that the
agent 0 represents a active non-autonomous leader which aim
to follow a desired sinusoidal depth trajectory and agents
1 to 5 designate the followers. The leader has the control
input u0(k) = K0x0(k) + r(k), where K0 is state feedback gain,
x0 denotes the leader state and r(k) represents the desired

(a)

(b)

Fig. 6: The Agents depth trajectory under the inﬂuence of the attack on AUV 3. (a)
Depth without adaptive compensator (b) The local neighborhood tracking error without
adaptive compensator

20406080100120140Time (s)5101520Depth (m)LeaderAgent 1Agent 2Agent 3Agent 4Agent 520406080100120140Time (s)5101520Depth (m)LeaderAgent 1Agent 2Agent 3Agent 4Agent 56570758014161820406080100120140Time (s)-1.5-1-0.500.511.5 Error (m)Agent 1Agent 2Agent 3Agent 4Agent 5Now, the effect of the attack on a non-root node is analyzed.

First, we consider the attack on actuators of Agent

(a)

(b)

Fig. 7: The Agents depth trajectory under the inﬂuence of the attack on AUV 3. (a)
Depth with adaptive compensator (b) The local neighborhood tracking error with adaptive
compensator

3 (non-root node) with time-varying attack signal ua
3(k) =
[10sin(k) 10sin(k)](cid:48) at t = 61 sec. Fig. 6(a) and (b) show
that agents which are reachable from the compromised Agent
3 are deviated from the desired behavior, despite the local
neighborhood tracking error goes to zero for intact agents.
These results follow the Theorem 2 and Theorem 4.

Then, Fig. 7(a) and (b) illustrate the response of the system
under the inﬂuence of the attacks using the proposed controller
(73) from t=61 sec with Q1 and R1 be identity matrix in (71)
and (72), respectively. The system states achieve the desired
consensus behavior and the local neighborhood tracking error
goes to almost zero, even in the presence of the attack. These
results demonstrate the effectiveness of the proposed resilient
controller.

Now, consider the effect of constant attack signal on actu-
ators of the Agent 2 (root-node) given by ua
2(k) = [5 5](cid:48) at
t = 61 sec. Fig. 8(a) shows that the compromised agent affect
the reachable agents after attack. Now, the proposed resilient
control protocol in (73) with adaptive attack compensator in
(75) is applied at t=61sec in the distributed network and Fig.
8(b) shows that the system states achieve the desired consensus
behavior, even in the presence of the attack.
B. Leaderless Network

Now, consider the same graph topology in Fig. 4 for
leaderless DMAS for 5 agents without leader Agent 0. For
leaderless system the dynamics of agent i is considered as

xi(k + 1) =

(cid:20) 0 −1
0
1
f or i = 1, . . . , 5

(cid:21)

xi(k) +

(cid:21)

(cid:20) 0
1

ui(k)

(90)

First, the effect of the attack on a root node is analyzed

with the IMP-based attack signal.

(a)

(b)

(a)

(b)

Fig. 8: The Agents depth trajectory under the inﬂuence of the attack on AUV 2. (a)
Depth without adaptive compensator (b) The local neighborhood tracking error without
adaptive compensator

Fig. 9: The DMAS response under the effect of IMP-based attack on agent 2 (root node)
with adaptive compensator. (a) The agent’s state without adaptive compensator (b) The
agent’s state with adaptive compensator

20406080100120140Time (s)5101520Depth (m)LeaderAgent 1Agent 2Agent 3Agent 4Agent 520406080100120140Time (s)-1.5-1-0.500.511.5 Error (m)Agent 1Agent 2Agent 3Agent 4Agent 520406080100120140Time (s)5101520Depth (m)LeaderAgent 1Agent 2Agent 3Agent 4Agent 5727476788082Time (s)161820406080100120140Time (s)5101520Depth (m)LeaderAgent 1Agent 2Agent 3Agent 4Agent 51020304050607080Time (s)-100-50050100Agent 1Agent 2Agent 3Agent 4Agent 51020304050607080Time (s)-2-1012Agent 1Agent 2Agent 3Agent 4Agent 5the proposed resilient control protocol

compromised agent destabilizes the entire network. All agents
of the DMAS deviate from the desired consensus behavior.
The simulation results verify Theorem 2 and Theorem 3. Let
Q1 and R1 be identity matrix in (71) and (72), respectively.
Now,
in (73) with
adaptive attack compensator in (75) is incorporated and Fig.
9(b) shows the response of the system. The system states
achieve the desired consensus behavior, even in the presence
of the attack on root node. This illustrates the mitigation of
sophisticated attack using the designed resilient controller.

Now, we present the results for the effect of the attack
on a non-root node. Consider an IMP-based attack signal
is launched on actuator of Agent 3 (non-root node) i.e.
ua
3(k) = sin(k). Fig. 10(a) and (b) show that Agents 4 and
5 which are reachable from the compromised Agent 3 do
not converge to the desired consensus value and the local
neighborhood tracking error goes to zero for intact agents.
These results comply with Theorem 3 and Theorem 4. Then,
in (73) with adaptive attack
the resilient control protocol
compensator in (75) is used. Fig. 11(a) and (b) illustrate that
the system states achieve the desired consensus behavior and
the local neighborhood tracking error goes to zero, even in the
presence of the attack on non-root node 3. This demonstrates
the mitigation of attack using the developed resilient controller.

(a)

(b)

Fig. 10: The DMAS response under the effect of IMP-based attack on agent 3 (non-root
node) without adaptive compensator. (a) The agent’s state (b) The local neighborhood
tracking error

VI. CONCLUSION

their mitigation. It

This paper presents a rigorous analysis of the effects of
attacks for leaderless discrete-time DMAS and designs a
resilient distributed control protocol
is
shown that the attack on a compromised agent can propagate
through the entire network and affects intact agents those are
reachable from it. Then, the IMP for the attacker shows that
an attack on a single root node can destabilize the entire
network. The attacker does not require to know about the
communication graph and the system dynamics. Furthermore,
the ineffectiveness of existing robust approach is discussed for
sophisticated attacks. To overcome the effect of the attacks on
sensor and actuators of the agent in discrete-time DMAS, a
resilient controller is developed based on an expected state
predictor. The presented controller shows that the attack on
sensor and actuator can be mitigated without compromising
the connectivity of the network and achieves the desired
consensus. Although we have considered a general leaderless
consensus problem for the proposed controller, it can be used
for the other DMAS problems such as leader-follower and
containment control problem. The analysis and effectiveness
of the presented work have shown in simulation results.

REFERENCES

[1] R. Olfati-Saber, J. A. Fax, and R. M. Murray, “Consensus and cooper-
ation in networked multi-agent systems”, Proceedings of the IEEE, vol.
95, pp. 215-233, 2007.

[2] J. A. Fax, and R. M. Murray, “Information ﬂow and cooperative control
of vehicle formations”, IEEE Transactions on Automatic Control, vol.
49, no. 9, pp. 1465-1476, 2004.

[3] F. Bullo, J. Cort´es, and S. Mart´ınez, Distributed control of robotic
networks: a mathematical approach to motion coordination algorithms,
Princeton University Press, 2009.

(a)

(b)

Fig. 11: The DMAS response under the effect of IMP-based attack on agent 3 (non-
root node) with adaptive compensator. (a) The agent’s state (b) The local neighborhood
tracking error

Consider the effect of attack on actuator of Agent 2 by IMP-
based attack signal i.e. ua
2(k) = sin(k). Fig. 9(a) shows that the

1020304050607080Time (s)-4-2024Agent 1Agent 2Agent 3Agent 4Agent 51020304050607080Time (s)-2-1012Agent 1Agent 2Agent 3Agent 4Agent 51020304050607080Time (s)-2-1012Agent 1Agent 2Agent 3Agent 4Agent 51020304050607080Time (s)-1-0.500.51Agent 1Agent 2Agent 3Agent 4Agent 5[28] A. Hota, and S. Sundaram, “Interdependent security games on networks
under behavioral probability weighting”, IEEE Transactions on Control
of Network Systems, vol. 5, no. 1, pp. 262-273, 2018.

[29] M. Zhu, and S. Mart´ınez, “On distributed constrained formation control
in operatorvehicle adversarial networks,” Automatica, vol. 49, no. 12,
pp. 3571-3582, 2013.

[30] M. Zhu, and S. Mart´ınez, “On the performance analysis of resilient
networked control systems under replay attacks,” IEEE Transactions on
Automatic Control, vol. 59, no. 3, pp.804-808, 2014.

[31] M. Zhu, and S. Mart´ınez, “Consensus-based distributed optimization
with malicious nodes,” In Proceedings of Communication, Control, and
Computing (Allerton), pp. 244-249, 2015.

[32] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and control for
cyber-physical systems under adversarial attacks,” IEEE Transactions on
Automatic Control, vol. 59, no. 6, pp. 1454-1467, 2014.

[33] Y. Shoukry, P. Nuzzo, A. Puggelli, A.L. Sangiovanni-Vincentelli, S.A.
Seshia, and P. Tabuada, “Secure state estimation for cyber physical
systems under sensor attacks: a satisﬁability modulo theory approach,”
IEEE Transactions on Automatic Control, vol. 62, no. 10, pp. 4917-4932,
2017.

[34] G. D. Torre and T. Yucelen, “Adaptive architectures for resilient control
of networked multi-agent systems in the presence of misbehaving
agents,” International Journal of Control, pp. 1-13, 2017.

[35] X. Jin, W.M. Haddad, and T. Yucelen, “An adaptive control architecture
for mitigating sensor and actuator attacks in cyber-physical systems,”
IEEE Transactions on Automatic Control, vol. 91, no. 3, pp. 1-13, 2017.
[36] F. Lewis, H. Zhang, K. Hengster-Movric, and A. Das, Cooperative Con-
trol of Multi-Agent Systems: Optimal and Adaptive Design Approaches,
Communications and Control Engineering, Springer, London, 2013.
[37] Z. Li, and Z. Duan, Cooperative Control of Multi-Agent Systems:
A Consensus Region Approach, Automation and Control Engineering,
Taylor and Francis, 2014.

[38] K.G. Vamvoudakis, F. L. Lewis, and G. R. Hudas, “Multi-agent differ-
ential graphical games: Online adaptive learning solution for synchro-
nization with optimality”, Automatica, vol. 48, no. 8, pp. 1598-1611,
2012.

[39] Y. Su, and J. Huang, “Stability of a class of linear switching systems
with applications to two consensus problems”,” IEEE Transactions on
Automatic Control, vol. 57, no. 6, pp. 1420-1430, 2012.

[40] D. Harville, Matrix algebra from a statistician’s perspective, Springer-

Verlag New York, 1997.

[41] Q. Jiao, H. Modares, F. L. Lewis, S. Xu, and L. Xie, “Distributed gain
output-feedback control of homogeneous and heterogeneous systems”,
Automatica, vol. 71, pp. 361-368, 2016.

[42] Q. Liu, Z. Wang, X. He, and D. Zhou, “Event-Based H∞ Consensus
control of multi-Agent systems With relative output Feedback: The
ﬁnite-horizon case”, IEEE Transactions on Automatic Control, vol. 60,
no. 9, pp. 2553-2558, 2015.

[43] A. Isidori, Nonlinear Control Systems, Springer Science and Business

Media, 2013.

[44] M. V. Jakuba, “Modeling and control of an autonomous underwater
vehicle with combined foil/thruster actuators,” M.S. thesis, Dept. Mech.
Eng., MIT Woods Hole Oceanographic Inst., Cambridge, MA, USA,
2003.

[4] A. Jadbabaie, J. Lin, and A. Morse, “Coordination of groups of mobile
autonomous agents using nearest neighbor rules”, IEEE Transactions on
Automatic Control, vol. 48, no. 6, pp. 988-1001, 2003.

[5] R. A. Gupta, and M. Y. Chow, “Networked control system: Overview
and research trends”, IEEE Transactions on Industrial Electronics, vol.
57, pp. 2527-2535, 2010.

[6] J. P. Hespanha, and P. Naghshtabrizi, “A survey of recent results in
networked control systems”, Proceedings of the IEEE, vol. 95, no. 1,
pp. 138-162, 2007.

[7] N Cameron, and J Cort´es. “Team-triggered coordination for real-time
control of networked cyber-physical systems”, IEEE Transactions on
Automatic Control, vol. 61, no. 1, pp. 34-47, 2016.

[8] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Attack detection and identi-
ﬁcation in cyber-physical systems”, IEEE Transactions on Automatic
Control, vol. 58, no. 18, pp. 2715-2729, 2013.

[9] K. G. Vamvoudakis, J. P. Hespanha, B. Sinopoli, and Y. Mo, “Detection
in adversarial environments,” IEEE Transactions on Automatic Control,
vol. 59, no. 12, pp. 3209-3223, 2014.

the output-to-output

[10] A. Teixeira, H. Sandberg, and K. H. Johansson, “ Strategic stealthy
l2-gain,” In Proceedings of IEEE 54th

attacks:
Annual Conference on Decision and Control, pp. 2582-2587, 2015.
[11] Z. Guo, D. Shi, K. H. Johansson, and L. Shi, “Optimal linear cyber-
attack on remote state estimation,” IEEE Transactions on Control of
Network Systems, vol. 4, no. 1, pp. 4-13, 2017.

[12] R. Mitchell, and I. Chen, “Adaptive intrusion detection of malicious
unmanned air vehicles using behavior rule speciﬁcations”, IEEE Trans-
actions on SMC systems, vol. 44, no. 5, pp. 593-604, May 2014.
[13] N. Bezzo, J. Weimer, M. Pajic, O. Sokolsky, G. J. Pappas, and I. Lee,
“Attack resilient state estimation for autonomous robotic systems,” In
proceedings of IEEE/RSJ Conference on Intelligent Robots and Systems,
pp. 3692-3698, 2014.

[14] C. Persis, and P. Tesi, “Resilient Control under Denial-of-Service”, In
proceedings of the 19th IFAC World Congress, South Africa, 2014.
[15] S. Sundaram, and C.N. Hadjicostis, “Distributed function calculation
via linear iterative strategies in the presence of malicious agents,” IEEE
Transactions on Automatic Control, vol. 56, no. 7, pp. 1495-1508, 2011.
[16] S. Sundaram, and B. Gharesifard, “Consensus-based distributed op-
timization with malicious nodes,” In Proceedings of Conference on
Communication, Control, and Computing (Allerton), pp. 244-249, 2015.
[17] F. Pasqualetti, A. Bicchi, and F. Bullo, “Consensus computation in
unreliable networks: A system theoretic approach”, IEEE Transactions
on Automatic Control, vol. 57, no. 1, pp. 90-104, 2012.

[18] H.J. LeBlanc, H. Zhang, X. Koutsoukos, and S. Sundaram, “Resilient
asymptotic consensus in robust networks,” IEEE Journal on Selected
Areas in Communications, vol. 31, no. 4, pp. 766-781, 2013.

[19] K. Saulnier, D. Saldana, A. Prorok, G. Pappas, and V. Kumar, “Resilient
Flocking for Mobile Robot Teams,” IEEE Robotics and Automation
Letters, vol. 2, no. 2, pp. 1039-1046, 2017.

[20] S. M. Dibaji, H. Ishii, and R. Tempo, “Resilient randomized quantized
consensus,” IEEE Transactions on Automatic Control, vol. 63, no. 8, pp.
2508-2522, 2017.

[21] A. Teixeira, I. Shames, H. Sandberg, and K. H. Johansson, “A secure
control framework for resource-limited adversaries,” Automatica, vol.
51, pp. 135-148, 2015.

[22] H.J. LeBlanc, H. Zhang, S. Sundaram, and X. Koutsoukos, “Consensus
of multi-agent networks in the presence of adversaries using only local
information,” In Proceedings of the 1st international conference on High
Conﬁdence Networked Systems, pp. 1-10, 2012.

[23] H.J. LeBlanc, and X. Koutsoukos, “Resilient synchronization in robust
networked multi-agent systems,” In Proceedings of the 16th interna-
tional conference on Hybrid systems: computation and control, pp. 21-
30, 2013.

[24] W. Zeng, and M. Chow, “Resilient distributed control in the presence of
misbehaving agents in networked control systems,” IEEE transactions
on cybernetics, vol. 44, no. 11, pp. 2038-2049, 2014.

[25] T. Alpcan, and T. Bas¸ar, “A game theoretic analysis of intrusion detection
in access control systems,” In Proceedings of IEEE Conference on
Decision and Control, pp. 1568-1573, 2004.

[26] Y. Mo, and B. Sinopoli, “Secure estimation in the presence of integrity
attacks”, IEEE Transactions on Automatic Control, vol. 60, no. 4, pp.
1145-1151, 2015.

[27] Q. Zhu, and T. Bas¸ar, “Robust and resilient control design for cyber-
physical systems with an application to power systems,” In Proceedings
of IEEE Conference on Decision and Control and European Control
Conference (CDC-ECC), pp. 4066-4071, 2011.

