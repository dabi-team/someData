2
2
0
2

l
u
J

7
2

]

R
C
.
s
c
[

5
v
1
7
5
5
0
.
2
0
1
2
:
v
i
X
r
a

TINKER: A framework for Open source
Cyberthreat Intelligence

1st Nidhi Rastogi
Department of Software Engineering
Rochester Institute of Technology
Rochester, NY, USA
nidhi.rastogi@rit.edu

2nd Sharmishtha Dutta
Department of Computer Science
Rensselaer Polytechnic Institute
Troy, NY, USA
duttas@rpi.edu

3rd Alex Gittens
Department of Computer Science
Rensselaer Polytechnic Institute
Troy, NY, USA
gittea@rpi.edu

4th Mohammed J. Zaki
Department of Computer Science
Rensselaer Polytechnic Institute
Troy, NY, USA
zaki@cs.rpi.edu

5th Charu Aggarwal
IBM Research
Yorktown Heights, NY, USA
charu@us.ibm.com

tions, blogs, common vulnerabilities, and exposure databases
(CVE), provide curated, sometimes very detailed, accounts of
the current cyber threat landscape. Security companies such
as McAfee and Symantec, researchers, government agencies,
and experts publish these accounts largely in unstructured
text. MITRE, NIST, OASIS Open have spearheaded initiatives
that make security information available in structured formats
through standards like common vulnerabilities and exposures
(CVE) [1] and national vulnerability database (NVD) [2], and
structured threat information eXpression (STIX) [3].

Abstract—Threat intelligence on malware attacks and cam-
paigns is increasingly being shared with other security experts for
a cost or for free. Other security analysts use this intelligence to
inform them of indicators of compromise, attack techniques, and
preventative actions. Security analysts prepare threat analysis
reports after investigating an attack, an emerging cyber threat,
or a recently discovered vulnerability. Collectively known as
cyber threat intelligence (CTI), the reports are typically in
an unstructured format and, therefore, challenging to integrate
seamlessly into existing intrusion detection systems. This paper
proposes a framework that uses the aggregated CTI for analysis
and defense at scale. The information is extracted and stored
in a structured format using knowledge graphs such that the
semantics of the threat intelligence can be preserved and shared
at scale with other security analysts. Speciﬁcally, we propose
the ﬁrst semi-supervised open-source knowledge graph-based
framework, TINKER, to capture cyber threat information and
its context. Following TINKER, we generate a Cyberthreat
Intelligence Knowledge Graph (CTI-KG) and demonstrate the
usage using different use cases.

Index Terms—Threat Intelligence, Knowledge Graphs, Infor-

mation Retrieval

I. INTRODUCTION

Fig. 1. Excerpt of a CTI report for malware family Backdoor.Winnti [4].

Security analysts investigate cyber threats to organizations
and regularly determine remedial actions to prevent them in the
future. They gather cyber threat intelligence analysis reports
that describe newly emerging threats and/or ways to mitigate
them(see Fig. 1). This information, called Cyber Threat In-
telligence (CTI), offers a detailed summary of one or more
cyber attacks and aggregates relevant knowledge and context.
It covers information on zero-day attacks, newly identiﬁed
vulnerabilities, indicators of compromise (IoC), threats, and at-
tack patterns. Such information is multi-modal, predominantly
unstructured, and does not follow a speciﬁc format. Other
cyber threat analysts utilize the shared threat intelligence (free
or paid) to mitigate potential threats and defend their organi-
zation. Existing unstructured and structured sources of threat
information, such as analysis reports from security organiza-

Threat Intelligence Knowledge Extractor (TINKER) ad-
dresses these two main gaps: (a) whereas the current taxonomy
and standards provide extensive coverage of threat concepts,
they lack semantic and contextual associations and (b) threat
intelligence extraction models not trained on cyber threat cor-
pus can lead to capturing fragmented and sometimes fallacious
threat information.

TINKER transforms multi-modal CTI into a structured
format while preserving the context of the information. TIN-
KER uses ontologies and information extraction models to
capture CTI. It seamlessly integrates heterogeneous sources
of data, captures data and its context, and structures them
using the Cyberthreat Intelligence Knowledge Graphs (CTI-
KG), which enables further machine learning like analysis [5].
This paper focuses on extracting threat intelligence from the

 
 
 
 
 
 
generic security corpus. In this paper, we make the following
contributions:

1) We present TINKER, the ﬁrst end-to-end framework for
capturing and analyzing multi-modal threat intelligence
information using a semi-supervised approach.

2) Using TINKER, we generate an open-source CTI-KG,
the ﬁrst open-access knowledge graphs for general cyber
threat intelligence.

3) We demonstrate the use of CTI-KG through two use
cases to infer previously unknown threat
information
such as vulnerabilities, associations between malware,
and malware author.

4) We present an open-access corpus of over 52K triples
comprising 30k unique named entities and 22 relation-
ships. This is a new benchmark framework for contextual
cyber security research problems.

Knowledge Graphs (KGs) for threat intelligence: Cyber-
attacks have evolved dramatically over the past decade, and
their attack patterns have become highly sophisticated and
complex. An attack pattern deﬁnes a sequence of tactics,
techniques, and procedures the attacker follows to conclude
the attack. Machine learning has successfully analyzed cyber
attacks using supervised, unsupervised, and deep learning
using host and network log data. While successful, they miss
out on attack vectors that use social engineering,
insider
threats, and similar, non-traceable vectors. Security analysts
want to investigate newly discovered attack vectors (attacker,
malware, vulnerability) and determine the threat level to their
organization at the earliest. Internal telemetries gathered from
log data are not mapped to newly emerging threat indicators.
Therefore, it is essential to aggregate, study and map external
threat indicators and patterns to internal enterprise threat de-
tection tools. KGs have been used extensively to organize and
integrate data from heterogeneous sources in the biomedical
domain. The proposed CTI-KG holds threat information from
the CTI dataset and stores it as a triple in RDF format with
two entities connected by one relationship. Entities represent
classes such as malware, organizations, vulnerability, attack
patterns, malware behavioral characteristics, and attack time-
line. Relationships connect entities and provide context for
their interpretation.
Motivating Example: Here, we describe a real-world malware
attack analysis to motivate threat intelligence using knowledge
graphs.
Curated threat intelligence information adds semantic analysis
to existing evidence and the provenance of the source of
information, adding evidence against the attacker (see Fig.
2). For instance, CTI1 written in early 2021, cyber attacks
on the SolarWinds software captured detailed analysis on
the Sunspot malware that inserted the Sunburst malware into
SolarWinds’ Orion software. In such events, with only sparse
data and preliminary evidence about the threat actor, CTI-KG
infers attack actors and other attributes for Sunburst with a
conﬁdence score. For instance, it infers that Sunburst and a

backdoor linked to the Turla advanced persistent threat (APT)
group share similarities without using this threat report in the
training of the knowledge graph. It infers this information
during testing.

Fig. 2. CTI-KG has captured two indicators of Malware-1. When CTI-KG
is queried for attribution on Malware-2, it can ﬁnd the associations between
the two malware.

Main Challenges: Some of the major challenges encoun-
tered in generating the knowledge-based framework for threat
intelligence are:
(a) Missing cybersecurity speciﬁc information extraction
models - CTI reports contain both generic and domain-
speciﬁc threat data. Named entity recognizer (NER) mod-
els such as StanfordNER2 trained on generic datasets
or UMLS for speciﬁc domains such as health cannot
be used. For example, existing domain-speciﬁc concepts
sometimes have titles that can mislead NER models
into categorizing them as generic concepts. For example,
when a vulnerability description mentions “Yosemite
backup 8.7,” a generic NER does not refer to Yosemite
as a server backup software but as a national park in
California, US.

(b) Missing context in extracting key phrases - Exist-
ing cybersecurity standards and taxonomies (like STIX,
TAXII) overlook the importance of context in extracted
concepts (our research addressed this via linking and
semantic metadata). Text data is not a mere aggregation of
words. There is a meaning in the information, and linking
concepts to outside sources is crucial
to its effective
use. For example, a human security analyst can correctly
comprehend the meaning of the term “Aurora” in a CTI
report. It refers to the series of cyber attacks conducted
by China by Advanced Persistent Threats (APTs), ﬁrst
detected by Google in 2009. However, a computer or
an AI model collecting this information might mistake
it for the Northern Lights unless provided with a security
context.

(c) Lack of standard format of cyber threat corpus -
Malware CTI reports cover technical and social aspects
of a malware attack in the form of unstructured text.
Generating a knowledge graph requires extracting key
phrases from these reports, which is not a trivial task. The

1https://www.cyberscoop.com/turla-solarwinds-kaspersky/

2https://nlp.stanford.edu/software/CRF-NER.shtml

varying degrees of attack and defense description and the
changing landscape of the information can render prior
information defunct, which is an additional challenge.
Unlike a small curated benchmark dataset, we require
information extraction systems that are scalable and repli-
cable for a large amount of text corpus speciﬁc to the
cyber threat domain.

(d) Missing validation techniques - Knowledge graphs for
cybersecurity threat intelligence is a new approach for
providing structured and semantically rich information to
people and machines. However, since this is an area of
research, there is no publicly available “ground truth” to
evaluate the knowledge framework.

II. DEFINITIONS

Cyberthreat Intelligence Knowledge Graph (CTI-KG)
is a directed multi-modal graph, CTI-KG = {E, R, T}, where
E, R and T indicate the sets of entities, relationships and
triples, respectively. Each triple (cid:104)ehead, r, etail(cid:105) ∈ T indicates
that there is a relationship r ∈ R between ehead ∈ E and
etail ∈ E. Knowledge graph entity prediction is the task of
predicting the best candidate for a missing entity. However, in
the CTI domain, prediction is replaced with the term inference
since we are inferring an attack vector based on the knowledge
present in the CTI-KG. Formally, the task is to infer the value
for h given (cid:104)?, r, t(cid:105) or t given (cid:104)h, r, ?(cid:105), where “?” indicates a
missing entity. A summary of the notation appears in Table I.
All triples have three vectors, e1, e2 ∈ Rde , r ∈ Rdr .

III. TINKER FRAMEWORK

We describe TINKER, the framework for generating CTI-
KG and inferring threat intelligence (see Fig.4). The frame-
work comprises modules that perform semi-supervised data
collection using information extraction models, CTI-KG con-
struction, generating vector embeddings from triples, and
inference. Automated data collection: We aggregate hun-
dreds of reports on threat intelligence uploaded on GitHub
repositories. These reports are written between the years 2010-
2022 by security analysts from top security companies such
as FireEye, Symantec, McAfee, Microsoft Research, security
bulletins, TechCrunch, and ESET. See Figure 1 for an excerpt
of a CTI report on the Backdoor.Winnti malware family. Not
all reports are consistent, accurate, or comprehensive and can
vary in technical depth and breadth of the attack description.
Information Extraction: This module is responsible for ex-
tracting contextual and structured cyber threat information.
Named entity extraction (NER) and the semantic relationship
between them (relation extraction, RE) from unstructured text
form triples – the fundamental unit of CTI-KG. We ﬁrst
create ground truth using a combination of hand-annotated
CTI, supervised and semi-supervised NER, and relationship
extraction. For instance, consider the following snippet from
a CTI report:3

“... DUSTMAN can be considered as a new variant of ZeroCleare malware
... both DUSTMAN and ZeroCleare utilized a skeleton of the modiﬁed “Turla
Driver Loader (TDL)” ... The malware executable ﬁle “dustman.exe” is not
the actual wiper. However, it contains all the needed resources and drops
three other ﬁles [assistant.sys, elrawdisk.sys, agent.exe] upon execution...”.

TABLE I
NOTATIONS AND DESCRIPTIONS

Notation
E, R, T
(cid:104)ehead, r, etail(cid:105)
(cid:104)h, r, t(cid:105)
de, dr
ne, nr, nt
fφ

Description
set of all entities, relationships and triples respectively
head entity, relationship and tail entity
embedding of h, r and t
embedding dimension of entities, relationships
number of h+t, r, triples
scoring function of each triple (cid:104)h, r, t(cid:105). measures plausibil-
ity of a fact in T, based on translational distance or semantic
similarity [6]

TABLE II
TRIPLES CORRESPONDING TO THE CTI REPORT.

Head Entity

Relationship

Tail Entity

(cid:104)DUSTMAN,
(cid:104)DUSTMAN,
(cid:104)ZeroCleare,
(cid:104)DUSTMAN,
(cid:104)dustman.exe,
(cid:104)dustman.exe,
(cid:104)dustman.exe,

similarTo,
involves,
involves,
involves,
drops,
drops,
drops,

ZeroCleare(cid:105)
Turla Driver Loader(TDL)(cid:105)
Turla Driver Loader(TDL)(cid:105)
dustman.exe(cid:105)
assistant.sys(cid:105)
elrawdisk.sys(cid:105)
agent.exe(cid:105)

Ontological mapping is performed using classes and rela-
tionships deﬁned in cyberthreat ontologies [7] [8] to extract
triples from unstructured text. An ontology maps disparate data
from multiple sources into a shared structure that maintains
a logic in that structure using rules and follows a common
vocabulary [9]. For example, there are classes named Malware
and Location in MALOnt. According to the relationships
deﬁned in an ontology, an entity of Malware class can have
a relationship “similarTo” with another Malware class entity.
However, according to the rule engine, an entity belonging to
the class Malware can never be related to an entity belong-
ing to the class Location. The same two entities can have
multiple relationships between them. For example, an entity
of type Malware and Application can have relationships such
as uses, communicates with have very different meaning.
Therefore, context plays a signiﬁcant role in analyzing entities.

CTI-KG Construction: Together, thousands of triples con-
struct CTI-KG where the entities and relationships model
nodes and directed edges, respectively. Figure 3 shows the
sample knowledge graph from the text. A knowledge graph
contains 1-to-1, 1-to-n, n-to-1, and n-to-n relationships be-
tween entities. In Figure 3, the entity “dustman.exe” is an
instance of a Malware File. It drops three different ﬁles.
Entities DUSTMAN and ZeroCleare both involve the Turla
Driver Loader (TDL) ﬁle. There exists an n-to-1 relationship
between the entities of the CTI-KG.
Inferring Threat Intelligence: This task infers threat intelli-
gence about an emerging or existing security threat along with
a conﬁdence score (0.0-1.0). We discuss various embedding

3https://www.lastwatchdog.com/wp/wp-content/uploads/

Saudi-Arabia-Dustman-report.pdf

2) Hits@n is calculated from the ranks of all true test triples,
where Hits@n denotes the ratio of true test triples in the
top n positions of the ranking. Smaller values of Hits@n
indicate a better model when comparing embedding mod-
els for prediction.

IV. DATASET PREPARATION

The ﬁrst dataset comprises hand-annotated triples, and the
second is from a larger CTI corpus from various cyber threats
such as APT, malware, and phishing. CTI report is originally
in .pdf or .html format and then converted into text format. Pre-
processing includes several techniques to minimize noise and
remove unnecessary information from the text. We tokenize
and parse the plain text sentences into words with start and
end positions using a python library called spaCy4, which
allows POS tagging, dependency parsing, and word vectors.
Each token is assigned an id and stored for each CTI report.
Ground Truth: 85 reports were hand-annotated by mapping
entities and relationships to classes deﬁned by ontology. Two
graduate and ﬁve undergraduate student researchers with cy-
bersecurity education performed this task in 3 to 4 months.
A senior, more experienced full-time researcher oversaw the
the same expert
task and broke ties when needed. Later,
veriﬁed the hand-annotated triples. The CTI reports were
written between 2010-2022. In Figure 5, “PowerPoint ﬁle” and
“installs malicious code” are labeled as classes Software and
Vulnerability respectively. The arrow from Software to Vul-
nerability denotes the semantic relationship hasVulnerability
between them. The annotation followed rules deﬁned in cyber
threat ontologies [7], [8]. 11 object properties (nr) are deﬁned
intelligence ontology [7]. The comparison
in cyber threat
between the structure of the knowledge graphs generated from
the hand-annotated ground truth and CS40K dataset, their
properties, and corpus details are described in Table III. The
columns in the table compare the number of entities, relations,
and triples, the average degree of entities, and graph density
of our datasets (CS3K, CS40K) and benchmark datasets.The
average degree across all relationships and graph density are
deﬁned as nt/ne and nt/n2
e, respectively [12]. A lower score
for these two metrics indicates a sparser graph.

Larger Dataset: A total of 1,100 threat advisory reports
were downloaded from GitHub repositories. They were written
by analysts from major security organizations’ websites such
as Symantec, Kaspersky, Microsoft, IBM, FireEye, TrendMi-
cro, and McAfee. The annotated key phrases were classiﬁed
into entities derived from semantic categories deﬁned in cyber
threat ontologies [7], [8]. The inference rule engine from the
ontologies was applied when forming relationships between
entities to produce triples used to build the knowledge graphs.
We use semi-supervised learning to train NER and relationship
extraction models by providing a few hand-annotated samples.
The CTI-KG comprises 40,000 triples generated from 27,354
unique entities and 11 relations.

4https://spacy.io/api/tokenizer

Fig. 3. Sample CKG. Nodes and edges represent entities and relations,
respectively. The edge labels denote relationship type.

models that we explored for the inference task in the related
work section VI. For this paper, we adapt the TuckER [10]
model, a linear model based on Tucker decomposition of
the binary tensor representation of CTI-KG triples. TuckER
creates vector embeddings for all triples in CTI-KG and infers
missing entities for classes deﬁned in the ontology [7].

Evaluation Criteria: Knowledge Graph-based threat in-
telligence is a new paradigm for inferring information about
emerging threats. Unlike machine learning-based models that
predict a value or label a data point based on prior learning
from training data, knowledge graph-based prediction provides
a list of entities inferred by a triple, using the vector em-
bedding approach and the conﬁdence score. Fundamentally,
inferring threat intelligence entities is modeled in CTI-KG by
predicting the missing entities in the graph. The training step
of the CTI-KG constructs the KG. Further, in the inference
step, we perform the inference operations to conclude new
facts not explicitly present in CTI-KG.

For example, consider “Adobe Flash Player” as an entity
belonging to the class Software in CTI-KG. Several entities
have an incomplete triple with a missing tail entity in the
training phase because that information was missing from the
threat reports. This triple will be of the form (cid:104)Adobe Flash
Player, hasVulnerability, ?(cid:105). The entity inference operation
will infer a list of missing tail entities and the conﬁdence score
of the predictions, i.e., a vulnerability of the Software titled
“Adobe Flash Player.” In another example, for an incomplete
triple, where the tail entity is the malware family “Hydraq”,
the CTI-KG returns the class of the head entity, Campaign,
and the entity itself, Trojan.Hydraq for the query (cid:104)?, involves-
Malware, Hydraq(cid:105). In CTI-KG, entity inference is evaluated,
and conﬁdence score is computed as described below [11]:

1) When is an incomplete triple, (cid:104)h, r,

t(cid:105) needs to be
completed by an entity, a set of candidate entities are
generated along with the scoring function, fφ(h, r, t), for
each triple. The score is sorted to obtain the rank of the
true test triple in the ordered set. This rank evaluates
the performance of the model in predicting tail given
(cid:104) head, relation, ? (cid:105). A higher rank indicates a model’s
better efﬁciency in learning embeddings for the entities
and relations.

Fig. 4. System Architecture for CTI-KG construction and showing entity prediction.

TABLE III
DESCRIPTION OF DATASETS

nr nt
Dataset ne
CS3K
22
CS40K 27,354 11

5,741

3,027
40,000

docs
81
1,100

avgDeg density
0.00009
0.5273
5.34 ×
1.46
10−5

Information Extraction and Ontological Mapping: Con-
cepts that a generic named entity recognition model can easily
classify require training using a representative dataset. We train
several NER models with suggestive keywords and the context
within which the keyword occurs. Both approaches are critical
in providing entity mapping for classes representing facts and
contextual data. We train an odd number of NER models
for each class, and the entity extraction (EE) step combines
the results of the ensemble of various extraction techniques.
A shortcoming of using multiple EE models is that some
entities can get classiﬁed multiple times, which might even be
inaccurate. We observed empirically that this phenomenon was
not limited to any speciﬁc class. This phenomenon explains
the variation and grammatical inconsistency in different CTI
reports and their writing style. For example, the entity “Linux”
was classiﬁed as Software and Organization for the same
position in a document. Since the entity extraction models are
running independently, it was likely for close class types to
have overlapped. We resolve this issue by following these rules
1) We compared the conﬁdence score of entities occurring
at the same position in the same document and between
classes.

2) For the same conﬁdence scores, we marked those classes
as ambiguous. We retained these instances until
the
relationship extraction phase. At that time, we relied on
the rule engine from the ontology to determine the correct
class of the head and tail entity for a given relationship
(described in the next section).

The entity classiﬁcation (EC) step addresses the disam-
biguation of an entity classiﬁed into more than one semantic

category and assigns only one class based on an empirically
learned algorithm. EE and EC maximize the automation of an
otherwise exhaustive entity recognition process. Semantic text
patterns from NER and RE map to classes (called entities in
KG) and object properties (called relationships in KG) deﬁned
by an ontology. For example, in [7], [13], three classes largely
describe malware behavior – Malware, Vulnerability, and
Indicators of Compromise. See Figure 1 for a snapshot on an
instance of ontology and Figure 6 for a snippet of the top-level
classes of the ontology. We segregate tokenized words’ extrac-
tion into domain-speciﬁc key-phrase extraction and generic
key-phrase extraction (class:Location). The cybersecurity
domain-speciﬁc EE task was further subdivided into factual
key-phrase extraction (class:Malware) and contextual key-
phrase extraction (class:Vulnerability). We use precision and
recall measures as evaluation criteria to narrow down the EE
models for different classes. For example, the Flair library [14]
gave high precision scores (0.88-0.98) for the classiﬁcation
of generic and factual domain-speciﬁc key phrases such as
- Person, Date, Geo-Political Entity, Product (Software,
Hardware). The diversity in writing style for the CTI reports
and the noise introduced during reports’ conversion to text led
to different precision scores for classes but within the range
of 0.9-0.99. For contextual entity extraction, we expanded the
SetExpan [15] model to generate all entities in the text corpus.
The feedback loop that inputs seed values of entities based on
conﬁdence scores allowed for improving the training dataset.
Some semantic classes used in this approach are Malware,
Malware Campaign, Attacker Organization, Vulnerability.
We perform relationship extraction for CTI-KG using a dis-
tantly supervised artiﬁcial neural network model [16] pre-
trained on the Wiki data and Wikipedia, initially with three
features. The CS3K triples and text corpus form the training
dataset and the entities generated in the previous steps, and
the processed text corpus is the testing dataset. We built on
this learning and improved automatic relation extraction (RE)
by using semi-supervised relation extraction methods5 aimed

5https://github.com/THU-BPM/MetaSRE

to leverage unlabeled data in addition to learning from limited
samples.

described earlier. A human-in-the-loop (a security expert) is
employed to ﬁx the false positives manually.

A. Inferring Threat Intelligence from CTI-KG

Table VII displays the results of entity prediction existing
embedding models on the benchmark datasets. An upward
arrow (↑) next to an evaluation metric indicates that a larger
value is preferred for that metric and vice versa. For ease of
interpretation, we present Hits@n measures as a percentage
value instead of a ratio between 0 and 1. TransE has the largest
Hits@10, whereas TransR performs better on the rest of the
three datasets. However, TransH is more expressive (capable
of modeling more relations) than TransE despite having the
simplicity of TransE (time complexity O(de)). The space
complexity of TransR (O(nede + nrdedr)) is more expensive
than TransH (O(nede + nrde)) [11]. Additionally, it takes six
times more time to train TransR6 compared to TransH [17].
Considering these model capabilities and complexity trade-
offs, we choose TransH as a representational translation-based
model. DistMult performs better than TuckER by a small
margin of 0.37% in only one case (Hits@10 on WN18).
TuckER and ComplEx both achieve very close results on
multiple cases.

Therefore, we look closely at the results of the recently re-
ﬁned datasets (FB15K-237 and WN18RR). The CS3K dataset
shares similar properties with these two datasets (CS3K has
hierarchical relationships as in WN18RR and no redundant
triples as in FB15K-237). Since the space complexity is very
close (ComplEx: O(nede + nrde) and TuckER: O(nede +
nrdr)) we choose TuckER for evaluation on CS3K, as it
subsumes ComplEx [10].

We evaluate the performance of TransH [18] and TuckER
[10] on our datasets. Tables IV and V display the performance
of TransH and TuckER on CS3K and CS40K. TransH’s MRR
score on CS3K improved when compared to the benchmarks.
Tucker’s performance improved in all measures when com-
pared to the other benchmark results. TuckER outperforms
TransH by a large margin on the CS3K dataset.

Since TuckER performed signiﬁcantly better than TransH
on the ground truth dataset, we employ only TuckER on the
CS40K dataset. It is noteworthy that all the measures except
mean rank (MR) improved on CS40K compared to CS3K.
It conﬁrms the general intuition that the model learns the
embeddings more effectively as we provide more data. MR
is not a stable measure and ﬂuctuates even when a single
entity is ranked poorly. We see that the MRR score improved
even though MR worsened, which conﬁrms the assumption
that only a few poor predictions drastically affected the MR
on CS40K. Hits@10 being 80.4 indicates that when the entity
prediction model predicted an ordered set of entities, the true
entity appeared in its top 10 80.4% times. Hits@1 measure
denotes that 73.9% times, the model ranked the true entity at
position 1, i.e., for 80.4% cases, the model’s best prediction
was the corresponding incomplete triple’s missing entity. We

6On benchmark datasets

Fig. 5. Annotation using Brat annotation tool.

Fig. 6. Main Classes (left), Object Properties (right) from a cyber threat
ontology. Instances of classes, called entities and instances of object properties
called relationships are mapped to CTI text using NER and relation extraction
models

V. EXPERIMENT AND EVALUATION

We infer threat

intelligence on the CTI-KG through a
tensor factorization-based approach [10] using PyTorch. To
train all the datasets, we choose all hyper-parameters based
on validation set performance through random search. Since
the datasets contain a signiﬁcantly smaller number of
all
relationships relative to the number of entities, we set entity
and relationship embedding dimensionality to de = 200 and
dr = 30, learning rate = 0.0005, batch size of 128 and 500
iterations. We use batch normalization and dropout to decrease
training time. For evaluation, for each test triple, we generate
ne candidate triples by combining the test entity-relation pair
with all possible entities E, followed by ranking the computed
scores. We use evaluation metrics standards across the link
prediction literature, and they are described in Section III.

CS3K validation set is used for tuning the hyper-parameters
for CS40K. For the prediction experiment on CS3K, we
achieved the best performance with de = 200 and dr = 30,
learning rate = 0.0005, batch size of 128 and 500 iterations.
We split each dataset into 70% train, 15% validation, and
15% test data. Due to the limited hand-annotated dataset, we
tested the CS40K dataset using CS3K. The challenge with
a smaller ground truth can lead to overﬁtting of results. To
increase the size of the ground truth, we increase the size of
triples through a semi-supervised method, i.e., by the process

TABLE IV
EXPERIMENTAL EVALUATION OF CS3K FOR ENTITY PREDICTION.

Model

Hits@1↑ Hits@3↑ Hits@10↑ MR↓ MRR↑

TransH
TuckER

26.8
64.3

50.5
70.5

65.2
81.21

32.34
7.6

0.414
0.697

TABLE V
EXPERIMENTAL EVALUATION OF CS40K FOR ENTITY PREDICTION.

Model

Hits@1↑ Hits@3↑ Hits@10↑ MR↓ MRR↑

TuckER

73.9

75.9

80.4

202

0.75

can interpret Hits@3 similarly. We translate the overall entity
prediction result on CS40K to be sufﬁcient such that
the
trained model can be improved and further used to infer unseen
facts.

B. Use-case Description

We query CTI-KG by forming an incomplete test triple
as this is the formal approach to inferring information from
a knowledge graph. The results are a set of predictions
where each prediction has a conﬁdence score associated with
it. The conﬁdence score of a predicted entity ei denotes
the probability of ei being the accurate candidate for the
incomplete triple. The predictions are sorted in descending
order by this score, and we observe the top 10 predictions as
potential predictions (Hits@10).

1) Case Study 1, Predicting a malware family: A secu-
rity analyst wants to identify which malware family is
associated with the indicator intel − update[.]com in a
CTI-KG. The following query is posed to the CTI-KG in
the form of an incomplete triple:

(cid:104)intel − update[.]com, indicates, ?(cid:105)
Here, the accurate malware family associated with the
domain intel − update[.]com is named Stealer. We refer
the reader to the FireEye report titled ‘Operation Saffron
Rose’7 for validating this fact. This CTI was not included
in the training corpus. However, the training set had some
triples involving Stealer, such as:

(cid:104)of f ice.windowsessentials[.]tk, indicates, Stealer(cid:105)
(cid:104)Saf f ron Rose, involvesM alware, Stealer(cid:105)
The model learns latent features of Stealer, its indicators
of compromise, and other related entities (e.g., campaigns
that involved Stealer) present in the training set. Table
VI shows the ordered set of predictions returned by
the model, and the true answer is ranked #1. This is
a signiﬁcant result as it can simplify the job of an
analyst to a great extent by narrowing down the scope for
further analysis. Starting with this set of 10 results with
different conﬁdence scores, the analyst ﬁnds the accurate

information in the second item. By deﬁnition, the Hits@3
and Hits@10 metrics increase as the true entity exists in
the top 3 and certainly in the top 10. As seen in table V,
we can say 75.9% times the true entity will appear in the
top 3 predictions of the model.

2) Case study 2, Inferring Attack Target: Note that CTI-
KG is built by extracting semantically rich information
on a variety of attacks. We, therefore, constructed CTI-
KG exclusively for android malware. We expected better
inferences as the corpus was speciﬁc to one category
of attacks. A security analyst queries CTI-KG to learn
about
the region impacted by a type of attack. The
following query is posed to the CTI-KG in the form of
an incomplete triple:

(cid:104)“coronavirus-themed attacks”, targets, ?(cid:105)
The training set had some triples on “coronavirus-themed
attacks”. Note that the training set contains facts from
different CTI reports, and the terms “coronavirus-themed
attacks” and ‘targets’ refer to the same attack category.
The model learns latent features of these entities and
relationships during training and later uses these features
to infer a set of regions highly probable to involve the
attack.
Table VI demonstrates the inferences made by this query.
We can see that the true answer (India) is ranked #1. In
order to validate this ﬁnding, we refer the reader to the
CTI report8.
This result contributes to increasing the Hits@10 metric
(since the rank is within the top 10), as well as to
Hits@1 and Hits@3. We obtain an intuition about what
the Hits@n metric on the overall test dataset represents.
Hits@10 score reported in table V can be interpreted that
80.4% time the true entity would appear in the top 10
inferences. We elaborate on this analysis in the following
section.

VI. RELATED WORK

Cyber threat knowledge discovery and analysis allows se-
curity analysts to mine threat and machine-readable attack
artifacts such as a list of indicators of compromise– trafﬁc
signatures, malicious IP addresses, virus signatures, malicious
URLs, and domains that organizations download and install
into their ﬁrewall [19]–[21]. These artifacts are routinely used
to prepare machine-learning models that perform predictive
security analytics [20], [22], [23]. Much of existing research
may not continue to help prevent further attack events [19]
as (a) attack characteristics change, e.g., malware samples
frequently get repackaged [24], (b) malicious domains do
not remain active for a long time [25], or (c) the analysts,
for example, may not connect the evidence they see in their
internal network log alerts to an ongoing, more extensive,
external attack campaign.

Security analysts deal with hundreds of thousands of false
alerts daily due to ML models not ﬁnding a pattern in their

7https://www.ﬁreeye.com/content/dam/ﬁreeye-www/global/en/

current-threats/pdfs/rpt-operation-saffron-rose.pdf

8shorturl.at/mnBFU

TABLE VI
DETAILED RESULT OF INFERRING ENTITIES

Case study 1: Inferring a Malware Family
(cid:104)intel − update[.]com, indicates, ?(cid:105)

Rank
1
2
3
4
5
6
7
8
9
10

Inferred Entity
Stealer
A malware hash9
A malware hash10
Gholee
200.63.46.33
26978 ns2. aeroconf2014[.]org
A malware hash11
Capstone Turbine
2012/06/06
Google Hack Attack

Conﬁdence score
0.5769
0.5694
0.5679
0.5679
0.5668
0.5662
0.5620
0.5602
0.5592
0.5566

Case study 2: Inferring Attack Target
(cid:104)“coronavirus-themed attacks”, targets, ?(cid:105)
Conﬁdence score
0.8683
0.8634
0.2972
0.1873
0.1662
0.1316
0.1173
0.0836
0.05486
0.04999

Inferred entity
India
recorded future
issuemakerslab
google
China
maas
United Arab Emirates
Kaspersky
Italy
Portugal

Bold text denotes the true entity for the corresponding test triple

TABLE VII
INFERRING ENTITY FOR DIFFERENT DATA SETS

FB15K
Hits@10↑ MRR↑
0.227
0.177
0.236
0.206
0.205
0.260

Model
TransE
TransH
TransR
DistMult
ComplEx
TuckER
The top three rows are models from the translation-based approach, rest are from tensor factorization-based approach
Bold numbers denote the best scores in each category

Hits@10↑
47.2
46.9
48.1
46.2
46.7
46.8

MRR↑
0.176
0.178
0.184
0.264
0.276
0.272

WN18
Hits@10↑ MRR↑
0.395
0.434
0.441
0.531
0.597
0.576

FB15K-237
Hits@10↑ MRR↑
0.169
0.157
0.164
0.151
0.158
0.197

32.2
30.9
31.4
30.3
29.9
35.4

75.4
76.2
77.8
80.9
81.5
80.6

44.3
45.5
48.8
45.1
43.8
51.3

WN18-RR

learning model. The latest work is gradually moving towards
proactive prediction [22] that captures the semantics behind
audit data. Further advances have been made [21] to automat-
ically analyze unstructured text to generate detectable patterns
that consist of combinations of IoCs. However, there is no
known signiﬁcant effort research similar to our work; however,
there is plentiful work on cyber threat knowledge for internal
log networks [21], [23], [26]. It models benign behaviors
and detects deviations from them for internal network and
computer logs. These differ from the proposed research in at
least two signiﬁcant ways. First, the intelligence is gathered
and analyzed from internal network data logs. Related work
[3] derives threat actions from reports and maps them to
attack patterns with pre-deﬁned ontology or machine learning
models. While [21] work provides a good starting point to-
wards extracting threat indicators and actions from cyberthreat
intelligence knowledge sources, they miss out on the context
in the form of the relationship between CTI concepts, like
ones that exist between IOCs and threat actions and provide a
comprehensive view of the attack behavior. Prior research [?],
[7], [13] established that characterization of the threat from
the attack and the defense perspective is crucial.

Knowledge graphs store a large amount of domain-speciﬁc
information in the form of triples using entities and re-
lationships between them [27]. Creating and completing a
knowledge graph from raw text comprises multiple tasks, e.g.,

901da7213940a74c292d09ebe17f1bd01
10a476dd10d34064514af906fc37fc12a3
11deeac56026f3804968348c8afa5b7aba10900aeabee05751c0fcac2b88cff71e

entity discovery, relationship extraction, and designing embed-
ding models. Vector embeddings, such as TuckER, address
the task of knowledge representation by enabling computing
on a knowledge graph. CTI-KG has highly structured and
contextual data and can be leveraged statistically for classiﬁ-
cation, clustering, and ranking. However, the implementations
of embedding vectors for the various models are very diverse.

VII. CONCLUSION

This paper proposes a framework to generate the ﬁrst cyber
threat intelligence knowledge graph, CTI-KG, to infer threat
intelligence from unstructured CTI reports. Since this is rela-
tively new research, we demonstrate how a knowledge graph
can infer threat information from the text corpus. We motivate
and empirically explore different models for encoding triples
and concluded that the tensor factorization-based approach
resulted in the highest overall performance among our datasets.

ACKNOWLEDGMENT

This work was supported by IBM Research through the AI

Horizons Network research grant.

REFERENCES

[1] C. Vulnerabilities, “Common vulnerabilities and exposures,” 2005.
[2] S. Radack and R. Kuhn, “Managing security: The security content

automation protocol,” IT professional, vol. 13, no. 1, pp. 9–11, 2011.

[3] S. Barnum, “Standardizing cyber threat intelligence information with
the structured threat information expression (stix),” MITRE Corporation,
vol. 11, pp. 1–22, 2012.

[25] M. K¨uhrer, C. Rossow, and T. Holz, “Paint it black: Evaluating the
effectiveness of malware blacklists,” in International Workshop on
Recent Advances in Intrusion Detection. Springer, 2014, pp. 1–21.

[26] K. Satvat, R. Gjomemo, and V. Venkatakrishnan, “Extractor: Extracting
attack behavior from threat reports,” in 2021 IEEE European Symposium
on Security and Privacy (EuroS&P).

IEEE, 2021, pp. 598–615.

[27] M. Nickel, K. Murphy, V. Tresp, and E. Gabrilovich, “A review of
relational machine learning for knowledge graphs,” Proceedings of the
IEEE, vol. 104, no. 1, pp. 11–33, 2015.

attackers
have
[Online]. Available:

a
closet?”
[4] “Backdoor.winnti
Broadcom.
https://community.broadcom.com/
symantecenterprise/viewdocument/backdoorwinnti-attackers-have-a-sk?
CommunityKey=1ecf5f55-9545-44d6-b0f4-4e4a7f5f5e68&amp;tab=
librarydocuments
[5] Knowledge graphs.

[Online]. Available: https://www.turing.ac.uk/

skeleton

their

in

research/interest-groups/knowledge-graphs

[6] J. Li, A. Sun, J. Han, and C. Li, “A survey on deep learning for
named entity recognition,” IEEE Transactions on Knowledge and Data
Engineering, 2020.

[7] N. Rastogi, S. Dutta, M. J. Zaki, A. Gittens, and C. Aggarwal, “Malont:
An ontology for malware threat intelligence,” in International Workshop
on Deployable Machine Learning for Security Defense. Springer, 2020,
pp. 28–44.

[8] M. Swimmer, “Towards an ontology of malware classes,” Online,

vol. 27, 2008.

[9] A. Oltramari, L. F. Cranor, R. J. Walls, and P. D. McDaniel, “Building
an ontology of cyber security.” in Semantic Technology for Intelligence,
Defense and Security. Citeseer, 2014, pp. 54–61.

[10] I. Balaˇzevi´c, C. Allen, and T. M. Hospedales, “Tucker: Tensor factoriza-
tion for knowledge graph completion,” arXiv preprint arXiv:1901.09590,
2019.

[11] Q. Wang, Z. Mao, B. Wang, and L. Guo, “Knowledge graph embed-
ding: A survey of approaches and applications,” IEEE Transactions on
Knowledge and Data Engineering, vol. 29, no. 12, pp. 2724–2743, 2017.
[12] A. Padia, K. Kalpakis, F. Ferraro, and T. Finin, “Knowledge graph fact
prediction via knowledge-enriched tensor factorization,” Journal of Web
Semantics, vol. 59, p. 100497, 2019.

[13] R. Christian, S. Dutta, Y. Park, and N. Rastogi, “Ontology-driven knowl-
edge graph for android malware,” arXiv preprint arXiv:2109.01544,
2021.

[14] A. Akbik, T. Bergmann, D. Blythe, K. Rasul, S. Schweter, and R. Voll-
graf, “Flair: An easy-to-use framework for state-of-the-art nlp,” in
Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics (Demonstrations), 2019,
pp. 54–59.

[15] J. Shen, Z. Wu, D. Lei, J. Shang, X. Ren, and J. Han, “Setexpan: Corpus-
based set expansion via context feature selection and rank ensemble,”
in Joint European Conference on Machine Learning and Knowledge
Discovery in Databases. Springer, 2017, pp. 288–304.

[16] Y. Yao, D. Ye, P. Li, X. Han, Y. Lin, Z. Liu, Z. Liu, L. Huang, J. Zhou,
and M. Sun, “Docred: A large-scale document-level relation extraction
dataset,” in Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics, 2019, pp. 764–777.

[17] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, “Learning entity and relation
embeddings for knowledge graph completion,” in Proceedings of the
AAAI Conference on Artiﬁcial Intelligence, vol. 29, no. 1, 2015.
[18] Z. Wang, J. Zhang, J. Feng, and Z. Chen, “Knowledge graph embedding
by translating on hyperplanes.” in AAAI, vol. 14, no. 2014. Citeseer,
2014, pp. 1112–1119.

[19] X. Liao, K. Yuan, X. Wang, Z. Li, L. Xing, and R. Beyah, “Acing
the ioc game: Toward automatic discovery and analysis of open-source
cyber threat intelligence,” in Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security, 2016, pp. 755–
766.

[20] G. Husari, E. Al-Shaer, M. Ahmed, B. Chu, and X. Niu, “Ttpdrill:
Automatic and accurate extraction of threat actions from unstructured
text of cti sources,” in Proceedings of the 33rd annual computer security
applications conference, 2017, pp. 103–115.

[21] Z. Zhu and T. Dumitras, “Chainsmith: Automatically learning the
semantics of malicious campaigns by mining threat intelligence reports,”
in 2018 IEEE European symposium on security and privacy (EuroS&P).
IEEE, 2018, pp. 458–472.

[22] N. Sun, J. Zhang, P. Rimba, S. Gao, L. Y. Zhang, and Y. Xiang, “Data-
driven cybersecurity incident prediction: A survey,” IEEE communica-
tions surveys & tutorials, vol. 21, no. 2, pp. 1744–1772, 2018.

[23] Z. Zhu and T. Dumitras¸, “Featuresmith: Automatically engineering
features for malware detection by mining the security literature,” in
Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security, 2016, pp. 767–778.

[24] J. Caballero, C. Grier, C. Kreibich, and V. Paxson, “Measuring {Pay-per-
Install}: The commoditization of malware distribution,” in 20th USENIX
Security Symposium (USENIX Security 11), 2011.

