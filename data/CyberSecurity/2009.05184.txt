0
2
0
2

p
e
S
1
1

]
P
S
.
s
s
e
e
[

1
v
4
8
1
5
0
.
9
0
0
2
:
v
i
X
r
a

STEP-GAN: A STEP-BY-STEP TRAINING FOR MULTI GENERATOR GANS WITH
APPLICATION TO CYBER SECURITY IN POWER SYSTEMS

Mohammad Adiban†, Arash Safari∗, Giampiero Salvi†

†Electronic Systems Department, Norwegian University of Science and Technology, NO-7491 Norway
∗School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran
E-mails: {mohammad.adiban,giampiero.salvi}@ntnu.no, & safari.arash@ut.ac.ir

ABSTRACT

In this study, we introduce a novel unsupervised countermeasure for
smart grid power systems, based on generative adversarial networks
(GANs). Given the pivotal role of smart grid systems (SGSs) in ur-
ban life, their security is of particular importance. In recent years,
however, advances in the ﬁeld of machine learning, have raised con-
cerns about cyber attacks on these systems. Power systems, among
the most important components of urban infrastructure, have, for
example, been widely attacked by adversaries. Attackers disrupt
power systems using false data injection attacks (FDIA), resulting
in a breach of availability, integrity, or conﬁdential principles of the
system. Our model simulates possible attacks on power systems us-
ing multiple generators in a step-by-step interaction with a discrimi-
nator in the training phase. As a consequence, our system is robust to
unseen attacks. Moreover, the proposed model considerably reduces
the well-known mode collapse problem of GAN-based models. Our
method is general and it can be potentially employed in a wide range
of one of one-class classiﬁcation tasks. The proposed model has low
computational complexity and outperforms baseline systems about
14% and 41% in terms of accuracy on the highly imbalanced pub-
licly available industrial control system (ICS) cyber attack power
system dataset.

Index Terms— Power System, Cyber Attacks, Security, GAN,

Unsupervised, Mode Collapse

1. INTRODUCTION

Cyber-physical systems (CPS) are deﬁned as transformative tech-
nologies that integrate interconnected systems, including physical
devices and computational networks in order to control and monitor
physical processes [1]. A Smart Grid System (SGS), as one of the
primary types of CPS, consists of a variety of operational and energy
measurements, including smart meters and appliances, renewable
energy resources, and energy efﬁciency resources [2]. Due to the
development and importance of smart grid systems, concerns about
the security of SGSs are signiﬁcantly increasing, inasmuch as these
systems are subjectable to cyber attacks and since reports of sabotage
and spooﬁng attacks on smart systems are increasing [3,4]. Further-
more, with the advances in technology, cyber-attacks are becoming
more blended and sophisticated, enabling adversaries to easily tar-
get multiple layers of a power system simultaneously [5–7]. These
attacks aim to affect the performance of the system by altering the

G. Salvi is also afﬁliated with KTH Royal Institute of Technology,
School of Electrical Engineering and Computer Science, Stockholm, Swe-
den.

transmitted data or adding manipulated data that leads to a breach of
availability, integrity, or conﬁdential principles [8].

Among smart grids, power systems are one of the most effective
and widespread infrastructure components on which today’s society
is increasingly dependent. These grids are signiﬁcantly threatened
by cyber attacks [9–12]. To assure the safety and reliability of op-
erations in power systems, many crucial data measurements, includ-
ing electricity power ﬂow and bus power injection, are continuously
monitored [13]. In the next step, the monitored data is transmitted to
a dispatching center system by a state estimation function of a super-
visory control and data acquisition (SCADA) system that obtains the
real-time operation state of power systems [14]. Most of the studies
that attempt to detect cyber attacks in smart grid power systems au-
tomatically, use some form of supervision assuming the nature of
the attacks is known [15–19]. While collecting attack data is a chal-
lenging process, with the advancement of technology, attackers are
able to use a variety of sophisticated methods to perform innovative
cyber attacks, making it difﬁcult to predict the nature of the attacks.
Furthermore, labeled data is not always available in the real world,
and data labeling is a costly and time-consuming process, requiring
the use of human resources that can be associated with human error.
An alternative approach is to treat attack detection in smart
grid systems as an unsupervised machine learning task. However,
many of the unsupervised techniques related to anomaly detection
in smart grid systems have been developed based on linear projec-
tion and transformation that is inadequate to deal with the inherent
non-linearity of multivariate time series data (e.g power systems
data) [20]. Also, most current methods use a simple comparison
between the current mode and the predicted normal range to detect
cyber attacks, which is mostly insufﬁcient owing to the inherent
complexity and high dimensionality of smart grids data. Recently,
the generative adversarial networks (GANs) have been proposed
to anomaly detection tasks [21–23]. Although GAN models have
been widely and successfully used in many tasks such as image
processing, their use in time-series data processing is much more
rare despite their successful performance in generating time-series
sequences [20,24,25]. One of the main problems that GANs suffer
from is mode collapse [26] which refers to the problem of missing
some of the modes of the multi-modal data it was trained on.

In this study, we propose a novel unsupervised GAN-based
countermeasure to detect anomalies on smart grid power systems,
which is inspired by [20] and [21]. Unlike many traditional tech-
niques, our proposed method detects anomalies in an unsupervised
fashion regardless of the nature of the attacks. The proposed model
attempts to simulate the distribution of attack data, assuming that
logically possible attacks on the power system have a complemen-
tary distribution [21,27] close to the real data distribution. Here,

 
 
 
 
 
 
mining approach to accurately extract patterns of power-system dis-
turbances and cyber-attacks from heterogeneous time-synchronized
data, consisting of synchrophasor measurements, relay logs, and
network event monitor logs. Karimipour et al. [10] presented a
state estimation algorithm to detect FDI attacks in power systems.
To this aim, they proposed an analytical technique based on the
Markov chain theory and Euclidean distance metric. Their results
show improvement in the traditional bad data detection method.
In another work [18], the authors proposed an unsupervised neu-
ral network, called autoencoders (AE) [30] to extract meaningful
features from power systems data. Then, they employed multiple
traditional machine learning based classiﬁers, including artiﬁcial
neural network, decision Tree, K-nearest neighbor, random forest,
gradient boosting, and Adaboost in order to detect cyber-attacks.
Basumallik et al. [31] proposed a convolutional neural network
(CNN) data ﬁlter with Nesterov Adam gradient descent and cate-
gorical cross-entropy loss to validate the phasor measurement units
(PMU) data. This ﬁlter extracts inter time-series relationships to
classify different power system events by comparing the temporal
structure of PMU packet data. [32] proposed a security model based
on the Conditional Generative Adversarial Network (CGAN) [33]
which models the conditional probability distribution between the
various information ﬂow that provides a theoretical foundation to
enable a system-level methodology for the design and analysis of
cyber physical production systems against cross-domain attacks.
They also used a generation algorithm to search and prune the graph
in order to reduce the complexity of the model. Hassan et al. [34]
proposed a supervised method using a combination of the Random
Subspace (RS) Method with a random tree (RT) classiﬁer, named
RSRT, to create a reasonable set of base learners. Their proposed
model can construct a set of random trees using different randomly
selected subsets of features from all different random features of
the training dataset. As a result, the ensembles of trees are able
to reduce redundancy of features and prevent the system to overﬁt,
which keeps the strength of the individual trees over the split random
selection. Results show their model achieved high attack detection
rates on ICS power system cyber attack Mississippi State University
dataset [19].

3. METHOD

The main task of anomalies detection for sequential data is to de-
termine whether the distributions of new observations ﬁt the distri-
bution of normal data learned in the training phase. Several terms
are used to describe non-ﬁtting points in different domains: anoma-
lies, outliers, intrusions, failures, or contaminants. We propose an
innovative countermeasure that attempts to model and detect the dis-
tributions of possible types of attacks in an unsupervised fashion on
power systems based on generative adversarial networks (GANs). In
the GAN objective, the task of a generator is usually more difﬁcult
than the task of the discriminator since the generator has to generate
fake samples that maximize the mistake of the discriminator [20].
This fact, in addition to the min-max nature of GAN objective func-
tion, leads to several issues for GAN-based models, such as mode
collapse, requiring large amounts of training data, and difﬁcult opti-
mization. Unlike conventional GANs, the discriminator plays a more
important role in our model.
In addition, we tried to address the
mode collapse problem by increasing the number of generators as
well as by providing an interaction between the discriminator and
the generators, relying on the performance of the discriminator. Our
method is inspired by two GAN-based models, called one-class ad-
versarial networks (OCAN) [21] and multi-agent diverse generative

Fig. 1: A simple schematic of complementary distribution. Blue
points indicate normal data and red points follow the complementary
distribution of normal data.

complementary distribution refers to a term in which the generated
data deﬁne a distribution that approaches the normal data distribu-
tion with minimal overlap (see Figure 1).
Intuitively, attack data
capable of deceiving power systems is expected to follow the com-
plementary distribution of normal data.

More importantly, our approach provides a new technique for re-
solving mode collapse problems and seeks to model potential modes
in which attacks (anomalies) can occur. As a result, our system is po-
tentially more robust to unseen attacks. Our contributions are sum-
marized as follow:

• we propose a novel step-by-step training for multi genera-
tors GAN-based countermeasure against False Data Injection
(FDI) attacks on power systems for the ﬁrst time, which is
robust to unseen attacks,

• we show that our model considerably reduces the well-known

mode collapse issue of GANs,

• the proposed method is general and it can be used in a wide

range of tasks,

• we demonstrate that the proposed method signiﬁcantly out-
performs the baseline systems in terms of accuracy and F-
measure on the highly imbalanced publicly available indus-
trial control system (ICS) cyber attack power system dataset.

The remainder of this paper is organized as follows. First, we
list the related studies in Section 2. Then, the proposed method is
introduced in Section 3. Subsequently, we give a brief explanation
of the experimental setup in Section 4. Results and discussion are
presented in Section 5 and 6. Finally, we conclude the paper in
Section 7.

2. RELATED WORKS

Many cyber physical attack detection techniques have been devel-
oped in recent years. In this section, we present a brief discussion
of the methods in this area. Lee et al.
[28] proposed a method to
model the malicious cyber attack inside the system estimation using
the expectation-maximization (EM) algorithm. They used the EM
algorithm to ﬁnd missing data and to optimize intractable likelihood
function. The work presented in [29] provided a sequential pattern

Fig. 2: Architecture of the Proposed System.

adversarial networks (MAD-GAN) [20]. The former was originally
proposed for fraud detection on online applications such as social
media. In the ﬁrst step, OCAN captures the meaningful representa-
tion of normal users from their sequences of online activities using
the long short term memory-autoencoder (LSTM-AE) [35]. In the
next step, it trains a discriminator of a complementary GAN model
in order to detect malicious users. The main difference between reg-
ular GAN and complementary GAN is that the generator in regular
GAN learns to reconcile the distribution of the generated fake data
representation to the representation of normal data. However, the
generator in complementary GAN is trained to generate a distribu-
tion of data that is close to the complementary distribution of the
normal data. The idea behind the complementary GAN is based on
the fact that the distribution of attack data, which is capable of mis-
leading systems, is similar to normal data but not exactly the same.
As a result, it can intuitively be argued that the distribution of at-
tack data is close to the complementary distribution of normal data.
On the other hand, the MAD-GAN was originally proposed to re-
solve the well-known mode collapse problem of regular GANs. To
this end, the MAD-GAN introduces a multi-agent GAN framework
that utilizes multiple generators and one discriminator. The gener-
ators are trained to generate diverse high probability regions of the
real data distribution, resulting in different identiﬁable modes. The
discriminator aims to differentiate between normal data and gener-
ated data by learning the distribution of generators and normal data.
Whereas, the generators aim to maximize the discriminator error.

Our method uses n generators as MAD-GAN, but tries to learn
the complementary data distribution as OCAN. Constraints on the
optimization ensure that the mode collapse problem is reduced.

3.1. Proposed System

The overall architecture of the proposed system is shown in Figure.
2. The model involves n generators and one discriminator. The
discriminator D(x; θd) assigns each observation x to one of n + 1

classes determining if the observation has been generated by one
of the n generators or belongs to the real data (class n + 1). To
train our system, similarly to regular GANs, we apply prior input
noise z ∼ pz to the multiple generators. Each generator i outputs a
fake sample ˜xi = Gi(z; θi
g) according to the distribution pgi . The
parameters θi
g of each generator are optimized by minimizing the
objective function

E
x∼pd

log Dn+1(x : θd)+ E
z∼pz

log(1−Dn+1(Gi(z; θi

g); θd)), (1)

where Dn+1(x; θd) is the probability that observation x belongs to
the real data, pd is the probability distribution of the real data, and pz
is the distribution of noise. The joint objective of all the generators
is to minimize

E
x∼pd

log Dn+1(x) +

n
(cid:88)

i=1

E
x∼pgi

log(1 − Dn+1(x)).

(2)

Simultaneously, the objective of the discriminator, which is optimiz-
ing θd, is to maximize:

E
x∼p

H(δ, D(x, θd)),

(3)

where δ ∈ {0, 1}n+1, and for i ∈ {1, ..., n}, δ(i) = 1 if the sample
belongs to the i-th generator, otherwise δ(n + 1) = 1 and H(., .)
is the negative of the cross entropy function. Obviously, the dis-
criminator needs to learn to push different generators towards differ-
ent identiﬁable modes in order to accurately recognize the generator
that generated a given fake data. Nevertheless, the objective of each
generator is the same as the objective of the generator in the stan-
dard GAN. Finally, in order to force the generators to generate data
with wider distributions, we apply a condition on a min-max inter-
action between generators and discriminators. The generators keep
learning as long as the sensitivities (SEs) and speciﬁcities (SPs) [36]

Normal DataNoise  GeneratorsNormal / Attack3Power SystemTraining Controller Unit12nDiscriminatorFake Datain Algorithm 1. Both the objective function Eq. 4 and the interaction
between the generators and the discriminator are intended to ensure
that the generated fake samples are not only well distributed in the
plane, but they are also similar to the real-world attack samples. If
this is true, it can be argued that the generated fake data (simulated
attack samples) by the generators can be sued as a simulation of
potential real-world attacks to power systems.

Result: Anomalies Detection in Power Systems.

% Training phase;

while (Epoch number < Max epoch) do

while (SE < α) and (SP < β) do

Train Discriminator().

end

Train Generators().

end

% Testing phase;

Discriminate normal data from attack data by Dn+1(x).

Algorithm 1: The proposed method algorithm. SE and SP indicate
Sensitivity and Speciﬁcity, respectively. hyper-parameter α and β
are adjustable thresholds.

3.2. Evaluation

During the evaluation, the trained discriminator decides which class
the input data belongs to (attack or normal data) using a softmax
function. Being this a binary classiﬁcation problem, we use accu-
racy and F-measure to evaluate the system performance. We also
used a 10-fold cross-validation strategy for training and testing the
proposed model. In this strategy, we randomly assigned 10% of the
dataset to the test set and the rest of the normal data are used to train
the system. This division will be repeated ten times, and the testing
result is the average of testing results for the ten times.

4. EXPERIMENTAL SETUP

The generators are composed of three fully connected layers with 50,
300 and 128 nodes for each layer, respectively. All the hidden layers
use Parametric ReLU (PReLU) [37] activation functions, whereas
the last layer uses Tanh activation function. The discriminator con-
sists of 6 fully connected layers (4 hidden layers). The input layer of
the discriminator consists of 128 nodes. Each hidden layer includes
300 nodes with Leaky ReLU activation function [38], whereas the
output layer has n + 1 softmax nodes that compute the probabil-
ity of an input sample to be a normal or attack. We use the Adam
optimizer [39] for training generators and the discriminator. The
cross-entropy is used as a loss function.

The main experimental parameters that are varied in our exper-
iments are the number of generators in the model that can assume
any value in {1, 2, 3, 5, 10, 15, 20} and the hyper-parameters α and
β that are varied between 0.55 and 1.0 in intervals of 0.05. All mod-
els are implemented in PyTorch [40].

4.1. Baseline systems

In order to evaluate the performance of our method, we compare it
to the two architectures the proposed method is inspired by, namely

Epoch number = 1.

Epoch number = 10.

Epoch number = 50.

Epoch number = 100.

Fig. 3: The schematic of train cycle. Green points indicate normal
data and red points represents generated data in each cycle. In each
training cycle, the generated data converges to the complementary
distribution of normal data.

from the discriminator are above the values of two hyper-parameters
α and β, respectively. When these values fall below the thresholds α
or β, we pause training the generators until the discriminator learns
to perform better than those thresholds values.

As a result, the proposed method objective can be written as

min
θg
(SE>α,SP>β)

max
θd

V (θd, θg) := E

x∼pd

log Dn+1(x)+

+

n
(cid:88)

i=1

E
x∼pgi

log(1 − Dn+1(x)) + E
x∼p

H(δ, D(x, θd)).

(4)

The training process is illustrated in Figure. 3. Similar to reg-
ular GAN, the objective functions of the generators try to learn the
distribution of the normal data and then generate fake data that has
a minimum difference with the distribution of normal data. How-
ever, the discriminator tries to learn to maximally discriminate the
generated fake samples from real data. One of the main differences
between our model and regular GAN is that the discriminator identi-
ﬁes the generated data that belongs to different generators (Eq. 3). It
then maximizes the dissimilarity of the distributions corresponding
to each generator. This is similar to MAD-GAN, but is not sufﬁ-
cient to resolve the mode collapse problem completely (as we will
illustrate later in Figure. 7). We improve the resolution of mode col-
lapse by employing two thresholds in the training phase as explained
above. Inspired by this step-by-step training process, we named our
proposed model STEP-GAN. Using this strategy, we do not fully op-
timize the generators. This results in more spread distributions that
can better cover the complementary distribution of normal data (see
Figure. 7-c). This cycle repeats until it guarantees that the discrimi-
nator is well trained to detect anomalies from real data, and the gen-
erators are able to generate a wide distribution of possible attach
data.

The algorithm of the proposed attack detection model is shown

Fig. 4: Distribution of benchmark datasets.

one-class adversarial networks (OCAN) and multi-agent diverse
generative adversarial networks (MAD-GAN). Similar to regular
GAN, the OCAN uses one generator and a complementary dis-
criminator. However, MAD-GAN uses multiple generators and
one discriminator. We also examined the MAD-GAN model with
various number of generators as we do for the proposed model.

4.2. Dataset

The experiments are conducted on an open-source simulated ICS
cyber attack dataset obtained from Supervisory Control and Data
Acquisition (SCADA) power systems provided by Mississippi State
University [19]. The dataset contains three groups including Binary,
Three-Class, and Multiclass datasets. Each group is made from one
initial dataset including 15 subsets that consist of 37 power system
event scenarios, compromising 28 Attack Events, 1 No Events, and
8 Normal Events. The benchmark distribution of each dataset in-
stances is shown in Figure. 4. Each instance includes 128 ﬁxed-
length dimensional sequential data.
In this study, we used binary
classiﬁcation events for detecting the FDI attacks on the SCADA
In order to reduce the effect of a small sample size, the
system.
datasets were randomly sampled at 1% to reduce the size and evalu-
ate the effectiveness of small sample sizes. The dataset statistics of
binary class events classiﬁcation is summarized in 1.

Fig. 5: The heat-map diagram of the results obtained from the pro-
posed model for different values of α and β and a ﬁxed ten genera-
tors.

Table 2: Average results of the proposed method (STEP-GAN) in
terms of accuracy(%) on 15 subsets.

#Generators

1
2
3
5
10
15
20

Hyper-parameters (α, β)
(0.95,0.95) (0.9,0.9) (0.8,0.8) (0.7,0.7) (0.6,0.6)
59.27
78.81
82.67
95.44
97.29
92.11
89.26

53.91
57.50
66.89
74.30
79.56
69.21
64.18

43.81
50.07
55.99
67.31
72.52
68.45
63.83

68.56
89.78
96.45
100.0
100.0
97.31
95.82

71.06
92.36
97.40
100.0
100.0
100.0
100.0

F-measure deﬁned as follows:

Accuracy =

F-measure =

TP + TN
TP + TN + FP + FN
2 × TP
2 × TP + FN + FP

,

,

(5)

(6)

Table 1: The dataset statistics of binary classiﬁcation events.

where TP , TN , FP and FN indicate true positive, true negative,
false positive and false negative, respectively.

Subset

#Event Scenario

#Instances

No Events
Natural Event
Attack
Total

1
8
28
37

294
1221
3711
5226

4.3. Evaluation Metrics

The detection of cyber-physical attacks in power systems is a binary
classiﬁcation task, in which data sequences from real sources (No
Events or Natural Events) are labeled as positive classes and attack
data are labeled as negative classes. Therefore, to verify the perfor-
mance of the proposed method we used two metrics: Accuracy and

5. RESULTS

Table 2 shows average accuracy as a function of the number of gener-
ators and different values for the hyper-parameters. The performance
is strongly dependent both on the number of generators and on the
values of the hyper-parameters. Best results are obtained for more
than 5 generators and for α and β over 90%. In order to examine
the effects of α and β on the proposed model, we ﬁxed the num-
ber of generators to 10 and varied α and β with ﬁner intervals. The
corresponding results are show in Figure. 5. The results show that
variations in α values affect the performance of the model more than
β variations. This means that the model is more dependent on the
performance of the discriminator for detecting normal data (higher
value of sensitivity) than the performance of generators for simulat-
ing fake data (higher values of speciﬁcity). In the following we will

386635253811340236803490391037713570392139693453411837623415927122212501397121112871118118812921322113715879501274134717332235440327019020835647832614538420379514050010001500200025003000350040004500S1S2S3S4S5S6S7S8S9S10S11S12S13S14S15Number of instancesSubsetAttackNaturalNo Event0.550.600.650.700.750.800.850.900.951.001.000.950.900.850.800.750.700.650.600.55Accuracy(%) heatmap daigram.73.3177.2972.4472.5273.2980.176.4572.3474.1975.6486.2282.1777.8473.373.7979.3279.5673.2479.3380.6687.0688.3786.5881.1583.6685.0285.1180.6383.6782.4396.5998.1895.4598.9197.2992.1787.3584.9188.5181.6487.6792.5910097.7198.3494.1989.0888.3282.2979.685.9998.8610094.2997.1397.4792.986.6677.6474.3981.4810010010096.8597.3793.3487.0780.2376.7482.4597.5795.1492.2990.1988.784.6979.1570.0166.9862.7957.1260.3658.5762.0966.4868.4563.5658.7964.3869.562.3565.8969.268.496968.3270.5370.5966.26065707580859095100Fig. 6: A comparison of STEP-GAN (top), MAD-GAN (middle) and OCAN (bottom) for each subset. The results are obtained from the best
conﬁgurations of each system for 10 independent repetitions of training the systems. In the case of STEP-GAN, α and β are set 0.9 and 10
generators are used for training the STEP-GAN.

Table 3: A comparison of the best results obtained from the differ-
ent numbers of the proposed system (STEP-GAN) generators and
baseline systems.

System
RSRT [34]
OCAN

MAD-GAN

Step-GAN
(proposed)

#Generators
-
(Default = 1)
1
2
3
5
10
15
20
1
2
3
5
10
15
20

Accuracy% F-measure
not reported
0.3510
0.3021
0.3605
0.5984
0.6237
0.6629
0.7044
0.7390
0.6789
0.9476
0.9601
1.0000
1.0000
1.0000
1.0000

95.95
70.64
64.77
69.46
74.32
77.20
80.91
83.05
87.53
71.06
92.36
97.04
100.00
100.00
100.00
100.00

use our method with hyper-parameters (α, β) = (0.9, 0.9).

Table 3 shows a comparison between the proposed model and
the baseline models. We also included results reported in [34] for
comparison. From the table, it is clear that STEP-GAN outperforms
MAD-GAN and OCAN for this task in all conﬁgurations, that is,
both in absolute terms but also for an equal number of generators.
STEP-GAN with 5 or more generators also outperforms RSRT [34].
The best conﬁguration for our model and the baseline models are
compared in Figure 6. The boxplots show the results over 10 inde-
pendent repetitions, and for each subset of the database. This ﬁgure
shows how the performance improvement for our system is consis-
tent and stable over repetitions and over subsets of the database.

Figure 7 illustrates the behaviour of the proposed systems when
addressing the model collapse issue. We used t-SNE to project the
original and generated data onto a two-dimensional space for visu-

alization. Compared to OCAN (Figure 7a) and MAD-GAN (Fig-
ure 7b), STEP-GAN (Figure 7c) obtains a wider coverage of the
space surrounding the real data, and thus a reduced mode collapse
problem with a lower number of generators. As a consequence we
obtain a more general model and prevent overﬁtting.

Finally, Figure 8 shows the convergence behavior of the pro-
posed model compared to MAD-GAN and OCAN for the best of
their conﬁgurations. As can be seen in Figure 8, STEP-GAN con-
verges using fewer number of epochs. However, MAD-GAN and
OCAN require a higher number of epochs to converge. The remark-
able point is that the OCAN system, despite using only one genera-
tor, needs more epochs to converge, indicating the advantage of our
proposed system in computational complexity.

6. DISCUSSION

A system that is successful in detection of cyber-attacks on power
grids or other systems, should be able to predict data that has not
been seen during training. A GAN based system is particularly suit-
able for this kind of application since the generators can be encour-
aged to generate data outside the normal data distribution by choos-
ing the proper optimality criterion. When the distributions are com-
plex, it is beneﬁcial to employ several generators in order to explore
the space more thoroughly. However, doing this creates a trade-off:
that can be seen in Figure 7: fewer generators may result in poor
exploration of the space (Figure 7a), but more generators can result
in overﬁtting and the phenomenon known as mode collapse (Fig-
ure 7b). Our system can take advantage of the increased number
of generators, and at the same time reduce mode collapse by care-
fully limiting the optimization of the generators during training, and
therefore avoiding overﬁtting (Figure 7c).

On one hand, a high sensitivity value is crucial when only real
data is available. Given the role assigned to the discriminator in our
task, it is exceedingly important for the proposed system to be able to
correctly detect normal data. This means that we expect the model
to reach a high sensitivity ratio. A proper choice of α allows the
discriminator to competently detect the normal data. Experimental
results show that 0.9 is an optimal choice for α both in terms of ac-
curacy and acceleration of the training process. On the other hand,

123456789101112131415Subset6065707580859095100Accuracy %Accuracy (%) vs Subsets and Systems.SystemSTEP-GANMAD-GANOCAN(a) OCAN

(b) MAD-GAN

(c) STEP-GAN

Fig. 7: A t-SNE comparison of generated data by (a) OCAN, (b) MAD-GAN, and the (c) proposed method. Green points indicate normal
data, and red points are generated by the model. As it can be seen, OCAN and MAD-GAN suffer from ”mode collapse”. While STEP-GAN
covers the complementary distribution of normal data well.

model was used through a step-by-step training with the interaction
between generators and a discriminator in order to simulate possi-
ble attacks to the system. Results show that our model signiﬁcantly
outperforms baseline systems and results reported in the literature
on the highly imbalanced publicly available ICS cyber attack power
system dataset. Compared to previously proposed methods, the sys-
tem achieves better performance with a lower number of parameters
(fewer generators). The reason for this performance improvement
is that the proposed training procedure mitigates the mode collapse
issue in GAN based systems, and therefore generates more ”space-
ﬁlling” distributions with fewer generators.

8. REFERENCES

[1] Jay Lee, Behrad Bagheri, and Hung-An Kao,

“A cyber-
physical systems architecture for industry 4.0-based manufac-
turing systems,” Manufacturing letters, vol. 3, pp. 18–23,
2015.

[2] Suman Avdhesh Yadav, Shipra Ravi Kumar, Smita Sharma,
and Akanksha Singh,
“A review of possibilities and solu-
tions of cyber attacks in smart grids,” in 2016 International
Conference on Innovation and Challenges in Cyber Security
(ICICCS-INBUSH). IEEE, 2016, pp. 60–63.

[3] Mohammad Adiban, Hossein Sameti, Noushin Maghsoodi,
and Sajjad Shahsavari,
“Sut system description for anti-
spooﬁng 2017 challenge,” in Proceedings of the 29th Con-
ference on Computational Linguistics and Speech Processing
(ROCLING 2017), 2017, pp. 264–275.

[4] Mohammad Adiban, Hossein Sameti,

and Saeedreza
“Replay spooﬁng countermeasure using au-
Shehnepoor,
toencoder and siamese networks on asvspoof 2019 challenge,”
Computer Speech & Language, p. 101105, 2020.

[5] Ralph Langner, “Stuxnet: Dissecting a cyberwarfare weapon,”
IEEE Security & Privacy, vol. 9, no. 3, pp. 49–51, 2011.

[6] Boldizs´ar Bencs´ath, G´abor P´ek, Levente Butty´an, and M´ark
F´elegyh´azi, “Duqu: Analysis, detection, and lessons learned,”
in ACM European Workshop on System Security (EuroSec),
2012, vol. 2012.

Fig. 8: Epoch comparison of the proposed method (STEP-GAN),
MAD-GAN, and OCAN. SG and MG represent ”STEP-GAN” and
”MAD-GAN”, respectively, and the numbers in front of them indi-
cate the number of generators.

we seek generators that can simulate the distribution of hypothetical
attacks data, which logically ﬁts into the complementary distribu-
tion of normal data. A good choice of the β causes fake data to be
generated in the complementary distribution of the normal data. If
the value of hyper-parameter β is too high, the generators lose their
freedom of action, and may not be properly trained. If the β value
is too low, the generated data might be similar to normal data. Ex-
perimental results show that in an interaction between the generators
and the discriminator, the best results are obtained when the β value
is 0.9. Using the aforementioned step-by-step training process, the
generators are able to gradually bring the generated data closer to
the complementary distribution of the normal data. Consequently,
the generators are able to simulate potential attack data and the dis-
criminator is able to competently detect the normal data.

7. CONCLUSION

In this study, we proposed a novel unsupervised countermeasure
against cyber physical false data injection attacks on power systems.
Our model is capable of potentially being employed in a wide range
of one-class classiﬁcation tasks. A multi-generators GAN-based

[7] Zakaria El Mrabet, Naima Kaabouch, Hassan El Ghazi, and
Hamid El Ghazi, “Cyber-security in smart grid: Survey and
challenges,” Computers & Electrical Engineering, vol. 67, pp.
469–482, 2018.

10203040506070Epoch number0.30.40.50.60.70.80.91AccuracySG-15SG-5SG-10MG-5MG-15MG-10OCAN[8] M Zekeriya Gunduz and Resul Das, “Analysis of cyber-attacks
on smart grid applications,” in 2018 International Conference
on Artiﬁcial Intelligence and Data Processing (IDAP). IEEE,
2018, pp. 1–5.

[21] Panpan Zheng, Shuhan Yuan, Xintao Wu, Jun Li, and Aidong
Lu, “One-class adversarial nets for fraud detection,” in Pro-
ceedings of the AAAI Conference on Artiﬁcial Intelligence,
2019, vol. 33, pp. 1286–1293.

[9] Andr´e Teixeira, Saurabh Amin, Henrik Sandberg, Karl H Jo-
hansson, and Shankar S Sastry, “Cyber security analysis of
state estimators in electric power systems,” in 49th IEEE con-
ference on decision and control (CDC). IEEE, 2010, pp. 5991–
5998.

[10] Hadis Karimipour and Venkata Dinavahi, “Robust massively
parallel dynamic state estimation of power systems against
cyber-attack,” IEEE Access, vol. 6, pp. 2984–2995, 2017.

[11] Rong Lai, Xiaoyu Qiu, and Jiajing Wu, “Robustness of asym-
metric cyber-physical power systems against cyber attacks,”
IEEE Access, vol. 7, pp. 61342–61352, 2019.

[12] Lei Chen, Dong Yue, Chunxia Dou, Jianbo Chen, and Zihao
Cheng, “Study on attack paths of cyber attack in cyber-physical
power systems,” IET Generation, Transmission & Distribu-
tion, vol. 14, no. 12, pp. 2352–2360, 2020.

[13] Lanchao Liu, Mohammad Esmalifalak, Qifeng Ding, Valen-
tine A Emesih, and Zhu Han, “Detecting false data injection
attacks on power grid by sparse optimization,” IEEE Transac-
tions on Smart Grid, vol. 5, no. 2, pp. 612–621, 2014.

[14] Jiaqi Ruan, Huaizhi Wang, Saddam Aziz, Guibin Wang, Bin
Zhou, and Xueqian Fu, “Interval state estimation based de-
fense mechanism against cyber attack on power systems,” in
2017 IEEE Conference on Energy Internet and Energy System
Integration (EI2). IEEE, 2017, pp. 1–5.

[15] Jacob Sakhnini, Hadis Karimipour, and Ali Dehghantanha,
“Smart grid cyber attacks detection using supervised learning
and heuristic feature selection,” in 2019 IEEE 7th International
Conference on Smart Energy Grid Engineering (SEGE). IEEE,
2019, pp. 108–112.

[16] Fengli Zhang and Qinghua Li,

“Deep learning-based data
forgery detection in automatic generation control,” in 2017
IEEE Conference on Communications and Network Security
(CNS). IEEE, 2017, pp. 400–404.

[17] Jun Yan, Bo Tang, and Haibo He, “Detection of false data
attacks in smart grid with supervised learning,” in 2016 Inter-
national Joint Conference on Neural Networks (IJCNN). IEEE,
2016, pp. 1395–1402.

[18] Amir Namavar Jahromi, Jacob Sakhnini, Hadis Karimpour,
and Ali Dehghantanha, “A deep unsupervised representation
learning approach for effective cyber-physical attack detection
and identiﬁcation on highly imbalanced data,” in Proceedings
of the 29th Annual International Conference on Computer Sci-
ence and Software Engineering, 2019, pp. 14–23.

[19] Raymond C Borges Hink, Justin M Beaver, Mark A Buckner,
Tommy Morris, Uttam Adhikari, and Shengyi Pan, “Machine
learning for power system disturbance and cyber-attack dis-
crimination,” in 2014 7th International symposium on resilient
control systems (ISRCS). IEEE, 2014, pp. 1–8.

[20] Arnab Ghosh, Viveka Kulharia, Vinay P Namboodiri,
Philip HS Torr, and Puneet K Dokania, “Multi-agent diverse
generative adversarial networks,” in Proceedings of the IEEE
conference on computer vision and pattern recognition, 2018,
pp. 8513–8521.

[22] Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav
Manek, and Vijay Ramaseshan Chandrasekhar, “Efﬁcient gan-
based anomaly detection,” arXiv preprint arXiv:1802.06222,
2018.

[23] Houssam Zenati, Manon Romain, Chuan-Sheng Foo, Bruno
“Adversarially learned
Lecouat, and Vijay Chandrasekhar,
anomaly detection,” in 2018 IEEE International Conference
on Data Mining (ICDM). IEEE, 2018, pp. 727–736.

[24] Olof Mogren,

“C-rnn-gan: Continuous recurrent neu-
arXiv preprint

training,”

ral networks with adversarial
arXiv:1611.09904, 2016.

[25] Crist´obal Esteban, Stephanie L Hyland, and Gunnar R¨atsch,
“Real-valued (medical) time series generation with recurrent
conditional gans,” arXiv preprint arXiv:1706.02633, 2017.

[26] Akash Srivastava, Lazar Valkov, Chris Russell, Michael U Gut-
mann, and Charles Sutton, “Veegan: Reducing mode collapse
in gans using implicit variational learning,” in Advances in
Neural Information Processing Systems, 2017, pp. 3308–3318.

[27] Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and
Russ R Salakhutdinov, “Good semi-supervised learning that
requires a bad gan,” in Advances in neural information pro-
cessing systems, 2017, pp. 6510–6520.

[28] Dongchan Lee and Deepa Kundur, “Cyber attack detection
in pmu measurements via the expectation-maximization algo-
rithm,” in 2014 IEEE Global Conference on Signal and Infor-
mation Processing (GlobalSIP). IEEE, 2014, pp. 223–227.

[29] Shengyi Pan, Thomas Morris, and Uttam Adhikari,

“Clas-
siﬁcation of disturbances and cyber-attacks in power systems
using heterogeneous time-synchronized data,” IEEE Transac-
tions on Industrial Informatics, vol. 11, no. 3, pp. 650–662,
2015.

[30] Andrew Ng et al., “Sparse autoencoder,” CS294A Lecture

notes, vol. 72, no. 2011, pp. 1–19, 2011.

[31] Sagnik Basumallik, Rui Ma, and Sara Eftekharnejad, “Packet-
data anomaly detection in pmu-based state estimator using con-
volutional neural network,” International Journal of Electrical
Power & Energy Systems, vol. 107, pp. 690–702, 2019.

[32] Sujit Rokka Chhetri, Anthony Bahadir Lopez, Jiang Wan, and
Mohammad Abdullah Al Faruque, “Gan-sec: Generative ad-
versarial network modeling for the security analysis of cyber-
physical production systems,” in 2019 Design, Automation &
Test in Europe Conference & Exhibition (DATE). IEEE, 2019,
pp. 770–775.

[33] Mehdi Mirza and Simon Osindero, “Conditional generative
adversarial nets,” arXiv preprint arXiv:1411.1784, 2014.

[34] Mohammad Mehedi Hassan, Abdu Gumaei, Shamsul Huda,
and Ahmad Almogren, “Increasing the trustworthiness in the
industrial iot networks through a reliable cyberattack detection
model,” IEEE Transactions on Industrial Informatics, vol. 16,
no. 9, pp. 6154–6162, 2020.

[35] Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov,
“Unsupervised learning of video representations using lstms,”
in International conference on machine learning, 2015, pp.
843–852.

[36] Abdul Ghaaliq Lalkhen and Anthony McCluskey, “Clinical
tests: sensitivity and speciﬁcity,” Continuing Education in
Anaesthesia Critical Care & Pain, vol. 8, no. 6, pp. 221–223,
2008.

[37] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun,
“Delving deep into rectiﬁers: Surpassing human-level perfor-
mance on imagenet classiﬁcation,” in Proceedings of the IEEE
international conference on computer vision, 2015, pp. 1026–
1034.

[38] Xiaohu Zhang, Yuexian Zou, and Wei Shi, “Dilated convo-
lution neural network with leakyrelu for environmental sound
classiﬁcation,” in 2017 22nd International Conference on Dig-
ital Signal Processing (DSP). IEEE, 2017, pp. 1–5.

[39] Diederik P Kingma and Jimmy Ba, “Adam: A method for
arXiv preprint arXiv:1412.6980,

stochastic optimization,”
2014.

[40] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan,
Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmai-
son, Luca Antiga, and Adam Lerer, “Automatic differentiation
in pytorch,” 2017.

