1
2
0
2

l
u
J

7

]

C
O
.
h
t
a
m

[

3
v
6
9
7
7
0
.
4
0
1
2
:
v
i
X
r
a

Inexact-Proximal Accelerated Gradient Method for Stochastic
Nonconvex Constrained Optimization Problems

Morteza Boroun, Afrooz Jalilzadeh∗

Abstract

Stochastic nonconvex optimization problems with nonlinear constraints have a broad range
of applications in intelligent transportation, cyber-security, and smart grids. In this paper, ﬁrst,
we propose an inexact-proximal accelerated gradient method to solve a nonconvex stochastic
composite optimization problem where the objective is the sum of smooth and nonsmooth
functions, the constraint functions are assumed to be deterministic and the solution to the
proximal map of the nonsmooth part is calculated inexactly at each iteration. We demonstrate
an asymptotic sublinear rate of convergence for stochastic settings using increasing sample-size
considering the error in the proximal operator diminishes at an appropriate rate. Then we
customize the proposed method for solving stochastic nonconvex optimization problems with
nonlinear constraints and demonstrate a convergence rate guarantee. Numerical results show
the eﬀectiveness of the proposed algorithm.

1

INTRODUCTION

There is a rapid growth in the global urban population and the concept of smart cities is proposed
Intelligent transportation, cyber-security,
to manage the impact of this surge in urbanization.
and smart grids are playing vital roles in smart city projects which are highly inﬂuenced by big
data analytic and eﬀective use of machine learning techniques [19]. As data gets more complex
and applications of machine learning algorithms for decision-making broaden and diversify, recent
research has been shifted to constrained optimization problems with nonconvex objectives [14] to
improve eﬃciency and scalability in smart city projects.

Consider the following constrained optimization problem with a stochastic and nonconvex ob-

jective:

f (x) , E[F (x, ζ(ω))]

min
x∈X
s.t. φi(x)

0,

i = 1, . . . , m,

≤

(1)

→

Ro, F : Rn

, P) denotes the associated probability space.
Ro
where ζ : Ω
We consider function f (x) : Rn
R are
deterministic, convex, and smooth for all i, and set X is convex and compact. To solve this
problem, ﬁrst we propose an algorithm for solving the following composite optimization problem

R, and (Ω,
R is smooth and possibly nonconvex, φi(x) : Rn

→

→

→

×

F

∗

Department of Systems and Industrial Engineering, The University of Arizona, 1127 E James Rogers Way, Tucson,

AZ. Email: morteza@email.arizona.edu, afrooz@arizona.edu.

g(x) , f (x) + h(x),

min
x∈Rn

(2)

1

 
 
 
 
 
 
∈

→

R is a convex function and possibly nonsmooth. Using the indicator function
where h(x) : Rn
IΘ(
Θ and IΘ(x) = +
), where IΘ(x) = 0 if x
Θ, one can write problem (1) in the form of
if x /
∞
·
∈
problem (2) by choosing h(x) = IΘ(x) and Θ =
. Moreover,
x
x
}
{
we show that how to customize the proposed method to solve problem (1).
Indeed, proximal-
gradient methods are an appealing approach for solving (2) due to their computational eﬃciency and
fast theoretical convergence guarantee. In deterministic and convex regime, subgradient methods
(1/√T ), however, proximal-gradient methods can
have been shown to have a convergence rate of
achieve a faster rate of
(1/T ), where T is the total number of iterations. Each iteration of a
proximal-gradient method requires solving the following:

i = 1, . . . , m

X, φi(x)

O

O

≤

0,

∈

∀

|

proxγ,h(y) = argmin
u∈Rn {

h(u) +

1
2γ k

u

y

2
k

.
}

−

(3)

In many scenarios, computing the exact solution of the proximal operator may be expensive or
may not have an analytic solution.
In this work, we propose a gradient-based scheme to solve
the nonconvex optimization problem (2) by computing the proximal operator inexactly at each
iteration.

Next, we introduce important notations that we use throughout the paper and then brieﬂy

summarize the related research.

1.1 Notations

We denote the optimal objective value (or solution) of (2) by g∗ (or x∗) and the set of the optimal
. E[
solutions by X ∗, which is assumed to be nonempty. For any a
]
•
}
denotes the expectation with respect to the probability measure P and
.
s
}
k ≤
) denotes the projection onto convex set Θ and relint(X) denotes the relative interior of the
ΠΘ(
·
set X. Throughout the paper, ˜
O

R, we deﬁne [a]+ = max
Rn
(s) =

is used to suppress all the logarithmic terms.

0, a
{
x
| k

x
{

∈

∈

B

1.2 Related Works

There has been a lot of studies on ﬁrst-order methods for convex optimization with convex con-
straints, see [18, 20] for deterministic constraints and [1, 10] for stochastic constraints. Nonconvex
optimization problems without constraints or with easy-to-compute projection on the constraint
set have been studied by [3, 21, 9]. When the function f in problem (2) is convex and h is a
nonsmooth function, [17] showed that even with errors in the computation of the gradient and the
proximal operator, the inexact proximal-gradient method achieves the same convergence rates as
the exact counterpart, if the magnitude of the errors is controlled in an appropriate rate. In non-
convex setting, assuming the proximal operator has an exact solution, [4] obtained a convergence
(1/T ), using accelerated gradient scheme for deterministic problems and in stochastic
rate of
regime using increasing sample-size they obtained the same convergence rate. Inspired by these
two works, we present accelerated inexact proximal-gradient framework that can solve problems
(1) and (2). In deterministic regime, [8] analyzed the iteration-complexity of a quadratic penalty
accelerated inexact proximal point method for solving linearly constrained nonconvex composite
programs with iteration complexity of ˜
(ǫ−3). Inexact proximal-point penalty method introduced
O
by [13] and [11] can solve nonlinear constraints with complexity of ˜
(ǫ−3) for aﬃne
O
equality constraints and nonconvex constraints, respectively. Recently, [12] showed complexity re-
sult of ˜
(ǫ−2.5) for deterministic problems with nonconvex objective and convex constraints with
O

(ǫ−2.5) and ˜
O

O

2

nonlinear functions to achieve ǫ-KKT point. In stochastic regime, [2] has studied functional con-
(ǫ−2) for
strained optimization problems and obtained a non-asymptotic convergence rate of
stochastic problems with convex constraints to achieve ǫ2-KKT point. In this paper, we obtain the
same convergence rate under weaker assumptions. In particular, in contrast to [2], our analysis
does not require the objective function to be Lipschitz and we prove an asymptotic convergence
rate result. Next, we outline the contributions of our paper.

O

1.3 Contributions

In this paper, we consider a stochastic nonconvex optimization problem with convex nonlinear
constraints. We propose an inexact proximal accelerated gradient (IPAG) method where at each
iteration the projection onto the nonlinear constraints is solved inexactly. By improving the accu-
racy of the approximate solution of the proximal subproblem (projection step) at an appropriate
rate and ensuring feasibility at each iteration combined with a variance reduction technique, we
(1/T ), where T is the total number of iterations, and the
demonstrate a convergence rate of
(1/ǫ2) to achieve an ǫ-ﬁrst-order optimality
oracle complexity (number of sample gradients) of
of problem (1). To accomplish this task, ﬁrst we analyze the proposed method for the composite
optimization problem (2) which can be specialized to (1) using an indicator function. Moreover,
our proposed method requires weaker assumptions compare to [2].

O

O

Next, we state the main deﬁnitions and assumptions that we need for the convergence analysis.
In Section 2, we introduce the IPAG algorithm to solve the composite optimization problem and
then in Section 2.1 we show that IPAG method can be customized to solve a nonconvex stochastic
optimization problem with nonlinear constraints (1). Finally, in section 3 we present some empirical
experiments to show the beneﬁt of our proposed scheme in comparison with a competitive scheme.

1.4 Assumptions and Deﬁnitions

Let ρ be the error in the calculation of the proximal objective function achieved by ˜x, i.e.,

1
2γ k

˜x

y

2 + h(˜x)
k

−

≤

ρ + min
x∈Rn

1
2γ k

x

y

−

(cid:26)

2 + h(x)
k

(cid:27)

,

(4)

and we call ˜x a ρ-approximate solution to the proximal problem. Next, we deﬁne ρ-subdiﬀerential
and then we state a lemma to characterize the elements of the ρ-subdiﬀerential of h at x.

Deﬁnition 1 (ρ-subdiﬀerential). Given a convex function h(x) : Rn
the ρ-approximate subdiﬀerential of h(x) at a point x

Rn, denoted as ∂ρh(x), is

→

R and a positive scalar ρ,

∂ρh(x) =

d
{

Rn : h(y)

≥
∂ρh(x), we say that d is a ρ-subgradient of h(x) at point x.

i −

−

∈

d, y
h

x

.
ρ
}

∈
h(x) +

Therefore, when d

∈

Lemma 1. If ˜x is a ρ-approximate solution to the proximal problem (3) in the sense of (4), then
there exists v such that

√2γρ and

v
k

k ≤

∈
Proof of Lemma 1 can be found in [17]. Throughout the paper, we exploit the following basic

−

−

1
γ (y

˜x

v)

∂ρh(˜x).

lemma.

3

Lemma 2. Given a symmetric positive deﬁnite matrix Q, we have the following for any ν1, ν2, ν3:

ν1)T Q(ν3 −

ν3 −
(ν2 −
k
In our analysis we use the following lemma [4].

ν2 −
(
k

ν1) =

ν1k

2
Q +

1
2

ν1k

2
Q − k

ν2 −

2
Q), where

ν3k

ν
k

kQ ,

νT Qν.

p

Lemma 3. Given a positive sequence αk, deﬁne Γk = 1 for k = 1 and Γk = (1
χk}k satisﬁes χk ≤
k > 1. Suppose a sequence
{
Γk
1, we have that χk ≤
k
The following assumptions are made throughout the paper.

αk)Γk−1 for
αk)χk−1 + λk, where λk > 0. Then for any

k
j=1 γj/Γj.

P

(1

−

−

≥

Assumption 1. The following statements hold:

(i) A slater point of problem (1) is available, i.e., there exists x◦

all i = 1, . . . , m and x◦

relint(X).

∈

Rn such that φi(x◦) < 0 for

∈

(ii) Function f is smooth and weakly-convex with Lipschitz continuous gradient, i.e. there exists

x

−

−

≥

L, ℓ

f (y)

f (x)

ℓ
y
2 k

0 such that

2
k
≤
−
(iii) There exists C > 0 such that
proxγ,h(y)
k
(iv) E[ξk | Fk] = 0 holds a.s., where ξk ,
| Fk]
≤

k ≤
f (zk)
holds a.s. for all k and

¯ξkk
that E[
k
Nk
j=1 ∇f (zk)−∇F (zk,ωj,k)
¯ξk , P
Nk

τ 2
Nk

∇

.

2

f (x), y

L
y
2 k
− h∇
C for any γ > 0 and y

i ≤

−

x

x

2.
−
k
Rn.

∈

− ∇
Fk , σ

F (zk, ωk). Also, there exists τ > 0 such
z0, ¯ξ0, z1, ¯ξ1 . . . , zk−1, ¯ξk−1}
, where
{
(cid:1)
(cid:0)

Note that Assumption 1 is a common assumption in nonconvex and stochastic optimization
problems and it holds for many real-world problems such as problem of non-negative principal
component analysis and classiﬁcation problem with nonconvex loss functions [16].

2 CONVERGENCE ANALYSIS

M

z
k

proxλh(z

In this section, we propose an inexact-proximal accelerated gradient scheme for solving problem
(2) assuming that an inexact solution to the proximal subproblem exists through an inner al-
gorithm
. Later in section 2.1, we show that how the inexact solution can be calculated at
each iteration for problem (1). Since problem (2) is nonconvex, we demonstrate the rate result
which is a standard termination criterion for solving con-
in terms of
strained or composite nonconvex problems [15, 5, 4]. For problem (1), the ﬁrst-order optimality
f (z∗)) for some λ > 0. Hence,
condition is equivalent to ﬁnd z∗ such that z∗ = ΠΘ(z∗
we show the convergence result in terms of ǫ-ﬁrst-order optimality condition for a vector z, i.e.,
z
k
∇
Assumption 2. For a given c

Rn and γ > 0, consider the problem ˜u , proxγh (c). An algorithm
(1/t2) within t steps exists, such

∈
with an initial point u0, output u and convergence rate of

2
f (z))
k

f (z))
k

ΠΘ(z

∇

∇

−

−

−

≤

−

−

ǫ.

λ

λ

λ

M
that

u
k

−

˜u

2
k

(a1k

u0 −

˜u

≤

2 + a2)/t2 for some a1, a2 > 0.
k

O

4

Rn, positive sequences

αk, γk, λk}k and Algorithm
{

Algorithm 1 Inexact-proximal Accelerated Gradient Algorithm (IPAG)
input: x0, y0 ∈
for k = 1 . . . T do
(1)
zk = (1
(2) xk ≈
(3)
yk ≈
end for
Output:
1

αk)yk−1 + αkxk−1;
xk−1 −
λk(
zk −
(cid:0)
(cid:0)

(solved inexactly by algorithm
(cid:1)

zN where N is randomly selected from

−
proxγkh
proxλkh

T /2, . . . , T
{

∇
f (zk) + ¯ξk)

f (zk) + ¯ξk)

(solved inexactly by algorithm

γk(

M

∇

}

(cid:1)

satisfying Assumption 2;

with qk iterations);

with pk iterations);

M

M

with Prob

N = k
{

}

=

PT

k=⌊T /2⌋

1−Lλk
16λkΓk (cid:16)

1−Lλk
16λkΓk

.

(cid:17)

proxλkh(zk
λk(

Suppose the solutions of proximal operators ˜xk , proxγkh

xk−1 −

γk(

∇

f (zk) + ¯ξk)

and ˜yk ,

∇

f (zk) + ¯ξk)) are not available exactly, instead an ek-subdiﬀerential solution xk and ρk-
−
In particular, given ¯ξk for the proximal
subdiﬀerential solution yk are available, respectively.
subproblem in step (2) and (3) of Algorithm 1 at iteration k, Assumption 2 immediately im-
with initial point xk−1 and yk−1, we have
plies that after qk and pk steps of Algorithm
k, for some c1, c2, b1, b2 > 0
xk−1 −
ek = γk(c1k
where γk, λk represents strong convexity of the subproblems, respectively. Later, in Section 2.1, we
show the existence of Algorithm

M
yk−1 −
k and ρk = λk(b1k
such that it satisﬁes Assumption 2.

2 + b2)/p2

2 + c2)/q2

˜xkk

˜ykk

(cid:0)

(cid:1)

M

Remark 1. Note that from Assumption 1(iii) and 2, we can show the following for all k > 0:

xk −
k

2

˜xkk

≤

1
q2
k

xk−1 −
2c1(
k

2 +

˜xk−1k

˜xk−1 −
k

2) + c2

˜xkk

xk−1 −

≤ k

˜xk−1k

2 + 8C2+c2

q2
k

=

xk −

⇒ k

(cid:2)
2

˜xkk

x0 −

≤ k

2 +

˜x0k

k

Xj=1

8C2+c2
q2
j

=

xkk ≤

⇒ k

(cid:3)
C +

x0 −
k

q

2 + ˜C , B1,

˜x0k

(5)

where ˜C ,
1, there exist B2, B3 > 0 such that the followings hold for all k > 0,

and we used the fact that

˜xkk ≤
k

k
j=1

8C2+c2
q2
j

P

C. Similarly for step (3) of Algorithm

Next, we state our main lemma that provides a bridge towards driving rate statements.

ykk ≤
k

B2,

zkk ≤
k

B3.

(6)

Lemma 4. Consider Algorithm 1 and suppose Assumption 1 and 2 hold and choose stepsizes
f (zk)) in the sense of (4) and
αk, γk and λk such that αkγk ≤
ˆyr
k

λk∇
1, then the following holds for all T > 0.

proxλkh (zk −

f (zk)) for any k

λk. Let ˆyk ≈
≥

, proxλkh (zk −
E[
2 +
zN k
ˆyN −
k

λk∇
ˆyr
N −
k

T

Xk=⌊T /2⌋

1−Lλk
16λkΓk 



λkτ 2

ΓkNk(1−Lλk) + 2ek
Γk

≤ 


T

+

Xk=1 (cid:16)

2]
zN k

−1

α1
2γ1Γ1 k

x0 −

x∗

2 + ℓ
2
k

h

+ B2

1 +C2
γkΓk

+ ρk(1+k)
Γk

5

T

αk
Γk

2B2

3 + C 2 + αk(1

αk)(2B2

2 + B2
1)

−

Xk=1
+ B2

(cid:2)
1 +B2
2
kλkΓk

+ 5λkτ 2(1−Lλk)
8ΓkNk

+ ρk(1−Lλk)
λ2
kΓk

(cid:3)

.

(7)

(cid:17) i

Proof. First of all from the fact that

f (x) is Lipschitz, for any k

1, the following holds:

∇
f (zk) +

f (yk)

≤

f (zk), yk −

2.
zkk
zki
(0, 1) one can obtain the following:

+ L

2 k

h∇

≥
yk −

Using Assumption 1(ii), for any αk ∈

(8)

f (zk)
[(1
−
= αk[f (zk)

−

αk)f (yk−1) + αkf (x)]
f (x)] + (1

2

i

x

−

−

(1

(1

h∇

αk[

≤
=

2 k

αkx

≤ h∇

h∇
x

+ ℓαk

xu −

−
+ ℓαk

−
+ ℓ
2 k

2]
yk−1k

−
f (zk), zk −
αkx

h∇
f (zk), zk −
f (zk), zk −

yk−1i
zk −
2
k
k(1−αk)
2

+ ℓ
2 k
yk−1k
yk−1 −
k

αk)[f (zk)
−
2] + (1
zk −
x
k
αk)yk−1i
−
αk)yk−1i

f (zk), zk −
2 + ℓ(1−αk)
k
ℓα2
2 +
k
yk−1 = αk(xk−1 −

f (yk−1)]
αk)[
zk −
zk −
−
where in the last inequality we used the fact that zk −
yk−1). From Lemma
1, if ek be the error in the proximal map of update xk in Algorithm 1 there exists vk such that
√2γkek and 1
∂ek h(xk). Therefore, from Deﬁnition
vk
xk−1 −
vkk ≤
γk
k
1, the following holds:
(cid:0)
(xk−1 −
f (zk) + ¯ξk, xk −
From Lemma 2, we have that 1
therefore,

1
vk, x
xki −
γk
−
1
vk, xk −
x
γk h
i
= 1
xk−1 −
[
2γk
k

xk, xk −
xk −

xk−1 −
xk−1k

¯ξk −
−
h(x)
−

≤
xk, xk −

ek
+ ek + 1

i
xk−1 −

− ∇
+ h(xk)

γk h
xk −

f (zk) + ¯ξk)

2,
xk−1k

h(xk) +

xk −

2],
k

f (zk)

⇒ h∇

h(x)

2 k

2
k

xk)

≥
=

γk h

γk(

− k

− k

(9)

1
γk

.
i

∇

−

∈

x

x

x

x

x

x

(cid:1)

h

i

2

h∇

f (zk) + ¯ξk, xk −
−
≤

x
i
vk, xk −

1
γk h

h(x)

+ h(xk)
x

i

+ ek + 1
2γk

xk−1 −
[
k

x

2
k

xk −

− k

2

xk−1k

xk −

− k

x

2].
k

(10)

Similarly if ρk be the error of computing the proximal map of update yk in Algorithm 1, then there
√2λkρk and one can obtain the following:
exists wk such that

wkk ≤
k
f (zk) + ¯ξk, yk −
−
≤

h∇

x
i
wk, yk −

+ h(yk)
x

x

h(x)

+ ρk + 1
2λk

Letting x = αkxk + (1

1
zk −
[
λk h
k
i
αk)yk−1 in (11) for any αk ≥
αk)yk−1i
1
λk h
−
αk)yk−1k

−
f (zk) + ¯ξk, yk −
αkxk −
(1
h(αkxk + (1
αk)yk−1)
−
≤
+ 1
αkxk −
zk −
[
2λk
k
From convexity of h and step (1) of algorithm 1 we obtain:

wk, yk −
− k

h∇

(1

−

−

2

+ h(yk)

(1
αkxk −
−
2].
zkk
yk −

2
k

yk −
− k
0, the following holds:

zkk

− k

2

yk −

x

2].
k

(11)

αk)yk−1i

+ ρk

h∇

f (zk) + ¯ξk, yk −
αkxk −
(1
−
αkh(xk) + (1
αk)h(yk−1)
−
≤
2
[α2
+ 1
xk−1k
xk −
kk
2λk

− k

αk)yk−1i
1
wk, yk −
λk h
−
2.
zkk
yk −

+ h(yk)

αkxk −

(1

αk)yk−1i

−

+ ρk

(12)

Multiplying (10) by αk and then sum it up with (12) gives us the following

f (zk) + ¯ξk, yk −

h∇

αkx

(1

αk)yk−1i

−

−

+ h(yk)

6

≤

−

(1
+ ek + αk(γkαk−λk)

αk)h(yk−1) + αkh(x)
xk −
k

2γkλk

αk
2γk
2

−
xk−1k

x

xk−1 −
[
k
1
2λk k

2
k
yk −

−

x

xk −
1
λk h

−

2]
1
γk h
k
−
wk, yk −

x

vk, xk −
(1
αkxk −

− k
2
zkk

term (a)

|

{z

}

i

αk)yk−1i

−

+ ρk.

(13)

By choosing γk such that αkγk ≤
(9) and (13) and using the facts that g(x) = f (x) + h(x) and zk = yk−1 + αk(xk−1 −
the following:

λk, one can easily conﬁrm that term (a)

0. Now combining (8),
yk−1), we get

≤

term (b)

g(yk)

≤

αk)g(yk−1) + αkg(x)

(1

−
+ αk
2γk
1
γk h

−

x

[
xk−1 −
k
x
vk, xk −

i

2
k
− k
+ ek −

1

2 ( 1
λk −
−
2] + ℓαk
x
xk −
k
1
wk, yk −
λk h

yk −
L)
k
xmd −
2 k
(1
αkxk −

zkk
x

¯ξk, αk(x
2 +
h
2 + ℓα2
z
k(1−αk)
2
k
αk)yk−1i

xk−1) + zk −
−
}|
xk−1k
yk−1 −
k
+ ρk.

2

−

Moreover one can bound term (b) as follows using the Young’s inequality.

¯ξk, αk(x
h

xk−1) + zk −

yki

−

=

¯ξk, αk(x
h
¯ξk, αk(x

xk−1)
i
xk−1)
i

−

−

¯ξk, zk −
+
h
+ λk
1−Lλk k

yki
zk −

ykk

2 + 1−Lλk

4λk k

¯ξkk
2.

≤ h

Using (15) in (14), we get the following.

yki
{

(14)

(15)

1

(1

g(yk)

≤

αk)g(yk−1) + αkg(x)

2
k
− k
+ ek −
Subtract g(x) from both sides, using lemma 3, assuming αk
λkΓk
summing over k from k = 1 to T, the following can be obtained.

[
xk−1 −
k
x
vk, xk −

4 ( 1
λk −
−
2] + ℓαk
x
xk −
k
1
wk, yk −
λk h

yk −
L)
k
xmd −
2 k
(1
αkxk −

−
+ αk
2γk
1
γk h

¯ξk, αk(x
2 +
h
2 + ℓα2
k(1−αk)
2
k
αk)yk−1i

zkk
x

−

−

x

i

2

¯ξkk

+ λk

xk−1)
i
−
xk−1k
yk−1 −
k
+ ρk.

1−Lλk k
2

is a non-decreasing sequence and

T

Xk=1
2

αk
Γk

zk −
k

x

2 + αk(1
k

yk−1 −
αk)
k

−

2

xk−1k

(cid:2)

(cid:3)

T

g(xT )−g(x)
ΓT

+

Xk=1
x0 −

α1
2γ1Γ1 k

≤

1−Lλk
4λkΓk k

yk −

2

zkk

x

2
k

−

αT +1
2γT +1ΓT +1 k

xT −

x

2 + ℓ
2
k

¯ξk, x

αk
Γk h

xk−1i

−

λk
Γk(1−Lλk) k

¯ξkk

T

+

Xk=1
+ ek

T

+

Xk=1
T

−

Xk=1

(cid:2)

wkk ≤
k
g(xT )−g(x∗)
ΓT

+

1
γkΓk h

vk, xk −

x

i

1
λkΓk h

wk, yk −

αkxk −

(1

αk)yk−1i

−

+ ρk
Γk

.

Γk −

(cid:3)

Letting x = x∗ and using Assumption 1(iii), inequalities (5) and (6) and the fact that
√2λkρk, we can simplify the above inequality as follows:
and

vkk ≤
k

√2γkek

T

Xk=1

1−Lλk
4λkΓk k

yk −

2

zkk

≤

α1
2γ1Γ1 k

x0 −

x∗

2 + ℓ
2
k

T

αk
Γk

2B2

3 + C 2 + αk(1

Xk=1

(cid:2)

αk)(2B2

2 + B2
1)

−

(cid:3)

7

T

Xk=1
T

+

+

¯ξk, x∗

αk
Γk h

−

xk−1i

2ek
Γk

+ B2

1 +C2
γkΓk

T

+

Xk=1
+ ρk(1+k)
Γk

λk
Γk(1−Lλk) k

¯ξkk

2

+ B2

1 +B2
2
kλkΓk

.

Using the fact that g(xT )
Assumption 1(iv) on the conditional ﬁrst and second moments, we get the following.

−

≥

g(x∗)

(cid:0)

Xk=1
0, taking conditional expectation from both sides and applying

(cid:1)

T

Xk=1

1−Lλk
4λkΓk

E[
yk −
k

2

zkk

| Fk]

≤

α1
2γ1Γ1 k

x0 −

x∗

2 + ℓ
2
k

T

+

T

λkτ 2
ΓkNk(1−Lλk) +

T

Xk=1

αk
Γk

2B2

3 + C 2 + αk(1

−

αk)(2B2

2 + B2
1)

(cid:2)
+ B2

1 +C2
γkΓk

+ ρk(1+k)
Γk

+ B2

1 +B2
2
kλkΓk

.

(cid:3)

(16)

2ek
Γk

Xk=1
To bound the left-hand side we use the following inequality by deﬁning yr
k
and ˆyr
k

f (zk)).

Xk=1

(cid:0)

λk∇

, proxλkh

(cid:1)
zk −
(cid:0)

f (zk) + ¯ξk)

λk(

∇

(cid:1)

yk −
k

zkk

, proxλkh (zk −
1
2 =
2 k
1
4 k
1
4 k

≥

yk −
ˆyk −
ˆyk −

zkk
zkk
zkk

2 +

2

−
2 +

1
2 k
1
2 k
1
4 k

yk −
ˆyk −
ˆyr
k −

2

2

2 +

zkk
ykk
zkk
R, we have that (a

ˆyr
k −
ˆyk −

zkk
2
ˆyr
kk

1
4 k
3
2 k

−

−

1
2 k
5
2 k

ˆyr
k −
ˆyr
k −

2

ykk
2
yr
kk

5
2 k

2

≥

b)2
where we used the fact that for any a, b
m
m
i=1 a2
i=1 ai)2
i . From Assumption 1(iv), we know that
(
2
ˆyr
ρk/λk and similarly
know that
kk
P
P
5
2 + 1
2
2 λ2
zkk
yk −
zkk
ˆyk −
k
from (16) and then using this bound, the following can be obtained.

m
≤
ˆyk −
k
1
4 k
≥

yr
k −
−
R,
b2 and for any ai ∈
kτ 2/Nk, also we
λ2
≤
yr
2
yk −
ρk/λk. Therefore, one can conclude that
kk
k
kτ 2/Nk −
4ρk/λk. Hence, by taking another expectation

1
2 a2
≥
−
2
yr
ˆyr
kk
k −
k

2,
ykk

≤
zkk

ˆyr
k −

4 k

≤

−

−

−

∈

2

T

Xk=1

1−Lλk
16λkΓk

E[
ˆyk −
k

2 +

zkk

ˆyr
k −
k

2]
zkk

T

≤

+

T

Xk=1 (cid:16)

Xk=1
ΓkNk(1−Lλk) + 2ek
Γk

λkτ 2

(cid:2)
1 +C2
+ B2
γkΓk

α1
2γ1Γ1 k

x0 −

x∗

2 + ℓ
2
k

αk
Γk

2B2

3 + C 2 + αk(1

−

αk)(2B2

2 + B2
1)

+ ρk(1+k)
Γk

+ B2

1 +B2
2
kλkΓk

+ 5λkτ 2(1−Lλk)
8ΓkNk

+ ρk(1−Lλk)
λ2
kΓk

.

(cid:17)

(cid:3)

Using the fact that

both side by
obtained.

P

T

k=⌊T /2⌋ At ≤

T
k=1 At where At = 1−Lλk
16λkΓk

E[
2], dividing
ˆyk −
k
and using deﬁnition of N in Algorithm 1, the desired result can be

ˆyr
k −
k

zkk

zkk

2 +

T
P
k=⌊T /2⌋

1−Lλk
16λkΓk

P

We are now ready to prove our main rate results.

8

generated by Algorithm 1 such that at each iteration k

Theorem 1. Let
1, ek-
yk, xk, zk}
{
approximate solution of step (2) and ρk-approximate solution of step (3) are available through an
. Suppose Assumption 1 and 2 hold and we select the parameters in Algorithm
inner algorithm
M
4L , λk = 1
k+1 , γk = k
1 as αk = 2
3 + C 2,
the following holds for all T > 0.

k(k+1) and Nk = k + 1. Then for B = B2

2L , Γk = 2

1 + B2

2 + B2

≥

E[
ˆyN −
k

2 +

zN k

ˆyr
N −
k

2]
zN k

≤

128
LT 3

2BT (T + 1)

"

(cid:16)

ℓ

4 + 13τ 2

64LB + 4L

T

+

(cid:17)

Xk=1 (cid:16)

2ek
Γk

+ ρk(1+k)
Γk

,

+ 4L2ρk
Γk

#
(cid:17)
(17)

where ˆyk ≈
1.
k
≥

proxλkh (zk −

λk∇

f (zk)) in the sense of (4), and ˆyr

k = proxλkh (zk −

λk∇

f (zk)) for any

Proof. Using the deﬁnition of λk and Γk, we get the following.

T

T

1−Lλk
16λkΓk

=

Xk=⌊T /2⌋

Xk=⌊T /2⌋

Lk(k+1)

32 = L

32

7T 3
24 + T 2 + 5T

6

LT 3
128 .

≥

i

h

(18)

Next, using the deﬁnition of parameters speciﬁed in the statement of the theorem we have that

T

T

αk
Γk

=

k = T (T +1)

2

,

Xk=1
T

Xk=1

Xk=1
T

1
γkΓk

=

Xk=1

2L(k + 1) = 2LT (T + 3),

Using (18) and (19) in (7) and the fact that αk(1
B2

3 + C 2 we get the desired result.

T

Xk=1
T

T

τ 2
ΓkNk

=

2 = τ 2T (1+T )
τ 2k

4

,

Xk=1
T

1
kλkΓk

=

L(k + 1) = LT (T + 3).

(19)

Xk=1
αk)

−

≤

Xk=1
1, T +3

T +1 ≤

2 and deﬁning B = B2

1 + B2

2 +

be generated by Algorithm 1 such that at each iteration k

Corollary 1. Let
1, ek-
yk, xk, zk}
{
approximate solution of step (2) and ρk-approximate solution of step (3) are calculated by an inner
algorithm
k. Suppose
where ek = γk(c1k
Assumptions 1 and 2 hold and pk = k + 1 and qk = k. If we choose the stepsize parameters as in
1.
Theorem 1, then the following holds for all T

k and ρk = λk(b1k

2 + b2)/p2

2 + c2)/q2

xk−1 −

yk−1 −

˜xkk

˜ykk

M

≥

E[
ˆyN −
k
D1 , 128
L
D2 , 128

2 +

zN k
4B

h

(cid:16)
b1(2B2

ℓ

2]
ˆyr
zN k
N −
k
≤
4 + 13τ 2
64LB + 4L
2 + C 2) + b2

(cid:17)
,

≥
D1
T + D2
T 2 ,
c1(2B2
+

1 +C2)+c2

L

+

b1(2B2

2 +C2)+b2
4L

(cid:16)

(cid:17)

(cid:16)

(20)

,

(cid:17)i

(cid:0)
proxλkh (zk −

k = proxλkh (zk −
1. The oracle complexity (number of gradient samples) to achieve E[
ˆyN −
k

f (zk)) in the sense of (4) and ˆyr

λk∇

(cid:1)

zN k

λk∇
2 +

f (zk)) for any
2]
zN k

ˆyr
N −
k

≤

where ˆyk ≈
k
≥
(1/ǫ2).
ǫ is

O

Proof. Using the deﬁnition of the stepsizes, pk, ek, and ρk one can obtain the following:

T

Xk=1

2ek
Γk ≤

c1(2B2

1 +C2)+c2
4L

T

(k + 1) =

c1(2B2

1 +C2)+c2
4L

T (T + 3).

Xk=1

(cid:16)

9

(cid:17)

ρk(1+k)

Γk ≤

T

Xk=1
T

T

b1(2B2

2 +C2)+b2
4L

k =

b1(2B2

2 +C2)+b2
8L

T (T + 1).

ρk
Γk

=

b1(2B2

2 +C2)+b2
4L

Xk=1

(cid:16)

Xk=1

T

(cid:16)

k(k+1)
(k+1)2 ≤

(cid:16)

(cid:17)

Xk=1

b1(2B2

(cid:17)
2 +C2)+b2
4L

T

1 =

b1(2B2

2 +C2)+b2
4L

T.

(cid:17)

Xk=1

(cid:16)

(cid:17)

Using the above inequalities in (17), we get the desired convergence result. Additionally, the
T
k=1(k + 1) = T (T + 3) and
total number of sample gradients of the objective is
T
k=1 2k + 1 = T (T + 2).
the total number of gradients of the constraint is
From (20), we have that E[
(1/ǫ2) and similarly
˜yN −
k

T
k=1 Nk =
T
k=1 pk + qk =
P
P
T
k=1 Nk =
P

(1/T ) = ǫ, hence,
P

T
k=1 pk + qk =
In the next corollary, we justify our choice of measure. We show that if E[
ˆyr
N −
k

2]
P
zN k
the ﬁrst order optimality condition for problem (2) holds within a ball with radius √ǫ.

ǫ, then

≤

2]
zN k

(1/ǫ2).

≤ O

P

O

O

Corollary 2. Under the premises of Corollary 1, after running Algorithm 1 for T
where D , D1 + D2, the following holds.

≥

D/ǫ iterations,

0

E[

f (ˆyr

N )] + E[∂h(ˆyr

N )] +

3L√ǫ

.

B

Proof. Suppose ˆyr
zN )/λ. Adding and subtracting
following:

∈
N is a solution of proxλN h (zN −
∇

f (ˆyr

∇

(cid:1)
N −
N ) form the right-hand side of the above inequality, gives the

(cid:0)
f (zN )). Then 0

f (zN ) + (ˆyr

λN ∇

∂h(ˆyr

N ) +

∇

∈

Moreover, using the fact that T
result.

D/ǫ and E[
ˆyr
N −
k

≥

∂h(ˆyr

N ) +

0

∈

∇

f (zN ) + 1/λ(ˆyr

zN )

f (ˆyr

N ).

N −
2]
zN k

≤

± ∇
D
T = ǫ one can show the following

(21)

E [

f (zN )

f (ˆyr

N ) + 1/λ(ˆyr

k∇

− ∇

≤
where we use the fact that λ = 1/(2L). Using the above inequality and taking expectation from
(21) the desired result can be obtained.

≤

N −

]
zN )
k

E [L

ˆyr
N −
k

zN k

+ 1/λ

ˆyr
N −
k

]
zN k

3L√ǫ,

In the next section, we show how Algorithm 1 can be customized to solve problem (1).

2.1 Constrained Optimization

Recall that problem (1) can be written in a composite form using an indicator function, i.e. problem
(1) is equivalent to minx g(x) = f (x) + h(x), where h(x) = IΘ(x) and Θ =
0,
inexactly which are of the following form:

≤
. In step (2) and (3) of Algorithm 1, one needs to compute the proximal operators
}

i = 1, . . . , m

X, φi(x)

x
{

∈

x

∀

|

min
u∈X

1
2γ k

u

y

2
k

−

s.t. φi(u)

≤

0,

i = 1, . . . , m,

(22)

Rn. Problem (22) has a strongly convex objective function with convex constraints, and
for some y
there has been variety of methods developed to solve such problems. One of the eﬃcient methods
for solving large-scale convex constrained optimization problem with strongly convex objective

∈

10

that satisﬁes Assumption 2 is ﬁrst-order primal-dual scheme that guarantees a convergence rate of
(1/√ǫ) in terms of suboptimality and infeasibility, e.g., [7, 6]. Next, we discuss some details of
O
implementing such schemes as an inner algorithm for solving the subproblems in step (2) and (3)
of Algorithm 1.

Based on Corollary 1, to obtain a convergence rate of

(1/T ), one needs to ﬁnd an ek- and
ǫk-approximated solution in the sense of (4). Note that since the nonsmooth part of the objective
function, h(x), in the proximal subproblem is an indicator function, (4) implies that the approximate
solution of the subproblem has to be feasible, otherwise the indicator function on the left-hand side
of (4) goes to inﬁnity. However, the ﬁrst-order primal-dual methods mentioned above ﬁnd an
approximate solution which might be infeasible. To remedy this issue, let x◦ be a slater feasible
point of (22) (i.e., φi(x◦) < 0 for all i = 1, . . . , m) and let ˆx be the output of the inner algorithm
κ)ˆx is a feasible point of (22)

such that it is ǫ-suboptimal and ǫ-infeasible, then ˜x = κx◦ + (1

O

M
for κ , maxi

[φi(ˆx)]+

[φi(ˆx)]+−φi(x◦) which is

O

(ǫ)-suboptimal, see the next lemma for the proof.

−

αk, γk, λk}k, and Algorithm
{

satisfying Assump-

M

(solved inexactly by algorithm

(solved inexactly by algorithm
(cid:1)

M

with qk iterations);

M
with pk iterations);

[φi(y)]+
[φi(y)]+−φi(x◦) ;

Rn and positive sequences

Algorithm 2 IPAG for constrained optimization
input: x◦, x0, y0 ∈
tion 2;
for k = 1 . . . T do
zk = (1
(1)
αk)yk−1 + αkxk−1;
−
ΠΘ
(2) x
xk−1 −
≈
∇
f (zk) + ¯ξk)
zk −
λk(
(3)
ΠΘ
y
(cid:0)
∇
≈
[φi(x)]+
[φi(x)]+−φi(x◦) and ˜κ = maxi
(4) κ = maxi
(cid:0)
(5) xk = κx◦ + (1
yk = ˜κx◦ + (1
(6)
end for
Output:
1

f (zk) + ¯ξk)

κ)x;
˜κ)y;

−
−

γk(

(cid:1)

PT

k=⌊T /2⌋

1−Lλk
16λkΓk (cid:16)

1−Lλk
16λkΓk

.

(cid:17)

zN where N is randomly selected from

T /2, . . . , T
{

}

with Prob

N = k
{

}

=

Lemma 5. Let x◦ be a strictly feasible point of (22) and ˆx be the output of an inner algorithm
such that it is ǫ-suboptimal and ǫ-infeasible solution of (22). Then ˜x = κx◦ + (1
point of (22) and an

M
κ)ˆx is a feasible
[φi(ˆx)]+
[φi(ˆx)]+−φi(x◦) .
Proof. Let x∗ be the optimal solution of (22). Since ˆx is ǫ-suboptimal and ǫ-infeasible solution,
ˆx

(ǫ)-approximate solution in the sense of (4) where κ = maxi

X and the following holds:

O

−

∈

y

y

−

−

x∗

2
k

1
1
ˆx
2γ k
2γ k
Since X is a convex set and x◦, ˆx
∈
φi(x◦) < 0 for all i, hence κ = maxi
), one can show the following for all i = 1, . . . , m.
φi(
·
κφi(x◦) + (1

k
(cid:12)
(cid:12)
[φi(ˆx)]+
[φi(ˆx)]+−φi(x◦) ∈

φi(˜x)

≤

ǫ,

(cid:12)
(cid:12)

−
X, then clearly κx◦ + (1

and [φi(ˆx)]+ ≤
κ)ˆx

−

[0, 1] and κ

≤

≤

κ)φi(ˆx)

0,

≤

−

ǫ,

i

∈ {

1, . . . , m

.
∀
}
[0, 1]. Moreover,
X for any κ
∈
ǫ
mini{−φi(x◦)} . From convexity of

∈

where we used the deﬁnition of κ. Hence, ˜x is a feasible point of (22). Next, we verify ˜x satisﬁes
(4).

1
˜x
2γ k

−

y

2 + IΘ(˜x)
k

−

x∗

1
2γ k

y

2
k

−

−

IΘ(x∗)

11

x∗

−
y

−
x◦
k

−

= 1
˜x
2γ k
κ2
2γ k
≤
= κ2
2γ k

y

−

−

−

x◦

x◦

x◦
2
1
2γ k
±
k
2 + (1−κ)2
ˆx
y
2γ k
k
2 + κ(1−κ)
k
−
1−(1−κ2)
2γ
x◦

x∗
y
k
−
2 + κ(1−κ)
k

2
k

y

y

γ

−
κ2
2γ k

y

2
k
2 + κ(1−κ)
k
y

y

γ

2
k

ˆx
k

−

x◦
k
−
2 + (1
k

y

2
ˆx
k
k
κ2)

−

x∗

y

2
k
−
1
ˆx
2γ k

1
2γ k
y

k −

−

−

−
1
2γ k

y

2
k
x∗

−

h

y

k
i

x◦
k
where we used the fact that ˆx, x∗ are feasible, ˆx is ǫ-suboptimal and κ

2 + ǫ
k

≤ O

ˆx
k

2
k

(ǫ),

−

≤

−

−

y

y

γ

ǫ
mini{−φi(x◦)} .

≤

In the following corollary, we show that the output of Algorithm 2 is feasible to problem (1)

and satisﬁes ǫ-ﬁrst-order optimality condition.

Corollary 3. Consider problem (1). Suppose Assumption 1 and 2 hold and let
be
generated by Algorithm 2 such that the stepsizes and parameters are chosen as in Corollary 1.
Then the iterates are feasible and E
(ǫ) holds with an oracle
ΠΘ (zN −
complexity

yk, xk, zk}
{

λN ∇

(1/ǫ2).

f (zN ))

≤ O

2
k

zN −
k
(cid:2)

(cid:3)

O

Proof. From Lemma 5 we know that the iterates are feasible and from Corollary 1, we conclude
that E[ˆ
(1/ǫ2). Considering problem (1), deﬁnition of
yr
ǫ with an oracle complexity
N −
≤
k
N is equivalent to ˆyr
ˆyr
λN ∇
N = ΠΘ (zN −

f (zN )) which implies the desired result.

2]
zN k

O

3 NUMERICAL EXPERIMENTS

The goal of this section is to present some computational results to compare the performance of the
IPAG method with another competitive scheme. For Algorithm 2, we consider accelerated primal-
. In
dual algorithm with backtracking (APDB) method introduced by [6] as the inner algorithm
(1/T 2) in terms of
particular, APDB is a primal-dual scheme with a convergence guarantee of
suboptimality and infeasibility when implemented for solving (22) which satisﬁes the requirements
of Corollary 3, i.e., produces approximate solutions for the proximal subproblems.

M

O

Example. The IPAG method is benchmarked against the inexact constrained proximal point
algorithm (ICPP) introduced by [2]. Consider the following stochastic quadratic programming
problem:

f (x) ,

DBx

ǫ
2 k

2 + τ
2
k

E[
Ax
k

2]
b(ξ)
k

−

ci ≤

−

0,

∀

i = 1 . . . m,

min
−10≤x≤10

s.t.

1

−
2 xT Qix + dT
i x
Rn×n, D

∈

∈

Rp×n, p = n/2, B

Rn×n is a diagonal matrix, b(ξ) = b + ω

Rp×1,
where A
where the elements of ω have an i.i.d. standard normal distribution. The entries of matrices A,
B, and vector b are generated by sampling from the uniform distribution U [0,1] and the diagonal
entries of matrix D are generated by sampling from the discrete uniform distribution U
.
1,1000
}
{
R for all i
. We chose scalers
Moreover, (δ, τ )
}
2f ) < 0, i.e., minimum eigenvalue of the Hessian is negative. Note that
δ and τ such that λmin(
Assumption 1(i) holds for x◦ = 0, where 0 is the vector of zeros.

R2
++ , Qi ∈
∇

Rn×1 and ci ∈

Rn×n, di ∈

1, . . . , m

∈ {

∈

∈

∈

In Table 1 (left), we compared the objective value, CPU time, and infeasibility (Infeas.) of
our proposed method with ICPP [2] and in Table 1 (right) we compared the methods for diﬀerent

12

n
100
100
100
200
200
200

m
25
50
75
25
50
75

f (xT )
-6.78e+5
-8.53e+5
-4.18e+5
-3.22e+6
-1.85e+6
-1.33e+6

IPAG
Infeas. CPU(s)

0
0
0
0
0
0

12.10
31.76
52.43
65.56
90.49
138.75

f (xT )
-4.85e+4
-2.42e+4
-2.16e+4
-1.81e+5
-8.45e+4
-7.78e+4

ICPP
Infeas.
3.56e-1
3.23e-1
3.75e-1
2.56e-1
4.54e-1
3.93e-1

CPU(s)
32.99
65.79
110.53
132.18
208.84
287.20

n
100
100
100
200
200
200

m std.
25
25
25
50
50
50

1
5
10
1
5
10

IPAG
f (xT )
-6.7866e+5
-6.5288e+5
-6.2336e+5
-1.8552e+6
-1.8452e+6
-1.8383e+6

ICPP
f (xT )
-4.8563e+4
-4.8596e+4
-4.8528e+4
-8.4550e+4
-8.5264e+4
-8.6096e+4

Table 1: Comparing IPAG and ICPP.

choices of standard deviation (std.) of ω. To have a fair comparison, we ﬁxed the oracle complexity
(i.e. the number of computed gradients is equal for both methods). As it can be seen in the table,
for diﬀerent choices of m and n, IPAG scheme outperforms ICPP. For instance, when we have 25
constraints and n = 100, the objective value for our scheme reaches f (xT ) =
6.78e + 5 which is
signiﬁcantly smaller than
4.85e + 4 for ICPP method. Note that our scheme, in contrast to ICPP,
obtains a feasible solution at each iteration. Similar behavior can be observed for diﬀerent choices
of the standard deviation in Table 1 (right). standard deviation.

−

−

References

[1] Basu, K., Nandy, P.: Optimal convergence for stochastic optimization with multiple expectation constraints.

arXiv preprint arXiv:1906.03401 (2019)

[2] Boob, D., Deng, Q., Lan, G.: Stochastic ﬁrst-order methods for convex and nonconvex functional constrained

optimization. arXiv preprint arXiv:1908.02734 (2019)

[3] Ghadimi, S., Lan, G.: Stochastic ﬁrst-and zeroth-order methods for nonconvex stochastic programming. SIAM

Journal on Optimization 23(4), 2341–2368 (2013)

[4] Ghadimi, S., Lan, G.: Accelerated gradient methods for nonconvex nonlinear and stochastic programming.

Mathematical Programming 156(1-2), 59–99 (2016)

[5] Ghadimi, S., Lan, G., Zhang, H.: Mini-batch stochastic approximation methods for constrained nonconvex
stochastic programming. Manuscript, Department of Industrial and Systems Engineering, University of Florida,
Gainesville, FL 32611 (2014)

[6] Hamedani, E.Y., Aybat, N.S.: A primal-dual algorithm with line search for general convex-concave saddle point

problems. SIAM Journal on Optimization 31(2), 1299–1329 (2021)

[7] He, N., Juditsky, A., Nemirovski, A.: Mirror prox algorithm for multi-term composite minimization and semi-

separable problems. Computational Optimization and Applications 61(2), 275–319 (2015)

[8] Kong, W., Melo, J.G., Monteiro, R.D.: Complexity of a quadratic penalty accelerated inexact proximal point
method for solving linearly constrained nonconvex composite programs. SIAM Journal on Optimization 29(4),
2566–2593 (2019)

[9] Lan, G., Yang, Y.: Accelerated stochastic algorithms for nonconvex ﬁnite-sum and multiblock optimization.

SIAM Journal on Optimization 29(4), 2753–2784 (2019)

[10] Lan, G., Zhou, Z.: Algorithms for stochastic optimization with expectation constraints.

arXiv preprint

arXiv:1604.03887 (2016)

[11] Li, Z., Chen, P.Y., Liu, S., Lu, S., Xu, Y.: Rate-improved inexact augmented lagrangian method for constrained
nonconvex optimization. In: International Conference on Artiﬁcial Intelligence and Statistics, pp. 2170–2178.
PMLR (2021)

[12] Li, Z., Xu, Y.: Augmented lagrangian based ﬁrst-order methods for convex and nonconvex programs: nonergodic

convergence and iteration complexity. arXiv preprint arXiv:2003.08880 (2020)

[13] Lin, Q., Ma, R., Xu, Y.: Inexact proximal-point penalty methods for constrained non-convex optimization.

arXiv preprint arXiv:1908.11518 (2019)

13

[14] Ma, K., Bai, Y., Yang, J., Yu, Y., Yang, Q.: Demand-side energy management based on nonconvex optimization

in smart grid. Energies 10(10), 1538 (2017)

[15] Nemirovski, A.S., Yudin, D.B.: Problem complexity and method eﬃciency in optimization (1983)

[16] Pham, N.H., Nguyen, L.M., Phan, D.T., Tran-Dinh, Q.: Proxsarah: An eﬃcient algorithmic framework for
stochastic composite nonconvex optimization. Journal of Machine Learning Research 21(110), 1–48 (2020)

[17] Schmidt, M., Roux, N.L., Bach, F.: Convergence rates of inexact proximal-gradient methods for convex opti-
mization. In: Proceedings of the 24th International Conference on Neural Information Processing Systems, pp.
1458–1466 (2011)

[18] Tran-Dinh, Q., Cevher, V.: A primal-dual algorithmic framework for constrained convex minimization. arXiv

preprint arXiv:1406.5403 (2014)

[19] Ullah, Z., Al-Turjman, F., Mostarda, L., Gagliardi, R.: Applications of artiﬁcial intelligence and machine learning

in smart cities. Computer Communications 154, 313–323 (2020)

[20] Xu, Y.: Iteration complexity of inexact augmented lagrangian methods for constrained convex programming.

Mathematical Programming pp. 1–46 (2019)

[21] Zhang, S., He, N.: On the convergence rate of stochastic mirror descent for nonsmooth nonconvex optimization.

arXiv preprint arXiv:1806.04781 (2018)

14

