Secure Minimum Time Planning Under Environmental
Uncertainty: an Extended Treatment

Alexander Ivanov1 and Mark Campbell2

8
1
0
2

r
a

M
6

]

O
R
.
s
c
[

1
v
6
6
9
1
0
.
3
0
8
1
:
v
i
X
r
a

Abstract— Cyber Physical Systems (CPS) are becoming
ubiquitous and affect the physical world, yet security is
seldom at the forefront of their design. This is especially
true of robotic control algorithms which seldom consider
the effect of a cyber attack on mission objectives and
success. This work presents a secure optimal control
algorithm in the face of a cyber attack on a robot’s
knowledge of the environment. This work focuses on cyber
attack, but the results generalize to incomplete or outdated
information of an environment. This work fuses ideas from
robust control, optimal control, and sensor based planning
to provide a generalization of stopping distance in 3D. The
planner is implemented in simulation and its properties are
analyzed.

I. INTRODUCTION

Knowledge of the environment is paramount for au-
tonomous Cyber Physical Systems (CPS) to succeed
in many tasks. Therefore, a system must be able to
trust given information, or else be able to account for
the possibility that its knowledge of the environment is
incorrect. Automation has permeated many physically
consequential tasks as far ranging as self driving cars
[1] and nuclear centrifuge control [2]. This ubiquity
has increased the need for security in CPS. Dangers
posed by security ﬂaws are exempliﬁed by several high
proﬁle instances such as the STUXNET worm and
the reported downing of a U.S. RQ-170 drone in Iran
[3]. The STUXNET worm was successful in causing
signiﬁcant damage to the nuclear enrichment program
of Iran, while the RQ-170 event exempliﬁes the kinds of
dangers which must be addressed if we hope to automate
vehicles on a large scale. Security ﬂaws have also been
shown in modern vehicles. Checkoway et al. showed
that the control and auxiliary systems of a car can be
compromised by a Man In the Middle (MIM) attack
where a hacker compromises a communication network
providing the vehicle with outside information [4].

Consider a point robot operating in a bounded, static,
obstacle environment. Traditionally, knowledge of the
environment, such as a map, is required and provided as

1information aii4@cornell.edu
2information mc288@cornell.edu

Fig. 1: The robot (blue triangle) seeks to achieve the
goal position (green circle). The sensor FOV is in light
green, but is obstructed by the known obstacle (red) .
An unsafe path (red) skirts around the obstacle. A safe
(blue) path gives wide berth to the known obstacle and
has time to avoid the unknown obstacle (black).

a polygonal or occupancy-grid representation [5]. Many
modern self driving frameworks provide this information
via a networked server [2]. This work considers a
scenario where the server is vulnerable to cyber attack.
If a server is vulnerable, the robotic system is unsure
if provided information is fully correct, incomplete, or
maliciously designed. A dangerous planning scenario is
exempliﬁed by the dotted red path in Fig. 1, where a
robot is planning the fastest path around a known red
obstacle, but will not be able to react in time to the
unknown obstacle shown in black. If trust is to be placed
in robotic vehicles, guarantees must be made on the
resilience of robotic systems and planning algorithms to
a variety of security threats including MIM attacks on
sensors, control inputs, and assumed knowledge about
the environment.

Previous work on control and planning security for
CPS has had two primary components: detecting MIM
attacks, and operating robotic systems under environ-
mental uncertainty. Mo, Chabukswar, and Sinopoli con-
sider detection of playback attacks on a Linear Time
Invariant (LTI) system, and propose a sub-optimal noisy

 
 
 
 
 
 
control to increase attack detection rates. [6]. Pasqualetti
et al. provide detailed analysis of detectability and
identiﬁability of noiseless LTI systems [7]. Fawzi et al.
provide theoretical bounds on how large the support of
an output attack vector can be while still ensuring that
the attack can be detected [8]. An NP-hard detector is
also provided in the form an l0 minimization, and a
tractable l1 approximation. Pajic et al. utilize a similar
method for noisy dynamical systems [9]. Shoukry et al.
focus on generating a sound method using Satisﬁability
Modulo Theories to ensure that a correct estimate of the
attack vector is returned [10].

Much work has focused on planning with uncertainty
in location of impassible obstacles and robot pose.
Several recent surveys detail much of the literature
in this area [11], [12]. Much previous work focuses
on Simultaneous Localization and Mapping (SLAM),
which is beyond the scope of the current contribution,
since this work concentrates on the planning problem.
Several studies consider planning with environmental
uncertainty. Missiuro and Roy adapted a Probabilistic
Random Map (PRM) to account for uncertainty in a
SLAM map [13] and use linear interpolation of uncer-
tainty ellipsoids along obstacle edges to give a proba-
bilistic guarantee on collision avoidance. Similarly, Vitus
and Tomlin study uncertainty in obstacle vertices [14],
and provide chance constraints on obstacle avoidance.
They propose a hybrid analytic-sampling method which
reduces complexity compared to previous techniques.

Current literature addresses the detection and estima-
tion of attacks on linear systems, or considers operation
with noisy sensors or adversarial pursuers. Conversely,
little work has been done on planning algorithms for
robots in complex environments while under malicious
attack. The primary contribution of this work is an
algorithm which provides guaranteed control of a robotic
system under malicious attack on its knowledge of the
environment. The continuous time problem is formulated
and solved using direct optimization methods through
a Nonlinear Program (NLP). The framework presented
allows generalization of this algorithm to a variety of
robotic system models.

II. PROBLEM DESCRIPTION AND DEFINITIONS

The problem of secure control under adversarial attack
is ﬁrst described qualitatively. Formal deﬁnitions are
then given, and a mathematical formulation is provided.
The problem formulation considers a 3D Euclidean
conﬁguration space of a point robot, but the results are
valid for the 2D case as demonstrated in Section VI.

Qualitatively, the problem statement is “Plan a path
from a start point s to an end point e in minimum

time, and guarantee that the robot can avoid collision
due to potentially malicious environmental knowledge.”
Several standard assumptions are required to make this
problem well posed. First, a dynamically feasible path
is assumed to exist between s and e, both in the true
environment as well as in the potentially malicious
information. Second, the robot state at time t can be
represented by a point x(t) ∈ Rn, with a sensor ﬁeld of
view Ss(x) ⊂ R3, which varies only with robot state.
Finally, sensor data and control inputs are assumed un-
compromised.

In the following formulation, J((cid:5)) is the cost function,
which in Lagrange form is the integral of the Lagrangian
L(x(t), u(t), t) up to the ﬁnal time tf . The conﬁguration
space, C = Cobst∪Cfree, is a union of the ‘free’ space and
‘obstacle’ or occupied space, and u(t) ∈ U ⊂ Rm are
controls. A Lagrange formulation for an optimal control
problem, with trusted environmental knowledge, is:

minimize
u(t)∈U,tf
s.t.

J(x(t), u(t), tf )

˙x(t) = f (x(t), u(t))
g(x(t), u(t)) ≤ 0
x(t) ∈ Cfree ∀t ∈ (0, tf )
x(0) = s,

x(tf ) = e

(1)

In this work, the robot does not know Cfree, but instead
knows some unveriﬁed estimate ˆCfree provided by a
server. Therefore, the robot must plan over ˆCfree. There
are many approaches to planning over an unknown
space which include probabilistic approaches seeking
to optimize some mean performance (expectation) as
well as robust approaches which seek to ﬁnd a solution
for the worst-case. This work can be viewed as a form
of ‘robust’ path planning which deterministically plans
over ˆCfree. Since Cfree is unknown, it is ﬁrst prudent to
consider the interaction of the FOV Ss(x) and Cobst.

Deﬁnition 2.1: An obstacle O ⊂ R3 is visible at time

t ⇐⇒ O ∩ Ss(x(t)) (cid:54)= ∅

The intuition behind the sequel comes from the wealth
of research which has analyzed reactivity to unknown or
moving obstacles in the conﬁguration space [12], [15].
In this work, a control law which reacts to an obstacle is
called a ‘reactive controller’. Conceptually, when a robot
encounters an unknown obstacle in the environment,
new information is gained about the conﬁguration space
which may make the previously planned path infeasible
or sub-optimal. Consider a locally optimal solution x∗(t)
to (1) with the distinction that the robot plans over ˆCfree
instead of the true Cfree. If x∗(t) ∈ Cfree, this means that
a path is safe, but perhaps sub-optimal. In other words,
even if ˆCfree is incorrect and some unknown obstacle

O (cid:42) ˆCobst is visible at t, the robotic system need not
react to this new information. Conversely, if x∗(t) passes
through such an obstacle, the robot must react. A key
challenge is that the robot has dynamics and cannot stop
instantaneously. Thus, if a planned path collides with an
unknown obstacle, the robot must observe the obstacle
far enough in advance to avoid collision.

Note that this work does not prescribe a particular
method for reacting to unknown obstacles in the environ-
ment. Instead, a reactive controller is assumed to exist
with a control law, π(x(t), O) : Rn × M → U , which
is only a function of a single obstacle O and x(t). Here,
M is the set of 3D non-empty polyhedra (obstacles).
Cobst is a union of a ﬁnite number of such polyhedra.
Furthermore, the control law π((cid:5)) is assumed to ensure
x(t) remains bounded near the position where the robot
ﬁrst encounters an unknown obstacle, i.e. the system is
stable in the sense of Lyapunov.

Algorithm 1: Robotic Planning Algorithm
Input: e, s, x(0), ˆCfree

1 [x∗(t), u∗(t)] ← Solve Eq. (1);
2 while Ou ∪ Ss(t) = ∅ do
3
4 end
5

if x∗(t)! = saf e then

u(t) = u∗(t)

6

7

while Evasive maneuver do
u(t) = π(x(t), O)

end

8
9 end
10 go to 1

The optimal controller solving Eq. (1) is usually dubbed
the path planner, while the reactive controller using
π(x(t), O) is usually called a ‘low level’ controller.
Since π(x(t), O) is stable,
it helps deﬁne a “reac-
the reactive path produced by π be
tive set”. Let
xr(t, x(τ ), O) with initial condition x(τ ).

Deﬁnition 2.2: The reactive set Sr(x(τ )) deﬁned by

control law π and the initial condition x(τ ) is:

Sr(x(τ )) := ∪

O∈M

xr(t, x(τ ), O)

The reactive set can be seen a generalization of
stopping distance to 3D. To give some intuition to this
deﬁnition, consider a one dimensional problem where
a robot has dynamics ˙x1(t) = x2(t), with bounded
˙x2(t) = u(t), u ∈ [−1, 1]. The
acceleration control
robot’s state is position and velocity. In this case, an
obstacle is also a value on the real line and a reactive
controller could simply try to stop the vehicle as quickly

as possible:

π(x(0), O) =






1
x2(t) < 0, O < x1(τ )
−1 x2(t) > 0, O > x1(τ )
0

o.w.

The reactive set is then the interval determined by
the initial state and stopping distance of the robot:
Sr(x(τ )) = [x(τ ), x(tr)], where tr > τ is the ﬁrst time
the robot is at rest.

III. PLANNING UNDER ADVERSARIAL MAPS

Several arguments are necessary to motivate a solution
to the problem of planning under adversarial environ-
mental attack. First, the ﬁrst argument shows that, in
order to guarantee planning under adversarial attack, the
reactive set Sr(x(t)) must be fully observed at some
previous time. Second, given that Sr(x(t)) is guaranteed
to be observed along a trajectory, one needs only ensure
that Sr(x(t)) ∩ ˆCobst = ∅ along a path x(t) to ensure
that the robot can avoid any unknown obstacle.

the robot

Given that

is planning over ˆCfree,

is
necessary to consider the effects of the mismatch be-
tween ˆCfree and the true Cfree on safety. The portion
of Cfree which is incorrectly assumed to be obstructed
is inconsequential in terms of safety, i.e. ˆCobst ∩ Cfree.
The ‘dangerous’ mismatch is described by the set of
unknown obstacles Ou := Cobst ∩ ˆCfree. When the robot
senses a component of Ou and switches to a reactive
controller, it must have a guarantee that the evasive
maneuver will not cause an obstacle collision. By deﬁni-
tion, Sr(x(0)) bounds all such evasive maneuvers. Since
Ou is unknown, the only way to guarantee safety is to
ensure that the robot has previously observed its planned
reactive set. In other words, the following constraint
must be satisﬁed:

it

∪
t∈[0,τ ]

Ss(x(t)) ⊇ Sr(x(τ ))

(2)

The ﬁnal argument requires one more deﬁnition.
Deﬁnition 3.1: A planned path x(t) deﬁned on t ∈
(2) and

it satisﬁes the constraint

is safe if

[0, tf ]
Sr(x(t)) ∩ ˆCobst = ∅
Suppose that

the constraint (2) is satisﬁed for a
particular trajectory x(t), and assume that
the robot
continuously updates its estimate ˆCfree and ˆCobst. In
practice, this implies maintaining an occupancy grid or
3D occupancy representation such as OctoMap [5].

Theorem 3.2: Let x∗(t) be a safe, planned, dynami-
cally feasible trajectory deﬁned on t ∈ [0, tf ]. Suppose
the robot utilizes a reactive controller π(x(t), O) and

Alg.1 in Section II. If the ﬁrst unknown obstacle is seen
at τ , then any realized robotic path x(t) = {x∗(t)|t ∈
[0, τ ), xr(x∗(τ ), O)

o.w.} will be collision free.

Proof: The proof will proceed by construction.
Consider the ﬁrst instance in time τ ∈ [0, tf ] when
an unknown obstacle O ⊂ Ou is visible. A reactive
controller will only be utilized if O causes x∗(t) to no
longer be safe. At τ , the free space estimate is updated
to be

ˆCfree ← ˆCfree ∪ (cid:0) ∪

t∈[0,τ ]

Ss(x(t))(cid:1)/O

and the obstacle estimate is updated to be

ˆCobst ← (cid:0) ˆCobst ∪ O(cid:1)/(cid:0) ∪

t∈[0,τ ]

Ss(x(t))

(cid:92)

Cfree

(cid:1).

therefore,

By deﬁnition, x∗(τ ) ∈ Sr(x∗(τ )),

if
x∗(t), t ∈ [τ, tf ] remains safe under the updated ˆCfree,
the planned trajectory can continue to be executed
without re-planning and without collision. Conversely, if
x∗(t) is no longer safe, the control policy π(x∗(τ ), O)
is utilized. Since O ∈ M by deﬁnition, the reactive path
satisﬁes xr(x∗(τ ), O) ⊂ Sr(x∗(τ )). Because constraint
(2) is satisﬁed, and τ is the ﬁrst time a component of
Ou is visible, it must be that Sr(x∗(τ )) ∈ Cfree(cid:4).

Theorem (3.2) says that,

to guarantee safety, one
need only ensure the reactive sets, Sr(x(t)), have been
observed in advance and that
intersect
with any known obstacles: O ∈ ˆCobst. Theorem (3.2)
motivates the ﬁnal formulation of the optimal control
problem under adversarial attack:

they do not

minimize
u(t)∈U,tf
s.t.

J(x(t), u(t), tf )

˙x(t) = f (x(t), u(t))
Sr(x(t)) ⊂ ∪
τ ∈[0,t]
Sr(x(t)) ∈ ˆCfree ∀t ∈ (0, tf )
x(0) = s,

Ss(x(τ ))

x(tf ) = e

(3)

IV. APPROXIMATING THE SET CONSTRAINTS
The set inclusion constraint in (3) is intuitive, but is
difﬁcult to compute in practice as it requires a union of
sets which has no analytic form in general. Conversely,
if the set constraints can be written as path inequality
constraints of the form in (1), trajectory optimization
using direct collocation methods could be used to solve
the optimal control problem.

A. The Visibility Constraint

Deﬁnition (3.1) requires that all parts of Sr(x(t)) are
observed by the time the robot is at x(t). A tighter

constraint is:

Sr(x(t)) ⊂ Ss(x(τ )),

0 < τ < t

(4)

In other words, the reactive set at time t must be seen,
in its entirety, at some particular previous time instance.
Therefore, a solution to the following optimal control
problem would also be a solution to problem (3):

minimize
u(t)∈U,tf
s.t.

J(x(t), u(t), tf )

s.t. Sr(x(t)) ⊂ Ss(x(τ ))

˙x(t) = f (x(t), u(t))
∃τ < t
Sr(x(t)) ∈ ˆCfree ∀t ∈ (0, tf )
x(0) = s,

x(tf ) = e

(5)

B. The Reactive Set

To achieve a practical solution, an upper bound is
proposed for the reactive set. This work uses an el-
lipsoidal upper bound to approximate Sr((cid:5)). There are
several properties which make an ellipsoidal approxi-
mation appealing. First, bounding simulated or observed
trajectory data with ellipsoids is relatively easy. Second,
ellipsoids are easily manipulated to provide constraint
if a
equations of the form in problem (1). Finally,
direct collocation method is utilized to perform the
discretization and optimization of the optimal control
problem, the constraint Sr(x(t)) ∈ ˆCfree can be formed
into a state-varying distance condition. Details on how
to practically perform this approximation are given in
Section VI and [16]. Let Q((cid:5)) be a real, positive-deﬁnite,
diagonal, and continuously varying matrix. Let R(x),
c(x), and a(x) be the rotation matrix, position of the
robot, and ellipse center respectively. Let z ∈ R3. For
the remainder of this work, Sr((cid:5)) is assumed to take the
form:

Sr(x) =
{y = R(x)((cid:112)Q(x)z + a(x)) + c(x)|zT z ≤ 1}

(6)

Clearly Q and a depend on x since the stopping distance
of an inertial object depends on its initial momentum.

V. DISCRETIZING THE PROBLEM

Direct trajectory optimization methods have seen wide
acceptance in recent robotic literature and practice [17].
Their appeal comes from recent improvements in opti-
mization tools, their wide availably [18], and because
these tools can ﬁnd locally optimal solutions even in
the face of non-linear and non-convex constraints. In

addition, direct methods require less expert knowledge
in optimal control when compared to methods based on
the calculus of variations, dynamic programming, or fast
marching [17].

The above analysis motivates the use of a direct opti-
mization method for the problem presented in this work
since the constraints proposed are complex (nonlinear,
time-varying) and vary with the model of the FOV and
Sr((cid:5)). This section presents a Nonlinear Program (NLP)
discretization of problem (5). The connection between
this NLP and (5) is not direct; additional details are
provided in the appendix. Finally, a model of the sensor
set Ss(x) is presented and the set inclusion constraints
in (5) are converted into inequality constraints.

A. Nonlinear program formulation

The formulation in (5) differs from standard trajectory
optimization problems only in its set constraint requiring
visibility and non-collision of Sr(x(t)). Reference [17]
provides details on standard discretizations of the ob-
jective function, dynamic, and obstacle constraints. This
section presents details on the set inclusion constraint.
Let xi be the ith discretized state, where xi := x(ti).
Following the notation in [17], the ith dynamics defect
is denoted ζi. In addition L((cid:5)) is the discretized, numer-
ically integrated form of L((cid:5)). The visibility constraint
can be discretized by requiring that Sr(xi) is observed
by a previous discretization point with a ﬁxed time index
difference:

minimize
ui∈U,tf
s.t.

L(x1, .., xK, u1, .., uK, tf )
ζi = 0, d(Sr(xi), ˆCobst) > 0 ∀i
Sr(xi) ⊂ Ss(xj)
x1 = s,
xK = e
j = i − ∆i, i ∈ {∆i, .., K}

(7)

where the distance d((cid:5), (cid:5)) is Euclidean when referring to
points and Hausdorff between sets in Rn.

Since ∆i is ﬁxed and the union of sets has been ig-
nored, Sr(xi) ⊂ Ss(xj) is a tight discrete approximation
of the set inclusion constraint in Eq. 5. Requiring that
∆i is ﬁxed may be overly restrictive, and a relaxation
of this constraint has been left for further study.

B. Sensor model and visibility constraint

Now that the method of discretization has been exem-
pliﬁed, the visibility constraint in (7) must be converted
into a set of inequalities. To do this, a model of the
sensor is required.

In this work, the sensor is represented by a subset
of R2 or R3, depending on the conﬁguration space of

the robot. In 2D, many sensor models such as LIDAR
can be modeled as a ‘slice’ of a disc with the radius
being the effective sensor range r. A more conservative
approximation is an isosceles triangle with equal sides
of length r. A similar assumption is made for cameras in
R3 using the pinhole-camera assumption and assuming
a rectangular digital image sensor. The set Ss(x) is then
a polyhedron in the appropriate dimension, and can be
expressed through a ﬁnite number of linear inequalities.

Ss(x) = {y|A(x)y ≤ b(x)}

y ∈ R3

(8)

Since the FOV is not time dependent, Ss(x) is a
rotation and translation of Ss(0). Let Ri be the rotation
matrix (in 2D or 3D) of the robot at time ti. Given
the representation of Sr() and Ss(), the reactive set
constraint in (7) can be written concisely as:

∀i ∈ {∆i, .., K},

j = i − ∆i
A(xj)(Ria(xi) + c(xi)) ≤ b(xj)

d( ˜Ss(xj, xi), B0(1)) ≥ 1

(9)

where ˜Ss(xj, xi) is Ss(xj) transformed via the bijective
mapping F : Sr(xi) → B0(1). Equation (9) states that
the origin must be within the translated and skewed FOV,
and that the FOV’s sides must be outside the unit ball
B0(1). Unfortunately, the constraint is not convex in xi
due to the rotation Ri and other nonlinear dependence
on xi. Note that, in the case of polygonal obstacles
the obstacle distance constraint in (7) is computed by
transforming obstacles via F and ensuring that
the
transformed obstacles’ sides are outside the unit sphere.

VI. RESULTS

Several examples are used to exemplify behavior
of the secure planning formulation. In the following
results the same objective function, minimum time, is
used. In addition, a Model Predictive Control (MPC)
reactive controller is utilized by all planners and pe-
nalizes distance to the unknown obstacle and from the
position x(τ ). A bounded acceleration differential drive
model is utilized to emulate the behavior of ground
robots [5]. For details on the exact formulation of both
the NLP in (7), the reactive controller, as well as a
MATLAB simulator, see [16] and the documentation
therein. Finally, timing data are presented comparing a
baseline trajectory optimizer to one solving problem (7).
In Figure 2, the robot is tasked with navigating a
narrow passageway with no unknown obstacles and
starts with an initial velocity of 1m/s. In Figure 2a, the
passageway has a width of 50cm. The robot’s initial

(a)

Fig. 2: Slowing behavior of the secure planner.

(b)

the ellipsoidal reactive set,

velocity reduces while in the passageway to ensure
that
in green, shrinks to
ﬁt within the polygonal constraints. As the robot exits
the passageway,
it accelerates quickly to reduce the
objective function (tf ). As mentioned in section IV-
B, Sr(x(t)) depends primarily on linear and angular
velocity (momentum) and actuation limits. In Figure 2b
the passageway has been narrowed to 20cm. In this case,
a reduction in speed is noticeable by the smaller velocity
arrows and their increased density while traversing the
passageway. The robot achieves the goal in Figure 2a
in 1.60 seconds while that in Figure 2b requires 2.12
seconds.

Figures 3 and 4 show the secure planner compared to
a base-line minimum time planner with obstacle avoid-
ance. In each case, the planners generate a minimum
time trajectory; an unknown obstacle is detected as the
robot rounds the corner, and the reactive controller is
engaged to avoid collision. Figure 3a shows the planned
trajectory of the baseline planner while Figure 3b shows
the realized trajectory. To avoid visual clutter, the sensor
FOV is not drawn, but has a range of r = 2m and angu-
lar range of ∠120. The detection point, red X, denotes
the position of the robot when the unknown obstacle is
observed: x(τ ). In Fig. 3b, a collision results because
the baseline planner did not give the reactive controller
enough time to avoid the obstacle. Conversely, Fig. 4
shows the respective trajectories for the secure planner.
The robot slows down before taking the left-hand turn in
order to maintain visibility of its future reactive regions.
The robot maintains a much larger distance from the
known obstacle (red) and sees the unknown obstacle
while initiating its turn maneuver. The reactive controller
subsequently activates and successfully brings the robot
to a stop.

It is important to note that solve times depend on the
initial guess provided to the optimizer, and a sufﬁciently
poor (read infeasible) guess may cause lack of con-
vergence. For the example in Fig. 4, computation time
ranged from 55-100 seconds depending on initial con-
ditions while the base-line planner took 12-25 seconds
to converge. In Fig. 2 the baseline planner takes 1.5-3
seconds while the secure planner takes 4-6 seconds. All
calculation was done in MATLAB 2016a using fmincon
and an SQP solver. Examples were run on the Windows
10 operating system and a Intel Xenon E5-1630 3.7GHz
processor with no parallelization. The run-time of the
guaranteed planner 5-6 times slower than the base-line
planner, but the use of better optimizers, implementation
in C++, and code optimization may enable near-real-
time computation. In addition, the result of the base-line
planner may be used as an initial guess to ‘warm-start’
the guaranteed planner.

VII. CONCLUSIONS

The problem of planning under adversarial attack on
environmental knowledge is addressed and formulated as
an optimal control problem. A novel idea of the reactive
set was introduced which generalizes stopping distance;
a visibility constraint of this region is also provided.
A connection was made between the continuous time-
problem and that of a Mixed Integer Nonliner Program
(MINP), and an asymptotic proof of safety is provided.
Tightened constraints are utilized to reduce this MINP
to a Nonlinear Program (NLP) enabling an efﬁcient
solution using current nonlinear optimization techniques.
The reduced formulation was then implemented in sim-
ulation.

The behavior of this formulation is analyzed through
several examples. The guaranteed formulation enables a

(a) Initial planned trajectory.

(b) Realized trajectory and collision

Fig. 3: Behavior of a base-line minimum-time planner, with dynamics constraints. The planned trajectory takes 1.67
seconds, but results in a collision.

(a) Initial planned trajectory.

(b) Realized trajectory and avoidance.

Fig. 4: Behavior of the secure planner. The safe path takes 2.50 seconds.

robot to act cautiously before committing to a turning
maneuver around a blind corner while also trading
between speed and safety. This trade prevents collisions
due to uncertainty in the knowledge of the robot’s
environment. Although this work focuses on uncertainty
stemming from a malicious attack, the techniques gen-
eralize to any cases where environmental knowledge
incomplete such as areas that have not yet fully been
explored.

A. The MINP Discretization

APPENDIX

In this appendix, the connection between the con-
tinuous time problem (5) and the NLP formulation is
presented. As mentioned previously, we will not seek
to justify standard discretizations of the objective and
dynamics, but will focus on the set inclusino constraints
in (5).

The constraint ∃τ < t

s.t. Sr(x(t)) ⊂ Ss(x(τ )),
can be read as: “The reactive set must be observed at

some previous time in its entirety.” Suppose a direct
optimization method is employed which discretized time
into K ∈ N+ intervals. The discretized visibility con-
straint is then:

∀i ∈ {2, .., K} ∃j < i

s.t. Sr(xi) ⊂ Ss(xj) (10)

This is an integer constraint since it requires an assign-
ment of a previous time step j for each time-step i.
Therefore, the presented discretized problem is a Mixed
Integer Nonlinear Program (MINP).

minimize
ui∈U,tf
s.t.

L(x1, .., xK, u1, .., uK, tf )

ζi = 0
∀i ∈ {1, .., K} ∃j < i
s.t. Sr(xi) ⊂ Ss(xj)
Sr(xi) ∈ ˆCfree
x1 = s,

xK = e

(11)

B. Proof of Safety

Given the discretization in (11), it is desirable to show
convergence properties for the integer constraint. There
have been several works, such as [19], which show that
the maximum error in the dynamics violation approaches
zero as the number of discretization points K → ∞ due
to the defect constraints ζi. In the case of (10), it is
shown that a ﬁne enough discretization of a path which
ensures that (10) holds, also ensures the continuous
constraint is satisﬁed. Several smoothness assumptions
are required.

Assumption 1.1: The reactive and sensor sets are de-
ﬁned respectively by Lipschitz continuous functions:
Sr : Rn → M, Ss : Rn → M with Lipschitz constants
Lr and Ls.

Assumption 1.2: A feasible solution x∗(t) to (5), sat-
isﬁes the set containment constraint loosely in the sense
that: ∃(cid:15) > 0 ﬁxed s.t. Sr(x(t), t) + B(cid:15)(0) ⊂ Ss(τ )

Given these assumptions:
Proposition 1.3: For any path, x∗(t), which sat-
isﬁes assumptions 1.1, 1.2,
there exists an integer
M ∈ N+ such that ∀K ≥ M , the the discrete set
{xi|x∗(itf /K) = xi, i = 0, 1, ..., K} has the property
that Sr(x∗(t)) ⊂ Ss(xi) for some i ≤ Kt/tf

Proof: During the following argument, the distance
d((cid:5), (cid:5)) is Euclidean when referring to points and Haus-
dorff between sets in Rn. Consider an arbitrary point on
the path x∗(t0). Since this point is part of the solution
to (5) and satisﬁes assumption (1.2), ∃0 ≤ t1 < t0 such
that Sr(x(t0)) + B(cid:15)(0) ⊂ Ss(x(t1)). By assumption
there exists a δ > 0 small enough so that
(1.1),
d(x1, x2) < δ =⇒ d(Sr(x1), Sr(x2)) < (cid:15)
2 , and
also d(Ss(x1), Ss(x2)) < (cid:15)
2 . This comes from taking
the maximum of the two functions’ Lipschitz constants.
Since x∗(t) is continuous on the interval t ∈ [0, tf ] it
is uniformly continuous and ∆t > 0 can be found s.t.

∀τ ∈ [−∆t, ∆t],

d(x∗(t), x∗(t ± τ )) ≤ δ

.

In particular, this is true for t = t1. Thus it follows
that Sr(x∗(t0) ⊂ Ss(x∗(t1 ± τ )). It is clear that M =
(cid:100)tf /∆t(cid:101) then satisﬁes the statement of the proposition.
(cid:4)

Prop. (1.3) states that only a ﬁnite number of points
along a trajectory can guarantee the set inclusion con-
straint is satisﬁed along an entire path. Since (cid:15) can
be arbitrarily small, the satisfaction of the continuous
constraint is well approximated by the discretization in
(10). Note that, if x(t) and Q(x) are Lipchitz, the models
provided in section V ensure that assumptions 1.1 and

1.2 hold. In addition, Prop. (1.3) trivially leads to the
following corollary:

Corollary 1.4: Any time discretization of an optimal
path {x∗(ti)|0 < t1 < t2, ..., tK ≤ tf } such that |ti+1 −
ti| ≤ ∆t, has the property that Sr(x∗(t)) ⊂ Ss(x∗(ti))
for some i where ti < t

REFERENCES

of

Owns

“Whoever

Self-Driving

the Maps

Berman,
Future

[1] B.
the
popularmechanics.com/cars/a21609/
here-maps-future-of-self-driving-cars, 2016.
[2] K. Zetter, “Iran: Computer Malware Sabotaged Uranium
https://www.wired.com/2010/11/

Owns
http://www.

Centrifuges.”
stuxnet-sabotage-centrifuges/, 2010.

Cars.”

[3] D. Majumdar,

“Iran Claims Successful Test Flight of
Stealth UAV.” https://news.usni.org/2014/11/12/
iran-claims-successful-test-flight-stealth-uav,
2014.

[4] S. Checkoway, D. Mccoy, B. Kantor, D. Anderson, H. Shacham,
S. Savage, K. Koscher, A. Czeskis, F. Roesner, and T. Kohno,
“Comprehensive Experimental Analyses of Automotive Attack
Surfaces,” System, pp. 6–6, 2011.

[5] S. Thrun, W. Burgard, and D. Fox, Probabilistic robotics. MIT

press, 2005.

[6] M. Yilin, C. Rohan, and S. Bruno, “Detecting Integrity Attacks
on SCADA Systems,” IFAC Proceedings Volumes, vol. 44, no. 1,
pp. 11239–11244, 2011.

[7] F. Pasqualetti, F. Dorﬂer, and F. Bullo, “Attack detection and
identiﬁcation in cyber-physical systems,” IEEE Transactions on
Automatic Control, vol. 58, no. 11, pp. 2715–2729, 2013.
[8] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation
and control for cyber-physical systems under adversarial at-
tacks,” IEEE Transactions on Automatic Control, vol. 59, no. 6,
pp. 1454–1467, 2014.

[9] M. Pajic, I. Lee, J. G. Pappas, and G. J. Pappas, “Attack-
Resilient State Estimation for Noisy Dynamical Systems,” IEEE
Transactions on Control of Network Systems, vol. PP, no. 99,
pp. 1–10, 2016.

[10] Y. Shoukry, A. Puggelli, P. Nuzzo, A. L. Sangiovanni-vincentelli,
S. A. Seshia, and P. Tabuada, “Sound and Complete State
Estimation for Linear Dynamical Systems Under Sensor Attacks
Using Satisﬁability Modulo Theory Solving,” pp. 3818–3823,
2015.

[11] N. Dadkhah and B. Mettler, “Survey of motion planning liter-
ature in the presence of uncertainty: Considerations for UAV
guidance,” Journal of Intelligent and Robotic Systems: Theory
and Applications, vol. 65, no. 1-4, pp. 233–246, 2012.

[12] M. Hoy, A. S. Matveev, and A. V. Savkin, “Algorithms for
collision-free navigation of mobile robots in complex cluttered
environments: A survey,” Robotica, vol. 33, no. 3, pp. 463–497,
2015.

[13] P. E. Missiuro and N. Roy, “Adapting probabilistic roadmaps
to handle uncertain maps,” Proceedings - IEEE International
Conference on Robotics and Automation, vol. 2006, no. May,
pp. 1261–1267, 2006.

[14] M. P. Vitus and C. J. Tomlin, “A hybrid method for chance
constrained control in uncertain environments,” 2012 IEEE 51st
IEEE Conference on Decision and Control (CDC), pp. 2177–
2182, 2012.

[15] C. Goerzen, Z. Kong, and B. Mettler, A survey of motion
planning algorithms from the perspective of autonomous UAV
guidance, vol. 57. 2010.

[16] A. Ivanov, “Robotic planning resilient to map attack.” https:

//github.com/A-I-Ivanov/CPS_Untrusted_Maps,
2018.

[17] J. T. Betts, Practical Methods for Optimal COntrol and Es-
timation Using Nonlinear Programming. Philadelphia: SIAM,
2nd ed., 2009.

[18] S. Boyd and L. Vandenberghe, Convex optimization. Cambridge,

U.K.: Cambridge Univ. Press, 2003.

[19] C. R. Hargraves and S. W. Paris, “Direct trajectory optimiza-
tion using nonlinear programming and collocation,” Journal of
Guidance Control and Dynamics, vol. 10, no. 4, pp. 338–342,
1987.

