The Challenges in SDN/ML Based Network
Security : A Survey

Tam Nguyen
North Carolina State University
tam.nguyen@ncsu.edu
https://www.linkedin.com/in/tamcs/

8
1
0
2

r
p
A
4
1

]

R
C
.
s
c
[

2
v
9
3
5
3
0
.
4
0
8
1
:
v
i
X
r
a

Abstract—Machine learning is gaining popularity in the net-
work security domain as many more network-enabled devices
get connected, as malicious activities become stealthier, and
as new technologies like Software Dened Networking (SDN)
emerge. Sitting at the application layer and communicating
with the control layer, machine learning based SDN security
models exercise a huge inﬂuence on the routing/switching of the
entire Software Deﬁned Network. Compromising the models is
therefore a very desirable goal. Previous surveys have been done
on either adversarial machine learning without the context of
secure networking environment or the general vulnerabilities of
SDNs without much consideration of the defending ML models.
Through examination of the latest ML based SDN security
applications and a good look at ML/SDN speciﬁc vulnerabilities
accompanied by common attack methods on ML, this paper
serves as a unique survey, making a case for more secure
development processes of ML-based SDN security applications.

I. INTRODUCTION
There is a signiﬁcant gap between the amounts of connected
devices and the number of cyber security professionals. Per
U.S. Bureau of Labor Statistics [1], a projected growth in
cyber security jobs from 2014 to 2024 is 18% while Cisco
[2] predicted a 100% increase in network-enabled devices,
growing from 4 billions in 2016 to 8 billions units in 2021.
Consequently, global data trafﬁcs will increase by at least
5 times. Furthermore,
the emergence of Software Deﬁned
Network makes machine learning (ML) based network security
solutions even more appealing. Usually, researchers design
new ML-based security solutions and then use benchmark
results to prove the models’ accuracy. Such methodology alone
is not attractive enough in the eyes of cybersecurity leaders
due to the lack of information on how those solutions will
ﬁt into the bigger picture at their organizations. Other than
accuracy, the cybersecurity leaders would also like to know
about the model’s projected maintenance costs, the model’s
ability to withstand abuses, the quality of source codes, the
ways datasets were collected, and so on. Previous surveys
have been done on either adversarial machine learning or the
general vulnerabilities of SDNs but not both. For the ﬁrst time,
this paper aims for a complete picture regarding ML-based
security solutions for SDN, addressing:
1. The latest landscape on ML enabled SDN security solutions
2. The vulnerabilities of the common ML models being used
3. The general ways the ML models can be attacked
4. What can be done to better develop ML-based SDN security
solutions.

The paper recognizes that ML models deployed in a network
detection/prevention system are not perfect. Hence there is
always a possibility for attackers to manipulate and/or bypass
the models. Once hackers can bypass the current state of the
model, they may also be able to predict and bypass future
states. From the beginning of their project, solution designers
should pay special attentions to the threat model, the secure
development processes, and so on.

II. SDN BASED NETWORK SECURITY SOLUTIONS

A. Background on SDNs

Software Deﬁned Networking was motivated by the inﬂex-
ibility of traditional networks. Since administrators have to
manually conﬁgure each main box (router/switch), changes do
not happen fast and accurate enough. Additional factors like
different manufacturers for network devices also make difﬁcult
to ﬁnd the right professionals and to scale up the infrastructure
when situations demand. The best example is the migration
from IPv4 to IPv6. The process started several years ago and
yet, we are still at it.
Fundamentally, SDNs differ from traditional networks on the
key principle of separating network policies completely from
network implementations [3]. It consists of 4 pillars : 1.
Separating control plane (CP) from data plane (DP) 2. Flow-
based forwarding (instead of destination based) 3. NOS -
network ”operating system” - controls all
the ﬂow logics
4. Everything is programmable through APIs. In fact, well-
deﬁned APIs between the planes are the indicator of a good
SDN as they are separated into Southbound group (facing
the data plane) and Northbound group (facing the application
plane). OpenFlow is one example of such API. During normal
operations, CP will dynamically modify the ﬂow table which
consists of 3 components: 1- A matching rule (based on ﬁelds
like switch port, TCP ports, Vlan ID, MAC, Ethernet type)
2- Actions per matched rule/packets (forward, encapsulate,
drop, send to processing pipelines) 3- Counters keeping track
of matched packets to form per table/per ﬂow/per port/per
queue statistics. Some example of SDN controlers include
NMS, NOX, POX, Floodlight, ProCel, Beacon, OpenDaylight,
ProgrammableFlow, FlowVisor, OpenSketch, Procera, Ethane,
Trema, SANE.
This centralized control design brings ﬂexibility, simplicity,
elasticity, promptness and many other beneﬁts. It is important
to note that while ﬂow control is centralized, the CP can be

 
 
 
 
 
 
Fig. 1. The Roles of ML Models in 2017 Software Deﬁned Network IEEE Xplore Published Papers

physically distributed. Some SDN implementations are already
at a very large scale production level such as the one being
used by Google to connect its data centers across the globe.

B. SDN based network security solutions

1) Policy Enforcement: Products like SANE [4] allow
enforcement of simple and natural access control policies at
the link layer - independent from topologies while hiding
topology and service information from those without the needs
to know. Between a server B and client A, there are 3 steps
in SANE’s model. First, each party has to be authenticated
with the controller. Second, B publishes to the controller what
kind of service it is willing to provide and A requests from
the controller what kind of service it needs. Finally, server
double checks everything and establishes service accordingly.
More than just access control, SDN also supports other diverse
security policies relating to intrusion detection, virus scanning,
protocol
identiﬁcation, etc. with linearly-increasing perfor-
mance. One example is LiveSec [5] with its ”interactive policy
enforcement” in which network administrators can add/remove
both rules and network security services easily with visual
feedbacks. It is supported by a global policy table enforced
by dynamic modiﬁcation of MAC addresses. The beneﬁts of
SDN becomes more obvious when it comes to virtual and
cloud environments. We can apply different sets of policies
onto different types of VMs being created dynamically on the
cloud, providing protection services similar to ﬁrewalls as well
as elastic IP service. [6] Because the controller has a detailed
overview of ﬂows and ﬂow paths on its network, enforcing
address validation policies is efﬁcient. [7] For example, if there

are B and C between the only path from A to D, a legitimate
ﬂow from A to D will have to leave its traces in A, B, C
and D. With such knowledge, the controller can easily spot a
spoofed ﬂow A to D after ﬁguring out that the ﬂow did not
travel through B and C.

2) Denial of Service Mitigation: The key point in protect-
ing networks from being DOS’ed is the recognition of what
ﬂows of trafﬁcs are malicious as soon as possible. Because
malicious packets are very similar to legitimate packets, the
use of machine learning (ML) algorithms for automatic ﬂow
classiﬁcation is not new. Traditional methods involve the pre-
processing of trafﬁc log ﬁles and captured packets in order
to produce some basic statistics that the ML models can use.
Such high overhead practice is not needed in SDN because
counters are embedded within each network device in the data
plane. The statics relating to forwarded trafﬁcs are always
ready and can be queried by the control plane at anytime.
A DOS detection loop contains 3 components:
the Flow
Collector, the Feature Extractor, and the Classiﬁer. [8] Once
identiﬁed, malicious trafﬁcs should be dropped or forwarded to
a null interface as being used in Remote Triggered Blackhole
Routing Component (RTBH). The collateral damage is high
with legacy RTBH due to the inﬂexibility of the trigger routers.
SDN can allow a much more ﬂexible RTBH, dropping the
malicious ﬂows while still maintaining benign ﬂows. [9]

3) Cloud Security: In current PaaS offerings, everything
follows the service model of which cycle involves (1) pro-
vision (2) bind, (3) unbind and (4) provision. Implementing
cloud network security functions is therefore difﬁcult. For
the ”wiring” between services can get really
one reason,

complicated and time consuming. For another reason, it is
very difﬁcult to reach to the network packet level from the
cloud application level - all packet ﬁelds are hidden. Going to
the rescue, SDN allows cloud network security services like
IDS/IPS to: +manipulate trafﬁcs with minimal data copying
+operate at both packet and request
levels +conveniently
generate callbacks via existing APIs +be chained with other
network services easily. [10] Many high level routing al-
gorithms can be designed and implemented in a way that
guarantees all packets will be inspected by at least one security
device.[11]

4) Topology Protection: Protecting network topology is
crucial
in SDNs since all popular SDN controller are all
subjected to network topology attacks [12]. Any changes
to ﬂow behaviors should be ﬂagged for immediate remedy.
Solutions can be ﬂow-graph based [13] in which ﬂow-graph
of ﬂows will be incrementally built and veriﬁed in real time.
Veriﬁcation is either deterministic (following the edges of
graph) or probabilistic. Other solutions include VeriFlow [14],
AvantGuard [15], and FloodGuard [16].

5) Others: The latest research landscape of ML based
security solutions for SDN is shown in ﬁgure 1. Other security
solutions for SDNs can be found in the ”Software-Deﬁned
Networking: A Comprehensive Survey” by Krewtzet et. al.
[17].

C. Anomaly Detection Using Machine Learning

Compared with signature based detection, anomaly detec-
tion using ML is more scalable, and more ﬂexible.[27] All
machine learning approaches follow the same general steps
of identifying/building learning data sets, feature extraction
and classiﬁcation.Selecting the right dataset is crucial because
ML models can only identify anomalies based on what it has
known (trained with).The more organic, diverse and properly
prepared dataset we have, the more accurate our models will
be. Pre-processing steps usually involves mapping symbolic
values to numeric values, data scaling, etc. In the feature
extraction step, we pick the optimal number of features that
will be used by the model to successfully categorize the classes
that we want. Common methods are dimensional reduction
(mapping more dimension variables into fewer ones), cluster-
ing (identifying groups of items with similar characteristics),
statistical sampling, measuring and pick samples based on en-
tropy and so on.For classiﬁcation, there are three approaches:
1. Supervised learning (the models learn from labeled data and
predict unknown cases) 2. Unsupervised learning (the models
learn the fundamentals of unlabeled data and predict unknown
cases) 3. Semi-supervised learning.Further details behind ML
algorithms and methodologies can be found in numerous ML
general surveys [28].
In the domain of network security, SDN brings some unique
advantages to the deployments of ML based network security
solutions. For example, the centralized control sitting on the
software layer with API access making it very convenient
to develop ML softwares. Devices in SDN data plane has
counters built-in and can provide statistical reports to applica-

tion layer softwares upon requests. Table I provides us with
the most notable SDN/ML research works indexed by IEEE
Xplore from 2017 to MAR2018 (the time of this paper) from
which we can see a broad range of ML based solutions and
the incredible ﬂexibility that SDN architecture can provide. It
also shows that there is an on going strong interest from the
research community in ML based network security solutions
for SDN.

III. ISSUES WITH ML MODELS IN SDN SECURITY
SOLUTIONS

In addition to existing problems within the protocols such
as OpenFlow vulnerabitlies [29], ML-based security solutions
for SDN also face issues with (1) hard to ﬁnd organic training
data; (2) a semantic gap between innitial work and practical
real world deployments; (3) enormous variability in input data;
(4) measuring and minimizing the cost of errors; and (5) other
difﬁculties in evaluation [30].
A large portion of training data for ML-based SDN security
applications is synthetic and is not realistic enough. Com-
monly used data sets include but not limiting to the University
of New Brunswick ISCX 2012 Intrusion Detection, Evaluation
Data Set, the CIC DOS Dataset, the KDD dataset, the ADFA-
LD12 dataset, the UNSW-NB15 dataset, the WSN-DS dataset,
and so on [27]. Because those datasets were developed by
research institutes and made available to the public, ML-
based solutions trained on those datasets alone can be out-
maneuvered by adversaries who studied the same data. While
some corporations have the capability to collect own training
datasets from their existing networks, the fear of business
secret, conﬁdential communications, and employees personal
identiﬁable information being leaked from such datasets really
discourages them
Unlike Artiﬁcial Intelligence, a ML model works by recog-
nizing the deviations from what it was trained on and because
of problems with training datasets, ML models usually give
plenty of false positives when being deployed in real-world
environment. It is also difﬁcult to interpret the overall results
for actionable intelligence - a.k.a the Semantic Gap. For
example, if the model’s accuracy is 98% on detecting some
variations of social security numbers in http trafﬁcs, it does
not give the administrators much information on how social
security numbers are actually being leaked out of the network.
The model does not know what it does not know, and it will
skip leaks that are far different from the samples it was trained
with.
Even when there is absolutely nothing wrong going on, per-
formance of ML models in the real world is usually degraded
because of a signiﬁcantly higher volume of data, a much wider
range of ﬂuctuations, real world constraints, and so on. In
short, while being good at classiﬁcation tasks, ML models are
not be able to recognize the context and logics behind real
world situations [27]. Consequently, it is challenging to really
evaluate a model. While there is no formal agreed standard
on how to evaluate ML models and what metrics should be
used, justiﬁcation cannot be relied on the accuracy rate alone.

PUBLICATION

FUNCTIONALITY SUCCESS ML METHODOLOGY

AMPS: Application aware multipath ﬂow
routing using machine learning in SDN [18]

Dynamic multipath
ﬂow routing

Dynamic attack detection and mitigation in
IoT using SDN [19]

IoT monitoring and
protection

Analytics-Enhanced Automated Code Ver-
iﬁcation for Dependability of Software-
Deﬁned Networks [20]

Detect and prevent
malicious SDN app
behaviors

98%

98%

99%

Supervised learning on 40-features dataset with C4.5 Decision Tree
algorithm

Support Vector Machine model was used on processed data passed
down from a learning module in order to classify trafﬁcs. Both linear
and non-linear kernel (RBF) were used.

It is a combination of automated code veriﬁcation (Java Path Finder)
with ML analytic model (Ckmeans), being independent of underlying
network topology

An applied pattern-driven corpus to predic-
tive analytics in mitigating SQL injection
attack

Prevent SQL injec-
tion in the cloud

98%

Two-Class Support Vector Machine and Two-Class Logistic Regression
with linear kernel implemented on Microsoft Azure Machine Learning

Forecasting and anticipating SLO breaches
in programmable networks [21]

Cognitive SLA en-
forcement

90%

Protecting Service Level Objectives
response time,
throughput) using Long Short Term Memory Recurrent Neural Network
(able to identify previously seen patterns in new distorted samples)

(availability,

Access point selection algorithm for pro-
viding optimal AP in SDN-based wireless
network [22]

Pick best QoS, less
backhaul
conges-
tion

depends

Trafﬁc classiﬁcation deployed at AP, using C5.0 Decision Tree algo-
rithm

Content Popularity Prediction and Caching
for ICN: A Deep Learning Approach With
SDN [23]

Cache
management

75%
mean
accuracy

Improving cach operations by predicting the popularity of content using
Deep-Learning-based Content Popularity Prediction (Stacked Auto-
Encoders + Softmax)

AWESoME: Big Data for Automatic Web
Service Management in SDN [24]

Web trafﬁc engi-
neering

90%

Annotation module at network edge classiﬁes ﬂows in real time based
on bag-of-domains (using Apache Spark), ﬂow-to-domain, domain-2-
service, and service-to-rule.

Athena: A Framework
Scalable
Anomaly Detection in Software-Deﬁned
Networks [25]

for

security

Network
development
framework

depends

11 ML models were made available as library, allowing developers to
quickly develop network security applications that can perform real-
time detection and responses.

FADM: DDoS Flooding Attack Detection
and Mitigation System in Software-Deﬁned
Networking [26]

framework
DOS prevention

for

depends

Feature extraction is entropy-based and attack detection is powered by
Support Vector Machine

TABLE I
10 ML-BASED SECURITY SOLUTIONS FOR SDNS SINCE 2017

In the following section, we will brieﬂy examine the inherent
limitations of common ML algorithms.

1) Artiﬁcial Neural Networks (ANNs) are ﬁt for non-linear
problems but tend to suffer from local minima leading to
long learning time, and as the number of features increases,
the longer it will take to learn. ANNS can reach deeper into
lower network layer data and are able to detect some low/slow
type attacks. While they can identify 100% of the normal
behavior, the amount of false alarms may sometimes reach
76% depending on what kind of attacks were being executed
[31].

2) Bayesian network is a probabilistic directed acyclic
graph type with nodes as variables and the edges as their
relationships. Based on the relationships, a node can ”walk”
to another. At the end of the walk, a ﬁnal probabilistic score is
formed. Relationship links that have high true positive score
will be veriﬁed and formed into rules. Therefore, a Bayesian
network is proactive even in misuse mode. In a test of using
model to label IRC-botnet generated data, the precision rate is

93% with a false positive rate of 1.39% (detecting fewer cases
than some other models but generating less false alerts). In
other tests, the reported precision rates are 89%, 99%, 21%,
7%, and 66% for DoS, probe/scan, remote-to-local, user-to-
root, and ”other” classes of attacks respectively [31].

3) Some popular clustering models are k-means, k-nearest
neighbor, density-based spatial clustering of applications with
noise (DBSCAN), etc. Explicit descriptions of classes are not
required. However too many features may confuse the model
and any imbalance in the feature set will negatively affect its
decisions (the ”curse of dimensionality”). Clustering can detect
up to 80% of unknown attacks. Some clustering models can be
really accurate (98%) in analyzing captured PCAP packages
but the performance goes down when dealing with streaming
data as false alarm rate may go up to 28%.

4) Decision tree is a ﬂow-chart

like structure built on
concepts of information gain/entropy where each node choose
the best ﬁt attribute to split current set of examples into
subsets. Normally, decision trees provide high accuracy with

Papers
BotMiner [32]
BotSniffer [33]
N-gram [34]
Unclean [35]
FluXOR [36]
Tight [37]

FPR (%)
0.1875
0.1600
8.1400
1.2100
0.0000
15.0400

FNR (%)
—
—
1.64
1.22
—
2.49

TPR (%)
96.82
100.00
98.36
98.78
—
75.10

TNR (%)
81.25
84.00
91.86
87.90
100.00
84.96

TABLE II
ACCURACY-BASED PERFORMANCE METRICS COMPARISON

simple implementation. It is not usually the case with larger
trees where the model tends to favor attributes with more
levels.

5) While Genetic Algorithm (GA) and Genetic Program-
ming (GP) are most used Evolutionary Computation (EC)
methods; Particle swarm optimization, Ant Colony Optimiza-
tion, Evolution Strategies are also parts of the group. The
main concept
is based on the idea of ”the strongest will
prevail” and basic operators are selection, crossover, and
mutation. Experiments with various attack types show that the
average false alarm rate is very low. However, the sensitivity
in detecting new attacks varies greatly (from 66% to 100%)
depending on attack types.

6) Naive Bayes model calculates the ﬁnal conditional prob-
ability of ”attack” (or ”normal”) with a naive assumption
that the used features are independent from each other. That
assumption is the biggest limitation of this model. However,
if the features are indeed independent from each other, naive
Bayes can be very powerful thanks to its simple algorithm.
It allows the model to be highly scalable and be used as an
online classiﬁer. In tests, model’s accuracy of identifying data
as ”normal” is 97% for DoS type attacks while only 9% for
remote-to-local type attacks.

7) Supported Vector Machine (SVM) is a binary classiﬁca-
tion model by design. With a kernel such as linear, polynomial,
Gaussian Radial Basis Function, or hyperbolic tangen; the
model will try to draw a hyperplane that divides the feature
space into two classes. Sometimes, when overlapping is un-
avoidable, slack variables will be added and each overlapping
data point will be be assigned a cost value. The model is quite
accurate but also shows limitations at identifying certain types
of attacks such as user-to-root attack.Test results show great
variations in accuracy (from 65% to 99.9%) and sometimes,
false negative rate can get really high (over 30%) [31].

IV. ATTACKING ML MODELS

The deﬁnition of ”attack” on ML models should be ﬂexible
and be focusing on the models’ purposes rather than the
the only
models’ functionalities. The accuracy rate is not
thing adversaries can target. For example, adversaries can
cause the models to produce true positives that are very close
to false positives. Consequently, it causes burn-outs on the
security analysts who are going to manually inspect those
ﬂags. ”Attack” can also mean signiﬁcantly increasing the time
it takes for a ML model to make a speciﬁc decision. No
matter what attack end-goals are, attackers must ﬁrst have

some really good insights about the targeted model. Thus,
there is a strong motivation to clone/extract a security ML
model. When performing model extraction, inputs are given
to a trained model, end results (outputs) got harvested, and
clone model learns from those input-output data pairs. While
it appears that training the original model and cloning an
existing model are quite similar, model cloning does not
have to deal with broken or faulty data entries that delay
or even mislead the learning process. Model cloning also
does not have to deal with optimization issues such as local
minima/maxima traps. In 2016, Tramer et. al. [38] proposed
several methods to perform model extraction of several ML
types but those methods were not weaponized. For example,
the number of probes used was too high to be considered
practical in targeting a protected environment.

A. Equation-solving attack

This form of attack is ﬁt for logistic regression types
such as binary logistic regression (BLR), multi-class logistic
regression (MLR), and multi-layer perceptron (MLP). Because
the models can be represented as equations with variables,
attackers just need to feed the known variable values in, use
mathematics to solve the equations and get the rest of the
unknown values. For example, with BLR, we have :
w ∈ Rd, β ∈ R with fi(x) = σ(w × x + β)
where
σ(t) = 1/(1 + e−t)
Attacker will feed xi to the trained model and the model will
give yi = f (xi) = σ(w × xi + β). If we have enough xi, yi,
we should be able to solve the equations to get w and β. The
math will be more complicated when dealing with MLRs and
MLPs.With softmax model in MLR for instance, we have:
c > 2, w ∈ Rcd, β ∈ Rc
fi(xi) = ewi×x+βi/((cid:80)c−1
j=0 ewj ×x+βj )
The function can be solved by minimizing its cost/loss func-
tions. The methods proved to be effective in Tramer’s exper-
iments [38]. With BLR, they were able to achieve Rtest =
Runif = 0 with an average probe of 41. The number of probe
is much greater with MLR and MLP. For instance,it required
them to perform 54,100 queries on average in order to achieve
100% accuracy on a 20 hidden node MLP. Unlike BLR, it is
sometimes very hard to estimate a correct amount of probes
needed for MLP and MLR cloning. Especially with MLP, it is
hard for attackers to guess how many hidden neuron layers are
there, and how many neurons per layer. Attackers will also not
be able to tell how many classes an original MLP can identify.
However, everything can be different in actual cyber attack
scenario. Instead of 100% accuracy, attackers may only need
to clone a model with 90% accuracy for their purposes, and the
amount of probes needed may be signiﬁcantly lower. Another
reason to not aiming for 100% accuracy is that original ML
models get tunned on a fast pace, daily. A 100% accurate
cloned model of today maybe different from the actual model
next week.

Fig. 2. A Sample Kill Chain for Attacking Stratosphere IPS

B. Model inversion attack

Given feature dimension d with feature vector x1, x2, ..., xd,
some knowledge about some of the features, and access to f
- the model, Fredrikson et al. [39] proposed that a black box
model inversion attack which involves ﬁnding an optimal x
that maximizes the probability of some known values.
xopt = argmaxx∈X fi(x)
For instance, if an image of Bob was used to train model M to
recognize category ”man”. If that exact image is fed into M,
the result will be ”man” with 100% conﬁdence while images
do not belong to the training set will never get such absolute
score from the model. An attacker can start with one pixel and
ﬁnd the pixel value that gives the maximum score possible of
category ”man”. The process continues to other pixels and the
end result is an image very close to Bob’s original image in
the training set. Tramer et al. [38] upgraded this approach by
performing inversion attack on a cloned model M’ of M. The
reported improvement is a 6-hour faster recovering time for
40 faces. This kind of attack opens a theoretical possibility of
which attackers can gain some insightful knowledge about a
security model’s trained data set if they could clone the model
with 100% accuracy and somehow was able to tunnel it out.

C. Path-ﬁnding attack

Tramer et al. [38] also extended prior works on tree attacks
and proposed their ”path-ﬁnding” attack which can be used to
map binary trees, multi-nary trees, and regression trees. We
have a tree T with v nodes and at each node, there is an
identiﬁer idv. With x ∈ X, an oracle query will give O(x) =
idv. If x ∈ X1 ∪ ⊥ × ... × Xd ∪ ⊥, O(x) will return the
identiﬁer at the node where T stops. To begin the attack, we
pick x ∈ X1 ∪⊥×X2 ∪⊥×...Xi1 = [a, b]×...×Xd ∪⊥. O(x)

gives idLv at the leaves of the tree. We then can separate [a, b]
into n sub ranges where n is the number of the corresponding
known leaves (at this point). For each Xi1 sub range, we repeat
the process and ﬁnd another nodes/leaves. This was referred to
as the top-down approach which is of higher performance than
the bottom-up approach. Reported performance evaluations of
this approach show that in order to achieve 100% on 1 − Rtest
and 1 − Runif , it will take 29,609 queries to clone a tree with
318 leaves, 8 layers of depth; 1,788 queries to clone a tree
with 49 leaves, 11 layers of depth; and 7,390 queries to clone
a tree with 155 leaves and 9 layers of depth.

D. Other attacks

There are several more ways to attack ML models. The
Lowd-Meek attack [40] targets linear classiﬁers that give only
class labels as models’ outputs. The general
idea of this
approach is using adaptive queries to throw sample points
at the suspected positions of the hyperplane. Another way to
attack was described by Bruckner [41] as a single Stackelberg
Prediction Game (SPG). In this game, the Leader (L) is the one
with the original ML model M. the Follower (F) is the attacker.
F will attack L by generating and feeding model M data that
at least will prevent M from learning new knowledge or at
most, teach M new faulty knowledge. Theoretically, this can
be achieved by providing learning data that maximize the cost
function of model M. In real life situations, there are more
than one attacker with different attacking goals and L does
not know how many F are there and what exactly each F is
trying to do. This escalates to the Bayesian Stackelberg Game.
Zhou and Kantarcioglu described it as ”Nested Stackelberg
Game” [42] suggesting a solution of using and switching a
set of models to confuse the attacker. Kantarcioglu later on

also proposed the concept of ”planning many steps ahead” in
this game. Details of these methods will be further studied and
evaluated within a defense-in-depth environment and will be
discussed in future works.

V. RECOMMENDATIONS

A. Invest time on attack/defense model

From the beginning, ML scientists should pay attention to
the ML cyber kill-chain (the attack model) and at least develop
a list of recommendations on safe implementation. Recom-
mendations may include but are not limited to the designer’s
deﬁnition of ”attack”, the meaning of model’s accuracy, the
side channels, etc. This is essentially important in the context
of open-source. As mentioned before, the deﬁnition of ”attack”
should depend on the model’s intended purposes rather than
just its accuracy. Some ML based solutions were designed to
be multi-purposes. Some solutions were originally designed
for a speciﬁc purpose but were used for other purposes in
real-world implementations. Nonetheless, the designers should
clearly communicate the intended purposes of the works they
are proposing and ways to protect them. For example, most
recent works in ML based security for SDNs have accuracy
rates of 98% (Table I) but the meaning of 0.2% increase in
false negatives may differ greatly from one to another. Based
on the attack model, the ML designers may also provide
a default protection model, explaining how the structure of
their designs ﬁt into the protection model, what may be done
to harden their works, what are the security trade-offs to
be considered, what are the potential side channels in real
world deployments, and so on. While research works are not
supposed to be commercial ready, basic recommendations on
how to protect and harden a ML based solution by its designers
are extremely valuable.

B. Design audit-able model

ML based solutions should generate meaningful logs or
even better, having an interface for the model to be audited
automatically. Audits may include information on who made
what changes, how much the model has drifted after a period
of time, the rates of false positives and false negatives, etc.
Ideally, the model itself should be able to give indications on
whether or not it is under attack and which stage of the kill
chain the attackers are at. ML based solution with good audit
capability will also help in case the model needs to be rolled
back to its earlier versions.

C. Follow secure development processes

Because ML based security solutions are softwares, the
designers should at least follow a secure software develop-
ment lifecycle [43]. It involves secure coding practices, static
analysis, test cases, attack surface reviews, and so on. Formal
veriﬁcation is absolutely necessary and should be done to the
largest extend possible considering there are huge challenges
in performing formal veriﬁcations on systems like the artiﬁcial
neural network. Side channels should be limited and there
are mechanisms to protect the privacy of the model and its

data. Finally, datasets used for training should be as organic
as possible.

D. Design an operational cost model

Cost is another factor as important as accuracy. For the
same purpose, a leaner ML algorithm will usually cost less
than a complicated one but there may be cases where it is
justiﬁable to have a complex ML model or even a group of
different ML models working together. The designers should at
least provide a cost model to make practical sense out of their
design decisions. A well designed cost model will help with
evaluating the cost of false negatives - a very important metric
in ML based solutions for cyber security. The paper ”Machine
Learning with Operational Costs” from MIT researchers [44]
may serve as a good start for further readings into optimizing
ML operational costs.

VI. CONCLUSION
There is a gap between academic researches on ML based
solutions for SDNs and their operational deployments. While
research works do not have to meet the strict requirements
for a commercial ready product, it is important that solution
designers pay attention and establish some initial foundations
for the hardening of their works just in case the works are
chosen to be implemented in ”the wild”. It is important to
note that there are issues with evaluating the true performance
of ML-based SDN security applications and model’s accuracy
alone will not be enough. Let’s not forget that attackers are
also equipped with Machine Learning powers and can build
systems to predict the behaviors of the defending models. For
those reasons, this paper suggests four speciﬁc recommenda-
tions:
1) Pay attention to threat models while designing ML solu-
tions.
2) Make the ML model audit-able
3) Follow a secure development process
4)Produce an initial operational cost model
It is believed that these recommendations will signiﬁcantly im-
prove the practical properties of ML based solutions for SDNs.
Future works will include an automatic system designed to
evaluate the robustness of well-known ML based, open source
cyber security products such as Apache Spot [45]. Hopefully,
it can be developed into a threat model assessment tool which
can be used to communicate better evaluation metrics of ML-
based SDN security solutions

REFERENCES

[1] Bureau of Labor Statistics, “US Bureau of Labor Statistics, Occupational

Outlook Handbook,” 2015.

[2] C. V. N. I. Forecast, “Cisco visual networking index: Global mobile data
trafﬁc forecast update 2016-2021,” Cisco Public Information, February,
2017.

[3] D. Kreutz, F. M. Ramos, and P. Verissimo, “Towards secure and
dependable software-deﬁned networks,” in Proceedings of the second
ACM SIGCOMM workshop on Hot topics in software deﬁned networking
- HotSDN ’13. New York, New York, USA: ACM Press, 2013, p. 55.
[4] M. Casado, T. Garﬁnkel, A. Akella, M. J. Freedman, D. Boneh,
N. McKeown, and S. Shenker, “SANE: a protection architecture for
enterprise networks,” 15th USENIX Security Symposium, p. 137151,
2006.

[5] K. Wang, Y. Qi, B. Yang, Y. Xue, and J. Li, “LiveSec: Towards Effective
Security Management in Large-Scale Production Networks,” Distributed
Computing Systems Workshops (ICDCSW), 2012 32nd International
Conference on, pp. 451–460, 2012.

[6] G. Stabler, A. Rosen, S. Goasguen, and K.-C. Wang, “Elastic IP and
security groups implementation using OpenFlow,” in Proceedings of the
6th international workshop on Virtualization Technologies in Distributed
Computing Date - VTDC ’12, 2012, p. 53.

[7] G. Yao, J. Bi, and P. Xiao, “Source address validation solution with
OpenFlow/NOX architecture,” in Proceedings - International Confer-
ence on Network Protocols, ICNP, 2011.

[8] R. Braga, E. Mota, and A. Passito, “Lightweight DDoS ﬂooding attack
detection using NOX/OpenFlow,” Proceedings - Conference on Local
Computer Networks, LCN, no. October, pp. 408–415, 2010.

[9] K. Giotis, G. Androulidakis, and V. Maglaris, “Leveraging SDN for
efﬁcient anomaly detection and mitigation on legacy networks,” in Pro-
ceedings - 2014 3rd European Workshop on Software-Deﬁned Networks,
EWSDN 2014, 2014.

[10] H. Jamjoom, D. Williams, and U. Sharma, “Don’t call them middle-
boxes, call them middlepipes,” in Proceedings of the third workshop
on Hot topics in software deﬁned networking - HotSDN ’14, 2014, pp.
19–24.

[11] S. Shin and G. Gu, “CloudWatcher: Network security monitoring using
OpenFlow in dynamic cloud networks (or: How to provide security
monitoring as a service in clouds?),” in Proceedings - International
Conference on Network Protocols, ICNP, 2012.

[12] S. Hong, L. Xu, H. Wang, and G. Gu, “Poisoning Network Visibility
in Software-Deﬁned Networks: New Attacks and Countermeasures,” in
Proceedings 2015 Network and Distributed System Security Symposium,
2015.

[13] M. Dhawan, R. Poddar, K. Mahajan, and V. Mann, “SPHINX: Detecting
Security Attacks in Software-Deﬁned Networks,” in Proceedings 2015
Network and Distributed System Security Symposium, 2015.

[14] A. Khurshid, W. Zhou, M. Caesar, P. B. Godfrey, X. Zou, W. Zhou,
M. Caesar, and P. B. Godfrey, “Veriﬂow: verifying network-wide invari-
ants in real time,” in Presented as part of the 10th USENIX Symposium
on Networked Systems Design and Implementation (NSDI 13), 2013, pp.
15–27.

[15] S. Shin, V. Yegneswaran, P. Porras, and G. Gu, “AVANT-GUARD,”
in Proceedings of the 2013 ACM SIGSAC conference on Computer &
communications security - CCS ’13, 2013, pp. 413–424.

[16] H. Wang, L. Xu, and G. Gu, “FloodGuard: A DoS Attack Prevention Ex-
tension in Software-Deﬁned Networks,” in 2015 45th Annual IEEE/IFIP
International Conference on Dependable Systems and Networks.
IEEE,
6 2015, pp. 239–250.

[17] D. Kreutz, F. M. V. Ramos, P. Esteves Verissimo, C. Esteve Rothen-
berg, S. Azodolmolky, and S. Uhlig, “Software-Deﬁned Networking: A
Comprehensive Survey,” Proceedings of the IEEE, vol. 103, no. 1, pp.
14–76, 1 2015.

[18] S. T. V. Pasca, S. S. P. Kodali, and K. Kataoka, “AMPS: Application
aware multipath ﬂow routing using machine learning in SDN,” in 2017
Twenty-third National Conference on Communications (NCC).
IEEE,
3 2017, pp. 1–6.

[19] S. S. Bhunia and M. Gurusamy, “Dynamic attack detection and mitiga-
tion in IoT using SDN,” in 2017 27th International Telecommunication
Networks and Applications Conference (ITNAC).
IEEE, 11 2017, pp.
1–6.

[20] L. J. Jagadeesan and V. Mendiratta, “Analytics-Enhanced Automated
Code Veriﬁcation for Dependability of Software-Deﬁned Networks,” in
2017 IEEE International Symposium on Software Reliability Engineer-
ing Workshops (ISSREW), 2017.

[21] J. Bendriss, I. G. Ben Yahia, and D. Zeghlache, “Forecasting and
anticipating SLO breaches in programmable networks,” in 2017 20th
Conference on Innovations in Clouds, Internet and Networks (ICIN).
IEEE, 3 2017, pp. 127–134.

[22] D. Lee and C. S. Hong, “Access point selection algorithm for providing
optimal AP in SDN-based wireless network,” in 2017 19th Asia-Paciﬁc
Network Operations and Management Symposium (APNOMS).
IEEE,
9 2017, pp. 362–365.

[23] W. X. Liu, J. Zhang, Z. W. Liang, L. X. Peng, and J. Cai, “Content
Popularity Prediction and Caching for ICN: A Deep Learning Approach
with SDN,” IEEE Access, vol. 6, pp. 5075–5089, 2017.

[24] M. Trevisan, I. Drago, M. Mellia, H. H. Song, and M. Baldi, “AWE-
SoME: Big Data for Automatic Web Service Management in SDN,”

IEEE Transactions on Network and Service Management, vol. 15, no. 1,
pp. 13–26, 3 2018.

[25] S. Lee, J. Kim, S. Shin, P. Porras, and V. Yegneswaran, “Athena:
A Framework for Scalable Anomaly Detection in Software-Deﬁned
Networks,” in 2017 47th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks (DSN).
IEEE, 6 2017, pp. 249–
260.

[26] D. Hu, P. Hong, and Y. Chen, “FADM: DDoS Flooding Attack Detection
and Mitigation System in Software-Deﬁned Networking,” in GLOBE-
COM 2017 - 2017 IEEE Global Communications Conference.
IEEE,
12 2017, pp. 1–7.

[27] N. Sultana, N. Chilamkurti, W. Peng, and R. Alhadad, “Survey on
SDN based network intrusion detection system using machine learning
approaches,” Springer - Special Issue on Software Deﬁned Networking:
Trends, Challenges and Prospective Smart Solutions, pp. 1–9, 2018.

[28] D. Kwon, H. Kim, J. Kim, S. C. Suh, I. Kim, and K. J. Kim, “A survey

of deep learning-based network anomaly detection,” pp. 1–13, 2017.

[29] K. Benton, L. J. Camp, and C. Small, “OpenFlow vulnerability assess-
ment,” in Proceedings of the second ACM SIGCOMM workshop on Hot
topics in software deﬁned networking - HotSDN ’13, 2013, p. 151.
[30] R. Sommer and V. Paxson, “Outside the Closed World: On Using
Machine Learning for Network Intrusion Detection,” in 2010 IEEE
Symposium on Security and Privacy, 2010, pp. 305–316.

[31] A. L. Buczak and E. Guven, “A Survey of Data Mining and Machine
Learning Methods for Cyber Security Intrusion Detection,” IEEE Com-
munications Surveys & Tutorials, vol. 18, no. 2, pp. 1153–1176, 22
2016.

[32] G. Gu, R. Perdisci, J. Zhang, and W. Lee, “BotMiner: clustering analysis
of network trafﬁc for protocol- and structure-independent botnet detec-
tion,” SS’08: Proceedings of the 17th conference on Security symposium,
2008.

[33] G. Gu, J. Zhang, and W. Lee, “BotSniffer : Detecting Botnet Command
and Control Channels in Network Trafﬁc,” Proceedings of the 15th
Annual Network and Distributed System Security Symposium., vol. 53,
no. 1, pp. 1–13, 2008.

[34] W. Lu, G. Rammidi, and A. A. Ghorbani, “Clustering botnet communi-
cation trafﬁc based on n-gram feature selection,” Computer Communi-
cations, vol. 34, no. 3, pp. 502–514, 3 2011.

[35] M. P. Collins, T. J. Shimeall, S. Faber, J. Janies, R. Weaver, M. De Shon,
and J. Kadane, “Using uncleanliness to predict future botnet addresses,”
in Proceedings of the 7th ACM SIGCOMM conference on Internet
measurement - IMC ’07. New York, New York, USA: ACM Press,
2007, p. 93.

[36] E. Passerini, R. Paleari, L. Martignoni, and D. Bruschi, “FluXOR:
Detecting and Monitoring Fast-Flux Service Networks,” in Detection
of Intrusions and Malware, and Vulnerability Assessment.
Berlin,
Heidelberg: Springer Berlin Heidelberg, 2008, pp. 186–206.

[37] W. T. Strayer, R. Walsh, C. Livadas, and D. Lapsley, “Detecting botnets
with tight command and control,” in Proceedings - Conference on Local
Computer Networks, LCN, 2006.

[38] F. Tram`er, F. Zhang, F. E. Epﬂ, A. Juels, M. K. Reiter, and T. Ris-
tenpart, “Stealing Machine Learning Models via Prediction APIs,” in
Proceedings of the 25th USENIX Security Symposium, 2016.

[39] M. Fredrikson, S. Jha, and T. Ristenpart, “Model Inversion Attacks
that Exploit Conﬁdence Information and Basic Countermeasures,” Pro-
ceedings of
the 22nd ACM SIGSAC Conference on Computer and
Communications Security - CCS ’15, pp. 1322–1333, 2015.

[40] D. Lowd and C. Meek, “Adversarial Learning / RL.”
[41] M. Br¨uckner and T. Scheffer, “Stackelberg Games for Adversarial

Prediction Problems.”

[42] Y. Zhou and M. Kantarcioglu, “Modeling Adversarial Learning as
Nested Stackelberg Games,” in Proceedings, Part II, of the 20th Paciﬁc-
Asia Conference on Advances in Knowledge Discovery and Data Mining
- Volume 9652. Springer-Verlag New York, Inc., 2016, pp. 350–362.

[43] “Microsoft Security Development Lifecycle.”
[44] T. Tulabandhula and C. Rudin, “Machine Learning with Operational
Costs,” Journal of Machine Learning Research, vol. 14, pp. 1989–2028,
2013.

[45] A. Spot, “Apache Spot,” 2017.

