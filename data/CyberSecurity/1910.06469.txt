9
1
0
2

t
c
O
5
1

]

R
C
.
s
c
[

1
v
9
6
4
6
0
.
0
1
9
1
:
v
i
X
r
a

Automated Ransomware Behavior Analysis:
Pattern Extraction and Early Detection (cid:63)

Qian Chen1, Sheikh Rabiul Islam2, Henry Haswell1, Robert A. Bridges3

1 Electrical and Computer Engineering Department, University of Texas at San
Antonio, San Antonio TX
guenevereqian.chen@utsa.edu, henry.haswell@my.utsa.edu
2 Computer Science Department, Tennessee Technological University, Cookeville, TN
sislam42@students.tntech.edu
3 Computational Sciences & Engineering Division, Oak Ridge National Laboratory,
Oak Ridge, TN, bridgesra@ornl.gov

Abstract. Security operation centers (SOCs) typically use a variety of
tools to collect large volumes of host logs for detection and forensic of
intrusions. Our experience, supported by recent user studies on SOC
operators, indicates that operators spend ample time (e.g., hundreds of
man hours) on investigations into logs seeking adversarial actions. Sim-
ilarly, reconﬁguration of tools to adapt detectors for future similar at-
tacks is commonplace upon gaining novel insights (e.g., through internal
investigation or shared indicators). This paper presents an automated
malware pattern-extraction and early detection tool, testing three ma-
chine learning approaches: TF-IDF (term frequencyinverse document
frequency), Fisher’s LDA (linear discriminant analysis) and ET (extra
trees/extremely randomized trees) that can (1) analyze freshly discovered
malware samples in sandboxes and generate dynamic analysis reports
(host logs); (2) automatically extract the sequence of events induced
by malware given a large volume of ambient (un-attacked) host logs,
and the relatively few logs from hosts that are infected with potentially
polymorphic malware; (3) rank the most discriminating features (unique
patterns) of malware and from the behavior learned detect malicious ac-
tivity, and (4) allows operators to visualize the discriminating features
and their correlations to facilitate malware forensic eﬀorts. To validate
the accuracy and eﬃciency of our tool, we design three experiments and
test seven ransomware attacks (i.e., WannaCry, DBGer, Cerber, Defray,
GandCrab, Locky, and nRansom). The experimental results show that
TF-IDF is the best of the three methods to identify discriminating fea-
tures, and ET is the most time-eﬃcient and robust approach.

(cid:63)

This manuscript has been authored by UT-Battelle, LLC, under contract DE-AC05-00OR22725
with the US Department of Energy (DOE). The US government retains and the publisher, by
accepting the article for publication, acknowledges that the US government retains a nonexclu-
sive, paid-up, irrevocable, worldwide license to publish or reproduce the published form of this
manuscript, or allow others to do so, for US government purposes. DOE will provide public access
to these results of federally sponsored research in accordance with the DOE Public Access Plan
(http://energy.gov/downloads/doe-public-access-plan)..

 
 
 
 
 
 
1

Introduction

Ransomware, a class of self-propagating malware, uses encryption to hold vic-
tim’s data and has experienced a 750% increase in frequency in 2018 [1]. Re-
cently, the majority of these ransomware attacks target local governments and
small business [2]. For example, the 2018 SamSam ransomware hit the city of
Atlanta, encrypted at least one third of users’ applications, disrupted the city’s
vital services [3], and resulted in $17M of remediation to rebuild its computer net-
work [4]. Unlike large multinational businesses, small cities and businesses usu-
ally face stricter ﬁnancial constraints than larger enterprises and struggle to es-
tablish or keep pace with cyber defensive technology and adversary/malware ad-
vancements. Consequently, they are less capable to defend against cyber threats.
More generally, SOC’s resource constraints and the shortage of cybersecurity tal-
ent [5–7] motivate us to develop an automated tools for SOCs.

Currently, manual investigation of logs is commonplace in SOCs and ex-
tremely tedious. E.g., our interaction with SOC operators revealed a 160 man-
hour forensic eﬀort to manually analyze a few CryptoWall 3.0 infected hosts’
logs [8] with the goal of (a) identifying the adversary/malware actions from user
actions in their logs and (b) leveraging learned information to reconﬁgure tools
for timely detection. This motivates our target use case—from SOC-collected
logs from an attacked host (esp. a ransomware infection) and non-attack host
logs, we seek to automated the (currently manual) process of identifying the
attack’s actions. In the ransomware case, this should be used to provides a pre-
encryption ransomware detector. For testing in a controlled environment, we use
“artiﬁcial logs”, that is, logs obtained by running malware and ambient (emu-
lated user) activities in a sandbox.

Note that this mirrors classical dynamic analysis—(a) performing dynamic
malware analysis to (b) extract indicators or signatures—and, hence, dynamic
analysis is a second use case. Malware analysis takes considerable time and
requires an individual or a team with extensive domain knowledge or reverse
engineering expertise. Therefore, malware analysts usually collaborate across
industry, university and government to analyze the ransomware attacks that
caused disruptive global attacks (e.g., WannaCry). However, the security com-
munity has insuﬃcient resources to manually analyze less destructive attacks
such as Defray, nRansom and certain versions of Gandcrab. Therefore, manual
analysis reports of such malware do not provide enough information for early
detection [9–16]. Our approach, regardless of the malware’s real-world impacts
and potential damages, eﬃciently help to automate tedious manual analysis by
accurately extracting the most discriminating features from large amount of host
logs and identifying malicious behavior induced by malware.

While our approach holds promise for more general malware and other at-
tacks, we focus on ransomware. Note that upon the ﬁrst infection identiﬁed in
an enterprise, the logs from the aﬀected host can be automatically turned into
a detector via our tool. The tool applies three machine learning algorithms, (1)
Term Frequency-Inverse Document Frequency (TF-IDF ), (2) Fisher’s Linear
Discriminant Analysis (Fisher’s LDA) and (3) Extra Trees/Extremely Random-

2

ized Trees (ET ) to (a) automatically identify discriminating features of an attack
from system logs (generated by an automatic analysis system, namely, Cuckoo
Sandbox [17]), and (b) detect future attacks from the same log streams. Using
Cuckoo and set scripts for running ransomware and emulated user activity pro-
vides source data for experimentation with ground truth. We test the tool using
infected system logs of seven disruptive ransomware attacks (i.e., WannaCry,
DBGer, Cerber, Defray, GandCrab, Locky, and nRansom) and non-attack logs
from emulated user activities, and present experiments varying log quality and
quantity to test robustness. These system logs include ﬁles, folders, memory,
network traﬃc, processes and API call activities.
Contributions of the pattern-extraction and early detection tool are

1. analyzing ransomware (esp. initial infection) using Cuckoo Sandbox logs
(more generally, ambient collected host logs) and generating features from
the host behavior reports.

2. extracting the sequence of events (features) induced by ransomware given
logs from (a few) hosts that are infected and (a potentially large amount of)
ambient logs from presumably uninfected hosts;

3. ranking the most discriminating features (unique patterns) of malware and
identifying malicious activity before data is encrypted by the ransomware.
4. creating graph visualizations of ET models to facilitate malware forensic
eﬀorts, and allowing operators to visualize discriminating features and their
correlations.

We compare outputs with ransomware intelligence reports, and validate that
our tool is robust to variations of input data. TF-IDF is the best method to
identify discriminating features, and ET is the most time-eﬃcient approach that
achieves an average of 98% accuracy rate to detect the seven ransomware. This
work builds on preliminary results of our workshop paper [8], which only consid-
ered feature extraction, only used TF-IDF, and only tested with one ransomware.

2 Background and Related Work

Ransomware. In contrast to the 2017 ransomware WannaCry that infected
300K machines across the globe, the majority of ransomware attacks in 2018
and 2019 have been targeting small businesses. These crypto-ransomware attacks
usually use Windows API function calls to read, encrypt and delete ﬁles. Ransom
messages are displayed on the screen after the ransomware infecting the host.
This paper selects and analyzes seven recently disruptive ransomware attacks.

1. WannaCry (2017), a ransomware with historic world-wide eﬀect, was
launched on May 12, 2017 [18]. The WannaCry dropper is a self-contained pro-
gram consists of three components, an application encrypting and decrypting
data; an encryption key ﬁle; and a copy of Tor. WannaCry exploits vulner-
abilities in Windows Server Message Block (SMB) and propagates malicious
code to infect other vulnerable machines on connected networks.

2. DBGer (2018), a new variant of the Satan ransomware [19], scans the victim
local network for vulnerable computers with outdated SMB services. DBGer

3

incorporates a new open-source password-dumping utility, Mimikatz, to store
credential of vulnearble computers [20]. The dropped Satan ﬁle is then exe-
cuted to encrypt ﬁles of the infected computers with AES encryption algo-
rithm. A text ﬁle How to decrypt ﬁles.txt containing a note of demands from
the attackers is displayed on victim’s screen.

3. Defray (2017), a ransomware attack targets healthcare, education, man-
ufacturing and technology industries [16]. Defray propagates via phishing
emails with an attached Word document embedding an OLE package ob-
ject. Once the victim executes the OLE ﬁle, the Defray payload is dropped
in the %TMP% folder and disguises itself as an legitimate executable (e.g.,
taskmgr.exe or explorer.exe). Defray encrypts the ﬁle system but does not
change ﬁle names or extensions. Finally, it deletes volume shadow copies of
the encrypted ﬁles [15]. Defray developers encourage victims to contact them
and negotiate the payment to get the encrypted ﬁles back [14].

4. Locky (2016, 2017) has more than 15 variants. It ﬁrst appeared in Febru-
ary 2016 to infect Hollywood Presbyterian Medical Center in Los Angeles,
California. The ransomware attackers send millions of phishing emails con-
taining attachments of malicious code that can be activated via Microsoft
Word Macros [11]. Locky encrypts data using RSA-2048 and AES-128 cipher
that only the developers can decrypt data. In this research, we analyze the
malicious behavior of a new variant of Locky ransomware called Asasin, which
encrypts and renames the ﬁles with a .asasin extension.

5. Cerber (2016-2018) infected 150K Windows computers in July 2016 alone.
Several Cerber variants appeared in the following two years have gained
widespread distribution globally. Once the Cerber ransonware is deployed
in the victim computer, it drops and runs an executable copy with a random
name from the hidden folder created in %APPDATA%. The ransomware also
creates a link to the malware, changes two Windows Registry keys, and en-
crypts ﬁles and databases oﬄine with .cerber extensions [21, 22].

6. GandCrab (2018,2019), a Ransomware-as-a-Service (RaaS) attack has
rapidly spread across the globe since January, 2018. GandCrab RaaS online
portal was ﬁnally shut down in June, 2019. During these 15 months, Gand-
Crab creators regularly updated its code and sold the malicious code, facili-
tating attackers without the knowledge to write their own ransomware [23].
Attackers then distribute GandCrab ransomware through compromised web-
sites that are built with WordPress. The newer versions of GandCrab use
Salsa20 stream cipher to encrypt ﬁles oﬄine instead of applying RSA-2048
encryption technique connecting to the C2 server [24]. GandCrab scans logical
drives from A: to Z:, and encrypts ﬁles by appending a random Salsa20 key
and a random initialization vector (IV) (8 bytes) to the contents of the ﬁle.
The private key is encrypted in the registry using another Salsa20 key and
the IV is encrypted with an RSA public key embedded in the malware. This
new encryption method makes GandCrab a very strong ransomware, and the
encrypted ﬁles can be decrypted by GandCrab creators only [25].

7. nRansom (2017) blocks the access to the infected computer rather than en-
crypting victim’s data [13]. It demands ten nude photos of the victim instead

4

of digital currency to unlock the computer. As recovery from nRansom is
relatively easy, it is not a sophisticated malware but a ”test” or a ”joke”.

Ransomware Pattern Extraction and Detection Works. Homayoun et
al. [26] apply sequential pattern mining to ﬁnd maximal frequency patterns
(MSP) of malicious activities of four ransomware attacks. Unlike generating
behavioral features directly from host logs, their approach summarizes activity
using types of MSPs. Using four machine learning classiﬁers, the team found
that atomic Registry MSPs are the most important sequence of events to detect
ransomware attacks with 99% accuracy.

Verma et al. [27] embed host logs into a semantically meaningful metric space.
The representation is used to build behavioral signatures of ransomware from
host logs exhibiting pre-encryption detection, among other interesting use cases.
Morato et al. introduces REDFISH [28], a ransomware detection algorithm
that identiﬁes ransomware actions when it tries to encrypt shared ﬁles. RED-
FISH is based on the analysis of passively monitored SMB traﬃc, and uses three
parameters of traﬃc statistics to detect malicious activity. The authors use 19
diﬀerent ransomware families to test REDFISH, which can detect malicious ac-
tivity in less than 20 seconds. REDFISH achieves a high detection rate but
cannot detect ransomware before it starts to encrypt data. Our approach, dis-
covering ransomware’s pre-encryption footprint, promises a more accurate and
in-time detection.

The Related Work section our preliminary work [8] includes works published
previously to those above. As the more general topic of dynamic analysis is large
and diverse, a comprehensive survey is out of scope, but many exist, e.g. [29].

3 Methodology

The proposed approach requires a set of normal (presumably uninfected) sys-
tem logs and at least one log stream containing ransomware behavior. In this
study, the seven ransomware executables introduced in Section 2 are deployed
inside a realistic but isolated environment with a sandbox tool, Cuckoo [17],
for harvesting reproducible and shareable host logs. The Cuckoo host logs are
dynamic analysis reports outlining behavior (i.e., API calls, ﬁles, registry keys,
mutexes), network traﬃc and dropped ﬁles Meanwhile, Cuckoo also captures
logs from scripted, emulated normal user activity such as reading and writing of
executables, deleting ﬁles, opening websites, watching YouTube videos, sending
and receiving emails, searching ﬂight tickets, and posting and deleting tweets on
Twitter (see [8]). The normal user and the ransomware events/behavior in the
raw host logs produced by Cuckoo are then converted to features, and the three
machine learning techniques are used to automatically obtain the most discrim-
inating features from normal and ransomware-including logs. Afterwards, we
discard the features that have little or no inﬂuence, and update the feature vec-
tor to reduce the search space of ET decision tree models. The decision tree
graphs are created to present the most discriminating features of ransomware
attacks. See ﬂowchart in Figure 1.

5

Fig. 1. Flowchart of Research Methodology

3.1 Feature Generation

To build features we only use the enhanced category and part of the behavior
category of Cuckoo-captured logging output. The details of the feature building
can be found in our previous work [8]. As malware often uses random names
to create ﬁles, modules and folders, in this study, we augment paths of speciﬁc
ﬁles to emphasize their names only. For example, C:\\Windows\\system32\
\rsaenh.dll is converted to a string “c:..rsaenh.dll”. Here, “..” is used as a
wild-card to avoid generating duplicated features that represent similar host
behavior.

3.2 Discriminating Feature Extraction with Machine Learning

TF-IDF, Fisher’s LDA and ET are algorithms used in this research to automat-
ically extract the most discriminating features of ransomware from host logs.

TF-IDF, was deﬁned to identify the relative importance of a word in a
particular document out of a collection of documents [30]. Our TF-IDF ap-
plication follow our previous work for accurate comparison. Given two sets of
documents let f (t, d) denote the frequency of term t in document d, and N the
size of the corpus. The TF-IDF weight is the product of the Term Frequency,
tf(t, d) = ft,d/ (cid:80)
t(cid:48)∈d ft(cid:48),d (giving the likelihood of t in d) and the Inverse Docu-
ment Frequency, idf(t, D) = log[N/(1 + |{d ∈ D : t ∈ d}|)] (giving the Shannon’s
information of the document containing t). Intuitively, given a document, those
terms that are uncommonly high frequency in that document are the only terms
receive high scores. We use log streams from infected hosts as one set of doc-
uments and a set of normal log streams as the other to apply TF-IDF; hence,

6

highly ranked features occur often in (and are guaranteed to occur at least once
in) the “infected” document, but infrequently anywhere else [8].

Fisher’s LDA is a supervised learning classiﬁcation algorithm that oper-
ates by projecting the input feature vectors to a line that (roughly speaking)
maximizes the separation between the two classes [31]. For our application we
consider a binary classiﬁcation where one class (C1) is comprised of the fea-
ture vectors {xi}i ⊆ Rm representing host logs that included ransomware, and
the second class (C2) are those vectors of ambient logs. We use this classiﬁer
for identifying the discriminating features between the classes. Consider the set
{vtxi : xi ∈ C1 ∪ C2} ⊂ R, which is the projection of all feature vectors to
a line in Rm deﬁned by unit vector v. Fisher’s LDA identiﬁes the unit vector
v that maximizes S(v) := [vt(µ1 − µ2)]2/[vt(Σ1 + Σ2)v] with µj, Σj the mean
and covariance of Cj, j = 1, 2, respectively. S(v) is the squared diﬀerence of the
projected classes’ means divided by the sum of the projected classes’ variances.
It is an exercise in linear algebra to see the optimal v ∝ (Σ1 + Σ2)−1(µ1 − µ2).
Geometrically, v can be thought of as a unit vector pointing from C1 to C2;
hence, ranking the components of v by absolute values sorts the features that
most discriminate the ransomware and normal activity.

Extremely Randomized Trees (ET) is a tree-based ensemble algorithm
for supervised classiﬁcation and regression. “It consists of randomizing strongly
both attribute and cut point choice while splitting the tree node” [32]. In the
extreme case, the algorithm provides “totally randomized trees whose structures
are independent of the output values of the learning sample” [32, 33]. The ran-
domization introduces increased bias and variance of individual trees. However,
the eﬀect on variance can be ignored when the results are averaged over a large
ensemble of trees. This approach is tolerant with respect to over-smoothed (bi-
ased) class probability estimates [32]. See the cited works for details.

4 Experimental Results

Experiment One: Extracting Discriminating Features from Host Logs.
This experiment applies the machine learning approaches to extract the most
discriminating features/behavior of each ransomware attack. In addition to ob-
taining a Cuckoo analysis report (raw behavior log) for each ransomware sample,
Python scripts imitating various users normal activities (such as reading, writing
and deleting ﬁles, opening websites, etc.) are submitted to the Cuckoo sandbox
to generate a large volume of normal reports.

Table 1 illustrates the most discriminating features of the seven ransomware
attacks. The ﬁrst column of the table (#) lists the name of seven ransomware.
The second column (Pattern) presents the pre-encryption patterns (activities)
of each ransomware attack obtained from the detailed ransomware technical
(static) analysis produced by cybersecurity companies (e.g., FireEye [34]), secu-
rity help websites (e.g., Bleeping Computer [35,36]) and malware research teams
(e.g., The Cylance Threat Research [16]). The third column (Feature) presents
the features extracted from the host logs using the proposed approaches that
match the unique patterns of rasomware attacks. The last column (Rank ) lists
the TF-IDF, Fisher’s LDA and ET rankings of the features that represent the

7

Table 1. The Most Discriminating Features of the Seven Ransomware Attacks

Pre-Encryption Pattern

Feature

#

y
r
C
a
n
n
a
W

.
1

.
3

y
k
c
o
L
.
4

r
e
b
r
e
C
.
5

b
a
r
c
d
n
a
G
.
6

e
r
a
w
m
o
s
n
a
R
n
.
7

1. Import CryptoAPI from advpi32.dll
2. Unzips itself to .wrny ﬁles

3.

4.

5.

6.

Creates a registry, HKEY_LOCAL_MACHINE\
Software\WanaCrypt0r\wd
Run ‘attrib +h’, to set the current directory
as a hidden folder
Run ‘icacls . /grant Everyone:F /T /C /Q’ to
grant user permissions to the current directory
Import public and private RSA AES
keys (000.pky, 000.eky) from t.wrny

r 1. Drop ExternalBlue ﬁles at
e
G
B
D

‘C:\Users\All Users\’

.
2

2. Drop satan.exe on C drive
and execute the ﬁle for encryption
3. Drop “KSession” ﬁle at %Temp%

y 1. Import/Load Microsoft OLE from “ole32.dll”
a
r
f
e
D

2. Drop and execute “explorer.exe”
3. Call ShellExecute to run as more privileged
user to disable startup recovery and delete
volume shadow copies
1. Read and write ‘PIPE\\wkssvc’ and
‘PIPE\lsarpc’

2. Read network provider name

3. Read the path to the network provider .dll ﬁle

4. Load the network provider ‘ntlanman.dll” ﬁle

5. Obtain the name of the Security Identiﬁer

1. Create two .tmp ﬁles under a random folder
in %APPData%

2. Find users proﬁles and read the proﬁles

3. Read and load “rsaenh.dll”

4. Obtain Machine GUID from registry

1. Scan and collect information
a. computer name
b. session manager name
c. domain name
d. processor type

2. Copy the ransomware .exe ﬁle
to %APPDATA%/Microsoft
and add an entry to RunOnce key

1. Create temprary directory in \%TEMP%\1.tmp\
tools\
2. Download and write following ﬁles:
a. an executable (i.e., nransom.exe)
b. a media control ﬁle (i.e.,interop.wmplib.dll)
c. a audio ﬁle (i.e., your-mom-gay.mp3)
3. Execute the executable (i.e., nransom.exe) using
command prompt (i.e.,cmd.exe) that lock the screen
4. Play the looped song using the downloaded
audio ﬁle (i.e., your-mom-gay.mp3)
5. Delete the temporary folders with
the downloaded ﬁles

data ﬁle+‘advapi32.dll’+event+‘load’+object+‘library’
*.wnry
api+‘regcreatekeyexw’+arguments 1 value+‘33554432’
+category+‘registry’ (subkey=“Software\\WanaCrypt0r”)

data ﬁle+‘attrib +h .’+event+‘execute’+object+‘ﬁle’

data ﬁle+‘icacls . ..q’+event+‘execute’+object+‘ﬁle’

data ﬁle+‘c:..00000000.pky’+event+‘write’+object+‘ﬁle’

data ﬁle+‘c:..users’+event+‘create’+object+‘dir’,
data ﬁle+‘c:..allusers’+event+‘create’+object+‘dir’,
data ﬁle+‘c:..blue.exe’+event+‘write’+object+‘ﬁle’,
... 22 various dropped ﬁle features...
data ﬁle+‘c:.. satan.exe +event+‘write’+object+‘ﬁle’,
data ﬁle+‘c:..mmkt.exe +event+‘write’+object+‘ﬁle’
data ﬁle+‘c:..satan.exe’+event+‘write’+object+‘ﬁle’,
data ﬁle+‘c:..satan.exe’+event+‘execute’+object+‘ﬁle’
data ﬁle+‘c:..ksession’+event+‘write’+object+‘ﬁle’
data ﬁle+‘ole32.dll’+event+‘load’+object+‘library’
data ﬁle+‘explorer.exe’+event+‘load’+object+‘library’

data ﬁle+‘c:..-hibernate-timeout-dc0’+event+‘execute’
+object+‘ﬁle’

data ﬁle+‘pipe..wkssvc’+event+‘write’(‘read’)+object+‘ﬁle’,
data ﬁle+‘pipe..lsarpc’+event+‘write’ (‘read’)+object+‘ﬁle’
data regkey+‘hkey local machine..
networkprovidername’+event+‘read’+object+‘registry’
data regkey+‘hkey local machine..
systworkproviderproviderpath’+event+‘read’+object+‘registry’
data ﬁle+‘c:..ntlanman.dll’+event+‘load’+object+‘library’
data regkey+‘hkey users..s-1-5-21-1966058-1343024091
-1003name’+event+‘read’+object+‘registry’
a. data ﬁle+‘c:..b51826f3’+event+‘create’+object+‘dir’
b. data ﬁle+‘c:..4e89.tmp’+event+‘write’+object+‘ﬁle’
c. data ﬁle+‘c:..5572.tmp’+event+‘write’+object+‘ﬁle’
a.data regkey+‘hkey local machine..
softilelistproﬁlesdirectory’+event+‘read’+object+‘registry’
b.data regkey+‘hkey local machine..
softlelistdefaultuserproﬁle’+event+‘read’+object+‘registry’
c. data regkey+‘hkey local machine..
softs-1-5-18proﬁleimagepath’ +event+‘read’+object+‘registry’
...omit SID 1-5-19∼1-5-20...
d. data regkey+‘hkey local machine..
soft091-1003proﬁleimagepath +event+’read’+object+‘registry’
a. data regkey+‘hkey local machine..
softaphic providerimage path’+event+‘read’+object+‘registry’
b. data ﬁle+‘c:..rsaenh.dll’+event+‘read’+object+‘ﬁle’
c. data ﬁle+‘c:..rsaenh.dll’+event+‘load’+object+‘ﬁle’
data regkey+‘hkey local machine..
cryptographymachineguid’+event+‘read’+object+‘registry’
a.data regkey+‘hkey local machine..systcomputername
computername’+event+‘read’+object+‘registry’
b.data regkey+‘hkey local machine..sessionmanagername’
+event+‘read’+object+‘registry’
c. data regkey+‘hkey local machine..parametersdomain’
+event+‘read’+object+‘registry’
d.1 data regkey+‘hkey local machine..0processornamestring’
+event+‘read’+object+‘registry’
d.2 data regkey+‘hkey local machine..0identiﬁer’
+event+‘read’+object+‘registry’
d.3 data regkey+‘hkey local machine..
systgersafeprocesssearchmode’+event+‘read’+object+‘registry’
a. data ﬁle+‘c:..lrcjty.exe’+event+‘write’+object+‘ﬁle’
b. data content+‘..x00’+data object+‘none’+data regkey+
‘hkey current user..runonceoopmhnlocoz’
+event+‘write’+object+‘registry’

data ﬁle+‘c:..tools’+event+‘create’+object+‘dir’

a.data ﬁle+‘c:..nransom.exe’+event+‘write’ +object+‘ﬁle’
b.data ﬁle+‘c:..interop.wmplib.dll’+event+‘write’ +object+‘ﬁle’
c.data ﬁle+‘c:..your-mom-gay.mp3’+event+‘write’ +object+‘ﬁle’

a. data ﬁle+‘nransom.exe’+event+‘execute’ +object+‘ﬁle’
b. data ﬁle+‘c:..cmd’+event+‘execute’ +object+‘ﬁle’
data ﬁle+‘c:..your-mom-gay.mp3’+event+‘read’
+object+‘ﬁle’
data ﬁle+‘c:..1.tmp’+event+‘delete’ +object+‘dir’
+object+‘ﬁle’

8

Rank
TF-IDF LDA ET
6
1

294
176

3
1

6

6

6

6

9

9

9
9
17

17

2
7

3

4

4

5

10

a.5
b.5
c.7
d.7

177 NA

298

11

298

11

298

11

125

11,
12

125

11,
12
11
9

125
10
93 NA

121 NA

72
408

186

171

130

408

2
7

3

4

4

5

a.105
b.230
c.230

a.10
b.10
c.11

a.111
b.111
c.150
d.150

a.5
b.5
c.7
d.7

a.3
b.1
c.6

a.79
b.15
c.119

a.3
b.1
c.6

2

69

2

a.1
b.6
c.7
d.7

a.276
b.430
c.431
d.431

a.1
b.8
c.10
d.9

7

5

a.4
b.4
c.4

a.6
b.6

5

6

431

a. 9
b.10

32

5

a.23
b.23
c.23

a.60
b.60

32

60

a.4
b.4
c.4

a.7
b.6

5

6

unique patterns of the seven ransomware attacks. The features that have the
largest TF-IDF and Fisher’s LDA scores, or the non-leaf nodes (features) of the
Extremely Randomized Trees that have smallest levels, are top-ranked discrim-
inating features. For the ET algorithm, the features that are at the top of the
tree contribute more to correctly classifying a larger portion of input logs. E.g.,
a feature with rank = 1 is one of the most indicative feature of the malware
according to that algorithm. Ties are possible as the scores may be the same
between multiple features. We use the rankings of these features to evaluate
the eﬃciency of the proposed three machine learning methods. The methods
that provide higher rankings of the selected features are more eﬃcient than the
approaches that yield a lower rank of the same feature.

We set a large class weight parameter for the target class in ExtraTreesClas-
siﬁer of Python’s Scikit-Learn library to make the ET classiﬁer biased to learn
the pattern of malicious logs more meticulously. Therefore, some features repre-
senting the ransomware patterns are not selected as the nodes to compose the
tree. In this scenario, we use “NA” to present the rankings of the feature that
are not nodes in the tree. Details are elaborated by ransomware:
1. WannaCry: The six patterns of WannaCry before the attack encrypting data
are presented in Table 1. All of these patterns can ﬁnd WannaCry-generated
features from the host logs. A total of 1, 207 unique features have been ex-
tracted from host logs containing both normal and abnormal behavior, while
only a small portion are resulting from WannaCry actions. The experimental
results indicate that TF-IDF is better than the other two methods for iden-
tifying WannaCry’s behaviors. The rankings generated by the ET classiﬁer
are slightly lower than the TF-IDF’s. However, ET is more time eﬃcient for
extracting the most discriminating features from large volume of host logs,
which requires only 215 features (nodes) to make decisions (i.e., WannaCry or
Normal). Therefore, the results suggest using TF-IDF to analyze the few in-
fected hosts logs in an attempt to produce shareable threat intelligence reports
and using the ET algorithm to obtain pre-encryption detection capabilities.
This experiment also illustrates that the top-ranked features generated by
Fisher’s LDA are quite diﬀerent from the other two techniques. Most of the
top-ranked features are normal activities. Features representing WannaCry’s
patterns are listed as low as #200. Additionally, we notice that the load-
ing and reading events of the rsaenh.dll module are ranked highly (i.e., #2
and #4 for TF-IDF and #3 and #8 for ET). The module implements the
Microsoft enhanced cryptographic service provider for WannaCry to encrypt
the victim’s data with 128-bit RSA encryption. These two top ranked features
are not listed in our table, as they are not discriminating features to identify
WannaCry attacks from other crypto-ransomware attacks.

2. DBGer: The three unique patterns of DBGer ransomware reported by [37]
are presented in Table 1. dbger.exe, the mother ﬁle of DBGer, ﬁrst creates
the C:\Users\AllUsers folder, drops EternalBlue and Mimikatz executables
in the new folder, and then saves satan.exe into the C drive. A ﬁle named
KSession is dropped to C:\Windows\Temp\ for storing the host ID. TF-IDF
and Fisher’s LDA rank 1, 104 features generated from normal and DBGer

9

Cuckoo reports. The ET classiﬁer builds the decision tree using 216 of the
1104 features. The three DBGer features are ranked highly. TF-IDF yields
a highest ranking of the three features, which is better than the other two
methods. ET is more time eﬃcient. However, there are many features ranked
higher than the ranking of the three features, but they are normal activity.
E.g., dynamic link library (DLL) ﬁles kernel32.dll and advapi.dll are on the
top of the three rankings, but are not discriminating features for DBGer.
3. Defray: The three unique patterns of Defray are loading the ole32.dll ﬁle,
dropping and executing the ransomware executable ﬁle explorer.exe, and exe-
cuting a shell command. The three machine algorithms rank the ﬁrst feature
“loading the ole32.dll ﬁle” #9 among the total 1, 243 features. As Defray’s
executable ﬁle is disguised as a Windows Internet Explorer, all of the three
methods struggle to distinguish it from the normal activities. The second fea-
ture therefore is not selected to build the ET model, and its TF-IDF and
Fisher’s LDA weights are much lower than the ﬁrst feature’s. The three ma-
chine learning approaches rank another three features (as shown in Table 2)
highest among the 1243 features. These features represent unique malicious
activities performed by Defray, thus, they are discriminating features to dis-
tinguish Defray from other ransomware. However, none of these three patterns
are discussed in Defray manual analysis reports [14–16].

4. Locky: We execute Asasin Locky, a 2017 variant of Locky ransomware in
the Cuckoo sandbox, collect and analyze its behavior using our tool. The
static analysis reports [9, 11] indicate that after being deployed, Locky’s ex-
ecutable ﬁle disappears. Its dropped copy svchost.exe is executed from the
%TEMP% folder. However, our tool generates features from the behavior
logs and presents that Asasin Locky does not drop the executable ﬁle. In-
stead, the attack modiﬁes the workstation services \PIPE\wkssvc launched
by the svchost.exe process. As a member of the Cryptowall family, Asasin
Locky also modiﬁes PIPE\lsarpc, a ﬁle communicates with the Local Secu-
rity Authority subsystem [38]. The attack then reads network provider name
and the path to the Network Provider DLL ﬁle from registry by loading the
network provider ntlanman.dll. Registry is retrieved by Asasin Locky to ob-
tain the name of the Security Identiﬁer. TF-IDF and ET provides the same
and higher rankings for these ﬁve features from a total 1, 047 normal and
ransomware features. These two methods both rank rsaenh.dll as the top
feature; however, this feature is not a unique pattern for Asasin Locky.

5. Cerber: This ransomware copies itself as cerber.exe to the hidden %APP-
DATA% folder, creates a directory with a random name, and drops two .tmp
ﬁles [10]. Cerber also escalates its privilege to admin level and reads proﬁles
from the users’ proﬁle image paths. Afterwards, Cerber ﬁnds the image path
of rsaenh.dll, reads and loads the DLL ﬁle to encrypt data. Cerber obtains
the Machine GUID (globally unique identiﬁer) and uses its fourth part as
the encrypted ﬁles’ extension. The Cerber sample tested has an extension of
93ﬀ. The three methods rank the total 1, 137 features. ET selects 145 features
to composes the decision tree. TF-IDF and ET provides similar and higher
rankings of the discriminating features than Fisher’s LDA’s.

10

6. GandCrab: This experiment uses Gandcrab V2.3.1, a variant that scans
the victim machine and collects information of user name, domain name,
computer name, session manager name and processor type [12]. The execu-
tion is terminated if the ransomware ﬁnds the system language is Russian
or the victim machine installed speciﬁc anti-virus (AV) software. Otherwise,
it copies the executable ﬁle into \%APPDATA\%/Microsoft and adds an entry
of the copied executable ﬁle path to the RunOnce key as a one-time persis-
tence mechanism. GandCrab then decrypts the ransom notes and generate
RSA keys for encryption. After encrypting data, the malware uses Windows’
NSLOOKUP tool to (1) ﬁnd IP address of the GandCrab’s C2 (command and
control) server; and (2) communicate with the C2 server (i.e., sending infor-
mation collected from the victims machines to the C2 server and/or receiving
commands from the C2 server). Table 1 presents two unique pre-encryption
patterns of GandCrab V2.3.1. TF-IDF and ET rank them highly among 1, 017
features. The rankings of these features are much lower by Fisher’s LDA.
7. nRansom: This attack ﬁrst creates a subfolder in %TEMP% with a ran-
dom name ended with .tmp. In our experiment, the subfolder is named
1.tmp. nRansom drops an executable ﬁle (i.e., nransom.exe) and two Win-
dows Media Player control library ﬁles (i.e., Interop.WMPLib.dll and AxIn-
terop.WMPLib.dll ) in 1.tmp. An audio ﬁle your-mom-gay.mp3 is dropped in
1.tmp\Tools. Then nransom.exe is executed through the command prompt
cmd.exe. After locking the victim’s computer screen, nRansom plays a looped
song from the dropped mp3 ﬁle, and deletes the subfolders and dropped ﬁles.
TF-IDF and ET both rank the ﬁve discriminating features of nRansom highly
among 1046 features. 55 features are used for composing ET.

Table 2. Static Analysis Missed Unique Patterns and Their Behavioral Features

Ransomware Unique Patterns Missed from Manual Analysis.
As discussed above, besides the patterns obtained from Defray’s threat intelli-
gence reports, the three features shown in Table 2 are also unique behavior to

11

distinguish Defray attacks. From the dynamic analysis provided by our method-
ology, we also found that many ransomware attacks have similar patterns. For
example, Defray, Locky and Cerber all conduct an event to load the ole32.dll
ﬁle. However, neither Locky nor Cerber’s static analysis have mentioned this
pattern. Similarly, manual analysis of GandCrab does not discuss the malware
sample has imported CryptoAPI from advapi32.dll, which is also a discrimi-
nating feature of WannaCry attacks. Thus, our tool provides automated—more
eﬃcient and without reliance on security experts—and better quality malware
behavior analysis.
Experiment Two: Ransomware Feature Rankings with Varying Nor-
mal Activities. This experiment aims to validate that the rankings of the seven
ransomware discriminating features are not inﬂuenced by varying the number of
normal logs. To validate the hypothesis, we calculate the TF-IDF, Fisher’s LDA
and ET weights of the ransomware features in the following three scenarios.

– Case 1 (C1): Using Experiment One’s normal logs as the baseline.
– Case 2 (C2): Adding 30% additional new normal host logs into training data.
– Case 3 (C3): Adding 60% more new normal host logs into training data.

Table 3. WannaCry Discriminating Feature Ranking with Varying Normal Data

Table 3 presents the top ten features of WannaCry that are calculated by the
three machine learning methods when the ambient logging data are diﬀerent.
The experimental results present that the ET method is robust to provide the
same rankings of the top ten features under the three tested scenarios. TF-IDF
is less robust than ET, but Fisher’s LDA provides completely diﬀerent rankings
of the top ten features in three diﬀerent scenarios. Similar results were found
when analyzing the top-ranked features of the other six ransomware attacks.

12

Fig. 2. Decision path based on the training logs showing how the most discriminating
features are correlated in the decision making process.

Therefore, the ET algorithm is more robust to varying training data containing
diﬀerent quality and quantity of normal activity.

Experiment Three: Ransomware Early Detection. The ET decision tree
classiﬁer is applied to detect the seven ransomware before encryption from a
large majority of non-malicious activity. Table 4 presents the detection rate
of the seven ransomware attacks. Note that while recall varies, meaning the
method produces false negatives, precision is always perfect, meaning there are
no false positives. In terms of overall performance metrics, the detection model
Gandcrab performs the best and DBGer performs the worst. We also create
graphs of each decision tree to better interpret and visualize the detection results.
Using WannaCry attack as an example, Figure 2 displays ﬁrst three levels of the
decision tree.

The brown non-leaf nodes (rectangular boxes) represent the features of nor-
mal activity and the blue non-leaf nodes represent features induced by Wan-
naCry. By retrieving the blue nodes on the top of the decision tree, we can iden-
tify WannaCry’s discriminating features. The correlation coeﬃcients of these
features are provided in non-leaf boxes. The graphs facilitate malware foren-
sics analysis and allow operators to visualize disruptive activity and determine
the damages induced by the malware for proposing an optimal protection and
response plan.

13

Table 4. ET Early Detection Results

Ransomware Accuracy Precision Recall F-Score
WannaCry
DBGer
Defray
Locky
Cerber

0.918
0.987
0.994
0.997
0.987
GandCrab 0.999
0.994
nRansom

0.835
0.471
0.996
0.893
0.671
0.999
0.553

0.717
0.308
0.992
0.806
0.505
0.997
0.382

1
1
1
1
1
1
1

5 Conclusion

We develop an automated ransomware pattern-extraction and early detection
tool that extracts the sequence of events induced by seven ransomware attacks,
identiﬁes the most discriminating features using three machine learning meth-
ods, and creates graphs to facilitate forensic eﬀorts by visualizing features and
their correlations. The experimental results present that TF-IDF feature rank-
ing yields the most accurate identiﬁcation of the ransomware-discriminating fea-
tures, while the ET method is the most time eﬃcient and robust to the variation
of inputs. Notable, discriminating features are automatically promoted by this
method that malware analysis reports failed to identify.

As the target application is using this to analyze real host logs collected by
SOCs, future research to test our tool using real-world host-based data captured
in enterprise networks to determine conditions for success. Moreover, large en-
terprises generate large volumes of host data. The oﬄine machine learning tech-
niques used in this paper—creating features from host logs, determining malware
discriminating features and detecting attacks—may not scale. Future research
using online machine learning technique (e.g., incremental decision tree) and
deep learning methods (e.g., LSTMs) can enhance the tool.

Acknowledgements

Special thanks to the reviewers that helped polish this document, including
Michael Iannacone. Research sponsored by the Laboratory Directed Research
and Development Program of Oak Ridge National Laboratory, managed by UT-
Battelle, LLC, for the U. S. Department of Energy, and by the National Science
Foundation under Grant No.1812599. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this material are those of the authors and do not
necessarily reﬂect the views of the National Science Foundation.

References

1. J. Davis, “71% of ransomware attacks targeted small businesses in 2018,” Mar.
https://healthitsecurity.com/news/71-of-ransomware-attacks-targeted-

2019,
small-businesses-in-2018.

2. B. Dobran, “Deﬁnitive guide for preventing and detecting ransomware,” 2019,

https://phoenixnap.com/blog/preventing-detecting-ransomware-attacks.

14

3. B. Freed, “One year after atlanta’s ransomware attack, the city says it’s trans-
forming its technology,” 2019, https://statescoop.com/one-year-after-atlantas-
ransomware-attack-the-city-says-its-transforming-its-technology/.

4. D. Olenick, “Atlanta ransomware recovery cost now at $17 million,

re-
ports say,” 2018, https://www.scmagazine.com/home/security-news/ransomware/
atlanta-ransomware-recovery-cost-now-at-17-million-reports-say/.

5. R. A. Bridges, M. D. Iannacone, J. R. Goodall, and J. M. Beaver, “How do in-
formation security workers use host data? a summary of interviews with security
analysts,” arXiv preprint 1812.02867, 2018.

6. J. Goodall, W. Lutters, and A. Komlodi, “The work of intrusion detection: re-
thinking the role of security analysts,” AMCIS 2004 Proceedings, p. 179, 2004.
7. R. Werlinger, K. Muldner, K. Hawkey, and K. Beznosov, “Preparation, detection,
and analysis: the diagnostic work of it security incident response,” Information
Management & Computer Security, vol. 18, no. 1, pp. 26–42, 2010.

8. Q. Chen and R. A. Bridges, “Automated behavioral analysis of malware: A case
study of wannacry ransomware,” in 2017 16th IEEE International Conference on
Machine Learning and Applications (ICMLA), Dec 2017, pp. 454–460.

9. M. LABS, “Look into locky ransomware,” 07 2016, https://blog.malwarebytes.

com/threat-analysis/2016/03/look-into-locky/.

10. W. Gao, “Dissecting cerber ransomware,” 07 2017, https://www.ixiacom.com/

company/blog/dissecting-cerber-ransomware.

11. J. Doevan, “Locky virus, how to remove,” 2018, https://www.2-spyware.com/

remove-locky-virus.html.

12. Cisco’s Talos Intelligence Group Blog: Gandcrab Ransomware Walks its Way
onto Compromised Sites, 2018 (accessed August 25, 2018). [Online]. Available:
https://blog.talosintelligence.com/2018/05/gandcrab-compromised-sites.html
13. This Ransomware Demands Nude instead of Bitcoin - Motherboard, 2017
(accessed August 24, 2018). [Online]. Available: https://motherboard.vice.com/
en us/article/yw3w47/this-ransomware-demands-nudes-instead-of-bitcoin

14. “Defray ransomware sets sights on healthcare and other industries,” 08 2017,
https://www.trendmicro.com/vinfo/us/security/news/cyber-attacks/defray-
ransomware-sets-sights-on-healthcare-and-other-industries.

15. J. Crowe, “Alert: Defray ransomware launching extremely personalized attacks,”
08 2017, https://blog.barkly.com/defray-ransomware-highly-targeted-campaigns.
16. Threat Spotlight: Defray Ransomeware Hits Healthcare and Education, 2017 (ac-
cessed August 16, 2018). [Online]. Available: https://threatvector.cylance.com/en
us/home/threat-spotlight-defray-ransomware-hits-healthcare-and-education.html
17. Cuckoo Sandbox - Automated Malware Analysis, accessed August 26, 2018.

[Online]. Available: https://cuckoosandbox.org/

18. N. Perlroth, “Boeing possibly hit by ’wannacry’ malware attack,” Mar 2018.
[Online]. Available: https://www.nytimes.com/2018/03/28/technology/boeing-
wannacry-malware.html

19. R. Lemos,

“Satan

ransomware

adds more

evil

tricks,” May

2019,

https://www.darkreading.com/vulnerabilities---threats/satan-ransomware-
adds-more-evil-tricks/d/d-id/1334779.

20. C. Cimpanu, “Dbger ransomware uses eternalblue and mimikatz to spread across
https://www.bleepingcomputer.com/news/security/dbger-

networks,”
ransomware-uses-eternalblue-and-mimikatz-to-spread-across-networks/.

2018,

21. B. Research, “Cerber ransomware: Everything you need to know,” 03 2017, https:

//blog.barkly.com/cerber-ransomware-statistics-2017.

15

22. M. LABS,

“Cerber

ransomware: new, but mature,”

06

2018, https:

//blog.malwarebytes.com/threat-analysis/2016/03/cerber-ransomware-new-
but-mature/.

23. R. Tiwari, “Evolution of gandcrab ransomware,” 04 2018, https://www.acronis.

com/en-us/articles/gandcrab/.

24. J. Salvio, “Gandcrab v4.0 analysis: New shell, same old menace,” 2018,
https://www.fortinet.com/blog/threat-research/gandcrab-v4-0-analysis--new-
shell--same-old-menace.html.

25. A. Mundo, “Gandcrab ransomware puts the pinch on victims,” 07 2018,

https://securingtomorrow.mcafee.com/mcafee-labs/gandcrab-ransomware-puts-
the-pinch-on-victims/.

26. S. Homayoun, A. Dehghantanha, M. Ahmadzadeh, S. Hashemi, and R. Khayami,
“Know abnormal, ﬁnd evil: Frequent pattern mining for ransomware threat hunting
and intelligence,” IEEE Transactions on Emerging Topics in Computing, 2019.
27. M. E. Verma and R. A. Bridges, “Deﬁning a metric space of host logs and opera-
tional use cases,” in 2018 IEEE International Conference on Big Data (Big Data),
Dec 2018, pp. 5068–5077.

28. D. Morato, E. Berrueta, E. Magaa, and M. Izal, “Ransomware early detection by
the analysis of ﬁle sharing traﬃc,” Journal of Network and Computer Applications,
vol. 124, pp. 14 – 32, 2018.

29. M. Egele et al., “A survey on automated dynamic malware-analysis techniques and

tools,” ACM computing surveys (CSUR), vol. 44, no. 2, p. 6, 2012.

30. G. Salton and C. Buckley, “Term-weighting approaches in automatic text re-
trieval,” Information processing & management, vol. 24, no. 5, pp. 513–523, 1988.
31. M. Welling, “Fisher linear discriminant analysis,” Department of Computer Sci-

ence, University of Toronto, vol. 3, no. 1, 2005.

32. P. Geurts, D. Ernst, and L. Wehenkel, “Extremely randomized trees,” Machine

learning, vol. 63, no. 1, pp. 3–42, 2006.

33. S. R. Islam, W. Eberle, and S. K. Ghafoor, “Credit default mining using combined
machine learning and heuristic approach,” in Proceedings of the 2018 International
Conference on Data Science (ICDATA). ACSE, 2018, pp. 16–22.

34. Wannacry Malware Proﬁle

10,
[Online]. Available: https://www.ﬁreeye.com/blog/threat-research/2017/

(accessed August

- FireEye,

2017

2018).
05/wannacry-malware-proﬁle.html
Ransomware

Uses

35. DBGer

2017

EternalBlue

(accessed August

Spread
Across Networks,
[Online]. Avail-
able: https://www.bleepingcomputer.com/news/security/dbger-ransomware-uses-
eternalblue-and-mimikatz-to-spread-across-networks/
to
the Asasin
(accessed August

Bro-
ken
[Online].
Available: https://www.bleepingcomputer.com/news/security/locky-ransomware-
switches-to-the-asasin-extension-via-broken-spam-campaigns/

and Mimikatz
2018).
10,

Extension
21,

Spam Campaign,

Switches
2017

2018).

via

to

36. Locky Ransomware

37. S. Munde, “Satan ransomware raises its head again!” 06 2018, https://blogs.

quickheal.com/satan-ransomware-raises-head/.

38. Monika, P. Zavarsky, and D. Lindskog, “Experimental analysis of ransomware on
windows and android platforms: Evolution and characterization,” Procedia Com-
puter Science, vol. 94, pp. 465 – 472, 2016.

16

