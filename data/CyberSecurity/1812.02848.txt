Cyber Anomaly Detection Using Graph-node Role-dynamics

Anthony Palladino
Boston Fusion Corp.
70 Westview Street, Suite 100
Lexington, Massachusetts 02421
anthony.palladino@bostonfusion.com

Christopher J. Thissen
Boston Fusion Corp.
70 Westview Street, Suite 100
Lexington, Massachusetts 02421
christopher.thissen@bostonfusion.com

ABSTRACT
Intrusion detection systems (IDSs) generate valuable knowledge
about network security, but an abundance of false alarms and a lack
of methods to capture the interdependence among alerts hampers
their utility for network defense. Here, we explore a graph-based
approach for fusing alerts generated by multiple IDSs (e.g., Snort,
OSSEC, and Bro). Our approach generates a weighted graph of alert
fields (not network topology) that makes explicit the connections
between multiple alerts, IDS systems, and other cyber artifacts. We
use this multi-modal graph to identify anomalous changes in the
alert patterns of a network. To detect the anomalies, we apply the
role-dynamics approach, which has successfully identified anom-
alies in social media, email, and IP communication graphs. In the
cyber domain, each node (alert field) in the fused IDS alert graph is
assigned a probability distribution across a small set of roles based
on that node’s features. A cyber attack should trigger IDS alerts
and cause changes in the node features, but rather than track every
feature for every alert-field node individually, roles provide a suc-
cinct, integrated summary of those feature changes. We measure
changes in each node’s probabilistic role assignment over time, and
identify anomalies as deviations from expected roles.

We test our approach using IDS alerts generated from a net-
work of 24 virtual machines (workstations, data and print servers,
DHCP and DNS servers), virtual switches, and a virtual server
that approximates connections to the internet. The simulation in-
cludes three weeks of normal background traffic, as well as cyber
attacks that occur near the end of the simulations. The network
includes installations of Snort and OSSEC, which generated alerts
throughout the experiment. A NetFlow sensor also captured the
network traffic during the simulation. This paper presents a novel
approach to multi-modal data fusion and a novel application of
role dynamics within the cyber-security domain. Our results show
a drastic decrease in the false-positive rate when considering our
anomaly indicator instead of the IDS alerts themselves, thereby
reducing alarm fatigue and providing a promising avenue for threat
intelligence in network defense.

9
1
0
2

n
a
J

6
1

]

R
C
.
s
c
[

2
v
8
4
8
2
0
.
2
1
8
1
:
v
i
X
r
a

Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of the United States
government. As such, the Government retains a nonexclusive, royalty-free right to
publish or reproduce this article, or to allow others to do so, for Government purposes
only.
DYNAMICS ’18, San Juan, Puerto Rico, USA
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
978-1-4503-6218-4/18/12. . . $15.00
DOI: 10.1145/3306195.3306198

CCS CONCEPTS
•Security and privacy → Intrusion/anomaly detection and
malware mitigation; •Computing methodologies → Machine
learning algorithms;

KEYWORDS
Anomaly detection, data fusion, unsupervised machine learning,
graph analysis, intrusion detection

ACM Reference format:
Anthony Palladino and Christopher J. Thissen. 2018. Cyber Anomaly Detec-
tion Using Graph-node Role-dynamics. In Proceedings of DYnamic and Novel
Advances in Machine Learning and Intelligent Cyber Security Workshop, San
Juan, Puerto Rico, USA, December 2018 (DYNAMICS ’18), 9 pages.
DOI: 10.1145/3306195.3306198

1 INTRODUCTION
Sophisticated modern cyber attackers, such as Advanced Persistent
Threats (APTs), pose a serious threat to critical cyber infrastructure.
The term APT generally refers to experienced cyber groups that
are directed and supported by governments, corporations, terror-
ist groups, or other entities motivated by political and economic
gain [11, 15, 22]. APTs have successfully infiltrated democratic
institutions [15], health insurance companies [15], and financial
institutions (e.g., Equifax [6, 17]). Specific goals differ and vary
over time; prior attacks have exfiltrated sensitive data (e.g., OPM
breach) and crippled physical infrastructure (e.g., Stuxnet). Lemay
et al. [15] provide an overview of recent APTs.

Defending against these advanced attacks has proven difficult.
APTs leverage social engineering, build advanced cyber-attack tools,
and exploit target-specific vulnerabilities [3, 4, 13–15, 20]. Some
APTs have altered tactics after their methods have been divulged or
countered [3, 4, 14, 15, 20]. Most prioritize stealth to maintain long-
term access and distribute attack steps over months or years [5] to
temporally separate indicators of compromise. These aspects make
each APT attack unique in most respects, and traditional signature-
based detection schemes are mostly ineffective for detecting them.
This is confirmed in [21], which found that in 86% of cases, evidence
about the data breach was recorded in the organization logs, but
the detection mechanisms failed to raise security alarms.

Detecting APTs in networks remains a top research priority [5].
Detection provides opportunities to: mobilize cyber defense; further
study state-of-the-art tactics, techniques, and procedures; attribute
an attack to a specific APT or supporting organization; and initiate
counter attacks. Although APT methods vary, previous work has
outlined abstract phases that characterize the sequence of events in
an attack. A widely used example is the intrusion kill chain [11]: (i)
reconnaissance, (ii) weaponization, (iii) delivery, (iv) exploitation,

 
 
 
 
 
 
DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

A. Palladino and C.J. Thissen

(v) installation, (vi) command and control, and (vii) actions on
objectives.

Regardless of the abstraction, attack steps during these phases
leave detectable artifacts. These artifacts, though incomplete, pro-
vide important information about APTs. Much of our knowledge
about APTs results from cyber forensic investigations of these arti-
facts (e.g., [15]). The success of cyber forensic analyses (e.g., [7, 13])
suggests that a sufficiently advanced system may be able to provide
early detection from these artifacts. A key challenge is developing
a method capable of correlating indicators of compromise (IOCs)
widely spread in time and modality.

We present a machine learning approach for detecting attacks
from cyber artifacts. Our approach uses unsupervised graph-based
anomaly detection [1]. Graphs easily fuse multi-modal data and
explicitly capture connections between artifacts that are otherwise
absent or only implicit in non-graph methods (e.g., [12]). Note
that the graph represents connections between artifacts, and not
network topology. Two hosts that frequently communicate may
not be directly connected in the graph, just as two hosts that never
communicate may be linked by artifacts.

Our unsupervised method learns the artifacts generated by nor-
mal network usage and flags anomalies in new data for further
inspection. It does not require labeled training data. We demon-
strate our graph-based anomaly detector by analyzing alert logs
generated by network and host intrusion detection systems (IDSs).
While APTs may use custom tools or zero-day exploits that circum-
vent IDSs, it is also not uncommon for APTs, in some phases, to
use more widely available malware that does trigger alerts from
IDSs [22]. A common problem with IDSs is alarm fatigue; attacks
may trigger IDS alerts, but so does normal network usage [12].
This allows an APT, even while generating IDS alerts, to remain
undetected in a network. Problematically, the same alerts may
be triggered by both normal usage and while under an attack, so
APT detection requires more than careful IDS tuning. Instead, the
challenge is to identify when a set of IDS alerts are triggered by
normal activity (false alarms) and when they are triggered by an
attack (true alarms).

We test our method using a virtual network that simulates both
normal usage and attacks characteristic of the Hurricane Panda and
Energetic Bear APTs [15]. Our experiments show that graph feature
anomalies are sensitive indicators of APT-like tactics, techniques,
and procedures and other types of cyber attacks.

2 CYBER ARTIFACT FUSION USING GRAPHS
Indications of a cyber attack are often split across modalities. A SQL
injection attack, for example, may trigger alerts from a network
IDS [2], while adding new admin users may trigger a different,
host-based IDS1. Rather than treat these alerts as independent, an
artifact graph explicitly captures the links between the alerts. In
this example, those links might include overlapping IP addresses if
both attacks involved the same machine.

IDS alerts are typically formatted as structured text where the
fields are populated by variables related to the triggering event
(Figure 1). We organize the fields as layers in the graph (e.g., an
IP address layer), with nodes that represent unique instances of

1https://ossec.github.io/

the variables (e.g., a specific IP address). Edges connect nodes that
appear in the same alert, incrementing in weight for each additional
co-occurrence. The pseudocode in Algorithm 1 summarizes our
multi-modal data fusion (graph building) algorithm.

Figure 1: Example of an artifact graph produced by fusing
one Snort alert and one OSSEC alert.

Every artifact type includes fields that vary in relevancy to de-
tecting cyber artifacts. Here we use a subset of alert fields that
provide orthogonal information. The classification message for a
Snort alert, for example, maps to a specific signature ID. As the mes-
sage can be reconstructed from the ID, the classification message
does not provide new information and is excluded. For Snort alerts,
we use the signature ID and the source and destination IP addresses.
For OSSEC alerts, we use the source IP address (when available)
and convert the hostname fields to their corresponding IP address.
We also include the rule ID and the log file that generated the alert.
A graph-based approach has several advantages for detecting

cyber attacks from artifacts:

• Context from alert interdependencies. IDSs generate many
different types of alerts (e.g., suspicious packets, failed
logins). Although they may indicate different activities,
alerts are not independent. For example, both alerts in
Figure 1 reference IP address 10.10.255.77. The graph struc-
ture explicitly links these alerts through their shared IP
address node. Each alert is thus considered in the context
of the other alerts in the network, which can help identify
anomalies in the alert data. An alert signaling a failed lo-
gin attempt, for example, may not itself be unusual. But a
failed login attempt accompanied by other linked alerts in
the graph may be significant.

• IDS fusion and efficient representation. The graph fuses to-
gether alerts generated by disparate IDSs. Figure 1, for
example, shows the fusion of alerts from a network IDS
(Snort) and a host IDS (OSSEC). Other IDSs that gener-
ate alerts with overlapping fields are straightforward to
include in the graph. By representing fields as nodes, we
can efficiently represent the alert structure. Each panel
in Figure 2 represents a time window with over 3,000
alerts in a single, compact graph with about 50 nodes and
200 weighted edges.

Cyber Anomaly Detection Using Graph-node Role-dynamics

DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

• Robust to circumvention. Akoglu et al. [1] argue that graph-
based detectors are especially difficult for adversaries to
circumvent. Due to the interconnected nature of the ar-
tifact graph, an adversary would need a global view of
the normal network operations (that is, the behavior of all
alerts) to evade the anomaly detector. As a result, graph-
based methods are widely used in fraud detection and may
prove especially difficult for cyber attackers to circumvent.

Algorithm 1: Build graph from IDS alerts
Input

:Alerts, a set of IDS alerts. Each alert ∈ Alerts is
parsed into key-value pairs, where each key maps to
a field in the alert (e.g., rule number) and the
corresponding value is the alert’s value for that field
(e.g., 215)

Output :G = {V , E, D}, undirected multilayer graph where V
are the vertices, E are the weighted edges, and D are
the layers. Edges are defined as (u, v, c, d, w) where
u, v ∈ V , c, d ∈ D such that c is the layer for u and d
is the layer for v. w is an integer weight for the edge.

(a) Normal

(b) Normal

(c) Attack

Figure 2: Comparison of artifact graphs during normal net-
work activity and when under attack.

3 GRAPH-NODE ROLES
Anomalies in the artifact graph are defined as unusual changes (over
time) in the graph features. Graphs contain many diverse features
(e.g., degree, page-rank) but the features that are most sensitive to a
cyber attack are not known in advance and may change over time.
Instead of manual selection, we automatically determine the salient
features and use machine learning to identify anomalies from this
expanded feature set (Figure 3).

3.1 Recursive Feature Extraction
We use recursive feature extraction (ReFex) [10] to automatically
generate feature vectors for every node in the artifact graph be-
cause it scales well and has proven successful in other applications
(e.g., [16]). These feature vectors form the matrix, Vnf
, where n
are the nodes and f are the features. Recursive features are cal-
culated over the node’s neighbors, such as the mean of neighbor
node degrees. Recursion continues until new recursive features are
approximately linearly dependent on prior features. Here, we use
both the sums and the means of neighbor node features.

The ReFex algorithm begins the recursive feature extraction with
a set of primary graph features for each node: (i) the number of
connected nodes (degree), (ii) the number of edges connecting its
neighbors (ego-network interconnectivity), and (iii) the number
of edges connecting its neighbors to other parts of the graph (ego-
network out-degree). In the IDS artifact graph, edges are weighted
by the number of alerts containing the connection, so we substitute
weighted degree for degree to increase sensitivity to alert frequency.
We also add transitivity as a fourth feature to quantify the connec-
tions between the node’s neighbors. For example, if an IP address
node is connected to both a rule node and a second IP address,
the node’s transitivity increases if the rule is also connected to the
second IP address node. This might occur, for example, if both IPs
were victim to the same intrusion attempt.

1 foreach alert ∈ Alerts do
2

foreach key, value ∈ alert do

if key (cid:60) D then

add key as new layer d ∈ D

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

end
if value (cid:60) V then

add value as new vertex v ∈ V

end

end
foreach key1, value1 ∈ alert do

foreach key2, value2 ∈ alert do

if key1 = key2 then
continue

else if (value1, value2, key1, key2, w) ∈ E then

w = w + 1

else

add edge (value1, value2, key1, key2, 1) as new
edge e ∈ E

end

end

end

20
21 end
22 return G = {V , E, D}

3.2 Dimensionality Reduction via Role

Extraction

Anomaly detection is difficult in the high-dimensional space created
by the expanded feature set. Rather than model every feature of
every node for anomalies, it is convenient to summarize and model a
reduced feature set. We use the role extraction algorithm (RolX [9])
for dimensionality reduction. RolX is an unsupervised, scalable
(linear in the number of graph edges) soft-clustering algorithm that
reduces the features to a small set of roles. In RolX, the node-feature
matrix is factorized as

Vnf (cid:39) Gnr Fr f ,

(1)

where Gnr is a node-role matrix in which each row quantifies the
membership of a node in each role, r , and Fr f
is a role-feature
matrix where each row defines a role in terms of the features. Non-
Negative Matrix Factorization ensures role membership and feature
importance are always positive [19], as negative values are difficult
to interpret.

DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

A. Palladino and C.J. Thissen

Figure 3: Recursive feature extraction followed by role ex-
traction. Alert-field nodes in the initial graph (upper-left)
are colored according to node type (signature ID, rule, IP ad-
dress, etc.). Nodes in the final graph (lower-left) are colored
according to the most probable role assignment.

3.3 Role Number Optimization
Evaluating (1) requires setting the number of roles: too few and
changes in the graph may not result in role changes (increasing false
negatives); too many and a node may fluctuate between two nearly
identical roles (increasing false positives). The optimal number of
nodes can be determined automatically [9] using the Minimum
Description Length criterion (MDL) [18].

The application of MDL is based on the insight that roles com-
press the node-feature matrix. Recall that the factorization in (1)
is approximate; as the number of roles increases, the factorization
accuracy increases but so does the model complexity. MDL balances
this trade-off between accuracy and complexity by minimizing the
description length L = M + E, where M is the model description
cost and E is the error cost. M is simply equal to Nb Nr (Nn + Nf )
where Nb
, and Nr , are
is the number of bits per value, and Nn , Nf
the numbers of nodes, features, and roles. Note that Nr (Nn + Nf )
is the total number of entries in Gnr and Fr f
. The error cost, E,
is calculated using the Kullback-Leibler divergence between the
node-feature matrix and the factorization,

E = Σi, j

(cid:0)Vi, j log (cid:0)Vi, j /(G (cid:48)F (cid:48))i, j

(cid:1) − Vi, j + (G (cid:48)F (cid:48))i, j

(cid:1) ,

(2)

Nb

where the primes indicate the matrices are encoded using Nb

bits.
and Nr are generally small integers, so a simple grid search
reveals the minimum L. Figure 4 shows the results from a graph
constructed from the first seven days of the Hurricane-Panda-like
APT scenario (described in Section 5.2). Each box in the grid is
colored according to the description length L for that pair of Nb
bits and Nr roles. The optimal number of roles for this graph is
three.

Figure 4: Optimization of the number of roles finds mini-
mum description length when using 3 bits and 3 roles.

periphery-nodes, clique-members), and are complementary to com-
munities [8]. Compact, feature-based descriptions are especially
helpful for understanding large graphs that cannot be easily visual-
ized.

Structural descriptions may be useful to investigate:

• the features that define a specific role (e.g., Role 3 is defined

by high betweenness values),

• why a node has been assigned a particular role (e.g., IP
address node 10.10.255.69 was assigned Role 2 because of
its high transitivity and eccentricity properties), or

• why a node has changed roles (e.g., rule node 20005 switched
from Role 1 to Role 3 during the latest time step due to a
large increase in betweenness).

Role descriptions are calculated by finding the non-negative ma-
trix, Er p , where each role, r , is described in terms of node properties,
p, (e.g., degree, betweenness, etc.) [9],

Gnr Er p = Mnp ,

(3)

where Mnp is a matrix of the properties for each node, and is calcu-
lated directly from the graph. The contribution of each property is
normalized relative to the other properties, and to its contribution
in the case of a single role, Er p /E (cid:48)
, where the prime indicates the
r p
matrix was calculated using a single role. Note that these properties,
p, are distinct from the recursive features, f , used in the role defini-
tions; properties are not recursive and are manually chosen to aid
comprehension. The role descriptions for the Hurricane-Panda-like
scenario are shown in Figure 5.

4 ANOMALY DETECTION – GRAPH-NODE

ROLE-DYNAMICS

3.4 Role Descriptions
A key advantage of RolX is interpretability; roles can be described
in terms of intuitive features such as degree, betweenness, or pager-
ank. The features reflect the structural behavior of the nodes (e.g.,

To identify anomalies, we divide the IDS alerts into a set of time
windows, t, and use a training period to define a fixed role-feature
matrix Fr f
. We bin the remaining IDS alerts into sequential time
windows, executing the following steps for each window:

Cyber Anomaly Detection Using Graph-node Role-dynamics

DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

5 TEST AND EVALUATION
5.1 Simulation
To evaluate the ability of our approach to identify anomalies in
IDS alerts, we use IDS alerts generated from a network of virtual
machines (Windows and Linux workstations, data servers, print
servers, and DNS servers), virtual switches, and a virtual server that
approximates connections to the internet (Figure 6). The network
includes installations of Snort and OSSEC which generated alerts
throughout the experiment.

Figure 5: Understanding the automatic role definitions us-
ing various graph properties. In our Hurricane-Panda-like
scenario (Section 5.2), alert-field nodes assigned to Role 1
have high degree and pagerank, nodes assigned to Role
2 have high transitivity, diversity, and eccentricity, while
nodes belonging to Role 3 have the highest betweenness.

Step 1: Collect and fuse artifacts to populate the artifact graph
for the current window. Step 2: Extract graph features to create a
node-feature matrix Vnf (t) (e.g., ReFex [10]). Step 3: Summarize
features using RolX [9], assigning each node a distribution over
the roles. Step 4: Calculate the role distribution for each node as
a function of time. Together, Steps 2–4 comprise role-dynamics
described in [19] and below. Step 5: Analyze the probabilistic role
assignments over time to identify anomalous changes in the roles.
Step 6: Investigate the anomaly cause.

To ensure that the role definitions are consistent across time
steps, we modify (1) to calculate role distributions using the fixed
role definitions, Fr f

,

Vnf (t)F −1

r f

(cid:39) Gnr (t)Fr f F −1

r f

= Gnr (t)

(4)

is initially defined during the training period but can be up-
Fr f
dated periodically to adapt role definitions to changes in normalcy
patterns.

Gnr (t) encodes a time-series for each node-role pair. There are
many ways to analyze time series data for anomalies; here we
analyze the average role change across all node-role pairs,

∆r (t) = ΣNn

n=1|Pn (t) − Pn (t − 1)|/Nn,

(5)

where Pn (t) is the maximum role membership probability for node
n in time window t. Nodes will not necessarily appear in every time
window, and Pn (t) is set to null until its first occurance. Once a node
appears, its previous probability of role membership fills forward
into new time bins where n (cid:60) V . For the scenarios here, setting
a constant threshold on ∆r (t) is sufficient to identify anomalies
corresponding to the start of the attacks.

Figure 6: The simulated network consists of 24 virtual ma-
chines (Windows and Linux workstations, as well as data,
print, and DNS servers), virtual switches, and a virtual server
approximating connections to the internet.

The simulations include three weeks of normal network oper-
ations, background traffic (packet flow), and IDS alerts, as well
as two distinct APT-like cyber attacks that occur near the end of
each simulation. We used the first week of the simulation (all prior
to the attack) to obtain the initial role definitions, Fr f
, and the
optimal number of roles. The remaining alerts are divided into
non-overlapping 8-hour windows, and the alerts in each window
populate an artifact graph. Gnr (t) is calculated using Steps 1–4 in
Section IV and ∆r is calculated using (5). Any values of ∆r above
the preset threshold are flagged as anomalous.

5.2 Simulated Attack 1
The first scenario is characteristic of Hurricane Panda, an APT
that targets infrastructure companies and is thought to be of Chi-
nese origin [15]. The simulation encompasses network operations
from from 9 Nov 2016 to 3 Dec 2016, with the first attack com-
mand being issued on 30 Nov at 8 PM (UTC), and the final attack
command occurring on 2 Dec at 10:03 PM (UTC). The attacker
in our simulation used database injection to steal authentication

pc1.secure.local10.10.255.62(Windows 7)LaptopIS2197.176.93.117192.172.226.123(CentOS 5)DNS ServerIS1161.165.201.20170.201.40.80(CentOS 5)IS3129.155.10.200213.251.138.21(CentOS 5)IS4200.200.200.204(CentOS 5)pc2.secure.local10.10.255.63(Windows 7)Workstationpc3.secure.local10.10.255.64(Windows 7)Laptoppc4.secure.local10.10.255.65(Windows 7)Workstationpc5.secure.local10.10.255.66(Windows 7)Workstationpc6.secure.local10.10.255.67(Windows 7)Workstationpc7.secure.local10.10.255.68(Windows 7)Laptopmetasploitable.localhost10.10.255.79(Debian 5.0.11)lariat.localhost10.10.255.51(Ubuntu 13.04)Lariatsrv2.secure.local10.10.255.80(Windows Server 2008 R2)SMB-CIFSsrv6.secure.local10.10.255.73(Windows Server 2008 R2)srv5.secure.local10.10.255.60(Windows Server 2008 R2)srv4.secure.local10.10.255.61(Windows Server 2008 R2)Localhost.localdomain10.10.255.77(Kali Linux)WIN-H7VH.secure.local10.10.255.50(Windows Server 2008 R2)Domain Controller / DNSsrv7.secure.local10.10.255.49(Windows Server 2008 R2)Domain Controller / DNSdhcp-server.secure.local10.10.255.10(Ubuntu 16.04 LTS)DHCPmail.secure.local10.10.255.22(Debian 7.11)postfixwww.secure.local10.10.255.71Apache web serverepiskopos.secure.local10.10.255.52(Ubuntu 16.04)Security OnionvSwitch0Port Group 1200vSwitch0Port Group 1210InternetWirelessAccess PointDYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

A. Palladino and C.J. Thissen

information and gain initial access to the network. After waiting
24 hours, the attacker used this access to steal additional authentica-
tion information for other users. Using the credentials stolen from
another user, the attacker moved laterally through the network,
installing post-exploitation tools (mimikatz2) on several windows
machines. Waiting another 24 hours, the attacker then used the
post-exploitation tools to disable the firewalls and task schedulers
for several windows machines on the network.

The entire set of 364,080 IDS alerts can be stored as 263 nodes
with 1625 weighted edges in our alert graph representation, illus-
trating the scalability of our approach. From these alert graphs,
ReFex identified 112 recursive features based on the weighted node
degree, ego-network interconnectivity, ego-network out-degree,
and transitivity features. The optimal number of roles is three (Fig-
ure 4). Role descriptions are shown in Figure 5. Figure 7 shows the
role membership over time for three typical alert-field nodes in the
graph; a log file node, an alert rule node, and an IP address node.

Using a manually-defined threshold of 0.05, our approach identi-
fies four anomalies in ∆r (t) (Figure 8). The first two are related to IP
address changes (10.10.255.40 appears on 15 Nov, and 10.10.255.49
appears on 18 Nov). The fourth correlates with the start of the at-
tack (the shaded attack region in Figure 8). Of the 364,080 IDS alerts
(Snort and OSSEC) produced by the simulation, only 316 are related
to the attack, yet our unsupervised machine learning approach
identified the start of the attack as anomalous. The anomalies also
appear when restricting the data to include only Snort or OSSEC
alerts, suggesting the approach may be robust to the specific IDSs
available on the network.

5.3 Simulated Attack 2
The second scenario is characteristic of Energetic Bear (a.k.a. Crouch-
ing Yeti, Dragonfly, or Havex), an APT that has targeted defense
and aviation companies in the U.S. and Canada, and energy firms
in Europe [15]. Artifacts in the code suggest Russian-speaking
authors, but the origin remains uncertain. In this simulated sce-
nario, the attacker used an email-based phishing attack to direct
a network user to a malicious webpage. While on the webpage,
that user’s browser downloaded an exploit that gave the attacker
access to the machine. Now able to access the network, the attacker
installed post-exploitation tools (mimikatz) to establish a persis-
tent foothold and steal authentication information of other users.
The attacker then moved laterally throughout the system, using a
remote desktop exploit to connect to other machines and create
new administrator users on those machines. Having established a
way to maintain access and control of these machines, the attacker
cleaned up logs and other traces of the attack.

This second scenario encompasses network operations from 1 Jan
2017 to 4 Feb 2017. The attack occurred on 31 Jan between 4:57 PM
(UTC) and 7:00 PM (UTC). OSSEC generated 702,241 IDS alerts
throughout this entire period, which can be represented as 90 nodes
and 475 weighted edges in our artifact graph representation. As
with the Hurricane Panda scenario, the first week of data was used
as a normalcy period to automatically determine the initial optimal
number of nodes, the recursive features, and the role definitions.

2https://www.offensive-security.com/metasploit-unleashed/mimikatz/

Figure 7: Probability of role membership for alert-field
nodes in the artifact graph corresponding to a log file node
(top), an OSSEC rule node (middle), and an IP address node
(bottom). The vertical dashed line indicates the start of Sim-
ulated Attack 1.

Using a manually-defined threshold of 0.1, we identified three
anomalies (Figure 9). We found the same three anomalies when
considering all alert-field nodes (Figure 9, top) and when restricting
the analysis to one layer, e.g., only “log file” nodes (Figure 9, middle).
The third anomaly coincides precisely with the simulated Energetic-
Bear-like attack campaign. This promising result suggests that this
formalism for anomaly detection may robustly identify anomalous
behavior from different types of attacks (e.g., Hurricane-Panda-like,
Energetic-Bear-like, etc.).

Cyber Anomaly Detection Using Graph-node Role-dynamics

DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

Figure 8: Anomaly detection using role dynamics in the
Hurricane-Panda-like attack simulation from fused Snort
and OSSEC alerts (top), only Snort alerts (middle), and only
OSSEC alerts (bottom). The shaded region on the right indi-
cates the simulated attack window.

Note that this attack-related anomaly does not correlate with
an unusual change in the number of alerts (Figure 9, bottom), as
the method is sensitive to alert interconnections (which affect the
nodes and edges of the alert graph), rather than simply alert vol-
ume (which affects the edge weights only). Contrast this with the
lack of an anomaly over the 0.1 threshold during the large spike
in alert volume near the middle of the dataset. Despite the large
increase in alert volume (perhaps comprising many identical alerts),
the alert graph does not change enough to cause anomalous role
dynamics. Our graph-based anomaly detector provides informa-
tion complementary to alert volume analyses; in this example the
attack/anomaly is much easier to find using role dynamics than
volume analyses alone.

Figure 9: Anomaly detection using role dynamics in the
Energetic-Bear-like attack simulation from OSSEC alerts
showing the incremental change in probabilistic role assign-
ment normalized over all 90 alert-field nodes in the artifact
graphs (top) and only considering the alert-field nodes in
the “log file” layer (middle). The vertical line to the right
indicates the time bin during which the simulated attack oc-
curred. Total number of IDS alerts throughout the simula-
tion (bottom).

6 DISCUSSION
With any model that learns normal behavior from real training
data, there is always some concern that the training data includes
an attack. Including the attack in the definition of normal prevents
identifying those attacks as anomalous, increasing false negatives.
This is a real risk, but there are some mitigating factors that are
useful to consider.

The first mitigating factor is the frequency of malicious activ-
ity. If the attacker has gained access to the network but is active
only infrequently to disperse any indicators of compromise, the

DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

A. Palladino and C.J. Thissen

probability of training on attack-related artifacts is small. If attack
components are included in the training data but are missing from
later time windows, this is also an anomaly that could be identified
by our method. Comparing results from multiple training periods
may also provide insight; large unexpected changes unrelated to
known network operations should be investigated.

The second mitigating factor is escalation. Artifacts from mali-
cious events included in the training data will likely not encompass
all phases of the cyber kill chain. Escalating the attack to new
phases should generate new cyber artifacts. As these new artifacts
are not included in the training data, they would be identified as
anomalous.

The third mitigating factor is the ability to detect changes in
the attack methods. Advanced attackers, such as APTs, build cus-
tom tools and frequently adapt their methods [15]. If some of the
methods are included in the training data, only those methods will
be learned as normal. New attacks not included in the training
data would be identified as anomalous. The ability to detect new,
previously unseen attack steps is an advantage of our unsupervised
approach.

Although the role-dynamics method includes an automatic method

for determining the optimal number of nodes, there remain several
hyperparameters that must be defined. These include which types
of cyber artifacts to use (e.g., IDS products), which artifact fields
(e.g., IDS alert fields) to populate the graph, the length of the train-
ing period, the time window size, and the anomaly threshold. In the
examples considered here, these choices were dictated by domain
knowledge about the IDS alerts and the limitations of the dataset.
As each network configuration differs, using detailed knowledge
about the network may be the best approach for determining the
hyperparameters. It may also be possible to optimize these hyper-
parameters to increase sensitivity to cyber attacks and decrease
sensitivity to benign anomalies using either known test cases, or
prior attacks on the network. We leave this for future work.

7 CONCLUSIONS
Graph-based anomaly detection is a promising new approach for
detecting cyber attacks from cyber artifacts. In both test scenarios,
our method identified anomalies corresponding to the start of the
attack. We fused data from several intrusion detection systems
into artifact graphs using a novel graph construction based on
fields in the triggered alerts, not the network topology. Analyzing
the role dynamics in these graphs for simulated Hurricane-Panda-
like and Energetic-Bear-like APT datasets, we identified a handful
of anomalies, including anomalies that coincide with the start of
each attack. Our approach successfully identified simulated attacks
through anomalies in IDS alert patterns, and reduced the number
of false-positive alerts from thousands to just three false-positive
anomalies (in one simulation) and two (in the other simulation).
Our results illustrate how graph-node role-dynamics analyses can
identify anomalies in IDS alerts, however causal analysis will re-
quire further investigation by human analysts.

ACKNOWLEDGMENTS
The authors would like to thank Dr. Angelos Keromytis for his
support and guidance throughout this research effort, and Dr. Ron

Watro for his helpful insights, recommendations, and direction.
The authors would also like to thank the anonymous referees for
their valuable comments. This research was supported by the De-
fense Advanced Research Projects Agency (DARPA) under Contract
No. W31P4Q-15-C-0069, and this paper has been approved with Dis-
tribution Statement “A” (Approved for Public Release, Distribution
Unlimited). The views, opinions, and/or findings contained in this
document are those of the authors and should not be interpreted
as representing the official policies, either expressed or implied, of
DARPA or the U.S. Government.

REFERENCES
[1] Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph Based Anomaly
Detection and Description: A Survey. Data Min. Knowl. Discov. 29, 3 (May 2015),
626–688. https://doi.org/10.1007/s10618-014-0365-y

[2] H. Alnabulsi, M. R. Islam, and Q. Mamun. 2014. Detecting SQL injection attacks
using SNORT IDS. In Asia-Pacific World Congress on Computer Science and Engi-
neering (APWC on CSE). 1–7. https://doi.org/10.1109/APWCCSE.2014.7053873
[3] Manos Antonakakis, Christopher Elisan, David Dagon, Gunter Ollmann, and
Erik Wu. 2010. The Command Structure of the Aurora Botnet. Research Report.
Damballa, Inc. http://www.damballa.com/research/aurora/

[4] Beth E. Binde, Russ McRee, and Terrence J. O’Connor. 2011. Assessing Outbound
Trafffic to Uncover Advanced Persistent Threat. Whitepaper. SANS Institute.
[5] E. Cole. 2012. Advanced Persistent Threat: Understanding the Danger and How to
Protect Your Organization. Elsevier Science. https://books.google.com/books?
id=w1 uugAACAAJ

[6] Eric Cole. 2017.
Sept. 2017).
equifax-advanced-persistent-threat-apt/

Equifax and the Advanced Persistent Threat.

(18
Retrieved March 5, 2018 from https://secure-anchor.com/

[7] DHS and FBI. 2016. GRIZZLY STEPPE – Russian Malicious Cyber Activity. Joint
Analysis Report (JAR-16-20296A). Department of Homeland Security (DHS) and
Federal Bureau of Investigation (FBI).

[8] Santo Fortunato. 2010. Community detection in graphs. Physics Reports 486, 3

(2010), 75 – 174. https://doi.org/10.1016/j.physrep.2009.11.002

[9] Keith Henderson, Brian Gallagher, Tina Eliassi-Rad, Hanghang Tong, Sugato
Basu, Leman Akoglu, Danai Koutra, Christos Faloutsos, and Lei Li. 2012. RolX:
structural role extraction & mining in large graphs. In KDD, Qiang Yang, Deepak
Agarwal, and Jian Pei (Eds.). ACM, 1231–1239. http://dblp.uni-trier.de/db/conf/
kdd/kdd2012.html#HendersonGETBAKFL12

[10] Keith Henderson, Brian Gallagher, Lei Li, Leman Akoglu, Tina Eliassi-Rad, Hang-
hang Tong, and Christos Faloutsos. 2011. It’s Who You Know: Graph Mining
Using Recursive Structural Features. In Proceedings of the 17th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining (KDD ’11).
ACM, New York, NY, USA, 663–671. https://doi.org/10.1145/2020408.2020512

[11] Eric M Hutchins, Michael J Cloppert, and Rohan M Amin. 2011. Intelligence-
driven computer network defense informed by analysis of adversary campaigns
and intrusion kill chains. Leading Issues in Information Warfare & Security
Research 1 (2011), 80.

[12] K. Julisch. 2001. Mining alarm clusters to improve alarm handling efficiency. In
Seventeenth Annual Computer Security Applications Conference (ACSAC). 12–21.
https://doi.org/10.1109/ACSAC.2001.991517

[13] George Khalil. 2015. An Overview to Forensic Enterprise Architecture Design.

SANS Institute InfoSec Reading Room (2015).

[14] Bryan Krekel, George Bakos, and Christopher Barnett. 2009. Capability of the
People’s Republic of China to Conduct Cyber Warfare and Computer Network
Exploitation. Research Report. The US–China Economic and Security Review
Commission, Washington, DC.

[15] Antoine Lemay, Joan Calvet, Franc¸ois Menet, and Jos´e M. Fernandez. 2018. Survey
of publicly available reports on advanced persistent threat actors. Computers &
Security 72 (2018), 26–59. https://doi.org/10.1016/j.cose.2017.08.005

[16] Marjan Momtazpour and Naren Ramakrishnan. 2015. Characterizing Taxi Flows
in New York City. In Proceedings of the ACM SIGKDD International Workshop on
Urban Computing (UrbComp).

[17] Lee Neubecker. 2018. Equifax Certificate Unravelling Security on Windows 10
OS. (2 March 2018). Retrieved March 5, 2018 from https://leeneubecker.com/
equifax-equimelt-vulnerability/
J. Rissanen. 1978. Paper: Modeling by Shortest Data Description. Automatica 14,
5 (Sept. 1978), 465–471. https://doi.org/10.1016/0005-1098(78)90005-5

[18]

[19] Ryan Rossi, Brian Gallagher, Jennifer Neville, and Keith Henderson. 2012. Role-
dynamics: Fast Mining of Large Dynamic Networks. In Proceedings of the 21st
International Conference on World Wide Web (WWW ’12 Companion). ACM, New
York, NY, USA, 997–1006. https://doi.org/10.1145/2187980.2188234

Cyber Anomaly Detection Using Graph-node Role-dynamics

DYNAMICS ’18, December 2018, San Juan, Puerto Rico, USA

[20] RSA. 2011. RSA Security Brief: Mobilizing Intelligent Security Operations for
http://www.emc.com/collateral/

(Feb. 2011).

Advanced Persistent Threats.
industry-overview/11313-apt-brf.pdf

[21] Verizon. 2010. 2010 Data Breach Investigations Report. (July 2010). Retrieved
Sep 14, 2018 from https://www.wired.com/images blogs/threatlevel/2010/07/

[22]

2010-Verizon-Data-Breach-Investigations-Report.pdf
J. Vukalovic and D. Delija. 2015. Advanced Persistent Threats - detection and
defense. In 38th International Convention on Information and Communication
Technology, Electronics and Microelectronics, MIPRO 2015, Opatija, Croatia, May
25-29, 2015. 1324–1330. https://doi.org/10.1109/MIPRO.2015.7160480

