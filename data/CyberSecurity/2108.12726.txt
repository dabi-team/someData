1
2
0
2

g
u
A
9
2

]

R
C
.
s
c
[

1
v
6
2
7
2
1
.
8
0
1
2
:
v
i
X
r
a

Characterizing Malicious URL Campaigns

Mahathir Almashor∗†
mahathir.almashor@data61.csiro.au

Ejaz Ahmed∗
ejaz.ahmed@data61.csiro.au

Benjamin Pick∗†
benjamin.pick@data61.csiro.au

Sharif Abuadbba∗†
sharif.abuadbba@data61.csiro.au

Raj Gaire∗†
raj.gaire@data61.csiro.au

Shuo Wang∗†
shuo.wang@data61.csiro.au

Seyit Camtepe∗†
seyit.camtepe@data61.csiro.au

Surya Nepal∗†
surya.nepal@data61.csiro.au

ABSTRACT
URLs are central to a myriad of cyber-security threats, from phish-
ing to the distribution of malware. Their inherent ease of use and fa-
miliarity is continuously abused by attackers to evade defences and
deceive end-users. Seemingly dissimilar URLs are being used in an
organized way to perform phishing attacks and distribute malware.
We refer to such behaviours as campaigns, with the hypothesis be-
ing that attacks are often coordinated to maximize success rates and
develop evasion tactics. The aim is to gain better insights into cam-
paigns, bolster our grasp of their characteristics, and thus aid the
community devise more robust solutions. To this end, we performed
extensive research and analysis into 311M records containing 77M
unique real-world URLs that were submitted to VirusTotal from
Dec 2019 to Jan 2020. From this dataset, 2.6M suspicious campaigns
were identified based on their attached metadata, of which 77,810
were doubly verified as malicious. Using the 38.1M records and
9.9M URLs within these malicious campaigns, we provide varied
insights such as their targeted victim brands as well as URL sizes
and heterogeneity. Some surprising findings were observed, such
as detection rates falling to just 13.27% for campaigns that employ
more than 100 unique URLs. The paper concludes with several case-
studies that illustrate the common malicious techniques employed
by attackers to imperil users and circumvent defences.

KEYWORDS
web security, malicious campaigns, threat intelligence

ACM Reference Format:
Mahathir Almashor, Ejaz Ahmed, Benjamin Pick, Sharif Abuadbba, Raj
Gaire, Shuo Wang, Seyit Camtepe, and Surya Nepal. 2021. Characterizing
Malicious URL Campaigns. In Proceedings of the Redacted Conference. ACM,
New York, NY, USA, 12 pages. https://doi.org/10.1145/1122445.1122456

∗Commonwealth Science and Industrial Research Organisation (CSIRO) Data61
†Cyber Security Cooperative Research Centre

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
Redacted Conference, December, 2021, Somewhere on Earth
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-70899. . . $15.00
https://doi.org/10.1145/1122445.1122456

1 INTRODUCTION
Regardless of their intent, malicious actors have relied on the hum-
ble Uniform Resource Locator (URL) as the penultimate step in their
pernicious operations. Littered throughout phishing emails, social
network spam, and suspicious web-sites, these otherwise common
text strings are crafted to mislead end-users [1, 2]. This results in
the divulging of sensitive personal and/or commercial information
via fake login pages [3], or the inadvertent download of malware
which compromise machines and allow unauthorized access [4].

A wide body of work exists on the urgent issue of harmful URLs,
from detection at the domain name level [5–7] to deep-learning
classification of entire URL strings [8, 9]. Yet, rarely have URLs been
used in an isolated fashion. Attackers incorporate them into multi-
stage compromise strategies, with reliance on waves of unique
URLs to maximise their eventual reach and evade cyber defences.
Witness the recent surge in attacks based on the COVID-19 pan-
demic [10] that used carefully crafted URLs and phishing emails to
deceive users. Criminal organisations often include popular brand
and domain names in their malicious URLs to better target their
intended victims (e.g., http://mail.get-apple[.]support). Such groups
of URLs are what we define as malicious campaigns.

The work herein shares the approach of prior campaign char-
acterization efforts, including phone-based robocalls [11], social
network spam [12] and domain names [13]. In [14], groups of web-
sites (including malicious ones) are clustered via advertising tokens
matched to the same owner. It is reported in [15] that a small per-
centage of operators were behind the most successful phishing
campaigns, and that threats can persist for up to 9 months by em-
ploying various evasion tactics. As for the URLs themselves, prior
focus has been on their general treatment as individual pieces.
We instead seek to identify and characterize clusters of seemingly
unique and disassociated URLs as a motivated whole and thus, gain
more pertinent insights into such concerted attacks.

This is exemplified in one of our key findings: Google Safe Brows-
ing1, the default block-list used in most web-browsers, is not able
to detect all unique URLs for 49.76% of 18,360 multi-URL malicious
campaigns we discovered. Considering the expectation that mal-
ware is often unleashed in waves, this indicates that a more refined
approach is warranted. The community needs insights into cam-
paigns of malicious URLs, so as to analyze and learn the evasion
and deception techniques that attackers exploit. This also throws

1https://safebrowsing.google.com/

 
 
 
 
 
 
Redacted Conference, December, 2021, Somewhere on Earth

Almashor et al.

open the possibility of timely detection of large-scale campaigns
and informs potential mitigation strategies that can be employed.
We begin by pre-processing and analysing 311,588,127 submis-
sions to the VirusTotal platform2. These represented individual
URL submissions from 2019-12-05 to 2020-01-31, with a total un-
compressed size of close to 2TB. To the best of our knowledge, no
prior work has attempted the analysis of a comprehensive dataset
of such size stretched across a prolonged 2 month period. The work
by Starov et al. in [14] examined only 145K URLs over a duration
of 2 weeks, while the raw work in [16] used 15M URLs but treated
the data as individual pieces for classification. Attempting work
on such large scale presented many challenges but proved vital, as
robust findings on the nature of malicious campaigns require high
confidence in the completeness of records over the duration of the
analysis. That is, the identification of campaigns and subsequent
results is weakened should gaps exist in the historical data.

Given this novel perspective and the access to a large dataset, our
research questions and contributions are summarised as follows:

RQ1 What patterns can we discern from submissions over
a prolonged period? Our contributions begin with Sec-
tion 3, where we deliver 10 key findings on the nature of
submissions. We detail how, when and by whom URLs are
submitted, delve into their general temporal characteristics
as well as high-level vendor performance.

RQ2 Can we cluster URLs into campaigns for subsequent
characterization? Section 4 details how we grouped seem-
ingly divergent URLs by simply using content hash metadata
available within submissions. We include 9 findings on the
identification, risk-factors, verification and the nature of
URLs within verified malicious campaigns. In-depth metrics
are also provided along dimensions such as campaign size,
domain names used and vendor detection rates.

RQ3 What attack methods can we see in campaigns? We
continue with a detailed presentation of several case-studies
in Section 5, which include investigations into targeted vic-
tim brands, payload types and fileless malware injected di-
rectly into the URL itself. The aim is to encapsulate the tactics
and methodology of attackers as seen within the dataset and
provide insights to the community as to the different types
of malicious URLs and strategies employed.

To conclude the paper, we review a campaign where a new mali-
cious URL could have been easily flagged by matching the content
hash of a known sibling. This is followed by a discussion on the
impact of the various findings presented, with further recommen-
dations that aim to dispel common misconceptions of campaigns.

2https://www.virustotal.com

2 BACKGROUND & RELATED WORK
Colloquially known as links, URLs are simply pointers to content
on the Internet [17]. Rather than downloading and re-distributing
an already online video, a person instead shares its URL with others.
This eases the sharing of data, with URLs present in social media
posts [18], websites, emails and phone messages [19]. This same
simplicity and ubiquity has led to abuse, with deceptive URLs that
ensnare users [20] (such as the second example in Table 1).

Breaking down a URL’s components, the scheme for most URLs
is http with increasing use of https. Attackers can use https to
lull end-users into a false sense of security [21]. Sub-domains are
entirely within the control of attackers, and is a favoured way to
trick end-users as to the legitimacy of malicious URLs [20]. Do-
mains are purchased from authorised registrars depending on the
suffix. For example, to purchase mysite.net.au, one must go thru
a commercial reseller appointed by Australia’s auDA [22]. The path
refers to the exact location of a page, file or other asset. They may
contain queries that provide additional information to the server
at the point of request, and includes any text after a “?” character.

2.1 VirusTotal Platform
Given the known scale of the issue even as far back as 2011 [23],
multitudes of suspicious URLs are therefore sent hourly to cyber-
security vendors such as PhishTank and Kaspersky. Each vendor
employs their own customised engine to classify and thus detect
malicious URLs, with varying levels of success [24].

Building atop of such services, the VirusTotal platform can be
thought of as an aggregator of results from a wide range of ven-
dors [25]. Essentially, it acts as a convenient front-end that allows
researchers to query the status of suspicious URLs across a variety
of scan engines available online. Figure 1 depicts this relationship
between users, security vendors and the VirusTotal platform.

While this offers much needed simplicity for the academic com-
munity, it must be noted that vendor labels do not always agree [26].
For example, a URL that has been flagged as malicious by one vendor
may not necessarily share the same fate with another. Nonetheless,
the platform has been extensively used by researchers to either
label existing data or collect datasets for training and evaluation of
algorithms. While past focus has been on both files [27–36] as well
as suspicious IP addresses and URLs [37–48], the work herein aims
to cluster and understand the dynamics of submitted URLs within
the VirusTotal platform. That is, we are primarily concerned about
characterising the URLs themselves via the metadata available for
each submission, as opposed to the raw content that they point to.

Scheme
https://
http://

Sub-domain Domain

support
mail

Suffix
com
support
Table 1: Components of URLs

apple
get-apple

Path
/en-us/
/index.php

Figure 1: Users, vendors and the VirusTotal service

SubmissionsDBScan APIQuery APIVendor 1Vendor 2Vendor NVirusTotal
ServiceUsers3  PartiesrdCharacterizing Malicious URL Campaigns

Redacted Conference, December, 2021, Somewhere on Earth

Field

url

content
hash

positives

Description

The URL that was submitted for analysis

Sub-Fields & Examples

http://example[.]com

A SHA-256 hash of the content that the URL was pointing to. For example, if the
URL pointed to a file, that file would be downloaded and a hash derived from it.
A count of how many vendors have flagged the URL, with 0 <= 𝑛 < 𝑁 where 𝑁
is the total number of vendors.

f568...215e

0

first_seen

The first time this particular URL was submitted to VirusTotal. There is also a
scan_date field which signifies when the URL was scanned.

2015-11-06 00:49:02

submission

Information specific to the user or application that submitted the URL, including
country of origin, date/time and by what method.

id:f69a77a0, country:ES,
interface:api

scans

Dictionary of results for each security vendor, with the detected sub-field being true
should that particular vendor flag a URL/submission as malicious.

Vendor-1: {detected:false}
Vendor-2: {detected:true}

Table 2: Example of metadata within submissions

2.2 Vendor Labelling
We note the slight contention within the community with regards
to vendor labelling accuracy and counts within VirusTotal submis-
sions. Most have defined a threshold, 𝑡, to classify submissions. That
is, a URL is deemed malicious if the number of vendors flagging it
surpasses said threshold. While most prior art [37–39, 42, 43, 45, 48]
has cast wider nets by setting 𝑡 = 1, some have been more conser-
vative by setting 𝑡 = 2, 3 [40, 44, 46], or even 𝑡 = 5 [16].

In contrast, the work herein is not directly concerned with la-
belling particular URLs as benign or malicious, and do not set
arbitrary thresholds to filter submissions. Rather, we take submis-
sions as a whole, cluster them by their metadata, and calculate the
average vendor hits for each cluster. For example, if bad.com and
worse.com are in a single cluster that points to the same malware,
and are flagged by 4 and 2 vendors respectively, then their cluster
would have a mean score of 3. Even then, we do not use these de-
rived values to label or filter URLs. They are instead used to further
characterise the clusters they represent and provide more insights
into those campaigns that are secondarily verified as malicious.

2.3 Dataset Description
With kind assistance from VirusTotal representatives, we collected
a large number of URL submissions via their /url/feed private
API endpoint3. These submissions stretched over a period of almost
2 months, from 2nd Dec 2019 thru to 30th Jan 2020. Submitted URLs
were checked by an average of 71.9 third-party security vendors,
with a majority of 94.18% of submissions checked by 72 vendors.
Each submission stores the URL in question, along with various
metadata around it, in multiple and nested fields in JSON format.
In Table 2, we’ve described and shown examples of the most per-
tinent metadata. The primary field of concern here is the content
hash (stored as Response content SHA-256), which is the com-
puted hash of the content that the URL points to. For example, if
both (bad.site/malware.exe) and (new.info/some.exe) point
to the same malicious executable, their submissions would have the

3https://developers.virustotal.com/reference#url-feed

same content hash. This is the straightforward mechanism with
which we cluster submissions and arrive at our various findings.

Striving for completeness and accuracy, the work herein pre-
processed, aggregated and analysed over 311M submissions encom-
passing 1.9TB of uncompressed text data. While studying a smaller
subset (e.g., 1 week duration) would be easier, it would not have
captured the full depth and width of malicious campaigns, and thus
limited our findings. Table 3 highlights the general aspects as well
as the scale of the data that was collected, specifically noting:

• 11.39% of the submissions (over 35.4M) had blank or entirely
missing content hashes. These did not exhibit clear patterns
and were uniformly spread, so it was not a case where data
for a period was corrupted. Possibly, there were intermittent
issues that prevented the recording of content hashes.

• There were only 77M unique URLs within the dataset, which
is unsurprising as the same URL can be repeatedly submitted
by multiple users. Thus, the naive mean rate of resubmissions
is 4.044 over a 2 month period. Further, 24.5M URLs (31.9%)
were flagged by at least one vendor as malicious.

3 CHARACTERIZATION OF SUBMISSIONS
We begin by providing a statistical overview of the entire dataset,
including general insights, temporal features, and the general per-
formance of security vendors. It is hoped that the findings here
would aid in the development of future detection strategies.

276,098,482
35,489,645

Submissions with content hash
Submissions without content hash

311,588,127 Total submissions

52,458,809 Unflagged unique URLs
24,579,130
Flagged unique URLs
77,037,939 Total unique URLs

Table 3: General details of collected dataset

Redacted Conference, December, 2021, Somewhere on Earth

Almashor et al.

3.1 General Findings
Finding 1: Attacks seem rampant in the United States (US). The
US leads the way with a quarter of all of submissions (78,687,777
– 25.25%), followed by South Korea (47,973,096 – 15.4%), Japan
(38,578,771 – 12.38%), and Germany (32,681,855 – 10.49%). As the
world’s technological hub it is perhaps reasonable that most sub-
missions originate from the US from businesses that use VirusTotal
via its API. Also, with populations that are more technology literate,
more people in such developed countries are aware of, and make
use of, the manual submission features of VirusTotal.

Finding 2: Majority of submissions were automated, with a large
percentage from a select few. By grouping on the interface sub-field
within each submission, we found an overwhelming 91.28% (284.4M)
of them came thru the API category, with email, web, community
respectively scoring 7.33% (22.8M), 1.06% (3.3M) and 0.32% (1M).
This shows that most use of the platform is automated, perhaps from
organisations that have commercial agreements with VirusTotal.
Further, based on the submitter_id field, we found that just two
organisations were responsible for 30.42% of all submissions, with
both contributing ∼47M each. In fact, just ten organisations were
responsible for close to half (48.34%) of all submissions.

Finding 3: 58.98% of submissions were unflagged. We observed
that 183,785,016 submissions were not flagged at all by any of the
vendors within VirusTotal. Going by the reasonable premise that
only suspicious URLs are being submitted, this means that more
than half of submissions were either truly benign or undetected
malicious. In the first case, this perhaps signals the need for more
work such as [20, 49] to understand why users may deem benign
URLs as suspicious. In the second case, this points to the need for
more effective methods to better detect attacks as they occur.

Finding 4: 17M unique pieces of content were flagged. By group-
ing on submissions’ content hashes, we identified that 20.6% of
unique hashes (17,116,732) within the dataset was potentially mali-
cious. This was pulled from the corresponding 41.02% of submis-
sions (127,803,111) where at least one vendor has flagged their
attached URLs as malicious. A majority of the 17M consisted of
single submissions, where a unique hash had only one submission
attached to it. As mentioned prior, there were 2.6M flagged clusters
where the unique hash had 2 or more submissions attached.

Given the contention between the multitude of scan engines, we
use the flagged status of submissions (and derived clusters) only as a
signal for further analysis. We have erred on the side of caution and
set a bare minimum threshold to guide our investigation. Simply,
if a cluster has a single vendor flag within it, we consider it as
potentially malicious, albeit at a lower risk than a cluster with
multiple vendor hits. Only clusters with absolutely no hits at all
amongst its submissions would be considered clean.

3.2 Temporal Characteristics
Daily scan volumes are shown in Figure 2, where we divided per
day arrivals into three equal 8-hour chunks starting midnight, 8am
and 4pm. As there was no timezone information within the dataset,
it is assumed that all times were recorded as UTC. Outliers were
observed in daily volumes from December 2nd to 5th, which we will
detail later. Otherwise, daily submission counts remained stable.

Figure 2: Scan times of all submissions

Finding 5: We observed stationary daily submission volumes over
a holiday period. We fit a linear model to our weekly average submis-
sion volume after normalizing the data, finding a slope of -0.0290,
indicating almost no change in the rate of submissions over the
study period. We also fit a model after discarding the anomalous
peaks from December 2-8, finding an even smaller slope of 0.0147.
This implies that the overall submission rate is fairly constant
which is somewhat surprising given the time of year. It is reason-
able to think that attackers would time their campaigns to coincide
with key holiday events (e.g., schemes that purport to be Christmas
sales). There would also be reasonable assumptions that submis-
sions would drop as industries close and communications decrease.
In any case, neither of these hypotheses materialised in the data.

3.3 Outbreaks: High submission volume events
As mentioned, we observed “outbreaks” in the daily submission
counts, where values were abnormally high (2nd to 5th Dec). To
mathematically identify outbreaks, we used a uniform mechanism
to compare submission volumes relatively across all submissions in
the collected period. To this end, we used a z-score which is defined
as 𝑧 = (𝑥 − 𝜇)/𝜎, where x is a data point in the distribution, 𝜇 is the
mean and 𝜎 is the standard deviation. This was computed over the
same 8-hourly periods for the entire 2 months. A z-score of 1 for a
specific time period of a day indicates that the submission volume
is a single standard deviation away from the mean. A conservative
z-score of 2 was chosen as the limit to identify abnormally high
submission volume events. Values greater than 2 indicated that
the submissions within the specific time period were 2 standard
deviations away and is an intuitive indication of outliers.

Finding 6: We observed one instance of an outbreak spread across
three consecutive days. During this outbreak, the average number
of submissions spiked to 347,747 per hour compared to 210,270
submissions per hour under normal conditions, which is ∼40%
increase in submission volumes. This indicates that outbreaks are
rare events, at least within the collected dataset. The term “outbreak”
does not imply that the submissions reported were malicious as
we cannot attribute a source for such events. However, there are
reported instances of widespread phishing campaigns targeting
numerous organizations across various industries. For example, on
2020-12-02, there was a wave of phishing campaigns targeting 28

02/1209/1216/1223/1230/1206/0113/0120/0127/018-hourly periods for all submissions (2019-12-02 to 2020-01-31)200K1M10MNumber of Submissions246,622 records submittedbefore 8am on 5th Dec7,460,838 records submittedafter 4pm on Dec 2Monday, 24 hour period00:00 to 08:0008:00 to 16:0016:00 to 24:001,721,314.58 mean1,810,891.62 mean1,660,922.22 mean1,721,314.58 mean1,810,891.62 mean1,660,922.22 meanCharacterizing Malicious URL Campaigns

Redacted Conference, December, 2021, Somewhere on Earth

flagged by 𝑛 number of vendors? That is, how quickly do vendors
catch up in flagging URLs after it was first submitted.

Finding 9: The number of vendors flagging submissions is in-
versely correlated to the time these submissions were first reported.
More specifically, if a large number of vendors detected a particular
set of submissions, it is more likely that these submissions are re-
cently reported to the VT. Conversely, if submissions were flagged
by only a few, it is are more likely that they were reported compar-
atively long ago. Intuitively, it is expected that more vendors would
flag malicious URLs over time but surprisingly, this relationship
between the time and vendors is quite opposite. Figure 4 shows
time-vendor distribution for the flagged submissions.

Finding 10: Submissions flagged by 12 or more vendors are de-
tected significantly earlier compared to others. There could be two
possible reasons for this. First, it indicates that some security ven-
dors are trained on specific types of attacks and consequently, they
are able to flag URLs in submissions promptly. We see this in Fig-
ure 4 for the time distribution of 12 to 21 vendors. Second, vendors
may rely on others when flagging URLs. For example, if 10 vendors
flag a particular URL, others may also follow suit.

4 CAMPAIGN CHARACTERISTICS
Here, we detail the clustering of submissions, and the subsequent
identification and verification of confirmed malicious campaigns.

4.1 Clustering
Each submission contains a hash code that is unique to the content
that its URL points to. This is stored within the Response content
SHA-256 field. Essentially, when a URL is given to VirusTotal, the file
or HTML page that it refers to is retrieved, and a hashing function
is run over it. It is important to note that the resultant output of
the hash function is a unique identifier for the input content.

Figure 5 illustrates this process, where Webpage 1 is fed into the
hash function and the resultant code is 1cf3...5e72. However, if a
single character a is changed to b as seen in Webpage 1’, the output
hash code is then completely changed to 82af...94d6. This is the

Figure 4: Mean time for submissions to reach 𝑁 flags

Figure 3: Spread of submissions by number of vendor flags

organizations [50]. Phishing emails from 26 unique email addresses
and containing URLs with at least 24 unique domain names were
used, all of which were engineered to lure victims to download
malware. We surmise that such large-scaled phishing campaigns
could result in abnormally high submissions rates.

3.4 Vendor Effectiveness
Submitted URLs are analysed in parallel by a median of 72 security
vendors to determine if they’re benign or malicious. As seen in
Table 2, each submission has a positives field that contains the
number of vendors that have flagged it. In Figure 3, we delved
deeper into the distribution of submissions with respect to vendor
flags, and observed that detection performance varies significantly
with most submissions being flagged by only a select few vendors.
Finding 7: We observed that around 98.27% (125.6M) of all flagged
submissions were detected by 10 or fewer vendors. This indicates that
vendor detection performance is highly skewed and only a few of
them are effective. However, it must be noted that vendors have dif-
ferent specialisations, with some better designed to detect phishing
and others customised to detect other malware. We observed that
only seven submissions were detected by the observed maximum of
21 vendors. More specifically, only 1.69% of all flagged submissions
were detected by more than 10 vendors (2.1M out of 127.8M), which
indicates that a select few were responsible for most detections.

Finding 8: We observed that on average around 4 security vendors
detected most of the flagged submissions. This implies that if a URL
is flagged by at least four vendors, it is reasonable to conclude that
it is malicious. This is important as it will assist system admins
when selecting a threshold when labelling URLs based only on VT
vendors. For example, if at least 𝑛 number of vendors has flagged a
URL, it is likely malicious. If an overly-restrictive threshold (e.g.,
𝑛=20) is set, it may result in significant number of missed detections.
Thus, appropriate thresholds may be set based on Figure 3.

3.5 Time to 𝑛 Vendor Flags
With each submission containing a first_seen field, the question
becomes: what is the mean time required for submissions to be

1101001K10K100K1M10M100MNumber of Submissions0123456789101112131415161718192021Vendor Flags (positive score) per Submission183,785,01626,374,19446,206,7258,020,2509,033,3248,814,6929,229,5447,693,8305,498,6783,288,7671,478,451900,244571,697359,275191,69493,82435,8369,4412,2703432570 positives 58.98%1 to 10 positives125,638,455 (40.32%)11+ positives2,164,656 (0.69%)1.4345Mean acrossall submissions3.4973Mean across1+ positives0100200300400500Number of Days123456789101112131415161718192021Vendor Flags (positive score) per Submission374.75167.90546.54518.02546.71494.11400.75301.20230.50179.05128.4997.7773.9372.1670.2263.5771.6766.8485.2487.48102.51Takes an average of 102.51 days fora submission to be flagged by 21 vendors(from first-seen to scan-date)127,803,111 submissions considered(discarded 13 with invalid dates)Redacted Conference, December, 2021, Somewhere on Earth

Almashor et al.

Figure 5: Showing how a single character change in a URL’s
content leads to a different hash code.

Figure 6: Distribution of clusters by number of submissions

mechanism with which we can cluster seemingly disparate sub-
missions together. For example, if both www.321.site/page.html
and xyz.com/index.html result in identical hash codes, we can
assume that they point to the same content (possibly on different
servers). Accordingly, if either is flagged, then both are malicious.
This is the method with which we organise the 311M submissions
into coherent clusters for further examination. Instead of trying to
find similarities between the URL strings themselves in the hopes
of finding groups, we simply rely on the reported content hashes
within each submission’s metadata. As noted previously in Table 3,
11.39% of all submissions did not have valid content hashes, which
we ignore given the overwhelming number of remaining submis-
sions. This results in the 82.9M clusters seen in Figure 6, where we
see that a majority 75.3M had only one submission attached. That
is, given a particular submission 𝑆 with a unique content hash 𝐻 ,
then 𝑆𝐻 = 1. We’ve ignored these for now, given time constraints
and our stated focus on campaigns of malicious URLs.

Figure 6 shows the distribution of all clusters according to their
number of submissions, where we see the single-submission cluster
on the extreme left. There was one cluster containing 8.5M sub-
missions (extreme right) which we theorise could be related to a
standard 404 error page. There were 7.5M clusters with at least
2 records (𝑆𝐻 >= 2), of which 2.6M (34.6%) had at least one sub-
mission flagged by at least one vendor as malicious. This strongly
signals the presence of concerted campaigns, especially given the
dataset’s relatively short time frame of 2 months. These are the
clusters we focus on as they are likely to contain malicious URLs.

4.2 Vendor Labelling
To help guide our analysis, we utilize the preexisting vendor labels
within each cluster. Recall that each submission contains a list of

security vendors that have labelled that submission’s URL as be-
nign or malicious. Most vendors claim to use some form of machine
learning, which despite their efficacy, is known for False-positive
and False-negative behaviours. Besides, the pre-existing labels for
each URL were issued simultaneously at the point of submission,
and there is an opportunity for us revisit their labelling with knowl-
edge from the present day. Therefore, we implemented secondary
labelling to act as an expanded ground truth for our analysis.

To that end, we examined three candidate phishing block-lists in
wide use today: Google Safe Browsing (GSB) [51], OpenPhish (OP)
[52], and PhishTank (PT) [53]. According to the recent empirical
analysis done in [54], GSB is by far the largest block-list available,
with over 17 times as many URLs compared to PT and OP combined.
It is also used by a majority of web browsers such as Chrome, Safari
and Firefox and protects roughly four billion devices per day by
showing warnings to users should they attempt to access malicious
URLs. This provides GSB with the largest pool of users (over 600M)
with which to obtain frequent reporting [54]. Hence, we selected
GSB as the secondary ground truth labelling mechanism.

4.3 Identification and Verification
Thus, we turn our attention to the 2,617,572 flagged clusters that
recorded at least one vendor hit within their submissions. These
proved fertile ground for the verification of malicious campaigns
via secondary GSB checks. Figure 7 shows these clusters sorted
from left to right according to a risk factor defined as follows:

• Positives: Each submission contains a positives field which

indicates the number of vendor flags against it.

• Mean Positive Score: This is simply the sum of all Posi-

tives divided by the submission count of each cluster.

• Unflagged Clusters: Clusters are deemed unflagged if they
have mean positive scores of 0.0. That is, not a single vendor
flag in any of the submissions within a cluster.

• Flagged Clusters: Conversely, this is when clusters have at

least one vendor hit (i.e., mean positive score > 0.0).

• Malicious Campaigns: Flagged clusters that are then veri-

fied by GSB as containing at least one malicious URL.

For example, if a cluster had three submissions with positive
scores of 7, 7, 8 respectively, then its mean positive score would be
7.33. Conversely, if a cluster had only a single positive vendor hit
amongst 10K submissions, then it’s score would be 0.0001. Subse-
quently, if either of these contain a URL that appears in the GSB
block-list, then they are deemed malicious campaigns.

Finding 11: Flagged clusters with seemingly very low risk can
contain verified malicious campaigns. Given their low mean positive
scores, one would expect that the bottom 5% quantile of flagged
clusters to perhaps be clear of malicious URLs. These 130,878 sup-
posedly low-risk clusters contained 7,002,793 unique URLs within
them and can be seen on the extreme left of Figure 7. However,
when we reran their URLs against GSB, we found hits for 974 of
the clusters. The confirmation of such clusters as malicious is con-
cerning, given their comparatively low mean positive scores that
range from as low as 0.001547 to 0.5 (with a mean of 0.3540).

This signals the need for better detection mechanisms, and that
vigilance is required even when a cluster seems of very low risk.
Of course, the numbers may be skewed in the sense that a wave of

baWebpage 1’1cf3...5e7282af...94d6SHA-256Hash FunctionWebpage 11101001K10K100K1M10MNumber of Submissions1101001K10K100K1M10M100MNumber of Clusters75,372,707 uniqueclusters had only 1submission each3,471,848 uniqueclusters had 2submissions each1 unique cluster had8,584,120 submissions75,372,7071 submission only4,943,058Unflagged 2+ submissions2,617,572Flagged 2+ submissions82,933,337Total unique clustersCharacterizing Malicious URL Campaigns

Redacted Conference, December, 2021, Somewhere on Earth

Content
Hash
5db9-1212
d992-844c
16f3-21a6

URLs

3
1,053
2

Submis-
sions
3,426
596,116
12

Mean
Positive
0.005254
0.033406 firsttime-traffic41[.]loan
0.083333

4ksudckusdkc[.]space

URLs Detected (GSB Secondary Verification)

everyday-vouchers[.]com, sweepstakehunter[.]com

Example Undetected URLs

alwkdlka[.]club
manerck[.]com
N/A

Table 4: Three (out of 974) low-risk flagged clusters that were confirmed as malicious campaigns

submissions with the same URL (and hence content) could dilute the
mean positive score and thus the perceived riskiness of a cluster. We
see examples of this with cluster 5db9-1212 in Table 4, where just
three URLs were repeatedly submitted and thus dragged down the
mean positive score. In any case, this points to the fact that, taking
all the vendors as a whole, even a single hit in a cluster is cause for
concern. This is true especially for cluster 16f3-21a6, where there
was only a single vendor flag across all 12 of its submissions.

We also see the first evidence of large campaigns with cluster
d992-844c. It contained seemingly unique URLs that all point to
the same content, of which only one was confirmed as malicious
by GSB. Whilst the sheer number of submissions seemed to dilute
the apparent risk, it was no less dangerous given the diversity of
URLs within it. There were 364 unique sub-domains, 782 unique
domains, and 109 unique suffixes used throughout its 1,053 URLs.
Finding 12: GSB did not detect all malicious URLs within cam-
paigns. This is exemplified in cluster d992-844c in Table 4 where
only a single URL was detected out of 1053 URLs. From the 974
discovered malicious campaigns, 939 had at least two unique URLs
and the mean percentage of undetected URLs within them stands
at 61.07%. That is, a majority of malicious URLs constantly escape
detection, especially as the number of unique URLs increases. As
context, the average number of URLs within these 939 campaigns
stands at 2326.12, with the largest campaigns maxing out at 729,858.
Finding 13: 94.5% of unique URLs went undetected by GSB in high-
risk flagged clusters. On the opposite end in Figure 7, we verified all
the unique URLs within the top 130,878 flagged clusters (i.e., the top
5% in terms of risk). Given their high mean positive scores, it can
be reasonably expected that the majority of URLs would indeed be
malicious. However, GSB only detected 5.4% of the 333,728 unique
URLs contained within these high-risk clusters.

Figure 7: 2.6M flagged clusters sorted by risk factor.

The argument here could be that these malicious campaigns were
swiftly detected, dealt with by authorities and/or their instigators
have since ceased their concerted attacks. This then may have
prompted subsequent removal of the URL entries from GSB block-
lists and thus bypassed our secondary verification. However, we
posit that GSB would not be so quick to remove such entries, given
the relative recency of the events. It has only been 14 months since
data collection in Jan 2020 and re-verification in Apr 2021. There
is also the fact that 17,895 malicious URLs (5.4%) from the same
clusters were indeed found in GSB block-lists.

Finding 14: 11,622 confirmed malicious campaigns were found in
high-risk flagged clusters. Despite the low URL detection rate above,
we found a much higher incidence of malicious campaigns. This is
perhaps to be expected given the high mean positive scores, which
implies more vendors were flagging the URLs within each cluster
and thus, a much higher likelihood of malicious campaigns.

On the other hand, only confirming 8.88% of 130,878 clusters
is seemingly low for a state-of-the-art block-list such as GSB. On
average, the mean positive score for clusters detected by GSB was
11.36. Using this as a benchmark, there were 36,678 other high-risk
clusters with higher mean positive scores that were missed by GSB.
This relatively high number of undetected clusters is in line with
the high number of undetected URLs seen earlier, and alludes to
the known shortcomings of the block-list approach. In other words,
should an attacker choose to rerun some of these campaigns today,
the majority of web-browsers that rely on GSB would not be able
to prevent their users from accessing these known bad URLs.

Finally, we do notice a significant drop in the number of unique
URLs in the low-risk clusters (7M) to just 333,728 within these high-
risk ones. An explanation could be that the campaigns here are
being detected at a higher rate by vendors, and thus the URLs and
domains that attackers use are shut down faster. This leads to less
reporting as the instances of abuse wither and attackers give up on
trying to use different URLs for the same malicious content.

59,450 Campaigns with a single unique URL
18,360 Campaigns with multiple unique URLs
77,810 Total Campaigns

59,450 URLs in Single-URL Campaigns
9,900,146 URLs in Multi-URL Campaigns
9,959,596 Total Unique URLs

276,801
37,880,096
38,156,897 Total Submissions

Submissions in Single-URL Campaigns
Submissions in Multi-URL Campaigns

Table 5: Characteristics of found malicious campaigns

0500K1.0M1.5M2.0M2.5M2,617,572 Flagged Clusters0369121518Mean Positive ScoreCluster 9ff5-6eadscored 4.77e-06 across419,634 submissionsCluster e15c-40b7scored 19.0 across2 submissionsTop 5% (130,878)most flagged clustersBottom 5% (130,878)least flagged clustersMean 4.43 (Std 2.84)75% (6.0)25% (2.0)Redacted Conference, December, 2021, Somewhere on Earth

Almashor et al.

degree of variance which we see in Figure 8 with some campaigns
on the extreme right employing URLs with tens of thousands of
characters. 50.89% of campaigns have average URL lengths of be-
tween 38.0 (1st quartile) and 73.0 (3rd quartile). This is likely due
to attackers relying on increasingly longer URLs to deceive both
end-users and commercial detection systems. As end-users are in-
creasingly trained to detect malicious URLs, they grow to distrust
shorter URLs that point to unknown locations [49] or comparatively
short URLs with added terms in their domain names [20].

4.5 Campaign Metrics
To systematically evaluate the characteristics of campaigns, we’ve
defined and calculated metrics to quantify their behaviors:
• Campaign size: Number of URLs deployed in each campaign.
• Source distribution: Ratio of the campaign size to the number
of submission count reported by users in a campaign. A 100% source
distribution indicates that the campaign used a different URL for
every submission reported at VT. This metric quantifies the rate at
which campaigns attempt to created URLs. This metric tells us how
diverse a campaign is in terms of the number of URLs created by
attackers and correspondingly how many times they are reported.
• Campaign footprint: For footprint, we consider campaign met-
rics from both attacker (count of unique URLs deployed by a cam-
paign) and victim (number of times these URLs reported by users)
sides. We use the following expression to compute the footprint
of a campaign: 𝑓 𝑝 = 𝜇𝑈 + (1 − 𝜇)𝑆, where 𝑈 represents the count
of number of URLs in a campaign, 𝑆 denotes the number of time
these URLs are reported VT by the users. 𝜇 represents the weight
assigned to each metric in the expression. We set equal weights(i.e.,
0.5) for both the metrics in a campaign. The parameter 𝜇 can be
tuned in order to prioritize certain metrics.
• Domain/sub-domain diversity: Ratio of the count of unique
sub-domains in a campaign to the number of URLs in a campaign.
A 100% sub-domain diversity indicates that every domain in a set of
URLs from this campaign was different. This metric is important for
us to understand if a campaign is targeting specific global brands
or tends to distribute phishing attempts across a wide range of
users. In this case, lower sub-domain diversity can suggest a highly
targeted campaign toward organizations.
• Detection: For phishing campaign detection, we evaluate detec-
tion rate using further two metrics: GSB and VT’s security vendors.
A 100% GSB detection against a campaign indicates that all URLs
in a campaign are flagged by GSB. However, for security vendors,
we report the mean number of vendors who flagged URLs in a
campaign. This metric helps us to understand the detection rate of
URLs in a campaign against GSB and overall VT vendors.

After we defined several metrics, we compute them for each of
the 15,505 phishing campaigns. Here, we interpret the metrics to
comprehend how these campaigns differ from each other.

Finding 18: Phishing campaigns had an average source distribu-
tion of 61.58%, which means that most campaigns attempt to deploy
different URLs in each campaign. We observed that 6,160 phishing
campaigns with on average campaign size of 146 URLs (footprint of
160) had source distribution of 98.75%. Moreover, 5,498 campaigns
had source distribution of 100%. The high source distribution rate
shows that the campaigns are likely to create new phishing URLs

Figure 8: Mean URL lengths of 77,810 campaigns

4.4 Malicious Campaigns
Concluding our initial analysis on the highest and lowest risk
flagged clusters, we proceeded to run our secondary verification
on the entire set of 2.6M flagged clusters. Our goal was to perform
analysis on verified malicious campaigns. The hope from the outset
was that we would perhaps gather 100K campaigns from the top
5% flagged clusters alone. However, the unexpectedly low numbers
seen in prior sections subsequently forced us to widen our net.

Finding 15: There are 77,810 confirmed malicious campaigns
within the dataset. We successfully verified that 2.97% of the 2.6M
flagged clusters were indeed malicious. These campaigns have at
least one URL within them that has been marked by GSB as point-
ing to either deceptive or phishing pages (SOCIAL_ENGINEERING),
or malicious payloads (MALWARE), or even both. As all of a cam-
paign’s submissions are labelled with the same content hash, a
single marked URL therefore implies that all URLs within that
campaign point to the same malicious content.

The number of confirmed campaigns seems low at only 77,810,
which perhaps points to the limitations of the current block-list
approach by GSB. On average, the mean positive score for these
clusters verified by GSB stands at 6.2, with a standard deviation of
3.05. If we were to use this as a threshold, it is noted that 605,323
other flagged clusters with higher mean positive scores were not
detected by GSB. That is, assuming that all flagged clusters were
indeed malicious, GSB may have missed this large number of flagged
clusters which comprise of 2,034,777 unique malicious URLs.

Finding 16: The vast majority of malicious URLs come from cam-
paigns that employ multiple unique URLs. Table 5 details the general
characteristics of the confirmed campaigns, which we have broadly
categorised into campaigns that have either a single unique URL, or
multiple unique URLs. A majority (76.4%) of the found campaigns
consists of single URLs (i.e., the same URL is repeatedly submitted)
but these only contributed 0.6% (59,450) of unique URLs and 0.73%
(276,801) of submissions. The 18,360 multi-URL campaigns on the
other hand, were responsible for the majority of URLs and submis-
sions. This lends credence to our hypothesis that masses of URLs
should be treated as coherent campaigns.

Finding 17: Campaigns favor the use of longer URLs. The average
URL lengths across campaigns (i.e., mean of means) stands at 64.29
characters. There is a standard deviation of 85.76 indicating a high

010K20K30K40K50K60K70K77,810 Malicious Campaigns (38,156,897 submissions, 9,959,596 URLs)101001K10KAverage URL Lengths12.0 chars forcampaign ”996f-5c8b”16,257.0 chars forcampaign ”7c41-69b6”38.0 chars (1st Quartile)73.0 chars (3rd Quartile)64.29 chars Mean85.76 chars Std.Dev45.00 chars MedianCharacterizing Malicious URL Campaigns

Redacted Conference, December, 2021, Somewhere on Earth

frequently. The findings regarding the source distribution indicate
that well-known blacklisting techniques that leverage whitelists or
blacklists will not effectively detect URLs from many campaigns.

We also observed that for 1,040 large-scaled campaigns (cam-
paign size greater than 100 URLs), the source distribution reduced
to 35.95%. For such campaigns, the average campaign size, footprint,
and number of reported submissions were 5,132, 19,682,and 34,233,
respectively. Moreover, we observed that the largest phishing cam-
paign with a campaign size of 1,391,080 URLs (footprint 4,987,600
and reported submissions were 8,584,120) has a source distribution
of 16.21%. Our findings indicate that the source distribution of a
campaign decreases with increase in campaign size. This behavior
could be attributed to the fact that as number of URLs increase,
the corresponding reports from users increases non-linearly. These
statistics indicates that large-scaled phishing campaigns might use
domain generation algorithms (DGAs) to generate a large num-
ber of domain names that could potentially be used as rendezvous
points with their command and control servers. The large number
of potential rendezvous points makes it difficult for security vendors
to detect and take down the URLs from phishing such campaigns
since the infected computers will attempt to contact some of these
domain names every day to receive updates or commands.

Finding 19: Phishing campaigns had an average domain and sub-
domain diversity of 66.57% and 21.45%, respectively, with specific tar-
geted organizations. We observed higher diversity in domain names
compared to that of sub-domains. This is because attackers need
to register the domain names following certain guidelines whereas
for sub-domains, the users can choose names of their choice. Due
to this flexibility, campaigns targeting particular organizations can
use sub-domain names specific to the target organization, such as in
targeted phishing. We observed that 153 campaigns had a domain
and sub-domain had diversities of 2.29% and 1.61%, respectively,
which indicates that attackers used a fixed set of domain and sub-
domain names targeted towards few global brands and financial
institutions. For instance, we discovered a large-scaled campaign
with campaign size of 4,081 unique URLs that used only 12 domains
and nine sub-domains targeting Apple brand (see Section 5.1).

Finding 20: We discovered that GSB performs well in detecting
campaigns (having size 100 or less) achieving 74.32% detection rate.
However, GSB’s detection performance drops to 13.27% for relatively
larger campaigns (size above 100). We observed that the performance
of GSB’s degrades with campaign size. For example, the overall
detection rate for larger campaigns, i.e., campaign sizes greater
than 10,000 URLs, the detection rate of GSB further drops to 2.46%.
One reason for this detection drop could be attributed to the fact
that malicious URLs are often short-lived. In [54], it was reported
that fewer URLs were residing in three popular blacklists (GSB, OP,
and PT) as the time since they were blacklisted increases, which
indicates that URLs are often short-lived. Moreover, none of the
three blacklists enforce permanent-resident policy for URLs. They
also observed that a significant number of URLs reappear once they
were removed from blacklist. The lower detection rate for larger
campaigns seems to be in consistent with the findings in [54].

Like GSB, security vendors in VT also struggle to detect URLs as
the campaign size grows. We observed that on average six security
vendors detect phishing campaigns (size of 100 or below) and four
security vendors detect large campaigns (size above 100).

5 CASE STUDIES
Here we provide examples of the attack strategies seen in campaigns
by randomly selecting three campaigns and analysing them in terms
of their scale, diversity, and detection by security vendors.

5.1 Targeted Campaigns
Finding 21: We discovered several campaigns impersonating well-
known global brands so as to deceive end-users. Such large-scale
campaigns aim to mislead victims by using URLs containing text
such as Apple and PayPal. For example, a large campaign (of size
4,081 unique URLs) used variations of domain and sub-domain
names resembling the targeted Apple brand. The 4,081 unique URLs
used a combination of 9 sub-domains, 12 domains, and 7 suffixes,
with the ratio of the number of unique domains to the number of
URLs standing at 0.29%. The complete list of variations are:

Subdomains: www.apple.com, www.icloud.com, www.apple,
icloud.com, apple, apple.com, icloud, www, mail.
Domains: lcloud-com, online-support, findmy, get-apple,
com-support, map-apple, id-info, wvvw-icloud, sign-in,
viewlocation-icloud, map-log, com-fml.
Tld: us, in, support, live, review, com, mobi.

This shows a campaign that is precisely targeting the Apple
brand. We found that the hash of URLs in this campaign were re-
ported 104,311 times, and observed that an average 11 vendors were
able to detect URLs from this campaign, which is significantly better
performance compared to the results show in Figure 3. Surprisingly,
we also observed that GSB only detected 2 of the URLs.

5.2 Malware Downloads
We discovered a campaign attempting to download and install
malware to victims’ machines, with a size of 1,589 URLs and a
source distribution of 16.57%. The campaign used 261 unique do-
main names and a total of 1,589 URLs which were submitted 9,589
times. 1,175 of the URLs had the domain ubar-pro4.ru, which was
confirmed as malicious [55] and used for malware distribution.

Finding 22: We discovered close to 98% (1,572/1,589) of URLs in
the campaign communicates using transport layer protocol (TLS).
This finding is consistent with [56] which reports that nearly a
quarter of malware now leverages TLS. Encryption is one of the
strongest weapons used by attackers to obfuscate their code or URLs
(specifically the path component of a URL) to remain undetected.
On further analysis, we discovered that the attacker used the
1,572 URLs to download malware to victim machines via TLS. The
downloaded files may have one of the following extension: .exe (19
malicious executables found), .js (28 javascript files), .zip or .rar (7
and 3 zip and rar files, respectively).

We also discovered that URLs in this campaign are embedded
with pointers to malicious torrent files. This is interesting as at-
tackers no longer have to rely on downloading torrent files from
a server but instead can do so directly from a torrent peer. This
allows for strong persistence of malicious content as victim access
is ensured even when trackers are closed, or down due to registra-
tion. We observed 46 (2.89%) URLs with such capability, with very
low detection rates for GSB and VT vendors. From the 1,589 unique

Redacted Conference, December, 2021, Somewhere on Earth

Almashor et al.

URLs, only two were detected by GSB and on average, only one
vendor flagged such URLs within this campaign.

5.3 Fileless Malware
Some campaigns exhibit increased sophistication, with malware
that leverages native legitimate and pre-installed system tools to
execute an attack. Unlike traditional malware, fileless malware
foregoes the need for malicious payloads which makes it harder to
detect by disk scanning tools. Such malicious techniques that rely
on using native tools is called “living off the land”.

Finding 23: We observed 23 campaigns that leverage system’s pre-
installed legitimate tools, such as PowerShell, to perform malicious
tasks. The URLs within such campaigns are representative of a three-
stage process: 1) The infection starts with phishing emails that are
rigged with a URL to lure the victim to click on it. 2) Download
a malicious payload using command-line tool (e.g., cmd.exe) to
invoke the PowerShell tool with code that is heavily obfuscated in
order to evade analysis. The malicious file downloaded from remote
server is kept in-memory rather than on-disk. 3) Finally, the file is
executed which loads its plugins and then enters a communication
loop which fetches tasks from command & control servers.

An example of such exploits is given below, where a clicked URL
will download an executable (bad.exe) from a remote server via
PowerShell and cmd.exe, and then execute it:

http://xxx.xxx.xxx.xxx/public/invokefunction&function=
call_user_func_array&vars[0]=system&vars[1][]=
cmd.exe\/c\powershell\(new-object\System.Net
DownloadFile(’www.bad.com/download.exe’,’\SystemRoot\
/Temp/bad.exe’);start\SystemRoot\/Temp/bad.exe

.WebClient).

We also discovered campaigns that leverage other legitimate
tools while performing malicious tasks. Examples of these include:

Tools: wmiprvse.exe, svchost.exe, conhost.exe, lsm.exe, sysstem.exe,
lsass.exe, winlogon.exe, spoolsv.exe, csrss.exe, securityhealthser-
vice.exe, services.exe, wininit.exe, cmd.exe, explorer.exe, wudfhost.exe,
yourphone.exe, smss.exe, dwm.exe, taskhost.exe, csrss.exe, system.exe,
regasm.exe, idle.exe

6 DISCUSSION
Content Hash Detection: Preceding sections have highlighted
that traditional block-lists are easily improved if defenders consider
the content hash of URLs. Previously unseen URLs could thus be
rapidly identified in the absence of obvious malicious connections.
We see evidence of this with cluster 16f3-21a6, where one URL
(everyday-vouchers.com) remained unflagged for six submissions
before being flagged by GSB on 2020-01-02. Shortly after, another
URL (sweepstakehunter.com) bearing the same content hash was
observed as remaining unflagged for 5 submissions (to end of data).
A year on, both URLs were marked as malicious by GSB from
our secondary checks. Thus, a content-hash detector would have
immediately flagged the second malicious URL as soon as it ap-
peared within the VirusTotal platform in Jan 2020. This would have
protected end-users from accessing it from an even earlier time.

It is noted that attackers could easily change generated hashes
by automatically mutating malicious content for each end-user

visit. This would evade content-hash detection as presumably, each
URL results in a unique hash. In this case, vendors can fall back
on methods such as linking IP addresses and server signatures.
For phishing pages, HTML comparison methods such as in [57]
could be used. Nonetheless, content hashes may still be of aid by
initially clustering URLs, before more computationally intensive
mechanisms are brought to bear. This could minimize the risk of
false positives in more complex detectors deployed in later stages.

Impact of Campaigns: With over 20 findings presented, the com-
munity is better positioned to understand malicious URLs and thus
better detect them. Traditional approaches must be improved as
we cannot rely on the wholesale lumping of URLs into binary be-
nign/malicious classifications. For deep-learning based detectors,
active threat intelligence such as this could aid in teasing out learn-
ing features from disparate URLs that may have a common attacker.
As attackers evolve their tactics, viewing the URLs as coherent cam-
paigns opens up avenues for more refined defences. We also see
the apparent limitations of current block-lists, which are not able
to detect URLs that are obviously a part of malicious campaigns.

The insights and various case studies shared here exemplifies
the tricks that attackers use to prolong and better target their cam-
paigns. We see the range of domains, sub-domains and suffixes used
to evade defences and deceive end-users in Sections 4.5 and 5.1.
Malware payloads also exhibit a dangerous prevalence throughout
the campaigns we discovered, with attackers becoming more apt at
using standard security mechanisms to mask their payloads. We
also see the efforts they go to in order to evade defences, with our
findings on their use of widely variant URL lengths and propensity
for longer URLs as seen in Section 4.4. It is hoped that such insights
would be of use to the wider cyber-security community.

An issue of concern is that vendors are not able to effectively iden-
tify a swathe of malicious URLs. It would be unfair to expect high
detection rates for all vendors represented on VirusTotal. However,
there seems to be little agreement between vendors when URLs are
indeed suspicious, evidenced by just 0.69% of submissions being
flagged by 11 or more vendors. The clear recommendation for the
community is to not rely on the fact that there are a large number of
vendors, as it may offer a false sense of completeness and security.
Rather, care must be taken to focus only on a select few vendors.
Even so, researchers are advised that even the most performant
vendor may struggle to detect whole campaigns. GSB, which is
the premier block-list used by a large section of Internet users,
suffers from poor detection rates in a variety of campaigns. This
is illustrated in detail from the multiple findings within Sections
4 and 5. Our uncommon perspective from the lens of campaigns
has laid bare the fact that, perhaps unsurprisingly, many malicious
URLs are slipping thru block-lists and endangering end-users.

Finally, file-less malware is also a rising concern, with exploits
encoded directly into the URLs themselves in order to compromise
machines with and without secondary download steps. We postu-
late that the use of static code analysis tools may be of use here.
That is, vendors may implement detectors that treat the URLs as
lines of code in order to detect inline scripts that may harm users.

Characterizing Malicious URL Campaigns

Redacted Conference, December, 2021, Somewhere on Earth

7 CONCLUSION
While there has been extensive work studying malicious URLs,
there remains a gap in the understanding of them as concerted
campaigns. The work herein is a culmination of extensive research
and analysis into 311 million records submitted to VirusTotal from
Dec 2019 to Jan 2020. Clusters of URLs are identified via their
metadata and doubly verified as malicious before being analysed.
This offers practical insights into the nature of campaigns along
dimensions such as individual URL attributes, temporal aspects, and
the victim brands they target. The nature of these campaigns are
also explored with several case-studies that illustrate the techniques
that victimise users and circumvent detection strategies.

Future work includes looking at measures to further group cam-
paigns together. That is, to see if there are ways for us to connect
different campaigns into a single large campaign that may be at-
tributed to a common attacker. A recommendation we have for
block-list providers is to simply block URLs that all point to the
same content, if said content is proven to be malicious. This perhaps
simple step can increase their protection coverage and leave them
better able to detect zero-day URLs that appear as attacks evolve.

ACKNOWLEDGEMENTS
The work has been supported by the Cyber Security Research Cen-
tre Limited whose activities are partially funded by the Australian
Government’s Cooperative Research Centres Programme.
This work was supported by resources provided by the Pawsey
Supercomputing Centre with funding from the Australian Govern-
ment and the Government of Western Australia.
This research was supported by use of the Nectar Research Cloud
and by the Tasmanian Partnership for Advanced Computing (TPAC).
The Nectar Research Cloud is a collaborative Australian research
platform supported by the NCRIS-funded Australian Research Data
Commons (ARDC).

REFERENCES
[1] Kholoud Althobaiti, Nicole Meng, and Kami Vaniea.

I don’t need an expert!
making url phishing features human comprehensible. In In CHI Conference on
Human Factors in Computing Systems (CHI ’21), May 2021.

[2] Daiki Chiba, Ayako Akiyama Hasegawa, Takashi Koide, Yuta Sawabe, Shigeki
Goto, and Mitsuaki Akiyama. Domainscouter: Understanding the risks of de-
ceptive idns. In 22nd International Symposium on Research in Attacks, Intrusions
and Defenses (RAID 2019), pages 413–426, Chaoyang District, Beijing, September
2019. USENIX Association.

[3] Sourena Maroofi, Maciej Korczyński, and Andrzej Duda. Are you human? re-
silience of phishing detection to evasion techniques based on human verification.
In Proceedings of the ACM Internet Measurement Conference, IMC ’20, page 78–86,
New York, NY, USA, 2020. Association for Computing Machinery.

[4] Toshiki Shibahara, Yuta Takata, Mitsuaki Akiyama, Takeshi Yagi, and Takeshi
Yada. Detecting malicious websites by integrating malicious, benign, and com-
promised redirection subgraph similarities. In 2017 IEEE 41st Annual Computer
Software and Applications Conference (COMPSAC), volume 1, pages 655–664, 2017.
[5] Yury Zhauniarovich, Issa Khalil, Ting Yu, and Marc Dacier. A survey on malicious
domains detection through dns data analysis. ACM Comput. Surv., 51(4), July
2018.

[6] Hang Hu, Steve T.K. Jan, Yang Wang, and Gang Wang. Assessing browser-level
defense against idn-based phishing. In 30th USENIX Security Symposium (USENIX
Security 21). USENIX Association, August 2021.

[7] Lieven Desmet, Jan Spooren, Thomas Vissers, Peter Janssen, and Wouter Joosen.
Premadoma: An operational solution to prevent malicious domain name reg-
istrations in the .eu tld. Digital Threats: Research and Practice, 2(1), January
2021.

[8] Arijit Das, Ankita Das, Anisha Datta, Shukrity Si, and Subhas Barman. Deep
approaches on malicious url classification. In 2020 11th International Conference

on Computing, Communication and Networking Technologies (ICCCNT), pages
1–6, 2020.

[9] Maria Sameen, Kyunghyun Han, and Seong Oun Hwang. Phishhaven—an efficient

real-time ai phishing urls detection system. IEEE Access, 8:83425–83443, 2020.

Security Centre.
activity 20 April 2020.

[10] Australian Signals Directorate’s Australian Cyber

cyber

Threat update: COVID-19 malicious
https://www.cyber.gov.au/sites/default/files/2020-04/ACSC-Threat-Update-
COVID-19-Malicious-Cyber-Activity-20200420.pdf. Accessed 2021-05-12.
[11] Sathvik Prasad, Elijah Bouma-Sims, Athishay Kiran Mylappan, and Bradley
Reaves. Who’s calling? characterizing robocalls through audio and metadata
analysis. In 29th USENIX Security Symposium (USENIX Security 20), pages 397–414.
USENIX Association, August 2020.

[12] Hongyu Gao, Jun Hu, Christo Wilson, Zhichun Li, Yan Chen, and Ben Y. Zhao.
Detecting and characterizing social spam campaigns. In Proceedings of the 10th
ACM SIGCOMM Conference on Internet Measurement, IMC ’10, page 35–47, New
York, NY, USA, 2010. Association for Computing Machinery.

[13] Michael Weber, Jun Wang, and Yuchen Zhou. Unsupervised clustering for identi-
fication of malicious domain campaigns. In Proceedings of the First Workshop on
Radical and Experiential Security, RESEC ’18, page 33–39, New York, NY, USA,
2018. Association for Computing Machinery.

[14] Oleksii Starov, Yuchen Zhou, Xiao Zhang, Najmeh Miramirkhani, and Nick
Nikiforakis. Betrayed by your dashboard: Discovering malicious campaigns via
web analytics. In Proceedings of the 2018 World Wide Web Conference, WWW ’18,
page 227–236, Republic and Canton of Geneva, CHE, 2018. International World
Wide Web Conferences Steering Committee.

[15] Adam Oest, Penghui Zhang, Brad Wardman, Eric Nunes, Jakub Burgis, Ali Zand,
Kurt Thomas, Adam Doupé, and Gail-Joon Ahn. Sunrise to sunset: Analyzing the
end-to-end life cycle and effectiveness of phishing attacks at scale. In 29th USENIX
Security Symposium (USENIX Security 20), pages 361–377. USENIX Association,
August 2020.

[16] Hung Le, Quang Pham, Doyen Sahoo, and Steven C. H. Hoi. Urlnet: Learning a

url representation with deep learning for malicious url detection, 2018.

[17] Tim Berners-Lee, Larry M Masinter, and Mark P. McCahill. Uniform Resource

Locators (URL). RFC 1738, December 1994.

[18] Sangho Lee and Jong Kim. WarningBird: A Near Real-Time Detection System for
Suspicious URLs in Twitter Stream. IEEE Transactions on Dependable and Secure
Computing, 10(3):183–195, May 2013. Conference Name: IEEE Transactions on
Dependable and Secure Computing.

[19] Bradley Reaves, Logan Blue, Dave Tian, Patrick Traynor, and Kevin R.B. Butler.
Detecting SMS Spam in the Age of Legitimate Bulk Messaging. In Proceedings
of the 9th ACM Conference on Security & Privacy in Wireless and Mobile Net-
works, WiSec ’16, pages 165–170, New York, NY, USA, July 2016. Association for
Computing Machinery.

[20] Florian Quinkert, Martin Degeling, Jim Blythe, and Thorsten Holz. Be the Phisher
– Understanding Users’ Perception of Malicious Domains. In Proceedings of the
15th ACM Asia Conference on Computer and Communications Security, ASIA CCS
’20, pages 263–276, New York, NY, USA, October 2020. Association for Computing
Machinery.

[21] Federal Bureau of Investigation. Cyber Actors Exploit ’Secure’ Websites In
Phishing Campaigns. https://www.ic3.gov/Media/Y2019/PSA190610. Accessed
2021-05-24.

[22] .au Domain Administration Ltd. About .au Domain Administration. https://www.
auda.org.au/about-auda/about-au-domain-administration. Accessed 2021-05-24.
[23] Justin Ma, Lawrence K. Saul, Stefan Savage, and Geoffrey M. Voelker. Learning to
detect malicious URLs. ACM Transactions on Intelligent Systems and Technology,
2(3):30:1–30:24, May 2011.

[24] Peng Peng, Limin Yang, Linhai Song, and Gang Wang. Opening the Blackbox
of VirusTotal: Analyzing Online Phishing Scan Engines. In Proceedings of the
Internet Measurement Conference, IMC ’19, pages 478–485, New York, NY, USA,
October 2019. Association for Computing Machinery.

[25] Linhai Song, Heqing Huang, Wu Zhou, Wenfei Wu, and Yiying Zhang. Learning
from Big Malwares. In Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop
on Systems, APSys ’16, pages 1–8, New York, NY, USA, August 2016. Association
for Computing Machinery.

[26] Shuofei Zhu, Ziyi Zhang, Limin Yang, Linhai Song, and Gang Wang. Benchmark-
ing Label Dynamics of VirusTotal Engines. In Proceedings of the 2020 ACM SIGSAC
Conference on Computer and Communications Security, CCS ’20, pages 2081–2083,
New York, NY, USA, October 2020. Association for Computing Machinery.
[27] Binlin Cheng, Jiang Ming, Jianmin Fu, Guojun Peng, Ting Chen, Xiaosong Zhang,
and Jean-Yves Marion. Towards paving the way for large-scale windows mal-
ware analysis: Generic binary unpacking with orders-of-magnitude performance
boost.
In Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, pages 395–411, 2018.

[28] Doowon Kim, Bum Jun Kwon, and Tudor Dumitraş. Certified malware: Measuring
breaches of trust in the windows code-signing pki. In Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security, pages 1435–1448,
2017.

Redacted Conference, December, 2021, Somewhere on Earth

Almashor et al.

[54] Simon Bell and Peter Komisarczuk. An analysis of phishing blacklists: Google
In Proceedings of the Australasian

safe browsing, openphish, and phishtank.
Computer Science Week Multiconference, pages 1–11, 2020.

[55] JoeSandboxCloud. Analysis report ubar-pro4[.]ru. https://www.joesandbox.com/

analysis/229408/0/html. Accessed: 2021-05-31.

[56] Sophos News.

Nearly a quarter of malware now communicates using
tls. https://news.sophos.com/en-us/2020/02/18/nearly-a-quarter-of-malware-
now-communicates-using-tls/. Accessed: 2021-05-31.

[57] Yukun Li, Zhenguo Yang, Xu Chen, Huaping Yuan, and Wenyin Liu. A stacking
model using URL and HTML features for phishing webpage detection. Future
Generation Computer Systems, 94:27–39, May 2019.

[29] Doowon Kim, Bum Jun Kwon, Kristián Kozák, Christopher Gates, and Tudor
Dumitras, . The broken shield: Measuring revocation effectiveness in the windows
code-signing {PKI}. In 27th {USENIX} Security Symposium ({USENIX} Security
18), pages 851–868, 2018.

[30] David Korczynski and Heng Yin. Capturing malware propagations with code
injections and code-reuse attacks. In Proceedings of the 2017 ACM SIGSAC Con-
ference on Computer and Communications Security, pages 1691–1708, 2017.
[31] Chaz Lever, Platon Kotzias, Davide Balzarotti, Juan Caballero, and Manos Anton-
akakis. A lustrum of malware network communication: Evolution and insights.
In 2017 IEEE Symposium on Security and Privacy (SP), pages 788–804. IEEE, 2017.
[32] Bo Li, Phani Vadrevu, Kyu Hyung Lee, Roberto Perdisci, Jienan Liu, Babak Rah-
barinia, Kang Li, and Manos Antonakakis. Jsgraph: Enabling reconstruction of
web attacks via efficient tracking of live in-browser javascript executions. In
NDSS, 2018.

[33] Janos Szurdi and Nicolas Christin. Email typosquatting. In IMC, pages 419–431,

2017.

[34] Haoyu Wang, Zhe Liu, Jingyue Liang, Narseo Vallina-Rodriguez, Yao Guo, Li Li,
Juan Tapiador, Jingcun Cao, and Guoai Xu. Beyond google play: A large-scale
comparative study of chinese android app markets. In IMC, pages 293–307, 2018.
[35] Michelle Y Wong and David Lie. Tackling runtime-based obfuscation in android
with {TIRO}. In 27th {USENIX} Security Symposium ({USENIX} Security 18),
pages 1247–1262, 2018.

[36] Dongpeng Xu, Jiang Ming, Yu Fu, and Dinghao Wu. Vmhunt: A verifiable
approach to partially-virtualized binary code simplification. In Proceedings of the
2018 ACM SIGSAC Conference on Computer and Communications Security, pages
442–458, 2018.

[37] Onur Catakoglu, Marco Balduzzi, and Davide Balzarotti. Automatic extraction
In Proceedings of the 25th

of indicators of compromise for web applications.
international conference on world wide web, pages 333–343, 2016.

[38] Geng Hong, Zhemin Yang, Sen Yang, Lei Zhang, Yuhong Nan, Zhibo Zhang, Min
Yang, Yuan Zhang, Zhiyun Qian, and Haixin Duan. How you get shot in the
back: A systematical study about cryptojacking in the real world. In Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communications Security,
pages 1701–1713, 2018.

[39] Najmeh Miramirkhani, Timothy Barron, Michael Ferdman, and Nick Nikiforakis.
Panning for gold. com: Understanding the dynamics of domain dropcatching. In
Proceedings of the 2018 World Wide Web Conference, pages 257–266, 2018.
[40] Alina Oprea, Zhou Li, Robin Norris, and Kevin Bowers. Made: Security analytics
In Proceedings of the 34th Annual Computer

for enterprise threat detection.
Security Applications Conference, pages 124–136, 2018.

[41] Ajaya Neupane, Nitesh Saxena, Keya Kuruvilla, Michael Georgescu, and Rajesh K
Kana. Neural signatures of user-centered security: An fmri study of phishing,
and malware warnings. In NDSS, 2014.

[42] Abbas Razaghpanah, Rishab Nithyanand, Narseo Vallina-Rodriguez, Srikanth
Sundaresan, Mark Allman, Christian Kreibich, and Phillipa Gill. Apps, trackers,
privacy, and regulators: A global study of the mobile tracking ecosystem. 2018.
[43] Armin Sarabi and Mingyan Liu. Characterizing the internet host population using
deep learning: A universal and lightweight numerical embedding. In Proceedings
of the Internet Measurement Conference 2018, pages 133–146, 2018.

[44] Mahmood Sharif, Jumpei Urakawa, Nicolas Christin, Ayumu Kubota, and Akira
Yamada. Predicting impending exposure to malicious content from user be-
havior. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, pages 1487–1501, 2018.

[45] Ke Tian, Steve TK Jan, Hang Hu, Danfeng Yao, and Gang Wang. Needle in a
haystack: Tracking down elite phishing domains in the wild. In Proceedings of
the Internet Measurement Conference 2018, pages 429–442, 2018.

[46] Liang Wang, Antonio Nappa, Juan Caballero, Thomas Ristenpart, and Aditya
Akella. Whowas: A platform for measuring web deployments on iaas clouds.
In Proceedings of the 2014 Conference on Internet Measurement Conference, pages
101–114, 2014.

[47] Zhaoyan Xu, Antonio Nappa, Robert Baykov, Guangliang Yang, Juan Caballero,
and Guofei Gu. Autoprobe: Towards automatic active malicious server probing
using dynamic binary analysis. In Proceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security, pages 179–190, 2014.

[48] Chaoshun Zuo and Zhiqiang Lin. Smartgen: Exposing server urls of mobile
apps with selective symbolic execution. In Proceedings of the 26th International
Conference on World Wide Web, pages 867–876, 2017.

[49] Sara Albakry, Kami Vaniea, and Maria K. Wolters. What is this URL’s Destination?
In Proceedings of the 2020 CHI
Empirical Evaluation of Users’ URL Reading.
Conference on Human Factors in Computing Systems, CHI ’20, pages 1–12, New
York, NY, USA, April 2020. Association for Computing Machinery.

[50] Nick Richard and Dimiter Andonov. The UNC2529 Triple Double: A Trifecta
Phishing Campaign, 2021. https://www.fireeye.com/blog/threat-research/2021/
05/unc2529-triple-double-trifecta-phishing-campaign.html.

[51] Google. Google safe browsing. https://safebrowsing.google.com/. Accessed:

2021-05-24.

[52] Openphish - phishing intelligence. https://openphish.com/. Accessed: 2021-05-24.
[53] Phishtank. https://www.phishtank.com/. Accessed: 2021-05-24.

