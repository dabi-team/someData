Resilient Control of Platooning Networked
Robotic Systems via Dynamic Watermarking

Matthew Porter, Arnav Joshi, Sidhartha Dey, Qirui Wu, Pedro Hespanhol
Anil Aswani, Matthew Johnson-Roberson, and Ram Vasudevan

1

1
2
0
2

n
u
J

4
1

]

C
O
.
h
t
a
m

[

1
v
1
4
5
7
0
.
6
0
1
2
:
v
i
X
r
a

Abstract—Networked robotic systems, such as connected ve-
hicle platoons, can improve the safety and efﬁciency of trans-
portation networks by allowing for high-speed coordination.
To enable such coordination, these systems rely on networked
communications. This can make them susceptible to cyber
attacks. Though security methods such as encryption or spe-
cially designed network topologies can increase the difﬁculty
of successfully executing such an attack, these techniques are
unable to guarantee secure communication against an attacker.
More troublingly, these security methods are unable to ensure
that individual agents are able to detect attacks that alter
the content of speciﬁc messages. To ensure resilient behavior
under such attacks, this paper formulates a networked linear
time-varying version of dynamic watermarking in which each
agent generates and adds a private excitation to the input of
its corresponding robotic subsystem. This paper demonstrates
that such a method can enable each agent in a networked
robotic system to detect cyber attacks. By altering measurements
sent between vehicles, this paper illustrates that an attacker
can create unstable behavior within a platoon. By utilizing the
dynamic watermarking method proposed in this paper, the attack
is detected, allowing the vehicles in the platoon to gracefully
degrade to a non-communicative control strategy that maintains
safety across a variety of scenarios.

I. INTRODUCTION

The adoption of intelligent

transportation systems (ITS)
promises to reduce road congestion while simultaneously
improving road user safety. Vehicle to vehicle (V2V) com-
munications, in particular, have been shown to improve efﬁ-
ciency and safety by enabling coordination [1], [2]. However,
this reliance on outside communication introduces additional
security concerns [3]–[5]. This paper considers the cooperative
task of vehicle platooning and illustrates that a malicious agent
can cause collisions by altering V2V communications within
a platoon. To address this challenge, we formulate a technique
that uses a private excitation added to the input of each vehicle
to identify whether an attack is taking place. The proposed

This work was supported by a grant from Ford Motor Company via the

Ford-UM Alliance under award N022977.

M. Porter, A. Joshi, and R. Vasudevan are with the Department of
Mechanical Engineering, University of Michigan, Ann Arbor, MI 48103 USA
(e-mail: matthepo@umich.edu; arnavj@umich.edu; ramv@umich.edu).

S. Dey is with the Robotics Institute, University of Michigan, Ann Arbor,

MI 48103 USA (e-mail: siddey@umich.edu).

Q. Wu is with the Department of Computer Engineering, University of

Michigan, Ann Arbor, MI 48103 USA (e-mail: wuqirui@umich.edu).

A. Aswani and P. Hespanhol are with the Department of Industrial Engineer-
ing and Operations Research, University of California Berkeley, Berkeley, CA
94720 USA (e-mail: aaswani@berkeley.edu; pedrohespanhol@berkeley.edu).
M. Johnson-Roberson is with the Department of Naval Architecture, Uni-
versity of Michigan, Ann Arbor, MI 48103 USA (e-mail: mattjr@umich.edu).

method enables individual vehicles within a platoon to identify
such attacks and gracefully degrade to a non-communicative
control strategy that ensures safe, resilient behavior of the
networked system.

A. Vehicle Platooning

Robotic vehicle platooning has been shown to decrease
fuel consumption by reducing air drag [6]–[9], while also
improving throughput on roads by reducing the occurrence of
bottlenecks [10], [11]. To achieve these performance improve-
ments without creating phantom trafﬁc jams or crashes [12],
[13], the longitudinal controller for these robotic platoons must
be string stable meaning that perturbations must be dampened
by subsequent vehicles in the string [14]–[18].

For platoons that do not rely on V2V communication, string
stability can be satisﬁed by maintaining a constant headway
between vehicles in the platoon [19]–[21]. Unfortunately,
since the headway is found by dividing the bumper-to-bumper
following distance by the speed, this leads to conservatively
sized gaps between vehicles that grow as the speed increases.
Since the reduction in air drag becomes less prominent as the
following distance increases, the methods that avoid utilizing
V2V communication are unable to achieve all the potential
energy efﬁciency beneﬁts of robotic vehicle platooning.

In contrast, for connected vehicles, the additional road user
information can be used to adopt a constant spacing policy
while still preserving string stability. Even under limited V2V
communication with just one or two neighboring vehicles
[22]–[27], energy efﬁciency and throughput can increase dra-
matically due to the reduction in following distance. However,
these communication channels introduce vulnerabilities to
cyber attacks.

B. Securing ITS

The use of ad-hoc networks to facilitate collaborative ac-
tions, such as in impromptu platooning, results in additional
security vulnerabilities. Namely, the trustworthiness of com-
munications received over the network is not guaranteed.
Therefore, to ensure the security of ITS, both the source of
a communication and the communication’s content must be
veriﬁed. The former has been widely studied as discussed
in Hussain et al. [28], Bagga et al. [29], and references
therein. The latter has received a good deal of attention as well
[30]. However, methods for deriving content trustworthiness
vary greatly. Some methods look for abnormalities in con-
tent without leveraging information on the underlying system

 
 
 
 
 
 
[31]–[33]. In contrast, model-aware methods incorporate a
system model in their trust analysis [34]–[38]. This allows for
plausibility of the content of a communication to be evaluated
in the context of the underlying system.

This paper focuses on one particular model-aware method,
dynamic watermarking, in which each vehicle generates and
adds a random excitation called a watermark to its inputs.
While each watermark is only known to the vehicle that gen-
erated it, the effect of each watermark propagates dynamically
through the state of the system and into the measurements of
surrounding vehicles. Each vehicle observes the correlation of
its watermark with the communicated measurements. Then,
using knowledge of the system dynamics, this correlation is
compared with the expected correlation under normal opera-
tion to decide if the communication content is trustworthy. In
doing so, dynamic watermarking has been shown to detect a
wider range of attack models than other methods while making
few assumptions on the underlying system model [39]–[41].
Originally, dynamic watermarking was derived for single
input single output (SISO) linear time-invariant (LTI) systems
[42], but extensions to multiple input multiple output (MIMO)
LTI systems [43], [44], networked LTI systems [35], switching
LTI systems [45], linear time-varying (LTV) systems [46],
[47], and simple non-linear systems have also been derived
[48], [49]. Furthermore, detecting attacks on connected vehicle
platoons using dynamic watermarking has also been previously
studied [35], [49]. However, each case makes a strict assump-
tion on the system model. In particular, Hespanhol et al. [35]
assumes that each vehicle observes the entire platoon state and
that the platoon maintains a constant velocity and road grade
allowing it to be modeled as a networked LTI system. While
the latter assumption is often satisﬁed in the current use case,
the expansion of ITS will allow for impromptu platooning
in less controlled environments where these assumptions are
no longer valid. More recently, Ko et al. [49] apply dynamic
watermarking to a nonlinear platoon model. This allows them
to make guarantees of detection directly for the nonlinear
system as opposed to a linearized approximation of the system.
However, their method does not readily extend beyond simple
kinematic models, which do not account for non-negligible
dynamic effects such as tire slip. As described in Kong et al.
[50], to realistically model a vehicle’s behavior one does need
to include such dynamic tire slip terms.

In this paper, we propose a new method of dynamic wa-
termarking developed around a networked LTV model. The
proposed method requires fewer assumption than Hespanhol
et al. [44] and, unlike Ko et al. [49], can be readily applied
to platoons with non-negligible dynamic effects.

C. Contributions

The contributions of this paper are threefold. First, we
develop a notion of dynamic watermarking for networked LTV
systems. In particular, we derive statistical tests for detecting
the presence of attacks. Second, we develop a mitigation
strategy that allows a robotic vehicle platoon to gracefully
degrade in the event of an attack. Third, networked LTV
dynamic watermarking is applied to a simulated platoon of

2

autonomous vehicles. The simulation uses empirically found
nonlinear dynamics to provide a realistic illustration of our
proposed method. Video of the simulated experiments can be
found in [51].

The remainder of this paper is organized as follows. Section
II overviews the notation used throughout the paper. Section
III outlines the problem of implementing attack detection for
robotic vehicle platoons and illustrates how the system can be
described using a networked LTV system. Section IV deﬁnes
a general controller and observer structure and makes some
assumptions on the system. Section V derives the statistical
tests for distributed attack detection using the generalized
networked LTV system. Section VI provides practical methods
for implementing the statistical tests on a real-world system.
Section VII derives two robotic vehicle platoon controllers
and observers that satisfy the conditions outlined in Section
IV. In addition, a third controller and observer that does
not use V2V communication is also derived to facilitate a
graceful degradation of the platoon in the event of an attack.
Section VIII illustrates the ability of the proposed algorithm
to detect attacks using a simulated vehicle platoon. We draw
conclusions in Section IX.

II. NOTATION

This section describes the notation used throughout
the
remainder of this paper. We denote a variable X for vehicle i
at step n by Xi,n. The zero matrix of size i by j is denoted
0i×j. The identity matrix of size i is denoted Ii. The block
diagonal matrix with the blocks M1, M2, M3, · · · on the
diagonal is denoted diag(M1, M2, M3, · · · ). The cardinality
of a set H is denoted card(H).

The Wishart distribution with scale matrix Σ and i degrees
of freedom is denoted W(Σ, i) [52, Section 7.2]. The multi-
variate Gaussian distribution with mean µ and covariance Σ
is denoted N (µ, Σ). The matrix Gaussian distribution with
mean M, and parameters Σ and Ω is denoted N (M, Σ, Ω).
The expectation of a random variable a is denoted E[a].

III. ROBOTIC VEHICLE PLATOONING

This section illustrates the ability of an LTV system model
to describe a robotic vehicle platoon. The general approach is
discussed and the resulting system is presented. A thorough
derivation of the LTV system used in this work can be found
in Appendix A. Whereas previous literature in platooning
has often assumed a constant velocity, the use of an LTV
system model can describe platooning with fewer assumptions.
Moreover, this system model provides a general structure for
deriving networked LTV dynamic watermarking.

The task of vehicle platooning is often broken into two
components, lane keeping and vehicle following [53]. The
objective of lane keeping is to minimize the lateral error i.e.
the distance to the nearest point on the trajectory. The task
of vehicle following, as described in Section I-A, attempts
to maintain a constant distance or a constant headway to
the preceding vehicle in the platoon. Note that
the lead
vehicle attempts to maintain a minimum headway when near
other vehicles and a desired velocity otherwise. In this work,

3

Fig. 1: The platooning state at step n is described by the velocity of each vehicle v1,n, . . . , vκ,n and the distances between vehicles d1,n, . . . , dκ−1,n. The
distance from a vehicle in an arbitrary position i to the lead vehicle is di,n.

we focus on the task of vehicle following since it requires
V2V communication to reduce following distances between
vehicles. However, we also describe our lateral dynamics in
Appendix A for the sake of completeness.

We start with the empirically found non-linear model







=







˙x
˙y
˙ψ
˙v







v cos ψ − ˙ψ(c8 + c9v2) sin ψ
v sin ψ + ˙ψ(c8 + c9v2) cos ψ
tan(c1δ+c2)v
c3+c4v2
c5 + c6(v − vd) + c7(v − vd)2







,

(1)

where (x, y) are the ground plane coordinates, ψ is the vehicle
heading, v is the forward velocity, δ is the desired steering
angle, vd is the desired velocity, and c1, . . . , c9 are ﬁtted
constants which can be found in Table IV in the appendix.
This model attempts to capture both the non-linear dynamics
of the power-train and various dynamic effects such as tire
slip. Namely, the constants c1 and c2 are used to calibrate
the steering angle, c4 and c9 are used to model the effect of
tire slip on the angular and lateral velocities, and c5, c6, and
c7 are used to approximate the drive train. Note that when
˙y, and ˙ψ follow
c4 = 0 and c9 = 0 the equations for ˙x,
from [54, Table 2.1] for a proper selection of c3 and c4. The
state of the longitudinal dynamics for a platoon of κ vehicles,
as illustrated in Figure 1, consists of each vehicle’s velocity
v1,n, . . . , vκ,n, and the distances between subsequent vehicles
d1,n, . . . , dκ−1,n. For convenience we deﬁne

where wn is the process noise and matrices An and Bi,n are
deﬁned in Appendix A.

Since the vehicle following task only seeks to maintain a
desired velocity and spacing policy, any longitudinal error with
respect to a predeﬁned trajectory will not be corrected by
the controller. As a result, the position of the platoon can
drift along the trajectory. Though this drift does not affect the
derivations in this section, it does pose a practical problem
which we resolve in Section VI.

We assume each vehicle is able to measure its own location,
velocity, and the distance to the previous vehicle in the platoon.
Using the location measurements, the lateral error and heading
error are calculated for the lane keeping task. For the vehicle
following task the measurements for vehicle i at step n satisfy

yi,n = Cixn + zi,n, i ∈ {1, . . . , κ},

(4)

where zi,n is the measurement noise and Ci,n takes one of two
forms depending on the choice of controller. In the ﬁrst case,
the leader measures its own velocity, while each of the other
vehicles measures both their own velocity and the distance to
the preceding vehicle. In the second case, we assume that the
ﬁrst vehicle also communicates its location along the trajectory
which can be used by other vehicles to calculate the distance to
the lead vehicle. However, we model this as the ﬁrst vehicle
also measuring the distance to all following vehicles. Both
versions of the matrix Ci,n can be found in Appendix A.

di,n =

i−1
(cid:88)

j=1

di,n

(2)

IV. NETWORKED LTV SYSTEM

to denote the distance from the lead vehicle to vehicle i in
the platoon. In this paper, the distance between vehicles is
measured along the trajectory based on the center of each
vehicle. This simpliﬁes notation while still allowing for vehicle
length to be accounted for in the platoons desired trajectory.
With the help of a few assumptions, we linearize and
discretize these dynamics about a desired trajectory de-
noted {¯xi,n, ¯yi,n, ¯ψi,n, ¯vi,n, ¯vd
n=0 for a step size of
0.05 seconds. Following the linearization and discretization,
take the form xn =
the state vector and input vector
[∆d1,n · · · ∆dκ−1,n ∆v1,n · · · ∆vκ,n](cid:124) and ui,n = ∆vd
i,n
respectively where ∆di,n = di,n − ¯di,n, ∆vi,n = vi,n − ¯vi,n,
and ∆vd
i,n. The resulting LTV system then
satisﬁes

i,n, ¯δi,n}∞

i,n = vd

i,n − ¯vd

xn+1 = Anxn +

κ
(cid:88)

i=1

Bi,nui,n + wn,

(3)

This section provides necessary assumptions on the system
noise, deﬁnes a generic controller and observer structure, and
derives the closed loop dynamics. This added structure allows
us to formulate our proposed detection algorithm.

Consider an LTV system of κ vehicles satisfying (3) and
(4), where xn, wn ∈ Rp, ui,n ∈ Rqi, yi,n, zi,n ∈ Rmi . We
then make the following assumption.

Assumption IV.1. The process and measurement noise are
mutually independent and Gaussian distributed such that

wn ∼ N (0p×1, Σw,n),
zi,n ∼ N (0mi×1, Σzi,n).

(5)

(6)

While the linearization of non-linear systems, generally does
not result in Gaussian distributed noise, this assumption allows
us to derive our proposed method using a statistical basis.
Furthermore, this assumption has not hindered the efﬁcacy of
LTV dynamic watermarking in non-networked settings [47].

The communication from vehicle j to vehicle i at step n is

denoted s(i,j),n and takes the form

s(i,j),n = yj,n + a(i,j),n,

(7)

where a(i,j),n is an additive attack on the communication
channel. In the platoon, this style of attack can take the form
of a man in the middle, where the attacker intercepts and
alters measurements being communicated between vehicles, or
a malicious vehicle that sends out false measurements. Since
vehicle i already has its own measurement, the additive attack
a(i,i),n is zero for i ∈ {1, . . . , κ}. To reduce computational
overhead, particularly in larger platoons, some V2V commu-
nications may not be used. We deﬁne the following set to ease
later notation.

H ⊆ ({1, . . . , κ} × {1, . . . , κ}) ,

(8)

where the communication from vehicle j to vehicle i is active
if (i, j) ∈ H. Moreover, we deﬁne the set

Hi = {j|(i, j) ∈ H},

(9)

which contains the indices of vehicles that send measurements
to vehicle i.

The input from vehicle i comes in the form

ui,n = Ki,n ˆxi,n + ei,n,
(10)
where Ki,n is a user deﬁned control gain and ei,n ∈ Rqi is the
watermark generated by vehicle i. The watermark is Gaussian
distributed such that ei,n ∼ N (0qi×1, Σei) and is mutually
independent with zi,n, wn. Vehicle i observes a subset of the
platoons state denoted ˆxi,n using the linear functional observer

ˆxi,n+1 = Mi,n ˆxi,n + NiBi,nei,n −

(cid:88)

j∈Hi

L(i,j),ns(i,j),n,

(11)

where the gain L(i,j),n and update matrix Mi are user deﬁned.
This observer follows a discrete time version of the observer
ﬁrst introduced in Luenberger [55]. However, since the water-
mark of other vehicles is unknown to vehicle i their input is
not included in (11).

Next we derive the closed loop dynamics. For ease of
notation, we combine each vehicle’s measurement noise and
watermark such that
n = (cid:2)z
z(cid:124)

z(cid:124)
κ,n

(cid:124)
1,n

(12)

(cid:3) ,

· · ·
Σz,n = diag(Σz1,n, . . . , Σzκ,n),
· · ·

(cid:3) ,
n = (cid:2)e
e(cid:124)
Σe = diag(Σe1, . . . , Σeκ).

e(cid:124)
κ,n

(cid:124)
1,n

The additive attacks are also combined such that
(cid:104)
(cid:124)
(cid:124)
a
i,n =
a
(i,1),n
n = (cid:2)a
(cid:124)
a(cid:124)
1,n

(cid:124)
a
(i,κ),n

a(cid:124)
κ,n

(cid:3) .

· · ·

· · ·

(cid:105)

,

Then we can write the closed loop system as

¯xn+1 = ¯An ¯xn + ¯Bnen +








wn
0
...
0








− ¯Ln








0
zn + a1,n
...
zn + aκ,n

(13)

(14)

(15)

(16)

(17)








,

(18)

4

n = (cid:2)x(cid:124)

(cid:3), and ¯An, ¯Bn, and ¯Ln
where ¯x(cid:124)
are found in Appendix B. On the closed loop system we make
the following assumption.

(cid:124)
ˆx
1,n

ˆx(cid:124)
κ,n

· · ·

n

Assumption IV.2. Consider a closed loop system satisfying
(18). If a(i,j),n = 0mi×1 for all (i, j) ∈ H and n ∈ N, there
exists positive constants η1, η2 ∈ R such that

(cid:107)E[¯xn ¯x(cid:124)

n](cid:107) < η1,
n]−1(cid:1) (cid:107) < η2.

(cid:107) (cid:0)E[¯xn ¯x(cid:124)

(19)

(20)

This assumption ensures that, despite being time varying, the
covariance of the closed loop system and its inverse are well
deﬁned for all time. For the system in this paper, (19) holds
since the controllers and observers we later derive render the
system stable. Furthermore, we note that our system also
satisﬁes (20) as a result of the system noise propagating
through the state vector.

V. NETWORKED LTV TESTS

This section derives the statistical tests for networked LTV
dynamic watermarking. These tests utilize the difference be-
tween the observed state and the measured state called the
measurement residual. The measurement residual for each
(i, j) ∈ H is formally deﬁned as

r(i,j),n = U(i,j) ˆxi,n − W(i,j)s(i,j),n,
where r(i,j),n ∈ Rp(i,j) . Furthermore, the matrices U(i,j) and
W(i,j),n are deﬁned such that

(21)

U(i,j)Ni = W(i,j)Cj ∀(i, j) ∈ H.

(22)

Here, the matrices U and W are used to select the common
state information between the observed state for vehicle i and
measurement from vehicle j.

The proposed detection scheme focuses on the covariance of
the measurement residual r(i,j),n and its correlation with the
watermark ei,n−ρ(i,j)−1 where ρ(i,j) is a user deﬁned delay.
In the case that the delayed watermark is correlated with the
common state information of the un-attacked measurement,
an attacker cannot scale the true measurement signal without
altering this correlation. As a result, monitoring the water-
marks correlation with the measurement residual (which is a
function of the measurement) allows our proposed algorithm
to detect attacks that scale or remove the true measurement.
To ensure a correlation between the delayed watermark and
the common state information of the measurement, ρ(i,j) is
selected to account for the time needed for the watermark
to propagate through the system and into the measurement
s(i,j),n. For example, suppose vehicle i adds ei,n to its
desired velocity input vd
i,n at step n. The effect of ei,n
will be seen in vehicle i’s velocity measurement and vehicle
i + 1’s distance measurement at step n + 1. However, vehicle
i + 2’s measurement will require additional time for the effect
of ei,n to be seen in its measurement. Though in general
there is no guarantee that a given vehicles watermark will
eventually propagate through the entire system, by our choice
of controllers and corresponding communication structures, we
guarantee the existence of a ρ(i,j) that ensures a correlation

between ei,n−ρ(i,j)−1 and W(i,j)s(i,j),n for each (i, j) ∈ H.
Moreover, given a particular ρ(i,j) we provide a sufﬁcient
condition for a non-zero correlation in Appendix D.

To monitor both the covariance of the measurement residual
and its correlation with the watermark, we aim to observe the
(i,j),n](cid:124),
normalized outer product of the vector [e
which follows a Gaussian distribution when the platoon is un-
attacked such that
(cid:20)ei,n−ρ(i,j)−1
r(i,j),n

0(p(i,j)+qi)×1, Σ(i,j),n

(cid:124)
i,n−ρ(i,j)−1 r

∼ N

(23)

(cid:17)

(cid:16)

(cid:21)

(cid:124)

.

To this end, we start by deﬁning a matrix normalizing factor
similar to that of Porter et al. [46]

V(i,j),n = Σ− 1

2

(i,j),n,

(24)

to create a new vector with constant covariance
(cid:20)ei,n−ρi,j −1
r(i,j),n

¯r(i,j),n = V(i,j),n

(cid:21)

∼ N (0(p(i,j)+qi)×1, I). (25)

Next, we form the matrix

P(i,j),n = (cid:2)¯r(i,j),n−(cid:96)(i,j)+1

· · ·

¯r(i,j),n

(cid:3) ,

(26)

which, under the assumption of no attack, is distributed as

P(i,j),n ∼ N

(cid:16)

0(p(i,j)+qi)×(cid:96)(i,j) , Ip(i,j)+qi, G(i,j),n

(cid:17)

,

(27)

where

G(i,j),n =

E[P

(cid:124)
(i,j),nP(i,j),n]
p(i,j) + qi

.

(28)

Note that the values of V(i,j),n and G(i,j),n can be derived
as functions of the dynamics and the covariances of the
watermarks, process noise, and measurement noise. However,
in real word applications these covariances must be approx-
imated. To avoid compounding error, we derive methods for
approximating both V(i,j),n and G(i,j),n in Section VI. Finally,
we form the matrix

S(i,j),n = P(i,j),nG−1

(i,j),nP

(cid:124)
(i,j),n,

(29)

which is distributed according to a Wishart distribution with
scale matrix Ip(i,j)+qi i.e.

5

Algorithm 1: Longitudinal Control for Vehicle i

set cntrl lvl=3 (resp. 2);
set ˆxi,0 = 0pi;
set n = 0;
set Hi using (39) (resp. (41)) and (9);
Loop

for j ∈ Hi do
get s(i,j),n;
set detect(i,j),n = 0;
if n > ρ(i,j) and cntrl lvl(cid:54)=1 then
set V(i,j),n = ¯V(i,j),hi(n);
set ¯r(i,j),n using (25);

end
if n > ρ(i,j) + (cid:96)(i,j) then

set G(i,j),n = ¯G(i,j),hi(n);
set L(i,j),n using (26), (29), and (31);
if L(i,j),n > Threshold(i,j) then

set detect(i,j),n=1;

end
if ((cid:80)n

k=n−39 detect(i,j),n) > 24 then

set cntrl lvl=1;
reformat ˆxi,n

end

end

end
ﬁnd hi(n) from high res. trajectory;
set {¯vj,n, ¯vd
j,hi(n)};
if cntrl lvl=3 (resp. 2) then

j,n} = {vj,hi(n), vd

set Mi,n, Ki,n using (73),(40) (resp. (75),(44));
for j ∈ Hi do

set L(i,j),n using (81) (resp. (83)-(86));

end
sample ei,n;
set ui,n = Ki,n ˆxi,n + ei,n + ¯ui,n;

else

set Mi,n, L(i,i),n, Ki,n using (77),(88),(47);
set ui,n = Ki,n ˆxi,n + ¯ui,n;

end
set ˆxi,n+1 using (11);
send ui,n;
set n = n + 1;

EndLoop

S(i,j),n ∼ W((cid:96)(i,j), Ip(i,j)+qi).

(30)

VI. CONSIDERATIONS FOR IMPLEMENTATION

Using this distribution, a statistical test can be implemented
using the negative log likelihood of the scale matrix given the
observation S(i,j),n

L(i,j) = (1 − (cid:96)(i,j) + p(i,j) + qi) log(|S(i,j),n|)+

+ trace(S(i,j),n).

(31)

If L(i,j) exceeds a user deﬁned threshold, vehicle i signals
that an attack has likely occurred. The threshold can be set to
satisfy a desired performance metric such as the false alarm
rate.

This section derives practical solutions to the issue of
drift along the trajectory as described in Section III. More
speciﬁcally, we devise a method for allowing the linearization
to drift along the trajectory by constructing the discretized
trajectory in a receding horizon fashion. Furthermore, we
derive an approximation scheme for the normalization matrices
used in the statistical tests that accommodates this drift as well.
We start by creating a high-resolution trajectory denoted
{xi,k, y
k=0 which uses a step size
i,k
i,k
1
10 of the step size used when discretizing the
0.005 s or
dynamics, controllers, and observers. At the nth 0.05 s step

i,k, δi,k}∞

, vi,k, vd

, ψ

of the system, vehicle i ﬁnds its closest point on the high-
resolution trajectory denoted hi(n), then sets

The auto-correlation normalizing matrices G(i,j),n can then
be approximated using (25)-(26) and the approximate matrix
normalization factor using the ensemble average

6

{¯xj,n, ¯yj,n, ¯ψj,n, ¯vj,n, ¯vd
, ψ

{xj,hi(n), y

j,hi(n)

j,n, ¯δj,n} =

, vj,hi(n), vd

j,hi(n), δj,hi(n)}

j,hi(n)

for each j ∈ {1, . . . , κ}. Note that the step in the high-
resolution trajectory found by each vehicle may differ due to
error in the following distances between vehicles. However,
this difference remains small since the longitudinal controller
regulates the following distance error.

Similarly to the discretized trajectory, the matrix normal-
izing factor V(i,j),n and the auto-correlation normalizing fac-
tor G(i,j),n are selected in a receding horizon fashion. We
accomplish this by approximating both normalizing factors
for each step in the high resolution trajectory then selecting
the appropriate normalizing factors at each 0.05 s step of the
system using the index of the high resolution trajectory hi(n).
To this end, we denote the sample covariance at index k of
the high-resolution trajectory using the ensemble average

¯Σ(i,j),k =

1
fi,k

τ ∗
(cid:88)

(cid:88)

(cid:34)

τ =1

h(τ )
i

(n)=k

e(τ )
i,n−ρ(i,j)−1

r(τ )
(i,j),n

(cid:35) (cid:34)

e(τ )
i,n−ρ(i,j)−1

r(τ )
(i,j),n

(33)

i

where the superscript (τ ) denotes the realization number, τ ∗ is
the total number of realizations, and fi,k = card({(τ, n) | τ ∈
{1, . . . , τ ∗}, h(τ )
(n) = k}). In the event that no samples are
available for a given k, we set ¯Σ(i,j),k = 0p(i,j)+qi
. Since we
are limited to having a ﬁnite number of realizations, there is
no guarantee that the sample covariance matrices all have a
sufﬁcient number of samples to be invertable. To overcome
this obstacle, we take a weighted average such that

¯V(i,j),k =

(cid:32)

1
bi,k

k+10
(cid:88)

(cid:15)=k−10

(cid:33)− 1

2

σ|k−(cid:15)| ¯Σ(i,j),k

,

(34)

where 0 < σ < 1 is used to reduce the weight of samples that
are farther away (we use σ = 0.8) and bk is the sum of the
weights for which samples exist

bi,k =

(cid:88)

σ|k−(cid:15)|.

(35)

(cid:15)=k−10,...k+10
fi,(cid:15)>0

Here, the range of indices in the summation was chosen such
that the number of realizations needed to ensure invertability of
¯V(i,j),n should be no more than the dimension of the sample
covariance matrix. However, the number of samples should
exceed this value to ensure a good approximation. Finally, the
matrix normalizing factor is approximated at each step as

V(i,j),n ≈ ¯V(i,j),hi(n).

(36)

¯G(i,j),k =

1
(p(i,j) + qi)gi,k
(cid:32)

×

(cid:88)

(32)

×

τ ∗
(cid:88)

τ =1

1
(n + 1) − h(τ )

i

×

(n)|

|h(τ )
i

(n)≤k

(n+1)>k

h(τ )
i
h(τ )
i
|k − h(τ )

i

(cid:16)

×

(n + 1)|

(cid:16)

P (τ )

(i,j),n

(cid:17)(cid:124)

+ |k − h(τ )

i

(n)|

(cid:16)

P (τ )

(i,j),n+1

(cid:17)(cid:124)

P (τ )

(i,j),n+
(cid:33)
,

(cid:17)

(i,j),n+1

P (τ )

(37)

where the superscript (τ ) denotes the realization number, τ ∗ is
the total number of realizations, and gi,k = card({(τ, n)|τ ∈
{1, . . . , τ ∗}, h(τ )
(n + 1) > k}). The auto-
i
correlation normalizing matrix is then approximated at each
step as

(n) ≤ k, h(τ )

i

G(i,j),n ≈ ¯G(i,j),hi(n).

(38)

(cid:35)(cid:124)

VII. CONTROLLER DESIGN

This section details the 3 different longitudinal controllers
utilized in the networked robotic system. In each case, we
provide a general control scheme and the parameters chosen
in this work based on their performance in the simulated
platoon. The level 3 and level 2 controllers both attempt to
maintain constant spacing between vehicles. However, they
utilize different communication strategies that allow us to
compare the beneﬁts of full communication between vehicles
in the platoon and a more limited communication strategy.
The level 1 controller attempts to maintain constant headway
without the aid of V2V communication. As a result, level 1
control strategy is used after an attack is detected, allowing the
platoon to gracefully degrade. Note that the lateral controller
has been included in Appendix C for completeness.

We assume that all vehicles in the platoon use the same
communication level and switch to the mitigation strategy
simultaneously when an attack is detected. For each level,
the longitudinal controller and observer follows the LTV form
(10)-(11) however the matrices Ki,n, L(i,j),n, Ni, Mi, U(i,j),
and W(i,j) are level dependent. Due to their size, the observer
matrices Ni, L(i,j),n, and Mi are located in Appendix E.

Level 3: To take advantage of full V2V communication
between the connected vehicles, a ”fully-connected” controller
and observer are devised. In this case

H = {1, . . . , κ} × {1, . . . , κ}

(39)

and the measurements follow the model
controller gains satisfy

in (4),(64). The

Ki,n =
(cid:104) 0.5
2(i−1) · · · 0.5

2(1)

−0.5

2(0) · · · −0.5

2(κ−i−1)

0.1

2(i−1) · · · 0.1

2(1)

−0.1

2(0) · · · −0.1

2(κ−i)

(cid:105)

(40)

for i ∈ {1, . . . , κ}. The idea here is to have each vehicle
react to the velocity and following distance error of all other
vehicles. In doing so, the watermark of each vehicle affects
all others in the platoon. Furthermore, the magnitude of the
control gains decays exponentially for vehicles further away in
the platoon to reduce the combined effect of the watermarks
especially in larger platoons.

As the platoon size increases, the number of communication
channels and corresponding incoming messages for each vehi-
cle increases. This problem along with other physical limiting
factors such as latency between vehicles at the ends of the
platoon can prove troublesome in larger, fully-connected pla-
toons. Along with these limitations, the fact that the visibility
of the watermark from vehicle i in vehicle j reduces as the
platoon positions i and j are further apart means there are
diminishing returns, from an attack detection standpoint, to
having level 3 communication in larger platoons.

Level 2: In light of the limitations associated with level 3,

a less connected strategy where

H = {(i, j) ∈ {1, . . . , κ}2 | j = 1 or |i − j| ≤ 1}

(41)

and measurements that follow the measurement model deﬁned
in (4), (65) are considered for the level 2 communication.
In this case, each vehicle observes a subset of the states.
Namely, its distance to the lead vehicle, preceding vehicle, and
following vehicle, and the velocities of each of these vehicles.
Next we derive the level 2 control strategy using inspiration
from Swaroop and Hedrick [25, Section 3.4], in which the
controller uses the state of the lead and preceding vehicles to
calculate a desired acceleration as

˙vi,n =

1
1 + γ1

[ ˙vi−1,n + γ1 ˙v1,n − (γ2 + 0.6)(vi,n − vi−1,n)+
− 0.6γ2(di−1,n − ¯di−1,n) − (γ3 + 0.6γ1)(vi,n − v1,n)+
+ 0.6γ3(di,n − ¯di,n)],
(42)

where γ1 is used to shift the relative gain from the acceleration
of the preceding vehicle to that of the leading vehicle, γ2
adjusts the control gains corresponding to following distance
and relative velocity to the previous vehicle, and γ3 adjusts
the control gains corresponding to the following distance and
relative velocity to the lead vehicle. To enact this control policy
we start by setting γ1 = 0.2, γ2 = 1, and γ3 = 1.2 to achieve
a spacing error attenuation rate of less than 0.5 [25, Equation
3]. Then, since our controller will specify the desired velocity
vd instead of the desired acceleration, we relate the two using
the partial derivative

∂ ˙vi,n
∂vd

i,n

= −1.2(c6 + 2c7(vi,n − vd

i,n)).

(43)

gain matrices satisfy

Ki,n =






×

0

(cid:104)
0 −2.92
(cid:104)
1.32
(cid:104)
0.72
(cid:104)
0.72

0.6

0.6

1

−1.2(c6 + 2c7(¯vi,n − ¯vd
(cid:105)
0

i,n))

×

2.92 −2.92

(cid:105)

0

1.32

1.6 −2.92

(cid:105)

0

1.32

1.6 −2.92

(cid:105)

0

7

i = 1

i = 2

i = κ

o/w,

(44)

with the corresponding observed state ˆxi,n approximating
Nixn as deﬁned in Table V located in Appendix E.

Level 1: In the event of an attack detection, communication
between agents in the network should be severed to mitigate
potential harm to the system. To maintain operation of the pla-
toon, the vehicles are able to switch to a non-communicative
platoon strategy such that

H = {(i, i) | i ∈ {1, . . . , κ}}.

(45)

Here each vehicle still measures and observes its own velocity
and the distance to the preceding vehicle.

The non-communicative level 1 controller is inspired by
the University of Michigan Transportation Research Institute’s
(UMTRI)’s algorithm for adaptive cruise control (ACC) [56,
Equation 1] which satisﬁes

vd
i,n = vi−1,n + φ1(fi−1,n − Thvi,n)+

+ φ2(vi−1,n − vi,n),

(46)

where φ1 is the control gain for the error in the headway,
fi−1,n is the bumper-to-bumper distance to the previous vehi-
cle, and φ2 is the control gain on the derivative of the following
distance. In this work, we set φ1 = 1, φ2 = 0.2, and Th = 1.
Since (46) is already linear the control gain Ki,n is written
directly as

Ki,n =

(cid:104)


(cid:104)


(cid:105)
−1

(cid:105)
1.2 −1.2

1

i = 1

i (cid:54)= 1,

(47)

with the corresponding observed state ˆxi,n approximating
Nixn as deﬁned in Table V located in Appendix E. Note that
a proportional gain is applied to the error in the lead vehicle’s
velocity since there is no preceding vehicle.

Since the level 1 control strategy is considered to be safe
from cyber attacks across communication channels, we do not
employ attack detection or a watermark after the switch is
made. Though the level 1 controller is less susceptible to cyber
attacks, it is unable to maintain constant following distances
without sacriﬁcing safety. In contrast, both the level 3 and
level 2 control strategies enable the use of constant following
distances. As a result, these strategies can lead to signiﬁcant
improvement in fuel economy and throughput on roads.

VIII. SIMULATED EXPERIMENTS

Further, we assume that the deviation in the acceleration of
the lead vehicle and preceding vehicle are negligible allowing
us to ignore the corresponding terms. The resulting controller

This section illustrates the effectiveness of networked LTV
dynamic watermarking on detecting attacks on V2V communi-
cation of platooning vehicles. The experiment is implemented

8

Fig. 3: Comparing LTV to LTI Dynamic Watermarking

between vehicles were computed over 20 simulations with and
without the added watermark. Table I shows the results for
each level controller. Since the level 1 controller is used only
after an attack is detected, we do not add a watermark to this
controller. From this comparison, we note that there is indeed
a reduction in performance resulting from the watermark as
illustrated by the increased standard deviation for both the
level 3 and level 2 controller. However, even with this reduced
performance, the level 3 and level 2 controller still maintain
a smaller following distance than the level 1 controller.

Without watermark With watermark

Level Mean
0.50
0.50
1.35

3
2
1

Std
0.01
0.02
0.21

Mean
0.50
0.49
-

Std
0.11
0.08
-

TABLE I: Aggregate statistics for bumper-to-bumper distance (m) using
20 un-attacked simulations for each controller/watermark combination. Each
simulation consists of a platoon of four vehicles following the trajectory in
Figure 2.

For each controller, the matrix normalization factor and
the auto-correlation normalizing factor were generated from
50 simulations using (33)-(36) and (37)-(38) respectively. To
illustrate the beneﬁt of using the matrix normalizing factor and
auto-correlation normalizing factor of the proposed method,
we provide a comparison to the LTI equivalent [35]. We
compute the matrix normalization factor and auto-correlation
normalizing factor for the LTI case as follows

V(i,j) =

6000
(cid:88)

V(i,j),n,

1
6001

n=0
G(i,j) = Ip(i,j)+qi,

(49)

(50)

where 6001 is the number of steps in the simulation.

For measurement s(3,4) we calculate the negative log like-
lihood using both the LTI and LTV normalizing factors for
20 un-attacked simulations as illustrated in Figure 3. While
the average negative log likelihood signal,
taken over 20
simulations, is similar for both the LTI and LTV case, the
actual signal for the LTI case shows far more spiking. As a
result, the threshold in the LTI case would likely need to be
set higher to avoid false alarms. However, a higher threshold
reduces the ability of the detector to identify attacks. Hence,
the LTV Dynamic Watermarking is superior for this system.
the attack thresholds are
computed to achieve a desired false alarm rate based on a

To select a robust

threshold,

Fig. 2: Reference trajectory of the lead vehicle in simulated platoon experi-
ments. Each simulation consists of three laps.

on a simulated platoon of four autonomous vehicles traveling
three times around the looped path illustrated in Figure 2. In
the simulation, the vehicles have a vehicle length of 0.5m and
drive according to the non-linear dynamics deﬁned in (1).

For simulations of the level 3 and 2 controllers, the platoon
was tasked with maintaining a 1m constant following distance
which was chosen based on the ability of each controller to
maintain the desired distance as shown in Table I. Simulations
of the level 1 controller had the platoon maintain a constant
headway of 1 second.

Process and measurement noise as deﬁned in (5) and (6)
were also added at each step n, where Σw,n = 1 × 10−6Ip,
and Σzi,n = diag(1 × 10−4, 1 × 10−3) for i ∈ {2, . . . , κ}.
For the lead vehicle, the measurement noise covariance is
Σz1,n = 1×10−3. However, for the special case where the dis-
tance from each vehicle to the lead vehicle di,n is treated as a
measurement the value Σz1,n = diag(1 × 10−4Iκ−1, 1 × 10−3)
is used instead. While the noise added to the system is
Gaussian, the state update between time steps is done using
the nonlinear dynamics in equation (1). This results in a non-
Gaussian distribution of the platoon state, which is meant to
better approximate the noise of a real-world system.

A. Dynamic Watermarking Setup

A watermark as deﬁned in (10) was added to each vehicles

input at each time step where

Σei = 0.25, ∀i ∈ {1, . . . , κ}.

(48)

While the watermark enables the detection of a wider range
of attacks, it also increases the noise in the system resulting
in reduced performance of the controller. This leads to a trade
off between performance and making sure the watermark is
sufﬁciently visible in the face of other noise sources. As
mentioned in Section I-A, the beneﬁt of V2V communications
in vehicle platooning stem from the reduction in following
distance under a constant spacing policy. Therefore, to observe
the reduction in performance due to the watermark, the mean
and standard deviation of the bumper-to-bumper distances

set of un-attacked trials. The false alarm rate is deﬁned as the
number of time steps above the attack threshold divided by
the total number of time steps. In this paper, 20 trials were
used to calculate the thresholds which achieved a false alarm
rate of 0.5%.

To decide when to switch to the level 1 controller, we count
the number of times each negative log likelihood has exceeded
its threshold in the last 40 steps. If this value exceeds 24 (60%)
for any given communication channel, the platoon switches
to the level 1 controller. The values of 60% and 40 steps
were chosen based on their ability to reduce the number of
unnecessary switches from false alarms while still avoiding
collisions in our simulated platoon.

B. Attack Schemes

In this paper, we considered two different types of attacks,
the stealthy replay attack and an aggressive attack. While these
attacks are not necessarily optimal, they are meant to represent
two possible approaches of an attacker: 1) to go unnoticed
while the effect of the attack slowly builds and 2) to make no
attempt at remaining stealthy while trying to affect the system
before a mitigation strategy can be implemented.

For a replay attack, the measurement signals (i.e. s(i,j),n)
from all or a subset of H communication channels from an
un-attacked realization are recorded and then played back
when the simulation is run for a separate realization. Since
an attack need not start at the beginning, we chose to start
the attack 100s after the start of the simulation. The replayed
measurements included the distance between vehicles and the
velocity of each vehicle in a platoon.

For the aggressive attack, we aimed to cause a collision as
quickly as possible. To generate the attack, the communication
channel from vehicle 1 to vehicle 2 (i.e. s(2,1),n) is hacked
and the velocity measurement is set to zero. The attack leads
vehicle 2 to believe the lead vehicle is braking and so brakes
as well. This results in vehicle 3, which receives the unaltered
measurement from the lead vehicle, to crash into vehicle 2.
While this attack scheme is overt, it only requires intercepting
a single communication channel and, if not mitigated quickly,
results in a crash. As with the replay attack, we start this attack
100s after the start of the simulation.

C. Simulation Results

To demonstrate the proposed detection algorithm, simu-
lations were run for the level 2 and 3 control methods
following Algorithm 1 with an attack scheme as described
in Section VIII-B. After an attack was detected as described
in Section VIII-A, the simulation was split into two concurrent
simulations of the platoon, one in which the platoon degrades
to the level 1 controller and one in which the platoon does
not. For the simulation, a crash was deﬁned as the bumper-to-
bumper distance between any two vehicles reaching 0 m.

For the simulations presented here, the replay attack in-
volved attacking all communication channels between ve-
hicles. However, even for simulations where a subset of
channels were replay attacked, the attack was detected in the
corresponding channels and the controller was successfully

9

able to degrade. This is important because even attacking a
subset of communication channels can result in a crash and
so being able to detect this in a timely manner is crucial. In
all cases, the attack was detected before any crash allowing
the platoon to gracefully degrade to the level 1 controller.

For the level 3 controller, we see the effects of the replay
attack in Figure 4. Even though the replay attack is subtle in
operation, it is still able to cause a crash if the platoon does
not degrade control schemes. However, the level 3 controller
appears resilient to the aggressive attack as illustrated in Figure
6 located in Appendix F. This is likely because the level
3 controller has a higher weighting on maintaining constant
distance than velocity according to the controller gain in (40).
In contrast, the level 2 controller appears to be more suscep-
tible to the aggressive attack. In Figure 5, the performance of
the level 2 controller worsens drastically under the aggressive
attack as vehicle 2 brakes and almost immediately collides
with vehicle 3 as a result. However, the level 2 controller is
more resilient to the replay attack, as seen in Figure 7 located
in Appendix F. This is likely because the level 2 controller
relies mainly on states that are measured directly.

D. Scaling the platoon size

To highlight the effect of scaling up the platoon size, we
ran the same simulated experiments on a platoon of ten
autonomous vehicles. In each realization,
the platoon was
subject to one of three possible attacks for both level 3 and 2
controllers: a replay attack on 30% of communication chan-
nels, a replay attack on 100% of channels, and an aggressive
attack (as described in Section VIII-B). For each realization,
the time of attack was randomly sampled from a range of
[100, 200]s and the subset of communication channels attacked
are randomly selected to avoid any bias from the trajectory or
speciﬁc communication channels.

For each controller, the matrix normalization factor and the
auto-correlation normalizing factor were generated from 100
un-attacked realizations. Attack thresholds are computed on
500 un-attacked realizations for a rate of false alarm of 0.1%.
The platoon switches to the level 1 control strategy when
the negative log likelihood exceeds the attack threshold for
18 steps in the last 40 steps (45%) for any communication
channel.

The results of comparing LTI vs LTV Dynamic Watermark-
ing for the level 3 and level 2 controllers are shown in Tables
II and III respectively. The results are shown for replay attack
1/ replay attack 2/ aggressive attack.

Successful detections
False alarms
Potential crashes
Actual crashes
No attack detected
and no crash caused
Mean detection
time (s)
Standard deviation
detection time (s)

LTI
1513/1494/1530
482/470/470

LTV
1903/1876/1913
88/78/87

1099/1997/24

4/36/0

1/0/0

8/46/0

1/0/0

2.771/2.823/0.905

2.701/2.587/0.957

3.118/3.125/0.041

3.812/3.576/0.363

TABLE II: Attack detection statistics for 2000 trials of level 3 controller.

10

Fig. 4: (top) Performance of the level 3 controller after a replay attack without switching to the level 1 controller and crashing soon thereafter. (middle)
Platoon switching to level 1 controller after detecting the attack and safely completing the entire trajectory. (bottom) Negative log likelihood of channel which
detected the replay attack ﬁrst.

Successful detections
False alarms
Potential crashes
Actual crashes
No attack detected
and no crash caused
Mean detection
time (s)
Standard deviation
detection time (s)

LTI
1880/1902/1968
103/98/32

LTV
1944/1987/1982
21/13/18

3/4/2000

0/0/0

17/0/0

0/0/0

35/0/0

2.193/0.907/1.099

1.925/0.901/0.899

10.221/0.075/0.031

9.003/0.077/0.022

TABLE III: Attack detection statistics for 2000 trials of level 2 controller.

the
From Tables II and III, potential crashes represent
number of realizations which would crash when not running
the dynamic watermarking attack detection. Looking at the
potential crashes, we see that the level 3 controller is more
robust to aggressive attacks whereas the level 2 controller is
more robust to replay attacks.

Actual crashes represent the number of realizations which
crashed while running the LTI or LTV dynamic watermarking
algorithm. These crashes result from the effect of the attack
on the platoon remaining below the user-deﬁned threshold
for detection. Selecting different user-deﬁned parameters can
reduce the number of actual crashes with the trade off of

potentially higher number of false alarms.

It is worth noting that for the level 3 controller, one replay
attack 1 realization using the LTI attack detection scheme and
one realization using the LTV scheme were not determined
successful detections, false alarms, or crashes. Upon further
investigation, we concluded that the platoon performance was
not affected by the attack in those realizations and so the
dynamic watermark algorithm was not able to successfully
detect the attack. A similar conclusion was made, looking
at replay attack 1 for the level 2 controller, for 17 and 35
realizations using the LTI and LTV attack detection schemes
respectively, where the replay attack did not deteriorate the
performance of the platoon signiﬁcantly and so there were
no crashes and no successful detection. These statistics are
recorded in Tables II and III as no attack detected and no
crash caused. Selecting different user-deﬁned parameters may
improve the detection rate for these realizations.

When comparing the LTV dynamic watermarking algorithm
to the LTI version, we see that the LTV attack detection
scheme has a greater number of successful attack detections
and lesser number of false alarms while maintaining a similar
number of crashes. This difference in performance is high-
lighted in Table II, where successful attack detection using

11

Fig. 5: (top) Performance of the level 2 controller after an aggressive attack without switching to the level 1 controller and crashing soon thereafter. (middle)
Platoon switching to level 1 controller after detecting the attack and safely completing the entire trajectory. (bottom) Negative log likelihood of channel which
detected the replay attack ﬁrst.

LTI dynamic watermarking is approximately 75% whereas
using LTV dynamic watermarking, we achieve approximately
95%. Increasing the user-deﬁned thresholds for the LTI attack
detection scheme led to a marginal decrease in number of
false alarms at the cost of a substantial increase in number
of crashes. Hence, the LTV dynamic watermarking is superior
for this system.

IX. CONCLUSION

In this paper, we formulated a linear-time varying version
of dynamic watermarking for networked robotic systems and
implemented it on a simulated platoon of autonomous ve-
hicles. We introduced different various levels of vehicle to
vehicle communication and deﬁned corresponding longitudinal
controllers two of which leveraged the extra information for
feedback control while the third does not rely on any vehicle to
vehicle communication and was used as a mitigation strategy
in the event of an attack. While detailing the statistical tests,
we provide implementation considerations on how to efﬁ-
ciently generate the normalization matrices used in the tests.
Compared to linear-time invariant dynamical watermarking,
we showed that the method proposed in this paper is superior
in that it provides a more consistent test metric. We described

two different attack schemes, one stealthy and one aggressive,
and showed that our algorithm could detect both types of
attack while utilizing each controller and successfully degrade
to a safe control strategy before a crash can occur.

REFERENCES
[1] B. van Arem, C. J. G. van Driel, and R. Visser, “The impact
of cooperative adaptive cruise control on trafﬁc-ﬂow char-
acteristics,” IEEE Transactions on Intelligent Transportation
Systems, vol. 7, no. 4, pp. 429–436, 2006.

[2] C. Englund, L. Chen, J. Ploeg, E. Semsar-Kazerooni, A.
Voronov, H. H. Bengtsson, and J. Didoff, “The grand coop-
erative driving challenge 2016: Boosting the introduction of
cooperative automated vehicles,” IEEE Wireless Communica-
tions, vol. 23, no. 4, pp. 146–152, 2016.

[3] M. Gerla and P. Reiher, “Securing the Future Autonomous
Vehicle: A Cyber-Physical Systems Approach,” in Securing
Cyber-Physical Systems, CRC Press, 2015, ch. 7, pp. 197–220.
[4] D. Dominic, S. Chhawri, R. M. Eustice, D. Ma, and A.
Weimerskirch, “Risk Assessment for Cooperative Automated
Driving,” in Proceedings of the 2nd ACM Workshop on Cyber-
Physical Systems Security and Privacy, 2016, pp. 47–58.
[5] M. Amoozadeh, A. Raghuramu, C. Chuah, D. Ghosal, H. M.
Zhang, J. Rowe, and K. Levitt, “Security Vulnerabilities of
Connected Vehicle Streams and Their Impact on Cooperative
Driving,” IEEE Communications Magazine, vol. 53, no. 6,
pp. 126–132, 2015.

[6] C. Bonnet and H. Fritz, “Fuel consumption reduction in a
platoon: Experimental results with two electronically coupled
trucks at close spacing,” SAE Technical Paper, Tech. Rep.,
2000.

[7] A. A. Alam, A. Gattami, and K. H. Johansson, “An exper-
imental study on the fuel reduction potential of heavy duty
vehicle platooning,” in 13th International IEEE Conference
on Intelligent Transportation Systems, 2010, pp. 306–311.

[8] K.-Y. Liang, J. M˚artensson, and K. H. Johansson, “Fuel-saving
potentials of platooning evaluated through sparse heavy-duty
vehicle position data,” in 2014 IEEE Intelligent Vehicles
Symposium Proceedings, IEEE, 2014, pp. 1061–1068.
[9] B. McAuliffe, M. Croken, M. Ahmadi-Baloutaki, and A.
Raeesi, “Fuel-economy testing of a three-vehicle truck
platooning system,” National Research Council Canada,
Aerospace Aerodynamics Laboratory, Tech. Rep. LTR-AL-
2017-000, 2017.

[10] C. C. Chien and P. Ioannou, “Automatic vehicle-following,”
in 1992 American Control Conference, 1992, pp. 1748–1752.
[11] R. Hall and C. Chin, “Vehicle sorting for platoon formation:
Impacts on highway entry and throughput,” Transportation
Research Part C: Emerging Technologies, vol. 13, no. 5-6,
pp. 405–420, 2005.

[12] Y. Sugiyama, M. Fukui, M. Kikuchi, K. Hasebe, A.
Nakayama, K. Nishinari, S.
ichi Tadaki, and S. Yukawa,
“Trafﬁc jams without bottlenecks—experimental evidence for
the physical mechanism of the formation of a jam,” New
Journal of Physics, vol. 10, no. 3, p. 033 001, 2008.
[13] M. R. Flynn, A. R. Kasimov, J.-C. Nave, R. R. Rosales, and
B. Seibold, “Self-sustained nonlinear waves in trafﬁc ﬂow,”
Phys. Rev. E, vol. 79, p. 056 113, 5 2009. [Online]. Available:
https://link.aps.org/doi/10.1103/PhysRevE.79.056113.
[14] R. Herman, E. W. Montroll, R. B. Potts, and R. W. Rothery,
“Trafﬁc dynamics: Analysis of stability in car following,”
Operations research, vol. 7, no. 1, pp. 86–106, 1959.
[15] K.-c. Chu, “Decentralized control of high-speed vehicular
strings,” Transportation science, vol. 8, no. 4, pp. 361–384,
1974.

[16] D Swaroop and J. K. Hedrick, “String stability of inter-
connected systems,” IEEE transactions on automatic control,
vol. 41, no. 3, pp. 349–357, 1996.
J. Ploeg, N. Van De Wouw, and H. Nijmeijer, “Lp string sta-
bility of cascaded systems: Application to vehicle platooning,”
IEEE Transactions on Control Systems Technology, vol. 22,
no. 2, pp. 786–793, 2013.

[17]

[18] S. Feng, Y. Zhang, S. E. Li, Z. Cao, H. X. Liu, and L. Li,
“String stability for vehicular platoon control: Deﬁnitions and
analysis methods,” Annual Reviews in Control, 2019.
[19] P. A. Ioannou and C.-C. Chien, “Autonomous intelligent cruise
control,” IEEE Transactions on Vehicular technology, vol. 42,
no. 4, pp. 657–672, 1993.

[20] D. Swaroop, J. K. Hedrick, C. Chien, and P. Ioannou, “A
comparision of spacing and headway control laws for automat-
ically controlled vehicles1,” Vehicle system dynamics, vol. 23,
no. 1, pp. 597–625, 1994.
J. Zhou and H. Peng, “String stability conditions of adap-
tive cruise control algorithms,” IFAC Proceedings Volumes,
vol. 37, no. 22, pp. 649–654, 2004.

[21]

[22] S. S. Stankovic, M. J. Stanojevic, and D. D. Siljak, “Decen-
tralized overlapping control of a platoon of vehicles,” IEEE
Transactions on Control Systems Technology, vol. 8, no. 5,
pp. 816–832, 2000.

[23] G. J. Naus, R. P. Vugts, J. Ploeg, M. J. van De Molengraft,
and M. Steinbuch, “String-stable cacc design and experimental
validation: A frequency-domain approach,” IEEE Transac-
tions on vehicular technology, vol. 59, no. 9, pp. 4268–4279,
2010.
J. Ploeg, D. P. Shukla, N. van de Wouw, and H. Nijmeijer,
“Controller synthesis for string stability of vehicle platoons,”

[24]

12

IEEE Transactions on Intelligent Transportation Systems,
vol. 15, no. 2, pp. 854–865, 2013.

[25] D. Swaroop and J. K. Hedrick, “Constant spacing strategies
for platooning in automated highway systems,” 1999.
[26] P. Seiler, A. Pant, and K. Hedrick, “Disturbance propagation
in vehicle strings,” IEEE Transactions on Automatic Control,
vol. 49, no. 10, pp. 1835–1842, 2004.

[27] L. Xiao, F. Gao, and Jiangfeng Wang, “On scalability of pla-
toon of automated vehicles for leader-predecessor information
framework,” in 2009 IEEE Intelligent Vehicles Symposium,
2009, pp. 1103–1108.

[28] R. Hussain, J. Lee, and S. Zeadally, “Trust in vanet: A survey
of current solutions and future research opportunities,” IEEE
Transactions on Intelligent Transportation Systems, pp. 1–19,
2020.

[29] P. Bagga, A. K. Das, M. Wazid, J. J. P. C. Rodrigues, and
Y. Park, “Authentication protocols in internet of vehicles:
Taxonomy, analysis, and challenges,” IEEE Access, vol. 8,
pp. 54 314–54 344, 2020.

[30] O. Y. Al-Jarrah, C. Maple, M. Dianati, D. Oxtoby, and
A. Mouzakitis, “Intrusion detection systems for intra-vehicle
networks: A review,” IEEE Access, vol. 7, pp. 21 266–21 289,
2019.

[31] A. Bezemskij, G. Loukas, R. J. Anthony, and D. Gan,
“Behaviour-based anomaly detection of cyber-physical attacks
on a robotic vehicle,” in 2016 15th International Conference
on Ubiquitous Computing and Communications and 2016
International Symposium on Cyberspace and Security (IUCC-
CSS), 2016, pp. 61–68.

[32] M. Kang and J. Kang, “A novel intrusion detection method
using deep neural network for in-vehicle network security,”
in 2016 IEEE 83rd Vehicular Technology Conference (VTC
Spring), 2016, pp. 1–5.

[33] M. M. Mehdi, I. Raza, and S. A. Hussain, “A game theory
based trust model for vehicular ad hoc networks (vanets),”
Computer Networks, vol. 121, pp. 152–172, 2017.

[34] N. Bißmeyer, S. Mauthofer, K. M. Bayarou, and F. Kargl,
“Assessment of node trustworthiness in vanets using data plau-
sibility checks with particle ﬁlters,” in 2012 IEEE Vehicular
Networking Conference (VNC), 2012, pp. 78–85.

[35] P. Hespanhol, M. Porter, R. Vasudevan, and A. Aswani,
“Statistical watermarking for networked control systems,” in
2018 Annual American Control Conference (ACC), 2018,
pp. 5467–5472.

[36] Y. Mo and B. Sinopoli, “Integrity attacks on cyber-physical
systems,” in Proceedings of the 1st International Conference
on High Conﬁdence Networked Systems, ser. HiCoNS ’12,
ACM, 2012, pp. 47–54.

[37] C. Murguia and J. Ruths, “CUSUM and Chi-squared Attack
Detection of Compromised Sensors,” in 2016 IEEE Confer-
ence on Control Applications (CCA), 2016, pp. 474–480.

[38] D. Umsonst and H. Sandberg, “Anomaly Detector Metrics
for Sensor Data Attacks in Control Systems,” in 2018 Annual
American Control Conference (ACC), 2018, pp. 153–158.

[39] S. Weerakkody, B. Sinopoli, S. Kar, and A. Datta, “Infor-
mation ﬂow for security in control systems,” in 55th IEEE
Conference on Decision and Control (CDC), 2016, pp. 5065–
5072.

[40] S. Weerakkody, O. Ozel, P. Grifﬁoen, and B. Sinopoli, “Active
detection for exposing intelligent attacks in control systems,”
in 2017 IEEE Conference on Control Technology and Appli-
cations (CCTA), 2017, pp. 1306–1312.

[41] M. Porter, A. Joshi, P. Hespanhol, A. Aswani, M. Johnson-
Roberson, and R. Vasudevan, “Simulation and real-world eval-
uation of attack detection schemes,” in 2019 Annual American
Control Conference (ACC), 2019, pp. 551–558.

[42] Y. Mo and B. Sinopoli, “Secure control against replay attacks,”
in 2009 47th Annual Allerton Conference on Communication,
Control, and Computing (Allerton), 2009, pp. 911–918.

[43] B. Satchidanandan and P. R. Kumar, “Dynamic Watermark-
ing: Active Defense of Networked Cyber-Physical Systems,”
Proceedings of the IEEE, vol. 105, no. 2, pp. 219–240, 2017.
[44] P. Hespanhol, M. Porter, R. Vasudevan, and A. Aswani,
“Dynamic Watermarking for General LTI Systems,” in 56th
IEEE Conference on Decision and Control (CDC), 2017,
pp. 1834–1839.

[45] P. Hespanhol, M. Porter, R. Vasudevan, and A. Aswani,
“Sensor switching control under attacks detectable by ﬁnite
sample dynamic watermarking tests,” IEEE Transactions on
Automatic Control (TAC), pp. 1–1, 2020.

[46] M. Porter, P. Hespanhol, A. Aswani, M. Johnson-Roberson,
and R. Vasudevan, “Detecting generalized replay attacks via
time-varying dynamic watermarking,” IEEE Transactions on
Automatic Control (TAC), pp. 1–1, 2020.

[47] M. Porter, S. Dey, A. Joshi, P. Hespanhol, A. Aswani, M.
Johnson-Roberson, and R. Vasudevan, “Detecting deception
attacks on autonomous vehicles via linear time-varying dy-
namic watermarking,” in 2020 IEEE Conference on Control
Technology and Applications (CCTA), 2020, pp. 1–8.
[48] W. H. Ko, B. Satchidanandan, and P. R. Kumar, “Theory and
implementation of dynamic watermarking for cybersecurity
of advanced transportation systems,” in 2016 IEEE Confer-
ence on Communications and Network Security (CNS), 2016,
pp. 416–420.

[49] W. H. Ko, B. Satchidanandan, and P. R. Kumar, “Dynamic
watermarking-based defense of transportation cyber-physical
systems,” ACM Transactions on Cyber-Physical Systems,
vol. 4, no. 1, pp. 1–21, 2019.
J. Kong, M. Pfeiffer, G. Schildbach, and F. Borrelli, “Kine-
matic and dynamic vehicle models for autonomous driving
control design,” in 2015 IEEE Intelligent Vehicles Symposium
(IV), 2015, pp. 1094–1099.

[50]

[51] M. Porter, A. Joshi, S. Dey, Q. Wu, P. Hespanhol, A. Aswani,
M. Johnson-Roberson, and R. Vasudevan, “Resilient control
of platooning networked robotic systems via dynamic water-
marking: Video,” 2020. [Online]. Available: www.roahmlab.
com/tro2020 platoon video.

[52] T. Anderson, An Introduction to Multivariate Statistical Anal-
ysis, ser. Wiley Series in Probability and Statistics. Wiley,
2003.

[53] X. Xu, J. W. Grizzle, P. Tabuada, and A. D. Ames, “Cor-
rectness guarantees for the composition of lane keeping and
adaptive cruise control,” IEEE Transactions on Automation
Science and Engineering, vol. 15, no. 3, pp. 1216–1229, 2018.
[54] R. Rajamani, Vehicle dynamics and control. Springer Science

& Business Media, 2011.

[55] D. Luenberger, “Observers for multivariable systems,” IEEE
Transactions on Automatic Control, vol. 11, no. 2, pp. 190–
197, 1966.

[56] P Fancher, H Peng, Z Bareket, C Assaf, and R Ervin,
“Evaluating the inﬂuences of adaptive cruise control systems
on the longitudinal dynamics of strings of highway vehicles,”
Vehicle System Dynamics, vol. 37, no. sup1, pp. 125–136,
2002.

APPENDIX

A. Derivation of LTV Dynamics

This section provides a thorough derivation of the lat-
eral and longitudinal dynamics used in this paper. Let
{¯xi(t), ¯yi(t), ¯ψi(t), ¯vi(t), ¯vd
i (t), ¯δi(t)} be the continuous states
and inputs that deﬁne the trajectory for vehicle i, and let
{¯xi,n, ¯yi,n, ¯ψi,n, ¯vi,n, ¯vd
n=0 be the corresponding sam-
pled trajectory for the discretized system. To ease notation we
drop the (t) from the continuous states.

i,n, ¯δi,n}∞

13

1) Lateral Dynamics: Consider the lateral error ∆lati and
heading error ∆ψi deﬁned as ∆lati = (yi − ¯yi) cos( ¯ψi) −
(xi − ¯xi) sin( ¯ψi) and ∆ψi = ψi − ¯ψi. We approximate the
continuous dynamics as follows.

∆ ˙ψi = ˙ψ − ˙¯ψ =

tan(c1δi + c2)vi
c1 + c4v2
i

−

tan(c1

¯δi + c2)¯vi

c3 + c4¯v2
i

≈

(tan(c1δi + c2) − tan(c1

c3 + c4¯v2
i

¯δi + c2))¯vi

,

=

(51)

where the second equality comes from (1) and the approxi-
mation from vi ≈ ¯vi and

˙∆lati = ( ˙yi − ˙¯yi) cos( ¯ψi) − ( ˙xi − ˙¯xi) sin( ¯ψi)+
(cid:0)(xi ¯xi) cos( ¯ψi) + (y)i ¯yi) sin( ¯ψi)(cid:1) =

− ˙¯ψi

≈ vi sin(∆ψi) + ˙ψi(c8 + c9v2

i ) cos(∆ψi)+

≈ ¯vi sin(∆ψi) +

− ˙¯ψi(c8 + c9¯v2

i ) =
(c8 + c9¯v2
c3 + c4¯v2
i
× (tan(c1δi + c2) cos(∆ψi) − tan(c1

i )¯vi

×

¯δi + c2)),

(52)

inequality comes

from (1) and (xi −
where the ﬁrst
¯xi) cos( ¯ψi) + (yi − ¯yi) sin( ¯ψi) ≈ 0, and the second from (1)
and vi ≈ ¯vi. These approximations are reasonable since the
longitudinal controller aims to maintain the desired velocity
and we reduce longitudinal error deﬁned as (xi − ¯xi) cos( ¯ψi)+
(yi − ¯yi) sin( ¯ψi) by accommoding drift along the trajectory.
Linearizing (51)-(52) then gives us

(cid:21)

(cid:20) ˙∆lati
˙∆ψi

(cid:20)0
0

=

(cid:21)

+

(cid:21) (cid:20)∆lati
∆ψi

¯vi
0
c1¯vi

+

cos2(c1

¯δi + c2)(c3 + c4¯v2
i )

(cid:21)
(cid:20)(c8 + c9¯v2
i )
1

∆δi,

(53)

where ∆δi = δi − ¯δi. Discretizing using a step size of 0.05 s
and a zero-order hold on ¯vi and δi then results in

(cid:21)

(cid:20)∆lati,n+1
∆ψi,n+1

(cid:20)1
0

=

¯vi,n
20
1

(cid:21) (cid:20)∆lati,n
∆ψi,n

(cid:21)

+

c1¯vi,n

+

×

cos2(c1
(cid:34)(cid:16) (c8+c9 ¯v2

¯δi,n + c2)(c3 + c4¯v2
+ ¯vi,n
800

i,n)

(cid:17)

(cid:35)

20

i,n)

∆δi,n.

×

(54)

1
20

Value
1.6615 × 10−5
−1.9555 × 10−7
3.619 × 10−6
4.382 × 10−7
−8.1112 × 10−2
−1.4736 × 100
1.2569 × 10−1
7.6459 × 10−2
−1.3991 × 10−2

Constant

c1
c2
c3
c4
c5
c6
c7
c8
c9

TABLE IV: Fitted constants for the nonlinear dynamics in Eq. (1)

2) Longitudinal Dynamics: The state of the longitudinal
dynamics for a platoon of κ vehicles, as illustrated in Figure
1, is made up of each vehicle’s velocity v1,n, . . . , vκ,n, and
the distances between subsequent vehicles d1,n, . . . , dκ−1,n.
Next, under the assumption that the tracking error for the
lane keeping controller is sufﬁciently small, we linearize the
longitudinal dynamics from (1) as

The measurement model satisﬁes (4) where the matrix C

takes the form

Ci =

(cid:104)

01×κ−1
(cid:34)

02×i−2






(cid:105)

1

01×κ−1

1
0

02×κ−1

0
1

i = 1

(cid:35)

02×κ−i

i (cid:54)= 1.

14

˙∆di = ∆vi − ∆vi+1
˙∆vi = αi∆vi − αi∆vd
i ,

(55)

(56)

where ∆di = di − ¯di, ∆vi = vi − ¯vi, ∆vd
i = vd
is the continuous equivalent to (60) deﬁned as

i − ¯vd

i , and αi

αi = c6 + 2c7(¯vi − ¯vd

i ).

(57)

Selecting a time step of 0.05 s and assuming a zero-order hold
on the input, these dynamics are then discretized as

Ci =

∆di,n+1 =∆di,n +

βi − 1
αi

∆vi,n −

βi+1 − 1
αi+1

∆vi+1,n+

− (

− 0.05)∆vd

βi − 1
αi

βi+1 − 1
αi+1
∆vi,n+1 =βi∆vi,n − (βi − 1)∆vd
i,n,

i + (

− 0.05)∆vd

i+1

where

αi,n = c6 + 2c7(¯vi,n − ¯vd
βi,n = e0.05αi,n .

i,n),

(58)

(59)

(60)

(61)

Vectorizing these discrete dynamics for the state vector
xn = [∆d1,n · · · ∆dκ−1,n ∆v1,n · · · ∆vκ,n](cid:124) and inputs
ui,n = ∆vd
i,n results in an LTV system satisfying (3) where

An =








β1,n−1
α1,n

− β2,n−1
α2,n
. . .

. . .

Iκ−1

0κ×κ−1

diag(β1,n, . . . , βκ,n)

βκ−1,n−1
ακ−1,n

− βκ,n−1
ακ,n









,

(62)

for the level 3 and level 1 controllers deﬁned in Section VII
and takes the form

(64)












(cid:34)






1
...
1
1

. . .
0
. . .
. . .
1
. . .
. . .
1
01×κ−1

0
...
0
1

02×i−2

1
0

02×κ−1

0κ−1×1

0κ−1












i = 1

01×κ−1
(cid:35)

1

0
1

02×κ−i

i (cid:54)= 1.

(65)

for the level 2 controller deﬁned in Section VII.

B. Closed Loop System Matrices

The matrices for the closed loop dynamics in (18) satisfy

An

B1,nK1,n · · · Bκ,nKκ,n

− (cid:80)

j∈H1

− (cid:80)

j∈Hκ

...

L1,jCj

Lκ,jCj

diag(M1,n, . . . , Mκ,n)

B1,n

· · · Bκ,n

diag(N1B1,n, . . . , NκBκ,n)

(cid:21)

,








(cid:20)

(cid:34)

¯An =

¯Bn =

¯Ln =

0p×(κ (cid:80)κ

j=1 rj)

Li,n = (cid:2)L(i,1),n

diag(L1,n, . . . , Lκ,n)
· · · L(i,κ),n

(cid:35)

,

(cid:3) .








,

(66)

(67)

(68)

(69)

Bi,n =

























1

20 − β1,n−1
α1,n
0κ−2×1
1 − β1,n
0κ−1×1








0i−2×1

βi,n−1
αi,n
1

− 1
20
20 − βi,n−1
αi,n
0κ−2×1
1 − βi,n
0κ−i×1













i = 1

i (cid:54)= 1.

In (69), when (i, j) /∈ H, L(i,j),n is replaced by 0pi×mi.

C. Lateral Controller and Observer

.

(63)

For lane keeping, a lateral controller is introduced which
operates independently of the longitudinal controller (i.e. each
vehicle runs the same lateral controller and observer at all
times). The feedback law follows

δi,n = (cid:2)−0.25 −1(cid:3)

(cid:21)

(cid:20)∆ ˆlati,n
∆ ˆψi,n

.

(70)

Furthermore, the observer follows

F. Simulation results

15

(cid:21)

(cid:20)∆ ˆlati,n+1
∆ ˆψi,n+1

=

(cid:32) (cid:20)1
0

(cid:21)

+

¯vi,n
20
1
c1¯vi,n

(cid:20)0.3
0

ˆvi,n
20
0.2

(cid:21) (cid:33) (cid:20)∆ ˆlati,n
∆ ˆψi,n

(cid:21)

+

The results of the aggressive attack on the level 3 controller
and the replay attack on the level 2 controller, shown in Figures
6 and 7 respectively.

cos2(c1
(cid:34)(cid:16) (c8+c9 ¯v2

¯δi,n + c2)(c3 + c4¯v2
+ ¯vi,n
800

i,n)

(cid:17)

(cid:35)

20

i,n)

∆δi,n

×

+

×

−

1bi,n
20
(cid:21)

(cid:20)0.3
0

ˆvi,n
20
0.2

∆y-lati,n,

(71)

where ∆y-lati,n is the measurement of the lateral and heading
error.

D. Sufﬁcient conditions for Correlation

The following proposition provides a sufﬁcient condition

for a non-zero correlation.

Proposition A.1. Consider a closed loop LTV system satisfy-
ing (18). If for some ρ(i,j) ∈ N
(cid:2)W(i,j)Cj
0mi×t
(cid:104)
0qi×(p+(cid:80)i−1

(cid:3) ¯An−1 · · · ¯An−ρ(i,j)
0qi×((cid:80)κ

¯Bn−ρ(i,j)−1×
(cid:105)(cid:124)

j=i+1 pj)

j=1 pj)

Iqi

×

(cid:54)= 0p(i,j)×qi
(78)

then

(cid:104)

E

W(i,j)s(i,j),ne

(cid:124)
i,n−ρ(i,j)−1

(cid:105)

(cid:54)= 0p(i,j)×qi

(79)

Proof. Due to the assumption that the watermark is mutually
independent and zero mean, only terms that are a function of
the watermark at that particular step have non-zero expecta-
tion. For ease of notation, these terms are removed without
loss of generality in this proof. Expanding the communicated
measurement on the left side of (79) ﬁrst using (7) then (18)
results in
(cid:104)

(cid:105)

E

W(i,j)s(i,j),ne

(cid:124)
i,n−ρ(i,j)−1

=

(cid:105)

=

(cid:104)

= E

= E

0mi×t

(cid:124)
i,n−ρ(i,j)−1

W(i,j)Cjxne
(cid:104) (cid:2)W(i,j)Cj
× ¯Bn−ρ(i,j)−1en−ρ(i,j)−1e
= (cid:2)W(i,j)Cj
0mi×t
(cid:104)
0qi×(p+(cid:80)i−1

j=1 pj)

×

(cid:3) ¯An−1 · · · ¯An−ρ(i,j) ×

(cid:124)
i,n−ρ(i,j)−1

(cid:105)

=

(cid:3) ¯An−1 · · · ¯An−ρ(i,j)
0qi×((cid:80)κ

Iqi

¯Bn−ρ(i,j)−1×
(cid:105)(cid:124)

j=i+1 pj)

Σei.

(80)
Since Σei is full rank and (78) holds, (79) holds as well. (cid:4)

E. Longitudinal Observer Matrices

This section provides the observer matrices for all three
control levels in Tables V and VI. To ease notation we deﬁne
the following

θi,n = βi,n − 0.1,

σi,n =

βi,n − 1
αi,n

− 0.05.

(89)

(90)

16

Controller

Level 3

Ni

Ni = I2κ−1

(72)

Mi,n = An +

Mi,n

κ
(cid:88)

j=1

(cid:0)Bj,nKj,n + L(i,j),nCj

(cid:1)

(73)

Mi,n = NiBi,nKi,n+

Nixn =


(cid:104)

d1,n

v1,n

v2,n

(cid:105)(cid:124)

(cid:104)

d1,n

d2,n

v1,n

v2,n

v3,n

(cid:105)(cid:124)

Level 2

=

dκ−1,n

v1,n

vκ−1,n

vκ,n

i = 1

i = 2

i = κ

(cid:105)(cid:124)

+




(cid:104)

(cid:104)

dκ,n

di,n

di−1,n

di,n

v1,n

vi−1,n

vi,n

vi+1,n

(cid:105)(cid:124)

o/w

(74)

(cid:34)























0.5
02×1

σ1,n −σ2,n
diag(θ1,n, θ2,n)

(cid:35)

0.5I2

03×2

0.5I2

03×2

0.5I3

04×3

0
σ1,n −σ2,n
0
−σ3,n
σ2,n
diag(θ1,n, θ2,n, θ3,n)

0

σ1,n
0

−σκ,n
σκ−1,n −σκ,n
diag(θ1,n, θκ−1,n, θκ,n)











0

−σi,n
σi−1,n −σi,n
σi,n

σ1,n
0
0
diag(θ1,n, θi−1,n, θi,n, θi+1,n)

0
0
−σi+1,n

0

i = 1

i = 2

i = κ








o/w

(75)

Mi,n = NiBi,nKi,n+

Level 1

Nixi,n =






(cid:105)

(cid:104)

v1,n





di−1,n
vi−1,n
vi,n

i = 1

i (cid:54)= 1






(76)

+

0.5


θ1,n






−1.2
0

βi−1,n−1
αi−1,n
βi−1,n
0






−σi,n
0
θi,n

i = 1

i (cid:54)= 1

(77)

TABLE V: Linear transform and observer system matrices for each controller

Controller

L(i,j),n

W(i,j), U(i,j)

17

Level 3

L(i,j),n =

(cid:104)

(cid:104)

(cid:104)






−0.05

01×κ−2 −0.1

01×κ−1

(cid:105)(cid:124)

02×κ−2

02×j−2

02×κ−2

−0.5
0.05

−0.5
0.05
0
−0.1

(cid:105)(cid:124)

0
−0.1

02×κ−1

0
−0.05

(cid:105)(cid:124)

02×κ−j

L(1,j),n =






(cid:34)






03×κ−1






−0.05
−0.1
0

−0.5
0.05

(cid:35)(cid:124)

0

0
0 −0.1

j = 1

j = 2

W(i,j) = Cj , U(i,j) = Imj

(82)

j = 1

j = κ

o/w.

(81)

(83)

Level 2

L(κ,j),n =








05×κ−2

−0.5 −0.05

0
0
02×1

0
0.1
02×1








j = 1

(cid:104)

0 −0.05

0 −0.1

(cid:105)(cid:124)
0

j = κ − 1

(cid:34)

0
0.05

−0.5
0.05

0
0

(cid:35)(cid:124)

0

0
0 −0.1

U(i,j)Nixn = W(i,j)Cj xn =

(cid:105)

(cid:104)
v1,n
(cid:104)(cid:80)i−1

k=1 dk,n

j = 1, i = 1

j = 1, i (cid:54)= 1

(cid:105)(cid:124)

v1,n

(85)

=

(cid:104)

(cid:104)

(cid:105)

vj,n

dj−1,n

vj

(cid:105)(cid:124)

.

j (cid:54)= 1, i = j + 1

j (cid:54)= 1, i (cid:54)= j + 1

(87)














for the ﬁrst vehicle,




L(2,j),n =






−0.25
04×1

01×κ−2








−0.05
0
−0.1
02×1

(cid:34)

(cid:34)

−0.25
0.05

0
−0.05

0 −0.5
0.05
0

0
0

0

0
0 −0.1
(cid:35)(cid:124)

0

0
0 −0.1

(cid:35)(cid:124)
0
0

j = 1

j = 2

j = 3

(84)

for the second vehicle,

for the last vehicle, and

L(i,j),n =










07×i−2

−0.5
06×1

07×κ−i

(cid:104)

0 −0.05

0

0 −0.1

0

=










−0.05
0
0
−0.1
03×1
(cid:105)(cid:124)
0

(cid:34)

(cid:34)

0
0.05

−0.5
0.05 −0.05

0

0
0

0

0
0 −0.1

0
0

0 −0.5
0.05
0

0
0

0
0

(cid:35)(cid:124)

0

0
0 −0.1




j = κ

j = 1

j = i − 1

(cid:35)(cid:124)
0
0

j = i

j = i + 1

for the remaining vehicles i.e. i /∈ {1, 2, κ}.

Level 1

L(i,i),n =


−0.1






−0.5
−1.2
0






0.05
0
−0.1

(86)

(88)

i = 1

i (cid:54)= 1

N/A

TABLE VI: Observer gain and measurement transform matrices

18

Fig. 6: (top) Performance of the level 3 controller after an aggressive attack without switching to the level 1 controller. However, it completes the trajectory
without crashing. (middle) Platoon switching to level 1 controller after detecting the attack and completing the entire trajectory. (bottom) Negative log likelihood
of channel which detected the replay attack ﬁrst.

19

Fig. 7: (top) Performance of the level 2 controller after a replay attack without switching to the level 1 controller. However, it completes the trajectory without
crashing. (middle) Platoon switching to level 1 controller after detecting the attack and completing the entire trajectory. (bottom) Negative log likelihood of
channel which detected the replay attack ﬁrst.

