ANUBIS: A Provenance Graph-Based Framework for Advanced
Persistent Threat Detection

Md. Monowar Anjum, Shahrear Iqbalâˆ—
National Research Council
Fredericton, NB, Canada
{mdmonowar.anjum,shahrear.iqbal}@nrc-cnrc.gc.ca

Benoit Hamelin
Tutte Institute for Mathematics and Computing
Ottawa, ON, Canada
benoit.hamelin@cyber.gc.ca

1
2
0
2

c
e
D
1
2

]

R
C
.
s
c
[

1
v
2
3
0
1
1
.
2
1
1
2
:
v
i
X
r
a

ABSTRACT
We present ANUBIS, a highly effective machine learning-based APT
detection system. Our design philosophy for ANUBIS involves two
principal components. Firstly, we intend ANUBIS to be effectively
utilized by cyber-response teams. Therefore, prediction explainabil-
ity is one of the main focuses of ANUBIS design. Secondly, ANUBIS
uses system provenance graphs to capture causality and thereby
achieve high detection performance. At the core of the predictive
capability of ANUBIS, there is a Bayesian Neural Network that
can tell how confident it is in its predictions. We evaluate ANUBIS
against a recent APT dataset (DARPA OpTC) and show that ANU-
BIS can detect malicious activity akin to APT campaigns with high
accuracy. Moreover, ANUBIS learns about high-level patterns that
allow it to explain its predictions to threat analysts. The high pre-
dictive performance with explainable attack story reconstruction
makes ANUBIS an effective tool to use for enterprise cyber defense.

CCS CONCEPTS
â€¢ Security and privacy â†’ Intrusion detection systems.

KEYWORDS
Advanced Persistent Threat, Provenance Graph Analysis

ACM Reference Format:
Md. Monowar Anjum, Shahrear Iqbal and Benoit Hamelin. 2022. ANUBIS:
A Provenance Graph-Based Framework for Advanced Persistent Threat
Detection . In The 37th ACM/SIGAPP Symposium on Applied Computing
(SAC â€™22), April 25â€“29, 2022, Virtual Event, . ACM, New York, NY, USA,
10 pages. https://doi.org/10.1145/3477314.3507097

1 INTRODUCTION
The term Advanced Persistent Threat (APT) was first introduced
in reference to intrusion into secure systems by US Air Force in
2006 [21]. Today, the term APT is used for a wide range of cyber
attacks executed over a long period of time to gain access to highly

âˆ—Corresponding Author

This article was authored by employees of the Government of Canada. As such, the
Canadian government retains all interest in the copyright to this work and grants to
ACM a nonexclusive, royalty-free right to publish or reproduce this article, or to allow
others to do so, provided that clear attribution is given both to the authors and the
Canadian government agency employing them. Permission to make digital or hard
copies for personal or classroom use is granted. Copies must bear this notice and
the full citation on the first page. Copyrights for components of this work owned by
others than the Canadian Government must be honored. To copy otherwise, distribute,
republish, or post, requires prior specific permission and/or a fee. Request permissions
from permissions@acm.org.
SAC â€™22, April 25â€“29, 2022, Virtual Event,
Â© 2022 Crown in Right of Canada. Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8713-2/22/04. . . $15.00
https://doi.org/10.1145/3477314.3507097

confidential information or to compromise high-integrity resources
while remaining undetected. According to the FireEye-Mandiant M-
Trends Threat Intelligence Report 2021, there are currently 41 active
APT groups in activity today [16]. These groups are responsible for
targeted campaigns such as APT29â€™s attempt to steal COVID-19
vaccine-related information [44]. Another prominent example is
2020â€™s United States federal government data breach via the supply
chain exploitation of the SolarWinds enterprise software vendor,
which was orchestrated by unknown state-sponsored actors [9].
Cyber security trend reports suggest that APT actors are taking
advantage of newly discovered zero-day vulnerabilities in popular
software to gain access into safety-critical systems [7, 42].

Traditional threat detection systems are not suitable for detect-
ing long running APT campaigns. Signature-based detection sys-
tems perform poorly in the face of zero-day exploits, polymor-
phic malware and living-off-the-land tactics. On the other hand,
systems based on anomaly detection fail to model long running
network behavior due to resource constraints of storing and pro-
cessing high-density telemetry and log events for a long period
of time [14, 26, 33, 37, 39]. Moreover, systems that take long term
behaviour into account limit their analysis to paired call stack event
occurrences [38].

Recent works [8, 18, 31, 32] suggest that system provenance
graphs are a more effective data source for APT detection. A system
provenance graph is a directed acyclic graph (DAG) that represents
causal relationships between running processes and objects (e.g.,
files, network flow, threads) in a system. It can connect events that
are temporally distant but causally related [34]. This property of
system provenance graphs provides rich contextual information re-
garding an eventâ€™s neighborhood and itâ€™s parent event. Leveraging
this property leads to robust separation of benign and malicious
events.

Motivation. Prior research works that used provenance graphs for
APT detection suffer from two major limitations. First, provenance
graph-based systems that use graph edge matching rules are very
sensitive [30, 32]. APTs can evade these systems by exploiting new
zero-day vulnerabilities. Second, in memory analysis of system
provenance graph is prohibitively expensive [27, 32] as provenance
graph grows exponentially with time. In our work, we mitigate the
first limitation by learning APT attack graph patterns from prove-
nance data. This allows our system to learn high level structures of
APT attacks. We believe that these structures are more reliable in-
dicators of attacks than low level handcrafted edge matching rules.
We circumvent the second limitation by proposing a novel graph
neighborhood encoding method. Our proposed method uses Pois-
son distribution to encode the neighboring events in a fixed length

 
 
 
 
 
 
SAC â€™22, April 25â€“29, 2022, Virtual Event,

Md. Monowar Anjum, Shahrear Iqbal and Benoit Hamelin

vector. This allows our system to efficiently perform in-memory
provenance graph analysis during runtime.

Prior research works that used provenance graph for APT attack
reconstruction focus on storytelling over explainability [4, 22]. Let
us illustrate this by an example. Suppose, a cmd.exe process opens
a word document by triggering winword.exe. This is a benign ac-
tion. The opposite sequence where winword.exe is triggering a
cmd.exe is considered malicious action. Current research works
focus on telling this story where they point out to the cyber analyst
that a suspicious activity took place and the story is: winword.exe
triggered cmd.exe. However, current works can not answer if the
cyber analyst asks â€œwhy this activity is suspicious?â€. The most con-
clusive way for an APT detection system to answer that question is
to map any detected suspicious activity to the most similar activity
in itâ€™s training dataset. In the above example, the answer given by
the APT detection system should be: â€œThis activity represents max-
imum similarity with an macroless shellcode injection example in
training set.â€ This approach of attack story reconstruction provides
explainability during the attack investigation. Moreover, it also
provides an insight into the detection systemâ€™s health (i.e., if the
system is making majority false positive predictions for a specific
type of events). In this work, we explore the explainable approach
for APT attack reconstruction. To the best of our knowledge, this is
the first work that takes explainability into account for attack story
reconstruction.
Contributions. We propose ANUBIS, a supervised machine learn-
ing approach for detecting APTs from provenance graph data and
explaining the predictions to cyber-threat responders. ANUBIS
is trained on event traces (a sequence of events related by parent-
child relationship) which are generated by walks on the provenance
graph. The model used for training ANUBIS is a Bayesian Neural
Network (BNN). During the operation phase, ANUBIS predicts the
class of the event traces that are generated from the streaming
provenance graph. These predictions are also associated with an
uncertainty score provided by our BNN model. If the prediction has
low uncertainty score, ANUBIS provides explanation of the predic-
tion by matching with the most similar example in the training set.
In summary, we make the following contributions:

â€¢ We propose a provenance graph-based supervised APT de-

tection framework.

â€¢ We develop a novel graph-neighborhood encoding method
using Poisson distribution that greatly reduces the memory
footprint of the graph-based detection system.

â€¢ We provide explanation of the predictions according to a
strategy that depends on the uncertainty of the prediction
given by the BNN model.

â€¢ We evaluate ANUBIS on a recent APT dataset called Op-
erationally Transparent Cyber (OpTC) released by DARPA.
ANUBIS achieves an accuracy of 99% with precision over
98% and false positive rate of less than 2% which show the
efficacy of our approach.

2 BACKGROUND
2.1 APT Life Cycle
According to the APT life cycle model [32], a typical APT attack
consists of the following steps: (1) Initial Compromise; (2) Foothold

Establishment; (3) Privilege Escalation; (4) Internal Reconnaissance;
(5) Lateral Movement; (6) Achieve Persistence; and (7) Complete
mission. Let us consider the 2020 US federal government data breach
as an example. The adversary initially compromised the system by
implanting a malicious dll (SUNBURST) in the Solarwinds Orion
product. Then the adversary communicated with a number of mali-
cious domains via DNS queries (CNAME records) and established
foothold in the compromised system. Afterwards, the adversary
used Mimikatz to harvest credentials in order to escalate their
privilege. The internal reconnaissance was performed by periodic
scanning of shared file system. The adversary then moved later-
ally to spread into other hosts. In order to achieve persistence, the
adversary moved away from the original source of compromise
(malicious dll) and leveraged VPN vulnerabilities to gain continu-
ous access to the system. Once the adversary detached itself from
the source of initial compromise, it became very difficult for cyber-
threat responders to detect and track the adversary activities. Lastly,
the adversary exfiltrated confidential data by common protocols
such as HTTPS and SMB from the hosts where the adversary suc-
cessfully achieved persistence [16].

2.2 Challenges of APT Detection
Any provenance graph-based APT detection system will have to
overcome three main challenges that can influence the philosophy
of the system design. One of them is related to the nature of the
APT attack, another is related to the log data which is used by
the system to construct the provenance graph and the final one is
related to the time sensitive nature of the task of APT detection.

First, APTs maintain a very low profile in the compromised
system. Their activities blend with normal system execution trace.
These long running, stealthy, and persistence attack techniques
make the task of detecting APT very difficult [5].

Second, Enterprise system hosts can produce terabytes of event
log data on a daily basis which are used to construct the provenance
graph. APT activities are usually an extremely small percentage
of this data (typically less than 0.001%). Therefore, designing a
detection system for APT which has low false positive rate is dif-
ficult [27]. High volume of false positive alarm can cause â€œThreat
Fatigue" among system administrators which can lead to dismissal
of threat alerts [18].

Third, detection of long-running APT campaign is a time sensi-
tive task. The longer an APT is within a system, the more potential
damage it can inflict. Therefore, it is imperative that APT detection
systems should isolate and summarize the suspicious events quickly
and present them to the cyber-response team for triage.

2.3 Bayesian Neural Network
Bayesian Neural Network (BNN) is a special class of neural network
proposed by Blundell et al. [10]. Ordinary Neural Networks (NN)
learn fixed weights and biases from the training data to approx-
imate the function for the given task. However, a BNN learns a
distribution of weights and biases to approximate the function for
a given task. This property allows BNNs to determine uncertainty
in its prediction. Let us illustrate this with an example. Consider a
NN which is trained on the MNIST dataset [24] to classify grayscale
images of integer numbers between 0 to 9. After training, the NN

ANUBIS: A Provenance Graph-Based Framework for Advanced Persistent Threat Detection

SAC â€™22, April 25â€“29, 2022, Virtual Event,

Figure 1: Block diagram showing the steps of ANUBIS training.

will achieve good accuracy on a test set of grayscale images con-
taining digits only. If we ask the same NN to predict the class of a
grayscale image that contains a car, the network will still predict
the class of a digit. This is because the NN is trained to approximate
a function that maps input images to classes of digits. If the input
image is not a digit, the NN does not know how to handle that.

Let us consider a BNN in a similar scenario. After being trained
on the MNIST dataset, the BNN will predict the class of grayscale
images containing digits with very low uncertainty score. In other
words, the BNN is confident that it is predicting the right class
for that image. Now, if the BNN is asked to predict a grayscale
image containing a car, it will classify the car as a digit. However,
it will attach a very high uncertainty score with this prediction
output. This means the BNN is not confident in its prediction. This
particular capability to attach an uncertainty score is extensively
leveraged in ANUBIS design (Section 4.2.2).

2.4 Problem Statement
The problem that is addressed in this work is the detection and ex-
planation (regarding the detection) of APT attacks from the system
provenance graph. An ideal detection system that can tackle the
problem should have the following properties:

â€¢ Ability to continuously monitor the system events and con-

struct the provenance graph of the system.

â€¢ Capacity to detect events that does not conform to the known
benign event patterns and provide a detailed explanation to
the cyber-response team for further actions. Explanations
can include matching the event with a known malicious
event pattern, attack story reconstruction, etc.

We also make the following assumptions:

â€¢ The adversary can not compromise the provenance graph

used to generated event traces for training ANUBIS.

â€¢ The adversary can not compromise the event logging mech-
anism of the host system during operational phase. This
assumption is central to the ANUBIS design.

â€¢ Malicious event traces show sufficiently different behavior

from benign event traces.

3 ANUBIS DESIGN
ANUBIS is a host-based system which is trained on event-traces
generated from provenance graphs from APT infected systems. It
has a two-phase design: Training and Operation. Figure 1 shows
ANUBIS training phase design.

Figure 2: Two subgraphs of the system provenance graph. The left
one shows a benign subgraph and the right one shows the malicious
subgraph of the same process.

3.1 Training Phase Design
3.1.1 Provenance Graph Construction. Provenance graph is a di-
rected acyclic graph that can causally connect system events even
when they are temporally distant. During the training phase, ANU-
BIS takes the system events generated by the logging mechanism
and constructs a provenance graph. Each internal node of the prove-
nance graph represents a process creation event. The children of the
internal nodes represent the events where the process interacted
with a system resource, i.e., open/modify/delete a file, send a packet
over the network, launch or communicate with another process, etc.
This structure of provenance graph provides valuable information
regarding the context, causality and neighborhood of a particular
system event.

Letâ€™s illustrate this with an example. Figure 2 shows the sub-
graph of the system provenance graph for a benign instance and a
malicious instance of the MS Word process. The context and causal
relationships for events are different between benign and malicious
subgraphs. Additionally, neighborhood of events in the subgraphs
is different from each other. These properties help ANUBIS to cate-
gorize benign and malicious event traces accurately.

3.1.2 Event Trace Generation. ANUBIS generates event traces from
the system provenance graph for training the BNN. An event trace
is defined as a sequence of events who are related by parent-child
relationships. Formally speaking, letâ€™s select a random internal node
on the provenance graph and consider a walk of length ğ‘™ which
starts on that node. This walk will generate an event sequence
[ğ‘’1, ğ‘’2, ğ‘’3, Â· Â· Â· , ğ‘’ğ‘™ ]. Here ğ‘’1 is the parent of ğ‘’2, ğ‘’2 is the parent of ğ‘’3
and so on. This sequence of events is called an event trace. For
example, winword.exe â†’ chrome.exe â†’ download.txt is an event
trace from the benign subgraph of Figure 2.

3.1.3 Encoding Event Traces into Floating Point Vectors. A neural
network or any machine learning algorithm for that matter, takes
floating point vectors as input. Therefore, ANUBIS converts the
generated event traces into floating point vectors that can be fed into
neural network layers. ANUBIS encodes two types of information
from the provenance graph. The first one is causal and contextual
information and the second one is neighborhood information.

Encoding Causal and Contextual Information. Prior works [18, 43]
have shown that one of the key inputs for any APT detection model
is the causality and contextual information. For an event trace of
length ğ‘™, we encode the causality and contextual information of

ProvenanceGraphTrace Generation NeighborhoodEncoding byPoissonDistributionSystem Events Classifier (LSTM andBNN) ContextualEncodingWinword.exeChrome.exeOutlook.exeFile1.docxFile2.docxdownload.txtnetsh.exeReadReadOpenWriteOpenOpenReadWinword.exeCmd.exeCmd.exepowershell.exepowershell.exeChrome.exeFile.docxapt.tor.orgOpenOpenOpenOpenOpenOpenAccessWriteReadSAC â€™22, April 25â€“29, 2022, Virtual Event,

Md. Monowar Anjum, Shahrear Iqbal and Benoit Hamelin

that trace in a ğ‘™ Ã— ğ‘‘1 matrix. Each event in the trace corresponds to
a ğ‘‘1-dimensional row vector in the matrix. The row vector contains
encoded information about the event type, time difference from
the parent event, the name and location of the parent process, the
type of the process responsible for triggering the process (system
or user), etc. We do not encode ephemeral properties of events in
the vector. Ephemeral properties include properties that change
across different instances of the same process (e.g., pid , ppid, and
sid). We exclude these properties to avoid generating noisy input
for ANUBIS training.

Encoding Neighborhood Information. Another key input for any
APT detection model is the neighborhood information of an event.
For example, Figure 2 shows that the benign provenance subgraph
has different neighboring event distribution compared to the apt-
infected provenance subgraph. We encode the neighborhood event
distribution in a floating point vector.

Now we define neighborhood of an event and describe the spe-
cific distribution that is used in this work. The neighborhood of an
event consists of the siblings that occurred prior to the event. In
order to model the neighborhood of an event, ANUBIS considers
every new event generation as a binary random variable ğ‘‹ âˆˆ {0, 1}.
Empirical observation suggests that ğ‘‹ is rarely 11. Consequently,
we need to choose a distribution that can model rare event oc-
currences. One such distribution is Poisson distribution which is
widely used in the literature to model rare events (ICU patient
survival, data-centre failure, etc.) [12, 13]. Therefore, we choose
Poisson distribution as the probability distribution to represent
the neighborhood information of an event. The probability mass
function of the distribution is given by the following equation:

P(ğ‘˜ events in interval ğ‘¡ ) = ğ‘’âˆ’ğœ† ğœ†ğ‘˜
ğ‘˜!

(1)

where ğœ† is the rate parameter and ğ‘¡ is normalized to 1. Usually,
ğœ† is interpreted as expected number of events per unit time2. To
the best of our knowledge, this is the first work that uses probability
distribution to encode neighborhood information of an event node in
the provenance graph.

Letâ€™s describe the encoding process now. In ANUBIS design, we
consider 4 different types of events of the OpTC dataset (process,
file, flow, and shell). In other words, in the neighborhood of a
newly generated event, 4 different types of events are present. Each
type of event has their own Poisson distribution for a specific neigh-
borhood3. We calculate the difference between expected number of
events and actual number of events from the distribution parame-
ters. We store the difference in a vector, ğ· = [ğ·ğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘ , ğ· ğ‘“ ğ‘–ğ‘™ğ‘’, ğ· ğ‘“ ğ‘™ğ‘œğ‘¤
, ğ·ğ‘ â„ğ‘’ğ‘™ğ‘™ ]. Let us denote the expected number of events for event
type ğ‘¡ as Eğ‘¡ and the actual number of events as Ağ‘¡ . We formally

1New event generation in the neighborhood of a provenance graph node is a rare
occurrence. Thousands of events are generated every second in the system. However,
not all of them are generated by the same process. Therefore, they end up in different
neighborhoods of the graph
2For sufficiently large observations (>10000), ğœ† often becomes Gaussian mean.
3Authors of [43] claimed that given the count and variation of events in the provenance
graph, it is extremely unlikely for a single multivariate distribution to capture the
whole picture. We agree with that view. In our work, each event type has their own
distribution.

define ğ· by the following equation:

ğ·ğ‘¡ ğ‘¦ğ‘ğ‘’ =

ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´

ï£³

Eğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘  âˆ’ Ağ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘ , when type = process
Eğ‘“ ğ‘–ğ‘™ğ‘’ âˆ’ Ağ‘“ ğ‘–ğ‘™ğ‘’,
Eğ‘“ ğ‘™ğ‘œğ‘¤ âˆ’ Ağ‘“ ğ‘™ğ‘œğ‘¤,
Eğ‘ â„ğ‘’ğ‘™ğ‘™ âˆ’ Ağ‘ â„ğ‘’ğ‘™ğ‘™ ,

when type = file
when type = flow

when type = shell

(2)

The vector ğ· signifies the expected nature of the neighborhood and if
there are any deviations from it so far. Additionally, we can infer the
potential events that can take place soon after the event in consid-
eration from the distribution as well. We encode this information
in a vector ğ‘ƒğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ = [ğ‘ƒğ‘“ ğ‘–ğ‘™ğ‘’, ğ‘ƒğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘ , ğ‘ƒğ‘“ ğ‘™ğ‘œğ‘¤, ğ‘ƒğ‘ â„ğ‘’ğ‘™ğ‘™ ] which is defined
by Equation 3.

ğ‘ƒğ‘¡ ğ‘¦ğ‘ğ‘’ =

(cid:40)P(Waiting Time â‰¤ âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’ ), when type = eventâ€™s type
P(Waiting time > âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’ ),

otherwise

The P in Equation 3 is defined by Equation 4 and 5.

P(Waiting time â‰¤ âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’ ) = 1 âˆ’ ğ‘’âˆ’ğœ†âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’
P(Waiting time > âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’ ) = ğ‘’âˆ’ğœ†âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’

(3)

(4)

(5)

Letâ€™s explain Equation 3, 4, 5 with an example. Suppose, a parent
event ğ‘’ğ‘ğ‘ğ‘Ÿğ‘’ğ‘›ğ‘¡ is triggering a flow type event ğ‘’ğ‘ğ‘¢ğ‘Ÿğ‘Ÿ , at time ğ‘¡ğ‘›ğ‘œğ‘¤ (e.g.,
iexplorer.exe connecting to msftr.com). Letâ€™s assume that the
last flow type event in the neighborhood before ğ‘’ğ‘ğ‘¢ğ‘Ÿğ‘Ÿ was triggered
at time ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘£. Therefore, waiting time for this event is âˆ†ğ‘¡ğ‘“ ğ‘™ğ‘œğ‘¤ =
ğ‘¡ğ‘›ğ‘œğ‘¤ âˆ’ ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘£.

We can calculate the probability of waiting less or equal to
âˆ†ğ‘¡ğ‘“ ğ‘™ğ‘œğ‘¤ for a flow event by using Equation 4. This probability is
the ğ‘ƒğ‘“ ğ‘™ğ‘œğ‘¤ component of the ğ‘ƒğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ vector described above. ğ‘ƒğ‘“ ğ‘™ğ‘œğ‘¤
signifies whether the flow event arrived at a natural interval or not.
For example, ğ‘ƒğ‘“ ğ‘™ğ‘œğ‘¤ being very close to 1 or 0 means current event
arrived too late or too early respectively. Essentially, probability
value that we get from our Poisson encoding process is a measure of
irregularity of an event.

Note that we have to calculate the probability of other types of
events too. This means calculating the ğ‘ƒğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘ , ğ‘ƒğ‘“ ğ‘–ğ‘™ğ‘’, and ğ‘ƒğ‘ â„ğ‘’ğ‘™ğ‘™ for
the time instant of a flow event. We assume that a parent process
event can only generate one child event at a specific time instant4.
When a specific type of event is being generated, the other type of
events are still waiting to be generated which makes their respective
waiting time greater than âˆ†ğ‘¡ğ‘¡ ğ‘¦ğ‘ğ‘’ . This probability can be calculated
by Equation 5.

The vector ğ· tells us a neighborhoodâ€™s behavior so far while the
vector ğ‘ƒğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ tells us about what is going to happen in the eventâ€™s
neighborhood in near future. We concatenate both vectors and denote
it as ğ¸ğ‘›. This ğ¸ğ‘› gives us a near-complete picture of the neighborhood
(i.e., what happened so far in the neighborhood, is it consistent with
the observed Poisson distribution patterns and how the neighborhood
will evolve in near future). Let us denote the length of ğ¸ğ‘› as ğ‘‘2.
Therefore, the neighborhood encoding of an event trace of length ğ‘™
will have the dimension ğ‘™ Ã— ğ‘‘2.

4One can argue that in a system with multi-core processors, a process can read a file
and execute a shell command at the same time by using separate processor cores. We
are not considering this case in this work.

ANUBIS: A Provenance Graph-Based Framework for Advanced Persistent Threat Detection

SAC â€™22, April 25â€“29, 2022, Virtual Event,

Figure 3: Block diagram showing the ANUBIS operating on encoded
trace from provenance graph.

3.1.4 Training Neural Network. Consider an event trace of length
ğ‘™. The causal and contextual information encoding gives us a ğ‘™ Ã— ğ‘‘1
matrix. The neighborhood encoding gives us a ğ‘™ Ã— ğ‘‘2 matrix. We
input these two matrices into the classifier. The classifier consists
of two parallel LSTM layers and a Bayesian Neural Network (BNN).
We used the ELBO loss to train the classifier which is described in
the original paper proposing BNN [10].

3.2 Operation Phase Design
During the operation phase, the input of ANUBIS consists of ğ‘™-
length event traces from a streaming provenance graph. The opera-
tion phase consists of two steps. In the first step, ANUBIS makes a
prediction on the input event trace (benign or APT). If the event
trace is predicted as APT and the certainty level is high, ANUBIS
proceeds to second step. In second step, ANUBIS creates an expla-
nation for the prediction (similar to attack story reconstruction
process). Figure 3 shows the structure of the operation phase of
ANUBIS.

In this work, we provide explanations when ANUBIS predicts
an APT with high certainty. According to [15], companies get more
than 17000 threat alerts per week where more than 51% of the alerts
are false positives. Due to the frequency of the alerts, only 4% of
them are properly investigated [20]. Our primary goal is to assist
the cyber-threat responders by providing necessary explanation for
an APT prediction to ensure trustworthy and timely investigation
of incidents. Therefore, high certainty APT predictions demand
higher priority in analysis. We intend to explore the explanation
analysis for low certainty APT predictions in future.

Prediction of Event Traces. The trained classifier takes an
3.2.1
event trace as input and makes a prediction. The prediction gener-
ates two values. The first is the prediction of the class (benign or
APT). The second is the uncertainty score associated with it (i.e.,
standard deviation of the predictions).

Letâ€™s illustrate the prediction process with an example. Consider
a test event trace from the provenance graph. We make ğ‘˜ predictions
on this event trace. Recall that our classifier (BNN) does not have
specific weights and biases. Instead, it has a learned distribution
of weights and biases. During each prediction, we sample weights
and biases from this distribution. Therefore, in each step, we may
get a different prediction result. This is illustrated in Table 1.

If the classifier is highly certain about the class of an event
trace, it will predict the same class with almost similar probability
in each iteration. In other words, the standard deviation of the
predictions would be very low. On the contrary, if the classifier
has low confidence in its prediction, it will predict different classes
with varying probability in each iteration. This leads to a higher
standard deviation of the predictions which can be seen from Table
1. The low certainty prediction has 5 times more standard deviation
than the high certainty prediction.

Table 1: Illustration of predictions on test event trace . Closer to 0
means benign and closer to 1 means malicious.

High Certainty

Low Certainty

#

1
2
3
4
5

Prediction

0.84
0.882
0.891
0.872
0.92

#

6
7
8
9
10

Prediction

0.92
0.814
0.794
0.914
0.886

#

1
2
3
4
5

Prediction

0.663
0.541
0.741
0.519
0.341

#

6
7
8
9
10

Prediction

0.512
0.986
0.186
0.616
0.781

mean
std. dev

0.8733
0.0418

mean
std. dev

0.5886
0.2146

In ANUBIS design, we consider an event trace as APT if proba-
bility is greater than 0.5. If the prediction have a standard deviation
less than or equal to 0.1, then it is considered as a high certainty
prediction5. Once ANUBIS determines the nature of the prediction,
it starts creating an explanation. This is the attack story reconstruc-
tion problem which is well studied in literature [4, 35].

Attack story reconstruction problem can be viewed from two
perspective. The first perspective is: What constitutes the attack?
The work in [4] proposes a system named ATLAS that solves the
problem from this perspective. ATLAS creates a sequence of events
from the optimized causal graph and trains an RNN-based model
to make prediction on it. If the trained model predicts an event se-
quence as malicious, ATLAS constructs the attack story by mapping
the sequence back to their causal events. The second perspective
is: Why this is an attack? It requires that any malicious prediction
made by the system is mapped to a member of the training set
that has the maximum similarity. In ANUBIS design, we adopt this
perspective for explainability. To the best of our knowledge, this is
the first work that leverages the second perspective to achieve attack
explainability.

3.3 Explanation of High Certainty Malicious

Prediction.

A Neural Network consists of several layers. Each layer takes a
vector as input and produces a vector as output. The output is
called the â€œactivationâ€ of the layer. We leverage the activation of
layers to get the training event trace that is most similar with the
input that generated the malicious prediction.

Letâ€™s assume that the trained BNN consists of ğ‘˜ layers {ğ¿1, Â· Â· Â· , ğ¿ğ‘˜ }.
Consider an event trace ğ‘‡ğ» . Letâ€™s also assume that when we in-
put ğ‘‡ğ» in the BNN, it generates a high certainty malicious pre-
diction. We denote the activation of the BNN layers for ğ‘‡ğ» as
ğ´ğ‘‡ğ» = {ğ¿1
ğ‘œğ‘¢ğ‘¡ (ğ‘‡ğ» )}. Now, consider a malicious event
trace ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› from the ANUBIS training set . We calculate the activa-
tion of BNN layers for ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› in the same manner and denote that
as ğ´ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› = {ğ¿1
ğ‘œğ‘¢ğ‘¡ (ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›)}. The similarity ğ‘‘ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’
between the two event traces is judged by the following equation8.

ğ‘œğ‘¢ğ‘¡ (ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›), Â· Â· Â· , ğ¿ğ‘˜

ğ‘œğ‘¢ğ‘¡ (ğ‘‡ğ» ), Â· Â· Â· , ğ¿ğ‘˜

5The value 0.1 was chosen by trial and error. We initially tried with 0.05. However,
the results were not great. Recall that lower standard deviation means concentrated
observations. Therefore, the lower the std. dev of predictions, the better since it
indicates certainty level in the prediction. In other words, no matter how many times
you ask the network, it gives more or less same answer which indicates that the
network has high confidence in itâ€™s prediction.
6Day numbering represents evaluation period. Not benign data collection period.
7We heavily pruned the graph. For example, we got rid of all the ICMP ping messages,
bi-directional network flow messages and TCP 3 way connection setup messages.
8 |ğ‘ âˆ’ ğ‘ |2 is Euclidean distance between two vectors a and b.

EncodedEvent TraceInputTrained Classifier (LSTM andBNN) Explanation Generation Output + MaximumSimilarity TrainingExample SAC â€™22, April 25â€“29, 2022, Virtual Event,

Md. Monowar Anjum, Shahrear Iqbal and Benoit Hamelin

Table 2: APT activities present in the OpTC dataset.

Vulnerability Code

Description

Attack Vectors

Recent Attacks

CVE-2021-30551
CVE-2020-0688
CVE-2019-0604

Remote Code Execution and Shell Code Injection
Remote Code Execution and Lateral Movement
Remote Code Execution and Credential Harvesting

Beacon (Cobalt Strike)
Powershell Empire

Google Chrome (2021) [40]
Microsoft Exchange (2020) [29]
Customized Mimikatz Microsoft Sharepoint (2019) [28]

Presence In Dataset6
Day 1
Day 1 and 2
Day 1 and 3

Table 3: Characteristics of the constructed provenance graphs.

Table 4: APT detection performance of ANUBIS.

Graph

# events7

# benign
traces

APT

#
traces

Day 1
Day 2
Day 3

78,237,643
42,618,311
59,140,814

5,000,000
5,000,000
5,000,000

22,919
26,212
8,343

Avg.
Benign
Trace
Length

12.65
10.86
13.41

Avg.
APT
Trace
Length

16.42
9.22
7.95

Graph

Accuracy

Precision

Recall

F-score

Day 1
Day 2
Day 3

Avg.

0.99
0.99
1.00

0.993

0.99
0.98
1.00

0.99

1.00
1.00
0.99

1.00

0.998
0.989
1.00

0.996

FPR 9
0.001
0.007
0.000

0.003

# False Positive

147
235
12

131.33

ğ‘‘ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ = ğ´ğ‘‡ğ» âˆ’ ğ´ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› =

1
ğ‘˜

ğ‘˜
âˆ‘ï¸
ğ‘–=1

|ğ¿ğ‘–
ğ‘œğ‘¢ğ‘¡ (ğ‘‡ğ» ) âˆ’ ğ¿ğ‘–

ğ‘œğ‘¢ğ‘¡ (ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›)|2

(6)

Equation 6 essentially computes whether ğ‘‡ğ» and ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› is trigger-
ing similar kind of response (activation) from the BNN. The smaller
value of ğ‘‘ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ suggests greater similarity. We compute ğ‘‘ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ for all
the malicious event traces in the ANUBIS training set. Let us de-
note the malicious event trace in the training set with the smallest
ğ‘‘ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ value as (cid:154)ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›. ANUBIS provides the cyber analyst with a
prediction report of ğ‘‡ğ» which contains (cid:154)ğ‘‡ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› as the most similar
malicious event trace. This enables the cyber analyst to understand
why ğ‘‡ğ» was predicted as malicious. Moreover, this enables the ana-
lyst to understand the prediction from a deeper level (e.g., evolution
of attack vector, if a previous vulnerability remained unpatched or
if a previous patch failed to prevent the vulnerability and so on).
We demonstrate this phenomenon in Section 4.

4 EXPERIMENTAL EVALUATION
4.1 Dataset
We used the DARPA OpTC dataset to perform experimental evalua-
tion of ANUBIS [1]. This dataset contains APT activities conducted
by a professional red team over the course of 7 days in a networked
environment of one thousand windows endpoints. The reasons for
choosing this dataset for experimental evaluation are as follows:

â€¢ The APT examples that are present in this dataset have been
used in recent high profile APT attacks. This is shown in
Table 2.

â€¢ This is by far the largest dataset available from DARPA Trans-
parent Computing Program [6]. Therefore, it is ideal to train
and test deep learning models.

â€¢ According to [16], 89% of APT malware focus specifically on
windows systems. This dataset consists data collected from
windows hosts only. Moreover, attackers predominantly use
powershell, remote desktop protocol and windows manage-
ment infrastructure to accomplish their goals. The OpTC
dataset specifically contains numerous instances of all three
techniques.

â€¢ No prior works on APT detection used the whole OpTC
dataset. The only work we found which used this dataset
is [11]. However, the authors used only a subset of the dataset
(data from the first day of malicious activities). In this work,

we used the whole dataset to construct the provenance graph.
Therefore, to the best of our knowledge, this is the first attempt
to benchmark an APT detection model on the OpTC dataset.

The OpTC dataset contains multiple APT scenarios. We con-
structed provenance graphs for each scenario to evaluate ANUBIS.

4.2 Evaluation
We evaluated ANUBIS on the DARPA OpTC dataset that contains
approximately 17 billion OS-level events in total. Our evaluation is
based on two criteria: prediction performance (benign/APT) and
high certainty prediction explainability. Specifically, the evaluation
analysis is driven by the following research questions:

Q1. How accurately ANUBIS can detect APT-related event traces?

What is the false positive rate? (Â§ 4.2.1)

Q2. What are the effects of the design decisions we made for

ANUBIS? (Â§ 4.2.2)

Q3. How effective ANUBIS is compared to the other state of the

art APT detection models? (Â§ 4.2.3)

Q4. How accurately can ANUBIS explain the predictions it makes?

(Â§ 4.2.4)

4.2.1 Detection Performance. We constructed three separate prove-
nance graphs for the three APT activity days in the dataset. The
details of the graphs are given in Table 3. It shows that there is
a class imbalance in the dataset. To mitigate this, we oversample
the APT traces during the ANUBIS training process. We split the
dataset into training set and testing set by 80-20 ratio. The predic-
tion result of ANUBIS is presented in Table 4. It is important to note
that Table 4 presents the results from the best configurations. The
effect of configurations and other design decisions on prediction
performance will be discussed further in Â§ 4.2.2. We can see from
Table 4 that ANUBIS has high prediction accuracy, precision and re-
call. Moreover, ANUBIS has very low false positive rate. As a result,
we believe that our approach is less likely to induce â€œthreat fatigueâ€
among cyber analysts in compare to other approaches currently
in use. It is interesting to note that ANUBIS performs significantly
well on day 3. Day 3 contains the scenario of â€œMalicious Upgradeâ€
where a malicious binary is downloaded as a software update (sim-
ilar to Solarwinds Sunburst APT attack). This shows that ANUBIS
can detect APTs that are relevant in todayâ€™s threat landscape.

4.2.2 Effect of Design Decisions. We identify two aspects of our de-
sign that can affect the detection performance of ANUBIS. The first

9False Positive Rate

ANUBIS: A Provenance Graph-Based Framework for Advanced Persistent Threat Detection

SAC â€™22, April 25â€“29, 2022, Virtual Event,

Table 5: Event trace length effect in operation phase.

Table 6: Neighborhood encoding length effect in operation phase

Graph

Day 1

Day 2

Day 3

ğ‘™

2
4
6

2
4
6

2
4
6

Accuracy

Precision

Recall

F-score

FPR

Metrics

System Memory (MB)
Graph

Model

0.979
0.993
0.984

0.964
0.990
0.989

0.939
0.997
1.00

0.932
0.997
0.991

0.902
0.977
0.983

0.915
0.977
1.00

0.961
1.00
1.00

0.944
1.00
1.00

0.927
1.00
0.996

0.965
0.998
0.985

0.922
0.988
0.989

0.921
0.988
1.00

0.021
0.001
0.002

0.034
0.011
0.007

0.029
0.004
0.00

98.6
351.4
572.9

72.1
297.1
472.4

77.4
313.8
533.6

5.8
6.1
6.3

5.8
6.1
6.3

5.8
6.1
6.3

one is the length of the event trace and the second one is the dimen-
sion of the neighborhood encoding. We present our comparative
analysis for both of them.

Length of Event Trace. The length of the event trace essentially
determines the amount of information we are considering for clas-
sification. We experimented with trace length ğ‘™ = {2, 4, 6}. The
result is presented in Table 5. Note that the best results are not
concentrated for a specific value of ğ‘™. For ğ‘™ = 2, the results are
less attractive than ğ‘™ = {4, 6}. An event trace of length 2 has the
contextual and neighborhood information from the parent and the
event itself. On the other hand an event trace of length 4 or 6 has
additional information regarding parents of itâ€™s parent event. This
richness of information allows ANUBIS to perform better classi-
fication on event traces of length 4 and 6. We did not experiment
on trace length more than 6 as improvement of metrics between
trace length 4 and 6 are marginal. However, this can be easily done
if required in the operation phase. Also, in the next subsection,
we will show how our novel neighborhood encoding increases the
detection performance greatly even when ğ‘™ is small.

The length of the event trace determines the size of the prove-
nance graph required to be stored during the operation phase. For
instance, if we consider event trace length 4, at least 3 previous
parent events are required to be present in the graph for any event
trace. In the system memory column of Table 5, we present the
size (in Megabytes) of the in-memory provenance graph that is
required for the operation phase. As ğ‘™ increases, the provenance
graph size monotonically increases. Same goes for the model size
(BNN and RNN layers) during runtime. However, it is important to
note that model size increase is very small. This is because, when
the trace event length increases, only the input layer of the model
architecture changes. In our analysis, we are not considering the
overhead of system level provenance event generation. Practical
whole-system provenance mechanisms are present in the litera-
ture [34, 36] and ANUBIS will leverage them to construct the graph
in the operation phase.

The Dimension of Neighborhood Encoding. The dimension ğ‘‘2 of
the neighborhood encoding also plays a role in the operation phase
performance. In the neighborhood encoding design, we concate-
nated ğ· and ğ‘ƒğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ vectors. Both of them have a component for
a specific event type. We experimented with different number of
event types to get different dimensions of the neighborhood encod-
ing. For example, if we only consider process events, then ğ‘‘2 = 2.
If both process and file are considered, then ğ‘‘2 = 4 and so on.
In our design, we used 4 types of events which resulted in ğ‘‘2 = 8.
The prediction results for neighborhood encoding with different ğ‘‘2

Graph

Day 1 (ğ‘™ = 4)

ğ‘‘2
2
4
6
8

Precision

Recall

F-score

Time (s)

Memory (MB)

0.754
0.882
0.914
0.997

0.782
0.794
0.929
1.00

0.768
0.836
0.921
0.998

0.39
0.41
0.83
0.97

56.2
144.4
346.1
572.9

Table 7: Summary of APT detection models in literature

Model

Method

Dataset

Unsupervised
Unicorn [18]
StreamSpot [27]
Unsupervised
Provdetector [43] Unsupervised
Holmes [32]
Poirot [30]
Atlas [4]

Edge Matching
Graph Matching
Supervised

DARPA TC3
Own Dataset
Own Dataset
DARPA TC3
DARPA TC3
Own Dataset

Acc.

0.99
0.66
N/A
N/A
N/A
N/A

Prec.

Rec.

F-score

0.98
0.74
0.959
0.99
0.99
0.998

1
N/A
1
0.99
0.99
0.998

0.99
N/A
0.978
0.99
0.99
0.998

Anubis

Supervised

DARPA OpTC

0.993

0.99

1

0.996

values for Day 1 are presented in Table 6. The results for Day 2 and
3 graph are omitted for space issues.

Table 6 gives us some interesting insights into the design. As
the length of neighborhood encoding increases, classification per-
formance increases greatly. This can be attributed to the fact that
granular neighborhood encoding allows ANUBIS to learn about
distributions more accurately. In other words, the less we limit in-
formation regarding neighborhood, the better ANUBIS learns about
potential discrepancies in an eventâ€™s neighborhood. Based on this
observation, it can be argued that the encoding process will be bet-
ter if we consider more granularity. For example, instead of a single
distribution for process, we should consider different distributions
for process-create, process-open and process-terminate. For
file, we should consider file-create,file-open,file-modify
and so on. This is accurate in theory. However, the practicality of
this approach is invalidated by observing the time and memory
column of Table 6. The time column represents the average time
required to calculate neighborhood of 100 event traces. It increases
monotonically with ğ‘‘2. Therefore, if we break up the current event
types into more granular event types based on their actions, it will
further increase the time needed for neighborhood encoding. This
can potentially be a performance issue in real world systems. For
example, consider ANUBIS operating on enterprise hosts that gen-
erate a lot of OS-level events (e.g., DNS servers). For a granular
neighborhood encoding, the required time for encoding will be
higher which can lead to a backlog of events waiting to be encoded
and sent to classifier for prediction. Additionally, it will also result
in a bigger provenance graph during runtime. This is demonstrated
in the memory column of Table 6. The memory footprint of the
graph increases monotonically with ğ‘‘2 since it is storing lengthier
floating point vectors per node. We carefully designed ANUBIS
to be not very resource hungry and our choice of granularity for
neighborhood encoding is optimal for our experiments.

4.2.3 Evaluation with respect to State-of-the-art Models. Table 7
gives a non-exhaustive summary of the APT detection models
available in the literature. It is important to understand that direct
comparison with these models is not possible due to a lot of factors.
Some of the prior models used older or custom datasets. Some of
them used unsupervised models for detecting APTs. We report the
best results from these models. We did not include results from
models [20, 31, 41] that used different metrics than the ones we
reported.

SAC â€™22, April 25â€“29, 2022, Virtual Event,

Md. Monowar Anjum, Shahrear Iqbal and Benoit Hamelin

Table 8: APT Prediction By Explainability

Graph

# Predictions

Low uncertainty

High uncertainty

Incorrect

Day 1
Day 2
Day 3

6876
7863
2503

6523
7805
2466

353
58
37

31
94
12

From Table 7, it is evident that ANUBISâ€™s performance is compa-
rable to the state of the art APT detection models. ANUBIS achieves
99.3% accuracy with F-score of 0.996. UNICORN, Holmes and Poirot
achieve similar accuracy and F-score on DARPA TC3 dataset. Note
that DARPA TC3 is a smaller dataset (approximately 400 million
events) with attacks on UNIX, BSD and Android ecosystems [18]
while DARPA OpTC is newer and orders of magnitude bigger in
terms of events (approximately 17 billion events). Therefore, the
OpTC dataset has much lower signal to noise ratio compared to
the TC3 dataset. In other words, the OpTC dataset is an extreme
example of â€œneedle in a haystack" scenario when compared with
the TC3 dataset.

ANUBIS achieves 2.28% false positive rate which is very low
(Table 4) when loosely compared to similar models. For example,
UNICORN reported 8% false positive rate in their experiment on
the Streamspot dataset [27]. UNICORN did not report their false
positive rate on the TC3 dataset. Moreover, Holmes and Poirot both
reported â€œvery low" false positive rate on TC3 without quantifying
any value. Streamspot did not report any false positive rate. How-
ever, given that Streamspot has accuracy and precision below 80%,
it is reasonable to assume that they have higher false positive rate
than all other models in Table 7.

4.2.4 Prediction Explainability. In the design section, we described
how ANUBIS handles the explanation of low uncertainty malicious
predictions. Table 8 presents the malicious test set classifications
by their uncertainty level. Day 1 has the maximum number of high
uncertainty prediction whereas day 3 had the least amount of high
uncertainty predictions. In Figure 4, we show a low uncertainty
prediction. ANUBIS predicted the event trace as malicious with
probability 0.91 and standard deviation 0.024. This input event trace
was matched with the training example in Figure 4. At a first glance,
two event traces do not offer any resemblance. However, detailed
analysis reveals that ANUBIS learned about higher level patterns.
In the training example, the first powershell process launches a
second powershell process. The first one injects the second pow-
ershell process with a shellcode. The shellcode contains this state-
ment:

SySteM.NEt.SeRviCePoInTMaNaGeR]::

â†©â†’

â†©â†’

â†©â†’

EXPEct100COnTiNUe=0;$WC=NEW-ObJecT
SyStEm.NEt.WebClIEnT;$u='Mozilla/5.0 (Windows
NT 6.1; WOW64; Trident/7.0; rv:11.0)

This code is using the Windows web client functionality to reach a
web domain for malicious package download. However, the system
does not have Mozilla Firefox installed. That is why iexplorer.exe
is launched. The pattern we see here is multiple shell command
process are injected with shellcode which launches the network
process for malicious domain visit. The input event trace follows
the same pattern but with different shell command clients and in-
ternet browser. The input event trace injects shellcode in cmd.exe

Figure 4: Explaining prediction with low Uncertainty

and visits the malicious domain with firefox.exe. ANUBIS under-
stands that this input event trace has the same high level structure
as the training example in Figure 4. The cyber analyst gets a com-
prehensive report from ANUBIS which includes the prediction and
attack story based on the matched training example.

5 DISCUSSION AND LIMITATIONS
ANUBIS shares a few limitations with other APT detection models
in the literature. Firstly, ANUBIS is trained on a dataset that con-
tains data from windows hosts only. As a result, ANUBIS does not
cover all kinds of hosts in an enterprise scenario. We intend to test
ANUBIS on different os-level provenance graphs in future.

Another issue is that ANUBIS requires high volume of data
for training since it depends on deep learning layers. This might
prove challenging for organizations with less computing power.
Therefore, ANUBIS is more suited for use in an enterprise scenario.
However, we also notice that ANUBIS performed extremely well in
a homogeneous enterprise environment. The DARPA OpTC dataset
contained data from 1000 windows hosts with similar workload.
If the workload varies in hosts (e.g., workstations with different
users), ANUBIS may require more training time and data to capture
that pattern. In general, APT detection in heterogeneous hosts is
a difficult problem [18]. We intend to explore the applicability of
ANUBIS in hosts with diverse workloads in future.

ANUBIS requires periodic re-training to function effectively
against new APT attacks. For example, an analyst can judge the
quality of high uncertainty event traces and can decide whether
to use them for re-training. This periodic re-training ensures that
the next time ANUBIS sees such an event trace it will be highly
confident about the classification. However, this also opens up an
attack vector for the adversary. An adversary with knowledge of
the system may try to get malicious event traces into benign re-
training dataset. This will cause ANUBIS to classify malicious traces
as benign with high confidence and eventually undermining the
security of the enterprise network. Therefore, the re-training data
need to be selected and sanitized carefully before training ANUBIS.
Moreover, the neural network parameters of ANUBIS also require
to be tuned in order to accommodate new training data (e.g., more
neurons per layer, more layers). In our future work, we intend to
address the difficulties in re-training ANUBIS with new data.

6 RELATED WORKS
This work lies in the intersection of graph-based anomaly detection
and attack story re-construction.

Type: ShellCommandProcess: cmd.exe62cc40a1-d25f-4039-9f75-07d307a914c8Type: Process Process: cmd.exe221db61b-50a8-4a88-8f85-874ac6e79e9cType: ProcessProcess: firefox.exe22da5202-7e93-425c-b8aa-8506a3099671Type: ProcessProcess:iexplorer.exeType: ShellCommandProcess:powershell.exeType: Process Process:powershell.exe7a76ee55-2807-4c94-93d5-e642bcd524cb236ff9c5-398f-4bff-800e-51b393db1aac46968fac-bd37-461b-b59f-0cc106cc24b3RuntimeInputMatchedTrainingExampleANUBIS: A Provenance Graph-Based Framework for Advanced Persistent Threat Detection

SAC â€™22, April 25â€“29, 2022, Virtual Event,

Graph-Based Anomaly Detection. There is a large body of work
in the context of threat and anomaly detection based on graph [2].
UNICORN [18] follows an unsupervised machine learning approach
to analyze a streaming provenance graph for detecting APTs. It
periodically computes a histogram sketch of the provenance graph
which allows it to model benign system behavior. The approach
is sensitive to sharp change in system behavior and can result
in increase of false positive predictions. PROVDETECTOR [43]
extracts rare execution paths from the provenance graph. These
rare paths are vectorized using doc2vec embedding model and
then local outlier factor algorithm is used to classify the benign and
malicious events. Both these approaches are unsupervised while
ANUBIS is supervised. Moreover, none of these approaches offer
causality analysis on the predictions. ANUBIS performs extensive
causality analysis based on the confidence level of the prediction.
StreamSpot [27] uses feature engineering from streaming in-
formation flow graphs to detect malicious activities. The feature
engineering process extracts local graph structures from a single
snapshot of the provenance graph. However, this approach is in-
effective against APT which sometimes have campaign length of
multiple months or years [16]. Moreover, StreamSpot triggers a
large number of false alarms which can cause threat-fatigue and
result in preemptive dismissal of alerts [20]. FRAPpuccino [19] is
another approach for provenance graph-based APT detection. It
performs a sliding window analysis which results in a feature vec-
tor based on counts. A model is trained on these feature vectors.
The model represents normal execution state of the system. Any
deviation from the model is considered as anomaly. Using count
for feature engineering is a major weakness of FRAPpuccino. We
have shown in Section 3.1 that count is a weaker density estimate
to model the provenance graph neighborhood.

ZePro [41] is the first work that uses probabilistic approach
for anomaly detection. ZePro differs from ANUBIS in many ways.
Firstly, ZePro uses Probability Network (shallow learning model)
while ANUBIS uses BNN (deep learning model). Secondly, ZePro
works on System Object Dependency Graph (graph has cycles)
where ANUBIS works on provenance graph (directed acyclic graph).
Finally, ZePro solves zero-day attack path identification problem.
On the other hand, ANUBIS solves the APT detection and explain-
ability problem. APTs may or may not have zero-day exploits in
them (although having zero-day is most common for APT). There-
fore, ZePro solves a subset of the problem which ANUBIS solves.
Gao et al. designed a complex query language SaQL [17] that can
query on a streaming provenance data. Based on the queries, the
system leverages multiple anomaly detection model (rule-based,
time-series-based, invariant-based, outlier-based anomaly detec-
tion models). The detection system aggregates data from multiple
hosts and has showed promising performance in enterprise network
settings. However, the rule-based matching still requires expert do-
main knowledge. ANUBIS does not require any expert domain
knowledge during training or operation phase. Barre et al. used
random forest classifier to detect APT by feature engineering from
provenance graph [8]. They used features that are likely to be im-
portant in APT detection (e.g., timespan, edge count, and type of
event count). However, the system only had â‰ˆ50% detection rate.
This exemplifies that feature engineering has limited value in APT
detection unless execution context is considered. ANUBIS takes

context into account by encoding causal and neighborhood infor-
mation in the training inputs.

Attack Story Reconstruction and Explainability. One of the
earliest works to leverage provenance graphs for attack story re-
construction is BackTracker [23]. This work leverages the prove-
nance graph to detect the entry point of an intrusion. BackTracker
is farther improved in PriorTracker [25] which includes both for-
ward and backward causality analysis. Both of these works perform
causality analysis by graph traversal. On the contrary, ANUBIS
takes a fundamentally different approach as it performs causality
analysis by matching the event trace with the most similar event
trace in the training set.

ProPatrol [31] approaches attack story reconstruction problem
by compartmentalizing high level activity. This mitigates the de-
pendence explosion problem which hinders forensic analysis of
APT attacks. HOLMES [32] is another work that focuses on attack
story reconstruction by high-level graph abstraction. HOLMES uses
MITRE TTPs [3] to correlate provenance graph events and generate
a high level overview of the attack story. POIROT [30] shares a
similar strategy for attack story reconstruction. POIROT constructs
a query graph from available cyber threat intelligence and tries
to align the query graph with the provenance graph in order to
detect APT attacks. POIROT demonstrated strong performance in
offline pattern matching, however, constructing a query graph from
attack description is difficult and requires significant domain ex-
pertise. ANUBIS design does not require any domain knowledge.
The causality and explainability provided by ANUBIS comes from
the training data.

ATLAS [4] uses a sequence-based deep learning model for attack
story reconstruction. Once ATLAS predicts an input sequence as
malicious, it maps the sequence back to itâ€™s original events. The
causality between the events are connected and the analyst can
see the attack story. While this describes â€œThis is how APT is
attackingâ€, it does not tell why the model thinks this sequence of
events represent an APT attack. ANUBIS takes an event trace as
input which is similar to the input sequence of ATLAS. Therefore,
ANUBIS can perform the same attack reconstruction that ATLAS
does. Additionally, ANUBIS also explains why the model thinks
this as a malicious event trace. This makes ANUBIS a superior
information source for attack explanation and reconstruction.

7 CONCLUSION
In this work, we developed ANUBIS, a supervised deep learning
framework for detecting advanced persistent threats from system
provenance graphs. ANUBIS also explains the reasoning behind its
prediction by matching a detected APT trace with similar traces in
the training set. We prioritized explainability over storytelling to
solve the attack story reconstruction problem since we believe this
will help an analyst immensely. We also proposed a novel graph
neighborhood encoding method using Poisson distribution that we
showed is highly effective. We benchmarked our framework on the
recently published DARPA OpTC APT dataset. ANUBIS achieved
accuracy over 99% and a low false positive rate of 2.8%. ANUBIS
also learned about high-level APT patterns to accurately explain
the attack story to the cyber analyst. In the future, we will test

SAC â€™22, April 25â€“29, 2022, Virtual Event,

Md. Monowar Anjum, Shahrear Iqbal and Benoit Hamelin

ANUBIS on different datasets and develop new methods for attack
story explanation.

REFERENCES
[1] 2020. Operationally Transparent Cyber (OpTC). (2020). https://github.com/

FiveDirections/OpTC-data

[2] Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly
detection and description: a survey. Data mining and knowledge discovery 29, 3
(2015), 626â€“688.

[3] Otis Alexander, Misha Belisle, and Jacob Steele. 2020. MITRE ATT&CKÂ® for
industrial control systems: Design and philosophy. The MITRE Corporation:
Bedford, MA, USA (2020).

[4] Abdulellah Alsaheel, Yuhong Nan, Shiqing Ma, Le Yu, Gregory Walkup, Z Berkay
Celik, Xiangyu Zhang, and Dongyan Xu. 2021. {ATLAS}: A Sequence-based
Learning Approach for Attack Investigation. In 30th {USENIX} Security Sympo-
sium ({USENIX} Security 21).

[5] Adel Alshamrani, Sowmya Myneni, Ankur Chowdhary, and Dijiang Huang. 2019.
A survey on advanced persistent threats: Techniques, solutions, challenges, and
research opportunities. IEEE Communications Surveys & Tutorials 21, 2 (2019),
1851â€“1877.

[6] Md. Monowar Anjum, Shahrear Iqbal, and Benoit Hamelin. 2021. Analyzing the
Usefulness of the DARPA OpTC Dataset in Cyber Threat Detection Research. In
Proceedings of the 26th ACM Symposium on Access Control Models and Technologies
(Virtual Event, Spain) (SACMAT â€™21). Association for Computing Machinery, New
York, NY, USA, 27â€“32. https://doi.org/10.1145/3450569.3463573

[7] Yulia De Bari. 2021. 2021 Cybersecurity Trends Report. https://www.infosys.
com/iki/insights/2021-cybersecurity-trends-report.html. [Online; accessed 12-
July-2021].

[8] Mathieu Barre, Ashish Gehani, and Vinod Yegneswaran. 2019. Mining data
provenance to detect advanced persistent threats. In 11th International Workshop
on Theory and Practice of Provenance (TaPP 2019).

[9] FireEye Threat Research Blog. 2020. Highly Evasive Attacker Leverages Solar-
Winds Supply Chain to Compromise Multiple Global Victims With SUNBURST
Backdoor.
https://www.fireeye.com/blog/threat-research/2020/12/evasive-
attacker-leverages-solarwinds-supply-chain-compromises-with-sunburst-
backdoor.html. [Online; accessed 12-July-2021].

[10] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015.
Weight uncertainty in neural network. In International Conference on Machine
Learning. PMLR, 1613â€“1622.

[11] Thomas Cochrane, Peter Foster, Varun Chhabra, Maud Lemercier, Cristopher
Salvi, and Terry Lyons. 2021. SK-Tree: a systematic malware detection algorithm
on streaming trees via the signature kernel. In IEEE International Conference On
Cyber Security and Resilience.

[12] Michael J Crowther, Richard D Riley, Jan A Staessen, Jiguang Wang, Francois
Gueyffier, and Paul C Lambert. 2012. Individual patient data meta-analysis of sur-
vival data using Poisson regression models. BMC Medical Research Methodology
12, 1 (2012), 1â€“14.

[13] Weidong Fang, Wuxiong Zhang, Wei Chen, Li Yi, and Weiwei Gao. 2021. PDTM:
Poisson Distribution-based Trust Model for Web of Things. In Companion Pro-
ceedings of the Web Conference 2021. 85â€“89.

[14] Henry Hanping Feng, Oleg M Kolesnikov, Prahlad Fogla, Wenke Lee, and Weibo
Gong. 2003. Anomaly detection using call stack information. In 2003 Symposium
on Security and Privacy, 2003. IEEE, 62â€“75.

[15] FireEye. 2018. The Numbers Game: How Many Alerts are too Many to Han-
dle? https://www.fireeye.com/offers/rpt-idc-the-numbers-game.html. [Online;
accessed 19-July-2021].

[16] FireEye-Mandiant. 2020. FireEye Mandiant M-Trends Report. https://content.
fireeye.com/m-trends/rpt-m-trends-2021. [Online; accessed 12-July-2021].
[17] Peng Gao, Xusheng Xiao, Ding Li, Zhichun Li, Kangkook Jee, Zhenyu Wu,
{SAQL}:
Chung Hwan Kim, Sanjeev R Kulkarni, and Prateek Mittal. 2018.
A stream-based query system for real-time abnormal system behavior detection.
In 27th {USENIX} Security Symposium ({USENIX} Security 18). 639â€“656.
[18] Xueyuan Han, Thomas Pasquier, Adam Bates, James Mickens, and Margo Seltzer.
2020. Unicorn: Runtime provenance-based detector for advanced persistent
threats. The Network and Distributed System Security (NDSS) (2020).

[19] Xueyuan Han, Thomas Pasquier, Tanvi Ranjan, Mark Goldstein, and Margo
Seltzer. 2017. Frappuccino: Fault-detection through runtime analysis of prove-
nance. In 9th {USENIX} Workshop on Hot Topics in Cloud Computing (HotCloud
17).

[20] Wajih Ul Hassan, Shengjian Guo, Ding Li, Zhengzhang Chen, Kangkook Jee,
Zhichun Li, and Adam Bates. 2019. Nodoze: Combatting threat alert fatigue
with automated provenance triage. In Network and Distributed Systems Security
Symposium.

[21] Javad Hassannataj Joloudari, Mojtaba Haderbadi, Amir Mashmool, Mohammad
Ghasemigol, Shahab S. Band, and Amir Mosavi. 2020. Early Detection of the
Advanced Persistent Threat Attack Using Performance Analysis of Deep Learning.

IEEE Access 8 (2020), 186125â€“186137.
3029202

https://doi.org/10.1109/ACCESS.2020.

[22] Md Nahid Hossain, Sadegh M Milajerdi, Junao Wang, Birhanu Eshete, Rigel
Gjomemo, R Sekar, Scott Stoller, and VN Venkatakrishnan. 2017. {SLEUTH}: Real-
time attack scenario reconstruction from {COTS} audit data. In 26th {USENIX}
Security Symposium ({USENIX} Security 17). 487â€“504.

[23] Samuel T King and Peter M Chen. 2003. Backtracking intrusions. In Proceedings
of the nineteenth ACM symposium on Operating systems principles. 223â€“236.
[24] Yann LeCun, Corinna Cortes, and Christopher J Burges. 2010. MNIST handwritten
digit database. 2010. URL http://yann. lecun. com/exdb/mnist 7 (2010), 23.
[25] Yushan Liu, Mu Zhang, Ding Li, Kangkook Jee, Zhichun Li, Zhenyu Wu, Jungh-
wan Rhee, and Prateek Mittal. 2018. Towards a Timely Causality Analysis for
Enterprise Security.. In NDSS.

[26] Federico Maggi, Matteo Matteucci, and Stefano Zanero. 2008. Detecting intrusions
IEEE Transactions on

through system call sequence and argument analysis.
Dependable and Secure Computing 7, 4 (2008), 381â€“395.

[27] Emaad Manzoor, Sadegh M Milajerdi, and Leman Akoglu. 2016. Fast memory-
efficient anomaly detection in streaming heterogeneous graphs. In Proceedings
of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining. 1035â€“1044.

[28] Microsoft Vulnerability Database. 2019. CVE-2019-0604. https://msrc.microsoft.

com/update-guide/en-US/vulnerability/CVE-2019-0604.

[29] Microsoft Vulnerability Database. 2020. CVE-2020-0688. https://msrc.microsoft.

com/update-guide/en-US/vulnerability/CVE-2020-0688.

[30] Sadegh M Milajerdi, Birhanu Eshete, Rigel Gjomemo, and VN Venkatakrishnan.
2019. Poirot: Aligning attack behavior with kernel audit records for cyber threat
hunting. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security. 1795â€“1812.

[31] Sadegh M Milajerdi, Birhanu Eshete, Rigel Gjomemo, and Venkat N Venkatakr-
ishnan. 2018. Propatrol: Attack investigation via extracted high-level tasks. In
International Conference on Information Systems Security. Springer, 107â€“126.
[32] Sadegh M. Milajerdi, Rigel Gjomemo, Birhanu Eshete, R. Sekar, and V.N.
Venkatakrishnan. 2019. HOLMES: Real-Time APT Detection through Corre-
lation of Suspicious Information Flows. In 2019 IEEE Symposium on Security and
Privacy (SP). 1137â€“1152. https://doi.org/10.1109/SP.2019.00026

[33] Darren Mutz, William Robertson, Giovanni Vigna, and Richard Kemmerer. 2007.
Exploiting execution context for the detection of anomalous system calls. In
International Workshop on Recent Advances in Intrusion Detection. Springer, 1â€“20.
[34] Thomas Pasquier, Xueyuan Han, Mark Goldstein, Thomas Moyer, David Eyers,
Margo Seltzer, and Jean Bacon. 2017. Practical whole-system provenance capture.
In Proceedings of the 2017 Symposium on Cloud Computing. 405â€“418.

[35] Kexin Pei, Zhongshu Gu, Brendan Saltaformaggio, Shiqing Ma, Fei Wang, Zhiwei
Zhang, Luo Si, Xiangyu Zhang, and Dongyan Xu. 2016. Hercule: Attack story
reconstruction via community discovery on correlated log graph. In Proceedings
of the 32Nd Annual Conference on Computer Security Applications. 583â€“595.
[36] Devin J. Pohly, Stephen McLaughlin, Patrick McDaniel, and Kevin Butler. 2012.
Hi-Fi: Collecting high-fidelity whole-system provenance. In Proceedings - 28th An-
nual Computer Security Applications Conference, ACSAC 2012 (ACM International
Conference Proceeding Series). 259â€“268. https://doi.org/10.1145/2420950.2420989
Copyright: Copyright 2013 Elsevier B.V., All rights reserved.; 28th Annual Com-
puter Security Applications Conference, ACSAC 2012 ; Conference date: 03-12-
2012 Through 07-12-2012.

[37] R Sekar, Mugdha Bendre, Dinakar Dhurjati, and Pradeep Bollineni. 2000. A
fast automaton-based method for detecting anomalous program behaviors. In
Proceedings 2001 IEEE Symposium on Security and Privacy. S&P 2001. IEEE, 144â€“
155.

[38] Xiaokui Shu, Danfeng (Daphne) Yao, Naren Ramakrishnan, and Trent Jaeger.
2017. Long-Span Program Behavior Modeling and Attack Detection. ACM Trans.
Priv. Secur. 20, 4, Article 12 (Sept. 2017), 28 pages. https://doi.org/10.1145/3105761
[39] Anil Somayaji and Stephanie Forrest. 2000. Automated Response Using System-

Call Delay.. In Usenix Security Symposium. 185â€“197.

[40] Maddie Stone and Clement Lecigne. 2021. How we protect users from 0-day
attacks. https://blog.google/threat-analysis-group/how-we-protect-users-0-day-
attacks/. Google Threat Research Blog (2021).

[41] Xiaoyan Sun, Jun Dai, Peng Liu, Anoop Singhal, and John Yen. 2018. Using
Bayesian Networks for Probabilistic Identification of Zero-Day Attack Paths.
IEEE Transactions on Information Forensics and Security 13, 10 (2018), 2506â€“2521.
https://doi.org/10.1109/TIFS.2018.2821095

[42] W Symantec. 2011. Advanced persistent threats: A symantec perspective. Syman-

tec World Headquarters (2011).

[43] Qi Wang, Wajih Ul Hassan, Ding Li, Kangkook Jee, Xiao Yu, Kexuan Zou, Jungh-
wan Rhee, Zhengzhang Chen, Wei Cheng, Carl A Gunter, et al. 2020. You Are
What You Do: Hunting Stealthy Malware via Data Provenance Analysis.. In
NDSS.

[44] Steve Scherer William James. 2020. Russia trying to steal COVID-19 vaccine
data, say UK, U.S. and Canada. https://www.reuters.com/article/us-health-
coronavirus-cyber-idUSKCN24H236. [Online; accessed 12-July-2021].

