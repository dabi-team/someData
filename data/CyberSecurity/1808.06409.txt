8
1
0
2

g
u
A
0
2

]

C
O
.
h
t
a
m

[

1
v
9
0
4
6
0
.
8
0
8
1
:
v
i
X
r
a

Evolutionary, Mean-Field and Pressure-Resistance

Game Modelling of Networks Security

Stamatios Katsikas1,Vassilli Kolokoltsov2

August 21, 2018

Abstract

The recently developed mean-ﬁeld game models of corruption and bot-net defence

in cyber-security, the evolutionary game approach to inspection and corruption, and

the pressure-resistance game element, can be combined under an extended model of

interaction of large number of indistinguishable small players against a major player,

with focus on the study of security and crime prevention. In this paper we introduce

such a general framework for complex interaction in network structures of many

players, that incorporates individual decision making inside the environment (the

mean-ﬁeld game component), binary interaction (the evolutionary game component),

and the interference of a principal player (the pressure-resistance game component).

To perform concrete calculations with this overall complicated model, we suggest

working, in sequence, in three basic asymptotic regimes; fast execution of personal

decisions, small rates of binary interactions, and small payoﬀ discounting in time.

Keywords: mean-ﬁeld game, evolutionary game, pressure-resistance game, counter-

terrorism, bot-net defense, cyber-security, inspection, corruption, crime prevention.

1

Introduction

The issue of social security and crime prevention dominantly concerns the modern so-

cieties. In the traditional terrain of counter-terrorism, corruption and tax evasion, the

corresponding authorities in charge struggle to deal with large populations of increasingly

informed violating individuals (this term will be used interchangeably with the terms

agents or small players). Reversely, in the recently emerging ﬁeld of cyber-security, large

1

2

Centre for Complexity Science, University of Warwick, Coventry, CV4 7AL, UK, s.katsikas@warwick.ac.uk
Department of Statistics, University of Warwick, Coventry, CV4 7AL, UK, associate member of Informatics

Problems of the Federal Research Center ”Computer Science and Control” of RAS, v.kolokoltsov@warwick.ac.uk

1

 
 
 
 
 
 
groups of individuals aim to defend their private computers against a lurking cyber-

criminal (bot-net defence). Similar reasoning can be asserted for the citizens of a large

city defending against a biological weapon (bio-terrorism). The rapid advance in means

of interaction, communication and exchange of information has established the individ-

uals’ social network as a decisive parameter of their strategies in the above and similar

instances. Here we consider agents who are organized in speciﬁc social or phenotypic (or

even geographical), and behavioural network structures. The central focus of this paper is

to investigate the evolution of the complex process where a (very) large number of inter-

acting individuals, susceptible to engage in or be aﬀected by criminal behaviour, decide

their strategies subject to a benevolent, or respectively to a malicious, major player’s (this

term will be used interchangeably with the term principal) pressure, to their individual

optimization criterion, and to their (social) environment’s inﬂuence.

In the real life scenaria we aim to capture with our approach, it is natural to distinguish

two main dimensions of structure. The ﬁrst dimension refers to the individuals’ objective

distribution among diﬀerent levels of social, bureaucratic, or phenotypic hierarchy, or

to their geographical distribution, in general to any ﬁnite partition according to their

independent characteristics. One can think for example of tax payers of diﬀerent bands,

employees of diﬀerent grades, or infected computers/individuals of diﬀerent degrees. The

second dimension refers to the agents’ distribution among diﬀerent types of strategy or

behaviour, subject (mainly) to the agents’ individual control; say for example the level of

tax evasion in the ﬁeld of inspection games, the extent of bribery acceptance in the ﬁeld

of corruption games, or the level of defence against terrorist activity or a malware in the

ﬁelds of counter terrorism and cyber-security respectively.

Note that our game theoretic approach is developed under the basic idea of a very large

number of non-cooperative, interacting agents playing against (i.e. under the pressure of)

a single major player.

In principle, our model belongs to the wide class of non-linear

Markov games, see e.g., Kolokoltsov (2010), combining under an extended scheme the

pressure-resistance, the evolutionary, and the mean-ﬁeld game approach.

The pressure-resistance terminology was introduced in Kolokoltsov (2014), where ideas

captured from evolutionary game theory were extended, including the pressure of a prin-

cipal player on a large group of interacting agents. Here, the pressure-resistance game

2

component refers to the principal’s interference generatin transitions solely on the ﬁrst

dimension of structure (e.g. a benevolent director being able to promote or downgrade

interacting bureaucrats, computers and individuals getting infected or recovering subject

to a cyber-criminal’s and a bio-terrorist’s activity respectively). This approach of major

and minor players has also been considered for the analysis of mean-ﬁeld type models,

see, e.g., Huang (2010); Bensoussan, Chau and Yam (2016); Carmona and Zhu (2016).

The evolutionary game component refers to the agents’ pairwise interactions, with a

particular focus on the established social norms eﬀect, potentially generating transitions

on both dimensions of structure. For a general survey on the literature of population dy-

namics applications on game theory, that is, on evolutionary game theory, see, e.g., Smith

(1988); Weibull (1997); Gintis (2000); Samuelson (2002); Hofbauer and Sigmund (2003);

Taylor et al. (2004); Szab´o and Fath (2007), and references therein. See also Friedman

(1998, 1991) for speciﬁc application in economics.

The mean-ﬁeld game component refers to the agents’ individual optimization con-

trolled by their strategic position on the second dimension of structure, taking into ac-

count the entire population’s behaviour. This element of ‘globally’ rational optimization

introduces an additional level of complexity compared to Katsikas, Kolokoltsov and Yang

(2016); Kolokoltsov (2014), where optimization strictly upon imitation of successful strate-

gies on the basis of binary comparison of payoﬀs was considered (purely evolutionary

approach). Mean-ﬁeld games (MFG) were introduced by Larsy and Lions (2007), by

analogy with the mean-ﬁeld theory in statistical mechanics, and were also developed inde-

pendently by Huang, Malham´e and Caines (2006) as large population stochastic dynamic

games. In principle, they represent a natural extension of earlier work in the economics

literature under the assumption of inﬁnite number of players, see, e.g., Aumann (1964);

Dubey, Mas-Colell and Shubik (1980) for static games, Jovanovic and Rosenthal (1988);

Bergin and Bernhardt (1992) for dynamic games. The literature on mean-ﬁeld games is

growing really fast, see, e.g., Tembine et al. (2009); Cardaliaguet (2010); Caines (2013);

Bensoussan, Frehse and Yam (2013); Carmona and Delarue (2013); Gomes and Saude (2014);

Bauso, Tembine and Basar (2016), and references therein for a general survey.

Here we shall work in three asymptotic regimes; fast execution of the agents’ personal

decisions, weak binary interactions, and small discounting in time. The need to intro-

3

duce this ternary asymptotic approach is revealed from the analysis of a similar setting

conducted by Kolokoltsov and Bensoussan (2016), where the distribution of infection in

a computers network with a malicious software controlled by a cyber-criminal was de-

scribed by a stationary MFG model with four states. Whilst the three states model

describing the distribution of corruption in a population of bureaucrats under the pres-

sure of a benevolent principal that was studied by Kolokoltsov and Malafeyev (2015), is

solved explicitly without any asymptotic simpliﬁcations, the introduction of a fourth state

in Kolokoltsov and Bensoussan (2016) already increases the complexity signiﬁcantly, such

that the need to consider (though not as strongly as we do here) the assumption of large

λ (fast decisions execution) is critical to obtain descent solutions.

Similarly, for the more complicated n × m states model we introduce here, the need

to consider the three asymptotic regimes mentioned above becomes obvious. In principle,

even without working in these regimes one can sometimes obtain explicit but extremely

lengthy formulas, not revealing any clearer insights. But also form a practical point of view

our asymptotic approach has clear interpretation. Indicatively, an inﬁnitely large transi-

tion rate λ implies the natural process of immediate execution of personal decisions as long

as they have already been taken, while a vanishingly small discounting coeﬃcient δdis im-

plies a short planning horizon. Both of the models studied in Kolokoltsov and Bensoussan

(2016); Kolokoltsov and Malafeyev (2015), as well as the extended approach presented in

this paper, belong to the category of ﬁnite state space mean-ﬁeld games that were initially

considered by Gomes, Mohr and Souza (2010, 2013). See also Gomes, Velho and Wolfram

(2014) speciﬁcally for socio-economic applications.

In addition to the above applications on corruption, and cyber-security, here we in-

troduce the bio-terrorism interpretation, that is, the defence of a population against a

biological weapon. The implementation of game theoretic methods to the analysis of

terrorism has been vastly developed ever since the 1980s, with game theory allowing the

investigation of diﬀerent strategic interactions (e.g. terrorists vs government, terrorists

vs terrorists, terrorists for sponsors, terrorists for supporters), see, e.g., Sandler (2005);

Sandler and Arce (2007); Sandler and Siqueira (2009) and references therein. The addi-

tional pairing captured here is civilians vs a bio-terrorist.

We organize the paper as follows. In Section 2 we introduce our model, specifying

4

explicitly the time-dependent and stationary MFG consistency problems. In Section 3

we solve the stationary problem in our proposed asymptotic regimes, and we show that

the identiﬁed solution is a stable ﬁxed point of the corresponding evolutionary dynam-

ics.

In Section 4 we obtain our main result; we construct the class of time-dependent

solutions that stay in a neighbourhood of the identiﬁed stationary solution. In the termi-

nology of mathematical economics, this stationary solution represents a turnpike (see, e.g.,

Kolokoltsov and Yang (2012); Zaslavski (2006)) for the class of time-dependent solutions.

In Section 5 we summarize our approach and our results.

2 Formal Model

Let H = {1, . . . , |H| = n} be a ﬁnite set characterizing the hierarchical partition of small

players inside the environment, say their position in the bureaucratic staircase of an

organization. Alternatively, it may describe the extend of individuals’ infection to a bio-

weapon. Moreover, let B = {1, . . . , |B| = m} be a ﬁnite set characterizing the behavioural

or strategic partition of agents, say the level of compliance with oﬃcial regulations, the

extend of involvement in terrorist activity, or the degree of protection for PCs/citizens

against cyber-criminals/bio-terrorists. Then, the states of an agent are given by ordered

pairs of the form (h, b), with h ∈ H, b ∈ B, the ﬁnite state space being S = H × B.

Remark. In some cases it is reasonable to include an additional zero state, some kind

of a rank-less sink, where no choice of B is available, say for example a corrupted civil

servant suspended from duty without the potential to be bribed, an infected individual put

in quarantine, and so forth. Thus, the state space can be either S = H × B as initially
deﬁned above, or ˜S = H × B ∪ {0} = S ∪ {0} as alternatively implied with this comment.

We shall stick here to the ﬁrst instance.

We distinguish the following three structures.

Firstly, the decision structure (B, ED, λ), that is a non-oriented graph with the set of

vertices B and the set of edges ED, where an edge e joins the vertices i and j whenever

an agent is able to switch between states (h, i) and (h, j). Every such transition in B

requires certain random λ-exponential time. For simplicity, a single parameter λ is chosen

for all possible transitions. As mentioned, we shall mostly look at the asymptotic regime

5

with λ → ∞. We take the agents to be homogeneous and indistinguishable, in the sense

that their strategies and payoﬀs may depend only on their states, and not on any other

individual characteristics. Hence, a decision of an agent in a state (h, b) at any time is

given by the decision matrix u = (uhb→h˜b), expressing his intention to switch from strategy
b to ˜b, for all ˜b ∈ B such that ˜b 6= b. In our model, we consider agents without mixed

strategies, that is, for any state (h, b) the decision vector (uhb→h˜b) is either identically

zero, when the agent does not wish to change strategy, or there exists one strategy b1 6= b

such that uhb→hb1 = 1, and all the other coordinates of (uhb→h˜b) being zero, when the

agent wishes to change from strategy b to b1.

Secondly, the pressure structure (H, EP , qjb→ib), that is an oriented graph, where an

edge e joins the vertices j and i whenever a major player has the power to upgrade or

downgrade the small players from the hierarchy level j to i. In this case, coeﬃcients qjb→ib

represent the rates of such transitions in H, that is, every such transition requires certain

qjb→ib-exponential waiting time. In general, these rates may depend on some principal’s

control (one can think of some parameter describing his/her eﬀorts, for example his/her

budget). We shall not exploit this version here.

Finally, we consider the evolution structure that characterizes the change in the distri-

bution of states due to the agents’ pairwise interaction (e.g. through exchange of opinions,

ﬁght with competitors, eﬀect of established social norms etc.). This can be described by

the set of rates qs

s1→s2/N , by which an agent in state s can stimulate the transition of

another agent from state s1 to state s2. For instance, an honest agent (or even a cor-

rupted one) may help the principal to discover, and therefore punish, the illegal behaviour

of a corrupted agent. Note that transitions due to binary interaction can be naturally

separated into transitions in B and transitions in H, yielding respectively the behavioural

and the hierarchical evolution structures.

Remark. The scaling 1/N for the rates of binary interactions is the standard procedure of

making the strength of N 2 (number of pairs) binary transitions comparable to the strength

of N unilateral transitions.

Here we shall ignore the behavioural element of the evolution structure. That is, we

shall assume that transition rates qs

s1→s2/N may not vanish only for two states s1, s2

6

that diﬀer strictly in their h-component. Moreover, since we shall work in the asymptotic

regime of small binary interactions, it would be helpful to introduce directly a small pa-

rameter δint discounting the power of these interactions. Then, we shall denote thereafter

the corresponding transition rates by δint · qs

h1b→h2b/N .

Remark. The evolutionary transitions in B represent an alternative to the individual

transitions described by the decision structure (B, ED, λ), and can be considered negligible

in the limit λ → ∞ that we shall look at here. Taking into account a behavioural evolution

structure is more appropriate in the absence of a decision structure, which was the case

developed by Kolokoltsov and Malafeyev (2015).

To introduce a more detailed description of our game theoretic framework, note that

the states of the corresponding N players game are the N -tuples of the form,

{(h1, b1), . . . , (hN , bN )},

where each pair (hi, bi) describes each of the N players position on the hierarchy and the

behaviour axis respectively. Assuming that each player adopts a decision matrix u, then

the system evolves according to the continuous time Markov chain introduced above, with

the corresponding transitions rates as were speciﬁed. If we further specify the rewards

for staying in each state per unit of time, the transition fees (or costs) for transiting form

one state to another, as well as the terminal payoﬀs corresponding to each state for some

ﬁnite terminal time, then we shall be working in the setting of a stochastic dynamic game

of ﬁnite number of players.

As usual in a mean-ﬁeld game approach, we are interested in estimating the approx-

imate symmetric Nash equilibria. Assuming indistinguishable agents, the system’s state

space can be reduced to the set Z nm

+ of vectors n = (nij), i ∈ H, j ∈ B, where nij denotes

the number of agents in state (i, j), and N =

ij nij denotes the (constant) total number

of agents.

P

Therefore, the initially introduced Markov chain reduces to the Markov chain on Z nm
+ ,

described by the time-dependent generator:

7

n

m

n

Xβ

Xc

Xa
m

Lt

N F (n) =

n

m

n

n

+

Xa

Xβ

Xγ
Xc
m
n

Xk
m

naβ · qaβ→cβ ·

F (ncβ

aβ) − F (n)

(cid:16)

(cid:17)

naβ · δint · qγk

aβ→cβ/N · nγk ·

F (ncβ

aβ) − F (n)

(cid:16)

(cid:17)

(1)

+

naβ · λ · uaβ→ac ·

Xa

Xβ

Xc

F (nac

aβ) − F (n)

,

(cid:17)

(cid:16)

where the unchanged values in the arguments of function F on the right-hand side are

omitted. Equivalently, in the normalized version the system’s state space can be reduced

to the subset of the probability simplex ΣN

n×m ⊆ Rn×m, with vectors of the form x =

(xij) = n/N , i ∈ H, j ∈ B, where each coordinate represents the occupation density

(alternatively the occupation probability) of each state (i, j).

For the Markov chain on ΣN

n×m, generator (1) can be rewritten in the equivalent form:

Lt

N f (x) =

n

m

n

Xa

Xβ

Xc

xaβ · N · qaβ→cβ ·

f (x + (ecβ − eaβ)/N ) − f (x)
(cid:16)

(cid:17)

n

m

+

Xa,c,γ

Xβ,k
n

+

xaβ · N · δint · qγk

aβ→cβ/N · xγk · N ·

f (x + (ecβ − eaβ)/N ) − f (x)
(cid:16)

(cid:17)

(2)

m

m

Xa

Xβ

Xc

xaβ · N · λ · uaβ→ac ·

(cid:16)

f (x + (eac − eaβ)/N ) − f (x)

,
(cid:17)

where {eij} is the standard orthonormal basis in Rn×m. Assuming, additionally, that f

is a continuously diﬀerentiable function on ΣN

n×m, and taking its Taylor expansion, in the

limit of inﬁnitely many small players N → ∞, we ﬁnd that the above generator eventually

converges to:

n

m

n

Ltf (x) =

n

m

n

n

Xβ

Xa
m

+

Xa

Xβ

Xc
n

Xγ
m

Xk
m

xaβ · qaβ→cβ ·

Xc

∂f
∂xcβ

(cid:16)

−

∂f
∂xaβ (cid:17)

xaβ · δint · qγk

aβ→cβ · xγk ·

∂f
∂xcβ

−

∂f
∂xaβ (cid:17)

∂f
∂xaβ (cid:17)

,

(cid:16)

−

(3)

∂f
∂xac

(cid:16)

+

xaβ · λ · uaβ→ac ·

Xa

Xβ

Xc

8

or equivalently to the form:

Ltf (x) =

n

m

n

Xa6=c

Xβ

Xc

(xaβ · qaβ→cβ − xcβ · qcβ→aβ) ·

∂f
∂xcβ

n

m

n

n

m

+

Xa6=c

Xβ

Xc

Xγ
m

Xs
n

m

(xaβ · δint · qγs

aβ→cβ · xγs − xcβ · δint · qγs

cβ→aβ · xγs) ·

∂f
∂xcβ

(4)

+

(xcs · λ · ucs→cβ − xcβ · λ · ucβ→cs) ·

Xβ

Xc

Xs6=β

∂f
∂xcβ

.

This is a ﬁrst order partial diﬀerential operator, that generates a deterministic Markov

process, whose dynamics are governed by the characteristic equations of Lt:

˙xij =

m

Xk6=j

+

(xik · λ · uik→ij − xij · λ · uij→ik) +

(xaj · qaj→ij − xij · qij→aj)

n

Xa6=i

(5)

(xaj · δint · qγk

sj→ij · xγk − xij · δint · qγk

ij→aj · xγk).

m

n

n

Xk

Xa6=i

Xγ

These calculations make the following result plausible:

Proposition 1. Given the Markovian interaction we introduced above consisting of the

decision, the pressure-resistance and the evolution structures, if the elements of the matrix-

valued function x = (xij) denote the occupation probabilities of states (i, j), and (ui,k→j)

is the decision matrix that may depend on time, the evolution of x is given by system (5).

Remark. For a rigorous explanation (not just the formal description that we provide

here) of the Markov chain’s convergence to the deterministic process given by (5), see,

e.g., Kolokoltsov (2012).

The above general structure is rather complicated. To deal eﬀectively with this com-

plexity, one can distinguish two natural simplifying frameworks: (i) the set of edges is

ordered and only the transitions between neighbours are allowed, (ii) the corresponding

graph is complete, so that all transitions are allowed and have comparable rates. We

shall choose the second alternative for B, and the ﬁrst alternative for H thinking of it

as an hierarchy of agents. Moreover, we shall assume that the binary interaction occurs

only within a common level in H, ignoring the binary interaction between the agents in

9

diﬀerent levels of the hierarchy structure. Therefore, for the transition rates qij→i+1,j of

the pressure structure increasing in i ∈ H, we introduce the shorter notation q+

ij , and for

the transition rates qij→i−1,j decreasing in i ∈ H, we introduce the notation q−

ij . Accord-

ingly, for the transition rates qik

ij→i+1,j of the hierarchical evolution structure increasing

in i ∈ H, we introduce the shorter notation q+k

ij , and for the transition rates qik

i→i−1,j

decreasing in i ∈ H, we shall use the notation q−k
ij .

H

i

s

•

•

•

•

•

q+
ij

q−
ij

•

•

•

•

•

j

•

•

•

•

usj→sl(λ)
•

k

q+k
il

q−k
il

•

•

•

•

•

l

•

•

•

•

•
B

Figure 1: The simpliﬁed version of our network: only the transitions between neighbours
are allowed in H, all transitions are allowed in B, binary interaction occurs only within
a common level in H.

Applying the above simpliﬁcations, the kinetic equations (5) reduce to the following

system:

˙xij = λ ·

+δint ·

Xk6=j

Xk∈B

(uik→ijxik − uij→ikxij) + q−

i+1,j · xi+1,j + q+

i−1,j · xi−1,j − (q+

ij + q−

ij) · xij

(q+k

i−1,j · xi−1,k · xi−1,j + q−k

i+1,j · xi+1,k · xi+1,j − (q+k

ij + q−k

ij ) · xik · xij).

(6)

Note that equations (6) hold only for the internal states (i, j), i ∈ H, j ∈ B, such

that i 6= 1, |H|. On the contrary, for the boundary states (i, j) the terms involving

downgrading to i − 1 and upgrading to i + 1 respectively are omitted. In particular, we

consider:

nj = q−k
q+k

1j = 0 ,

nj = q−
q+

1j = 0.

(7)

10

Additionally, to simplify further the ﬁnal explicit calculations, for all i ∈ H, j ∈ B,

we shall consider the constraint:

ij = q−
q+

i+1,j,

(8)

which can be interpreted as a detailed balance condition;

it actually asserts that the

number of downgrades is compensated in average by the number of upgrades.

Remark. An alternative simple (and analogously manageable) model allows the principal

either to move an agent one-step upward in the hierarchy with rates q+

ij and q+k
ij

respec-

tively, or send an agent directly down to the lowest state with rates qd

ij and qdk

ij respectively.

In this case the system describing the evolution of occupation densities becomes, for i 6= 1:

˙xij = λ ·

Xk6=j

(ui,k→j · xik − ui,j→k · xij) + q+

i−1,j · xi−1,j − (q+

ij + qd

ij) · xij

(9)

+δint ·

Xk∈B

(q+k

i−1,j · xi−1,k · xi−1,j − q+k
ij

· xik · xij) − δint ·

qdk
ij · xik · xij,

Xk∈B

with an obvious modiﬁcation for i = 1.

To identify the agents’ optimal decision vector, we need ﬁrst to deﬁne certain game

characteristics such as the state rewards and the transition costs. In particular, we assign

the reward wij per unit of time to an agent for staying in state (i, j), the fee/cost f B

kj for an

agent’s elective transition from state (h, k) to state (h, j) (which we assume independent

of h for brevity), and the ﬁne/cost f H
j

for an agent’s enforced transition from state (j, b)

to state (j − 1, b) (which we assume independent of b for brevity). Let, additionally,

gij = gij(t) be the payoﬀ corresponding to the state (i, j) in the process starting at time t

and terminating at time T . Then, for an inﬁnitesimally small time step τ , and assuming

that g(t) is diﬀerentiable in time, an agent at state (i, j) decides his/her strategy targeting

to optimize the expression:

11

gij(t) = max

u n

τ · wij + τ ·
m

+q+

ij · gi+1,j(t + τ ) +

Xk

(cid:16)
xik · δint · (q+k

λ · uij→ik · (gik(t + τ ) − f B

jk) + q−

ij · (gi−1,j(t + τ ) − f H
i )

ij gi+1,j(t + τ ) + q−k
m

ij (gi−1,j(t + τ ) − f H

i ))

(10)

(cid:17)

+

1 − τ · (λ · uij→ik + q+
(cid:16)

ij + q−

ij +

xik · δint · (q+k

ij + q−k

ij ))

· gij(t + τ )

.
o

(cid:17)

Xk

Remark. Depending on the application we choose to investigate in each instance, the

agents’ optimum can be either to maximize his/her payoﬀ/ﬁtness, or to minimize his/her

cost. Here we stick to the ﬁrst case, thinking of bribed bureaucrats or defending civilians.

Taking the Taylor expansion speciﬁcally of the term gij(t + τ ), and omitting terms of

order O(τ 2), the above optimization equation turns into the form:

wij +

∂gij(t)
∂t

+ max

u n

λ · uij→ik · (gik(t + τ ) − f B

jk − gij(t))

m

+

xik · δint ·

Xk

(cid:16)

q+k
ij

· (gi+1,j(t + τ ) − gij(t)) + q−k
ij

o
· (gi−1,j(t + τ ) − f H

i − gij(t))

(11)

(cid:17)

+q+

ij · (gi+1,j(t + τ ) − gij(t)) + q−

ij · (gi−1,j(t + τ ) − f H

i − gij(t)) = 0.

In the limit of inﬁnitesimally small time step τ → 0, equation (11) implies the evolu-

tionary Hamilton-Jacoby-Bellman (HJB) equation, that is satisﬁed by the individual opti-

mal payoﬀs gij. A rigorous derivation of the HJB equation can be found in every standard

textbook on dynamic programming and optimal control, see, e.g., Kamien and Schwartz

(1991). In particular for stochastic dynamic programming, see, e.g., Ross (2014).

The above yields the following result:

Proposition 2. Given the Markovian interaction we introduced above consisting of the

decision, the pressure-resistance and the evolution structure, if gij = gij(t) denotes the

payoﬀ to an agent at state (ij) in the process starting at time t and terminating at time

T , and subject to a given evolution of the occupation density vector x given by (6), these

individual optimal payoﬀs gij(t) will satisfy the following evolutionary HJB equation:

12

˙gij + λ · max

u

{uij→ik · (gik − gij − f B

jk)} + q+

ij · (gi+1,j − gij) + q−

ij · (gi−1,j − gij − f H
i )

+δint ·

(cid:16)Xk∈B

q+k
ij

· xik · (gi+1,j − gij) +

q−k
ij

· xik · (gi−1,j − gij − f H
i )

+ wij = 0.

(cid:17)

Xk∈B

(12)

As above, note that equations (12) hold only for the internal states (i, j), i ∈ H,

j ∈ B, such that i 6= 1, |H|. For the boundary states (i, j) the terms involving transitions

to i − 1 or from i + 1 respectively are omitted. Indicatively, for i = 1 it is:

˙g1j = w1j + λ max

u

{u1,j→k(gik − g1j − f B

jk)} + q+

1j(g2,j − g1,j) + δint

q+k
1j xik(g2j − g1j).

Xk∈B

We consider here the optimization problem of estimating the discounted optimal payoﬀ

(alternatively one can look for the average payoﬀ in a long time horizon). Hence, assuming

the discounting coeﬃcient δdis for future payoﬀs, the evolutionary HJB equation for the

discounted optimal payoﬀ e−δdis·t · gij(t) of an agent at state (i, j), with any ﬁnite planning

horizon T , can be written as:

˙gij + λ · max

u

{uij→ik · (gik − gij − f B

jk)} + q+

ij (gi+1,j − gij) + q−

ij (gi−1,j − gij − f H
i )

+

δint · xik ·

Xk∈B

(cid:16)

ij (gi+1,j − gij) + q−k
q+k

ij (gi−1,j − gij − f H
i )

+ wij = δdis · gij(t).

(cid:17)

(13)

The basic mean-ﬁeld game consistency problem states that, for some interval [0, T ],

every agent will beneﬁt from applying the same common control, that is, from adopting

the same decision vector. In other words, the MFG consistency condition states that one

needs to consider the kinetic equations (6) (i.e. the forward system), where the collective

control is taken into account, and the evolutionary HJB equations (13) (i.e. the backward

system), where individual controls are used, as a coupled forward-backward system of

equations on a given time horizon [0, T ], complemented by some initial condition x0 for

the occupation density vector x, and some terminal condition gT for the optimal payoﬀ

g, such that x, g and the common u solve the aforesaid system. Our aim here is ﬁrst to

13

identify the solution of the stationary consistency problem, and then to investigate the

general time-dependent problem, extending (if possible) our ﬁndings for the stationary

problem. As mentioned, we shall work in three asymptotic regimes; fast execution of the

agents’ personal decisions, weak binary interactions, and small payoﬀ discounting in time.

3 Stationary Problem

The stationary MFG consistency problem consists of the stationary HJB equation for the

discounted optimal payoﬀ e−δdis·t · gij of an agent at state (i, j), with a ﬁnite time horizon:

wij + λ · max

u

ui,j→k · (gik − gij − f B

jk) + q+

ij · (gi+1,j − gij) + q−

ij · (gi−1,j − gij − f H
i )

+δint ·

xik ·

Xk∈B

(cid:16)

q+k
ij

· (gi+1,j − gij) + q−k
ij

· (gi−1,j − gij − f H
i )

= δdis · gij,

(cid:17)

(14)

where the evolution given by (6) is replaced with the corresponding ﬁxed point condition:

λ ·

Xk6=j

+δint ·

(ui,k→j · xik − ui,j→k · xij) + q−

i+1,j · xi+1,j + q+

i−1,j · xi−1,j − (q+

i,j + q−

i,j) · xij

i−1,j · xi−1,k · xi−1,j + q−k
q+k

i+1,j · xi+1,k · xi+1,j − (q+k

ij + q−k

ij ) · xik · xij = 0.

Xk∈B

(15)

By analogy with the time-dependent problem, for the stationary MFG consistency

problem one needs to consider (14),(15) as a coupled stationary system. In the asymptotic

limit of fast execution of individual decisions, λ → ∞, the terms in (14),(15) containing

the transition rates λ should obviously vanish (otherwise they would ‘explode’ to inﬁnity).

For a practical interpretation of this observation, one can think that if the execution of

personal decisions is signiﬁcantly fast, then in a stationary state no agent should be

interested in switching strategy. In this case (14),(15) turn respectively into the form:

wij + q+

ij · (gi+1,j − gij) + q−

ij · (gi−1,j − gij − f H
i )

+δint ·

xik ·

Xk∈B

(cid:16)

q+k
ij

· (gi+1,j − gij) + q−k
ij

· (gi−1,j − gij − f H
i )

= δdis · gij,

(cid:17)

(16)

14

and,

+δint ·

Xk∈B

q−
i+1,j · xi+1,j + q+

i−1,j · xi−1,j − (q+

i,j + q−

i,j) · xij

i−1,j · xi−1,k · xi−1,j + q−k
q+k

i+1,j · xi+1,k · xi+1,j − (q+k

ij + q−k

ij ) · xik · xij = 0,

supplemented by the consistency condition:

gik − gij − f B

jk ≤ 0,

(17)

(18)

for all i ∈ H, j, k ∈ B, such that xij 6= 0. In fact, the consistency condition (18) ensures

that all terms in (14) and (15) including elements of the decision matrix indeed vanish in

(16) and (17) respectively, for all the occupied states.

Introducing further the auxiliary notation ˜wij = wij − q−

ij · f H
i

, (16) and (17) are

written respectively in the form:

(−AT

j + δdis − δint · ET

j (x)) · gij = ˜wij − δint · f H
i

and,

(Aj + δint · Ej(x)) · xij = 0,

q−k
ij

· xik,

·

Xk∈B

(19)

(20)

where the matrices Aj, with the transpose matrix AT

j , and Ej(x), with the transpose

matrix ET

j (x), are given respectively by:

Aj =

−q+
1j
q+
1j −q+

q−
2j
2j − q−
2j

. . .

. . .

. . .

. . .

q+
n−2,j

0


















0

q−
3j

. . .

−q+

n−1,j − q−
q+
n−1,j

n−1,j

. . .

. . .

. . .

q−
nj
−q−
nj

,


















(21)

15

and,

−



Ej =

Pk


















q+k
1j x1k

Pk

q+k
1j x1k −

q−k
2j x2k

Pk
2j + q−k
(q+k

2j )x2k

Pk

. . .

. . .

. . .

. . .

q+k
n−2,jxn−2,k −

Pk

Pk

0

0

q−k
3j x3k

Pk

. . .

(q+k

n−1,j + q−k

n−1,j)xn−1,k

q+k
n−1,jxn−1,k

Pk

. . .

. . .

. . .

q−k
nj xnk

Pk
−

Pk

q−k
nj xnk

. (22)




















We shall look further for the asymptotic regime with small rates δint · q±k

ij . Therefore,

starting with (20) we are looking for stationary solutions of the form:

xij = x0

ij + δint · x1

ij + O(δ2

int).

(23)

Substituting (23) into (20), and equating terms of the same order in δ0

int, δ1

int, we

obtain respectively the following equations:

Aj · x0

ij = 0,

Aj · x1

ij + E0

j · x0

ij = 0,

(24)

(25)

where the notation E0

j corresponds to the matrix Ej containing only elements of order

O(δ0

int) (we use respectively the notation E0T
j

for the transpose matrix).

Assumption 1. Let the detailed balance condition (8) hold with all q+

ij (or q−

ij ) being

strictly positive. We shall use the shorter notation, for i ∈ H : i 6= n, j ∈ B:

qij = q+

ij = q−

i+1,j.

(26)

In the linear approximation of vanishing δint, we end up with an uncoupled system.

Since diﬀerent elements of B are also uncoupled, then (24),(25) can be solved separately

for any j ∈ B. Looking at the zero order of small evolution transition rates, by (24), we

have the following result:

16

Proposition 3. Let Assumption 1 hold. Then, the rank of Aj is exactly n − 1, while the

kernel of Aj is generated by the following vector:

x0
2j =

q+
1j
q−
2j

· x0

1j,

x0
3j =

q+
2j
q−
3j

·

q+
1j
q−
2j

· x0

1j,

. . . ,

x0
nj =

q+
lj
q−
l+1,j

n−1

Yl=1
−1

· x0
1j

(27)

x0
1j = 

1 +



q+
1j
q−
2j

+

q+
2j
q−
3j

·

q+
1j
q−
2j

+ · · · +

n−1

Yl=1

q+
lj
q−
l+1,j

· x0
j ,





where we have introduced the notation x0

j =

i x0

ij. Speciﬁcally, under the detailed balance

P
condition Aj is symmetric, and its kernel generated by (27) is proportional to the uniform

distribution, x0

ij = x0

j /n for all i ∈ H, j ∈ B, that is, Ker(Aj) is generated by (1, . . . , 1).

Proof. Notice that system (24) is degenerate, as expected, since we are looking for non-

negative solutions satisfying

j(x0

1j + · · · + x0

nj) = 1. Thus, one of the n equations of (24)

can be discarded, say for example the last one. Rewriting the system of the remaining

P

(n − 1) equations by using the ﬁrst equation, and then adding sequentially to each of the

next (n − 2) equations their previous one, one eventually obtains the following system:

1j · x0
q+

1j − q−

2j · x0

2j = 0

2j · x0
q+

2j − q−

3j · x0

3j = 0

...

(28)

n−1,j · x0
q+

n−1,j − q−

nj · x0

nj = 0.

This has an obvious solution, that is unique up to a multiplier, and is given by (27).

Alternatively, starting the exclusion from the last equation of (28), the solution to (24) is:

x0
n−1,j =

q−
nj

q+
n−1,j

· x0

nj, x0

n−2,j =

q−
n−1,j
q+
n−2,j

·

q−
nj

q+
n−1,j

· x0

nj,

. . . , x0

1j =

n−1

Yl=1

q−
l+1,j
q+
l,j

· x0
nj

x0
nj = 

1 +



q−
nj

q+
n−1,j

+

q−
n−1,j
q+
n−2,j

·

q−
nj

q+
n−1,j

+ · · · +

n−1

Yl=1

q−
l+1,j
q+
l,j

−1





· x0
j .

(29)

Given now the detailed balance condition (8), and the non-degeneracy established by

17

Assumption 1, one observes from (27), or (29), that for every strategy j ∈ B we have:

x0
1j = x0

2j = · · · = x0

nj = x0

j /n.

We have shown that in the main order of small evolution rates δint · q±κ

ij , x0∗

ij = x0∗

j /n

is a ﬁxed point of the evolution (6), along with the common control ucom = (uij→iκ = 0),

∀i ∈ H, ∀j, κ ∈ B, that is consistent with condition (18), and expresses the instantaneous

execution of personal decisions. This will also be a stable solution of the stationary system,

if x0∗

ij = x0∗

j /n is a stable ﬁxed point of (6), for ucom = (uij→iκ = 0), ∀i ∈ H, j, κ ∈ B.

Assumption 2. For technical (computational) purposes only, let the hierarchy and the

strategy set be of the same size, i.e. |H| = |B| ⇒ n = m.

To conduct the stability analysis, in the asymptotic regimes of large λ and small δint,

let us introduce the auxiliary variables:

yκ = x0

ij − x0∗
ij ,

(30)

where κ = i + (j − 1) · n, such that κ ∈ K = {1, . . . , n2 − 1}.

Using the above variables, we transform system (6) into the non-degenerate linear

homogeneous system:

where Λ is the block matrix:

˙y = Λ · y,

A1



0

. . .

. . .

. . .

0

0 A2

0

. . .

0 Aj

. . .

. . .

0 An−1

∆ . . .

. . .

∆

Λ =
















(31)

(32)

.

. . .

. . .

. . .

0

D


















Each matrix ∆ has the same non zero entries −q−

nn on its bottom row, while the rest of

18

its elements are equal to zero. Note, as well, that the Aj matrices are of dimension n × n,

and each zero matrix to the right of an Aj matrix is of dimension n × n · (n − j) − 1. The

(n − 1) × (n − 1) matrix D is given by:

D =

−q+
1n
1n −q+
q+

q−
2n
2n − q−
2n

. . .

. . .

. . .

. . .

q+
n−3,n

0


















0

q−
3n

. . .

. . .

. . .

. . .

−q+

n−2,n − q−
q+
n−2,n − q−
nn

n−2,n

q−
n−1,n
n−1,n − q−

−q+

n−1,n − q−
nn

.

(33)


















Applying sequentially (starting with C1 ≡ A1, setting in the next step C1 ≡ A2 etc.)

the following block matrix formula:

det 




C1

0

C2 C3







= det C1 · det C3,

where C1, C2, and C3 are n × n, m × n, and m × m matrices respectively, the determinant

of Λ is given by:

det Λ = det(A1) · det(A2) · · · det(An−1) · det D.

(34)

We further apply sequentially n − 1 times the elementary row operation of row addition

on every n × n matrix Aj, starting with row n and adding in each step row i to row i − 1.

Eventually, we transform Aj into a lower triangular matrix of the form:

0

0

1j −q−
q+
2j

0

0

. . .

. . .

. . .

. . .

. . .

n−2,j −q−
q+
n−1,j
n−1,j −q−
q+
nj

0

0


















. . .

. . .

. . .

,


















(35)

with a single zero eigenvalue, and n − 1 negative eigenvalues −q−

ij, for i = 2, . . . , n. Note

that since Aj are symmetric matrices (due to the detailed balance condition), the algebraic

multiplicity of each of their eigenvalues is equal to the geometric multiplicity.

19

Regarding the (n − 1) × (n − 1) matrix D, and bearing in mind the detailed balance

condition, we apply once the elementary row operation of adding row n − 1 to row n − 2,

and then, we apply sequentially n − 2 times the elementary column operation of adding

column i to column i + 1, starting with column 1, to eventually transform D into the

following lower triangular form:

0

0

. . .

−q+
1n



q+
1n

. . .

. . .

. . .
















0

−q+
2n

. . .

q+
n−3,n

0

−q−
n,n
n−2,n − q−

(q+

n,n) −q−

n−1,n

. . .

. . .

. . .

0

,


















(36)

with n − 1 negative eigenvalues −q+

in, for i = 1, . . . , n − 1. In total, we ﬁnd that matrix Λ

has one zero eigenvalue of algebraic multiplicity n − 1, and n · (n − 1) negative eigenvalues.

Now it is trivial to transform Λ into a block diagonal matrix, subtracting sequentially from

each column i, ∀i = {1, . . . , n · n − n}, each column j, ∀j = {n · n − n + 2, . . . , n · n − 1}.

For a block diagonal matrix, both the algebraic and the geometric multiplicity of an

eigenvalue is given by adding the multiplicities from each block. Then, for the block matrix

Λ the algebraic multiplicity of the zero eigenvalue is equal to its geometric multiplicity.

We, thus, have the following result:

Lemma 1. Let the Assumptions 1, 2 hold. Consider the linear system ˙y = Λ · y as deﬁned

above. The solution to this system, that is the vector x0∗

j /n given by Proposition 3,
is stable (but not asymptotically stable) since Λ has n · (n − 1) negative eigenvalues, and

ij = x0∗

a single zero eigenvalue whose algebraic multiplicity equals to its geometric multiplicity.

The third asymptotic regime we shall look at is that of small discounting δdis. Obvi-

ously, no payoﬀ discounting terms appear in the stationary kinetic equations (17). Moving

to the stationary HJB equation (16), or (19), initially we are looking for solutions of the

form:

gij = g0

ij + δdis · g1
ij.

(37)

Substituting (37) into (19), and equating terms of zero order in δint and δdis, we get

20

the equation:

−AT

j · g0

ij = ˜wij,

(38)

In general, equation (38) has no (non-degenerate) solution, since (by Proposition 3)

the kernel of the symmetric matrix AT

j = Aj is one dimensional, implying that the image

of the transpose matrix AT
j

is (n − 1) dimensional (by the rank-nullity theorem). More

precisely, equation (38) has no solution if:

( ˜wij, x0

ij) =

x0
j
n

·

Xi

˜wij 6= 0.

(39)

Thus, to remain in the non-degenerate regime, we need to introduce additionally the

following assumption;

Assumption 3. For every strategy j ∈ B the following is true;

˜wij 6= 0.

Pi

As a result, we are looking next for solutions of (19) in the form of the expansion:

gij = g0

ij /δdis + g1

ij + g2

ij · δdis.

(40)

Recall that we are looking at the asymptotic regime with small δint (weak binary in-

teraction), and small δdis (small discounting). One needs to distinguish clear assumptions

on the relation between the small parameters δint and δdis, for a full perturbation analysis.

In principle, three basic regimes can be naturally identiﬁed:

ID1: Interaction is relatively very small, i.e. δdis = δ and δint = δ2.

ID2: Interaction and Discounting are small eﬀects of comparable order, i.e. δdis =

δint = δ.

ID3: Discounting is relatively very small, i.e. δint = δ and δdis = δ2.

We initially concentrate on the ID1 regime. Substituting (40) into (19), and equating

terms of order δ−1, δ0, δ1, we ﬁnd respectively the following equations:

21

AT

j · g0

ij = 0

−AT

j · g1

ij + g0

ij = ˜wij

(41)

−AT

j · g2

ij + g1

ij − E0T
j

· g0

ij = 0.

The ﬁrst equation in (41) tells us that g0

ij belongs to the kernel of Aj (since Aj = AT

j ),

that is, for arbitrary constants aj ∈ R, we get:

g0
ij = aj · x0
ij.

(42)

The second equation in (41) tells us that ˜wij − g0

ij belongs to the image of Aj, which

coincides with the orthogonal compliment to Ker(Aj), given the identity:

Im(Aj) = Ker⊥(AT

j ).

Besides, from Proposition 3 we ﬁnd that the orthogonal compliment to Ker(Aj) is:

Ker⊥(Aj) = {x :

xij = 0}.

Xi

In this case, the fact that ˜wij − g0

ij ∈ Im(Aj) further implies that:

˜wij =

Xi

Xi

ij ⇒ · · · ⇒ g0
g0

ij =

˜wij /n.

Xi

(43)

(44)

Looking at the third equation in (41), and noting that E0T g0

ij = 0 for a uniform g0
·j,

we conclude that g1

ij ∈ Im(Aj) as well, that is, g1
need to invert Aj on the reduced (n − 1) dimension of Ker⊥(Aj).

ij ∈ Ker⊥(Aj). Thus, to identify g1

ij we

Lemma 2. Let Assumption 1 hold, and let y ∈ Ker⊥(Aj). Then all solutions z to the

matrix equation Aj · z = y are given by the formula:

zij = z1j −

i−1

a

(cid:18)

Xa=1

Xβ=1

yβj
,
qaj (cid:19)

(45)

22

∀i 6= 1, with arbitrary z1j. There exists a unique solution z·j ∈ Ker⊥(Aj) speciﬁed by:

z1j =

n−1

(cid:18)

Xa=1

n − a
n

·

a

Xβ=1

yβj
qaj (cid:19)

.

(46)

Notice that formulae (45) and (46) yield zij = g1

ij when yij = ˜wij − g0

ij. In particular,

for g1

ij we ﬁnd the explicit expression:

g1
ij =

n−1

(cid:18)(cid:16)

Xa=1

1(i > a) ·

n − a − 1
n

+ 1(i ≤ a) ·

n − a

n (cid:17)

a
qaj

·

(cid:16)

·

˜wκj
n

−

a

Xβ=1

˜wβj
,
qaj (cid:17)(cid:19)

Xκ∈H

(47)

where 1(·) is the indicator function.

Regarding the consistency condition (18), in the main order in small δ it can be written

in the equivalent form:

˜wik <

˜wij,

Xi

Xi

(48)

for all i ∈ H, k, j ∈ B. Given that ˜w·,· does not depend on δ, this leads to the interesting

result that in the equilibrium of the asymptotic regime of small δ, only those strategic

levels j ∈ B are occupied (that is, x0

j 6= 0), where the sum

i ˜wij obtains its maximum.

For simplicity, let us further consider the following assumption;

P

Assumption 4. There exists a unique behavioural level b ∈ B, such that:

˜wib >

˜wij.

Xi

Xi

(49)

for all j ∈ B, such that j 6= b.

Note that Assumption 4 implies that in any equilibrium x∗, with δ suﬃciently small,

all terms with j 6= b become irrelevant for the analysis.

We, thus, have the following result:

Proposition 4. Let Assumptions 1, 2, 3 and 4 hold. Consider the ID1 regime. Then,

the solution to the stationary problem described by (16), (17) and (18), in the main order

23

in small δ, is given by:

ib = x0∗
x∗

ib = 1/n,

x0∗
iκ = 0 ∀κ 6= b ∈ B, i ∈ H,

gib = δ−1 · g0

ib = δ−1 ·

˜wib/n, (50)

Xi

where x0∗

ij is a stable ﬁxed point of (6).

Remark. If we continue in the next order of our perturbation analysis (subsequently in

the second next order, and so forth) we can obtain explicit approximate solutions with

arbitrary precision.

Next we consider the ID2 regime. In this case, we look at the solutions to (17) in the

next order with respect to small δ. In view of (50), we write (25) in the form:

Ab · x1

ib + (q+b

i−1,b − q+b

ib + q−b

i+1,b − q−b

ib )/n2 = 0,

(51)

where

i x1

ib = 0, and the usual convention for the boundary terms, i = 1, n, apply.

P

Note that the right-hand side of Equation (51) belongs to Ker⊥(Aj), implying that:

−(q+b

i−1,b − q+b

ib + q−b

i+1,b − q−b

ib )/n2 = 0,

(52)

Xi

Moreover, given that x1

lae (45), (46) yield zib = x1

ib ∈ Ker⊥(Aj), we can identify x1
ib + q−b
ib when yib = −(q+b

i−1,b − q+b

ib applying Lemma 2. Formu-
i+1,b − q−b

ib )/n2.

Regarding the solution to (19) in ID2, substituting (40) into (19), and equating terms

of order δ−1, δ0, δ1, we get respectively the following equations:

AT

j · g0

ij = 0

−AT

j · g1

ij + g0

ij − E0T
j

· g0

ij = ˜wij

(53)

−AT

j · g2

ij + g1

ij − E0T
j

· g1

ij − E1T
j

· g0

ij = −f H
i

·

q−k
ij

· x0

ik,

Xk

where the notation E1

j corresponds to the matrix Ej containing only elements of order

O(δint) (we use respectively the notation E1T
j

for the transpose matrix).

24

The ﬁrst two equations in (53) are identical with the corresponding equations in (41)

(recall that E0T

j g0

ij = 0 for a uniform g0

ij), and provide the same results expressed through

(42), (44). Looking at the third equation in (53), and noting that E1T

j g0
ik) ∈ Ker⊥(Aj), implying that g1

ij = 0, we observe

ij can be uniquely

that (g1

ij − E0T

j g1

ij + f H
i

·

k q−k
ij

· x0

identiﬁed through formula (45) of Lemma 2, with zij = g1

ij and yij = ˜wij − g0

ij, under the

P

condition:

(g1

ij − E0T
j

· g1

ij + f H
i

q−k
ij

· x0

ik) = 0.

Xk

Xi

(54)

Last we consider the ID3 regime. Substituting (40) into (19), but equating now terms

of order δ−2, δ−1, δ0, we get the equations (in analogy to (41), (53)):

AT

j · g0

ij = 0

E0T
j

· g0

ij = 0

(55)

−AT

j · g1

ij + g0

ij − E1T
j

· g0

ij = ˜wij.

Again, the ﬁrst and the third equations in (55) lead to the same results with the ﬁrst

and the second equations in (41), namely to (42) and (44) respectively, while the second

equation in (55) always holds for a uniform g0
ij.

We, thus, have the following result:

Proposition 5. The solution to the stationary consistency problem in the main order in

small δ in ID2 and ID3, is the same with the one identiﬁed in Proposition 4 for ID1.

4 Time-dependent Problem

The solution to a non-linear Markov game of mean-ﬁeld type like the one we consider

here (on a ﬁnite time horizon), deﬁnes an epsilon-Nash equilibrium of the corresponding

game with a ﬁnite number of players, see, e.g., Basna, Hilbert and Kolokoltsov (2014).

Having identiﬁed the solution to the stationary MFG consistency problem, we need next

to look at the time-dependent consistency problem in order to validate our results for ini-

tial/terminal conditions other than those given by the solution of the stationary problem.

25

We further need to investigate the stability of the ﬁxed point x0∗

ij (see Lemma 1) without

necessarily assuming that from the very beginning all players apply the same stationary

control ucom = (uij→iκ = 0).

For the full time-dependent problem, the HJB equation for the discounted optimal

payoﬀ e−δdis·t · gij(t) of an individual at state (i, j) with any planning horizon T is given by

(13), where the occupation density vector x = (xij) is also time varying. For deﬁniteness,

we shall focus on the ID1 regime (the same method applies for ID2, ID3 regimes). Our

aim is to show that by ﬁxing the control uiα→iβ = 0 in (13), ∀i ∈ H, α, β ∈ B, the solution

to the resulting system:

˙giα + wiα + q+

iα · (gi+1,α − giα) + q−

iα · (gi−1,α − giα − f H
i )

δint · xik · (q+k

iα · (gi+1,α − giα) + q−k

iα · (gi−1,α − giα − f H

i )) = δdis · giα(t),

(56)

+

Xk∈B

will be consistent, that is, the control uiα→iβ = 0 will indeed give a maximum in (13)

in all times. Fixing the control uiα→iβ = 0, ∀i ∈ H, α, β ∈ B, is actually equivalent to

assuming that:

giβ(T ) − f B

αβ ≤ giα(T ).

(57)

Our aim here is to show that starting with a terminal condition belonging to the cone

deﬁned by (57), we shall stay inside the cone for all t ≤ T . Therefore, it is suﬃcient

to show that on the boundary of this cone the inverted tangent vector of (56) is never

directed outside the cone. The necessary condition that needs to be satisﬁed for this to

be true for any boundary point gjβ − f B

αβ = gjα is the following:

˙gjα − ˙gjβ ≤ 0,

(58)

where,

26

˙gjα − ˙gjβ = δdis · (gjα − gjβ) + (wjβ − wjα) + q+

jβ · (gj+1,β − gjβ)

−q+

jα · (gj+1,α − gjα) + q−

jβ · (gj−1,β − gjβ − f H

j ) − q−

jα · (gj−1,α − gjα − f H
j )

(59)

+

δint · xjk ·

Xk∈B

jβ · (gj+1,β − gjβ) + q−k
q+k

jβ · (gj−1,β − gjβ − f H
j )

(cid:16)

−q+k

jα · (gj+1,α − gjα) − q−k

jα · (gj−1,α − gjα − f H
j )

.
(cid:17)

We substitute into (59) gij and xij, taken from (40) and (23) respectively. Assuming,

then, that f H
j

is independent of δ, and equating terms of similar order, in the main order

O(δ−1) in small δ, condition (58) is equivalent to (recall that we are in the ID1 regime):

jβ · (g0
q+

j+1,β − g0

jβ) + q−

jβ · (g0

j−1,β − g0

jβ) ≤ q+

jα · (g0

j+1,α − g0

jα) + q−

jα · (g0

j−1,α − g0

jα). (60)

Note that in the main order O(δ−1) in small δ (assuming that f B

αβ is also independent

of δ) for the speciﬁed boundary point of the cone, we get:

jβ = g0
g0

jα,

while for all the other i ∈ H, such that i 6= j, will be:

iβ ≤ g0
g0
iα.

Combining (61) and (62) we obviously get:

jα − g0
g0

iα ≤ g0

jβ − g0
iβ,

and rewriting (60) in the equivalent form:

(61)

(62)

(63)

jα · (g0
q+

jα − g0

j+1,α) + q−

jα · (g0

jα − g0

j−1,α) ≤ q+

jβ · (g0

jβ − g0

j+1,β) + q−

jβ · (g0

jβ − g0

j−1,β), (64)

we check that condition (64) is satisﬁed when qiα ≤ qiβ, ∀i ∈ H (the ﬁrst term is smaller

27

or equal than the third term, the second term is smaller or equal than the fourth term).

But also for the case when qiβ < qiα, ∀i ∈ H, rewriting (63) in the equivalent form:

iβ − g0
g0

jβ ≤ g0

iα − g0

jα,

(65)

we check that (60) is satisﬁed (again the ﬁrst term is smaller or equal than the third term,

the second term is smaller or equal than the fourth term).

Thus we obtain the following main result:

Theorem 1. Let Assumptions 1, 2, 3 and 4 hold. Assume additionally, ∀α, β ∈ B, that:

qiα ≤ qiβ

or

qiβ < qiα,

∀i ∈ H.

(66)

Then, for suﬃciently small discounting δdis = δ, and relatively smaller binary interaction

coeﬃcient δint = δ2, in the main order in small δ, for any T > t, and for any initial

occupation probability distribution x(t), and any terminal payoﬀs such that:

giβ(T ) − f B

αβ ≤ giα(T ),

there exists a unique solution to the time-dependent discounted MFG consistency problem

such that the control u is stationary, and is given by uiα→iβ = 0, ∀i ∈ H, ∀α, β ∈ B, x(s)

stays near the ﬁxed point of Proposition 4 as s → T , and gij(s) stays near the stationary

solution of Proposition 4 (almost for all time), for large T − t.

5 Discussion

In this paper we formulate the interaction of a large number of small players under

the pressure of a major player (principal), on n-dimensional arrays, having in mind the

paradigm of individuals defending against a bio-terrorist; alternatively, the similar con-

text of corrupted tax inspectors against a benevolent authority. The n-dimensional arrays

dual structure naturally describes on the one hand the distribution of individuals among

m levels of ‘behaviour’ (e.g. levels of defence) and on the other, their distribution accord-

ing to a phenotypic characteristic among n levels of ‘hierarchy’ (e.g. levels of infection).

28

Transitions on the ﬁrst network structure are mainly subject to the individuals’ control,

while transitions on the second are mainly subject to the principal’s pressure. Transitions

on both structures may as well be an outcome of the individuals’ binary interactions. Our

model is a performance of a ﬁnite state non-linear Markov game combining mean-ﬁeld,

evolutionary, and pressure-resistance types of interaction. For our analysis, we consider

the discounted mean-ﬁeld game consistency problem. According to the general frame-

work of mean-ﬁeld games we analyse the forward-backward system of coupled equations,

the kinetic equations governing the evolution of the individuals’ distribution among the

n × m states (forward equation), and the Hamilton-Jacobi-Bellman equation giving the

individuals’ optimal payoﬀ (backward equation). We solve the stationary problem and we

provide a link of the stationary solution to the time-dependent problem. For simplicity,

we work in the asymptotic regimes of fast execution of personal decisions, weak binary

interactions, and small payoﬀ discounting in time. Considering a stationary control that

is consistent with the assumption of fast execution of personal decisions, in the main

order of small payoﬀ discounting in time (or in the main order of weak binary interac-

tions), we ﬁnd that individuals will be uniformly distributed among the ‘behaviours’ of

the unique ‘hierarchy’ level where the sum of rewards is maximised, and we obtain the

optimal payoﬀ as a function of these rewards. We show that there is a unique solution to

the time-dependent problem, that is very close to the stationary solution. Our simpliﬁ-

cations, while necessary for concrete calculations, represent the ﬁrst step towards a more

comprehensive treatment of the game that we have introduced and explicitly formulated.

Acknowledgements

Stamatios Katsikas would like to acknowledge support from the Engineering and Physi-

cal Sciences Research Council (EPSRC). Vassilli Kolokoltsov would like to acknowledge

support from the Russian Foundation for Basic Research (RFBR, grant No. 17-01-00069).

Conﬂicts of Interest

The authors declare no conﬂict of interest.

29

References

Aumann R J (1964) Markets with a continuum of traders. Econometrica: Journal of the

Econometric Society. 39-50.

Basna R, Hilbert A, Kolokoltsov V N (2014) An epsilon-Nash equilibrium for non-linear

Markov games of mean-ﬁeld-type on ﬁnite spaces. Communications on Stochastic Anal-

ysis. 8(4), 3.

Bauso D, Tembine H, Basar T (2016) Robust mean ﬁeld games. Dynamic games and

applications. 6(3):277-303.

Bensoussan A, Frehse J, Yam P (2013) Mean ﬁeld games and mean ﬁeld type control

theory. New York: Springer.

Bensoussan A, Chau M H M, Yam S C P (2016) Mean ﬁeld games with a dominating

player. Applied Mathematics & Optimization. 74(1):91-128.

Bergin J, Bernhardt D (1992) Anonymous sequential games with aggregate uncertainty.

Journal of Mathematical Economics. 21(6):543-562.

Caines P E (2013) Mean ﬁeld games. Encyclopedia of Systems and Control. 1-6.

Canty M J, Rothenstein D, Avenhaus R (2001) Timely inspection and deterrence. Euro-

pean Journal of Operational Research. 131(1):208-223.

Cardaliaguet P (2010) Notes on mean ﬁeld games (p. 120). Technical report.

Carmona R, Delarue F (2013) Probabilistic analysis of mean-ﬁeld games. SIAM Journal

on Control and Optimization. 51(4):2705-2734.

Carmona R, Zhu X (2016) A probabilistic approach to mean ﬁeld games with major and

minor players. The Annals of Applied Probability. 26(3):1535-1580.

Dubey P, Mas-Colell A, Shubik M (1980) Eﬃciency properties of strategies market games:

An axiomatic approach. Journal of Economic Theory. 22(2):339-362.

Friedman D (1991) Evolutionary games in economics. Econometrica: Journal of the

Econometric Societ. 637-666.

30

Friedman D (1998) On economic applications of evolutionary game theory. Journal of

Evolutionary Economics. 8(1):15-43.

Gintis H (2000) Game theory evolving: A problem-centered introduction to modeling

strategic behavior. Princeton university press.

Gomes D A, Mohr J, Souza R R (2010) Discrete time, ﬁnite state space mean ﬁeld games.

Journal de math´ematiques pures et appliqu´ees. 93(3):308-328.

Gomes D A, Mohr J, Souza R R (2013) Continuous time ﬁnite state mean ﬁeld games.

Applied Mathematics & Optimization. 68(1):99-143.

Gomes D, Velho R M, Wolfram M T (2014) Socio-economic applications of ﬁnite state

mean ﬁeld games. Phil. Trans. R. Soc. A. 372(2028), 20130405.

Gomes D A, Saude J (2014) Mean ﬁeld games models—a brief survey. Dynamic Games

and Applications. 4(2):110-154.

Hofbauer J, Sigmund K (2003) Evolutionary game dynamics. Bulletin of the American

Mathematical Society. 40(4):479-519.

Huang M, Malham´e R P, Caines P E (2006) Large population stochastic dynamic games:

closed-loop McKean-Vlasov systems and the Nash certainty equivalence principle. Com-

munications in Information & Systems. 6(3):221-252.

Huang M (2010) Large-population LQG games involving a major player: the Nash cer-

tainty equivalence principle. SIAM Journal on Control and Optimization. 48(5):3318-

3353.

Jovanovic B, Rosenthal R W (1988) Anonymous sequential games. Journal of Mathemat-

ical Economics. 17(1):77-87.

Kamien M I, Schwartz N L (1991) Dynamic optimisation. The calculus of variations and

optimal control in economics and management. North Holland, New York.

Katsikas S, Kolokoltsov V, Yang W (2016) Evolutionary Inspection and Corruption

Games. Games. 7(4), 31.

31

Kolokoltsov V N (2010, July) Nonlinear Markov games. In Proceedings of the 19th MTNS

Symposium.

Kolokoltsov V N (2010). Nonlinear Markov processes and kinetic equations (Vol. 182).

Cambridge University Press.

Kolokoltsov V, Yang W (2012) Turnpike theorems for Markov games. Dynamic Games

and Applications. 2(3):294-312.

Kolokoltsov V N (2012) Nonlinear Markov games on a ﬁnite state space (mean-ﬁeld and

binary interactions). International Journal of Statistics and Probability. 1(1).

Kolokoltsov V N (2014) The evolutionary game of pressure (or

interference),

resistance

and collaboration.

arXiv preprint arXiv:1412.1269. Available

online:

https://arxiv.org/abs/1412.1269 (accessed on 3 December 2014) (to appear in MOR

(Mathematics of Operartion Research))

Kolokoltsov V N, Malafeyev O A (2015) Mean-ﬁeld-game model of corruption. Dynamic

Games and Applications. 1-14.

Kolokoltsov V N, Bensoussan A (2016) Mean-ﬁeld-game model for Botnet defense in

Cyber-security. Applied Mathematics & Optimization. 74(3):669-692.

Lasry J M, Lions P L (2007) Mean ﬁeld games. Japanese journal of mathematics. 2(1):229-

260.

Ross S M (2014) Introduction to stochastic dynamic programming. Academic press.

Samuelson L (2002) Evolution and game theory. The Journal of Economic Perspectives.

16(2):47-66.

Sandler T (2005) Counterterrorism: A game-theoretic analysis. Journal of conﬂict reso-

lution. 49(2):183-200.

Sandler T, Arce D G (2007) Terrorism: a game-theoretic approach. Handbook of defense

economics. 2:775-813.

32

Sandler T, Siqueira K (2009) Games and terrorism: Recent developments. Simulation &

Gaming. 40(2):164-192.

Szab´o G, Fath G (2007) Evolutionary games on graphs. Physics reports. 446(4):97-216.

Smith J M (1988) Evolution and the Theory of Games. In Did Darwin Get It Right? (pp.

202-215). Springer US.

Taylor C, Fudenberg D, Sasaki A, & Nowak M A (2004) Evolutionary game dynamics in

ﬁnite populations. Bulletin of mathematical biology. 66(6):1621-1644.

Tembine H, Le Boudec J Y, El-Azouzi R, Altman E (2009, May) Mean ﬁeld asymptotics

of Markov decision evolutionary games and teams. In Game Theory for Networks, 2009.

GameNets’ 09. International Conference on (pp. 140-150). IEEE.

Weibull J W (1997) Evolutionary game theory. MIT press.

Zaslavski A J (2006) Turnpike properties in the calculus of variations and optimal control.

(Vol. 80). Springer Science & Business Media.

33

