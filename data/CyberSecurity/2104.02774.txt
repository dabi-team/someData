1
2
0
2

b
e
F
0
2

]

R
C
.
s
c
[

1
v
4
7
7
2
0
.
4
0
1
2
:
v
i
X
r
a

Bayesian adversarial multi-node bandit for optimal smart grid
protection against cyber attacks (cid:63)

Jianyu Xu a, Bin Liu b, Huadong Mo c, Daoyi Dong c

aInternational Business School Suzhou, Xi’an Jiaotong-Liverpool University, Suzhou, China

bDepartment of Management Science, University of Strathclyde, G1 1XQ, Glasgow, UK

cSchool of Engineering and Information Technology, University of New South Wales, Canberra, ACT 2600, Australia

Abstract

The cybersecurity of smart grids has become one of key problems in developing reliable modern power and energy systems.
This paper introduces a non-stationary adversarial cost with a variation constraint for smart grids and enables us to investigate
the problem of optimal smart grid protection against cyber attacks in a relatively practical scenario. In particular, a Bayesian
multi-node bandit (MNB) model with adversarial costs is constructed and a new regret function is deﬁned for this model. An
algorithm called Thompson-Hedge algorithm is presented to solve the problem and the superior performance of the proposed
algorithm is proven in terms of the convergence rate of the regret function. The applicability of the algorithm to real smart
grid scenarios is veriﬁed and the performance of the algorithm is also demonstrated by numerical examples.

Key words: Multi-node bandit; reinforcement learning; Bayesian updating; cyber attack; smart grid.

1 Introduction

The upgrade of traditional grids to smart grids has
brought many beneﬁts to the overall management of
power and energy systems, including higher reliability,
better eﬃciency, improved integration of renewable en-
ergy resources, more ﬂexible choice for stakeholders and
lower operation cost (Konstantelos et al., 2016; Pogaku
et al., 2007; Yu et al., 2015). However, the core tech-
nologies, e.g., communication techniques and SCADA
systems (Abiri-Jahromi et al., 2020; Khalili et al., 2020;
Rana, Xiang and Wang, 2018; Todescato et al., 2020),
which deliver advantages of smart grids, also open the
grids to vulnerabilities that already exist in the Infor-
mation and Communications Technology world. Now,
those vulnerabilities pose threats to smart grids, such
as denial of service (DoS) attacks, false data injection,

(cid:63) This work is partially supported by Fudan Scholar and
Special Research Grant, UNSW, and by the Australian Re-
search Council’s Discovery Projects funding scheme under
Project DP190101566. Corresponding author Huadong Mo.
Tel. +61-2-62688683. Fax +61-2-62688683

Email addresses: Jianyu.Xu@xjtlu.edu.cn (Jianyu

Xu), b.liu@strath.ac.uk (Bin Liu),
huadong.mo@adfa.edu.au (Huadong Mo),
d.dong@adfa.edu.au (Daoyi Dong).

replay attacks, privacy data theft and sabotage of criti-
cal infrastructure (Gallo et al., 2020; Mo and Sansavini,
2017; Zhu and Mart´ınez, 2013). In addition, the failures
in a smart grid caused by cyber attacks can easily cas-
cade to other highly dependent critical infrastructure
sectors, such as transportation systems, wastewater
systems, health care systems and banking systems, re-
sulting in extensive physical damage and social and
economic disruption (Abiri-Jahromi et al., 2020; Che
et al., 2018).

While governments, the private sector and academia are
recognising the cyber vulnerability of smart grids, the
likelihood and impact of a cyber attack are diﬃcult to
quantify. Furthermore, for a smart grid, there may be
mandatory standards and operation requirements from
the grid stakeholders. Current risk management strate-
gies are generally qualitative or heuristic (Patsakis et al.,
2018). In these strategies, some assumptions, e.g., con-
stant reward with respect to successful anti cyber attack
(Rana, Li and Su, 2017; Smith and Pat´e-Cornell, 2018),
may be unrealistic for most smart grids.

This paper presents a probabilistic risk analysis frame-
work to enhance the smart grid cyber security. In par-
ticular, the dynamical and stochastic characteristics of
smart grids, such as uncertain demands, are taken into

Preprint submitted to Automatica

8 April 2021

 
 
 
 
 
 
account to investigate the eﬀect of defending strategies
on the real operation cost. The Optimal Power Flow
model (Zhang and Papachristodoulou, 2015) is applied
to a 11-node radial smart grid originated from the Elia
grid, Belgium. Compared with the existing studies that
focus on the inherent risk (Mo and Sansavini, 2017;
Zhang and Papachristodoulou, 2015), such as the nat-
ural degradation and uncertain renewable energy re-
sources for better maintenance actions and power dis-
patch, this paper concerns about impact of the external
threat - cyber attacks on the operation cost for eﬀective
deployment of cyber defense teams. In previous work,
the cost of each attack on a node is usually assumed
to be a constant (Smith and Pat´e-Cornell, 2018). Nev-
ertheless, through investigating some practical scenar-
ios, it has been found that the costs are more likely to
be decided by some adversarial factors from the nature.
Therefore, an adversarial cost sequence associated with
each node is assumed, and a widely used variation con-
straint is introduced on each cost sequence. To cope with
the objective of sequential decision strategy, the problem
is formulated using the reinforcement learning frame-
work (Li et al., 2020; Littman, 2015; Sutton and Barto,
2018). Speciﬁcally, the Bayesian prior method (Smith
and Pat´e-Cornell, 2018) is employed for the model pa-
rameters and the problem is formulated as a Bayesian
adversarial multi-node bandit (MNB) model. In addi-
tion, a Bayesian minmax type regret function is con-
structed, which is subject to the learning context.

Research on online algorithms for adversarial MNB
problems started from Auer et al. (2002), which is later
extended to general adversarial reinforcement learning
models by (Even-Dar et al., 2009). Recently, Besbes
et al. (2019) implemented the classical method in Auer
et al. (2002) for the adversarial bandit problem assum-
ing cost sequences with restricted variation and achieved
the state-of-the-art performance for such problems. An
obvious gap when using these methods in the problem
of our work is that they do not adapt to the Bayesian
framework and cannot take advantages of the additional
information provided by the Bayesian assumptions. As
a result, these algorithms may be ineﬀective in Bayesian
problems in terms of the convergence rate of the regret.
An alternative feasible method is proposed in Smith
and Pat´e-Cornell (2018), where model parameters are
considered to be system states included in the state
space. Therefore, the problem is no longer Bayesian and
can be solved using existing algorithms for stochastic
MNB. However, this method suﬀers from a tremendous
state space and is always computationally hard even in
problems with moderate sizes.

To cope with the abovementioned technical challenge,
an online learning method is developed in this study
the Thompson sampling method
which integrates
(Russo and Van Roy, 2014) with the classical Hedge al-
gorithm (Auer et al., 2002; Russo and Van Roy, 2014).
Our algorithm takes advantages of both algorithms. In

particular, Thompson sampling method is used to cope
with the Bayesian framework and Hedge algorithm is
applied to the adversarial costs. A theoretical bound
on the regret function is proved in the proposed algo-
rithm, which is superior to the typical regret bound by
the state-of-the-art algorithms for the same problem.
The applicability and numerical performance of the
proposed algorithm is also illustrated through real data
and simulation studies.

The main contributions of our work are summarized as
follows.

1. A relatively practical adversarial reward with re-
stricted variation constraint is proposed for the MNB
model. The prior information of the model parame-
ters is incorporated through a Bayesian framework
and a Bayesian adversarial MNB model is formulated.
2. A Bayesian sup regret is deﬁned as the criterion func-
tion for decision making objective of the proposed
problem. A new online algorithm, called Thompson-
Hedge algorithm, is developed to solve the problem.
The convergence rate of the Bayesian sup regret for
the proposed algorithm is theoretically proven.

3. Real smart grid data are used to demonstrate the ap-
plicability of the proposed method and numerical re-
sults show that the proposed algorithm can achieve
the state-of-the-art performance.

This paper is organized as follows. Section 2 formulates
the problem as a Bayesian reinforcement learning model
and constructs the regret function. In Section 3, an al-
gorithm called Thompson-Hedge algorithm is developed
for our learning model and a theoretical upper bound
on the regret function is established. Section 4 veriﬁes
the feasibility of our model and algorithm using a real
data set. In Section 5, a comparative study is investi-
gated on the performance between our algorithm and a
state-of-the-art algorithm. Section 6 presents concluding
remarks.

2 Problem formulation

In the electricity network with cyber attacks, an attacker
launches a coordinated attack using multiple attack vec-
tors, because the smart grid communication networks
are physically distributed and highly heterogeneous. The
successful rate of such attack behavior is data-driven,
which follows a Poisson distribution, as demonstrated
by the empirical study from U.S. Department of Energy
(Smith and Pat´e-Cornell, 2018). The network defender
aims to optimally allocate cyber defense teams among
nodes in the network, via probing one node per day.
Such a defending action thwarts all attempted cyber at-
tacks to that node on that day, and also helps update
his/her belief about the uncertain successful rates of at-
tack. The above interaction between the attacker and
the defender has the sequential decision-making nature

2

and leads itself to a Bayesian MNB model. This model
employs proactively defense teams that traditionally re-
spond to cyber threats after they occur.

The considered attack scenario in a realistic smart grid
is that the DoS attacks block the demand response
(DR) messages and dispatch commands (Pillitteri and
Brewer, 2014; Smith and Pat´e-Cornell, 2018). The DoS
attacks can be accomplished by ﬂooding the communi-
cation channel, e.g., the one between the demand re-
sponse automation server and customer systems or the
one between the control center and power plant router,
with other messages and commands, or by tampering
with the communication channel (Amin et al., 2013; Pil-
litteri and Brewer, 2014; Smith and Pat´e-Cornell, 2018).
Above actions can prevent legitimate DR messages and
dispatch commands being received and transmitted,
i.e., depriving authorized access or control to customer
systems and power plant, resulting in demand not be-
ing responded and power plant not being controlled
(Pillitteri and Brewer, 2014). Therefore, the impact of
successful DoS attacks on the optimal power ﬂow model
of the smart grid is described by making the target
node temporarily unavailable and disconnected from
the grid, which is illustrated in Section 4.1.

Consider a smart grid with N nodes that suﬀers cyber
attacks. Let N (cid:44) {1, · · · , N } be the set of all nodes. At
each time t = 1, 2, . . ., the operator’s action is to choose
a node to probe. If i ∈ N is probed, the operator observes
a (random) number of Ki, t cyber attacks on node i.

The historical cyber incident data from US Department
of Energy (Fig. 2 of Smith and Pat´e-Cornell (2018))
has demonstrated that the arrival interval of successful
cyber attacks on per node can be well described by a
truncated Poisson distribution, and there is no record
of multiple cyber attacks (maximum is 3) on per node
per day. Therefore, the physical meaning is that in real
applications, there should not be more than 3 cyber at-
tacks arriving per node in a deﬁned time interval. In ad-
dition, the Palm-Khintchine theorem (Heyman and So-
bel, 2004; Smith and Pat´e-Cornell, 2018) justiﬁes that
the aggregate arrivals from many sources (no need to be
strict Poisson) approach a truncated Poisson distribu-
tion in the limit time interval. It is assumed that for all
i ∈ N, {Ki, t, t = 1, 2, . . .} is a sequence of independent
and identically distributed random variable sequence
drawn from a Poisson distribution truncated at m > 0
with rate λi, i.e., for all k = 1, 2, . . ., and t = 1, 2, . . .,

P r (Ki, t = k | λi) =






(cid:80)∞

λk
k! e−λi,
i
λj
j! e−λi,
i
0,

j=m

k < m

k = m

.

otherwise

In particular, the average number of attacks on each

3

node i ∈ N, denoted by µi, is

µi =

m−1
(cid:88)

k=1

k ·

λk
i
k!

e−λi + m

∞
(cid:88)

k=m

λk
i
k!

e−λi.

Let λ = (λ1, · · · , λN ) and assume a foresight belief on λ
in terms of a prior distribution F = (F1, · · · , FN ) over
λ, where λi ∼ Fi for all i ∈ N. In particular, it is assumed
that each Fi is a gamma distribution with parameters
(αi, βi) and all Fi’s are mutually independent with each
other. Whenever k cyber attacks are observed at node i ∈
N, the parameters (αi, βi) are updated through Bayesian
posterior as (αi, βi) → (αi + k, βi + 1).

At time t = 1, 2, . . ., a cost ci, t is calculated from an
optimization process for all i ∈ N. Without loss of gen-
erality, it is assumed that all ci, t’s are normalized such
that ci, t ∈ [0, 1/m] for all i ∈ N and t = 1, 2, . . .. The
process uses some inputs (e.g., external factors) that are
decided by an adversary (environment). Without ambi-
guity, the cost vector ct = (c1, t, · · · , cN, t) is assumed to
be decided by the adversary at each time t = 1, 2, . . ..
If node i ∈ N is probed, the operator avoids incurring a
total cost of X(i, t) = Ki, t · ci, t, X(i, t) ∈ [0, 1]. Equiv-
alently, a reward of Ki, t ·ci, t is achieved by probing node
πt at time t. An admissible policy π is a sequence of
mappings π = {π1, π2, · · · }, where each πt is a mapping
from historical observations to the set of all probability
distributions on N. To distinguish, let {i1, i2, · · · } rep-
resent the sequence of chosen nodes. The axioms of the
problem are formulated in the problem protocol below.

Problem protocol:

For each time t = 1, 2, . . .
1: The adversary decides an cost ci, t for all i ∈ N.
2: The operator probes a node it ∈ N according to πt
and observes the number of cyber attacks on this
node to be kit, t.

3: All ci, t’s are revealed to the operator.
4: A reward kit, t · cit, t is achieved by the operator.

For notational convenience, let θ = (α1, β1, · · · , αN , βN )
denote the initial parameter vector and (cid:126)cT = {c1, · · · , cT }
the cost sequence up to time T . To proceed, the optimal
policy and the regret function is ﬁrstly formulated given
the parameter vector θ and cost sequence (cid:126)ct. The mean
reward of node i ∈ N at time t is E (Ki, t · ci, t) = µi ·ci, t.
Since the reward sequence from each node is not station-
ary due to ci, t, for all t = 1, 2, . . ., the optimal node is
(cid:44) arg maxi∈Nµi · ci, t and a non-stationary
deﬁned as i∗
t
optimal policy is supposed to choose node i∗
t at time
t = 1, 2, . . .. Thus, for any admissible policy π, given θ

and (cid:126)cT , the regret function up to time T is deﬁned as

(cid:32) T

T
(cid:88)

µi∗

·ci∗

Rπ (λ, (cid:126)cT , T ) (cid:44)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT
(1)
where Eπ means the expectation taken with respect to
the (random) sequence {i1, · · · , iT } generated by π.

µπt · cπt, t

t , t−Eπ

(cid:88)

t=1

t=1

t

(cid:33)

A constraint is imposed upon the adversary by introduc-
ing a sequence of sets {Ct ⊂ [0, 1]t}t≥2, that for all time
t = 1, 2, . . ., (cid:126)cT ∈ Ct. Then, given θ, the regret function
with respect to the worst case up to time T > 0 is

Rπ (λ, (cid:126)cT , T ) .

sup
(cid:126)cT ∈CT

(2)

Note that sup(cid:126)cT ∈CT R (λ, (cid:126)cT , T ) is supposed to measure
the performance with the action sequence uniformly on
all possible cost sequences. Finally, incorporating the
prior distribution F on θ, the Bayesian regret function
with respect to the worst case is deﬁned as

Assumption 1 There exists T0 ≥ 1, such that for all
T ≥ T0, 1/m ≤ VT ≤ T /m.

,

The restriction of T ≥ T0 for some T0 in Assumption
1 is necessary to further present our results. Actually
the condition 1/m ≤ VT cannot be directly concluded
based on the previous discussions. Since VT is the accu-
mulation of maxi∈N |ci, t+1 − ci, t| and we suppose that
maxi∈N |ci, t+1 − ci, t| (cid:28) 1/m . Hence, when T is small,
VT may not satisfy the condition 1/m ≤ VT . It is worth
noting that a justiﬁcation of the existence of T0 is useful
to guarantee the performance of our algorithm, while it is
not necessary to know the exact value of T0. Prior knowl-
edge can be incorporated to ensure the existence of T0.
For example, if the diﬀerence term maxi∈N |ci, t+1 − ci, t|
fails to rapidly become inﬁnitely small (which is natural
when the cost sequences are non-stationary), then VT
will surely be larger than 1/m when T is large enough.
Examples of securing an estimated value for T0 can be
found in the smart grid application of Section 4, where
VT is estimated to grow linearly in T and a threshold
time for VT to exceed 1/m can be easily calculated.

Rπ (CT , T ) (cid:44) Eλ∼F

(cid:20)

sup
(cid:126)cT ∈CT

(cid:21)
Rπ (λ, (cid:126)cT , T )

.

(3)

3 Thompson-Hedge algorithm

To distinguish between the regret functions in (1),
(2) and (3), they are named as regret, sup regret and
Bayesian sup regret, respectively, for brevity.

By analyzing some real databases (such as the Elia Grid
in Section 4), the sequence of sets (cid:8)CT ⊂ [0, 1]T (cid:9)
T ≥2 is
formulated with constraint on the cost. It is concluded
from the statistical analysis of the real data that the tem-
poral variations of the cost sequence of each node i ∈ N,
i.e., {|ci, t+1 − ci, t|}t≥1, are stationary and uniformly
upper bounded by a value, which only relies on i and is
small compared to the average value of {ci, t}t≥1. There-
fore, it is assumed that for each node the cumulative
temporal variation up to time t ≥ 1 is upper bounded
by a linear function of t. Based on this assumption, a
uniform upper bound on the cumulative temporal vari-
ation for all nodes is introduced and (cid:8)CT ⊂ [0, 1]T (cid:9)
is constructed as follows.

T ≥2

CT (cid:44){{ci, t}T
T
(cid:88)

max
i∈N

t=1

t=1 ∈ [0, 1]T , i ∈ N :

|ci, t+1 − ci, t| ≤ VT }, ∀T ≥ 2,

(4)

where {VT }T ≥1 is a sequence of positive numbers. Since
ci, t ∈ [0, 1/m], ∀i ∈ N and t ≥ 1, maxi∈N |ci, t+1 −
ci, t| (cid:28) 1/m holds for all t ≥ 1. Thus, VT ≤ O(T ) and
VT /T (cid:28) 1/m. Meanwhile, VT is monotonically increas-
ing in T . Based on these considerations, the following
assumption on VT is proposed.

4

In this section, an online learning algorithm is developed
to optimize the Bayesian sup regret for our problem.
The algorithm has two layers. In the outer layer, at each
time t ≥ 1, the algorithm uses Thompson sampling (pos-
terior sampling) method to sample a parameter vector
(λ1, · · · , λN ) from the posterior distributions of all λi’s
based on the historical observations. Then, in the inner
layer, a so-called sub-algorithm is fed with the sampled
parameters. The sub-algorithm returns an action πt ∈ N.
At the end of this loop, the algorithm chooses node πt,
observes the reward from πt and updates the posterior
distribution of λπt. In the end of this section, a theorem
is provided to characterize the convergence rate of the
regret function.

Since Hedge algorithm is applied as the sub-algorithm
in the inner layer, the proposed algorithm is named as
Thompson-Hedge algorithm. Before formally presenting
our algorithm, the Hedge algorithm is ﬁrstly introduced.
Hedge algorithm is a classical algorithm designed for
the adversarial MNB problem with full feedback (Fre-
und and Schapire, 1999). It is a randomized algorithm
that maintains a weight ωt(i) for each i ∈ N. Hedge al-
gorithm then chooses node i ∈ N with a probability pro-
portional to ωt(i) at time t. Subsequently, the weight for
each node is updated according to the observed reward
of this node. The algorithm chooses a size ∆ and restarts
updating the weights of each node every ∆ times. The
set of intervals between two successive restarting epochs
(including the ﬁrst restarting time) is called a batch.
Since Hedge algorithm is designed for non-Bayesian ad-
versarial MNB, in order to use it under the Bayesian

framework, one needs to modify the original Hedge al-
gorithm and feed it by the value of parameter λ. Denote
Hedge(λ) as the modiﬁed Hedge algorithm used in our
Bayesian adversarial MNB fed by λ. The algorithm is
summarized in Algorithm 1.

Algorithm 1: Hedge(λ) Algorithm

Initialization: Parameter
1 − (cid:112)ln N/2T

(cid:17)−1

(cid:16)

, calculate µi using λi.

vector

λ,

ε

=

1: for b = 1, 2, · · · , (cid:100)T /∆(cid:101) do
For all i ∈ N, ωi
2:
while t ≤ min {T, b · ∆} do
3:
For each i ∈ N, set
4:

1 = 1.

pi
t =

(cid:80)

ωi
t
j∈N ωj

t

.

from the posterior distribution of λ. Finally, the algo-
rithm updates the weight of each node for next epoch
using both the observed costs and ˆλ. Gamma(α, β) is
used to represent Gamma distribution with parameters
(α, β). The proposed Thompson-Hedge algorithm is
summarized in Algorithm 2.

Algorithm 2: Thompson-Hedge Algorithm

Initialization: Parameter θ, batch size ∆, ε =

(cid:16)

1 − (cid:112)ln N/2T

(cid:17)−1

, t=1.

1: for b = 1, 2, · · · , (cid:100)T /∆(cid:101) do
For all i ∈ N, ωi
2:
while t ≤ min {T, b · ∆} do
3:
For each i ∈ N, set
4:

1 = 1.

pi
t =

ωi
t
j∈N ωj

t

(cid:80)

.

5:

6:

distribution (cid:8)pi

Choose a node πt according to the probability
i∈N and receive a reward kπt, t·cπt, t.

(cid:9)

t

For each node i ∈ N, update

t+1 = ωi
ωi

tεµi·cπt, t .

5:

6:

7:

Set t → t + 1.

7:
8:
9: end for

end while

distribution (cid:8)pi
For

Choose a node it according to the probability
i∈N and receive a reward kit, t ·cit, t.
(αit, βit) →

t
node

update

it,

(cid:9)

(αit + kit, t, βit + 1).

For each node i ∈ N, sample ˆλi ∼
Gamma(αi, βi), calculate ˆµi using ˆλi, and update

t+1 = ωi
ωi

t · εˆµi·cit, t .

Hedge(λ) follows the paradigm of the classical Hedge al-
gorithm. The following lemma shows that if the value of
parameter λ fed to Hedge(λ) is the true parameter of the
Bayesian adversarial MNB model, then Hedge(λ) retains
a convergent sup regret with a known upper bound.

Lemma 1 If the input λ in the Hedge algorithm is the
true model parameter and the batch size is chosen to be
, then for all T ≥ N , the
∆ =

(ln N )1/3 (T /mVT )2/3(cid:109)
(cid:108)

sup regret by the Hedge(λ) algorithm is upper bounded by

Rπ (λ, (cid:126)cT , T ) ≤

(cid:16)

√

(cid:17)
2

8 + 2

(mVT ln N )1/3 (T )2/3 .

sup
(cid:126)cT ∈CT

(5)

Detailed proof of Lemma 1 is given in the Appendix. In
the proof of our main result of Theorem 1, the conclusion
of Lemma 1 is used as an intermediate benchmark result.

In the proposed Thompson-Hedge algorithm, parame-
ter λ is sampled from its posterior distribution in each
epoch. Then, the sampled parameter is fed to the inner
algorithm Hedge(λ) and a node is chosen correspond-
ingly. In particular, the algorithm chooses a node ac-
cording to the probability weight of each node. Then, the
algorithm observes the costs and updates the posterior
distribution of λ. Next, a sampled parameter ˆλ is drawn

5

Set t → t + 1.

8:
9:
10: end for

end while

Before the main result (Theorem 1) is presented, the
following lemma is introduced that will be used for the
proof of the main result.

Lemma 2 [(Osband et al., 2013), Lemma 2] If F is the
true distribution of λ, and ˆλ is the sampled parameter
in epoch t, then for any σ(Ht)-measurable function g, it
follows

Eλ [g(λ) | Ht] = Eˆλ

(cid:104)
g(ˆλ) | Ht

(cid:105)

.

Lemma 2 shows a central result in Bayesian learning
area. The sampled parameter from the posterior distri-
bution each time can be “considered” as the true param-
eter in the sense that any deterministic function using
it as an argument independently has the same expecta-
tion. On the basis of Lemma 1 and Lemma 2, the main
theorem is presented as below, which establishes an up-
per bound on the Bayesian sup regret for our Thompson-
Hedge algorithm and thus indicates its convergence rate.

Theorem 1 Let π be the Thompson-Hedge algorithm
, CT be de-
with batch size ∆ =
ﬁned in (4), and T0 be the same value as deﬁned in As-
sumption 1, then for all T ≥ T0, the Bayesian sup regret

(ln N )1/3 (T /mVT )2/3(cid:109)
(cid:108)

Rπ (CT , T ) can be upper bounded by

b) Upper bound of Λ1

Rπ (CT , T ) ≤

(cid:16)

√

(cid:17)
2

8 + 2

(mVT ln N )1/3 (T )2/3 .

(6)

Λ1 is rewritten as

Λ1 = Eλ∼F

(cid:20)

sup
(cid:126)cT ∈CT

(cid:21)
RH (λ, (cid:126)cT , T )

.

Note that the upper bound in Lemma 1 holds for any
true model parameter λ. Thus the upper bound still
holds after taking expectation on λ on both sides of (5).
Therefore, it holds that

(cid:16)

8 + 2

√
(cid:17)
2

Λ1 ≤

(mVT ln N )1/3 (T )2/3 .

c) Upper bound Λ2

The following clariﬁcation is made for notational con-
venience. λt
is used for the sampled parameter by
Thompson-Hedge algorithm at time t and λ for the
true model parameter which is the input of Hedge algo-
rithm. To bound the Bayesian sup regret by Thompson-
Hedge algorithm, the diﬀerence between the Bayesian
sup regret functions by Thompson-Hedge and Hedge
algorithms, respectively, is ﬁrstly bounded, namely,

PROOF. The basic idea for the proof is sketched as
follows. The Bayesian sup regret by Thompson-Hedge
algorithm is ﬁrstly decomposed into two parts: the regret
of the introduced Hedge(λ) algorithm and the diﬀerence
of performance between Thompson-Hedge and Hedge
algorithms. Since the sup regret by Hedge algorithm is
bounded by Lemma 1, Theorem 1 can then be proved by
upper bounding the performance diﬀerence between the
two algorithms. To distinguish between two algorithms
in the work, πT H and πH are used for Thompson-Hedge
and Hedge algorithms correspondingly. Moreover, RT H
and RH are denoted as the regret function of πT H and
πH , respectively.

a) Separation of the target regret RT H .

In the ﬁrst step, the Bayesian sup regret RT H is sepa-
rated into a combination of two terms. In Step b) and
Step c), the upper bound of these two terms are obtained
separately and therefore, the upper bound of RT H can
be readily obtained. The separation of RT H is given as
below.

RT H (CT , T ) = Eλ∼F

(cid:34)

sup
(cid:126)cT ∈CT

(cid:40) T

(cid:88)

µi∗

t

· ci∗

t , t

− ET H

(cid:32) T

(cid:88)

t=1
(cid:34)

≤ Eλ∼F

sup
(cid:126)cT ∈CT

− EH

(cid:32) T

(cid:88)

t=1
(cid:34)

t=1

(cid:33) (cid:41)(cid:35)

µit · cit, t

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

(cid:40) T

(cid:88)

t=1

µi∗

t

· ci∗

t , t

(cid:33) (cid:41)(cid:35)

µiti · cit, t

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT
(cid:32) T

(cid:88)

(cid:40)

EH

+ Eλ∼F

sup
(cid:126)cT ∈CT

− ET H

(cid:32) T

(cid:88)

t=1

µit · cit, t

µit · cit, t

t=1

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

(cid:33) (cid:41)(cid:35)
.

(cid:33)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

(cid:34)

(cid:40)

Eλ∼F

sup
(cid:126)cT ∈CT

(7)

(cid:32) T

(cid:88)

ET H

µit · cit, t

(cid:33)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

− EH

t=1
(cid:32) T

(cid:88)

t=1

µit · cit, t

(cid:33) (cid:41)(cid:35)
,

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

(8)

For notational convenience, denote the above two terms
in the two square brackets by Λ1 and Λ2, respectively.
The relation in (7) can be rewritten as

RT H = Λ1 + Λ2

Note that Λ1 is closely associated with the sup regret of
πH and can be bounded based on the result in Lemma
1. Λ2 is the diﬀerence between the return of πT H and
πH that will be bounded in the following step.

where ET H and EH have the same meaning as Eπ given
π, for Thompson-Hedge algorithm and Hedge algorithm,
respectively. Denote the observation history before time
(cid:9).
t ≥ 2 as Ht = (cid:8)i1, ki1, 1, c1, · · · , it−1, kit−1, t−1, ct−1
Conditioned on the observation history, the probability
weight function pt(·) in both algorithms is functions of
λ and λ(t) correspondingly. Moreover, let pt(·) and ˜pi
t(·)
be the probability functions of Thompson-Hedge and
Hedge algorithms, respectively. For any ﬁxed (cid:126)cT ∈ CT ,

6

the following relation holds,

the results in a), b) and c). In particular, it holds that

RT H (CT , T ) ≤ Λ1 + Λ2 = Λ1 + 0
(cid:16)

≤

8 + 2

√
(cid:17)
2

(mVT ln N )1/3 (T )2/3 .

µit · cit, t

(cid:33)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

Therefore, the proof is concluded.

(cid:32) T

(cid:88)

ET H

µit · cit, t

(cid:33)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

t=1
(cid:32) T

(cid:88)

− EH

t=1

(cid:32) T

(cid:88)

− EH

t=1
(cid:32) T

(cid:88)

t=1

=ET H

µit · cit, t

(cid:33)

(cid:12)
(cid:12) λ, (cid:126)cT , HT
(cid:12)

µit · cit, t

(cid:12)
(cid:12) λ, (cid:126)cT , HT
(cid:12)

(cid:33)

=

T
(cid:88)

t=1

Eλt

(cid:2)pi

t(λt) − ˜pi

t(λ)|Ht

(cid:3) µi · ci, t.

(9)

At any time t ≥ 1, note that λt is the sampled param-
eter from the same posterior distribution as the true λ.
Meanwhile, pi
t(·) are the same deterministic
function based on Ht. According to Lemma 2, it follows

t(·) and ˜pi

Eλt, λ

(cid:2)pi

t(λt) − ˜pi

t(λ)|Ht

(cid:3) µi · ci, t = 0.

Therefore, for any ﬁxed (cid:126)cT ∈ CT , it holds that

(cid:34)(cid:40)

Eλ∼F

ET H

(cid:32) T

(cid:88)

t=1

(cid:32) T

(cid:88)

t=1

− EH

(cid:32)

µit · cit, t

(cid:34)(cid:40)

µit · cit, t

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT
(cid:33) (cid:41)(cid:35)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT
(cid:32) T

(cid:88)

t=1

(cid:33)

(cid:33)

(cid:12)
(cid:12) λ, (cid:126)cT , HT
(cid:12)

= E

Eλ∼F

ET H

µit · cit, t

(cid:32) T

(cid:88)

− EH

t=1

= E (cid:0)Eλt, λ
= 0.

(cid:33) (cid:41)(cid:35)(cid:33)

µit · cit, t

(cid:12)
(cid:12) λ, (cid:126)cT , HT
(cid:12)
t(λ)|Ht

(cid:2)pi

t(λt) − ˜pi

(cid:3) µi · ci, t

(cid:1)

Note that the relation above holds for any (cid:126)cT ∈ CT ,
which leads to

(cid:34)

(cid:40)

Eλ∼F

sup
(cid:126)cT ∈CT

ET H

(cid:32) T

(cid:88)

µit · cit, t

(cid:33)

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

− EH

t=1
(cid:32) T

(cid:88)

t=1

(cid:33) (cid:41)(cid:35)

µit · cit, t

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

≡ 0.

(10)

d) Upper bound of the regret RT H .

Finally, the upper bound of the Bayesian sup regret of
Thompson-Hedge algorithm is obtained by combining

7

(cid:16)

(mVT N ln N )1/3 (T )2/3(cid:17)

Remark 1 Relevant research that considers a sim-
ilar problem can be found in Besbes et al. (2019).
In Besbes et al. (2019), the classical EXP3 type al-
gorithm was used and an upper bound of the order
O
was obtained for the sup
regret. Since the upper bound holds uniformly on the pa-
rameter space, the same upper bound also holds for the
Bayesian sup regret. If the constant (cid:0)8 + 2
2(cid:1) in (6) is
neglected, our bound outperforms the bound in Besbes
et al. (2019) by a term of O(N 1/3), which implies that
the performance of our Thompson-Hedge algorithm is
less sensitive to the number of nodes N . It indicates
that when considering problems with large scales, our
proposed algorithm is supposed to retain a Bayesian sup
regret that converges relatively faster. Meanwhile, Bes-
bes et al. (2019) constructs a lower bound of the order

√

(cid:16)

T T 2/3(cid:17)
V 1/3

O
on the regret by any algorithm. Simi-
larly, the lower bound also holds uniformly on all the
parameters and adapts to our problem. Therefore, the
lower bound shows that our algorithm achieves the order
optimality.

4 Applicability in smart grids

The model is formulated following the learning context
in Section 2 and an online learning algorithm is devel-
oped in Section 3. This section presents an application
case to demonstrate the applicability of the proposed
model and method in practical smart grids. In particu-
lar, Assumption 1 plays a central role in our model. A
real data set is used to verify that Assumption 1 may
hold in reality, and thus the proposed method is practi-
cal. Section 4.1 introduces the procedure for calculating
the reward ci, t in the smart grid. In Section 4.2, linear
regression method is used to show a linear growth rate
of the critical quantity VT in Assumption 1, and thus it
is concluded that Assumption 1 holds for the selected
data set.

4.1 Operation cost of the smart grid

To facilitate reading, meanings of the variables used in
calculating the operation cost of the smart grid, are dis-
played in diﬀerent categories as follows. For the opera-
tional variables, ϑt is the operation state of the smart
grid at time t, P t
i,j [kW] is the output of type j power
source at Node i, ¯Pi,j is the rate power of type j power
source at Node i, Lt
i is

i is the power load at Node i, ¯Lt

the load shedding, i.e., power demand not supplied, at
Node i, ϕ is the state of charge of the energy storage sys-
tem (ESS) and ¯CESS is the power capacity of the ESS.
For the conﬁguration parameters of the smart grid, Bi,i(cid:48)
(cid:48)
), δi
[1/Ω] is the susceptance of the pairs of Nodes (i, i
is the voltage angle at Node i, ∆δ is the voltage angle
diﬀerence (δi − δi(cid:48) ) of two nearby nodes, Ai,i(cid:48) [A] is the
(cid:48)
ampacity of the pairs of Nodes (i, i
) and V [kW] is the
nominal voltage of the smart grid. For the cost and price
coeﬃcients, Coϑt is the operation cost of the smart grid
subject to operation state ϑt, Csj is the variable oper-
ation cost for power source j, Cfi,i(cid:48) is the variable op-
(cid:48)
eration cost for feeder (i, i
), Cp is the penalty cost for
power demand not supplied, and Epϑt is the energy price
associated with operation state ϑt. Ts is the duration of
ϑt, P denotes a subset of power sources, N denotes the
set of all nodes, and F denotes the set of node pairs with
transmission line between them. si,i(cid:48) = 1 indicates that
power cannot be transmitted between Node i and Node
(cid:48)
i

due to the successful cyber attack on Node i.

The linear Direct Current (DC) power ﬂow model (Mo
and Sansavini, 2019; Sahraei-Ardakani and Hedman,
2016) is introduced to interprete the physical meaning
of ci, t in the smart grid. At time t, operation state of
the distributed generation system (DGS) is denoted by
the following vector:

ϑt = (cid:2)P t

i, j Lt
i

(cid:3) ,

(11)

where the power sources considered in this work consists
of natural gas plant, biomass plant, wind farm, Photo-
voltaic farm and ESS. These data are all sampled from
the historical database provided by the Elia Grid, Bel-
gium 1 .

Before calculating ci, t, the ﬁrst objective is to achieve the
minimal cost in the presence of load shedding, denoted
by Coϑt, by solving the following linear optimization
problem

subject to

i − ¯Lt
Lt

i −

P t

i, j −

(cid:88)

j∈P

N
(cid:88)

i=1

Bi, i(cid:48) (δi − δi(cid:48) ) = 0,

(13)

0 ≤ Pi, j ≤ ¯P t

i, j, j (cid:54)= ESS,

(14)

(cid:12)
(cid:12)P t

i, j · Ts

(cid:12)
(cid:12) ≤ min

(cid:110)
(1 − ϕ) · ¯CESS, ¯P j

i · Ts

(cid:111)

, j = ESS,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12) ≤ (1 − si, i(cid:48) )V Ai, i(cid:48) ,
(cid:12)Bi, i(cid:48) (δi − δi(cid:48) )

(15)

(16)

where constraint (13) requires that the power generated
and consumed is balancing at each node of DGS, con-
straint (14) requires that the power generated should not
be larger than the rated power, constraint (15) indicates
that the charging or discharging of ESS should not be
larger than the remaining capacity or nominal rate, and
constraint (16) indicates that the power ﬂow between
two nodes should not be larger than the capacity of the
transmission line. Eq. (12) is the objective function of
a typical linear DC Optimal Power Flow model, which
aims to minimize the total operation cost including the
cost of generating power, the cost of running feeders and
the penalty cost of demand not supplied, when satisfy-
ing physical constraints (13)-(16) of DGS.

The linear DC optimal power ﬂow model is conﬁgu-
rated in the Matlab and can be solved using the well-
known Simplex method, where the values of conﬁgura-
tion parameters have been given in Mo and Sansavini
(2019) and the computation time of operation cost for
each practical operation state is around 0.006 second in
Gurobi. This computation time contributes most to the
total simulation time and therefore our proposed algo-
rithm can be implemented in real time.

The physical meaning of ci, t in the smart grid can be
deﬁned as the diﬀerence between the operation cost of
the DGS without cyber attacks and the operation cost
of the DGS given the Node i∗ is temporarily unavailable
caused by a successful cyber attack. Therefore, when
probing Node i at time t, the reward function ci, i is
deﬁned as

min Coϑt =

(cid:88)

(cid:88)

j∈P
(cid:88)

i∈N

+

(i, i(cid:48) )∈F

(cid:0)Csj − Epϑt(cid:1) P t

i, j

ci, t (cid:44)

Cfi, i(cid:48)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)Bi, i(cid:48) (δi − δi(cid:48) )
(cid:12)

(cid:16)

(cid:12)
(cid:12)Coϑt
(cid:12)
− Coϑt

P t
i,j, Lt
(cid:16)

(cid:17)
i, ∆δ; si, i(cid:48) = 0

i,j, Lt
P t

i, ∆δ, si, i(cid:48) ; si, i(cid:48) = 1

(17)

(cid:17) (cid:12)
(cid:12)
(cid:12),

+ (cid:0)Cp + Epϑt(cid:1)

N
(cid:88)

i=1

¯Lt
i

(12)

1 (URL: https://www.elia.be/en/grid-data)

8

(cid:16)

i,j, Lt
P t

(cid:17)
where Coϑt
the opera-
i, ∆δ; si, i(cid:48) = 0
tion cost of the DGS without cyber attacks, and
Coϑt
is the operation cost of
the DGS given Node i is unavailable caused by the suc-
cessful cyber attack on Node i. That is to say, the reward

(cid:17)
i, ∆δ; si, i(cid:48) = 1

i,j, Lt
P t

is

(cid:16)

Fig. 2. Data scatter plot and linear prediction of VT .

merical results of the linear regression are presented in
Table 1.
Table 1
Regression results.

Coeﬃcients Standard error

t Stat P-value

Intercept

1.560

0.04711

32.04 < 0.01

T

0.02648

0.0001212

218.5

0

According to the results in Table 1, the coeﬃcient for
T is about 0.03, which means that Assumption 1 holds
with T0 chosen to be 9. As a signiﬁcance test for the
regression model, results of ANOVA for the regression
model is shown in Table 2.
Table 2
ANOVA results.

Regression

df

1

SS

MS

F

Signiﬁcance

17655

17655

47734

≤0.01

Residual

669

247.4

0.3699

Total

670 17902.4

From the results in Table 2, the signiﬁcance level is below
0.01, which means that the linear relation between VT
and T for this data set is signiﬁcant and the model is
justiﬁed.

5 Numerical results

In this section, the performance of our Thompson-Hedge
algorithm is illustrated through simulation studies. In
Section 5.1, a comparative study is conducted between
the performances of our Thompson-Hedge algorithm and
the R.EXP3 algorithm which was recently proposed in
Besbes et al. (2019). Subsequently, in Section 5.2, sensi-
tivity analysis is conducted to investigate the inﬂuence
of constraint VT on the cost sequence.

Fig. 1. The 11-node radial DGS originated from the IEEE
13 node test feeder.

ci,t can be calculated via solving the linear optimization
problem, deﬁned by (12) through (16) (with/without
cyber attacks), where the input ϑt is drawn from the
dataset of Elia Grid, Belgium.

4.2 Numerical analysis of cost sequences

In this section, numerical analysis is presented based on a
real data set to verify that Assumption 1 holds in reality.
Note that Assumption 1 implies a linear or sub-linear
upper bound in terms of T on VT . Therefore, if VT has a
linear or sub-linear growth rate in T , then Assumption
1 is supposed to hold by choosing a proper value for m.
Thus, linear regression is performed on the sequence of
VT against time T . The realistic grid data from the Elia
is used, which provides data from the Belgian electricity
market system. The underlying electricity network (a
subgrid of Elia Grid) is shown in Figure 1. In the DGS,
the dataset of Elia Grid, Belgium is recorded every 15
minutes, which means that the optimal power ﬂow model
will be performed and generate one attack cost ci,t every
15 minutes. The DGS under cyber attacks is investigated
over one week, which indicates that a speciﬁc dataset
with 672 successive observations of the attack cost is
selected for illustration. m is chosen to be 4 and the
data has been normalized such that ci, t ∈ [0, 1/4]. The
scatter plot is presented in Figure 2.

From Figure 2, a signiﬁcant linear relation between VT
and T can be observed. For further justiﬁcation, the nu-

9

0100200300400500600700Time0510152025Value of VTPredicted valueReal value5.1 Comparative study

Algorithm 3: Simulation for comparison

This section compares the performance of the proposed
Thompson-Hedge algorithm with the R.EXP3 algorithm
that was also designed for the same adversarial prob-
lem with constrained variation on cost sequence. Both
algorithms use batch methods from the original EXP3
algorithm, i.e., the time horizon is divided into small
batches and the algorithm “restarts” at the beginning
of each batch. Meanwhile, the R.EXP3 algorithm is also
a randomized algorithm, retains a weight function for
each node and updates the weights each time. Diﬀerent
from our Thompson-Hedge algorithm, in the R.EXP3
algorithm, if node i ∈ N is chosen at any time, the total
reward Ki, t · ci, t is considered as a whole adversarial re-
ward. Since the attack number ki(cid:48) , t is unknown if i (cid:54)= i
,
the R.EXP3 is supposed to ignore ci(cid:48) , t and treat the
problem as a typical MNB model with bandit feedback.

(cid:48)

The simulation is executed under N = 10 and N = 20.
To initialize, the parameter θ = (α1, β1, · · · , αN , βN )
is set for all i ∈ N, and two large numbers for Q and
L. The preset parameter θ is used to generate λ =
(λ1, · · · , λN ) for Q times in total. Under each generated
λ, λ is used to generate the sequence {Ki, t}T
t=1, and the
adversarial cost sequence {ci, t}T
t=1 is artiﬁcially gener-
ated. Then, both algorithms are run based on {Ki, t}T
t=1
t=1, ∀i ∈ N. Finally, the Bayesian sup regret
and {ci, t}T
in the two algorithms are calculated and compared. The
simulation process is summarized using pseudo codes in
Algorithm 3. Experience from the previous work Smith
and Pat´e-Cornell (2018) and the real database from our
numerical example are integrated to determine the pa-
rameter vector θ. In Smith and Pat´e-Cornell (2018), the
prior distribution is set to be Gamma(2, 2); in our nu-
merical example. It is estimated that λ ≈ 0.25, which
may correspond to the prior distribution Gamma(1, 4).
Therefore, two values for θ are selected to implement the
simulation: θ1 : (α1, β1) = · · · = (αN , βN ) = (2, 2) and
θ2 : (α1, β1) = · · · = (αN , βN ) = (1, 4). According to
the choices of θ, the truncation parameter m is set as
3, which ensures that the probability P r(Ki, t > m) is
small.

Note that in the simulation, the empirical estimation of
the sup regret and Bayesian sup regret functions is used
in the two algorithms. Therefore, it is necessary to set
the values of Q and L large enough to make the estima-
tion with good precision. In the simulation, it is set as
Q = L = 105. To simulate the real situations, the proce-
dures of sketching the cost sequence are given as below:

Step 1 : For all i ∈ N, generate ci, 1 uniformly on (0, 1/m)
independently.

Step 2 : For t = 2, · · · , T , generate ci, t independently

Initialization: Preset

=
(α1, β1, · · · , αN , βN ); numbers of simulation trials
Q, L; time horizon T .

parameter

θ

For all i ∈ N, generate λi from Gamma(αi, βi).
for l = 1 : L do

for t = 1 : T do
for i ∈ N do

1: for q = 1 : Q do
2:
3:
4:
5:
6:
7:
8:
9:
10:

end for

Generate Ki, t from P oisson(λi).
Generate ci, t artiﬁcially.

11:

12:
13:

end for
Run Thompson-Hedge

algorithm and
R.EXP3 algorithm independently based on the
t=1 and {ci, t}T
sequences {Ki, t}T
Calculate the regret function RT H
for Thompson-Hedge algorithm and RR3
for R.EXP3 algorithm.

t=1, ∀i ∈ N.
l

(λ, (cid:126)cT , T )
(λ, (cid:126)cT , T )

l

end for
Calculate the sup regret ˜RT H

for Thompson-Hedge algorithm and
maxl=1:L RR3

for R.EXP3 algorithm.

l

14: end for
15: Calculate the Bayesian sup regret

q = maxl=1:L RT H
=

˜RR3
q

l

RT H (CT , T ) = 1/Q

Q
(cid:88)

q=1

˜RT H
q

,

for Thompson-Hedge algorithm and,

RR3 (CT , T ) = 1/Q

Q
(cid:88)

q=1

˜RR3
q ,

for R.EXP3 algorithm.

from the uniform distribution on the overlapping inter-
val between (ci, t−1 − 1/100m, ci, t−1 + 1/100m) and
(0, 1/m).

By Step 1, simulate the random initial value of each cost
sequence. Then, by Step 2, set |ci, t − ci, t−1| ≤ 1/50m. It
can be veriﬁed that any cost sequence generated by Step
1 and Step 2 satisﬁes Assumption 1 with T0 = 50. The
simulation results under (α1, β1) = · · · = (αN , βN ) =
(2, 2) are given in Figures 3 and 4.

Using the same process, simulation is implemented for
(α1, β1) = · · · = (αN , βN ) = (1, 4). The results are
given in Figures 5 and 6.

In Figures 3-6, our Thompson-Hedge algorithm out-
performs the existing R.EXP3 algorithm in terms of
Bayesian sup regret. In particular, Thompson-Hedge

10

Fig. 3. Comparison of regrets (θ = θ1, N = 10).

Fig. 4. Comparison of regrets (θ = θ1, N = 20).

Fig. 5. Comparison of regrets (θ = θ2, N = 10).

11

Fig. 6. Comparison of regrets (θ = θ2, N = 20).

algorithm is less sensitive to the problem scale N by
comparing the regret curves under N = 10 and N = 20,
which is consistent with our discussion in Remark 1.
Our algorithm has advantages over a typical algorithm
designed for MNB with bandit feedback, such as the
EXP3 or R.EXP3 algorithm. The usual convergence
order of the regret function by a typical algorithm is
O(N log N )1/3 for MNB with bandit feedback in terms
of the problem scale N . Our Thompson-Hedge algo-
rithm feeds a set of sampled parameters to Hedge algo-
rithm. In the proof of Theorem 1, it is shown that using
the sampled parameters is “as good as” using the true
parameters under the Bayesian framework. Moreover, if
the true parameters are known, then Hedge algorithm
can solve the problem, which has a convergence order of
O(log N ). Therefore, our Thompson-Hedge algorithm
is supposed to retain a convergence rate of O(log N ) for
the Bayesian sup regret in the special case.

Meanwhile, upper bound in Theorem 1 is also drawn in
Figures 3-6. It is worth noting that the upper bound in
Theorem 1 holds uniformly on all possible values of θ.
Hence, it is concluded that when θ varies, the deviation
of the regret from the upper bound also varies. In partic-
ular, as shown in the ﬁgures, the diﬀerence between the
upper bound and the regret is comparatively large un-
der θ = θ1, N = 20 while small or moderate under other
three parameters. However, it can be observed from the
ﬁgures that our upper bound is obviously sharper than
that for the R.EXP3 algorithm in the sense that our up-
per bound is below the regret under R.EXP3 at some
time points in all the four ﬁgures.

5.2 Sensitivity to the variation

This section presents the sensitivity analysis of our
Thompson-Hedge algorithm to the variation constraint
VT . In reality, according to the speciﬁc environment and
workload under which the network functions, the adver-
sary may generate the cost sequence subject to various

0100150200300400500Time020406080100120140160Bayesian sup regretThompson-HedgeR.EXP3Upper bound0100200300400500Time020406080100120140160Bayesian sup regretThompson-HedgeR.EXP3Upper bound0100200300400500Time020406080100120140160Bayesian sup regretThompson-HedgeR.EXP3Upper bound0100200300400500Time020406080100120140160Bayesian sup regretThompson-HedgeR.EXP3Upper boundthat between the curves under 1/50m and 1/20m. This
implies that when the variation is within VT ≤ T /50m,
the regret function is less sensitive to the variation than
the situation that VT is around 1/10m. In the numeri-
cal example, the real data set (from Elia Grid, Belgium)
is examined and it appears that the corresponding VT
is around T /100m. Therefore, it can be concluded that
the sensitivity of our Thompson-Hedge algorithm to the
variation may not be high in practice.

6 Concluding remarks

This study investigates the sequential control problem in
modern energy and power systems with smart grids. The
existing work is extended by introducing an adversarial
cost sequence with a variation constraint. A Bayesian
MNB model is constructed to cope with the problem and
an online learning algorithm named Thompson-Hedge
algorithm is proposed to retain a converging regret func-
tion. In addition, it is proved that the convergence rate
of the regret in the proposed algorithm is superior to an
existing algorithm that can be used for this problem.

In developing our algorithm, a basic idea is to ﬁrstly ob-
tain sampled parameters from the posterior distribution
when the reinforcement learning model is a partly pa-
rameterized Bayesian model. Subsequently, the sampled
parameters are used instead of the true parameters in
the model. It is worth pointing out that although spe-
ciﬁc models are used in this work, the paradigm of our
algorithm framework can also be used for other classical
models.

From a conceptual perspective, future research will ex-
plore the applications of the proposed algorithms to
more situations in reality. For example, the proposed al-
gorithm can be used to mitigate the impact of failure in
tracking goods, or obtain suppliers to exchange inven-
tory information due to successful cyber attacks. Other
potential applications can be found in the domains of
multi-robot systems (Liu et al., 2017), Internet of Things
(IOT) (Perera et al., 2015), e.g., traﬃc management,
water distribution, waste management, online manufac-
turing and smart supply chain. It is also worth investi-
gating the impact of other types of cyber attacks such as
the botnet command and control, data exﬁltration, data
tampering, data destruction or even physical, destruc-
tion via alternation of critical software/data (Pillitteri
and Brewer, 2014) on the smart grid by properly mod-
eling their inﬂuences on the Optimal Power Flow model
according to their attack mechanisms. For example, the
replay attacks maliciously repeat DR messages or dis-
patch commands, and the false data injection attacks
purposely alter the integrity of a smart grid by compro-
mising a subset of transmitted data packages and send-
ing out inaccurate DR messages or dispatch commands.

Fig. 7. Regrets under diﬀerent variations (θ = θ1, N = 20).

Fig. 8. Regrets under diﬀerent variations (θ = θ2, N = 20).

rules. In our model, the variation constraint VT is used
to characterize the cost sequence. Thus, numerical re-
sults for the proposed Thompson-Hedge algorithm are
presented under four levels of variation. In particular,
the same steps given in Section 5.1 are employed, but
4 levels are selected for the variation scale in Step 2 :
1/20m, 1/50m, 1/100m and 1/200m. Other parameters
are set to be identical as those in Section 5.1. The sim-
ulation results are illustrated under both θ1 and θ2 as
shown in Figures 7 and 8.

The results in Figures 7 and 8 illustrate the diﬀerent
performances of our Thompson-Hedge algorithm under
diﬀerent variation scales. The Bayesian regret monoton-
ically increases with the variation. This is because larger
variation leads to more uncertainties of the cost sequence
and makes the experience from historical observations
unreliable. Thus, as an adaptive online learning algo-
rithm, the Bayesian sup regret in our Thompson-Hedge
algorithm may increase and the performance may have
ﬂuctuations. However, it should be noted that the in-
cremental diﬀerence between the regret curves under
1/100m and 1/200m are not so signiﬁcant compared to

12

050100150200250Time020406080100120140160180200Bayesian sup regret1/20m1/50m1/100m1/200m0100200300400500Time020406080100120140160180200Bayesian sup regret1/20m1/50m1/100m1/200mAppendix A Proof of Lemma 1

function within bth batch is decomposed as

In this section, detailed proof of Lemma 1 is provided,
which is used in the proof of Theorem 1. Before reaching
the proof of Lemma 1, a preliminary result is presented
in the following lemma Slivkins et al. (2019).

Lemma 3 [Slivkins et al. (2019), Theorem 5.16] If
all per-time costs are in [0, 1] and ε is chosen to be
(cid:16)
1 − (cid:112)ln N/2T

, then the Hedge algorithm satisﬁes

(cid:17)−1

+ sup
(cid:126)cT ∈CT


− EH



τb−1
(cid:88)

µi∗

t

· ci∗

t , t − EH

sup
(cid:126)cT ∈CT





τb−1
(cid:88)

t=τb−1

µit · cit, t





(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

≤ sup
(cid:126)cT ∈CT

t=τb−1



τb−1
(cid:88)


t=τb−1
(cid:40) τb−1
(cid:88)

t=τb−1

τb−1
(cid:88)

t=τb−1

µI ∗

b

· cI ∗

b , t






µi∗

t

· ci∗

t , t −

µI ∗

b

· cI ∗

b , t

µit · cit, t





(cid:41)

.

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

τb−1
(cid:88)

t=τb−1

(A.1)




τb−1
(cid:88)

max
i∈N



Ki, t · ci, t






t=τb−1


τb−1
(cid:88)

− EH



Kit, t · cit, t

√

≤ 2

2 ·

t=τb−1
√

∆ ln N .





(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

The two terms in the right hand side of (A.1) are deﬁned
as

Rb, 1 (cid:44) sup
(cid:126)cT ∈CT




τb−1
(cid:88)



t=τb−1

µi∗

t

· ci∗

t , t −

τb−1
(cid:88)

t=τb−1

µI ∗

b

· cI ∗

b , t






,

Note that the original theorem in Slivkins et al. (2019)
concerns a reward-based problem and the parameter ε is
chosen to be (cid:112)ln N/2T . Actually, by using the transfor-
mation of cost = 1 − reward between the per-time cost
and reward, the result can be transferred in the original
theorem into the conclusion in Lemma 3. Detailed proof
of Lemma 1 is given as follows.

Proof of Lemma 1. The proof is divided into four steps.
In the ﬁrst step, the best single action policy is used
to decompose the regret function into two parts. In the
second and third steps, upper bounds on the two parts
from the ﬁrst step are constructed, respectively. Finally,
the upper bound on the original regret function is pre-
sented. Denote the sub-sequence of times when Hedge
algorithm restarts as 1 = τ0 ≤ τ1 ≤ · · · ≤ τ(cid:100)T /∆(cid:101), which
implies that τb+1 − τb = ∆ for all b = 1, · · · , (cid:100)T /∆(cid:101) − 1
and τ(cid:100)T /∆(cid:101) − τ(cid:100)T /∆(cid:101)−1 ≤ ∆. For all b = 1, · · · , (cid:100)T /∆(cid:101),
note that the set of times {τb−1, · · · , τb − 1} exactly
forms the bth batch.

Step 1 Regret decomposition.
For each b = 1, · · · , (cid:100)T /∆(cid:101), the best single node I ∗
batch is deﬁned as I ∗
b
A speciﬁc sequence {ci, t}T

b in bth
(cid:111)
.
t=1 ∈ CT is ﬁxed and the regret

(cid:44) arg maxi∈N

(cid:110)(cid:80)τb−1

µi · ci, t

t=τb−1

and

Rb, 2 (cid:44) sup
(cid:126)cT ∈CT

− EH

(cid:40) τb−1
(cid:88)





t=τb−1

τb−1
(cid:88)

t=τb−1

µI ∗

b

· cI ∗

b , t

µit · cit, t





(cid:41)

.

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

(cid:44) (cid:80)τb−2

Step 2 Upper bounding Rb, 1.
Let V b
|ci, t+1 − ci, t| be the total variation of
T
ci, t in bth batch. For all (cid:126)cT ∈ CT , the following relation
holds

t=τb−1

max
τb−1≤t≤τb−1

(cid:110)

µi∗

t

· ci∗

t , t − µI ∗

b

(cid:111)

· cI ∗

b , t

≤ 2mV b

T . (A.2)

By contradiction, if (A.2) does not hold, then there is at
least one time τb−1 ≤ t0 ≤ τb − 1 such that µi∗
t , t0 −
= i0. Since µi ≤ m, ∀i ∈ N,
T . Let i∗
µI ∗
t0
for all τb−1 ≤ t ≤ τb − 1, it follows

b , t0 ≥ 2mV b

· cI ∗

· ci∗

b

t

µi0 · ci0, t > µi0

> µI ∗

b

> µI ∗

b

(cid:1) > µi0 · ci0, t0 − mV b
(cid:16)
b , t0 + V b
T > µI ∗

cI ∗

T

T

b

(cid:0)ci0, t0 − V b
· cI ∗

T

b , t0 + mV b
b , t.

· cI ∗

(cid:17)

However, this contradicts with the fact that I ∗
b is the
optimal single node of bth batch. Thus, inequality (A.2)

13

holds. Therefore, it can be obtained that

rithm are summarized. Note that

Rb, 1 = sup
(cid:126)cT ∈CT

τb−1
(cid:88)

(cid:16)

µi∗

t

t=τb−1

· ci∗

t , t − µI ∗

b

max
τb−1≤t≤τb−1

≤ ∆ sup
(cid:126)cT ∈CT
≤ 2∆mV b
T .

(cid:110)

µi∗

t

· ci∗

t , t − µI ∗

b

(cid:17)

· cI ∗

b , t

RH (λ, (cid:126)cT , T ) ≤

sup
(cid:126)cT ∈CT

(cid:100)T /∆(cid:101)
(cid:88)

b=1

(Rb, 1 + Rb, 2)

(cid:111)

· cI ∗

b , t

(cid:100)T /∆(cid:101)
(cid:88)

(cid:16)

≤

b=1

2∆mV b

T + 2

√

√

2 ·

∆ ln N

(cid:17)

≤ 2∆mVT +

(cid:19)

√

√
2

2 ·

+ 1

(cid:18) T
∆

∆ ln N ,

(A.3)

Step 3 Upper bounding Rb, 2.
Note that

where the third inequality follows from the relation
(cid:80)(cid:100)T /∆(cid:101)

b=1 V b

T = VT .

µI ∗

b

· cI ∗

b , t =

τb−1
(cid:88)

(cid:16)

E

KI ∗

b , t · cI ∗

b , t

(cid:17)

Embedding ∆ =
follows

(ln N )1/3 (T /mVT )2/3(cid:109)
(cid:108)

into (A.3), it

τb−1
(cid:88)

t=τb−1

t=τb−1



= max
i∈N





τb−1
(cid:88)

E (Ki, t · ci, t)

t=τb−1



τb−1
(cid:88)



t=τb−1

max
i∈N

Ki, t · ci, t












 .

≤ E

Therefore, it holds that

Rπ (λ, (cid:126)cT , T )

sup
(cid:126)cT ∈CT
(cid:34)

≤ 2

(ln N )1/3

(cid:18) T

(cid:19)2/3

mVT

(cid:35)

+ 1

mVT

(cid:115)

√

+ 2

2 · T ·

ln N (ln N )−1/3

√

(cid:118)
(cid:117)
(cid:117)
(cid:116)ln N

2

+ 2

(cid:34)
(ln N )1/3

(cid:18) T

mVT

(cid:18) T

(cid:19)−2/3

mVT

(cid:19)2/3

(cid:35)

+ 1

.

Rb, 2 ≤ sup
(cid:126)cT ∈CT


− EH



(cid:40)

(cid:34) 

E

max
i∈N






τb−1
(cid:88)

t=τb−1

Ki, t · ci, t

τb−1
(cid:88)

µit · cit, t

(cid:35)(cid:41)





(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

t=τb−1
(cid:40)

(cid:34) 

E

max
i∈N

τb−1
(cid:88)

kit, t · cit, t

t=τb−1






τb−1
(cid:88)

t=τb−1

Ki, t · ci, t





(cid:35)(cid:41)
.

(cid:12)
(cid:12)
(cid:12) λ, (cid:126)cT

≤ sup
(cid:126)cT ∈CT


− EH





















Since N > 2, Assumption 1 leads to (ln N )1/3 (T /mVT )2/3 >
1 and (cid:2)ln N/T (mVT )2(cid:3) < 1. It follows

Rπ (λ, (cid:126)cT , T )

sup
(cid:126)cT ∈CT
(cid:16)

≤

4 + 2

(cid:17)

√

2

(mVT ln N )1/3 (T )2/3
(cid:18) T

(cid:19)1/3

mVT
(mVT ln N )1/3 (T )2/3

+ 4 (ln N )2/3

(cid:16)

≤

4 + 2

√

(cid:17)

2

+ 4 (mVT ln N )1/3 (T )2/3

(cid:16)

≤

4 + 2

√

(cid:17)

2

(mVT ln N )1/3 (T )2/3

(cid:35)1/3

(cid:34)

ln N
T (mVT )2

According to Lemma 1 and noting that the relation in
Lemma 1 holds for arbitrary (cid:126)cT satisfying Ki, t · ci, t ≤ 1,
∀i, t, it follows

+ 4 (mVT ln N )1/3 (T )2/3
(cid:17)

√

(cid:16)

≤

8 + 2

2

(mVT ln N )1/3 (T )2/3 ,

√

Rb, 2 ≤ 2

√

2 ·

∆ ln N .

which concludes the proof.

References

Step 4 Upper bounding the sup regret.
In the ﬁnal step, discussions in the previous two steps
and the upper bound on the sup regret by Hedge algo-

Abiri-Jahromi, A., Kemmeugne, A., Kundur, D. and
Haddadi, A. (2020), ‘Cyber-physical attacks target-
ing communication-assisted protection schemes’,

14

IEEE Transactions on Power Systems 35(1), 440–
450.

Amin, S., Schwartz, G. A. and Sastry, S. S. (2013), ‘Secu-
rity of interdependent and identical networked con-
trol systems’, Automatica 49(1), 186–192.

Auer, P., Cesa-Bianchi, N., Freund, Y. and Schapire,
R. E. (2002), ‘The nonstochastic multiarmed bandit
problem’, SIAM journal on computing 32(1), 48–77.
Besbes, O., Gur, Y. and Zeevi, A. (2019), ‘Optimal
exploration–exploitation in a multi-armed bandit
problem with non-stationary rewards’, Stochastic
Systems 9(4), 319–337.

Che, L., Liu, X., Shuai, Z., Li, Z. and Wen, Y. (2018),
‘Cyber cascades screening considering the impacts
of false data injection attacks’, IEEE Transactions
on Power Systems 33(6), 6545–6556.

Even-Dar, E., Kakade, S. M. and Mansour, Y. (2009),
‘Online markov decision processes’, Mathematics of
Operations Research 34(3), 726–736.

Freund, Y. and Schapire, R. E. (1999), ‘Adaptive game
playing using multiplicative weights’, Games and
Economic Behavior 29(1-2), 79–103.

Gallo, A. J., Turan, M. S., Boem, F., Parisini, T. and
Ferrari-Trecate, G. (2020), ‘A distributed cyber-
attack detection scheme with application to dc mi-
crogrids’, IEEE Transactions on Automatic Control
DOI: 10.1109/TAC.2020.2982577.

Heyman, D. and Sobel, M. (2004), ‘Superposition of re-
newal processes’, Stochastic Models in Operations
Research: Stochastic Processes and Operating Char-
acteristics p. 158.

Khalili, M., Zhang, X., Cao, Y., Polycarpou, M. M. and
Parisini, T. (2020), ‘Distributed fault-tolerant con-
trol of multiagent systems: An adaptive learning
approach’, IEEE Transactions on Neural Networks
and Learning Systems 31(2), 420–432.

Konstantelos, I., Giannelos, S. and Strbac, G. (2016),
‘Strategic valuation of smart grid technology op-
tions in distribution networks’, IEEE Transactions
on Power Systems 32(2), 1293–1303.

Li, J.-A., Dong, D., Wei, Z., Liu, Y., Pan, Y., Nori, F. and
Zhang, X. (2020), ‘Quantum reinforcement learn-
ing during human decision-making’, Nature Human
Behaviour 4(3), 294–307.

Littman, M. L. (2015),

‘Reinforcement learning im-
proves behaviour from evaluative feedback’, Nature
521(7553), 445–451.

Liu, Z., Wang, L., Wang, J., Dong, D. and Hu, X. (2017),
‘Distributed sampled-data control of nonholonomic
multi-robot systems with proximity networks’, Au-
tomatica 77, 170–179.

Mo, H. and Sansavini, G. (2017), ‘Dynamic defense
resource allocation for minimizing unsupplied de-
mand in cyber-physical systems against uncer-
tain attacks’, IEEE Transactions on Reliability
66(4), 1253–1265.

Mo, H. and Sansavini, G. (2019), ‘Impact of aging and
performance degradation on the operational costs of
distributed generation systems’, Renewable energy

143, 426–439.

Osband, I., Russo, D. and Van Roy, B. (2013), (more)
eﬃcient reinforcement learning via posterior sam-
pling, in ‘Advances in Neural Information Process-
ing Systems’, pp. 3003–3011.

Patsakis, G., Rajan, D., Aravena, I., Rios, J. and Oren,
S. (2018), ‘Optimal black start allocation for power
system restoration’, IEEE Transactions on Power
Systems 33(6), 6766–6776.

Perera, C., Liu, C. H. and Jayawardena, S. (2015), ‘The
emerging internet of things marketplace from an in-
dustrial perspective: A survey’, IEEE Transactions
on Emerging Topics in Computing 3(4), 585–598.

Pillitteri, V. Y. and Brewer, T. L. (2014), Guidelines for

smart grid cybersecurity, Technical report.

Pogaku, N., Prodanovic, M. and Green, T. C. (2007),
‘Modeling, analysis and testing of autonomous
operation of an inverter-based microgrid’, IEEE
Transactions on Power Electronics 22(2), 613–625.
Rana, M. M., Li, L. and Su, S. W. (2017), ‘Cyber attack
protection and control of microgrids’, IEEE/CAA
Journal of Automatica Sinica 5(2), 602–609.
Rana, M. M., Xiang, W. and Wang, E. (2018), ‘Smart
grid state estimation and stabilisation’, Interna-
tional Journal of Electrical Power & Energy Systems
102, 152–159.

Russo, D. and Van Roy, B. (2014), ‘Learning to optimize
via posterior sampling’, Mathematics of Operations
Research 39(4), 1221–1243.

Sahraei-Ardakani, M. and Hedman, K. W. (2016), ‘Com-
putationally eﬃcient adjustment of facts set points
in dc optimal power ﬂow with shift factor structure’,
IEEE Transactions on Power Systems 32(3), 1733–
1740.

Slivkins, A. et al. (2019), ‘Introduction to multi-armed
bandits’, Foundations and Trends® in Machine
Learning 12(1-2), 1–286.

Smith, M. D. and Pat´e-Cornell, M. E. (2018), ‘Cyber
risk analysis for a smart grid: how smart is smart
enough? a multiarmed bandit approach to cyber
security investment’, IEEE Transactions on Engi-
neering Management 65(3), 434–447.

Sutton, R. S. and Barto, A. G. (2018), Reinforcement

learning: An introduction, MIT press.

Todescato, M., Bof, N., Cavraro, G., Carli, R. and Schen-
ato, L. (2020), ‘Partition-based multi-agent opti-
mization in the presence of lossy and asynchronous
communication’, Automatica 111, 108648.

Yu, K., Ai, Q., Wang, S., Ni, J. and Lv, T. (2015), ‘Anal-
ysis and optimization of droop controller for micro-
grid system based on small-signal dynamic model’,
IEEE Transactions on Smart Grid 7(2), 695–705.

Zhang, X. and Papachristodoulou, A. (2015), ‘A real-
time control framework for smart power networks:
Design methodology and stability’, Automatica
58, 43–50.

Zhu, M. and Mart´ınez, S. (2013), ‘On distributed con-
strained formation control in operator–vehicle ad-
versarial networks’, Automatica 49(12), 3571–3582.

15

