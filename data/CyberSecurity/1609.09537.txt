7
1
0
2

r
p
A
3

]

R
C
.
s
c
[

3
v
7
3
5
9
0
.
9
0
6
1
:
v
i
X
r
a

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

1

Covert Attacks in Cyber-Physical
Control Systems
Alan Oliveira de S´a∗†, Luiz F. Rust da Costa Carmo∗‡, Raphael C. S. Machado‡

∗Institute of Mathematics / NCE - T´ercio Pacitti Institute,
Federal University of Rio de Janeiro, 21.941-901, RJ – Brazil
†Admiral Wandenkolk Instruction Center – Brazilian Navy,
Ilha das Enxadas, Ba´ıa de Guanabara – Rio de Janeiro – RJ – Brazil
alan.oliveira.sa@gmail.com
†National Institute of Metrology, Quality and Technology (Inmetro)
Av. Nossa Senhora das Grac¸as, 50, Xer´em, Duque de Caxias, 25.250-020, RJ – Brazil
{lfrust,rcmachado}@inmetro.gov.br

Abstract—The advantages of using communication networks
to interconnect controllers and physical plants motivate the
increasing number of Networked Control Systems, in industrial
and critical infrastructure facilities. However, this integration also
exposes such control systems to new threats, typical of the cyber
domain. In this context, studies have been conduced, aiming to
explore vulnerabilities and propose security solutions for cyber-
physical systems. In this paper, it is proposed a covert attack for
service degradation, which is planned based on the intelligence
gathered by another attack, herein proposed, referred as System
Identiﬁcation attack. The simulation results demonstrate that the
joint operation of the two attacks is capable to affect, in a covert
and accurate way, the physical behavior of a system.

Controller

forward stream

Plant

r(k)

+

e(k)
_

Control
function
C(z )

s
r
o
t
a
u
t
c
A

Physical
Process
G(z )

s
r
o
s
n
e
S

u(k)

u’(k)

Network

y’(k)

y(k)

feedback stream

Index Terms—Security, Cyber-Physical Systems, Networked

Figure 1. Networked Control Systems (NCS)

Control Systems.

I. INTRODUCTION

T HE integration of the systems used to control physical

processes via communication networks aims to assign to
such systems better operational and management capabilities,
as well as reduce its costs. Motivated by these advantages,
there is a trend to have an increasing number of industrial pro-
cess and critical infrastructure systems driven by Networked
Control Systems (NCS) [1]–[4], also referred as Network-
Based Control Systems (NBCS) [5], [6]. A NCS, shown in
Figure 1, consists of a physical plant, described by its transfer
function G(z), a controller, which runs a control function
C(z), and a communication network that interconnect both
devices through a forward stream and a feedback stream. The
forward stream connects the output of the controller to the
plant’s actuators. The feedback stream connects the output of
the plant’s sensors to the controller’s input.

At the same time it brings several advantages, the integration
of controllers and physical plants in a closed loop through a
communication network also exposes such control systems to
new threats, typical of the cyber domain. In this context, stu-
dies have been conduced aiming to characterize vulnerabilities
and propose security solutions for the NCSs.

One possible way to attack a NCS is by hacking its software,
i.e. changing the conﬁguration or even the code executed by
the controller, following a strategy similar to that used by the
Stuxnet worm [7]. Another possible way for an attacker to
negatively affect a NCS is by interfering on its communication
process. Basically, an attacker may interfere in the forward
and/or the feedback streams by three different means: inducing
a jitter, causing data loss due to packet drop outs, or even
injecting false data in the communication process.

In this work, it is developed an attack where false data
is injected in the communication process of a NCS. It is
demonstrated the possibility to degrade the service performed
by a plant, through interventions that produce subtle changes
on its physical behavior. Such interventions aim to reduce the
efﬁciency of the plant or even cause it damage in mid/long
therm. It is worth mentioning that an uncontrolled intervention
in a NCS may lead the plant to an immediate breakdown,
or even signiﬁcantly change its behavior, which may cause
the disclosure of the attack and the eventual failure of the
the changes driven by the attack herein
operation. Thus,
proposed are dimensioned so that the modiﬁcations in the
plant’s behavior are physically difﬁcult to be perceived. That
is why the present attack is classiﬁed as physically covert.

To ensure that the attack to a NCS is physically covert,
the attacker must plan his offensive based on an accurate
Copyright (c) 2017 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from
the IEEE by sending a request to pubs-permissions@ieee.org. The ﬁnal version of this paper is available at http://dx.doi.org/10.1109/TII.2017.2676005.

 
 
 
 
 
 
FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

2

knowledge about the system dynamics, otherwise the conse-
quences of the attack may be unpredictable. One possible way
to obtain such knowledge is through conventional intelligence
operations, performed to collect information regarding to the
design and the dynamics of the NCS. Another way to gather
information about the targeted system is through what we
refer in this paper as a Cyber-Physical Intelligence attack.
To this end, it is also proposed in this paper the System
Identiﬁcation attack, which aims to collect information about
the plant’s transfer function G(z) and the controller’s control
function C(z) of a NCS. This attack is proposed based on the
Backtracking Search Optimization algorithm (BSA) [8].

This work motivated the formalization of a number of
concepts related to covertness and intelligence in the context of
the cyber-physical security. Thus, an additional contribution of
this paper is the proposition of a terminology that encompasses
a whole new class of attacks on cyber-physical systems. The
proposed taxonomy establishes a new approach regarding to
the covertness of attacks on cyber-physical systems, which
must be analyzed from two aspects simultaneously: the phys-
ical and the cybernetic aspects.

It is worth mentioning that the objective of this work is not
to facilitate covert attacks for service degradation in cyber-
physical control systems. The purpose of this work is to
demonstrate the degree of accuracy that may be achieved
in this kind of attack, especially when supported by System
Identiﬁcation attacks and, therefore, encourage the research
for countermeasures to such attacks. The rest of this paper
is organized as follows: First, in Section II, some related
works are presented. Later, in Section III, it is proposed a
taxonomy regarding to the cyber-physical attacks that may
happen in the control loop of a NCS. In Section IV, it is
described a System Identiﬁcation attack. Then, in Section V,
it is deﬁned a cover attack for service degradation. After
that, in Section VI, there are reported the results obtained by
simulations of covert attacks for service degradation, supported
by System Identiﬁcation attacks. Finally, in Section VII, some
conclusions and possible future works are presented.

II. RELATED WORKS

The possibility of cyber-physical attacks became a reality
after the launch of the Stuxnet worm [7] and has been
motivating researches concerning the security of NCSs. In this
section, some works related to this subject are presented.

In [6] the authors propose two queueing models to evaluate
the impact of delay jitter and packet loss in a NCS under
attack. The attack is not designed taking into account a
previous knowledge about the models of the controller and the
physical plant. Thus, to affect the plant’s behavior, the attacker
arbitrarily ﬂoods the network with an additional trafﬁc, causing
jitter and packet loss. In this tactics, the excess of packets in
the network can reduce the covertness of the attack, allowing
the adoption of countermeasures, such as packet ﬁltering [6]
or blocking the malicious trafﬁc on its origin [9]. Additionally,
the arbitrary intervention in a system which the model is
unknown may lead the plant to an extreme physical behavior,
which is not desired if it is intended a covert attack.

In [4],

the authors present a Supervisory Control and
Data Acquisition (SCADA) testbed using TrueTime, a MAT-
LAB/Simulink based tool. They demonstrate an attack where a
malicious agent sends false signals to the controller and to the
actuator of a NCS. In that paper, the false signals are randomly
generated aiming to make a DC motor lose its stability. This
kind of attack does not require a previous knowledge about
the plant and controller of the NCS. On the other hand, the
desired physical effect and the covertness of the attack can
not be ensured due to the unpredictable consequences of the
application of random false signals to a system which the
model is unknown.

More recently, in [10], the authors give a general framework
for the analysis of a wide variety of methods of attack in
NCSs. In their classiﬁcation, it is stated that covert attacks
in NCSs require high level of knowledge about the targeted
system. Exemples of covert attacks are provided in [11],
[12]. In these works the attacks are reformed by a man-in-
the-middle (MitM), where the attacker needs to know the
model of the plant under attack and also inject false data in
both the forward and the feedback streams. The covertness
of the attacks described in [11], [12], which depends on the
difference between the actual model of the plant and the model
used by the attacker, is analyzed from the perspective of the
signals arriving to the controller, without addressing if the
physical effects on the plant are noticeable, or if they are covet
when faced by a human observer.

In [10]–[12], where it is required a previous knowledge
about the models of the NCS under attack, it is not described
how the knowledge about
the system is obtained by the
attacker. It is just stated that a model is previously known
to subsidize the design of the attack. The joint operation,
herein proposed, of a covert attack for service degradation,
supported by a System Identiﬁcation attack, aims to ﬁll this
hiatus, demonstrating how the data of a NCS can be obtained
and how a covert attack can take advantage from it. The
Table I presents a synthesis of the characteristics of the attacks
referred in this section.

Table I
SYNTHESIS OF THE RELATED ATTACKS

Attack

Stuxnet worm [7]

Long, et al. [6]

Farooqui, et al. [4]
Smith [11], [12]

Method

Modiﬁcations in
the PLC code
Inducing jitter
and packet loss
Data injection
Data injection

System
knowledge

How the knowledge
is obtained

Yes

None

None
Yes

Experiments in
a real system
N/A

N/A
Not described

III. TAXONOMY

In this section it is presented a taxonomy concerning the
possible attacks on cyber-physical control systems. In Section
III-A, the attacks are brieﬂy described and classiﬁed according
to the way they act in the NCS. In Section III-B, it is proposed
a new approach for the analysis of the covertness of attacks
in cyber-physichal systems.

A. Classiﬁcation of the Attacks

The attacks to cyber-physichal control systems may take
place on its devices – i.e. the controller, and the plant’s sensors

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

3

and actuators – and/or on its communication system, affecting
the forward and the feedback streams. As a premise, we must
consider that the service intended to be attacked/protected in
such system is the work performed by the physical process,
controlled by the NCS.

Considering the aforementioned deﬁnition of service in a
the attacks may be classiﬁed within three different

NCS,
categories, as shown in Figure 2:

• Denial-of-Service (DoS) [13]: in a NCS, the DoS attacks
comprehends all kind of cyber-physical attacks that deny
the operation of the physical process, interrupting the
execution of the work, or service, that the controlled
plant is intended to do. The attack results, for example, in
behaviors that may shut the plant down or even destroy
it in a short therm.

• Service Degradation (SD):

the SD attacks consist of
malicious interventions that are done in the control loop
in order to reduce the efﬁciency of the service, i.e. the
efﬁciency of the physical process, or even reduce the
mean time between failure (MTBF) of the plant in mid
therm or long therm.

• Cyber-physical Intelligence (CPI): the concept of Cyber-
physical Intelligence, herein proposed, is different from
the concept of where cyber-physical systems are in-
tegrated with intelligent systems [14]. In the present
taxonomy, the CPI attacks comprehend actions that are
performed in the control loop of a NCS in order to gather
information about the system’s operation and/or its de-
sign. This attacks are intended to acquire the intelligence
necessary to plan covert and controlled attacks, or even
to subsidize data for replay attacks [7].

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:5)(cid:13)(cid:14)(cid:5)

(cid:15)(cid:16)(cid:16)(cid:5)(cid:3)(cid:3)(cid:7)(cid:4)(cid:10)(cid:7)(cid:4)(cid:17)(cid:5)(cid:7)(cid:13)(cid:18)(cid:4)(cid:18)

(cid:15)(cid:16)(cid:16)(cid:5)(cid:3)(cid:3)(cid:7)(cid:4)(cid:10)(cid:7)(cid:4)(cid:17)(cid:5)(cid:7)(cid:16)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12) (cid:12)(cid:10)(cid:10)(cid:20)

(cid:10)
(cid:9)
(cid:8)
(cid:2)
(cid:7)
(cid:2)
(cid:6)
(cid:5)
(cid:4)
(cid:3)
(cid:2)
(cid:1)

(cid:1)(cid:2)(cid:3)

(cid:26)(cid:10)(cid:1)(cid:27)(cid:15)(cid:19)(cid:28)(cid:23)(cid:4)(cid:19)(cid:18)(cid:19)(cid:2)(cid:7)
(cid:29)(cid:23)(cid:4)(cid:4)(cid:5)(cid:19)

(cid:26)(cid:10)(cid:1)(cid:27)(cid:15)(cid:19)(cid:28)(cid:23)(cid:4)(cid:19)(cid:18)(cid:19)(cid:2)(cid:7)
(cid:26)(cid:18)(cid:4)(cid:18)(cid:7)(cid:12)(cid:10)(cid:3)(cid:3)

(cid:26)(cid:10)(cid:1)(cid:27)(cid:15)(cid:19)(cid:28)(cid:23)(cid:4)(cid:19)(cid:18)(cid:19)(cid:2)(cid:7)
(cid:26)(cid:18)(cid:4)(cid:18)(cid:7)(cid:24)(cid:9)(cid:30)(cid:5)(cid:16)(cid:4)(cid:23)(cid:10)(cid:9)

(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:4)(cid:9)
(cid:1)(cid:4)(cid:10)(cid:5)(cid:11)(cid:12)(cid:11)(cid:13)(cid:7)(cid:2)(cid:14)

(cid:26)(cid:10)(cid:1)(cid:27)(cid:31)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12)(cid:12)(cid:5)(cid:13)(cid:7)
(cid:29)(cid:23)(cid:4)(cid:4)(cid:5)(cid:19)

(cid:26)(cid:10)(cid:1)(cid:27)(cid:31)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12)(cid:12)(cid:5)(cid:13)
(cid:26)(cid:18)(cid:4)(cid:18)(cid:7)(cid:12)(cid:10)(cid:3)(cid:3)

(cid:26)(cid:10)(cid:1)(cid:27)(cid:31)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12)(cid:12)(cid:5)(cid:13)
(cid:26)(cid:18)(cid:4)(cid:18)(cid:7)(cid:24)(cid:9)(cid:30)(cid:5)(cid:16)(cid:4)(cid:23)(cid:10)(cid:9)

(cid:1)(cid:26)(cid:27)(cid:31)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12)(cid:12)(cid:5)(cid:13)(cid:7)
(cid:29)(cid:23)(cid:4)(cid:4)(cid:5)(cid:19)

(cid:1)(cid:26)(cid:27)(cid:31)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12)(cid:12)(cid:5)(cid:13)
(cid:26)(cid:18)(cid:4)(cid:18)(cid:7)(cid:12)(cid:10)(cid:3)(cid:3)

(cid:1)(cid:26)(cid:27)(cid:31)(cid:10)(cid:9)(cid:4)(cid:19)(cid:10)(cid:12)(cid:12)(cid:5)(cid:13)
(cid:26)(cid:18)(cid:4)(cid:18)(cid:7)(cid:24)(cid:9)(cid:30)(cid:5)(cid:16)(cid:4)(cid:23)(cid:10)(cid:9)

(cid:15)(cid:16)(cid:17)(cid:4)(cid:5)(cid:18)(cid:19)(cid:20)(cid:16)(cid:21)(cid:7)(cid:8)(cid:11)(cid:22)(cid:9)
(cid:7)(cid:14)(cid:13)(cid:4)(cid:22)(cid:22)(cid:7)(cid:10)(cid:4)(cid:14)(cid:8)(cid:4)

(cid:21)(cid:18)(cid:22)(cid:5)(cid:3)(cid:13)(cid:19)(cid:10)(cid:20)(cid:20)(cid:23)(cid:9)(cid:14)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)
(cid:24)(cid:13)(cid:5)(cid:9)(cid:4)(cid:23)(cid:25)(cid:23)(cid:16)(cid:18)(cid:4)(cid:23)(cid:10)(cid:9)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)

(cid:15)(cid:2)(cid:23)(cid:19)(cid:22)(cid:4)(cid:24)(cid:7)(cid:13)(cid:16)(cid:9)(cid:2)(cid:25)(cid:9)(cid:13)(cid:20)(cid:4)(cid:9)(cid:11)(cid:13)(cid:13)(cid:11)(cid:8)(cid:26)

(cid:1)(cid:8)(cid:9)(cid:10)(cid:11)(cid:5)(cid:6)(cid:7)

Figure 2. Classiﬁcation and requirements of the cyber-physical attacks that
act in the control loop of a NCS.

In Figure 2, six kinds of DoS attacks are presented, with
their respective requirements. From this six DoS attacks, the
less complex are the arbitrary ones:

• DoS-Arbitrary Jitter: in this kind of attack, the delay
of the forward and/or the feedback stream is arbitrarily
changed, without a previous knowledge about the models
of the NCS, in order to lead the system to an instability
or to a condition that causes the interruption of the
physical process. This attack only requires access to the
control loop, once it may be performed by just consuming
the resources of the system, such as the bandwidth of
communication links, or the computational resources of
the equipments that are in the control loop.

in this kind of attack,

• DoS-Arbitrary Data Loss:

the
attacker prevents the data from reaching the actuator
and/or the controller of the NCS. The communication
channel is jammed arbitrarily, without a previous know-
ledge about the models of the NCS, leading the system to
an instability or to a condition that causes the interruption
of the physical process. It is worth mentioning that some
DoS-Arbitrary Jitter attack may result in a DoS-Arbitrary
Data Loss attack, if an eventual higher delay cause packet
drop outs. As the DoS-Arbitrary Jitter attack, this attack
only requires access to the control loop of the NCS.
• DoS-Arbitrary Data Injection: in such attacks, the attacker
sends arbitrary false data to the controller, as it was sent
by the sensors, and/or to the actuators, as it was sent by
the controller. The false data is injected in the NCS closed
loop without a previous knowledge about the models of
the NCS. This attack is more complex than the DoS-
Arbitrary Jitter and the DoS-Arbitrary Data Loss attacks,
given that it requires access to the data that ﬂows in the
control loop of the NCS.

The attacks classiﬁed as DoS-controlled – DoS-Controlled
Jitter, DoS-Controlled Data Loss, and DoS-Controlled Data
Injection – shown in Figure 2 interfere in the control loop
of a NCS by the same means that
their respective DoS-
Arbitrary attacks. The difference between a DoS-Controlled
attack and a DoS-Arbitrary attack is that, in the former, the
interference caused by the attacker is precisely planned and
executed, in order to achieve the exact desired behavior that
leads the physical service to an interruption, in a more efﬁcient
way. Thus, to achieve such efﬁciency, a DoS-Controlled attack
require an accurate knowledge about the NCS models, i.e. the
plant and the controller transfer functions, which have to be
analyzed to plan the attack.

Regarding to the SD attacks, we must consider the three dif-
ferent kinds of attack shown in Figure 2: SD-Controlled Jitter,
SD-Controlled Data Loss, and SD-Controlled Data Injection.
The difference between a SD-Controlled attack and a DoS-
Controlled attack is that the former is not intended to interrupt
the physical process in a short therm. It aims to keep the pro-
cess running with reduced efﬁciency, sometimes also targeting
a gradual physical deterioration of the controlled devices. To
succeed, the SD-Controlled attacks need to be planned based
on an accurate knowledge about the dynamics and the design
of the NCS. Otherwise, the attack can eventually interrupt the
physical process, due to unpredicted reasons, evolving to a
DoS attack.

The system knowledge required to both DoS-Controlled and
SD-Controlled attacks, can be gathered through CPI attacks,

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

4

as shown in Figure 2. The ﬁrst, and simpler, CPI attack
is the eavesdropping attack [15], [16], which consists of
simply capturing the data transmitted through the forward and
feedback streams of the NCS. The second CPI attack, herein
proposed, is the System Identiﬁcation attack, which aims to
obtain information about the control function of the controller
and the transfer function of the plant, by analyzing the signals
that ﬂow in the network between the controller and the plant.
The CPI attacks by themselves do not impact on the NCS,
but they are an useful tool to plan efﬁcient and accurate DoS-
Controlled and SD-Controlled attacks.

B. Cybernetic vs. Physical Covertness

The covertness of an attack regards to its capacity to not be
perceived or detected. In the case of cyber-physical attacks on
NCSs, the covertness must be simultaneously analyzed in two
different domains: the cyber domain; and the physical domain.
In this sense, it is presented in this section the deﬁnition of
what is a cybernetically covert attack and what is a physically
covert attack:

• Cybernetically covert attacks: are the attacks that have
low probability to be detected by algorithms that monitor
the softwares, communications and data of the NCS, or
by systems that monitor the dynamics of the plant.

• Physically covert attacks: are attacks that cause physical
effects that can not be easily noticed or identiﬁed by
a human observer. The attack slightly modiﬁes some
behaviors of the system in a way that it physically affects
the plant, but the effect is not easily perceptible or it can
eventually be understood as a consequence of another
root cause, other than an attack.

IV. THE SYSTEM IDENTIFICATION ATTACK

The System Identiﬁcation attack, herein proposed, is in-
tended to assess the coefﬁcients of the plant’s transfer function
G(z) and the controller’s control function C(z). Both func-
tions are linear time-invariant (LTI). The attack uses the BSA
metaheuristic, proposed in [8] and brieﬂy described in [17],
to minimize the ﬁtness function presented in this section.

The BSA is an evolutionary algorithm that uses the informa-
tion obtained by past generations – or iterations – to perform
the search for solutions for optimization problems. The algo-
rithm has two parameters that are empirically adjusted: the size
of its population P ; and η, described in [17], that establishes
the amplitude of the movements of the individuals of P . The
parameter η must be adjusted aiming to assign to the algorithm
both good exploration and exploitation capabilities.

If the input i(k) and the output o(k) of a device of the
NCS is known, the model of such device can be assessed
by applying the known i(k) in an estimated model, which
must be adjusted until its estimated output ˆo(k) converge to
o(k). In this sense, the BSA is used to iteratively adjust the
estimated model, by minimizing a speciﬁc ﬁtness function,
until the estimated model converge to the actual model of the
real device, that can be a controller or a plant of the NCS.

To establish the ﬁtness function, ﬁrstly, it must be consid-
ered a generic LTI system, whose transfer function Q(z) is
represented by (1):

Q(z) =

O(z)
I(z)

=

anzn + an−1zn−1 + ... + a1z1 + a0
zm + bm−1zm−1 + ... + b1z1 + b0

,

(1)

wherein I(z) is the input of the system, O(z) is the output
of the system, n and m are the order of the numerator
and the denominator, respectively, and [an, an−1, ...a1, a0] and
[bm−1, bm−2, ...b1, b0] are the coefﬁcients of the numerator
and the denominator, respectively, that are intended to be
found by this System Identiﬁcation attack. Also, it must be
considered that i(k) and o(k) represent the sampled input and
output of the system, respectively, where I(z) = Z[i(k)],
O(z) = Z[o(k)], k is the number of the sample and Z
represents the Z-transform operation.

In this System Identiﬁcation attack, i(k) and o(k) are ﬁrstly
captured by an eavesdropping attack [15], [16], for exemple,
during a monitoring period T . To deal with the eventual loss
of samples, that may not be received by the attacker during
T , the algorithm holds the value of the last received sample,
according with (2), wherein x(k) can either be i(k) or o(k):

x(k) = 


x(k − 1)

if the sample k is lost;

(2)

x(k)

otherwise.



Then, after acquiring i(k) and o(k),

the captured i(k)
that
is applied to the input of an estimated model,
is described by a transfer
function whose coefﬁcients
[an,j, an−1,j, ...a1,j, a0,j, bm−1,j, bm−2,j, ...b1,j, b0,j] are the
coordinates of an individual j of the BSA. The application
of i(k) to the input of the estimated model results in an
output signal ˆoj(k). After obtaining ˆoj(k),
the ﬁtness fj
of the individual j is computed comparing the output o(k),
captured from the attacked device, with the output ˆoj(k) of
the estimated model, according with (3):

N

Pk=0

fj =

(o(k) − ˆoj(k))2

N

,

(3)

wherein N is the number of samples that exist during the
monitoring period T . Note that, if the attacker do not lose
any sample of i(k) and o(k) during T , then min fj = 0
when [an,j, an−1,j, ...a1,j, a0,j, bm−1,j, bm−2,j, ...b1,j, b0,j] =
[an, an−1, ...a1, a0, bm−1, bm−2, ...b1, b0], i.e. when the esti-
mated model converges to the actual model of the attacked
device.

It is possible to establish an analogy between this System
Identiﬁcation attack and the Known Plaintext cryptanalytic
attack [18], wherein i(k) and o(k) correspond to the plaintext
and ciphertext, respectively, the form of the generic transfer
function Q(z) corresponds to the encryption algorithm and the
actual coefﬁcients of Q(z) corresponds to the secret key.

V. THE COVERT ATTACK FOR SERVICE DEGRADATION

Based on the taxonomy presented in Section III-A,
the
attack described in this section is classiﬁed as a SD-Controlled
Data Injection attack. Its purpose is to reduce the MTBF of the

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

5

plant and/or reduce the efﬁciency of the physical process that
the plant performs, by inserting false data in the control loop.
At the same time, the attacker desires that the attack meets
the requirement of being physically covert, as the deﬁnition
presented in Section III-B.

One way to degrade a physical service is through the
induction of an overshoot during the transient response of
a plant. The overshoots, or peaks occurred when the system
exceeds the targeted value during the transient response, can
cause stress and possibly damage physical systems such as
mechanical, chemical and electromechanical systems [19],
[20]. Additionally, once they occur in a short period of time,
the overshoots are difﬁcult to be noticed by a human observer.
Another way to degrade the service of a plant is causing a
constant steady state error on it, i.e. producing a constant error
when t → ∞. A low proportion steady state error, besides
being difﬁcult to be perceived by a human observer, may
reduce the efﬁciency of the physical process or, occasionally,
stress and damage the system in mid/long therm.

In the present attack, to achieve either of the two mentioned
effects, i.e. an overshoot or a constant steady state error, the
attacker interfere in the NCS’s communication process by
injecting false data into the system in a controlled way. To do
so, the attacker act as a MitM that executes an attack function
M (z), as presented in Figure 3, wherein U ′(z) = M (z)U (z),
U (z) = Z[u(k)] and U ′(z) = Z[u′(k)]. The function
M (z) is designed based on the models of the plant and the
controller, both obtained through the System Identiﬁcation
attack, described in Section IV. The effectiveness of the attack,
therefore, depends on the design of M (z), which in turn
depends on the accuracy of the System Identiﬁcation attack.
It is worth mentioning that, in Figure 3, although the MitM
is placed in the forward stream, it is also possible perform an
attack by interfering in the feedback stream of the NCS. The
MitM may act in wired or wireless networks, such as in [21].

Controller

forward stream

Plant

r(k)

+

e(k)
_

Control
function
C(z )

u(k)

u’(k)

s
r
o
t
a
u
t
c
A

Physical
process
G(z )

s
r
o
s
n
e
S

M(z )

MitM

Network

y’(k)

y(k)

feedback stream

Figure 3. MitM attack

VI. RESULTS

In this section,

there are presented the results obtained
through simulations that combines the System Identiﬁcation
attack with physically covert SD-Controlled attacks. First, in
Section VI-A, the model of the attacked system is described.
Then, in Section VI-B, there are presented the results obtained
by the System Identiﬁcation attack. After that, in Section VI-C,

there are presented the results achieved by simulations of phys-
ically covert SD-Controlled Data Injection attacks, planned
based on the data gathered by the System Identiﬁcation attack.

A. The Model of the Attacked System

The attacked NCS has the same architecture of the NCS
shown in Figure 1, and consists of a Proportional-Integral (PI)
controller that controls the rotational speed of a DC motor. The
PI control function C(z) and the DC motor transfer function
G(z) are the same as in [6]. The equations of this NCS are
represented in (4):

C(z) =

c1z − c2
z − 1

G(z) =

g1z + g2
z2 − g3z + g4

(4)

wherein c1 = 0, 1701, c2 = −0, 1673, g1 = 0, 3379, g2 =
0, 2793, g3 = −1, 5462 and g4 = 0, 5646. The sample rate of
the system is 50 samples/s and the set point r(k) is an unitary
step function. The network delay is not taken into account in
the simulations of this paper.

B. Results of the System Identiﬁcation Attack

In this Section, the performance of the System Identiﬁcation
attack is evaluated through a set of simulations performed
in MATLAB. The SIMULINK tool is used to compute the
output ˆoj of the estimated models, whose coefﬁcients are the
coordinates of an individual j of the BSA.

The structure of the equations represented in (4) are pre-
viously known by the attacker once that, as a premise, it is
known that the target is a NCS that controls a DC motor using
a PI controller. In these simulations, the goal of the System
Identiﬁcation attack is to discover g1, g2, g3, g4, c1 and c2,
also taking into account scenarios in which the attacker occa-
sionally loses samples of the forward and feedback streams.
Each time that the DC motor is turned on, the forward
and the feedback streams are captured by the attacker during
a period T = 2s. All initial conditions are considered 0,
by the time that the motor is turned on. The coefﬁcients of
G(z), [g1, g2, g3, g4], and the coefﬁcients of C(z), [c1, c2],
are computed separately considering that, albeit the closed
loop, G(z) and C(z) are independent transfer functions. To
assess [g1, g2, g3, g4], the attacker considers the forward stream
as the input and the feedback stream as the output of the
estimated plant. In the opposite way, to assess [c1, c2], the
attacker considers the feedback stream as the input and the
forward stream as the output of the estimated controller.

it

To simulate the loss of samples,

is considered four
different rates l of sample loss: 0, 0.05, 0.1 and 0.2. Thus,
a sample is lost by the attacker every time that l < P, where
P ∼ U (0, 1) and U is the uniform distribution. There are
executed 100 different simulations for each rate of sample loss.
In the BSA, the population is set to 100 individuals and
η, empirically adjusted, is 1. To assess the coefﬁcients of the
controller [c1, c2], the algorithm is executed for 600 iterations.
To assess the coefﬁcients of the plant
the
number of iterations is increased to 800, due to the higher
number of dimensions of the search space in this case. The
limits of each dimension of the search space are [−10, 10].

[g1, g2, g3, g4],

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

6

Figure 4 shows the means of 100 estimated values of g1,
g2, g3, g4, c1 and c2, with a Conﬁdence Interval (CI) of 95%,
considering different rates of sample loss. The actual values of
the coefﬁcients of C(z) and G(z) are also depicted in Figure 4.
Note that the scales of Figures 4(a), 4(b), 4(c) and 4(d) are
different from the scales of Figures 4(f) and 4(f), due to the
smaller amplitude of the CI of c1 and c2. In Addition, some
statistics of the obtained results are presented in Table II.

According with Table II the distributions of g1, g2, g3 and g4
have a high skewness, while the distributions of c1 and c2 have
a moderate skewness. Regarding the kurtosis, the distributions
of all coefﬁcients of G(z) and C(z) are leptokurtic. However,
analyzing Table II, it is not possible to state a clear general
pattern of an increasing/decreasing skewness or kurtosis, in
face of the growth of sample loss.

In Figure 4, it is possible to verify that, in all cases, the ICs
tend to grow with the increase of the sample loss. The same
thing occur with the standard deviations shown in Table II.
Regarding to the coefﬁcients of G(z), Figure 4 shows that the
difference between the mean and the actual value of g1, g2,
g3 and g4 also tends to raise with the increase of sample loss.
It is worth mentioning that the performance of the algorithm
when computing g3 and g4 is better then when computing
g1 and g2, regarding the means and their CIs. This behavior
results from the higher sensitivity that the output of G(z) has
to the variation of its poles than to the variations of its zeros.
It means that, in this problem, fj grows faster for errors in g3
and g4 than for errors in g1 and g2, making the BSA population
converge more accurately in dimensions g3 and g4.

In Figure 4 it is also possible to note that the accuracy
obtained with the coefﬁcients of C(z) is better than the
accuracy of the coefﬁcients of G(z), for all rates of sample
loss. The means of c1 and c2 are closer to their actual values,
with a smaller CI. In fact, the optimization process is more
effective when computing the coefﬁcients of C(z) due to its
smaller search space, that has only two dimensions instead of
the four dimensions of the G(z) problem.

As an additional metric to evaluate the performance of the
algorithm, it is computed |Eg| = |Gr−Ge| and |Ec| = |Cr−Ce|,
that synthesize the error of the estimated coefﬁcients of G(z)
and C(z), respectively, for each solution found. Gr and Ge are
vectors that contain the actual and the estimated coefﬁcients
of G(z), respectively. Similarly, Cr and Ce are vectors that
contain the actual and the estimated coefﬁcients of C(z),
respectively. The histograms of |Eg| and |Ec| are presented
in Figure 5, considering the mentioned rates of sample loss.
The histograms graphically show that |Eg| and |Ec|, which
correspond to the modulus of the error of the estimated
coefﬁcients of G(z) and C(z), respectively, tend to present
higher values as the loss of samples grows. It can also be
conﬁrmed by the increase of the standard deviation of the
coefﬁcients of G(z) and C(z) presented in Table II. However,
according with Figure 5, the mode of this errors remain close
to zero for all considered rates of sample loss.

C. Results of the Service Degradation Attacks

In this section,

there are presented the results obtained
through simulations of SD-Controlled Data Injection attacks,

performed by a MitM acting in the control link of the NCS, as
shown in Figure (3). The attacks were simulated in MATLAB,
aiming to evaluate their accuracy when planned based on the
results provided in Section VI-B, obtained by the System
Identiﬁcation attack. There were performed two sets of attack.
The ﬁrst one, aims to cause an overshoot of 50% in the
rotational speed of the motor. The second one, aims to cause a
stationary error of −10% in the rotational speed of the motor
when it is on the steady state.

In the attack aiming the overshoot, the function executed by
the attacker is M (z) = Ko. Performing a root locus analysis
considering the obtained models, the attacker adjusts Ko to
make the system underdamped, with a peak of rotational speed
50% higher than its steady state speed. The values of Ko are
adjusted considering the average of the coefﬁcients estimated
in Section III-B. Table III shows the values of Ko, estimated
considering different rates of sample loss during the System
Identiﬁcation attack, as well as the overshoots obtained with
the respective Ko in the real model. In Figure 6 it is possible
to compare the response of the system without attack, with the
response of the system with an attack aiming the overshoot of
50%. It is also possible to note that the attack to the actual
model presents, in the time domain, a response quite similar
to the attack estimated with the model obtained by the System
Identiﬁcation attack. This can be veriﬁed not only in the case
where the system is identiﬁed with 0% of sample loss, but also
in the worst considered case, i.e. with 20% of sample loss. It
is worth mentioning that all responses presented in Figure 6
converge to 1 rad/s.

In the attack where objective is to cause a stationary error
of −10% on the rotational speed of the motor, the attacker
executes (5):

M (z) =

KEss(z − 1)
z − 0.94

,

(5)

wherein KEss is adjusted based on the data obtained with
the System Identiﬁcation attack. The pole of M (z) is added
aiming to allow a stationary error in the system. The zero
of M (z) is intended to format the root locus in order to
guarantee the existence of a stable KEss that leads the system
to a stationary error of −10%. Table III shows the KEss
resultant from different rates of sample loss during the System
Identiﬁcation attack, as well as the stationary errors obtained
with the respective KEss in the real model.

According with the data presented in Table III, it is possible
to state that the SD-Controlled Data Injection attack, designed
based on the data gathered by the System Identiﬁcation attack,
is capable to modify, in an accurate way, the response of the
physical system, considering all the evaluated rates of sample
loss. In the worst case, i.e. with 20% of sample loss, it is
obtained an overshoot of 45.94% and a stationary error of
−9.8%, quite close to the desired values of 50% and −10%,
respectively. Such accuracy allows the attacker to keep his
offensive under control, leading the system to a behavior that
is predeﬁned as physically covert and capable to degrade the
service performed by the plant under attack.

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

7

0.4

0.35

0.3

0.25

1
g

0.2

0.15

0.1

0.05

0

0.55

0.5

0.45

4
g

0.4

0.35

0.3

0.25

0.2

Actual

Actual

0

5

10

20

  Loss of samples (%)
(a) g1 of G(z)

Actual

Actual

0

5

10

20

  Loss of samples (%)
(b) g2 of G(z)

0.4

0.35

0.3

0.25

2
g

0.2

0.15

0.1

0.05

0

0.18

0.175

0.17

0.165

1
c

0.16

0.155

0.15

0.145

Actual

Actual

0

5

10

20

  Loss of samples (%)
(c) g3 of G(z)

−1,6

−1,55

−1,5

−1,45

3
g

−1,4

−1,35

−1,3

−1,25

−1,2

−0,18

−0,175

−0,17

−0,165

2
c

−0,16

−0,155

−0,15

−0,145

0

5

10

20

  Loss of samples (%)
(d) g4 of G(z)

0

5

10

20

  Loss of samples (%)
(e) c1 of C(z)

0

5

10

20

  Loss of samples (%)
(f) c2 of C(z)

Figure 4. Mean, with a CI of 95%, of the estimated coefﬁcients of G(z) and C(z), in face of different rates of sample loss.

Table II
STATISTICS OF THE RESULTS OBTAINED WITH DIFFERENT RATES OF SAMPLE LOSS

Loss of
samples

0%
5%
10%
20%
Loss of
samples

Mean

Standard deviation

g1

0.32793
0.31835
0.30473
0.26963

g2

0.29652
0.29689
0.30461
0.33352

g3

-1.54121
-1.54251
-1.54110
-1.53119

g4

0.55983
0.56085
0.55925
0.54916

c1

0.16991
0.16997
0.16999
0.16989

c2

g1

g2

g3

g4

c1

c2

-0.16712
-0.16719
-0.16724
-0.16716

0.03097
0.07572
0.08781
0.14120

0.04288
0.11523
0.13483
0.22378

0.00986
0.03322
0.04076
0.08596

0.00944
0.03194
0.03922
0.08313

0.00167
0.00287
0.00397
0.00596

0.00178
0.00287
0.00399
0.00598

g1

g2

Skewness(*)
g4

g3

c1

c2

g1

g2

g3

g4

c1

c2

Kurtosis

0%
5%
10%
20%
(*) Computed in accordance with the Pearson’s 2nd Coefﬁcient of Skewness.

-1.73202
-1.41346
-1.26045
-1.71055

-0.64331
-0.42288
-0.23379
-0.40055

-1.21214
-2.34607
-2.52938
-3.24122

1.75298
1.35284
1.18018
1.68335

1.23278
1.64875
1.97711
1.75186

0.79458
0.36037
0.13377
0.37927

0.18846
0.08094
0.16833
0.21292

0.19433
0.10527
0.17123
0.21127

0.21259
0.09412
0.25041
0.25054

0.21218
0.09802
0.24811
0.24932

0.15119
0.02540
0.24361
0.23883

0.16472
0.03118
0.23429
0.24441

(a) Distribution of |Eg|

(b) Distribution of |Ec|

Figure 5. Histograms of |Eg| and |Ec| in face of different rates of sample loss

FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

8

1.5

1

0.5

)
s
/
d
a
r
(

d
e
e
p
s

l

a
n
o
i
t
a
t
o
R

Without attack
Estimated attack
Actual attack

1.5

1

0.5

)
s
/
d
a
r
(

d
e
e
p
s

l

a
n
o
i
t
a
t
o
R

Without attack
Estimated attack
Actual attack

0

0

0.2

0.4

0.6

0.8

1

0

0

0.2

0.4

0.6

0.8

1

Time (s)
(a) Attack based on the data obtained without loss of samples

Time (s)
(b) Attack based on the data obtained with 20% of sample loss

Figure 6. Response of the system to attacks planned to cause an overshoot of 50% in the rotational speed of the motor.

Table III
VALUES OF Ko, KEss AND THE RESULTS OBTAINED WITH THE ATTACKS

Ko
Overshoot in the real model
KEss
Stationary error in the real model

Sample loss in the System Identiﬁcation attack

0 %

5 %

4.0451
48.90 %
5.7471
−10%

4.0745
49.43 %
5.7803
−10%

10 %

4.0828
49.57 %
5.8140
−9.9%

20 %

3.796
45.94 %
5.8823
−9.8%

VII. CONCLUSIONS

This work proposes a physically covert attack for service
degradation, which the performance depends on the knowledge
about the model of the plant under attack and its controller.
To obtain such knowledge, it is proposed a System Identiﬁca-
tion attack, based on the BSA algorithm. The effectiveness
of the System Identiﬁcation attack is demonstrated and its
performance is statistically analyzed in face of different rates
of sample loss. The results achieved by the physically covert
attacks for service degradation, designed based on the data
gathered by the System Identiﬁcation attack, demonstrate the
high degree of accuracy that may be achieved with the joint
operation of the two attacks. In the worst case, i.e. with 20%
of sample loss during the System Identiﬁcation attack, the
attacker attained an overshoot of 45.94% and a stationary
error of −9.8%, quite close to the desired values of 50% and
−10%, respectively. In both physically covert interventions,
the accuracy of the attacks ensure that they will not evolve to
unwanted behaviors, physically perceivable.

As future work, it is encouraged the research of techniques
capable to avoid, or complicate, physically convert attacks
planned with the data obtained by System Identiﬁcation at-
tacks. In this sense, we plan to further investigate counter-
measures capable to make it difﬁcult to obtain information
about cyber-physical control systems, which is essential for
planning covert and controlled attacks.

REFERENCES

[1] Y. Tipsuwan, M.-Y. Chow, and R. Vanijjirattikhan, “An implementation
of a networked pi controller over ip network,” in Industrial Electronics
Society, 2003. IECON’03. The 29th Annual Conference of the IEEE,
vol. 3.

IEEE, 2003, pp. 2805–2810.

[2] R. A. Gupta and M.-Y. Chow, “Networked control system: overview and
research trends,” Industrial Electronics, IEEE Transactions on, vol. 57,
no. 7, pp. 2527–2535, 2010.

[3] L. Zhang, L. Xie, W. Li, and Z. Wang, “Security solutions for networked
control systems based on des algorithm and improved grey prediction
model,” International Journal of Computer Network and Information
Security, vol. 6, no. 1, p. 78, 2013.

[4] A. A. Farooqui, S. S. H. Zaidi, A. Y. Memon, and S. Qazi, “Cyber
security backdrop: A scada testbed,” in Computing, Communications and
IT Applications Conference (ComComAp), 2014 IEEE.
IEEE, 2014, pp.
98–103.

[5] M.-Y. Chow and Y. Tipsuwan, “Network-based control systems: a
tutorial,” in Industrial Electronics Society, 2001. IECON’01. The 27th
Annual Conference of the IEEE, vol. 3.
IEEE, 2001, pp. 1593–1602.
[6] M. Long, C.-H. Wu, and J. Y. Hung, “Denial of service attacks
on network-based control systems: impact and mitigation,” Industrial
Informatics, IEEE Transactions on, vol. 1, no. 2, pp. 85–96, 2005.
[7] R. Langner, “Stuxnet: Dissecting a cyberwarfare weapon,” Security &

Privacy, IEEE, vol. 9, no. 3, pp. 49–51, 2011.

[8] P. Civicioglu, “Backtracking search optimization algorithm for numerical
optimization problems,” Applied Mathematics and Computation, vol.
219, no. 15, pp. 8121–8144, 2013.

[9] A. C. Snoeren, C. Partridge, L. A. Sanchez, C. E. Jones, F. Tchakountio,
B. Schwartz, S. T. Kent, and W. T. Strayer, “Single-packet ip traceback,”
IEEE/ACM Transactions on Networking (ToN), vol. 10, no. 6, pp. 721–
734, 2002.

[10] A. Teixeira, I. Shames, H. Sandberg, and K. H. Johansson, “A se-
cure control framework for resource-limited adversaries,” Automatica,
vol. 51, pp. 135–148, 2015.

[11] R. Smith, “A decoupled feedback structure for covertly appropriating
networked control systems,” in Proceedings of the 18th IFAC World
Congress 2011, vol. 18, no. 1.

IFAC-PapersOnLine, 2011.

[12] R. S. Smith, “Covert misappropriation of networked control systems:
Presenting a feedback structure,” Control Systems, IEEE, vol. 35, no. 1,
pp. 82–92, 2015.

[13] A. Hussain, J. Heidemann, and C. Papadopoulos, “A framework for
classifying denial of service attacks,” in Proceedings of
the 2003
conference on Applications, technologies, architectures, and protocols
for computer communications. ACM, 2003, pp. 99–110.

[14] C. Ramos, Z. Vale, and L. Faria, “Cyber-physical intelligence in the con-
text of power systems,” in Future Generation Information Technology.
Springer, 2011, pp. 19–29.

[15] S. Khatri, P. Sharma, P. Chaudhary, and A. Bijalwan, “A taxonomy
of physical layer attacks in manet,” International Journal of Computer
Applications, vol. 117, no. 22, 2015.

[16] Y. Zou and G. Wang, “Intercept behavior analysis of industrial wireless
sensor networks in the presence of eavesdropping attack,” IEEE Trans-
actions on Industrial Informatics, vol. 12, no. 2, pp. 780–787, 2016.

[17] A. O. de S´a, N. Nedjah, and L. de Macedo Mourelle, “Distributed
efﬁcient localization in swarm robotic systems using swarm intelligence
algorithms,” Neurocomputing, vol. 172, pp. 322–336, 2016.

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
FINAL VERSION OF THIS PAPER AVAILABLE AT IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS (HTTP://DX.DOI.ORG/10.1109/TII.2017.2676005)

9

[18] W. Stallings, Cryptography and network security: principles and prac-

tices. Pearson Education India, 2006.

[19] M. El-Sharkawi and C. Huang, “Variable structure tracking of dc
motor for high performance applications,” Energy Conversion, IEEE
Transactions on, vol. 4, no. 4, pp. 643–650, 1989.

[20] T. Tran, Q. P. Ha, and H. T. Nguyen, “Robust non-overshoot

time
responses using cascade sliding mode-pid control,” Journal of Advanced
Computational Intelligence and Intelligent Informatics, 2007.

[21] H. Hwang, G. Jung, K. Sohn, and S. Park, “A study on mitm (man in
the middle) vulnerability in wireless network using 802.1 x and eap,” in
Information Science and Security, 2008. ICISS. International Conference
on.

IEEE, 2008, pp. 164–170.

