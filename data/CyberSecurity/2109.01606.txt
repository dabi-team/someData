This paper is a preprint; it has been accepted for publication in 2020 IEEE World Congress on Services 
(SERVICES), 18-23 Oct. 2020, Beijing, China. 

IEEE copyright notice  

© 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all 
other uses, in any current or future media, including reprinting/republishing this material for advertising 
or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or 
reuse of any copyrighted component of this work in other works.  

 
 
Privacy Issues in Voice Assistant Ecosystems

Georgios Germanos∗, Dimitris Kavallieros∗†, Nicholas Kolokotronis∗, and Nikolaos Georgiou†
∗University of Peloponnese, 22131 Tripolis, Greece
Email: {germanos, d.kavallieros, nkolok}@uop.gr
†Center for Security Studies (KEMEA), 10177 Athens, Greece
Email: {d.kavallieros, n.georgiou}@kemea-research.gr

Abstract—Voice assistants have become quite popular lately
while in parallel they are an important part of smart-home
systems. Through their voice assistants, users can perform var-
ious tasks, control other devices and enjoy third party services.
The assistants are part of a wider “ecosystem”. Their function
relies on the users’ voice commands, received through original
voice assistant devices or companion applications for smart-
phones and tablets, which are then sent through the internet to
the vendor’s cloud services and are translated into commands.
These commands are then transferred to other applications and
services. As this huge volume of data, and mainly personal
data of the user, moves around the voice assistant ecosystem,
there are several places where personal data is temporarily or
permanently stored and thus it is easy for a cyber attacker to
tamper with this data, bringing forward major privacy issues. In
our work we present the types and location of such personal data
artifacts within the ecosystems of three popular voice assistants,
after having set up our own testbed, and using IoT forensic
procedures. Our privacy evaluation includes the companion apps
of the assistants, as we also compare the permissions they require
before their installation on an Android device.

Index Terms—Forensics, Internet of things, Privacy, Security,

Voice assistants.

I. INTRODUCTION

As the Internet of Things is becoming more and more preva-
lent in our day-to-day life, there is a signiﬁcant increase in the
use of services and devices, the so-called voice assistants, also
known as smart speakers or intelligent virtual assistants. In
January 2019, more than 66 million smart voice assistants were
installed in houses across the United States. The adoption rate
in the country was at about 25%, and by 2022, it’s expected
to reach 55% [1].

Practically, a smart speaker is a type of wireless speaker,
that comes with an integrated voice-activated digital assistant.
Voice assistants perform tasks on behalf of a user: they make
phone calls, answer general or speciﬁc questions (e.g. “what
time does the next ﬂight to New York depart?”), customize a
user’s daily schedule, set reminders, make product purchases
on behalf of the user and even control IoT enabled devices
(e.g. lights and locks) [2].

Other devices, mainly mobile phones and personal comput-
ers, may also function as voice assistants, through respective
applications.

To achieve all the above mentioned tasks, it is necessary
in order
for them to become part of a wider ecosystem,
to interact with the provider’s cloud services and various
other devices and applications. During their interaction, voice
assistants exchange a large amount of data. Much of this data
is considered personal information related to the user(s) of the
ecosystem, which means that privacy issues arise.

In this paper, we focus on privacy issues, by examining the
types and location of data and personal information that reside
within a voice assistant ecosystem, while in parallel presenting
existing IoT forensic techniques - which can also be used by
a security professional or an investigator to have access to
valuable evidence related to cyber attacks. Additionally, we
compare the permissions required by the companion applica-
tions, before their installation on an Android mobile device, to
verify if they are indeed necessary for the proper functioning
of the voice assistant.

To verify the ﬁndings of our research, we built a testbed
where we simulated the functioning of three very well-
known assistants, Amazon’s Alexa, Google’s Assistant and
Microsoft’s Cortana.

The rest of the paper is organized as follows: In Section
II we provide the background on voice assistant ecosystems,
legal and privacy issues as well as Internet of Things forensic
methodologies. Section III formalizes the methodology we fol-
lowed to setup our testbed and the processes for the extraction
and analysis of data. Section IV presents in detail our ﬁndings
and an analysis on them, while Section V summarizes our
work and outlines future work directions.

II. BACKGROUND AND RELATED WORK

In this section we ﬁrstly describe a typical voice assistant
ecosystem. Secondly, we discuss legal and privacy issues
related to voice assistants. Last, we present methodologies
that have been suggested for Internet of Things forensics
procedures and techniques.

A. Voice assistants

This project has received funding from the European Union’s
Horizon 2020 research and innovation programme under grant
agreement no. 786698. The work reﬂects only the authors’ view
and the Agency is not responsible for any use that may be made of the
information it contains.

Voice assistants can be integrated into devices speciﬁcally
designed for this purpose or work as an application on a smart
phone, tablet or computer. A typical example of a widespread
voice assistant is Amazon’s Alexa. Alexa is the digital assistant

provider prepares the response - result of its tasks - to the
user, which is ﬁnally delivered to the user through the voice
assistant, again in the form of audio.

This practically means that the user’s data move around and
may be located in the voice assistant device (hardware), the
companion applications (client), the company’s cloud (cloud)
and the networks used for communication (network) [4].

B. Legal and privacy issues

Within the European Union, the General Data Protection
Regulation entered into force on May 25th 2018 [5]. Its
purpose is to protect the data of the citizens of EU countries
that are processed by individual or companies anywhere in
the world, as well as any personal data that are processed by
individuals or companies located within the territory of the
EU. Among others, one of the priorities of GDPR is ensuring
the respect and protection of privacy.

According to the GDPR, personal data means any infor-
mation relating to an identiﬁed or identiﬁable natural person.
Voice is also considered personal data and speciﬁcally bio-
metric data, since it is related to the physical characteristics
of a natural person, and can be used to identify individual.
Processing means any operation or set of operations which is
performed on personal data or on sets of personal data, such
as collection, recording, organisation, structuring, storage,
adaptation or alteration, retrieval, consultation, use and more.
It is clear that voice assistants do exactly the above men-
tioned processes, which means that, at least for voice assistants
used by EU citizens or for processes of data that take place
within the EU, the GDPR rules have to be respected. There
are seven key principles set by the GDPR:
• Lawfulness, fairness and transparency
• Purpose limitation
• Data minimization
• Accuracy
• Storage limitation
• Integrity and conﬁdentiality (security)
• Accountability
Article 5 of the GDPR requires that processing will be
performed in a manner that ensures appropriate security of
the personal data, including protection against unauthorised
or unlawful processing and against accidental loss, destruc-
tion or damage, using appropriate technical or organisational
measures.

An important principle of GDPR is “privacy by design”, as
described in article 25. The controller must, both at the time
of the determination of the means for processing and at the
time of the processing itself, implement appropriate technical
and organisational measures, which are designed to implement
data-protection principles, in an effective manner. In parallel,
the controller should integrate the necessary safeguards into
the processing in order to meet the requirements of the GDPR
the rights of data subjects. For the controller
and protect
to implement
the appropriate technical and organizational
measures, he should take into account the state of the art,
the cost of implementation and the nature, scope, context

Fig. 1: A typical ecosystem of a voice assistant

that comes with the devices such as Echo, Echo Dot, Echo
Show [3]. Other well-known voice assistants are Google’s
Assistant, and Microsoft’s Cortana.

A typical ecosystem of a voice assistant is illustrated in
Fig. 1.The user interacts directly, using his voice, with the
speciﬁcally designed for this reason device of the company
(e.g. Amazon Echo, Google Home, etc.), or through the
companion app, which he has installed on one of his devices
(mainly smart phone and tablet, but also laptop or desktop).
His request
to the company’s
cloud service, where further processing takes place. Then, the
user’s commands reach other devices and applications. The
user ﬁnally receives the answer to his request through a voice
message. In this way, the user can, for example, turn the lights
of his house on, listen to his favorite music or order a taxi.

through a network,

is sent,

More in depth, the user interacts directly with the system
using his voice. The device is enabled after it listens to the
deﬁned “wake up” word. It is designed to continuously listen
to the sounds of the environment and start recording the
user’s voice (and command) only after the user speaks the
“wake up” word. The ﬁle with the user’s recorded command
is sent,
to the cloud service of the
provider, where extensive voice processing takes place, the
voice is transformed into text and commands are identiﬁed.
Depending on the commands, the provider either makes use
of its own services to execute the task, or forwards it to other
providers. This means that other smart IoT devices may receive
commands from the provider. Then, back in the cloud, the

through the internet,

Voice	assistant	device,	companion	apps	and	web	UIThird	party	apps	and	devices																						Service	on	company's	cloudOther	cloudsGateway	agentIoT	home	devicesInternetand purposes of processing as well as the risks of varying
likelihood and severity for rights and freedoms of natural
persons posed by the processing.

C. IoT forensics

The issue of digital forensics in voice assistants has attracted
the attention of many researchers as it is a major challenge.
As a rule, scientiﬁc research focuses on studying traditional
devices, such as hard drives or cell phones. To date, there is
no serious need for digital forensics of voice search devices.
However, it is almost certain that these devices, as part of
the Internet of Things, will gain the attraction either Law
Enforcement Authorities or specialists in the ﬁeld of digital
forensics. The digital examiner will be asked to study the
function of his voice assistant, his memory, his connections
and more. Due to the speciﬁcity of each voice assistant device,
each one requires a specialized approach [6], [7].

To date, there is no software or tool speciﬁcally tailored to
conduct forensic investigations on voice assistants. Each case
is considered individually, however some IoT device testing
models have been suggested that could be applied to voice
assistants as well. It is certain that the incorporation of the
’forensics by design’ principle during the design phase of a
voice assistant would greatly solve the research question on
these devices.

There are a few methodologies that have been proposed for
IoT forensics procedures and techniques. Zawoad et al. [8]
proposed a Forensics-aware IoT (FAIoT) model for supporting
reliable forensics investigations in the IoT environment. They
identiﬁed IoT forensics as a combination of three digital
forensics schemes, on the basis of the IoT ecosystem: device
level forensics, network forensics, and cloud forensics. Their
model includes a centralized trusted evidence repository to
facilitate the process of evidence collection and analysis. At
the same time, reliability of the evidence is also achieved,
thanks to the application of the secure logging scheme.

Perumal et al. [9] proposed a novel model, which included
authorization, planning, chain of custody, analysis and storage,
and was based on triage model and 1-2-3 zone model for
volatile based data preservation.

In [10], Kebande et al. proposed a generic Digital Forensic
Investigation Framework for IoT (DFIF-IoT), which was ex-
pected to support future IoT investigative capabilities. The pro-
posed framework would comply with the ISO/IEC 27043:2015
which is an international standard for information technology,
security techniques, incident investigation principles, and pro-
cesses.

A procedure for digital evidence acquisition model for IoT
forensic was provided as a theoretical framework by Harbawi
et al. in [11]. One aspect of the procedure was the deployment
of Last-on-Scene algorithm that would improve traceability
and reduce the overhead as well as digital forensic analysis
complications. Then, a revision was made for IoT forensic
in order to ensure the usability of the proposed enhanced
acquisition procedure. Last, a management platform concept
was also proposed.

Meffert et al. presented a primary account for a general
framework and practical approach, called “Forensic State Ac-
quisition from Internet of Things (FSAIoT)” [12]. The method
provided a general solution towards device state acquisition.
It would not physically acquire the memory of the devices
themselves. FSAIoT consisted of a centralized Forensic State
Acquisition Controller (FSAC) employed in three state collec-
tion modes: controller to IoT device, controller to cloud, and
controller to controller.

In their work [13], Dorai et al. examined the forensic
artifacts produced by Nest devices, and speciﬁcally the log-
ical backup structure of an iPhone used to control
these
devices. For this reason, they built an open-source forensic
tool, the “Forensic Evidence Acquisition and Analysis System
(FEAAS)”,
that would consolidate evidentiary data into a
readable report that could infer user events.

Goudbeek et al. proposed a forensic investigation frame-
work for the smart home environment, which could also be
used as a quick reference guide for digital forensic inves-
tigators working on future home automation systems. The
framework included seven phases, during which a range of
artefacts of forensic relevance could be recovered to inform
forensic investigations [14]. The same framework has been
used by Tristan et al. to perform forensic investigation in smart
speakers [15].

III. METHODOLOGY

In order to examine the privacy issue more in depth, we
set up our own testbed for three different voice assistants.
Furthermore, a forensic analysis took place in order to identify
any information related to the identity or the activities of the
user.

A. Testbed setup

As a means to have a better understanding of the three major
voice assistants ecosystems, we created our own testbed, in a
home environment, which we used for a period of almost 8
weeks, from April 1st 2020 to May 31st 2020. Our testbed is
presented in Fig. 2.

More speciﬁcally, we used a Xiaomi Redmi Note 6 Pro
mobile phone, with Android 9 installed on it, a Lenovo Yoga
730 laptop, with Windows 10 installed on it, as well as a
Raspberry Pi 4, with Raspberry Pi OS (ex. Raspbian) installed
on it, to simulate the functioning of voice assistant devices.
These devices had wireless internet access through a typical
home router device (ZTE H108N). The mobile phone had also
access to the internet through 4G connection.

We installed the companion mobile apps “Amazon Alexa”,
“Google Assistant – Get Things Done, Hands-free”, as well
as “Microsoft Cortana – Digital Assistant” that were available
on Play Store. We installed the applications for Amazon’s
Alexa and Microsoft’s Cortana on the laptop. We also installed
Amazon’s Alexa and Google’s Assistant on the Raspberry
Pi device [16], [17]. For the analysis of the storage of the
Raspberry Pi, we primarily used the FTK Imager while, for

Fig. 2: The testbed used for the evaluation of the voice assistants ecosystems’ privacy

the clients, methods for mobile and computer forensics were
used.

To better understand the location of the artifacts of Table I
and II, we use A for Alexa, G for Assistant and C for Cortana
and 1 for the mobile device, 2 for the laptop and 3 for the
Raspberry Pi. A1 in Fig. 2 refers to the artifacts related to
Alexa, found on the mobile device, A2 refers to the artifacts
related to Alexa, found on the laptop, etc.

B. Testing process

With a view to accurately test the proper functioning of the
ecosystems, we created three different accounts (proﬁles), one
for each ecosystem, through their respective web interface.

In practice, we interact, using our voice, with each ecosys-
tem through the mobile phone, the laptop and the Raspberry
Pi (end device): each of our oral questions – requests travels
through the end device to the internet and then to the cloud of
each company, where further processing takes place. We then
receive, in voice format, the answer to our request through the
end device.

The testing included various commands such as, creation
of To-do list, open applications, listen to music, add items to
the calendar, identify trafﬁc conditions between two locations,
create shopping list, open images and videos stored in the end
device, etc.

At the end of the testing, we performed information gath-
ering and analysis in order to identify possible artifacts cor-
related with the user’s privacy. The main activities employed
for the identiﬁcation of information stored in the devices of
our testbed were, (a) image acquisition and analysis of the
Raspberry Pi storage, (b) manual search for the ﬁle path and
the location of the folders the voice assistants store data (in
the laptop and android), (c) usage of APIs for information
retrieval from the respective cloud and (c) literature review.

The image of the Raspberry Pi storage was acquired using
the FTK Imager, while for the analysis the Forensic Toolkit
(FTK) was used.

It is important to highlight that, in order to retrieve data
through the APIs, we assumed that we already had access to
the user’s account.

ZTE H108N routerRedmi Note 6 ProAndroid9Lenovo Yoga 730Windows 10Raspberry Pi 4Raspberry Pi OS(ex Raspbian)“when is sunrise?”A1 | G1 | C1A2 | C2A3 | G3wake detectionásignal processingon device processing audiocloud processing device“sunrise in”“Tripolis…”userautomatic speech recognitionspeech to textnatural language understandingintent: get sunriseskilllocation: Tripolistext to speechTABLE I: Location of voice assistant artifacts in our testbed

Location
User registration
0: Cloud

1: Mobile

2: Laptop

3: Raspberry Pi

A: Alexa (Amazon)
alexa.amazon.com
https://www.amazon.com/hz/mycd/
digital-console/privacysettings
/Android/data/com.amazon.dee.app

\(cid:104)User(cid:105)\AppData\Local\Packages\
57540AMZNMobileLLC.AmazonAl
exa 22t9g3sebte08
/root/home/pi/db/...

G: Assistant (Google)
assistant.google.com
https://myactivity.google.com/item

/Android/data/com.google.android.
apps.chromecast.app

/root/.conﬁg/googlesamples-assist
ant/device conﬁg.json

C: Cortana (Microsoft)
www.microsoft.com/en-us/cortana
https://account.microsoft.com/privacy/
activity-history
/Android/data/com.microsoft.cortana/
ﬁles
\(cid:104)User(cid:105)\AppData\Local\Packages\
Microsoft.Windows.Cortana cw5n1h
2txyewy

TABLE II: User’s artifacts found in various ecosystems

Artifact
Access information
Activities
Calendar details
Contacts
Emails
History: activities
History: audio input
History: browsing
Interests
Location data
Multimedia
Personal details
Systems connected

A: Alexa (Amazon)

yes (to-do list, shopping list)
yes (alarms, reminders)
yes
yes
yes
yes (voice commands)
yes
yes (restaurants, sports, trafﬁc)
yes
yes (photos via Amazon photos)
yes (name, birthday, gender)
yes (apps, devices, services)

G: Assistant (Google)
yes (password, phone number)
yes (ﬁles on Google drive)
yes
yes
yes
yes (searches, viewed videos/ads)

yes

yes
yes (photos, videos)
yes (name, birthday, gender)
yes (apps, devices, services)

C: Cortana (Microsoft)

yes (photo albums, apps installed in devices)
yes
yes (incl. relationships if set up)
yes
yes (communications from messages, apps)
yes (voice commands)
yes
yes (sports, news, etc. from apps, services)
yes (also linked to users’ requests)
yes (music, books, podcasts)
yes (name, nickname, age, family members)
yes (apps, devices, services in home app)

IV. FINDINGS AND ANALYSIS

In this section we present the ﬁndings of our experiments
within the testbed and at the same time an analysis from a
privacy perspective.

A. Personal data and other information

In their ofﬁcial websites, Amazon, Google and Microsoft

explain the types of data that they process [18], [19], [20].

We were able to locate and identify various types of
artifacts, related to our activities. The location of the artifacts
is presented in Table I.

The manual search on the A2 and C2 revealed the locations
where Alexa and Cortana, respectively, store information in a
laptop device. For example, in Cortana the search history of
the user, applications that he had used and voice command
history, as well as the respective audio ﬁles were identiﬁed
[21], [22].

It is important to highlight that the ﬁle path presented in
Table I regarding the mobile device can only be found if the
mobile device is rooted. The mobile used for A1/G1/C1 was
not rooted thus, no manual search could be conducted.

Using the unofﬁcial API presented in [23], we could identify
plethora of personal information, including locations, the email
of the account and photos, among other artifacts. Regarding
Alexa we found very limited amount of information.

As it was presented in the previous section, forensic analysis
was conducted in A3 and G3. The main objective of the
analysis was to identify the presence/absence of artifacts
related to either Alexa or Assistant (Google). The following
artifacts were identiﬁed regarding Alexa:

a) device serial number,
b) the client ID,
c) the product ID,
d) client ID name,
e) proﬁle ID
f) name of the user
g) secret of the user

Speciﬁcally, artifacts (d)–(g) were identiﬁed in the cache
memory. Fig. 3a and Fig. 3b are depicting this information.
Regarding Google Assistant, we were able to identify the
following artifacts:

a) client secret, and
b) client ID.

These ﬁnding are presented in Fig. 3c.

A summary of these artifacts is presented in Table II. More
in depth, we were able to identify access information (e.g.
password, phone number), various user activities (e.g. to-do
list, shopping list, photo albums, apps installed on devices),
details related to calendars (e.g. alarms, reminders), contacts,
email accounts, history of user’s activities (e.g. searches,
viewed videos/ads, communications from messages, apps,
browsing, audio inputs),
interests (e.g. restaurants, sports,
trafﬁc, news), location data, multimedia ﬁles (photos, videos,
music, books, podcasts), personal details (such as name,
birthday, gender, nickname, age) and systems connected (apps,
devices, services).

B. Applications’ permissions

In Table III we present the permissions that each voice as-
sistant application (Alexa, Assistant, Cortana) requests, before

(a) The device serial number and product ID used by Amazon Alexa in the testbed

(b) The client ID, proﬁle ID, user name, client secret, client name used by Amazon Alexa in the testbed

(c) The client ID and secret used by Google Assistant in the testbed

Fig. 3: Examples of artifacts being identiﬁed during the analysis of the Raspberry Pi images with the Forensic Toolkit (FTK)

its installation on Android devices.

By exploiting known or zero-day vulnerabilities of these
features, someone could gain unauthorized access to the de-
vice and its data. The permissions required by the assistant
applications are numerous.

Within the Android environment, permissions characterized
as “dangerous” require user agreement. How Android asks for
dangerous permissions depends on the application version and
the system version targeted by the application [25].

The last column in Table III presents if the permission is
among the dangerous ones (if the permission is dangerous, D
is present).

The assistants need permissions to use various features of
the mobile device, nevertheless, Cortana’s list of permissions
looks extensive. At the same time, it should be noted that
Google’s Assistant permissions look smaller in number, but
this is due to the fact
there are usually many other
Google’s applications installed on Android devices [24]. This
means that, most probably, Google already has the ”missing”
permissions of the Table.

that

In terms of statistics, Alexa asks for 17, Assistant (Google)
asks for 6 and Cortana asks for 22 dangerous permissions.
This does not necessarily mean that Assistant gives importance
in user’s privacy, as we already mentioned that many of the
Assistant’s permissions which are not present in the Table have
already been provided to Google through other applications.

Table IV below presents the artifacts and information found
in each assistant, on the different “devices” as depicted on
Table I, namely, the cloud of each assistant, the Raspberry Pi
installation – A3, G3 (only for Alexa and Assistant) and the
respective clients – A1, A2, G1, G3, C1 and C3.

It also provides, in the case of Android clients, a correlation
among the identiﬁed artifacts and the permissions depicted on
Table III. This list is not an exhaustive as it is based on the
setup and testing described in Section III.

V. CONCLUSIONS AND FUTURE WORK

In our work we examined privacy issues in voice assistant
ecosystems. After describing a typical voice assistant ecosys-
tem, we presented the existing legislation on personal data pro-
cessing within the EU and its privacy aspects. We then made
a literature review of existing IoT forensics methodologies.

Our main goal was to identify the types and location
of data that reside within a voice assistant ecosystem. For
this reason, we built our own testbed where we simulated
the functioning of Amazon’s Alexa, Google’s Assistant and
Microsoft’s Cortana voice assistants.

We also compared the permissions required by the voice
assistant companion applications before their installation on
an Android device and their relation to privacy.

In the future, our intention is to examine ways of enhancing
privacy in voice assistant ecosystems, as well as further study

TABLE III: The permissions requested by voice assistants’ mobile application during their installation on an Android device
and dangerous ones [25]. The notation ‘A’, ‘G’ and ‘C’ denotes Alexa (Amazon), Assistant (Google), and Cortana (Microsoft)
respectively. Dangerous permissions are indicated by the letter ‘D’ in the last column.

ID

1.1
1.2
1.3
1.4
1.5

2.1
2.2
2.3

Permission
Identity
Read your own contact card
Find accounts on device
Create accounts and set passwords
Add or remove accounts
Use accounts on the device
Wi-Fi connection information
View Wi-Fi connections
Connect and disconnect from Wi-Fi
Allow Wi-Fi Multicast reception
Photos, media, ﬁles

5.1

4.1
4.2

3.1 Modify/delete photos, media, ﬁles
Read photos, media, ﬁles
3.2
Microphone
Record audio
Change audio settings
Device ID and call information
Read phone status and identity
Camera
Take pictures and videos
Contacts
Find accounts on device
Read your contacts
Phone
Directly call phone
Read phone status and identity
Reroute outgoing calls
Storage, media ﬁles

8.1
8.2
8.3

7.1
7.2

6.1

9.1 Modify/delete USB storage contents
Read USB storage contents
9.2
Location-based services

A

G

C

×

× × × D
×
×
× × ×
×
×

× × ×
× × ×
×

×
×

× D
× D

× × × D
× × ×

×

× D

× × × D

× × × D
× D
×

× × × D
× D
×
× D

×
×

× D
× D

10.1 Precise location (GPS, network-based)
10.2 Approximate location (network-based)
10.3 Additional location provider commands

× × × D
× D
×
×

ID

11.1
11.2
11.3
11.4

12.1
12.2
12.3

13.1

Permission
SMS and MMS
Read text messages
Receive text messages
Send text messages
Edit text messages
Calendar
Read events and private information
Add/modify calendar events
Send emails without users’ knowledge
Device and app history
Retrieve running apps
Other
Receive data from Internet
Run at startup
Full network access
Control vibration
Prevent device from sleeping
Pair with Bluetooth devices
Change network connectivity
View network connections
Access Bluetooth settings
Read Google service conﬁguration
Hot word detection
Download ﬁles without notiﬁcation
Full license to interact across users
Update component usage statistics
Read home settings and shortcuts
Toggle sync on and off
Install/uninstall shortcuts
Read sync settings

14.1
14.2
14.3
14.4
14.5
14.6
14.7
14.8
14.9
14.10
14.11
14.12
14.13
14.14
14.15
14.16
14.17
14.18
14.19 Modify system settings
14.20
14.21
14.22

Disable your screen lock
Set an alarm
Draw over other apps

A

×
×
×

G

C

× D
× D
× D
×

× D
× D
× D

×

× × ×
× × ×
× × ×
×
×
× × ×
× × ×
× × ×
× × ×
× × ×
×

×
×
× D
×
×
×
×
×
×
×
×
×

attacks on voice assistants and formulate a novel forensic
methodology for artifacts in voice assistant ecosystems.

Furthermore, part of our future work is to tamper with
original assistant devices (e.g. use Alexa instead of Raspberry
Pi), connected to multiple smart devices (e.g. smart lamps).
Moreover, we intend to use rooted mobiles, mobile mirroring
for un-rooted devices and emulator for different types of OS of
mobiles. This approach will allow us to investigate for stored
artifacts in different types of setups and compare them while at
the same time we will be able to compare the results between
the different testbeds.

REFERENCES

[1] The Fight for Smart Speaker Market Share. [Online] Available at: https://

www.visualcapitalist.com/smart-speaker-market-share-ﬁght/

[2] Hoy, Matthew B. “Alexa, Siri, Cortana, and more: an introduction to
voice assistants.” Medical reference services quarterly 37.1 (2018): 81-
88.

[3] Amazon Echo & Alexa Devices. [Online] Available at: https://www.ama
zon.com/Amazon-Echo-And-Alexa-Devices/b?&node=9818047011
[4] Chung, Hyunji, et al. “Alexa, can I trust you?.” Computer 50.9 (2017):

100-104.

[5] Regulation (EU) 2016/679 of the European Parliament and of the
Council of 27 April 2016 on the protection of natural persons with regard
to the processing of personal data and on the free movement of such data,

and repealing Directive 95/46/EC (General Data Protection Regulation).
[Online] Available at: https://eur-lex.europa.eu/eli/reg/2016/679/oj
[6] Yaqoob, Ibrar, et al. “Internet of things forensics: Recent advances,
taxonomy, requirements, and open challenges.” Future Generation Com-
puter Systems 92 (2019): 265-275.

[7] MacDermott, Aine, Thar Baker, and Qi Shi. “Iot forensics: Challenges
for the ioa era.” 2018 9th IFIP International Conference on New
Technologies, Mobility and Security (NTMS). IEEE, 2018.

[8] Zawoad, Shams, and Ragib Hasan. “Faiot: Towards building a forensics
aware eco system for the internet of things.” 2015 IEEE International
Conference on Services Computing. IEEE, 2015.

[9] Perumal, Sundresan, Norita Md Norwawi, and Valliappan Raman. “In-
ternet of Things (IoT) digital forensic investigation model: Top-down
forensic approach methodology.” 2015 Fifth International Conference on
Digital Information Processing and Communications (ICDIPC). IEEE,
2015.

[10] Kebande, Victor R., and Indrakshi Ray. “A generic digital forensic
investigation framework for internet of things (iot).” 2016 IEEE 4th
International Conference on Future Internet of Things and Cloud (Fi-
Cloud). IEEE, 2016.

[11] Harbawi, Malek, and Asaf Varol. “An improved digital evidence ac-
quisition model for the Internet of Things forensic I: A theoretical
framework.” 2017 5th International Symposium on Digital Forensic and
Security (ISDFS). IEEE, 2017.

[12] Meffert, Christopher, et al. “Forensic State Acquisition from Internet of
Things (FSAIoT): A general framework and practical approach for IoT
forensics through IoT device state acquisition.” Proceedings of the 12th
International Conference on Availability, Reliability and Security. ACM,
2017.

TABLE IV: Correlation between the identiﬁed artifacts and the permissions depicted on Table III

Artifact
Access information
Activities
Calendar details
Contacts
Emails
History: activities
History: audio input
History: browsing
Interests
Location data
Multimedia
Personal details
Systems connected

A: Alexa (Amazon)

3.x, 9.x
12.x, 14.21
7.x
14.1
3.x
3.x, 4.x, 9.x
14.1
14.1
10.x, 14.1
3.x, 9.x
1.1
2.x, 13.x, 14.1, 14.6–14.8

G: Assistant (Google)
1.x
3.x, 9.x
12.x
7.x
14.1
3.x, 9.x

14.1

10.x, 14.1
3.x, 9.x
1.1
2.x, 13.x, 14.1, 14.6–14.8

C: Cortana (Microsoft)

3.x, 13.x, 14.19
12.x
7.x
14.1
3.x, 11.x, 14.1
3.x, 4.x, 9.x
14.1
14.1
10.x, 14.1
3.x, 9.x
1.1–1.2, 7.x
1.2, 2.x, 13.x, 14.1, 14.6–14.8, 14.15

[13] Dorai, Gokila, Shiva Houshmand, and Ibrahim Baggili. “I know what
you did last summer: your smart home Internet of Things and your
iPhone forensically ratting you out.” Proceedings of the 13th Interna-
tional Conference on Availability, Reliability and Security. ACM, 2018.
[14] Goudbeek, Arnoud, Kim-Kwang Raymond Choo, and Nhien-An Le-
Khac. “A forensic investigation framework for smart home environ-
ment.” 2018 17th IEEE International Conference On Trust, Security
And Privacy In Computing And Communications/12th IEEE Inter-
national Conference On Big Data Science And Engineering (Trust-
Com/BigDataSE). IEEE, 2018.

[15] Tristan, Sean, Shally Sharma, and Robert Gonzalez. “Alexa/Google
Home Forensics.” Digital Forensic Education. Springer, Cham, 2020.
101-121.

[16] Set Up Raspberry Pi. [Online] Available at: https://developer.amazon.co
m/en-US/docs/alexa/alexa-voice-service/set-up-raspberry-pi.html

[17] Add the Google Assistant

to your experimental projects. [Online]

alexaprivacysettings

[19] Making it easy to understand what data we collect and why, Google.

[Online] Available at: https://safety.google/privacy/data/

[20] Cortana and privacy. [Online] Available at: https://support.microsoft.com

/en-us/help/4468233/cortana-and-privacy-microsoft-privacy

[21] Singh, Bhupendra, and Upasna Singh. “A forensic insight into Windows
10 Cortana search.” Computers & Security 66 (2017): 142-154.
[22] Domingues, Patricio, and Miguel Frade. “Digital forensic artifacts of the
cortana device search cache on Windows 10 Desktop.” 2016 11th Inter-
national Conference on Availability, Reliability and Security (ARES).
IEEE, 2016.

[23] Chung, H., Park, J., & Lee, S. (2017). Digital forensic approaches for

Amazon Alexa ecosystem. Digital Investigation, 22, S15-S25.

[24] The best of Google, right on your devices. [Online] Available at: https://

www.android.com/gms/

Available at: https://developers.google.com/assistant/sdk

[25] Android permissions, API level 30. [Online] Available at: https://develop

[18] Alexa Privacy Settings. [Online] Available at: https://www.amazon.com/

er.android.com/reference/android/Manifest.permission

