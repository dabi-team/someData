8
1
0
2

n
u
J

7
2

]

O
L
.
s
c
[

1
v
3
6
4
0
1
.
6
0
8
1
:
v
i
X
r
a

Towards a formal notion of impact metric for
cyber-physical attacks (full version)⋆

Ruggero Lanotte1, Massimo Merro2, and Simone Tini1

1 Dipartimento di Scienza e Alta Tecnologia, Universit`a dell’Insubria, Como, Italy
{ruggero.lanotte,simone.tini}@uninsubria.it
2 Dipartimento di Informatica, Universit`a degli Studi di Verona, Verona, Italy
massimo.merro@univr.it

Abstract. Industrial facilities and critical infrastructures are transform-
ing into “smart” environments that dynamically adapt to external events.
The result is an ecosystem of heterogeneous physical and cyber compo-
nents integrated in cyber-physical systems which are more and more
exposed to cyber-physical attacks, i.e., security breaches in cyberspace
that adversely aﬀect the physical processes at the core of the systems.
We provide a formal compositional metric to estimate the impact of
cyber-physical attacks targeting sensor devices of IoT systems formalised
in a simple extension of Hennessy and Regan’s Timed Process Language.
Our impact metric relies on a discrete-time generalisation of Desharnais
et al.’s weak bisimulation metric for concurrent systems. We show the ad-
equacy of our deﬁnition on two diﬀerent attacks on a simple surveillance
system.

1

Introduction

The Internet of Things (IoT) is heavily aﬀecting our daily lives in many domains,
ranging from tiny wearable devices to large industrial systems with thousands
of heterogeneous cyber and physical components that interact with each other.
Cyber-Physical Systems (CPSs) are integrations of networking and distributed
computing systems with physical processes, where feedback loops allow the latter
to aﬀect the computations of the former and vice versa. Historically, CPSs re-
lied on proprietary technologies and were implemented as stand-alone networks
in physically protected locations. However, the growing connectivity and inte-
gration of these systems has triggered a dramatic increase in the number of
cyber-physical attacks [26], i.e., security breaches in cyberspace that adversely
aﬀect the physical processes, e.g., manipulating sensor readings and, in general,
inﬂuencing physical processes to bring the system into a state desired by the at-
tacker.

Cyber-physical attacks are complex and challenging as they usually cross
the boundary between cyberspace and the physical world, possibly more than

⋆

An extended abstract will appear in the Proc. of the 14th International Conference
on integrated Formal Methods (iFM 2018), 5th-7th September 2018, Maynooth Uni-
versity, Ireland, and published in a volume of Lecture Notes in Computer Science.

 
 
 
 
 
 
once [14]. Some notorious examples are: (i) the Stuxnet worm, which repro-
grammed PLCs of nuclear centrifuges in Iran [9], (ii) the attack on a sewage
treatment facility in Queensland, Australia, which manipulated the SCADA sys-
tem to release raw sewage into local rivers [34], or the (iii) the recent BlackEnergy
cyber-attack on the Ukrainian power grid, again compromising the SCADA sys-
tem [18].

The points in common of these systems is that they are all safety critical
and failures may cause catastrophic consequences. Thus, the concern for conse-
quences at the physical level puts CPS security apart from standard IT security.
Timing is particularly relevant in CPS security because the physical state
of a system changes continuously over time and, as the system evolves in time,
some states might be more vulnerable to attacks than others [20]. For example,
an attack launched when the target state variable reaches a local maximum (or
minimum) may have a great impact on the whole system behaviour [21]. Also the
duration of the attack is an important parameter to be taken into consideration
in order to achieve a successful attack. For example, it may take minutes for a
chemical reactor to rupture [37], hours to heat a tank of water or burn out a
motor, and days to destroy centrifuges [9].

Actually, the estimation of the impact of cyber-physical attacks on the target
system is crucial when protecting CPSs [13]. For instance, in industrial CPSs,
before taking any countermeasure against an attack, engineers ﬁrst try to esti-
mate the impact of the attack on the system functioning (e.g., performance and
security) and weight it against the cost of stopping the plant. If this cost is higher
than the damage caused by the attack (as is sometimes the case), then engineers
might actually decide to let the system continue its activities even under attack.
Thus, once an attack is detected, impact metrics are necessary to quantify the
perturbation introduced in the physical behaviour of the system under attack.
The goal of this paper is to lay theoretical foundations to provide formal
instruments to precisely deﬁne the notion of impact of cyber-physical attack
targeting physical devices, such as sensor devices of IoT systems. For that we
rely on a timed generalisation of bisimulation metrics [8,7,39] to compare the
behaviour of two systems up to a given tolerance, for time-bounded executions.
Weak bisimulation metric [8] allows us to compare two systems M and N ,
writing M ≃p N , if the weak bisimilarity holds with a distance or tolerance
p ∈ [0, 1], i.e., if M and N exhibit a diﬀerent behaviour with probability p,
and the same behaviour with probability 1 − p. A useful generalisation is the
n-bisimulation metric [38] that takes into account bounded computations. In-
tuitively, the distance p is ensured only for the ﬁrst n computational steps, for
some n ∈ N. However, in timed systems it is desirable to focus on the passage
of time rather than the number of computational steps. This would allow us to
deal with situations where it is not necessary (or it simply does not make sense)
to compare two systems “ad inﬁnitum” but only for a limited amount of time.

Contribution. In this paper, we ﬁrst introduce a general notion of timed bisim-
ulation metric for concurrent probabilistic systems equipped with a discrete no-

tion of time. Intuitively, this kind of metric allows us to derive a timed weak
p, for k ∈ N+ ∪ {∞} and p ∈ [0, 1],
bisimulation with tolerance, denoted with ≈k
to express that the tolerance p between two timed systems is ensured only for
the ﬁrst k time instants (tick-actions). Then, we use our timed bisimulation met-
ric to set up a formal compositional theory to study and measure the impact of
cyber-physical attacks on IoT systems speciﬁed in a simple probabilistic timed
process calculus which extends Hennessy and Regan’s Timed Process Language
(TPL) [16]. IoT systems in our calculus are modelled by specifying: (i) a physi-
cal environment , containing informations on the physical state variables and the
sensor measurements, and (ii) a logics that governs both accesses to sensors and
channel-based communications with other cyber components.

We focus on attacks on sensors that may eavesdrop and possibly modify the
sensor measurements provided to the controllers of sensors, aﬀecting both the
integrity and the availability of the system under attack.

In order to make security assessments of our IoT systems, we adapt a well-
know approach called Generalized Non Deducibility on Composition (GNDC) [10]
to compare the behaviour of an IoT system M with the behaviour of the same
system under attack, written M k A, for some arbitrary cyber-physical attack
A. This comparison makes use of our timed bisimulation metric to evaluate not
only the tolerance and the vulnerability of a system M with respect to a certain
attack A, but also the impact of a successful attack in terms of the deviation
introduced in the behaviour of the target system. In particular, we say that
a system M tolerates an attack A if M k A ≈∞
0 M , i.e., the presence of A
does not aﬀect the behaviour of M ; whereas M is said to be vulnerable to A in
the time interval m..n with impact p if m..n is the smallest interval such that
M k A ≈m−1
p M , for any k ≥ n, i.e., if the perturbation
introduced by the attack A becomes observable in the m-th time slot and yields
the maximum impact p in the n-th time slot. In the concluding discussion we
will show that the temporal vulnerability window m..n provides several informa-
tions about the corresponding attack, such as stealthiness capability, duration
of the physical eﬀects of the attack, and consequent room for possible run-time
countermeasures.

0 M and M k A ≈k

As a case study, we use our timed bisimulation metric to measure the impact
of two diﬀerent attacks injecting false positives and false negative, respectively,
into a simple surveillance system expressed in our process calculus.

Outline. Section 2 formalises our timed bisimulation metrics in a general setting.
Section 3 provides a simple calculus of IoT systems. Section 4 deﬁnes cyber-
physical attacks together with the notions of tolerance and vulnerability w.r.t.
an attack. In Section 5 we use our metrics to evaluate the impact of two attacks
on a simple surveillance system. Section 6 draws conclusions and discusses related
and future work. In this extended abstract proofs are omitted, full details of the
proofs can be found in the Appendix.

2 Timed Bisimulation Metrics

In this section, we introduce timed bisimulation metrics as a general instrument
to derive a notion of timed and approximate weak bisimulation between proba-
bilistic systems equipped with a discrete notion of time. In Section 2.1, we recall
the semantic model of nondeterministic probabilistic labelled transition systems;
in Section 2.2, we present our metric semantics.

2.1 Nondeterministic Probabilistic Labelled Transition Systems

Nondeterministic probabilistic labelled transition systems (pLTS) [33] combine
classic LTSs [19] and discrete-time Markov chains [15,35] to model, at the same
time, reactive behaviour, nondeterminism and probability. We ﬁrst provide the
mathematical machinery required to deﬁne a pLTS.

The state space in a pLTS is given by a set T , whose elements are called
processes, or terms. We use t, t′, .. to range over T . A (discrete) probability sub-
t∈T ∆(t) ∈ (0, 1]. We
distribution over T is a mapping ∆ : T → [0, 1], with
t∈T ∆(t) by | ∆ |, and we say that ∆ is a probability distribution if
denote
|∆|= 1. The support of ∆ is given by ⌈∆⌉ = {t ∈ T : ∆(t) > 0}. The set of all
sub-distributions (resp. distributions) over T with ﬁnite support will be denoted
with Dsub(T ) (resp. D(T )). We use ∆, Θ, Φ to range over Dsub(T ) and D(T ).

P

P

Deﬁnition 1 (pLTS [33]). A pLTS is a triple (T , A, −→), where: (i) T is a
countable set of terms, (ii) A is a countable set of actions, and (iii) −→ ⊆
T × A × D(T ) is a transition relation.

In Deﬁnition 1, we assume the presence of a special deadlocked term Dead ∈ T .
Furthermore, we assume that the set of actions A contains at least two actions:
τ and tick. The former to model internal computations that cannot be externally
observed, while the latter denotes the passage of one time unit in a setting with
a discrete notion of time [16]. In particular, tick is the only timed action in A.

We write t α

−→ ∆ for (t, α, ∆) ∈ −→, t α

−→ ∆, and t α
−→6

−→ if there is a distribution ∆ ∈ D(T )
with t α
−→ ∆} denote
the set of the derivatives (i.e. distributions) reachable from term t through action
α. We say that a pLTS is image-ﬁnite [17] if der (t, α) is ﬁnite for all t ∈ T and
α ∈ A. In this paper, we will always work with image-ﬁnite pLTSs.

otherwise. Let der (t, α) = {∆ ∈ D(T ) | t α

Weak transitions. As we are interested in developing a weak bisimulation metric,
we need a deﬁnition of weak transition which abstracts away from τ -actions. In a
probabilistic setting, the deﬁnition of weak transition is somewhat complicated
by the fact that (strong) transitions take terms to distributions; consequently
if we are to use weak transitions then we need to generalise transitions, so that
they take (sub-)distributions to (sub-)distributions.

To this end, we need some extra notation on distributions. For a term t ∈ T ,
the point (Dirac) distribution at t, denoted t, is deﬁned by t(t) = 1 and t(t′) = 0
for all t′ 6= t. Then, the convex combination
i∈I pi · ∆i of a family {∆i}i∈I of
i∈I pi ≤ 1,
(sub-)distributions, with I a ﬁnite set of indexes, pi ∈ (0, 1] and

P

P

i∈I pi · ∆i)(t)

def
=

i∈I pi · ∆i(t) for all

is the (sub-)distribution deﬁned by (
t ∈ T . We write

i∈I pi · ∆i as p1 · ∆1 + . . . + pn · ∆n when I = {1, . . . , n}.

P

P

P

Along the lines of [6], we write t ˆτ

−→ ∆, for some term t and some distribution
−→ ∆.
−→ is extended to model transitions from sub-distributions to sub-
−→ Θ if there

∆, if either t
Relation ˆα
distributions. For a sub-distribution ∆ =

τ
−→ ∆ or ∆ = t. Then, for α 6= τ , we write t

i∈I pi · ti, we write ∆ ˆα

−→ ∆ if t α
ˆα

ˆα
−→6

ˆα
−→ Θj for all j ∈ J,
is a non-empty set of indexes J ⊆ I such that: (i) tj
P
, for all i ∈ I \ J, and (iii) Θ =
(ii) ti
j∈J pj · Θj . Note that if α 6= τ
then this deﬁnition admits that only some terms in the support of ∆ make the
−→ transition. Then, we deﬁne the weak transition relation ˆτ
ˆα
=⇒ as the transitive
and reﬂexive closure of ˆτ
ˆα
−→, i.e., ˆτ
=⇒ denote
=⇒ ˆα
ˆτ

−→)∗, while for α 6= τ we let

=⇒ = ( ˆτ

−→ ˆτ

=⇒.

P

2.2 Timed Weak Bisimulation with Tolerance

In this section, we deﬁne a family of relations ≈k
p over T , with p ∈ [0, 1] and k ∈
N+ ∪ {∞}, where, intuitively, t ≈k
p t′ means that t and t′ can weakly bisimulate
each other with a tolerance p accumulated in k timed steps. This is done by
introducing a family of pseudometrics mk : T × T → [0, 1] and deﬁning t ≈k
p t′
iﬀ mk(t, t′) = p. The pseudometrics mk will have the following properties for any
t, t′ ∈ T : (i) mk1 (t, t′) ≤ mk2(t, t′) whenever k1 < k2 (tolerance monotonicity);
(ii) m∞(t, t′) = p iﬀ p is the distance between t and t′ as given by the weak
bisimilarity metric in [8] in an untimed setting; (iii) m∞(t, t′) = 0 iﬀ t and t′ are
related by the standard weak probabilistic bisimilarity [30].
Let us recall the standard deﬁnition of pseudometric.

Deﬁnition 2 (Pseudometric). A function d : T × T → [0, 1] is a 1-bounded
pseudometric over T if

– d(t, t) = 0 for all t ∈ T ,
– d(t, t′) = d(t′, t) for all t, t′ ∈ T (symmetry),
– d(t, t′) ≤ d(t, t′′) + d(t′′, t′) for all t, t′, t′′ ∈ T (triangle inequality).

In order to deﬁne the family of functions mk, we deﬁne an auxiliary family
of functions mk,h : T × T → [0, 1], with k, h ∈ N, quantifying the tolerance of
the weak bisimulation after a sequence of computation steps such that: (i) the
sequence contains exactly k tick-actions, (ii) the sequence terminates with a
tick-action, (iii) any term performs exactly h untimed actions before the ﬁrst
tick-action, (iv) between any i-th and (i+1)-th tick-action, with 1 ≤ i < k, there
are an arbitrary number of untimed actions.

The deﬁnition of mk,h relies on a timed and quantitative version of the classic
bisimulation game: The tolerance between t and t′ as given by mk,h(t, t′) can be
below a threshold ǫ ∈ [0, 1] only if each transition t α
−→ ∆ is mimicked by a weak
ˆα
transition t′
=⇒ Θ such that the bisimulation tolerance between ∆ and Θ is, in

turn, below ǫ. This requires to lift pseudometrics over T to pseudometrics over
(sub-)distributions in Dsub(T ). To this end, we adopt the notions of matching [43]
(also called coupling) and Kantorovich lifting [5].

Deﬁnition 3 (Matching). A matching for a pair of distributions (∆, Θ) ∈
D(T ) × D(T ) is a distribution ω in the state product space D(T × T ) such that:

–
–

t′∈T ω(t, t′) = ∆(t), for all t ∈ T , and
t∈T ω(t, t′) = Θ(t′), for all t′ ∈ T .

P
P

We write Ω(∆, Θ) to denote the set of all matchings for (∆, Θ).

A matching for (∆, Θ) may be understood as a transportation schedule for the
shipment of probability mass from ∆ to Θ [43].

Deﬁnition 4 (Kantorovich lifting). Assume a pseudometric d : T × T →
[0, 1]. The Kantorovich lifting of d is the function K(d) : D(T ) × D(T ) → [0, 1]
deﬁned for distributions ∆ and Θ as:

K(d)(∆, Θ)

def
= minω∈Ω(∆,Θ)

s,t∈T ω(s, t) · d(s, t).

P

Note that since we are considering only distributions with ﬁnite support, the
minimum over the set of matchings Ω(∆, Θ) used in Deﬁnition 4 is well deﬁned.
Pseudometrics mk,h are inductively deﬁned on k and h by means of suitable
functionals over the complete lattice ([0, 1]T ×T , ⊑) of functions of type T × T →
[0, 1], ordered by d1 ⊑ d2 iﬀ d1(t, t′) ≤ d2(t, t′) for all t, t′ ∈ T . Notice that in this
lattice, for each set D ⊆ [0, 1]T ×T , the supremum and inﬁmum are deﬁned as
sup(D)(t, t′) = supd∈D d(t, t′) and inf(D)(t, t′) = inf d∈D d(t, t′), for all t, t′ ∈ T .
The inﬁmum of the lattice is the constant function zero, denoted by 0, and the
supremum is the constant function one, denoted by 1.

Deﬁnition 5 (Functionals for mk,h). The functionals B, Btick : [0, 1]T ×T →
[0, 1]T ×T are deﬁned for any function d ∈ [0, 1]T ×T and terms t, t′ ∈ T as:

B(d)(t, t′) = max{ d(t, t′),
sup
α∈A\{tick}
sup
α∈A\{tick}

Btick(d)(t, t′) = max{ d(t, t′),
max
tick−−→∆
t
max
tick−−→Θ
where inf ∅ = 1 and max ∅ = 0.

t′

max
α−→∆
t
max
t′ α−→Θ

inf
t′ ˆα=⇒Θ
inf
ˆα=⇒∆
t

K(d)

∆, Θ + (1− |Θ|)Dead

,

(cid:0)
K(d)

(cid:1)
∆ + (1− |∆|)Dead, Θ

}

(cid:0)

(cid:1)

inf
tick==⇒Θ
t′ c
inf
tick==⇒∆
t c

K(d)

∆, Θ + (1− |Θ|)Dead

,

(cid:1)
(cid:0)
∆ + (1− |∆|)Dead, Θ
K(d)

}

(cid:0)

(cid:1)

Notice that all max in Deﬁnition 5 are well deﬁned since the pLTS is image-
ﬁnite. Notice also that any strong transitions from t to a distribution ∆ is mim-
icked by a weak transition from t′, which, in general, takes to a sub-distribution
Θ. Thus, process t′ may not simulate t with probability 1− |Θ|.

Deﬁnition 6 (Timed weak bisimilarity metrics). The family of the timed
weak bisimilarity metrics mk : (T × T ) → [0, 1] is deﬁned for all k ∈ N by

mk =

0
suph∈N mk,h

if k = 0
if k > 0

(

while the functions mk,h : (T ×T ) → [0, 1] are deﬁned for all k ∈ N+ and h ∈ N by

(

mk,h =

Btick(mk−1)
B(mk,h−1)

if h = 0
if h > 0.
Then, we deﬁne m∞ : (T × T ) → [0, 1] as m∞ = supk∈N mk.
Note that any mk,h is obtained from mk−1 by one application of the functional
Btick, in order to take into account the distance between terms introduced by the
k-th tick-action, and h applications of the functional B, in order to lift such a
distance to terms that take h untimed actions to be able to perform a tick-action.
By taking suph∈N mk,h we consider an arbitrary number of untimed steps.

The pseudometric property of mk is necessary to conclude that the tolerance

between terms as given by mk is a reasonable notion of behavioural distance.

Theorem 1. For any k ≥ 1, mk is a 1-bounded pseudometric.

Finally, everything is in place to deﬁne our timed weak bisimilarity ≈k

tolerance p ∈ [0, 1] accumulated after k time units, for k ∈ N ∪ {∞}.
Deﬁnition 7 (Timed weak bisimilarity with tolerance). Let t, t′ ∈ T ,
k ∈ N and p ∈ [0, 1]. We say that t and t′ are weakly bisimilar with a tolerance p,
which accumulates in k timed actions, written t ≈k
p t′, if and only if mk(t, t′) = p.
Then, we write t ≈∞

p t′ if and only if m∞(t, t′) = p.

p with

Since the Kantorovich lifting K is monotone [29], it follows that both func-
tionals B and Btick are monotone. This implies that, for any k ≥ 1, (mk,h)h≥0 is
a non-decreasing chain and, analogously, also (mk)k≥0 is a non-decreasing chain,
thus giving the following expected result saying that the distance between terms
grows when we consider a higher number of tick computation steps.
Proposition 1 (Tolerance monotonicity). For all terms t, t′ ∈ T and k1, k2 ∈
N+ with k1 < k2, t ≈k1
p1

t′ entail p1 ≤ p2.

t′ and t ≈k2
p2

We conclude this section by comparing our behavioural distance with the

behavioural relations known in the literature.

We recall that in [8] a family of relations ≃p for untimed process calculi
are deﬁned such that t ≃p t′ if and only if t and t′ weakly bisimulate each
other with tolerance p. Of course, one can apply these relations also to timed
process calculi, the eﬀect being that timed actions are treated in exactly the
same manner as untimed actions. The following result compares the behavioural
metrics proposed in the present paper with those of [8], and with the classical
notions of probabilistic weak bisimilarity [30] denoted ≈.

Proposition 2. Let t, t′ ∈ T and p ∈ [0, 1]. Then,

– t ≈∞
– t ≈∞

p t′ iﬀ t ≃p t′
0 t′ iﬀ t ≈ t′.

3 A Simple Probabilistic Timed Calculus for IoT Systems

In this section, we propose a simple extension of Hennessy and Regan’s timed
process algebra TPL [16] to express IoT systems and cyber-physical attacks. The
goal is to show that timed weak bisimilarity with tolerance is a suitable notion
to estimate the impact of cyber-physical attacks on IoT systems.

Let us start with some preliminary notations.

Notation 1 We use x, xk for state variables, c, ck, for communication channels,
z,zk for communication variables, s, sk for sensors devices, while o ranges over
both channels and sensors. Values, ranged over by v, v′, belong to a ﬁnite set of
admissible values V. We use u, uk for both values and communication variables.
Given a generic set of names N , we write V N to denote the set of functions
N → V assigning a value to each name in N . For m ∈ N and n ∈ N ∪ {∞}, we
write m..n to denote an integer interval. As we will adopt a discrete notion of
time, we will use integer intervals to denote time intervals.

State variables are associated to physical properties like temperature, pressure,
etc. Sensor names are metavariables for sensor devices, such as thermometers
and barometers. Please, notice that in cyber-physical systems, state variables
cannot be directly accessed but they can only be tested via one or more sensors.

Deﬁnition 8 (IoT system). Let X be a set of state variables and S be a set of
sensors. Let range : X → 2V be a total function returning the range of admissible
values for any state variable x ∈ X . An IoT system consists of two components:

– a physical environment ξ = hξx, ξmi where:

• ξx ∈ V X is the physical state of the system that associates a value to
each state variable in X , such that ξx(x) ∈ range(x) for any x ∈ X ,
• ξm : V X → S → D(V) is the measurement map that given a physical
state returns a function that associates to any sensor in S a discrete
probability distribution over the set of possible sensed values;

– a logical (or cyber) component P that interacts with the sensors deﬁned in

ξ, and can communicate, via channels, with other cyber components.

We write ξ ⋊⋉ P to denote the resulting IoT system, and use M and N to range
over IoT systems.

Let us now formalise the cyber component of an IoT system. Basically, we

adapt Hennessy and Regan’s timed process algebra TPL [16].

Deﬁnition 9 (Logics). Logical components of IoT systems are deﬁned by the
following grammar:
P, Q ::= nil
pfx ::= o!v

if (b) {P } else {Q}

⌊pfx .P ⌋Q

P k Q

tick.P

Hh˜ui

P \c

o?(z)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

The process tick.P sleeps for one time unit and then continues as P . We write
P k Q to denote the parallel composition of concurrent processes P and Q. The

(cid:12)
(cid:12)

(cid:12)
(cid:12)

process ⌊pfx .P ⌋Q denotes preﬁxing with timeout. We recall that o ranges over
both channel and sensor names. Thus, for instance, ⌊c!v.P ⌋Q sends the value
v on channel c and, after that, it continues as P ; otherwise, if no communica-
tion partner is available within one time unit, it evolves into Q. The process
⌊c?(z).P ⌋Q is the obvious counterpart for channel reception. On the other hand,
the process ⌊s?(z).P ⌋Q reads the sensor s, according to the measurement map
of the systems, and, after that, it continues as P . The process ⌊s!v.P ⌋Q writes
to the sensor s and, after that, it continues as P ; here, we wish to point out
that this a malicious activity, as controllers may only access sensors for reading
sensed data. Thus, the construct ⌊s!v.P ⌋Q serves to implement an integrity at-
tack that attempts at synchronising with the controller of sensor s to provide a
fake value v. In the following, we say that a process is honest if it never writes
on sensors. The deﬁnition of honesty naturally lifts to IoT systems. In processes
of the form tick.Q and ⌊pfx .P ⌋Q, the occurrence of Q is said to be time-guarded.
Recursive processes Hh˜ui are deﬁned via equations H(z1, . . . , zk) = P , where
(i) the tuple z1, . . . , zk contains all the variables that appear free in P , and (ii)
P contains only time-guarded occurrences of the process identiﬁers, such as H
itself (to avoid zeno behaviours). The two remaining constructs are standard;
they model conditionals and channel restriction, respectively.

Finally, we deﬁne how to compose IoT systems. For simplicity, we compose

two systems only if they have the same physical environment.
Deﬁnition 10 (System composition). Let M1 = ξ ⋊⋉ P1 and M2 = ξ ⋊⋉ P2 be
two IoT systems, and Q be a process whose sensors are deﬁned in the physical
environment ξ. We write:

– M1 k M2 to denote ξ ⋊⋉ (P1 k P2);
– M1 k Q to denote ξ ⋊⋉ (P1 k Q);
– M1\c as an abbreviation for ξ ⋊⋉ (P1\c).

We conclude this section with the following abbreviations that will be used

in the rest of the paper.

Notation 2 We write P \{c1, c2, . . . , cn}, or P \˜c, to mean P \c1\c2 · · · \cn. For
simplicity, we sometimes abbreviate both H(i) and Hhii with Hi. We write pfx .P
as an abbreviation for the process deﬁned via the equation H = ⌊pfx .P ⌋H , where
the process name H does not occur in P . We write tickk.P as a shorthand for
tick.tick. . . . tick.P , where the preﬁx tick appears k ≥ 0 consecutive times. We
write Dead to denote a deadlocked IoT system that cannot perform any action.

3.1 Probabilistic labelled transition semantics

As said before, sensors serve to observe the evolution of the physical state of an
IoT system. However, sensors are usually aﬀected by an error/noise that we rep-
resent in our measurement maps by means of discrete probability distributions.
For this reason, we equip our calculus with a probabilistic labelled transition
system. In the following, the symbol ǫ ranges over distributions on physical envi-
ronments, whereas π ranges over distributions on (logical) processes. Thus, ǫ ⋊⋉ π

(Write)

−

⌊o!v.P ⌋Q

o!v

−−−→ P

P

(Sync)

o?(z)
o!v
−−−→ P ′ Q
−−−−−→ Q′
τ
v
−−→ P ′ k Q′{
/z}

P k Q

(Read)

P

(Par)

−

⌊o?(z).P ⌋Q

o?(z)

−−−−−→ P

λ
−−→ P ′ λ 6= tick
λ
−−→ P ′ k Q
λ

P k Q

P

(Res)

(Then)

P \o

λ
−−→ P ′ λ 6∈ {o!v, o?(z)}
λ
−−→ P ′\o
λ
−−→ P ′
λ
−−→ P ′

JbK = true P

if (b) {P } else {Q}

(Rec)

(Else)

P {˜v

/˜z}

−−→ Q H(˜z) = P

Hh˜vi

λ

−−→ Q
λ
−−→ Q′
λ
−−→ Q′

JbK = false Q

if (b) {P } else {Q}

−
tick
−−−→ nil

nil

−

(TimeNil)

(Timeout)

(Delay)

−

tick.P

tick

−−−→ P

tick

(TimePar)

−−−→ Q

⌊pfx .P ⌋Q
Table 1. Labelled transition system for processes

P k Q

tick
−−−→ P ′ k Q′

P

tick
−−−→ P ′ Q

tick
−−−→ Q′

denotes the distribution over IoT systems deﬁned by (ǫ ⋊⋉ π)(ξ ⋊⋉ P ) = ǫ(ξ)·π(P ).
The symbol γ ranges over distributions on IoT systems.

In Table 1, we give a standard labelled transition system for logical compo-
nents (timed processes), whereas in Table 2 we rely on the LTS of Table 1 to
deﬁne a simple pLTS for IoT systems by lifting transition rules from processes
to systems.

In Table 1, the meta-variable λ ranges over labels in the set {τ, tick, o!v, o?(z)}.
Rule (Sync) serve to model synchronisation and value passing, on some name (for
channel or sensor) o: if o is a channel then we have standard point-to-point com-
munication, whereas if o is a sensor then this rule models an integrity attack on
sensor s, as the controller is provided with a fake value v. The remaining rules
are standard. The symmetric counterparts of rules (Sync) and (Par) are omitted.
According to Table 2, IoT systems may ﬁre four possible actions ranged over
by α. These actions represent: internal activities (τ ), the passage of time (tick),
channel transmission (c!v) and channel reception (c?v).

Rules (Snd) and (Rcv) model transmission and reception on a channel c with
an external system, respectively. Rule (SensRead) models the reading of the value
detected at a sensor s according to the current physical environment ξ = hξx, ξmi.
In particular, this rule says that if a process P in a system ξ ⋊⋉ P reads a sensor
s deﬁned in ξ then it will get a value that may vary according to the probability
distribution resulting by providing the state function ξx and the sensor s to the
measurement map ξm.

Rule (Tau) lifts internal actions from processes to systems. This includes
communications on channels and malicious accesses to sensors’ controllers. Ac-

(Snd)

P
ξ ⋊⋉ P

c!v
−−−→ P ′
c!v
−−−→ ξ ⋊⋉ P ′

(Rcv)

P

c?(z)
−−−−−→ P ′
c?v
−−−→ ξ ⋊⋉ P ′{v/z}

ξ ⋊⋉ P

(SensRead)

P

s?(z)
−−−−−→ P ′
τ
ξ ⋊⋉ P

ξm(ξx)(s) = Pi∈I pi · vi

−−→ ξ ⋊⋉ Pi∈I pi · P ′{vi/z}

(Tau)

P
ξ ⋊⋉ P

τ
−−→ P ′
τ
−−→ ξ ⋊⋉ P ′

(Time)

P

tick
−−−→ P ′

τ
ξ ⋊⋉ P
−−→6
tick
−−−→ ξ′ ⋊⋉ P ′

ξ ⋊⋉ P

ξ′ ∈ next (ξ)

Table 2. Probabilistic LTS for a IoT system ξ ⋊⋉ P with ξ = hξx, ξmi

cording to Deﬁnition 10, rule (Tau) models also channel communication between
two parallel IoT systems sharing the same physical environment.

A second lifting occurs in rule (Time) for timed actions tick. Here, ξ′ denotes
an admissible physical environment for the next time slot, nondeterministically
chosen from the ﬁnite set next(hξx, ξmi). This set is deﬁned as {hξ′
x(x) ∈
range(x) for any x ∈ X }.3 As a consequence, the rules in Table 2 deﬁne an
image-ﬁnite pLTS.

x, ξmi : ξ′

For simplicity, we abstract from the physical process behind our IoT systems.

4 Cyber-physical attacks on sensor devices

In this section, we consider attacks tampering with sensors by eavesdropping
and possibly modifying the sensor measurements provided to the corresponding
controllers. These attacks may aﬀect both the integrity and the availability of
the system under attack. We do not represent (well-known) attacks on communi-
cation channels as our focus is on attacks to physical devices and the consequent
impact on the physical state. However, our technique can be easily generalised
to deal with attacks on channels as well.

Deﬁnition 11 (Cyber-physical attack). A (pure) cyber-physical attack A is
a process derivable from the grammar of Deﬁnition 9 such that:

– A writes on at least one sensor;
– A never uses communication channels.

In order to make security assessments on our IoT systems, we adapt a well-
known approach called Generalized Non Deducibility on Composition (GNDC) [10].
Intuitively, an attack A aﬀects an honest IoT system M if the execution of the
composed system M k A diﬀers from that of the original system M in an observ-
able manner. Basically, a cyber-physical attack can inﬂuence the system under
attack in at least two diﬀerent ways:

3 The ﬁniteness follows from the ﬁniteness of V, and hence of range(x), for any x ∈ X .

– The system M k A might have non-genuine execution traces containing
observables that cannot be reproduced by M ; here the attack aﬀects the
integrity of the system behaviour (integrity attack ).

– The system M might have execution traces containing observables that can-
not be reproduced by the system under attack M k A (because they are
prevented by the attack); this is an attack against the availability of the
system (DoS attack ).

Now, everything is in place to provide a formal deﬁnition of system tolerance
and system vulnerability with respect to a given attack. Intuitively, a system M
tolerates an attack A if the presence of the attack does not aﬀect the behaviour
of M ; on the other hand M is vulnerable to A in a certain time interval if the
attack has an impact on the behaviour of M in that time interval.

Deﬁnition 12 (Attack tolerance). Let M be a honest IoT system. We say
that M tolerates an attack A if M k A ≈∞

0 M .

Deﬁnition 13 (Attack vulnerability and impact). Let M be a honest IoT
system. We say that M is vulnerable to an attack A in the time interval m..n
with impact p ∈ [0, 1], for m ∈ N+ and n ∈ N+∪{∞}, if m..n is the smallest time
interval such that: (i) M k A ≈m−1
p M .4

0 M , (ii) M k A ≈n

p M , (iii) M k A ≈∞

Basically, the deﬁnition above says that if a system is vulnerable to an attack in
the time interval m..n then the perturbation introduced by the attack starts in
the m-th time slot and reaches the maximum impact in the n-th time slot.

The following result says that both notions of tolerance and vulnerability
are suitable for compositional reasonings. More precisely, we prove that they are
both preserved by parallel composition and channel restriction. Actually, channel
restriction may obviously make a system less vulnerable by hiding channels.

Theorem 2 (Compositionality). Let M1 = ξ ⋊⋉ P1 and M2 = ξ ⋊⋉ P2 be two
honest IoT systems with the same physical environment ξ, A an arbitrary attack,
and ˜c a set of channels.

– If both M1 and M2 tolerate A then (M1 k M2)\˜c tolerates A.
– If M1 is vulnerable to A in the time interval m1..n1 with impact p1, and M2
is vulnerable to A in the time interval m2..n2 with impact p2, then M1 k M2
is vulnerable to A in a the time interval min(m1, m2).. max(n1, n2) with an
impact p′ ≤ (p1 + p2 − p1p2).

– If M1 is vulnerable to A in the interval m1..n1 with impact p1 then M1\˜c is
vulnerable to A in a time interval m′..n′ ⊆ m1..n1 with an impact p′ ≤ p1.

Note that if an attack A is tolerated by a system M and can interact with
a honest process P then the compound system M k P may be vulnerable to
A. However, if A does not write on the sensors of P then it is tolerated by
M k P as well. The bound p′ ≤ (p1 + p2 − p1p2) can be explained as follows.

4 By Proposition 1, at all time instants greater than n the impact remains p.

The likelihood that the attack does not impact on Mi is (1 − pi), for i ∈ {1, 2}.
Thus, the likelihood that the attack impacts neither on M1 nor on M2 is at least
(1 − p1)(1 − p2). Summarising, the likelihood that the attack impacts on at least
one of the two systems M1 and M2 is at most 1 − (1 − p1)(1 − p2) = p1 + p2 − p1p2.
An easy corollary of Theorem 2 allows us to lift the notions of tolerance and
vulnerability from a honest system M to the compound systems M k P , for a
honest process P .

Corollary 1. Let M be a honest system, A an attack, ˜c a set of channels, and
P a honest process that reads sensors deﬁned in M but not those written by A.

– If M tolerates A then (M k P )\˜c tolerates A.
– If M is vulnerable to A in the interval m..n with impact p, then (M k P )\˜c
is vulnerable to A in a time interval m′..n′ ⊆ m..n, with an impact p′ ≤ p.

5 Attacking a smart surveillance system: A case study

Consider an alarmed ambient consisting of three rooms, ri for i ∈ {1, 2, 3}, each
of which equipped with a sensor si to detect unauthorised accesses. The alarm
goes oﬀ if at least one of the three sensors detects an intrusion.

The logics of the system can be easily speciﬁed in our language as follows:

Sys = (Mng k Ctrl1 k Ctrl2 k Ctrl3 ) \{c1, c2, c3}
Mng = c1?(z1).c2?(z2).c3?(z3).if (W3

i=1 zi=on) {alarm!on.tick.Checkk } else {tick.Mng}

Check0 = Mng
Checkj = alarm!on.c1?(z1).c2?(z2).c3?(z3).if (W3

else {tick.Checkj −1 }

for j > 0

i=1 zi = on) {tick.Checkk }

Ctrli = si?(zi).if (zi=presence) {ci!on.tick.Ctrli } else {ci!oﬀ.tick.Ctrli } for i∈{1, 2, 3}.

Intuitively, the process Sys is composed by three controllers, Ctrli , one for
each sensor si, and a manager Mng that interacts with the controllers via private
channels ci. The process Mng ﬁres an alarm if at least one of the controllers
signals an intrusion. As usual in this kind of surveillance systems, the alarm will
keep going oﬀ for k instants of time after the last detected intrusion.

i and p−

As regards the physical environment, the physical state ξx : {r1, r2, r3} →
{presence, absence} is set to ξx(ri) = absence, for any i ∈ {1, 2, 3}. Furthermore,
let p+
i be the probabilities of having false positives (erroneously detected
5, re-
intrusion) and false negatives (erroneously missed intrusion) at sensor si
spectively, for i ∈ {1, 2, 3}, the measurement function ξm is deﬁned as follows:
ξm(ξx)(si) = (1−p−
i absence, if ξx(ri) = presence; ξm(ξx)(si) =
(1−p+
i ) absence + p+
Thus, the whole IoT system has the form ξ ⋊⋉ Sys, with ξ = hξx, ξmi.
We start our analysis studying the impact of a simple cyber-physical attack
that provides fake false positives to the controller of one of the sensors si. This
attack aﬀects the integrity of the system behaviour as the system under attack
will ﬁre alarms without any physical intrusion.

i ) presence + p−
i presence, otherwise.

5 These probabilities are usually very small; we assume them smaller than 1
2 .

Example 1 (Introducing false positives). In this example, we provide an attack
that tries to increase the number of false positives detected by the controller of
some sensor si during a speciﬁc time interval m..n, with m, n ∈ N, n ≥ m > 0.
Intuitively, the attack waits for m − 1 time slots, then, during the time interval
m..n, it provides the controller of sensor si with a fake intrusion signal. Formally,

Afp(i, m, n) = tickm−1.Bhi, n − m + 1i

B(i, j) = if (j = 0) {nil} else {⌊si!presence.tick.Bhi, j − 1i⌋Bhi, j − 1i} .

In the following proposition, we use our metric to measure the perturbation
introduced by the attack to the controller of a sensor si by varying the time of
observation of the system under attack.

Proposition 3. Let ξ be an arbitrary physical state for the systems Mi =
ξ ⋊⋉ Ctrl i, for i ∈ {1, 2, 3}. Then,
– Mi k Afphi, m, ni ≈j
– Mi k Afphi, m, ni ≈j
– Mi k Afphi, m, ni ≈j

0 Mi, for j ∈ 1..m−1;
h Mi, with h = 1 − (p+
r Mi, with r = 1 − (p+

i )j−m+1, for j ∈ m..n;
i )n−m+1, for j > n or j = ∞.

i )n−m+1.

By an application of Deﬁnition 13 we can measure the impact of the attack Afp
to the (sub)systems ξ ⋊⋉ Ctrli .
Corollary 2. The IoT systems ξ ⋊⋉ Ctrli are vulnerable to the attack Afphi, m, ni
in the time interval m..n with impact 1 − (p+
Note that the vulnerability window m..n coincides with the activity period of
the attack Afp. This means that the system under attack recovers its normal be-
haviour immediately after the termination of the attack. However, in general, an
attack may impact the behaviour of the target system long after its termination.
Note also that the attack Afphi, m, ni has an impact not only on the controller
Ctrl i but also on the whole system ξ ⋊⋉ Sys. This because the process Mng will
surely ﬁre the alarm as it will receive at least one intrusion detection from Ctrl i.
However, by an application of Corollary 1 we can prove that the impact on the
whole system will not get ampliﬁed.
Proposition 4 (Impact of the attack Afp). The system ξ ⋊⋉ Sys is vulnerable
to the attack Afphi, m, ni in a time interval m′..n′ ⊆ m..n with impact p′ ≤
1 − (p+

i )n−m+1.

Now, the reader may wonder what happens if we consider a complementary
attack that provides fake false negatives to the controller of one of the sensors
si. In this case, the attack aﬀects the availability of the system behaviour as the
system will no ﬁre the alarm in the presence of a real intrusion. This because a
real intrusion will be somehow “hidden” by the attack.

Example 2 (Introducing false negatives). The goal of the following attack is to
increase the number of false negatives during the time interval m..n, with n ≥
m > 0. Formally, the attack is deﬁned as follows:

Afn(i, m, n) = tickm−1.Chi, n − m + 1i

C(i, j) = if (j = 0) {nil} else {⌊si!absence.tick.Chi, j − 1i⌋Chi, j − 1i} .

In the following proposition, we use our metric to measure the deviation intro-
duced by the attack Afn to the controller of a sensor si. With no surprise we get
a result that is the symmetric version of Proposition 3.

Proposition 5. Let ξ be an arbitrary physical state for the system Mi = ξ ⋊⋉ Ctrl i,
for i ∈ {1, 2, 3}. Then,

– Mi k Afnhi, m, ni ≈j
– Mi k Afnhi, m, ni ≈j
– Mi k Afnhi, m, ni ≈j

0 Mi, for j ∈ 1..m−1;
h Mi, with h = 1 − (p−
r Mi, with r = 1 − (p−

i )j−m+1, for j ∈ m..n;
i )n−m+1, for j > n or j = ∞.

Again, by an application of Deﬁnition 13 we can measure the impact of the

attack Afn to the (sub)systems ξ ⋊⋉ Ctrli .

Corollary 3. The IoT systems ξ ⋊⋉ Ctrli are vulnerable to the attack Afnhi, m, ni
in the time interval m..n with impact 1 − (p−

i )n−m+1.

As our timed metric is compositional, by an application of Corollary 1 we

can estimate the impact of the attack Afn to the whole system ξ ⋊⋉ Sys.

Proposition 6 (Impact of the attack Afn). The system ξ ⋊⋉ Sys is vulnerable
to the attack Afnhi, m, ni in a time interval m′..n′ ⊆ m..n with impact p′ ≤
1 − (p−

i )n−m+1.

6 Conclusions, related and future work

We have proposed a timed generalisation of the n-bisimulation metric [38], called
timed bisimulation metric, obtained by deﬁning two functionals over the complete
lattice of the functions assigning a distance in [0, 1] to each pair of systems: the
former deals with the distance accumulated when executing untimed steps, the
latter with the distance introduced by timed actions.

We have used our timed bisimulation metrics to provide a formal and com-
positional notion of impact metric for cyber-physical attacks on IoT systems
speciﬁed in a simple timed process calculus. In particular, we have focussed on
cyber-physical attacks targeting sensor devices (attack on sensors are by far the
most studied cyber-physical attacks [44]). We have used our timed weak bisim-
ulation with tolerance to formalise the notions of attack tolerance and attack
vulnerability with a given impact p. In particular, a system M is said to be vul-
nerable to an attack A in the time interval m..n with impact p if the perturbation
introduced by A becomes observable in the m-th time slot and yields the maxi-
mum impact p in the n-th time slot. Here, we wish to stress that the vulnerability
window m..n is quite informative. In practise, this interval says when an attack
will produce observable eﬀects on the system under attack. Thus, if n is ﬁnite
we have an attack with temporary eﬀects, otherwise we have an attack with per-
manent eﬀects. Furthermore, if the attack is quick enough, and terminates well
before the time instant m, then we have a stealthy attack that aﬀects the system
late enough to allow attack camouﬂages [14]. On the other hand, if at time m

the attack is far from termination, then the IoT system under attack has good
chances of undertaking countermeasures to stop the attack.

As a case study, we have estimated the impact of two cyber-physical attacks
on sensors that introduce false positives and false negatives, respectively, into
a simple surveillance system, aﬀecting the integrity and the availability of the
IoT system. Although our attacks are quite simple, the speciﬁcation language
and the corresponding metric semantics presented in the paper allow us to deal
with smarter attacks, such as periodic attacks with constant or variable period of
attack. Moreover, we can easily extend our threat model to recover (well-known)
attacks on communication channels.

Related work. We are aware of a number of works using formal methods for
CPS security, although they apply methods, and most of the time have goals,
that are quite diﬀerent from ours.

Burmester et al. [3] employed hybrid timed automata to give a threat model
based on the traditional Byzantine fault model for crypto-security. However,
as remarked in [36], cyber-physical attacks and faults have inherently distinct
characteristics. In fact, unlike faults, cyber-physical attacks may be performed
over a signiﬁcant number of attack points and in a coordinated way.

In [40], Vigo presented an attack scenario that addresses some of the pecu-
liarities of a cyber-physical adversary, and discussed how this scenario relates to
other attack models popular in the security protocol literature. Then, in [41,42]
Vigo et al. proposed an untimed calculus of broadcasting processes equipped
with notions of failed and unwanted communication. They focus on DoS attacks
without taking into consideration timing aspects or attack impact.

Bodei et al. [1,2] proposed an untimed process calculus, IoT-LySa, supporting
a control ﬂow analysis that safely approximates the abstract behaviour of IoT
systems. Essentially, they track how data spread from sensors to the logics of
the network, and how physical data are manipulated.

Rocchetto and Tippenhaur [32] introduced a taxonomy of the diverse attacker
models proposed for CPS security and outline requirements for generalised at-
tacker models; in [31], they then proposed an extended Dolev-Yao attacker model
suitable for CPSs. In their approach, physical layer interactions are modelled as
abstract interactions between logical components to support reasoning on the
physical-layer security of CPSs. This is done by introducing additional orthogo-
nal channels. Time is not represented.

Nigam et al. [28] worked around the notion of Timed Dolev-Yao Intruder
Models for Cyber-Physical Security Protocols by bounding the number of in-
truders required for the automated veriﬁcation of such protocols. Following a
tradition in security protocol analysis, they provide an answer to the question:
How many intruders are enough for veriﬁcation and where should they be placed?
Their notion of time is somehow diﬀerent from ours, as they focus on the time a
message needs to travel from an agent to another. The paper does not mention
physical devices, such as sensors and/or actuators.

Finally, Lanotte et al. [23] deﬁned a hybrid process calculus to model both
CPSs and cyber-physical attacks; they deﬁned a threat model for cyber-physical
attacks to physical devices and provided a proof methods to assess attack tol-
erance/vulnerability with respect to a timed trace semantics (no tolerance al-
lowed).

Future work. Recent works [22,11,24,25,12] have shown that bisimulation met-
rics are suitable for compositional reasoning, as the distance between two com-
plex systems can be often derived in terms of the distance between their com-
ponents. In this respect, Theorem 2 and Corollary 1 allows us compositional
reasonings when computing the impact of attacks on a target system, in terms
of the impact on its sub-systems. We believe that this result can be generalised
to estimate the impact of parallel attacks of the form A = A1 k . . . k Ak in terms
of the impacts of each malicious module Ai.

As future work, we also intend to adopt our impact metric in more involved
languages for cyber-physical systems and attacks, such as the language devel-
oped in [23], with an explicit representation of physical processes via diﬀerential
equations or their discrete counterpart, diﬀerence equations.

Acknowledgements. We thank the anonymous reviewers for valuable comments.
This work has been partially supported by the project “Dipartimenti di Eccel-
lenza 2018-2022”, funded by the Italian Ministry of Education, Universities and
Research (MIUR), and by the Joint Project 2017 “Security Static Analysis for
Android Things”, funded by the University of Verona and JuliaSoft Srl. [4,27]

References

1. C. Bodei, P. Degano, G. Ferrari, and L. Galletta. Where Do Your IoT Ingredients
Come From? In COORDINATION, volume 9686 of LNCS, pages 35–50. Springer,
2016.

2. C. Bodei, P. Degano, G. Ferrari, and L. Galletta. Tracing where IoT data are
collected and aggregated. Logical Methods in Computer Science, 13(3):1–38, 2017.
3. M. Burmester, E. Magkos, and V. Chrissikopoulos. Modeling security in cyber-

physical systems. IJCIP, 5(3-4):118–126, 2012.

4. A. Cerone, M. Hennessy, and M. Merro. Modelling mac-layer communications in

wireless systems. Logical Methods in Computer Science, 11(1:18), 2015.

5. Y. Deng and W. Du. The Kantorovich Metric in Computer Science: A Brief Survey.

In QAPL, volume 253(3) of ENTCS, pages 73–82, 2009.

6. Y. Deng, R. J. van Glabbeek, M. Hennessy, and C. Morgan. Characterising testing
preorders for ﬁnite probabilistic processes. Logical Meth. Comput. Sci., 4(4), 2008.
7. J. Desharnais, J. Gupta, R. Jagadeesan, and P. Panangaden. Metrics for Labelled

Markov Processes. Theoretical Computer Science, 318(3):323–354, 2004.

8. J. Desharnais, R. Jagadeesan, V. Gupta, and P. Panangaden. The metric analogue
In LICS 2002, pages 413–422,

of weak bisimulation for probabilistic processes.
2002.

9. N. Falliere, L. Murchu, and E. Chien. W32.Stuxnet Dossier, 2011.

10. R. Focardi and F. Martinelli. A Uniform Approach for the Deﬁnition of Security

Properties. In FM, volume 1708 of LNCS, pages 794–813. Springer, 1999.

11. D. Gebler, K. G. Larsen, and S. Tini. Compositional Bisimulation Metric Reason-
ing with Probabilistic Process Calculi. Logical Meth. Comput. Sci., 12(4), 2016.
12. D. Gebler and S. Tini. Sos speciﬁcations for uniformly continuous operators. Jour-

nal of Computer and System Sciences, 92:113–151, 2018.

13. B. Genge, I. Kiss, and P. Haller. A system dynamics approach for assessing the
impact of cyber attacks on critical infrastructures. Int. J. Critical Infrastructure
Protection, 10:3–17, 2015.

14. D. Gollmann, P. Gurikov, A. Isakov, M. Krotoﬁl, J. Larsen, and A. Winnicki.
Cyber-Physical Systems Security: Experimental Analysis of a Vinyl Acetate
Monomer Plant. In ACM CCPS, pages 1–12, 2015.

15. H. Hansson and B. Jonsson. A logic for reasoning about time and reliability. Formal

Aspects of Computing, 6(5):512–535, 1994.

16. M. Hennessy and T. Regan. A process algebra for timed systems. Information and

Computation, 117(2):221–239, 1995.

17. H. Hermanns, A. Parma, R. Segala, B. Wachter, and L. Zhang. Probabilistic logical

characterization. Information and Computation, 209(2):154–172, 2011.

18. ICS-CERT. Cyber-Attack Against Ukrainian Critical Infrastructure. https://ics-

cert.us-cert.gov/alerts/IR-ALERT-H-16-056-01.

19. R. M. Keller. Formal veriﬁcation of parallel programs. Communications of the

ACM, 19:371–384, 1976.

20. M. Krotoﬁl and A. A. C´ardenas. Resilience of Process Control Systems to Cyber-

Physical Attacks. In NordSec, volume 8208 of LNCS. Springer, 2013.

21. M. Krotoﬁl, A. A. C´ardenas, J. Larsen, and D. Gollmann. Vulnerabilities of cyber-
physical systems to stale data - Determining the optimal time to launch attacks.
Int. J. Critical Infrastructure Protection, 7(4):213–232, 2014.

22. R. Lanotte and M. Merro. Semantic analysis of gossip protocols for wireless sensor
In CONCUR 2011, volume 6901 of LNCS, pages 156–170. Springer,

networks.
2011.

23. R. Lanotte, M. Merro, R. Muradore, and L. Vigan`o. A formal approach to cyber-

physical attacks. In CSF, pages 436–450. IEEE, 2017.

24. R. Lanotte, M. Merro, and S. Tini. Compositional weak metrics for group key

update. In MFCS, volume 42 of LIPIcs, 2017.

25. R. Lanotte, M. Merro, and S. Tini. Weak simulation quasimetric in a gossip
scenario. In FORTE 2017, volume 10321 of LNCS, pages 139–155. Springer, 2017.
26. G. Loukas. Cyber-Physical Attacks - A Growing Invisible Threat. Butterworth-

Heinemann, 2015.

27. M. Merro, J. Kleist, and U. Nestmann. Mobile Objects as Mobile Processes. In-

formation and Computation, 177(2):195–241, 2002.

28. V. Nigam, C. Talcott, and A. A. Urquiza. Towards the Automated Veriﬁcation of
Cyber-Physical Security Protocols: Bounding the Number of Timed Intruders. In
ESORICS, volume 9879 of LNCS, pages 450–470. Springer, 2016.

29. P. Panangaden. Labelled Markov Processes. Imperial College Press, 2009.
30. A. Philippou, I. Lee, and O. Sokolsky. Weak bisimulation for probabilistic systems.

In CONCUR, volume 1877 of LNCS, pages 334–349, 2000.

31. M. Rocchetto and N. O. Tippenhauer. CPDY: Extending the Dolev-Yao Attacker
with Physical-Layer Interactions. In ICFEM, volume 10009 of LNCS, pages 175–
192, 2016.

32. M. Rocchetto and N. O. Tippenhauer. On Attacker Models and Proﬁles for Cyber-
Physical Systems. In ESORICS, volume 9879 of LNCS, pages 427–449. Springer,
2016.

33. R. Segala. Modeling and Veriﬁcation of Randomized Distributed Real-Time Sys-

tems. PhD thesis, MIT, 1995.

34. J. Slay and M. Miller. Lessons Learned from the Maroochy Water Breach.

In
Critical Infrastructure Protection, volume 253 of IFIP, pages 73–82. Springer, 2007.
35. W. J. Stewart. Introduction to the Numerical Solution of Markov Chains. Princeton

University Press, 1994.

36. A. Teixeira, I. Shames, J. Sandberg, and K. H. Johansson. A secure control frame-

work for resource-limited adversaries. Automatica, 51:135–148, 2015.

37. U.S. Chemical Safety and Hazard Investigation Board, T2 Laboratories Inc. Re-
active Chemical Explosion: Final Investigation Report. Report No. 2008-3-I-FL,
2009.

38. F. van Breugel. On behavioural pseudometrics and closure ordinals. Inf. Process.

Lett., 112(19):715–718, 2012.

39. F. van Breugel and J. Worrell. A behavioural pseudometric for probabilistic tran-

sition systems. Theoretical Computer Science, 331(1):115–142, 2005.

40. R. Vigo. The Cyber-Physical Attacker. In SAFECOMP, volume 7613 of LNCS,

pages 347–356. Springer, 2012.

41. R. Vigo. Availability by Design: A Complementary Approach to Denial-of-Service.

PhD thesis, Danish Technical University, 2015.

42. R. Vigo, F. Nielson, and H. Riis Nielson. Broadcast, denial-of-service, and secure
communication. In IFM, volume 7940 of LNCS, pages 412–427. Springer, 2013.

43. C. Villani. Optimal transport, old and new. Springer, 2008.
44. Y. Zacchia Lun, A. D’Innocenzo, I. Malavolta, and M. D. Di Benedetto. Cyber-
Physical Systems Security: a Systematic Mapping Study. CoRR, abs/1605.09641,
2016.

A Proofs

To prove Theorem 1 we need some preliminary results. The ﬁrst of these results
is Proposition 7 below, which states that the pseudometric property is preserved
by function K, namely K(d) is a pseudometric over D(T ) whenever d is a pseu-
dometric over T . Lemma 1 supports Proposition 7.

Lemma 1. Assume two functions d, d′ : T × T → [0, 1] with d(t, t′) ≤ d′(t, t′′) +
d′(t′′, t) for all terms t, t′, t′′ ∈ T . Then K(d)(∆1, ∆2) ≤ K(d′)(∆1, ∆3)+K(d′)(∆3, ∆2)
for all distributions ∆1, ∆2, ∆3 ∈ D(T ).

Proof. Consider the function ω : T × T → [0, 1] deﬁned for all terms t1, t2 ∈ T
as

ω(t1, t2) =

Xt3∈T |∆3(t3)6=0

ω1(t1, t3) · ω2(t3, t2)
∆3(t3)

with ω1 ∈ Ω(∆1, ∆3) one of the optimal matchings realising K(d′)(∆1, ∆3), and
ω2 ∈ Ω(∆3, ∆2) one of the optimal matchings realising K(d′)(∆3, ∆2). We will
prove that:

1. ω is a matching in Ω(∆1, ∆2), and
2.

t1,t2∈T ω(t1, t2) · d(t1, t2) ≤ K(d′)(∆1, ∆3) + K(d′)(∆3, ∆2).

P

t1,t2∈T ω(t1, t2) · d(t1, t2), then by
By property 1 we infer K(d)(∆1, ∆2) ≤
property 2 we infer the thesis K(d)(∆1, ∆2) ≤ K(d′)(∆1, ∆3) + K(d′)(∆3, ∆2).
To show (1) we prove that the left marginal of ω is ∆1 by

P

=

P

=

P

=

=

P

≤

P

P

t2∈T ω(t1, t2)

t2∈T

t3∈T |∆3(t3)6=0

ω1(t1,t3)·ω2(t3,t2)
∆3(t3)

ω1(t1,t3)·∆3(t3)
P
t3∈T |∆3(t3)6=0
∆3(t3)
t3∈T |∆3(t3)6=0 ω1(t1, t3)

(by ω2 ∈ Ω(∆3, ∆2))

P
= ∆1(t1)
P
and we observe that the proof that the right marginal of ω is ∆2 is analogous.
Then, we show (2) by

(by ω1 ∈ Ω(∆1, ∆3))

t1,t2∈T ω(t1, t2) · d(t1, t2)

t1,t2∈T

t3∈T |∆3(t3)6=0

ω1(t1,t3)·ω2(t3,t2)
∆3(t3)

· d(t1, t2)

t1,t2∈T ,t3∈T |∆3(t3)6=0

P

ω1(t1,t3)·ω2(t3,t2)
∆3(t3)
ω1(t1,t3)·ω2(t3,t2)
∆3(t3)
· d′(t1, t3) +

· d′(t1, t3) +

· d′(t3, t2)

=

P

P

t1,t2∈T ,t3∈T |∆3(t3)6=0
ω1(t1,t3)·∆3(t3)
t1,t3∈T
∆3(t3)
t1,t3∈T ω1(t1, t3) · d′(t1, t3) +
=
= K(d′)(∆1, ∆3) + K(d′)(∆3, ∆2)
where the inequality follows from the hypothesis and the third last equality
follows by ω2 ∈ Ω(∆3, ∆2) and ω1 ∈ Ω(∆1, ∆2).
⊓⊔

t2,t3∈T ω2(t3, t2) · d′(t3, t2)

∆3(t3)·ω2(t3,t2)
∆3(t3)

· d′(t3, t2)

t2,t3∈T

P

P

P

Proposition 7. If d : T × T → [0, 1] is a 1-bounded pseudometric over T , then
K(d) : D(T ) × D(T ) → [0, 1] is a 1-bounded pseudometric over D(T ).

Proof. We have to prove that K(d) satisﬁes the three properties in Deﬁnition 2.

To show K(d)(∆, ∆) = 0 it is enough to take the matching ω ∈ Ω(∆, ∆)
deﬁned by ω(t, t) = ∆(t), for all t ∈ T , and ω(t, t′) = 0, for all t, t′ ∈ T with t 6= t′.
t,t′∈T ω(t, t′) · d(t, t′) =
In fact, we obtain K(d)(∆, ∆) = 0 by K(d)(∆, ∆) ≤
t∈T ∆(t) · d(t, t) = 0, with the last equality from the property d(t, t) = 0 of

P

the pseudometric d.
P

To show the symmetry property K(d)(∆1, ∆2) = K(d)(∆2, ∆1) it is enough
to observe that for any matching ω ∈ Ω(∆1, ∆2), the function ω′ : T × T → [0, 1]
deﬁned for all processes t1, t2 ∈ T as ω′(t1, t2) = ω(t2, t1), is a matching in
Ω(∆2, ∆1). In fact, by exploiting this property, given one of the optimal match-
ing ω ∈ Ω(∆1, ∆2) realising K(d)(∆1, ∆2) we get

K(d)(∆1, ∆2)

=

=

t1,t2∈T ω(t1, t2) · d(t1, t2)
t2,t1∈T ω′(t2, t1) · d(t2, t1)

P

≥ K(d)(∆2, ∆1)

P

with the second equality from the symmetry property d(t1, t2) = d(t2, t1) of the
pseudometric d. Then, by exchanging the role of ∆1 and ∆2 we get K(d)(∆2, ∆1) ≥
K(d)(∆1, ∆2), thus giving K(d)(∆1, ∆2) = K(d)(∆2, ∆1).

We conclude by observing that the triangular property K(d)(∆1, ∆2) ≤
K(d)(∆1, ∆3) + K(d)(∆3, ∆2) is an instance of Lemma 1, which can be applied
since the hypothesis d(t, t′) ≤ d(t, t′′) + d(t′′, t′) for all t, t′, t′′ ∈ T follows from
the triangular property of the pseudometric d.
⊓⊔

Now we prove that for all k ≥ 1, the function mk is a ﬁxed point of B.

Lemma 2. For all k ≥ 1, B(mk) = mk

Proof. First we note that structure ({d : T × T → [0, 1] | Btick(mk−1) ⊑ d}, ⊑),
with d1 ⊑ d2 iﬀ d1(t, t′) ≤ d2(t, t′) for all t, t′ ∈ T , is a complete lattice. In-
deed, for each set D ⊆ [0, 1]T ×T , the supremum and inﬁmum are deﬁned as
sup(D)(t, t′) = supd∈D d(t, t′) and inf(D)(t, t′) = inf d∈D d(t, t′), for all t, t′ ∈ T .
The inﬁmum of the lattice is clearly Btick(mk−1). Being B monotone, by the
Knaster-Tarski theorem B has a least ﬁxed point. Since our pLTS is image-ﬁnite,
and all transitions lead to distributions with ﬁnite support, with arguments anal-
ogous to those used in [38] it is possible to prove that B is continuous and its clo-
sure ordinal is ω, thus implying that its least ﬁxed point is the supremum of the
Kleene ascending chain Btick(mk−1) ⊑ B(Btick(mk−1)) ⊑ B2(Btick(mk−1)) ⊑
. . . = mk,0 ⊑ mk,1 ⊑ mk,2 ⊑ . . ., and, by deﬁnition, the supremum of this chain
is mk.

Now we exploit Lemma 2 to prove that for arbitrary processes t, t′ ∈ T ,
=⇒ ∆, besides those of the

process t′ is able to simulate transitions of the form t ˆα
form t α

−→ ∆, when α 6= tick.

Lemma 3. Given two arbitrary terms t, t′ ∈ T , whenever t ˆα
we have:

=⇒ ∆ for α 6= tick,

K(mk)(∆ + (1− |∆|)Dead, Θ + (1− |Θ|)Dead) ≤ mk(t, t′)

inf
t′ ˆα=⇒Θ

Proof. The thesis is immediate if mk(t, t′) = 1. Consider the case mk(t, t′) < 1.
We reason by induction on the length n of t ˆα

=⇒ ∆.

Base case n = 1. In this case t ˆα

−→ ∆. There
are two sub-cases. The ﬁrst is α = τ and ∆ = t, the second is t α
−→ ∆, with α an
arbitrary action in A \ {tick}. In the former case, by the deﬁnition of the weak
τ
τ
−−→ t′ and, consequently, t′ b
=⇒ t′. The
b

τ
−−→ we have that t′
transition relation b

=⇒ ∆ is directly derived from t ˆα

thesis holds for distribution Θ = t′. More precisely, we have that K(mk)(t+(1− |
t|)Dead, t′ + (1− |t′ |)Dead) = K(mk)(t, t′) = mk(t, t′). In the latter case, the
thesis follows directly by Deﬁnition 5 and Lemma 2. In detail, Deﬁnition 5 gives

K(mk)(∆, Θ + (1− |Θ|)Dead) ≤ B(mk)(t, t′)

inf
t′ ˆα=⇒Θ

and Lemma 2 gives B(mk)(t, t′) = mk(t, t′).
ˆα
=⇒ ∆ is obtained by t

ˆβ1==⇒ ∆′ and
Inductive step n > 1. The derivation t
ˆβ2−−→ ∆, for some distribution ∆′ ∈ D(T ) and actions β1, β2 ∈ A \ {tick}. We
∆′
have two sub-cases. The ﬁrst is β1 = τ and β2 = α, the other is β1 = α and
β2 = τ . We consider the case β1 = τ and β2 = α, the other is analogous.

The length of derivation t

ˆβ1==⇒ ∆′ is n − 1. Therefore, by the inductive

hypothesis we have

K(mk)(∆′ + (1− |∆′|)Dead, Θ′ + (1− |Θ′|)Dead) ≤ mk(t, t′)

(1)

inf
ˆβ1==⇒Θ′

t′

ˆβ1==⇒ Θ′}
Notice that mk(t, t′) < 1 and Equation 1 ensure that the set {Θ′ | t′
is not be empty. Moreover, being β1 = τ , we have that |∆′ |= 1 and, for each
ˆβ1==⇒ Θ′, also |Θ′|= 1. Therefore, the inductive hypothesis Equation 1
transition t′
instantiates to

K(mk)(∆′, Θ′) ≤ mk(t, t′)

(2)

inf
ˆβ1==⇒Θ′

t′

P

ˆβ2−−→, the transition ∆′

The sub-distribution ∆′ is of the form ∆′ =

i∈I pi · ti for suitable processes
ˆβ2−−→ ∆ is derived
t′
i and, by deﬁnition of transition relation
from a β2-transition by some of the processes ti, namely I is partitioned into sets
β2−−→ ∆i for suitable distributions
I1 ∪ I2 such that: (i) for all i ∈ I1 we have ti
pi · ∆i.
∆i, (ii) for each i ∈ I2 we have ti

, and (iii) ∆ =
ˆβ1==⇒ Θ′ (remember we argued above that
it is not possible that there are none). The sub-distribution Θ′ is of the form
Θ′ =
j. Then, J can be partitioned into sets
ˆβ2==⇒ Θj for suitable distributions
ˆβ2==⇒ Θ with

J1 ∪ J2 such that for all j ∈ J1 we have t′
j

Let us ﬁx an arbitrary transition t′

Θj and for each j ∈ J2 we have t′
j

j, for suitable processes t′

j∈J qj · t′

β2−−→6

i∈I1

P

P

P

j∈J1

Θ =

qj · Θj. Since we had t′

ˆα
=⇒ Θ. Notice
ˆβ1==⇒ Θ′ for which J1 6= ∅.
that we are sure that there exist some some Θ′ with t′
Indeed, if for all Θ′ with t′
, giving
B(mk)(t, t′) = 1 and contradicting B(mk)(t, t′) = mk(t, t′) < 1. We remark
ˆα
that in all cases where J1 6= ∅, the weak transition t′
=⇒ Θ is obtained by

ˆβ1==⇒ Θ′ we had J1 = ∅, this would cause t ˆα
=⇒6

ˆβ2==⇒6
. If J1 6= ∅ this gives Θ′
ˆβ1==⇒ Θ′, we can conclude t′

j, namely t′
j

ﬁrstly choosing one of the available weak transitions labelled ˆβ1 from t′, namely
ˆβ1==⇒ Θ′, and, then, by choosing one of the available weak transitions labelled
t′
β2 from t′

ˆβ2==⇒ Θj, for all j ∈ J1.
ˆβ1==⇒ Θ′ ﬁxed above, let ω be one of the optimal matchings
realising K(mk)(∆′, Θ′). We can rewrite the distributions ∆′ and Θ′ as ∆′ =
i∈I,j∈J ω(ti, t′
j. For all i ∈ I1 and j ∈ J,
j)·∆i,j. Analogously,
ˆβ2==⇒ qj · Θj can always

deﬁne ∆i,j = ∆i. We can rewrite ∆ as ∆ =
P
for each j ∈ J1 and i ∈ I we note that the transition qjt′
j

For the transition t′

j) · ti and Θ′ =

i∈I1,j∈J ω(ti, t′

i∈I,j∈J ω(ti, t′

j) · t′

P

P

be split into
as Θj =

i∈I ω(ti, t′

j)t′
j

ˆβ2==⇒
i∈I ω(ti, t′
j) · Θi,j and Θ as Θ =

i∈I ω(ti, t′
P

P

note that for all i ∈ I1 and j ∈ J1, all transition t′
j

P

P

j) · Θi,j so that we can rewrite Θj
j) · Θi,j . Then we

ω(ti, t′

i∈I,j∈J1

ˆβ2==⇒ Θi,j ensure that

K(mk)(∆i,j , Θi,j + (1− |Θi,j|)Dead) ≤ mk(ti, t′
j)

(3)

inf
ˆβ2==⇒Θi,j

t′
j

Indeed, by deﬁnition of B, whenever ti

β2−−→ ∆i = ∆i,j we have

K(mk)(∆i,j , Θi,j + (1− |Θi,j|)Dead) ≤ B(mk)(ti, t′
j)

inf
ˆβ2==⇒Θi,j

t′
j

Then, being mk a ﬁxed point of B we have B(mk)(ti, t′
Equation 3 follows.

j) = mk(ti, t′

j) and

Consider any j ∈ J1 and i ∈ I1. By Equation 3 and B(mk)(ti, t′

j),
we infer that if if mk(ti, t′
j) < 1, then the set of the weak transitions labelled
ˆβ2==⇒ Θi,j , let ωi,j be one
ˆβ2 from t′
of the optimal matchings realising K(mk)(∆i,j , Θi,j + (1− |Θi,j |)Dead). Deﬁne
ω′ : T × T → [0, 1] as the function such that for arbitrary processes u, v ∈ T we
have:

j cannot be empty. For any transition t′
i

j) = mk(ti, t′

ω′(u, v) =

ω(ti, t′

j)ωi,j (u, v)

if u 6= Dead 6= v

ω(ti, t′

j)ωi,j (u, v) +

ω(ti, t′

j)∆i,j (u)

if u 6= Dead = v

ω(ti, t′

j)ωi,j (u, v) +

ω(ti, t′

j)ωi,j (u, v) +

i∈I1,j∈J2
X

i∈I2,j∈J1
X

ω(ti, t′

j)Θi,j (v)

if u = Dead 6= v

ω(ti, tj)∆i,j (u)+

ω(ti, t′

j)Θi,j (v) +

i∈I1,j∈J2
X

ω(ti, t′
j)

i∈I2,j∈J2
X

if u = Dead = v.

i∈I1,j∈J1
X

i∈I1,j∈J1
X

i∈I1,j∈J1
X

i∈I1,j∈J1
X






i∈I2,j∈J1
X
To infer the proof obligation

K(mk)(∆ + (1− |∆|)Dead, Θ + (1− |Θ|)Dead) ≤ mk(t, t′)

(4)

inf
t′ ˆα=⇒Θ

it is now enough to show that:

1. the function ω′ is a matching in Ω(∆ + (1− |∆|)Dead, Θ + (1− |Θ|)Dead)
2.

inf
ˆβ1==⇒Θ′
t′
Θ′ =Pj∈J1 ∪J2
t′
j

ˆβ2==⇒Θi,j

qj δ(t′
j )

ω′(u, v) · mk(u, v) ≤ mk(t, t′)

(5)

u,v∈T
X

To show property 1 we prove that the left marginal of ω′ is ∆ + (1− |∆|)Dead.
The proof that the right marginal is Θ + (1− |Θ|)Dead is analogous. For any
process u 6= Dead we have

v∈T ω′(u, v)

v6=Dead

i∈I1,j∈J1
ω(ti, t′

i∈I1,j∈J1

P

ω(ti, t′
j)ωi,j (u, v)
j)ωi,j (u, Dead) +
v∈T ωi,j(u, v) +

P

P
i∈I1,j∈J1

ω(ti, t′
j)
ω(ti, t′
j)∆i,j (u) +
P
i∈I1,j∈J1
i∈I1,j∈J ω(ti, t′
j)∆i,j (u)
pi∆i(u)

P

=

=

=

=

P
+
P

P

P

=

P
i∈I1
= ∆(u)
P

i∈I1,j∈J2

ω(ti, t′
ω(ti, t′

j)∆i,j (u)
j)∆i,j(u)

i∈I1,j∈J2
ω(ti, t′

j)∆i,j(u)

P
i∈I1,j∈J2

= (∆ + (1− |∆|)Dead)(u)

with the third equality from the fact that ωi,j is a matching in Ω(∆i,j , Θi,j), the
j) = pi and
fourth equality by J = J1 ∪ J2 and the ﬁfth equality by
∆i,j = ∆i. Consider now Dead. We have

j∈J ω(ti, t′

P

v∈T ω′(Dead, v)

P
+
P
+

v6=Dead

i∈I1,j∈J1

P

P

i∈I2,j∈J1

i∈I1,j∈J1
ω(ti, t′
ω(ti, t′

ω(ti, t′

j)ωi,j (Dead, v) +

v6=Dead

i∈I2,j∈J1

ω(ti, t′

j)Θi,j (v)

j)ωi,j (Dead, Dead) +
j)Θi,j (Dead) +

P
i∈I1,j∈J2

ω(ti, t′
P
ω(ti, t′
j)

P
i∈I2,j∈J2

j)∆i,j (Dead)

P
v∈T

i∈I1,j∈J1

ω(ti, t′

j)ωi,j(Dead, v) +

P

v∈T

i∈I2,j∈J1

ω(ti, t′

j)Θi,j(v)

+
P

P
i∈I1,j∈J2

ω(ti, t′

j)∆i,j (Dead) +

P
i∈I2,j∈J2

P
i∈I1,j∈J1

ω(ti, t′

j)∆i,j (Dead) +

P
i∈I2,j∈J1

+
P

i∈I1,j∈J2
i∈I1,j∈J ω(ti, t′
P

ω(ti, t′

j)∆i,j (Dead) +
P

j)∆i,j (Dead) +

i∈I2,j∈J2
i∈I2,j∈J ω(ti, t′
j)
P

ω(ti, t′
j)
P
ω(ti, t′
j)
ω(ti, t′
j)

=

P

pi∆i(Dead) +

i∈I1

i∈I2
= (∆ + (1− |∆|)Dead)(Dead)

P

P

pi

P

where the third equality by the fact that ωi,j is a matching in Ω(∆i,j , Θi,j) and
the fact that Θi,j is a distribution, the fourth equality by J = J1 ∪ J2, the ﬁfth

=

=

=

=

j∈J ω(ti, t′

equality by

j) = pi and ∆i,j = ∆i and the last equality follows from
i∈I1

pi =|∆|.
i∈I1,j∈J ω(si, tj) =
P
Summarising, for all processes u ∈ T we have proved that

v∈T ω′(u, v) =
P
(∆ + (1− |∆|)Dead)(u), thus conﬁrming that the left marginal of ω′ is ∆ + (1− |
∆|)Dead.

P

P

To prove (2), by looking at the deﬁnition of ω′ given above we get that
u,v∈T ω′(u, v) · mk(u, v) is the summation of the following values:

P
–

u6=Dead6=v

i∈I1,j∈J1

ω(ti, t′

j)ωi,j (u, v)mk(u, v)

P

–

u6=Dead

i∈I1,j∈J2
P

P
i∈I1,j∈J1
ω(ti, t′

ω(ti, t′

j)ωi,j(u, Dead)mk(u, Dead) +

j)∆i,j(u)mk(u, Dead)

v6=Dead

i∈I2,j∈J1
P

i∈I1,j∈J1
ω(ti, t′

j)Θi,j (v)mk(Dead, v)

ω(ti, t′

j)ωi,j(Dead, v)mk(Dead, v) +

i∈I1,j∈J2

i∈I1,j∈J1

ω(ti, t′
ω(ti, t′
ω(ti, t′
ω(ti, t′

j)ωi,j(Dead, Dead)mk(Dead, Dead) +
j)∆i,j(Dead)mk(Dead, Dead) +
j)Θi,j (Dead)mk(Dead, Dead)+
j)mk(Dead, Dead).

P
P
P
By moving the ﬁrst summand of the second, third and fourth items to the
P
ﬁrst item, we rewrite this summation as the summation of the following values:

i∈I2,j∈J2

i∈I2,j∈J1

u,v∈T

i∈I1,j∈J1

ω(ti, t′

j)ωi,j(u, v)mk(u, v)

P

P
i∈I1,j∈J2

ω(ti, t′

j)∆i,j(u)mk(u, Dead)

i∈I2,j∈J1

ω(ti, t′

j)Θi,j (v)mk(Dead, v)

P
P

P
P

–

–

–

–

–

–

P

P

i∈I1,j∈J2

ω(ti, t′
ω(ti, t′
ω(ti, t′

j)∆i,j(Dead)mk(Dead, Dead) +
j)Θi,j (v)mk(Dead, Dead) +
j)mk(Dead, Dead).

i∈I2,j∈J1

inf
P

i∈I2,j∈J2

P
P
Since the function ωi,j was deﬁned as one of the optimal matchings real-
P
ising K(mk)(∆i,j , Θi,j + (1− | Θi,j |)Dead), the ﬁrst item can be rewritten as
j) K(mk)(∆i,j , Θi,j + (1− |Θi,j|)Dead). From Equation 3 we get
j). Henceforth the

ω(ti, t′
K(mk)(∆i,j , Θi,j + (1− |Θi,j |)Dead)) ≤ mk(ti, t′

i∈I1,j∈J1
ˆβ2==⇒Θi,j
inﬁmum for all t′
j
mk(ti, t′
third item is clearly less or equal than

ˆβ2==⇒ Θi,j of the ﬁrst item is less or equal

j). The second item is clearly less or equal than
ω(ti, t′

j) ·
j). The
j). Finally, the last item
P
ˆβ2==⇒ Θi,j of
P
u,v∈T ω′(u, v) · mk(u, v) is bounded by the summation of the following three

is 0 since mk(Dead, Dead) = 0. Namely, the inﬁmum for all t′
j

i∈I1,j∈J2
P

ω(ti, t′

ω(ti, t′

i∈I2,j∈J1

i∈I1,j∈J1

t′
j

values:
P

–
–
–

i∈I1,j∈J1

i∈I1,j∈J2

i∈I2,j∈J1

j)mk(ti, t′
ω(ti, t′
j)
ω(ti, t′
j)
ω(ti, t′
j).

P
P
Formally:
P

t′
j

inf
ˆβ2==⇒Θi,j X
≤

u,v∈T

ω′(u, v) · mk(u, v)

ω(ti, t′

j)mk(ti, t′

j) +

ω(ti, t′

j) +

ω(ti, t′
j)

(6)

i∈I1,j∈J1
X

i∈I1,j∈J2
X

i∈I2,j∈J1
X

Then, since K(mk)(∆′, Θ′) is the summation of the following values:

–

–

–

–

i∈I1,j∈J1

ω(ti, t′

P
i∈I1,j∈J2
give mk(ti, t′
P

i∈I2,j∈J1
give mk(ti, t′
P

i∈I2,j∈J2

ω(ti, t′
j) = 1)
ω(ti, t′
j) = 1)
ω(ti, t′

j)mk(ti, t′
j)
j)mk(ti, t′

j) =

j)mk(ti, t′

j) =

j)mk(ti, t′
j)

i∈I1,j∈J2

ω(ti, t′

j) (since ti

β2−−→ and t′

j

ˆβ2==⇒6

P

i∈I2,j∈J1

ω(ti, t′

j) (since t′
j

β2−−→ and ti

ˆβ2==⇒6

P

we infer that the right hand side of Equation 6

P

ω(ti, t′

i∈I1,j∈J2

j) +
Together with Equation 6 this gives
P

i∈I2,j∈J1

P

ω(ti, t′

j) +
j) is less or equal than K(mk)(∆′, Θ′).

j) · mk(ti, t′

ω(ti, t′

i∈I1,j∈J1

P

inf
ˆβ2==⇒Θi,j X

u,v∈T

t′
j

ω′(u, v) · mk(u, v) ≤ K(mk)(∆′, Θ′)

(7)

which, together with Equation 2 gives Equation 5, which concludes the proof.

⊓⊔

We are now ready to prove Theorem 1.

Proof (of Theorem 1). We have to prove that mk satisﬁes the three properties
in Deﬁnition 2. Properties mk(t, t) = 0 and mk(t, t′) = mk(t′, t) for all t, t′ ∈
T are immediate. The interesting case is the triangular property mk(t, t′) ≤
mk(t, t′′) + mk(t′′, t′) for all t, t′, t′′ ∈ T . To this purpose, let us deﬁne the
function m : T × T → [0, 1] such that

m(t, t′) = min

mk(t, t′),
(cid:16)

inf
t′′∈T

(mk(t, t′′) + mk(t′′, t′))
(cid:17)

.

We will prove that m = mk. By the deﬁnition of m, this gives mk(t, t′) ≤
mk(t, t′′) + mk(t′′, t′) for all t′′ ∈ T , thus conﬁrming that also the triangular
property holds for mk.

In order to prove m = mk, we observe ﬁrst that relation m ⊑ mk follows
immediately by the deﬁnition of m. It remains to prove mk ⊑ m. To this pur-
pose we prove that: (i) mk is the least preﬁxed point of the functional B on

the complete lattice ({d : T × T → [0, 1] : Btick(mk−1) ⊑ d}, ⊑), and (ii) m is a
preﬁxed point of the same functional on the same lattice.

Let us start with property (i) By Lemma 2, mk is the least ﬁxed point of the
functional B, which is monotone and continuous in the lattice. This coincides
with the least preﬁxed point.

Let us consider now (ii). We have to prove B(m) ⊑ m, namely, whenever

m(t, t′) < 1, then, for all α 6= tick we have

∀t

α
−−→ ∆.

inf
t′ ˆα=⇒Θ

K(m)(∆, Θ + (1− |Θ|)Dead) ≤ m(t, t′).

(8)

To prove Equation 8 we distinguish two cases, namely m(t, t′) = mk(t, t′) and
m(t, t′) = inf t′′∈T (mk(t, t′′) + mk(t′′, t′)).

Assume ﬁrst m(t, t′) = mk(t, t′). In this case, being mk the least ﬁxed point

of B, t

α
−−→ ∆ implies that

K(mk)(∆, Θ + (1− |Θ|)Dead) ≤ B(mk)(t, t′) = mk(t, t′) = m(t, t′)

inf
t′ ˆα=⇒Θ

Since K is monotone and m ⊑ mk, we infer

K(m)(∆, Θ + (1− |Θ|)Dead) ≤ m(t, t′)

inf
t′ ˆα=⇒Θ

thus giving Equation 8.

Assume now m(t, t′) = inf t′′∈T (mk(t, t′′) + mk(t′′, t′)). Since m(t, t′) < 1,
there exist terms t′′ ∈ T with mk(t, t′′) + mk(t′′, t′) < 1, thus implying both
α
mk(t, t′′) < 1 and mk(t′′, t′) < 1. By Lemma 3, from mk(t, t′′) < 1 and t
−−→ ∆
we infer

K(mk)(∆, Φ + (1− |Φ|)Dead) ≤ mk(t, t′′)

inf
t′′ ˆα=⇒Φ

By Lemma 3, from mk(t′′, t′) < 1, for all t′′

ˆα
==⇒ Φ we have

K(mk)(Φ + (1− |Φ|)Dead, Θ + (1− |Θ|)Dead) ≤ mk(t′′, t′)

inf
t′ ˆα=⇒Θ

By the deﬁnition of m and Lemma 1 we have K(mk)(∆, Φ + (1− |Φ|)Dead) +
K(mk)(Φ + (1− |Φ|)Dead), Θ + (1− |Θ|)Dead) ≥ K(m)(∆, Θ + (1− |Θ|)Dead).
We derive

K(m)(∆, Θ + (1− |Θ|)Dead) ≤ mk(t, t′′) + mk(t′′, t′)

inf
ˆα=⇒Φ
ˆα=⇒Θ

t′′
t′

and, by deﬁnition of inﬁmum,

K(m)(∆, Θ + (1− |Θ|)Dead) ≤ m(t, t′)

inf
ˆα=⇒Φ
ˆα=⇒Θ

t′′
t′

which gives Equation 8 and concludes the proof.

⊓⊔

We prove now Proposition 2.

Proof (of Proposition 2). We prove the ﬁrst item, then the second item follows
by the ﬁrst and the result t ≃0 t′ iﬀ t ≈ t′ given in [8]. First we recall that
t ≃p t′ iﬀ m(t, t′) = p, where m is the least ﬁxed point (and also least preﬁxed
point) in the lattice ([0, 1]T ×T , ⊑) of a functional B′ such that B′(d)(t, t′) =
max(B(d)(t, t′), Btick(d)(t, t′)) for all t, t′ ∈ T and d ∈ [0, 1]T ×T . Therefore, we
have to prove that m∞ = m.

Let us start with m∞ ⊑ m. Being m∞ the supremum of all mk, it is enough
to show mk ⊑ m for all k ∈ IN. This property can be shown by induction
over k. The base case is immediate since m0 = 0. Consider the inductive step
k + 1. Function mk+1 is obtained as supn→∞ Bn(Btick(mk)). Assume any n ∈ IN.
By B′ ≥ B, Btick we get Bn(Btick(mk)) ⊑ (B′)n+1(mk) for all n ∈ IN. By the
monotonicity of B′ and the inductive hypothesis mk ⊑ m, we get (B′)n+1(mk) ⊑
(B′)n+1(m). Finally, since m is a ﬁxed point of B′ we infer (B′)n+1(m) = m.
Summarising, Bn(Btick(mk)) ⊑ m. By the arbitrarity of n we infer m∞ ⊑ m.

Let us show now m ⊑ m∞. Being m the least preﬁxed point of B′, it is
enough to show that m∞ is a preﬁxed point of B′. We have both m∞ ⊒ B(m∞)
and m∞ ⊒ Btick(m∞), thus giving m∞ ⊒ B′(m∞), conﬁrming that m∞ is a
preﬁxed point of B′.
⊓⊔

Now we prove Theorem 2.

Proof (of Theorem 2). We prove the second item. The proof of the third item is
analogous, then the ﬁrst item is a consequence of the others. To prove the thesis
we can prove that for all k ∈ IN we have

mk(ξ ⋊⋉ P1 k P2 k A, ξ ⋊⋉ P1 k P2)

≤ mk(ξ ⋊⋉ P1 k A, ξ ⋊⋉ P1) + mk(ξ ⋊⋉ P2 k A, ξ ⋊⋉ P2)
− (mk(ξ ⋊⋉ P1 k A, ξ ⋊⋉ P1) · mk(ξ ⋊⋉ P2 k A, ξ ⋊⋉ P2))

Since ξ ⋊⋉ P1 k P2 k A can mimic all the behaviours by ξ ⋊⋉ P1 k P2, the distance
mk(ξ ⋊⋉ P1 k P2 k A, ξ ⋊⋉ P1 k P2) is given by the behaviours by ξ ⋊⋉ P1 k P2 k A
that are not mimicked by ξ ⋊⋉ P1 k P2. Then, since ξ ⋊⋉ P1 k A k P2 k A can
mimic all the behaviours by ξ ⋊⋉ P1 k P2 k A, we have that

mk(ξ ⋊⋉ P1 k P2 k A, ξ ⋊⋉ P1 k P2) ≤ mk(ξ ⋊⋉ P1 k A k P2 k A, ξ ⋊⋉ P1 k P2)

thus implying that to have the proof obligation we can prove the stronger prop-
erty

mk(ξ ⋊⋉ P1 k A k P2 k A, ξ ⋊⋉ P1 k P2)

≤ mk(ξ ⋊⋉ P1 k A, ξ ⋊⋉ P1) + mk(ξ ⋊⋉ P2 k A, ξ ⋊⋉ P2)
− (mk(ξ ⋊⋉ P1 k A, ξ ⋊⋉ P1) · mk(ξ ⋊⋉ P2 k A, ξ ⋊⋉ P2)).

More in general, we prove

mk(ξ ⋊⋉ Q1 k Q2, ξ ⋊⋉ P1 k P2)

≤ mk(ξ ⋊⋉ Q1, ξ ⋊⋉ P1) + mk(ξ ⋊⋉ Q2, ξ ⋊⋉ P2)
− (mk(ξ ⋊⋉ Q1, ξ ⋊⋉ P1) · mk(ξ ⋊⋉ Q2, ξ ⋊⋉ P2))

for arbitrary Q1 and Q2, written also

mk(M1 k M2, N1 k N2) ≤

mk(M1, N1) + mk(M2, N2) − (mk(M1, N1) · mk(M2, N2)).

(9)

To this purpose, ﬁrst we need to introduce the notion of congruence closure
for mk as the quantitative analogue of the well-known concept of congruence
closure of a process equivalence. We deﬁne the metric congruence closure of mk
for operator k w.r.t. the bound provided in Equation 9 as a function m assigning
to each pair of systems a distance in [0, 1] given by

min(m(M1, N1) + m(M2, N2) − (m(M1, N1)m(M2, N2)), mk(M, N ))
M = M1 k M2 ∧ N = N1 k N2 ∧
mk(M1, N1) < 1 ∧ mk(M2, N2) < 1

if

"

mk(M, N ) otherwise

m(M, N ) = 



We note that m satisﬁes by construction m(M1 k M1, N1 k N2) ≤ m(M1, N1)+
m(M2, N2) − (m(M1, N1) · m(M2, N2)). We note also that m satisﬁes by con-
struction m ⊑ mk. It remains to show that mk ⊑ m, thus giving mk = m,
and Equation 9 holds. Since mk is the least preﬁxed point of B over the lat-
tice ({d : T × T → [0, 1] | Btick(mk−1) ⊑ d}, ⊑) to show mk ⊑ m it is enough to
prove that m is a preﬁxed point of the same functional on the same lattice.

To prove that B(m) ⊑ m we need to show that m satisﬁes the transfer

condition of the bisimulation metrics, namely

∀M

α
−−→ γ. ∃M ′

α
==⇒ γ′. K(m)(γ, γ′ + (1− | γ′ |)Dead) ≤ m(M, M ′)

(10)

for all systems M, M with m(M, M ′) < 1 and α 6= tick.

This can be proved by applying the same arguments used to prove Proposi-
⊓⊔

tion 3.2 in [11].

Proof of Proposition 3 First we observe that in the evolution of both sys-
tems ξ ⋊⋉ Ctrli and ξ ⋊⋉ Ctrli k Afphi, m, ni it never happens that there are more
than two instantaneous actions in between any two tick actions. This implies
that for all j ∈ IN, system M reachable from ξ ⋊⋉ Ctrli and system N reach-
able from ξ ⋊⋉ Ctrli k Afphi, m, ni, we have mj(M, N ) = suph∈IN mj,h(M, N ) =
mj,2(M, N ). Then, the proof follows from the following 7 properties, by observ-
ing that ﬁrst item of the thesis follows from the property expressed by item 1
below and the second and third items of the thesis follow from the property
expressed by item 7 below, when, respectively, j1 = j − m + 1 and j2 = m − 1.
For any j ∈ IN, it holds that:

1. mj,l(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 0 for any P and whenever process Q has the form

Q = tickj′

.Bhi, n − m + 1i for some j < j′.

2. mj,0(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 1 − (p+

i )j−1 whenever 0 < j ≤ n − m + 1, ξ(ri) =
absence, and the processes P and Q have the form P = tick.Ctrli and Q =
Bhi, n − m + 1 − ji.

3. mj,1(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 1 − (p+

i )j−1 whenever 0 < j ≤ n − m + 1, ξ(ri) =
absence, and the processes P and Q have the form P = ci!on.tick.Ctrli and
Q = Bhi, 0, n − m + 1 − ji.
4. mj(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 1−(p+

i )j whenever 0 < j ≤ n−m+1, ξ(ri) = absence,
and the processes P and Q have the form P = Ctrli and Q = Bhi, n − m + 1i.
i )j1 whenever processes P and Q have the
form P = tick.Ctrli and Q = tickj2 .Bhi, n − m + 1i, for some 0 < j2 ≤ j such
that j1 = min(j − j2 + 1, n − m + 1).

5. mj,0(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 1 − (p+

6. mj,1(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 1 − (p+

i )j1 whenever processes P has either the
form P = ci!on.tick.Ctrli or P = ci!oﬀ.tick.Ctrli , and process Q has the
form Q = tickj2 .Bhi, n − m + 1i, for some 0 < j2 ≤ j such that j1 =
min(j − j2 + 1, n − m + 1).
7. mj(ξ ⋊⋉ P, ξ ⋊⋉ P k Q) = 1 − (p+

i )j1 whenever processes P and Q have the
form form P = Ctrli and Q = tickj2 .Bhi, n − m + 1i, for some 0 < j2 ≤ j
such that j1 = min(j − j2 + 1, n − m + 1).

The seven properties above can be proved for all mj and mj,l by well founded

induction over the relation ≺ deﬁned as follows:
– mj ≺ m if m ∈ {mj′
– mj,l ≺ m if either m ∈ {mj′

, mj′,l} with j < j′

, mj′,l} with j < j′, or, m = mj′,l′

with j′ = j

and l < l′.

Obviously, ≺ is irreﬂexive and there does not exist any inﬁnite descending chain
(the base case is m0).

The base case j = 0 is immediate since m0 is the constant zero function 0

and 1 − (p+

i )0 = 0.

We consider the inductive step.

1. The thesis can be easily proved since Q can perform only tick actions and,

tick
−−−→

tick
−−−→

intuitively, it does not aﬀect the behaviour of P .
i∈I ξi ⋊⋉ Pi,
In detail, for j = 1 and l = 0, we have that whenever ξ ⋊⋉ P
i∈I ξi ⋊⋉ Pi k Q′ with Q = tickj′−1.Bhi, n − m + 1i.
then ξ ⋊⋉ P k Q
Hence the thesis follows, since m0(ξi ⋊⋉ Pi, ξi ⋊⋉ Pi k Q′) = 0 by deﬁnition of
m0.
Assume now l > 0. In this case, whenever ξ ⋊⋉ P
α 6= tick, then ξ ⋊⋉ P k Q
induction on case item 1, we have mj,l−1(ξ ⋊⋉ Pi, ξ ⋊⋉ Pi k Q) = 0.
P
Similarly, for l = 0 and j > 1, whenever ξ ⋊⋉ P
ξ ⋊⋉ P k Q

i∈I ξi ⋊⋉ Pi, then
i∈I ξi ⋊⋉ Pi k Q′ with Q′ = tickj′−1.Bhi, n − m + 1i. Hence

α
i∈I ξ ⋊⋉ Pi with
−−→
i∈I ξ ⋊⋉ Pi k Q. The thesis holds since, by

tick
−−−→

tick
−−−→

α
−−→

P

P

P

P

P

the thesis holds since, by induction on case item 1, for any h, it holds that
mj−1,h(ξi ⋊⋉ Pi, ξi ⋊⋉ P k Q′) = 0 thus implying that

mj−1(ξi ⋊⋉ Pi, ξi ⋊⋉ P k Q′) = sup
h∈IN∞

mj−1,h(ξi ⋊⋉ Pi, ξi ⋊⋉ P k Q′) = 0.

2. Deﬁne M = ξ ⋊⋉ P and N = ξ ⋊⋉ P k Q. We have that mj.0(M, N ) =
Btick(mj−1)(M, N ) = Btick(mj−1,2)(M, N ). Hence we have to prove that
Btick(mj−1,2)(M, N ) = 1 − (p+
i )j−1. Such a property follows by the follow-
ing two facts:
– max
M

K(mj−1,2)(∆, Θ + (1− |Θ|)Dead) = 1 − (p+

i )j−1

min
tick==⇒Θ

tick−−→∆

N

– max
N

tick−−→Θ

min
tick==⇒∆

M

K(mj−1,2)(∆ + (1− |∆|)Dead, Θ) = 1 − (p+

i )j−1.

We prove with the ﬁrst case, the second one is similar.
The only transitions by M are of the form M
next(ξ). The environments ξ′ ∈ next(ξ) maximising the set

tick
−−−→ ξ′ ⋊⋉ Ctrli with ξ′ ∈

K(mj−1,2)(ξ′ ⋊⋉ Ctrli , Θ)

min
tick==⇒Θ

N

are such that ξ′
x(ri) = absence. Indeed the attacker could force N to perform
ci!on with probability equal to 1. If ξ′(ri) = absence, then M will perform
ci!on with probability p+
i . Hence M does not simulate N with a probability
1 − p+
i . Otherwise, if ξ′(ri) = presence, then M will perform ci!on with
probability 1 − p−
i . Hence M does not simulate N with a probability p−
i .
Since 0 ≤ p+
i < 1
The system N = ξ ⋊⋉ P k Q minimises

2 , then 1 − p+

i > p−
i .

i , p−

K(mj−1,2)(ξ′ ⋊⋉ Ctrli , Θ)

min
tick==⇒Θ

N

by simulating M with the transition N
Bhi, max(0, n − m + 1 − j − 1)i.
The only admissible matching ω for K(mj−1,2)(ξ′ ⋊⋉ Ctrli ξ′ ⋊⋉ Ctrli k Q′) is
such that ω(ξ′ ⋊⋉ Ctrli , ξ′ ⋊⋉ Ctrli k Q′) = 1.
Summarising we have:

tick
−−−→ ξ′ ⋊⋉ Ctrli k Q′ with Q′ =

max

M

tick−−→∆

min

N

tick==⇒Θ

K(mj−1,2)(∆, Θ + (1− |Θ|)Dead)

= min

N

tick==⇒Θ

K(mj−1,2)(ξ′ ⋊⋉ Ctrli , Θ)

with ξ′(ri) = absence

= K(mj−1,2)(ξ′ ⋊⋉ Ctrli , ξ′ ⋊⋉ Ctrli k Q′)

= mj−1,2(ξ′ ⋊⋉ Ctrli , ξ′ ⋊⋉ Ctrli k Q′)

(by induct. on case item 4)

= 1 − (p+

i )j−1

which completes the the proof.

3. Deﬁne M = ξ ⋊⋉ P and N = ξ ⋊⋉ P k Q.

Analogously to item 2, to prove B(mj,0)(M, N ) = 1 − (p+
to prove the following two facts:

i )j−1 it is suﬃcient

– max

– max

ci !on
−−−→∆
ci!on
−−−→Θ

M

N

min

N

min

M

ci!on
===⇒Θ
ci!on
===⇒∆

K(mj,0)(∆, Θ + (1− |Θ|)Dead) = 1 − (p+
K(mj,0)(∆+(1− |∆|)Dead, Θ) = 1−(p+

i )j−1
i )j−1.

We prove the ﬁrst case, the second one is similar.
ci!on
The only transition by M = ξ ⋊⋉ P is M
−−−−→ ξ ⋊⋉ tick.Ctrli . The only
ci!on
transition by N = ξ ⋊⋉ P k Q is N
−−−−→ ξ ⋊⋉ tick.Ctrli k Q.
The only admissible matching ω for K(mj−1,0)(ξ ⋊⋉ tick.Ctrli , ξ ⋊⋉ tick.Ctrli k Q)
is such that ω(ξ ⋊⋉ tick.Ctrli , ξ ⋊⋉ tick.Ctrli k Q) = 1.
Summarising we have:

max

M

ci!on
−−−→∆

min

ci !on
===⇒Θ

N

K(mj−1,0)(∆, Θ + (1− |Θ|)Dead)

= min

N

ci!on
===⇒Θ

K(mj−1,0)(ξ ⋊⋉ tick.Ctrli , Θ)

= K(mj−1,0)(ξ ⋊⋉ tick.Ctrli , ξ ⋊⋉ tick.Ctrli k Q )

= mj−1,0(ξ ⋊⋉ tick.Ctrli , ξ ⋊⋉ tick.Ctrli k Q)

(by induct. on case item 2)

= 1 − (p+

i )j−1

which completes the the proof.

4. Deﬁne M = ξ ⋊⋉ P and N = ξ ⋊⋉ P k Q.

N

N

M

i )j

min
min

τ−→∆
τ−→Θ

Since mj = mj,2, analogously to item 2, to prove B(mj,1)(M, N ) = 1−(p+
it is suﬃcient to prove the following two facts:
τ=⇒Θ
τ=⇒∆

K(mj,1)(∆, Θ + (1− |Θ|)Dead) ≤ 1 − (p+
K(mj,1)(∆ + (1− |∆|)Dead, Θ) = 1 − (p+

– max
– max

The interesting case is the second. Indeed, N is always able to simulate M
by considering the case in which the controller reads the right value of the
sensor and does not take the value provided by the attacker. The system
N = ξ ⋊⋉ P k Q can perform two transitions depending on the fact that
the controller reads or not the fake value provided by the attacker. But,
obviously, the system N = ξ ⋊⋉ P k Q maximises

i )j
i )j .

M

max
τ−→Θ
N

min
τ=⇒∆

M

K(mj,1)(∆ + (1− |∆|)Dead, Θ)

τ
when the controller reads the fake value, namely by the transition N b
=⇒
γN = N ′ where N ′ = ξ ⋊⋉ ci!on.tick.Ctrli .
The system M = ξ ⋊⋉ P minimises

K(mj,1)(∆ + (1− |∆|)Dead, γN )

min
τ=⇒∆

M

by simulating N by the transition

M

τ
−−→ γM = (p+

i ) · M1 + (1 − p+

i ) · M2

where M1 = ξ ⋊⋉ ci!on.tick.Ctrli and M2 = ξ ⋊⋉ ci!oﬀ.tick.Ctrli .
Moreover, the only admissible matching ω for K(mj.1)(γM , γN ) is such that
ω(M1, N ′) = p+
Summarising:

i and ω(M2, N ′) = 1 − p+
i .

max

N

τ−→Θ

min

M

τ=⇒∆

K(mj,1)(∆ + (1− |∆|)Dead, Θ)

K(mj,1)(∆ + (1− |∆|)Dead, γN )

= min

M

τ=⇒∆
= K(mj.1)(γM , γN )

= (p+

i ) · mj,1(M1, N ′) + (1 − p+

i ) · mj,1(M2, N ′)

= (p+

i ) · (1 − (p+

i )j−1) + (1 − p+

i ) · 1

(by induct. on case item 3)

= 1 − (p+

i )j.

which completes the proof.

5. The proof is similar to the proof of item 2. Indeed this case can be proved by
induction on case item 4 if j = j1 and j2 = 1, and, on case item 7 if j2 > 1.
6. The proof is similar to the proof of item 3. Indeed this case can be proved

by induction on case item 5.

7. The proof is similar to the proof of item 4. Indeed this case can be proved

by induction on case item 6.

Proof of Proposition 5
considering p−
i

instead of p+

⊓⊔
The proof is similar to that of Proposition 3 by
⊓⊔

i , and, Ch. . .i instead of Bh. . .i.

