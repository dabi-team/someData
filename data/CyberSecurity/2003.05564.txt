0
2
0
2

r
a

M
2
1

]

R
C
.
s
c
[

1
v
4
6
5
5
0
.
3
0
0
2
:
v
i
X
r
a

IEEE TRANASCTIONS ON XXXXXX

1

Securing Autonomous Service Robots through
Fuzzing, Detection, and Mitigation

Chundong Wang, Yee Ching Tok, Rohini Poolat, Sudipta Chattopadhyay, and Mohan Rajesh Elara

Abstract—Autonomous service robots share social spaces with humans, usually working together for domestic or professional tasks.
Cyber security breaches in such robots undermine the trust between humans and robots. In this paper, we investigate how to
apprehend and inﬂict security threats at the design and implementation stage of a movable autonomous service robot. To this end, we
leverage the idea of directed fuzzing and design ROBOFUZZ that systematically tests an autonomous service robot in line with the
robot’s states and the surrounding environment. The methodology of ROBOFUZZ is to study critical environmental parameters affecting
the robot’s state transitions and subject the robot control program with rational but harmful sensor values so as to compromise the
robot. Furthermore, we develop detection and mitigation algorithms to counteract the impact of ROBOFUZZ. The difﬁculties mainly lie in
the trade-off among limited computation resources, timely detection and the retention of work efﬁciency in mitigation. In particular, we
propose detection and mitigation methods that take advantage of historical records of obstacles to detect inconsistent obstacle
appearances regarding untrustworthy sensor values and navigate the movable robot to continue moving so as to carry on a planned
task. By doing so, we manage to maintain a low cost for detection and mitigation but also retain the robot’s work efﬁcacy. We have
prototyped the bundle of ROBOFUZZ, detection and mitigation algorithms in a real-world movable robot. Experimental results conﬁrm
that ROBOFUZZ makes a success rate of up to 93.3% in imposing concrete threats to the robot while the overall loss of work efﬁcacy is
merely 4.1% at the mitigation mode.

Index Terms—Fuzzing, Autonomous Service Robot, Attack Detection and Mitigation

(cid:70)

1 INTRODUCTION
Autonomous service robots are widely used to not only
relieve people from dirty, monotonous, and dull tasks, but
also reduce economic costs [1, 2, 3, 4, 5]. For example,
cleaning robots gain wide popularity in tidying private
apartments and public places. Seoul-Incheon and Singapore
Changi airports have deployed cleaning robots to replace
human cleaners and the latter should save 20% housekeep-
ing manpowers [6, 7]. Since autonomous service robots are
sharing social spaces with humans at home, in the ofﬁces
and even in critical infrastructures like airports and banks,
their security and safety are of paramount importance,
especially concerning they are autonomous without human
attendance.

Robotics are generally categorized as cyber-physical sys-
tems (CPS). A robot typically has 1) a digital controller, e.g.,
Raspberry Pi, to manage the system, 2) physical compo-
nents, such as sensors and actuators, to sense the surround-
ing environment (e.g., distance) and to manipulate physical
entities (e.g., wheels and robotic arms), respectively, and
3) cyber components that connect the robot to networks
(e.g., for remote control via smartphones). The robot control
program running in the controller is critical to the security
and safety of a robot as it decides how to manoeuvre
actuators of the robot on reading sensor values. A number

• C. Wang, Y. C. Tok, S. Chattopadhyay, and M. R. Elara are with

Singapore Universtiy of Technology and Design, Singapore
E-mail:
sudipta chattopadhyay@sutd.edu.sg, and rajeshelara@sutd.edu.sg.

cd wang@outlook.com,

yeeching tok@mymail.sutd.edu.sg,

• R. Poolat is with National University of Singapore. This work was done
when she worked in Singapore University of Technology and Design.
Email: rohini poolat@yahoo.com.

Manuscript received MM DD, 2020; revised MM DD, 2020.

of studies have revealed that it is possible to compromise
a CPS through fraudulent sensor values, while mitigating
such attacks usually requires the involvement of a cloud
server for remote computation or attestation [8, 9, 10, 11, 12].
However, such methods are not applicable to autonomous
service robot. The reason is threefold. Firstly, the compu-
tational resource and battery capacity are relatively limited
for an economical autonomous service robot compared to
large CPS, say, a power grid. Secondly, the vast popularity
of autonomous service robots imposes overwhelming difﬁ-
culty on security patches or remote attestation from time
to time. Thirdly, many autonomous service robots move
themselves to complete planned tasks, which differentiates
them from stationary CPS like power grid or 3D printer
and necessitates a mitigation method that replenishes the
movement of autonomous service robot. As a result, it is
preferable and practical to secure an autonomous service
robot as early as at its design and implementation stage.

In this paper, we work at the standpoint of developers
to enhance the security and safety of autonomous service
robots, particularly ones that are movable because they
would be physically detrimental to human beings once com-
promised. We would proceed at two dimensions. On one
hand, we attempt to systematically scrutinize the security
threats to autonomous service robot through investigating
the values of critical sensors, since these sensor values, as in-
puts to the robot control program, determine the next states
of robot. On the other hand, with regard to the uncovered
threats, we develop an efﬁcient algorithm to mitigate their
impacts while retaining most of the robot’s work efﬁcacy.

Without loss of generality, we illustrate with an au-
tonomous service robot cruising by means of an ultrasonic
distance sensor to avoid obstacles. Once the distance sensor

 
 
 
 
 
 
IEEE TRANASCTIONS ON XXXXXX

2

indicates a close obstacle ahead, the robot control program
ought to direct the robot to turn left or right. Otherwise,
the robot would crash into the obstacle. As a result, alter-
ing the sensor value to be malicious for the robot control
program would inﬂict serious threats to the robot. We hence
employ the idea of software fuzzing to test the robot control
program. In software testing, fuzzing is used to identify
security vulnerabilities or bugs in a program by subjecting
the program to various kinds of input, and the program may
crash or yield absurd outputs [13, 14, 15]. By fuzzing the
robot control program, we aim to discover as many ﬂaws as
possible in the robot control program and secure the robot
in turn.

We use a state-of-the-art fuzzing tool, i.e., Radamsa [14],
to fuzz the robot control program of the aforementioned
movable robot employing a distance sensor for motion.
We generate and feed a series of distance sensor values
to the robot control program replacing real-world distances
when the robot is moving. The robot trembles because the
sensor values fuzzed by Radamsa, as intended to maximally
uncover bugs of a program, ﬂuctuate signiﬁcantly. We can
easily patch the robot control program with a ﬁlter to rule
out such volatile sensor values, since a moving robot work-
ing in a rational environment is expecting sensor values that
fall in a reasonable range in line with the environment and
the state of robot. For instance, a robot moving towards a
wall should continuously receive decreasing distance sensor
values.

The analysis over arbitrary and irregular sensor values,
however, implies us further in fuzzing the robot control
program, i.e., to test the control program with rational and
regular sensor values in a directed fuzzing way. The distance
can be viewed as a critical environmental parameter for a
moving service robot as it triggers state transitions for the
robot. For example, a moving robot receiving decreasing
distance sensor values would turn left or right while the
distance gradually drops below a threshold. Given a dy-
namic obstacle, say, an automatic sliding door, it may move
out of the robot’s path and the distance sensor value should
suddenly increase to a large value, after which the robot
keeps moving forward. Note that the robot control program
is unable to ascertain whether an obstacle is truly dynamic
or static solely depending on distance sensor values, be-
cause the scenarios where the distance either monotonically
decreases or abruptly increases are both possible in the real
world. Assume that the robot is moving towards a hard
wall, but we intentionally replace the distance sensor values
with ones that resemble the getaway of a dynamic obstacle.
The robot should collide with the wall.

The aforementioned example addresses the essence of
our directed fuzzing strategy, namely ROBOFUZZ. In a
nutshell, by investigating the state transitions and envi-
ronmental parameters that inﬂuence the behaviors of an
autonomous service robot, ROBOFUZZ generates rational
but harmful sensor values so as to mislead the robot for
concrete threats.

Adversaries can implement ROBOFUZZ with realistic
attack models, like suspending or fabricating sensor values,
to compromise an autonomous service robot. As devel-
opers, we move forward and defend against the attacks
entailed via ROBOFUZZ by detecting and mitigating them.

There are two concerns in doing so. First, the detection
and mitigation should not be heavyweight regarding the
limited computational resources of an autonomous service
robot. Secondly, once an attack is detected, the mitigation
cannot barely shut down the robot but maximally retain
the robot’s work efﬁcacy. Nevertheless, as mentioned, the
robot control program alone cannot rule out rational but
anomalous sensor values. We need further information that
can be used to counteract ROBOFUZZ. We note that, for
a movable service robot, such as a cleaning robot, it is
supposed to repeatedly cruise in a certain and steady place.
Consequently, the robot is able to make and maintain a his-
torical record of obstacles for the place [16]. Such a historical
record is an exploitable resource for us to detect the attacks
initiated through ROBOFUZZ. Concerning that ROBOFUZZ
deceives the robot control program using fuzzed distance
sensor values that emulate a dynamic obstacle, a historical
record can help the robot control program to cross-check
if the obstacle is really dynamic so as to avoid a collision
where necessary.

The historical record is also effectual for us to mitigate
the impact caused by ROBOFUZZ. A movable autonomous
robot must keep moving to complete the task planned for
it even in the presence of an untrustworthy distance sensor.
Although the robot control program cannot put reliance on
distance sensor values, it can reuse the historical record to
circumvent obstacles and navigate the robot. Reusing such
records not only retains a movable robot’s work efﬁcacy,
but also gains high cost efﬁciency in mitigating for an
economical robot.

The main ideas of this paper are summarized as follows.
• We propose ROBOFUZZ which tests an autonomous ser-
vice robot by fuzzing rational but harmful sensor values
so as to mislead the robot’s control program;

• To defend against the attacks initiated by ROBOFUZZ,
we develop detection and mitigation methods which
leverage historical records to maximally protect the robot
and efﬁciently accomplish planned tasks.

ROBOFUZZ and strategies of detection and mitigation to
contract ROBOFUZZ form a self-contained and systematic
scheme that help to develop a secure autonomous service
robot. We have prototyped them with a real-world movable
robot, i.e., iRobot Create 2 with an HC-SR04 distance sensor.
Experimental results conﬁrm that ROBOFUZZ attains up
to 93.3% success rate in imposing threats onto a moving
iRobot Create 2. Our detection and mitigation methods also
efﬁciently detect attacks at a very high rate and make the
robot being under attack accomplish scheduled tasks with
an insigniﬁcant loss of work efﬁcacy, i.e., 4.1% overall.

The remainder of this paper is organized as follows.
In Section 2, we present the background of autonomous
service robot and attack models it is prone to. We conduct
a motivational study to incur concrete threats to a movable
service robot in Section 3. In Section 4, we detail the design
and methodology of ROBOFUZZ. In Section 5 and Section 6,
respectively, we show our algorithms for detecting and
mitigating threats incurred by ROBOFUZZ. We present ex-
perimental results with a prototype built with iRobot Create
2 in Section 7. We discuss threats to validity in Section 9 and
conclude the paper in Section 10.

IEEE TRANASCTIONS ON XXXXXX

3

(a) Suspension Attack

Fig. 1: A Illustration of Autonomous Service Robot and
Adversaries

2 BACKGROUND AND RELATED WORK

In contrast to robots used by manufacturers or special-
ists, service robots are close to people and easy to operate,
providing a variety of services, such as housekeeping and
entertainment [3, 4]. According to ISO standard [17], a
service robot is a class of robots that “perform useful tasks
for humans or equipment excluding industrial automation
applications”. A movable autonomous service robot, such
as the typical cleaning robot, has following components: 1)
a digital controller such as Raspberry Pi or Arduino Mega
where a control program runs, 2) numerous sensors to sense
surroundings, 3) wheels to move the robot around, and
4) cyber accessories for network connection. Autonomous
service robot puts reliance on the control program to decide
the next move of it in accordance with sensor values ob-
tained from time to time. Regarding sensors installed in a
service robot, they quantitatively measure and report the
environmental parameters the robot is encountering. For
example, a distance sensor tells whether the robot is too
close to any obstacle. Sensors may work in different modes.
A sensor working in the proactive mode alerts the robot
control program periodically or in case of emergency while a
sensor working in the passive mode pends the robot control
program to ask for sensor value.

Robots fall into the broad category of CPS. One outstand-
ing characteristic of CPS is the vast heterogeneity of building
blocks in different CPS for different usages [10, 18, 19, 20].
An autonomous service robot is signiﬁcantly distinct from
typical CPS such as power grids, handheld smartphones
or 3D printer [21, 22, 23]. First, an autonomous service
robot is generally a simple system with an economical
micro-controller and a few hardware components including
sensors, actuators, and network modules. Figure 1 shows a
classic architecture of autonomous service robot. Secondly,
autonomous service robots gain worldwide popularity in
our daily life. For example, iRobot has sold more than
20 million cleaning robots since its foundation [24] while
the sales volume of Xiaomi Mi robots has reached one
million in 18 months since its release date [25]. Assuming
that a critical ﬂaw of cleaning robot is uncovered, a large
population of users would be affected. Thirdly, unlike CPS
that undergo frequent maintenance services in subways,
hospitals, and power stations [26, 23, 27], many service
robots are unlikely to be promptly upgraded with security

(b) Fabrication Attack

Fig. 2: An Illustration of Typical Attacks Models

patches. To update a large number of robots or do remote
attestation for each of them is also challenging and costly
for a manufacturer. Finally, a movable service robot is not
stationary like 3D printer or handheld smartphone. Once
compromised, it might be manipluated to incur physical
damages to surrounding people.

In summary, the demand to study security-related is-
sues for autonomous service robots is actual and critical.
Recently, researchers have looked into the cyber security
of robots [28, 29, 30, 31]. The security issues should be
considered in the design phase of a service robot due to the
ever-increasing popularity of service robots and the ever-
growing strengths of adversaries. In this paper, we ﬁrst
proceed at the standpoint of developers to explore how
to reveal as many ﬂaws as possible for an autonomous
service robot. Then we continue to contemplate cost-efﬁcient
methods for detection and mitigation while retaining the
robot’s work efﬁcacy.

3 MOTIVATION AND OVERVIEW

3.1 Security Treats for Autonomous Service Robot

Recently, Bonaci et al. [26] investigated the vulnerabilities of
teleoperated surgical robots and Quarta et al. [32] performed
an empirical analysis on the security issues of industrial
robots. These works draw the attention of research commu-
nity to the security of robots found in factories, operating
rooms, and so on. Nevertheless, such awareness should
be extended to the security of autonomous service robots.
In practice, Giese and Wegemer have managed to hack a
Xiaomi Mi cleaning robot [33]. Their success should not only
alert robot manufacturers, but also the users of such service
robots.

As mentioned, the robot control program maneuvers an
autonomous service robot by reading sensor values. On the
other hand, the network interface of robot widely provides
adversaries an exploitable attack surface, because many
users still use default or weak passwords today, especially
for domestic robots. As a result, adversaries are bound to
manipulate the robot’s sensor values through unauthorized

SensorsControllerMotor, actuator, etc.Sensor Value Command Bluetooth/Wi-FiService RobotAdversariesControllerSensorActuatorActuator commandDropSensor value(distance: 5cm)ControllerSensorActuatorActuator commandAlter: 5cm100cmSensor value(distance: 5cm)IEEE TRANASCTIONS ON XXXXXX

4

(a) A static obstacle (e.g., a wall)

(b) A dynamic obstacle suddenly
moves in the same direction as
robot

(c) A dynamic obstacle suddenly
moves towards the robot

(d) A dynamic obstacle suddenly
moves out of the path of robot

Fig. 3: An Illustration of State Transitions for a Cleaning Robot Regarding Four Types of Obstacles

remote access so as to misguide the robot control pro-
gram. In the meantime, there are multiple attack models
for adversaries to follow. In this paper we consider two
harmful and representative ones that have been manifested
recently [34, 30], i.e., suspension attack and fabrication attack.

Suspension Attack: As shown in Figure 2(a), attack-
ers suspend sensors from sending out information. A sensor
at the passive mode, once suspended, would leave a null
response to the robot control program, which misleads the
control program to conclude that the sensor malfunctions. If
the sensor works at the proactive mode, the impact of sus-
pension attack should be even worse. Consider a distance
sensor that alerts the robot control program only in case of
a very close obstacle. After a successful suspension attack,
the control program would no longer receive any alert. As a
consequence, the robot might crash into an obstacle.

Fabrication Attack: With a fabrication attack, adver-
saries fabricate harmful sensor values and feed them to the
robot control program. As shown by Figure 2(b), when the
robot is in motion, the control program asks for a distance
sensor value to decide whether an obstacle is nearby to
the robot. Noticing such a request, adversaries replace the
normal sensor value with an anomalous one. The control
program would accordingly make a wrong decision and put
the robot into a concrete danger.

3.2 A Motional Study

Without loss of generality, we choose a programmable clean-
ing robot, i.e., iRobot Create 2 [35], for case study. We run
a control program in a Raspberry Pi 3 to maneuver the
robot and install an ultrasonic distance sensor (HC-SR04)
to enable the robot to avoid obstacles. As developers, we
use the WiFi interface shown in Figure 1 as the port to
communicate with the robot controller for monitoring and
debugging.

The distance to obstacles is a crucial environmental pa-
rameter for a cleaning robot. The control program depends
on the distance sensor values received at runtime to decide
whether the robot moves forward or turns. As these sensor
values are the input to the control program, the ﬁrst attempt
we did is leverage the idea of software fuzzing, which
generates various kinds of input values to a program so
as to inﬂict disorder or even crash to the program. We
used Radamsa [14], a state-of-the-art fuzzing tool, to make
a series of 1,006 values within the distance range supported
by HC-SR04 (2cm to 400cm). A segment of the values fuzzed
by Radamsa are as follows:

{..., 26, 128, 5, 16, 3, 241, 107, 6, 255, 45, 240, 4, 18, ...}

We supposed that such distance sensor values, when fed to
the control program, should have compromised the robot.
However, after we delivered them to satisfy the requests
raised by the control program, the control program would
refuse them as anomalies. We then analyzed the failure of
fuzzing control program in isolation. The reason is mainly
due to the concept of software fuzzing and the mechanism
of service robot. Fuzzing a program is used to reveal bugs
and security vulnerabilities of a program. Hence the fuzzed
inputs, as shown in the above segment, ﬂuctuate signiﬁ-
cantly so as to traverse different code paths and generate as
many corner cases as possible. Therefore, fuzzing the control
program is a good approach to test the program alone
but ignores the mechanism of service robot. As mentioned,
the control program transits a cleaning robot among states
depending on sensor values it receives. A cleaning robot
moving towards a wall will receive decreasing sensor values
and in the end it should turn or stop, so the robot transits
from a state of moving forward to the next state of turning
or stopping. Given sensor values fuzzed by Radamsa that
change strikingly and continually, they are easy to be distin-
guished since they obviously deviate from what the control
program expects in an ordinary environment.

We thoroughly investigate the states of cleaning robot
and environmental parameters that drive the robot to do
state transitions. We ﬁnd that, for a cleaning robot moving
at a stable velocity (e.g., 5cm/s), its state transitions are
affected by the distance to obstacles in four scenarios, as ide-
ally illustrated by Figure 3. In the four diagrams of Figure 3,
the Y axis is the distance to obstacles measured over time (cf.
X axis). In Figure 3(a), the robot is moving towards a ﬁxed
obstacle (e.g., a wall), so the distance gradually decreases
to zero. The remaining three diagrams show a robot meets
three types of dynamic obstacles. In Figure 3(b), at a time,
a dynamic obstacle (e.g., a pet) suddenly moves away at
a higher velocity and in the same direction as the robot,
so the distance stops dropping but increases abruptly. In
Figure 3(c), after 20s, the dynamic obstacle moves towards
the robot, which makes their distance decrease faster than
before. Figure 3(d) represents another kind of obstacle that
has been on the path of the robot but, at one moment,
moves out of the robot’s path, like the prompt open of
an automatic sliding door. The distance thus migrates to
another decreasing linear curve.

The four cases capture normal scenarios where the dis-
tance to obstacles, as a critical environmental parameter,
affects a cleaning robot in transiting its states at runtime,
say, to keep moving forward or turn/stop. The four curves

02040608010012014016018020001020304050Distance to Obstacle (cm)Time (second)02040608010012014016018020001020304050Distance to Obstacle (cm)Time (second)02040608010012014016018020001020304050Distance to Obstacle (cm)Time (second)02040608010012014016018020001020304050Distance to Obstacle (cm)Time (second)IEEE TRANASCTIONS ON XXXXXX

5

Fig. 4: An Overview of ROBOFUZZ, Detection and Mitiga-
tion

Fig. 5: An Illustration of State Composition of ROBOFUZZ

in Figure 3 help the control program rule out anomalous
sensor values like ones generated by Radamsa. More im-
portant, they inspire us with the opportunities to mislead the
control program. Note that the control program relies on
the distance sensor values to learn the distance to obstacles.
Consider a cleaning robot is steadily moving to a wall. We
are monitoring the robot’s state and the real distance by
reading sensor values. When the robot is close to the wall,
we fuzz increasing distance sensor values to emulate that
the obstacle is dynamic and moving away. If the control
program asks for distance sensor values, we will feed fuzzed
values to it. From the viewpoint of control program, such
increasing sensor values are absolutely rational regarding
Figure 3(b). So the robot is misled from the curve in Fig-
ure 3(a) to the one in Figure 3(b). In the end, the robot shall
crash into the wall.

3.3 Overview

Figure 4 illustrates an overview of the three schemes pro-
posed in this paper. The preceding motivating example
indicates the essence of ROBOFUZZ (at the leftmost corner
of Figure 4). By closely monitoring the state of a robot and
its environmental parameters ( 1 in Figure 4), ROBOFUZZ
starts to deceive the robot’s control program at an appro-
priate occasion with faked but rational sensor values ( 2
in Figure 4) so as to inﬂict concrete harm to the movable
robot.

The sensor values fuzzed by ROBOFUZZ should impose
concrete security breaches to autonomous service robots.
Because our intention is to enhance the security and safety
of autonomous service robots at their design and imple-
mentation stage, we need to defend against ROBOFUZZ.
We subsequently develop detection and mitigation schemes,
i.e., Shade and Remit at the top of Figure 4, to counteract
ROBOFUZZ. The detection and mitigation reside within the
robot control program. As a result, they can learn the robot’s
states and historical records of the environment in which the
robot is working. Using such information ( 3 in Figure 4),
the detection module would report whether the sensor
values are compromised or not ( 4 in Figure 4). Upon an
alert of detected attacks, the robot control program cannot
rely on the sensor values to proceed moving. Instead, the
mitigation module would be activated to leverage historical
records ( 5 in Figure 4) of obstacles in the environment so

as to navigate the robot to complete planned tasks ( 6 in
Figure 4).

4 ROBOFUZZ
ROBOT

FOR AUTONOMOUS

SERVICE

In this section, we ﬁrst model the state transitions of
autonomous service robot and explain the feasibility and
procedure of ROBOFUZZ through state composition (cf.
Section 4.1). Then we model ROBOFUZZ, a systematic
scheme that effectively damages autonomous service robot
by fuzzing sensor values (cf. Section 4.2).

4.1 State Compositions of ROBOFUZZ

An autonomous service robot can be modeled as a ﬁnite
state machine (FSM). The upper-left part of Figure 5 cap-
tures a segment of a simpliﬁed FSM for a cleaning robot.
This segment applies to all four scenarios mentioned in
Section 3 as it shows how the cleaning robot proceeds on
meeting an obstacle that can be either ﬁxed or movable.
Meanwhile, as developers of the robot, we maintain the FSM
(cf. Figure 5) and continuously observe the environmental
parameters from time to time. The outcome of ROBOFUZZ
hence can be viewed as a composition of two FSMs ( 1 in
Figure 5). In particular, once ROBOFUZZ notices a signiﬁcant
change of an environmental parameter that is to incur a
state transition, like the distance to an obstacle decreasing to
be very small, ROBOFUZZ will fabricate a series of rational
sensor values and feed them to the robot control program to
make an illusion ( 2 in Figure 5), e.g., the obstacle moving
away. By doing so, ROBOFUZZ misleads the robot into the
FSM intended by ROBOFUZZ, which, however, the robot
control program will not be aware of. Eventually the robot
is supposed to be wrecked because of hitting the obstacle
( 3 in Figure 5).

We note that the main purpose of ROBOFUZZ is to
unveil the vulnerability of robot control program and in
turn compromise the robot through fuzzing sensor values.
ROBOFUZZ is an automated procedure. It keeps monitor-
ing the states of robot and environmental parameters. At
a proper occasion, it activates the state composition with
faked but rational sensor values to deceive the robot control
program.

Sensor Value Command RoboFuzz(Fuzzing)Shade (Detection)Remit (Mitigation)Control programRobot Controller Detected?①②③④⑥⑤Robot’s states Records of environment Operational States of an AdversaryMove forwardTurn/stopOperational States of Cleaning RobotComposeObstacle is closeObstacle moves awayMove forwardObstacle moves awayObstacle is closeTurn/stopMove ForwardObstacle moves awayRobot to be wrecked12Obstacle is far away3Move forwardTurn/stopObstacle is closeObstacle moves awayIEEE TRANASCTIONS ON XXXXXX

6

4.2 Fuzzing Autonomous Service Robots with ROBO-
FUZZ

How ROBOFUZZ compromises an autonomous service
robot is modeled as follows. Because ROBOFUZZ works in
line with the state of an autonomous service robot and the
environment, it falls into the category of directed fuzzing.
Directed fuzzing starts off with a given target, such as
damaging the robot or reducing the robot’s work efﬁcacy.
Let these targets form a set,

T = {τ0, τ1, ..., τi, ..., τn−1},
where τi (0 ≤ i < n) is one independent target, e.g., to
damage the robot, and the value of n depends on the in-
tention of adversaries. Before fuzzing, we, at the standpoint
of adversaries, assume that the physical states of the robot
monitored at runtime form a set, i.e.,

Z = {ζ0, ζ1, ..., ζk, ..., ζp−1}.
We also assume a thorough understanding of the robot,
particularly all the components embodied in the robot, say,
C = {s0, s1, ..., sl−1, a0, a1, ..., am−1},
in which there exist all l sensors and m actuators. ROBO-
FUZZ relies on the l sensors to spot the environment. In
addition, ROBOFUZZ can also utilize actuators for a target
although we use sensors for illustration in preceding sec-
tions, e.g., by driving wheels faster than usual towards an
obstacle.

To attain a speciﬁc target, ROBOFUZZ must formulate
1) what states and environmental parameters should be
monitored, 2) which sensors and actuators in C are useful
for the target, and 3) when (i.e., the aforementioned ‘appro-
priate’ occasion) and how to alter sensor values or actuator
commands for a detrimental state transition (e.g., transiting
between different curves shown in Figure 3).

.

(cid:68)

(cid:69)

v(i)
j

Hence, for a target τi, we need 1) a subset of Z, i.e., Zi,
which subsumes states that are useful for τi, 2) a subset of
C, say, Ci, which is a list of essential sensors and actuators
for τi, and 3) a set V i in which each element includes a tuple
for the j-th (0 ≤ j < |Ci|) sensor or actuator in Ci, i.e.,
, γ(i)
j

, f (i)
j
v(i)
is a normal sensor value/actuator command while γ(i)
j
j
is a fuzzed sensor value/actuator command. For instance,
v(i)
fall into the range of [2, 400] (cm) for an HC-
j
SR04 ultrasonic distance sensor. Note that both of them
can also be a special value ∅ which stands for the non-
existence of sensor value/actuator command. ∅ is useful
when there ought to be no sensor value/actuator command
or adversaries intentionally drop a sensor value/actuator
command. The third element in the tuple, i.e., f (i)
, is a
function,

and γ(i)
j

j

(cid:17)

(cid:16)
γ(i)
j

,

f (i)
j

→ Dom

: Zi × Dom

v(i)
j
where Dom(x) means the domain of x. Assuming that the
robot is at a state ζ ∈ Zi (e.g., moving forward) and one
or multiple environmental parameters are to change, like
when the distance to obstacles, i.e., v(i)
, is going to decrease
j
alters v(i)
to be 6cm, f (i)
j
(i.e., making a ﬁxed obstacle ‘move’). f (i)

, say, from 6cm to 60cm
j hence converts a

to γ(i)
j

(1)

j

(cid:16)

(cid:17)

Algorithm 1 The Gi for a Distance Sensor
Input: The target τi for fuzzing;
Ensure: γ(i)
j
1: while (the robot is working) do
2:
3:
4:

Get the current state ζk, and sensor value v(i)
j
if (τi is to crash the robot) then

for the distance sensor si;

;

5:
6:
7:

8:
9:

10:

11:
12:
13:
14:

15:

16:

17:

18:

then

if (v(i)
j
if (v(i)

is decreasing) then //Approaching an obstacle
j gradually decreasing) then
//Figure 3(a) ⇒ Figure 3(b)
When v(i)
j
f (i)
−−→ γ(i)
v(i)
j
else if (v(i)
j decreasing more sharply) then

is small enough, e.g., v(i)

continues to increase);

j < 20cm,

(γ(i)
j

j

//Figure 3(c) ⇒ Figure 3(b)
v(i)
j
gradually increases);

f (i)
−−→ γ(i)

(γ(i)
j

j

no longer decreases but

end if

else if (τi is to reduce the robot’s work efﬁcacy) then

increases and continue increasing) then

if (v(i)
j
//Figure 3(b) ⇒ Figure 3(a)
v(i)
j
else if (v(i)
j

f (i)
−−→ γ(i)

(γ(i)
j

j

continues to decrease);

suddenly increases but then drops)

//Figure 3(d) ⇒ Figure 3(a)
When v(i)
j
(γ(i)
j
end if

continues to decrease);

suddenly increase, v(i)
j

f (i)
−−→ γ(i)

j

end if

19:
20:
end if
21:
22: end while
23: Return γ(i)
j

to replace v(i)
j

for τi;

normal sensor value/actuator command or ∅ to be a still
rational but harmful value. Also it may replace a sensor
value/actuator command with ∅ to hinder the robot control
process from interacting with corresponding sensors/actu-
ators. f (i)
j keeps affecting the robot control process until the
achievement of target τi.

Finally, we capture a successful fuzzing procedure for

target τi as:

Gi (cid:15) τi,

(2)

in which Gi is deﬁned as
(cid:91)

(cid:110)

Gi =

(cid:104)v(i), γ(i), f (i)(cid:105) | (cid:104)v(i), γ(i), f (i)(cid:105) ∈ V i

ζ∈Zi

(3)

∧ Dom

f (i)(cid:17)
(cid:16)
Gi means that, for every state ζ ∈ Zi, ROBOFUZZ discovers
all tuples related to ζ and calls the respective function f (i) to
fabricate and/or drop one or multiple sensor values and/or
actuator commands for the success of τi.

v(i)(cid:17)(cid:111)
(cid:16)

= ζ × Dom

.

Implementing Gi: The implementation of Gi is based
on the rationale discussed in the preceding section (cf. Sec-
tion 3). Algorithm 1 shows the implementation of Gi for a
distance sensor while the target τi is either to crash the robot
or reduce the robot’s work efﬁcacy. ROBOFUZZ continuously
tracks running states of an autonomous service robot and
waits for a proper time to fuzz the robot ((Lines 1 to 2 in
Algorithm 1)). For instance, when the sensor value v(i)
is
j
gradually decreasing (Line 4), ROBOFUZZ realizes that there
is a ﬁxed obstacle ahead. Therefore, to crash the robot (τi

IEEE TRANASCTIONS ON XXXXXX

7

at Line 3), the Gi function would generate sensor values,
i.e., γ(i)
, which continue increasing to resemble a leaving
j
obstacle (Line 7). By doing so, ROBOFUZZ aims to use faked
sensor values to change the scenario shown by Figure 3(a)
to the one in Figure 3(b). Algorithms 1 also shows how to
convert scenarios for other types of obstacles ( Lines 8 to 10,
Lines 12 to 15, and Lines 16 to 18).

5 ATTACK DETECTION WITH SHADE

ROBOFUZZ provides a way to initiate successful attacks
to an autonomous service robot. In this section we will
consider how to efﬁciently detect attacks. We ﬁrst inves-
tigate possible attack models which, once integrated with
ROBOFUZZ, would carry the robot into misbehaving states.
Accordingly we look into three classic detection methods,
and develop a hybrid one with wider coverage, higher
accuracy and less overhead.

5.1 Classic Detection Methods

Fingerprinting: Hardware devices have their unique
physical characteristics [34], i.e., ﬁngerprints, such as the
sensor latency (i.e., response time). Assuming that attackers
fabricate and send fake sensor values via Wi-Fi, the sensor
latency observed by the control process should be extraor-
dinary as network latencies are generally one or two orders
of magnitude longer than typical sensor latencies. Take the
ultrasonic distance sensor (HC-SR04) for example. Its sensor
latency mostly falls in a range of 2ms to 12ms. By contrast,
the network latency under TCP and UDP protocols varies
between 200ms and 250ms. If the robot control process has
learned a sensor’s normal latency, it is able to detect an
attack that delivers sensor values through the network.

Fingerprinting is advantageous with its simplicity and
low overhead. But it has limited usages. Given a sensor
working in a periodical or proactive mode, the robot control
process cannot measure its sensor latency for validation.

Cross-reference Validation (CRV): CRV leverages
information from two or more sources to cross-check for
veriﬁcation. The challenge in using CRV for an autonomous
service robot is that every sensor might be compromised
and using different sensors for cross-checking is unreliable.
Also, not many sensors are installed in a small service robot
for similar purposes. CRV must use some information that
attackers are unaware of. Let us still use the distance sensor
for example. A cleaning robot can make historical records
of the positions of stationary obstacles in a normal working
routine. In fact, some iRobot Roomba robots draw a map
of the space they have cleaned [16]. Such historical records
can be secured and used as the norm to validate distance
sensor values. If the distance sensor gives a value that badly
violates historical records, CRV can indicate the occurrence
of an attack.

Compared to ﬁngerprinting, CRV can detect attacks that
compromise sensors working in the proactive mode since
CRV cross-checks by exploiting extra historical records.
However, CRV requires continually tracking the robot’s
motion so as to refer to the correct record. Also, the accu-
racy of CRV is not very high because records have been
approximately made [36].

Fig. 6: An Illustration of Shade with Robot Controller

Algorithm 2 The Shade Process (Shade())

Input: A request for attack detection p with runtime informa-
tion; // p may contain the sensor mode µ, the sensor latency λ,
the current location of robot ζ, etc.

Ensure: An attack alert γ // γ will be either True or False

1: if (p is with sensor information) then
2:

if (µ is PASSIVE) then //Robot actively demands sensor

value

3:
4:
5:

// Shade calls ﬁngerprinting method with sensor latency
γ := fingerprinting_check(λ);

else // The sensor reports to robot periodically or in emer-

gency

end if

// Shade calls CRV ﬁrst with robot location, then NID
γ := CRV_check(ζ) Or NID_check();

6:
7:
8:
9: else // Robot controller queries without sensor information
10:
11:
12: end if
13: Return γ to the robot controller process;

// Shade calls NID method
γ := NID_check();

Network intrusion detection (NID): NID performs
an analysis over the behavior, payload and contents of
inbound and outbound network packets [37]. As attackers
remotely attack the robot via network, NID should be prac-
tical. Given a service robot working in a normal routine,
packets exchanged between it and a legitimate user must
follow a regular pattern and the network payload should
not change largely. But when attackers undertake to obtain
and alter sensor values, they would bring about unusual
network packets, either in a large quantity or with abnormal
contents. An independent process monitoring the network
trafﬁc should detect such breaches.

A major drawback of NID is its high cost in computa-
tion and energy. Therefore, in an autonomous service robot
powered by a battery, NID should be periodically called for
energy-efﬁciency [38]. Also, NID cannot capture all attacks
although they go through the network interface. Consider
suspension attacks. If attackers manage to compromise a
sensor just at the ﬁrst try with few packets, NID might
neglect such an attack.

5.2 The Design of Shade

Each of the aforementioned methods has its strengths and
limitations. We have developed a hybrid method called the
shadow detector (Shade). Shade acts as a shadow process of
the robot control process and closely communicates with
the latter to avoid missing any attack imprint. Figure 6
illustrates how the Shade process collaborates with robot
control process through inter-process communication. The
control process provides runtime information to Shade, such
as the motion trace, sensor values, sensor latencies, etc. On
the other side, Shade swiftly informs the control process in
case of attacks.

ControllerSensor valueShade ProcessRuntime informationAttack AlertSensorFingerprintingCRVNIDIEEE TRANASCTIONS ON XXXXXX

Algorithm 3 The Mitigation Process (Remit())

Input: A switch from normal mode to safe mode for mitigation.
Ensure: A completion of task, or a switch back to normal mode.

1: repeat
2:
3:

Change/keep the robot moving at a lower speed;

// Navigate the robot with historical records used by

CRV_check()

4:
5:
6:
7:
8:
9:
10:
11:
12:

Call Navigate_with_historical_records();
Try to reset corresponding sensor;
Call Network_block_attacks() to block attackers;
if (attackers are successfully blocked) then

Return back to normal mode;

end if
// A dynamic obstacle (e.g., a pet) might appear
if (Robot cannot move with no obstacle recorded) then
Play sound to drive the person/pet, and wait 1

second;

end if
Continue moving with historical records;
if (the scheduled task is completed) then

13:
14:
15:
16:
17:
18: until (Shade() returns False); // No attack any longer
19: Switch back to the normal mode of robot control process;

Return a completion to the robot control process;

end if

Shade is a hybrid mechanism of ﬁngerprinting, CRV and
NID so as to achieve wide coverage, high accuracy and
low overhead. Algorithm 2 describes the main procedure of
Shade. The robot control process sends a request for attack
detection either in an on-demand or periodical way and
the Shade process returns whether an attack is happening
or not. If Shade receives a request with sensor information
(Lines 1 to 8 in Algorithm 2), it ﬁrst determines the working
mode of the sensor. Given a sensor working at a passive
mode with a measurable latency, Shade prefers the ﬁnger-
printing method that comes with low cost but high accuracy
(Lines 2 to 4). However, as to a sensor working in a proactive
or periodical mode, Shade calls CRV to validate the sensor
value against historical records (Lines 5 to 8); nevertheless,
due to the accuracy of CRV, Shade may use NID for double
check with a short-circuiting logical Or operator (Line 7).
Moreover, the robot control process may ask Shade without
any sensor information. For example, the control process can
consult Shade every ﬁve seconds. In this case, Shade needs
to execute NID that ﬁnds out abnormal network trafﬁcs
(Lines 9 to 11). In the end, Shade timely notiﬁes the robot
control process with a detection result (Line 13).

Shade can detect various attacks and it is beyond just in-
tegrating three methods in one process. First, Shade explores
the context provided by the robot control process for attack
detection. Generic NID can also detect the most attacks but
with high cost for self-learning and frequent computations.
Shade, however, gains legitimate network behaviors shared
by the robot control process, which surely entails higher
accuracy and less overhead. Second, Shade considers the
pros and cons of three methods and complement them for
wider coverage. Like at Line 7 of Algorithm 2, Shade makes
NID recheck if CRV generates a false result because of the
latter’s accuracy.

6 MITIGATION WITH REMIT
Once Shade detects any attack affecting an autonomous
service robot, we must mitigate the attack’s impact. A

8

straightforward solution is to halt the robot immediately.
However, a shutdown of the robot badly loses its work
efﬁcacy because the robot is supposed to have a scheduled
task, like tidying a room. As a result, we need a mitigation
algorithm that retains as much work efﬁcacy as possible
for the robot being attacked. In particular, the mitigation
algorithm ought to take into account two issues. First, an au-
tonomous service robot signiﬁcantly differs from stationary
CPS and handheld smartphones as the robot needs to move
itself to work. Since the distance sensor is not reliable due
to attacks, how to navigate the robot to continue its motion
must be resolved. Second, because of the limited resources
of a small service robot, including the computation capabil-
ity and energy supply, the mitigation algorithm should be
lightweight and cost-efﬁcient.

Regarding the two challenges, we have designed a mit-
igation algorithm, namely retaining-oriented mitigation (Re-
mit), to achieve the least loss of work efﬁcacy for an au-
tonomous service robot. One noteworthy point of Remit
is that, it reuses the historical records used by Shade in
detecting attacks with CRV, which not only preserves the
motion of robot, but also avoids any extra cost for enabling
the navigation. Algorithm 3 captures the procedure of Re-
mit. We deﬁne the robot without being attacked is in the
normal mode. Remit switches the robot to mitigation mode
once Shade detects an attack. On entering the safe mode,
the robot ﬁrst decelerates its speed (Line 2 of Algorithm 3).
This helps it have more time to respond to an emergent
object, say, an obstacle. Then, Remit leverages the historical
records to navigate the robot (Lines 3 to 4). Since these
records are not very accurate, Remit tries to repair the
compromised sensor through resetting (Line 5) and calls the
network module to block attackers (Line 6). If the attackers
are successfully blocked, Remit will switch the robot back
to the normal mode (Lines 7 to 8). Remit also needs to
deal with a dynamic obstacle (e.g., a pet or person) if the
robot cannot move at a time but no obstacle was recorded
(Lines 10 to 13). Remit alerts the pet or person by playing a
sound (Line 12) and continues moving (Line 14). If the robot
completes the scheduled task, Remit stops the robot (Lines
15 to 17). Otherwise, Remit repeats the aforementioned steps
until Shade detects no attack any more (Line 18).

Remit attempts to guarantee the work efﬁcacy of the
robot. Since the robot needs to move at a lower velocity,
the time needed to complete a planned task might become
longer. However, with regard to the robot being under
attack, such additional time cost is insigniﬁcant and accept-
able.

7 EVALUATION

In this section, we would evaluate ROBOFUZZ, Shade, and
Remit to answer following questions.

1) Does ROBOFUZZ manage to compromise an au-
tonomous service robot? Compared to other fuzzing
approaches, does ROBOFUZZ embrace a higher success
rate?

2) Is Shade able to detect most of the attacks initiated

through ROBOFUZZ?

3) Can Remit retain the work efﬁcacy of service robot

when mitigating the attacks detected by Shade?

IEEE TRANASCTIONS ON XXXXXX

9

(a) The Use Case Scenario for Testing ROBOFUZZ

(b) The Use Case Scenario for Testing Shade and Remit

Fig. 8: An Illustration of Use Case Scenarios for Evaluation

It has two rooms that are connected by an automatic sliding
door. The cleaning robot needs to clean both rooms starting
from the top-left corner. When the robot is working, we
try to compromise it using three fuzzing methods with two
attack targets: 1) to damage the robot by crashing it to a hard
obstacle (e.g., wall or cabinet), and 2) to reduce the robot’s
work efﬁcacy by preventing it from entering and cleaning
the right room. As to three fuzzing methods, the ﬁrst one
is Radamsa fuzzing sensor values for the control program,
the second one is random fuzzing that initiates an attack at
a random time with a hazardous alteration of sensor values
(e.g., changing v of 10cm to γ of 60cm), and the third one is
ROBOFUZZ. For both attack targets, we conducted 30 trials
for a fuzzing method. We deﬁne the success rate as the
fraction of the number of successful attacks to 30 trials in
percentage. We note that besides Shade, the robot control
program can rule out anomalous distance sensor values,
e.g., ones that ﬂuctuate greatly, and subsequently reset the
sensor.

Figure 8(b) captures the scenario we would use to test
Shade and Remit. The reason why we evaluate them in a
scenario different from Figure 8(a) is that we need a quan-
titative presentation to measure the work efﬁcacy of robot
in case of attacks. As mentioned, we use the quantitative
success rate to show the effectiveness of ROBOFUZZ. On the
other hand, the width of the room in Figure 8(b) is 200cm
that falls into the range of HC-SR04 (≤400cm); the cleaning
robot would cruise in the room, so we can record the exact
distance a robot cleans with and without attacks. To avoid
physically crashing the robot into walls or obstacles due
to attacks, we set a safe distance to be 20cm. In other
words, without any attack, when the distance to a wall or
obstacle drops below 20cm, the robot should stop moving
and turn left or right; however, on a successful attack, the
robot spins itself in front of an obstacle to indicate that it is
being attacked instead of really colliding with the obstacle.
Concerning the safe distance and the diameter of robot, the
robot would clean an estimate of 570cm overall in the room
of Figure 8(b). In addition, for the use of ﬁngerprinting and
CRV, we have run the robot without any attack to collect
sensor latencies and historical records of obstacles.

Fig. 7: An Illustration of Initiating an Attack

In brief, we ﬁrst present experimental setup and evaluation
results regarding the competence of ROBOFUZZ in compro-
mising a real-world cleaning robot with two attack targets.
Then we test Shade and Remit to show their effectiveness in
detecting two attack models and retaining the work efﬁcacy
of robot.

7.1 Evaluation Setup

Platform: We use the aforementioned iRobot Create
2 [35] as the platform for evaluation. We have prepared a
control program in Python 3 that runs in the Raspberry Pi
3 Model B+. The default velocity of the robot is set to be
50mm/s. The path planning of the robot follows the classic
zigzag fashion. The main sensor used for the path planning
is an ultrasonic distance sensor (HC-SR04) installed in front
of the robot. The sensor can detect an obstacle from 2cm
to 400cm. As mentioned in Section 2, in the robot control
program, we conﬁgure the sensor to work in different
modes to suit different attack models. In the passive sensor
mode, the control program asks for the sensor value. In the
proactive sensor mode, the sensor warns the control process
if an obstacle is nearby or periodically.

As to the attacker side,. we have implemented ROBO-
FUZZ with two attack models (cf. Section 3.1). In light of
the analyses in Section 3.1, we set the sensor mode to be
passive for fabrication attack model. For the suspension
attack model, we choose the proactive mode.

Implementation: In order to manipulate the iRobot
Create 2, we make attack programs in a computer with
Ubuntu 18.04. We ﬁrst exploit the attack vector of WiFi
interface of Raspberry Pi as the attack surface to invade the
robot. Today many users still use default or simple pass-
words or their credentials are stored in plain text [32, 33].
For a Raspberry Pi with Raspbian, its default username/-
password are ‘pi/raspberry’. After we successfully access
the robot, we start to compromise it. Figure 7 exempliﬁes
the process of altering one sensor value. As adversaries, we
fetch the sensor value v through network ( 1 in Figure 7),
and then alter it to be γ via the function f ( 2 in Figure 7).
After sending back γ and replacing v ( 3 and 4 in Figure 7),
the robot control program would proceed with γ instead
of v. At runtime, ROBOFUZZ frequently reads v, but only
when it perceives an appropriate opportunity, like the robot
approaching a wall, will it call f and send faked γ back to
mislead the robot control program.

Conﬁguration: We have made two scenarios to test
ROBOFUZZ, Shade and Remit, respectively. Figure 8(a)
shows the scenario we have used for testing ROBOFUZZ.

remote_read(𝑣);𝑓(𝑣𝛾);send_back(𝛾);𝑣= read_sensor();…do_act(𝑣); // 𝛾②𝑣𝛾 WiFiWiFi④𝑣 𝛾MemoryMemoryNetwork①Sensor value 𝑣③Altered sensor value 𝛾Robot TableChair Chair Auto sliding door Cabinet/shelf200cmRobotObstacleObstacleWall Wall IEEE TRANASCTIONS ON XXXXXX

10

(a) Robot moving towards a wall
without any attack

(b) Robot deceived with the ap-
pearance of dynamic obstacle

Fig. 9: A Comparison between Distance Sensor Values with
and without ROBOFUZZ when damaging the robot

(a) Robot moving towards auto-
matic sliding door

(b) Robot stopped with auto slid-
ing door changed to be an immov-
able wall

Fig. 10: A Comparison between Distance Sensor Values with
and without ROBOFUZZ when prematurely stopping the
robot

7.2 Target 1 for ROBOFUZZ: Damaging the Robot

In order to damage the robot, fuzzing methods must let
the robot crash into a ﬁxed obstacle in Figure 8(a). Note
that the robot was not really damaged in trials but would
play a special sound to indicate it was enforced to be within
5cm to an obstacle. Table 1 shows the number of successful
attacks out of overall 30 trials for three fuzzing methods
when they tried to achieve the target of damaging the
robot. Radamsa failed in all trials because the robot control
process certainly refused sensor values fuzzed by it as they
evidently deviate from normal sensor values expected in the
environment shown in Figure 8(a). As to random fuzzing,
with regards to multiple stationary walls and furnitures in
Figure 8(a), if it launched an attack at a moment when,
though being randomly picked, the robot was approaching
closely to any wall or furniture, the fuzzed sensor values
might make the robot hit the obstacle and in turn attain the
attack target. Whereas, since random fuzzing acts based on
randomization, the success rate is low as conﬁrmed by the
experimental results (5 out of 30 trials).

On the other hand, ROBOFUZZ successfully damaged
the robot in all 30 trials. Because ROBOFUZZ continued to
observe the environment and monitor the state of robot,
at a proper occasion, it would generate sensor values that
brought the robot from the curve in Figure 3(a) to the
one in Figure 3(b). For a thorough comparison, we have

(a) Suspension Attack Model

(b) Fabrication Attack Model

Fig. 11: The Reaction Time of Shade to Attacks at Different
Distances to Obstacle with Two Attack Models

collected distance sensor values in a normal routine without
any attack and when ROBOFUZZ took effect in one trial.
Figure 9(a) indicates that the sensor values from the normal
routine well ﬁt in a decreasing linear curve. On the other
hand, in Figure 9(b), the solid linear curve links genuine
sensor values before the attack initiated by ROBOFUZZ and
the dashed line ﬁts sensor values that impaired the robot.
The two diagrams in Figure 9 clearly verify the capability of
ROBOFUZZ.

7.3 Target 2 for ROBOFUZZ: Reducing the Work Efﬁcacy
of Robot

To reduce the work efﬁcacy of the cleaning robot, we
called three fuzzing methods to hinder the robot from tidy-
ing the right room. In other words, after the robot ﬁnished
cleaning up the left room, the robot should not cross the
automatic sliding door due to attacks. Table 2 shows that
ROBOFUZZ achieves a success rate of 93.3% while the rates
for Radamsa and random fuzzing are still low. Note that
the success rates for both random fuzzing and ROBOFUZZ
drop compared to that with the ﬁrst target. The reason is,
on damaging the robot, both fuzzing methods could ﬁnd
a number of static obstacles to leverage, but there is only
one automatic sliding door connecting two rooms. Even so,
ROBOFUZZ managed to sense the existence of automatic
sliding door, and successfully changed sensor values in the
most trials (28 out of 30) to be decreasing ones that emulated
the door as an immovable wall.

We again tracked sensor values when the robot was
going through the sliding door without attack (cf. Fig-
ure 10(a)). Also in one successful trial, we recorded sensor
values the control process received before and after ROBO-
FUZZ launched the attack (cf. Figure 10(b)). As observed
in Figure 10, after 12s, ROBOFUZZ effectively deceived the
robot which subsequently stopped in front of the automatic
sliding door.

7.4 Detection Results of Shade

We compared Shade to ﬁngerprinting, CRV and NID meth-
ods. We used ROBOFUZZ to initiate attacks in line with two
aforementioned attack models, i.e., suspension and fabri-
cation attacks. For each attack model, a detection method

TABLE 1: The number of successful trials and success rates
of three fuzzing methods to achieve the 1st target

TABLE 2: The number of successful trials and success rates
of three fuzzing methods to achieve the 2nd target

Fuzzing Method
The number of successful trials
Success rate

Radamsa
0
0%

Random fuzzing
5
16.7%

ROBOFUZZ
30
100%

Fuzzing Method
The number of successful trials
Success rate

Radamsa
0
0%

Random fuzzing
3
10.0%

ROBOFUZZ
28
93.3%

01020304050607080901000246810121416Distance to Obstacle (cm)Time (second)01020304050607080901000246810121416Distance to Obstacle (cm)Time (second)0204060801001201400246810121416182022242628303234Distance to Obstacle (cm)Time (second)020406080100120024681012141618Distance to Obstacle (cm)Time (second) 0 5 10 15 20 25 30255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(a) Suspension Attack  0 1 2 3 4 5255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(b) Extended Suspension Attack  0 0.2 0.4 0.6 0.8 1255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(c) Fabrication Attack  0 1 2 3 4 5255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(d) Masquerade Attack  0 5 10 15 20 25 30255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(a) Suspension Attack  0 1 2 3 4 5255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(b) Extended Suspension Attack  0 0.2 0.4 0.6 0.8 1255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(c) Fabrication Attack  0 1 2 3 4 5255075100125150175200Reaction Time (s)Distance to Obstacle (cm)(d) Masquerade Attack IEEE TRANASCTIONS ON XXXXXX

11

TABLE 3: Detection Results of Four Detection Methods under Two Attack Models

Attack Model

Suspension Attack Model
Fabrication Attack Model

Number of Trials Detected

Fingerprinting
0
10

CRV NID Shade
0
10

10
10

10
10

Average Reaction Time for Detection (unit: second)
Fingerprinting
Nil
0.6

CRV NID
Nil
27.1
10.1
0.8

Shade
27.2
0.6

different distances to the left wall. Figure 11 captures four
curves of reaction time for Shade. In particular, given an
attack occurring at a very short distance to the wall, say
25cm in Figure 11, Shade manages to detect it at 0.6s to 3s,
which efﬁciently protects the robot from security threats.

(a) Cleaned Distance

(b) Running time

7.5 Mitigation Results of Remit

Fig. 12: A Comparison between Remit with Attacks and
Normal Routine

underwent ten trials of attacks. So in all we performed
2 × 4 × 10 = 80 trials regarding the composition of detection
methods and attack models. Every trial was triggered at the
startup of the robot, which means the robot is at the top-
right corner as shown in Figure 8(b). We did so because an
attack at the very beginning may incur the most challenges
for a detection method, especially when the sensor works
at a proactive mode reporting boolean values. We use two
metrics to evaluate the effect of detection. One is the number
of trials that a detection method successfully detected under
an attack model. The other one is the average reaction time
of ten trials for a detection method under each attack model.
Table 3 summarizes the results collected in 80 trials.
Shade has successfully detected all trials while the limi-
tations of other three methods are evident. For example,
ﬁngerprinting is competent only when the sensor works in
the passive mode because the sensor latency is measurable.
NID is not suitable for a suspension attack as such an
attack model manages to suspend the sensor at the ﬁrst
attempt, which hardly leaves any hint for NID to take effect.
Comparatively, Shade, as a hybrid detection method that
closely collaborates with the robot control program, is not
hindered by the working mode of sensors or attack models.
A notable observation revealed by Table 3 is that the
average reaction time of Shade is much shorter or compa-
rable than other detection methods. For suspension attacks,
CRV could detect them as well. Given a suspension attack
initiated at the startup of robot, only when the robot reached
the safe distance (20cm) would CRV ﬁnd that the sensor did
not raise a ‘True’ warning. This is why the average reaction
time for CRV and Shade is about 27s. For fabrication attacks,
ﬁngerprinting could instantly detect them. Meanwhile, the
reaction time of CRV is much shorter for fabrication attack
model than two preceding attack models. It is because of
the passive sensor mode with fabrication attacks. Once the
robot control program obtains a sensor value, it asks CRV to
check the numeric distance, which facilitates CRV compared
to boolean values used in the preceding two attack models.
The default position to initiate an attack is when the
robot starts up, so the attack is issued at a distance of 200cm
to the obstacle. To further verify the efﬁciency of Shade, we
did more tests when ROBOFUZZ triggered attacks at eight

We have also done experiments to evaluate Remit. The
measurement of its effectiveness is the distance cleaned
by the robot while its efﬁciency is measured in terms of
running time to clean the use case in Figure 8(b). We ﬁrst
made the robot clean the use case in a normal routine
without any attack and recorded the cleaned distance as
well as running time. Then, we ran Remit with the robot
under attacks. Figure 12(a) and Figure 12(b) present the
results of cleaned distance and running time, respectively,
for the normal routine and Remit. Since Remit leverages the
historical records maintained by Shade for cross-checking,
it can navigate the robot although the distance sensor is no
longer reliable. Owing to the accuracy limitation of records
in navigation, Remit made losses of 3.3% and 4.9%, respec-
tively, with two attack models. The overall loss is 4.1%.
Such insigniﬁcant losses conﬁrm the effectiveness of Remit.
On the other hand, after the robot entered the mitigation
mode, Remit reduced the velocity of robot by 10%. Though,
as the robot cleaned 4.1% less distances under attacks, the
total running time at the mitigation mode is eventually 5.0%
more than that of the normal routine. To sum up, Remit not
only accomplishes scheduled tasks but also restricts extra
time cost to an acceptable extent.

8 RELATED WORK

CPS must be highly secure, especially for autonomous
robotics systems [30, 29, 10, 39]. Researchers investigated
the cyber threats to teleoperated surgical robots [26, 40]. For
the cyber-security of industrial robots, Quarta et al. [32] per-
formed a thorough analysis. Comparatively, service robots
are close to human beings, usually working together for
service tasks [4]. Recently, Lera et al. [29] looked into the
security threats with a survey on the cyber-attacks associ-
ated to service robots as well as a taxonomy that classiﬁes
the risks in using service robots. However, not much work
has been done to compromise a movable service robot with
rational but harmful sensor values as ROBOFUZZ does. In
particular, Sabaliauskaite et al. [30] comprehensively devel-
oped methods to conduct cyber-attacks to a speciﬁc mobile
robot. Whereas, their methods were signiﬁcantly different
from ROBOFUZZ since they tried to use irrational sensor
values to crash the robot.

On the other hand, how to detect and mitigate attacks for
various CPS has been investigated [41, 42, 10, 34, 43]. For
example, Liu et al. [44] used partially observable Markov

0100200300400500600Suspension AttackFabrication AttackCleaned Distance (cm)Normal routine (w/o attack)Remit (under attack)020406080100120140160Suspension AttackFabrication AttackRunning TimeNormal routine (w/o attack)Remit (under attack)IEEE TRANASCTIONS ON XXXXXX

12

decision process to monitor and protect a smart home
against pricing attacks. Dutta et al. [11] utilized the chal-
lenge response authentication to detect attacks for active
sensors and the recursive least square algorithm to mitigate
the impact of attacks. Chhetri et al. [45] studied how to
detect an attack that could happen at various points of the
digital process chain of analog emissions in CPS like a 3D
printer.

Researchers have also looked into security issues of ser-
vice robots in other aspects. For instance, Guerrero-Higueras
et al. [36] attended attacks to real time location systems
for autonomous mobile robots. Li et al. [46] proposed to
upload the analysis of attack detection and mitigation to
a cloud server in the improved deep belief networks. Our
Shade and Remit differ from aforementioned approaches in
that they detect attacks within the computational resources
of an autonomous service robot and, furthermore, mitigate
attacks without badly losing the robot’s work efﬁcacy.

9 THREATS TO VALIDITY

In this paper, we focus on protecting movable au-
tonomous service robots. We use ROBOFUZZ to fuzz sensor
values that would impact the physical movement of robot.
We leverage the historical records of obstacles to detect
fuzzed sensor values and navigate the robot to retain work
efﬁcacy. The limits of our proposals are twofold. First, they
are not directly applicable to non-movable autonomous
robots. Second, ROBOFUZZ fuzzes sensor values which are
related to the movement of a robot; therefore, ROBOFUZZ
does not cover how to fuzz values for other types of sensors,
e.g., the detectors for dust and water.

The two attack models considered in this paper, i.e.,
suspension attack and fabrication attack, are comprehensive
and representative. Adversaries have managed to conduct
such attacks to CPS [34]. These two attack models target
compromising the sensor values and subsequently misguide
the robot control program. However, there exist other attack
models that are not discussed in this paper. For example,
a strong attacker may inject a malware in the control pro-
gram; consequently, the attacker does not rely on forging or
suspending sensor values to manipulate the robot.

The Shade and Remit schemes which detect and mitigate
attacks launched by ROBOFUZZ demand the support of
historical records of the environment. Thus, if a movable
robot is placed in a fresh environment, or new furnitures
are installed in the original environment, Shade and Remit
might not function effectively as the records of such changed
environments have not been fully obtained yet.

10 CONCLUSION

In this paper, we have considered security threats for
autonomous service robots in order to protect them. At
the standpoint of developers, we propose ROBOFUZZ that
automatically performs directed fuzzing in line with the
normal state transitions of robot and the environment where
the robot works. By fuzzing sensor values at appropriate
occasions, ROBOFUZZ misleads the robot to a rational but
dangerous state so as to compromise it.

Moving even further, we develop Shade and Remit to
detect and mitigate attacks initiated through ROBOFUZZ,
respectively. Shade and Remit take advantage of historical
records of obstacles to detect inconsistent obstacle appear-
ances regarding untrustworthy sensor values and navigate
the movable service robot to continue working in motion.
As a result, we are able to efﬁciently detect and mitigate
attacks but also retain the robot’s work efﬁcacy, which in
turn enhances the security and stability of autonomous
service robot. Experiments with a real-world cleaning robot
show that, 1) ROBOFUZZ dramatically outperforms fuzzing
robot control program than state-of-the-art fuzzing tools,
with much higher success rates of compromising the robot,
and 2) Shade and Remit maintain a high work efﬁcacy at the
mitigation mode with an insigniﬁcant loss.

REFERENCES

[1] P. Fiorini and E. Prassler. Cleaning and household
Autonomous Robots,

robots: A technology survey.
9(3):227–235, Dec 2000.

[2] D. Lee, W. Chung, and M. Kim. A reliable position
estimation method of the service robot by map match-
ing. In 2003 IEEE International Conference on Robotics and
Automation (ICRA), volume 2, pages 2830–2835 vol.2,
Sep. 2003.

[3] T. Haidegger, M. Barreto, P. Gonalves, M. K. Habib,
S. K. V. Ragavan, H. Li, A. Vaccarella, R. Perrone,
and E. Prestes. Applied ontologies and standards
for service robots. Robotics and Autonomous Systems,
61(11):1215 – 1223, 2013. Ubiquitous Robotics.

[4] M. Decker, M. Fischer, and I. Ott. Service robotics
and human labor: A ﬁrst technology assessment of
substitution and cooperation. Robotics and Autonomous
Systems, 87:348 – 354, 2017.

[5] S. Wang, X. Liu, J. Zhao, and H. I. Christensen. Rorg:
Service robot software management with linux con-
tainers. In 2019 International Conference on Robotics and
Automation (ICRA), pages 584–590, May 2019.

[6] LG Electronics.

koreas

over
https://www.lg.com/sg/press-release/
lg-airport-robots-take-over-koreas-largest-airport.

largest

LG airport
airport,

robots
July

take
2017.

Changi

Lim.
keep

[7] K.
to
//www.channelnewsasia.com/news/singapore/
changi-airport-turns-to-robots-to-keep-t4-clean-9112610.

airport
clean, August

robots
https:

turns
2017.

T4

to

[8] Y. Liu, Pl Ning, and M. K. Reiter. False data injection
attacks against state estimation in electric power grids.
In Proceedings of the 16th ACM Conference on Computer
and Communications Security, CCS ’09, pages 21–32,
New York, NY, USA, 2009. ACM.

[9] D. I. Urbina, J. A. Giraldo, A. A. Cardenas, N. O.
Tippenhauer, J. Valente, M. Faisal, J. Ruths, R. Candell,
and H. Sandberg. Limiting the impact of stealthy
attacks on industrial control systems. In Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Com-
munications Security, CCS ’16, pages 1092–1105, New
York, NY, USA, 2016. ACM.

[10] A. Chattopadhyay, A. Prakash, and M. Shaﬁque. Secure
cyber-physical systems: Current trends, tools and open

IEEE TRANASCTIONS ON XXXXXX

13

research problems. In Design, Automation Test in Europe
Conference Exhibition (DATE), 2017, pages 1104–1109,
March 2017.

[11] R. G. Dutta, X. Guo, T. Zhang, K. Kwiat, C. Kamhoua,
L. Njilla, and Y. Jin. Estimation of safe sensor mea-
surements of autonomous system under attack. In Pro-
ceedings of the 54th Annual Design Automation Conference
2017, DAC ’17, pages 46:1–46:6, New York, NY, USA,
2017. ACM.

[12] L. Cheng, K. Tian, and D. (D.) Yao. Orpheus: Enforcing
cyber-physical execution semantics to defend against
data-oriented attacks. In Proceedings of the 33rd Annual
Computer Security Applications Conference, ACSAC 2017,
pages 315–326, New York, NY, USA, 2017. ACM.
[13] A. Takanen, J. D. Demott, and C. Miller. Fuzzing for
Software Security Testing and Quality Assurance. Artech
House, Inc., Norwood, MA, USA, 1st edition, 2008.

[14] A. Helin.

Radamsa: a general-purpose fuzzer.

https://gitlab.com/akihe/radamsa, June 2018.

[15] M. B ¨ohme, V.-T. Pham, M.-D. Nguyen, and A. Roy-
In Proceedings
choudhury. Directed greybox fuzzing.
of the 2017 ACM SIGSAC Conference on Computer and
Communications Security, CCS ’17, pages 2329–2344,
New York, NY, USA, 2017. ACM.

[16] J. Vincent.

iRobot’s latest roomba remembers your
https://www.

homes layout and empties itself.
theverge.com/circuitbreaker/2018/9/6/17817220/
irobot-roomba-i7-robot-vacuum-empties-itself-maps-house,
September 2018.

[17] ISO

8373:2012.
–

and
devices
March
https://www.iso.org/standard/55890.html.

vocabulary,

Robots

robotic
2012.

[18] A. Humayed, J. Lin, F. Li, and B. Luo. Cyber-physical
IEEE Internet of Things

systems security – a survey.
Journal, 4(6):1802–1831, 2017.

[19] P. Moosbrugger, K. Y. Rozier, and J. Schumann. R2U2:
monitoring and diagnosis of security threats for un-
manned aerial systems. Formal Methods in System De-
sign, 51(1):31–61, Aug 2017.

[20] E. Bartocci et al. Speciﬁcation-Based Monitoring of Cyber-
Physical Systems: A Survey on Theory, Tools and Applica-
tions, pages 135–175. Springer International Publishing,
Cham, 2018.

[21] Y. Liu and S. Hu and T. Ho. Vulnerability assessment
and defense technology for smart home cybersecurity
In 2014 IEEE/ACM
considering pricing cyberattacks.
International Conference on Computer-Aided Design (IC-
CAD), pages 183–190, Nov 2014.

[22] A. Wasicek, P. Derler, and E. A. Lee. Aspect-oriented
modeling of attacks in automotive cyber-physical sys-
tems. In Proceedings of the 51st Annual Design Automa-
tion Conference, DAC ’14, pages 21:1–21:6, New York,
NY, USA, 2014. ACM.

[23] T. Wei, B. Zheng, Q. Zhu, and S. Hu. Security analysis
of proactive participation of smart buildings in smart
In 2015 IEEE/ACM International Conference on
grid.
Computer-Aided Design (ICCAD), pages 465–472, Nov
2015.

[24] iRobot Corporation.

iRobot, September 2018.
About-iRobot/Company-Information.aspx.

Company information of
http://www.irobot.com/

[25] bogdan-chub.

Robot vacuum cleaner Xiaomi Mi
robot vacuum stepped over the milestone, February
2018. http://gagadget.com/en/32219-robot-vacuum-
cleaner-xiaomi-mi-robot-vacuum-stepped-over-the-
milestone/.

[26] T. Bonaci, J. Herron, T. Yusuf, J. Yan, T. Kohno, and
H. J. Chizeck. To make a robot secure: An experimental
analysis of cyber security threats against teleoperated
surgical robots. CoRR, abs/1504.04339, 2015.

[27] B. Zheng, W. Li, P. Deng, L. Grardy, Q. Zhu, and
N. Shankar. Design and veriﬁcation for transportation
system security. In Proceedings of the 52nd Annual Design
Automation Conference, DAC ’15, pages 96:1–96:6, New
York, NY, USA, 2015. ACM.

[28] P. Salvini, G. Ciaravella, W. Yu, G. Ferri, A. Manzi,
B. Mazzolai, C. Laschi, S. R. Oh, and P. Dario. How
safe are service robots in urban environments? bullying
In 19th International Symposium in Robot and
a robot.
Human Interactive Communication, pages 1–7, Sep. 2010.
[29] F. J. R. Lera, C. F. Llamas, . M. Guerrero, and V. M.
Olivera. Cybersecurity of robotics and autonomous
systems: Privacy and safety. In George Dekoulis, editor,
Robotics, chapter 5. IntechOpen, Rijeka, 2017.

[30] G. Sabaliauskaite, G.S. Ng, J. Ruths, and A. Mathur.
A comprehensive approach, and a case study, for con-
ducting attack detection experiments in cyberphysical
systems. Robotics and Autonomous Systems, 98:174 – 191,
2017.

[31] L. A. Kirschgens, I. Z. Ugarte, E. Gil-Uriarte, A. M.
Rosas, and V. M. Vilches. Robot hazards: from safety to
security. CoRR, abs/1806.06681, 2018.

[32] D. Quarta, M. Pogliani, M. Polino, F. Maggi, A. M.
Zanchettin, and S. Zanero. An experimental security
analysis of an industrial robot controller. In 2017 IEEE
Symposium on Security and Privacy (SP), pages 268–286,
May 2017.

[33] D. Giese and D. Wegemer. Xiaomi smart home de-
vice reverse engineering and hacking, January 2018.
https://github.com/dgiese/dustcloud.

[34] K.-T. Cho and K. G. Shin. Fingerprinting electronic
In 25th
control units for vehicle intrusion detection.
USENIX Security Symposium (USENIX Security 16),
pages 911–927, Austin, TX, 2016. USENIX.

[35] iRobot Corporation.

iRobot Create R(cid:13) 2 pro-
grammable robot, August 2018. http://www.irobot.
com/About-iRobot/STEM/Create-2.aspx.

[36] . M. Guerrero-Higueras, N. DeCastro-Garca, and
V. Matelln.
Detection of cyber-attacks to indoor
real time localization systems for autonomous robots.
Robotics and Autonomous Systems, 99:75 – 83, 2018.
[37] R. Sommer and V. Paxson. Outside the closed world:
On using machine learning for network intrusion de-
tection. In 2010 IEEE Symposium on Security and Privacy,
pages 305–316, May 2010.

[38] K. Yan, L. Peng, M. Chen, and X. Fu. Exploring energy-
efﬁcient cache design in emerging mobile platforms.
ACM Trans. Des. Autom. Electron. Syst., 22(4):58:1–58:20,
July 2017.

[39] K. Ahmad Yousef, A. AlMajali, S. Ghalyon, W. Dweik,
and B. Mohd. Analyzing cyber-physical threats on
robotic platforms. Sensors, 18(5):1643, 2018.

IEEE TRANASCTIONS ON XXXXXX

14

[40] H. Alemzadeh, D. Chen, X. Li, T. Kesavadas, Z. T.
Kalbarczyk, and R. K. Iyer. Targeted attacks on teleop-
erated surgical robots: Dynamic model-based detection
In 2016 46th Annual IEEE/IFIP Inter-
and mitigation.
national Conference on Dependable Systems and Networks
(DSN), pages 395–406, June 2016.

[41] R. Mitchell and I.-R. Chen. A survey of intrusion
detection techniques for cyber-physical systems. ACM
Comput. Surv., 46(4):55:1–55:29, March 2014.

[42] B. Zheng, P. Deng, R. Anguluri, Q. Zhu, and
F. Pasqualetti. Cross-layer codesign for secure cyber-
physical systems. Trans. Comp.-Aided Des. Integ. Cir.
Sys., 35(5):699–711, May 2016.

[43] S. Belikovetsky et al. dr0wned – cyber-physical attack
In 11th USENIX Work-
with additive manufacturing.
shop on Offensive Technologies (WOOT 17), Vancouver,
BC, 2017. USENIX.

[44] Y. Liu, S. Hu, and T. Ho. Leveraging strategic detec-
tion techniques for smart home pricing cyberattacks.
IEEE Transactions on Dependable and Secure Computing,
13(2):220–235, March 2016.

[45] S. R. Chhetri, A. Canedo, and M. A. Al Faruque.
KCAD: Kinetic cyber-attack detection method for
cyber-physical additive manufacturing systems. In Pro-
ceedings of the 35th International Conference on Computer-
Aided Design, ICCAD ’16, pages 74:1–74:8, New York,
NY, USA, 2016. ACM.

[46] L. Li, L. Xie, W. Li, Z. Liu, and Z. Wang.

Improved
deep belief networks (IDBN) dynamic model-based
detection and mitigation for targeted attacks on heavy-
duty robots. Applied Sciences, 8(5), 2018.

Chundong Wang received the Bachelor’s de-
gree in computer science from Xi’an Jiaotong
University (2004-2008), and the Ph.D. degree
in computer science from National University of
Singapore (2008-2013). Currently he is a re-
search fellow in Singapore University of Tech-
nology and Design (SUTD), Singapore. Before
joining SUTD, he worked as a scientist in Data
Storage Institute, A(cid:63)STAR, Singapore. Chun-
dong has published a number of papers in IEEE
TC, ACM TOS, DAC, DATE, LCTES, USENIX
FAST, etc. His research interests include data storage systems, non-
volatile memory and computer architecture.

Yee Ching Tok received the Master’s degree in
information security from Royal Holloway, Uni-
versity of London, United Kingdom, in 2017. He
is currently a PhD Student with the Information
Systems Technology and Design Pillar, Singa-
pore University of Technology and Design, Sin-
gapore. His current research interests are as-
sessment of security in cyber-physical Systems,
attack detection, and malicious software. Before
pursuing his PhD degree, he worked as a Threat
Hunter at Countercept where he helped to de-
tect, respond and reduce impacts caused by malicious attackers to
clients’ critical assets. He has also carried out responsible disclosure
of vulnerabilities to device manufacturers in his course of professional
and academic research activities.

Yee Ching serves as an executive committee member in the Associa-

tion of Information Security Professionals in Singapore.

Rohini Poolat received the Master of Technol-
ogy in Software Engineering from the National
University of Singapore, Singapore in 2009. She
is a research assistant in the cyber security re-
search team at Singapore University of Technol-
ogy and Design (SUTD), Singapore. She has
worked on all phases of the software develop-
ment cycle in various industry projects before
moving into the research area. Her research in-
terests include cyber-attack detection, mitigation
and solutions to prevent attacks.

Sudipta Chattopadhyay received the Ph.D. de-
gree in computer science from the National Uni-
versity of Singapore, Singapore, in 2013. He is
an Assistant Professor with the Information Sys-
tems Technology and Design Pillar, Singapore
University of Technology and Design, Singapore.
In his doctoral dissertation, he researched on
Execution-Time Predictability, focusing on Mul-
ticore Platforms. He seeks to understand the in-
ﬂuence of execution platform on critical software
properties, such as performance, energy, robust-
ness, and security. His research interests include program analysis,
embedded systems, and compilers.

Mr. Chattopadhyay serves in the review board of the IEEE Transac-

tions on Software Engineering.

Mohan Rajesh Elara received the B.E. degree
from the Bharathiar University, India, in 2003,
and the M.Sc. and Ph.D. degrees from Nanyang
Technological University in 2005 and 2012, re-
spectively. He is currently an Assistant Profes-
sor with the Engineering Product Development
Pillar, Singapore University of Technology and
Design. He is also a Visiting Faculty Member
with the International Design Institute, Zhejiang
University, China. He has published over 80
papers in leading journals, books, and confer-
ences. His research interests are in robotics with an emphasis on self-
reconﬁgurable platforms as well as research problems related to robot
ergonomics and autonomous systems. He was a recipient of the SG
Mark Design Award in 2016 and 2017, the ASEE Best of Design in
Engineering Award in 2012, and the Tan Kah Kee Young Inventors
Award in 2010.

P.Veerajagadheswaretal.:Tiling-TheoreticApproachtoEfficientAreaCoverageinaTetris-InspiredFloorCleaningRobot[10]D.Sakamoto,K.Honda,M.Inami,andT.Igarashi,‘‘Sketchandrun:Astroke-basedinterfaceforhomerobots,’’inProc.ACMSIGCHIConf.Hum.FactorsComput.Syst.,Apr.2009,pp.197–200.[11]C.LuoandS.X.Yang,‘‘Areal-timecooperativesweepingstrategyformultiplecleaningrobots,’’inProc.IEEEInt.Symp.Intell.Control,Oct.2002,pp.660–665.[12]A.Janchiv,D.Batsaikhan,G.H.Kim,andS.-G.Lee,‘‘Completecoveragepathplanningformulti-robotsbasedon,’’inProc.IEEE11thInt.Conf.Control,Autom.Syst.(ICCAS),Oct.2011,pp.824–827.[13]M.AhmadiandP.Stone,‘‘Amulti-robotsystemforcontinuousareasweep-ingtasks,’’inProc.IEEEInt.Conf.Robot.Automat.(ICRA),May2006,pp.1724–1729.[14]M.JagerandB.Nebel,‘‘Dynamicdecentralizedareapartitioningforcooperatingcleaningrobots,’’inProc.IEEEInt.Conf.Robot.Autom.(ICRA),vol.4,May2002,pp.3577–3582.[15]Y.WuandR.Lu,‘‘OutputsynchronizationandL2-gainanaly-sisfornetworksystems,’’IEEETrans.Syst.,Man,Cybern.,Syst.,tobepublished.[16]Y.Wu,R.Lu,P.Shi,H.Su,andZ.-G.Wu,‘‘Adaptiveoutputsynchro-nizationofheterogeneousnetworkwithanuncertainleader,’’Automatica,vol.76,pp.183–192,Feb.2017.[17]S.Rhim,J.-C.Ryu,K.-H.Park,andS.-G.Lee,‘‘Performanceevalua-tioncriteriaforautonomouscleaningrobots,’’inProc.IEEEInt.Symp.Comput.Intell.Robot.Automat.(CIRA),Jun.2007,pp.167–172.[18]S.C.Wong,L.Middleton,B.A.MacDonald,andN.Auckland,‘‘Perfor-mancemetricsforrobotcoveragetasks,’’inProc.Australas.Conf.Robot.Autom.,vol.27,Nov.2002,p.29.[19]N.Tan,N.Rojas,R.E.Mohan,V.Kee,andR.Sosa,‘‘Nestedreconﬁg-urablerobots:Theory,design,andrealization,’’Int.J.Adv.RoboticSyst.,vol.12,no.7,p.110,Jul.2015.[20]N.Tan,R.E.Mohan,andK.Elangovan,‘‘Abio-inspiredreconﬁgurablerobot,’’inAdvancesinReconﬁgurableMechanismsandRobotsII.Cham,Switzerland:Springer,2016,pp.483–493.[21]G.Wei,J.S.Dai,S.Wang,andH.Luo,‘‘Kinematicanalysisandprototypeofametamorphicanthropomorphichandwithareconﬁgurablepalm,’’Int.J.HumanoidRobot.,vol.8,no.3,pp.459–479,2011.[22]S.Nansai,N.Rojas,M.R.Elara,andR.Sosa,‘‘Explorationofadaptivegaitpatternswithareconﬁgurablelinkagemechanism,’’inProc.IEEE/RSJInt.Conf.Intell.RobotsSyst.(IROS),Nov.2013,pp.4661–4668.[23]H.Wei,Y.Cai,H.Li,D.Li,andT.Wang,‘‘Sambot:Aself-assemblymodularrobotforswarmrobot,’’inProc.IEEEInt.Conf.Robot.Autom.(ICRA),May2010,pp.66–71.[24]S.Mintchevetal.,‘‘Anunderwaterreconﬁgurablerobotwithbioinspiredelectricsense,’’inProc.IEEEInt.Conf.Robot.Autom.(ICRA),May2012,pp.1149–1154.[25]V.Kee,N.Rojas,M.R.Elara,andR.Sosa,‘‘Hinged-Tetro:Aself-reconﬁgurablemodulefornestedreconﬁguration,’’inProc.IEEE/ASMEInt.Conf.Adv.Intell.Mechatronics(AIM),Jul.2014,pp.1539–1546.[26]V.Prabakaran,R.E.Mohan,T.Pathmakumar,andS.Nansai,‘‘hTetro:Atetrisinspiredshapeshiftingﬂoorcleaningrobot,’’inProc.IEEEInt.Conf.Robot.Autom.(ICRA),May2017,pp.6105–6112.[27]AlliedMarketResearch.(Feb.15,2017).CleaningServicesMarkettoReach$74,299Million,Globally,by2022.[Online].Available:https://www.prnewswire.com/news-releases/cleaning-services-market-to-reach-74299-million-globally-by-2022-613830813.html[28]E.GalceranandM.Carreras,‘‘Asurveyoncoveragepathplanningforrobotics,’’Robot.Auton.Syst.,vol.61,no.12,pp.1258–1276,2013.[29]C.S.Kaplan,IntroductoryTilingTheoryforComputerGraphics(SynthesisLecturesonComputerGraphicsandAnimation),vol.4.SanRafael,CA,USA:Morgan&Claypool,2009,pp.1–113.[30]V.Ostromoukhov,C.Donohue,andP.-M.Jodoin,‘‘Fasthierarchicalimportancesamplingwithbluenoiseproperties,’’ACMTrans.Graph.,vol.23,no.3,pp.488–495,Aug.2004.[31]Y.TakefujiandK.-C.Lee,‘‘Aparallelalgorithmfortilingproblems,’’IEEETrans.NeuralNetw.,vol.1,no.1,pp.143–145,Mar.1990.[32]C.-W.JhoandW.-H.Lee,‘‘Videopuzzlegameapplicationofpolyominore-tiling,’’inEmbeddedandMultimediaComputingTechnologyandSer-vice.Dordrecht,TheNetherlands:Springer,2012,pp.363–369.[33]K.-Y.Lo,C.-W.Fu,andH.Li,‘‘3Dpolyominopuzzle,’’ACMTrans.Graph.,vol.28,no.5,Dec.2009,Art.no.157.[34]P.Chiu,‘‘Generatingpolyominovideogamepiecesandpuzzlepiecesfromdigitalphotostocreatephotominoes,’’U.S.Patent7878891,Feb.1,2011.[35]G.N.Frederickson,HingedDissections:SwingingandTwisting.Cambridge,U.K.:CambridgeUniv.Press,2002.[36]E.D.Demaine,M.L.Demaine,D.Eppstein,G.N.Frederickson,andE.Friedman,‘‘Hingeddissectionofpolyominoesandpolyforms,’’Com-put.Geometry,vol.31,no.3,pp.237–262,2005.[37]E.D.Demaine,M.L.Demaine,J.F.Lindy,andD.L.Souvaine,‘‘Hingeddissectionofpolypolyhedra,’’inProc.WorkshopAlgorithmsDataStruct..Berlin,Germany:Springer,pp.205–217,Aug.2005.[38]R.Sarhangi,‘‘Makingpatternsonthesurfacesofswing-hingeddissec-tions,’’inProc.BridgesLeeuwarden,2008,pp.251–258.[39]D.Klarner,‘‘Polyominoes,’’inHandbookofDiscreteandComputationalGeometry,J.E.GoodmanandJ.O’Rourke,Eds.BocaRaton,FL,USA:CRCPress,1997,ch.12.[40]C.Lester,‘‘TilingwithTandskewtetrominoes,’’Querqus,LinﬁeldJ.Under,vol.1,no.1,p.3,Oct.2012.[41]V.Nitica.(Feb.2017).‘‘ThetilingsofdeﬁcientsquaresbyribbonL-tetrominoesarediagonallycracked.’’[Online].Available:https://arxiv.org/abs/1701.00419[42]Y.Wang,H.Shen,H.R.Karimi,andD.Duan,‘‘Dissipativity-basedfuzzyintegralslidingmodecontrolofcontinuous-timeT-Sfuzzysystems,’’IEEETrans.FuzzySyst.,vol.26,no.3,pp.1164–1176,Jun.2018.[43]Y.Wang,Y.Xia,H.Shen,andP.Zhou,‘‘SMCdesignforrobuststabiliza-tionofnonlinearMarkovianjumpsingularsystems,’’IEEETrans.Autom.Control,vol.63,no.1,pp.219–224,Jan.2018.PRABAKARANVEERAJAGADHESWARreceivedthebachelor’sdegreeinelectronicsandinstrumentationengineeringfromSathyabamaUniversity,India,in2013,andthemaster’sdegreeininformationtechnologyfromSikkimManipalUniversityin2017.HeiscurrentlyaResearchAssistantwiththeROARSLab,SingaporeUni-versityofTechnologyandDesign.HeisalsoaVisitingInstructorforadesigncoursewiththeInternationalDesignInstitute,ZhejiangUniver-sity,China.Hisresearchinterestsincludethedevelopmentofcompletecoveragepathplanning,SLAMframework,andembeddedcontrolforrecon-ﬁgurablerobots.HereceivedtheSGMarkDesignAwardin2017forthedesigningofhTetro,aself-reconﬁgurablecleaningrobot.MOHANRAJESHELARAreceivedtheB.E.degreefromtheBharathiarUniversity,India,in2003,andtheM.Sc.andPh.D.degreesfromNanyangTechnologicalUniversityin2005and2012,respectively.HeiscurrentlyanAssistantProfessorwiththeEngineeringProductDevelop-mentPillar,SingaporeUniversityofTechnologyandDesign.HeisalsoaVisitingFacultyMemberwiththeInternationalDesignInstitute,ZhejiangUniversity,China.Hehaspublishedover80papersinleadingjournals,books,andconferences.Hisresearchinterestsareinroboticswithanemphasisonself-reconﬁgurableplatformsaswellasresearchproblemsrelatedtorobotergonomicsandautonomoussystems.HewasarecipientoftheSGMarkDesignAwardin2016and2017,theASEEBestofDesigninEngineeringAwardin2012,andtheTanKahKeeYoungInventors’Awardin2010.35270VOLUME6,2018